ENOMEM	,	V_22
mbx_tbl	,	V_12
qlcnic_poll_rsp	,	F_7
");(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)}(NL)(NL)int(NL)qlcnic_fw_cmd_set_port(struct qlcnic_adapter *adapter, u32 config)(NL){(NL)	int err;(NL)	struct qlcnic_cmd_args cmd;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_CONFIG_PORT);(NL)	if (err)(NL)		return err;(NL)(NL)	cmd.req.arg[1] = config;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)	return err;(NL)}(NL)(NL)int qlcnic_alloc_hw_resources(struct qlcnic_adapter *adapter)(NL){(NL)	void *addr;(NL)	int err, ring;(NL)	struct qlcnic_recv_context *recv_ctx;(NL)	struct qlcnic_host_rds_ring *rds_ring;(NL)	struct qlcnic_host_sds_ring *sds_ring;(NL)	struct qlcnic_host_tx_ring *tx_ring;(NL)	__le32 *ptr;(NL)(NL)	struct pci_dev *pdev = adapter-&gt;pdev;(NL)(NL)	recv_ctx = adapter-&gt;recv_ctx;(NL)(NL)	for (ring = 0; ring &lt; adapter-&gt;drv_tx_rings; ring++) {(NL)		tx_ring = &amp;adapter-&gt;tx_ring[ring];(NL)		ptr = (__le32 *)dma_alloc_coherent(&amp;pdev-&gt;dev, sizeof(u32),(NL)						   &amp;tx_ring-&gt;hw_cons_phys_addr,(NL)						   GFP_KERNEL);(NL)		if (ptr == NULL) {(NL)			err = -ENOMEM;(NL)			goto err_out_free;(NL)		}(NL)(NL)		tx_ring-&gt;hw_consumer = ptr;(NL)		/* cmd desc ring */(NL)		addr = dma_alloc_coherent(&amp;pdev-&gt;dev, TX_DESC_RINGSIZE(tx_ring),(NL)					  &amp;tx_ring-&gt;phys_addr,(NL)					  GFP_KERNEL);(NL)		if (addr == NULL) {(NL)			err = -ENOMEM;(NL)			goto err_out_free;(NL)		}(NL)(NL)		tx_ring-&gt;desc_head = addr;(NL)	}(NL)(NL)	for (ring = 0; ring &lt; adapter-&gt;max_rds_rings; ring++) {(NL)		rds_ring = &amp;recv_ctx-&gt;rds_rings[ring];(NL)		addr = dma_alloc_coherent(&amp;adapter-&gt;pdev-&gt;dev,(NL)					  RCV_DESC_RINGSIZE(rds_ring),(NL)					  &amp;rds_ring-&gt;phys_addr, GFP_KERNEL);(NL)		if (addr == NULL) {(NL)			err = -ENOMEM;(NL)			goto err_out_free;(NL)		}(NL)		rds_ring-&gt;desc_head = addr;(NL)(NL)	}(NL)(NL)	for (ring = 0; ring &lt; adapter-&gt;drv_sds_rings; ring++) {(NL)		sds_ring = &amp;recv_ctx-&gt;sds_rings[ring];(NL)(NL)		addr = dma_alloc_coherent(&amp;adapter-&gt;pdev-&gt;dev,(NL)					  STATUS_DESC_RINGSIZE(sds_ring),(NL)					  &amp;sds_ring-&gt;phys_addr, GFP_KERNEL);(NL)		if (addr == NULL) {(NL)			err = -ENOMEM;(NL)			goto err_out_free;(NL)		}(NL)		sds_ring-&gt;desc_head = addr;(NL)	}(NL)(NL)	return 0;(NL)(NL)err_out_free:(NL)	qlcnic_free_hw_resources(adapter);(NL)	return err;(NL)}(NL)(NL)int qlcnic_fw_create_ctx(struct qlcnic_adapter *dev)(NL){(NL)	int i, err, ring;(NL)(NL)	if (dev-&gt;flags &amp; QLCNIC_NEED_FLR) {(NL)		pci_reset_function(dev-&gt;pdev);(NL)		dev-&gt;flags &amp;= ~QLCNIC_NEED_FLR;(NL)	}(NL)(NL)	if (qlcnic_83xx_check(dev) &amp;&amp; (dev-&gt;flags &amp; QLCNIC_MSIX_ENABLED)) {(NL)		if (dev-&gt;ahw-&gt;diag_test != QLCNIC_LOOPBACK_TEST) {(NL)			err = qlcnic_83xx_config_intrpt(dev, 1);(NL)			if (err)(NL)				return err;(NL)		}(NL)	}(NL)(NL)	if (qlcnic_82xx_check(dev) &amp;&amp; (dev-&gt;flags &amp; QLCNIC_MSIX_ENABLED) &amp;&amp;(NL)	    qlcnic_check_multi_tx(dev) &amp;&amp; !dev-&gt;ahw-&gt;diag_test) {(NL)		err = qlcnic_82xx_mq_intrpt(dev, 1);(NL)		if (err)(NL)			return err;(NL)	}(NL)(NL)	err = qlcnic_fw_cmd_create_rx_ctx(dev);(NL)	if (err)(NL)		goto err_out;(NL)(NL)	for (ring = 0; ring &lt; dev-&gt;drv_tx_rings; ring++) {(NL)		err = qlcnic_fw_cmd_create_tx_ctx(dev,(NL)						  &amp;dev-&gt;tx_ring[ring],(NL)						  ring);(NL)		if (err) {(NL)			qlcnic_fw_cmd_del_rx_ctx(dev);(NL)			if (ring == 0)(NL)				goto err_out;(NL)(NL)			for (i = 0; i &lt; ring; i++)(NL)				qlcnic_fw_cmd_del_tx_ctx(dev, &amp;dev-&gt;tx_ring[i]);(NL)(NL)			goto err_out;(NL)		}(NL)	}(NL)(NL)	set_bit(__QLCNIC_FW_ATTACHED, &amp;dev-&gt;state);(NL)(NL)	return 0;(NL)(NL)err_out:(NL)	if (qlcnic_82xx_check(dev) &amp;&amp; (dev-&gt;flags &amp; QLCNIC_MSIX_ENABLED) &amp;&amp;(NL)	    qlcnic_check_multi_tx(dev) &amp;&amp; !dev-&gt;ahw-&gt;diag_test)(NL)			qlcnic_82xx_config_intrpt(dev, 0);(NL)(NL)	if (qlcnic_83xx_check(dev) &amp;&amp; (dev-&gt;flags &amp; QLCNIC_MSIX_ENABLED)) {(NL)		if (dev-&gt;ahw-&gt;diag_test != QLCNIC_LOOPBACK_TEST)(NL)			qlcnic_83xx_config_intrpt(dev, 0);(NL)	}(NL)(NL)	return err;(NL)}(NL)(NL)void qlcnic_fw_destroy_ctx(struct qlcnic_adapter *adapter)(NL){(NL)	int ring;(NL)(NL)	if (test_and_clear_bit(__QLCNIC_FW_ATTACHED, &amp;adapter-&gt;state)) {(NL)		qlcnic_fw_cmd_del_rx_ctx(adapter);(NL)		for (ring = 0; ring &lt; adapter-&gt;drv_tx_rings; ring++)(NL)			qlcnic_fw_cmd_del_tx_ctx(adapter,(NL)						 &amp;adapter-&gt;tx_ring[ring]);(NL)(NL)		if (qlcnic_82xx_check(adapter) &amp;&amp;(NL)		    (adapter-&gt;flags &amp; QLCNIC_MSIX_ENABLED) &amp;&amp;(NL)		    qlcnic_check_multi_tx(adapter) &amp;&amp;(NL)		    !adapter-&gt;ahw-&gt;diag_test)(NL)				qlcnic_82xx_config_intrpt(adapter, 0);(NL)(NL)		if (qlcnic_83xx_check(adapter) &amp;&amp;(NL)		    (adapter-&gt;flags &amp; QLCNIC_MSIX_ENABLED)) {(NL)			if (adapter-&gt;ahw-&gt;diag_test != QLCNIC_LOOPBACK_TEST)(NL)				qlcnic_83xx_config_intrpt(adapter, 0);(NL)		}(NL)		/* Allow dma queues to drain after context reset */(NL)		mdelay(20);(NL)	}(NL)}(NL)(NL)void qlcnic_free_hw_resources(struct qlcnic_adapter *adapter)(NL){(NL)	struct qlcnic_recv_context *recv_ctx;(NL)	struct qlcnic_host_rds_ring *rds_ring;(NL)	struct qlcnic_host_sds_ring *sds_ring;(NL)	struct qlcnic_host_tx_ring *tx_ring;(NL)	int ring;(NL)(NL)	recv_ctx = adapter-&gt;recv_ctx;(NL)(NL)	for (ring = 0; ring &lt; adapter-&gt;drv_tx_rings; ring++) {(NL)		tx_ring = &amp;adapter-&gt;tx_ring[ring];(NL)		if (tx_ring-&gt;hw_consumer != NULL) {(NL)			dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, sizeof(u32),(NL)					  tx_ring-&gt;hw_consumer,(NL)					  tx_ring-&gt;hw_cons_phys_addr);(NL)(NL)			tx_ring-&gt;hw_consumer = NULL;(NL)		}(NL)(NL)		if (tx_ring-&gt;desc_head != NULL) {(NL)			dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev,(NL)					  TX_DESC_RINGSIZE(tx_ring),(NL)					  tx_ring-&gt;desc_head,(NL)					  tx_ring-&gt;phys_addr);(NL)			tx_ring-&gt;desc_head = NULL;(NL)		}(NL)	}(NL)(NL)	for (ring = 0; ring &lt; adapter-&gt;max_rds_rings; ring++) {(NL)		rds_ring = &amp;recv_ctx-&gt;rds_rings[ring];(NL)(NL)		if (rds_ring-&gt;desc_head != NULL) {(NL)			dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev,(NL)					RCV_DESC_RINGSIZE(rds_ring),(NL)					rds_ring-&gt;desc_head,(NL)					rds_ring-&gt;phys_addr);(NL)			rds_ring-&gt;desc_head = NULL;(NL)		}(NL)	}(NL)(NL)	for (ring = 0; ring &lt; adapter-&gt;drv_sds_rings; ring++) {(NL)		sds_ring = &amp;recv_ctx-&gt;sds_rings[ring];(NL)(NL)		if (sds_ring-&gt;desc_head != NULL) {(NL)			dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev,(NL)				STATUS_DESC_RINGSIZE(sds_ring),(NL)				sds_ring-&gt;desc_head,(NL)				sds_ring-&gt;phys_addr);(NL)			sds_ring-&gt;desc_head = NULL;(NL)		}(NL)	}(NL)}(NL)(NL)int qlcnic_82xx_config_intrpt(struct qlcnic_adapter *adapter, u8 op_type)(NL){(NL)	struct qlcnic_hardware_context *ahw = adapter-&gt;ahw;(NL)	struct net_device *netdev = adapter-&gt;netdev;(NL)	struct qlcnic_cmd_args cmd;(NL)	u32 type, val;(NL)	int i, err = 0;(NL)(NL)	for (i = 0; i &lt; ahw-&gt;num_msix; i++) {(NL)		err = qlcnic_alloc_mbx_args(&amp;cmd, adapter,(NL)					    QLCNIC_CMD_MQ_TX_CONFIG_INTR);(NL)		if (err)(NL)			return err;(NL)		type = op_type ? QLCNIC_INTRPT_ADD : QLCNIC_INTRPT_DEL;(NL)		val = type | (ahw-&gt;intr_tbl[i].type &lt;&lt; 4);(NL)		if (ahw-&gt;intr_tbl[i].type == QLCNIC_INTRPT_MSIX)(NL)			val |= (ahw-&gt;intr_tbl[i].id &lt;&lt; 16);(NL)		cmd.req.arg[1] = val;(NL)		err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)		if (err) {(NL)			netdev_err(netdev, "	,	L_18
fw_cmd	,	V_43
QLCNIC_RCODE_INVALID	,	V_40
QLCNIC_RCODE_NOT_IMPL	,	V_38
", err);(NL)		goto out_free_rsp;(NL)	}(NL)(NL)	prsp_rds = ((struct qlcnic_cardrsp_rds_ring *)(NL)			 &amp;prsp-&gt;data[le32_to_cpu(prsp-&gt;rds_ring_offset)]);(NL)(NL)	for (i = 0; i &lt; le16_to_cpu(prsp-&gt;num_rds_rings); i++) {(NL)		rds_ring = &amp;recv_ctx-&gt;rds_rings[i];(NL)		reg = le32_to_cpu(prsp_rds[i].host_producer_crb);(NL)		rds_ring-&gt;crb_rcv_producer = ahw-&gt;pci_base0 + reg;(NL)	}(NL)(NL)	prsp_sds = ((struct qlcnic_cardrsp_sds_ring *)(NL)			&amp;prsp-&gt;data[le32_to_cpu(prsp-&gt;sds_ring_offset)]);(NL)(NL)	for (i = 0; i &lt; le16_to_cpu(prsp-&gt;num_sds_rings); i++) {(NL)		sds_ring = &amp;recv_ctx-&gt;sds_rings[i];(NL)		reg = le32_to_cpu(prsp_sds[i].host_consumer_crb);(NL)		if (qlcnic_check_multi_tx(adapter) &amp;&amp; !adapter-&gt;ahw-&gt;diag_test)(NL)			reg2 = ahw-&gt;intr_tbl[i].src;(NL)		else(NL)			reg2 = le32_to_cpu(prsp_sds[i].interrupt_crb);(NL)(NL)		sds_ring-&gt;crb_intr_mask = ahw-&gt;pci_base0 + reg2;(NL)		sds_ring-&gt;crb_sts_consumer = ahw-&gt;pci_base0 + reg;(NL)	}(NL)(NL)	recv_ctx-&gt;state = le32_to_cpu(prsp-&gt;host_ctx_state);(NL)	recv_ctx-&gt;context_id = le16_to_cpu(prsp-&gt;context_id);(NL)	recv_ctx-&gt;virt_port = prsp-&gt;virt_port;(NL)(NL)	netdev_info(netdev, "	,	L_13
dev	,	V_34
"CDRP command timeout: [%d]\n"	,	L_6
"CDRP command not supported: [%d]\n"	,	L_3
out_args	,	V_19
",(NL)		    recv_ctx-&gt;context_id, recv_ctx-&gt;state);(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)(NL)out_free_rsp:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, rsp_size, prsp,(NL)			  cardrsp_phys_addr);(NL)out_free_rq:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, rq_size, prq, hostrq_phys_addr);(NL)(NL)	return err;(NL)}(NL)(NL)void qlcnic_82xx_fw_cmd_del_rx_ctx(struct qlcnic_adapter *adapter)(NL){(NL)	int err;(NL)	struct qlcnic_cmd_args cmd;(NL)	struct qlcnic_recv_context *recv_ctx = adapter-&gt;recv_ctx;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_DESTROY_RX_CTX);(NL)	if (err)(NL)		return;(NL)(NL)	cmd.req.arg[1] = recv_ctx-&gt;context_id;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	if (err)(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_14
ARRAY_SIZE	,	F_3
", err);(NL)		err = -EIO;(NL)	}(NL)(NL)	ahw-&gt;total_nic_func = nic;(NL)	ahw-&gt;total_pci_func = nic + fcoe + iscsi;(NL)	if (ahw-&gt;total_nic_func == 0 || ahw-&gt;total_pci_func == 0) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_26
qlcnic_free_mbx_args	,	F_6
adapter	,	V_8
",(NL)			__func__, esw_cfg-&gt;op_mode);(NL)		return err;(NL)	}(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter,(NL)				    QLCNIC_CMD_CONFIGURE_ESWITCH);(NL)	if (err)(NL)		return err;(NL)(NL)	cmd.req.arg[1] = arg1;(NL)	cmd.req.arg[2] = arg2;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)(NL)	if (err != QLCNIC_RCODE_SUCCESS)(NL)		dev_err(dev, "	,	L_37
ahw	,	V_2
size	,	V_10
", err);(NL)		err = -EIO;(NL)	} else {(NL)		npar_info-&gt;pci_func = le16_to_cpu(nic_info-&gt;pci_func);(NL)		npar_info-&gt;op_mode = le16_to_cpu(nic_info-&gt;op_mode);(NL)		npar_info-&gt;min_tx_bw = le16_to_cpu(nic_info-&gt;min_tx_bw);(NL)		npar_info-&gt;max_tx_bw = le16_to_cpu(nic_info-&gt;max_tx_bw);(NL)		npar_info-&gt;phys_port = le16_to_cpu(nic_info-&gt;phys_port);(NL)		npar_info-&gt;switch_mode = le16_to_cpu(nic_info-&gt;switch_mode);(NL)		npar_info-&gt;max_tx_ques = le16_to_cpu(nic_info-&gt;max_tx_ques);(NL)		npar_info-&gt;max_rx_ques = le16_to_cpu(nic_info-&gt;max_rx_ques);(NL)		npar_info-&gt;capabilities = le32_to_cpu(nic_info-&gt;capabilities);(NL)		npar_info-&gt;max_mtu = le16_to_cpu(nic_info-&gt;max_mtu);(NL)	}(NL)(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)out_free_dma:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, nic_size, nic_info_addr,(NL)			  nic_dma_t);(NL)(NL)	return err;(NL)}(NL)(NL)/* Configure a NIC partition */(NL)int qlcnic_82xx_set_nic_info(struct qlcnic_adapter *adapter,(NL)			     struct qlcnic_info *nic)(NL){(NL)	int err = -EIO;(NL)	dma_addr_t nic_dma_t;(NL)	void *nic_info_addr;(NL)	struct qlcnic_cmd_args cmd;(NL)	struct qlcnic_info_le *nic_info;(NL)	size_t nic_size = sizeof(struct qlcnic_info_le);(NL)(NL)	if (adapter-&gt;ahw-&gt;op_mode != QLCNIC_MGMT_FUNC)(NL)		return err;(NL)(NL)	nic_info_addr = dma_zalloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, nic_size,(NL)					    &amp;nic_dma_t, GFP_KERNEL);(NL)	if (!nic_info_addr)(NL)		return -ENOMEM;(NL)(NL)	nic_info = nic_info_addr;(NL)(NL)	nic_info-&gt;pci_func = cpu_to_le16(nic-&gt;pci_func);(NL)	nic_info-&gt;op_mode = cpu_to_le16(nic-&gt;op_mode);(NL)	nic_info-&gt;phys_port = cpu_to_le16(nic-&gt;phys_port);(NL)	nic_info-&gt;switch_mode = cpu_to_le16(nic-&gt;switch_mode);(NL)	nic_info-&gt;capabilities = cpu_to_le32(nic-&gt;capabilities);(NL)	nic_info-&gt;max_mac_filters = nic-&gt;max_mac_filters;(NL)	nic_info-&gt;max_tx_ques = cpu_to_le16(nic-&gt;max_tx_ques);(NL)	nic_info-&gt;max_rx_ques = cpu_to_le16(nic-&gt;max_rx_ques);(NL)	nic_info-&gt;min_tx_bw = cpu_to_le16(nic-&gt;min_tx_bw);(NL)	nic_info-&gt;max_tx_bw = cpu_to_le16(nic-&gt;max_tx_bw);(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_SET_NIC_INFO);(NL)	if (err)(NL)		goto out_free_dma;(NL)(NL)	cmd.req.arg[1] = MSD(nic_dma_t);(NL)	cmd.req.arg[2] = LSD(nic_dma_t);(NL)	cmd.req.arg[3] = ((nic-&gt;pci_func &lt;&lt; 16) | nic_size);(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)(NL)	if (err != QLCNIC_RCODE_SUCCESS) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_24
qlcnic_82xx_alloc_mbx_args	,	F_2
QLCNIC_CDRP_RSP_TIMEOUT	,	V_26
qlcnic_api_unlock	,	F_18
cmd	,	V_14
in_args	,	V_17
qlcnic_dump_mbx	,	F_17
""	,	L_9
",(NL)		func_esw, port, rx_tx);(NL)	return -EIO;(NL)}(NL)(NL)static int __qlcnic_get_eswitch_port_config(struct qlcnic_adapter *adapter,(NL)					    u32 *arg1, u32 *arg2)(NL){(NL)	struct device *dev = &amp;adapter-&gt;pdev-&gt;dev;(NL)	struct qlcnic_cmd_args cmd;(NL)	u8 pci_func = *arg1 &gt;&gt; 8;(NL)	int err;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter,(NL)				    QLCNIC_CMD_GET_ESWITCH_PORT_CONFIG);(NL)	if (err)(NL)		return err;(NL)(NL)	cmd.req.arg[1] = *arg1;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	*arg1 = cmd.rsp.arg[1];(NL)	*arg2 = cmd.rsp.arg[2];(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)(NL)	if (err == QLCNIC_RCODE_SUCCESS)(NL)		dev_info(dev, "	,	L_33
kfree	,	F_5
signature	,	V_28
GFP_ATOMIC	,	V_21
rsp	,	V_18
QLCNIC_CDRP_ARG	,	F_14
QLCNIC_RCODE_INVALID_ARGS	,	V_36
qlcnic_fw_cmd_set_drv_version	,	F_19
",(NL)			    tx_ring-&gt;ctx_id, tx_ring-&gt;state);(NL)	} else {(NL)		netdev_err(netdev, "	,	L_16
arg	,	V_20
qlcnic_get_cmd_signature	,	F_1
"command timeout, response = 0x%x\n"	,	L_1
QLCNIC_RCODE_SUCCESS	,	V_42
",(NL)			 pci_func, id);(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)(NL)	return err;(NL)}(NL)(NL)int qlcnic_get_port_stats(struct qlcnic_adapter *adapter, const u8 func,(NL)		const u8 rx_tx, struct __qlcnic_esw_statistics *esw_stats) {(NL)(NL)	size_t stats_size = sizeof(struct qlcnic_esw_stats_le);(NL)	struct qlcnic_esw_stats_le *stats;(NL)	dma_addr_t stats_dma_t;(NL)	void *stats_addr;(NL)	u32 arg1;(NL)	struct qlcnic_cmd_args cmd;(NL)	int err;(NL)(NL)	if (esw_stats == NULL)(NL)		return -ENOMEM;(NL)(NL)	if ((adapter-&gt;ahw-&gt;op_mode != QLCNIC_MGMT_FUNC) &amp;&amp;(NL)	    (func != adapter-&gt;ahw-&gt;pci_func)) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_30
QLCNIC_CDRP_IS_RSP	,	F_10
QLCWR32	,	F_13
err	,	V_24
i	,	V_9
kcalloc	,	F_4
",(NL)			pci_func);(NL)	return err;(NL)}(NL)/* Configure eSwitch port(NL)op_mode = 0 for setting default port behavior(NL)op_mode = 1 for setting  vlan id(NL)op_mode = 2 for deleting vlan id(NL)op_type = 0 for vlan_id(NL)op_type = 1 for port vlan_id(NL)*/(NL)int qlcnic_config_switch_port(struct qlcnic_adapter *adapter,(NL)		struct qlcnic_esw_func_cfg *esw_cfg)(NL){(NL)	struct device *dev = &amp;adapter-&gt;pdev-&gt;dev;(NL)	struct qlcnic_cmd_args cmd;(NL)	int err = -EIO, index;(NL)	u32 arg1, arg2 = 0;(NL)	u8 pci_func;(NL)(NL)	if (adapter-&gt;ahw-&gt;op_mode != QLCNIC_MGMT_FUNC) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev, "	,	L_35
"%d""	,	L_8
", __func__, err);(NL)	}(NL)(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)(NL)out_free_dma:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, stats_size, stats_addr,(NL)			  stats_dma_t);(NL)(NL)	return err;(NL)}(NL)(NL)int qlcnic_get_eswitch_stats(struct qlcnic_adapter *adapter, const u8 eswitch,(NL)		const u8 rx_tx, struct __qlcnic_esw_statistics *esw_stats) {(NL)(NL)	struct __qlcnic_esw_statistics port_stats;(NL)	u8 i;(NL)	int ret = -EIO;(NL)(NL)	if (esw_stats == NULL)(NL)		return -ENOMEM;(NL)	if (adapter-&gt;ahw-&gt;op_mode != QLCNIC_MGMT_FUNC)(NL)		return -EIO;(NL)	if (adapter-&gt;npars == NULL)(NL)		return -EIO;(NL)(NL)	memset(esw_stats, 0, sizeof(u64));(NL)	esw_stats-&gt;unicast_frames = QLCNIC_STATS_NOT_AVAIL;(NL)	esw_stats-&gt;multicast_frames = QLCNIC_STATS_NOT_AVAIL;(NL)	esw_stats-&gt;broadcast_frames = QLCNIC_STATS_NOT_AVAIL;(NL)	esw_stats-&gt;dropped_frames = QLCNIC_STATS_NOT_AVAIL;(NL)	esw_stats-&gt;errors = QLCNIC_STATS_NOT_AVAIL;(NL)	esw_stats-&gt;local_frames = QLCNIC_STATS_NOT_AVAIL;(NL)	esw_stats-&gt;numbytes = QLCNIC_STATS_NOT_AVAIL;(NL)	esw_stats-&gt;context_id = eswitch;(NL)(NL)	for (i = 0; i &lt; adapter-&gt;ahw-&gt;total_nic_func; i++) {(NL)		if (adapter-&gt;npars[i].phy_port != eswitch)(NL)			continue;(NL)(NL)		memset(&amp;port_stats, 0, sizeof(struct __qlcnic_esw_statistics));(NL)		if (qlcnic_get_port_stats(adapter, adapter-&gt;npars[i].pci_func,(NL)					  rx_tx, &amp;port_stats))(NL)			continue;(NL)(NL)		esw_stats-&gt;size = port_stats.size;(NL)		esw_stats-&gt;version = port_stats.version;(NL)		QLCNIC_ADD_ESW_STATS(esw_stats-&gt;unicast_frames,(NL)						port_stats.unicast_frames);(NL)		QLCNIC_ADD_ESW_STATS(esw_stats-&gt;multicast_frames,(NL)						port_stats.multicast_frames);(NL)		QLCNIC_ADD_ESW_STATS(esw_stats-&gt;broadcast_frames,(NL)						port_stats.broadcast_frames);(NL)		QLCNIC_ADD_ESW_STATS(esw_stats-&gt;dropped_frames,(NL)						port_stats.dropped_frames);(NL)		QLCNIC_ADD_ESW_STATS(esw_stats-&gt;errors,(NL)						port_stats.errors);(NL)		QLCNIC_ADD_ESW_STATS(esw_stats-&gt;local_frames,(NL)						port_stats.local_frames);(NL)		QLCNIC_ADD_ESW_STATS(esw_stats-&gt;numbytes,(NL)						port_stats.numbytes);(NL)		ret = 0;(NL)	}(NL)	return ret;(NL)}(NL)(NL)int qlcnic_clear_esw_stats(struct qlcnic_adapter *adapter, const u8 func_esw,(NL)		const u8 port, const u8 rx_tx)(NL){(NL)	struct qlcnic_hardware_context *ahw = adapter-&gt;ahw;(NL)	struct qlcnic_cmd_args cmd;(NL)	int err;(NL)	u32 arg1;(NL)(NL)	if (ahw-&gt;op_mode != QLCNIC_MGMT_FUNC)(NL)		return -EIO;(NL)(NL)	if (func_esw == QLCNIC_STATS_PORT) {(NL)		if (port &gt;= ahw-&gt;max_vnic_func)(NL)			goto err_ret;(NL)	} else if (func_esw == QLCNIC_STATS_ESWITCH) {(NL)		if (port &gt;= QLCNIC_NIU_MAX_XG_PORTS)(NL)			goto err_ret;(NL)	} else {(NL)		goto err_ret;(NL)	}(NL)(NL)	if (rx_tx &gt; QLCNIC_QUERY_TX_COUNTER)(NL)		goto err_ret;(NL)(NL)	arg1 = port | QLCNIC_STATS_VERSION &lt;&lt; 8 | func_esw &lt;&lt; 12;(NL)	arg1 |= BIT_14 | rx_tx &lt;&lt; 15;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter,(NL)				    QLCNIC_CMD_GET_ESWITCH_STATS);(NL)	if (err)(NL)		return err;(NL)(NL)	cmd.req.arg[1] = arg1;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)	return err;(NL)(NL)err_ret:(NL)	dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)		"	,	L_32
QLCNIC_CDRP_FORM_CMD	,	F_15
qlcnic_mbx_tbl	,	V_13
", func);(NL)		return -EIO;(NL)	}(NL)(NL)	stats_addr = dma_zalloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, stats_size,(NL)					 &amp;stats_dma_t, GFP_KERNEL);(NL)	if (!stats_addr)(NL)		return -ENOMEM;(NL)(NL)	arg1 = func | QLCNIC_STATS_VERSION &lt;&lt; 8 | QLCNIC_STATS_PORT &lt;&lt; 12;(NL)	arg1 |= rx_tx &lt;&lt; 15 | stats_size &lt;&lt; 16;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter,(NL)				    QLCNIC_CMD_GET_ESWITCH_STATS);(NL)	if (err)(NL)		goto out_free_dma;(NL)(NL)	cmd.req.arg[1] = arg1;(NL)	cmd.req.arg[2] = MSD(stats_dma_t);(NL)	cmd.req.arg[3] = LSD(stats_dma_t);(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)(NL)	if (!err) {(NL)		stats = stats_addr;(NL)		esw_stats-&gt;context_id = le16_to_cpu(stats-&gt;context_id);(NL)		esw_stats-&gt;version = le16_to_cpu(stats-&gt;version);(NL)		esw_stats-&gt;size = le16_to_cpu(stats-&gt;size);(NL)		esw_stats-&gt;multicast_frames =(NL)				le64_to_cpu(stats-&gt;multicast_frames);(NL)		esw_stats-&gt;broadcast_frames =(NL)				le64_to_cpu(stats-&gt;broadcast_frames);(NL)		esw_stats-&gt;unicast_frames = le64_to_cpu(stats-&gt;unicast_frames);(NL)		esw_stats-&gt;dropped_frames = le64_to_cpu(stats-&gt;dropped_frames);(NL)		esw_stats-&gt;local_frames = le64_to_cpu(stats-&gt;local_frames);(NL)		esw_stats-&gt;errors = le64_to_cpu(stats-&gt;errors);(NL)		esw_stats-&gt;numbytes = le64_to_cpu(stats-&gt;numbytes);(NL)	}(NL)(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)out_free_dma:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, stats_size, stats_addr,(NL)			  stats_dma_t);(NL)(NL)	return err;(NL)}(NL)(NL)/* This routine will retrieve the MAC statistics from firmware */(NL)int qlcnic_get_mac_stats(struct qlcnic_adapter *adapter,(NL)		struct qlcnic_mac_statistics *mac_stats)(NL){(NL)	struct qlcnic_mac_statistics_le *stats;(NL)	struct qlcnic_cmd_args cmd;(NL)	size_t stats_size = sizeof(struct qlcnic_mac_statistics_le);(NL)	dma_addr_t stats_dma_t;(NL)	void *stats_addr;(NL)	int err;(NL)(NL)	if (mac_stats == NULL)(NL)		return -ENOMEM;(NL)(NL)	stats_addr = dma_zalloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, stats_size,(NL)					 &amp;stats_dma_t, GFP_KERNEL);(NL)	if (!stats_addr)(NL)		return -ENOMEM;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_GET_MAC_STATS);(NL)	if (err)(NL)		goto out_free_dma;(NL)(NL)	cmd.req.arg[1] = stats_size &lt;&lt; 16;(NL)	cmd.req.arg[2] = MSD(stats_dma_t);(NL)	cmd.req.arg[3] = LSD(stats_dma_t);(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	if (!err) {(NL)		stats = stats_addr;(NL)		mac_stats-&gt;mac_tx_frames = le64_to_cpu(stats-&gt;mac_tx_frames);(NL)		mac_stats-&gt;mac_tx_bytes = le64_to_cpu(stats-&gt;mac_tx_bytes);(NL)		mac_stats-&gt;mac_tx_mcast_pkts =(NL)					le64_to_cpu(stats-&gt;mac_tx_mcast_pkts);(NL)		mac_stats-&gt;mac_tx_bcast_pkts =(NL)					le64_to_cpu(stats-&gt;mac_tx_bcast_pkts);(NL)		mac_stats-&gt;mac_rx_frames = le64_to_cpu(stats-&gt;mac_rx_frames);(NL)		mac_stats-&gt;mac_rx_bytes = le64_to_cpu(stats-&gt;mac_rx_bytes);(NL)		mac_stats-&gt;mac_rx_mcast_pkts =(NL)					le64_to_cpu(stats-&gt;mac_rx_mcast_pkts);(NL)		mac_stats-&gt;mac_rx_length_error =(NL)				le64_to_cpu(stats-&gt;mac_rx_length_error);(NL)		mac_stats-&gt;mac_rx_length_small =(NL)				le64_to_cpu(stats-&gt;mac_rx_length_small);(NL)		mac_stats-&gt;mac_rx_length_large =(NL)				le64_to_cpu(stats-&gt;mac_rx_length_large);(NL)		mac_stats-&gt;mac_rx_jabber = le64_to_cpu(stats-&gt;mac_rx_jabber);(NL)		mac_stats-&gt;mac_rx_dropped = le64_to_cpu(stats-&gt;mac_rx_dropped);(NL)		mac_stats-&gt;mac_rx_crc_error = le64_to_cpu(stats-&gt;mac_rx_crc_error);(NL)	} else {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_31
",(NL)			pci_func);(NL)	else(NL)		dev_info(dev, "	,	L_38
QLCNIC_OS_CRB_RETRY_COUNT	,	V_25
",(NL)			pci_func, id);(NL)	else(NL)		dev_info(dev, "	,	L_29
mbx	,	V_6
qlcnic_api_lock	,	F_12
mdelay	,	F_8
num	,	V_16
QLCNIC_RCODE_NOT_SUPPORTED	,	V_37
fmt	,	V_31
pdev	,	V_30
u32	,	T_1
req	,	V_15
", err);(NL)		err = -EIO;(NL)	}(NL)(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)out_free_dma:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, nic_size, nic_info_addr,(NL)			  nic_dma_t);(NL)(NL)	return err;(NL)}(NL)(NL)/* Get PCI Info of a partition */(NL)int qlcnic_82xx_get_pci_info(struct qlcnic_adapter *adapter,(NL)			     struct qlcnic_pci_info *pci_info)(NL){(NL)	struct qlcnic_hardware_context *ahw = adapter-&gt;ahw;(NL)	size_t npar_size = sizeof(struct qlcnic_pci_info_le);(NL)	size_t pci_size = npar_size * ahw-&gt;max_vnic_func;(NL)	u16 nic = 0, fcoe = 0, iscsi = 0;(NL)	struct qlcnic_pci_info_le *npar;(NL)	struct qlcnic_cmd_args cmd;(NL)	dma_addr_t pci_info_dma_t;(NL)	void *pci_info_addr;(NL)	int err = 0, i;(NL)(NL)	pci_info_addr = dma_zalloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, pci_size,(NL)					    &amp;pci_info_dma_t, GFP_KERNEL);(NL)	if (!pci_info_addr)(NL)		return -ENOMEM;(NL)(NL)	npar = pci_info_addr;(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_GET_PCI_INFO);(NL)	if (err)(NL)		goto out_free_dma;(NL)(NL)	cmd.req.arg[1] = MSD(pci_info_dma_t);(NL)	cmd.req.arg[2] = LSD(pci_info_dma_t);(NL)	cmd.req.arg[3] = pci_size;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)(NL)	ahw-&gt;total_nic_func = 0;(NL)	if (err == QLCNIC_RCODE_SUCCESS) {(NL)		for (i = 0; i &lt; ahw-&gt;max_vnic_func; i++, npar++, pci_info++) {(NL)			pci_info-&gt;id = le16_to_cpu(npar-&gt;id);(NL)			pci_info-&gt;active = le16_to_cpu(npar-&gt;active);(NL)			if (!pci_info-&gt;active)(NL)				continue;(NL)			pci_info-&gt;type = le16_to_cpu(npar-&gt;type);(NL)			err = qlcnic_get_pci_func_type(adapter, pci_info-&gt;type,(NL)						       &amp;nic, &amp;fcoe, &amp;iscsi);(NL)			pci_info-&gt;default_port =(NL)				le16_to_cpu(npar-&gt;default_port);(NL)			pci_info-&gt;tx_min_bw =(NL)				le16_to_cpu(npar-&gt;tx_min_bw);(NL)			pci_info-&gt;tx_max_bw =(NL)				le16_to_cpu(npar-&gt;tx_max_bw);(NL)			memcpy(pci_info-&gt;mac, npar-&gt;mac, ETH_ALEN);(NL)		}(NL)	} else {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_25
",(NL)			__func__, ahw-&gt;total_nic_func, ahw-&gt;total_pci_func);(NL)		err = -EIO;(NL)	}(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)out_free_dma:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, pci_size, pci_info_addr,(NL)		pci_info_dma_t);(NL)(NL)	return err;(NL)}(NL)(NL)/* Configure eSwitch for port mirroring */(NL)int qlcnic_config_port_mirroring(struct qlcnic_adapter *adapter, u8 id,(NL)				 u8 enable_mirroring, u8 pci_func)(NL){(NL)	struct device *dev = &amp;adapter-&gt;pdev-&gt;dev;(NL)	struct qlcnic_cmd_args cmd;(NL)	int err = -EIO;(NL)	u32 arg1;(NL)(NL)	if (adapter-&gt;ahw-&gt;op_mode != QLCNIC_MGMT_FUNC ||(NL)	    !(adapter-&gt;eswitch[id].flags &amp; QLCNIC_SWITCH_ENABLE)) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev, "	,	L_27
QLCNIC_CDRP_RSP_OK	,	V_41
");(NL)		err = -EIO;(NL)	}(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)	return err;(NL)}(NL)(NL)int(NL)qlcnic_fw_cmd_set_mtu(struct qlcnic_adapter *adapter, int mtu)(NL){(NL)	int err = 0;(NL)	struct qlcnic_cmd_args cmd;(NL)	struct qlcnic_recv_context *recv_ctx = adapter-&gt;recv_ctx;(NL)(NL)	if (recv_ctx-&gt;state != QLCNIC_HOST_CTX_STATE_ACTIVE)(NL)		return err;(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_SET_MTU);(NL)	if (err)(NL)		return err;(NL)(NL)	cmd.req.arg[1] = recv_ctx-&gt;context_id;(NL)	cmd.req.arg[2] = mtu;(NL)(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	if (err) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev, "	,	L_11
"CDRP invalid args: [%d]\n"	,	L_2
qlcnic_mailbox_metadata	,	V_11
pci_func	,	V_3
",(NL)		 _QLCNIC_LINUX_MAJOR, _QLCNIC_LINUX_MINOR,(NL)		 _QLCNIC_LINUX_SUBVERSION);(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, fw_cmd);(NL)	if (err)(NL)		return err;(NL)(NL)	memcpy(&amp;arg1, drv_string, sizeof(u32));(NL)	memcpy(&amp;arg2, drv_string + 4, sizeof(u32));(NL)	memcpy(&amp;arg3, drv_string + 8, sizeof(u32));(NL)(NL)	cmd.req.arg[1] = arg1;(NL)	cmd.req.arg[2] = arg2;(NL)	cmd.req.arg[3] = arg3;(NL)(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	if (err) {(NL)		dev_info(&amp;adapter-&gt;pdev-&gt;dev,(NL)			 "	,	L_10
QLCNIC_CDRP_RSP_FAIL	,	V_35
" :(NL)				   "	,	L_20
QLCNIC_RCODE_NOT_PERMITTED	,	V_39
arg3	,	V_46
arg2	,	V_45
drv_string	,	V_47
qlcnic_82xx_issue_cmd	,	F_11
pci_dev	,	V_29
qlcnic_hardware_context	,	V_1
", err);(NL)		err = -EIO;(NL)	}(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)	return err;(NL)}(NL)(NL)/* Get info of a NIC partition */(NL)int qlcnic_82xx_get_nic_info(struct qlcnic_adapter *adapter,(NL)			     struct qlcnic_info *npar_info, u8 func_id)(NL){(NL)	int	err;(NL)	dma_addr_t nic_dma_t;(NL)	const struct qlcnic_info_le *nic_info;(NL)	void *nic_info_addr;(NL)	struct qlcnic_cmd_args cmd;(NL)	size_t  nic_size = sizeof(struct qlcnic_info_le);(NL)(NL)	nic_info_addr = dma_zalloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, nic_size,(NL)					    &amp;nic_dma_t, GFP_KERNEL);(NL)	if (!nic_info_addr)(NL)		return -ENOMEM;(NL)(NL)	nic_info = nic_info_addr;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_GET_NIC_INFO);(NL)	if (err)(NL)		goto out_free_dma;(NL)(NL)	cmd.req.arg[1] = MSD(nic_dma_t);(NL)	cmd.req.arg[2] = LSD(nic_dma_t);(NL)	cmd.req.arg[3] = (func_id &lt;&lt; 16 | nic_size);(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	if (err != QLCNIC_RCODE_SUCCESS) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_23
QLCNIC_RCODE_TIMEOUT	,	V_32
arg1	,	V_44
",(NL)				   op_type == QLCNIC_INTRPT_ADD ? "	,	L_19
");(NL)		err = -EIO;(NL)	}(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)	return err;(NL)}(NL)(NL)int qlcnic_82xx_fw_cmd_create_rx_ctx(struct qlcnic_adapter *adapter)(NL){(NL)	struct qlcnic_recv_context *recv_ctx = adapter-&gt;recv_ctx;(NL)	struct qlcnic_hardware_context *ahw = adapter-&gt;ahw;(NL)	dma_addr_t hostrq_phys_addr, cardrsp_phys_addr;(NL)	struct net_device *netdev = adapter-&gt;netdev;(NL)	u32 temp_intr_crb_mode, temp_rds_crb_mode;(NL)	struct qlcnic_cardrsp_rds_ring *prsp_rds;(NL)	struct qlcnic_cardrsp_sds_ring *prsp_sds;(NL)	struct qlcnic_hostrq_rds_ring *prq_rds;(NL)	struct qlcnic_hostrq_sds_ring *prq_sds;(NL)	struct qlcnic_host_rds_ring *rds_ring;(NL)	struct qlcnic_host_sds_ring *sds_ring;(NL)	struct qlcnic_cardrsp_rx_ctx *prsp;(NL)	struct qlcnic_hostrq_rx_ctx *prq;(NL)	u8 i, nrds_rings, nsds_rings;(NL)	struct qlcnic_cmd_args cmd;(NL)	size_t rq_size, rsp_size;(NL)	u32 cap, reg, val, reg2;(NL)	u64 phys_addr;(NL)	u16 temp_u16;(NL)	void *addr;(NL)	int err;(NL)(NL)	nrds_rings = adapter-&gt;max_rds_rings;(NL)	nsds_rings = adapter-&gt;drv_sds_rings;(NL)(NL)	rq_size = SIZEOF_HOSTRQ_RX(struct qlcnic_hostrq_rx_ctx, nrds_rings,(NL)				   nsds_rings);(NL)	rsp_size = SIZEOF_CARDRSP_RX(struct qlcnic_cardrsp_rx_ctx, nrds_rings,(NL)				     nsds_rings);(NL)(NL)	addr = dma_alloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, rq_size,(NL)				  &amp;hostrq_phys_addr, GFP_KERNEL);(NL)	if (addr == NULL)(NL)		return -ENOMEM;(NL)	prq = addr;(NL)(NL)	addr = dma_alloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, rsp_size,(NL)			&amp;cardrsp_phys_addr, GFP_KERNEL);(NL)	if (addr == NULL) {(NL)		err = -ENOMEM;(NL)		goto out_free_rq;(NL)	}(NL)	prsp = addr;(NL)(NL)	prq-&gt;host_rsp_dma_addr = cpu_to_le64(cardrsp_phys_addr);(NL)(NL)	cap = (QLCNIC_CAP0_LEGACY_CONTEXT | QLCNIC_CAP0_LEGACY_MN(NL)						| QLCNIC_CAP0_VALIDOFF);(NL)	cap |= (QLCNIC_CAP0_JUMBO_CONTIGUOUS | QLCNIC_CAP0_LRO_CONTIGUOUS);(NL)(NL)	if (qlcnic_check_multi_tx(adapter) &amp;&amp;(NL)	    !adapter-&gt;ahw-&gt;diag_test) {(NL)		cap |= QLCNIC_CAP0_TX_MULTI;(NL)	} else {(NL)		temp_u16 = offsetof(struct qlcnic_hostrq_rx_ctx, msix_handler);(NL)		prq-&gt;valid_field_offset = cpu_to_le16(temp_u16);(NL)		prq-&gt;txrx_sds_binding = nsds_rings - 1;(NL)		temp_intr_crb_mode = QLCNIC_HOST_INT_CRB_MODE_SHARED;(NL)		prq-&gt;host_int_crb_mode = cpu_to_le32(temp_intr_crb_mode);(NL)		temp_rds_crb_mode = QLCNIC_HOST_RDS_CRB_MODE_UNIQUE;(NL)		prq-&gt;host_rds_crb_mode = cpu_to_le32(temp_rds_crb_mode);(NL)	}(NL)(NL)	prq-&gt;capabilities[0] = cpu_to_le32(cap);(NL)(NL)	prq-&gt;num_rds_rings = cpu_to_le16(nrds_rings);(NL)	prq-&gt;num_sds_rings = cpu_to_le16(nsds_rings);(NL)	prq-&gt;rds_ring_offset = 0;(NL)(NL)	val = le32_to_cpu(prq-&gt;rds_ring_offset) +(NL)		(sizeof(struct qlcnic_hostrq_rds_ring) * nrds_rings);(NL)	prq-&gt;sds_ring_offset = cpu_to_le32(val);(NL)(NL)	prq_rds = (struct qlcnic_hostrq_rds_ring *)(prq-&gt;data +(NL)			le32_to_cpu(prq-&gt;rds_ring_offset));(NL)(NL)	for (i = 0; i &lt; nrds_rings; i++) {(NL)		rds_ring = &amp;recv_ctx-&gt;rds_rings[i];(NL)		rds_ring-&gt;producer = 0;(NL)		prq_rds[i].host_phys_addr = cpu_to_le64(rds_ring-&gt;phys_addr);(NL)		prq_rds[i].ring_size = cpu_to_le32(rds_ring-&gt;num_desc);(NL)		prq_rds[i].ring_kind = cpu_to_le32(i);(NL)		prq_rds[i].buff_size = cpu_to_le64(rds_ring-&gt;dma_size);(NL)	}(NL)(NL)	prq_sds = (struct qlcnic_hostrq_sds_ring *)(prq-&gt;data +(NL)			le32_to_cpu(prq-&gt;sds_ring_offset));(NL)(NL)	for (i = 0; i &lt; nsds_rings; i++) {(NL)		sds_ring = &amp;recv_ctx-&gt;sds_rings[i];(NL)		sds_ring-&gt;consumer = 0;(NL)		memset(sds_ring-&gt;desc_head, 0, STATUS_DESC_RINGSIZE(sds_ring));(NL)		prq_sds[i].host_phys_addr = cpu_to_le64(sds_ring-&gt;phys_addr);(NL)		prq_sds[i].ring_size = cpu_to_le32(sds_ring-&gt;num_desc);(NL)		if (qlcnic_check_multi_tx(adapter) &amp;&amp;(NL)		    !adapter-&gt;ahw-&gt;diag_test)(NL)			prq_sds[i].msi_index = cpu_to_le16(ahw-&gt;intr_tbl[i].id);(NL)		else(NL)			prq_sds[i].msi_index = cpu_to_le16(i);(NL)	}(NL)(NL)	phys_addr = hostrq_phys_addr;(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_CREATE_RX_CTX);(NL)	if (err)(NL)		goto out_free_rsp;(NL)(NL)	cmd.req.arg[1] = MSD(phys_addr);(NL)	cmd.req.arg[2] = LSD(phys_addr);(NL)	cmd.req.arg[3] = rq_size;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)	if (err) {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_12
QLCRD32	,	F_9
qlcnic_adapter	,	V_7
timeout	,	V_23
dev_err	,	F_16
QLCNIC_SIGN_CRB_OFFSET	,	V_33
",(NL)			 pci_func);(NL)	else(NL)		dev_err(dev, "	,	L_34
",(NL)				    ahw-&gt;intr_tbl[i].id);(NL)			continue;(NL)		}(NL)		if (op_type) {(NL)			ahw-&gt;intr_tbl[i].id = MSW(val);(NL)			ahw-&gt;intr_tbl[i].enabled = 1;(NL)			ahw-&gt;intr_tbl[i].src = cmd.rsp.arg[2];(NL)		} else {(NL)			ahw-&gt;intr_tbl[i].id = i;(NL)			ahw-&gt;intr_tbl[i].enabled = 0;(NL)			ahw-&gt;intr_tbl[i].src = 0;(NL)		}(NL)		qlcnic_free_mbx_args(&amp;cmd);(NL)	}(NL)(NL)	return err;(NL)}(NL)(NL)int qlcnic_82xx_get_mac_address(struct qlcnic_adapter *adapter, u8 *mac,(NL)				u8 function)(NL){(NL)	int err, i;(NL)	struct qlcnic_cmd_args cmd;(NL)	u32 mac_low, mac_high;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_MAC_ADDRESS);(NL)	if (err)(NL)		return err;(NL)(NL)	cmd.req.arg[1] = function | BIT_8;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)(NL)	if (err == QLCNIC_RCODE_SUCCESS) {(NL)		mac_low = cmd.rsp.arg[1];(NL)		mac_high = cmd.rsp.arg[2];(NL)(NL)		for (i = 0; i &lt; 2; i++)(NL)			mac[i] = (u8) (mac_high &gt;&gt; ((1 - i) * 8));(NL)		for (i = 2; i &lt; 6; i++)(NL)			mac[i] = (u8) (mac_low &gt;&gt; ((5 - i) * 8));(NL)	} else {(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_22
");(NL)(NL)	recv_ctx-&gt;state = QLCNIC_HOST_CTX_STATE_FREED;(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)}(NL)(NL)int qlcnic_82xx_fw_cmd_create_tx_ctx(struct qlcnic_adapter *adapter,(NL)				     struct qlcnic_host_tx_ring *tx_ring,(NL)				     int ring)(NL){(NL)	struct qlcnic_hardware_context *ahw = adapter-&gt;ahw;(NL)	struct net_device *netdev = adapter-&gt;netdev;(NL)	struct qlcnic_hostrq_tx_ctx	*prq;(NL)	struct qlcnic_hostrq_cds_ring	*prq_cds;(NL)	struct qlcnic_cardrsp_tx_ctx	*prsp;(NL)	struct qlcnic_cmd_args cmd;(NL)	u32 temp, intr_mask, temp_int_crb_mode;(NL)	dma_addr_t rq_phys_addr, rsp_phys_addr;(NL)	int temp_nsds_rings, index, err;(NL)	void *rq_addr, *rsp_addr;(NL)	size_t rq_size, rsp_size;(NL)	u64 phys_addr;(NL)	u16 msix_id;(NL)(NL)	/* reset host resources */(NL)	tx_ring-&gt;producer = 0;(NL)	tx_ring-&gt;sw_consumer = 0;(NL)	*(tx_ring-&gt;hw_consumer) = 0;(NL)(NL)	rq_size = SIZEOF_HOSTRQ_TX(struct qlcnic_hostrq_tx_ctx);(NL)	rq_addr = dma_zalloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, rq_size,(NL)				      &amp;rq_phys_addr, GFP_KERNEL);(NL)	if (!rq_addr)(NL)		return -ENOMEM;(NL)(NL)	rsp_size = SIZEOF_CARDRSP_TX(struct qlcnic_cardrsp_tx_ctx);(NL)	rsp_addr = dma_zalloc_coherent(&amp;adapter-&gt;pdev-&gt;dev, rsp_size,(NL)				       &amp;rsp_phys_addr, GFP_KERNEL);(NL)	if (!rsp_addr) {(NL)		err = -ENOMEM;(NL)		goto out_free_rq;(NL)	}(NL)(NL)	prq = rq_addr;(NL)	prsp = rsp_addr;(NL)(NL)	prq-&gt;host_rsp_dma_addr = cpu_to_le64(rsp_phys_addr);(NL)(NL)	temp = (QLCNIC_CAP0_LEGACY_CONTEXT | QLCNIC_CAP0_LEGACY_MN |(NL)		QLCNIC_CAP0_LSO);(NL)	if (qlcnic_check_multi_tx(adapter) &amp;&amp; !adapter-&gt;ahw-&gt;diag_test)(NL)		temp |= QLCNIC_CAP0_TX_MULTI;(NL)(NL)	prq-&gt;capabilities[0] = cpu_to_le32(temp);(NL)(NL)	if (qlcnic_check_multi_tx(adapter) &amp;&amp;(NL)	    !adapter-&gt;ahw-&gt;diag_test) {(NL)		temp_nsds_rings = adapter-&gt;drv_sds_rings;(NL)		index = temp_nsds_rings + ring;(NL)		msix_id = ahw-&gt;intr_tbl[index].id;(NL)		prq-&gt;msi_index = cpu_to_le16(msix_id);(NL)	} else {(NL)		temp_int_crb_mode = QLCNIC_HOST_INT_CRB_MODE_SHARED;(NL)		prq-&gt;host_int_crb_mode = cpu_to_le32(temp_int_crb_mode);(NL)		prq-&gt;msi_index = 0;(NL)	}(NL)(NL)	prq-&gt;interrupt_ctl = 0;(NL)	prq-&gt;cmd_cons_dma_addr = cpu_to_le64(tx_ring-&gt;hw_cons_phys_addr);(NL)(NL)	prq_cds = &amp;prq-&gt;cds_ring;(NL)(NL)	prq_cds-&gt;host_phys_addr = cpu_to_le64(tx_ring-&gt;phys_addr);(NL)	prq_cds-&gt;ring_size = cpu_to_le32(tx_ring-&gt;num_desc);(NL)(NL)	phys_addr = rq_phys_addr;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_CREATE_TX_CTX);(NL)	if (err)(NL)		goto out_free_rsp;(NL)(NL)	cmd.req.arg[1] = MSD(phys_addr);(NL)	cmd.req.arg[2] = LSD(phys_addr);(NL)	cmd.req.arg[3] = rq_size;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)(NL)	if (err == QLCNIC_RCODE_SUCCESS) {(NL)		tx_ring-&gt;state = le32_to_cpu(prsp-&gt;host_ctx_state);(NL)		temp = le32_to_cpu(prsp-&gt;cds_ring.host_producer_crb);(NL)		tx_ring-&gt;crb_cmd_producer = adapter-&gt;ahw-&gt;pci_base0 + temp;(NL)		tx_ring-&gt;ctx_id = le16_to_cpu(prsp-&gt;context_id);(NL)		if (qlcnic_check_multi_tx(adapter) &amp;&amp;(NL)		    !adapter-&gt;ahw-&gt;diag_test &amp;&amp;(NL)		    (adapter-&gt;flags &amp; QLCNIC_MSIX_ENABLED)) {(NL)			index = adapter-&gt;drv_sds_rings + ring;(NL)			intr_mask = ahw-&gt;intr_tbl[index].src;(NL)			tx_ring-&gt;crb_intr_mask = ahw-&gt;pci_base0 + intr_mask;(NL)		}(NL)(NL)		netdev_info(netdev, "	,	L_15
",(NL)			__func__);(NL)		return err;(NL)	}(NL)(NL)	arg1 = id | (enable_mirroring ? BIT_4 : 0);(NL)	arg1 |= pci_func &lt;&lt; 8;(NL)(NL)	err = qlcnic_alloc_mbx_args(&amp;cmd, adapter,(NL)				    QLCNIC_CMD_SET_PORTMIRRORING);(NL)	if (err)(NL)		return err;(NL)(NL)	cmd.req.arg[1] = arg1;(NL)	err = qlcnic_issue_cmd(adapter, &amp;cmd);(NL)(NL)	if (err != QLCNIC_RCODE_SUCCESS)(NL)		dev_err(dev, "	,	L_28
"CDRP invalid or unknown cmd received: [%d]\n"	,	L_5
",(NL)			__func__);(NL)		return err;(NL)	}(NL)(NL)	pci_func = esw_cfg-&gt;pci_func;(NL)	index = qlcnic_is_valid_nic_func(adapter, pci_func);(NL)	if (index &lt; 0)(NL)		return err;(NL)	arg1 = (adapter-&gt;npars[index].phy_port &amp; BIT_0);(NL)	arg1 |= (pci_func &lt;&lt; 8);(NL)(NL)	if (__qlcnic_get_eswitch_port_config(adapter, &amp;arg1, &amp;arg2))(NL)		return err;(NL)	arg1 &amp;= ~(0x0ff &lt;&lt; 8);(NL)	arg1 |= (pci_func &lt;&lt; 8);(NL)	arg1 &amp;= ~(BIT_2 | BIT_3);(NL)	switch (esw_cfg-&gt;op_mode) {(NL)	case QLCNIC_PORT_DEFAULTS:(NL)		arg1 |= (BIT_4 | BIT_6 | BIT_7);(NL)		arg2 |= (BIT_0 | BIT_1);(NL)		if (adapter-&gt;ahw-&gt;capabilities &amp; QLCNIC_FW_CAPABILITY_TSO)(NL)			arg2 |= (BIT_2 | BIT_3);(NL)		if (!(esw_cfg-&gt;discard_tagged))(NL)			arg1 &amp;= ~BIT_4;(NL)		if (!(esw_cfg-&gt;promisc_mode))(NL)			arg1 &amp;= ~BIT_6;(NL)		if (!(esw_cfg-&gt;mac_override))(NL)			arg1 &amp;= ~BIT_7;(NL)		if (!(esw_cfg-&gt;mac_anti_spoof))(NL)			arg2 &amp;= ~BIT_0;(NL)		if (!(esw_cfg-&gt;offload_flags &amp; BIT_0))(NL)			arg2 &amp;= ~(BIT_1 | BIT_2 | BIT_3);(NL)		if (!(esw_cfg-&gt;offload_flags &amp; BIT_1))(NL)			arg2 &amp;= ~BIT_2;(NL)		if (!(esw_cfg-&gt;offload_flags &amp; BIT_2))(NL)			arg2 &amp;= ~BIT_3;(NL)		break;(NL)	case QLCNIC_ADD_VLAN:(NL)			arg1 &amp;= ~(0x0ffff &lt;&lt; 16);(NL)			arg1 |= (BIT_2 | BIT_5);(NL)			arg1 |= (esw_cfg-&gt;vlan_id &lt;&lt; 16);(NL)			break;(NL)	case QLCNIC_DEL_VLAN:(NL)			arg1 |= (BIT_3 | BIT_5);(NL)			arg1 &amp;= ~(0x0ffff &lt;&lt; 16);(NL)			break;(NL)	default:(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev, "	,	L_36
QLCNIC_CDRP_CRB_OFFSET	,	V_27
fw_hal_version	,	V_4
qlcnic_cmd_args	,	V_5
"CDRP command failed: [%d]\n"	,	L_7
", err);(NL)			qlcnic_free_mbx_args(&amp;cmd);(NL)			return err;(NL)		}(NL)		val = cmd.rsp.arg[1];(NL)		if (LSB(val)) {(NL)			netdev_info(netdev,(NL)				    "	,	L_21
"CDRP requested action not permitted: [%d]\n"	,	L_4
",(NL)			   err);(NL)		err = -EIO;(NL)	}(NL)	qlcnic_free_mbx_args(&amp;cmd);(NL)(NL)out_free_rsp:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, rsp_size, rsp_addr,(NL)			  rsp_phys_addr);(NL)out_free_rq:(NL)	dma_free_coherent(&amp;adapter-&gt;pdev-&gt;dev, rq_size, rq_addr, rq_phys_addr);(NL)(NL)	return err;(NL)}(NL)(NL)void qlcnic_82xx_fw_cmd_del_tx_ctx(struct qlcnic_adapter *adapter,(NL)				   struct qlcnic_host_tx_ring *tx_ring)(NL){(NL)	struct qlcnic_cmd_args cmd;(NL)	int ret;(NL)(NL)	ret = qlcnic_alloc_mbx_args(&amp;cmd, adapter, QLCNIC_CMD_DESTROY_TX_CTX);(NL)	if (ret)(NL)		return;(NL)(NL)	cmd.req.arg[1] = tx_ring-&gt;ctx_id;(NL)	if (qlcnic_issue_cmd(adapter, &amp;cmd))(NL)		dev_err(&amp;adapter-&gt;pdev-&gt;dev,(NL)			"	,	L_17
