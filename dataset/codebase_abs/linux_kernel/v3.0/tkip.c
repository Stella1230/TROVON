unsigned int F_1 ( unsigned int V_1 )
{
unsigned int V_2 ;
unsigned int V_3 ;
unsigned int V_4 , V_5 ;
V_2 = ( V_1 % 256 ) ;
V_3 = ( ( V_1 >> 8 ) % 256 ) ;
V_4 = V_6 [ V_2 ] + ( V_7 [ V_2 ] * 256 ) ;
V_5 = V_7 [ V_3 ] + ( V_6 [ V_3 ] * 256 ) ;
return ( V_4 ^ V_5 ) ;
}
unsigned int F_2 ( unsigned int V_8 )
{
unsigned int V_9 ;
if ( ( V_8 & 0x01 ) == 0x01 ) {
V_9 = ( V_8 >> 1 ) | 0x8000 ;
} else {
V_9 = ( V_8 >> 1 ) & 0x7fff ;
}
V_9 = V_9 % 65536 ;
return V_9 ;
}
void F_3 (
unsigned char * V_10 ,
unsigned char * V_11 ,
unsigned short V_12 ,
unsigned long V_13 ,
unsigned char * V_14
)
{
unsigned int V_15 [ 5 ] ;
unsigned int V_16 , V_17 , V_18 ;
unsigned int V_19 , V_20 , V_21 , V_22 , V_23 , V_24 ;
unsigned long int V_25 , V_26 ;
int V_27 , V_28 ;
V_25 = V_12 ;
V_26 = V_13 ;
V_16 = ( unsigned int ) ( ( V_26 >> 16 ) % 65536 ) ;
V_17 = ( unsigned int ) ( V_26 % 65536 ) ;
V_18 = ( unsigned int ) ( V_25 % 65536 ) ;
V_15 [ 0 ] = V_17 ;
V_15 [ 1 ] = V_16 ;
V_15 [ 2 ] = ( unsigned int ) ( V_11 [ 0 ] + ( V_11 [ 1 ] * 256 ) ) ;
V_15 [ 3 ] = ( unsigned int ) ( V_11 [ 2 ] + ( V_11 [ 3 ] * 256 ) ) ;
V_15 [ 4 ] = ( unsigned int ) ( V_11 [ 4 ] + ( V_11 [ 5 ] * 256 ) ) ;
for ( V_27 = 0 ; V_27 < 8 ; V_27 ++ ) {
V_28 = 2 * ( V_27 & 1 ) ;
V_15 [ 0 ] = ( V_15 [ 0 ] + F_1 ( ( V_15 [ 4 ] ^ ( ( 256 * V_10 [ 1 + V_28 ] ) + V_10 [ V_28 ] ) ) % 65536 ) ) % 65536 ;
V_15 [ 1 ] = ( V_15 [ 1 ] + F_1 ( ( V_15 [ 0 ] ^ ( ( 256 * V_10 [ 5 + V_28 ] ) + V_10 [ 4 + V_28 ] ) ) % 65536 ) ) % 65536 ;
V_15 [ 2 ] = ( V_15 [ 2 ] + F_1 ( ( V_15 [ 1 ] ^ ( ( 256 * V_10 [ 9 + V_28 ] ) + V_10 [ 8 + V_28 ] ) ) % 65536 ) ) % 65536 ;
V_15 [ 3 ] = ( V_15 [ 3 ] + F_1 ( ( V_15 [ 2 ] ^ ( ( 256 * V_10 [ 13 + V_28 ] ) + V_10 [ 12 + V_28 ] ) ) % 65536 ) ) % 65536 ;
V_15 [ 4 ] = ( V_15 [ 4 ] + F_1 ( ( V_15 [ 3 ] ^ ( ( ( 256 * V_10 [ 1 + V_28 ] ) + V_10 [ V_28 ] ) ) ) % 65536 ) ) % 65536 ;
V_15 [ 4 ] = ( V_15 [ 4 ] + V_27 ) % 65536 ;
}
V_19 = V_15 [ 0 ] ;
V_20 = V_15 [ 1 ] ;
V_21 = V_15 [ 2 ] ;
V_22 = V_15 [ 3 ] ;
V_23 = V_15 [ 4 ] ;
V_24 = ( V_15 [ 4 ] + V_18 ) % 65536 ;
V_19 = V_19 + F_1 ( ( V_24 ^ ( ( 256 * V_10 [ 1 ] ) + V_10 [ 0 ] ) ) % 65536 ) ;
V_20 = V_20 + F_1 ( ( V_19 ^ ( ( 256 * V_10 [ 3 ] ) + V_10 [ 2 ] ) ) % 65536 ) ;
V_21 = V_21 + F_1 ( ( V_20 ^ ( ( 256 * V_10 [ 5 ] ) + V_10 [ 4 ] ) ) % 65536 ) ;
V_22 = V_22 + F_1 ( ( V_21 ^ ( ( 256 * V_10 [ 7 ] ) + V_10 [ 6 ] ) ) % 65536 ) ;
V_23 = V_23 + F_1 ( ( V_22 ^ ( ( 256 * V_10 [ 9 ] ) + V_10 [ 8 ] ) ) % 65536 ) ;
V_24 = V_24 + F_1 ( ( V_23 ^ ( ( 256 * V_10 [ 11 ] ) + V_10 [ 10 ] ) ) % 65536 ) ;
V_19 = V_19 + F_2 ( V_24 ^ ( ( 256 * V_10 [ 13 ] ) + V_10 [ 12 ] ) ) ;
V_20 = V_20 + F_2 ( V_19 ^ ( ( 256 * V_10 [ 15 ] ) + V_10 [ 14 ] ) ) ;
V_21 = V_21 + F_2 ( V_20 ) ;
V_22 = V_22 + F_2 ( V_21 ) ;
V_23 = V_23 + F_2 ( V_22 ) ;
V_24 = V_24 + F_2 ( V_23 ) ;
V_14 [ 0 ] = ( V_18 >> 8 ) % 256 ;
V_14 [ 1 ] = ( ( ( V_18 >> 8 ) % 256 ) | 0x20 ) & 0x7f ;
V_14 [ 2 ] = V_18 % 256 ;
V_14 [ 3 ] = ( ( V_24 ^ ( ( 256 * V_10 [ 1 ] ) + V_10 [ 0 ] ) ) >> 1 ) % 256 ;
V_14 [ 4 ] = V_19 % 256 ;
V_14 [ 5 ] = ( V_19 >> 8 ) % 256 ;
V_14 [ 6 ] = V_20 % 256 ;
V_14 [ 7 ] = ( V_20 >> 8 ) % 256 ;
V_14 [ 8 ] = V_21 % 256 ;
V_14 [ 9 ] = ( V_21 >> 8 ) % 256 ;
V_14 [ 10 ] = V_22 % 256 ;
V_14 [ 11 ] = ( V_22 >> 8 ) % 256 ;
V_14 [ 12 ] = V_23 % 256 ;
V_14 [ 13 ] = ( V_23 >> 8 ) % 256 ;
V_14 [ 14 ] = V_24 % 256 ;
V_14 [ 15 ] = ( V_24 >> 8 ) % 256 ;
}
