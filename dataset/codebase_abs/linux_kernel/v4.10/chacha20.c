static inline T_1 F_1 ( T_1 V_1 , T_2 V_2 )
{
return ( V_1 << V_2 ) | ( V_1 >> ( sizeof( V_1 ) * 8 - V_2 ) ) ;
}
extern void F_2 ( T_1 * V_3 , void * V_4 )
{
T_1 V_5 [ 16 ] , * V_6 = V_4 ;
int V_7 ;
for ( V_7 = 0 ; V_7 < F_3 ( V_5 ) ; V_7 ++ )
V_5 [ V_7 ] = V_3 [ V_7 ] ;
for ( V_7 = 0 ; V_7 < 20 ; V_7 += 2 ) {
V_5 [ 0 ] += V_5 [ 4 ] ; V_5 [ 12 ] = F_1 ( V_5 [ 12 ] ^ V_5 [ 0 ] , 16 ) ;
V_5 [ 1 ] += V_5 [ 5 ] ; V_5 [ 13 ] = F_1 ( V_5 [ 13 ] ^ V_5 [ 1 ] , 16 ) ;
V_5 [ 2 ] += V_5 [ 6 ] ; V_5 [ 14 ] = F_1 ( V_5 [ 14 ] ^ V_5 [ 2 ] , 16 ) ;
V_5 [ 3 ] += V_5 [ 7 ] ; V_5 [ 15 ] = F_1 ( V_5 [ 15 ] ^ V_5 [ 3 ] , 16 ) ;
V_5 [ 8 ] += V_5 [ 12 ] ; V_5 [ 4 ] = F_1 ( V_5 [ 4 ] ^ V_5 [ 8 ] , 12 ) ;
V_5 [ 9 ] += V_5 [ 13 ] ; V_5 [ 5 ] = F_1 ( V_5 [ 5 ] ^ V_5 [ 9 ] , 12 ) ;
V_5 [ 10 ] += V_5 [ 14 ] ; V_5 [ 6 ] = F_1 ( V_5 [ 6 ] ^ V_5 [ 10 ] , 12 ) ;
V_5 [ 11 ] += V_5 [ 15 ] ; V_5 [ 7 ] = F_1 ( V_5 [ 7 ] ^ V_5 [ 11 ] , 12 ) ;
V_5 [ 0 ] += V_5 [ 4 ] ; V_5 [ 12 ] = F_1 ( V_5 [ 12 ] ^ V_5 [ 0 ] , 8 ) ;
V_5 [ 1 ] += V_5 [ 5 ] ; V_5 [ 13 ] = F_1 ( V_5 [ 13 ] ^ V_5 [ 1 ] , 8 ) ;
V_5 [ 2 ] += V_5 [ 6 ] ; V_5 [ 14 ] = F_1 ( V_5 [ 14 ] ^ V_5 [ 2 ] , 8 ) ;
V_5 [ 3 ] += V_5 [ 7 ] ; V_5 [ 15 ] = F_1 ( V_5 [ 15 ] ^ V_5 [ 3 ] , 8 ) ;
V_5 [ 8 ] += V_5 [ 12 ] ; V_5 [ 4 ] = F_1 ( V_5 [ 4 ] ^ V_5 [ 8 ] , 7 ) ;
V_5 [ 9 ] += V_5 [ 13 ] ; V_5 [ 5 ] = F_1 ( V_5 [ 5 ] ^ V_5 [ 9 ] , 7 ) ;
V_5 [ 10 ] += V_5 [ 14 ] ; V_5 [ 6 ] = F_1 ( V_5 [ 6 ] ^ V_5 [ 10 ] , 7 ) ;
V_5 [ 11 ] += V_5 [ 15 ] ; V_5 [ 7 ] = F_1 ( V_5 [ 7 ] ^ V_5 [ 11 ] , 7 ) ;
V_5 [ 0 ] += V_5 [ 5 ] ; V_5 [ 15 ] = F_1 ( V_5 [ 15 ] ^ V_5 [ 0 ] , 16 ) ;
V_5 [ 1 ] += V_5 [ 6 ] ; V_5 [ 12 ] = F_1 ( V_5 [ 12 ] ^ V_5 [ 1 ] , 16 ) ;
V_5 [ 2 ] += V_5 [ 7 ] ; V_5 [ 13 ] = F_1 ( V_5 [ 13 ] ^ V_5 [ 2 ] , 16 ) ;
V_5 [ 3 ] += V_5 [ 4 ] ; V_5 [ 14 ] = F_1 ( V_5 [ 14 ] ^ V_5 [ 3 ] , 16 ) ;
V_5 [ 10 ] += V_5 [ 15 ] ; V_5 [ 5 ] = F_1 ( V_5 [ 5 ] ^ V_5 [ 10 ] , 12 ) ;
V_5 [ 11 ] += V_5 [ 12 ] ; V_5 [ 6 ] = F_1 ( V_5 [ 6 ] ^ V_5 [ 11 ] , 12 ) ;
V_5 [ 8 ] += V_5 [ 13 ] ; V_5 [ 7 ] = F_1 ( V_5 [ 7 ] ^ V_5 [ 8 ] , 12 ) ;
V_5 [ 9 ] += V_5 [ 14 ] ; V_5 [ 4 ] = F_1 ( V_5 [ 4 ] ^ V_5 [ 9 ] , 12 ) ;
V_5 [ 0 ] += V_5 [ 5 ] ; V_5 [ 15 ] = F_1 ( V_5 [ 15 ] ^ V_5 [ 0 ] , 8 ) ;
V_5 [ 1 ] += V_5 [ 6 ] ; V_5 [ 12 ] = F_1 ( V_5 [ 12 ] ^ V_5 [ 1 ] , 8 ) ;
V_5 [ 2 ] += V_5 [ 7 ] ; V_5 [ 13 ] = F_1 ( V_5 [ 13 ] ^ V_5 [ 2 ] , 8 ) ;
V_5 [ 3 ] += V_5 [ 4 ] ; V_5 [ 14 ] = F_1 ( V_5 [ 14 ] ^ V_5 [ 3 ] , 8 ) ;
V_5 [ 10 ] += V_5 [ 15 ] ; V_5 [ 5 ] = F_1 ( V_5 [ 5 ] ^ V_5 [ 10 ] , 7 ) ;
V_5 [ 11 ] += V_5 [ 12 ] ; V_5 [ 6 ] = F_1 ( V_5 [ 6 ] ^ V_5 [ 11 ] , 7 ) ;
V_5 [ 8 ] += V_5 [ 13 ] ; V_5 [ 7 ] = F_1 ( V_5 [ 7 ] ^ V_5 [ 8 ] , 7 ) ;
V_5 [ 9 ] += V_5 [ 14 ] ; V_5 [ 4 ] = F_1 ( V_5 [ 4 ] ^ V_5 [ 9 ] , 7 ) ;
}
for ( V_7 = 0 ; V_7 < F_3 ( V_5 ) ; V_7 ++ )
V_6 [ V_7 ] = F_4 ( V_5 [ V_7 ] + V_3 [ V_7 ] ) ;
V_3 [ 12 ] ++ ;
}
