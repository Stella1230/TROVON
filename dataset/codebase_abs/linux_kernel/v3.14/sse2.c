static int F_1 ( void )\r\n{\r\nreturn F_2 ( V_1 ) &&\r\nF_2 ( V_2 ) &&\r\nF_2 ( V_3 ) &&\r\nF_2 ( V_4 ) ;\r\n}\r\nstatic void F_3 ( int V_5 , T_1 V_6 , void * * V_7 )\r\n{\r\nT_2 * * V_8 = ( T_2 * * ) V_7 ;\r\nT_2 * V_9 , * V_10 ;\r\nint V_11 , V_12 , V_13 ;\r\nV_13 = V_5 - 3 ;\r\nV_9 = V_8 [ V_13 + 1 ] ;\r\nV_10 = V_8 [ V_13 + 2 ] ;\r\nF_4 () ;\r\nasm volatile("movdqa %0,%%xmm0" : : "m" (raid6_sse_constants.x1d[0]));\r\nasm volatile("pxor %xmm5,%xmm5");\r\nfor ( V_11 = 0 ; V_11 < V_6 ; V_11 += 16 ) {\r\nasm volatile("prefetchnta %0" : : "m" (dptr[z0][d]));\r\nasm volatile("movdqa %0,%%xmm2" : : "m" (dptr[z0][d]));\r\nasm volatile("prefetchnta %0" : : "m" (dptr[z0-1][d]));\r\nasm volatile("movdqa %xmm2,%xmm4");\r\nasm volatile("movdqa %0,%%xmm6" : : "m" (dptr[z0-1][d]));\r\nfor ( V_12 = V_13 - 2 ; V_12 >= 0 ; V_12 -- ) {\r\nasm volatile("prefetchnta %0" : : "m" (dptr[z][d]));\r\nasm volatile("pcmpgtb %xmm4,%xmm5");\r\nasm volatile("paddb %xmm4,%xmm4");\r\nasm volatile("pand %xmm0,%xmm5");\r\nasm volatile("pxor %xmm5,%xmm4");\r\nasm volatile("pxor %xmm5,%xmm5");\r\nasm volatile("pxor %xmm6,%xmm2");\r\nasm volatile("pxor %xmm6,%xmm4");\r\nasm volatile("movdqa %0,%%xmm6" : : "m" (dptr[z][d]));\r\n}\r\nasm volatile("pcmpgtb %xmm4,%xmm5");\r\nasm volatile("paddb %xmm4,%xmm4");\r\nasm volatile("pand %xmm0,%xmm5");\r\nasm volatile("pxor %xmm5,%xmm4");\r\nasm volatile("pxor %xmm5,%xmm5");\r\nasm volatile("pxor %xmm6,%xmm2");\r\nasm volatile("pxor %xmm6,%xmm4");\r\nasm volatile("movntdq %%xmm2,%0" : "=m" (p[d]));\r\nasm volatile("pxor %xmm2,%xmm2");\r\nasm volatile("movntdq %%xmm4,%0" : "=m" (q[d]));\r\nasm volatile("pxor %xmm4,%xmm4");\r\n}\r\nasm volatile("sfence" : : : "memory");\r\nF_5 () ;\r\n}\r\nstatic void F_6 ( int V_5 , T_1 V_6 , void * * V_7 )\r\n{\r\nT_2 * * V_8 = ( T_2 * * ) V_7 ;\r\nT_2 * V_9 , * V_10 ;\r\nint V_11 , V_12 , V_13 ;\r\nV_13 = V_5 - 3 ;\r\nV_9 = V_8 [ V_13 + 1 ] ;\r\nV_10 = V_8 [ V_13 + 2 ] ;\r\nF_4 () ;\r\nasm volatile("movdqa %0,%%xmm0" : : "m" (raid6_sse_constants.x1d[0]));\r\nasm volatile("pxor %xmm5,%xmm5");\r\nasm volatile("pxor %xmm7,%xmm7");\r\nfor ( V_11 = 0 ; V_11 < V_6 ; V_11 += 32 ) {\r\nasm volatile("prefetchnta %0" : : "m" (dptr[z0][d]));\r\nasm volatile("movdqa %0,%%xmm2" : : "m" (dptr[z0][d]));\r\nasm volatile("movdqa %0,%%xmm3" : : "m" (dptr[z0][d+16]));\r\nasm volatile("movdqa %xmm2,%xmm4");\r\nasm volatile("movdqa %xmm3,%xmm6");\r\nfor ( V_12 = V_13 - 1 ; V_12 >= 0 ; V_12 -- ) {\r\nasm volatile("prefetchnta %0" : : "m" (dptr[z][d]));\r\nasm volatile("pcmpgtb %xmm4,%xmm5");\r\nasm volatile("pcmpgtb %xmm6,%xmm7");\r\nasm volatile("paddb %xmm4,%xmm4");\r\nasm volatile("paddb %xmm6,%xmm6");\r\nasm volatile("pand %xmm0,%xmm5");\r\nasm volatile("pand %xmm0,%xmm7");\r\nasm volatile("pxor %xmm5,%xmm4");\r\nasm volatile("pxor %xmm7,%xmm6");\r\nasm volatile("movdqa %0,%%xmm5" : : "m" (dptr[z][d]));\r\nasm volatile("movdqa %0,%%xmm7" : : "m" (dptr[z][d+16]));\r\nasm volatile("pxor %xmm5,%xmm2");\r\nasm volatile("pxor %xmm7,%xmm3");\r\nasm volatile("pxor %xmm5,%xmm4");\r\nasm volatile("pxor %xmm7,%xmm6");\r\nasm volatile("pxor %xmm5,%xmm5");\r\nasm volatile("pxor %xmm7,%xmm7");\r\n}\r\nasm volatile("movntdq %%xmm2,%0" : "=m" (p[d]));\r\nasm volatile("movntdq %%xmm3,%0" : "=m" (p[d+16]));\r\nasm volatile("movntdq %%xmm4,%0" : "=m" (q[d]));\r\nasm volatile("movntdq %%xmm6,%0" : "=m" (q[d+16]));\r\n}\r\nasm volatile("sfence" : : : "memory");\r\nF_5 () ;\r\n}\r\nstatic void F_7 ( int V_5 , T_1 V_6 , void * * V_7 )\r\n{\r\nT_2 * * V_8 = ( T_2 * * ) V_7 ;\r\nT_2 * V_9 , * V_10 ;\r\nint V_11 , V_12 , V_13 ;\r\nV_13 = V_5 - 3 ;\r\nV_9 = V_8 [ V_13 + 1 ] ;\r\nV_10 = V_8 [ V_13 + 2 ] ;\r\nF_4 () ;\r\nasm volatile("movdqa %0,%%xmm0" :: "m" (raid6_sse_constants.x1d[0]));\r\nasm volatile("pxor %xmm2,%xmm2");\r\nasm volatile("pxor %xmm3,%xmm3");\r\nasm volatile("pxor %xmm4,%xmm4");\r\nasm volatile("pxor %xmm5,%xmm5");\r\nasm volatile("pxor %xmm6,%xmm6");\r\nasm volatile("pxor %xmm7,%xmm7");\r\nasm volatile("pxor %xmm10,%xmm10");\r\nasm volatile("pxor %xmm11,%xmm11");\r\nasm volatile("pxor %xmm12,%xmm12");\r\nasm volatile("pxor %xmm13,%xmm13");\r\nasm volatile("pxor %xmm14,%xmm14");\r\nasm volatile("pxor %xmm15,%xmm15");\r\nfor ( V_11 = 0 ; V_11 < V_6 ; V_11 += 64 ) {\r\nfor ( V_12 = V_13 ; V_12 >= 0 ; V_12 -- ) {\r\nasm volatile("prefetchnta %0" :: "m" (dptr[z][d]));\r\nasm volatile("prefetchnta %0" :: "m" (dptr[z][d+32]));\r\nasm volatile("pcmpgtb %xmm4,%xmm5");\r\nasm volatile("pcmpgtb %xmm6,%xmm7");\r\nasm volatile("pcmpgtb %xmm12,%xmm13");\r\nasm volatile("pcmpgtb %xmm14,%xmm15");\r\nasm volatile("paddb %xmm4,%xmm4");\r\nasm volatile("paddb %xmm6,%xmm6");\r\nasm volatile("paddb %xmm12,%xmm12");\r\nasm volatile("paddb %xmm14,%xmm14");\r\nasm volatile("pand %xmm0,%xmm5");\r\nasm volatile("pand %xmm0,%xmm7");\r\nasm volatile("pand %xmm0,%xmm13");\r\nasm volatile("pand %xmm0,%xmm15");\r\nasm volatile("pxor %xmm5,%xmm4");\r\nasm volatile("pxor %xmm7,%xmm6");\r\nasm volatile("pxor %xmm13,%xmm12");\r\nasm volatile("pxor %xmm15,%xmm14");\r\nasm volatile("movdqa %0,%%xmm5" :: "m" (dptr[z][d]));\r\nasm volatile("movdqa %0,%%xmm7" :: "m" (dptr[z][d+16]));\r\nasm volatile("movdqa %0,%%xmm13" :: "m" (dptr[z][d+32]));\r\nasm volatile("movdqa %0,%%xmm15" :: "m" (dptr[z][d+48]));\r\nasm volatile("pxor %xmm5,%xmm2");\r\nasm volatile("pxor %xmm7,%xmm3");\r\nasm volatile("pxor %xmm13,%xmm10");\r\nasm volatile("pxor %xmm15,%xmm11");\r\nasm volatile("pxor %xmm5,%xmm4");\r\nasm volatile("pxor %xmm7,%xmm6");\r\nasm volatile("pxor %xmm13,%xmm12");\r\nasm volatile("pxor %xmm15,%xmm14");\r\nasm volatile("pxor %xmm5,%xmm5");\r\nasm volatile("pxor %xmm7,%xmm7");\r\nasm volatile("pxor %xmm13,%xmm13");\r\nasm volatile("pxor %xmm15,%xmm15");\r\n}\r\nasm volatile("movntdq %%xmm2,%0" : "=m" (p[d]));\r\nasm volatile("pxor %xmm2,%xmm2");\r\nasm volatile("movntdq %%xmm3,%0" : "=m" (p[d+16]));\r\nasm volatile("pxor %xmm3,%xmm3");\r\nasm volatile("movntdq %%xmm10,%0" : "=m" (p[d+32]));\r\nasm volatile("pxor %xmm10,%xmm10");\r\nasm volatile("movntdq %%xmm11,%0" : "=m" (p[d+48]));\r\nasm volatile("pxor %xmm11,%xmm11");\r\nasm volatile("movntdq %%xmm4,%0" : "=m" (q[d]));\r\nasm volatile("pxor %xmm4,%xmm4");\r\nasm volatile("movntdq %%xmm6,%0" : "=m" (q[d+16]));\r\nasm volatile("pxor %xmm6,%xmm6");\r\nasm volatile("movntdq %%xmm12,%0" : "=m" (q[d+32]));\r\nasm volatile("pxor %xmm12,%xmm12");\r\nasm volatile("movntdq %%xmm14,%0" : "=m" (q[d+48]));\r\nasm volatile("pxor %xmm14,%xmm14");\r\n}\r\nasm volatile("sfence" : : : "memory");\r\nF_5 () ;\r\n}
