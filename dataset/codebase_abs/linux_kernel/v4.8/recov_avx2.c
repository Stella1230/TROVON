static int F_1 ( void )\r\n{\r\nreturn F_2 ( V_1 ) &&\r\nF_2 ( V_2 ) ;\r\n}\r\nstatic void F_3 ( int V_3 , T_1 V_4 , int V_5 ,\r\nint V_6 , void * * V_7 )\r\n{\r\nT_2 * V_8 , * V_9 , * V_10 , * V_11 ;\r\nconst T_2 * V_12 ;\r\nconst T_2 * V_13 ;\r\nconst T_2 V_14 = 0x0f ;\r\nV_8 = ( T_2 * ) V_7 [ V_3 - 2 ] ;\r\nV_9 = ( T_2 * ) V_7 [ V_3 - 1 ] ;\r\nV_10 = ( T_2 * ) V_7 [ V_5 ] ;\r\nV_7 [ V_5 ] = ( void * ) V_15 ;\r\nV_7 [ V_3 - 2 ] = V_10 ;\r\nV_11 = ( T_2 * ) V_7 [ V_6 ] ;\r\nV_7 [ V_6 ] = ( void * ) V_15 ;\r\nV_7 [ V_3 - 1 ] = V_11 ;\r\nV_16 . V_17 ( V_3 , V_4 , V_7 ) ;\r\nV_7 [ V_5 ] = V_10 ;\r\nV_7 [ V_6 ] = V_11 ;\r\nV_7 [ V_3 - 2 ] = V_8 ;\r\nV_7 [ V_3 - 1 ] = V_9 ;\r\nV_12 = V_18 [ V_19 [ V_6 - V_5 ] ] ;\r\nV_13 = V_18 [ V_20 [ V_21 [ V_5 ] ^\r\nV_21 [ V_6 ] ] ] ;\r\nF_4 () ;\r\nasm volatile("vpbroadcastb %0, %%ymm7" : : "m" (x0f));\r\nwhile ( V_4 ) {\r\n#ifdef F_5\r\nasm volatile("vmovdqa %0, %%ymm1" : : "m" (q[0]));\r\nasm volatile("vmovdqa %0, %%ymm9" : : "m" (q[32]));\r\nasm volatile("vmovdqa %0, %%ymm0" : : "m" (p[0]));\r\nasm volatile("vmovdqa %0, %%ymm8" : : "m" (p[32]));\r\nasm volatile("vpxor %0, %%ymm1, %%ymm1" : : "m" (dq[0]));\r\nasm volatile("vpxor %0, %%ymm9, %%ymm9" : : "m" (dq[32]));\r\nasm volatile("vpxor %0, %%ymm0, %%ymm0" : : "m" (dp[0]));\r\nasm volatile("vpxor %0, %%ymm8, %%ymm8" : : "m" (dp[32]));\r\nasm volatile("vbroadcasti128 %0, %%ymm4" : : "m" (qmul[0]));\r\nasm volatile("vbroadcasti128 %0, %%ymm5" : : "m" (qmul[16]));\r\nasm volatile("vpsraw $4, %ymm1, %ymm3");\r\nasm volatile("vpsraw $4, %ymm9, %ymm12");\r\nasm volatile("vpand %ymm7, %ymm1, %ymm1");\r\nasm volatile("vpand %ymm7, %ymm9, %ymm9");\r\nasm volatile("vpand %ymm7, %ymm3, %ymm3");\r\nasm volatile("vpand %ymm7, %ymm12, %ymm12");\r\nasm volatile("vpshufb %ymm9, %ymm4, %ymm14");\r\nasm volatile("vpshufb %ymm1, %ymm4, %ymm4");\r\nasm volatile("vpshufb %ymm12, %ymm5, %ymm15");\r\nasm volatile("vpshufb %ymm3, %ymm5, %ymm5");\r\nasm volatile("vpxor %ymm14, %ymm15, %ymm15");\r\nasm volatile("vpxor %ymm4, %ymm5, %ymm5");\r\nasm volatile("vbroadcasti128 %0, %%ymm4" : : "m" (pbmul[0]));\r\nasm volatile("vbroadcasti128 %0, %%ymm1" : : "m" (pbmul[16]));\r\nasm volatile("vpsraw $4, %ymm0, %ymm2");\r\nasm volatile("vpsraw $4, %ymm8, %ymm6");\r\nasm volatile("vpand %ymm7, %ymm0, %ymm3");\r\nasm volatile("vpand %ymm7, %ymm8, %ymm14");\r\nasm volatile("vpand %ymm7, %ymm2, %ymm2");\r\nasm volatile("vpand %ymm7, %ymm6, %ymm6");\r\nasm volatile("vpshufb %ymm14, %ymm4, %ymm12");\r\nasm volatile("vpshufb %ymm3, %ymm4, %ymm4");\r\nasm volatile("vpshufb %ymm6, %ymm1, %ymm13");\r\nasm volatile("vpshufb %ymm2, %ymm1, %ymm1");\r\nasm volatile("vpxor %ymm4, %ymm1, %ymm1");\r\nasm volatile("vpxor %ymm12, %ymm13, %ymm13");\r\nasm volatile("vpxor %ymm5, %ymm1, %ymm1");\r\nasm volatile("vpxor %ymm15, %ymm13, %ymm13");\r\nasm volatile("vmovdqa %%ymm1, %0" : "=m" (dq[0]));\r\nasm volatile("vmovdqa %%ymm13,%0" : "=m" (dq[32]));\r\nasm volatile("vpxor %ymm1, %ymm0, %ymm0");\r\nasm volatile("vpxor %ymm13, %ymm8, %ymm8");\r\nasm volatile("vmovdqa %%ymm0, %0" : "=m" (dp[0]));\r\nasm volatile("vmovdqa %%ymm8, %0" : "=m" (dp[32]));\r\nV_4 -= 64 ;\r\nV_8 += 64 ;\r\nV_9 += 64 ;\r\nV_10 += 64 ;\r\nV_11 += 64 ;\r\n#else\r\nasm volatile("vmovdqa %0, %%ymm1" : : "m" (*q));\r\nasm volatile("vmovdqa %0, %%ymm0" : : "m" (*p));\r\nasm volatile("vpxor %0, %%ymm1, %%ymm1" : : "m" (*dq));\r\nasm volatile("vpxor %0, %%ymm0, %%ymm0" : : "m" (*dp));\r\nasm volatile("vbroadcasti128 %0, %%ymm4" : : "m" (qmul[0]));\r\nasm volatile("vbroadcasti128 %0, %%ymm5" : : "m" (qmul[16]));\r\nasm volatile("vpsraw $4, %ymm1, %ymm3");\r\nasm volatile("vpand %ymm7, %ymm1, %ymm1");\r\nasm volatile("vpand %ymm7, %ymm3, %ymm3");\r\nasm volatile("vpshufb %ymm1, %ymm4, %ymm4");\r\nasm volatile("vpshufb %ymm3, %ymm5, %ymm5");\r\nasm volatile("vpxor %ymm4, %ymm5, %ymm5");\r\nasm volatile("vbroadcasti128 %0, %%ymm4" : : "m" (pbmul[0]));\r\nasm volatile("vbroadcasti128 %0, %%ymm1" : : "m" (pbmul[16]));\r\nasm volatile("vpsraw $4, %ymm0, %ymm2");\r\nasm volatile("vpand %ymm7, %ymm0, %ymm3");\r\nasm volatile("vpand %ymm7, %ymm2, %ymm2");\r\nasm volatile("vpshufb %ymm3, %ymm4, %ymm4");\r\nasm volatile("vpshufb %ymm2, %ymm1, %ymm1");\r\nasm volatile("vpxor %ymm4, %ymm1, %ymm1");\r\nasm volatile("vpxor %ymm5, %ymm1, %ymm1");\r\nasm volatile("vmovdqa %%ymm1, %0" : "=m" (dq[0]));\r\nasm volatile("vpxor %ymm1, %ymm0, %ymm0");\r\nasm volatile("vmovdqa %%ymm0, %0" : "=m" (dp[0]));\r\nV_4 -= 32 ;\r\nV_8 += 32 ;\r\nV_9 += 32 ;\r\nV_10 += 32 ;\r\nV_11 += 32 ;\r\n#endif\r\n}\r\nF_6 () ;\r\n}\r\nstatic void F_7 ( int V_3 , T_1 V_4 , int V_5 ,\r\nvoid * * V_7 )\r\n{\r\nT_2 * V_8 , * V_9 , * V_11 ;\r\nconst T_2 * V_13 ;\r\nconst T_2 V_14 = 0x0f ;\r\nV_8 = ( T_2 * ) V_7 [ V_3 - 2 ] ;\r\nV_9 = ( T_2 * ) V_7 [ V_3 - 1 ] ;\r\nV_11 = ( T_2 * ) V_7 [ V_5 ] ;\r\nV_7 [ V_5 ] = ( void * ) V_15 ;\r\nV_7 [ V_3 - 1 ] = V_11 ;\r\nV_16 . V_17 ( V_3 , V_4 , V_7 ) ;\r\nV_7 [ V_5 ] = V_11 ;\r\nV_7 [ V_3 - 1 ] = V_9 ;\r\nV_13 = V_18 [ V_20 [ V_21 [ V_5 ] ] ] ;\r\nF_4 () ;\r\nasm volatile("vpbroadcastb %0, %%ymm7" : : "m" (x0f));\r\nwhile ( V_4 ) {\r\n#ifdef F_5\r\nasm volatile("vmovdqa %0, %%ymm3" : : "m" (dq[0]));\r\nasm volatile("vmovdqa %0, %%ymm8" : : "m" (dq[32]));\r\nasm volatile("vpxor %0, %%ymm3, %%ymm3" : : "m" (q[0]));\r\nasm volatile("vpxor %0, %%ymm8, %%ymm8" : : "m" (q[32]));\r\nasm volatile("vbroadcasti128 %0, %%ymm0" : : "m" (qmul[0]));\r\nasm volatile("vmovapd %ymm0, %ymm13");\r\nasm volatile("vbroadcasti128 %0, %%ymm1" : : "m" (qmul[16]));\r\nasm volatile("vmovapd %ymm1, %ymm14");\r\nasm volatile("vpsraw $4, %ymm3, %ymm6");\r\nasm volatile("vpsraw $4, %ymm8, %ymm12");\r\nasm volatile("vpand %ymm7, %ymm3, %ymm3");\r\nasm volatile("vpand %ymm7, %ymm8, %ymm8");\r\nasm volatile("vpand %ymm7, %ymm6, %ymm6");\r\nasm volatile("vpand %ymm7, %ymm12, %ymm12");\r\nasm volatile("vpshufb %ymm3, %ymm0, %ymm0");\r\nasm volatile("vpshufb %ymm8, %ymm13, %ymm13");\r\nasm volatile("vpshufb %ymm6, %ymm1, %ymm1");\r\nasm volatile("vpshufb %ymm12, %ymm14, %ymm14");\r\nasm volatile("vpxor %ymm0, %ymm1, %ymm1");\r\nasm volatile("vpxor %ymm13, %ymm14, %ymm14");\r\nasm volatile("vmovdqa %0, %%ymm2" : : "m" (p[0]));\r\nasm volatile("vmovdqa %0, %%ymm12" : : "m" (p[32]));\r\nasm volatile("vpxor %ymm1, %ymm2, %ymm2");\r\nasm volatile("vpxor %ymm14, %ymm12, %ymm12");\r\nasm volatile("vmovdqa %%ymm1, %0" : "=m" (dq[0]));\r\nasm volatile("vmovdqa %%ymm14, %0" : "=m" (dq[32]));\r\nasm volatile("vmovdqa %%ymm2, %0" : "=m" (p[0]));\r\nasm volatile("vmovdqa %%ymm12,%0" : "=m" (p[32]));\r\nV_4 -= 64 ;\r\nV_8 += 64 ;\r\nV_9 += 64 ;\r\nV_11 += 64 ;\r\n#else\r\nasm volatile("vmovdqa %0, %%ymm3" : : "m" (dq[0]));\r\nasm volatile("vpxor %0, %%ymm3, %%ymm3" : : "m" (q[0]));\r\nasm volatile("vbroadcasti128 %0, %%ymm0" : : "m" (qmul[0]));\r\nasm volatile("vbroadcasti128 %0, %%ymm1" : : "m" (qmul[16]));\r\nasm volatile("vpsraw $4, %ymm3, %ymm6");\r\nasm volatile("vpand %ymm7, %ymm3, %ymm3");\r\nasm volatile("vpand %ymm7, %ymm6, %ymm6");\r\nasm volatile("vpshufb %ymm3, %ymm0, %ymm0");\r\nasm volatile("vpshufb %ymm6, %ymm1, %ymm1");\r\nasm volatile("vpxor %ymm0, %ymm1, %ymm1");\r\nasm volatile("vmovdqa %0, %%ymm2" : : "m" (p[0]));\r\nasm volatile("vpxor %ymm1, %ymm2, %ymm2");\r\nasm volatile("vmovdqa %%ymm1, %0" : "=m" (dq[0]));\r\nasm volatile("vmovdqa %%ymm2, %0" : "=m" (p[0]));\r\nV_4 -= 32 ;\r\nV_8 += 32 ;\r\nV_9 += 32 ;\r\nV_11 += 32 ;\r\n#endif\r\n}\r\nF_6 () ;\r\n}
