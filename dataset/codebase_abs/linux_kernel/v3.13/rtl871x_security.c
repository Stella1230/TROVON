static void F_1 ( struct V_1 * V_2 , T_1 * V_3 , T_2 V_4 )
{
T_2 V_5 , V_6 ;
T_2 V_7 ;
T_2 V_8 ;
T_1 * V_9 ;
T_2 V_10 ;
V_9 = V_2 -> V_9 ;
V_2 -> V_11 = 0 ;
V_2 -> V_12 = 0 ;
for ( V_10 = 0 ; V_10 < 256 ; V_10 ++ )
V_9 [ V_10 ] = ( T_1 ) V_10 ;
V_7 = 0 ;
V_8 = 0 ;
for ( V_10 = 0 ; V_10 < 256 ; V_10 ++ ) {
V_5 = V_9 [ V_10 ] ;
V_8 = ( V_8 + V_3 [ V_7 ] + V_5 ) & 0xff ;
V_6 = V_9 [ V_8 ] ;
V_9 [ V_8 ] = ( T_1 ) V_5 ;
V_9 [ V_10 ] = ( T_1 ) V_6 ;
if ( ++ V_7 >= V_4 )
V_7 = 0 ;
}
}
static T_2 F_2 ( struct V_1 * V_2 )
{
T_2 V_11 ;
T_2 V_12 ;
T_2 V_13 , V_14 ;
T_1 * V_9 ;
V_9 = V_2 -> V_9 ;
V_11 = ( V_2 -> V_11 + 1 ) & 0xff ;
V_13 = V_9 [ V_11 ] ;
V_12 = ( V_13 + V_2 -> V_12 ) & 0xff ;
V_14 = V_9 [ V_12 ] ;
V_2 -> V_11 = V_11 ;
V_2 -> V_12 = V_12 ;
V_9 [ V_12 ] = ( T_1 ) V_13 ;
V_9 [ V_11 ] = ( T_1 ) V_14 ;
return V_9 [ ( V_13 + V_14 ) & 0xff ] ;
}
static void F_3 ( struct V_1 * V_2 ,
T_1 * V_15 , T_1 * V_16 , T_2 V_17 )
{
T_2 V_18 ;
for ( V_18 = 0 ; V_18 < V_17 ; V_18 ++ )
V_15 [ V_18 ] = V_16 [ V_18 ] ^ ( unsigned char ) F_2 ( V_2 ) ;
}
static T_1 F_4 ( T_1 V_19 )
{
return ( ( T_1 ) ( V_19 << 7 ) & 0x80 ) | ( ( V_19 << 5 ) & 0x40 ) | ( ( V_19 << 3 )
& 0x20 ) | ( ( V_19 << 1 ) & 0x10 ) | ( ( V_19 >> 1 ) & 0x08 ) |
( ( V_19 >> 3 ) & 0x04 ) | ( ( V_19 >> 5 ) & 0x02 ) | ( ( V_19 >> 7 ) &
0x01 ) ;
}
static void F_5 ( void )
{
if ( V_20 == 1 )
return;
else {
T_3 V_18 , V_21 ;
T_2 V_22 ;
T_1 * V_23 = ( T_1 * ) & V_22 , * V_24 ;
T_1 V_25 ;
V_22 = 0x12340000 ;
for ( V_18 = 0 ; V_18 < 256 ; ++ V_18 ) {
V_25 = F_4 ( ( T_1 ) V_18 ) ;
for ( V_22 = ( ( T_2 ) V_25 ) << 24 , V_21 = 8 ; V_21 > 0 ; -- V_21 )
V_22 = V_22 & 0x80000000 ? ( V_22 << 1 ) ^ V_26 :
( V_22 << 1 ) ;
V_24 = ( T_1 * ) & V_27 [ V_18 ] ;
V_24 [ 0 ] = F_4 ( V_23 [ 3 ] ) ;
V_24 [ 1 ] = F_4 ( V_23 [ 2 ] ) ;
V_24 [ 2 ] = F_4 ( V_23 [ 1 ] ) ;
V_24 [ 3 ] = F_4 ( V_23 [ 0 ] ) ;
}
V_20 = 1 ;
}
}
static T_2 F_6 ( T_1 * V_28 , T_2 V_17 )
{
T_1 * V_23 ;
T_2 V_29 ;
if ( V_20 == 0 )
F_5 () ;
V_29 = 0xffffffff ;
for ( V_23 = V_28 ; V_17 > 0 ; ++ V_23 , -- V_17 )
V_29 = V_27 [ ( V_29 ^ * V_23 ) & 0xff ] ^ ( V_29 >> 8 ) ;
return ~ V_29 ;
}
void F_7 ( struct V_30 * V_31 , T_1 * V_32 )
{
unsigned char V_29 [ 4 ] ;
struct V_1 V_33 ;
T_2 V_34 , V_35 , V_36 ;
T_1 * V_37 , * V_38 , * V_39 ;
T_1 V_40 [ 16 ] ;
struct V_41 * V_42 = & ( (struct V_43 * )
V_32 ) -> V_44 ;
struct V_45 * V_46 = & V_31 -> V_47 ;
struct V_48 * V_49 = & V_31 -> V_50 ;
if ( ( (struct V_43 * ) V_32 ) -> V_51 == NULL )
return;
V_37 = ( (struct V_43 * ) V_32 ) -> V_51 + V_52 ;
if ( ( V_42 -> V_53 == V_54 ) || ( V_42 -> V_53 == V_55 ) ) {
V_36 = V_46 -> V_56 [ V_46 ->
V_57 ] ;
for ( V_34 = 0 ; V_34 < V_42 -> V_58 ;
V_34 ++ ) {
V_39 = V_37 + V_42 -> V_59 ;
memcpy ( & V_40 [ 0 ] , V_39 , 3 ) ;
memcpy ( & V_40 [ 3 ] , & V_46 -> V_60 [
V_46 -> V_57 ] . V_61 [ 0 ] ,
V_36 ) ;
V_38 = V_37 + V_42 -> V_62 + V_42 -> V_59 ;
if ( ( V_34 + 1 ) == V_42 -> V_58 ) {
V_35 = V_42 -> V_63 - V_42 ->
V_59 - V_42 -> V_62 -
V_42 -> V_64 ;
* ( ( T_2 * ) V_29 ) = F_8 ( F_6 (
V_38 , V_35 ) ) ;
F_1 ( & V_33 , V_40 , 3 + V_36 ) ;
F_3 ( & V_33 , V_38 , V_38 ,
V_35 ) ;
F_3 ( & V_33 , V_38 + V_35 ,
V_29 , 4 ) ;
} else {
V_35 = V_49 -> V_65 - V_42 -> V_59 -
V_42 -> V_62 - V_42 -> V_64 ;
* ( ( T_2 * ) V_29 ) = F_8 ( F_6 (
V_38 , V_35 ) ) ;
F_1 ( & V_33 , V_40 , 3 + V_36 ) ;
F_3 ( & V_33 , V_38 , V_38 ,
V_35 ) ;
F_3 ( & V_33 , V_38 + V_35 ,
V_29 , 4 ) ;
V_37 += V_49 -> V_65 ;
V_37 = ( T_1 * ) F_9 ( ( V_66 ) ( V_37 ) ) ;
}
}
}
}
void F_10 ( struct V_30 * V_31 , T_1 * V_67 )
{
T_1 V_29 [ 4 ] ;
struct V_1 V_33 ;
T_2 V_35 , V_36 ;
T_1 * V_37 , * V_38 , * V_39 , V_40 [ 16 ] ;
T_1 V_7 ;
struct V_68 * V_69 = & ( ( (union V_70 * )
V_67 ) -> V_6 . V_71 . V_44 ) ;
struct V_45 * V_46 = & V_31 -> V_47 ;
V_37 = ( unsigned char * ) ( (union V_70 * ) V_67 ) ->
V_6 . V_71 . V_72 ;
if ( ( V_69 -> V_53 == V_54 ) || ( V_69 -> V_53 ==
V_55 ) ) {
V_39 = V_37 + V_69 -> V_59 ;
V_7 = ( V_39 [ 3 ] & 0x3 ) ;
V_36 = V_46 -> V_56 [ V_7 ] ;
memcpy ( & V_40 [ 0 ] , V_39 , 3 ) ;
memcpy ( & V_40 [ 3 ] , & V_46 -> V_60 [
V_46 -> V_57 ] . V_61 [ 0 ] ,
V_36 ) ;
V_35 = ( (union V_70 * ) V_67 ) ->
V_6 . V_71 . V_17 - V_69 -> V_59 - V_69 -> V_62 ;
V_38 = V_37 + V_69 -> V_62 + V_69 -> V_59 ;
F_1 ( & V_33 , V_40 , 3 + V_36 ) ;
F_3 ( & V_33 , V_38 , V_38 , V_35 ) ;
* ( ( T_2 * ) V_29 ) = F_8 ( F_6 ( V_38 , V_35 - 4 ) ) ;
}
return;
}
static T_2 F_11 ( T_1 * V_23 )
{
T_4 V_18 ;
T_2 V_73 = 0 ;
for ( V_18 = 0 ; V_18 < 4 ; V_18 ++ )
V_73 |= ( ( T_2 ) ( * V_23 ++ ) ) << ( 8 * V_18 ) ;
return V_73 ;
}
static void F_12 ( T_1 * V_23 , T_2 V_74 )
{
long V_18 ;
for ( V_18 = 0 ; V_18 < 4 ; V_18 ++ ) {
* V_23 ++ = ( T_1 ) ( V_74 & 0xff ) ;
V_74 >>= 8 ;
}
}
static void F_13 ( struct V_75 * V_76 )
{
V_76 -> V_77 = V_76 -> V_78 ;
V_76 -> V_79 = V_76 -> V_80 ;
V_76 -> V_81 = 0 ;
V_76 -> V_82 = 0 ;
}
void F_14 ( struct V_75 * V_76 , T_1 * V_3 )
{
V_76 -> V_78 = F_11 ( V_3 ) ;
V_76 -> V_80 = F_11 ( V_3 + 4 ) ;
F_13 ( V_76 ) ;
}
static void F_15 ( struct V_75 * V_76 , T_1 V_83 )
{
V_76 -> V_82 |= ( ( T_2 ) V_83 ) << ( 8 * V_76 -> V_81 ) ;
V_76 -> V_81 ++ ;
if ( V_76 -> V_81 >= 4 ) {
V_76 -> V_77 ^= V_76 -> V_82 ;
V_76 -> V_79 ^= F_16 ( V_76 -> V_77 , 17 ) ;
V_76 -> V_77 += V_76 -> V_79 ;
V_76 -> V_79 ^= ( ( V_76 -> V_77 & 0xff00ff00 ) >> 8 ) |
( ( V_76 -> V_77 & 0x00ff00ff ) << 8 ) ;
V_76 -> V_77 += V_76 -> V_79 ;
V_76 -> V_79 ^= F_16 ( V_76 -> V_77 , 3 ) ;
V_76 -> V_77 += V_76 -> V_79 ;
V_76 -> V_79 ^= F_17 ( V_76 -> V_77 , 2 ) ;
V_76 -> V_77 += V_76 -> V_79 ;
V_76 -> V_82 = 0 ;
V_76 -> V_81 = 0 ;
}
}
void F_18 ( struct V_75 * V_76 , T_1 * V_16 , T_2 V_84 )
{
while ( V_84 > 0 ) {
F_15 ( V_76 , * V_16 ++ ) ;
V_84 -- ;
}
}
void F_19 ( struct V_75 * V_76 , T_1 * V_85 )
{
F_15 ( V_76 , 0x5a ) ;
F_15 ( V_76 , 0 ) ;
F_15 ( V_76 , 0 ) ;
F_15 ( V_76 , 0 ) ;
F_15 ( V_76 , 0 ) ;
while ( V_76 -> V_81 != 0 )
F_15 ( V_76 , 0 ) ;
F_12 ( V_85 , V_76 -> V_77 ) ;
F_12 ( V_85 + 4 , V_76 -> V_79 ) ;
F_13 ( V_76 ) ;
}
void F_20 ( T_1 * V_3 , T_1 * V_86 , T_1 * V_19 , T_2 V_87 , T_1 * V_88 ,
T_1 V_89 )
{
struct V_75 V_90 ;
T_1 V_91 [ 4 ] = { 0x0 , 0x0 , 0x0 , 0x0 } ;
F_14 ( & V_90 , V_3 ) ;
V_91 [ 0 ] = V_89 ;
if ( V_86 [ 1 ] & 1 ) {
F_18 ( & V_90 , & V_86 [ 16 ] , 6 ) ;
if ( V_86 [ 1 ] & 2 )
F_18 ( & V_90 , & V_86 [ 24 ] , 6 ) ;
else
F_18 ( & V_90 , & V_86 [ 10 ] , 6 ) ;
} else {
F_18 ( & V_90 , & V_86 [ 4 ] , 6 ) ;
if ( V_86 [ 1 ] & 2 )
F_18 ( & V_90 , & V_86 [ 16 ] , 6 ) ;
else
F_18 ( & V_90 , & V_86 [ 10 ] , 6 ) ;
}
F_18 ( & V_90 , & V_91 [ 0 ] , 4 ) ;
F_18 ( & V_90 , V_19 , V_87 ) ;
F_19 ( & V_90 , V_88 ) ;
}
static void F_21 ( T_5 * V_92 , const T_1 * V_93 , const T_1 * V_94 , T_2 V_95 )
{
T_3 V_18 ;
V_92 [ 0 ] = F_22 ( V_95 ) ;
V_92 [ 1 ] = F_23 ( V_95 ) ;
V_92 [ 2 ] = F_24 ( V_94 [ 1 ] , V_94 [ 0 ] ) ;
V_92 [ 3 ] = F_24 ( V_94 [ 3 ] , V_94 [ 2 ] ) ;
V_92 [ 4 ] = F_24 ( V_94 [ 5 ] , V_94 [ 4 ] ) ;
for ( V_18 = 0 ; V_18 < V_96 ; V_18 ++ ) {
V_92 [ 0 ] += F_25 ( V_92 [ 4 ] ^ F_26 ( ( V_18 & 1 ) + 0 ) ) ;
V_92 [ 1 ] += F_25 ( V_92 [ 0 ] ^ F_26 ( ( V_18 & 1 ) + 2 ) ) ;
V_92 [ 2 ] += F_25 ( V_92 [ 1 ] ^ F_26 ( ( V_18 & 1 ) + 4 ) ) ;
V_92 [ 3 ] += F_25 ( V_92 [ 2 ] ^ F_26 ( ( V_18 & 1 ) + 6 ) ) ;
V_92 [ 4 ] += F_25 ( V_92 [ 3 ] ^ F_26 ( ( V_18 & 1 ) + 0 ) ) ;
V_92 [ 4 ] += ( unsigned short ) V_18 ;
}
}
static void F_27 ( T_1 * V_97 , const T_1 * V_93 , const T_5 * V_92 , T_5 V_98 )
{
T_3 V_18 ;
T_5 V_99 [ 6 ] ;
for ( V_18 = 0 ; V_18 < 5 ; V_18 ++ )
V_99 [ V_18 ] = V_92 [ V_18 ] ;
V_99 [ 5 ] = V_92 [ 4 ] + V_98 ;
V_99 [ 0 ] += F_25 ( V_99 [ 5 ] ^ F_26 ( 0 ) ) ;
V_99 [ 1 ] += F_25 ( V_99 [ 0 ] ^ F_26 ( 1 ) ) ;
V_99 [ 2 ] += F_25 ( V_99 [ 1 ] ^ F_26 ( 2 ) ) ;
V_99 [ 3 ] += F_25 ( V_99 [ 2 ] ^ F_26 ( 3 ) ) ;
V_99 [ 4 ] += F_25 ( V_99 [ 3 ] ^ F_26 ( 4 ) ) ;
V_99 [ 5 ] += F_25 ( V_99 [ 4 ] ^ F_26 ( 5 ) ) ;
V_99 [ 0 ] += F_28 ( V_99 [ 5 ] ^ F_26 ( 6 ) ) ;
V_99 [ 1 ] += F_28 ( V_99 [ 0 ] ^ F_26 ( 7 ) ) ;
V_99 [ 2 ] += F_28 ( V_99 [ 1 ] ) ;
V_99 [ 3 ] += F_28 ( V_99 [ 2 ] ) ;
V_99 [ 4 ] += F_28 ( V_99 [ 3 ] ) ;
V_99 [ 5 ] += F_28 ( V_99 [ 4 ] ) ;
V_97 [ 0 ] = F_29 ( V_98 ) ;
V_97 [ 1 ] = ( F_29 ( V_98 ) | 0x20 ) & 0x7F ;
V_97 [ 2 ] = F_30 ( V_98 ) ;
V_97 [ 3 ] = F_30 ( ( V_99 [ 5 ] ^ F_26 ( 0 ) ) >> 1 ) ;
for ( V_18 = 0 ; V_18 < 6 ; V_18 ++ ) {
V_97 [ 4 + 2 * V_18 ] = F_30 ( V_99 [ V_18 ] ) ;
V_97 [ 5 + 2 * V_18 ] = F_29 ( V_99 [ V_18 ] ) ;
}
}
T_2 F_31 ( struct V_30 * V_31 , T_1 * V_32 )
{
T_5 V_100 ;
T_2 V_101 ;
T_1 V_97 [ 16 ] ;
T_1 V_102 [ 16 ] ;
T_1 V_29 [ 4 ] ;
struct V_1 V_33 ;
T_2 V_34 , V_35 , V_103 ;
T_1 * V_37 , * V_38 , * V_39 , * V_104 ;
union V_105 V_106 ;
struct V_107 * V_108 ;
struct V_41 * V_42 = & ( (struct V_43 * ) V_32 ) -> V_44 ;
struct V_48 * V_49 = & V_31 -> V_50 ;
T_2 V_73 = V_109 ;
if ( ( (struct V_43 * ) V_32 ) -> V_51 == NULL )
return V_110 ;
V_37 = ( (struct V_43 * ) V_32 ) -> V_51 + V_52 ;
if ( V_42 -> V_53 == V_111 ) {
if ( V_42 -> V_112 )
V_108 = V_42 -> V_112 ;
else
V_108 = F_32 ( & V_31 -> V_113 ,
& V_42 -> V_114 [ 0 ] ) ;
if ( V_108 != NULL ) {
V_104 = & V_108 -> V_115 . V_61 [ 0 ] ;
V_103 = 16 ;
for ( V_34 = 0 ; V_34 < V_42 -> V_58 ;
V_34 ++ ) {
V_39 = V_37 + V_42 -> V_59 ;
V_38 = V_37 + V_42 -> V_62 +
V_42 -> V_59 ;
F_33 ( V_39 , V_106 ) ;
V_100 = ( T_5 ) ( V_106 . V_74 ) ;
V_101 = ( T_2 ) ( V_106 . V_74 >> 16 ) ;
F_21 ( ( T_5 * ) & V_102 [ 0 ] , V_104 , & V_42 ->
V_94 [ 0 ] , V_101 ) ;
F_27 ( & V_97 [ 0 ] , V_104 , ( T_5 * ) & V_102 [ 0 ] ,
V_100 ) ;
if ( ( V_34 + 1 ) == V_42 -> V_58 ) {
V_35 = V_42 -> V_63 -
V_42 -> V_59 - V_42 -> V_62 -
V_42 -> V_64 ;
* ( ( T_2 * ) V_29 ) = F_8 (
F_6 ( V_38 , V_35 ) ) ;
F_1 ( & V_33 , V_97 , 16 ) ;
F_3 ( & V_33 , V_38 ,
V_38 , V_35 ) ;
F_3 ( & V_33 , V_38 +
V_35 , V_29 , 4 ) ;
} else {
V_35 = V_49 -> V_65 - V_42 ->
V_59 - V_42 ->
V_62 - V_42 -> V_64 ;
* ( ( T_2 * ) V_29 ) = F_8 ( F_6 (
V_38 , V_35 ) ) ;
F_1 ( & V_33 , V_97 , 16 ) ;
F_3 ( & V_33 , V_38 ,
V_38 , V_35 ) ;
F_3 ( & V_33 ,
V_38 + V_35 , V_29 , 4 ) ;
V_37 += V_49 -> V_65 ;
V_37 = ( T_1 * ) F_9 ( ( V_66 ) ( V_37 ) ) ;
}
}
} else
V_73 = V_110 ;
}
return V_73 ;
}
T_2 F_34 ( struct V_30 * V_31 , T_1 * V_67 )
{
T_5 V_100 ;
T_2 V_101 ;
T_1 V_97 [ 16 ] ;
T_1 V_102 [ 16 ] ;
T_1 V_29 [ 4 ] ;
struct V_1 V_33 ;
T_2 V_35 , V_103 ;
T_1 * V_37 , * V_38 , * V_39 , * V_104 , V_116 = 0 ;
union V_105 V_106 ;
struct V_107 * V_108 ;
struct V_68 * V_69 = & ( (union V_70 * )
V_67 ) -> V_6 . V_71 . V_44 ;
struct V_45 * V_46 = & V_31 -> V_47 ;
V_37 = ( unsigned char * ) ( (union V_70 * )
V_67 ) -> V_6 . V_71 . V_72 ;
if ( V_69 -> V_53 == V_111 ) {
V_108 = F_32 ( & V_31 -> V_113 ,
& V_69 -> V_94 [ 0 ] ) ;
if ( V_108 != NULL ) {
V_39 = V_37 + V_69 -> V_59 ;
V_38 = V_37 + V_69 -> V_62 + V_69 -> V_59 ;
V_35 = ( (union V_70 * ) V_67 ) ->
V_6 . V_71 . V_17 - V_69 -> V_59 -
V_69 -> V_62 ;
if ( F_35 ( V_69 -> V_114 ) ) {
V_116 = V_39 [ 3 ] ;
V_104 = & V_46 -> V_117 [
( ( V_116 >> 6 ) & 0x3 ) - 1 ] . V_61 [ 0 ] ;
if ( V_46 -> V_118 == false )
return V_110 ;
} else
V_104 = & V_108 -> V_115 . V_61 [ 0 ] ;
V_103 = 16 ;
F_33 ( V_39 , V_106 ) ;
V_100 = ( T_5 ) ( V_106 . V_74 ) ;
V_101 = ( T_2 ) ( V_106 . V_74 >> 16 ) ;
F_21 ( ( T_5 * ) & V_102 [ 0 ] , V_104 , & V_69 -> V_94 [ 0 ] ,
V_101 ) ;
F_27 ( & V_97 [ 0 ] , V_104 , ( unsigned short * )
& V_102 [ 0 ] , V_100 ) ;
F_1 ( & V_33 , V_97 , 16 ) ;
F_3 ( & V_33 , V_38 , V_38 , V_35 ) ;
* ( ( T_2 * ) V_29 ) = F_8 ( F_6 ( V_38 ,
V_35 - 4 ) ) ;
if ( V_29 [ 3 ] != V_38 [ V_35 - 1 ] ||
V_29 [ 2 ] != V_38 [ V_35 - 2 ] ||
V_29 [ 1 ] != V_38 [ V_35 - 3 ] ||
V_29 [ 0 ] != V_38 [ V_35 - 4 ] )
return V_110 ;
} else
return V_110 ;
}
return V_109 ;
}
static void F_36 ( T_1 * V_119 , T_1 * V_83 , T_1 * V_120 )
{
T_3 V_18 ;
for ( V_18 = 0 ; V_18 < 16 ; V_18 ++ )
V_120 [ V_18 ] = V_119 [ V_18 ] ^ V_83 [ V_18 ] ;
}
static void F_37 ( T_1 * V_119 , T_1 * V_83 , T_1 * V_120 )
{
T_3 V_18 ;
for ( V_18 = 0 ; V_18 < 4 ; V_18 ++ )
V_120 [ V_18 ] = V_119 [ V_18 ] ^ V_83 [ V_18 ] ;
}
static T_1 F_38 ( T_1 V_119 )
{
return V_121 [ ( T_3 ) V_119 ] ;
}
static void F_39 ( T_1 * V_3 , T_3 V_122 )
{
T_1 V_123 ;
T_1 V_124 [ 4 ] ;
T_1 V_125 [ 12 ] = {
0x01 , 0x02 , 0x04 , 0x08 , 0x10 , 0x20 , 0x40 , 0x80 ,
0x1b , 0x36 , 0x36 , 0x36
} ;
V_124 [ 0 ] = F_38 ( V_3 [ 13 ] ) ;
V_124 [ 1 ] = F_38 ( V_3 [ 14 ] ) ;
V_124 [ 2 ] = F_38 ( V_3 [ 15 ] ) ;
V_124 [ 3 ] = F_38 ( V_3 [ 12 ] ) ;
V_123 = V_125 [ V_122 ] ;
F_37 ( & V_3 [ 0 ] , V_124 , & V_3 [ 0 ] ) ;
V_3 [ 0 ] = V_3 [ 0 ] ^ V_123 ;
F_37 ( & V_3 [ 4 ] , & V_3 [ 0 ] , & V_3 [ 4 ] ) ;
F_37 ( & V_3 [ 8 ] , & V_3 [ 4 ] , & V_3 [ 8 ] ) ;
F_37 ( & V_3 [ 12 ] , & V_3 [ 8 ] , & V_3 [ 12 ] ) ;
}
static void F_40 ( T_1 * V_126 , T_1 * V_120 )
{
T_3 V_18 ;
for ( V_18 = 0 ; V_18 < 16 ; V_18 ++ )
V_120 [ V_18 ] = F_38 ( V_126 [ V_18 ] ) ;
}
static void F_41 ( T_1 * V_126 , T_1 * V_120 )
{
V_120 [ 0 ] = V_126 [ 0 ] ;
V_120 [ 1 ] = V_126 [ 5 ] ;
V_120 [ 2 ] = V_126 [ 10 ] ;
V_120 [ 3 ] = V_126 [ 15 ] ;
V_120 [ 4 ] = V_126 [ 4 ] ;
V_120 [ 5 ] = V_126 [ 9 ] ;
V_120 [ 6 ] = V_126 [ 14 ] ;
V_120 [ 7 ] = V_126 [ 3 ] ;
V_120 [ 8 ] = V_126 [ 8 ] ;
V_120 [ 9 ] = V_126 [ 13 ] ;
V_120 [ 10 ] = V_126 [ 2 ] ;
V_120 [ 11 ] = V_126 [ 7 ] ;
V_120 [ 12 ] = V_126 [ 12 ] ;
V_120 [ 13 ] = V_126 [ 1 ] ;
V_120 [ 14 ] = V_126 [ 6 ] ;
V_120 [ 15 ] = V_126 [ 11 ] ;
}
static void F_42 ( T_1 * V_126 , T_1 * V_120 )
{
T_3 V_18 ;
T_1 V_127 [ 4 ] ;
T_1 V_128 [ 4 ] ;
T_1 V_129 [ 4 ] ;
T_1 V_130 [ 4 ] ;
T_1 V_131 [ 4 ] ;
T_1 V_132 [ 4 ] ;
T_1 V_133 [ 4 ] ;
T_1 V_134 [ 4 ] ;
for ( V_18 = 0 ; V_18 < 4 ; V_18 ++ ) {
if ( ( V_126 [ V_18 ] & 0x80 ) == 0x80 )
V_127 [ V_18 ] = 0x1b ;
else
V_127 [ V_18 ] = 0x00 ;
}
V_130 [ 0 ] = V_126 [ 2 ] ;
V_130 [ 1 ] = V_126 [ 3 ] ;
V_130 [ 2 ] = V_126 [ 0 ] ;
V_130 [ 3 ] = V_126 [ 1 ] ;
V_129 [ 0 ] = V_126 [ 3 ] ;
V_129 [ 1 ] = V_126 [ 0 ] ;
V_129 [ 2 ] = V_126 [ 1 ] ;
V_129 [ 3 ] = V_126 [ 2 ] ;
V_131 [ 0 ] = V_126 [ 0 ] & 0x7f ;
V_131 [ 1 ] = V_126 [ 1 ] & 0x7f ;
V_131 [ 2 ] = V_126 [ 2 ] & 0x7f ;
V_131 [ 3 ] = V_126 [ 3 ] & 0x7f ;
for ( V_18 = 3 ; V_18 > 0 ; V_18 -- ) {
V_131 [ V_18 ] = V_131 [ V_18 ] << 1 ;
if ( ( V_131 [ V_18 - 1 ] & 0x80 ) == 0x80 )
V_131 [ V_18 ] = ( V_131 [ V_18 ] | 0x01 ) ;
}
V_131 [ 0 ] = V_131 [ 0 ] << 1 ;
V_131 [ 0 ] = V_131 [ 0 ] & 0xfe ;
F_37 ( V_127 , V_131 , V_128 ) ;
F_37 ( V_126 , V_128 , V_132 ) ;
V_133 [ 0 ] = V_132 [ 0 ] ;
V_132 [ 0 ] = V_132 [ 1 ] ;
V_132 [ 1 ] = V_132 [ 2 ] ;
V_132 [ 2 ] = V_132 [ 3 ] ;
V_132 [ 3 ] = V_133 [ 0 ] ;
F_37 ( V_128 , V_132 , V_133 ) ;
F_37 ( V_130 , V_129 , V_134 ) ;
F_37 ( V_133 , V_134 , V_120 ) ;
}
static void F_43 ( T_1 * V_3 , T_1 * V_19 , T_1 * V_135 )
{
T_3 V_122 ;
T_3 V_18 ;
T_1 V_136 [ 16 ] ;
T_1 V_137 [ 16 ] ;
T_1 V_138 [ 16 ] ;
for ( V_18 = 0 ; V_18 < 16 ; V_18 ++ )
V_138 [ V_18 ] = V_3 [ V_18 ] ;
for ( V_122 = 0 ; V_122 < 11 ; V_122 ++ ) {
if ( V_122 == 0 ) {
F_36 ( V_138 , V_19 , V_135 ) ;
F_39 ( V_138 , V_122 ) ;
} else if ( V_122 == 10 ) {
F_40 ( V_135 , V_136 ) ;
F_41 ( V_136 , V_137 ) ;
F_36 ( V_137 , V_138 , V_135 ) ;
} else {
F_40 ( V_135 , V_136 ) ;
F_41 ( V_136 , V_137 ) ;
F_42 ( & V_137 [ 0 ] , & V_136 [ 0 ] ) ;
F_42 ( & V_137 [ 4 ] , & V_136 [ 4 ] ) ;
F_42 ( & V_137 [ 8 ] , & V_136 [ 8 ] ) ;
F_42 ( & V_137 [ 12 ] , & V_136 [ 12 ] ) ;
F_36 ( V_136 , V_138 , V_135 ) ;
F_39 ( V_138 , V_122 ) ;
}
}
}
static void F_44 ( T_1 * V_139 , T_3 V_140 , T_3 V_141 ,
T_1 * V_142 , T_6 V_143 , T_1 * V_144 )
{
T_3 V_18 ;
V_139 [ 0 ] = 0x59 ;
if ( V_140 && V_141 )
V_139 [ 1 ] = V_142 [ 30 ] & 0x0f ;
if ( V_140 && ! V_141 )
V_139 [ 1 ] = V_142 [ 24 ] & 0x0f ;
if ( ! V_140 )
V_139 [ 1 ] = 0x00 ;
for ( V_18 = 2 ; V_18 < 8 ; V_18 ++ )
V_139 [ V_18 ] = V_142 [ V_18 + 8 ] ;
for ( V_18 = 8 ; V_18 < 14 ; V_18 ++ )
V_139 [ V_18 ] = V_144 [ 13 - V_18 ] ;
V_139 [ 14 ] = ( unsigned char ) ( V_143 / 256 ) ;
V_139 [ 15 ] = ( unsigned char ) ( V_143 % 256 ) ;
}
static void F_45 ( T_1 * V_145 , T_3 V_146 , T_1 * V_142 )
{
V_145 [ 0 ] = ( T_1 ) ( ( V_146 - 2 ) / 256 ) ;
V_145 [ 1 ] = ( T_1 ) ( ( V_146 - 2 ) % 256 ) ;
V_145 [ 2 ] = V_142 [ 0 ] & 0xcf ;
V_145 [ 3 ] = V_142 [ 1 ] & 0xc7 ;
V_145 [ 4 ] = V_142 [ 4 ] ;
V_145 [ 5 ] = V_142 [ 5 ] ;
V_145 [ 6 ] = V_142 [ 6 ] ;
V_145 [ 7 ] = V_142 [ 7 ] ;
V_145 [ 8 ] = V_142 [ 8 ] ;
V_145 [ 9 ] = V_142 [ 9 ] ;
V_145 [ 10 ] = V_142 [ 10 ] ;
V_145 [ 11 ] = V_142 [ 11 ] ;
V_145 [ 12 ] = V_142 [ 12 ] ;
V_145 [ 13 ] = V_142 [ 13 ] ;
V_145 [ 14 ] = V_142 [ 14 ] ;
V_145 [ 15 ] = V_142 [ 15 ] ;
}
static void F_46 ( T_1 * V_147 , T_1 * V_142 , T_3 V_141 ,
T_3 V_140 )
{
T_3 V_18 ;
for ( V_18 = 0 ; V_18 < 16 ; V_18 ++ )
V_147 [ V_18 ] = 0x00 ;
V_147 [ 0 ] = V_142 [ 16 ] ;
V_147 [ 1 ] = V_142 [ 17 ] ;
V_147 [ 2 ] = V_142 [ 18 ] ;
V_147 [ 3 ] = V_142 [ 19 ] ;
V_147 [ 4 ] = V_142 [ 20 ] ;
V_147 [ 5 ] = V_142 [ 21 ] ;
V_147 [ 6 ] = 0x00 ;
V_147 [ 7 ] = 0x00 ;
if ( ! V_140 && V_141 )
for ( V_18 = 0 ; V_18 < 6 ; V_18 ++ )
V_147 [ 8 + V_18 ] = V_142 [ 24 + V_18 ] ;
if ( V_140 && ! V_141 ) {
V_147 [ 8 ] = V_142 [ 24 ] & 0x0f ;
V_147 [ 9 ] = V_142 [ 25 ] & 0x00 ;
}
if ( V_140 && V_141 ) {
for ( V_18 = 0 ; V_18 < 6 ; V_18 ++ )
V_147 [ 8 + V_18 ] = V_142 [ 24 + V_18 ] ;
V_147 [ 14 ] = V_142 [ 30 ] & 0x0f ;
V_147 [ 15 ] = V_142 [ 31 ] & 0x00 ;
}
}
static void F_47 ( T_1 * V_148 , T_3 V_141 , T_3 V_140 ,
T_1 * V_142 , T_1 * V_144 , T_3 V_22 )
{
T_3 V_18 ;
for ( V_18 = 0 ; V_18 < 16 ; V_18 ++ )
V_148 [ V_18 ] = 0x00 ;
V_18 = 0 ;
V_148 [ 0 ] = 0x01 ;
if ( V_140 && V_141 )
V_148 [ 1 ] = V_142 [ 30 ] & 0x0f ;
if ( V_140 && ! V_141 )
V_148 [ 1 ] = V_142 [ 24 ] & 0x0f ;
for ( V_18 = 2 ; V_18 < 8 ; V_18 ++ )
V_148 [ V_18 ] = V_142 [ V_18 + 8 ] ;
for ( V_18 = 8 ; V_18 < 14 ; V_18 ++ )
V_148 [ V_18 ] = V_144 [ 13 - V_18 ] ;
V_148 [ 14 ] = ( unsigned char ) ( V_22 / 256 ) ;
V_148 [ 15 ] = ( unsigned char ) ( V_22 % 256 ) ;
}
static void F_48 ( T_1 * V_149 , T_1 * V_150 , T_1 * V_120 )
{
T_3 V_18 ;
for ( V_18 = 0 ; V_18 < 16 ; V_18 ++ )
V_120 [ V_18 ] = V_149 [ V_18 ] ^ V_150 [ V_18 ] ;
}
static T_3 F_49 ( T_1 * V_3 , T_6 V_59 ,
T_1 * V_37 , T_6 V_151 )
{
T_6 V_140 , V_141 , V_18 , V_21 , V_152 ;
T_6 V_153 , V_154 ;
T_1 V_144 [ 6 ] ;
T_1 V_139 [ 16 ] ;
T_1 V_145 [ 16 ] ;
T_1 V_147 [ 16 ] ;
T_1 V_148 [ 16 ] ;
T_1 V_155 [ 16 ] ;
T_1 V_156 [ 16 ] ;
T_1 V_157 [ 16 ] ;
T_1 V_158 [ 8 ] ;
T_6 V_159 = F_50 ( V_37 ) ;
T_6 V_160 = F_51 ( V_37 ) ;
V_160 = V_160 >> 4 ;
memset ( ( void * ) V_139 , 0 , 16 ) ;
memset ( ( void * ) V_145 , 0 , 16 ) ;
memset ( ( void * ) V_147 , 0 , 16 ) ;
memset ( ( void * ) V_148 , 0 , 16 ) ;
memset ( ( void * ) V_155 , 0 , 16 ) ;
memset ( ( void * ) V_156 , 0 , 16 ) ;
memset ( ( void * ) V_157 , 0 , 16 ) ;
if ( ( V_59 == V_161 ) || ( V_59 == V_162 ) )
V_141 = 0 ;
else
V_141 = 1 ;
if ( ( V_159 == V_163 ) ||
( V_159 == V_164 ) ||
( V_159 == V_165 ) ) {
V_140 = 1 ;
if ( V_59 != V_162 )
V_59 += 2 ;
} else if ( ( V_160 == 0x08 ) ||
( V_160 == 0x09 ) ||
( V_160 == 0x0a ) ||
( V_160 == 0x0b ) ) {
if ( V_59 != V_162 )
V_59 += 2 ;
V_140 = 1 ;
} else
V_140 = 0 ;
V_144 [ 0 ] = V_37 [ V_59 ] ;
V_144 [ 1 ] = V_37 [ V_59 + 1 ] ;
V_144 [ 2 ] = V_37 [ V_59 + 4 ] ;
V_144 [ 3 ] = V_37 [ V_59 + 5 ] ;
V_144 [ 4 ] = V_37 [ V_59 + 6 ] ;
V_144 [ 5 ] = V_37 [ V_59 + 7 ] ;
F_44 ( V_139 , V_140 , V_141 , V_37 , V_151 , V_144 ) ;
F_45 ( V_145 , V_59 , V_37 ) ;
F_46 ( V_147 , V_37 , V_141 , V_140 ) ;
V_152 = V_151 % 16 ;
V_153 = V_151 / 16 ;
V_154 = ( V_59 + 8 ) ;
F_43 ( V_3 , V_139 , V_156 ) ;
F_48 ( V_156 , V_145 , V_155 ) ;
F_43 ( V_3 , V_155 , V_156 ) ;
F_48 ( V_156 , V_147 , V_155 ) ;
F_43 ( V_3 , V_155 , V_156 ) ;
for ( V_18 = 0 ; V_18 < V_153 ; V_18 ++ ) {
F_48 ( V_156 , & V_37 [ V_154 ] , V_155 ) ;
V_154 += 16 ;
F_43 ( V_3 , V_155 , V_156 ) ;
}
if ( V_152 > 0 ) {
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_157 [ V_21 ] = 0x00 ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_157 [ V_21 ] = V_37 [ V_154 ++ ] ;
F_48 ( V_156 , V_157 , V_155 ) ;
F_43 ( V_3 , V_155 , V_156 ) ;
}
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_158 [ V_21 ] = V_156 [ V_21 ] ;
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_37 [ V_154 + V_21 ] = V_158 [ V_21 ] ;
V_154 = V_59 + 8 ;
for ( V_18 = 0 ; V_18 < V_153 ; V_18 ++ ) {
F_47 ( V_148 , V_141 , V_140 ,
V_37 , V_144 , V_18 + 1 ) ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , & V_37 [ V_154 ] , V_155 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_37 [ V_154 ++ ] = V_155 [ V_21 ] ;
}
if ( V_152 > 0 ) {
F_47 ( V_148 , V_141 , V_140 ,
V_37 , V_144 , V_153 + 1 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_157 [ V_21 ] = 0x00 ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_157 [ V_21 ] = V_37 [ V_154 + V_21 ] ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , V_157 , V_155 ) ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_37 [ V_154 ++ ] = V_155 [ V_21 ] ;
}
F_47 ( V_148 , V_141 , V_140 ,
V_37 , V_144 , 0 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_157 [ V_21 ] = 0x00 ;
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_157 [ V_21 ] = V_37 [ V_21 + V_59 + 8 + V_151 ] ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , V_157 , V_155 ) ;
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_37 [ V_154 ++ ] = V_155 [ V_21 ] ;
return V_109 ;
}
T_2 F_52 ( struct V_30 * V_31 , T_1 * V_32 )
{
T_3 V_34 , V_35 ;
T_2 V_103 ;
T_1 * V_37 , * V_104 ;
struct V_107 * V_108 ;
struct V_41 * V_42 = & ( (struct V_43 * )
V_32 ) -> V_44 ;
struct V_48 * V_49 = & V_31 -> V_50 ;
T_2 V_73 = V_109 ;
if ( ( (struct V_43 * ) V_32 ) -> V_51 == NULL )
return V_110 ;
V_37 = ( (struct V_43 * ) V_32 ) -> V_51 + V_52 ;
if ( ( V_42 -> V_53 == V_166 ) ) {
if ( V_42 -> V_112 )
V_108 = V_42 -> V_112 ;
else
V_108 = F_32 ( & V_31 -> V_113 ,
& V_42 -> V_114 [ 0 ] ) ;
if ( V_108 != NULL ) {
V_104 = & V_108 -> V_115 . V_61 [ 0 ] ;
V_103 = 16 ;
for ( V_34 = 0 ; V_34 < V_42 -> V_58 ;
V_34 ++ ) {
if ( ( V_34 + 1 ) == V_42 -> V_58 ) {\
V_35 = V_42 -> V_63 -
V_42 -> V_59 -
V_42 -> V_62 -
V_42 -> V_64 ;
F_49 ( V_104 , V_42 ->
V_59 , V_37 , V_35 ) ;
} else {
V_35 = V_49 -> V_65 -
V_42 -> V_59 -
V_42 -> V_62 -
V_42 -> V_64 ;
F_49 ( V_104 , V_42 ->
V_59 , V_37 , V_35 ) ;
V_37 += V_49 -> V_65 ;
V_37 = ( T_1 * ) F_9 ( ( V_66 ) ( V_37 ) ) ;
}
}
} else
V_73 = V_110 ;
}
return V_73 ;
}
static T_3 F_53 ( T_1 * V_3 , T_6 V_59 ,
T_1 * V_37 , T_6 V_151 )
{
static T_1 V_167 [ V_168 ] ;
T_6 V_140 , V_141 , V_18 , V_21 , V_152 ;
T_6 V_153 , V_154 ;
T_1 V_144 [ 6 ] ;
T_1 V_139 [ 16 ] ;
T_1 V_145 [ 16 ] ;
T_1 V_147 [ 16 ] ;
T_1 V_148 [ 16 ] ;
T_1 V_155 [ 16 ] ;
T_1 V_156 [ 16 ] ;
T_1 V_157 [ 16 ] ;
T_1 V_158 [ 8 ] ;
T_6 V_159 = F_50 ( V_37 ) ;
T_6 V_160 = F_51 ( V_37 ) ;
V_160 = V_160 >> 4 ;
memset ( ( void * ) V_139 , 0 , 16 ) ;
memset ( ( void * ) V_145 , 0 , 16 ) ;
memset ( ( void * ) V_147 , 0 , 16 ) ;
memset ( ( void * ) V_148 , 0 , 16 ) ;
memset ( ( void * ) V_155 , 0 , 16 ) ;
memset ( ( void * ) V_156 , 0 , 16 ) ;
memset ( ( void * ) V_157 , 0 , 16 ) ;
V_153 = ( V_151 - 8 ) / 16 ;
V_152 = ( V_151 - 8 ) % 16 ;
V_144 [ 0 ] = V_37 [ V_59 ] ;
V_144 [ 1 ] = V_37 [ V_59 + 1 ] ;
V_144 [ 2 ] = V_37 [ V_59 + 4 ] ;
V_144 [ 3 ] = V_37 [ V_59 + 5 ] ;
V_144 [ 4 ] = V_37 [ V_59 + 6 ] ;
V_144 [ 5 ] = V_37 [ V_59 + 7 ] ;
if ( ( V_59 == V_161 ) || ( V_59 == V_162 ) )
V_141 = 0 ;
else
V_141 = 1 ;
if ( ( V_159 == V_163 ) ||
( V_159 == V_164 ) ||
( V_159 == V_165 ) ) {
V_140 = 1 ;
if ( V_59 != V_162 )
V_59 += 2 ;
} else if ( ( V_160 == 0x08 ) ||
( V_160 == 0x09 ) ||
( V_160 == 0x0a ) ||
( V_160 == 0x0b ) ) {
if ( V_59 != V_162 )
V_59 += 2 ;
V_140 = 1 ;
} else
V_140 = 0 ;
V_154 = V_59 + 8 ;
for ( V_18 = 0 ; V_18 < V_153 ; V_18 ++ ) {
F_47 ( V_148 , V_141 , V_140 ,
V_37 , V_144 , V_18 + 1 ) ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , & V_37 [ V_154 ] , V_155 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_37 [ V_154 ++ ] = V_155 [ V_21 ] ;
}
if ( V_152 > 0 ) {
F_47 ( V_148 , V_141 , V_140 ,
V_37 , V_144 , V_153 + 1 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_157 [ V_21 ] = 0x00 ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_157 [ V_21 ] = V_37 [ V_154 + V_21 ] ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , V_157 , V_155 ) ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_37 [ V_154 ++ ] = V_155 [ V_21 ] ;
}
memcpy ( ( void * ) V_167 , V_37 , ( V_59 + V_151 + 8 ) ) ;
V_144 [ 0 ] = V_37 [ V_59 ] ;
V_144 [ 1 ] = V_37 [ V_59 + 1 ] ;
V_144 [ 2 ] = V_37 [ V_59 + 4 ] ;
V_144 [ 3 ] = V_37 [ V_59 + 5 ] ;
V_144 [ 4 ] = V_37 [ V_59 + 6 ] ;
V_144 [ 5 ] = V_37 [ V_59 + 7 ] ;
F_44 ( V_139 , V_140 , V_141 , V_167 , V_151 - 8 ,
V_144 ) ;
F_45 ( V_145 , V_59 , V_167 ) ;
F_46 ( V_147 , V_167 , V_141 , V_140 ) ;
V_152 = ( V_151 - 8 ) % 16 ;
V_153 = ( V_151 - 8 ) / 16 ;
V_154 = ( V_59 + 8 ) ;
F_43 ( V_3 , V_139 , V_156 ) ;
F_48 ( V_156 , V_145 , V_155 ) ;
F_43 ( V_3 , V_155 , V_156 ) ;
F_48 ( V_156 , V_147 , V_155 ) ;
F_43 ( V_3 , V_155 , V_156 ) ;
for ( V_18 = 0 ; V_18 < V_153 ; V_18 ++ ) {
F_48 ( V_156 , & V_167 [ V_154 ] , V_155 ) ;
V_154 += 16 ;
F_43 ( V_3 , V_155 , V_156 ) ;
}
if ( V_152 > 0 ) {
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_157 [ V_21 ] = 0x00 ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_157 [ V_21 ] = V_167 [ V_154 ++ ] ;
F_48 ( V_156 , V_157 , V_155 ) ;
F_43 ( V_3 , V_155 , V_156 ) ;
}
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_158 [ V_21 ] = V_156 [ V_21 ] ;
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_167 [ V_154 + V_21 ] = V_158 [ V_21 ] ;
V_154 = V_59 + 8 ;
for ( V_18 = 0 ; V_18 < V_153 ; V_18 ++ ) {
F_47 ( V_148 , V_141 , V_140 ,
V_167 , V_144 , V_18 + 1 ) ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , & V_167 [ V_154 ] , V_155 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_167 [ V_154 ++ ] = V_155 [ V_21 ] ;
}
if ( V_152 > 0 ) {
F_47 ( V_148 , V_141 , V_140 ,
V_167 , V_144 , V_153 + 1 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_157 [ V_21 ] = 0x00 ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_157 [ V_21 ] = V_167 [ V_154 + V_21 ] ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , V_157 , V_155 ) ;
for ( V_21 = 0 ; V_21 < V_152 ; V_21 ++ )
V_167 [ V_154 ++ ] = V_155 [ V_21 ] ;
}
F_47 ( V_148 , V_141 , V_140 , V_167 ,
V_144 , 0 ) ;
for ( V_21 = 0 ; V_21 < 16 ; V_21 ++ )
V_157 [ V_21 ] = 0x00 ;
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_157 [ V_21 ] = V_167 [ V_21 + V_59 + V_151 ] ;
F_43 ( V_3 , V_148 , V_156 ) ;
F_48 ( V_156 , V_157 , V_155 ) ;
for ( V_21 = 0 ; V_21 < 8 ; V_21 ++ )
V_167 [ V_154 ++ ] = V_155 [ V_21 ] ;
return V_109 ;
}
T_2 F_54 ( struct V_30 * V_31 , T_1 * V_67 )
{
T_3 V_35 ;
T_2 V_103 ;
T_1 * V_37 , * V_104 , * V_39 , V_116 ;
struct V_107 * V_108 ;
struct V_68 * V_69 = & ( (union V_70 * )
V_67 ) -> V_6 . V_71 . V_44 ;
struct V_45 * V_46 = & V_31 -> V_47 ;
V_37 = ( unsigned char * ) ( (union V_70 * ) V_67 ) ->
V_6 . V_71 . V_72 ;
if ( ( V_69 -> V_53 == V_166 ) ) {
V_108 = F_32 ( & V_31 -> V_113 ,
& V_69 -> V_94 [ 0 ] ) ;
if ( V_108 != NULL ) {
if ( F_35 ( V_69 -> V_114 ) ) {
V_39 = V_37 + V_69 -> V_59 ;
V_116 = V_39 [ 3 ] ;
V_104 = & V_46 -> V_117 [
( ( V_116 >> 6 ) & 0x3 ) - 1 ] . V_61 [ 0 ] ;
if ( V_46 -> V_118 == false )
return V_110 ;
} else
V_104 = & V_108 -> V_115 . V_61 [ 0 ] ;
V_103 = 16 ;
V_35 = ( (union V_70 * ) V_67 ) ->
V_6 . V_71 . V_17 - V_69 -> V_59 - V_69 -> V_62 ;
F_53 ( V_104 , V_69 -> V_59 , V_37 ,
V_35 ) ;
} else
return V_110 ;
}
return V_109 ;
}
void F_55 ( void * V_169 )
{
struct V_30 * V_31 = (struct V_30 * ) V_169 ;
V_31 -> V_47 . V_170 = true ;
}
