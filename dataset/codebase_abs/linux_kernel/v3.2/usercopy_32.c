static inline int F_1 ( unsigned long V_1 , unsigned long V_2 , unsigned long V_3 )\r\n{\r\n#ifdef F_2\r\nif ( V_3 >= 64 && ( ( V_1 ^ V_2 ) & V_4 . V_5 ) )\r\nreturn 0 ;\r\n#endif\r\nreturn 1 ;\r\n}\r\nlong\r\nF_3 ( char * V_6 , const char T_1 * V_7 , long V_8 )\r\n{\r\nlong V_9 ;\r\nF_4 ( V_6 , V_7 , V_8 , V_9 ) ;\r\nreturn V_9 ;\r\n}\r\nlong\r\nF_5 ( char * V_6 , const char T_1 * V_7 , long V_8 )\r\n{\r\nlong V_9 = - V_10 ;\r\nif ( F_6 ( V_11 , V_7 , 1 ) )\r\nF_4 ( V_6 , V_7 , V_8 , V_9 ) ;\r\nreturn V_9 ;\r\n}\r\nunsigned long\r\nF_7 ( void T_1 * V_12 , unsigned long V_3 )\r\n{\r\nF_8 () ;\r\nif ( F_6 ( V_13 , V_12 , V_3 ) )\r\nF_9 ( V_12 , V_3 ) ;\r\nreturn V_3 ;\r\n}\r\nunsigned long\r\nF_10 ( void T_1 * V_12 , unsigned long V_3 )\r\n{\r\nF_9 ( V_12 , V_3 ) ;\r\nreturn V_3 ;\r\n}\r\nlong F_11 ( const char T_1 * V_14 , long V_3 )\r\n{\r\nunsigned long V_5 = - F_12 ( V_14 ) ;\r\nunsigned long V_9 , V_15 ;\r\nF_8 () ;\r\n__asm__ __volatile__(\r\n" testl %0, %0\n"\r\n" jz 3f\n"\r\n" andl %0,%%ecx\n"\r\n"0: repne; scasb\n"\r\n" setne %%al\n"\r\n" subl %%ecx,%0\n"\r\n" addl %0,%%eax\n"\r\n"1:\n"\r\n".section .fixup,\"ax\"\n"\r\n"2: xorl %%eax,%%eax\n"\r\n" jmp 1b\n"\r\n"3: movb $1,%%al\n"\r\n" jmp 1b\n"\r\n".previous\n"\r\n".section __ex_table,\"a\"\n"\r\n" .align 4\n"\r\n" .long 0b,2b\n"\r\n".previous"\r\n:"=&r" (n), "=&D" (s), "=&a" (res), "=&c" (tmp)\r\n:"0" (n), "1" (s), "2" (0), "3" (mask)\r\n:"cc");\r\nreturn V_9 & V_5 ;\r\n}\r\nstatic unsigned long\r\nF_13 ( void T_1 * V_12 , const void * V_16 , unsigned long V_17 )\r\n{\r\nint V_18 , V_19 ;\r\n__asm__ __volatile__(\r\n" .align 2,0x90\n"\r\n"1: movl 32(%4), %%eax\n"\r\n" cmpl $67, %0\n"\r\n" jbe 3f\n"\r\n"2: movl 64(%4), %%eax\n"\r\n" .align 2,0x90\n"\r\n"3: movl 0(%4), %%eax\n"\r\n"4: movl 4(%4), %%edx\n"\r\n"5: movl %%eax, 0(%3)\n"\r\n"6: movl %%edx, 4(%3)\n"\r\n"7: movl 8(%4), %%eax\n"\r\n"8: movl 12(%4),%%edx\n"\r\n"9: movl %%eax, 8(%3)\n"\r\n"10: movl %%edx, 12(%3)\n"\r\n"11: movl 16(%4), %%eax\n"\r\n"12: movl 20(%4), %%edx\n"\r\n"13: movl %%eax, 16(%3)\n"\r\n"14: movl %%edx, 20(%3)\n"\r\n"15: movl 24(%4), %%eax\n"\r\n"16: movl 28(%4), %%edx\n"\r\n"17: movl %%eax, 24(%3)\n"\r\n"18: movl %%edx, 28(%3)\n"\r\n"19: movl 32(%4), %%eax\n"\r\n"20: movl 36(%4), %%edx\n"\r\n"21: movl %%eax, 32(%3)\n"\r\n"22: movl %%edx, 36(%3)\n"\r\n"23: movl 40(%4), %%eax\n"\r\n"24: movl 44(%4), %%edx\n"\r\n"25: movl %%eax, 40(%3)\n"\r\n"26: movl %%edx, 44(%3)\n"\r\n"27: movl 48(%4), %%eax\n"\r\n"28: movl 52(%4), %%edx\n"\r\n"29: movl %%eax, 48(%3)\n"\r\n"30: movl %%edx, 52(%3)\n"\r\n"31: movl 56(%4), %%eax\n"\r\n"32: movl 60(%4), %%edx\n"\r\n"33: movl %%eax, 56(%3)\n"\r\n"34: movl %%edx, 60(%3)\n"\r\n" addl $-64, %0\n"\r\n" addl $64, %4\n"\r\n" addl $64, %3\n"\r\n" cmpl $63, %0\n"\r\n" ja 1b\n"\r\n"35: movl %0, %%eax\n"\r\n" shrl $2, %0\n"\r\n" andl $3, %%eax\n"\r\n" cld\n"\r\n"99: rep; movsl\n"\r\n"36: movl %%eax, %0\n"\r\n"37: rep; movsb\n"\r\n"100:\n"\r\n".section .fixup,\"ax\"\n"\r\n"101: lea 0(%%eax,%0,4),%0\n"\r\n" jmp 100b\n"\r\n".previous\n"\r\n".section __ex_table,\"a\"\n"\r\n" .align 4\n"\r\n" .long 1b,100b\n"\r\n" .long 2b,100b\n"\r\n" .long 3b,100b\n"\r\n" .long 4b,100b\n"\r\n" .long 5b,100b\n"\r\n" .long 6b,100b\n"\r\n" .long 7b,100b\n"\r\n" .long 8b,100b\n"\r\n" .long 9b,100b\n"\r\n" .long 10b,100b\n"\r\n" .long 11b,100b\n"\r\n" .long 12b,100b\n"\r\n" .long 13b,100b\n"\r\n" .long 14b,100b\n"\r\n" .long 15b,100b\n"\r\n" .long 16b,100b\n"\r\n" .long 17b,100b\n"\r\n" .long 18b,100b\n"\r\n" .long 19b,100b\n"\r\n" .long 20b,100b\n"\r\n" .long 21b,100b\n"\r\n" .long 22b,100b\n"\r\n" .long 23b,100b\n"\r\n" .long 24b,100b\n"\r\n" .long 25b,100b\n"\r\n" .long 26b,100b\n"\r\n" .long 27b,100b\n"\r\n" .long 28b,100b\n"\r\n" .long 29b,100b\n"\r\n" .long 30b,100b\n"\r\n" .long 31b,100b\n"\r\n" .long 32b,100b\n"\r\n" .long 33b,100b\n"\r\n" .long 34b,100b\n"\r\n" .long 35b,100b\n"\r\n" .long 36b,100b\n"\r\n" .long 37b,100b\n"\r\n" .long 99b,101b\n"\r\n".previous"\r\n: "=&c"(size), "=&D" (d0), "=&S" (d1)\r\n: "1"(to), "2"(from), "0"(size)\r\n: "eax", "edx", "memory");\r\nreturn V_17 ;\r\n}\r\nstatic unsigned long\r\nF_14 ( void * V_12 , const void T_1 * V_16 , unsigned long V_17 )\r\n{\r\nint V_18 , V_19 ;\r\n__asm__ __volatile__(\r\n" .align 2,0x90\n"\r\n"0: movl 32(%4), %%eax\n"\r\n" cmpl $67, %0\n"\r\n" jbe 2f\n"\r\n"1: movl 64(%4), %%eax\n"\r\n" .align 2,0x90\n"\r\n"2: movl 0(%4), %%eax\n"\r\n"21: movl 4(%4), %%edx\n"\r\n" movl %%eax, 0(%3)\n"\r\n" movl %%edx, 4(%3)\n"\r\n"3: movl 8(%4), %%eax\n"\r\n"31: movl 12(%4),%%edx\n"\r\n" movl %%eax, 8(%3)\n"\r\n" movl %%edx, 12(%3)\n"\r\n"4: movl 16(%4), %%eax\n"\r\n"41: movl 20(%4), %%edx\n"\r\n" movl %%eax, 16(%3)\n"\r\n" movl %%edx, 20(%3)\n"\r\n"10: movl 24(%4), %%eax\n"\r\n"51: movl 28(%4), %%edx\n"\r\n" movl %%eax, 24(%3)\n"\r\n" movl %%edx, 28(%3)\n"\r\n"11: movl 32(%4), %%eax\n"\r\n"61: movl 36(%4), %%edx\n"\r\n" movl %%eax, 32(%3)\n"\r\n" movl %%edx, 36(%3)\n"\r\n"12: movl 40(%4), %%eax\n"\r\n"71: movl 44(%4), %%edx\n"\r\n" movl %%eax, 40(%3)\n"\r\n" movl %%edx, 44(%3)\n"\r\n"13: movl 48(%4), %%eax\n"\r\n"81: movl 52(%4), %%edx\n"\r\n" movl %%eax, 48(%3)\n"\r\n" movl %%edx, 52(%3)\n"\r\n"14: movl 56(%4), %%eax\n"\r\n"91: movl 60(%4), %%edx\n"\r\n" movl %%eax, 56(%3)\n"\r\n" movl %%edx, 60(%3)\n"\r\n" addl $-64, %0\n"\r\n" addl $64, %4\n"\r\n" addl $64, %3\n"\r\n" cmpl $63, %0\n"\r\n" ja 0b\n"\r\n"5: movl %0, %%eax\n"\r\n" shrl $2, %0\n"\r\n" andl $3, %%eax\n"\r\n" cld\n"\r\n"6: rep; movsl\n"\r\n" movl %%eax,%0\n"\r\n"7: rep; movsb\n"\r\n"8:\n"\r\n".section .fixup,\"ax\"\n"\r\n"9: lea 0(%%eax,%0,4),%0\n"\r\n"16: pushl %0\n"\r\n" pushl %%eax\n"\r\n" xorl %%eax,%%eax\n"\r\n" rep; stosb\n"\r\n" popl %%eax\n"\r\n" popl %0\n"\r\n" jmp 8b\n"\r\n".previous\n"\r\n".section __ex_table,\"a\"\n"\r\n" .align 4\n"\r\n" .long 0b,16b\n"\r\n" .long 1b,16b\n"\r\n" .long 2b,16b\n"\r\n" .long 21b,16b\n"\r\n" .long 3b,16b\n"\r\n" .long 31b,16b\n"\r\n" .long 4b,16b\n"\r\n" .long 41b,16b\n"\r\n" .long 10b,16b\n"\r\n" .long 51b,16b\n"\r\n" .long 11b,16b\n"\r\n" .long 61b,16b\n"\r\n" .long 12b,16b\n"\r\n" .long 71b,16b\n"\r\n" .long 13b,16b\n"\r\n" .long 81b,16b\n"\r\n" .long 14b,16b\n"\r\n" .long 91b,16b\n"\r\n" .long 6b,9b\n"\r\n" .long 7b,16b\n"\r\n".previous"\r\n: "=&c"(size), "=&D" (d0), "=&S" (d1)\r\n: "1"(to), "2"(from), "0"(size)\r\n: "eax", "edx", "memory");\r\nreturn V_17 ;\r\n}\r\nstatic unsigned long F_15 ( void * V_12 ,\r\nconst void T_1 * V_16 , unsigned long V_17 )\r\n{\r\nint V_18 , V_19 ;\r\n__asm__ __volatile__(\r\n" .align 2,0x90\n"\r\n"0: movl 32(%4), %%eax\n"\r\n" cmpl $67, %0\n"\r\n" jbe 2f\n"\r\n"1: movl 64(%4), %%eax\n"\r\n" .align 2,0x90\n"\r\n"2: movl 0(%4), %%eax\n"\r\n"21: movl 4(%4), %%edx\n"\r\n" movnti %%eax, 0(%3)\n"\r\n" movnti %%edx, 4(%3)\n"\r\n"3: movl 8(%4), %%eax\n"\r\n"31: movl 12(%4),%%edx\n"\r\n" movnti %%eax, 8(%3)\n"\r\n" movnti %%edx, 12(%3)\n"\r\n"4: movl 16(%4), %%eax\n"\r\n"41: movl 20(%4), %%edx\n"\r\n" movnti %%eax, 16(%3)\n"\r\n" movnti %%edx, 20(%3)\n"\r\n"10: movl 24(%4), %%eax\n"\r\n"51: movl 28(%4), %%edx\n"\r\n" movnti %%eax, 24(%3)\n"\r\n" movnti %%edx, 28(%3)\n"\r\n"11: movl 32(%4), %%eax\n"\r\n"61: movl 36(%4), %%edx\n"\r\n" movnti %%eax, 32(%3)\n"\r\n" movnti %%edx, 36(%3)\n"\r\n"12: movl 40(%4), %%eax\n"\r\n"71: movl 44(%4), %%edx\n"\r\n" movnti %%eax, 40(%3)\n"\r\n" movnti %%edx, 44(%3)\n"\r\n"13: movl 48(%4), %%eax\n"\r\n"81: movl 52(%4), %%edx\n"\r\n" movnti %%eax, 48(%3)\n"\r\n" movnti %%edx, 52(%3)\n"\r\n"14: movl 56(%4), %%eax\n"\r\n"91: movl 60(%4), %%edx\n"\r\n" movnti %%eax, 56(%3)\n"\r\n" movnti %%edx, 60(%3)\n"\r\n" addl $-64, %0\n"\r\n" addl $64, %4\n"\r\n" addl $64, %3\n"\r\n" cmpl $63, %0\n"\r\n" ja 0b\n"\r\n" sfence \n"\r\n"5: movl %0, %%eax\n"\r\n" shrl $2, %0\n"\r\n" andl $3, %%eax\n"\r\n" cld\n"\r\n"6: rep; movsl\n"\r\n" movl %%eax,%0\n"\r\n"7: rep; movsb\n"\r\n"8:\n"\r\n".section .fixup,\"ax\"\n"\r\n"9: lea 0(%%eax,%0,4),%0\n"\r\n"16: pushl %0\n"\r\n" pushl %%eax\n"\r\n" xorl %%eax,%%eax\n"\r\n" rep; stosb\n"\r\n" popl %%eax\n"\r\n" popl %0\n"\r\n" jmp 8b\n"\r\n".previous\n"\r\n".section __ex_table,\"a\"\n"\r\n" .align 4\n"\r\n" .long 0b,16b\n"\r\n" .long 1b,16b\n"\r\n" .long 2b,16b\n"\r\n" .long 21b,16b\n"\r\n" .long 3b,16b\n"\r\n" .long 31b,16b\n"\r\n" .long 4b,16b\n"\r\n" .long 41b,16b\n"\r\n" .long 10b,16b\n"\r\n" .long 51b,16b\n"\r\n" .long 11b,16b\n"\r\n" .long 61b,16b\n"\r\n" .long 12b,16b\n"\r\n" .long 71b,16b\n"\r\n" .long 13b,16b\n"\r\n" .long 81b,16b\n"\r\n" .long 14b,16b\n"\r\n" .long 91b,16b\n"\r\n" .long 6b,9b\n"\r\n" .long 7b,16b\n"\r\n".previous"\r\n: "=&c"(size), "=&D" (d0), "=&S" (d1)\r\n: "1"(to), "2"(from), "0"(size)\r\n: "eax", "edx", "memory");\r\nreturn V_17 ;\r\n}\r\nstatic unsigned long F_16 ( void * V_12 ,\r\nconst void T_1 * V_16 , unsigned long V_17 )\r\n{\r\nint V_18 , V_19 ;\r\n__asm__ __volatile__(\r\n" .align 2,0x90\n"\r\n"0: movl 32(%4), %%eax\n"\r\n" cmpl $67, %0\n"\r\n" jbe 2f\n"\r\n"1: movl 64(%4), %%eax\n"\r\n" .align 2,0x90\n"\r\n"2: movl 0(%4), %%eax\n"\r\n"21: movl 4(%4), %%edx\n"\r\n" movnti %%eax, 0(%3)\n"\r\n" movnti %%edx, 4(%3)\n"\r\n"3: movl 8(%4), %%eax\n"\r\n"31: movl 12(%4),%%edx\n"\r\n" movnti %%eax, 8(%3)\n"\r\n" movnti %%edx, 12(%3)\n"\r\n"4: movl 16(%4), %%eax\n"\r\n"41: movl 20(%4), %%edx\n"\r\n" movnti %%eax, 16(%3)\n"\r\n" movnti %%edx, 20(%3)\n"\r\n"10: movl 24(%4), %%eax\n"\r\n"51: movl 28(%4), %%edx\n"\r\n" movnti %%eax, 24(%3)\n"\r\n" movnti %%edx, 28(%3)\n"\r\n"11: movl 32(%4), %%eax\n"\r\n"61: movl 36(%4), %%edx\n"\r\n" movnti %%eax, 32(%3)\n"\r\n" movnti %%edx, 36(%3)\n"\r\n"12: movl 40(%4), %%eax\n"\r\n"71: movl 44(%4), %%edx\n"\r\n" movnti %%eax, 40(%3)\n"\r\n" movnti %%edx, 44(%3)\n"\r\n"13: movl 48(%4), %%eax\n"\r\n"81: movl 52(%4), %%edx\n"\r\n" movnti %%eax, 48(%3)\n"\r\n" movnti %%edx, 52(%3)\n"\r\n"14: movl 56(%4), %%eax\n"\r\n"91: movl 60(%4), %%edx\n"\r\n" movnti %%eax, 56(%3)\n"\r\n" movnti %%edx, 60(%3)\n"\r\n" addl $-64, %0\n"\r\n" addl $64, %4\n"\r\n" addl $64, %3\n"\r\n" cmpl $63, %0\n"\r\n" ja 0b\n"\r\n" sfence \n"\r\n"5: movl %0, %%eax\n"\r\n" shrl $2, %0\n"\r\n" andl $3, %%eax\n"\r\n" cld\n"\r\n"6: rep; movsl\n"\r\n" movl %%eax,%0\n"\r\n"7: rep; movsb\n"\r\n"8:\n"\r\n".section .fixup,\"ax\"\n"\r\n"9: lea 0(%%eax,%0,4),%0\n"\r\n"16: jmp 8b\n"\r\n".previous\n"\r\n".section __ex_table,\"a\"\n"\r\n" .align 4\n"\r\n" .long 0b,16b\n"\r\n" .long 1b,16b\n"\r\n" .long 2b,16b\n"\r\n" .long 21b,16b\n"\r\n" .long 3b,16b\n"\r\n" .long 31b,16b\n"\r\n" .long 4b,16b\n"\r\n" .long 41b,16b\n"\r\n" .long 10b,16b\n"\r\n" .long 51b,16b\n"\r\n" .long 11b,16b\n"\r\n" .long 61b,16b\n"\r\n" .long 12b,16b\n"\r\n" .long 71b,16b\n"\r\n" .long 13b,16b\n"\r\n" .long 81b,16b\n"\r\n" .long 14b,16b\n"\r\n" .long 91b,16b\n"\r\n" .long 6b,9b\n"\r\n" .long 7b,16b\n"\r\n".previous"\r\n: "=&c"(size), "=&D" (d0), "=&S" (d1)\r\n: "1"(to), "2"(from), "0"(size)\r\n: "eax", "edx", "memory");\r\nreturn V_17 ;\r\n}\r\nunsigned long F_17 ( void T_1 * V_12 , const void * V_16 ,\r\nunsigned long V_3 )\r\n{\r\n#ifndef F_18\r\nif ( F_19 ( V_20 . V_21 == 0 ) &&\r\n( ( unsigned long ) V_12 ) < V_22 ) {\r\nif ( F_20 () )\r\nreturn V_3 ;\r\nwhile ( V_3 ) {\r\nunsigned long V_23 = ( ( unsigned long ) V_12 ) % V_24 ;\r\nunsigned long V_25 = V_24 - V_23 ;\r\nint V_26 ;\r\nstruct V_27 * V_28 ;\r\nvoid * V_29 ;\r\nif ( V_25 > V_3 )\r\nV_25 = V_3 ;\r\nV_30:\r\nF_21 ( & V_31 -> V_32 -> V_33 ) ;\r\nV_26 = F_22 ( V_31 , V_31 -> V_32 ,\r\n( unsigned long ) V_12 , 1 , 1 , 0 , & V_28 , NULL ) ;\r\nif ( V_26 == - V_34 && F_23 ( V_31 ) ) {\r\nF_24 ( & V_31 -> V_32 -> V_33 ) ;\r\nF_25 ( V_35 , V_36 / 50 ) ;\r\ngoto V_30;\r\n}\r\nif ( V_26 != 1 ) {\r\nF_24 ( & V_31 -> V_32 -> V_33 ) ;\r\nbreak;\r\n}\r\nV_29 = F_26 ( V_28 , V_37 ) ;\r\nmemcpy ( V_29 + V_23 , V_16 , V_25 ) ;\r\nF_27 ( V_29 , V_37 ) ;\r\nF_28 ( V_28 ) ;\r\nF_29 ( V_28 ) ;\r\nF_24 ( & V_31 -> V_32 -> V_33 ) ;\r\nV_16 += V_25 ;\r\nV_12 += V_25 ;\r\nV_3 -= V_25 ;\r\n}\r\nreturn V_3 ;\r\n}\r\n#endif\r\nif ( F_30 ( V_12 , V_16 , V_3 ) )\r\nF_31 ( V_12 , V_16 , V_3 ) ;\r\nelse\r\nV_3 = F_13 ( V_12 , V_16 , V_3 ) ;\r\nreturn V_3 ;\r\n}\r\nunsigned long F_32 ( void * V_12 , const void T_1 * V_16 ,\r\nunsigned long V_3 )\r\n{\r\nif ( F_30 ( V_12 , V_16 , V_3 ) )\r\nF_33 ( V_12 , V_16 , V_3 ) ;\r\nelse\r\nV_3 = F_14 ( V_12 , V_16 , V_3 ) ;\r\nreturn V_3 ;\r\n}\r\nunsigned long F_34 ( void * V_12 , const void T_1 * V_16 ,\r\nunsigned long V_3 )\r\n{\r\nif ( F_30 ( V_12 , V_16 , V_3 ) )\r\nF_31 ( V_12 , V_16 , V_3 ) ;\r\nelse\r\nV_3 = F_13 ( ( void T_1 * ) V_12 ,\r\n( const void * ) V_16 , V_3 ) ;\r\nreturn V_3 ;\r\n}\r\nunsigned long F_35 ( void * V_12 , const void T_1 * V_16 ,\r\nunsigned long V_3 )\r\n{\r\n#ifdef F_2\r\nif ( V_3 > 64 && V_38 )\r\nV_3 = F_15 ( V_12 , V_16 , V_3 ) ;\r\nelse\r\nF_33 ( V_12 , V_16 , V_3 ) ;\r\n#else\r\nF_33 ( V_12 , V_16 , V_3 ) ;\r\n#endif\r\nreturn V_3 ;\r\n}\r\nunsigned long F_36 ( void * V_12 , const void T_1 * V_16 ,\r\nunsigned long V_3 )\r\n{\r\n#ifdef F_2\r\nif ( V_3 > 64 && V_38 )\r\nV_3 = F_16 ( V_12 , V_16 , V_3 ) ;\r\nelse\r\nF_31 ( V_12 , V_16 , V_3 ) ;\r\n#else\r\nF_31 ( V_12 , V_16 , V_3 ) ;\r\n#endif\r\nreturn V_3 ;\r\n}\r\nunsigned long\r\nF_37 ( void T_1 * V_12 , const void * V_16 , unsigned long V_3 )\r\n{\r\nif ( F_6 ( V_13 , V_12 , V_3 ) )\r\nV_3 = F_38 ( V_12 , V_16 , V_3 ) ;\r\nreturn V_3 ;\r\n}\r\nunsigned long\r\nF_39 ( void * V_12 , const void T_1 * V_16 , unsigned long V_3 )\r\n{\r\nif ( F_6 ( V_11 , V_16 , V_3 ) )\r\nV_3 = F_40 ( V_12 , V_16 , V_3 ) ;\r\nelse\r\nmemset ( V_12 , 0 , V_3 ) ;\r\nreturn V_3 ;\r\n}\r\nvoid F_41 ( void )\r\n{\r\nF_42 ( 1 , L_1 ) ;\r\n}
