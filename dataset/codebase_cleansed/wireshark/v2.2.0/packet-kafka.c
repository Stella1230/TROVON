static guint\r\nget_kafka_pdu_len(packet_info *pinfo _U_, tvbuff_t *tvb, int offset, void *data _U_)\r\n{\r\nreturn 4 + tvb_get_ntohl(tvb, offset);\r\n}\r\nstatic int\r\ndissect_kafka_array(proto_tree *tree, tvbuff_t *tvb, packet_info *pinfo, int offset,\r\nint(*func)(tvbuff_t*, packet_info*, proto_tree*, int))\r\n{\r\ngint32 count, i;\r\ncount = (gint32) tvb_get_ntohl(tvb, offset);\r\nproto_tree_add_item(tree, hf_kafka_array_count, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nfor (i=0; i<count; i++) {\r\noffset = func(tvb, pinfo, tree, offset);\r\n}\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_string(proto_tree *tree, int hf_item, tvbuff_t *tvb, packet_info *pinfo, int offset,\r\nint *p_string_offset, int *p_string_len)\r\n{\r\ngint16 len;\r\nproto_item *pi;\r\nlen = (gint16) tvb_get_ntohs(tvb, offset);\r\npi = proto_tree_add_item(tree, hf_kafka_string_len, tvb, offset, 2, ENC_BIG_ENDIAN);\r\noffset += 2;\r\nif (p_string_offset != NULL) *p_string_offset = offset;\r\nif (len < -1) {\r\nexpert_add_info(pinfo, pi, &ei_kafka_bad_string_length);\r\n}\r\nelse if (len == -1) {\r\nproto_tree_add_string(tree, hf_item, tvb, offset, 0, NULL);\r\n}\r\nelse {\r\nproto_tree_add_item(tree, hf_item, tvb, offset, len, ENC_NA|ENC_ASCII);\r\noffset += len;\r\n}\r\nif (p_string_len != NULL) *p_string_len = len;\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_bytes(proto_tree *tree, int hf_item, tvbuff_t *tvb, packet_info *pinfo, int offset,\r\nint *p_string_offset, int *p_string_len)\r\n{\r\ngint32 len;\r\nproto_item *pi;\r\nlen = (gint32) tvb_get_ntohl(tvb, offset);\r\npi = proto_tree_add_item(tree, hf_kafka_bytes_len, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nif (p_string_offset != NULL) *p_string_offset = offset;\r\nif (len < -1) {\r\nexpert_add_info(pinfo, pi, &ei_kafka_bad_bytes_length);\r\n}\r\nelse if (len == -1) {\r\nproto_tree_add_bytes(tree, hf_item, tvb, offset, 0, NULL);\r\n}\r\nelse {\r\nproto_tree_add_item(tree, hf_item, tvb, offset, len, ENC_NA);\r\noffset += len;\r\n}\r\nif (p_string_len != NULL) *p_string_len = len;\r\nreturn offset;\r\n}\r\nstatic tvbuff_t *\r\nkafka_get_bytes(proto_tree *tree, tvbuff_t *tvb, packet_info *pinfo, int offset)\r\n{\r\ngint32 len;\r\nproto_item *pi;\r\nlen = (gint32) tvb_get_ntohl(tvb, offset);\r\npi = proto_tree_add_item(tree, hf_kafka_bytes_len, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nif (len < -1) {\r\nexpert_add_info(pinfo, pi, &ei_kafka_bad_bytes_length);\r\nreturn NULL;\r\n}\r\nelse if (len == -1) {\r\nreturn NULL;\r\n}\r\nelse {\r\nreturn tvb_new_subset_length(tvb, offset, len);\r\n}\r\n}\r\nstatic int\r\ndissect_kafka_message(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti, *decrypt_item;\r\nproto_tree *subtree;\r\ntvbuff_t *raw, *payload;\r\nint offset = start_offset;\r\nguint8 codec;\r\nguint bytes_length = 0;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_message, &ti, "Message");\r\nproto_tree_add_item(subtree, hf_kafka_message_crc, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nproto_tree_add_item(subtree, hf_kafka_message_magic, tvb, offset, 1, ENC_BIG_ENDIAN);\r\noffset += 1;\r\nproto_tree_add_item(subtree, hf_kafka_message_codec, tvb, offset, 1, ENC_BIG_ENDIAN);\r\ncodec = tvb_get_guint8(tvb, offset) & 0x07;\r\noffset += 1;\r\noffset = dissect_kafka_bytes(subtree, hf_kafka_message_key, tvb, pinfo, offset, NULL, &bytes_length);\r\nswitch (codec) {\r\ncase KAFKA_COMPRESSION_GZIP:\r\nraw = kafka_get_bytes(tree, tvb, pinfo, offset);\r\noffset += 4;\r\nif (raw) {\r\npayload = tvb_child_uncompress(tvb, raw, 0, tvb_captured_length(raw));\r\nif (payload) {\r\nadd_new_data_source(pinfo, payload, "Uncompressed Message");\r\ndissect_kafka_message_set(payload, pinfo, subtree, 0, FALSE);\r\n} else {\r\ndecrypt_item = proto_tree_add_item(subtree, hf_kafka_message_value, raw, 0, -1, ENC_NA);\r\nexpert_add_info(pinfo, decrypt_item, &ei_kafka_message_decompress);\r\n}\r\noffset += tvb_captured_length(raw);\r\n}\r\nelse {\r\nproto_tree_add_bytes(subtree, hf_kafka_message_value, tvb, offset, 0, NULL);\r\n}\r\ncol_append_fstr(pinfo->cinfo, COL_INFO, " [%u bytes GZIPd]", bytes_length);\r\nproto_item_append_text(ti, " (%u bytes GZIPd)", bytes_length);\r\nbreak;\r\ncase KAFKA_COMPRESSION_SNAPPY:\r\ncase KAFKA_COMPRESSION_NONE:\r\ndefault:\r\noffset = dissect_kafka_bytes(subtree, hf_kafka_message_value, tvb, pinfo, offset, NULL, &bytes_length);\r\ncol_append_fstr(pinfo->cinfo, COL_INFO, " [%u bytes]", bytes_length);\r\nproto_item_append_text(ti, " (%u bytes)", bytes_length);\r\n}\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_message_set(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset, gboolean has_length_field)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\ngint len;\r\nint offset = start_offset;\r\nint messages = 0;\r\nif (has_length_field) {\r\nproto_tree_add_item(tree, hf_kafka_message_set_size, tvb, offset, 4, ENC_BIG_ENDIAN);\r\nlen = (gint)tvb_get_ntohl(tvb, offset);\r\noffset += 4;\r\nstart_offset += 4;\r\n}\r\nelse {\r\nlen = tvb_reported_length_remaining(tvb, offset);\r\n}\r\nif (len <= 0) {\r\nreturn offset;\r\n}\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_message_set, &ti, "Message Set");\r\nwhile (offset - start_offset < len) {\r\nproto_tree_add_item(subtree, hf_kafka_offset, tvb, offset, 8, ENC_BIG_ENDIAN);\r\noffset += 8;\r\nproto_tree_add_item(subtree, hf_kafka_message_size, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\noffset = dissect_kafka_message(tvb, pinfo, subtree, offset);\r\nmessages += 1;\r\n}\r\nproto_item_append_text(ti, " (%d Messages)", messages);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_partition_id(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_partition_id, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_partition_id_get_value(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, kafka_packet_values_t* packet_values)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_partition_id, tvb, offset, 4, ENC_BIG_ENDIAN);\r\nif (packet_values != NULL) {\r\npacket_values->partition_id = tvb_get_ntohl(tvb, offset);\r\n}\r\noffset += 4;\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_get_value(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, kafka_packet_values_t* packet_values)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_offset, tvb, offset, 8, ENC_BIG_ENDIAN);\r\nif (packet_values != NULL) {\r\npacket_values->offset = tvb_get_ntoh64(tvb, offset);\r\n}\r\noffset += 8;\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_offset, tvb, offset, 8, ENC_BIG_ENDIAN);\r\noffset += 8;\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_fetch_request_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nguint32 count;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_request_topic, &ti, "Offset Fetch Request Topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\ncount = (gint32)tvb_get_ntohl(tvb, offset);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_partition_id);\r\nproto_item_set_len(ti, offset - start_offset);\r\nproto_item_append_text(ti, " (%u partitions)", count);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_fetch_request(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\noffset = dissect_kafka_string(tree, hf_kafka_consumer_group, tvb, pinfo, offset, NULL, NULL);\r\noffset = dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_offset_fetch_request_topic);\r\nreturn offset;\r\n}\r\nstatic int dissect_kafka_error(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nguint16 error = tvb_get_ntohs(tvb, offset);\r\nproto_tree_add_item(tree, hf_kafka_error, tvb, offset, 2, ENC_BIG_ENDIAN);\r\nif (error != 0) {\r\ncol_append_fstr(pinfo->cinfo, COL_INFO,\r\n" [%s] ", val_to_str_const(error, kafka_errors, "Unknown"));\r\n}\r\noffset += 2;\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_fetch_response_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nkafka_packet_values_t packet_values;\r\nmemset(&packet_values, 0, sizeof(packet_values));\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_request_partition, &ti, "Offset Fetch Response Partition");\r\noffset = dissect_kafka_partition_id_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\noffset = dissect_kafka_offset(tvb, pinfo, subtree, offset);\r\noffset = dissect_kafka_string(subtree, hf_kafka_metadata, tvb, pinfo, offset, NULL, NULL);\r\noffset = dissect_kafka_error(tvb, pinfo, subtree, offset);\r\nproto_item_append_text(ti, " (Partition-ID=%u, Offset=%" G_GINT64_MODIFIER "u)",\r\npacket_values.partition_id, packet_values.offset);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_fetch_response_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_topic, &ti, "offset fetch response topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_offset_fetch_response_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_fetch_response(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\nreturn dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_offset_fetch_response_topic);\r\n}\r\nstatic int\r\ndissect_kafka_metadata_request_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\nreturn dissect_kafka_string(tree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\n}\r\nstatic int\r\ndissect_kafka_metadata_request(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\nreturn dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_metadata_request_topic);\r\n}\r\nstatic int\r\ndissect_kafka_metadata_broker(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nguint32 nodeid;\r\nint host_start, host_len;\r\nguint32 broker_port;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, 14, ett_kafka_metadata_broker, &ti, "Broker");\r\nnodeid = tvb_get_ntohl(tvb, offset);\r\nproto_tree_add_item(subtree, hf_kafka_broker_nodeid, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\noffset = dissect_kafka_string(subtree, hf_kafka_broker_host, tvb, pinfo, offset, &host_start, &host_len);\r\nbroker_port = tvb_get_ntohl(tvb, offset);\r\nproto_tree_add_item(subtree, hf_kafka_broker_port, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nproto_item_append_text(ti, " (node %u: %s:%u)",\r\nnodeid,\r\ntvb_get_string_enc(wmem_packet_scope(), tvb,\r\nhost_start, host_len, ENC_UTF_8|ENC_NA),\r\nbroker_port);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_metadata_replica(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_replica, tvb, offset, 4, ENC_BIG_ENDIAN);\r\nreturn offset + 4;\r\n}\r\nstatic int\r\ndissect_kafka_metadata_isr(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_isr, tvb, offset, 4, ENC_BIG_ENDIAN);\r\nreturn offset + 4;\r\n}\r\nstatic int\r\ndissect_kafka_metadata_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti, *subti;\r\nproto_tree *subtree, *subsubtree;\r\nint offset = start_offset;\r\nint sub_start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_partition, &ti, "Partition");\r\noffset = dissect_kafka_error(tvb, pinfo, subtree, offset);\r\noffset = dissect_kafka_partition_id(tvb, pinfo, subtree, offset);\r\nproto_tree_add_item(subtree, hf_kafka_partition_leader, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nsub_start_offset = offset;\r\nsubsubtree = proto_tree_add_subtree(subtree, tvb, offset, -1, ett_kafka_metadata_replicas, &subti, "Replicas");\r\noffset = dissect_kafka_array(subsubtree, tvb, pinfo, offset, &dissect_kafka_metadata_replica);\r\nproto_item_set_len(subti, offset - sub_start_offset);\r\nsub_start_offset = offset;\r\nsubsubtree = proto_tree_add_subtree(subtree, tvb, offset, -1, ett_kafka_metadata_isr, &subti, "Caught-Up Replicas");\r\noffset = dissect_kafka_array(subsubtree, tvb, pinfo, offset, &dissect_kafka_metadata_isr);\r\nproto_item_set_len(subti, offset - sub_start_offset);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_metadata_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nint name_start, name_length;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_topic, &ti, "Topic");\r\noffset = dissect_kafka_error(tvb, pinfo, subtree, offset);\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, &name_start, &name_length);\r\nproto_item_append_text(ti, " (%s)",\r\ntvb_get_string_enc(wmem_packet_scope(), tvb,\r\nname_start, name_length, ENC_UTF_8|ENC_NA));\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_metadata_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_metadata_response(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_metadata_brokers, &ti, "Broker Metadata");\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_metadata_broker);\r\nproto_item_set_len(ti, offset - start_offset);\r\nstart_offset = offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_metadata_topics, &ti, "Topic Metadata");\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_metadata_topic);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_fetch_request_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nkafka_packet_values_t packet_values;\r\nmemset(&packet_values, 0, sizeof(packet_values));\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, 16, ett_kafka_request_partition, &ti, "Fetch Request Partition");\r\noffset = dissect_kafka_partition_id_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\noffset = dissect_kafka_offset_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\nproto_tree_add_item(subtree, hf_kafka_max_bytes, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nproto_item_append_text(ti, " (Partition-ID=%u, Offset=%" G_GINT64_MODIFIER "u)",\r\npacket_values.partition_id, packet_values.offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_fetch_request_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nguint32 count;\r\nint name_start, name_length;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_request_topic, &ti, "Fetch Request Topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, &name_start, &name_length);\r\ncount = tvb_get_ntohl(tvb, offset);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_fetch_request_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nproto_item_append_text(ti, " (%u partitions)", count);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_fetch_request(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_replica, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nproto_tree_add_item(tree, hf_kafka_max_wait_time, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nproto_tree_add_item(tree, hf_kafka_min_bytes, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\noffset = dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_fetch_request_topic);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_fetch_response_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nkafka_packet_values_t packet_values;\r\nmemset(&packet_values, 0, sizeof(packet_values));\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_partition, &ti, "Fetch Response Partition");\r\noffset = dissect_kafka_partition_id_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\noffset = dissect_kafka_error(tvb, pinfo, subtree, offset);\r\noffset = dissect_kafka_offset_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\noffset = dissect_kafka_message_set(tvb, pinfo, subtree, offset, TRUE);\r\nproto_item_set_len(ti, offset - start_offset);\r\nproto_item_append_text(ti, " (Partition-ID=%u, Offset=%" G_GINT64_MODIFIER "u)",\r\npacket_values.partition_id, packet_values.offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_fetch_response_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nguint32 count;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_topic, &ti, "Fetch Response Topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\ncount = tvb_get_ntohl(tvb, offset);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_fetch_response_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nproto_item_append_text(ti, " (%u partitions)", count);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_fetch_response(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset, guint16 api_version)\r\n{\r\nif (api_version > 0) {\r\nproto_tree_add_item(tree, hf_kafka_throttle_time, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\n}\r\nreturn dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_fetch_response_topic);\r\n}\r\nstatic int\r\ndissect_kafka_produce_request_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nkafka_packet_values_t packet_values;\r\nmemset(&packet_values, 0, sizeof(packet_values));\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, 14, ett_kafka_request_partition, &ti, "Produce Request Partition");\r\noffset = dissect_kafka_partition_id_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\noffset = dissect_kafka_message_set(tvb, pinfo, subtree, offset, TRUE);\r\nproto_item_append_text(ti, " (Partition-ID=%u)", packet_values.partition_id);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_produce_request_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_request_topic, &ti, "Produce Request Topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_produce_request_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_produce_request(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_required_acks, tvb, offset, 2, ENC_BIG_ENDIAN);\r\noffset += 2;\r\nproto_tree_add_item(tree, hf_kafka_timeout, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\noffset = dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_produce_request_topic);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_produce_response_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nkafka_packet_values_t packet_values;\r\nmemset(&packet_values, 0, sizeof(packet_values));\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, 14, ett_kafka_response_partition, &ti, "Produce Response Partition");\r\noffset = dissect_kafka_partition_id_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\noffset = dissect_kafka_error(tvb, pinfo, subtree, offset);\r\noffset = dissect_kafka_offset_get_value(tvb, pinfo, subtree, offset, &packet_values);\r\nproto_item_append_text(ti, " (Partition-ID=%u, Offset=%" G_GINT64_MODIFIER "u)",\r\npacket_values.partition_id, packet_values.offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_produce_response_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_topic, &ti, "Produce Response Topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_produce_response_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_produce_response(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset, guint16 api_version)\r\n{\r\noffset = dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_produce_response_topic);\r\nif (api_version > 0) {\r\nproto_tree_add_item(tree, hf_kafka_throttle_time, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\n}\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_request_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, 16, ett_kafka_request_partition, &ti, "Offset Request Partition");\r\noffset = dissect_kafka_partition_id(tvb, pinfo, subtree, offset);\r\nproto_tree_add_item(subtree, hf_kafka_offset_time, tvb, offset, 8, ENC_BIG_ENDIAN);\r\noffset += 8;\r\nproto_tree_add_item(subtree, hf_kafka_max_offsets, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_request_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_request_topic, &ti, "Offset Request Topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_offset_request_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_request(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\nproto_tree_add_item(tree, hf_kafka_replica, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\noffset = dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_offset_request_topic);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_response_partition(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_partition, &ti, "Offset Response Partition");\r\noffset = dissect_kafka_partition_id(tvb, pinfo, subtree, offset);\r\noffset = dissect_kafka_error(tvb, pinfo, subtree, offset);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_offset);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_response_topic(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int start_offset)\r\n{\r\nproto_item *ti;\r\nproto_tree *subtree;\r\nint offset = start_offset;\r\nsubtree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_kafka_response_topic, &ti, "Offset Response Topic");\r\noffset = dissect_kafka_string(subtree, hf_kafka_topic_name, tvb, pinfo, offset, NULL, NULL);\r\noffset = dissect_kafka_array(subtree, tvb, pinfo, offset, &dissect_kafka_offset_response_partition);\r\nproto_item_set_len(ti, offset - start_offset);\r\nreturn offset;\r\n}\r\nstatic int\r\ndissect_kafka_offset_response(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, int offset)\r\n{\r\nreturn dissect_kafka_array(tree, tvb, pinfo, offset, &dissect_kafka_offset_response_topic);\r\n}\r\nstatic int\r\ndissect_kafka(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, void* data _U_)\r\n{\r\nproto_item *root_ti, *ti;\r\nproto_tree *kafka_tree;\r\nint offset = 0;\r\nkafka_query_response_t *matcher = NULL;\r\nconversation_t *conversation;\r\nwmem_queue_t *match_queue;\r\ncol_set_str(pinfo->cinfo, COL_PROTOCOL, "Kafka");\r\ncol_clear(pinfo->cinfo, COL_INFO);\r\nroot_ti = proto_tree_add_item(tree, proto_kafka, tvb, 0, -1, ENC_NA);\r\nkafka_tree = proto_item_add_subtree(root_ti, ett_kafka);\r\nproto_tree_add_item(kafka_tree, hf_kafka_len, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nconversation = find_or_create_conversation(pinfo);\r\nmatch_queue = (wmem_queue_t *) conversation_get_proto_data(conversation, proto_kafka);\r\nif (match_queue == NULL) {\r\nmatch_queue = wmem_queue_new(wmem_file_scope());\r\nconversation_add_proto_data(conversation, proto_kafka, match_queue);\r\n}\r\nif (PINFO_FD_VISITED(pinfo)) {\r\nmatcher = (kafka_query_response_t *) p_get_proto_data(wmem_file_scope(), pinfo, proto_kafka, 0);\r\n}\r\nif (value_is_in_range(current_kafka_tcp_range, pinfo->destport)) {\r\nif (matcher == NULL) {\r\nmatcher = wmem_new(wmem_file_scope(), kafka_query_response_t);\r\nmatcher->api_key = tvb_get_ntohs(tvb, offset);\r\nmatcher->api_version = tvb_get_ntohs(tvb, offset+2);\r\nmatcher->request_frame = pinfo->num;\r\nmatcher->response_found = FALSE;\r\np_add_proto_data(wmem_file_scope(), pinfo, proto_kafka, 0, matcher);\r\nif (matcher->api_key != KAFKA_PRODUCE) {\r\nwmem_queue_push(match_queue, matcher);\r\n}\r\n}\r\ncol_add_fstr(pinfo->cinfo, COL_INFO, "Kafka %s Request",\r\nval_to_str_const(matcher->api_key, kafka_apis, "Unknown"));\r\nproto_item_append_text(root_ti, " (%s Request)",\r\nval_to_str_const(matcher->api_key, kafka_apis, "Unknown"));\r\nif (matcher->response_found) {\r\nti = proto_tree_add_uint(kafka_tree, hf_kafka_response_frame, tvb,\r\n0, 0, matcher->response_frame);\r\nPROTO_ITEM_SET_GENERATED(ti);\r\n}\r\nproto_tree_add_item(kafka_tree, hf_kafka_request_api_key, tvb, offset, 2, ENC_BIG_ENDIAN);\r\noffset += 2;\r\nproto_tree_add_item(kafka_tree, hf_kafka_request_api_version, tvb, offset, 2, ENC_BIG_ENDIAN);\r\noffset += 2;\r\nproto_tree_add_item(kafka_tree, hf_kafka_correlation_id, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\noffset = dissect_kafka_string(kafka_tree, hf_kafka_client_id, tvb, pinfo, offset, NULL, NULL);\r\nswitch (matcher->api_key) {\r\ncase KAFKA_PRODUCE:\r\nif (tvb_get_ntohs(tvb, offset) != 0 && !PINFO_FD_VISITED(pinfo)) {\r\nwmem_queue_push(match_queue, matcher);\r\n}\r\ndissect_kafka_produce_request(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\ncase KAFKA_OFFSET_FETCH:\r\ndissect_kafka_offset_fetch_request(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\ncase KAFKA_METADATA:\r\ndissect_kafka_metadata_request(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\ncase KAFKA_FETCH:\r\ndissect_kafka_fetch_request(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\ncase KAFKA_OFFSET:\r\ndissect_kafka_offset_request(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\n}\r\n}\r\nelse {\r\nproto_tree_add_item(kafka_tree, hf_kafka_correlation_id, tvb, offset, 4, ENC_BIG_ENDIAN);\r\noffset += 4;\r\nif (matcher == NULL) {\r\nif (wmem_queue_count(match_queue) > 0) {\r\nmatcher = (kafka_query_response_t *) wmem_queue_peek(match_queue);\r\n}\r\nif (matcher == NULL || matcher->request_frame >= pinfo->num) {\r\ncol_set_str(pinfo->cinfo, COL_INFO, "Kafka Response (Unknown API, Missing Request)");\r\nreturn tvb_captured_length(tvb);\r\n}\r\nwmem_queue_pop(match_queue);\r\nmatcher->response_frame = pinfo->num;\r\nmatcher->response_found = TRUE;\r\np_add_proto_data(wmem_file_scope(), pinfo, proto_kafka, 0, matcher);\r\n}\r\ncol_add_fstr(pinfo->cinfo, COL_INFO, "Kafka %s Response",\r\nval_to_str_const(matcher->api_key, kafka_apis, "Unknown"));\r\nproto_item_append_text(root_ti, " (%s Response)",\r\nval_to_str_const(matcher->api_key, kafka_apis, "Unknown"));\r\nti = proto_tree_add_uint(kafka_tree, hf_kafka_request_frame, tvb,\r\n0, 0, matcher->request_frame);\r\nPROTO_ITEM_SET_GENERATED(ti);\r\nti = proto_tree_add_int(kafka_tree, hf_kafka_response_api_key, tvb,\r\n0, 0, matcher->api_key);\r\nPROTO_ITEM_SET_GENERATED(ti);\r\nti = proto_tree_add_int(kafka_tree, hf_kafka_response_api_version, tvb,\r\n0, 0, matcher->api_version);\r\nPROTO_ITEM_SET_GENERATED(ti);\r\nswitch (matcher->api_key) {\r\ncase KAFKA_PRODUCE:\r\ndissect_kafka_produce_response(tvb, pinfo, kafka_tree, offset, matcher->api_version);\r\nbreak;\r\ncase KAFKA_OFFSET_FETCH:\r\ndissect_kafka_offset_fetch_response(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\ncase KAFKA_METADATA:\r\ndissect_kafka_metadata_response(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\ncase KAFKA_FETCH:\r\ndissect_kafka_fetch_response(tvb, pinfo, kafka_tree, offset, matcher->api_version);\r\nbreak;\r\ncase KAFKA_OFFSET:\r\ndissect_kafka_offset_response(tvb, pinfo, kafka_tree, offset);\r\nbreak;\r\n}\r\n}\r\nreturn tvb_captured_length(tvb);\r\n}\r\nstatic int\r\ndissect_kafka_tcp(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,\r\nvoid *data)\r\n{\r\ntcp_dissect_pdus(tvb, pinfo, tree, TRUE, 4,\r\nget_kafka_pdu_len, dissect_kafka, data);\r\nreturn tvb_captured_length(tvb);\r\n}\r\nvoid\r\nproto_register_kafka(void)\r\n{\r\nmodule_t *kafka_module;\r\nstatic hf_register_info hf[] = {\r\n{ &hf_kafka_len,\r\n{ "Length", "kafka.len",\r\nFT_INT32, BASE_DEC, 0, 0,\r\n"The length of this Kafka packet.", HFILL }\r\n},\r\n{ &hf_kafka_offset,\r\n{ "Offset", "kafka.offset",\r\nFT_INT64, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_offset_time,\r\n{ "Time", "kafka.offset_time",\r\nFT_INT64, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_max_offsets,\r\n{ "Max Offsets", "kafka.max_offsets",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_metadata,\r\n{ "Metadata", "kafka.metadata",\r\nFT_STRING, BASE_NONE, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_error,\r\n{ "Error", "kafka.error",\r\nFT_INT16, BASE_DEC, VALS(kafka_errors), 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_request_api_key,\r\n{ "API Key", "kafka.request_key",\r\nFT_INT16, BASE_DEC, VALS(kafka_apis), 0,\r\n"Request API.", HFILL }\r\n},\r\n{ &hf_kafka_response_api_key,\r\n{ "API Key", "kafka.response_key",\r\nFT_INT16, BASE_DEC, VALS(kafka_apis), 0,\r\n"Response API.", HFILL }\r\n},\r\n{ &hf_kafka_request_api_version,\r\n{ "API Version", "kafka.request.version",\r\nFT_INT16, BASE_DEC, 0, 0,\r\n"Request API Version.", HFILL }\r\n},\r\n{ &hf_kafka_response_api_version,\r\n{ "API Version", "kafka.response.version",\r\nFT_INT16, BASE_DEC, 0, 0,\r\n"Response API Version.", HFILL }\r\n},\r\n{ &hf_kafka_correlation_id,\r\n{ "Correlation ID", "kafka.correlation_id",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_client_id,\r\n{ "Client ID", "kafka.client_id",\r\nFT_STRING, BASE_NONE, 0, 0,\r\n"The ID of the sending client.", HFILL }\r\n},\r\n{ &hf_kafka_string_len,\r\n{ "String Length", "kafka.string_len",\r\nFT_INT16, BASE_DEC, 0, 0,\r\n"Generic length for kafka-encoded string.", HFILL }\r\n},\r\n{ &hf_kafka_bytes_len,\r\n{ "Bytes Length", "kafka.bytes_len",\r\nFT_INT32, BASE_DEC, 0, 0,\r\n"Generic length for kafka-encoded bytes.", HFILL }\r\n},\r\n{ &hf_kafka_array_count,\r\n{ "Array Count", "kafka.array_count",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_required_acks,\r\n{ "Required Acks", "kafka.required_acks",\r\nFT_INT16, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_timeout,\r\n{ "Timeout", "kafka.timeout",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_topic_name,\r\n{ "Topic Name", "kafka.topic_name",\r\nFT_STRING, BASE_NONE, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_partition_id,\r\n{ "Partition ID", "kafka.partition_id",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_replica,\r\n{ "Replica ID", "kafka.replica_id",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_isr,\r\n{ "Caught-Up Replica ID", "kafka.isr_id",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_partition_leader,\r\n{ "Leader", "kafka.leader",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_message_set_size,\r\n{ "Message Set Size", "kafka.message_set_size",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_message_size,\r\n{ "Message Size", "kafka.message_size",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_message_crc,\r\n{ "CRC32", "kafka.message_crc",\r\nFT_UINT32, BASE_HEX, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_message_magic,\r\n{ "Magic Byte", "kafka.message_magic",\r\nFT_INT8, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_message_codec,\r\n{ "Compression Codec", "kafka.message_codec",\r\nFT_UINT8, BASE_DEC, VALS(kafka_codecs), 0x03,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_message_key,\r\n{ "Key", "kafka.message_key",\r\nFT_BYTES, BASE_NONE, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_message_value,\r\n{ "Value", "kafka.message_value",\r\nFT_BYTES, BASE_NONE, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_consumer_group,\r\n{ "Consumer Group", "kafka.consumer_group",\r\nFT_STRING, BASE_NONE, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_request_frame,\r\n{ "Request Frame", "kafka.request_frame",\r\nFT_FRAMENUM, BASE_NONE, FRAMENUM_TYPE(FT_FRAMENUM_REQUEST), 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_broker_nodeid,\r\n{ "Node ID", "kafka.node_id",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_broker_host,\r\n{ "Host", "kafka.host",\r\nFT_STRING, BASE_NONE, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_broker_port,\r\n{ "Port", "kafka.port",\r\nFT_INT32, BASE_DEC, 0, 0,\r\nNULL, HFILL }\r\n},\r\n{ &hf_kafka_min_bytes,\r\n{ "Min Bytes", "kafka.min_bytes",\r\nFT_INT32, BASE_DEC, 0, 0,\r\n"The minimum number of bytes of messages that must be available"\r\n" to give a response.",\r\nHFILL }\r\n},\r\n{ &hf_kafka_max_bytes,\r\n{ "Max Bytes", "kafka.max_bytes",\r\nFT_INT32, BASE_DEC, 0, 0,\r\n"The maximum bytes to include in the message set for this"\r\n" partition. This helps bound the size of the response.",\r\nHFILL }\r\n},\r\n{ &hf_kafka_max_wait_time,\r\n{ "Max Wait Time", "kafka.max_wait_time",\r\nFT_INT32, BASE_DEC, 0, 0,\r\n"The maximum amount of time in milliseconds to block waiting if"\r\n" insufficient data is available at the time the request is"\r\n" issued.",\r\nHFILL }\r\n},\r\n{ &hf_kafka_throttle_time,\r\n{ "Throttle time", "kafka.throttle_time",\r\nFT_INT32, BASE_DEC, 0, 0,\r\n"Duration in milliseconds for which the request was throttled"\r\n" due to quota violation."\r\n" (Zero if the request did not violate any quota.)",\r\nHFILL }\r\n},\r\n{ &hf_kafka_response_frame,\r\n{ "Response Frame", "kafka.reponse_frame",\r\nFT_FRAMENUM, BASE_NONE, FRAMENUM_TYPE(FT_FRAMENUM_RESPONSE), 0,\r\nNULL, HFILL }\r\n}\r\n};\r\nstatic gint *ett[] = {\r\n&ett_kafka,\r\n&ett_kafka_message,\r\n&ett_kafka_message_set,\r\n&ett_kafka_metadata_isr,\r\n&ett_kafka_metadata_replicas,\r\n&ett_kafka_metadata_broker,\r\n&ett_kafka_metadata_brokers,\r\n&ett_kafka_metadata_topics,\r\n&ett_kafka_request_topic,\r\n&ett_kafka_request_partition,\r\n&ett_kafka_response_topic,\r\n&ett_kafka_response_partition\r\n};\r\nstatic ei_register_info ei[] = {\r\n{ &ei_kafka_message_decompress, { "kafka.decompress_failed", PI_UNDECODED, PI_WARN, "Failed to decompress message", EXPFILL }},\r\n{ &ei_kafka_bad_string_length, { "kafka.bad_string_length", PI_MALFORMED, PI_WARN, "Invalid string length field", EXPFILL }},\r\n{ &ei_kafka_bad_bytes_length, { "kafka.bad_bytes_length", PI_MALFORMED, PI_WARN, "Invalid byte length field", EXPFILL }},\r\n};\r\nexpert_module_t* expert_kafka;\r\nproto_kafka = proto_register_protocol("Kafka",\r\n"Kafka", "kafka");\r\nproto_register_field_array(proto_kafka, hf, array_length(hf));\r\nproto_register_subtree_array(ett, array_length(ett));\r\nexpert_kafka = expert_register_protocol(proto_kafka);\r\nexpert_register_field_array(expert_kafka, ei, array_length(ei));\r\nkafka_module = prefs_register_protocol(proto_kafka,\r\nproto_reg_handoff_kafka);\r\nrange_convert_str(&new_kafka_tcp_range, TCP_DEFAULT_RANGE, 65535);\r\nnew_kafka_tcp_range = range_empty();\r\nprefs_register_range_preference(kafka_module, "tcp.ports", "Broker TCP Ports",\r\n"TCP Ports range",\r\n&new_kafka_tcp_range, 65535);\r\nprefs_register_obsolete_preference(kafka_module, "tcp.port");\r\n}\r\nvoid\r\nproto_reg_handoff_kafka(void)\r\n{\r\nstatic gboolean initialized = FALSE;\r\nstatic dissector_handle_t kafka_handle;\r\nif (!initialized) {\r\nkafka_handle = create_dissector_handle(dissect_kafka_tcp,\r\nproto_kafka);\r\ninitialized = TRUE;\r\n}\r\ndissector_delete_uint_range("tcp.port", current_kafka_tcp_range, kafka_handle);\r\ng_free(current_kafka_tcp_range);\r\ncurrent_kafka_tcp_range = range_copy(new_kafka_tcp_range);\r\ndissector_add_uint_range("tcp.port", new_kafka_tcp_range, kafka_handle);\r\n}
