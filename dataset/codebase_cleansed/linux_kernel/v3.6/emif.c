static void do_emif_regdump_show(struct seq_file *s, struct emif_data *emif,\r\nstruct emif_regs *regs)\r\n{\r\nu32 type = emif->plat_data->device_info->type;\r\nu32 ip_rev = emif->plat_data->ip_rev;\r\nseq_printf(s, "EMIF register cache dump for %dMHz\n",\r\nregs->freq/1000000);\r\nseq_printf(s, "ref_ctrl_shdw\t: 0x%08x\n", regs->ref_ctrl_shdw);\r\nseq_printf(s, "sdram_tim1_shdw\t: 0x%08x\n", regs->sdram_tim1_shdw);\r\nseq_printf(s, "sdram_tim2_shdw\t: 0x%08x\n", regs->sdram_tim2_shdw);\r\nseq_printf(s, "sdram_tim3_shdw\t: 0x%08x\n", regs->sdram_tim3_shdw);\r\nif (ip_rev == EMIF_4D) {\r\nseq_printf(s, "read_idle_ctrl_shdw_normal\t: 0x%08x\n",\r\nregs->read_idle_ctrl_shdw_normal);\r\nseq_printf(s, "read_idle_ctrl_shdw_volt_ramp\t: 0x%08x\n",\r\nregs->read_idle_ctrl_shdw_volt_ramp);\r\n} else if (ip_rev == EMIF_4D5) {\r\nseq_printf(s, "dll_calib_ctrl_shdw_normal\t: 0x%08x\n",\r\nregs->dll_calib_ctrl_shdw_normal);\r\nseq_printf(s, "dll_calib_ctrl_shdw_volt_ramp\t: 0x%08x\n",\r\nregs->dll_calib_ctrl_shdw_volt_ramp);\r\n}\r\nif (type == DDR_TYPE_LPDDR2_S2 || type == DDR_TYPE_LPDDR2_S4) {\r\nseq_printf(s, "ref_ctrl_shdw_derated\t: 0x%08x\n",\r\nregs->ref_ctrl_shdw_derated);\r\nseq_printf(s, "sdram_tim1_shdw_derated\t: 0x%08x\n",\r\nregs->sdram_tim1_shdw_derated);\r\nseq_printf(s, "sdram_tim3_shdw_derated\t: 0x%08x\n",\r\nregs->sdram_tim3_shdw_derated);\r\n}\r\n}\r\nstatic int emif_regdump_show(struct seq_file *s, void *unused)\r\n{\r\nstruct emif_data *emif = s->private;\r\nstruct emif_regs **regs_cache;\r\nint i;\r\nif (emif->duplicate)\r\nregs_cache = emif1->regs_cache;\r\nelse\r\nregs_cache = emif->regs_cache;\r\nfor (i = 0; i < EMIF_MAX_NUM_FREQUENCIES && regs_cache[i]; i++) {\r\ndo_emif_regdump_show(s, emif, regs_cache[i]);\r\nseq_printf(s, "\n");\r\n}\r\nreturn 0;\r\n}\r\nstatic int emif_regdump_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, emif_regdump_show, inode->i_private);\r\n}\r\nstatic int emif_mr4_show(struct seq_file *s, void *unused)\r\n{\r\nstruct emif_data *emif = s->private;\r\nseq_printf(s, "MR4=%d\n", emif->temperature_level);\r\nreturn 0;\r\n}\r\nstatic int emif_mr4_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, emif_mr4_show, inode->i_private);\r\n}\r\nstatic int __init_or_module emif_debugfs_init(struct emif_data *emif)\r\n{\r\nstruct dentry *dentry;\r\nint ret;\r\ndentry = debugfs_create_dir(dev_name(emif->dev), NULL);\r\nif (IS_ERR(dentry)) {\r\nret = PTR_ERR(dentry);\r\ngoto err0;\r\n}\r\nemif->debugfs_root = dentry;\r\ndentry = debugfs_create_file("regcache_dump", S_IRUGO,\r\nemif->debugfs_root, emif, &emif_regdump_fops);\r\nif (IS_ERR(dentry)) {\r\nret = PTR_ERR(dentry);\r\ngoto err1;\r\n}\r\ndentry = debugfs_create_file("mr4", S_IRUGO,\r\nemif->debugfs_root, emif, &emif_mr4_fops);\r\nif (IS_ERR(dentry)) {\r\nret = PTR_ERR(dentry);\r\ngoto err1;\r\n}\r\nreturn 0;\r\nerr1:\r\ndebugfs_remove_recursive(emif->debugfs_root);\r\nerr0:\r\nreturn ret;\r\n}\r\nstatic void __exit emif_debugfs_exit(struct emif_data *emif)\r\n{\r\ndebugfs_remove_recursive(emif->debugfs_root);\r\nemif->debugfs_root = NULL;\r\n}\r\nstatic void set_ddr_clk_period(u32 freq)\r\n{\r\nt_ck = (u32)DIV_ROUND_UP_ULL(1000000000000ull, freq);\r\n}\r\nstatic u32 get_emif_bus_width(struct emif_data *emif)\r\n{\r\nu32 width;\r\nvoid __iomem *base = emif->base;\r\nwidth = (readl(base + EMIF_SDRAM_CONFIG) & NARROW_MODE_MASK)\r\n>> NARROW_MODE_SHIFT;\r\nwidth = width == 0 ? 32 : 16;\r\nreturn width;\r\n}\r\nstatic u32 get_cl(struct emif_data *emif)\r\n{\r\nu32 cl;\r\nvoid __iomem *base = emif->base;\r\ncl = (readl(base + EMIF_SDRAM_CONFIG) & CL_MASK) >> CL_SHIFT;\r\nreturn cl;\r\n}\r\nstatic void set_lpmode(struct emif_data *emif, u8 lpmode)\r\n{\r\nu32 temp;\r\nvoid __iomem *base = emif->base;\r\ntemp = readl(base + EMIF_POWER_MANAGEMENT_CONTROL);\r\ntemp &= ~LP_MODE_MASK;\r\ntemp |= (lpmode << LP_MODE_SHIFT);\r\nwritel(temp, base + EMIF_POWER_MANAGEMENT_CONTROL);\r\n}\r\nstatic void do_freq_update(void)\r\n{\r\nstruct emif_data *emif;\r\nlist_for_each_entry(emif, &device_list, node) {\r\nif (emif->lpmode == EMIF_LP_MODE_SELF_REFRESH)\r\nset_lpmode(emif, EMIF_LP_MODE_DISABLE);\r\n}\r\nlist_for_each_entry(emif, &device_list, node) {\r\nif (emif->lpmode == EMIF_LP_MODE_SELF_REFRESH)\r\nset_lpmode(emif, EMIF_LP_MODE_SELF_REFRESH);\r\n}\r\n}\r\nstatic const struct lpddr2_addressing *get_addressing_table(\r\nconst struct ddr_device_info *device_info)\r\n{\r\nu32 index, type, density;\r\ntype = device_info->type;\r\ndensity = device_info->density;\r\nswitch (type) {\r\ncase DDR_TYPE_LPDDR2_S4:\r\nindex = density - 1;\r\nbreak;\r\ncase DDR_TYPE_LPDDR2_S2:\r\nswitch (density) {\r\ncase DDR_DENSITY_1Gb:\r\ncase DDR_DENSITY_2Gb:\r\nindex = density + 3;\r\nbreak;\r\ndefault:\r\nindex = density - 1;\r\n}\r\nbreak;\r\ndefault:\r\nreturn NULL;\r\n}\r\nreturn &lpddr2_jedec_addressing_table[index];\r\n}\r\nstatic const struct lpddr2_timings *get_timings_table(struct emif_data *emif,\r\nu32 freq)\r\n{\r\nu32 i, min, max, freq_nearest;\r\nconst struct lpddr2_timings *timings = NULL;\r\nconst struct lpddr2_timings *timings_arr = emif->plat_data->timings;\r\nstruct device *dev = emif->dev;\r\nfreq_nearest = 1000000000;\r\nfor (i = 0; i < emif->plat_data->timings_arr_size; i++) {\r\nmax = timings_arr[i].max_freq;\r\nmin = timings_arr[i].min_freq;\r\nif ((freq >= min) && (freq <= max) && (max < freq_nearest)) {\r\nfreq_nearest = max;\r\ntimings = &timings_arr[i];\r\n}\r\n}\r\nif (!timings)\r\ndev_err(dev, "%s: couldn't find timings for - %dHz\n",\r\n__func__, freq);\r\ndev_dbg(dev, "%s: timings table: freq %d, speed bin freq %d\n",\r\n__func__, freq, freq_nearest);\r\nreturn timings;\r\n}\r\nstatic u32 get_sdram_ref_ctrl_shdw(u32 freq,\r\nconst struct lpddr2_addressing *addressing)\r\n{\r\nu32 ref_ctrl_shdw = 0, val = 0, freq_khz, t_refi;\r\nfreq_khz = freq / 1000;\r\nt_refi = addressing->tREFI_ns / 100;\r\nval = t_refi * freq_khz / 10000;\r\nref_ctrl_shdw |= val << REFRESH_RATE_SHIFT;\r\nreturn ref_ctrl_shdw;\r\n}\r\nstatic u32 get_sdram_tim_1_shdw(const struct lpddr2_timings *timings,\r\nconst struct lpddr2_min_tck *min_tck,\r\nconst struct lpddr2_addressing *addressing)\r\n{\r\nu32 tim1 = 0, val = 0;\r\nval = max(min_tck->tWTR, DIV_ROUND_UP(timings->tWTR, t_ck)) - 1;\r\ntim1 |= val << T_WTR_SHIFT;\r\nif (addressing->num_banks == B8)\r\nval = DIV_ROUND_UP(timings->tFAW, t_ck*4);\r\nelse\r\nval = max(min_tck->tRRD, DIV_ROUND_UP(timings->tRRD, t_ck));\r\ntim1 |= (val - 1) << T_RRD_SHIFT;\r\nval = DIV_ROUND_UP(timings->tRAS_min + timings->tRPab, t_ck) - 1;\r\ntim1 |= val << T_RC_SHIFT;\r\nval = max(min_tck->tRASmin, DIV_ROUND_UP(timings->tRAS_min, t_ck));\r\ntim1 |= (val - 1) << T_RAS_SHIFT;\r\nval = max(min_tck->tWR, DIV_ROUND_UP(timings->tWR, t_ck)) - 1;\r\ntim1 |= val << T_WR_SHIFT;\r\nval = max(min_tck->tRCD, DIV_ROUND_UP(timings->tRCD, t_ck)) - 1;\r\ntim1 |= val << T_RCD_SHIFT;\r\nval = max(min_tck->tRPab, DIV_ROUND_UP(timings->tRPab, t_ck)) - 1;\r\ntim1 |= val << T_RP_SHIFT;\r\nreturn tim1;\r\n}\r\nstatic u32 get_sdram_tim_1_shdw_derated(const struct lpddr2_timings *timings,\r\nconst struct lpddr2_min_tck *min_tck,\r\nconst struct lpddr2_addressing *addressing)\r\n{\r\nu32 tim1 = 0, val = 0;\r\nval = max(min_tck->tWTR, DIV_ROUND_UP(timings->tWTR, t_ck)) - 1;\r\ntim1 = val << T_WTR_SHIFT;\r\nif (addressing->num_banks == B8) {\r\nval = DIV_ROUND_UP(timings->tFAW + 7500, 4 * t_ck) - 1;\r\n} else {\r\nval = DIV_ROUND_UP(timings->tRRD + 1875, t_ck);\r\nval = max(min_tck->tRRD, val) - 1;\r\n}\r\ntim1 |= val << T_RRD_SHIFT;\r\nval = DIV_ROUND_UP(timings->tRAS_min + timings->tRPab + 1875, t_ck);\r\ntim1 |= (val - 1) << T_RC_SHIFT;\r\nval = DIV_ROUND_UP(timings->tRAS_min + 1875, t_ck);\r\nval = max(min_tck->tRASmin, val) - 1;\r\ntim1 |= val << T_RAS_SHIFT;\r\nval = max(min_tck->tWR, DIV_ROUND_UP(timings->tWR, t_ck)) - 1;\r\ntim1 |= val << T_WR_SHIFT;\r\nval = max(min_tck->tRCD, DIV_ROUND_UP(timings->tRCD + 1875, t_ck));\r\ntim1 |= (val - 1) << T_RCD_SHIFT;\r\nval = max(min_tck->tRPab, DIV_ROUND_UP(timings->tRPab + 1875, t_ck));\r\ntim1 |= (val - 1) << T_RP_SHIFT;\r\nreturn tim1;\r\n}\r\nstatic u32 get_sdram_tim_2_shdw(const struct lpddr2_timings *timings,\r\nconst struct lpddr2_min_tck *min_tck,\r\nconst struct lpddr2_addressing *addressing,\r\nu32 type)\r\n{\r\nu32 tim2 = 0, val = 0;\r\nval = min_tck->tCKE - 1;\r\ntim2 |= val << T_CKE_SHIFT;\r\nval = max(min_tck->tRTP, DIV_ROUND_UP(timings->tRTP, t_ck)) - 1;\r\ntim2 |= val << T_RTP_SHIFT;\r\nval = DIV_ROUND_UP(addressing->tRFCab_ps + 10000, t_ck) - 1;\r\ntim2 |= val << T_XSNR_SHIFT;\r\ntim2 |= val << T_XSRD_SHIFT;\r\nval = max(min_tck->tXP, DIV_ROUND_UP(timings->tXP, t_ck)) - 1;\r\ntim2 |= val << T_XP_SHIFT;\r\nreturn tim2;\r\n}\r\nstatic u32 get_sdram_tim_3_shdw(const struct lpddr2_timings *timings,\r\nconst struct lpddr2_min_tck *min_tck,\r\nconst struct lpddr2_addressing *addressing,\r\nu32 type, u32 ip_rev, u32 derated)\r\n{\r\nu32 tim3 = 0, val = 0, t_dqsck;\r\nval = timings->tRAS_max_ns / addressing->tREFI_ns - 1;\r\nval = val > 0xF ? 0xF : val;\r\ntim3 |= val << T_RAS_MAX_SHIFT;\r\nval = DIV_ROUND_UP(addressing->tRFCab_ps, t_ck) - 1;\r\ntim3 |= val << T_RFC_SHIFT;\r\nt_dqsck = (derated == EMIF_DERATED_TIMINGS) ?\r\ntimings->tDQSCK_max_derated : timings->tDQSCK_max;\r\nif (ip_rev == EMIF_4D5)\r\nval = DIV_ROUND_UP(t_dqsck + 1000, t_ck) - 1;\r\nelse\r\nval = DIV_ROUND_UP(t_dqsck, t_ck) - 1;\r\ntim3 |= val << T_TDQSCKMAX_SHIFT;\r\nval = DIV_ROUND_UP(timings->tZQCS, t_ck) - 1;\r\ntim3 |= val << ZQ_ZQCS_SHIFT;\r\nval = DIV_ROUND_UP(timings->tCKESR, t_ck);\r\nval = max(min_tck->tCKESR, val) - 1;\r\ntim3 |= val << T_CKESR_SHIFT;\r\nif (ip_rev == EMIF_4D5) {\r\ntim3 |= (EMIF_T_CSTA - 1) << T_CSTA_SHIFT;\r\nval = DIV_ROUND_UP(EMIF_T_PDLL_UL, 128) - 1;\r\ntim3 |= val << T_PDLL_UL_SHIFT;\r\n}\r\nreturn tim3;\r\n}\r\nstatic u32 get_zq_config_reg(const struct lpddr2_addressing *addressing,\r\nbool cs1_used, bool cal_resistors_per_cs)\r\n{\r\nu32 zq = 0, val = 0;\r\nval = EMIF_ZQCS_INTERVAL_US * 1000 / addressing->tREFI_ns;\r\nzq |= val << ZQ_REFINTERVAL_SHIFT;\r\nval = DIV_ROUND_UP(T_ZQCL_DEFAULT_NS, T_ZQCS_DEFAULT_NS) - 1;\r\nzq |= val << ZQ_ZQCL_MULT_SHIFT;\r\nval = DIV_ROUND_UP(T_ZQINIT_DEFAULT_NS, T_ZQCL_DEFAULT_NS) - 1;\r\nzq |= val << ZQ_ZQINIT_MULT_SHIFT;\r\nzq |= ZQ_SFEXITEN_ENABLE << ZQ_SFEXITEN_SHIFT;\r\nif (cal_resistors_per_cs)\r\nzq |= ZQ_DUALCALEN_ENABLE << ZQ_DUALCALEN_SHIFT;\r\nelse\r\nzq |= ZQ_DUALCALEN_DISABLE << ZQ_DUALCALEN_SHIFT;\r\nzq |= ZQ_CS0EN_MASK;\r\nval = cs1_used ? 1 : 0;\r\nzq |= val << ZQ_CS1EN_SHIFT;\r\nreturn zq;\r\n}\r\nstatic u32 get_temp_alert_config(const struct lpddr2_addressing *addressing,\r\nconst struct emif_custom_configs *custom_configs, bool cs1_used,\r\nu32 sdram_io_width, u32 emif_bus_width)\r\n{\r\nu32 alert = 0, interval, devcnt;\r\nif (custom_configs && (custom_configs->mask &\r\nEMIF_CUSTOM_CONFIG_TEMP_ALERT_POLL_INTERVAL))\r\ninterval = custom_configs->temp_alert_poll_interval_ms;\r\nelse\r\ninterval = TEMP_ALERT_POLL_INTERVAL_DEFAULT_MS;\r\ninterval *= 1000000;\r\ninterval /= addressing->tREFI_ns;\r\nalert |= (interval << TA_REFINTERVAL_SHIFT);\r\nemif_bus_width = __fls(emif_bus_width) - 1;\r\ndevcnt = emif_bus_width - sdram_io_width;\r\nalert |= devcnt << TA_DEVCNT_SHIFT;\r\nalert |= (sdram_io_width - 2) << TA_DEVWDT_SHIFT;\r\nalert |= 1 << TA_SFEXITEN_SHIFT;\r\nalert |= 1 << TA_CS0EN_SHIFT;\r\nalert |= (cs1_used ? 1 : 0) << TA_CS1EN_SHIFT;\r\nreturn alert;\r\n}\r\nstatic u32 get_read_idle_ctrl_shdw(u8 volt_ramp)\r\n{\r\nu32 idle = 0, val = 0;\r\nif (volt_ramp)\r\nval = READ_IDLE_INTERVAL_DVFS / t_ck / 64 - 1;\r\nelse\r\nval = 0x1FF;\r\nidle |= val << DLL_CALIB_INTERVAL_SHIFT;\r\nidle |= EMIF_READ_IDLE_LEN_VAL << ACK_WAIT_SHIFT;\r\nreturn idle;\r\n}\r\nstatic u32 get_dll_calib_ctrl_shdw(u8 volt_ramp)\r\n{\r\nu32 calib = 0, val = 0;\r\nif (volt_ramp == DDR_VOLTAGE_RAMPING)\r\nval = DLL_CALIB_INTERVAL_DVFS / t_ck / 16 - 1;\r\nelse\r\nval = 0;\r\ncalib |= val << DLL_CALIB_INTERVAL_SHIFT;\r\ncalib |= DLL_CALIB_ACK_WAIT_VAL << ACK_WAIT_SHIFT;\r\nreturn calib;\r\n}\r\nstatic u32 get_ddr_phy_ctrl_1_attilaphy_4d(const struct lpddr2_timings *timings,\r\nu32 freq, u8 RL)\r\n{\r\nu32 phy = EMIF_DDR_PHY_CTRL_1_BASE_VAL_ATTILAPHY, val = 0;\r\nval = RL + DIV_ROUND_UP(timings->tDQSCK_max, t_ck) - 1;\r\nphy |= val << READ_LATENCY_SHIFT_4D;\r\nif (freq <= 100000000)\r\nval = EMIF_DLL_SLAVE_DLY_CTRL_100_MHZ_AND_LESS_ATTILAPHY;\r\nelse if (freq <= 200000000)\r\nval = EMIF_DLL_SLAVE_DLY_CTRL_200_MHZ_ATTILAPHY;\r\nelse\r\nval = EMIF_DLL_SLAVE_DLY_CTRL_400_MHZ_ATTILAPHY;\r\nphy |= val << DLL_SLAVE_DLY_CTRL_SHIFT_4D;\r\nreturn phy;\r\n}\r\nstatic u32 get_phy_ctrl_1_intelliphy_4d5(u32 freq, u8 cl)\r\n{\r\nu32 phy = EMIF_DDR_PHY_CTRL_1_BASE_VAL_INTELLIPHY, half_delay;\r\nif (freq >= 265000000 && freq < 267000000)\r\nhalf_delay = 0;\r\nelse\r\nhalf_delay = 1;\r\nphy |= half_delay << DLL_HALF_DELAY_SHIFT_4D5;\r\nphy |= ((cl + DIV_ROUND_UP(EMIF_PHY_TOTAL_READ_LATENCY_INTELLIPHY_PS,\r\nt_ck) - 1) << READ_LATENCY_SHIFT_4D5);\r\nreturn phy;\r\n}\r\nstatic u32 get_ext_phy_ctrl_2_intelliphy_4d5(void)\r\n{\r\nu32 fifo_we_slave_ratio;\r\nfifo_we_slave_ratio = DIV_ROUND_CLOSEST(\r\nEMIF_INTELLI_PHY_DQS_GATE_OPENING_DELAY_PS * 256 , t_ck);\r\nreturn fifo_we_slave_ratio | fifo_we_slave_ratio << 11 |\r\nfifo_we_slave_ratio << 22;\r\n}\r\nstatic u32 get_ext_phy_ctrl_3_intelliphy_4d5(void)\r\n{\r\nu32 fifo_we_slave_ratio;\r\nfifo_we_slave_ratio = DIV_ROUND_CLOSEST(\r\nEMIF_INTELLI_PHY_DQS_GATE_OPENING_DELAY_PS * 256 , t_ck);\r\nreturn fifo_we_slave_ratio >> 10 | fifo_we_slave_ratio << 1 |\r\nfifo_we_slave_ratio << 12 | fifo_we_slave_ratio << 23;\r\n}\r\nstatic u32 get_ext_phy_ctrl_4_intelliphy_4d5(void)\r\n{\r\nu32 fifo_we_slave_ratio;\r\nfifo_we_slave_ratio = DIV_ROUND_CLOSEST(\r\nEMIF_INTELLI_PHY_DQS_GATE_OPENING_DELAY_PS * 256 , t_ck);\r\nreturn fifo_we_slave_ratio >> 9 | fifo_we_slave_ratio << 2 |\r\nfifo_we_slave_ratio << 13;\r\n}\r\nstatic u32 get_pwr_mgmt_ctrl(u32 freq, struct emif_data *emif, u32 ip_rev)\r\n{\r\nu32 pwr_mgmt_ctrl = 0, timeout;\r\nu32 lpmode = EMIF_LP_MODE_SELF_REFRESH;\r\nu32 timeout_perf = EMIF_LP_MODE_TIMEOUT_PERFORMANCE;\r\nu32 timeout_pwr = EMIF_LP_MODE_TIMEOUT_POWER;\r\nu32 freq_threshold = EMIF_LP_MODE_FREQ_THRESHOLD;\r\nstruct emif_custom_configs *cust_cfgs = emif->plat_data->custom_configs;\r\nif (cust_cfgs && (cust_cfgs->mask & EMIF_CUSTOM_CONFIG_LPMODE)) {\r\nlpmode = cust_cfgs->lpmode;\r\ntimeout_perf = cust_cfgs->lpmode_timeout_performance;\r\ntimeout_pwr = cust_cfgs->lpmode_timeout_power;\r\nfreq_threshold = cust_cfgs->lpmode_freq_threshold;\r\n}\r\ntimeout = freq >= freq_threshold ? timeout_perf : timeout_pwr;\r\nif (timeout < 16) {\r\ntimeout = 0;\r\n} else {\r\ntimeout = __fls(timeout) - 3;\r\nif (timeout & (timeout - 1))\r\ntimeout++;\r\n}\r\nswitch (lpmode) {\r\ncase EMIF_LP_MODE_CLOCK_STOP:\r\npwr_mgmt_ctrl = (timeout << CS_TIM_SHIFT) |\r\nSR_TIM_MASK | PD_TIM_MASK;\r\nbreak;\r\ncase EMIF_LP_MODE_SELF_REFRESH:\r\nif (timeout < 6)\r\ntimeout = 6;\r\npwr_mgmt_ctrl = (timeout << SR_TIM_SHIFT) |\r\nCS_TIM_MASK | PD_TIM_MASK;\r\nbreak;\r\ncase EMIF_LP_MODE_PWR_DN:\r\npwr_mgmt_ctrl = (timeout << PD_TIM_SHIFT) |\r\nCS_TIM_MASK | SR_TIM_MASK;\r\nbreak;\r\ncase EMIF_LP_MODE_DISABLE:\r\ndefault:\r\npwr_mgmt_ctrl = CS_TIM_MASK |\r\nPD_TIM_MASK | SR_TIM_MASK;\r\n}\r\nif (ip_rev == EMIF_4D5)\r\npwr_mgmt_ctrl &= ~CS_TIM_MASK;\r\npwr_mgmt_ctrl |= lpmode << LP_MODE_SHIFT;\r\nreturn pwr_mgmt_ctrl;\r\n}\r\nstatic void get_temperature_level(struct emif_data *emif)\r\n{\r\nu32 temp, temperature_level;\r\nvoid __iomem *base;\r\nbase = emif->base;\r\nwritel(DDR_MR4, base + EMIF_LPDDR2_MODE_REG_CONFIG);\r\ntemperature_level = readl(base + EMIF_LPDDR2_MODE_REG_DATA);\r\ntemperature_level = (temperature_level & MR4_SDRAM_REF_RATE_MASK) >>\r\nMR4_SDRAM_REF_RATE_SHIFT;\r\nif (emif->plat_data->device_info->cs1_used) {\r\nwritel(DDR_MR4 | CS_MASK, base + EMIF_LPDDR2_MODE_REG_CONFIG);\r\ntemp = readl(base + EMIF_LPDDR2_MODE_REG_DATA);\r\ntemp = (temp & MR4_SDRAM_REF_RATE_MASK)\r\n>> MR4_SDRAM_REF_RATE_SHIFT;\r\ntemperature_level = max(temp, temperature_level);\r\n}\r\nif (unlikely(temperature_level < SDRAM_TEMP_NOMINAL))\r\ntemperature_level = SDRAM_TEMP_NOMINAL;\r\nif (likely(temperature_level != SDRAM_TEMP_RESERVED_4))\r\nemif->temperature_level = temperature_level;\r\n}\r\nstatic void setup_registers(struct emif_data *emif, struct emif_regs *regs)\r\n{\r\nvoid __iomem *base = emif->base;\r\nwritel(regs->sdram_tim2_shdw, base + EMIF_SDRAM_TIMING_2_SHDW);\r\nwritel(regs->phy_ctrl_1_shdw, base + EMIF_DDR_PHY_CTRL_1_SHDW);\r\nif (emif->plat_data->ip_rev != EMIF_4D5)\r\nreturn;\r\nwritel(regs->ext_phy_ctrl_2_shdw, base + EMIF_EXT_PHY_CTRL_2_SHDW);\r\nwritel(regs->ext_phy_ctrl_3_shdw, base + EMIF_EXT_PHY_CTRL_3_SHDW);\r\nwritel(regs->ext_phy_ctrl_4_shdw, base + EMIF_EXT_PHY_CTRL_4_SHDW);\r\n}\r\nstatic void setup_volt_sensitive_regs(struct emif_data *emif,\r\nstruct emif_regs *regs, u32 volt_state)\r\n{\r\nu32 calib_ctrl;\r\nvoid __iomem *base = emif->base;\r\nif (volt_state == DDR_VOLTAGE_RAMPING)\r\ncalib_ctrl = regs->dll_calib_ctrl_shdw_volt_ramp;\r\nelse\r\ncalib_ctrl = regs->dll_calib_ctrl_shdw_normal;\r\nwritel(calib_ctrl, base + EMIF_DLL_CALIB_CTRL_SHDW);\r\n}\r\nstatic void setup_temperature_sensitive_regs(struct emif_data *emif,\r\nstruct emif_regs *regs)\r\n{\r\nu32 tim1, tim3, ref_ctrl, type;\r\nvoid __iomem *base = emif->base;\r\nu32 temperature;\r\ntype = emif->plat_data->device_info->type;\r\ntim1 = regs->sdram_tim1_shdw;\r\ntim3 = regs->sdram_tim3_shdw;\r\nref_ctrl = regs->ref_ctrl_shdw;\r\nif (type != DDR_TYPE_LPDDR2_S2 && type != DDR_TYPE_LPDDR2_S4)\r\ngoto out;\r\ntemperature = emif->temperature_level;\r\nif (temperature == SDRAM_TEMP_HIGH_DERATE_REFRESH) {\r\nref_ctrl = regs->ref_ctrl_shdw_derated;\r\n} else if (temperature == SDRAM_TEMP_HIGH_DERATE_REFRESH_AND_TIMINGS) {\r\ntim1 = regs->sdram_tim1_shdw_derated;\r\ntim3 = regs->sdram_tim3_shdw_derated;\r\nref_ctrl = regs->ref_ctrl_shdw_derated;\r\n}\r\nout:\r\nwritel(tim1, base + EMIF_SDRAM_TIMING_1_SHDW);\r\nwritel(tim3, base + EMIF_SDRAM_TIMING_3_SHDW);\r\nwritel(ref_ctrl, base + EMIF_SDRAM_REFRESH_CTRL_SHDW);\r\n}\r\nstatic irqreturn_t handle_temp_alert(void __iomem *base, struct emif_data *emif)\r\n{\r\nu32 old_temp_level;\r\nirqreturn_t ret = IRQ_HANDLED;\r\nspin_lock_irqsave(&emif_lock, irq_state);\r\nold_temp_level = emif->temperature_level;\r\nget_temperature_level(emif);\r\nif (unlikely(emif->temperature_level == old_temp_level)) {\r\ngoto out;\r\n} else if (!emif->curr_regs) {\r\ndev_err(emif->dev, "temperature alert before registers are calculated, not de-rating timings\n");\r\ngoto out;\r\n}\r\nif (emif->temperature_level < old_temp_level ||\r\nemif->temperature_level == SDRAM_TEMP_VERY_HIGH_SHUTDOWN) {\r\nret = IRQ_WAKE_THREAD;\r\n} else {\r\nsetup_temperature_sensitive_regs(emif, emif->curr_regs);\r\ndo_freq_update();\r\n}\r\nout:\r\nspin_unlock_irqrestore(&emif_lock, irq_state);\r\nreturn ret;\r\n}\r\nstatic irqreturn_t emif_interrupt_handler(int irq, void *dev_id)\r\n{\r\nu32 interrupts;\r\nstruct emif_data *emif = dev_id;\r\nvoid __iomem *base = emif->base;\r\nstruct device *dev = emif->dev;\r\nirqreturn_t ret = IRQ_HANDLED;\r\ninterrupts = readl(base + EMIF_SYSTEM_OCP_INTERRUPT_STATUS);\r\nwritel(interrupts, base + EMIF_SYSTEM_OCP_INTERRUPT_STATUS);\r\nif (interrupts & TA_SYS_MASK)\r\nret = handle_temp_alert(base, emif);\r\nif (interrupts & ERR_SYS_MASK)\r\ndev_err(dev, "Access error from SYS port - %x\n", interrupts);\r\nif (emif->plat_data->hw_caps & EMIF_HW_CAPS_LL_INTERFACE) {\r\ninterrupts = readl(base + EMIF_LL_OCP_INTERRUPT_STATUS);\r\nwritel(interrupts, base + EMIF_LL_OCP_INTERRUPT_STATUS);\r\nif (interrupts & ERR_LL_MASK)\r\ndev_err(dev, "Access error from LL port - %x\n",\r\ninterrupts);\r\n}\r\nreturn ret;\r\n}\r\nstatic irqreturn_t emif_threaded_isr(int irq, void *dev_id)\r\n{\r\nstruct emif_data *emif = dev_id;\r\nif (emif->temperature_level == SDRAM_TEMP_VERY_HIGH_SHUTDOWN) {\r\ndev_emerg(emif->dev, "SDRAM temperature exceeds operating limit.. Needs shut down!!!\n");\r\nkernel_power_off();\r\nreturn IRQ_HANDLED;\r\n}\r\nspin_lock_irqsave(&emif_lock, irq_state);\r\nif (emif->curr_regs) {\r\nsetup_temperature_sensitive_regs(emif, emif->curr_regs);\r\ndo_freq_update();\r\n} else {\r\ndev_err(emif->dev, "temperature alert before registers are calculated, not de-rating timings\n");\r\n}\r\nspin_unlock_irqrestore(&emif_lock, irq_state);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void clear_all_interrupts(struct emif_data *emif)\r\n{\r\nvoid __iomem *base = emif->base;\r\nwritel(readl(base + EMIF_SYSTEM_OCP_INTERRUPT_STATUS),\r\nbase + EMIF_SYSTEM_OCP_INTERRUPT_STATUS);\r\nif (emif->plat_data->hw_caps & EMIF_HW_CAPS_LL_INTERFACE)\r\nwritel(readl(base + EMIF_LL_OCP_INTERRUPT_STATUS),\r\nbase + EMIF_LL_OCP_INTERRUPT_STATUS);\r\n}\r\nstatic void disable_and_clear_all_interrupts(struct emif_data *emif)\r\n{\r\nvoid __iomem *base = emif->base;\r\nwritel(readl(base + EMIF_SYSTEM_OCP_INTERRUPT_ENABLE_SET),\r\nbase + EMIF_SYSTEM_OCP_INTERRUPT_ENABLE_CLEAR);\r\nif (emif->plat_data->hw_caps & EMIF_HW_CAPS_LL_INTERFACE)\r\nwritel(readl(base + EMIF_LL_OCP_INTERRUPT_ENABLE_SET),\r\nbase + EMIF_LL_OCP_INTERRUPT_ENABLE_CLEAR);\r\nclear_all_interrupts(emif);\r\n}\r\nstatic int __init_or_module setup_interrupts(struct emif_data *emif, u32 irq)\r\n{\r\nu32 interrupts, type;\r\nvoid __iomem *base = emif->base;\r\ntype = emif->plat_data->device_info->type;\r\nclear_all_interrupts(emif);\r\ninterrupts = EN_ERR_SYS_MASK;\r\nif (type == DDR_TYPE_LPDDR2_S2 || type == DDR_TYPE_LPDDR2_S4)\r\ninterrupts |= EN_TA_SYS_MASK;\r\nwritel(interrupts, base + EMIF_SYSTEM_OCP_INTERRUPT_ENABLE_SET);\r\nif (emif->plat_data->hw_caps & EMIF_HW_CAPS_LL_INTERFACE) {\r\ninterrupts = EN_ERR_LL_MASK;\r\nwritel(interrupts, base + EMIF_LL_OCP_INTERRUPT_ENABLE_SET);\r\n}\r\nreturn devm_request_threaded_irq(emif->dev, irq,\r\nemif_interrupt_handler,\r\nemif_threaded_isr,\r\n0, dev_name(emif->dev),\r\nemif);\r\n}\r\nstatic void __init_or_module emif_onetime_settings(struct emif_data *emif)\r\n{\r\nu32 pwr_mgmt_ctrl, zq, temp_alert_cfg;\r\nvoid __iomem *base = emif->base;\r\nconst struct lpddr2_addressing *addressing;\r\nconst struct ddr_device_info *device_info;\r\ndevice_info = emif->plat_data->device_info;\r\naddressing = get_addressing_table(device_info);\r\npwr_mgmt_ctrl = get_pwr_mgmt_ctrl(1000000000, emif,\r\nemif->plat_data->ip_rev);\r\nemif->lpmode = (pwr_mgmt_ctrl & LP_MODE_MASK) >> LP_MODE_SHIFT;\r\nwritel(pwr_mgmt_ctrl, base + EMIF_POWER_MANAGEMENT_CONTROL);\r\nzq = get_zq_config_reg(addressing, device_info->cs1_used,\r\ndevice_info->cal_resistors_per_cs);\r\nwritel(zq, base + EMIF_SDRAM_OUTPUT_IMPEDANCE_CALIBRATION_CONFIG);\r\nget_temperature_level(emif);\r\nif (emif->temperature_level == SDRAM_TEMP_VERY_HIGH_SHUTDOWN)\r\ndev_emerg(emif->dev, "SDRAM temperature exceeds operating limit.. Needs shut down!!!\n");\r\ntemp_alert_cfg = get_temp_alert_config(addressing,\r\nemif->plat_data->custom_configs, device_info->cs1_used,\r\ndevice_info->io_width, get_emif_bus_width(emif));\r\nwritel(temp_alert_cfg, base + EMIF_TEMPERATURE_ALERT_CONFIG);\r\nif (emif->plat_data->phy_type != EMIF_PHY_TYPE_INTELLIPHY)\r\nreturn;\r\nwritel(EMIF_EXT_PHY_CTRL_1_VAL, base + EMIF_EXT_PHY_CTRL_1_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_5_VAL, base + EMIF_EXT_PHY_CTRL_5_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_6_VAL, base + EMIF_EXT_PHY_CTRL_6_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_7_VAL, base + EMIF_EXT_PHY_CTRL_7_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_8_VAL, base + EMIF_EXT_PHY_CTRL_8_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_9_VAL, base + EMIF_EXT_PHY_CTRL_9_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_10_VAL, base + EMIF_EXT_PHY_CTRL_10_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_11_VAL, base + EMIF_EXT_PHY_CTRL_11_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_12_VAL, base + EMIF_EXT_PHY_CTRL_12_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_13_VAL, base + EMIF_EXT_PHY_CTRL_13_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_14_VAL, base + EMIF_EXT_PHY_CTRL_14_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_15_VAL, base + EMIF_EXT_PHY_CTRL_15_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_16_VAL, base + EMIF_EXT_PHY_CTRL_16_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_17_VAL, base + EMIF_EXT_PHY_CTRL_17_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_18_VAL, base + EMIF_EXT_PHY_CTRL_18_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_19_VAL, base + EMIF_EXT_PHY_CTRL_19_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_20_VAL, base + EMIF_EXT_PHY_CTRL_20_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_21_VAL, base + EMIF_EXT_PHY_CTRL_21_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_22_VAL, base + EMIF_EXT_PHY_CTRL_22_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_23_VAL, base + EMIF_EXT_PHY_CTRL_23_SHDW);\r\nwritel(EMIF_EXT_PHY_CTRL_24_VAL, base + EMIF_EXT_PHY_CTRL_24_SHDW);\r\n}\r\nstatic void get_default_timings(struct emif_data *emif)\r\n{\r\nstruct emif_platform_data *pd = emif->plat_data;\r\npd->timings = lpddr2_jedec_timings;\r\npd->timings_arr_size = ARRAY_SIZE(lpddr2_jedec_timings);\r\ndev_warn(emif->dev, "%s: using default timings\n", __func__);\r\n}\r\nstatic int is_dev_data_valid(u32 type, u32 density, u32 io_width, u32 phy_type,\r\nu32 ip_rev, struct device *dev)\r\n{\r\nint valid;\r\nvalid = (type == DDR_TYPE_LPDDR2_S4 ||\r\ntype == DDR_TYPE_LPDDR2_S2)\r\n&& (density >= DDR_DENSITY_64Mb\r\n&& density <= DDR_DENSITY_8Gb)\r\n&& (io_width >= DDR_IO_WIDTH_8\r\n&& io_width <= DDR_IO_WIDTH_32);\r\nswitch (ip_rev) {\r\ncase EMIF_4D:\r\nvalid = valid && (phy_type == EMIF_PHY_TYPE_ATTILAPHY);\r\nbreak;\r\ncase EMIF_4D5:\r\nvalid = valid && (phy_type == EMIF_PHY_TYPE_INTELLIPHY);\r\nbreak;\r\ndefault:\r\nvalid = 0;\r\n}\r\nif (!valid)\r\ndev_err(dev, "%s: invalid DDR details\n", __func__);\r\nreturn valid;\r\n}\r\nstatic int is_custom_config_valid(struct emif_custom_configs *cust_cfgs,\r\nstruct device *dev)\r\n{\r\nint valid = 1;\r\nif ((cust_cfgs->mask & EMIF_CUSTOM_CONFIG_LPMODE) &&\r\n(cust_cfgs->lpmode != EMIF_LP_MODE_DISABLE))\r\nvalid = cust_cfgs->lpmode_freq_threshold &&\r\ncust_cfgs->lpmode_timeout_performance &&\r\ncust_cfgs->lpmode_timeout_power;\r\nif (cust_cfgs->mask & EMIF_CUSTOM_CONFIG_TEMP_ALERT_POLL_INTERVAL)\r\nvalid = valid && cust_cfgs->temp_alert_poll_interval_ms;\r\nif (!valid)\r\ndev_warn(dev, "%s: invalid custom configs\n", __func__);\r\nreturn valid;\r\n}\r\nstatic struct emif_data *__init_or_module get_device_details(\r\nstruct platform_device *pdev)\r\n{\r\nu32 size;\r\nstruct emif_data *emif = NULL;\r\nstruct ddr_device_info *dev_info;\r\nstruct emif_custom_configs *cust_cfgs;\r\nstruct emif_platform_data *pd;\r\nstruct device *dev;\r\nvoid *temp;\r\npd = pdev->dev.platform_data;\r\ndev = &pdev->dev;\r\nif (!(pd && pd->device_info && is_dev_data_valid(pd->device_info->type,\r\npd->device_info->density, pd->device_info->io_width,\r\npd->phy_type, pd->ip_rev, dev))) {\r\ndev_err(dev, "%s: invalid device data\n", __func__);\r\ngoto error;\r\n}\r\nemif = devm_kzalloc(dev, sizeof(*emif), GFP_KERNEL);\r\ntemp = devm_kzalloc(dev, sizeof(*pd), GFP_KERNEL);\r\ndev_info = devm_kzalloc(dev, sizeof(*dev_info), GFP_KERNEL);\r\nif (!emif || !pd || !dev_info) {\r\ndev_err(dev, "%s:%d: allocation error\n", __func__, __LINE__);\r\ngoto error;\r\n}\r\nmemcpy(temp, pd, sizeof(*pd));\r\npd = temp;\r\nmemcpy(dev_info, pd->device_info, sizeof(*dev_info));\r\npd->device_info = dev_info;\r\nemif->plat_data = pd;\r\nemif->dev = dev;\r\nemif->temperature_level = SDRAM_TEMP_NOMINAL;\r\nemif->duplicate = emif1 && (memcmp(dev_info,\r\nemif1->plat_data->device_info,\r\nsizeof(struct ddr_device_info)) == 0);\r\nif (emif->duplicate) {\r\npd->timings = NULL;\r\npd->min_tck = NULL;\r\ngoto out;\r\n} else if (emif1) {\r\ndev_warn(emif->dev, "%s: Non-symmetric DDR geometry\n",\r\n__func__);\r\n}\r\ncust_cfgs = pd->custom_configs;\r\nif (cust_cfgs && is_custom_config_valid(cust_cfgs, dev)) {\r\ntemp = devm_kzalloc(dev, sizeof(*cust_cfgs), GFP_KERNEL);\r\nif (temp)\r\nmemcpy(temp, cust_cfgs, sizeof(*cust_cfgs));\r\nelse\r\ndev_warn(dev, "%s:%d: allocation error\n", __func__,\r\n__LINE__);\r\npd->custom_configs = temp;\r\n}\r\nsize = sizeof(struct lpddr2_timings) * pd->timings_arr_size;\r\nif (pd->timings) {\r\ntemp = devm_kzalloc(dev, size, GFP_KERNEL);\r\nif (temp) {\r\nmemcpy(temp, pd->timings, sizeof(*pd->timings));\r\npd->timings = temp;\r\n} else {\r\ndev_warn(dev, "%s:%d: allocation error\n", __func__,\r\n__LINE__);\r\nget_default_timings(emif);\r\n}\r\n} else {\r\nget_default_timings(emif);\r\n}\r\nif (pd->min_tck) {\r\ntemp = devm_kzalloc(dev, sizeof(*pd->min_tck), GFP_KERNEL);\r\nif (temp) {\r\nmemcpy(temp, pd->min_tck, sizeof(*pd->min_tck));\r\npd->min_tck = temp;\r\n} else {\r\ndev_warn(dev, "%s:%d: allocation error\n", __func__,\r\n__LINE__);\r\npd->min_tck = &lpddr2_jedec_min_tck;\r\n}\r\n} else {\r\npd->min_tck = &lpddr2_jedec_min_tck;\r\n}\r\nout:\r\nreturn emif;\r\nerror:\r\nreturn NULL;\r\n}\r\nstatic int __init_or_module emif_probe(struct platform_device *pdev)\r\n{\r\nstruct emif_data *emif;\r\nstruct resource *res;\r\nint irq;\r\nemif = get_device_details(pdev);\r\nif (!emif) {\r\npr_err("%s: error getting device data\n", __func__);\r\ngoto error;\r\n}\r\nlist_add(&emif->node, &device_list);\r\nemif->addressing = get_addressing_table(emif->plat_data->device_info);\r\nemif->dev = &pdev->dev;\r\nplatform_set_drvdata(pdev, emif);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(emif->dev, "%s: error getting memory resource\n",\r\n__func__);\r\ngoto error;\r\n}\r\nemif->base = devm_request_and_ioremap(emif->dev, res);\r\nif (!emif->base) {\r\ndev_err(emif->dev, "%s: devm_request_and_ioremap() failed\n",\r\n__func__);\r\ngoto error;\r\n}\r\nirq = platform_get_irq(pdev, 0);\r\nif (irq < 0) {\r\ndev_err(emif->dev, "%s: error getting IRQ resource - %d\n",\r\n__func__, irq);\r\ngoto error;\r\n}\r\nemif_onetime_settings(emif);\r\nemif_debugfs_init(emif);\r\ndisable_and_clear_all_interrupts(emif);\r\nsetup_interrupts(emif, irq);\r\nif (!emif1) {\r\nemif1 = emif;\r\nspin_lock_init(&emif_lock);\r\n}\r\ndev_info(&pdev->dev, "%s: device configured with addr = %p and IRQ%d\n",\r\n__func__, emif->base, irq);\r\nreturn 0;\r\nerror:\r\nreturn -ENODEV;\r\n}\r\nstatic int __exit emif_remove(struct platform_device *pdev)\r\n{\r\nstruct emif_data *emif = platform_get_drvdata(pdev);\r\nemif_debugfs_exit(emif);\r\nreturn 0;\r\n}\r\nstatic void emif_shutdown(struct platform_device *pdev)\r\n{\r\nstruct emif_data *emif = platform_get_drvdata(pdev);\r\ndisable_and_clear_all_interrupts(emif);\r\n}\r\nstatic int get_emif_reg_values(struct emif_data *emif, u32 freq,\r\nstruct emif_regs *regs)\r\n{\r\nu32 cs1_used, ip_rev, phy_type;\r\nu32 cl, type;\r\nconst struct lpddr2_timings *timings;\r\nconst struct lpddr2_min_tck *min_tck;\r\nconst struct ddr_device_info *device_info;\r\nconst struct lpddr2_addressing *addressing;\r\nstruct emif_data *emif_for_calc;\r\nstruct device *dev;\r\nconst struct emif_custom_configs *custom_configs;\r\ndev = emif->dev;\r\nemif_for_calc = emif->duplicate ? emif1 : emif;\r\ntimings = get_timings_table(emif_for_calc, freq);\r\naddressing = emif_for_calc->addressing;\r\nif (!timings || !addressing) {\r\ndev_err(dev, "%s: not enough data available for %dHz",\r\n__func__, freq);\r\nreturn -1;\r\n}\r\ndevice_info = emif_for_calc->plat_data->device_info;\r\ntype = device_info->type;\r\ncs1_used = device_info->cs1_used;\r\nip_rev = emif_for_calc->plat_data->ip_rev;\r\nphy_type = emif_for_calc->plat_data->phy_type;\r\nmin_tck = emif_for_calc->plat_data->min_tck;\r\ncustom_configs = emif_for_calc->plat_data->custom_configs;\r\nset_ddr_clk_period(freq);\r\nregs->ref_ctrl_shdw = get_sdram_ref_ctrl_shdw(freq, addressing);\r\nregs->sdram_tim1_shdw = get_sdram_tim_1_shdw(timings, min_tck,\r\naddressing);\r\nregs->sdram_tim2_shdw = get_sdram_tim_2_shdw(timings, min_tck,\r\naddressing, type);\r\nregs->sdram_tim3_shdw = get_sdram_tim_3_shdw(timings, min_tck,\r\naddressing, type, ip_rev, EMIF_NORMAL_TIMINGS);\r\ncl = get_cl(emif);\r\nif (phy_type == EMIF_PHY_TYPE_ATTILAPHY && ip_rev == EMIF_4D) {\r\nregs->phy_ctrl_1_shdw = get_ddr_phy_ctrl_1_attilaphy_4d(\r\ntimings, freq, cl);\r\n} else if (phy_type == EMIF_PHY_TYPE_INTELLIPHY && ip_rev == EMIF_4D5) {\r\nregs->phy_ctrl_1_shdw = get_phy_ctrl_1_intelliphy_4d5(freq, cl);\r\nregs->ext_phy_ctrl_2_shdw = get_ext_phy_ctrl_2_intelliphy_4d5();\r\nregs->ext_phy_ctrl_3_shdw = get_ext_phy_ctrl_3_intelliphy_4d5();\r\nregs->ext_phy_ctrl_4_shdw = get_ext_phy_ctrl_4_intelliphy_4d5();\r\n} else {\r\nreturn -1;\r\n}\r\nregs->pwr_mgmt_ctrl_shdw =\r\nget_pwr_mgmt_ctrl(freq, emif_for_calc, ip_rev) &\r\n(CS_TIM_MASK | SR_TIM_MASK | PD_TIM_MASK);\r\nif (ip_rev & EMIF_4D) {\r\nregs->read_idle_ctrl_shdw_normal =\r\nget_read_idle_ctrl_shdw(DDR_VOLTAGE_STABLE);\r\nregs->read_idle_ctrl_shdw_volt_ramp =\r\nget_read_idle_ctrl_shdw(DDR_VOLTAGE_RAMPING);\r\n} else if (ip_rev & EMIF_4D5) {\r\nregs->dll_calib_ctrl_shdw_normal =\r\nget_dll_calib_ctrl_shdw(DDR_VOLTAGE_STABLE);\r\nregs->dll_calib_ctrl_shdw_volt_ramp =\r\nget_dll_calib_ctrl_shdw(DDR_VOLTAGE_RAMPING);\r\n}\r\nif (type == DDR_TYPE_LPDDR2_S2 || type == DDR_TYPE_LPDDR2_S4) {\r\nregs->ref_ctrl_shdw_derated = get_sdram_ref_ctrl_shdw(freq / 4,\r\naddressing);\r\nregs->sdram_tim1_shdw_derated =\r\nget_sdram_tim_1_shdw_derated(timings, min_tck,\r\naddressing);\r\nregs->sdram_tim3_shdw_derated = get_sdram_tim_3_shdw(timings,\r\nmin_tck, addressing, type, ip_rev,\r\nEMIF_DERATED_TIMINGS);\r\n}\r\nregs->freq = freq;\r\nreturn 0;\r\n}\r\nstatic struct emif_regs *get_regs(struct emif_data *emif, u32 freq)\r\n{\r\nint i;\r\nstruct emif_regs **regs_cache;\r\nstruct emif_regs *regs = NULL;\r\nstruct device *dev;\r\ndev = emif->dev;\r\nif (emif->curr_regs && emif->curr_regs->freq == freq) {\r\ndev_dbg(dev, "%s: using curr_regs - %u Hz", __func__, freq);\r\nreturn emif->curr_regs;\r\n}\r\nif (emif->duplicate)\r\nregs_cache = emif1->regs_cache;\r\nelse\r\nregs_cache = emif->regs_cache;\r\nfor (i = 0; i < EMIF_MAX_NUM_FREQUENCIES && regs_cache[i]; i++) {\r\nif (regs_cache[i]->freq == freq) {\r\nregs = regs_cache[i];\r\ndev_dbg(dev,\r\n"%s: reg dump found in reg cache for %u Hz\n",\r\n__func__, freq);\r\nbreak;\r\n}\r\n}\r\nif (!regs) {\r\nregs = devm_kzalloc(emif->dev, sizeof(*regs), GFP_ATOMIC);\r\nif (!regs)\r\nreturn NULL;\r\nif (get_emif_reg_values(emif, freq, regs)) {\r\ndevm_kfree(emif->dev, regs);\r\nreturn NULL;\r\n}\r\nfor (i = 0; i < EMIF_MAX_NUM_FREQUENCIES && regs_cache[i]; i++)\r\n;\r\nif (i >= EMIF_MAX_NUM_FREQUENCIES) {\r\ndev_warn(dev, "%s: regs_cache full - reusing a slot!!\n",\r\n__func__);\r\ni = EMIF_MAX_NUM_FREQUENCIES - 1;\r\ndevm_kfree(emif->dev, regs_cache[i]);\r\n}\r\nregs_cache[i] = regs;\r\n}\r\nreturn regs;\r\n}\r\nstatic void do_volt_notify_handling(struct emif_data *emif, u32 volt_state)\r\n{\r\ndev_dbg(emif->dev, "%s: voltage notification : %d", __func__,\r\nvolt_state);\r\nif (!emif->curr_regs) {\r\ndev_err(emif->dev,\r\n"%s: volt-notify before registers are ready: %d\n",\r\n__func__, volt_state);\r\nreturn;\r\n}\r\nsetup_volt_sensitive_regs(emif, emif->curr_regs, volt_state);\r\n}\r\nstatic void do_freq_pre_notify_handling(struct emif_data *emif, u32 new_freq)\r\n{\r\nstruct emif_regs *regs;\r\nregs = get_regs(emif, new_freq);\r\nif (!regs)\r\nreturn;\r\nemif->curr_regs = regs;\r\ndev_dbg(emif->dev, "%s: setting up shadow registers for %uHz",\r\n__func__, new_freq);\r\nsetup_registers(emif, regs);\r\nsetup_temperature_sensitive_regs(emif, regs);\r\nsetup_volt_sensitive_regs(emif, regs, DDR_VOLTAGE_STABLE);\r\nif (emif->lpmode == EMIF_LP_MODE_SELF_REFRESH)\r\nset_lpmode(emif, EMIF_LP_MODE_DISABLE);\r\n}\r\nstatic void do_freq_post_notify_handling(struct emif_data *emif)\r\n{\r\nif (emif->lpmode == EMIF_LP_MODE_SELF_REFRESH)\r\nset_lpmode(emif, EMIF_LP_MODE_SELF_REFRESH);\r\n}\r\nstatic int __init_or_module emif_register(void)\r\n{\r\nreturn platform_driver_probe(&emif_driver, emif_probe);\r\n}\r\nstatic void __exit emif_unregister(void)\r\n{\r\nplatform_driver_unregister(&emif_driver);\r\n}
