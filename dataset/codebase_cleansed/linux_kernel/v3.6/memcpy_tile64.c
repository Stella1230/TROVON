static void memcpy_multicache(void *dest, const void *source,\r\npte_t dst_pte, pte_t src_pte, int len)\r\n{\r\nint idx;\r\nunsigned long flags, newsrc, newdst;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\nint type0, type1;\r\nint cpu = get_cpu();\r\nlocal_irq_save(flags);\r\nsim_allow_multiple_caching(1);\r\ntype0 = kmap_atomic_idx_push();\r\nidx = FIX_KMAP_BEGIN + (KM_TYPE_NR * cpu) + type0;\r\nnewdst = __fix_to_virt(idx) + ((unsigned long)dest & (PAGE_SIZE-1));\r\npmdp = pmd_offset(pud_offset(pgd_offset_k(newdst), newdst), newdst);\r\nptep = pte_offset_kernel(pmdp, newdst);\r\nif (pte_val(*ptep) != pte_val(dst_pte)) {\r\nset_pte(ptep, dst_pte);\r\nlocal_flush_tlb_page(NULL, newdst, PAGE_SIZE);\r\n}\r\ntype1 = kmap_atomic_idx_push();\r\nidx += (type0 - type1);\r\nsrc_pte = hv_pte_set_nc(src_pte);\r\nsrc_pte = hv_pte_clear_writable(src_pte);\r\nnewsrc = __fix_to_virt(idx) + ((unsigned long)source & (PAGE_SIZE-1));\r\npmdp = pmd_offset(pud_offset(pgd_offset_k(newsrc), newsrc), newsrc);\r\nptep = pte_offset_kernel(pmdp, newsrc);\r\n__set_pte(ptep, src_pte);\r\nlocal_flush_tlb_page(NULL, newsrc, PAGE_SIZE);\r\n__memcpy_asm((void *)newdst, (const void *)newsrc, len);\r\nsrc_pte = hv_pte_set_mode(src_pte, HV_PTE_MODE_CACHE_NO_L3);\r\nsrc_pte = hv_pte_set_writable(src_pte);\r\n__set_pte(ptep, src_pte);\r\nlocal_flush_tlb_page(NULL, newsrc, PAGE_SIZE);\r\n__inv_buffer((void *)newsrc, len);\r\nkmap_atomic_idx_pop();\r\nkmap_atomic_idx_pop();\r\nsim_allow_multiple_caching(0);\r\nlocal_irq_restore(flags);\r\nput_cpu();\r\n}\r\nstatic unsigned long fast_copy(void *dest, const void *source, int len,\r\nmemcpy_t func)\r\n{\r\nwhile (len >= LARGE_COPY_CUTOFF) {\r\nint copy_size, bytes_left_on_page;\r\npte_t *src_ptep, *dst_ptep;\r\npte_t src_pte, dst_pte;\r\nstruct page *src_page, *dst_page;\r\nretry_source:\r\nsrc_ptep = virt_to_pte(current->mm, (unsigned long)source);\r\nif (src_ptep == NULL)\r\nbreak;\r\nsrc_pte = *src_ptep;\r\nif (!hv_pte_get_present(src_pte) ||\r\n!hv_pte_get_readable(src_pte) ||\r\nhv_pte_get_mode(src_pte) != HV_PTE_MODE_CACHE_TILE_L3)\r\nbreak;\r\nif (get_remote_cache_cpu(src_pte) == smp_processor_id())\r\nbreak;\r\nsrc_page = pfn_to_page(pte_pfn(src_pte));\r\nget_page(src_page);\r\nif (pte_val(src_pte) != pte_val(*src_ptep)) {\r\nput_page(src_page);\r\ngoto retry_source;\r\n}\r\nif (pte_huge(src_pte)) {\r\nint pfn = pte_pfn(src_pte);\r\npfn += (((unsigned long)source & (HPAGE_SIZE-1))\r\n>> PAGE_SHIFT);\r\nsrc_pte = pfn_pte(pfn, src_pte);\r\nsrc_pte = pte_mksmall(src_pte);\r\n}\r\nretry_dest:\r\ndst_ptep = virt_to_pte(current->mm, (unsigned long)dest);\r\nif (dst_ptep == NULL) {\r\nput_page(src_page);\r\nbreak;\r\n}\r\ndst_pte = *dst_ptep;\r\nif (!hv_pte_get_present(dst_pte) ||\r\n!hv_pte_get_writable(dst_pte)) {\r\nput_page(src_page);\r\nbreak;\r\n}\r\ndst_page = pfn_to_page(pte_pfn(dst_pte));\r\nif (dst_page == src_page) {\r\nput_page(src_page);\r\nbreak;\r\n}\r\nget_page(dst_page);\r\nif (pte_val(dst_pte) != pte_val(*dst_ptep)) {\r\nput_page(dst_page);\r\ngoto retry_dest;\r\n}\r\nif (pte_huge(dst_pte)) {\r\nint pfn = pte_pfn(dst_pte);\r\npfn += (((unsigned long)dest & (HPAGE_SIZE-1))\r\n>> PAGE_SHIFT);\r\ndst_pte = pfn_pte(pfn, dst_pte);\r\ndst_pte = pte_mksmall(dst_pte);\r\n}\r\ncopy_size = len;\r\nbytes_left_on_page =\r\nPAGE_SIZE - (((int)source) & (PAGE_SIZE-1));\r\nif (copy_size > bytes_left_on_page)\r\ncopy_size = bytes_left_on_page;\r\nbytes_left_on_page =\r\nPAGE_SIZE - (((int)dest) & (PAGE_SIZE-1));\r\nif (copy_size > bytes_left_on_page)\r\ncopy_size = bytes_left_on_page;\r\nmemcpy_multicache(dest, source, dst_pte, src_pte, copy_size);\r\nput_page(dst_page);\r\nput_page(src_page);\r\ndest += copy_size;\r\nsource += copy_size;\r\nlen -= copy_size;\r\n}\r\nreturn func(dest, source, len);\r\n}\r\nvoid *memcpy(void *to, const void *from, __kernel_size_t n)\r\n{\r\nif (n < LARGE_COPY_CUTOFF)\r\nreturn (void *)__memcpy_asm(to, from, n);\r\nelse\r\nreturn (void *)fast_copy(to, from, n, __memcpy_asm);\r\n}\r\nunsigned long __copy_to_user_inatomic(void __user *to, const void *from,\r\nunsigned long n)\r\n{\r\nif (n < LARGE_COPY_CUTOFF)\r\nreturn __copy_to_user_inatomic_asm(to, from, n);\r\nelse\r\nreturn fast_copy(to, from, n, __copy_to_user_inatomic_asm);\r\n}\r\nunsigned long __copy_from_user_inatomic(void *to, const void __user *from,\r\nunsigned long n)\r\n{\r\nif (n < LARGE_COPY_CUTOFF)\r\nreturn __copy_from_user_inatomic_asm(to, from, n);\r\nelse\r\nreturn fast_copy(to, from, n, __copy_from_user_inatomic_asm);\r\n}\r\nunsigned long __copy_from_user_zeroing(void *to, const void __user *from,\r\nunsigned long n)\r\n{\r\nif (n < LARGE_COPY_CUTOFF)\r\nreturn __copy_from_user_zeroing_asm(to, from, n);\r\nelse\r\nreturn fast_copy(to, from, n, __copy_from_user_zeroing_asm);\r\n}
