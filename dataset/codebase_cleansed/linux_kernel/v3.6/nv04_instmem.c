static int\r\nnouveau_fifo_ctx_size(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nif (dev_priv->chipset >= 0x40)\r\nreturn 128 * 32;\r\nelse\r\nif (dev_priv->chipset >= 0x17)\r\nreturn 64 * 32;\r\nelse\r\nif (dev_priv->chipset >= 0x10)\r\nreturn 32 * 32;\r\nreturn 32 * 16;\r\n}\r\nint nv04_instmem_init(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj *ramht = NULL;\r\nu32 offset, length;\r\nint ret;\r\ndev_priv->ramin_available = true;\r\nif (dev_priv->card_type >= NV_40) {\r\nu32 vs = hweight8((nv_rd32(dev, 0x001540) & 0x0000ff00) >> 8);\r\nu32 rsvd;\r\nif (dev_priv->chipset == 0x40) rsvd = 0x6aa0 * vs;\r\nelse if (dev_priv->chipset < 0x43) rsvd = 0x4f00 * vs;\r\nelse if (nv44_graph_class(dev)) rsvd = 0x4980 * vs;\r\nelse rsvd = 0x4a40 * vs;\r\nrsvd += 16 * 1024;\r\nrsvd *= 32;\r\nrsvd += 512 * 1024;\r\nrsvd += 512 * 1024;\r\ndev_priv->ramin_rsvd_vram = round_up(rsvd, 4096);\r\n} else {\r\ndev_priv->ramin_rsvd_vram = 512 * 1024;\r\n}\r\nret = nouveau_gpuobj_new_fake(dev, 0x10000, ~0, 4096,\r\nNVOBJ_FLAG_ZERO_ALLOC, &ramht);\r\nif (ret)\r\nreturn ret;\r\nret = nouveau_ramht_new(dev, ramht, &dev_priv->ramht);\r\nnouveau_gpuobj_ref(NULL, &ramht);\r\nif (ret)\r\nreturn ret;\r\nret = nouveau_gpuobj_new_fake(dev, 0x11200, ~0, 512,\r\nNVOBJ_FLAG_ZERO_ALLOC, &dev_priv->ramro);\r\nif (ret)\r\nreturn ret;\r\nlength = nouveau_fifo_ctx_size(dev);\r\nswitch (dev_priv->card_type) {\r\ncase NV_40:\r\noffset = 0x20000;\r\nbreak;\r\ndefault:\r\noffset = 0x11400;\r\nbreak;\r\n}\r\nret = nouveau_gpuobj_new_fake(dev, offset, ~0, length,\r\nNVOBJ_FLAG_ZERO_ALLOC, &dev_priv->ramfc);\r\nif (ret)\r\nreturn ret;\r\noffset += length;\r\nif (dev_priv->card_type >= NV_40) {\r\nif (offset < 0x40000)\r\noffset = 0x40000;\r\n}\r\nret = drm_mm_init(&dev_priv->ramin_heap, offset,\r\ndev_priv->ramin_rsvd_vram - offset);\r\nif (ret) {\r\nNV_ERROR(dev, "Failed to init RAMIN heap: %d\n", ret);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nnv04_instmem_takedown(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nnouveau_ramht_ref(NULL, &dev_priv->ramht, NULL);\r\nnouveau_gpuobj_ref(NULL, &dev_priv->ramro);\r\nnouveau_gpuobj_ref(NULL, &dev_priv->ramfc);\r\nif (drm_mm_initialized(&dev_priv->ramin_heap))\r\ndrm_mm_takedown(&dev_priv->ramin_heap);\r\n}\r\nint\r\nnv04_instmem_suspend(struct drm_device *dev)\r\n{\r\nreturn 0;\r\n}\r\nvoid\r\nnv04_instmem_resume(struct drm_device *dev)\r\n{\r\n}\r\nint\r\nnv04_instmem_get(struct nouveau_gpuobj *gpuobj, struct nouveau_channel *chan,\r\nu32 size, u32 align)\r\n{\r\nstruct drm_nouveau_private *dev_priv = gpuobj->dev->dev_private;\r\nstruct drm_mm_node *ramin = NULL;\r\ndo {\r\nif (drm_mm_pre_get(&dev_priv->ramin_heap))\r\nreturn -ENOMEM;\r\nspin_lock(&dev_priv->ramin_lock);\r\nramin = drm_mm_search_free(&dev_priv->ramin_heap, size, align, 0);\r\nif (ramin == NULL) {\r\nspin_unlock(&dev_priv->ramin_lock);\r\nreturn -ENOMEM;\r\n}\r\nramin = drm_mm_get_block_atomic(ramin, size, align);\r\nspin_unlock(&dev_priv->ramin_lock);\r\n} while (ramin == NULL);\r\ngpuobj->node = ramin;\r\ngpuobj->vinst = ramin->start;\r\nreturn 0;\r\n}\r\nvoid\r\nnv04_instmem_put(struct nouveau_gpuobj *gpuobj)\r\n{\r\nstruct drm_nouveau_private *dev_priv = gpuobj->dev->dev_private;\r\nspin_lock(&dev_priv->ramin_lock);\r\ndrm_mm_put_block(gpuobj->node);\r\ngpuobj->node = NULL;\r\nspin_unlock(&dev_priv->ramin_lock);\r\n}\r\nint\r\nnv04_instmem_map(struct nouveau_gpuobj *gpuobj)\r\n{\r\ngpuobj->pinst = gpuobj->vinst;\r\nreturn 0;\r\n}\r\nvoid\r\nnv04_instmem_unmap(struct nouveau_gpuobj *gpuobj)\r\n{\r\n}\r\nvoid\r\nnv04_instmem_flush(struct drm_device *dev)\r\n{\r\n}
