const char *fnic_state_to_str(unsigned int state)\r\n{\r\nif (state >= ARRAY_SIZE(fnic_state_str) || !fnic_state_str[state])\r\nreturn "unknown";\r\nreturn fnic_state_str[state];\r\n}\r\nstatic const char *fnic_ioreq_state_to_str(unsigned int state)\r\n{\r\nif (state >= ARRAY_SIZE(fnic_ioreq_state_str) ||\r\n!fnic_ioreq_state_str[state])\r\nreturn "unknown";\r\nreturn fnic_ioreq_state_str[state];\r\n}\r\nstatic const char *fnic_fcpio_status_to_str(unsigned int status)\r\n{\r\nif (status >= ARRAY_SIZE(fcpio_status_str) || !fcpio_status_str[status])\r\nreturn "unknown";\r\nreturn fcpio_status_str[status];\r\n}\r\nstatic inline spinlock_t *fnic_io_lock_hash(struct fnic *fnic,\r\nstruct scsi_cmnd *sc)\r\n{\r\nu32 hash = sc->request->tag & (FNIC_IO_LOCKS - 1);\r\nreturn &fnic->io_req_lock[hash];\r\n}\r\nstatic void fnic_release_ioreq_buf(struct fnic *fnic,\r\nstruct fnic_io_req *io_req,\r\nstruct scsi_cmnd *sc)\r\n{\r\nif (io_req->sgl_list_pa)\r\npci_unmap_single(fnic->pdev, io_req->sgl_list_pa,\r\nsizeof(io_req->sgl_list[0]) * io_req->sgl_cnt,\r\nPCI_DMA_TODEVICE);\r\nscsi_dma_unmap(sc);\r\nif (io_req->sgl_cnt)\r\nmempool_free(io_req->sgl_list_alloc,\r\nfnic->io_sgl_pool[io_req->sgl_type]);\r\nif (io_req->sense_buf_pa)\r\npci_unmap_single(fnic->pdev, io_req->sense_buf_pa,\r\nSCSI_SENSE_BUFFERSIZE, PCI_DMA_FROMDEVICE);\r\n}\r\nstatic int free_wq_copy_descs(struct fnic *fnic, struct vnic_wq_copy *wq)\r\n{\r\nif (!fnic->fw_ack_recd[0])\r\nreturn 1;\r\nif (wq->to_clean_index <= fnic->fw_ack_index[0])\r\nwq->ring.desc_avail += (fnic->fw_ack_index[0]\r\n- wq->to_clean_index + 1);\r\nelse\r\nwq->ring.desc_avail += (wq->ring.desc_count\r\n- wq->to_clean_index\r\n+ fnic->fw_ack_index[0] + 1);\r\nwq->to_clean_index =\r\n(fnic->fw_ack_index[0] + 1) % wq->ring.desc_count;\r\nfnic->fw_ack_recd[0] = 0;\r\nreturn 0;\r\n}\r\nint fnic_fw_reset_handler(struct fnic *fnic)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nint ret = 0;\r\nunsigned long flags;\r\nskb_queue_purge(&fnic->frame_queue);\r\nskb_queue_purge(&fnic->tx_queue);\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq))\r\nret = -EAGAIN;\r\nelse\r\nfnic_queue_wq_copy_desc_fw_reset(wq, SCSI_NO_TAG);\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\nif (!ret)\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Issued fw reset\n");\r\nelse\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Failed to issue fw reset\n");\r\nreturn ret;\r\n}\r\nint fnic_flogi_reg_handler(struct fnic *fnic, u32 fc_id)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nenum fcpio_flogi_reg_format_type format;\r\nstruct fc_lport *lp = fnic->lport;\r\nu8 gw_mac[ETH_ALEN];\r\nint ret = 0;\r\nunsigned long flags;\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq)) {\r\nret = -EAGAIN;\r\ngoto flogi_reg_ioreq_end;\r\n}\r\nif (fnic->ctlr.map_dest) {\r\nmemset(gw_mac, 0xff, ETH_ALEN);\r\nformat = FCPIO_FLOGI_REG_DEF_DEST;\r\n} else {\r\nmemcpy(gw_mac, fnic->ctlr.dest_addr, ETH_ALEN);\r\nformat = FCPIO_FLOGI_REG_GW_DEST;\r\n}\r\nif ((fnic->config.flags & VFCF_FIP_CAPABLE) && !fnic->ctlr.map_dest) {\r\nfnic_queue_wq_copy_desc_fip_reg(wq, SCSI_NO_TAG,\r\nfc_id, gw_mac,\r\nfnic->data_src_addr,\r\nlp->r_a_tov, lp->e_d_tov);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"FLOGI FIP reg issued fcid %x src %pM dest %pM\n",\r\nfc_id, fnic->data_src_addr, gw_mac);\r\n} else {\r\nfnic_queue_wq_copy_desc_flogi_reg(wq, SCSI_NO_TAG,\r\nformat, fc_id, gw_mac);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"FLOGI reg issued fcid %x map %d dest %pM\n",\r\nfc_id, fnic->ctlr.map_dest, gw_mac);\r\n}\r\nflogi_reg_ioreq_end:\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\nreturn ret;\r\n}\r\nstatic inline int fnic_queue_wq_copy_desc(struct fnic *fnic,\r\nstruct vnic_wq_copy *wq,\r\nstruct fnic_io_req *io_req,\r\nstruct scsi_cmnd *sc,\r\nint sg_count)\r\n{\r\nstruct scatterlist *sg;\r\nstruct fc_rport *rport = starget_to_rport(scsi_target(sc->device));\r\nstruct fc_rport_libfc_priv *rp = rport->dd_data;\r\nstruct host_sg_desc *desc;\r\nu8 pri_tag = 0;\r\nunsigned int i;\r\nunsigned long intr_flags;\r\nint flags;\r\nu8 exch_flags;\r\nstruct scsi_lun fc_lun;\r\nchar msg[2];\r\nif (sg_count) {\r\ndesc = io_req->sgl_list;\r\nfor_each_sg(scsi_sglist(sc), sg, sg_count, i) {\r\ndesc->addr = cpu_to_le64(sg_dma_address(sg));\r\ndesc->len = cpu_to_le32(sg_dma_len(sg));\r\ndesc->_resvd = 0;\r\ndesc++;\r\n}\r\nio_req->sgl_list_pa = pci_map_single\r\n(fnic->pdev,\r\nio_req->sgl_list,\r\nsizeof(io_req->sgl_list[0]) * sg_count,\r\nPCI_DMA_TODEVICE);\r\n}\r\nio_req->sense_buf_pa = pci_map_single(fnic->pdev,\r\nsc->sense_buffer,\r\nSCSI_SENSE_BUFFERSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\npri_tag = FCPIO_ICMND_PTA_SIMPLE;\r\nmsg[0] = MSG_SIMPLE_TAG;\r\nscsi_populate_tag_msg(sc, msg);\r\nif (msg[0] == MSG_ORDERED_TAG)\r\npri_tag = FCPIO_ICMND_PTA_ORDERED;\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], intr_flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (unlikely(!vnic_wq_copy_desc_avail(wq))) {\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], intr_flags);\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\n}\r\nflags = 0;\r\nif (sc->sc_data_direction == DMA_FROM_DEVICE)\r\nflags = FCPIO_ICMND_RDDATA;\r\nelse if (sc->sc_data_direction == DMA_TO_DEVICE)\r\nflags = FCPIO_ICMND_WRDATA;\r\nexch_flags = 0;\r\nif ((fnic->config.flags & VFCF_FCP_SEQ_LVL_ERR) &&\r\n(rp->flags & FC_RP_FLAGS_RETRY))\r\nexch_flags |= FCPIO_ICMND_SRFLAG_RETRY;\r\nfnic_queue_wq_copy_desc_icmnd_16(wq, sc->request->tag,\r\n0, exch_flags, io_req->sgl_cnt,\r\nSCSI_SENSE_BUFFERSIZE,\r\nio_req->sgl_list_pa,\r\nio_req->sense_buf_pa,\r\n0,\r\npri_tag,\r\nflags,\r\nsc->cmnd, sc->cmd_len,\r\nscsi_bufflen(sc),\r\nfc_lun.scsi_lun, io_req->port_id,\r\nrport->maxframe_size, rp->r_a_tov,\r\nrp->e_d_tov);\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], intr_flags);\r\nreturn 0;\r\n}\r\nstatic int fnic_queuecommand_lck(struct scsi_cmnd *sc, void (*done)(struct scsi_cmnd *))\r\n{\r\nstruct fc_lport *lp;\r\nstruct fc_rport *rport;\r\nstruct fnic_io_req *io_req;\r\nstruct fnic *fnic;\r\nstruct vnic_wq_copy *wq;\r\nint ret;\r\nint sg_count;\r\nunsigned long flags;\r\nunsigned long ptr;\r\nrport = starget_to_rport(scsi_target(sc->device));\r\nret = fc_remote_port_chkready(rport);\r\nif (ret) {\r\nsc->result = ret;\r\ndone(sc);\r\nreturn 0;\r\n}\r\nlp = shost_priv(sc->device->host);\r\nif (lp->state != LPORT_ST_READY || !(lp->link_up))\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\nspin_unlock(lp->host->host_lock);\r\nfnic = lport_priv(lp);\r\nio_req = mempool_alloc(fnic->io_req_pool, GFP_ATOMIC);\r\nif (!io_req) {\r\nret = SCSI_MLQUEUE_HOST_BUSY;\r\ngoto out;\r\n}\r\nmemset(io_req, 0, sizeof(*io_req));\r\nsg_count = scsi_dma_map(sc);\r\nif (sg_count < 0) {\r\nmempool_free(io_req, fnic->io_req_pool);\r\ngoto out;\r\n}\r\nio_req->sgl_cnt = sg_count;\r\nio_req->sgl_type = FNIC_SGL_CACHE_DFLT;\r\nif (sg_count > FNIC_DFLT_SG_DESC_CNT)\r\nio_req->sgl_type = FNIC_SGL_CACHE_MAX;\r\nif (sg_count) {\r\nio_req->sgl_list =\r\nmempool_alloc(fnic->io_sgl_pool[io_req->sgl_type],\r\nGFP_ATOMIC);\r\nif (!io_req->sgl_list) {\r\nret = SCSI_MLQUEUE_HOST_BUSY;\r\nscsi_dma_unmap(sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\ngoto out;\r\n}\r\nio_req->sgl_list_alloc = io_req->sgl_list;\r\nptr = (unsigned long) io_req->sgl_list;\r\nif (ptr % FNIC_SG_DESC_ALIGN) {\r\nio_req->sgl_list = (struct host_sg_desc *)\r\n(((unsigned long) ptr\r\n+ FNIC_SG_DESC_ALIGN - 1)\r\n& ~(FNIC_SG_DESC_ALIGN - 1));\r\n}\r\n}\r\nio_req->port_id = rport->port_id;\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_PENDING;\r\nCMD_SP(sc) = (char *)io_req;\r\nsc->scsi_done = done;\r\nwq = &fnic->wq_copy[0];\r\nret = fnic_queue_wq_copy_desc(fnic, wq, io_req, sc, sg_count);\r\nif (ret) {\r\nspinlock_t *io_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nCMD_SP(sc) = NULL;\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_COMPLETE;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (io_req) {\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\n}\r\n}\r\nout:\r\nspin_lock(lp->host->host_lock);\r\nreturn ret;\r\n}\r\nstatic int fnic_fcpio_fw_reset_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nint ret = 0;\r\nunsigned long flags;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\nfnic_cleanup_io(fnic, SCSI_NO_TAG);\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE) {\r\nif (!hdr_status) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"reset cmpl success\n");\r\nfnic->state = FNIC_IN_ETH_MODE;\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic fw_reset : failed %s\n",\r\nfnic_fcpio_status_to_str(hdr_status));\r\nfnic->state = FNIC_IN_FC_MODE;\r\nret = -1;\r\n}\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"Unexpected state %s while processing"\r\n" reset cmpl\n", fnic_state_to_str(fnic->state));\r\nret = -1;\r\n}\r\nif (fnic->remove_wait)\r\ncomplete(fnic->remove_wait);\r\nif (fnic->remove_wait || ret) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nskb_queue_purge(&fnic->tx_queue);\r\ngoto reset_cmpl_handler_end;\r\n}\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nfnic_flush_tx(fnic);\r\nreset_cmpl_handler_end:\r\nreturn ret;\r\n}\r\nstatic int fnic_fcpio_flogi_reg_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nint ret = 0;\r\nunsigned long flags;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_ETH_TRANS_FC_MODE) {\r\nif (!hdr_status) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"flog reg succeeded\n");\r\nfnic->state = FNIC_IN_FC_MODE;\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic flogi reg :failed %s\n",\r\nfnic_fcpio_status_to_str(hdr_status));\r\nfnic->state = FNIC_IN_ETH_MODE;\r\nret = -1;\r\n}\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Unexpected fnic state %s while"\r\n" processing flogi reg completion\n",\r\nfnic_state_to_str(fnic->state));\r\nret = -1;\r\n}\r\nif (!ret) {\r\nif (fnic->stop_rx_link_events) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\ngoto reg_cmpl_handler_end;\r\n}\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nfnic_flush_tx(fnic);\r\nqueue_work(fnic_event_queue, &fnic->frame_work);\r\n} else {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\nreg_cmpl_handler_end:\r\nreturn ret;\r\n}\r\nstatic inline int is_ack_index_in_range(struct vnic_wq_copy *wq,\r\nu16 request_out)\r\n{\r\nif (wq->to_clean_index <= wq->to_use_index) {\r\nif (request_out < wq->to_clean_index ||\r\nrequest_out >= wq->to_use_index)\r\nreturn 0;\r\n} else {\r\nif (request_out < wq->to_clean_index &&\r\nrequest_out >= wq->to_use_index)\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic inline void fnic_fcpio_ack_handler(struct fnic *fnic,\r\nunsigned int cq_index,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nstruct vnic_wq_copy *wq;\r\nu16 request_out = desc->u.ack.request_out;\r\nunsigned long flags;\r\nwq = &fnic->wq_copy[cq_index - fnic->raw_wq_count - fnic->rq_count];\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nif (is_ack_index_in_range(wq, request_out)) {\r\nfnic->fw_ack_index[0] = request_out;\r\nfnic->fw_ack_recd[0] = 1;\r\n}\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\n}\r\nstatic void fnic_fcpio_icmnd_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nu32 id;\r\nu64 xfer_len = 0;\r\nstruct fcpio_icmnd_cmpl *icmnd_cmpl;\r\nstruct fnic_io_req *io_req;\r\nstruct scsi_cmnd *sc;\r\nunsigned long flags;\r\nspinlock_t *io_lock;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\nfcpio_tag_id_dec(&tag, &id);\r\nif (id >= FNIC_MAX_IO_REQ)\r\nreturn;\r\nsc = scsi_host_find_tag(fnic->lport->host, id);\r\nWARN_ON_ONCE(!sc);\r\nif (!sc)\r\nreturn;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nWARN_ON_ONCE(!io_req);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nreturn;\r\n}\r\nio_req->io_completed = 1;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nreturn;\r\n}\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_COMPLETE;\r\nicmnd_cmpl = &desc->u.icmnd_cmpl;\r\nswitch (hdr_status) {\r\ncase FCPIO_SUCCESS:\r\nsc->result = (DID_OK << 16) | icmnd_cmpl->scsi_status;\r\nxfer_len = scsi_bufflen(sc);\r\nscsi_set_resid(sc, icmnd_cmpl->residual);\r\nif (icmnd_cmpl->flags & FCPIO_ICMND_CMPL_RESID_UNDER)\r\nxfer_len -= icmnd_cmpl->residual;\r\nif (icmnd_cmpl->scsi_status == QUEUE_FULL) {\r\nstruct scsi_device *t_sdev;\r\nint qd = 0;\r\nshost_for_each_device(t_sdev, sc->device->host) {\r\nif (t_sdev->id != sc->device->id)\r\ncontinue;\r\nif (t_sdev->queue_depth > 1) {\r\nqd = scsi_track_queue_full\r\n(t_sdev,\r\nt_sdev->queue_depth - 1);\r\nif (qd == -1)\r\nqd = t_sdev->host->cmd_per_lun;\r\nshost_printk(KERN_INFO,\r\nfnic->lport->host,\r\n"scsi[%d:%d:%d:%d"\r\n"] queue full detected,"\r\n"new depth = %d\n",\r\nt_sdev->host->host_no,\r\nt_sdev->channel,\r\nt_sdev->id, t_sdev->lun,\r\nt_sdev->queue_depth);\r\n}\r\n}\r\n}\r\nbreak;\r\ncase FCPIO_TIMEOUT:\r\nsc->result = (DID_TIME_OUT << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_ABORTED:\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_DATA_CNT_MISMATCH:\r\nscsi_set_resid(sc, icmnd_cmpl->residual);\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_OUT_OF_RESOURCE:\r\nsc->result = (DID_REQUEUE << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_INVALID_HEADER:\r\ncase FCPIO_INVALID_PARAM:\r\ncase FCPIO_REQ_NOT_SUPPORTED:\r\ncase FCPIO_IO_NOT_FOUND:\r\ncase FCPIO_SGL_INVALID:\r\ncase FCPIO_MSS_INVALID:\r\ncase FCPIO_FW_ERR:\r\ndefault:\r\nshost_printk(KERN_ERR, fnic->lport->host, "hdr status = %s\n",\r\nfnic_fcpio_status_to_str(hdr_status));\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\n}\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\nif (sc->sc_data_direction == DMA_FROM_DEVICE) {\r\nfnic->lport->host_stats.fcp_input_requests++;\r\nfnic->fcp_input_bytes += xfer_len;\r\n} else if (sc->sc_data_direction == DMA_TO_DEVICE) {\r\nfnic->lport->host_stats.fcp_output_requests++;\r\nfnic->fcp_output_bytes += xfer_len;\r\n} else\r\nfnic->lport->host_stats.fcp_control_requests++;\r\nif (sc->scsi_done)\r\nsc->scsi_done(sc);\r\n}\r\nstatic void fnic_fcpio_itmf_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nu32 id;\r\nstruct scsi_cmnd *sc;\r\nstruct fnic_io_req *io_req;\r\nunsigned long flags;\r\nspinlock_t *io_lock;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\nfcpio_tag_id_dec(&tag, &id);\r\nif ((id & FNIC_TAG_MASK) >= FNIC_MAX_IO_REQ)\r\nreturn;\r\nsc = scsi_host_find_tag(fnic->lport->host, id & FNIC_TAG_MASK);\r\nWARN_ON_ONCE(!sc);\r\nif (!sc)\r\nreturn;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nWARN_ON_ONCE(!io_req);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nreturn;\r\n}\r\nif (id & FNIC_TAG_ABORT) {\r\nif (CMD_STATE(sc) != FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nreturn;\r\n}\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_COMPLETE;\r\nCMD_ABTS_STATUS(sc) = hdr_status;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"abts cmpl recd. id %d status %s\n",\r\n(int)(id & FNIC_TAG_MASK),\r\nfnic_fcpio_status_to_str(hdr_status));\r\nif (io_req->abts_done) {\r\ncomplete(io_req->abts_done);\r\nspin_unlock_irqrestore(io_lock, flags);\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"abts cmpl, completing IO\n");\r\nCMD_SP(sc) = NULL;\r\nsc->result = (DID_ERROR << 16);\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\nif (sc->scsi_done)\r\nsc->scsi_done(sc);\r\n}\r\n} else if (id & FNIC_TAG_DEV_RST) {\r\nCMD_LR_STATUS(sc) = hdr_status;\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_COMPLETE;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"dev reset cmpl recd. id %d status %s\n",\r\n(int)(id & FNIC_TAG_MASK),\r\nfnic_fcpio_status_to_str(hdr_status));\r\nif (io_req->dr_done)\r\ncomplete(io_req->dr_done);\r\nspin_unlock_irqrestore(io_lock, flags);\r\n} else {\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"Unexpected itmf io state %s tag %x\n",\r\nfnic_ioreq_state_to_str(CMD_STATE(sc)), id);\r\nspin_unlock_irqrestore(io_lock, flags);\r\n}\r\n}\r\nstatic int fnic_fcpio_cmpl_handler(struct vnic_dev *vdev,\r\nunsigned int cq_index,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nstruct fnic *fnic = vnic_dev_priv(vdev);\r\nint ret = 0;\r\nswitch (desc->hdr.type) {\r\ncase FCPIO_ACK:\r\nfnic_fcpio_ack_handler(fnic, cq_index, desc);\r\nbreak;\r\ncase FCPIO_ICMND_CMPL:\r\nfnic_fcpio_icmnd_cmpl_handler(fnic, desc);\r\nbreak;\r\ncase FCPIO_ITMF_CMPL:\r\nfnic_fcpio_itmf_cmpl_handler(fnic, desc);\r\nbreak;\r\ncase FCPIO_FLOGI_REG_CMPL:\r\ncase FCPIO_FLOGI_FIP_REG_CMPL:\r\nret = fnic_fcpio_flogi_reg_cmpl_handler(fnic, desc);\r\nbreak;\r\ncase FCPIO_RESET_CMPL:\r\nret = fnic_fcpio_fw_reset_cmpl_handler(fnic, desc);\r\nbreak;\r\ndefault:\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"firmware completion type %d\n",\r\ndesc->hdr.type);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nint fnic_wq_copy_cmpl_handler(struct fnic *fnic, int copy_work_to_do)\r\n{\r\nunsigned int wq_work_done = 0;\r\nunsigned int i, cq_index;\r\nunsigned int cur_work_done;\r\nfor (i = 0; i < fnic->wq_copy_count; i++) {\r\ncq_index = i + fnic->raw_wq_count + fnic->rq_count;\r\ncur_work_done = vnic_cq_copy_service(&fnic->cq[cq_index],\r\nfnic_fcpio_cmpl_handler,\r\ncopy_work_to_do);\r\nwq_work_done += cur_work_done;\r\n}\r\nreturn wq_work_done;\r\n}\r\nstatic void fnic_cleanup_io(struct fnic *fnic, int exclude_id)\r\n{\r\nunsigned int i;\r\nstruct fnic_io_req *io_req;\r\nunsigned long flags = 0;\r\nstruct scsi_cmnd *sc;\r\nspinlock_t *io_lock;\r\nfor (i = 0; i < FNIC_MAX_IO_REQ; i++) {\r\nif (i == exclude_id)\r\ncontinue;\r\nsc = scsi_host_find_tag(fnic->lport->host, i);\r\nif (!sc)\r\ncontinue;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto cleanup_scsi_cmd;\r\n}\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\ncleanup_scsi_cmd:\r\nsc->result = DID_TRANSPORT_DISRUPTED << 16;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host, "fnic_cleanup_io:"\r\n" DID_TRANSPORT_DISRUPTED\n");\r\nif (sc->scsi_done)\r\nsc->scsi_done(sc);\r\n}\r\n}\r\nvoid fnic_wq_copy_cleanup_handler(struct vnic_wq_copy *wq,\r\nstruct fcpio_host_req *desc)\r\n{\r\nu32 id;\r\nstruct fnic *fnic = vnic_dev_priv(wq->vdev);\r\nstruct fnic_io_req *io_req;\r\nstruct scsi_cmnd *sc;\r\nunsigned long flags;\r\nspinlock_t *io_lock;\r\nfcpio_tag_id_dec(&desc->hdr.tag, &id);\r\nid &= FNIC_TAG_MASK;\r\nif (id >= FNIC_MAX_IO_REQ)\r\nreturn;\r\nsc = scsi_host_find_tag(fnic->lport->host, id);\r\nif (!sc)\r\nreturn;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto wq_copy_cleanup_scsi_cmd;\r\n}\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\nwq_copy_cleanup_scsi_cmd:\r\nsc->result = DID_NO_CONNECT << 16;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host, "wq_copy_cleanup_handler:"\r\n" DID_NO_CONNECT\n");\r\nif (sc->scsi_done)\r\nsc->scsi_done(sc);\r\n}\r\nstatic inline int fnic_queue_abort_io_req(struct fnic *fnic, int tag,\r\nu32 task_req, u8 *fc_lun,\r\nstruct fnic_io_req *io_req)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nunsigned long flags;\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq)) {\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\nreturn 1;\r\n}\r\nfnic_queue_wq_copy_desc_itmf(wq, tag | FNIC_TAG_ABORT,\r\n0, task_req, tag, fc_lun, io_req->port_id,\r\nfnic->config.ra_tov, fnic->config.ed_tov);\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\nreturn 0;\r\n}\r\nvoid fnic_rport_exch_reset(struct fnic *fnic, u32 port_id)\r\n{\r\nint tag;\r\nstruct fnic_io_req *io_req;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nstruct scsi_cmnd *sc;\r\nstruct scsi_lun fc_lun;\r\nenum fnic_ioreq_state old_ioreq_state;\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic_rport_reset_exch called portid 0x%06x\n",\r\nport_id);\r\nif (fnic->in_remove)\r\nreturn;\r\nfor (tag = 0; tag < FNIC_MAX_IO_REQ; tag++) {\r\nsc = scsi_host_find_tag(fnic->lport->host, tag);\r\nif (!sc)\r\ncontinue;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req || io_req->port_id != port_id) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nold_ioreq_state = CMD_STATE(sc);\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nBUG_ON(io_req->abts_done);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_rport_reset_exch: Issuing abts\n");\r\nspin_unlock_irqrestore(io_lock, flags);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, tag,\r\nFCPIO_ITMF_ABT_TASK_TERM,\r\nfc_lun.scsi_lun, io_req)) {\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)\r\nCMD_STATE(sc) = old_ioreq_state;\r\nspin_unlock_irqrestore(io_lock, flags);\r\n}\r\n}\r\n}\r\nvoid fnic_terminate_rport_io(struct fc_rport *rport)\r\n{\r\nint tag;\r\nstruct fnic_io_req *io_req;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nstruct scsi_cmnd *sc;\r\nstruct scsi_lun fc_lun;\r\nstruct fc_rport_libfc_priv *rdata = rport->dd_data;\r\nstruct fc_lport *lport = rdata->local_port;\r\nstruct fnic *fnic = lport_priv(lport);\r\nstruct fc_rport *cmd_rport;\r\nenum fnic_ioreq_state old_ioreq_state;\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host, "fnic_terminate_rport_io called"\r\n" wwpn 0x%llx, wwnn0x%llx, portid 0x%06x\n",\r\nrport->port_name, rport->node_name,\r\nrport->port_id);\r\nif (fnic->in_remove)\r\nreturn;\r\nfor (tag = 0; tag < FNIC_MAX_IO_REQ; tag++) {\r\nsc = scsi_host_find_tag(fnic->lport->host, tag);\r\nif (!sc)\r\ncontinue;\r\ncmd_rport = starget_to_rport(scsi_target(sc->device));\r\nif (rport != cmd_rport)\r\ncontinue;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req || rport != cmd_rport) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nold_ioreq_state = CMD_STATE(sc);\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nBUG_ON(io_req->abts_done);\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic_terminate_rport_io: Issuing abts\n");\r\nspin_unlock_irqrestore(io_lock, flags);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, tag,\r\nFCPIO_ITMF_ABT_TASK_TERM,\r\nfc_lun.scsi_lun, io_req)) {\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)\r\nCMD_STATE(sc) = old_ioreq_state;\r\nspin_unlock_irqrestore(io_lock, flags);\r\n}\r\n}\r\n}\r\nint fnic_abort_cmd(struct scsi_cmnd *sc)\r\n{\r\nstruct fc_lport *lp;\r\nstruct fnic *fnic;\r\nstruct fnic_io_req *io_req;\r\nstruct fc_rport *rport;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nint ret = SUCCESS;\r\nu32 task_req;\r\nstruct scsi_lun fc_lun;\r\nDECLARE_COMPLETION_ONSTACK(tm_done);\r\nfc_block_scsi_eh(sc);\r\nlp = shost_priv(sc->device->host);\r\nfnic = lport_priv(lp);\r\nrport = starget_to_rport(scsi_target(sc->device));\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Abort Cmd called FCID 0x%x, LUN 0x%x TAG %d\n",\r\nrport->port_id, sc->device->lun, sc->request->tag);\r\nif (lp->state != LPORT_ST_READY || !(lp->link_up)) {\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto fnic_abort_cmd_end;\r\n}\r\nio_req->abts_done = &tm_done;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto wait_pending;\r\n}\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (fc_remote_port_chkready(rport) == 0)\r\ntask_req = FCPIO_ITMF_ABT_TASK;\r\nelse\r\ntask_req = FCPIO_ITMF_ABT_TASK_TERM;\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, sc->request->tag, task_req,\r\nfc_lun.scsi_lun, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nio_req->abts_done = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nwait_pending:\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies\r\n(2 * fnic->config.ra_tov +\r\nfnic->config.ed_tov));\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nio_req->abts_done = NULL;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nif (CMD_ABTS_STATUS(sc) != FCPIO_SUCCESS)\r\nret = FAILED;\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\nfnic_abort_cmd_end:\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Returning from abort cmd %s\n",\r\n(ret == SUCCESS) ?\r\n"SUCCESS" : "FAILED");\r\nreturn ret;\r\n}\r\nstatic inline int fnic_queue_dr_io_req(struct fnic *fnic,\r\nstruct scsi_cmnd *sc,\r\nstruct fnic_io_req *io_req)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nstruct scsi_lun fc_lun;\r\nint ret = 0;\r\nunsigned long intr_flags;\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], intr_flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq)) {\r\nret = -EAGAIN;\r\ngoto lr_io_req_end;\r\n}\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nfnic_queue_wq_copy_desc_itmf(wq, sc->request->tag | FNIC_TAG_DEV_RST,\r\n0, FCPIO_ITMF_LUN_RESET, SCSI_NO_TAG,\r\nfc_lun.scsi_lun, io_req->port_id,\r\nfnic->config.ra_tov, fnic->config.ed_tov);\r\nlr_io_req_end:\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], intr_flags);\r\nreturn ret;\r\n}\r\nstatic int fnic_clean_pending_aborts(struct fnic *fnic,\r\nstruct scsi_cmnd *lr_sc)\r\n{\r\nint tag;\r\nstruct fnic_io_req *io_req;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nint ret = 0;\r\nstruct scsi_cmnd *sc;\r\nstruct scsi_lun fc_lun;\r\nstruct scsi_device *lun_dev = lr_sc->device;\r\nDECLARE_COMPLETION_ONSTACK(tm_done);\r\nfor (tag = 0; tag < FNIC_MAX_IO_REQ; tag++) {\r\nsc = scsi_host_find_tag(fnic->lport->host, tag);\r\nif (!sc || sc == lr_sc || sc->device != lun_dev)\r\ncontinue;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req || sc->device != lun_dev) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Found IO in %s on lun\n",\r\nfnic_ioreq_state_to_str(CMD_STATE(sc)));\r\nBUG_ON(CMD_STATE(sc) != FNIC_IOREQ_ABTS_PENDING);\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nio_req->abts_done = &tm_done;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, tag,\r\nFCPIO_ITMF_ABT_TASK_TERM,\r\nfc_lun.scsi_lun, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nio_req->abts_done = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = 1;\r\ngoto clean_pending_aborts_end;\r\n}\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies\r\n(fnic->config.ed_tov));\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = 1;\r\ngoto clean_pending_aborts_end;\r\n}\r\nio_req->abts_done = NULL;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = 1;\r\ngoto clean_pending_aborts_end;\r\n}\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\n}\r\nclean_pending_aborts_end:\r\nreturn ret;\r\n}\r\nint fnic_device_reset(struct scsi_cmnd *sc)\r\n{\r\nstruct fc_lport *lp;\r\nstruct fnic *fnic;\r\nstruct fnic_io_req *io_req;\r\nstruct fc_rport *rport;\r\nint status;\r\nint ret = FAILED;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nDECLARE_COMPLETION_ONSTACK(tm_done);\r\nfc_block_scsi_eh(sc);\r\nlp = shost_priv(sc->device->host);\r\nfnic = lport_priv(lp);\r\nrport = starget_to_rport(scsi_target(sc->device));\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Device reset called FCID 0x%x, LUN 0x%x\n",\r\nrport->port_id, sc->device->lun);\r\nif (lp->state != LPORT_ST_READY || !(lp->link_up))\r\ngoto fnic_device_reset_end;\r\nif (fc_remote_port_chkready(rport))\r\ngoto fnic_device_reset_end;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nio_req = mempool_alloc(fnic->io_req_pool, GFP_ATOMIC);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto fnic_device_reset_end;\r\n}\r\nmemset(io_req, 0, sizeof(*io_req));\r\nio_req->port_id = rport->port_id;\r\nCMD_SP(sc) = (char *)io_req;\r\n}\r\nio_req->dr_done = &tm_done;\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_PENDING;\r\nCMD_LR_STATUS(sc) = FCPIO_INVALID_CODE;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host, "TAG %d\n",\r\nsc->request->tag);\r\nif (fnic_queue_dr_io_req(fnic, sc, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nio_req->dr_done = NULL;\r\ngoto fnic_device_reset_clean;\r\n}\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies(FNIC_LUN_RESET_TIMEOUT));\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto fnic_device_reset_end;\r\n}\r\nio_req->dr_done = NULL;\r\nstatus = CMD_LR_STATUS(sc);\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (status == FCPIO_INVALID_CODE) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Device reset timed out\n");\r\ngoto fnic_device_reset_end;\r\n}\r\nif (status != FCPIO_SUCCESS) {\r\nspin_lock_irqsave(io_lock, flags);\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"Device reset completed - failed\n");\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\ngoto fnic_device_reset_clean;\r\n}\r\nif (fnic_clean_pending_aborts(fnic, sc)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Device reset failed"\r\n" since could not abort all IOs\n");\r\ngoto fnic_device_reset_clean;\r\n}\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nret = SUCCESS;\r\nfnic_device_reset_clean:\r\nif (io_req)\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (io_req) {\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\n}\r\nfnic_device_reset_end:\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Returning from device reset %s\n",\r\n(ret == SUCCESS) ?\r\n"SUCCESS" : "FAILED");\r\nreturn ret;\r\n}\r\nint fnic_reset(struct Scsi_Host *shost)\r\n{\r\nstruct fc_lport *lp;\r\nstruct fnic *fnic;\r\nint ret = SUCCESS;\r\nlp = shost_priv(shost);\r\nfnic = lport_priv(lp);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_reset called\n");\r\nif (lp->tt.lport_reset(lp))\r\nret = FAILED;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Returning from fnic reset %s\n",\r\n(ret == SUCCESS) ?\r\n"SUCCESS" : "FAILED");\r\nreturn ret;\r\n}\r\nint fnic_host_reset(struct scsi_cmnd *sc)\r\n{\r\nint ret;\r\nunsigned long wait_host_tmo;\r\nstruct Scsi_Host *shost = sc->device->host;\r\nstruct fc_lport *lp = shost_priv(shost);\r\nret = fnic_reset(shost);\r\nif (ret == SUCCESS) {\r\nwait_host_tmo = jiffies + FNIC_HOST_RESET_SETTLE_TIME * HZ;\r\nret = FAILED;\r\nwhile (time_before(jiffies, wait_host_tmo)) {\r\nif ((lp->state == LPORT_ST_READY) &&\r\n(lp->link_up)) {\r\nret = SUCCESS;\r\nbreak;\r\n}\r\nssleep(1);\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid fnic_scsi_abort_io(struct fc_lport *lp)\r\n{\r\nint err = 0;\r\nunsigned long flags;\r\nenum fnic_state old_state;\r\nstruct fnic *fnic = lport_priv(lp);\r\nDECLARE_COMPLETION_ONSTACK(remove_wait);\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nfnic->remove_wait = &remove_wait;\r\nold_state = fnic->state;\r\nfnic->state = FNIC_IN_FC_TRANS_ETH_MODE;\r\nfnic_update_mac_locked(fnic, fnic->ctlr.ctl_src_addr);\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nerr = fnic_fw_reset_handler(fnic);\r\nif (err) {\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)\r\nfnic->state = old_state;\r\nfnic->remove_wait = NULL;\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nreturn;\r\n}\r\nwait_for_completion_timeout(&remove_wait,\r\nmsecs_to_jiffies(FNIC_RMDEVICE_TIMEOUT));\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nfnic->remove_wait = NULL;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_scsi_abort_io %s\n",\r\n(fnic->state == FNIC_IN_ETH_MODE) ?\r\n"SUCCESS" : "FAILED");\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\nvoid fnic_scsi_cleanup(struct fc_lport *lp)\r\n{\r\nunsigned long flags;\r\nenum fnic_state old_state;\r\nstruct fnic *fnic = lport_priv(lp);\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nold_state = fnic->state;\r\nfnic->state = FNIC_IN_FC_TRANS_ETH_MODE;\r\nfnic_update_mac_locked(fnic, fnic->ctlr.ctl_src_addr);\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nif (fnic_fw_reset_handler(fnic)) {\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)\r\nfnic->state = old_state;\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\n}\r\nvoid fnic_empty_scsi_cleanup(struct fc_lport *lp)\r\n{\r\n}\r\nvoid fnic_exch_mgr_reset(struct fc_lport *lp, u32 sid, u32 did)\r\n{\r\nstruct fnic *fnic = lport_priv(lp);\r\nif (sid)\r\ngoto call_fc_exch_mgr_reset;\r\nif (did) {\r\nfnic_rport_exch_reset(fnic, did);\r\ngoto call_fc_exch_mgr_reset;\r\n}\r\nif (!fnic->in_remove)\r\nfnic_scsi_cleanup(lp);\r\nelse\r\nfnic_scsi_abort_io(lp);\r\ncall_fc_exch_mgr_reset:\r\nfc_exch_mgr_reset(lp, sid, did);\r\n}
