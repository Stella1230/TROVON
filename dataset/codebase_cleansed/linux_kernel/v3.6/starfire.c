static int netdev_vlan_rx_add_vid(struct net_device *dev, unsigned short vid)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nspin_lock(&np->lock);\r\nif (debug > 1)\r\nprintk("%s: Adding vlanid %d to vlan filter\n", dev->name, vid);\r\nset_bit(vid, np->active_vlans);\r\nset_rx_mode(dev);\r\nspin_unlock(&np->lock);\r\nreturn 0;\r\n}\r\nstatic int netdev_vlan_rx_kill_vid(struct net_device *dev, unsigned short vid)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nspin_lock(&np->lock);\r\nif (debug > 1)\r\nprintk("%s: removing vlanid %d from vlan filter\n", dev->name, vid);\r\nclear_bit(vid, np->active_vlans);\r\nset_rx_mode(dev);\r\nspin_unlock(&np->lock);\r\nreturn 0;\r\n}\r\nstatic int __devinit starfire_init_one(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nstruct device *d = &pdev->dev;\r\nstruct netdev_private *np;\r\nint i, irq, chip_idx = ent->driver_data;\r\nstruct net_device *dev;\r\nlong ioaddr;\r\nvoid __iomem *base;\r\nint drv_flags, io_size;\r\nint boguscnt;\r\n#ifndef MODULE\r\nstatic int printed_version;\r\nif (!printed_version++)\r\nprintk(version);\r\n#endif\r\nif (pci_enable_device (pdev))\r\nreturn -EIO;\r\nioaddr = pci_resource_start(pdev, 0);\r\nio_size = pci_resource_len(pdev, 0);\r\nif (!ioaddr || ((pci_resource_flags(pdev, 0) & IORESOURCE_MEM) == 0)) {\r\ndev_err(d, "no PCI MEM resources, aborting\n");\r\nreturn -ENODEV;\r\n}\r\ndev = alloc_etherdev(sizeof(*np));\r\nif (!dev)\r\nreturn -ENOMEM;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nirq = pdev->irq;\r\nif (pci_request_regions (pdev, DRV_NAME)) {\r\ndev_err(d, "cannot reserve PCI resources, aborting\n");\r\ngoto err_out_free_netdev;\r\n}\r\nbase = ioremap(ioaddr, io_size);\r\nif (!base) {\r\ndev_err(d, "cannot remap %#x @ %#lx, aborting\n",\r\nio_size, ioaddr);\r\ngoto err_out_free_res;\r\n}\r\npci_set_master(pdev);\r\npci_try_set_mwi(pdev);\r\n#ifdef ZEROCOPY\r\nif (enable_hw_cksum)\r\ndev->features |= NETIF_F_IP_CSUM | NETIF_F_SG;\r\n#endif\r\n#ifdef VLAN_SUPPORT\r\ndev->features |= NETIF_F_HW_VLAN_RX | NETIF_F_HW_VLAN_FILTER;\r\n#endif\r\n#ifdef ADDR_64BITS\r\ndev->features |= NETIF_F_HIGHDMA;\r\n#endif\r\nfor (i = 0; i < 6; i++)\r\ndev->dev_addr[i] = readb(base + EEPROMCtrl + 20 - i);\r\n#if ! defined(final_version)\r\nif (debug > 4)\r\nfor (i = 0; i < 0x20; i++)\r\nprintk("%2.2x%s",\r\n(unsigned int)readb(base + EEPROMCtrl + i),\r\ni % 16 != 15 ? " " : "\n");\r\n#endif\r\nwritel(MiiSoftReset, base + TxMode);\r\nudelay(1000);\r\nwritel(0, base + TxMode);\r\nwritel(1, base + PCIDeviceConfig);\r\nboguscnt = 1000;\r\nwhile (--boguscnt > 0) {\r\nudelay(10);\r\nif ((readl(base + PCIDeviceConfig) & 1) == 0)\r\nbreak;\r\n}\r\nif (boguscnt == 0)\r\nprintk("%s: chipset reset never completed!\n", dev->name);\r\nudelay(1000);\r\nnp = netdev_priv(dev);\r\nnp->dev = dev;\r\nnp->base = base;\r\nspin_lock_init(&np->lock);\r\npci_set_drvdata(pdev, dev);\r\nnp->pci_dev = pdev;\r\nnp->mii_if.dev = dev;\r\nnp->mii_if.mdio_read = mdio_read;\r\nnp->mii_if.mdio_write = mdio_write;\r\nnp->mii_if.phy_id_mask = 0x1f;\r\nnp->mii_if.reg_num_mask = 0x1f;\r\ndrv_flags = netdrv_tbl[chip_idx].drv_flags;\r\nnp->speed100 = 1;\r\nnp->intr_timer_ctrl = (((intr_latency * 10) / 1024) & IntrLatencyMask) |\r\nTimer10X | EnableIntrMasking;\r\nif (small_frames > 0) {\r\nnp->intr_timer_ctrl |= SmallFrameBypass;\r\nswitch (small_frames) {\r\ncase 1 ... 64:\r\nnp->intr_timer_ctrl |= SmallFrame64;\r\nbreak;\r\ncase 65 ... 128:\r\nnp->intr_timer_ctrl |= SmallFrame128;\r\nbreak;\r\ncase 129 ... 256:\r\nnp->intr_timer_ctrl |= SmallFrame256;\r\nbreak;\r\ndefault:\r\nnp->intr_timer_ctrl |= SmallFrame512;\r\nif (small_frames > 512)\r\nprintk("Adjusting small_frames down to 512\n");\r\nbreak;\r\n}\r\n}\r\ndev->netdev_ops = &netdev_ops;\r\ndev->watchdog_timeo = TX_TIMEOUT;\r\nSET_ETHTOOL_OPS(dev, &ethtool_ops);\r\nnetif_napi_add(dev, &np->napi, netdev_poll, max_interrupt_work);\r\nif (mtu)\r\ndev->mtu = mtu;\r\nif (register_netdev(dev))\r\ngoto err_out_cleardev;\r\nprintk(KERN_INFO "%s: %s at %p, %pM, IRQ %d.\n",\r\ndev->name, netdrv_tbl[chip_idx].name, base,\r\ndev->dev_addr, irq);\r\nif (drv_flags & CanHaveMII) {\r\nint phy, phy_idx = 0;\r\nint mii_status;\r\nfor (phy = 0; phy < 32 && phy_idx < PHY_CNT; phy++) {\r\nmdio_write(dev, phy, MII_BMCR, BMCR_RESET);\r\nmdelay(100);\r\nboguscnt = 1000;\r\nwhile (--boguscnt > 0)\r\nif ((mdio_read(dev, phy, MII_BMCR) & BMCR_RESET) == 0)\r\nbreak;\r\nif (boguscnt == 0) {\r\nprintk("%s: PHY#%d reset never completed!\n", dev->name, phy);\r\ncontinue;\r\n}\r\nmii_status = mdio_read(dev, phy, MII_BMSR);\r\nif (mii_status != 0) {\r\nnp->phys[phy_idx++] = phy;\r\nnp->mii_if.advertising = mdio_read(dev, phy, MII_ADVERTISE);\r\nprintk(KERN_INFO "%s: MII PHY found at address %d, status "\r\n"%#4.4x advertising %#4.4x.\n",\r\ndev->name, phy, mii_status, np->mii_if.advertising);\r\nbreak;\r\n}\r\n}\r\nnp->phy_cnt = phy_idx;\r\nif (np->phy_cnt > 0)\r\nnp->mii_if.phy_id = np->phys[0];\r\nelse\r\nmemset(&np->mii_if, 0, sizeof(np->mii_if));\r\n}\r\nprintk(KERN_INFO "%s: scatter-gather and hardware TCP cksumming %s.\n",\r\ndev->name, enable_hw_cksum ? "enabled" : "disabled");\r\nreturn 0;\r\nerr_out_cleardev:\r\npci_set_drvdata(pdev, NULL);\r\niounmap(base);\r\nerr_out_free_res:\r\npci_release_regions (pdev);\r\nerr_out_free_netdev:\r\nfree_netdev(dev);\r\nreturn -ENODEV;\r\n}\r\nstatic int mdio_read(struct net_device *dev, int phy_id, int location)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *mdio_addr = np->base + MIICtrl + (phy_id<<7) + (location<<2);\r\nint result, boguscnt=1000;\r\ndo {\r\nresult = readl(mdio_addr);\r\n} while ((result & 0xC0000000) != 0x80000000 && --boguscnt > 0);\r\nif (boguscnt == 0)\r\nreturn 0;\r\nif ((result & 0xffff) == 0xffff)\r\nreturn 0;\r\nreturn result & 0xffff;\r\n}\r\nstatic void mdio_write(struct net_device *dev, int phy_id, int location, int value)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *mdio_addr = np->base + MIICtrl + (phy_id<<7) + (location<<2);\r\nwritel(value, mdio_addr);\r\n}\r\nstatic int netdev_open(struct net_device *dev)\r\n{\r\nconst struct firmware *fw_rx, *fw_tx;\r\nconst __be32 *fw_rx_data, *fw_tx_data;\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base;\r\nconst int irq = np->pci_dev->irq;\r\nint i, retval;\r\nsize_t tx_size, rx_size;\r\nsize_t tx_done_q_size, rx_done_q_size, tx_ring_size, rx_ring_size;\r\nretval = request_irq(irq, intr_handler, IRQF_SHARED, dev->name, dev);\r\nif (retval)\r\nreturn retval;\r\nwritel(0, ioaddr + GenCtrl);\r\nwritel(1, ioaddr + PCIDeviceConfig);\r\nif (debug > 1)\r\nprintk(KERN_DEBUG "%s: netdev_open() irq %d.\n",\r\ndev->name, irq);\r\nif (!np->queue_mem) {\r\ntx_done_q_size = ((sizeof(struct tx_done_desc) * DONE_Q_SIZE + QUEUE_ALIGN - 1) / QUEUE_ALIGN) * QUEUE_ALIGN;\r\nrx_done_q_size = ((sizeof(rx_done_desc) * DONE_Q_SIZE + QUEUE_ALIGN - 1) / QUEUE_ALIGN) * QUEUE_ALIGN;\r\ntx_ring_size = ((sizeof(starfire_tx_desc) * TX_RING_SIZE + QUEUE_ALIGN - 1) / QUEUE_ALIGN) * QUEUE_ALIGN;\r\nrx_ring_size = sizeof(struct starfire_rx_desc) * RX_RING_SIZE;\r\nnp->queue_mem_size = tx_done_q_size + rx_done_q_size + tx_ring_size + rx_ring_size;\r\nnp->queue_mem = pci_alloc_consistent(np->pci_dev, np->queue_mem_size, &np->queue_mem_dma);\r\nif (np->queue_mem == NULL) {\r\nfree_irq(irq, dev);\r\nreturn -ENOMEM;\r\n}\r\nnp->tx_done_q = np->queue_mem;\r\nnp->tx_done_q_dma = np->queue_mem_dma;\r\nnp->rx_done_q = (void *) np->tx_done_q + tx_done_q_size;\r\nnp->rx_done_q_dma = np->tx_done_q_dma + tx_done_q_size;\r\nnp->tx_ring = (void *) np->rx_done_q + rx_done_q_size;\r\nnp->tx_ring_dma = np->rx_done_q_dma + rx_done_q_size;\r\nnp->rx_ring = (void *) np->tx_ring + tx_ring_size;\r\nnp->rx_ring_dma = np->tx_ring_dma + tx_ring_size;\r\n}\r\nnetif_carrier_off(dev);\r\ninit_ring(dev);\r\nwritel((np->rx_buf_sz << RxBufferLenShift) |\r\n(0 << RxMinDescrThreshShift) |\r\nRxPrefetchMode | RxVariableQ |\r\nRX_Q_ENTRIES |\r\nRX_DESC_Q_ADDR_SIZE | RX_DESC_ADDR_SIZE |\r\nRxDescSpace4,\r\nioaddr + RxDescQCtrl);\r\nwritel(RxChecksumIgnore |\r\n(0 << RxEarlyIntThreshShift) |\r\n(6 << RxHighPrioThreshShift) |\r\n((DMA_BURST_SIZE / 32) << RxBurstSizeShift),\r\nioaddr + RxDMACtrl);\r\nwritel((2 << TxHiPriFIFOThreshShift) |\r\n(0 << TxPadLenShift) |\r\n((DMA_BURST_SIZE / 32) << TxDMABurstSizeShift) |\r\nTX_DESC_Q_ADDR_SIZE |\r\nTX_DESC_SPACING | TX_DESC_TYPE,\r\nioaddr + TxDescCtrl);\r\nwritel( (np->queue_mem_dma >> 16) >> 16, ioaddr + RxDescQHiAddr);\r\nwritel( (np->queue_mem_dma >> 16) >> 16, ioaddr + TxRingHiAddr);\r\nwritel( (np->queue_mem_dma >> 16) >> 16, ioaddr + CompletionHiAddr);\r\nwritel(np->rx_ring_dma, ioaddr + RxDescQAddr);\r\nwritel(np->tx_ring_dma, ioaddr + TxRingPtr);\r\nwritel(np->tx_done_q_dma, ioaddr + TxCompletionAddr);\r\nwritel(np->rx_done_q_dma |\r\nRxComplType |\r\n(0 << RxComplThreshShift),\r\nioaddr + RxCompletionAddr);\r\nif (debug > 1)\r\nprintk(KERN_DEBUG "%s: Filling in the station address.\n", dev->name);\r\nfor (i = 0; i < 6; i++)\r\nwriteb(dev->dev_addr[i], ioaddr + TxStationAddr + 5 - i);\r\nwritew(0, ioaddr + PerfFilterTable);\r\nwritew(0, ioaddr + PerfFilterTable + 4);\r\nwritew(0, ioaddr + PerfFilterTable + 8);\r\nfor (i = 1; i < 16; i++) {\r\n__be16 *eaddrs = (__be16 *)dev->dev_addr;\r\nvoid __iomem *setup_frm = ioaddr + PerfFilterTable + i * 16;\r\nwritew(be16_to_cpu(eaddrs[2]), setup_frm); setup_frm += 4;\r\nwritew(be16_to_cpu(eaddrs[1]), setup_frm); setup_frm += 4;\r\nwritew(be16_to_cpu(eaddrs[0]), setup_frm); setup_frm += 8;\r\n}\r\nnp->tx_mode = TxFlowEnable|RxFlowEnable|PadEnable;\r\nwritel(MiiSoftReset | np->tx_mode, ioaddr + TxMode);\r\nudelay(1000);\r\nwritel(np->tx_mode, ioaddr + TxMode);\r\nnp->tx_threshold = 4;\r\nwritel(np->tx_threshold, ioaddr + TxThreshold);\r\nwritel(np->intr_timer_ctrl, ioaddr + IntrTimerCtrl);\r\nnapi_enable(&np->napi);\r\nnetif_start_queue(dev);\r\nif (debug > 1)\r\nprintk(KERN_DEBUG "%s: Setting the Rx and Tx modes.\n", dev->name);\r\nset_rx_mode(dev);\r\nnp->mii_if.advertising = mdio_read(dev, np->phys[0], MII_ADVERTISE);\r\ncheck_duplex(dev);\r\nwritel(0x0f00ff00, ioaddr + GPIOCtrl);\r\nwritel(IntrRxDone | IntrRxEmpty | IntrDMAErr |\r\nIntrTxDMADone | IntrStatsMax | IntrLinkChange |\r\nIntrRxGFPDead | IntrNoTxCsum | IntrTxBadID,\r\nioaddr + IntrEnable);\r\nwritel(0x00800000 | readl(ioaddr + PCIDeviceConfig),\r\nioaddr + PCIDeviceConfig);\r\n#ifdef VLAN_SUPPORT\r\nwritel(ETH_P_8021Q, ioaddr + VlanType);\r\n#endif\r\nretval = request_firmware(&fw_rx, FIRMWARE_RX, &np->pci_dev->dev);\r\nif (retval) {\r\nprintk(KERN_ERR "starfire: Failed to load firmware \"%s\"\n",\r\nFIRMWARE_RX);\r\ngoto out_init;\r\n}\r\nif (fw_rx->size % 4) {\r\nprintk(KERN_ERR "starfire: bogus length %zu in \"%s\"\n",\r\nfw_rx->size, FIRMWARE_RX);\r\nretval = -EINVAL;\r\ngoto out_rx;\r\n}\r\nretval = request_firmware(&fw_tx, FIRMWARE_TX, &np->pci_dev->dev);\r\nif (retval) {\r\nprintk(KERN_ERR "starfire: Failed to load firmware \"%s\"\n",\r\nFIRMWARE_TX);\r\ngoto out_rx;\r\n}\r\nif (fw_tx->size % 4) {\r\nprintk(KERN_ERR "starfire: bogus length %zu in \"%s\"\n",\r\nfw_tx->size, FIRMWARE_TX);\r\nretval = -EINVAL;\r\ngoto out_tx;\r\n}\r\nfw_rx_data = (const __be32 *)&fw_rx->data[0];\r\nfw_tx_data = (const __be32 *)&fw_tx->data[0];\r\nrx_size = fw_rx->size / 4;\r\ntx_size = fw_tx->size / 4;\r\nfor (i = 0; i < rx_size; i++)\r\nwritel(be32_to_cpup(&fw_rx_data[i]), ioaddr + RxGfpMem + i * 4);\r\nfor (i = 0; i < tx_size; i++)\r\nwritel(be32_to_cpup(&fw_tx_data[i]), ioaddr + TxGfpMem + i * 4);\r\nif (enable_hw_cksum)\r\nwritel(TxEnable|TxGFPEnable|RxEnable|RxGFPEnable, ioaddr + GenCtrl);\r\nelse\r\nwritel(TxEnable|RxEnable, ioaddr + GenCtrl);\r\nif (debug > 1)\r\nprintk(KERN_DEBUG "%s: Done netdev_open().\n",\r\ndev->name);\r\nout_tx:\r\nrelease_firmware(fw_tx);\r\nout_rx:\r\nrelease_firmware(fw_rx);\r\nout_init:\r\nif (retval)\r\nnetdev_close(dev);\r\nreturn retval;\r\n}\r\nstatic void check_duplex(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nu16 reg0;\r\nint silly_count = 1000;\r\nmdio_write(dev, np->phys[0], MII_ADVERTISE, np->mii_if.advertising);\r\nmdio_write(dev, np->phys[0], MII_BMCR, BMCR_RESET);\r\nudelay(500);\r\nwhile (--silly_count && mdio_read(dev, np->phys[0], MII_BMCR) & BMCR_RESET)\r\n;\r\nif (!silly_count) {\r\nprintk("%s: MII reset failed!\n", dev->name);\r\nreturn;\r\n}\r\nreg0 = mdio_read(dev, np->phys[0], MII_BMCR);\r\nif (!np->mii_if.force_media) {\r\nreg0 |= BMCR_ANENABLE | BMCR_ANRESTART;\r\n} else {\r\nreg0 &= ~(BMCR_ANENABLE | BMCR_ANRESTART);\r\nif (np->speed100)\r\nreg0 |= BMCR_SPEED100;\r\nif (np->mii_if.full_duplex)\r\nreg0 |= BMCR_FULLDPLX;\r\nprintk(KERN_DEBUG "%s: Link forced to %sMbit %s-duplex\n",\r\ndev->name,\r\nnp->speed100 ? "100" : "10",\r\nnp->mii_if.full_duplex ? "full" : "half");\r\n}\r\nmdio_write(dev, np->phys[0], MII_BMCR, reg0);\r\n}\r\nstatic void tx_timeout(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base;\r\nint old_debug;\r\nprintk(KERN_WARNING "%s: Transmit timed out, status %#8.8x, "\r\n"resetting...\n", dev->name, (int) readl(ioaddr + IntrStatus));\r\nold_debug = debug;\r\ndebug = 2;\r\nnetdev_close(dev);\r\nnetdev_open(dev);\r\ndebug = old_debug;\r\ndev->trans_start = jiffies;\r\ndev->stats.tx_errors++;\r\nnetif_wake_queue(dev);\r\n}\r\nstatic void init_ring(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint i;\r\nnp->cur_rx = np->cur_tx = np->reap_tx = 0;\r\nnp->dirty_rx = np->dirty_tx = np->rx_done = np->tx_done = 0;\r\nnp->rx_buf_sz = (dev->mtu <= 1500 ? PKT_BUF_SZ : dev->mtu + 32);\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nstruct sk_buff *skb = netdev_alloc_skb(dev, np->rx_buf_sz);\r\nnp->rx_info[i].skb = skb;\r\nif (skb == NULL)\r\nbreak;\r\nnp->rx_info[i].mapping = pci_map_single(np->pci_dev, skb->data, np->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nnp->rx_ring[i].rxaddr = cpu_to_dma(np->rx_info[i].mapping | RxDescValid);\r\n}\r\nwritew(i - 1, np->base + RxDescQIdx);\r\nnp->dirty_rx = (unsigned int)(i - RX_RING_SIZE);\r\nfor ( ; i < RX_RING_SIZE; i++) {\r\nnp->rx_ring[i].rxaddr = 0;\r\nnp->rx_info[i].skb = NULL;\r\nnp->rx_info[i].mapping = 0;\r\n}\r\nnp->rx_ring[RX_RING_SIZE - 1].rxaddr |= cpu_to_dma(RxDescEndRing);\r\nfor (i = 0; i < DONE_Q_SIZE; i++) {\r\nnp->rx_done_q[i].status = 0;\r\nnp->tx_done_q[i].status = 0;\r\n}\r\nfor (i = 0; i < TX_RING_SIZE; i++)\r\nmemset(&np->tx_info[i], 0, sizeof(np->tx_info[i]));\r\n}\r\nstatic netdev_tx_t start_tx(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nunsigned int entry;\r\nu32 status;\r\nint i;\r\nif ((np->cur_tx - np->dirty_tx) + skb_num_frags(skb) * 2 > TX_RING_SIZE) {\r\nnetif_stop_queue(dev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\n#if defined(ZEROCOPY) && defined(HAS_BROKEN_FIRMWARE)\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nif (skb_padto(skb, (skb->len + PADDING_MASK) & ~PADDING_MASK))\r\nreturn NETDEV_TX_OK;\r\n}\r\n#endif\r\nentry = np->cur_tx % TX_RING_SIZE;\r\nfor (i = 0; i < skb_num_frags(skb); i++) {\r\nint wrap_ring = 0;\r\nstatus = TxDescID;\r\nif (i == 0) {\r\nnp->tx_info[entry].skb = skb;\r\nstatus |= TxCRCEn;\r\nif (entry >= TX_RING_SIZE - skb_num_frags(skb)) {\r\nstatus |= TxRingWrap;\r\nwrap_ring = 1;\r\n}\r\nif (np->reap_tx) {\r\nstatus |= TxDescIntr;\r\nnp->reap_tx = 0;\r\n}\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nstatus |= TxCalTCP;\r\ndev->stats.tx_compressed++;\r\n}\r\nstatus |= skb_first_frag_len(skb) | (skb_num_frags(skb) << 16);\r\nnp->tx_info[entry].mapping =\r\npci_map_single(np->pci_dev, skb->data, skb_first_frag_len(skb), PCI_DMA_TODEVICE);\r\n} else {\r\nconst skb_frag_t *this_frag = &skb_shinfo(skb)->frags[i - 1];\r\nstatus |= skb_frag_size(this_frag);\r\nnp->tx_info[entry].mapping =\r\npci_map_single(np->pci_dev,\r\nskb_frag_address(this_frag),\r\nskb_frag_size(this_frag),\r\nPCI_DMA_TODEVICE);\r\n}\r\nnp->tx_ring[entry].addr = cpu_to_dma(np->tx_info[entry].mapping);\r\nnp->tx_ring[entry].status = cpu_to_le32(status);\r\nif (debug > 3)\r\nprintk(KERN_DEBUG "%s: Tx #%d/#%d slot %d status %#8.8x.\n",\r\ndev->name, np->cur_tx, np->dirty_tx,\r\nentry, status);\r\nif (wrap_ring) {\r\nnp->tx_info[entry].used_slots = TX_RING_SIZE - entry;\r\nnp->cur_tx += np->tx_info[entry].used_slots;\r\nentry = 0;\r\n} else {\r\nnp->tx_info[entry].used_slots = 1;\r\nnp->cur_tx += np->tx_info[entry].used_slots;\r\nentry++;\r\n}\r\nif (np->cur_tx % (TX_RING_SIZE / 2) == 0)\r\nnp->reap_tx = 1;\r\n}\r\nwmb();\r\nwritel(entry * (sizeof(starfire_tx_desc) / 8), np->base + TxProducerIdx);\r\nif ((np->cur_tx - np->dirty_tx) + 4 > TX_RING_SIZE)\r\nnetif_stop_queue(dev);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic irqreturn_t intr_handler(int irq, void *dev_instance)\r\n{\r\nstruct net_device *dev = dev_instance;\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base;\r\nint boguscnt = max_interrupt_work;\r\nint consumer;\r\nint tx_status;\r\nint handled = 0;\r\ndo {\r\nu32 intr_status = readl(ioaddr + IntrClear);\r\nif (debug > 4)\r\nprintk(KERN_DEBUG "%s: Interrupt status %#8.8x.\n",\r\ndev->name, intr_status);\r\nif (intr_status == 0 || intr_status == (u32) -1)\r\nbreak;\r\nhandled = 1;\r\nif (intr_status & (IntrRxDone | IntrRxEmpty)) {\r\nu32 enable;\r\nif (likely(napi_schedule_prep(&np->napi))) {\r\n__napi_schedule(&np->napi);\r\nenable = readl(ioaddr + IntrEnable);\r\nenable &= ~(IntrRxDone | IntrRxEmpty);\r\nwritel(enable, ioaddr + IntrEnable);\r\nreadl(ioaddr + IntrEnable);\r\n} else {\r\nenable = readl(ioaddr + IntrEnable);\r\nif (enable & (IntrRxDone | IntrRxEmpty)) {\r\nprintk(KERN_INFO\r\n"%s: interrupt while in poll!\n",\r\ndev->name);\r\nenable &= ~(IntrRxDone | IntrRxEmpty);\r\nwritel(enable, ioaddr + IntrEnable);\r\n}\r\n}\r\n}\r\nconsumer = readl(ioaddr + TxConsumerIdx);\r\nif (debug > 3)\r\nprintk(KERN_DEBUG "%s: Tx Consumer index is %d.\n",\r\ndev->name, consumer);\r\nwhile ((tx_status = le32_to_cpu(np->tx_done_q[np->tx_done].status)) != 0) {\r\nif (debug > 3)\r\nprintk(KERN_DEBUG "%s: Tx completion #%d entry %d is %#8.8x.\n",\r\ndev->name, np->dirty_tx, np->tx_done, tx_status);\r\nif ((tx_status & 0xe0000000) == 0xa0000000) {\r\ndev->stats.tx_packets++;\r\n} else if ((tx_status & 0xe0000000) == 0x80000000) {\r\nu16 entry = (tx_status & 0x7fff) / sizeof(starfire_tx_desc);\r\nstruct sk_buff *skb = np->tx_info[entry].skb;\r\nnp->tx_info[entry].skb = NULL;\r\npci_unmap_single(np->pci_dev,\r\nnp->tx_info[entry].mapping,\r\nskb_first_frag_len(skb),\r\nPCI_DMA_TODEVICE);\r\nnp->tx_info[entry].mapping = 0;\r\nnp->dirty_tx += np->tx_info[entry].used_slots;\r\nentry = (entry + np->tx_info[entry].used_slots) % TX_RING_SIZE;\r\n{\r\nint i;\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\npci_unmap_single(np->pci_dev,\r\nnp->tx_info[entry].mapping,\r\nskb_frag_size(&skb_shinfo(skb)->frags[i]),\r\nPCI_DMA_TODEVICE);\r\nnp->dirty_tx++;\r\nentry++;\r\n}\r\n}\r\ndev_kfree_skb_irq(skb);\r\n}\r\nnp->tx_done_q[np->tx_done].status = 0;\r\nnp->tx_done = (np->tx_done + 1) % DONE_Q_SIZE;\r\n}\r\nwritew(np->tx_done, ioaddr + CompletionQConsumerIdx + 2);\r\nif (netif_queue_stopped(dev) &&\r\n(np->cur_tx - np->dirty_tx + 4 < TX_RING_SIZE)) {\r\nnetif_wake_queue(dev);\r\n}\r\nif (intr_status & IntrStatsMax)\r\nget_stats(dev);\r\nif (intr_status & IntrLinkChange)\r\nnetdev_media_change(dev);\r\nif (intr_status & IntrAbnormalSummary)\r\nnetdev_error(dev, intr_status);\r\nif (--boguscnt < 0) {\r\nif (debug > 1)\r\nprintk(KERN_WARNING "%s: Too much work at interrupt, "\r\n"status=%#8.8x.\n",\r\ndev->name, intr_status);\r\nbreak;\r\n}\r\n} while (1);\r\nif (debug > 4)\r\nprintk(KERN_DEBUG "%s: exiting interrupt, status=%#8.8x.\n",\r\ndev->name, (int) readl(ioaddr + IntrStatus));\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic int __netdev_rx(struct net_device *dev, int *quota)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nu32 desc_status;\r\nint retcode = 0;\r\nwhile ((desc_status = le32_to_cpu(np->rx_done_q[np->rx_done].status)) != 0) {\r\nstruct sk_buff *skb;\r\nu16 pkt_len;\r\nint entry;\r\nrx_done_desc *desc = &np->rx_done_q[np->rx_done];\r\nif (debug > 4)\r\nprintk(KERN_DEBUG " netdev_rx() status of %d was %#8.8x.\n", np->rx_done, desc_status);\r\nif (!(desc_status & RxOK)) {\r\nif (debug > 2)\r\nprintk(KERN_DEBUG " netdev_rx() Rx error was %#8.8x.\n", desc_status);\r\ndev->stats.rx_errors++;\r\nif (desc_status & RxFIFOErr)\r\ndev->stats.rx_fifo_errors++;\r\ngoto next_rx;\r\n}\r\nif (*quota <= 0) {\r\nretcode = 1;\r\ngoto out;\r\n}\r\n(*quota)--;\r\npkt_len = desc_status;\r\nentry = (desc_status >> 16) & 0x7ff;\r\nif (debug > 4)\r\nprintk(KERN_DEBUG " netdev_rx() normal Rx pkt length %d, quota %d.\n", pkt_len, *quota);\r\nif (pkt_len < rx_copybreak &&\r\n(skb = netdev_alloc_skb(dev, pkt_len + 2)) != NULL) {\r\nskb_reserve(skb, 2);\r\npci_dma_sync_single_for_cpu(np->pci_dev,\r\nnp->rx_info[entry].mapping,\r\npkt_len, PCI_DMA_FROMDEVICE);\r\nskb_copy_to_linear_data(skb, np->rx_info[entry].skb->data, pkt_len);\r\npci_dma_sync_single_for_device(np->pci_dev,\r\nnp->rx_info[entry].mapping,\r\npkt_len, PCI_DMA_FROMDEVICE);\r\nskb_put(skb, pkt_len);\r\n} else {\r\npci_unmap_single(np->pci_dev, np->rx_info[entry].mapping, np->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nskb = np->rx_info[entry].skb;\r\nskb_put(skb, pkt_len);\r\nnp->rx_info[entry].skb = NULL;\r\nnp->rx_info[entry].mapping = 0;\r\n}\r\n#ifndef final_version\r\nif (debug > 5) {\r\nprintk(KERN_DEBUG " Rx data %pM %pM %2.2x%2.2x.\n",\r\nskb->data, skb->data + 6,\r\nskb->data[12], skb->data[13]);\r\n}\r\n#endif\r\nskb->protocol = eth_type_trans(skb, dev);\r\n#ifdef VLAN_SUPPORT\r\nif (debug > 4)\r\nprintk(KERN_DEBUG " netdev_rx() status2 of %d was %#4.4x.\n", np->rx_done, le16_to_cpu(desc->status2));\r\n#endif\r\nif (le16_to_cpu(desc->status2) & 0x0100) {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\ndev->stats.rx_compressed++;\r\n}\r\nelse if (le16_to_cpu(desc->status2) & 0x0040) {\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\nskb->csum = le16_to_cpu(desc->csum);\r\nprintk(KERN_DEBUG "%s: checksum_hw, status2 = %#x\n", dev->name, le16_to_cpu(desc->status2));\r\n}\r\n#ifdef VLAN_SUPPORT\r\nif (le16_to_cpu(desc->status2) & 0x0200) {\r\nu16 vlid = le16_to_cpu(desc->vlanid);\r\nif (debug > 4) {\r\nprintk(KERN_DEBUG " netdev_rx() vlanid = %d\n",\r\nvlid);\r\n}\r\n__vlan_hwaccel_put_tag(skb, vlid);\r\n}\r\n#endif\r\nnetif_receive_skb(skb);\r\ndev->stats.rx_packets++;\r\nnext_rx:\r\nnp->cur_rx++;\r\ndesc->status = 0;\r\nnp->rx_done = (np->rx_done + 1) % DONE_Q_SIZE;\r\n}\r\nif (*quota == 0) {\r\nretcode = 1;\r\ngoto out;\r\n}\r\nwritew(np->rx_done, np->base + CompletionQConsumerIdx);\r\nout:\r\nrefill_rx_ring(dev);\r\nif (debug > 5)\r\nprintk(KERN_DEBUG " exiting netdev_rx(): %d, status of %d was %#8.8x.\n",\r\nretcode, np->rx_done, desc_status);\r\nreturn retcode;\r\n}\r\nstatic int netdev_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct netdev_private *np = container_of(napi, struct netdev_private, napi);\r\nstruct net_device *dev = np->dev;\r\nu32 intr_status;\r\nvoid __iomem *ioaddr = np->base;\r\nint quota = budget;\r\ndo {\r\nwritel(IntrRxDone | IntrRxEmpty, ioaddr + IntrClear);\r\nif (__netdev_rx(dev, &quota))\r\ngoto out;\r\nintr_status = readl(ioaddr + IntrStatus);\r\n} while (intr_status & (IntrRxDone | IntrRxEmpty));\r\nnapi_complete(napi);\r\nintr_status = readl(ioaddr + IntrEnable);\r\nintr_status |= IntrRxDone | IntrRxEmpty;\r\nwritel(intr_status, ioaddr + IntrEnable);\r\nout:\r\nif (debug > 5)\r\nprintk(KERN_DEBUG " exiting netdev_poll(): %d.\n",\r\nbudget - quota);\r\nreturn budget - quota;\r\n}\r\nstatic void refill_rx_ring(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nstruct sk_buff *skb;\r\nint entry = -1;\r\nfor (; np->cur_rx - np->dirty_rx > 0; np->dirty_rx++) {\r\nentry = np->dirty_rx % RX_RING_SIZE;\r\nif (np->rx_info[entry].skb == NULL) {\r\nskb = netdev_alloc_skb(dev, np->rx_buf_sz);\r\nnp->rx_info[entry].skb = skb;\r\nif (skb == NULL)\r\nbreak;\r\nnp->rx_info[entry].mapping =\r\npci_map_single(np->pci_dev, skb->data, np->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nnp->rx_ring[entry].rxaddr =\r\ncpu_to_dma(np->rx_info[entry].mapping | RxDescValid);\r\n}\r\nif (entry == RX_RING_SIZE - 1)\r\nnp->rx_ring[entry].rxaddr |= cpu_to_dma(RxDescEndRing);\r\n}\r\nif (entry >= 0)\r\nwritew(entry, np->base + RxDescQIdx);\r\n}\r\nstatic void netdev_media_change(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base;\r\nu16 reg0, reg1, reg4, reg5;\r\nu32 new_tx_mode;\r\nu32 new_intr_timer_ctrl;\r\nmdio_read(dev, np->phys[0], MII_BMCR);\r\nmdio_read(dev, np->phys[0], MII_BMSR);\r\nreg0 = mdio_read(dev, np->phys[0], MII_BMCR);\r\nreg1 = mdio_read(dev, np->phys[0], MII_BMSR);\r\nif (reg1 & BMSR_LSTATUS) {\r\nif (reg0 & BMCR_ANENABLE) {\r\nreg4 = mdio_read(dev, np->phys[0], MII_ADVERTISE);\r\nreg5 = mdio_read(dev, np->phys[0], MII_LPA);\r\nif (reg4 & ADVERTISE_100FULL && reg5 & LPA_100FULL) {\r\nnp->speed100 = 1;\r\nnp->mii_if.full_duplex = 1;\r\n} else if (reg4 & ADVERTISE_100HALF && reg5 & LPA_100HALF) {\r\nnp->speed100 = 1;\r\nnp->mii_if.full_duplex = 0;\r\n} else if (reg4 & ADVERTISE_10FULL && reg5 & LPA_10FULL) {\r\nnp->speed100 = 0;\r\nnp->mii_if.full_duplex = 1;\r\n} else {\r\nnp->speed100 = 0;\r\nnp->mii_if.full_duplex = 0;\r\n}\r\n} else {\r\nif (reg0 & BMCR_SPEED100)\r\nnp->speed100 = 1;\r\nelse\r\nnp->speed100 = 0;\r\nif (reg0 & BMCR_FULLDPLX)\r\nnp->mii_if.full_duplex = 1;\r\nelse\r\nnp->mii_if.full_duplex = 0;\r\n}\r\nnetif_carrier_on(dev);\r\nprintk(KERN_DEBUG "%s: Link is up, running at %sMbit %s-duplex\n",\r\ndev->name,\r\nnp->speed100 ? "100" : "10",\r\nnp->mii_if.full_duplex ? "full" : "half");\r\nnew_tx_mode = np->tx_mode & ~FullDuplex;\r\nif (np->mii_if.full_duplex)\r\nnew_tx_mode |= FullDuplex;\r\nif (np->tx_mode != new_tx_mode) {\r\nnp->tx_mode = new_tx_mode;\r\nwritel(np->tx_mode | MiiSoftReset, ioaddr + TxMode);\r\nudelay(1000);\r\nwritel(np->tx_mode, ioaddr + TxMode);\r\n}\r\nnew_intr_timer_ctrl = np->intr_timer_ctrl & ~Timer10X;\r\nif (np->speed100)\r\nnew_intr_timer_ctrl |= Timer10X;\r\nif (np->intr_timer_ctrl != new_intr_timer_ctrl) {\r\nnp->intr_timer_ctrl = new_intr_timer_ctrl;\r\nwritel(new_intr_timer_ctrl, ioaddr + IntrTimerCtrl);\r\n}\r\n} else {\r\nnetif_carrier_off(dev);\r\nprintk(KERN_DEBUG "%s: Link is down\n", dev->name);\r\n}\r\n}\r\nstatic void netdev_error(struct net_device *dev, int intr_status)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nif (intr_status & IntrTxDataLow) {\r\nif (np->tx_threshold <= PKT_BUF_SZ / 16) {\r\nwritel(++np->tx_threshold, np->base + TxThreshold);\r\nprintk(KERN_NOTICE "%s: PCI bus congestion, increasing Tx FIFO threshold to %d bytes\n",\r\ndev->name, np->tx_threshold * 16);\r\n} else\r\nprintk(KERN_WARNING "%s: PCI Tx underflow -- adapter is probably malfunctioning\n", dev->name);\r\n}\r\nif (intr_status & IntrRxGFPDead) {\r\ndev->stats.rx_fifo_errors++;\r\ndev->stats.rx_errors++;\r\n}\r\nif (intr_status & (IntrNoTxCsum | IntrDMAErr)) {\r\ndev->stats.tx_fifo_errors++;\r\ndev->stats.tx_errors++;\r\n}\r\nif ((intr_status & ~(IntrNormalMask | IntrAbnormalSummary | IntrLinkChange | IntrStatsMax | IntrTxDataLow | IntrRxGFPDead | IntrNoTxCsum | IntrPCIPad)) && debug)\r\nprintk(KERN_ERR "%s: Something Wicked happened! %#8.8x.\n",\r\ndev->name, intr_status);\r\n}\r\nstatic struct net_device_stats *get_stats(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base;\r\ndev->stats.tx_bytes = readl(ioaddr + 0x57010);\r\ndev->stats.rx_bytes = readl(ioaddr + 0x57044);\r\ndev->stats.tx_packets = readl(ioaddr + 0x57000);\r\ndev->stats.tx_aborted_errors =\r\nreadl(ioaddr + 0x57024) + readl(ioaddr + 0x57028);\r\ndev->stats.tx_window_errors = readl(ioaddr + 0x57018);\r\ndev->stats.collisions =\r\nreadl(ioaddr + 0x57004) + readl(ioaddr + 0x57008);\r\ndev->stats.rx_dropped += readw(ioaddr + RxDMAStatus);\r\nwritew(0, ioaddr + RxDMAStatus);\r\ndev->stats.rx_crc_errors = readl(ioaddr + 0x5703C);\r\ndev->stats.rx_frame_errors = readl(ioaddr + 0x57040);\r\ndev->stats.rx_length_errors = readl(ioaddr + 0x57058);\r\ndev->stats.rx_missed_errors = readl(ioaddr + 0x5707C);\r\nreturn &dev->stats;\r\n}\r\nstatic u32 set_vlan_mode(struct netdev_private *np)\r\n{\r\nu32 ret = VlanMode;\r\nu16 vid;\r\nvoid __iomem *filter_addr = np->base + HashTable + 8;\r\nint vlan_count = 0;\r\nfor_each_set_bit(vid, np->active_vlans, VLAN_N_VID) {\r\nif (vlan_count == 32)\r\nbreak;\r\nwritew(vid, filter_addr);\r\nfilter_addr += 16;\r\nvlan_count++;\r\n}\r\nif (vlan_count == 32) {\r\nret |= PerfectFilterVlan;\r\nwhile (vlan_count < 32) {\r\nwritew(0, filter_addr);\r\nfilter_addr += 16;\r\nvlan_count++;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic void set_rx_mode(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base;\r\nu32 rx_mode = MinVLANPrio;\r\nstruct netdev_hw_addr *ha;\r\nint i;\r\n#ifdef VLAN_SUPPORT\r\nrx_mode |= set_vlan_mode(np);\r\n#endif\r\nif (dev->flags & IFF_PROMISC) {\r\nrx_mode |= AcceptAll;\r\n} else if ((netdev_mc_count(dev) > multicast_filter_limit) ||\r\n(dev->flags & IFF_ALLMULTI)) {\r\nrx_mode |= AcceptBroadcast|AcceptAllMulticast|PerfectFilter;\r\n} else if (netdev_mc_count(dev) <= 14) {\r\nvoid __iomem *filter_addr = ioaddr + PerfFilterTable + 2 * 16;\r\n__be16 *eaddrs;\r\nnetdev_for_each_mc_addr(ha, dev) {\r\neaddrs = (__be16 *) ha->addr;\r\nwritew(be16_to_cpu(eaddrs[2]), filter_addr); filter_addr += 4;\r\nwritew(be16_to_cpu(eaddrs[1]), filter_addr); filter_addr += 4;\r\nwritew(be16_to_cpu(eaddrs[0]), filter_addr); filter_addr += 8;\r\n}\r\neaddrs = (__be16 *)dev->dev_addr;\r\ni = netdev_mc_count(dev) + 2;\r\nwhile (i++ < 16) {\r\nwritew(be16_to_cpu(eaddrs[0]), filter_addr); filter_addr += 4;\r\nwritew(be16_to_cpu(eaddrs[1]), filter_addr); filter_addr += 4;\r\nwritew(be16_to_cpu(eaddrs[2]), filter_addr); filter_addr += 8;\r\n}\r\nrx_mode |= AcceptBroadcast|PerfectFilter;\r\n} else {\r\nvoid __iomem *filter_addr;\r\n__be16 *eaddrs;\r\n__le16 mc_filter[32] __attribute__ ((aligned(sizeof(long))));\r\nmemset(mc_filter, 0, sizeof(mc_filter));\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nint bit_nr = ether_crc_le(ETH_ALEN, ha->addr) >> 23;\r\n__le32 *fptr = (__le32 *) &mc_filter[(bit_nr >> 4) & ~1];\r\n*fptr |= cpu_to_le32(1 << (bit_nr & 31));\r\n}\r\nfilter_addr = ioaddr + PerfFilterTable + 2 * 16;\r\neaddrs = (__be16 *)dev->dev_addr;\r\nfor (i = 2; i < 16; i++) {\r\nwritew(be16_to_cpu(eaddrs[0]), filter_addr); filter_addr += 4;\r\nwritew(be16_to_cpu(eaddrs[1]), filter_addr); filter_addr += 4;\r\nwritew(be16_to_cpu(eaddrs[2]), filter_addr); filter_addr += 8;\r\n}\r\nfor (filter_addr = ioaddr + HashTable, i = 0; i < 32; filter_addr+= 16, i++)\r\nwritew(mc_filter[i], filter_addr);\r\nrx_mode |= AcceptBroadcast|PerfectFilter|HashFilter;\r\n}\r\nwritel(rx_mode, ioaddr + RxFilterMode);\r\n}\r\nstatic int check_if_running(struct net_device *dev)\r\n{\r\nif (!netif_running(dev))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic void get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(np->pci_dev), sizeof(info->bus_info));\r\n}\r\nstatic int get_settings(struct net_device *dev, struct ethtool_cmd *ecmd)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nspin_lock_irq(&np->lock);\r\nmii_ethtool_gset(&np->mii_if, ecmd);\r\nspin_unlock_irq(&np->lock);\r\nreturn 0;\r\n}\r\nstatic int set_settings(struct net_device *dev, struct ethtool_cmd *ecmd)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint res;\r\nspin_lock_irq(&np->lock);\r\nres = mii_ethtool_sset(&np->mii_if, ecmd);\r\nspin_unlock_irq(&np->lock);\r\ncheck_duplex(dev);\r\nreturn res;\r\n}\r\nstatic int nway_reset(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nreturn mii_nway_restart(&np->mii_if);\r\n}\r\nstatic u32 get_link(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nreturn mii_link_ok(&np->mii_if);\r\n}\r\nstatic u32 get_msglevel(struct net_device *dev)\r\n{\r\nreturn debug;\r\n}\r\nstatic void set_msglevel(struct net_device *dev, u32 val)\r\n{\r\ndebug = val;\r\n}\r\nstatic int netdev_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nstruct mii_ioctl_data *data = if_mii(rq);\r\nint rc;\r\nif (!netif_running(dev))\r\nreturn -EINVAL;\r\nspin_lock_irq(&np->lock);\r\nrc = generic_mii_ioctl(&np->mii_if, data, cmd, NULL);\r\nspin_unlock_irq(&np->lock);\r\nif ((cmd == SIOCSMIIREG) && (data->phy_id == np->phys[0]))\r\ncheck_duplex(dev);\r\nreturn rc;\r\n}\r\nstatic int netdev_close(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base;\r\nint i;\r\nnetif_stop_queue(dev);\r\nnapi_disable(&np->napi);\r\nif (debug > 1) {\r\nprintk(KERN_DEBUG "%s: Shutting down ethercard, Intr status %#8.8x.\n",\r\ndev->name, (int) readl(ioaddr + IntrStatus));\r\nprintk(KERN_DEBUG "%s: Queue pointers were Tx %d / %d, Rx %d / %d.\n",\r\ndev->name, np->cur_tx, np->dirty_tx,\r\nnp->cur_rx, np->dirty_rx);\r\n}\r\nwritel(0, ioaddr + IntrEnable);\r\nwritel(0, ioaddr + GenCtrl);\r\nreadl(ioaddr + GenCtrl);\r\nif (debug > 5) {\r\nprintk(KERN_DEBUG" Tx ring at %#llx:\n",\r\n(long long) np->tx_ring_dma);\r\nfor (i = 0; i < 8 ; i++)\r\nprintk(KERN_DEBUG " #%d desc. %#8.8x %#llx -> %#8.8x.\n",\r\ni, le32_to_cpu(np->tx_ring[i].status),\r\n(long long) dma_to_cpu(np->tx_ring[i].addr),\r\nle32_to_cpu(np->tx_done_q[i].status));\r\nprintk(KERN_DEBUG " Rx ring at %#llx -> %p:\n",\r\n(long long) np->rx_ring_dma, np->rx_done_q);\r\nif (np->rx_done_q)\r\nfor (i = 0; i < 8 ; i++) {\r\nprintk(KERN_DEBUG " #%d desc. %#llx -> %#8.8x\n",\r\ni, (long long) dma_to_cpu(np->rx_ring[i].rxaddr), le32_to_cpu(np->rx_done_q[i].status));\r\n}\r\n}\r\nfree_irq(np->pci_dev->irq, dev);\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nnp->rx_ring[i].rxaddr = cpu_to_dma(0xBADF00D0);\r\nif (np->rx_info[i].skb != NULL) {\r\npci_unmap_single(np->pci_dev, np->rx_info[i].mapping, np->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(np->rx_info[i].skb);\r\n}\r\nnp->rx_info[i].skb = NULL;\r\nnp->rx_info[i].mapping = 0;\r\n}\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nstruct sk_buff *skb = np->tx_info[i].skb;\r\nif (skb == NULL)\r\ncontinue;\r\npci_unmap_single(np->pci_dev,\r\nnp->tx_info[i].mapping,\r\nskb_first_frag_len(skb), PCI_DMA_TODEVICE);\r\nnp->tx_info[i].mapping = 0;\r\ndev_kfree_skb(skb);\r\nnp->tx_info[i].skb = NULL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int starfire_suspend(struct pci_dev *pdev, pm_message_t state)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nif (netif_running(dev)) {\r\nnetif_device_detach(dev);\r\nnetdev_close(dev);\r\n}\r\npci_save_state(pdev);\r\npci_set_power_state(pdev, pci_choose_state(pdev,state));\r\nreturn 0;\r\n}\r\nstatic int starfire_resume(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\npci_set_power_state(pdev, PCI_D0);\r\npci_restore_state(pdev);\r\nif (netif_running(dev)) {\r\nnetdev_open(dev);\r\nnetif_device_attach(dev);\r\n}\r\nreturn 0;\r\n}\r\nstatic void __devexit starfire_remove_one (struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct netdev_private *np = netdev_priv(dev);\r\nBUG_ON(!dev);\r\nunregister_netdev(dev);\r\nif (np->queue_mem)\r\npci_free_consistent(pdev, np->queue_mem_size, np->queue_mem, np->queue_mem_dma);\r\npci_set_power_state(pdev, PCI_D3hot);\r\npci_disable_device(pdev);\r\niounmap(np->base);\r\npci_release_regions(pdev);\r\npci_set_drvdata(pdev, NULL);\r\nfree_netdev(dev);\r\n}\r\nstatic int __init starfire_init (void)\r\n{\r\n#ifdef MODULE\r\nprintk(version);\r\nprintk(KERN_INFO DRV_NAME ": polling (NAPI) enabled\n");\r\n#endif\r\nBUILD_BUG_ON(sizeof(dma_addr_t) != sizeof(netdrv_addr_t));\r\nreturn pci_register_driver(&starfire_driver);\r\n}\r\nstatic void __exit starfire_cleanup (void)\r\n{\r\npci_unregister_driver (&starfire_driver);\r\n}
