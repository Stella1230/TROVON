STATIC int\r\nxfs_alloc_lookup_eq(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agblock_t bno,\r\nxfs_extlen_t len,\r\nint *stat)\r\n{\r\ncur->bc_rec.a.ar_startblock = bno;\r\ncur->bc_rec.a.ar_blockcount = len;\r\nreturn xfs_btree_lookup(cur, XFS_LOOKUP_EQ, stat);\r\n}\r\nint\r\nxfs_alloc_lookup_ge(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agblock_t bno,\r\nxfs_extlen_t len,\r\nint *stat)\r\n{\r\ncur->bc_rec.a.ar_startblock = bno;\r\ncur->bc_rec.a.ar_blockcount = len;\r\nreturn xfs_btree_lookup(cur, XFS_LOOKUP_GE, stat);\r\n}\r\nint\r\nxfs_alloc_lookup_le(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agblock_t bno,\r\nxfs_extlen_t len,\r\nint *stat)\r\n{\r\ncur->bc_rec.a.ar_startblock = bno;\r\ncur->bc_rec.a.ar_blockcount = len;\r\nreturn xfs_btree_lookup(cur, XFS_LOOKUP_LE, stat);\r\n}\r\nSTATIC int\r\nxfs_alloc_update(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agblock_t bno,\r\nxfs_extlen_t len)\r\n{\r\nunion xfs_btree_rec rec;\r\nrec.alloc.ar_startblock = cpu_to_be32(bno);\r\nrec.alloc.ar_blockcount = cpu_to_be32(len);\r\nreturn xfs_btree_update(cur, &rec);\r\n}\r\nint\r\nxfs_alloc_get_rec(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agblock_t *bno,\r\nxfs_extlen_t *len,\r\nint *stat)\r\n{\r\nunion xfs_btree_rec *rec;\r\nint error;\r\nerror = xfs_btree_get_rec(cur, &rec, stat);\r\nif (!error && *stat == 1) {\r\n*bno = be32_to_cpu(rec->alloc.ar_startblock);\r\n*len = be32_to_cpu(rec->alloc.ar_blockcount);\r\n}\r\nreturn error;\r\n}\r\nSTATIC void\r\nxfs_alloc_compute_aligned(\r\nxfs_alloc_arg_t *args,\r\nxfs_agblock_t foundbno,\r\nxfs_extlen_t foundlen,\r\nxfs_agblock_t *resbno,\r\nxfs_extlen_t *reslen)\r\n{\r\nxfs_agblock_t bno;\r\nxfs_extlen_t len;\r\nxfs_extent_busy_trim(args, foundbno, foundlen, &bno, &len);\r\nif (args->alignment > 1 && len >= args->minlen) {\r\nxfs_agblock_t aligned_bno = roundup(bno, args->alignment);\r\nxfs_extlen_t diff = aligned_bno - bno;\r\n*resbno = aligned_bno;\r\n*reslen = diff >= len ? 0 : len - diff;\r\n} else {\r\n*resbno = bno;\r\n*reslen = len;\r\n}\r\n}\r\nSTATIC xfs_extlen_t\r\nxfs_alloc_compute_diff(\r\nxfs_agblock_t wantbno,\r\nxfs_extlen_t wantlen,\r\nxfs_extlen_t alignment,\r\nxfs_agblock_t freebno,\r\nxfs_extlen_t freelen,\r\nxfs_agblock_t *newbnop)\r\n{\r\nxfs_agblock_t freeend;\r\nxfs_agblock_t newbno1;\r\nxfs_agblock_t newbno2;\r\nxfs_extlen_t newlen1=0;\r\nxfs_extlen_t newlen2=0;\r\nxfs_agblock_t wantend;\r\nASSERT(freelen >= wantlen);\r\nfreeend = freebno + freelen;\r\nwantend = wantbno + wantlen;\r\nif (freebno >= wantbno) {\r\nif ((newbno1 = roundup(freebno, alignment)) >= freeend)\r\nnewbno1 = NULLAGBLOCK;\r\n} else if (freeend >= wantend && alignment > 1) {\r\nnewbno1 = roundup(wantbno, alignment);\r\nnewbno2 = newbno1 - alignment;\r\nif (newbno1 >= freeend)\r\nnewbno1 = NULLAGBLOCK;\r\nelse\r\nnewlen1 = XFS_EXTLEN_MIN(wantlen, freeend - newbno1);\r\nif (newbno2 < freebno)\r\nnewbno2 = NULLAGBLOCK;\r\nelse\r\nnewlen2 = XFS_EXTLEN_MIN(wantlen, freeend - newbno2);\r\nif (newbno1 != NULLAGBLOCK && newbno2 != NULLAGBLOCK) {\r\nif (newlen1 < newlen2 ||\r\n(newlen1 == newlen2 &&\r\nXFS_ABSDIFF(newbno1, wantbno) >\r\nXFS_ABSDIFF(newbno2, wantbno)))\r\nnewbno1 = newbno2;\r\n} else if (newbno2 != NULLAGBLOCK)\r\nnewbno1 = newbno2;\r\n} else if (freeend >= wantend) {\r\nnewbno1 = wantbno;\r\n} else if (alignment > 1) {\r\nnewbno1 = roundup(freeend - wantlen, alignment);\r\nif (newbno1 > freeend - wantlen &&\r\nnewbno1 - alignment >= freebno)\r\nnewbno1 -= alignment;\r\nelse if (newbno1 >= freeend)\r\nnewbno1 = NULLAGBLOCK;\r\n} else\r\nnewbno1 = freeend - wantlen;\r\n*newbnop = newbno1;\r\nreturn newbno1 == NULLAGBLOCK ? 0 : XFS_ABSDIFF(newbno1, wantbno);\r\n}\r\nSTATIC void\r\nxfs_alloc_fix_len(\r\nxfs_alloc_arg_t *args)\r\n{\r\nxfs_extlen_t k;\r\nxfs_extlen_t rlen;\r\nASSERT(args->mod < args->prod);\r\nrlen = args->len;\r\nASSERT(rlen >= args->minlen);\r\nASSERT(rlen <= args->maxlen);\r\nif (args->prod <= 1 || rlen < args->mod || rlen == args->maxlen ||\r\n(args->mod == 0 && rlen < args->prod))\r\nreturn;\r\nk = rlen % args->prod;\r\nif (k == args->mod)\r\nreturn;\r\nif (k > args->mod) {\r\nif ((int)(rlen = rlen - k - args->mod) < (int)args->minlen)\r\nreturn;\r\n} else {\r\nif ((int)(rlen = rlen - args->prod - (args->mod - k)) <\r\n(int)args->minlen)\r\nreturn;\r\n}\r\nASSERT(rlen >= args->minlen);\r\nASSERT(rlen <= args->maxlen);\r\nargs->len = rlen;\r\n}\r\nSTATIC int\r\nxfs_alloc_fix_minleft(\r\nxfs_alloc_arg_t *args)\r\n{\r\nxfs_agf_t *agf;\r\nint diff;\r\nif (args->minleft == 0)\r\nreturn 1;\r\nagf = XFS_BUF_TO_AGF(args->agbp);\r\ndiff = be32_to_cpu(agf->agf_freeblks)\r\n- args->len - args->minleft;\r\nif (diff >= 0)\r\nreturn 1;\r\nargs->len += diff;\r\nif (args->len >= args->minlen)\r\nreturn 1;\r\nargs->agbno = NULLAGBLOCK;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_alloc_fixup_trees(\r\nxfs_btree_cur_t *cnt_cur,\r\nxfs_btree_cur_t *bno_cur,\r\nxfs_agblock_t fbno,\r\nxfs_extlen_t flen,\r\nxfs_agblock_t rbno,\r\nxfs_extlen_t rlen,\r\nint flags)\r\n{\r\nint error;\r\nint i;\r\nxfs_agblock_t nfbno1;\r\nxfs_agblock_t nfbno2;\r\nxfs_extlen_t nflen1=0;\r\nxfs_extlen_t nflen2=0;\r\nif (flags & XFSA_FIXUP_CNT_OK) {\r\n#ifdef DEBUG\r\nif ((error = xfs_alloc_get_rec(cnt_cur, &nfbno1, &nflen1, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(\r\ni == 1 && nfbno1 == fbno && nflen1 == flen);\r\n#endif\r\n} else {\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, fbno, flen, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 1);\r\n}\r\nif (flags & XFSA_FIXUP_BNO_OK) {\r\n#ifdef DEBUG\r\nif ((error = xfs_alloc_get_rec(bno_cur, &nfbno1, &nflen1, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(\r\ni == 1 && nfbno1 == fbno && nflen1 == flen);\r\n#endif\r\n} else {\r\nif ((error = xfs_alloc_lookup_eq(bno_cur, fbno, flen, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 1);\r\n}\r\n#ifdef DEBUG\r\nif (bno_cur->bc_nlevels == 1 && cnt_cur->bc_nlevels == 1) {\r\nstruct xfs_btree_block *bnoblock;\r\nstruct xfs_btree_block *cntblock;\r\nbnoblock = XFS_BUF_TO_BLOCK(bno_cur->bc_bufs[0]);\r\ncntblock = XFS_BUF_TO_BLOCK(cnt_cur->bc_bufs[0]);\r\nXFS_WANT_CORRUPTED_RETURN(\r\nbnoblock->bb_numrecs == cntblock->bb_numrecs);\r\n}\r\n#endif\r\nif (rbno == fbno && rlen == flen)\r\nnfbno1 = nfbno2 = NULLAGBLOCK;\r\nelse if (rbno == fbno) {\r\nnfbno1 = rbno + rlen;\r\nnflen1 = flen - rlen;\r\nnfbno2 = NULLAGBLOCK;\r\n} else if (rbno + rlen == fbno + flen) {\r\nnfbno1 = fbno;\r\nnflen1 = flen - rlen;\r\nnfbno2 = NULLAGBLOCK;\r\n} else {\r\nnfbno1 = fbno;\r\nnflen1 = rbno - fbno;\r\nnfbno2 = rbno + rlen;\r\nnflen2 = (fbno + flen) - nfbno2;\r\n}\r\nif ((error = xfs_btree_delete(cnt_cur, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 1);\r\nif (nfbno1 != NULLAGBLOCK) {\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, nfbno1, nflen1, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 0);\r\nif ((error = xfs_btree_insert(cnt_cur, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 1);\r\n}\r\nif (nfbno2 != NULLAGBLOCK) {\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, nfbno2, nflen2, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 0);\r\nif ((error = xfs_btree_insert(cnt_cur, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 1);\r\n}\r\nif (nfbno1 == NULLAGBLOCK) {\r\nif ((error = xfs_btree_delete(bno_cur, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 1);\r\n} else {\r\nif ((error = xfs_alloc_update(bno_cur, nfbno1, nflen1)))\r\nreturn error;\r\n}\r\nif (nfbno2 != NULLAGBLOCK) {\r\nif ((error = xfs_alloc_lookup_eq(bno_cur, nfbno2, nflen2, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 0);\r\nif ((error = xfs_btree_insert(bno_cur, &i)))\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(i == 1);\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_alloc_read_agfl(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_agnumber_t agno,\r\nxfs_buf_t **bpp)\r\n{\r\nxfs_buf_t *bp;\r\nint error;\r\nASSERT(agno != NULLAGNUMBER);\r\nerror = xfs_trans_read_buf(\r\nmp, tp, mp->m_ddev_targp,\r\nXFS_AG_DADDR(mp, agno, XFS_AGFL_DADDR(mp)),\r\nXFS_FSS_TO_BB(mp, 1), 0, &bp);\r\nif (error)\r\nreturn error;\r\nASSERT(!xfs_buf_geterror(bp));\r\nxfs_buf_set_ref(bp, XFS_AGFL_REF);\r\n*bpp = bp;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_alloc_update_counters(\r\nstruct xfs_trans *tp,\r\nstruct xfs_perag *pag,\r\nstruct xfs_buf *agbp,\r\nlong len)\r\n{\r\nstruct xfs_agf *agf = XFS_BUF_TO_AGF(agbp);\r\npag->pagf_freeblks += len;\r\nbe32_add_cpu(&agf->agf_freeblks, len);\r\nxfs_trans_agblocks_delta(tp, len);\r\nif (unlikely(be32_to_cpu(agf->agf_freeblks) >\r\nbe32_to_cpu(agf->agf_length)))\r\nreturn EFSCORRUPTED;\r\nxfs_alloc_log_agf(tp, agbp, XFS_AGF_FREEBLKS);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_alloc_ag_vextent(\r\nxfs_alloc_arg_t *args)\r\n{\r\nint error=0;\r\nASSERT(args->minlen > 0);\r\nASSERT(args->maxlen > 0);\r\nASSERT(args->minlen <= args->maxlen);\r\nASSERT(args->mod < args->prod);\r\nASSERT(args->alignment > 0);\r\nargs->wasfromfl = 0;\r\nswitch (args->type) {\r\ncase XFS_ALLOCTYPE_THIS_AG:\r\nerror = xfs_alloc_ag_vextent_size(args);\r\nbreak;\r\ncase XFS_ALLOCTYPE_NEAR_BNO:\r\nerror = xfs_alloc_ag_vextent_near(args);\r\nbreak;\r\ncase XFS_ALLOCTYPE_THIS_BNO:\r\nerror = xfs_alloc_ag_vextent_exact(args);\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\n}\r\nif (error || args->agbno == NULLAGBLOCK)\r\nreturn error;\r\nASSERT(args->len >= args->minlen);\r\nASSERT(args->len <= args->maxlen);\r\nASSERT(!args->wasfromfl || !args->isfl);\r\nASSERT(args->agbno % args->alignment == 0);\r\nif (!args->wasfromfl) {\r\nerror = xfs_alloc_update_counters(args->tp, args->pag,\r\nargs->agbp,\r\n-((long)(args->len)));\r\nif (error)\r\nreturn error;\r\nASSERT(!xfs_extent_busy_search(args->mp, args->agno,\r\nargs->agbno, args->len));\r\n}\r\nif (!args->isfl) {\r\nxfs_trans_mod_sb(args->tp, args->wasdel ?\r\nXFS_TRANS_SB_RES_FDBLOCKS :\r\nXFS_TRANS_SB_FDBLOCKS,\r\n-((long)(args->len)));\r\n}\r\nXFS_STATS_INC(xs_allocx);\r\nXFS_STATS_ADD(xs_allocb, args->len);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_alloc_ag_vextent_exact(\r\nxfs_alloc_arg_t *args)\r\n{\r\nxfs_btree_cur_t *bno_cur;\r\nxfs_btree_cur_t *cnt_cur;\r\nint error;\r\nxfs_agblock_t fbno;\r\nxfs_extlen_t flen;\r\nxfs_agblock_t tbno;\r\nxfs_extlen_t tlen;\r\nxfs_agblock_t tend;\r\nint i;\r\nASSERT(args->alignment == 1);\r\nbno_cur = xfs_allocbt_init_cursor(args->mp, args->tp, args->agbp,\r\nargs->agno, XFS_BTNUM_BNO);\r\nerror = xfs_alloc_lookup_le(bno_cur, args->agbno, args->minlen, &i);\r\nif (error)\r\ngoto error0;\r\nif (!i)\r\ngoto not_found;\r\nerror = xfs_alloc_get_rec(bno_cur, &fbno, &flen, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nASSERT(fbno <= args->agbno);\r\nxfs_extent_busy_trim(args, fbno, flen, &tbno, &tlen);\r\nif (tbno > args->agbno)\r\ngoto not_found;\r\nif (tlen < args->minlen)\r\ngoto not_found;\r\ntend = tbno + tlen;\r\nif (tend < args->agbno + args->minlen)\r\ngoto not_found;\r\nargs->len = XFS_AGBLOCK_MIN(tend, args->agbno + args->maxlen)\r\n- args->agbno;\r\nxfs_alloc_fix_len(args);\r\nif (!xfs_alloc_fix_minleft(args))\r\ngoto not_found;\r\nASSERT(args->agbno + args->len <= tend);\r\ncnt_cur = xfs_allocbt_init_cursor(args->mp, args->tp, args->agbp,\r\nargs->agno, XFS_BTNUM_CNT);\r\nASSERT(args->agbno + args->len <=\r\nbe32_to_cpu(XFS_BUF_TO_AGF(args->agbp)->agf_length));\r\nerror = xfs_alloc_fixup_trees(cnt_cur, bno_cur, fbno, flen, args->agbno,\r\nargs->len, XFSA_FIXUP_BNO_OK);\r\nif (error) {\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_ERROR);\r\ngoto error0;\r\n}\r\nxfs_btree_del_cursor(bno_cur, XFS_BTREE_NOERROR);\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\nargs->wasfromfl = 0;\r\ntrace_xfs_alloc_exact_done(args);\r\nreturn 0;\r\nnot_found:\r\nxfs_btree_del_cursor(bno_cur, XFS_BTREE_NOERROR);\r\nargs->agbno = NULLAGBLOCK;\r\ntrace_xfs_alloc_exact_notfound(args);\r\nreturn 0;\r\nerror0:\r\nxfs_btree_del_cursor(bno_cur, XFS_BTREE_ERROR);\r\ntrace_xfs_alloc_exact_error(args);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_alloc_find_best_extent(\r\nstruct xfs_alloc_arg *args,\r\nstruct xfs_btree_cur **gcur,\r\nstruct xfs_btree_cur **scur,\r\nxfs_agblock_t gdiff,\r\nxfs_agblock_t *sbno,\r\nxfs_extlen_t *slen,\r\nxfs_agblock_t *sbnoa,\r\nxfs_extlen_t *slena,\r\nint dir)\r\n{\r\nxfs_agblock_t new;\r\nxfs_agblock_t sdiff;\r\nint error;\r\nint i;\r\nif (!gdiff)\r\ngoto out_use_good;\r\ndo {\r\nerror = xfs_alloc_get_rec(*scur, sbno, slen, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nxfs_alloc_compute_aligned(args, *sbno, *slen, sbnoa, slena);\r\nif (!dir) {\r\nif (*sbnoa >= args->agbno + gdiff)\r\ngoto out_use_good;\r\n} else {\r\nif (*sbnoa <= args->agbno - gdiff)\r\ngoto out_use_good;\r\n}\r\nif (*slena >= args->minlen) {\r\nargs->len = XFS_EXTLEN_MIN(*slena, args->maxlen);\r\nxfs_alloc_fix_len(args);\r\nsdiff = xfs_alloc_compute_diff(args->agbno, args->len,\r\nargs->alignment, *sbnoa,\r\n*slena, &new);\r\nif (sdiff < gdiff)\r\ngoto out_use_search;\r\ngoto out_use_good;\r\n}\r\nif (!dir)\r\nerror = xfs_btree_increment(*scur, 0, &i);\r\nelse\r\nerror = xfs_btree_decrement(*scur, 0, &i);\r\nif (error)\r\ngoto error0;\r\n} while (i);\r\nout_use_good:\r\nxfs_btree_del_cursor(*scur, XFS_BTREE_NOERROR);\r\n*scur = NULL;\r\nreturn 0;\r\nout_use_search:\r\nxfs_btree_del_cursor(*gcur, XFS_BTREE_NOERROR);\r\n*gcur = NULL;\r\nreturn 0;\r\nerror0:\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_alloc_ag_vextent_near(\r\nxfs_alloc_arg_t *args)\r\n{\r\nxfs_btree_cur_t *bno_cur_gt;\r\nxfs_btree_cur_t *bno_cur_lt;\r\nxfs_btree_cur_t *cnt_cur;\r\nxfs_agblock_t gtbno;\r\nxfs_agblock_t gtbnoa;\r\nxfs_extlen_t gtdiff;\r\nxfs_extlen_t gtlen;\r\nxfs_extlen_t gtlena;\r\nxfs_agblock_t gtnew;\r\nint error;\r\nint i;\r\nint j;\r\nxfs_agblock_t ltbno;\r\nxfs_agblock_t ltbnoa;\r\nxfs_extlen_t ltdiff;\r\nxfs_extlen_t ltlen;\r\nxfs_extlen_t ltlena;\r\nxfs_agblock_t ltnew;\r\nxfs_extlen_t rlen;\r\nint forced = 0;\r\n#if defined(DEBUG) && defined(__KERNEL__)\r\nint dofirst;\r\ndofirst = random32() & 1;\r\n#endif\r\nrestart:\r\nbno_cur_lt = NULL;\r\nbno_cur_gt = NULL;\r\nltlen = 0;\r\ngtlena = 0;\r\nltlena = 0;\r\ncnt_cur = xfs_allocbt_init_cursor(args->mp, args->tp, args->agbp,\r\nargs->agno, XFS_BTNUM_CNT);\r\nif ((error = xfs_alloc_lookup_ge(cnt_cur, 0, args->maxlen, &i)))\r\ngoto error0;\r\nif (!i) {\r\nif ((error = xfs_alloc_ag_vextent_small(args, cnt_cur, &ltbno,\r\n&ltlen, &i)))\r\ngoto error0;\r\nif (i == 0 || ltlen == 0) {\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\ntrace_xfs_alloc_near_noentry(args);\r\nreturn 0;\r\n}\r\nASSERT(i == 1);\r\n}\r\nargs->wasfromfl = 0;\r\nwhile (xfs_btree_islastblock(cnt_cur, 0)) {\r\nxfs_extlen_t bdiff;\r\nint besti=0;\r\nxfs_extlen_t blen=0;\r\nxfs_agblock_t bnew=0;\r\n#if defined(DEBUG) && defined(__KERNEL__)\r\nif (!dofirst)\r\nbreak;\r\n#endif\r\nif (ltlen || args->alignment > 1) {\r\ncnt_cur->bc_ptrs[0] = 1;\r\ndo {\r\nif ((error = xfs_alloc_get_rec(cnt_cur, &ltbno,\r\n&ltlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif (ltlen >= args->minlen)\r\nbreak;\r\nif ((error = xfs_btree_increment(cnt_cur, 0, &i)))\r\ngoto error0;\r\n} while (i);\r\nASSERT(ltlen >= args->minlen);\r\nif (!i)\r\nbreak;\r\n}\r\ni = cnt_cur->bc_ptrs[0];\r\nfor (j = 1, blen = 0, bdiff = 0;\r\n!error && j && (blen < args->maxlen || bdiff > 0);\r\nerror = xfs_btree_increment(cnt_cur, 0, &j)) {\r\nif ((error = xfs_alloc_get_rec(cnt_cur, &ltbno, &ltlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nxfs_alloc_compute_aligned(args, ltbno, ltlen,\r\n&ltbnoa, &ltlena);\r\nif (ltlena < args->minlen)\r\ncontinue;\r\nargs->len = XFS_EXTLEN_MIN(ltlena, args->maxlen);\r\nxfs_alloc_fix_len(args);\r\nASSERT(args->len >= args->minlen);\r\nif (args->len < blen)\r\ncontinue;\r\nltdiff = xfs_alloc_compute_diff(args->agbno, args->len,\r\nargs->alignment, ltbnoa, ltlena, &ltnew);\r\nif (ltnew != NULLAGBLOCK &&\r\n(args->len > blen || ltdiff < bdiff)) {\r\nbdiff = ltdiff;\r\nbnew = ltnew;\r\nblen = args->len;\r\nbesti = cnt_cur->bc_ptrs[0];\r\n}\r\n}\r\nif (blen == 0)\r\nbreak;\r\ncnt_cur->bc_ptrs[0] = besti;\r\nif ((error = xfs_alloc_get_rec(cnt_cur, &ltbno, &ltlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nASSERT(ltbno + ltlen <= be32_to_cpu(XFS_BUF_TO_AGF(args->agbp)->agf_length));\r\nargs->len = blen;\r\nif (!xfs_alloc_fix_minleft(args)) {\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\ntrace_xfs_alloc_near_nominleft(args);\r\nreturn 0;\r\n}\r\nblen = args->len;\r\nargs->agbno = bnew;\r\nASSERT(bnew >= ltbno);\r\nASSERT(bnew + blen <= ltbno + ltlen);\r\nbno_cur_lt = xfs_allocbt_init_cursor(args->mp, args->tp,\r\nargs->agbp, args->agno, XFS_BTNUM_BNO);\r\nif ((error = xfs_alloc_fixup_trees(cnt_cur, bno_cur_lt, ltbno,\r\nltlen, bnew, blen, XFSA_FIXUP_CNT_OK)))\r\ngoto error0;\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\nxfs_btree_del_cursor(bno_cur_lt, XFS_BTREE_NOERROR);\r\ntrace_xfs_alloc_near_first(args);\r\nreturn 0;\r\n}\r\nbno_cur_lt = xfs_allocbt_init_cursor(args->mp, args->tp, args->agbp,\r\nargs->agno, XFS_BTNUM_BNO);\r\nif ((error = xfs_alloc_lookup_le(bno_cur_lt, args->agbno, args->maxlen, &i)))\r\ngoto error0;\r\nif (!i) {\r\nbno_cur_gt = bno_cur_lt;\r\nbno_cur_lt = NULL;\r\n}\r\nelse if ((error = xfs_btree_dup_cursor(bno_cur_lt, &bno_cur_gt)))\r\ngoto error0;\r\nif ((error = xfs_btree_increment(bno_cur_gt, 0, &i)))\r\ngoto error0;\r\nif (!i) {\r\nxfs_btree_del_cursor(bno_cur_gt, XFS_BTREE_NOERROR);\r\nbno_cur_gt = NULL;\r\n}\r\ndo {\r\nif (bno_cur_lt) {\r\nif ((error = xfs_alloc_get_rec(bno_cur_lt, &ltbno, &ltlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nxfs_alloc_compute_aligned(args, ltbno, ltlen,\r\n&ltbnoa, &ltlena);\r\nif (ltlena >= args->minlen)\r\nbreak;\r\nif ((error = xfs_btree_decrement(bno_cur_lt, 0, &i)))\r\ngoto error0;\r\nif (!i) {\r\nxfs_btree_del_cursor(bno_cur_lt,\r\nXFS_BTREE_NOERROR);\r\nbno_cur_lt = NULL;\r\n}\r\n}\r\nif (bno_cur_gt) {\r\nif ((error = xfs_alloc_get_rec(bno_cur_gt, &gtbno, &gtlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nxfs_alloc_compute_aligned(args, gtbno, gtlen,\r\n&gtbnoa, &gtlena);\r\nif (gtlena >= args->minlen)\r\nbreak;\r\nif ((error = xfs_btree_increment(bno_cur_gt, 0, &i)))\r\ngoto error0;\r\nif (!i) {\r\nxfs_btree_del_cursor(bno_cur_gt,\r\nXFS_BTREE_NOERROR);\r\nbno_cur_gt = NULL;\r\n}\r\n}\r\n} while (bno_cur_lt || bno_cur_gt);\r\nif (bno_cur_lt && bno_cur_gt) {\r\nif (ltlena >= args->minlen) {\r\nargs->len = XFS_EXTLEN_MIN(ltlena, args->maxlen);\r\nxfs_alloc_fix_len(args);\r\nltdiff = xfs_alloc_compute_diff(args->agbno, args->len,\r\nargs->alignment, ltbnoa, ltlena, &ltnew);\r\nerror = xfs_alloc_find_best_extent(args,\r\n&bno_cur_lt, &bno_cur_gt,\r\nltdiff, &gtbno, &gtlen,\r\n&gtbnoa, &gtlena,\r\n0 );\r\n} else {\r\nASSERT(gtlena >= args->minlen);\r\nargs->len = XFS_EXTLEN_MIN(gtlena, args->maxlen);\r\nxfs_alloc_fix_len(args);\r\ngtdiff = xfs_alloc_compute_diff(args->agbno, args->len,\r\nargs->alignment, gtbnoa, gtlena, &gtnew);\r\nerror = xfs_alloc_find_best_extent(args,\r\n&bno_cur_gt, &bno_cur_lt,\r\ngtdiff, &ltbno, &ltlen,\r\n&ltbnoa, &ltlena,\r\n1 );\r\n}\r\nif (error)\r\ngoto error0;\r\n}\r\nif (bno_cur_lt == NULL && bno_cur_gt == NULL) {\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\nif (!forced++) {\r\ntrace_xfs_alloc_near_busy(args);\r\nxfs_log_force(args->mp, XFS_LOG_SYNC);\r\ngoto restart;\r\n}\r\ntrace_xfs_alloc_size_neither(args);\r\nargs->agbno = NULLAGBLOCK;\r\nreturn 0;\r\n}\r\nif (bno_cur_gt) {\r\nbno_cur_lt = bno_cur_gt;\r\nbno_cur_gt = NULL;\r\nltbno = gtbno;\r\nltbnoa = gtbnoa;\r\nltlen = gtlen;\r\nltlena = gtlena;\r\nj = 1;\r\n} else\r\nj = 0;\r\nargs->len = XFS_EXTLEN_MIN(ltlena, args->maxlen);\r\nxfs_alloc_fix_len(args);\r\nif (!xfs_alloc_fix_minleft(args)) {\r\ntrace_xfs_alloc_near_nominleft(args);\r\nxfs_btree_del_cursor(bno_cur_lt, XFS_BTREE_NOERROR);\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\nreturn 0;\r\n}\r\nrlen = args->len;\r\n(void)xfs_alloc_compute_diff(args->agbno, rlen, args->alignment,\r\nltbnoa, ltlena, &ltnew);\r\nASSERT(ltnew >= ltbno);\r\nASSERT(ltnew + rlen <= ltbnoa + ltlena);\r\nASSERT(ltnew + rlen <= be32_to_cpu(XFS_BUF_TO_AGF(args->agbp)->agf_length));\r\nargs->agbno = ltnew;\r\nif ((error = xfs_alloc_fixup_trees(cnt_cur, bno_cur_lt, ltbno, ltlen,\r\nltnew, rlen, XFSA_FIXUP_BNO_OK)))\r\ngoto error0;\r\nif (j)\r\ntrace_xfs_alloc_near_greater(args);\r\nelse\r\ntrace_xfs_alloc_near_lesser(args);\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\nxfs_btree_del_cursor(bno_cur_lt, XFS_BTREE_NOERROR);\r\nreturn 0;\r\nerror0:\r\ntrace_xfs_alloc_near_error(args);\r\nif (cnt_cur != NULL)\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_ERROR);\r\nif (bno_cur_lt != NULL)\r\nxfs_btree_del_cursor(bno_cur_lt, XFS_BTREE_ERROR);\r\nif (bno_cur_gt != NULL)\r\nxfs_btree_del_cursor(bno_cur_gt, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_alloc_ag_vextent_size(\r\nxfs_alloc_arg_t *args)\r\n{\r\nxfs_btree_cur_t *bno_cur;\r\nxfs_btree_cur_t *cnt_cur;\r\nint error;\r\nxfs_agblock_t fbno;\r\nxfs_extlen_t flen;\r\nint i;\r\nxfs_agblock_t rbno;\r\nxfs_extlen_t rlen;\r\nint forced = 0;\r\nrestart:\r\ncnt_cur = xfs_allocbt_init_cursor(args->mp, args->tp, args->agbp,\r\nargs->agno, XFS_BTNUM_CNT);\r\nbno_cur = NULL;\r\nif ((error = xfs_alloc_lookup_ge(cnt_cur, 0,\r\nargs->maxlen + args->alignment - 1, &i)))\r\ngoto error0;\r\nif (!i || forced > 1) {\r\nerror = xfs_alloc_ag_vextent_small(args, cnt_cur,\r\n&fbno, &flen, &i);\r\nif (error)\r\ngoto error0;\r\nif (i == 0 || flen == 0) {\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\ntrace_xfs_alloc_size_noentry(args);\r\nreturn 0;\r\n}\r\nASSERT(i == 1);\r\nxfs_alloc_compute_aligned(args, fbno, flen, &rbno, &rlen);\r\n} else {\r\nfor (;;) {\r\nerror = xfs_alloc_get_rec(cnt_cur, &fbno, &flen, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nxfs_alloc_compute_aligned(args, fbno, flen,\r\n&rbno, &rlen);\r\nif (rlen >= args->maxlen)\r\nbreak;\r\nerror = xfs_btree_increment(cnt_cur, 0, &i);\r\nif (error)\r\ngoto error0;\r\nif (i == 0) {\r\nxfs_btree_del_cursor(cnt_cur,\r\nXFS_BTREE_NOERROR);\r\ntrace_xfs_alloc_size_busy(args);\r\nif (!forced++)\r\nxfs_log_force(args->mp, XFS_LOG_SYNC);\r\ngoto restart;\r\n}\r\n}\r\n}\r\nrlen = XFS_EXTLEN_MIN(args->maxlen, rlen);\r\nXFS_WANT_CORRUPTED_GOTO(rlen == 0 ||\r\n(rlen <= flen && rbno + rlen <= fbno + flen), error0);\r\nif (rlen < args->maxlen) {\r\nxfs_agblock_t bestfbno;\r\nxfs_extlen_t bestflen;\r\nxfs_agblock_t bestrbno;\r\nxfs_extlen_t bestrlen;\r\nbestrlen = rlen;\r\nbestrbno = rbno;\r\nbestflen = flen;\r\nbestfbno = fbno;\r\nfor (;;) {\r\nif ((error = xfs_btree_decrement(cnt_cur, 0, &i)))\r\ngoto error0;\r\nif (i == 0)\r\nbreak;\r\nif ((error = xfs_alloc_get_rec(cnt_cur, &fbno, &flen,\r\n&i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif (flen < bestrlen)\r\nbreak;\r\nxfs_alloc_compute_aligned(args, fbno, flen,\r\n&rbno, &rlen);\r\nrlen = XFS_EXTLEN_MIN(args->maxlen, rlen);\r\nXFS_WANT_CORRUPTED_GOTO(rlen == 0 ||\r\n(rlen <= flen && rbno + rlen <= fbno + flen),\r\nerror0);\r\nif (rlen > bestrlen) {\r\nbestrlen = rlen;\r\nbestrbno = rbno;\r\nbestflen = flen;\r\nbestfbno = fbno;\r\nif (rlen == args->maxlen)\r\nbreak;\r\n}\r\n}\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, bestfbno, bestflen,\r\n&i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nrlen = bestrlen;\r\nrbno = bestrbno;\r\nflen = bestflen;\r\nfbno = bestfbno;\r\n}\r\nargs->wasfromfl = 0;\r\nargs->len = rlen;\r\nif (rlen < args->minlen) {\r\nif (!forced++) {\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\ntrace_xfs_alloc_size_busy(args);\r\nxfs_log_force(args->mp, XFS_LOG_SYNC);\r\ngoto restart;\r\n}\r\ngoto out_nominleft;\r\n}\r\nxfs_alloc_fix_len(args);\r\nif (!xfs_alloc_fix_minleft(args))\r\ngoto out_nominleft;\r\nrlen = args->len;\r\nXFS_WANT_CORRUPTED_GOTO(rlen <= flen, error0);\r\nbno_cur = xfs_allocbt_init_cursor(args->mp, args->tp, args->agbp,\r\nargs->agno, XFS_BTNUM_BNO);\r\nif ((error = xfs_alloc_fixup_trees(cnt_cur, bno_cur, fbno, flen,\r\nrbno, rlen, XFSA_FIXUP_CNT_OK)))\r\ngoto error0;\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\nxfs_btree_del_cursor(bno_cur, XFS_BTREE_NOERROR);\r\ncnt_cur = bno_cur = NULL;\r\nargs->len = rlen;\r\nargs->agbno = rbno;\r\nXFS_WANT_CORRUPTED_GOTO(\r\nargs->agbno + args->len <=\r\nbe32_to_cpu(XFS_BUF_TO_AGF(args->agbp)->agf_length),\r\nerror0);\r\ntrace_xfs_alloc_size_done(args);\r\nreturn 0;\r\nerror0:\r\ntrace_xfs_alloc_size_error(args);\r\nif (cnt_cur)\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_ERROR);\r\nif (bno_cur)\r\nxfs_btree_del_cursor(bno_cur, XFS_BTREE_ERROR);\r\nreturn error;\r\nout_nominleft:\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\ntrace_xfs_alloc_size_nominleft(args);\r\nargs->agbno = NULLAGBLOCK;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_alloc_ag_vextent_small(\r\nxfs_alloc_arg_t *args,\r\nxfs_btree_cur_t *ccur,\r\nxfs_agblock_t *fbnop,\r\nxfs_extlen_t *flenp,\r\nint *stat)\r\n{\r\nint error;\r\nxfs_agblock_t fbno;\r\nxfs_extlen_t flen;\r\nint i;\r\nif ((error = xfs_btree_decrement(ccur, 0, &i)))\r\ngoto error0;\r\nif (i) {\r\nif ((error = xfs_alloc_get_rec(ccur, &fbno, &flen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\n}\r\nelse if (args->minlen == 1 && args->alignment == 1 && !args->isfl &&\r\n(be32_to_cpu(XFS_BUF_TO_AGF(args->agbp)->agf_flcount)\r\n> args->minleft)) {\r\nerror = xfs_alloc_get_freelist(args->tp, args->agbp, &fbno, 0);\r\nif (error)\r\ngoto error0;\r\nif (fbno != NULLAGBLOCK) {\r\nxfs_extent_busy_reuse(args->mp, args->agno, fbno, 1,\r\nargs->userdata);\r\nif (args->userdata) {\r\nxfs_buf_t *bp;\r\nbp = xfs_btree_get_bufs(args->mp, args->tp,\r\nargs->agno, fbno, 0);\r\nxfs_trans_binval(args->tp, bp);\r\n}\r\nargs->len = 1;\r\nargs->agbno = fbno;\r\nXFS_WANT_CORRUPTED_GOTO(\r\nargs->agbno + args->len <=\r\nbe32_to_cpu(XFS_BUF_TO_AGF(args->agbp)->agf_length),\r\nerror0);\r\nargs->wasfromfl = 1;\r\ntrace_xfs_alloc_small_freelist(args);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\nelse\r\nflen = 0;\r\n}\r\nelse {\r\nfbno = NULLAGBLOCK;\r\nflen = 0;\r\n}\r\nif (flen < args->minlen) {\r\nargs->agbno = NULLAGBLOCK;\r\ntrace_xfs_alloc_small_notenough(args);\r\nflen = 0;\r\n}\r\n*fbnop = fbno;\r\n*flenp = flen;\r\n*stat = 1;\r\ntrace_xfs_alloc_small_done(args);\r\nreturn 0;\r\nerror0:\r\ntrace_xfs_alloc_small_error(args);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_free_ag_extent(\r\nxfs_trans_t *tp,\r\nxfs_buf_t *agbp,\r\nxfs_agnumber_t agno,\r\nxfs_agblock_t bno,\r\nxfs_extlen_t len,\r\nint isfl)\r\n{\r\nxfs_btree_cur_t *bno_cur;\r\nxfs_btree_cur_t *cnt_cur;\r\nint error;\r\nxfs_agblock_t gtbno;\r\nxfs_extlen_t gtlen;\r\nint haveleft;\r\nint haveright;\r\nint i;\r\nxfs_agblock_t ltbno;\r\nxfs_extlen_t ltlen;\r\nxfs_mount_t *mp;\r\nxfs_agblock_t nbno;\r\nxfs_extlen_t nlen;\r\nxfs_perag_t *pag;\r\nmp = tp->t_mountp;\r\nbno_cur = xfs_allocbt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_BNO);\r\ncnt_cur = NULL;\r\nif ((error = xfs_alloc_lookup_le(bno_cur, bno, len, &haveleft)))\r\ngoto error0;\r\nif (haveleft) {\r\nif ((error = xfs_alloc_get_rec(bno_cur, &ltbno, &ltlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif (ltbno + ltlen < bno)\r\nhaveleft = 0;\r\nelse {\r\nXFS_WANT_CORRUPTED_GOTO(ltbno + ltlen <= bno, error0);\r\n}\r\n}\r\nif ((error = xfs_btree_increment(bno_cur, 0, &haveright)))\r\ngoto error0;\r\nif (haveright) {\r\nif ((error = xfs_alloc_get_rec(bno_cur, &gtbno, &gtlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif (bno + len < gtbno)\r\nhaveright = 0;\r\nelse {\r\nXFS_WANT_CORRUPTED_GOTO(gtbno >= bno + len, error0);\r\n}\r\n}\r\ncnt_cur = xfs_allocbt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_CNT);\r\nif (haveleft && haveright) {\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, ltbno, ltlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_btree_delete(cnt_cur, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, gtbno, gtlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_btree_delete(cnt_cur, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_btree_delete(bno_cur, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_btree_decrement(bno_cur, 0, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\n#ifdef DEBUG\r\n{\r\nxfs_agblock_t xxbno;\r\nxfs_extlen_t xxlen;\r\nif ((error = xfs_alloc_get_rec(bno_cur, &xxbno, &xxlen,\r\n&i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(\r\ni == 1 && xxbno == ltbno && xxlen == ltlen,\r\nerror0);\r\n}\r\n#endif\r\nnbno = ltbno;\r\nnlen = len + ltlen + gtlen;\r\nif ((error = xfs_alloc_update(bno_cur, nbno, nlen)))\r\ngoto error0;\r\n}\r\nelse if (haveleft) {\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, ltbno, ltlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_btree_delete(cnt_cur, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_btree_decrement(bno_cur, 0, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nnbno = ltbno;\r\nnlen = len + ltlen;\r\nif ((error = xfs_alloc_update(bno_cur, nbno, nlen)))\r\ngoto error0;\r\n}\r\nelse if (haveright) {\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, gtbno, gtlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nif ((error = xfs_btree_delete(cnt_cur, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nnbno = bno;\r\nnlen = len + gtlen;\r\nif ((error = xfs_alloc_update(bno_cur, nbno, nlen)))\r\ngoto error0;\r\n}\r\nelse {\r\nnbno = bno;\r\nnlen = len;\r\nif ((error = xfs_btree_insert(bno_cur, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\n}\r\nxfs_btree_del_cursor(bno_cur, XFS_BTREE_NOERROR);\r\nbno_cur = NULL;\r\nif ((error = xfs_alloc_lookup_eq(cnt_cur, nbno, nlen, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 0, error0);\r\nif ((error = xfs_btree_insert(cnt_cur, &i)))\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(i == 1, error0);\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_NOERROR);\r\ncnt_cur = NULL;\r\npag = xfs_perag_get(mp, agno);\r\nerror = xfs_alloc_update_counters(tp, pag, agbp, len);\r\nxfs_perag_put(pag);\r\nif (error)\r\ngoto error0;\r\nif (!isfl)\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_FDBLOCKS, (long)len);\r\nXFS_STATS_INC(xs_freex);\r\nXFS_STATS_ADD(xs_freeb, len);\r\ntrace_xfs_free_extent(mp, agno, bno, len, isfl, haveleft, haveright);\r\nreturn 0;\r\nerror0:\r\ntrace_xfs_free_extent(mp, agno, bno, len, isfl, -1, -1);\r\nif (bno_cur)\r\nxfs_btree_del_cursor(bno_cur, XFS_BTREE_ERROR);\r\nif (cnt_cur)\r\nxfs_btree_del_cursor(cnt_cur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nvoid\r\nxfs_alloc_compute_maxlevels(\r\nxfs_mount_t *mp)\r\n{\r\nint level;\r\nuint maxblocks;\r\nuint maxleafents;\r\nint minleafrecs;\r\nint minnoderecs;\r\nmaxleafents = (mp->m_sb.sb_agblocks + 1) / 2;\r\nminleafrecs = mp->m_alloc_mnr[0];\r\nminnoderecs = mp->m_alloc_mnr[1];\r\nmaxblocks = (maxleafents + minleafrecs - 1) / minleafrecs;\r\nfor (level = 1; maxblocks > 1; level++)\r\nmaxblocks = (maxblocks + minnoderecs - 1) / minnoderecs;\r\nmp->m_ag_maxlevels = level;\r\n}\r\nxfs_extlen_t\r\nxfs_alloc_longest_free_extent(\r\nstruct xfs_mount *mp,\r\nstruct xfs_perag *pag)\r\n{\r\nxfs_extlen_t need, delta = 0;\r\nneed = XFS_MIN_FREELIST_PAG(pag, mp);\r\nif (need > pag->pagf_flcount)\r\ndelta = need - pag->pagf_flcount;\r\nif (pag->pagf_longest > delta)\r\nreturn pag->pagf_longest - delta;\r\nreturn pag->pagf_flcount > 0 || pag->pagf_longest > 0;\r\n}\r\nSTATIC int\r\nxfs_alloc_fix_freelist(\r\nxfs_alloc_arg_t *args,\r\nint flags)\r\n{\r\nxfs_buf_t *agbp;\r\nxfs_agf_t *agf;\r\nxfs_buf_t *agflbp;\r\nxfs_agblock_t bno;\r\nxfs_extlen_t delta;\r\nint error;\r\nxfs_extlen_t longest;\r\nxfs_mount_t *mp;\r\nxfs_extlen_t need;\r\nxfs_perag_t *pag;\r\nxfs_alloc_arg_t targs;\r\nxfs_trans_t *tp;\r\nmp = args->mp;\r\npag = args->pag;\r\ntp = args->tp;\r\nif (!pag->pagf_init) {\r\nif ((error = xfs_alloc_read_agf(mp, tp, args->agno, flags,\r\n&agbp)))\r\nreturn error;\r\nif (!pag->pagf_init) {\r\nASSERT(flags & XFS_ALLOC_FLAG_TRYLOCK);\r\nASSERT(!(flags & XFS_ALLOC_FLAG_FREEING));\r\nargs->agbp = NULL;\r\nreturn 0;\r\n}\r\n} else\r\nagbp = NULL;\r\nif (pag->pagf_metadata && args->userdata &&\r\n(flags & XFS_ALLOC_FLAG_TRYLOCK)) {\r\nASSERT(!(flags & XFS_ALLOC_FLAG_FREEING));\r\nargs->agbp = NULL;\r\nreturn 0;\r\n}\r\nif (!(flags & XFS_ALLOC_FLAG_FREEING)) {\r\nneed = XFS_MIN_FREELIST_PAG(pag, mp);\r\nlongest = xfs_alloc_longest_free_extent(mp, pag);\r\nif ((args->minlen + args->alignment + args->minalignslop - 1) >\r\nlongest ||\r\n((int)(pag->pagf_freeblks + pag->pagf_flcount -\r\nneed - args->total) < (int)args->minleft)) {\r\nif (agbp)\r\nxfs_trans_brelse(tp, agbp);\r\nargs->agbp = NULL;\r\nreturn 0;\r\n}\r\n}\r\nif (agbp == NULL) {\r\nif ((error = xfs_alloc_read_agf(mp, tp, args->agno, flags,\r\n&agbp)))\r\nreturn error;\r\nif (agbp == NULL) {\r\nASSERT(flags & XFS_ALLOC_FLAG_TRYLOCK);\r\nASSERT(!(flags & XFS_ALLOC_FLAG_FREEING));\r\nargs->agbp = NULL;\r\nreturn 0;\r\n}\r\n}\r\nagf = XFS_BUF_TO_AGF(agbp);\r\nneed = XFS_MIN_FREELIST(agf, mp);\r\nif (!(flags & XFS_ALLOC_FLAG_FREEING)) {\r\ndelta = need > be32_to_cpu(agf->agf_flcount) ?\r\n(need - be32_to_cpu(agf->agf_flcount)) : 0;\r\nlongest = be32_to_cpu(agf->agf_longest);\r\nlongest = (longest > delta) ? (longest - delta) :\r\n(be32_to_cpu(agf->agf_flcount) > 0 || longest > 0);\r\nif ((args->minlen + args->alignment + args->minalignslop - 1) >\r\nlongest ||\r\n((int)(be32_to_cpu(agf->agf_freeblks) +\r\nbe32_to_cpu(agf->agf_flcount) - need - args->total) <\r\n(int)args->minleft)) {\r\nxfs_trans_brelse(tp, agbp);\r\nargs->agbp = NULL;\r\nreturn 0;\r\n}\r\n}\r\nwhile (be32_to_cpu(agf->agf_flcount) > need) {\r\nxfs_buf_t *bp;\r\nerror = xfs_alloc_get_freelist(tp, agbp, &bno, 0);\r\nif (error)\r\nreturn error;\r\nif ((error = xfs_free_ag_extent(tp, agbp, args->agno, bno, 1, 1)))\r\nreturn error;\r\nbp = xfs_btree_get_bufs(mp, tp, args->agno, bno, 0);\r\nxfs_trans_binval(tp, bp);\r\n}\r\ntargs.tp = tp;\r\ntargs.mp = mp;\r\ntargs.agbp = agbp;\r\ntargs.agno = args->agno;\r\ntargs.mod = targs.minleft = targs.wasdel = targs.userdata =\r\ntargs.minalignslop = 0;\r\ntargs.alignment = targs.minlen = targs.prod = targs.isfl = 1;\r\ntargs.type = XFS_ALLOCTYPE_THIS_AG;\r\ntargs.pag = pag;\r\nif ((error = xfs_alloc_read_agfl(mp, tp, targs.agno, &agflbp)))\r\nreturn error;\r\nwhile (be32_to_cpu(agf->agf_flcount) < need) {\r\ntargs.agbno = 0;\r\ntargs.maxlen = need - be32_to_cpu(agf->agf_flcount);\r\nif ((error = xfs_alloc_ag_vextent(&targs))) {\r\nxfs_trans_brelse(tp, agflbp);\r\nreturn error;\r\n}\r\nif (targs.agbno == NULLAGBLOCK) {\r\nif (flags & XFS_ALLOC_FLAG_FREEING)\r\nbreak;\r\nxfs_trans_brelse(tp, agflbp);\r\nargs->agbp = NULL;\r\nreturn 0;\r\n}\r\nfor (bno = targs.agbno; bno < targs.agbno + targs.len; bno++) {\r\nerror = xfs_alloc_put_freelist(tp, agbp,\r\nagflbp, bno, 0);\r\nif (error)\r\nreturn error;\r\n}\r\n}\r\nxfs_trans_brelse(tp, agflbp);\r\nargs->agbp = agbp;\r\nreturn 0;\r\n}\r\nint\r\nxfs_alloc_get_freelist(\r\nxfs_trans_t *tp,\r\nxfs_buf_t *agbp,\r\nxfs_agblock_t *bnop,\r\nint btreeblk)\r\n{\r\nxfs_agf_t *agf;\r\nxfs_agfl_t *agfl;\r\nxfs_buf_t *agflbp;\r\nxfs_agblock_t bno;\r\nint error;\r\nint logflags;\r\nxfs_mount_t *mp;\r\nxfs_perag_t *pag;\r\nagf = XFS_BUF_TO_AGF(agbp);\r\nif (!agf->agf_flcount) {\r\n*bnop = NULLAGBLOCK;\r\nreturn 0;\r\n}\r\nmp = tp->t_mountp;\r\nif ((error = xfs_alloc_read_agfl(mp, tp,\r\nbe32_to_cpu(agf->agf_seqno), &agflbp)))\r\nreturn error;\r\nagfl = XFS_BUF_TO_AGFL(agflbp);\r\nbno = be32_to_cpu(agfl->agfl_bno[be32_to_cpu(agf->agf_flfirst)]);\r\nbe32_add_cpu(&agf->agf_flfirst, 1);\r\nxfs_trans_brelse(tp, agflbp);\r\nif (be32_to_cpu(agf->agf_flfirst) == XFS_AGFL_SIZE(mp))\r\nagf->agf_flfirst = 0;\r\npag = xfs_perag_get(mp, be32_to_cpu(agf->agf_seqno));\r\nbe32_add_cpu(&agf->agf_flcount, -1);\r\nxfs_trans_agflist_delta(tp, -1);\r\npag->pagf_flcount--;\r\nxfs_perag_put(pag);\r\nlogflags = XFS_AGF_FLFIRST | XFS_AGF_FLCOUNT;\r\nif (btreeblk) {\r\nbe32_add_cpu(&agf->agf_btreeblks, 1);\r\npag->pagf_btreeblks++;\r\nlogflags |= XFS_AGF_BTREEBLKS;\r\n}\r\nxfs_alloc_log_agf(tp, agbp, logflags);\r\n*bnop = bno;\r\nreturn 0;\r\n}\r\nvoid\r\nxfs_alloc_log_agf(\r\nxfs_trans_t *tp,\r\nxfs_buf_t *bp,\r\nint fields)\r\n{\r\nint first;\r\nint last;\r\nstatic const short offsets[] = {\r\noffsetof(xfs_agf_t, agf_magicnum),\r\noffsetof(xfs_agf_t, agf_versionnum),\r\noffsetof(xfs_agf_t, agf_seqno),\r\noffsetof(xfs_agf_t, agf_length),\r\noffsetof(xfs_agf_t, agf_roots[0]),\r\noffsetof(xfs_agf_t, agf_levels[0]),\r\noffsetof(xfs_agf_t, agf_flfirst),\r\noffsetof(xfs_agf_t, agf_fllast),\r\noffsetof(xfs_agf_t, agf_flcount),\r\noffsetof(xfs_agf_t, agf_freeblks),\r\noffsetof(xfs_agf_t, agf_longest),\r\noffsetof(xfs_agf_t, agf_btreeblks),\r\nsizeof(xfs_agf_t)\r\n};\r\ntrace_xfs_agf(tp->t_mountp, XFS_BUF_TO_AGF(bp), fields, _RET_IP_);\r\nxfs_btree_offsets(fields, offsets, XFS_AGF_NUM_BITS, &first, &last);\r\nxfs_trans_log_buf(tp, bp, (uint)first, (uint)last);\r\n}\r\nint\r\nxfs_alloc_pagf_init(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_agnumber_t agno,\r\nint flags)\r\n{\r\nxfs_buf_t *bp;\r\nint error;\r\nif ((error = xfs_alloc_read_agf(mp, tp, agno, flags, &bp)))\r\nreturn error;\r\nif (bp)\r\nxfs_trans_brelse(tp, bp);\r\nreturn 0;\r\n}\r\nint\r\nxfs_alloc_put_freelist(\r\nxfs_trans_t *tp,\r\nxfs_buf_t *agbp,\r\nxfs_buf_t *agflbp,\r\nxfs_agblock_t bno,\r\nint btreeblk)\r\n{\r\nxfs_agf_t *agf;\r\nxfs_agfl_t *agfl;\r\n__be32 *blockp;\r\nint error;\r\nint logflags;\r\nxfs_mount_t *mp;\r\nxfs_perag_t *pag;\r\nagf = XFS_BUF_TO_AGF(agbp);\r\nmp = tp->t_mountp;\r\nif (!agflbp && (error = xfs_alloc_read_agfl(mp, tp,\r\nbe32_to_cpu(agf->agf_seqno), &agflbp)))\r\nreturn error;\r\nagfl = XFS_BUF_TO_AGFL(agflbp);\r\nbe32_add_cpu(&agf->agf_fllast, 1);\r\nif (be32_to_cpu(agf->agf_fllast) == XFS_AGFL_SIZE(mp))\r\nagf->agf_fllast = 0;\r\npag = xfs_perag_get(mp, be32_to_cpu(agf->agf_seqno));\r\nbe32_add_cpu(&agf->agf_flcount, 1);\r\nxfs_trans_agflist_delta(tp, 1);\r\npag->pagf_flcount++;\r\nlogflags = XFS_AGF_FLLAST | XFS_AGF_FLCOUNT;\r\nif (btreeblk) {\r\nbe32_add_cpu(&agf->agf_btreeblks, -1);\r\npag->pagf_btreeblks--;\r\nlogflags |= XFS_AGF_BTREEBLKS;\r\n}\r\nxfs_perag_put(pag);\r\nxfs_alloc_log_agf(tp, agbp, logflags);\r\nASSERT(be32_to_cpu(agf->agf_flcount) <= XFS_AGFL_SIZE(mp));\r\nblockp = &agfl->agfl_bno[be32_to_cpu(agf->agf_fllast)];\r\n*blockp = cpu_to_be32(bno);\r\nxfs_alloc_log_agf(tp, agbp, logflags);\r\nxfs_trans_log_buf(tp, agflbp,\r\n(int)((xfs_caddr_t)blockp - (xfs_caddr_t)agfl),\r\n(int)((xfs_caddr_t)blockp - (xfs_caddr_t)agfl +\r\nsizeof(xfs_agblock_t) - 1));\r\nreturn 0;\r\n}\r\nint\r\nxfs_read_agf(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nxfs_agnumber_t agno,\r\nint flags,\r\nstruct xfs_buf **bpp)\r\n{\r\nstruct xfs_agf *agf;\r\nint agf_ok;\r\nint error;\r\nASSERT(agno != NULLAGNUMBER);\r\nerror = xfs_trans_read_buf(\r\nmp, tp, mp->m_ddev_targp,\r\nXFS_AG_DADDR(mp, agno, XFS_AGF_DADDR(mp)),\r\nXFS_FSS_TO_BB(mp, 1), flags, bpp);\r\nif (error)\r\nreturn error;\r\nif (!*bpp)\r\nreturn 0;\r\nASSERT(!(*bpp)->b_error);\r\nagf = XFS_BUF_TO_AGF(*bpp);\r\nagf_ok =\r\nagf->agf_magicnum == cpu_to_be32(XFS_AGF_MAGIC) &&\r\nXFS_AGF_GOOD_VERSION(be32_to_cpu(agf->agf_versionnum)) &&\r\nbe32_to_cpu(agf->agf_freeblks) <= be32_to_cpu(agf->agf_length) &&\r\nbe32_to_cpu(agf->agf_flfirst) < XFS_AGFL_SIZE(mp) &&\r\nbe32_to_cpu(agf->agf_fllast) < XFS_AGFL_SIZE(mp) &&\r\nbe32_to_cpu(agf->agf_flcount) <= XFS_AGFL_SIZE(mp) &&\r\nbe32_to_cpu(agf->agf_seqno) == agno;\r\nif (xfs_sb_version_haslazysbcount(&mp->m_sb))\r\nagf_ok = agf_ok && be32_to_cpu(agf->agf_btreeblks) <=\r\nbe32_to_cpu(agf->agf_length);\r\nif (unlikely(XFS_TEST_ERROR(!agf_ok, mp, XFS_ERRTAG_ALLOC_READ_AGF,\r\nXFS_RANDOM_ALLOC_READ_AGF))) {\r\nXFS_CORRUPTION_ERROR("xfs_alloc_read_agf",\r\nXFS_ERRLEVEL_LOW, mp, agf);\r\nxfs_trans_brelse(tp, *bpp);\r\nreturn XFS_ERROR(EFSCORRUPTED);\r\n}\r\nxfs_buf_set_ref(*bpp, XFS_AGF_REF);\r\nreturn 0;\r\n}\r\nint\r\nxfs_alloc_read_agf(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nxfs_agnumber_t agno,\r\nint flags,\r\nstruct xfs_buf **bpp)\r\n{\r\nstruct xfs_agf *agf;\r\nstruct xfs_perag *pag;\r\nint error;\r\nASSERT(agno != NULLAGNUMBER);\r\nerror = xfs_read_agf(mp, tp, agno,\r\n(flags & XFS_ALLOC_FLAG_TRYLOCK) ? XBF_TRYLOCK : 0,\r\nbpp);\r\nif (error)\r\nreturn error;\r\nif (!*bpp)\r\nreturn 0;\r\nASSERT(!(*bpp)->b_error);\r\nagf = XFS_BUF_TO_AGF(*bpp);\r\npag = xfs_perag_get(mp, agno);\r\nif (!pag->pagf_init) {\r\npag->pagf_freeblks = be32_to_cpu(agf->agf_freeblks);\r\npag->pagf_btreeblks = be32_to_cpu(agf->agf_btreeblks);\r\npag->pagf_flcount = be32_to_cpu(agf->agf_flcount);\r\npag->pagf_longest = be32_to_cpu(agf->agf_longest);\r\npag->pagf_levels[XFS_BTNUM_BNOi] =\r\nbe32_to_cpu(agf->agf_levels[XFS_BTNUM_BNOi]);\r\npag->pagf_levels[XFS_BTNUM_CNTi] =\r\nbe32_to_cpu(agf->agf_levels[XFS_BTNUM_CNTi]);\r\nspin_lock_init(&pag->pagb_lock);\r\npag->pagb_count = 0;\r\npag->pagb_tree = RB_ROOT;\r\npag->pagf_init = 1;\r\n}\r\n#ifdef DEBUG\r\nelse if (!XFS_FORCED_SHUTDOWN(mp)) {\r\nASSERT(pag->pagf_freeblks == be32_to_cpu(agf->agf_freeblks));\r\nASSERT(pag->pagf_btreeblks == be32_to_cpu(agf->agf_btreeblks));\r\nASSERT(pag->pagf_flcount == be32_to_cpu(agf->agf_flcount));\r\nASSERT(pag->pagf_longest == be32_to_cpu(agf->agf_longest));\r\nASSERT(pag->pagf_levels[XFS_BTNUM_BNOi] ==\r\nbe32_to_cpu(agf->agf_levels[XFS_BTNUM_BNOi]));\r\nASSERT(pag->pagf_levels[XFS_BTNUM_CNTi] ==\r\nbe32_to_cpu(agf->agf_levels[XFS_BTNUM_CNTi]));\r\n}\r\n#endif\r\nxfs_perag_put(pag);\r\nreturn 0;\r\n}\r\nint\r\n__xfs_alloc_vextent(\r\nxfs_alloc_arg_t *args)\r\n{\r\nxfs_agblock_t agsize;\r\nint error;\r\nint flags;\r\nxfs_extlen_t minleft;\r\nxfs_mount_t *mp;\r\nxfs_agnumber_t sagno;\r\nxfs_alloctype_t type;\r\nint bump_rotor = 0;\r\nint no_min = 0;\r\nxfs_agnumber_t rotorstep = xfs_rotorstep;\r\nmp = args->mp;\r\ntype = args->otype = args->type;\r\nargs->agbno = NULLAGBLOCK;\r\nagsize = mp->m_sb.sb_agblocks;\r\nif (args->maxlen > agsize)\r\nargs->maxlen = agsize;\r\nif (args->alignment == 0)\r\nargs->alignment = 1;\r\nASSERT(XFS_FSB_TO_AGNO(mp, args->fsbno) < mp->m_sb.sb_agcount);\r\nASSERT(XFS_FSB_TO_AGBNO(mp, args->fsbno) < agsize);\r\nASSERT(args->minlen <= args->maxlen);\r\nASSERT(args->minlen <= agsize);\r\nASSERT(args->mod < args->prod);\r\nif (XFS_FSB_TO_AGNO(mp, args->fsbno) >= mp->m_sb.sb_agcount ||\r\nXFS_FSB_TO_AGBNO(mp, args->fsbno) >= agsize ||\r\nargs->minlen > args->maxlen || args->minlen > agsize ||\r\nargs->mod >= args->prod) {\r\nargs->fsbno = NULLFSBLOCK;\r\ntrace_xfs_alloc_vextent_badargs(args);\r\nreturn 0;\r\n}\r\nminleft = args->minleft;\r\nswitch (type) {\r\ncase XFS_ALLOCTYPE_THIS_AG:\r\ncase XFS_ALLOCTYPE_NEAR_BNO:\r\ncase XFS_ALLOCTYPE_THIS_BNO:\r\nargs->agno = XFS_FSB_TO_AGNO(mp, args->fsbno);\r\nargs->pag = xfs_perag_get(mp, args->agno);\r\nargs->minleft = 0;\r\nerror = xfs_alloc_fix_freelist(args, 0);\r\nargs->minleft = minleft;\r\nif (error) {\r\ntrace_xfs_alloc_vextent_nofix(args);\r\ngoto error0;\r\n}\r\nif (!args->agbp) {\r\ntrace_xfs_alloc_vextent_noagbp(args);\r\nbreak;\r\n}\r\nargs->agbno = XFS_FSB_TO_AGBNO(mp, args->fsbno);\r\nif ((error = xfs_alloc_ag_vextent(args)))\r\ngoto error0;\r\nbreak;\r\ncase XFS_ALLOCTYPE_START_BNO:\r\nif ((args->userdata == XFS_ALLOC_INITIAL_USER_DATA) &&\r\n(mp->m_flags & XFS_MOUNT_32BITINODES)) {\r\nargs->fsbno = XFS_AGB_TO_FSB(mp,\r\n((mp->m_agfrotor / rotorstep) %\r\nmp->m_sb.sb_agcount), 0);\r\nbump_rotor = 1;\r\n}\r\nargs->agbno = XFS_FSB_TO_AGBNO(mp, args->fsbno);\r\nargs->type = XFS_ALLOCTYPE_NEAR_BNO;\r\ncase XFS_ALLOCTYPE_ANY_AG:\r\ncase XFS_ALLOCTYPE_START_AG:\r\ncase XFS_ALLOCTYPE_FIRST_AG:\r\nif (type == XFS_ALLOCTYPE_ANY_AG) {\r\nargs->agno = sagno = (mp->m_agfrotor / rotorstep) %\r\nmp->m_sb.sb_agcount;\r\nargs->type = XFS_ALLOCTYPE_THIS_AG;\r\nflags = XFS_ALLOC_FLAG_TRYLOCK;\r\n} else if (type == XFS_ALLOCTYPE_FIRST_AG) {\r\nargs->agno = XFS_FSB_TO_AGNO(mp, args->fsbno);\r\nargs->type = XFS_ALLOCTYPE_THIS_AG;\r\nsagno = 0;\r\nflags = 0;\r\n} else {\r\nif (type == XFS_ALLOCTYPE_START_AG)\r\nargs->type = XFS_ALLOCTYPE_THIS_AG;\r\nargs->agno = sagno = XFS_FSB_TO_AGNO(mp, args->fsbno);\r\nflags = XFS_ALLOC_FLAG_TRYLOCK;\r\n}\r\nfor (;;) {\r\nargs->pag = xfs_perag_get(mp, args->agno);\r\nif (no_min) args->minleft = 0;\r\nerror = xfs_alloc_fix_freelist(args, flags);\r\nargs->minleft = minleft;\r\nif (error) {\r\ntrace_xfs_alloc_vextent_nofix(args);\r\ngoto error0;\r\n}\r\nif (args->agbp) {\r\nif ((error = xfs_alloc_ag_vextent(args)))\r\ngoto error0;\r\nbreak;\r\n}\r\ntrace_xfs_alloc_vextent_loopfailed(args);\r\nif (args->agno == sagno &&\r\ntype == XFS_ALLOCTYPE_START_BNO)\r\nargs->type = XFS_ALLOCTYPE_THIS_AG;\r\nif (++(args->agno) == mp->m_sb.sb_agcount) {\r\nif (args->firstblock != NULLFSBLOCK)\r\nargs->agno = sagno;\r\nelse\r\nargs->agno = 0;\r\n}\r\nif (args->agno == sagno) {\r\nif (no_min == 1) {\r\nargs->agbno = NULLAGBLOCK;\r\ntrace_xfs_alloc_vextent_allfailed(args);\r\nbreak;\r\n}\r\nif (flags == 0) {\r\nno_min = 1;\r\n} else {\r\nflags = 0;\r\nif (type == XFS_ALLOCTYPE_START_BNO) {\r\nargs->agbno = XFS_FSB_TO_AGBNO(mp,\r\nargs->fsbno);\r\nargs->type = XFS_ALLOCTYPE_NEAR_BNO;\r\n}\r\n}\r\n}\r\nxfs_perag_put(args->pag);\r\n}\r\nif (bump_rotor || (type == XFS_ALLOCTYPE_ANY_AG)) {\r\nif (args->agno == sagno)\r\nmp->m_agfrotor = (mp->m_agfrotor + 1) %\r\n(mp->m_sb.sb_agcount * rotorstep);\r\nelse\r\nmp->m_agfrotor = (args->agno * rotorstep + 1) %\r\n(mp->m_sb.sb_agcount * rotorstep);\r\n}\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\n}\r\nif (args->agbno == NULLAGBLOCK)\r\nargs->fsbno = NULLFSBLOCK;\r\nelse {\r\nargs->fsbno = XFS_AGB_TO_FSB(mp, args->agno, args->agbno);\r\n#ifdef DEBUG\r\nASSERT(args->len >= args->minlen);\r\nASSERT(args->len <= args->maxlen);\r\nASSERT(args->agbno % args->alignment == 0);\r\nXFS_AG_CHECK_DADDR(mp, XFS_FSB_TO_DADDR(mp, args->fsbno),\r\nargs->len);\r\n#endif\r\n}\r\nxfs_perag_put(args->pag);\r\nreturn 0;\r\nerror0:\r\nxfs_perag_put(args->pag);\r\nreturn error;\r\n}\r\nstatic void\r\nxfs_alloc_vextent_worker(\r\nstruct work_struct *work)\r\n{\r\nstruct xfs_alloc_arg *args = container_of(work,\r\nstruct xfs_alloc_arg, work);\r\nunsigned long pflags;\r\ncurrent_set_flags_nested(&pflags, PF_FSTRANS);\r\nargs->result = __xfs_alloc_vextent(args);\r\ncomplete(args->done);\r\ncurrent_restore_flags_nested(&pflags, PF_FSTRANS);\r\n}\r\nint\r\nxfs_alloc_vextent(\r\nstruct xfs_alloc_arg *args)\r\n{\r\nDECLARE_COMPLETION_ONSTACK(done);\r\nif (!args->userdata)\r\nreturn __xfs_alloc_vextent(args);\r\nargs->done = &done;\r\nINIT_WORK_ONSTACK(&args->work, xfs_alloc_vextent_worker);\r\nqueue_work(xfs_alloc_wq, &args->work);\r\nwait_for_completion(&done);\r\nreturn args->result;\r\n}\r\nint\r\nxfs_free_extent(\r\nxfs_trans_t *tp,\r\nxfs_fsblock_t bno,\r\nxfs_extlen_t len)\r\n{\r\nxfs_alloc_arg_t args;\r\nint error;\r\nASSERT(len != 0);\r\nmemset(&args, 0, sizeof(xfs_alloc_arg_t));\r\nargs.tp = tp;\r\nargs.mp = tp->t_mountp;\r\nargs.agno = XFS_FSB_TO_AGNO(args.mp, bno);\r\nif (args.agno >= args.mp->m_sb.sb_agcount)\r\nreturn EFSCORRUPTED;\r\nargs.agbno = XFS_FSB_TO_AGBNO(args.mp, bno);\r\nif (args.agbno >= args.mp->m_sb.sb_agblocks)\r\nreturn EFSCORRUPTED;\r\nargs.pag = xfs_perag_get(args.mp, args.agno);\r\nASSERT(args.pag);\r\nerror = xfs_alloc_fix_freelist(&args, XFS_ALLOC_FLAG_FREEING);\r\nif (error)\r\ngoto error0;\r\nif (args.agbno + len >\r\nbe32_to_cpu(XFS_BUF_TO_AGF(args.agbp)->agf_length)) {\r\nerror = EFSCORRUPTED;\r\ngoto error0;\r\n}\r\nerror = xfs_free_ag_extent(tp, args.agbp, args.agno, args.agbno, len, 0);\r\nif (!error)\r\nxfs_extent_busy_insert(tp, args.agno, args.agbno, len, 0);\r\nerror0:\r\nxfs_perag_put(args.pag);\r\nreturn error;\r\n}
