static struct sg_table *radeon_gem_map_dma_buf(struct dma_buf_attachment *attachment,\r\nenum dma_data_direction dir)\r\n{\r\nstruct radeon_bo *bo = attachment->dmabuf->priv;\r\nstruct drm_device *dev = bo->rdev->ddev;\r\nint npages = bo->tbo.num_pages;\r\nstruct sg_table *sg;\r\nint nents;\r\nmutex_lock(&dev->struct_mutex);\r\nsg = drm_prime_pages_to_sg(bo->tbo.ttm->pages, npages);\r\nnents = dma_map_sg(attachment->dev, sg->sgl, sg->nents, dir);\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn sg;\r\n}\r\nstatic void radeon_gem_unmap_dma_buf(struct dma_buf_attachment *attachment,\r\nstruct sg_table *sg, enum dma_data_direction dir)\r\n{\r\ndma_unmap_sg(attachment->dev, sg->sgl, sg->nents, dir);\r\nsg_free_table(sg);\r\nkfree(sg);\r\n}\r\nstatic void radeon_gem_dmabuf_release(struct dma_buf *dma_buf)\r\n{\r\nstruct radeon_bo *bo = dma_buf->priv;\r\nif (bo->gem_base.export_dma_buf == dma_buf) {\r\nDRM_ERROR("unreference dmabuf %p\n", &bo->gem_base);\r\nbo->gem_base.export_dma_buf = NULL;\r\ndrm_gem_object_unreference_unlocked(&bo->gem_base);\r\n}\r\n}\r\nstatic void *radeon_gem_kmap_atomic(struct dma_buf *dma_buf, unsigned long page_num)\r\n{\r\nreturn NULL;\r\n}\r\nstatic void radeon_gem_kunmap_atomic(struct dma_buf *dma_buf, unsigned long page_num, void *addr)\r\n{\r\n}\r\nstatic void *radeon_gem_kmap(struct dma_buf *dma_buf, unsigned long page_num)\r\n{\r\nreturn NULL;\r\n}\r\nstatic void radeon_gem_kunmap(struct dma_buf *dma_buf, unsigned long page_num, void *addr)\r\n{\r\n}\r\nstatic int radeon_gem_prime_mmap(struct dma_buf *dma_buf, struct vm_area_struct *vma)\r\n{\r\nreturn -EINVAL;\r\n}\r\nstatic void *radeon_gem_prime_vmap(struct dma_buf *dma_buf)\r\n{\r\nstruct radeon_bo *bo = dma_buf->priv;\r\nstruct drm_device *dev = bo->rdev->ddev;\r\nint ret;\r\nmutex_lock(&dev->struct_mutex);\r\nif (bo->vmapping_count) {\r\nbo->vmapping_count++;\r\ngoto out_unlock;\r\n}\r\nret = ttm_bo_kmap(&bo->tbo, 0, bo->tbo.num_pages,\r\n&bo->dma_buf_vmap);\r\nif (ret) {\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn ERR_PTR(ret);\r\n}\r\nbo->vmapping_count = 1;\r\nout_unlock:\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn bo->dma_buf_vmap.virtual;\r\n}\r\nstatic void radeon_gem_prime_vunmap(struct dma_buf *dma_buf, void *vaddr)\r\n{\r\nstruct radeon_bo *bo = dma_buf->priv;\r\nstruct drm_device *dev = bo->rdev->ddev;\r\nmutex_lock(&dev->struct_mutex);\r\nbo->vmapping_count--;\r\nif (bo->vmapping_count == 0) {\r\nttm_bo_kunmap(&bo->dma_buf_vmap);\r\n}\r\nmutex_unlock(&dev->struct_mutex);\r\n}\r\nstatic int radeon_prime_create(struct drm_device *dev,\r\nsize_t size,\r\nstruct sg_table *sg,\r\nstruct radeon_bo **pbo)\r\n{\r\nstruct radeon_device *rdev = dev->dev_private;\r\nstruct radeon_bo *bo;\r\nint ret;\r\nret = radeon_bo_create(rdev, size, PAGE_SIZE, false,\r\nRADEON_GEM_DOMAIN_GTT, sg, pbo);\r\nif (ret)\r\nreturn ret;\r\nbo = *pbo;\r\nbo->gem_base.driver_private = bo;\r\nmutex_lock(&rdev->gem.mutex);\r\nlist_add_tail(&bo->list, &rdev->gem.objects);\r\nmutex_unlock(&rdev->gem.mutex);\r\nreturn 0;\r\n}\r\nstruct dma_buf *radeon_gem_prime_export(struct drm_device *dev,\r\nstruct drm_gem_object *obj,\r\nint flags)\r\n{\r\nstruct radeon_bo *bo = gem_to_radeon_bo(obj);\r\nint ret = 0;\r\nret = radeon_bo_reserve(bo, false);\r\nif (unlikely(ret != 0))\r\nreturn ERR_PTR(ret);\r\nret = radeon_bo_pin(bo, RADEON_GEM_DOMAIN_GTT, NULL);\r\nif (ret) {\r\nradeon_bo_unreserve(bo);\r\nreturn ERR_PTR(ret);\r\n}\r\nradeon_bo_unreserve(bo);\r\nreturn dma_buf_export(bo, &radeon_dmabuf_ops, obj->size, flags);\r\n}\r\nstruct drm_gem_object *radeon_gem_prime_import(struct drm_device *dev,\r\nstruct dma_buf *dma_buf)\r\n{\r\nstruct dma_buf_attachment *attach;\r\nstruct sg_table *sg;\r\nstruct radeon_bo *bo;\r\nint ret;\r\nif (dma_buf->ops == &radeon_dmabuf_ops) {\r\nbo = dma_buf->priv;\r\nif (bo->gem_base.dev == dev) {\r\ndrm_gem_object_reference(&bo->gem_base);\r\nreturn &bo->gem_base;\r\n}\r\n}\r\nattach = dma_buf_attach(dma_buf, dev->dev);\r\nif (IS_ERR(attach))\r\nreturn ERR_CAST(attach);\r\nsg = dma_buf_map_attachment(attach, DMA_BIDIRECTIONAL);\r\nif (IS_ERR(sg)) {\r\nret = PTR_ERR(sg);\r\ngoto fail_detach;\r\n}\r\nret = radeon_prime_create(dev, dma_buf->size, sg, &bo);\r\nif (ret)\r\ngoto fail_unmap;\r\nbo->gem_base.import_attach = attach;\r\nreturn &bo->gem_base;\r\nfail_unmap:\r\ndma_buf_unmap_attachment(attach, sg, DMA_BIDIRECTIONAL);\r\nfail_detach:\r\ndma_buf_detach(dma_buf, attach);\r\nreturn ERR_PTR(ret);\r\n}
