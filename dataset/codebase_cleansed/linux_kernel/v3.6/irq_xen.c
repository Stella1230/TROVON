static int\r\nxen_assign_irq_vector(int irq)\r\n{\r\nstruct physdev_irq irq_op;\r\nirq_op.irq = irq;\r\nif (HYPERVISOR_physdev_op(PHYSDEVOP_alloc_irq_vector, &irq_op))\r\nreturn -ENOSPC;\r\nreturn irq_op.vector;\r\n}\r\nstatic void\r\nxen_free_irq_vector(int vector)\r\n{\r\nstruct physdev_irq irq_op;\r\nif (vector < IA64_FIRST_DEVICE_VECTOR ||\r\nvector > IA64_LAST_DEVICE_VECTOR)\r\nreturn;\r\nirq_op.vector = vector;\r\nif (HYPERVISOR_physdev_op(PHYSDEVOP_free_irq_vector, &irq_op))\r\nprintk(KERN_WARNING "%s: xen_free_irq_vector fail vector=%d\n",\r\n__func__, vector);\r\n}\r\nstatic irqreturn_t\r\nxen_dummy_handler(int irq, void *dev_id)\r\n{\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t\r\nxen_resched_handler(int irq, void *dev_id)\r\n{\r\nscheduler_ipi();\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void\r\n__xen_register_percpu_irq(unsigned int cpu, unsigned int vec,\r\nstruct irqaction *action, int save)\r\n{\r\nint irq = 0;\r\nif (xen_slab_ready) {\r\nswitch (vec) {\r\ncase IA64_TIMER_VECTOR:\r\nsnprintf(per_cpu(xen_timer_name, cpu),\r\nsizeof(per_cpu(xen_timer_name, cpu)),\r\n"%s%d", action->name, cpu);\r\nirq = bind_virq_to_irqhandler(VIRQ_ITC, cpu,\r\naction->handler, action->flags,\r\nper_cpu(xen_timer_name, cpu), action->dev_id);\r\nper_cpu(xen_timer_irq, cpu) = irq;\r\nbreak;\r\ncase IA64_IPI_RESCHEDULE:\r\nsnprintf(per_cpu(xen_resched_name, cpu),\r\nsizeof(per_cpu(xen_resched_name, cpu)),\r\n"%s%d", action->name, cpu);\r\nirq = bind_ipi_to_irqhandler(XEN_RESCHEDULE_VECTOR, cpu,\r\naction->handler, action->flags,\r\nper_cpu(xen_resched_name, cpu), action->dev_id);\r\nper_cpu(xen_resched_irq, cpu) = irq;\r\nbreak;\r\ncase IA64_IPI_VECTOR:\r\nsnprintf(per_cpu(xen_ipi_name, cpu),\r\nsizeof(per_cpu(xen_ipi_name, cpu)),\r\n"%s%d", action->name, cpu);\r\nirq = bind_ipi_to_irqhandler(XEN_IPI_VECTOR, cpu,\r\naction->handler, action->flags,\r\nper_cpu(xen_ipi_name, cpu), action->dev_id);\r\nper_cpu(xen_ipi_irq, cpu) = irq;\r\nbreak;\r\ncase IA64_CMC_VECTOR:\r\nsnprintf(per_cpu(xen_cmc_name, cpu),\r\nsizeof(per_cpu(xen_cmc_name, cpu)),\r\n"%s%d", action->name, cpu);\r\nirq = bind_virq_to_irqhandler(VIRQ_MCA_CMC, cpu,\r\naction->handler,\r\naction->flags,\r\nper_cpu(xen_cmc_name, cpu),\r\naction->dev_id);\r\nper_cpu(xen_cmc_irq, cpu) = irq;\r\nbreak;\r\ncase IA64_CMCP_VECTOR:\r\nsnprintf(per_cpu(xen_cmcp_name, cpu),\r\nsizeof(per_cpu(xen_cmcp_name, cpu)),\r\n"%s%d", action->name, cpu);\r\nirq = bind_ipi_to_irqhandler(XEN_CMCP_VECTOR, cpu,\r\naction->handler,\r\naction->flags,\r\nper_cpu(xen_cmcp_name, cpu),\r\naction->dev_id);\r\nper_cpu(xen_cmcp_irq, cpu) = irq;\r\nbreak;\r\ncase IA64_CPEP_VECTOR:\r\nsnprintf(per_cpu(xen_cpep_name, cpu),\r\nsizeof(per_cpu(xen_cpep_name, cpu)),\r\n"%s%d", action->name, cpu);\r\nirq = bind_ipi_to_irqhandler(XEN_CPEP_VECTOR, cpu,\r\naction->handler,\r\naction->flags,\r\nper_cpu(xen_cpep_name, cpu),\r\naction->dev_id);\r\nper_cpu(xen_cpep_irq, cpu) = irq;\r\nbreak;\r\ncase IA64_CPE_VECTOR:\r\ncase IA64_MCA_RENDEZ_VECTOR:\r\ncase IA64_PERFMON_VECTOR:\r\ncase IA64_MCA_WAKEUP_VECTOR:\r\ncase IA64_SPURIOUS_INT_VECTOR:\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING "Percpu irq %d is unsupported "\r\n"by xen!\n", vec);\r\nbreak;\r\n}\r\nBUG_ON(irq < 0);\r\nif (irq > 0) {\r\nirq_set_status_flags(irq, IRQ_PER_CPU);\r\n}\r\n}\r\nif (!cpu && save) {\r\nBUG_ON(saved_irq_cnt == MAX_LATE_IRQ);\r\nsaved_percpu_irqs[saved_irq_cnt].irq = vec;\r\nsaved_percpu_irqs[saved_irq_cnt].action = action;\r\nsaved_irq_cnt++;\r\nif (!xen_slab_ready)\r\nlate_irq_cnt++;\r\n}\r\n}\r\nstatic void\r\nxen_register_percpu_irq(ia64_vector vec, struct irqaction *action)\r\n{\r\n__xen_register_percpu_irq(smp_processor_id(), vec, action, 1);\r\n}\r\nstatic void\r\nxen_bind_early_percpu_irq(void)\r\n{\r\nint i;\r\nxen_slab_ready = 1;\r\nfor (i = 0; i < late_irq_cnt; i++)\r\n__xen_register_percpu_irq(smp_processor_id(),\r\nsaved_percpu_irqs[i].irq,\r\nsaved_percpu_irqs[i].action, 0);\r\n}\r\nstatic int __devinit\r\nunbind_evtchn_callback(struct notifier_block *nfb,\r\nunsigned long action, void *hcpu)\r\n{\r\nunsigned int cpu = (unsigned long)hcpu;\r\nif (action == CPU_DEAD) {\r\nif (per_cpu(xen_cpep_irq, cpu) >= 0) {\r\nunbind_from_irqhandler(per_cpu(xen_cpep_irq, cpu),\r\nNULL);\r\nper_cpu(xen_cpep_irq, cpu) = -1;\r\n}\r\nif (per_cpu(xen_cmcp_irq, cpu) >= 0) {\r\nunbind_from_irqhandler(per_cpu(xen_cmcp_irq, cpu),\r\nNULL);\r\nper_cpu(xen_cmcp_irq, cpu) = -1;\r\n}\r\nif (per_cpu(xen_cmc_irq, cpu) >= 0) {\r\nunbind_from_irqhandler(per_cpu(xen_cmc_irq, cpu), NULL);\r\nper_cpu(xen_cmc_irq, cpu) = -1;\r\n}\r\nif (per_cpu(xen_ipi_irq, cpu) >= 0) {\r\nunbind_from_irqhandler(per_cpu(xen_ipi_irq, cpu), NULL);\r\nper_cpu(xen_ipi_irq, cpu) = -1;\r\n}\r\nif (per_cpu(xen_resched_irq, cpu) >= 0) {\r\nunbind_from_irqhandler(per_cpu(xen_resched_irq, cpu),\r\nNULL);\r\nper_cpu(xen_resched_irq, cpu) = -1;\r\n}\r\nif (per_cpu(xen_timer_irq, cpu) >= 0) {\r\nunbind_from_irqhandler(per_cpu(xen_timer_irq, cpu),\r\nNULL);\r\nper_cpu(xen_timer_irq, cpu) = -1;\r\n}\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nvoid xen_smp_intr_init_early(unsigned int cpu)\r\n{\r\n#ifdef CONFIG_SMP\r\nunsigned int i;\r\nfor (i = 0; i < saved_irq_cnt; i++)\r\n__xen_register_percpu_irq(cpu, saved_percpu_irqs[i].irq,\r\nsaved_percpu_irqs[i].action, 0);\r\n#endif\r\n}\r\nvoid xen_smp_intr_init(void)\r\n{\r\n#ifdef CONFIG_SMP\r\nunsigned int cpu = smp_processor_id();\r\nstruct callback_register event = {\r\n.type = CALLBACKTYPE_event,\r\n.address = { .ip = (unsigned long)&xen_event_callback },\r\n};\r\nif (cpu == 0) {\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nregister_cpu_notifier(&unbind_evtchn_notifier);\r\n#endif\r\nreturn;\r\n}\r\nBUG_ON(HYPERVISOR_callback_op(CALLBACKOP_register, &event));\r\n#endif\r\n}\r\nvoid __init\r\nxen_irq_init(void)\r\n{\r\nstruct callback_register event = {\r\n.type = CALLBACKTYPE_event,\r\n.address = { .ip = (unsigned long)&xen_event_callback },\r\n};\r\nxen_init_IRQ();\r\nBUG_ON(HYPERVISOR_callback_op(CALLBACKOP_register, &event));\r\nlate_time_init = xen_bind_early_percpu_irq;\r\n}\r\nvoid\r\nxen_platform_send_ipi(int cpu, int vector, int delivery_mode, int redirect)\r\n{\r\n#ifdef CONFIG_SMP\r\nif (unlikely(vector == ap_wakeup_vector)) {\r\nxen_smp_intr_init_early(cpu);\r\nxen_send_ipi(cpu, vector);\r\nreturn;\r\n}\r\n#endif\r\nswitch (vector) {\r\ncase IA64_IPI_VECTOR:\r\nxen_send_IPI_one(cpu, XEN_IPI_VECTOR);\r\nbreak;\r\ncase IA64_IPI_RESCHEDULE:\r\nxen_send_IPI_one(cpu, XEN_RESCHEDULE_VECTOR);\r\nbreak;\r\ncase IA64_CMCP_VECTOR:\r\nxen_send_IPI_one(cpu, XEN_CMCP_VECTOR);\r\nbreak;\r\ncase IA64_CPEP_VECTOR:\r\nxen_send_IPI_one(cpu, XEN_CPEP_VECTOR);\r\nbreak;\r\ncase IA64_TIMER_VECTOR: {\r\nstatic int used = 0;\r\nif (!used) {\r\nxen_send_ipi(cpu, IA64_TIMER_VECTOR);\r\nused = 1;\r\nbreak;\r\n}\r\n}\r\ndefault:\r\nprintk(KERN_WARNING "Unsupported IPI type 0x%x\n",\r\nvector);\r\nnotify_remote_via_irq(0);\r\nbreak;\r\n}\r\n}\r\nstatic void __init\r\nxen_register_ipi(void)\r\n{\r\n#ifdef CONFIG_SMP\r\nregister_percpu_irq(IA64_IPI_VECTOR, &xen_ipi_irqaction);\r\nregister_percpu_irq(IA64_IPI_RESCHEDULE, &xen_resched_irqaction);\r\nregister_percpu_irq(IA64_IPI_LOCAL_TLB_FLUSH, &xen_tlb_irqaction);\r\n#endif\r\n}\r\nstatic void\r\nxen_resend_irq(unsigned int vector)\r\n{\r\n(void)resend_irq_on_evtchn(vector);\r\n}
