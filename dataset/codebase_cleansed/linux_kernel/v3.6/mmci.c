static void mmci_write_clkreg(struct mmci_host *host, u32 clk)\r\n{\r\nif (host->clk_reg != clk) {\r\nhost->clk_reg = clk;\r\nwritel(clk, host->base + MMCICLOCK);\r\n}\r\n}\r\nstatic void mmci_write_pwrreg(struct mmci_host *host, u32 pwr)\r\n{\r\nif (host->pwr_reg != pwr) {\r\nhost->pwr_reg = pwr;\r\nwritel(pwr, host->base + MMCIPOWER);\r\n}\r\n}\r\nstatic void mmci_set_clkreg(struct mmci_host *host, unsigned int desired)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nu32 clk = variant->clkreg;\r\nif (desired) {\r\nif (desired >= host->mclk) {\r\nclk = MCI_CLK_BYPASS;\r\nif (variant->st_clkdiv)\r\nclk |= MCI_ST_UX500_NEG_EDGE;\r\nhost->cclk = host->mclk;\r\n} else if (variant->st_clkdiv) {\r\nclk = DIV_ROUND_UP(host->mclk, desired) - 2;\r\nif (clk >= 256)\r\nclk = 255;\r\nhost->cclk = host->mclk / (clk + 2);\r\n} else {\r\nclk = host->mclk / (2 * desired) - 1;\r\nif (clk >= 256)\r\nclk = 255;\r\nhost->cclk = host->mclk / (2 * (clk + 1));\r\n}\r\nclk |= variant->clkreg_enable;\r\nclk |= MCI_CLK_ENABLE;\r\n}\r\nif (host->mmc->ios.bus_width == MMC_BUS_WIDTH_4)\r\nclk |= MCI_4BIT_BUS;\r\nif (host->mmc->ios.bus_width == MMC_BUS_WIDTH_8)\r\nclk |= MCI_ST_8BIT_BUS;\r\nmmci_write_clkreg(host, clk);\r\n}\r\nstatic void\r\nmmci_request_end(struct mmci_host *host, struct mmc_request *mrq)\r\n{\r\nwritel(0, host->base + MMCICOMMAND);\r\nBUG_ON(host->data);\r\nhost->mrq = NULL;\r\nhost->cmd = NULL;\r\nmmc_request_done(host->mmc, mrq);\r\npm_runtime_mark_last_busy(mmc_dev(host->mmc));\r\npm_runtime_put_autosuspend(mmc_dev(host->mmc));\r\n}\r\nstatic void mmci_set_mask1(struct mmci_host *host, unsigned int mask)\r\n{\r\nvoid __iomem *base = host->base;\r\nif (host->singleirq) {\r\nunsigned int mask0 = readl(base + MMCIMASK0);\r\nmask0 &= ~MCI_IRQ1MASK;\r\nmask0 |= mask;\r\nwritel(mask0, base + MMCIMASK0);\r\n}\r\nwritel(mask, base + MMCIMASK1);\r\n}\r\nstatic void mmci_stop_data(struct mmci_host *host)\r\n{\r\nwritel(0, host->base + MMCIDATACTRL);\r\nmmci_set_mask1(host, 0);\r\nhost->data = NULL;\r\n}\r\nstatic void mmci_init_sg(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nunsigned int flags = SG_MITER_ATOMIC;\r\nif (data->flags & MMC_DATA_READ)\r\nflags |= SG_MITER_TO_SG;\r\nelse\r\nflags |= SG_MITER_FROM_SG;\r\nsg_miter_start(&host->sg_miter, data->sg, data->sg_len, flags);\r\n}\r\nstatic void __devinit mmci_dma_setup(struct mmci_host *host)\r\n{\r\nstruct mmci_platform_data *plat = host->plat;\r\nconst char *rxname, *txname;\r\ndma_cap_mask_t mask;\r\nif (!plat || !plat->dma_filter) {\r\ndev_info(mmc_dev(host->mmc), "no DMA platform data\n");\r\nreturn;\r\n}\r\nhost->next_data.cookie = 1;\r\ndma_cap_zero(mask);\r\ndma_cap_set(DMA_SLAVE, mask);\r\nif (plat->dma_rx_param) {\r\nhost->dma_rx_channel = dma_request_channel(mask,\r\nplat->dma_filter,\r\nplat->dma_rx_param);\r\nif (!host->dma_rx_channel)\r\ndev_err(mmc_dev(host->mmc), "no RX DMA channel\n");\r\n}\r\nif (plat->dma_tx_param) {\r\nhost->dma_tx_channel = dma_request_channel(mask,\r\nplat->dma_filter,\r\nplat->dma_tx_param);\r\nif (!host->dma_tx_channel)\r\ndev_warn(mmc_dev(host->mmc), "no TX DMA channel\n");\r\n} else {\r\nhost->dma_tx_channel = host->dma_rx_channel;\r\n}\r\nif (host->dma_rx_channel)\r\nrxname = dma_chan_name(host->dma_rx_channel);\r\nelse\r\nrxname = "none";\r\nif (host->dma_tx_channel)\r\ntxname = dma_chan_name(host->dma_tx_channel);\r\nelse\r\ntxname = "none";\r\ndev_info(mmc_dev(host->mmc), "DMA channels RX %s, TX %s\n",\r\nrxname, txname);\r\nif (host->dma_tx_channel) {\r\nstruct device *dev = host->dma_tx_channel->device->dev;\r\nunsigned int max_seg_size = dma_get_max_seg_size(dev);\r\nif (max_seg_size < host->mmc->max_seg_size)\r\nhost->mmc->max_seg_size = max_seg_size;\r\n}\r\nif (host->dma_rx_channel) {\r\nstruct device *dev = host->dma_rx_channel->device->dev;\r\nunsigned int max_seg_size = dma_get_max_seg_size(dev);\r\nif (max_seg_size < host->mmc->max_seg_size)\r\nhost->mmc->max_seg_size = max_seg_size;\r\n}\r\n}\r\nstatic inline void mmci_dma_release(struct mmci_host *host)\r\n{\r\nstruct mmci_platform_data *plat = host->plat;\r\nif (host->dma_rx_channel)\r\ndma_release_channel(host->dma_rx_channel);\r\nif (host->dma_tx_channel && plat->dma_tx_param)\r\ndma_release_channel(host->dma_tx_channel);\r\nhost->dma_rx_channel = host->dma_tx_channel = NULL;\r\n}\r\nstatic void mmci_dma_unmap(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nstruct dma_chan *chan = host->dma_current;\r\nenum dma_data_direction dir;\r\nu32 status;\r\nint i;\r\nfor (i = 0; ; i++) {\r\nstatus = readl(host->base + MMCISTATUS);\r\nif (!(status & MCI_RXDATAAVLBLMASK) || i >= 100)\r\nbreak;\r\nudelay(10);\r\n}\r\nif (status & MCI_RXDATAAVLBLMASK) {\r\ndmaengine_terminate_all(chan);\r\nif (!data->error)\r\ndata->error = -EIO;\r\n}\r\nif (data->flags & MMC_DATA_WRITE) {\r\ndir = DMA_TO_DEVICE;\r\n} else {\r\ndir = DMA_FROM_DEVICE;\r\n}\r\nif (!data->host_cookie)\r\ndma_unmap_sg(chan->device->dev, data->sg, data->sg_len, dir);\r\nif (status & MCI_RXDATAAVLBLMASK) {\r\ndev_err(mmc_dev(host->mmc), "buggy DMA detected. Taking evasive action.\n");\r\nmmci_dma_release(host);\r\n}\r\n}\r\nstatic void mmci_dma_data_error(struct mmci_host *host)\r\n{\r\ndev_err(mmc_dev(host->mmc), "error during DMA transfer!\n");\r\ndmaengine_terminate_all(host->dma_current);\r\n}\r\nstatic int mmci_dma_prep_data(struct mmci_host *host, struct mmc_data *data,\r\nstruct mmci_host_next *next)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nstruct dma_slave_config conf = {\r\n.src_addr = host->phybase + MMCIFIFO,\r\n.dst_addr = host->phybase + MMCIFIFO,\r\n.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES,\r\n.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES,\r\n.src_maxburst = variant->fifohalfsize >> 2,\r\n.dst_maxburst = variant->fifohalfsize >> 2,\r\n.device_fc = false,\r\n};\r\nstruct dma_chan *chan;\r\nstruct dma_device *device;\r\nstruct dma_async_tx_descriptor *desc;\r\nenum dma_data_direction buffer_dirn;\r\nint nr_sg;\r\nif (data->host_cookie && !next &&\r\nhost->dma_current && host->dma_desc_current)\r\nreturn 0;\r\nif (!next) {\r\nhost->dma_current = NULL;\r\nhost->dma_desc_current = NULL;\r\n}\r\nif (data->flags & MMC_DATA_READ) {\r\nconf.direction = DMA_DEV_TO_MEM;\r\nbuffer_dirn = DMA_FROM_DEVICE;\r\nchan = host->dma_rx_channel;\r\n} else {\r\nconf.direction = DMA_MEM_TO_DEV;\r\nbuffer_dirn = DMA_TO_DEVICE;\r\nchan = host->dma_tx_channel;\r\n}\r\nif (!chan)\r\nreturn -EINVAL;\r\nif (data->blksz * data->blocks <= variant->fifosize)\r\nreturn -EINVAL;\r\ndevice = chan->device;\r\nnr_sg = dma_map_sg(device->dev, data->sg, data->sg_len, buffer_dirn);\r\nif (nr_sg == 0)\r\nreturn -EINVAL;\r\ndmaengine_slave_config(chan, &conf);\r\ndesc = dmaengine_prep_slave_sg(chan, data->sg, nr_sg,\r\nconf.direction, DMA_CTRL_ACK);\r\nif (!desc)\r\ngoto unmap_exit;\r\nif (next) {\r\nnext->dma_chan = chan;\r\nnext->dma_desc = desc;\r\n} else {\r\nhost->dma_current = chan;\r\nhost->dma_desc_current = desc;\r\n}\r\nreturn 0;\r\nunmap_exit:\r\nif (!next)\r\ndmaengine_terminate_all(chan);\r\ndma_unmap_sg(device->dev, data->sg, data->sg_len, buffer_dirn);\r\nreturn -ENOMEM;\r\n}\r\nstatic int mmci_dma_start_data(struct mmci_host *host, unsigned int datactrl)\r\n{\r\nint ret;\r\nstruct mmc_data *data = host->data;\r\nret = mmci_dma_prep_data(host, host->data, NULL);\r\nif (ret)\r\nreturn ret;\r\ndev_vdbg(mmc_dev(host->mmc),\r\n"Submit MMCI DMA job, sglen %d blksz %04x blks %04x flags %08x\n",\r\ndata->sg_len, data->blksz, data->blocks, data->flags);\r\ndmaengine_submit(host->dma_desc_current);\r\ndma_async_issue_pending(host->dma_current);\r\ndatactrl |= MCI_DPSM_DMAENABLE;\r\nwritel(datactrl, host->base + MMCIDATACTRL);\r\nwritel(readl(host->base + MMCIMASK0) | MCI_DATAENDMASK,\r\nhost->base + MMCIMASK0);\r\nreturn 0;\r\n}\r\nstatic void mmci_get_next_data(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nstruct mmci_host_next *next = &host->next_data;\r\nif (data->host_cookie && data->host_cookie != next->cookie) {\r\npr_warning("[%s] invalid cookie: data->host_cookie %d"\r\n" host->next_data.cookie %d\n",\r\n__func__, data->host_cookie, host->next_data.cookie);\r\ndata->host_cookie = 0;\r\n}\r\nif (!data->host_cookie)\r\nreturn;\r\nhost->dma_desc_current = next->dma_desc;\r\nhost->dma_current = next->dma_chan;\r\nnext->dma_desc = NULL;\r\nnext->dma_chan = NULL;\r\n}\r\nstatic void mmci_pre_request(struct mmc_host *mmc, struct mmc_request *mrq,\r\nbool is_first_req)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct mmc_data *data = mrq->data;\r\nstruct mmci_host_next *nd = &host->next_data;\r\nif (!data)\r\nreturn;\r\nif (data->host_cookie) {\r\ndata->host_cookie = 0;\r\nreturn;\r\n}\r\nif (((data->flags & MMC_DATA_WRITE) && host->dma_tx_channel) ||\r\n((data->flags & MMC_DATA_READ) && host->dma_rx_channel)) {\r\nif (mmci_dma_prep_data(host, data, nd))\r\ndata->host_cookie = 0;\r\nelse\r\ndata->host_cookie = ++nd->cookie < 0 ? 1 : nd->cookie;\r\n}\r\n}\r\nstatic void mmci_post_request(struct mmc_host *mmc, struct mmc_request *mrq,\r\nint err)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct mmc_data *data = mrq->data;\r\nstruct dma_chan *chan;\r\nenum dma_data_direction dir;\r\nif (!data)\r\nreturn;\r\nif (data->flags & MMC_DATA_READ) {\r\ndir = DMA_FROM_DEVICE;\r\nchan = host->dma_rx_channel;\r\n} else {\r\ndir = DMA_TO_DEVICE;\r\nchan = host->dma_tx_channel;\r\n}\r\nif (chan) {\r\nif (err)\r\ndmaengine_terminate_all(chan);\r\nif (data->host_cookie)\r\ndma_unmap_sg(mmc_dev(host->mmc), data->sg,\r\ndata->sg_len, dir);\r\nmrq->data->host_cookie = 0;\r\n}\r\n}\r\nstatic void mmci_get_next_data(struct mmci_host *host, struct mmc_data *data)\r\n{\r\n}\r\nstatic inline void mmci_dma_setup(struct mmci_host *host)\r\n{\r\n}\r\nstatic inline void mmci_dma_release(struct mmci_host *host)\r\n{\r\n}\r\nstatic inline void mmci_dma_unmap(struct mmci_host *host, struct mmc_data *data)\r\n{\r\n}\r\nstatic inline void mmci_dma_data_error(struct mmci_host *host)\r\n{\r\n}\r\nstatic inline int mmci_dma_start_data(struct mmci_host *host, unsigned int datactrl)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic void mmci_start_data(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nunsigned int datactrl, timeout, irqmask;\r\nunsigned long long clks;\r\nvoid __iomem *base;\r\nint blksz_bits;\r\ndev_dbg(mmc_dev(host->mmc), "blksz %04x blks %04x flags %08x\n",\r\ndata->blksz, data->blocks, data->flags);\r\nhost->data = data;\r\nhost->size = data->blksz * data->blocks;\r\ndata->bytes_xfered = 0;\r\nclks = (unsigned long long)data->timeout_ns * host->cclk;\r\ndo_div(clks, 1000000000UL);\r\ntimeout = data->timeout_clks + (unsigned int)clks;\r\nbase = host->base;\r\nwritel(timeout, base + MMCIDATATIMER);\r\nwritel(host->size, base + MMCIDATALENGTH);\r\nblksz_bits = ffs(data->blksz) - 1;\r\nBUG_ON(1 << blksz_bits != data->blksz);\r\nif (variant->blksz_datactrl16)\r\ndatactrl = MCI_DPSM_ENABLE | (data->blksz << 16);\r\nelse\r\ndatactrl = MCI_DPSM_ENABLE | blksz_bits << 4;\r\nif (data->flags & MMC_DATA_READ)\r\ndatactrl |= MCI_DPSM_DIRECTION;\r\nif (variant->sdio && host->mmc->card)\r\nif (mmc_card_sdio(host->mmc->card))\r\ndatactrl |= MCI_ST_DPSM_SDIOEN;\r\nif (!mmci_dma_start_data(host, datactrl))\r\nreturn;\r\nmmci_init_sg(host, data);\r\nif (data->flags & MMC_DATA_READ) {\r\nirqmask = MCI_RXFIFOHALFFULLMASK;\r\nif (host->size < variant->fifohalfsize)\r\nirqmask |= MCI_RXDATAAVLBLMASK;\r\n} else {\r\nirqmask = MCI_TXFIFOHALFEMPTYMASK;\r\n}\r\nwritel(datactrl, base + MMCIDATACTRL);\r\nwritel(readl(base + MMCIMASK0) & ~MCI_DATAENDMASK, base + MMCIMASK0);\r\nmmci_set_mask1(host, irqmask);\r\n}\r\nstatic void\r\nmmci_start_command(struct mmci_host *host, struct mmc_command *cmd, u32 c)\r\n{\r\nvoid __iomem *base = host->base;\r\ndev_dbg(mmc_dev(host->mmc), "op %02x arg %08x flags %08x\n",\r\ncmd->opcode, cmd->arg, cmd->flags);\r\nif (readl(base + MMCICOMMAND) & MCI_CPSM_ENABLE) {\r\nwritel(0, base + MMCICOMMAND);\r\nudelay(1);\r\n}\r\nc |= cmd->opcode | MCI_CPSM_ENABLE;\r\nif (cmd->flags & MMC_RSP_PRESENT) {\r\nif (cmd->flags & MMC_RSP_136)\r\nc |= MCI_CPSM_LONGRSP;\r\nc |= MCI_CPSM_RESPONSE;\r\n}\r\nif (0)\r\nc |= MCI_CPSM_INTERRUPT;\r\nhost->cmd = cmd;\r\nwritel(cmd->arg, base + MMCIARGUMENT);\r\nwritel(c, base + MMCICOMMAND);\r\n}\r\nstatic void\r\nmmci_data_irq(struct mmci_host *host, struct mmc_data *data,\r\nunsigned int status)\r\n{\r\nif (status & (MCI_DATACRCFAIL|MCI_DATATIMEOUT|MCI_STARTBITERR|\r\nMCI_TXUNDERRUN|MCI_RXOVERRUN)) {\r\nu32 remain, success;\r\nif (dma_inprogress(host))\r\nmmci_dma_data_error(host);\r\nremain = readl(host->base + MMCIDATACNT);\r\nsuccess = data->blksz * data->blocks - remain;\r\ndev_dbg(mmc_dev(host->mmc), "MCI ERROR IRQ, status 0x%08x at 0x%08x\n",\r\nstatus, success);\r\nif (status & MCI_DATACRCFAIL) {\r\nsuccess -= 1;\r\ndata->error = -EILSEQ;\r\n} else if (status & MCI_DATATIMEOUT) {\r\ndata->error = -ETIMEDOUT;\r\n} else if (status & MCI_STARTBITERR) {\r\ndata->error = -ECOMM;\r\n} else if (status & MCI_TXUNDERRUN) {\r\ndata->error = -EIO;\r\n} else if (status & MCI_RXOVERRUN) {\r\nif (success > host->variant->fifosize)\r\nsuccess -= host->variant->fifosize;\r\nelse\r\nsuccess = 0;\r\ndata->error = -EIO;\r\n}\r\ndata->bytes_xfered = round_down(success, data->blksz);\r\n}\r\nif (status & MCI_DATABLOCKEND)\r\ndev_err(mmc_dev(host->mmc), "stray MCI_DATABLOCKEND interrupt\n");\r\nif (status & MCI_DATAEND || data->error) {\r\nif (dma_inprogress(host))\r\nmmci_dma_unmap(host, data);\r\nmmci_stop_data(host);\r\nif (!data->error)\r\ndata->bytes_xfered = data->blksz * data->blocks;\r\nif (!data->stop) {\r\nmmci_request_end(host, data->mrq);\r\n} else {\r\nmmci_start_command(host, data->stop, 0);\r\n}\r\n}\r\n}\r\nstatic void\r\nmmci_cmd_irq(struct mmci_host *host, struct mmc_command *cmd,\r\nunsigned int status)\r\n{\r\nvoid __iomem *base = host->base;\r\nhost->cmd = NULL;\r\nif (status & MCI_CMDTIMEOUT) {\r\ncmd->error = -ETIMEDOUT;\r\n} else if (status & MCI_CMDCRCFAIL && cmd->flags & MMC_RSP_CRC) {\r\ncmd->error = -EILSEQ;\r\n} else {\r\ncmd->resp[0] = readl(base + MMCIRESPONSE0);\r\ncmd->resp[1] = readl(base + MMCIRESPONSE1);\r\ncmd->resp[2] = readl(base + MMCIRESPONSE2);\r\ncmd->resp[3] = readl(base + MMCIRESPONSE3);\r\n}\r\nif (!cmd->data || cmd->error) {\r\nif (host->data) {\r\nif (dma_inprogress(host))\r\nmmci_dma_data_error(host);\r\nmmci_stop_data(host);\r\n}\r\nmmci_request_end(host, cmd->mrq);\r\n} else if (!(cmd->data->flags & MMC_DATA_READ)) {\r\nmmci_start_data(host, cmd->data);\r\n}\r\n}\r\nstatic int mmci_pio_read(struct mmci_host *host, char *buffer, unsigned int remain)\r\n{\r\nvoid __iomem *base = host->base;\r\nchar *ptr = buffer;\r\nu32 status;\r\nint host_remain = host->size;\r\ndo {\r\nint count = host_remain - (readl(base + MMCIFIFOCNT) << 2);\r\nif (count > remain)\r\ncount = remain;\r\nif (count <= 0)\r\nbreak;\r\nif (unlikely(count & 0x3)) {\r\nif (count < 4) {\r\nunsigned char buf[4];\r\nreadsl(base + MMCIFIFO, buf, 1);\r\nmemcpy(ptr, buf, count);\r\n} else {\r\nreadsl(base + MMCIFIFO, ptr, count >> 2);\r\ncount &= ~0x3;\r\n}\r\n} else {\r\nreadsl(base + MMCIFIFO, ptr, count >> 2);\r\n}\r\nptr += count;\r\nremain -= count;\r\nhost_remain -= count;\r\nif (remain == 0)\r\nbreak;\r\nstatus = readl(base + MMCISTATUS);\r\n} while (status & MCI_RXDATAAVLBL);\r\nreturn ptr - buffer;\r\n}\r\nstatic int mmci_pio_write(struct mmci_host *host, char *buffer, unsigned int remain, u32 status)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nvoid __iomem *base = host->base;\r\nchar *ptr = buffer;\r\ndo {\r\nunsigned int count, maxcnt;\r\nmaxcnt = status & MCI_TXFIFOEMPTY ?\r\nvariant->fifosize : variant->fifohalfsize;\r\ncount = min(remain, maxcnt);\r\nif (variant->sdio &&\r\nmmc_card_sdio(host->mmc->card)) {\r\nu32 clk;\r\nif (count < 8)\r\nclk = host->clk_reg & ~variant->clkreg_enable;\r\nelse\r\nclk = host->clk_reg | variant->clkreg_enable;\r\nmmci_write_clkreg(host, clk);\r\n}\r\nwritesl(base + MMCIFIFO, ptr, (count + 3) >> 2);\r\nptr += count;\r\nremain -= count;\r\nif (remain == 0)\r\nbreak;\r\nstatus = readl(base + MMCISTATUS);\r\n} while (status & MCI_TXFIFOHALFEMPTY);\r\nreturn ptr - buffer;\r\n}\r\nstatic irqreturn_t mmci_pio_irq(int irq, void *dev_id)\r\n{\r\nstruct mmci_host *host = dev_id;\r\nstruct sg_mapping_iter *sg_miter = &host->sg_miter;\r\nstruct variant_data *variant = host->variant;\r\nvoid __iomem *base = host->base;\r\nunsigned long flags;\r\nu32 status;\r\nstatus = readl(base + MMCISTATUS);\r\ndev_dbg(mmc_dev(host->mmc), "irq1 (pio) %08x\n", status);\r\nlocal_irq_save(flags);\r\ndo {\r\nunsigned int remain, len;\r\nchar *buffer;\r\nif (!(status & (MCI_TXFIFOHALFEMPTY|MCI_RXDATAAVLBL)))\r\nbreak;\r\nif (!sg_miter_next(sg_miter))\r\nbreak;\r\nbuffer = sg_miter->addr;\r\nremain = sg_miter->length;\r\nlen = 0;\r\nif (status & MCI_RXACTIVE)\r\nlen = mmci_pio_read(host, buffer, remain);\r\nif (status & MCI_TXACTIVE)\r\nlen = mmci_pio_write(host, buffer, remain, status);\r\nsg_miter->consumed = len;\r\nhost->size -= len;\r\nremain -= len;\r\nif (remain)\r\nbreak;\r\nstatus = readl(base + MMCISTATUS);\r\n} while (1);\r\nsg_miter_stop(sg_miter);\r\nlocal_irq_restore(flags);\r\nif (status & MCI_RXACTIVE && host->size < variant->fifohalfsize)\r\nmmci_set_mask1(host, MCI_RXDATAAVLBLMASK);\r\nif (host->size == 0) {\r\nmmci_set_mask1(host, 0);\r\nwritel(readl(base + MMCIMASK0) | MCI_DATAENDMASK, base + MMCIMASK0);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t mmci_irq(int irq, void *dev_id)\r\n{\r\nstruct mmci_host *host = dev_id;\r\nu32 status;\r\nint ret = 0;\r\nspin_lock(&host->lock);\r\ndo {\r\nstruct mmc_command *cmd;\r\nstruct mmc_data *data;\r\nstatus = readl(host->base + MMCISTATUS);\r\nif (host->singleirq) {\r\nif (status & readl(host->base + MMCIMASK1))\r\nmmci_pio_irq(irq, dev_id);\r\nstatus &= ~MCI_IRQ1MASK;\r\n}\r\nstatus &= readl(host->base + MMCIMASK0);\r\nwritel(status, host->base + MMCICLEAR);\r\ndev_dbg(mmc_dev(host->mmc), "irq0 (data+cmd) %08x\n", status);\r\ndata = host->data;\r\nif (status & (MCI_DATACRCFAIL|MCI_DATATIMEOUT|MCI_STARTBITERR|\r\nMCI_TXUNDERRUN|MCI_RXOVERRUN|MCI_DATAEND|\r\nMCI_DATABLOCKEND) && data)\r\nmmci_data_irq(host, data, status);\r\ncmd = host->cmd;\r\nif (status & (MCI_CMDCRCFAIL|MCI_CMDTIMEOUT|MCI_CMDSENT|MCI_CMDRESPEND) && cmd)\r\nmmci_cmd_irq(host, cmd, status);\r\nret = 1;\r\n} while (status);\r\nspin_unlock(&host->lock);\r\nreturn IRQ_RETVAL(ret);\r\n}\r\nstatic void mmci_request(struct mmc_host *mmc, struct mmc_request *mrq)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nunsigned long flags;\r\nWARN_ON(host->mrq != NULL);\r\nif (mrq->data && !is_power_of_2(mrq->data->blksz)) {\r\ndev_err(mmc_dev(mmc), "unsupported block size (%d bytes)\n",\r\nmrq->data->blksz);\r\nmrq->cmd->error = -EINVAL;\r\nmmc_request_done(mmc, mrq);\r\nreturn;\r\n}\r\npm_runtime_get_sync(mmc_dev(mmc));\r\nspin_lock_irqsave(&host->lock, flags);\r\nhost->mrq = mrq;\r\nif (mrq->data)\r\nmmci_get_next_data(host, mrq->data);\r\nif (mrq->data && mrq->data->flags & MMC_DATA_READ)\r\nmmci_start_data(host, mrq->data);\r\nmmci_start_command(host, mrq->cmd, 0);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\n}\r\nstatic void mmci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct variant_data *variant = host->variant;\r\nu32 pwr = 0;\r\nunsigned long flags;\r\nint ret;\r\npm_runtime_get_sync(mmc_dev(mmc));\r\nif (host->plat->ios_handler &&\r\nhost->plat->ios_handler(mmc_dev(mmc), ios))\r\ndev_err(mmc_dev(mmc), "platform ios_handler failed\n");\r\nswitch (ios->power_mode) {\r\ncase MMC_POWER_OFF:\r\nif (host->vcc)\r\nret = mmc_regulator_set_ocr(mmc, host->vcc, 0);\r\nbreak;\r\ncase MMC_POWER_UP:\r\nif (host->vcc) {\r\nret = mmc_regulator_set_ocr(mmc, host->vcc, ios->vdd);\r\nif (ret) {\r\ndev_err(mmc_dev(mmc), "unable to set OCR\n");\r\ngoto out;\r\n}\r\n}\r\npwr |= variant->pwrreg_powerup;\r\nbreak;\r\ncase MMC_POWER_ON:\r\npwr |= MCI_PWR_ON;\r\nbreak;\r\n}\r\nif (variant->signal_direction && ios->power_mode != MMC_POWER_OFF) {\r\npwr |= host->plat->sigdir;\r\nif (ios->bus_width == MMC_BUS_WIDTH_4)\r\npwr &= ~MCI_ST_DATA74DIREN;\r\nelse if (ios->bus_width == MMC_BUS_WIDTH_1)\r\npwr &= (~MCI_ST_DATA74DIREN &\r\n~MCI_ST_DATA31DIREN &\r\n~MCI_ST_DATA2DIREN);\r\n}\r\nif (ios->bus_mode == MMC_BUSMODE_OPENDRAIN) {\r\nif (host->hw_designer != AMBA_VENDOR_ST)\r\npwr |= MCI_ROD;\r\nelse {\r\npwr |= MCI_OD;\r\n}\r\n}\r\nspin_lock_irqsave(&host->lock, flags);\r\nmmci_set_clkreg(host, ios->clock);\r\nmmci_write_pwrreg(host, pwr);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nout:\r\npm_runtime_mark_last_busy(mmc_dev(mmc));\r\npm_runtime_put_autosuspend(mmc_dev(mmc));\r\n}\r\nstatic int mmci_get_ro(struct mmc_host *mmc)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nif (host->gpio_wp == -ENOSYS)\r\nreturn -ENOSYS;\r\nreturn gpio_get_value_cansleep(host->gpio_wp);\r\n}\r\nstatic int mmci_get_cd(struct mmc_host *mmc)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct mmci_platform_data *plat = host->plat;\r\nunsigned int status;\r\nif (host->gpio_cd == -ENOSYS) {\r\nif (!plat->status)\r\nreturn 1;\r\nstatus = plat->status(mmc_dev(host->mmc));\r\n} else\r\nstatus = !!gpio_get_value_cansleep(host->gpio_cd)\r\n^ plat->cd_invert;\r\nreturn status;\r\n}\r\nstatic irqreturn_t mmci_cd_irq(int irq, void *dev_id)\r\n{\r\nstruct mmci_host *host = dev_id;\r\nmmc_detect_change(host->mmc, msecs_to_jiffies(500));\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void mmci_dt_populate_generic_pdata(struct device_node *np,\r\nstruct mmci_platform_data *pdata)\r\n{\r\nint bus_width = 0;\r\npdata->gpio_wp = of_get_named_gpio(np, "wp-gpios", 0);\r\npdata->gpio_cd = of_get_named_gpio(np, "cd-gpios", 0);\r\nif (of_get_property(np, "cd-inverted", NULL))\r\npdata->cd_invert = true;\r\nelse\r\npdata->cd_invert = false;\r\nof_property_read_u32(np, "max-frequency", &pdata->f_max);\r\nif (!pdata->f_max)\r\npr_warn("%s has no 'max-frequency' property\n", np->full_name);\r\nif (of_get_property(np, "mmc-cap-mmc-highspeed", NULL))\r\npdata->capabilities |= MMC_CAP_MMC_HIGHSPEED;\r\nif (of_get_property(np, "mmc-cap-sd-highspeed", NULL))\r\npdata->capabilities |= MMC_CAP_SD_HIGHSPEED;\r\nof_property_read_u32(np, "bus-width", &bus_width);\r\nswitch (bus_width) {\r\ncase 0 :\r\nbreak;\r\ncase 4 :\r\npdata->capabilities |= MMC_CAP_4_BIT_DATA;\r\nbreak;\r\ncase 8 :\r\npdata->capabilities |= MMC_CAP_8_BIT_DATA;\r\nbreak;\r\ndefault :\r\npr_warn("%s: Unsupported bus width\n", np->full_name);\r\n}\r\n}\r\nstatic void mmci_dt_populate_generic_pdata(struct device_node *np,\r\nstruct mmci_platform_data *pdata)\r\n{\r\nreturn;\r\n}\r\nstatic int __devinit mmci_probe(struct amba_device *dev,\r\nconst struct amba_id *id)\r\n{\r\nstruct mmci_platform_data *plat = dev->dev.platform_data;\r\nstruct device_node *np = dev->dev.of_node;\r\nstruct variant_data *variant = id->data;\r\nstruct mmci_host *host;\r\nstruct mmc_host *mmc;\r\nint ret;\r\nif (!plat && !np) {\r\ndev_err(&dev->dev, "No plat data or DT found\n");\r\nreturn -EINVAL;\r\n}\r\nif (!plat) {\r\nplat = devm_kzalloc(&dev->dev, sizeof(*plat), GFP_KERNEL);\r\nif (!plat)\r\nreturn -ENOMEM;\r\n}\r\nif (np)\r\nmmci_dt_populate_generic_pdata(np, plat);\r\nret = amba_request_regions(dev, DRIVER_NAME);\r\nif (ret)\r\ngoto out;\r\nmmc = mmc_alloc_host(sizeof(struct mmci_host), &dev->dev);\r\nif (!mmc) {\r\nret = -ENOMEM;\r\ngoto rel_regions;\r\n}\r\nhost = mmc_priv(mmc);\r\nhost->mmc = mmc;\r\nhost->gpio_wp = -ENOSYS;\r\nhost->gpio_cd = -ENOSYS;\r\nhost->gpio_cd_irq = -1;\r\nhost->hw_designer = amba_manf(dev);\r\nhost->hw_revision = amba_rev(dev);\r\ndev_dbg(mmc_dev(mmc), "designer ID = 0x%02x\n", host->hw_designer);\r\ndev_dbg(mmc_dev(mmc), "revision = 0x%01x\n", host->hw_revision);\r\nhost->clk = clk_get(&dev->dev, NULL);\r\nif (IS_ERR(host->clk)) {\r\nret = PTR_ERR(host->clk);\r\nhost->clk = NULL;\r\ngoto host_free;\r\n}\r\nret = clk_prepare(host->clk);\r\nif (ret)\r\ngoto clk_free;\r\nret = clk_enable(host->clk);\r\nif (ret)\r\ngoto clk_unprep;\r\nhost->plat = plat;\r\nhost->variant = variant;\r\nhost->mclk = clk_get_rate(host->clk);\r\nif (host->mclk > 100000000) {\r\nret = clk_set_rate(host->clk, 100000000);\r\nif (ret < 0)\r\ngoto clk_disable;\r\nhost->mclk = clk_get_rate(host->clk);\r\ndev_dbg(mmc_dev(mmc), "eventual mclk rate: %u Hz\n",\r\nhost->mclk);\r\n}\r\nhost->phybase = dev->res.start;\r\nhost->base = ioremap(dev->res.start, resource_size(&dev->res));\r\nif (!host->base) {\r\nret = -ENOMEM;\r\ngoto clk_disable;\r\n}\r\nmmc->ops = &mmci_ops;\r\nif (variant->st_clkdiv)\r\nmmc->f_min = DIV_ROUND_UP(host->mclk, 257);\r\nelse\r\nmmc->f_min = DIV_ROUND_UP(host->mclk, 512);\r\nif (plat->f_max)\r\nmmc->f_max = min(host->mclk, plat->f_max);\r\nelse\r\nmmc->f_max = min(host->mclk, fmax);\r\ndev_dbg(mmc_dev(mmc), "clocking block at %u Hz\n", mmc->f_max);\r\n#ifdef CONFIG_REGULATOR\r\nhost->vcc = regulator_get(&dev->dev, "vmmc");\r\nif (IS_ERR(host->vcc))\r\nhost->vcc = NULL;\r\nelse {\r\nint mask = mmc_regulator_get_ocrmask(host->vcc);\r\nif (mask < 0)\r\ndev_err(&dev->dev, "error getting OCR mask (%d)\n",\r\nmask);\r\nelse {\r\nhost->mmc->ocr_avail = (u32) mask;\r\nif (plat->ocr_mask)\r\ndev_warn(&dev->dev,\r\n"Provided ocr_mask/setpower will not be used "\r\n"(using regulator instead)\n");\r\n}\r\n}\r\n#endif\r\nif (host->vcc == NULL)\r\nmmc->ocr_avail = plat->ocr_mask;\r\nmmc->caps = plat->capabilities;\r\nmmc->caps2 = plat->capabilities2;\r\nmmc->max_segs = NR_SG;\r\nmmc->max_req_size = (1 << variant->datalength_bits) - 1;\r\nmmc->max_seg_size = mmc->max_req_size;\r\nmmc->max_blk_size = 1 << 11;\r\nmmc->max_blk_count = mmc->max_req_size >> 11;\r\nspin_lock_init(&host->lock);\r\nwritel(0, host->base + MMCIMASK0);\r\nwritel(0, host->base + MMCIMASK1);\r\nwritel(0xfff, host->base + MMCICLEAR);\r\nif (plat->gpio_cd == -EPROBE_DEFER) {\r\nret = -EPROBE_DEFER;\r\ngoto err_gpio_cd;\r\n}\r\nif (gpio_is_valid(plat->gpio_cd)) {\r\nret = gpio_request(plat->gpio_cd, DRIVER_NAME " (cd)");\r\nif (ret == 0)\r\nret = gpio_direction_input(plat->gpio_cd);\r\nif (ret == 0)\r\nhost->gpio_cd = plat->gpio_cd;\r\nelse if (ret != -ENOSYS)\r\ngoto err_gpio_cd;\r\nret = request_any_context_irq(gpio_to_irq(plat->gpio_cd),\r\nmmci_cd_irq,\r\nIRQF_TRIGGER_RISING | IRQF_TRIGGER_FALLING,\r\nDRIVER_NAME " (cd)", host);\r\nif (ret >= 0)\r\nhost->gpio_cd_irq = gpio_to_irq(plat->gpio_cd);\r\n}\r\nif (plat->gpio_wp == -EPROBE_DEFER) {\r\nret = -EPROBE_DEFER;\r\ngoto err_gpio_wp;\r\n}\r\nif (gpio_is_valid(plat->gpio_wp)) {\r\nret = gpio_request(plat->gpio_wp, DRIVER_NAME " (wp)");\r\nif (ret == 0)\r\nret = gpio_direction_input(plat->gpio_wp);\r\nif (ret == 0)\r\nhost->gpio_wp = plat->gpio_wp;\r\nelse if (ret != -ENOSYS)\r\ngoto err_gpio_wp;\r\n}\r\nif ((host->plat->status || host->gpio_cd != -ENOSYS)\r\n&& host->gpio_cd_irq < 0)\r\nmmc->caps |= MMC_CAP_NEEDS_POLL;\r\nret = request_irq(dev->irq[0], mmci_irq, IRQF_SHARED, DRIVER_NAME " (cmd)", host);\r\nif (ret)\r\ngoto unmap;\r\nif (!dev->irq[1])\r\nhost->singleirq = true;\r\nelse {\r\nret = request_irq(dev->irq[1], mmci_pio_irq, IRQF_SHARED,\r\nDRIVER_NAME " (pio)", host);\r\nif (ret)\r\ngoto irq0_free;\r\n}\r\nwritel(MCI_IRQENABLE, host->base + MMCIMASK0);\r\namba_set_drvdata(dev, mmc);\r\ndev_info(&dev->dev, "%s: PL%03x manf %x rev%u at 0x%08llx irq %d,%d (pio)\n",\r\nmmc_hostname(mmc), amba_part(dev), amba_manf(dev),\r\namba_rev(dev), (unsigned long long)dev->res.start,\r\ndev->irq[0], dev->irq[1]);\r\nmmci_dma_setup(host);\r\npm_runtime_set_autosuspend_delay(&dev->dev, 50);\r\npm_runtime_use_autosuspend(&dev->dev);\r\npm_runtime_put(&dev->dev);\r\nmmc_add_host(mmc);\r\nreturn 0;\r\nirq0_free:\r\nfree_irq(dev->irq[0], host);\r\nunmap:\r\nif (host->gpio_wp != -ENOSYS)\r\ngpio_free(host->gpio_wp);\r\nerr_gpio_wp:\r\nif (host->gpio_cd_irq >= 0)\r\nfree_irq(host->gpio_cd_irq, host);\r\nif (host->gpio_cd != -ENOSYS)\r\ngpio_free(host->gpio_cd);\r\nerr_gpio_cd:\r\niounmap(host->base);\r\nclk_disable:\r\nclk_disable(host->clk);\r\nclk_unprep:\r\nclk_unprepare(host->clk);\r\nclk_free:\r\nclk_put(host->clk);\r\nhost_free:\r\nmmc_free_host(mmc);\r\nrel_regions:\r\namba_release_regions(dev);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int __devexit mmci_remove(struct amba_device *dev)\r\n{\r\nstruct mmc_host *mmc = amba_get_drvdata(dev);\r\namba_set_drvdata(dev, NULL);\r\nif (mmc) {\r\nstruct mmci_host *host = mmc_priv(mmc);\r\npm_runtime_get_sync(&dev->dev);\r\nmmc_remove_host(mmc);\r\nwritel(0, host->base + MMCIMASK0);\r\nwritel(0, host->base + MMCIMASK1);\r\nwritel(0, host->base + MMCICOMMAND);\r\nwritel(0, host->base + MMCIDATACTRL);\r\nmmci_dma_release(host);\r\nfree_irq(dev->irq[0], host);\r\nif (!host->singleirq)\r\nfree_irq(dev->irq[1], host);\r\nif (host->gpio_wp != -ENOSYS)\r\ngpio_free(host->gpio_wp);\r\nif (host->gpio_cd_irq >= 0)\r\nfree_irq(host->gpio_cd_irq, host);\r\nif (host->gpio_cd != -ENOSYS)\r\ngpio_free(host->gpio_cd);\r\niounmap(host->base);\r\nclk_disable(host->clk);\r\nclk_unprepare(host->clk);\r\nclk_put(host->clk);\r\nif (host->vcc)\r\nmmc_regulator_set_ocr(mmc, host->vcc, 0);\r\nregulator_put(host->vcc);\r\nmmc_free_host(mmc);\r\namba_release_regions(dev);\r\n}\r\nreturn 0;\r\n}\r\nstatic int mmci_suspend(struct device *dev)\r\n{\r\nstruct amba_device *adev = to_amba_device(dev);\r\nstruct mmc_host *mmc = amba_get_drvdata(adev);\r\nint ret = 0;\r\nif (mmc) {\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nret = mmc_suspend_host(mmc);\r\nif (ret == 0) {\r\npm_runtime_get_sync(dev);\r\nwritel(0, host->base + MMCIMASK0);\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int mmci_resume(struct device *dev)\r\n{\r\nstruct amba_device *adev = to_amba_device(dev);\r\nstruct mmc_host *mmc = amba_get_drvdata(adev);\r\nint ret = 0;\r\nif (mmc) {\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nwritel(MCI_IRQENABLE, host->base + MMCIMASK0);\r\npm_runtime_put(dev);\r\nret = mmc_resume_host(mmc);\r\n}\r\nreturn ret;\r\n}
