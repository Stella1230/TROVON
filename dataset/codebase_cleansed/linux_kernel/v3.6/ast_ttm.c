static inline struct ast_private *\r\nast_bdev(struct ttm_bo_device *bd)\r\n{\r\nreturn container_of(bd, struct ast_private, ttm.bdev);\r\n}\r\nstatic int\r\nast_ttm_mem_global_init(struct drm_global_reference *ref)\r\n{\r\nreturn ttm_mem_global_init(ref->object);\r\n}\r\nstatic void\r\nast_ttm_mem_global_release(struct drm_global_reference *ref)\r\n{\r\nttm_mem_global_release(ref->object);\r\n}\r\nstatic int ast_ttm_global_init(struct ast_private *ast)\r\n{\r\nstruct drm_global_reference *global_ref;\r\nint r;\r\nglobal_ref = &ast->ttm.mem_global_ref;\r\nglobal_ref->global_type = DRM_GLOBAL_TTM_MEM;\r\nglobal_ref->size = sizeof(struct ttm_mem_global);\r\nglobal_ref->init = &ast_ttm_mem_global_init;\r\nglobal_ref->release = &ast_ttm_mem_global_release;\r\nr = drm_global_item_ref(global_ref);\r\nif (r != 0) {\r\nDRM_ERROR("Failed setting up TTM memory accounting "\r\n"subsystem.\n");\r\nreturn r;\r\n}\r\nast->ttm.bo_global_ref.mem_glob =\r\nast->ttm.mem_global_ref.object;\r\nglobal_ref = &ast->ttm.bo_global_ref.ref;\r\nglobal_ref->global_type = DRM_GLOBAL_TTM_BO;\r\nglobal_ref->size = sizeof(struct ttm_bo_global);\r\nglobal_ref->init = &ttm_bo_global_init;\r\nglobal_ref->release = &ttm_bo_global_release;\r\nr = drm_global_item_ref(global_ref);\r\nif (r != 0) {\r\nDRM_ERROR("Failed setting up TTM BO subsystem.\n");\r\ndrm_global_item_unref(&ast->ttm.mem_global_ref);\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nast_ttm_global_release(struct ast_private *ast)\r\n{\r\nif (ast->ttm.mem_global_ref.release == NULL)\r\nreturn;\r\ndrm_global_item_unref(&ast->ttm.bo_global_ref.ref);\r\ndrm_global_item_unref(&ast->ttm.mem_global_ref);\r\nast->ttm.mem_global_ref.release = NULL;\r\n}\r\nstatic void ast_bo_ttm_destroy(struct ttm_buffer_object *tbo)\r\n{\r\nstruct ast_bo *bo;\r\nbo = container_of(tbo, struct ast_bo, bo);\r\ndrm_gem_object_release(&bo->gem);\r\nkfree(bo);\r\n}\r\nbool ast_ttm_bo_is_ast_bo(struct ttm_buffer_object *bo)\r\n{\r\nif (bo->destroy == &ast_bo_ttm_destroy)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic int\r\nast_bo_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,\r\nstruct ttm_mem_type_manager *man)\r\n{\r\nswitch (type) {\r\ncase TTM_PL_SYSTEM:\r\nman->flags = TTM_MEMTYPE_FLAG_MAPPABLE;\r\nman->available_caching = TTM_PL_MASK_CACHING;\r\nman->default_caching = TTM_PL_FLAG_CACHED;\r\nbreak;\r\ncase TTM_PL_VRAM:\r\nman->func = &ttm_bo_manager_func;\r\nman->flags = TTM_MEMTYPE_FLAG_FIXED |\r\nTTM_MEMTYPE_FLAG_MAPPABLE;\r\nman->available_caching = TTM_PL_FLAG_UNCACHED |\r\nTTM_PL_FLAG_WC;\r\nman->default_caching = TTM_PL_FLAG_WC;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unsupported memory type %u\n", (unsigned)type);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nast_bo_evict_flags(struct ttm_buffer_object *bo, struct ttm_placement *pl)\r\n{\r\nstruct ast_bo *astbo = ast_bo(bo);\r\nif (!ast_ttm_bo_is_ast_bo(bo))\r\nreturn;\r\nast_ttm_placement(astbo, TTM_PL_FLAG_SYSTEM);\r\n*pl = astbo->placement;\r\n}\r\nstatic int ast_bo_verify_access(struct ttm_buffer_object *bo, struct file *filp)\r\n{\r\nreturn 0;\r\n}\r\nstatic int ast_ttm_io_mem_reserve(struct ttm_bo_device *bdev,\r\nstruct ttm_mem_reg *mem)\r\n{\r\nstruct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];\r\nstruct ast_private *ast = ast_bdev(bdev);\r\nmem->bus.addr = NULL;\r\nmem->bus.offset = 0;\r\nmem->bus.size = mem->num_pages << PAGE_SHIFT;\r\nmem->bus.base = 0;\r\nmem->bus.is_iomem = false;\r\nif (!(man->flags & TTM_MEMTYPE_FLAG_MAPPABLE))\r\nreturn -EINVAL;\r\nswitch (mem->mem_type) {\r\ncase TTM_PL_SYSTEM:\r\nreturn 0;\r\ncase TTM_PL_VRAM:\r\nmem->bus.offset = mem->start << PAGE_SHIFT;\r\nmem->bus.base = pci_resource_start(ast->dev->pdev, 0);\r\nmem->bus.is_iomem = true;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic void ast_ttm_io_mem_free(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem)\r\n{\r\n}\r\nstatic int ast_bo_move(struct ttm_buffer_object *bo,\r\nbool evict, bool interruptible,\r\nbool no_wait_reserve, bool no_wait_gpu,\r\nstruct ttm_mem_reg *new_mem)\r\n{\r\nint r;\r\nr = ttm_bo_move_memcpy(bo, evict, no_wait_reserve, no_wait_gpu, new_mem);\r\nreturn r;\r\n}\r\nstatic void ast_ttm_backend_destroy(struct ttm_tt *tt)\r\n{\r\nttm_tt_fini(tt);\r\nkfree(tt);\r\n}\r\nstruct ttm_tt *ast_ttm_tt_create(struct ttm_bo_device *bdev,\r\nunsigned long size, uint32_t page_flags,\r\nstruct page *dummy_read_page)\r\n{\r\nstruct ttm_tt *tt;\r\ntt = kzalloc(sizeof(struct ttm_tt), GFP_KERNEL);\r\nif (tt == NULL)\r\nreturn NULL;\r\ntt->func = &ast_tt_backend_func;\r\nif (ttm_tt_init(tt, bdev, size, page_flags, dummy_read_page)) {\r\nkfree(tt);\r\nreturn NULL;\r\n}\r\nreturn tt;\r\n}\r\nstatic int ast_ttm_tt_populate(struct ttm_tt *ttm)\r\n{\r\nreturn ttm_pool_populate(ttm);\r\n}\r\nstatic void ast_ttm_tt_unpopulate(struct ttm_tt *ttm)\r\n{\r\nttm_pool_unpopulate(ttm);\r\n}\r\nint ast_mm_init(struct ast_private *ast)\r\n{\r\nint ret;\r\nstruct drm_device *dev = ast->dev;\r\nstruct ttm_bo_device *bdev = &ast->ttm.bdev;\r\nret = ast_ttm_global_init(ast);\r\nif (ret)\r\nreturn ret;\r\nret = ttm_bo_device_init(&ast->ttm.bdev,\r\nast->ttm.bo_global_ref.ref.object,\r\n&ast_bo_driver, DRM_FILE_PAGE_OFFSET,\r\ntrue);\r\nif (ret) {\r\nDRM_ERROR("Error initialising bo driver; %d\n", ret);\r\nreturn ret;\r\n}\r\nret = ttm_bo_init_mm(bdev, TTM_PL_VRAM,\r\nast->vram_size >> PAGE_SHIFT);\r\nif (ret) {\r\nDRM_ERROR("Failed ttm VRAM init: %d\n", ret);\r\nreturn ret;\r\n}\r\nast->fb_mtrr = drm_mtrr_add(pci_resource_start(dev->pdev, 0),\r\npci_resource_len(dev->pdev, 0),\r\nDRM_MTRR_WC);\r\nreturn 0;\r\n}\r\nvoid ast_mm_fini(struct ast_private *ast)\r\n{\r\nstruct drm_device *dev = ast->dev;\r\nttm_bo_device_release(&ast->ttm.bdev);\r\nast_ttm_global_release(ast);\r\nif (ast->fb_mtrr >= 0) {\r\ndrm_mtrr_del(ast->fb_mtrr,\r\npci_resource_start(dev->pdev, 0),\r\npci_resource_len(dev->pdev, 0), DRM_MTRR_WC);\r\nast->fb_mtrr = -1;\r\n}\r\n}\r\nvoid ast_ttm_placement(struct ast_bo *bo, int domain)\r\n{\r\nu32 c = 0;\r\nbo->placement.fpfn = 0;\r\nbo->placement.lpfn = 0;\r\nbo->placement.placement = bo->placements;\r\nbo->placement.busy_placement = bo->placements;\r\nif (domain & TTM_PL_FLAG_VRAM)\r\nbo->placements[c++] = TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED | TTM_PL_FLAG_VRAM;\r\nif (domain & TTM_PL_FLAG_SYSTEM)\r\nbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;\r\nif (!c)\r\nbo->placements[c++] = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;\r\nbo->placement.num_placement = c;\r\nbo->placement.num_busy_placement = c;\r\n}\r\nint ast_bo_reserve(struct ast_bo *bo, bool no_wait)\r\n{\r\nint ret;\r\nret = ttm_bo_reserve(&bo->bo, true, no_wait, false, 0);\r\nif (ret) {\r\nif (ret != -ERESTARTSYS)\r\nDRM_ERROR("reserve failed %p\n", bo);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nvoid ast_bo_unreserve(struct ast_bo *bo)\r\n{\r\nttm_bo_unreserve(&bo->bo);\r\n}\r\nint ast_bo_create(struct drm_device *dev, int size, int align,\r\nuint32_t flags, struct ast_bo **pastbo)\r\n{\r\nstruct ast_private *ast = dev->dev_private;\r\nstruct ast_bo *astbo;\r\nsize_t acc_size;\r\nint ret;\r\nastbo = kzalloc(sizeof(struct ast_bo), GFP_KERNEL);\r\nif (!astbo)\r\nreturn -ENOMEM;\r\nret = drm_gem_object_init(dev, &astbo->gem, size);\r\nif (ret) {\r\nkfree(astbo);\r\nreturn ret;\r\n}\r\nastbo->gem.driver_private = NULL;\r\nastbo->bo.bdev = &ast->ttm.bdev;\r\nast_ttm_placement(astbo, TTM_PL_FLAG_VRAM | TTM_PL_FLAG_SYSTEM);\r\nacc_size = ttm_bo_dma_acc_size(&ast->ttm.bdev, size,\r\nsizeof(struct ast_bo));\r\nret = ttm_bo_init(&ast->ttm.bdev, &astbo->bo, size,\r\nttm_bo_type_device, &astbo->placement,\r\nalign >> PAGE_SHIFT, 0, false, NULL, acc_size,\r\nNULL, ast_bo_ttm_destroy);\r\nif (ret)\r\nreturn ret;\r\n*pastbo = astbo;\r\nreturn 0;\r\n}\r\nstatic inline u64 ast_bo_gpu_offset(struct ast_bo *bo)\r\n{\r\nreturn bo->bo.offset;\r\n}\r\nint ast_bo_pin(struct ast_bo *bo, u32 pl_flag, u64 *gpu_addr)\r\n{\r\nint i, ret;\r\nif (bo->pin_count) {\r\nbo->pin_count++;\r\nif (gpu_addr)\r\n*gpu_addr = ast_bo_gpu_offset(bo);\r\n}\r\nast_ttm_placement(bo, pl_flag);\r\nfor (i = 0; i < bo->placement.num_placement; i++)\r\nbo->placements[i] |= TTM_PL_FLAG_NO_EVICT;\r\nret = ttm_bo_validate(&bo->bo, &bo->placement, false, false, false);\r\nif (ret)\r\nreturn ret;\r\nbo->pin_count = 1;\r\nif (gpu_addr)\r\n*gpu_addr = ast_bo_gpu_offset(bo);\r\nreturn 0;\r\n}\r\nint ast_bo_unpin(struct ast_bo *bo)\r\n{\r\nint i, ret;\r\nif (!bo->pin_count) {\r\nDRM_ERROR("unpin bad %p\n", bo);\r\nreturn 0;\r\n}\r\nbo->pin_count--;\r\nif (bo->pin_count)\r\nreturn 0;\r\nfor (i = 0; i < bo->placement.num_placement ; i++)\r\nbo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;\r\nret = ttm_bo_validate(&bo->bo, &bo->placement, false, false, false);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nint ast_bo_push_sysram(struct ast_bo *bo)\r\n{\r\nint i, ret;\r\nif (!bo->pin_count) {\r\nDRM_ERROR("unpin bad %p\n", bo);\r\nreturn 0;\r\n}\r\nbo->pin_count--;\r\nif (bo->pin_count)\r\nreturn 0;\r\nif (bo->kmap.virtual)\r\nttm_bo_kunmap(&bo->kmap);\r\nast_ttm_placement(bo, TTM_PL_FLAG_SYSTEM);\r\nfor (i = 0; i < bo->placement.num_placement ; i++)\r\nbo->placements[i] |= TTM_PL_FLAG_NO_EVICT;\r\nret = ttm_bo_validate(&bo->bo, &bo->placement, false, false, false);\r\nif (ret) {\r\nDRM_ERROR("pushing to VRAM failed\n");\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint ast_mmap(struct file *filp, struct vm_area_struct *vma)\r\n{\r\nstruct drm_file *file_priv;\r\nstruct ast_private *ast;\r\nif (unlikely(vma->vm_pgoff < DRM_FILE_PAGE_OFFSET))\r\nreturn drm_mmap(filp, vma);\r\nfile_priv = filp->private_data;\r\nast = file_priv->minor->dev->dev_private;\r\nreturn ttm_bo_mmap(filp, vma, &ast->ttm.bdev);\r\n}
