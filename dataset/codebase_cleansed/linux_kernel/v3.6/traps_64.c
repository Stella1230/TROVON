static void dump_tl1_traplog(struct tl1_traplog *p)\r\n{\r\nint i, limit;\r\nprintk(KERN_EMERG "TRAPLOG: Error at trap level 0x%lx, "\r\n"dumping track stack.\n", p->tl);\r\nlimit = (tlb_type == hypervisor) ? 2 : 4;\r\nfor (i = 0; i < limit; i++) {\r\nprintk(KERN_EMERG\r\n"TRAPLOG: Trap level %d TSTATE[%016lx] TPC[%016lx] "\r\n"TNPC[%016lx] TT[%lx]\n",\r\ni + 1,\r\np->trapstack[i].tstate, p->trapstack[i].tpc,\r\np->trapstack[i].tnpc, p->trapstack[i].tt);\r\nprintk("TRAPLOG: TPC<%pS>\n", (void *) p->trapstack[i].tpc);\r\n}\r\n}\r\nvoid bad_trap(struct pt_regs *regs, long lvl)\r\n{\r\nchar buffer[32];\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "bad trap", regs,\r\n0, lvl, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\nif (lvl < 0x100) {\r\nsprintf(buffer, "Bad hw trap %lx at tl0\n", lvl);\r\ndie_if_kernel(buffer, regs);\r\n}\r\nlvl -= 0x100;\r\nif (regs->tstate & TSTATE_PRIV) {\r\nsprintf(buffer, "Kernel bad sw trap %lx", lvl);\r\ndie_if_kernel(buffer, regs);\r\n}\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGILL;\r\ninfo.si_errno = 0;\r\ninfo.si_code = ILL_ILLTRP;\r\ninfo.si_addr = (void __user *)regs->tpc;\r\ninfo.si_trapno = lvl;\r\nforce_sig_info(SIGILL, &info, current);\r\n}\r\nvoid bad_trap_tl1(struct pt_regs *regs, long lvl)\r\n{\r\nchar buffer[32];\r\nif (notify_die(DIE_TRAP_TL1, "bad trap tl1", regs,\r\n0, lvl, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\nsprintf (buffer, "Bad trap %lx at tl>0", lvl);\r\ndie_if_kernel (buffer, regs);\r\n}\r\nvoid do_BUG(const char *file, int line)\r\n{\r\nbust_spinlocks(1);\r\nprintk("kernel BUG at %s:%d!\n", file, line);\r\n}\r\nstatic int sprintf_dimm(int synd_code, unsigned long paddr, char *buf, int buflen)\r\n{\r\nunsigned long flags;\r\nint ret = -ENODEV;\r\nspin_lock_irqsave(&dimm_handler_lock, flags);\r\nif (dimm_handler) {\r\nret = dimm_handler(synd_code, paddr, buf, buflen);\r\n} else if (tlb_type == spitfire) {\r\nif (prom_getunumber(synd_code, paddr, buf, buflen) == -1)\r\nret = -EINVAL;\r\nelse\r\nret = 0;\r\n} else\r\nret = -ENODEV;\r\nspin_unlock_irqrestore(&dimm_handler_lock, flags);\r\nreturn ret;\r\n}\r\nint register_dimm_printer(dimm_printer_t func)\r\n{\r\nunsigned long flags;\r\nint ret = 0;\r\nspin_lock_irqsave(&dimm_handler_lock, flags);\r\nif (!dimm_handler)\r\ndimm_handler = func;\r\nelse\r\nret = -EEXIST;\r\nspin_unlock_irqrestore(&dimm_handler_lock, flags);\r\nreturn ret;\r\n}\r\nvoid unregister_dimm_printer(dimm_printer_t func)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&dimm_handler_lock, flags);\r\nif (dimm_handler == func)\r\ndimm_handler = NULL;\r\nspin_unlock_irqrestore(&dimm_handler_lock, flags);\r\n}\r\nvoid spitfire_insn_access_exception(struct pt_regs *regs, unsigned long sfsr, unsigned long sfar)\r\n{\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "instruction access exception", regs,\r\n0, 0x8, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV) {\r\nprintk("spitfire_insn_access_exception: SFSR[%016lx] "\r\n"SFAR[%016lx], going.\n", sfsr, sfar);\r\ndie_if_kernel("Iax", regs);\r\n}\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGSEGV;\r\ninfo.si_errno = 0;\r\ninfo.si_code = SEGV_MAPERR;\r\ninfo.si_addr = (void __user *)regs->tpc;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGSEGV, &info, current);\r\n}\r\nvoid spitfire_insn_access_exception_tl1(struct pt_regs *regs, unsigned long sfsr, unsigned long sfar)\r\n{\r\nif (notify_die(DIE_TRAP_TL1, "instruction access exception tl1", regs,\r\n0, 0x8, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\nspitfire_insn_access_exception(regs, sfsr, sfar);\r\n}\r\nvoid sun4v_insn_access_exception(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)\r\n{\r\nunsigned short type = (type_ctx >> 16);\r\nunsigned short ctx = (type_ctx & 0xffff);\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "instruction access exception", regs,\r\n0, 0x8, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV) {\r\nprintk("sun4v_insn_access_exception: ADDR[%016lx] "\r\n"CTX[%04x] TYPE[%04x], going.\n",\r\naddr, ctx, type);\r\ndie_if_kernel("Iax", regs);\r\n}\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGSEGV;\r\ninfo.si_errno = 0;\r\ninfo.si_code = SEGV_MAPERR;\r\ninfo.si_addr = (void __user *) addr;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGSEGV, &info, current);\r\n}\r\nvoid sun4v_insn_access_exception_tl1(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)\r\n{\r\nif (notify_die(DIE_TRAP_TL1, "instruction access exception tl1", regs,\r\n0, 0x8, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\nsun4v_insn_access_exception(regs, addr, type_ctx);\r\n}\r\nvoid spitfire_data_access_exception(struct pt_regs *regs, unsigned long sfsr, unsigned long sfar)\r\n{\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "data access exception", regs,\r\n0, 0x30, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV) {\r\nconst struct exception_table_entry *entry;\r\nentry = search_exception_tables(regs->tpc);\r\nif (entry) {\r\n#ifdef DEBUG_EXCEPTIONS\r\nprintk("Exception: PC<%016lx> faddr<UNKNOWN>\n", regs->tpc);\r\nprintk("EX_TABLE: insn<%016lx> fixup<%016lx>\n",\r\nregs->tpc, entry->fixup);\r\n#endif\r\nregs->tpc = entry->fixup;\r\nregs->tnpc = regs->tpc + 4;\r\nreturn;\r\n}\r\nprintk("spitfire_data_access_exception: SFSR[%016lx] "\r\n"SFAR[%016lx], going.\n", sfsr, sfar);\r\ndie_if_kernel("Dax", regs);\r\n}\r\ninfo.si_signo = SIGSEGV;\r\ninfo.si_errno = 0;\r\ninfo.si_code = SEGV_MAPERR;\r\ninfo.si_addr = (void __user *)sfar;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGSEGV, &info, current);\r\n}\r\nvoid spitfire_data_access_exception_tl1(struct pt_regs *regs, unsigned long sfsr, unsigned long sfar)\r\n{\r\nif (notify_die(DIE_TRAP_TL1, "data access exception tl1", regs,\r\n0, 0x30, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\nspitfire_data_access_exception(regs, sfsr, sfar);\r\n}\r\nvoid sun4v_data_access_exception(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)\r\n{\r\nunsigned short type = (type_ctx >> 16);\r\nunsigned short ctx = (type_ctx & 0xffff);\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "data access exception", regs,\r\n0, 0x8, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV) {\r\nconst struct exception_table_entry *entry;\r\nentry = search_exception_tables(regs->tpc);\r\nif (entry) {\r\n#ifdef DEBUG_EXCEPTIONS\r\nprintk("Exception: PC<%016lx> faddr<UNKNOWN>\n", regs->tpc);\r\nprintk("EX_TABLE: insn<%016lx> fixup<%016lx>\n",\r\nregs->tpc, entry->fixup);\r\n#endif\r\nregs->tpc = entry->fixup;\r\nregs->tnpc = regs->tpc + 4;\r\nreturn;\r\n}\r\nprintk("sun4v_data_access_exception: ADDR[%016lx] "\r\n"CTX[%04x] TYPE[%04x], going.\n",\r\naddr, ctx, type);\r\ndie_if_kernel("Dax", regs);\r\n}\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGSEGV;\r\ninfo.si_errno = 0;\r\ninfo.si_code = SEGV_MAPERR;\r\ninfo.si_addr = (void __user *) addr;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGSEGV, &info, current);\r\n}\r\nvoid sun4v_data_access_exception_tl1(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)\r\n{\r\nif (notify_die(DIE_TRAP_TL1, "data access exception tl1", regs,\r\n0, 0x8, SIGTRAP) == NOTIFY_STOP)\r\nreturn;\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\nsun4v_data_access_exception(regs, addr, type_ctx);\r\n}\r\nstatic void spitfire_clean_and_reenable_l1_caches(void)\r\n{\r\nunsigned long va;\r\nif (tlb_type != spitfire)\r\nBUG();\r\nfor (va = 0; va < (PAGE_SIZE << 1); va += 32) {\r\nspitfire_put_icache_tag(va, 0x0);\r\nspitfire_put_dcache_tag(va, 0x0);\r\n}\r\n__asm__ __volatile__("flush %%g6\n\t"\r\n"membar #Sync\n\t"\r\n"stxa %0, [%%g0] %1\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (LSU_CONTROL_IC | LSU_CONTROL_DC |\r\nLSU_CONTROL_IM | LSU_CONTROL_DM),\r\n"i" (ASI_LSU_CONTROL)\r\n: "memory");\r\n}\r\nstatic void spitfire_enable_estate_errors(void)\r\n{\r\n__asm__ __volatile__("stxa %0, [%%g0] %1\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (ESTATE_ERR_ALL),\r\n"i" (ASI_ESTATE_ERROR_EN));\r\n}\r\nstatic void spitfire_log_udb_syndrome(unsigned long afar, unsigned long udbh, unsigned long udbl, unsigned long bit)\r\n{\r\nunsigned short scode;\r\nchar memmod_str[64], *p;\r\nif (udbl & bit) {\r\nscode = ecc_syndrome_table[udbl & 0xff];\r\nif (sprintf_dimm(scode, afar, memmod_str, sizeof(memmod_str)) < 0)\r\np = syndrome_unknown;\r\nelse\r\np = memmod_str;\r\nprintk(KERN_WARNING "CPU[%d]: UDBL Syndrome[%x] "\r\n"Memory Module \"%s\"\n",\r\nsmp_processor_id(), scode, p);\r\n}\r\nif (udbh & bit) {\r\nscode = ecc_syndrome_table[udbh & 0xff];\r\nif (sprintf_dimm(scode, afar, memmod_str, sizeof(memmod_str)) < 0)\r\np = syndrome_unknown;\r\nelse\r\np = memmod_str;\r\nprintk(KERN_WARNING "CPU[%d]: UDBH Syndrome[%x] "\r\n"Memory Module \"%s\"\n",\r\nsmp_processor_id(), scode, p);\r\n}\r\n}\r\nstatic void spitfire_cee_log(unsigned long afsr, unsigned long afar, unsigned long udbh, unsigned long udbl, int tl1, struct pt_regs *regs)\r\n{\r\nprintk(KERN_WARNING "CPU[%d]: Correctable ECC Error "\r\n"AFSR[%lx] AFAR[%016lx] UDBL[%lx] UDBH[%lx] TL>1[%d]\n",\r\nsmp_processor_id(), afsr, afar, udbl, udbh, tl1);\r\nspitfire_log_udb_syndrome(afar, udbh, udbl, UDBE_CE);\r\nnotify_die(DIE_TRAP, "Correctable ECC Error", regs,\r\n0, TRAP_TYPE_CEE, SIGTRAP);\r\nspitfire_enable_estate_errors();\r\n}\r\nstatic void spitfire_ue_log(unsigned long afsr, unsigned long afar, unsigned long udbh, unsigned long udbl, unsigned long tt, int tl1, struct pt_regs *regs)\r\n{\r\nsiginfo_t info;\r\nprintk(KERN_WARNING "CPU[%d]: Uncorrectable Error AFSR[%lx] "\r\n"AFAR[%lx] UDBL[%lx] UDBH[%ld] TT[%lx] TL>1[%d]\n",\r\nsmp_processor_id(), afsr, afar, udbl, udbh, tt, tl1);\r\nspitfire_log_udb_syndrome(afar, udbh, udbl, UDBE_UE);\r\nnotify_die(DIE_TRAP, "Uncorrectable Error", regs,\r\n0, tt, SIGTRAP);\r\nif (regs->tstate & TSTATE_PRIV) {\r\nif (tl1)\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("UE", regs);\r\n}\r\nspitfire_clean_and_reenable_l1_caches();\r\nspitfire_enable_estate_errors();\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGBUS;\r\ninfo.si_errno = 0;\r\ninfo.si_code = BUS_OBJERR;\r\ninfo.si_addr = (void *)0;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGBUS, &info, current);\r\n}\r\nvoid spitfire_access_error(struct pt_regs *regs, unsigned long status_encoded, unsigned long afar)\r\n{\r\nunsigned long afsr, tt, udbh, udbl;\r\nint tl1;\r\nafsr = (status_encoded & SFSTAT_AFSR_MASK) >> SFSTAT_AFSR_SHIFT;\r\ntt = (status_encoded & SFSTAT_TRAP_TYPE) >> SFSTAT_TRAP_TYPE_SHIFT;\r\ntl1 = (status_encoded & SFSTAT_TL_GT_ONE) ? 1 : 0;\r\nudbl = (status_encoded & SFSTAT_UDBL_MASK) >> SFSTAT_UDBL_SHIFT;\r\nudbh = (status_encoded & SFSTAT_UDBH_MASK) >> SFSTAT_UDBH_SHIFT;\r\n#ifdef CONFIG_PCI\r\nif (tt == TRAP_TYPE_DAE &&\r\npci_poke_in_progress && pci_poke_cpu == smp_processor_id()) {\r\nspitfire_clean_and_reenable_l1_caches();\r\nspitfire_enable_estate_errors();\r\npci_poke_faulted = 1;\r\nregs->tnpc = regs->tpc + 4;\r\nreturn;\r\n}\r\n#endif\r\nif (afsr & SFAFSR_UE)\r\nspitfire_ue_log(afsr, afar, udbh, udbl, tt, tl1, regs);\r\nif (tt == TRAP_TYPE_CEE) {\r\nif (afsr & SFAFSR_UE) {\r\nif (udbh & UDBE_CE) {\r\n__asm__ __volatile__(\r\n"stxa %0, [%1] %2\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (udbh & UDBE_CE),\r\n"r" (0x0), "i" (ASI_UDB_ERROR_W));\r\n}\r\nif (udbl & UDBE_CE) {\r\n__asm__ __volatile__(\r\n"stxa %0, [%1] %2\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (udbl & UDBE_CE),\r\n"r" (0x18), "i" (ASI_UDB_ERROR_W));\r\n}\r\n}\r\nspitfire_cee_log(afsr, afar, udbh, udbl, tl1, regs);\r\n}\r\n}\r\nvoid cheetah_enable_pcache(void)\r\n{\r\nunsigned long dcr;\r\nprintk("CHEETAH: Enabling P-Cache on cpu %d.\n",\r\nsmp_processor_id());\r\n__asm__ __volatile__("ldxa [%%g0] %1, %0"\r\n: "=r" (dcr)\r\n: "i" (ASI_DCU_CONTROL_REG));\r\ndcr |= (DCU_PE | DCU_HPE | DCU_SPE | DCU_SL);\r\n__asm__ __volatile__("stxa %0, [%%g0] %1\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (dcr), "i" (ASI_DCU_CONTROL_REG));\r\n}\r\nstatic inline struct cheetah_err_info *cheetah_get_error_log(unsigned long afsr)\r\n{\r\nstruct cheetah_err_info *p;\r\nint cpu = smp_processor_id();\r\nif (!cheetah_error_log)\r\nreturn NULL;\r\np = cheetah_error_log + (cpu * 2);\r\nif ((afsr & CHAFSR_TL1) != 0UL)\r\np++;\r\nreturn p;\r\n}\r\nvoid __init cheetah_ecache_flush_init(void)\r\n{\r\nunsigned long largest_size, smallest_linesize, order, ver;\r\nint i, sz;\r\nlargest_size = 0UL;\r\nsmallest_linesize = ~0UL;\r\nfor (i = 0; i < NR_CPUS; i++) {\r\nunsigned long val;\r\nval = cpu_data(i).ecache_size;\r\nif (!val)\r\ncontinue;\r\nif (val > largest_size)\r\nlargest_size = val;\r\nval = cpu_data(i).ecache_line_size;\r\nif (val < smallest_linesize)\r\nsmallest_linesize = val;\r\n}\r\nif (largest_size == 0UL || smallest_linesize == ~0UL) {\r\nprom_printf("cheetah_ecache_flush_init: Cannot probe cpu E-cache "\r\n"parameters.\n");\r\nprom_halt();\r\n}\r\necache_flush_size = (2 * largest_size);\r\necache_flush_linesize = smallest_linesize;\r\necache_flush_physbase = find_ecache_flush_span(ecache_flush_size);\r\nif (ecache_flush_physbase == ~0UL) {\r\nprom_printf("cheetah_ecache_flush_init: Cannot find %d byte "\r\n"contiguous physical memory.\n",\r\necache_flush_size);\r\nprom_halt();\r\n}\r\nsz = NR_CPUS * (2 * sizeof(struct cheetah_err_info));\r\nfor (order = 0; order < MAX_ORDER; order++) {\r\nif ((PAGE_SIZE << order) >= sz)\r\nbreak;\r\n}\r\ncheetah_error_log = (struct cheetah_err_info *)\r\n__get_free_pages(GFP_KERNEL, order);\r\nif (!cheetah_error_log) {\r\nprom_printf("cheetah_ecache_flush_init: Failed to allocate "\r\n"error logging scoreboard (%d bytes).\n", sz);\r\nprom_halt();\r\n}\r\nmemset(cheetah_error_log, 0, PAGE_SIZE << order);\r\nfor (i = 0; i < 2 * NR_CPUS; i++)\r\ncheetah_error_log[i].afsr = CHAFSR_INVALID;\r\n__asm__ ("rdpr %%ver, %0" : "=r" (ver));\r\nif ((ver >> 32) == __JALAPENO_ID ||\r\n(ver >> 32) == __SERRANO_ID) {\r\ncheetah_error_table = &__jalapeno_error_table[0];\r\ncheetah_afsr_errors = JPAFSR_ERRORS;\r\n} else if ((ver >> 32) == 0x003e0015) {\r\ncheetah_error_table = &__cheetah_plus_error_table[0];\r\ncheetah_afsr_errors = CHPAFSR_ERRORS;\r\n} else {\r\ncheetah_error_table = &__cheetah_error_table[0];\r\ncheetah_afsr_errors = CHAFSR_ERRORS;\r\n}\r\nmemcpy(tl0_fecc, cheetah_fecc_trap_vector, (8 * 4));\r\nmemcpy(tl1_fecc, cheetah_fecc_trap_vector_tl1, (8 * 4));\r\nmemcpy(tl0_cee, cheetah_cee_trap_vector, (8 * 4));\r\nmemcpy(tl1_cee, cheetah_cee_trap_vector_tl1, (8 * 4));\r\nmemcpy(tl0_iae, cheetah_deferred_trap_vector, (8 * 4));\r\nmemcpy(tl1_iae, cheetah_deferred_trap_vector_tl1, (8 * 4));\r\nmemcpy(tl0_dae, cheetah_deferred_trap_vector, (8 * 4));\r\nmemcpy(tl1_dae, cheetah_deferred_trap_vector_tl1, (8 * 4));\r\nif (tlb_type == cheetah_plus) {\r\nmemcpy(tl0_dcpe, cheetah_plus_dcpe_trap_vector, (8 * 4));\r\nmemcpy(tl1_dcpe, cheetah_plus_dcpe_trap_vector_tl1, (8 * 4));\r\nmemcpy(tl0_icpe, cheetah_plus_icpe_trap_vector, (8 * 4));\r\nmemcpy(tl1_icpe, cheetah_plus_icpe_trap_vector_tl1, (8 * 4));\r\n}\r\nflushi(PAGE_OFFSET);\r\n}\r\nstatic void cheetah_flush_ecache(void)\r\n{\r\nunsigned long flush_base = ecache_flush_physbase;\r\nunsigned long flush_linesize = ecache_flush_linesize;\r\nunsigned long flush_size = ecache_flush_size;\r\n__asm__ __volatile__("1: subcc %0, %4, %0\n\t"\r\n" bne,pt %%xcc, 1b\n\t"\r\n" ldxa [%2 + %0] %3, %%g0\n\t"\r\n: "=&r" (flush_size)\r\n: "0" (flush_size), "r" (flush_base),\r\n"i" (ASI_PHYS_USE_EC), "r" (flush_linesize));\r\n}\r\nstatic void cheetah_flush_ecache_line(unsigned long physaddr)\r\n{\r\nunsigned long alias;\r\nphysaddr &= ~(8UL - 1UL);\r\nphysaddr = (ecache_flush_physbase +\r\n(physaddr & ((ecache_flush_size>>1UL) - 1UL)));\r\nalias = physaddr + (ecache_flush_size >> 1UL);\r\n__asm__ __volatile__("ldxa [%0] %2, %%g0\n\t"\r\n"ldxa [%1] %2, %%g0\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (physaddr), "r" (alias),\r\n"i" (ASI_PHYS_USE_EC));\r\n}\r\nstatic void __cheetah_flush_icache(void)\r\n{\r\nunsigned int icache_size, icache_line_size;\r\nunsigned long addr;\r\nicache_size = local_cpu_data().icache_size;\r\nicache_line_size = local_cpu_data().icache_line_size;\r\nfor (addr = 0; addr < icache_size; addr += icache_line_size) {\r\n__asm__ __volatile__("stxa %%g0, [%0] %1\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (addr | (2 << 3)),\r\n"i" (ASI_IC_TAG));\r\n}\r\n}\r\nstatic void cheetah_flush_icache(void)\r\n{\r\nunsigned long dcu_save;\r\n__asm__ __volatile__("ldxa [%%g0] %1, %0\n\t"\r\n"or %0, %2, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %1\n\t"\r\n"membar #Sync"\r\n: "=r" (dcu_save)\r\n: "i" (ASI_DCU_CONTROL_REG), "i" (DCU_IC)\r\n: "g1");\r\n__cheetah_flush_icache();\r\n__asm__ __volatile__("stxa %0, [%%g0] %1\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (dcu_save), "i" (ASI_DCU_CONTROL_REG));\r\n}\r\nstatic void cheetah_flush_dcache(void)\r\n{\r\nunsigned int dcache_size, dcache_line_size;\r\nunsigned long addr;\r\ndcache_size = local_cpu_data().dcache_size;\r\ndcache_line_size = local_cpu_data().dcache_line_size;\r\nfor (addr = 0; addr < dcache_size; addr += dcache_line_size) {\r\n__asm__ __volatile__("stxa %%g0, [%0] %1\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (addr), "i" (ASI_DCACHE_TAG));\r\n}\r\n}\r\nstatic void cheetah_plus_zap_dcache_parity(void)\r\n{\r\nunsigned int dcache_size, dcache_line_size;\r\nunsigned long addr;\r\ndcache_size = local_cpu_data().dcache_size;\r\ndcache_line_size = local_cpu_data().dcache_line_size;\r\nfor (addr = 0; addr < dcache_size; addr += dcache_line_size) {\r\nunsigned long tag = (addr >> 14);\r\nunsigned long line;\r\n__asm__ __volatile__("membar #Sync\n\t"\r\n"stxa %0, [%1] %2\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (tag), "r" (addr),\r\n"i" (ASI_DCACHE_UTAG));\r\nfor (line = addr; line < addr + dcache_line_size; line += 8)\r\n__asm__ __volatile__("membar #Sync\n\t"\r\n"stxa %%g0, [%0] %1\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (line),\r\n"i" (ASI_DCACHE_DATA));\r\n}\r\n}\r\nstatic inline unsigned long cheetah_get_hipri(unsigned long afsr)\r\n{\r\nunsigned long tmp = 0;\r\nint i;\r\nfor (i = 0; cheetah_error_table[i].mask; i++) {\r\nif ((tmp = (afsr & cheetah_error_table[i].mask)) != 0UL)\r\nreturn tmp;\r\n}\r\nreturn tmp;\r\n}\r\nstatic const char *cheetah_get_string(unsigned long bit)\r\n{\r\nint i;\r\nfor (i = 0; cheetah_error_table[i].mask; i++) {\r\nif ((bit & cheetah_error_table[i].mask) != 0UL)\r\nreturn cheetah_error_table[i].name;\r\n}\r\nreturn "???";\r\n}\r\nstatic void cheetah_log_errors(struct pt_regs *regs, struct cheetah_err_info *info,\r\nunsigned long afsr, unsigned long afar, int recoverable)\r\n{\r\nunsigned long hipri;\r\nchar unum[256];\r\nprintk("%s" "ERROR(%d): Cheetah error trap taken afsr[%016lx] afar[%016lx] TL1(%d)\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\nafsr, afar,\r\n(afsr & CHAFSR_TL1) ? 1 : 0);\r\nprintk("%s" "ERROR(%d): TPC[%lx] TNPC[%lx] O7[%lx] TSTATE[%lx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\nregs->tpc, regs->tnpc, regs->u_regs[UREG_I7], regs->tstate);\r\nprintk("%s" "ERROR(%d): ",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id());\r\nprintk("TPC<%pS>\n", (void *) regs->tpc);\r\nprintk("%s" "ERROR(%d): M_SYND(%lx), E_SYND(%lx)%s%s\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\n(afsr & CHAFSR_M_SYNDROME) >> CHAFSR_M_SYNDROME_SHIFT,\r\n(afsr & CHAFSR_E_SYNDROME) >> CHAFSR_E_SYNDROME_SHIFT,\r\n(afsr & CHAFSR_ME) ? ", Multiple Errors" : "",\r\n(afsr & CHAFSR_PRIV) ? ", Privileged" : "");\r\nhipri = cheetah_get_hipri(afsr);\r\nprintk("%s" "ERROR(%d): Highest priority error (%016lx) \"%s\"\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\nhipri, cheetah_get_string(hipri));\r\n#define ESYND_ERRORS (CHAFSR_IVC | CHAFSR_IVU | \\r\nCHAFSR_CPC | CHAFSR_CPU | \\r\nCHAFSR_UE | CHAFSR_CE | \\r\nCHAFSR_EDC | CHAFSR_EDU | \\r\nCHAFSR_UCC | CHAFSR_UCU | \\r\nCHAFSR_WDU | CHAFSR_WDC)\r\n#define MSYND_ERRORS (CHAFSR_EMC | CHAFSR_EMU)\r\nif (afsr & ESYND_ERRORS) {\r\nint syndrome;\r\nint ret;\r\nsyndrome = (afsr & CHAFSR_E_SYNDROME) >> CHAFSR_E_SYNDROME_SHIFT;\r\nsyndrome = cheetah_ecc_syntab[syndrome];\r\nret = sprintf_dimm(syndrome, afar, unum, sizeof(unum));\r\nif (ret != -1)\r\nprintk("%s" "ERROR(%d): AFAR E-syndrome [%s]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT),\r\nsmp_processor_id(), unum);\r\n} else if (afsr & MSYND_ERRORS) {\r\nint syndrome;\r\nint ret;\r\nsyndrome = (afsr & CHAFSR_M_SYNDROME) >> CHAFSR_M_SYNDROME_SHIFT;\r\nsyndrome = cheetah_mtag_syntab[syndrome];\r\nret = sprintf_dimm(syndrome, afar, unum, sizeof(unum));\r\nif (ret != -1)\r\nprintk("%s" "ERROR(%d): AFAR M-syndrome [%s]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT),\r\nsmp_processor_id(), unum);\r\n}\r\nprintk("%s" "ERROR(%d): D-cache idx[%x] tag[%016llx] utag[%016llx] stag[%016llx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\n(int) info->dcache_index,\r\ninfo->dcache_tag,\r\ninfo->dcache_utag,\r\ninfo->dcache_stag);\r\nprintk("%s" "ERROR(%d): D-cache data0[%016llx] data1[%016llx] data2[%016llx] data3[%016llx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\ninfo->dcache_data[0],\r\ninfo->dcache_data[1],\r\ninfo->dcache_data[2],\r\ninfo->dcache_data[3]);\r\nprintk("%s" "ERROR(%d): I-cache idx[%x] tag[%016llx] utag[%016llx] stag[%016llx] "\r\n"u[%016llx] l[%016llx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\n(int) info->icache_index,\r\ninfo->icache_tag,\r\ninfo->icache_utag,\r\ninfo->icache_stag,\r\ninfo->icache_upper,\r\ninfo->icache_lower);\r\nprintk("%s" "ERROR(%d): I-cache INSN0[%016llx] INSN1[%016llx] INSN2[%016llx] INSN3[%016llx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\ninfo->icache_data[0],\r\ninfo->icache_data[1],\r\ninfo->icache_data[2],\r\ninfo->icache_data[3]);\r\nprintk("%s" "ERROR(%d): I-cache INSN4[%016llx] INSN5[%016llx] INSN6[%016llx] INSN7[%016llx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\ninfo->icache_data[4],\r\ninfo->icache_data[5],\r\ninfo->icache_data[6],\r\ninfo->icache_data[7]);\r\nprintk("%s" "ERROR(%d): E-cache idx[%x] tag[%016llx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\n(int) info->ecache_index, info->ecache_tag);\r\nprintk("%s" "ERROR(%d): E-cache data0[%016llx] data1[%016llx] data2[%016llx] data3[%016llx]\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT), smp_processor_id(),\r\ninfo->ecache_data[0],\r\ninfo->ecache_data[1],\r\ninfo->ecache_data[2],\r\ninfo->ecache_data[3]);\r\nafsr = (afsr & ~hipri) & cheetah_afsr_errors;\r\nwhile (afsr != 0UL) {\r\nunsigned long bit = cheetah_get_hipri(afsr);\r\nprintk("%s" "ERROR: Multiple-error (%016lx) \"%s\"\n",\r\n(recoverable ? KERN_WARNING : KERN_CRIT),\r\nbit, cheetah_get_string(bit));\r\nafsr &= ~bit;\r\n}\r\nif (!recoverable)\r\nprintk(KERN_CRIT "ERROR: This condition is not recoverable.\n");\r\n}\r\nstatic int cheetah_recheck_errors(struct cheetah_err_info *logp)\r\n{\r\nunsigned long afsr, afar;\r\nint ret = 0;\r\n__asm__ __volatile__("ldxa [%%g0] %1, %0\n\t"\r\n: "=r" (afsr)\r\n: "i" (ASI_AFSR));\r\nif ((afsr & cheetah_afsr_errors) != 0) {\r\nif (logp != NULL) {\r\n__asm__ __volatile__("ldxa [%%g0] %1, %0\n\t"\r\n: "=r" (afar)\r\n: "i" (ASI_AFAR));\r\nlogp->afsr = afsr;\r\nlogp->afar = afar;\r\n}\r\nret = 1;\r\n}\r\n__asm__ __volatile__("stxa %0, [%%g0] %1\n\t"\r\n"membar #Sync\n\t"\r\n: : "r" (afsr), "i" (ASI_AFSR));\r\nreturn ret;\r\n}\r\nvoid cheetah_fecc_handler(struct pt_regs *regs, unsigned long afsr, unsigned long afar)\r\n{\r\nstruct cheetah_err_info local_snapshot, *p;\r\nint recoverable;\r\ncheetah_flush_ecache();\r\np = cheetah_get_error_log(afsr);\r\nif (!p) {\r\nprom_printf("ERROR: Early Fast-ECC error afsr[%016lx] afar[%016lx]\n",\r\nafsr, afar);\r\nprom_printf("ERROR: CPU(%d) TPC[%016lx] TNPC[%016lx] TSTATE[%016lx]\n",\r\nsmp_processor_id(), regs->tpc, regs->tnpc, regs->tstate);\r\nprom_halt();\r\n}\r\nmemcpy(&local_snapshot, p, sizeof(local_snapshot));\r\nif (p->afsr != afsr || p->afar != afar)\r\nlocal_snapshot.afsr = CHAFSR_INVALID;\r\nelse\r\np->afsr = CHAFSR_INVALID;\r\ncheetah_flush_icache();\r\ncheetah_flush_dcache();\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_DCU_CONTROL_REG),\r\n"i" (DCU_DC | DCU_IC)\r\n: "g1");\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_ESTATE_ERROR_EN),\r\n"i" (ESTATE_ERROR_NCEEN | ESTATE_ERROR_CEEN)\r\n: "g1");\r\nrecoverable = 1;\r\nif (afsr & (CHAFSR_PERR | CHAFSR_IERR | CHAFSR_ISAP))\r\nrecoverable = 0;\r\nif (cheetah_recheck_errors(&local_snapshot)) {\r\nunsigned long new_afsr = local_snapshot.afsr;\r\nif (new_afsr & (CHAFSR_EMU | CHAFSR_EDU |\r\nCHAFSR_WDU | CHAFSR_CPU |\r\nCHAFSR_IVU | CHAFSR_UE |\r\nCHAFSR_BERR | CHAFSR_TO))\r\nrecoverable = 0;\r\n}\r\ncheetah_log_errors(regs, &local_snapshot, afsr, afar, recoverable);\r\nif (!recoverable)\r\npanic("Irrecoverable Fast-ECC error trap.\n");\r\ncheetah_flush_ecache();\r\n}\r\nstatic int cheetah_fix_ce(unsigned long physaddr)\r\n{\r\nunsigned long orig_estate;\r\nunsigned long alias1, alias2;\r\nint ret;\r\n__asm__ __volatile__("ldxa [%%g0] %2, %0\n\t"\r\n"andn %0, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %2\n\t"\r\n"membar #Sync"\r\n: "=&r" (orig_estate)\r\n: "i" (ESTATE_ERROR_CEEN),\r\n"i" (ASI_ESTATE_ERROR_EN)\r\n: "g1");\r\nphysaddr &= ~(8UL - 1UL);\r\nalias1 = (ecache_flush_physbase +\r\n(physaddr & ((ecache_flush_size >> 1) - 1)));\r\nalias2 = alias1 + (ecache_flush_size >> 1);\r\n__asm__ __volatile__("ldxa [%0] %3, %%g0\n\t"\r\n"ldxa [%1] %3, %%g0\n\t"\r\n"casxa [%2] %3, %%g0, %%g0\n\t"\r\n"ldxa [%0] %3, %%g0\n\t"\r\n"ldxa [%1] %3, %%g0\n\t"\r\n"membar #Sync"\r\n:\r\n: "r" (alias1), "r" (alias2),\r\n"r" (physaddr), "i" (ASI_PHYS_USE_EC));\r\nif (cheetah_recheck_errors(NULL)) {\r\n__asm__ __volatile__("ldxa [%0] %1, %%g0\n\t"\r\n"membar #Sync"\r\n: : "r" (physaddr), "i" (ASI_PHYS_USE_EC));\r\nif (cheetah_recheck_errors(NULL))\r\nret = 2;\r\nelse\r\nret = 1;\r\n} else {\r\nret = 0;\r\n}\r\n__asm__ __volatile__("stxa %0, [%%g0] %1\n\t"\r\n"membar #Sync"\r\n: : "r" (orig_estate), "i" (ASI_ESTATE_ERROR_EN));\r\nreturn ret;\r\n}\r\nstatic int cheetah_check_main_memory(unsigned long paddr)\r\n{\r\nunsigned long vaddr = PAGE_OFFSET + paddr;\r\nif (vaddr > (unsigned long) high_memory)\r\nreturn 0;\r\nreturn kern_addr_valid(vaddr);\r\n}\r\nvoid cheetah_cee_handler(struct pt_regs *regs, unsigned long afsr, unsigned long afar)\r\n{\r\nstruct cheetah_err_info local_snapshot, *p;\r\nint recoverable, is_memory;\r\np = cheetah_get_error_log(afsr);\r\nif (!p) {\r\nprom_printf("ERROR: Early CEE error afsr[%016lx] afar[%016lx]\n",\r\nafsr, afar);\r\nprom_printf("ERROR: CPU(%d) TPC[%016lx] TNPC[%016lx] TSTATE[%016lx]\n",\r\nsmp_processor_id(), regs->tpc, regs->tnpc, regs->tstate);\r\nprom_halt();\r\n}\r\nmemcpy(&local_snapshot, p, sizeof(local_snapshot));\r\nif (p->afsr != afsr || p->afar != afar)\r\nlocal_snapshot.afsr = CHAFSR_INVALID;\r\nelse\r\np->afsr = CHAFSR_INVALID;\r\nis_memory = cheetah_check_main_memory(afar);\r\nif (is_memory && (afsr & CHAFSR_CE) != 0UL) {\r\ncheetah_fix_ce(afar);\r\n}\r\n{\r\nint flush_all, flush_line;\r\nflush_all = flush_line = 0;\r\nif ((afsr & CHAFSR_EDC) != 0UL) {\r\nif ((afsr & cheetah_afsr_errors) == CHAFSR_EDC)\r\nflush_line = 1;\r\nelse\r\nflush_all = 1;\r\n} else if ((afsr & CHAFSR_CPC) != 0UL) {\r\nif ((afsr & cheetah_afsr_errors) == CHAFSR_CPC)\r\nflush_line = 1;\r\nelse\r\nflush_all = 1;\r\n}\r\ncheetah_flush_icache();\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_DCU_CONTROL_REG),\r\n"i" (DCU_IC)\r\n: "g1");\r\nif (flush_all)\r\ncheetah_flush_ecache();\r\nelse if (flush_line)\r\ncheetah_flush_ecache_line(afar);\r\n}\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_ESTATE_ERROR_EN),\r\n"i" (ESTATE_ERROR_CEEN)\r\n: "g1");\r\nrecoverable = 1;\r\nif (afsr & (CHAFSR_PERR | CHAFSR_IERR | CHAFSR_ISAP))\r\nrecoverable = 0;\r\n(void) cheetah_recheck_errors(&local_snapshot);\r\ncheetah_log_errors(regs, &local_snapshot, afsr, afar, recoverable);\r\nif (!recoverable)\r\npanic("Irrecoverable Correctable-ECC error trap.\n");\r\n}\r\nvoid cheetah_deferred_handler(struct pt_regs *regs, unsigned long afsr, unsigned long afar)\r\n{\r\nstruct cheetah_err_info local_snapshot, *p;\r\nint recoverable, is_memory;\r\n#ifdef CONFIG_PCI\r\nif (pci_poke_in_progress && pci_poke_cpu == smp_processor_id()) {\r\ncheetah_flush_icache();\r\ncheetah_flush_dcache();\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_DCU_CONTROL_REG),\r\n"i" (DCU_DC | DCU_IC)\r\n: "g1");\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_ESTATE_ERROR_EN),\r\n"i" (ESTATE_ERROR_NCEEN | ESTATE_ERROR_CEEN)\r\n: "g1");\r\n(void) cheetah_recheck_errors(NULL);\r\npci_poke_faulted = 1;\r\nregs->tpc += 4;\r\nregs->tnpc = regs->tpc + 4;\r\nreturn;\r\n}\r\n#endif\r\np = cheetah_get_error_log(afsr);\r\nif (!p) {\r\nprom_printf("ERROR: Early deferred error afsr[%016lx] afar[%016lx]\n",\r\nafsr, afar);\r\nprom_printf("ERROR: CPU(%d) TPC[%016lx] TNPC[%016lx] TSTATE[%016lx]\n",\r\nsmp_processor_id(), regs->tpc, regs->tnpc, regs->tstate);\r\nprom_halt();\r\n}\r\nmemcpy(&local_snapshot, p, sizeof(local_snapshot));\r\nif (p->afsr != afsr || p->afar != afar)\r\nlocal_snapshot.afsr = CHAFSR_INVALID;\r\nelse\r\np->afsr = CHAFSR_INVALID;\r\nis_memory = cheetah_check_main_memory(afar);\r\n{\r\nint flush_all, flush_line;\r\nflush_all = flush_line = 0;\r\nif ((afsr & CHAFSR_EDU) != 0UL) {\r\nif ((afsr & cheetah_afsr_errors) == CHAFSR_EDU)\r\nflush_line = 1;\r\nelse\r\nflush_all = 1;\r\n} else if ((afsr & CHAFSR_BERR) != 0UL) {\r\nif ((afsr & cheetah_afsr_errors) == CHAFSR_BERR)\r\nflush_line = 1;\r\nelse\r\nflush_all = 1;\r\n}\r\ncheetah_flush_icache();\r\ncheetah_flush_dcache();\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_DCU_CONTROL_REG),\r\n"i" (DCU_IC | DCU_DC)\r\n: "g1");\r\nif (flush_all)\r\ncheetah_flush_ecache();\r\nelse if (flush_line)\r\ncheetah_flush_ecache_line(afar);\r\n}\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_ESTATE_ERROR_EN),\r\n"i" (ESTATE_ERROR_NCEEN | ESTATE_ERROR_CEEN)\r\n: "g1");\r\nrecoverable = 1;\r\nif (afsr & (CHAFSR_PERR | CHAFSR_IERR | CHAFSR_ISAP))\r\nrecoverable = 0;\r\nif (cheetah_recheck_errors(&local_snapshot)) {\r\nunsigned long new_afsr = local_snapshot.afsr;\r\nif (new_afsr & (CHAFSR_EMU | CHAFSR_EDU |\r\nCHAFSR_WDU | CHAFSR_CPU |\r\nCHAFSR_IVU | CHAFSR_UE |\r\nCHAFSR_BERR | CHAFSR_TO))\r\nrecoverable = 0;\r\n}\r\ncheetah_log_errors(regs, &local_snapshot, afsr, afar, recoverable);\r\nif (recoverable && is_memory) {\r\nif ((regs->tstate & TSTATE_PRIV) == 0UL) {\r\nrecoverable = 1;\r\n} else {\r\nconst struct exception_table_entry *entry;\r\nentry = search_exception_tables(regs->tpc);\r\nif (entry) {\r\nrecoverable = 1;\r\n} else {\r\nrecoverable = 0;\r\n}\r\nif (recoverable) {\r\nif (pfn_valid(afar >> PAGE_SHIFT))\r\nget_page(pfn_to_page(afar >> PAGE_SHIFT));\r\nelse\r\nrecoverable = 0;\r\nif (recoverable) {\r\nregs->tpc = entry->fixup;\r\nregs->tnpc = regs->tpc + 4;\r\n}\r\n}\r\n}\r\n} else {\r\nrecoverable = 0;\r\n}\r\nif (!recoverable)\r\npanic("Irrecoverable deferred error trap.\n");\r\n}\r\nvoid cheetah_plus_parity_error(int type, struct pt_regs *regs)\r\n{\r\nif (type & 0x1)\r\n__cheetah_flush_icache();\r\nelse\r\ncheetah_plus_zap_dcache_parity();\r\ncheetah_flush_dcache();\r\n__asm__ __volatile__("ldxa [%%g0] %0, %%g1\n\t"\r\n"or %%g1, %1, %%g1\n\t"\r\n"stxa %%g1, [%%g0] %0\n\t"\r\n"membar #Sync"\r\n:\r\n: "i" (ASI_DCU_CONTROL_REG),\r\n"i" (DCU_DC | DCU_IC)\r\n: "g1");\r\nif (type & 0x2) {\r\nprintk(KERN_EMERG "CPU[%d]: Cheetah+ %c-cache parity error at TPC[%016lx]\n",\r\nsmp_processor_id(),\r\n(type & 0x1) ? 'I' : 'D',\r\nregs->tpc);\r\nprintk(KERN_EMERG "TPC<%pS>\n", (void *) regs->tpc);\r\npanic("Irrecoverable Cheetah+ parity error.");\r\n}\r\nprintk(KERN_WARNING "CPU[%d]: Cheetah+ %c-cache parity error at TPC[%016lx]\n",\r\nsmp_processor_id(),\r\n(type & 0x1) ? 'I' : 'D',\r\nregs->tpc);\r\nprintk(KERN_WARNING "TPC<%pS>\n", (void *) regs->tpc);\r\n}\r\nstatic const char *sun4v_err_type_to_str(u32 type)\r\n{\r\nswitch (type) {\r\ncase SUN4V_ERR_TYPE_UNDEFINED:\r\nreturn "undefined";\r\ncase SUN4V_ERR_TYPE_UNCORRECTED_RES:\r\nreturn "uncorrected resumable";\r\ncase SUN4V_ERR_TYPE_PRECISE_NONRES:\r\nreturn "precise nonresumable";\r\ncase SUN4V_ERR_TYPE_DEFERRED_NONRES:\r\nreturn "deferred nonresumable";\r\ncase SUN4V_ERR_TYPE_WARNING_RES:\r\nreturn "warning resumable";\r\ndefault:\r\nreturn "unknown";\r\n}\r\n}\r\nstatic void sun4v_log_error(struct pt_regs *regs, struct sun4v_error_entry *ent, int cpu, const char *pfx, atomic_t *ocnt)\r\n{\r\nint cnt;\r\nprintk("%s: Reporting on cpu %d\n", pfx, cpu);\r\nprintk("%s: err_handle[%llx] err_stick[%llx] err_type[%08x:%s]\n",\r\npfx,\r\nent->err_handle, ent->err_stick,\r\nent->err_type,\r\nsun4v_err_type_to_str(ent->err_type));\r\nprintk("%s: err_attrs[%08x:%s %s %s %s %s %s %s %s]\n",\r\npfx,\r\nent->err_attrs,\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_PROCESSOR) ?\r\n"processor" : ""),\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_MEMORY) ?\r\n"memory" : ""),\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_PIO) ?\r\n"pio" : ""),\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_INT_REGISTERS) ?\r\n"integer-regs" : ""),\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_FPU_REGISTERS) ?\r\n"fpu-regs" : ""),\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_USER_MODE) ?\r\n"user" : ""),\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_PRIV_MODE) ?\r\n"privileged" : ""),\r\n((ent->err_attrs & SUN4V_ERR_ATTRS_RES_QUEUE_FULL) ?\r\n"queue-full" : ""));\r\nprintk("%s: err_raddr[%016llx] err_size[%u] err_cpu[%u]\n",\r\npfx,\r\nent->err_raddr, ent->err_size, ent->err_cpu);\r\nshow_regs(regs);\r\nif ((cnt = atomic_read(ocnt)) != 0) {\r\natomic_set(ocnt, 0);\r\nwmb();\r\nprintk("%s: Queue overflowed %d times.\n",\r\npfx, cnt);\r\n}\r\n}\r\nvoid sun4v_resum_error(struct pt_regs *regs, unsigned long offset)\r\n{\r\nstruct sun4v_error_entry *ent, local_copy;\r\nstruct trap_per_cpu *tb;\r\nunsigned long paddr;\r\nint cpu;\r\ncpu = get_cpu();\r\ntb = &trap_block[cpu];\r\npaddr = tb->resum_kernel_buf_pa + offset;\r\nent = __va(paddr);\r\nmemcpy(&local_copy, ent, sizeof(struct sun4v_error_entry));\r\nent->err_handle = 0;\r\nwmb();\r\nput_cpu();\r\nif (ent->err_type == SUN4V_ERR_TYPE_WARNING_RES) {\r\nprintk(KERN_INFO "Power down request...\n");\r\nkill_cad_pid(SIGINT, 1);\r\nreturn;\r\n}\r\nsun4v_log_error(regs, &local_copy, cpu,\r\nKERN_ERR "RESUMABLE ERROR",\r\n&sun4v_resum_oflow_cnt);\r\n}\r\nvoid sun4v_resum_overflow(struct pt_regs *regs)\r\n{\r\natomic_inc(&sun4v_resum_oflow_cnt);\r\n}\r\nvoid sun4v_nonresum_error(struct pt_regs *regs, unsigned long offset)\r\n{\r\nstruct sun4v_error_entry *ent, local_copy;\r\nstruct trap_per_cpu *tb;\r\nunsigned long paddr;\r\nint cpu;\r\ncpu = get_cpu();\r\ntb = &trap_block[cpu];\r\npaddr = tb->nonresum_kernel_buf_pa + offset;\r\nent = __va(paddr);\r\nmemcpy(&local_copy, ent, sizeof(struct sun4v_error_entry));\r\nent->err_handle = 0;\r\nwmb();\r\nput_cpu();\r\n#ifdef CONFIG_PCI\r\nif (pci_poke_in_progress && pci_poke_cpu == cpu) {\r\npci_poke_faulted = 1;\r\nregs->tpc += 4;\r\nregs->tnpc = regs->tpc + 4;\r\nreturn;\r\n}\r\n#endif\r\nsun4v_log_error(regs, &local_copy, cpu,\r\nKERN_EMERG "NON-RESUMABLE ERROR",\r\n&sun4v_nonresum_oflow_cnt);\r\npanic("Non-resumable error.");\r\n}\r\nvoid sun4v_nonresum_overflow(struct pt_regs *regs)\r\n{\r\natomic_inc(&sun4v_nonresum_oflow_cnt);\r\n}\r\nvoid sun4v_itlb_error_report(struct pt_regs *regs, int tl)\r\n{\r\nif (tl > 1)\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\nprintk(KERN_EMERG "SUN4V-ITLB: Error at TPC[%lx], tl %d\n",\r\nregs->tpc, tl);\r\nprintk(KERN_EMERG "SUN4V-ITLB: TPC<%pS>\n", (void *) regs->tpc);\r\nprintk(KERN_EMERG "SUN4V-ITLB: O7[%lx]\n", regs->u_regs[UREG_I7]);\r\nprintk(KERN_EMERG "SUN4V-ITLB: O7<%pS>\n",\r\n(void *) regs->u_regs[UREG_I7]);\r\nprintk(KERN_EMERG "SUN4V-ITLB: vaddr[%lx] ctx[%lx] "\r\n"pte[%lx] error[%lx]\n",\r\nsun4v_err_itlb_vaddr, sun4v_err_itlb_ctx,\r\nsun4v_err_itlb_pte, sun4v_err_itlb_error);\r\nprom_halt();\r\n}\r\nvoid sun4v_dtlb_error_report(struct pt_regs *regs, int tl)\r\n{\r\nif (tl > 1)\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\nprintk(KERN_EMERG "SUN4V-DTLB: Error at TPC[%lx], tl %d\n",\r\nregs->tpc, tl);\r\nprintk(KERN_EMERG "SUN4V-DTLB: TPC<%pS>\n", (void *) regs->tpc);\r\nprintk(KERN_EMERG "SUN4V-DTLB: O7[%lx]\n", regs->u_regs[UREG_I7]);\r\nprintk(KERN_EMERG "SUN4V-DTLB: O7<%pS>\n",\r\n(void *) regs->u_regs[UREG_I7]);\r\nprintk(KERN_EMERG "SUN4V-DTLB: vaddr[%lx] ctx[%lx] "\r\n"pte[%lx] error[%lx]\n",\r\nsun4v_err_dtlb_vaddr, sun4v_err_dtlb_ctx,\r\nsun4v_err_dtlb_pte, sun4v_err_dtlb_error);\r\nprom_halt();\r\n}\r\nvoid hypervisor_tlbop_error(unsigned long err, unsigned long op)\r\n{\r\nprintk(KERN_CRIT "SUN4V: TLB hv call error %lu for op %lu\n",\r\nerr, op);\r\n}\r\nvoid hypervisor_tlbop_error_xcall(unsigned long err, unsigned long op)\r\n{\r\nprintk(KERN_CRIT "SUN4V: XCALL TLB hv call error %lu for op %lu\n",\r\nerr, op);\r\n}\r\nvoid do_fpe_common(struct pt_regs *regs)\r\n{\r\nif (regs->tstate & TSTATE_PRIV) {\r\nregs->tpc = regs->tnpc;\r\nregs->tnpc += 4;\r\n} else {\r\nunsigned long fsr = current_thread_info()->xfsr[0];\r\nsiginfo_t info;\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGFPE;\r\ninfo.si_errno = 0;\r\ninfo.si_addr = (void __user *)regs->tpc;\r\ninfo.si_trapno = 0;\r\ninfo.si_code = __SI_FAULT;\r\nif ((fsr & 0x1c000) == (1 << 14)) {\r\nif (fsr & 0x10)\r\ninfo.si_code = FPE_FLTINV;\r\nelse if (fsr & 0x08)\r\ninfo.si_code = FPE_FLTOVF;\r\nelse if (fsr & 0x04)\r\ninfo.si_code = FPE_FLTUND;\r\nelse if (fsr & 0x02)\r\ninfo.si_code = FPE_FLTDIV;\r\nelse if (fsr & 0x01)\r\ninfo.si_code = FPE_FLTRES;\r\n}\r\nforce_sig_info(SIGFPE, &info, current);\r\n}\r\n}\r\nvoid do_fpieee(struct pt_regs *regs)\r\n{\r\nif (notify_die(DIE_TRAP, "fpu exception ieee", regs,\r\n0, 0x24, SIGFPE) == NOTIFY_STOP)\r\nreturn;\r\ndo_fpe_common(regs);\r\n}\r\nvoid do_fpother(struct pt_regs *regs)\r\n{\r\nstruct fpustate *f = FPUSTATE;\r\nint ret = 0;\r\nif (notify_die(DIE_TRAP, "fpu exception other", regs,\r\n0, 0x25, SIGFPE) == NOTIFY_STOP)\r\nreturn;\r\nswitch ((current_thread_info()->xfsr[0] & 0x1c000)) {\r\ncase (2 << 14):\r\ncase (3 << 14):\r\nret = do_mathemu(regs, f, false);\r\nbreak;\r\n}\r\nif (ret)\r\nreturn;\r\ndo_fpe_common(regs);\r\n}\r\nvoid do_tof(struct pt_regs *regs)\r\n{\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "tagged arithmetic overflow", regs,\r\n0, 0x26, SIGEMT) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV)\r\ndie_if_kernel("Penguin overflow trap from kernel mode", regs);\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGEMT;\r\ninfo.si_errno = 0;\r\ninfo.si_code = EMT_TAGOVF;\r\ninfo.si_addr = (void __user *)regs->tpc;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGEMT, &info, current);\r\n}\r\nvoid do_div0(struct pt_regs *regs)\r\n{\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "integer division by zero", regs,\r\n0, 0x28, SIGFPE) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV)\r\ndie_if_kernel("TL0: Kernel divide by zero.", regs);\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGFPE;\r\ninfo.si_errno = 0;\r\ninfo.si_code = FPE_INTDIV;\r\ninfo.si_addr = (void __user *)regs->tpc;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGFPE, &info, current);\r\n}\r\nstatic void instruction_dump(unsigned int *pc)\r\n{\r\nint i;\r\nif ((((unsigned long) pc) & 3))\r\nreturn;\r\nprintk("Instruction DUMP:");\r\nfor (i = -3; i < 6; i++)\r\nprintk("%c%08x%c",i?' ':'<',pc[i],i?' ':'>');\r\nprintk("\n");\r\n}\r\nstatic void user_instruction_dump(unsigned int __user *pc)\r\n{\r\nint i;\r\nunsigned int buf[9];\r\nif ((((unsigned long) pc) & 3))\r\nreturn;\r\nif (copy_from_user(buf, pc - 3, sizeof(buf)))\r\nreturn;\r\nprintk("Instruction DUMP:");\r\nfor (i = 0; i < 9; i++)\r\nprintk("%c%08x%c",i==3?' ':'<',buf[i],i==3?' ':'>');\r\nprintk("\n");\r\n}\r\nvoid show_stack(struct task_struct *tsk, unsigned long *_ksp)\r\n{\r\nunsigned long fp, ksp;\r\nstruct thread_info *tp;\r\nint count = 0;\r\n#ifdef CONFIG_FUNCTION_GRAPH_TRACER\r\nint graph = 0;\r\n#endif\r\nksp = (unsigned long) _ksp;\r\nif (!tsk)\r\ntsk = current;\r\ntp = task_thread_info(tsk);\r\nif (ksp == 0UL) {\r\nif (tsk == current)\r\nasm("mov %%fp, %0" : "=r" (ksp));\r\nelse\r\nksp = tp->ksp;\r\n}\r\nif (tp == current_thread_info())\r\nflushw_all();\r\nfp = ksp + STACK_BIAS;\r\nprintk("Call Trace:\n");\r\ndo {\r\nstruct sparc_stackf *sf;\r\nstruct pt_regs *regs;\r\nunsigned long pc;\r\nif (!kstack_valid(tp, fp))\r\nbreak;\r\nsf = (struct sparc_stackf *) fp;\r\nregs = (struct pt_regs *) (sf + 1);\r\nif (kstack_is_trap_frame(tp, regs)) {\r\nif (!(regs->tstate & TSTATE_PRIV))\r\nbreak;\r\npc = regs->tpc;\r\nfp = regs->u_regs[UREG_I6] + STACK_BIAS;\r\n} else {\r\npc = sf->callers_pc;\r\nfp = (unsigned long)sf->fp + STACK_BIAS;\r\n}\r\nprintk(" [%016lx] %pS\n", pc, (void *) pc);\r\n#ifdef CONFIG_FUNCTION_GRAPH_TRACER\r\nif ((pc + 8UL) == (unsigned long) &return_to_handler) {\r\nint index = tsk->curr_ret_stack;\r\nif (tsk->ret_stack && index >= graph) {\r\npc = tsk->ret_stack[index - graph].ret;\r\nprintk(" [%016lx] %pS\n", pc, (void *) pc);\r\ngraph++;\r\n}\r\n}\r\n#endif\r\n} while (++count < 16);\r\n}\r\nvoid dump_stack(void)\r\n{\r\nshow_stack(current, NULL);\r\n}\r\nstatic inline struct reg_window *kernel_stack_up(struct reg_window *rw)\r\n{\r\nunsigned long fp = rw->ins[6];\r\nif (!fp)\r\nreturn NULL;\r\nreturn (struct reg_window *) (fp + STACK_BIAS);\r\n}\r\nvoid die_if_kernel(char *str, struct pt_regs *regs)\r\n{\r\nstatic int die_counter;\r\nint count = 0;\r\nprintk(\r\n" \\|/ ____ \\|/\n"\r\n" \"@'/ .. \\`@\"\n"\r\n" /_| \\__/ |_\\\n"\r\n" \\__U_/\n");\r\nprintk("%s(%d): %s [#%d]\n", current->comm, task_pid_nr(current), str, ++die_counter);\r\nnotify_die(DIE_OOPS, str, regs, 0, 255, SIGSEGV);\r\n__asm__ __volatile__("flushw");\r\nshow_regs(regs);\r\nadd_taint(TAINT_DIE);\r\nif (regs->tstate & TSTATE_PRIV) {\r\nstruct thread_info *tp = current_thread_info();\r\nstruct reg_window *rw = (struct reg_window *)\r\n(regs->u_regs[UREG_FP] + STACK_BIAS);\r\nwhile (rw &&\r\ncount++ < 30 &&\r\nkstack_valid(tp, (unsigned long) rw)) {\r\nprintk("Caller[%016lx]: %pS\n", rw->ins[7],\r\n(void *) rw->ins[7]);\r\nrw = kernel_stack_up(rw);\r\n}\r\ninstruction_dump ((unsigned int *) regs->tpc);\r\n} else {\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\nuser_instruction_dump ((unsigned int __user *) regs->tpc);\r\n}\r\nif (regs->tstate & TSTATE_PRIV)\r\ndo_exit(SIGKILL);\r\ndo_exit(SIGSEGV);\r\n}\r\nvoid do_illegal_instruction(struct pt_regs *regs)\r\n{\r\nunsigned long pc = regs->tpc;\r\nunsigned long tstate = regs->tstate;\r\nu32 insn;\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "illegal instruction", regs,\r\n0, 0x10, SIGILL) == NOTIFY_STOP)\r\nreturn;\r\nif (tstate & TSTATE_PRIV)\r\ndie_if_kernel("Kernel illegal instruction", regs);\r\nif (test_thread_flag(TIF_32BIT))\r\npc = (u32)pc;\r\nif (get_user(insn, (u32 __user *) pc) != -EFAULT) {\r\nif ((insn & 0xc1ffc000) == 0x81700000) {\r\nif (handle_popc(insn, regs))\r\nreturn;\r\n} else if ((insn & 0xc1580000) == 0xc1100000) {\r\nif (handle_ldf_stq(insn, regs))\r\nreturn;\r\n} else if (tlb_type == hypervisor) {\r\nif ((insn & VIS_OPCODE_MASK) == VIS_OPCODE_VAL) {\r\nif (!vis_emul(regs, insn))\r\nreturn;\r\n} else {\r\nstruct fpustate *f = FPUSTATE;\r\nif (do_mathemu(regs, f, true))\r\nreturn;\r\n}\r\n}\r\n}\r\ninfo.si_signo = SIGILL;\r\ninfo.si_errno = 0;\r\ninfo.si_code = ILL_ILLOPC;\r\ninfo.si_addr = (void __user *)pc;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGILL, &info, current);\r\n}\r\nvoid mem_address_unaligned(struct pt_regs *regs, unsigned long sfar, unsigned long sfsr)\r\n{\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "memory address unaligned", regs,\r\n0, 0x34, SIGSEGV) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV) {\r\nkernel_unaligned_trap(regs, *((unsigned int *)regs->tpc));\r\nreturn;\r\n}\r\ninfo.si_signo = SIGBUS;\r\ninfo.si_errno = 0;\r\ninfo.si_code = BUS_ADRALN;\r\ninfo.si_addr = (void __user *)sfar;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGBUS, &info, current);\r\n}\r\nvoid sun4v_do_mna(struct pt_regs *regs, unsigned long addr, unsigned long type_ctx)\r\n{\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "memory address unaligned", regs,\r\n0, 0x34, SIGSEGV) == NOTIFY_STOP)\r\nreturn;\r\nif (regs->tstate & TSTATE_PRIV) {\r\nkernel_unaligned_trap(regs, *((unsigned int *)regs->tpc));\r\nreturn;\r\n}\r\ninfo.si_signo = SIGBUS;\r\ninfo.si_errno = 0;\r\ninfo.si_code = BUS_ADRALN;\r\ninfo.si_addr = (void __user *) addr;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGBUS, &info, current);\r\n}\r\nvoid do_privop(struct pt_regs *regs)\r\n{\r\nsiginfo_t info;\r\nif (notify_die(DIE_TRAP, "privileged operation", regs,\r\n0, 0x11, SIGILL) == NOTIFY_STOP)\r\nreturn;\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\ninfo.si_signo = SIGILL;\r\ninfo.si_errno = 0;\r\ninfo.si_code = ILL_PRVOPC;\r\ninfo.si_addr = (void __user *)regs->tpc;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGILL, &info, current);\r\n}\r\nvoid do_privact(struct pt_regs *regs)\r\n{\r\ndo_privop(regs);\r\n}\r\nvoid do_cee(struct pt_regs *regs)\r\n{\r\ndie_if_kernel("TL0: Cache Error Exception", regs);\r\n}\r\nvoid do_cee_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: Cache Error Exception", regs);\r\n}\r\nvoid do_dae_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: Data Access Exception", regs);\r\n}\r\nvoid do_iae_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: Instruction Access Exception", regs);\r\n}\r\nvoid do_div0_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: DIV0 Exception", regs);\r\n}\r\nvoid do_fpdis_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: FPU Disabled", regs);\r\n}\r\nvoid do_fpieee_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: FPU IEEE Exception", regs);\r\n}\r\nvoid do_fpother_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: FPU Other Exception", regs);\r\n}\r\nvoid do_ill_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: Illegal Instruction Exception", regs);\r\n}\r\nvoid do_irq_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: IRQ Exception", regs);\r\n}\r\nvoid do_lddfmna_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: LDDF Exception", regs);\r\n}\r\nvoid do_stdfmna_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: STDF Exception", regs);\r\n}\r\nvoid do_paw(struct pt_regs *regs)\r\n{\r\ndie_if_kernel("TL0: Phys Watchpoint Exception", regs);\r\n}\r\nvoid do_paw_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: Phys Watchpoint Exception", regs);\r\n}\r\nvoid do_vaw(struct pt_regs *regs)\r\n{\r\ndie_if_kernel("TL0: Virt Watchpoint Exception", regs);\r\n}\r\nvoid do_vaw_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: Virt Watchpoint Exception", regs);\r\n}\r\nvoid do_tof_tl1(struct pt_regs *regs)\r\n{\r\ndump_tl1_traplog((struct tl1_traplog *)(regs + 1));\r\ndie_if_kernel("TL1: Tag Overflow Exception", regs);\r\n}\r\nvoid do_getpsr(struct pt_regs *regs)\r\n{\r\nregs->u_regs[UREG_I0] = tstate_to_psr(regs->tstate);\r\nregs->tpc = regs->tnpc;\r\nregs->tnpc += 4;\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\n}\r\nvoid notrace init_cur_cpu_trap(struct thread_info *t)\r\n{\r\nint cpu = hard_smp_processor_id();\r\nstruct trap_per_cpu *p = &trap_block[cpu];\r\np->thread = t;\r\np->pgd_paddr = 0;\r\n}\r\nvoid __init trap_init(void)\r\n{\r\nBUILD_BUG_ON(TI_TASK != offsetof(struct thread_info, task) ||\r\nTI_FLAGS != offsetof(struct thread_info, flags) ||\r\nTI_CPU != offsetof(struct thread_info, cpu) ||\r\nTI_FPSAVED != offsetof(struct thread_info, fpsaved) ||\r\nTI_KSP != offsetof(struct thread_info, ksp) ||\r\nTI_FAULT_ADDR != offsetof(struct thread_info,\r\nfault_address) ||\r\nTI_KREGS != offsetof(struct thread_info, kregs) ||\r\nTI_UTRAPS != offsetof(struct thread_info, utraps) ||\r\nTI_EXEC_DOMAIN != offsetof(struct thread_info,\r\nexec_domain) ||\r\nTI_REG_WINDOW != offsetof(struct thread_info,\r\nreg_window) ||\r\nTI_RWIN_SPTRS != offsetof(struct thread_info,\r\nrwbuf_stkptrs) ||\r\nTI_GSR != offsetof(struct thread_info, gsr) ||\r\nTI_XFSR != offsetof(struct thread_info, xfsr) ||\r\nTI_PRE_COUNT != offsetof(struct thread_info,\r\npreempt_count) ||\r\nTI_NEW_CHILD != offsetof(struct thread_info, new_child) ||\r\nTI_SYS_NOERROR != offsetof(struct thread_info,\r\nsyscall_noerror) ||\r\nTI_RESTART_BLOCK != offsetof(struct thread_info,\r\nrestart_block) ||\r\nTI_KUNA_REGS != offsetof(struct thread_info,\r\nkern_una_regs) ||\r\nTI_KUNA_INSN != offsetof(struct thread_info,\r\nkern_una_insn) ||\r\nTI_FPREGS != offsetof(struct thread_info, fpregs) ||\r\n(TI_FPREGS & (64 - 1)));\r\nBUILD_BUG_ON(TRAP_PER_CPU_THREAD != offsetof(struct trap_per_cpu,\r\nthread) ||\r\n(TRAP_PER_CPU_PGD_PADDR !=\r\noffsetof(struct trap_per_cpu, pgd_paddr)) ||\r\n(TRAP_PER_CPU_CPU_MONDO_PA !=\r\noffsetof(struct trap_per_cpu, cpu_mondo_pa)) ||\r\n(TRAP_PER_CPU_DEV_MONDO_PA !=\r\noffsetof(struct trap_per_cpu, dev_mondo_pa)) ||\r\n(TRAP_PER_CPU_RESUM_MONDO_PA !=\r\noffsetof(struct trap_per_cpu, resum_mondo_pa)) ||\r\n(TRAP_PER_CPU_RESUM_KBUF_PA !=\r\noffsetof(struct trap_per_cpu, resum_kernel_buf_pa)) ||\r\n(TRAP_PER_CPU_NONRESUM_MONDO_PA !=\r\noffsetof(struct trap_per_cpu, nonresum_mondo_pa)) ||\r\n(TRAP_PER_CPU_NONRESUM_KBUF_PA !=\r\noffsetof(struct trap_per_cpu, nonresum_kernel_buf_pa)) ||\r\n(TRAP_PER_CPU_FAULT_INFO !=\r\noffsetof(struct trap_per_cpu, fault_info)) ||\r\n(TRAP_PER_CPU_CPU_MONDO_BLOCK_PA !=\r\noffsetof(struct trap_per_cpu, cpu_mondo_block_pa)) ||\r\n(TRAP_PER_CPU_CPU_LIST_PA !=\r\noffsetof(struct trap_per_cpu, cpu_list_pa)) ||\r\n(TRAP_PER_CPU_TSB_HUGE !=\r\noffsetof(struct trap_per_cpu, tsb_huge)) ||\r\n(TRAP_PER_CPU_TSB_HUGE_TEMP !=\r\noffsetof(struct trap_per_cpu, tsb_huge_temp)) ||\r\n(TRAP_PER_CPU_IRQ_WORKLIST_PA !=\r\noffsetof(struct trap_per_cpu, irq_worklist_pa)) ||\r\n(TRAP_PER_CPU_CPU_MONDO_QMASK !=\r\noffsetof(struct trap_per_cpu, cpu_mondo_qmask)) ||\r\n(TRAP_PER_CPU_DEV_MONDO_QMASK !=\r\noffsetof(struct trap_per_cpu, dev_mondo_qmask)) ||\r\n(TRAP_PER_CPU_RESUM_QMASK !=\r\noffsetof(struct trap_per_cpu, resum_qmask)) ||\r\n(TRAP_PER_CPU_NONRESUM_QMASK !=\r\noffsetof(struct trap_per_cpu, nonresum_qmask)) ||\r\n(TRAP_PER_CPU_PER_CPU_BASE !=\r\noffsetof(struct trap_per_cpu, __per_cpu_base)));\r\nBUILD_BUG_ON((TSB_CONFIG_TSB !=\r\noffsetof(struct tsb_config, tsb)) ||\r\n(TSB_CONFIG_RSS_LIMIT !=\r\noffsetof(struct tsb_config, tsb_rss_limit)) ||\r\n(TSB_CONFIG_NENTRIES !=\r\noffsetof(struct tsb_config, tsb_nentries)) ||\r\n(TSB_CONFIG_REG_VAL !=\r\noffsetof(struct tsb_config, tsb_reg_val)) ||\r\n(TSB_CONFIG_MAP_VADDR !=\r\noffsetof(struct tsb_config, tsb_map_vaddr)) ||\r\n(TSB_CONFIG_MAP_PTE !=\r\noffsetof(struct tsb_config, tsb_map_pte)));\r\natomic_inc(&init_mm.mm_count);\r\ncurrent->active_mm = &init_mm;\r\n}
