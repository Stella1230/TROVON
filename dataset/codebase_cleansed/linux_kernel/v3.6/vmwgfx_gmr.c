static int vmw_gmr2_bind(struct vmw_private *dev_priv,\r\nstruct page *pages[],\r\nunsigned long num_pages,\r\nint gmr_id)\r\n{\r\nSVGAFifoCmdDefineGMR2 define_cmd;\r\nSVGAFifoCmdRemapGMR2 remap_cmd;\r\nuint32_t define_size = sizeof(define_cmd) + 4;\r\nuint32_t remap_size = VMW_PPN_SIZE * num_pages + sizeof(remap_cmd) + 4;\r\nuint32_t *cmd;\r\nuint32_t *cmd_orig;\r\nuint32_t i;\r\ncmd_orig = cmd = vmw_fifo_reserve(dev_priv, define_size + remap_size);\r\nif (unlikely(cmd == NULL))\r\nreturn -ENOMEM;\r\ndefine_cmd.gmrId = gmr_id;\r\ndefine_cmd.numPages = num_pages;\r\nremap_cmd.gmrId = gmr_id;\r\nremap_cmd.flags = (VMW_PPN_SIZE > sizeof(*cmd)) ?\r\nSVGA_REMAP_GMR2_PPN64 : SVGA_REMAP_GMR2_PPN32;\r\nremap_cmd.offsetPages = 0;\r\nremap_cmd.numPages = num_pages;\r\n*cmd++ = SVGA_CMD_DEFINE_GMR2;\r\nmemcpy(cmd, &define_cmd, sizeof(define_cmd));\r\ncmd += sizeof(define_cmd) / sizeof(uint32);\r\n*cmd++ = SVGA_CMD_REMAP_GMR2;\r\nmemcpy(cmd, &remap_cmd, sizeof(remap_cmd));\r\ncmd += sizeof(remap_cmd) / sizeof(uint32);\r\nfor (i = 0; i < num_pages; ++i) {\r\nif (VMW_PPN_SIZE <= 4)\r\n*cmd = page_to_pfn(*pages++);\r\nelse\r\n*((uint64_t *)cmd) = page_to_pfn(*pages++);\r\ncmd += VMW_PPN_SIZE / sizeof(*cmd);\r\n}\r\nvmw_fifo_commit(dev_priv, define_size + remap_size);\r\nreturn 0;\r\n}\r\nstatic void vmw_gmr2_unbind(struct vmw_private *dev_priv,\r\nint gmr_id)\r\n{\r\nSVGAFifoCmdDefineGMR2 define_cmd;\r\nuint32_t define_size = sizeof(define_cmd) + 4;\r\nuint32_t *cmd;\r\ncmd = vmw_fifo_reserve(dev_priv, define_size);\r\nif (unlikely(cmd == NULL)) {\r\nDRM_ERROR("GMR2 unbind failed.\n");\r\nreturn;\r\n}\r\ndefine_cmd.gmrId = gmr_id;\r\ndefine_cmd.numPages = 0;\r\n*cmd++ = SVGA_CMD_DEFINE_GMR2;\r\nmemcpy(cmd, &define_cmd, sizeof(define_cmd));\r\nvmw_fifo_commit(dev_priv, define_size);\r\n}\r\nstatic int vmw_gmr_build_descriptors(struct list_head *desc_pages,\r\nstruct page *pages[],\r\nunsigned long num_pages)\r\n{\r\nstruct page *page, *next;\r\nstruct svga_guest_mem_descriptor *page_virtual = NULL;\r\nstruct svga_guest_mem_descriptor *desc_virtual = NULL;\r\nunsigned int desc_per_page;\r\nunsigned long prev_pfn;\r\nunsigned long pfn;\r\nint ret;\r\ndesc_per_page = PAGE_SIZE /\r\nsizeof(struct svga_guest_mem_descriptor) - 1;\r\nwhile (likely(num_pages != 0)) {\r\npage = alloc_page(__GFP_HIGHMEM);\r\nif (unlikely(page == NULL)) {\r\nret = -ENOMEM;\r\ngoto out_err;\r\n}\r\nlist_add_tail(&page->lru, desc_pages);\r\nif (likely(page_virtual != NULL)) {\r\ndesc_virtual->ppn = page_to_pfn(page);\r\nkunmap_atomic(page_virtual);\r\n}\r\npage_virtual = kmap_atomic(page);\r\ndesc_virtual = page_virtual - 1;\r\nprev_pfn = ~(0UL);\r\nwhile (likely(num_pages != 0)) {\r\npfn = page_to_pfn(*pages);\r\nif (pfn != prev_pfn + 1) {\r\nif (desc_virtual - page_virtual ==\r\ndesc_per_page - 1)\r\nbreak;\r\n(++desc_virtual)->ppn = cpu_to_le32(pfn);\r\ndesc_virtual->num_pages = cpu_to_le32(1);\r\n} else {\r\nuint32_t tmp =\r\nle32_to_cpu(desc_virtual->num_pages);\r\ndesc_virtual->num_pages = cpu_to_le32(tmp + 1);\r\n}\r\nprev_pfn = pfn;\r\n--num_pages;\r\n++pages;\r\n}\r\n(++desc_virtual)->ppn = cpu_to_le32(0);\r\ndesc_virtual->num_pages = cpu_to_le32(0);\r\n}\r\nif (likely(page_virtual != NULL))\r\nkunmap_atomic(page_virtual);\r\nreturn 0;\r\nout_err:\r\nlist_for_each_entry_safe(page, next, desc_pages, lru) {\r\nlist_del_init(&page->lru);\r\n__free_page(page);\r\n}\r\nreturn ret;\r\n}\r\nstatic inline void vmw_gmr_free_descriptors(struct list_head *desc_pages)\r\n{\r\nstruct page *page, *next;\r\nlist_for_each_entry_safe(page, next, desc_pages, lru) {\r\nlist_del_init(&page->lru);\r\n__free_page(page);\r\n}\r\n}\r\nstatic void vmw_gmr_fire_descriptors(struct vmw_private *dev_priv,\r\nint gmr_id, struct list_head *desc_pages)\r\n{\r\nstruct page *page;\r\nif (unlikely(list_empty(desc_pages)))\r\nreturn;\r\npage = list_entry(desc_pages->next, struct page, lru);\r\nmutex_lock(&dev_priv->hw_mutex);\r\nvmw_write(dev_priv, SVGA_REG_GMR_ID, gmr_id);\r\nwmb();\r\nvmw_write(dev_priv, SVGA_REG_GMR_DESCRIPTOR, page_to_pfn(page));\r\nmb();\r\nmutex_unlock(&dev_priv->hw_mutex);\r\n}\r\nstatic unsigned long vmw_gmr_count_descriptors(struct page *pages[],\r\nunsigned long num_pages)\r\n{\r\nunsigned long prev_pfn = ~(0UL);\r\nunsigned long pfn;\r\nunsigned long descriptors = 0;\r\nwhile (num_pages--) {\r\npfn = page_to_pfn(*pages++);\r\nif (prev_pfn + 1 != pfn)\r\n++descriptors;\r\nprev_pfn = pfn;\r\n}\r\nreturn descriptors;\r\n}\r\nint vmw_gmr_bind(struct vmw_private *dev_priv,\r\nstruct page *pages[],\r\nunsigned long num_pages,\r\nint gmr_id)\r\n{\r\nstruct list_head desc_pages;\r\nint ret;\r\nif (likely(dev_priv->capabilities & SVGA_CAP_GMR2))\r\nreturn vmw_gmr2_bind(dev_priv, pages, num_pages, gmr_id);\r\nif (unlikely(!(dev_priv->capabilities & SVGA_CAP_GMR)))\r\nreturn -EINVAL;\r\nif (vmw_gmr_count_descriptors(pages, num_pages) >\r\ndev_priv->max_gmr_descriptors)\r\nreturn -EINVAL;\r\nINIT_LIST_HEAD(&desc_pages);\r\nret = vmw_gmr_build_descriptors(&desc_pages, pages, num_pages);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_gmr_fire_descriptors(dev_priv, gmr_id, &desc_pages);\r\nvmw_gmr_free_descriptors(&desc_pages);\r\nreturn 0;\r\n}\r\nvoid vmw_gmr_unbind(struct vmw_private *dev_priv, int gmr_id)\r\n{\r\nif (likely(dev_priv->capabilities & SVGA_CAP_GMR2)) {\r\nvmw_gmr2_unbind(dev_priv, gmr_id);\r\nreturn;\r\n}\r\nmutex_lock(&dev_priv->hw_mutex);\r\nvmw_write(dev_priv, SVGA_REG_GMR_ID, gmr_id);\r\nwmb();\r\nvmw_write(dev_priv, SVGA_REG_GMR_DESCRIPTOR, 0);\r\nmb();\r\nmutex_unlock(&dev_priv->hw_mutex);\r\n}
