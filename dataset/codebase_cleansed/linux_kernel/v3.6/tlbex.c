static inline int r45k_bvahwbug(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic inline int r4k_250MHZhwbug(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic inline int __maybe_unused bcm1250_m3_war(void)\r\n{\r\nreturn BCM1250_M3_WAR;\r\n}\r\nstatic inline int __maybe_unused r10000_llsc_war(void)\r\n{\r\nreturn R10000_LLSC_WAR;\r\n}\r\nstatic int use_bbit_insns(void)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_CAVIUM_OCTEON:\r\ncase CPU_CAVIUM_OCTEON_PLUS:\r\ncase CPU_CAVIUM_OCTEON2:\r\nreturn 1;\r\ndefault:\r\nreturn 0;\r\n}\r\n}\r\nstatic int use_lwx_insns(void)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_CAVIUM_OCTEON2:\r\nreturn 1;\r\ndefault:\r\nreturn 0;\r\n}\r\n}\r\nstatic bool scratchpad_available(void)\r\n{\r\nreturn true;\r\n}\r\nstatic int scratchpad_offset(int i)\r\n{\r\ni += 1;\r\nreturn CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE * 128 - (8 * i) - 32768;\r\n}\r\nstatic bool scratchpad_available(void)\r\n{\r\nreturn false;\r\n}\r\nstatic int scratchpad_offset(int i)\r\n{\r\nBUG();\r\nreturn 0;\r\n}\r\nstatic int __cpuinit m4kc_tlbp_war(void)\r\n{\r\nreturn (current_cpu_data.processor_id & 0xffff00) ==\r\n(PRID_COMP_MIPS | PRID_IMP_4KC);\r\n}\r\nstatic inline void dump_handler(const u32 *handler, int count)\r\n{\r\nint i;\r\npr_debug("\t.set push\n");\r\npr_debug("\t.set noreorder\n");\r\nfor (i = 0; i < count; i++)\r\npr_debug("\t%p\t.word 0x%08x\n", &handler[i], handler[i]);\r\npr_debug("\t.set pop\n");\r\n}\r\nstatic int __cpuinit allocate_kscratch(void)\r\n{\r\nint r;\r\nunsigned int a = cpu_data[0].kscratch_mask & ~kscratch_used_mask;\r\nr = ffs(a);\r\nif (r == 0)\r\nreturn -1;\r\nr--;\r\nkscratch_used_mask |= (1 << r);\r\nreturn r;\r\n}\r\nstatic struct work_registers __cpuinit build_get_work_registers(u32 **p)\r\n{\r\nstruct work_registers r;\r\nint smp_processor_id_reg;\r\nint smp_processor_id_sel;\r\nint smp_processor_id_shift;\r\nif (scratch_reg > 0) {\r\nUASM_i_MTC0(p, 1, 31, scratch_reg);\r\nr.r1 = K0;\r\nr.r2 = K1;\r\nr.r3 = 1;\r\nreturn r;\r\n}\r\nif (num_possible_cpus() > 1) {\r\n#ifdef CONFIG_MIPS_PGD_C0_CONTEXT\r\nsmp_processor_id_shift = 51;\r\nsmp_processor_id_reg = 20;\r\nsmp_processor_id_sel = 0;\r\n#else\r\n# ifdef CONFIG_32BIT\r\nsmp_processor_id_shift = 25;\r\nsmp_processor_id_reg = 4;\r\nsmp_processor_id_sel = 0;\r\n# endif\r\n# ifdef CONFIG_64BIT\r\nsmp_processor_id_shift = 26;\r\nsmp_processor_id_reg = 4;\r\nsmp_processor_id_sel = 0;\r\n# endif\r\n#endif\r\nUASM_i_MFC0(p, K0, smp_processor_id_reg, smp_processor_id_sel);\r\nUASM_i_SRL_SAFE(p, K0, K0, smp_processor_id_shift);\r\nUASM_i_SLL(p, K0, K0, ilog2(sizeof(struct tlb_reg_save)));\r\nUASM_i_LA(p, K1, (long)&handler_reg_save);\r\nUASM_i_ADDU(p, K0, K0, K1);\r\n} else {\r\nUASM_i_LA(p, K0, (long)&handler_reg_save);\r\n}\r\nUASM_i_SW(p, 1, offsetof(struct tlb_reg_save, a), K0);\r\nUASM_i_SW(p, 2, offsetof(struct tlb_reg_save, b), K0);\r\nr.r1 = K1;\r\nr.r2 = 1;\r\nr.r3 = 2;\r\nreturn r;\r\n}\r\nstatic void __cpuinit build_restore_work_registers(u32 **p)\r\n{\r\nif (scratch_reg > 0) {\r\nUASM_i_MFC0(p, 1, 31, scratch_reg);\r\nreturn;\r\n}\r\nUASM_i_LW(p, 1, offsetof(struct tlb_reg_save, a), K0);\r\nUASM_i_LW(p, 2, offsetof(struct tlb_reg_save, b), K0);\r\n}\r\nstatic void __cpuinit build_r3000_tlb_refill_handler(void)\r\n{\r\nlong pgdc = (long)pgd_current;\r\nu32 *p;\r\nmemset(tlb_handler, 0, sizeof(tlb_handler));\r\np = tlb_handler;\r\nuasm_i_mfc0(&p, K0, C0_BADVADDR);\r\nuasm_i_lui(&p, K1, uasm_rel_hi(pgdc));\r\nuasm_i_lw(&p, K1, uasm_rel_lo(pgdc), K1);\r\nuasm_i_srl(&p, K0, K0, 22);\r\nuasm_i_sll(&p, K0, K0, 2);\r\nuasm_i_addu(&p, K1, K1, K0);\r\nuasm_i_mfc0(&p, K0, C0_CONTEXT);\r\nuasm_i_lw(&p, K1, 0, K1);\r\nuasm_i_andi(&p, K0, K0, 0xffc);\r\nuasm_i_addu(&p, K1, K1, K0);\r\nuasm_i_lw(&p, K0, 0, K1);\r\nuasm_i_nop(&p);\r\nuasm_i_mtc0(&p, K0, C0_ENTRYLO0);\r\nuasm_i_mfc0(&p, K1, C0_EPC);\r\nuasm_i_tlbwr(&p);\r\nuasm_i_jr(&p, K1);\r\nuasm_i_rfe(&p);\r\nif (p > tlb_handler + 32)\r\npanic("TLB refill handler space exceeded");\r\npr_debug("Wrote TLB refill handler (%u instructions).\n",\r\n(unsigned int)(p - tlb_handler));\r\nmemcpy((void *)ebase, tlb_handler, 0x80);\r\ndump_handler((u32 *)ebase, 32);\r\n}\r\nstatic void __cpuinit __maybe_unused build_tlb_probe_entry(u32 **p)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_R4600:\r\ncase CPU_R4700:\r\ncase CPU_R5000:\r\ncase CPU_R5000A:\r\ncase CPU_NEVADA:\r\nuasm_i_nop(p);\r\nuasm_i_tlbp(p);\r\nbreak;\r\ndefault:\r\nuasm_i_tlbp(p);\r\nbreak;\r\n}\r\n}\r\nstatic void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r,\r\nenum tlb_write_entry wmode)\r\n{\r\nvoid(*tlbw)(u32 **) = NULL;\r\nswitch (wmode) {\r\ncase tlb_random: tlbw = uasm_i_tlbwr; break;\r\ncase tlb_indexed: tlbw = uasm_i_tlbwi; break;\r\n}\r\nif (cpu_has_mips_r2) {\r\nif (cpu_has_mips_r2_exec_hazard)\r\nuasm_i_ehb(p);\r\ntlbw(p);\r\nreturn;\r\n}\r\nswitch (current_cpu_type()) {\r\ncase CPU_R4000PC:\r\ncase CPU_R4000SC:\r\ncase CPU_R4000MC:\r\ncase CPU_R4400PC:\r\ncase CPU_R4400SC:\r\ncase CPU_R4400MC:\r\nuasm_il_bgezl(p, r, 0, label_tlbw_hazard);\r\ntlbw(p);\r\nuasm_l_tlbw_hazard(l, *p);\r\nuasm_i_nop(p);\r\nbreak;\r\ncase CPU_R4600:\r\ncase CPU_R4700:\r\ncase CPU_R5000:\r\ncase CPU_R5000A:\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nuasm_i_nop(p);\r\nbreak;\r\ncase CPU_R4300:\r\ncase CPU_5KC:\r\ncase CPU_TX49XX:\r\ncase CPU_PR4450:\r\ncase CPU_XLR:\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nbreak;\r\ncase CPU_R10000:\r\ncase CPU_R12000:\r\ncase CPU_R14000:\r\ncase CPU_4KC:\r\ncase CPU_4KEC:\r\ncase CPU_M14KC:\r\ncase CPU_SB1:\r\ncase CPU_SB1A:\r\ncase CPU_4KSC:\r\ncase CPU_20KC:\r\ncase CPU_25KF:\r\ncase CPU_BMIPS32:\r\ncase CPU_BMIPS3300:\r\ncase CPU_BMIPS4350:\r\ncase CPU_BMIPS4380:\r\ncase CPU_BMIPS5000:\r\ncase CPU_LOONGSON2:\r\ncase CPU_R5500:\r\nif (m4kc_tlbp_war())\r\nuasm_i_nop(p);\r\ncase CPU_ALCHEMY:\r\ntlbw(p);\r\nbreak;\r\ncase CPU_NEVADA:\r\nuasm_i_nop(p);\r\nuasm_il_bgezl(p, r, 0, label_tlbw_hazard);\r\ntlbw(p);\r\nuasm_l_tlbw_hazard(l, *p);\r\nbreak;\r\ncase CPU_RM7000:\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nbreak;\r\ncase CPU_RM9000:\r\nuasm_i_ssnop(p);\r\nuasm_i_ssnop(p);\r\nuasm_i_ssnop(p);\r\nuasm_i_ssnop(p);\r\ntlbw(p);\r\nuasm_i_ssnop(p);\r\nuasm_i_ssnop(p);\r\nuasm_i_ssnop(p);\r\nuasm_i_ssnop(p);\r\nbreak;\r\ncase CPU_VR4111:\r\ncase CPU_VR4121:\r\ncase CPU_VR4122:\r\ncase CPU_VR4181:\r\ncase CPU_VR4181A:\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\nbreak;\r\ncase CPU_VR4131:\r\ncase CPU_VR4133:\r\ncase CPU_R5432:\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nbreak;\r\ncase CPU_JZRISC:\r\ntlbw(p);\r\nuasm_i_nop(p);\r\nbreak;\r\ndefault:\r\npanic("No TLB refill handler yet (CPU type: %d)",\r\ncurrent_cpu_data.cputype);\r\nbreak;\r\n}\r\n}\r\nstatic __cpuinit __maybe_unused void build_convert_pte_to_entrylo(u32 **p,\r\nunsigned int reg)\r\n{\r\nif (kernel_uses_smartmips_rixi) {\r\nUASM_i_SRL(p, reg, reg, ilog2(_PAGE_NO_EXEC));\r\nUASM_i_ROTR(p, reg, reg, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\n} else {\r\n#ifdef CONFIG_64BIT_PHYS_ADDR\r\nuasm_i_dsrl_safe(p, reg, reg, ilog2(_PAGE_GLOBAL));\r\n#else\r\nUASM_i_SRL(p, reg, reg, ilog2(_PAGE_GLOBAL));\r\n#endif\r\n}\r\n}\r\nstatic __cpuinit void build_restore_pagemask(u32 **p,\r\nstruct uasm_reloc **r,\r\nunsigned int tmp,\r\nenum label_id lid,\r\nint restore_scratch)\r\n{\r\nif (restore_scratch) {\r\nif (PM_DEFAULT_MASK >> 16) {\r\nuasm_i_lui(p, tmp, PM_DEFAULT_MASK >> 16);\r\nuasm_i_ori(p, tmp, tmp, PM_DEFAULT_MASK & 0xffff);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\nuasm_il_b(p, r, lid);\r\n} else if (PM_DEFAULT_MASK) {\r\nuasm_i_ori(p, tmp, 0, PM_DEFAULT_MASK);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\nuasm_il_b(p, r, lid);\r\n} else {\r\nuasm_i_mtc0(p, 0, C0_PAGEMASK);\r\nuasm_il_b(p, r, lid);\r\n}\r\nif (scratch_reg > 0)\r\nUASM_i_MFC0(p, 1, 31, scratch_reg);\r\nelse\r\nUASM_i_LW(p, 1, scratchpad_offset(0), 0);\r\n} else {\r\nif (PM_DEFAULT_MASK >> 16) {\r\nuasm_i_lui(p, tmp, PM_DEFAULT_MASK >> 16);\r\nuasm_i_ori(p, tmp, tmp, PM_DEFAULT_MASK & 0xffff);\r\nuasm_il_b(p, r, lid);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\n} else if (PM_DEFAULT_MASK) {\r\nuasm_i_ori(p, tmp, 0, PM_DEFAULT_MASK);\r\nuasm_il_b(p, r, lid);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\n} else {\r\nuasm_il_b(p, r, lid);\r\nuasm_i_mtc0(p, 0, C0_PAGEMASK);\r\n}\r\n}\r\n}\r\nstatic __cpuinit void build_huge_tlb_write_entry(u32 **p,\r\nstruct uasm_label **l,\r\nstruct uasm_reloc **r,\r\nunsigned int tmp,\r\nenum tlb_write_entry wmode,\r\nint restore_scratch)\r\n{\r\nuasm_i_lui(p, tmp, PM_HUGE_MASK >> 16);\r\nuasm_i_ori(p, tmp, tmp, PM_HUGE_MASK & 0xffff);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\nbuild_tlb_write_entry(p, l, r, wmode);\r\nbuild_restore_pagemask(p, r, tmp, label_leave, restore_scratch);\r\n}\r\nstatic void __cpuinit\r\nbuild_is_huge_pte(u32 **p, struct uasm_reloc **r, unsigned int tmp,\r\nunsigned int pmd, int lid)\r\n{\r\nUASM_i_LW(p, tmp, 0, pmd);\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit1(p, r, tmp, ilog2(_PAGE_HUGE), lid);\r\n} else {\r\nuasm_i_andi(p, tmp, tmp, _PAGE_HUGE);\r\nuasm_il_bnez(p, r, tmp, lid);\r\n}\r\n}\r\nstatic __cpuinit void build_huge_update_entries(u32 **p,\r\nunsigned int pte,\r\nunsigned int tmp)\r\n{\r\nint small_sequence;\r\nsmall_sequence = (HPAGE_SIZE >> 7) < 0x10000;\r\nif (!small_sequence)\r\nuasm_i_lui(p, tmp, HPAGE_SIZE >> (7 + 16));\r\nbuild_convert_pte_to_entrylo(p, pte);\r\nUASM_i_MTC0(p, pte, C0_ENTRYLO0);\r\nif (small_sequence)\r\nUASM_i_ADDIU(p, pte, pte, HPAGE_SIZE >> 7);\r\nelse\r\nUASM_i_ADDU(p, pte, pte, tmp);\r\nUASM_i_MTC0(p, pte, C0_ENTRYLO1);\r\n}\r\nstatic __cpuinit void build_huge_handler_tail(u32 **p,\r\nstruct uasm_reloc **r,\r\nstruct uasm_label **l,\r\nunsigned int pte,\r\nunsigned int ptr)\r\n{\r\n#ifdef CONFIG_SMP\r\nUASM_i_SC(p, pte, 0, ptr);\r\nuasm_il_beqz(p, r, pte, label_tlb_huge_update);\r\nUASM_i_LW(p, pte, 0, ptr);\r\n#else\r\nUASM_i_SW(p, pte, 0, ptr);\r\n#endif\r\nbuild_huge_update_entries(p, pte, ptr);\r\nbuild_huge_tlb_write_entry(p, l, r, pte, tlb_indexed, 0);\r\n}\r\nstatic void __cpuinit\r\nbuild_get_pmde64(u32 **p, struct uasm_label **l, struct uasm_reloc **r,\r\nunsigned int tmp, unsigned int ptr)\r\n{\r\n#ifndef CONFIG_MIPS_PGD_C0_CONTEXT\r\nlong pgdc = (long)pgd_current;\r\n#endif\r\nuasm_i_dmfc0(p, tmp, C0_BADVADDR);\r\nif (check_for_high_segbits) {\r\nuasm_i_dsrl_safe(p, ptr, tmp, PGDIR_SHIFT + PGD_ORDER + PAGE_SHIFT - 3);\r\nuasm_il_bnez(p, r, ptr, label_vmalloc);\r\n} else {\r\nuasm_il_bltz(p, r, tmp, label_vmalloc);\r\n}\r\n#ifdef CONFIG_MIPS_PGD_C0_CONTEXT\r\nif (pgd_reg != -1) {\r\nUASM_i_MFC0(p, ptr, 31, pgd_reg);\r\n} else {\r\nUASM_i_MFC0(p, ptr, C0_CONTEXT);\r\nuasm_i_dins(p, ptr, 0, 0, 23);\r\nuasm_i_ori(p, ptr, ptr, 0x540);\r\nuasm_i_drotr(p, ptr, ptr, 11);\r\n}\r\n#elif defined(CONFIG_SMP)\r\n# ifdef CONFIG_MIPS_MT_SMTC\r\nuasm_i_mfc0(p, ptr, C0_TCBIND);\r\nuasm_i_dsrl_safe(p, ptr, ptr, 19);\r\n# else\r\nuasm_i_dmfc0(p, ptr, C0_CONTEXT);\r\nuasm_i_dsrl_safe(p, ptr, ptr, 23);\r\n# endif\r\nUASM_i_LA_mostly(p, tmp, pgdc);\r\nuasm_i_daddu(p, ptr, ptr, tmp);\r\nuasm_i_dmfc0(p, tmp, C0_BADVADDR);\r\nuasm_i_ld(p, ptr, uasm_rel_lo(pgdc), ptr);\r\n#else\r\nUASM_i_LA_mostly(p, ptr, pgdc);\r\nuasm_i_ld(p, ptr, uasm_rel_lo(pgdc), ptr);\r\n#endif\r\nuasm_l_vmalloc_done(l, *p);\r\nuasm_i_dsrl_safe(p, tmp, tmp, PGDIR_SHIFT - 3);\r\nuasm_i_andi(p, tmp, tmp, (PTRS_PER_PGD - 1)<<3);\r\nuasm_i_daddu(p, ptr, ptr, tmp);\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\nuasm_i_dmfc0(p, tmp, C0_BADVADDR);\r\nuasm_i_ld(p, ptr, 0, ptr);\r\nuasm_i_dsrl_safe(p, tmp, tmp, PMD_SHIFT-3);\r\nuasm_i_andi(p, tmp, tmp, (PTRS_PER_PMD - 1)<<3);\r\nuasm_i_daddu(p, ptr, ptr, tmp);\r\n#endif\r\n}\r\nstatic void __cpuinit\r\nbuild_get_pgd_vmalloc64(u32 **p, struct uasm_label **l, struct uasm_reloc **r,\r\nunsigned int bvaddr, unsigned int ptr,\r\nenum vmalloc64_mode mode)\r\n{\r\nlong swpd = (long)swapper_pg_dir;\r\nint single_insn_swpd;\r\nint did_vmalloc_branch = 0;\r\nsingle_insn_swpd = uasm_in_compat_space_p(swpd) && !uasm_rel_lo(swpd);\r\nuasm_l_vmalloc(l, *p);\r\nif (mode != not_refill && check_for_high_segbits) {\r\nif (single_insn_swpd) {\r\nuasm_il_bltz(p, r, bvaddr, label_vmalloc_done);\r\nuasm_i_lui(p, ptr, uasm_rel_hi(swpd));\r\ndid_vmalloc_branch = 1;\r\n} else {\r\nuasm_il_bgez(p, r, bvaddr, label_large_segbits_fault);\r\n}\r\n}\r\nif (!did_vmalloc_branch) {\r\nif (uasm_in_compat_space_p(swpd) && !uasm_rel_lo(swpd)) {\r\nuasm_il_b(p, r, label_vmalloc_done);\r\nuasm_i_lui(p, ptr, uasm_rel_hi(swpd));\r\n} else {\r\nUASM_i_LA_mostly(p, ptr, swpd);\r\nuasm_il_b(p, r, label_vmalloc_done);\r\nif (uasm_in_compat_space_p(swpd))\r\nuasm_i_addiu(p, ptr, ptr, uasm_rel_lo(swpd));\r\nelse\r\nuasm_i_daddiu(p, ptr, ptr, uasm_rel_lo(swpd));\r\n}\r\n}\r\nif (mode != not_refill && check_for_high_segbits) {\r\nuasm_l_large_segbits_fault(l, *p);\r\nUASM_i_LA(p, ptr, (unsigned long)tlb_do_page_fault_0);\r\nuasm_i_jr(p, ptr);\r\nif (mode == refill_scratch) {\r\nif (scratch_reg > 0)\r\nUASM_i_MFC0(p, 1, 31, scratch_reg);\r\nelse\r\nUASM_i_LW(p, 1, scratchpad_offset(0), 0);\r\n} else {\r\nuasm_i_nop(p);\r\n}\r\n}\r\n}\r\nstatic void __cpuinit __maybe_unused\r\nbuild_get_pgde32(u32 **p, unsigned int tmp, unsigned int ptr)\r\n{\r\nlong pgdc = (long)pgd_current;\r\n#ifdef CONFIG_SMP\r\n#ifdef CONFIG_MIPS_MT_SMTC\r\nuasm_i_mfc0(p, ptr, C0_TCBIND);\r\nUASM_i_LA_mostly(p, tmp, pgdc);\r\nuasm_i_srl(p, ptr, ptr, 19);\r\n#else\r\nuasm_i_mfc0(p, ptr, C0_CONTEXT);\r\nUASM_i_LA_mostly(p, tmp, pgdc);\r\nuasm_i_srl(p, ptr, ptr, 23);\r\n#endif\r\nuasm_i_addu(p, ptr, tmp, ptr);\r\n#else\r\nUASM_i_LA_mostly(p, ptr, pgdc);\r\n#endif\r\nuasm_i_mfc0(p, tmp, C0_BADVADDR);\r\nuasm_i_lw(p, ptr, uasm_rel_lo(pgdc), ptr);\r\nuasm_i_srl(p, tmp, tmp, PGDIR_SHIFT);\r\nuasm_i_sll(p, tmp, tmp, PGD_T_LOG2);\r\nuasm_i_addu(p, ptr, ptr, tmp);\r\n}\r\nstatic void __cpuinit build_adjust_context(u32 **p, unsigned int ctx)\r\n{\r\nunsigned int shift = 4 - (PTE_T_LOG2 + 1) + PAGE_SHIFT - 12;\r\nunsigned int mask = (PTRS_PER_PTE / 2 - 1) << (PTE_T_LOG2 + 1);\r\nswitch (current_cpu_type()) {\r\ncase CPU_VR41XX:\r\ncase CPU_VR4111:\r\ncase CPU_VR4121:\r\ncase CPU_VR4122:\r\ncase CPU_VR4131:\r\ncase CPU_VR4181:\r\ncase CPU_VR4181A:\r\ncase CPU_VR4133:\r\nshift += 2;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (shift)\r\nUASM_i_SRL(p, ctx, ctx, shift);\r\nuasm_i_andi(p, ctx, ctx, mask);\r\n}\r\nstatic void __cpuinit build_get_ptep(u32 **p, unsigned int tmp, unsigned int ptr)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_NEVADA:\r\nUASM_i_LW(p, ptr, 0, ptr);\r\nGET_CONTEXT(p, tmp);\r\nbreak;\r\ndefault:\r\nGET_CONTEXT(p, tmp);\r\nUASM_i_LW(p, ptr, 0, ptr);\r\nbreak;\r\n}\r\nbuild_adjust_context(p, tmp);\r\nUASM_i_ADDU(p, ptr, ptr, tmp);\r\n}\r\nstatic void __cpuinit build_update_entries(u32 **p, unsigned int tmp,\r\nunsigned int ptep)\r\n{\r\n#ifdef CONFIG_64BIT_PHYS_ADDR\r\nif (cpu_has_64bits) {\r\nuasm_i_ld(p, tmp, 0, ptep);\r\nuasm_i_ld(p, ptep, sizeof(pte_t), ptep);\r\nif (kernel_uses_smartmips_rixi) {\r\nUASM_i_SRL(p, tmp, tmp, ilog2(_PAGE_NO_EXEC));\r\nUASM_i_SRL(p, ptep, ptep, ilog2(_PAGE_NO_EXEC));\r\nUASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO0);\r\nUASM_i_ROTR(p, ptep, ptep, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\n} else {\r\nuasm_i_dsrl_safe(p, tmp, tmp, ilog2(_PAGE_GLOBAL));\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO0);\r\nuasm_i_dsrl_safe(p, ptep, ptep, ilog2(_PAGE_GLOBAL));\r\n}\r\nUASM_i_MTC0(p, ptep, C0_ENTRYLO1);\r\n} else {\r\nint pte_off_even = sizeof(pte_t) / 2;\r\nint pte_off_odd = pte_off_even + sizeof(pte_t);\r\nuasm_i_lw(p, tmp, pte_off_even, ptep);\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO0);\r\nuasm_i_lw(p, ptep, pte_off_odd, ptep);\r\nUASM_i_MTC0(p, ptep, C0_ENTRYLO1);\r\n}\r\n#else\r\nUASM_i_LW(p, tmp, 0, ptep);\r\nUASM_i_LW(p, ptep, sizeof(pte_t), ptep);\r\nif (r45k_bvahwbug())\r\nbuild_tlb_probe_entry(p);\r\nif (kernel_uses_smartmips_rixi) {\r\nUASM_i_SRL(p, tmp, tmp, ilog2(_PAGE_NO_EXEC));\r\nUASM_i_SRL(p, ptep, ptep, ilog2(_PAGE_NO_EXEC));\r\nUASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\nif (r4k_250MHZhwbug())\r\nUASM_i_MTC0(p, 0, C0_ENTRYLO0);\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO0);\r\nUASM_i_ROTR(p, ptep, ptep, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\n} else {\r\nUASM_i_SRL(p, tmp, tmp, ilog2(_PAGE_GLOBAL));\r\nif (r4k_250MHZhwbug())\r\nUASM_i_MTC0(p, 0, C0_ENTRYLO0);\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO0);\r\nUASM_i_SRL(p, ptep, ptep, ilog2(_PAGE_GLOBAL));\r\nif (r45k_bvahwbug())\r\nuasm_i_mfc0(p, tmp, C0_INDEX);\r\n}\r\nif (r4k_250MHZhwbug())\r\nUASM_i_MTC0(p, 0, C0_ENTRYLO1);\r\nUASM_i_MTC0(p, ptep, C0_ENTRYLO1);\r\n#endif\r\n}\r\nstatic struct mips_huge_tlb_info __cpuinit\r\nbuild_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r, unsigned int tmp,\r\nunsigned int ptr, int c0_scratch)\r\n{\r\nstruct mips_huge_tlb_info rv;\r\nunsigned int even, odd;\r\nint vmalloc_branch_delay_filled = 0;\r\nconst int scratch = 1;\r\nrv.huge_pte = scratch;\r\nrv.restore_scratch = 0;\r\nif (check_for_high_segbits) {\r\nUASM_i_MFC0(p, tmp, C0_BADVADDR);\r\nif (pgd_reg != -1)\r\nUASM_i_MFC0(p, ptr, 31, pgd_reg);\r\nelse\r\nUASM_i_MFC0(p, ptr, C0_CONTEXT);\r\nif (c0_scratch >= 0)\r\nUASM_i_MTC0(p, scratch, 31, c0_scratch);\r\nelse\r\nUASM_i_SW(p, scratch, scratchpad_offset(0), 0);\r\nuasm_i_dsrl_safe(p, scratch, tmp,\r\nPGDIR_SHIFT + PGD_ORDER + PAGE_SHIFT - 3);\r\nuasm_il_bnez(p, r, scratch, label_vmalloc);\r\nif (pgd_reg == -1) {\r\nvmalloc_branch_delay_filled = 1;\r\nuasm_i_dins(p, ptr, 0, 0, 23);\r\n}\r\n} else {\r\nif (pgd_reg != -1)\r\nUASM_i_MFC0(p, ptr, 31, pgd_reg);\r\nelse\r\nUASM_i_MFC0(p, ptr, C0_CONTEXT);\r\nUASM_i_MFC0(p, tmp, C0_BADVADDR);\r\nif (c0_scratch >= 0)\r\nUASM_i_MTC0(p, scratch, 31, c0_scratch);\r\nelse\r\nUASM_i_SW(p, scratch, scratchpad_offset(0), 0);\r\nif (pgd_reg == -1)\r\nuasm_i_dins(p, ptr, 0, 0, 23);\r\nuasm_il_bltz(p, r, tmp, label_vmalloc);\r\n}\r\nif (pgd_reg == -1) {\r\nvmalloc_branch_delay_filled = 1;\r\nuasm_i_ori(p, ptr, ptr, 0x540);\r\nuasm_i_drotr(p, ptr, ptr, 11);\r\n}\r\n#ifdef __PAGETABLE_PMD_FOLDED\r\n#define LOC_PTEP scratch\r\n#else\r\n#define LOC_PTEP ptr\r\n#endif\r\nif (!vmalloc_branch_delay_filled)\r\nuasm_i_dsrl_safe(p, scratch, tmp, PGDIR_SHIFT - 3);\r\nuasm_l_vmalloc_done(l, *p);\r\nif (vmalloc_branch_delay_filled)\r\nuasm_i_dsrl_safe(p, scratch, tmp, PGDIR_SHIFT - 3);\r\n#ifdef __PAGETABLE_PMD_FOLDED\r\nGET_CONTEXT(p, tmp);\r\n#endif\r\nuasm_i_andi(p, scratch, scratch, (PTRS_PER_PGD - 1) << 3);\r\nif (use_lwx_insns()) {\r\nUASM_i_LWX(p, LOC_PTEP, scratch, ptr);\r\n} else {\r\nuasm_i_daddu(p, ptr, ptr, scratch);\r\nuasm_i_ld(p, LOC_PTEP, 0, ptr);\r\n}\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\nuasm_i_dsrl_safe(p, scratch, tmp, PMD_SHIFT - 3);\r\nuasm_i_andi(p, scratch, scratch, (PTRS_PER_PMD - 1) << 3);\r\nGET_CONTEXT(p, tmp);\r\nif (use_lwx_insns()) {\r\nUASM_i_LWX(p, scratch, scratch, ptr);\r\n} else {\r\nuasm_i_daddu(p, ptr, ptr, scratch);\r\nUASM_i_LW(p, scratch, 0, ptr);\r\n}\r\n#endif\r\nbuild_adjust_context(p, tmp);\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nuasm_il_bbit1(p, r, scratch, ilog2(_PAGE_HUGE), label_tlb_huge_update);\r\nif (use_lwx_insns())\r\nuasm_i_nop(p);\r\n#endif\r\nif (use_lwx_insns()) {\r\neven = ptr;\r\nodd = tmp;\r\nUASM_i_LWX(p, even, scratch, tmp);\r\nUASM_i_ADDIU(p, tmp, tmp, sizeof(pte_t));\r\nUASM_i_LWX(p, odd, scratch, tmp);\r\n} else {\r\nUASM_i_ADDU(p, ptr, scratch, tmp);\r\neven = tmp;\r\nodd = ptr;\r\nUASM_i_LW(p, even, 0, ptr);\r\nUASM_i_LW(p, odd, sizeof(pte_t), ptr);\r\n}\r\nif (kernel_uses_smartmips_rixi) {\r\nuasm_i_dsrl_safe(p, even, even, ilog2(_PAGE_NO_EXEC));\r\nuasm_i_dsrl_safe(p, odd, odd, ilog2(_PAGE_NO_EXEC));\r\nuasm_i_drotr(p, even, even,\r\nilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\nUASM_i_MTC0(p, even, C0_ENTRYLO0);\r\nuasm_i_drotr(p, odd, odd,\r\nilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\n} else {\r\nuasm_i_dsrl_safe(p, even, even, ilog2(_PAGE_GLOBAL));\r\nUASM_i_MTC0(p, even, C0_ENTRYLO0);\r\nuasm_i_dsrl_safe(p, odd, odd, ilog2(_PAGE_GLOBAL));\r\n}\r\nUASM_i_MTC0(p, odd, C0_ENTRYLO1);\r\nif (c0_scratch >= 0) {\r\nUASM_i_MFC0(p, scratch, 31, c0_scratch);\r\nbuild_tlb_write_entry(p, l, r, tlb_random);\r\nuasm_l_leave(l, *p);\r\nrv.restore_scratch = 1;\r\n} else if (PAGE_SHIFT == 14 || PAGE_SHIFT == 13) {\r\nbuild_tlb_write_entry(p, l, r, tlb_random);\r\nuasm_l_leave(l, *p);\r\nUASM_i_LW(p, scratch, scratchpad_offset(0), 0);\r\n} else {\r\nUASM_i_LW(p, scratch, scratchpad_offset(0), 0);\r\nbuild_tlb_write_entry(p, l, r, tlb_random);\r\nuasm_l_leave(l, *p);\r\nrv.restore_scratch = 1;\r\n}\r\nuasm_i_eret(p);\r\nreturn rv;\r\n}\r\nstatic void __cpuinit build_r4000_tlb_refill_handler(void)\r\n{\r\nu32 *p = tlb_handler;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nu32 *f;\r\nunsigned int final_len;\r\nstruct mips_huge_tlb_info htlb_info __maybe_unused;\r\nenum vmalloc64_mode vmalloc_mode __maybe_unused;\r\nmemset(tlb_handler, 0, sizeof(tlb_handler));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nmemset(final_handler, 0, sizeof(final_handler));\r\nif ((scratch_reg > 0 || scratchpad_available()) && use_bbit_insns()) {\r\nhtlb_info = build_fast_tlb_refill_handler(&p, &l, &r, K0, K1,\r\nscratch_reg);\r\nvmalloc_mode = refill_scratch;\r\n} else {\r\nhtlb_info.huge_pte = K0;\r\nhtlb_info.restore_scratch = 0;\r\nvmalloc_mode = refill_noscratch;\r\nif (bcm1250_m3_war()) {\r\nunsigned int segbits = 44;\r\nuasm_i_dmfc0(&p, K0, C0_BADVADDR);\r\nuasm_i_dmfc0(&p, K1, C0_ENTRYHI);\r\nuasm_i_xor(&p, K0, K0, K1);\r\nuasm_i_dsrl_safe(&p, K1, K0, 62);\r\nuasm_i_dsrl_safe(&p, K0, K0, 12 + 1);\r\nuasm_i_dsll_safe(&p, K0, K0, 64 + 12 + 1 - segbits);\r\nuasm_i_or(&p, K0, K0, K1);\r\nuasm_il_bnez(&p, &r, K0, label_leave);\r\n}\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pmde64(&p, &l, &r, K0, K1);\r\n#else\r\nbuild_get_pgde32(&p, K0, K1);\r\n#endif\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nbuild_is_huge_pte(&p, &r, K0, K1, label_tlb_huge_update);\r\n#endif\r\nbuild_get_ptep(&p, K0, K1);\r\nbuild_update_entries(&p, K0, K1);\r\nbuild_tlb_write_entry(&p, &l, &r, tlb_random);\r\nuasm_l_leave(&l, p);\r\nuasm_i_eret(&p);\r\n}\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nuasm_l_tlb_huge_update(&l, p);\r\nbuild_huge_update_entries(&p, htlb_info.huge_pte, K1);\r\nbuild_huge_tlb_write_entry(&p, &l, &r, K0, tlb_random,\r\nhtlb_info.restore_scratch);\r\n#endif\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pgd_vmalloc64(&p, &l, &r, K0, K1, vmalloc_mode);\r\n#endif\r\n#if defined(CONFIG_32BIT) || defined(CONFIG_CPU_LOONGSON2)\r\nif ((p - tlb_handler) > 64)\r\npanic("TLB refill handler space exceeded");\r\n#else\r\nif (((p - tlb_handler) > (MIPS64_REFILL_INSNS * 2) - 1)\r\n|| (((p - tlb_handler) > (MIPS64_REFILL_INSNS * 2) - 3)\r\n&& uasm_insn_has_bdelay(relocs,\r\ntlb_handler + MIPS64_REFILL_INSNS - 3)))\r\npanic("TLB refill handler space exceeded");\r\n#endif\r\n#if defined(CONFIG_32BIT) || defined(CONFIG_CPU_LOONGSON2)\r\nf = final_handler;\r\nuasm_copy_handler(relocs, labels, tlb_handler, p, f);\r\nfinal_len = p - tlb_handler;\r\n#else\r\nf = final_handler + MIPS64_REFILL_INSNS;\r\nif ((p - tlb_handler) <= MIPS64_REFILL_INSNS) {\r\nuasm_copy_handler(relocs, labels, tlb_handler, p, f);\r\nfinal_len = p - tlb_handler;\r\n} else {\r\n#if defined(CONFIG_HUGETLB_PAGE)\r\nconst enum label_id ls = label_tlb_huge_update;\r\n#else\r\nconst enum label_id ls = label_vmalloc;\r\n#endif\r\nu32 *split;\r\nint ov = 0;\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(labels) && labels[i].lab != ls; i++)\r\n;\r\nBUG_ON(i == ARRAY_SIZE(labels));\r\nsplit = labels[i].addr;\r\nif (split > tlb_handler + MIPS64_REFILL_INSNS ||\r\nsplit < p - MIPS64_REFILL_INSNS)\r\nov = 1;\r\nif (ov) {\r\nsplit = tlb_handler + MIPS64_REFILL_INSNS - 2;\r\nif (uasm_insn_has_bdelay(relocs, split - 1))\r\nsplit--;\r\n}\r\nuasm_copy_handler(relocs, labels, tlb_handler, split, f);\r\nf += split - tlb_handler;\r\nif (ov) {\r\nuasm_l_split(&l, final_handler);\r\nuasm_il_b(&f, &r, label_split);\r\nif (uasm_insn_has_bdelay(relocs, split))\r\nuasm_i_nop(&f);\r\nelse {\r\nuasm_copy_handler(relocs, labels,\r\nsplit, split + 1, f);\r\nuasm_move_labels(labels, f, f + 1, -1);\r\nf++;\r\nsplit++;\r\n}\r\n}\r\nuasm_copy_handler(relocs, labels, split, p, final_handler);\r\nfinal_len = (f - (final_handler + MIPS64_REFILL_INSNS)) +\r\n(p - split);\r\n}\r\n#endif\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB refill handler (%u instructions).\n",\r\nfinal_len);\r\nmemcpy((void *)ebase, final_handler, 0x100);\r\ndump_handler((u32 *)ebase, 64);\r\n}\r\nstatic void __cpuinit build_r4000_setup_pgd(void)\r\n{\r\nconst int a0 = 4;\r\nconst int a1 = 5;\r\nu32 *p = tlbmiss_handler_setup_pgd;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(tlbmiss_handler_setup_pgd, 0, sizeof(tlbmiss_handler_setup_pgd));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\npgd_reg = allocate_kscratch();\r\nif (pgd_reg == -1) {\r\nUASM_i_SRA(&p, a1, a0, 29);\r\nUASM_i_ADDIU(&p, a1, a1, 4);\r\nuasm_il_bnez(&p, &r, a1, label_tlbl_goaround1);\r\nuasm_i_nop(&p);\r\nuasm_i_dinsm(&p, a0, 0, 29, 64 - 29);\r\nuasm_l_tlbl_goaround1(&l, p);\r\nUASM_i_SLL(&p, a0, a0, 11);\r\nuasm_i_jr(&p, 31);\r\nUASM_i_MTC0(&p, a0, C0_CONTEXT);\r\n} else {\r\nuasm_i_jr(&p, 31);\r\nUASM_i_MTC0(&p, a0, 31, pgd_reg);\r\n}\r\nif (p - tlbmiss_handler_setup_pgd > ARRAY_SIZE(tlbmiss_handler_setup_pgd))\r\npanic("tlbmiss_handler_setup_pgd space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote tlbmiss_handler_setup_pgd (%u instructions).\n",\r\n(unsigned int)(p - tlbmiss_handler_setup_pgd));\r\ndump_handler(tlbmiss_handler_setup_pgd,\r\nARRAY_SIZE(tlbmiss_handler_setup_pgd));\r\n}\r\nstatic void __cpuinit\r\niPTE_LW(u32 **p, unsigned int pte, unsigned int ptr)\r\n{\r\n#ifdef CONFIG_SMP\r\n# ifdef CONFIG_64BIT_PHYS_ADDR\r\nif (cpu_has_64bits)\r\nuasm_i_lld(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_LL(p, pte, 0, ptr);\r\n#else\r\n# ifdef CONFIG_64BIT_PHYS_ADDR\r\nif (cpu_has_64bits)\r\nuasm_i_ld(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_LW(p, pte, 0, ptr);\r\n#endif\r\n}\r\nstatic void __cpuinit\r\niPTE_SW(u32 **p, struct uasm_reloc **r, unsigned int pte, unsigned int ptr,\r\nunsigned int mode)\r\n{\r\n#ifdef CONFIG_64BIT_PHYS_ADDR\r\nunsigned int hwmode = mode & (_PAGE_VALID | _PAGE_DIRTY);\r\n#endif\r\nuasm_i_ori(p, pte, pte, mode);\r\n#ifdef CONFIG_SMP\r\n# ifdef CONFIG_64BIT_PHYS_ADDR\r\nif (cpu_has_64bits)\r\nuasm_i_scd(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_SC(p, pte, 0, ptr);\r\nif (r10000_llsc_war())\r\nuasm_il_beqzl(p, r, pte, label_smp_pgtable_change);\r\nelse\r\nuasm_il_beqz(p, r, pte, label_smp_pgtable_change);\r\n# ifdef CONFIG_64BIT_PHYS_ADDR\r\nif (!cpu_has_64bits) {\r\nuasm_i_ll(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_i_ori(p, pte, pte, hwmode);\r\nuasm_i_sc(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_il_beqz(p, r, pte, label_smp_pgtable_change);\r\nuasm_i_lw(p, pte, 0, ptr);\r\n} else\r\nuasm_i_nop(p);\r\n# else\r\nuasm_i_nop(p);\r\n# endif\r\n#else\r\n# ifdef CONFIG_64BIT_PHYS_ADDR\r\nif (cpu_has_64bits)\r\nuasm_i_sd(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_SW(p, pte, 0, ptr);\r\n# ifdef CONFIG_64BIT_PHYS_ADDR\r\nif (!cpu_has_64bits) {\r\nuasm_i_lw(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_i_ori(p, pte, pte, hwmode);\r\nuasm_i_sw(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_i_lw(p, pte, 0, ptr);\r\n}\r\n# endif\r\n#endif\r\n}\r\nstatic void __cpuinit\r\nbuild_pte_present(u32 **p, struct uasm_reloc **r,\r\nint pte, int ptr, int scratch, enum label_id lid)\r\n{\r\nint t = scratch >= 0 ? scratch : pte;\r\nif (kernel_uses_smartmips_rixi) {\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(p, r, pte, ilog2(_PAGE_PRESENT), lid);\r\nuasm_i_nop(p);\r\n} else {\r\nuasm_i_andi(p, t, pte, _PAGE_PRESENT);\r\nuasm_il_beqz(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\n}\r\n} else {\r\nuasm_i_andi(p, t, pte, _PAGE_PRESENT | _PAGE_READ);\r\nuasm_i_xori(p, t, t, _PAGE_PRESENT | _PAGE_READ);\r\nuasm_il_bnez(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\n}\r\n}\r\nstatic void __cpuinit\r\nbuild_make_valid(u32 **p, struct uasm_reloc **r, unsigned int pte,\r\nunsigned int ptr)\r\n{\r\nunsigned int mode = _PAGE_VALID | _PAGE_ACCESSED;\r\niPTE_SW(p, r, pte, ptr, mode);\r\n}\r\nstatic void __cpuinit\r\nbuild_pte_writable(u32 **p, struct uasm_reloc **r,\r\nunsigned int pte, unsigned int ptr, int scratch,\r\nenum label_id lid)\r\n{\r\nint t = scratch >= 0 ? scratch : pte;\r\nuasm_i_andi(p, t, pte, _PAGE_PRESENT | _PAGE_WRITE);\r\nuasm_i_xori(p, t, t, _PAGE_PRESENT | _PAGE_WRITE);\r\nuasm_il_bnez(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\nelse\r\nuasm_i_nop(p);\r\n}\r\nstatic void __cpuinit\r\nbuild_make_write(u32 **p, struct uasm_reloc **r, unsigned int pte,\r\nunsigned int ptr)\r\n{\r\nunsigned int mode = (_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID\r\n| _PAGE_DIRTY);\r\niPTE_SW(p, r, pte, ptr, mode);\r\n}\r\nstatic void __cpuinit\r\nbuild_pte_modifiable(u32 **p, struct uasm_reloc **r,\r\nunsigned int pte, unsigned int ptr, int scratch,\r\nenum label_id lid)\r\n{\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(p, r, pte, ilog2(_PAGE_WRITE), lid);\r\nuasm_i_nop(p);\r\n} else {\r\nint t = scratch >= 0 ? scratch : pte;\r\nuasm_i_andi(p, t, pte, _PAGE_WRITE);\r\nuasm_il_beqz(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\n}\r\n}\r\nstatic void __cpuinit\r\nbuild_r3000_pte_reload_tlbwi(u32 **p, unsigned int pte, unsigned int tmp)\r\n{\r\nuasm_i_mtc0(p, pte, C0_ENTRYLO0);\r\nuasm_i_mfc0(p, tmp, C0_EPC);\r\nuasm_i_tlbwi(p);\r\nuasm_i_jr(p, tmp);\r\nuasm_i_rfe(p);\r\n}\r\nstatic void __cpuinit\r\nbuild_r3000_tlb_reload_write(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r, unsigned int pte,\r\nunsigned int tmp)\r\n{\r\nuasm_i_mfc0(p, tmp, C0_INDEX);\r\nuasm_i_mtc0(p, pte, C0_ENTRYLO0);\r\nuasm_il_bltz(p, r, tmp, label_r3000_write_probe_fail);\r\nuasm_i_mfc0(p, tmp, C0_EPC);\r\nuasm_i_tlbwi(p);\r\nuasm_i_jr(p, tmp);\r\nuasm_i_rfe(p);\r\nuasm_l_r3000_write_probe_fail(l, *p);\r\nuasm_i_tlbwr(p);\r\nuasm_i_jr(p, tmp);\r\nuasm_i_rfe(p);\r\n}\r\nstatic void __cpuinit\r\nbuild_r3000_tlbchange_handler_head(u32 **p, unsigned int pte,\r\nunsigned int ptr)\r\n{\r\nlong pgdc = (long)pgd_current;\r\nuasm_i_mfc0(p, pte, C0_BADVADDR);\r\nuasm_i_lui(p, ptr, uasm_rel_hi(pgdc));\r\nuasm_i_lw(p, ptr, uasm_rel_lo(pgdc), ptr);\r\nuasm_i_srl(p, pte, pte, 22);\r\nuasm_i_sll(p, pte, pte, 2);\r\nuasm_i_addu(p, ptr, ptr, pte);\r\nuasm_i_mfc0(p, pte, C0_CONTEXT);\r\nuasm_i_lw(p, ptr, 0, ptr);\r\nuasm_i_andi(p, pte, pte, 0xffc);\r\nuasm_i_addu(p, ptr, ptr, pte);\r\nuasm_i_lw(p, pte, 0, ptr);\r\nuasm_i_tlbp(p);\r\n}\r\nstatic void __cpuinit build_r3000_tlb_load_handler(void)\r\n{\r\nu32 *p = handle_tlbl;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(handle_tlbl, 0, sizeof(handle_tlbl));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nbuild_r3000_tlbchange_handler_head(&p, K0, K1);\r\nbuild_pte_present(&p, &r, K0, K1, -1, label_nopage_tlbl);\r\nuasm_i_nop(&p);\r\nbuild_make_valid(&p, &r, K0, K1);\r\nbuild_r3000_tlb_reload_write(&p, &l, &r, K0, K1);\r\nuasm_l_nopage_tlbl(&l, p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_0 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif ((p - handle_tlbl) > FASTPATH_SIZE)\r\npanic("TLB load handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB load handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbl));\r\ndump_handler(handle_tlbl, ARRAY_SIZE(handle_tlbl));\r\n}\r\nstatic void __cpuinit build_r3000_tlb_store_handler(void)\r\n{\r\nu32 *p = handle_tlbs;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(handle_tlbs, 0, sizeof(handle_tlbs));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nbuild_r3000_tlbchange_handler_head(&p, K0, K1);\r\nbuild_pte_writable(&p, &r, K0, K1, -1, label_nopage_tlbs);\r\nuasm_i_nop(&p);\r\nbuild_make_write(&p, &r, K0, K1);\r\nbuild_r3000_tlb_reload_write(&p, &l, &r, K0, K1);\r\nuasm_l_nopage_tlbs(&l, p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif ((p - handle_tlbs) > FASTPATH_SIZE)\r\npanic("TLB store handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB store handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbs));\r\ndump_handler(handle_tlbs, ARRAY_SIZE(handle_tlbs));\r\n}\r\nstatic void __cpuinit build_r3000_tlb_modify_handler(void)\r\n{\r\nu32 *p = handle_tlbm;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(handle_tlbm, 0, sizeof(handle_tlbm));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nbuild_r3000_tlbchange_handler_head(&p, K0, K1);\r\nbuild_pte_modifiable(&p, &r, K0, K1, -1, label_nopage_tlbm);\r\nuasm_i_nop(&p);\r\nbuild_make_write(&p, &r, K0, K1);\r\nbuild_r3000_pte_reload_tlbwi(&p, K0, K1);\r\nuasm_l_nopage_tlbm(&l, p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif ((p - handle_tlbm) > FASTPATH_SIZE)\r\npanic("TLB modify handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB modify handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbm));\r\ndump_handler(handle_tlbm, ARRAY_SIZE(handle_tlbm));\r\n}\r\nstatic struct work_registers __cpuinit\r\nbuild_r4000_tlbchange_handler_head(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r)\r\n{\r\nstruct work_registers wr = build_get_work_registers(p);\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pmde64(p, l, r, wr.r1, wr.r2);\r\n#else\r\nbuild_get_pgde32(p, wr.r1, wr.r2);\r\n#endif\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nbuild_is_huge_pte(p, r, wr.r1, wr.r2, label_tlb_huge_update);\r\n#endif\r\nUASM_i_MFC0(p, wr.r1, C0_BADVADDR);\r\nUASM_i_LW(p, wr.r2, 0, wr.r2);\r\nUASM_i_SRL(p, wr.r1, wr.r1, PAGE_SHIFT + PTE_ORDER - PTE_T_LOG2);\r\nuasm_i_andi(p, wr.r1, wr.r1, (PTRS_PER_PTE - 1) << PTE_T_LOG2);\r\nUASM_i_ADDU(p, wr.r2, wr.r2, wr.r1);\r\n#ifdef CONFIG_SMP\r\nuasm_l_smp_pgtable_change(l, *p);\r\n#endif\r\niPTE_LW(p, wr.r1, wr.r2);\r\nif (!m4kc_tlbp_war())\r\nbuild_tlb_probe_entry(p);\r\nreturn wr;\r\n}\r\nstatic void __cpuinit\r\nbuild_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r, unsigned int tmp,\r\nunsigned int ptr)\r\n{\r\nuasm_i_ori(p, ptr, ptr, sizeof(pte_t));\r\nuasm_i_xori(p, ptr, ptr, sizeof(pte_t));\r\nbuild_update_entries(p, tmp, ptr);\r\nbuild_tlb_write_entry(p, l, r, tlb_indexed);\r\nuasm_l_leave(l, *p);\r\nbuild_restore_work_registers(p);\r\nuasm_i_eret(p);\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pgd_vmalloc64(p, l, r, tmp, ptr, not_refill);\r\n#endif\r\n}\r\nstatic void __cpuinit build_r4000_tlb_load_handler(void)\r\n{\r\nu32 *p = handle_tlbl;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nstruct work_registers wr;\r\nmemset(handle_tlbl, 0, sizeof(handle_tlbl));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nif (bcm1250_m3_war()) {\r\nunsigned int segbits = 44;\r\nuasm_i_dmfc0(&p, K0, C0_BADVADDR);\r\nuasm_i_dmfc0(&p, K1, C0_ENTRYHI);\r\nuasm_i_xor(&p, K0, K0, K1);\r\nuasm_i_dsrl_safe(&p, K1, K0, 62);\r\nuasm_i_dsrl_safe(&p, K0, K0, 12 + 1);\r\nuasm_i_dsll_safe(&p, K0, K0, 64 + 12 + 1 - segbits);\r\nuasm_i_or(&p, K0, K0, K1);\r\nuasm_il_bnez(&p, &r, K0, label_leave);\r\n}\r\nwr = build_r4000_tlbchange_handler_head(&p, &l, &r);\r\nbuild_pte_present(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbl);\r\nif (m4kc_tlbp_war())\r\nbuild_tlb_probe_entry(&p);\r\nif (kernel_uses_smartmips_rixi) {\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(&p, &r, wr.r1, ilog2(_PAGE_VALID),\r\nlabel_tlbl_goaround1);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);\r\nuasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround1);\r\n}\r\nuasm_i_nop(&p);\r\nuasm_i_tlbr(&p);\r\nif (use_bbit_insns()) {\r\nuasm_i_bbit0(&p, wr.r2, ilog2(sizeof(pte_t)), 8);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));\r\nuasm_i_beqz(&p, wr.r3, 8);\r\n}\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO0);\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO1);\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit1(&p, &r, wr.r3, 1, label_nopage_tlbl);\r\nuasm_i_nop(&p);\r\nuasm_l_tlbl_goaround1(&l, p);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r3, 2);\r\nuasm_il_bnez(&p, &r, wr.r3, label_nopage_tlbl);\r\nuasm_i_nop(&p);\r\n}\r\nuasm_l_tlbl_goaround1(&l, p);\r\n}\r\nbuild_make_valid(&p, &r, wr.r1, wr.r2);\r\nbuild_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nuasm_l_tlb_huge_update(&l, p);\r\niPTE_LW(&p, wr.r1, wr.r2);\r\nbuild_pte_present(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbl);\r\nbuild_tlb_probe_entry(&p);\r\nif (kernel_uses_smartmips_rixi) {\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(&p, &r, wr.r1, ilog2(_PAGE_VALID),\r\nlabel_tlbl_goaround2);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);\r\nuasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);\r\n}\r\nuasm_i_nop(&p);\r\nuasm_i_tlbr(&p);\r\nif (use_bbit_insns()) {\r\nuasm_i_bbit0(&p, wr.r2, ilog2(sizeof(pte_t)), 8);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));\r\nuasm_i_beqz(&p, wr.r3, 8);\r\n}\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO0);\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO1);\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(&p, &r, wr.r3, 1, label_tlbl_goaround2);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r3, 2);\r\nuasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);\r\n}\r\nif (PM_DEFAULT_MASK == 0)\r\nuasm_i_nop(&p);\r\nbuild_restore_pagemask(&p, &r, wr.r3, label_nopage_tlbl, 0);\r\nuasm_l_tlbl_goaround2(&l, p);\r\n}\r\nuasm_i_ori(&p, wr.r1, wr.r1, (_PAGE_ACCESSED | _PAGE_VALID));\r\nbuild_huge_handler_tail(&p, &r, &l, wr.r1, wr.r2);\r\n#endif\r\nuasm_l_nopage_tlbl(&l, p);\r\nbuild_restore_work_registers(&p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_0 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif ((p - handle_tlbl) > FASTPATH_SIZE)\r\npanic("TLB load handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB load handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbl));\r\ndump_handler(handle_tlbl, ARRAY_SIZE(handle_tlbl));\r\n}\r\nstatic void __cpuinit build_r4000_tlb_store_handler(void)\r\n{\r\nu32 *p = handle_tlbs;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nstruct work_registers wr;\r\nmemset(handle_tlbs, 0, sizeof(handle_tlbs));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nwr = build_r4000_tlbchange_handler_head(&p, &l, &r);\r\nbuild_pte_writable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbs);\r\nif (m4kc_tlbp_war())\r\nbuild_tlb_probe_entry(&p);\r\nbuild_make_write(&p, &r, wr.r1, wr.r2);\r\nbuild_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nuasm_l_tlb_huge_update(&l, p);\r\niPTE_LW(&p, wr.r1, wr.r2);\r\nbuild_pte_writable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbs);\r\nbuild_tlb_probe_entry(&p);\r\nuasm_i_ori(&p, wr.r1, wr.r1,\r\n_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY);\r\nbuild_huge_handler_tail(&p, &r, &l, wr.r1, wr.r2);\r\n#endif\r\nuasm_l_nopage_tlbs(&l, p);\r\nbuild_restore_work_registers(&p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif ((p - handle_tlbs) > FASTPATH_SIZE)\r\npanic("TLB store handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB store handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbs));\r\ndump_handler(handle_tlbs, ARRAY_SIZE(handle_tlbs));\r\n}\r\nstatic void __cpuinit build_r4000_tlb_modify_handler(void)\r\n{\r\nu32 *p = handle_tlbm;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nstruct work_registers wr;\r\nmemset(handle_tlbm, 0, sizeof(handle_tlbm));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nwr = build_r4000_tlbchange_handler_head(&p, &l, &r);\r\nbuild_pte_modifiable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbm);\r\nif (m4kc_tlbp_war())\r\nbuild_tlb_probe_entry(&p);\r\nbuild_make_write(&p, &r, wr.r1, wr.r2);\r\nbuild_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nuasm_l_tlb_huge_update(&l, p);\r\niPTE_LW(&p, wr.r1, wr.r2);\r\nbuild_pte_modifiable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbm);\r\nbuild_tlb_probe_entry(&p);\r\nuasm_i_ori(&p, wr.r1, wr.r1,\r\n_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY);\r\nbuild_huge_handler_tail(&p, &r, &l, wr.r1, wr.r2);\r\n#endif\r\nuasm_l_nopage_tlbm(&l, p);\r\nbuild_restore_work_registers(&p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif ((p - handle_tlbm) > FASTPATH_SIZE)\r\npanic("TLB modify handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB modify handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbm));\r\ndump_handler(handle_tlbm, ARRAY_SIZE(handle_tlbm));\r\n}\r\nvoid __cpuinit build_tlb_refill_handler(void)\r\n{\r\nstatic int run_once = 0;\r\n#ifdef CONFIG_64BIT\r\ncheck_for_high_segbits = current_cpu_data.vmbits > (PGDIR_SHIFT + PGD_ORDER + PAGE_SHIFT - 3);\r\n#endif\r\nswitch (current_cpu_type()) {\r\ncase CPU_R2000:\r\ncase CPU_R3000:\r\ncase CPU_R3000A:\r\ncase CPU_R3081E:\r\ncase CPU_TX3912:\r\ncase CPU_TX3922:\r\ncase CPU_TX3927:\r\n#ifndef CONFIG_MIPS_PGD_C0_CONTEXT\r\nbuild_r3000_tlb_refill_handler();\r\nif (!run_once) {\r\nbuild_r3000_tlb_load_handler();\r\nbuild_r3000_tlb_store_handler();\r\nbuild_r3000_tlb_modify_handler();\r\nrun_once++;\r\n}\r\n#else\r\npanic("No R3000 TLB refill handler");\r\n#endif\r\nbreak;\r\ncase CPU_R6000:\r\ncase CPU_R6000A:\r\npanic("No R6000 TLB refill handler yet");\r\nbreak;\r\ncase CPU_R8000:\r\npanic("No R8000 TLB refill handler yet");\r\nbreak;\r\ndefault:\r\nif (!run_once) {\r\nscratch_reg = allocate_kscratch();\r\n#ifdef CONFIG_MIPS_PGD_C0_CONTEXT\r\nbuild_r4000_setup_pgd();\r\n#endif\r\nbuild_r4000_tlb_load_handler();\r\nbuild_r4000_tlb_store_handler();\r\nbuild_r4000_tlb_modify_handler();\r\nrun_once++;\r\n}\r\nbuild_r4000_tlb_refill_handler();\r\n}\r\n}\r\nvoid __cpuinit flush_tlb_handlers(void)\r\n{\r\nlocal_flush_icache_range((unsigned long)handle_tlbl,\r\n(unsigned long)handle_tlbl + sizeof(handle_tlbl));\r\nlocal_flush_icache_range((unsigned long)handle_tlbs,\r\n(unsigned long)handle_tlbs + sizeof(handle_tlbs));\r\nlocal_flush_icache_range((unsigned long)handle_tlbm,\r\n(unsigned long)handle_tlbm + sizeof(handle_tlbm));\r\n#ifdef CONFIG_MIPS_PGD_C0_CONTEXT\r\nlocal_flush_icache_range((unsigned long)tlbmiss_handler_setup_pgd,\r\n(unsigned long)tlbmiss_handler_setup_pgd + sizeof(handle_tlbm));\r\n#endif\r\n}
