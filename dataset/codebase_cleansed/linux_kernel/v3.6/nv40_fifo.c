static int\r\nnv40_fifo_context_new(struct nouveau_channel *chan, int engine)\r\n{\r\nstruct drm_device *dev = chan->dev;\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nv40_fifo_priv *priv = nv_engine(dev, engine);\r\nstruct nv40_fifo_chan *fctx;\r\nunsigned long flags;\r\nint ret;\r\nfctx = chan->engctx[engine] = kzalloc(sizeof(*fctx), GFP_KERNEL);\r\nif (!fctx)\r\nreturn -ENOMEM;\r\nchan->user = ioremap(pci_resource_start(dev->pdev, 0) +\r\nNV03_USER(chan->id), PAGE_SIZE);\r\nif (!chan->user) {\r\nret = -ENOMEM;\r\ngoto error;\r\n}\r\nret = nouveau_gpuobj_new_fake(dev, dev_priv->ramfc->pinst +\r\nchan->id * 128, ~0, 128,\r\nNVOBJ_FLAG_ZERO_ALLOC |\r\nNVOBJ_FLAG_ZERO_FREE, &fctx->ramfc);\r\nif (ret)\r\ngoto error;\r\nnv_wo32(fctx->ramfc, 0x00, chan->pushbuf_base);\r\nnv_wo32(fctx->ramfc, 0x04, chan->pushbuf_base);\r\nnv_wo32(fctx->ramfc, 0x0c, chan->pushbuf->pinst >> 4);\r\nnv_wo32(fctx->ramfc, 0x18, 0x30000000 |\r\nNV_PFIFO_CACHE1_DMA_FETCH_TRIG_128_BYTES |\r\nNV_PFIFO_CACHE1_DMA_FETCH_SIZE_128_BYTES |\r\n#ifdef __BIG_ENDIAN\r\nNV_PFIFO_CACHE1_BIG_ENDIAN |\r\n#endif\r\nNV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_8);\r\nnv_wo32(fctx->ramfc, 0x3c, 0x0001ffff);\r\nspin_lock_irqsave(&dev_priv->context_switch_lock, flags);\r\nnv_mask(dev, NV04_PFIFO_MODE, (1 << chan->id), (1 << chan->id));\r\nspin_unlock_irqrestore(&dev_priv->context_switch_lock, flags);\r\nnouveau_gpuobj_ref(fctx->ramfc, &chan->ramfc);\r\nerror:\r\nif (ret)\r\npriv->base.base.context_del(chan, engine);\r\nreturn ret;\r\n}\r\nstatic int\r\nnv40_fifo_init(struct drm_device *dev, int engine)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nv40_fifo_priv *priv = nv_engine(dev, engine);\r\nint i;\r\nnv_mask(dev, NV03_PMC_ENABLE, NV_PMC_ENABLE_PFIFO, 0);\r\nnv_mask(dev, NV03_PMC_ENABLE, NV_PMC_ENABLE_PFIFO, NV_PMC_ENABLE_PFIFO);\r\nnv_wr32(dev, 0x002040, 0x000000ff);\r\nnv_wr32(dev, 0x002044, 0x2101ffff);\r\nnv_wr32(dev, 0x002058, 0x00000001);\r\nnv_wr32(dev, NV03_PFIFO_RAMHT, (0x03 << 24) |\r\n((dev_priv->ramht->bits - 9) << 16) |\r\n(dev_priv->ramht->gpuobj->pinst >> 8));\r\nnv_wr32(dev, NV03_PFIFO_RAMRO, dev_priv->ramro->pinst >> 8);\r\nswitch (dev_priv->chipset) {\r\ncase 0x47:\r\ncase 0x49:\r\ncase 0x4b:\r\nnv_wr32(dev, 0x002230, 0x00000001);\r\ncase 0x40:\r\ncase 0x41:\r\ncase 0x42:\r\ncase 0x43:\r\ncase 0x45:\r\ncase 0x48:\r\nnv_wr32(dev, 0x002220, 0x00030002);\r\nbreak;\r\ndefault:\r\nnv_wr32(dev, 0x002230, 0x00000000);\r\nnv_wr32(dev, 0x002220, ((dev_priv->vram_size - 512 * 1024 +\r\ndev_priv->ramfc->pinst) >> 16) |\r\n0x00030000);\r\nbreak;\r\n}\r\nnv_wr32(dev, NV03_PFIFO_CACHE1_PUSH1, priv->base.channels);\r\nnv_wr32(dev, NV03_PFIFO_INTR_0, 0xffffffff);\r\nnv_wr32(dev, NV03_PFIFO_INTR_EN_0, 0xffffffff);\r\nnv_wr32(dev, NV03_PFIFO_CACHE1_PUSH0, 1);\r\nnv_wr32(dev, NV04_PFIFO_CACHE1_PULL0, 1);\r\nnv_wr32(dev, NV03_PFIFO_CACHES, 1);\r\nfor (i = 0; i < priv->base.channels; i++) {\r\nif (dev_priv->channels.ptr[i])\r\nnv_mask(dev, NV04_PFIFO_MODE, (1 << i), (1 << i));\r\n}\r\nreturn 0;\r\n}\r\nint\r\nnv40_fifo_create(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nv40_fifo_priv *priv;\r\npriv = kzalloc(sizeof(*priv), GFP_KERNEL);\r\nif (!priv)\r\nreturn -ENOMEM;\r\npriv->base.base.destroy = nv04_fifo_destroy;\r\npriv->base.base.init = nv40_fifo_init;\r\npriv->base.base.fini = nv04_fifo_fini;\r\npriv->base.base.context_new = nv40_fifo_context_new;\r\npriv->base.base.context_del = nv04_fifo_context_del;\r\npriv->base.channels = 31;\r\npriv->ramfc_desc = nv40_ramfc;\r\ndev_priv->eng[NVOBJ_ENGINE_FIFO] = &priv->base.base;\r\nnouveau_irq_register(dev, 8, nv04_fifo_isr);\r\nreturn 0;\r\n}
