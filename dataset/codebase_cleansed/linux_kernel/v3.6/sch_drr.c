static struct drr_class *drr_find_class(struct Qdisc *sch, u32 classid)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct Qdisc_class_common *clc;\r\nclc = qdisc_class_find(&q->clhash, classid);\r\nif (clc == NULL)\r\nreturn NULL;\r\nreturn container_of(clc, struct drr_class, common);\r\n}\r\nstatic void drr_purge_queue(struct drr_class *cl)\r\n{\r\nunsigned int len = cl->qdisc->q.qlen;\r\nqdisc_reset(cl->qdisc);\r\nqdisc_tree_decrease_qlen(cl->qdisc, len);\r\n}\r\nstatic int drr_change_class(struct Qdisc *sch, u32 classid, u32 parentid,\r\nstruct nlattr **tca, unsigned long *arg)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl = (struct drr_class *)*arg;\r\nstruct nlattr *opt = tca[TCA_OPTIONS];\r\nstruct nlattr *tb[TCA_DRR_MAX + 1];\r\nu32 quantum;\r\nint err;\r\nif (!opt)\r\nreturn -EINVAL;\r\nerr = nla_parse_nested(tb, TCA_DRR_MAX, opt, drr_policy);\r\nif (err < 0)\r\nreturn err;\r\nif (tb[TCA_DRR_QUANTUM]) {\r\nquantum = nla_get_u32(tb[TCA_DRR_QUANTUM]);\r\nif (quantum == 0)\r\nreturn -EINVAL;\r\n} else\r\nquantum = psched_mtu(qdisc_dev(sch));\r\nif (cl != NULL) {\r\nif (tca[TCA_RATE]) {\r\nerr = gen_replace_estimator(&cl->bstats, &cl->rate_est,\r\nqdisc_root_sleeping_lock(sch),\r\ntca[TCA_RATE]);\r\nif (err)\r\nreturn err;\r\n}\r\nsch_tree_lock(sch);\r\nif (tb[TCA_DRR_QUANTUM])\r\ncl->quantum = quantum;\r\nsch_tree_unlock(sch);\r\nreturn 0;\r\n}\r\ncl = kzalloc(sizeof(struct drr_class), GFP_KERNEL);\r\nif (cl == NULL)\r\nreturn -ENOBUFS;\r\ncl->refcnt = 1;\r\ncl->common.classid = classid;\r\ncl->quantum = quantum;\r\ncl->qdisc = qdisc_create_dflt(sch->dev_queue,\r\n&pfifo_qdisc_ops, classid);\r\nif (cl->qdisc == NULL)\r\ncl->qdisc = &noop_qdisc;\r\nif (tca[TCA_RATE]) {\r\nerr = gen_replace_estimator(&cl->bstats, &cl->rate_est,\r\nqdisc_root_sleeping_lock(sch),\r\ntca[TCA_RATE]);\r\nif (err) {\r\nqdisc_destroy(cl->qdisc);\r\nkfree(cl);\r\nreturn err;\r\n}\r\n}\r\nsch_tree_lock(sch);\r\nqdisc_class_hash_insert(&q->clhash, &cl->common);\r\nsch_tree_unlock(sch);\r\nqdisc_class_hash_grow(sch, &q->clhash);\r\n*arg = (unsigned long)cl;\r\nreturn 0;\r\n}\r\nstatic void drr_destroy_class(struct Qdisc *sch, struct drr_class *cl)\r\n{\r\ngen_kill_estimator(&cl->bstats, &cl->rate_est);\r\nqdisc_destroy(cl->qdisc);\r\nkfree(cl);\r\n}\r\nstatic int drr_delete_class(struct Qdisc *sch, unsigned long arg)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\nif (cl->filter_cnt > 0)\r\nreturn -EBUSY;\r\nsch_tree_lock(sch);\r\ndrr_purge_queue(cl);\r\nqdisc_class_hash_remove(&q->clhash, &cl->common);\r\nBUG_ON(--cl->refcnt == 0);\r\nsch_tree_unlock(sch);\r\nreturn 0;\r\n}\r\nstatic unsigned long drr_get_class(struct Qdisc *sch, u32 classid)\r\n{\r\nstruct drr_class *cl = drr_find_class(sch, classid);\r\nif (cl != NULL)\r\ncl->refcnt++;\r\nreturn (unsigned long)cl;\r\n}\r\nstatic void drr_put_class(struct Qdisc *sch, unsigned long arg)\r\n{\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\nif (--cl->refcnt == 0)\r\ndrr_destroy_class(sch, cl);\r\n}\r\nstatic struct tcf_proto **drr_tcf_chain(struct Qdisc *sch, unsigned long cl)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nif (cl)\r\nreturn NULL;\r\nreturn &q->filter_list;\r\n}\r\nstatic unsigned long drr_bind_tcf(struct Qdisc *sch, unsigned long parent,\r\nu32 classid)\r\n{\r\nstruct drr_class *cl = drr_find_class(sch, classid);\r\nif (cl != NULL)\r\ncl->filter_cnt++;\r\nreturn (unsigned long)cl;\r\n}\r\nstatic void drr_unbind_tcf(struct Qdisc *sch, unsigned long arg)\r\n{\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\ncl->filter_cnt--;\r\n}\r\nstatic int drr_graft_class(struct Qdisc *sch, unsigned long arg,\r\nstruct Qdisc *new, struct Qdisc **old)\r\n{\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\nif (new == NULL) {\r\nnew = qdisc_create_dflt(sch->dev_queue,\r\n&pfifo_qdisc_ops, cl->common.classid);\r\nif (new == NULL)\r\nnew = &noop_qdisc;\r\n}\r\nsch_tree_lock(sch);\r\ndrr_purge_queue(cl);\r\n*old = cl->qdisc;\r\ncl->qdisc = new;\r\nsch_tree_unlock(sch);\r\nreturn 0;\r\n}\r\nstatic struct Qdisc *drr_class_leaf(struct Qdisc *sch, unsigned long arg)\r\n{\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\nreturn cl->qdisc;\r\n}\r\nstatic void drr_qlen_notify(struct Qdisc *csh, unsigned long arg)\r\n{\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\nif (cl->qdisc->q.qlen == 0)\r\nlist_del(&cl->alist);\r\n}\r\nstatic int drr_dump_class(struct Qdisc *sch, unsigned long arg,\r\nstruct sk_buff *skb, struct tcmsg *tcm)\r\n{\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\nstruct nlattr *nest;\r\ntcm->tcm_parent = TC_H_ROOT;\r\ntcm->tcm_handle = cl->common.classid;\r\ntcm->tcm_info = cl->qdisc->handle;\r\nnest = nla_nest_start(skb, TCA_OPTIONS);\r\nif (nest == NULL)\r\ngoto nla_put_failure;\r\nif (nla_put_u32(skb, TCA_DRR_QUANTUM, cl->quantum))\r\ngoto nla_put_failure;\r\nreturn nla_nest_end(skb, nest);\r\nnla_put_failure:\r\nnla_nest_cancel(skb, nest);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int drr_dump_class_stats(struct Qdisc *sch, unsigned long arg,\r\nstruct gnet_dump *d)\r\n{\r\nstruct drr_class *cl = (struct drr_class *)arg;\r\nstruct tc_drr_stats xstats;\r\nmemset(&xstats, 0, sizeof(xstats));\r\nif (cl->qdisc->q.qlen) {\r\nxstats.deficit = cl->deficit;\r\ncl->qdisc->qstats.qlen = cl->qdisc->q.qlen;\r\n}\r\nif (gnet_stats_copy_basic(d, &cl->bstats) < 0 ||\r\ngnet_stats_copy_rate_est(d, &cl->bstats, &cl->rate_est) < 0 ||\r\ngnet_stats_copy_queue(d, &cl->qdisc->qstats) < 0)\r\nreturn -1;\r\nreturn gnet_stats_copy_app(d, &xstats, sizeof(xstats));\r\n}\r\nstatic void drr_walk(struct Qdisc *sch, struct qdisc_walker *arg)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl;\r\nstruct hlist_node *n;\r\nunsigned int i;\r\nif (arg->stop)\r\nreturn;\r\nfor (i = 0; i < q->clhash.hashsize; i++) {\r\nhlist_for_each_entry(cl, n, &q->clhash.hash[i], common.hnode) {\r\nif (arg->count < arg->skip) {\r\narg->count++;\r\ncontinue;\r\n}\r\nif (arg->fn(sch, (unsigned long)cl, arg) < 0) {\r\narg->stop = 1;\r\nreturn;\r\n}\r\narg->count++;\r\n}\r\n}\r\n}\r\nstatic struct drr_class *drr_classify(struct sk_buff *skb, struct Qdisc *sch,\r\nint *qerr)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl;\r\nstruct tcf_result res;\r\nint result;\r\nif (TC_H_MAJ(skb->priority ^ sch->handle) == 0) {\r\ncl = drr_find_class(sch, skb->priority);\r\nif (cl != NULL)\r\nreturn cl;\r\n}\r\n*qerr = NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\r\nresult = tc_classify(skb, q->filter_list, &res);\r\nif (result >= 0) {\r\n#ifdef CONFIG_NET_CLS_ACT\r\nswitch (result) {\r\ncase TC_ACT_QUEUED:\r\ncase TC_ACT_STOLEN:\r\n*qerr = NET_XMIT_SUCCESS | __NET_XMIT_STOLEN;\r\ncase TC_ACT_SHOT:\r\nreturn NULL;\r\n}\r\n#endif\r\ncl = (struct drr_class *)res.class;\r\nif (cl == NULL)\r\ncl = drr_find_class(sch, res.classid);\r\nreturn cl;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int drr_enqueue(struct sk_buff *skb, struct Qdisc *sch)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl;\r\nint err;\r\ncl = drr_classify(skb, sch, &err);\r\nif (cl == NULL) {\r\nif (err & __NET_XMIT_BYPASS)\r\nsch->qstats.drops++;\r\nkfree_skb(skb);\r\nreturn err;\r\n}\r\nerr = qdisc_enqueue(skb, cl->qdisc);\r\nif (unlikely(err != NET_XMIT_SUCCESS)) {\r\nif (net_xmit_drop_count(err)) {\r\ncl->qstats.drops++;\r\nsch->qstats.drops++;\r\n}\r\nreturn err;\r\n}\r\nif (cl->qdisc->q.qlen == 1) {\r\nlist_add_tail(&cl->alist, &q->active);\r\ncl->deficit = cl->quantum;\r\n}\r\nsch->q.qlen++;\r\nreturn err;\r\n}\r\nstatic struct sk_buff *drr_dequeue(struct Qdisc *sch)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl;\r\nstruct sk_buff *skb;\r\nunsigned int len;\r\nif (list_empty(&q->active))\r\ngoto out;\r\nwhile (1) {\r\ncl = list_first_entry(&q->active, struct drr_class, alist);\r\nskb = cl->qdisc->ops->peek(cl->qdisc);\r\nif (skb == NULL)\r\ngoto out;\r\nlen = qdisc_pkt_len(skb);\r\nif (len <= cl->deficit) {\r\ncl->deficit -= len;\r\nskb = qdisc_dequeue_peeked(cl->qdisc);\r\nif (cl->qdisc->q.qlen == 0)\r\nlist_del(&cl->alist);\r\nbstats_update(&cl->bstats, skb);\r\nqdisc_bstats_update(sch, skb);\r\nsch->q.qlen--;\r\nreturn skb;\r\n}\r\ncl->deficit += cl->quantum;\r\nlist_move_tail(&cl->alist, &q->active);\r\n}\r\nout:\r\nreturn NULL;\r\n}\r\nstatic unsigned int drr_drop(struct Qdisc *sch)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl;\r\nunsigned int len;\r\nlist_for_each_entry(cl, &q->active, alist) {\r\nif (cl->qdisc->ops->drop) {\r\nlen = cl->qdisc->ops->drop(cl->qdisc);\r\nif (len > 0) {\r\nsch->q.qlen--;\r\nif (cl->qdisc->q.qlen == 0)\r\nlist_del(&cl->alist);\r\nreturn len;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int drr_init_qdisc(struct Qdisc *sch, struct nlattr *opt)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nint err;\r\nerr = qdisc_class_hash_init(&q->clhash);\r\nif (err < 0)\r\nreturn err;\r\nINIT_LIST_HEAD(&q->active);\r\nreturn 0;\r\n}\r\nstatic void drr_reset_qdisc(struct Qdisc *sch)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl;\r\nstruct hlist_node *n;\r\nunsigned int i;\r\nfor (i = 0; i < q->clhash.hashsize; i++) {\r\nhlist_for_each_entry(cl, n, &q->clhash.hash[i], common.hnode) {\r\nif (cl->qdisc->q.qlen)\r\nlist_del(&cl->alist);\r\nqdisc_reset(cl->qdisc);\r\n}\r\n}\r\nsch->q.qlen = 0;\r\n}\r\nstatic void drr_destroy_qdisc(struct Qdisc *sch)\r\n{\r\nstruct drr_sched *q = qdisc_priv(sch);\r\nstruct drr_class *cl;\r\nstruct hlist_node *n, *next;\r\nunsigned int i;\r\ntcf_destroy_chain(&q->filter_list);\r\nfor (i = 0; i < q->clhash.hashsize; i++) {\r\nhlist_for_each_entry_safe(cl, n, next, &q->clhash.hash[i],\r\ncommon.hnode)\r\ndrr_destroy_class(sch, cl);\r\n}\r\nqdisc_class_hash_destroy(&q->clhash);\r\n}\r\nstatic int __init drr_init(void)\r\n{\r\nreturn register_qdisc(&drr_qdisc_ops);\r\n}\r\nstatic void __exit drr_exit(void)\r\n{\r\nunregister_qdisc(&drr_qdisc_ops);\r\n}
