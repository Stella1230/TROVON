void\r\nfile_ra_state_init(struct file_ra_state *ra, struct address_space *mapping)\r\n{\r\nra->ra_pages = mapping->backing_dev_info->ra_pages;\r\nra->prev_pos = -1;\r\n}\r\nstatic void read_cache_pages_invalidate_page(struct address_space *mapping,\r\nstruct page *page)\r\n{\r\nif (page_has_private(page)) {\r\nif (!trylock_page(page))\r\nBUG();\r\npage->mapping = mapping;\r\ndo_invalidatepage(page, 0);\r\npage->mapping = NULL;\r\nunlock_page(page);\r\n}\r\npage_cache_release(page);\r\n}\r\nstatic void read_cache_pages_invalidate_pages(struct address_space *mapping,\r\nstruct list_head *pages)\r\n{\r\nstruct page *victim;\r\nwhile (!list_empty(pages)) {\r\nvictim = list_to_page(pages);\r\nlist_del(&victim->lru);\r\nread_cache_pages_invalidate_page(mapping, victim);\r\n}\r\n}\r\nint read_cache_pages(struct address_space *mapping, struct list_head *pages,\r\nint (*filler)(void *, struct page *), void *data)\r\n{\r\nstruct page *page;\r\nint ret = 0;\r\nwhile (!list_empty(pages)) {\r\npage = list_to_page(pages);\r\nlist_del(&page->lru);\r\nif (add_to_page_cache_lru(page, mapping,\r\npage->index, GFP_KERNEL)) {\r\nread_cache_pages_invalidate_page(mapping, page);\r\ncontinue;\r\n}\r\npage_cache_release(page);\r\nret = filler(data, page);\r\nif (unlikely(ret)) {\r\nread_cache_pages_invalidate_pages(mapping, pages);\r\nbreak;\r\n}\r\ntask_io_account_read(PAGE_CACHE_SIZE);\r\n}\r\nreturn ret;\r\n}\r\nstatic int read_pages(struct address_space *mapping, struct file *filp,\r\nstruct list_head *pages, unsigned nr_pages)\r\n{\r\nstruct blk_plug plug;\r\nunsigned page_idx;\r\nint ret;\r\nblk_start_plug(&plug);\r\nif (mapping->a_ops->readpages) {\r\nret = mapping->a_ops->readpages(filp, mapping, pages, nr_pages);\r\nput_pages_list(pages);\r\ngoto out;\r\n}\r\nfor (page_idx = 0; page_idx < nr_pages; page_idx++) {\r\nstruct page *page = list_to_page(pages);\r\nlist_del(&page->lru);\r\nif (!add_to_page_cache_lru(page, mapping,\r\npage->index, GFP_KERNEL)) {\r\nmapping->a_ops->readpage(filp, page);\r\n}\r\npage_cache_release(page);\r\n}\r\nret = 0;\r\nout:\r\nblk_finish_plug(&plug);\r\nreturn ret;\r\n}\r\nstatic int\r\n__do_page_cache_readahead(struct address_space *mapping, struct file *filp,\r\npgoff_t offset, unsigned long nr_to_read,\r\nunsigned long lookahead_size)\r\n{\r\nstruct inode *inode = mapping->host;\r\nstruct page *page;\r\nunsigned long end_index;\r\nLIST_HEAD(page_pool);\r\nint page_idx;\r\nint ret = 0;\r\nloff_t isize = i_size_read(inode);\r\nif (isize == 0)\r\ngoto out;\r\nend_index = ((isize - 1) >> PAGE_CACHE_SHIFT);\r\nfor (page_idx = 0; page_idx < nr_to_read; page_idx++) {\r\npgoff_t page_offset = offset + page_idx;\r\nif (page_offset > end_index)\r\nbreak;\r\nrcu_read_lock();\r\npage = radix_tree_lookup(&mapping->page_tree, page_offset);\r\nrcu_read_unlock();\r\nif (page)\r\ncontinue;\r\npage = page_cache_alloc_readahead(mapping);\r\nif (!page)\r\nbreak;\r\npage->index = page_offset;\r\nlist_add(&page->lru, &page_pool);\r\nif (page_idx == nr_to_read - lookahead_size)\r\nSetPageReadahead(page);\r\nret++;\r\n}\r\nif (ret)\r\nread_pages(mapping, filp, &page_pool, ret);\r\nBUG_ON(!list_empty(&page_pool));\r\nout:\r\nreturn ret;\r\n}\r\nint force_page_cache_readahead(struct address_space *mapping, struct file *filp,\r\npgoff_t offset, unsigned long nr_to_read)\r\n{\r\nint ret = 0;\r\nif (unlikely(!mapping->a_ops->readpage && !mapping->a_ops->readpages))\r\nreturn -EINVAL;\r\nnr_to_read = max_sane_readahead(nr_to_read);\r\nwhile (nr_to_read) {\r\nint err;\r\nunsigned long this_chunk = (2 * 1024 * 1024) / PAGE_CACHE_SIZE;\r\nif (this_chunk > nr_to_read)\r\nthis_chunk = nr_to_read;\r\nerr = __do_page_cache_readahead(mapping, filp,\r\noffset, this_chunk, 0);\r\nif (err < 0) {\r\nret = err;\r\nbreak;\r\n}\r\nret += err;\r\noffset += this_chunk;\r\nnr_to_read -= this_chunk;\r\n}\r\nreturn ret;\r\n}\r\nunsigned long max_sane_readahead(unsigned long nr)\r\n{\r\nreturn min(nr, (node_page_state(numa_node_id(), NR_INACTIVE_FILE)\r\n+ node_page_state(numa_node_id(), NR_FREE_PAGES)) / 2);\r\n}\r\nunsigned long ra_submit(struct file_ra_state *ra,\r\nstruct address_space *mapping, struct file *filp)\r\n{\r\nint actual;\r\nactual = __do_page_cache_readahead(mapping, filp,\r\nra->start, ra->size, ra->async_size);\r\nreturn actual;\r\n}\r\nstatic unsigned long get_init_ra_size(unsigned long size, unsigned long max)\r\n{\r\nunsigned long newsize = roundup_pow_of_two(size);\r\nif (newsize <= max / 32)\r\nnewsize = newsize * 4;\r\nelse if (newsize <= max / 4)\r\nnewsize = newsize * 2;\r\nelse\r\nnewsize = max;\r\nreturn newsize;\r\n}\r\nstatic unsigned long get_next_ra_size(struct file_ra_state *ra,\r\nunsigned long max)\r\n{\r\nunsigned long cur = ra->size;\r\nunsigned long newsize;\r\nif (cur < max / 16)\r\nnewsize = 4 * cur;\r\nelse\r\nnewsize = 2 * cur;\r\nreturn min(newsize, max);\r\n}\r\nstatic pgoff_t count_history_pages(struct address_space *mapping,\r\nstruct file_ra_state *ra,\r\npgoff_t offset, unsigned long max)\r\n{\r\npgoff_t head;\r\nrcu_read_lock();\r\nhead = radix_tree_prev_hole(&mapping->page_tree, offset - 1, max);\r\nrcu_read_unlock();\r\nreturn offset - 1 - head;\r\n}\r\nstatic int try_context_readahead(struct address_space *mapping,\r\nstruct file_ra_state *ra,\r\npgoff_t offset,\r\nunsigned long req_size,\r\nunsigned long max)\r\n{\r\npgoff_t size;\r\nsize = count_history_pages(mapping, ra, offset, max);\r\nif (!size)\r\nreturn 0;\r\nif (size >= offset)\r\nsize *= 2;\r\nra->start = offset;\r\nra->size = get_init_ra_size(size + req_size, max);\r\nra->async_size = ra->size;\r\nreturn 1;\r\n}\r\nstatic unsigned long\r\nondemand_readahead(struct address_space *mapping,\r\nstruct file_ra_state *ra, struct file *filp,\r\nbool hit_readahead_marker, pgoff_t offset,\r\nunsigned long req_size)\r\n{\r\nunsigned long max = max_sane_readahead(ra->ra_pages);\r\nif (!offset)\r\ngoto initial_readahead;\r\nif ((offset == (ra->start + ra->size - ra->async_size) ||\r\noffset == (ra->start + ra->size))) {\r\nra->start += ra->size;\r\nra->size = get_next_ra_size(ra, max);\r\nra->async_size = ra->size;\r\ngoto readit;\r\n}\r\nif (hit_readahead_marker) {\r\npgoff_t start;\r\nrcu_read_lock();\r\nstart = radix_tree_next_hole(&mapping->page_tree, offset+1,max);\r\nrcu_read_unlock();\r\nif (!start || start - offset > max)\r\nreturn 0;\r\nra->start = start;\r\nra->size = start - offset;\r\nra->size += req_size;\r\nra->size = get_next_ra_size(ra, max);\r\nra->async_size = ra->size;\r\ngoto readit;\r\n}\r\nif (req_size > max)\r\ngoto initial_readahead;\r\nif (offset - (ra->prev_pos >> PAGE_CACHE_SHIFT) <= 1UL)\r\ngoto initial_readahead;\r\nif (try_context_readahead(mapping, ra, offset, req_size, max))\r\ngoto readit;\r\nreturn __do_page_cache_readahead(mapping, filp, offset, req_size, 0);\r\ninitial_readahead:\r\nra->start = offset;\r\nra->size = get_init_ra_size(req_size, max);\r\nra->async_size = ra->size > req_size ? ra->size - req_size : ra->size;\r\nreadit:\r\nif (offset == ra->start && ra->size == ra->async_size) {\r\nra->async_size = get_next_ra_size(ra, max);\r\nra->size += ra->async_size;\r\n}\r\nreturn ra_submit(ra, mapping, filp);\r\n}\r\nvoid page_cache_sync_readahead(struct address_space *mapping,\r\nstruct file_ra_state *ra, struct file *filp,\r\npgoff_t offset, unsigned long req_size)\r\n{\r\nif (!ra->ra_pages)\r\nreturn;\r\nif (filp && (filp->f_mode & FMODE_RANDOM)) {\r\nforce_page_cache_readahead(mapping, filp, offset, req_size);\r\nreturn;\r\n}\r\nondemand_readahead(mapping, ra, filp, false, offset, req_size);\r\n}\r\nvoid\r\npage_cache_async_readahead(struct address_space *mapping,\r\nstruct file_ra_state *ra, struct file *filp,\r\nstruct page *page, pgoff_t offset,\r\nunsigned long req_size)\r\n{\r\nif (!ra->ra_pages)\r\nreturn;\r\nif (PageWriteback(page))\r\nreturn;\r\nClearPageReadahead(page);\r\nif (bdi_read_congested(mapping->backing_dev_info))\r\nreturn;\r\nondemand_readahead(mapping, ra, filp, true, offset, req_size);\r\n}\r\nstatic ssize_t\r\ndo_readahead(struct address_space *mapping, struct file *filp,\r\npgoff_t index, unsigned long nr)\r\n{\r\nif (!mapping || !mapping->a_ops || !mapping->a_ops->readpage)\r\nreturn -EINVAL;\r\nforce_page_cache_readahead(mapping, filp, index, nr);\r\nreturn 0;\r\n}\r\nSYSCALL_DEFINE(readahead)(int fd, loff_t offset, size_t count)\r\n{\r\nssize_t ret;\r\nstruct file *file;\r\nret = -EBADF;\r\nfile = fget(fd);\r\nif (file) {\r\nif (file->f_mode & FMODE_READ) {\r\nstruct address_space *mapping = file->f_mapping;\r\npgoff_t start = offset >> PAGE_CACHE_SHIFT;\r\npgoff_t end = (offset + count - 1) >> PAGE_CACHE_SHIFT;\r\nunsigned long len = end - start + 1;\r\nret = do_readahead(mapping, file, start, len);\r\n}\r\nfput(file);\r\n}\r\nreturn ret;\r\n}\r\nasmlinkage long SyS_readahead(long fd, loff_t offset, long count)\r\n{\r\nreturn SYSC_readahead((int) fd, offset, (size_t) count);\r\n}
