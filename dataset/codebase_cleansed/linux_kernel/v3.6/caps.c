static char *gcap_string(char *s, int c)\r\n{\r\nif (c & CEPH_CAP_GSHARED)\r\n*s++ = 's';\r\nif (c & CEPH_CAP_GEXCL)\r\n*s++ = 'x';\r\nif (c & CEPH_CAP_GCACHE)\r\n*s++ = 'c';\r\nif (c & CEPH_CAP_GRD)\r\n*s++ = 'r';\r\nif (c & CEPH_CAP_GWR)\r\n*s++ = 'w';\r\nif (c & CEPH_CAP_GBUFFER)\r\n*s++ = 'b';\r\nif (c & CEPH_CAP_GLAZYIO)\r\n*s++ = 'l';\r\nreturn s;\r\n}\r\nconst char *ceph_cap_string(int caps)\r\n{\r\nint i;\r\nchar *s;\r\nint c;\r\nspin_lock(&cap_str_lock);\r\ni = last_cap_str++;\r\nif (last_cap_str == MAX_CAP_STR)\r\nlast_cap_str = 0;\r\nspin_unlock(&cap_str_lock);\r\ns = cap_str[i];\r\nif (caps & CEPH_CAP_PIN)\r\n*s++ = 'p';\r\nc = (caps >> CEPH_CAP_SAUTH) & 3;\r\nif (c) {\r\n*s++ = 'A';\r\ns = gcap_string(s, c);\r\n}\r\nc = (caps >> CEPH_CAP_SLINK) & 3;\r\nif (c) {\r\n*s++ = 'L';\r\ns = gcap_string(s, c);\r\n}\r\nc = (caps >> CEPH_CAP_SXATTR) & 3;\r\nif (c) {\r\n*s++ = 'X';\r\ns = gcap_string(s, c);\r\n}\r\nc = caps >> CEPH_CAP_SFILE;\r\nif (c) {\r\n*s++ = 'F';\r\ns = gcap_string(s, c);\r\n}\r\nif (s == cap_str[i])\r\n*s++ = '-';\r\n*s = 0;\r\nreturn cap_str[i];\r\n}\r\nvoid ceph_caps_init(struct ceph_mds_client *mdsc)\r\n{\r\nINIT_LIST_HEAD(&mdsc->caps_list);\r\nspin_lock_init(&mdsc->caps_list_lock);\r\n}\r\nvoid ceph_caps_finalize(struct ceph_mds_client *mdsc)\r\n{\r\nstruct ceph_cap *cap;\r\nspin_lock(&mdsc->caps_list_lock);\r\nwhile (!list_empty(&mdsc->caps_list)) {\r\ncap = list_first_entry(&mdsc->caps_list,\r\nstruct ceph_cap, caps_item);\r\nlist_del(&cap->caps_item);\r\nkmem_cache_free(ceph_cap_cachep, cap);\r\n}\r\nmdsc->caps_total_count = 0;\r\nmdsc->caps_avail_count = 0;\r\nmdsc->caps_use_count = 0;\r\nmdsc->caps_reserve_count = 0;\r\nmdsc->caps_min_count = 0;\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nvoid ceph_adjust_min_caps(struct ceph_mds_client *mdsc, int delta)\r\n{\r\nspin_lock(&mdsc->caps_list_lock);\r\nmdsc->caps_min_count += delta;\r\nBUG_ON(mdsc->caps_min_count < 0);\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nint ceph_reserve_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_cap_reservation *ctx, int need)\r\n{\r\nint i;\r\nstruct ceph_cap *cap;\r\nint have;\r\nint alloc = 0;\r\nLIST_HEAD(newcaps);\r\nint ret = 0;\r\ndout("reserve caps ctx=%p need=%d\n", ctx, need);\r\nspin_lock(&mdsc->caps_list_lock);\r\nif (mdsc->caps_avail_count >= need)\r\nhave = need;\r\nelse\r\nhave = mdsc->caps_avail_count;\r\nmdsc->caps_avail_count -= have;\r\nmdsc->caps_reserve_count += have;\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count +\r\nmdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\nfor (i = have; i < need; i++) {\r\ncap = kmem_cache_alloc(ceph_cap_cachep, GFP_NOFS);\r\nif (!cap) {\r\nret = -ENOMEM;\r\ngoto out_alloc_count;\r\n}\r\nlist_add(&cap->caps_item, &newcaps);\r\nalloc++;\r\n}\r\nBUG_ON(have + alloc != need);\r\nspin_lock(&mdsc->caps_list_lock);\r\nmdsc->caps_total_count += alloc;\r\nmdsc->caps_reserve_count += alloc;\r\nlist_splice(&newcaps, &mdsc->caps_list);\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count +\r\nmdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\nctx->count = need;\r\ndout("reserve caps ctx=%p %d = %d used + %d resv + %d avail\n",\r\nctx, mdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\nreturn 0;\r\nout_alloc_count:\r\npr_warning("reserve caps ctx=%p ENOMEM need=%d got=%d\n",\r\nctx, need, have);\r\nreturn ret;\r\n}\r\nint ceph_unreserve_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_cap_reservation *ctx)\r\n{\r\ndout("unreserve caps ctx=%p count=%d\n", ctx, ctx->count);\r\nif (ctx->count) {\r\nspin_lock(&mdsc->caps_list_lock);\r\nBUG_ON(mdsc->caps_reserve_count < ctx->count);\r\nmdsc->caps_reserve_count -= ctx->count;\r\nmdsc->caps_avail_count += ctx->count;\r\nctx->count = 0;\r\ndout("unreserve caps %d = %d used + %d resv + %d avail\n",\r\nmdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count +\r\nmdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nreturn 0;\r\n}\r\nstatic struct ceph_cap *get_cap(struct ceph_mds_client *mdsc,\r\nstruct ceph_cap_reservation *ctx)\r\n{\r\nstruct ceph_cap *cap = NULL;\r\nif (!ctx) {\r\ncap = kmem_cache_alloc(ceph_cap_cachep, GFP_NOFS);\r\nif (cap) {\r\nmdsc->caps_use_count++;\r\nmdsc->caps_total_count++;\r\n}\r\nreturn cap;\r\n}\r\nspin_lock(&mdsc->caps_list_lock);\r\ndout("get_cap ctx=%p (%d) %d = %d used + %d resv + %d avail\n",\r\nctx, ctx->count, mdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\nBUG_ON(!ctx->count);\r\nBUG_ON(ctx->count > mdsc->caps_reserve_count);\r\nBUG_ON(list_empty(&mdsc->caps_list));\r\nctx->count--;\r\nmdsc->caps_reserve_count--;\r\nmdsc->caps_use_count++;\r\ncap = list_first_entry(&mdsc->caps_list, struct ceph_cap, caps_item);\r\nlist_del(&cap->caps_item);\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count + mdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\nreturn cap;\r\n}\r\nvoid ceph_put_cap(struct ceph_mds_client *mdsc, struct ceph_cap *cap)\r\n{\r\nspin_lock(&mdsc->caps_list_lock);\r\ndout("put_cap %p %d = %d used + %d resv + %d avail\n",\r\ncap, mdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\nmdsc->caps_use_count--;\r\nif (mdsc->caps_avail_count >= mdsc->caps_reserve_count +\r\nmdsc->caps_min_count) {\r\nmdsc->caps_total_count--;\r\nkmem_cache_free(ceph_cap_cachep, cap);\r\n} else {\r\nmdsc->caps_avail_count++;\r\nlist_add(&cap->caps_item, &mdsc->caps_list);\r\n}\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count + mdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nvoid ceph_reservation_status(struct ceph_fs_client *fsc,\r\nint *total, int *avail, int *used, int *reserved,\r\nint *min)\r\n{\r\nstruct ceph_mds_client *mdsc = fsc->mdsc;\r\nif (total)\r\n*total = mdsc->caps_total_count;\r\nif (avail)\r\n*avail = mdsc->caps_avail_count;\r\nif (used)\r\n*used = mdsc->caps_use_count;\r\nif (reserved)\r\n*reserved = mdsc->caps_reserve_count;\r\nif (min)\r\n*min = mdsc->caps_min_count;\r\n}\r\nstatic struct ceph_cap *__get_cap_for_mds(struct ceph_inode_info *ci, int mds)\r\n{\r\nstruct ceph_cap *cap;\r\nstruct rb_node *n = ci->i_caps.rb_node;\r\nwhile (n) {\r\ncap = rb_entry(n, struct ceph_cap, ci_node);\r\nif (mds < cap->mds)\r\nn = n->rb_left;\r\nelse if (mds > cap->mds)\r\nn = n->rb_right;\r\nelse\r\nreturn cap;\r\n}\r\nreturn NULL;\r\n}\r\nstruct ceph_cap *ceph_get_cap_for_mds(struct ceph_inode_info *ci, int mds)\r\n{\r\nstruct ceph_cap *cap;\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = __get_cap_for_mds(ci, mds);\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn cap;\r\n}\r\nstatic int __ceph_get_cap_mds(struct ceph_inode_info *ci)\r\n{\r\nstruct ceph_cap *cap;\r\nint mds = -1;\r\nstruct rb_node *p;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nmds = cap->mds;\r\nif (cap->issued & (CEPH_CAP_FILE_WR |\r\nCEPH_CAP_FILE_BUFFER |\r\nCEPH_CAP_FILE_EXCL))\r\nbreak;\r\n}\r\nreturn mds;\r\n}\r\nint ceph_get_cap_mds(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds;\r\nspin_lock(&ci->i_ceph_lock);\r\nmds = __ceph_get_cap_mds(ceph_inode(inode));\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn mds;\r\n}\r\nstatic void __insert_cap_node(struct ceph_inode_info *ci,\r\nstruct ceph_cap *new)\r\n{\r\nstruct rb_node **p = &ci->i_caps.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_cap *cap = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\ncap = rb_entry(parent, struct ceph_cap, ci_node);\r\nif (new->mds < cap->mds)\r\np = &(*p)->rb_left;\r\nelse if (new->mds > cap->mds)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->ci_node, parent, p);\r\nrb_insert_color(&new->ci_node, &ci->i_caps);\r\n}\r\nstatic void __cap_set_timeouts(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\nstruct ceph_mount_options *ma = mdsc->fsc->mount_options;\r\nci->i_hold_caps_min = round_jiffies(jiffies +\r\nma->caps_wanted_delay_min * HZ);\r\nci->i_hold_caps_max = round_jiffies(jiffies +\r\nma->caps_wanted_delay_max * HZ);\r\ndout("__cap_set_timeouts %p min %lu max %lu\n", &ci->vfs_inode,\r\nci->i_hold_caps_min - jiffies, ci->i_hold_caps_max - jiffies);\r\n}\r\nstatic void __cap_delay_requeue(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\n__cap_set_timeouts(mdsc, ci);\r\ndout("__cap_delay_requeue %p flags %d at %lu\n", &ci->vfs_inode,\r\nci->i_ceph_flags, ci->i_hold_caps_max);\r\nif (!mdsc->stopping) {\r\nspin_lock(&mdsc->cap_delay_lock);\r\nif (!list_empty(&ci->i_cap_delay_list)) {\r\nif (ci->i_ceph_flags & CEPH_I_FLUSH)\r\ngoto no_change;\r\nlist_del_init(&ci->i_cap_delay_list);\r\n}\r\nlist_add_tail(&ci->i_cap_delay_list, &mdsc->cap_delay_list);\r\nno_change:\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\n}\r\nstatic void __cap_delay_requeue_front(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\ndout("__cap_delay_requeue_front %p\n", &ci->vfs_inode);\r\nspin_lock(&mdsc->cap_delay_lock);\r\nci->i_ceph_flags |= CEPH_I_FLUSH;\r\nif (!list_empty(&ci->i_cap_delay_list))\r\nlist_del_init(&ci->i_cap_delay_list);\r\nlist_add(&ci->i_cap_delay_list, &mdsc->cap_delay_list);\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\nstatic void __cap_delay_cancel(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\ndout("__cap_delay_cancel %p\n", &ci->vfs_inode);\r\nif (list_empty(&ci->i_cap_delay_list))\r\nreturn;\r\nspin_lock(&mdsc->cap_delay_lock);\r\nlist_del_init(&ci->i_cap_delay_list);\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\nstatic void __check_cap_issue(struct ceph_inode_info *ci, struct ceph_cap *cap,\r\nunsigned issued)\r\n{\r\nunsigned had = __ceph_caps_issued(ci, NULL);\r\nif ((issued & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)) &&\r\n(had & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)) == 0)\r\nci->i_rdcache_gen++;\r\nif ((issued & CEPH_CAP_FILE_SHARED) &&\r\n(had & CEPH_CAP_FILE_SHARED) == 0) {\r\nci->i_shared_gen++;\r\nif (S_ISDIR(ci->vfs_inode.i_mode))\r\nceph_dir_clear_complete(&ci->vfs_inode);\r\n}\r\n}\r\nint ceph_add_cap(struct inode *inode,\r\nstruct ceph_mds_session *session, u64 cap_id,\r\nint fmode, unsigned issued, unsigned wanted,\r\nunsigned seq, unsigned mseq, u64 realmino, int flags,\r\nstruct ceph_cap_reservation *caps_reservation)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap *new_cap = NULL;\r\nstruct ceph_cap *cap;\r\nint mds = session->s_mds;\r\nint actual_wanted;\r\ndout("add_cap %p mds%d cap %llx %s seq %d\n", inode,\r\nsession->s_mds, cap_id, ceph_cap_string(issued), seq);\r\nif (fmode >= 0)\r\nwanted |= ceph_caps_for_mode(fmode);\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = __get_cap_for_mds(ci, mds);\r\nif (!cap) {\r\nif (new_cap) {\r\ncap = new_cap;\r\nnew_cap = NULL;\r\n} else {\r\nspin_unlock(&ci->i_ceph_lock);\r\nnew_cap = get_cap(mdsc, caps_reservation);\r\nif (new_cap == NULL)\r\nreturn -ENOMEM;\r\ngoto retry;\r\n}\r\ncap->issued = 0;\r\ncap->implemented = 0;\r\ncap->mds = mds;\r\ncap->mds_wanted = 0;\r\ncap->ci = ci;\r\n__insert_cap_node(ci, cap);\r\nif (ci->i_cap_exporting_mds == mds) {\r\nci->i_cap_exporting_issued = 0;\r\nci->i_cap_exporting_mseq = 0;\r\nci->i_cap_exporting_mds = -1;\r\n}\r\ncap->session = session;\r\nspin_lock(&session->s_cap_lock);\r\nlist_add_tail(&cap->session_caps, &session->s_caps);\r\nsession->s_nr_caps++;\r\nspin_unlock(&session->s_cap_lock);\r\n} else if (new_cap)\r\nceph_put_cap(mdsc, new_cap);\r\nif (!ci->i_snap_realm) {\r\nstruct ceph_snap_realm *realm = ceph_lookup_snap_realm(mdsc,\r\nrealmino);\r\nif (realm) {\r\nceph_get_snap_realm(mdsc, realm);\r\nspin_lock(&realm->inodes_with_caps_lock);\r\nci->i_snap_realm = realm;\r\nlist_add(&ci->i_snap_realm_item,\r\n&realm->inodes_with_caps);\r\nspin_unlock(&realm->inodes_with_caps_lock);\r\n} else {\r\npr_err("ceph_add_cap: couldn't find snap realm %llx\n",\r\nrealmino);\r\nWARN_ON(!realm);\r\n}\r\n}\r\n__check_cap_issue(ci, cap, issued);\r\nactual_wanted = __ceph_caps_wanted(ci);\r\nif ((wanted & ~actual_wanted) ||\r\n(issued & ~actual_wanted & CEPH_CAP_ANY_WR)) {\r\ndout(" issued %s, mds wanted %s, actual %s, queueing\n",\r\nceph_cap_string(issued), ceph_cap_string(wanted),\r\nceph_cap_string(actual_wanted));\r\n__cap_delay_requeue(mdsc, ci);\r\n}\r\nif (flags & CEPH_CAP_FLAG_AUTH)\r\nci->i_auth_cap = cap;\r\nelse if (ci->i_auth_cap == cap)\r\nci->i_auth_cap = NULL;\r\ndout("add_cap inode %p (%llx.%llx) cap %p %s now %s seq %d mds%d\n",\r\ninode, ceph_vinop(inode), cap, ceph_cap_string(issued),\r\nceph_cap_string(issued|cap->issued), seq, mds);\r\ncap->cap_id = cap_id;\r\ncap->issued = issued;\r\ncap->implemented |= issued;\r\ncap->mds_wanted |= wanted;\r\ncap->seq = seq;\r\ncap->issue_seq = seq;\r\ncap->mseq = mseq;\r\ncap->cap_gen = session->s_cap_gen;\r\nif (fmode >= 0)\r\n__ceph_get_fmode(ci, fmode);\r\nspin_unlock(&ci->i_ceph_lock);\r\nwake_up_all(&ci->i_cap_wq);\r\nreturn 0;\r\n}\r\nstatic int __cap_is_valid(struct ceph_cap *cap)\r\n{\r\nunsigned long ttl;\r\nu32 gen;\r\nspin_lock(&cap->session->s_gen_ttl_lock);\r\ngen = cap->session->s_cap_gen;\r\nttl = cap->session->s_cap_ttl;\r\nspin_unlock(&cap->session->s_gen_ttl_lock);\r\nif (cap->cap_gen < gen || time_after_eq(jiffies, ttl)) {\r\ndout("__cap_is_valid %p cap %p issued %s "\r\n"but STALE (gen %u vs %u)\n", &cap->ci->vfs_inode,\r\ncap, ceph_cap_string(cap->issued), cap->cap_gen, gen);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nint __ceph_caps_issued(struct ceph_inode_info *ci, int *implemented)\r\n{\r\nint have = ci->i_snap_caps | ci->i_cap_exporting_issued;\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nif (implemented)\r\n*implemented = 0;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\ndout("__ceph_caps_issued %p cap %p issued %s\n",\r\n&ci->vfs_inode, cap, ceph_cap_string(cap->issued));\r\nhave |= cap->issued;\r\nif (implemented)\r\n*implemented |= cap->implemented;\r\n}\r\nreturn have;\r\n}\r\nint __ceph_caps_issued_other(struct ceph_inode_info *ci, struct ceph_cap *ocap)\r\n{\r\nint have = ci->i_snap_caps;\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (cap == ocap)\r\ncontinue;\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\nhave |= cap->issued;\r\n}\r\nreturn have;\r\n}\r\nstatic void __touch_cap(struct ceph_cap *cap)\r\n{\r\nstruct ceph_mds_session *s = cap->session;\r\nspin_lock(&s->s_cap_lock);\r\nif (s->s_cap_iterator == NULL) {\r\ndout("__touch_cap %p cap %p mds%d\n", &cap->ci->vfs_inode, cap,\r\ns->s_mds);\r\nlist_move_tail(&cap->session_caps, &s->s_caps);\r\n} else {\r\ndout("__touch_cap %p cap %p mds%d NOP, iterating over caps\n",\r\n&cap->ci->vfs_inode, cap, s->s_mds);\r\n}\r\nspin_unlock(&s->s_cap_lock);\r\n}\r\nint __ceph_caps_issued_mask(struct ceph_inode_info *ci, int mask, int touch)\r\n{\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nint have = ci->i_snap_caps;\r\nif ((have & mask) == mask) {\r\ndout("__ceph_caps_issued_mask %p snap issued %s"\r\n" (mask %s)\n", &ci->vfs_inode,\r\nceph_cap_string(have),\r\nceph_cap_string(mask));\r\nreturn 1;\r\n}\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\nif ((cap->issued & mask) == mask) {\r\ndout("__ceph_caps_issued_mask %p cap %p issued %s"\r\n" (mask %s)\n", &ci->vfs_inode, cap,\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(mask));\r\nif (touch)\r\n__touch_cap(cap);\r\nreturn 1;\r\n}\r\nhave |= cap->issued;\r\nif ((have & mask) == mask) {\r\ndout("__ceph_caps_issued_mask %p combo issued %s"\r\n" (mask %s)\n", &ci->vfs_inode,\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(mask));\r\nif (touch) {\r\nstruct rb_node *q;\r\n__touch_cap(cap);\r\nfor (q = rb_first(&ci->i_caps); q != p;\r\nq = rb_next(q)) {\r\ncap = rb_entry(q, struct ceph_cap,\r\nci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\n__touch_cap(cap);\r\n}\r\n}\r\nreturn 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint ceph_caps_revoking(struct ceph_inode_info *ci, int mask)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nint ret = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (__cap_is_valid(cap) &&\r\n(cap->implemented & ~cap->issued & mask)) {\r\nret = 1;\r\nbreak;\r\n}\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\ndout("ceph_caps_revoking %p %s = %d\n", inode,\r\nceph_cap_string(mask), ret);\r\nreturn ret;\r\n}\r\nint __ceph_caps_used(struct ceph_inode_info *ci)\r\n{\r\nint used = 0;\r\nif (ci->i_pin_ref)\r\nused |= CEPH_CAP_PIN;\r\nif (ci->i_rd_ref)\r\nused |= CEPH_CAP_FILE_RD;\r\nif (ci->i_rdcache_ref || ci->vfs_inode.i_data.nrpages)\r\nused |= CEPH_CAP_FILE_CACHE;\r\nif (ci->i_wr_ref)\r\nused |= CEPH_CAP_FILE_WR;\r\nif (ci->i_wb_ref || ci->i_wrbuffer_ref)\r\nused |= CEPH_CAP_FILE_BUFFER;\r\nreturn used;\r\n}\r\nint __ceph_caps_file_wanted(struct ceph_inode_info *ci)\r\n{\r\nint want = 0;\r\nint mode;\r\nfor (mode = 0; mode < CEPH_FILE_MODE_NUM; mode++)\r\nif (ci->i_nr_by_mode[mode])\r\nwant |= ceph_caps_for_mode(mode);\r\nreturn want;\r\n}\r\nint __ceph_caps_mds_wanted(struct ceph_inode_info *ci)\r\n{\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nint mds_wanted = 0;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\nmds_wanted |= cap->mds_wanted;\r\n}\r\nreturn mds_wanted;\r\n}\r\nstatic int __ceph_is_any_caps(struct ceph_inode_info *ci)\r\n{\r\nreturn !RB_EMPTY_ROOT(&ci->i_caps) || ci->i_cap_exporting_mds >= 0;\r\n}\r\nvoid __ceph_remove_cap(struct ceph_cap *cap)\r\n{\r\nstruct ceph_mds_session *session = cap->session;\r\nstruct ceph_inode_info *ci = cap->ci;\r\nstruct ceph_mds_client *mdsc =\r\nceph_sb_to_client(ci->vfs_inode.i_sb)->mdsc;\r\nint removed = 0;\r\ndout("__ceph_remove_cap %p from %p\n", cap, &ci->vfs_inode);\r\nspin_lock(&session->s_cap_lock);\r\nif (session->s_cap_iterator == cap) {\r\ndout("__ceph_remove_cap delaying %p removal from session %p\n",\r\ncap, cap->session);\r\n} else {\r\nlist_del_init(&cap->session_caps);\r\nsession->s_nr_caps--;\r\ncap->session = NULL;\r\nremoved = 1;\r\n}\r\ncap->ci = NULL;\r\nspin_unlock(&session->s_cap_lock);\r\nrb_erase(&cap->ci_node, &ci->i_caps);\r\nif (ci->i_auth_cap == cap)\r\nci->i_auth_cap = NULL;\r\nif (removed)\r\nceph_put_cap(mdsc, cap);\r\nif (!__ceph_is_any_caps(ci) && ci->i_snap_realm) {\r\nstruct ceph_snap_realm *realm = ci->i_snap_realm;\r\nspin_lock(&realm->inodes_with_caps_lock);\r\nlist_del_init(&ci->i_snap_realm_item);\r\nci->i_snap_realm_counter++;\r\nci->i_snap_realm = NULL;\r\nspin_unlock(&realm->inodes_with_caps_lock);\r\nceph_put_snap_realm(mdsc, realm);\r\n}\r\nif (!__ceph_is_any_real_caps(ci))\r\n__cap_delay_cancel(mdsc, ci);\r\n}\r\nstatic int send_cap_msg(struct ceph_mds_session *session,\r\nu64 ino, u64 cid, int op,\r\nint caps, int wanted, int dirty,\r\nu32 seq, u64 flush_tid, u32 issue_seq, u32 mseq,\r\nu64 size, u64 max_size,\r\nstruct timespec *mtime, struct timespec *atime,\r\nu64 time_warp_seq,\r\nuid_t uid, gid_t gid, umode_t mode,\r\nu64 xattr_version,\r\nstruct ceph_buffer *xattrs_buf,\r\nu64 follows)\r\n{\r\nstruct ceph_mds_caps *fc;\r\nstruct ceph_msg *msg;\r\ndout("send_cap_msg %s %llx %llx caps %s wanted %s dirty %s"\r\n" seq %u/%u mseq %u follows %lld size %llu/%llu"\r\n" xattr_ver %llu xattr_len %d\n", ceph_cap_op_name(op),\r\ncid, ino, ceph_cap_string(caps), ceph_cap_string(wanted),\r\nceph_cap_string(dirty),\r\nseq, issue_seq, mseq, follows, size, max_size,\r\nxattr_version, xattrs_buf ? (int)xattrs_buf->vec.iov_len : 0);\r\nmsg = ceph_msg_new(CEPH_MSG_CLIENT_CAPS, sizeof(*fc), GFP_NOFS, false);\r\nif (!msg)\r\nreturn -ENOMEM;\r\nmsg->hdr.tid = cpu_to_le64(flush_tid);\r\nfc = msg->front.iov_base;\r\nmemset(fc, 0, sizeof(*fc));\r\nfc->cap_id = cpu_to_le64(cid);\r\nfc->op = cpu_to_le32(op);\r\nfc->seq = cpu_to_le32(seq);\r\nfc->issue_seq = cpu_to_le32(issue_seq);\r\nfc->migrate_seq = cpu_to_le32(mseq);\r\nfc->caps = cpu_to_le32(caps);\r\nfc->wanted = cpu_to_le32(wanted);\r\nfc->dirty = cpu_to_le32(dirty);\r\nfc->ino = cpu_to_le64(ino);\r\nfc->snap_follows = cpu_to_le64(follows);\r\nfc->size = cpu_to_le64(size);\r\nfc->max_size = cpu_to_le64(max_size);\r\nif (mtime)\r\nceph_encode_timespec(&fc->mtime, mtime);\r\nif (atime)\r\nceph_encode_timespec(&fc->atime, atime);\r\nfc->time_warp_seq = cpu_to_le32(time_warp_seq);\r\nfc->uid = cpu_to_le32(uid);\r\nfc->gid = cpu_to_le32(gid);\r\nfc->mode = cpu_to_le32(mode);\r\nfc->xattr_version = cpu_to_le64(xattr_version);\r\nif (xattrs_buf) {\r\nmsg->middle = ceph_buffer_get(xattrs_buf);\r\nfc->xattr_len = cpu_to_le32(xattrs_buf->vec.iov_len);\r\nmsg->hdr.middle_len = cpu_to_le32(xattrs_buf->vec.iov_len);\r\n}\r\nceph_con_send(&session->s_con, msg);\r\nreturn 0;\r\n}\r\nstatic void __queue_cap_release(struct ceph_mds_session *session,\r\nu64 ino, u64 cap_id, u32 migrate_seq,\r\nu32 issue_seq)\r\n{\r\nstruct ceph_msg *msg;\r\nstruct ceph_mds_cap_release *head;\r\nstruct ceph_mds_cap_item *item;\r\nspin_lock(&session->s_cap_lock);\r\nBUG_ON(!session->s_num_cap_releases);\r\nmsg = list_first_entry(&session->s_cap_releases,\r\nstruct ceph_msg, list_head);\r\ndout(" adding %llx release to mds%d msg %p (%d left)\n",\r\nino, session->s_mds, msg, session->s_num_cap_releases);\r\nBUG_ON(msg->front.iov_len + sizeof(*item) > PAGE_CACHE_SIZE);\r\nhead = msg->front.iov_base;\r\nhead->num = cpu_to_le32(le32_to_cpu(head->num) + 1);\r\nitem = msg->front.iov_base + msg->front.iov_len;\r\nitem->ino = cpu_to_le64(ino);\r\nitem->cap_id = cpu_to_le64(cap_id);\r\nitem->migrate_seq = cpu_to_le32(migrate_seq);\r\nitem->seq = cpu_to_le32(issue_seq);\r\nsession->s_num_cap_releases--;\r\nmsg->front.iov_len += sizeof(*item);\r\nif (le32_to_cpu(head->num) == CEPH_CAPS_PER_RELEASE) {\r\ndout(" release msg %p full\n", msg);\r\nlist_move_tail(&msg->list_head, &session->s_cap_releases_done);\r\n} else {\r\ndout(" release msg %p at %d/%d (%d)\n", msg,\r\n(int)le32_to_cpu(head->num),\r\n(int)CEPH_CAPS_PER_RELEASE,\r\n(int)msg->front.iov_len);\r\n}\r\nspin_unlock(&session->s_cap_lock);\r\n}\r\nvoid ceph_queue_caps_release(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct rb_node *p;\r\np = rb_first(&ci->i_caps);\r\nwhile (p) {\r\nstruct ceph_cap *cap = rb_entry(p, struct ceph_cap, ci_node);\r\nstruct ceph_mds_session *session = cap->session;\r\n__queue_cap_release(session, ceph_ino(inode), cap->cap_id,\r\ncap->mseq, cap->issue_seq);\r\np = rb_next(p);\r\n__ceph_remove_cap(cap);\r\n}\r\n}\r\nstatic int __send_cap(struct ceph_mds_client *mdsc, struct ceph_cap *cap,\r\nint op, int used, int want, int retain, int flushing,\r\nunsigned *pflush_tid)\r\n__releases(cap->ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = cap->ci;\r\nstruct inode *inode = &ci->vfs_inode;\r\nu64 cap_id = cap->cap_id;\r\nint held, revoking, dropping, keep;\r\nu64 seq, issue_seq, mseq, time_warp_seq, follows;\r\nu64 size, max_size;\r\nstruct timespec mtime, atime;\r\nint wake = 0;\r\numode_t mode;\r\nuid_t uid;\r\ngid_t gid;\r\nstruct ceph_mds_session *session;\r\nu64 xattr_version = 0;\r\nstruct ceph_buffer *xattr_blob = NULL;\r\nint delayed = 0;\r\nu64 flush_tid = 0;\r\nint i;\r\nint ret;\r\nheld = cap->issued | cap->implemented;\r\nrevoking = cap->implemented & ~cap->issued;\r\nretain &= ~revoking;\r\ndropping = cap->issued & ~retain;\r\ndout("__send_cap %p cap %p session %p %s -> %s (revoking %s)\n",\r\ninode, cap, cap->session,\r\nceph_cap_string(held), ceph_cap_string(held & retain),\r\nceph_cap_string(revoking));\r\nBUG_ON((retain & CEPH_CAP_PIN) == 0);\r\nsession = cap->session;\r\nif ((ci->i_ceph_flags & CEPH_I_NODELAY) == 0 &&\r\ntime_before(jiffies, ci->i_hold_caps_min)) {\r\ndout(" delaying issued %s -> %s, wanted %s -> %s on send\n",\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(cap->issued & retain),\r\nceph_cap_string(cap->mds_wanted),\r\nceph_cap_string(want));\r\nwant |= cap->mds_wanted;\r\nretain |= cap->issued;\r\ndelayed = 1;\r\n}\r\nci->i_ceph_flags &= ~(CEPH_I_NODELAY | CEPH_I_FLUSH);\r\ncap->issued &= retain;\r\nif (cap->implemented & ~cap->issued) {\r\nwake = 1;\r\n}\r\ncap->implemented &= cap->issued | used;\r\ncap->mds_wanted = want;\r\nif (flushing) {\r\nflush_tid = ++ci->i_cap_flush_last_tid;\r\nif (pflush_tid)\r\n*pflush_tid = flush_tid;\r\ndout(" cap_flush_tid %d\n", (int)flush_tid);\r\nfor (i = 0; i < CEPH_CAP_BITS; i++)\r\nif (flushing & (1 << i))\r\nci->i_cap_flush_tid[i] = flush_tid;\r\nfollows = ci->i_head_snapc->seq;\r\n} else {\r\nfollows = 0;\r\n}\r\nkeep = cap->implemented;\r\nseq = cap->seq;\r\nissue_seq = cap->issue_seq;\r\nmseq = cap->mseq;\r\nsize = inode->i_size;\r\nci->i_reported_size = size;\r\nmax_size = ci->i_wanted_max_size;\r\nci->i_requested_max_size = max_size;\r\nmtime = inode->i_mtime;\r\natime = inode->i_atime;\r\ntime_warp_seq = ci->i_time_warp_seq;\r\nuid = inode->i_uid;\r\ngid = inode->i_gid;\r\nmode = inode->i_mode;\r\nif (flushing & CEPH_CAP_XATTR_EXCL) {\r\n__ceph_build_xattrs_blob(ci);\r\nxattr_blob = ci->i_xattrs.blob;\r\nxattr_version = ci->i_xattrs.version;\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nret = send_cap_msg(session, ceph_vino(inode).ino, cap_id,\r\nop, keep, want, flushing, seq, flush_tid, issue_seq, mseq,\r\nsize, max_size, &mtime, &atime, time_warp_seq,\r\nuid, gid, mode, xattr_version, xattr_blob,\r\nfollows);\r\nif (ret < 0) {\r\ndout("error sending cap msg, must requeue %p\n", inode);\r\ndelayed = 1;\r\n}\r\nif (wake)\r\nwake_up_all(&ci->i_cap_wq);\r\nreturn delayed;\r\n}\r\nvoid __ceph_flush_snaps(struct ceph_inode_info *ci,\r\nstruct ceph_mds_session **psession,\r\nint again)\r\n__releases(ci->i_ceph_lock)\r\n__acquires(ci->i_ceph_lock)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nint mds;\r\nstruct ceph_cap_snap *capsnap;\r\nu32 mseq;\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nstruct ceph_mds_session *session = NULL;\r\nu64 next_follows = 0;\r\nif (psession)\r\nsession = *psession;\r\ndout("__flush_snaps %p\n", inode);\r\nretry:\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\nif (capsnap->follows < next_follows)\r\ncontinue;\r\nif (capsnap->dirty_pages || capsnap->writing)\r\nbreak;\r\nBUG_ON(capsnap->dirty == 0);\r\nif (ci->i_auth_cap == NULL) {\r\ndout("no auth cap (migrating?), doing nothing\n");\r\ngoto out;\r\n}\r\nif (!again && !list_empty(&capsnap->flushing_item)) {\r\ndout("already flushed %p, skipping\n", capsnap);\r\ncontinue;\r\n}\r\nmds = ci->i_auth_cap->session->s_mds;\r\nmseq = ci->i_auth_cap->mseq;\r\nif (session && session->s_mds != mds) {\r\ndout("oops, wrong session %p mutex\n", session);\r\nmutex_unlock(&session->s_mutex);\r\nceph_put_mds_session(session);\r\nsession = NULL;\r\n}\r\nif (!session) {\r\nspin_unlock(&ci->i_ceph_lock);\r\nmutex_lock(&mdsc->mutex);\r\nsession = __ceph_lookup_mds_session(mdsc, mds);\r\nmutex_unlock(&mdsc->mutex);\r\nif (session) {\r\ndout("inverting session/ino locks on %p\n",\r\nsession);\r\nmutex_lock(&session->s_mutex);\r\n}\r\nspin_lock(&ci->i_ceph_lock);\r\ngoto retry;\r\n}\r\ncapsnap->flush_tid = ++ci->i_cap_flush_last_tid;\r\natomic_inc(&capsnap->nref);\r\nif (!list_empty(&capsnap->flushing_item))\r\nlist_del_init(&capsnap->flushing_item);\r\nlist_add_tail(&capsnap->flushing_item,\r\n&session->s_cap_snaps_flushing);\r\nspin_unlock(&ci->i_ceph_lock);\r\ndout("flush_snaps %p cap_snap %p follows %lld tid %llu\n",\r\ninode, capsnap, capsnap->follows, capsnap->flush_tid);\r\nsend_cap_msg(session, ceph_vino(inode).ino, 0,\r\nCEPH_CAP_OP_FLUSHSNAP, capsnap->issued, 0,\r\ncapsnap->dirty, 0, capsnap->flush_tid, 0, mseq,\r\ncapsnap->size, 0,\r\n&capsnap->mtime, &capsnap->atime,\r\ncapsnap->time_warp_seq,\r\ncapsnap->uid, capsnap->gid, capsnap->mode,\r\ncapsnap->xattr_version, capsnap->xattr_blob,\r\ncapsnap->follows);\r\nnext_follows = capsnap->follows + 1;\r\nceph_put_cap_snap(capsnap);\r\nspin_lock(&ci->i_ceph_lock);\r\ngoto retry;\r\n}\r\nspin_lock(&mdsc->snap_flush_lock);\r\nlist_del_init(&ci->i_snap_flush_item);\r\nspin_unlock(&mdsc->snap_flush_lock);\r\nout:\r\nif (psession)\r\n*psession = session;\r\nelse if (session) {\r\nmutex_unlock(&session->s_mutex);\r\nceph_put_mds_session(session);\r\n}\r\n}\r\nstatic void ceph_flush_snaps(struct ceph_inode_info *ci)\r\n{\r\nspin_lock(&ci->i_ceph_lock);\r\n__ceph_flush_snaps(ci, NULL, 0);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nint __ceph_mark_dirty_caps(struct ceph_inode_info *ci, int mask)\r\n{\r\nstruct ceph_mds_client *mdsc =\r\nceph_sb_to_client(ci->vfs_inode.i_sb)->mdsc;\r\nstruct inode *inode = &ci->vfs_inode;\r\nint was = ci->i_dirty_caps;\r\nint dirty = 0;\r\ndout("__mark_dirty_caps %p %s dirty %s -> %s\n", &ci->vfs_inode,\r\nceph_cap_string(mask), ceph_cap_string(was),\r\nceph_cap_string(was | mask));\r\nci->i_dirty_caps |= mask;\r\nif (was == 0) {\r\nif (!ci->i_head_snapc)\r\nci->i_head_snapc = ceph_get_snap_context(\r\nci->i_snap_realm->cached_context);\r\ndout(" inode %p now dirty snapc %p\n", &ci->vfs_inode,\r\nci->i_head_snapc);\r\nBUG_ON(!list_empty(&ci->i_dirty_item));\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nlist_add(&ci->i_dirty_item, &mdsc->cap_dirty);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nif (ci->i_flushing_caps == 0) {\r\nihold(inode);\r\ndirty |= I_DIRTY_SYNC;\r\n}\r\n}\r\nBUG_ON(list_empty(&ci->i_dirty_item));\r\nif (((was | ci->i_flushing_caps) & CEPH_CAP_FILE_BUFFER) &&\r\n(mask & CEPH_CAP_FILE_BUFFER))\r\ndirty |= I_DIRTY_DATASYNC;\r\n__cap_delay_requeue(mdsc, ci);\r\nreturn dirty;\r\n}\r\nstatic int __mark_caps_flushing(struct inode *inode,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_sb_to_client(inode->i_sb)->mdsc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint flushing;\r\nBUG_ON(ci->i_dirty_caps == 0);\r\nBUG_ON(list_empty(&ci->i_dirty_item));\r\nflushing = ci->i_dirty_caps;\r\ndout("__mark_caps_flushing flushing %s, flushing_caps %s -> %s\n",\r\nceph_cap_string(flushing),\r\nceph_cap_string(ci->i_flushing_caps),\r\nceph_cap_string(ci->i_flushing_caps | flushing));\r\nci->i_flushing_caps |= flushing;\r\nci->i_dirty_caps = 0;\r\ndout(" inode %p now !dirty\n", inode);\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nlist_del_init(&ci->i_dirty_item);\r\nci->i_cap_flush_seq = ++mdsc->cap_flush_seq;\r\nif (list_empty(&ci->i_flushing_item)) {\r\nlist_add_tail(&ci->i_flushing_item, &session->s_cap_flushing);\r\nmdsc->num_cap_flushing++;\r\ndout(" inode %p now flushing seq %lld\n", inode,\r\nci->i_cap_flush_seq);\r\n} else {\r\nlist_move_tail(&ci->i_flushing_item, &session->s_cap_flushing);\r\ndout(" inode %p now flushing (more) seq %lld\n", inode,\r\nci->i_cap_flush_seq);\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nreturn flushing;\r\n}\r\nstatic int try_nonblocking_invalidate(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nu32 invalidating_gen = ci->i_rdcache_gen;\r\nspin_unlock(&ci->i_ceph_lock);\r\ninvalidate_mapping_pages(&inode->i_data, 0, -1);\r\nspin_lock(&ci->i_ceph_lock);\r\nif (inode->i_data.nrpages == 0 &&\r\ninvalidating_gen == ci->i_rdcache_gen) {\r\ndout("try_nonblocking_invalidate %p success\n", inode);\r\nci->i_rdcache_revoking = ci->i_rdcache_gen - 1;\r\nreturn 0;\r\n}\r\ndout("try_nonblocking_invalidate %p failed\n", inode);\r\nreturn -1;\r\n}\r\nvoid ceph_check_caps(struct ceph_inode_info *ci, int flags,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(&ci->vfs_inode);\r\nstruct ceph_mds_client *mdsc = fsc->mdsc;\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_cap *cap;\r\nint file_wanted, used;\r\nint took_snap_rwsem = 0;\r\nint issued, implemented, want, retain, revoking, flushing = 0;\r\nint mds = -1;\r\nstruct rb_node *p;\r\nint tried_invalidate = 0;\r\nint delayed = 0, sent = 0, force_requeue = 0, num;\r\nint queue_invalidate = 0;\r\nint is_delayed = flags & CHECK_CAPS_NODELAY;\r\nif (mdsc->stopping)\r\nis_delayed = 1;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (ci->i_ceph_flags & CEPH_I_FLUSH)\r\nflags |= CHECK_CAPS_FLUSH;\r\nif (!list_empty(&ci->i_cap_snaps))\r\n__ceph_flush_snaps(ci, &session, 0);\r\ngoto retry_locked;\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\nretry_locked:\r\nfile_wanted = __ceph_caps_file_wanted(ci);\r\nused = __ceph_caps_used(ci);\r\nwant = file_wanted | used;\r\nissued = __ceph_caps_issued(ci, &implemented);\r\nrevoking = implemented & ~issued;\r\nretain = want | CEPH_CAP_PIN;\r\nif (!mdsc->stopping && inode->i_nlink > 0) {\r\nif (want) {\r\nretain |= CEPH_CAP_ANY;\r\n} else {\r\nretain |= CEPH_CAP_ANY_SHARED;\r\nif (ci->i_max_size == 0)\r\nretain |= CEPH_CAP_ANY_RD;\r\n}\r\n}\r\ndout("check_caps %p file_want %s used %s dirty %s flushing %s"\r\n" issued %s revoking %s retain %s %s%s%s\n", inode,\r\nceph_cap_string(file_wanted),\r\nceph_cap_string(used), ceph_cap_string(ci->i_dirty_caps),\r\nceph_cap_string(ci->i_flushing_caps),\r\nceph_cap_string(issued), ceph_cap_string(revoking),\r\nceph_cap_string(retain),\r\n(flags & CHECK_CAPS_AUTHONLY) ? " AUTHONLY" : "",\r\n(flags & CHECK_CAPS_NODELAY) ? " NODELAY" : "",\r\n(flags & CHECK_CAPS_FLUSH) ? " FLUSH" : "");\r\nif ((!is_delayed || mdsc->stopping) &&\r\nci->i_wrbuffer_ref == 0 &&\r\ninode->i_data.nrpages &&\r\n(file_wanted == 0 ||\r\n(revoking & (CEPH_CAP_FILE_CACHE|\r\nCEPH_CAP_FILE_LAZYIO))) &&\r\n!tried_invalidate) {\r\ndout("check_caps trying to invalidate on %p\n", inode);\r\nif (try_nonblocking_invalidate(inode) < 0) {\r\nif (revoking & (CEPH_CAP_FILE_CACHE|\r\nCEPH_CAP_FILE_LAZYIO)) {\r\ndout("check_caps queuing invalidate\n");\r\nqueue_invalidate = 1;\r\nci->i_rdcache_revoking = ci->i_rdcache_gen;\r\n} else {\r\ndout("check_caps failed to invalidate pages\n");\r\nforce_requeue = 1;\r\n__cap_set_timeouts(mdsc, ci);\r\n}\r\n}\r\ntried_invalidate = 1;\r\ngoto retry_locked;\r\n}\r\nnum = 0;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nnum++;\r\nif (mds >= cap->mds ||\r\n((flags & CHECK_CAPS_AUTHONLY) && cap != ci->i_auth_cap))\r\ncontinue;\r\nrevoking = cap->implemented & ~cap->issued;\r\ndout(" mds%d cap %p issued %s implemented %s revoking %s\n",\r\ncap->mds, cap, ceph_cap_string(cap->issued),\r\nceph_cap_string(cap->implemented),\r\nceph_cap_string(revoking));\r\nif (cap == ci->i_auth_cap &&\r\n(cap->issued & CEPH_CAP_FILE_WR)) {\r\nif (ci->i_wanted_max_size > ci->i_max_size &&\r\nci->i_wanted_max_size > ci->i_requested_max_size) {\r\ndout("requesting new max_size\n");\r\ngoto ack;\r\n}\r\nif ((inode->i_size << 1) >= ci->i_max_size &&\r\n(ci->i_reported_size << 1) < ci->i_max_size) {\r\ndout("i_size approaching max_size\n");\r\ngoto ack;\r\n}\r\n}\r\nif (cap == ci->i_auth_cap && (flags & CHECK_CAPS_FLUSH) &&\r\nci->i_dirty_caps) {\r\ndout("flushing dirty caps\n");\r\ngoto ack;\r\n}\r\nif (revoking && (revoking & used) == 0) {\r\ndout("completed revocation of %s\n",\r\nceph_cap_string(cap->implemented & ~cap->issued));\r\ngoto ack;\r\n}\r\nif (want & ~(cap->mds_wanted | cap->issued))\r\ngoto ack;\r\nif ((cap->issued & ~retain) == 0 &&\r\ncap->mds_wanted == want)\r\ncontinue;\r\nif (is_delayed)\r\ngoto ack;\r\nif ((ci->i_ceph_flags & CEPH_I_NODELAY) == 0 &&\r\ntime_before(jiffies, ci->i_hold_caps_max)) {\r\ndout(" delaying issued %s -> %s, wanted %s -> %s\n",\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(cap->issued & retain),\r\nceph_cap_string(cap->mds_wanted),\r\nceph_cap_string(want));\r\ndelayed++;\r\ncontinue;\r\n}\r\nack:\r\nif (ci->i_ceph_flags & CEPH_I_NOFLUSH) {\r\ndout(" skipping %p I_NOFLUSH set\n", inode);\r\ncontinue;\r\n}\r\nif (session && session != cap->session) {\r\ndout("oops, wrong session %p mutex\n", session);\r\nmutex_unlock(&session->s_mutex);\r\nsession = NULL;\r\n}\r\nif (!session) {\r\nsession = cap->session;\r\nif (mutex_trylock(&session->s_mutex) == 0) {\r\ndout("inverting session/ino locks on %p\n",\r\nsession);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (took_snap_rwsem) {\r\nup_read(&mdsc->snap_rwsem);\r\ntook_snap_rwsem = 0;\r\n}\r\nmutex_lock(&session->s_mutex);\r\ngoto retry;\r\n}\r\n}\r\nif (!took_snap_rwsem) {\r\nif (down_read_trylock(&mdsc->snap_rwsem) == 0) {\r\ndout("inverting snap/in locks on %p\n",\r\ninode);\r\nspin_unlock(&ci->i_ceph_lock);\r\ndown_read(&mdsc->snap_rwsem);\r\ntook_snap_rwsem = 1;\r\ngoto retry;\r\n}\r\ntook_snap_rwsem = 1;\r\n}\r\nif (cap == ci->i_auth_cap && ci->i_dirty_caps)\r\nflushing = __mark_caps_flushing(inode, session);\r\nelse\r\nflushing = 0;\r\nmds = cap->mds;\r\nsent++;\r\ndelayed += __send_cap(mdsc, cap, CEPH_CAP_OP_UPDATE, used, want,\r\nretain, flushing, NULL);\r\ngoto retry;\r\n}\r\nif (delayed && is_delayed)\r\nforce_requeue = 1;\r\nif (!delayed && !is_delayed)\r\n__cap_delay_cancel(mdsc, ci);\r\nelse if (!is_delayed || force_requeue)\r\n__cap_delay_requeue(mdsc, ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (queue_invalidate)\r\nceph_queue_invalidate(inode);\r\nif (session)\r\nmutex_unlock(&session->s_mutex);\r\nif (took_snap_rwsem)\r\nup_read(&mdsc->snap_rwsem);\r\n}\r\nstatic int try_flush_caps(struct inode *inode, struct ceph_mds_session *session,\r\nunsigned *flush_tid)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_sb_to_client(inode->i_sb)->mdsc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint unlock_session = session ? 0 : 1;\r\nint flushing = 0;\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\nif (ci->i_ceph_flags & CEPH_I_NOFLUSH) {\r\ndout("try_flush_caps skipping %p I_NOFLUSH set\n", inode);\r\ngoto out;\r\n}\r\nif (ci->i_dirty_caps && ci->i_auth_cap) {\r\nstruct ceph_cap *cap = ci->i_auth_cap;\r\nint used = __ceph_caps_used(ci);\r\nint want = __ceph_caps_wanted(ci);\r\nint delayed;\r\nif (!session) {\r\nspin_unlock(&ci->i_ceph_lock);\r\nsession = cap->session;\r\nmutex_lock(&session->s_mutex);\r\ngoto retry;\r\n}\r\nBUG_ON(session != cap->session);\r\nif (cap->session->s_state < CEPH_MDS_SESSION_OPEN)\r\ngoto out;\r\nflushing = __mark_caps_flushing(inode, session);\r\ndelayed = __send_cap(mdsc, cap, CEPH_CAP_OP_FLUSH, used, want,\r\ncap->issued | cap->implemented, flushing,\r\nflush_tid);\r\nif (!delayed)\r\ngoto out_unlocked;\r\nspin_lock(&ci->i_ceph_lock);\r\n__cap_delay_requeue(mdsc, ci);\r\n}\r\nout:\r\nspin_unlock(&ci->i_ceph_lock);\r\nout_unlocked:\r\nif (session && unlock_session)\r\nmutex_unlock(&session->s_mutex);\r\nreturn flushing;\r\n}\r\nstatic int caps_are_flushed(struct inode *inode, unsigned tid)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint i, ret = 1;\r\nspin_lock(&ci->i_ceph_lock);\r\nfor (i = 0; i < CEPH_CAP_BITS; i++)\r\nif ((ci->i_flushing_caps & (1 << i)) &&\r\nci->i_cap_flush_tid[i] <= tid) {\r\nret = 0;\r\nbreak;\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn ret;\r\n}\r\nstatic void sync_write_wait(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct list_head *head = &ci->i_unsafe_writes;\r\nstruct ceph_osd_request *req;\r\nu64 last_tid;\r\nspin_lock(&ci->i_unsafe_lock);\r\nif (list_empty(head))\r\ngoto out;\r\nreq = list_entry(head->prev, struct ceph_osd_request,\r\nr_unsafe_item);\r\nlast_tid = req->r_tid;\r\ndo {\r\nceph_osdc_get_request(req);\r\nspin_unlock(&ci->i_unsafe_lock);\r\ndout("sync_write_wait on tid %llu (until %llu)\n",\r\nreq->r_tid, last_tid);\r\nwait_for_completion(&req->r_safe_completion);\r\nspin_lock(&ci->i_unsafe_lock);\r\nceph_osdc_put_request(req);\r\nif (list_empty(head))\r\nbreak;\r\nreq = list_entry(head->next, struct ceph_osd_request,\r\nr_unsafe_item);\r\n} while (req->r_tid < last_tid);\r\nout:\r\nspin_unlock(&ci->i_unsafe_lock);\r\n}\r\nint ceph_fsync(struct file *file, loff_t start, loff_t end, int datasync)\r\n{\r\nstruct inode *inode = file->f_mapping->host;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nunsigned flush_tid;\r\nint ret;\r\nint dirty;\r\ndout("fsync %p%s\n", inode, datasync ? " datasync" : "");\r\nsync_write_wait(inode);\r\nret = filemap_write_and_wait_range(inode->i_mapping, start, end);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&inode->i_mutex);\r\ndirty = try_flush_caps(inode, NULL, &flush_tid);\r\ndout("fsync dirty caps are %s\n", ceph_cap_string(dirty));\r\nif (!datasync && (dirty & ~CEPH_CAP_ANY_FILE_WR)) {\r\ndout("fsync waiting for flush_tid %u\n", flush_tid);\r\nret = wait_event_interruptible(ci->i_cap_wq,\r\ncaps_are_flushed(inode, flush_tid));\r\n}\r\ndout("fsync %p%s done\n", inode, datasync ? " datasync" : "");\r\nmutex_unlock(&inode->i_mutex);\r\nreturn ret;\r\n}\r\nint ceph_write_inode(struct inode *inode, struct writeback_control *wbc)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nunsigned flush_tid;\r\nint err = 0;\r\nint dirty;\r\nint wait = wbc->sync_mode == WB_SYNC_ALL;\r\ndout("write_inode %p wait=%d\n", inode, wait);\r\nif (wait) {\r\ndirty = try_flush_caps(inode, NULL, &flush_tid);\r\nif (dirty)\r\nerr = wait_event_interruptible(ci->i_cap_wq,\r\ncaps_are_flushed(inode, flush_tid));\r\n} else {\r\nstruct ceph_mds_client *mdsc =\r\nceph_sb_to_client(inode->i_sb)->mdsc;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (__ceph_caps_dirty(ci))\r\n__cap_delay_requeue_front(mdsc, ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nreturn err;\r\n}\r\nstatic void kick_flushing_capsnaps(struct ceph_mds_client *mdsc,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_cap_snap *capsnap;\r\ndout("kick_flushing_capsnaps mds%d\n", session->s_mds);\r\nlist_for_each_entry(capsnap, &session->s_cap_snaps_flushing,\r\nflushing_item) {\r\nstruct ceph_inode_info *ci = capsnap->ci;\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_cap *cap;\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = ci->i_auth_cap;\r\nif (cap && cap->session == session) {\r\ndout("kick_flushing_caps %p cap %p capsnap %p\n", inode,\r\ncap, capsnap);\r\n__ceph_flush_snaps(ci, &session, 1);\r\n} else {\r\npr_err("%p auth cap %p not mds%d ???\n", inode,\r\ncap, session->s_mds);\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n}\r\nvoid ceph_kick_flushing_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_inode_info *ci;\r\nkick_flushing_capsnaps(mdsc, session);\r\ndout("kick_flushing_caps mds%d\n", session->s_mds);\r\nlist_for_each_entry(ci, &session->s_cap_flushing, i_flushing_item) {\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_cap *cap;\r\nint delayed = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = ci->i_auth_cap;\r\nif (cap && cap->session == session) {\r\ndout("kick_flushing_caps %p cap %p %s\n", inode,\r\ncap, ceph_cap_string(ci->i_flushing_caps));\r\ndelayed = __send_cap(mdsc, cap, CEPH_CAP_OP_FLUSH,\r\n__ceph_caps_used(ci),\r\n__ceph_caps_wanted(ci),\r\ncap->issued | cap->implemented,\r\nci->i_flushing_caps, NULL);\r\nif (delayed) {\r\nspin_lock(&ci->i_ceph_lock);\r\n__cap_delay_requeue(mdsc, ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n} else {\r\npr_err("%p auth cap %p not mds%d ???\n", inode,\r\ncap, session->s_mds);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n}\r\n}\r\nstatic void kick_flushing_inode_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_mds_session *session,\r\nstruct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap *cap;\r\nint delayed = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = ci->i_auth_cap;\r\ndout("kick_flushing_inode_caps %p flushing %s flush_seq %lld\n", inode,\r\nceph_cap_string(ci->i_flushing_caps), ci->i_cap_flush_seq);\r\n__ceph_flush_snaps(ci, &session, 1);\r\nif (ci->i_flushing_caps) {\r\ndelayed = __send_cap(mdsc, cap, CEPH_CAP_OP_FLUSH,\r\n__ceph_caps_used(ci),\r\n__ceph_caps_wanted(ci),\r\ncap->issued | cap->implemented,\r\nci->i_flushing_caps, NULL);\r\nif (delayed) {\r\nspin_lock(&ci->i_ceph_lock);\r\n__cap_delay_requeue(mdsc, ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n} else {\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n}\r\nstatic void __take_cap_refs(struct ceph_inode_info *ci, int got)\r\n{\r\nif (got & CEPH_CAP_PIN)\r\nci->i_pin_ref++;\r\nif (got & CEPH_CAP_FILE_RD)\r\nci->i_rd_ref++;\r\nif (got & CEPH_CAP_FILE_CACHE)\r\nci->i_rdcache_ref++;\r\nif (got & CEPH_CAP_FILE_WR)\r\nci->i_wr_ref++;\r\nif (got & CEPH_CAP_FILE_BUFFER) {\r\nif (ci->i_wb_ref == 0)\r\nihold(&ci->vfs_inode);\r\nci->i_wb_ref++;\r\ndout("__take_cap_refs %p wb %d -> %d (?)\n",\r\n&ci->vfs_inode, ci->i_wb_ref-1, ci->i_wb_ref);\r\n}\r\n}\r\nstatic int try_get_cap_refs(struct ceph_inode_info *ci, int need, int want,\r\nint *got, loff_t endoff, int *check_max, int *err)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nint ret = 0;\r\nint have, implemented;\r\nint file_wanted;\r\ndout("get_cap_refs %p need %s want %s\n", inode,\r\nceph_cap_string(need), ceph_cap_string(want));\r\nspin_lock(&ci->i_ceph_lock);\r\nfile_wanted = __ceph_caps_file_wanted(ci);\r\nif ((file_wanted & need) == 0) {\r\ndout("try_get_cap_refs need %s file_wanted %s, EBADF\n",\r\nceph_cap_string(need), ceph_cap_string(file_wanted));\r\n*err = -EBADF;\r\nret = 1;\r\ngoto out;\r\n}\r\nif (need & CEPH_CAP_FILE_WR) {\r\nif (endoff >= 0 && endoff > (loff_t)ci->i_max_size) {\r\ndout("get_cap_refs %p endoff %llu > maxsize %llu\n",\r\ninode, endoff, ci->i_max_size);\r\nif (endoff > ci->i_wanted_max_size) {\r\n*check_max = 1;\r\nret = 1;\r\n}\r\ngoto out;\r\n}\r\nif (__ceph_have_pending_cap_snap(ci)) {\r\ndout("get_cap_refs %p cap_snap_pending\n", inode);\r\ngoto out;\r\n}\r\n}\r\nhave = __ceph_caps_issued(ci, &implemented);\r\nif (ci->i_truncate_pending)\r\nhave &= ~CEPH_CAP_FILE_WR;\r\nif ((have & need) == need) {\r\nint not = want & ~(have & need);\r\nint revoking = implemented & ~have;\r\ndout("get_cap_refs %p have %s but not %s (revoking %s)\n",\r\ninode, ceph_cap_string(have), ceph_cap_string(not),\r\nceph_cap_string(revoking));\r\nif ((revoking & not) == 0) {\r\n*got = need | (have & want);\r\n__take_cap_refs(ci, *got);\r\nret = 1;\r\n}\r\n} else {\r\ndout("get_cap_refs %p have %s needed %s\n", inode,\r\nceph_cap_string(have), ceph_cap_string(need));\r\n}\r\nout:\r\nspin_unlock(&ci->i_ceph_lock);\r\ndout("get_cap_refs %p ret %d got %s\n", inode,\r\nret, ceph_cap_string(*got));\r\nreturn ret;\r\n}\r\nstatic void check_max_size(struct inode *inode, loff_t endoff)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint check = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\nif ((endoff >= ci->i_max_size ||\r\nendoff > (inode->i_size << 1)) &&\r\nendoff > ci->i_wanted_max_size) {\r\ndout("write %p at large endoff %llu, req max_size\n",\r\ninode, endoff);\r\nci->i_wanted_max_size = endoff;\r\ncheck = 1;\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (check)\r\nceph_check_caps(ci, CHECK_CAPS_AUTHONLY, NULL);\r\n}\r\nint ceph_get_caps(struct ceph_inode_info *ci, int need, int want, int *got,\r\nloff_t endoff)\r\n{\r\nint check_max, ret, err;\r\nretry:\r\nif (endoff > 0)\r\ncheck_max_size(&ci->vfs_inode, endoff);\r\ncheck_max = 0;\r\nerr = 0;\r\nret = wait_event_interruptible(ci->i_cap_wq,\r\ntry_get_cap_refs(ci, need, want,\r\ngot, endoff,\r\n&check_max, &err));\r\nif (err)\r\nret = err;\r\nif (check_max)\r\ngoto retry;\r\nreturn ret;\r\n}\r\nvoid ceph_get_cap_refs(struct ceph_inode_info *ci, int caps)\r\n{\r\nspin_lock(&ci->i_ceph_lock);\r\n__take_cap_refs(ci, caps);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nvoid ceph_put_cap_refs(struct ceph_inode_info *ci, int had)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nint last = 0, put = 0, flushsnaps = 0, wake = 0;\r\nstruct ceph_cap_snap *capsnap;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (had & CEPH_CAP_PIN)\r\n--ci->i_pin_ref;\r\nif (had & CEPH_CAP_FILE_RD)\r\nif (--ci->i_rd_ref == 0)\r\nlast++;\r\nif (had & CEPH_CAP_FILE_CACHE)\r\nif (--ci->i_rdcache_ref == 0)\r\nlast++;\r\nif (had & CEPH_CAP_FILE_BUFFER) {\r\nif (--ci->i_wb_ref == 0) {\r\nlast++;\r\nput++;\r\n}\r\ndout("put_cap_refs %p wb %d -> %d (?)\n",\r\ninode, ci->i_wb_ref+1, ci->i_wb_ref);\r\n}\r\nif (had & CEPH_CAP_FILE_WR)\r\nif (--ci->i_wr_ref == 0) {\r\nlast++;\r\nif (!list_empty(&ci->i_cap_snaps)) {\r\ncapsnap = list_first_entry(&ci->i_cap_snaps,\r\nstruct ceph_cap_snap,\r\nci_item);\r\nif (capsnap->writing) {\r\ncapsnap->writing = 0;\r\nflushsnaps =\r\n__ceph_finish_cap_snap(ci,\r\ncapsnap);\r\nwake = 1;\r\n}\r\n}\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\ndout("put_cap_refs %p had %s%s%s\n", inode, ceph_cap_string(had),\r\nlast ? " last" : "", put ? " put" : "");\r\nif (last && !flushsnaps)\r\nceph_check_caps(ci, 0, NULL);\r\nelse if (flushsnaps)\r\nceph_flush_snaps(ci);\r\nif (wake)\r\nwake_up_all(&ci->i_cap_wq);\r\nif (put)\r\niput(inode);\r\n}\r\nvoid ceph_put_wrbuffer_cap_refs(struct ceph_inode_info *ci, int nr,\r\nstruct ceph_snap_context *snapc)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nint last = 0;\r\nint complete_capsnap = 0;\r\nint drop_capsnap = 0;\r\nint found = 0;\r\nstruct ceph_cap_snap *capsnap = NULL;\r\nspin_lock(&ci->i_ceph_lock);\r\nci->i_wrbuffer_ref -= nr;\r\nlast = !ci->i_wrbuffer_ref;\r\nif (ci->i_head_snapc == snapc) {\r\nci->i_wrbuffer_ref_head -= nr;\r\nif (ci->i_wrbuffer_ref_head == 0 &&\r\nci->i_dirty_caps == 0 && ci->i_flushing_caps == 0) {\r\nBUG_ON(!ci->i_head_snapc);\r\nceph_put_snap_context(ci->i_head_snapc);\r\nci->i_head_snapc = NULL;\r\n}\r\ndout("put_wrbuffer_cap_refs on %p head %d/%d -> %d/%d %s\n",\r\ninode,\r\nci->i_wrbuffer_ref+nr, ci->i_wrbuffer_ref_head+nr,\r\nci->i_wrbuffer_ref, ci->i_wrbuffer_ref_head,\r\nlast ? " LAST" : "");\r\n} else {\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\nif (capsnap->context == snapc) {\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nBUG_ON(!found);\r\ncapsnap->dirty_pages -= nr;\r\nif (capsnap->dirty_pages == 0) {\r\ncomplete_capsnap = 1;\r\nif (capsnap->dirty == 0)\r\ndrop_capsnap = 1;\r\n}\r\ndout("put_wrbuffer_cap_refs on %p cap_snap %p "\r\n" snap %lld %d/%d -> %d/%d %s%s%s\n",\r\ninode, capsnap, capsnap->context->seq,\r\nci->i_wrbuffer_ref+nr, capsnap->dirty_pages + nr,\r\nci->i_wrbuffer_ref, capsnap->dirty_pages,\r\nlast ? " (wrbuffer last)" : "",\r\ncomplete_capsnap ? " (complete capsnap)" : "",\r\ndrop_capsnap ? " (drop capsnap)" : "");\r\nif (drop_capsnap) {\r\nceph_put_snap_context(capsnap->context);\r\nlist_del(&capsnap->ci_item);\r\nlist_del(&capsnap->flushing_item);\r\nceph_put_cap_snap(capsnap);\r\n}\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (last) {\r\nceph_check_caps(ci, CHECK_CAPS_AUTHONLY, NULL);\r\niput(inode);\r\n} else if (complete_capsnap) {\r\nceph_flush_snaps(ci);\r\nwake_up_all(&ci->i_cap_wq);\r\n}\r\nif (drop_capsnap)\r\niput(inode);\r\n}\r\nstatic void handle_cap_grant(struct inode *inode, struct ceph_mds_caps *grant,\r\nstruct ceph_mds_session *session,\r\nstruct ceph_cap *cap,\r\nstruct ceph_buffer *xattr_buf)\r\n__releases(ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds = session->s_mds;\r\nint seq = le32_to_cpu(grant->seq);\r\nint newcaps = le32_to_cpu(grant->caps);\r\nint issued, implemented, used, wanted, dirty;\r\nu64 size = le64_to_cpu(grant->size);\r\nu64 max_size = le64_to_cpu(grant->max_size);\r\nstruct timespec mtime, atime, ctime;\r\nint check_caps = 0;\r\nint wake = 0;\r\nint writeback = 0;\r\nint revoked_rdcache = 0;\r\nint queue_invalidate = 0;\r\ndout("handle_cap_grant inode %p cap %p mds%d seq %d %s\n",\r\ninode, cap, mds, seq, ceph_cap_string(newcaps));\r\ndout(" size %llu max_size %llu, i_size %llu\n", size, max_size,\r\ninode->i_size);\r\nif (((cap->issued & ~newcaps) & CEPH_CAP_FILE_CACHE) &&\r\n(newcaps & CEPH_CAP_FILE_LAZYIO) == 0 &&\r\n!ci->i_wrbuffer_ref) {\r\nif (try_nonblocking_invalidate(inode) == 0) {\r\nrevoked_rdcache = 1;\r\n} else {\r\nif (ci->i_rdcache_revoking != ci->i_rdcache_gen) {\r\nqueue_invalidate = 1;\r\nci->i_rdcache_revoking = ci->i_rdcache_gen;\r\n}\r\n}\r\n}\r\nissued = __ceph_caps_issued(ci, &implemented);\r\nissued |= implemented | __ceph_caps_dirty(ci);\r\ncap->cap_gen = session->s_cap_gen;\r\n__check_cap_issue(ci, cap, newcaps);\r\nif ((issued & CEPH_CAP_AUTH_EXCL) == 0) {\r\ninode->i_mode = le32_to_cpu(grant->mode);\r\ninode->i_uid = le32_to_cpu(grant->uid);\r\ninode->i_gid = le32_to_cpu(grant->gid);\r\ndout("%p mode 0%o uid.gid %d.%d\n", inode, inode->i_mode,\r\ninode->i_uid, inode->i_gid);\r\n}\r\nif ((issued & CEPH_CAP_LINK_EXCL) == 0)\r\nset_nlink(inode, le32_to_cpu(grant->nlink));\r\nif ((issued & CEPH_CAP_XATTR_EXCL) == 0 && grant->xattr_len) {\r\nint len = le32_to_cpu(grant->xattr_len);\r\nu64 version = le64_to_cpu(grant->xattr_version);\r\nif (version > ci->i_xattrs.version) {\r\ndout(" got new xattrs v%llu on %p len %d\n",\r\nversion, inode, len);\r\nif (ci->i_xattrs.blob)\r\nceph_buffer_put(ci->i_xattrs.blob);\r\nci->i_xattrs.blob = ceph_buffer_get(xattr_buf);\r\nci->i_xattrs.version = version;\r\n}\r\n}\r\nceph_fill_file_size(inode, issued,\r\nle32_to_cpu(grant->truncate_seq),\r\nle64_to_cpu(grant->truncate_size), size);\r\nceph_decode_timespec(&mtime, &grant->mtime);\r\nceph_decode_timespec(&atime, &grant->atime);\r\nceph_decode_timespec(&ctime, &grant->ctime);\r\nceph_fill_file_time(inode, issued,\r\nle32_to_cpu(grant->time_warp_seq), &ctime, &mtime,\r\n&atime);\r\nif (max_size != ci->i_max_size) {\r\ndout("max_size %lld -> %llu\n", ci->i_max_size, max_size);\r\nci->i_max_size = max_size;\r\nif (max_size >= ci->i_wanted_max_size) {\r\nci->i_wanted_max_size = 0;\r\nci->i_requested_max_size = 0;\r\n}\r\nwake = 1;\r\n}\r\nwanted = __ceph_caps_wanted(ci);\r\nused = __ceph_caps_used(ci);\r\ndirty = __ceph_caps_dirty(ci);\r\ndout(" my wanted = %s, used = %s, dirty %s\n",\r\nceph_cap_string(wanted),\r\nceph_cap_string(used),\r\nceph_cap_string(dirty));\r\nif (wanted != le32_to_cpu(grant->wanted)) {\r\ndout("mds wanted %s -> %s\n",\r\nceph_cap_string(le32_to_cpu(grant->wanted)),\r\nceph_cap_string(wanted));\r\ngrant->wanted = cpu_to_le32(wanted);\r\n}\r\ncap->seq = seq;\r\nci->i_layout = grant->layout;\r\nif (cap->issued & ~newcaps) {\r\nint revoking = cap->issued & ~newcaps;\r\ndout("revocation: %s -> %s (revoking %s)\n",\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(newcaps),\r\nceph_cap_string(revoking));\r\nif (revoking & used & CEPH_CAP_FILE_BUFFER)\r\nwriteback = 1;\r\nelse if (revoking == CEPH_CAP_FILE_CACHE &&\r\n(newcaps & CEPH_CAP_FILE_LAZYIO) == 0 &&\r\nqueue_invalidate)\r\n;\r\nelse if (cap == ci->i_auth_cap)\r\ncheck_caps = 1;\r\nelse\r\ncheck_caps = 2;\r\ncap->issued = newcaps;\r\ncap->implemented |= newcaps;\r\n} else if (cap->issued == newcaps) {\r\ndout("caps unchanged: %s -> %s\n",\r\nceph_cap_string(cap->issued), ceph_cap_string(newcaps));\r\n} else {\r\ndout("grant: %s -> %s\n", ceph_cap_string(cap->issued),\r\nceph_cap_string(newcaps));\r\ncap->issued = newcaps;\r\ncap->implemented |= newcaps;\r\nwake = 1;\r\n}\r\nBUG_ON(cap->issued & ~cap->implemented);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (writeback)\r\nceph_queue_writeback(inode);\r\nif (queue_invalidate)\r\nceph_queue_invalidate(inode);\r\nif (wake)\r\nwake_up_all(&ci->i_cap_wq);\r\nif (check_caps == 1)\r\nceph_check_caps(ci, CHECK_CAPS_NODELAY|CHECK_CAPS_AUTHONLY,\r\nsession);\r\nelse if (check_caps == 2)\r\nceph_check_caps(ci, CHECK_CAPS_NODELAY, session);\r\nelse\r\nmutex_unlock(&session->s_mutex);\r\n}\r\nstatic void handle_cap_flush_ack(struct inode *inode, u64 flush_tid,\r\nstruct ceph_mds_caps *m,\r\nstruct ceph_mds_session *session,\r\nstruct ceph_cap *cap)\r\n__releases(ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_mds_client *mdsc = ceph_sb_to_client(inode->i_sb)->mdsc;\r\nunsigned seq = le32_to_cpu(m->seq);\r\nint dirty = le32_to_cpu(m->dirty);\r\nint cleaned = 0;\r\nint drop = 0;\r\nint i;\r\nfor (i = 0; i < CEPH_CAP_BITS; i++)\r\nif ((dirty & (1 << i)) &&\r\nflush_tid == ci->i_cap_flush_tid[i])\r\ncleaned |= 1 << i;\r\ndout("handle_cap_flush_ack inode %p mds%d seq %d on %s cleaned %s,"\r\n" flushing %s -> %s\n",\r\ninode, session->s_mds, seq, ceph_cap_string(dirty),\r\nceph_cap_string(cleaned), ceph_cap_string(ci->i_flushing_caps),\r\nceph_cap_string(ci->i_flushing_caps & ~cleaned));\r\nif (ci->i_flushing_caps == (ci->i_flushing_caps & ~cleaned))\r\ngoto out;\r\nci->i_flushing_caps &= ~cleaned;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nif (ci->i_flushing_caps == 0) {\r\nlist_del_init(&ci->i_flushing_item);\r\nif (!list_empty(&session->s_cap_flushing))\r\ndout(" mds%d still flushing cap on %p\n",\r\nsession->s_mds,\r\n&list_entry(session->s_cap_flushing.next,\r\nstruct ceph_inode_info,\r\ni_flushing_item)->vfs_inode);\r\nmdsc->num_cap_flushing--;\r\nwake_up_all(&mdsc->cap_flushing_wq);\r\ndout(" inode %p now !flushing\n", inode);\r\nif (ci->i_dirty_caps == 0) {\r\ndout(" inode %p now clean\n", inode);\r\nBUG_ON(!list_empty(&ci->i_dirty_item));\r\ndrop = 1;\r\nif (ci->i_wrbuffer_ref_head == 0) {\r\nBUG_ON(!ci->i_head_snapc);\r\nceph_put_snap_context(ci->i_head_snapc);\r\nci->i_head_snapc = NULL;\r\n}\r\n} else {\r\nBUG_ON(list_empty(&ci->i_dirty_item));\r\n}\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nwake_up_all(&ci->i_cap_wq);\r\nout:\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (drop)\r\niput(inode);\r\n}\r\nstatic void handle_cap_flushsnap_ack(struct inode *inode, u64 flush_tid,\r\nstruct ceph_mds_caps *m,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nu64 follows = le64_to_cpu(m->snap_follows);\r\nstruct ceph_cap_snap *capsnap;\r\nint drop = 0;\r\ndout("handle_cap_flushsnap_ack inode %p ci %p mds%d follows %lld\n",\r\ninode, ci, session->s_mds, follows);\r\nspin_lock(&ci->i_ceph_lock);\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\nif (capsnap->follows == follows) {\r\nif (capsnap->flush_tid != flush_tid) {\r\ndout(" cap_snap %p follows %lld tid %lld !="\r\n" %lld\n", capsnap, follows,\r\nflush_tid, capsnap->flush_tid);\r\nbreak;\r\n}\r\nWARN_ON(capsnap->dirty_pages || capsnap->writing);\r\ndout(" removing %p cap_snap %p follows %lld\n",\r\ninode, capsnap, follows);\r\nceph_put_snap_context(capsnap->context);\r\nlist_del(&capsnap->ci_item);\r\nlist_del(&capsnap->flushing_item);\r\nceph_put_cap_snap(capsnap);\r\ndrop = 1;\r\nbreak;\r\n} else {\r\ndout(" skipping cap_snap %p follows %lld\n",\r\ncapsnap, capsnap->follows);\r\n}\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (drop)\r\niput(inode);\r\n}\r\nstatic void handle_cap_trunc(struct inode *inode,\r\nstruct ceph_mds_caps *trunc,\r\nstruct ceph_mds_session *session)\r\n__releases(ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds = session->s_mds;\r\nint seq = le32_to_cpu(trunc->seq);\r\nu32 truncate_seq = le32_to_cpu(trunc->truncate_seq);\r\nu64 truncate_size = le64_to_cpu(trunc->truncate_size);\r\nu64 size = le64_to_cpu(trunc->size);\r\nint implemented = 0;\r\nint dirty = __ceph_caps_dirty(ci);\r\nint issued = __ceph_caps_issued(ceph_inode(inode), &implemented);\r\nint queue_trunc = 0;\r\nissued |= implemented | dirty;\r\ndout("handle_cap_trunc inode %p mds%d seq %d to %lld seq %d\n",\r\ninode, mds, seq, truncate_size, truncate_seq);\r\nqueue_trunc = ceph_fill_file_size(inode, issued,\r\ntruncate_seq, truncate_size, size);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (queue_trunc)\r\nceph_queue_vmtruncate(inode);\r\n}\r\nstatic void handle_cap_export(struct inode *inode, struct ceph_mds_caps *ex,\r\nstruct ceph_mds_session *session,\r\nint *open_target_sessions)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds = session->s_mds;\r\nunsigned mseq = le32_to_cpu(ex->migrate_seq);\r\nstruct ceph_cap *cap = NULL, *t;\r\nstruct rb_node *p;\r\nint remember = 1;\r\ndout("handle_cap_export inode %p ci %p mds%d mseq %d\n",\r\ninode, ci, mds, mseq);\r\nspin_lock(&ci->i_ceph_lock);\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\nt = rb_entry(p, struct ceph_cap, ci_node);\r\nif (ceph_seq_cmp(t->mseq, mseq) > 0) {\r\ndout(" higher mseq on cap from mds%d\n",\r\nt->session->s_mds);\r\nremember = 0;\r\n}\r\nif (t->session->s_mds == mds)\r\ncap = t;\r\n}\r\nif (cap) {\r\nif (remember) {\r\nci->i_cap_exporting_mds = mds;\r\nci->i_cap_exporting_mseq = mseq;\r\nci->i_cap_exporting_issued = cap->issued;\r\n*open_target_sessions = 1;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nif (!list_empty(&ci->i_dirty_item)) {\r\ndout(" moving %p to cap_dirty_migrating\n",\r\ninode);\r\nlist_move(&ci->i_dirty_item,\r\n&mdsc->cap_dirty_migrating);\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\n}\r\n__ceph_remove_cap(cap);\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nstatic void handle_cap_import(struct ceph_mds_client *mdsc,\r\nstruct inode *inode, struct ceph_mds_caps *im,\r\nstruct ceph_mds_session *session,\r\nvoid *snaptrace, int snaptrace_len)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds = session->s_mds;\r\nunsigned issued = le32_to_cpu(im->caps);\r\nunsigned wanted = le32_to_cpu(im->wanted);\r\nunsigned seq = le32_to_cpu(im->seq);\r\nunsigned mseq = le32_to_cpu(im->migrate_seq);\r\nu64 realmino = le64_to_cpu(im->realm);\r\nu64 cap_id = le64_to_cpu(im->cap_id);\r\nif (ci->i_cap_exporting_mds >= 0 &&\r\nceph_seq_cmp(ci->i_cap_exporting_mseq, mseq) < 0) {\r\ndout("handle_cap_import inode %p ci %p mds%d mseq %d"\r\n" - cleared exporting from mds%d\n",\r\ninode, ci, mds, mseq,\r\nci->i_cap_exporting_mds);\r\nci->i_cap_exporting_issued = 0;\r\nci->i_cap_exporting_mseq = 0;\r\nci->i_cap_exporting_mds = -1;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nif (!list_empty(&ci->i_dirty_item)) {\r\ndout(" moving %p back to cap_dirty\n", inode);\r\nlist_move(&ci->i_dirty_item, &mdsc->cap_dirty);\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\n} else {\r\ndout("handle_cap_import inode %p ci %p mds%d mseq %d\n",\r\ninode, ci, mds, mseq);\r\n}\r\ndown_write(&mdsc->snap_rwsem);\r\nceph_update_snap_trace(mdsc, snaptrace, snaptrace+snaptrace_len,\r\nfalse);\r\ndowngrade_write(&mdsc->snap_rwsem);\r\nceph_add_cap(inode, session, cap_id, -1,\r\nissued, wanted, seq, mseq, realmino, CEPH_CAP_FLAG_AUTH,\r\nNULL );\r\nkick_flushing_inode_caps(mdsc, session, inode);\r\nup_read(&mdsc->snap_rwsem);\r\nspin_lock(&ci->i_ceph_lock);\r\nci->i_requested_max_size = 0;\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nvoid ceph_handle_caps(struct ceph_mds_session *session,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct ceph_mds_client *mdsc = session->s_mdsc;\r\nstruct super_block *sb = mdsc->fsc->sb;\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_cap *cap;\r\nstruct ceph_mds_caps *h;\r\nint mds = session->s_mds;\r\nint op;\r\nu32 seq, mseq;\r\nstruct ceph_vino vino;\r\nu64 cap_id;\r\nu64 size, max_size;\r\nu64 tid;\r\nvoid *snaptrace;\r\nsize_t snaptrace_len;\r\nvoid *flock;\r\nu32 flock_len;\r\nint open_target_sessions = 0;\r\ndout("handle_caps from mds%d\n", mds);\r\ntid = le64_to_cpu(msg->hdr.tid);\r\nif (msg->front.iov_len < sizeof(*h))\r\ngoto bad;\r\nh = msg->front.iov_base;\r\nop = le32_to_cpu(h->op);\r\nvino.ino = le64_to_cpu(h->ino);\r\nvino.snap = CEPH_NOSNAP;\r\ncap_id = le64_to_cpu(h->cap_id);\r\nseq = le32_to_cpu(h->seq);\r\nmseq = le32_to_cpu(h->migrate_seq);\r\nsize = le64_to_cpu(h->size);\r\nmax_size = le64_to_cpu(h->max_size);\r\nsnaptrace = h + 1;\r\nsnaptrace_len = le32_to_cpu(h->snap_trace_len);\r\nif (le16_to_cpu(msg->hdr.version) >= 2) {\r\nvoid *p, *end;\r\np = snaptrace + snaptrace_len;\r\nend = msg->front.iov_base + msg->front.iov_len;\r\nceph_decode_32_safe(&p, end, flock_len, bad);\r\nflock = p;\r\n} else {\r\nflock = NULL;\r\nflock_len = 0;\r\n}\r\nmutex_lock(&session->s_mutex);\r\nsession->s_seq++;\r\ndout(" mds%d seq %lld cap seq %u\n", session->s_mds, session->s_seq,\r\n(unsigned)seq);\r\ninode = ceph_find_inode(sb, vino);\r\nci = ceph_inode(inode);\r\ndout(" op %s ino %llx.%llx inode %p\n", ceph_cap_op_name(op), vino.ino,\r\nvino.snap, inode);\r\nif (!inode) {\r\ndout(" i don't have ino %llx\n", vino.ino);\r\nif (op == CEPH_CAP_OP_IMPORT)\r\n__queue_cap_release(session, vino.ino, cap_id,\r\nmseq, seq);\r\ngoto flush_cap_releases;\r\n}\r\nswitch (op) {\r\ncase CEPH_CAP_OP_FLUSHSNAP_ACK:\r\nhandle_cap_flushsnap_ack(inode, tid, h, session);\r\ngoto done;\r\ncase CEPH_CAP_OP_EXPORT:\r\nhandle_cap_export(inode, h, session, &open_target_sessions);\r\ngoto done;\r\ncase CEPH_CAP_OP_IMPORT:\r\nhandle_cap_import(mdsc, inode, h, session,\r\nsnaptrace, snaptrace_len);\r\nceph_check_caps(ceph_inode(inode), 0, session);\r\ngoto done_unlocked;\r\n}\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = __get_cap_for_mds(ceph_inode(inode), mds);\r\nif (!cap) {\r\ndout(" no cap on %p ino %llx.%llx from mds%d\n",\r\ninode, ceph_ino(inode), ceph_snap(inode), mds);\r\nspin_unlock(&ci->i_ceph_lock);\r\ngoto flush_cap_releases;\r\n}\r\nswitch (op) {\r\ncase CEPH_CAP_OP_REVOKE:\r\ncase CEPH_CAP_OP_GRANT:\r\nhandle_cap_grant(inode, h, session, cap, msg->middle);\r\ngoto done_unlocked;\r\ncase CEPH_CAP_OP_FLUSH_ACK:\r\nhandle_cap_flush_ack(inode, tid, h, session, cap);\r\nbreak;\r\ncase CEPH_CAP_OP_TRUNC:\r\nhandle_cap_trunc(inode, h, session);\r\nbreak;\r\ndefault:\r\nspin_unlock(&ci->i_ceph_lock);\r\npr_err("ceph_handle_caps: unknown cap op %d %s\n", op,\r\nceph_cap_op_name(op));\r\n}\r\ngoto done;\r\nflush_cap_releases:\r\nceph_add_cap_releases(mdsc, session);\r\nceph_send_cap_releases(mdsc, session);\r\ndone:\r\nmutex_unlock(&session->s_mutex);\r\ndone_unlocked:\r\nif (inode)\r\niput(inode);\r\nif (open_target_sessions)\r\nceph_mdsc_open_export_target_sessions(mdsc, session);\r\nreturn;\r\nbad:\r\npr_err("ceph_handle_caps: corrupt message\n");\r\nceph_msg_dump(msg);\r\nreturn;\r\n}\r\nvoid ceph_check_delayed_caps(struct ceph_mds_client *mdsc)\r\n{\r\nstruct ceph_inode_info *ci;\r\nint flags = CHECK_CAPS_NODELAY;\r\ndout("check_delayed_caps\n");\r\nwhile (1) {\r\nspin_lock(&mdsc->cap_delay_lock);\r\nif (list_empty(&mdsc->cap_delay_list))\r\nbreak;\r\nci = list_first_entry(&mdsc->cap_delay_list,\r\nstruct ceph_inode_info,\r\ni_cap_delay_list);\r\nif ((ci->i_ceph_flags & CEPH_I_FLUSH) == 0 &&\r\ntime_before(jiffies, ci->i_hold_caps_max))\r\nbreak;\r\nlist_del_init(&ci->i_cap_delay_list);\r\nspin_unlock(&mdsc->cap_delay_lock);\r\ndout("check_delayed_caps on %p\n", &ci->vfs_inode);\r\nceph_check_caps(ci, flags, NULL);\r\n}\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\nvoid ceph_flush_dirty_caps(struct ceph_mds_client *mdsc)\r\n{\r\nstruct ceph_inode_info *ci;\r\nstruct inode *inode;\r\ndout("flush_dirty_caps\n");\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nwhile (!list_empty(&mdsc->cap_dirty)) {\r\nci = list_first_entry(&mdsc->cap_dirty, struct ceph_inode_info,\r\ni_dirty_item);\r\ninode = &ci->vfs_inode;\r\nihold(inode);\r\ndout("flush_dirty_caps %p\n", inode);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nceph_check_caps(ci, CHECK_CAPS_NODELAY|CHECK_CAPS_FLUSH, NULL);\r\niput(inode);\r\nspin_lock(&mdsc->cap_dirty_lock);\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\ndout("flush_dirty_caps done\n");\r\n}\r\nvoid ceph_put_fmode(struct ceph_inode_info *ci, int fmode)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nint last = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\ndout("put_fmode %p fmode %d %d -> %d\n", inode, fmode,\r\nci->i_nr_by_mode[fmode], ci->i_nr_by_mode[fmode]-1);\r\nBUG_ON(ci->i_nr_by_mode[fmode] == 0);\r\nif (--ci->i_nr_by_mode[fmode] == 0)\r\nlast++;\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (last && ci->i_vino.snap == CEPH_NOSNAP)\r\nceph_check_caps(ci, 0, NULL);\r\n}\r\nint ceph_encode_inode_release(void **p, struct inode *inode,\r\nint mds, int drop, int unless, int force)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap *cap;\r\nstruct ceph_mds_request_release *rel = *p;\r\nint used, dirty;\r\nint ret = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\nused = __ceph_caps_used(ci);\r\ndirty = __ceph_caps_dirty(ci);\r\ndout("encode_inode_release %p mds%d used|dirty %s drop %s unless %s\n",\r\ninode, mds, ceph_cap_string(used|dirty), ceph_cap_string(drop),\r\nceph_cap_string(unless));\r\ndrop &= ~(used | dirty);\r\ncap = __get_cap_for_mds(ci, mds);\r\nif (cap && __cap_is_valid(cap)) {\r\nif (force ||\r\n((cap->issued & drop) &&\r\n(cap->issued & unless) == 0)) {\r\nif ((cap->issued & drop) &&\r\n(cap->issued & unless) == 0) {\r\ndout("encode_inode_release %p cap %p %s -> "\r\n"%s\n", inode, cap,\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(cap->issued & ~drop));\r\ncap->issued &= ~drop;\r\ncap->implemented &= ~drop;\r\nif (ci->i_ceph_flags & CEPH_I_NODELAY) {\r\nint wanted = __ceph_caps_wanted(ci);\r\ndout(" wanted %s -> %s (act %s)\n",\r\nceph_cap_string(cap->mds_wanted),\r\nceph_cap_string(cap->mds_wanted &\r\n~wanted),\r\nceph_cap_string(wanted));\r\ncap->mds_wanted &= wanted;\r\n}\r\n} else {\r\ndout("encode_inode_release %p cap %p %s"\r\n" (force)\n", inode, cap,\r\nceph_cap_string(cap->issued));\r\n}\r\nrel->ino = cpu_to_le64(ceph_ino(inode));\r\nrel->cap_id = cpu_to_le64(cap->cap_id);\r\nrel->seq = cpu_to_le32(cap->seq);\r\nrel->issue_seq = cpu_to_le32(cap->issue_seq),\r\nrel->mseq = cpu_to_le32(cap->mseq);\r\nrel->caps = cpu_to_le32(cap->issued);\r\nrel->wanted = cpu_to_le32(cap->mds_wanted);\r\nrel->dname_len = 0;\r\nrel->dname_seq = 0;\r\n*p += sizeof(*rel);\r\nret = 1;\r\n} else {\r\ndout("encode_inode_release %p cap %p %s\n",\r\ninode, cap, ceph_cap_string(cap->issued));\r\n}\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn ret;\r\n}\r\nint ceph_encode_dentry_release(void **p, struct dentry *dentry,\r\nint mds, int drop, int unless)\r\n{\r\nstruct inode *dir = dentry->d_parent->d_inode;\r\nstruct ceph_mds_request_release *rel = *p;\r\nstruct ceph_dentry_info *di = ceph_dentry(dentry);\r\nint force = 0;\r\nint ret;\r\nspin_lock(&dentry->d_lock);\r\nif (di->lease_session && di->lease_session->s_mds == mds)\r\nforce = 1;\r\nspin_unlock(&dentry->d_lock);\r\nret = ceph_encode_inode_release(p, dir, mds, drop, unless, force);\r\nspin_lock(&dentry->d_lock);\r\nif (ret && di->lease_session && di->lease_session->s_mds == mds) {\r\ndout("encode_dentry_release %p mds%d seq %d\n",\r\ndentry, mds, (int)di->lease_seq);\r\nrel->dname_len = cpu_to_le32(dentry->d_name.len);\r\nmemcpy(*p, dentry->d_name.name, dentry->d_name.len);\r\n*p += dentry->d_name.len;\r\nrel->dname_seq = cpu_to_le32(di->lease_seq);\r\n__ceph_mdsc_drop_dentry_lease(dentry);\r\n}\r\nspin_unlock(&dentry->d_lock);\r\nreturn ret;\r\n}
