notrace static cycle_t vread_tsc(void)\r\n{\r\ncycle_t ret;\r\nu64 last;\r\nrdtsc_barrier();\r\nret = (cycle_t)vget_cycles();\r\nlast = VVAR(vsyscall_gtod_data).clock.cycle_last;\r\nif (likely(ret >= last))\r\nreturn ret;\r\nasm volatile ("");\r\nreturn last;\r\n}\r\nstatic notrace cycle_t vread_hpet(void)\r\n{\r\nreturn readl((const void __iomem *)fix_to_virt(VSYSCALL_HPET) + 0xf0);\r\n}\r\nnotrace static long vdso_fallback_gettime(long clock, struct timespec *ts)\r\n{\r\nlong ret;\r\nasm("syscall" : "=a" (ret) :\r\n"0" (__NR_clock_gettime),"D" (clock), "S" (ts) : "memory");\r\nreturn ret;\r\n}\r\nnotrace static long vdso_fallback_gtod(struct timeval *tv, struct timezone *tz)\r\n{\r\nlong ret;\r\nasm("syscall" : "=a" (ret) :\r\n"0" (__NR_gettimeofday), "D" (tv), "S" (tz) : "memory");\r\nreturn ret;\r\n}\r\nnotrace static inline long vgetns(void)\r\n{\r\nlong v;\r\ncycles_t cycles;\r\nif (gtod->clock.vclock_mode == VCLOCK_TSC)\r\ncycles = vread_tsc();\r\nelse if (gtod->clock.vclock_mode == VCLOCK_HPET)\r\ncycles = vread_hpet();\r\nelse\r\nreturn 0;\r\nv = (cycles - gtod->clock.cycle_last) & gtod->clock.mask;\r\nreturn (v * gtod->clock.mult) >> gtod->clock.shift;\r\n}\r\nnotrace static int __always_inline do_realtime(struct timespec *ts)\r\n{\r\nunsigned long seq, ns;\r\nint mode;\r\ndo {\r\nseq = read_seqcount_begin(&gtod->seq);\r\nmode = gtod->clock.vclock_mode;\r\nts->tv_sec = gtod->wall_time_sec;\r\nts->tv_nsec = gtod->wall_time_nsec;\r\nns = vgetns();\r\n} while (unlikely(read_seqcount_retry(&gtod->seq, seq)));\r\ntimespec_add_ns(ts, ns);\r\nreturn mode;\r\n}\r\nnotrace static int do_monotonic(struct timespec *ts)\r\n{\r\nunsigned long seq, ns;\r\nint mode;\r\ndo {\r\nseq = read_seqcount_begin(&gtod->seq);\r\nmode = gtod->clock.vclock_mode;\r\nts->tv_sec = gtod->monotonic_time_sec;\r\nts->tv_nsec = gtod->monotonic_time_nsec;\r\nns = vgetns();\r\n} while (unlikely(read_seqcount_retry(&gtod->seq, seq)));\r\ntimespec_add_ns(ts, ns);\r\nreturn mode;\r\n}\r\nnotrace static int do_realtime_coarse(struct timespec *ts)\r\n{\r\nunsigned long seq;\r\ndo {\r\nseq = read_seqcount_begin(&gtod->seq);\r\nts->tv_sec = gtod->wall_time_coarse.tv_sec;\r\nts->tv_nsec = gtod->wall_time_coarse.tv_nsec;\r\n} while (unlikely(read_seqcount_retry(&gtod->seq, seq)));\r\nreturn 0;\r\n}\r\nnotrace static int do_monotonic_coarse(struct timespec *ts)\r\n{\r\nunsigned long seq;\r\ndo {\r\nseq = read_seqcount_begin(&gtod->seq);\r\nts->tv_sec = gtod->monotonic_time_coarse.tv_sec;\r\nts->tv_nsec = gtod->monotonic_time_coarse.tv_nsec;\r\n} while (unlikely(read_seqcount_retry(&gtod->seq, seq)));\r\nreturn 0;\r\n}\r\nnotrace int __vdso_clock_gettime(clockid_t clock, struct timespec *ts)\r\n{\r\nint ret = VCLOCK_NONE;\r\nswitch (clock) {\r\ncase CLOCK_REALTIME:\r\nret = do_realtime(ts);\r\nbreak;\r\ncase CLOCK_MONOTONIC:\r\nret = do_monotonic(ts);\r\nbreak;\r\ncase CLOCK_REALTIME_COARSE:\r\nreturn do_realtime_coarse(ts);\r\ncase CLOCK_MONOTONIC_COARSE:\r\nreturn do_monotonic_coarse(ts);\r\n}\r\nif (ret == VCLOCK_NONE)\r\nreturn vdso_fallback_gettime(clock, ts);\r\nreturn 0;\r\n}\r\nnotrace int __vdso_gettimeofday(struct timeval *tv, struct timezone *tz)\r\n{\r\nlong ret = VCLOCK_NONE;\r\nif (likely(tv != NULL)) {\r\nBUILD_BUG_ON(offsetof(struct timeval, tv_usec) !=\r\noffsetof(struct timespec, tv_nsec) ||\r\nsizeof(*tv) != sizeof(struct timespec));\r\nret = do_realtime((struct timespec *)tv);\r\ntv->tv_usec /= 1000;\r\n}\r\nif (unlikely(tz != NULL)) {\r\ntz->tz_minuteswest = gtod->sys_tz.tz_minuteswest;\r\ntz->tz_dsttime = gtod->sys_tz.tz_dsttime;\r\n}\r\nif (ret == VCLOCK_NONE)\r\nreturn vdso_fallback_gtod(tv, tz);\r\nreturn 0;\r\n}\r\nnotrace time_t __vdso_time(time_t *t)\r\n{\r\ntime_t result = ACCESS_ONCE(VVAR(vsyscall_gtod_data).wall_time_sec);\r\nif (t)\r\n*t = result;\r\nreturn result;\r\n}
