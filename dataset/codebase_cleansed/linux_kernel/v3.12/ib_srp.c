static inline struct srp_target_port *host_to_target(struct Scsi_Host *host)\r\n{\r\nreturn (struct srp_target_port *) host->hostdata;\r\n}\r\nstatic const char *srp_target_info(struct Scsi_Host *host)\r\n{\r\nreturn host_to_target(host)->target_name;\r\n}\r\nstatic int srp_target_is_topspin(struct srp_target_port *target)\r\n{\r\nstatic const u8 topspin_oui[3] = { 0x00, 0x05, 0xad };\r\nstatic const u8 cisco_oui[3] = { 0x00, 0x1b, 0x0d };\r\nreturn topspin_workarounds &&\r\n(!memcmp(&target->ioc_guid, topspin_oui, sizeof topspin_oui) ||\r\n!memcmp(&target->ioc_guid, cisco_oui, sizeof cisco_oui));\r\n}\r\nstatic struct srp_iu *srp_alloc_iu(struct srp_host *host, size_t size,\r\ngfp_t gfp_mask,\r\nenum dma_data_direction direction)\r\n{\r\nstruct srp_iu *iu;\r\niu = kmalloc(sizeof *iu, gfp_mask);\r\nif (!iu)\r\ngoto out;\r\niu->buf = kzalloc(size, gfp_mask);\r\nif (!iu->buf)\r\ngoto out_free_iu;\r\niu->dma = ib_dma_map_single(host->srp_dev->dev, iu->buf, size,\r\ndirection);\r\nif (ib_dma_mapping_error(host->srp_dev->dev, iu->dma))\r\ngoto out_free_buf;\r\niu->size = size;\r\niu->direction = direction;\r\nreturn iu;\r\nout_free_buf:\r\nkfree(iu->buf);\r\nout_free_iu:\r\nkfree(iu);\r\nout:\r\nreturn NULL;\r\n}\r\nstatic void srp_free_iu(struct srp_host *host, struct srp_iu *iu)\r\n{\r\nif (!iu)\r\nreturn;\r\nib_dma_unmap_single(host->srp_dev->dev, iu->dma, iu->size,\r\niu->direction);\r\nkfree(iu->buf);\r\nkfree(iu);\r\n}\r\nstatic void srp_qp_event(struct ib_event *event, void *context)\r\n{\r\npr_debug("QP event %d\n", event->event);\r\n}\r\nstatic int srp_init_qp(struct srp_target_port *target,\r\nstruct ib_qp *qp)\r\n{\r\nstruct ib_qp_attr *attr;\r\nint ret;\r\nattr = kmalloc(sizeof *attr, GFP_KERNEL);\r\nif (!attr)\r\nreturn -ENOMEM;\r\nret = ib_find_pkey(target->srp_host->srp_dev->dev,\r\ntarget->srp_host->port,\r\nbe16_to_cpu(target->path.pkey),\r\n&attr->pkey_index);\r\nif (ret)\r\ngoto out;\r\nattr->qp_state = IB_QPS_INIT;\r\nattr->qp_access_flags = (IB_ACCESS_REMOTE_READ |\r\nIB_ACCESS_REMOTE_WRITE);\r\nattr->port_num = target->srp_host->port;\r\nret = ib_modify_qp(qp, attr,\r\nIB_QP_STATE |\r\nIB_QP_PKEY_INDEX |\r\nIB_QP_ACCESS_FLAGS |\r\nIB_QP_PORT);\r\nout:\r\nkfree(attr);\r\nreturn ret;\r\n}\r\nstatic int srp_new_cm_id(struct srp_target_port *target)\r\n{\r\nstruct ib_cm_id *new_cm_id;\r\nnew_cm_id = ib_create_cm_id(target->srp_host->srp_dev->dev,\r\nsrp_cm_handler, target);\r\nif (IS_ERR(new_cm_id))\r\nreturn PTR_ERR(new_cm_id);\r\nif (target->cm_id)\r\nib_destroy_cm_id(target->cm_id);\r\ntarget->cm_id = new_cm_id;\r\nreturn 0;\r\n}\r\nstatic int srp_create_target_ib(struct srp_target_port *target)\r\n{\r\nstruct ib_qp_init_attr *init_attr;\r\nstruct ib_cq *recv_cq, *send_cq;\r\nstruct ib_qp *qp;\r\nint ret;\r\ninit_attr = kzalloc(sizeof *init_attr, GFP_KERNEL);\r\nif (!init_attr)\r\nreturn -ENOMEM;\r\nrecv_cq = ib_create_cq(target->srp_host->srp_dev->dev,\r\nsrp_recv_completion, NULL, target, SRP_RQ_SIZE,\r\ntarget->comp_vector);\r\nif (IS_ERR(recv_cq)) {\r\nret = PTR_ERR(recv_cq);\r\ngoto err;\r\n}\r\nsend_cq = ib_create_cq(target->srp_host->srp_dev->dev,\r\nsrp_send_completion, NULL, target, SRP_SQ_SIZE,\r\ntarget->comp_vector);\r\nif (IS_ERR(send_cq)) {\r\nret = PTR_ERR(send_cq);\r\ngoto err_recv_cq;\r\n}\r\nib_req_notify_cq(recv_cq, IB_CQ_NEXT_COMP);\r\ninit_attr->event_handler = srp_qp_event;\r\ninit_attr->cap.max_send_wr = SRP_SQ_SIZE;\r\ninit_attr->cap.max_recv_wr = SRP_RQ_SIZE;\r\ninit_attr->cap.max_recv_sge = 1;\r\ninit_attr->cap.max_send_sge = 1;\r\ninit_attr->sq_sig_type = IB_SIGNAL_ALL_WR;\r\ninit_attr->qp_type = IB_QPT_RC;\r\ninit_attr->send_cq = send_cq;\r\ninit_attr->recv_cq = recv_cq;\r\nqp = ib_create_qp(target->srp_host->srp_dev->pd, init_attr);\r\nif (IS_ERR(qp)) {\r\nret = PTR_ERR(qp);\r\ngoto err_send_cq;\r\n}\r\nret = srp_init_qp(target, qp);\r\nif (ret)\r\ngoto err_qp;\r\nif (target->qp)\r\nib_destroy_qp(target->qp);\r\nif (target->recv_cq)\r\nib_destroy_cq(target->recv_cq);\r\nif (target->send_cq)\r\nib_destroy_cq(target->send_cq);\r\ntarget->qp = qp;\r\ntarget->recv_cq = recv_cq;\r\ntarget->send_cq = send_cq;\r\nkfree(init_attr);\r\nreturn 0;\r\nerr_qp:\r\nib_destroy_qp(qp);\r\nerr_send_cq:\r\nib_destroy_cq(send_cq);\r\nerr_recv_cq:\r\nib_destroy_cq(recv_cq);\r\nerr:\r\nkfree(init_attr);\r\nreturn ret;\r\n}\r\nstatic void srp_free_target_ib(struct srp_target_port *target)\r\n{\r\nint i;\r\nib_destroy_qp(target->qp);\r\nib_destroy_cq(target->send_cq);\r\nib_destroy_cq(target->recv_cq);\r\ntarget->qp = NULL;\r\ntarget->send_cq = target->recv_cq = NULL;\r\nfor (i = 0; i < SRP_RQ_SIZE; ++i)\r\nsrp_free_iu(target->srp_host, target->rx_ring[i]);\r\nfor (i = 0; i < SRP_SQ_SIZE; ++i)\r\nsrp_free_iu(target->srp_host, target->tx_ring[i]);\r\n}\r\nstatic void srp_path_rec_completion(int status,\r\nstruct ib_sa_path_rec *pathrec,\r\nvoid *target_ptr)\r\n{\r\nstruct srp_target_port *target = target_ptr;\r\ntarget->status = status;\r\nif (status)\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "Got failed path rec status %d\n", status);\r\nelse\r\ntarget->path = *pathrec;\r\ncomplete(&target->done);\r\n}\r\nstatic int srp_lookup_path(struct srp_target_port *target)\r\n{\r\ntarget->path.numb_path = 1;\r\ninit_completion(&target->done);\r\ntarget->path_query_id = ib_sa_path_rec_get(&srp_sa_client,\r\ntarget->srp_host->srp_dev->dev,\r\ntarget->srp_host->port,\r\n&target->path,\r\nIB_SA_PATH_REC_SERVICE_ID |\r\nIB_SA_PATH_REC_DGID |\r\nIB_SA_PATH_REC_SGID |\r\nIB_SA_PATH_REC_NUMB_PATH |\r\nIB_SA_PATH_REC_PKEY,\r\nSRP_PATH_REC_TIMEOUT_MS,\r\nGFP_KERNEL,\r\nsrp_path_rec_completion,\r\ntarget, &target->path_query);\r\nif (target->path_query_id < 0)\r\nreturn target->path_query_id;\r\nwait_for_completion(&target->done);\r\nif (target->status < 0)\r\nshost_printk(KERN_WARNING, target->scsi_host,\r\nPFX "Path record query failed\n");\r\nreturn target->status;\r\n}\r\nstatic int srp_send_req(struct srp_target_port *target)\r\n{\r\nstruct {\r\nstruct ib_cm_req_param param;\r\nstruct srp_login_req priv;\r\n} *req = NULL;\r\nint status;\r\nreq = kzalloc(sizeof *req, GFP_KERNEL);\r\nif (!req)\r\nreturn -ENOMEM;\r\nreq->param.primary_path = &target->path;\r\nreq->param.alternate_path = NULL;\r\nreq->param.service_id = target->service_id;\r\nreq->param.qp_num = target->qp->qp_num;\r\nreq->param.qp_type = target->qp->qp_type;\r\nreq->param.private_data = &req->priv;\r\nreq->param.private_data_len = sizeof req->priv;\r\nreq->param.flow_control = 1;\r\nget_random_bytes(&req->param.starting_psn, 4);\r\nreq->param.starting_psn &= 0xffffff;\r\nreq->param.responder_resources = 4;\r\nreq->param.remote_cm_response_timeout = 20;\r\nreq->param.local_cm_response_timeout = 20;\r\nreq->param.retry_count = 7;\r\nreq->param.rnr_retry_count = 7;\r\nreq->param.max_cm_retries = 15;\r\nreq->priv.opcode = SRP_LOGIN_REQ;\r\nreq->priv.tag = 0;\r\nreq->priv.req_it_iu_len = cpu_to_be32(target->max_iu_len);\r\nreq->priv.req_buf_fmt = cpu_to_be16(SRP_BUF_FORMAT_DIRECT |\r\nSRP_BUF_FORMAT_INDIRECT);\r\nif (target->io_class == SRP_REV10_IB_IO_CLASS) {\r\nmemcpy(req->priv.initiator_port_id,\r\n&target->path.sgid.global.interface_id, 8);\r\nmemcpy(req->priv.initiator_port_id + 8,\r\n&target->initiator_ext, 8);\r\nmemcpy(req->priv.target_port_id, &target->ioc_guid, 8);\r\nmemcpy(req->priv.target_port_id + 8, &target->id_ext, 8);\r\n} else {\r\nmemcpy(req->priv.initiator_port_id,\r\n&target->initiator_ext, 8);\r\nmemcpy(req->priv.initiator_port_id + 8,\r\n&target->path.sgid.global.interface_id, 8);\r\nmemcpy(req->priv.target_port_id, &target->id_ext, 8);\r\nmemcpy(req->priv.target_port_id + 8, &target->ioc_guid, 8);\r\n}\r\nif (srp_target_is_topspin(target)) {\r\nshost_printk(KERN_DEBUG, target->scsi_host,\r\nPFX "Topspin/Cisco initiator port ID workaround "\r\n"activated for target GUID %016llx\n",\r\n(unsigned long long) be64_to_cpu(target->ioc_guid));\r\nmemset(req->priv.initiator_port_id, 0, 8);\r\nmemcpy(req->priv.initiator_port_id + 8,\r\n&target->srp_host->srp_dev->dev->node_guid, 8);\r\n}\r\nstatus = ib_send_cm_req(target->cm_id, &req->param);\r\nkfree(req);\r\nreturn status;\r\n}\r\nstatic bool srp_queue_remove_work(struct srp_target_port *target)\r\n{\r\nbool changed = false;\r\nspin_lock_irq(&target->lock);\r\nif (target->state != SRP_TARGET_REMOVED) {\r\ntarget->state = SRP_TARGET_REMOVED;\r\nchanged = true;\r\n}\r\nspin_unlock_irq(&target->lock);\r\nif (changed)\r\nqueue_work(system_long_wq, &target->remove_work);\r\nreturn changed;\r\n}\r\nstatic bool srp_change_conn_state(struct srp_target_port *target,\r\nbool connected)\r\n{\r\nbool changed = false;\r\nspin_lock_irq(&target->lock);\r\nif (target->connected != connected) {\r\ntarget->connected = connected;\r\nchanged = true;\r\n}\r\nspin_unlock_irq(&target->lock);\r\nreturn changed;\r\n}\r\nstatic void srp_disconnect_target(struct srp_target_port *target)\r\n{\r\nif (srp_change_conn_state(target, false)) {\r\nif (ib_send_cm_dreq(target->cm_id, NULL, 0)) {\r\nshost_printk(KERN_DEBUG, target->scsi_host,\r\nPFX "Sending CM DREQ failed\n");\r\n}\r\n}\r\n}\r\nstatic void srp_free_req_data(struct srp_target_port *target)\r\n{\r\nstruct ib_device *ibdev = target->srp_host->srp_dev->dev;\r\nstruct srp_request *req;\r\nint i;\r\nfor (i = 0, req = target->req_ring; i < SRP_CMD_SQ_SIZE; ++i, ++req) {\r\nkfree(req->fmr_list);\r\nkfree(req->map_page);\r\nif (req->indirect_dma_addr) {\r\nib_dma_unmap_single(ibdev, req->indirect_dma_addr,\r\ntarget->indirect_size,\r\nDMA_TO_DEVICE);\r\n}\r\nkfree(req->indirect_desc);\r\n}\r\n}\r\nstatic void srp_del_scsi_host_attr(struct Scsi_Host *shost)\r\n{\r\nstruct device_attribute **attr;\r\nfor (attr = shost->hostt->shost_attrs; attr && *attr; ++attr)\r\ndevice_remove_file(&shost->shost_dev, *attr);\r\n}\r\nstatic void srp_remove_target(struct srp_target_port *target)\r\n{\r\nWARN_ON_ONCE(target->state != SRP_TARGET_REMOVED);\r\nsrp_del_scsi_host_attr(target->scsi_host);\r\nsrp_remove_host(target->scsi_host);\r\nscsi_remove_host(target->scsi_host);\r\nsrp_disconnect_target(target);\r\nib_destroy_cm_id(target->cm_id);\r\nsrp_free_target_ib(target);\r\nsrp_free_req_data(target);\r\nscsi_host_put(target->scsi_host);\r\n}\r\nstatic void srp_remove_work(struct work_struct *work)\r\n{\r\nstruct srp_target_port *target =\r\ncontainer_of(work, struct srp_target_port, remove_work);\r\nWARN_ON_ONCE(target->state != SRP_TARGET_REMOVED);\r\nsrp_remove_target(target);\r\nspin_lock(&target->srp_host->target_lock);\r\nlist_del(&target->list);\r\nspin_unlock(&target->srp_host->target_lock);\r\n}\r\nstatic void srp_rport_delete(struct srp_rport *rport)\r\n{\r\nstruct srp_target_port *target = rport->lld_data;\r\nsrp_queue_remove_work(target);\r\n}\r\nstatic int srp_connect_target(struct srp_target_port *target)\r\n{\r\nint retries = 3;\r\nint ret;\r\nWARN_ON_ONCE(target->connected);\r\ntarget->qp_in_error = false;\r\nret = srp_lookup_path(target);\r\nif (ret)\r\nreturn ret;\r\nwhile (1) {\r\ninit_completion(&target->done);\r\nret = srp_send_req(target);\r\nif (ret)\r\nreturn ret;\r\nwait_for_completion(&target->done);\r\nswitch (target->status) {\r\ncase 0:\r\nsrp_change_conn_state(target, true);\r\nreturn 0;\r\ncase SRP_PORT_REDIRECT:\r\nret = srp_lookup_path(target);\r\nif (ret)\r\nreturn ret;\r\nbreak;\r\ncase SRP_DLID_REDIRECT:\r\nbreak;\r\ncase SRP_STALE_CONN:\r\nif (!retries-- || srp_new_cm_id(target)) {\r\nshost_printk(KERN_ERR, target->scsi_host, PFX\r\n"giving up on stale connection\n");\r\ntarget->status = -ECONNRESET;\r\nreturn target->status;\r\n}\r\nshost_printk(KERN_ERR, target->scsi_host, PFX\r\n"retrying stale connection\n");\r\nbreak;\r\ndefault:\r\nreturn target->status;\r\n}\r\n}\r\n}\r\nstatic void srp_unmap_data(struct scsi_cmnd *scmnd,\r\nstruct srp_target_port *target,\r\nstruct srp_request *req)\r\n{\r\nstruct ib_device *ibdev = target->srp_host->srp_dev->dev;\r\nstruct ib_pool_fmr **pfmr;\r\nif (!scsi_sglist(scmnd) ||\r\n(scmnd->sc_data_direction != DMA_TO_DEVICE &&\r\nscmnd->sc_data_direction != DMA_FROM_DEVICE))\r\nreturn;\r\npfmr = req->fmr_list;\r\nwhile (req->nfmr--)\r\nib_fmr_pool_unmap(*pfmr++);\r\nib_dma_unmap_sg(ibdev, scsi_sglist(scmnd), scsi_sg_count(scmnd),\r\nscmnd->sc_data_direction);\r\n}\r\nstatic struct scsi_cmnd *srp_claim_req(struct srp_target_port *target,\r\nstruct srp_request *req,\r\nstruct scsi_cmnd *scmnd)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&target->lock, flags);\r\nif (!scmnd) {\r\nscmnd = req->scmnd;\r\nreq->scmnd = NULL;\r\n} else if (req->scmnd == scmnd) {\r\nreq->scmnd = NULL;\r\n} else {\r\nscmnd = NULL;\r\n}\r\nspin_unlock_irqrestore(&target->lock, flags);\r\nreturn scmnd;\r\n}\r\nstatic void srp_free_req(struct srp_target_port *target,\r\nstruct srp_request *req, struct scsi_cmnd *scmnd,\r\ns32 req_lim_delta)\r\n{\r\nunsigned long flags;\r\nsrp_unmap_data(scmnd, target, req);\r\nspin_lock_irqsave(&target->lock, flags);\r\ntarget->req_lim += req_lim_delta;\r\nlist_add_tail(&req->list, &target->free_reqs);\r\nspin_unlock_irqrestore(&target->lock, flags);\r\n}\r\nstatic void srp_reset_req(struct srp_target_port *target, struct srp_request *req)\r\n{\r\nstruct scsi_cmnd *scmnd = srp_claim_req(target, req, NULL);\r\nif (scmnd) {\r\nsrp_free_req(target, req, scmnd, 0);\r\nscmnd->result = DID_RESET << 16;\r\nscmnd->scsi_done(scmnd);\r\n}\r\n}\r\nstatic int srp_reconnect_target(struct srp_target_port *target)\r\n{\r\nstruct Scsi_Host *shost = target->scsi_host;\r\nint i, ret;\r\nscsi_target_block(&shost->shost_gendev);\r\nsrp_disconnect_target(target);\r\nret = srp_new_cm_id(target);\r\nif (ret == 0)\r\nret = srp_create_target_ib(target);\r\nelse\r\nsrp_create_target_ib(target);\r\nfor (i = 0; i < SRP_CMD_SQ_SIZE; ++i) {\r\nstruct srp_request *req = &target->req_ring[i];\r\nif (req->scmnd)\r\nsrp_reset_req(target, req);\r\n}\r\nINIT_LIST_HEAD(&target->free_tx);\r\nfor (i = 0; i < SRP_SQ_SIZE; ++i)\r\nlist_add(&target->tx_ring[i]->list, &target->free_tx);\r\nif (ret == 0)\r\nret = srp_connect_target(target);\r\nscsi_target_unblock(&shost->shost_gendev, ret == 0 ? SDEV_RUNNING :\r\nSDEV_TRANSPORT_OFFLINE);\r\ntarget->transport_offline = !!ret;\r\nif (ret)\r\ngoto err;\r\nshost_printk(KERN_INFO, target->scsi_host, PFX "reconnect succeeded\n");\r\nreturn ret;\r\nerr:\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "reconnect failed (%d), removing target port.\n", ret);\r\nsrp_queue_remove_work(target);\r\nreturn ret;\r\n}\r\nstatic void srp_map_desc(struct srp_map_state *state, dma_addr_t dma_addr,\r\nunsigned int dma_len, u32 rkey)\r\n{\r\nstruct srp_direct_buf *desc = state->desc;\r\ndesc->va = cpu_to_be64(dma_addr);\r\ndesc->key = cpu_to_be32(rkey);\r\ndesc->len = cpu_to_be32(dma_len);\r\nstate->total_len += dma_len;\r\nstate->desc++;\r\nstate->ndesc++;\r\n}\r\nstatic int srp_map_finish_fmr(struct srp_map_state *state,\r\nstruct srp_target_port *target)\r\n{\r\nstruct srp_device *dev = target->srp_host->srp_dev;\r\nstruct ib_pool_fmr *fmr;\r\nu64 io_addr = 0;\r\nif (!state->npages)\r\nreturn 0;\r\nif (state->npages == 1) {\r\nsrp_map_desc(state, state->base_dma_addr, state->fmr_len,\r\ntarget->rkey);\r\nstate->npages = state->fmr_len = 0;\r\nreturn 0;\r\n}\r\nfmr = ib_fmr_pool_map_phys(dev->fmr_pool, state->pages,\r\nstate->npages, io_addr);\r\nif (IS_ERR(fmr))\r\nreturn PTR_ERR(fmr);\r\n*state->next_fmr++ = fmr;\r\nstate->nfmr++;\r\nsrp_map_desc(state, 0, state->fmr_len, fmr->fmr->rkey);\r\nstate->npages = state->fmr_len = 0;\r\nreturn 0;\r\n}\r\nstatic void srp_map_update_start(struct srp_map_state *state,\r\nstruct scatterlist *sg, int sg_index,\r\ndma_addr_t dma_addr)\r\n{\r\nstate->unmapped_sg = sg;\r\nstate->unmapped_index = sg_index;\r\nstate->unmapped_addr = dma_addr;\r\n}\r\nstatic int srp_map_sg_entry(struct srp_map_state *state,\r\nstruct srp_target_port *target,\r\nstruct scatterlist *sg, int sg_index,\r\nint use_fmr)\r\n{\r\nstruct srp_device *dev = target->srp_host->srp_dev;\r\nstruct ib_device *ibdev = dev->dev;\r\ndma_addr_t dma_addr = ib_sg_dma_address(ibdev, sg);\r\nunsigned int dma_len = ib_sg_dma_len(ibdev, sg);\r\nunsigned int len;\r\nint ret;\r\nif (!dma_len)\r\nreturn 0;\r\nif (use_fmr == SRP_MAP_NO_FMR) {\r\nsrp_map_desc(state, dma_addr, dma_len, target->rkey);\r\nreturn 0;\r\n}\r\nif (dma_addr & ~dev->fmr_page_mask || dma_len > dev->fmr_max_size) {\r\nret = srp_map_finish_fmr(state, target);\r\nif (ret)\r\nreturn ret;\r\nsrp_map_desc(state, dma_addr, dma_len, target->rkey);\r\nsrp_map_update_start(state, NULL, 0, 0);\r\nreturn 0;\r\n}\r\nif (!state->unmapped_sg)\r\nsrp_map_update_start(state, sg, sg_index, dma_addr);\r\nwhile (dma_len) {\r\nif (state->npages == SRP_FMR_SIZE) {\r\nret = srp_map_finish_fmr(state, target);\r\nif (ret)\r\nreturn ret;\r\nsrp_map_update_start(state, sg, sg_index, dma_addr);\r\n}\r\nlen = min_t(unsigned int, dma_len, dev->fmr_page_size);\r\nif (!state->npages)\r\nstate->base_dma_addr = dma_addr;\r\nstate->pages[state->npages++] = dma_addr;\r\nstate->fmr_len += len;\r\ndma_addr += len;\r\ndma_len -= len;\r\n}\r\nret = 0;\r\nif (len != dev->fmr_page_size) {\r\nret = srp_map_finish_fmr(state, target);\r\nif (!ret)\r\nsrp_map_update_start(state, NULL, 0, 0);\r\n}\r\nreturn ret;\r\n}\r\nstatic int srp_map_data(struct scsi_cmnd *scmnd, struct srp_target_port *target,\r\nstruct srp_request *req)\r\n{\r\nstruct scatterlist *scat, *sg;\r\nstruct srp_cmd *cmd = req->cmd->buf;\r\nint i, len, nents, count, use_fmr;\r\nstruct srp_device *dev;\r\nstruct ib_device *ibdev;\r\nstruct srp_map_state state;\r\nstruct srp_indirect_buf *indirect_hdr;\r\nu32 table_len;\r\nu8 fmt;\r\nif (!scsi_sglist(scmnd) || scmnd->sc_data_direction == DMA_NONE)\r\nreturn sizeof (struct srp_cmd);\r\nif (scmnd->sc_data_direction != DMA_FROM_DEVICE &&\r\nscmnd->sc_data_direction != DMA_TO_DEVICE) {\r\nshost_printk(KERN_WARNING, target->scsi_host,\r\nPFX "Unhandled data direction %d\n",\r\nscmnd->sc_data_direction);\r\nreturn -EINVAL;\r\n}\r\nnents = scsi_sg_count(scmnd);\r\nscat = scsi_sglist(scmnd);\r\ndev = target->srp_host->srp_dev;\r\nibdev = dev->dev;\r\ncount = ib_dma_map_sg(ibdev, scat, nents, scmnd->sc_data_direction);\r\nif (unlikely(count == 0))\r\nreturn -EIO;\r\nfmt = SRP_DATA_DESC_DIRECT;\r\nlen = sizeof (struct srp_cmd) + sizeof (struct srp_direct_buf);\r\nif (count == 1) {\r\nstruct srp_direct_buf *buf = (void *) cmd->add_data;\r\nbuf->va = cpu_to_be64(ib_sg_dma_address(ibdev, scat));\r\nbuf->key = cpu_to_be32(target->rkey);\r\nbuf->len = cpu_to_be32(ib_sg_dma_len(ibdev, scat));\r\nreq->nfmr = 0;\r\ngoto map_complete;\r\n}\r\nindirect_hdr = (void *) cmd->add_data;\r\nib_dma_sync_single_for_cpu(ibdev, req->indirect_dma_addr,\r\ntarget->indirect_size, DMA_TO_DEVICE);\r\nmemset(&state, 0, sizeof(state));\r\nstate.desc = req->indirect_desc;\r\nstate.pages = req->map_page;\r\nstate.next_fmr = req->fmr_list;\r\nuse_fmr = dev->fmr_pool ? SRP_MAP_ALLOW_FMR : SRP_MAP_NO_FMR;\r\nfor_each_sg(scat, sg, count, i) {\r\nif (srp_map_sg_entry(&state, target, sg, i, use_fmr)) {\r\ndma_addr_t dma_addr;\r\nunsigned int dma_len;\r\nbacktrack:\r\nsg = state.unmapped_sg;\r\ni = state.unmapped_index;\r\ndma_addr = ib_sg_dma_address(ibdev, sg);\r\ndma_len = ib_sg_dma_len(ibdev, sg);\r\ndma_len -= (state.unmapped_addr - dma_addr);\r\ndma_addr = state.unmapped_addr;\r\nuse_fmr = SRP_MAP_NO_FMR;\r\nsrp_map_desc(&state, dma_addr, dma_len, target->rkey);\r\n}\r\n}\r\nif (use_fmr == SRP_MAP_ALLOW_FMR && srp_map_finish_fmr(&state, target))\r\ngoto backtrack;\r\nreq->nfmr = state.nfmr;\r\nif (state.ndesc == 1) {\r\nstruct srp_direct_buf *buf = (void *) cmd->add_data;\r\n*buf = req->indirect_desc[0];\r\ngoto map_complete;\r\n}\r\nif (unlikely(target->cmd_sg_cnt < state.ndesc &&\r\n!target->allow_ext_sg)) {\r\nshost_printk(KERN_ERR, target->scsi_host,\r\n"Could not fit S/G list into SRP_CMD\n");\r\nreturn -EIO;\r\n}\r\ncount = min(state.ndesc, target->cmd_sg_cnt);\r\ntable_len = state.ndesc * sizeof (struct srp_direct_buf);\r\nfmt = SRP_DATA_DESC_INDIRECT;\r\nlen = sizeof(struct srp_cmd) + sizeof (struct srp_indirect_buf);\r\nlen += count * sizeof (struct srp_direct_buf);\r\nmemcpy(indirect_hdr->desc_list, req->indirect_desc,\r\ncount * sizeof (struct srp_direct_buf));\r\nindirect_hdr->table_desc.va = cpu_to_be64(req->indirect_dma_addr);\r\nindirect_hdr->table_desc.key = cpu_to_be32(target->rkey);\r\nindirect_hdr->table_desc.len = cpu_to_be32(table_len);\r\nindirect_hdr->len = cpu_to_be32(state.total_len);\r\nif (scmnd->sc_data_direction == DMA_TO_DEVICE)\r\ncmd->data_out_desc_cnt = count;\r\nelse\r\ncmd->data_in_desc_cnt = count;\r\nib_dma_sync_single_for_device(ibdev, req->indirect_dma_addr, table_len,\r\nDMA_TO_DEVICE);\r\nmap_complete:\r\nif (scmnd->sc_data_direction == DMA_TO_DEVICE)\r\ncmd->buf_fmt = fmt << 4;\r\nelse\r\ncmd->buf_fmt = fmt;\r\nreturn len;\r\n}\r\nstatic void srp_put_tx_iu(struct srp_target_port *target, struct srp_iu *iu,\r\nenum srp_iu_type iu_type)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&target->lock, flags);\r\nlist_add(&iu->list, &target->free_tx);\r\nif (iu_type != SRP_IU_RSP)\r\n++target->req_lim;\r\nspin_unlock_irqrestore(&target->lock, flags);\r\n}\r\nstatic struct srp_iu *__srp_get_tx_iu(struct srp_target_port *target,\r\nenum srp_iu_type iu_type)\r\n{\r\ns32 rsv = (iu_type == SRP_IU_TSK_MGMT) ? 0 : SRP_TSK_MGMT_SQ_SIZE;\r\nstruct srp_iu *iu;\r\nsrp_send_completion(target->send_cq, target);\r\nif (list_empty(&target->free_tx))\r\nreturn NULL;\r\nif (iu_type != SRP_IU_RSP) {\r\nif (target->req_lim <= rsv) {\r\n++target->zero_req_lim;\r\nreturn NULL;\r\n}\r\n--target->req_lim;\r\n}\r\niu = list_first_entry(&target->free_tx, struct srp_iu, list);\r\nlist_del(&iu->list);\r\nreturn iu;\r\n}\r\nstatic int srp_post_send(struct srp_target_port *target,\r\nstruct srp_iu *iu, int len)\r\n{\r\nstruct ib_sge list;\r\nstruct ib_send_wr wr, *bad_wr;\r\nlist.addr = iu->dma;\r\nlist.length = len;\r\nlist.lkey = target->lkey;\r\nwr.next = NULL;\r\nwr.wr_id = (uintptr_t) iu;\r\nwr.sg_list = &list;\r\nwr.num_sge = 1;\r\nwr.opcode = IB_WR_SEND;\r\nwr.send_flags = IB_SEND_SIGNALED;\r\nreturn ib_post_send(target->qp, &wr, &bad_wr);\r\n}\r\nstatic int srp_post_recv(struct srp_target_port *target, struct srp_iu *iu)\r\n{\r\nstruct ib_recv_wr wr, *bad_wr;\r\nstruct ib_sge list;\r\nlist.addr = iu->dma;\r\nlist.length = iu->size;\r\nlist.lkey = target->lkey;\r\nwr.next = NULL;\r\nwr.wr_id = (uintptr_t) iu;\r\nwr.sg_list = &list;\r\nwr.num_sge = 1;\r\nreturn ib_post_recv(target->qp, &wr, &bad_wr);\r\n}\r\nstatic void srp_process_rsp(struct srp_target_port *target, struct srp_rsp *rsp)\r\n{\r\nstruct srp_request *req;\r\nstruct scsi_cmnd *scmnd;\r\nunsigned long flags;\r\nif (unlikely(rsp->tag & SRP_TAG_TSK_MGMT)) {\r\nspin_lock_irqsave(&target->lock, flags);\r\ntarget->req_lim += be32_to_cpu(rsp->req_lim_delta);\r\nspin_unlock_irqrestore(&target->lock, flags);\r\ntarget->tsk_mgmt_status = -1;\r\nif (be32_to_cpu(rsp->resp_data_len) >= 4)\r\ntarget->tsk_mgmt_status = rsp->data[3];\r\ncomplete(&target->tsk_mgmt_done);\r\n} else {\r\nreq = &target->req_ring[rsp->tag];\r\nscmnd = srp_claim_req(target, req, NULL);\r\nif (!scmnd) {\r\nshost_printk(KERN_ERR, target->scsi_host,\r\n"Null scmnd for RSP w/tag %016llx\n",\r\n(unsigned long long) rsp->tag);\r\nspin_lock_irqsave(&target->lock, flags);\r\ntarget->req_lim += be32_to_cpu(rsp->req_lim_delta);\r\nspin_unlock_irqrestore(&target->lock, flags);\r\nreturn;\r\n}\r\nscmnd->result = rsp->status;\r\nif (rsp->flags & SRP_RSP_FLAG_SNSVALID) {\r\nmemcpy(scmnd->sense_buffer, rsp->data +\r\nbe32_to_cpu(rsp->resp_data_len),\r\nmin_t(int, be32_to_cpu(rsp->sense_data_len),\r\nSCSI_SENSE_BUFFERSIZE));\r\n}\r\nif (rsp->flags & (SRP_RSP_FLAG_DOOVER | SRP_RSP_FLAG_DOUNDER))\r\nscsi_set_resid(scmnd, be32_to_cpu(rsp->data_out_res_cnt));\r\nelse if (rsp->flags & (SRP_RSP_FLAG_DIOVER | SRP_RSP_FLAG_DIUNDER))\r\nscsi_set_resid(scmnd, be32_to_cpu(rsp->data_in_res_cnt));\r\nsrp_free_req(target, req, scmnd,\r\nbe32_to_cpu(rsp->req_lim_delta));\r\nscmnd->host_scribble = NULL;\r\nscmnd->scsi_done(scmnd);\r\n}\r\n}\r\nstatic int srp_response_common(struct srp_target_port *target, s32 req_delta,\r\nvoid *rsp, int len)\r\n{\r\nstruct ib_device *dev = target->srp_host->srp_dev->dev;\r\nunsigned long flags;\r\nstruct srp_iu *iu;\r\nint err;\r\nspin_lock_irqsave(&target->lock, flags);\r\ntarget->req_lim += req_delta;\r\niu = __srp_get_tx_iu(target, SRP_IU_RSP);\r\nspin_unlock_irqrestore(&target->lock, flags);\r\nif (!iu) {\r\nshost_printk(KERN_ERR, target->scsi_host, PFX\r\n"no IU available to send response\n");\r\nreturn 1;\r\n}\r\nib_dma_sync_single_for_cpu(dev, iu->dma, len, DMA_TO_DEVICE);\r\nmemcpy(iu->buf, rsp, len);\r\nib_dma_sync_single_for_device(dev, iu->dma, len, DMA_TO_DEVICE);\r\nerr = srp_post_send(target, iu, len);\r\nif (err) {\r\nshost_printk(KERN_ERR, target->scsi_host, PFX\r\n"unable to post response: %d\n", err);\r\nsrp_put_tx_iu(target, iu, SRP_IU_RSP);\r\n}\r\nreturn err;\r\n}\r\nstatic void srp_process_cred_req(struct srp_target_port *target,\r\nstruct srp_cred_req *req)\r\n{\r\nstruct srp_cred_rsp rsp = {\r\n.opcode = SRP_CRED_RSP,\r\n.tag = req->tag,\r\n};\r\ns32 delta = be32_to_cpu(req->req_lim_delta);\r\nif (srp_response_common(target, delta, &rsp, sizeof rsp))\r\nshost_printk(KERN_ERR, target->scsi_host, PFX\r\n"problems processing SRP_CRED_REQ\n");\r\n}\r\nstatic void srp_process_aer_req(struct srp_target_port *target,\r\nstruct srp_aer_req *req)\r\n{\r\nstruct srp_aer_rsp rsp = {\r\n.opcode = SRP_AER_RSP,\r\n.tag = req->tag,\r\n};\r\ns32 delta = be32_to_cpu(req->req_lim_delta);\r\nshost_printk(KERN_ERR, target->scsi_host, PFX\r\n"ignoring AER for LUN %llu\n", be64_to_cpu(req->lun));\r\nif (srp_response_common(target, delta, &rsp, sizeof rsp))\r\nshost_printk(KERN_ERR, target->scsi_host, PFX\r\n"problems processing SRP_AER_REQ\n");\r\n}\r\nstatic void srp_handle_recv(struct srp_target_port *target, struct ib_wc *wc)\r\n{\r\nstruct ib_device *dev = target->srp_host->srp_dev->dev;\r\nstruct srp_iu *iu = (struct srp_iu *) (uintptr_t) wc->wr_id;\r\nint res;\r\nu8 opcode;\r\nib_dma_sync_single_for_cpu(dev, iu->dma, target->max_ti_iu_len,\r\nDMA_FROM_DEVICE);\r\nopcode = *(u8 *) iu->buf;\r\nif (0) {\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "recv completion, opcode 0x%02x\n", opcode);\r\nprint_hex_dump(KERN_ERR, "", DUMP_PREFIX_OFFSET, 8, 1,\r\niu->buf, wc->byte_len, true);\r\n}\r\nswitch (opcode) {\r\ncase SRP_RSP:\r\nsrp_process_rsp(target, iu->buf);\r\nbreak;\r\ncase SRP_CRED_REQ:\r\nsrp_process_cred_req(target, iu->buf);\r\nbreak;\r\ncase SRP_AER_REQ:\r\nsrp_process_aer_req(target, iu->buf);\r\nbreak;\r\ncase SRP_T_LOGOUT:\r\nshost_printk(KERN_WARNING, target->scsi_host,\r\nPFX "Got target logout request\n");\r\nbreak;\r\ndefault:\r\nshost_printk(KERN_WARNING, target->scsi_host,\r\nPFX "Unhandled SRP opcode 0x%02x\n", opcode);\r\nbreak;\r\n}\r\nib_dma_sync_single_for_device(dev, iu->dma, target->max_ti_iu_len,\r\nDMA_FROM_DEVICE);\r\nres = srp_post_recv(target, iu);\r\nif (res != 0)\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "Recv failed with error code %d\n", res);\r\n}\r\nstatic void srp_handle_qp_err(enum ib_wc_status wc_status,\r\nenum ib_wc_opcode wc_opcode,\r\nstruct srp_target_port *target)\r\n{\r\nif (target->connected && !target->qp_in_error) {\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "failed %s status %d\n",\r\nwc_opcode & IB_WC_RECV ? "receive" : "send",\r\nwc_status);\r\n}\r\ntarget->qp_in_error = true;\r\n}\r\nstatic void srp_recv_completion(struct ib_cq *cq, void *target_ptr)\r\n{\r\nstruct srp_target_port *target = target_ptr;\r\nstruct ib_wc wc;\r\nib_req_notify_cq(cq, IB_CQ_NEXT_COMP);\r\nwhile (ib_poll_cq(cq, 1, &wc) > 0) {\r\nif (likely(wc.status == IB_WC_SUCCESS)) {\r\nsrp_handle_recv(target, &wc);\r\n} else {\r\nsrp_handle_qp_err(wc.status, wc.opcode, target);\r\n}\r\n}\r\n}\r\nstatic void srp_send_completion(struct ib_cq *cq, void *target_ptr)\r\n{\r\nstruct srp_target_port *target = target_ptr;\r\nstruct ib_wc wc;\r\nstruct srp_iu *iu;\r\nwhile (ib_poll_cq(cq, 1, &wc) > 0) {\r\nif (likely(wc.status == IB_WC_SUCCESS)) {\r\niu = (struct srp_iu *) (uintptr_t) wc.wr_id;\r\nlist_add(&iu->list, &target->free_tx);\r\n} else {\r\nsrp_handle_qp_err(wc.status, wc.opcode, target);\r\n}\r\n}\r\n}\r\nstatic int srp_queuecommand(struct Scsi_Host *shost, struct scsi_cmnd *scmnd)\r\n{\r\nstruct srp_target_port *target = host_to_target(shost);\r\nstruct srp_request *req;\r\nstruct srp_iu *iu;\r\nstruct srp_cmd *cmd;\r\nstruct ib_device *dev;\r\nunsigned long flags;\r\nint len;\r\nif (unlikely(target->transport_offline)) {\r\nscmnd->result = DID_NO_CONNECT << 16;\r\nscmnd->scsi_done(scmnd);\r\nreturn 0;\r\n}\r\nspin_lock_irqsave(&target->lock, flags);\r\niu = __srp_get_tx_iu(target, SRP_IU_CMD);\r\nif (!iu)\r\ngoto err_unlock;\r\nreq = list_first_entry(&target->free_reqs, struct srp_request, list);\r\nlist_del(&req->list);\r\nspin_unlock_irqrestore(&target->lock, flags);\r\ndev = target->srp_host->srp_dev->dev;\r\nib_dma_sync_single_for_cpu(dev, iu->dma, target->max_iu_len,\r\nDMA_TO_DEVICE);\r\nscmnd->result = 0;\r\nscmnd->host_scribble = (void *) req;\r\ncmd = iu->buf;\r\nmemset(cmd, 0, sizeof *cmd);\r\ncmd->opcode = SRP_CMD;\r\ncmd->lun = cpu_to_be64((u64) scmnd->device->lun << 48);\r\ncmd->tag = req->index;\r\nmemcpy(cmd->cdb, scmnd->cmnd, scmnd->cmd_len);\r\nreq->scmnd = scmnd;\r\nreq->cmd = iu;\r\nlen = srp_map_data(scmnd, target, req);\r\nif (len < 0) {\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "Failed to map data\n");\r\ngoto err_iu;\r\n}\r\nib_dma_sync_single_for_device(dev, iu->dma, target->max_iu_len,\r\nDMA_TO_DEVICE);\r\nif (srp_post_send(target, iu, len)) {\r\nshost_printk(KERN_ERR, target->scsi_host, PFX "Send failed\n");\r\ngoto err_unmap;\r\n}\r\nreturn 0;\r\nerr_unmap:\r\nsrp_unmap_data(scmnd, target, req);\r\nerr_iu:\r\nsrp_put_tx_iu(target, iu, SRP_IU_CMD);\r\nspin_lock_irqsave(&target->lock, flags);\r\nlist_add(&req->list, &target->free_reqs);\r\nerr_unlock:\r\nspin_unlock_irqrestore(&target->lock, flags);\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\n}\r\nstatic int srp_alloc_iu_bufs(struct srp_target_port *target)\r\n{\r\nint i;\r\nfor (i = 0; i < SRP_RQ_SIZE; ++i) {\r\ntarget->rx_ring[i] = srp_alloc_iu(target->srp_host,\r\ntarget->max_ti_iu_len,\r\nGFP_KERNEL, DMA_FROM_DEVICE);\r\nif (!target->rx_ring[i])\r\ngoto err;\r\n}\r\nfor (i = 0; i < SRP_SQ_SIZE; ++i) {\r\ntarget->tx_ring[i] = srp_alloc_iu(target->srp_host,\r\ntarget->max_iu_len,\r\nGFP_KERNEL, DMA_TO_DEVICE);\r\nif (!target->tx_ring[i])\r\ngoto err;\r\nlist_add(&target->tx_ring[i]->list, &target->free_tx);\r\n}\r\nreturn 0;\r\nerr:\r\nfor (i = 0; i < SRP_RQ_SIZE; ++i) {\r\nsrp_free_iu(target->srp_host, target->rx_ring[i]);\r\ntarget->rx_ring[i] = NULL;\r\n}\r\nfor (i = 0; i < SRP_SQ_SIZE; ++i) {\r\nsrp_free_iu(target->srp_host, target->tx_ring[i]);\r\ntarget->tx_ring[i] = NULL;\r\n}\r\nreturn -ENOMEM;\r\n}\r\nstatic uint32_t srp_compute_rq_tmo(struct ib_qp_attr *qp_attr, int attr_mask)\r\n{\r\nuint64_t T_tr_ns, max_compl_time_ms;\r\nuint32_t rq_tmo_jiffies;\r\nWARN_ON_ONCE((attr_mask & (IB_QP_TIMEOUT | IB_QP_RETRY_CNT)) !=\r\n(IB_QP_TIMEOUT | IB_QP_RETRY_CNT));\r\nT_tr_ns = 4096 * (1ULL << qp_attr->timeout);\r\nmax_compl_time_ms = qp_attr->retry_cnt * 4 * T_tr_ns;\r\ndo_div(max_compl_time_ms, NSEC_PER_MSEC);\r\nrq_tmo_jiffies = msecs_to_jiffies(max_compl_time_ms + 1000);\r\nreturn rq_tmo_jiffies;\r\n}\r\nstatic void srp_cm_rep_handler(struct ib_cm_id *cm_id,\r\nstruct srp_login_rsp *lrsp,\r\nstruct srp_target_port *target)\r\n{\r\nstruct ib_qp_attr *qp_attr = NULL;\r\nint attr_mask = 0;\r\nint ret;\r\nint i;\r\nif (lrsp->opcode == SRP_LOGIN_RSP) {\r\ntarget->max_ti_iu_len = be32_to_cpu(lrsp->max_ti_iu_len);\r\ntarget->req_lim = be32_to_cpu(lrsp->req_lim_delta);\r\ntarget->scsi_host->can_queue\r\n= min(target->req_lim - SRP_TSK_MGMT_SQ_SIZE,\r\ntarget->scsi_host->can_queue);\r\n} else {\r\nshost_printk(KERN_WARNING, target->scsi_host,\r\nPFX "Unhandled RSP opcode %#x\n", lrsp->opcode);\r\nret = -ECONNRESET;\r\ngoto error;\r\n}\r\nif (!target->rx_ring[0]) {\r\nret = srp_alloc_iu_bufs(target);\r\nif (ret)\r\ngoto error;\r\n}\r\nret = -ENOMEM;\r\nqp_attr = kmalloc(sizeof *qp_attr, GFP_KERNEL);\r\nif (!qp_attr)\r\ngoto error;\r\nqp_attr->qp_state = IB_QPS_RTR;\r\nret = ib_cm_init_qp_attr(cm_id, qp_attr, &attr_mask);\r\nif (ret)\r\ngoto error_free;\r\nret = ib_modify_qp(target->qp, qp_attr, attr_mask);\r\nif (ret)\r\ngoto error_free;\r\nfor (i = 0; i < SRP_RQ_SIZE; i++) {\r\nstruct srp_iu *iu = target->rx_ring[i];\r\nret = srp_post_recv(target, iu);\r\nif (ret)\r\ngoto error_free;\r\n}\r\nqp_attr->qp_state = IB_QPS_RTS;\r\nret = ib_cm_init_qp_attr(cm_id, qp_attr, &attr_mask);\r\nif (ret)\r\ngoto error_free;\r\ntarget->rq_tmo_jiffies = srp_compute_rq_tmo(qp_attr, attr_mask);\r\nret = ib_modify_qp(target->qp, qp_attr, attr_mask);\r\nif (ret)\r\ngoto error_free;\r\nret = ib_send_cm_rtu(cm_id, NULL, 0);\r\nerror_free:\r\nkfree(qp_attr);\r\nerror:\r\ntarget->status = ret;\r\n}\r\nstatic void srp_cm_rej_handler(struct ib_cm_id *cm_id,\r\nstruct ib_cm_event *event,\r\nstruct srp_target_port *target)\r\n{\r\nstruct Scsi_Host *shost = target->scsi_host;\r\nstruct ib_class_port_info *cpi;\r\nint opcode;\r\nswitch (event->param.rej_rcvd.reason) {\r\ncase IB_CM_REJ_PORT_CM_REDIRECT:\r\ncpi = event->param.rej_rcvd.ari;\r\ntarget->path.dlid = cpi->redirect_lid;\r\ntarget->path.pkey = cpi->redirect_pkey;\r\ncm_id->remote_cm_qpn = be32_to_cpu(cpi->redirect_qp) & 0x00ffffff;\r\nmemcpy(target->path.dgid.raw, cpi->redirect_gid, 16);\r\ntarget->status = target->path.dlid ?\r\nSRP_DLID_REDIRECT : SRP_PORT_REDIRECT;\r\nbreak;\r\ncase IB_CM_REJ_PORT_REDIRECT:\r\nif (srp_target_is_topspin(target)) {\r\nmemcpy(target->path.dgid.raw,\r\nevent->param.rej_rcvd.ari, 16);\r\nshost_printk(KERN_DEBUG, shost,\r\nPFX "Topspin/Cisco redirect to target port GID %016llx%016llx\n",\r\n(unsigned long long) be64_to_cpu(target->path.dgid.global.subnet_prefix),\r\n(unsigned long long) be64_to_cpu(target->path.dgid.global.interface_id));\r\ntarget->status = SRP_PORT_REDIRECT;\r\n} else {\r\nshost_printk(KERN_WARNING, shost,\r\n" REJ reason: IB_CM_REJ_PORT_REDIRECT\n");\r\ntarget->status = -ECONNRESET;\r\n}\r\nbreak;\r\ncase IB_CM_REJ_DUPLICATE_LOCAL_COMM_ID:\r\nshost_printk(KERN_WARNING, shost,\r\n" REJ reason: IB_CM_REJ_DUPLICATE_LOCAL_COMM_ID\n");\r\ntarget->status = -ECONNRESET;\r\nbreak;\r\ncase IB_CM_REJ_CONSUMER_DEFINED:\r\nopcode = *(u8 *) event->private_data;\r\nif (opcode == SRP_LOGIN_REJ) {\r\nstruct srp_login_rej *rej = event->private_data;\r\nu32 reason = be32_to_cpu(rej->reason);\r\nif (reason == SRP_LOGIN_REJ_REQ_IT_IU_LENGTH_TOO_LARGE)\r\nshost_printk(KERN_WARNING, shost,\r\nPFX "SRP_LOGIN_REJ: requested max_it_iu_len too large\n");\r\nelse\r\nshost_printk(KERN_WARNING, shost,\r\nPFX "SRP LOGIN REJECTED, reason 0x%08x\n", reason);\r\n} else\r\nshost_printk(KERN_WARNING, shost,\r\n" REJ reason: IB_CM_REJ_CONSUMER_DEFINED,"\r\n" opcode 0x%02x\n", opcode);\r\ntarget->status = -ECONNRESET;\r\nbreak;\r\ncase IB_CM_REJ_STALE_CONN:\r\nshost_printk(KERN_WARNING, shost, " REJ reason: stale connection\n");\r\ntarget->status = SRP_STALE_CONN;\r\nbreak;\r\ndefault:\r\nshost_printk(KERN_WARNING, shost, " REJ reason 0x%x\n",\r\nevent->param.rej_rcvd.reason);\r\ntarget->status = -ECONNRESET;\r\n}\r\n}\r\nstatic int srp_cm_handler(struct ib_cm_id *cm_id, struct ib_cm_event *event)\r\n{\r\nstruct srp_target_port *target = cm_id->context;\r\nint comp = 0;\r\nswitch (event->event) {\r\ncase IB_CM_REQ_ERROR:\r\nshost_printk(KERN_DEBUG, target->scsi_host,\r\nPFX "Sending CM REQ failed\n");\r\ncomp = 1;\r\ntarget->status = -ECONNRESET;\r\nbreak;\r\ncase IB_CM_REP_RECEIVED:\r\ncomp = 1;\r\nsrp_cm_rep_handler(cm_id, event->private_data, target);\r\nbreak;\r\ncase IB_CM_REJ_RECEIVED:\r\nshost_printk(KERN_DEBUG, target->scsi_host, PFX "REJ received\n");\r\ncomp = 1;\r\nsrp_cm_rej_handler(cm_id, event, target);\r\nbreak;\r\ncase IB_CM_DREQ_RECEIVED:\r\nshost_printk(KERN_WARNING, target->scsi_host,\r\nPFX "DREQ received - connection closed\n");\r\nsrp_change_conn_state(target, false);\r\nif (ib_send_cm_drep(cm_id, NULL, 0))\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "Sending CM DREP failed\n");\r\nbreak;\r\ncase IB_CM_TIMEWAIT_EXIT:\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "connection closed\n");\r\ntarget->status = 0;\r\nbreak;\r\ncase IB_CM_MRA_RECEIVED:\r\ncase IB_CM_DREQ_ERROR:\r\ncase IB_CM_DREP_RECEIVED:\r\nbreak;\r\ndefault:\r\nshost_printk(KERN_WARNING, target->scsi_host,\r\nPFX "Unhandled CM event %d\n", event->event);\r\nbreak;\r\n}\r\nif (comp)\r\ncomplete(&target->done);\r\nreturn 0;\r\n}\r\nstatic int srp_send_tsk_mgmt(struct srp_target_port *target,\r\nu64 req_tag, unsigned int lun, u8 func)\r\n{\r\nstruct ib_device *dev = target->srp_host->srp_dev->dev;\r\nstruct srp_iu *iu;\r\nstruct srp_tsk_mgmt *tsk_mgmt;\r\nif (!target->connected || target->qp_in_error)\r\nreturn -1;\r\ninit_completion(&target->tsk_mgmt_done);\r\nspin_lock_irq(&target->lock);\r\niu = __srp_get_tx_iu(target, SRP_IU_TSK_MGMT);\r\nspin_unlock_irq(&target->lock);\r\nif (!iu)\r\nreturn -1;\r\nib_dma_sync_single_for_cpu(dev, iu->dma, sizeof *tsk_mgmt,\r\nDMA_TO_DEVICE);\r\ntsk_mgmt = iu->buf;\r\nmemset(tsk_mgmt, 0, sizeof *tsk_mgmt);\r\ntsk_mgmt->opcode = SRP_TSK_MGMT;\r\ntsk_mgmt->lun = cpu_to_be64((u64) lun << 48);\r\ntsk_mgmt->tag = req_tag | SRP_TAG_TSK_MGMT;\r\ntsk_mgmt->tsk_mgmt_func = func;\r\ntsk_mgmt->task_tag = req_tag;\r\nib_dma_sync_single_for_device(dev, iu->dma, sizeof *tsk_mgmt,\r\nDMA_TO_DEVICE);\r\nif (srp_post_send(target, iu, sizeof *tsk_mgmt)) {\r\nsrp_put_tx_iu(target, iu, SRP_IU_TSK_MGMT);\r\nreturn -1;\r\n}\r\nif (!wait_for_completion_timeout(&target->tsk_mgmt_done,\r\nmsecs_to_jiffies(SRP_ABORT_TIMEOUT_MS)))\r\nreturn -1;\r\nreturn 0;\r\n}\r\nstatic int srp_abort(struct scsi_cmnd *scmnd)\r\n{\r\nstruct srp_target_port *target = host_to_target(scmnd->device->host);\r\nstruct srp_request *req = (struct srp_request *) scmnd->host_scribble;\r\nint ret;\r\nshost_printk(KERN_ERR, target->scsi_host, "SRP abort called\n");\r\nif (!req || !srp_claim_req(target, req, scmnd))\r\nreturn FAILED;\r\nif (srp_send_tsk_mgmt(target, req->index, scmnd->device->lun,\r\nSRP_TSK_ABORT_TASK) == 0)\r\nret = SUCCESS;\r\nelse if (target->transport_offline)\r\nret = FAST_IO_FAIL;\r\nelse\r\nret = FAILED;\r\nsrp_free_req(target, req, scmnd, 0);\r\nscmnd->result = DID_ABORT << 16;\r\nscmnd->scsi_done(scmnd);\r\nreturn ret;\r\n}\r\nstatic int srp_reset_device(struct scsi_cmnd *scmnd)\r\n{\r\nstruct srp_target_port *target = host_to_target(scmnd->device->host);\r\nint i;\r\nshost_printk(KERN_ERR, target->scsi_host, "SRP reset_device called\n");\r\nif (srp_send_tsk_mgmt(target, SRP_TAG_NO_REQ, scmnd->device->lun,\r\nSRP_TSK_LUN_RESET))\r\nreturn FAILED;\r\nif (target->tsk_mgmt_status)\r\nreturn FAILED;\r\nfor (i = 0; i < SRP_CMD_SQ_SIZE; ++i) {\r\nstruct srp_request *req = &target->req_ring[i];\r\nif (req->scmnd && req->scmnd->device == scmnd->device)\r\nsrp_reset_req(target, req);\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int srp_reset_host(struct scsi_cmnd *scmnd)\r\n{\r\nstruct srp_target_port *target = host_to_target(scmnd->device->host);\r\nint ret = FAILED;\r\nshost_printk(KERN_ERR, target->scsi_host, PFX "SRP reset_host called\n");\r\nif (!srp_reconnect_target(target))\r\nret = SUCCESS;\r\nreturn ret;\r\n}\r\nstatic int srp_slave_configure(struct scsi_device *sdev)\r\n{\r\nstruct Scsi_Host *shost = sdev->host;\r\nstruct srp_target_port *target = host_to_target(shost);\r\nstruct request_queue *q = sdev->request_queue;\r\nunsigned long timeout;\r\nif (sdev->type == TYPE_DISK) {\r\ntimeout = max_t(unsigned, 30 * HZ, target->rq_tmo_jiffies);\r\nblk_queue_rq_timeout(q, timeout);\r\n}\r\nreturn 0;\r\n}\r\nstatic ssize_t show_id_ext(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "0x%016llx\n",\r\n(unsigned long long) be64_to_cpu(target->id_ext));\r\n}\r\nstatic ssize_t show_ioc_guid(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "0x%016llx\n",\r\n(unsigned long long) be64_to_cpu(target->ioc_guid));\r\n}\r\nstatic ssize_t show_service_id(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "0x%016llx\n",\r\n(unsigned long long) be64_to_cpu(target->service_id));\r\n}\r\nstatic ssize_t show_pkey(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "0x%04x\n", be16_to_cpu(target->path.pkey));\r\n}\r\nstatic ssize_t show_dgid(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%pI6\n", target->path.dgid.raw);\r\n}\r\nstatic ssize_t show_orig_dgid(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%pI6\n", target->orig_dgid);\r\n}\r\nstatic ssize_t show_req_lim(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%d\n", target->req_lim);\r\n}\r\nstatic ssize_t show_zero_req_lim(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%d\n", target->zero_req_lim);\r\n}\r\nstatic ssize_t show_local_ib_port(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%d\n", target->srp_host->port);\r\n}\r\nstatic ssize_t show_local_ib_device(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%s\n", target->srp_host->srp_dev->dev->name);\r\n}\r\nstatic ssize_t show_comp_vector(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%d\n", target->comp_vector);\r\n}\r\nstatic ssize_t show_cmd_sg_entries(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%u\n", target->cmd_sg_cnt);\r\n}\r\nstatic ssize_t show_allow_ext_sg(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_target_port *target = host_to_target(class_to_shost(dev));\r\nreturn sprintf(buf, "%s\n", target->allow_ext_sg ? "true" : "false");\r\n}\r\nstatic int srp_add_target(struct srp_host *host, struct srp_target_port *target)\r\n{\r\nstruct srp_rport_identifiers ids;\r\nstruct srp_rport *rport;\r\nsprintf(target->target_name, "SRP.T10:%016llX",\r\n(unsigned long long) be64_to_cpu(target->id_ext));\r\nif (scsi_add_host(target->scsi_host, host->srp_dev->dev->dma_device))\r\nreturn -ENODEV;\r\nmemcpy(ids.port_id, &target->id_ext, 8);\r\nmemcpy(ids.port_id + 8, &target->ioc_guid, 8);\r\nids.roles = SRP_RPORT_ROLE_TARGET;\r\nrport = srp_rport_add(target->scsi_host, &ids);\r\nif (IS_ERR(rport)) {\r\nscsi_remove_host(target->scsi_host);\r\nreturn PTR_ERR(rport);\r\n}\r\nrport->lld_data = target;\r\nspin_lock(&host->target_lock);\r\nlist_add_tail(&target->list, &host->target_list);\r\nspin_unlock(&host->target_lock);\r\ntarget->state = SRP_TARGET_LIVE;\r\nscsi_scan_target(&target->scsi_host->shost_gendev,\r\n0, target->scsi_id, SCAN_WILD_CARD, 0);\r\nreturn 0;\r\n}\r\nstatic void srp_release_dev(struct device *dev)\r\n{\r\nstruct srp_host *host =\r\ncontainer_of(dev, struct srp_host, dev);\r\ncomplete(&host->released);\r\n}\r\nstatic bool srp_conn_unique(struct srp_host *host,\r\nstruct srp_target_port *target)\r\n{\r\nstruct srp_target_port *t;\r\nbool ret = false;\r\nif (target->state == SRP_TARGET_REMOVED)\r\ngoto out;\r\nret = true;\r\nspin_lock(&host->target_lock);\r\nlist_for_each_entry(t, &host->target_list, list) {\r\nif (t != target &&\r\ntarget->id_ext == t->id_ext &&\r\ntarget->ioc_guid == t->ioc_guid &&\r\ntarget->initiator_ext == t->initiator_ext) {\r\nret = false;\r\nbreak;\r\n}\r\n}\r\nspin_unlock(&host->target_lock);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int srp_parse_options(const char *buf, struct srp_target_port *target)\r\n{\r\nchar *options, *sep_opt;\r\nchar *p;\r\nchar dgid[3];\r\nsubstring_t args[MAX_OPT_ARGS];\r\nint opt_mask = 0;\r\nint token;\r\nint ret = -EINVAL;\r\nint i;\r\noptions = kstrdup(buf, GFP_KERNEL);\r\nif (!options)\r\nreturn -ENOMEM;\r\nsep_opt = options;\r\nwhile ((p = strsep(&sep_opt, ",")) != NULL) {\r\nif (!*p)\r\ncontinue;\r\ntoken = match_token(p, srp_opt_tokens, args);\r\nopt_mask |= token;\r\nswitch (token) {\r\ncase SRP_OPT_ID_EXT:\r\np = match_strdup(args);\r\nif (!p) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\ntarget->id_ext = cpu_to_be64(simple_strtoull(p, NULL, 16));\r\nkfree(p);\r\nbreak;\r\ncase SRP_OPT_IOC_GUID:\r\np = match_strdup(args);\r\nif (!p) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\ntarget->ioc_guid = cpu_to_be64(simple_strtoull(p, NULL, 16));\r\nkfree(p);\r\nbreak;\r\ncase SRP_OPT_DGID:\r\np = match_strdup(args);\r\nif (!p) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nif (strlen(p) != 32) {\r\npr_warn("bad dest GID parameter '%s'\n", p);\r\nkfree(p);\r\ngoto out;\r\n}\r\nfor (i = 0; i < 16; ++i) {\r\nstrlcpy(dgid, p + i * 2, 3);\r\ntarget->path.dgid.raw[i] = simple_strtoul(dgid, NULL, 16);\r\n}\r\nkfree(p);\r\nmemcpy(target->orig_dgid, target->path.dgid.raw, 16);\r\nbreak;\r\ncase SRP_OPT_PKEY:\r\nif (match_hex(args, &token)) {\r\npr_warn("bad P_Key parameter '%s'\n", p);\r\ngoto out;\r\n}\r\ntarget->path.pkey = cpu_to_be16(token);\r\nbreak;\r\ncase SRP_OPT_SERVICE_ID:\r\np = match_strdup(args);\r\nif (!p) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\ntarget->service_id = cpu_to_be64(simple_strtoull(p, NULL, 16));\r\ntarget->path.service_id = target->service_id;\r\nkfree(p);\r\nbreak;\r\ncase SRP_OPT_MAX_SECT:\r\nif (match_int(args, &token)) {\r\npr_warn("bad max sect parameter '%s'\n", p);\r\ngoto out;\r\n}\r\ntarget->scsi_host->max_sectors = token;\r\nbreak;\r\ncase SRP_OPT_MAX_CMD_PER_LUN:\r\nif (match_int(args, &token)) {\r\npr_warn("bad max cmd_per_lun parameter '%s'\n",\r\np);\r\ngoto out;\r\n}\r\ntarget->scsi_host->cmd_per_lun = min(token, SRP_CMD_SQ_SIZE);\r\nbreak;\r\ncase SRP_OPT_IO_CLASS:\r\nif (match_hex(args, &token)) {\r\npr_warn("bad IO class parameter '%s'\n", p);\r\ngoto out;\r\n}\r\nif (token != SRP_REV10_IB_IO_CLASS &&\r\ntoken != SRP_REV16A_IB_IO_CLASS) {\r\npr_warn("unknown IO class parameter value %x specified (use %x or %x).\n",\r\ntoken, SRP_REV10_IB_IO_CLASS,\r\nSRP_REV16A_IB_IO_CLASS);\r\ngoto out;\r\n}\r\ntarget->io_class = token;\r\nbreak;\r\ncase SRP_OPT_INITIATOR_EXT:\r\np = match_strdup(args);\r\nif (!p) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\ntarget->initiator_ext = cpu_to_be64(simple_strtoull(p, NULL, 16));\r\nkfree(p);\r\nbreak;\r\ncase SRP_OPT_CMD_SG_ENTRIES:\r\nif (match_int(args, &token) || token < 1 || token > 255) {\r\npr_warn("bad max cmd_sg_entries parameter '%s'\n",\r\np);\r\ngoto out;\r\n}\r\ntarget->cmd_sg_cnt = token;\r\nbreak;\r\ncase SRP_OPT_ALLOW_EXT_SG:\r\nif (match_int(args, &token)) {\r\npr_warn("bad allow_ext_sg parameter '%s'\n", p);\r\ngoto out;\r\n}\r\ntarget->allow_ext_sg = !!token;\r\nbreak;\r\ncase SRP_OPT_SG_TABLESIZE:\r\nif (match_int(args, &token) || token < 1 ||\r\ntoken > SCSI_MAX_SG_CHAIN_SEGMENTS) {\r\npr_warn("bad max sg_tablesize parameter '%s'\n",\r\np);\r\ngoto out;\r\n}\r\ntarget->sg_tablesize = token;\r\nbreak;\r\ncase SRP_OPT_COMP_VECTOR:\r\nif (match_int(args, &token) || token < 0) {\r\npr_warn("bad comp_vector parameter '%s'\n", p);\r\ngoto out;\r\n}\r\ntarget->comp_vector = token;\r\nbreak;\r\ndefault:\r\npr_warn("unknown parameter or missing value '%s' in target creation request\n",\r\np);\r\ngoto out;\r\n}\r\n}\r\nif ((opt_mask & SRP_OPT_ALL) == SRP_OPT_ALL)\r\nret = 0;\r\nelse\r\nfor (i = 0; i < ARRAY_SIZE(srp_opt_tokens); ++i)\r\nif ((srp_opt_tokens[i].token & SRP_OPT_ALL) &&\r\n!(srp_opt_tokens[i].token & opt_mask))\r\npr_warn("target creation request is missing parameter '%s'\n",\r\nsrp_opt_tokens[i].pattern);\r\nout:\r\nkfree(options);\r\nreturn ret;\r\n}\r\nstatic ssize_t srp_create_target(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct srp_host *host =\r\ncontainer_of(dev, struct srp_host, dev);\r\nstruct Scsi_Host *target_host;\r\nstruct srp_target_port *target;\r\nstruct ib_device *ibdev = host->srp_dev->dev;\r\ndma_addr_t dma_addr;\r\nint i, ret;\r\ntarget_host = scsi_host_alloc(&srp_template,\r\nsizeof (struct srp_target_port));\r\nif (!target_host)\r\nreturn -ENOMEM;\r\ntarget_host->transportt = ib_srp_transport_template;\r\ntarget_host->max_channel = 0;\r\ntarget_host->max_id = 1;\r\ntarget_host->max_lun = SRP_MAX_LUN;\r\ntarget_host->max_cmd_len = sizeof ((struct srp_cmd *) (void *) 0L)->cdb;\r\ntarget = host_to_target(target_host);\r\ntarget->io_class = SRP_REV16A_IB_IO_CLASS;\r\ntarget->scsi_host = target_host;\r\ntarget->srp_host = host;\r\ntarget->lkey = host->srp_dev->mr->lkey;\r\ntarget->rkey = host->srp_dev->mr->rkey;\r\ntarget->cmd_sg_cnt = cmd_sg_entries;\r\ntarget->sg_tablesize = indirect_sg_entries ? : cmd_sg_entries;\r\ntarget->allow_ext_sg = allow_ext_sg;\r\nret = srp_parse_options(buf, target);\r\nif (ret)\r\ngoto err;\r\nif (!srp_conn_unique(target->srp_host, target)) {\r\nshost_printk(KERN_INFO, target->scsi_host,\r\nPFX "Already connected to target port with id_ext=%016llx;ioc_guid=%016llx;initiator_ext=%016llx\n",\r\nbe64_to_cpu(target->id_ext),\r\nbe64_to_cpu(target->ioc_guid),\r\nbe64_to_cpu(target->initiator_ext));\r\nret = -EEXIST;\r\ngoto err;\r\n}\r\nif (!host->srp_dev->fmr_pool && !target->allow_ext_sg &&\r\ntarget->cmd_sg_cnt < target->sg_tablesize) {\r\npr_warn("No FMR pool and no external indirect descriptors, limiting sg_tablesize to cmd_sg_cnt\n");\r\ntarget->sg_tablesize = target->cmd_sg_cnt;\r\n}\r\ntarget_host->sg_tablesize = target->sg_tablesize;\r\ntarget->indirect_size = target->sg_tablesize *\r\nsizeof (struct srp_direct_buf);\r\ntarget->max_iu_len = sizeof (struct srp_cmd) +\r\nsizeof (struct srp_indirect_buf) +\r\ntarget->cmd_sg_cnt * sizeof (struct srp_direct_buf);\r\nINIT_WORK(&target->remove_work, srp_remove_work);\r\nspin_lock_init(&target->lock);\r\nINIT_LIST_HEAD(&target->free_tx);\r\nINIT_LIST_HEAD(&target->free_reqs);\r\nfor (i = 0; i < SRP_CMD_SQ_SIZE; ++i) {\r\nstruct srp_request *req = &target->req_ring[i];\r\nreq->fmr_list = kmalloc(target->cmd_sg_cnt * sizeof (void *),\r\nGFP_KERNEL);\r\nreq->map_page = kmalloc(SRP_FMR_SIZE * sizeof (void *),\r\nGFP_KERNEL);\r\nreq->indirect_desc = kmalloc(target->indirect_size, GFP_KERNEL);\r\nif (!req->fmr_list || !req->map_page || !req->indirect_desc)\r\ngoto err_free_mem;\r\ndma_addr = ib_dma_map_single(ibdev, req->indirect_desc,\r\ntarget->indirect_size,\r\nDMA_TO_DEVICE);\r\nif (ib_dma_mapping_error(ibdev, dma_addr))\r\ngoto err_free_mem;\r\nreq->indirect_dma_addr = dma_addr;\r\nreq->index = i;\r\nlist_add_tail(&req->list, &target->free_reqs);\r\n}\r\nib_query_gid(ibdev, host->port, 0, &target->path.sgid);\r\nshost_printk(KERN_DEBUG, target->scsi_host, PFX\r\n"new target: id_ext %016llx ioc_guid %016llx pkey %04x "\r\n"service_id %016llx dgid %pI6\n",\r\n(unsigned long long) be64_to_cpu(target->id_ext),\r\n(unsigned long long) be64_to_cpu(target->ioc_guid),\r\nbe16_to_cpu(target->path.pkey),\r\n(unsigned long long) be64_to_cpu(target->service_id),\r\ntarget->path.dgid.raw);\r\nret = srp_create_target_ib(target);\r\nif (ret)\r\ngoto err_free_mem;\r\nret = srp_new_cm_id(target);\r\nif (ret)\r\ngoto err_free_ib;\r\nret = srp_connect_target(target);\r\nif (ret) {\r\nshost_printk(KERN_ERR, target->scsi_host,\r\nPFX "Connection failed\n");\r\ngoto err_cm_id;\r\n}\r\nret = srp_add_target(host, target);\r\nif (ret)\r\ngoto err_disconnect;\r\nreturn count;\r\nerr_disconnect:\r\nsrp_disconnect_target(target);\r\nerr_cm_id:\r\nib_destroy_cm_id(target->cm_id);\r\nerr_free_ib:\r\nsrp_free_target_ib(target);\r\nerr_free_mem:\r\nsrp_free_req_data(target);\r\nerr:\r\nscsi_host_put(target_host);\r\nreturn ret;\r\n}\r\nstatic ssize_t show_ibdev(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_host *host = container_of(dev, struct srp_host, dev);\r\nreturn sprintf(buf, "%s\n", host->srp_dev->dev->name);\r\n}\r\nstatic ssize_t show_port(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_host *host = container_of(dev, struct srp_host, dev);\r\nreturn sprintf(buf, "%d\n", host->port);\r\n}\r\nstatic struct srp_host *srp_add_port(struct srp_device *device, u8 port)\r\n{\r\nstruct srp_host *host;\r\nhost = kzalloc(sizeof *host, GFP_KERNEL);\r\nif (!host)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&host->target_list);\r\nspin_lock_init(&host->target_lock);\r\ninit_completion(&host->released);\r\nhost->srp_dev = device;\r\nhost->port = port;\r\nhost->dev.class = &srp_class;\r\nhost->dev.parent = device->dev->dma_device;\r\ndev_set_name(&host->dev, "srp-%s-%d", device->dev->name, port);\r\nif (device_register(&host->dev))\r\ngoto free_host;\r\nif (device_create_file(&host->dev, &dev_attr_add_target))\r\ngoto err_class;\r\nif (device_create_file(&host->dev, &dev_attr_ibdev))\r\ngoto err_class;\r\nif (device_create_file(&host->dev, &dev_attr_port))\r\ngoto err_class;\r\nreturn host;\r\nerr_class:\r\ndevice_unregister(&host->dev);\r\nfree_host:\r\nkfree(host);\r\nreturn NULL;\r\n}\r\nstatic void srp_add_one(struct ib_device *device)\r\n{\r\nstruct srp_device *srp_dev;\r\nstruct ib_device_attr *dev_attr;\r\nstruct ib_fmr_pool_param fmr_param;\r\nstruct srp_host *host;\r\nint max_pages_per_fmr, fmr_page_shift, s, e, p;\r\ndev_attr = kmalloc(sizeof *dev_attr, GFP_KERNEL);\r\nif (!dev_attr)\r\nreturn;\r\nif (ib_query_device(device, dev_attr)) {\r\npr_warn("Query device failed for %s\n", device->name);\r\ngoto free_attr;\r\n}\r\nsrp_dev = kmalloc(sizeof *srp_dev, GFP_KERNEL);\r\nif (!srp_dev)\r\ngoto free_attr;\r\nfmr_page_shift = max(12, ffs(dev_attr->page_size_cap) - 1);\r\nsrp_dev->fmr_page_size = 1 << fmr_page_shift;\r\nsrp_dev->fmr_page_mask = ~((u64) srp_dev->fmr_page_size - 1);\r\nsrp_dev->fmr_max_size = srp_dev->fmr_page_size * SRP_FMR_SIZE;\r\nINIT_LIST_HEAD(&srp_dev->dev_list);\r\nsrp_dev->dev = device;\r\nsrp_dev->pd = ib_alloc_pd(device);\r\nif (IS_ERR(srp_dev->pd))\r\ngoto free_dev;\r\nsrp_dev->mr = ib_get_dma_mr(srp_dev->pd,\r\nIB_ACCESS_LOCAL_WRITE |\r\nIB_ACCESS_REMOTE_READ |\r\nIB_ACCESS_REMOTE_WRITE);\r\nif (IS_ERR(srp_dev->mr))\r\ngoto err_pd;\r\nfor (max_pages_per_fmr = SRP_FMR_SIZE;\r\nmax_pages_per_fmr >= SRP_FMR_MIN_SIZE;\r\nmax_pages_per_fmr /= 2, srp_dev->fmr_max_size /= 2) {\r\nmemset(&fmr_param, 0, sizeof fmr_param);\r\nfmr_param.pool_size = SRP_FMR_POOL_SIZE;\r\nfmr_param.dirty_watermark = SRP_FMR_DIRTY_SIZE;\r\nfmr_param.cache = 1;\r\nfmr_param.max_pages_per_fmr = max_pages_per_fmr;\r\nfmr_param.page_shift = fmr_page_shift;\r\nfmr_param.access = (IB_ACCESS_LOCAL_WRITE |\r\nIB_ACCESS_REMOTE_WRITE |\r\nIB_ACCESS_REMOTE_READ);\r\nsrp_dev->fmr_pool = ib_create_fmr_pool(srp_dev->pd, &fmr_param);\r\nif (!IS_ERR(srp_dev->fmr_pool))\r\nbreak;\r\n}\r\nif (IS_ERR(srp_dev->fmr_pool))\r\nsrp_dev->fmr_pool = NULL;\r\nif (device->node_type == RDMA_NODE_IB_SWITCH) {\r\ns = 0;\r\ne = 0;\r\n} else {\r\ns = 1;\r\ne = device->phys_port_cnt;\r\n}\r\nfor (p = s; p <= e; ++p) {\r\nhost = srp_add_port(srp_dev, p);\r\nif (host)\r\nlist_add_tail(&host->list, &srp_dev->dev_list);\r\n}\r\nib_set_client_data(device, &srp_client, srp_dev);\r\ngoto free_attr;\r\nerr_pd:\r\nib_dealloc_pd(srp_dev->pd);\r\nfree_dev:\r\nkfree(srp_dev);\r\nfree_attr:\r\nkfree(dev_attr);\r\n}\r\nstatic void srp_remove_one(struct ib_device *device)\r\n{\r\nstruct srp_device *srp_dev;\r\nstruct srp_host *host, *tmp_host;\r\nstruct srp_target_port *target;\r\nsrp_dev = ib_get_client_data(device, &srp_client);\r\nif (!srp_dev)\r\nreturn;\r\nlist_for_each_entry_safe(host, tmp_host, &srp_dev->dev_list, list) {\r\ndevice_unregister(&host->dev);\r\nwait_for_completion(&host->released);\r\nspin_lock(&host->target_lock);\r\nlist_for_each_entry(target, &host->target_list, list)\r\nsrp_queue_remove_work(target);\r\nspin_unlock(&host->target_lock);\r\nflush_workqueue(system_long_wq);\r\nkfree(host);\r\n}\r\nif (srp_dev->fmr_pool)\r\nib_destroy_fmr_pool(srp_dev->fmr_pool);\r\nib_dereg_mr(srp_dev->mr);\r\nib_dealloc_pd(srp_dev->pd);\r\nkfree(srp_dev);\r\n}\r\nstatic int __init srp_init_module(void)\r\n{\r\nint ret;\r\nBUILD_BUG_ON(FIELD_SIZEOF(struct ib_wc, wr_id) < sizeof(void *));\r\nif (srp_sg_tablesize) {\r\npr_warn("srp_sg_tablesize is deprecated, please use cmd_sg_entries\n");\r\nif (!cmd_sg_entries)\r\ncmd_sg_entries = srp_sg_tablesize;\r\n}\r\nif (!cmd_sg_entries)\r\ncmd_sg_entries = SRP_DEF_SG_TABLESIZE;\r\nif (cmd_sg_entries > 255) {\r\npr_warn("Clamping cmd_sg_entries to 255\n");\r\ncmd_sg_entries = 255;\r\n}\r\nif (!indirect_sg_entries)\r\nindirect_sg_entries = cmd_sg_entries;\r\nelse if (indirect_sg_entries < cmd_sg_entries) {\r\npr_warn("Bumping up indirect_sg_entries to match cmd_sg_entries (%u)\n",\r\ncmd_sg_entries);\r\nindirect_sg_entries = cmd_sg_entries;\r\n}\r\nib_srp_transport_template =\r\nsrp_attach_transport(&ib_srp_transport_functions);\r\nif (!ib_srp_transport_template)\r\nreturn -ENOMEM;\r\nret = class_register(&srp_class);\r\nif (ret) {\r\npr_err("couldn't register class infiniband_srp\n");\r\nsrp_release_transport(ib_srp_transport_template);\r\nreturn ret;\r\n}\r\nib_sa_register_client(&srp_sa_client);\r\nret = ib_register_client(&srp_client);\r\nif (ret) {\r\npr_err("couldn't register IB client\n");\r\nsrp_release_transport(ib_srp_transport_template);\r\nib_sa_unregister_client(&srp_sa_client);\r\nclass_unregister(&srp_class);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void __exit srp_cleanup_module(void)\r\n{\r\nib_unregister_client(&srp_client);\r\nib_sa_unregister_client(&srp_sa_client);\r\nclass_unregister(&srp_class);\r\nsrp_release_transport(ib_srp_transport_template);\r\n}
