static void sh_irda_write(struct sh_irda_self *self, u32 offset, u16 data)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&self->lock, flags);\r\niowrite16(data, self->membase + offset);\r\nspin_unlock_irqrestore(&self->lock, flags);\r\n}\r\nstatic u16 sh_irda_read(struct sh_irda_self *self, u32 offset)\r\n{\r\nunsigned long flags;\r\nu16 ret;\r\nspin_lock_irqsave(&self->lock, flags);\r\nret = ioread16(self->membase + offset);\r\nspin_unlock_irqrestore(&self->lock, flags);\r\nreturn ret;\r\n}\r\nstatic void sh_irda_update_bits(struct sh_irda_self *self, u32 offset,\r\nu16 mask, u16 data)\r\n{\r\nunsigned long flags;\r\nu16 old, new;\r\nspin_lock_irqsave(&self->lock, flags);\r\nold = ioread16(self->membase + offset);\r\nnew = (old & ~mask) | data;\r\nif (old != new)\r\niowrite16(data, self->membase + offset);\r\nspin_unlock_irqrestore(&self->lock, flags);\r\n}\r\nstatic void sh_irda_rcv_ctrl(struct sh_irda_self *self, int enable)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\nsh_irda_update_bits(self, IRRCTR, RE, enable ? RE : 0);\r\ndev_dbg(dev, "recv %s\n", enable ? "enable" : "disable");\r\n}\r\nstatic int sh_irda_set_timeout(struct sh_irda_self *self, int interval)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\nif (SH_IRDA_SIR != self->mode)\r\ninterval = 0;\r\nif (interval < 0 || interval > 2) {\r\ndev_err(dev, "unsupported timeout interval\n");\r\nreturn -EINVAL;\r\n}\r\nsh_irda_update_bits(self, IRCFR, RTO, interval << RTO_SHIFT);\r\nreturn 0;\r\n}\r\nstatic int sh_irda_set_baudrate(struct sh_irda_self *self, int baudrate)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\nu16 val;\r\nif (baudrate < 0)\r\nreturn 0;\r\nif (SH_IRDA_SIR != self->mode) {\r\ndev_err(dev, "it is not SIR mode\n");\r\nreturn -EINVAL;\r\n}\r\nval = (48000000 / 26 / 16 / baudrate) - 1;\r\ndev_dbg(dev, "baudrate = %d, val = 0x%02x\n", baudrate, val);\r\nsh_irda_update_bits(self, SIRBCR, BRC_MASK, val);\r\nreturn 0;\r\n}\r\nstatic int sh_irda_get_rcv_length(struct sh_irda_self *self)\r\n{\r\nreturn RFL_MASK & sh_irda_read(self, IRRFLR);\r\n}\r\nstatic int sh_irda_xir_fre(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "none mode: frame recv\n");\r\nreturn 0;\r\n}\r\nstatic int sh_irda_xir_trov(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "none mode: buffer ram over\n");\r\nreturn 0;\r\n}\r\nstatic int sh_irda_xir_9(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "none mode: time over\n");\r\nreturn 0;\r\n}\r\nstatic int sh_irda_xir_8(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "none mode: framing error\n");\r\nreturn 0;\r\n}\r\nstatic int sh_irda_xir_fte(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "none mode: frame transmit end\n");\r\nreturn 0;\r\n}\r\nstatic int sh_irda_sir_fre(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\nu16 data16;\r\nu8 *data = (u8 *)&data16;\r\nint len = sh_irda_get_rcv_length(self);\r\nint i, j;\r\nif (len > IRDARAM_LEN)\r\nlen = IRDARAM_LEN;\r\ndev_dbg(dev, "frame recv length = %d\n", len);\r\nfor (i = 0; i < len; i++) {\r\nj = i % 2;\r\nif (!j)\r\ndata16 = sh_irda_read(self, IRDARAM + i);\r\nasync_unwrap_char(self->ndev, &self->ndev->stats,\r\n&self->rx_buff, data[j]);\r\n}\r\nself->ndev->last_rx = jiffies;\r\nsh_irda_rcv_ctrl(self, 1);\r\nreturn 0;\r\n}\r\nstatic int sh_irda_sir_trov(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "buffer ram over\n");\r\nsh_irda_rcv_ctrl(self, 1);\r\nreturn 0;\r\n}\r\nstatic int sh_irda_sir_tot(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "time over\n");\r\nsh_irda_set_baudrate(self, 9600);\r\nsh_irda_rcv_ctrl(self, 1);\r\nreturn 0;\r\n}\r\nstatic int sh_irda_sir_fer(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_err(dev, "framing error\n");\r\nsh_irda_rcv_ctrl(self, 1);\r\nreturn 0;\r\n}\r\nstatic int sh_irda_sir_fte(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\ndev_dbg(dev, "frame transmit end\n");\r\nnetif_wake_queue(self->ndev);\r\nreturn 0;\r\n}\r\nstatic void sh_irda_set_mode(struct sh_irda_self *self, enum sh_irda_mode mode)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\nstruct sh_irda_xir_func *func;\r\nconst char *name;\r\nu16 data;\r\nswitch (mode) {\r\ncase SH_IRDA_SIR:\r\nname = "SIR";\r\ndata = TMD_SIR;\r\nfunc = &sh_irda_sir_func;\r\nbreak;\r\ncase SH_IRDA_MIR:\r\nname = "MIR";\r\ndata = TMD_MIR;\r\nfunc = &sh_irda_mfir_func;\r\nbreak;\r\ncase SH_IRDA_FIR:\r\nname = "FIR";\r\ndata = TMD_FIR;\r\nfunc = &sh_irda_mfir_func;\r\nbreak;\r\ndefault:\r\nname = "NONE";\r\ndata = 0;\r\nfunc = &sh_irda_xir_func;\r\nbreak;\r\n}\r\nself->mode = mode;\r\nself->xir_func = func;\r\nsh_irda_update_bits(self, IRTMR, TMD_MASK, data);\r\ndev_dbg(dev, "switch to %s mode", name);\r\n}\r\nstatic void sh_irda_set_irq_mask(struct sh_irda_self *self)\r\n{\r\nu16 tmr_hole;\r\nu16 xir_reg;\r\nsh_irda_update_bits(self, IRTMR, xIM_MASK, xIM_MASK);\r\nsh_irda_update_bits(self, SIRIMR, xIR_MASK, xIR_MASK);\r\nsh_irda_update_bits(self, MFIRIMR, xIR_MASK, xIR_MASK);\r\nsh_irda_update_bits(self, SIRICR, xIR_MASK, xIR_MASK);\r\nsh_irda_update_bits(self, MFIRICR, xIR_MASK, xIR_MASK);\r\nswitch (self->mode) {\r\ncase SH_IRDA_SIR:\r\ntmr_hole = SIM;\r\nxir_reg = SIRIMR;\r\nbreak;\r\ncase SH_IRDA_MIR:\r\ncase SH_IRDA_FIR:\r\ntmr_hole = MIM;\r\nxir_reg = MFIRIMR;\r\nbreak;\r\ndefault:\r\ntmr_hole = 0;\r\nxir_reg = 0;\r\nbreak;\r\n}\r\nif (xir_reg) {\r\nsh_irda_update_bits(self, IRTMR, tmr_hole, 0);\r\nsh_irda_update_bits(self, xir_reg, xIR_MASK, 0);\r\n}\r\n}\r\nstatic irqreturn_t sh_irda_irq(int irq, void *dev_id)\r\n{\r\nstruct sh_irda_self *self = dev_id;\r\nstruct sh_irda_xir_func *func = self->xir_func;\r\nu16 isr = sh_irda_read(self, SIRISR);\r\nsh_irda_write(self, SIRICR, isr);\r\nif (isr & FRE)\r\nfunc->xir_fre(self);\r\nif (isr & TROV)\r\nfunc->xir_trov(self);\r\nif (isr & xIR_9)\r\nfunc->xir_9(self);\r\nif (isr & xIR_8)\r\nfunc->xir_8(self);\r\nif (isr & FTE)\r\nfunc->xir_fte(self);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void sh_irda_crc_reset(struct sh_irda_self *self)\r\n{\r\nsh_irda_write(self, CRCCTR, CRC_RST);\r\n}\r\nstatic void sh_irda_crc_add(struct sh_irda_self *self, u16 data)\r\n{\r\nsh_irda_write(self, CRCIR, data & CRC_IN_MASK);\r\n}\r\nstatic u16 sh_irda_crc_cnt(struct sh_irda_self *self)\r\n{\r\nreturn CRC_CT_MASK & sh_irda_read(self, CRCCTR);\r\n}\r\nstatic u16 sh_irda_crc_out(struct sh_irda_self *self)\r\n{\r\nreturn sh_irda_read(self, CRCOR);\r\n}\r\nstatic int sh_irda_crc_init(struct sh_irda_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\nint ret = -EIO;\r\nu16 val;\r\nsh_irda_crc_reset(self);\r\nsh_irda_crc_add(self, 0xCC);\r\nsh_irda_crc_add(self, 0xF5);\r\nsh_irda_crc_add(self, 0xF1);\r\nsh_irda_crc_add(self, 0xA7);\r\nval = sh_irda_crc_cnt(self);\r\nif (4 != val) {\r\ndev_err(dev, "CRC count error %x\n", val);\r\ngoto crc_init_out;\r\n}\r\nval = sh_irda_crc_out(self);\r\nif (0x51DF != val) {\r\ndev_err(dev, "CRC result error%x\n", val);\r\ngoto crc_init_out;\r\n}\r\nret = 0;\r\ncrc_init_out:\r\nsh_irda_crc_reset(self);\r\nreturn ret;\r\n}\r\nstatic void sh_irda_remove_iobuf(struct sh_irda_self *self)\r\n{\r\nkfree(self->rx_buff.head);\r\nself->tx_buff.head = NULL;\r\nself->tx_buff.data = NULL;\r\nself->rx_buff.head = NULL;\r\nself->rx_buff.data = NULL;\r\n}\r\nstatic int sh_irda_init_iobuf(struct sh_irda_self *self, int rxsize, int txsize)\r\n{\r\nif (self->rx_buff.head ||\r\nself->tx_buff.head) {\r\ndev_err(&self->ndev->dev, "iobuff has already existed.");\r\nreturn -EINVAL;\r\n}\r\nself->rx_buff.head = kmalloc(rxsize, GFP_KERNEL);\r\nif (!self->rx_buff.head)\r\nreturn -ENOMEM;\r\nself->rx_buff.truesize = rxsize;\r\nself->rx_buff.in_frame = FALSE;\r\nself->rx_buff.state = OUTSIDE_FRAME;\r\nself->rx_buff.data = self->rx_buff.head;\r\nself->tx_buff.head = self->membase + IRDARAM;\r\nself->tx_buff.truesize = IRDARAM_LEN;\r\nreturn 0;\r\n}\r\nstatic int sh_irda_hard_xmit(struct sk_buff *skb, struct net_device *ndev)\r\n{\r\nstruct sh_irda_self *self = netdev_priv(ndev);\r\nstruct device *dev = &self->ndev->dev;\r\nint speed = irda_get_next_speed(skb);\r\nint ret;\r\ndev_dbg(dev, "hard xmit\n");\r\nnetif_stop_queue(ndev);\r\nsh_irda_rcv_ctrl(self, 0);\r\nret = sh_irda_set_baudrate(self, speed);\r\nif (ret < 0)\r\ngoto sh_irda_hard_xmit_end;\r\nself->tx_buff.len = 0;\r\nif (skb->len) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&self->lock, flags);\r\nself->tx_buff.len = async_wrap_skb(skb,\r\nself->tx_buff.head,\r\nself->tx_buff.truesize);\r\nspin_unlock_irqrestore(&self->lock, flags);\r\nif (self->tx_buff.len > self->tx_buff.truesize)\r\nself->tx_buff.len = self->tx_buff.truesize;\r\nsh_irda_write(self, IRTFLR, self->tx_buff.len);\r\nsh_irda_write(self, IRTCTR, ARMOD | TE);\r\n} else\r\ngoto sh_irda_hard_xmit_end;\r\ndev_kfree_skb(skb);\r\nreturn 0;\r\nsh_irda_hard_xmit_end:\r\nsh_irda_set_baudrate(self, 9600);\r\nnetif_wake_queue(self->ndev);\r\nsh_irda_rcv_ctrl(self, 1);\r\ndev_kfree_skb(skb);\r\nreturn ret;\r\n}\r\nstatic int sh_irda_ioctl(struct net_device *ndev, struct ifreq *ifreq, int cmd)\r\n{\r\nreturn 0;\r\n}\r\nstatic struct net_device_stats *sh_irda_stats(struct net_device *ndev)\r\n{\r\nstruct sh_irda_self *self = netdev_priv(ndev);\r\nreturn &self->ndev->stats;\r\n}\r\nstatic int sh_irda_open(struct net_device *ndev)\r\n{\r\nstruct sh_irda_self *self = netdev_priv(ndev);\r\nint err;\r\npm_runtime_get_sync(&self->pdev->dev);\r\nerr = sh_irda_crc_init(self);\r\nif (err)\r\ngoto open_err;\r\nsh_irda_set_mode(self, SH_IRDA_SIR);\r\nsh_irda_set_timeout(self, 2);\r\nsh_irda_set_baudrate(self, 9600);\r\nself->irlap = irlap_open(ndev, &self->qos, DRIVER_NAME);\r\nif (!self->irlap) {\r\nerr = -ENODEV;\r\ngoto open_err;\r\n}\r\nnetif_start_queue(ndev);\r\nsh_irda_rcv_ctrl(self, 1);\r\nsh_irda_set_irq_mask(self);\r\ndev_info(&ndev->dev, "opened\n");\r\nreturn 0;\r\nopen_err:\r\npm_runtime_put_sync(&self->pdev->dev);\r\nreturn err;\r\n}\r\nstatic int sh_irda_stop(struct net_device *ndev)\r\n{\r\nstruct sh_irda_self *self = netdev_priv(ndev);\r\nif (self->irlap) {\r\nirlap_close(self->irlap);\r\nself->irlap = NULL;\r\n}\r\nnetif_stop_queue(ndev);\r\npm_runtime_put_sync(&self->pdev->dev);\r\ndev_info(&ndev->dev, "stopped\n");\r\nreturn 0;\r\n}\r\nstatic int sh_irda_probe(struct platform_device *pdev)\r\n{\r\nstruct net_device *ndev;\r\nstruct sh_irda_self *self;\r\nstruct resource *res;\r\nint irq;\r\nint err = -ENOMEM;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nirq = platform_get_irq(pdev, 0);\r\nif (!res || irq < 0) {\r\ndev_err(&pdev->dev, "Not enough platform resources.\n");\r\ngoto exit;\r\n}\r\nndev = alloc_irdadev(sizeof(*self));\r\nif (!ndev)\r\ngoto exit;\r\nself = netdev_priv(ndev);\r\nself->membase = ioremap_nocache(res->start, resource_size(res));\r\nif (!self->membase) {\r\nerr = -ENXIO;\r\ndev_err(&pdev->dev, "Unable to ioremap.\n");\r\ngoto err_mem_1;\r\n}\r\nerr = sh_irda_init_iobuf(self, IRDA_SKB_MAX_MTU, IRDA_SIR_MAX_FRAME);\r\nif (err)\r\ngoto err_mem_2;\r\nself->pdev = pdev;\r\npm_runtime_enable(&pdev->dev);\r\nirda_init_max_qos_capabilies(&self->qos);\r\nndev->netdev_ops = &sh_irda_ndo;\r\nndev->irq = irq;\r\nself->ndev = ndev;\r\nself->qos.baud_rate.bits &= IR_9600;\r\nself->qos.min_turn_time.bits = 1;\r\nspin_lock_init(&self->lock);\r\nirda_qos_bits_to_value(&self->qos);\r\nerr = register_netdev(ndev);\r\nif (err)\r\ngoto err_mem_4;\r\nplatform_set_drvdata(pdev, ndev);\r\nerr = request_irq(irq, sh_irda_irq, IRQF_DISABLED, "sh_irda", self);\r\nif (err) {\r\ndev_warn(&pdev->dev, "Unable to attach sh_irda interrupt\n");\r\ngoto err_mem_4;\r\n}\r\ndev_info(&pdev->dev, "SuperH IrDA probed\n");\r\ngoto exit;\r\nerr_mem_4:\r\npm_runtime_disable(&pdev->dev);\r\nsh_irda_remove_iobuf(self);\r\nerr_mem_2:\r\niounmap(self->membase);\r\nerr_mem_1:\r\nfree_netdev(ndev);\r\nexit:\r\nreturn err;\r\n}\r\nstatic int sh_irda_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *ndev = platform_get_drvdata(pdev);\r\nstruct sh_irda_self *self = netdev_priv(ndev);\r\nif (!self)\r\nreturn 0;\r\nunregister_netdev(ndev);\r\npm_runtime_disable(&pdev->dev);\r\nsh_irda_remove_iobuf(self);\r\niounmap(self->membase);\r\nfree_netdev(ndev);\r\nreturn 0;\r\n}\r\nstatic int sh_irda_runtime_nop(struct device *dev)\r\n{\r\nreturn 0;\r\n}
