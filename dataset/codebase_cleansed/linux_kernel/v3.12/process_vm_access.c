static int process_vm_rw_pages(struct task_struct *task,\r\nstruct mm_struct *mm,\r\nstruct page **process_pages,\r\nunsigned long pa,\r\nunsigned long start_offset,\r\nunsigned long len,\r\nconst struct iovec *lvec,\r\nunsigned long lvec_cnt,\r\nunsigned long *lvec_current,\r\nsize_t *lvec_offset,\r\nint vm_write,\r\nunsigned int nr_pages_to_copy,\r\nssize_t *bytes_copied)\r\n{\r\nint pages_pinned;\r\nvoid *target_kaddr;\r\nint pgs_copied = 0;\r\nint j;\r\nint ret;\r\nssize_t bytes_to_copy;\r\nssize_t rc = 0;\r\n*bytes_copied = 0;\r\ndown_read(&mm->mmap_sem);\r\npages_pinned = get_user_pages(task, mm, pa,\r\nnr_pages_to_copy,\r\nvm_write, 0, process_pages, NULL);\r\nup_read(&mm->mmap_sem);\r\nif (pages_pinned != nr_pages_to_copy) {\r\nrc = -EFAULT;\r\ngoto end;\r\n}\r\nfor (pgs_copied = 0;\r\n(pgs_copied < nr_pages_to_copy) && (*lvec_current < lvec_cnt);\r\npgs_copied++) {\r\nwhile (*lvec_current < lvec_cnt\r\n&& lvec[*lvec_current].iov_len == 0)\r\n(*lvec_current)++;\r\nif (*lvec_current == lvec_cnt)\r\nbreak;\r\nbytes_to_copy = min_t(ssize_t, PAGE_SIZE - start_offset,\r\nlen - *bytes_copied);\r\nbytes_to_copy = min_t(ssize_t, bytes_to_copy,\r\nlvec[*lvec_current].iov_len\r\n- *lvec_offset);\r\ntarget_kaddr = kmap(process_pages[pgs_copied]) + start_offset;\r\nif (vm_write)\r\nret = copy_from_user(target_kaddr,\r\nlvec[*lvec_current].iov_base\r\n+ *lvec_offset,\r\nbytes_to_copy);\r\nelse\r\nret = copy_to_user(lvec[*lvec_current].iov_base\r\n+ *lvec_offset,\r\ntarget_kaddr, bytes_to_copy);\r\nkunmap(process_pages[pgs_copied]);\r\nif (ret) {\r\n*bytes_copied += bytes_to_copy - ret;\r\npgs_copied++;\r\nrc = -EFAULT;\r\ngoto end;\r\n}\r\n*bytes_copied += bytes_to_copy;\r\n*lvec_offset += bytes_to_copy;\r\nif (*lvec_offset == lvec[*lvec_current].iov_len) {\r\n(*lvec_current)++;\r\n*lvec_offset = 0;\r\nstart_offset = (start_offset + bytes_to_copy)\r\n% PAGE_SIZE;\r\nif (start_offset)\r\npgs_copied--;\r\n} else {\r\nstart_offset = 0;\r\n}\r\n}\r\nend:\r\nif (vm_write) {\r\nfor (j = 0; j < pages_pinned; j++) {\r\nif (j < pgs_copied)\r\nset_page_dirty_lock(process_pages[j]);\r\nput_page(process_pages[j]);\r\n}\r\n} else {\r\nfor (j = 0; j < pages_pinned; j++)\r\nput_page(process_pages[j]);\r\n}\r\nreturn rc;\r\n}\r\nstatic int process_vm_rw_single_vec(unsigned long addr,\r\nunsigned long len,\r\nconst struct iovec *lvec,\r\nunsigned long lvec_cnt,\r\nunsigned long *lvec_current,\r\nsize_t *lvec_offset,\r\nstruct page **process_pages,\r\nstruct mm_struct *mm,\r\nstruct task_struct *task,\r\nint vm_write,\r\nssize_t *bytes_copied)\r\n{\r\nunsigned long pa = addr & PAGE_MASK;\r\nunsigned long start_offset = addr - pa;\r\nunsigned long nr_pages;\r\nssize_t bytes_copied_loop;\r\nssize_t rc = 0;\r\nunsigned long nr_pages_copied = 0;\r\nunsigned long nr_pages_to_copy;\r\nunsigned long max_pages_per_loop = PVM_MAX_KMALLOC_PAGES\r\n/ sizeof(struct pages *);\r\n*bytes_copied = 0;\r\nif (len == 0)\r\nreturn 0;\r\nnr_pages = (addr + len - 1) / PAGE_SIZE - addr / PAGE_SIZE + 1;\r\nwhile ((nr_pages_copied < nr_pages) && (*lvec_current < lvec_cnt)) {\r\nnr_pages_to_copy = min(nr_pages - nr_pages_copied,\r\nmax_pages_per_loop);\r\nrc = process_vm_rw_pages(task, mm, process_pages, pa,\r\nstart_offset, len,\r\nlvec, lvec_cnt,\r\nlvec_current, lvec_offset,\r\nvm_write, nr_pages_to_copy,\r\n&bytes_copied_loop);\r\nstart_offset = 0;\r\n*bytes_copied += bytes_copied_loop;\r\nif (rc < 0) {\r\nreturn rc;\r\n} else {\r\nlen -= bytes_copied_loop;\r\nnr_pages_copied += nr_pages_to_copy;\r\npa += nr_pages_to_copy * PAGE_SIZE;\r\n}\r\n}\r\nreturn rc;\r\n}\r\nstatic ssize_t process_vm_rw_core(pid_t pid, const struct iovec *lvec,\r\nunsigned long liovcnt,\r\nconst struct iovec *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags, int vm_write)\r\n{\r\nstruct task_struct *task;\r\nstruct page *pp_stack[PVM_MAX_PP_ARRAY_COUNT];\r\nstruct page **process_pages = pp_stack;\r\nstruct mm_struct *mm;\r\nunsigned long i;\r\nssize_t rc = 0;\r\nssize_t bytes_copied_loop;\r\nssize_t bytes_copied = 0;\r\nunsigned long nr_pages = 0;\r\nunsigned long nr_pages_iov;\r\nunsigned long iov_l_curr_idx = 0;\r\nsize_t iov_l_curr_offset = 0;\r\nssize_t iov_len;\r\nfor (i = 0; i < riovcnt; i++) {\r\niov_len = rvec[i].iov_len;\r\nif (iov_len > 0) {\r\nnr_pages_iov = ((unsigned long)rvec[i].iov_base\r\n+ iov_len)\r\n/ PAGE_SIZE - (unsigned long)rvec[i].iov_base\r\n/ PAGE_SIZE + 1;\r\nnr_pages = max(nr_pages, nr_pages_iov);\r\n}\r\n}\r\nif (nr_pages == 0)\r\nreturn 0;\r\nif (nr_pages > PVM_MAX_PP_ARRAY_COUNT) {\r\nprocess_pages = kmalloc(min_t(size_t, PVM_MAX_KMALLOC_PAGES,\r\nsizeof(struct pages *)*nr_pages),\r\nGFP_KERNEL);\r\nif (!process_pages)\r\nreturn -ENOMEM;\r\n}\r\nrcu_read_lock();\r\ntask = find_task_by_vpid(pid);\r\nif (task)\r\nget_task_struct(task);\r\nrcu_read_unlock();\r\nif (!task) {\r\nrc = -ESRCH;\r\ngoto free_proc_pages;\r\n}\r\nmm = mm_access(task, PTRACE_MODE_ATTACH);\r\nif (!mm || IS_ERR(mm)) {\r\nrc = IS_ERR(mm) ? PTR_ERR(mm) : -ESRCH;\r\nif (rc == -EACCES)\r\nrc = -EPERM;\r\ngoto put_task_struct;\r\n}\r\nfor (i = 0; i < riovcnt && iov_l_curr_idx < liovcnt; i++) {\r\nrc = process_vm_rw_single_vec(\r\n(unsigned long)rvec[i].iov_base, rvec[i].iov_len,\r\nlvec, liovcnt, &iov_l_curr_idx, &iov_l_curr_offset,\r\nprocess_pages, mm, task, vm_write, &bytes_copied_loop);\r\nbytes_copied += bytes_copied_loop;\r\nif (rc != 0) {\r\nif (bytes_copied)\r\nrc = bytes_copied;\r\ngoto put_mm;\r\n}\r\n}\r\nrc = bytes_copied;\r\nput_mm:\r\nmmput(mm);\r\nput_task_struct:\r\nput_task_struct(task);\r\nfree_proc_pages:\r\nif (process_pages != pp_stack)\r\nkfree(process_pages);\r\nreturn rc;\r\n}\r\nstatic ssize_t process_vm_rw(pid_t pid,\r\nconst struct iovec __user *lvec,\r\nunsigned long liovcnt,\r\nconst struct iovec __user *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags, int vm_write)\r\n{\r\nstruct iovec iovstack_l[UIO_FASTIOV];\r\nstruct iovec iovstack_r[UIO_FASTIOV];\r\nstruct iovec *iov_l = iovstack_l;\r\nstruct iovec *iov_r = iovstack_r;\r\nssize_t rc;\r\nif (flags != 0)\r\nreturn -EINVAL;\r\nif (vm_write)\r\nrc = rw_copy_check_uvector(WRITE, lvec, liovcnt, UIO_FASTIOV,\r\niovstack_l, &iov_l);\r\nelse\r\nrc = rw_copy_check_uvector(READ, lvec, liovcnt, UIO_FASTIOV,\r\niovstack_l, &iov_l);\r\nif (rc <= 0)\r\ngoto free_iovecs;\r\nrc = rw_copy_check_uvector(CHECK_IOVEC_ONLY, rvec, riovcnt, UIO_FASTIOV,\r\niovstack_r, &iov_r);\r\nif (rc <= 0)\r\ngoto free_iovecs;\r\nrc = process_vm_rw_core(pid, iov_l, liovcnt, iov_r, riovcnt, flags,\r\nvm_write);\r\nfree_iovecs:\r\nif (iov_r != iovstack_r)\r\nkfree(iov_r);\r\nif (iov_l != iovstack_l)\r\nkfree(iov_l);\r\nreturn rc;\r\n}\r\nasmlinkage ssize_t\r\ncompat_process_vm_rw(compat_pid_t pid,\r\nconst struct compat_iovec __user *lvec,\r\nunsigned long liovcnt,\r\nconst struct compat_iovec __user *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags, int vm_write)\r\n{\r\nstruct iovec iovstack_l[UIO_FASTIOV];\r\nstruct iovec iovstack_r[UIO_FASTIOV];\r\nstruct iovec *iov_l = iovstack_l;\r\nstruct iovec *iov_r = iovstack_r;\r\nssize_t rc = -EFAULT;\r\nif (flags != 0)\r\nreturn -EINVAL;\r\nif (vm_write)\r\nrc = compat_rw_copy_check_uvector(WRITE, lvec, liovcnt,\r\nUIO_FASTIOV, iovstack_l,\r\n&iov_l);\r\nelse\r\nrc = compat_rw_copy_check_uvector(READ, lvec, liovcnt,\r\nUIO_FASTIOV, iovstack_l,\r\n&iov_l);\r\nif (rc <= 0)\r\ngoto free_iovecs;\r\nrc = compat_rw_copy_check_uvector(CHECK_IOVEC_ONLY, rvec, riovcnt,\r\nUIO_FASTIOV, iovstack_r,\r\n&iov_r);\r\nif (rc <= 0)\r\ngoto free_iovecs;\r\nrc = process_vm_rw_core(pid, iov_l, liovcnt, iov_r, riovcnt, flags,\r\nvm_write);\r\nfree_iovecs:\r\nif (iov_r != iovstack_r)\r\nkfree(iov_r);\r\nif (iov_l != iovstack_l)\r\nkfree(iov_l);\r\nreturn rc;\r\n}\r\nasmlinkage ssize_t\r\ncompat_sys_process_vm_readv(compat_pid_t pid,\r\nconst struct compat_iovec __user *lvec,\r\nunsigned long liovcnt,\r\nconst struct compat_iovec __user *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags)\r\n{\r\nreturn compat_process_vm_rw(pid, lvec, liovcnt, rvec,\r\nriovcnt, flags, 0);\r\n}\r\nasmlinkage ssize_t\r\ncompat_sys_process_vm_writev(compat_pid_t pid,\r\nconst struct compat_iovec __user *lvec,\r\nunsigned long liovcnt,\r\nconst struct compat_iovec __user *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags)\r\n{\r\nreturn compat_process_vm_rw(pid, lvec, liovcnt, rvec,\r\nriovcnt, flags, 1);\r\n}
