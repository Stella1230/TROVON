static struct v4l2_clk *v4l2_clk_find(const char *dev_id, const char *id)\r\n{\r\nstruct v4l2_clk *clk;\r\nlist_for_each_entry(clk, &clk_list, list) {\r\nif (strcmp(dev_id, clk->dev_id))\r\ncontinue;\r\nif (!id || !clk->id || !strcmp(clk->id, id))\r\nreturn clk;\r\n}\r\nreturn ERR_PTR(-ENODEV);\r\n}\r\nstruct v4l2_clk *v4l2_clk_get(struct device *dev, const char *id)\r\n{\r\nstruct v4l2_clk *clk;\r\nmutex_lock(&clk_lock);\r\nclk = v4l2_clk_find(dev_name(dev), id);\r\nif (!IS_ERR(clk))\r\natomic_inc(&clk->use_count);\r\nmutex_unlock(&clk_lock);\r\nreturn clk;\r\n}\r\nvoid v4l2_clk_put(struct v4l2_clk *clk)\r\n{\r\nstruct v4l2_clk *tmp;\r\nif (IS_ERR(clk))\r\nreturn;\r\nmutex_lock(&clk_lock);\r\nlist_for_each_entry(tmp, &clk_list, list)\r\nif (tmp == clk)\r\natomic_dec(&clk->use_count);\r\nmutex_unlock(&clk_lock);\r\n}\r\nstatic int v4l2_clk_lock_driver(struct v4l2_clk *clk)\r\n{\r\nstruct v4l2_clk *tmp;\r\nint ret = -ENODEV;\r\nmutex_lock(&clk_lock);\r\nlist_for_each_entry(tmp, &clk_list, list)\r\nif (tmp == clk) {\r\nret = !try_module_get(clk->ops->owner);\r\nif (ret)\r\nret = -EFAULT;\r\nbreak;\r\n}\r\nmutex_unlock(&clk_lock);\r\nreturn ret;\r\n}\r\nstatic void v4l2_clk_unlock_driver(struct v4l2_clk *clk)\r\n{\r\nmodule_put(clk->ops->owner);\r\n}\r\nint v4l2_clk_enable(struct v4l2_clk *clk)\r\n{\r\nint ret = v4l2_clk_lock_driver(clk);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&clk->lock);\r\nif (++clk->enable == 1 && clk->ops->enable) {\r\nret = clk->ops->enable(clk);\r\nif (ret < 0)\r\nclk->enable--;\r\n}\r\nmutex_unlock(&clk->lock);\r\nreturn ret;\r\n}\r\nvoid v4l2_clk_disable(struct v4l2_clk *clk)\r\n{\r\nint enable;\r\nmutex_lock(&clk->lock);\r\nenable = --clk->enable;\r\nif (WARN(enable < 0, "Unbalanced %s() on %s:%s!\n", __func__,\r\nclk->dev_id, clk->id))\r\nclk->enable++;\r\nelse if (!enable && clk->ops->disable)\r\nclk->ops->disable(clk);\r\nmutex_unlock(&clk->lock);\r\nv4l2_clk_unlock_driver(clk);\r\n}\r\nunsigned long v4l2_clk_get_rate(struct v4l2_clk *clk)\r\n{\r\nint ret = v4l2_clk_lock_driver(clk);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&clk->lock);\r\nif (!clk->ops->get_rate)\r\nret = -ENOSYS;\r\nelse\r\nret = clk->ops->get_rate(clk);\r\nmutex_unlock(&clk->lock);\r\nv4l2_clk_unlock_driver(clk);\r\nreturn ret;\r\n}\r\nint v4l2_clk_set_rate(struct v4l2_clk *clk, unsigned long rate)\r\n{\r\nint ret = v4l2_clk_lock_driver(clk);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&clk->lock);\r\nif (!clk->ops->set_rate)\r\nret = -ENOSYS;\r\nelse\r\nret = clk->ops->set_rate(clk, rate);\r\nmutex_unlock(&clk->lock);\r\nv4l2_clk_unlock_driver(clk);\r\nreturn ret;\r\n}\r\nstruct v4l2_clk *v4l2_clk_register(const struct v4l2_clk_ops *ops,\r\nconst char *dev_id,\r\nconst char *id, void *priv)\r\n{\r\nstruct v4l2_clk *clk;\r\nint ret;\r\nif (!ops || !dev_id)\r\nreturn ERR_PTR(-EINVAL);\r\nclk = kzalloc(sizeof(struct v4l2_clk), GFP_KERNEL);\r\nif (!clk)\r\nreturn ERR_PTR(-ENOMEM);\r\nclk->id = kstrdup(id, GFP_KERNEL);\r\nclk->dev_id = kstrdup(dev_id, GFP_KERNEL);\r\nif ((id && !clk->id) || !clk->dev_id) {\r\nret = -ENOMEM;\r\ngoto ealloc;\r\n}\r\nclk->ops = ops;\r\nclk->priv = priv;\r\natomic_set(&clk->use_count, 0);\r\nmutex_init(&clk->lock);\r\nmutex_lock(&clk_lock);\r\nif (!IS_ERR(v4l2_clk_find(dev_id, id))) {\r\nmutex_unlock(&clk_lock);\r\nret = -EEXIST;\r\ngoto eexist;\r\n}\r\nlist_add_tail(&clk->list, &clk_list);\r\nmutex_unlock(&clk_lock);\r\nreturn clk;\r\neexist:\r\nealloc:\r\nkfree(clk->id);\r\nkfree(clk->dev_id);\r\nkfree(clk);\r\nreturn ERR_PTR(ret);\r\n}\r\nvoid v4l2_clk_unregister(struct v4l2_clk *clk)\r\n{\r\nif (WARN(atomic_read(&clk->use_count),\r\n"%s(): Refusing to unregister ref-counted %s:%s clock!\n",\r\n__func__, clk->dev_id, clk->id))\r\nreturn;\r\nmutex_lock(&clk_lock);\r\nlist_del(&clk->list);\r\nmutex_unlock(&clk_lock);\r\nkfree(clk->id);\r\nkfree(clk->dev_id);\r\nkfree(clk);\r\n}
