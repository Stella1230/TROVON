static void shrink_liability(struct ubifs_info *c, int nr_to_write)\r\n{\r\ndown_read(&c->vfs_sb->s_umount);\r\nwriteback_inodes_sb(c->vfs_sb, WB_REASON_FS_FREE_SPACE);\r\nup_read(&c->vfs_sb->s_umount);\r\n}\r\nstatic int run_gc(struct ubifs_info *c)\r\n{\r\nint err, lnum;\r\ndown_read(&c->commit_sem);\r\nlnum = ubifs_garbage_collect(c, 1);\r\nup_read(&c->commit_sem);\r\nif (lnum < 0)\r\nreturn lnum;\r\ndbg_budg("GC freed LEB %d", lnum);\r\nerr = ubifs_return_leb(c, lnum);\r\nif (err)\r\nreturn err;\r\nreturn 0;\r\n}\r\nstatic long long get_liability(struct ubifs_info *c)\r\n{\r\nlong long liab;\r\nspin_lock(&c->space_lock);\r\nliab = c->bi.idx_growth + c->bi.data_growth + c->bi.dd_growth;\r\nspin_unlock(&c->space_lock);\r\nreturn liab;\r\n}\r\nstatic int make_free_space(struct ubifs_info *c)\r\n{\r\nint err, retries = 0;\r\nlong long liab1, liab2;\r\ndo {\r\nliab1 = get_liability(c);\r\ndbg_budg("liability %lld, run write-back", liab1);\r\nshrink_liability(c, NR_TO_WRITE);\r\nliab2 = get_liability(c);\r\nif (liab2 < liab1)\r\nreturn -EAGAIN;\r\ndbg_budg("new liability %lld (not shrunk)", liab2);\r\ndbg_budg("Run GC");\r\nerr = run_gc(c);\r\nif (!err)\r\nreturn -EAGAIN;\r\nif (err != -EAGAIN && err != -ENOSPC)\r\nreturn err;\r\ndbg_budg("Run commit (retries %d)", retries);\r\nerr = ubifs_run_commit(c);\r\nif (err)\r\nreturn err;\r\n} while (retries++ < MAX_MKSPC_RETRIES);\r\nreturn -ENOSPC;\r\n}\r\nint ubifs_calc_min_idx_lebs(struct ubifs_info *c)\r\n{\r\nint idx_lebs;\r\nlong long idx_size;\r\nidx_size = c->bi.old_idx_sz + c->bi.idx_growth + c->bi.uncommitted_idx;\r\nidx_size += idx_size << 1;\r\nidx_lebs = div_u64(idx_size + c->idx_leb_size - 1, c->idx_leb_size);\r\nidx_lebs += 1;\r\nif (idx_lebs < MIN_INDEX_LEBS)\r\nidx_lebs = MIN_INDEX_LEBS;\r\nreturn idx_lebs;\r\n}\r\nlong long ubifs_calc_available(const struct ubifs_info *c, int min_idx_lebs)\r\n{\r\nint subtract_lebs;\r\nlong long available;\r\navailable = c->main_bytes - c->lst.total_used;\r\nsubtract_lebs = min_idx_lebs;\r\nsubtract_lebs += 1;\r\nsubtract_lebs += c->jhead_cnt - 1;\r\nsubtract_lebs += 1;\r\navailable -= (long long)subtract_lebs * c->leb_size;\r\navailable -= c->lst.total_dead;\r\navailable -= c->lst.total_dark;\r\nif (c->lst.idx_lebs > min_idx_lebs) {\r\nsubtract_lebs = c->lst.idx_lebs - min_idx_lebs;\r\navailable -= subtract_lebs * c->dark_wm;\r\n}\r\nreturn available > 0 ? available : 0;\r\n}\r\nstatic int can_use_rp(struct ubifs_info *c)\r\n{\r\nif (uid_eq(current_fsuid(), c->rp_uid) || capable(CAP_SYS_RESOURCE) ||\r\n(!gid_eq(c->rp_gid, GLOBAL_ROOT_GID) && in_group_p(c->rp_gid)))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int do_budget_space(struct ubifs_info *c)\r\n{\r\nlong long outstanding, available;\r\nint lebs, rsvd_idx_lebs, min_idx_lebs;\r\nmin_idx_lebs = ubifs_calc_min_idx_lebs(c);\r\nif (min_idx_lebs > c->lst.idx_lebs)\r\nrsvd_idx_lebs = min_idx_lebs - c->lst.idx_lebs;\r\nelse\r\nrsvd_idx_lebs = 0;\r\nlebs = c->lst.empty_lebs + c->freeable_cnt + c->idx_gc_cnt -\r\nc->lst.taken_empty_lebs;\r\nif (unlikely(rsvd_idx_lebs > lebs)) {\r\ndbg_budg("out of indexing space: min_idx_lebs %d (old %d), rsvd_idx_lebs %d",\r\nmin_idx_lebs, c->bi.min_idx_lebs, rsvd_idx_lebs);\r\nreturn -ENOSPC;\r\n}\r\navailable = ubifs_calc_available(c, min_idx_lebs);\r\noutstanding = c->bi.data_growth + c->bi.dd_growth;\r\nif (unlikely(available < outstanding)) {\r\ndbg_budg("out of data space: available %lld, outstanding %lld",\r\navailable, outstanding);\r\nreturn -ENOSPC;\r\n}\r\nif (available - outstanding <= c->rp_size && !can_use_rp(c))\r\nreturn -ENOSPC;\r\nc->bi.min_idx_lebs = min_idx_lebs;\r\nreturn 0;\r\n}\r\nstatic int calc_idx_growth(const struct ubifs_info *c,\r\nconst struct ubifs_budget_req *req)\r\n{\r\nint znodes;\r\nznodes = req->new_ino + (req->new_page << UBIFS_BLOCKS_PER_PAGE_SHIFT) +\r\nreq->new_dent;\r\nreturn znodes * c->max_idx_node_sz;\r\n}\r\nstatic int calc_data_growth(const struct ubifs_info *c,\r\nconst struct ubifs_budget_req *req)\r\n{\r\nint data_growth;\r\ndata_growth = req->new_ino ? c->bi.inode_budget : 0;\r\nif (req->new_page)\r\ndata_growth += c->bi.page_budget;\r\nif (req->new_dent)\r\ndata_growth += c->bi.dent_budget;\r\ndata_growth += req->new_ino_d;\r\nreturn data_growth;\r\n}\r\nstatic int calc_dd_growth(const struct ubifs_info *c,\r\nconst struct ubifs_budget_req *req)\r\n{\r\nint dd_growth;\r\ndd_growth = req->dirtied_page ? c->bi.page_budget : 0;\r\nif (req->dirtied_ino)\r\ndd_growth += c->bi.inode_budget << (req->dirtied_ino - 1);\r\nif (req->mod_dent)\r\ndd_growth += c->bi.dent_budget;\r\ndd_growth += req->dirtied_ino_d;\r\nreturn dd_growth;\r\n}\r\nint ubifs_budget_space(struct ubifs_info *c, struct ubifs_budget_req *req)\r\n{\r\nint uninitialized_var(cmt_retries), uninitialized_var(wb_retries);\r\nint err, idx_growth, data_growth, dd_growth, retried = 0;\r\nubifs_assert(req->new_page <= 1);\r\nubifs_assert(req->dirtied_page <= 1);\r\nubifs_assert(req->new_dent <= 1);\r\nubifs_assert(req->mod_dent <= 1);\r\nubifs_assert(req->new_ino <= 1);\r\nubifs_assert(req->new_ino_d <= UBIFS_MAX_INO_DATA);\r\nubifs_assert(req->dirtied_ino <= 4);\r\nubifs_assert(req->dirtied_ino_d <= UBIFS_MAX_INO_DATA * 4);\r\nubifs_assert(!(req->new_ino_d & 7));\r\nubifs_assert(!(req->dirtied_ino_d & 7));\r\ndata_growth = calc_data_growth(c, req);\r\ndd_growth = calc_dd_growth(c, req);\r\nif (!data_growth && !dd_growth)\r\nreturn 0;\r\nidx_growth = calc_idx_growth(c, req);\r\nagain:\r\nspin_lock(&c->space_lock);\r\nubifs_assert(c->bi.idx_growth >= 0);\r\nubifs_assert(c->bi.data_growth >= 0);\r\nubifs_assert(c->bi.dd_growth >= 0);\r\nif (unlikely(c->bi.nospace) && (c->bi.nospace_rp || !can_use_rp(c))) {\r\ndbg_budg("no space");\r\nspin_unlock(&c->space_lock);\r\nreturn -ENOSPC;\r\n}\r\nc->bi.idx_growth += idx_growth;\r\nc->bi.data_growth += data_growth;\r\nc->bi.dd_growth += dd_growth;\r\nerr = do_budget_space(c);\r\nif (likely(!err)) {\r\nreq->idx_growth = idx_growth;\r\nreq->data_growth = data_growth;\r\nreq->dd_growth = dd_growth;\r\nspin_unlock(&c->space_lock);\r\nreturn 0;\r\n}\r\nc->bi.idx_growth -= idx_growth;\r\nc->bi.data_growth -= data_growth;\r\nc->bi.dd_growth -= dd_growth;\r\nspin_unlock(&c->space_lock);\r\nif (req->fast) {\r\ndbg_budg("no space for fast budgeting");\r\nreturn err;\r\n}\r\nerr = make_free_space(c);\r\ncond_resched();\r\nif (err == -EAGAIN) {\r\ndbg_budg("try again");\r\ngoto again;\r\n} else if (err == -ENOSPC) {\r\nif (!retried) {\r\nretried = 1;\r\ndbg_budg("-ENOSPC, but anyway try once again");\r\ngoto again;\r\n}\r\ndbg_budg("FS is full, -ENOSPC");\r\nc->bi.nospace = 1;\r\nif (can_use_rp(c) || c->rp_size == 0)\r\nc->bi.nospace_rp = 1;\r\nsmp_wmb();\r\n} else\r\nubifs_err("cannot budget space, error %d", err);\r\nreturn err;\r\n}\r\nvoid ubifs_release_budget(struct ubifs_info *c, struct ubifs_budget_req *req)\r\n{\r\nubifs_assert(req->new_page <= 1);\r\nubifs_assert(req->dirtied_page <= 1);\r\nubifs_assert(req->new_dent <= 1);\r\nubifs_assert(req->mod_dent <= 1);\r\nubifs_assert(req->new_ino <= 1);\r\nubifs_assert(req->new_ino_d <= UBIFS_MAX_INO_DATA);\r\nubifs_assert(req->dirtied_ino <= 4);\r\nubifs_assert(req->dirtied_ino_d <= UBIFS_MAX_INO_DATA * 4);\r\nubifs_assert(!(req->new_ino_d & 7));\r\nubifs_assert(!(req->dirtied_ino_d & 7));\r\nif (!req->recalculate) {\r\nubifs_assert(req->idx_growth >= 0);\r\nubifs_assert(req->data_growth >= 0);\r\nubifs_assert(req->dd_growth >= 0);\r\n}\r\nif (req->recalculate) {\r\nreq->data_growth = calc_data_growth(c, req);\r\nreq->dd_growth = calc_dd_growth(c, req);\r\nreq->idx_growth = calc_idx_growth(c, req);\r\n}\r\nif (!req->data_growth && !req->dd_growth)\r\nreturn;\r\nc->bi.nospace = c->bi.nospace_rp = 0;\r\nsmp_wmb();\r\nspin_lock(&c->space_lock);\r\nc->bi.idx_growth -= req->idx_growth;\r\nc->bi.uncommitted_idx += req->idx_growth;\r\nc->bi.data_growth -= req->data_growth;\r\nc->bi.dd_growth -= req->dd_growth;\r\nc->bi.min_idx_lebs = ubifs_calc_min_idx_lebs(c);\r\nubifs_assert(c->bi.idx_growth >= 0);\r\nubifs_assert(c->bi.data_growth >= 0);\r\nubifs_assert(c->bi.dd_growth >= 0);\r\nubifs_assert(c->bi.min_idx_lebs < c->main_lebs);\r\nubifs_assert(!(c->bi.idx_growth & 7));\r\nubifs_assert(!(c->bi.data_growth & 7));\r\nubifs_assert(!(c->bi.dd_growth & 7));\r\nspin_unlock(&c->space_lock);\r\n}\r\nvoid ubifs_convert_page_budget(struct ubifs_info *c)\r\n{\r\nspin_lock(&c->space_lock);\r\nc->bi.idx_growth -= c->max_idx_node_sz << UBIFS_BLOCKS_PER_PAGE_SHIFT;\r\nc->bi.data_growth -= c->bi.page_budget;\r\nc->bi.dd_growth += c->bi.page_budget;\r\nc->bi.min_idx_lebs = ubifs_calc_min_idx_lebs(c);\r\nspin_unlock(&c->space_lock);\r\n}\r\nvoid ubifs_release_dirty_inode_budget(struct ubifs_info *c,\r\nstruct ubifs_inode *ui)\r\n{\r\nstruct ubifs_budget_req req;\r\nmemset(&req, 0, sizeof(struct ubifs_budget_req));\r\nreq.dd_growth = c->bi.inode_budget + ALIGN(ui->data_len, 8);\r\nubifs_release_budget(c, &req);\r\n}\r\nlong long ubifs_reported_space(const struct ubifs_info *c, long long free)\r\n{\r\nint divisor, factor, f;\r\nf = c->fanout > 3 ? c->fanout >> 1 : 2;\r\nfactor = UBIFS_BLOCK_SIZE;\r\ndivisor = UBIFS_MAX_DATA_NODE_SZ;\r\ndivisor += (c->max_idx_node_sz * 3) / (f - 1);\r\nfree *= factor;\r\nreturn div_u64(free, divisor);\r\n}\r\nlong long ubifs_get_free_space_nolock(struct ubifs_info *c)\r\n{\r\nint rsvd_idx_lebs, lebs;\r\nlong long available, outstanding, free;\r\nubifs_assert(c->bi.min_idx_lebs == ubifs_calc_min_idx_lebs(c));\r\noutstanding = c->bi.data_growth + c->bi.dd_growth;\r\navailable = ubifs_calc_available(c, c->bi.min_idx_lebs);\r\nif (c->bi.min_idx_lebs > c->lst.idx_lebs)\r\nrsvd_idx_lebs = c->bi.min_idx_lebs - c->lst.idx_lebs;\r\nelse\r\nrsvd_idx_lebs = 0;\r\nlebs = c->lst.empty_lebs + c->freeable_cnt + c->idx_gc_cnt -\r\nc->lst.taken_empty_lebs;\r\nlebs -= rsvd_idx_lebs;\r\navailable += lebs * (c->dark_wm - c->leb_overhead);\r\nif (available > outstanding)\r\nfree = ubifs_reported_space(c, available - outstanding);\r\nelse\r\nfree = 0;\r\nreturn free;\r\n}\r\nlong long ubifs_get_free_space(struct ubifs_info *c)\r\n{\r\nlong long free;\r\nspin_lock(&c->space_lock);\r\nfree = ubifs_get_free_space_nolock(c);\r\nspin_unlock(&c->space_lock);\r\nreturn free;\r\n}
