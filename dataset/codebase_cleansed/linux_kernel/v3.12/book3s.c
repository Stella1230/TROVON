void kvmppc_core_load_host_debugstate(struct kvm_vcpu *vcpu)\r\n{\r\n}\r\nvoid kvmppc_core_load_guest_debugstate(struct kvm_vcpu *vcpu)\r\n{\r\n}\r\nvoid kvmppc_inject_interrupt(struct kvm_vcpu *vcpu, int vec, u64 flags)\r\n{\r\nvcpu->arch.shared->srr0 = kvmppc_get_pc(vcpu);\r\nvcpu->arch.shared->srr1 = vcpu->arch.shared->msr | flags;\r\nkvmppc_set_pc(vcpu, kvmppc_interrupt_offset(vcpu) + vec);\r\nvcpu->arch.mmu.reset_msr(vcpu);\r\n}\r\nstatic int kvmppc_book3s_vec2irqprio(unsigned int vec)\r\n{\r\nunsigned int prio;\r\nswitch (vec) {\r\ncase 0x100: prio = BOOK3S_IRQPRIO_SYSTEM_RESET; break;\r\ncase 0x200: prio = BOOK3S_IRQPRIO_MACHINE_CHECK; break;\r\ncase 0x300: prio = BOOK3S_IRQPRIO_DATA_STORAGE; break;\r\ncase 0x380: prio = BOOK3S_IRQPRIO_DATA_SEGMENT; break;\r\ncase 0x400: prio = BOOK3S_IRQPRIO_INST_STORAGE; break;\r\ncase 0x480: prio = BOOK3S_IRQPRIO_INST_SEGMENT; break;\r\ncase 0x500: prio = BOOK3S_IRQPRIO_EXTERNAL; break;\r\ncase 0x501: prio = BOOK3S_IRQPRIO_EXTERNAL_LEVEL; break;\r\ncase 0x600: prio = BOOK3S_IRQPRIO_ALIGNMENT; break;\r\ncase 0x700: prio = BOOK3S_IRQPRIO_PROGRAM; break;\r\ncase 0x800: prio = BOOK3S_IRQPRIO_FP_UNAVAIL; break;\r\ncase 0x900: prio = BOOK3S_IRQPRIO_DECREMENTER; break;\r\ncase 0xc00: prio = BOOK3S_IRQPRIO_SYSCALL; break;\r\ncase 0xd00: prio = BOOK3S_IRQPRIO_DEBUG; break;\r\ncase 0xf20: prio = BOOK3S_IRQPRIO_ALTIVEC; break;\r\ncase 0xf40: prio = BOOK3S_IRQPRIO_VSX; break;\r\ndefault: prio = BOOK3S_IRQPRIO_MAX; break;\r\n}\r\nreturn prio;\r\n}\r\nvoid kvmppc_book3s_dequeue_irqprio(struct kvm_vcpu *vcpu,\r\nunsigned int vec)\r\n{\r\nunsigned long old_pending = vcpu->arch.pending_exceptions;\r\nclear_bit(kvmppc_book3s_vec2irqprio(vec),\r\n&vcpu->arch.pending_exceptions);\r\nkvmppc_update_int_pending(vcpu, vcpu->arch.pending_exceptions,\r\nold_pending);\r\n}\r\nvoid kvmppc_book3s_queue_irqprio(struct kvm_vcpu *vcpu, unsigned int vec)\r\n{\r\nvcpu->stat.queue_intr++;\r\nset_bit(kvmppc_book3s_vec2irqprio(vec),\r\n&vcpu->arch.pending_exceptions);\r\n#ifdef EXIT_DEBUG\r\nprintk(KERN_INFO "Queueing interrupt %x\n", vec);\r\n#endif\r\n}\r\nvoid kvmppc_core_queue_program(struct kvm_vcpu *vcpu, ulong flags)\r\n{\r\nkvmppc_inject_interrupt(vcpu, BOOK3S_INTERRUPT_PROGRAM, flags);\r\n}\r\nvoid kvmppc_core_queue_dec(struct kvm_vcpu *vcpu)\r\n{\r\nkvmppc_book3s_queue_irqprio(vcpu, BOOK3S_INTERRUPT_DECREMENTER);\r\n}\r\nint kvmppc_core_pending_dec(struct kvm_vcpu *vcpu)\r\n{\r\nreturn test_bit(BOOK3S_IRQPRIO_DECREMENTER, &vcpu->arch.pending_exceptions);\r\n}\r\nvoid kvmppc_core_dequeue_dec(struct kvm_vcpu *vcpu)\r\n{\r\nkvmppc_book3s_dequeue_irqprio(vcpu, BOOK3S_INTERRUPT_DECREMENTER);\r\n}\r\nvoid kvmppc_core_queue_external(struct kvm_vcpu *vcpu,\r\nstruct kvm_interrupt *irq)\r\n{\r\nunsigned int vec = BOOK3S_INTERRUPT_EXTERNAL;\r\nif (irq->irq == KVM_INTERRUPT_SET_LEVEL)\r\nvec = BOOK3S_INTERRUPT_EXTERNAL_LEVEL;\r\nkvmppc_book3s_queue_irqprio(vcpu, vec);\r\n}\r\nvoid kvmppc_core_dequeue_external(struct kvm_vcpu *vcpu)\r\n{\r\nkvmppc_book3s_dequeue_irqprio(vcpu, BOOK3S_INTERRUPT_EXTERNAL);\r\nkvmppc_book3s_dequeue_irqprio(vcpu, BOOK3S_INTERRUPT_EXTERNAL_LEVEL);\r\n}\r\nint kvmppc_book3s_irqprio_deliver(struct kvm_vcpu *vcpu, unsigned int priority)\r\n{\r\nint deliver = 1;\r\nint vec = 0;\r\nbool crit = kvmppc_critical_section(vcpu);\r\nswitch (priority) {\r\ncase BOOK3S_IRQPRIO_DECREMENTER:\r\ndeliver = (vcpu->arch.shared->msr & MSR_EE) && !crit;\r\nvec = BOOK3S_INTERRUPT_DECREMENTER;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_EXTERNAL:\r\ncase BOOK3S_IRQPRIO_EXTERNAL_LEVEL:\r\ndeliver = (vcpu->arch.shared->msr & MSR_EE) && !crit;\r\nvec = BOOK3S_INTERRUPT_EXTERNAL;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_SYSTEM_RESET:\r\nvec = BOOK3S_INTERRUPT_SYSTEM_RESET;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_MACHINE_CHECK:\r\nvec = BOOK3S_INTERRUPT_MACHINE_CHECK;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_DATA_STORAGE:\r\nvec = BOOK3S_INTERRUPT_DATA_STORAGE;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_INST_STORAGE:\r\nvec = BOOK3S_INTERRUPT_INST_STORAGE;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_DATA_SEGMENT:\r\nvec = BOOK3S_INTERRUPT_DATA_SEGMENT;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_INST_SEGMENT:\r\nvec = BOOK3S_INTERRUPT_INST_SEGMENT;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_ALIGNMENT:\r\nvec = BOOK3S_INTERRUPT_ALIGNMENT;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_PROGRAM:\r\nvec = BOOK3S_INTERRUPT_PROGRAM;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_VSX:\r\nvec = BOOK3S_INTERRUPT_VSX;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_ALTIVEC:\r\nvec = BOOK3S_INTERRUPT_ALTIVEC;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_FP_UNAVAIL:\r\nvec = BOOK3S_INTERRUPT_FP_UNAVAIL;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_SYSCALL:\r\nvec = BOOK3S_INTERRUPT_SYSCALL;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_DEBUG:\r\nvec = BOOK3S_INTERRUPT_TRACE;\r\nbreak;\r\ncase BOOK3S_IRQPRIO_PERFORMANCE_MONITOR:\r\nvec = BOOK3S_INTERRUPT_PERFMON;\r\nbreak;\r\ndefault:\r\ndeliver = 0;\r\nprintk(KERN_ERR "KVM: Unknown interrupt: 0x%x\n", priority);\r\nbreak;\r\n}\r\n#if 0\r\nprintk(KERN_INFO "Deliver interrupt 0x%x? %x\n", vec, deliver);\r\n#endif\r\nif (deliver)\r\nkvmppc_inject_interrupt(vcpu, vec, 0);\r\nreturn deliver;\r\n}\r\nstatic bool clear_irqprio(struct kvm_vcpu *vcpu, unsigned int priority)\r\n{\r\nswitch (priority) {\r\ncase BOOK3S_IRQPRIO_DECREMENTER:\r\nreturn false;\r\ncase BOOK3S_IRQPRIO_EXTERNAL_LEVEL:\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nint kvmppc_core_prepare_to_enter(struct kvm_vcpu *vcpu)\r\n{\r\nunsigned long *pending = &vcpu->arch.pending_exceptions;\r\nunsigned long old_pending = vcpu->arch.pending_exceptions;\r\nunsigned int priority;\r\n#ifdef EXIT_DEBUG\r\nif (vcpu->arch.pending_exceptions)\r\nprintk(KERN_EMERG "KVM: Check pending: %lx\n", vcpu->arch.pending_exceptions);\r\n#endif\r\npriority = __ffs(*pending);\r\nwhile (priority < BOOK3S_IRQPRIO_MAX) {\r\nif (kvmppc_book3s_irqprio_deliver(vcpu, priority) &&\r\nclear_irqprio(vcpu, priority)) {\r\nclear_bit(priority, &vcpu->arch.pending_exceptions);\r\nbreak;\r\n}\r\npriority = find_next_bit(pending,\r\nBITS_PER_BYTE * sizeof(*pending),\r\npriority + 1);\r\n}\r\nkvmppc_update_int_pending(vcpu, *pending, old_pending);\r\nreturn 0;\r\n}\r\npfn_t kvmppc_gfn_to_pfn(struct kvm_vcpu *vcpu, gfn_t gfn)\r\n{\r\nulong mp_pa = vcpu->arch.magic_page_pa;\r\nif (!(vcpu->arch.shared->msr & MSR_SF))\r\nmp_pa = (uint32_t)mp_pa;\r\nif (unlikely(mp_pa) &&\r\nunlikely(((gfn << PAGE_SHIFT) & KVM_PAM) ==\r\n((mp_pa & PAGE_MASK) & KVM_PAM))) {\r\nulong shared_page = ((ulong)vcpu->arch.shared) & PAGE_MASK;\r\npfn_t pfn;\r\npfn = (pfn_t)virt_to_phys((void*)shared_page) >> PAGE_SHIFT;\r\nget_page(pfn_to_page(pfn));\r\nreturn pfn;\r\n}\r\nreturn gfn_to_pfn(vcpu->kvm, gfn);\r\n}\r\nstatic int kvmppc_xlate(struct kvm_vcpu *vcpu, ulong eaddr, bool data,\r\nstruct kvmppc_pte *pte)\r\n{\r\nint relocated = (vcpu->arch.shared->msr & (data ? MSR_DR : MSR_IR));\r\nint r;\r\nif (relocated) {\r\nr = vcpu->arch.mmu.xlate(vcpu, eaddr, pte, data);\r\n} else {\r\npte->eaddr = eaddr;\r\npte->raddr = eaddr & KVM_PAM;\r\npte->vpage = VSID_REAL | eaddr >> 12;\r\npte->may_read = true;\r\npte->may_write = true;\r\npte->may_execute = true;\r\nr = 0;\r\n}\r\nreturn r;\r\n}\r\nstatic hva_t kvmppc_bad_hva(void)\r\n{\r\nreturn PAGE_OFFSET;\r\n}\r\nstatic hva_t kvmppc_pte_to_hva(struct kvm_vcpu *vcpu, struct kvmppc_pte *pte,\r\nbool read)\r\n{\r\nhva_t hpage;\r\nif (read && !pte->may_read)\r\ngoto err;\r\nif (!read && !pte->may_write)\r\ngoto err;\r\nhpage = gfn_to_hva(vcpu->kvm, pte->raddr >> PAGE_SHIFT);\r\nif (kvm_is_error_hva(hpage))\r\ngoto err;\r\nreturn hpage | (pte->raddr & ~PAGE_MASK);\r\nerr:\r\nreturn kvmppc_bad_hva();\r\n}\r\nint kvmppc_st(struct kvm_vcpu *vcpu, ulong *eaddr, int size, void *ptr,\r\nbool data)\r\n{\r\nstruct kvmppc_pte pte;\r\nvcpu->stat.st++;\r\nif (kvmppc_xlate(vcpu, *eaddr, data, &pte))\r\nreturn -ENOENT;\r\n*eaddr = pte.raddr;\r\nif (!pte.may_write)\r\nreturn -EPERM;\r\nif (kvm_write_guest(vcpu->kvm, pte.raddr, ptr, size))\r\nreturn EMULATE_DO_MMIO;\r\nreturn EMULATE_DONE;\r\n}\r\nint kvmppc_ld(struct kvm_vcpu *vcpu, ulong *eaddr, int size, void *ptr,\r\nbool data)\r\n{\r\nstruct kvmppc_pte pte;\r\nhva_t hva = *eaddr;\r\nvcpu->stat.ld++;\r\nif (kvmppc_xlate(vcpu, *eaddr, data, &pte))\r\ngoto nopte;\r\n*eaddr = pte.raddr;\r\nhva = kvmppc_pte_to_hva(vcpu, &pte, true);\r\nif (kvm_is_error_hva(hva))\r\ngoto mmio;\r\nif (copy_from_user(ptr, (void __user *)hva, size)) {\r\nprintk(KERN_INFO "kvmppc_ld at 0x%lx failed\n", hva);\r\ngoto mmio;\r\n}\r\nreturn EMULATE_DONE;\r\nnopte:\r\nreturn -ENOENT;\r\nmmio:\r\nreturn EMULATE_DO_MMIO;\r\n}\r\nint kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)\r\n{\r\nreturn 0;\r\n}\r\nint kvmppc_subarch_vcpu_init(struct kvm_vcpu *vcpu)\r\n{\r\nreturn 0;\r\n}\r\nvoid kvmppc_subarch_vcpu_uninit(struct kvm_vcpu *vcpu)\r\n{\r\n}\r\nint kvm_arch_vcpu_ioctl_get_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)\r\n{\r\nint i;\r\nregs->pc = kvmppc_get_pc(vcpu);\r\nregs->cr = kvmppc_get_cr(vcpu);\r\nregs->ctr = kvmppc_get_ctr(vcpu);\r\nregs->lr = kvmppc_get_lr(vcpu);\r\nregs->xer = kvmppc_get_xer(vcpu);\r\nregs->msr = vcpu->arch.shared->msr;\r\nregs->srr0 = vcpu->arch.shared->srr0;\r\nregs->srr1 = vcpu->arch.shared->srr1;\r\nregs->pid = vcpu->arch.pid;\r\nregs->sprg0 = vcpu->arch.shared->sprg0;\r\nregs->sprg1 = vcpu->arch.shared->sprg1;\r\nregs->sprg2 = vcpu->arch.shared->sprg2;\r\nregs->sprg3 = vcpu->arch.shared->sprg3;\r\nregs->sprg4 = vcpu->arch.shared->sprg4;\r\nregs->sprg5 = vcpu->arch.shared->sprg5;\r\nregs->sprg6 = vcpu->arch.shared->sprg6;\r\nregs->sprg7 = vcpu->arch.shared->sprg7;\r\nfor (i = 0; i < ARRAY_SIZE(regs->gpr); i++)\r\nregs->gpr[i] = kvmppc_get_gpr(vcpu, i);\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)\r\n{\r\nint i;\r\nkvmppc_set_pc(vcpu, regs->pc);\r\nkvmppc_set_cr(vcpu, regs->cr);\r\nkvmppc_set_ctr(vcpu, regs->ctr);\r\nkvmppc_set_lr(vcpu, regs->lr);\r\nkvmppc_set_xer(vcpu, regs->xer);\r\nkvmppc_set_msr(vcpu, regs->msr);\r\nvcpu->arch.shared->srr0 = regs->srr0;\r\nvcpu->arch.shared->srr1 = regs->srr1;\r\nvcpu->arch.shared->sprg0 = regs->sprg0;\r\nvcpu->arch.shared->sprg1 = regs->sprg1;\r\nvcpu->arch.shared->sprg2 = regs->sprg2;\r\nvcpu->arch.shared->sprg3 = regs->sprg3;\r\nvcpu->arch.shared->sprg4 = regs->sprg4;\r\nvcpu->arch.shared->sprg5 = regs->sprg5;\r\nvcpu->arch.shared->sprg6 = regs->sprg6;\r\nvcpu->arch.shared->sprg7 = regs->sprg7;\r\nfor (i = 0; i < ARRAY_SIZE(regs->gpr); i++)\r\nkvmppc_set_gpr(vcpu, i, regs->gpr[i]);\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_get_fpu(struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)\r\n{\r\nreturn -ENOTSUPP;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_fpu(struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)\r\n{\r\nreturn -ENOTSUPP;\r\n}\r\nint kvm_vcpu_ioctl_get_one_reg(struct kvm_vcpu *vcpu, struct kvm_one_reg *reg)\r\n{\r\nint r;\r\nunion kvmppc_one_reg val;\r\nint size;\r\nlong int i;\r\nsize = one_reg_size(reg->id);\r\nif (size > sizeof(val))\r\nreturn -EINVAL;\r\nr = kvmppc_get_one_reg(vcpu, reg->id, &val);\r\nif (r == -EINVAL) {\r\nr = 0;\r\nswitch (reg->id) {\r\ncase KVM_REG_PPC_DAR:\r\nval = get_reg_val(reg->id, vcpu->arch.shared->dar);\r\nbreak;\r\ncase KVM_REG_PPC_DSISR:\r\nval = get_reg_val(reg->id, vcpu->arch.shared->dsisr);\r\nbreak;\r\ncase KVM_REG_PPC_FPR0 ... KVM_REG_PPC_FPR31:\r\ni = reg->id - KVM_REG_PPC_FPR0;\r\nval = get_reg_val(reg->id, vcpu->arch.fpr[i]);\r\nbreak;\r\ncase KVM_REG_PPC_FPSCR:\r\nval = get_reg_val(reg->id, vcpu->arch.fpscr);\r\nbreak;\r\n#ifdef CONFIG_ALTIVEC\r\ncase KVM_REG_PPC_VR0 ... KVM_REG_PPC_VR31:\r\nif (!cpu_has_feature(CPU_FTR_ALTIVEC)) {\r\nr = -ENXIO;\r\nbreak;\r\n}\r\nval.vval = vcpu->arch.vr[reg->id - KVM_REG_PPC_VR0];\r\nbreak;\r\ncase KVM_REG_PPC_VSCR:\r\nif (!cpu_has_feature(CPU_FTR_ALTIVEC)) {\r\nr = -ENXIO;\r\nbreak;\r\n}\r\nval = get_reg_val(reg->id, vcpu->arch.vscr.u[3]);\r\nbreak;\r\n#endif\r\ncase KVM_REG_PPC_DEBUG_INST: {\r\nu32 opcode = INS_TW;\r\nr = copy_to_user((u32 __user *)(long)reg->addr,\r\n&opcode, sizeof(u32));\r\nbreak;\r\n}\r\n#ifdef CONFIG_KVM_XICS\r\ncase KVM_REG_PPC_ICP_STATE:\r\nif (!vcpu->arch.icp) {\r\nr = -ENXIO;\r\nbreak;\r\n}\r\nval = get_reg_val(reg->id, kvmppc_xics_get_icp(vcpu));\r\nbreak;\r\n#endif\r\ndefault:\r\nr = -EINVAL;\r\nbreak;\r\n}\r\n}\r\nif (r)\r\nreturn r;\r\nif (copy_to_user((char __user *)(unsigned long)reg->addr, &val, size))\r\nr = -EFAULT;\r\nreturn r;\r\n}\r\nint kvm_vcpu_ioctl_set_one_reg(struct kvm_vcpu *vcpu, struct kvm_one_reg *reg)\r\n{\r\nint r;\r\nunion kvmppc_one_reg val;\r\nint size;\r\nlong int i;\r\nsize = one_reg_size(reg->id);\r\nif (size > sizeof(val))\r\nreturn -EINVAL;\r\nif (copy_from_user(&val, (char __user *)(unsigned long)reg->addr, size))\r\nreturn -EFAULT;\r\nr = kvmppc_set_one_reg(vcpu, reg->id, &val);\r\nif (r == -EINVAL) {\r\nr = 0;\r\nswitch (reg->id) {\r\ncase KVM_REG_PPC_DAR:\r\nvcpu->arch.shared->dar = set_reg_val(reg->id, val);\r\nbreak;\r\ncase KVM_REG_PPC_DSISR:\r\nvcpu->arch.shared->dsisr = set_reg_val(reg->id, val);\r\nbreak;\r\ncase KVM_REG_PPC_FPR0 ... KVM_REG_PPC_FPR31:\r\ni = reg->id - KVM_REG_PPC_FPR0;\r\nvcpu->arch.fpr[i] = set_reg_val(reg->id, val);\r\nbreak;\r\ncase KVM_REG_PPC_FPSCR:\r\nvcpu->arch.fpscr = set_reg_val(reg->id, val);\r\nbreak;\r\n#ifdef CONFIG_ALTIVEC\r\ncase KVM_REG_PPC_VR0 ... KVM_REG_PPC_VR31:\r\nif (!cpu_has_feature(CPU_FTR_ALTIVEC)) {\r\nr = -ENXIO;\r\nbreak;\r\n}\r\nvcpu->arch.vr[reg->id - KVM_REG_PPC_VR0] = val.vval;\r\nbreak;\r\ncase KVM_REG_PPC_VSCR:\r\nif (!cpu_has_feature(CPU_FTR_ALTIVEC)) {\r\nr = -ENXIO;\r\nbreak;\r\n}\r\nvcpu->arch.vscr.u[3] = set_reg_val(reg->id, val);\r\nbreak;\r\n#endif\r\n#ifdef CONFIG_KVM_XICS\r\ncase KVM_REG_PPC_ICP_STATE:\r\nif (!vcpu->arch.icp) {\r\nr = -ENXIO;\r\nbreak;\r\n}\r\nr = kvmppc_xics_set_icp(vcpu,\r\nset_reg_val(reg->id, val));\r\nbreak;\r\n#endif\r\ndefault:\r\nr = -EINVAL;\r\nbreak;\r\n}\r\n}\r\nreturn r;\r\n}\r\nint kvm_arch_vcpu_ioctl_translate(struct kvm_vcpu *vcpu,\r\nstruct kvm_translation *tr)\r\n{\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_guest_debug(struct kvm_vcpu *vcpu,\r\nstruct kvm_guest_debug *dbg)\r\n{\r\nreturn -EINVAL;\r\n}\r\nvoid kvmppc_decrementer_func(unsigned long data)\r\n{\r\nstruct kvm_vcpu *vcpu = (struct kvm_vcpu *)data;\r\nkvmppc_core_queue_dec(vcpu);\r\nkvm_vcpu_kick(vcpu);\r\n}
