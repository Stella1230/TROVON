static inline int mmu_get_tsize(int psize)\r\n{\r\nreturn mmu_psize_defs[psize].enc;\r\n}\r\nstatic inline int mmu_get_tsize(int psize)\r\n{\r\nreturn 0;\r\n}\r\nvoid local_flush_tlb_mm(struct mm_struct *mm)\r\n{\r\nunsigned int pid;\r\npreempt_disable();\r\npid = mm->context.id;\r\nif (pid != MMU_NO_CONTEXT)\r\n_tlbil_pid(pid);\r\npreempt_enable();\r\n}\r\nvoid __local_flush_tlb_page(struct mm_struct *mm, unsigned long vmaddr,\r\nint tsize, int ind)\r\n{\r\nunsigned int pid;\r\npreempt_disable();\r\npid = mm ? mm->context.id : 0;\r\nif (pid != MMU_NO_CONTEXT)\r\n_tlbil_va(vmaddr, pid, tsize, ind);\r\npreempt_enable();\r\n}\r\nvoid local_flush_tlb_page(struct vm_area_struct *vma, unsigned long vmaddr)\r\n{\r\n__local_flush_tlb_page(vma ? vma->vm_mm : NULL, vmaddr,\r\nmmu_get_tsize(mmu_virtual_psize), 0);\r\n}\r\nstatic int mm_is_core_local(struct mm_struct *mm)\r\n{\r\nreturn cpumask_subset(mm_cpumask(mm),\r\ntopology_thread_cpumask(smp_processor_id()));\r\n}\r\nstatic void do_flush_tlb_mm_ipi(void *param)\r\n{\r\nstruct tlb_flush_param *p = param;\r\n_tlbil_pid(p ? p->pid : 0);\r\n}\r\nstatic void do_flush_tlb_page_ipi(void *param)\r\n{\r\nstruct tlb_flush_param *p = param;\r\n_tlbil_va(p->addr, p->pid, p->tsize, p->ind);\r\n}\r\nvoid flush_tlb_mm(struct mm_struct *mm)\r\n{\r\nunsigned int pid;\r\npreempt_disable();\r\npid = mm->context.id;\r\nif (unlikely(pid == MMU_NO_CONTEXT))\r\ngoto no_context;\r\nif (!mm_is_core_local(mm)) {\r\nstruct tlb_flush_param p = { .pid = pid };\r\nsmp_call_function_many(mm_cpumask(mm),\r\ndo_flush_tlb_mm_ipi, &p, 1);\r\n}\r\n_tlbil_pid(pid);\r\nno_context:\r\npreempt_enable();\r\n}\r\nvoid __flush_tlb_page(struct mm_struct *mm, unsigned long vmaddr,\r\nint tsize, int ind)\r\n{\r\nstruct cpumask *cpu_mask;\r\nunsigned int pid;\r\npreempt_disable();\r\npid = mm ? mm->context.id : 0;\r\nif (unlikely(pid == MMU_NO_CONTEXT))\r\ngoto bail;\r\ncpu_mask = mm_cpumask(mm);\r\nif (!mm_is_core_local(mm)) {\r\nif (mmu_has_feature(MMU_FTR_USE_TLBIVAX_BCAST)) {\r\nint lock = mmu_has_feature(MMU_FTR_LOCK_BCAST_INVAL);\r\nif (lock)\r\nraw_spin_lock(&tlbivax_lock);\r\n_tlbivax_bcast(vmaddr, pid, tsize, ind);\r\nif (lock)\r\nraw_spin_unlock(&tlbivax_lock);\r\ngoto bail;\r\n} else {\r\nstruct tlb_flush_param p = {\r\n.pid = pid,\r\n.addr = vmaddr,\r\n.tsize = tsize,\r\n.ind = ind,\r\n};\r\nsmp_call_function_many(cpu_mask,\r\ndo_flush_tlb_page_ipi, &p, 1);\r\n}\r\n}\r\n_tlbil_va(vmaddr, pid, tsize, ind);\r\nbail:\r\npreempt_enable();\r\n}\r\nvoid flush_tlb_page(struct vm_area_struct *vma, unsigned long vmaddr)\r\n{\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nif (is_vm_hugetlb_page(vma))\r\nflush_hugetlb_page(vma, vmaddr);\r\n#endif\r\n__flush_tlb_page(vma ? vma->vm_mm : NULL, vmaddr,\r\nmmu_get_tsize(mmu_virtual_psize), 0);\r\n}\r\nvoid __init early_init_mmu_47x(void)\r\n{\r\n#ifdef CONFIG_SMP\r\nunsigned long root = of_get_flat_dt_root();\r\nif (of_get_flat_dt_prop(root, "cooperative-partition", NULL))\r\nmmu_clear_feature(MMU_FTR_USE_TLBIVAX_BCAST);\r\n#endif\r\n}\r\nvoid flush_tlb_kernel_range(unsigned long start, unsigned long end)\r\n{\r\n#ifdef CONFIG_SMP\r\npreempt_disable();\r\nsmp_call_function(do_flush_tlb_mm_ipi, NULL, 1);\r\n_tlbil_pid(0);\r\npreempt_enable();\r\n#else\r\n_tlbil_pid(0);\r\n#endif\r\n}\r\nvoid flush_tlb_range(struct vm_area_struct *vma, unsigned long start,\r\nunsigned long end)\r\n{\r\nflush_tlb_mm(vma->vm_mm);\r\n}\r\nvoid tlb_flush(struct mmu_gather *tlb)\r\n{\r\nflush_tlb_mm(tlb->mm);\r\n}\r\nvoid tlb_flush_pgtable(struct mmu_gather *tlb, unsigned long address)\r\n{\r\nint tsize = mmu_psize_defs[mmu_pte_psize].enc;\r\nif (book3e_htw_enabled) {\r\nunsigned long start = address & PMD_MASK;\r\nunsigned long end = address + PMD_SIZE;\r\nunsigned long size = 1UL << mmu_psize_defs[mmu_pte_psize].shift;\r\nwhile (start < end) {\r\n__flush_tlb_page(tlb->mm, start, tsize, 1);\r\nstart += size;\r\n}\r\n} else {\r\nunsigned long rmask = 0xf000000000000000ul;\r\nunsigned long rid = (address & rmask) | 0x1000000000000000ul;\r\nunsigned long vpte = address & ~rmask;\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nvpte = (vpte >> (PAGE_SHIFT - 4)) & ~0xfffful;\r\n#else\r\nvpte = (vpte >> (PAGE_SHIFT - 3)) & ~0xffful;\r\n#endif\r\nvpte |= rid;\r\n__flush_tlb_page(tlb->mm, vpte, tsize, 0);\r\n}\r\n}\r\nstatic void setup_page_sizes(void)\r\n{\r\nunsigned int tlb0cfg;\r\nunsigned int tlb0ps;\r\nunsigned int eptcfg;\r\nint i, psize;\r\n#ifdef CONFIG_PPC_FSL_BOOK3E\r\nunsigned int mmucfg = mfspr(SPRN_MMUCFG);\r\nint fsl_mmu = mmu_has_feature(MMU_FTR_TYPE_FSL_E);\r\nif (fsl_mmu && (mmucfg & MMUCFG_MAVN) == MMUCFG_MAVN_V1) {\r\nunsigned int tlb1cfg = mfspr(SPRN_TLB1CFG);\r\nunsigned int min_pg, max_pg;\r\nmin_pg = (tlb1cfg & TLBnCFG_MINSIZE) >> TLBnCFG_MINSIZE_SHIFT;\r\nmax_pg = (tlb1cfg & TLBnCFG_MAXSIZE) >> TLBnCFG_MAXSIZE_SHIFT;\r\nfor (psize = 0; psize < MMU_PAGE_COUNT; ++psize) {\r\nstruct mmu_psize_def *def;\r\nunsigned int shift;\r\ndef = &mmu_psize_defs[psize];\r\nshift = def->shift;\r\nif (shift == 0)\r\ncontinue;\r\nshift = (shift - 10) >> 1;\r\nif ((shift >= min_pg) && (shift <= max_pg))\r\ndef->flags |= MMU_PAGE_SIZE_DIRECT;\r\n}\r\ngoto no_indirect;\r\n}\r\nif (fsl_mmu && (mmucfg & MMUCFG_MAVN) == MMUCFG_MAVN_V2) {\r\nu32 tlb1ps = mfspr(SPRN_TLB1PS);\r\nfor (psize = 0; psize < MMU_PAGE_COUNT; ++psize) {\r\nstruct mmu_psize_def *def = &mmu_psize_defs[psize];\r\nif (tlb1ps & (1U << (def->shift - 10))) {\r\ndef->flags |= MMU_PAGE_SIZE_DIRECT;\r\n}\r\n}\r\ngoto no_indirect;\r\n}\r\n#endif\r\ntlb0cfg = mfspr(SPRN_TLB0CFG);\r\ntlb0ps = mfspr(SPRN_TLB0PS);\r\neptcfg = mfspr(SPRN_EPTCFG);\r\nfor (psize = 0; psize < MMU_PAGE_COUNT; ++psize) {\r\nstruct mmu_psize_def *def = &mmu_psize_defs[psize];\r\nif (tlb0ps & (1U << (def->shift - 10)))\r\ndef->flags |= MMU_PAGE_SIZE_DIRECT;\r\n}\r\nif ((tlb0cfg & TLBnCFG_IND) == 0)\r\ngoto no_indirect;\r\nfor (i = 0; i < 3; i++) {\r\nunsigned int ps, sps;\r\nsps = eptcfg & 0x1f;\r\neptcfg >>= 5;\r\nps = eptcfg & 0x1f;\r\neptcfg >>= 5;\r\nif (!ps || !sps)\r\ncontinue;\r\nfor (psize = 0; psize < MMU_PAGE_COUNT; psize++) {\r\nstruct mmu_psize_def *def = &mmu_psize_defs[psize];\r\nif (ps == (def->shift - 10))\r\ndef->flags |= MMU_PAGE_SIZE_INDIRECT;\r\nif (sps == (def->shift - 10))\r\ndef->ind = ps + 10;\r\n}\r\n}\r\nno_indirect:\r\npr_info("MMU: Supported page sizes\n");\r\nfor (psize = 0; psize < MMU_PAGE_COUNT; ++psize) {\r\nstruct mmu_psize_def *def = &mmu_psize_defs[psize];\r\nconst char *__page_type_names[] = {\r\n"unsupported",\r\n"direct",\r\n"indirect",\r\n"direct & indirect"\r\n};\r\nif (def->flags == 0) {\r\ndef->shift = 0;\r\ncontinue;\r\n}\r\npr_info(" %8ld KB as %s\n", 1ul << (def->shift - 10),\r\n__page_type_names[def->flags & 0x3]);\r\n}\r\n}\r\nstatic void __patch_exception(int exc, unsigned long addr)\r\n{\r\nextern unsigned int interrupt_base_book3e;\r\nunsigned int *ibase = &interrupt_base_book3e;\r\npatch_branch(ibase + (exc / 4) + 1, addr, 0);\r\n}\r\nstatic void setup_mmu_htw(void)\r\n{\r\nunsigned int tlb0cfg = mfspr(SPRN_TLB0CFG);\r\nif ((tlb0cfg & TLBnCFG_IND) &&\r\n(tlb0cfg & TLBnCFG_PT)) {\r\npatch_exception(0x1c0, exc_data_tlb_miss_htw_book3e);\r\npatch_exception(0x1e0, exc_instruction_tlb_miss_htw_book3e);\r\nbook3e_htw_enabled = 1;\r\n}\r\npr_info("MMU: Book3E HW tablewalk %s\n",\r\nbook3e_htw_enabled ? "enabled" : "not supported");\r\n}\r\nstatic void __early_init_mmu(int boot_cpu)\r\n{\r\nunsigned int mas4;\r\nmmu_linear_psize = MMU_PAGE_1G;\r\nmmu_vmemmap_psize = MMU_PAGE_16M;\r\nif (boot_cpu) {\r\nsetup_page_sizes();\r\nsetup_mmu_htw();\r\n}\r\nmas4 = 0x4 << MAS4_WIMGED_SHIFT;\r\nif (book3e_htw_enabled) {\r\nmas4 |= mas4 | MAS4_INDD;\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nmas4 |= BOOK3E_PAGESZ_256M << MAS4_TSIZED_SHIFT;\r\nmmu_pte_psize = MMU_PAGE_256M;\r\n#else\r\nmas4 |= BOOK3E_PAGESZ_1M << MAS4_TSIZED_SHIFT;\r\nmmu_pte_psize = MMU_PAGE_1M;\r\n#endif\r\n} else {\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nmas4 |= BOOK3E_PAGESZ_64K << MAS4_TSIZED_SHIFT;\r\n#else\r\nmas4 |= BOOK3E_PAGESZ_4K << MAS4_TSIZED_SHIFT;\r\n#endif\r\nmmu_pte_psize = mmu_virtual_psize;\r\n}\r\nmtspr(SPRN_MAS4, mas4);\r\nlinear_map_top = memblock_end_of_DRAM();\r\n#ifdef CONFIG_PPC_FSL_BOOK3E\r\nif (mmu_has_feature(MMU_FTR_TYPE_FSL_E)) {\r\nunsigned int num_cams;\r\nnum_cams = (mfspr(SPRN_TLB1CFG) & TLBnCFG_N_ENTRY) / 4;\r\nlinear_map_top = map_mem_in_cams(linear_map_top, num_cams);\r\nmemblock_enforce_memory_limit(linear_map_top);\r\npatch_exception(0x1c0, exc_data_tlb_miss_bolted_book3e);\r\npatch_exception(0x1e0, exc_instruction_tlb_miss_bolted_book3e);\r\n}\r\n#endif\r\nmb();\r\nmemblock_set_current_limit(linear_map_top);\r\n}\r\nvoid __init early_init_mmu(void)\r\n{\r\n__early_init_mmu(1);\r\n}\r\nvoid early_init_mmu_secondary(void)\r\n{\r\n__early_init_mmu(0);\r\n}\r\nvoid setup_initial_memory_limit(phys_addr_t first_memblock_base,\r\nphys_addr_t first_memblock_size)\r\n{\r\n#ifdef CONFIG_PPC_FSL_BOOK3E\r\nif (mmu_has_feature(MMU_FTR_TYPE_FSL_E)) {\r\nunsigned long linear_sz;\r\nlinear_sz = calc_cam_sz(first_memblock_size, PAGE_OFFSET,\r\nfirst_memblock_base);\r\nppc64_rma_size = min_t(u64, linear_sz, 0x40000000);\r\n} else\r\n#endif\r\nppc64_rma_size = min_t(u64, first_memblock_size, 0x40000000);\r\nmemblock_set_current_limit(first_memblock_base + ppc64_rma_size);\r\n}\r\nvoid __init early_init_mmu(void)\r\n{\r\n#ifdef CONFIG_PPC_47x\r\nearly_init_mmu_47x();\r\n#endif\r\n}
