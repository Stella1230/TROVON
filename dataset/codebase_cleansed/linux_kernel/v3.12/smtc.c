static int __init vpe0tcs(char *str)\r\n{\r\nget_option(&str, &vpe0limit);\r\nreturn 1;\r\n}\r\nstatic int __init ipibufs(char *str)\r\n{\r\nget_option(&str, &ipibuffers);\r\nreturn 1;\r\n}\r\nstatic int __init stlb_disable(char *s)\r\n{\r\nnostlb = 1;\r\nreturn 1;\r\n}\r\nstatic int __init asidmask_set(char *str)\r\n{\r\nget_option(&str, &asidmask);\r\nswitch (asidmask) {\r\ncase 0x1:\r\ncase 0x3:\r\ncase 0x7:\r\ncase 0xf:\r\ncase 0x1f:\r\ncase 0x3f:\r\ncase 0x7f:\r\ncase 0xff:\r\nsmtc_asid_mask = (unsigned long)asidmask;\r\nbreak;\r\ndefault:\r\nprintk("ILLEGAL ASID mask 0x%x from command line\n", asidmask);\r\n}\r\nreturn 1;\r\n}\r\nstatic int __init hangtrig_enable(char *s)\r\n{\r\nhang_trig = 1;\r\nreturn 1;\r\n}\r\nstatic int __init tintq(char *str)\r\n{\r\nget_option(&str, &timerq_limit);\r\nreturn 1;\r\n}\r\nstatic void smtc_configure_tlb(void)\r\n{\r\nint i, tlbsiz, vpes;\r\nunsigned long mvpconf0;\r\nunsigned long config1val;\r\nfor (vpes=0; vpes<MAX_SMTC_TLBS; vpes++) {\r\nfor(i = 0; i < MAX_SMTC_ASIDS; i++) {\r\nsmtc_live_asid[vpes][i] = 0;\r\n}\r\n}\r\nmvpconf0 = read_c0_mvpconf0();\r\nif ((vpes = ((mvpconf0 & MVPCONF0_PVPE)\r\n>> MVPCONF0_PVPE_SHIFT) + 1) > 1) {\r\nif ((mvpconf0 & MVPCONF0_TLBS) && !nostlb) {\r\nif ((tlbsiz = ((mvpconf0 & MVPCONF0_PTLBE)\r\n>> MVPCONF0_PTLBE_SHIFT)) == 0) {\r\nsettc(1);\r\nwrite_tc_c0_tchalt(TCHALT_H);\r\nmips_ihb();\r\nfor (i=0; i < vpes; i++) {\r\nwrite_tc_c0_tcbind(i);\r\nwrite_c0_mvpcontrol(\r\nread_c0_mvpcontrol() & ~ MVPCONTROL_VPC );\r\nmips_ihb();\r\nif (((read_vpe_c0_config() & MIPS_CONF_MT) >> 7) == 1) {\r\nconfig1val = read_vpe_c0_config1();\r\ntlbsiz += ((config1val >> 25) & 0x3f) + 1;\r\n}\r\nwrite_c0_mvpcontrol(\r\nread_c0_mvpcontrol() | MVPCONTROL_VPC );\r\nmips_ihb();\r\n}\r\n}\r\nwrite_c0_mvpcontrol(read_c0_mvpcontrol() | MVPCONTROL_STLB);\r\nehb();\r\nif (tlbsiz > 64)\r\ntlbsiz = 64;\r\ncpu_data[0].tlbsize = current_cpu_data.tlbsize = tlbsiz;\r\nsmtc_status |= SMTC_TLB_SHARED;\r\nlocal_flush_tlb_all();\r\nprintk("TLB of %d entry pairs shared by %d VPEs\n",\r\ntlbsiz, vpes);\r\n} else {\r\nprintk("WARNING: TLB Not Sharable on SMTC Boot!\n");\r\n}\r\n}\r\n}\r\nint __init smtc_build_cpu_map(int start_cpu_slot)\r\n{\r\nint i, ntcs;\r\nntcs = ((read_c0_mvpconf0() & MVPCONF0_PTC) >> MVPCONF0_PTC_SHIFT) + 1;\r\nfor (i=start_cpu_slot; i<NR_CPUS && i<ntcs; i++) {\r\nset_cpu_possible(i, true);\r\n__cpu_number_map[i] = i;\r\n__cpu_logical_map[i] = i;\r\n}\r\n#ifdef CONFIG_MIPS_MT_FPAFF\r\ncpus_clear(mt_fpu_cpumask);\r\n#endif\r\nprintk("%i available secondary CPU TC(s)\n", i - 1);\r\nreturn i;\r\n}\r\nstatic void smtc_tc_setup(int vpe, int tc, int cpu)\r\n{\r\nstatic int cp1contexts[MAX_SMTC_VPES];\r\nif (tc == 1)\r\n{\r\ncp1contexts[0] = smtc_nconf1[0] - 1;\r\ncp1contexts[1] = smtc_nconf1[1];\r\n}\r\nsettc(tc);\r\nwrite_tc_c0_tchalt(TCHALT_H);\r\nmips_ihb();\r\nwrite_tc_c0_tcstatus((read_tc_c0_tcstatus()\r\n& ~(TCSTATUS_TKSU | TCSTATUS_DA | TCSTATUS_IXMT))\r\n| TCSTATUS_A);\r\nwrite_tc_c0_tccontext((sizeof(struct smtc_ipi_q) * cpu) << 16);\r\nwrite_tc_c0_tcbind(vpe);\r\nmemcpy(&cpu_data[cpu], &cpu_data[0], sizeof(struct cpuinfo_mips));\r\nif (!cp1contexts[vpe])\r\ncpu_data[cpu].options &= ~MIPS_CPU_FPU;\r\nelse\r\ncp1contexts[vpe]--;\r\ncpu_data[cpu].vpe_id = vpe;\r\ncpu_data[cpu].tc_id = tc;\r\ncpu_data[cpu].core = (read_vpe_c0_ebase() >> 1) & 0xff;\r\n}\r\nvoid smtc_prepare_cpus(int cpus)\r\n{\r\nint i, vpe, tc, ntc, nvpe, tcpervpe[NR_CPUS], slop, cpu;\r\nunsigned long flags;\r\nunsigned long val;\r\nint nipi;\r\nstruct smtc_ipi *pipi;\r\nlocal_irq_save(flags);\r\ndvpe();\r\ndmt();\r\nspin_lock_init(&freeIPIq.lock);\r\nfor (i=0; i<NR_CPUS; i++) {\r\nIPIQ[i].head = IPIQ[i].tail = NULL;\r\nspin_lock_init(&IPIQ[i].lock);\r\nIPIQ[i].depth = 0;\r\nIPIQ[i].resched_flag = 0;\r\n}\r\ncpu = 0;\r\ncpu_data[cpu].vpe_id = 0;\r\ncpu_data[cpu].tc_id = 0;\r\ncpu_data[cpu].core = (read_c0_ebase() >> 1) & 0xff;\r\ncpu++;\r\nmips_mt_set_cpuoptions();\r\nif (vpelimit > 0)\r\nprintk("Limit of %d VPEs set\n", vpelimit);\r\nif (tclimit > 0)\r\nprintk("Limit of %d TCs set\n", tclimit);\r\nif (nostlb) {\r\nprintk("Shared TLB Use Inhibited - UNSAFE for Multi-VPE Operation\n");\r\n}\r\nif (asidmask)\r\nprintk("ASID mask value override to 0x%x\n", asidmask);\r\n#ifdef CONFIG_SMTC_IDLE_HOOK_DEBUG\r\nif (hang_trig)\r\nprintk("Logic Analyser Trigger on suspected TC hang\n");\r\n#endif\r\nwrite_c0_mvpcontrol( read_c0_mvpcontrol() | MVPCONTROL_VPC );\r\nval = read_c0_mvpconf0();\r\nnvpe = ((val & MVPCONF0_PVPE) >> MVPCONF0_PVPE_SHIFT) + 1;\r\nif (vpelimit > 0 && nvpe > vpelimit)\r\nnvpe = vpelimit;\r\nntc = ((val & MVPCONF0_PTC) >> MVPCONF0_PTC_SHIFT) + 1;\r\nif (ntc > NR_CPUS)\r\nntc = NR_CPUS;\r\nif (tclimit > 0 && ntc > tclimit)\r\nntc = tclimit;\r\nslop = ntc % nvpe;\r\nfor (i = 0; i < nvpe; i++) {\r\ntcpervpe[i] = ntc / nvpe;\r\nif (slop) {\r\nif((slop - i) > 0) tcpervpe[i]++;\r\n}\r\n}\r\nif (vpe0limit > ntc) vpe0limit = ntc;\r\nif (vpe0limit > 0) {\r\nint slopslop;\r\nif (vpe0limit < tcpervpe[0]) {\r\nslop = tcpervpe[0] - vpe0limit;\r\nslopslop = slop % (nvpe - 1);\r\ntcpervpe[0] = vpe0limit;\r\nfor (i = 1; i < nvpe; i++) {\r\ntcpervpe[i] += slop / (nvpe - 1);\r\nif(slopslop && ((slopslop - (i - 1) > 0)))\r\ntcpervpe[i]++;\r\n}\r\n} else if (vpe0limit > tcpervpe[0]) {\r\nslop = vpe0limit - tcpervpe[0];\r\nslopslop = slop % (nvpe - 1);\r\ntcpervpe[0] = vpe0limit;\r\nfor (i = 1; i < nvpe; i++) {\r\ntcpervpe[i] -= slop / (nvpe - 1);\r\nif(slopslop && ((slopslop - (i - 1) > 0)))\r\ntcpervpe[i]--;\r\n}\r\n}\r\n}\r\nsmtc_configure_tlb();\r\nfor (tc = 0, vpe = 0 ; (vpe < nvpe) && (tc < ntc) ; vpe++) {\r\nif (tc == 0)\r\n{\r\nsmtc_nconf1[0] = ((read_vpe_c0_vpeconf1() &\r\nVPECONF1_NCP1) >> VPECONF1_NCP1_SHIFT);\r\nif (nvpe == 2)\r\n{\r\nsettc(1);\r\nsmtc_nconf1[1] = ((read_vpe_c0_vpeconf1() &\r\nVPECONF1_NCP1) >> VPECONF1_NCP1_SHIFT);\r\nsettc(0);\r\n}\r\n}\r\nif (tcpervpe[vpe] == 0)\r\ncontinue;\r\nif (vpe != 0)\r\nprintk(", ");\r\nprintk("VPE %d: TC", vpe);\r\nfor (i = 0; i < tcpervpe[vpe]; i++) {\r\nif (tc != 0) {\r\nsmtc_tc_setup(vpe, tc, cpu);\r\nif (vpe != 0) {\r\nwrite_vpe_c0_vpeconf0(\r\nread_vpe_c0_vpeconf0() |\r\nVPECONF0_MVP);\r\n}\r\ncpu++;\r\n}\r\nprintk(" %d", tc);\r\ntc++;\r\n}\r\nif (vpe != 0) {\r\nwrite_vpe_c0_vpeconf0(read_vpe_c0_vpeconf0() |\r\nVPECONF0_MVP);\r\nwrite_vpe_c0_cause(0);\r\nwrite_vpe_c0_status((read_vpe_c0_status()\r\n& ~(ST0_BEV | ST0_ERL | ST0_EXL | ST0_IM))\r\n| (STATUSF_IP0 | STATUSF_IP1 | STATUSF_IP7\r\n| ST0_IE));\r\nwrite_vpe_c0_config(read_c0_config());\r\nwrite_vpe_c0_compare(0);\r\nwrite_vpe_c0_config7(read_c0_config7());\r\nwrite_vpe_c0_count(read_c0_count() + CP0_SKEW);\r\nehb();\r\n}\r\nwrite_vpe_c0_vpecontrol(read_vpe_c0_vpecontrol() | VPECONTROL_TE);\r\nwrite_vpe_c0_vpeconf0(read_vpe_c0_vpeconf0() | VPECONF0_VPA);\r\n}\r\nwhile (tc < (((val & MVPCONF0_PTC) >> MVPCONF0_PTC_SHIFT) + 1)) {\r\nset_cpu_possible(tc, false);\r\nset_cpu_present(tc, false);\r\ntc++;\r\n}\r\nwrite_c0_mvpcontrol( read_c0_mvpcontrol() & ~ MVPCONTROL_VPC );\r\nprintk("\n");\r\n#ifdef CONFIG_MIPS_MT_FPAFF\r\nfor (tc = 0; tc < ntc; tc++) {\r\nif (cpu_data[tc].options & MIPS_CPU_FPU)\r\ncpu_set(tc, mt_fpu_cpumask);\r\n}\r\n#endif\r\nsetup_cross_vpe_interrupts(nvpe);\r\nnipi = NR_CPUS * IPIBUF_PER_CPU;\r\nif (ipibuffers > 0)\r\nnipi = ipibuffers;\r\npipi = kmalloc(nipi *sizeof(struct smtc_ipi), GFP_KERNEL);\r\nif (pipi == NULL)\r\npanic("kmalloc of IPI message buffers failed");\r\nelse\r\nprintk("IPI buffer pool of %d buffers\n", nipi);\r\nfor (i = 0; i < nipi; i++) {\r\nsmtc_ipi_nq(&freeIPIq, pipi);\r\npipi++;\r\n}\r\nemt(EMT_ENABLE);\r\nevpe(EVPE_ENABLE);\r\nlocal_irq_restore(flags);\r\ninit_smtc_stats();\r\n}\r\nvoid smtc_boot_secondary(int cpu, struct task_struct *idle)\r\n{\r\nextern u32 kernelsp[NR_CPUS];\r\nunsigned long flags;\r\nint mtflags;\r\nLOCK_MT_PRA();\r\nif (cpu_data[cpu].vpe_id != cpu_data[smp_processor_id()].vpe_id) {\r\ndvpe();\r\n}\r\nsettc(cpu_data[cpu].tc_id);\r\nwrite_tc_c0_tcrestart((unsigned long)&smp_bootstrap);\r\nkernelsp[cpu] = __KSTK_TOS(idle);\r\nwrite_tc_gpr_sp(__KSTK_TOS(idle));\r\nwrite_tc_gpr_gp((unsigned long)task_thread_info(idle));\r\nsmtc_status |= SMTC_MTC_ACTIVE;\r\nwrite_tc_c0_tchalt(0);\r\nif (cpu_data[cpu].vpe_id != cpu_data[smp_processor_id()].vpe_id) {\r\nevpe(EVPE_ENABLE);\r\n}\r\nUNLOCK_MT_PRA();\r\n}\r\nvoid smtc_init_secondary(void)\r\n{\r\n}\r\nvoid smtc_smp_finish(void)\r\n{\r\nint cpu = smp_processor_id();\r\nif (cpu > 0 && (cpu_data[cpu].vpe_id != cpu_data[cpu - 1].vpe_id))\r\nwrite_c0_compare(read_c0_count() + mips_hpt_frequency/HZ);\r\nlocal_irq_enable();\r\nprintk("TC %d going on-line as CPU %d\n",\r\ncpu_data[smp_processor_id()].tc_id, smp_processor_id());\r\n}\r\nvoid smtc_cpus_done(void)\r\n{\r\n}\r\nint setup_irq_smtc(unsigned int irq, struct irqaction * new,\r\nunsigned long hwmask)\r\n{\r\n#ifdef CONFIG_SMTC_IDLE_HOOK_DEBUG\r\nunsigned int vpe = current_cpu_data.vpe_id;\r\nvpemask[vpe][irq - MIPS_CPU_IRQ_BASE] = 1;\r\n#endif\r\nirq_hwmask[irq] = hwmask;\r\nreturn setup_irq(irq, new);\r\n}\r\nvoid smtc_set_irq_affinity(unsigned int irq, cpumask_t affinity)\r\n{\r\n}\r\nvoid smtc_forward_irq(struct irq_data *d)\r\n{\r\nunsigned int irq = d->irq;\r\nint target;\r\ntarget = cpumask_first(d->affinity);\r\nif (target >= NR_CPUS)\r\ndo_IRQ_no_affinity(irq);\r\nelse\r\nsmtc_send_ipi(target, IRQ_AFFINITY_IPI, irq);\r\n}\r\nstatic void smtc_ipi_qdump(void)\r\n{\r\nint i;\r\nstruct smtc_ipi *temp;\r\nfor (i = 0; i < NR_CPUS ;i++) {\r\npr_info("IPIQ[%d]: head = 0x%x, tail = 0x%x, depth = %d\n",\r\ni, (unsigned)IPIQ[i].head, (unsigned)IPIQ[i].tail,\r\nIPIQ[i].depth);\r\ntemp = IPIQ[i].head;\r\nwhile (temp != IPIQ[i].tail) {\r\npr_debug("%d %d %d: ", temp->type, temp->dest,\r\n(int)temp->arg);\r\n#ifdef SMTC_IPI_DEBUG\r\npr_debug("%u %lu\n", temp->sender, temp->stamp);\r\n#else\r\npr_debug("\n");\r\n#endif\r\ntemp = temp->flink;\r\n}\r\n}\r\n}\r\nstatic inline int atomic_postincrement(atomic_t *v)\r\n{\r\nunsigned long result;\r\nunsigned long temp;\r\n__asm__ __volatile__(\r\n"1: ll %0, %2 \n"\r\n" addu %1, %0, 1 \n"\r\n" sc %1, %2 \n"\r\n" beqz %1, 1b \n"\r\n__WEAK_LLSC_MB\r\n: "=&r" (result), "=&r" (temp), "=m" (v->counter)\r\n: "m" (v->counter)\r\n: "memory");\r\nreturn result;\r\n}\r\nvoid smtc_send_ipi(int cpu, int type, unsigned int action)\r\n{\r\nint tcstatus;\r\nstruct smtc_ipi *pipi;\r\nunsigned long flags;\r\nint mtflags;\r\nunsigned long tcrestart;\r\nint set_resched_flag = (type == LINUX_SMP_IPI &&\r\naction == SMP_RESCHEDULE_YOURSELF);\r\nif (cpu == smp_processor_id()) {\r\nprintk("Cannot Send IPI to self!\n");\r\nreturn;\r\n}\r\nif (set_resched_flag && IPIQ[cpu].resched_flag != 0)\r\nreturn;\r\npipi = smtc_ipi_dq(&freeIPIq);\r\nif (pipi == NULL) {\r\nbust_spinlocks(1);\r\nmips_mt_regdump(dvpe());\r\npanic("IPI Msg. Buffers Depleted");\r\n}\r\npipi->type = type;\r\npipi->arg = (void *)action;\r\npipi->dest = cpu;\r\nif (cpu_data[cpu].vpe_id != cpu_data[smp_processor_id()].vpe_id) {\r\nIPIQ[cpu].resched_flag |= set_resched_flag;\r\nsmtc_ipi_nq(&IPIQ[cpu], pipi);\r\nLOCK_CORE_PRA();\r\nsettc(cpu_data[cpu].tc_id);\r\nwrite_vpe_c0_cause(read_vpe_c0_cause() | C_SW1);\r\nUNLOCK_CORE_PRA();\r\n} else {\r\nLOCK_CORE_PRA();\r\nsettc(cpu_data[cpu].tc_id);\r\nwrite_tc_c0_tchalt(TCHALT_H);\r\nmips_ihb();\r\ntcstatus = read_tc_c0_tcstatus();\r\nif ((tcstatus & TCSTATUS_IXMT) != 0) {\r\nif (cpu_wait == r4k_wait_irqoff) {\r\ntcrestart = read_tc_c0_tcrestart();\r\nif (address_is_in_r4k_wait_irqoff(tcrestart)) {\r\nwrite_tc_c0_tcrestart(__pastwait);\r\ntcstatus &= ~TCSTATUS_IXMT;\r\nwrite_tc_c0_tcstatus(tcstatus);\r\ngoto postdirect;\r\n}\r\n}\r\nwrite_tc_c0_tchalt(0);\r\nUNLOCK_CORE_PRA();\r\nIPIQ[cpu].resched_flag |= set_resched_flag;\r\nsmtc_ipi_nq(&IPIQ[cpu], pipi);\r\n} else {\r\npostdirect:\r\npost_direct_ipi(cpu, pipi);\r\nwrite_tc_c0_tchalt(0);\r\nUNLOCK_CORE_PRA();\r\n}\r\n}\r\n}\r\nstatic void post_direct_ipi(int cpu, struct smtc_ipi *pipi)\r\n{\r\nstruct pt_regs *kstack;\r\nunsigned long tcstatus;\r\nunsigned long tcrestart;\r\nextern u32 kernelsp[NR_CPUS];\r\nextern void __smtc_ipi_vector(void);\r\ntcstatus = read_tc_c0_tcstatus();\r\ntcrestart = read_tc_c0_tcrestart();\r\nif ((tcrestart & 0x80000000)\r\n&& ((*(unsigned int *)tcrestart & 0xfe00003f) == 0x42000020)) {\r\ntcrestart += 4;\r\n}\r\nif (tcstatus & ST0_CU0) {\r\nkstack = ((struct pt_regs *)read_tc_gpr_sp()) - 1;\r\n} else {\r\nkstack = ((struct pt_regs *)kernelsp[cpu]) - 1;\r\n}\r\nkstack->cp0_epc = (long)tcrestart;\r\nkstack->cp0_tcstatus = tcstatus;\r\nkstack->pad0[4] = (unsigned long)pipi;\r\nkstack->pad0[5] = (unsigned long)&ipi_decode;\r\ntcstatus |= TCSTATUS_IXMT;\r\ntcstatus &= ~TCSTATUS_TKSU;\r\nwrite_tc_c0_tcstatus(tcstatus);\r\nehb();\r\nwrite_tc_c0_tcrestart(__smtc_ipi_vector);\r\n}\r\nstatic void ipi_resched_interrupt(void)\r\n{\r\nscheduler_ipi();\r\n}\r\nstatic void ipi_call_interrupt(void)\r\n{\r\nsmp_call_function_interrupt();\r\n}\r\nstatic void __irq_entry smtc_clock_tick_interrupt(void)\r\n{\r\nunsigned int cpu = smp_processor_id();\r\nstruct clock_event_device *cd;\r\nint irq = MIPS_CPU_IRQ_BASE + 1;\r\nirq_enter();\r\nkstat_incr_irqs_this_cpu(irq, irq_to_desc(irq));\r\ncd = &per_cpu(mips_clockevent_device, cpu);\r\ncd->event_handler(cd);\r\nirq_exit();\r\n}\r\nvoid ipi_decode(struct smtc_ipi *pipi)\r\n{\r\nvoid *arg_copy = pipi->arg;\r\nint type_copy = pipi->type;\r\nsmtc_ipi_nq(&freeIPIq, pipi);\r\nswitch (type_copy) {\r\ncase SMTC_CLOCK_TICK:\r\nsmtc_clock_tick_interrupt();\r\nbreak;\r\ncase LINUX_SMP_IPI:\r\nswitch ((int)arg_copy) {\r\ncase SMP_RESCHEDULE_YOURSELF:\r\nipi_resched_interrupt();\r\nbreak;\r\ncase SMP_CALL_FUNCTION:\r\nipi_call_interrupt();\r\nbreak;\r\ndefault:\r\nprintk("Impossible SMTC IPI Argument %p\n", arg_copy);\r\nbreak;\r\n}\r\nbreak;\r\n#ifdef CONFIG_MIPS_MT_SMTC_IRQAFF\r\ncase IRQ_AFFINITY_IPI:\r\ndo_IRQ_no_affinity((int)arg_copy);\r\nbreak;\r\n#endif\r\ndefault:\r\nprintk("Impossible SMTC IPI Type 0x%x\n", type_copy);\r\nbreak;\r\n}\r\n}\r\nvoid deferred_smtc_ipi(void)\r\n{\r\nint cpu = smp_processor_id();\r\nwhile (IPIQ[cpu].head != NULL) {\r\nstruct smtc_ipi_q *q = &IPIQ[cpu];\r\nstruct smtc_ipi *pipi;\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nspin_lock(&q->lock);\r\npipi = __smtc_ipi_dq(q);\r\nspin_unlock(&q->lock);\r\nif (pipi != NULL) {\r\nif (pipi->type == LINUX_SMP_IPI &&\r\n(int)pipi->arg == SMP_RESCHEDULE_YOURSELF)\r\nIPIQ[cpu].resched_flag = 0;\r\nipi_decode(pipi);\r\n}\r\n__arch_local_irq_restore(flags);\r\n}\r\n}\r\nstatic irqreturn_t ipi_interrupt(int irq, void *dev_idm)\r\n{\r\nint my_vpe = cpu_data[smp_processor_id()].vpe_id;\r\nint my_tc = cpu_data[smp_processor_id()].tc_id;\r\nint cpu;\r\nstruct smtc_ipi *pipi;\r\nunsigned long tcstatus;\r\nint sent;\r\nunsigned long flags;\r\nunsigned int mtflags;\r\nunsigned int vpflags;\r\nlocal_irq_save(flags);\r\nvpflags = dvpe();\r\nclear_c0_cause(0x100 << MIPS_CPU_IPI_IRQ);\r\nset_c0_status(0x100 << MIPS_CPU_IPI_IRQ);\r\nirq_enable_hazard();\r\nevpe(vpflags);\r\nlocal_irq_restore(flags);\r\nfor_each_online_cpu(cpu) {\r\nif (cpu_data[cpu].vpe_id != my_vpe)\r\ncontinue;\r\npipi = smtc_ipi_dq(&IPIQ[cpu]);\r\nif (pipi != NULL) {\r\nif (cpu_data[cpu].tc_id != my_tc) {\r\nsent = 0;\r\nLOCK_MT_PRA();\r\nsettc(cpu_data[cpu].tc_id);\r\nwrite_tc_c0_tchalt(TCHALT_H);\r\nmips_ihb();\r\ntcstatus = read_tc_c0_tcstatus();\r\nif ((tcstatus & TCSTATUS_IXMT) == 0) {\r\npost_direct_ipi(cpu, pipi);\r\nsent = 1;\r\n}\r\nwrite_tc_c0_tchalt(0);\r\nUNLOCK_MT_PRA();\r\nif (!sent) {\r\nsmtc_ipi_req(&IPIQ[cpu], pipi);\r\n}\r\n} else {\r\nlocal_irq_save(flags);\r\nif (pipi->type == LINUX_SMP_IPI &&\r\n(int)pipi->arg == SMP_RESCHEDULE_YOURSELF)\r\nIPIQ[cpu].resched_flag = 0;\r\nipi_decode(pipi);\r\nlocal_irq_restore(flags);\r\n}\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void ipi_irq_dispatch(void)\r\n{\r\ndo_IRQ(cpu_ipi_irq);\r\n}\r\nstatic void setup_cross_vpe_interrupts(unsigned int nvpe)\r\n{\r\nif (nvpe < 1)\r\nreturn;\r\nif (!cpu_has_vint)\r\npanic("SMTC Kernel requires Vectored Interrupt support");\r\nset_vi_handler(MIPS_CPU_IPI_IRQ, ipi_irq_dispatch);\r\nsetup_irq_smtc(cpu_ipi_irq, &irq_ipi, (0x100 << MIPS_CPU_IPI_IRQ));\r\nirq_set_handler(cpu_ipi_irq, handle_percpu_irq);\r\n}\r\nvoid smtc_ipi_replay(void)\r\n{\r\nunsigned int cpu = smp_processor_id();\r\nwhile (IPIQ[cpu].head != NULL) {\r\nstruct smtc_ipi_q *q = &IPIQ[cpu];\r\nstruct smtc_ipi *pipi;\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nspin_lock(&q->lock);\r\npipi = __smtc_ipi_dq(q);\r\nspin_unlock(&q->lock);\r\n__arch_local_irq_restore(flags);\r\nif (pipi) {\r\nself_ipi(pipi);\r\nsmtc_cpu_stats[cpu].selfipis++;\r\n}\r\n}\r\n}\r\nvoid smtc_idle_loop_hook(void)\r\n{\r\n#ifdef CONFIG_SMTC_IDLE_HOOK_DEBUG\r\nint im;\r\nint flags;\r\nint mtflags;\r\nint bit;\r\nint vpe;\r\nint tc;\r\nint hook_ntcs;\r\nchar *pdb_msg;\r\nchar id_ho_db_msg[768];\r\nif (atomic_read(&idle_hook_initialized) == 0) {\r\nif (atomic_add_return(1, &idle_hook_initialized) == 1) {\r\nint mvpconf0;\r\nmvpconf0 = read_c0_mvpconf0();\r\nhook_ntcs = ((mvpconf0 & MVPCONF0_PTC) >> MVPCONF0_PTC_SHIFT) + 1;\r\nif (hook_ntcs > NR_CPUS)\r\nhook_ntcs = NR_CPUS;\r\nfor (tc = 0; tc < hook_ntcs; tc++) {\r\ntcnoprog[tc] = 0;\r\nclock_hang_reported[tc] = 0;\r\n}\r\nfor (vpe = 0; vpe < 2; vpe++)\r\nfor (im = 0; im < 8; im++)\r\nimstuckcount[vpe][im] = 0;\r\nprintk("Idle loop test hook initialized for %d TCs\n", hook_ntcs);\r\natomic_set(&idle_hook_initialized, 1000);\r\n} else {\r\nwhile (atomic_read(&idle_hook_initialized) < 1000)\r\n;\r\n}\r\n}\r\nif (read_c0_tcstatus() & 0x400) {\r\nwrite_c0_tcstatus(read_c0_tcstatus() & ~0x400);\r\nehb();\r\nprintk("Dangling IXMT in cpu_idle()\n");\r\n}\r\n#define IM_LIMIT 2000\r\nlocal_irq_save(flags);\r\nmtflags = dmt();\r\npdb_msg = &id_ho_db_msg[0];\r\nim = read_c0_status();\r\nvpe = current_cpu_data.vpe_id;\r\nfor (bit = 0; bit < 8; bit++) {\r\nif (vpemask[vpe][bit]) {\r\nif (!(im & (0x100 << bit)))\r\nimstuckcount[vpe][bit]++;\r\nelse\r\nimstuckcount[vpe][bit] = 0;\r\nif (imstuckcount[vpe][bit] > IM_LIMIT) {\r\nset_c0_status(0x100 << bit);\r\nehb();\r\nimstuckcount[vpe][bit] = 0;\r\npdb_msg += sprintf(pdb_msg,\r\n"Dangling IM %d fixed for VPE %d\n", bit,\r\nvpe);\r\n}\r\n}\r\n}\r\nemt(mtflags);\r\nlocal_irq_restore(flags);\r\nif (pdb_msg != &id_ho_db_msg[0])\r\nprintk("CPU%d: %s", smp_processor_id(), id_ho_db_msg);\r\n#endif\r\nsmtc_ipi_replay();\r\n}\r\nvoid smtc_soft_dump(void)\r\n{\r\nint i;\r\nprintk("Counter Interrupts taken per CPU (TC)\n");\r\nfor (i=0; i < NR_CPUS; i++) {\r\nprintk("%d: %ld\n", i, smtc_cpu_stats[i].timerints);\r\n}\r\nprintk("Self-IPI invocations:\n");\r\nfor (i=0; i < NR_CPUS; i++) {\r\nprintk("%d: %ld\n", i, smtc_cpu_stats[i].selfipis);\r\n}\r\nsmtc_ipi_qdump();\r\nprintk("%d Recoveries of \"stolen\" FPU\n",\r\natomic_read(&smtc_fpu_recoveries));\r\n}\r\nvoid smtc_get_new_mmu_context(struct mm_struct *mm, unsigned long cpu)\r\n{\r\nunsigned long flags, mtflags, tcstat, prevhalt, asid;\r\nint tlb, i;\r\nlocal_irq_save(flags);\r\nif (smtc_status & SMTC_TLB_SHARED) {\r\nmtflags = dvpe();\r\ntlb = 0;\r\n} else {\r\nmtflags = dmt();\r\ntlb = cpu_data[cpu].vpe_id;\r\n}\r\nasid = asid_cache(cpu);\r\ndo {\r\nif (!((asid += ASID_INC) & ASID_MASK) ) {\r\nif (cpu_has_vtag_icache)\r\nflush_icache_all();\r\nfor_each_online_cpu(i) {\r\nif ((i != smp_processor_id()) &&\r\n((smtc_status & SMTC_TLB_SHARED) ||\r\n(cpu_data[i].vpe_id == cpu_data[cpu].vpe_id))) {\r\nsettc(cpu_data[i].tc_id);\r\nprevhalt = read_tc_c0_tchalt() & TCHALT_H;\r\nif (!prevhalt) {\r\nwrite_tc_c0_tchalt(TCHALT_H);\r\nmips_ihb();\r\n}\r\ntcstat = read_tc_c0_tcstatus();\r\nsmtc_live_asid[tlb][(tcstat & ASID_MASK)] |= (asiduse)(0x1 << i);\r\nif (!prevhalt)\r\nwrite_tc_c0_tchalt(0);\r\n}\r\n}\r\nif (!asid)\r\nasid = ASID_FIRST_VERSION;\r\nlocal_flush_tlb_all();\r\n}\r\n} while (smtc_live_asid[tlb][(asid & ASID_MASK)]);\r\nfor_each_online_cpu(i) {\r\nif ((smtc_status & SMTC_TLB_SHARED) ||\r\n(cpu_data[i].vpe_id == cpu_data[cpu].vpe_id))\r\ncpu_context(i, mm) = asid_cache(i) = asid;\r\n}\r\nif (smtc_status & SMTC_TLB_SHARED)\r\nevpe(mtflags);\r\nelse\r\nemt(mtflags);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid smtc_flush_tlb_asid(unsigned long asid)\r\n{\r\nint entry;\r\nunsigned long ehi;\r\nentry = read_c0_wired();\r\nwhile (entry < current_cpu_data.tlbsize) {\r\nwrite_c0_index(entry);\r\nehb();\r\ntlb_read();\r\nehb();\r\nehi = read_c0_entryhi();\r\nif ((ehi & ASID_MASK) == asid) {\r\nwrite_c0_entryhi(CKSEG0 + (entry << (PAGE_SHIFT + 1)));\r\nwrite_c0_entrylo0(0);\r\nwrite_c0_entrylo1(0);\r\nmtc0_tlbw_hazard();\r\ntlb_write_indexed();\r\n}\r\nentry++;\r\n}\r\nwrite_c0_index(PARKED_INDEX);\r\ntlbw_use_hazard();\r\n}\r\nvoid smtc_cflush_lockdown(void)\r\n{\r\nint cpu;\r\nfor_each_online_cpu(cpu) {\r\nif (cpu != smp_processor_id()) {\r\nsettc(cpu_data[cpu].tc_id);\r\nhalt_state_save[cpu] = read_tc_c0_tchalt();\r\nwrite_tc_c0_tchalt(TCHALT_H);\r\n}\r\n}\r\nmips_ihb();\r\n}\r\nvoid smtc_cflush_release(void)\r\n{\r\nint cpu;\r\nmips_ihb();\r\nfor_each_online_cpu(cpu) {\r\nif (cpu != smp_processor_id()) {\r\nsettc(cpu_data[cpu].tc_id);\r\nwrite_tc_c0_tchalt(halt_state_save[cpu]);\r\n}\r\n}\r\nmips_ihb();\r\n}
