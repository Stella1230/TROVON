static void rt_fibinfo_free(struct rtable __rcu **rtp)\r\n{\r\nstruct rtable *rt = rcu_dereference_protected(*rtp, 1);\r\nif (!rt)\r\nreturn;\r\ndst_free(&rt->dst);\r\n}\r\nstatic void free_nh_exceptions(struct fib_nh *nh)\r\n{\r\nstruct fnhe_hash_bucket *hash = nh->nh_exceptions;\r\nint i;\r\nfor (i = 0; i < FNHE_HASH_SIZE; i++) {\r\nstruct fib_nh_exception *fnhe;\r\nfnhe = rcu_dereference_protected(hash[i].chain, 1);\r\nwhile (fnhe) {\r\nstruct fib_nh_exception *next;\r\nnext = rcu_dereference_protected(fnhe->fnhe_next, 1);\r\nrt_fibinfo_free(&fnhe->fnhe_rth_input);\r\nrt_fibinfo_free(&fnhe->fnhe_rth_output);\r\nkfree(fnhe);\r\nfnhe = next;\r\n}\r\n}\r\nkfree(hash);\r\n}\r\nstatic void rt_fibinfo_free_cpus(struct rtable __rcu * __percpu *rtp)\r\n{\r\nint cpu;\r\nif (!rtp)\r\nreturn;\r\nfor_each_possible_cpu(cpu) {\r\nstruct rtable *rt;\r\nrt = rcu_dereference_protected(*per_cpu_ptr(rtp, cpu), 1);\r\nif (rt)\r\ndst_free(&rt->dst);\r\n}\r\nfree_percpu(rtp);\r\n}\r\nstatic void free_fib_info_rcu(struct rcu_head *head)\r\n{\r\nstruct fib_info *fi = container_of(head, struct fib_info, rcu);\r\nchange_nexthops(fi) {\r\nif (nexthop_nh->nh_dev)\r\ndev_put(nexthop_nh->nh_dev);\r\nif (nexthop_nh->nh_exceptions)\r\nfree_nh_exceptions(nexthop_nh);\r\nrt_fibinfo_free_cpus(nexthop_nh->nh_pcpu_rth_output);\r\nrt_fibinfo_free(&nexthop_nh->nh_rth_input);\r\n} endfor_nexthops(fi);\r\nrelease_net(fi->fib_net);\r\nif (fi->fib_metrics != (u32 *) dst_default_metrics)\r\nkfree(fi->fib_metrics);\r\nkfree(fi);\r\n}\r\nvoid free_fib_info(struct fib_info *fi)\r\n{\r\nif (fi->fib_dead == 0) {\r\npr_warn("Freeing alive fib_info %p\n", fi);\r\nreturn;\r\n}\r\nfib_info_cnt--;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nchange_nexthops(fi) {\r\nif (nexthop_nh->nh_tclassid)\r\nfi->fib_net->ipv4.fib_num_tclassid_users--;\r\n} endfor_nexthops(fi);\r\n#endif\r\ncall_rcu(&fi->rcu, free_fib_info_rcu);\r\n}\r\nvoid fib_release_info(struct fib_info *fi)\r\n{\r\nspin_lock_bh(&fib_info_lock);\r\nif (fi && --fi->fib_treeref == 0) {\r\nhlist_del(&fi->fib_hash);\r\nif (fi->fib_prefsrc)\r\nhlist_del(&fi->fib_lhash);\r\nchange_nexthops(fi) {\r\nif (!nexthop_nh->nh_dev)\r\ncontinue;\r\nhlist_del(&nexthop_nh->nh_hash);\r\n} endfor_nexthops(fi)\r\nfi->fib_dead = 1;\r\nfib_info_put(fi);\r\n}\r\nspin_unlock_bh(&fib_info_lock);\r\n}\r\nstatic inline int nh_comp(const struct fib_info *fi, const struct fib_info *ofi)\r\n{\r\nconst struct fib_nh *onh = ofi->fib_nh;\r\nfor_nexthops(fi) {\r\nif (nh->nh_oif != onh->nh_oif ||\r\nnh->nh_gw != onh->nh_gw ||\r\nnh->nh_scope != onh->nh_scope ||\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nnh->nh_weight != onh->nh_weight ||\r\n#endif\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nnh->nh_tclassid != onh->nh_tclassid ||\r\n#endif\r\n((nh->nh_flags ^ onh->nh_flags) & ~RTNH_F_DEAD))\r\nreturn -1;\r\nonh++;\r\n} endfor_nexthops(fi);\r\nreturn 0;\r\n}\r\nstatic inline unsigned int fib_devindex_hashfn(unsigned int val)\r\n{\r\nunsigned int mask = DEVINDEX_HASHSIZE - 1;\r\nreturn (val ^\r\n(val >> DEVINDEX_HASHBITS) ^\r\n(val >> (DEVINDEX_HASHBITS * 2))) & mask;\r\n}\r\nstatic inline unsigned int fib_info_hashfn(const struct fib_info *fi)\r\n{\r\nunsigned int mask = (fib_info_hash_size - 1);\r\nunsigned int val = fi->fib_nhs;\r\nval ^= (fi->fib_protocol << 8) | fi->fib_scope;\r\nval ^= (__force u32)fi->fib_prefsrc;\r\nval ^= fi->fib_priority;\r\nfor_nexthops(fi) {\r\nval ^= fib_devindex_hashfn(nh->nh_oif);\r\n} endfor_nexthops(fi)\r\nreturn (val ^ (val >> 7) ^ (val >> 12)) & mask;\r\n}\r\nstatic struct fib_info *fib_find_info(const struct fib_info *nfi)\r\n{\r\nstruct hlist_head *head;\r\nstruct fib_info *fi;\r\nunsigned int hash;\r\nhash = fib_info_hashfn(nfi);\r\nhead = &fib_info_hash[hash];\r\nhlist_for_each_entry(fi, head, fib_hash) {\r\nif (!net_eq(fi->fib_net, nfi->fib_net))\r\ncontinue;\r\nif (fi->fib_nhs != nfi->fib_nhs)\r\ncontinue;\r\nif (nfi->fib_protocol == fi->fib_protocol &&\r\nnfi->fib_scope == fi->fib_scope &&\r\nnfi->fib_prefsrc == fi->fib_prefsrc &&\r\nnfi->fib_priority == fi->fib_priority &&\r\nnfi->fib_type == fi->fib_type &&\r\nmemcmp(nfi->fib_metrics, fi->fib_metrics,\r\nsizeof(u32) * RTAX_MAX) == 0 &&\r\n((nfi->fib_flags ^ fi->fib_flags) & ~RTNH_F_DEAD) == 0 &&\r\n(nfi->fib_nhs == 0 || nh_comp(fi, nfi) == 0))\r\nreturn fi;\r\n}\r\nreturn NULL;\r\n}\r\nint ip_fib_check_default(__be32 gw, struct net_device *dev)\r\n{\r\nstruct hlist_head *head;\r\nstruct fib_nh *nh;\r\nunsigned int hash;\r\nspin_lock(&fib_info_lock);\r\nhash = fib_devindex_hashfn(dev->ifindex);\r\nhead = &fib_info_devhash[hash];\r\nhlist_for_each_entry(nh, head, nh_hash) {\r\nif (nh->nh_dev == dev &&\r\nnh->nh_gw == gw &&\r\n!(nh->nh_flags & RTNH_F_DEAD)) {\r\nspin_unlock(&fib_info_lock);\r\nreturn 0;\r\n}\r\n}\r\nspin_unlock(&fib_info_lock);\r\nreturn -1;\r\n}\r\nstatic inline size_t fib_nlmsg_size(struct fib_info *fi)\r\n{\r\nsize_t payload = NLMSG_ALIGN(sizeof(struct rtmsg))\r\n+ nla_total_size(4)\r\n+ nla_total_size(4)\r\n+ nla_total_size(4)\r\n+ nla_total_size(4);\r\npayload += nla_total_size((RTAX_MAX * nla_total_size(4)));\r\nif (fi->fib_nhs) {\r\nsize_t nhsize = nla_total_size(sizeof(struct rtnexthop));\r\nnhsize += 2 * nla_total_size(4);\r\npayload += nla_total_size(fi->fib_nhs * nhsize);\r\n}\r\nreturn payload;\r\n}\r\nvoid rtmsg_fib(int event, __be32 key, struct fib_alias *fa,\r\nint dst_len, u32 tb_id, struct nl_info *info,\r\nunsigned int nlm_flags)\r\n{\r\nstruct sk_buff *skb;\r\nu32 seq = info->nlh ? info->nlh->nlmsg_seq : 0;\r\nint err = -ENOBUFS;\r\nskb = nlmsg_new(fib_nlmsg_size(fa->fa_info), GFP_KERNEL);\r\nif (skb == NULL)\r\ngoto errout;\r\nerr = fib_dump_info(skb, info->portid, seq, event, tb_id,\r\nfa->fa_type, key, dst_len,\r\nfa->fa_tos, fa->fa_info, nlm_flags);\r\nif (err < 0) {\r\nWARN_ON(err == -EMSGSIZE);\r\nkfree_skb(skb);\r\ngoto errout;\r\n}\r\nrtnl_notify(skb, info->nl_net, info->portid, RTNLGRP_IPV4_ROUTE,\r\ninfo->nlh, GFP_KERNEL);\r\nreturn;\r\nerrout:\r\nif (err < 0)\r\nrtnl_set_sk_err(info->nl_net, RTNLGRP_IPV4_ROUTE, err);\r\n}\r\nstruct fib_alias *fib_find_alias(struct list_head *fah, u8 tos, u32 prio)\r\n{\r\nif (fah) {\r\nstruct fib_alias *fa;\r\nlist_for_each_entry(fa, fah, fa_list) {\r\nif (fa->fa_tos > tos)\r\ncontinue;\r\nif (fa->fa_info->fib_priority >= prio ||\r\nfa->fa_tos < tos)\r\nreturn fa;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nint fib_detect_death(struct fib_info *fi, int order,\r\nstruct fib_info **last_resort, int *last_idx, int dflt)\r\n{\r\nstruct neighbour *n;\r\nint state = NUD_NONE;\r\nn = neigh_lookup(&arp_tbl, &fi->fib_nh[0].nh_gw, fi->fib_dev);\r\nif (n) {\r\nstate = n->nud_state;\r\nneigh_release(n);\r\n}\r\nif (state == NUD_REACHABLE)\r\nreturn 0;\r\nif ((state & NUD_VALID) && order != dflt)\r\nreturn 0;\r\nif ((state & NUD_VALID) ||\r\n(*last_idx < 0 && order > dflt)) {\r\n*last_resort = fi;\r\n*last_idx = order;\r\n}\r\nreturn 1;\r\n}\r\nstatic int fib_count_nexthops(struct rtnexthop *rtnh, int remaining)\r\n{\r\nint nhs = 0;\r\nwhile (rtnh_ok(rtnh, remaining)) {\r\nnhs++;\r\nrtnh = rtnh_next(rtnh, &remaining);\r\n}\r\nreturn remaining > 0 ? 0 : nhs;\r\n}\r\nstatic int fib_get_nhs(struct fib_info *fi, struct rtnexthop *rtnh,\r\nint remaining, struct fib_config *cfg)\r\n{\r\nchange_nexthops(fi) {\r\nint attrlen;\r\nif (!rtnh_ok(rtnh, remaining))\r\nreturn -EINVAL;\r\nnexthop_nh->nh_flags =\r\n(cfg->fc_flags & ~0xFF) | rtnh->rtnh_flags;\r\nnexthop_nh->nh_oif = rtnh->rtnh_ifindex;\r\nnexthop_nh->nh_weight = rtnh->rtnh_hops + 1;\r\nattrlen = rtnh_attrlen(rtnh);\r\nif (attrlen > 0) {\r\nstruct nlattr *nla, *attrs = rtnh_attrs(rtnh);\r\nnla = nla_find(attrs, attrlen, RTA_GATEWAY);\r\nnexthop_nh->nh_gw = nla ? nla_get_be32(nla) : 0;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nnla = nla_find(attrs, attrlen, RTA_FLOW);\r\nnexthop_nh->nh_tclassid = nla ? nla_get_u32(nla) : 0;\r\nif (nexthop_nh->nh_tclassid)\r\nfi->fib_net->ipv4.fib_num_tclassid_users++;\r\n#endif\r\n}\r\nrtnh = rtnh_next(rtnh, &remaining);\r\n} endfor_nexthops(fi);\r\nreturn 0;\r\n}\r\nint fib_nh_match(struct fib_config *cfg, struct fib_info *fi)\r\n{\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nstruct rtnexthop *rtnh;\r\nint remaining;\r\n#endif\r\nif (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)\r\nreturn 1;\r\nif (cfg->fc_oif || cfg->fc_gw) {\r\nif ((!cfg->fc_oif || cfg->fc_oif == fi->fib_nh->nh_oif) &&\r\n(!cfg->fc_gw || cfg->fc_gw == fi->fib_nh->nh_gw))\r\nreturn 0;\r\nreturn 1;\r\n}\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nif (cfg->fc_mp == NULL)\r\nreturn 0;\r\nrtnh = cfg->fc_mp;\r\nremaining = cfg->fc_mp_len;\r\nfor_nexthops(fi) {\r\nint attrlen;\r\nif (!rtnh_ok(rtnh, remaining))\r\nreturn -EINVAL;\r\nif (rtnh->rtnh_ifindex && rtnh->rtnh_ifindex != nh->nh_oif)\r\nreturn 1;\r\nattrlen = rtnh_attrlen(rtnh);\r\nif (attrlen < 0) {\r\nstruct nlattr *nla, *attrs = rtnh_attrs(rtnh);\r\nnla = nla_find(attrs, attrlen, RTA_GATEWAY);\r\nif (nla && nla_get_be32(nla) != nh->nh_gw)\r\nreturn 1;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nnla = nla_find(attrs, attrlen, RTA_FLOW);\r\nif (nla && nla_get_u32(nla) != nh->nh_tclassid)\r\nreturn 1;\r\n#endif\r\n}\r\nrtnh = rtnh_next(rtnh, &remaining);\r\n} endfor_nexthops(fi);\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int fib_check_nh(struct fib_config *cfg, struct fib_info *fi,\r\nstruct fib_nh *nh)\r\n{\r\nint err;\r\nstruct net *net;\r\nstruct net_device *dev;\r\nnet = cfg->fc_nlinfo.nl_net;\r\nif (nh->nh_gw) {\r\nstruct fib_result res;\r\nif (nh->nh_flags & RTNH_F_ONLINK) {\r\nif (cfg->fc_scope >= RT_SCOPE_LINK)\r\nreturn -EINVAL;\r\nif (inet_addr_type(net, nh->nh_gw) != RTN_UNICAST)\r\nreturn -EINVAL;\r\ndev = __dev_get_by_index(net, nh->nh_oif);\r\nif (!dev)\r\nreturn -ENODEV;\r\nif (!(dev->flags & IFF_UP))\r\nreturn -ENETDOWN;\r\nnh->nh_dev = dev;\r\ndev_hold(dev);\r\nnh->nh_scope = RT_SCOPE_LINK;\r\nreturn 0;\r\n}\r\nrcu_read_lock();\r\n{\r\nstruct flowi4 fl4 = {\r\n.daddr = nh->nh_gw,\r\n.flowi4_scope = cfg->fc_scope + 1,\r\n.flowi4_oif = nh->nh_oif,\r\n};\r\nif (fl4.flowi4_scope < RT_SCOPE_LINK)\r\nfl4.flowi4_scope = RT_SCOPE_LINK;\r\nerr = fib_lookup(net, &fl4, &res);\r\nif (err) {\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\n}\r\nerr = -EINVAL;\r\nif (res.type != RTN_UNICAST && res.type != RTN_LOCAL)\r\ngoto out;\r\nnh->nh_scope = res.scope;\r\nnh->nh_oif = FIB_RES_OIF(res);\r\nnh->nh_dev = dev = FIB_RES_DEV(res);\r\nif (!dev)\r\ngoto out;\r\ndev_hold(dev);\r\nerr = (dev->flags & IFF_UP) ? 0 : -ENETDOWN;\r\n} else {\r\nstruct in_device *in_dev;\r\nif (nh->nh_flags & (RTNH_F_PERVASIVE | RTNH_F_ONLINK))\r\nreturn -EINVAL;\r\nrcu_read_lock();\r\nerr = -ENODEV;\r\nin_dev = inetdev_by_index(net, nh->nh_oif);\r\nif (in_dev == NULL)\r\ngoto out;\r\nerr = -ENETDOWN;\r\nif (!(in_dev->dev->flags & IFF_UP))\r\ngoto out;\r\nnh->nh_dev = in_dev->dev;\r\ndev_hold(nh->nh_dev);\r\nnh->nh_scope = RT_SCOPE_HOST;\r\nerr = 0;\r\n}\r\nout:\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nstatic inline unsigned int fib_laddr_hashfn(__be32 val)\r\n{\r\nunsigned int mask = (fib_info_hash_size - 1);\r\nreturn ((__force u32)val ^\r\n((__force u32)val >> 7) ^\r\n((__force u32)val >> 14)) & mask;\r\n}\r\nstatic struct hlist_head *fib_info_hash_alloc(int bytes)\r\n{\r\nif (bytes <= PAGE_SIZE)\r\nreturn kzalloc(bytes, GFP_KERNEL);\r\nelse\r\nreturn (struct hlist_head *)\r\n__get_free_pages(GFP_KERNEL | __GFP_ZERO,\r\nget_order(bytes));\r\n}\r\nstatic void fib_info_hash_free(struct hlist_head *hash, int bytes)\r\n{\r\nif (!hash)\r\nreturn;\r\nif (bytes <= PAGE_SIZE)\r\nkfree(hash);\r\nelse\r\nfree_pages((unsigned long) hash, get_order(bytes));\r\n}\r\nstatic void fib_info_hash_move(struct hlist_head *new_info_hash,\r\nstruct hlist_head *new_laddrhash,\r\nunsigned int new_size)\r\n{\r\nstruct hlist_head *old_info_hash, *old_laddrhash;\r\nunsigned int old_size = fib_info_hash_size;\r\nunsigned int i, bytes;\r\nspin_lock_bh(&fib_info_lock);\r\nold_info_hash = fib_info_hash;\r\nold_laddrhash = fib_info_laddrhash;\r\nfib_info_hash_size = new_size;\r\nfor (i = 0; i < old_size; i++) {\r\nstruct hlist_head *head = &fib_info_hash[i];\r\nstruct hlist_node *n;\r\nstruct fib_info *fi;\r\nhlist_for_each_entry_safe(fi, n, head, fib_hash) {\r\nstruct hlist_head *dest;\r\nunsigned int new_hash;\r\nhlist_del(&fi->fib_hash);\r\nnew_hash = fib_info_hashfn(fi);\r\ndest = &new_info_hash[new_hash];\r\nhlist_add_head(&fi->fib_hash, dest);\r\n}\r\n}\r\nfib_info_hash = new_info_hash;\r\nfor (i = 0; i < old_size; i++) {\r\nstruct hlist_head *lhead = &fib_info_laddrhash[i];\r\nstruct hlist_node *n;\r\nstruct fib_info *fi;\r\nhlist_for_each_entry_safe(fi, n, lhead, fib_lhash) {\r\nstruct hlist_head *ldest;\r\nunsigned int new_hash;\r\nhlist_del(&fi->fib_lhash);\r\nnew_hash = fib_laddr_hashfn(fi->fib_prefsrc);\r\nldest = &new_laddrhash[new_hash];\r\nhlist_add_head(&fi->fib_lhash, ldest);\r\n}\r\n}\r\nfib_info_laddrhash = new_laddrhash;\r\nspin_unlock_bh(&fib_info_lock);\r\nbytes = old_size * sizeof(struct hlist_head *);\r\nfib_info_hash_free(old_info_hash, bytes);\r\nfib_info_hash_free(old_laddrhash, bytes);\r\n}\r\n__be32 fib_info_update_nh_saddr(struct net *net, struct fib_nh *nh)\r\n{\r\nnh->nh_saddr = inet_select_addr(nh->nh_dev,\r\nnh->nh_gw,\r\nnh->nh_parent->fib_scope);\r\nnh->nh_saddr_genid = atomic_read(&net->ipv4.dev_addr_genid);\r\nreturn nh->nh_saddr;\r\n}\r\nstruct fib_info *fib_create_info(struct fib_config *cfg)\r\n{\r\nint err;\r\nstruct fib_info *fi = NULL;\r\nstruct fib_info *ofi;\r\nint nhs = 1;\r\nstruct net *net = cfg->fc_nlinfo.nl_net;\r\nif (cfg->fc_type > RTN_MAX)\r\ngoto err_inval;\r\nif (fib_props[cfg->fc_type].scope > cfg->fc_scope)\r\ngoto err_inval;\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nif (cfg->fc_mp) {\r\nnhs = fib_count_nexthops(cfg->fc_mp, cfg->fc_mp_len);\r\nif (nhs == 0)\r\ngoto err_inval;\r\n}\r\n#endif\r\nerr = -ENOBUFS;\r\nif (fib_info_cnt >= fib_info_hash_size) {\r\nunsigned int new_size = fib_info_hash_size << 1;\r\nstruct hlist_head *new_info_hash;\r\nstruct hlist_head *new_laddrhash;\r\nunsigned int bytes;\r\nif (!new_size)\r\nnew_size = 16;\r\nbytes = new_size * sizeof(struct hlist_head *);\r\nnew_info_hash = fib_info_hash_alloc(bytes);\r\nnew_laddrhash = fib_info_hash_alloc(bytes);\r\nif (!new_info_hash || !new_laddrhash) {\r\nfib_info_hash_free(new_info_hash, bytes);\r\nfib_info_hash_free(new_laddrhash, bytes);\r\n} else\r\nfib_info_hash_move(new_info_hash, new_laddrhash, new_size);\r\nif (!fib_info_hash_size)\r\ngoto failure;\r\n}\r\nfi = kzalloc(sizeof(*fi)+nhs*sizeof(struct fib_nh), GFP_KERNEL);\r\nif (fi == NULL)\r\ngoto failure;\r\nif (cfg->fc_mx) {\r\nfi->fib_metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);\r\nif (!fi->fib_metrics)\r\ngoto failure;\r\n} else\r\nfi->fib_metrics = (u32 *) dst_default_metrics;\r\nfib_info_cnt++;\r\nfi->fib_net = hold_net(net);\r\nfi->fib_protocol = cfg->fc_protocol;\r\nfi->fib_scope = cfg->fc_scope;\r\nfi->fib_flags = cfg->fc_flags;\r\nfi->fib_priority = cfg->fc_priority;\r\nfi->fib_prefsrc = cfg->fc_prefsrc;\r\nfi->fib_type = cfg->fc_type;\r\nfi->fib_nhs = nhs;\r\nchange_nexthops(fi) {\r\nnexthop_nh->nh_parent = fi;\r\nnexthop_nh->nh_pcpu_rth_output = alloc_percpu(struct rtable __rcu *);\r\nif (!nexthop_nh->nh_pcpu_rth_output)\r\ngoto failure;\r\n} endfor_nexthops(fi)\r\nif (cfg->fc_mx) {\r\nstruct nlattr *nla;\r\nint remaining;\r\nnla_for_each_attr(nla, cfg->fc_mx, cfg->fc_mx_len, remaining) {\r\nint type = nla_type(nla);\r\nif (type) {\r\nu32 val;\r\nif (type > RTAX_MAX)\r\ngoto err_inval;\r\nval = nla_get_u32(nla);\r\nif (type == RTAX_ADVMSS && val > 65535 - 40)\r\nval = 65535 - 40;\r\nif (type == RTAX_MTU && val > 65535 - 15)\r\nval = 65535 - 15;\r\nfi->fib_metrics[type - 1] = val;\r\n}\r\n}\r\n}\r\nif (cfg->fc_mp) {\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nerr = fib_get_nhs(fi, cfg->fc_mp, cfg->fc_mp_len, cfg);\r\nif (err != 0)\r\ngoto failure;\r\nif (cfg->fc_oif && fi->fib_nh->nh_oif != cfg->fc_oif)\r\ngoto err_inval;\r\nif (cfg->fc_gw && fi->fib_nh->nh_gw != cfg->fc_gw)\r\ngoto err_inval;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nif (cfg->fc_flow && fi->fib_nh->nh_tclassid != cfg->fc_flow)\r\ngoto err_inval;\r\n#endif\r\n#else\r\ngoto err_inval;\r\n#endif\r\n} else {\r\nstruct fib_nh *nh = fi->fib_nh;\r\nnh->nh_oif = cfg->fc_oif;\r\nnh->nh_gw = cfg->fc_gw;\r\nnh->nh_flags = cfg->fc_flags;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nnh->nh_tclassid = cfg->fc_flow;\r\nif (nh->nh_tclassid)\r\nfi->fib_net->ipv4.fib_num_tclassid_users++;\r\n#endif\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nnh->nh_weight = 1;\r\n#endif\r\n}\r\nif (fib_props[cfg->fc_type].error) {\r\nif (cfg->fc_gw || cfg->fc_oif || cfg->fc_mp)\r\ngoto err_inval;\r\ngoto link_it;\r\n} else {\r\nswitch (cfg->fc_type) {\r\ncase RTN_UNICAST:\r\ncase RTN_LOCAL:\r\ncase RTN_BROADCAST:\r\ncase RTN_ANYCAST:\r\ncase RTN_MULTICAST:\r\nbreak;\r\ndefault:\r\ngoto err_inval;\r\n}\r\n}\r\nif (cfg->fc_scope > RT_SCOPE_HOST)\r\ngoto err_inval;\r\nif (cfg->fc_scope == RT_SCOPE_HOST) {\r\nstruct fib_nh *nh = fi->fib_nh;\r\nif (nhs != 1 || nh->nh_gw)\r\ngoto err_inval;\r\nnh->nh_scope = RT_SCOPE_NOWHERE;\r\nnh->nh_dev = dev_get_by_index(net, fi->fib_nh->nh_oif);\r\nerr = -ENODEV;\r\nif (nh->nh_dev == NULL)\r\ngoto failure;\r\n} else {\r\nchange_nexthops(fi) {\r\nerr = fib_check_nh(cfg, fi, nexthop_nh);\r\nif (err != 0)\r\ngoto failure;\r\n} endfor_nexthops(fi)\r\n}\r\nif (fi->fib_prefsrc) {\r\nif (cfg->fc_type != RTN_LOCAL || !cfg->fc_dst ||\r\nfi->fib_prefsrc != cfg->fc_dst)\r\nif (inet_addr_type(net, fi->fib_prefsrc) != RTN_LOCAL)\r\ngoto err_inval;\r\n}\r\nchange_nexthops(fi) {\r\nfib_info_update_nh_saddr(net, nexthop_nh);\r\n} endfor_nexthops(fi)\r\nlink_it:\r\nofi = fib_find_info(fi);\r\nif (ofi) {\r\nfi->fib_dead = 1;\r\nfree_fib_info(fi);\r\nofi->fib_treeref++;\r\nreturn ofi;\r\n}\r\nfi->fib_treeref++;\r\natomic_inc(&fi->fib_clntref);\r\nspin_lock_bh(&fib_info_lock);\r\nhlist_add_head(&fi->fib_hash,\r\n&fib_info_hash[fib_info_hashfn(fi)]);\r\nif (fi->fib_prefsrc) {\r\nstruct hlist_head *head;\r\nhead = &fib_info_laddrhash[fib_laddr_hashfn(fi->fib_prefsrc)];\r\nhlist_add_head(&fi->fib_lhash, head);\r\n}\r\nchange_nexthops(fi) {\r\nstruct hlist_head *head;\r\nunsigned int hash;\r\nif (!nexthop_nh->nh_dev)\r\ncontinue;\r\nhash = fib_devindex_hashfn(nexthop_nh->nh_dev->ifindex);\r\nhead = &fib_info_devhash[hash];\r\nhlist_add_head(&nexthop_nh->nh_hash, head);\r\n} endfor_nexthops(fi)\r\nspin_unlock_bh(&fib_info_lock);\r\nreturn fi;\r\nerr_inval:\r\nerr = -EINVAL;\r\nfailure:\r\nif (fi) {\r\nfi->fib_dead = 1;\r\nfree_fib_info(fi);\r\n}\r\nreturn ERR_PTR(err);\r\n}\r\nint fib_dump_info(struct sk_buff *skb, u32 portid, u32 seq, int event,\r\nu32 tb_id, u8 type, __be32 dst, int dst_len, u8 tos,\r\nstruct fib_info *fi, unsigned int flags)\r\n{\r\nstruct nlmsghdr *nlh;\r\nstruct rtmsg *rtm;\r\nnlh = nlmsg_put(skb, portid, seq, event, sizeof(*rtm), flags);\r\nif (nlh == NULL)\r\nreturn -EMSGSIZE;\r\nrtm = nlmsg_data(nlh);\r\nrtm->rtm_family = AF_INET;\r\nrtm->rtm_dst_len = dst_len;\r\nrtm->rtm_src_len = 0;\r\nrtm->rtm_tos = tos;\r\nif (tb_id < 256)\r\nrtm->rtm_table = tb_id;\r\nelse\r\nrtm->rtm_table = RT_TABLE_COMPAT;\r\nif (nla_put_u32(skb, RTA_TABLE, tb_id))\r\ngoto nla_put_failure;\r\nrtm->rtm_type = type;\r\nrtm->rtm_flags = fi->fib_flags;\r\nrtm->rtm_scope = fi->fib_scope;\r\nrtm->rtm_protocol = fi->fib_protocol;\r\nif (rtm->rtm_dst_len &&\r\nnla_put_be32(skb, RTA_DST, dst))\r\ngoto nla_put_failure;\r\nif (fi->fib_priority &&\r\nnla_put_u32(skb, RTA_PRIORITY, fi->fib_priority))\r\ngoto nla_put_failure;\r\nif (rtnetlink_put_metrics(skb, fi->fib_metrics) < 0)\r\ngoto nla_put_failure;\r\nif (fi->fib_prefsrc &&\r\nnla_put_be32(skb, RTA_PREFSRC, fi->fib_prefsrc))\r\ngoto nla_put_failure;\r\nif (fi->fib_nhs == 1) {\r\nif (fi->fib_nh->nh_gw &&\r\nnla_put_be32(skb, RTA_GATEWAY, fi->fib_nh->nh_gw))\r\ngoto nla_put_failure;\r\nif (fi->fib_nh->nh_oif &&\r\nnla_put_u32(skb, RTA_OIF, fi->fib_nh->nh_oif))\r\ngoto nla_put_failure;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nif (fi->fib_nh[0].nh_tclassid &&\r\nnla_put_u32(skb, RTA_FLOW, fi->fib_nh[0].nh_tclassid))\r\ngoto nla_put_failure;\r\n#endif\r\n}\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nif (fi->fib_nhs > 1) {\r\nstruct rtnexthop *rtnh;\r\nstruct nlattr *mp;\r\nmp = nla_nest_start(skb, RTA_MULTIPATH);\r\nif (mp == NULL)\r\ngoto nla_put_failure;\r\nfor_nexthops(fi) {\r\nrtnh = nla_reserve_nohdr(skb, sizeof(*rtnh));\r\nif (rtnh == NULL)\r\ngoto nla_put_failure;\r\nrtnh->rtnh_flags = nh->nh_flags & 0xFF;\r\nrtnh->rtnh_hops = nh->nh_weight - 1;\r\nrtnh->rtnh_ifindex = nh->nh_oif;\r\nif (nh->nh_gw &&\r\nnla_put_be32(skb, RTA_GATEWAY, nh->nh_gw))\r\ngoto nla_put_failure;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nif (nh->nh_tclassid &&\r\nnla_put_u32(skb, RTA_FLOW, nh->nh_tclassid))\r\ngoto nla_put_failure;\r\n#endif\r\nrtnh->rtnh_len = nlmsg_get_pos(skb) - (void *) rtnh;\r\n} endfor_nexthops(fi);\r\nnla_nest_end(skb, mp);\r\n}\r\n#endif\r\nreturn nlmsg_end(skb, nlh);\r\nnla_put_failure:\r\nnlmsg_cancel(skb, nlh);\r\nreturn -EMSGSIZE;\r\n}\r\nint fib_sync_down_addr(struct net *net, __be32 local)\r\n{\r\nint ret = 0;\r\nunsigned int hash = fib_laddr_hashfn(local);\r\nstruct hlist_head *head = &fib_info_laddrhash[hash];\r\nstruct fib_info *fi;\r\nif (fib_info_laddrhash == NULL || local == 0)\r\nreturn 0;\r\nhlist_for_each_entry(fi, head, fib_lhash) {\r\nif (!net_eq(fi->fib_net, net))\r\ncontinue;\r\nif (fi->fib_prefsrc == local) {\r\nfi->fib_flags |= RTNH_F_DEAD;\r\nret++;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nint fib_sync_down_dev(struct net_device *dev, int force)\r\n{\r\nint ret = 0;\r\nint scope = RT_SCOPE_NOWHERE;\r\nstruct fib_info *prev_fi = NULL;\r\nunsigned int hash = fib_devindex_hashfn(dev->ifindex);\r\nstruct hlist_head *head = &fib_info_devhash[hash];\r\nstruct fib_nh *nh;\r\nif (force)\r\nscope = -1;\r\nhlist_for_each_entry(nh, head, nh_hash) {\r\nstruct fib_info *fi = nh->nh_parent;\r\nint dead;\r\nBUG_ON(!fi->fib_nhs);\r\nif (nh->nh_dev != dev || fi == prev_fi)\r\ncontinue;\r\nprev_fi = fi;\r\ndead = 0;\r\nchange_nexthops(fi) {\r\nif (nexthop_nh->nh_flags & RTNH_F_DEAD)\r\ndead++;\r\nelse if (nexthop_nh->nh_dev == dev &&\r\nnexthop_nh->nh_scope != scope) {\r\nnexthop_nh->nh_flags |= RTNH_F_DEAD;\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nspin_lock_bh(&fib_multipath_lock);\r\nfi->fib_power -= nexthop_nh->nh_power;\r\nnexthop_nh->nh_power = 0;\r\nspin_unlock_bh(&fib_multipath_lock);\r\n#endif\r\ndead++;\r\n}\r\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\r\nif (force > 1 && nexthop_nh->nh_dev == dev) {\r\ndead = fi->fib_nhs;\r\nbreak;\r\n}\r\n#endif\r\n} endfor_nexthops(fi)\r\nif (dead == fi->fib_nhs) {\r\nfi->fib_flags |= RTNH_F_DEAD;\r\nret++;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid fib_select_default(struct fib_result *res)\r\n{\r\nstruct fib_info *fi = NULL, *last_resort = NULL;\r\nstruct list_head *fa_head = res->fa_head;\r\nstruct fib_table *tb = res->table;\r\nint order = -1, last_idx = -1;\r\nstruct fib_alias *fa;\r\nlist_for_each_entry_rcu(fa, fa_head, fa_list) {\r\nstruct fib_info *next_fi = fa->fa_info;\r\nif (next_fi->fib_scope != res->scope ||\r\nfa->fa_type != RTN_UNICAST)\r\ncontinue;\r\nif (next_fi->fib_priority > res->fi->fib_priority)\r\nbreak;\r\nif (!next_fi->fib_nh[0].nh_gw ||\r\nnext_fi->fib_nh[0].nh_scope != RT_SCOPE_LINK)\r\ncontinue;\r\nfib_alias_accessed(fa);\r\nif (fi == NULL) {\r\nif (next_fi != res->fi)\r\nbreak;\r\n} else if (!fib_detect_death(fi, order, &last_resort,\r\n&last_idx, tb->tb_default)) {\r\nfib_result_assign(res, fi);\r\ntb->tb_default = order;\r\ngoto out;\r\n}\r\nfi = next_fi;\r\norder++;\r\n}\r\nif (order <= 0 || fi == NULL) {\r\ntb->tb_default = -1;\r\ngoto out;\r\n}\r\nif (!fib_detect_death(fi, order, &last_resort, &last_idx,\r\ntb->tb_default)) {\r\nfib_result_assign(res, fi);\r\ntb->tb_default = order;\r\ngoto out;\r\n}\r\nif (last_idx >= 0)\r\nfib_result_assign(res, last_resort);\r\ntb->tb_default = last_idx;\r\nout:\r\nreturn;\r\n}\r\nint fib_sync_up(struct net_device *dev)\r\n{\r\nstruct fib_info *prev_fi;\r\nunsigned int hash;\r\nstruct hlist_head *head;\r\nstruct fib_nh *nh;\r\nint ret;\r\nif (!(dev->flags & IFF_UP))\r\nreturn 0;\r\nprev_fi = NULL;\r\nhash = fib_devindex_hashfn(dev->ifindex);\r\nhead = &fib_info_devhash[hash];\r\nret = 0;\r\nhlist_for_each_entry(nh, head, nh_hash) {\r\nstruct fib_info *fi = nh->nh_parent;\r\nint alive;\r\nBUG_ON(!fi->fib_nhs);\r\nif (nh->nh_dev != dev || fi == prev_fi)\r\ncontinue;\r\nprev_fi = fi;\r\nalive = 0;\r\nchange_nexthops(fi) {\r\nif (!(nexthop_nh->nh_flags & RTNH_F_DEAD)) {\r\nalive++;\r\ncontinue;\r\n}\r\nif (nexthop_nh->nh_dev == NULL ||\r\n!(nexthop_nh->nh_dev->flags & IFF_UP))\r\ncontinue;\r\nif (nexthop_nh->nh_dev != dev ||\r\n!__in_dev_get_rtnl(dev))\r\ncontinue;\r\nalive++;\r\nspin_lock_bh(&fib_multipath_lock);\r\nnexthop_nh->nh_power = 0;\r\nnexthop_nh->nh_flags &= ~RTNH_F_DEAD;\r\nspin_unlock_bh(&fib_multipath_lock);\r\n} endfor_nexthops(fi)\r\nif (alive > 0) {\r\nfi->fib_flags &= ~RTNH_F_DEAD;\r\nret++;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid fib_select_multipath(struct fib_result *res)\r\n{\r\nstruct fib_info *fi = res->fi;\r\nint w;\r\nspin_lock_bh(&fib_multipath_lock);\r\nif (fi->fib_power <= 0) {\r\nint power = 0;\r\nchange_nexthops(fi) {\r\nif (!(nexthop_nh->nh_flags & RTNH_F_DEAD)) {\r\npower += nexthop_nh->nh_weight;\r\nnexthop_nh->nh_power = nexthop_nh->nh_weight;\r\n}\r\n} endfor_nexthops(fi);\r\nfi->fib_power = power;\r\nif (power <= 0) {\r\nspin_unlock_bh(&fib_multipath_lock);\r\nres->nh_sel = 0;\r\nreturn;\r\n}\r\n}\r\nw = jiffies % fi->fib_power;\r\nchange_nexthops(fi) {\r\nif (!(nexthop_nh->nh_flags & RTNH_F_DEAD) &&\r\nnexthop_nh->nh_power) {\r\nw -= nexthop_nh->nh_power;\r\nif (w <= 0) {\r\nnexthop_nh->nh_power--;\r\nfi->fib_power--;\r\nres->nh_sel = nhsel;\r\nspin_unlock_bh(&fib_multipath_lock);\r\nreturn;\r\n}\r\n}\r\n} endfor_nexthops(fi);\r\nres->nh_sel = 0;\r\nspin_unlock_bh(&fib_multipath_lock);\r\n}
