static int rx_flow_is_on(struct caifsock *cf_sk)\r\n{\r\nreturn test_bit(RX_FLOW_ON_BIT,\r\n(void *) &cf_sk->flow_state);\r\n}\r\nstatic int tx_flow_is_on(struct caifsock *cf_sk)\r\n{\r\nreturn test_bit(TX_FLOW_ON_BIT,\r\n(void *) &cf_sk->flow_state);\r\n}\r\nstatic void set_rx_flow_off(struct caifsock *cf_sk)\r\n{\r\nclear_bit(RX_FLOW_ON_BIT,\r\n(void *) &cf_sk->flow_state);\r\n}\r\nstatic void set_rx_flow_on(struct caifsock *cf_sk)\r\n{\r\nset_bit(RX_FLOW_ON_BIT,\r\n(void *) &cf_sk->flow_state);\r\n}\r\nstatic void set_tx_flow_off(struct caifsock *cf_sk)\r\n{\r\nclear_bit(TX_FLOW_ON_BIT,\r\n(void *) &cf_sk->flow_state);\r\n}\r\nstatic void set_tx_flow_on(struct caifsock *cf_sk)\r\n{\r\nset_bit(TX_FLOW_ON_BIT,\r\n(void *) &cf_sk->flow_state);\r\n}\r\nstatic void caif_read_lock(struct sock *sk)\r\n{\r\nstruct caifsock *cf_sk;\r\ncf_sk = container_of(sk, struct caifsock, sk);\r\nmutex_lock(&cf_sk->readlock);\r\n}\r\nstatic void caif_read_unlock(struct sock *sk)\r\n{\r\nstruct caifsock *cf_sk;\r\ncf_sk = container_of(sk, struct caifsock, sk);\r\nmutex_unlock(&cf_sk->readlock);\r\n}\r\nstatic int sk_rcvbuf_lowwater(struct caifsock *cf_sk)\r\n{\r\nreturn cf_sk->sk.sk_rcvbuf / 4;\r\n}\r\nstatic void caif_flow_ctrl(struct sock *sk, int mode)\r\n{\r\nstruct caifsock *cf_sk;\r\ncf_sk = container_of(sk, struct caifsock, sk);\r\nif (cf_sk->layer.dn && cf_sk->layer.dn->modemcmd)\r\ncf_sk->layer.dn->modemcmd(cf_sk->layer.dn, mode);\r\n}\r\nstatic int caif_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)\r\n{\r\nint err;\r\nint skb_len;\r\nunsigned long flags;\r\nstruct sk_buff_head *list = &sk->sk_receive_queue;\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nif (atomic_read(&sk->sk_rmem_alloc) + skb->truesize >=\r\n(unsigned int)sk->sk_rcvbuf && rx_flow_is_on(cf_sk)) {\r\nnet_dbg_ratelimited("sending flow OFF (queue len = %d %d)\n",\r\natomic_read(&cf_sk->sk.sk_rmem_alloc),\r\nsk_rcvbuf_lowwater(cf_sk));\r\nset_rx_flow_off(cf_sk);\r\ncaif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_OFF_REQ);\r\n}\r\nerr = sk_filter(sk, skb);\r\nif (err)\r\nreturn err;\r\nif (!sk_rmem_schedule(sk, skb, skb->truesize) && rx_flow_is_on(cf_sk)) {\r\nset_rx_flow_off(cf_sk);\r\nnet_dbg_ratelimited("sending flow OFF due to rmem_schedule\n");\r\ncaif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_OFF_REQ);\r\n}\r\nskb->dev = NULL;\r\nskb_set_owner_r(skb, sk);\r\nskb_len = skb->len;\r\nspin_lock_irqsave(&list->lock, flags);\r\nif (!sock_flag(sk, SOCK_DEAD))\r\n__skb_queue_tail(list, skb);\r\nspin_unlock_irqrestore(&list->lock, flags);\r\nif (!sock_flag(sk, SOCK_DEAD))\r\nsk->sk_data_ready(sk, skb_len);\r\nelse\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nstatic int caif_sktrecv_cb(struct cflayer *layr, struct cfpkt *pkt)\r\n{\r\nstruct caifsock *cf_sk;\r\nstruct sk_buff *skb;\r\ncf_sk = container_of(layr, struct caifsock, layer);\r\nskb = cfpkt_tonative(pkt);\r\nif (unlikely(cf_sk->sk.sk_state != CAIF_CONNECTED)) {\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\ncaif_queue_rcv_skb(&cf_sk->sk, skb);\r\nreturn 0;\r\n}\r\nstatic void cfsk_hold(struct cflayer *layr)\r\n{\r\nstruct caifsock *cf_sk = container_of(layr, struct caifsock, layer);\r\nsock_hold(&cf_sk->sk);\r\n}\r\nstatic void cfsk_put(struct cflayer *layr)\r\n{\r\nstruct caifsock *cf_sk = container_of(layr, struct caifsock, layer);\r\nsock_put(&cf_sk->sk);\r\n}\r\nstatic void caif_ctrl_cb(struct cflayer *layr,\r\nenum caif_ctrlcmd flow,\r\nint phyid)\r\n{\r\nstruct caifsock *cf_sk = container_of(layr, struct caifsock, layer);\r\nswitch (flow) {\r\ncase CAIF_CTRLCMD_FLOW_ON_IND:\r\nset_tx_flow_on(cf_sk);\r\ncf_sk->sk.sk_state_change(&cf_sk->sk);\r\nbreak;\r\ncase CAIF_CTRLCMD_FLOW_OFF_IND:\r\nset_tx_flow_off(cf_sk);\r\ncf_sk->sk.sk_state_change(&cf_sk->sk);\r\nbreak;\r\ncase CAIF_CTRLCMD_INIT_RSP:\r\ncaif_client_register_refcnt(&cf_sk->layer,\r\ncfsk_hold, cfsk_put);\r\ncf_sk->sk.sk_state = CAIF_CONNECTED;\r\nset_tx_flow_on(cf_sk);\r\ncf_sk->sk.sk_shutdown = 0;\r\ncf_sk->sk.sk_state_change(&cf_sk->sk);\r\nbreak;\r\ncase CAIF_CTRLCMD_DEINIT_RSP:\r\ncf_sk->sk.sk_state = CAIF_DISCONNECTED;\r\ncf_sk->sk.sk_state_change(&cf_sk->sk);\r\nbreak;\r\ncase CAIF_CTRLCMD_INIT_FAIL_RSP:\r\ncf_sk->sk.sk_err = ECONNREFUSED;\r\ncf_sk->sk.sk_state = CAIF_DISCONNECTED;\r\ncf_sk->sk.sk_shutdown = SHUTDOWN_MASK;\r\nset_tx_flow_on(cf_sk);\r\ncf_sk->sk.sk_state_change(&cf_sk->sk);\r\nbreak;\r\ncase CAIF_CTRLCMD_REMOTE_SHUTDOWN_IND:\r\ncf_sk->sk.sk_shutdown = SHUTDOWN_MASK;\r\ncf_sk->sk.sk_err = ECONNRESET;\r\nset_rx_flow_on(cf_sk);\r\ncf_sk->sk.sk_error_report(&cf_sk->sk);\r\nbreak;\r\ndefault:\r\npr_debug("Unexpected flow command %d\n", flow);\r\n}\r\n}\r\nstatic void caif_check_flow_release(struct sock *sk)\r\n{\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nif (rx_flow_is_on(cf_sk))\r\nreturn;\r\nif (atomic_read(&sk->sk_rmem_alloc) <= sk_rcvbuf_lowwater(cf_sk)) {\r\nset_rx_flow_on(cf_sk);\r\ncaif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_ON_REQ);\r\n}\r\n}\r\nstatic int caif_seqpkt_recvmsg(struct kiocb *iocb, struct socket *sock,\r\nstruct msghdr *m, size_t len, int flags)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct sk_buff *skb;\r\nint ret;\r\nint copylen;\r\nret = -EOPNOTSUPP;\r\nif (m->msg_flags&MSG_OOB)\r\ngoto read_error;\r\nm->msg_namelen = 0;\r\nskb = skb_recv_datagram(sk, flags, 0 , &ret);\r\nif (!skb)\r\ngoto read_error;\r\ncopylen = skb->len;\r\nif (len < copylen) {\r\nm->msg_flags |= MSG_TRUNC;\r\ncopylen = len;\r\n}\r\nret = skb_copy_datagram_iovec(skb, 0, m->msg_iov, copylen);\r\nif (ret)\r\ngoto out_free;\r\nret = (flags & MSG_TRUNC) ? skb->len : copylen;\r\nout_free:\r\nskb_free_datagram(sk, skb);\r\ncaif_check_flow_release(sk);\r\nreturn ret;\r\nread_error:\r\nreturn ret;\r\n}\r\nstatic long caif_stream_data_wait(struct sock *sk, long timeo)\r\n{\r\nDEFINE_WAIT(wait);\r\nlock_sock(sk);\r\nfor (;;) {\r\nprepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);\r\nif (!skb_queue_empty(&sk->sk_receive_queue) ||\r\nsk->sk_err ||\r\nsk->sk_state != CAIF_CONNECTED ||\r\nsock_flag(sk, SOCK_DEAD) ||\r\n(sk->sk_shutdown & RCV_SHUTDOWN) ||\r\nsignal_pending(current) ||\r\n!timeo)\r\nbreak;\r\nset_bit(SOCK_ASYNC_WAITDATA, &sk->sk_socket->flags);\r\nrelease_sock(sk);\r\ntimeo = schedule_timeout(timeo);\r\nlock_sock(sk);\r\nclear_bit(SOCK_ASYNC_WAITDATA, &sk->sk_socket->flags);\r\n}\r\nfinish_wait(sk_sleep(sk), &wait);\r\nrelease_sock(sk);\r\nreturn timeo;\r\n}\r\nstatic int caif_stream_recvmsg(struct kiocb *iocb, struct socket *sock,\r\nstruct msghdr *msg, size_t size,\r\nint flags)\r\n{\r\nstruct sock *sk = sock->sk;\r\nint copied = 0;\r\nint target;\r\nint err = 0;\r\nlong timeo;\r\nerr = -EOPNOTSUPP;\r\nif (flags&MSG_OOB)\r\ngoto out;\r\nmsg->msg_namelen = 0;\r\nerr = -EAGAIN;\r\nif (sk->sk_state == CAIF_CONNECTING)\r\ngoto out;\r\ncaif_read_lock(sk);\r\ntarget = sock_rcvlowat(sk, flags&MSG_WAITALL, size);\r\ntimeo = sock_rcvtimeo(sk, flags&MSG_DONTWAIT);\r\ndo {\r\nint chunk;\r\nstruct sk_buff *skb;\r\nlock_sock(sk);\r\nskb = skb_dequeue(&sk->sk_receive_queue);\r\ncaif_check_flow_release(sk);\r\nif (skb == NULL) {\r\nif (copied >= target)\r\ngoto unlock;\r\nerr = sock_error(sk);\r\nif (err)\r\ngoto unlock;\r\nerr = -ECONNRESET;\r\nif (sk->sk_shutdown & RCV_SHUTDOWN)\r\ngoto unlock;\r\nerr = -EPIPE;\r\nif (sk->sk_state != CAIF_CONNECTED)\r\ngoto unlock;\r\nif (sock_flag(sk, SOCK_DEAD))\r\ngoto unlock;\r\nrelease_sock(sk);\r\nerr = -EAGAIN;\r\nif (!timeo)\r\nbreak;\r\ncaif_read_unlock(sk);\r\ntimeo = caif_stream_data_wait(sk, timeo);\r\nif (signal_pending(current)) {\r\nerr = sock_intr_errno(timeo);\r\ngoto out;\r\n}\r\ncaif_read_lock(sk);\r\ncontinue;\r\nunlock:\r\nrelease_sock(sk);\r\nbreak;\r\n}\r\nrelease_sock(sk);\r\nchunk = min_t(unsigned int, skb->len, size);\r\nif (memcpy_toiovec(msg->msg_iov, skb->data, chunk)) {\r\nskb_queue_head(&sk->sk_receive_queue, skb);\r\nif (copied == 0)\r\ncopied = -EFAULT;\r\nbreak;\r\n}\r\ncopied += chunk;\r\nsize -= chunk;\r\nif (!(flags & MSG_PEEK)) {\r\nskb_pull(skb, chunk);\r\nif (skb->len) {\r\nskb_queue_head(&sk->sk_receive_queue, skb);\r\nbreak;\r\n}\r\nkfree_skb(skb);\r\n} else {\r\nskb_queue_head(&sk->sk_receive_queue, skb);\r\nbreak;\r\n}\r\n} while (size);\r\ncaif_read_unlock(sk);\r\nout:\r\nreturn copied ? : err;\r\n}\r\nstatic long caif_wait_for_flow_on(struct caifsock *cf_sk,\r\nint wait_writeable, long timeo, int *err)\r\n{\r\nstruct sock *sk = &cf_sk->sk;\r\nDEFINE_WAIT(wait);\r\nfor (;;) {\r\n*err = 0;\r\nif (tx_flow_is_on(cf_sk) &&\r\n(!wait_writeable || sock_writeable(&cf_sk->sk)))\r\nbreak;\r\n*err = -ETIMEDOUT;\r\nif (!timeo)\r\nbreak;\r\n*err = -ERESTARTSYS;\r\nif (signal_pending(current))\r\nbreak;\r\nprepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);\r\n*err = -ECONNRESET;\r\nif (sk->sk_shutdown & SHUTDOWN_MASK)\r\nbreak;\r\n*err = -sk->sk_err;\r\nif (sk->sk_err)\r\nbreak;\r\n*err = -EPIPE;\r\nif (cf_sk->sk.sk_state != CAIF_CONNECTED)\r\nbreak;\r\ntimeo = schedule_timeout(timeo);\r\n}\r\nfinish_wait(sk_sleep(sk), &wait);\r\nreturn timeo;\r\n}\r\nstatic int transmit_skb(struct sk_buff *skb, struct caifsock *cf_sk,\r\nint noblock, long timeo)\r\n{\r\nstruct cfpkt *pkt;\r\npkt = cfpkt_fromnative(CAIF_DIR_OUT, skb);\r\nmemset(skb->cb, 0, sizeof(struct caif_payload_info));\r\ncfpkt_set_prio(pkt, cf_sk->sk.sk_priority);\r\nif (cf_sk->layer.dn == NULL) {\r\nkfree_skb(skb);\r\nreturn -EINVAL;\r\n}\r\nreturn cf_sk->layer.dn->transmit(cf_sk->layer.dn, pkt);\r\n}\r\nstatic int caif_seqpkt_sendmsg(struct kiocb *kiocb, struct socket *sock,\r\nstruct msghdr *msg, size_t len)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nint buffer_size;\r\nint ret = 0;\r\nstruct sk_buff *skb = NULL;\r\nint noblock;\r\nlong timeo;\r\ncaif_assert(cf_sk);\r\nret = sock_error(sk);\r\nif (ret)\r\ngoto err;\r\nret = -EOPNOTSUPP;\r\nif (msg->msg_flags&MSG_OOB)\r\ngoto err;\r\nret = -EOPNOTSUPP;\r\nif (msg->msg_namelen)\r\ngoto err;\r\nret = -EINVAL;\r\nif (unlikely(msg->msg_iov->iov_base == NULL))\r\ngoto err;\r\nnoblock = msg->msg_flags & MSG_DONTWAIT;\r\ntimeo = sock_sndtimeo(sk, noblock);\r\ntimeo = caif_wait_for_flow_on(container_of(sk, struct caifsock, sk),\r\n1, timeo, &ret);\r\nif (ret)\r\ngoto err;\r\nret = -EPIPE;\r\nif (cf_sk->sk.sk_state != CAIF_CONNECTED ||\r\nsock_flag(sk, SOCK_DEAD) ||\r\n(sk->sk_shutdown & RCV_SHUTDOWN))\r\ngoto err;\r\nret = -EMSGSIZE;\r\nif (len > cf_sk->maxframe && cf_sk->sk.sk_protocol != CAIFPROTO_RFM)\r\ngoto err;\r\nbuffer_size = len + cf_sk->headroom + cf_sk->tailroom;\r\nret = -ENOMEM;\r\nskb = sock_alloc_send_skb(sk, buffer_size, noblock, &ret);\r\nif (!skb || skb_tailroom(skb) < buffer_size)\r\ngoto err;\r\nskb_reserve(skb, cf_sk->headroom);\r\nret = memcpy_fromiovec(skb_put(skb, len), msg->msg_iov, len);\r\nif (ret)\r\ngoto err;\r\nret = transmit_skb(skb, cf_sk, noblock, timeo);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn len;\r\nerr:\r\nkfree_skb(skb);\r\nreturn ret;\r\n}\r\nstatic int caif_stream_sendmsg(struct kiocb *kiocb, struct socket *sock,\r\nstruct msghdr *msg, size_t len)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nint err, size;\r\nstruct sk_buff *skb;\r\nint sent = 0;\r\nlong timeo;\r\nerr = -EOPNOTSUPP;\r\nif (unlikely(msg->msg_flags&MSG_OOB))\r\ngoto out_err;\r\nif (unlikely(msg->msg_namelen))\r\ngoto out_err;\r\ntimeo = sock_sndtimeo(sk, msg->msg_flags & MSG_DONTWAIT);\r\ntimeo = caif_wait_for_flow_on(cf_sk, 1, timeo, &err);\r\nif (unlikely(sk->sk_shutdown & SEND_SHUTDOWN))\r\ngoto pipe_err;\r\nwhile (sent < len) {\r\nsize = len-sent;\r\nif (size > cf_sk->maxframe)\r\nsize = cf_sk->maxframe;\r\nif (size > ((sk->sk_sndbuf >> 1) - 64))\r\nsize = (sk->sk_sndbuf >> 1) - 64;\r\nif (size > SKB_MAX_ALLOC)\r\nsize = SKB_MAX_ALLOC;\r\nskb = sock_alloc_send_skb(sk,\r\nsize + cf_sk->headroom +\r\ncf_sk->tailroom,\r\nmsg->msg_flags&MSG_DONTWAIT,\r\n&err);\r\nif (skb == NULL)\r\ngoto out_err;\r\nskb_reserve(skb, cf_sk->headroom);\r\nsize = min_t(int, size, skb_tailroom(skb));\r\nerr = memcpy_fromiovec(skb_put(skb, size), msg->msg_iov, size);\r\nif (err) {\r\nkfree_skb(skb);\r\ngoto out_err;\r\n}\r\nerr = transmit_skb(skb, cf_sk,\r\nmsg->msg_flags&MSG_DONTWAIT, timeo);\r\nif (err < 0)\r\ngoto pipe_err;\r\nsent += size;\r\n}\r\nreturn sent;\r\npipe_err:\r\nif (sent == 0 && !(msg->msg_flags&MSG_NOSIGNAL))\r\nsend_sig(SIGPIPE, current, 0);\r\nerr = -EPIPE;\r\nout_err:\r\nreturn sent ? : err;\r\n}\r\nstatic int setsockopt(struct socket *sock,\r\nint lvl, int opt, char __user *ov, unsigned int ol)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nint linksel;\r\nif (cf_sk->sk.sk_socket->state != SS_UNCONNECTED)\r\nreturn -ENOPROTOOPT;\r\nswitch (opt) {\r\ncase CAIFSO_LINK_SELECT:\r\nif (ol < sizeof(int))\r\nreturn -EINVAL;\r\nif (lvl != SOL_CAIF)\r\ngoto bad_sol;\r\nif (copy_from_user(&linksel, ov, sizeof(int)))\r\nreturn -EINVAL;\r\nlock_sock(&(cf_sk->sk));\r\ncf_sk->conn_req.link_selector = linksel;\r\nrelease_sock(&cf_sk->sk);\r\nreturn 0;\r\ncase CAIFSO_REQ_PARAM:\r\nif (lvl != SOL_CAIF)\r\ngoto bad_sol;\r\nif (cf_sk->sk.sk_protocol != CAIFPROTO_UTIL)\r\nreturn -ENOPROTOOPT;\r\nlock_sock(&(cf_sk->sk));\r\nif (ol > sizeof(cf_sk->conn_req.param.data) ||\r\ncopy_from_user(&cf_sk->conn_req.param.data, ov, ol)) {\r\nrelease_sock(&cf_sk->sk);\r\nreturn -EINVAL;\r\n}\r\ncf_sk->conn_req.param.size = ol;\r\nrelease_sock(&cf_sk->sk);\r\nreturn 0;\r\ndefault:\r\nreturn -ENOPROTOOPT;\r\n}\r\nreturn 0;\r\nbad_sol:\r\nreturn -ENOPROTOOPT;\r\n}\r\nstatic int caif_connect(struct socket *sock, struct sockaddr *uaddr,\r\nint addr_len, int flags)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nlong timeo;\r\nint err;\r\nint ifindex, headroom, tailroom;\r\nunsigned int mtu;\r\nstruct net_device *dev;\r\nlock_sock(sk);\r\nerr = -EAFNOSUPPORT;\r\nif (uaddr->sa_family != AF_CAIF)\r\ngoto out;\r\nswitch (sock->state) {\r\ncase SS_UNCONNECTED:\r\ncaif_assert(sk->sk_state == CAIF_DISCONNECTED);\r\nbreak;\r\ncase SS_CONNECTING:\r\nswitch (sk->sk_state) {\r\ncase CAIF_CONNECTED:\r\nsock->state = SS_CONNECTED;\r\nerr = -EISCONN;\r\ngoto out;\r\ncase CAIF_DISCONNECTED:\r\nbreak;\r\ncase CAIF_CONNECTING:\r\nerr = -EALREADY;\r\nif (flags & O_NONBLOCK)\r\ngoto out;\r\ngoto wait_connect;\r\n}\r\nbreak;\r\ncase SS_CONNECTED:\r\ncaif_assert(sk->sk_state == CAIF_CONNECTED ||\r\nsk->sk_state == CAIF_DISCONNECTED);\r\nif (sk->sk_shutdown & SHUTDOWN_MASK) {\r\ncaif_disconnect_client(sock_net(sk), &cf_sk->layer);\r\ncaif_free_client(&cf_sk->layer);\r\nbreak;\r\n}\r\nerr = -EISCONN;\r\ngoto out;\r\ncase SS_DISCONNECTING:\r\ncase SS_FREE:\r\ncaif_assert(1);\r\nbreak;\r\n}\r\nsk->sk_state = CAIF_DISCONNECTED;\r\nsock->state = SS_UNCONNECTED;\r\nsk_stream_kill_queues(&cf_sk->sk);\r\nerr = -EINVAL;\r\nif (addr_len != sizeof(struct sockaddr_caif))\r\ngoto out;\r\nmemcpy(&cf_sk->conn_req.sockaddr, uaddr,\r\nsizeof(struct sockaddr_caif));\r\nsock->state = SS_CONNECTING;\r\nsk->sk_state = CAIF_CONNECTING;\r\nif (cf_sk->sk.sk_priority > CAIF_PRIO_MAX)\r\ncf_sk->conn_req.priority = CAIF_PRIO_MAX;\r\nelse if (cf_sk->sk.sk_priority < CAIF_PRIO_MIN)\r\ncf_sk->conn_req.priority = CAIF_PRIO_MIN;\r\nelse\r\ncf_sk->conn_req.priority = cf_sk->sk.sk_priority;\r\ncf_sk->conn_req.ifindex = cf_sk->sk.sk_bound_dev_if;\r\ncf_sk->layer.receive = caif_sktrecv_cb;\r\nerr = caif_connect_client(sock_net(sk), &cf_sk->conn_req,\r\n&cf_sk->layer, &ifindex, &headroom, &tailroom);\r\nif (err < 0) {\r\ncf_sk->sk.sk_socket->state = SS_UNCONNECTED;\r\ncf_sk->sk.sk_state = CAIF_DISCONNECTED;\r\ngoto out;\r\n}\r\nerr = -ENODEV;\r\nrcu_read_lock();\r\ndev = dev_get_by_index_rcu(sock_net(sk), ifindex);\r\nif (!dev) {\r\nrcu_read_unlock();\r\ngoto out;\r\n}\r\ncf_sk->headroom = LL_RESERVED_SPACE_EXTRA(dev, headroom);\r\nmtu = dev->mtu;\r\nrcu_read_unlock();\r\ncf_sk->tailroom = tailroom;\r\ncf_sk->maxframe = mtu - (headroom + tailroom);\r\nif (cf_sk->maxframe < 1) {\r\npr_warn("CAIF Interface MTU too small (%d)\n", dev->mtu);\r\nerr = -ENODEV;\r\ngoto out;\r\n}\r\nerr = -EINPROGRESS;\r\nwait_connect:\r\nif (sk->sk_state != CAIF_CONNECTED && (flags & O_NONBLOCK))\r\ngoto out;\r\ntimeo = sock_sndtimeo(sk, flags & O_NONBLOCK);\r\nrelease_sock(sk);\r\nerr = -ERESTARTSYS;\r\ntimeo = wait_event_interruptible_timeout(*sk_sleep(sk),\r\nsk->sk_state != CAIF_CONNECTING,\r\ntimeo);\r\nlock_sock(sk);\r\nif (timeo < 0)\r\ngoto out;\r\nerr = -ETIMEDOUT;\r\nif (timeo == 0 && sk->sk_state != CAIF_CONNECTED)\r\ngoto out;\r\nif (sk->sk_state != CAIF_CONNECTED) {\r\nsock->state = SS_UNCONNECTED;\r\nerr = sock_error(sk);\r\nif (!err)\r\nerr = -ECONNREFUSED;\r\ngoto out;\r\n}\r\nsock->state = SS_CONNECTED;\r\nerr = 0;\r\nout:\r\nrelease_sock(sk);\r\nreturn err;\r\n}\r\nstatic int caif_release(struct socket *sock)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nif (!sk)\r\nreturn 0;\r\nset_tx_flow_off(cf_sk);\r\nspin_lock_bh(&sk->sk_receive_queue.lock);\r\nsock_set_flag(sk, SOCK_DEAD);\r\nspin_unlock_bh(&sk->sk_receive_queue.lock);\r\nsock->sk = NULL;\r\nWARN_ON(IS_ERR(cf_sk->debugfs_socket_dir));\r\nif (cf_sk->debugfs_socket_dir != NULL)\r\ndebugfs_remove_recursive(cf_sk->debugfs_socket_dir);\r\nlock_sock(&(cf_sk->sk));\r\nsk->sk_state = CAIF_DISCONNECTED;\r\nsk->sk_shutdown = SHUTDOWN_MASK;\r\ncaif_disconnect_client(sock_net(sk), &cf_sk->layer);\r\ncf_sk->sk.sk_socket->state = SS_DISCONNECTING;\r\nwake_up_interruptible_poll(sk_sleep(sk), POLLERR|POLLHUP);\r\nsock_orphan(sk);\r\nsk_stream_kill_queues(&cf_sk->sk);\r\nrelease_sock(sk);\r\nsock_put(sk);\r\nreturn 0;\r\n}\r\nstatic unsigned int caif_poll(struct file *file,\r\nstruct socket *sock, poll_table *wait)\r\n{\r\nstruct sock *sk = sock->sk;\r\nunsigned int mask;\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\nsock_poll_wait(file, sk_sleep(sk), wait);\r\nmask = 0;\r\nif (sk->sk_err)\r\nmask |= POLLERR;\r\nif (sk->sk_shutdown == SHUTDOWN_MASK)\r\nmask |= POLLHUP;\r\nif (sk->sk_shutdown & RCV_SHUTDOWN)\r\nmask |= POLLRDHUP;\r\nif (!skb_queue_empty(&sk->sk_receive_queue) ||\r\n(sk->sk_shutdown & RCV_SHUTDOWN))\r\nmask |= POLLIN | POLLRDNORM;\r\nif (sock_writeable(sk) && tx_flow_is_on(cf_sk))\r\nmask |= POLLOUT | POLLWRNORM | POLLWRBAND;\r\nreturn mask;\r\n}\r\nstatic void caif_sock_destructor(struct sock *sk)\r\n{\r\nstruct caifsock *cf_sk = container_of(sk, struct caifsock, sk);\r\ncaif_assert(!atomic_read(&sk->sk_wmem_alloc));\r\ncaif_assert(sk_unhashed(sk));\r\ncaif_assert(!sk->sk_socket);\r\nif (!sock_flag(sk, SOCK_DEAD)) {\r\npr_debug("Attempt to release alive CAIF socket: %p\n", sk);\r\nreturn;\r\n}\r\nsk_stream_kill_queues(&cf_sk->sk);\r\ncaif_free_client(&cf_sk->layer);\r\n}\r\nstatic int caif_create(struct net *net, struct socket *sock, int protocol,\r\nint kern)\r\n{\r\nstruct sock *sk = NULL;\r\nstruct caifsock *cf_sk = NULL;\r\nstatic struct proto prot = {.name = "PF_CAIF",\r\n.owner = THIS_MODULE,\r\n.obj_size = sizeof(struct caifsock),\r\n};\r\nif (!capable(CAP_SYS_ADMIN) && !capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (sock->type == SOCK_SEQPACKET)\r\nsock->ops = &caif_seqpacket_ops;\r\nelse if (sock->type == SOCK_STREAM)\r\nsock->ops = &caif_stream_ops;\r\nelse\r\nreturn -ESOCKTNOSUPPORT;\r\nif (protocol < 0 || protocol >= CAIFPROTO_MAX)\r\nreturn -EPROTONOSUPPORT;\r\nsk = sk_alloc(net, PF_CAIF, GFP_KERNEL, &prot);\r\nif (!sk)\r\nreturn -ENOMEM;\r\ncf_sk = container_of(sk, struct caifsock, sk);\r\nsk->sk_protocol = (unsigned char) protocol;\r\nswitch (protocol) {\r\ncase CAIFPROTO_AT:\r\nsk->sk_priority = TC_PRIO_CONTROL;\r\nbreak;\r\ncase CAIFPROTO_RFM:\r\nsk->sk_priority = TC_PRIO_INTERACTIVE_BULK;\r\nbreak;\r\ndefault:\r\nsk->sk_priority = TC_PRIO_BESTEFFORT;\r\n}\r\nlock_sock(&(cf_sk->sk));\r\nsock_init_data(sock, sk);\r\nsk->sk_destruct = caif_sock_destructor;\r\nmutex_init(&cf_sk->readlock);\r\ncf_sk->layer.ctrlcmd = caif_ctrl_cb;\r\ncf_sk->sk.sk_socket->state = SS_UNCONNECTED;\r\ncf_sk->sk.sk_state = CAIF_DISCONNECTED;\r\nset_tx_flow_off(cf_sk);\r\nset_rx_flow_on(cf_sk);\r\ncf_sk->conn_req.link_selector = CAIF_LINK_LOW_LATENCY;\r\ncf_sk->conn_req.protocol = protocol;\r\nrelease_sock(&cf_sk->sk);\r\nreturn 0;\r\n}\r\nstatic int __init caif_sktinit_module(void)\r\n{\r\nint err = sock_register(&caif_family_ops);\r\nif (!err)\r\nreturn err;\r\nreturn 0;\r\n}\r\nstatic void __exit caif_sktexit_module(void)\r\n{\r\nsock_unregister(PF_CAIF);\r\n}
