static struct fsnotify_event *get_one_event(struct fsnotify_group *group,\r\nsize_t count)\r\n{\r\nBUG_ON(!mutex_is_locked(&group->notification_mutex));\r\npr_debug("%s: group=%p count=%zd\n", __func__, group, count);\r\nif (fsnotify_notify_queue_is_empty(group))\r\nreturn NULL;\r\nif (FAN_EVENT_METADATA_LEN > count)\r\nreturn ERR_PTR(-EINVAL);\r\nreturn fsnotify_remove_notify_event(group);\r\n}\r\nstatic int create_fd(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\nstruct file **file)\r\n{\r\nint client_fd;\r\nstruct file *new_file;\r\npr_debug("%s: group=%p event=%p\n", __func__, group, event);\r\nclient_fd = get_unused_fd();\r\nif (client_fd < 0)\r\nreturn client_fd;\r\nif (event->data_type != FSNOTIFY_EVENT_PATH) {\r\nWARN_ON(1);\r\nput_unused_fd(client_fd);\r\nreturn -EINVAL;\r\n}\r\nif (event->path.dentry && event->path.mnt)\r\nnew_file = dentry_open(&event->path,\r\ngroup->fanotify_data.f_flags | FMODE_NONOTIFY,\r\ncurrent_cred());\r\nelse\r\nnew_file = ERR_PTR(-EOVERFLOW);\r\nif (IS_ERR(new_file)) {\r\nput_unused_fd(client_fd);\r\nclient_fd = PTR_ERR(new_file);\r\n} else {\r\n*file = new_file;\r\n}\r\nreturn client_fd;\r\n}\r\nstatic int fill_event_metadata(struct fsnotify_group *group,\r\nstruct fanotify_event_metadata *metadata,\r\nstruct fsnotify_event *event,\r\nstruct file **file)\r\n{\r\nint ret = 0;\r\npr_debug("%s: group=%p metadata=%p event=%p\n", __func__,\r\ngroup, metadata, event);\r\n*file = NULL;\r\nmetadata->event_len = FAN_EVENT_METADATA_LEN;\r\nmetadata->metadata_len = FAN_EVENT_METADATA_LEN;\r\nmetadata->vers = FANOTIFY_METADATA_VERSION;\r\nmetadata->reserved = 0;\r\nmetadata->mask = event->mask & FAN_ALL_OUTGOING_EVENTS;\r\nmetadata->pid = pid_vnr(event->tgid);\r\nif (unlikely(event->mask & FAN_Q_OVERFLOW))\r\nmetadata->fd = FAN_NOFD;\r\nelse {\r\nmetadata->fd = create_fd(group, event, file);\r\nif (metadata->fd < 0)\r\nret = metadata->fd;\r\n}\r\nreturn ret;\r\n}\r\nstatic struct fanotify_response_event *dequeue_re(struct fsnotify_group *group,\r\n__s32 fd)\r\n{\r\nstruct fanotify_response_event *re, *return_re = NULL;\r\nmutex_lock(&group->fanotify_data.access_mutex);\r\nlist_for_each_entry(re, &group->fanotify_data.access_list, list) {\r\nif (re->fd != fd)\r\ncontinue;\r\nlist_del_init(&re->list);\r\nreturn_re = re;\r\nbreak;\r\n}\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\npr_debug("%s: found return_re=%p\n", __func__, return_re);\r\nreturn return_re;\r\n}\r\nstatic int process_access_response(struct fsnotify_group *group,\r\nstruct fanotify_response *response_struct)\r\n{\r\nstruct fanotify_response_event *re;\r\n__s32 fd = response_struct->fd;\r\n__u32 response = response_struct->response;\r\npr_debug("%s: group=%p fd=%d response=%d\n", __func__, group,\r\nfd, response);\r\nswitch (response) {\r\ncase FAN_ALLOW:\r\ncase FAN_DENY:\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (fd < 0)\r\nreturn -EINVAL;\r\nre = dequeue_re(group, fd);\r\nif (!re)\r\nreturn -ENOENT;\r\nre->event->response = response;\r\nwake_up(&group->fanotify_data.access_waitq);\r\nkmem_cache_free(fanotify_response_event_cache, re);\r\nreturn 0;\r\n}\r\nstatic int prepare_for_access_response(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\n__s32 fd)\r\n{\r\nstruct fanotify_response_event *re;\r\nif (!(event->mask & FAN_ALL_PERM_EVENTS))\r\nreturn 0;\r\nre = kmem_cache_alloc(fanotify_response_event_cache, GFP_KERNEL);\r\nif (!re)\r\nreturn -ENOMEM;\r\nre->event = event;\r\nre->fd = fd;\r\nmutex_lock(&group->fanotify_data.access_mutex);\r\nif (atomic_read(&group->fanotify_data.bypass_perm)) {\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\nkmem_cache_free(fanotify_response_event_cache, re);\r\nevent->response = FAN_ALLOW;\r\nreturn 0;\r\n}\r\nlist_add_tail(&re->list, &group->fanotify_data.access_list);\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\nreturn 0;\r\n}\r\nstatic int prepare_for_access_response(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\n__s32 fd)\r\n{\r\nreturn 0;\r\n}\r\nstatic ssize_t copy_event_to_user(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\nchar __user *buf)\r\n{\r\nstruct fanotify_event_metadata fanotify_event_metadata;\r\nstruct file *f;\r\nint fd, ret;\r\npr_debug("%s: group=%p event=%p\n", __func__, group, event);\r\nret = fill_event_metadata(group, &fanotify_event_metadata, event, &f);\r\nif (ret < 0)\r\ngoto out;\r\nfd = fanotify_event_metadata.fd;\r\nret = -EFAULT;\r\nif (copy_to_user(buf, &fanotify_event_metadata,\r\nfanotify_event_metadata.event_len))\r\ngoto out_close_fd;\r\nret = prepare_for_access_response(group, event, fd);\r\nif (ret)\r\ngoto out_close_fd;\r\nif (fd != FAN_NOFD)\r\nfd_install(fd, f);\r\nreturn fanotify_event_metadata.event_len;\r\nout_close_fd:\r\nif (fd != FAN_NOFD) {\r\nput_unused_fd(fd);\r\nfput(f);\r\n}\r\nout:\r\n#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS\r\nif (event->mask & FAN_ALL_PERM_EVENTS) {\r\nevent->response = FAN_DENY;\r\nwake_up(&group->fanotify_data.access_waitq);\r\n}\r\n#endif\r\nreturn ret;\r\n}\r\nstatic unsigned int fanotify_poll(struct file *file, poll_table *wait)\r\n{\r\nstruct fsnotify_group *group = file->private_data;\r\nint ret = 0;\r\npoll_wait(file, &group->notification_waitq, wait);\r\nmutex_lock(&group->notification_mutex);\r\nif (!fsnotify_notify_queue_is_empty(group))\r\nret = POLLIN | POLLRDNORM;\r\nmutex_unlock(&group->notification_mutex);\r\nreturn ret;\r\n}\r\nstatic ssize_t fanotify_read(struct file *file, char __user *buf,\r\nsize_t count, loff_t *pos)\r\n{\r\nstruct fsnotify_group *group;\r\nstruct fsnotify_event *kevent;\r\nchar __user *start;\r\nint ret;\r\nDEFINE_WAIT(wait);\r\nstart = buf;\r\ngroup = file->private_data;\r\npr_debug("%s: group=%p\n", __func__, group);\r\nwhile (1) {\r\nprepare_to_wait(&group->notification_waitq, &wait, TASK_INTERRUPTIBLE);\r\nmutex_lock(&group->notification_mutex);\r\nkevent = get_one_event(group, count);\r\nmutex_unlock(&group->notification_mutex);\r\nif (kevent) {\r\nret = PTR_ERR(kevent);\r\nif (IS_ERR(kevent))\r\nbreak;\r\nret = copy_event_to_user(group, kevent, buf);\r\nfsnotify_put_event(kevent);\r\nif (ret < 0)\r\nbreak;\r\nbuf += ret;\r\ncount -= ret;\r\ncontinue;\r\n}\r\nret = -EAGAIN;\r\nif (file->f_flags & O_NONBLOCK)\r\nbreak;\r\nret = -ERESTARTSYS;\r\nif (signal_pending(current))\r\nbreak;\r\nif (start != buf)\r\nbreak;\r\nschedule();\r\n}\r\nfinish_wait(&group->notification_waitq, &wait);\r\nif (start != buf && ret != -EFAULT)\r\nret = buf - start;\r\nreturn ret;\r\n}\r\nstatic ssize_t fanotify_write(struct file *file, const char __user *buf, size_t count, loff_t *pos)\r\n{\r\n#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS\r\nstruct fanotify_response response = { .fd = -1, .response = -1 };\r\nstruct fsnotify_group *group;\r\nint ret;\r\ngroup = file->private_data;\r\nif (count > sizeof(response))\r\ncount = sizeof(response);\r\npr_debug("%s: group=%p count=%zu\n", __func__, group, count);\r\nif (copy_from_user(&response, buf, count))\r\nreturn -EFAULT;\r\nret = process_access_response(group, &response);\r\nif (ret < 0)\r\ncount = ret;\r\nreturn count;\r\n#else\r\nreturn -EINVAL;\r\n#endif\r\n}\r\nstatic int fanotify_release(struct inode *ignored, struct file *file)\r\n{\r\nstruct fsnotify_group *group = file->private_data;\r\n#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS\r\nstruct fanotify_response_event *re, *lre;\r\nmutex_lock(&group->fanotify_data.access_mutex);\r\natomic_inc(&group->fanotify_data.bypass_perm);\r\nlist_for_each_entry_safe(re, lre, &group->fanotify_data.access_list, list) {\r\npr_debug("%s: found group=%p re=%p event=%p\n", __func__, group,\r\nre, re->event);\r\nlist_del_init(&re->list);\r\nre->event->response = FAN_ALLOW;\r\nkmem_cache_free(fanotify_response_event_cache, re);\r\n}\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\nwake_up(&group->fanotify_data.access_waitq);\r\n#endif\r\nfsnotify_destroy_group(group);\r\nreturn 0;\r\n}\r\nstatic long fanotify_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\r\n{\r\nstruct fsnotify_group *group;\r\nstruct fsnotify_event_holder *holder;\r\nvoid __user *p;\r\nint ret = -ENOTTY;\r\nsize_t send_len = 0;\r\ngroup = file->private_data;\r\np = (void __user *) arg;\r\nswitch (cmd) {\r\ncase FIONREAD:\r\nmutex_lock(&group->notification_mutex);\r\nlist_for_each_entry(holder, &group->notification_list, event_list)\r\nsend_len += FAN_EVENT_METADATA_LEN;\r\nmutex_unlock(&group->notification_mutex);\r\nret = put_user(send_len, (int __user *) p);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic void fanotify_free_mark(struct fsnotify_mark *fsn_mark)\r\n{\r\nkmem_cache_free(fanotify_mark_cache, fsn_mark);\r\n}\r\nstatic int fanotify_find_path(int dfd, const char __user *filename,\r\nstruct path *path, unsigned int flags)\r\n{\r\nint ret;\r\npr_debug("%s: dfd=%d filename=%p flags=%x\n", __func__,\r\ndfd, filename, flags);\r\nif (filename == NULL) {\r\nstruct fd f = fdget(dfd);\r\nret = -EBADF;\r\nif (!f.file)\r\ngoto out;\r\nret = -ENOTDIR;\r\nif ((flags & FAN_MARK_ONLYDIR) &&\r\n!(S_ISDIR(file_inode(f.file)->i_mode))) {\r\nfdput(f);\r\ngoto out;\r\n}\r\n*path = f.file->f_path;\r\npath_get(path);\r\nfdput(f);\r\n} else {\r\nunsigned int lookup_flags = 0;\r\nif (!(flags & FAN_MARK_DONT_FOLLOW))\r\nlookup_flags |= LOOKUP_FOLLOW;\r\nif (flags & FAN_MARK_ONLYDIR)\r\nlookup_flags |= LOOKUP_DIRECTORY;\r\nret = user_path_at(dfd, filename, lookup_flags, path);\r\nif (ret)\r\ngoto out;\r\n}\r\nret = inode_permission(path->dentry->d_inode, MAY_READ);\r\nif (ret)\r\npath_put(path);\r\nout:\r\nreturn ret;\r\n}\r\nstatic __u32 fanotify_mark_remove_from_mask(struct fsnotify_mark *fsn_mark,\r\n__u32 mask,\r\nunsigned int flags,\r\nint *destroy)\r\n{\r\n__u32 oldmask;\r\nspin_lock(&fsn_mark->lock);\r\nif (!(flags & FAN_MARK_IGNORED_MASK)) {\r\noldmask = fsn_mark->mask;\r\nfsnotify_set_mark_mask_locked(fsn_mark, (oldmask & ~mask));\r\n} else {\r\noldmask = fsn_mark->ignored_mask;\r\nfsnotify_set_mark_ignored_mask_locked(fsn_mark, (oldmask & ~mask));\r\n}\r\nspin_unlock(&fsn_mark->lock);\r\n*destroy = !(oldmask & ~mask);\r\nreturn mask & oldmask;\r\n}\r\nstatic int fanotify_remove_vfsmount_mark(struct fsnotify_group *group,\r\nstruct vfsmount *mnt, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark = NULL;\r\n__u32 removed;\r\nint destroy_mark;\r\nmutex_lock(&group->mark_mutex);\r\nfsn_mark = fsnotify_find_vfsmount_mark(group, mnt);\r\nif (!fsn_mark) {\r\nmutex_unlock(&group->mark_mutex);\r\nreturn -ENOENT;\r\n}\r\nremoved = fanotify_mark_remove_from_mask(fsn_mark, mask, flags,\r\n&destroy_mark);\r\nif (destroy_mark)\r\nfsnotify_destroy_mark_locked(fsn_mark, group);\r\nmutex_unlock(&group->mark_mutex);\r\nfsnotify_put_mark(fsn_mark);\r\nif (removed & real_mount(mnt)->mnt_fsnotify_mask)\r\nfsnotify_recalc_vfsmount_mask(mnt);\r\nreturn 0;\r\n}\r\nstatic int fanotify_remove_inode_mark(struct fsnotify_group *group,\r\nstruct inode *inode, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark = NULL;\r\n__u32 removed;\r\nint destroy_mark;\r\nmutex_lock(&group->mark_mutex);\r\nfsn_mark = fsnotify_find_inode_mark(group, inode);\r\nif (!fsn_mark) {\r\nmutex_unlock(&group->mark_mutex);\r\nreturn -ENOENT;\r\n}\r\nremoved = fanotify_mark_remove_from_mask(fsn_mark, mask, flags,\r\n&destroy_mark);\r\nif (destroy_mark)\r\nfsnotify_destroy_mark_locked(fsn_mark, group);\r\nmutex_unlock(&group->mark_mutex);\r\nfsnotify_put_mark(fsn_mark);\r\nif (removed & inode->i_fsnotify_mask)\r\nfsnotify_recalc_inode_mask(inode);\r\nreturn 0;\r\n}\r\nstatic __u32 fanotify_mark_add_to_mask(struct fsnotify_mark *fsn_mark,\r\n__u32 mask,\r\nunsigned int flags)\r\n{\r\n__u32 oldmask = -1;\r\nspin_lock(&fsn_mark->lock);\r\nif (!(flags & FAN_MARK_IGNORED_MASK)) {\r\noldmask = fsn_mark->mask;\r\nfsnotify_set_mark_mask_locked(fsn_mark, (oldmask | mask));\r\n} else {\r\n__u32 tmask = fsn_mark->ignored_mask | mask;\r\nfsnotify_set_mark_ignored_mask_locked(fsn_mark, tmask);\r\nif (flags & FAN_MARK_IGNORED_SURV_MODIFY)\r\nfsn_mark->flags |= FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY;\r\n}\r\nif (!(flags & FAN_MARK_ONDIR)) {\r\n__u32 tmask = fsn_mark->ignored_mask | FAN_ONDIR;\r\nfsnotify_set_mark_ignored_mask_locked(fsn_mark, tmask);\r\n}\r\nspin_unlock(&fsn_mark->lock);\r\nreturn mask & ~oldmask;\r\n}\r\nstatic struct fsnotify_mark *fanotify_add_new_mark(struct fsnotify_group *group,\r\nstruct inode *inode,\r\nstruct vfsmount *mnt)\r\n{\r\nstruct fsnotify_mark *mark;\r\nint ret;\r\nif (atomic_read(&group->num_marks) > group->fanotify_data.max_marks)\r\nreturn ERR_PTR(-ENOSPC);\r\nmark = kmem_cache_alloc(fanotify_mark_cache, GFP_KERNEL);\r\nif (!mark)\r\nreturn ERR_PTR(-ENOMEM);\r\nfsnotify_init_mark(mark, fanotify_free_mark);\r\nret = fsnotify_add_mark_locked(mark, group, inode, mnt, 0);\r\nif (ret) {\r\nfsnotify_put_mark(mark);\r\nreturn ERR_PTR(ret);\r\n}\r\nreturn mark;\r\n}\r\nstatic int fanotify_add_vfsmount_mark(struct fsnotify_group *group,\r\nstruct vfsmount *mnt, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark;\r\n__u32 added;\r\nmutex_lock(&group->mark_mutex);\r\nfsn_mark = fsnotify_find_vfsmount_mark(group, mnt);\r\nif (!fsn_mark) {\r\nfsn_mark = fanotify_add_new_mark(group, NULL, mnt);\r\nif (IS_ERR(fsn_mark)) {\r\nmutex_unlock(&group->mark_mutex);\r\nreturn PTR_ERR(fsn_mark);\r\n}\r\n}\r\nadded = fanotify_mark_add_to_mask(fsn_mark, mask, flags);\r\nmutex_unlock(&group->mark_mutex);\r\nif (added & ~real_mount(mnt)->mnt_fsnotify_mask)\r\nfsnotify_recalc_vfsmount_mask(mnt);\r\nfsnotify_put_mark(fsn_mark);\r\nreturn 0;\r\n}\r\nstatic int fanotify_add_inode_mark(struct fsnotify_group *group,\r\nstruct inode *inode, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark;\r\n__u32 added;\r\npr_debug("%s: group=%p inode=%p\n", __func__, group, inode);\r\nif ((flags & FAN_MARK_IGNORED_MASK) &&\r\n!(flags & FAN_MARK_IGNORED_SURV_MODIFY) &&\r\n(atomic_read(&inode->i_writecount) > 0))\r\nreturn 0;\r\nmutex_lock(&group->mark_mutex);\r\nfsn_mark = fsnotify_find_inode_mark(group, inode);\r\nif (!fsn_mark) {\r\nfsn_mark = fanotify_add_new_mark(group, inode, NULL);\r\nif (IS_ERR(fsn_mark)) {\r\nmutex_unlock(&group->mark_mutex);\r\nreturn PTR_ERR(fsn_mark);\r\n}\r\n}\r\nadded = fanotify_mark_add_to_mask(fsn_mark, mask, flags);\r\nmutex_unlock(&group->mark_mutex);\r\nif (added & ~inode->i_fsnotify_mask)\r\nfsnotify_recalc_inode_mask(inode);\r\nfsnotify_put_mark(fsn_mark);\r\nreturn 0;\r\n}\r\nstatic int __init fanotify_user_setup(void)\r\n{\r\nfanotify_mark_cache = KMEM_CACHE(fsnotify_mark, SLAB_PANIC);\r\nfanotify_response_event_cache = KMEM_CACHE(fanotify_response_event,\r\nSLAB_PANIC);\r\nreturn 0;\r\n}
