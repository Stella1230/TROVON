static u64 cvt_kvaddr(void *p)\r\n{\r\nstruct page *page;\r\nu64 paddr = 0;\r\npage = vmalloc_to_page(p);\r\nif (page)\r\npaddr = page_to_pfn(page) << PAGE_SHIFT;\r\nreturn paddr;\r\n}\r\nstatic int ipath_get_base_info(struct file *fp,\r\nvoid __user *ubase, size_t ubase_size)\r\n{\r\nstruct ipath_portdata *pd = port_fp(fp);\r\nint ret = 0;\r\nstruct ipath_base_info *kinfo = NULL;\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nunsigned subport_cnt;\r\nint shared, master;\r\nsize_t sz;\r\nsubport_cnt = pd->port_subport_cnt;\r\nif (!subport_cnt) {\r\nshared = 0;\r\nmaster = 0;\r\nsubport_cnt = 1;\r\n} else {\r\nshared = 1;\r\nmaster = !subport_fp(fp);\r\n}\r\nsz = sizeof(*kinfo);\r\nif (!shared)\r\nsz -= 7 * sizeof(u64);\r\nif (ubase_size < sz) {\r\nipath_cdbg(PROC,\r\n"Base size %zu, need %zu (version mismatch?)\n",\r\nubase_size, sz);\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nkinfo = kzalloc(sizeof(*kinfo), GFP_KERNEL);\r\nif (kinfo == NULL) {\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\nret = dd->ipath_f_get_base_info(pd, kinfo);\r\nif (ret < 0)\r\ngoto bail;\r\nkinfo->spi_rcvhdr_cnt = dd->ipath_rcvhdrcnt;\r\nkinfo->spi_rcvhdrent_size = dd->ipath_rcvhdrentsize;\r\nkinfo->spi_tidegrcnt = dd->ipath_rcvegrcnt;\r\nkinfo->spi_rcv_egrbufsize = dd->ipath_rcvegrbufsize;\r\nkinfo->spi_rcv_egrbuftotlen =\r\npd->port_rcvegrbuf_chunks * pd->port_rcvegrbuf_size;\r\nkinfo->spi_rcv_egrperchunk = pd->port_rcvegrbufs_perchunk;\r\nkinfo->spi_rcv_egrchunksize = kinfo->spi_rcv_egrbuftotlen /\r\npd->port_rcvegrbuf_chunks;\r\nkinfo->spi_tidcnt = dd->ipath_rcvtidcnt / subport_cnt;\r\nif (master)\r\nkinfo->spi_tidcnt += dd->ipath_rcvtidcnt % subport_cnt;\r\nkinfo->spi_nports = dd->ipath_cfgports;\r\nkinfo->spi_unit = dd->ipath_unit;\r\nkinfo->spi_tid_maxsize = PAGE_SIZE;\r\nkinfo->spi_rcvhdr_base = (u64) pd->port_rcvhdrq_phys;\r\nkinfo->spi_rcvhdr_tailaddr = (u64) pd->port_rcvhdrqtailaddr_phys;\r\nkinfo->spi_rcv_egrbufs = (u64) pd->port_rcvegr_phys;\r\nkinfo->spi_pioavailaddr = (u64) dd->ipath_pioavailregs_phys;\r\nkinfo->spi_status = (u64) kinfo->spi_pioavailaddr +\r\n(void *) dd->ipath_statusp -\r\n(void *) dd->ipath_pioavailregs_dma;\r\nif (!shared) {\r\nkinfo->spi_piocnt = pd->port_piocnt;\r\nkinfo->spi_piobufbase = (u64) pd->port_piobufs;\r\nkinfo->__spi_uregbase = (u64) dd->ipath_uregbase +\r\ndd->ipath_ureg_align * pd->port_port;\r\n} else if (master) {\r\nkinfo->spi_piocnt = (pd->port_piocnt / subport_cnt) +\r\n(pd->port_piocnt % subport_cnt);\r\nkinfo->spi_piobufbase = (u64) pd->port_piobufs +\r\ndd->ipath_palign *\r\n(pd->port_piocnt - kinfo->spi_piocnt);\r\n} else {\r\nunsigned slave = subport_fp(fp) - 1;\r\nkinfo->spi_piocnt = pd->port_piocnt / subport_cnt;\r\nkinfo->spi_piobufbase = (u64) pd->port_piobufs +\r\ndd->ipath_palign * kinfo->spi_piocnt * slave;\r\n}\r\nif (shared) {\r\nkinfo->spi_port_uregbase = (u64) dd->ipath_uregbase +\r\ndd->ipath_ureg_align * pd->port_port;\r\nkinfo->spi_port_rcvegrbuf = kinfo->spi_rcv_egrbufs;\r\nkinfo->spi_port_rcvhdr_base = kinfo->spi_rcvhdr_base;\r\nkinfo->spi_port_rcvhdr_tailaddr = kinfo->spi_rcvhdr_tailaddr;\r\nkinfo->__spi_uregbase = cvt_kvaddr(pd->subport_uregbase +\r\nPAGE_SIZE * subport_fp(fp));\r\nkinfo->spi_rcvhdr_base = cvt_kvaddr(pd->subport_rcvhdr_base +\r\npd->port_rcvhdrq_size * subport_fp(fp));\r\nkinfo->spi_rcvhdr_tailaddr = 0;\r\nkinfo->spi_rcv_egrbufs = cvt_kvaddr(pd->subport_rcvegrbuf +\r\npd->port_rcvegrbuf_chunks * pd->port_rcvegrbuf_size *\r\nsubport_fp(fp));\r\nkinfo->spi_subport_uregbase =\r\ncvt_kvaddr(pd->subport_uregbase);\r\nkinfo->spi_subport_rcvegrbuf =\r\ncvt_kvaddr(pd->subport_rcvegrbuf);\r\nkinfo->spi_subport_rcvhdr_base =\r\ncvt_kvaddr(pd->subport_rcvhdr_base);\r\nipath_cdbg(PROC, "port %u flags %x %llx %llx %llx\n",\r\nkinfo->spi_port, kinfo->spi_runtime_flags,\r\n(unsigned long long) kinfo->spi_subport_uregbase,\r\n(unsigned long long) kinfo->spi_subport_rcvegrbuf,\r\n(unsigned long long) kinfo->spi_subport_rcvhdr_base);\r\n}\r\nkinfo->spi_pioindex = (kinfo->spi_piobufbase -\r\n(dd->ipath_piobufbase & 0xffffffff)) / dd->ipath_palign;\r\nkinfo->spi_pioalign = dd->ipath_palign;\r\nkinfo->spi_qpair = IPATH_KD_QP;\r\nkinfo->spi_piosize = dd->ipath_piosize2k - 2 * sizeof(u32);\r\nkinfo->spi_mtu = dd->ipath_ibmaxlen;\r\nkinfo->spi_port = pd->port_port;\r\nkinfo->spi_subport = subport_fp(fp);\r\nkinfo->spi_sw_version = IPATH_KERN_SWVERSION;\r\nkinfo->spi_hw_version = dd->ipath_revision;\r\nif (master) {\r\nkinfo->spi_runtime_flags |= IPATH_RUNTIME_MASTER;\r\n}\r\nsz = (ubase_size < sizeof(*kinfo)) ? ubase_size : sizeof(*kinfo);\r\nif (copy_to_user(ubase, kinfo, sz))\r\nret = -EFAULT;\r\nbail:\r\nkfree(kinfo);\r\nreturn ret;\r\n}\r\nstatic int ipath_tid_update(struct ipath_portdata *pd, struct file *fp,\r\nconst struct ipath_tid_info *ti)\r\n{\r\nint ret = 0, ntids;\r\nu32 tid, porttid, cnt, i, tidcnt, tidoff;\r\nu16 *tidlist;\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nu64 physaddr;\r\nunsigned long vaddr;\r\nu64 __iomem *tidbase;\r\nunsigned long tidmap[8];\r\nstruct page **pagep = NULL;\r\nunsigned subport = subport_fp(fp);\r\nif (!dd->ipath_pageshadow) {\r\nret = -ENOMEM;\r\ngoto done;\r\n}\r\ncnt = ti->tidcnt;\r\nif (!cnt) {\r\nipath_dbg("After copyin, tidcnt 0, tidlist %llx\n",\r\n(unsigned long long) ti->tidlist);\r\nret = -EFAULT;\r\ngoto done;\r\n}\r\nporttid = pd->port_port * dd->ipath_rcvtidcnt;\r\nif (!pd->port_subport_cnt) {\r\ntidcnt = dd->ipath_rcvtidcnt;\r\ntid = pd->port_tidcursor;\r\ntidoff = 0;\r\n} else if (!subport) {\r\ntidcnt = (dd->ipath_rcvtidcnt / pd->port_subport_cnt) +\r\n(dd->ipath_rcvtidcnt % pd->port_subport_cnt);\r\ntidoff = dd->ipath_rcvtidcnt - tidcnt;\r\nporttid += tidoff;\r\ntid = tidcursor_fp(fp);\r\n} else {\r\ntidcnt = dd->ipath_rcvtidcnt / pd->port_subport_cnt;\r\ntidoff = tidcnt * (subport - 1);\r\nporttid += tidoff;\r\ntid = tidcursor_fp(fp);\r\n}\r\nif (cnt > tidcnt) {\r\ndev_info(&dd->pcidev->dev, "Process tried to allocate %u "\r\n"TIDs, only trying max (%u)\n", cnt, tidcnt);\r\ncnt = tidcnt;\r\n}\r\npagep = &((struct page **) pd->port_tid_pg_list)[tidoff];\r\ntidlist = &((u16 *) &pagep[dd->ipath_rcvtidcnt])[tidoff];\r\nmemset(tidmap, 0, sizeof(tidmap));\r\nntids = tidcnt;\r\ntidbase = (u64 __iomem *) (((char __iomem *) dd->ipath_kregbase) +\r\ndd->ipath_rcvtidbase +\r\nporttid * sizeof(*tidbase));\r\nipath_cdbg(VERBOSE, "Port%u %u tids, cursor %u, tidbase %p\n",\r\npd->port_port, cnt, tid, tidbase);\r\nvaddr = ti->tidvaddr;\r\nif (!access_ok(VERIFY_WRITE, (void __user *) vaddr,\r\ncnt * PAGE_SIZE)) {\r\nipath_dbg("Fail vaddr %p, %u pages, !access_ok\n",\r\n(void *)vaddr, cnt);\r\nret = -EFAULT;\r\ngoto done;\r\n}\r\nret = ipath_get_user_pages(vaddr, cnt, pagep);\r\nif (ret) {\r\nif (ret == -EBUSY) {\r\nipath_dbg("Failed to lock addr %p, %u pages "\r\n"(already locked)\n",\r\n(void *) vaddr, cnt);\r\nret = 0;\r\n} else {\r\ndev_info(&dd->pcidev->dev,\r\n"Failed to lock addr %p, %u pages: "\r\n"errno %d\n", (void *) vaddr, cnt, -ret);\r\ngoto done;\r\n}\r\n}\r\nfor (i = 0; i < cnt; i++, vaddr += PAGE_SIZE) {\r\nfor (; ntids--; tid++) {\r\nif (tid == tidcnt)\r\ntid = 0;\r\nif (!dd->ipath_pageshadow[porttid + tid])\r\nbreak;\r\n}\r\nif (ntids < 0) {\r\nipath_dbg("Not enough free TIDs for %u pages "\r\n"(index %d), failing\n", cnt, i);\r\ni--;\r\nret = -ENOMEM;\r\nbreak;\r\n}\r\ntidlist[i] = tid + tidoff;\r\nipath_cdbg(VERBOSE, "Updating idx %u to TID %u, "\r\n"vaddr %lx\n", i, tid + tidoff, vaddr);\r\ndd->ipath_pageshadow[porttid + tid] = pagep[i];\r\ndd->ipath_physshadow[porttid + tid] = ipath_map_page(\r\ndd->pcidev, pagep[i], 0, PAGE_SIZE,\r\nPCI_DMA_FROMDEVICE);\r\n__set_bit(tid, tidmap);\r\nphysaddr = dd->ipath_physshadow[porttid + tid];\r\nipath_stats.sps_pagelocks++;\r\nipath_cdbg(VERBOSE,\r\n"TID %u, vaddr %lx, physaddr %llx pgp %p\n",\r\ntid, vaddr, (unsigned long long) physaddr,\r\npagep[i]);\r\ndd->ipath_f_put_tid(dd, &tidbase[tid], RCVHQ_RCV_TYPE_EXPECTED,\r\nphysaddr);\r\ntid++;\r\n}\r\nif (ret) {\r\nu32 limit;\r\ncleanup:\r\nipath_dbg("After failure (ret=%d), undo %d of %d entries\n",\r\n-ret, i, cnt);\r\nlimit = sizeof(tidmap) * BITS_PER_BYTE;\r\nif (limit > tidcnt)\r\nlimit = tidcnt;\r\ntid = find_first_bit((const unsigned long *)tidmap, limit);\r\nfor (; tid < limit; tid++) {\r\nif (!test_bit(tid, tidmap))\r\ncontinue;\r\nif (dd->ipath_pageshadow[porttid + tid]) {\r\nipath_cdbg(VERBOSE, "Freeing TID %u\n",\r\ntid);\r\ndd->ipath_f_put_tid(dd, &tidbase[tid],\r\nRCVHQ_RCV_TYPE_EXPECTED,\r\ndd->ipath_tidinvalid);\r\npci_unmap_page(dd->pcidev,\r\ndd->ipath_physshadow[porttid + tid],\r\nPAGE_SIZE, PCI_DMA_FROMDEVICE);\r\ndd->ipath_pageshadow[porttid + tid] = NULL;\r\nipath_stats.sps_pageunlocks++;\r\n}\r\n}\r\nipath_release_user_pages(pagep, cnt);\r\n} else {\r\nif (copy_to_user((void __user *)\r\n(unsigned long) ti->tidlist,\r\ntidlist, cnt * sizeof(*tidlist))) {\r\nret = -EFAULT;\r\ngoto cleanup;\r\n}\r\nif (copy_to_user((void __user *) (unsigned long) ti->tidmap,\r\ntidmap, sizeof tidmap)) {\r\nret = -EFAULT;\r\ngoto cleanup;\r\n}\r\nif (tid == tidcnt)\r\ntid = 0;\r\nif (!pd->port_subport_cnt)\r\npd->port_tidcursor = tid;\r\nelse\r\ntidcursor_fp(fp) = tid;\r\n}\r\ndone:\r\nif (ret)\r\nipath_dbg("Failed to map %u TID pages, failing with %d\n",\r\nti->tidcnt, -ret);\r\nreturn ret;\r\n}\r\nstatic int ipath_tid_free(struct ipath_portdata *pd, unsigned subport,\r\nconst struct ipath_tid_info *ti)\r\n{\r\nint ret = 0;\r\nu32 tid, porttid, cnt, limit, tidcnt;\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nu64 __iomem *tidbase;\r\nunsigned long tidmap[8];\r\nif (!dd->ipath_pageshadow) {\r\nret = -ENOMEM;\r\ngoto done;\r\n}\r\nif (copy_from_user(tidmap, (void __user *)(unsigned long)ti->tidmap,\r\nsizeof tidmap)) {\r\nret = -EFAULT;\r\ngoto done;\r\n}\r\nporttid = pd->port_port * dd->ipath_rcvtidcnt;\r\nif (!pd->port_subport_cnt)\r\ntidcnt = dd->ipath_rcvtidcnt;\r\nelse if (!subport) {\r\ntidcnt = (dd->ipath_rcvtidcnt / pd->port_subport_cnt) +\r\n(dd->ipath_rcvtidcnt % pd->port_subport_cnt);\r\nporttid += dd->ipath_rcvtidcnt - tidcnt;\r\n} else {\r\ntidcnt = dd->ipath_rcvtidcnt / pd->port_subport_cnt;\r\nporttid += tidcnt * (subport - 1);\r\n}\r\ntidbase = (u64 __iomem *) ((char __iomem *)(dd->ipath_kregbase) +\r\ndd->ipath_rcvtidbase +\r\nporttid * sizeof(*tidbase));\r\nlimit = sizeof(tidmap) * BITS_PER_BYTE;\r\nif (limit > tidcnt)\r\nlimit = tidcnt;\r\ntid = find_first_bit(tidmap, limit);\r\nipath_cdbg(VERBOSE, "Port%u free %u tids; first bit (max=%d) "\r\n"set is %d, porttid %u\n", pd->port_port, ti->tidcnt,\r\nlimit, tid, porttid);\r\nfor (cnt = 0; tid < limit; tid++) {\r\nif (!test_bit(tid, tidmap))\r\ncontinue;\r\ncnt++;\r\nif (dd->ipath_pageshadow[porttid + tid]) {\r\nstruct page *p;\r\np = dd->ipath_pageshadow[porttid + tid];\r\ndd->ipath_pageshadow[porttid + tid] = NULL;\r\nipath_cdbg(VERBOSE, "PID %u freeing TID %u\n",\r\npid_nr(pd->port_pid), tid);\r\ndd->ipath_f_put_tid(dd, &tidbase[tid],\r\nRCVHQ_RCV_TYPE_EXPECTED,\r\ndd->ipath_tidinvalid);\r\npci_unmap_page(dd->pcidev,\r\ndd->ipath_physshadow[porttid + tid],\r\nPAGE_SIZE, PCI_DMA_FROMDEVICE);\r\nipath_release_user_pages(&p, 1);\r\nipath_stats.sps_pageunlocks++;\r\n} else\r\nipath_dbg("Unused tid %u, ignoring\n", tid);\r\n}\r\nif (cnt != ti->tidcnt)\r\nipath_dbg("passed in tidcnt %d, only %d bits set in map\n",\r\nti->tidcnt, cnt);\r\ndone:\r\nif (ret)\r\nipath_dbg("Failed to unmap %u TID pages, failing with %d\n",\r\nti->tidcnt, -ret);\r\nreturn ret;\r\n}\r\nstatic int ipath_set_part_key(struct ipath_portdata *pd, u16 key)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nint i, any = 0, pidx = -1;\r\nu16 lkey = key & 0x7FFF;\r\nint ret;\r\nif (lkey == (IPATH_DEFAULT_P_KEY & 0x7FFF)) {\r\nret = 0;\r\ngoto bail;\r\n}\r\nipath_cdbg(VERBOSE, "p%u try to set pkey %hx, current keys "\r\n"%hx:%x %hx:%x %hx:%x %hx:%x\n",\r\npd->port_port, key, dd->ipath_pkeys[0],\r\natomic_read(&dd->ipath_pkeyrefs[0]), dd->ipath_pkeys[1],\r\natomic_read(&dd->ipath_pkeyrefs[1]), dd->ipath_pkeys[2],\r\natomic_read(&dd->ipath_pkeyrefs[2]), dd->ipath_pkeys[3],\r\natomic_read(&dd->ipath_pkeyrefs[3]));\r\nif (!lkey) {\r\nipath_cdbg(PROC, "p%u tries to set key 0, not allowed\n",\r\npd->port_port);\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nkey |= 0x8000;\r\nfor (i = 0; i < ARRAY_SIZE(pd->port_pkeys); i++) {\r\nif (!pd->port_pkeys[i] && pidx == -1)\r\npidx = i;\r\nif (pd->port_pkeys[i] == key) {\r\nipath_cdbg(VERBOSE, "p%u tries to set same pkey "\r\n"(%x) more than once\n",\r\npd->port_port, key);\r\nret = -EEXIST;\r\ngoto bail;\r\n}\r\n}\r\nif (pidx == -1) {\r\nipath_dbg("All pkeys for port %u already in use, "\r\n"can't set %x\n", pd->port_port, key);\r\nret = -EBUSY;\r\ngoto bail;\r\n}\r\nfor (any = i = 0; i < ARRAY_SIZE(dd->ipath_pkeys); i++) {\r\nif (!dd->ipath_pkeys[i]) {\r\nany++;\r\ncontinue;\r\n}\r\nif (dd->ipath_pkeys[i] == key) {\r\natomic_t *pkrefs = &dd->ipath_pkeyrefs[i];\r\nif (atomic_inc_return(pkrefs) > 1) {\r\npd->port_pkeys[pidx] = key;\r\nipath_cdbg(VERBOSE, "p%u set key %x "\r\n"matches #%d, count now %d\n",\r\npd->port_port, key, i,\r\natomic_read(pkrefs));\r\nret = 0;\r\ngoto bail;\r\n} else {\r\natomic_dec(pkrefs);\r\nipath_cdbg(VERBOSE, "Lost race, count was "\r\n"0, after dec, it's %d\n",\r\natomic_read(pkrefs));\r\nany++;\r\n}\r\n}\r\nif ((dd->ipath_pkeys[i] & 0x7FFF) == lkey) {\r\nret = -EEXIST;\r\ngoto bail;\r\n}\r\n}\r\nif (!any) {\r\nipath_dbg("port %u, all pkeys already in use, "\r\n"can't set %x\n", pd->port_port, key);\r\nret = -EBUSY;\r\ngoto bail;\r\n}\r\nfor (any = i = 0; i < ARRAY_SIZE(dd->ipath_pkeys); i++) {\r\nif (!dd->ipath_pkeys[i] &&\r\natomic_inc_return(&dd->ipath_pkeyrefs[i]) == 1) {\r\nu64 pkey;\r\nipath_stats.sps_pkeys[i] = lkey;\r\npd->port_pkeys[pidx] = dd->ipath_pkeys[i] = key;\r\npkey =\r\n(u64) dd->ipath_pkeys[0] |\r\n((u64) dd->ipath_pkeys[1] << 16) |\r\n((u64) dd->ipath_pkeys[2] << 32) |\r\n((u64) dd->ipath_pkeys[3] << 48);\r\nipath_cdbg(PROC, "p%u set key %x in #%d, "\r\n"portidx %d, new pkey reg %llx\n",\r\npd->port_port, key, i, pidx,\r\n(unsigned long long) pkey);\r\nipath_write_kreg(\r\ndd, dd->ipath_kregs->kr_partitionkey, pkey);\r\nret = 0;\r\ngoto bail;\r\n}\r\n}\r\nipath_dbg("port %u, all pkeys already in use 2nd pass, "\r\n"can't set %x\n", pd->port_port, key);\r\nret = -EBUSY;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int ipath_manage_rcvq(struct ipath_portdata *pd, unsigned subport,\r\nint start_stop)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nipath_cdbg(PROC, "%sabling rcv for unit %u port %u:%u\n",\r\nstart_stop ? "en" : "dis", dd->ipath_unit,\r\npd->port_port, subport);\r\nif (subport)\r\ngoto bail;\r\nif (start_stop) {\r\nif (pd->port_rcvhdrtail_kvaddr)\r\nipath_clear_rcvhdrtail(pd);\r\nset_bit(dd->ipath_r_portenable_shift + pd->port_port,\r\n&dd->ipath_rcvctrl);\r\n} else\r\nclear_bit(dd->ipath_r_portenable_shift + pd->port_port,\r\n&dd->ipath_rcvctrl);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_rcvctrl,\r\ndd->ipath_rcvctrl);\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\nif (start_stop) {\r\nipath_read_ureg32(dd, ur_rcvhdrtail, pd->port_port);\r\n}\r\nbail:\r\nreturn 0;\r\n}\r\nstatic void ipath_clean_part_key(struct ipath_portdata *pd,\r\nstruct ipath_devdata *dd)\r\n{\r\nint i, j, pchanged = 0;\r\nu64 oldpkey;\r\noldpkey = (u64) dd->ipath_pkeys[0] |\r\n((u64) dd->ipath_pkeys[1] << 16) |\r\n((u64) dd->ipath_pkeys[2] << 32) |\r\n((u64) dd->ipath_pkeys[3] << 48);\r\nfor (i = 0; i < ARRAY_SIZE(pd->port_pkeys); i++) {\r\nif (!pd->port_pkeys[i])\r\ncontinue;\r\nipath_cdbg(VERBOSE, "look for key[%d] %hx in pkeys\n", i,\r\npd->port_pkeys[i]);\r\nfor (j = 0; j < ARRAY_SIZE(dd->ipath_pkeys); j++) {\r\nif ((dd->ipath_pkeys[j] & 0x7fff) !=\r\n(pd->port_pkeys[i] & 0x7fff))\r\ncontinue;\r\nif (atomic_dec_and_test(&dd->ipath_pkeyrefs[j])) {\r\nipath_cdbg(VERBOSE, "p%u clear key "\r\n"%x matches #%d\n",\r\npd->port_port,\r\npd->port_pkeys[i], j);\r\nipath_stats.sps_pkeys[j] =\r\ndd->ipath_pkeys[j] = 0;\r\npchanged++;\r\n}\r\nelse ipath_cdbg(\r\nVERBOSE, "p%u key %x matches #%d, "\r\n"but ref still %d\n", pd->port_port,\r\npd->port_pkeys[i], j,\r\natomic_read(&dd->ipath_pkeyrefs[j]));\r\nbreak;\r\n}\r\npd->port_pkeys[i] = 0;\r\n}\r\nif (pchanged) {\r\nu64 pkey = (u64) dd->ipath_pkeys[0] |\r\n((u64) dd->ipath_pkeys[1] << 16) |\r\n((u64) dd->ipath_pkeys[2] << 32) |\r\n((u64) dd->ipath_pkeys[3] << 48);\r\nipath_cdbg(VERBOSE, "p%u old pkey reg %llx, "\r\n"new pkey reg %llx\n", pd->port_port,\r\n(unsigned long long) oldpkey,\r\n(unsigned long long) pkey);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_partitionkey,\r\npkey);\r\n}\r\n}\r\nstatic void init_user_egr_sizes(struct ipath_portdata *pd)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nunsigned egrperchunk, egrcnt, size;\r\nsize = 0x8000;\r\negrperchunk = size / dd->ipath_rcvegrbufsize;\r\negrcnt = dd->ipath_rcvegrcnt;\r\npd->port_rcvegrbuf_chunks = (egrcnt + egrperchunk - 1) / egrperchunk;\r\npd->port_rcvegrbufs_perchunk = egrperchunk;\r\npd->port_rcvegrbuf_size = size;\r\n}\r\nstatic int ipath_create_user_egr(struct ipath_portdata *pd)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nunsigned e, egrcnt, egrperchunk, chunk, egrsize, egroff;\r\nsize_t size;\r\nint ret;\r\ngfp_t gfp_flags;\r\ngfp_flags = __GFP_WAIT | __GFP_IO | __GFP_COMP;\r\negrcnt = dd->ipath_rcvegrcnt;\r\negroff = (pd->port_port - 1) * egrcnt + dd->ipath_p0_rcvegrcnt;\r\negrsize = dd->ipath_rcvegrbufsize;\r\nipath_cdbg(VERBOSE, "Allocating %d egr buffers, at egrtid "\r\n"offset %x, egrsize %u\n", egrcnt, egroff, egrsize);\r\nchunk = pd->port_rcvegrbuf_chunks;\r\negrperchunk = pd->port_rcvegrbufs_perchunk;\r\nsize = pd->port_rcvegrbuf_size;\r\npd->port_rcvegrbuf = kmalloc(chunk * sizeof(pd->port_rcvegrbuf[0]),\r\nGFP_KERNEL);\r\nif (!pd->port_rcvegrbuf) {\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\npd->port_rcvegrbuf_phys =\r\nkmalloc(chunk * sizeof(pd->port_rcvegrbuf_phys[0]),\r\nGFP_KERNEL);\r\nif (!pd->port_rcvegrbuf_phys) {\r\nret = -ENOMEM;\r\ngoto bail_rcvegrbuf;\r\n}\r\nfor (e = 0; e < pd->port_rcvegrbuf_chunks; e++) {\r\npd->port_rcvegrbuf[e] = dma_alloc_coherent(\r\n&dd->pcidev->dev, size, &pd->port_rcvegrbuf_phys[e],\r\ngfp_flags);\r\nif (!pd->port_rcvegrbuf[e]) {\r\nret = -ENOMEM;\r\ngoto bail_rcvegrbuf_phys;\r\n}\r\n}\r\npd->port_rcvegr_phys = pd->port_rcvegrbuf_phys[0];\r\nfor (e = chunk = 0; chunk < pd->port_rcvegrbuf_chunks; chunk++) {\r\ndma_addr_t pa = pd->port_rcvegrbuf_phys[chunk];\r\nunsigned i;\r\nfor (i = 0; e < egrcnt && i < egrperchunk; e++, i++) {\r\ndd->ipath_f_put_tid(dd, e + egroff +\r\n(u64 __iomem *)\r\n((char __iomem *)\r\ndd->ipath_kregbase +\r\ndd->ipath_rcvegrbase),\r\nRCVHQ_RCV_TYPE_EAGER, pa);\r\npa += egrsize;\r\n}\r\ncond_resched();\r\n}\r\nret = 0;\r\ngoto bail;\r\nbail_rcvegrbuf_phys:\r\nfor (e = 0; e < pd->port_rcvegrbuf_chunks &&\r\npd->port_rcvegrbuf[e]; e++) {\r\ndma_free_coherent(&dd->pcidev->dev, size,\r\npd->port_rcvegrbuf[e],\r\npd->port_rcvegrbuf_phys[e]);\r\n}\r\nkfree(pd->port_rcvegrbuf_phys);\r\npd->port_rcvegrbuf_phys = NULL;\r\nbail_rcvegrbuf:\r\nkfree(pd->port_rcvegrbuf);\r\npd->port_rcvegrbuf = NULL;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int ipath_mmap_mem(struct vm_area_struct *vma,\r\nstruct ipath_portdata *pd, unsigned len, int write_ok,\r\nvoid *kvaddr, char *what)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nunsigned long pfn;\r\nint ret;\r\nif ((vma->vm_end - vma->vm_start) > len) {\r\ndev_info(&dd->pcidev->dev,\r\n"FAIL on %s: len %lx > %x\n", what,\r\nvma->vm_end - vma->vm_start, len);\r\nret = -EFAULT;\r\ngoto bail;\r\n}\r\nif (!write_ok) {\r\nif (vma->vm_flags & VM_WRITE) {\r\ndev_info(&dd->pcidev->dev,\r\n"%s must be mapped readonly\n", what);\r\nret = -EPERM;\r\ngoto bail;\r\n}\r\nvma->vm_flags &= ~VM_MAYWRITE;\r\n}\r\npfn = virt_to_phys(kvaddr) >> PAGE_SHIFT;\r\nret = remap_pfn_range(vma, vma->vm_start, pfn,\r\nlen, vma->vm_page_prot);\r\nif (ret)\r\ndev_info(&dd->pcidev->dev, "%s port%u mmap of %lx, %x "\r\n"bytes r%c failed: %d\n", what, pd->port_port,\r\npfn, len, write_ok?'w':'o', ret);\r\nelse\r\nipath_cdbg(VERBOSE, "%s port%u mmaped %lx, %x bytes "\r\n"r%c\n", what, pd->port_port, pfn, len,\r\nwrite_ok?'w':'o');\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int mmap_ureg(struct vm_area_struct *vma, struct ipath_devdata *dd,\r\nu64 ureg)\r\n{\r\nunsigned long phys;\r\nint ret;\r\nif ((vma->vm_end - vma->vm_start) > PAGE_SIZE) {\r\ndev_info(&dd->pcidev->dev, "FAIL mmap userreg: reqlen "\r\n"%lx > PAGE\n", vma->vm_end - vma->vm_start);\r\nret = -EFAULT;\r\n} else {\r\nphys = dd->ipath_physaddr + ureg;\r\nvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\r\nvma->vm_flags |= VM_DONTCOPY | VM_DONTEXPAND;\r\nret = io_remap_pfn_range(vma, vma->vm_start,\r\nphys >> PAGE_SHIFT,\r\nvma->vm_end - vma->vm_start,\r\nvma->vm_page_prot);\r\n}\r\nreturn ret;\r\n}\r\nstatic int mmap_piobufs(struct vm_area_struct *vma,\r\nstruct ipath_devdata *dd,\r\nstruct ipath_portdata *pd,\r\nunsigned piobufs, unsigned piocnt)\r\n{\r\nunsigned long phys;\r\nint ret;\r\nif ((vma->vm_end - vma->vm_start) > (piocnt * dd->ipath_palign)) {\r\ndev_info(&dd->pcidev->dev, "FAIL mmap piobufs: "\r\n"reqlen %lx > PAGE\n",\r\nvma->vm_end - vma->vm_start);\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nphys = dd->ipath_physaddr + piobufs;\r\n#if defined(__powerpc__)\r\npgprot_val(vma->vm_page_prot) |= _PAGE_NO_CACHE;\r\npgprot_val(vma->vm_page_prot) |= _PAGE_WRITETHRU;\r\npgprot_val(vma->vm_page_prot) &= ~_PAGE_GUARDED;\r\n#endif\r\nvma->vm_flags &= ~VM_MAYREAD;\r\nvma->vm_flags |= VM_DONTCOPY | VM_DONTEXPAND;\r\nret = io_remap_pfn_range(vma, vma->vm_start, phys >> PAGE_SHIFT,\r\nvma->vm_end - vma->vm_start,\r\nvma->vm_page_prot);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int mmap_rcvegrbufs(struct vm_area_struct *vma,\r\nstruct ipath_portdata *pd)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nunsigned long start, size;\r\nsize_t total_size, i;\r\nunsigned long pfn;\r\nint ret;\r\nsize = pd->port_rcvegrbuf_size;\r\ntotal_size = pd->port_rcvegrbuf_chunks * size;\r\nif ((vma->vm_end - vma->vm_start) > total_size) {\r\ndev_info(&dd->pcidev->dev, "FAIL on egr bufs: "\r\n"reqlen %lx > actual %lx\n",\r\nvma->vm_end - vma->vm_start,\r\n(unsigned long) total_size);\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nif (vma->vm_flags & VM_WRITE) {\r\ndev_info(&dd->pcidev->dev, "Can't map eager buffers as "\r\n"writable (flags=%lx)\n", vma->vm_flags);\r\nret = -EPERM;\r\ngoto bail;\r\n}\r\nvma->vm_flags &= ~VM_MAYWRITE;\r\nstart = vma->vm_start;\r\nfor (i = 0; i < pd->port_rcvegrbuf_chunks; i++, start += size) {\r\npfn = virt_to_phys(pd->port_rcvegrbuf[i]) >> PAGE_SHIFT;\r\nret = remap_pfn_range(vma, start, pfn, size,\r\nvma->vm_page_prot);\r\nif (ret < 0)\r\ngoto bail;\r\n}\r\nret = 0;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int ipath_file_vma_fault(struct vm_area_struct *vma,\r\nstruct vm_fault *vmf)\r\n{\r\nstruct page *page;\r\npage = vmalloc_to_page((void *)(vmf->pgoff << PAGE_SHIFT));\r\nif (!page)\r\nreturn VM_FAULT_SIGBUS;\r\nget_page(page);\r\nvmf->page = page;\r\nreturn 0;\r\n}\r\nstatic int mmap_kvaddr(struct vm_area_struct *vma, u64 pgaddr,\r\nstruct ipath_portdata *pd, unsigned subport)\r\n{\r\nunsigned long len;\r\nstruct ipath_devdata *dd;\r\nvoid *addr;\r\nsize_t size;\r\nint ret = 0;\r\nif (!pd->port_subport_cnt)\r\ngoto bail;\r\ndd = pd->port_dd;\r\nsize = pd->port_rcvegrbuf_chunks * pd->port_rcvegrbuf_size;\r\nif (pgaddr == cvt_kvaddr(pd->subport_uregbase)) {\r\naddr = pd->subport_uregbase;\r\nsize = PAGE_SIZE * pd->port_subport_cnt;\r\n} else if (pgaddr == cvt_kvaddr(pd->subport_rcvhdr_base)) {\r\naddr = pd->subport_rcvhdr_base;\r\nsize = pd->port_rcvhdrq_size * pd->port_subport_cnt;\r\n} else if (pgaddr == cvt_kvaddr(pd->subport_rcvegrbuf)) {\r\naddr = pd->subport_rcvegrbuf;\r\nsize *= pd->port_subport_cnt;\r\n} else if (pgaddr == cvt_kvaddr(pd->subport_uregbase +\r\nPAGE_SIZE * subport)) {\r\naddr = pd->subport_uregbase + PAGE_SIZE * subport;\r\nsize = PAGE_SIZE;\r\n} else if (pgaddr == cvt_kvaddr(pd->subport_rcvhdr_base +\r\npd->port_rcvhdrq_size * subport)) {\r\naddr = pd->subport_rcvhdr_base +\r\npd->port_rcvhdrq_size * subport;\r\nsize = pd->port_rcvhdrq_size;\r\n} else if (pgaddr == cvt_kvaddr(pd->subport_rcvegrbuf +\r\nsize * subport)) {\r\naddr = pd->subport_rcvegrbuf + size * subport;\r\nif (vma->vm_flags & VM_WRITE) {\r\ndev_info(&dd->pcidev->dev,\r\n"Can't map eager buffers as "\r\n"writable (flags=%lx)\n", vma->vm_flags);\r\nret = -EPERM;\r\ngoto bail;\r\n}\r\nvma->vm_flags &= ~VM_MAYWRITE;\r\n} else {\r\ngoto bail;\r\n}\r\nlen = vma->vm_end - vma->vm_start;\r\nif (len > size) {\r\nipath_cdbg(MM, "FAIL: reqlen %lx > %zx\n", len, size);\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nvma->vm_pgoff = (unsigned long) addr >> PAGE_SHIFT;\r\nvma->vm_ops = &ipath_file_vm_ops;\r\nvma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;\r\nret = 1;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int ipath_mmap(struct file *fp, struct vm_area_struct *vma)\r\n{\r\nstruct ipath_portdata *pd;\r\nstruct ipath_devdata *dd;\r\nu64 pgaddr, ureg;\r\nunsigned piobufs, piocnt;\r\nint ret;\r\npd = port_fp(fp);\r\nif (!pd) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\ndd = pd->port_dd;\r\npgaddr = vma->vm_pgoff << PAGE_SHIFT;\r\nif (!pgaddr) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nipath_cdbg(MM, "pgaddr %llx vm_start=%lx len %lx port %u:%u:%u\n",\r\n(unsigned long long) pgaddr, vma->vm_start,\r\nvma->vm_end - vma->vm_start, dd->ipath_unit,\r\npd->port_port, subport_fp(fp));\r\nret = mmap_kvaddr(vma, pgaddr, pd, subport_fp(fp));\r\nif (ret) {\r\nif (ret > 0)\r\nret = 0;\r\ngoto bail;\r\n}\r\nureg = dd->ipath_uregbase + dd->ipath_ureg_align * pd->port_port;\r\nif (!pd->port_subport_cnt) {\r\npiocnt = pd->port_piocnt;\r\npiobufs = pd->port_piobufs;\r\n} else if (!subport_fp(fp)) {\r\npiocnt = (pd->port_piocnt / pd->port_subport_cnt) +\r\n(pd->port_piocnt % pd->port_subport_cnt);\r\npiobufs = pd->port_piobufs +\r\ndd->ipath_palign * (pd->port_piocnt - piocnt);\r\n} else {\r\nunsigned slave = subport_fp(fp) - 1;\r\npiocnt = pd->port_piocnt / pd->port_subport_cnt;\r\npiobufs = pd->port_piobufs + dd->ipath_palign * piocnt * slave;\r\n}\r\nif (pgaddr == ureg)\r\nret = mmap_ureg(vma, dd, ureg);\r\nelse if (pgaddr == piobufs)\r\nret = mmap_piobufs(vma, dd, pd, piobufs, piocnt);\r\nelse if (pgaddr == dd->ipath_pioavailregs_phys)\r\nret = ipath_mmap_mem(vma, pd, PAGE_SIZE, 0,\r\n(void *) dd->ipath_pioavailregs_dma,\r\n"pioavail registers");\r\nelse if (pgaddr == pd->port_rcvegr_phys)\r\nret = mmap_rcvegrbufs(vma, pd);\r\nelse if (pgaddr == (u64) pd->port_rcvhdrq_phys)\r\nret = ipath_mmap_mem(vma, pd, pd->port_rcvhdrq_size, 1,\r\npd->port_rcvhdrq,\r\n"rcvhdrq");\r\nelse if (pgaddr == (u64) pd->port_rcvhdrqtailaddr_phys)\r\nret = ipath_mmap_mem(vma, pd, PAGE_SIZE, 0,\r\npd->port_rcvhdrtail_kvaddr,\r\n"rcvhdrq tail");\r\nelse\r\nret = -EINVAL;\r\nvma->vm_private_data = NULL;\r\nif (ret < 0)\r\ndev_info(&dd->pcidev->dev,\r\n"Failure %d on off %llx len %lx\n",\r\n-ret, (unsigned long long)pgaddr,\r\nvma->vm_end - vma->vm_start);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic unsigned ipath_poll_hdrqfull(struct ipath_portdata *pd)\r\n{\r\nunsigned pollflag = 0;\r\nif ((pd->poll_type & IPATH_POLL_TYPE_OVERFLOW) &&\r\npd->port_hdrqfull != pd->port_hdrqfull_poll) {\r\npollflag |= POLLIN | POLLRDNORM;\r\npd->port_hdrqfull_poll = pd->port_hdrqfull;\r\n}\r\nreturn pollflag;\r\n}\r\nstatic unsigned int ipath_poll_urgent(struct ipath_portdata *pd,\r\nstruct file *fp,\r\nstruct poll_table_struct *pt)\r\n{\r\nunsigned pollflag = 0;\r\nstruct ipath_devdata *dd;\r\ndd = pd->port_dd;\r\nrmb();\r\npollflag = ipath_poll_hdrqfull(pd);\r\nif (pd->port_urgent != pd->port_urgent_poll) {\r\npollflag |= POLLIN | POLLRDNORM;\r\npd->port_urgent_poll = pd->port_urgent;\r\n}\r\nif (!pollflag) {\r\nset_bit(IPATH_PORT_WAITING_URG, &pd->port_flag);\r\nwmb();\r\npoll_wait(fp, &pd->port_wait, pt);\r\n}\r\nreturn pollflag;\r\n}\r\nstatic unsigned int ipath_poll_next(struct ipath_portdata *pd,\r\nstruct file *fp,\r\nstruct poll_table_struct *pt)\r\n{\r\nu32 head;\r\nu32 tail;\r\nunsigned pollflag = 0;\r\nstruct ipath_devdata *dd;\r\ndd = pd->port_dd;\r\nrmb();\r\npollflag = ipath_poll_hdrqfull(pd);\r\nhead = ipath_read_ureg32(dd, ur_rcvhdrhead, pd->port_port);\r\nif (pd->port_rcvhdrtail_kvaddr)\r\ntail = ipath_get_rcvhdrtail(pd);\r\nelse\r\ntail = ipath_read_ureg32(dd, ur_rcvhdrtail, pd->port_port);\r\nif (head != tail)\r\npollflag |= POLLIN | POLLRDNORM;\r\nelse {\r\nset_bit(IPATH_PORT_WAITING_RCV, &pd->port_flag);\r\nwmb();\r\nset_bit(pd->port_port + dd->ipath_r_intravail_shift,\r\n&dd->ipath_rcvctrl);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_rcvctrl,\r\ndd->ipath_rcvctrl);\r\nif (dd->ipath_rhdrhead_intr_off)\r\nipath_write_ureg(dd, ur_rcvhdrhead,\r\ndd->ipath_rhdrhead_intr_off | head,\r\npd->port_port);\r\npoll_wait(fp, &pd->port_wait, pt);\r\n}\r\nreturn pollflag;\r\n}\r\nstatic unsigned int ipath_poll(struct file *fp,\r\nstruct poll_table_struct *pt)\r\n{\r\nstruct ipath_portdata *pd;\r\nunsigned pollflag;\r\npd = port_fp(fp);\r\nif (!pd)\r\npollflag = 0;\r\nelse if (pd->poll_type & IPATH_POLL_TYPE_URGENT)\r\npollflag = ipath_poll_urgent(pd, fp, pt);\r\nelse\r\npollflag = ipath_poll_next(pd, fp, pt);\r\nreturn pollflag;\r\n}\r\nstatic int ipath_supports_subports(int user_swmajor, int user_swminor)\r\n{\r\nreturn (user_swmajor > 1) || (user_swminor >= 3);\r\n}\r\nstatic int ipath_compatible_subports(int user_swmajor, int user_swminor)\r\n{\r\nif (IPATH_USER_SWMAJOR != user_swmajor) {\r\nreturn 0;\r\n}\r\nif (IPATH_USER_SWMAJOR == 1) {\r\nswitch (IPATH_USER_SWMINOR) {\r\ncase 0:\r\ncase 1:\r\ncase 2:\r\nreturn 0;\r\ncase 3:\r\nreturn user_swminor == 3;\r\ndefault:\r\nreturn user_swminor >= 4;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int init_subports(struct ipath_devdata *dd,\r\nstruct ipath_portdata *pd,\r\nconst struct ipath_user_info *uinfo)\r\n{\r\nint ret = 0;\r\nunsigned num_subports;\r\nsize_t size;\r\nif (uinfo->spu_subport_cnt <= 0)\r\ngoto bail;\r\nif (ipath_supports_subports(IPATH_USER_SWMAJOR, IPATH_USER_SWMINOR) &&\r\n!ipath_compatible_subports(IPATH_USER_SWMAJOR,\r\nIPATH_USER_SWMINOR)) {\r\ndev_info(&dd->pcidev->dev,\r\n"Inconsistent ipath_compatible_subports()\n");\r\ngoto bail;\r\n}\r\nif (!ipath_compatible_subports(uinfo->spu_userversion >> 16,\r\nuinfo->spu_userversion & 0xffff)) {\r\ndev_info(&dd->pcidev->dev,\r\n"Mismatched user version (%d.%d) and driver "\r\n"version (%d.%d) while port sharing. Ensure "\r\n"that driver and library are from the same "\r\n"release.\n",\r\n(int) (uinfo->spu_userversion >> 16),\r\n(int) (uinfo->spu_userversion & 0xffff),\r\nIPATH_USER_SWMAJOR,\r\nIPATH_USER_SWMINOR);\r\ngoto bail;\r\n}\r\nif (uinfo->spu_subport_cnt > INFINIPATH_MAX_SUBPORT) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nnum_subports = uinfo->spu_subport_cnt;\r\npd->subport_uregbase = vzalloc(PAGE_SIZE * num_subports);\r\nif (!pd->subport_uregbase) {\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\nsize = ALIGN(dd->ipath_rcvhdrcnt * dd->ipath_rcvhdrentsize *\r\nsizeof(u32), PAGE_SIZE) * num_subports;\r\npd->subport_rcvhdr_base = vzalloc(size);\r\nif (!pd->subport_rcvhdr_base) {\r\nret = -ENOMEM;\r\ngoto bail_ureg;\r\n}\r\npd->subport_rcvegrbuf = vzalloc(pd->port_rcvegrbuf_chunks *\r\npd->port_rcvegrbuf_size *\r\nnum_subports);\r\nif (!pd->subport_rcvegrbuf) {\r\nret = -ENOMEM;\r\ngoto bail_rhdr;\r\n}\r\npd->port_subport_cnt = uinfo->spu_subport_cnt;\r\npd->port_subport_id = uinfo->spu_subport_id;\r\npd->active_slaves = 1;\r\nset_bit(IPATH_PORT_MASTER_UNINIT, &pd->port_flag);\r\ngoto bail;\r\nbail_rhdr:\r\nvfree(pd->subport_rcvhdr_base);\r\nbail_ureg:\r\nvfree(pd->subport_uregbase);\r\npd->subport_uregbase = NULL;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int try_alloc_port(struct ipath_devdata *dd, int port,\r\nstruct file *fp,\r\nconst struct ipath_user_info *uinfo)\r\n{\r\nstruct ipath_portdata *pd;\r\nint ret;\r\nif (!(pd = dd->ipath_pd[port])) {\r\nvoid *ptmp;\r\npd = kzalloc(sizeof(struct ipath_portdata), GFP_KERNEL);\r\nptmp = kmalloc(dd->ipath_rcvtidcnt * sizeof(u16) +\r\ndd->ipath_rcvtidcnt * sizeof(struct page **),\r\nGFP_KERNEL);\r\nif (!pd || !ptmp) {\r\nipath_dev_err(dd, "Unable to allocate portdata "\r\n"memory, failing open\n");\r\nret = -ENOMEM;\r\nkfree(pd);\r\nkfree(ptmp);\r\ngoto bail;\r\n}\r\ndd->ipath_pd[port] = pd;\r\ndd->ipath_pd[port]->port_port = port;\r\ndd->ipath_pd[port]->port_dd = dd;\r\ndd->ipath_pd[port]->port_tid_pg_list = ptmp;\r\ninit_waitqueue_head(&dd->ipath_pd[port]->port_wait);\r\n}\r\nif (!pd->port_cnt) {\r\npd->userversion = uinfo->spu_userversion;\r\ninit_user_egr_sizes(pd);\r\nif ((ret = init_subports(dd, pd, uinfo)) != 0)\r\ngoto bail;\r\nipath_cdbg(PROC, "%s[%u] opened unit:port %u:%u\n",\r\ncurrent->comm, current->pid, dd->ipath_unit,\r\nport);\r\npd->port_cnt = 1;\r\nport_fp(fp) = pd;\r\npd->port_pid = get_pid(task_pid(current));\r\nstrlcpy(pd->port_comm, current->comm, sizeof(pd->port_comm));\r\nipath_stats.sps_ports++;\r\nret = 0;\r\n} else\r\nret = -EBUSY;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic inline int usable(struct ipath_devdata *dd)\r\n{\r\nreturn dd &&\r\n(dd->ipath_flags & IPATH_PRESENT) &&\r\ndd->ipath_kregbase &&\r\ndd->ipath_lid &&\r\n!(dd->ipath_flags & (IPATH_LINKDOWN | IPATH_DISABLED\r\n| IPATH_LINKUNK));\r\n}\r\nstatic int find_free_port(int unit, struct file *fp,\r\nconst struct ipath_user_info *uinfo)\r\n{\r\nstruct ipath_devdata *dd = ipath_lookup(unit);\r\nint ret, i;\r\nif (!dd) {\r\nret = -ENODEV;\r\ngoto bail;\r\n}\r\nif (!usable(dd)) {\r\nret = -ENETDOWN;\r\ngoto bail;\r\n}\r\nfor (i = 1; i < dd->ipath_cfgports; i++) {\r\nret = try_alloc_port(dd, i, fp, uinfo);\r\nif (ret != -EBUSY)\r\ngoto bail;\r\n}\r\nret = -EBUSY;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int find_best_unit(struct file *fp,\r\nconst struct ipath_user_info *uinfo)\r\n{\r\nint ret = 0, i, prefunit = -1, devmax;\r\nint maxofallports, npresent, nup;\r\nint ndev;\r\ndevmax = ipath_count_units(&npresent, &nup, &maxofallports);\r\nif (!cpumask_empty(tsk_cpus_allowed(current)) &&\r\n!cpumask_full(tsk_cpus_allowed(current))) {\r\nint ncpus = num_online_cpus(), curcpu = -1, nset = 0;\r\nget_online_cpus();\r\nfor_each_online_cpu(i)\r\nif (cpumask_test_cpu(i, tsk_cpus_allowed(current))) {\r\nipath_cdbg(PROC, "%s[%u] affinity set for "\r\n"cpu %d/%d\n", current->comm,\r\ncurrent->pid, i, ncpus);\r\ncurcpu = i;\r\nnset++;\r\n}\r\nput_online_cpus();\r\nif (curcpu != -1 && nset != ncpus) {\r\nif (npresent) {\r\nprefunit = curcpu / (ncpus / npresent);\r\nipath_cdbg(PROC,"%s[%u] %d chips, %d cpus, "\r\n"%d cpus/chip, select unit %d\n",\r\ncurrent->comm, current->pid,\r\nnpresent, ncpus, ncpus / npresent,\r\nprefunit);\r\n}\r\n}\r\n}\r\nif (prefunit != -1)\r\ndevmax = prefunit + 1;\r\nrecheck:\r\nfor (i = 1; i < maxofallports; i++) {\r\nfor (ndev = prefunit != -1 ? prefunit : 0; ndev < devmax;\r\nndev++) {\r\nstruct ipath_devdata *dd = ipath_lookup(ndev);\r\nif (!usable(dd))\r\ncontinue;\r\nif (i >= dd->ipath_cfgports)\r\ncontinue;\r\nret = try_alloc_port(dd, i, fp, uinfo);\r\nif (!ret)\r\ngoto done;\r\n}\r\n}\r\nif (npresent) {\r\nif (nup == 0) {\r\nret = -ENETDOWN;\r\nipath_dbg("No ports available (none initialized "\r\n"and ready)\n");\r\n} else {\r\nif (prefunit > 0) {\r\nipath_cdbg(PROC,\r\n"%s[%u] no ports on prefunit "\r\n"%d, clear and re-check\n",\r\ncurrent->comm, current->pid,\r\nprefunit);\r\ndevmax = ipath_count_units(NULL, NULL,\r\nNULL);\r\nprefunit = -1;\r\ngoto recheck;\r\n}\r\nret = -EBUSY;\r\nipath_dbg("No ports available\n");\r\n}\r\n} else {\r\nret = -ENXIO;\r\nipath_dbg("No boards found\n");\r\n}\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int find_shared_port(struct file *fp,\r\nconst struct ipath_user_info *uinfo)\r\n{\r\nint devmax, ndev, i;\r\nint ret = 0;\r\ndevmax = ipath_count_units(NULL, NULL, NULL);\r\nfor (ndev = 0; ndev < devmax; ndev++) {\r\nstruct ipath_devdata *dd = ipath_lookup(ndev);\r\nif (!usable(dd))\r\ncontinue;\r\nfor (i = 1; i < dd->ipath_cfgports; i++) {\r\nstruct ipath_portdata *pd = dd->ipath_pd[i];\r\nif (!pd || !pd->port_cnt)\r\ncontinue;\r\nif (pd->port_subport_id != uinfo->spu_subport_id)\r\ncontinue;\r\nif (pd->port_subport_cnt != uinfo->spu_subport_cnt ||\r\npd->userversion != uinfo->spu_userversion ||\r\npd->port_cnt >= pd->port_subport_cnt) {\r\nret = -EINVAL;\r\ngoto done;\r\n}\r\nport_fp(fp) = pd;\r\nsubport_fp(fp) = pd->port_cnt++;\r\npd->port_subpid[subport_fp(fp)] =\r\nget_pid(task_pid(current));\r\ntidcursor_fp(fp) = 0;\r\npd->active_slaves |= 1 << subport_fp(fp);\r\nipath_cdbg(PROC,\r\n"%s[%u] %u sharing %s[%u] unit:port %u:%u\n",\r\ncurrent->comm, current->pid,\r\nsubport_fp(fp),\r\npd->port_comm, pid_nr(pd->port_pid),\r\ndd->ipath_unit, pd->port_port);\r\nret = 1;\r\ngoto done;\r\n}\r\n}\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int ipath_open(struct inode *in, struct file *fp)\r\n{\r\nfp->private_data = kzalloc(sizeof(struct ipath_filedata), GFP_KERNEL);\r\nreturn fp->private_data ? 0 : -ENOMEM;\r\n}\r\nstatic int ipath_assign_port(struct file *fp,\r\nconst struct ipath_user_info *uinfo)\r\n{\r\nint ret;\r\nint i_minor;\r\nunsigned swmajor, swminor;\r\nif (port_fp(fp)) {\r\nret = -EINVAL;\r\ngoto done;\r\n}\r\nswmajor = uinfo->spu_userversion >> 16;\r\nif (swmajor != IPATH_USER_SWMAJOR) {\r\nipath_dbg("User major version %d not same as driver "\r\n"major %d\n", uinfo->spu_userversion >> 16,\r\nIPATH_USER_SWMAJOR);\r\nret = -ENODEV;\r\ngoto done;\r\n}\r\nswminor = uinfo->spu_userversion & 0xffff;\r\nif (swminor != IPATH_USER_SWMINOR)\r\nipath_dbg("User minor version %d not same as driver "\r\n"minor %d\n", swminor, IPATH_USER_SWMINOR);\r\nmutex_lock(&ipath_mutex);\r\nif (ipath_compatible_subports(swmajor, swminor) &&\r\nuinfo->spu_subport_cnt &&\r\n(ret = find_shared_port(fp, uinfo))) {\r\nif (ret > 0)\r\nret = 0;\r\ngoto done_chk_sdma;\r\n}\r\ni_minor = iminor(file_inode(fp)) - IPATH_USER_MINOR_BASE;\r\nipath_cdbg(VERBOSE, "open on dev %lx (minor %d)\n",\r\n(long)file_inode(fp)->i_rdev, i_minor);\r\nif (i_minor)\r\nret = find_free_port(i_minor - 1, fp, uinfo);\r\nelse\r\nret = find_best_unit(fp, uinfo);\r\ndone_chk_sdma:\r\nif (!ret) {\r\nstruct ipath_filedata *fd = fp->private_data;\r\nconst struct ipath_portdata *pd = fd->pd;\r\nconst struct ipath_devdata *dd = pd->port_dd;\r\nfd->pq = ipath_user_sdma_queue_create(&dd->pcidev->dev,\r\ndd->ipath_unit,\r\npd->port_port,\r\nfd->subport);\r\nif (!fd->pq)\r\nret = -ENOMEM;\r\n}\r\nmutex_unlock(&ipath_mutex);\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int ipath_do_user_init(struct file *fp,\r\nconst struct ipath_user_info *uinfo)\r\n{\r\nint ret;\r\nstruct ipath_portdata *pd = port_fp(fp);\r\nstruct ipath_devdata *dd;\r\nu32 head32;\r\nif (subport_fp(fp)) {\r\nret = wait_event_interruptible(pd->port_wait,\r\n!test_bit(IPATH_PORT_MASTER_UNINIT, &pd->port_flag));\r\ngoto done;\r\n}\r\ndd = pd->port_dd;\r\nif (uinfo->spu_rcvhdrsize) {\r\nret = ipath_setrcvhdrsize(dd, uinfo->spu_rcvhdrsize);\r\nif (ret)\r\ngoto done;\r\n}\r\nif (pd->port_port <= dd->ipath_ports_extrabuf)\r\npd->port_piocnt = dd->ipath_pbufsport + 1;\r\nelse\r\npd->port_piocnt = dd->ipath_pbufsport;\r\nif (pd->port_port <= dd->ipath_ports_extrabuf)\r\npd->port_pio_base = (dd->ipath_pbufsport + 1)\r\n* (pd->port_port - 1);\r\nelse\r\npd->port_pio_base = dd->ipath_ports_extrabuf +\r\ndd->ipath_pbufsport * (pd->port_port - 1);\r\npd->port_piobufs = dd->ipath_piobufbase +\r\npd->port_pio_base * dd->ipath_palign;\r\nipath_cdbg(VERBOSE, "piobuf base for port %u is 0x%x, piocnt %u,"\r\n" first pio %u\n", pd->port_port, pd->port_piobufs,\r\npd->port_piocnt, pd->port_pio_base);\r\nipath_chg_pioavailkernel(dd, pd->port_pio_base, pd->port_piocnt, 0);\r\nret = ipath_create_rcvhdrq(dd, pd);\r\nif (!ret)\r\nret = ipath_create_user_egr(pd);\r\nif (ret)\r\ngoto done;\r\nhead32 = ipath_read_ureg32(dd, ur_rcvegrindextail, pd->port_port);\r\nipath_write_ureg(dd, ur_rcvegrindexhead, head32, pd->port_port);\r\npd->port_lastrcvhdrqtail = -1;\r\nipath_cdbg(VERBOSE, "Wrote port%d egrhead %x from tail regs\n",\r\npd->port_port, head32);\r\npd->port_tidcursor = 0;\r\npd->port_urgent = 0;\r\npd->port_urgent_poll = 0;\r\npd->port_hdrqfull_poll = pd->port_hdrqfull;\r\nset_bit(dd->ipath_r_portenable_shift + pd->port_port,\r\n&dd->ipath_rcvctrl);\r\nif (!(dd->ipath_flags & IPATH_NODMA_RTAIL)) {\r\nif (pd->port_rcvhdrtail_kvaddr)\r\nipath_clear_rcvhdrtail(pd);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_rcvctrl,\r\ndd->ipath_rcvctrl &\r\n~(1ULL << dd->ipath_r_tailupd_shift));\r\n}\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_rcvctrl,\r\ndd->ipath_rcvctrl);\r\nif (pd->port_subport_cnt) {\r\nclear_bit(IPATH_PORT_MASTER_UNINIT, &pd->port_flag);\r\nwake_up(&pd->port_wait);\r\n}\r\ndone:\r\nreturn ret;\r\n}\r\nstatic void unlock_expected_tids(struct ipath_portdata *pd)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\nint port_tidbase = pd->port_port * dd->ipath_rcvtidcnt;\r\nint i, cnt = 0, maxtid = port_tidbase + dd->ipath_rcvtidcnt;\r\nipath_cdbg(VERBOSE, "Port %u unlocking any locked expTID pages\n",\r\npd->port_port);\r\nfor (i = port_tidbase; i < maxtid; i++) {\r\nstruct page *ps = dd->ipath_pageshadow[i];\r\nif (!ps)\r\ncontinue;\r\ndd->ipath_pageshadow[i] = NULL;\r\npci_unmap_page(dd->pcidev, dd->ipath_physshadow[i],\r\nPAGE_SIZE, PCI_DMA_FROMDEVICE);\r\nipath_release_user_pages_on_close(&ps, 1);\r\ncnt++;\r\nipath_stats.sps_pageunlocks++;\r\n}\r\nif (cnt)\r\nipath_cdbg(VERBOSE, "Port %u locked %u expTID entries\n",\r\npd->port_port, cnt);\r\nif (ipath_stats.sps_pagelocks || ipath_stats.sps_pageunlocks)\r\nipath_cdbg(VERBOSE, "%llu pages locked, %llu unlocked\n",\r\n(unsigned long long) ipath_stats.sps_pagelocks,\r\n(unsigned long long)\r\nipath_stats.sps_pageunlocks);\r\n}\r\nstatic int ipath_close(struct inode *in, struct file *fp)\r\n{\r\nint ret = 0;\r\nstruct ipath_filedata *fd;\r\nstruct ipath_portdata *pd;\r\nstruct ipath_devdata *dd;\r\nunsigned long flags;\r\nunsigned port;\r\nstruct pid *pid;\r\nipath_cdbg(VERBOSE, "close on dev %lx, private data %p\n",\r\n(long)in->i_rdev, fp->private_data);\r\nmutex_lock(&ipath_mutex);\r\nfd = fp->private_data;\r\nfp->private_data = NULL;\r\npd = fd->pd;\r\nif (!pd) {\r\nmutex_unlock(&ipath_mutex);\r\ngoto bail;\r\n}\r\ndd = pd->port_dd;\r\nipath_user_sdma_queue_drain(dd, fd->pq);\r\nipath_user_sdma_queue_destroy(fd->pq);\r\nif (--pd->port_cnt) {\r\npd->active_slaves &= ~(1 << fd->subport);\r\nput_pid(pd->port_subpid[fd->subport]);\r\npd->port_subpid[fd->subport] = NULL;\r\nmutex_unlock(&ipath_mutex);\r\ngoto bail;\r\n}\r\nspin_lock_irqsave(&dd->ipath_uctxt_lock, flags);\r\nport = pd->port_port;\r\ndd->ipath_pd[port] = NULL;\r\npid = pd->port_pid;\r\npd->port_pid = NULL;\r\nspin_unlock_irqrestore(&dd->ipath_uctxt_lock, flags);\r\nif (pd->port_rcvwait_to || pd->port_piowait_to\r\n|| pd->port_rcvnowait || pd->port_pionowait) {\r\nipath_cdbg(VERBOSE, "port%u, %u rcv, %u pio wait timeo; "\r\n"%u rcv %u, pio already\n",\r\npd->port_port, pd->port_rcvwait_to,\r\npd->port_piowait_to, pd->port_rcvnowait,\r\npd->port_pionowait);\r\npd->port_rcvwait_to = pd->port_piowait_to =\r\npd->port_rcvnowait = pd->port_pionowait = 0;\r\n}\r\nif (pd->port_flag) {\r\nipath_cdbg(PROC, "port %u port_flag set: 0x%lx\n",\r\npd->port_port, pd->port_flag);\r\npd->port_flag = 0;\r\n}\r\nif (dd->ipath_kregbase) {\r\nclear_bit(dd->ipath_r_portenable_shift + port,\r\n&dd->ipath_rcvctrl);\r\nclear_bit(pd->port_port + dd->ipath_r_intravail_shift,\r\n&dd->ipath_rcvctrl);\r\nipath_write_kreg( dd, dd->ipath_kregs->kr_rcvctrl,\r\ndd->ipath_rcvctrl);\r\n(void)ipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\nipath_clean_part_key(pd, dd);\r\nipath_write_kreg_port(dd,\r\ndd->ipath_kregs->kr_rcvhdrtailaddr, port,\r\ndd->ipath_dummy_hdrq_phys);\r\nipath_write_kreg_port(dd, dd->ipath_kregs->kr_rcvhdraddr,\r\npd->port_port, dd->ipath_dummy_hdrq_phys);\r\nipath_disarm_piobufs(dd, pd->port_pio_base, pd->port_piocnt);\r\nipath_chg_pioavailkernel(dd, pd->port_pio_base,\r\npd->port_piocnt, 1);\r\ndd->ipath_f_clear_tids(dd, pd->port_port);\r\nif (dd->ipath_pageshadow)\r\nunlock_expected_tids(pd);\r\nipath_stats.sps_ports--;\r\nipath_cdbg(PROC, "%s[%u] closed port %u:%u\n",\r\npd->port_comm, pid_nr(pid),\r\ndd->ipath_unit, port);\r\n}\r\nput_pid(pid);\r\nmutex_unlock(&ipath_mutex);\r\nipath_free_pddata(dd, pd);\r\nbail:\r\nkfree(fd);\r\nreturn ret;\r\n}\r\nstatic int ipath_port_info(struct ipath_portdata *pd, u16 subport,\r\nstruct ipath_port_info __user *uinfo)\r\n{\r\nstruct ipath_port_info info;\r\nint nup;\r\nint ret;\r\nsize_t sz;\r\n(void) ipath_count_units(NULL, &nup, NULL);\r\ninfo.num_active = nup;\r\ninfo.unit = pd->port_dd->ipath_unit;\r\ninfo.port = pd->port_port;\r\ninfo.subport = subport;\r\nif (ipath_supports_subports(pd->userversion >> 16,\r\npd->userversion & 0xffff)) {\r\ninfo.num_ports = pd->port_dd->ipath_cfgports - 1;\r\ninfo.num_subports = pd->port_subport_cnt;\r\nsz = sizeof(info);\r\n} else\r\nsz = sizeof(info) - 2 * sizeof(u16);\r\nif (copy_to_user(uinfo, &info, sz)) {\r\nret = -EFAULT;\r\ngoto bail;\r\n}\r\nret = 0;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int ipath_get_slave_info(struct ipath_portdata *pd,\r\nvoid __user *slave_mask_addr)\r\n{\r\nint ret = 0;\r\nif (copy_to_user(slave_mask_addr, &pd->active_slaves, sizeof(u32)))\r\nret = -EFAULT;\r\nreturn ret;\r\n}\r\nstatic int ipath_sdma_get_inflight(struct ipath_user_sdma_queue *pq,\r\nu32 __user *inflightp)\r\n{\r\nconst u32 val = ipath_user_sdma_inflight_counter(pq);\r\nif (put_user(val, inflightp))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nstatic int ipath_sdma_get_complete(struct ipath_devdata *dd,\r\nstruct ipath_user_sdma_queue *pq,\r\nu32 __user *completep)\r\n{\r\nu32 val;\r\nint err;\r\nerr = ipath_user_sdma_make_progress(dd, pq);\r\nif (err < 0)\r\nreturn err;\r\nval = ipath_user_sdma_complete_counter(pq);\r\nif (put_user(val, completep))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nstatic ssize_t ipath_write(struct file *fp, const char __user *data,\r\nsize_t count, loff_t *off)\r\n{\r\nconst struct ipath_cmd __user *ucmd;\r\nstruct ipath_portdata *pd;\r\nconst void __user *src;\r\nsize_t consumed, copy;\r\nstruct ipath_cmd cmd;\r\nssize_t ret = 0;\r\nvoid *dest;\r\nif (count < sizeof(cmd.type)) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nucmd = (const struct ipath_cmd __user *) data;\r\nif (copy_from_user(&cmd.type, &ucmd->type, sizeof(cmd.type))) {\r\nret = -EFAULT;\r\ngoto bail;\r\n}\r\nconsumed = sizeof(cmd.type);\r\nswitch (cmd.type) {\r\ncase IPATH_CMD_ASSIGN_PORT:\r\ncase __IPATH_CMD_USER_INIT:\r\ncase IPATH_CMD_USER_INIT:\r\ncopy = sizeof(cmd.cmd.user_info);\r\ndest = &cmd.cmd.user_info;\r\nsrc = &ucmd->cmd.user_info;\r\nbreak;\r\ncase IPATH_CMD_RECV_CTRL:\r\ncopy = sizeof(cmd.cmd.recv_ctrl);\r\ndest = &cmd.cmd.recv_ctrl;\r\nsrc = &ucmd->cmd.recv_ctrl;\r\nbreak;\r\ncase IPATH_CMD_PORT_INFO:\r\ncopy = sizeof(cmd.cmd.port_info);\r\ndest = &cmd.cmd.port_info;\r\nsrc = &ucmd->cmd.port_info;\r\nbreak;\r\ncase IPATH_CMD_TID_UPDATE:\r\ncase IPATH_CMD_TID_FREE:\r\ncopy = sizeof(cmd.cmd.tid_info);\r\ndest = &cmd.cmd.tid_info;\r\nsrc = &ucmd->cmd.tid_info;\r\nbreak;\r\ncase IPATH_CMD_SET_PART_KEY:\r\ncopy = sizeof(cmd.cmd.part_key);\r\ndest = &cmd.cmd.part_key;\r\nsrc = &ucmd->cmd.part_key;\r\nbreak;\r\ncase __IPATH_CMD_SLAVE_INFO:\r\ncopy = sizeof(cmd.cmd.slave_mask_addr);\r\ndest = &cmd.cmd.slave_mask_addr;\r\nsrc = &ucmd->cmd.slave_mask_addr;\r\nbreak;\r\ncase IPATH_CMD_PIOAVAILUPD:\r\ncopy = 0;\r\nsrc = NULL;\r\ndest = NULL;\r\nbreak;\r\ncase IPATH_CMD_POLL_TYPE:\r\ncopy = sizeof(cmd.cmd.poll_type);\r\ndest = &cmd.cmd.poll_type;\r\nsrc = &ucmd->cmd.poll_type;\r\nbreak;\r\ncase IPATH_CMD_ARMLAUNCH_CTRL:\r\ncopy = sizeof(cmd.cmd.armlaunch_ctrl);\r\ndest = &cmd.cmd.armlaunch_ctrl;\r\nsrc = &ucmd->cmd.armlaunch_ctrl;\r\nbreak;\r\ncase IPATH_CMD_SDMA_INFLIGHT:\r\ncopy = sizeof(cmd.cmd.sdma_inflight);\r\ndest = &cmd.cmd.sdma_inflight;\r\nsrc = &ucmd->cmd.sdma_inflight;\r\nbreak;\r\ncase IPATH_CMD_SDMA_COMPLETE:\r\ncopy = sizeof(cmd.cmd.sdma_complete);\r\ndest = &cmd.cmd.sdma_complete;\r\nsrc = &ucmd->cmd.sdma_complete;\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nif (copy) {\r\nif ((count - consumed) < copy) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nif (copy_from_user(dest, src, copy)) {\r\nret = -EFAULT;\r\ngoto bail;\r\n}\r\nconsumed += copy;\r\n}\r\npd = port_fp(fp);\r\nif (!pd && cmd.type != __IPATH_CMD_USER_INIT &&\r\ncmd.type != IPATH_CMD_ASSIGN_PORT) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nswitch (cmd.type) {\r\ncase IPATH_CMD_ASSIGN_PORT:\r\nret = ipath_assign_port(fp, &cmd.cmd.user_info);\r\nif (ret)\r\ngoto bail;\r\nbreak;\r\ncase __IPATH_CMD_USER_INIT:\r\nret = ipath_assign_port(fp, &cmd.cmd.user_info);\r\nif (ret)\r\ngoto bail;\r\ncase IPATH_CMD_USER_INIT:\r\nret = ipath_do_user_init(fp, &cmd.cmd.user_info);\r\nif (ret)\r\ngoto bail;\r\nret = ipath_get_base_info(\r\nfp, (void __user *) (unsigned long)\r\ncmd.cmd.user_info.spu_base_info,\r\ncmd.cmd.user_info.spu_base_info_size);\r\nbreak;\r\ncase IPATH_CMD_RECV_CTRL:\r\nret = ipath_manage_rcvq(pd, subport_fp(fp), cmd.cmd.recv_ctrl);\r\nbreak;\r\ncase IPATH_CMD_PORT_INFO:\r\nret = ipath_port_info(pd, subport_fp(fp),\r\n(struct ipath_port_info __user *)\r\n(unsigned long) cmd.cmd.port_info);\r\nbreak;\r\ncase IPATH_CMD_TID_UPDATE:\r\nret = ipath_tid_update(pd, fp, &cmd.cmd.tid_info);\r\nbreak;\r\ncase IPATH_CMD_TID_FREE:\r\nret = ipath_tid_free(pd, subport_fp(fp), &cmd.cmd.tid_info);\r\nbreak;\r\ncase IPATH_CMD_SET_PART_KEY:\r\nret = ipath_set_part_key(pd, cmd.cmd.part_key);\r\nbreak;\r\ncase __IPATH_CMD_SLAVE_INFO:\r\nret = ipath_get_slave_info(pd,\r\n(void __user *) (unsigned long)\r\ncmd.cmd.slave_mask_addr);\r\nbreak;\r\ncase IPATH_CMD_PIOAVAILUPD:\r\nipath_force_pio_avail_update(pd->port_dd);\r\nbreak;\r\ncase IPATH_CMD_POLL_TYPE:\r\npd->poll_type = cmd.cmd.poll_type;\r\nbreak;\r\ncase IPATH_CMD_ARMLAUNCH_CTRL:\r\nif (cmd.cmd.armlaunch_ctrl)\r\nipath_enable_armlaunch(pd->port_dd);\r\nelse\r\nipath_disable_armlaunch(pd->port_dd);\r\nbreak;\r\ncase IPATH_CMD_SDMA_INFLIGHT:\r\nret = ipath_sdma_get_inflight(user_sdma_queue_fp(fp),\r\n(u32 __user *) (unsigned long)\r\ncmd.cmd.sdma_inflight);\r\nbreak;\r\ncase IPATH_CMD_SDMA_COMPLETE:\r\nret = ipath_sdma_get_complete(pd->port_dd,\r\nuser_sdma_queue_fp(fp),\r\n(u32 __user *) (unsigned long)\r\ncmd.cmd.sdma_complete);\r\nbreak;\r\n}\r\nif (ret >= 0)\r\nret = consumed;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic ssize_t ipath_writev(struct kiocb *iocb, const struct iovec *iov,\r\nunsigned long dim, loff_t off)\r\n{\r\nstruct file *filp = iocb->ki_filp;\r\nstruct ipath_filedata *fp = filp->private_data;\r\nstruct ipath_portdata *pd = port_fp(filp);\r\nstruct ipath_user_sdma_queue *pq = fp->pq;\r\nif (!dim)\r\nreturn -EINVAL;\r\nreturn ipath_user_sdma_writev(pd->port_dd, pq, iov, dim);\r\n}\r\nstatic int init_cdev(int minor, char *name, const struct file_operations *fops,\r\nstruct cdev **cdevp, struct device **devp)\r\n{\r\nconst dev_t dev = MKDEV(IPATH_MAJOR, minor);\r\nstruct cdev *cdev = NULL;\r\nstruct device *device = NULL;\r\nint ret;\r\ncdev = cdev_alloc();\r\nif (!cdev) {\r\nprintk(KERN_ERR IPATH_DRV_NAME\r\n": Could not allocate cdev for minor %d, %s\n",\r\nminor, name);\r\nret = -ENOMEM;\r\ngoto done;\r\n}\r\ncdev->owner = THIS_MODULE;\r\ncdev->ops = fops;\r\nkobject_set_name(&cdev->kobj, name);\r\nret = cdev_add(cdev, dev, 1);\r\nif (ret < 0) {\r\nprintk(KERN_ERR IPATH_DRV_NAME\r\n": Could not add cdev for minor %d, %s (err %d)\n",\r\nminor, name, -ret);\r\ngoto err_cdev;\r\n}\r\ndevice = device_create(ipath_class, NULL, dev, NULL, name);\r\nif (IS_ERR(device)) {\r\nret = PTR_ERR(device);\r\nprintk(KERN_ERR IPATH_DRV_NAME ": Could not create "\r\n"device for minor %d, %s (err %d)\n",\r\nminor, name, -ret);\r\ngoto err_cdev;\r\n}\r\ngoto done;\r\nerr_cdev:\r\ncdev_del(cdev);\r\ncdev = NULL;\r\ndone:\r\nif (ret >= 0) {\r\n*cdevp = cdev;\r\n*devp = device;\r\n} else {\r\n*cdevp = NULL;\r\n*devp = NULL;\r\n}\r\nreturn ret;\r\n}\r\nint ipath_cdev_init(int minor, char *name, const struct file_operations *fops,\r\nstruct cdev **cdevp, struct device **devp)\r\n{\r\nreturn init_cdev(minor, name, fops, cdevp, devp);\r\n}\r\nstatic void cleanup_cdev(struct cdev **cdevp,\r\nstruct device **devp)\r\n{\r\nstruct device *dev = *devp;\r\nif (dev) {\r\ndevice_unregister(dev);\r\n*devp = NULL;\r\n}\r\nif (*cdevp) {\r\ncdev_del(*cdevp);\r\n*cdevp = NULL;\r\n}\r\n}\r\nvoid ipath_cdev_cleanup(struct cdev **cdevp,\r\nstruct device **devp)\r\n{\r\ncleanup_cdev(cdevp, devp);\r\n}\r\nstatic int user_init(void)\r\n{\r\nint ret;\r\nret = register_chrdev_region(dev, IPATH_NMINORS, IPATH_DRV_NAME);\r\nif (ret < 0) {\r\nprintk(KERN_ERR IPATH_DRV_NAME ": Could not register "\r\n"chrdev region (err %d)\n", -ret);\r\ngoto done;\r\n}\r\nipath_class = class_create(THIS_MODULE, IPATH_DRV_NAME);\r\nif (IS_ERR(ipath_class)) {\r\nret = PTR_ERR(ipath_class);\r\nprintk(KERN_ERR IPATH_DRV_NAME ": Could not create "\r\n"device class (err %d)\n", -ret);\r\ngoto bail;\r\n}\r\ngoto done;\r\nbail:\r\nunregister_chrdev_region(dev, IPATH_NMINORS);\r\ndone:\r\nreturn ret;\r\n}\r\nstatic void user_cleanup(void)\r\n{\r\nif (ipath_class) {\r\nclass_destroy(ipath_class);\r\nipath_class = NULL;\r\n}\r\nunregister_chrdev_region(dev, IPATH_NMINORS);\r\n}\r\nint ipath_user_add(struct ipath_devdata *dd)\r\n{\r\nchar name[10];\r\nint ret;\r\nif (atomic_inc_return(&user_count) == 1) {\r\nret = user_init();\r\nif (ret < 0) {\r\nipath_dev_err(dd, "Unable to set up user support: "\r\n"error %d\n", -ret);\r\ngoto bail;\r\n}\r\nret = init_cdev(0, "ipath", &ipath_file_ops, &wildcard_cdev,\r\n&wildcard_dev);\r\nif (ret < 0) {\r\nipath_dev_err(dd, "Could not create wildcard "\r\n"minor: error %d\n", -ret);\r\ngoto bail_user;\r\n}\r\natomic_set(&user_setup, 1);\r\n}\r\nsnprintf(name, sizeof(name), "ipath%d", dd->ipath_unit);\r\nret = init_cdev(dd->ipath_unit + 1, name, &ipath_file_ops,\r\n&dd->user_cdev, &dd->user_dev);\r\nif (ret < 0)\r\nipath_dev_err(dd, "Could not create user minor %d, %s\n",\r\ndd->ipath_unit + 1, name);\r\ngoto bail;\r\nbail_user:\r\nuser_cleanup();\r\nbail:\r\nreturn ret;\r\n}\r\nvoid ipath_user_remove(struct ipath_devdata *dd)\r\n{\r\ncleanup_cdev(&dd->user_cdev, &dd->user_dev);\r\nif (atomic_dec_return(&user_count) == 0) {\r\nif (atomic_read(&user_setup) == 0)\r\ngoto bail;\r\ncleanup_cdev(&wildcard_cdev, &wildcard_dev);\r\nuser_cleanup();\r\natomic_set(&user_setup, 0);\r\n}\r\nbail:\r\nreturn;\r\n}
