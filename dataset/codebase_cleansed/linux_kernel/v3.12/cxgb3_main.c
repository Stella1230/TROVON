static void link_report(struct net_device *dev)\r\n{\r\nif (!netif_carrier_ok(dev))\r\nnetdev_info(dev, "link down\n");\r\nelse {\r\nconst char *s = "10Mbps";\r\nconst struct port_info *p = netdev_priv(dev);\r\nswitch (p->link_config.speed) {\r\ncase SPEED_10000:\r\ns = "10Gbps";\r\nbreak;\r\ncase SPEED_1000:\r\ns = "1000Mbps";\r\nbreak;\r\ncase SPEED_100:\r\ns = "100Mbps";\r\nbreak;\r\n}\r\nnetdev_info(dev, "link up, %s, %s-duplex\n",\r\ns, p->link_config.duplex == DUPLEX_FULL\r\n? "full" : "half");\r\n}\r\n}\r\nstatic void enable_tx_fifo_drain(struct adapter *adapter,\r\nstruct port_info *pi)\r\n{\r\nt3_set_reg_field(adapter, A_XGM_TXFIFO_CFG + pi->mac.offset, 0,\r\nF_ENDROPPKT);\r\nt3_write_reg(adapter, A_XGM_RX_CTRL + pi->mac.offset, 0);\r\nt3_write_reg(adapter, A_XGM_TX_CTRL + pi->mac.offset, F_TXEN);\r\nt3_write_reg(adapter, A_XGM_RX_CTRL + pi->mac.offset, F_RXEN);\r\n}\r\nstatic void disable_tx_fifo_drain(struct adapter *adapter,\r\nstruct port_info *pi)\r\n{\r\nt3_set_reg_field(adapter, A_XGM_TXFIFO_CFG + pi->mac.offset,\r\nF_ENDROPPKT, 0);\r\n}\r\nvoid t3_os_link_fault(struct adapter *adap, int port_id, int state)\r\n{\r\nstruct net_device *dev = adap->port[port_id];\r\nstruct port_info *pi = netdev_priv(dev);\r\nif (state == netif_carrier_ok(dev))\r\nreturn;\r\nif (state) {\r\nstruct cmac *mac = &pi->mac;\r\nnetif_carrier_on(dev);\r\ndisable_tx_fifo_drain(adap, pi);\r\nt3_xgm_intr_disable(adap, pi->port_id);\r\nt3_read_reg(adap, A_XGM_INT_STATUS +\r\npi->mac.offset);\r\nt3_write_reg(adap,\r\nA_XGM_INT_CAUSE + pi->mac.offset,\r\nF_XGM_INT);\r\nt3_set_reg_field(adap,\r\nA_XGM_INT_ENABLE +\r\npi->mac.offset,\r\nF_XGM_INT, F_XGM_INT);\r\nt3_xgm_intr_enable(adap, pi->port_id);\r\nt3_mac_enable(mac, MAC_DIRECTION_TX);\r\n} else {\r\nnetif_carrier_off(dev);\r\nenable_tx_fifo_drain(adap, pi);\r\n}\r\nlink_report(dev);\r\n}\r\nvoid t3_os_link_changed(struct adapter *adapter, int port_id, int link_stat,\r\nint speed, int duplex, int pause)\r\n{\r\nstruct net_device *dev = adapter->port[port_id];\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct cmac *mac = &pi->mac;\r\nif (!netif_running(dev))\r\nreturn;\r\nif (link_stat != netif_carrier_ok(dev)) {\r\nif (link_stat) {\r\ndisable_tx_fifo_drain(adapter, pi);\r\nt3_mac_enable(mac, MAC_DIRECTION_RX);\r\nt3_xgm_intr_disable(adapter, pi->port_id);\r\nt3_read_reg(adapter, A_XGM_INT_STATUS +\r\npi->mac.offset);\r\nt3_write_reg(adapter,\r\nA_XGM_INT_CAUSE + pi->mac.offset,\r\nF_XGM_INT);\r\nt3_set_reg_field(adapter,\r\nA_XGM_INT_ENABLE + pi->mac.offset,\r\nF_XGM_INT, F_XGM_INT);\r\nt3_xgm_intr_enable(adapter, pi->port_id);\r\nnetif_carrier_on(dev);\r\n} else {\r\nnetif_carrier_off(dev);\r\nt3_xgm_intr_disable(adapter, pi->port_id);\r\nt3_read_reg(adapter, A_XGM_INT_STATUS + pi->mac.offset);\r\nt3_set_reg_field(adapter,\r\nA_XGM_INT_ENABLE + pi->mac.offset,\r\nF_XGM_INT, 0);\r\nif (is_10G(adapter))\r\npi->phy.ops->power_down(&pi->phy, 1);\r\nt3_read_reg(adapter, A_XGM_INT_STATUS + pi->mac.offset);\r\nt3_mac_disable(mac, MAC_DIRECTION_RX);\r\nt3_link_start(&pi->phy, mac, &pi->link_config);\r\nenable_tx_fifo_drain(adapter, pi);\r\n}\r\nlink_report(dev);\r\n}\r\n}\r\nvoid t3_os_phymod_changed(struct adapter *adap, int port_id)\r\n{\r\nstatic const char *mod_str[] = {\r\nNULL, "SR", "LR", "LRM", "TWINAX", "TWINAX", "unknown"\r\n};\r\nconst struct net_device *dev = adap->port[port_id];\r\nconst struct port_info *pi = netdev_priv(dev);\r\nif (pi->phy.modtype == phy_modtype_none)\r\nnetdev_info(dev, "PHY module unplugged\n");\r\nelse\r\nnetdev_info(dev, "%s PHY module inserted\n",\r\nmod_str[pi->phy.modtype]);\r\n}\r\nstatic void cxgb_set_rxmode(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nt3_mac_set_rx_mode(&pi->mac, dev);\r\n}\r\nstatic void link_start(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct cmac *mac = &pi->mac;\r\nt3_mac_reset(mac);\r\nt3_mac_set_num_ucast(mac, MAX_MAC_IDX);\r\nt3_mac_set_mtu(mac, dev->mtu);\r\nt3_mac_set_address(mac, LAN_MAC_IDX, dev->dev_addr);\r\nt3_mac_set_address(mac, SAN_MAC_IDX, pi->iscsic.mac_addr);\r\nt3_mac_set_rx_mode(mac, dev);\r\nt3_link_start(&pi->phy, mac, &pi->link_config);\r\nt3_mac_enable(mac, MAC_DIRECTION_RX | MAC_DIRECTION_TX);\r\n}\r\nstatic inline void cxgb_disable_msi(struct adapter *adapter)\r\n{\r\nif (adapter->flags & USING_MSIX) {\r\npci_disable_msix(adapter->pdev);\r\nadapter->flags &= ~USING_MSIX;\r\n} else if (adapter->flags & USING_MSI) {\r\npci_disable_msi(adapter->pdev);\r\nadapter->flags &= ~USING_MSI;\r\n}\r\n}\r\nstatic irqreturn_t t3_async_intr_handler(int irq, void *cookie)\r\n{\r\nt3_slow_intr_handler(cookie);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void name_msix_vecs(struct adapter *adap)\r\n{\r\nint i, j, msi_idx = 1, n = sizeof(adap->msix_info[0].desc) - 1;\r\nsnprintf(adap->msix_info[0].desc, n, "%s", adap->name);\r\nadap->msix_info[0].desc[n] = 0;\r\nfor_each_port(adap, j) {\r\nstruct net_device *d = adap->port[j];\r\nconst struct port_info *pi = netdev_priv(d);\r\nfor (i = 0; i < pi->nqsets; i++, msi_idx++) {\r\nsnprintf(adap->msix_info[msi_idx].desc, n,\r\n"%s-%d", d->name, pi->first_qset + i);\r\nadap->msix_info[msi_idx].desc[n] = 0;\r\n}\r\n}\r\n}\r\nstatic int request_msix_data_irqs(struct adapter *adap)\r\n{\r\nint i, j, err, qidx = 0;\r\nfor_each_port(adap, i) {\r\nint nqsets = adap2pinfo(adap, i)->nqsets;\r\nfor (j = 0; j < nqsets; ++j) {\r\nerr = request_irq(adap->msix_info[qidx + 1].vec,\r\nt3_intr_handler(adap,\r\nadap->sge.qs[qidx].\r\nrspq.polling), 0,\r\nadap->msix_info[qidx + 1].desc,\r\n&adap->sge.qs[qidx]);\r\nif (err) {\r\nwhile (--qidx >= 0)\r\nfree_irq(adap->msix_info[qidx + 1].vec,\r\n&adap->sge.qs[qidx]);\r\nreturn err;\r\n}\r\nqidx++;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void free_irq_resources(struct adapter *adapter)\r\n{\r\nif (adapter->flags & USING_MSIX) {\r\nint i, n = 0;\r\nfree_irq(adapter->msix_info[0].vec, adapter);\r\nfor_each_port(adapter, i)\r\nn += adap2pinfo(adapter, i)->nqsets;\r\nfor (i = 0; i < n; ++i)\r\nfree_irq(adapter->msix_info[i + 1].vec,\r\n&adapter->sge.qs[i]);\r\n} else\r\nfree_irq(adapter->pdev->irq, adapter);\r\n}\r\nstatic int await_mgmt_replies(struct adapter *adap, unsigned long init_cnt,\r\nunsigned long n)\r\n{\r\nint attempts = 10;\r\nwhile (adap->sge.qs[0].rspq.offload_pkts < init_cnt + n) {\r\nif (!--attempts)\r\nreturn -ETIMEDOUT;\r\nmsleep(10);\r\n}\r\nreturn 0;\r\n}\r\nstatic int init_tp_parity(struct adapter *adap)\r\n{\r\nint i;\r\nstruct sk_buff *skb;\r\nstruct cpl_set_tcb_field *greq;\r\nunsigned long cnt = adap->sge.qs[0].rspq.offload_pkts;\r\nt3_tp_set_offload_mode(adap, 1);\r\nfor (i = 0; i < 16; i++) {\r\nstruct cpl_smt_write_req *req;\r\nskb = alloc_skb(sizeof(*req), GFP_KERNEL);\r\nif (!skb)\r\nskb = adap->nofail_skb;\r\nif (!skb)\r\ngoto alloc_skb_fail;\r\nreq = (struct cpl_smt_write_req *)__skb_put(skb, sizeof(*req));\r\nmemset(req, 0, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SMT_WRITE_REQ, i));\r\nreq->mtu_idx = NMTUS - 1;\r\nreq->iff = i;\r\nt3_mgmt_tx(adap, skb);\r\nif (skb == adap->nofail_skb) {\r\nawait_mgmt_replies(adap, cnt, i + 1);\r\nadap->nofail_skb = alloc_skb(sizeof(*greq), GFP_KERNEL);\r\nif (!adap->nofail_skb)\r\ngoto alloc_skb_fail;\r\n}\r\n}\r\nfor (i = 0; i < 2048; i++) {\r\nstruct cpl_l2t_write_req *req;\r\nskb = alloc_skb(sizeof(*req), GFP_KERNEL);\r\nif (!skb)\r\nskb = adap->nofail_skb;\r\nif (!skb)\r\ngoto alloc_skb_fail;\r\nreq = (struct cpl_l2t_write_req *)__skb_put(skb, sizeof(*req));\r\nmemset(req, 0, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_L2T_WRITE_REQ, i));\r\nreq->params = htonl(V_L2T_W_IDX(i));\r\nt3_mgmt_tx(adap, skb);\r\nif (skb == adap->nofail_skb) {\r\nawait_mgmt_replies(adap, cnt, 16 + i + 1);\r\nadap->nofail_skb = alloc_skb(sizeof(*greq), GFP_KERNEL);\r\nif (!adap->nofail_skb)\r\ngoto alloc_skb_fail;\r\n}\r\n}\r\nfor (i = 0; i < 2048; i++) {\r\nstruct cpl_rte_write_req *req;\r\nskb = alloc_skb(sizeof(*req), GFP_KERNEL);\r\nif (!skb)\r\nskb = adap->nofail_skb;\r\nif (!skb)\r\ngoto alloc_skb_fail;\r\nreq = (struct cpl_rte_write_req *)__skb_put(skb, sizeof(*req));\r\nmemset(req, 0, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_RTE_WRITE_REQ, i));\r\nreq->l2t_idx = htonl(V_L2T_W_IDX(i));\r\nt3_mgmt_tx(adap, skb);\r\nif (skb == adap->nofail_skb) {\r\nawait_mgmt_replies(adap, cnt, 16 + 2048 + i + 1);\r\nadap->nofail_skb = alloc_skb(sizeof(*greq), GFP_KERNEL);\r\nif (!adap->nofail_skb)\r\ngoto alloc_skb_fail;\r\n}\r\n}\r\nskb = alloc_skb(sizeof(*greq), GFP_KERNEL);\r\nif (!skb)\r\nskb = adap->nofail_skb;\r\nif (!skb)\r\ngoto alloc_skb_fail;\r\ngreq = (struct cpl_set_tcb_field *)__skb_put(skb, sizeof(*greq));\r\nmemset(greq, 0, sizeof(*greq));\r\ngreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(greq) = htonl(MK_OPCODE_TID(CPL_SET_TCB_FIELD, 0));\r\ngreq->mask = cpu_to_be64(1);\r\nt3_mgmt_tx(adap, skb);\r\ni = await_mgmt_replies(adap, cnt, 16 + 2048 + 2048 + 1);\r\nif (skb == adap->nofail_skb) {\r\ni = await_mgmt_replies(adap, cnt, 16 + 2048 + 2048 + 1);\r\nadap->nofail_skb = alloc_skb(sizeof(*greq), GFP_KERNEL);\r\n}\r\nt3_tp_set_offload_mode(adap, 0);\r\nreturn i;\r\nalloc_skb_fail:\r\nt3_tp_set_offload_mode(adap, 0);\r\nreturn -ENOMEM;\r\n}\r\nstatic void setup_rss(struct adapter *adap)\r\n{\r\nint i;\r\nunsigned int nq0 = adap2pinfo(adap, 0)->nqsets;\r\nunsigned int nq1 = adap->port[1] ? adap2pinfo(adap, 1)->nqsets : 1;\r\nu8 cpus[SGE_QSETS + 1];\r\nu16 rspq_map[RSS_TABLE_SIZE];\r\nfor (i = 0; i < SGE_QSETS; ++i)\r\ncpus[i] = i;\r\ncpus[SGE_QSETS] = 0xff;\r\nfor (i = 0; i < RSS_TABLE_SIZE / 2; ++i) {\r\nrspq_map[i] = i % nq0;\r\nrspq_map[i + RSS_TABLE_SIZE / 2] = (i % nq1) + nq0;\r\n}\r\nt3_config_rss(adap, F_RQFEEDBACKENABLE | F_TNLLKPEN | F_TNLMAPEN |\r\nF_TNLPRTEN | F_TNL2TUPEN | F_TNL4TUPEN |\r\nV_RRCPLCPUSIZE(6) | F_HASHTOEPLITZ, cpus, rspq_map);\r\n}\r\nstatic void ring_dbs(struct adapter *adap)\r\n{\r\nint i, j;\r\nfor (i = 0; i < SGE_QSETS; i++) {\r\nstruct sge_qset *qs = &adap->sge.qs[i];\r\nif (qs->adap)\r\nfor (j = 0; j < SGE_TXQ_PER_SET; j++)\r\nt3_write_reg(adap, A_SG_KDOORBELL, F_SELEGRCNTX | V_EGRCNTX(qs->txq[j].cntxt_id));\r\n}\r\n}\r\nstatic void init_napi(struct adapter *adap)\r\n{\r\nint i;\r\nfor (i = 0; i < SGE_QSETS; i++) {\r\nstruct sge_qset *qs = &adap->sge.qs[i];\r\nif (qs->adap)\r\nnetif_napi_add(qs->netdev, &qs->napi, qs->napi.poll,\r\n64);\r\n}\r\nadap->flags |= NAPI_INIT;\r\n}\r\nstatic void quiesce_rx(struct adapter *adap)\r\n{\r\nint i;\r\nfor (i = 0; i < SGE_QSETS; i++)\r\nif (adap->sge.qs[i].adap)\r\nnapi_disable(&adap->sge.qs[i].napi);\r\n}\r\nstatic void enable_all_napi(struct adapter *adap)\r\n{\r\nint i;\r\nfor (i = 0; i < SGE_QSETS; i++)\r\nif (adap->sge.qs[i].adap)\r\nnapi_enable(&adap->sge.qs[i].napi);\r\n}\r\nstatic int setup_sge_qsets(struct adapter *adap)\r\n{\r\nint i, j, err, irq_idx = 0, qset_idx = 0;\r\nunsigned int ntxq = SGE_TXQ_PER_SET;\r\nif (adap->params.rev > 0 && !(adap->flags & USING_MSI))\r\nirq_idx = -1;\r\nfor_each_port(adap, i) {\r\nstruct net_device *dev = adap->port[i];\r\nstruct port_info *pi = netdev_priv(dev);\r\npi->qs = &adap->sge.qs[pi->first_qset];\r\nfor (j = 0; j < pi->nqsets; ++j, ++qset_idx) {\r\nerr = t3_sge_alloc_qset(adap, qset_idx, 1,\r\n(adap->flags & USING_MSIX) ? qset_idx + 1 :\r\nirq_idx,\r\n&adap->params.sge.qset[qset_idx], ntxq, dev,\r\nnetdev_get_tx_queue(dev, j));\r\nif (err) {\r\nt3_free_sge_resources(adap);\r\nreturn err;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic ssize_t attr_show(struct device *d, char *buf,\r\nssize_t(*format) (struct net_device *, char *))\r\n{\r\nssize_t len;\r\nrtnl_lock();\r\nlen = (*format) (to_net_dev(d), buf);\r\nrtnl_unlock();\r\nreturn len;\r\n}\r\nstatic ssize_t attr_store(struct device *d,\r\nconst char *buf, size_t len,\r\nssize_t(*set) (struct net_device *, unsigned int),\r\nunsigned int min_val, unsigned int max_val)\r\n{\r\nchar *endp;\r\nssize_t ret;\r\nunsigned int val;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nval = simple_strtoul(buf, &endp, 0);\r\nif (endp == buf || val < min_val || val > max_val)\r\nreturn -EINVAL;\r\nrtnl_lock();\r\nret = (*set) (to_net_dev(d), val);\r\nif (!ret)\r\nret = len;\r\nrtnl_unlock();\r\nreturn ret;\r\n}\r\nstatic ssize_t set_nfilters(struct net_device *dev, unsigned int val)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adap = pi->adapter;\r\nint min_tids = is_offload(adap) ? MC5_MIN_TIDS : 0;\r\nif (adap->flags & FULL_INIT_DONE)\r\nreturn -EBUSY;\r\nif (val && adap->params.rev == 0)\r\nreturn -EINVAL;\r\nif (val > t3_mc5_size(&adap->mc5) - adap->params.mc5.nservers -\r\nmin_tids)\r\nreturn -EINVAL;\r\nadap->params.mc5.nfilters = val;\r\nreturn 0;\r\n}\r\nstatic ssize_t store_nfilters(struct device *d, struct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nreturn attr_store(d, buf, len, set_nfilters, 0, ~0);\r\n}\r\nstatic ssize_t set_nservers(struct net_device *dev, unsigned int val)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adap = pi->adapter;\r\nif (adap->flags & FULL_INIT_DONE)\r\nreturn -EBUSY;\r\nif (val > t3_mc5_size(&adap->mc5) - adap->params.mc5.nfilters -\r\nMC5_MIN_TIDS)\r\nreturn -EINVAL;\r\nadap->params.mc5.nservers = val;\r\nreturn 0;\r\n}\r\nstatic ssize_t store_nservers(struct device *d, struct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nreturn attr_store(d, buf, len, set_nservers, 0, ~0);\r\n}\r\nstatic ssize_t tm_attr_show(struct device *d,\r\nchar *buf, int sched)\r\n{\r\nstruct port_info *pi = netdev_priv(to_net_dev(d));\r\nstruct adapter *adap = pi->adapter;\r\nunsigned int v, addr, bpt, cpt;\r\nssize_t len;\r\naddr = A_TP_TX_MOD_Q1_Q0_RATE_LIMIT - sched / 2;\r\nrtnl_lock();\r\nt3_write_reg(adap, A_TP_TM_PIO_ADDR, addr);\r\nv = t3_read_reg(adap, A_TP_TM_PIO_DATA);\r\nif (sched & 1)\r\nv >>= 16;\r\nbpt = (v >> 8) & 0xff;\r\ncpt = v & 0xff;\r\nif (!cpt)\r\nlen = sprintf(buf, "disabled\n");\r\nelse {\r\nv = (adap->params.vpd.cclk * 1000) / cpt;\r\nlen = sprintf(buf, "%u Kbps\n", (v * bpt) / 125);\r\n}\r\nrtnl_unlock();\r\nreturn len;\r\n}\r\nstatic ssize_t tm_attr_store(struct device *d,\r\nconst char *buf, size_t len, int sched)\r\n{\r\nstruct port_info *pi = netdev_priv(to_net_dev(d));\r\nstruct adapter *adap = pi->adapter;\r\nunsigned int val;\r\nchar *endp;\r\nssize_t ret;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nval = simple_strtoul(buf, &endp, 0);\r\nif (endp == buf || val > 10000000)\r\nreturn -EINVAL;\r\nrtnl_lock();\r\nret = t3_config_sched(adap, val, sched);\r\nif (!ret)\r\nret = len;\r\nrtnl_unlock();\r\nreturn ret;\r\n}\r\nstatic inline int offload_tx(struct t3cdev *tdev, struct sk_buff *skb)\r\n{\r\nint ret;\r\nlocal_bh_disable();\r\nret = t3_offload_tx(tdev, skb);\r\nlocal_bh_enable();\r\nreturn ret;\r\n}\r\nstatic int write_smt_entry(struct adapter *adapter, int idx)\r\n{\r\nstruct cpl_smt_write_req *req;\r\nstruct port_info *pi = netdev_priv(adapter->port[idx]);\r\nstruct sk_buff *skb = alloc_skb(sizeof(*req), GFP_KERNEL);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nreq = (struct cpl_smt_write_req *)__skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SMT_WRITE_REQ, idx));\r\nreq->mtu_idx = NMTUS - 1;\r\nreq->iff = idx;\r\nmemcpy(req->src_mac0, adapter->port[idx]->dev_addr, ETH_ALEN);\r\nmemcpy(req->src_mac1, pi->iscsic.mac_addr, ETH_ALEN);\r\nskb->priority = 1;\r\noffload_tx(&adapter->tdev, skb);\r\nreturn 0;\r\n}\r\nstatic int init_smt(struct adapter *adapter)\r\n{\r\nint i;\r\nfor_each_port(adapter, i)\r\nwrite_smt_entry(adapter, i);\r\nreturn 0;\r\n}\r\nstatic void init_port_mtus(struct adapter *adapter)\r\n{\r\nunsigned int mtus = adapter->port[0]->mtu;\r\nif (adapter->port[1])\r\nmtus |= adapter->port[1]->mtu << 16;\r\nt3_write_reg(adapter, A_TP_MTU_PORT_TABLE, mtus);\r\n}\r\nstatic int send_pktsched_cmd(struct adapter *adap, int sched, int qidx, int lo,\r\nint hi, int port)\r\n{\r\nstruct sk_buff *skb;\r\nstruct mngt_pktsched_wr *req;\r\nint ret;\r\nskb = alloc_skb(sizeof(*req), GFP_KERNEL);\r\nif (!skb)\r\nskb = adap->nofail_skb;\r\nif (!skb)\r\nreturn -ENOMEM;\r\nreq = (struct mngt_pktsched_wr *)skb_put(skb, sizeof(*req));\r\nreq->wr_hi = htonl(V_WR_OP(FW_WROPCODE_MNGT));\r\nreq->mngt_opcode = FW_MNGTOPCODE_PKTSCHED_SET;\r\nreq->sched = sched;\r\nreq->idx = qidx;\r\nreq->min = lo;\r\nreq->max = hi;\r\nreq->binding = port;\r\nret = t3_mgmt_tx(adap, skb);\r\nif (skb == adap->nofail_skb) {\r\nadap->nofail_skb = alloc_skb(sizeof(struct cpl_set_tcb_field),\r\nGFP_KERNEL);\r\nif (!adap->nofail_skb)\r\nret = -ENOMEM;\r\n}\r\nreturn ret;\r\n}\r\nstatic int bind_qsets(struct adapter *adap)\r\n{\r\nint i, j, err = 0;\r\nfor_each_port(adap, i) {\r\nconst struct port_info *pi = adap2pinfo(adap, i);\r\nfor (j = 0; j < pi->nqsets; ++j) {\r\nint ret = send_pktsched_cmd(adap, 1,\r\npi->first_qset + j, -1,\r\n-1, i);\r\nif (ret)\r\nerr = ret;\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic inline const char *get_edc_fw_name(int edc_idx)\r\n{\r\nconst char *fw_name = NULL;\r\nswitch (edc_idx) {\r\ncase EDC_OPT_AEL2005:\r\nfw_name = AEL2005_OPT_EDC_NAME;\r\nbreak;\r\ncase EDC_TWX_AEL2005:\r\nfw_name = AEL2005_TWX_EDC_NAME;\r\nbreak;\r\ncase EDC_TWX_AEL2020:\r\nfw_name = AEL2020_TWX_EDC_NAME;\r\nbreak;\r\n}\r\nreturn fw_name;\r\n}\r\nint t3_get_edc_fw(struct cphy *phy, int edc_idx, int size)\r\n{\r\nstruct adapter *adapter = phy->adapter;\r\nconst struct firmware *fw;\r\nchar buf[64];\r\nu32 csum;\r\nconst __be32 *p;\r\nu16 *cache = phy->phy_cache;\r\nint i, ret;\r\nsnprintf(buf, sizeof(buf), get_edc_fw_name(edc_idx));\r\nret = request_firmware(&fw, buf, &adapter->pdev->dev);\r\nif (ret < 0) {\r\ndev_err(&adapter->pdev->dev,\r\n"could not upgrade firmware: unable to load %s\n",\r\nbuf);\r\nreturn ret;\r\n}\r\nif (fw->size > size + 4) {\r\nCH_ERR(adapter, "firmware image too large %u, expected %d\n",\r\n(unsigned int)fw->size, size + 4);\r\nret = -EINVAL;\r\n}\r\np = (const __be32 *)fw->data;\r\nfor (csum = 0, i = 0; i < fw->size / sizeof(csum); i++)\r\ncsum += ntohl(p[i]);\r\nif (csum != 0xffffffff) {\r\nCH_ERR(adapter, "corrupted firmware image, checksum %u\n",\r\ncsum);\r\nret = -EINVAL;\r\n}\r\nfor (i = 0; i < size / 4 ; i++) {\r\n*cache++ = (be32_to_cpu(p[i]) & 0xffff0000) >> 16;\r\n*cache++ = be32_to_cpu(p[i]) & 0xffff;\r\n}\r\nrelease_firmware(fw);\r\nreturn ret;\r\n}\r\nstatic int upgrade_fw(struct adapter *adap)\r\n{\r\nint ret;\r\nconst struct firmware *fw;\r\nstruct device *dev = &adap->pdev->dev;\r\nret = request_firmware(&fw, FW_FNAME, dev);\r\nif (ret < 0) {\r\ndev_err(dev, "could not upgrade firmware: unable to load %s\n",\r\nFW_FNAME);\r\nreturn ret;\r\n}\r\nret = t3_load_fw(adap, fw->data, fw->size);\r\nrelease_firmware(fw);\r\nif (ret == 0)\r\ndev_info(dev, "successful upgrade to firmware %d.%d.%d\n",\r\nFW_VERSION_MAJOR, FW_VERSION_MINOR, FW_VERSION_MICRO);\r\nelse\r\ndev_err(dev, "failed to upgrade to firmware %d.%d.%d\n",\r\nFW_VERSION_MAJOR, FW_VERSION_MINOR, FW_VERSION_MICRO);\r\nreturn ret;\r\n}\r\nstatic inline char t3rev2char(struct adapter *adapter)\r\n{\r\nchar rev = 0;\r\nswitch(adapter->params.rev) {\r\ncase T3_REV_B:\r\ncase T3_REV_B2:\r\nrev = 'b';\r\nbreak;\r\ncase T3_REV_C:\r\nrev = 'c';\r\nbreak;\r\n}\r\nreturn rev;\r\n}\r\nstatic int update_tpsram(struct adapter *adap)\r\n{\r\nconst struct firmware *tpsram;\r\nchar buf[64];\r\nstruct device *dev = &adap->pdev->dev;\r\nint ret;\r\nchar rev;\r\nrev = t3rev2char(adap);\r\nif (!rev)\r\nreturn 0;\r\nsnprintf(buf, sizeof(buf), TPSRAM_NAME, rev);\r\nret = request_firmware(&tpsram, buf, dev);\r\nif (ret < 0) {\r\ndev_err(dev, "could not load TP SRAM: unable to load %s\n",\r\nbuf);\r\nreturn ret;\r\n}\r\nret = t3_check_tpsram(adap, tpsram->data, tpsram->size);\r\nif (ret)\r\ngoto release_tpsram;\r\nret = t3_set_proto_sram(adap, tpsram->data);\r\nif (ret == 0)\r\ndev_info(dev,\r\n"successful update of protocol engine "\r\n"to %d.%d.%d\n",\r\nTP_VERSION_MAJOR, TP_VERSION_MINOR, TP_VERSION_MICRO);\r\nelse\r\ndev_err(dev, "failed to update of protocol engine %d.%d.%d\n",\r\nTP_VERSION_MAJOR, TP_VERSION_MINOR, TP_VERSION_MICRO);\r\nif (ret)\r\ndev_err(dev, "loading protocol SRAM failed\n");\r\nrelease_tpsram:\r\nrelease_firmware(tpsram);\r\nreturn ret;\r\n}\r\nstatic void t3_synchronize_rx(struct adapter *adap, const struct port_info *p)\r\n{\r\nint i;\r\nfor (i = p->first_qset; i < p->first_qset + p->nqsets; i++) {\r\nstruct sge_rspq *q = &adap->sge.qs[i].rspq;\r\nspin_lock_irq(&q->lock);\r\nspin_unlock_irq(&q->lock);\r\n}\r\n}\r\nstatic void cxgb_vlan_mode(struct net_device *dev, netdev_features_t features)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nif (adapter->params.rev > 0) {\r\nt3_set_vlan_accel(adapter, 1 << pi->port_id,\r\nfeatures & NETIF_F_HW_VLAN_CTAG_RX);\r\n} else {\r\nunsigned int i, have_vlans = features & NETIF_F_HW_VLAN_CTAG_RX;\r\nfor_each_port(adapter, i)\r\nhave_vlans |=\r\nadapter->port[i]->features &\r\nNETIF_F_HW_VLAN_CTAG_RX;\r\nt3_set_vlan_accel(adapter, 1, have_vlans);\r\n}\r\nt3_synchronize_rx(adapter, pi);\r\n}\r\nstatic int cxgb_up(struct adapter *adap)\r\n{\r\nint i, err;\r\nif (!(adap->flags & FULL_INIT_DONE)) {\r\nerr = t3_check_fw_version(adap);\r\nif (err == -EINVAL) {\r\nerr = upgrade_fw(adap);\r\nCH_WARN(adap, "FW upgrade to %d.%d.%d %s\n",\r\nFW_VERSION_MAJOR, FW_VERSION_MINOR,\r\nFW_VERSION_MICRO, err ? "failed" : "succeeded");\r\n}\r\nerr = t3_check_tpsram_version(adap);\r\nif (err == -EINVAL) {\r\nerr = update_tpsram(adap);\r\nCH_WARN(adap, "TP upgrade to %d.%d.%d %s\n",\r\nTP_VERSION_MAJOR, TP_VERSION_MINOR,\r\nTP_VERSION_MICRO, err ? "failed" : "succeeded");\r\n}\r\nt3_intr_clear(adap);\r\nerr = t3_init_hw(adap, 0);\r\nif (err)\r\ngoto out;\r\nt3_set_reg_field(adap, A_TP_PARA_REG5, 0, F_RXDDPOFFINIT);\r\nt3_write_reg(adap, A_ULPRX_TDDP_PSZ, V_HPZ0(PAGE_SHIFT - 12));\r\nerr = setup_sge_qsets(adap);\r\nif (err)\r\ngoto out;\r\nfor_each_port(adap, i)\r\ncxgb_vlan_mode(adap->port[i], adap->port[i]->features);\r\nsetup_rss(adap);\r\nif (!(adap->flags & NAPI_INIT))\r\ninit_napi(adap);\r\nt3_start_sge_timers(adap);\r\nadap->flags |= FULL_INIT_DONE;\r\n}\r\nt3_intr_clear(adap);\r\nif (adap->flags & USING_MSIX) {\r\nname_msix_vecs(adap);\r\nerr = request_irq(adap->msix_info[0].vec,\r\nt3_async_intr_handler, 0,\r\nadap->msix_info[0].desc, adap);\r\nif (err)\r\ngoto irq_err;\r\nerr = request_msix_data_irqs(adap);\r\nif (err) {\r\nfree_irq(adap->msix_info[0].vec, adap);\r\ngoto irq_err;\r\n}\r\n} else if ((err = request_irq(adap->pdev->irq,\r\nt3_intr_handler(adap,\r\nadap->sge.qs[0].rspq.\r\npolling),\r\n(adap->flags & USING_MSI) ?\r\n0 : IRQF_SHARED,\r\nadap->name, adap)))\r\ngoto irq_err;\r\nenable_all_napi(adap);\r\nt3_sge_start(adap);\r\nt3_intr_enable(adap);\r\nif (adap->params.rev >= T3_REV_C && !(adap->flags & TP_PARITY_INIT) &&\r\nis_offload(adap) && init_tp_parity(adap) == 0)\r\nadap->flags |= TP_PARITY_INIT;\r\nif (adap->flags & TP_PARITY_INIT) {\r\nt3_write_reg(adap, A_TP_INT_CAUSE,\r\nF_CMCACHEPERR | F_ARPLUTPERR);\r\nt3_write_reg(adap, A_TP_INT_ENABLE, 0x7fbfffff);\r\n}\r\nif (!(adap->flags & QUEUES_BOUND)) {\r\nint ret = bind_qsets(adap);\r\nif (ret < 0) {\r\nCH_ERR(adap, "failed to bind qsets, err %d\n", ret);\r\nt3_intr_disable(adap);\r\nfree_irq_resources(adap);\r\nerr = ret;\r\ngoto out;\r\n}\r\nadap->flags |= QUEUES_BOUND;\r\n}\r\nout:\r\nreturn err;\r\nirq_err:\r\nCH_ERR(adap, "request_irq failed, err %d\n", err);\r\ngoto out;\r\n}\r\nstatic void cxgb_down(struct adapter *adapter, int on_wq)\r\n{\r\nt3_sge_stop(adapter);\r\nspin_lock_irq(&adapter->work_lock);\r\nt3_intr_disable(adapter);\r\nspin_unlock_irq(&adapter->work_lock);\r\nfree_irq_resources(adapter);\r\nquiesce_rx(adapter);\r\nt3_sge_stop(adapter);\r\nif (!on_wq)\r\nflush_workqueue(cxgb3_wq);\r\n}\r\nstatic void schedule_chk_task(struct adapter *adap)\r\n{\r\nunsigned int timeo;\r\ntimeo = adap->params.linkpoll_period ?\r\n(HZ * adap->params.linkpoll_period) / 10 :\r\nadap->params.stats_update_period * HZ;\r\nif (timeo)\r\nqueue_delayed_work(cxgb3_wq, &adap->adap_check_task, timeo);\r\n}\r\nstatic int offload_open(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nstruct t3cdev *tdev = dev2t3cdev(dev);\r\nint adap_up = adapter->open_device_map & PORT_MASK;\r\nint err;\r\nif (test_and_set_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map))\r\nreturn 0;\r\nif (!adap_up && (err = cxgb_up(adapter)) < 0)\r\ngoto out;\r\nt3_tp_set_offload_mode(adapter, 1);\r\ntdev->lldev = adapter->port[0];\r\nerr = cxgb3_offload_activate(adapter);\r\nif (err)\r\ngoto out;\r\ninit_port_mtus(adapter);\r\nt3_load_mtus(adapter, adapter->params.mtus, adapter->params.a_wnd,\r\nadapter->params.b_wnd,\r\nadapter->params.rev == 0 ?\r\nadapter->port[0]->mtu : 0xffff);\r\ninit_smt(adapter);\r\nif (sysfs_create_group(&tdev->lldev->dev.kobj, &offload_attr_group))\r\ndev_dbg(&dev->dev, "cannot create sysfs group\n");\r\ncxgb3_add_clients(tdev);\r\nout:\r\nif (err) {\r\nt3_tp_set_offload_mode(adapter, 0);\r\nclear_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map);\r\ncxgb3_set_dummy_ops(tdev);\r\n}\r\nreturn err;\r\n}\r\nstatic int offload_close(struct t3cdev *tdev)\r\n{\r\nstruct adapter *adapter = tdev2adap(tdev);\r\nstruct t3c_data *td = T3C_DATA(tdev);\r\nif (!test_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map))\r\nreturn 0;\r\ncxgb3_remove_clients(tdev);\r\nsysfs_remove_group(&tdev->lldev->dev.kobj, &offload_attr_group);\r\nflush_work(&td->tid_release_task);\r\ntdev->lldev = NULL;\r\ncxgb3_set_dummy_ops(tdev);\r\nt3_tp_set_offload_mode(adapter, 0);\r\nclear_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map);\r\nif (!adapter->open_device_map)\r\ncxgb_down(adapter, 0);\r\ncxgb3_offload_deactivate(adapter);\r\nreturn 0;\r\n}\r\nstatic int cxgb_open(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nint other_ports = adapter->open_device_map & PORT_MASK;\r\nint err;\r\nif (!adapter->open_device_map && (err = cxgb_up(adapter)) < 0)\r\nreturn err;\r\nset_bit(pi->port_id, &adapter->open_device_map);\r\nif (is_offload(adapter) && !ofld_disable) {\r\nerr = offload_open(dev);\r\nif (err)\r\npr_warn("Could not initialize offload capabilities\n");\r\n}\r\nnetif_set_real_num_tx_queues(dev, pi->nqsets);\r\nerr = netif_set_real_num_rx_queues(dev, pi->nqsets);\r\nif (err)\r\nreturn err;\r\nlink_start(dev);\r\nt3_port_intr_enable(adapter, pi->port_id);\r\nnetif_tx_start_all_queues(dev);\r\nif (!other_ports)\r\nschedule_chk_task(adapter);\r\ncxgb3_event_notify(&adapter->tdev, OFFLOAD_PORT_UP, pi->port_id);\r\nreturn 0;\r\n}\r\nstatic int __cxgb_close(struct net_device *dev, int on_wq)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nif (!adapter->open_device_map)\r\nreturn 0;\r\nt3_xgm_intr_disable(adapter, pi->port_id);\r\nt3_read_reg(adapter, A_XGM_INT_STATUS + pi->mac.offset);\r\nt3_port_intr_disable(adapter, pi->port_id);\r\nnetif_tx_stop_all_queues(dev);\r\npi->phy.ops->power_down(&pi->phy, 1);\r\nnetif_carrier_off(dev);\r\nt3_mac_disable(&pi->mac, MAC_DIRECTION_TX | MAC_DIRECTION_RX);\r\nspin_lock_irq(&adapter->work_lock);\r\nclear_bit(pi->port_id, &adapter->open_device_map);\r\nspin_unlock_irq(&adapter->work_lock);\r\nif (!(adapter->open_device_map & PORT_MASK))\r\ncancel_delayed_work_sync(&adapter->adap_check_task);\r\nif (!adapter->open_device_map)\r\ncxgb_down(adapter, on_wq);\r\ncxgb3_event_notify(&adapter->tdev, OFFLOAD_PORT_DOWN, pi->port_id);\r\nreturn 0;\r\n}\r\nstatic int cxgb_close(struct net_device *dev)\r\n{\r\nreturn __cxgb_close(dev, 0);\r\n}\r\nstatic struct net_device_stats *cxgb_get_stats(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nstruct net_device_stats *ns = &pi->netstats;\r\nconst struct mac_stats *pstats;\r\nspin_lock(&adapter->stats_lock);\r\npstats = t3_mac_update_stats(&pi->mac);\r\nspin_unlock(&adapter->stats_lock);\r\nns->tx_bytes = pstats->tx_octets;\r\nns->tx_packets = pstats->tx_frames;\r\nns->rx_bytes = pstats->rx_octets;\r\nns->rx_packets = pstats->rx_frames;\r\nns->multicast = pstats->rx_mcast_frames;\r\nns->tx_errors = pstats->tx_underrun;\r\nns->rx_errors = pstats->rx_symbol_errs + pstats->rx_fcs_errs +\r\npstats->rx_too_long + pstats->rx_jabber + pstats->rx_short +\r\npstats->rx_fifo_ovfl;\r\nns->rx_length_errors = pstats->rx_jabber + pstats->rx_too_long;\r\nns->rx_over_errors = 0;\r\nns->rx_crc_errors = pstats->rx_fcs_errs;\r\nns->rx_frame_errors = pstats->rx_symbol_errs;\r\nns->rx_fifo_errors = pstats->rx_fifo_ovfl;\r\nns->rx_missed_errors = pstats->rx_cong_drops;\r\nns->tx_aborted_errors = 0;\r\nns->tx_carrier_errors = 0;\r\nns->tx_fifo_errors = pstats->tx_underrun;\r\nns->tx_heartbeat_errors = 0;\r\nns->tx_window_errors = 0;\r\nreturn ns;\r\n}\r\nstatic u32 get_msglevel(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nreturn adapter->msg_enable;\r\n}\r\nstatic void set_msglevel(struct net_device *dev, u32 val)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nadapter->msg_enable = val;\r\n}\r\nstatic int get_sset_count(struct net_device *dev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn ARRAY_SIZE(stats_strings);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic int get_regs_len(struct net_device *dev)\r\n{\r\nreturn T3_REGMAP_SIZE;\r\n}\r\nstatic int get_eeprom_len(struct net_device *dev)\r\n{\r\nreturn EEPROMSIZE;\r\n}\r\nstatic void get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nu32 fw_vers = 0;\r\nu32 tp_vers = 0;\r\nspin_lock(&adapter->stats_lock);\r\nt3_get_fw_version(adapter, &fw_vers);\r\nt3_get_tp_version(adapter, &tp_vers);\r\nspin_unlock(&adapter->stats_lock);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(adapter->pdev),\r\nsizeof(info->bus_info));\r\nif (fw_vers)\r\nsnprintf(info->fw_version, sizeof(info->fw_version),\r\n"%s %u.%u.%u TP %u.%u.%u",\r\nG_FW_VERSION_TYPE(fw_vers) ? "T" : "N",\r\nG_FW_VERSION_MAJOR(fw_vers),\r\nG_FW_VERSION_MINOR(fw_vers),\r\nG_FW_VERSION_MICRO(fw_vers),\r\nG_TP_VERSION_MAJOR(tp_vers),\r\nG_TP_VERSION_MINOR(tp_vers),\r\nG_TP_VERSION_MICRO(tp_vers));\r\n}\r\nstatic void get_strings(struct net_device *dev, u32 stringset, u8 * data)\r\n{\r\nif (stringset == ETH_SS_STATS)\r\nmemcpy(data, stats_strings, sizeof(stats_strings));\r\n}\r\nstatic unsigned long collect_sge_port_stats(struct adapter *adapter,\r\nstruct port_info *p, int idx)\r\n{\r\nint i;\r\nunsigned long tot = 0;\r\nfor (i = p->first_qset; i < p->first_qset + p->nqsets; ++i)\r\ntot += adapter->sge.qs[i].port_stats[idx];\r\nreturn tot;\r\n}\r\nstatic void get_stats(struct net_device *dev, struct ethtool_stats *stats,\r\nu64 *data)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nconst struct mac_stats *s;\r\nspin_lock(&adapter->stats_lock);\r\ns = t3_mac_update_stats(&pi->mac);\r\nspin_unlock(&adapter->stats_lock);\r\n*data++ = s->tx_octets;\r\n*data++ = s->tx_frames;\r\n*data++ = s->tx_mcast_frames;\r\n*data++ = s->tx_bcast_frames;\r\n*data++ = s->tx_pause;\r\n*data++ = s->tx_underrun;\r\n*data++ = s->tx_fifo_urun;\r\n*data++ = s->tx_frames_64;\r\n*data++ = s->tx_frames_65_127;\r\n*data++ = s->tx_frames_128_255;\r\n*data++ = s->tx_frames_256_511;\r\n*data++ = s->tx_frames_512_1023;\r\n*data++ = s->tx_frames_1024_1518;\r\n*data++ = s->tx_frames_1519_max;\r\n*data++ = s->rx_octets;\r\n*data++ = s->rx_frames;\r\n*data++ = s->rx_mcast_frames;\r\n*data++ = s->rx_bcast_frames;\r\n*data++ = s->rx_pause;\r\n*data++ = s->rx_fcs_errs;\r\n*data++ = s->rx_symbol_errs;\r\n*data++ = s->rx_short;\r\n*data++ = s->rx_jabber;\r\n*data++ = s->rx_too_long;\r\n*data++ = s->rx_fifo_ovfl;\r\n*data++ = s->rx_frames_64;\r\n*data++ = s->rx_frames_65_127;\r\n*data++ = s->rx_frames_128_255;\r\n*data++ = s->rx_frames_256_511;\r\n*data++ = s->rx_frames_512_1023;\r\n*data++ = s->rx_frames_1024_1518;\r\n*data++ = s->rx_frames_1519_max;\r\n*data++ = pi->phy.fifo_errors;\r\n*data++ = collect_sge_port_stats(adapter, pi, SGE_PSTAT_TSO);\r\n*data++ = collect_sge_port_stats(adapter, pi, SGE_PSTAT_VLANEX);\r\n*data++ = collect_sge_port_stats(adapter, pi, SGE_PSTAT_VLANINS);\r\n*data++ = collect_sge_port_stats(adapter, pi, SGE_PSTAT_TX_CSUM);\r\n*data++ = collect_sge_port_stats(adapter, pi, SGE_PSTAT_RX_CSUM_GOOD);\r\n*data++ = 0;\r\n*data++ = 0;\r\n*data++ = 0;\r\n*data++ = s->rx_cong_drops;\r\n*data++ = s->num_toggled;\r\n*data++ = s->num_resets;\r\n*data++ = s->link_faults;\r\n}\r\nstatic inline void reg_block_dump(struct adapter *ap, void *buf,\r\nunsigned int start, unsigned int end)\r\n{\r\nu32 *p = buf + start;\r\nfor (; start <= end; start += sizeof(u32))\r\n*p++ = t3_read_reg(ap, start);\r\n}\r\nstatic void get_regs(struct net_device *dev, struct ethtool_regs *regs,\r\nvoid *buf)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *ap = pi->adapter;\r\nregs->version = 3 | (ap->params.rev << 10) | (is_pcie(ap) << 31);\r\nmemset(buf, 0, T3_REGMAP_SIZE);\r\nreg_block_dump(ap, buf, 0, A_SG_RSPQ_CREDIT_RETURN);\r\nreg_block_dump(ap, buf, A_SG_HI_DRB_HI_THRSH, A_ULPRX_PBL_ULIMIT);\r\nreg_block_dump(ap, buf, A_ULPTX_CONFIG, A_MPS_INT_CAUSE);\r\nreg_block_dump(ap, buf, A_CPL_SWITCH_CNTRL, A_CPL_MAP_TBL_DATA);\r\nreg_block_dump(ap, buf, A_SMB_GLOBAL_TIME_CFG, A_XGM_SERDES_STAT3);\r\nreg_block_dump(ap, buf, A_XGM_SERDES_STATUS0,\r\nXGM_REG(A_XGM_SERDES_STAT3, 1));\r\nreg_block_dump(ap, buf, XGM_REG(A_XGM_SERDES_STATUS0, 1),\r\nXGM_REG(A_XGM_RX_SPI4_SOP_EOP_CNT, 1));\r\n}\r\nstatic int restart_autoneg(struct net_device *dev)\r\n{\r\nstruct port_info *p = netdev_priv(dev);\r\nif (!netif_running(dev))\r\nreturn -EAGAIN;\r\nif (p->link_config.autoneg != AUTONEG_ENABLE)\r\nreturn -EINVAL;\r\np->phy.ops->autoneg_restart(&p->phy);\r\nreturn 0;\r\n}\r\nstatic int set_phys_id(struct net_device *dev,\r\nenum ethtool_phys_id_state state)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nswitch (state) {\r\ncase ETHTOOL_ID_ACTIVE:\r\nreturn 1;\r\ncase ETHTOOL_ID_OFF:\r\nt3_set_reg_field(adapter, A_T3DBG_GPIO_EN, F_GPIO0_OUT_VAL, 0);\r\nbreak;\r\ncase ETHTOOL_ID_ON:\r\ncase ETHTOOL_ID_INACTIVE:\r\nt3_set_reg_field(adapter, A_T3DBG_GPIO_EN, F_GPIO0_OUT_VAL,\r\nF_GPIO0_OUT_VAL);\r\n}\r\nreturn 0;\r\n}\r\nstatic int get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct port_info *p = netdev_priv(dev);\r\ncmd->supported = p->link_config.supported;\r\ncmd->advertising = p->link_config.advertising;\r\nif (netif_carrier_ok(dev)) {\r\nethtool_cmd_speed_set(cmd, p->link_config.speed);\r\ncmd->duplex = p->link_config.duplex;\r\n} else {\r\nethtool_cmd_speed_set(cmd, -1);\r\ncmd->duplex = -1;\r\n}\r\ncmd->port = (cmd->supported & SUPPORTED_TP) ? PORT_TP : PORT_FIBRE;\r\ncmd->phy_address = p->phy.mdio.prtad;\r\ncmd->transceiver = XCVR_EXTERNAL;\r\ncmd->autoneg = p->link_config.autoneg;\r\ncmd->maxtxpkt = 0;\r\ncmd->maxrxpkt = 0;\r\nreturn 0;\r\n}\r\nstatic int speed_duplex_to_caps(int speed, int duplex)\r\n{\r\nint cap = 0;\r\nswitch (speed) {\r\ncase SPEED_10:\r\nif (duplex == DUPLEX_FULL)\r\ncap = SUPPORTED_10baseT_Full;\r\nelse\r\ncap = SUPPORTED_10baseT_Half;\r\nbreak;\r\ncase SPEED_100:\r\nif (duplex == DUPLEX_FULL)\r\ncap = SUPPORTED_100baseT_Full;\r\nelse\r\ncap = SUPPORTED_100baseT_Half;\r\nbreak;\r\ncase SPEED_1000:\r\nif (duplex == DUPLEX_FULL)\r\ncap = SUPPORTED_1000baseT_Full;\r\nelse\r\ncap = SUPPORTED_1000baseT_Half;\r\nbreak;\r\ncase SPEED_10000:\r\nif (duplex == DUPLEX_FULL)\r\ncap = SUPPORTED_10000baseT_Full;\r\n}\r\nreturn cap;\r\n}\r\nstatic int set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct port_info *p = netdev_priv(dev);\r\nstruct link_config *lc = &p->link_config;\r\nif (!(lc->supported & SUPPORTED_Autoneg)) {\r\nif (cmd->autoneg == AUTONEG_DISABLE) {\r\nu32 speed = ethtool_cmd_speed(cmd);\r\nint cap = speed_duplex_to_caps(speed, cmd->duplex);\r\nif (lc->supported & cap)\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nif (cmd->autoneg == AUTONEG_DISABLE) {\r\nu32 speed = ethtool_cmd_speed(cmd);\r\nint cap = speed_duplex_to_caps(speed, cmd->duplex);\r\nif (!(lc->supported & cap) || (speed == SPEED_1000))\r\nreturn -EINVAL;\r\nlc->requested_speed = speed;\r\nlc->requested_duplex = cmd->duplex;\r\nlc->advertising = 0;\r\n} else {\r\ncmd->advertising &= ADVERTISED_MASK;\r\ncmd->advertising &= lc->supported;\r\nif (!cmd->advertising)\r\nreturn -EINVAL;\r\nlc->requested_speed = SPEED_INVALID;\r\nlc->requested_duplex = DUPLEX_INVALID;\r\nlc->advertising = cmd->advertising | ADVERTISED_Autoneg;\r\n}\r\nlc->autoneg = cmd->autoneg;\r\nif (netif_running(dev))\r\nt3_link_start(&p->phy, &p->mac, lc);\r\nreturn 0;\r\n}\r\nstatic void get_pauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *epause)\r\n{\r\nstruct port_info *p = netdev_priv(dev);\r\nepause->autoneg = (p->link_config.requested_fc & PAUSE_AUTONEG) != 0;\r\nepause->rx_pause = (p->link_config.fc & PAUSE_RX) != 0;\r\nepause->tx_pause = (p->link_config.fc & PAUSE_TX) != 0;\r\n}\r\nstatic int set_pauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *epause)\r\n{\r\nstruct port_info *p = netdev_priv(dev);\r\nstruct link_config *lc = &p->link_config;\r\nif (epause->autoneg == AUTONEG_DISABLE)\r\nlc->requested_fc = 0;\r\nelse if (lc->supported & SUPPORTED_Autoneg)\r\nlc->requested_fc = PAUSE_AUTONEG;\r\nelse\r\nreturn -EINVAL;\r\nif (epause->rx_pause)\r\nlc->requested_fc |= PAUSE_RX;\r\nif (epause->tx_pause)\r\nlc->requested_fc |= PAUSE_TX;\r\nif (lc->autoneg == AUTONEG_ENABLE) {\r\nif (netif_running(dev))\r\nt3_link_start(&p->phy, &p->mac, lc);\r\n} else {\r\nlc->fc = lc->requested_fc & (PAUSE_RX | PAUSE_TX);\r\nif (netif_running(dev))\r\nt3_mac_set_speed_duplex_fc(&p->mac, -1, -1, lc->fc);\r\n}\r\nreturn 0;\r\n}\r\nstatic void get_sge_param(struct net_device *dev, struct ethtool_ringparam *e)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nconst struct qset_params *q = &adapter->params.sge.qset[pi->first_qset];\r\ne->rx_max_pending = MAX_RX_BUFFERS;\r\ne->rx_jumbo_max_pending = MAX_RX_JUMBO_BUFFERS;\r\ne->tx_max_pending = MAX_TXQ_ENTRIES;\r\ne->rx_pending = q->fl_size;\r\ne->rx_mini_pending = q->rspq_size;\r\ne->rx_jumbo_pending = q->jumbo_size;\r\ne->tx_pending = q->txq_size[0];\r\n}\r\nstatic int set_sge_param(struct net_device *dev, struct ethtool_ringparam *e)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nstruct qset_params *q;\r\nint i;\r\nif (e->rx_pending > MAX_RX_BUFFERS ||\r\ne->rx_jumbo_pending > MAX_RX_JUMBO_BUFFERS ||\r\ne->tx_pending > MAX_TXQ_ENTRIES ||\r\ne->rx_mini_pending > MAX_RSPQ_ENTRIES ||\r\ne->rx_mini_pending < MIN_RSPQ_ENTRIES ||\r\ne->rx_pending < MIN_FL_ENTRIES ||\r\ne->rx_jumbo_pending < MIN_FL_ENTRIES ||\r\ne->tx_pending < adapter->params.nports * MIN_TXQ_ENTRIES)\r\nreturn -EINVAL;\r\nif (adapter->flags & FULL_INIT_DONE)\r\nreturn -EBUSY;\r\nq = &adapter->params.sge.qset[pi->first_qset];\r\nfor (i = 0; i < pi->nqsets; ++i, ++q) {\r\nq->rspq_size = e->rx_mini_pending;\r\nq->fl_size = e->rx_pending;\r\nq->jumbo_size = e->rx_jumbo_pending;\r\nq->txq_size[0] = e->tx_pending;\r\nq->txq_size[1] = e->tx_pending;\r\nq->txq_size[2] = e->tx_pending;\r\n}\r\nreturn 0;\r\n}\r\nstatic int set_coalesce(struct net_device *dev, struct ethtool_coalesce *c)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nstruct qset_params *qsp;\r\nstruct sge_qset *qs;\r\nint i;\r\nif (c->rx_coalesce_usecs * 10 > M_NEWTIMER)\r\nreturn -EINVAL;\r\nfor (i = 0; i < pi->nqsets; i++) {\r\nqsp = &adapter->params.sge.qset[i];\r\nqs = &adapter->sge.qs[i];\r\nqsp->coalesce_usecs = c->rx_coalesce_usecs;\r\nt3_update_qset_coalesce(qs, qsp);\r\n}\r\nreturn 0;\r\n}\r\nstatic int get_coalesce(struct net_device *dev, struct ethtool_coalesce *c)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nstruct qset_params *q = adapter->params.sge.qset;\r\nc->rx_coalesce_usecs = q->coalesce_usecs;\r\nreturn 0;\r\n}\r\nstatic int get_eeprom(struct net_device *dev, struct ethtool_eeprom *e,\r\nu8 * data)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nint i, err = 0;\r\nu8 *buf = kmalloc(EEPROMSIZE, GFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\ne->magic = EEPROM_MAGIC;\r\nfor (i = e->offset & ~3; !err && i < e->offset + e->len; i += 4)\r\nerr = t3_seeprom_read(adapter, i, (__le32 *) & buf[i]);\r\nif (!err)\r\nmemcpy(data, buf + e->offset, e->len);\r\nkfree(buf);\r\nreturn err;\r\n}\r\nstatic int set_eeprom(struct net_device *dev, struct ethtool_eeprom *eeprom,\r\nu8 * data)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nu32 aligned_offset, aligned_len;\r\n__le32 *p;\r\nu8 *buf;\r\nint err;\r\nif (eeprom->magic != EEPROM_MAGIC)\r\nreturn -EINVAL;\r\naligned_offset = eeprom->offset & ~3;\r\naligned_len = (eeprom->len + (eeprom->offset & 3) + 3) & ~3;\r\nif (aligned_offset != eeprom->offset || aligned_len != eeprom->len) {\r\nbuf = kmalloc(aligned_len, GFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\nerr = t3_seeprom_read(adapter, aligned_offset, (__le32 *) buf);\r\nif (!err && aligned_len > 4)\r\nerr = t3_seeprom_read(adapter,\r\naligned_offset + aligned_len - 4,\r\n(__le32 *) & buf[aligned_len - 4]);\r\nif (err)\r\ngoto out;\r\nmemcpy(buf + (eeprom->offset & 3), data, eeprom->len);\r\n} else\r\nbuf = data;\r\nerr = t3_seeprom_wp(adapter, 0);\r\nif (err)\r\ngoto out;\r\nfor (p = (__le32 *) buf; !err && aligned_len; aligned_len -= 4, p++) {\r\nerr = t3_seeprom_write(adapter, aligned_offset, *p);\r\naligned_offset += 4;\r\n}\r\nif (!err)\r\nerr = t3_seeprom_wp(adapter, 1);\r\nout:\r\nif (buf != data)\r\nkfree(buf);\r\nreturn err;\r\n}\r\nstatic void get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nwol->supported = 0;\r\nwol->wolopts = 0;\r\nmemset(&wol->sopass, 0, sizeof(wol->sopass));\r\n}\r\nstatic int in_range(int val, int lo, int hi)\r\n{\r\nreturn val < 0 || (val <= hi && val >= lo);\r\n}\r\nstatic int cxgb_extension_ioctl(struct net_device *dev, void __user *useraddr)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nu32 cmd;\r\nint ret;\r\nif (copy_from_user(&cmd, useraddr, sizeof(cmd)))\r\nreturn -EFAULT;\r\nswitch (cmd) {\r\ncase CHELSIO_SET_QSET_PARAMS:{\r\nint i;\r\nstruct qset_params *q;\r\nstruct ch_qset_params t;\r\nint q1 = pi->first_qset;\r\nint nqsets = pi->nqsets;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (copy_from_user(&t, useraddr, sizeof(t)))\r\nreturn -EFAULT;\r\nif (t.qset_idx >= SGE_QSETS)\r\nreturn -EINVAL;\r\nif (!in_range(t.intr_lat, 0, M_NEWTIMER) ||\r\n!in_range(t.cong_thres, 0, 255) ||\r\n!in_range(t.txq_size[0], MIN_TXQ_ENTRIES,\r\nMAX_TXQ_ENTRIES) ||\r\n!in_range(t.txq_size[1], MIN_TXQ_ENTRIES,\r\nMAX_TXQ_ENTRIES) ||\r\n!in_range(t.txq_size[2], MIN_CTRL_TXQ_ENTRIES,\r\nMAX_CTRL_TXQ_ENTRIES) ||\r\n!in_range(t.fl_size[0], MIN_FL_ENTRIES,\r\nMAX_RX_BUFFERS) ||\r\n!in_range(t.fl_size[1], MIN_FL_ENTRIES,\r\nMAX_RX_JUMBO_BUFFERS) ||\r\n!in_range(t.rspq_size, MIN_RSPQ_ENTRIES,\r\nMAX_RSPQ_ENTRIES))\r\nreturn -EINVAL;\r\nif ((adapter->flags & FULL_INIT_DONE) &&\r\n(t.rspq_size >= 0 || t.fl_size[0] >= 0 ||\r\nt.fl_size[1] >= 0 || t.txq_size[0] >= 0 ||\r\nt.txq_size[1] >= 0 || t.txq_size[2] >= 0 ||\r\nt.polling >= 0 || t.cong_thres >= 0))\r\nreturn -EBUSY;\r\nif (test_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map)) {\r\nq1 = 0;\r\nfor_each_port(adapter, i) {\r\npi = adap2pinfo(adapter, i);\r\nnqsets += pi->first_qset + pi->nqsets;\r\n}\r\n}\r\nif (t.qset_idx < q1)\r\nreturn -EINVAL;\r\nif (t.qset_idx > q1 + nqsets - 1)\r\nreturn -EINVAL;\r\nq = &adapter->params.sge.qset[t.qset_idx];\r\nif (t.rspq_size >= 0)\r\nq->rspq_size = t.rspq_size;\r\nif (t.fl_size[0] >= 0)\r\nq->fl_size = t.fl_size[0];\r\nif (t.fl_size[1] >= 0)\r\nq->jumbo_size = t.fl_size[1];\r\nif (t.txq_size[0] >= 0)\r\nq->txq_size[0] = t.txq_size[0];\r\nif (t.txq_size[1] >= 0)\r\nq->txq_size[1] = t.txq_size[1];\r\nif (t.txq_size[2] >= 0)\r\nq->txq_size[2] = t.txq_size[2];\r\nif (t.cong_thres >= 0)\r\nq->cong_thres = t.cong_thres;\r\nif (t.intr_lat >= 0) {\r\nstruct sge_qset *qs =\r\n&adapter->sge.qs[t.qset_idx];\r\nq->coalesce_usecs = t.intr_lat;\r\nt3_update_qset_coalesce(qs, q);\r\n}\r\nif (t.polling >= 0) {\r\nif (adapter->flags & USING_MSIX)\r\nq->polling = t.polling;\r\nelse {\r\nif (adapter->params.rev == 0 &&\r\n!(adapter->flags & USING_MSI))\r\nt.polling = 0;\r\nfor (i = 0; i < SGE_QSETS; i++) {\r\nq = &adapter->params.sge.\r\nqset[i];\r\nq->polling = t.polling;\r\n}\r\n}\r\n}\r\nif (t.lro >= 0) {\r\nif (t.lro)\r\ndev->wanted_features |= NETIF_F_GRO;\r\nelse\r\ndev->wanted_features &= ~NETIF_F_GRO;\r\nnetdev_update_features(dev);\r\n}\r\nbreak;\r\n}\r\ncase CHELSIO_GET_QSET_PARAMS:{\r\nstruct qset_params *q;\r\nstruct ch_qset_params t;\r\nint q1 = pi->first_qset;\r\nint nqsets = pi->nqsets;\r\nint i;\r\nif (copy_from_user(&t, useraddr, sizeof(t)))\r\nreturn -EFAULT;\r\nif (test_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map)) {\r\nq1 = 0;\r\nfor_each_port(adapter, i) {\r\npi = adap2pinfo(adapter, i);\r\nnqsets = pi->first_qset + pi->nqsets;\r\n}\r\n}\r\nif (t.qset_idx >= nqsets)\r\nreturn -EINVAL;\r\nq = &adapter->params.sge.qset[q1 + t.qset_idx];\r\nt.rspq_size = q->rspq_size;\r\nt.txq_size[0] = q->txq_size[0];\r\nt.txq_size[1] = q->txq_size[1];\r\nt.txq_size[2] = q->txq_size[2];\r\nt.fl_size[0] = q->fl_size;\r\nt.fl_size[1] = q->jumbo_size;\r\nt.polling = q->polling;\r\nt.lro = !!(dev->features & NETIF_F_GRO);\r\nt.intr_lat = q->coalesce_usecs;\r\nt.cong_thres = q->cong_thres;\r\nt.qnum = q1;\r\nif (adapter->flags & USING_MSIX)\r\nt.vector = adapter->msix_info[q1 + t.qset_idx + 1].vec;\r\nelse\r\nt.vector = adapter->pdev->irq;\r\nif (copy_to_user(useraddr, &t, sizeof(t)))\r\nreturn -EFAULT;\r\nbreak;\r\n}\r\ncase CHELSIO_SET_QSET_NUM:{\r\nstruct ch_reg edata;\r\nunsigned int i, first_qset = 0, other_qsets = 0;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (adapter->flags & FULL_INIT_DONE)\r\nreturn -EBUSY;\r\nif (copy_from_user(&edata, useraddr, sizeof(edata)))\r\nreturn -EFAULT;\r\nif (edata.val < 1 ||\r\n(edata.val > 1 && !(adapter->flags & USING_MSIX)))\r\nreturn -EINVAL;\r\nfor_each_port(adapter, i)\r\nif (adapter->port[i] && adapter->port[i] != dev)\r\nother_qsets += adap2pinfo(adapter, i)->nqsets;\r\nif (edata.val + other_qsets > SGE_QSETS)\r\nreturn -EINVAL;\r\npi->nqsets = edata.val;\r\nfor_each_port(adapter, i)\r\nif (adapter->port[i]) {\r\npi = adap2pinfo(adapter, i);\r\npi->first_qset = first_qset;\r\nfirst_qset += pi->nqsets;\r\n}\r\nbreak;\r\n}\r\ncase CHELSIO_GET_QSET_NUM:{\r\nstruct ch_reg edata;\r\nmemset(&edata, 0, sizeof(struct ch_reg));\r\nedata.cmd = CHELSIO_GET_QSET_NUM;\r\nedata.val = pi->nqsets;\r\nif (copy_to_user(useraddr, &edata, sizeof(edata)))\r\nreturn -EFAULT;\r\nbreak;\r\n}\r\ncase CHELSIO_LOAD_FW:{\r\nu8 *fw_data;\r\nstruct ch_mem_range t;\r\nif (!capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\nif (copy_from_user(&t, useraddr, sizeof(t)))\r\nreturn -EFAULT;\r\nfw_data = memdup_user(useraddr + sizeof(t), t.len);\r\nif (IS_ERR(fw_data))\r\nreturn PTR_ERR(fw_data);\r\nret = t3_load_fw(adapter, fw_data, t.len);\r\nkfree(fw_data);\r\nif (ret)\r\nreturn ret;\r\nbreak;\r\n}\r\ncase CHELSIO_SETMTUTAB:{\r\nstruct ch_mtus m;\r\nint i;\r\nif (!is_offload(adapter))\r\nreturn -EOPNOTSUPP;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (offload_running(adapter))\r\nreturn -EBUSY;\r\nif (copy_from_user(&m, useraddr, sizeof(m)))\r\nreturn -EFAULT;\r\nif (m.nmtus != NMTUS)\r\nreturn -EINVAL;\r\nif (m.mtus[0] < 81)\r\nreturn -EINVAL;\r\nfor (i = 1; i < NMTUS; ++i)\r\nif (m.mtus[i] < m.mtus[i - 1])\r\nreturn -EINVAL;\r\nmemcpy(adapter->params.mtus, m.mtus,\r\nsizeof(adapter->params.mtus));\r\nbreak;\r\n}\r\ncase CHELSIO_GET_PM:{\r\nstruct tp_params *p = &adapter->params.tp;\r\nstruct ch_pm m = {.cmd = CHELSIO_GET_PM };\r\nif (!is_offload(adapter))\r\nreturn -EOPNOTSUPP;\r\nm.tx_pg_sz = p->tx_pg_size;\r\nm.tx_num_pg = p->tx_num_pgs;\r\nm.rx_pg_sz = p->rx_pg_size;\r\nm.rx_num_pg = p->rx_num_pgs;\r\nm.pm_total = p->pmtx_size + p->chan_rx_size * p->nchan;\r\nif (copy_to_user(useraddr, &m, sizeof(m)))\r\nreturn -EFAULT;\r\nbreak;\r\n}\r\ncase CHELSIO_SET_PM:{\r\nstruct ch_pm m;\r\nstruct tp_params *p = &adapter->params.tp;\r\nif (!is_offload(adapter))\r\nreturn -EOPNOTSUPP;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (adapter->flags & FULL_INIT_DONE)\r\nreturn -EBUSY;\r\nif (copy_from_user(&m, useraddr, sizeof(m)))\r\nreturn -EFAULT;\r\nif (!is_power_of_2(m.rx_pg_sz) ||\r\n!is_power_of_2(m.tx_pg_sz))\r\nreturn -EINVAL;\r\nif (!(m.rx_pg_sz & 0x14000))\r\nreturn -EINVAL;\r\nif (!(m.tx_pg_sz & 0x1554000))\r\nreturn -EINVAL;\r\nif (m.tx_num_pg == -1)\r\nm.tx_num_pg = p->tx_num_pgs;\r\nif (m.rx_num_pg == -1)\r\nm.rx_num_pg = p->rx_num_pgs;\r\nif (m.tx_num_pg % 24 || m.rx_num_pg % 24)\r\nreturn -EINVAL;\r\nif (m.rx_num_pg * m.rx_pg_sz > p->chan_rx_size ||\r\nm.tx_num_pg * m.tx_pg_sz > p->chan_tx_size)\r\nreturn -EINVAL;\r\np->rx_pg_size = m.rx_pg_sz;\r\np->tx_pg_size = m.tx_pg_sz;\r\np->rx_num_pgs = m.rx_num_pg;\r\np->tx_num_pgs = m.tx_num_pg;\r\nbreak;\r\n}\r\ncase CHELSIO_GET_MEM:{\r\nstruct ch_mem_range t;\r\nstruct mc7 *mem;\r\nu64 buf[32];\r\nif (!is_offload(adapter))\r\nreturn -EOPNOTSUPP;\r\nif (!(adapter->flags & FULL_INIT_DONE))\r\nreturn -EIO;\r\nif (copy_from_user(&t, useraddr, sizeof(t)))\r\nreturn -EFAULT;\r\nif ((t.addr & 7) || (t.len & 7))\r\nreturn -EINVAL;\r\nif (t.mem_id == MEM_CM)\r\nmem = &adapter->cm;\r\nelse if (t.mem_id == MEM_PMRX)\r\nmem = &adapter->pmrx;\r\nelse if (t.mem_id == MEM_PMTX)\r\nmem = &adapter->pmtx;\r\nelse\r\nreturn -EINVAL;\r\nt.version = 3 | (adapter->params.rev << 10);\r\nif (copy_to_user(useraddr, &t, sizeof(t)))\r\nreturn -EFAULT;\r\nuseraddr += sizeof(t);\r\nwhile (t.len) {\r\nunsigned int chunk =\r\nmin_t(unsigned int, t.len, sizeof(buf));\r\nret =\r\nt3_mc7_bd_read(mem, t.addr / 8, chunk / 8,\r\nbuf);\r\nif (ret)\r\nreturn ret;\r\nif (copy_to_user(useraddr, buf, chunk))\r\nreturn -EFAULT;\r\nuseraddr += chunk;\r\nt.addr += chunk;\r\nt.len -= chunk;\r\n}\r\nbreak;\r\n}\r\ncase CHELSIO_SET_TRACE_FILTER:{\r\nstruct ch_trace t;\r\nconst struct trace_params *tp;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (!offload_running(adapter))\r\nreturn -EAGAIN;\r\nif (copy_from_user(&t, useraddr, sizeof(t)))\r\nreturn -EFAULT;\r\ntp = (const struct trace_params *)&t.sip;\r\nif (t.config_tx)\r\nt3_config_trace_filter(adapter, tp, 0,\r\nt.invert_match,\r\nt.trace_tx);\r\nif (t.config_rx)\r\nt3_config_trace_filter(adapter, tp, 1,\r\nt.invert_match,\r\nt.trace_rx);\r\nbreak;\r\n}\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cxgb_ioctl(struct net_device *dev, struct ifreq *req, int cmd)\r\n{\r\nstruct mii_ioctl_data *data = if_mii(req);\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nswitch (cmd) {\r\ncase SIOCGMIIREG:\r\ncase SIOCSMIIREG:\r\nif (is_10G(adapter) &&\r\n!mdio_phy_id_is_c45(data->phy_id) &&\r\n(data->phy_id & 0x1f00) &&\r\n!(data->phy_id & 0xe0e0))\r\ndata->phy_id = mdio_phy_id_c45(data->phy_id >> 8,\r\ndata->phy_id & 0x1f);\r\ncase SIOCGMIIPHY:\r\nreturn mdio_mii_ioctl(&pi->phy.mdio, data, cmd);\r\ncase SIOCCHIOCTL:\r\nreturn cxgb_extension_ioctl(dev, req->ifr_data);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic int cxgb_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nint ret;\r\nif (new_mtu < 81)\r\nreturn -EINVAL;\r\nif ((ret = t3_mac_set_mtu(&pi->mac, new_mtu)))\r\nreturn ret;\r\ndev->mtu = new_mtu;\r\ninit_port_mtus(adapter);\r\nif (adapter->params.rev == 0 && offload_running(adapter))\r\nt3_load_mtus(adapter, adapter->params.mtus,\r\nadapter->params.a_wnd, adapter->params.b_wnd,\r\nadapter->port[0]->mtu);\r\nreturn 0;\r\n}\r\nstatic int cxgb_set_mac_addr(struct net_device *dev, void *p)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nstruct sockaddr *addr = p;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(dev->dev_addr, addr->sa_data, dev->addr_len);\r\nt3_mac_set_address(&pi->mac, LAN_MAC_IDX, dev->dev_addr);\r\nif (offload_running(adapter))\r\nwrite_smt_entry(adapter, pi->port_id);\r\nreturn 0;\r\n}\r\nstatic netdev_features_t cxgb_fix_features(struct net_device *dev,\r\nnetdev_features_t features)\r\n{\r\nif (features & NETIF_F_HW_VLAN_CTAG_RX)\r\nfeatures |= NETIF_F_HW_VLAN_CTAG_TX;\r\nelse\r\nfeatures &= ~NETIF_F_HW_VLAN_CTAG_TX;\r\nreturn features;\r\n}\r\nstatic int cxgb_set_features(struct net_device *dev, netdev_features_t features)\r\n{\r\nnetdev_features_t changed = dev->features ^ features;\r\nif (changed & NETIF_F_HW_VLAN_CTAG_RX)\r\ncxgb_vlan_mode(dev, features);\r\nreturn 0;\r\n}\r\nstatic void cxgb_netpoll(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nstruct adapter *adapter = pi->adapter;\r\nint qidx;\r\nfor (qidx = pi->first_qset; qidx < pi->first_qset + pi->nqsets; qidx++) {\r\nstruct sge_qset *qs = &adapter->sge.qs[qidx];\r\nvoid *source;\r\nif (adapter->flags & USING_MSIX)\r\nsource = qs;\r\nelse\r\nsource = adapter;\r\nt3_intr_handler(adapter, qs->rspq.polling) (0, source);\r\n}\r\n}\r\nstatic void mac_stats_update(struct adapter *adapter)\r\n{\r\nint i;\r\nfor_each_port(adapter, i) {\r\nstruct net_device *dev = adapter->port[i];\r\nstruct port_info *p = netdev_priv(dev);\r\nif (netif_running(dev)) {\r\nspin_lock(&adapter->stats_lock);\r\nt3_mac_update_stats(&p->mac);\r\nspin_unlock(&adapter->stats_lock);\r\n}\r\n}\r\n}\r\nstatic void check_link_status(struct adapter *adapter)\r\n{\r\nint i;\r\nfor_each_port(adapter, i) {\r\nstruct net_device *dev = adapter->port[i];\r\nstruct port_info *p = netdev_priv(dev);\r\nint link_fault;\r\nspin_lock_irq(&adapter->work_lock);\r\nlink_fault = p->link_fault;\r\nspin_unlock_irq(&adapter->work_lock);\r\nif (link_fault) {\r\nt3_link_fault(adapter, i);\r\ncontinue;\r\n}\r\nif (!(p->phy.caps & SUPPORTED_IRQ) && netif_running(dev)) {\r\nt3_xgm_intr_disable(adapter, i);\r\nt3_read_reg(adapter, A_XGM_INT_STATUS + p->mac.offset);\r\nt3_link_changed(adapter, i);\r\nt3_xgm_intr_enable(adapter, i);\r\n}\r\n}\r\n}\r\nstatic void check_t3b2_mac(struct adapter *adapter)\r\n{\r\nint i;\r\nif (!rtnl_trylock())\r\nreturn;\r\nfor_each_port(adapter, i) {\r\nstruct net_device *dev = adapter->port[i];\r\nstruct port_info *p = netdev_priv(dev);\r\nint status;\r\nif (!netif_running(dev))\r\ncontinue;\r\nstatus = 0;\r\nif (netif_running(dev) && netif_carrier_ok(dev))\r\nstatus = t3b2_mac_watchdog_task(&p->mac);\r\nif (status == 1)\r\np->mac.stats.num_toggled++;\r\nelse if (status == 2) {\r\nstruct cmac *mac = &p->mac;\r\nt3_mac_set_mtu(mac, dev->mtu);\r\nt3_mac_set_address(mac, LAN_MAC_IDX, dev->dev_addr);\r\ncxgb_set_rxmode(dev);\r\nt3_link_start(&p->phy, mac, &p->link_config);\r\nt3_mac_enable(mac, MAC_DIRECTION_RX | MAC_DIRECTION_TX);\r\nt3_port_intr_enable(adapter, p->port_id);\r\np->mac.stats.num_resets++;\r\n}\r\n}\r\nrtnl_unlock();\r\n}\r\nstatic void t3_adap_check_task(struct work_struct *work)\r\n{\r\nstruct adapter *adapter = container_of(work, struct adapter,\r\nadap_check_task.work);\r\nconst struct adapter_params *p = &adapter->params;\r\nint port;\r\nunsigned int v, status, reset;\r\nadapter->check_task_cnt++;\r\ncheck_link_status(adapter);\r\nif (!p->linkpoll_period ||\r\n(adapter->check_task_cnt * p->linkpoll_period) / 10 >=\r\np->stats_update_period) {\r\nmac_stats_update(adapter);\r\nadapter->check_task_cnt = 0;\r\n}\r\nif (p->rev == T3_REV_B2)\r\ncheck_t3b2_mac(adapter);\r\nfor_each_port(adapter, port) {\r\nstruct cmac *mac = &adap2pinfo(adapter, port)->mac;\r\nu32 cause;\r\ncause = t3_read_reg(adapter, A_XGM_INT_CAUSE + mac->offset);\r\nreset = 0;\r\nif (cause & F_RXFIFO_OVERFLOW) {\r\nmac->stats.rx_fifo_ovfl++;\r\nreset |= F_RXFIFO_OVERFLOW;\r\n}\r\nt3_write_reg(adapter, A_XGM_INT_CAUSE + mac->offset, reset);\r\n}\r\nstatus = t3_read_reg(adapter, A_SG_INT_CAUSE);\r\nreset = 0;\r\nif (status & F_FLEMPTY) {\r\nstruct sge_qset *qs = &adapter->sge.qs[0];\r\nint i = 0;\r\nreset |= F_FLEMPTY;\r\nv = (t3_read_reg(adapter, A_SG_RSPQ_FL_STATUS) >> S_FL0EMPTY) &\r\n0xffff;\r\nwhile (v) {\r\nqs->fl[i].empty += (v & 1);\r\nif (i)\r\nqs++;\r\ni ^= 1;\r\nv >>= 1;\r\n}\r\n}\r\nt3_write_reg(adapter, A_SG_INT_CAUSE, reset);\r\nspin_lock_irq(&adapter->work_lock);\r\nif (adapter->open_device_map & PORT_MASK)\r\nschedule_chk_task(adapter);\r\nspin_unlock_irq(&adapter->work_lock);\r\n}\r\nstatic void db_full_task(struct work_struct *work)\r\n{\r\nstruct adapter *adapter = container_of(work, struct adapter,\r\ndb_full_task);\r\ncxgb3_event_notify(&adapter->tdev, OFFLOAD_DB_FULL, 0);\r\n}\r\nstatic void db_empty_task(struct work_struct *work)\r\n{\r\nstruct adapter *adapter = container_of(work, struct adapter,\r\ndb_empty_task);\r\ncxgb3_event_notify(&adapter->tdev, OFFLOAD_DB_EMPTY, 0);\r\n}\r\nstatic void db_drop_task(struct work_struct *work)\r\n{\r\nstruct adapter *adapter = container_of(work, struct adapter,\r\ndb_drop_task);\r\nunsigned long delay = 1000;\r\nunsigned short r;\r\ncxgb3_event_notify(&adapter->tdev, OFFLOAD_DB_DROP, 0);\r\nget_random_bytes(&r, 2);\r\ndelay += r & 1023;\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nschedule_timeout(usecs_to_jiffies(delay));\r\nring_dbs(adapter);\r\n}\r\nstatic void ext_intr_task(struct work_struct *work)\r\n{\r\nstruct adapter *adapter = container_of(work, struct adapter,\r\next_intr_handler_task);\r\nint i;\r\nfor_each_port(adapter, i) {\r\nstruct net_device *dev = adapter->port[i];\r\nstruct port_info *p = netdev_priv(dev);\r\nt3_xgm_intr_disable(adapter, i);\r\nt3_read_reg(adapter, A_XGM_INT_STATUS + p->mac.offset);\r\n}\r\nt3_phy_intr_handler(adapter);\r\nfor_each_port(adapter, i)\r\nt3_xgm_intr_enable(adapter, i);\r\nspin_lock_irq(&adapter->work_lock);\r\nif (adapter->slow_intr_mask) {\r\nadapter->slow_intr_mask |= F_T3DBG;\r\nt3_write_reg(adapter, A_PL_INT_CAUSE0, F_T3DBG);\r\nt3_write_reg(adapter, A_PL_INT_ENABLE0,\r\nadapter->slow_intr_mask);\r\n}\r\nspin_unlock_irq(&adapter->work_lock);\r\n}\r\nvoid t3_os_ext_intr_handler(struct adapter *adapter)\r\n{\r\nspin_lock(&adapter->work_lock);\r\nif (adapter->slow_intr_mask) {\r\nadapter->slow_intr_mask &= ~F_T3DBG;\r\nt3_write_reg(adapter, A_PL_INT_ENABLE0,\r\nadapter->slow_intr_mask);\r\nqueue_work(cxgb3_wq, &adapter->ext_intr_handler_task);\r\n}\r\nspin_unlock(&adapter->work_lock);\r\n}\r\nvoid t3_os_link_fault_handler(struct adapter *adapter, int port_id)\r\n{\r\nstruct net_device *netdev = adapter->port[port_id];\r\nstruct port_info *pi = netdev_priv(netdev);\r\nspin_lock(&adapter->work_lock);\r\npi->link_fault = 1;\r\nspin_unlock(&adapter->work_lock);\r\n}\r\nstatic int t3_adapter_error(struct adapter *adapter, int reset, int on_wq)\r\n{\r\nint i, ret = 0;\r\nif (is_offload(adapter) &&\r\ntest_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map)) {\r\ncxgb3_event_notify(&adapter->tdev, OFFLOAD_STATUS_DOWN, 0);\r\noffload_close(&adapter->tdev);\r\n}\r\nfor_each_port(adapter, i) {\r\nstruct net_device *netdev = adapter->port[i];\r\nif (netif_running(netdev))\r\n__cxgb_close(netdev, on_wq);\r\n}\r\nt3_stop_sge_timers(adapter);\r\nadapter->flags &= ~FULL_INIT_DONE;\r\nif (reset)\r\nret = t3_reset_adapter(adapter);\r\npci_disable_device(adapter->pdev);\r\nreturn ret;\r\n}\r\nstatic int t3_reenable_adapter(struct adapter *adapter)\r\n{\r\nif (pci_enable_device(adapter->pdev)) {\r\ndev_err(&adapter->pdev->dev,\r\n"Cannot re-enable PCI device after reset.\n");\r\ngoto err;\r\n}\r\npci_set_master(adapter->pdev);\r\npci_restore_state(adapter->pdev);\r\npci_save_state(adapter->pdev);\r\nt3_free_sge_resources(adapter);\r\nif (t3_replay_prep_adapter(adapter))\r\ngoto err;\r\nreturn 0;\r\nerr:\r\nreturn -1;\r\n}\r\nstatic void t3_resume_ports(struct adapter *adapter)\r\n{\r\nint i;\r\nfor_each_port(adapter, i) {\r\nstruct net_device *netdev = adapter->port[i];\r\nif (netif_running(netdev)) {\r\nif (cxgb_open(netdev)) {\r\ndev_err(&adapter->pdev->dev,\r\n"can't bring device back up"\r\n" after reset\n");\r\ncontinue;\r\n}\r\n}\r\n}\r\nif (is_offload(adapter) && !ofld_disable)\r\ncxgb3_event_notify(&adapter->tdev, OFFLOAD_STATUS_UP, 0);\r\n}\r\nstatic void fatal_error_task(struct work_struct *work)\r\n{\r\nstruct adapter *adapter = container_of(work, struct adapter,\r\nfatal_error_handler_task);\r\nint err = 0;\r\nrtnl_lock();\r\nerr = t3_adapter_error(adapter, 1, 1);\r\nif (!err)\r\nerr = t3_reenable_adapter(adapter);\r\nif (!err)\r\nt3_resume_ports(adapter);\r\nCH_ALERT(adapter, "adapter reset %s\n", err ? "failed" : "succeeded");\r\nrtnl_unlock();\r\n}\r\nvoid t3_fatal_err(struct adapter *adapter)\r\n{\r\nunsigned int fw_status[4];\r\nif (adapter->flags & FULL_INIT_DONE) {\r\nt3_sge_stop(adapter);\r\nt3_write_reg(adapter, A_XGM_TX_CTRL, 0);\r\nt3_write_reg(adapter, A_XGM_RX_CTRL, 0);\r\nt3_write_reg(adapter, XGM_REG(A_XGM_TX_CTRL, 1), 0);\r\nt3_write_reg(adapter, XGM_REG(A_XGM_RX_CTRL, 1), 0);\r\nspin_lock(&adapter->work_lock);\r\nt3_intr_disable(adapter);\r\nqueue_work(cxgb3_wq, &adapter->fatal_error_handler_task);\r\nspin_unlock(&adapter->work_lock);\r\n}\r\nCH_ALERT(adapter, "encountered fatal error, operation suspended\n");\r\nif (!t3_cim_ctl_blk_read(adapter, 0xa0, 4, fw_status))\r\nCH_ALERT(adapter, "FW status: 0x%x, 0x%x, 0x%x, 0x%x\n",\r\nfw_status[0], fw_status[1],\r\nfw_status[2], fw_status[3]);\r\n}\r\nstatic pci_ers_result_t t3_io_error_detected(struct pci_dev *pdev,\r\npci_channel_state_t state)\r\n{\r\nstruct adapter *adapter = pci_get_drvdata(pdev);\r\nif (state == pci_channel_io_perm_failure)\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\nt3_adapter_error(adapter, 0, 0);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nstatic pci_ers_result_t t3_io_slot_reset(struct pci_dev *pdev)\r\n{\r\nstruct adapter *adapter = pci_get_drvdata(pdev);\r\nif (!t3_reenable_adapter(adapter))\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nstatic void t3_io_resume(struct pci_dev *pdev)\r\n{\r\nstruct adapter *adapter = pci_get_drvdata(pdev);\r\nCH_ALERT(adapter, "adapter recovering, PEX ERR 0x%x\n",\r\nt3_read_reg(adapter, A_PCIE_PEX_ERR));\r\nrtnl_lock();\r\nt3_resume_ports(adapter);\r\nrtnl_unlock();\r\n}\r\nstatic void set_nqsets(struct adapter *adap)\r\n{\r\nint i, j = 0;\r\nint num_cpus = netif_get_num_default_rss_queues();\r\nint hwports = adap->params.nports;\r\nint nqsets = adap->msix_nvectors - 1;\r\nif (adap->params.rev > 0 && adap->flags & USING_MSIX) {\r\nif (hwports == 2 &&\r\n(hwports * nqsets > SGE_QSETS ||\r\nnum_cpus >= nqsets / hwports))\r\nnqsets /= hwports;\r\nif (nqsets > num_cpus)\r\nnqsets = num_cpus;\r\nif (nqsets < 1 || hwports == 4)\r\nnqsets = 1;\r\n} else\r\nnqsets = 1;\r\nfor_each_port(adap, i) {\r\nstruct port_info *pi = adap2pinfo(adap, i);\r\npi->first_qset = j;\r\npi->nqsets = nqsets;\r\nj = pi->first_qset + nqsets;\r\ndev_info(&adap->pdev->dev,\r\n"Port %d using %d queue sets.\n", i, nqsets);\r\n}\r\n}\r\nstatic int cxgb_enable_msix(struct adapter *adap)\r\n{\r\nstruct msix_entry entries[SGE_QSETS + 1];\r\nint vectors;\r\nint i, err;\r\nvectors = ARRAY_SIZE(entries);\r\nfor (i = 0; i < vectors; ++i)\r\nentries[i].entry = i;\r\nwhile ((err = pci_enable_msix(adap->pdev, entries, vectors)) > 0)\r\nvectors = err;\r\nif (err < 0)\r\npci_disable_msix(adap->pdev);\r\nif (!err && vectors < (adap->params.nports + 1)) {\r\npci_disable_msix(adap->pdev);\r\nerr = -1;\r\n}\r\nif (!err) {\r\nfor (i = 0; i < vectors; ++i)\r\nadap->msix_info[i].vec = entries[i].vector;\r\nadap->msix_nvectors = vectors;\r\n}\r\nreturn err;\r\n}\r\nstatic void print_port_info(struct adapter *adap, const struct adapter_info *ai)\r\n{\r\nstatic const char *pci_variant[] = {\r\n"PCI", "PCI-X", "PCI-X ECC", "PCI-X 266", "PCI Express"\r\n};\r\nint i;\r\nchar buf[80];\r\nif (is_pcie(adap))\r\nsnprintf(buf, sizeof(buf), "%s x%d",\r\npci_variant[adap->params.pci.variant],\r\nadap->params.pci.width);\r\nelse\r\nsnprintf(buf, sizeof(buf), "%s %dMHz/%d-bit",\r\npci_variant[adap->params.pci.variant],\r\nadap->params.pci.speed, adap->params.pci.width);\r\nfor_each_port(adap, i) {\r\nstruct net_device *dev = adap->port[i];\r\nconst struct port_info *pi = netdev_priv(dev);\r\nif (!test_bit(i, &adap->registered_device_map))\r\ncontinue;\r\nnetdev_info(dev, "%s %s %sNIC (rev %d) %s%s\n",\r\nai->desc, pi->phy.desc,\r\nis_offload(adap) ? "R" : "", adap->params.rev, buf,\r\n(adap->flags & USING_MSIX) ? " MSI-X" :\r\n(adap->flags & USING_MSI) ? " MSI" : "");\r\nif (adap->name == dev->name && adap->params.vpd.mclk)\r\npr_info("%s: %uMB CM, %uMB PMTX, %uMB PMRX, S/N: %s\n",\r\nadap->name, t3_mc7_size(&adap->cm) >> 20,\r\nt3_mc7_size(&adap->pmtx) >> 20,\r\nt3_mc7_size(&adap->pmrx) >> 20,\r\nadap->params.vpd.sn);\r\n}\r\n}\r\nstatic void cxgb3_init_iscsi_mac(struct net_device *dev)\r\n{\r\nstruct port_info *pi = netdev_priv(dev);\r\nmemcpy(pi->iscsic.mac_addr, dev->dev_addr, ETH_ALEN);\r\npi->iscsic.mac_addr[3] |= 0x80;\r\n}\r\nstatic int init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint i, err, pci_using_dac = 0;\r\nresource_size_t mmio_start, mmio_len;\r\nconst struct adapter_info *ai;\r\nstruct adapter *adapter = NULL;\r\nstruct port_info *pi;\r\npr_info_once("%s - version %s\n", DRV_DESC, DRV_VERSION);\r\nif (!cxgb3_wq) {\r\ncxgb3_wq = create_singlethread_workqueue(DRV_NAME);\r\nif (!cxgb3_wq) {\r\npr_err("cannot initialize work queue\n");\r\nreturn -ENOMEM;\r\n}\r\n}\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot enable PCI device\n");\r\ngoto out;\r\n}\r\nerr = pci_request_regions(pdev, DRV_NAME);\r\nif (err) {\r\ndev_info(&pdev->dev, "cannot obtain PCI resources\n");\r\ngoto out_disable_device;\r\n}\r\nif (!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {\r\npci_using_dac = 1;\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (err) {\r\ndev_err(&pdev->dev, "unable to obtain 64-bit DMA for "\r\n"coherent allocations\n");\r\ngoto out_release_regions;\r\n}\r\n} else if ((err = pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) != 0) {\r\ndev_err(&pdev->dev, "no usable DMA configuration\n");\r\ngoto out_release_regions;\r\n}\r\npci_set_master(pdev);\r\npci_save_state(pdev);\r\nmmio_start = pci_resource_start(pdev, 0);\r\nmmio_len = pci_resource_len(pdev, 0);\r\nai = t3_get_adapter_info(ent->driver_data);\r\nadapter = kzalloc(sizeof(*adapter), GFP_KERNEL);\r\nif (!adapter) {\r\nerr = -ENOMEM;\r\ngoto out_release_regions;\r\n}\r\nadapter->nofail_skb =\r\nalloc_skb(sizeof(struct cpl_set_tcb_field), GFP_KERNEL);\r\nif (!adapter->nofail_skb) {\r\ndev_err(&pdev->dev, "cannot allocate nofail buffer\n");\r\nerr = -ENOMEM;\r\ngoto out_free_adapter;\r\n}\r\nadapter->regs = ioremap_nocache(mmio_start, mmio_len);\r\nif (!adapter->regs) {\r\ndev_err(&pdev->dev, "cannot map device registers\n");\r\nerr = -ENOMEM;\r\ngoto out_free_adapter;\r\n}\r\nadapter->pdev = pdev;\r\nadapter->name = pci_name(pdev);\r\nadapter->msg_enable = dflt_msg_enable;\r\nadapter->mmio_len = mmio_len;\r\nmutex_init(&adapter->mdio_lock);\r\nspin_lock_init(&adapter->work_lock);\r\nspin_lock_init(&adapter->stats_lock);\r\nINIT_LIST_HEAD(&adapter->adapter_list);\r\nINIT_WORK(&adapter->ext_intr_handler_task, ext_intr_task);\r\nINIT_WORK(&adapter->fatal_error_handler_task, fatal_error_task);\r\nINIT_WORK(&adapter->db_full_task, db_full_task);\r\nINIT_WORK(&adapter->db_empty_task, db_empty_task);\r\nINIT_WORK(&adapter->db_drop_task, db_drop_task);\r\nINIT_DELAYED_WORK(&adapter->adap_check_task, t3_adap_check_task);\r\nfor (i = 0; i < ai->nports0 + ai->nports1; ++i) {\r\nstruct net_device *netdev;\r\nnetdev = alloc_etherdev_mq(sizeof(struct port_info), SGE_QSETS);\r\nif (!netdev) {\r\nerr = -ENOMEM;\r\ngoto out_free_dev;\r\n}\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\nadapter->port[i] = netdev;\r\npi = netdev_priv(netdev);\r\npi->adapter = adapter;\r\npi->port_id = i;\r\nnetif_carrier_off(netdev);\r\nnetdev->irq = pdev->irq;\r\nnetdev->mem_start = mmio_start;\r\nnetdev->mem_end = mmio_start + mmio_len - 1;\r\nnetdev->hw_features = NETIF_F_SG | NETIF_F_IP_CSUM |\r\nNETIF_F_TSO | NETIF_F_RXCSUM | NETIF_F_HW_VLAN_CTAG_RX;\r\nnetdev->features |= netdev->hw_features |\r\nNETIF_F_HW_VLAN_CTAG_TX;\r\nnetdev->vlan_features |= netdev->features & VLAN_FEAT;\r\nif (pci_using_dac)\r\nnetdev->features |= NETIF_F_HIGHDMA;\r\nnetdev->netdev_ops = &cxgb_netdev_ops;\r\nSET_ETHTOOL_OPS(netdev, &cxgb_ethtool_ops);\r\n}\r\npci_set_drvdata(pdev, adapter);\r\nif (t3_prep_adapter(adapter, ai, 1) < 0) {\r\nerr = -ENODEV;\r\ngoto out_free_dev;\r\n}\r\nfor_each_port(adapter, i) {\r\nerr = register_netdev(adapter->port[i]);\r\nif (err)\r\ndev_warn(&pdev->dev,\r\n"cannot register net device %s, skipping\n",\r\nadapter->port[i]->name);\r\nelse {\r\nif (!adapter->registered_device_map)\r\nadapter->name = adapter->port[i]->name;\r\n__set_bit(i, &adapter->registered_device_map);\r\n}\r\n}\r\nif (!adapter->registered_device_map) {\r\ndev_err(&pdev->dev, "could not register any net devices\n");\r\ngoto out_free_dev;\r\n}\r\nfor_each_port(adapter, i)\r\ncxgb3_init_iscsi_mac(adapter->port[i]);\r\nt3_led_ready(adapter);\r\nif (is_offload(adapter)) {\r\n__set_bit(OFFLOAD_DEVMAP_BIT, &adapter->registered_device_map);\r\ncxgb3_adapter_ofld(adapter);\r\n}\r\nif (msi > 1 && cxgb_enable_msix(adapter) == 0)\r\nadapter->flags |= USING_MSIX;\r\nelse if (msi > 0 && pci_enable_msi(pdev) == 0)\r\nadapter->flags |= USING_MSI;\r\nset_nqsets(adapter);\r\nerr = sysfs_create_group(&adapter->port[0]->dev.kobj,\r\n&cxgb3_attr_group);\r\nprint_port_info(adapter, ai);\r\nreturn 0;\r\nout_free_dev:\r\niounmap(adapter->regs);\r\nfor (i = ai->nports0 + ai->nports1 - 1; i >= 0; --i)\r\nif (adapter->port[i])\r\nfree_netdev(adapter->port[i]);\r\nout_free_adapter:\r\nkfree(adapter);\r\nout_release_regions:\r\npci_release_regions(pdev);\r\nout_disable_device:\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\nout:\r\nreturn err;\r\n}\r\nstatic void remove_one(struct pci_dev *pdev)\r\n{\r\nstruct adapter *adapter = pci_get_drvdata(pdev);\r\nif (adapter) {\r\nint i;\r\nt3_sge_stop(adapter);\r\nsysfs_remove_group(&adapter->port[0]->dev.kobj,\r\n&cxgb3_attr_group);\r\nif (is_offload(adapter)) {\r\ncxgb3_adapter_unofld(adapter);\r\nif (test_bit(OFFLOAD_DEVMAP_BIT,\r\n&adapter->open_device_map))\r\noffload_close(&adapter->tdev);\r\n}\r\nfor_each_port(adapter, i)\r\nif (test_bit(i, &adapter->registered_device_map))\r\nunregister_netdev(adapter->port[i]);\r\nt3_stop_sge_timers(adapter);\r\nt3_free_sge_resources(adapter);\r\ncxgb_disable_msi(adapter);\r\nfor_each_port(adapter, i)\r\nif (adapter->port[i])\r\nfree_netdev(adapter->port[i]);\r\niounmap(adapter->regs);\r\nif (adapter->nofail_skb)\r\nkfree_skb(adapter->nofail_skb);\r\nkfree(adapter);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\n}\r\n}\r\nstatic int __init cxgb3_init_module(void)\r\n{\r\nint ret;\r\ncxgb3_offload_init();\r\nret = pci_register_driver(&driver);\r\nreturn ret;\r\n}\r\nstatic void __exit cxgb3_cleanup_module(void)\r\n{\r\npci_unregister_driver(&driver);\r\nif (cxgb3_wq)\r\ndestroy_workqueue(cxgb3_wq);\r\n}
