static void __scm_free_rq(struct scm_request *scmrq)\r\n{\r\nstruct aob_rq_header *aobrq = to_aobrq(scmrq);\r\nfree_page((unsigned long) scmrq->aob);\r\nfree_page((unsigned long) scmrq->aidaw);\r\n__scm_free_rq_cluster(scmrq);\r\nkfree(aobrq);\r\n}\r\nstatic void scm_free_rqs(void)\r\n{\r\nstruct list_head *iter, *safe;\r\nstruct scm_request *scmrq;\r\nspin_lock_irq(&list_lock);\r\nlist_for_each_safe(iter, safe, &inactive_requests) {\r\nscmrq = list_entry(iter, struct scm_request, list);\r\nlist_del(&scmrq->list);\r\n__scm_free_rq(scmrq);\r\n}\r\nspin_unlock_irq(&list_lock);\r\n}\r\nstatic int __scm_alloc_rq(void)\r\n{\r\nstruct aob_rq_header *aobrq;\r\nstruct scm_request *scmrq;\r\naobrq = kzalloc(sizeof(*aobrq) + sizeof(*scmrq), GFP_KERNEL);\r\nif (!aobrq)\r\nreturn -ENOMEM;\r\nscmrq = (void *) aobrq->data;\r\nscmrq->aidaw = (void *) get_zeroed_page(GFP_DMA);\r\nscmrq->aob = (void *) get_zeroed_page(GFP_DMA);\r\nif (!scmrq->aob || !scmrq->aidaw) {\r\n__scm_free_rq(scmrq);\r\nreturn -ENOMEM;\r\n}\r\nif (__scm_alloc_rq_cluster(scmrq)) {\r\n__scm_free_rq(scmrq);\r\nreturn -ENOMEM;\r\n}\r\nINIT_LIST_HEAD(&scmrq->list);\r\nspin_lock_irq(&list_lock);\r\nlist_add(&scmrq->list, &inactive_requests);\r\nspin_unlock_irq(&list_lock);\r\nreturn 0;\r\n}\r\nstatic int scm_alloc_rqs(unsigned int nrqs)\r\n{\r\nint ret = 0;\r\nwhile (nrqs-- && !ret)\r\nret = __scm_alloc_rq();\r\nreturn ret;\r\n}\r\nstatic struct scm_request *scm_request_fetch(void)\r\n{\r\nstruct scm_request *scmrq = NULL;\r\nspin_lock(&list_lock);\r\nif (list_empty(&inactive_requests))\r\ngoto out;\r\nscmrq = list_first_entry(&inactive_requests, struct scm_request, list);\r\nlist_del(&scmrq->list);\r\nout:\r\nspin_unlock(&list_lock);\r\nreturn scmrq;\r\n}\r\nstatic void scm_request_done(struct scm_request *scmrq)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&list_lock, flags);\r\nlist_add(&scmrq->list, &inactive_requests);\r\nspin_unlock_irqrestore(&list_lock, flags);\r\n}\r\nstatic int scm_open(struct block_device *blkdev, fmode_t mode)\r\n{\r\nreturn scm_get_ref();\r\n}\r\nstatic void scm_release(struct gendisk *gendisk, fmode_t mode)\r\n{\r\nscm_put_ref();\r\n}\r\nstatic bool scm_permit_request(struct scm_blk_dev *bdev, struct request *req)\r\n{\r\nreturn rq_data_dir(req) != WRITE || bdev->state != SCM_WR_PROHIBIT;\r\n}\r\nstatic void scm_request_prepare(struct scm_request *scmrq)\r\n{\r\nstruct scm_blk_dev *bdev = scmrq->bdev;\r\nstruct scm_device *scmdev = bdev->gendisk->private_data;\r\nstruct aidaw *aidaw = scmrq->aidaw;\r\nstruct msb *msb = &scmrq->aob->msb[0];\r\nstruct req_iterator iter;\r\nstruct bio_vec *bv;\r\nmsb->bs = MSB_BS_4K;\r\nscmrq->aob->request.msb_count = 1;\r\nmsb->scm_addr = scmdev->address +\r\n((u64) blk_rq_pos(scmrq->request) << 9);\r\nmsb->oc = (rq_data_dir(scmrq->request) == READ) ?\r\nMSB_OC_READ : MSB_OC_WRITE;\r\nmsb->flags |= MSB_FLAG_IDA;\r\nmsb->data_addr = (u64) aidaw;\r\nrq_for_each_segment(bv, scmrq->request, iter) {\r\nWARN_ON(bv->bv_offset);\r\nmsb->blk_count += bv->bv_len >> 12;\r\naidaw->data_addr = (u64) page_address(bv->bv_page);\r\naidaw++;\r\n}\r\n}\r\nstatic inline void scm_request_init(struct scm_blk_dev *bdev,\r\nstruct scm_request *scmrq,\r\nstruct request *req)\r\n{\r\nstruct aob_rq_header *aobrq = to_aobrq(scmrq);\r\nstruct aob *aob = scmrq->aob;\r\nmemset(aob, 0, sizeof(*aob));\r\nmemset(scmrq->aidaw, 0, PAGE_SIZE);\r\naobrq->scmdev = bdev->scmdev;\r\naob->request.cmd_code = ARQB_CMD_MOVE;\r\naob->request.data = (u64) aobrq;\r\nscmrq->request = req;\r\nscmrq->bdev = bdev;\r\nscmrq->retries = 4;\r\nscmrq->error = 0;\r\nscm_request_cluster_init(scmrq);\r\n}\r\nstatic void scm_ensure_queue_restart(struct scm_blk_dev *bdev)\r\n{\r\nif (atomic_read(&bdev->queued_reqs)) {\r\nreturn;\r\n}\r\nblk_delay_queue(bdev->rq, SCM_QUEUE_DELAY);\r\n}\r\nvoid scm_request_requeue(struct scm_request *scmrq)\r\n{\r\nstruct scm_blk_dev *bdev = scmrq->bdev;\r\nscm_release_cluster(scmrq);\r\nblk_requeue_request(bdev->rq, scmrq->request);\r\natomic_dec(&bdev->queued_reqs);\r\nscm_request_done(scmrq);\r\nscm_ensure_queue_restart(bdev);\r\n}\r\nvoid scm_request_finish(struct scm_request *scmrq)\r\n{\r\nstruct scm_blk_dev *bdev = scmrq->bdev;\r\nscm_release_cluster(scmrq);\r\nblk_end_request_all(scmrq->request, scmrq->error);\r\natomic_dec(&bdev->queued_reqs);\r\nscm_request_done(scmrq);\r\n}\r\nstatic void scm_blk_request(struct request_queue *rq)\r\n{\r\nstruct scm_device *scmdev = rq->queuedata;\r\nstruct scm_blk_dev *bdev = dev_get_drvdata(&scmdev->dev);\r\nstruct scm_request *scmrq;\r\nstruct request *req;\r\nint ret;\r\nwhile ((req = blk_peek_request(rq))) {\r\nif (req->cmd_type != REQ_TYPE_FS)\r\ncontinue;\r\nif (!scm_permit_request(bdev, req)) {\r\nscm_ensure_queue_restart(bdev);\r\nreturn;\r\n}\r\nscmrq = scm_request_fetch();\r\nif (!scmrq) {\r\nSCM_LOG(5, "no request");\r\nscm_ensure_queue_restart(bdev);\r\nreturn;\r\n}\r\nscm_request_init(bdev, scmrq, req);\r\nif (!scm_reserve_cluster(scmrq)) {\r\nSCM_LOG(5, "cluster busy");\r\nscm_request_done(scmrq);\r\nreturn;\r\n}\r\nif (scm_need_cluster_request(scmrq)) {\r\natomic_inc(&bdev->queued_reqs);\r\nblk_start_request(req);\r\nscm_initiate_cluster_request(scmrq);\r\nreturn;\r\n}\r\nscm_request_prepare(scmrq);\r\natomic_inc(&bdev->queued_reqs);\r\nblk_start_request(req);\r\nret = scm_start_aob(scmrq->aob);\r\nif (ret) {\r\nSCM_LOG(5, "no subchannel");\r\nscm_request_requeue(scmrq);\r\nreturn;\r\n}\r\n}\r\n}\r\nstatic void __scmrq_log_error(struct scm_request *scmrq)\r\n{\r\nstruct aob *aob = scmrq->aob;\r\nif (scmrq->error == -ETIMEDOUT)\r\nSCM_LOG(1, "Request timeout");\r\nelse {\r\nSCM_LOG(1, "Request error");\r\nSCM_LOG_HEX(1, &aob->response, sizeof(aob->response));\r\n}\r\nif (scmrq->retries)\r\nSCM_LOG(1, "Retry request");\r\nelse\r\npr_err("An I/O operation to SCM failed with rc=%d\n",\r\nscmrq->error);\r\n}\r\nvoid scm_blk_irq(struct scm_device *scmdev, void *data, int error)\r\n{\r\nstruct scm_request *scmrq = data;\r\nstruct scm_blk_dev *bdev = scmrq->bdev;\r\nscmrq->error = error;\r\nif (error)\r\n__scmrq_log_error(scmrq);\r\nspin_lock(&bdev->lock);\r\nlist_add_tail(&scmrq->list, &bdev->finished_requests);\r\nspin_unlock(&bdev->lock);\r\ntasklet_hi_schedule(&bdev->tasklet);\r\n}\r\nstatic void scm_blk_handle_error(struct scm_request *scmrq)\r\n{\r\nstruct scm_blk_dev *bdev = scmrq->bdev;\r\nunsigned long flags;\r\nif (scmrq->error != -EIO)\r\ngoto restart;\r\nswitch (scmrq->aob->response.eqc) {\r\ncase EQC_WR_PROHIBIT:\r\nspin_lock_irqsave(&bdev->lock, flags);\r\nif (bdev->state != SCM_WR_PROHIBIT)\r\npr_info("%lx: Write access to the SCM increment is suspended\n",\r\n(unsigned long) bdev->scmdev->address);\r\nbdev->state = SCM_WR_PROHIBIT;\r\nspin_unlock_irqrestore(&bdev->lock, flags);\r\ngoto requeue;\r\ndefault:\r\nbreak;\r\n}\r\nrestart:\r\nif (!scm_start_aob(scmrq->aob))\r\nreturn;\r\nrequeue:\r\nspin_lock_irqsave(&bdev->rq_lock, flags);\r\nscm_request_requeue(scmrq);\r\nspin_unlock_irqrestore(&bdev->rq_lock, flags);\r\n}\r\nstatic void scm_blk_tasklet(struct scm_blk_dev *bdev)\r\n{\r\nstruct scm_request *scmrq;\r\nunsigned long flags;\r\nspin_lock_irqsave(&bdev->lock, flags);\r\nwhile (!list_empty(&bdev->finished_requests)) {\r\nscmrq = list_first_entry(&bdev->finished_requests,\r\nstruct scm_request, list);\r\nlist_del(&scmrq->list);\r\nspin_unlock_irqrestore(&bdev->lock, flags);\r\nif (scmrq->error && scmrq->retries-- > 0) {\r\nscm_blk_handle_error(scmrq);\r\nspin_lock_irqsave(&bdev->lock, flags);\r\ncontinue;\r\n}\r\nif (scm_test_cluster_request(scmrq)) {\r\nscm_cluster_request_irq(scmrq);\r\nspin_lock_irqsave(&bdev->lock, flags);\r\ncontinue;\r\n}\r\nscm_request_finish(scmrq);\r\nspin_lock_irqsave(&bdev->lock, flags);\r\n}\r\nspin_unlock_irqrestore(&bdev->lock, flags);\r\nblk_run_queue(bdev->rq);\r\n}\r\nint scm_blk_dev_setup(struct scm_blk_dev *bdev, struct scm_device *scmdev)\r\n{\r\nstruct request_queue *rq;\r\nint len, ret = -ENOMEM;\r\nunsigned int devindex, nr_max_blk;\r\ndevindex = atomic_inc_return(&nr_devices) - 1;\r\nif (devindex > 701) {\r\nret = -ENODEV;\r\ngoto out;\r\n}\r\nbdev->scmdev = scmdev;\r\nbdev->state = SCM_OPER;\r\nspin_lock_init(&bdev->rq_lock);\r\nspin_lock_init(&bdev->lock);\r\nINIT_LIST_HEAD(&bdev->finished_requests);\r\natomic_set(&bdev->queued_reqs, 0);\r\ntasklet_init(&bdev->tasklet,\r\n(void (*)(unsigned long)) scm_blk_tasklet,\r\n(unsigned long) bdev);\r\nrq = blk_init_queue(scm_blk_request, &bdev->rq_lock);\r\nif (!rq)\r\ngoto out;\r\nbdev->rq = rq;\r\nnr_max_blk = min(scmdev->nr_max_block,\r\n(unsigned int) (PAGE_SIZE / sizeof(struct aidaw)));\r\nblk_queue_logical_block_size(rq, 1 << 12);\r\nblk_queue_max_hw_sectors(rq, nr_max_blk << 3);\r\nblk_queue_max_segments(rq, nr_max_blk);\r\nqueue_flag_set_unlocked(QUEUE_FLAG_NONROT, rq);\r\nscm_blk_dev_cluster_setup(bdev);\r\nbdev->gendisk = alloc_disk(SCM_NR_PARTS);\r\nif (!bdev->gendisk)\r\ngoto out_queue;\r\nrq->queuedata = scmdev;\r\nbdev->gendisk->driverfs_dev = &scmdev->dev;\r\nbdev->gendisk->private_data = scmdev;\r\nbdev->gendisk->fops = &scm_blk_devops;\r\nbdev->gendisk->queue = rq;\r\nbdev->gendisk->major = scm_major;\r\nbdev->gendisk->first_minor = devindex * SCM_NR_PARTS;\r\nlen = snprintf(bdev->gendisk->disk_name, DISK_NAME_LEN, "scm");\r\nif (devindex > 25) {\r\nlen += snprintf(bdev->gendisk->disk_name + len,\r\nDISK_NAME_LEN - len, "%c",\r\n'a' + (devindex / 26) - 1);\r\ndevindex = devindex % 26;\r\n}\r\nsnprintf(bdev->gendisk->disk_name + len, DISK_NAME_LEN - len, "%c",\r\n'a' + devindex);\r\nset_capacity(bdev->gendisk, scmdev->size >> 9);\r\nadd_disk(bdev->gendisk);\r\nreturn 0;\r\nout_queue:\r\nblk_cleanup_queue(rq);\r\nout:\r\natomic_dec(&nr_devices);\r\nreturn ret;\r\n}\r\nvoid scm_blk_dev_cleanup(struct scm_blk_dev *bdev)\r\n{\r\ntasklet_kill(&bdev->tasklet);\r\ndel_gendisk(bdev->gendisk);\r\nblk_cleanup_queue(bdev->gendisk->queue);\r\nput_disk(bdev->gendisk);\r\n}\r\nvoid scm_blk_set_available(struct scm_blk_dev *bdev)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&bdev->lock, flags);\r\nif (bdev->state == SCM_WR_PROHIBIT)\r\npr_info("%lx: Write access to the SCM increment is restored\n",\r\n(unsigned long) bdev->scmdev->address);\r\nbdev->state = SCM_OPER;\r\nspin_unlock_irqrestore(&bdev->lock, flags);\r\n}\r\nstatic int __init scm_blk_init(void)\r\n{\r\nint ret = -EINVAL;\r\nif (!scm_cluster_size_valid())\r\ngoto out;\r\nret = register_blkdev(0, "scm");\r\nif (ret < 0)\r\ngoto out;\r\nscm_major = ret;\r\nret = scm_alloc_rqs(nr_requests);\r\nif (ret)\r\ngoto out_free;\r\nscm_debug = debug_register("scm_log", 16, 1, 16);\r\nif (!scm_debug) {\r\nret = -ENOMEM;\r\ngoto out_free;\r\n}\r\ndebug_register_view(scm_debug, &debug_hex_ascii_view);\r\ndebug_set_level(scm_debug, 2);\r\nret = scm_drv_init();\r\nif (ret)\r\ngoto out_dbf;\r\nreturn ret;\r\nout_dbf:\r\ndebug_unregister(scm_debug);\r\nout_free:\r\nscm_free_rqs();\r\nunregister_blkdev(scm_major, "scm");\r\nout:\r\nreturn ret;\r\n}\r\nstatic void __exit scm_blk_cleanup(void)\r\n{\r\nscm_drv_cleanup();\r\ndebug_unregister(scm_debug);\r\nscm_free_rqs();\r\nunregister_blkdev(scm_major, "scm");\r\n}
