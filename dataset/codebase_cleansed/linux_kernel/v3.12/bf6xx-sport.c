int sport_set_tx_params(struct sport_device *sport,\r\nstruct sport_params *params)\r\n{\r\nif (sport->tx_regs->spctl & SPORT_CTL_SPENPRI)\r\nreturn -EBUSY;\r\nsport->tx_regs->spctl = params->spctl | SPORT_CTL_SPTRAN;\r\nsport->tx_regs->div = params->div;\r\nSSYNC();\r\nreturn 0;\r\n}\r\nint sport_set_rx_params(struct sport_device *sport,\r\nstruct sport_params *params)\r\n{\r\nif (sport->rx_regs->spctl & SPORT_CTL_SPENPRI)\r\nreturn -EBUSY;\r\nsport->rx_regs->spctl = params->spctl & ~SPORT_CTL_SPTRAN;\r\nsport->rx_regs->div = params->div;\r\nSSYNC();\r\nreturn 0;\r\n}\r\nstatic int compute_wdsize(size_t wdsize)\r\n{\r\nswitch (wdsize) {\r\ncase 1:\r\nreturn WDSIZE_8 | PSIZE_8;\r\ncase 2:\r\nreturn WDSIZE_16 | PSIZE_16;\r\ndefault:\r\nreturn WDSIZE_32 | PSIZE_32;\r\n}\r\n}\r\nvoid sport_tx_start(struct sport_device *sport)\r\n{\r\nset_dma_next_desc_addr(sport->tx_dma_chan, sport->tx_desc);\r\nset_dma_config(sport->tx_dma_chan, DMAFLOW_LIST | DI_EN\r\n| compute_wdsize(sport->wdsize) | NDSIZE_6);\r\nenable_dma(sport->tx_dma_chan);\r\nsport->tx_regs->spctl |= SPORT_CTL_SPENPRI;\r\nSSYNC();\r\n}\r\nvoid sport_rx_start(struct sport_device *sport)\r\n{\r\nset_dma_next_desc_addr(sport->rx_dma_chan, sport->rx_desc);\r\nset_dma_config(sport->rx_dma_chan, DMAFLOW_LIST | DI_EN | WNR\r\n| compute_wdsize(sport->wdsize) | NDSIZE_6);\r\nenable_dma(sport->rx_dma_chan);\r\nsport->rx_regs->spctl |= SPORT_CTL_SPENPRI;\r\nSSYNC();\r\n}\r\nvoid sport_tx_stop(struct sport_device *sport)\r\n{\r\nsport->tx_regs->spctl &= ~SPORT_CTL_SPENPRI;\r\nSSYNC();\r\ndisable_dma(sport->tx_dma_chan);\r\n}\r\nvoid sport_rx_stop(struct sport_device *sport)\r\n{\r\nsport->rx_regs->spctl &= ~SPORT_CTL_SPENPRI;\r\nSSYNC();\r\ndisable_dma(sport->rx_dma_chan);\r\n}\r\nvoid sport_set_tx_callback(struct sport_device *sport,\r\nvoid (*tx_callback)(void *), void *tx_data)\r\n{\r\nsport->tx_callback = tx_callback;\r\nsport->tx_data = tx_data;\r\n}\r\nvoid sport_set_rx_callback(struct sport_device *sport,\r\nvoid (*rx_callback)(void *), void *rx_data)\r\n{\r\nsport->rx_callback = rx_callback;\r\nsport->rx_data = rx_data;\r\n}\r\nstatic void setup_desc(struct dmasg *desc, void *buf, int fragcount,\r\nsize_t fragsize, unsigned int cfg,\r\nunsigned int count, size_t wdsize)\r\n{\r\nint i;\r\nfor (i = 0; i < fragcount; ++i) {\r\ndesc[i].next_desc_addr = &(desc[i + 1]);\r\ndesc[i].start_addr = (unsigned long)buf + i*fragsize;\r\ndesc[i].cfg = cfg;\r\ndesc[i].x_count = count;\r\ndesc[i].x_modify = wdsize;\r\ndesc[i].y_count = 0;\r\ndesc[i].y_modify = 0;\r\n}\r\ndesc[fragcount-1].next_desc_addr = desc;\r\n}\r\nint sport_config_tx_dma(struct sport_device *sport, void *buf,\r\nint fragcount, size_t fragsize)\r\n{\r\nunsigned int count;\r\nunsigned int cfg;\r\ndma_addr_t addr;\r\ncount = fragsize/sport->wdsize;\r\nif (sport->tx_desc)\r\ndma_free_coherent(NULL, sport->tx_desc_size,\r\nsport->tx_desc, 0);\r\nsport->tx_desc = dma_alloc_coherent(NULL,\r\nfragcount * sizeof(struct dmasg), &addr, 0);\r\nsport->tx_desc_size = fragcount * sizeof(struct dmasg);\r\nif (!sport->tx_desc)\r\nreturn -ENOMEM;\r\nsport->tx_buf = buf;\r\nsport->tx_fragsize = fragsize;\r\nsport->tx_frags = fragcount;\r\ncfg = DMAFLOW_LIST | DI_EN | compute_wdsize(sport->wdsize) | NDSIZE_6;\r\nsetup_desc(sport->tx_desc, buf, fragcount, fragsize,\r\ncfg|DMAEN, count, sport->wdsize);\r\nreturn 0;\r\n}\r\nint sport_config_rx_dma(struct sport_device *sport, void *buf,\r\nint fragcount, size_t fragsize)\r\n{\r\nunsigned int count;\r\nunsigned int cfg;\r\ndma_addr_t addr;\r\ncount = fragsize/sport->wdsize;\r\nif (sport->rx_desc)\r\ndma_free_coherent(NULL, sport->rx_desc_size,\r\nsport->rx_desc, 0);\r\nsport->rx_desc = dma_alloc_coherent(NULL,\r\nfragcount * sizeof(struct dmasg), &addr, 0);\r\nsport->rx_desc_size = fragcount * sizeof(struct dmasg);\r\nif (!sport->rx_desc)\r\nreturn -ENOMEM;\r\nsport->rx_buf = buf;\r\nsport->rx_fragsize = fragsize;\r\nsport->rx_frags = fragcount;\r\ncfg = DMAFLOW_LIST | DI_EN | compute_wdsize(sport->wdsize)\r\n| WNR | NDSIZE_6;\r\nsetup_desc(sport->rx_desc, buf, fragcount, fragsize,\r\ncfg|DMAEN, count, sport->wdsize);\r\nreturn 0;\r\n}\r\nunsigned long sport_curr_offset_tx(struct sport_device *sport)\r\n{\r\nunsigned long curr = get_dma_curr_addr(sport->tx_dma_chan);\r\nreturn (unsigned char *)curr - sport->tx_buf;\r\n}\r\nunsigned long sport_curr_offset_rx(struct sport_device *sport)\r\n{\r\nunsigned long curr = get_dma_curr_addr(sport->rx_dma_chan);\r\nreturn (unsigned char *)curr - sport->rx_buf;\r\n}\r\nstatic irqreturn_t sport_tx_irq(int irq, void *dev_id)\r\n{\r\nstruct sport_device *sport = dev_id;\r\nstatic unsigned long status;\r\nstatus = get_dma_curr_irqstat(sport->tx_dma_chan);\r\nif (status & (DMA_DONE|DMA_ERR)) {\r\nclear_dma_irqstat(sport->tx_dma_chan);\r\nSSYNC();\r\n}\r\nif (sport->tx_callback)\r\nsport->tx_callback(sport->tx_data);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t sport_rx_irq(int irq, void *dev_id)\r\n{\r\nstruct sport_device *sport = dev_id;\r\nunsigned long status;\r\nstatus = get_dma_curr_irqstat(sport->rx_dma_chan);\r\nif (status & (DMA_DONE|DMA_ERR)) {\r\nclear_dma_irqstat(sport->rx_dma_chan);\r\nSSYNC();\r\n}\r\nif (sport->rx_callback)\r\nsport->rx_callback(sport->rx_data);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t sport_err_irq(int irq, void *dev_id)\r\n{\r\nstruct sport_device *sport = dev_id;\r\nstruct device *dev = &sport->pdev->dev;\r\nif (sport->tx_regs->spctl & SPORT_CTL_DERRPRI)\r\ndev_err(dev, "sport error: TUVF\n");\r\nif (sport->rx_regs->spctl & SPORT_CTL_DERRPRI)\r\ndev_err(dev, "sport error: ROVF\n");\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int sport_get_resource(struct sport_device *sport)\r\n{\r\nstruct platform_device *pdev = sport->pdev;\r\nstruct device *dev = &pdev->dev;\r\nstruct bfin_snd_platform_data *pdata = dev->platform_data;\r\nstruct resource *res;\r\nif (!pdata) {\r\ndev_err(dev, "No platform data\n");\r\nreturn -ENODEV;\r\n}\r\nsport->pin_req = pdata->pin_req;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(dev, "No tx MEM resource\n");\r\nreturn -ENODEV;\r\n}\r\nsport->tx_regs = (struct sport_register *)res->start;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 1);\r\nif (!res) {\r\ndev_err(dev, "No rx MEM resource\n");\r\nreturn -ENODEV;\r\n}\r\nsport->rx_regs = (struct sport_register *)res->start;\r\nres = platform_get_resource(pdev, IORESOURCE_DMA, 0);\r\nif (!res) {\r\ndev_err(dev, "No tx DMA resource\n");\r\nreturn -ENODEV;\r\n}\r\nsport->tx_dma_chan = res->start;\r\nres = platform_get_resource(pdev, IORESOURCE_DMA, 1);\r\nif (!res) {\r\ndev_err(dev, "No rx DMA resource\n");\r\nreturn -ENODEV;\r\n}\r\nsport->rx_dma_chan = res->start;\r\nres = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\r\nif (!res) {\r\ndev_err(dev, "No tx error irq resource\n");\r\nreturn -ENODEV;\r\n}\r\nsport->tx_err_irq = res->start;\r\nres = platform_get_resource(pdev, IORESOURCE_IRQ, 1);\r\nif (!res) {\r\ndev_err(dev, "No rx error irq resource\n");\r\nreturn -ENODEV;\r\n}\r\nsport->rx_err_irq = res->start;\r\nreturn 0;\r\n}\r\nstatic int sport_request_resource(struct sport_device *sport)\r\n{\r\nstruct device *dev = &sport->pdev->dev;\r\nint ret;\r\nret = peripheral_request_list(sport->pin_req, "soc-audio");\r\nif (ret) {\r\ndev_err(dev, "Unable to request sport pin\n");\r\nreturn ret;\r\n}\r\nret = request_dma(sport->tx_dma_chan, "SPORT TX Data");\r\nif (ret) {\r\ndev_err(dev, "Unable to allocate DMA channel for sport tx\n");\r\ngoto err_tx_dma;\r\n}\r\nset_dma_callback(sport->tx_dma_chan, sport_tx_irq, sport);\r\nret = request_dma(sport->rx_dma_chan, "SPORT RX Data");\r\nif (ret) {\r\ndev_err(dev, "Unable to allocate DMA channel for sport rx\n");\r\ngoto err_rx_dma;\r\n}\r\nset_dma_callback(sport->rx_dma_chan, sport_rx_irq, sport);\r\nret = request_irq(sport->tx_err_irq, sport_err_irq,\r\n0, "SPORT TX ERROR", sport);\r\nif (ret) {\r\ndev_err(dev, "Unable to allocate tx error IRQ for sport\n");\r\ngoto err_tx_irq;\r\n}\r\nret = request_irq(sport->rx_err_irq, sport_err_irq,\r\n0, "SPORT RX ERROR", sport);\r\nif (ret) {\r\ndev_err(dev, "Unable to allocate rx error IRQ for sport\n");\r\ngoto err_rx_irq;\r\n}\r\nreturn 0;\r\nerr_rx_irq:\r\nfree_irq(sport->tx_err_irq, sport);\r\nerr_tx_irq:\r\nfree_dma(sport->rx_dma_chan);\r\nerr_rx_dma:\r\nfree_dma(sport->tx_dma_chan);\r\nerr_tx_dma:\r\nperipheral_free_list(sport->pin_req);\r\nreturn ret;\r\n}\r\nstatic void sport_free_resource(struct sport_device *sport)\r\n{\r\nfree_irq(sport->rx_err_irq, sport);\r\nfree_irq(sport->tx_err_irq, sport);\r\nfree_dma(sport->rx_dma_chan);\r\nfree_dma(sport->tx_dma_chan);\r\nperipheral_free_list(sport->pin_req);\r\n}\r\nstruct sport_device *sport_create(struct platform_device *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct sport_device *sport;\r\nint ret;\r\nsport = kzalloc(sizeof(*sport), GFP_KERNEL);\r\nif (!sport) {\r\ndev_err(dev, "Unable to allocate memory for sport device\n");\r\nreturn NULL;\r\n}\r\nsport->pdev = pdev;\r\nret = sport_get_resource(sport);\r\nif (ret) {\r\nkfree(sport);\r\nreturn NULL;\r\n}\r\nret = sport_request_resource(sport);\r\nif (ret) {\r\nkfree(sport);\r\nreturn NULL;\r\n}\r\ndev_dbg(dev, "SPORT create success\n");\r\nreturn sport;\r\n}\r\nvoid sport_delete(struct sport_device *sport)\r\n{\r\nif (sport->tx_desc)\r\ndma_free_coherent(NULL, sport->tx_desc_size,\r\nsport->tx_desc, 0);\r\nif (sport->rx_desc)\r\ndma_free_coherent(NULL, sport->rx_desc_size,\r\nsport->rx_desc, 0);\r\nsport_free_resource(sport);\r\nkfree(sport);\r\n}
