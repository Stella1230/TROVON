static struct jz4740_dma_dev *jz4740_dma_chan_get_dev(\r\nstruct jz4740_dmaengine_chan *chan)\r\n{\r\nreturn container_of(chan->vchan.chan.device, struct jz4740_dma_dev,\r\nddev);\r\n}\r\nstatic struct jz4740_dmaengine_chan *to_jz4740_dma_chan(struct dma_chan *c)\r\n{\r\nreturn container_of(c, struct jz4740_dmaengine_chan, vchan.chan);\r\n}\r\nstatic struct jz4740_dma_desc *to_jz4740_dma_desc(struct virt_dma_desc *vdesc)\r\n{\r\nreturn container_of(vdesc, struct jz4740_dma_desc, vdesc);\r\n}\r\nstatic inline uint32_t jz4740_dma_read(struct jz4740_dma_dev *dmadev,\r\nunsigned int reg)\r\n{\r\nreturn readl(dmadev->base + reg);\r\n}\r\nstatic inline void jz4740_dma_write(struct jz4740_dma_dev *dmadev,\r\nunsigned reg, uint32_t val)\r\n{\r\nwritel(val, dmadev->base + reg);\r\n}\r\nstatic inline void jz4740_dma_write_mask(struct jz4740_dma_dev *dmadev,\r\nunsigned int reg, uint32_t val, uint32_t mask)\r\n{\r\nuint32_t tmp;\r\ntmp = jz4740_dma_read(dmadev, reg);\r\ntmp &= ~mask;\r\ntmp |= val;\r\njz4740_dma_write(dmadev, reg, tmp);\r\n}\r\nstatic struct jz4740_dma_desc *jz4740_dma_alloc_desc(unsigned int num_sgs)\r\n{\r\nreturn kzalloc(sizeof(struct jz4740_dma_desc) +\r\nsizeof(struct jz4740_dma_sg) * num_sgs, GFP_ATOMIC);\r\n}\r\nstatic enum jz4740_dma_width jz4740_dma_width(enum dma_slave_buswidth width)\r\n{\r\nswitch (width) {\r\ncase DMA_SLAVE_BUSWIDTH_1_BYTE:\r\nreturn JZ4740_DMA_WIDTH_8BIT;\r\ncase DMA_SLAVE_BUSWIDTH_2_BYTES:\r\nreturn JZ4740_DMA_WIDTH_16BIT;\r\ncase DMA_SLAVE_BUSWIDTH_4_BYTES:\r\nreturn JZ4740_DMA_WIDTH_32BIT;\r\ndefault:\r\nreturn JZ4740_DMA_WIDTH_32BIT;\r\n}\r\n}\r\nstatic enum jz4740_dma_transfer_size jz4740_dma_maxburst(u32 maxburst)\r\n{\r\nif (maxburst <= 1)\r\nreturn JZ4740_DMA_TRANSFER_SIZE_1BYTE;\r\nelse if (maxburst <= 3)\r\nreturn JZ4740_DMA_TRANSFER_SIZE_2BYTE;\r\nelse if (maxburst <= 15)\r\nreturn JZ4740_DMA_TRANSFER_SIZE_4BYTE;\r\nelse if (maxburst <= 31)\r\nreturn JZ4740_DMA_TRANSFER_SIZE_16BYTE;\r\nreturn JZ4740_DMA_TRANSFER_SIZE_32BYTE;\r\n}\r\nstatic int jz4740_dma_slave_config(struct dma_chan *c,\r\nconst struct dma_slave_config *config)\r\n{\r\nstruct jz4740_dmaengine_chan *chan = to_jz4740_dma_chan(c);\r\nstruct jz4740_dma_dev *dmadev = jz4740_dma_chan_get_dev(chan);\r\nenum jz4740_dma_width src_width;\r\nenum jz4740_dma_width dst_width;\r\nenum jz4740_dma_transfer_size transfer_size;\r\nenum jz4740_dma_flags flags;\r\nuint32_t cmd;\r\nswitch (config->direction) {\r\ncase DMA_MEM_TO_DEV:\r\nflags = JZ4740_DMA_SRC_AUTOINC;\r\ntransfer_size = jz4740_dma_maxburst(config->dst_maxburst);\r\nchan->fifo_addr = config->dst_addr;\r\nbreak;\r\ncase DMA_DEV_TO_MEM:\r\nflags = JZ4740_DMA_DST_AUTOINC;\r\ntransfer_size = jz4740_dma_maxburst(config->src_maxburst);\r\nchan->fifo_addr = config->src_addr;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nsrc_width = jz4740_dma_width(config->src_addr_width);\r\ndst_width = jz4740_dma_width(config->dst_addr_width);\r\nswitch (transfer_size) {\r\ncase JZ4740_DMA_TRANSFER_SIZE_2BYTE:\r\nchan->transfer_shift = 1;\r\nbreak;\r\ncase JZ4740_DMA_TRANSFER_SIZE_4BYTE:\r\nchan->transfer_shift = 2;\r\nbreak;\r\ncase JZ4740_DMA_TRANSFER_SIZE_16BYTE:\r\nchan->transfer_shift = 4;\r\nbreak;\r\ncase JZ4740_DMA_TRANSFER_SIZE_32BYTE:\r\nchan->transfer_shift = 5;\r\nbreak;\r\ndefault:\r\nchan->transfer_shift = 0;\r\nbreak;\r\n}\r\ncmd = flags << JZ_DMA_CMD_FLAGS_OFFSET;\r\ncmd |= src_width << JZ_DMA_CMD_SRC_WIDTH_OFFSET;\r\ncmd |= dst_width << JZ_DMA_CMD_DST_WIDTH_OFFSET;\r\ncmd |= transfer_size << JZ_DMA_CMD_TRANSFER_SIZE_OFFSET;\r\ncmd |= JZ4740_DMA_MODE_SINGLE << JZ_DMA_CMD_MODE_OFFSET;\r\ncmd |= JZ_DMA_CMD_TRANSFER_IRQ_ENABLE;\r\njz4740_dma_write(dmadev, JZ_REG_DMA_CMD(chan->id), cmd);\r\njz4740_dma_write(dmadev, JZ_REG_DMA_STATUS_CTRL(chan->id), 0);\r\njz4740_dma_write(dmadev, JZ_REG_DMA_REQ_TYPE(chan->id),\r\nconfig->slave_id);\r\nreturn 0;\r\n}\r\nstatic int jz4740_dma_terminate_all(struct dma_chan *c)\r\n{\r\nstruct jz4740_dmaengine_chan *chan = to_jz4740_dma_chan(c);\r\nstruct jz4740_dma_dev *dmadev = jz4740_dma_chan_get_dev(chan);\r\nunsigned long flags;\r\nLIST_HEAD(head);\r\nspin_lock_irqsave(&chan->vchan.lock, flags);\r\njz4740_dma_write_mask(dmadev, JZ_REG_DMA_STATUS_CTRL(chan->id), 0,\r\nJZ_DMA_STATUS_CTRL_ENABLE);\r\nchan->desc = NULL;\r\nvchan_get_all_descriptors(&chan->vchan, &head);\r\nspin_unlock_irqrestore(&chan->vchan.lock, flags);\r\nvchan_dma_desc_free_list(&chan->vchan, &head);\r\nreturn 0;\r\n}\r\nstatic int jz4740_dma_control(struct dma_chan *chan, enum dma_ctrl_cmd cmd,\r\nunsigned long arg)\r\n{\r\nstruct dma_slave_config *config = (struct dma_slave_config *)arg;\r\nswitch (cmd) {\r\ncase DMA_SLAVE_CONFIG:\r\nreturn jz4740_dma_slave_config(chan, config);\r\ncase DMA_TERMINATE_ALL:\r\nreturn jz4740_dma_terminate_all(chan);\r\ndefault:\r\nreturn -ENOSYS;\r\n}\r\n}\r\nstatic int jz4740_dma_start_transfer(struct jz4740_dmaengine_chan *chan)\r\n{\r\nstruct jz4740_dma_dev *dmadev = jz4740_dma_chan_get_dev(chan);\r\ndma_addr_t src_addr, dst_addr;\r\nstruct virt_dma_desc *vdesc;\r\nstruct jz4740_dma_sg *sg;\r\njz4740_dma_write_mask(dmadev, JZ_REG_DMA_STATUS_CTRL(chan->id), 0,\r\nJZ_DMA_STATUS_CTRL_ENABLE);\r\nif (!chan->desc) {\r\nvdesc = vchan_next_desc(&chan->vchan);\r\nif (!vdesc)\r\nreturn 0;\r\nchan->desc = to_jz4740_dma_desc(vdesc);\r\nchan->next_sg = 0;\r\n}\r\nif (chan->next_sg == chan->desc->num_sgs)\r\nchan->next_sg = 0;\r\nsg = &chan->desc->sg[chan->next_sg];\r\nif (chan->desc->direction == DMA_MEM_TO_DEV) {\r\nsrc_addr = sg->addr;\r\ndst_addr = chan->fifo_addr;\r\n} else {\r\nsrc_addr = chan->fifo_addr;\r\ndst_addr = sg->addr;\r\n}\r\njz4740_dma_write(dmadev, JZ_REG_DMA_SRC_ADDR(chan->id), src_addr);\r\njz4740_dma_write(dmadev, JZ_REG_DMA_DST_ADDR(chan->id), dst_addr);\r\njz4740_dma_write(dmadev, JZ_REG_DMA_TRANSFER_COUNT(chan->id),\r\nsg->len >> chan->transfer_shift);\r\nchan->next_sg++;\r\njz4740_dma_write_mask(dmadev, JZ_REG_DMA_STATUS_CTRL(chan->id),\r\nJZ_DMA_STATUS_CTRL_NO_DESC | JZ_DMA_STATUS_CTRL_ENABLE,\r\nJZ_DMA_STATUS_CTRL_HALT | JZ_DMA_STATUS_CTRL_NO_DESC |\r\nJZ_DMA_STATUS_CTRL_ENABLE);\r\njz4740_dma_write_mask(dmadev, JZ_REG_DMA_CTRL,\r\nJZ_DMA_CTRL_ENABLE,\r\nJZ_DMA_CTRL_HALT | JZ_DMA_CTRL_ENABLE);\r\nreturn 0;\r\n}\r\nstatic void jz4740_dma_chan_irq(struct jz4740_dmaengine_chan *chan)\r\n{\r\nspin_lock(&chan->vchan.lock);\r\nif (chan->desc) {\r\nif (chan->desc && chan->desc->cyclic) {\r\nvchan_cyclic_callback(&chan->desc->vdesc);\r\n} else {\r\nif (chan->next_sg == chan->desc->num_sgs) {\r\nchan->desc = NULL;\r\nvchan_cookie_complete(&chan->desc->vdesc);\r\n}\r\n}\r\n}\r\njz4740_dma_start_transfer(chan);\r\nspin_unlock(&chan->vchan.lock);\r\n}\r\nstatic irqreturn_t jz4740_dma_irq(int irq, void *devid)\r\n{\r\nstruct jz4740_dma_dev *dmadev = devid;\r\nuint32_t irq_status;\r\nunsigned int i;\r\nirq_status = readl(dmadev->base + JZ_REG_DMA_IRQ);\r\nfor (i = 0; i < 6; ++i) {\r\nif (irq_status & (1 << i)) {\r\njz4740_dma_write_mask(dmadev,\r\nJZ_REG_DMA_STATUS_CTRL(i), 0,\r\nJZ_DMA_STATUS_CTRL_ENABLE |\r\nJZ_DMA_STATUS_CTRL_TRANSFER_DONE);\r\njz4740_dma_chan_irq(&dmadev->chan[i]);\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void jz4740_dma_issue_pending(struct dma_chan *c)\r\n{\r\nstruct jz4740_dmaengine_chan *chan = to_jz4740_dma_chan(c);\r\nunsigned long flags;\r\nspin_lock_irqsave(&chan->vchan.lock, flags);\r\nif (vchan_issue_pending(&chan->vchan) && !chan->desc)\r\njz4740_dma_start_transfer(chan);\r\nspin_unlock_irqrestore(&chan->vchan.lock, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *jz4740_dma_prep_slave_sg(\r\nstruct dma_chan *c, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct jz4740_dmaengine_chan *chan = to_jz4740_dma_chan(c);\r\nstruct jz4740_dma_desc *desc;\r\nstruct scatterlist *sg;\r\nunsigned int i;\r\ndesc = jz4740_dma_alloc_desc(sg_len);\r\nif (!desc)\r\nreturn NULL;\r\nfor_each_sg(sgl, sg, sg_len, i) {\r\ndesc->sg[i].addr = sg_dma_address(sg);\r\ndesc->sg[i].len = sg_dma_len(sg);\r\n}\r\ndesc->num_sgs = sg_len;\r\ndesc->direction = direction;\r\ndesc->cyclic = false;\r\nreturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *jz4740_dma_prep_dma_cyclic(\r\nstruct dma_chan *c, dma_addr_t buf_addr, size_t buf_len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct jz4740_dmaengine_chan *chan = to_jz4740_dma_chan(c);\r\nstruct jz4740_dma_desc *desc;\r\nunsigned int num_periods, i;\r\nif (buf_len % period_len)\r\nreturn NULL;\r\nnum_periods = buf_len / period_len;\r\ndesc = jz4740_dma_alloc_desc(num_periods);\r\nif (!desc)\r\nreturn NULL;\r\nfor (i = 0; i < num_periods; i++) {\r\ndesc->sg[i].addr = buf_addr;\r\ndesc->sg[i].len = period_len;\r\nbuf_addr += period_len;\r\n}\r\ndesc->num_sgs = num_periods;\r\ndesc->direction = direction;\r\ndesc->cyclic = true;\r\nreturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\r\n}\r\nstatic size_t jz4740_dma_desc_residue(struct jz4740_dmaengine_chan *chan,\r\nstruct jz4740_dma_desc *desc, unsigned int next_sg)\r\n{\r\nstruct jz4740_dma_dev *dmadev = jz4740_dma_chan_get_dev(chan);\r\nunsigned int residue, count;\r\nunsigned int i;\r\nresidue = 0;\r\nfor (i = next_sg; i < desc->num_sgs; i++)\r\nresidue += desc->sg[i].len;\r\nif (next_sg != 0) {\r\ncount = jz4740_dma_read(dmadev,\r\nJZ_REG_DMA_TRANSFER_COUNT(chan->id));\r\nresidue += count << chan->transfer_shift;\r\n}\r\nreturn residue;\r\n}\r\nstatic enum dma_status jz4740_dma_tx_status(struct dma_chan *c,\r\ndma_cookie_t cookie, struct dma_tx_state *state)\r\n{\r\nstruct jz4740_dmaengine_chan *chan = to_jz4740_dma_chan(c);\r\nstruct virt_dma_desc *vdesc;\r\nenum dma_status status;\r\nunsigned long flags;\r\nstatus = dma_cookie_status(c, cookie, state);\r\nif (status == DMA_SUCCESS || !state)\r\nreturn status;\r\nspin_lock_irqsave(&chan->vchan.lock, flags);\r\nvdesc = vchan_find_desc(&chan->vchan, cookie);\r\nif (cookie == chan->desc->vdesc.tx.cookie) {\r\nstate->residue = jz4740_dma_desc_residue(chan, chan->desc,\r\nchan->next_sg);\r\n} else if (vdesc) {\r\nstate->residue = jz4740_dma_desc_residue(chan,\r\nto_jz4740_dma_desc(vdesc), 0);\r\n} else {\r\nstate->residue = 0;\r\n}\r\nspin_unlock_irqrestore(&chan->vchan.lock, flags);\r\nreturn status;\r\n}\r\nstatic int jz4740_dma_alloc_chan_resources(struct dma_chan *c)\r\n{\r\nreturn 0;\r\n}\r\nstatic void jz4740_dma_free_chan_resources(struct dma_chan *c)\r\n{\r\nvchan_free_chan_resources(to_virt_chan(c));\r\n}\r\nstatic void jz4740_dma_desc_free(struct virt_dma_desc *vdesc)\r\n{\r\nkfree(container_of(vdesc, struct jz4740_dma_desc, vdesc));\r\n}\r\nstatic int jz4740_dma_probe(struct platform_device *pdev)\r\n{\r\nstruct jz4740_dmaengine_chan *chan;\r\nstruct jz4740_dma_dev *dmadev;\r\nstruct dma_device *dd;\r\nunsigned int i;\r\nstruct resource *res;\r\nint ret;\r\nint irq;\r\ndmadev = devm_kzalloc(&pdev->dev, sizeof(*dmadev), GFP_KERNEL);\r\nif (!dmadev)\r\nreturn -EINVAL;\r\ndd = &dmadev->ddev;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\ndmadev->base = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(dmadev->base))\r\nreturn PTR_ERR(dmadev->base);\r\ndmadev->clk = clk_get(&pdev->dev, "dma");\r\nif (IS_ERR(dmadev->clk))\r\nreturn PTR_ERR(dmadev->clk);\r\nclk_prepare_enable(dmadev->clk);\r\ndma_cap_set(DMA_SLAVE, dd->cap_mask);\r\ndma_cap_set(DMA_CYCLIC, dd->cap_mask);\r\ndd->device_alloc_chan_resources = jz4740_dma_alloc_chan_resources;\r\ndd->device_free_chan_resources = jz4740_dma_free_chan_resources;\r\ndd->device_tx_status = jz4740_dma_tx_status;\r\ndd->device_issue_pending = jz4740_dma_issue_pending;\r\ndd->device_prep_slave_sg = jz4740_dma_prep_slave_sg;\r\ndd->device_prep_dma_cyclic = jz4740_dma_prep_dma_cyclic;\r\ndd->device_control = jz4740_dma_control;\r\ndd->dev = &pdev->dev;\r\ndd->chancnt = JZ_DMA_NR_CHANS;\r\nINIT_LIST_HEAD(&dd->channels);\r\nfor (i = 0; i < dd->chancnt; i++) {\r\nchan = &dmadev->chan[i];\r\nchan->id = i;\r\nchan->vchan.desc_free = jz4740_dma_desc_free;\r\nvchan_init(&chan->vchan, dd);\r\n}\r\nret = dma_async_device_register(dd);\r\nif (ret)\r\nreturn ret;\r\nirq = platform_get_irq(pdev, 0);\r\nret = request_irq(irq, jz4740_dma_irq, 0, dev_name(&pdev->dev), dmadev);\r\nif (ret)\r\ngoto err_unregister;\r\nplatform_set_drvdata(pdev, dmadev);\r\nreturn 0;\r\nerr_unregister:\r\ndma_async_device_unregister(dd);\r\nreturn ret;\r\n}\r\nstatic int jz4740_dma_remove(struct platform_device *pdev)\r\n{\r\nstruct jz4740_dma_dev *dmadev = platform_get_drvdata(pdev);\r\nint irq = platform_get_irq(pdev, 0);\r\nfree_irq(irq, dmadev);\r\ndma_async_device_unregister(&dmadev->ddev);\r\nclk_disable_unprepare(dmadev->clk);\r\nreturn 0;\r\n}
