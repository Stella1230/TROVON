void *drbd_md_get_buffer(struct drbd_conf *mdev)\r\n{\r\nint r;\r\nwait_event(mdev->misc_wait,\r\n(r = atomic_cmpxchg(&mdev->md_io_in_use, 0, 1)) == 0 ||\r\nmdev->state.disk <= D_FAILED);\r\nreturn r ? NULL : page_address(mdev->md_io_page);\r\n}\r\nvoid drbd_md_put_buffer(struct drbd_conf *mdev)\r\n{\r\nif (atomic_dec_and_test(&mdev->md_io_in_use))\r\nwake_up(&mdev->misc_wait);\r\n}\r\nvoid wait_until_done_or_force_detached(struct drbd_conf *mdev, struct drbd_backing_dev *bdev,\r\nunsigned int *done)\r\n{\r\nlong dt;\r\nrcu_read_lock();\r\ndt = rcu_dereference(bdev->disk_conf)->disk_timeout;\r\nrcu_read_unlock();\r\ndt = dt * HZ / 10;\r\nif (dt == 0)\r\ndt = MAX_SCHEDULE_TIMEOUT;\r\ndt = wait_event_timeout(mdev->misc_wait,\r\n*done || test_bit(FORCE_DETACH, &mdev->flags), dt);\r\nif (dt == 0) {\r\ndev_err(DEV, "meta-data IO operation timed out\n");\r\ndrbd_chk_io_error(mdev, 1, DRBD_FORCE_DETACH);\r\n}\r\n}\r\nstatic int _drbd_md_sync_page_io(struct drbd_conf *mdev,\r\nstruct drbd_backing_dev *bdev,\r\nstruct page *page, sector_t sector,\r\nint rw, int size)\r\n{\r\nstruct bio *bio;\r\nint err;\r\nmdev->md_io.done = 0;\r\nmdev->md_io.error = -ENODEV;\r\nif ((rw & WRITE) && !test_bit(MD_NO_FUA, &mdev->flags))\r\nrw |= REQ_FUA | REQ_FLUSH;\r\nrw |= REQ_SYNC;\r\nbio = bio_alloc_drbd(GFP_NOIO);\r\nbio->bi_bdev = bdev->md_bdev;\r\nbio->bi_sector = sector;\r\nerr = -EIO;\r\nif (bio_add_page(bio, page, size, 0) != size)\r\ngoto out;\r\nbio->bi_private = &mdev->md_io;\r\nbio->bi_end_io = drbd_md_io_complete;\r\nbio->bi_rw = rw;\r\nif (!(rw & WRITE) && mdev->state.disk == D_DISKLESS && mdev->ldev == NULL)\r\n;\r\nelse if (!get_ldev_if_state(mdev, D_ATTACHING)) {\r\ndev_err(DEV, "ASSERT FAILED: get_ldev_if_state() == 1 in _drbd_md_sync_page_io()\n");\r\nerr = -ENODEV;\r\ngoto out;\r\n}\r\nbio_get(bio);\r\natomic_inc(&mdev->md_io_in_use);\r\nif (drbd_insert_fault(mdev, (rw & WRITE) ? DRBD_FAULT_MD_WR : DRBD_FAULT_MD_RD))\r\nbio_endio(bio, -EIO);\r\nelse\r\nsubmit_bio(rw, bio);\r\nwait_until_done_or_force_detached(mdev, bdev, &mdev->md_io.done);\r\nif (bio_flagged(bio, BIO_UPTODATE))\r\nerr = mdev->md_io.error;\r\nout:\r\nbio_put(bio);\r\nreturn err;\r\n}\r\nint drbd_md_sync_page_io(struct drbd_conf *mdev, struct drbd_backing_dev *bdev,\r\nsector_t sector, int rw)\r\n{\r\nint err;\r\nstruct page *iop = mdev->md_io_page;\r\nD_ASSERT(atomic_read(&mdev->md_io_in_use) == 1);\r\nBUG_ON(!bdev->md_bdev);\r\ndev_dbg(DEV, "meta_data io: %s [%d]:%s(,%llus,%s) %pS\n",\r\ncurrent->comm, current->pid, __func__,\r\n(unsigned long long)sector, (rw & WRITE) ? "WRITE" : "READ",\r\n(void*)_RET_IP_ );\r\nif (sector < drbd_md_first_sector(bdev) ||\r\nsector + 7 > drbd_md_last_sector(bdev))\r\ndev_alert(DEV, "%s [%d]:%s(,%llus,%s) out of range md access!\n",\r\ncurrent->comm, current->pid, __func__,\r\n(unsigned long long)sector, (rw & WRITE) ? "WRITE" : "READ");\r\nerr = _drbd_md_sync_page_io(mdev, bdev, iop, sector, rw, 4096);\r\nif (err) {\r\ndev_err(DEV, "drbd_md_sync_page_io(,%llus,%s) failed with error %d\n",\r\n(unsigned long long)sector, (rw & WRITE) ? "WRITE" : "READ", err);\r\n}\r\nreturn err;\r\n}\r\nstatic struct bm_extent *find_active_resync_extent(struct drbd_conf *mdev, unsigned int enr)\r\n{\r\nstruct lc_element *tmp;\r\ntmp = lc_find(mdev->resync, enr/AL_EXT_PER_BM_SECT);\r\nif (unlikely(tmp != NULL)) {\r\nstruct bm_extent *bm_ext = lc_entry(tmp, struct bm_extent, lce);\r\nif (test_bit(BME_NO_WRITES, &bm_ext->flags))\r\nreturn bm_ext;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct lc_element *_al_get(struct drbd_conf *mdev, unsigned int enr, bool nonblock)\r\n{\r\nstruct lc_element *al_ext;\r\nstruct bm_extent *bm_ext;\r\nint wake;\r\nspin_lock_irq(&mdev->al_lock);\r\nbm_ext = find_active_resync_extent(mdev, enr);\r\nif (bm_ext) {\r\nwake = !test_and_set_bit(BME_PRIORITY, &bm_ext->flags);\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (wake)\r\nwake_up(&mdev->al_wait);\r\nreturn NULL;\r\n}\r\nif (nonblock)\r\nal_ext = lc_try_get(mdev->act_log, enr);\r\nelse\r\nal_ext = lc_get(mdev->act_log, enr);\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn al_ext;\r\n}\r\nbool drbd_al_begin_io_fastpath(struct drbd_conf *mdev, struct drbd_interval *i)\r\n{\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nD_ASSERT((unsigned)(last - first) <= 1);\r\nD_ASSERT(atomic_read(&mdev->local_cnt) > 0);\r\nif (first != last)\r\nreturn false;\r\nreturn _al_get(mdev, first, true);\r\n}\r\nbool drbd_al_begin_io_prepare(struct drbd_conf *mdev, struct drbd_interval *i)\r\n{\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nunsigned enr;\r\nbool need_transaction = false;\r\nD_ASSERT(first <= last);\r\nD_ASSERT(atomic_read(&mdev->local_cnt) > 0);\r\nfor (enr = first; enr <= last; enr++) {\r\nstruct lc_element *al_ext;\r\nwait_event(mdev->al_wait,\r\n(al_ext = _al_get(mdev, enr, false)) != NULL);\r\nif (al_ext->lc_number != enr)\r\nneed_transaction = true;\r\n}\r\nreturn need_transaction;\r\n}\r\nvoid drbd_al_begin_io_commit(struct drbd_conf *mdev, bool delegate)\r\n{\r\nbool locked = false;\r\nBUG_ON(delegate && current == mdev->tconn->worker.task);\r\nwait_event(mdev->al_wait,\r\nmdev->act_log->pending_changes == 0 ||\r\n(locked = lc_try_lock_for_transaction(mdev->act_log)));\r\nif (locked) {\r\nif (mdev->act_log->pending_changes) {\r\nbool write_al_updates;\r\nrcu_read_lock();\r\nwrite_al_updates = rcu_dereference(mdev->ldev->disk_conf)->al_updates;\r\nrcu_read_unlock();\r\nif (write_al_updates)\r\nal_write_transaction(mdev, delegate);\r\nspin_lock_irq(&mdev->al_lock);\r\nlc_committed(mdev->act_log);\r\nspin_unlock_irq(&mdev->al_lock);\r\n}\r\nlc_unlock(mdev->act_log);\r\nwake_up(&mdev->al_wait);\r\n}\r\n}\r\nvoid drbd_al_begin_io(struct drbd_conf *mdev, struct drbd_interval *i, bool delegate)\r\n{\r\nBUG_ON(delegate && current == mdev->tconn->worker.task);\r\nif (drbd_al_begin_io_prepare(mdev, i))\r\ndrbd_al_begin_io_commit(mdev, delegate);\r\n}\r\nint drbd_al_begin_io_nonblock(struct drbd_conf *mdev, struct drbd_interval *i)\r\n{\r\nstruct lru_cache *al = mdev->act_log;\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nunsigned nr_al_extents;\r\nunsigned available_update_slots;\r\nunsigned enr;\r\nD_ASSERT(first <= last);\r\nnr_al_extents = 1 + last - first;\r\navailable_update_slots = min(al->nr_elements - al->used,\r\nal->max_pending_changes - al->pending_changes);\r\nif (available_update_slots < nr_al_extents)\r\nreturn -EWOULDBLOCK;\r\nfor (enr = first; enr <= last; enr++) {\r\nstruct lc_element *tmp;\r\ntmp = lc_find(mdev->resync, enr/AL_EXT_PER_BM_SECT);\r\nif (unlikely(tmp != NULL)) {\r\nstruct bm_extent *bm_ext = lc_entry(tmp, struct bm_extent, lce);\r\nif (test_bit(BME_NO_WRITES, &bm_ext->flags)) {\r\nif (!test_and_set_bit(BME_PRIORITY, &bm_ext->flags))\r\nreturn -EBUSY;\r\nreturn -EWOULDBLOCK;\r\n}\r\n}\r\n}\r\nfor (enr = first; enr <= last; enr++) {\r\nstruct lc_element *al_ext;\r\nal_ext = lc_get_cumulative(mdev->act_log, enr);\r\nif (!al_ext)\r\ndev_info(DEV, "LOGIC BUG for enr=%u\n", enr);\r\n}\r\nreturn 0;\r\n}\r\nvoid drbd_al_complete_io(struct drbd_conf *mdev, struct drbd_interval *i)\r\n{\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nunsigned enr;\r\nstruct lc_element *extent;\r\nunsigned long flags;\r\nD_ASSERT(first <= last);\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\nfor (enr = first; enr <= last; enr++) {\r\nextent = lc_find(mdev->act_log, enr);\r\nif (!extent) {\r\ndev_err(DEV, "al_complete_io() called on inactive extent %u\n", enr);\r\ncontinue;\r\n}\r\nlc_put(mdev->act_log, extent);\r\n}\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\nwake_up(&mdev->al_wait);\r\n}\r\nstatic unsigned int al_extent_to_bm_page(unsigned int al_enr)\r\n{\r\nreturn al_enr >>\r\n((PAGE_SHIFT + 3) -\r\n(AL_EXTENT_SHIFT - BM_BLOCK_SHIFT));\r\n}\r\nstatic unsigned int rs_extent_to_bm_page(unsigned int rs_enr)\r\n{\r\nreturn rs_enr >>\r\n((PAGE_SHIFT + 3) -\r\n(BM_EXT_SHIFT - BM_BLOCK_SHIFT));\r\n}\r\nstatic sector_t al_tr_number_to_on_disk_sector(struct drbd_conf *mdev)\r\n{\r\nconst unsigned int stripes = mdev->ldev->md.al_stripes;\r\nconst unsigned int stripe_size_4kB = mdev->ldev->md.al_stripe_size_4k;\r\nunsigned int t = mdev->al_tr_number % (mdev->ldev->md.al_size_4k);\r\nt = ((t % stripes) * stripe_size_4kB) + t/stripes;\r\nt *= 8;\r\nreturn mdev->ldev->md.md_offset + mdev->ldev->md.al_offset + t;\r\n}\r\nstatic int\r\n_al_write_transaction(struct drbd_conf *mdev)\r\n{\r\nstruct al_transaction_on_disk *buffer;\r\nstruct lc_element *e;\r\nsector_t sector;\r\nint i, mx;\r\nunsigned extent_nr;\r\nunsigned crc = 0;\r\nint err = 0;\r\nif (!get_ldev(mdev)) {\r\ndev_err(DEV, "disk is %s, cannot start al transaction\n",\r\ndrbd_disk_str(mdev->state.disk));\r\nreturn -EIO;\r\n}\r\nif (mdev->state.disk < D_INCONSISTENT) {\r\ndev_err(DEV,\r\n"disk is %s, cannot write al transaction\n",\r\ndrbd_disk_str(mdev->state.disk));\r\nput_ldev(mdev);\r\nreturn -EIO;\r\n}\r\nbuffer = drbd_md_get_buffer(mdev);\r\nif (!buffer) {\r\ndev_err(DEV, "disk failed while waiting for md_io buffer\n");\r\nput_ldev(mdev);\r\nreturn -ENODEV;\r\n}\r\nmemset(buffer, 0, sizeof(*buffer));\r\nbuffer->magic = cpu_to_be32(DRBD_AL_MAGIC);\r\nbuffer->tr_number = cpu_to_be32(mdev->al_tr_number);\r\ni = 0;\r\nspin_lock_irq(&mdev->al_lock);\r\nlist_for_each_entry(e, &mdev->act_log->to_be_changed, list) {\r\nif (i == AL_UPDATES_PER_TRANSACTION) {\r\ni++;\r\nbreak;\r\n}\r\nbuffer->update_slot_nr[i] = cpu_to_be16(e->lc_index);\r\nbuffer->update_extent_nr[i] = cpu_to_be32(e->lc_new_number);\r\nif (e->lc_number != LC_FREE)\r\ndrbd_bm_mark_for_writeout(mdev,\r\nal_extent_to_bm_page(e->lc_number));\r\ni++;\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nBUG_ON(i > AL_UPDATES_PER_TRANSACTION);\r\nbuffer->n_updates = cpu_to_be16(i);\r\nfor ( ; i < AL_UPDATES_PER_TRANSACTION; i++) {\r\nbuffer->update_slot_nr[i] = cpu_to_be16(-1);\r\nbuffer->update_extent_nr[i] = cpu_to_be32(LC_FREE);\r\n}\r\nbuffer->context_size = cpu_to_be16(mdev->act_log->nr_elements);\r\nbuffer->context_start_slot_nr = cpu_to_be16(mdev->al_tr_cycle);\r\nmx = min_t(int, AL_CONTEXT_PER_TRANSACTION,\r\nmdev->act_log->nr_elements - mdev->al_tr_cycle);\r\nfor (i = 0; i < mx; i++) {\r\nunsigned idx = mdev->al_tr_cycle + i;\r\nextent_nr = lc_element_by_index(mdev->act_log, idx)->lc_number;\r\nbuffer->context[i] = cpu_to_be32(extent_nr);\r\n}\r\nfor (; i < AL_CONTEXT_PER_TRANSACTION; i++)\r\nbuffer->context[i] = cpu_to_be32(LC_FREE);\r\nmdev->al_tr_cycle += AL_CONTEXT_PER_TRANSACTION;\r\nif (mdev->al_tr_cycle >= mdev->act_log->nr_elements)\r\nmdev->al_tr_cycle = 0;\r\nsector = al_tr_number_to_on_disk_sector(mdev);\r\ncrc = crc32c(0, buffer, 4096);\r\nbuffer->crc32c = cpu_to_be32(crc);\r\nif (drbd_bm_write_hinted(mdev))\r\nerr = -EIO;\r\nelse {\r\nbool write_al_updates;\r\nrcu_read_lock();\r\nwrite_al_updates = rcu_dereference(mdev->ldev->disk_conf)->al_updates;\r\nrcu_read_unlock();\r\nif (write_al_updates) {\r\nif (drbd_md_sync_page_io(mdev, mdev->ldev, sector, WRITE)) {\r\nerr = -EIO;\r\ndrbd_chk_io_error(mdev, 1, DRBD_META_IO_ERROR);\r\n} else {\r\nmdev->al_tr_number++;\r\nmdev->al_writ_cnt++;\r\n}\r\n}\r\n}\r\ndrbd_md_put_buffer(mdev);\r\nput_ldev(mdev);\r\nreturn err;\r\n}\r\nstatic int w_al_write_transaction(struct drbd_work *w, int unused)\r\n{\r\nstruct update_al_work *aw = container_of(w, struct update_al_work, w);\r\nstruct drbd_conf *mdev = w->mdev;\r\nint err;\r\nerr = _al_write_transaction(mdev);\r\naw->err = err;\r\ncomplete(&aw->event);\r\nreturn err != -EIO ? err : 0;\r\n}\r\nstatic int al_write_transaction(struct drbd_conf *mdev, bool delegate)\r\n{\r\nif (delegate) {\r\nstruct update_al_work al_work;\r\ninit_completion(&al_work.event);\r\nal_work.w.cb = w_al_write_transaction;\r\nal_work.w.mdev = mdev;\r\ndrbd_queue_work_front(&mdev->tconn->sender_work, &al_work.w);\r\nwait_for_completion(&al_work.event);\r\nreturn al_work.err;\r\n} else\r\nreturn _al_write_transaction(mdev);\r\n}\r\nstatic int _try_lc_del(struct drbd_conf *mdev, struct lc_element *al_ext)\r\n{\r\nint rv;\r\nspin_lock_irq(&mdev->al_lock);\r\nrv = (al_ext->refcnt == 0);\r\nif (likely(rv))\r\nlc_del(mdev->act_log, al_ext);\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn rv;\r\n}\r\nvoid drbd_al_shrink(struct drbd_conf *mdev)\r\n{\r\nstruct lc_element *al_ext;\r\nint i;\r\nD_ASSERT(test_bit(__LC_LOCKED, &mdev->act_log->flags));\r\nfor (i = 0; i < mdev->act_log->nr_elements; i++) {\r\nal_ext = lc_element_by_index(mdev->act_log, i);\r\nif (al_ext->lc_number == LC_FREE)\r\ncontinue;\r\nwait_event(mdev->al_wait, _try_lc_del(mdev, al_ext));\r\n}\r\nwake_up(&mdev->al_wait);\r\n}\r\nint drbd_initialize_al(struct drbd_conf *mdev, void *buffer)\r\n{\r\nstruct al_transaction_on_disk *al = buffer;\r\nstruct drbd_md *md = &mdev->ldev->md;\r\nsector_t al_base = md->md_offset + md->al_offset;\r\nint al_size_4k = md->al_stripes * md->al_stripe_size_4k;\r\nint i;\r\nmemset(al, 0, 4096);\r\nal->magic = cpu_to_be32(DRBD_AL_MAGIC);\r\nal->transaction_type = cpu_to_be16(AL_TR_INITIALIZED);\r\nal->crc32c = cpu_to_be32(crc32c(0, al, 4096));\r\nfor (i = 0; i < al_size_4k; i++) {\r\nint err = drbd_md_sync_page_io(mdev, mdev->ldev, al_base + i * 8, WRITE);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic int w_update_odbm(struct drbd_work *w, int unused)\r\n{\r\nstruct update_odbm_work *udw = container_of(w, struct update_odbm_work, w);\r\nstruct drbd_conf *mdev = w->mdev;\r\nstruct sib_info sib = { .sib_reason = SIB_SYNC_PROGRESS, };\r\nif (!get_ldev(mdev)) {\r\nif (__ratelimit(&drbd_ratelimit_state))\r\ndev_warn(DEV, "Can not update on disk bitmap, local IO disabled.\n");\r\nkfree(udw);\r\nreturn 0;\r\n}\r\ndrbd_bm_write_page(mdev, rs_extent_to_bm_page(udw->enr));\r\nput_ldev(mdev);\r\nkfree(udw);\r\nif (drbd_bm_total_weight(mdev) <= mdev->rs_failed) {\r\nswitch (mdev->state.conn) {\r\ncase C_SYNC_SOURCE: case C_SYNC_TARGET:\r\ncase C_PAUSED_SYNC_S: case C_PAUSED_SYNC_T:\r\ndrbd_resync_finished(mdev);\r\ndefault:\r\nbreak;\r\n}\r\n}\r\ndrbd_bcast_event(mdev, &sib);\r\nreturn 0;\r\n}\r\nstatic void drbd_try_clear_on_disk_bm(struct drbd_conf *mdev, sector_t sector,\r\nint count, int success)\r\n{\r\nstruct lc_element *e;\r\nstruct update_odbm_work *udw;\r\nunsigned int enr;\r\nD_ASSERT(atomic_read(&mdev->local_cnt));\r\nenr = BM_SECT_TO_EXT(sector);\r\ne = lc_get(mdev->resync, enr);\r\nif (e) {\r\nstruct bm_extent *ext = lc_entry(e, struct bm_extent, lce);\r\nif (ext->lce.lc_number == enr) {\r\nif (success)\r\next->rs_left -= count;\r\nelse\r\next->rs_failed += count;\r\nif (ext->rs_left < ext->rs_failed) {\r\ndev_warn(DEV, "BAD! sector=%llus enr=%u rs_left=%d "\r\n"rs_failed=%d count=%d cstate=%s\n",\r\n(unsigned long long)sector,\r\next->lce.lc_number, ext->rs_left,\r\next->rs_failed, count,\r\ndrbd_conn_str(mdev->state.conn));\r\next->rs_left = drbd_bm_e_weight(mdev, enr);\r\n}\r\n} else {\r\nint rs_left = drbd_bm_e_weight(mdev, enr);\r\nif (ext->flags != 0) {\r\ndev_warn(DEV, "changing resync lce: %d[%u;%02lx]"\r\n" -> %d[%u;00]\n",\r\next->lce.lc_number, ext->rs_left,\r\next->flags, enr, rs_left);\r\next->flags = 0;\r\n}\r\nif (ext->rs_failed) {\r\ndev_warn(DEV, "Kicking resync_lru element enr=%u "\r\n"out with rs_failed=%d\n",\r\next->lce.lc_number, ext->rs_failed);\r\n}\r\next->rs_left = rs_left;\r\next->rs_failed = success ? 0 : count;\r\nlc_committed(mdev->resync);\r\n}\r\nlc_put(mdev->resync, &ext->lce);\r\nif (ext->rs_left == ext->rs_failed) {\r\next->rs_failed = 0;\r\nudw = kmalloc(sizeof(*udw), GFP_ATOMIC);\r\nif (udw) {\r\nudw->enr = ext->lce.lc_number;\r\nudw->w.cb = w_update_odbm;\r\nudw->w.mdev = mdev;\r\ndrbd_queue_work_front(&mdev->tconn->sender_work, &udw->w);\r\n} else {\r\ndev_warn(DEV, "Could not kmalloc an udw\n");\r\n}\r\n}\r\n} else {\r\ndev_err(DEV, "lc_get() failed! locked=%d/%d flags=%lu\n",\r\nmdev->resync_locked,\r\nmdev->resync->nr_elements,\r\nmdev->resync->flags);\r\n}\r\n}\r\nvoid drbd_advance_rs_marks(struct drbd_conf *mdev, unsigned long still_to_go)\r\n{\r\nunsigned long now = jiffies;\r\nunsigned long last = mdev->rs_mark_time[mdev->rs_last_mark];\r\nint next = (mdev->rs_last_mark + 1) % DRBD_SYNC_MARKS;\r\nif (time_after_eq(now, last + DRBD_SYNC_MARK_STEP)) {\r\nif (mdev->rs_mark_left[mdev->rs_last_mark] != still_to_go &&\r\nmdev->state.conn != C_PAUSED_SYNC_T &&\r\nmdev->state.conn != C_PAUSED_SYNC_S) {\r\nmdev->rs_mark_time[next] = now;\r\nmdev->rs_mark_left[next] = still_to_go;\r\nmdev->rs_last_mark = next;\r\n}\r\n}\r\n}\r\nvoid __drbd_set_in_sync(struct drbd_conf *mdev, sector_t sector, int size,\r\nconst char *file, const unsigned int line)\r\n{\r\nunsigned long sbnr, ebnr, lbnr;\r\nunsigned long count = 0;\r\nsector_t esector, nr_sectors;\r\nint wake_up = 0;\r\nunsigned long flags;\r\nif (size <= 0 || !IS_ALIGNED(size, 512) || size > DRBD_MAX_BIO_SIZE) {\r\ndev_err(DEV, "drbd_set_in_sync: sector=%llus size=%d nonsense!\n",\r\n(unsigned long long)sector, size);\r\nreturn;\r\n}\r\nif (!get_ldev(mdev))\r\nreturn;\r\nnr_sectors = drbd_get_capacity(mdev->this_bdev);\r\nesector = sector + (size >> 9) - 1;\r\nif (!expect(sector < nr_sectors))\r\ngoto out;\r\nif (!expect(esector < nr_sectors))\r\nesector = nr_sectors - 1;\r\nlbnr = BM_SECT_TO_BIT(nr_sectors-1);\r\nif (unlikely(esector < BM_SECT_PER_BIT-1))\r\ngoto out;\r\nif (unlikely(esector == (nr_sectors-1)))\r\nebnr = lbnr;\r\nelse\r\nebnr = BM_SECT_TO_BIT(esector - (BM_SECT_PER_BIT-1));\r\nsbnr = BM_SECT_TO_BIT(sector + BM_SECT_PER_BIT-1);\r\nif (sbnr > ebnr)\r\ngoto out;\r\ncount = drbd_bm_clear_bits(mdev, sbnr, ebnr);\r\nif (count) {\r\ndrbd_advance_rs_marks(mdev, drbd_bm_total_weight(mdev));\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\ndrbd_try_clear_on_disk_bm(mdev, sector, count, true);\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\nwake_up = 1;\r\n}\r\nout:\r\nput_ldev(mdev);\r\nif (wake_up)\r\nwake_up(&mdev->al_wait);\r\n}\r\nint __drbd_set_out_of_sync(struct drbd_conf *mdev, sector_t sector, int size,\r\nconst char *file, const unsigned int line)\r\n{\r\nunsigned long sbnr, ebnr, flags;\r\nsector_t esector, nr_sectors;\r\nunsigned int enr, count = 0;\r\nstruct lc_element *e;\r\nif (size == 0)\r\nreturn 0;\r\nif (size < 0 || !IS_ALIGNED(size, 512) || size > DRBD_MAX_BIO_SIZE) {\r\ndev_err(DEV, "sector: %llus, size: %d\n",\r\n(unsigned long long)sector, size);\r\nreturn 0;\r\n}\r\nif (!get_ldev(mdev))\r\nreturn 0;\r\nnr_sectors = drbd_get_capacity(mdev->this_bdev);\r\nesector = sector + (size >> 9) - 1;\r\nif (!expect(sector < nr_sectors))\r\ngoto out;\r\nif (!expect(esector < nr_sectors))\r\nesector = nr_sectors - 1;\r\nsbnr = BM_SECT_TO_BIT(sector);\r\nebnr = BM_SECT_TO_BIT(esector);\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\ncount = drbd_bm_set_bits(mdev, sbnr, ebnr);\r\nenr = BM_SECT_TO_EXT(sector);\r\ne = lc_find(mdev->resync, enr);\r\nif (e)\r\nlc_entry(e, struct bm_extent, lce)->rs_left += count;\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\nout:\r\nput_ldev(mdev);\r\nreturn count;\r\n}\r\nstatic\r\nstruct bm_extent *_bme_get(struct drbd_conf *mdev, unsigned int enr)\r\n{\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint wakeup = 0;\r\nunsigned long rs_flags;\r\nspin_lock_irq(&mdev->al_lock);\r\nif (mdev->resync_locked > mdev->resync->nr_elements/2) {\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn NULL;\r\n}\r\ne = lc_get(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nif (bm_ext->lce.lc_number != enr) {\r\nbm_ext->rs_left = drbd_bm_e_weight(mdev, enr);\r\nbm_ext->rs_failed = 0;\r\nlc_committed(mdev->resync);\r\nwakeup = 1;\r\n}\r\nif (bm_ext->lce.refcnt == 1)\r\nmdev->resync_locked++;\r\nset_bit(BME_NO_WRITES, &bm_ext->flags);\r\n}\r\nrs_flags = mdev->resync->flags;\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (wakeup)\r\nwake_up(&mdev->al_wait);\r\nif (!bm_ext) {\r\nif (rs_flags & LC_STARVING)\r\ndev_warn(DEV, "Have to wait for element"\r\n" (resync LRU too small?)\n");\r\nBUG_ON(rs_flags & LC_LOCKED);\r\n}\r\nreturn bm_ext;\r\n}\r\nstatic int _is_in_al(struct drbd_conf *mdev, unsigned int enr)\r\n{\r\nint rv;\r\nspin_lock_irq(&mdev->al_lock);\r\nrv = lc_is_used(mdev->act_log, enr);\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn rv;\r\n}\r\nint drbd_rs_begin_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nstruct bm_extent *bm_ext;\r\nint i, sig;\r\nint sa = 200;\r\nretry:\r\nsig = wait_event_interruptible(mdev->al_wait,\r\n(bm_ext = _bme_get(mdev, enr)));\r\nif (sig)\r\nreturn -EINTR;\r\nif (test_bit(BME_LOCKED, &bm_ext->flags))\r\nreturn 0;\r\nfor (i = 0; i < AL_EXT_PER_BM_SECT; i++) {\r\nsig = wait_event_interruptible(mdev->al_wait,\r\n!_is_in_al(mdev, enr * AL_EXT_PER_BM_SECT + i) ||\r\ntest_bit(BME_PRIORITY, &bm_ext->flags));\r\nif (sig || (test_bit(BME_PRIORITY, &bm_ext->flags) && sa)) {\r\nspin_lock_irq(&mdev->al_lock);\r\nif (lc_put(mdev->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\nmdev->resync_locked--;\r\nwake_up(&mdev->al_wait);\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (sig)\r\nreturn -EINTR;\r\nif (schedule_timeout_interruptible(HZ/10))\r\nreturn -EINTR;\r\nif (sa && --sa == 0)\r\ndev_warn(DEV,"drbd_rs_begin_io() stepped aside for 20sec."\r\n"Resync stalled?\n");\r\ngoto retry;\r\n}\r\n}\r\nset_bit(BME_LOCKED, &bm_ext->flags);\r\nreturn 0;\r\n}\r\nint drbd_try_rs_begin_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nconst unsigned int al_enr = enr*AL_EXT_PER_BM_SECT;\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint i;\r\nspin_lock_irq(&mdev->al_lock);\r\nif (mdev->resync_wenr != LC_FREE && mdev->resync_wenr != enr) {\r\ne = lc_find(mdev->resync, mdev->resync_wenr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nD_ASSERT(!test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nclear_bit(BME_NO_WRITES, &bm_ext->flags);\r\nmdev->resync_wenr = LC_FREE;\r\nif (lc_put(mdev->resync, &bm_ext->lce) == 0)\r\nmdev->resync_locked--;\r\nwake_up(&mdev->al_wait);\r\n} else {\r\ndev_alert(DEV, "LOGIC BUG\n");\r\n}\r\n}\r\ne = lc_try_get(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nif (test_bit(BME_LOCKED, &bm_ext->flags))\r\ngoto proceed;\r\nif (!test_and_set_bit(BME_NO_WRITES, &bm_ext->flags)) {\r\nmdev->resync_locked++;\r\n} else {\r\nbm_ext->lce.refcnt--;\r\nD_ASSERT(bm_ext->lce.refcnt > 0);\r\n}\r\ngoto check_al;\r\n} else {\r\nif (mdev->resync_locked > mdev->resync->nr_elements-3)\r\ngoto try_again;\r\ne = lc_get(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (!bm_ext) {\r\nconst unsigned long rs_flags = mdev->resync->flags;\r\nif (rs_flags & LC_STARVING)\r\ndev_warn(DEV, "Have to wait for element"\r\n" (resync LRU too small?)\n");\r\nBUG_ON(rs_flags & LC_LOCKED);\r\ngoto try_again;\r\n}\r\nif (bm_ext->lce.lc_number != enr) {\r\nbm_ext->rs_left = drbd_bm_e_weight(mdev, enr);\r\nbm_ext->rs_failed = 0;\r\nlc_committed(mdev->resync);\r\nwake_up(&mdev->al_wait);\r\nD_ASSERT(test_bit(BME_LOCKED, &bm_ext->flags) == 0);\r\n}\r\nset_bit(BME_NO_WRITES, &bm_ext->flags);\r\nD_ASSERT(bm_ext->lce.refcnt == 1);\r\nmdev->resync_locked++;\r\ngoto check_al;\r\n}\r\ncheck_al:\r\nfor (i = 0; i < AL_EXT_PER_BM_SECT; i++) {\r\nif (lc_is_used(mdev->act_log, al_enr+i))\r\ngoto try_again;\r\n}\r\nset_bit(BME_LOCKED, &bm_ext->flags);\r\nproceed:\r\nmdev->resync_wenr = LC_FREE;\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn 0;\r\ntry_again:\r\nif (bm_ext)\r\nmdev->resync_wenr = enr;\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn -EAGAIN;\r\n}\r\nvoid drbd_rs_complete_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\ne = lc_find(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (!bm_ext) {\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\nif (__ratelimit(&drbd_ratelimit_state))\r\ndev_err(DEV, "drbd_rs_complete_io() called, but extent not found\n");\r\nreturn;\r\n}\r\nif (bm_ext->lce.refcnt == 0) {\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\ndev_err(DEV, "drbd_rs_complete_io(,%llu [=%u]) called, "\r\n"but refcnt is 0!?\n",\r\n(unsigned long long)sector, enr);\r\nreturn;\r\n}\r\nif (lc_put(mdev->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\nmdev->resync_locked--;\r\nwake_up(&mdev->al_wait);\r\n}\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\n}\r\nvoid drbd_rs_cancel_all(struct drbd_conf *mdev)\r\n{\r\nspin_lock_irq(&mdev->al_lock);\r\nif (get_ldev_if_state(mdev, D_FAILED)) {\r\nlc_reset(mdev->resync);\r\nput_ldev(mdev);\r\n}\r\nmdev->resync_locked = 0;\r\nmdev->resync_wenr = LC_FREE;\r\nspin_unlock_irq(&mdev->al_lock);\r\nwake_up(&mdev->al_wait);\r\n}\r\nint drbd_rs_del_all(struct drbd_conf *mdev)\r\n{\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint i;\r\nspin_lock_irq(&mdev->al_lock);\r\nif (get_ldev_if_state(mdev, D_FAILED)) {\r\nfor (i = 0; i < mdev->resync->nr_elements; i++) {\r\ne = lc_element_by_index(mdev->resync, i);\r\nbm_ext = lc_entry(e, struct bm_extent, lce);\r\nif (bm_ext->lce.lc_number == LC_FREE)\r\ncontinue;\r\nif (bm_ext->lce.lc_number == mdev->resync_wenr) {\r\ndev_info(DEV, "dropping %u in drbd_rs_del_all, apparently"\r\n" got 'synced' by application io\n",\r\nmdev->resync_wenr);\r\nD_ASSERT(!test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nclear_bit(BME_NO_WRITES, &bm_ext->flags);\r\nmdev->resync_wenr = LC_FREE;\r\nlc_put(mdev->resync, &bm_ext->lce);\r\n}\r\nif (bm_ext->lce.refcnt != 0) {\r\ndev_info(DEV, "Retrying drbd_rs_del_all() later. "\r\n"refcnt=%d\n", bm_ext->lce.refcnt);\r\nput_ldev(mdev);\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn -EAGAIN;\r\n}\r\nD_ASSERT(!test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(!test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nlc_del(mdev->resync, &bm_ext->lce);\r\n}\r\nD_ASSERT(mdev->resync->used == 0);\r\nput_ldev(mdev);\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nwake_up(&mdev->al_wait);\r\nreturn 0;\r\n}\r\nvoid drbd_rs_failed_io(struct drbd_conf *mdev, sector_t sector, int size)\r\n{\r\nunsigned long sbnr, ebnr, lbnr;\r\nunsigned long count;\r\nsector_t esector, nr_sectors;\r\nint wake_up = 0;\r\nif (size <= 0 || !IS_ALIGNED(size, 512) || size > DRBD_MAX_BIO_SIZE) {\r\ndev_err(DEV, "drbd_rs_failed_io: sector=%llus size=%d nonsense!\n",\r\n(unsigned long long)sector, size);\r\nreturn;\r\n}\r\nnr_sectors = drbd_get_capacity(mdev->this_bdev);\r\nesector = sector + (size >> 9) - 1;\r\nif (!expect(sector < nr_sectors))\r\nreturn;\r\nif (!expect(esector < nr_sectors))\r\nesector = nr_sectors - 1;\r\nlbnr = BM_SECT_TO_BIT(nr_sectors-1);\r\nif (unlikely(esector < BM_SECT_PER_BIT-1))\r\nreturn;\r\nif (unlikely(esector == (nr_sectors-1)))\r\nebnr = lbnr;\r\nelse\r\nebnr = BM_SECT_TO_BIT(esector - (BM_SECT_PER_BIT-1));\r\nsbnr = BM_SECT_TO_BIT(sector + BM_SECT_PER_BIT-1);\r\nif (sbnr > ebnr)\r\nreturn;\r\nspin_lock_irq(&mdev->al_lock);\r\ncount = drbd_bm_count_bits(mdev, sbnr, ebnr);\r\nif (count) {\r\nmdev->rs_failed += count;\r\nif (get_ldev(mdev)) {\r\ndrbd_try_clear_on_disk_bm(mdev, sector, count, false);\r\nput_ldev(mdev);\r\n}\r\nwake_up = 1;\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (wake_up)\r\nwake_up(&mdev->al_wait);\r\n}
