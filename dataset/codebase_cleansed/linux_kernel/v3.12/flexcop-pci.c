static flexcop_ibi_value flexcop_pci_read_ibi_reg(struct flexcop_device *fc,\r\nflexcop_ibi_register r)\r\n{\r\nstruct flexcop_pci *fc_pci = fc->bus_specific;\r\nflexcop_ibi_value v;\r\nv.raw = readl(fc_pci->io_mem + r);\r\nif (lastrreg != r || lastrval != v.raw) {\r\nlastrreg = r; lastrval = v.raw;\r\ndeb_reg("new rd: %3x: %08x\n", r, v.raw);\r\n}\r\nreturn v;\r\n}\r\nstatic int flexcop_pci_write_ibi_reg(struct flexcop_device *fc,\r\nflexcop_ibi_register r, flexcop_ibi_value v)\r\n{\r\nstruct flexcop_pci *fc_pci = fc->bus_specific;\r\nif (lastwreg != r || lastwval != v.raw) {\r\nlastwreg = r; lastwval = v.raw;\r\ndeb_reg("new wr: %3x: %08x\n", r, v.raw);\r\n}\r\nwritel(v.raw, fc_pci->io_mem + r);\r\nreturn 0;\r\n}\r\nstatic void flexcop_pci_irq_check_work(struct work_struct *work)\r\n{\r\nstruct flexcop_pci *fc_pci =\r\ncontainer_of(work, struct flexcop_pci, irq_check_work.work);\r\nstruct flexcop_device *fc = fc_pci->fc_dev;\r\nif (fc->feedcount) {\r\nif (fc_pci->count == fc_pci->count_prev) {\r\ndeb_chk("no IRQ since the last check\n");\r\nif (fc_pci->stream_problem++ == 3) {\r\nstruct dvb_demux_feed *feed;\r\ndeb_info("flexcop-pci: stream problem, resetting pid filter\n");\r\nspin_lock_irq(&fc->demux.lock);\r\nlist_for_each_entry(feed, &fc->demux.feed_list,\r\nlist_head) {\r\nflexcop_pid_feed_control(fc, feed, 0);\r\n}\r\nlist_for_each_entry(feed, &fc->demux.feed_list,\r\nlist_head) {\r\nflexcop_pid_feed_control(fc, feed, 1);\r\n}\r\nspin_unlock_irq(&fc->demux.lock);\r\nfc_pci->stream_problem = 0;\r\n}\r\n} else {\r\nfc_pci->stream_problem = 0;\r\nfc_pci->count_prev = fc_pci->count;\r\n}\r\n}\r\nschedule_delayed_work(&fc_pci->irq_check_work,\r\nmsecs_to_jiffies(irq_chk_intv < 100 ? 100 : irq_chk_intv));\r\n}\r\nstatic irqreturn_t flexcop_pci_isr(int irq, void *dev_id)\r\n{\r\nstruct flexcop_pci *fc_pci = dev_id;\r\nstruct flexcop_device *fc = fc_pci->fc_dev;\r\nunsigned long flags;\r\nflexcop_ibi_value v;\r\nirqreturn_t ret = IRQ_HANDLED;\r\nspin_lock_irqsave(&fc_pci->irq_lock, flags);\r\nv = fc->read_ibi_reg(fc, irq_20c);\r\nif (v.irq_20c.Data_receiver_error)\r\ndeb_chk("data receiver error\n");\r\nif (v.irq_20c.Continuity_error_flag)\r\ndeb_chk("Contunuity error flag is set\n");\r\nif (v.irq_20c.LLC_SNAP_FLAG_set)\r\ndeb_chk("LLC_SNAP_FLAG_set is set\n");\r\nif (v.irq_20c.Transport_Error)\r\ndeb_chk("Transport error\n");\r\nif ((fc_pci->count % 1000) == 0)\r\ndeb_chk("%d valid irq took place so far\n", fc_pci->count);\r\nif (v.irq_20c.DMA1_IRQ_Status == 1) {\r\nif (fc_pci->active_dma1_addr == 0)\r\nflexcop_pass_dmx_packets(fc_pci->fc_dev,\r\nfc_pci->dma[0].cpu_addr0,\r\nfc_pci->dma[0].size / 188);\r\nelse\r\nflexcop_pass_dmx_packets(fc_pci->fc_dev,\r\nfc_pci->dma[0].cpu_addr1,\r\nfc_pci->dma[0].size / 188);\r\ndeb_irq("page change to page: %d\n",!fc_pci->active_dma1_addr);\r\nfc_pci->active_dma1_addr = !fc_pci->active_dma1_addr;\r\n} else if (v.irq_20c.DMA1_Timer_Status == 1) {\r\ndma_addr_t cur_addr =\r\nfc->read_ibi_reg(fc,dma1_008).dma_0x8.dma_cur_addr << 2;\r\nu32 cur_pos = cur_addr - fc_pci->dma[0].dma_addr0;\r\ndeb_irq("%u irq: %08x cur_addr: %llx: cur_pos: %08x, "\r\n"last_cur_pos: %08x ",\r\njiffies_to_usecs(jiffies - fc_pci->last_irq),\r\nv.raw, (unsigned long long)cur_addr, cur_pos,\r\nfc_pci->last_dma1_cur_pos);\r\nfc_pci->last_irq = jiffies;\r\nif (cur_pos < fc_pci->last_dma1_cur_pos) {\r\ndeb_irq(" end was reached: passing %d bytes ",\r\n(fc_pci->dma[0].size*2 - 1) -\r\nfc_pci->last_dma1_cur_pos);\r\nflexcop_pass_dmx_data(fc_pci->fc_dev,\r\nfc_pci->dma[0].cpu_addr0 +\r\nfc_pci->last_dma1_cur_pos,\r\n(fc_pci->dma[0].size*2) -\r\nfc_pci->last_dma1_cur_pos);\r\nfc_pci->last_dma1_cur_pos = 0;\r\n}\r\nif (cur_pos > fc_pci->last_dma1_cur_pos) {\r\ndeb_irq(" passing %d bytes ",\r\ncur_pos - fc_pci->last_dma1_cur_pos);\r\nflexcop_pass_dmx_data(fc_pci->fc_dev,\r\nfc_pci->dma[0].cpu_addr0 +\r\nfc_pci->last_dma1_cur_pos,\r\ncur_pos - fc_pci->last_dma1_cur_pos);\r\n}\r\ndeb_irq("\n");\r\nfc_pci->last_dma1_cur_pos = cur_pos;\r\nfc_pci->count++;\r\n} else {\r\ndeb_irq("isr for flexcop called, "\r\n"apparently without reason (%08x)\n", v.raw);\r\nret = IRQ_NONE;\r\n}\r\nspin_unlock_irqrestore(&fc_pci->irq_lock, flags);\r\nreturn ret;\r\n}\r\nstatic int flexcop_pci_stream_control(struct flexcop_device *fc, int onoff)\r\n{\r\nstruct flexcop_pci *fc_pci = fc->bus_specific;\r\nif (onoff) {\r\nflexcop_dma_config(fc, &fc_pci->dma[0], FC_DMA_1);\r\nflexcop_dma_config(fc, &fc_pci->dma[1], FC_DMA_2);\r\nflexcop_dma_config_timer(fc, FC_DMA_1, 0);\r\nflexcop_dma_xfer_control(fc, FC_DMA_1,\r\nFC_DMA_SUBADDR_0 | FC_DMA_SUBADDR_1, 1);\r\ndeb_irq("DMA xfer enabled\n");\r\nfc_pci->last_dma1_cur_pos = 0;\r\nflexcop_dma_control_timer_irq(fc, FC_DMA_1, 1);\r\ndeb_irq("IRQ enabled\n");\r\nfc_pci->count_prev = fc_pci->count;\r\n} else {\r\nflexcop_dma_control_timer_irq(fc, FC_DMA_1, 0);\r\ndeb_irq("IRQ disabled\n");\r\nflexcop_dma_xfer_control(fc, FC_DMA_1,\r\nFC_DMA_SUBADDR_0 | FC_DMA_SUBADDR_1, 0);\r\ndeb_irq("DMA xfer disabled\n");\r\n}\r\nreturn 0;\r\n}\r\nstatic int flexcop_pci_dma_init(struct flexcop_pci *fc_pci)\r\n{\r\nint ret;\r\nret = flexcop_dma_allocate(fc_pci->pdev, &fc_pci->dma[0],\r\nFC_DEFAULT_DMA1_BUFSIZE);\r\nif (ret != 0)\r\nreturn ret;\r\nret = flexcop_dma_allocate(fc_pci->pdev, &fc_pci->dma[1],\r\nFC_DEFAULT_DMA2_BUFSIZE);\r\nif (ret != 0) {\r\nflexcop_dma_free(&fc_pci->dma[0]);\r\nreturn ret;\r\n}\r\nflexcop_sram_set_dest(fc_pci->fc_dev, FC_SRAM_DEST_MEDIA |\r\nFC_SRAM_DEST_NET, FC_SRAM_DEST_TARGET_DMA1);\r\nflexcop_sram_set_dest(fc_pci->fc_dev, FC_SRAM_DEST_CAO |\r\nFC_SRAM_DEST_CAI, FC_SRAM_DEST_TARGET_DMA2);\r\nfc_pci->init_state |= FC_PCI_DMA_INIT;\r\nreturn ret;\r\n}\r\nstatic void flexcop_pci_dma_exit(struct flexcop_pci *fc_pci)\r\n{\r\nif (fc_pci->init_state & FC_PCI_DMA_INIT) {\r\nflexcop_dma_free(&fc_pci->dma[0]);\r\nflexcop_dma_free(&fc_pci->dma[1]);\r\n}\r\nfc_pci->init_state &= ~FC_PCI_DMA_INIT;\r\n}\r\nstatic int flexcop_pci_init(struct flexcop_pci *fc_pci)\r\n{\r\nint ret;\r\ninfo("card revision %x", fc_pci->pdev->revision);\r\nif ((ret = pci_enable_device(fc_pci->pdev)) != 0)\r\nreturn ret;\r\npci_set_master(fc_pci->pdev);\r\nif ((ret = pci_request_regions(fc_pci->pdev, DRIVER_NAME)) != 0)\r\ngoto err_pci_disable_device;\r\nfc_pci->io_mem = pci_iomap(fc_pci->pdev, 0, 0x800);\r\nif (!fc_pci->io_mem) {\r\nerr("cannot map io memory\n");\r\nret = -EIO;\r\ngoto err_pci_release_regions;\r\n}\r\npci_set_drvdata(fc_pci->pdev, fc_pci);\r\nspin_lock_init(&fc_pci->irq_lock);\r\nif ((ret = request_irq(fc_pci->pdev->irq, flexcop_pci_isr,\r\nIRQF_SHARED, DRIVER_NAME, fc_pci)) != 0)\r\ngoto err_pci_iounmap;\r\nfc_pci->init_state |= FC_PCI_INIT;\r\nreturn ret;\r\nerr_pci_iounmap:\r\npci_iounmap(fc_pci->pdev, fc_pci->io_mem);\r\npci_set_drvdata(fc_pci->pdev, NULL);\r\nerr_pci_release_regions:\r\npci_release_regions(fc_pci->pdev);\r\nerr_pci_disable_device:\r\npci_disable_device(fc_pci->pdev);\r\nreturn ret;\r\n}\r\nstatic void flexcop_pci_exit(struct flexcop_pci *fc_pci)\r\n{\r\nif (fc_pci->init_state & FC_PCI_INIT) {\r\nfree_irq(fc_pci->pdev->irq, fc_pci);\r\npci_iounmap(fc_pci->pdev, fc_pci->io_mem);\r\npci_set_drvdata(fc_pci->pdev, NULL);\r\npci_release_regions(fc_pci->pdev);\r\npci_disable_device(fc_pci->pdev);\r\n}\r\nfc_pci->init_state &= ~FC_PCI_INIT;\r\n}\r\nstatic int flexcop_pci_probe(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nstruct flexcop_device *fc;\r\nstruct flexcop_pci *fc_pci;\r\nint ret = -ENOMEM;\r\nif ((fc = flexcop_device_kmalloc(sizeof(struct flexcop_pci))) == NULL) {\r\nerr("out of memory\n");\r\nreturn -ENOMEM;\r\n}\r\nfc_pci = fc->bus_specific;\r\nfc_pci->fc_dev = fc;\r\nfc->read_ibi_reg = flexcop_pci_read_ibi_reg;\r\nfc->write_ibi_reg = flexcop_pci_write_ibi_reg;\r\nfc->i2c_request = flexcop_i2c_request;\r\nfc->get_mac_addr = flexcop_eeprom_check_mac_addr;\r\nfc->stream_control = flexcop_pci_stream_control;\r\nif (enable_pid_filtering)\r\ninfo("will use the HW PID filter.");\r\nelse\r\ninfo("will pass the complete TS to the demuxer.");\r\nfc->pid_filtering = enable_pid_filtering;\r\nfc->bus_type = FC_PCI;\r\nfc->dev = &pdev->dev;\r\nfc->owner = THIS_MODULE;\r\nfc_pci->pdev = pdev;\r\nif ((ret = flexcop_pci_init(fc_pci)) != 0)\r\ngoto err_kfree;\r\nif ((ret = flexcop_device_initialize(fc)) != 0)\r\ngoto err_pci_exit;\r\nif ((ret = flexcop_pci_dma_init(fc_pci)) != 0)\r\ngoto err_fc_exit;\r\nINIT_DELAYED_WORK(&fc_pci->irq_check_work, flexcop_pci_irq_check_work);\r\nif (irq_chk_intv > 0)\r\nschedule_delayed_work(&fc_pci->irq_check_work,\r\nmsecs_to_jiffies(irq_chk_intv < 100 ?\r\n100 :\r\nirq_chk_intv));\r\nreturn ret;\r\nerr_fc_exit:\r\nflexcop_device_exit(fc);\r\nerr_pci_exit:\r\nflexcop_pci_exit(fc_pci);\r\nerr_kfree:\r\nflexcop_device_kfree(fc);\r\nreturn ret;\r\n}\r\nstatic void flexcop_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct flexcop_pci *fc_pci = pci_get_drvdata(pdev);\r\nif (irq_chk_intv > 0)\r\ncancel_delayed_work(&fc_pci->irq_check_work);\r\nflexcop_pci_dma_exit(fc_pci);\r\nflexcop_device_exit(fc_pci->fc_dev);\r\nflexcop_pci_exit(fc_pci);\r\nflexcop_device_kfree(fc_pci->fc_dev);\r\n}
