static void __intel_pmu_lbr_enable(void)\r\n{\r\nu64 debugctl;\r\nstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\r\nif (cpuc->lbr_sel)\r\nwrmsrl(MSR_LBR_SELECT, cpuc->lbr_sel->config);\r\nrdmsrl(MSR_IA32_DEBUGCTLMSR, debugctl);\r\ndebugctl |= (DEBUGCTLMSR_LBR | DEBUGCTLMSR_FREEZE_LBRS_ON_PMI);\r\nwrmsrl(MSR_IA32_DEBUGCTLMSR, debugctl);\r\n}\r\nstatic void __intel_pmu_lbr_disable(void)\r\n{\r\nu64 debugctl;\r\nrdmsrl(MSR_IA32_DEBUGCTLMSR, debugctl);\r\ndebugctl &= ~(DEBUGCTLMSR_LBR | DEBUGCTLMSR_FREEZE_LBRS_ON_PMI);\r\nwrmsrl(MSR_IA32_DEBUGCTLMSR, debugctl);\r\n}\r\nstatic void intel_pmu_lbr_reset_32(void)\r\n{\r\nint i;\r\nfor (i = 0; i < x86_pmu.lbr_nr; i++)\r\nwrmsrl(x86_pmu.lbr_from + i, 0);\r\n}\r\nstatic void intel_pmu_lbr_reset_64(void)\r\n{\r\nint i;\r\nfor (i = 0; i < x86_pmu.lbr_nr; i++) {\r\nwrmsrl(x86_pmu.lbr_from + i, 0);\r\nwrmsrl(x86_pmu.lbr_to + i, 0);\r\n}\r\n}\r\nvoid intel_pmu_lbr_reset(void)\r\n{\r\nif (!x86_pmu.lbr_nr)\r\nreturn;\r\nif (x86_pmu.intel_cap.lbr_format == LBR_FORMAT_32)\r\nintel_pmu_lbr_reset_32();\r\nelse\r\nintel_pmu_lbr_reset_64();\r\n}\r\nvoid intel_pmu_lbr_enable(struct perf_event *event)\r\n{\r\nstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\r\nif (!x86_pmu.lbr_nr)\r\nreturn;\r\nif (event->ctx->task && cpuc->lbr_context != event->ctx) {\r\nintel_pmu_lbr_reset();\r\ncpuc->lbr_context = event->ctx;\r\n}\r\ncpuc->br_sel = event->hw.branch_reg.reg;\r\ncpuc->lbr_users++;\r\n}\r\nvoid intel_pmu_lbr_disable(struct perf_event *event)\r\n{\r\nstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\r\nif (!x86_pmu.lbr_nr)\r\nreturn;\r\ncpuc->lbr_users--;\r\nWARN_ON_ONCE(cpuc->lbr_users < 0);\r\nif (cpuc->enabled && !cpuc->lbr_users) {\r\n__intel_pmu_lbr_disable();\r\ncpuc->lbr_context = NULL;\r\n}\r\n}\r\nvoid intel_pmu_lbr_enable_all(void)\r\n{\r\nstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\r\nif (cpuc->lbr_users)\r\n__intel_pmu_lbr_enable();\r\n}\r\nvoid intel_pmu_lbr_disable_all(void)\r\n{\r\nstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\r\nif (cpuc->lbr_users)\r\n__intel_pmu_lbr_disable();\r\n}\r\nstatic inline u64 intel_pmu_lbr_tos(void)\r\n{\r\nu64 tos;\r\nrdmsrl(x86_pmu.lbr_tos, tos);\r\nreturn tos;\r\n}\r\nstatic void intel_pmu_lbr_read_32(struct cpu_hw_events *cpuc)\r\n{\r\nunsigned long mask = x86_pmu.lbr_nr - 1;\r\nu64 tos = intel_pmu_lbr_tos();\r\nint i;\r\nfor (i = 0; i < x86_pmu.lbr_nr; i++) {\r\nunsigned long lbr_idx = (tos - i) & mask;\r\nunion {\r\nstruct {\r\nu32 from;\r\nu32 to;\r\n};\r\nu64 lbr;\r\n} msr_lastbranch;\r\nrdmsrl(x86_pmu.lbr_from + lbr_idx, msr_lastbranch.lbr);\r\ncpuc->lbr_entries[i].from = msr_lastbranch.from;\r\ncpuc->lbr_entries[i].to = msr_lastbranch.to;\r\ncpuc->lbr_entries[i].mispred = 0;\r\ncpuc->lbr_entries[i].predicted = 0;\r\ncpuc->lbr_entries[i].reserved = 0;\r\n}\r\ncpuc->lbr_stack.nr = i;\r\n}\r\nstatic void intel_pmu_lbr_read_64(struct cpu_hw_events *cpuc)\r\n{\r\nunsigned long mask = x86_pmu.lbr_nr - 1;\r\nint lbr_format = x86_pmu.intel_cap.lbr_format;\r\nu64 tos = intel_pmu_lbr_tos();\r\nint i;\r\nint out = 0;\r\nfor (i = 0; i < x86_pmu.lbr_nr; i++) {\r\nunsigned long lbr_idx = (tos - i) & mask;\r\nu64 from, to, mis = 0, pred = 0, in_tx = 0, abort = 0;\r\nint skip = 0;\r\nint lbr_flags = lbr_desc[lbr_format];\r\nrdmsrl(x86_pmu.lbr_from + lbr_idx, from);\r\nrdmsrl(x86_pmu.lbr_to + lbr_idx, to);\r\nif (lbr_flags & LBR_EIP_FLAGS) {\r\nmis = !!(from & LBR_FROM_FLAG_MISPRED);\r\npred = !mis;\r\nskip = 1;\r\n}\r\nif (lbr_flags & LBR_TSX) {\r\nin_tx = !!(from & LBR_FROM_FLAG_IN_TX);\r\nabort = !!(from & LBR_FROM_FLAG_ABORT);\r\nskip = 3;\r\n}\r\nfrom = (u64)((((s64)from) << skip) >> skip);\r\nif (abort && x86_pmu.lbr_double_abort && out > 0)\r\nout--;\r\ncpuc->lbr_entries[out].from = from;\r\ncpuc->lbr_entries[out].to = to;\r\ncpuc->lbr_entries[out].mispred = mis;\r\ncpuc->lbr_entries[out].predicted = pred;\r\ncpuc->lbr_entries[out].in_tx = in_tx;\r\ncpuc->lbr_entries[out].abort = abort;\r\ncpuc->lbr_entries[out].reserved = 0;\r\nout++;\r\n}\r\ncpuc->lbr_stack.nr = out;\r\n}\r\nvoid intel_pmu_lbr_read(void)\r\n{\r\nstruct cpu_hw_events *cpuc = this_cpu_ptr(&cpu_hw_events);\r\nif (!cpuc->lbr_users)\r\nreturn;\r\nif (x86_pmu.intel_cap.lbr_format == LBR_FORMAT_32)\r\nintel_pmu_lbr_read_32(cpuc);\r\nelse\r\nintel_pmu_lbr_read_64(cpuc);\r\nintel_pmu_lbr_filter(cpuc);\r\n}\r\nstatic void intel_pmu_setup_sw_lbr_filter(struct perf_event *event)\r\n{\r\nu64 br_type = event->attr.branch_sample_type;\r\nint mask = 0;\r\nif (br_type & PERF_SAMPLE_BRANCH_USER)\r\nmask |= X86_BR_USER;\r\nif (br_type & PERF_SAMPLE_BRANCH_KERNEL)\r\nmask |= X86_BR_KERNEL;\r\nif (br_type & PERF_SAMPLE_BRANCH_ANY)\r\nmask |= X86_BR_ANY;\r\nif (br_type & PERF_SAMPLE_BRANCH_ANY_CALL)\r\nmask |= X86_BR_ANY_CALL;\r\nif (br_type & PERF_SAMPLE_BRANCH_ANY_RETURN)\r\nmask |= X86_BR_RET | X86_BR_IRET | X86_BR_SYSRET;\r\nif (br_type & PERF_SAMPLE_BRANCH_IND_CALL)\r\nmask |= X86_BR_IND_CALL;\r\nif (br_type & PERF_SAMPLE_BRANCH_ABORT_TX)\r\nmask |= X86_BR_ABORT;\r\nif (br_type & PERF_SAMPLE_BRANCH_IN_TX)\r\nmask |= X86_BR_IN_TX;\r\nif (br_type & PERF_SAMPLE_BRANCH_NO_TX)\r\nmask |= X86_BR_NO_TX;\r\nif (br_type & PERF_SAMPLE_BRANCH_COND)\r\nmask |= X86_BR_JCC;\r\nevent->hw.branch_reg.reg = mask;\r\n}\r\nstatic int intel_pmu_setup_hw_lbr_filter(struct perf_event *event)\r\n{\r\nstruct hw_perf_event_extra *reg;\r\nu64 br_type = event->attr.branch_sample_type;\r\nu64 mask = 0, m;\r\nu64 v;\r\nfor_each_branch_sample_type(m) {\r\nif (!(br_type & m))\r\ncontinue;\r\nv = x86_pmu.lbr_sel_map[m];\r\nif (v == LBR_NOT_SUPP)\r\nreturn -EOPNOTSUPP;\r\nif (v != LBR_IGN)\r\nmask |= v;\r\n}\r\nreg = &event->hw.branch_reg;\r\nreg->idx = EXTRA_REG_LBR;\r\nreg->config = ~mask & x86_pmu.lbr_sel_mask;\r\nreturn 0;\r\n}\r\nint intel_pmu_setup_lbr_filter(struct perf_event *event)\r\n{\r\nint ret = 0;\r\nif (!x86_pmu.lbr_nr)\r\nreturn -EOPNOTSUPP;\r\nintel_pmu_setup_sw_lbr_filter(event);\r\nif (x86_pmu.lbr_sel_map)\r\nret = intel_pmu_setup_hw_lbr_filter(event);\r\nreturn ret;\r\n}\r\nstatic int branch_type(unsigned long from, unsigned long to, int abort)\r\n{\r\nstruct insn insn;\r\nvoid *addr;\r\nint bytes_read, bytes_left;\r\nint ret = X86_BR_NONE;\r\nint ext, to_plm, from_plm;\r\nu8 buf[MAX_INSN_SIZE];\r\nint is64 = 0;\r\nto_plm = kernel_ip(to) ? X86_BR_KERNEL : X86_BR_USER;\r\nfrom_plm = kernel_ip(from) ? X86_BR_KERNEL : X86_BR_USER;\r\nif (from == 0 || to == 0)\r\nreturn X86_BR_NONE;\r\nif (abort)\r\nreturn X86_BR_ABORT | to_plm;\r\nif (from_plm == X86_BR_USER) {\r\nif (!current->mm)\r\nreturn X86_BR_NONE;\r\nbytes_left = copy_from_user_nmi(buf, (void __user *)from,\r\nMAX_INSN_SIZE);\r\nbytes_read = MAX_INSN_SIZE - bytes_left;\r\nif (!bytes_read)\r\nreturn X86_BR_NONE;\r\naddr = buf;\r\n} else {\r\nif (kernel_text_address(from)) {\r\naddr = (void *)from;\r\nbytes_read = MAX_INSN_SIZE;\r\n} else {\r\nreturn X86_BR_NONE;\r\n}\r\n}\r\n#ifdef CONFIG_X86_64\r\nis64 = kernel_ip((unsigned long)addr) || !test_thread_flag(TIF_IA32);\r\n#endif\r\ninsn_init(&insn, addr, bytes_read, is64);\r\ninsn_get_opcode(&insn);\r\nif (!insn.opcode.got)\r\nreturn X86_BR_ABORT;\r\nswitch (insn.opcode.bytes[0]) {\r\ncase 0xf:\r\nswitch (insn.opcode.bytes[1]) {\r\ncase 0x05:\r\ncase 0x34:\r\nret = X86_BR_SYSCALL;\r\nbreak;\r\ncase 0x07:\r\ncase 0x35:\r\nret = X86_BR_SYSRET;\r\nbreak;\r\ncase 0x80 ... 0x8f:\r\nret = X86_BR_JCC;\r\nbreak;\r\ndefault:\r\nret = X86_BR_NONE;\r\n}\r\nbreak;\r\ncase 0x70 ... 0x7f:\r\nret = X86_BR_JCC;\r\nbreak;\r\ncase 0xc2:\r\ncase 0xc3:\r\ncase 0xca:\r\ncase 0xcb:\r\nret = X86_BR_RET;\r\nbreak;\r\ncase 0xcf:\r\nret = X86_BR_IRET;\r\nbreak;\r\ncase 0xcc ... 0xce:\r\nret = X86_BR_INT;\r\nbreak;\r\ncase 0xe8:\r\ncase 0x9a:\r\nret = X86_BR_CALL;\r\nbreak;\r\ncase 0xe0 ... 0xe3:\r\nret = X86_BR_JCC;\r\nbreak;\r\ncase 0xe9 ... 0xeb:\r\nret = X86_BR_JMP;\r\nbreak;\r\ncase 0xff:\r\ninsn_get_modrm(&insn);\r\next = (insn.modrm.bytes[0] >> 3) & 0x7;\r\nswitch (ext) {\r\ncase 2:\r\ncase 3:\r\nret = X86_BR_IND_CALL;\r\nbreak;\r\ncase 4:\r\ncase 5:\r\nret = X86_BR_JMP;\r\nbreak;\r\n}\r\nbreak;\r\ndefault:\r\nret = X86_BR_NONE;\r\n}\r\nif (from_plm == X86_BR_USER && to_plm == X86_BR_KERNEL\r\n&& ret != X86_BR_SYSCALL && ret != X86_BR_INT)\r\nret = X86_BR_IRQ;\r\nif (ret != X86_BR_NONE)\r\nret |= to_plm;\r\nreturn ret;\r\n}\r\nstatic void\r\nintel_pmu_lbr_filter(struct cpu_hw_events *cpuc)\r\n{\r\nu64 from, to;\r\nint br_sel = cpuc->br_sel;\r\nint i, j, type;\r\nbool compress = false;\r\nif ((br_sel & X86_BR_ALL) == X86_BR_ALL)\r\nreturn;\r\nfor (i = 0; i < cpuc->lbr_stack.nr; i++) {\r\nfrom = cpuc->lbr_entries[i].from;\r\nto = cpuc->lbr_entries[i].to;\r\ntype = branch_type(from, to, cpuc->lbr_entries[i].abort);\r\nif (type != X86_BR_NONE && (br_sel & X86_BR_ANYTX)) {\r\nif (cpuc->lbr_entries[i].in_tx)\r\ntype |= X86_BR_IN_TX;\r\nelse\r\ntype |= X86_BR_NO_TX;\r\n}\r\nif (type == X86_BR_NONE || (br_sel & type) != type) {\r\ncpuc->lbr_entries[i].from = 0;\r\ncompress = true;\r\n}\r\n}\r\nif (!compress)\r\nreturn;\r\nfor (i = 0; i < cpuc->lbr_stack.nr; ) {\r\nif (!cpuc->lbr_entries[i].from) {\r\nj = i;\r\nwhile (++j < cpuc->lbr_stack.nr)\r\ncpuc->lbr_entries[j-1] = cpuc->lbr_entries[j];\r\ncpuc->lbr_stack.nr--;\r\nif (!cpuc->lbr_entries[i].from)\r\ncontinue;\r\n}\r\ni++;\r\n}\r\n}\r\nvoid __init intel_pmu_lbr_init_core(void)\r\n{\r\nx86_pmu.lbr_nr = 4;\r\nx86_pmu.lbr_tos = MSR_LBR_TOS;\r\nx86_pmu.lbr_from = MSR_LBR_CORE_FROM;\r\nx86_pmu.lbr_to = MSR_LBR_CORE_TO;\r\npr_cont("4-deep LBR, ");\r\n}\r\nvoid __init intel_pmu_lbr_init_nhm(void)\r\n{\r\nx86_pmu.lbr_nr = 16;\r\nx86_pmu.lbr_tos = MSR_LBR_TOS;\r\nx86_pmu.lbr_from = MSR_LBR_NHM_FROM;\r\nx86_pmu.lbr_to = MSR_LBR_NHM_TO;\r\nx86_pmu.lbr_sel_mask = LBR_SEL_MASK;\r\nx86_pmu.lbr_sel_map = nhm_lbr_sel_map;\r\npr_cont("16-deep LBR, ");\r\n}\r\nvoid __init intel_pmu_lbr_init_snb(void)\r\n{\r\nx86_pmu.lbr_nr = 16;\r\nx86_pmu.lbr_tos = MSR_LBR_TOS;\r\nx86_pmu.lbr_from = MSR_LBR_NHM_FROM;\r\nx86_pmu.lbr_to = MSR_LBR_NHM_TO;\r\nx86_pmu.lbr_sel_mask = LBR_SEL_MASK;\r\nx86_pmu.lbr_sel_map = snb_lbr_sel_map;\r\npr_cont("16-deep LBR, ");\r\n}\r\nvoid __init intel_pmu_lbr_init_atom(void)\r\n{\r\nif (boot_cpu_data.x86_model == 28\r\n&& boot_cpu_data.x86_mask < 10) {\r\npr_cont("LBR disabled due to erratum");\r\nreturn;\r\n}\r\nx86_pmu.lbr_nr = 8;\r\nx86_pmu.lbr_tos = MSR_LBR_TOS;\r\nx86_pmu.lbr_from = MSR_LBR_CORE_FROM;\r\nx86_pmu.lbr_to = MSR_LBR_CORE_TO;\r\npr_cont("8-deep LBR, ");\r\n}
