void qat_crypto_put_instance(struct qat_crypto_instance *inst)\r\n{\r\nif (atomic_sub_return(1, &inst->refctr) == 0)\r\nadf_dev_put(inst->accel_dev);\r\n}\r\nstatic int qat_crypto_free_instances(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct qat_crypto_instance *inst;\r\nstruct list_head *list_ptr, *tmp;\r\nint i;\r\nlist_for_each_safe(list_ptr, tmp, &accel_dev->crypto_list) {\r\ninst = list_entry(list_ptr, struct qat_crypto_instance, list);\r\nfor (i = 0; i < atomic_read(&inst->refctr); i++)\r\nqat_crypto_put_instance(inst);\r\nif (inst->sym_tx)\r\nadf_remove_ring(inst->sym_tx);\r\nif (inst->sym_rx)\r\nadf_remove_ring(inst->sym_rx);\r\nif (inst->pke_tx)\r\nadf_remove_ring(inst->pke_tx);\r\nif (inst->pke_rx)\r\nadf_remove_ring(inst->pke_rx);\r\nif (inst->rnd_tx)\r\nadf_remove_ring(inst->rnd_tx);\r\nif (inst->rnd_rx)\r\nadf_remove_ring(inst->rnd_rx);\r\nlist_del(list_ptr);\r\nkfree(inst);\r\n}\r\nreturn 0;\r\n}\r\nstruct qat_crypto_instance *qat_crypto_get_instance_node(int node)\r\n{\r\nstruct adf_accel_dev *accel_dev = NULL;\r\nstruct qat_crypto_instance *inst_best = NULL;\r\nstruct list_head *itr;\r\nunsigned long best = ~0;\r\nlist_for_each(itr, adf_devmgr_get_head()) {\r\naccel_dev = list_entry(itr, struct adf_accel_dev, list);\r\nif ((node == dev_to_node(&GET_DEV(accel_dev)) ||\r\ndev_to_node(&GET_DEV(accel_dev)) < 0)\r\n&& adf_dev_started(accel_dev))\r\nbreak;\r\naccel_dev = NULL;\r\n}\r\nif (!accel_dev) {\r\npr_err("QAT: Could not find device on node %d\n", node);\r\naccel_dev = adf_devmgr_get_first();\r\n}\r\nif (!accel_dev || !adf_dev_started(accel_dev))\r\nreturn NULL;\r\nlist_for_each(itr, &accel_dev->crypto_list) {\r\nstruct qat_crypto_instance *inst;\r\nunsigned long cur;\r\ninst = list_entry(itr, struct qat_crypto_instance, list);\r\ncur = atomic_read(&inst->refctr);\r\nif (best > cur) {\r\ninst_best = inst;\r\nbest = cur;\r\n}\r\n}\r\nif (inst_best) {\r\nif (atomic_add_return(1, &inst_best->refctr) == 1) {\r\nif (adf_dev_get(accel_dev)) {\r\natomic_dec(&inst_best->refctr);\r\npr_err("QAT: Could increment dev refctr\n");\r\nreturn NULL;\r\n}\r\n}\r\n}\r\nreturn inst_best;\r\n}\r\nstatic int qat_crypto_create_instances(struct adf_accel_dev *accel_dev)\r\n{\r\nint i;\r\nunsigned long bank;\r\nunsigned long num_inst, num_msg_sym, num_msg_asym;\r\nint msg_size;\r\nstruct qat_crypto_instance *inst;\r\nchar key[ADF_CFG_MAX_KEY_LEN_IN_BYTES];\r\nchar val[ADF_CFG_MAX_VAL_LEN_IN_BYTES];\r\nINIT_LIST_HEAD(&accel_dev->crypto_list);\r\nstrlcpy(key, ADF_NUM_CY, sizeof(key));\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\nreturn -EFAULT;\r\nif (kstrtoul(val, 0, &num_inst))\r\nreturn -EFAULT;\r\nfor (i = 0; i < num_inst; i++) {\r\ninst = kzalloc_node(sizeof(*inst), GFP_KERNEL,\r\ndev_to_node(&GET_DEV(accel_dev)));\r\nif (!inst)\r\ngoto err;\r\nlist_add_tail(&inst->list, &accel_dev->crypto_list);\r\ninst->id = i;\r\natomic_set(&inst->refctr, 0);\r\ninst->accel_dev = accel_dev;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_BANK_NUM, i);\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\ngoto err;\r\nif (kstrtoul(val, 10, &bank))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_SIZE, i);\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\ngoto err;\r\nif (kstrtoul(val, 10, &num_msg_sym))\r\ngoto err;\r\nnum_msg_sym = num_msg_sym >> 1;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_SIZE, i);\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\ngoto err;\r\nif (kstrtoul(val, 10, &num_msg_asym))\r\ngoto err;\r\nnum_msg_asym = num_msg_asym >> 1;\r\nmsg_size = ICP_QAT_FW_REQ_DEFAULT_SZ;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_TX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_sym,\r\nmsg_size, key, NULL, 0, &inst->sym_tx))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_RND_TX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_asym,\r\nmsg_size, key, NULL, 0, &inst->rnd_tx))\r\ngoto err;\r\nmsg_size = msg_size >> 1;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_TX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_asym,\r\nmsg_size, key, NULL, 0, &inst->pke_tx))\r\ngoto err;\r\nmsg_size = ICP_QAT_FW_RESP_DEFAULT_SZ;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_RX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_sym,\r\nmsg_size, key, qat_alg_callback, 0,\r\n&inst->sym_rx))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_RND_RX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_asym,\r\nmsg_size, key, qat_alg_callback, 0,\r\n&inst->rnd_rx))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_RX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_asym,\r\nmsg_size, key, qat_alg_callback, 0,\r\n&inst->pke_rx))\r\ngoto err;\r\n}\r\nreturn 0;\r\nerr:\r\nqat_crypto_free_instances(accel_dev);\r\nreturn -ENOMEM;\r\n}\r\nstatic int qat_crypto_init(struct adf_accel_dev *accel_dev)\r\n{\r\nif (qat_crypto_create_instances(accel_dev))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nstatic int qat_crypto_shutdown(struct adf_accel_dev *accel_dev)\r\n{\r\nreturn qat_crypto_free_instances(accel_dev);\r\n}\r\nstatic int qat_crypto_event_handler(struct adf_accel_dev *accel_dev,\r\nenum adf_event event)\r\n{\r\nint ret;\r\nswitch (event) {\r\ncase ADF_EVENT_INIT:\r\nret = qat_crypto_init(accel_dev);\r\nbreak;\r\ncase ADF_EVENT_SHUTDOWN:\r\nret = qat_crypto_shutdown(accel_dev);\r\nbreak;\r\ncase ADF_EVENT_RESTARTING:\r\ncase ADF_EVENT_RESTARTED:\r\ncase ADF_EVENT_START:\r\ncase ADF_EVENT_STOP:\r\ndefault:\r\nret = 0;\r\n}\r\nreturn ret;\r\n}\r\nint qat_crypto_register(void)\r\n{\r\nmemset(&qat_crypto, 0, sizeof(qat_crypto));\r\nqat_crypto.event_hld = qat_crypto_event_handler;\r\nqat_crypto.name = "qat_crypto";\r\nreturn adf_service_register(&qat_crypto);\r\n}\r\nint qat_crypto_unregister(void)\r\n{\r\nreturn adf_service_unregister(&qat_crypto);\r\n}
