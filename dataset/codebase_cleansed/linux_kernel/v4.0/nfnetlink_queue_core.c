static struct nfnl_queue_net *nfnl_queue_pernet(struct net *net)\r\n{\r\nreturn net_generic(net, nfnl_queue_net_id);\r\n}\r\nstatic inline u_int8_t instance_hashfn(u_int16_t queue_num)\r\n{\r\nreturn ((queue_num >> 8) ^ queue_num) % INSTANCE_BUCKETS;\r\n}\r\nstatic struct nfqnl_instance *\r\ninstance_lookup(struct nfnl_queue_net *q, u_int16_t queue_num)\r\n{\r\nstruct hlist_head *head;\r\nstruct nfqnl_instance *inst;\r\nhead = &q->instance_table[instance_hashfn(queue_num)];\r\nhlist_for_each_entry_rcu(inst, head, hlist) {\r\nif (inst->queue_num == queue_num)\r\nreturn inst;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct nfqnl_instance *\r\ninstance_create(struct nfnl_queue_net *q, u_int16_t queue_num,\r\nint portid)\r\n{\r\nstruct nfqnl_instance *inst;\r\nunsigned int h;\r\nint err;\r\nspin_lock(&q->instances_lock);\r\nif (instance_lookup(q, queue_num)) {\r\nerr = -EEXIST;\r\ngoto out_unlock;\r\n}\r\ninst = kzalloc(sizeof(*inst), GFP_ATOMIC);\r\nif (!inst) {\r\nerr = -ENOMEM;\r\ngoto out_unlock;\r\n}\r\ninst->queue_num = queue_num;\r\ninst->peer_portid = portid;\r\ninst->queue_maxlen = NFQNL_QMAX_DEFAULT;\r\ninst->copy_range = NFQNL_MAX_COPY_RANGE;\r\ninst->copy_mode = NFQNL_COPY_NONE;\r\nspin_lock_init(&inst->lock);\r\nINIT_LIST_HEAD(&inst->queue_list);\r\nif (!try_module_get(THIS_MODULE)) {\r\nerr = -EAGAIN;\r\ngoto out_free;\r\n}\r\nh = instance_hashfn(queue_num);\r\nhlist_add_head_rcu(&inst->hlist, &q->instance_table[h]);\r\nspin_unlock(&q->instances_lock);\r\nreturn inst;\r\nout_free:\r\nkfree(inst);\r\nout_unlock:\r\nspin_unlock(&q->instances_lock);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic void\r\ninstance_destroy_rcu(struct rcu_head *head)\r\n{\r\nstruct nfqnl_instance *inst = container_of(head, struct nfqnl_instance,\r\nrcu);\r\nnfqnl_flush(inst, NULL, 0);\r\nkfree(inst);\r\nmodule_put(THIS_MODULE);\r\n}\r\nstatic void\r\n__instance_destroy(struct nfqnl_instance *inst)\r\n{\r\nhlist_del_rcu(&inst->hlist);\r\ncall_rcu(&inst->rcu, instance_destroy_rcu);\r\n}\r\nstatic void\r\ninstance_destroy(struct nfnl_queue_net *q, struct nfqnl_instance *inst)\r\n{\r\nspin_lock(&q->instances_lock);\r\n__instance_destroy(inst);\r\nspin_unlock(&q->instances_lock);\r\n}\r\nstatic inline void\r\n__enqueue_entry(struct nfqnl_instance *queue, struct nf_queue_entry *entry)\r\n{\r\nlist_add_tail(&entry->list, &queue->queue_list);\r\nqueue->queue_total++;\r\n}\r\nstatic void\r\n__dequeue_entry(struct nfqnl_instance *queue, struct nf_queue_entry *entry)\r\n{\r\nlist_del(&entry->list);\r\nqueue->queue_total--;\r\n}\r\nstatic struct nf_queue_entry *\r\nfind_dequeue_entry(struct nfqnl_instance *queue, unsigned int id)\r\n{\r\nstruct nf_queue_entry *entry = NULL, *i;\r\nspin_lock_bh(&queue->lock);\r\nlist_for_each_entry(i, &queue->queue_list, list) {\r\nif (i->id == id) {\r\nentry = i;\r\nbreak;\r\n}\r\n}\r\nif (entry)\r\n__dequeue_entry(queue, entry);\r\nspin_unlock_bh(&queue->lock);\r\nreturn entry;\r\n}\r\nstatic void\r\nnfqnl_flush(struct nfqnl_instance *queue, nfqnl_cmpfn cmpfn, unsigned long data)\r\n{\r\nstruct nf_queue_entry *entry, *next;\r\nspin_lock_bh(&queue->lock);\r\nlist_for_each_entry_safe(entry, next, &queue->queue_list, list) {\r\nif (!cmpfn || cmpfn(entry, data)) {\r\nlist_del(&entry->list);\r\nqueue->queue_total--;\r\nnf_reinject(entry, NF_DROP);\r\n}\r\n}\r\nspin_unlock_bh(&queue->lock);\r\n}\r\nstatic int\r\nnfqnl_put_packet_info(struct sk_buff *nlskb, struct sk_buff *packet,\r\nbool csum_verify)\r\n{\r\n__u32 flags = 0;\r\nif (packet->ip_summed == CHECKSUM_PARTIAL)\r\nflags = NFQA_SKB_CSUMNOTREADY;\r\nelse if (csum_verify)\r\nflags = NFQA_SKB_CSUM_NOTVERIFIED;\r\nif (skb_is_gso(packet))\r\nflags |= NFQA_SKB_GSO;\r\nreturn flags ? nla_put_be32(nlskb, NFQA_SKB_INFO, htonl(flags)) : 0;\r\n}\r\nstatic int nfqnl_put_sk_uidgid(struct sk_buff *skb, struct sock *sk)\r\n{\r\nconst struct cred *cred;\r\nif (sk->sk_state == TCP_TIME_WAIT)\r\nreturn 0;\r\nread_lock_bh(&sk->sk_callback_lock);\r\nif (sk->sk_socket && sk->sk_socket->file) {\r\ncred = sk->sk_socket->file->f_cred;\r\nif (nla_put_be32(skb, NFQA_UID,\r\nhtonl(from_kuid_munged(&init_user_ns, cred->fsuid))))\r\ngoto nla_put_failure;\r\nif (nla_put_be32(skb, NFQA_GID,\r\nhtonl(from_kgid_munged(&init_user_ns, cred->fsgid))))\r\ngoto nla_put_failure;\r\n}\r\nread_unlock_bh(&sk->sk_callback_lock);\r\nreturn 0;\r\nnla_put_failure:\r\nread_unlock_bh(&sk->sk_callback_lock);\r\nreturn -1;\r\n}\r\nstatic struct sk_buff *\r\nnfqnl_build_packet_message(struct net *net, struct nfqnl_instance *queue,\r\nstruct nf_queue_entry *entry,\r\n__be32 **packet_id_ptr)\r\n{\r\nsize_t size;\r\nsize_t data_len = 0, cap_len = 0;\r\nunsigned int hlen = 0;\r\nstruct sk_buff *skb;\r\nstruct nlattr *nla;\r\nstruct nfqnl_msg_packet_hdr *pmsg;\r\nstruct nlmsghdr *nlh;\r\nstruct nfgenmsg *nfmsg;\r\nstruct sk_buff *entskb = entry->skb;\r\nstruct net_device *indev;\r\nstruct net_device *outdev;\r\nstruct nf_conn *ct = NULL;\r\nenum ip_conntrack_info uninitialized_var(ctinfo);\r\nbool csum_verify;\r\nsize = nlmsg_total_size(sizeof(struct nfgenmsg))\r\n+ nla_total_size(sizeof(struct nfqnl_msg_packet_hdr))\r\n+ nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(u_int32_t))\r\n#if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\r\n+ nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(u_int32_t))\r\n#endif\r\n+ nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(struct nfqnl_msg_packet_hw))\r\n+ nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(u_int32_t));\r\nif (entskb->tstamp.tv64)\r\nsize += nla_total_size(sizeof(struct nfqnl_msg_packet_timestamp));\r\nif (entry->hook <= NF_INET_FORWARD ||\r\n(entry->hook == NF_INET_POST_ROUTING && entskb->sk == NULL))\r\ncsum_verify = !skb_csum_unnecessary(entskb);\r\nelse\r\ncsum_verify = false;\r\noutdev = entry->outdev;\r\nswitch ((enum nfqnl_config_mode)ACCESS_ONCE(queue->copy_mode)) {\r\ncase NFQNL_COPY_META:\r\ncase NFQNL_COPY_NONE:\r\nbreak;\r\ncase NFQNL_COPY_PACKET:\r\nif (!(queue->flags & NFQA_CFG_F_GSO) &&\r\nentskb->ip_summed == CHECKSUM_PARTIAL &&\r\nskb_checksum_help(entskb))\r\nreturn NULL;\r\ndata_len = ACCESS_ONCE(queue->copy_range);\r\nif (data_len > entskb->len)\r\ndata_len = entskb->len;\r\nhlen = skb_zerocopy_headlen(entskb);\r\nhlen = min_t(unsigned int, hlen, data_len);\r\nsize += sizeof(struct nlattr) + hlen;\r\ncap_len = entskb->len;\r\nbreak;\r\n}\r\nif (queue->flags & NFQA_CFG_F_CONNTRACK)\r\nct = nfqnl_ct_get(entskb, &size, &ctinfo);\r\nif (queue->flags & NFQA_CFG_F_UID_GID) {\r\nsize += (nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(u_int32_t)));\r\n}\r\nskb = nfnetlink_alloc_skb(net, size, queue->peer_portid,\r\nGFP_ATOMIC);\r\nif (!skb) {\r\nskb_tx_error(entskb);\r\nreturn NULL;\r\n}\r\nnlh = nlmsg_put(skb, 0, 0,\r\nNFNL_SUBSYS_QUEUE << 8 | NFQNL_MSG_PACKET,\r\nsizeof(struct nfgenmsg), 0);\r\nif (!nlh) {\r\nskb_tx_error(entskb);\r\nkfree_skb(skb);\r\nreturn NULL;\r\n}\r\nnfmsg = nlmsg_data(nlh);\r\nnfmsg->nfgen_family = entry->pf;\r\nnfmsg->version = NFNETLINK_V0;\r\nnfmsg->res_id = htons(queue->queue_num);\r\nnla = __nla_reserve(skb, NFQA_PACKET_HDR, sizeof(*pmsg));\r\npmsg = nla_data(nla);\r\npmsg->hw_protocol = entskb->protocol;\r\npmsg->hook = entry->hook;\r\n*packet_id_ptr = &pmsg->packet_id;\r\nindev = entry->indev;\r\nif (indev) {\r\n#if !IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\r\nif (nla_put_be32(skb, NFQA_IFINDEX_INDEV, htonl(indev->ifindex)))\r\ngoto nla_put_failure;\r\n#else\r\nif (entry->pf == PF_BRIDGE) {\r\nif (nla_put_be32(skb, NFQA_IFINDEX_PHYSINDEV,\r\nhtonl(indev->ifindex)) ||\r\nnla_put_be32(skb, NFQA_IFINDEX_INDEV,\r\nhtonl(br_port_get_rcu(indev)->br->dev->ifindex)))\r\ngoto nla_put_failure;\r\n} else {\r\nif (nla_put_be32(skb, NFQA_IFINDEX_INDEV,\r\nhtonl(indev->ifindex)))\r\ngoto nla_put_failure;\r\nif (entskb->nf_bridge && entskb->nf_bridge->physindev &&\r\nnla_put_be32(skb, NFQA_IFINDEX_PHYSINDEV,\r\nhtonl(entskb->nf_bridge->physindev->ifindex)))\r\ngoto nla_put_failure;\r\n}\r\n#endif\r\n}\r\nif (outdev) {\r\n#if !IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\r\nif (nla_put_be32(skb, NFQA_IFINDEX_OUTDEV, htonl(outdev->ifindex)))\r\ngoto nla_put_failure;\r\n#else\r\nif (entry->pf == PF_BRIDGE) {\r\nif (nla_put_be32(skb, NFQA_IFINDEX_PHYSOUTDEV,\r\nhtonl(outdev->ifindex)) ||\r\nnla_put_be32(skb, NFQA_IFINDEX_OUTDEV,\r\nhtonl(br_port_get_rcu(outdev)->br->dev->ifindex)))\r\ngoto nla_put_failure;\r\n} else {\r\nif (nla_put_be32(skb, NFQA_IFINDEX_OUTDEV,\r\nhtonl(outdev->ifindex)))\r\ngoto nla_put_failure;\r\nif (entskb->nf_bridge && entskb->nf_bridge->physoutdev &&\r\nnla_put_be32(skb, NFQA_IFINDEX_PHYSOUTDEV,\r\nhtonl(entskb->nf_bridge->physoutdev->ifindex)))\r\ngoto nla_put_failure;\r\n}\r\n#endif\r\n}\r\nif (entskb->mark &&\r\nnla_put_be32(skb, NFQA_MARK, htonl(entskb->mark)))\r\ngoto nla_put_failure;\r\nif (indev && entskb->dev &&\r\nentskb->mac_header != entskb->network_header) {\r\nstruct nfqnl_msg_packet_hw phw;\r\nint len;\r\nmemset(&phw, 0, sizeof(phw));\r\nlen = dev_parse_header(entskb, phw.hw_addr);\r\nif (len) {\r\nphw.hw_addrlen = htons(len);\r\nif (nla_put(skb, NFQA_HWADDR, sizeof(phw), &phw))\r\ngoto nla_put_failure;\r\n}\r\n}\r\nif (entskb->tstamp.tv64) {\r\nstruct nfqnl_msg_packet_timestamp ts;\r\nstruct timeval tv = ktime_to_timeval(entskb->tstamp);\r\nts.sec = cpu_to_be64(tv.tv_sec);\r\nts.usec = cpu_to_be64(tv.tv_usec);\r\nif (nla_put(skb, NFQA_TIMESTAMP, sizeof(ts), &ts))\r\ngoto nla_put_failure;\r\n}\r\nif ((queue->flags & NFQA_CFG_F_UID_GID) && entskb->sk &&\r\nnfqnl_put_sk_uidgid(skb, entskb->sk) < 0)\r\ngoto nla_put_failure;\r\nif (ct && nfqnl_ct_put(skb, ct, ctinfo) < 0)\r\ngoto nla_put_failure;\r\nif (cap_len > data_len &&\r\nnla_put_be32(skb, NFQA_CAP_LEN, htonl(cap_len)))\r\ngoto nla_put_failure;\r\nif (nfqnl_put_packet_info(skb, entskb, csum_verify))\r\ngoto nla_put_failure;\r\nif (data_len) {\r\nstruct nlattr *nla;\r\nif (skb_tailroom(skb) < sizeof(*nla) + hlen)\r\ngoto nla_put_failure;\r\nnla = (struct nlattr *)skb_put(skb, sizeof(*nla));\r\nnla->nla_type = NFQA_PAYLOAD;\r\nnla->nla_len = nla_attr_size(data_len);\r\nif (skb_zerocopy(skb, entskb, data_len, hlen))\r\ngoto nla_put_failure;\r\n}\r\nnlh->nlmsg_len = skb->len;\r\nreturn skb;\r\nnla_put_failure:\r\nskb_tx_error(entskb);\r\nkfree_skb(skb);\r\nnet_err_ratelimited("nf_queue: error creating packet message\n");\r\nreturn NULL;\r\n}\r\nstatic int\r\n__nfqnl_enqueue_packet(struct net *net, struct nfqnl_instance *queue,\r\nstruct nf_queue_entry *entry)\r\n{\r\nstruct sk_buff *nskb;\r\nint err = -ENOBUFS;\r\n__be32 *packet_id_ptr;\r\nint failopen = 0;\r\nnskb = nfqnl_build_packet_message(net, queue, entry, &packet_id_ptr);\r\nif (nskb == NULL) {\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\nspin_lock_bh(&queue->lock);\r\nif (queue->queue_total >= queue->queue_maxlen) {\r\nif (queue->flags & NFQA_CFG_F_FAIL_OPEN) {\r\nfailopen = 1;\r\nerr = 0;\r\n} else {\r\nqueue->queue_dropped++;\r\nnet_warn_ratelimited("nf_queue: full at %d entries, dropping packets(s)\n",\r\nqueue->queue_total);\r\n}\r\ngoto err_out_free_nskb;\r\n}\r\nentry->id = ++queue->id_sequence;\r\n*packet_id_ptr = htonl(entry->id);\r\nerr = nfnetlink_unicast(nskb, net, queue->peer_portid, MSG_DONTWAIT);\r\nif (err < 0) {\r\nqueue->queue_user_dropped++;\r\ngoto err_out_unlock;\r\n}\r\n__enqueue_entry(queue, entry);\r\nspin_unlock_bh(&queue->lock);\r\nreturn 0;\r\nerr_out_free_nskb:\r\nkfree_skb(nskb);\r\nerr_out_unlock:\r\nspin_unlock_bh(&queue->lock);\r\nif (failopen)\r\nnf_reinject(entry, NF_ACCEPT);\r\nerr_out:\r\nreturn err;\r\n}\r\nstatic struct nf_queue_entry *\r\nnf_queue_entry_dup(struct nf_queue_entry *e)\r\n{\r\nstruct nf_queue_entry *entry = kmemdup(e, e->size, GFP_ATOMIC);\r\nif (entry) {\r\nif (nf_queue_entry_get_refs(entry))\r\nreturn entry;\r\nkfree(entry);\r\n}\r\nreturn NULL;\r\n}\r\nstatic void nf_bridge_adjust_skb_data(struct sk_buff *skb)\r\n{\r\nif (skb->nf_bridge)\r\n__skb_push(skb, skb->network_header - skb->mac_header);\r\n}\r\nstatic void nf_bridge_adjust_segmented_data(struct sk_buff *skb)\r\n{\r\nif (skb->nf_bridge)\r\n__skb_pull(skb, skb->network_header - skb->mac_header);\r\n}\r\nstatic void free_entry(struct nf_queue_entry *entry)\r\n{\r\nnf_queue_entry_release_refs(entry);\r\nkfree(entry);\r\n}\r\nstatic int\r\n__nfqnl_enqueue_packet_gso(struct net *net, struct nfqnl_instance *queue,\r\nstruct sk_buff *skb, struct nf_queue_entry *entry)\r\n{\r\nint ret = -ENOMEM;\r\nstruct nf_queue_entry *entry_seg;\r\nnf_bridge_adjust_segmented_data(skb);\r\nif (skb->next == NULL) {\r\nstruct sk_buff *gso_skb = entry->skb;\r\nentry->skb = skb;\r\nret = __nfqnl_enqueue_packet(net, queue, entry);\r\nif (ret)\r\nentry->skb = gso_skb;\r\nreturn ret;\r\n}\r\nskb->next = NULL;\r\nentry_seg = nf_queue_entry_dup(entry);\r\nif (entry_seg) {\r\nentry_seg->skb = skb;\r\nret = __nfqnl_enqueue_packet(net, queue, entry_seg);\r\nif (ret)\r\nfree_entry(entry_seg);\r\n}\r\nreturn ret;\r\n}\r\nstatic int\r\nnfqnl_enqueue_packet(struct nf_queue_entry *entry, unsigned int queuenum)\r\n{\r\nunsigned int queued;\r\nstruct nfqnl_instance *queue;\r\nstruct sk_buff *skb, *segs;\r\nint err = -ENOBUFS;\r\nstruct net *net = dev_net(entry->indev ?\r\nentry->indev : entry->outdev);\r\nstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\r\nqueue = instance_lookup(q, queuenum);\r\nif (!queue)\r\nreturn -ESRCH;\r\nif (queue->copy_mode == NFQNL_COPY_NONE)\r\nreturn -EINVAL;\r\nskb = entry->skb;\r\nswitch (entry->pf) {\r\ncase NFPROTO_IPV4:\r\nskb->protocol = htons(ETH_P_IP);\r\nbreak;\r\ncase NFPROTO_IPV6:\r\nskb->protocol = htons(ETH_P_IPV6);\r\nbreak;\r\n}\r\nif ((queue->flags & NFQA_CFG_F_GSO) || !skb_is_gso(skb))\r\nreturn __nfqnl_enqueue_packet(net, queue, entry);\r\nnf_bridge_adjust_skb_data(skb);\r\nsegs = skb_gso_segment(skb, 0);\r\nif (IS_ERR_OR_NULL(segs))\r\ngoto out_err;\r\nqueued = 0;\r\nerr = 0;\r\ndo {\r\nstruct sk_buff *nskb = segs->next;\r\nif (err == 0)\r\nerr = __nfqnl_enqueue_packet_gso(net, queue,\r\nsegs, entry);\r\nif (err == 0)\r\nqueued++;\r\nelse\r\nkfree_skb(segs);\r\nsegs = nskb;\r\n} while (segs);\r\nif (queued) {\r\nif (err)\r\nfree_entry(entry);\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nout_err:\r\nnf_bridge_adjust_segmented_data(skb);\r\nreturn err;\r\n}\r\nstatic int\r\nnfqnl_mangle(void *data, int data_len, struct nf_queue_entry *e, int diff)\r\n{\r\nstruct sk_buff *nskb;\r\nif (diff < 0) {\r\nif (pskb_trim(e->skb, data_len))\r\nreturn -ENOMEM;\r\n} else if (diff > 0) {\r\nif (data_len > 0xFFFF)\r\nreturn -EINVAL;\r\nif (diff > skb_tailroom(e->skb)) {\r\nnskb = skb_copy_expand(e->skb, skb_headroom(e->skb),\r\ndiff, GFP_ATOMIC);\r\nif (!nskb) {\r\nprintk(KERN_WARNING "nf_queue: OOM "\r\n"in mangle, dropping packet\n");\r\nreturn -ENOMEM;\r\n}\r\nkfree_skb(e->skb);\r\ne->skb = nskb;\r\n}\r\nskb_put(e->skb, diff);\r\n}\r\nif (!skb_make_writable(e->skb, data_len))\r\nreturn -ENOMEM;\r\nskb_copy_to_linear_data(e->skb, data, data_len);\r\ne->skb->ip_summed = CHECKSUM_NONE;\r\nreturn 0;\r\n}\r\nstatic int\r\nnfqnl_set_mode(struct nfqnl_instance *queue,\r\nunsigned char mode, unsigned int range)\r\n{\r\nint status = 0;\r\nspin_lock_bh(&queue->lock);\r\nswitch (mode) {\r\ncase NFQNL_COPY_NONE:\r\ncase NFQNL_COPY_META:\r\nqueue->copy_mode = mode;\r\nqueue->copy_range = 0;\r\nbreak;\r\ncase NFQNL_COPY_PACKET:\r\nqueue->copy_mode = mode;\r\nif (range == 0 || range > NFQNL_MAX_COPY_RANGE)\r\nqueue->copy_range = NFQNL_MAX_COPY_RANGE;\r\nelse\r\nqueue->copy_range = range;\r\nbreak;\r\ndefault:\r\nstatus = -EINVAL;\r\n}\r\nspin_unlock_bh(&queue->lock);\r\nreturn status;\r\n}\r\nstatic int\r\ndev_cmp(struct nf_queue_entry *entry, unsigned long ifindex)\r\n{\r\nif (entry->indev)\r\nif (entry->indev->ifindex == ifindex)\r\nreturn 1;\r\nif (entry->outdev)\r\nif (entry->outdev->ifindex == ifindex)\r\nreturn 1;\r\n#if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)\r\nif (entry->skb->nf_bridge) {\r\nif (entry->skb->nf_bridge->physindev &&\r\nentry->skb->nf_bridge->physindev->ifindex == ifindex)\r\nreturn 1;\r\nif (entry->skb->nf_bridge->physoutdev &&\r\nentry->skb->nf_bridge->physoutdev->ifindex == ifindex)\r\nreturn 1;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void\r\nnfqnl_dev_drop(struct net *net, int ifindex)\r\n{\r\nint i;\r\nstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\r\nrcu_read_lock();\r\nfor (i = 0; i < INSTANCE_BUCKETS; i++) {\r\nstruct nfqnl_instance *inst;\r\nstruct hlist_head *head = &q->instance_table[i];\r\nhlist_for_each_entry_rcu(inst, head, hlist)\r\nnfqnl_flush(inst, dev_cmp, ifindex);\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic int\r\nnfqnl_rcv_dev_event(struct notifier_block *this,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\r\nif (event == NETDEV_DOWN)\r\nnfqnl_dev_drop(dev_net(dev), dev->ifindex);\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int\r\nnfqnl_rcv_nl_event(struct notifier_block *this,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct netlink_notify *n = ptr;\r\nstruct nfnl_queue_net *q = nfnl_queue_pernet(n->net);\r\nif (event == NETLINK_URELEASE && n->protocol == NETLINK_NETFILTER) {\r\nint i;\r\nspin_lock(&q->instances_lock);\r\nfor (i = 0; i < INSTANCE_BUCKETS; i++) {\r\nstruct hlist_node *t2;\r\nstruct nfqnl_instance *inst;\r\nstruct hlist_head *head = &q->instance_table[i];\r\nhlist_for_each_entry_safe(inst, t2, head, hlist) {\r\nif (n->portid == inst->peer_portid)\r\n__instance_destroy(inst);\r\n}\r\n}\r\nspin_unlock(&q->instances_lock);\r\n}\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic struct nfqnl_instance *\r\nverdict_instance_lookup(struct nfnl_queue_net *q, u16 queue_num, int nlportid)\r\n{\r\nstruct nfqnl_instance *queue;\r\nqueue = instance_lookup(q, queue_num);\r\nif (!queue)\r\nreturn ERR_PTR(-ENODEV);\r\nif (queue->peer_portid != nlportid)\r\nreturn ERR_PTR(-EPERM);\r\nreturn queue;\r\n}\r\nstatic struct nfqnl_msg_verdict_hdr*\r\nverdicthdr_get(const struct nlattr * const nfqa[])\r\n{\r\nstruct nfqnl_msg_verdict_hdr *vhdr;\r\nunsigned int verdict;\r\nif (!nfqa[NFQA_VERDICT_HDR])\r\nreturn NULL;\r\nvhdr = nla_data(nfqa[NFQA_VERDICT_HDR]);\r\nverdict = ntohl(vhdr->verdict) & NF_VERDICT_MASK;\r\nif (verdict > NF_MAX_VERDICT || verdict == NF_STOLEN)\r\nreturn NULL;\r\nreturn vhdr;\r\n}\r\nstatic int nfq_id_after(unsigned int id, unsigned int max)\r\n{\r\nreturn (int)(id - max) > 0;\r\n}\r\nstatic int\r\nnfqnl_recv_verdict_batch(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nstruct nfgenmsg *nfmsg = nlmsg_data(nlh);\r\nstruct nf_queue_entry *entry, *tmp;\r\nunsigned int verdict, maxid;\r\nstruct nfqnl_msg_verdict_hdr *vhdr;\r\nstruct nfqnl_instance *queue;\r\nLIST_HEAD(batch_list);\r\nu16 queue_num = ntohs(nfmsg->res_id);\r\nstruct net *net = sock_net(ctnl);\r\nstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\r\nqueue = verdict_instance_lookup(q, queue_num,\r\nNETLINK_CB(skb).portid);\r\nif (IS_ERR(queue))\r\nreturn PTR_ERR(queue);\r\nvhdr = verdicthdr_get(nfqa);\r\nif (!vhdr)\r\nreturn -EINVAL;\r\nverdict = ntohl(vhdr->verdict);\r\nmaxid = ntohl(vhdr->id);\r\nspin_lock_bh(&queue->lock);\r\nlist_for_each_entry_safe(entry, tmp, &queue->queue_list, list) {\r\nif (nfq_id_after(entry->id, maxid))\r\nbreak;\r\n__dequeue_entry(queue, entry);\r\nlist_add_tail(&entry->list, &batch_list);\r\n}\r\nspin_unlock_bh(&queue->lock);\r\nif (list_empty(&batch_list))\r\nreturn -ENOENT;\r\nlist_for_each_entry_safe(entry, tmp, &batch_list, list) {\r\nif (nfqa[NFQA_MARK])\r\nentry->skb->mark = ntohl(nla_get_be32(nfqa[NFQA_MARK]));\r\nnf_reinject(entry, verdict);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nnfqnl_recv_verdict(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nstruct nfgenmsg *nfmsg = nlmsg_data(nlh);\r\nu_int16_t queue_num = ntohs(nfmsg->res_id);\r\nstruct nfqnl_msg_verdict_hdr *vhdr;\r\nstruct nfqnl_instance *queue;\r\nunsigned int verdict;\r\nstruct nf_queue_entry *entry;\r\nenum ip_conntrack_info uninitialized_var(ctinfo);\r\nstruct nf_conn *ct = NULL;\r\nstruct net *net = sock_net(ctnl);\r\nstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\r\nqueue = instance_lookup(q, queue_num);\r\nif (!queue)\r\nqueue = verdict_instance_lookup(q, queue_num,\r\nNETLINK_CB(skb).portid);\r\nif (IS_ERR(queue))\r\nreturn PTR_ERR(queue);\r\nvhdr = verdicthdr_get(nfqa);\r\nif (!vhdr)\r\nreturn -EINVAL;\r\nverdict = ntohl(vhdr->verdict);\r\nentry = find_dequeue_entry(queue, ntohl(vhdr->id));\r\nif (entry == NULL)\r\nreturn -ENOENT;\r\nif (nfqa[NFQA_CT]) {\r\nct = nfqnl_ct_parse(entry->skb, nfqa[NFQA_CT], &ctinfo);\r\nif (ct && nfqa[NFQA_EXP]) {\r\nnfqnl_attach_expect(ct, nfqa[NFQA_EXP],\r\nNETLINK_CB(skb).portid,\r\nnlmsg_report(nlh));\r\n}\r\n}\r\nif (nfqa[NFQA_PAYLOAD]) {\r\nu16 payload_len = nla_len(nfqa[NFQA_PAYLOAD]);\r\nint diff = payload_len - entry->skb->len;\r\nif (nfqnl_mangle(nla_data(nfqa[NFQA_PAYLOAD]),\r\npayload_len, entry, diff) < 0)\r\nverdict = NF_DROP;\r\nif (ct)\r\nnfqnl_ct_seq_adjust(entry->skb, ct, ctinfo, diff);\r\n}\r\nif (nfqa[NFQA_MARK])\r\nentry->skb->mark = ntohl(nla_get_be32(nfqa[NFQA_MARK]));\r\nnf_reinject(entry, verdict);\r\nreturn 0;\r\n}\r\nstatic int\r\nnfqnl_recv_unsupp(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nreturn -ENOTSUPP;\r\n}\r\nstatic int\r\nnfqnl_recv_config(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nstruct nfgenmsg *nfmsg = nlmsg_data(nlh);\r\nu_int16_t queue_num = ntohs(nfmsg->res_id);\r\nstruct nfqnl_instance *queue;\r\nstruct nfqnl_msg_config_cmd *cmd = NULL;\r\nstruct net *net = sock_net(ctnl);\r\nstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\r\nint ret = 0;\r\nif (nfqa[NFQA_CFG_CMD]) {\r\ncmd = nla_data(nfqa[NFQA_CFG_CMD]);\r\nswitch (cmd->command) {\r\ncase NFQNL_CFG_CMD_PF_BIND: return 0;\r\ncase NFQNL_CFG_CMD_PF_UNBIND: return 0;\r\n}\r\n}\r\nrcu_read_lock();\r\nqueue = instance_lookup(q, queue_num);\r\nif (queue && queue->peer_portid != NETLINK_CB(skb).portid) {\r\nret = -EPERM;\r\ngoto err_out_unlock;\r\n}\r\nif (cmd != NULL) {\r\nswitch (cmd->command) {\r\ncase NFQNL_CFG_CMD_BIND:\r\nif (queue) {\r\nret = -EBUSY;\r\ngoto err_out_unlock;\r\n}\r\nqueue = instance_create(q, queue_num,\r\nNETLINK_CB(skb).portid);\r\nif (IS_ERR(queue)) {\r\nret = PTR_ERR(queue);\r\ngoto err_out_unlock;\r\n}\r\nbreak;\r\ncase NFQNL_CFG_CMD_UNBIND:\r\nif (!queue) {\r\nret = -ENODEV;\r\ngoto err_out_unlock;\r\n}\r\ninstance_destroy(q, queue);\r\nbreak;\r\ncase NFQNL_CFG_CMD_PF_BIND:\r\ncase NFQNL_CFG_CMD_PF_UNBIND:\r\nbreak;\r\ndefault:\r\nret = -ENOTSUPP;\r\nbreak;\r\n}\r\n}\r\nif (nfqa[NFQA_CFG_PARAMS]) {\r\nstruct nfqnl_msg_config_params *params;\r\nif (!queue) {\r\nret = -ENODEV;\r\ngoto err_out_unlock;\r\n}\r\nparams = nla_data(nfqa[NFQA_CFG_PARAMS]);\r\nnfqnl_set_mode(queue, params->copy_mode,\r\nntohl(params->copy_range));\r\n}\r\nif (nfqa[NFQA_CFG_QUEUE_MAXLEN]) {\r\n__be32 *queue_maxlen;\r\nif (!queue) {\r\nret = -ENODEV;\r\ngoto err_out_unlock;\r\n}\r\nqueue_maxlen = nla_data(nfqa[NFQA_CFG_QUEUE_MAXLEN]);\r\nspin_lock_bh(&queue->lock);\r\nqueue->queue_maxlen = ntohl(*queue_maxlen);\r\nspin_unlock_bh(&queue->lock);\r\n}\r\nif (nfqa[NFQA_CFG_FLAGS]) {\r\n__u32 flags, mask;\r\nif (!queue) {\r\nret = -ENODEV;\r\ngoto err_out_unlock;\r\n}\r\nif (!nfqa[NFQA_CFG_MASK]) {\r\nret = -EINVAL;\r\ngoto err_out_unlock;\r\n}\r\nflags = ntohl(nla_get_be32(nfqa[NFQA_CFG_FLAGS]));\r\nmask = ntohl(nla_get_be32(nfqa[NFQA_CFG_MASK]));\r\nif (flags >= NFQA_CFG_F_MAX) {\r\nret = -EOPNOTSUPP;\r\ngoto err_out_unlock;\r\n}\r\nspin_lock_bh(&queue->lock);\r\nqueue->flags &= ~mask;\r\nqueue->flags |= flags & mask;\r\nspin_unlock_bh(&queue->lock);\r\n}\r\nerr_out_unlock:\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nstatic struct hlist_node *get_first(struct seq_file *seq)\r\n{\r\nstruct iter_state *st = seq->private;\r\nstruct net *net;\r\nstruct nfnl_queue_net *q;\r\nif (!st)\r\nreturn NULL;\r\nnet = seq_file_net(seq);\r\nq = nfnl_queue_pernet(net);\r\nfor (st->bucket = 0; st->bucket < INSTANCE_BUCKETS; st->bucket++) {\r\nif (!hlist_empty(&q->instance_table[st->bucket]))\r\nreturn q->instance_table[st->bucket].first;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct hlist_node *get_next(struct seq_file *seq, struct hlist_node *h)\r\n{\r\nstruct iter_state *st = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nh = h->next;\r\nwhile (!h) {\r\nstruct nfnl_queue_net *q;\r\nif (++st->bucket >= INSTANCE_BUCKETS)\r\nreturn NULL;\r\nq = nfnl_queue_pernet(net);\r\nh = q->instance_table[st->bucket].first;\r\n}\r\nreturn h;\r\n}\r\nstatic struct hlist_node *get_idx(struct seq_file *seq, loff_t pos)\r\n{\r\nstruct hlist_node *head;\r\nhead = get_first(seq);\r\nif (head)\r\nwhile (pos && (head = get_next(seq, head)))\r\npos--;\r\nreturn pos ? NULL : head;\r\n}\r\nstatic void *seq_start(struct seq_file *s, loff_t *pos)\r\n__acquires(nfnl_queue_pernet(seq_file_net(s)\r\nstatic void *seq_next(struct seq_file *s, void *v, loff_t *pos)\r\n{\r\n(*pos)++;\r\nreturn get_next(s, v);\r\n}\r\nstatic void seq_stop(struct seq_file *s, void *v)\r\n__releases(nfnl_queue_pernet(seq_file_net(s)\r\nstatic int seq_show(struct seq_file *s, void *v)\r\n{\r\nconst struct nfqnl_instance *inst = v;\r\nseq_printf(s, "%5d %6d %5d %1d %5d %5d %5d %8d %2d\n",\r\ninst->queue_num,\r\ninst->peer_portid, inst->queue_total,\r\ninst->copy_mode, inst->copy_range,\r\ninst->queue_dropped, inst->queue_user_dropped,\r\ninst->id_sequence, 1);\r\nreturn seq_has_overflowed(s);\r\n}\r\nstatic int nfqnl_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open_net(inode, file, &nfqnl_seq_ops,\r\nsizeof(struct iter_state));\r\n}\r\nstatic int __net_init nfnl_queue_net_init(struct net *net)\r\n{\r\nunsigned int i;\r\nstruct nfnl_queue_net *q = nfnl_queue_pernet(net);\r\nfor (i = 0; i < INSTANCE_BUCKETS; i++)\r\nINIT_HLIST_HEAD(&q->instance_table[i]);\r\nspin_lock_init(&q->instances_lock);\r\n#ifdef CONFIG_PROC_FS\r\nif (!proc_create("nfnetlink_queue", 0440,\r\nnet->nf.proc_netfilter, &nfqnl_file_ops))\r\nreturn -ENOMEM;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void __net_exit nfnl_queue_net_exit(struct net *net)\r\n{\r\n#ifdef CONFIG_PROC_FS\r\nremove_proc_entry("nfnetlink_queue", net->nf.proc_netfilter);\r\n#endif\r\n}\r\nstatic int __init nfnetlink_queue_init(void)\r\n{\r\nint status = -ENOMEM;\r\nnetlink_register_notifier(&nfqnl_rtnl_notifier);\r\nstatus = nfnetlink_subsys_register(&nfqnl_subsys);\r\nif (status < 0) {\r\npr_err("nf_queue: failed to create netlink socket\n");\r\ngoto cleanup_netlink_notifier;\r\n}\r\nstatus = register_pernet_subsys(&nfnl_queue_net_ops);\r\nif (status < 0) {\r\npr_err("nf_queue: failed to register pernet ops\n");\r\ngoto cleanup_subsys;\r\n}\r\nregister_netdevice_notifier(&nfqnl_dev_notifier);\r\nnf_register_queue_handler(&nfqh);\r\nreturn status;\r\ncleanup_subsys:\r\nnfnetlink_subsys_unregister(&nfqnl_subsys);\r\ncleanup_netlink_notifier:\r\nnetlink_unregister_notifier(&nfqnl_rtnl_notifier);\r\nreturn status;\r\n}\r\nstatic void __exit nfnetlink_queue_fini(void)\r\n{\r\nnf_unregister_queue_handler();\r\nunregister_netdevice_notifier(&nfqnl_dev_notifier);\r\nunregister_pernet_subsys(&nfnl_queue_net_ops);\r\nnfnetlink_subsys_unregister(&nfqnl_subsys);\r\nnetlink_unregister_notifier(&nfqnl_rtnl_notifier);\r\nrcu_barrier();\r\n}
