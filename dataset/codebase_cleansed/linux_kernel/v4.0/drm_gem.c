int\r\ndrm_gem_init(struct drm_device *dev)\r\n{\r\nstruct drm_vma_offset_manager *vma_offset_manager;\r\nmutex_init(&dev->object_name_lock);\r\nidr_init(&dev->object_name_idr);\r\nvma_offset_manager = kzalloc(sizeof(*vma_offset_manager), GFP_KERNEL);\r\nif (!vma_offset_manager) {\r\nDRM_ERROR("out of memory\n");\r\nreturn -ENOMEM;\r\n}\r\ndev->vma_offset_manager = vma_offset_manager;\r\ndrm_vma_offset_manager_init(vma_offset_manager,\r\nDRM_FILE_PAGE_OFFSET_START,\r\nDRM_FILE_PAGE_OFFSET_SIZE);\r\nreturn 0;\r\n}\r\nvoid\r\ndrm_gem_destroy(struct drm_device *dev)\r\n{\r\ndrm_vma_offset_manager_destroy(dev->vma_offset_manager);\r\nkfree(dev->vma_offset_manager);\r\ndev->vma_offset_manager = NULL;\r\n}\r\nint drm_gem_object_init(struct drm_device *dev,\r\nstruct drm_gem_object *obj, size_t size)\r\n{\r\nstruct file *filp;\r\ndrm_gem_private_object_init(dev, obj, size);\r\nfilp = shmem_file_setup("drm mm object", size, VM_NORESERVE);\r\nif (IS_ERR(filp))\r\nreturn PTR_ERR(filp);\r\nobj->filp = filp;\r\nreturn 0;\r\n}\r\nvoid drm_gem_private_object_init(struct drm_device *dev,\r\nstruct drm_gem_object *obj, size_t size)\r\n{\r\nBUG_ON((size & (PAGE_SIZE - 1)) != 0);\r\nobj->dev = dev;\r\nobj->filp = NULL;\r\nkref_init(&obj->refcount);\r\nobj->handle_count = 0;\r\nobj->size = size;\r\ndrm_vma_node_reset(&obj->vma_node);\r\n}\r\nstatic void\r\ndrm_gem_remove_prime_handles(struct drm_gem_object *obj, struct drm_file *filp)\r\n{\r\nmutex_lock(&filp->prime.lock);\r\nif (obj->dma_buf) {\r\ndrm_prime_remove_buf_handle_locked(&filp->prime,\r\nobj->dma_buf);\r\n}\r\nmutex_unlock(&filp->prime.lock);\r\n}\r\nstatic void drm_gem_object_handle_free(struct drm_gem_object *obj)\r\n{\r\nstruct drm_device *dev = obj->dev;\r\nif (obj->name) {\r\nidr_remove(&dev->object_name_idr, obj->name);\r\nobj->name = 0;\r\n}\r\n}\r\nstatic void drm_gem_object_exported_dma_buf_free(struct drm_gem_object *obj)\r\n{\r\nif (obj->dma_buf) {\r\ndma_buf_put(obj->dma_buf);\r\nobj->dma_buf = NULL;\r\n}\r\n}\r\nstatic void\r\ndrm_gem_object_handle_unreference_unlocked(struct drm_gem_object *obj)\r\n{\r\nif (WARN_ON(obj->handle_count == 0))\r\nreturn;\r\nmutex_lock(&obj->dev->object_name_lock);\r\nif (--obj->handle_count == 0) {\r\ndrm_gem_object_handle_free(obj);\r\ndrm_gem_object_exported_dma_buf_free(obj);\r\n}\r\nmutex_unlock(&obj->dev->object_name_lock);\r\ndrm_gem_object_unreference_unlocked(obj);\r\n}\r\nint\r\ndrm_gem_handle_delete(struct drm_file *filp, u32 handle)\r\n{\r\nstruct drm_device *dev;\r\nstruct drm_gem_object *obj;\r\nspin_lock(&filp->table_lock);\r\nobj = idr_find(&filp->object_idr, handle);\r\nif (obj == NULL) {\r\nspin_unlock(&filp->table_lock);\r\nreturn -EINVAL;\r\n}\r\ndev = obj->dev;\r\nidr_remove(&filp->object_idr, handle);\r\nspin_unlock(&filp->table_lock);\r\nif (drm_core_check_feature(dev, DRIVER_PRIME))\r\ndrm_gem_remove_prime_handles(obj, filp);\r\ndrm_vma_node_revoke(&obj->vma_node, filp->filp);\r\nif (dev->driver->gem_close_object)\r\ndev->driver->gem_close_object(obj, filp);\r\ndrm_gem_object_handle_unreference_unlocked(obj);\r\nreturn 0;\r\n}\r\nint drm_gem_dumb_destroy(struct drm_file *file,\r\nstruct drm_device *dev,\r\nuint32_t handle)\r\n{\r\nreturn drm_gem_handle_delete(file, handle);\r\n}\r\nint\r\ndrm_gem_handle_create_tail(struct drm_file *file_priv,\r\nstruct drm_gem_object *obj,\r\nu32 *handlep)\r\n{\r\nstruct drm_device *dev = obj->dev;\r\nint ret;\r\nWARN_ON(!mutex_is_locked(&dev->object_name_lock));\r\nidr_preload(GFP_KERNEL);\r\nspin_lock(&file_priv->table_lock);\r\nret = idr_alloc(&file_priv->object_idr, obj, 1, 0, GFP_NOWAIT);\r\ndrm_gem_object_reference(obj);\r\nobj->handle_count++;\r\nspin_unlock(&file_priv->table_lock);\r\nidr_preload_end();\r\nmutex_unlock(&dev->object_name_lock);\r\nif (ret < 0) {\r\ndrm_gem_object_handle_unreference_unlocked(obj);\r\nreturn ret;\r\n}\r\n*handlep = ret;\r\nret = drm_vma_node_allow(&obj->vma_node, file_priv->filp);\r\nif (ret) {\r\ndrm_gem_handle_delete(file_priv, *handlep);\r\nreturn ret;\r\n}\r\nif (dev->driver->gem_open_object) {\r\nret = dev->driver->gem_open_object(obj, file_priv);\r\nif (ret) {\r\ndrm_gem_handle_delete(file_priv, *handlep);\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint drm_gem_handle_create(struct drm_file *file_priv,\r\nstruct drm_gem_object *obj,\r\nu32 *handlep)\r\n{\r\nmutex_lock(&obj->dev->object_name_lock);\r\nreturn drm_gem_handle_create_tail(file_priv, obj, handlep);\r\n}\r\nvoid\r\ndrm_gem_free_mmap_offset(struct drm_gem_object *obj)\r\n{\r\nstruct drm_device *dev = obj->dev;\r\ndrm_vma_offset_remove(dev->vma_offset_manager, &obj->vma_node);\r\n}\r\nint\r\ndrm_gem_create_mmap_offset_size(struct drm_gem_object *obj, size_t size)\r\n{\r\nstruct drm_device *dev = obj->dev;\r\nreturn drm_vma_offset_add(dev->vma_offset_manager, &obj->vma_node,\r\nsize / PAGE_SIZE);\r\n}\r\nint drm_gem_create_mmap_offset(struct drm_gem_object *obj)\r\n{\r\nreturn drm_gem_create_mmap_offset_size(obj, obj->size);\r\n}\r\nstruct page **drm_gem_get_pages(struct drm_gem_object *obj)\r\n{\r\nstruct address_space *mapping;\r\nstruct page *p, **pages;\r\nint i, npages;\r\nmapping = file_inode(obj->filp)->i_mapping;\r\nWARN_ON((obj->size & (PAGE_SIZE - 1)) != 0);\r\nnpages = obj->size >> PAGE_SHIFT;\r\npages = drm_malloc_ab(npages, sizeof(struct page *));\r\nif (pages == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nfor (i = 0; i < npages; i++) {\r\np = shmem_read_mapping_page(mapping, i);\r\nif (IS_ERR(p))\r\ngoto fail;\r\npages[i] = p;\r\nBUG_ON((mapping_gfp_mask(mapping) & __GFP_DMA32) &&\r\n(page_to_pfn(p) >= 0x00100000UL));\r\n}\r\nreturn pages;\r\nfail:\r\nwhile (i--)\r\npage_cache_release(pages[i]);\r\ndrm_free_large(pages);\r\nreturn ERR_CAST(p);\r\n}\r\nvoid drm_gem_put_pages(struct drm_gem_object *obj, struct page **pages,\r\nbool dirty, bool accessed)\r\n{\r\nint i, npages;\r\nWARN_ON((obj->size & (PAGE_SIZE - 1)) != 0);\r\nnpages = obj->size >> PAGE_SHIFT;\r\nfor (i = 0; i < npages; i++) {\r\nif (dirty)\r\nset_page_dirty(pages[i]);\r\nif (accessed)\r\nmark_page_accessed(pages[i]);\r\npage_cache_release(pages[i]);\r\n}\r\ndrm_free_large(pages);\r\n}\r\nstruct drm_gem_object *\r\ndrm_gem_object_lookup(struct drm_device *dev, struct drm_file *filp,\r\nu32 handle)\r\n{\r\nstruct drm_gem_object *obj;\r\nspin_lock(&filp->table_lock);\r\nobj = idr_find(&filp->object_idr, handle);\r\nif (obj == NULL) {\r\nspin_unlock(&filp->table_lock);\r\nreturn NULL;\r\n}\r\ndrm_gem_object_reference(obj);\r\nspin_unlock(&filp->table_lock);\r\nreturn obj;\r\n}\r\nint\r\ndrm_gem_close_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_gem_close *args = data;\r\nint ret;\r\nif (!drm_core_check_feature(dev, DRIVER_GEM))\r\nreturn -ENODEV;\r\nret = drm_gem_handle_delete(file_priv, args->handle);\r\nreturn ret;\r\n}\r\nint\r\ndrm_gem_flink_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_gem_flink *args = data;\r\nstruct drm_gem_object *obj;\r\nint ret;\r\nif (!drm_core_check_feature(dev, DRIVER_GEM))\r\nreturn -ENODEV;\r\nobj = drm_gem_object_lookup(dev, file_priv, args->handle);\r\nif (obj == NULL)\r\nreturn -ENOENT;\r\nmutex_lock(&dev->object_name_lock);\r\nidr_preload(GFP_KERNEL);\r\nif (obj->handle_count == 0) {\r\nret = -ENOENT;\r\ngoto err;\r\n}\r\nif (!obj->name) {\r\nret = idr_alloc(&dev->object_name_idr, obj, 1, 0, GFP_NOWAIT);\r\nif (ret < 0)\r\ngoto err;\r\nobj->name = ret;\r\n}\r\nargs->name = (uint64_t) obj->name;\r\nret = 0;\r\nerr:\r\nidr_preload_end();\r\nmutex_unlock(&dev->object_name_lock);\r\ndrm_gem_object_unreference_unlocked(obj);\r\nreturn ret;\r\n}\r\nint\r\ndrm_gem_open_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_gem_open *args = data;\r\nstruct drm_gem_object *obj;\r\nint ret;\r\nu32 handle;\r\nif (!drm_core_check_feature(dev, DRIVER_GEM))\r\nreturn -ENODEV;\r\nmutex_lock(&dev->object_name_lock);\r\nobj = idr_find(&dev->object_name_idr, (int) args->name);\r\nif (obj) {\r\ndrm_gem_object_reference(obj);\r\n} else {\r\nmutex_unlock(&dev->object_name_lock);\r\nreturn -ENOENT;\r\n}\r\nret = drm_gem_handle_create_tail(file_priv, obj, &handle);\r\ndrm_gem_object_unreference_unlocked(obj);\r\nif (ret)\r\nreturn ret;\r\nargs->handle = handle;\r\nargs->size = obj->size;\r\nreturn 0;\r\n}\r\nvoid\r\ndrm_gem_open(struct drm_device *dev, struct drm_file *file_private)\r\n{\r\nidr_init(&file_private->object_idr);\r\nspin_lock_init(&file_private->table_lock);\r\n}\r\nstatic int\r\ndrm_gem_object_release_handle(int id, void *ptr, void *data)\r\n{\r\nstruct drm_file *file_priv = data;\r\nstruct drm_gem_object *obj = ptr;\r\nstruct drm_device *dev = obj->dev;\r\nif (drm_core_check_feature(dev, DRIVER_PRIME))\r\ndrm_gem_remove_prime_handles(obj, file_priv);\r\ndrm_vma_node_revoke(&obj->vma_node, file_priv->filp);\r\nif (dev->driver->gem_close_object)\r\ndev->driver->gem_close_object(obj, file_priv);\r\ndrm_gem_object_handle_unreference_unlocked(obj);\r\nreturn 0;\r\n}\r\nvoid\r\ndrm_gem_release(struct drm_device *dev, struct drm_file *file_private)\r\n{\r\nidr_for_each(&file_private->object_idr,\r\n&drm_gem_object_release_handle, file_private);\r\nidr_destroy(&file_private->object_idr);\r\n}\r\nvoid\r\ndrm_gem_object_release(struct drm_gem_object *obj)\r\n{\r\nWARN_ON(obj->dma_buf);\r\nif (obj->filp)\r\nfput(obj->filp);\r\ndrm_gem_free_mmap_offset(obj);\r\n}\r\nvoid\r\ndrm_gem_object_free(struct kref *kref)\r\n{\r\nstruct drm_gem_object *obj = (struct drm_gem_object *) kref;\r\nstruct drm_device *dev = obj->dev;\r\nBUG_ON(!mutex_is_locked(&dev->struct_mutex));\r\nif (dev->driver->gem_free_object != NULL)\r\ndev->driver->gem_free_object(obj);\r\n}\r\nvoid drm_gem_vm_open(struct vm_area_struct *vma)\r\n{\r\nstruct drm_gem_object *obj = vma->vm_private_data;\r\ndrm_gem_object_reference(obj);\r\nmutex_lock(&obj->dev->struct_mutex);\r\ndrm_vm_open_locked(obj->dev, vma);\r\nmutex_unlock(&obj->dev->struct_mutex);\r\n}\r\nvoid drm_gem_vm_close(struct vm_area_struct *vma)\r\n{\r\nstruct drm_gem_object *obj = vma->vm_private_data;\r\nstruct drm_device *dev = obj->dev;\r\nmutex_lock(&dev->struct_mutex);\r\ndrm_vm_close_locked(obj->dev, vma);\r\ndrm_gem_object_unreference(obj);\r\nmutex_unlock(&dev->struct_mutex);\r\n}\r\nint drm_gem_mmap_obj(struct drm_gem_object *obj, unsigned long obj_size,\r\nstruct vm_area_struct *vma)\r\n{\r\nstruct drm_device *dev = obj->dev;\r\nlockdep_assert_held(&dev->struct_mutex);\r\nif (obj_size < vma->vm_end - vma->vm_start)\r\nreturn -EINVAL;\r\nif (!dev->driver->gem_vm_ops)\r\nreturn -EINVAL;\r\nvma->vm_flags |= VM_IO | VM_PFNMAP | VM_DONTEXPAND | VM_DONTDUMP;\r\nvma->vm_ops = dev->driver->gem_vm_ops;\r\nvma->vm_private_data = obj;\r\nvma->vm_page_prot = pgprot_writecombine(vm_get_page_prot(vma->vm_flags));\r\ndrm_gem_object_reference(obj);\r\ndrm_vm_open_locked(dev, vma);\r\nreturn 0;\r\n}\r\nint drm_gem_mmap(struct file *filp, struct vm_area_struct *vma)\r\n{\r\nstruct drm_file *priv = filp->private_data;\r\nstruct drm_device *dev = priv->minor->dev;\r\nstruct drm_gem_object *obj;\r\nstruct drm_vma_offset_node *node;\r\nint ret;\r\nif (drm_device_is_unplugged(dev))\r\nreturn -ENODEV;\r\nmutex_lock(&dev->struct_mutex);\r\nnode = drm_vma_offset_exact_lookup(dev->vma_offset_manager,\r\nvma->vm_pgoff,\r\nvma_pages(vma));\r\nif (!node) {\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn -EINVAL;\r\n} else if (!drm_vma_node_is_allowed(node, filp)) {\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn -EACCES;\r\n}\r\nobj = container_of(node, struct drm_gem_object, vma_node);\r\nret = drm_gem_mmap_obj(obj, drm_vma_node_size(node) << PAGE_SHIFT, vma);\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn ret;\r\n}
