static inline int\r\nxlog_buf_bbcount_valid(\r\nstruct xlog *log,\r\nint bbcount)\r\n{\r\nreturn bbcount > 0 && bbcount <= log->l_logBBsize;\r\n}\r\nSTATIC xfs_buf_t *\r\nxlog_get_bp(\r\nstruct xlog *log,\r\nint nbblks)\r\n{\r\nstruct xfs_buf *bp;\r\nif (!xlog_buf_bbcount_valid(log, nbblks)) {\r\nxfs_warn(log->l_mp, "Invalid block length (0x%x) for buffer",\r\nnbblks);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_HIGH, log->l_mp);\r\nreturn NULL;\r\n}\r\nif (nbblks > 1 && log->l_sectBBsize > 1)\r\nnbblks += log->l_sectBBsize;\r\nnbblks = round_up(nbblks, log->l_sectBBsize);\r\nbp = xfs_buf_get_uncached(log->l_mp->m_logdev_targp, nbblks, 0);\r\nif (bp)\r\nxfs_buf_unlock(bp);\r\nreturn bp;\r\n}\r\nSTATIC void\r\nxlog_put_bp(\r\nxfs_buf_t *bp)\r\n{\r\nxfs_buf_free(bp);\r\n}\r\nSTATIC xfs_caddr_t\r\nxlog_align(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp)\r\n{\r\nxfs_daddr_t offset = blk_no & ((xfs_daddr_t)log->l_sectBBsize - 1);\r\nASSERT(offset + nbblks <= bp->b_length);\r\nreturn bp->b_addr + BBTOB(offset);\r\n}\r\nSTATIC int\r\nxlog_bread_noalign(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp)\r\n{\r\nint error;\r\nif (!xlog_buf_bbcount_valid(log, nbblks)) {\r\nxfs_warn(log->l_mp, "Invalid block length (0x%x) for buffer",\r\nnbblks);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_HIGH, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nblk_no = round_down(blk_no, log->l_sectBBsize);\r\nnbblks = round_up(nbblks, log->l_sectBBsize);\r\nASSERT(nbblks > 0);\r\nASSERT(nbblks <= bp->b_length);\r\nXFS_BUF_SET_ADDR(bp, log->l_logBBstart + blk_no);\r\nXFS_BUF_READ(bp);\r\nbp->b_io_length = nbblks;\r\nbp->b_error = 0;\r\nerror = xfs_buf_submit_wait(bp);\r\nif (error && !XFS_FORCED_SHUTDOWN(log->l_mp))\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_bread(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp,\r\nxfs_caddr_t *offset)\r\n{\r\nint error;\r\nerror = xlog_bread_noalign(log, blk_no, nbblks, bp);\r\nif (error)\r\nreturn error;\r\n*offset = xlog_align(log, blk_no, nbblks, bp);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_bread_offset(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp,\r\nxfs_caddr_t offset)\r\n{\r\nxfs_caddr_t orig_offset = bp->b_addr;\r\nint orig_len = BBTOB(bp->b_length);\r\nint error, error2;\r\nerror = xfs_buf_associate_memory(bp, offset, BBTOB(nbblks));\r\nif (error)\r\nreturn error;\r\nerror = xlog_bread_noalign(log, blk_no, nbblks, bp);\r\nerror2 = xfs_buf_associate_memory(bp, orig_offset, orig_len);\r\nif (error)\r\nreturn error;\r\nreturn error2;\r\n}\r\nSTATIC int\r\nxlog_bwrite(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp)\r\n{\r\nint error;\r\nif (!xlog_buf_bbcount_valid(log, nbblks)) {\r\nxfs_warn(log->l_mp, "Invalid block length (0x%x) for buffer",\r\nnbblks);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_HIGH, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nblk_no = round_down(blk_no, log->l_sectBBsize);\r\nnbblks = round_up(nbblks, log->l_sectBBsize);\r\nASSERT(nbblks > 0);\r\nASSERT(nbblks <= bp->b_length);\r\nXFS_BUF_SET_ADDR(bp, log->l_logBBstart + blk_no);\r\nXFS_BUF_ZEROFLAGS(bp);\r\nxfs_buf_hold(bp);\r\nxfs_buf_lock(bp);\r\nbp->b_io_length = nbblks;\r\nbp->b_error = 0;\r\nerror = xfs_bwrite(bp);\r\nif (error)\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nxfs_buf_relse(bp);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_header_check_dump(\r\nxfs_mount_t *mp,\r\nxlog_rec_header_t *head)\r\n{\r\nxfs_debug(mp, "%s: SB : uuid = %pU, fmt = %d",\r\n__func__, &mp->m_sb.sb_uuid, XLOG_FMT);\r\nxfs_debug(mp, " log : uuid = %pU, fmt = %d",\r\n&head->h_fs_uuid, be32_to_cpu(head->h_fmt));\r\n}\r\nSTATIC int\r\nxlog_header_check_recover(\r\nxfs_mount_t *mp,\r\nxlog_rec_header_t *head)\r\n{\r\nASSERT(head->h_magicno == cpu_to_be32(XLOG_HEADER_MAGIC_NUM));\r\nif (unlikely(head->h_fmt != cpu_to_be32(XLOG_FMT))) {\r\nxfs_warn(mp,\r\n"dirty log written in incompatible format - can't recover");\r\nxlog_header_check_dump(mp, head);\r\nXFS_ERROR_REPORT("xlog_header_check_recover(1)",\r\nXFS_ERRLEVEL_HIGH, mp);\r\nreturn -EFSCORRUPTED;\r\n} else if (unlikely(!uuid_equal(&mp->m_sb.sb_uuid, &head->h_fs_uuid))) {\r\nxfs_warn(mp,\r\n"dirty log entry has mismatched uuid - can't recover");\r\nxlog_header_check_dump(mp, head);\r\nXFS_ERROR_REPORT("xlog_header_check_recover(2)",\r\nXFS_ERRLEVEL_HIGH, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_header_check_mount(\r\nxfs_mount_t *mp,\r\nxlog_rec_header_t *head)\r\n{\r\nASSERT(head->h_magicno == cpu_to_be32(XLOG_HEADER_MAGIC_NUM));\r\nif (uuid_is_nil(&head->h_fs_uuid)) {\r\nxfs_warn(mp, "nil uuid in log - IRIX style log");\r\n} else if (unlikely(!uuid_equal(&mp->m_sb.sb_uuid, &head->h_fs_uuid))) {\r\nxfs_warn(mp, "log has mismatched uuid - can't recover");\r\nxlog_header_check_dump(mp, head);\r\nXFS_ERROR_REPORT("xlog_header_check_mount",\r\nXFS_ERRLEVEL_HIGH, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxlog_recover_iodone(\r\nstruct xfs_buf *bp)\r\n{\r\nif (bp->b_error) {\r\nif (!XFS_FORCED_SHUTDOWN(bp->b_target->bt_mount)) {\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nxfs_force_shutdown(bp->b_target->bt_mount,\r\nSHUTDOWN_META_IO_ERROR);\r\n}\r\n}\r\nbp->b_iodone = NULL;\r\nxfs_buf_ioend(bp);\r\n}\r\nSTATIC int\r\nxlog_find_cycle_start(\r\nstruct xlog *log,\r\nstruct xfs_buf *bp,\r\nxfs_daddr_t first_blk,\r\nxfs_daddr_t *last_blk,\r\nuint cycle)\r\n{\r\nxfs_caddr_t offset;\r\nxfs_daddr_t mid_blk;\r\nxfs_daddr_t end_blk;\r\nuint mid_cycle;\r\nint error;\r\nend_blk = *last_blk;\r\nmid_blk = BLK_AVG(first_blk, end_blk);\r\nwhile (mid_blk != first_blk && mid_blk != end_blk) {\r\nerror = xlog_bread(log, mid_blk, 1, bp, &offset);\r\nif (error)\r\nreturn error;\r\nmid_cycle = xlog_get_cycle(offset);\r\nif (mid_cycle == cycle)\r\nend_blk = mid_blk;\r\nelse\r\nfirst_blk = mid_blk;\r\nmid_blk = BLK_AVG(first_blk, end_blk);\r\n}\r\nASSERT((mid_blk == first_blk && mid_blk+1 == end_blk) ||\r\n(mid_blk == end_blk && mid_blk-1 == first_blk));\r\n*last_blk = end_blk;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_find_verify_cycle(\r\nstruct xlog *log,\r\nxfs_daddr_t start_blk,\r\nint nbblks,\r\nuint stop_on_cycle_no,\r\nxfs_daddr_t *new_blk)\r\n{\r\nxfs_daddr_t i, j;\r\nuint cycle;\r\nxfs_buf_t *bp;\r\nxfs_daddr_t bufblks;\r\nxfs_caddr_t buf = NULL;\r\nint error = 0;\r\nbufblks = 1 << ffs(nbblks);\r\nwhile (bufblks > log->l_logBBsize)\r\nbufblks >>= 1;\r\nwhile (!(bp = xlog_get_bp(log, bufblks))) {\r\nbufblks >>= 1;\r\nif (bufblks < log->l_sectBBsize)\r\nreturn -ENOMEM;\r\n}\r\nfor (i = start_blk; i < start_blk + nbblks; i += bufblks) {\r\nint bcount;\r\nbcount = min(bufblks, (start_blk + nbblks - i));\r\nerror = xlog_bread(log, i, bcount, bp, &buf);\r\nif (error)\r\ngoto out;\r\nfor (j = 0; j < bcount; j++) {\r\ncycle = xlog_get_cycle(buf);\r\nif (cycle == stop_on_cycle_no) {\r\n*new_blk = i+j;\r\ngoto out;\r\n}\r\nbuf += BBSIZE;\r\n}\r\n}\r\n*new_blk = -1;\r\nout:\r\nxlog_put_bp(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_find_verify_log_record(\r\nstruct xlog *log,\r\nxfs_daddr_t start_blk,\r\nxfs_daddr_t *last_blk,\r\nint extra_bblks)\r\n{\r\nxfs_daddr_t i;\r\nxfs_buf_t *bp;\r\nxfs_caddr_t offset = NULL;\r\nxlog_rec_header_t *head = NULL;\r\nint error = 0;\r\nint smallmem = 0;\r\nint num_blks = *last_blk - start_blk;\r\nint xhdrs;\r\nASSERT(start_blk != 0 || *last_blk != start_blk);\r\nif (!(bp = xlog_get_bp(log, num_blks))) {\r\nif (!(bp = xlog_get_bp(log, 1)))\r\nreturn -ENOMEM;\r\nsmallmem = 1;\r\n} else {\r\nerror = xlog_bread(log, start_blk, num_blks, bp, &offset);\r\nif (error)\r\ngoto out;\r\noffset += ((num_blks - 1) << BBSHIFT);\r\n}\r\nfor (i = (*last_blk) - 1; i >= 0; i--) {\r\nif (i < start_blk) {\r\nxfs_warn(log->l_mp,\r\n"Log inconsistent (didn't find previous header)");\r\nASSERT(0);\r\nerror = -EIO;\r\ngoto out;\r\n}\r\nif (smallmem) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto out;\r\n}\r\nhead = (xlog_rec_header_t *)offset;\r\nif (head->h_magicno == cpu_to_be32(XLOG_HEADER_MAGIC_NUM))\r\nbreak;\r\nif (!smallmem)\r\noffset -= BBSIZE;\r\n}\r\nif (i == -1) {\r\nerror = 1;\r\ngoto out;\r\n}\r\nif ((error = xlog_header_check_mount(log->l_mp, head)))\r\ngoto out;\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nuint h_size = be32_to_cpu(head->h_size);\r\nxhdrs = h_size / XLOG_HEADER_CYCLE_SIZE;\r\nif (h_size % XLOG_HEADER_CYCLE_SIZE)\r\nxhdrs++;\r\n} else {\r\nxhdrs = 1;\r\n}\r\nif (*last_blk - i + extra_bblks !=\r\nBTOBB(be32_to_cpu(head->h_len)) + xhdrs)\r\n*last_blk = i;\r\nout:\r\nxlog_put_bp(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_find_head(\r\nstruct xlog *log,\r\nxfs_daddr_t *return_head_blk)\r\n{\r\nxfs_buf_t *bp;\r\nxfs_caddr_t offset;\r\nxfs_daddr_t new_blk, first_blk, start_blk, last_blk, head_blk;\r\nint num_scan_bblks;\r\nuint first_half_cycle, last_half_cycle;\r\nuint stop_on_cycle;\r\nint error, log_bbnum = log->l_logBBsize;\r\nerror = xlog_find_zeroed(log, &first_blk);\r\nif (error < 0) {\r\nxfs_warn(log->l_mp, "empty log check failed");\r\nreturn error;\r\n}\r\nif (error == 1) {\r\n*return_head_blk = first_blk;\r\nif (!first_blk) {\r\nxfs_warn(log->l_mp, "totally zeroed log");\r\n}\r\nreturn 0;\r\n}\r\nfirst_blk = 0;\r\nbp = xlog_get_bp(log, 1);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nerror = xlog_bread(log, 0, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nfirst_half_cycle = xlog_get_cycle(offset);\r\nlast_blk = head_blk = log_bbnum - 1;\r\nerror = xlog_bread(log, last_blk, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nlast_half_cycle = xlog_get_cycle(offset);\r\nASSERT(last_half_cycle != 0);\r\nif (first_half_cycle == last_half_cycle) {\r\nhead_blk = log_bbnum;\r\nstop_on_cycle = last_half_cycle - 1;\r\n} else {\r\nstop_on_cycle = last_half_cycle;\r\nif ((error = xlog_find_cycle_start(log, bp, first_blk,\r\n&head_blk, last_half_cycle)))\r\ngoto bp_err;\r\n}\r\nnum_scan_bblks = XLOG_TOTAL_REC_SHIFT(log);\r\nif (head_blk >= num_scan_bblks) {\r\nstart_blk = head_blk - num_scan_bblks;\r\nif ((error = xlog_find_verify_cycle(log,\r\nstart_blk, num_scan_bblks,\r\nstop_on_cycle, &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1)\r\nhead_blk = new_blk;\r\n} else {\r\nASSERT(head_blk <= INT_MAX &&\r\n(xfs_daddr_t) num_scan_bblks >= head_blk);\r\nstart_blk = log_bbnum - (num_scan_bblks - head_blk);\r\nif ((error = xlog_find_verify_cycle(log, start_blk,\r\nnum_scan_bblks - (int)head_blk,\r\n(stop_on_cycle - 1), &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1) {\r\nhead_blk = new_blk;\r\ngoto validate_head;\r\n}\r\nstart_blk = 0;\r\nASSERT(head_blk <= INT_MAX);\r\nif ((error = xlog_find_verify_cycle(log,\r\nstart_blk, (int)head_blk,\r\nstop_on_cycle, &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1)\r\nhead_blk = new_blk;\r\n}\r\nvalidate_head:\r\nnum_scan_bblks = XLOG_REC_SHIFT(log);\r\nif (head_blk >= num_scan_bblks) {\r\nstart_blk = head_blk - num_scan_bblks;\r\nerror = xlog_find_verify_log_record(log, start_blk, &head_blk, 0);\r\nif (error == 1)\r\nerror = -EIO;\r\nif (error)\r\ngoto bp_err;\r\n} else {\r\nstart_blk = 0;\r\nASSERT(head_blk <= INT_MAX);\r\nerror = xlog_find_verify_log_record(log, start_blk, &head_blk, 0);\r\nif (error < 0)\r\ngoto bp_err;\r\nif (error == 1) {\r\nstart_blk = log_bbnum - (num_scan_bblks - head_blk);\r\nnew_blk = log_bbnum;\r\nASSERT(start_blk <= INT_MAX &&\r\n(xfs_daddr_t) log_bbnum-start_blk >= 0);\r\nASSERT(head_blk <= INT_MAX);\r\nerror = xlog_find_verify_log_record(log, start_blk,\r\n&new_blk, (int)head_blk);\r\nif (error == 1)\r\nerror = -EIO;\r\nif (error)\r\ngoto bp_err;\r\nif (new_blk != log_bbnum)\r\nhead_blk = new_blk;\r\n} else if (error)\r\ngoto bp_err;\r\n}\r\nxlog_put_bp(bp);\r\nif (head_blk == log_bbnum)\r\n*return_head_blk = 0;\r\nelse\r\n*return_head_blk = head_blk;\r\nreturn 0;\r\nbp_err:\r\nxlog_put_bp(bp);\r\nif (error)\r\nxfs_warn(log->l_mp, "failed to find log head");\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_find_tail(\r\nstruct xlog *log,\r\nxfs_daddr_t *head_blk,\r\nxfs_daddr_t *tail_blk)\r\n{\r\nxlog_rec_header_t *rhead;\r\nxlog_op_header_t *op_head;\r\nxfs_caddr_t offset = NULL;\r\nxfs_buf_t *bp;\r\nint error, i, found;\r\nxfs_daddr_t umount_data_blk;\r\nxfs_daddr_t after_umount_blk;\r\nxfs_lsn_t tail_lsn;\r\nint hblks;\r\nfound = 0;\r\nif ((error = xlog_find_head(log, head_blk)))\r\nreturn error;\r\nbp = xlog_get_bp(log, 1);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nif (*head_blk == 0) {\r\nerror = xlog_bread(log, 0, 1, bp, &offset);\r\nif (error)\r\ngoto done;\r\nif (xlog_get_cycle(offset) == 0) {\r\n*tail_blk = 0;\r\ngoto done;\r\n}\r\n}\r\nASSERT(*head_blk < INT_MAX);\r\nfor (i = (int)(*head_blk) - 1; i >= 0; i--) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto done;\r\nif (*(__be32 *)offset == cpu_to_be32(XLOG_HEADER_MAGIC_NUM)) {\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nfor (i = log->l_logBBsize - 1; i >= (int)(*head_blk); i--) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto done;\r\nif (*(__be32 *)offset ==\r\ncpu_to_be32(XLOG_HEADER_MAGIC_NUM)) {\r\nfound = 2;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (!found) {\r\nxfs_warn(log->l_mp, "%s: couldn't find sync record", __func__);\r\nxlog_put_bp(bp);\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\nrhead = (xlog_rec_header_t *)offset;\r\n*tail_blk = BLOCK_LSN(be64_to_cpu(rhead->h_tail_lsn));\r\nlog->l_prev_block = i;\r\nlog->l_curr_block = (int)*head_blk;\r\nlog->l_curr_cycle = be32_to_cpu(rhead->h_cycle);\r\nif (found == 2)\r\nlog->l_curr_cycle++;\r\natomic64_set(&log->l_tail_lsn, be64_to_cpu(rhead->h_tail_lsn));\r\natomic64_set(&log->l_last_sync_lsn, be64_to_cpu(rhead->h_lsn));\r\nxlog_assign_grant_head(&log->l_reserve_head.grant, log->l_curr_cycle,\r\nBBTOB(log->l_curr_block));\r\nxlog_assign_grant_head(&log->l_write_head.grant, log->l_curr_cycle,\r\nBBTOB(log->l_curr_block));\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nint h_size = be32_to_cpu(rhead->h_size);\r\nint h_version = be32_to_cpu(rhead->h_version);\r\nif ((h_version & XLOG_VERSION_2) &&\r\n(h_size > XLOG_HEADER_CYCLE_SIZE)) {\r\nhblks = h_size / XLOG_HEADER_CYCLE_SIZE;\r\nif (h_size % XLOG_HEADER_CYCLE_SIZE)\r\nhblks++;\r\n} else {\r\nhblks = 1;\r\n}\r\n} else {\r\nhblks = 1;\r\n}\r\nafter_umount_blk = (i + hblks + (int)\r\nBTOBB(be32_to_cpu(rhead->h_len))) % log->l_logBBsize;\r\ntail_lsn = atomic64_read(&log->l_tail_lsn);\r\nif (*head_blk == after_umount_blk &&\r\nbe32_to_cpu(rhead->h_num_logops) == 1) {\r\numount_data_blk = (i + hblks) % log->l_logBBsize;\r\nerror = xlog_bread(log, umount_data_blk, 1, bp, &offset);\r\nif (error)\r\ngoto done;\r\nop_head = (xlog_op_header_t *)offset;\r\nif (op_head->oh_flags & XLOG_UNMOUNT_TRANS) {\r\nxlog_assign_atomic_lsn(&log->l_tail_lsn,\r\nlog->l_curr_cycle, after_umount_blk);\r\nxlog_assign_atomic_lsn(&log->l_last_sync_lsn,\r\nlog->l_curr_cycle, after_umount_blk);\r\n*tail_blk = after_umount_blk;\r\nlog->l_mp->m_flags |= XFS_MOUNT_WAS_CLEAN;\r\n}\r\n}\r\nif (!xfs_readonly_buftarg(log->l_mp->m_logdev_targp))\r\nerror = xlog_clear_stale_blocks(log, tail_lsn);\r\ndone:\r\nxlog_put_bp(bp);\r\nif (error)\r\nxfs_warn(log->l_mp, "failed to locate log tail");\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_find_zeroed(\r\nstruct xlog *log,\r\nxfs_daddr_t *blk_no)\r\n{\r\nxfs_buf_t *bp;\r\nxfs_caddr_t offset;\r\nuint first_cycle, last_cycle;\r\nxfs_daddr_t new_blk, last_blk, start_blk;\r\nxfs_daddr_t num_scan_bblks;\r\nint error, log_bbnum = log->l_logBBsize;\r\n*blk_no = 0;\r\nbp = xlog_get_bp(log, 1);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nerror = xlog_bread(log, 0, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nfirst_cycle = xlog_get_cycle(offset);\r\nif (first_cycle == 0) {\r\n*blk_no = 0;\r\nxlog_put_bp(bp);\r\nreturn 1;\r\n}\r\nerror = xlog_bread(log, log_bbnum-1, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nlast_cycle = xlog_get_cycle(offset);\r\nif (last_cycle != 0) {\r\nxlog_put_bp(bp);\r\nreturn 0;\r\n} else if (first_cycle != 1) {\r\nxfs_warn(log->l_mp,\r\n"Log inconsistent or not a log (last==0, first!=1)");\r\nerror = -EINVAL;\r\ngoto bp_err;\r\n}\r\nlast_blk = log_bbnum-1;\r\nif ((error = xlog_find_cycle_start(log, bp, 0, &last_blk, 0)))\r\ngoto bp_err;\r\nnum_scan_bblks = XLOG_TOTAL_REC_SHIFT(log);\r\nASSERT(num_scan_bblks <= INT_MAX);\r\nif (last_blk < num_scan_bblks)\r\nnum_scan_bblks = last_blk;\r\nstart_blk = last_blk - num_scan_bblks;\r\nif ((error = xlog_find_verify_cycle(log, start_blk,\r\n(int)num_scan_bblks, 0, &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1)\r\nlast_blk = new_blk;\r\nerror = xlog_find_verify_log_record(log, start_blk, &last_blk, 0);\r\nif (error == 1)\r\nerror = -EIO;\r\nif (error)\r\ngoto bp_err;\r\n*blk_no = last_blk;\r\nbp_err:\r\nxlog_put_bp(bp);\r\nif (error)\r\nreturn error;\r\nreturn 1;\r\n}\r\nSTATIC void\r\nxlog_add_record(\r\nstruct xlog *log,\r\nxfs_caddr_t buf,\r\nint cycle,\r\nint block,\r\nint tail_cycle,\r\nint tail_block)\r\n{\r\nxlog_rec_header_t *recp = (xlog_rec_header_t *)buf;\r\nmemset(buf, 0, BBSIZE);\r\nrecp->h_magicno = cpu_to_be32(XLOG_HEADER_MAGIC_NUM);\r\nrecp->h_cycle = cpu_to_be32(cycle);\r\nrecp->h_version = cpu_to_be32(\r\nxfs_sb_version_haslogv2(&log->l_mp->m_sb) ? 2 : 1);\r\nrecp->h_lsn = cpu_to_be64(xlog_assign_lsn(cycle, block));\r\nrecp->h_tail_lsn = cpu_to_be64(xlog_assign_lsn(tail_cycle, tail_block));\r\nrecp->h_fmt = cpu_to_be32(XLOG_FMT);\r\nmemcpy(&recp->h_fs_uuid, &log->l_mp->m_sb.sb_uuid, sizeof(uuid_t));\r\n}\r\nSTATIC int\r\nxlog_write_log_records(\r\nstruct xlog *log,\r\nint cycle,\r\nint start_block,\r\nint blocks,\r\nint tail_cycle,\r\nint tail_block)\r\n{\r\nxfs_caddr_t offset;\r\nxfs_buf_t *bp;\r\nint balign, ealign;\r\nint sectbb = log->l_sectBBsize;\r\nint end_block = start_block + blocks;\r\nint bufblks;\r\nint error = 0;\r\nint i, j = 0;\r\nbufblks = 1 << ffs(blocks);\r\nwhile (bufblks > log->l_logBBsize)\r\nbufblks >>= 1;\r\nwhile (!(bp = xlog_get_bp(log, bufblks))) {\r\nbufblks >>= 1;\r\nif (bufblks < sectbb)\r\nreturn -ENOMEM;\r\n}\r\nbalign = round_down(start_block, sectbb);\r\nif (balign != start_block) {\r\nerror = xlog_bread_noalign(log, start_block, 1, bp);\r\nif (error)\r\ngoto out_put_bp;\r\nj = start_block - balign;\r\n}\r\nfor (i = start_block; i < end_block; i += bufblks) {\r\nint bcount, endcount;\r\nbcount = min(bufblks, end_block - start_block);\r\nendcount = bcount - j;\r\nealign = round_down(end_block, sectbb);\r\nif (j == 0 && (start_block + endcount > ealign)) {\r\noffset = bp->b_addr + BBTOB(ealign - start_block);\r\nerror = xlog_bread_offset(log, ealign, sectbb,\r\nbp, offset);\r\nif (error)\r\nbreak;\r\n}\r\noffset = xlog_align(log, start_block, endcount, bp);\r\nfor (; j < endcount; j++) {\r\nxlog_add_record(log, offset, cycle, i+j,\r\ntail_cycle, tail_block);\r\noffset += BBSIZE;\r\n}\r\nerror = xlog_bwrite(log, start_block, endcount, bp);\r\nif (error)\r\nbreak;\r\nstart_block += endcount;\r\nj = 0;\r\n}\r\nout_put_bp:\r\nxlog_put_bp(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_clear_stale_blocks(\r\nstruct xlog *log,\r\nxfs_lsn_t tail_lsn)\r\n{\r\nint tail_cycle, head_cycle;\r\nint tail_block, head_block;\r\nint tail_distance, max_distance;\r\nint distance;\r\nint error;\r\ntail_cycle = CYCLE_LSN(tail_lsn);\r\ntail_block = BLOCK_LSN(tail_lsn);\r\nhead_cycle = log->l_curr_cycle;\r\nhead_block = log->l_curr_block;\r\nif (head_cycle == tail_cycle) {\r\nif (unlikely(head_block < tail_block || head_block >= log->l_logBBsize)) {\r\nXFS_ERROR_REPORT("xlog_clear_stale_blocks(1)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\ntail_distance = tail_block + (log->l_logBBsize - head_block);\r\n} else {\r\nif (unlikely(head_block >= tail_block || head_cycle != (tail_cycle + 1))){\r\nXFS_ERROR_REPORT("xlog_clear_stale_blocks(2)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\ntail_distance = tail_block - head_block;\r\n}\r\nif (tail_distance <= 0) {\r\nASSERT(tail_distance == 0);\r\nreturn 0;\r\n}\r\nmax_distance = XLOG_TOTAL_REC_SHIFT(log);\r\nmax_distance = MIN(max_distance, tail_distance);\r\nif ((head_block + max_distance) <= log->l_logBBsize) {\r\nerror = xlog_write_log_records(log, (head_cycle - 1),\r\nhead_block, max_distance, tail_cycle,\r\ntail_block);\r\nif (error)\r\nreturn error;\r\n} else {\r\ndistance = log->l_logBBsize - head_block;\r\nerror = xlog_write_log_records(log, (head_cycle - 1),\r\nhead_block, distance, tail_cycle,\r\ntail_block);\r\nif (error)\r\nreturn error;\r\ndistance = max_distance - (log->l_logBBsize - head_block);\r\nerror = xlog_write_log_records(log, head_cycle, 0, distance,\r\ntail_cycle, tail_block);\r\nif (error)\r\nreturn error;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_reorder_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nint pass)\r\n{\r\nxlog_recover_item_t *item, *n;\r\nint error = 0;\r\nLIST_HEAD(sort_list);\r\nLIST_HEAD(cancel_list);\r\nLIST_HEAD(buffer_list);\r\nLIST_HEAD(inode_buffer_list);\r\nLIST_HEAD(inode_list);\r\nlist_splice_init(&trans->r_itemq, &sort_list);\r\nlist_for_each_entry_safe(item, n, &sort_list, ri_list) {\r\nxfs_buf_log_format_t *buf_f = item->ri_buf[0].i_addr;\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_ICREATE:\r\nlist_move_tail(&item->ri_list, &buffer_list);\r\nbreak;\r\ncase XFS_LI_BUF:\r\nif (buf_f->blf_flags & XFS_BLF_CANCEL) {\r\ntrace_xfs_log_recover_item_reorder_head(log,\r\ntrans, item, pass);\r\nlist_move(&item->ri_list, &cancel_list);\r\nbreak;\r\n}\r\nif (buf_f->blf_flags & XFS_BLF_INODE_BUF) {\r\nlist_move(&item->ri_list, &inode_buffer_list);\r\nbreak;\r\n}\r\nlist_move_tail(&item->ri_list, &buffer_list);\r\nbreak;\r\ncase XFS_LI_INODE:\r\ncase XFS_LI_DQUOT:\r\ncase XFS_LI_QUOTAOFF:\r\ncase XFS_LI_EFD:\r\ncase XFS_LI_EFI:\r\ntrace_xfs_log_recover_item_reorder_tail(log,\r\ntrans, item, pass);\r\nlist_move_tail(&item->ri_list, &inode_list);\r\nbreak;\r\ndefault:\r\nxfs_warn(log->l_mp,\r\n"%s: unrecognized type of log operation",\r\n__func__);\r\nASSERT(0);\r\nif (!list_empty(&sort_list))\r\nlist_splice_init(&sort_list, &trans->r_itemq);\r\nerror = -EIO;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nASSERT(list_empty(&sort_list));\r\nif (!list_empty(&buffer_list))\r\nlist_splice(&buffer_list, &trans->r_itemq);\r\nif (!list_empty(&inode_list))\r\nlist_splice_tail(&inode_list, &trans->r_itemq);\r\nif (!list_empty(&inode_buffer_list))\r\nlist_splice_tail(&inode_buffer_list, &trans->r_itemq);\r\nif (!list_empty(&cancel_list))\r\nlist_splice_tail(&cancel_list, &trans->r_itemq);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_buffer_pass1(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nxfs_buf_log_format_t *buf_f = item->ri_buf[0].i_addr;\r\nstruct list_head *bucket;\r\nstruct xfs_buf_cancel *bcp;\r\nif (!(buf_f->blf_flags & XFS_BLF_CANCEL)) {\r\ntrace_xfs_log_recover_buf_not_cancel(log, buf_f);\r\nreturn 0;\r\n}\r\nbucket = XLOG_BUF_CANCEL_BUCKET(log, buf_f->blf_blkno);\r\nlist_for_each_entry(bcp, bucket, bc_list) {\r\nif (bcp->bc_blkno == buf_f->blf_blkno &&\r\nbcp->bc_len == buf_f->blf_len) {\r\nbcp->bc_refcount++;\r\ntrace_xfs_log_recover_buf_cancel_ref_inc(log, buf_f);\r\nreturn 0;\r\n}\r\n}\r\nbcp = kmem_alloc(sizeof(struct xfs_buf_cancel), KM_SLEEP);\r\nbcp->bc_blkno = buf_f->blf_blkno;\r\nbcp->bc_len = buf_f->blf_len;\r\nbcp->bc_refcount = 1;\r\nlist_add_tail(&bcp->bc_list, bucket);\r\ntrace_xfs_log_recover_buf_cancel_add(log, buf_f);\r\nreturn 0;\r\n}\r\nSTATIC struct xfs_buf_cancel *\r\nxlog_peek_buffer_cancelled(\r\nstruct xlog *log,\r\nxfs_daddr_t blkno,\r\nuint len,\r\nushort flags)\r\n{\r\nstruct list_head *bucket;\r\nstruct xfs_buf_cancel *bcp;\r\nif (!log->l_buf_cancel_table) {\r\nASSERT(!(flags & XFS_BLF_CANCEL));\r\nreturn NULL;\r\n}\r\nbucket = XLOG_BUF_CANCEL_BUCKET(log, blkno);\r\nlist_for_each_entry(bcp, bucket, bc_list) {\r\nif (bcp->bc_blkno == blkno && bcp->bc_len == len)\r\nreturn bcp;\r\n}\r\nASSERT(!(flags & XFS_BLF_CANCEL));\r\nreturn NULL;\r\n}\r\nSTATIC int\r\nxlog_check_buffer_cancelled(\r\nstruct xlog *log,\r\nxfs_daddr_t blkno,\r\nuint len,\r\nushort flags)\r\n{\r\nstruct xfs_buf_cancel *bcp;\r\nbcp = xlog_peek_buffer_cancelled(log, blkno, len, flags);\r\nif (!bcp)\r\nreturn 0;\r\nif (flags & XFS_BLF_CANCEL) {\r\nif (--bcp->bc_refcount == 0) {\r\nlist_del(&bcp->bc_list);\r\nkmem_free(bcp);\r\n}\r\n}\r\nreturn 1;\r\n}\r\nSTATIC int\r\nxlog_recover_do_inode_buffer(\r\nstruct xfs_mount *mp,\r\nxlog_recover_item_t *item,\r\nstruct xfs_buf *bp,\r\nxfs_buf_log_format_t *buf_f)\r\n{\r\nint i;\r\nint item_index = 0;\r\nint bit = 0;\r\nint nbits = 0;\r\nint reg_buf_offset = 0;\r\nint reg_buf_bytes = 0;\r\nint next_unlinked_offset;\r\nint inodes_per_buf;\r\nxfs_agino_t *logged_nextp;\r\nxfs_agino_t *buffer_nextp;\r\ntrace_xfs_log_recover_buf_inode_buf(mp->m_log, buf_f);\r\nif (xfs_sb_version_hascrc(&mp->m_sb))\r\nbp->b_ops = &xfs_inode_buf_ops;\r\ninodes_per_buf = BBTOB(bp->b_io_length) >> mp->m_sb.sb_inodelog;\r\nfor (i = 0; i < inodes_per_buf; i++) {\r\nnext_unlinked_offset = (i * mp->m_sb.sb_inodesize) +\r\noffsetof(xfs_dinode_t, di_next_unlinked);\r\nwhile (next_unlinked_offset >=\r\n(reg_buf_offset + reg_buf_bytes)) {\r\nbit += nbits;\r\nbit = xfs_next_bit(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nif (bit == -1)\r\nreturn 0;\r\nnbits = xfs_contig_bits(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nASSERT(nbits > 0);\r\nreg_buf_offset = bit << XFS_BLF_SHIFT;\r\nreg_buf_bytes = nbits << XFS_BLF_SHIFT;\r\nitem_index++;\r\n}\r\nif (next_unlinked_offset < reg_buf_offset)\r\ncontinue;\r\nASSERT(item->ri_buf[item_index].i_addr != NULL);\r\nASSERT((item->ri_buf[item_index].i_len % XFS_BLF_CHUNK) == 0);\r\nASSERT((reg_buf_offset + reg_buf_bytes) <=\r\nBBTOB(bp->b_io_length));\r\nlogged_nextp = item->ri_buf[item_index].i_addr +\r\nnext_unlinked_offset - reg_buf_offset;\r\nif (unlikely(*logged_nextp == 0)) {\r\nxfs_alert(mp,\r\n"Bad inode buffer log record (ptr = 0x%p, bp = 0x%p). "\r\n"Trying to replay bad (0) inode di_next_unlinked field.",\r\nitem, bp);\r\nXFS_ERROR_REPORT("xlog_recover_do_inode_buf",\r\nXFS_ERRLEVEL_LOW, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nbuffer_nextp = (xfs_agino_t *)xfs_buf_offset(bp,\r\nnext_unlinked_offset);\r\n*buffer_nextp = *logged_nextp;\r\nxfs_dinode_calc_crc(mp, (struct xfs_dinode *)\r\nxfs_buf_offset(bp, i * mp->m_sb.sb_inodesize));\r\n}\r\nreturn 0;\r\n}\r\nstatic xfs_lsn_t\r\nxlog_recover_get_buf_lsn(\r\nstruct xfs_mount *mp,\r\nstruct xfs_buf *bp)\r\n{\r\n__uint32_t magic32;\r\n__uint16_t magic16;\r\n__uint16_t magicda;\r\nvoid *blk = bp->b_addr;\r\nuuid_t *uuid;\r\nxfs_lsn_t lsn = -1;\r\nif (!xfs_sb_version_hascrc(&mp->m_sb))\r\ngoto recover_immediately;\r\nmagic32 = be32_to_cpu(*(__be32 *)blk);\r\nswitch (magic32) {\r\ncase XFS_ABTB_CRC_MAGIC:\r\ncase XFS_ABTC_CRC_MAGIC:\r\ncase XFS_ABTB_MAGIC:\r\ncase XFS_ABTC_MAGIC:\r\ncase XFS_IBT_CRC_MAGIC:\r\ncase XFS_IBT_MAGIC: {\r\nstruct xfs_btree_block *btb = blk;\r\nlsn = be64_to_cpu(btb->bb_u.s.bb_lsn);\r\nuuid = &btb->bb_u.s.bb_uuid;\r\nbreak;\r\n}\r\ncase XFS_BMAP_CRC_MAGIC:\r\ncase XFS_BMAP_MAGIC: {\r\nstruct xfs_btree_block *btb = blk;\r\nlsn = be64_to_cpu(btb->bb_u.l.bb_lsn);\r\nuuid = &btb->bb_u.l.bb_uuid;\r\nbreak;\r\n}\r\ncase XFS_AGF_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_agf *)blk)->agf_lsn);\r\nuuid = &((struct xfs_agf *)blk)->agf_uuid;\r\nbreak;\r\ncase XFS_AGFL_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_agfl *)blk)->agfl_lsn);\r\nuuid = &((struct xfs_agfl *)blk)->agfl_uuid;\r\nbreak;\r\ncase XFS_AGI_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_agi *)blk)->agi_lsn);\r\nuuid = &((struct xfs_agi *)blk)->agi_uuid;\r\nbreak;\r\ncase XFS_SYMLINK_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_dsymlink_hdr *)blk)->sl_lsn);\r\nuuid = &((struct xfs_dsymlink_hdr *)blk)->sl_uuid;\r\nbreak;\r\ncase XFS_DIR3_BLOCK_MAGIC:\r\ncase XFS_DIR3_DATA_MAGIC:\r\ncase XFS_DIR3_FREE_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_dir3_blk_hdr *)blk)->lsn);\r\nuuid = &((struct xfs_dir3_blk_hdr *)blk)->uuid;\r\nbreak;\r\ncase XFS_ATTR3_RMT_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_attr3_rmt_hdr *)blk)->rm_lsn);\r\nuuid = &((struct xfs_attr3_rmt_hdr *)blk)->rm_uuid;\r\nbreak;\r\ncase XFS_SB_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_dsb *)blk)->sb_lsn);\r\nuuid = &((struct xfs_dsb *)blk)->sb_uuid;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (lsn != (xfs_lsn_t)-1) {\r\nif (!uuid_equal(&mp->m_sb.sb_uuid, uuid))\r\ngoto recover_immediately;\r\nreturn lsn;\r\n}\r\nmagicda = be16_to_cpu(((struct xfs_da_blkinfo *)blk)->magic);\r\nswitch (magicda) {\r\ncase XFS_DIR3_LEAF1_MAGIC:\r\ncase XFS_DIR3_LEAFN_MAGIC:\r\ncase XFS_DA3_NODE_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_da3_blkinfo *)blk)->lsn);\r\nuuid = &((struct xfs_da3_blkinfo *)blk)->uuid;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (lsn != (xfs_lsn_t)-1) {\r\nif (!uuid_equal(&mp->m_sb.sb_uuid, uuid))\r\ngoto recover_immediately;\r\nreturn lsn;\r\n}\r\nmagic16 = be16_to_cpu(*(__be16 *)blk);\r\nswitch (magic16) {\r\ncase XFS_DQUOT_MAGIC:\r\ncase XFS_DINODE_MAGIC:\r\ngoto recover_immediately;\r\ndefault:\r\nbreak;\r\n}\r\nrecover_immediately:\r\nreturn (xfs_lsn_t)-1;\r\n}\r\nstatic void\r\nxlog_recover_validate_buf_type(\r\nstruct xfs_mount *mp,\r\nstruct xfs_buf *bp,\r\nxfs_buf_log_format_t *buf_f)\r\n{\r\nstruct xfs_da_blkinfo *info = bp->b_addr;\r\n__uint32_t magic32;\r\n__uint16_t magic16;\r\n__uint16_t magicda;\r\nif (!xfs_sb_version_hascrc(&mp->m_sb))\r\nreturn;\r\nmagic32 = be32_to_cpu(*(__be32 *)bp->b_addr);\r\nmagic16 = be16_to_cpu(*(__be16*)bp->b_addr);\r\nmagicda = be16_to_cpu(info->magic);\r\nswitch (xfs_blft_from_flags(buf_f)) {\r\ncase XFS_BLFT_BTREE_BUF:\r\nswitch (magic32) {\r\ncase XFS_ABTB_CRC_MAGIC:\r\ncase XFS_ABTC_CRC_MAGIC:\r\ncase XFS_ABTB_MAGIC:\r\ncase XFS_ABTC_MAGIC:\r\nbp->b_ops = &xfs_allocbt_buf_ops;\r\nbreak;\r\ncase XFS_IBT_CRC_MAGIC:\r\ncase XFS_FIBT_CRC_MAGIC:\r\ncase XFS_IBT_MAGIC:\r\ncase XFS_FIBT_MAGIC:\r\nbp->b_ops = &xfs_inobt_buf_ops;\r\nbreak;\r\ncase XFS_BMAP_CRC_MAGIC:\r\ncase XFS_BMAP_MAGIC:\r\nbp->b_ops = &xfs_bmbt_buf_ops;\r\nbreak;\r\ndefault:\r\nxfs_warn(mp, "Bad btree block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbreak;\r\ncase XFS_BLFT_AGF_BUF:\r\nif (magic32 != XFS_AGF_MAGIC) {\r\nxfs_warn(mp, "Bad AGF block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_agf_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_AGFL_BUF:\r\nif (magic32 != XFS_AGFL_MAGIC) {\r\nxfs_warn(mp, "Bad AGFL block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_agfl_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_AGI_BUF:\r\nif (magic32 != XFS_AGI_MAGIC) {\r\nxfs_warn(mp, "Bad AGI block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_agi_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_UDQUOT_BUF:\r\ncase XFS_BLFT_PDQUOT_BUF:\r\ncase XFS_BLFT_GDQUOT_BUF:\r\n#ifdef CONFIG_XFS_QUOTA\r\nif (magic16 != XFS_DQUOT_MAGIC) {\r\nxfs_warn(mp, "Bad DQUOT block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dquot_buf_ops;\r\n#else\r\nxfs_alert(mp,\r\n"Trying to recover dquots without QUOTA support built in!");\r\nASSERT(0);\r\n#endif\r\nbreak;\r\ncase XFS_BLFT_DINO_BUF:\r\nif (magic16 != XFS_DINODE_MAGIC) {\r\nxfs_warn(mp, "Bad INODE block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_inode_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_SYMLINK_BUF:\r\nif (magic32 != XFS_SYMLINK_MAGIC) {\r\nxfs_warn(mp, "Bad symlink block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_symlink_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_BLOCK_BUF:\r\nif (magic32 != XFS_DIR2_BLOCK_MAGIC &&\r\nmagic32 != XFS_DIR3_BLOCK_MAGIC) {\r\nxfs_warn(mp, "Bad dir block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_block_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_DATA_BUF:\r\nif (magic32 != XFS_DIR2_DATA_MAGIC &&\r\nmagic32 != XFS_DIR3_DATA_MAGIC) {\r\nxfs_warn(mp, "Bad dir data magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_data_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_FREE_BUF:\r\nif (magic32 != XFS_DIR2_FREE_MAGIC &&\r\nmagic32 != XFS_DIR3_FREE_MAGIC) {\r\nxfs_warn(mp, "Bad dir3 free magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_free_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_LEAF1_BUF:\r\nif (magicda != XFS_DIR2_LEAF1_MAGIC &&\r\nmagicda != XFS_DIR3_LEAF1_MAGIC) {\r\nxfs_warn(mp, "Bad dir leaf1 magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_leaf1_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_LEAFN_BUF:\r\nif (magicda != XFS_DIR2_LEAFN_MAGIC &&\r\nmagicda != XFS_DIR3_LEAFN_MAGIC) {\r\nxfs_warn(mp, "Bad dir leafn magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_leafn_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DA_NODE_BUF:\r\nif (magicda != XFS_DA_NODE_MAGIC &&\r\nmagicda != XFS_DA3_NODE_MAGIC) {\r\nxfs_warn(mp, "Bad da node magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_da3_node_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_ATTR_LEAF_BUF:\r\nif (magicda != XFS_ATTR_LEAF_MAGIC &&\r\nmagicda != XFS_ATTR3_LEAF_MAGIC) {\r\nxfs_warn(mp, "Bad attr leaf magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_attr3_leaf_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_ATTR_RMT_BUF:\r\nif (magic32 != XFS_ATTR3_RMT_MAGIC) {\r\nxfs_warn(mp, "Bad attr remote magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_attr3_rmt_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_SB_BUF:\r\nif (magic32 != XFS_SB_MAGIC) {\r\nxfs_warn(mp, "Bad SB block magic!");\r\nASSERT(0);\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_sb_buf_ops;\r\nbreak;\r\ndefault:\r\nxfs_warn(mp, "Unknown buffer type %d!",\r\nxfs_blft_from_flags(buf_f));\r\nbreak;\r\n}\r\n}\r\nSTATIC void\r\nxlog_recover_do_reg_buffer(\r\nstruct xfs_mount *mp,\r\nxlog_recover_item_t *item,\r\nstruct xfs_buf *bp,\r\nxfs_buf_log_format_t *buf_f)\r\n{\r\nint i;\r\nint bit;\r\nint nbits;\r\nint error;\r\ntrace_xfs_log_recover_buf_reg_buf(mp->m_log, buf_f);\r\nbit = 0;\r\ni = 1;\r\nwhile (1) {\r\nbit = xfs_next_bit(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nif (bit == -1)\r\nbreak;\r\nnbits = xfs_contig_bits(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nASSERT(nbits > 0);\r\nASSERT(item->ri_buf[i].i_addr != NULL);\r\nASSERT(item->ri_buf[i].i_len % XFS_BLF_CHUNK == 0);\r\nASSERT(BBTOB(bp->b_io_length) >=\r\n((uint)bit << XFS_BLF_SHIFT) + (nbits << XFS_BLF_SHIFT));\r\nif (item->ri_buf[i].i_len < (nbits << XFS_BLF_SHIFT))\r\nnbits = item->ri_buf[i].i_len >> XFS_BLF_SHIFT;\r\nerror = 0;\r\nif (buf_f->blf_flags &\r\n(XFS_BLF_UDQUOT_BUF|XFS_BLF_PDQUOT_BUF|XFS_BLF_GDQUOT_BUF)) {\r\nif (item->ri_buf[i].i_addr == NULL) {\r\nxfs_alert(mp,\r\n"XFS: NULL dquot in %s.", __func__);\r\ngoto next;\r\n}\r\nif (item->ri_buf[i].i_len < sizeof(xfs_disk_dquot_t)) {\r\nxfs_alert(mp,\r\n"XFS: dquot too small (%d) in %s.",\r\nitem->ri_buf[i].i_len, __func__);\r\ngoto next;\r\n}\r\nerror = xfs_dqcheck(mp, item->ri_buf[i].i_addr,\r\n-1, 0, XFS_QMOPT_DOWARN,\r\n"dquot_buf_recover");\r\nif (error)\r\ngoto next;\r\n}\r\nmemcpy(xfs_buf_offset(bp,\r\n(uint)bit << XFS_BLF_SHIFT),\r\nitem->ri_buf[i].i_addr,\r\nnbits<<XFS_BLF_SHIFT);\r\nnext:\r\ni++;\r\nbit += nbits;\r\n}\r\nASSERT(i == item->ri_total);\r\nxlog_recover_validate_buf_type(mp, bp, buf_f);\r\n}\r\nSTATIC bool\r\nxlog_recover_do_dquot_buffer(\r\nstruct xfs_mount *mp,\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item,\r\nstruct xfs_buf *bp,\r\nstruct xfs_buf_log_format *buf_f)\r\n{\r\nuint type;\r\ntrace_xfs_log_recover_buf_dquot_buf(log, buf_f);\r\nif (!mp->m_qflags)\r\nreturn false;\r\ntype = 0;\r\nif (buf_f->blf_flags & XFS_BLF_UDQUOT_BUF)\r\ntype |= XFS_DQ_USER;\r\nif (buf_f->blf_flags & XFS_BLF_PDQUOT_BUF)\r\ntype |= XFS_DQ_PROJ;\r\nif (buf_f->blf_flags & XFS_BLF_GDQUOT_BUF)\r\ntype |= XFS_DQ_GROUP;\r\nif (log->l_quotaoffs_flag & type)\r\nreturn false;\r\nxlog_recover_do_reg_buffer(mp, item, bp, buf_f);\r\nreturn true;\r\n}\r\nSTATIC int\r\nxlog_recover_buffer_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t current_lsn)\r\n{\r\nxfs_buf_log_format_t *buf_f = item->ri_buf[0].i_addr;\r\nxfs_mount_t *mp = log->l_mp;\r\nxfs_buf_t *bp;\r\nint error;\r\nuint buf_flags;\r\nxfs_lsn_t lsn;\r\nif (xlog_check_buffer_cancelled(log, buf_f->blf_blkno,\r\nbuf_f->blf_len, buf_f->blf_flags)) {\r\ntrace_xfs_log_recover_buf_cancel(log, buf_f);\r\nreturn 0;\r\n}\r\ntrace_xfs_log_recover_buf_recover(log, buf_f);\r\nbuf_flags = 0;\r\nif (buf_f->blf_flags & XFS_BLF_INODE_BUF)\r\nbuf_flags |= XBF_UNMAPPED;\r\nbp = xfs_buf_read(mp->m_ddev_targp, buf_f->blf_blkno, buf_f->blf_len,\r\nbuf_flags, NULL);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nerror = bp->b_error;\r\nif (error) {\r\nxfs_buf_ioerror_alert(bp, "xlog_recover_do..(read#1)");\r\ngoto out_release;\r\n}\r\nlsn = xlog_recover_get_buf_lsn(mp, bp);\r\nif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\r\nxlog_recover_validate_buf_type(mp, bp, buf_f);\r\ngoto out_release;\r\n}\r\nif (buf_f->blf_flags & XFS_BLF_INODE_BUF) {\r\nerror = xlog_recover_do_inode_buffer(mp, item, bp, buf_f);\r\nif (error)\r\ngoto out_release;\r\n} else if (buf_f->blf_flags &\r\n(XFS_BLF_UDQUOT_BUF|XFS_BLF_PDQUOT_BUF|XFS_BLF_GDQUOT_BUF)) {\r\nbool dirty;\r\ndirty = xlog_recover_do_dquot_buffer(mp, log, item, bp, buf_f);\r\nif (!dirty)\r\ngoto out_release;\r\n} else {\r\nxlog_recover_do_reg_buffer(mp, item, bp, buf_f);\r\n}\r\nif (XFS_DINODE_MAGIC ==\r\nbe16_to_cpu(*((__be16 *)xfs_buf_offset(bp, 0))) &&\r\n(BBTOB(bp->b_io_length) != MAX(log->l_mp->m_sb.sb_blocksize,\r\n(__uint32_t)log->l_mp->m_inode_cluster_size))) {\r\nxfs_buf_stale(bp);\r\nerror = xfs_bwrite(bp);\r\n} else {\r\nASSERT(bp->b_target->bt_mount == mp);\r\nbp->b_iodone = xlog_recover_iodone;\r\nxfs_buf_delwri_queue(bp, buffer_list);\r\n}\r\nout_release:\r\nxfs_buf_relse(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_recover_inode_owner_change(\r\nstruct xfs_mount *mp,\r\nstruct xfs_dinode *dip,\r\nstruct xfs_inode_log_format *in_f,\r\nstruct list_head *buffer_list)\r\n{\r\nstruct xfs_inode *ip;\r\nint error;\r\nASSERT(in_f->ilf_fields & (XFS_ILOG_DOWNER|XFS_ILOG_AOWNER));\r\nip = xfs_inode_alloc(mp, in_f->ilf_ino);\r\nif (!ip)\r\nreturn -ENOMEM;\r\nxfs_dinode_from_disk(&ip->i_d, dip);\r\nASSERT(ip->i_d.di_version >= 3);\r\nerror = xfs_iformat_fork(ip, dip);\r\nif (error)\r\ngoto out_free_ip;\r\nif (in_f->ilf_fields & XFS_ILOG_DOWNER) {\r\nASSERT(in_f->ilf_fields & XFS_ILOG_DBROOT);\r\nerror = xfs_bmbt_change_owner(NULL, ip, XFS_DATA_FORK,\r\nip->i_ino, buffer_list);\r\nif (error)\r\ngoto out_free_ip;\r\n}\r\nif (in_f->ilf_fields & XFS_ILOG_AOWNER) {\r\nASSERT(in_f->ilf_fields & XFS_ILOG_ABROOT);\r\nerror = xfs_bmbt_change_owner(NULL, ip, XFS_ATTR_FORK,\r\nip->i_ino, buffer_list);\r\nif (error)\r\ngoto out_free_ip;\r\n}\r\nout_free_ip:\r\nxfs_inode_free(ip);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_inode_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t current_lsn)\r\n{\r\nxfs_inode_log_format_t *in_f;\r\nxfs_mount_t *mp = log->l_mp;\r\nxfs_buf_t *bp;\r\nxfs_dinode_t *dip;\r\nint len;\r\nxfs_caddr_t src;\r\nxfs_caddr_t dest;\r\nint error;\r\nint attr_index;\r\nuint fields;\r\nxfs_icdinode_t *dicp;\r\nuint isize;\r\nint need_free = 0;\r\nif (item->ri_buf[0].i_len == sizeof(xfs_inode_log_format_t)) {\r\nin_f = item->ri_buf[0].i_addr;\r\n} else {\r\nin_f = kmem_alloc(sizeof(xfs_inode_log_format_t), KM_SLEEP);\r\nneed_free = 1;\r\nerror = xfs_inode_item_format_convert(&item->ri_buf[0], in_f);\r\nif (error)\r\ngoto error;\r\n}\r\nif (xlog_check_buffer_cancelled(log, in_f->ilf_blkno,\r\nin_f->ilf_len, 0)) {\r\nerror = 0;\r\ntrace_xfs_log_recover_inode_cancel(log, in_f);\r\ngoto error;\r\n}\r\ntrace_xfs_log_recover_inode_recover(log, in_f);\r\nbp = xfs_buf_read(mp->m_ddev_targp, in_f->ilf_blkno, in_f->ilf_len, 0,\r\n&xfs_inode_buf_ops);\r\nif (!bp) {\r\nerror = -ENOMEM;\r\ngoto error;\r\n}\r\nerror = bp->b_error;\r\nif (error) {\r\nxfs_buf_ioerror_alert(bp, "xlog_recover_do..(read#2)");\r\ngoto out_release;\r\n}\r\nASSERT(in_f->ilf_fields & XFS_ILOG_CORE);\r\ndip = (xfs_dinode_t *)xfs_buf_offset(bp, in_f->ilf_boffset);\r\nif (unlikely(dip->di_magic != cpu_to_be16(XFS_DINODE_MAGIC))) {\r\nxfs_alert(mp,\r\n"%s: Bad inode magic number, dip = 0x%p, dino bp = 0x%p, ino = %Ld",\r\n__func__, dip, bp, in_f->ilf_ino);\r\nXFS_ERROR_REPORT("xlog_recover_inode_pass2(1)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\ndicp = item->ri_buf[1].i_addr;\r\nif (unlikely(dicp->di_magic != XFS_DINODE_MAGIC)) {\r\nxfs_alert(mp,\r\n"%s: Bad inode log record, rec ptr 0x%p, ino %Ld",\r\n__func__, item, in_f->ilf_ino);\r\nXFS_ERROR_REPORT("xlog_recover_inode_pass2(2)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nif (dip->di_version >= 3) {\r\nxfs_lsn_t lsn = be64_to_cpu(dip->di_lsn);\r\nif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\r\ntrace_xfs_log_recover_inode_skip(log, in_f);\r\nerror = 0;\r\ngoto out_owner_change;\r\n}\r\n}\r\nif (!xfs_sb_version_hascrc(&mp->m_sb) &&\r\ndicp->di_flushiter < be16_to_cpu(dip->di_flushiter)) {\r\nif (be16_to_cpu(dip->di_flushiter) == DI_MAX_FLUSH &&\r\ndicp->di_flushiter < (DI_MAX_FLUSH >> 1)) {\r\n} else {\r\ntrace_xfs_log_recover_inode_skip(log, in_f);\r\nerror = 0;\r\ngoto out_release;\r\n}\r\n}\r\ndicp->di_flushiter = 0;\r\nif (unlikely(S_ISREG(dicp->di_mode))) {\r\nif ((dicp->di_format != XFS_DINODE_FMT_EXTENTS) &&\r\n(dicp->di_format != XFS_DINODE_FMT_BTREE)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(3)",\r\nXFS_ERRLEVEL_LOW, mp, dicp);\r\nxfs_alert(mp,\r\n"%s: Bad regular inode log record, rec ptr 0x%p, "\r\n"ino ptr = 0x%p, ino bp = 0x%p, ino %Ld",\r\n__func__, item, dip, bp, in_f->ilf_ino);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\n} else if (unlikely(S_ISDIR(dicp->di_mode))) {\r\nif ((dicp->di_format != XFS_DINODE_FMT_EXTENTS) &&\r\n(dicp->di_format != XFS_DINODE_FMT_BTREE) &&\r\n(dicp->di_format != XFS_DINODE_FMT_LOCAL)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(4)",\r\nXFS_ERRLEVEL_LOW, mp, dicp);\r\nxfs_alert(mp,\r\n"%s: Bad dir inode log record, rec ptr 0x%p, "\r\n"ino ptr = 0x%p, ino bp = 0x%p, ino %Ld",\r\n__func__, item, dip, bp, in_f->ilf_ino);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\n}\r\nif (unlikely(dicp->di_nextents + dicp->di_anextents > dicp->di_nblocks)){\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(5)",\r\nXFS_ERRLEVEL_LOW, mp, dicp);\r\nxfs_alert(mp,\r\n"%s: Bad inode log record, rec ptr 0x%p, dino ptr 0x%p, "\r\n"dino bp 0x%p, ino %Ld, total extents = %d, nblocks = %Ld",\r\n__func__, item, dip, bp, in_f->ilf_ino,\r\ndicp->di_nextents + dicp->di_anextents,\r\ndicp->di_nblocks);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nif (unlikely(dicp->di_forkoff > mp->m_sb.sb_inodesize)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(6)",\r\nXFS_ERRLEVEL_LOW, mp, dicp);\r\nxfs_alert(mp,\r\n"%s: Bad inode log record, rec ptr 0x%p, dino ptr 0x%p, "\r\n"dino bp 0x%p, ino %Ld, forkoff 0x%x", __func__,\r\nitem, dip, bp, in_f->ilf_ino, dicp->di_forkoff);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nisize = xfs_icdinode_size(dicp->di_version);\r\nif (unlikely(item->ri_buf[1].i_len > isize)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(7)",\r\nXFS_ERRLEVEL_LOW, mp, dicp);\r\nxfs_alert(mp,\r\n"%s: Bad inode log record length %d, rec ptr 0x%p",\r\n__func__, item->ri_buf[1].i_len, item);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nxfs_dinode_to_disk(dip, dicp);\r\nif (item->ri_buf[1].i_len > isize) {\r\nmemcpy((char *)dip + isize,\r\nitem->ri_buf[1].i_addr + isize,\r\nitem->ri_buf[1].i_len - isize);\r\n}\r\nfields = in_f->ilf_fields;\r\nswitch (fields & (XFS_ILOG_DEV | XFS_ILOG_UUID)) {\r\ncase XFS_ILOG_DEV:\r\nxfs_dinode_put_rdev(dip, in_f->ilf_u.ilfu_rdev);\r\nbreak;\r\ncase XFS_ILOG_UUID:\r\nmemcpy(XFS_DFORK_DPTR(dip),\r\n&in_f->ilf_u.ilfu_uuid,\r\nsizeof(uuid_t));\r\nbreak;\r\n}\r\nif (in_f->ilf_size == 2)\r\ngoto out_owner_change;\r\nlen = item->ri_buf[2].i_len;\r\nsrc = item->ri_buf[2].i_addr;\r\nASSERT(in_f->ilf_size <= 4);\r\nASSERT((in_f->ilf_size == 3) || (fields & XFS_ILOG_AFORK));\r\nASSERT(!(fields & XFS_ILOG_DFORK) ||\r\n(len == in_f->ilf_dsize));\r\nswitch (fields & XFS_ILOG_DFORK) {\r\ncase XFS_ILOG_DDATA:\r\ncase XFS_ILOG_DEXT:\r\nmemcpy(XFS_DFORK_DPTR(dip), src, len);\r\nbreak;\r\ncase XFS_ILOG_DBROOT:\r\nxfs_bmbt_to_bmdr(mp, (struct xfs_btree_block *)src, len,\r\n(xfs_bmdr_block_t *)XFS_DFORK_DPTR(dip),\r\nXFS_DFORK_DSIZE(dip, mp));\r\nbreak;\r\ndefault:\r\nASSERT((fields & XFS_ILOG_DFORK) == 0);\r\nbreak;\r\n}\r\nif (in_f->ilf_fields & XFS_ILOG_AFORK) {\r\nif (in_f->ilf_fields & XFS_ILOG_DFORK) {\r\nattr_index = 3;\r\n} else {\r\nattr_index = 2;\r\n}\r\nlen = item->ri_buf[attr_index].i_len;\r\nsrc = item->ri_buf[attr_index].i_addr;\r\nASSERT(len == in_f->ilf_asize);\r\nswitch (in_f->ilf_fields & XFS_ILOG_AFORK) {\r\ncase XFS_ILOG_ADATA:\r\ncase XFS_ILOG_AEXT:\r\ndest = XFS_DFORK_APTR(dip);\r\nASSERT(len <= XFS_DFORK_ASIZE(dip, mp));\r\nmemcpy(dest, src, len);\r\nbreak;\r\ncase XFS_ILOG_ABROOT:\r\ndest = XFS_DFORK_APTR(dip);\r\nxfs_bmbt_to_bmdr(mp, (struct xfs_btree_block *)src,\r\nlen, (xfs_bmdr_block_t*)dest,\r\nXFS_DFORK_ASIZE(dip, mp));\r\nbreak;\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: Invalid flag", __func__);\r\nASSERT(0);\r\nerror = -EIO;\r\ngoto out_release;\r\n}\r\n}\r\nout_owner_change:\r\nif (in_f->ilf_fields & (XFS_ILOG_DOWNER|XFS_ILOG_AOWNER))\r\nerror = xfs_recover_inode_owner_change(mp, dip, in_f,\r\nbuffer_list);\r\nxfs_dinode_calc_crc(log->l_mp, dip);\r\nASSERT(bp->b_target->bt_mount == mp);\r\nbp->b_iodone = xlog_recover_iodone;\r\nxfs_buf_delwri_queue(bp, buffer_list);\r\nout_release:\r\nxfs_buf_relse(bp);\r\nerror:\r\nif (need_free)\r\nkmem_free(in_f);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_quotaoff_pass1(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nxfs_qoff_logformat_t *qoff_f = item->ri_buf[0].i_addr;\r\nASSERT(qoff_f);\r\nif (qoff_f->qf_flags & XFS_UQUOTA_ACCT)\r\nlog->l_quotaoffs_flag |= XFS_DQ_USER;\r\nif (qoff_f->qf_flags & XFS_PQUOTA_ACCT)\r\nlog->l_quotaoffs_flag |= XFS_DQ_PROJ;\r\nif (qoff_f->qf_flags & XFS_GQUOTA_ACCT)\r\nlog->l_quotaoffs_flag |= XFS_DQ_GROUP;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_dquot_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t current_lsn)\r\n{\r\nxfs_mount_t *mp = log->l_mp;\r\nxfs_buf_t *bp;\r\nstruct xfs_disk_dquot *ddq, *recddq;\r\nint error;\r\nxfs_dq_logformat_t *dq_f;\r\nuint type;\r\nif (mp->m_qflags == 0)\r\nreturn 0;\r\nrecddq = item->ri_buf[1].i_addr;\r\nif (recddq == NULL) {\r\nxfs_alert(log->l_mp, "NULL dquot in %s.", __func__);\r\nreturn -EIO;\r\n}\r\nif (item->ri_buf[1].i_len < sizeof(xfs_disk_dquot_t)) {\r\nxfs_alert(log->l_mp, "dquot too small (%d) in %s.",\r\nitem->ri_buf[1].i_len, __func__);\r\nreturn -EIO;\r\n}\r\ntype = recddq->d_flags & (XFS_DQ_USER | XFS_DQ_PROJ | XFS_DQ_GROUP);\r\nASSERT(type);\r\nif (log->l_quotaoffs_flag & type)\r\nreturn 0;\r\ndq_f = item->ri_buf[0].i_addr;\r\nASSERT(dq_f);\r\nerror = xfs_dqcheck(mp, recddq, dq_f->qlf_id, 0, XFS_QMOPT_DOWARN,\r\n"xlog_recover_dquot_pass2 (log copy)");\r\nif (error)\r\nreturn -EIO;\r\nASSERT(dq_f->qlf_len == 1);\r\nerror = xfs_trans_read_buf(mp, NULL, mp->m_ddev_targp, dq_f->qlf_blkno,\r\nXFS_FSB_TO_BB(mp, dq_f->qlf_len), 0, &bp,\r\n&xfs_dquot_buf_ops);\r\nif (error)\r\nreturn error;\r\nASSERT(bp);\r\nddq = (xfs_disk_dquot_t *)xfs_buf_offset(bp, dq_f->qlf_boffset);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nstruct xfs_dqblk *dqb = (struct xfs_dqblk *)ddq;\r\nxfs_lsn_t lsn = be64_to_cpu(dqb->dd_lsn);\r\nif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\r\ngoto out_release;\r\n}\r\n}\r\nmemcpy(ddq, recddq, item->ri_buf[1].i_len);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nxfs_update_cksum((char *)ddq, sizeof(struct xfs_dqblk),\r\nXFS_DQUOT_CRC_OFF);\r\n}\r\nASSERT(dq_f->qlf_size == 2);\r\nASSERT(bp->b_target->bt_mount == mp);\r\nbp->b_iodone = xlog_recover_iodone;\r\nxfs_buf_delwri_queue(bp, buffer_list);\r\nout_release:\r\nxfs_buf_relse(bp);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_efi_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t lsn)\r\n{\r\nint error;\r\nxfs_mount_t *mp = log->l_mp;\r\nxfs_efi_log_item_t *efip;\r\nxfs_efi_log_format_t *efi_formatp;\r\nefi_formatp = item->ri_buf[0].i_addr;\r\nefip = xfs_efi_init(mp, efi_formatp->efi_nextents);\r\nif ((error = xfs_efi_copy_format(&(item->ri_buf[0]),\r\n&(efip->efi_format)))) {\r\nxfs_efi_item_free(efip);\r\nreturn error;\r\n}\r\natomic_set(&efip->efi_next_extent, efi_formatp->efi_nextents);\r\nspin_lock(&log->l_ailp->xa_lock);\r\nxfs_trans_ail_update(log->l_ailp, &efip->efi_item, lsn);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_efd_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nxfs_efd_log_format_t *efd_formatp;\r\nxfs_efi_log_item_t *efip = NULL;\r\nxfs_log_item_t *lip;\r\n__uint64_t efi_id;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp = log->l_ailp;\r\nefd_formatp = item->ri_buf[0].i_addr;\r\nASSERT((item->ri_buf[0].i_len == (sizeof(xfs_efd_log_format_32_t) +\r\n((efd_formatp->efd_nextents - 1) * sizeof(xfs_extent_32_t)))) ||\r\n(item->ri_buf[0].i_len == (sizeof(xfs_efd_log_format_64_t) +\r\n((efd_formatp->efd_nextents - 1) * sizeof(xfs_extent_64_t)))));\r\nefi_id = efd_formatp->efd_efi_id;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nwhile (lip != NULL) {\r\nif (lip->li_type == XFS_LI_EFI) {\r\nefip = (xfs_efi_log_item_t *)lip;\r\nif (efip->efi_format.efi_id == efi_id) {\r\nxfs_trans_ail_delete(ailp, lip,\r\nSHUTDOWN_CORRUPT_INCORE);\r\nxfs_efi_item_free(efip);\r\nspin_lock(&ailp->xa_lock);\r\nbreak;\r\n}\r\n}\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_do_icreate_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nxlog_recover_item_t *item)\r\n{\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_icreate_log *icl;\r\nxfs_agnumber_t agno;\r\nxfs_agblock_t agbno;\r\nunsigned int count;\r\nunsigned int isize;\r\nxfs_agblock_t length;\r\nicl = (struct xfs_icreate_log *)item->ri_buf[0].i_addr;\r\nif (icl->icl_type != XFS_LI_ICREATE) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad type");\r\nreturn -EINVAL;\r\n}\r\nif (icl->icl_size != 1) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad icl size");\r\nreturn -EINVAL;\r\n}\r\nagno = be32_to_cpu(icl->icl_ag);\r\nif (agno >= mp->m_sb.sb_agcount) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad agno");\r\nreturn -EINVAL;\r\n}\r\nagbno = be32_to_cpu(icl->icl_agbno);\r\nif (!agbno || agbno == NULLAGBLOCK || agbno >= mp->m_sb.sb_agblocks) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad agbno");\r\nreturn -EINVAL;\r\n}\r\nisize = be32_to_cpu(icl->icl_isize);\r\nif (isize != mp->m_sb.sb_inodesize) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad isize");\r\nreturn -EINVAL;\r\n}\r\ncount = be32_to_cpu(icl->icl_count);\r\nif (!count) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad count");\r\nreturn -EINVAL;\r\n}\r\nlength = be32_to_cpu(icl->icl_length);\r\nif (!length || length >= mp->m_sb.sb_agblocks) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad length");\r\nreturn -EINVAL;\r\n}\r\nASSERT(count == mp->m_ialloc_inos);\r\nASSERT(length == mp->m_ialloc_blks);\r\nif (count != mp->m_ialloc_inos ||\r\nlength != mp->m_ialloc_blks) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad count 2");\r\nreturn -EINVAL;\r\n}\r\nif (xlog_check_buffer_cancelled(log,\r\nXFS_AGB_TO_DADDR(mp, agno, agbno), length, 0))\r\nreturn 0;\r\nxfs_ialloc_inode_init(mp, NULL, buffer_list, agno, agbno, length,\r\nbe32_to_cpu(icl->icl_gen));\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxlog_recover_buffer_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_buf_log_format *buf_f = item->ri_buf[0].i_addr;\r\nstruct xfs_mount *mp = log->l_mp;\r\nif (xlog_peek_buffer_cancelled(log, buf_f->blf_blkno,\r\nbuf_f->blf_len, buf_f->blf_flags)) {\r\nreturn;\r\n}\r\nxfs_buf_readahead(mp->m_ddev_targp, buf_f->blf_blkno,\r\nbuf_f->blf_len, NULL);\r\n}\r\nSTATIC void\r\nxlog_recover_inode_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_inode_log_format ilf_buf;\r\nstruct xfs_inode_log_format *ilfp;\r\nstruct xfs_mount *mp = log->l_mp;\r\nint error;\r\nif (item->ri_buf[0].i_len == sizeof(struct xfs_inode_log_format)) {\r\nilfp = item->ri_buf[0].i_addr;\r\n} else {\r\nilfp = &ilf_buf;\r\nmemset(ilfp, 0, sizeof(*ilfp));\r\nerror = xfs_inode_item_format_convert(&item->ri_buf[0], ilfp);\r\nif (error)\r\nreturn;\r\n}\r\nif (xlog_peek_buffer_cancelled(log, ilfp->ilf_blkno, ilfp->ilf_len, 0))\r\nreturn;\r\nxfs_buf_readahead(mp->m_ddev_targp, ilfp->ilf_blkno,\r\nilfp->ilf_len, &xfs_inode_buf_ra_ops);\r\n}\r\nSTATIC void\r\nxlog_recover_dquot_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_disk_dquot *recddq;\r\nstruct xfs_dq_logformat *dq_f;\r\nuint type;\r\nif (mp->m_qflags == 0)\r\nreturn;\r\nrecddq = item->ri_buf[1].i_addr;\r\nif (recddq == NULL)\r\nreturn;\r\nif (item->ri_buf[1].i_len < sizeof(struct xfs_disk_dquot))\r\nreturn;\r\ntype = recddq->d_flags & (XFS_DQ_USER | XFS_DQ_PROJ | XFS_DQ_GROUP);\r\nASSERT(type);\r\nif (log->l_quotaoffs_flag & type)\r\nreturn;\r\ndq_f = item->ri_buf[0].i_addr;\r\nASSERT(dq_f);\r\nASSERT(dq_f->qlf_len == 1);\r\nxfs_buf_readahead(mp->m_ddev_targp, dq_f->qlf_blkno,\r\nXFS_FSB_TO_BB(mp, dq_f->qlf_len), NULL);\r\n}\r\nSTATIC void\r\nxlog_recover_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_BUF:\r\nxlog_recover_buffer_ra_pass2(log, item);\r\nbreak;\r\ncase XFS_LI_INODE:\r\nxlog_recover_inode_ra_pass2(log, item);\r\nbreak;\r\ncase XFS_LI_DQUOT:\r\nxlog_recover_dquot_ra_pass2(log, item);\r\nbreak;\r\ncase XFS_LI_EFI:\r\ncase XFS_LI_EFD:\r\ncase XFS_LI_QUOTAOFF:\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nSTATIC int\r\nxlog_recover_commit_pass1(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nstruct xlog_recover_item *item)\r\n{\r\ntrace_xfs_log_recover_item_recover(log, trans, item, XLOG_RECOVER_PASS1);\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_BUF:\r\nreturn xlog_recover_buffer_pass1(log, item);\r\ncase XFS_LI_QUOTAOFF:\r\nreturn xlog_recover_quotaoff_pass1(log, item);\r\ncase XFS_LI_INODE:\r\ncase XFS_LI_EFI:\r\ncase XFS_LI_EFD:\r\ncase XFS_LI_DQUOT:\r\ncase XFS_LI_ICREATE:\r\nreturn 0;\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: invalid item type (%d)",\r\n__func__, ITEM_TYPE(item));\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\n}\r\nSTATIC int\r\nxlog_recover_commit_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item)\r\n{\r\ntrace_xfs_log_recover_item_recover(log, trans, item, XLOG_RECOVER_PASS2);\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_BUF:\r\nreturn xlog_recover_buffer_pass2(log, buffer_list, item,\r\ntrans->r_lsn);\r\ncase XFS_LI_INODE:\r\nreturn xlog_recover_inode_pass2(log, buffer_list, item,\r\ntrans->r_lsn);\r\ncase XFS_LI_EFI:\r\nreturn xlog_recover_efi_pass2(log, item, trans->r_lsn);\r\ncase XFS_LI_EFD:\r\nreturn xlog_recover_efd_pass2(log, item);\r\ncase XFS_LI_DQUOT:\r\nreturn xlog_recover_dquot_pass2(log, buffer_list, item,\r\ntrans->r_lsn);\r\ncase XFS_LI_ICREATE:\r\nreturn xlog_recover_do_icreate_pass2(log, buffer_list, item);\r\ncase XFS_LI_QUOTAOFF:\r\nreturn 0;\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: invalid item type (%d)",\r\n__func__, ITEM_TYPE(item));\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\n}\r\nSTATIC int\r\nxlog_recover_items_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nstruct list_head *buffer_list,\r\nstruct list_head *item_list)\r\n{\r\nstruct xlog_recover_item *item;\r\nint error = 0;\r\nlist_for_each_entry(item, item_list, ri_list) {\r\nerror = xlog_recover_commit_pass2(log, trans,\r\nbuffer_list, item);\r\nif (error)\r\nreturn error;\r\n}\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_commit_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nint pass)\r\n{\r\nint error = 0;\r\nint error2;\r\nint items_queued = 0;\r\nstruct xlog_recover_item *item;\r\nstruct xlog_recover_item *next;\r\nLIST_HEAD (buffer_list);\r\nLIST_HEAD (ra_list);\r\nLIST_HEAD (done_list);\r\n#define XLOG_RECOVER_COMMIT_QUEUE_MAX 100\r\nhlist_del(&trans->r_list);\r\nerror = xlog_recover_reorder_trans(log, trans, pass);\r\nif (error)\r\nreturn error;\r\nlist_for_each_entry_safe(item, next, &trans->r_itemq, ri_list) {\r\nswitch (pass) {\r\ncase XLOG_RECOVER_PASS1:\r\nerror = xlog_recover_commit_pass1(log, trans, item);\r\nbreak;\r\ncase XLOG_RECOVER_PASS2:\r\nxlog_recover_ra_pass2(log, item);\r\nlist_move_tail(&item->ri_list, &ra_list);\r\nitems_queued++;\r\nif (items_queued >= XLOG_RECOVER_COMMIT_QUEUE_MAX) {\r\nerror = xlog_recover_items_pass2(log, trans,\r\n&buffer_list, &ra_list);\r\nlist_splice_tail_init(&ra_list, &done_list);\r\nitems_queued = 0;\r\n}\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\n}\r\nif (error)\r\ngoto out;\r\n}\r\nout:\r\nif (!list_empty(&ra_list)) {\r\nif (!error)\r\nerror = xlog_recover_items_pass2(log, trans,\r\n&buffer_list, &ra_list);\r\nlist_splice_tail_init(&ra_list, &done_list);\r\n}\r\nif (!list_empty(&done_list))\r\nlist_splice_init(&done_list, &trans->r_itemq);\r\nerror2 = xfs_buf_delwri_submit(&buffer_list);\r\nreturn error ? error : error2;\r\n}\r\nSTATIC void\r\nxlog_recover_add_item(\r\nstruct list_head *head)\r\n{\r\nxlog_recover_item_t *item;\r\nitem = kmem_zalloc(sizeof(xlog_recover_item_t), KM_SLEEP);\r\nINIT_LIST_HEAD(&item->ri_list);\r\nlist_add_tail(&item->ri_list, head);\r\n}\r\nSTATIC int\r\nxlog_recover_add_to_cont_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nxfs_caddr_t dp,\r\nint len)\r\n{\r\nxlog_recover_item_t *item;\r\nxfs_caddr_t ptr, old_ptr;\r\nint old_len;\r\nif (list_empty(&trans->r_itemq)) {\r\nxlog_recover_add_item(&trans->r_itemq);\r\nptr = (xfs_caddr_t) &trans->r_theader +\r\nsizeof(xfs_trans_header_t) - len;\r\nmemcpy(ptr, dp, len);\r\nreturn 0;\r\n}\r\nitem = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);\r\nold_ptr = item->ri_buf[item->ri_cnt-1].i_addr;\r\nold_len = item->ri_buf[item->ri_cnt-1].i_len;\r\nptr = kmem_realloc(old_ptr, len+old_len, old_len, KM_SLEEP);\r\nmemcpy(&ptr[old_len], dp, len);\r\nitem->ri_buf[item->ri_cnt-1].i_len += len;\r\nitem->ri_buf[item->ri_cnt-1].i_addr = ptr;\r\ntrace_xfs_log_recover_item_add_cont(log, trans, item, 0);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_add_to_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nxfs_caddr_t dp,\r\nint len)\r\n{\r\nxfs_inode_log_format_t *in_f;\r\nxlog_recover_item_t *item;\r\nxfs_caddr_t ptr;\r\nif (!len)\r\nreturn 0;\r\nif (list_empty(&trans->r_itemq)) {\r\nif (*(uint *)dp != XFS_TRANS_HEADER_MAGIC) {\r\nxfs_warn(log->l_mp, "%s: bad header magic number",\r\n__func__);\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\nif (len == sizeof(xfs_trans_header_t))\r\nxlog_recover_add_item(&trans->r_itemq);\r\nmemcpy(&trans->r_theader, dp, len);\r\nreturn 0;\r\n}\r\nptr = kmem_alloc(len, KM_SLEEP);\r\nmemcpy(ptr, dp, len);\r\nin_f = (xfs_inode_log_format_t *)ptr;\r\nitem = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);\r\nif (item->ri_total != 0 &&\r\nitem->ri_total == item->ri_cnt) {\r\nxlog_recover_add_item(&trans->r_itemq);\r\nitem = list_entry(trans->r_itemq.prev,\r\nxlog_recover_item_t, ri_list);\r\n}\r\nif (item->ri_total == 0) {\r\nif (in_f->ilf_size == 0 ||\r\nin_f->ilf_size > XLOG_MAX_REGIONS_IN_ITEM) {\r\nxfs_warn(log->l_mp,\r\n"bad number of regions (%d) in inode log format",\r\nin_f->ilf_size);\r\nASSERT(0);\r\nkmem_free(ptr);\r\nreturn -EIO;\r\n}\r\nitem->ri_total = in_f->ilf_size;\r\nitem->ri_buf =\r\nkmem_zalloc(item->ri_total * sizeof(xfs_log_iovec_t),\r\nKM_SLEEP);\r\n}\r\nASSERT(item->ri_total > item->ri_cnt);\r\nitem->ri_buf[item->ri_cnt].i_addr = ptr;\r\nitem->ri_buf[item->ri_cnt].i_len = len;\r\nitem->ri_cnt++;\r\ntrace_xfs_log_recover_item_add(log, trans, item, 0);\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxlog_recover_free_trans(\r\nstruct xlog_recover *trans)\r\n{\r\nxlog_recover_item_t *item, *n;\r\nint i;\r\nlist_for_each_entry_safe(item, n, &trans->r_itemq, ri_list) {\r\nlist_del(&item->ri_list);\r\nfor (i = 0; i < item->ri_cnt; i++)\r\nkmem_free(item->ri_buf[i].i_addr);\r\nkmem_free(item->ri_buf);\r\nkmem_free(item);\r\n}\r\nkmem_free(trans);\r\n}\r\nSTATIC int\r\nxlog_recovery_process_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nxfs_caddr_t dp,\r\nunsigned int len,\r\nunsigned int flags,\r\nint pass)\r\n{\r\nint error = 0;\r\nbool freeit = false;\r\nflags &= ~XLOG_END_TRANS;\r\nif (flags & XLOG_WAS_CONT_TRANS)\r\nflags &= ~XLOG_CONTINUE_TRANS;\r\nswitch (flags) {\r\ncase 0:\r\ncase XLOG_CONTINUE_TRANS:\r\nerror = xlog_recover_add_to_trans(log, trans, dp, len);\r\nbreak;\r\ncase XLOG_WAS_CONT_TRANS:\r\nerror = xlog_recover_add_to_cont_trans(log, trans, dp, len);\r\nbreak;\r\ncase XLOG_COMMIT_TRANS:\r\nerror = xlog_recover_commit_trans(log, trans, pass);\r\nfreeit = true;\r\nbreak;\r\ncase XLOG_UNMOUNT_TRANS:\r\nxfs_warn(log->l_mp, "%s: Unmount LR", __func__);\r\nfreeit = true;\r\nbreak;\r\ncase XLOG_START_TRANS:\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: bad flag 0x%x", __func__, flags);\r\nASSERT(0);\r\nerror = -EIO;\r\nbreak;\r\n}\r\nif (error || freeit)\r\nxlog_recover_free_trans(trans);\r\nreturn error;\r\n}\r\nSTATIC struct xlog_recover *\r\nxlog_recover_ophdr_to_trans(\r\nstruct hlist_head rhash[],\r\nstruct xlog_rec_header *rhead,\r\nstruct xlog_op_header *ohead)\r\n{\r\nstruct xlog_recover *trans;\r\nxlog_tid_t tid;\r\nstruct hlist_head *rhp;\r\ntid = be32_to_cpu(ohead->oh_tid);\r\nrhp = &rhash[XLOG_RHASH(tid)];\r\nhlist_for_each_entry(trans, rhp, r_list) {\r\nif (trans->r_log_tid == tid)\r\nreturn trans;\r\n}\r\nif (!(ohead->oh_flags & XLOG_START_TRANS))\r\nreturn NULL;\r\nASSERT(be32_to_cpu(ohead->oh_len) == 0);\r\ntrans = kmem_zalloc(sizeof(struct xlog_recover), KM_SLEEP);\r\ntrans->r_log_tid = tid;\r\ntrans->r_lsn = be64_to_cpu(rhead->h_lsn);\r\nINIT_LIST_HEAD(&trans->r_itemq);\r\nINIT_HLIST_NODE(&trans->r_list);\r\nhlist_add_head(&trans->r_list, rhp);\r\nreturn NULL;\r\n}\r\nSTATIC int\r\nxlog_recover_process_ophdr(\r\nstruct xlog *log,\r\nstruct hlist_head rhash[],\r\nstruct xlog_rec_header *rhead,\r\nstruct xlog_op_header *ohead,\r\nxfs_caddr_t dp,\r\nxfs_caddr_t end,\r\nint pass)\r\n{\r\nstruct xlog_recover *trans;\r\nunsigned int len;\r\nif (ohead->oh_clientid != XFS_TRANSACTION &&\r\nohead->oh_clientid != XFS_LOG) {\r\nxfs_warn(log->l_mp, "%s: bad clientid 0x%x",\r\n__func__, ohead->oh_clientid);\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\nlen = be32_to_cpu(ohead->oh_len);\r\nif (dp + len > end) {\r\nxfs_warn(log->l_mp, "%s: bad length 0x%x", __func__, len);\r\nWARN_ON(1);\r\nreturn -EIO;\r\n}\r\ntrans = xlog_recover_ophdr_to_trans(rhash, rhead, ohead);\r\nif (!trans) {\r\nreturn 0;\r\n}\r\nreturn xlog_recovery_process_trans(log, trans, dp, len,\r\nohead->oh_flags, pass);\r\n}\r\nSTATIC int\r\nxlog_recover_process_data(\r\nstruct xlog *log,\r\nstruct hlist_head rhash[],\r\nstruct xlog_rec_header *rhead,\r\nxfs_caddr_t dp,\r\nint pass)\r\n{\r\nstruct xlog_op_header *ohead;\r\nxfs_caddr_t end;\r\nint num_logops;\r\nint error;\r\nend = dp + be32_to_cpu(rhead->h_len);\r\nnum_logops = be32_to_cpu(rhead->h_num_logops);\r\nif (xlog_header_check_recover(log->l_mp, rhead))\r\nreturn -EIO;\r\nwhile ((dp < end) && num_logops) {\r\nohead = (struct xlog_op_header *)dp;\r\ndp += sizeof(*ohead);\r\nASSERT(dp <= end);\r\nerror = xlog_recover_process_ophdr(log, rhash, rhead, ohead,\r\ndp, end, pass);\r\nif (error)\r\nreturn error;\r\ndp += be32_to_cpu(ohead->oh_len);\r\nnum_logops--;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_process_efi(\r\nxfs_mount_t *mp,\r\nxfs_efi_log_item_t *efip)\r\n{\r\nxfs_efd_log_item_t *efdp;\r\nxfs_trans_t *tp;\r\nint i;\r\nint error = 0;\r\nxfs_extent_t *extp;\r\nxfs_fsblock_t startblock_fsb;\r\nASSERT(!test_bit(XFS_EFI_RECOVERED, &efip->efi_flags));\r\nfor (i = 0; i < efip->efi_format.efi_nextents; i++) {\r\nextp = &(efip->efi_format.efi_extents[i]);\r\nstartblock_fsb = XFS_BB_TO_FSB(mp,\r\nXFS_FSB_TO_DADDR(mp, extp->ext_start));\r\nif ((startblock_fsb == 0) ||\r\n(extp->ext_len == 0) ||\r\n(startblock_fsb >= mp->m_sb.sb_dblocks) ||\r\n(extp->ext_len >= mp->m_sb.sb_agblocks)) {\r\nset_bit(XFS_EFI_RECOVERED, &efip->efi_flags);\r\nxfs_efi_release(efip, efip->efi_format.efi_nextents);\r\nreturn -EIO;\r\n}\r\n}\r\ntp = xfs_trans_alloc(mp, 0);\r\nerror = xfs_trans_reserve(tp, &M_RES(mp)->tr_itruncate, 0, 0);\r\nif (error)\r\ngoto abort_error;\r\nefdp = xfs_trans_get_efd(tp, efip, efip->efi_format.efi_nextents);\r\nfor (i = 0; i < efip->efi_format.efi_nextents; i++) {\r\nextp = &(efip->efi_format.efi_extents[i]);\r\nerror = xfs_free_extent(tp, extp->ext_start, extp->ext_len);\r\nif (error)\r\ngoto abort_error;\r\nxfs_trans_log_efd_extent(tp, efdp, extp->ext_start,\r\nextp->ext_len);\r\n}\r\nset_bit(XFS_EFI_RECOVERED, &efip->efi_flags);\r\nerror = xfs_trans_commit(tp, 0);\r\nreturn error;\r\nabort_error:\r\nxfs_trans_cancel(tp, XFS_TRANS_ABORT);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_process_efis(\r\nstruct xlog *log)\r\n{\r\nxfs_log_item_t *lip;\r\nxfs_efi_log_item_t *efip;\r\nint error = 0;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp;\r\nailp = log->l_ailp;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nwhile (lip != NULL) {\r\nif (lip->li_type != XFS_LI_EFI) {\r\n#ifdef DEBUG\r\nfor (; lip; lip = xfs_trans_ail_cursor_next(ailp, &cur))\r\nASSERT(lip->li_type != XFS_LI_EFI);\r\n#endif\r\nbreak;\r\n}\r\nefip = (xfs_efi_log_item_t *)lip;\r\nif (test_bit(XFS_EFI_RECOVERED, &efip->efi_flags)) {\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\ncontinue;\r\n}\r\nspin_unlock(&ailp->xa_lock);\r\nerror = xlog_recover_process_efi(log->l_mp, efip);\r\nspin_lock(&ailp->xa_lock);\r\nif (error)\r\ngoto out;\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nout:\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_recover_clear_agi_bucket(\r\nxfs_mount_t *mp,\r\nxfs_agnumber_t agno,\r\nint bucket)\r\n{\r\nxfs_trans_t *tp;\r\nxfs_agi_t *agi;\r\nxfs_buf_t *agibp;\r\nint offset;\r\nint error;\r\ntp = xfs_trans_alloc(mp, XFS_TRANS_CLEAR_AGI_BUCKET);\r\nerror = xfs_trans_reserve(tp, &M_RES(mp)->tr_clearagi, 0, 0);\r\nif (error)\r\ngoto out_abort;\r\nerror = xfs_read_agi(mp, tp, agno, &agibp);\r\nif (error)\r\ngoto out_abort;\r\nagi = XFS_BUF_TO_AGI(agibp);\r\nagi->agi_unlinked[bucket] = cpu_to_be32(NULLAGINO);\r\noffset = offsetof(xfs_agi_t, agi_unlinked) +\r\n(sizeof(xfs_agino_t) * bucket);\r\nxfs_trans_log_buf(tp, agibp, offset,\r\n(offset + sizeof(xfs_agino_t) - 1));\r\nerror = xfs_trans_commit(tp, 0);\r\nif (error)\r\ngoto out_error;\r\nreturn;\r\nout_abort:\r\nxfs_trans_cancel(tp, XFS_TRANS_ABORT);\r\nout_error:\r\nxfs_warn(mp, "%s: failed to clear agi %d. Continuing.", __func__, agno);\r\nreturn;\r\n}\r\nSTATIC xfs_agino_t\r\nxlog_recover_process_one_iunlink(\r\nstruct xfs_mount *mp,\r\nxfs_agnumber_t agno,\r\nxfs_agino_t agino,\r\nint bucket)\r\n{\r\nstruct xfs_buf *ibp;\r\nstruct xfs_dinode *dip;\r\nstruct xfs_inode *ip;\r\nxfs_ino_t ino;\r\nint error;\r\nino = XFS_AGINO_TO_INO(mp, agno, agino);\r\nerror = xfs_iget(mp, NULL, ino, 0, 0, &ip);\r\nif (error)\r\ngoto fail;\r\nerror = xfs_imap_to_bp(mp, NULL, &ip->i_imap, &dip, &ibp, 0, 0);\r\nif (error)\r\ngoto fail_iput;\r\nASSERT(ip->i_d.di_nlink == 0);\r\nASSERT(ip->i_d.di_mode != 0);\r\nagino = be32_to_cpu(dip->di_next_unlinked);\r\nxfs_buf_relse(ibp);\r\nip->i_d.di_dmevmask = 0;\r\nIRELE(ip);\r\nreturn agino;\r\nfail_iput:\r\nIRELE(ip);\r\nfail:\r\nxlog_recover_clear_agi_bucket(mp, agno, bucket);\r\nreturn NULLAGINO;\r\n}\r\nSTATIC void\r\nxlog_recover_process_iunlinks(\r\nstruct xlog *log)\r\n{\r\nxfs_mount_t *mp;\r\nxfs_agnumber_t agno;\r\nxfs_agi_t *agi;\r\nxfs_buf_t *agibp;\r\nxfs_agino_t agino;\r\nint bucket;\r\nint error;\r\nuint mp_dmevmask;\r\nmp = log->l_mp;\r\nmp_dmevmask = mp->m_dmevmask;\r\nmp->m_dmevmask = 0;\r\nfor (agno = 0; agno < mp->m_sb.sb_agcount; agno++) {\r\nerror = xfs_read_agi(mp, NULL, agno, &agibp);\r\nif (error) {\r\ncontinue;\r\n}\r\nagi = XFS_BUF_TO_AGI(agibp);\r\nxfs_buf_unlock(agibp);\r\nfor (bucket = 0; bucket < XFS_AGI_UNLINKED_BUCKETS; bucket++) {\r\nagino = be32_to_cpu(agi->agi_unlinked[bucket]);\r\nwhile (agino != NULLAGINO) {\r\nagino = xlog_recover_process_one_iunlink(mp,\r\nagno, agino, bucket);\r\n}\r\n}\r\nxfs_buf_rele(agibp);\r\n}\r\nmp->m_dmevmask = mp_dmevmask;\r\n}\r\nSTATIC int\r\nxlog_unpack_data_crc(\r\nstruct xlog_rec_header *rhead,\r\nxfs_caddr_t dp,\r\nstruct xlog *log)\r\n{\r\n__le32 crc;\r\ncrc = xlog_cksum(log, rhead, dp, be32_to_cpu(rhead->h_len));\r\nif (crc != rhead->h_crc) {\r\nif (rhead->h_crc || xfs_sb_version_hascrc(&log->l_mp->m_sb)) {\r\nxfs_alert(log->l_mp,\r\n"log record CRC mismatch: found 0x%x, expected 0x%x.",\r\nle32_to_cpu(rhead->h_crc),\r\nle32_to_cpu(crc));\r\nxfs_hex_dump(dp, 32);\r\n}\r\nif (xfs_sb_version_hascrc(&log->l_mp->m_sb))\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_unpack_data(\r\nstruct xlog_rec_header *rhead,\r\nxfs_caddr_t dp,\r\nstruct xlog *log)\r\n{\r\nint i, j, k;\r\nint error;\r\nerror = xlog_unpack_data_crc(rhead, dp, log);\r\nif (error)\r\nreturn error;\r\nfor (i = 0; i < BTOBB(be32_to_cpu(rhead->h_len)) &&\r\ni < (XLOG_HEADER_CYCLE_SIZE / BBSIZE); i++) {\r\n*(__be32 *)dp = *(__be32 *)&rhead->h_cycle_data[i];\r\ndp += BBSIZE;\r\n}\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nxlog_in_core_2_t *xhdr = (xlog_in_core_2_t *)rhead;\r\nfor ( ; i < BTOBB(be32_to_cpu(rhead->h_len)); i++) {\r\nj = i / (XLOG_HEADER_CYCLE_SIZE / BBSIZE);\r\nk = i % (XLOG_HEADER_CYCLE_SIZE / BBSIZE);\r\n*(__be32 *)dp = xhdr[j].hic_xheader.xh_cycle_data[k];\r\ndp += BBSIZE;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_valid_rec_header(\r\nstruct xlog *log,\r\nstruct xlog_rec_header *rhead,\r\nxfs_daddr_t blkno)\r\n{\r\nint hlen;\r\nif (unlikely(rhead->h_magicno != cpu_to_be32(XLOG_HEADER_MAGIC_NUM))) {\r\nXFS_ERROR_REPORT("xlog_valid_rec_header(1)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nif (unlikely(\r\n(!rhead->h_version ||\r\n(be32_to_cpu(rhead->h_version) & (~XLOG_VERSION_OKBITS))))) {\r\nxfs_warn(log->l_mp, "%s: unrecognised log version (%d).",\r\n__func__, be32_to_cpu(rhead->h_version));\r\nreturn -EIO;\r\n}\r\nhlen = be32_to_cpu(rhead->h_len);\r\nif (unlikely( hlen <= 0 || hlen > INT_MAX )) {\r\nXFS_ERROR_REPORT("xlog_valid_rec_header(2)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nif (unlikely( blkno > log->l_logBBsize || blkno > INT_MAX )) {\r\nXFS_ERROR_REPORT("xlog_valid_rec_header(3)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_do_recovery_pass(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk,\r\nint pass)\r\n{\r\nxlog_rec_header_t *rhead;\r\nxfs_daddr_t blk_no;\r\nxfs_caddr_t offset;\r\nxfs_buf_t *hbp, *dbp;\r\nint error = 0, h_size;\r\nint bblks, split_bblks;\r\nint hblks, split_hblks, wrapped_hblks;\r\nstruct hlist_head rhash[XLOG_RHASH_SIZE];\r\nASSERT(head_blk != tail_blk);\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nhbp = xlog_get_bp(log, 1);\r\nif (!hbp)\r\nreturn -ENOMEM;\r\nerror = xlog_bread(log, tail_blk, 1, hbp, &offset);\r\nif (error)\r\ngoto bread_err1;\r\nrhead = (xlog_rec_header_t *)offset;\r\nerror = xlog_valid_rec_header(log, rhead, tail_blk);\r\nif (error)\r\ngoto bread_err1;\r\nh_size = be32_to_cpu(rhead->h_size);\r\nif ((be32_to_cpu(rhead->h_version) & XLOG_VERSION_2) &&\r\n(h_size > XLOG_HEADER_CYCLE_SIZE)) {\r\nhblks = h_size / XLOG_HEADER_CYCLE_SIZE;\r\nif (h_size % XLOG_HEADER_CYCLE_SIZE)\r\nhblks++;\r\nxlog_put_bp(hbp);\r\nhbp = xlog_get_bp(log, hblks);\r\n} else {\r\nhblks = 1;\r\n}\r\n} else {\r\nASSERT(log->l_sectBBsize == 1);\r\nhblks = 1;\r\nhbp = xlog_get_bp(log, 1);\r\nh_size = XLOG_BIG_RECORD_BSIZE;\r\n}\r\nif (!hbp)\r\nreturn -ENOMEM;\r\ndbp = xlog_get_bp(log, BTOBB(h_size));\r\nif (!dbp) {\r\nxlog_put_bp(hbp);\r\nreturn -ENOMEM;\r\n}\r\nmemset(rhash, 0, sizeof(rhash));\r\nblk_no = tail_blk;\r\nif (tail_blk > head_blk) {\r\nwhile (blk_no < log->l_logBBsize) {\r\noffset = hbp->b_addr;\r\nsplit_hblks = 0;\r\nwrapped_hblks = 0;\r\nif (blk_no + hblks <= log->l_logBBsize) {\r\nerror = xlog_bread(log, blk_no, hblks, hbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n} else {\r\nif (blk_no != log->l_logBBsize) {\r\nASSERT(blk_no <= INT_MAX);\r\nsplit_hblks = log->l_logBBsize - (int)blk_no;\r\nASSERT(split_hblks > 0);\r\nerror = xlog_bread(log, blk_no,\r\nsplit_hblks, hbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nwrapped_hblks = hblks - split_hblks;\r\nerror = xlog_bread_offset(log, 0,\r\nwrapped_hblks, hbp,\r\noffset + BBTOB(split_hblks));\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nrhead = (xlog_rec_header_t *)offset;\r\nerror = xlog_valid_rec_header(log, rhead,\r\nsplit_hblks ? blk_no : 0);\r\nif (error)\r\ngoto bread_err2;\r\nbblks = (int)BTOBB(be32_to_cpu(rhead->h_len));\r\nblk_no += hblks;\r\nif (blk_no + bblks <= log->l_logBBsize) {\r\nerror = xlog_bread(log, blk_no, bblks, dbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n} else {\r\noffset = dbp->b_addr;\r\nsplit_bblks = 0;\r\nif (blk_no != log->l_logBBsize) {\r\nASSERT(!wrapped_hblks);\r\nASSERT(blk_no <= INT_MAX);\r\nsplit_bblks =\r\nlog->l_logBBsize - (int)blk_no;\r\nASSERT(split_bblks > 0);\r\nerror = xlog_bread(log, blk_no,\r\nsplit_bblks, dbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nerror = xlog_bread_offset(log, 0,\r\nbblks - split_bblks, dbp,\r\noffset + BBTOB(split_bblks));\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nerror = xlog_unpack_data(rhead, offset, log);\r\nif (error)\r\ngoto bread_err2;\r\nerror = xlog_recover_process_data(log, rhash,\r\nrhead, offset, pass);\r\nif (error)\r\ngoto bread_err2;\r\nblk_no += bblks;\r\n}\r\nASSERT(blk_no >= log->l_logBBsize);\r\nblk_no -= log->l_logBBsize;\r\n}\r\nwhile (blk_no < head_blk) {\r\nerror = xlog_bread(log, blk_no, hblks, hbp, &offset);\r\nif (error)\r\ngoto bread_err2;\r\nrhead = (xlog_rec_header_t *)offset;\r\nerror = xlog_valid_rec_header(log, rhead, blk_no);\r\nif (error)\r\ngoto bread_err2;\r\nbblks = (int)BTOBB(be32_to_cpu(rhead->h_len));\r\nerror = xlog_bread(log, blk_no+hblks, bblks, dbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\nerror = xlog_unpack_data(rhead, offset, log);\r\nif (error)\r\ngoto bread_err2;\r\nerror = xlog_recover_process_data(log, rhash,\r\nrhead, offset, pass);\r\nif (error)\r\ngoto bread_err2;\r\nblk_no += bblks + hblks;\r\n}\r\nbread_err2:\r\nxlog_put_bp(dbp);\r\nbread_err1:\r\nxlog_put_bp(hbp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_do_log_recovery(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk)\r\n{\r\nint error, i;\r\nASSERT(head_blk != tail_blk);\r\nlog->l_buf_cancel_table = kmem_zalloc(XLOG_BC_TABLE_SIZE *\r\nsizeof(struct list_head),\r\nKM_SLEEP);\r\nfor (i = 0; i < XLOG_BC_TABLE_SIZE; i++)\r\nINIT_LIST_HEAD(&log->l_buf_cancel_table[i]);\r\nerror = xlog_do_recovery_pass(log, head_blk, tail_blk,\r\nXLOG_RECOVER_PASS1);\r\nif (error != 0) {\r\nkmem_free(log->l_buf_cancel_table);\r\nlog->l_buf_cancel_table = NULL;\r\nreturn error;\r\n}\r\nerror = xlog_do_recovery_pass(log, head_blk, tail_blk,\r\nXLOG_RECOVER_PASS2);\r\n#ifdef DEBUG\r\nif (!error) {\r\nint i;\r\nfor (i = 0; i < XLOG_BC_TABLE_SIZE; i++)\r\nASSERT(list_empty(&log->l_buf_cancel_table[i]));\r\n}\r\n#endif\r\nkmem_free(log->l_buf_cancel_table);\r\nlog->l_buf_cancel_table = NULL;\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_do_recover(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk)\r\n{\r\nint error;\r\nxfs_buf_t *bp;\r\nxfs_sb_t *sbp;\r\nerror = xlog_do_log_recovery(log, head_blk, tail_blk);\r\nif (error)\r\nreturn error;\r\nif (XFS_FORCED_SHUTDOWN(log->l_mp)) {\r\nreturn -EIO;\r\n}\r\nxlog_assign_tail_lsn(log->l_mp);\r\nbp = xfs_getsb(log->l_mp, 0);\r\nXFS_BUF_UNDONE(bp);\r\nASSERT(!(XFS_BUF_ISWRITE(bp)));\r\nXFS_BUF_READ(bp);\r\nXFS_BUF_UNASYNC(bp);\r\nbp->b_ops = &xfs_sb_buf_ops;\r\nerror = xfs_buf_submit_wait(bp);\r\nif (error) {\r\nif (!XFS_FORCED_SHUTDOWN(log->l_mp)) {\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nASSERT(0);\r\n}\r\nxfs_buf_relse(bp);\r\nreturn error;\r\n}\r\nsbp = &log->l_mp->m_sb;\r\nxfs_sb_from_disk(sbp, XFS_BUF_TO_SBP(bp));\r\nASSERT(sbp->sb_magicnum == XFS_SB_MAGIC);\r\nASSERT(xfs_sb_good_version(sbp));\r\nxfs_buf_relse(bp);\r\nxfs_icsb_reinit_counters(log->l_mp);\r\nxlog_recover_check_summary(log);\r\nlog->l_flags &= ~XLOG_ACTIVE_RECOVERY;\r\nreturn 0;\r\n}\r\nint\r\nxlog_recover(\r\nstruct xlog *log)\r\n{\r\nxfs_daddr_t head_blk, tail_blk;\r\nint error;\r\nif ((error = xlog_find_tail(log, &head_blk, &tail_blk)))\r\nreturn error;\r\nif (tail_blk != head_blk) {\r\nif ((error = xfs_dev_is_read_only(log->l_mp, "recovery"))) {\r\nreturn error;\r\n}\r\nif (XFS_SB_VERSION_NUM(&log->l_mp->m_sb) == XFS_SB_VERSION_5 &&\r\nxfs_sb_has_incompat_log_feature(&log->l_mp->m_sb,\r\nXFS_SB_FEAT_INCOMPAT_LOG_UNKNOWN)) {\r\nxfs_warn(log->l_mp,\r\n"Superblock has unknown incompatible log features (0x%x) enabled.\n"\r\n"The log can not be fully and/or safely recovered by this kernel.\n"\r\n"Please recover the log on a kernel that supports the unknown features.",\r\n(log->l_mp->m_sb.sb_features_log_incompat &\r\nXFS_SB_FEAT_INCOMPAT_LOG_UNKNOWN));\r\nreturn -EINVAL;\r\n}\r\nif (xfs_globals.log_recovery_delay) {\r\nxfs_notice(log->l_mp,\r\n"Delaying log recovery for %d seconds.",\r\nxfs_globals.log_recovery_delay);\r\nmsleep(xfs_globals.log_recovery_delay * 1000);\r\n}\r\nxfs_notice(log->l_mp, "Starting recovery (logdev: %s)",\r\nlog->l_mp->m_logname ? log->l_mp->m_logname\r\n: "internal");\r\nerror = xlog_do_recover(log, head_blk, tail_blk);\r\nlog->l_flags |= XLOG_RECOVERY_NEEDED;\r\n}\r\nreturn error;\r\n}\r\nint\r\nxlog_recover_finish(\r\nstruct xlog *log)\r\n{\r\nif (log->l_flags & XLOG_RECOVERY_NEEDED) {\r\nint error;\r\nerror = xlog_recover_process_efis(log);\r\nif (error) {\r\nxfs_alert(log->l_mp, "Failed to recover EFIs");\r\nreturn error;\r\n}\r\nxfs_log_force(log->l_mp, XFS_LOG_SYNC);\r\nxlog_recover_process_iunlinks(log);\r\nxlog_recover_check_summary(log);\r\nxfs_notice(log->l_mp, "Ending recovery (logdev: %s)",\r\nlog->l_mp->m_logname ? log->l_mp->m_logname\r\n: "internal");\r\nlog->l_flags &= ~XLOG_RECOVERY_NEEDED;\r\n} else {\r\nxfs_info(log->l_mp, "Ending clean mount");\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nxlog_recover_check_summary(\r\nstruct xlog *log)\r\n{\r\nxfs_mount_t *mp;\r\nxfs_agf_t *agfp;\r\nxfs_buf_t *agfbp;\r\nxfs_buf_t *agibp;\r\nxfs_agnumber_t agno;\r\n__uint64_t freeblks;\r\n__uint64_t itotal;\r\n__uint64_t ifree;\r\nint error;\r\nmp = log->l_mp;\r\nfreeblks = 0LL;\r\nitotal = 0LL;\r\nifree = 0LL;\r\nfor (agno = 0; agno < mp->m_sb.sb_agcount; agno++) {\r\nerror = xfs_read_agf(mp, NULL, agno, 0, &agfbp);\r\nif (error) {\r\nxfs_alert(mp, "%s agf read failed agno %d error %d",\r\n__func__, agno, error);\r\n} else {\r\nagfp = XFS_BUF_TO_AGF(agfbp);\r\nfreeblks += be32_to_cpu(agfp->agf_freeblks) +\r\nbe32_to_cpu(agfp->agf_flcount);\r\nxfs_buf_relse(agfbp);\r\n}\r\nerror = xfs_read_agi(mp, NULL, agno, &agibp);\r\nif (error) {\r\nxfs_alert(mp, "%s agi read failed agno %d error %d",\r\n__func__, agno, error);\r\n} else {\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agibp);\r\nitotal += be32_to_cpu(agi->agi_count);\r\nifree += be32_to_cpu(agi->agi_freecount);\r\nxfs_buf_relse(agibp);\r\n}\r\n}\r\n}
