static int dma_buf_release(struct inode *inode, struct file *file)\r\n{\r\nstruct dma_buf *dmabuf;\r\nif (!is_dma_buf_file(file))\r\nreturn -EINVAL;\r\ndmabuf = file->private_data;\r\nBUG_ON(dmabuf->vmapping_counter);\r\nBUG_ON(dmabuf->cb_shared.active || dmabuf->cb_excl.active);\r\ndmabuf->ops->release(dmabuf);\r\nmutex_lock(&db_list.lock);\r\nlist_del(&dmabuf->list_node);\r\nmutex_unlock(&db_list.lock);\r\nif (dmabuf->resv == (struct reservation_object *)&dmabuf[1])\r\nreservation_object_fini(dmabuf->resv);\r\nkfree(dmabuf);\r\nreturn 0;\r\n}\r\nstatic int dma_buf_mmap_internal(struct file *file, struct vm_area_struct *vma)\r\n{\r\nstruct dma_buf *dmabuf;\r\nif (!is_dma_buf_file(file))\r\nreturn -EINVAL;\r\ndmabuf = file->private_data;\r\nif (vma->vm_pgoff + ((vma->vm_end - vma->vm_start) >> PAGE_SHIFT) >\r\ndmabuf->size >> PAGE_SHIFT)\r\nreturn -EINVAL;\r\nreturn dmabuf->ops->mmap(dmabuf, vma);\r\n}\r\nstatic loff_t dma_buf_llseek(struct file *file, loff_t offset, int whence)\r\n{\r\nstruct dma_buf *dmabuf;\r\nloff_t base;\r\nif (!is_dma_buf_file(file))\r\nreturn -EBADF;\r\ndmabuf = file->private_data;\r\nif (whence == SEEK_END)\r\nbase = dmabuf->size;\r\nelse if (whence == SEEK_SET)\r\nbase = 0;\r\nelse\r\nreturn -EINVAL;\r\nif (offset != 0)\r\nreturn -EINVAL;\r\nreturn base + offset;\r\n}\r\nstatic void dma_buf_poll_cb(struct fence *fence, struct fence_cb *cb)\r\n{\r\nstruct dma_buf_poll_cb_t *dcb = (struct dma_buf_poll_cb_t *)cb;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dcb->poll->lock, flags);\r\nwake_up_locked_poll(dcb->poll, dcb->active);\r\ndcb->active = 0;\r\nspin_unlock_irqrestore(&dcb->poll->lock, flags);\r\n}\r\nstatic unsigned int dma_buf_poll(struct file *file, poll_table *poll)\r\n{\r\nstruct dma_buf *dmabuf;\r\nstruct reservation_object *resv;\r\nstruct reservation_object_list *fobj;\r\nstruct fence *fence_excl;\r\nunsigned long events;\r\nunsigned shared_count, seq;\r\ndmabuf = file->private_data;\r\nif (!dmabuf || !dmabuf->resv)\r\nreturn POLLERR;\r\nresv = dmabuf->resv;\r\npoll_wait(file, &dmabuf->poll, poll);\r\nevents = poll_requested_events(poll) & (POLLIN | POLLOUT);\r\nif (!events)\r\nreturn 0;\r\nretry:\r\nseq = read_seqcount_begin(&resv->seq);\r\nrcu_read_lock();\r\nfobj = rcu_dereference(resv->fence);\r\nif (fobj)\r\nshared_count = fobj->shared_count;\r\nelse\r\nshared_count = 0;\r\nfence_excl = rcu_dereference(resv->fence_excl);\r\nif (read_seqcount_retry(&resv->seq, seq)) {\r\nrcu_read_unlock();\r\ngoto retry;\r\n}\r\nif (fence_excl && (!(events & POLLOUT) || shared_count == 0)) {\r\nstruct dma_buf_poll_cb_t *dcb = &dmabuf->cb_excl;\r\nunsigned long pevents = POLLIN;\r\nif (shared_count == 0)\r\npevents |= POLLOUT;\r\nspin_lock_irq(&dmabuf->poll.lock);\r\nif (dcb->active) {\r\ndcb->active |= pevents;\r\nevents &= ~pevents;\r\n} else\r\ndcb->active = pevents;\r\nspin_unlock_irq(&dmabuf->poll.lock);\r\nif (events & pevents) {\r\nif (!fence_get_rcu(fence_excl)) {\r\nevents &= ~pevents;\r\ndma_buf_poll_cb(NULL, &dcb->cb);\r\n} else if (!fence_add_callback(fence_excl, &dcb->cb,\r\ndma_buf_poll_cb)) {\r\nevents &= ~pevents;\r\nfence_put(fence_excl);\r\n} else {\r\nfence_put(fence_excl);\r\ndma_buf_poll_cb(NULL, &dcb->cb);\r\n}\r\n}\r\n}\r\nif ((events & POLLOUT) && shared_count > 0) {\r\nstruct dma_buf_poll_cb_t *dcb = &dmabuf->cb_shared;\r\nint i;\r\nspin_lock_irq(&dmabuf->poll.lock);\r\nif (dcb->active)\r\nevents &= ~POLLOUT;\r\nelse\r\ndcb->active = POLLOUT;\r\nspin_unlock_irq(&dmabuf->poll.lock);\r\nif (!(events & POLLOUT))\r\ngoto out;\r\nfor (i = 0; i < shared_count; ++i) {\r\nstruct fence *fence = rcu_dereference(fobj->shared[i]);\r\nif (!fence_get_rcu(fence)) {\r\nevents &= ~POLLOUT;\r\ndma_buf_poll_cb(NULL, &dcb->cb);\r\nbreak;\r\n}\r\nif (!fence_add_callback(fence, &dcb->cb,\r\ndma_buf_poll_cb)) {\r\nfence_put(fence);\r\nevents &= ~POLLOUT;\r\nbreak;\r\n}\r\nfence_put(fence);\r\n}\r\nif (i == shared_count)\r\ndma_buf_poll_cb(NULL, &dcb->cb);\r\n}\r\nout:\r\nrcu_read_unlock();\r\nreturn events;\r\n}\r\nstatic inline int is_dma_buf_file(struct file *file)\r\n{\r\nreturn file->f_op == &dma_buf_fops;\r\n}\r\nstruct dma_buf *dma_buf_export_named(void *priv, const struct dma_buf_ops *ops,\r\nsize_t size, int flags, const char *exp_name,\r\nstruct reservation_object *resv)\r\n{\r\nstruct dma_buf *dmabuf;\r\nstruct file *file;\r\nsize_t alloc_size = sizeof(struct dma_buf);\r\nif (!resv)\r\nalloc_size += sizeof(struct reservation_object);\r\nelse\r\nalloc_size += 1;\r\nif (WARN_ON(!priv || !ops\r\n|| !ops->map_dma_buf\r\n|| !ops->unmap_dma_buf\r\n|| !ops->release\r\n|| !ops->kmap_atomic\r\n|| !ops->kmap\r\n|| !ops->mmap)) {\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\ndmabuf = kzalloc(alloc_size, GFP_KERNEL);\r\nif (dmabuf == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\ndmabuf->priv = priv;\r\ndmabuf->ops = ops;\r\ndmabuf->size = size;\r\ndmabuf->exp_name = exp_name;\r\ninit_waitqueue_head(&dmabuf->poll);\r\ndmabuf->cb_excl.poll = dmabuf->cb_shared.poll = &dmabuf->poll;\r\ndmabuf->cb_excl.active = dmabuf->cb_shared.active = 0;\r\nif (!resv) {\r\nresv = (struct reservation_object *)&dmabuf[1];\r\nreservation_object_init(resv);\r\n}\r\ndmabuf->resv = resv;\r\nfile = anon_inode_getfile("dmabuf", &dma_buf_fops, dmabuf, flags);\r\nif (IS_ERR(file)) {\r\nkfree(dmabuf);\r\nreturn ERR_CAST(file);\r\n}\r\nfile->f_mode |= FMODE_LSEEK;\r\ndmabuf->file = file;\r\nmutex_init(&dmabuf->lock);\r\nINIT_LIST_HEAD(&dmabuf->attachments);\r\nmutex_lock(&db_list.lock);\r\nlist_add(&dmabuf->list_node, &db_list.head);\r\nmutex_unlock(&db_list.lock);\r\nreturn dmabuf;\r\n}\r\nint dma_buf_fd(struct dma_buf *dmabuf, int flags)\r\n{\r\nint fd;\r\nif (!dmabuf || !dmabuf->file)\r\nreturn -EINVAL;\r\nfd = get_unused_fd_flags(flags);\r\nif (fd < 0)\r\nreturn fd;\r\nfd_install(fd, dmabuf->file);\r\nreturn fd;\r\n}\r\nstruct dma_buf *dma_buf_get(int fd)\r\n{\r\nstruct file *file;\r\nfile = fget(fd);\r\nif (!file)\r\nreturn ERR_PTR(-EBADF);\r\nif (!is_dma_buf_file(file)) {\r\nfput(file);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nreturn file->private_data;\r\n}\r\nvoid dma_buf_put(struct dma_buf *dmabuf)\r\n{\r\nif (WARN_ON(!dmabuf || !dmabuf->file))\r\nreturn;\r\nfput(dmabuf->file);\r\n}\r\nstruct dma_buf_attachment *dma_buf_attach(struct dma_buf *dmabuf,\r\nstruct device *dev)\r\n{\r\nstruct dma_buf_attachment *attach;\r\nint ret;\r\nif (WARN_ON(!dmabuf || !dev))\r\nreturn ERR_PTR(-EINVAL);\r\nattach = kzalloc(sizeof(struct dma_buf_attachment), GFP_KERNEL);\r\nif (attach == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nattach->dev = dev;\r\nattach->dmabuf = dmabuf;\r\nmutex_lock(&dmabuf->lock);\r\nif (dmabuf->ops->attach) {\r\nret = dmabuf->ops->attach(dmabuf, dev, attach);\r\nif (ret)\r\ngoto err_attach;\r\n}\r\nlist_add(&attach->node, &dmabuf->attachments);\r\nmutex_unlock(&dmabuf->lock);\r\nreturn attach;\r\nerr_attach:\r\nkfree(attach);\r\nmutex_unlock(&dmabuf->lock);\r\nreturn ERR_PTR(ret);\r\n}\r\nvoid dma_buf_detach(struct dma_buf *dmabuf, struct dma_buf_attachment *attach)\r\n{\r\nif (WARN_ON(!dmabuf || !attach))\r\nreturn;\r\nmutex_lock(&dmabuf->lock);\r\nlist_del(&attach->node);\r\nif (dmabuf->ops->detach)\r\ndmabuf->ops->detach(dmabuf, attach);\r\nmutex_unlock(&dmabuf->lock);\r\nkfree(attach);\r\n}\r\nstruct sg_table *dma_buf_map_attachment(struct dma_buf_attachment *attach,\r\nenum dma_data_direction direction)\r\n{\r\nstruct sg_table *sg_table = ERR_PTR(-EINVAL);\r\nmight_sleep();\r\nif (WARN_ON(!attach || !attach->dmabuf))\r\nreturn ERR_PTR(-EINVAL);\r\nsg_table = attach->dmabuf->ops->map_dma_buf(attach, direction);\r\nif (!sg_table)\r\nsg_table = ERR_PTR(-ENOMEM);\r\nreturn sg_table;\r\n}\r\nvoid dma_buf_unmap_attachment(struct dma_buf_attachment *attach,\r\nstruct sg_table *sg_table,\r\nenum dma_data_direction direction)\r\n{\r\nmight_sleep();\r\nif (WARN_ON(!attach || !attach->dmabuf || !sg_table))\r\nreturn;\r\nattach->dmabuf->ops->unmap_dma_buf(attach, sg_table,\r\ndirection);\r\n}\r\nint dma_buf_begin_cpu_access(struct dma_buf *dmabuf, size_t start, size_t len,\r\nenum dma_data_direction direction)\r\n{\r\nint ret = 0;\r\nif (WARN_ON(!dmabuf))\r\nreturn -EINVAL;\r\nif (dmabuf->ops->begin_cpu_access)\r\nret = dmabuf->ops->begin_cpu_access(dmabuf, start, len, direction);\r\nreturn ret;\r\n}\r\nvoid dma_buf_end_cpu_access(struct dma_buf *dmabuf, size_t start, size_t len,\r\nenum dma_data_direction direction)\r\n{\r\nWARN_ON(!dmabuf);\r\nif (dmabuf->ops->end_cpu_access)\r\ndmabuf->ops->end_cpu_access(dmabuf, start, len, direction);\r\n}\r\nvoid *dma_buf_kmap_atomic(struct dma_buf *dmabuf, unsigned long page_num)\r\n{\r\nWARN_ON(!dmabuf);\r\nreturn dmabuf->ops->kmap_atomic(dmabuf, page_num);\r\n}\r\nvoid dma_buf_kunmap_atomic(struct dma_buf *dmabuf, unsigned long page_num,\r\nvoid *vaddr)\r\n{\r\nWARN_ON(!dmabuf);\r\nif (dmabuf->ops->kunmap_atomic)\r\ndmabuf->ops->kunmap_atomic(dmabuf, page_num, vaddr);\r\n}\r\nvoid *dma_buf_kmap(struct dma_buf *dmabuf, unsigned long page_num)\r\n{\r\nWARN_ON(!dmabuf);\r\nreturn dmabuf->ops->kmap(dmabuf, page_num);\r\n}\r\nvoid dma_buf_kunmap(struct dma_buf *dmabuf, unsigned long page_num,\r\nvoid *vaddr)\r\n{\r\nWARN_ON(!dmabuf);\r\nif (dmabuf->ops->kunmap)\r\ndmabuf->ops->kunmap(dmabuf, page_num, vaddr);\r\n}\r\nint dma_buf_mmap(struct dma_buf *dmabuf, struct vm_area_struct *vma,\r\nunsigned long pgoff)\r\n{\r\nstruct file *oldfile;\r\nint ret;\r\nif (WARN_ON(!dmabuf || !vma))\r\nreturn -EINVAL;\r\nif (pgoff + ((vma->vm_end - vma->vm_start) >> PAGE_SHIFT) < pgoff)\r\nreturn -EOVERFLOW;\r\nif (pgoff + ((vma->vm_end - vma->vm_start) >> PAGE_SHIFT) >\r\ndmabuf->size >> PAGE_SHIFT)\r\nreturn -EINVAL;\r\nget_file(dmabuf->file);\r\noldfile = vma->vm_file;\r\nvma->vm_file = dmabuf->file;\r\nvma->vm_pgoff = pgoff;\r\nret = dmabuf->ops->mmap(dmabuf, vma);\r\nif (ret) {\r\nvma->vm_file = oldfile;\r\nfput(dmabuf->file);\r\n} else {\r\nif (oldfile)\r\nfput(oldfile);\r\n}\r\nreturn ret;\r\n}\r\nvoid *dma_buf_vmap(struct dma_buf *dmabuf)\r\n{\r\nvoid *ptr;\r\nif (WARN_ON(!dmabuf))\r\nreturn NULL;\r\nif (!dmabuf->ops->vmap)\r\nreturn NULL;\r\nmutex_lock(&dmabuf->lock);\r\nif (dmabuf->vmapping_counter) {\r\ndmabuf->vmapping_counter++;\r\nBUG_ON(!dmabuf->vmap_ptr);\r\nptr = dmabuf->vmap_ptr;\r\ngoto out_unlock;\r\n}\r\nBUG_ON(dmabuf->vmap_ptr);\r\nptr = dmabuf->ops->vmap(dmabuf);\r\nif (WARN_ON_ONCE(IS_ERR(ptr)))\r\nptr = NULL;\r\nif (!ptr)\r\ngoto out_unlock;\r\ndmabuf->vmap_ptr = ptr;\r\ndmabuf->vmapping_counter = 1;\r\nout_unlock:\r\nmutex_unlock(&dmabuf->lock);\r\nreturn ptr;\r\n}\r\nvoid dma_buf_vunmap(struct dma_buf *dmabuf, void *vaddr)\r\n{\r\nif (WARN_ON(!dmabuf))\r\nreturn;\r\nBUG_ON(!dmabuf->vmap_ptr);\r\nBUG_ON(dmabuf->vmapping_counter == 0);\r\nBUG_ON(dmabuf->vmap_ptr != vaddr);\r\nmutex_lock(&dmabuf->lock);\r\nif (--dmabuf->vmapping_counter == 0) {\r\nif (dmabuf->ops->vunmap)\r\ndmabuf->ops->vunmap(dmabuf, vaddr);\r\ndmabuf->vmap_ptr = NULL;\r\n}\r\nmutex_unlock(&dmabuf->lock);\r\n}\r\nstatic int dma_buf_describe(struct seq_file *s)\r\n{\r\nint ret;\r\nstruct dma_buf *buf_obj;\r\nstruct dma_buf_attachment *attach_obj;\r\nint count = 0, attach_count;\r\nsize_t size = 0;\r\nret = mutex_lock_interruptible(&db_list.lock);\r\nif (ret)\r\nreturn ret;\r\nseq_puts(s, "\nDma-buf Objects:\n");\r\nseq_puts(s, "size\tflags\tmode\tcount\texp_name\n");\r\nlist_for_each_entry(buf_obj, &db_list.head, list_node) {\r\nret = mutex_lock_interruptible(&buf_obj->lock);\r\nif (ret) {\r\nseq_puts(s,\r\n"\tERROR locking buffer object: skipping\n");\r\ncontinue;\r\n}\r\nseq_printf(s, "%08zu\t%08x\t%08x\t%08ld\t%s\n",\r\nbuf_obj->size,\r\nbuf_obj->file->f_flags, buf_obj->file->f_mode,\r\nfile_count(buf_obj->file),\r\nbuf_obj->exp_name);\r\nseq_puts(s, "\tAttached Devices:\n");\r\nattach_count = 0;\r\nlist_for_each_entry(attach_obj, &buf_obj->attachments, node) {\r\nseq_puts(s, "\t");\r\nseq_printf(s, "%s\n", dev_name(attach_obj->dev));\r\nattach_count++;\r\n}\r\nseq_printf(s, "Total %d devices attached\n\n",\r\nattach_count);\r\ncount++;\r\nsize += buf_obj->size;\r\nmutex_unlock(&buf_obj->lock);\r\n}\r\nseq_printf(s, "\nTotal %d objects, %zu bytes\n", count, size);\r\nmutex_unlock(&db_list.lock);\r\nreturn 0;\r\n}\r\nstatic int dma_buf_show(struct seq_file *s, void *unused)\r\n{\r\nvoid (*func)(struct seq_file *) = s->private;\r\nfunc(s);\r\nreturn 0;\r\n}\r\nstatic int dma_buf_debug_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, dma_buf_show, inode->i_private);\r\n}\r\nstatic int dma_buf_init_debugfs(void)\r\n{\r\nint err = 0;\r\ndma_buf_debugfs_dir = debugfs_create_dir("dma_buf", NULL);\r\nif (IS_ERR(dma_buf_debugfs_dir)) {\r\nerr = PTR_ERR(dma_buf_debugfs_dir);\r\ndma_buf_debugfs_dir = NULL;\r\nreturn err;\r\n}\r\nerr = dma_buf_debugfs_create_file("bufinfo", dma_buf_describe);\r\nif (err)\r\npr_debug("dma_buf: debugfs: failed to create node bufinfo\n");\r\nreturn err;\r\n}\r\nstatic void dma_buf_uninit_debugfs(void)\r\n{\r\nif (dma_buf_debugfs_dir)\r\ndebugfs_remove_recursive(dma_buf_debugfs_dir);\r\n}\r\nint dma_buf_debugfs_create_file(const char *name,\r\nint (*write)(struct seq_file *))\r\n{\r\nstruct dentry *d;\r\nd = debugfs_create_file(name, S_IRUGO, dma_buf_debugfs_dir,\r\nwrite, &dma_buf_debug_fops);\r\nreturn PTR_ERR_OR_ZERO(d);\r\n}\r\nstatic inline int dma_buf_init_debugfs(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic inline void dma_buf_uninit_debugfs(void)\r\n{\r\n}\r\nstatic int __init dma_buf_init(void)\r\n{\r\nmutex_init(&db_list.lock);\r\nINIT_LIST_HEAD(&db_list.head);\r\ndma_buf_init_debugfs();\r\nreturn 0;\r\n}\r\nstatic void __exit dma_buf_deinit(void)\r\n{\r\ndma_buf_uninit_debugfs();\r\n}
