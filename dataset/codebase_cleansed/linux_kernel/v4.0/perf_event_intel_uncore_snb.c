static void snb_uncore_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nif (hwc->idx < UNCORE_PMC_IDX_FIXED)\r\nwrmsrl(hwc->config_base, hwc->config | SNB_UNC_CTL_EN);\r\nelse\r\nwrmsrl(hwc->config_base, SNB_UNC_CTL_EN);\r\n}\r\nstatic void snb_uncore_msr_disable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nwrmsrl(event->hw.config_base, 0);\r\n}\r\nstatic void snb_uncore_msr_init_box(struct intel_uncore_box *box)\r\n{\r\nif (box->pmu->pmu_idx == 0) {\r\nwrmsrl(SNB_UNC_PERF_GLOBAL_CTL,\r\nSNB_UNC_GLOBAL_CTL_EN | SNB_UNC_GLOBAL_CTL_CORE_ALL);\r\n}\r\n}\r\nvoid snb_uncore_cpu_init(void)\r\n{\r\nuncore_msr_uncores = snb_msr_uncores;\r\nif (snb_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\r\nsnb_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\r\n}\r\nstatic void snb_uncore_imc_init_box(struct intel_uncore_box *box)\r\n{\r\nstruct pci_dev *pdev = box->pci_dev;\r\nint where = SNB_UNCORE_PCI_IMC_BAR_OFFSET;\r\nresource_size_t addr;\r\nu32 pci_dword;\r\npci_read_config_dword(pdev, where, &pci_dword);\r\naddr = pci_dword;\r\n#ifdef CONFIG_PHYS_ADDR_T_64BIT\r\npci_read_config_dword(pdev, where + 4, &pci_dword);\r\naddr |= ((resource_size_t)pci_dword << 32);\r\n#endif\r\naddr &= ~(PAGE_SIZE - 1);\r\nbox->io_addr = ioremap(addr, SNB_UNCORE_PCI_IMC_MAP_SIZE);\r\nbox->hrtimer_duration = UNCORE_SNB_IMC_HRTIMER_INTERVAL;\r\n}\r\nstatic void snb_uncore_imc_enable_box(struct intel_uncore_box *box)\r\n{}\r\nstatic void snb_uncore_imc_disable_box(struct intel_uncore_box *box)\r\n{}\r\nstatic void snb_uncore_imc_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{}\r\nstatic void snb_uncore_imc_disable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{}\r\nstatic u64 snb_uncore_imc_read_counter(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nreturn (u64)*(unsigned int *)(box->io_addr + hwc->event_base);\r\n}\r\nstatic int snb_uncore_imc_event_init(struct perf_event *event)\r\n{\r\nstruct intel_uncore_pmu *pmu;\r\nstruct intel_uncore_box *box;\r\nstruct hw_perf_event *hwc = &event->hw;\r\nu64 cfg = event->attr.config & SNB_UNCORE_PCI_IMC_EVENT_MASK;\r\nint idx, base;\r\nif (event->attr.type != event->pmu->type)\r\nreturn -ENOENT;\r\npmu = uncore_event_to_pmu(event);\r\nif (pmu->func_id < 0)\r\nreturn -ENOENT;\r\nif (hwc->sample_period)\r\nreturn -EINVAL;\r\nif (event->attr.exclude_user ||\r\nevent->attr.exclude_kernel ||\r\nevent->attr.exclude_hv ||\r\nevent->attr.exclude_idle ||\r\nevent->attr.exclude_host ||\r\nevent->attr.exclude_guest ||\r\nevent->attr.sample_period)\r\nreturn -EINVAL;\r\nif (event->cpu < 0)\r\nreturn -EINVAL;\r\nif (event->attr.config & ~SNB_UNCORE_PCI_IMC_EVENT_MASK)\r\nreturn -EINVAL;\r\nbox = uncore_pmu_to_box(pmu, event->cpu);\r\nif (!box || box->cpu < 0)\r\nreturn -EINVAL;\r\nevent->cpu = box->cpu;\r\nevent->hw.idx = -1;\r\nevent->hw.last_tag = ~0ULL;\r\nevent->hw.extra_reg.idx = EXTRA_REG_NONE;\r\nevent->hw.branch_reg.idx = EXTRA_REG_NONE;\r\nswitch (cfg) {\r\ncase SNB_UNCORE_PCI_IMC_DATA_READS:\r\nbase = SNB_UNCORE_PCI_IMC_DATA_READS_BASE;\r\nidx = UNCORE_PMC_IDX_FIXED;\r\nbreak;\r\ncase SNB_UNCORE_PCI_IMC_DATA_WRITES:\r\nbase = SNB_UNCORE_PCI_IMC_DATA_WRITES_BASE;\r\nidx = UNCORE_PMC_IDX_FIXED + 1;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nevent->hw.event_base = base;\r\nevent->hw.config = cfg;\r\nevent->hw.idx = idx;\r\nreturn 0;\r\n}\r\nstatic int snb_uncore_imc_hw_config(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nreturn 0;\r\n}\r\nstatic void snb_uncore_imc_event_start(struct perf_event *event, int flags)\r\n{\r\nstruct intel_uncore_box *box = uncore_event_to_box(event);\r\nu64 count;\r\nif (WARN_ON_ONCE(!(event->hw.state & PERF_HES_STOPPED)))\r\nreturn;\r\nevent->hw.state = 0;\r\nbox->n_active++;\r\nlist_add_tail(&event->active_entry, &box->active_list);\r\ncount = snb_uncore_imc_read_counter(box, event);\r\nlocal64_set(&event->hw.prev_count, count);\r\nif (box->n_active == 1)\r\nuncore_pmu_start_hrtimer(box);\r\n}\r\nstatic void snb_uncore_imc_event_stop(struct perf_event *event, int flags)\r\n{\r\nstruct intel_uncore_box *box = uncore_event_to_box(event);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nif (!(hwc->state & PERF_HES_STOPPED)) {\r\nbox->n_active--;\r\nWARN_ON_ONCE(hwc->state & PERF_HES_STOPPED);\r\nhwc->state |= PERF_HES_STOPPED;\r\nlist_del(&event->active_entry);\r\nif (box->n_active == 0)\r\nuncore_pmu_cancel_hrtimer(box);\r\n}\r\nif ((flags & PERF_EF_UPDATE) && !(hwc->state & PERF_HES_UPTODATE)) {\r\nuncore_perf_event_update(box, event);\r\nhwc->state |= PERF_HES_UPTODATE;\r\n}\r\n}\r\nstatic int snb_uncore_imc_event_add(struct perf_event *event, int flags)\r\n{\r\nstruct intel_uncore_box *box = uncore_event_to_box(event);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nif (!box)\r\nreturn -ENODEV;\r\nhwc->state = PERF_HES_UPTODATE | PERF_HES_STOPPED;\r\nif (!(flags & PERF_EF_START))\r\nhwc->state |= PERF_HES_ARCH;\r\nsnb_uncore_imc_event_start(event, 0);\r\nbox->n_events++;\r\nreturn 0;\r\n}\r\nstatic void snb_uncore_imc_event_del(struct perf_event *event, int flags)\r\n{\r\nstruct intel_uncore_box *box = uncore_event_to_box(event);\r\nint i;\r\nsnb_uncore_imc_event_stop(event, PERF_EF_UPDATE);\r\nfor (i = 0; i < box->n_events; i++) {\r\nif (event == box->event_list[i]) {\r\n--box->n_events;\r\nbreak;\r\n}\r\n}\r\n}\r\nstatic int snb_pci2phy_map_init(int devid)\r\n{\r\nstruct pci_dev *dev = NULL;\r\nint bus;\r\ndev = pci_get_device(PCI_VENDOR_ID_INTEL, devid, dev);\r\nif (!dev)\r\nreturn -ENOTTY;\r\nbus = dev->bus->number;\r\nuncore_pcibus_to_physid[bus] = 0;\r\npci_dev_put(dev);\r\nreturn 0;\r\n}\r\nstatic struct pci_driver *imc_uncore_find_dev(void)\r\n{\r\nconst struct imc_uncore_pci_dev *p;\r\nint ret;\r\nfor_each_imc_pci_id(p, desktop_imc_pci_ids) {\r\nret = snb_pci2phy_map_init(p->pci_id);\r\nif (ret == 0)\r\nreturn p->driver;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int imc_uncore_pci_init(void)\r\n{\r\nstruct pci_driver *imc_drv = imc_uncore_find_dev();\r\nif (!imc_drv)\r\nreturn -ENODEV;\r\nuncore_pci_uncores = snb_pci_uncores;\r\nuncore_pci_driver = imc_drv;\r\nreturn 0;\r\n}\r\nint snb_uncore_pci_init(void)\r\n{\r\nreturn imc_uncore_pci_init();\r\n}\r\nint ivb_uncore_pci_init(void)\r\n{\r\nreturn imc_uncore_pci_init();\r\n}\r\nint hsw_uncore_pci_init(void)\r\n{\r\nreturn imc_uncore_pci_init();\r\n}\r\nstatic void nhm_uncore_msr_disable_box(struct intel_uncore_box *box)\r\n{\r\nwrmsrl(NHM_UNC_PERF_GLOBAL_CTL, 0);\r\n}\r\nstatic void nhm_uncore_msr_enable_box(struct intel_uncore_box *box)\r\n{\r\nwrmsrl(NHM_UNC_PERF_GLOBAL_CTL, NHM_UNC_GLOBAL_CTL_EN_PC_ALL | NHM_UNC_GLOBAL_CTL_EN_FC);\r\n}\r\nstatic void nhm_uncore_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nif (hwc->idx < UNCORE_PMC_IDX_FIXED)\r\nwrmsrl(hwc->config_base, hwc->config | SNB_UNC_CTL_EN);\r\nelse\r\nwrmsrl(hwc->config_base, NHM_UNC_FIXED_CTR_CTL_EN);\r\n}\r\nvoid nhm_uncore_cpu_init(void)\r\n{\r\nuncore_msr_uncores = nhm_msr_uncores;\r\n}
