static void do_set_multicast(struct work_struct *w)\r\n{\r\nstruct net_device_context *ndevctx =\r\ncontainer_of(w, struct net_device_context, work);\r\nstruct netvsc_device *nvdev;\r\nstruct rndis_device *rdev;\r\nnvdev = hv_get_drvdata(ndevctx->device_ctx);\r\nif (nvdev == NULL || nvdev->ndev == NULL)\r\nreturn;\r\nrdev = nvdev->extension;\r\nif (rdev == NULL)\r\nreturn;\r\nif (nvdev->ndev->flags & IFF_PROMISC)\r\nrndis_filter_set_packet_filter(rdev,\r\nNDIS_PACKET_TYPE_PROMISCUOUS);\r\nelse\r\nrndis_filter_set_packet_filter(rdev,\r\nNDIS_PACKET_TYPE_BROADCAST |\r\nNDIS_PACKET_TYPE_ALL_MULTICAST |\r\nNDIS_PACKET_TYPE_DIRECTED);\r\n}\r\nstatic void netvsc_set_multicast_list(struct net_device *net)\r\n{\r\nstruct net_device_context *net_device_ctx = netdev_priv(net);\r\nschedule_work(&net_device_ctx->work);\r\n}\r\nstatic int netvsc_open(struct net_device *net)\r\n{\r\nstruct net_device_context *net_device_ctx = netdev_priv(net);\r\nstruct hv_device *device_obj = net_device_ctx->device_ctx;\r\nstruct netvsc_device *nvdev;\r\nstruct rndis_device *rdev;\r\nint ret = 0;\r\nnetif_carrier_off(net);\r\nret = rndis_filter_open(device_obj);\r\nif (ret != 0) {\r\nnetdev_err(net, "unable to open device (ret %d).\n", ret);\r\nreturn ret;\r\n}\r\nnetif_tx_start_all_queues(net);\r\nnvdev = hv_get_drvdata(device_obj);\r\nrdev = nvdev->extension;\r\nif (!rdev->link_state)\r\nnetif_carrier_on(net);\r\nreturn ret;\r\n}\r\nstatic int netvsc_close(struct net_device *net)\r\n{\r\nstruct net_device_context *net_device_ctx = netdev_priv(net);\r\nstruct hv_device *device_obj = net_device_ctx->device_ctx;\r\nint ret;\r\nnetif_tx_disable(net);\r\ncancel_work_sync(&net_device_ctx->work);\r\nret = rndis_filter_close(device_obj);\r\nif (ret != 0)\r\nnetdev_err(net, "unable to close device (ret %d).\n", ret);\r\nreturn ret;\r\n}\r\nstatic void *init_ppi_data(struct rndis_message *msg, u32 ppi_size,\r\nint pkt_type)\r\n{\r\nstruct rndis_packet *rndis_pkt;\r\nstruct rndis_per_packet_info *ppi;\r\nrndis_pkt = &msg->msg.pkt;\r\nrndis_pkt->data_offset += ppi_size;\r\nppi = (struct rndis_per_packet_info *)((void *)rndis_pkt +\r\nrndis_pkt->per_pkt_info_offset + rndis_pkt->per_pkt_info_len);\r\nppi->size = ppi_size;\r\nppi->type = pkt_type;\r\nppi->ppi_offset = sizeof(struct rndis_per_packet_info);\r\nrndis_pkt->per_pkt_info_len += ppi_size;\r\nreturn ppi;\r\n}\r\nstatic u32 comp_hash(u8 *key, int klen, void *data, int dlen)\r\n{\r\nunion sub_key subk;\r\nint k_next = 4;\r\nu8 dt;\r\nint i, j;\r\nu32 ret = 0;\r\nsubk.k = 0;\r\nsubk.ka = ntohl(*(u32 *)key);\r\nfor (i = 0; i < dlen; i++) {\r\nsubk.kb = key[k_next];\r\nk_next = (k_next + 1) % klen;\r\ndt = ((u8 *)data)[i];\r\nfor (j = 0; j < 8; j++) {\r\nif (dt & 0x80)\r\nret ^= subk.ka;\r\ndt <<= 1;\r\nsubk.k <<= 1;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic bool netvsc_set_hash(u32 *hash, struct sk_buff *skb)\r\n{\r\nstruct flow_keys flow;\r\nint data_len;\r\nif (!skb_flow_dissect(skb, &flow) ||\r\n!(flow.n_proto == htons(ETH_P_IP) ||\r\nflow.n_proto == htons(ETH_P_IPV6)))\r\nreturn false;\r\nif (flow.ip_proto == IPPROTO_TCP)\r\ndata_len = 12;\r\nelse\r\ndata_len = 8;\r\n*hash = comp_hash(netvsc_hash_key, HASH_KEYLEN, &flow, data_len);\r\nreturn true;\r\n}\r\nstatic u16 netvsc_select_queue(struct net_device *ndev, struct sk_buff *skb,\r\nvoid *accel_priv, select_queue_fallback_t fallback)\r\n{\r\nstruct net_device_context *net_device_ctx = netdev_priv(ndev);\r\nstruct hv_device *hdev = net_device_ctx->device_ctx;\r\nstruct netvsc_device *nvsc_dev = hv_get_drvdata(hdev);\r\nu32 hash;\r\nu16 q_idx = 0;\r\nif (nvsc_dev == NULL || ndev->real_num_tx_queues <= 1)\r\nreturn 0;\r\nif (netvsc_set_hash(&hash, skb)) {\r\nq_idx = nvsc_dev->send_table[hash % VRSS_SEND_TAB_SIZE] %\r\nndev->real_num_tx_queues;\r\nskb_set_hash(skb, hash, PKT_HASH_TYPE_L3);\r\n}\r\nreturn q_idx;\r\n}\r\nstatic void netvsc_xmit_completion(void *context)\r\n{\r\nstruct hv_netvsc_packet *packet = (struct hv_netvsc_packet *)context;\r\nstruct sk_buff *skb = (struct sk_buff *)\r\n(unsigned long)packet->send_completion_tid;\r\nu32 index = packet->send_buf_index;\r\nkfree(packet);\r\nif (skb && (index == NETVSC_INVALID_INDEX))\r\ndev_kfree_skb_any(skb);\r\n}\r\nstatic u32 fill_pg_buf(struct page *page, u32 offset, u32 len,\r\nstruct hv_page_buffer *pb)\r\n{\r\nint j = 0;\r\npage += (offset >> PAGE_SHIFT);\r\noffset &= ~PAGE_MASK;\r\nwhile (len > 0) {\r\nunsigned long bytes;\r\nbytes = PAGE_SIZE - offset;\r\nif (bytes > len)\r\nbytes = len;\r\npb[j].pfn = page_to_pfn(page);\r\npb[j].offset = offset;\r\npb[j].len = bytes;\r\noffset += bytes;\r\nlen -= bytes;\r\nif (offset == PAGE_SIZE && len) {\r\npage++;\r\noffset = 0;\r\nj++;\r\n}\r\n}\r\nreturn j + 1;\r\n}\r\nstatic u32 init_page_array(void *hdr, u32 len, struct sk_buff *skb,\r\nstruct hv_page_buffer *pb)\r\n{\r\nu32 slots_used = 0;\r\nchar *data = skb->data;\r\nint frags = skb_shinfo(skb)->nr_frags;\r\nint i;\r\nif (hdr != NULL)\r\nslots_used += fill_pg_buf(virt_to_page(hdr),\r\noffset_in_page(hdr),\r\nlen, &pb[slots_used]);\r\nslots_used += fill_pg_buf(virt_to_page(data),\r\noffset_in_page(data),\r\nskb_headlen(skb), &pb[slots_used]);\r\nfor (i = 0; i < frags; i++) {\r\nskb_frag_t *frag = skb_shinfo(skb)->frags + i;\r\nslots_used += fill_pg_buf(skb_frag_page(frag),\r\nfrag->page_offset,\r\nskb_frag_size(frag), &pb[slots_used]);\r\n}\r\nreturn slots_used;\r\n}\r\nstatic int count_skb_frag_slots(struct sk_buff *skb)\r\n{\r\nint i, frags = skb_shinfo(skb)->nr_frags;\r\nint pages = 0;\r\nfor (i = 0; i < frags; i++) {\r\nskb_frag_t *frag = skb_shinfo(skb)->frags + i;\r\nunsigned long size = skb_frag_size(frag);\r\nunsigned long offset = frag->page_offset;\r\noffset &= ~PAGE_MASK;\r\npages += PFN_UP(offset + size);\r\n}\r\nreturn pages;\r\n}\r\nstatic int netvsc_get_slots(struct sk_buff *skb)\r\n{\r\nchar *data = skb->data;\r\nunsigned int offset = offset_in_page(data);\r\nunsigned int len = skb_headlen(skb);\r\nint slots;\r\nint frag_slots;\r\nslots = DIV_ROUND_UP(offset + len, PAGE_SIZE);\r\nfrag_slots = count_skb_frag_slots(skb);\r\nreturn slots + frag_slots;\r\n}\r\nstatic u32 get_net_transport_info(struct sk_buff *skb, u32 *trans_off)\r\n{\r\nu32 ret_val = TRANSPORT_INFO_NOT_IP;\r\nif ((eth_hdr(skb)->h_proto != htons(ETH_P_IP)) &&\r\n(eth_hdr(skb)->h_proto != htons(ETH_P_IPV6))) {\r\ngoto not_ip;\r\n}\r\n*trans_off = skb_transport_offset(skb);\r\nif ((eth_hdr(skb)->h_proto == htons(ETH_P_IP))) {\r\nstruct iphdr *iphdr = ip_hdr(skb);\r\nif (iphdr->protocol == IPPROTO_TCP)\r\nret_val = TRANSPORT_INFO_IPV4_TCP;\r\nelse if (iphdr->protocol == IPPROTO_UDP)\r\nret_val = TRANSPORT_INFO_IPV4_UDP;\r\n} else {\r\nif (ipv6_hdr(skb)->nexthdr == IPPROTO_TCP)\r\nret_val = TRANSPORT_INFO_IPV6_TCP;\r\nelse if (ipv6_hdr(skb)->nexthdr == IPPROTO_UDP)\r\nret_val = TRANSPORT_INFO_IPV6_UDP;\r\n}\r\nnot_ip:\r\nreturn ret_val;\r\n}\r\nstatic int netvsc_start_xmit(struct sk_buff *skb, struct net_device *net)\r\n{\r\nstruct net_device_context *net_device_ctx = netdev_priv(net);\r\nstruct hv_netvsc_packet *packet;\r\nint ret;\r\nunsigned int num_data_pgs;\r\nstruct rndis_message *rndis_msg;\r\nstruct rndis_packet *rndis_pkt;\r\nu32 rndis_msg_size;\r\nbool isvlan;\r\nstruct rndis_per_packet_info *ppi;\r\nstruct ndis_tcp_ip_checksum_info *csum_info;\r\nstruct ndis_tcp_lso_info *lso_info;\r\nint hdr_offset;\r\nu32 net_trans_info;\r\nu32 hash;\r\nu32 skb_length = skb->len;\r\nnum_data_pgs = netvsc_get_slots(skb) + 2;\r\nif (num_data_pgs > MAX_PAGE_BUFFER_COUNT) {\r\nnetdev_err(net, "Packet too big: %u\n", skb->len);\r\ndev_kfree_skb(skb);\r\nnet->stats.tx_dropped++;\r\nreturn NETDEV_TX_OK;\r\n}\r\npacket = kzalloc(sizeof(struct hv_netvsc_packet) +\r\n(num_data_pgs * sizeof(struct hv_page_buffer)) +\r\nsizeof(struct rndis_message) +\r\nNDIS_VLAN_PPI_SIZE + NDIS_CSUM_PPI_SIZE +\r\nNDIS_LSO_PPI_SIZE + NDIS_HASH_PPI_SIZE, GFP_ATOMIC);\r\nif (!packet) {\r\nnetdev_err(net, "unable to allocate hv_netvsc_packet\n");\r\ndev_kfree_skb(skb);\r\nnet->stats.tx_dropped++;\r\nreturn NETDEV_TX_OK;\r\n}\r\npacket->vlan_tci = skb->vlan_tci;\r\npacket->q_idx = skb_get_queue_mapping(skb);\r\npacket->is_data_pkt = true;\r\npacket->total_data_buflen = skb->len;\r\npacket->rndis_msg = (struct rndis_message *)((unsigned long)packet +\r\nsizeof(struct hv_netvsc_packet) +\r\n(num_data_pgs * sizeof(struct hv_page_buffer)));\r\npacket->send_completion = netvsc_xmit_completion;\r\npacket->send_completion_ctx = packet;\r\npacket->send_completion_tid = (unsigned long)skb;\r\nisvlan = packet->vlan_tci & VLAN_TAG_PRESENT;\r\nrndis_msg = packet->rndis_msg;\r\nrndis_msg->ndis_msg_type = RNDIS_MSG_PACKET;\r\nrndis_msg->msg_len = packet->total_data_buflen;\r\nrndis_pkt = &rndis_msg->msg.pkt;\r\nrndis_pkt->data_offset = sizeof(struct rndis_packet);\r\nrndis_pkt->data_len = packet->total_data_buflen;\r\nrndis_pkt->per_pkt_info_offset = sizeof(struct rndis_packet);\r\nrndis_msg_size = RNDIS_MESSAGE_SIZE(struct rndis_packet);\r\nhash = skb_get_hash_raw(skb);\r\nif (hash != 0 && net->real_num_tx_queues > 1) {\r\nrndis_msg_size += NDIS_HASH_PPI_SIZE;\r\nppi = init_ppi_data(rndis_msg, NDIS_HASH_PPI_SIZE,\r\nNBL_HASH_VALUE);\r\n*(u32 *)((void *)ppi + ppi->ppi_offset) = hash;\r\n}\r\nif (isvlan) {\r\nstruct ndis_pkt_8021q_info *vlan;\r\nrndis_msg_size += NDIS_VLAN_PPI_SIZE;\r\nppi = init_ppi_data(rndis_msg, NDIS_VLAN_PPI_SIZE,\r\nIEEE_8021Q_INFO);\r\nvlan = (struct ndis_pkt_8021q_info *)((void *)ppi +\r\nppi->ppi_offset);\r\nvlan->vlanid = packet->vlan_tci & VLAN_VID_MASK;\r\nvlan->pri = (packet->vlan_tci & VLAN_PRIO_MASK) >>\r\nVLAN_PRIO_SHIFT;\r\n}\r\nnet_trans_info = get_net_transport_info(skb, &hdr_offset);\r\nif (net_trans_info == TRANSPORT_INFO_NOT_IP)\r\ngoto do_send;\r\nif (skb_is_gso(skb))\r\ngoto do_lso;\r\nif ((skb->ip_summed == CHECKSUM_NONE) ||\r\n(skb->ip_summed == CHECKSUM_UNNECESSARY))\r\ngoto do_send;\r\nrndis_msg_size += NDIS_CSUM_PPI_SIZE;\r\nppi = init_ppi_data(rndis_msg, NDIS_CSUM_PPI_SIZE,\r\nTCPIP_CHKSUM_PKTINFO);\r\ncsum_info = (struct ndis_tcp_ip_checksum_info *)((void *)ppi +\r\nppi->ppi_offset);\r\nif (net_trans_info & (INFO_IPV4 << 16))\r\ncsum_info->transmit.is_ipv4 = 1;\r\nelse\r\ncsum_info->transmit.is_ipv6 = 1;\r\nif (net_trans_info & INFO_TCP) {\r\ncsum_info->transmit.tcp_checksum = 1;\r\ncsum_info->transmit.tcp_header_offset = hdr_offset;\r\n} else if (net_trans_info & INFO_UDP) {\r\nstruct udphdr *uh;\r\nu16 udp_len;\r\nret = skb_cow_head(skb, 0);\r\nif (ret)\r\ngoto drop;\r\nuh = udp_hdr(skb);\r\nudp_len = ntohs(uh->len);\r\nuh->check = 0;\r\nuh->check = csum_tcpudp_magic(ip_hdr(skb)->saddr,\r\nip_hdr(skb)->daddr,\r\nudp_len, IPPROTO_UDP,\r\ncsum_partial(uh, udp_len, 0));\r\nif (uh->check == 0)\r\nuh->check = CSUM_MANGLED_0;\r\ncsum_info->transmit.udp_checksum = 0;\r\n}\r\ngoto do_send;\r\ndo_lso:\r\nrndis_msg_size += NDIS_LSO_PPI_SIZE;\r\nppi = init_ppi_data(rndis_msg, NDIS_LSO_PPI_SIZE,\r\nTCP_LARGESEND_PKTINFO);\r\nlso_info = (struct ndis_tcp_lso_info *)((void *)ppi +\r\nppi->ppi_offset);\r\nlso_info->lso_v2_transmit.type = NDIS_TCP_LARGE_SEND_OFFLOAD_V2_TYPE;\r\nif (net_trans_info & (INFO_IPV4 << 16)) {\r\nlso_info->lso_v2_transmit.ip_version =\r\nNDIS_TCP_LARGE_SEND_OFFLOAD_IPV4;\r\nip_hdr(skb)->tot_len = 0;\r\nip_hdr(skb)->check = 0;\r\ntcp_hdr(skb)->check =\r\n~csum_tcpudp_magic(ip_hdr(skb)->saddr,\r\nip_hdr(skb)->daddr, 0, IPPROTO_TCP, 0);\r\n} else {\r\nlso_info->lso_v2_transmit.ip_version =\r\nNDIS_TCP_LARGE_SEND_OFFLOAD_IPV6;\r\nipv6_hdr(skb)->payload_len = 0;\r\ntcp_hdr(skb)->check =\r\n~csum_ipv6_magic(&ipv6_hdr(skb)->saddr,\r\n&ipv6_hdr(skb)->daddr, 0, IPPROTO_TCP, 0);\r\n}\r\nlso_info->lso_v2_transmit.tcp_header_offset = hdr_offset;\r\nlso_info->lso_v2_transmit.mss = skb_shinfo(skb)->gso_size;\r\ndo_send:\r\nrndis_msg->msg_len += rndis_msg_size;\r\npacket->total_data_buflen = rndis_msg->msg_len;\r\npacket->page_buf_cnt = init_page_array(rndis_msg, rndis_msg_size,\r\nskb, &packet->page_buf[0]);\r\nret = netvsc_send(net_device_ctx->device_ctx, packet);\r\ndrop:\r\nif (ret == 0) {\r\nnet->stats.tx_bytes += skb_length;\r\nnet->stats.tx_packets++;\r\n} else {\r\nkfree(packet);\r\nif (ret != -EAGAIN) {\r\ndev_kfree_skb_any(skb);\r\nnet->stats.tx_dropped++;\r\n}\r\n}\r\nreturn (ret == -EAGAIN) ? NETDEV_TX_BUSY : NETDEV_TX_OK;\r\n}\r\nvoid netvsc_linkstatus_callback(struct hv_device *device_obj,\r\nstruct rndis_message *resp)\r\n{\r\nstruct rndis_indicate_status *indicate = &resp->msg.indicate_status;\r\nstruct net_device *net;\r\nstruct net_device_context *ndev_ctx;\r\nstruct netvsc_device *net_device;\r\nstruct rndis_device *rdev;\r\nnet_device = hv_get_drvdata(device_obj);\r\nrdev = net_device->extension;\r\nswitch (indicate->status) {\r\ncase RNDIS_STATUS_MEDIA_CONNECT:\r\nrdev->link_state = false;\r\nbreak;\r\ncase RNDIS_STATUS_MEDIA_DISCONNECT:\r\nrdev->link_state = true;\r\nbreak;\r\ncase RNDIS_STATUS_NETWORK_CHANGE:\r\nrdev->link_change = true;\r\nbreak;\r\ndefault:\r\nreturn;\r\n}\r\nnet = net_device->ndev;\r\nif (!net || net->reg_state != NETREG_REGISTERED)\r\nreturn;\r\nndev_ctx = netdev_priv(net);\r\nif (!rdev->link_state) {\r\nschedule_delayed_work(&ndev_ctx->dwork, 0);\r\nschedule_delayed_work(&ndev_ctx->dwork, msecs_to_jiffies(20));\r\n} else {\r\nschedule_delayed_work(&ndev_ctx->dwork, 0);\r\n}\r\n}\r\nint netvsc_recv_callback(struct hv_device *device_obj,\r\nstruct hv_netvsc_packet *packet,\r\nstruct ndis_tcp_ip_checksum_info *csum_info)\r\n{\r\nstruct net_device *net;\r\nstruct sk_buff *skb;\r\nnet = ((struct netvsc_device *)hv_get_drvdata(device_obj))->ndev;\r\nif (!net || net->reg_state != NETREG_REGISTERED) {\r\npacket->status = NVSP_STAT_FAIL;\r\nreturn 0;\r\n}\r\nskb = netdev_alloc_skb_ip_align(net, packet->total_data_buflen);\r\nif (unlikely(!skb)) {\r\n++net->stats.rx_dropped;\r\npacket->status = NVSP_STAT_FAIL;\r\nreturn 0;\r\n}\r\nmemcpy(skb_put(skb, packet->total_data_buflen), packet->data,\r\npacket->total_data_buflen);\r\nskb->protocol = eth_type_trans(skb, net);\r\nif (csum_info) {\r\nif (csum_info->receive.ip_checksum_succeeded)\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nelse\r\nskb->ip_summed = CHECKSUM_NONE;\r\n}\r\nif (packet->vlan_tci & VLAN_TAG_PRESENT)\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),\r\npacket->vlan_tci);\r\nskb_record_rx_queue(skb, packet->channel->\r\noffermsg.offer.sub_channel_index);\r\nnet->stats.rx_packets++;\r\nnet->stats.rx_bytes += packet->total_data_buflen;\r\nnetif_rx(skb);\r\nreturn 0;\r\n}\r\nstatic void netvsc_get_drvinfo(struct net_device *net,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstrlcpy(info->driver, KBUILD_MODNAME, sizeof(info->driver));\r\nstrlcpy(info->fw_version, "N/A", sizeof(info->fw_version));\r\n}\r\nstatic int netvsc_change_mtu(struct net_device *ndev, int mtu)\r\n{\r\nstruct net_device_context *ndevctx = netdev_priv(ndev);\r\nstruct hv_device *hdev = ndevctx->device_ctx;\r\nstruct netvsc_device *nvdev = hv_get_drvdata(hdev);\r\nstruct netvsc_device_info device_info;\r\nint limit = ETH_DATA_LEN;\r\nif (nvdev == NULL || nvdev->destroy)\r\nreturn -ENODEV;\r\nif (nvdev->nvsp_version >= NVSP_PROTOCOL_VERSION_2)\r\nlimit = NETVSC_MTU - ETH_HLEN;\r\nif (mtu < ETH_DATA_LEN || mtu > limit)\r\nreturn -EINVAL;\r\nnvdev->start_remove = true;\r\ncancel_work_sync(&ndevctx->work);\r\nnetif_tx_disable(ndev);\r\nrndis_filter_device_remove(hdev);\r\nndev->mtu = mtu;\r\nndevctx->device_ctx = hdev;\r\nhv_set_drvdata(hdev, ndev);\r\ndevice_info.ring_size = ring_size;\r\nrndis_filter_device_add(hdev, &device_info);\r\nnetif_tx_wake_all_queues(ndev);\r\nreturn 0;\r\n}\r\nstatic int netvsc_set_mac_addr(struct net_device *ndev, void *p)\r\n{\r\nstruct net_device_context *ndevctx = netdev_priv(ndev);\r\nstruct hv_device *hdev = ndevctx->device_ctx;\r\nstruct sockaddr *addr = p;\r\nchar save_adr[ETH_ALEN];\r\nunsigned char save_aatype;\r\nint err;\r\nmemcpy(save_adr, ndev->dev_addr, ETH_ALEN);\r\nsave_aatype = ndev->addr_assign_type;\r\nerr = eth_mac_addr(ndev, p);\r\nif (err != 0)\r\nreturn err;\r\nerr = rndis_filter_set_device_mac(hdev, addr->sa_data);\r\nif (err != 0) {\r\nmemcpy(ndev->dev_addr, save_adr, ETH_ALEN);\r\nndev->addr_assign_type = save_aatype;\r\n}\r\nreturn err;\r\n}\r\nstatic void netvsc_poll_controller(struct net_device *net)\r\n{\r\n}\r\nstatic void netvsc_link_change(struct work_struct *w)\r\n{\r\nstruct net_device_context *ndev_ctx;\r\nstruct net_device *net;\r\nstruct netvsc_device *net_device;\r\nstruct rndis_device *rdev;\r\nbool notify, refresh = false;\r\nchar *argv[] = { "/etc/init.d/network", "restart", NULL };\r\nchar *envp[] = { "HOME=/", "PATH=/sbin:/usr/sbin:/bin:/usr/bin", NULL };\r\nrtnl_lock();\r\nndev_ctx = container_of(w, struct net_device_context, dwork.work);\r\nnet_device = hv_get_drvdata(ndev_ctx->device_ctx);\r\nrdev = net_device->extension;\r\nnet = net_device->ndev;\r\nif (rdev->link_state) {\r\nnetif_carrier_off(net);\r\nnotify = false;\r\n} else {\r\nnetif_carrier_on(net);\r\nnotify = true;\r\nif (rdev->link_change) {\r\nrdev->link_change = false;\r\nrefresh = true;\r\n}\r\n}\r\nrtnl_unlock();\r\nif (refresh)\r\ncall_usermodehelper(argv[0], argv, envp, UMH_WAIT_EXEC);\r\nif (notify)\r\nnetdev_notify_peers(net);\r\n}\r\nstatic int netvsc_probe(struct hv_device *dev,\r\nconst struct hv_vmbus_device_id *dev_id)\r\n{\r\nstruct net_device *net = NULL;\r\nstruct net_device_context *net_device_ctx;\r\nstruct netvsc_device_info device_info;\r\nstruct netvsc_device *nvdev;\r\nint ret;\r\nnet = alloc_etherdev_mq(sizeof(struct net_device_context),\r\nnum_online_cpus());\r\nif (!net)\r\nreturn -ENOMEM;\r\nnetif_carrier_off(net);\r\nnet_device_ctx = netdev_priv(net);\r\nnet_device_ctx->device_ctx = dev;\r\nhv_set_drvdata(dev, net);\r\nINIT_DELAYED_WORK(&net_device_ctx->dwork, netvsc_link_change);\r\nINIT_WORK(&net_device_ctx->work, do_set_multicast);\r\nnet->netdev_ops = &device_ops;\r\nnet->hw_features = NETIF_F_RXCSUM | NETIF_F_SG | NETIF_F_IP_CSUM |\r\nNETIF_F_TSO;\r\nnet->features = NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_SG | NETIF_F_RXCSUM |\r\nNETIF_F_IP_CSUM | NETIF_F_TSO;\r\nnet->ethtool_ops = &ethtool_ops;\r\nSET_NETDEV_DEV(net, &dev->device);\r\ndevice_info.ring_size = ring_size;\r\nret = rndis_filter_device_add(dev, &device_info);\r\nif (ret != 0) {\r\nnetdev_err(net, "unable to add netvsc device (ret %d)\n", ret);\r\nfree_netdev(net);\r\nhv_set_drvdata(dev, NULL);\r\nreturn ret;\r\n}\r\nmemcpy(net->dev_addr, device_info.mac_adr, ETH_ALEN);\r\nnvdev = hv_get_drvdata(dev);\r\nnetif_set_real_num_tx_queues(net, nvdev->num_chn);\r\nnetif_set_real_num_rx_queues(net, nvdev->num_chn);\r\nret = register_netdev(net);\r\nif (ret != 0) {\r\npr_err("Unable to register netdev.\n");\r\nrndis_filter_device_remove(dev);\r\nfree_netdev(net);\r\n} else {\r\nschedule_delayed_work(&net_device_ctx->dwork, 0);\r\n}\r\nreturn ret;\r\n}\r\nstatic int netvsc_remove(struct hv_device *dev)\r\n{\r\nstruct net_device *net;\r\nstruct net_device_context *ndev_ctx;\r\nstruct netvsc_device *net_device;\r\nnet_device = hv_get_drvdata(dev);\r\nnet = net_device->ndev;\r\nif (net == NULL) {\r\ndev_err(&dev->device, "No net device to remove\n");\r\nreturn 0;\r\n}\r\nnet_device->start_remove = true;\r\nndev_ctx = netdev_priv(net);\r\ncancel_delayed_work_sync(&ndev_ctx->dwork);\r\ncancel_work_sync(&ndev_ctx->work);\r\nnetif_tx_disable(net);\r\nunregister_netdev(net);\r\nrndis_filter_device_remove(dev);\r\nfree_netdev(net);\r\nreturn 0;\r\n}\r\nstatic void __exit netvsc_drv_exit(void)\r\n{\r\nvmbus_driver_unregister(&netvsc_drv);\r\n}\r\nstatic int __init netvsc_drv_init(void)\r\n{\r\nif (ring_size < RING_SIZE_MIN) {\r\nring_size = RING_SIZE_MIN;\r\npr_info("Increased ring_size to %d (min allowed)\n",\r\nring_size);\r\n}\r\nreturn vmbus_driver_register(&netvsc_drv);\r\n}
