static void ib_umad_release_dev(struct kobject *kobj)\r\n{\r\nstruct ib_umad_device *dev =\r\ncontainer_of(kobj, struct ib_umad_device, kobj);\r\nkfree(dev);\r\n}\r\nstatic int hdr_size(struct ib_umad_file *file)\r\n{\r\nreturn file->use_pkey_index ? sizeof (struct ib_user_mad_hdr) :\r\nsizeof (struct ib_user_mad_hdr_old);\r\n}\r\nstatic struct ib_mad_agent *__get_agent(struct ib_umad_file *file, int id)\r\n{\r\nreturn file->agents_dead ? NULL : file->agent[id];\r\n}\r\nstatic int queue_packet(struct ib_umad_file *file,\r\nstruct ib_mad_agent *agent,\r\nstruct ib_umad_packet *packet)\r\n{\r\nint ret = 1;\r\nmutex_lock(&file->mutex);\r\nfor (packet->mad.hdr.id = 0;\r\npacket->mad.hdr.id < IB_UMAD_MAX_AGENTS;\r\npacket->mad.hdr.id++)\r\nif (agent == __get_agent(file, packet->mad.hdr.id)) {\r\nlist_add_tail(&packet->list, &file->recv_list);\r\nwake_up_interruptible(&file->recv_wait);\r\nret = 0;\r\nbreak;\r\n}\r\nmutex_unlock(&file->mutex);\r\nreturn ret;\r\n}\r\nstatic void dequeue_send(struct ib_umad_file *file,\r\nstruct ib_umad_packet *packet)\r\n{\r\nspin_lock_irq(&file->send_lock);\r\nlist_del(&packet->list);\r\nspin_unlock_irq(&file->send_lock);\r\n}\r\nstatic void send_handler(struct ib_mad_agent *agent,\r\nstruct ib_mad_send_wc *send_wc)\r\n{\r\nstruct ib_umad_file *file = agent->context;\r\nstruct ib_umad_packet *packet = send_wc->send_buf->context[0];\r\ndequeue_send(file, packet);\r\nib_destroy_ah(packet->msg->ah);\r\nib_free_send_mad(packet->msg);\r\nif (send_wc->status == IB_WC_RESP_TIMEOUT_ERR) {\r\npacket->length = IB_MGMT_MAD_HDR;\r\npacket->mad.hdr.status = ETIMEDOUT;\r\nif (!queue_packet(file, agent, packet))\r\nreturn;\r\n}\r\nkfree(packet);\r\n}\r\nstatic void recv_handler(struct ib_mad_agent *agent,\r\nstruct ib_mad_recv_wc *mad_recv_wc)\r\n{\r\nstruct ib_umad_file *file = agent->context;\r\nstruct ib_umad_packet *packet;\r\nif (mad_recv_wc->wc->status != IB_WC_SUCCESS)\r\ngoto err1;\r\npacket = kzalloc(sizeof *packet, GFP_KERNEL);\r\nif (!packet)\r\ngoto err1;\r\npacket->length = mad_recv_wc->mad_len;\r\npacket->recv_wc = mad_recv_wc;\r\npacket->mad.hdr.status = 0;\r\npacket->mad.hdr.length = hdr_size(file) + mad_recv_wc->mad_len;\r\npacket->mad.hdr.qpn = cpu_to_be32(mad_recv_wc->wc->src_qp);\r\npacket->mad.hdr.lid = cpu_to_be16(mad_recv_wc->wc->slid);\r\npacket->mad.hdr.sl = mad_recv_wc->wc->sl;\r\npacket->mad.hdr.path_bits = mad_recv_wc->wc->dlid_path_bits;\r\npacket->mad.hdr.pkey_index = mad_recv_wc->wc->pkey_index;\r\npacket->mad.hdr.grh_present = !!(mad_recv_wc->wc->wc_flags & IB_WC_GRH);\r\nif (packet->mad.hdr.grh_present) {\r\nstruct ib_ah_attr ah_attr;\r\nib_init_ah_from_wc(agent->device, agent->port_num,\r\nmad_recv_wc->wc, mad_recv_wc->recv_buf.grh,\r\n&ah_attr);\r\npacket->mad.hdr.gid_index = ah_attr.grh.sgid_index;\r\npacket->mad.hdr.hop_limit = ah_attr.grh.hop_limit;\r\npacket->mad.hdr.traffic_class = ah_attr.grh.traffic_class;\r\nmemcpy(packet->mad.hdr.gid, &ah_attr.grh.dgid, 16);\r\npacket->mad.hdr.flow_label = cpu_to_be32(ah_attr.grh.flow_label);\r\n}\r\nif (queue_packet(file, agent, packet))\r\ngoto err2;\r\nreturn;\r\nerr2:\r\nkfree(packet);\r\nerr1:\r\nib_free_recv_mad(mad_recv_wc);\r\n}\r\nstatic ssize_t copy_recv_mad(struct ib_umad_file *file, char __user *buf,\r\nstruct ib_umad_packet *packet, size_t count)\r\n{\r\nstruct ib_mad_recv_buf *recv_buf;\r\nint left, seg_payload, offset, max_seg_payload;\r\nrecv_buf = &packet->recv_wc->recv_buf;\r\nif ((packet->length <= sizeof (*recv_buf->mad) &&\r\ncount < hdr_size(file) + packet->length) ||\r\n(packet->length > sizeof (*recv_buf->mad) &&\r\ncount < hdr_size(file) + sizeof (*recv_buf->mad)))\r\nreturn -EINVAL;\r\nif (copy_to_user(buf, &packet->mad, hdr_size(file)))\r\nreturn -EFAULT;\r\nbuf += hdr_size(file);\r\nseg_payload = min_t(int, packet->length, sizeof (*recv_buf->mad));\r\nif (copy_to_user(buf, recv_buf->mad, seg_payload))\r\nreturn -EFAULT;\r\nif (seg_payload < packet->length) {\r\nif (count < hdr_size(file) + packet->length) {\r\nreturn -ENOSPC;\r\n}\r\noffset = ib_get_mad_data_offset(recv_buf->mad->mad_hdr.mgmt_class);\r\nmax_seg_payload = sizeof (struct ib_mad) - offset;\r\nfor (left = packet->length - seg_payload, buf += seg_payload;\r\nleft; left -= seg_payload, buf += seg_payload) {\r\nrecv_buf = container_of(recv_buf->list.next,\r\nstruct ib_mad_recv_buf, list);\r\nseg_payload = min(left, max_seg_payload);\r\nif (copy_to_user(buf, ((void *) recv_buf->mad) + offset,\r\nseg_payload))\r\nreturn -EFAULT;\r\n}\r\n}\r\nreturn hdr_size(file) + packet->length;\r\n}\r\nstatic ssize_t copy_send_mad(struct ib_umad_file *file, char __user *buf,\r\nstruct ib_umad_packet *packet, size_t count)\r\n{\r\nssize_t size = hdr_size(file) + packet->length;\r\nif (count < size)\r\nreturn -EINVAL;\r\nif (copy_to_user(buf, &packet->mad, hdr_size(file)))\r\nreturn -EFAULT;\r\nbuf += hdr_size(file);\r\nif (copy_to_user(buf, packet->mad.data, packet->length))\r\nreturn -EFAULT;\r\nreturn size;\r\n}\r\nstatic ssize_t ib_umad_read(struct file *filp, char __user *buf,\r\nsize_t count, loff_t *pos)\r\n{\r\nstruct ib_umad_file *file = filp->private_data;\r\nstruct ib_umad_packet *packet;\r\nssize_t ret;\r\nif (count < hdr_size(file))\r\nreturn -EINVAL;\r\nmutex_lock(&file->mutex);\r\nwhile (list_empty(&file->recv_list)) {\r\nmutex_unlock(&file->mutex);\r\nif (filp->f_flags & O_NONBLOCK)\r\nreturn -EAGAIN;\r\nif (wait_event_interruptible(file->recv_wait,\r\n!list_empty(&file->recv_list)))\r\nreturn -ERESTARTSYS;\r\nmutex_lock(&file->mutex);\r\n}\r\npacket = list_entry(file->recv_list.next, struct ib_umad_packet, list);\r\nlist_del(&packet->list);\r\nmutex_unlock(&file->mutex);\r\nif (packet->recv_wc)\r\nret = copy_recv_mad(file, buf, packet, count);\r\nelse\r\nret = copy_send_mad(file, buf, packet, count);\r\nif (ret < 0) {\r\nmutex_lock(&file->mutex);\r\nlist_add(&packet->list, &file->recv_list);\r\nmutex_unlock(&file->mutex);\r\n} else {\r\nif (packet->recv_wc)\r\nib_free_recv_mad(packet->recv_wc);\r\nkfree(packet);\r\n}\r\nreturn ret;\r\n}\r\nstatic int copy_rmpp_mad(struct ib_mad_send_buf *msg, const char __user *buf)\r\n{\r\nint left, seg;\r\nif ((msg->hdr_len > IB_MGMT_RMPP_HDR) &&\r\ncopy_from_user(msg->mad + IB_MGMT_RMPP_HDR, buf + IB_MGMT_RMPP_HDR,\r\nmsg->hdr_len - IB_MGMT_RMPP_HDR))\r\nreturn -EFAULT;\r\nfor (seg = 1, left = msg->data_len, buf += msg->hdr_len; left > 0;\r\nseg++, left -= msg->seg_size, buf += msg->seg_size) {\r\nif (copy_from_user(ib_get_rmpp_segment(msg, seg), buf,\r\nmin(left, msg->seg_size)))\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int same_destination(struct ib_user_mad_hdr *hdr1,\r\nstruct ib_user_mad_hdr *hdr2)\r\n{\r\nif (!hdr1->grh_present && !hdr2->grh_present)\r\nreturn (hdr1->lid == hdr2->lid);\r\nif (hdr1->grh_present && hdr2->grh_present)\r\nreturn !memcmp(hdr1->gid, hdr2->gid, 16);\r\nreturn 0;\r\n}\r\nstatic int is_duplicate(struct ib_umad_file *file,\r\nstruct ib_umad_packet *packet)\r\n{\r\nstruct ib_umad_packet *sent_packet;\r\nstruct ib_mad_hdr *sent_hdr, *hdr;\r\nhdr = (struct ib_mad_hdr *) packet->mad.data;\r\nlist_for_each_entry(sent_packet, &file->send_list, list) {\r\nsent_hdr = (struct ib_mad_hdr *) sent_packet->mad.data;\r\nif ((hdr->tid != sent_hdr->tid) ||\r\n(hdr->mgmt_class != sent_hdr->mgmt_class))\r\ncontinue;\r\nif (!ib_response_mad((struct ib_mad *) hdr)) {\r\nif (!ib_response_mad((struct ib_mad *) sent_hdr))\r\nreturn 1;\r\ncontinue;\r\n} else if (!ib_response_mad((struct ib_mad *) sent_hdr))\r\ncontinue;\r\nif (same_destination(&packet->mad.hdr, &sent_packet->mad.hdr))\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic ssize_t ib_umad_write(struct file *filp, const char __user *buf,\r\nsize_t count, loff_t *pos)\r\n{\r\nstruct ib_umad_file *file = filp->private_data;\r\nstruct ib_umad_packet *packet;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_ah_attr ah_attr;\r\nstruct ib_ah *ah;\r\nstruct ib_rmpp_mad *rmpp_mad;\r\n__be64 *tid;\r\nint ret, data_len, hdr_len, copy_offset, rmpp_active;\r\nif (count < hdr_size(file) + IB_MGMT_RMPP_HDR)\r\nreturn -EINVAL;\r\npacket = kzalloc(sizeof *packet + IB_MGMT_RMPP_HDR, GFP_KERNEL);\r\nif (!packet)\r\nreturn -ENOMEM;\r\nif (copy_from_user(&packet->mad, buf, hdr_size(file))) {\r\nret = -EFAULT;\r\ngoto err;\r\n}\r\nif (packet->mad.hdr.id >= IB_UMAD_MAX_AGENTS) {\r\nret = -EINVAL;\r\ngoto err;\r\n}\r\nbuf += hdr_size(file);\r\nif (copy_from_user(packet->mad.data, buf, IB_MGMT_RMPP_HDR)) {\r\nret = -EFAULT;\r\ngoto err;\r\n}\r\nmutex_lock(&file->mutex);\r\nagent = __get_agent(file, packet->mad.hdr.id);\r\nif (!agent) {\r\nret = -EINVAL;\r\ngoto err_up;\r\n}\r\nmemset(&ah_attr, 0, sizeof ah_attr);\r\nah_attr.dlid = be16_to_cpu(packet->mad.hdr.lid);\r\nah_attr.sl = packet->mad.hdr.sl;\r\nah_attr.src_path_bits = packet->mad.hdr.path_bits;\r\nah_attr.port_num = file->port->port_num;\r\nif (packet->mad.hdr.grh_present) {\r\nah_attr.ah_flags = IB_AH_GRH;\r\nmemcpy(ah_attr.grh.dgid.raw, packet->mad.hdr.gid, 16);\r\nah_attr.grh.sgid_index = packet->mad.hdr.gid_index;\r\nah_attr.grh.flow_label = be32_to_cpu(packet->mad.hdr.flow_label);\r\nah_attr.grh.hop_limit = packet->mad.hdr.hop_limit;\r\nah_attr.grh.traffic_class = packet->mad.hdr.traffic_class;\r\n}\r\nah = ib_create_ah(agent->qp->pd, &ah_attr);\r\nif (IS_ERR(ah)) {\r\nret = PTR_ERR(ah);\r\ngoto err_up;\r\n}\r\nrmpp_mad = (struct ib_rmpp_mad *) packet->mad.data;\r\nhdr_len = ib_get_mad_data_offset(rmpp_mad->mad_hdr.mgmt_class);\r\nif (ib_is_mad_class_rmpp(rmpp_mad->mad_hdr.mgmt_class)\r\n&& ib_mad_kernel_rmpp_agent(agent)) {\r\ncopy_offset = IB_MGMT_RMPP_HDR;\r\nrmpp_active = ib_get_rmpp_flags(&rmpp_mad->rmpp_hdr) &\r\nIB_MGMT_RMPP_FLAG_ACTIVE;\r\n} else {\r\ncopy_offset = IB_MGMT_MAD_HDR;\r\nrmpp_active = 0;\r\n}\r\ndata_len = count - hdr_size(file) - hdr_len;\r\npacket->msg = ib_create_send_mad(agent,\r\nbe32_to_cpu(packet->mad.hdr.qpn),\r\npacket->mad.hdr.pkey_index, rmpp_active,\r\nhdr_len, data_len, GFP_KERNEL);\r\nif (IS_ERR(packet->msg)) {\r\nret = PTR_ERR(packet->msg);\r\ngoto err_ah;\r\n}\r\npacket->msg->ah = ah;\r\npacket->msg->timeout_ms = packet->mad.hdr.timeout_ms;\r\npacket->msg->retries = packet->mad.hdr.retries;\r\npacket->msg->context[0] = packet;\r\nmemcpy(packet->msg->mad, packet->mad.data, IB_MGMT_MAD_HDR);\r\nif (!rmpp_active) {\r\nif (copy_from_user(packet->msg->mad + copy_offset,\r\nbuf + copy_offset,\r\nhdr_len + data_len - copy_offset)) {\r\nret = -EFAULT;\r\ngoto err_msg;\r\n}\r\n} else {\r\nret = copy_rmpp_mad(packet->msg, buf);\r\nif (ret)\r\ngoto err_msg;\r\n}\r\nif (!ib_response_mad(packet->msg->mad)) {\r\ntid = &((struct ib_mad_hdr *) packet->msg->mad)->tid;\r\n*tid = cpu_to_be64(((u64) agent->hi_tid) << 32 |\r\n(be64_to_cpup(tid) & 0xffffffff));\r\nrmpp_mad->mad_hdr.tid = *tid;\r\n}\r\nif (!ib_mad_kernel_rmpp_agent(agent)\r\n&& ib_is_mad_class_rmpp(rmpp_mad->mad_hdr.mgmt_class)\r\n&& (ib_get_rmpp_flags(&rmpp_mad->rmpp_hdr) & IB_MGMT_RMPP_FLAG_ACTIVE)) {\r\nspin_lock_irq(&file->send_lock);\r\nlist_add_tail(&packet->list, &file->send_list);\r\nspin_unlock_irq(&file->send_lock);\r\n} else {\r\nspin_lock_irq(&file->send_lock);\r\nret = is_duplicate(file, packet);\r\nif (!ret)\r\nlist_add_tail(&packet->list, &file->send_list);\r\nspin_unlock_irq(&file->send_lock);\r\nif (ret) {\r\nret = -EINVAL;\r\ngoto err_msg;\r\n}\r\n}\r\nret = ib_post_send_mad(packet->msg, NULL);\r\nif (ret)\r\ngoto err_send;\r\nmutex_unlock(&file->mutex);\r\nreturn count;\r\nerr_send:\r\ndequeue_send(file, packet);\r\nerr_msg:\r\nib_free_send_mad(packet->msg);\r\nerr_ah:\r\nib_destroy_ah(ah);\r\nerr_up:\r\nmutex_unlock(&file->mutex);\r\nerr:\r\nkfree(packet);\r\nreturn ret;\r\n}\r\nstatic unsigned int ib_umad_poll(struct file *filp, struct poll_table_struct *wait)\r\n{\r\nstruct ib_umad_file *file = filp->private_data;\r\nunsigned int mask = POLLOUT | POLLWRNORM;\r\npoll_wait(filp, &file->recv_wait, wait);\r\nif (!list_empty(&file->recv_list))\r\nmask |= POLLIN | POLLRDNORM;\r\nreturn mask;\r\n}\r\nstatic int ib_umad_reg_agent(struct ib_umad_file *file, void __user *arg,\r\nint compat_method_mask)\r\n{\r\nstruct ib_user_mad_reg_req ureq;\r\nstruct ib_mad_reg_req req;\r\nstruct ib_mad_agent *agent = NULL;\r\nint agent_id;\r\nint ret;\r\nmutex_lock(&file->port->file_mutex);\r\nmutex_lock(&file->mutex);\r\nif (!file->port->ib_dev) {\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent: invalid device\n");\r\nret = -EPIPE;\r\ngoto out;\r\n}\r\nif (copy_from_user(&ureq, arg, sizeof ureq)) {\r\nret = -EFAULT;\r\ngoto out;\r\n}\r\nif (ureq.qpn != 0 && ureq.qpn != 1) {\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent: invalid QPN %d specified\n",\r\nureq.qpn);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nfor (agent_id = 0; agent_id < IB_UMAD_MAX_AGENTS; ++agent_id)\r\nif (!__get_agent(file, agent_id))\r\ngoto found;\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent: Max Agents (%u) reached\n",\r\nIB_UMAD_MAX_AGENTS);\r\nret = -ENOMEM;\r\ngoto out;\r\nfound:\r\nif (ureq.mgmt_class) {\r\nmemset(&req, 0, sizeof(req));\r\nreq.mgmt_class = ureq.mgmt_class;\r\nreq.mgmt_class_version = ureq.mgmt_class_version;\r\nmemcpy(req.oui, ureq.oui, sizeof req.oui);\r\nif (compat_method_mask) {\r\nu32 *umm = (u32 *) ureq.method_mask;\r\nint i;\r\nfor (i = 0; i < BITS_TO_LONGS(IB_MGMT_MAX_METHODS); ++i)\r\nreq.method_mask[i] =\r\numm[i * 2] | ((u64) umm[i * 2 + 1] << 32);\r\n} else\r\nmemcpy(req.method_mask, ureq.method_mask,\r\nsizeof req.method_mask);\r\n}\r\nagent = ib_register_mad_agent(file->port->ib_dev, file->port->port_num,\r\nureq.qpn ? IB_QPT_GSI : IB_QPT_SMI,\r\nureq.mgmt_class ? &req : NULL,\r\nureq.rmpp_version,\r\nsend_handler, recv_handler, file, 0);\r\nif (IS_ERR(agent)) {\r\nret = PTR_ERR(agent);\r\nagent = NULL;\r\ngoto out;\r\n}\r\nif (put_user(agent_id,\r\n(u32 __user *) (arg + offsetof(struct ib_user_mad_reg_req, id)))) {\r\nret = -EFAULT;\r\ngoto out;\r\n}\r\nif (!file->already_used) {\r\nfile->already_used = 1;\r\nif (!file->use_pkey_index) {\r\ndev_warn(file->port->dev,\r\n"process %s did not enable P_Key index support.\n",\r\ncurrent->comm);\r\ndev_warn(file->port->dev,\r\n" Documentation/infiniband/user_mad.txt has info on the new ABI.\n");\r\n}\r\n}\r\nfile->agent[agent_id] = agent;\r\nret = 0;\r\nout:\r\nmutex_unlock(&file->mutex);\r\nif (ret && agent)\r\nib_unregister_mad_agent(agent);\r\nmutex_unlock(&file->port->file_mutex);\r\nreturn ret;\r\n}\r\nstatic int ib_umad_reg_agent2(struct ib_umad_file *file, void __user *arg)\r\n{\r\nstruct ib_user_mad_reg_req2 ureq;\r\nstruct ib_mad_reg_req req;\r\nstruct ib_mad_agent *agent = NULL;\r\nint agent_id;\r\nint ret;\r\nmutex_lock(&file->port->file_mutex);\r\nmutex_lock(&file->mutex);\r\nif (!file->port->ib_dev) {\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent2: invalid device\n");\r\nret = -EPIPE;\r\ngoto out;\r\n}\r\nif (copy_from_user(&ureq, arg, sizeof(ureq))) {\r\nret = -EFAULT;\r\ngoto out;\r\n}\r\nif (ureq.qpn != 0 && ureq.qpn != 1) {\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent2: invalid QPN %d specified\n",\r\nureq.qpn);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nif (ureq.flags & ~IB_USER_MAD_REG_FLAGS_CAP) {\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent2 failed: invalid registration flags specified 0x%x; supported 0x%x\n",\r\nureq.flags, IB_USER_MAD_REG_FLAGS_CAP);\r\nret = -EINVAL;\r\nif (put_user((u32)IB_USER_MAD_REG_FLAGS_CAP,\r\n(u32 __user *) (arg + offsetof(struct\r\nib_user_mad_reg_req2, flags))))\r\nret = -EFAULT;\r\ngoto out;\r\n}\r\nfor (agent_id = 0; agent_id < IB_UMAD_MAX_AGENTS; ++agent_id)\r\nif (!__get_agent(file, agent_id))\r\ngoto found;\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent2: Max Agents (%u) reached\n",\r\nIB_UMAD_MAX_AGENTS);\r\nret = -ENOMEM;\r\ngoto out;\r\nfound:\r\nif (ureq.mgmt_class) {\r\nmemset(&req, 0, sizeof(req));\r\nreq.mgmt_class = ureq.mgmt_class;\r\nreq.mgmt_class_version = ureq.mgmt_class_version;\r\nif (ureq.oui & 0xff000000) {\r\ndev_notice(file->port->dev,\r\n"ib_umad_reg_agent2 failed: oui invalid 0x%08x\n",\r\nureq.oui);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nreq.oui[2] = ureq.oui & 0x0000ff;\r\nreq.oui[1] = (ureq.oui & 0x00ff00) >> 8;\r\nreq.oui[0] = (ureq.oui & 0xff0000) >> 16;\r\nmemcpy(req.method_mask, ureq.method_mask,\r\nsizeof(req.method_mask));\r\n}\r\nagent = ib_register_mad_agent(file->port->ib_dev, file->port->port_num,\r\nureq.qpn ? IB_QPT_GSI : IB_QPT_SMI,\r\nureq.mgmt_class ? &req : NULL,\r\nureq.rmpp_version,\r\nsend_handler, recv_handler, file,\r\nureq.flags);\r\nif (IS_ERR(agent)) {\r\nret = PTR_ERR(agent);\r\nagent = NULL;\r\ngoto out;\r\n}\r\nif (put_user(agent_id,\r\n(u32 __user *)(arg +\r\noffsetof(struct ib_user_mad_reg_req2, id)))) {\r\nret = -EFAULT;\r\ngoto out;\r\n}\r\nif (!file->already_used) {\r\nfile->already_used = 1;\r\nfile->use_pkey_index = 1;\r\n}\r\nfile->agent[agent_id] = agent;\r\nret = 0;\r\nout:\r\nmutex_unlock(&file->mutex);\r\nif (ret && agent)\r\nib_unregister_mad_agent(agent);\r\nmutex_unlock(&file->port->file_mutex);\r\nreturn ret;\r\n}\r\nstatic int ib_umad_unreg_agent(struct ib_umad_file *file, u32 __user *arg)\r\n{\r\nstruct ib_mad_agent *agent = NULL;\r\nu32 id;\r\nint ret = 0;\r\nif (get_user(id, arg))\r\nreturn -EFAULT;\r\nmutex_lock(&file->port->file_mutex);\r\nmutex_lock(&file->mutex);\r\nif (id >= IB_UMAD_MAX_AGENTS || !__get_agent(file, id)) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nagent = file->agent[id];\r\nfile->agent[id] = NULL;\r\nout:\r\nmutex_unlock(&file->mutex);\r\nif (agent)\r\nib_unregister_mad_agent(agent);\r\nmutex_unlock(&file->port->file_mutex);\r\nreturn ret;\r\n}\r\nstatic long ib_umad_enable_pkey(struct ib_umad_file *file)\r\n{\r\nint ret = 0;\r\nmutex_lock(&file->mutex);\r\nif (file->already_used)\r\nret = -EINVAL;\r\nelse\r\nfile->use_pkey_index = 1;\r\nmutex_unlock(&file->mutex);\r\nreturn ret;\r\n}\r\nstatic long ib_umad_ioctl(struct file *filp, unsigned int cmd,\r\nunsigned long arg)\r\n{\r\nswitch (cmd) {\r\ncase IB_USER_MAD_REGISTER_AGENT:\r\nreturn ib_umad_reg_agent(filp->private_data, (void __user *) arg, 0);\r\ncase IB_USER_MAD_UNREGISTER_AGENT:\r\nreturn ib_umad_unreg_agent(filp->private_data, (__u32 __user *) arg);\r\ncase IB_USER_MAD_ENABLE_PKEY:\r\nreturn ib_umad_enable_pkey(filp->private_data);\r\ncase IB_USER_MAD_REGISTER_AGENT2:\r\nreturn ib_umad_reg_agent2(filp->private_data, (void __user *) arg);\r\ndefault:\r\nreturn -ENOIOCTLCMD;\r\n}\r\n}\r\nstatic long ib_umad_compat_ioctl(struct file *filp, unsigned int cmd,\r\nunsigned long arg)\r\n{\r\nswitch (cmd) {\r\ncase IB_USER_MAD_REGISTER_AGENT:\r\nreturn ib_umad_reg_agent(filp->private_data, compat_ptr(arg), 1);\r\ncase IB_USER_MAD_UNREGISTER_AGENT:\r\nreturn ib_umad_unreg_agent(filp->private_data, compat_ptr(arg));\r\ncase IB_USER_MAD_ENABLE_PKEY:\r\nreturn ib_umad_enable_pkey(filp->private_data);\r\ncase IB_USER_MAD_REGISTER_AGENT2:\r\nreturn ib_umad_reg_agent2(filp->private_data, compat_ptr(arg));\r\ndefault:\r\nreturn -ENOIOCTLCMD;\r\n}\r\n}\r\nstatic int ib_umad_open(struct inode *inode, struct file *filp)\r\n{\r\nstruct ib_umad_port *port;\r\nstruct ib_umad_file *file;\r\nint ret = -ENXIO;\r\nport = container_of(inode->i_cdev, struct ib_umad_port, cdev);\r\nmutex_lock(&port->file_mutex);\r\nif (!port->ib_dev)\r\ngoto out;\r\nret = -ENOMEM;\r\nfile = kzalloc(sizeof *file, GFP_KERNEL);\r\nif (!file)\r\ngoto out;\r\nmutex_init(&file->mutex);\r\nspin_lock_init(&file->send_lock);\r\nINIT_LIST_HEAD(&file->recv_list);\r\nINIT_LIST_HEAD(&file->send_list);\r\ninit_waitqueue_head(&file->recv_wait);\r\nfile->port = port;\r\nfilp->private_data = file;\r\nlist_add_tail(&file->port_list, &port->file_list);\r\nret = nonseekable_open(inode, filp);\r\nif (ret) {\r\nlist_del(&file->port_list);\r\nkfree(file);\r\ngoto out;\r\n}\r\nkobject_get(&port->umad_dev->kobj);\r\nout:\r\nmutex_unlock(&port->file_mutex);\r\nreturn ret;\r\n}\r\nstatic int ib_umad_close(struct inode *inode, struct file *filp)\r\n{\r\nstruct ib_umad_file *file = filp->private_data;\r\nstruct ib_umad_device *dev = file->port->umad_dev;\r\nstruct ib_umad_packet *packet, *tmp;\r\nint already_dead;\r\nint i;\r\nmutex_lock(&file->port->file_mutex);\r\nmutex_lock(&file->mutex);\r\nalready_dead = file->agents_dead;\r\nfile->agents_dead = 1;\r\nlist_for_each_entry_safe(packet, tmp, &file->recv_list, list) {\r\nif (packet->recv_wc)\r\nib_free_recv_mad(packet->recv_wc);\r\nkfree(packet);\r\n}\r\nlist_del(&file->port_list);\r\nmutex_unlock(&file->mutex);\r\nif (!already_dead)\r\nfor (i = 0; i < IB_UMAD_MAX_AGENTS; ++i)\r\nif (file->agent[i])\r\nib_unregister_mad_agent(file->agent[i]);\r\nmutex_unlock(&file->port->file_mutex);\r\nkfree(file);\r\nkobject_put(&dev->kobj);\r\nreturn 0;\r\n}\r\nstatic int ib_umad_sm_open(struct inode *inode, struct file *filp)\r\n{\r\nstruct ib_umad_port *port;\r\nstruct ib_port_modify props = {\r\n.set_port_cap_mask = IB_PORT_SM\r\n};\r\nint ret;\r\nport = container_of(inode->i_cdev, struct ib_umad_port, sm_cdev);\r\nif (filp->f_flags & O_NONBLOCK) {\r\nif (down_trylock(&port->sm_sem)) {\r\nret = -EAGAIN;\r\ngoto fail;\r\n}\r\n} else {\r\nif (down_interruptible(&port->sm_sem)) {\r\nret = -ERESTARTSYS;\r\ngoto fail;\r\n}\r\n}\r\nret = ib_modify_port(port->ib_dev, port->port_num, 0, &props);\r\nif (ret)\r\ngoto err_up_sem;\r\nfilp->private_data = port;\r\nret = nonseekable_open(inode, filp);\r\nif (ret)\r\ngoto err_clr_sm_cap;\r\nkobject_get(&port->umad_dev->kobj);\r\nreturn 0;\r\nerr_clr_sm_cap:\r\nswap(props.set_port_cap_mask, props.clr_port_cap_mask);\r\nib_modify_port(port->ib_dev, port->port_num, 0, &props);\r\nerr_up_sem:\r\nup(&port->sm_sem);\r\nfail:\r\nreturn ret;\r\n}\r\nstatic int ib_umad_sm_close(struct inode *inode, struct file *filp)\r\n{\r\nstruct ib_umad_port *port = filp->private_data;\r\nstruct ib_port_modify props = {\r\n.clr_port_cap_mask = IB_PORT_SM\r\n};\r\nint ret = 0;\r\nmutex_lock(&port->file_mutex);\r\nif (port->ib_dev)\r\nret = ib_modify_port(port->ib_dev, port->port_num, 0, &props);\r\nmutex_unlock(&port->file_mutex);\r\nup(&port->sm_sem);\r\nkobject_put(&port->umad_dev->kobj);\r\nreturn ret;\r\n}\r\nstatic ssize_t show_ibdev(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct ib_umad_port *port = dev_get_drvdata(dev);\r\nif (!port)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%s\n", port->ib_dev->name);\r\n}\r\nstatic ssize_t show_port(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct ib_umad_port *port = dev_get_drvdata(dev);\r\nif (!port)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n", port->port_num);\r\n}\r\nstatic int find_overflow_devnum(struct ib_device *device)\r\n{\r\nint ret;\r\nif (!overflow_maj) {\r\nret = alloc_chrdev_region(&overflow_maj, 0, IB_UMAD_MAX_PORTS * 2,\r\n"infiniband_mad");\r\nif (ret) {\r\ndev_err(&device->dev,\r\n"couldn't register dynamic device number\n");\r\nreturn ret;\r\n}\r\n}\r\nret = find_first_zero_bit(overflow_map, IB_UMAD_MAX_PORTS);\r\nif (ret >= IB_UMAD_MAX_PORTS)\r\nreturn -1;\r\nreturn ret;\r\n}\r\nstatic int ib_umad_init_port(struct ib_device *device, int port_num,\r\nstruct ib_umad_device *umad_dev,\r\nstruct ib_umad_port *port)\r\n{\r\nint devnum;\r\ndev_t base;\r\nspin_lock(&port_lock);\r\ndevnum = find_first_zero_bit(dev_map, IB_UMAD_MAX_PORTS);\r\nif (devnum >= IB_UMAD_MAX_PORTS) {\r\nspin_unlock(&port_lock);\r\ndevnum = find_overflow_devnum(device);\r\nif (devnum < 0)\r\nreturn -1;\r\nspin_lock(&port_lock);\r\nport->dev_num = devnum + IB_UMAD_MAX_PORTS;\r\nbase = devnum + overflow_maj;\r\nset_bit(devnum, overflow_map);\r\n} else {\r\nport->dev_num = devnum;\r\nbase = devnum + base_dev;\r\nset_bit(devnum, dev_map);\r\n}\r\nspin_unlock(&port_lock);\r\nport->ib_dev = device;\r\nport->port_num = port_num;\r\nsema_init(&port->sm_sem, 1);\r\nmutex_init(&port->file_mutex);\r\nINIT_LIST_HEAD(&port->file_list);\r\ncdev_init(&port->cdev, &umad_fops);\r\nport->cdev.owner = THIS_MODULE;\r\nport->cdev.kobj.parent = &umad_dev->kobj;\r\nkobject_set_name(&port->cdev.kobj, "umad%d", port->dev_num);\r\nif (cdev_add(&port->cdev, base, 1))\r\ngoto err_cdev;\r\nport->dev = device_create(umad_class, device->dma_device,\r\nport->cdev.dev, port,\r\n"umad%d", port->dev_num);\r\nif (IS_ERR(port->dev))\r\ngoto err_cdev;\r\nif (device_create_file(port->dev, &dev_attr_ibdev))\r\ngoto err_dev;\r\nif (device_create_file(port->dev, &dev_attr_port))\r\ngoto err_dev;\r\nbase += IB_UMAD_MAX_PORTS;\r\ncdev_init(&port->sm_cdev, &umad_sm_fops);\r\nport->sm_cdev.owner = THIS_MODULE;\r\nport->sm_cdev.kobj.parent = &umad_dev->kobj;\r\nkobject_set_name(&port->sm_cdev.kobj, "issm%d", port->dev_num);\r\nif (cdev_add(&port->sm_cdev, base, 1))\r\ngoto err_sm_cdev;\r\nport->sm_dev = device_create(umad_class, device->dma_device,\r\nport->sm_cdev.dev, port,\r\n"issm%d", port->dev_num);\r\nif (IS_ERR(port->sm_dev))\r\ngoto err_sm_cdev;\r\nif (device_create_file(port->sm_dev, &dev_attr_ibdev))\r\ngoto err_sm_dev;\r\nif (device_create_file(port->sm_dev, &dev_attr_port))\r\ngoto err_sm_dev;\r\nreturn 0;\r\nerr_sm_dev:\r\ndevice_destroy(umad_class, port->sm_cdev.dev);\r\nerr_sm_cdev:\r\ncdev_del(&port->sm_cdev);\r\nerr_dev:\r\ndevice_destroy(umad_class, port->cdev.dev);\r\nerr_cdev:\r\ncdev_del(&port->cdev);\r\nif (port->dev_num < IB_UMAD_MAX_PORTS)\r\nclear_bit(devnum, dev_map);\r\nelse\r\nclear_bit(devnum, overflow_map);\r\nreturn -1;\r\n}\r\nstatic void ib_umad_kill_port(struct ib_umad_port *port)\r\n{\r\nstruct ib_umad_file *file;\r\nint id;\r\ndev_set_drvdata(port->dev, NULL);\r\ndev_set_drvdata(port->sm_dev, NULL);\r\ndevice_destroy(umad_class, port->cdev.dev);\r\ndevice_destroy(umad_class, port->sm_cdev.dev);\r\ncdev_del(&port->cdev);\r\ncdev_del(&port->sm_cdev);\r\nmutex_lock(&port->file_mutex);\r\nport->ib_dev = NULL;\r\nlist_for_each_entry(file, &port->file_list, port_list) {\r\nmutex_lock(&file->mutex);\r\nfile->agents_dead = 1;\r\nmutex_unlock(&file->mutex);\r\nfor (id = 0; id < IB_UMAD_MAX_AGENTS; ++id)\r\nif (file->agent[id])\r\nib_unregister_mad_agent(file->agent[id]);\r\n}\r\nmutex_unlock(&port->file_mutex);\r\nif (port->dev_num < IB_UMAD_MAX_PORTS)\r\nclear_bit(port->dev_num, dev_map);\r\nelse\r\nclear_bit(port->dev_num - IB_UMAD_MAX_PORTS, overflow_map);\r\n}\r\nstatic void ib_umad_add_one(struct ib_device *device)\r\n{\r\nstruct ib_umad_device *umad_dev;\r\nint s, e, i;\r\nif (rdma_node_get_transport(device->node_type) != RDMA_TRANSPORT_IB)\r\nreturn;\r\nif (device->node_type == RDMA_NODE_IB_SWITCH)\r\ns = e = 0;\r\nelse {\r\ns = 1;\r\ne = device->phys_port_cnt;\r\n}\r\numad_dev = kzalloc(sizeof *umad_dev +\r\n(e - s + 1) * sizeof (struct ib_umad_port),\r\nGFP_KERNEL);\r\nif (!umad_dev)\r\nreturn;\r\nkobject_init(&umad_dev->kobj, &ib_umad_dev_ktype);\r\numad_dev->start_port = s;\r\numad_dev->end_port = e;\r\nfor (i = s; i <= e; ++i) {\r\numad_dev->port[i - s].umad_dev = umad_dev;\r\nif (ib_umad_init_port(device, i, umad_dev,\r\n&umad_dev->port[i - s]))\r\ngoto err;\r\n}\r\nib_set_client_data(device, &umad_client, umad_dev);\r\nreturn;\r\nerr:\r\nwhile (--i >= s)\r\nib_umad_kill_port(&umad_dev->port[i - s]);\r\nkobject_put(&umad_dev->kobj);\r\n}\r\nstatic void ib_umad_remove_one(struct ib_device *device)\r\n{\r\nstruct ib_umad_device *umad_dev = ib_get_client_data(device, &umad_client);\r\nint i;\r\nif (!umad_dev)\r\nreturn;\r\nfor (i = 0; i <= umad_dev->end_port - umad_dev->start_port; ++i)\r\nib_umad_kill_port(&umad_dev->port[i]);\r\nkobject_put(&umad_dev->kobj);\r\n}\r\nstatic char *umad_devnode(struct device *dev, umode_t *mode)\r\n{\r\nreturn kasprintf(GFP_KERNEL, "infiniband/%s", dev_name(dev));\r\n}\r\nstatic int __init ib_umad_init(void)\r\n{\r\nint ret;\r\nret = register_chrdev_region(base_dev, IB_UMAD_MAX_PORTS * 2,\r\n"infiniband_mad");\r\nif (ret) {\r\npr_err("couldn't register device number\n");\r\ngoto out;\r\n}\r\numad_class = class_create(THIS_MODULE, "infiniband_mad");\r\nif (IS_ERR(umad_class)) {\r\nret = PTR_ERR(umad_class);\r\npr_err("couldn't create class infiniband_mad\n");\r\ngoto out_chrdev;\r\n}\r\numad_class->devnode = umad_devnode;\r\nret = class_create_file(umad_class, &class_attr_abi_version.attr);\r\nif (ret) {\r\npr_err("couldn't create abi_version attribute\n");\r\ngoto out_class;\r\n}\r\nret = ib_register_client(&umad_client);\r\nif (ret) {\r\npr_err("couldn't register ib_umad client\n");\r\ngoto out_class;\r\n}\r\nreturn 0;\r\nout_class:\r\nclass_destroy(umad_class);\r\nout_chrdev:\r\nunregister_chrdev_region(base_dev, IB_UMAD_MAX_PORTS * 2);\r\nout:\r\nreturn ret;\r\n}\r\nstatic void __exit ib_umad_cleanup(void)\r\n{\r\nib_unregister_client(&umad_client);\r\nclass_destroy(umad_class);\r\nunregister_chrdev_region(base_dev, IB_UMAD_MAX_PORTS * 2);\r\nif (overflow_maj)\r\nunregister_chrdev_region(overflow_maj, IB_UMAD_MAX_PORTS * 2);\r\n}
