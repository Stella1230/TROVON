static void spu_buff_add(unsigned long int value, int spu)\r\n{\r\nint full = 1;\r\nif (spu_buff[spu].head >= spu_buff[spu].tail) {\r\nif ((spu_buff[spu].head - spu_buff[spu].tail)\r\n< (max_spu_buff - 1))\r\nfull = 0;\r\n} else if (spu_buff[spu].tail > spu_buff[spu].head) {\r\nif ((spu_buff[spu].tail - spu_buff[spu].head)\r\n> 1)\r\nfull = 0;\r\n}\r\nif (!full) {\r\nspu_buff[spu].buff[spu_buff[spu].head] = value;\r\nspu_buff[spu].head++;\r\nif (spu_buff[spu].head >= max_spu_buff)\r\nspu_buff[spu].head = 0;\r\n} else {\r\noprofile_cpu_buffer_inc_smpl_lost();\r\n}\r\n}\r\nvoid sync_spu_buff(void)\r\n{\r\nint spu;\r\nunsigned long flags;\r\nint curr_head;\r\nfor (spu = 0; spu < num_spu_nodes; spu++) {\r\nif (spu_buff[spu].buff == NULL)\r\ncontinue;\r\nspin_lock_irqsave(&buffer_lock, flags);\r\ncurr_head = spu_buff[spu].head;\r\nspin_unlock_irqrestore(&buffer_lock, flags);\r\noprofile_put_buff(spu_buff[spu].buff,\r\nspu_buff[spu].tail,\r\ncurr_head, max_spu_buff);\r\nspin_lock_irqsave(&buffer_lock, flags);\r\nspu_buff[spu].tail = curr_head;\r\nspin_unlock_irqrestore(&buffer_lock, flags);\r\n}\r\n}\r\nstatic void wq_sync_spu_buff(struct work_struct *work)\r\n{\r\nsync_spu_buff();\r\nif (spu_prof_running)\r\nschedule_delayed_work(&spu_work, DEFAULT_TIMER_EXPIRE);\r\n}\r\nstatic void destroy_cached_info(struct kref *kref)\r\n{\r\nstruct cached_info *info;\r\ninfo = container_of(kref, struct cached_info, cache_ref);\r\nvma_map_free(info->map);\r\nkfree(info);\r\nmodule_put(THIS_MODULE);\r\n}\r\nstatic struct cached_info *get_cached_info(struct spu *the_spu, int spu_num)\r\n{\r\nstruct kref *ref;\r\nstruct cached_info *ret_info;\r\nif (spu_num >= num_spu_nodes) {\r\nprintk(KERN_ERR "SPU_PROF: "\r\n"%s, line %d: Invalid index %d into spu info cache\n",\r\n__func__, __LINE__, spu_num);\r\nret_info = NULL;\r\ngoto out;\r\n}\r\nif (!spu_info[spu_num] && the_spu) {\r\nref = spu_get_profile_private_kref(the_spu->ctx);\r\nif (ref) {\r\nspu_info[spu_num] = container_of(ref, struct cached_info, cache_ref);\r\nkref_get(&spu_info[spu_num]->cache_ref);\r\n}\r\n}\r\nret_info = spu_info[spu_num];\r\nout:\r\nreturn ret_info;\r\n}\r\nstatic int\r\nprepare_cached_spu_info(struct spu *spu, unsigned long objectId)\r\n{\r\nunsigned long flags;\r\nstruct vma_to_fileoffset_map *new_map;\r\nint retval = 0;\r\nstruct cached_info *info;\r\ninfo = get_cached_info(spu, spu->number);\r\nif (info) {\r\npr_debug("Found cached SPU info.\n");\r\ngoto out;\r\n}\r\ninfo = kzalloc(sizeof(struct cached_info), GFP_KERNEL);\r\nif (!info) {\r\nprintk(KERN_ERR "SPU_PROF: "\r\n"%s, line %d: create vma_map failed\n",\r\n__func__, __LINE__);\r\nretval = -ENOMEM;\r\ngoto err_alloc;\r\n}\r\nnew_map = create_vma_map(spu, objectId);\r\nif (!new_map) {\r\nprintk(KERN_ERR "SPU_PROF: "\r\n"%s, line %d: create vma_map failed\n",\r\n__func__, __LINE__);\r\nretval = -ENOMEM;\r\ngoto err_alloc;\r\n}\r\npr_debug("Created vma_map\n");\r\ninfo->map = new_map;\r\ninfo->the_spu = spu;\r\nkref_init(&info->cache_ref);\r\nspin_lock_irqsave(&cache_lock, flags);\r\nspu_info[spu->number] = info;\r\nkref_get(&info->cache_ref);\r\ntry_module_get(THIS_MODULE);\r\nspu_set_profile_private_kref(spu->ctx, &info->cache_ref,\r\ndestroy_cached_info);\r\nspin_unlock_irqrestore(&cache_lock, flags);\r\ngoto out;\r\nerr_alloc:\r\nkfree(info);\r\nout:\r\nreturn retval;\r\n}\r\nstatic int release_cached_info(int spu_index)\r\n{\r\nint index, end;\r\nif (spu_index == RELEASE_ALL) {\r\nend = num_spu_nodes;\r\nindex = 0;\r\n} else {\r\nif (spu_index >= num_spu_nodes) {\r\nprintk(KERN_ERR "SPU_PROF: "\r\n"%s, line %d: "\r\n"Invalid index %d into spu info cache\n",\r\n__func__, __LINE__, spu_index);\r\ngoto out;\r\n}\r\nend = spu_index + 1;\r\nindex = spu_index;\r\n}\r\nfor (; index < end; index++) {\r\nif (spu_info[index]) {\r\nkref_put(&spu_info[index]->cache_ref,\r\ndestroy_cached_info);\r\nspu_info[index] = NULL;\r\n}\r\n}\r\nout:\r\nreturn 0;\r\n}\r\nstatic inline unsigned long fast_get_dcookie(struct path *path)\r\n{\r\nunsigned long cookie;\r\nif (path->dentry->d_flags & DCACHE_COOKIE)\r\nreturn (unsigned long)path->dentry;\r\nget_dcookie(path, &cookie);\r\nreturn cookie;\r\n}\r\nstatic unsigned long\r\nget_exec_dcookie_and_offset(struct spu *spu, unsigned int *offsetp,\r\nunsigned long *spu_bin_dcookie,\r\nunsigned long spu_ref)\r\n{\r\nunsigned long app_cookie = 0;\r\nunsigned int my_offset = 0;\r\nstruct vm_area_struct *vma;\r\nstruct mm_struct *mm = spu->mm;\r\nif (!mm)\r\ngoto out;\r\ndown_read(&mm->mmap_sem);\r\nif (mm->exe_file) {\r\napp_cookie = fast_get_dcookie(&mm->exe_file->f_path);\r\npr_debug("got dcookie for %pD\n", mm->exe_file);\r\n}\r\nfor (vma = mm->mmap; vma; vma = vma->vm_next) {\r\nif (vma->vm_start > spu_ref || vma->vm_end <= spu_ref)\r\ncontinue;\r\nmy_offset = spu_ref - vma->vm_start;\r\nif (!vma->vm_file)\r\ngoto fail_no_image_cookie;\r\npr_debug("Found spu ELF at %X(object-id:%lx) for file %pD\n",\r\nmy_offset, spu_ref, vma->vm_file);\r\n*offsetp = my_offset;\r\nbreak;\r\n}\r\n*spu_bin_dcookie = fast_get_dcookie(&vma->vm_file->f_path);\r\npr_debug("got dcookie for %pD\n", vma->vm_file);\r\nup_read(&mm->mmap_sem);\r\nout:\r\nreturn app_cookie;\r\nfail_no_image_cookie:\r\nup_read(&mm->mmap_sem);\r\nprintk(KERN_ERR "SPU_PROF: "\r\n"%s, line %d: Cannot find dcookie for SPU binary\n",\r\n__func__, __LINE__);\r\ngoto out;\r\n}\r\nstatic int process_context_switch(struct spu *spu, unsigned long objectId)\r\n{\r\nunsigned long flags;\r\nint retval;\r\nunsigned int offset = 0;\r\nunsigned long spu_cookie = 0, app_dcookie;\r\nretval = prepare_cached_spu_info(spu, objectId);\r\nif (retval)\r\ngoto out;\r\napp_dcookie = get_exec_dcookie_and_offset(spu, &offset, &spu_cookie, objectId);\r\nif (!app_dcookie || !spu_cookie) {\r\nretval = -ENOENT;\r\ngoto out;\r\n}\r\nspin_lock_irqsave(&buffer_lock, flags);\r\nspu_buff_add(ESCAPE_CODE, spu->number);\r\nspu_buff_add(SPU_CTX_SWITCH_CODE, spu->number);\r\nspu_buff_add(spu->number, spu->number);\r\nspu_buff_add(spu->pid, spu->number);\r\nspu_buff_add(spu->tgid, spu->number);\r\nspu_buff_add(app_dcookie, spu->number);\r\nspu_buff_add(spu_cookie, spu->number);\r\nspu_buff_add(offset, spu->number);\r\nspu_buff[spu->number].ctx_sw_seen = 1;\r\nspin_unlock_irqrestore(&buffer_lock, flags);\r\nsmp_wmb();\r\nout:\r\nreturn retval;\r\n}\r\nstatic int spu_active_notify(struct notifier_block *self, unsigned long val,\r\nvoid *data)\r\n{\r\nint retval;\r\nunsigned long flags;\r\nstruct spu *the_spu = data;\r\npr_debug("SPU event notification arrived\n");\r\nif (!val) {\r\nspin_lock_irqsave(&cache_lock, flags);\r\nretval = release_cached_info(the_spu->number);\r\nspin_unlock_irqrestore(&cache_lock, flags);\r\n} else {\r\nretval = process_context_switch(the_spu, val);\r\n}\r\nreturn retval;\r\n}\r\nstatic int number_of_online_nodes(void)\r\n{\r\nu32 cpu; u32 tmp;\r\nint nodes = 0;\r\nfor_each_online_cpu(cpu) {\r\ntmp = cbe_cpu_to_node(cpu) + 1;\r\nif (tmp > nodes)\r\nnodes++;\r\n}\r\nreturn nodes;\r\n}\r\nstatic int oprofile_spu_buff_create(void)\r\n{\r\nint spu;\r\nmax_spu_buff = oprofile_get_cpu_buffer_size();\r\nfor (spu = 0; spu < num_spu_nodes; spu++) {\r\nspu_buff[spu].head = 0;\r\nspu_buff[spu].tail = 0;\r\nspu_buff[spu].buff = kzalloc((max_spu_buff\r\n* sizeof(unsigned long)),\r\nGFP_KERNEL);\r\nif (!spu_buff[spu].buff) {\r\nprintk(KERN_ERR "SPU_PROF: "\r\n"%s, line %d: oprofile_spu_buff_create "\r\n"failed to allocate spu buffer %d.\n",\r\n__func__, __LINE__, spu);\r\nwhile (spu >= 0) {\r\nkfree(spu_buff[spu].buff);\r\nspu_buff[spu].buff = 0;\r\nspu--;\r\n}\r\nreturn -ENOMEM;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint spu_sync_start(void)\r\n{\r\nint spu;\r\nint ret = SKIP_GENERIC_SYNC;\r\nint register_ret;\r\nunsigned long flags = 0;\r\nspu_prof_num_nodes = number_of_online_nodes();\r\nnum_spu_nodes = spu_prof_num_nodes * 8;\r\nINIT_DELAYED_WORK(&spu_work, wq_sync_spu_buff);\r\nret = oprofile_spu_buff_create();\r\nif (ret)\r\ngoto out;\r\nspin_lock_irqsave(&buffer_lock, flags);\r\nfor (spu = 0; spu < num_spu_nodes; spu++) {\r\nspu_buff_add(ESCAPE_CODE, spu);\r\nspu_buff_add(SPU_PROFILING_CODE, spu);\r\nspu_buff_add(num_spu_nodes, spu);\r\n}\r\nspin_unlock_irqrestore(&buffer_lock, flags);\r\nfor (spu = 0; spu < num_spu_nodes; spu++) {\r\nspu_buff[spu].ctx_sw_seen = 0;\r\nspu_buff[spu].last_guard_val = 0;\r\n}\r\nregister_ret = spu_switch_event_register(&spu_active);\r\nif (register_ret) {\r\nret = SYNC_START_ERROR;\r\ngoto out;\r\n}\r\npr_debug("spu_sync_start -- running.\n");\r\nout:\r\nreturn ret;\r\n}\r\nvoid spu_sync_buffer(int spu_num, unsigned int *samples,\r\nint num_samples)\r\n{\r\nunsigned long long file_offset;\r\nunsigned long flags;\r\nint i;\r\nstruct vma_to_fileoffset_map *map;\r\nstruct spu *the_spu;\r\nunsigned long long spu_num_ll = spu_num;\r\nunsigned long long spu_num_shifted = spu_num_ll << 32;\r\nstruct cached_info *c_info;\r\nspin_lock_irqsave(&cache_lock, flags);\r\nc_info = get_cached_info(NULL, spu_num);\r\nif (!c_info) {\r\npr_debug("SPU_PROF: No cached SPU contex "\r\n"for SPU #%d. Dropping samples.\n", spu_num);\r\ngoto out;\r\n}\r\nmap = c_info->map;\r\nthe_spu = c_info->the_spu;\r\nspin_lock(&buffer_lock);\r\nfor (i = 0; i < num_samples; i++) {\r\nunsigned int sample = *(samples+i);\r\nint grd_val = 0;\r\nfile_offset = 0;\r\nif (sample == 0)\r\ncontinue;\r\nfile_offset = vma_map_lookup( map, sample, the_spu, &grd_val);\r\nif (grd_val && grd_val != spu_buff[spu_num].last_guard_val) {\r\nspu_buff[spu_num].last_guard_val = grd_val;\r\nbreak;\r\n}\r\nif (spu_buff[spu_num].ctx_sw_seen)\r\nspu_buff_add((file_offset | spu_num_shifted),\r\nspu_num);\r\n}\r\nspin_unlock(&buffer_lock);\r\nout:\r\nspin_unlock_irqrestore(&cache_lock, flags);\r\n}\r\nint spu_sync_stop(void)\r\n{\r\nunsigned long flags = 0;\r\nint ret;\r\nint k;\r\nret = spu_switch_event_unregister(&spu_active);\r\nif (ret)\r\nprintk(KERN_ERR "SPU_PROF: "\r\n"%s, line %d: spu_switch_event_unregister " \\r\n"returned %d\n",\r\n__func__, __LINE__, ret);\r\nsync_spu_buff();\r\nspin_lock_irqsave(&cache_lock, flags);\r\nret = release_cached_info(RELEASE_ALL);\r\nspin_unlock_irqrestore(&cache_lock, flags);\r\ncancel_delayed_work(&spu_work);\r\nfor (k = 0; k < num_spu_nodes; k++) {\r\nspu_buff[k].ctx_sw_seen = 0;\r\nkfree(spu_buff[k].buff);\r\nspu_buff[k].buff = 0;\r\n}\r\npr_debug("spu_sync_stop -- done.\n");\r\nreturn ret;\r\n}
