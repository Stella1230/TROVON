int radeon_gart_table_ram_alloc(struct radeon_device *rdev)\r\n{\r\nvoid *ptr;\r\nptr = pci_alloc_consistent(rdev->pdev, rdev->gart.table_size,\r\n&rdev->gart.table_addr);\r\nif (ptr == NULL) {\r\nreturn -ENOMEM;\r\n}\r\n#ifdef CONFIG_X86\r\nif (rdev->family == CHIP_RS400 || rdev->family == CHIP_RS480 ||\r\nrdev->family == CHIP_RS690 || rdev->family == CHIP_RS740) {\r\nset_memory_uc((unsigned long)ptr,\r\nrdev->gart.table_size >> PAGE_SHIFT);\r\n}\r\n#endif\r\nrdev->gart.ptr = ptr;\r\nmemset((void *)rdev->gart.ptr, 0, rdev->gart.table_size);\r\nreturn 0;\r\n}\r\nvoid radeon_gart_table_ram_free(struct radeon_device *rdev)\r\n{\r\nif (rdev->gart.ptr == NULL) {\r\nreturn;\r\n}\r\n#ifdef CONFIG_X86\r\nif (rdev->family == CHIP_RS400 || rdev->family == CHIP_RS480 ||\r\nrdev->family == CHIP_RS690 || rdev->family == CHIP_RS740) {\r\nset_memory_wb((unsigned long)rdev->gart.ptr,\r\nrdev->gart.table_size >> PAGE_SHIFT);\r\n}\r\n#endif\r\npci_free_consistent(rdev->pdev, rdev->gart.table_size,\r\n(void *)rdev->gart.ptr,\r\nrdev->gart.table_addr);\r\nrdev->gart.ptr = NULL;\r\nrdev->gart.table_addr = 0;\r\n}\r\nint radeon_gart_table_vram_alloc(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->gart.robj == NULL) {\r\nr = radeon_bo_create(rdev, rdev->gart.table_size,\r\nPAGE_SIZE, true, RADEON_GEM_DOMAIN_VRAM,\r\n0, NULL, NULL, &rdev->gart.robj);\r\nif (r) {\r\nreturn r;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint radeon_gart_table_vram_pin(struct radeon_device *rdev)\r\n{\r\nuint64_t gpu_addr;\r\nint r;\r\nr = radeon_bo_reserve(rdev->gart.robj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_pin(rdev->gart.robj,\r\nRADEON_GEM_DOMAIN_VRAM, &gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(rdev->gart.robj);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(rdev->gart.robj, &rdev->gart.ptr);\r\nif (r)\r\nradeon_bo_unpin(rdev->gart.robj);\r\nradeon_bo_unreserve(rdev->gart.robj);\r\nrdev->gart.table_addr = gpu_addr;\r\nif (!r) {\r\nint i;\r\nfor (i = 0; i < rdev->gart.num_gpu_pages; i++)\r\nradeon_gart_set_page(rdev, i, rdev->gart.pages_entry[i]);\r\nmb();\r\nradeon_gart_tlb_flush(rdev);\r\n}\r\nreturn r;\r\n}\r\nvoid radeon_gart_table_vram_unpin(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->gart.robj == NULL) {\r\nreturn;\r\n}\r\nr = radeon_bo_reserve(rdev->gart.robj, false);\r\nif (likely(r == 0)) {\r\nradeon_bo_kunmap(rdev->gart.robj);\r\nradeon_bo_unpin(rdev->gart.robj);\r\nradeon_bo_unreserve(rdev->gart.robj);\r\nrdev->gart.ptr = NULL;\r\n}\r\n}\r\nvoid radeon_gart_table_vram_free(struct radeon_device *rdev)\r\n{\r\nif (rdev->gart.robj == NULL) {\r\nreturn;\r\n}\r\nradeon_bo_unref(&rdev->gart.robj);\r\n}\r\nvoid radeon_gart_unbind(struct radeon_device *rdev, unsigned offset,\r\nint pages)\r\n{\r\nunsigned t;\r\nunsigned p;\r\nint i, j;\r\nif (!rdev->gart.ready) {\r\nWARN(1, "trying to unbind memory from uninitialized GART !\n");\r\nreturn;\r\n}\r\nt = offset / RADEON_GPU_PAGE_SIZE;\r\np = t / (PAGE_SIZE / RADEON_GPU_PAGE_SIZE);\r\nfor (i = 0; i < pages; i++, p++) {\r\nif (rdev->gart.pages[p]) {\r\nrdev->gart.pages[p] = NULL;\r\nfor (j = 0; j < (PAGE_SIZE / RADEON_GPU_PAGE_SIZE); j++, t++) {\r\nrdev->gart.pages_entry[t] = rdev->dummy_page.entry;\r\nif (rdev->gart.ptr) {\r\nradeon_gart_set_page(rdev, t,\r\nrdev->dummy_page.entry);\r\n}\r\n}\r\n}\r\n}\r\nmb();\r\nradeon_gart_tlb_flush(rdev);\r\n}\r\nint radeon_gart_bind(struct radeon_device *rdev, unsigned offset,\r\nint pages, struct page **pagelist, dma_addr_t *dma_addr,\r\nuint32_t flags)\r\n{\r\nunsigned t;\r\nunsigned p;\r\nuint64_t page_base, page_entry;\r\nint i, j;\r\nif (!rdev->gart.ready) {\r\nWARN(1, "trying to bind memory to uninitialized GART !\n");\r\nreturn -EINVAL;\r\n}\r\nt = offset / RADEON_GPU_PAGE_SIZE;\r\np = t / (PAGE_SIZE / RADEON_GPU_PAGE_SIZE);\r\nfor (i = 0; i < pages; i++, p++) {\r\nrdev->gart.pages[p] = pagelist[i];\r\npage_base = dma_addr[i];\r\nfor (j = 0; j < (PAGE_SIZE / RADEON_GPU_PAGE_SIZE); j++, t++) {\r\npage_entry = radeon_gart_get_page_entry(page_base, flags);\r\nrdev->gart.pages_entry[t] = page_entry;\r\nif (rdev->gart.ptr) {\r\nradeon_gart_set_page(rdev, t, page_entry);\r\n}\r\npage_base += RADEON_GPU_PAGE_SIZE;\r\n}\r\n}\r\nmb();\r\nradeon_gart_tlb_flush(rdev);\r\nreturn 0;\r\n}\r\nint radeon_gart_init(struct radeon_device *rdev)\r\n{\r\nint r, i;\r\nif (rdev->gart.pages) {\r\nreturn 0;\r\n}\r\nif (PAGE_SIZE < RADEON_GPU_PAGE_SIZE) {\r\nDRM_ERROR("Page size is smaller than GPU page size!\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_dummy_page_init(rdev);\r\nif (r)\r\nreturn r;\r\nrdev->gart.num_cpu_pages = rdev->mc.gtt_size / PAGE_SIZE;\r\nrdev->gart.num_gpu_pages = rdev->mc.gtt_size / RADEON_GPU_PAGE_SIZE;\r\nDRM_INFO("GART: num cpu pages %u, num gpu pages %u\n",\r\nrdev->gart.num_cpu_pages, rdev->gart.num_gpu_pages);\r\nrdev->gart.pages = vzalloc(sizeof(void *) * rdev->gart.num_cpu_pages);\r\nif (rdev->gart.pages == NULL) {\r\nradeon_gart_fini(rdev);\r\nreturn -ENOMEM;\r\n}\r\nrdev->gart.pages_entry = vmalloc(sizeof(uint64_t) *\r\nrdev->gart.num_gpu_pages);\r\nif (rdev->gart.pages_entry == NULL) {\r\nradeon_gart_fini(rdev);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < rdev->gart.num_gpu_pages; i++)\r\nrdev->gart.pages_entry[i] = rdev->dummy_page.entry;\r\nreturn 0;\r\n}\r\nvoid radeon_gart_fini(struct radeon_device *rdev)\r\n{\r\nif (rdev->gart.ready) {\r\nradeon_gart_unbind(rdev, 0, rdev->gart.num_cpu_pages);\r\n}\r\nrdev->gart.ready = false;\r\nvfree(rdev->gart.pages);\r\nvfree(rdev->gart.pages_entry);\r\nrdev->gart.pages = NULL;\r\nrdev->gart.pages_entry = NULL;\r\nradeon_dummy_page_fini(rdev);\r\n}
