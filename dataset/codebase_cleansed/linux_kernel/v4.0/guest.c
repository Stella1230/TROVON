int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)\r\n{\r\nreturn 0;\r\n}\r\nstatic u64 core_reg_offset_from_id(u64 id)\r\n{\r\nreturn id & ~(KVM_REG_ARCH_MASK | KVM_REG_SIZE_MASK | KVM_REG_ARM_CORE);\r\n}\r\nstatic int get_core_reg(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)\r\n{\r\nu32 __user *uaddr = (u32 __user *)(long)reg->addr;\r\nstruct kvm_regs *regs = &vcpu->arch.regs;\r\nu64 off;\r\nif (KVM_REG_SIZE(reg->id) != 4)\r\nreturn -ENOENT;\r\noff = core_reg_offset_from_id(reg->id);\r\nif (off >= sizeof(*regs) / KVM_REG_SIZE(reg->id))\r\nreturn -ENOENT;\r\nreturn put_user(((u32 *)regs)[off], uaddr);\r\n}\r\nstatic int set_core_reg(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)\r\n{\r\nu32 __user *uaddr = (u32 __user *)(long)reg->addr;\r\nstruct kvm_regs *regs = &vcpu->arch.regs;\r\nu64 off, val;\r\nif (KVM_REG_SIZE(reg->id) != 4)\r\nreturn -ENOENT;\r\noff = core_reg_offset_from_id(reg->id);\r\nif (off >= sizeof(*regs) / KVM_REG_SIZE(reg->id))\r\nreturn -ENOENT;\r\nif (get_user(val, uaddr) != 0)\r\nreturn -EFAULT;\r\nif (off == KVM_REG_ARM_CORE_REG(usr_regs.ARM_cpsr)) {\r\nunsigned long mode = val & MODE_MASK;\r\nswitch (mode) {\r\ncase USR_MODE:\r\ncase FIQ_MODE:\r\ncase IRQ_MODE:\r\ncase SVC_MODE:\r\ncase ABT_MODE:\r\ncase UND_MODE:\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\n((u32 *)regs)[off] = val;\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_get_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)\r\n{\r\nreturn -EINVAL;\r\n}\r\nstatic int copy_timer_indices(struct kvm_vcpu *vcpu, u64 __user *uindices)\r\n{\r\nreturn 0;\r\n}\r\nstatic bool is_timer_reg(u64 index)\r\n{\r\nreturn false;\r\n}\r\nstatic bool is_timer_reg(u64 index)\r\n{\r\nswitch (index) {\r\ncase KVM_REG_ARM_TIMER_CTL:\r\ncase KVM_REG_ARM_TIMER_CNT:\r\ncase KVM_REG_ARM_TIMER_CVAL:\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic int copy_timer_indices(struct kvm_vcpu *vcpu, u64 __user *uindices)\r\n{\r\nif (put_user(KVM_REG_ARM_TIMER_CTL, uindices))\r\nreturn -EFAULT;\r\nuindices++;\r\nif (put_user(KVM_REG_ARM_TIMER_CNT, uindices))\r\nreturn -EFAULT;\r\nuindices++;\r\nif (put_user(KVM_REG_ARM_TIMER_CVAL, uindices))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nstatic int set_timer_reg(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)\r\n{\r\nvoid __user *uaddr = (void __user *)(long)reg->addr;\r\nu64 val;\r\nint ret;\r\nret = copy_from_user(&val, uaddr, KVM_REG_SIZE(reg->id));\r\nif (ret != 0)\r\nreturn -EFAULT;\r\nreturn kvm_arm_timer_set_reg(vcpu, reg->id, val);\r\n}\r\nstatic int get_timer_reg(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)\r\n{\r\nvoid __user *uaddr = (void __user *)(long)reg->addr;\r\nu64 val;\r\nval = kvm_arm_timer_get_reg(vcpu, reg->id);\r\nreturn copy_to_user(uaddr, &val, KVM_REG_SIZE(reg->id));\r\n}\r\nstatic unsigned long num_core_regs(void)\r\n{\r\nreturn sizeof(struct kvm_regs) / sizeof(u32);\r\n}\r\nunsigned long kvm_arm_num_regs(struct kvm_vcpu *vcpu)\r\n{\r\nreturn num_core_regs() + kvm_arm_num_coproc_regs(vcpu)\r\n+ NUM_TIMER_REGS;\r\n}\r\nint kvm_arm_copy_reg_indices(struct kvm_vcpu *vcpu, u64 __user *uindices)\r\n{\r\nunsigned int i;\r\nconst u64 core_reg = KVM_REG_ARM | KVM_REG_SIZE_U32 | KVM_REG_ARM_CORE;\r\nint ret;\r\nfor (i = 0; i < sizeof(struct kvm_regs)/sizeof(u32); i++) {\r\nif (put_user(core_reg | i, uindices))\r\nreturn -EFAULT;\r\nuindices++;\r\n}\r\nret = copy_timer_indices(vcpu, uindices);\r\nif (ret)\r\nreturn ret;\r\nuindices += NUM_TIMER_REGS;\r\nreturn kvm_arm_copy_coproc_indices(vcpu, uindices);\r\n}\r\nint kvm_arm_get_reg(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)\r\n{\r\nif ((reg->id & ~KVM_REG_SIZE_MASK) >> 32 != KVM_REG_ARM >> 32)\r\nreturn -EINVAL;\r\nif ((reg->id & KVM_REG_ARM_COPROC_MASK) == KVM_REG_ARM_CORE)\r\nreturn get_core_reg(vcpu, reg);\r\nif (is_timer_reg(reg->id))\r\nreturn get_timer_reg(vcpu, reg);\r\nreturn kvm_arm_coproc_get_reg(vcpu, reg);\r\n}\r\nint kvm_arm_set_reg(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)\r\n{\r\nif ((reg->id & ~KVM_REG_SIZE_MASK) >> 32 != KVM_REG_ARM >> 32)\r\nreturn -EINVAL;\r\nif ((reg->id & KVM_REG_ARM_COPROC_MASK) == KVM_REG_ARM_CORE)\r\nreturn set_core_reg(vcpu, reg);\r\nif (is_timer_reg(reg->id))\r\nreturn set_timer_reg(vcpu, reg);\r\nreturn kvm_arm_coproc_set_reg(vcpu, reg);\r\n}\r\nint kvm_arch_vcpu_ioctl_get_sregs(struct kvm_vcpu *vcpu,\r\nstruct kvm_sregs *sregs)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_sregs(struct kvm_vcpu *vcpu,\r\nstruct kvm_sregs *sregs)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint __attribute_const__ kvm_target_cpu(void)\r\n{\r\nswitch (read_cpuid_part()) {\r\ncase ARM_CPU_PART_CORTEX_A7:\r\nreturn KVM_ARM_TARGET_CORTEX_A7;\r\ncase ARM_CPU_PART_CORTEX_A15:\r\nreturn KVM_ARM_TARGET_CORTEX_A15;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nint kvm_vcpu_preferred_target(struct kvm_vcpu_init *init)\r\n{\r\nint target = kvm_target_cpu();\r\nif (target < 0)\r\nreturn -ENODEV;\r\nmemset(init, 0, sizeof(*init));\r\ninit->target = (__u32)target;\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_get_fpu(struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_fpu(struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint kvm_arch_vcpu_ioctl_translate(struct kvm_vcpu *vcpu,\r\nstruct kvm_translation *tr)\r\n{\r\nreturn -EINVAL;\r\n}
