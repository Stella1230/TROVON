static inline struct ip_vs_dest_dst *ip_vs_dest_dst_alloc(void)\r\n{\r\nreturn kmalloc(sizeof(struct ip_vs_dest_dst), GFP_ATOMIC);\r\n}\r\nstatic inline void ip_vs_dest_dst_free(struct ip_vs_dest_dst *dest_dst)\r\n{\r\nkfree(dest_dst);\r\n}\r\nstatic inline void\r\n__ip_vs_dst_set(struct ip_vs_dest *dest, struct ip_vs_dest_dst *dest_dst,\r\nstruct dst_entry *dst, u32 dst_cookie)\r\n{\r\nstruct ip_vs_dest_dst *old;\r\nold = rcu_dereference_protected(dest->dest_dst,\r\nlockdep_is_held(&dest->dst_lock));\r\nif (dest_dst) {\r\ndest_dst->dst_cache = dst;\r\ndest_dst->dst_cookie = dst_cookie;\r\n}\r\nrcu_assign_pointer(dest->dest_dst, dest_dst);\r\nif (old)\r\ncall_rcu(&old->rcu_head, ip_vs_dest_dst_rcu_free);\r\n}\r\nstatic inline struct ip_vs_dest_dst *\r\n__ip_vs_dst_check(struct ip_vs_dest *dest)\r\n{\r\nstruct ip_vs_dest_dst *dest_dst = rcu_dereference(dest->dest_dst);\r\nstruct dst_entry *dst;\r\nif (!dest_dst)\r\nreturn NULL;\r\ndst = dest_dst->dst_cache;\r\nif (dst->obsolete &&\r\ndst->ops->check(dst, dest_dst->dst_cookie) == NULL)\r\nreturn NULL;\r\nreturn dest_dst;\r\n}\r\nstatic inline bool\r\n__mtu_check_toobig_v6(const struct sk_buff *skb, u32 mtu)\r\n{\r\nif (IP6CB(skb)->frag_max_size) {\r\nif (IP6CB(skb)->frag_max_size > mtu)\r\nreturn true;\r\n}\r\nelse if (skb->len > mtu && !skb_is_gso(skb)) {\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic struct rtable *do_output_route4(struct net *net, __be32 daddr,\r\nint rt_mode, __be32 *saddr)\r\n{\r\nstruct flowi4 fl4;\r\nstruct rtable *rt;\r\nint loop = 0;\r\nmemset(&fl4, 0, sizeof(fl4));\r\nfl4.daddr = daddr;\r\nfl4.saddr = (rt_mode & IP_VS_RT_MODE_CONNECT) ? *saddr : 0;\r\nfl4.flowi4_flags = (rt_mode & IP_VS_RT_MODE_KNOWN_NH) ?\r\nFLOWI_FLAG_KNOWN_NH : 0;\r\nretry:\r\nrt = ip_route_output_key(net, &fl4);\r\nif (IS_ERR(rt)) {\r\nif (PTR_ERR(rt) == -EINVAL && *saddr &&\r\nrt_mode & IP_VS_RT_MODE_CONNECT && !loop) {\r\n*saddr = 0;\r\nflowi4_update_output(&fl4, 0, 0, daddr, 0);\r\ngoto retry;\r\n}\r\nIP_VS_DBG_RL("ip_route_output error, dest: %pI4\n", &daddr);\r\nreturn NULL;\r\n} else if (!*saddr && rt_mode & IP_VS_RT_MODE_CONNECT && fl4.saddr) {\r\nip_rt_put(rt);\r\n*saddr = fl4.saddr;\r\nflowi4_update_output(&fl4, 0, 0, daddr, fl4.saddr);\r\nloop++;\r\ngoto retry;\r\n}\r\n*saddr = fl4.saddr;\r\nreturn rt;\r\n}\r\nstatic inline int __ip_vs_is_local_route6(struct rt6_info *rt)\r\n{\r\nreturn rt->dst.dev && rt->dst.dev->flags & IFF_LOOPBACK;\r\n}\r\nstatic inline bool crosses_local_route_boundary(int skb_af, struct sk_buff *skb,\r\nint rt_mode,\r\nbool new_rt_is_local)\r\n{\r\nbool rt_mode_allow_local = !!(rt_mode & IP_VS_RT_MODE_LOCAL);\r\nbool rt_mode_allow_non_local = !!(rt_mode & IP_VS_RT_MODE_LOCAL);\r\nbool rt_mode_allow_redirect = !!(rt_mode & IP_VS_RT_MODE_RDR);\r\nbool source_is_loopback;\r\nbool old_rt_is_local;\r\n#ifdef CONFIG_IP_VS_IPV6\r\nif (skb_af == AF_INET6) {\r\nint addr_type = ipv6_addr_type(&ipv6_hdr(skb)->saddr);\r\nsource_is_loopback =\r\n(!skb->dev || skb->dev->flags & IFF_LOOPBACK) &&\r\n(addr_type & IPV6_ADDR_LOOPBACK);\r\nold_rt_is_local = __ip_vs_is_local_route6(\r\n(struct rt6_info *)skb_dst(skb));\r\n} else\r\n#endif\r\n{\r\nsource_is_loopback = ipv4_is_loopback(ip_hdr(skb)->saddr);\r\nold_rt_is_local = skb_rtable(skb)->rt_flags & RTCF_LOCAL;\r\n}\r\nif (unlikely(new_rt_is_local)) {\r\nif (!rt_mode_allow_local)\r\nreturn true;\r\nif (!rt_mode_allow_redirect && !old_rt_is_local)\r\nreturn true;\r\n} else {\r\nif (!rt_mode_allow_non_local)\r\nreturn true;\r\nif (source_is_loopback)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic inline void maybe_update_pmtu(int skb_af, struct sk_buff *skb, int mtu)\r\n{\r\nstruct sock *sk = skb->sk;\r\nstruct rtable *ort = skb_rtable(skb);\r\nif (!skb->dev && sk && sk->sk_state != TCP_TIME_WAIT)\r\nort->dst.ops->update_pmtu(&ort->dst, sk, NULL, mtu);\r\n}\r\nstatic inline bool ensure_mtu_is_adequate(int skb_af, int rt_mode,\r\nstruct ip_vs_iphdr *ipvsh,\r\nstruct sk_buff *skb, int mtu)\r\n{\r\n#ifdef CONFIG_IP_VS_IPV6\r\nif (skb_af == AF_INET6) {\r\nstruct net *net = dev_net(skb_dst(skb)->dev);\r\nif (unlikely(__mtu_check_toobig_v6(skb, mtu))) {\r\nif (!skb->dev)\r\nskb->dev = net->loopback_dev;\r\nif (!ipvsh->fragoffs)\r\nicmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu);\r\nIP_VS_DBG(1, "frag needed for %pI6c\n",\r\n&ipv6_hdr(skb)->saddr);\r\nreturn false;\r\n}\r\n} else\r\n#endif\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(skb_net(skb));\r\nif ((rt_mode & IP_VS_RT_MODE_TUNNEL) && !sysctl_pmtu_disc(ipvs))\r\nreturn true;\r\nif (unlikely(ip_hdr(skb)->frag_off & htons(IP_DF) &&\r\nskb->len > mtu && !skb_is_gso(skb))) {\r\nicmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,\r\nhtonl(mtu));\r\nIP_VS_DBG(1, "frag needed for %pI4\n",\r\n&ip_hdr(skb)->saddr);\r\nreturn false;\r\n}\r\n}\r\nreturn true;\r\n}\r\nstatic int\r\n__ip_vs_get_out_rt(int skb_af, struct sk_buff *skb, struct ip_vs_dest *dest,\r\n__be32 daddr, int rt_mode, __be32 *ret_saddr,\r\nstruct ip_vs_iphdr *ipvsh)\r\n{\r\nstruct net *net = dev_net(skb_dst(skb)->dev);\r\nstruct ip_vs_dest_dst *dest_dst;\r\nstruct rtable *rt;\r\nint mtu;\r\nint local, noref = 1;\r\nif (dest) {\r\ndest_dst = __ip_vs_dst_check(dest);\r\nif (likely(dest_dst))\r\nrt = (struct rtable *) dest_dst->dst_cache;\r\nelse {\r\ndest_dst = ip_vs_dest_dst_alloc();\r\nspin_lock_bh(&dest->dst_lock);\r\nif (!dest_dst) {\r\n__ip_vs_dst_set(dest, NULL, NULL, 0);\r\nspin_unlock_bh(&dest->dst_lock);\r\ngoto err_unreach;\r\n}\r\nrt = do_output_route4(net, dest->addr.ip, rt_mode,\r\n&dest_dst->dst_saddr.ip);\r\nif (!rt) {\r\n__ip_vs_dst_set(dest, NULL, NULL, 0);\r\nspin_unlock_bh(&dest->dst_lock);\r\nip_vs_dest_dst_free(dest_dst);\r\ngoto err_unreach;\r\n}\r\n__ip_vs_dst_set(dest, dest_dst, &rt->dst, 0);\r\nspin_unlock_bh(&dest->dst_lock);\r\nIP_VS_DBG(10, "new dst %pI4, src %pI4, refcnt=%d\n",\r\n&dest->addr.ip, &dest_dst->dst_saddr.ip,\r\natomic_read(&rt->dst.__refcnt));\r\n}\r\nif (ret_saddr)\r\n*ret_saddr = dest_dst->dst_saddr.ip;\r\n} else {\r\n__be32 saddr = htonl(INADDR_ANY);\r\nnoref = 0;\r\nrt_mode &= ~IP_VS_RT_MODE_CONNECT;\r\nrt = do_output_route4(net, daddr, rt_mode, &saddr);\r\nif (!rt)\r\ngoto err_unreach;\r\nif (ret_saddr)\r\n*ret_saddr = saddr;\r\n}\r\nlocal = (rt->rt_flags & RTCF_LOCAL) ? 1 : 0;\r\nif (unlikely(crosses_local_route_boundary(skb_af, skb, rt_mode,\r\nlocal))) {\r\nIP_VS_DBG_RL("We are crossing local and non-local addresses"\r\n" daddr=%pI4\n", &daddr);\r\ngoto err_put;\r\n}\r\nif (unlikely(local)) {\r\nif (!noref)\r\nip_rt_put(rt);\r\nreturn local;\r\n}\r\nif (likely(!(rt_mode & IP_VS_RT_MODE_TUNNEL))) {\r\nmtu = dst_mtu(&rt->dst);\r\n} else {\r\nmtu = dst_mtu(&rt->dst) - sizeof(struct iphdr);\r\nif (mtu < 68) {\r\nIP_VS_DBG_RL("%s(): mtu less than 68\n", __func__);\r\ngoto err_put;\r\n}\r\nmaybe_update_pmtu(skb_af, skb, mtu);\r\n}\r\nif (!ensure_mtu_is_adequate(skb_af, rt_mode, ipvsh, skb, mtu))\r\ngoto err_put;\r\nskb_dst_drop(skb);\r\nif (noref) {\r\nif (!local)\r\nskb_dst_set_noref(skb, &rt->dst);\r\nelse\r\nskb_dst_set(skb, dst_clone(&rt->dst));\r\n} else\r\nskb_dst_set(skb, &rt->dst);\r\nreturn local;\r\nerr_put:\r\nif (!noref)\r\nip_rt_put(rt);\r\nreturn -1;\r\nerr_unreach:\r\ndst_link_failure(skb);\r\nreturn -1;\r\n}\r\nstatic struct dst_entry *\r\n__ip_vs_route_output_v6(struct net *net, struct in6_addr *daddr,\r\nstruct in6_addr *ret_saddr, int do_xfrm)\r\n{\r\nstruct dst_entry *dst;\r\nstruct flowi6 fl6 = {\r\n.daddr = *daddr,\r\n};\r\ndst = ip6_route_output(net, NULL, &fl6);\r\nif (dst->error)\r\ngoto out_err;\r\nif (!ret_saddr)\r\nreturn dst;\r\nif (ipv6_addr_any(&fl6.saddr) &&\r\nipv6_dev_get_saddr(net, ip6_dst_idev(dst)->dev,\r\n&fl6.daddr, 0, &fl6.saddr) < 0)\r\ngoto out_err;\r\nif (do_xfrm) {\r\ndst = xfrm_lookup(net, dst, flowi6_to_flowi(&fl6), NULL, 0);\r\nif (IS_ERR(dst)) {\r\ndst = NULL;\r\ngoto out_err;\r\n}\r\n}\r\n*ret_saddr = fl6.saddr;\r\nreturn dst;\r\nout_err:\r\ndst_release(dst);\r\nIP_VS_DBG_RL("ip6_route_output error, dest: %pI6\n", daddr);\r\nreturn NULL;\r\n}\r\nstatic int\r\n__ip_vs_get_out_rt_v6(int skb_af, struct sk_buff *skb, struct ip_vs_dest *dest,\r\nstruct in6_addr *daddr, struct in6_addr *ret_saddr,\r\nstruct ip_vs_iphdr *ipvsh, int do_xfrm, int rt_mode)\r\n{\r\nstruct net *net = dev_net(skb_dst(skb)->dev);\r\nstruct ip_vs_dest_dst *dest_dst;\r\nstruct rt6_info *rt;\r\nstruct dst_entry *dst;\r\nint mtu;\r\nint local, noref = 1;\r\nif (dest) {\r\ndest_dst = __ip_vs_dst_check(dest);\r\nif (likely(dest_dst))\r\nrt = (struct rt6_info *) dest_dst->dst_cache;\r\nelse {\r\nu32 cookie;\r\ndest_dst = ip_vs_dest_dst_alloc();\r\nspin_lock_bh(&dest->dst_lock);\r\nif (!dest_dst) {\r\n__ip_vs_dst_set(dest, NULL, NULL, 0);\r\nspin_unlock_bh(&dest->dst_lock);\r\ngoto err_unreach;\r\n}\r\ndst = __ip_vs_route_output_v6(net, &dest->addr.in6,\r\n&dest_dst->dst_saddr.in6,\r\ndo_xfrm);\r\nif (!dst) {\r\n__ip_vs_dst_set(dest, NULL, NULL, 0);\r\nspin_unlock_bh(&dest->dst_lock);\r\nip_vs_dest_dst_free(dest_dst);\r\ngoto err_unreach;\r\n}\r\nrt = (struct rt6_info *) dst;\r\ncookie = rt->rt6i_node ? rt->rt6i_node->fn_sernum : 0;\r\n__ip_vs_dst_set(dest, dest_dst, &rt->dst, cookie);\r\nspin_unlock_bh(&dest->dst_lock);\r\nIP_VS_DBG(10, "new dst %pI6, src %pI6, refcnt=%d\n",\r\n&dest->addr.in6, &dest_dst->dst_saddr.in6,\r\natomic_read(&rt->dst.__refcnt));\r\n}\r\nif (ret_saddr)\r\n*ret_saddr = dest_dst->dst_saddr.in6;\r\n} else {\r\nnoref = 0;\r\ndst = __ip_vs_route_output_v6(net, daddr, ret_saddr, do_xfrm);\r\nif (!dst)\r\ngoto err_unreach;\r\nrt = (struct rt6_info *) dst;\r\n}\r\nlocal = __ip_vs_is_local_route6(rt);\r\nif (unlikely(crosses_local_route_boundary(skb_af, skb, rt_mode,\r\nlocal))) {\r\nIP_VS_DBG_RL("We are crossing local and non-local addresses"\r\n" daddr=%pI6\n", daddr);\r\ngoto err_put;\r\n}\r\nif (unlikely(local)) {\r\nif (!noref)\r\ndst_release(&rt->dst);\r\nreturn local;\r\n}\r\nif (likely(!(rt_mode & IP_VS_RT_MODE_TUNNEL)))\r\nmtu = dst_mtu(&rt->dst);\r\nelse {\r\nmtu = dst_mtu(&rt->dst) - sizeof(struct ipv6hdr);\r\nif (mtu < IPV6_MIN_MTU) {\r\nIP_VS_DBG_RL("%s(): mtu less than %d\n", __func__,\r\nIPV6_MIN_MTU);\r\ngoto err_put;\r\n}\r\nmaybe_update_pmtu(skb_af, skb, mtu);\r\n}\r\nif (!ensure_mtu_is_adequate(skb_af, rt_mode, ipvsh, skb, mtu))\r\ngoto err_put;\r\nskb_dst_drop(skb);\r\nif (noref) {\r\nif (!local)\r\nskb_dst_set_noref(skb, &rt->dst);\r\nelse\r\nskb_dst_set(skb, dst_clone(&rt->dst));\r\n} else\r\nskb_dst_set(skb, &rt->dst);\r\nreturn local;\r\nerr_put:\r\nif (!noref)\r\ndst_release(&rt->dst);\r\nreturn -1;\r\nerr_unreach:\r\ndst_link_failure(skb);\r\nreturn -1;\r\n}\r\nstatic inline int ip_vs_tunnel_xmit_prepare(struct sk_buff *skb,\r\nstruct ip_vs_conn *cp)\r\n{\r\nint ret = NF_ACCEPT;\r\nskb->ipvs_property = 1;\r\nif (unlikely(cp->flags & IP_VS_CONN_F_NFCT))\r\nret = ip_vs_confirm_conntrack(skb);\r\nif (ret == NF_ACCEPT) {\r\nnf_reset(skb);\r\nskb_forward_csum(skb);\r\n}\r\nreturn ret;\r\n}\r\nstatic inline int ip_vs_nat_send_or_cont(int pf, struct sk_buff *skb,\r\nstruct ip_vs_conn *cp, int local)\r\n{\r\nint ret = NF_STOLEN;\r\nskb->ipvs_property = 1;\r\nif (likely(!(cp->flags & IP_VS_CONN_F_NFCT)))\r\nip_vs_notrack(skb);\r\nelse\r\nip_vs_update_conntrack(skb, cp, 1);\r\nif (!local) {\r\nskb_forward_csum(skb);\r\nNF_HOOK(pf, NF_INET_LOCAL_OUT, skb, NULL, skb_dst(skb)->dev,\r\ndst_output);\r\n} else\r\nret = NF_ACCEPT;\r\nreturn ret;\r\n}\r\nstatic inline int ip_vs_send_or_cont(int pf, struct sk_buff *skb,\r\nstruct ip_vs_conn *cp, int local)\r\n{\r\nint ret = NF_STOLEN;\r\nskb->ipvs_property = 1;\r\nif (likely(!(cp->flags & IP_VS_CONN_F_NFCT)))\r\nip_vs_notrack(skb);\r\nif (!local) {\r\nskb_forward_csum(skb);\r\nNF_HOOK(pf, NF_INET_LOCAL_OUT, skb, NULL, skb_dst(skb)->dev,\r\ndst_output);\r\n} else\r\nret = NF_ACCEPT;\r\nreturn ret;\r\n}\r\nint\r\nip_vs_null_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nreturn ip_vs_send_or_cont(NFPROTO_IPV4, skb, cp, 1);\r\n}\r\nint\r\nip_vs_bypass_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nstruct iphdr *iph = ip_hdr(skb);\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nif (__ip_vs_get_out_rt(cp->af, skb, NULL, iph->daddr,\r\nIP_VS_RT_MODE_NON_LOCAL, NULL, ipvsh) < 0)\r\ngoto tx_error;\r\nip_send_check(iph);\r\nskb->ignore_df = 1;\r\nip_vs_send_or_cont(NFPROTO_IPV4, skb, cp, 0);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\ntx_error:\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\n}\r\nint\r\nip_vs_bypass_xmit_v6(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nif (__ip_vs_get_out_rt_v6(cp->af, skb, NULL, &ipvsh->daddr.in6, NULL,\r\nipvsh, 0, IP_VS_RT_MODE_NON_LOCAL) < 0)\r\ngoto tx_error;\r\nskb->ignore_df = 1;\r\nip_vs_send_or_cont(NFPROTO_IPV6, skb, cp, 0);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\ntx_error:\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\n}\r\nint\r\nip_vs_nat_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nstruct rtable *rt;\r\nint local, rc, was_input;\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nif (unlikely(cp->flags & IP_VS_CONN_F_NO_CPORT)) {\r\n__be16 _pt, *p;\r\np = skb_header_pointer(skb, ipvsh->len, sizeof(_pt), &_pt);\r\nif (p == NULL)\r\ngoto tx_error;\r\nip_vs_conn_fill_cport(cp, *p);\r\nIP_VS_DBG(10, "filled cport=%d\n", ntohs(*p));\r\n}\r\nwas_input = rt_is_input_route(skb_rtable(skb));\r\nlocal = __ip_vs_get_out_rt(cp->af, skb, cp->dest, cp->daddr.ip,\r\nIP_VS_RT_MODE_LOCAL |\r\nIP_VS_RT_MODE_NON_LOCAL |\r\nIP_VS_RT_MODE_RDR, NULL, ipvsh);\r\nif (local < 0)\r\ngoto tx_error;\r\nrt = skb_rtable(skb);\r\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\r\nif (cp->flags & IP_VS_CONN_F_SYNC && local) {\r\nenum ip_conntrack_info ctinfo;\r\nstruct nf_conn *ct = nf_ct_get(skb, &ctinfo);\r\nif (ct && !nf_ct_is_untracked(ct)) {\r\nIP_VS_DBG_RL_PKT(10, AF_INET, pp, skb, 0,\r\n"ip_vs_nat_xmit(): "\r\n"stopping DNAT to local address");\r\ngoto tx_error;\r\n}\r\n}\r\n#endif\r\nif (local && ipv4_is_loopback(cp->daddr.ip) && was_input) {\r\nIP_VS_DBG_RL_PKT(1, AF_INET, pp, skb, 0, "ip_vs_nat_xmit(): "\r\n"stopping DNAT to loopback address");\r\ngoto tx_error;\r\n}\r\nif (!skb_make_writable(skb, sizeof(struct iphdr)))\r\ngoto tx_error;\r\nif (skb_cow(skb, rt->dst.dev->hard_header_len))\r\ngoto tx_error;\r\nif (pp->dnat_handler && !pp->dnat_handler(skb, pp, cp, ipvsh))\r\ngoto tx_error;\r\nip_hdr(skb)->daddr = cp->daddr.ip;\r\nip_send_check(ip_hdr(skb));\r\nIP_VS_DBG_PKT(10, AF_INET, pp, skb, 0, "After DNAT");\r\nskb->ignore_df = 1;\r\nrc = ip_vs_nat_send_or_cont(NFPROTO_IPV4, skb, cp, local);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn rc;\r\ntx_error:\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\n}\r\nint\r\nip_vs_nat_xmit_v6(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nstruct rt6_info *rt;\r\nint local, rc;\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nif (unlikely(cp->flags & IP_VS_CONN_F_NO_CPORT && !ipvsh->fragoffs)) {\r\n__be16 _pt, *p;\r\np = skb_header_pointer(skb, ipvsh->len, sizeof(_pt), &_pt);\r\nif (p == NULL)\r\ngoto tx_error;\r\nip_vs_conn_fill_cport(cp, *p);\r\nIP_VS_DBG(10, "filled cport=%d\n", ntohs(*p));\r\n}\r\nlocal = __ip_vs_get_out_rt_v6(cp->af, skb, cp->dest, &cp->daddr.in6,\r\nNULL, ipvsh, 0,\r\nIP_VS_RT_MODE_LOCAL |\r\nIP_VS_RT_MODE_NON_LOCAL |\r\nIP_VS_RT_MODE_RDR);\r\nif (local < 0)\r\ngoto tx_error;\r\nrt = (struct rt6_info *) skb_dst(skb);\r\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\r\nif (cp->flags & IP_VS_CONN_F_SYNC && local) {\r\nenum ip_conntrack_info ctinfo;\r\nstruct nf_conn *ct = nf_ct_get(skb, &ctinfo);\r\nif (ct && !nf_ct_is_untracked(ct)) {\r\nIP_VS_DBG_RL_PKT(10, AF_INET6, pp, skb, 0,\r\n"ip_vs_nat_xmit_v6(): "\r\n"stopping DNAT to local address");\r\ngoto tx_error;\r\n}\r\n}\r\n#endif\r\nif (local && skb->dev && !(skb->dev->flags & IFF_LOOPBACK) &&\r\nipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_LOOPBACK) {\r\nIP_VS_DBG_RL_PKT(1, AF_INET6, pp, skb, 0,\r\n"ip_vs_nat_xmit_v6(): "\r\n"stopping DNAT to loopback address");\r\ngoto tx_error;\r\n}\r\nif (!skb_make_writable(skb, sizeof(struct ipv6hdr)))\r\ngoto tx_error;\r\nif (skb_cow(skb, rt->dst.dev->hard_header_len))\r\ngoto tx_error;\r\nif (pp->dnat_handler && !pp->dnat_handler(skb, pp, cp, ipvsh))\r\ngoto tx_error;\r\nipv6_hdr(skb)->daddr = cp->daddr.in6;\r\nIP_VS_DBG_PKT(10, AF_INET6, pp, skb, 0, "After DNAT");\r\nskb->ignore_df = 1;\r\nrc = ip_vs_nat_send_or_cont(NFPROTO_IPV6, skb, cp, local);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn rc;\r\ntx_error:\r\nLeaveFunction(10);\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nreturn NF_STOLEN;\r\n}\r\nstatic struct sk_buff *\r\nip_vs_prepare_tunneled_skb(struct sk_buff *skb, int skb_af,\r\nunsigned int max_headroom, __u8 *next_protocol,\r\n__u32 *payload_len, __u8 *dsfield, __u8 *ttl,\r\n__be16 *df)\r\n{\r\nstruct sk_buff *new_skb = NULL;\r\nstruct iphdr *old_iph = NULL;\r\n#ifdef CONFIG_IP_VS_IPV6\r\nstruct ipv6hdr *old_ipv6h = NULL;\r\n#endif\r\nif (skb_headroom(skb) < max_headroom || skb_cloned(skb)) {\r\nnew_skb = skb_realloc_headroom(skb, max_headroom);\r\nif (!new_skb)\r\ngoto error;\r\nif (skb->sk)\r\nskb_set_owner_w(new_skb, skb->sk);\r\nconsume_skb(skb);\r\nskb = new_skb;\r\n}\r\n#ifdef CONFIG_IP_VS_IPV6\r\nif (skb_af == AF_INET6) {\r\nold_ipv6h = ipv6_hdr(skb);\r\n*next_protocol = IPPROTO_IPV6;\r\nif (payload_len)\r\n*payload_len =\r\nntohs(old_ipv6h->payload_len) +\r\nsizeof(*old_ipv6h);\r\n*dsfield = ipv6_get_dsfield(old_ipv6h);\r\n*ttl = old_ipv6h->hop_limit;\r\nif (df)\r\n*df = 0;\r\n} else\r\n#endif\r\n{\r\nold_iph = ip_hdr(skb);\r\nif (df)\r\n*df = (old_iph->frag_off & htons(IP_DF));\r\n*next_protocol = IPPROTO_IPIP;\r\nip_send_check(old_iph);\r\n*dsfield = ipv4_get_dsfield(old_iph);\r\n*ttl = old_iph->ttl;\r\nif (payload_len)\r\n*payload_len = ntohs(old_iph->tot_len);\r\n}\r\nreturn skb;\r\nerror:\r\nkfree_skb(skb);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nstatic inline int __tun_gso_type_mask(int encaps_af, int orig_af)\r\n{\r\nif (encaps_af == AF_INET) {\r\nif (orig_af == AF_INET)\r\nreturn SKB_GSO_IPIP;\r\nreturn SKB_GSO_SIT;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nip_vs_tunnel_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(skb_net(skb));\r\nstruct rtable *rt;\r\n__be32 saddr;\r\nstruct net_device *tdev;\r\n__u8 next_protocol = 0;\r\n__u8 dsfield = 0;\r\n__u8 ttl = 0;\r\n__be16 df = 0;\r\n__be16 *dfp = NULL;\r\nstruct iphdr *iph;\r\nunsigned int max_headroom;\r\nint ret, local;\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nlocal = __ip_vs_get_out_rt(cp->af, skb, cp->dest, cp->daddr.ip,\r\nIP_VS_RT_MODE_LOCAL |\r\nIP_VS_RT_MODE_NON_LOCAL |\r\nIP_VS_RT_MODE_CONNECT |\r\nIP_VS_RT_MODE_TUNNEL, &saddr, ipvsh);\r\nif (local < 0)\r\ngoto tx_error;\r\nif (local) {\r\nrcu_read_unlock();\r\nreturn ip_vs_send_or_cont(NFPROTO_IPV4, skb, cp, 1);\r\n}\r\nrt = skb_rtable(skb);\r\ntdev = rt->dst.dev;\r\nmax_headroom = LL_RESERVED_SPACE(tdev) + sizeof(struct iphdr);\r\ndfp = sysctl_pmtu_disc(ipvs) ? &df : NULL;\r\nskb = ip_vs_prepare_tunneled_skb(skb, cp->af, max_headroom,\r\n&next_protocol, NULL, &dsfield,\r\n&ttl, dfp);\r\nif (IS_ERR(skb))\r\ngoto tx_error;\r\nskb = iptunnel_handle_offloads(\r\nskb, false, __tun_gso_type_mask(AF_INET, cp->af));\r\nif (IS_ERR(skb))\r\ngoto tx_error;\r\nskb->transport_header = skb->network_header;\r\nskb_push(skb, sizeof(struct iphdr));\r\nskb_reset_network_header(skb);\r\nmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\r\niph = ip_hdr(skb);\r\niph->version = 4;\r\niph->ihl = sizeof(struct iphdr)>>2;\r\niph->frag_off = df;\r\niph->protocol = next_protocol;\r\niph->tos = dsfield;\r\niph->daddr = cp->daddr.ip;\r\niph->saddr = saddr;\r\niph->ttl = ttl;\r\nip_select_ident(skb, NULL);\r\nskb->ignore_df = 1;\r\nret = ip_vs_tunnel_xmit_prepare(skb, cp);\r\nif (ret == NF_ACCEPT)\r\nip_local_out(skb);\r\nelse if (ret == NF_DROP)\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\ntx_error:\r\nif (!IS_ERR(skb))\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\n}\r\nint\r\nip_vs_tunnel_xmit_v6(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nstruct rt6_info *rt;\r\nstruct in6_addr saddr;\r\nstruct net_device *tdev;\r\n__u8 next_protocol = 0;\r\n__u32 payload_len = 0;\r\n__u8 dsfield = 0;\r\n__u8 ttl = 0;\r\nstruct ipv6hdr *iph;\r\nunsigned int max_headroom;\r\nint ret, local;\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nlocal = __ip_vs_get_out_rt_v6(cp->af, skb, cp->dest, &cp->daddr.in6,\r\n&saddr, ipvsh, 1,\r\nIP_VS_RT_MODE_LOCAL |\r\nIP_VS_RT_MODE_NON_LOCAL |\r\nIP_VS_RT_MODE_TUNNEL);\r\nif (local < 0)\r\ngoto tx_error;\r\nif (local) {\r\nrcu_read_unlock();\r\nreturn ip_vs_send_or_cont(NFPROTO_IPV6, skb, cp, 1);\r\n}\r\nrt = (struct rt6_info *) skb_dst(skb);\r\ntdev = rt->dst.dev;\r\nmax_headroom = LL_RESERVED_SPACE(tdev) + sizeof(struct ipv6hdr);\r\nskb = ip_vs_prepare_tunneled_skb(skb, cp->af, max_headroom,\r\n&next_protocol, &payload_len,\r\n&dsfield, &ttl, NULL);\r\nif (IS_ERR(skb))\r\ngoto tx_error;\r\nskb = iptunnel_handle_offloads(\r\nskb, false, __tun_gso_type_mask(AF_INET6, cp->af));\r\nif (IS_ERR(skb))\r\ngoto tx_error;\r\nskb->transport_header = skb->network_header;\r\nskb_push(skb, sizeof(struct ipv6hdr));\r\nskb_reset_network_header(skb);\r\nmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\r\niph = ipv6_hdr(skb);\r\niph->version = 6;\r\niph->nexthdr = next_protocol;\r\niph->payload_len = htons(payload_len);\r\nmemset(&iph->flow_lbl, 0, sizeof(iph->flow_lbl));\r\nipv6_change_dsfield(iph, 0, dsfield);\r\niph->daddr = cp->daddr.in6;\r\niph->saddr = saddr;\r\niph->hop_limit = ttl;\r\nskb->ignore_df = 1;\r\nret = ip_vs_tunnel_xmit_prepare(skb, cp);\r\nif (ret == NF_ACCEPT)\r\nip6_local_out(skb);\r\nelse if (ret == NF_DROP)\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\ntx_error:\r\nif (!IS_ERR(skb))\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\n}\r\nint\r\nip_vs_dr_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nint local;\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nlocal = __ip_vs_get_out_rt(cp->af, skb, cp->dest, cp->daddr.ip,\r\nIP_VS_RT_MODE_LOCAL |\r\nIP_VS_RT_MODE_NON_LOCAL |\r\nIP_VS_RT_MODE_KNOWN_NH, NULL, ipvsh);\r\nif (local < 0)\r\ngoto tx_error;\r\nif (local) {\r\nrcu_read_unlock();\r\nreturn ip_vs_send_or_cont(NFPROTO_IPV4, skb, cp, 1);\r\n}\r\nip_send_check(ip_hdr(skb));\r\nskb->ignore_df = 1;\r\nip_vs_send_or_cont(NFPROTO_IPV4, skb, cp, 0);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\ntx_error:\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\n}\r\nint\r\nip_vs_dr_xmit_v6(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, struct ip_vs_iphdr *ipvsh)\r\n{\r\nint local;\r\nEnterFunction(10);\r\nrcu_read_lock();\r\nlocal = __ip_vs_get_out_rt_v6(cp->af, skb, cp->dest, &cp->daddr.in6,\r\nNULL, ipvsh, 0,\r\nIP_VS_RT_MODE_LOCAL |\r\nIP_VS_RT_MODE_NON_LOCAL);\r\nif (local < 0)\r\ngoto tx_error;\r\nif (local) {\r\nrcu_read_unlock();\r\nreturn ip_vs_send_or_cont(NFPROTO_IPV6, skb, cp, 1);\r\n}\r\nskb->ignore_df = 1;\r\nip_vs_send_or_cont(NFPROTO_IPV6, skb, cp, 0);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\ntx_error:\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nLeaveFunction(10);\r\nreturn NF_STOLEN;\r\n}\r\nint\r\nip_vs_icmp_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, int offset, unsigned int hooknum,\r\nstruct ip_vs_iphdr *iph)\r\n{\r\nstruct rtable *rt;\r\nint rc;\r\nint local;\r\nint rt_mode, was_input;\r\nEnterFunction(10);\r\nif (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ) {\r\nif (cp->packet_xmit)\r\nrc = cp->packet_xmit(skb, cp, pp, iph);\r\nelse\r\nrc = NF_ACCEPT;\r\natomic_inc(&cp->in_pkts);\r\ngoto out;\r\n}\r\nwas_input = rt_is_input_route(skb_rtable(skb));\r\nrt_mode = (hooknum != NF_INET_FORWARD) ?\r\nIP_VS_RT_MODE_LOCAL | IP_VS_RT_MODE_NON_LOCAL |\r\nIP_VS_RT_MODE_RDR : IP_VS_RT_MODE_NON_LOCAL;\r\nrcu_read_lock();\r\nlocal = __ip_vs_get_out_rt(cp->af, skb, cp->dest, cp->daddr.ip, rt_mode,\r\nNULL, iph);\r\nif (local < 0)\r\ngoto tx_error;\r\nrt = skb_rtable(skb);\r\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\r\nif (cp->flags & IP_VS_CONN_F_SYNC && local) {\r\nenum ip_conntrack_info ctinfo;\r\nstruct nf_conn *ct = nf_ct_get(skb, &ctinfo);\r\nif (ct && !nf_ct_is_untracked(ct)) {\r\nIP_VS_DBG(10, "%s(): "\r\n"stopping DNAT to local address %pI4\n",\r\n__func__, &cp->daddr.ip);\r\ngoto tx_error;\r\n}\r\n}\r\n#endif\r\nif (local && ipv4_is_loopback(cp->daddr.ip) && was_input) {\r\nIP_VS_DBG(1, "%s(): "\r\n"stopping DNAT to loopback %pI4\n",\r\n__func__, &cp->daddr.ip);\r\ngoto tx_error;\r\n}\r\nif (!skb_make_writable(skb, offset))\r\ngoto tx_error;\r\nif (skb_cow(skb, rt->dst.dev->hard_header_len))\r\ngoto tx_error;\r\nip_vs_nat_icmp(skb, pp, cp, 0);\r\nskb->ignore_df = 1;\r\nrc = ip_vs_nat_send_or_cont(NFPROTO_IPV4, skb, cp, local);\r\nrcu_read_unlock();\r\ngoto out;\r\ntx_error:\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nrc = NF_STOLEN;\r\nout:\r\nLeaveFunction(10);\r\nreturn rc;\r\n}\r\nint\r\nip_vs_icmp_xmit_v6(struct sk_buff *skb, struct ip_vs_conn *cp,\r\nstruct ip_vs_protocol *pp, int offset, unsigned int hooknum,\r\nstruct ip_vs_iphdr *ipvsh)\r\n{\r\nstruct rt6_info *rt;\r\nint rc;\r\nint local;\r\nint rt_mode;\r\nEnterFunction(10);\r\nif (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ) {\r\nif (cp->packet_xmit)\r\nrc = cp->packet_xmit(skb, cp, pp, ipvsh);\r\nelse\r\nrc = NF_ACCEPT;\r\natomic_inc(&cp->in_pkts);\r\ngoto out;\r\n}\r\nrt_mode = (hooknum != NF_INET_FORWARD) ?\r\nIP_VS_RT_MODE_LOCAL | IP_VS_RT_MODE_NON_LOCAL |\r\nIP_VS_RT_MODE_RDR : IP_VS_RT_MODE_NON_LOCAL;\r\nrcu_read_lock();\r\nlocal = __ip_vs_get_out_rt_v6(cp->af, skb, cp->dest, &cp->daddr.in6,\r\nNULL, ipvsh, 0, rt_mode);\r\nif (local < 0)\r\ngoto tx_error;\r\nrt = (struct rt6_info *) skb_dst(skb);\r\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\r\nif (cp->flags & IP_VS_CONN_F_SYNC && local) {\r\nenum ip_conntrack_info ctinfo;\r\nstruct nf_conn *ct = nf_ct_get(skb, &ctinfo);\r\nif (ct && !nf_ct_is_untracked(ct)) {\r\nIP_VS_DBG(10, "%s(): "\r\n"stopping DNAT to local address %pI6\n",\r\n__func__, &cp->daddr.in6);\r\ngoto tx_error;\r\n}\r\n}\r\n#endif\r\nif (local && skb->dev && !(skb->dev->flags & IFF_LOOPBACK) &&\r\nipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_LOOPBACK) {\r\nIP_VS_DBG(1, "%s(): "\r\n"stopping DNAT to loopback %pI6\n",\r\n__func__, &cp->daddr.in6);\r\ngoto tx_error;\r\n}\r\nif (!skb_make_writable(skb, offset))\r\ngoto tx_error;\r\nif (skb_cow(skb, rt->dst.dev->hard_header_len))\r\ngoto tx_error;\r\nip_vs_nat_icmp_v6(skb, pp, cp, 0);\r\nskb->ignore_df = 1;\r\nrc = ip_vs_nat_send_or_cont(NFPROTO_IPV6, skb, cp, local);\r\nrcu_read_unlock();\r\ngoto out;\r\ntx_error:\r\nkfree_skb(skb);\r\nrcu_read_unlock();\r\nrc = NF_STOLEN;\r\nout:\r\nLeaveFunction(10);\r\nreturn rc;\r\n}
