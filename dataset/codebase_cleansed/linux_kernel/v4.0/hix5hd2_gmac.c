static void hix5hd2_config_port(struct net_device *dev, u32 speed, u32 duplex)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nu32 val;\r\npriv->speed = speed;\r\npriv->duplex = duplex;\r\nswitch (priv->phy_mode) {\r\ncase PHY_INTERFACE_MODE_RGMII:\r\nif (speed == SPEED_1000)\r\nval = RGMII_SPEED_1000;\r\nelse if (speed == SPEED_100)\r\nval = RGMII_SPEED_100;\r\nelse\r\nval = RGMII_SPEED_10;\r\nbreak;\r\ncase PHY_INTERFACE_MODE_MII:\r\nif (speed == SPEED_100)\r\nval = MII_SPEED_100;\r\nelse\r\nval = MII_SPEED_10;\r\nbreak;\r\ndefault:\r\nnetdev_warn(dev, "not supported mode\n");\r\nval = MII_SPEED_10;\r\nbreak;\r\n}\r\nif (duplex)\r\nval |= GMAC_FULL_DUPLEX;\r\nwritel_relaxed(val, priv->ctrl_base);\r\nwritel_relaxed(BIT_MODE_CHANGE_EN, priv->base + MODE_CHANGE_EN);\r\nif (speed == SPEED_1000)\r\nval = GMAC_SPEED_1000;\r\nelse if (speed == SPEED_100)\r\nval = GMAC_SPEED_100;\r\nelse\r\nval = GMAC_SPEED_10;\r\nwritel_relaxed(val, priv->base + PORT_MODE);\r\nwritel_relaxed(0, priv->base + MODE_CHANGE_EN);\r\nwritel_relaxed(duplex, priv->base + MAC_DUPLEX_HALF_CTRL);\r\n}\r\nstatic void hix5hd2_set_desc_depth(struct hix5hd2_priv *priv, int rx, int tx)\r\n{\r\nwritel_relaxed(BITS_RX_FQ_DEPTH_EN, priv->base + RX_FQ_REG_EN);\r\nwritel_relaxed(rx << 3, priv->base + RX_FQ_DEPTH);\r\nwritel_relaxed(0, priv->base + RX_FQ_REG_EN);\r\nwritel_relaxed(BITS_RX_BQ_DEPTH_EN, priv->base + RX_BQ_REG_EN);\r\nwritel_relaxed(rx << 3, priv->base + RX_BQ_DEPTH);\r\nwritel_relaxed(0, priv->base + RX_BQ_REG_EN);\r\nwritel_relaxed(BITS_TX_BQ_DEPTH_EN, priv->base + TX_BQ_REG_EN);\r\nwritel_relaxed(tx << 3, priv->base + TX_BQ_DEPTH);\r\nwritel_relaxed(0, priv->base + TX_BQ_REG_EN);\r\nwritel_relaxed(BITS_TX_RQ_DEPTH_EN, priv->base + TX_RQ_REG_EN);\r\nwritel_relaxed(tx << 3, priv->base + TX_RQ_DEPTH);\r\nwritel_relaxed(0, priv->base + TX_RQ_REG_EN);\r\n}\r\nstatic void hix5hd2_set_rx_fq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\r\n{\r\nwritel_relaxed(BITS_RX_FQ_START_ADDR_EN, priv->base + RX_FQ_REG_EN);\r\nwritel_relaxed(phy_addr, priv->base + RX_FQ_START_ADDR);\r\nwritel_relaxed(0, priv->base + RX_FQ_REG_EN);\r\n}\r\nstatic void hix5hd2_set_rx_bq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\r\n{\r\nwritel_relaxed(BITS_RX_BQ_START_ADDR_EN, priv->base + RX_BQ_REG_EN);\r\nwritel_relaxed(phy_addr, priv->base + RX_BQ_START_ADDR);\r\nwritel_relaxed(0, priv->base + RX_BQ_REG_EN);\r\n}\r\nstatic void hix5hd2_set_tx_bq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\r\n{\r\nwritel_relaxed(BITS_TX_BQ_START_ADDR_EN, priv->base + TX_BQ_REG_EN);\r\nwritel_relaxed(phy_addr, priv->base + TX_BQ_START_ADDR);\r\nwritel_relaxed(0, priv->base + TX_BQ_REG_EN);\r\n}\r\nstatic void hix5hd2_set_tx_rq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\r\n{\r\nwritel_relaxed(BITS_TX_RQ_START_ADDR_EN, priv->base + TX_RQ_REG_EN);\r\nwritel_relaxed(phy_addr, priv->base + TX_RQ_START_ADDR);\r\nwritel_relaxed(0, priv->base + TX_RQ_REG_EN);\r\n}\r\nstatic void hix5hd2_set_desc_addr(struct hix5hd2_priv *priv)\r\n{\r\nhix5hd2_set_rx_fq(priv, priv->rx_fq.phys_addr);\r\nhix5hd2_set_rx_bq(priv, priv->rx_bq.phys_addr);\r\nhix5hd2_set_tx_rq(priv, priv->tx_rq.phys_addr);\r\nhix5hd2_set_tx_bq(priv, priv->tx_bq.phys_addr);\r\n}\r\nstatic void hix5hd2_hw_init(struct hix5hd2_priv *priv)\r\n{\r\nu32 val;\r\nwritel_relaxed(0, priv->base + ENA_PMU_INT);\r\nwritel_relaxed(~0, priv->base + RAW_PMU_INT);\r\nwritel_relaxed(BIT_CRC_ERR_PASS, priv->base + REC_FILT_CONTROL);\r\nwritel_relaxed(MAC_MAX_FRAME_SIZE, priv->base + CONTROL_WORD);\r\nwritel_relaxed(0, priv->base + COL_SLOT_TIME);\r\nval = RX_BQ_INT_THRESHOLD | TX_RQ_INT_THRESHOLD << QUEUE_TX_BQ_SHIFT;\r\nwritel_relaxed(val, priv->base + IN_QUEUE_TH);\r\nwritel_relaxed(RX_BQ_IN_TIMEOUT, priv->base + RX_BQ_IN_TIMEOUT_TH);\r\nwritel_relaxed(TX_RQ_IN_TIMEOUT, priv->base + TX_RQ_IN_TIMEOUT_TH);\r\nhix5hd2_set_desc_depth(priv, RX_DESC_NUM, TX_DESC_NUM);\r\nhix5hd2_set_desc_addr(priv);\r\n}\r\nstatic void hix5hd2_irq_enable(struct hix5hd2_priv *priv)\r\n{\r\nwritel_relaxed(DEF_INT_MASK, priv->base + ENA_PMU_INT);\r\n}\r\nstatic void hix5hd2_irq_disable(struct hix5hd2_priv *priv)\r\n{\r\nwritel_relaxed(0, priv->base + ENA_PMU_INT);\r\n}\r\nstatic void hix5hd2_port_enable(struct hix5hd2_priv *priv)\r\n{\r\nwritel_relaxed(0xf, priv->base + DESC_WR_RD_ENA);\r\nwritel_relaxed(BITS_RX_EN | BITS_TX_EN, priv->base + PORT_EN);\r\n}\r\nstatic void hix5hd2_port_disable(struct hix5hd2_priv *priv)\r\n{\r\nwritel_relaxed(~(BITS_RX_EN | BITS_TX_EN), priv->base + PORT_EN);\r\nwritel_relaxed(0, priv->base + DESC_WR_RD_ENA);\r\n}\r\nstatic void hix5hd2_hw_set_mac_addr(struct net_device *dev)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nunsigned char *mac = dev->dev_addr;\r\nu32 val;\r\nval = mac[1] | (mac[0] << 8);\r\nwritel_relaxed(val, priv->base + STATION_ADDR_HIGH);\r\nval = mac[5] | (mac[4] << 8) | (mac[3] << 16) | (mac[2] << 24);\r\nwritel_relaxed(val, priv->base + STATION_ADDR_LOW);\r\n}\r\nstatic int hix5hd2_net_set_mac_address(struct net_device *dev, void *p)\r\n{\r\nint ret;\r\nret = eth_mac_addr(dev, p);\r\nif (!ret)\r\nhix5hd2_hw_set_mac_addr(dev);\r\nreturn ret;\r\n}\r\nstatic void hix5hd2_adjust_link(struct net_device *dev)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nstruct phy_device *phy = priv->phy;\r\nif ((priv->speed != phy->speed) || (priv->duplex != phy->duplex)) {\r\nhix5hd2_config_port(dev, phy->speed, phy->duplex);\r\nphy_print_status(phy);\r\n}\r\n}\r\nstatic void hix5hd2_rx_refill(struct hix5hd2_priv *priv)\r\n{\r\nstruct hix5hd2_desc *desc;\r\nstruct sk_buff *skb;\r\nu32 start, end, num, pos, i;\r\nu32 len = MAC_MAX_FRAME_SIZE;\r\ndma_addr_t addr;\r\nstart = dma_cnt(readl_relaxed(priv->base + RX_FQ_WR_ADDR));\r\nend = dma_cnt(readl_relaxed(priv->base + RX_FQ_RD_ADDR));\r\nnum = CIRC_SPACE(start, end, RX_DESC_NUM);\r\nfor (i = 0, pos = start; i < num; i++) {\r\nif (priv->rx_skb[pos]) {\r\nbreak;\r\n} else {\r\nskb = netdev_alloc_skb_ip_align(priv->netdev, len);\r\nif (unlikely(skb == NULL))\r\nbreak;\r\n}\r\naddr = dma_map_single(priv->dev, skb->data, len, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(priv->dev, addr)) {\r\ndev_kfree_skb_any(skb);\r\nbreak;\r\n}\r\ndesc = priv->rx_fq.desc + pos;\r\ndesc->buff_addr = cpu_to_le32(addr);\r\npriv->rx_skb[pos] = skb;\r\ndesc->cmd = cpu_to_le32(DESC_VLD_FREE |\r\n(len - 1) << DESC_BUFF_LEN_OFF);\r\npos = dma_ring_incr(pos, RX_DESC_NUM);\r\n}\r\nwmb();\r\nif (pos != start)\r\nwritel_relaxed(dma_byte(pos), priv->base + RX_FQ_WR_ADDR);\r\n}\r\nstatic int hix5hd2_rx(struct net_device *dev, int limit)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nstruct sk_buff *skb;\r\nstruct hix5hd2_desc *desc;\r\ndma_addr_t addr;\r\nu32 start, end, num, pos, i, len;\r\nstart = dma_cnt(readl_relaxed(priv->base + RX_BQ_RD_ADDR));\r\nend = dma_cnt(readl_relaxed(priv->base + RX_BQ_WR_ADDR));\r\nnum = CIRC_CNT(end, start, RX_DESC_NUM);\r\nif (num > limit)\r\nnum = limit;\r\nrmb();\r\nfor (i = 0, pos = start; i < num; i++) {\r\nskb = priv->rx_skb[pos];\r\nif (unlikely(!skb)) {\r\nnetdev_err(dev, "inconsistent rx_skb\n");\r\nbreak;\r\n}\r\npriv->rx_skb[pos] = NULL;\r\ndesc = priv->rx_bq.desc + pos;\r\nlen = (le32_to_cpu(desc->cmd) >> DESC_DATA_LEN_OFF) &\r\nDESC_DATA_MASK;\r\naddr = le32_to_cpu(desc->buff_addr);\r\ndma_unmap_single(priv->dev, addr, MAC_MAX_FRAME_SIZE,\r\nDMA_FROM_DEVICE);\r\nskb_put(skb, len);\r\nif (skb->len > MAC_MAX_FRAME_SIZE) {\r\nnetdev_err(dev, "rcv len err, len = %d\n", skb->len);\r\ndev->stats.rx_errors++;\r\ndev->stats.rx_length_errors++;\r\ndev_kfree_skb_any(skb);\r\ngoto next;\r\n}\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnapi_gro_receive(&priv->napi, skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += skb->len;\r\ndev->last_rx = jiffies;\r\nnext:\r\npos = dma_ring_incr(pos, RX_DESC_NUM);\r\n}\r\nif (pos != start)\r\nwritel_relaxed(dma_byte(pos), priv->base + RX_BQ_RD_ADDR);\r\nhix5hd2_rx_refill(priv);\r\nreturn num;\r\n}\r\nstatic void hix5hd2_xmit_reclaim(struct net_device *dev)\r\n{\r\nstruct sk_buff *skb;\r\nstruct hix5hd2_desc *desc;\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nunsigned int bytes_compl = 0, pkts_compl = 0;\r\nu32 start, end, num, pos, i;\r\ndma_addr_t addr;\r\nnetif_tx_lock(dev);\r\nstart = dma_cnt(readl_relaxed(priv->base + TX_RQ_RD_ADDR));\r\nend = dma_cnt(readl_relaxed(priv->base + TX_RQ_WR_ADDR));\r\nnum = CIRC_CNT(end, start, TX_DESC_NUM);\r\nfor (i = 0, pos = start; i < num; i++) {\r\nskb = priv->tx_skb[pos];\r\nif (unlikely(!skb)) {\r\nnetdev_err(dev, "inconsistent tx_skb\n");\r\nbreak;\r\n}\r\npkts_compl++;\r\nbytes_compl += skb->len;\r\ndesc = priv->tx_rq.desc + pos;\r\naddr = le32_to_cpu(desc->buff_addr);\r\ndma_unmap_single(priv->dev, addr, skb->len, DMA_TO_DEVICE);\r\npriv->tx_skb[pos] = NULL;\r\ndev_consume_skb_any(skb);\r\npos = dma_ring_incr(pos, TX_DESC_NUM);\r\n}\r\nif (pos != start)\r\nwritel_relaxed(dma_byte(pos), priv->base + TX_RQ_RD_ADDR);\r\nnetif_tx_unlock(dev);\r\nif (pkts_compl || bytes_compl)\r\nnetdev_completed_queue(dev, pkts_compl, bytes_compl);\r\nif (unlikely(netif_queue_stopped(priv->netdev)) && pkts_compl)\r\nnetif_wake_queue(priv->netdev);\r\n}\r\nstatic int hix5hd2_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct hix5hd2_priv *priv = container_of(napi,\r\nstruct hix5hd2_priv, napi);\r\nstruct net_device *dev = priv->netdev;\r\nint work_done = 0, task = budget;\r\nint ints, num;\r\ndo {\r\nhix5hd2_xmit_reclaim(dev);\r\nnum = hix5hd2_rx(dev, task);\r\nwork_done += num;\r\ntask -= num;\r\nif ((work_done >= budget) || (num == 0))\r\nbreak;\r\nints = readl_relaxed(priv->base + RAW_PMU_INT);\r\nwritel_relaxed(ints, priv->base + RAW_PMU_INT);\r\n} while (ints & DEF_INT_MASK);\r\nif (work_done < budget) {\r\nnapi_complete(napi);\r\nhix5hd2_irq_enable(priv);\r\n}\r\nreturn work_done;\r\n}\r\nstatic irqreturn_t hix5hd2_interrupt(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *)dev_id;\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nint ints = readl_relaxed(priv->base + RAW_PMU_INT);\r\nwritel_relaxed(ints, priv->base + RAW_PMU_INT);\r\nif (likely(ints & DEF_INT_MASK)) {\r\nhix5hd2_irq_disable(priv);\r\nnapi_schedule(&priv->napi);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int hix5hd2_net_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nstruct hix5hd2_desc *desc;\r\ndma_addr_t addr;\r\nu32 pos;\r\npos = dma_cnt(readl_relaxed(priv->base + TX_BQ_WR_ADDR));\r\nif (unlikely(priv->tx_skb[pos])) {\r\ndev->stats.tx_dropped++;\r\ndev->stats.tx_fifo_errors++;\r\nnetif_stop_queue(dev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\naddr = dma_map_single(priv->dev, skb->data, skb->len, DMA_TO_DEVICE);\r\nif (dma_mapping_error(priv->dev, addr)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\ndesc = priv->tx_bq.desc + pos;\r\ndesc->buff_addr = cpu_to_le32(addr);\r\npriv->tx_skb[pos] = skb;\r\ndesc->cmd = cpu_to_le32(DESC_VLD_BUSY | DESC_FL_FULL |\r\n(skb->len & DESC_DATA_MASK) << DESC_DATA_LEN_OFF |\r\n(skb->len & DESC_DATA_MASK) << DESC_BUFF_LEN_OFF);\r\nwmb();\r\npos = dma_ring_incr(pos, TX_DESC_NUM);\r\nwritel_relaxed(dma_byte(pos), priv->base + TX_BQ_WR_ADDR);\r\ndev->trans_start = jiffies;\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += skb->len;\r\nnetdev_sent_queue(dev, skb->len);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void hix5hd2_free_dma_desc_rings(struct hix5hd2_priv *priv)\r\n{\r\nstruct hix5hd2_desc *desc;\r\ndma_addr_t addr;\r\nint i;\r\nfor (i = 0; i < RX_DESC_NUM; i++) {\r\nstruct sk_buff *skb = priv->rx_skb[i];\r\nif (skb == NULL)\r\ncontinue;\r\ndesc = priv->rx_fq.desc + i;\r\naddr = le32_to_cpu(desc->buff_addr);\r\ndma_unmap_single(priv->dev, addr,\r\nMAC_MAX_FRAME_SIZE, DMA_FROM_DEVICE);\r\ndev_kfree_skb_any(skb);\r\npriv->rx_skb[i] = NULL;\r\n}\r\nfor (i = 0; i < TX_DESC_NUM; i++) {\r\nstruct sk_buff *skb = priv->tx_skb[i];\r\nif (skb == NULL)\r\ncontinue;\r\ndesc = priv->tx_rq.desc + i;\r\naddr = le32_to_cpu(desc->buff_addr);\r\ndma_unmap_single(priv->dev, addr, skb->len, DMA_TO_DEVICE);\r\ndev_kfree_skb_any(skb);\r\npriv->tx_skb[i] = NULL;\r\n}\r\n}\r\nstatic int hix5hd2_net_open(struct net_device *dev)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nint ret;\r\nret = clk_prepare_enable(priv->clk);\r\nif (ret < 0) {\r\nnetdev_err(dev, "failed to enable clk %d\n", ret);\r\nreturn ret;\r\n}\r\npriv->phy = of_phy_connect(dev, priv->phy_node,\r\n&hix5hd2_adjust_link, 0, priv->phy_mode);\r\nif (!priv->phy)\r\nreturn -ENODEV;\r\nphy_start(priv->phy);\r\nhix5hd2_hw_init(priv);\r\nhix5hd2_rx_refill(priv);\r\nnetdev_reset_queue(dev);\r\nnetif_start_queue(dev);\r\nnapi_enable(&priv->napi);\r\nhix5hd2_port_enable(priv);\r\nhix5hd2_irq_enable(priv);\r\nreturn 0;\r\n}\r\nstatic int hix5hd2_net_close(struct net_device *dev)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nhix5hd2_port_disable(priv);\r\nhix5hd2_irq_disable(priv);\r\nnapi_disable(&priv->napi);\r\nnetif_stop_queue(dev);\r\nhix5hd2_free_dma_desc_rings(priv);\r\nif (priv->phy) {\r\nphy_stop(priv->phy);\r\nphy_disconnect(priv->phy);\r\n}\r\nclk_disable_unprepare(priv->clk);\r\nreturn 0;\r\n}\r\nstatic void hix5hd2_tx_timeout_task(struct work_struct *work)\r\n{\r\nstruct hix5hd2_priv *priv;\r\npriv = container_of(work, struct hix5hd2_priv, tx_timeout_task);\r\nhix5hd2_net_close(priv->netdev);\r\nhix5hd2_net_open(priv->netdev);\r\n}\r\nstatic void hix5hd2_net_timeout(struct net_device *dev)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(dev);\r\nschedule_work(&priv->tx_timeout_task);\r\n}\r\nstatic int hix5hd2_get_settings(struct net_device *net_dev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(net_dev);\r\nif (!priv->phy)\r\nreturn -ENODEV;\r\nreturn phy_ethtool_gset(priv->phy, cmd);\r\n}\r\nstatic int hix5hd2_set_settings(struct net_device *net_dev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct hix5hd2_priv *priv = netdev_priv(net_dev);\r\nif (!priv->phy)\r\nreturn -ENODEV;\r\nreturn phy_ethtool_sset(priv->phy, cmd);\r\n}\r\nstatic int hix5hd2_mdio_wait_ready(struct mii_bus *bus)\r\n{\r\nstruct hix5hd2_priv *priv = bus->priv;\r\nvoid __iomem *base = priv->base;\r\nint i, timeout = 10000;\r\nfor (i = 0; readl_relaxed(base + MDIO_SINGLE_CMD) & MDIO_START; i++) {\r\nif (i == timeout)\r\nreturn -ETIMEDOUT;\r\nusleep_range(10, 20);\r\n}\r\nreturn 0;\r\n}\r\nstatic int hix5hd2_mdio_read(struct mii_bus *bus, int phy, int reg)\r\n{\r\nstruct hix5hd2_priv *priv = bus->priv;\r\nvoid __iomem *base = priv->base;\r\nint val, ret;\r\nret = hix5hd2_mdio_wait_ready(bus);\r\nif (ret < 0)\r\ngoto out;\r\nwritel_relaxed(MDIO_READ | phy << 8 | reg, base + MDIO_SINGLE_CMD);\r\nret = hix5hd2_mdio_wait_ready(bus);\r\nif (ret < 0)\r\ngoto out;\r\nval = readl_relaxed(base + MDIO_RDATA_STATUS);\r\nif (val & MDIO_R_VALID) {\r\ndev_err(bus->parent, "SMI bus read not valid\n");\r\nret = -ENODEV;\r\ngoto out;\r\n}\r\nval = readl_relaxed(priv->base + MDIO_SINGLE_DATA);\r\nret = (val >> 16) & 0xFFFF;\r\nout:\r\nreturn ret;\r\n}\r\nstatic int hix5hd2_mdio_write(struct mii_bus *bus, int phy, int reg, u16 val)\r\n{\r\nstruct hix5hd2_priv *priv = bus->priv;\r\nvoid __iomem *base = priv->base;\r\nint ret;\r\nret = hix5hd2_mdio_wait_ready(bus);\r\nif (ret < 0)\r\ngoto out;\r\nwritel_relaxed(val, base + MDIO_SINGLE_DATA);\r\nwritel_relaxed(MDIO_WRITE | phy << 8 | reg, base + MDIO_SINGLE_CMD);\r\nret = hix5hd2_mdio_wait_ready(bus);\r\nout:\r\nreturn ret;\r\n}\r\nstatic void hix5hd2_destroy_hw_desc_queue(struct hix5hd2_priv *priv)\r\n{\r\nint i;\r\nfor (i = 0; i < QUEUE_NUMS; i++) {\r\nif (priv->pool[i].desc) {\r\ndma_free_coherent(priv->dev, priv->pool[i].size,\r\npriv->pool[i].desc,\r\npriv->pool[i].phys_addr);\r\npriv->pool[i].desc = NULL;\r\n}\r\n}\r\n}\r\nstatic int hix5hd2_init_hw_desc_queue(struct hix5hd2_priv *priv)\r\n{\r\nstruct device *dev = priv->dev;\r\nstruct hix5hd2_desc *virt_addr;\r\ndma_addr_t phys_addr;\r\nint size, i;\r\npriv->rx_fq.count = RX_DESC_NUM;\r\npriv->rx_bq.count = RX_DESC_NUM;\r\npriv->tx_bq.count = TX_DESC_NUM;\r\npriv->tx_rq.count = TX_DESC_NUM;\r\nfor (i = 0; i < QUEUE_NUMS; i++) {\r\nsize = priv->pool[i].count * sizeof(struct hix5hd2_desc);\r\nvirt_addr = dma_alloc_coherent(dev, size, &phys_addr,\r\nGFP_KERNEL);\r\nif (virt_addr == NULL)\r\ngoto error_free_pool;\r\nmemset(virt_addr, 0, size);\r\npriv->pool[i].size = size;\r\npriv->pool[i].desc = virt_addr;\r\npriv->pool[i].phys_addr = phys_addr;\r\n}\r\nreturn 0;\r\nerror_free_pool:\r\nhix5hd2_destroy_hw_desc_queue(priv);\r\nreturn -ENOMEM;\r\n}\r\nstatic int hix5hd2_dev_probe(struct platform_device *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct device_node *node = dev->of_node;\r\nstruct net_device *ndev;\r\nstruct hix5hd2_priv *priv;\r\nstruct resource *res;\r\nstruct mii_bus *bus;\r\nconst char *mac_addr;\r\nint ret;\r\nndev = alloc_etherdev(sizeof(struct hix5hd2_priv));\r\nif (!ndev)\r\nreturn -ENOMEM;\r\nplatform_set_drvdata(pdev, ndev);\r\npriv = netdev_priv(ndev);\r\npriv->dev = dev;\r\npriv->netdev = ndev;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\npriv->base = devm_ioremap_resource(dev, res);\r\nif (IS_ERR(priv->base)) {\r\nret = PTR_ERR(priv->base);\r\ngoto out_free_netdev;\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 1);\r\npriv->ctrl_base = devm_ioremap_resource(dev, res);\r\nif (IS_ERR(priv->ctrl_base)) {\r\nret = PTR_ERR(priv->ctrl_base);\r\ngoto out_free_netdev;\r\n}\r\npriv->clk = devm_clk_get(&pdev->dev, NULL);\r\nif (IS_ERR(priv->clk)) {\r\nnetdev_err(ndev, "failed to get clk\n");\r\nret = -ENODEV;\r\ngoto out_free_netdev;\r\n}\r\nret = clk_prepare_enable(priv->clk);\r\nif (ret < 0) {\r\nnetdev_err(ndev, "failed to enable clk %d\n", ret);\r\ngoto out_free_netdev;\r\n}\r\nbus = mdiobus_alloc();\r\nif (bus == NULL) {\r\nret = -ENOMEM;\r\ngoto out_free_netdev;\r\n}\r\nbus->priv = priv;\r\nbus->name = "hix5hd2_mii_bus";\r\nbus->read = hix5hd2_mdio_read;\r\nbus->write = hix5hd2_mdio_write;\r\nbus->parent = &pdev->dev;\r\nsnprintf(bus->id, MII_BUS_ID_SIZE, "%s-mii", dev_name(&pdev->dev));\r\npriv->bus = bus;\r\nret = of_mdiobus_register(bus, node);\r\nif (ret)\r\ngoto err_free_mdio;\r\npriv->phy_mode = of_get_phy_mode(node);\r\nif (priv->phy_mode < 0) {\r\nnetdev_err(ndev, "not find phy-mode\n");\r\nret = -EINVAL;\r\ngoto err_mdiobus;\r\n}\r\npriv->phy_node = of_parse_phandle(node, "phy-handle", 0);\r\nif (!priv->phy_node) {\r\nnetdev_err(ndev, "not find phy-handle\n");\r\nret = -EINVAL;\r\ngoto err_mdiobus;\r\n}\r\nndev->irq = platform_get_irq(pdev, 0);\r\nif (ndev->irq <= 0) {\r\nnetdev_err(ndev, "No irq resource\n");\r\nret = -EINVAL;\r\ngoto out_phy_node;\r\n}\r\nret = devm_request_irq(dev, ndev->irq, hix5hd2_interrupt,\r\n0, pdev->name, ndev);\r\nif (ret) {\r\nnetdev_err(ndev, "devm_request_irq failed\n");\r\ngoto out_phy_node;\r\n}\r\nmac_addr = of_get_mac_address(node);\r\nif (mac_addr)\r\nether_addr_copy(ndev->dev_addr, mac_addr);\r\nif (!is_valid_ether_addr(ndev->dev_addr)) {\r\neth_hw_addr_random(ndev);\r\nnetdev_warn(ndev, "using random MAC address %pM\n",\r\nndev->dev_addr);\r\n}\r\nINIT_WORK(&priv->tx_timeout_task, hix5hd2_tx_timeout_task);\r\nndev->watchdog_timeo = 6 * HZ;\r\nndev->priv_flags |= IFF_UNICAST_FLT;\r\nndev->netdev_ops = &hix5hd2_netdev_ops;\r\nndev->ethtool_ops = &hix5hd2_ethtools_ops;\r\nSET_NETDEV_DEV(ndev, dev);\r\nret = hix5hd2_init_hw_desc_queue(priv);\r\nif (ret)\r\ngoto out_phy_node;\r\nnetif_napi_add(ndev, &priv->napi, hix5hd2_poll, NAPI_POLL_WEIGHT);\r\nret = register_netdev(priv->netdev);\r\nif (ret) {\r\nnetdev_err(ndev, "register_netdev failed!");\r\ngoto out_destroy_queue;\r\n}\r\nclk_disable_unprepare(priv->clk);\r\nreturn ret;\r\nout_destroy_queue:\r\nnetif_napi_del(&priv->napi);\r\nhix5hd2_destroy_hw_desc_queue(priv);\r\nout_phy_node:\r\nof_node_put(priv->phy_node);\r\nerr_mdiobus:\r\nmdiobus_unregister(bus);\r\nerr_free_mdio:\r\nmdiobus_free(bus);\r\nout_free_netdev:\r\nfree_netdev(ndev);\r\nreturn ret;\r\n}\r\nstatic int hix5hd2_dev_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *ndev = platform_get_drvdata(pdev);\r\nstruct hix5hd2_priv *priv = netdev_priv(ndev);\r\nnetif_napi_del(&priv->napi);\r\nunregister_netdev(ndev);\r\nmdiobus_unregister(priv->bus);\r\nmdiobus_free(priv->bus);\r\nhix5hd2_destroy_hw_desc_queue(priv);\r\nof_node_put(priv->phy_node);\r\ncancel_work_sync(&priv->tx_timeout_task);\r\nfree_netdev(ndev);\r\nreturn 0;\r\n}
