static int adf_enable_msix(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_accel_pci *pci_dev_info = &accel_dev->accel_pci_dev;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nuint32_t msix_num_entries = hw_data->num_banks + 1;\r\nint i;\r\nfor (i = 0; i < msix_num_entries; i++)\r\npci_dev_info->msix_entries.entries[i].entry = i;\r\nif (pci_enable_msix_exact(pci_dev_info->pci_dev,\r\npci_dev_info->msix_entries.entries,\r\nmsix_num_entries)) {\r\npr_err("QAT: Failed to enable MSIX IRQ\n");\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nstatic void adf_disable_msix(struct adf_accel_pci *pci_dev_info)\r\n{\r\npci_disable_msix(pci_dev_info->pci_dev);\r\n}\r\nstatic irqreturn_t adf_msix_isr_bundle(int irq, void *bank_ptr)\r\n{\r\nstruct adf_etr_bank_data *bank = bank_ptr;\r\nWRITE_CSR_INT_FLAG_AND_COL(bank->csr_addr, bank->bank_number, 0);\r\ntasklet_hi_schedule(&bank->resp_handler);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t adf_msix_isr_ae(int irq, void *dev_ptr)\r\n{\r\nstruct adf_accel_dev *accel_dev = dev_ptr;\r\npr_info("QAT: qat_dev%d spurious AE interrupt\n", accel_dev->accel_id);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int adf_request_irqs(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_accel_pci *pci_dev_info = &accel_dev->accel_pci_dev;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nstruct msix_entry *msixe = pci_dev_info->msix_entries.entries;\r\nstruct adf_etr_data *etr_data = accel_dev->transport;\r\nint ret, i;\r\nchar *name;\r\nfor (i = 0; i < hw_data->num_banks; i++) {\r\nstruct adf_etr_bank_data *bank = &etr_data->banks[i];\r\nunsigned int cpu, cpus = num_online_cpus();\r\nname = *(pci_dev_info->msix_entries.names + i);\r\nsnprintf(name, ADF_MAX_MSIX_VECTOR_NAME,\r\n"qat%d-bundle%d", accel_dev->accel_id, i);\r\nret = request_irq(msixe[i].vector,\r\nadf_msix_isr_bundle, 0, name, bank);\r\nif (ret) {\r\npr_err("QAT: failed to enable irq %d for %s\n",\r\nmsixe[i].vector, name);\r\nreturn ret;\r\n}\r\ncpu = ((accel_dev->accel_id * hw_data->num_banks) + i) % cpus;\r\nirq_set_affinity_hint(msixe[i].vector, get_cpu_mask(cpu));\r\n}\r\nname = *(pci_dev_info->msix_entries.names + i);\r\nsnprintf(name, ADF_MAX_MSIX_VECTOR_NAME,\r\n"qat%d-ae-cluster", accel_dev->accel_id);\r\nret = request_irq(msixe[i].vector, adf_msix_isr_ae, 0, name, accel_dev);\r\nif (ret) {\r\npr_err("QAT: failed to enable irq %d, for %s\n",\r\nmsixe[i].vector, name);\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic void adf_free_irqs(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_accel_pci *pci_dev_info = &accel_dev->accel_pci_dev;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nstruct msix_entry *msixe = pci_dev_info->msix_entries.entries;\r\nstruct adf_etr_data *etr_data = accel_dev->transport;\r\nint i;\r\nfor (i = 0; i < hw_data->num_banks; i++) {\r\nirq_set_affinity_hint(msixe[i].vector, NULL);\r\nfree_irq(msixe[i].vector, &etr_data->banks[i]);\r\n}\r\nirq_set_affinity_hint(msixe[i].vector, NULL);\r\nfree_irq(msixe[i].vector, accel_dev);\r\n}\r\nstatic int adf_isr_alloc_msix_entry_table(struct adf_accel_dev *accel_dev)\r\n{\r\nint i;\r\nchar **names;\r\nstruct msix_entry *entries;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nuint32_t msix_num_entries = hw_data->num_banks + 1;\r\nentries = kzalloc_node(msix_num_entries * sizeof(*entries),\r\nGFP_KERNEL, dev_to_node(&GET_DEV(accel_dev)));\r\nif (!entries)\r\nreturn -ENOMEM;\r\nnames = kcalloc(msix_num_entries, sizeof(char *), GFP_KERNEL);\r\nif (!names) {\r\nkfree(entries);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < msix_num_entries; i++) {\r\n*(names + i) = kzalloc(ADF_MAX_MSIX_VECTOR_NAME, GFP_KERNEL);\r\nif (!(*(names + i)))\r\ngoto err;\r\n}\r\naccel_dev->accel_pci_dev.msix_entries.entries = entries;\r\naccel_dev->accel_pci_dev.msix_entries.names = names;\r\nreturn 0;\r\nerr:\r\nfor (i = 0; i < msix_num_entries; i++)\r\nkfree(*(names + i));\r\nkfree(entries);\r\nkfree(names);\r\nreturn -ENOMEM;\r\n}\r\nstatic void adf_isr_free_msix_entry_table(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nuint32_t msix_num_entries = hw_data->num_banks + 1;\r\nchar **names = accel_dev->accel_pci_dev.msix_entries.names;\r\nint i;\r\nkfree(accel_dev->accel_pci_dev.msix_entries.entries);\r\nfor (i = 0; i < msix_num_entries; i++)\r\nkfree(*(names + i));\r\nkfree(names);\r\n}\r\nstatic int adf_setup_bh(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_etr_data *priv_data = accel_dev->transport;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nint i;\r\nfor (i = 0; i < hw_data->num_banks; i++)\r\ntasklet_init(&priv_data->banks[i].resp_handler,\r\nadf_response_handler,\r\n(unsigned long)&priv_data->banks[i]);\r\nreturn 0;\r\n}\r\nstatic void adf_cleanup_bh(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_etr_data *priv_data = accel_dev->transport;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nint i;\r\nfor (i = 0; i < hw_data->num_banks; i++) {\r\ntasklet_disable(&priv_data->banks[i].resp_handler);\r\ntasklet_kill(&priv_data->banks[i].resp_handler);\r\n}\r\n}\r\nvoid adf_isr_resource_free(struct adf_accel_dev *accel_dev)\r\n{\r\nadf_free_irqs(accel_dev);\r\nadf_cleanup_bh(accel_dev);\r\nadf_disable_msix(&accel_dev->accel_pci_dev);\r\nadf_isr_free_msix_entry_table(accel_dev);\r\n}\r\nint adf_isr_resource_alloc(struct adf_accel_dev *accel_dev)\r\n{\r\nint ret;\r\nret = adf_isr_alloc_msix_entry_table(accel_dev);\r\nif (ret)\r\nreturn ret;\r\nif (adf_enable_msix(accel_dev))\r\ngoto err_out;\r\nif (adf_setup_bh(accel_dev))\r\ngoto err_out;\r\nif (adf_request_irqs(accel_dev))\r\ngoto err_out;\r\nreturn 0;\r\nerr_out:\r\nadf_isr_resource_free(accel_dev);\r\nreturn -EFAULT;\r\n}
