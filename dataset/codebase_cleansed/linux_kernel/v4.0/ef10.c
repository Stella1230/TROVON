static int efx_ef10_get_warm_boot_count(struct efx_nic *efx)\r\n{\r\nefx_dword_t reg;\r\nefx_readd(efx, &reg, ER_DZ_BIU_MC_SFT_STATUS);\r\nreturn EFX_DWORD_FIELD(reg, EFX_WORD_1) == 0xb007 ?\r\nEFX_DWORD_FIELD(reg, EFX_WORD_0) : -EIO;\r\n}\r\nstatic unsigned int efx_ef10_mem_map_size(struct efx_nic *efx)\r\n{\r\nreturn resource_size(&efx->pci_dev->resource[EFX_MEM_BAR]);\r\n}\r\nstatic int efx_ef10_init_datapath_caps(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_CAPABILITIES_OUT_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t outlen;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_GET_CAPABILITIES_IN_LEN != 0);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_CAPABILITIES, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < sizeof(outbuf)) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"unable to read datapath firmware capabilities\n");\r\nreturn -EIO;\r\n}\r\nnic_data->datapath_caps =\r\nMCDI_DWORD(outbuf, GET_CAPABILITIES_OUT_FLAGS1);\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_TX_TSO_LBN))) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"current firmware does not support TSO\n");\r\nreturn -ENODEV;\r\n}\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_RX_PREFIX_LEN_14_LBN))) {\r\nnetif_err(efx, probe, efx->net_dev,\r\n"current firmware does not support an RX prefix\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_get_sysclk_freq(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_CLOCK_OUT_LEN);\r\nint rc;\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_CLOCK, NULL, 0,\r\noutbuf, sizeof(outbuf), NULL);\r\nif (rc)\r\nreturn rc;\r\nrc = MCDI_DWORD(outbuf, GET_CLOCK_OUT_SYS_FREQ);\r\nreturn rc > 0 ? rc : -ERANGE;\r\n}\r\nstatic int efx_ef10_get_mac_address(struct efx_nic *efx, u8 *mac_address)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_MAC_ADDRESSES_OUT_LEN);\r\nsize_t outlen;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_GET_MAC_ADDRESSES_IN_LEN != 0);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_MAC_ADDRESSES, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_GET_MAC_ADDRESSES_OUT_LEN)\r\nreturn -EIO;\r\nether_addr_copy(mac_address,\r\nMCDI_PTR(outbuf, GET_MAC_ADDRESSES_OUT_MAC_ADDR_BASE));\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_probe(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data;\r\nint i, rc;\r\nefx->max_channels =\r\nmin_t(unsigned int,\r\nEFX_MAX_CHANNELS,\r\nresource_size(&efx->pci_dev->resource[EFX_MEM_BAR]) /\r\n(EFX_VI_PAGE_SIZE * EFX_TXQ_TYPES));\r\nif (WARN_ON(efx->max_channels == 0))\r\nreturn -EIO;\r\nnic_data = kzalloc(sizeof(*nic_data), GFP_KERNEL);\r\nif (!nic_data)\r\nreturn -ENOMEM;\r\nefx->nic_data = nic_data;\r\nrc = efx_nic_alloc_buffer(efx, &nic_data->mcdi_buf,\r\n8 + MCDI_CTL_SDU_LEN_MAX_V2, GFP_KERNEL);\r\nif (rc)\r\ngoto fail1;\r\ni = 0;\r\nfor (;;) {\r\nrc = efx_ef10_get_warm_boot_count(efx);\r\nif (rc >= 0)\r\nbreak;\r\nif (++i == 5)\r\ngoto fail2;\r\nssleep(1);\r\n}\r\nnic_data->warm_boot_count = rc;\r\nnic_data->rx_rss_context = EFX_EF10_RSS_CONTEXT_INVALID;\r\n_efx_writed(efx, cpu_to_le32(1), ER_DZ_MC_DB_HWRD);\r\nrc = efx_mcdi_init(efx);\r\nif (rc)\r\ngoto fail2;\r\nrc = efx_mcdi_reset(efx, RESET_TYPE_ALL);\r\nif (rc)\r\ngoto fail3;\r\nrc = efx_mcdi_log_ctrl(efx, true, false, 0);\r\nif (rc)\r\ngoto fail3;\r\nrc = efx_ef10_init_datapath_caps(efx);\r\nif (rc < 0)\r\ngoto fail3;\r\nefx->rx_packet_len_offset =\r\nES_DZ_RX_PREFIX_PKTLEN_OFST - ES_DZ_RX_PREFIX_SIZE;\r\nrc = efx_mcdi_port_get_number(efx);\r\nif (rc < 0)\r\ngoto fail3;\r\nefx->port_num = rc;\r\nrc = efx_ef10_get_mac_address(efx, efx->net_dev->perm_addr);\r\nif (rc)\r\ngoto fail3;\r\nrc = efx_ef10_get_sysclk_freq(efx);\r\nif (rc < 0)\r\ngoto fail3;\r\nefx->timer_quantum_ns = 1536000 / rc;\r\nrc = efx_mcdi_set_workaround(efx, MC_CMD_WORKAROUND_BUG35388, true);\r\nif (rc == 0)\r\nnic_data->workaround_35388 = true;\r\nelse if (rc != -ENOSYS && rc != -ENOENT)\r\ngoto fail3;\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"workaround for bug 35388 is %sabled\n",\r\nnic_data->workaround_35388 ? "en" : "dis");\r\nrc = efx_mcdi_mon_probe(efx);\r\nif (rc)\r\ngoto fail3;\r\nefx_ptp_probe(efx, NULL);\r\nreturn 0;\r\nfail3:\r\nefx_mcdi_fini(efx);\r\nfail2:\r\nefx_nic_free_buffer(efx, &nic_data->mcdi_buf);\r\nfail1:\r\nkfree(nic_data);\r\nefx->nic_data = NULL;\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_free_vis(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF_OUT_OR_ERR(outbuf, 0);\r\nsize_t outlen;\r\nint rc = efx_mcdi_rpc_quiet(efx, MC_CMD_FREE_VIS, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc == -EALREADY)\r\nrc = 0;\r\nif (rc)\r\nefx_mcdi_display_error(efx, MC_CMD_FREE_VIS, 0, outbuf, outlen,\r\nrc);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_free_piobufs(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FREE_PIOBUF_IN_LEN);\r\nunsigned int i;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_FREE_PIOBUF_OUT_LEN != 0);\r\nfor (i = 0; i < nic_data->n_piobufs; i++) {\r\nMCDI_SET_DWORD(inbuf, FREE_PIOBUF_IN_PIOBUF_HANDLE,\r\nnic_data->piobuf_handle[i]);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FREE_PIOBUF, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nWARN_ON(rc);\r\n}\r\nnic_data->n_piobufs = 0;\r\n}\r\nstatic int efx_ef10_alloc_piobufs(struct efx_nic *efx, unsigned int n)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_ALLOC_PIOBUF_OUT_LEN);\r\nunsigned int i;\r\nsize_t outlen;\r\nint rc = 0;\r\nBUILD_BUG_ON(MC_CMD_ALLOC_PIOBUF_IN_LEN != 0);\r\nfor (i = 0; i < n; i++) {\r\nrc = efx_mcdi_rpc(efx, MC_CMD_ALLOC_PIOBUF, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nbreak;\r\nif (outlen < MC_CMD_ALLOC_PIOBUF_OUT_LEN) {\r\nrc = -EIO;\r\nbreak;\r\n}\r\nnic_data->piobuf_handle[i] =\r\nMCDI_DWORD(outbuf, ALLOC_PIOBUF_OUT_PIOBUF_HANDLE);\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"allocated PIO buffer %u handle %x\n", i,\r\nnic_data->piobuf_handle[i]);\r\n}\r\nnic_data->n_piobufs = i;\r\nif (rc)\r\nefx_ef10_free_piobufs(efx);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_link_piobufs(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(inbuf,\r\nmax(MC_CMD_LINK_PIOBUF_IN_LEN,\r\nMC_CMD_UNLINK_PIOBUF_IN_LEN));\r\nstruct efx_channel *channel;\r\nstruct efx_tx_queue *tx_queue;\r\nunsigned int offset, index;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_LINK_PIOBUF_OUT_LEN != 0);\r\nBUILD_BUG_ON(MC_CMD_UNLINK_PIOBUF_OUT_LEN != 0);\r\nfor (index = 0; index < nic_data->n_piobufs; ++index) {\r\nMCDI_SET_DWORD(inbuf, LINK_PIOBUF_IN_PIOBUF_HANDLE,\r\nnic_data->piobuf_handle[index]);\r\nMCDI_SET_DWORD(inbuf, LINK_PIOBUF_IN_TXQ_INSTANCE,\r\nnic_data->pio_write_vi_base + index);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_LINK_PIOBUF,\r\ninbuf, MC_CMD_LINK_PIOBUF_IN_LEN,\r\nNULL, 0, NULL);\r\nif (rc) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"failed to link VI %u to PIO buffer %u (%d)\n",\r\nnic_data->pio_write_vi_base + index, index,\r\nrc);\r\ngoto fail;\r\n}\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"linked VI %u to PIO buffer %u\n",\r\nnic_data->pio_write_vi_base + index, index);\r\n}\r\nefx_for_each_channel(channel, efx) {\r\nefx_for_each_channel_tx_queue(tx_queue, channel) {\r\noffset = ((efx->tx_channel_offset + efx->n_tx_channels -\r\ntx_queue->channel->channel - 1) *\r\nefx_piobuf_size);\r\nindex = offset / ER_DZ_TX_PIOBUF_SIZE;\r\noffset = offset % ER_DZ_TX_PIOBUF_SIZE;\r\nif (tx_queue->queue == nic_data->pio_write_vi_base) {\r\nBUG_ON(index != 0);\r\nrc = 0;\r\n} else {\r\nMCDI_SET_DWORD(inbuf,\r\nLINK_PIOBUF_IN_PIOBUF_HANDLE,\r\nnic_data->piobuf_handle[index]);\r\nMCDI_SET_DWORD(inbuf,\r\nLINK_PIOBUF_IN_TXQ_INSTANCE,\r\ntx_queue->queue);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_LINK_PIOBUF,\r\ninbuf, MC_CMD_LINK_PIOBUF_IN_LEN,\r\nNULL, 0, NULL);\r\n}\r\nif (rc) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"failed to link VI %u to PIO buffer %u (%d)\n",\r\ntx_queue->queue, index, rc);\r\ntx_queue->piobuf = NULL;\r\n} else {\r\ntx_queue->piobuf =\r\nnic_data->pio_write_base +\r\nindex * EFX_VI_PAGE_SIZE + offset;\r\ntx_queue->piobuf_offset = offset;\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"linked VI %u to PIO buffer %u offset %x addr %p\n",\r\ntx_queue->queue, index,\r\ntx_queue->piobuf_offset,\r\ntx_queue->piobuf);\r\n}\r\n}\r\n}\r\nreturn 0;\r\nfail:\r\nwhile (index--) {\r\nMCDI_SET_DWORD(inbuf, UNLINK_PIOBUF_IN_TXQ_INSTANCE,\r\nnic_data->pio_write_vi_base + index);\r\nefx_mcdi_rpc(efx, MC_CMD_UNLINK_PIOBUF,\r\ninbuf, MC_CMD_UNLINK_PIOBUF_IN_LEN,\r\nNULL, 0, NULL);\r\n}\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_alloc_piobufs(struct efx_nic *efx, unsigned int n)\r\n{\r\nreturn n == 0 ? 0 : -ENOBUFS;\r\n}\r\nstatic int efx_ef10_link_piobufs(struct efx_nic *efx)\r\n{\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_free_piobufs(struct efx_nic *efx)\r\n{\r\n}\r\nstatic void efx_ef10_remove(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\nefx_ptp_remove(efx);\r\nefx_mcdi_mon_remove(efx);\r\nefx_ef10_rx_free_indir_table(efx);\r\nif (nic_data->wc_membase)\r\niounmap(nic_data->wc_membase);\r\nrc = efx_ef10_free_vis(efx);\r\nWARN_ON(rc != 0);\r\nif (!nic_data->must_restore_piobufs)\r\nefx_ef10_free_piobufs(efx);\r\nefx_mcdi_fini(efx);\r\nefx_nic_free_buffer(efx, &nic_data->mcdi_buf);\r\nkfree(nic_data);\r\n}\r\nstatic int efx_ef10_alloc_vis(struct efx_nic *efx,\r\nunsigned int min_vis, unsigned int max_vis)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_ALLOC_VIS_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_ALLOC_VIS_OUT_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, ALLOC_VIS_IN_MIN_VI_COUNT, min_vis);\r\nMCDI_SET_DWORD(inbuf, ALLOC_VIS_IN_MAX_VI_COUNT, max_vis);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_ALLOC_VIS, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (outlen < MC_CMD_ALLOC_VIS_OUT_LEN)\r\nreturn -EIO;\r\nnetif_dbg(efx, drv, efx->net_dev, "base VI is A0x%03x\n",\r\nMCDI_DWORD(outbuf, ALLOC_VIS_OUT_VI_BASE));\r\nnic_data->vi_base = MCDI_DWORD(outbuf, ALLOC_VIS_OUT_VI_BASE);\r\nnic_data->n_allocated_vis = MCDI_DWORD(outbuf, ALLOC_VIS_OUT_VI_COUNT);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_dimension_resources(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nunsigned int uc_mem_map_size, wc_mem_map_size;\r\nunsigned int min_vis, pio_write_vi_base, max_vis;\r\nvoid __iomem *membase;\r\nint rc;\r\nmin_vis = max(efx->n_channels, efx->n_tx_channels * EFX_TXQ_TYPES);\r\n#ifdef EFX_USE_PIO\r\nif (efx_piobuf_size != 0 &&\r\nER_DZ_TX_PIOBUF_SIZE / efx_piobuf_size * EF10_TX_PIOBUF_COUNT >=\r\nefx->n_tx_channels) {\r\nunsigned int n_piobufs =\r\nDIV_ROUND_UP(efx->n_tx_channels,\r\nER_DZ_TX_PIOBUF_SIZE / efx_piobuf_size);\r\nrc = efx_ef10_alloc_piobufs(efx, n_piobufs);\r\nif (rc)\r\nnetif_err(efx, probe, efx->net_dev,\r\n"failed to allocate PIO buffers (%d)\n", rc);\r\nelse\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"allocated %u PIO buffers\n", n_piobufs);\r\n}\r\n#else\r\nnic_data->n_piobufs = 0;\r\n#endif\r\nuc_mem_map_size = PAGE_ALIGN((min_vis - 1) * EFX_VI_PAGE_SIZE +\r\nER_DZ_TX_PIOBUF);\r\nif (nic_data->n_piobufs) {\r\npio_write_vi_base = uc_mem_map_size / EFX_VI_PAGE_SIZE;\r\nwc_mem_map_size = (PAGE_ALIGN((pio_write_vi_base +\r\nnic_data->n_piobufs) *\r\nEFX_VI_PAGE_SIZE) -\r\nuc_mem_map_size);\r\nmax_vis = pio_write_vi_base + nic_data->n_piobufs;\r\n} else {\r\npio_write_vi_base = 0;\r\nwc_mem_map_size = 0;\r\nmax_vis = min_vis;\r\n}\r\nrc = efx_ef10_free_vis(efx);\r\nif (rc != 0)\r\nreturn rc;\r\nrc = efx_ef10_alloc_vis(efx, min_vis, max_vis);\r\nif (rc != 0)\r\nreturn rc;\r\nif (nic_data->n_piobufs &&\r\nnic_data->n_allocated_vis <\r\npio_write_vi_base + nic_data->n_piobufs) {\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"%u VIs are not sufficient to map %u PIO buffers\n",\r\nnic_data->n_allocated_vis, nic_data->n_piobufs);\r\nefx_ef10_free_piobufs(efx);\r\n}\r\nmembase = ioremap_nocache(efx->membase_phys, uc_mem_map_size);\r\nif (!membase) {\r\nnetif_err(efx, probe, efx->net_dev,\r\n"could not shrink memory BAR to %x\n",\r\nuc_mem_map_size);\r\nreturn -ENOMEM;\r\n}\r\niounmap(efx->membase);\r\nefx->membase = membase;\r\nif (wc_mem_map_size) {\r\nnic_data->wc_membase = ioremap_wc(efx->membase_phys +\r\nuc_mem_map_size,\r\nwc_mem_map_size);\r\nif (!nic_data->wc_membase) {\r\nnetif_err(efx, probe, efx->net_dev,\r\n"could not allocate WC mapping of size %x\n",\r\nwc_mem_map_size);\r\nreturn -ENOMEM;\r\n}\r\nnic_data->pio_write_vi_base = pio_write_vi_base;\r\nnic_data->pio_write_base =\r\nnic_data->wc_membase +\r\n(pio_write_vi_base * EFX_VI_PAGE_SIZE + ER_DZ_TX_PIOBUF -\r\nuc_mem_map_size);\r\nrc = efx_ef10_link_piobufs(efx);\r\nif (rc)\r\nefx_ef10_free_piobufs(efx);\r\n}\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"memory BAR at %pa (virtual %p+%x UC, %p+%x WC)\n",\r\n&efx->membase_phys, efx->membase, uc_mem_map_size,\r\nnic_data->wc_membase, wc_mem_map_size);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_init_nic(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\nif (nic_data->must_check_datapath_caps) {\r\nrc = efx_ef10_init_datapath_caps(efx);\r\nif (rc)\r\nreturn rc;\r\nnic_data->must_check_datapath_caps = false;\r\n}\r\nif (nic_data->must_realloc_vis) {\r\nrc = efx_ef10_alloc_vis(efx, nic_data->n_allocated_vis,\r\nnic_data->n_allocated_vis);\r\nif (rc)\r\nreturn rc;\r\nnic_data->must_realloc_vis = false;\r\n}\r\nif (nic_data->must_restore_piobufs && nic_data->n_piobufs) {\r\nrc = efx_ef10_alloc_piobufs(efx, nic_data->n_piobufs);\r\nif (rc == 0) {\r\nrc = efx_ef10_link_piobufs(efx);\r\nif (rc)\r\nefx_ef10_free_piobufs(efx);\r\n}\r\nif (rc)\r\nnetif_err(efx, drv, efx->net_dev,\r\n"failed to restore PIO buffers (%d)\n", rc);\r\nnic_data->must_restore_piobufs = false;\r\n}\r\nefx_ef10_rx_push_rss_config(efx);\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_reset_mc_allocations(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nnic_data->must_realloc_vis = true;\r\nnic_data->must_restore_filters = true;\r\nnic_data->must_restore_piobufs = true;\r\nnic_data->rx_rss_context = EFX_EF10_RSS_CONTEXT_INVALID;\r\n}\r\nstatic int efx_ef10_map_reset_flags(u32 *flags)\r\n{\r\nenum {\r\nEF10_RESET_PORT = ((ETH_RESET_MAC | ETH_RESET_PHY) <<\r\nETH_RESET_SHARED_SHIFT),\r\nEF10_RESET_MC = ((ETH_RESET_DMA | ETH_RESET_FILTER |\r\nETH_RESET_OFFLOAD | ETH_RESET_MAC |\r\nETH_RESET_PHY | ETH_RESET_MGMT) <<\r\nETH_RESET_SHARED_SHIFT)\r\n};\r\nif ((*flags & EF10_RESET_MC) == EF10_RESET_MC) {\r\n*flags &= ~EF10_RESET_MC;\r\nreturn RESET_TYPE_WORLD;\r\n}\r\nif ((*flags & EF10_RESET_PORT) == EF10_RESET_PORT) {\r\n*flags &= ~EF10_RESET_PORT;\r\nreturn RESET_TYPE_ALL;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int efx_ef10_reset(struct efx_nic *efx, enum reset_type reset_type)\r\n{\r\nint rc = efx_mcdi_reset(efx, reset_type);\r\nif ((reset_type == RESET_TYPE_ALL ||\r\nreset_type == RESET_TYPE_MCDI_TIMEOUT) && !rc)\r\nefx_ef10_reset_mc_allocations(efx);\r\nreturn rc;\r\n}\r\nstatic u64 efx_ef10_raw_stat_mask(struct efx_nic *efx)\r\n{\r\nu64 raw_mask = HUNT_COMMON_STAT_MASK;\r\nu32 port_caps = efx_mcdi_phy_get_caps(efx);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (port_caps & (1 << MC_CMD_PHY_CAP_40000FDX_LBN))\r\nraw_mask |= HUNT_40G_EXTRA_STAT_MASK;\r\nelse\r\nraw_mask |= HUNT_10G_ONLY_STAT_MASK;\r\nif (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_PM_AND_RXDP_COUNTERS_LBN))\r\nraw_mask |= HUNT_PM_AND_RXDP_STAT_MASK;\r\nreturn raw_mask;\r\n}\r\nstatic void efx_ef10_get_stat_mask(struct efx_nic *efx, unsigned long *mask)\r\n{\r\nu64 raw_mask = efx_ef10_raw_stat_mask(efx);\r\n#if BITS_PER_LONG == 64\r\nmask[0] = raw_mask;\r\n#else\r\nmask[0] = raw_mask & 0xffffffff;\r\nmask[1] = raw_mask >> 32;\r\n#endif\r\n}\r\nstatic size_t efx_ef10_describe_stats(struct efx_nic *efx, u8 *names)\r\n{\r\nDECLARE_BITMAP(mask, EF10_STAT_COUNT);\r\nefx_ef10_get_stat_mask(efx, mask);\r\nreturn efx_nic_describe_stats(efx_ef10_stat_desc, EF10_STAT_COUNT,\r\nmask, names);\r\n}\r\nstatic int efx_ef10_try_update_nic_stats(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nDECLARE_BITMAP(mask, EF10_STAT_COUNT);\r\n__le64 generation_start, generation_end;\r\nu64 *stats = nic_data->stats;\r\n__le64 *dma_stats;\r\nefx_ef10_get_stat_mask(efx, mask);\r\ndma_stats = efx->stats_buffer.addr;\r\nnic_data = efx->nic_data;\r\ngeneration_end = dma_stats[MC_CMD_MAC_GENERATION_END];\r\nif (generation_end == EFX_MC_STATS_GENERATION_INVALID)\r\nreturn 0;\r\nrmb();\r\nefx_nic_update_stats(efx_ef10_stat_desc, EF10_STAT_COUNT, mask,\r\nstats, efx->stats_buffer.addr, false);\r\nrmb();\r\ngeneration_start = dma_stats[MC_CMD_MAC_GENERATION_START];\r\nif (generation_end != generation_start)\r\nreturn -EAGAIN;\r\nefx_nic_fix_nodesc_drop_stat(efx, &stats[EF10_STAT_rx_nodesc_drops]);\r\nstats[EF10_STAT_rx_good_bytes] =\r\nstats[EF10_STAT_rx_bytes] -\r\nstats[EF10_STAT_rx_bytes_minus_good_bytes];\r\nefx_update_diff_stat(&stats[EF10_STAT_rx_bad_bytes],\r\nstats[EF10_STAT_rx_bytes_minus_good_bytes]);\r\nefx_update_sw_stats(efx, stats);\r\nreturn 0;\r\n}\r\nstatic size_t efx_ef10_update_stats(struct efx_nic *efx, u64 *full_stats,\r\nstruct rtnl_link_stats64 *core_stats)\r\n{\r\nDECLARE_BITMAP(mask, EF10_STAT_COUNT);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu64 *stats = nic_data->stats;\r\nsize_t stats_count = 0, index;\r\nint retry;\r\nefx_ef10_get_stat_mask(efx, mask);\r\nfor (retry = 0; retry < 100; ++retry) {\r\nif (efx_ef10_try_update_nic_stats(efx) == 0)\r\nbreak;\r\nudelay(100);\r\n}\r\nif (full_stats) {\r\nfor_each_set_bit(index, mask, EF10_STAT_COUNT) {\r\nif (efx_ef10_stat_desc[index].name) {\r\n*full_stats++ = stats[index];\r\n++stats_count;\r\n}\r\n}\r\n}\r\nif (core_stats) {\r\ncore_stats->rx_packets = stats[EF10_STAT_rx_packets];\r\ncore_stats->tx_packets = stats[EF10_STAT_tx_packets];\r\ncore_stats->rx_bytes = stats[EF10_STAT_rx_bytes];\r\ncore_stats->tx_bytes = stats[EF10_STAT_tx_bytes];\r\ncore_stats->rx_dropped = stats[EF10_STAT_rx_nodesc_drops] +\r\nstats[GENERIC_STAT_rx_nodesc_trunc] +\r\nstats[GENERIC_STAT_rx_noskb_drops];\r\ncore_stats->multicast = stats[EF10_STAT_rx_multicast];\r\ncore_stats->rx_length_errors =\r\nstats[EF10_STAT_rx_gtjumbo] +\r\nstats[EF10_STAT_rx_length_error];\r\ncore_stats->rx_crc_errors = stats[EF10_STAT_rx_bad];\r\ncore_stats->rx_frame_errors = stats[EF10_STAT_rx_align_error];\r\ncore_stats->rx_fifo_errors = stats[EF10_STAT_rx_overflow];\r\ncore_stats->rx_errors = (core_stats->rx_length_errors +\r\ncore_stats->rx_crc_errors +\r\ncore_stats->rx_frame_errors);\r\n}\r\nreturn stats_count;\r\n}\r\nstatic void efx_ef10_push_irq_moderation(struct efx_channel *channel)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nunsigned int mode, value;\r\nefx_dword_t timer_cmd;\r\nif (channel->irq_moderation) {\r\nmode = 3;\r\nvalue = channel->irq_moderation - 1;\r\n} else {\r\nmode = 0;\r\nvalue = 0;\r\n}\r\nif (EFX_EF10_WORKAROUND_35388(efx)) {\r\nEFX_POPULATE_DWORD_3(timer_cmd, ERF_DD_EVQ_IND_TIMER_FLAGS,\r\nEFE_DD_EVQ_IND_TIMER_FLAGS,\r\nERF_DD_EVQ_IND_TIMER_MODE, mode,\r\nERF_DD_EVQ_IND_TIMER_VAL, value);\r\nefx_writed_page(efx, &timer_cmd, ER_DD_EVQ_INDIRECT,\r\nchannel->channel);\r\n} else {\r\nEFX_POPULATE_DWORD_2(timer_cmd, ERF_DZ_TC_TIMER_MODE, mode,\r\nERF_DZ_TC_TIMER_VAL, value);\r\nefx_writed_page(efx, &timer_cmd, ER_DZ_EVQ_TMR,\r\nchannel->channel);\r\n}\r\n}\r\nstatic void efx_ef10_get_wol(struct efx_nic *efx, struct ethtool_wolinfo *wol)\r\n{\r\nwol->supported = 0;\r\nwol->wolopts = 0;\r\nmemset(&wol->sopass, 0, sizeof(wol->sopass));\r\n}\r\nstatic int efx_ef10_set_wol(struct efx_nic *efx, u32 type)\r\n{\r\nif (type != 0)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_mcdi_request(struct efx_nic *efx,\r\nconst efx_dword_t *hdr, size_t hdr_len,\r\nconst efx_dword_t *sdu, size_t sdu_len)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu8 *pdu = nic_data->mcdi_buf.addr;\r\nmemcpy(pdu, hdr, hdr_len);\r\nmemcpy(pdu + hdr_len, sdu, sdu_len);\r\nwmb();\r\n_efx_writed(efx, cpu_to_le32((u64)nic_data->mcdi_buf.dma_addr >> 32),\r\nER_DZ_MC_DB_LWRD);\r\n_efx_writed(efx, cpu_to_le32((u32)nic_data->mcdi_buf.dma_addr),\r\nER_DZ_MC_DB_HWRD);\r\n}\r\nstatic bool efx_ef10_mcdi_poll_response(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nconst efx_dword_t hdr = *(const efx_dword_t *)nic_data->mcdi_buf.addr;\r\nrmb();\r\nreturn EFX_DWORD_FIELD(hdr, MCDI_HEADER_RESPONSE);\r\n}\r\nstatic void\r\nefx_ef10_mcdi_read_response(struct efx_nic *efx, efx_dword_t *outbuf,\r\nsize_t offset, size_t outlen)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nconst u8 *pdu = nic_data->mcdi_buf.addr;\r\nmemcpy(outbuf, pdu + offset, outlen);\r\n}\r\nstatic int efx_ef10_mcdi_poll_reboot(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\nrc = efx_ef10_get_warm_boot_count(efx);\r\nif (rc < 0) {\r\nreturn 0;\r\n}\r\nif (rc == nic_data->warm_boot_count)\r\nreturn 0;\r\nnic_data->warm_boot_count = rc;\r\nefx_ef10_reset_mc_allocations(efx);\r\nnic_data->must_check_datapath_caps = true;\r\nnic_data->stats[EF10_STAT_rx_bad_bytes] = 0;\r\nreturn -EIO;\r\n}\r\nstatic irqreturn_t efx_ef10_msi_interrupt(int irq, void *dev_id)\r\n{\r\nstruct efx_msi_context *context = dev_id;\r\nstruct efx_nic *efx = context->efx;\r\nnetif_vdbg(efx, intr, efx->net_dev,\r\n"IRQ %d on CPU %d\n", irq, raw_smp_processor_id());\r\nif (likely(ACCESS_ONCE(efx->irq_soft_enabled))) {\r\nif (context->index == efx->irq_level)\r\nefx->last_irq_cpu = raw_smp_processor_id();\r\nefx_schedule_channel_irq(efx->channel[context->index]);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t efx_ef10_legacy_interrupt(int irq, void *dev_id)\r\n{\r\nstruct efx_nic *efx = dev_id;\r\nbool soft_enabled = ACCESS_ONCE(efx->irq_soft_enabled);\r\nstruct efx_channel *channel;\r\nefx_dword_t reg;\r\nu32 queues;\r\nefx_readd(efx, &reg, ER_DZ_BIU_INT_ISR);\r\nqueues = EFX_DWORD_FIELD(reg, ERF_DZ_ISR_REG);\r\nif (queues == 0)\r\nreturn IRQ_NONE;\r\nif (likely(soft_enabled)) {\r\nif (queues & (1U << efx->irq_level))\r\nefx->last_irq_cpu = raw_smp_processor_id();\r\nefx_for_each_channel(channel, efx) {\r\nif (queues & 1)\r\nefx_schedule_channel_irq(channel);\r\nqueues >>= 1;\r\n}\r\n}\r\nnetif_vdbg(efx, intr, efx->net_dev,\r\n"IRQ %d on CPU %d status " EFX_DWORD_FMT "\n",\r\nirq, raw_smp_processor_id(), EFX_DWORD_VAL(reg));\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void efx_ef10_irq_test_generate(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_TRIGGER_INTERRUPT_IN_LEN);\r\nBUILD_BUG_ON(MC_CMD_TRIGGER_INTERRUPT_OUT_LEN != 0);\r\nMCDI_SET_DWORD(inbuf, TRIGGER_INTERRUPT_IN_INTR_LEVEL, efx->irq_level);\r\n(void) efx_mcdi_rpc(efx, MC_CMD_TRIGGER_INTERRUPT,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\n}\r\nstatic int efx_ef10_tx_probe(struct efx_tx_queue *tx_queue)\r\n{\r\nreturn efx_nic_alloc_buffer(tx_queue->efx, &tx_queue->txd.buf,\r\n(tx_queue->ptr_mask + 1) *\r\nsizeof(efx_qword_t),\r\nGFP_KERNEL);\r\n}\r\nstatic inline void efx_ef10_push_tx_desc(struct efx_tx_queue *tx_queue,\r\nconst efx_qword_t *txd)\r\n{\r\nunsigned int write_ptr;\r\nefx_oword_t reg;\r\nwrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\r\nEFX_POPULATE_OWORD_1(reg, ERF_DZ_TX_DESC_WPTR, write_ptr);\r\nreg.qword[0] = *txd;\r\nefx_writeo_page(tx_queue->efx, &reg,\r\nER_DZ_TX_DESC_UPD, tx_queue->queue);\r\n}\r\nstatic void efx_ef10_tx_init(struct efx_tx_queue *tx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_INIT_TXQ_IN_LEN(EFX_MAX_DMAQ_SIZE * 8 /\r\nEFX_BUF_SIZE));\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_INIT_TXQ_OUT_LEN);\r\nbool csum_offload = tx_queue->queue & EFX_TXQ_TYPE_OFFLOAD;\r\nsize_t entries = tx_queue->txd.buf.len / EFX_BUF_SIZE;\r\nstruct efx_channel *channel = tx_queue->channel;\r\nstruct efx_nic *efx = tx_queue->efx;\r\nsize_t inlen, outlen;\r\ndma_addr_t dma_addr;\r\nefx_qword_t *txd;\r\nint rc;\r\nint i;\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_SIZE, tx_queue->ptr_mask + 1);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_TARGET_EVQ, channel->channel);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_LABEL, tx_queue->queue);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_INSTANCE, tx_queue->queue);\r\nMCDI_POPULATE_DWORD_2(inbuf, INIT_TXQ_IN_FLAGS,\r\nINIT_TXQ_IN_FLAG_IP_CSUM_DIS, !csum_offload,\r\nINIT_TXQ_IN_FLAG_TCP_CSUM_DIS, !csum_offload);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_OWNER_ID, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_PORT_ID, EVB_PORT_ID_ASSIGNED);\r\ndma_addr = tx_queue->txd.buf.dma_addr;\r\nnetif_dbg(efx, hw, efx->net_dev, "pushing TXQ %d. %zu entries (%llx)\n",\r\ntx_queue->queue, entries, (u64)dma_addr);\r\nfor (i = 0; i < entries; ++i) {\r\nMCDI_SET_ARRAY_QWORD(inbuf, INIT_TXQ_IN_DMA_ADDR, i, dma_addr);\r\ndma_addr += EFX_BUF_SIZE;\r\n}\r\ninlen = MC_CMD_INIT_TXQ_IN_LEN(entries);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_INIT_TXQ, inbuf, inlen,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\ngoto fail;\r\ntx_queue->buffer[0].flags = EFX_TX_BUF_OPTION;\r\ntx_queue->insert_count = 1;\r\ntxd = efx_tx_desc(tx_queue, 0);\r\nEFX_POPULATE_QWORD_4(*txd,\r\nESF_DZ_TX_DESC_IS_OPT, true,\r\nESF_DZ_TX_OPTION_TYPE,\r\nESE_DZ_TX_OPTION_DESC_CRC_CSUM,\r\nESF_DZ_TX_OPTION_UDP_TCP_CSUM, csum_offload,\r\nESF_DZ_TX_OPTION_IP_CSUM, csum_offload);\r\ntx_queue->write_count = 1;\r\nwmb();\r\nefx_ef10_push_tx_desc(tx_queue, txd);\r\nreturn;\r\nfail:\r\nnetdev_WARN(efx->net_dev, "failed to initialise TXQ %d\n",\r\ntx_queue->queue);\r\n}\r\nstatic void efx_ef10_tx_fini(struct efx_tx_queue *tx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FINI_TXQ_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_FINI_TXQ_OUT_LEN);\r\nstruct efx_nic *efx = tx_queue->efx;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, FINI_TXQ_IN_INSTANCE,\r\ntx_queue->queue);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FINI_TXQ, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc && rc != -EALREADY)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nefx_mcdi_display_error(efx, MC_CMD_FINI_TXQ, MC_CMD_FINI_TXQ_IN_LEN,\r\noutbuf, outlen, rc);\r\n}\r\nstatic void efx_ef10_tx_remove(struct efx_tx_queue *tx_queue)\r\n{\r\nefx_nic_free_buffer(tx_queue->efx, &tx_queue->txd.buf);\r\n}\r\nstatic inline void efx_ef10_notify_tx_desc(struct efx_tx_queue *tx_queue)\r\n{\r\nunsigned int write_ptr;\r\nefx_dword_t reg;\r\nwrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\r\nEFX_POPULATE_DWORD_1(reg, ERF_DZ_TX_DESC_WPTR_DWORD, write_ptr);\r\nefx_writed_page(tx_queue->efx, &reg,\r\nER_DZ_TX_DESC_UPD_DWORD, tx_queue->queue);\r\n}\r\nstatic void efx_ef10_tx_write(struct efx_tx_queue *tx_queue)\r\n{\r\nunsigned int old_write_count = tx_queue->write_count;\r\nstruct efx_tx_buffer *buffer;\r\nunsigned int write_ptr;\r\nefx_qword_t *txd;\r\nBUG_ON(tx_queue->write_count == tx_queue->insert_count);\r\ndo {\r\nwrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\r\nbuffer = &tx_queue->buffer[write_ptr];\r\ntxd = efx_tx_desc(tx_queue, write_ptr);\r\n++tx_queue->write_count;\r\nif (buffer->flags & EFX_TX_BUF_OPTION) {\r\n*txd = buffer->option;\r\n} else {\r\nBUILD_BUG_ON(EFX_TX_BUF_CONT != 1);\r\nEFX_POPULATE_QWORD_3(\r\n*txd,\r\nESF_DZ_TX_KER_CONT,\r\nbuffer->flags & EFX_TX_BUF_CONT,\r\nESF_DZ_TX_KER_BYTE_CNT, buffer->len,\r\nESF_DZ_TX_KER_BUF_ADDR, buffer->dma_addr);\r\n}\r\n} while (tx_queue->write_count != tx_queue->insert_count);\r\nwmb();\r\nif (efx_nic_may_push_tx_desc(tx_queue, old_write_count)) {\r\ntxd = efx_tx_desc(tx_queue,\r\nold_write_count & tx_queue->ptr_mask);\r\nefx_ef10_push_tx_desc(tx_queue, txd);\r\n++tx_queue->pushes;\r\n} else {\r\nefx_ef10_notify_tx_desc(tx_queue);\r\n}\r\n}\r\nstatic int efx_ef10_alloc_rss_context(struct efx_nic *efx, u32 *context)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_RSS_CONTEXT_ALLOC_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_RSS_CONTEXT_ALLOC_OUT_LEN);\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_ALLOC_IN_UPSTREAM_PORT_ID,\r\nEVB_PORT_ID_ASSIGNED);\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_ALLOC_IN_TYPE,\r\nMC_CMD_RSS_CONTEXT_ALLOC_IN_TYPE_EXCLUSIVE);\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_ALLOC_IN_NUM_QUEUES,\r\nEFX_MAX_CHANNELS);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_ALLOC, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (outlen < MC_CMD_RSS_CONTEXT_ALLOC_OUT_LEN)\r\nreturn -EIO;\r\n*context = MCDI_DWORD(outbuf, RSS_CONTEXT_ALLOC_OUT_RSS_CONTEXT_ID);\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_free_rss_context(struct efx_nic *efx, u32 context)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_RSS_CONTEXT_FREE_IN_LEN);\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_FREE_IN_RSS_CONTEXT_ID,\r\ncontext);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_FREE, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nWARN_ON(rc != 0);\r\n}\r\nstatic int efx_ef10_populate_rss_table(struct efx_nic *efx, u32 context)\r\n{\r\nMCDI_DECLARE_BUF(tablebuf, MC_CMD_RSS_CONTEXT_SET_TABLE_IN_LEN);\r\nMCDI_DECLARE_BUF(keybuf, MC_CMD_RSS_CONTEXT_SET_KEY_IN_LEN);\r\nint i, rc;\r\nMCDI_SET_DWORD(tablebuf, RSS_CONTEXT_SET_TABLE_IN_RSS_CONTEXT_ID,\r\ncontext);\r\nBUILD_BUG_ON(ARRAY_SIZE(efx->rx_indir_table) !=\r\nMC_CMD_RSS_CONTEXT_SET_TABLE_IN_INDIRECTION_TABLE_LEN);\r\nfor (i = 0; i < ARRAY_SIZE(efx->rx_indir_table); ++i)\r\nMCDI_PTR(tablebuf,\r\nRSS_CONTEXT_SET_TABLE_IN_INDIRECTION_TABLE)[i] =\r\n(u8) efx->rx_indir_table[i];\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_SET_TABLE, tablebuf,\r\nsizeof(tablebuf), NULL, 0, NULL);\r\nif (rc != 0)\r\nreturn rc;\r\nMCDI_SET_DWORD(keybuf, RSS_CONTEXT_SET_KEY_IN_RSS_CONTEXT_ID,\r\ncontext);\r\nBUILD_BUG_ON(ARRAY_SIZE(efx->rx_hash_key) !=\r\nMC_CMD_RSS_CONTEXT_SET_KEY_IN_TOEPLITZ_KEY_LEN);\r\nfor (i = 0; i < ARRAY_SIZE(efx->rx_hash_key); ++i)\r\nMCDI_PTR(keybuf, RSS_CONTEXT_SET_KEY_IN_TOEPLITZ_KEY)[i] =\r\nefx->rx_hash_key[i];\r\nreturn efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_SET_KEY, keybuf,\r\nsizeof(keybuf), NULL, 0, NULL);\r\n}\r\nstatic void efx_ef10_rx_free_indir_table(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (nic_data->rx_rss_context != EFX_EF10_RSS_CONTEXT_INVALID)\r\nefx_ef10_free_rss_context(efx, nic_data->rx_rss_context);\r\nnic_data->rx_rss_context = EFX_EF10_RSS_CONTEXT_INVALID;\r\n}\r\nstatic void efx_ef10_rx_push_rss_config(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\nnetif_dbg(efx, drv, efx->net_dev, "pushing RSS config\n");\r\nif (nic_data->rx_rss_context == EFX_EF10_RSS_CONTEXT_INVALID) {\r\nrc = efx_ef10_alloc_rss_context(efx, &nic_data->rx_rss_context);\r\nif (rc != 0)\r\ngoto fail;\r\n}\r\nrc = efx_ef10_populate_rss_table(efx, nic_data->rx_rss_context);\r\nif (rc != 0)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nnetif_err(efx, hw, efx->net_dev, "%s: failed rc=%d\n", __func__, rc);\r\n}\r\nstatic int efx_ef10_rx_probe(struct efx_rx_queue *rx_queue)\r\n{\r\nreturn efx_nic_alloc_buffer(rx_queue->efx, &rx_queue->rxd.buf,\r\n(rx_queue->ptr_mask + 1) *\r\nsizeof(efx_qword_t),\r\nGFP_KERNEL);\r\n}\r\nstatic void efx_ef10_rx_init(struct efx_rx_queue *rx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_INIT_RXQ_IN_LEN(EFX_MAX_DMAQ_SIZE * 8 /\r\nEFX_BUF_SIZE));\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_INIT_RXQ_OUT_LEN);\r\nstruct efx_channel *channel = efx_rx_queue_channel(rx_queue);\r\nsize_t entries = rx_queue->rxd.buf.len / EFX_BUF_SIZE;\r\nstruct efx_nic *efx = rx_queue->efx;\r\nsize_t inlen, outlen;\r\ndma_addr_t dma_addr;\r\nint rc;\r\nint i;\r\nrx_queue->scatter_n = 0;\r\nrx_queue->scatter_len = 0;\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_SIZE, rx_queue->ptr_mask + 1);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_TARGET_EVQ, channel->channel);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_LABEL, efx_rx_queue_index(rx_queue));\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_INSTANCE,\r\nefx_rx_queue_index(rx_queue));\r\nMCDI_POPULATE_DWORD_2(inbuf, INIT_RXQ_IN_FLAGS,\r\nINIT_RXQ_IN_FLAG_PREFIX, 1,\r\nINIT_RXQ_IN_FLAG_TIMESTAMP, 1);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_OWNER_ID, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_PORT_ID, EVB_PORT_ID_ASSIGNED);\r\ndma_addr = rx_queue->rxd.buf.dma_addr;\r\nnetif_dbg(efx, hw, efx->net_dev, "pushing RXQ %d. %zu entries (%llx)\n",\r\nefx_rx_queue_index(rx_queue), entries, (u64)dma_addr);\r\nfor (i = 0; i < entries; ++i) {\r\nMCDI_SET_ARRAY_QWORD(inbuf, INIT_RXQ_IN_DMA_ADDR, i, dma_addr);\r\ndma_addr += EFX_BUF_SIZE;\r\n}\r\ninlen = MC_CMD_INIT_RXQ_IN_LEN(entries);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_INIT_RXQ, inbuf, inlen,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nnetdev_WARN(efx->net_dev, "failed to initialise RXQ %d\n",\r\nefx_rx_queue_index(rx_queue));\r\n}\r\nstatic void efx_ef10_rx_fini(struct efx_rx_queue *rx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FINI_RXQ_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_FINI_RXQ_OUT_LEN);\r\nstruct efx_nic *efx = rx_queue->efx;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, FINI_RXQ_IN_INSTANCE,\r\nefx_rx_queue_index(rx_queue));\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FINI_RXQ, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc && rc != -EALREADY)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nefx_mcdi_display_error(efx, MC_CMD_FINI_RXQ, MC_CMD_FINI_RXQ_IN_LEN,\r\noutbuf, outlen, rc);\r\n}\r\nstatic void efx_ef10_rx_remove(struct efx_rx_queue *rx_queue)\r\n{\r\nefx_nic_free_buffer(rx_queue->efx, &rx_queue->rxd.buf);\r\n}\r\nstatic inline void\r\nefx_ef10_build_rx_desc(struct efx_rx_queue *rx_queue, unsigned int index)\r\n{\r\nstruct efx_rx_buffer *rx_buf;\r\nefx_qword_t *rxd;\r\nrxd = efx_rx_desc(rx_queue, index);\r\nrx_buf = efx_rx_buffer(rx_queue, index);\r\nEFX_POPULATE_QWORD_2(*rxd,\r\nESF_DZ_RX_KER_BYTE_CNT, rx_buf->len,\r\nESF_DZ_RX_KER_BUF_ADDR, rx_buf->dma_addr);\r\n}\r\nstatic void efx_ef10_rx_write(struct efx_rx_queue *rx_queue)\r\n{\r\nstruct efx_nic *efx = rx_queue->efx;\r\nunsigned int write_count;\r\nefx_dword_t reg;\r\nwrite_count = rx_queue->added_count & ~7;\r\nif (rx_queue->notified_count == write_count)\r\nreturn;\r\ndo\r\nefx_ef10_build_rx_desc(\r\nrx_queue,\r\nrx_queue->notified_count & rx_queue->ptr_mask);\r\nwhile (++rx_queue->notified_count != write_count);\r\nwmb();\r\nEFX_POPULATE_DWORD_1(reg, ERF_DZ_RX_DESC_WPTR,\r\nwrite_count & rx_queue->ptr_mask);\r\nefx_writed_page(efx, &reg, ER_DZ_RX_DESC_UPD,\r\nefx_rx_queue_index(rx_queue));\r\n}\r\nstatic void efx_ef10_rx_defer_refill(struct efx_rx_queue *rx_queue)\r\n{\r\nstruct efx_channel *channel = efx_rx_queue_channel(rx_queue);\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_DRIVER_EVENT_IN_LEN);\r\nefx_qword_t event;\r\nEFX_POPULATE_QWORD_2(event,\r\nESF_DZ_EV_CODE, EFX_EF10_DRVGEN_EV,\r\nESF_DZ_EV_DATA, EFX_EF10_REFILL);\r\nMCDI_SET_DWORD(inbuf, DRIVER_EVENT_IN_EVQ, channel->channel);\r\nmemcpy(MCDI_PTR(inbuf, DRIVER_EVENT_IN_DATA), &event.u64[0],\r\nsizeof(efx_qword_t));\r\nefx_mcdi_rpc_async(channel->efx, MC_CMD_DRIVER_EVENT,\r\ninbuf, sizeof(inbuf), 0,\r\nefx_ef10_rx_defer_refill_complete, 0);\r\n}\r\nstatic void\r\nefx_ef10_rx_defer_refill_complete(struct efx_nic *efx, unsigned long cookie,\r\nint rc, efx_dword_t *outbuf,\r\nsize_t outlen_actual)\r\n{\r\n}\r\nstatic int efx_ef10_ev_probe(struct efx_channel *channel)\r\n{\r\nreturn efx_nic_alloc_buffer(channel->efx, &channel->eventq.buf,\r\n(channel->eventq_mask + 1) *\r\nsizeof(efx_qword_t),\r\nGFP_KERNEL);\r\n}\r\nstatic int efx_ef10_ev_init(struct efx_channel *channel)\r\n{\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_INIT_EVQ_IN_LEN(EFX_MAX_EVQ_SIZE * 8 /\r\nEFX_BUF_SIZE));\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_INIT_EVQ_OUT_LEN);\r\nsize_t entries = channel->eventq.buf.len / EFX_BUF_SIZE;\r\nstruct efx_nic *efx = channel->efx;\r\nstruct efx_ef10_nic_data *nic_data;\r\nbool supports_rx_merge;\r\nsize_t inlen, outlen;\r\ndma_addr_t dma_addr;\r\nint rc;\r\nint i;\r\nnic_data = efx->nic_data;\r\nsupports_rx_merge =\r\n!!(nic_data->datapath_caps &\r\n1 << MC_CMD_GET_CAPABILITIES_OUT_RX_BATCHING_LBN);\r\nmemset(channel->eventq.buf.addr, 0xff, channel->eventq.buf.len);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_SIZE, channel->eventq_mask + 1);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_INSTANCE, channel->channel);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_IRQ_NUM, channel->channel);\r\nMCDI_POPULATE_DWORD_4(inbuf, INIT_EVQ_IN_FLAGS,\r\nINIT_EVQ_IN_FLAG_INTERRUPTING, 1,\r\nINIT_EVQ_IN_FLAG_RX_MERGE, 1,\r\nINIT_EVQ_IN_FLAG_TX_MERGE, 1,\r\nINIT_EVQ_IN_FLAG_CUT_THRU, !supports_rx_merge);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_TMR_MODE,\r\nMC_CMD_INIT_EVQ_IN_TMR_MODE_DIS);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_TMR_LOAD, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_TMR_RELOAD, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_COUNT_MODE,\r\nMC_CMD_INIT_EVQ_IN_COUNT_MODE_DIS);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_COUNT_THRSHLD, 0);\r\ndma_addr = channel->eventq.buf.dma_addr;\r\nfor (i = 0; i < entries; ++i) {\r\nMCDI_SET_ARRAY_QWORD(inbuf, INIT_EVQ_IN_DMA_ADDR, i, dma_addr);\r\ndma_addr += EFX_BUF_SIZE;\r\n}\r\ninlen = MC_CMD_INIT_EVQ_IN_LEN(entries);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_INIT_EVQ, inbuf, inlen,\r\noutbuf, sizeof(outbuf), &outlen);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_ev_fini(struct efx_channel *channel)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FINI_EVQ_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_FINI_EVQ_OUT_LEN);\r\nstruct efx_nic *efx = channel->efx;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, FINI_EVQ_IN_INSTANCE, channel->channel);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FINI_EVQ, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc && rc != -EALREADY)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nefx_mcdi_display_error(efx, MC_CMD_FINI_EVQ, MC_CMD_FINI_EVQ_IN_LEN,\r\noutbuf, outlen, rc);\r\n}\r\nstatic void efx_ef10_ev_remove(struct efx_channel *channel)\r\n{\r\nefx_nic_free_buffer(channel->efx, &channel->eventq.buf);\r\n}\r\nstatic void efx_ef10_handle_rx_wrong_queue(struct efx_rx_queue *rx_queue,\r\nunsigned int rx_queue_label)\r\n{\r\nstruct efx_nic *efx = rx_queue->efx;\r\nnetif_info(efx, hw, efx->net_dev,\r\n"rx event arrived on queue %d labeled as queue %u\n",\r\nefx_rx_queue_index(rx_queue), rx_queue_label);\r\nefx_schedule_reset(efx, RESET_TYPE_DISABLE);\r\n}\r\nstatic void\r\nefx_ef10_handle_rx_bad_lbits(struct efx_rx_queue *rx_queue,\r\nunsigned int actual, unsigned int expected)\r\n{\r\nunsigned int dropped = (actual - expected) & rx_queue->ptr_mask;\r\nstruct efx_nic *efx = rx_queue->efx;\r\nnetif_info(efx, hw, efx->net_dev,\r\n"dropped %d events (index=%d expected=%d)\n",\r\ndropped, actual, expected);\r\nefx_schedule_reset(efx, RESET_TYPE_DISABLE);\r\n}\r\nstatic void efx_ef10_handle_rx_abort(struct efx_rx_queue *rx_queue)\r\n{\r\nunsigned int rx_desc_ptr;\r\nnetif_dbg(rx_queue->efx, hw, rx_queue->efx->net_dev,\r\n"scattered RX aborted (dropping %u buffers)\n",\r\nrx_queue->scatter_n);\r\nrx_desc_ptr = rx_queue->removed_count & rx_queue->ptr_mask;\r\nefx_rx_packet(rx_queue, rx_desc_ptr, rx_queue->scatter_n,\r\n0, EFX_RX_PKT_DISCARD);\r\nrx_queue->removed_count += rx_queue->scatter_n;\r\nrx_queue->scatter_n = 0;\r\nrx_queue->scatter_len = 0;\r\n++efx_rx_queue_channel(rx_queue)->n_rx_nodesc_trunc;\r\n}\r\nstatic int efx_ef10_handle_rx_event(struct efx_channel *channel,\r\nconst efx_qword_t *event)\r\n{\r\nunsigned int rx_bytes, next_ptr_lbits, rx_queue_label, rx_l4_class;\r\nunsigned int n_descs, n_packets, i;\r\nstruct efx_nic *efx = channel->efx;\r\nstruct efx_rx_queue *rx_queue;\r\nbool rx_cont;\r\nu16 flags = 0;\r\nif (unlikely(ACCESS_ONCE(efx->reset_pending)))\r\nreturn 0;\r\nrx_bytes = EFX_QWORD_FIELD(*event, ESF_DZ_RX_BYTES);\r\nnext_ptr_lbits = EFX_QWORD_FIELD(*event, ESF_DZ_RX_DSC_PTR_LBITS);\r\nrx_queue_label = EFX_QWORD_FIELD(*event, ESF_DZ_RX_QLABEL);\r\nrx_l4_class = EFX_QWORD_FIELD(*event, ESF_DZ_RX_L4_CLASS);\r\nrx_cont = EFX_QWORD_FIELD(*event, ESF_DZ_RX_CONT);\r\nif (EFX_QWORD_FIELD(*event, ESF_DZ_RX_DROP_EVENT))\r\nnetdev_WARN(efx->net_dev, "saw RX_DROP_EVENT: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nrx_queue = efx_channel_get_rx_queue(channel);\r\nif (unlikely(rx_queue_label != efx_rx_queue_index(rx_queue)))\r\nefx_ef10_handle_rx_wrong_queue(rx_queue, rx_queue_label);\r\nn_descs = ((next_ptr_lbits - rx_queue->removed_count) &\r\n((1 << ESF_DZ_RX_DSC_PTR_LBITS_WIDTH) - 1));\r\nif (n_descs != rx_queue->scatter_n + 1) {\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (unlikely(n_descs == rx_queue->scatter_n)) {\r\nif (rx_queue->scatter_n == 0 || rx_bytes != 0)\r\nnetdev_WARN(efx->net_dev,\r\n"invalid RX abort: scatter_n=%u event="\r\nEFX_QWORD_FMT "\n",\r\nrx_queue->scatter_n,\r\nEFX_QWORD_VAL(*event));\r\nefx_ef10_handle_rx_abort(rx_queue);\r\nreturn 0;\r\n}\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_RX_BATCHING_LBN)) ||\r\nrx_queue->scatter_n != 0 || rx_cont) {\r\nefx_ef10_handle_rx_bad_lbits(\r\nrx_queue, next_ptr_lbits,\r\n(rx_queue->removed_count +\r\nrx_queue->scatter_n + 1) &\r\n((1 << ESF_DZ_RX_DSC_PTR_LBITS_WIDTH) - 1));\r\nreturn 0;\r\n}\r\nrx_queue->scatter_n = 1;\r\nrx_queue->scatter_len = 0;\r\nn_packets = n_descs;\r\n++channel->n_rx_merge_events;\r\nchannel->n_rx_merge_packets += n_packets;\r\nflags |= EFX_RX_PKT_PREFIX_LEN;\r\n} else {\r\n++rx_queue->scatter_n;\r\nrx_queue->scatter_len += rx_bytes;\r\nif (rx_cont)\r\nreturn 0;\r\nn_packets = 1;\r\n}\r\nif (unlikely(EFX_QWORD_FIELD(*event, ESF_DZ_RX_ECRC_ERR)))\r\nflags |= EFX_RX_PKT_DISCARD;\r\nif (unlikely(EFX_QWORD_FIELD(*event, ESF_DZ_RX_IPCKSUM_ERR))) {\r\nchannel->n_rx_ip_hdr_chksum_err += n_packets;\r\n} else if (unlikely(EFX_QWORD_FIELD(*event,\r\nESF_DZ_RX_TCPUDP_CKSUM_ERR))) {\r\nchannel->n_rx_tcp_udp_chksum_err += n_packets;\r\n} else if (rx_l4_class == ESE_DZ_L4_CLASS_TCP ||\r\nrx_l4_class == ESE_DZ_L4_CLASS_UDP) {\r\nflags |= EFX_RX_PKT_CSUMMED;\r\n}\r\nif (rx_l4_class == ESE_DZ_L4_CLASS_TCP)\r\nflags |= EFX_RX_PKT_TCP;\r\nchannel->irq_mod_score += 2 * n_packets;\r\nfor (i = 0; i < n_packets; i++) {\r\nefx_rx_packet(rx_queue,\r\nrx_queue->removed_count & rx_queue->ptr_mask,\r\nrx_queue->scatter_n, rx_queue->scatter_len,\r\nflags);\r\nrx_queue->removed_count += rx_queue->scatter_n;\r\n}\r\nrx_queue->scatter_n = 0;\r\nrx_queue->scatter_len = 0;\r\nreturn n_packets;\r\n}\r\nstatic int\r\nefx_ef10_handle_tx_event(struct efx_channel *channel, efx_qword_t *event)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nstruct efx_tx_queue *tx_queue;\r\nunsigned int tx_ev_desc_ptr;\r\nunsigned int tx_ev_q_label;\r\nint tx_descs = 0;\r\nif (unlikely(ACCESS_ONCE(efx->reset_pending)))\r\nreturn 0;\r\nif (unlikely(EFX_QWORD_FIELD(*event, ESF_DZ_TX_DROP_EVENT)))\r\nreturn 0;\r\ntx_ev_desc_ptr = EFX_QWORD_FIELD(*event, ESF_DZ_TX_DESCR_INDX);\r\ntx_ev_q_label = EFX_QWORD_FIELD(*event, ESF_DZ_TX_QLABEL);\r\ntx_queue = efx_channel_get_tx_queue(channel,\r\ntx_ev_q_label % EFX_TXQ_TYPES);\r\ntx_descs = ((tx_ev_desc_ptr + 1 - tx_queue->read_count) &\r\ntx_queue->ptr_mask);\r\nefx_xmit_done(tx_queue, tx_ev_desc_ptr & tx_queue->ptr_mask);\r\nreturn tx_descs;\r\n}\r\nstatic void\r\nefx_ef10_handle_driver_event(struct efx_channel *channel, efx_qword_t *event)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nint subcode;\r\nsubcode = EFX_QWORD_FIELD(*event, ESF_DZ_DRV_SUB_CODE);\r\nswitch (subcode) {\r\ncase ESE_DZ_DRV_TIMER_EV:\r\ncase ESE_DZ_DRV_WAKE_UP_EV:\r\nbreak;\r\ncase ESE_DZ_DRV_START_UP_EV:\r\nbreak;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"channel %d unknown driver event type %d"\r\n" (data " EFX_QWORD_FMT ")\n",\r\nchannel->channel, subcode,\r\nEFX_QWORD_VAL(*event));\r\n}\r\n}\r\nstatic void efx_ef10_handle_driver_generated_event(struct efx_channel *channel,\r\nefx_qword_t *event)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nu32 subcode;\r\nsubcode = EFX_QWORD_FIELD(*event, EFX_DWORD_0);\r\nswitch (subcode) {\r\ncase EFX_EF10_TEST:\r\nchannel->event_test_cpu = raw_smp_processor_id();\r\nbreak;\r\ncase EFX_EF10_REFILL:\r\nefx_fast_push_rx_descriptors(&channel->rx_queue, true);\r\nbreak;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"channel %d unknown driver event type %u"\r\n" (data " EFX_QWORD_FMT ")\n",\r\nchannel->channel, (unsigned) subcode,\r\nEFX_QWORD_VAL(*event));\r\n}\r\n}\r\nstatic int efx_ef10_ev_process(struct efx_channel *channel, int quota)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nefx_qword_t event, *p_event;\r\nunsigned int read_ptr;\r\nint ev_code;\r\nint tx_descs = 0;\r\nint spent = 0;\r\nif (quota <= 0)\r\nreturn spent;\r\nread_ptr = channel->eventq_read_ptr;\r\nfor (;;) {\r\np_event = efx_event(channel, read_ptr);\r\nevent = *p_event;\r\nif (!efx_event_present(&event))\r\nbreak;\r\nEFX_SET_QWORD(*p_event);\r\n++read_ptr;\r\nev_code = EFX_QWORD_FIELD(event, ESF_DZ_EV_CODE);\r\nnetif_vdbg(efx, drv, efx->net_dev,\r\n"processing event on %d " EFX_QWORD_FMT "\n",\r\nchannel->channel, EFX_QWORD_VAL(event));\r\nswitch (ev_code) {\r\ncase ESE_DZ_EV_CODE_MCDI_EV:\r\nefx_mcdi_process_event(channel, &event);\r\nbreak;\r\ncase ESE_DZ_EV_CODE_RX_EV:\r\nspent += efx_ef10_handle_rx_event(channel, &event);\r\nif (spent >= quota) {\r\nspent = quota;\r\ngoto out;\r\n}\r\nbreak;\r\ncase ESE_DZ_EV_CODE_TX_EV:\r\ntx_descs += efx_ef10_handle_tx_event(channel, &event);\r\nif (tx_descs > efx->txq_entries) {\r\nspent = quota;\r\ngoto out;\r\n} else if (++spent == quota) {\r\ngoto out;\r\n}\r\nbreak;\r\ncase ESE_DZ_EV_CODE_DRIVER_EV:\r\nefx_ef10_handle_driver_event(channel, &event);\r\nif (++spent == quota)\r\ngoto out;\r\nbreak;\r\ncase EFX_EF10_DRVGEN_EV:\r\nefx_ef10_handle_driver_generated_event(channel, &event);\r\nbreak;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"channel %d unknown event type %d"\r\n" (data " EFX_QWORD_FMT ")\n",\r\nchannel->channel, ev_code,\r\nEFX_QWORD_VAL(event));\r\n}\r\n}\r\nout:\r\nchannel->eventq_read_ptr = read_ptr;\r\nreturn spent;\r\n}\r\nstatic void efx_ef10_ev_read_ack(struct efx_channel *channel)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nefx_dword_t rptr;\r\nif (EFX_EF10_WORKAROUND_35388(efx)) {\r\nBUILD_BUG_ON(EFX_MIN_EVQ_SIZE <\r\n(1 << ERF_DD_EVQ_IND_RPTR_WIDTH));\r\nBUILD_BUG_ON(EFX_MAX_EVQ_SIZE >\r\n(1 << 2 * ERF_DD_EVQ_IND_RPTR_WIDTH));\r\nEFX_POPULATE_DWORD_2(rptr, ERF_DD_EVQ_IND_RPTR_FLAGS,\r\nEFE_DD_EVQ_IND_RPTR_FLAGS_HIGH,\r\nERF_DD_EVQ_IND_RPTR,\r\n(channel->eventq_read_ptr &\r\nchannel->eventq_mask) >>\r\nERF_DD_EVQ_IND_RPTR_WIDTH);\r\nefx_writed_page(efx, &rptr, ER_DD_EVQ_INDIRECT,\r\nchannel->channel);\r\nEFX_POPULATE_DWORD_2(rptr, ERF_DD_EVQ_IND_RPTR_FLAGS,\r\nEFE_DD_EVQ_IND_RPTR_FLAGS_LOW,\r\nERF_DD_EVQ_IND_RPTR,\r\nchannel->eventq_read_ptr &\r\n((1 << ERF_DD_EVQ_IND_RPTR_WIDTH) - 1));\r\nefx_writed_page(efx, &rptr, ER_DD_EVQ_INDIRECT,\r\nchannel->channel);\r\n} else {\r\nEFX_POPULATE_DWORD_1(rptr, ERF_DZ_EVQ_RPTR,\r\nchannel->eventq_read_ptr &\r\nchannel->eventq_mask);\r\nefx_writed_page(efx, &rptr, ER_DZ_EVQ_RPTR, channel->channel);\r\n}\r\n}\r\nstatic void efx_ef10_ev_test_generate(struct efx_channel *channel)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_DRIVER_EVENT_IN_LEN);\r\nstruct efx_nic *efx = channel->efx;\r\nefx_qword_t event;\r\nint rc;\r\nEFX_POPULATE_QWORD_2(event,\r\nESF_DZ_EV_CODE, EFX_EF10_DRVGEN_EV,\r\nESF_DZ_EV_DATA, EFX_EF10_TEST);\r\nMCDI_SET_DWORD(inbuf, DRIVER_EVENT_IN_EVQ, channel->channel);\r\nmemcpy(MCDI_PTR(inbuf, DRIVER_EVENT_IN_DATA), &event.u64[0],\r\nsizeof(efx_qword_t));\r\nrc = efx_mcdi_rpc(efx, MC_CMD_DRIVER_EVENT, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nif (rc != 0)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nWARN_ON(true);\r\nnetif_err(efx, hw, efx->net_dev, "%s: failed rc=%d\n", __func__, rc);\r\n}\r\nvoid efx_ef10_handle_drain_event(struct efx_nic *efx)\r\n{\r\nif (atomic_dec_and_test(&efx->active_queues))\r\nwake_up(&efx->flush_wq);\r\nWARN_ON(atomic_read(&efx->active_queues) < 0);\r\n}\r\nstatic int efx_ef10_fini_dmaq(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_channel *channel;\r\nstruct efx_tx_queue *tx_queue;\r\nstruct efx_rx_queue *rx_queue;\r\nint pending;\r\nif (nic_data->must_realloc_vis) {\r\natomic_set(&efx->active_queues, 0);\r\nreturn 0;\r\n}\r\nif (efx->state != STATE_RECOVERY) {\r\nefx_for_each_channel(channel, efx) {\r\nefx_for_each_channel_rx_queue(rx_queue, channel)\r\nefx_ef10_rx_fini(rx_queue);\r\nefx_for_each_channel_tx_queue(tx_queue, channel)\r\nefx_ef10_tx_fini(tx_queue);\r\n}\r\nwait_event_timeout(efx->flush_wq,\r\natomic_read(&efx->active_queues) == 0,\r\nmsecs_to_jiffies(EFX_MAX_FLUSH_TIME));\r\npending = atomic_read(&efx->active_queues);\r\nif (pending) {\r\nnetif_err(efx, hw, efx->net_dev, "failed to flush %d queues\n",\r\npending);\r\nreturn -ETIMEDOUT;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_prepare_flr(struct efx_nic *efx)\r\n{\r\natomic_set(&efx->active_queues, 0);\r\n}\r\nstatic bool efx_ef10_filter_equal(const struct efx_filter_spec *left,\r\nconst struct efx_filter_spec *right)\r\n{\r\nif ((left->match_flags ^ right->match_flags) |\r\n((left->flags ^ right->flags) &\r\n(EFX_FILTER_FLAG_RX | EFX_FILTER_FLAG_TX)))\r\nreturn false;\r\nreturn memcmp(&left->outer_vid, &right->outer_vid,\r\nsizeof(struct efx_filter_spec) -\r\noffsetof(struct efx_filter_spec, outer_vid)) == 0;\r\n}\r\nstatic unsigned int efx_ef10_filter_hash(const struct efx_filter_spec *spec)\r\n{\r\nBUILD_BUG_ON(offsetof(struct efx_filter_spec, outer_vid) & 3);\r\nreturn jhash2((const u32 *)&spec->outer_vid,\r\n(sizeof(struct efx_filter_spec) -\r\noffsetof(struct efx_filter_spec, outer_vid)) / 4,\r\n0);\r\n}\r\nstatic bool efx_ef10_filter_is_exclusive(const struct efx_filter_spec *spec)\r\n{\r\nif (spec->match_flags & EFX_FILTER_MATCH_LOC_MAC &&\r\n!is_multicast_ether_addr(spec->loc_mac))\r\nreturn true;\r\nif ((spec->match_flags &\r\n(EFX_FILTER_MATCH_ETHER_TYPE | EFX_FILTER_MATCH_LOC_HOST)) ==\r\n(EFX_FILTER_MATCH_ETHER_TYPE | EFX_FILTER_MATCH_LOC_HOST)) {\r\nif (spec->ether_type == htons(ETH_P_IP) &&\r\n!ipv4_is_multicast(spec->loc_host[0]))\r\nreturn true;\r\nif (spec->ether_type == htons(ETH_P_IPV6) &&\r\n((const u8 *)spec->loc_host)[0] != 0xff)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic struct efx_filter_spec *\r\nefx_ef10_filter_entry_spec(const struct efx_ef10_filter_table *table,\r\nunsigned int filter_idx)\r\n{\r\nreturn (struct efx_filter_spec *)(table->entry[filter_idx].spec &\r\n~EFX_EF10_FILTER_FLAGS);\r\n}\r\nstatic unsigned int\r\nefx_ef10_filter_entry_flags(const struct efx_ef10_filter_table *table,\r\nunsigned int filter_idx)\r\n{\r\nreturn table->entry[filter_idx].spec & EFX_EF10_FILTER_FLAGS;\r\n}\r\nstatic void\r\nefx_ef10_filter_set_entry(struct efx_ef10_filter_table *table,\r\nunsigned int filter_idx,\r\nconst struct efx_filter_spec *spec,\r\nunsigned int flags)\r\n{\r\ntable->entry[filter_idx].spec = (unsigned long)spec | flags;\r\n}\r\nstatic void efx_ef10_filter_push_prep(struct efx_nic *efx,\r\nconst struct efx_filter_spec *spec,\r\nefx_dword_t *inbuf, u64 handle,\r\nbool replacing)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nmemset(inbuf, 0, MC_CMD_FILTER_OP_IN_LEN);\r\nif (replacing) {\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nMC_CMD_FILTER_OP_IN_OP_REPLACE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE, handle);\r\n} else {\r\nu32 match_fields = 0;\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nefx_ef10_filter_is_exclusive(spec) ?\r\nMC_CMD_FILTER_OP_IN_OP_INSERT :\r\nMC_CMD_FILTER_OP_IN_OP_SUBSCRIBE);\r\nif (spec->match_flags & EFX_FILTER_MATCH_LOC_MAC_IG)\r\nmatch_fields |=\r\nis_multicast_ether_addr(spec->loc_mac) ?\r\n1 << MC_CMD_FILTER_OP_IN_MATCH_UNKNOWN_MCAST_DST_LBN :\r\n1 << MC_CMD_FILTER_OP_IN_MATCH_UNKNOWN_UCAST_DST_LBN;\r\n#define COPY_FIELD(gen_flag, gen_field, mcdi_field) \\r\nif (spec->match_flags & EFX_FILTER_MATCH_ ## gen_flag) { \\r\nmatch_fields |= \\r\n1 << MC_CMD_FILTER_OP_IN_MATCH_ ## \\r\nmcdi_field ## _LBN; \\r\nBUILD_BUG_ON( \\r\nMC_CMD_FILTER_OP_IN_ ## mcdi_field ## _LEN < \\r\nsizeof(spec->gen_field)); \\r\nmemcpy(MCDI_PTR(inbuf, FILTER_OP_IN_ ## mcdi_field), \\r\n&spec->gen_field, sizeof(spec->gen_field)); \\r\n}\r\nCOPY_FIELD(REM_HOST, rem_host, SRC_IP);\r\nCOPY_FIELD(LOC_HOST, loc_host, DST_IP);\r\nCOPY_FIELD(REM_MAC, rem_mac, SRC_MAC);\r\nCOPY_FIELD(REM_PORT, rem_port, SRC_PORT);\r\nCOPY_FIELD(LOC_MAC, loc_mac, DST_MAC);\r\nCOPY_FIELD(LOC_PORT, loc_port, DST_PORT);\r\nCOPY_FIELD(ETHER_TYPE, ether_type, ETHER_TYPE);\r\nCOPY_FIELD(INNER_VID, inner_vid, INNER_VLAN);\r\nCOPY_FIELD(OUTER_VID, outer_vid, OUTER_VLAN);\r\nCOPY_FIELD(IP_PROTO, ip_proto, IP_PROTO);\r\n#undef COPY_FIELD\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_MATCH_FIELDS,\r\nmatch_fields);\r\n}\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_PORT_ID, EVB_PORT_ID_ASSIGNED);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_DEST,\r\nspec->dmaq_id == EFX_FILTER_RX_DMAQ_ID_DROP ?\r\nMC_CMD_FILTER_OP_IN_RX_DEST_DROP :\r\nMC_CMD_FILTER_OP_IN_RX_DEST_HOST);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_TX_DEST,\r\nMC_CMD_FILTER_OP_IN_TX_DEST_DEFAULT);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_QUEUE,\r\nspec->dmaq_id == EFX_FILTER_RX_DMAQ_ID_DROP ?\r\n0 : spec->dmaq_id);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_MODE,\r\n(spec->flags & EFX_FILTER_FLAG_RX_RSS) ?\r\nMC_CMD_FILTER_OP_IN_RX_MODE_RSS :\r\nMC_CMD_FILTER_OP_IN_RX_MODE_SIMPLE);\r\nif (spec->flags & EFX_FILTER_FLAG_RX_RSS)\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_CONTEXT,\r\nspec->rss_context !=\r\nEFX_FILTER_RSS_CONTEXT_DEFAULT ?\r\nspec->rss_context : nic_data->rx_rss_context);\r\n}\r\nstatic int efx_ef10_filter_push(struct efx_nic *efx,\r\nconst struct efx_filter_spec *spec,\r\nu64 *handle, bool replacing)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_FILTER_OP_OUT_LEN);\r\nint rc;\r\nefx_ef10_filter_push_prep(efx, spec, inbuf, *handle, replacing);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), NULL);\r\nif (rc == 0)\r\n*handle = MCDI_QWORD(outbuf, FILTER_OP_OUT_HANDLE);\r\nif (rc == -ENOSPC)\r\nrc = -EBUSY;\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_filter_rx_match_pri(struct efx_ef10_filter_table *table,\r\nenum efx_filter_match_flags match_flags)\r\n{\r\nunsigned int match_pri;\r\nfor (match_pri = 0;\r\nmatch_pri < table->rx_match_count;\r\nmatch_pri++)\r\nif (table->rx_match_flags[match_pri] == match_flags)\r\nreturn match_pri;\r\nreturn -EPROTONOSUPPORT;\r\n}\r\nstatic s32 efx_ef10_filter_insert(struct efx_nic *efx,\r\nstruct efx_filter_spec *spec,\r\nbool replace_equal)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nDECLARE_BITMAP(mc_rem_map, EFX_EF10_FILTER_SEARCH_LIMIT);\r\nstruct efx_filter_spec *saved_spec;\r\nunsigned int match_pri, hash;\r\nunsigned int priv_flags;\r\nbool replacing = false;\r\nint ins_index = -1;\r\nDEFINE_WAIT(wait);\r\nbool is_mc_recip;\r\ns32 rc;\r\nif ((spec->flags & (EFX_FILTER_FLAG_RX | EFX_FILTER_FLAG_TX)) !=\r\nEFX_FILTER_FLAG_RX)\r\nreturn -EINVAL;\r\nrc = efx_ef10_filter_rx_match_pri(table, spec->match_flags);\r\nif (rc < 0)\r\nreturn rc;\r\nmatch_pri = rc;\r\nhash = efx_ef10_filter_hash(spec);\r\nis_mc_recip = efx_filter_is_mc_recipient(spec);\r\nif (is_mc_recip)\r\nbitmap_zero(mc_rem_map, EFX_EF10_FILTER_SEARCH_LIMIT);\r\nfor (;;) {\r\nunsigned int depth = 1;\r\nunsigned int i;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (;;) {\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, i);\r\nif (!saved_spec) {\r\nif (ins_index < 0)\r\nins_index = i;\r\n} else if (efx_ef10_filter_equal(spec, saved_spec)) {\r\nif (table->entry[i].spec &\r\nEFX_EF10_FILTER_FLAG_BUSY)\r\nbreak;\r\nif (spec->priority < saved_spec->priority &&\r\nspec->priority != EFX_FILTER_PRI_AUTO) {\r\nrc = -EPERM;\r\ngoto out_unlock;\r\n}\r\nif (!is_mc_recip) {\r\nif (spec->priority ==\r\nsaved_spec->priority &&\r\n!replace_equal) {\r\nrc = -EEXIST;\r\ngoto out_unlock;\r\n}\r\nins_index = i;\r\ngoto found;\r\n} else if (spec->priority >\r\nsaved_spec->priority ||\r\n(spec->priority ==\r\nsaved_spec->priority &&\r\nreplace_equal)) {\r\nif (ins_index < 0)\r\nins_index = i;\r\nelse\r\n__set_bit(depth, mc_rem_map);\r\n}\r\n}\r\nif (depth == EFX_EF10_FILTER_SEARCH_LIMIT) {\r\nif (ins_index < 0) {\r\nrc = -EBUSY;\r\ngoto out_unlock;\r\n}\r\ngoto found;\r\n}\r\n++depth;\r\n}\r\nprepare_to_wait(&table->waitq, &wait, TASK_UNINTERRUPTIBLE);\r\nspin_unlock_bh(&efx->filter_lock);\r\nschedule();\r\n}\r\nfound:\r\nsaved_spec = efx_ef10_filter_entry_spec(table, ins_index);\r\nif (saved_spec) {\r\nif (spec->priority == EFX_FILTER_PRI_AUTO &&\r\nsaved_spec->priority >= EFX_FILTER_PRI_AUTO) {\r\nif (saved_spec->priority > EFX_FILTER_PRI_AUTO)\r\nsaved_spec->flags |= EFX_FILTER_FLAG_RX_OVER_AUTO;\r\ntable->entry[ins_index].spec &=\r\n~EFX_EF10_FILTER_FLAG_AUTO_OLD;\r\nrc = ins_index;\r\ngoto out_unlock;\r\n}\r\nreplacing = true;\r\npriv_flags = efx_ef10_filter_entry_flags(table, ins_index);\r\n} else {\r\nsaved_spec = kmalloc(sizeof(*spec), GFP_ATOMIC);\r\nif (!saved_spec) {\r\nrc = -ENOMEM;\r\ngoto out_unlock;\r\n}\r\n*saved_spec = *spec;\r\npriv_flags = 0;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, saved_spec,\r\npriv_flags | EFX_EF10_FILTER_FLAG_BUSY);\r\nif (is_mc_recip) {\r\nunsigned int depth, i;\r\nfor (depth = 0; depth < EFX_EF10_FILTER_SEARCH_LIMIT; depth++) {\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nif (test_bit(depth, mc_rem_map))\r\ntable->entry[i].spec |=\r\nEFX_EF10_FILTER_FLAG_BUSY;\r\n}\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nrc = efx_ef10_filter_push(efx, spec, &table->entry[ins_index].handle,\r\nreplacing);\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc == 0) {\r\nif (replacing) {\r\nif (saved_spec->priority == EFX_FILTER_PRI_AUTO)\r\nsaved_spec->flags |=\r\nEFX_FILTER_FLAG_RX_OVER_AUTO;\r\nsaved_spec->priority = spec->priority;\r\nsaved_spec->flags &= EFX_FILTER_FLAG_RX_OVER_AUTO;\r\nsaved_spec->flags |= spec->flags;\r\nsaved_spec->rss_context = spec->rss_context;\r\nsaved_spec->dmaq_id = spec->dmaq_id;\r\n}\r\n} else if (!replacing) {\r\nkfree(saved_spec);\r\nsaved_spec = NULL;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, saved_spec, priv_flags);\r\nif (is_mc_recip) {\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_IN_LEN);\r\nunsigned int depth, i;\r\nmemset(inbuf, 0, sizeof(inbuf));\r\nfor (depth = 0; depth < EFX_EF10_FILTER_SEARCH_LIMIT; depth++) {\r\nif (!test_bit(depth, mc_rem_map))\r\ncontinue;\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, i);\r\npriv_flags = efx_ef10_filter_entry_flags(table, i);\r\nif (rc == 0) {\r\nspin_unlock_bh(&efx->filter_lock);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nMC_CMD_FILTER_OP_IN_OP_UNSUBSCRIBE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[i].handle);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FILTER_OP,\r\ninbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nspin_lock_bh(&efx->filter_lock);\r\n}\r\nif (rc == 0) {\r\nkfree(saved_spec);\r\nsaved_spec = NULL;\r\npriv_flags = 0;\r\n} else {\r\npriv_flags &= ~EFX_EF10_FILTER_FLAG_BUSY;\r\n}\r\nefx_ef10_filter_set_entry(table, i, saved_spec,\r\npriv_flags);\r\n}\r\n}\r\nif (rc == 0)\r\nrc = match_pri * HUNT_FILTER_TBL_ROWS + ins_index;\r\nwake_up_all(&table->waitq);\r\nout_unlock:\r\nspin_unlock_bh(&efx->filter_lock);\r\nfinish_wait(&table->waitq, &wait);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_filter_update_rx_scatter(struct efx_nic *efx)\r\n{\r\n}\r\nstatic int efx_ef10_filter_remove_internal(struct efx_nic *efx,\r\nunsigned int priority_mask,\r\nu32 filter_id, bool by_index)\r\n{\r\nunsigned int filter_idx = filter_id % HUNT_FILTER_TBL_ROWS;\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_FILTER_OP_IN_HANDLE_OFST +\r\nMC_CMD_FILTER_OP_IN_HANDLE_LEN);\r\nstruct efx_filter_spec *spec;\r\nDEFINE_WAIT(wait);\r\nint rc;\r\nfor (;;) {\r\nspin_lock_bh(&efx->filter_lock);\r\nif (!(table->entry[filter_idx].spec &\r\nEFX_EF10_FILTER_FLAG_BUSY))\r\nbreak;\r\nprepare_to_wait(&table->waitq, &wait, TASK_UNINTERRUPTIBLE);\r\nspin_unlock_bh(&efx->filter_lock);\r\nschedule();\r\n}\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (!spec ||\r\n(!by_index &&\r\nefx_ef10_filter_rx_match_pri(table, spec->match_flags) !=\r\nfilter_id / HUNT_FILTER_TBL_ROWS)) {\r\nrc = -ENOENT;\r\ngoto out_unlock;\r\n}\r\nif (spec->flags & EFX_FILTER_FLAG_RX_OVER_AUTO &&\r\npriority_mask == (1U << EFX_FILTER_PRI_AUTO)) {\r\nspec->flags &= ~EFX_FILTER_FLAG_RX_OVER_AUTO;\r\ntable->entry[filter_idx].spec &= ~EFX_EF10_FILTER_FLAG_AUTO_OLD;\r\nrc = 0;\r\ngoto out_unlock;\r\n}\r\nif (!(priority_mask & (1U << spec->priority))) {\r\nrc = -ENOENT;\r\ngoto out_unlock;\r\n}\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_BUSY;\r\nspin_unlock_bh(&efx->filter_lock);\r\nif (spec->flags & EFX_FILTER_FLAG_RX_OVER_AUTO) {\r\nstruct efx_filter_spec new_spec = *spec;\r\nnew_spec.priority = EFX_FILTER_PRI_AUTO;\r\nnew_spec.flags = (EFX_FILTER_FLAG_RX |\r\nEFX_FILTER_FLAG_RX_RSS);\r\nnew_spec.dmaq_id = 0;\r\nnew_spec.rss_context = EFX_FILTER_RSS_CONTEXT_DEFAULT;\r\nrc = efx_ef10_filter_push(efx, &new_spec,\r\n&table->entry[filter_idx].handle,\r\ntrue);\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc == 0)\r\n*spec = new_spec;\r\n} else {\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nefx_ef10_filter_is_exclusive(spec) ?\r\nMC_CMD_FILTER_OP_IN_OP_REMOVE :\r\nMC_CMD_FILTER_OP_IN_OP_UNSUBSCRIBE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[filter_idx].handle);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FILTER_OP,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc == 0) {\r\nkfree(spec);\r\nefx_ef10_filter_set_entry(table, filter_idx, NULL, 0);\r\n}\r\n}\r\ntable->entry[filter_idx].spec &= ~EFX_EF10_FILTER_FLAG_BUSY;\r\nwake_up_all(&table->waitq);\r\nout_unlock:\r\nspin_unlock_bh(&efx->filter_lock);\r\nfinish_wait(&table->waitq, &wait);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_filter_remove_safe(struct efx_nic *efx,\r\nenum efx_filter_priority priority,\r\nu32 filter_id)\r\n{\r\nreturn efx_ef10_filter_remove_internal(efx, 1U << priority,\r\nfilter_id, false);\r\n}\r\nstatic int efx_ef10_filter_get_safe(struct efx_nic *efx,\r\nenum efx_filter_priority priority,\r\nu32 filter_id, struct efx_filter_spec *spec)\r\n{\r\nunsigned int filter_idx = filter_id % HUNT_FILTER_TBL_ROWS;\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nconst struct efx_filter_spec *saved_spec;\r\nint rc;\r\nspin_lock_bh(&efx->filter_lock);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (saved_spec && saved_spec->priority == priority &&\r\nefx_ef10_filter_rx_match_pri(table, saved_spec->match_flags) ==\r\nfilter_id / HUNT_FILTER_TBL_ROWS) {\r\n*spec = *saved_spec;\r\nrc = 0;\r\n} else {\r\nrc = -ENOENT;\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_filter_clear_rx(struct efx_nic *efx,\r\nenum efx_filter_priority priority)\r\n{\r\nunsigned int priority_mask;\r\nunsigned int i;\r\nint rc;\r\npriority_mask = (((1U << (priority + 1)) - 1) &\r\n~(1U << EFX_FILTER_PRI_AUTO));\r\nfor (i = 0; i < HUNT_FILTER_TBL_ROWS; i++) {\r\nrc = efx_ef10_filter_remove_internal(efx, priority_mask,\r\ni, true);\r\nif (rc && rc != -ENOENT)\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic u32 efx_ef10_filter_count_rx_used(struct efx_nic *efx,\r\nenum efx_filter_priority priority)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nunsigned int filter_idx;\r\ns32 count = 0;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nif (table->entry[filter_idx].spec &&\r\nefx_ef10_filter_entry_spec(table, filter_idx)->priority ==\r\npriority)\r\n++count;\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn count;\r\n}\r\nstatic u32 efx_ef10_filter_get_rx_id_limit(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nreturn table->rx_match_count * HUNT_FILTER_TBL_ROWS;\r\n}\r\nstatic s32 efx_ef10_filter_get_rx_ids(struct efx_nic *efx,\r\nenum efx_filter_priority priority,\r\nu32 *buf, u32 size)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_filter_spec *spec;\r\nunsigned int filter_idx;\r\ns32 count = 0;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (spec && spec->priority == priority) {\r\nif (count == size) {\r\ncount = -EMSGSIZE;\r\nbreak;\r\n}\r\nbuf[count++] = (efx_ef10_filter_rx_match_pri(\r\ntable, spec->match_flags) *\r\nHUNT_FILTER_TBL_ROWS +\r\nfilter_idx);\r\n}\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn count;\r\n}\r\nstatic s32 efx_ef10_filter_rfs_insert(struct efx_nic *efx,\r\nstruct efx_filter_spec *spec)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_IN_LEN);\r\nstruct efx_filter_spec *saved_spec;\r\nunsigned int hash, i, depth = 1;\r\nbool replacing = false;\r\nint ins_index = -1;\r\nu64 cookie;\r\ns32 rc;\r\nEFX_WARN_ON_PARANOID(spec->flags !=\r\n(EFX_FILTER_FLAG_RX | EFX_FILTER_FLAG_RX_SCATTER));\r\nEFX_WARN_ON_PARANOID(spec->priority != EFX_FILTER_PRI_HINT);\r\nEFX_WARN_ON_PARANOID(efx_filter_is_mc_recipient(spec));\r\nhash = efx_ef10_filter_hash(spec);\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (;;) {\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, i);\r\nif (!saved_spec) {\r\nif (ins_index < 0)\r\nins_index = i;\r\n} else if (efx_ef10_filter_equal(spec, saved_spec)) {\r\nif (table->entry[i].spec & EFX_EF10_FILTER_FLAG_BUSY) {\r\nrc = -EBUSY;\r\ngoto fail_unlock;\r\n}\r\nif (spec->priority < saved_spec->priority) {\r\nrc = -EPERM;\r\ngoto fail_unlock;\r\n}\r\nins_index = i;\r\nbreak;\r\n}\r\nif (depth == EFX_EF10_FILTER_SEARCH_LIMIT) {\r\nif (ins_index < 0) {\r\nrc = -EBUSY;\r\ngoto fail_unlock;\r\n}\r\nbreak;\r\n}\r\n++depth;\r\n}\r\nsaved_spec = efx_ef10_filter_entry_spec(table, ins_index);\r\nif (saved_spec) {\r\nreplacing = true;\r\n} else {\r\nsaved_spec = kmalloc(sizeof(*spec), GFP_ATOMIC);\r\nif (!saved_spec) {\r\nrc = -ENOMEM;\r\ngoto fail_unlock;\r\n}\r\n*saved_spec = *spec;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, saved_spec,\r\nEFX_EF10_FILTER_FLAG_BUSY);\r\nspin_unlock_bh(&efx->filter_lock);\r\ncookie = replacing << 31 | ins_index << 16 | spec->dmaq_id;\r\nefx_ef10_filter_push_prep(efx, spec, inbuf,\r\ntable->entry[ins_index].handle, replacing);\r\nefx_mcdi_rpc_async(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf),\r\nMC_CMD_FILTER_OP_OUT_LEN,\r\nefx_ef10_filter_rfs_insert_complete, cookie);\r\nreturn ins_index;\r\nfail_unlock:\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn rc;\r\n}\r\nstatic void\r\nefx_ef10_filter_rfs_insert_complete(struct efx_nic *efx, unsigned long cookie,\r\nint rc, efx_dword_t *outbuf,\r\nsize_t outlen_actual)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nunsigned int ins_index, dmaq_id;\r\nstruct efx_filter_spec *spec;\r\nbool replacing;\r\nreplacing = cookie >> 31;\r\nins_index = (cookie >> 16) & (HUNT_FILTER_TBL_ROWS - 1);\r\ndmaq_id = cookie & 0xffff;\r\nspin_lock_bh(&efx->filter_lock);\r\nspec = efx_ef10_filter_entry_spec(table, ins_index);\r\nif (rc == 0) {\r\ntable->entry[ins_index].handle =\r\nMCDI_QWORD(outbuf, FILTER_OP_OUT_HANDLE);\r\nif (replacing)\r\nspec->dmaq_id = dmaq_id;\r\n} else if (!replacing) {\r\nkfree(spec);\r\nspec = NULL;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, spec, 0);\r\nspin_unlock_bh(&efx->filter_lock);\r\nwake_up_all(&table->waitq);\r\n}\r\nstatic bool efx_ef10_filter_rfs_expire_one(struct efx_nic *efx, u32 flow_id,\r\nunsigned int filter_idx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_filter_spec *spec =\r\nefx_ef10_filter_entry_spec(table, filter_idx);\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_FILTER_OP_IN_HANDLE_OFST +\r\nMC_CMD_FILTER_OP_IN_HANDLE_LEN);\r\nif (!spec ||\r\n(table->entry[filter_idx].spec & EFX_EF10_FILTER_FLAG_BUSY) ||\r\nspec->priority != EFX_FILTER_PRI_HINT ||\r\n!rps_may_expire_flow(efx->net_dev, spec->dmaq_id,\r\nflow_id, filter_idx))\r\nreturn false;\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nMC_CMD_FILTER_OP_IN_OP_REMOVE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[filter_idx].handle);\r\nif (efx_mcdi_rpc_async(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf), 0,\r\nefx_ef10_filter_rfs_expire_complete, filter_idx))\r\nreturn false;\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_BUSY;\r\nreturn true;\r\n}\r\nstatic void\r\nefx_ef10_filter_rfs_expire_complete(struct efx_nic *efx,\r\nunsigned long filter_idx,\r\nint rc, efx_dword_t *outbuf,\r\nsize_t outlen_actual)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_filter_spec *spec =\r\nefx_ef10_filter_entry_spec(table, filter_idx);\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc == 0) {\r\nkfree(spec);\r\nefx_ef10_filter_set_entry(table, filter_idx, NULL, 0);\r\n}\r\ntable->entry[filter_idx].spec &= ~EFX_EF10_FILTER_FLAG_BUSY;\r\nwake_up_all(&table->waitq);\r\nspin_unlock_bh(&efx->filter_lock);\r\n}\r\nstatic int efx_ef10_filter_match_flags_from_mcdi(u32 mcdi_flags)\r\n{\r\nint match_flags = 0;\r\n#define MAP_FLAG(gen_flag, mcdi_field) { \\r\nu32 old_mcdi_flags = mcdi_flags; \\r\nmcdi_flags &= ~(1 << MC_CMD_FILTER_OP_IN_MATCH_ ## \\r\nmcdi_field ## _LBN); \\r\nif (mcdi_flags != old_mcdi_flags) \\r\nmatch_flags |= EFX_FILTER_MATCH_ ## gen_flag; \\r\n}\r\nMAP_FLAG(LOC_MAC_IG, UNKNOWN_UCAST_DST);\r\nMAP_FLAG(LOC_MAC_IG, UNKNOWN_MCAST_DST);\r\nMAP_FLAG(REM_HOST, SRC_IP);\r\nMAP_FLAG(LOC_HOST, DST_IP);\r\nMAP_FLAG(REM_MAC, SRC_MAC);\r\nMAP_FLAG(REM_PORT, SRC_PORT);\r\nMAP_FLAG(LOC_MAC, DST_MAC);\r\nMAP_FLAG(LOC_PORT, DST_PORT);\r\nMAP_FLAG(ETHER_TYPE, ETHER_TYPE);\r\nMAP_FLAG(INNER_VID, INNER_VLAN);\r\nMAP_FLAG(OUTER_VID, OUTER_VLAN);\r\nMAP_FLAG(IP_PROTO, IP_PROTO);\r\n#undef MAP_FLAG\r\nif (mcdi_flags)\r\nreturn -EINVAL;\r\nreturn match_flags;\r\n}\r\nstatic int efx_ef10_filter_table_probe(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_GET_PARSER_DISP_INFO_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_PARSER_DISP_INFO_OUT_LENMAX);\r\nunsigned int pd_match_pri, pd_match_count;\r\nstruct efx_ef10_filter_table *table;\r\nsize_t outlen;\r\nint rc;\r\ntable = kzalloc(sizeof(*table), GFP_KERNEL);\r\nif (!table)\r\nreturn -ENOMEM;\r\nMCDI_SET_DWORD(inbuf, GET_PARSER_DISP_INFO_IN_OP,\r\nMC_CMD_GET_PARSER_DISP_INFO_IN_OP_GET_SUPPORTED_RX_MATCHES);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_PARSER_DISP_INFO,\r\ninbuf, sizeof(inbuf), outbuf, sizeof(outbuf),\r\n&outlen);\r\nif (rc)\r\ngoto fail;\r\npd_match_count = MCDI_VAR_ARRAY_LEN(\r\noutlen, GET_PARSER_DISP_INFO_OUT_SUPPORTED_MATCHES);\r\ntable->rx_match_count = 0;\r\nfor (pd_match_pri = 0; pd_match_pri < pd_match_count; pd_match_pri++) {\r\nu32 mcdi_flags =\r\nMCDI_ARRAY_DWORD(\r\noutbuf,\r\nGET_PARSER_DISP_INFO_OUT_SUPPORTED_MATCHES,\r\npd_match_pri);\r\nrc = efx_ef10_filter_match_flags_from_mcdi(mcdi_flags);\r\nif (rc < 0) {\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"%s: fw flags %#x pri %u not supported in driver\n",\r\n__func__, mcdi_flags, pd_match_pri);\r\n} else {\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"%s: fw flags %#x pri %u supported as driver flags %#x pri %u\n",\r\n__func__, mcdi_flags, pd_match_pri,\r\nrc, table->rx_match_count);\r\ntable->rx_match_flags[table->rx_match_count++] = rc;\r\n}\r\n}\r\ntable->entry = vzalloc(HUNT_FILTER_TBL_ROWS * sizeof(*table->entry));\r\nif (!table->entry) {\r\nrc = -ENOMEM;\r\ngoto fail;\r\n}\r\nefx->filter_state = table;\r\ninit_waitqueue_head(&table->waitq);\r\nreturn 0;\r\nfail:\r\nkfree(table);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_filter_table_restore(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_filter_spec *spec;\r\nunsigned int filter_idx;\r\nbool failed = false;\r\nint rc;\r\nif (!nic_data->must_restore_filters)\r\nreturn;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (!spec)\r\ncontinue;\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_BUSY;\r\nspin_unlock_bh(&efx->filter_lock);\r\nrc = efx_ef10_filter_push(efx, spec,\r\n&table->entry[filter_idx].handle,\r\nfalse);\r\nif (rc)\r\nfailed = true;\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc) {\r\nkfree(spec);\r\nefx_ef10_filter_set_entry(table, filter_idx, NULL, 0);\r\n} else {\r\ntable->entry[filter_idx].spec &=\r\n~EFX_EF10_FILTER_FLAG_BUSY;\r\n}\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nif (failed)\r\nnetif_err(efx, hw, efx->net_dev,\r\n"unable to restore all filters\n");\r\nelse\r\nnic_data->must_restore_filters = false;\r\n}\r\nstatic void efx_ef10_filter_table_remove(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_IN_LEN);\r\nstruct efx_filter_spec *spec;\r\nunsigned int filter_idx;\r\nint rc;\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (!spec)\r\ncontinue;\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nefx_ef10_filter_is_exclusive(spec) ?\r\nMC_CMD_FILTER_OP_IN_OP_REMOVE :\r\nMC_CMD_FILTER_OP_IN_OP_UNSUBSCRIBE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[filter_idx].handle);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nif (rc)\r\nnetdev_WARN(efx->net_dev,\r\n"filter_idx=%#x handle=%#llx\n",\r\nfilter_idx,\r\ntable->entry[filter_idx].handle);\r\nkfree(spec);\r\n}\r\nvfree(table->entry);\r\nkfree(table);\r\n}\r\nstatic void efx_ef10_filter_sync_rx_mode(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct net_device *net_dev = efx->net_dev;\r\nstruct efx_filter_spec spec;\r\nbool remove_failed = false;\r\nstruct netdev_hw_addr *uc;\r\nstruct netdev_hw_addr *mc;\r\nunsigned int filter_idx;\r\nint i, n, rc;\r\nif (!efx_dev_registered(efx))\r\nreturn;\r\nspin_lock_bh(&efx->filter_lock);\r\nn = table->dev_uc_count < 0 ? 1 : table->dev_uc_count;\r\nfor (i = 0; i < n; i++) {\r\nfilter_idx = table->dev_uc_list[i].id % HUNT_FILTER_TBL_ROWS;\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_AUTO_OLD;\r\n}\r\nn = table->dev_mc_count < 0 ? 1 : table->dev_mc_count;\r\nfor (i = 0; i < n; i++) {\r\nfilter_idx = table->dev_mc_list[i].id % HUNT_FILTER_TBL_ROWS;\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_AUTO_OLD;\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nnetif_addr_lock_bh(net_dev);\r\nif (net_dev->flags & IFF_PROMISC ||\r\nnetdev_uc_count(net_dev) >= EFX_EF10_FILTER_DEV_UC_MAX) {\r\ntable->dev_uc_count = -1;\r\n} else {\r\ntable->dev_uc_count = 1 + netdev_uc_count(net_dev);\r\nether_addr_copy(table->dev_uc_list[0].addr, net_dev->dev_addr);\r\ni = 1;\r\nnetdev_for_each_uc_addr(uc, net_dev) {\r\nether_addr_copy(table->dev_uc_list[i].addr, uc->addr);\r\ni++;\r\n}\r\n}\r\nif (net_dev->flags & (IFF_PROMISC | IFF_ALLMULTI) ||\r\nnetdev_mc_count(net_dev) >= EFX_EF10_FILTER_DEV_MC_MAX) {\r\ntable->dev_mc_count = -1;\r\n} else {\r\ntable->dev_mc_count = 1 + netdev_mc_count(net_dev);\r\neth_broadcast_addr(table->dev_mc_list[0].addr);\r\ni = 1;\r\nnetdev_for_each_mc_addr(mc, net_dev) {\r\nether_addr_copy(table->dev_mc_list[i].addr, mc->addr);\r\ni++;\r\n}\r\n}\r\nnetif_addr_unlock_bh(net_dev);\r\nif (table->dev_uc_count >= 0) {\r\nfor (i = 0; i < table->dev_uc_count; i++) {\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO,\r\nEFX_FILTER_FLAG_RX_RSS,\r\n0);\r\nefx_filter_set_eth_local(&spec, EFX_FILTER_VID_UNSPEC,\r\ntable->dev_uc_list[i].addr);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nwhile (i--)\r\nefx_ef10_filter_remove_safe(\r\nefx, EFX_FILTER_PRI_AUTO,\r\ntable->dev_uc_list[i].id);\r\ntable->dev_uc_count = -1;\r\nbreak;\r\n}\r\ntable->dev_uc_list[i].id = rc;\r\n}\r\n}\r\nif (table->dev_uc_count < 0) {\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO,\r\nEFX_FILTER_FLAG_RX_RSS,\r\n0);\r\nefx_filter_set_uc_def(&spec);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nWARN_ON(1);\r\ntable->dev_uc_count = 0;\r\n} else {\r\ntable->dev_uc_list[0].id = rc;\r\n}\r\n}\r\nif (table->dev_mc_count >= 0) {\r\nfor (i = 0; i < table->dev_mc_count; i++) {\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO,\r\nEFX_FILTER_FLAG_RX_RSS,\r\n0);\r\nefx_filter_set_eth_local(&spec, EFX_FILTER_VID_UNSPEC,\r\ntable->dev_mc_list[i].addr);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nwhile (i--)\r\nefx_ef10_filter_remove_safe(\r\nefx, EFX_FILTER_PRI_AUTO,\r\ntable->dev_mc_list[i].id);\r\ntable->dev_mc_count = -1;\r\nbreak;\r\n}\r\ntable->dev_mc_list[i].id = rc;\r\n}\r\n}\r\nif (table->dev_mc_count < 0) {\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO,\r\nEFX_FILTER_FLAG_RX_RSS,\r\n0);\r\nefx_filter_set_mc_def(&spec);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nWARN_ON(1);\r\ntable->dev_mc_count = 0;\r\n} else {\r\ntable->dev_mc_list[0].id = rc;\r\n}\r\n}\r\nfor (i = 0; i < HUNT_FILTER_TBL_ROWS; i++) {\r\nif (ACCESS_ONCE(table->entry[i].spec) &\r\nEFX_EF10_FILTER_FLAG_AUTO_OLD) {\r\nif (efx_ef10_filter_remove_internal(\r\nefx, 1U << EFX_FILTER_PRI_AUTO,\r\ni, true) < 0)\r\nremove_failed = true;\r\n}\r\n}\r\nWARN_ON(remove_failed);\r\n}\r\nstatic int efx_ef10_mac_reconfigure(struct efx_nic *efx)\r\n{\r\nefx_ef10_filter_sync_rx_mode(efx);\r\nreturn efx_mcdi_set_mac(efx);\r\n}\r\nstatic int efx_ef10_start_bist(struct efx_nic *efx, u32 bist_type)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_START_BIST_IN_LEN);\r\nMCDI_SET_DWORD(inbuf, START_BIST_IN_TYPE, bist_type);\r\nreturn efx_mcdi_rpc(efx, MC_CMD_START_BIST, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\n}\r\nstatic int efx_ef10_poll_bist(struct efx_nic *efx)\r\n{\r\nint rc;\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_POLL_BIST_OUT_LEN);\r\nsize_t outlen;\r\nu32 result;\r\nrc = efx_mcdi_rpc(efx, MC_CMD_POLL_BIST, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (outlen < MC_CMD_POLL_BIST_OUT_LEN)\r\nreturn -EIO;\r\nresult = MCDI_DWORD(outbuf, POLL_BIST_OUT_RESULT);\r\nswitch (result) {\r\ncase MC_CMD_POLL_BIST_PASSED:\r\nnetif_dbg(efx, hw, efx->net_dev, "BIST passed.\n");\r\nreturn 0;\r\ncase MC_CMD_POLL_BIST_TIMEOUT:\r\nnetif_err(efx, hw, efx->net_dev, "BIST timed out\n");\r\nreturn -EIO;\r\ncase MC_CMD_POLL_BIST_FAILED:\r\nnetif_err(efx, hw, efx->net_dev, "BIST failed.\n");\r\nreturn -EIO;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"BIST returned unknown result %u", result);\r\nreturn -EIO;\r\n}\r\n}\r\nstatic int efx_ef10_run_bist(struct efx_nic *efx, u32 bist_type)\r\n{\r\nint rc;\r\nnetif_dbg(efx, drv, efx->net_dev, "starting BIST type %u\n", bist_type);\r\nrc = efx_ef10_start_bist(efx, bist_type);\r\nif (rc != 0)\r\nreturn rc;\r\nreturn efx_ef10_poll_bist(efx);\r\n}\r\nstatic int\r\nefx_ef10_test_chip(struct efx_nic *efx, struct efx_self_tests *tests)\r\n{\r\nint rc, rc2;\r\nefx_reset_down(efx, RESET_TYPE_WORLD);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_ENABLE_OFFLINE_BIST,\r\nNULL, 0, NULL, 0, NULL);\r\nif (rc != 0)\r\ngoto out;\r\ntests->memory = efx_ef10_run_bist(efx, MC_CMD_MC_MEM_BIST) ? -1 : 1;\r\ntests->registers = efx_ef10_run_bist(efx, MC_CMD_REG_BIST) ? -1 : 1;\r\nrc = efx_mcdi_reset(efx, RESET_TYPE_WORLD);\r\nout:\r\nrc2 = efx_reset_up(efx, RESET_TYPE_WORLD, rc == 0);\r\nreturn rc ? rc : rc2;\r\n}\r\nstatic int efx_ef10_mtd_probe_partition(struct efx_nic *efx,\r\nstruct efx_mcdi_mtd_partition *part,\r\nunsigned int type)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_NVRAM_METADATA_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_NVRAM_METADATA_OUT_LENMAX);\r\nconst struct efx_ef10_nvram_type_info *info;\r\nsize_t size, erase_size, outlen;\r\nbool protected;\r\nint rc;\r\nfor (info = efx_ef10_nvram_types; ; info++) {\r\nif (info ==\r\nefx_ef10_nvram_types + ARRAY_SIZE(efx_ef10_nvram_types))\r\nreturn -ENODEV;\r\nif ((type & ~info->type_mask) == info->type)\r\nbreak;\r\n}\r\nif (info->port != efx_port_num(efx))\r\nreturn -ENODEV;\r\nrc = efx_mcdi_nvram_info(efx, type, &size, &erase_size, &protected);\r\nif (rc)\r\nreturn rc;\r\nif (protected)\r\nreturn -ENODEV;\r\npart->nvram_type = type;\r\nMCDI_SET_DWORD(inbuf, NVRAM_METADATA_IN_TYPE, type);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_NVRAM_METADATA, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_NVRAM_METADATA_OUT_LENMIN)\r\nreturn -EIO;\r\nif (MCDI_DWORD(outbuf, NVRAM_METADATA_OUT_FLAGS) &\r\n(1 << MC_CMD_NVRAM_METADATA_OUT_SUBTYPE_VALID_LBN))\r\npart->fw_subtype = MCDI_DWORD(outbuf,\r\nNVRAM_METADATA_OUT_SUBTYPE);\r\npart->common.dev_type_name = "EF10 NVRAM manager";\r\npart->common.type_name = info->name;\r\npart->common.mtd.type = MTD_NORFLASH;\r\npart->common.mtd.flags = MTD_CAP_NORFLASH;\r\npart->common.mtd.size = size;\r\npart->common.mtd.erasesize = erase_size;\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_mtd_probe(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_NVRAM_PARTITIONS_OUT_LENMAX);\r\nstruct efx_mcdi_mtd_partition *parts;\r\nsize_t outlen, n_parts_total, i, n_parts;\r\nunsigned int type;\r\nint rc;\r\nASSERT_RTNL();\r\nBUILD_BUG_ON(MC_CMD_NVRAM_PARTITIONS_IN_LEN != 0);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_NVRAM_PARTITIONS, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_NVRAM_PARTITIONS_OUT_LENMIN)\r\nreturn -EIO;\r\nn_parts_total = MCDI_DWORD(outbuf, NVRAM_PARTITIONS_OUT_NUM_PARTITIONS);\r\nif (n_parts_total >\r\nMCDI_VAR_ARRAY_LEN(outlen, NVRAM_PARTITIONS_OUT_TYPE_ID))\r\nreturn -EIO;\r\nparts = kcalloc(n_parts_total, sizeof(*parts), GFP_KERNEL);\r\nif (!parts)\r\nreturn -ENOMEM;\r\nn_parts = 0;\r\nfor (i = 0; i < n_parts_total; i++) {\r\ntype = MCDI_ARRAY_DWORD(outbuf, NVRAM_PARTITIONS_OUT_TYPE_ID,\r\ni);\r\nrc = efx_ef10_mtd_probe_partition(efx, &parts[n_parts], type);\r\nif (rc == 0)\r\nn_parts++;\r\nelse if (rc != -ENODEV)\r\ngoto fail;\r\n}\r\nrc = efx_mtd_add(efx, &parts[0].common, n_parts, sizeof(*parts));\r\nfail:\r\nif (rc)\r\nkfree(parts);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_ptp_write_host_time(struct efx_nic *efx, u32 host_time)\r\n{\r\n_efx_writed(efx, cpu_to_le32(host_time), ER_DZ_MC_DB_LWRD);\r\n}\r\nstatic int efx_ef10_rx_enable_timestamping(struct efx_channel *channel,\r\nbool temp)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_PTP_IN_TIME_EVENT_SUBSCRIBE_LEN);\r\nint rc;\r\nif (channel->sync_events_state == SYNC_EVENTS_REQUESTED ||\r\nchannel->sync_events_state == SYNC_EVENTS_VALID ||\r\n(temp && channel->sync_events_state == SYNC_EVENTS_DISABLED))\r\nreturn 0;\r\nchannel->sync_events_state = SYNC_EVENTS_REQUESTED;\r\nMCDI_SET_DWORD(inbuf, PTP_IN_OP, MC_CMD_PTP_OP_TIME_EVENT_SUBSCRIBE);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_PERIPH_ID, 0);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_TIME_EVENT_SUBSCRIBE_QUEUE,\r\nchannel->channel);\r\nrc = efx_mcdi_rpc(channel->efx, MC_CMD_PTP,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\nif (rc != 0)\r\nchannel->sync_events_state = temp ? SYNC_EVENTS_QUIESCENT :\r\nSYNC_EVENTS_DISABLED;\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_rx_disable_timestamping(struct efx_channel *channel,\r\nbool temp)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_PTP_IN_TIME_EVENT_UNSUBSCRIBE_LEN);\r\nint rc;\r\nif (channel->sync_events_state == SYNC_EVENTS_DISABLED ||\r\n(temp && channel->sync_events_state == SYNC_EVENTS_QUIESCENT))\r\nreturn 0;\r\nif (channel->sync_events_state == SYNC_EVENTS_QUIESCENT) {\r\nchannel->sync_events_state = SYNC_EVENTS_DISABLED;\r\nreturn 0;\r\n}\r\nchannel->sync_events_state = temp ? SYNC_EVENTS_QUIESCENT :\r\nSYNC_EVENTS_DISABLED;\r\nMCDI_SET_DWORD(inbuf, PTP_IN_OP, MC_CMD_PTP_OP_TIME_EVENT_UNSUBSCRIBE);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_PERIPH_ID, 0);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_TIME_EVENT_UNSUBSCRIBE_CONTROL,\r\nMC_CMD_PTP_IN_TIME_EVENT_UNSUBSCRIBE_SINGLE);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_TIME_EVENT_UNSUBSCRIBE_QUEUE,\r\nchannel->channel);\r\nrc = efx_mcdi_rpc(channel->efx, MC_CMD_PTP,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_ptp_set_ts_sync_events(struct efx_nic *efx, bool en,\r\nbool temp)\r\n{\r\nint (*set)(struct efx_channel *channel, bool temp);\r\nstruct efx_channel *channel;\r\nset = en ?\r\nefx_ef10_rx_enable_timestamping :\r\nefx_ef10_rx_disable_timestamping;\r\nefx_for_each_channel(channel, efx) {\r\nint rc = set(channel, temp);\r\nif (en && rc != 0) {\r\nefx_ef10_ptp_set_ts_sync_events(efx, false, temp);\r\nreturn rc;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_ptp_set_ts_config(struct efx_nic *efx,\r\nstruct hwtstamp_config *init)\r\n{\r\nint rc;\r\nswitch (init->rx_filter) {\r\ncase HWTSTAMP_FILTER_NONE:\r\nefx_ef10_ptp_set_ts_sync_events(efx, false, false);\r\nreturn efx_ptp_change_mode(efx,\r\ninit->tx_type != HWTSTAMP_TX_OFF, 0);\r\ncase HWTSTAMP_FILTER_ALL:\r\ncase HWTSTAMP_FILTER_PTP_V1_L4_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V1_L4_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:\r\ncase HWTSTAMP_FILTER_PTP_V2_L4_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V2_L4_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:\r\ncase HWTSTAMP_FILTER_PTP_V2_L2_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V2_L2_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:\r\ncase HWTSTAMP_FILTER_PTP_V2_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V2_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:\r\ninit->rx_filter = HWTSTAMP_FILTER_ALL;\r\nrc = efx_ptp_change_mode(efx, true, 0);\r\nif (!rc)\r\nrc = efx_ef10_ptp_set_ts_sync_events(efx, true, false);\r\nif (rc)\r\nefx_ptp_change_mode(efx, false, 0);\r\nreturn rc;\r\ndefault:\r\nreturn -ERANGE;\r\n}\r\n}
