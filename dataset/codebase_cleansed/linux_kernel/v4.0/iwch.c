static int disable_qp_db(int id, void *p, void *data)\r\n{\r\nstruct iwch_qp *qhp = p;\r\ncxio_disable_wq_db(&qhp->wq);\r\nreturn 0;\r\n}\r\nstatic int enable_qp_db(int id, void *p, void *data)\r\n{\r\nstruct iwch_qp *qhp = p;\r\nif (data)\r\nring_doorbell(qhp->rhp->rdev.ctrl_qp.doorbell, qhp->wq.qpid);\r\ncxio_enable_wq_db(&qhp->wq);\r\nreturn 0;\r\n}\r\nstatic void disable_dbs(struct iwch_dev *rnicp)\r\n{\r\nspin_lock_irq(&rnicp->lock);\r\nidr_for_each(&rnicp->qpidr, disable_qp_db, NULL);\r\nspin_unlock_irq(&rnicp->lock);\r\n}\r\nstatic void enable_dbs(struct iwch_dev *rnicp, int ring_db)\r\n{\r\nspin_lock_irq(&rnicp->lock);\r\nidr_for_each(&rnicp->qpidr, enable_qp_db,\r\n(void *)(unsigned long)ring_db);\r\nspin_unlock_irq(&rnicp->lock);\r\n}\r\nstatic void iwch_db_drop_task(struct work_struct *work)\r\n{\r\nstruct iwch_dev *rnicp = container_of(work, struct iwch_dev,\r\ndb_drop_task.work);\r\nenable_dbs(rnicp, 1);\r\n}\r\nstatic void rnic_init(struct iwch_dev *rnicp)\r\n{\r\nPDBG("%s iwch_dev %p\n", __func__, rnicp);\r\nidr_init(&rnicp->cqidr);\r\nidr_init(&rnicp->qpidr);\r\nidr_init(&rnicp->mmidr);\r\nspin_lock_init(&rnicp->lock);\r\nINIT_DELAYED_WORK(&rnicp->db_drop_task, iwch_db_drop_task);\r\nrnicp->attr.max_qps = T3_MAX_NUM_QP - 32;\r\nrnicp->attr.max_wrs = T3_MAX_QP_DEPTH;\r\nrnicp->attr.max_sge_per_wr = T3_MAX_SGE;\r\nrnicp->attr.max_sge_per_rdma_write_wr = T3_MAX_SGE;\r\nrnicp->attr.max_cqs = T3_MAX_NUM_CQ - 1;\r\nrnicp->attr.max_cqes_per_cq = T3_MAX_CQ_DEPTH;\r\nrnicp->attr.max_mem_regs = cxio_num_stags(&rnicp->rdev);\r\nrnicp->attr.max_phys_buf_entries = T3_MAX_PBL_SIZE;\r\nrnicp->attr.max_pds = T3_MAX_NUM_PD - 1;\r\nrnicp->attr.mem_pgsizes_bitmask = T3_PAGESIZE_MASK;\r\nrnicp->attr.max_mr_size = T3_MAX_MR_SIZE;\r\nrnicp->attr.can_resize_wq = 0;\r\nrnicp->attr.max_rdma_reads_per_qp = 8;\r\nrnicp->attr.max_rdma_read_resources =\r\nrnicp->attr.max_rdma_reads_per_qp * rnicp->attr.max_qps;\r\nrnicp->attr.max_rdma_read_qp_depth = 8;\r\nrnicp->attr.max_rdma_read_depth =\r\nrnicp->attr.max_rdma_read_qp_depth * rnicp->attr.max_qps;\r\nrnicp->attr.rq_overflow_handled = 0;\r\nrnicp->attr.can_modify_ird = 0;\r\nrnicp->attr.can_modify_ord = 0;\r\nrnicp->attr.max_mem_windows = rnicp->attr.max_mem_regs - 1;\r\nrnicp->attr.stag0_value = 1;\r\nrnicp->attr.zbva_support = 1;\r\nrnicp->attr.local_invalidate_fence = 1;\r\nrnicp->attr.cq_overflow_detection = 1;\r\nreturn;\r\n}\r\nstatic void open_rnic_dev(struct t3cdev *tdev)\r\n{\r\nstruct iwch_dev *rnicp;\r\nPDBG("%s t3cdev %p\n", __func__, tdev);\r\nprintk_once(KERN_INFO MOD "Chelsio T3 RDMA Driver - version %s\n",\r\nDRV_VERSION);\r\nrnicp = (struct iwch_dev *)ib_alloc_device(sizeof(*rnicp));\r\nif (!rnicp) {\r\nprintk(KERN_ERR MOD "Cannot allocate ib device\n");\r\nreturn;\r\n}\r\nrnicp->rdev.ulp = rnicp;\r\nrnicp->rdev.t3cdev_p = tdev;\r\nmutex_lock(&dev_mutex);\r\nif (cxio_rdev_open(&rnicp->rdev)) {\r\nmutex_unlock(&dev_mutex);\r\nprintk(KERN_ERR MOD "Unable to open CXIO rdev\n");\r\nib_dealloc_device(&rnicp->ibdev);\r\nreturn;\r\n}\r\nrnic_init(rnicp);\r\nlist_add_tail(&rnicp->entry, &dev_list);\r\nmutex_unlock(&dev_mutex);\r\nif (iwch_register_device(rnicp)) {\r\nprintk(KERN_ERR MOD "Unable to register device\n");\r\nclose_rnic_dev(tdev);\r\n}\r\nprintk(KERN_INFO MOD "Initialized device %s\n",\r\npci_name(rnicp->rdev.rnic_info.pdev));\r\nreturn;\r\n}\r\nstatic void close_rnic_dev(struct t3cdev *tdev)\r\n{\r\nstruct iwch_dev *dev, *tmp;\r\nPDBG("%s t3cdev %p\n", __func__, tdev);\r\nmutex_lock(&dev_mutex);\r\nlist_for_each_entry_safe(dev, tmp, &dev_list, entry) {\r\nif (dev->rdev.t3cdev_p == tdev) {\r\ndev->rdev.flags = CXIO_ERROR_FATAL;\r\nsynchronize_net();\r\ncancel_delayed_work_sync(&dev->db_drop_task);\r\nlist_del(&dev->entry);\r\niwch_unregister_device(dev);\r\ncxio_rdev_close(&dev->rdev);\r\nidr_destroy(&dev->cqidr);\r\nidr_destroy(&dev->qpidr);\r\nidr_destroy(&dev->mmidr);\r\nib_dealloc_device(&dev->ibdev);\r\nbreak;\r\n}\r\n}\r\nmutex_unlock(&dev_mutex);\r\n}\r\nstatic void iwch_event_handler(struct t3cdev *tdev, u32 evt, u32 port_id)\r\n{\r\nstruct cxio_rdev *rdev = tdev->ulp;\r\nstruct iwch_dev *rnicp;\r\nstruct ib_event event;\r\nu32 portnum = port_id + 1;\r\nint dispatch = 0;\r\nif (!rdev)\r\nreturn;\r\nrnicp = rdev_to_iwch_dev(rdev);\r\nswitch (evt) {\r\ncase OFFLOAD_STATUS_DOWN: {\r\nrdev->flags = CXIO_ERROR_FATAL;\r\nsynchronize_net();\r\nevent.event = IB_EVENT_DEVICE_FATAL;\r\ndispatch = 1;\r\nbreak;\r\n}\r\ncase OFFLOAD_PORT_DOWN: {\r\nevent.event = IB_EVENT_PORT_ERR;\r\ndispatch = 1;\r\nbreak;\r\n}\r\ncase OFFLOAD_PORT_UP: {\r\nevent.event = IB_EVENT_PORT_ACTIVE;\r\ndispatch = 1;\r\nbreak;\r\n}\r\ncase OFFLOAD_DB_FULL: {\r\ndisable_dbs(rnicp);\r\nbreak;\r\n}\r\ncase OFFLOAD_DB_EMPTY: {\r\nenable_dbs(rnicp, 1);\r\nbreak;\r\n}\r\ncase OFFLOAD_DB_DROP: {\r\nunsigned long delay = 1000;\r\nunsigned short r;\r\ndisable_dbs(rnicp);\r\nget_random_bytes(&r, 2);\r\ndelay += r & 1023;\r\nschedule_delayed_work(&rnicp->db_drop_task,\r\nusecs_to_jiffies(delay));\r\nbreak;\r\n}\r\n}\r\nif (dispatch) {\r\nevent.device = &rnicp->ibdev;\r\nevent.element.port_num = portnum;\r\nib_dispatch_event(&event);\r\n}\r\nreturn;\r\n}\r\nstatic int __init iwch_init_module(void)\r\n{\r\nint err;\r\nerr = cxio_hal_init();\r\nif (err)\r\nreturn err;\r\nerr = iwch_cm_init();\r\nif (err)\r\nreturn err;\r\ncxio_register_ev_cb(iwch_ev_dispatch);\r\ncxgb3_register_client(&t3c_client);\r\nreturn 0;\r\n}\r\nstatic void __exit iwch_exit_module(void)\r\n{\r\ncxgb3_unregister_client(&t3c_client);\r\ncxio_unregister_ev_cb(iwch_ev_dispatch);\r\niwch_cm_term();\r\ncxio_hal_exit();\r\n}
