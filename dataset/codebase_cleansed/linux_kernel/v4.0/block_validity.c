int __init ext4_init_system_zone(void)\r\n{\r\next4_system_zone_cachep = KMEM_CACHE(ext4_system_zone, 0);\r\nif (ext4_system_zone_cachep == NULL)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid ext4_exit_system_zone(void)\r\n{\r\nkmem_cache_destroy(ext4_system_zone_cachep);\r\n}\r\nstatic inline int can_merge(struct ext4_system_zone *entry1,\r\nstruct ext4_system_zone *entry2)\r\n{\r\nif ((entry1->start_blk + entry1->count) == entry2->start_blk)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int add_system_zone(struct ext4_sb_info *sbi,\r\next4_fsblk_t start_blk,\r\nunsigned int count)\r\n{\r\nstruct ext4_system_zone *new_entry = NULL, *entry;\r\nstruct rb_node **n = &sbi->system_blks.rb_node, *node;\r\nstruct rb_node *parent = NULL, *new_node = NULL;\r\nwhile (*n) {\r\nparent = *n;\r\nentry = rb_entry(parent, struct ext4_system_zone, node);\r\nif (start_blk < entry->start_blk)\r\nn = &(*n)->rb_left;\r\nelse if (start_blk >= (entry->start_blk + entry->count))\r\nn = &(*n)->rb_right;\r\nelse {\r\nif (start_blk + count > (entry->start_blk +\r\nentry->count))\r\nentry->count = (start_blk + count -\r\nentry->start_blk);\r\nnew_node = *n;\r\nnew_entry = rb_entry(new_node, struct ext4_system_zone,\r\nnode);\r\nbreak;\r\n}\r\n}\r\nif (!new_entry) {\r\nnew_entry = kmem_cache_alloc(ext4_system_zone_cachep,\r\nGFP_KERNEL);\r\nif (!new_entry)\r\nreturn -ENOMEM;\r\nnew_entry->start_blk = start_blk;\r\nnew_entry->count = count;\r\nnew_node = &new_entry->node;\r\nrb_link_node(new_node, parent, n);\r\nrb_insert_color(new_node, &sbi->system_blks);\r\n}\r\nnode = rb_prev(new_node);\r\nif (node) {\r\nentry = rb_entry(node, struct ext4_system_zone, node);\r\nif (can_merge(entry, new_entry)) {\r\nnew_entry->start_blk = entry->start_blk;\r\nnew_entry->count += entry->count;\r\nrb_erase(node, &sbi->system_blks);\r\nkmem_cache_free(ext4_system_zone_cachep, entry);\r\n}\r\n}\r\nnode = rb_next(new_node);\r\nif (node) {\r\nentry = rb_entry(node, struct ext4_system_zone, node);\r\nif (can_merge(new_entry, entry)) {\r\nnew_entry->count += entry->count;\r\nrb_erase(node, &sbi->system_blks);\r\nkmem_cache_free(ext4_system_zone_cachep, entry);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void debug_print_tree(struct ext4_sb_info *sbi)\r\n{\r\nstruct rb_node *node;\r\nstruct ext4_system_zone *entry;\r\nint first = 1;\r\nprintk(KERN_INFO "System zones: ");\r\nnode = rb_first(&sbi->system_blks);\r\nwhile (node) {\r\nentry = rb_entry(node, struct ext4_system_zone, node);\r\nprintk("%s%llu-%llu", first ? "" : ", ",\r\nentry->start_blk, entry->start_blk + entry->count - 1);\r\nfirst = 0;\r\nnode = rb_next(node);\r\n}\r\nprintk("\n");\r\n}\r\nint ext4_setup_system_zone(struct super_block *sb)\r\n{\r\next4_group_t ngroups = ext4_get_groups_count(sb);\r\nstruct ext4_sb_info *sbi = EXT4_SB(sb);\r\nstruct ext4_group_desc *gdp;\r\next4_group_t i;\r\nint flex_size = ext4_flex_bg_size(sbi);\r\nint ret;\r\nif (!test_opt(sb, BLOCK_VALIDITY)) {\r\nif (EXT4_SB(sb)->system_blks.rb_node)\r\next4_release_system_zone(sb);\r\nreturn 0;\r\n}\r\nif (EXT4_SB(sb)->system_blks.rb_node)\r\nreturn 0;\r\nfor (i=0; i < ngroups; i++) {\r\nif (ext4_bg_has_super(sb, i) &&\r\n((i < 5) || ((i % flex_size) == 0)))\r\nadd_system_zone(sbi, ext4_group_first_block_no(sb, i),\r\next4_bg_num_gdb(sb, i) + 1);\r\ngdp = ext4_get_group_desc(sb, i, NULL);\r\nret = add_system_zone(sbi, ext4_block_bitmap(sb, gdp), 1);\r\nif (ret)\r\nreturn ret;\r\nret = add_system_zone(sbi, ext4_inode_bitmap(sb, gdp), 1);\r\nif (ret)\r\nreturn ret;\r\nret = add_system_zone(sbi, ext4_inode_table(sb, gdp),\r\nsbi->s_itb_per_group);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (test_opt(sb, DEBUG))\r\ndebug_print_tree(EXT4_SB(sb));\r\nreturn 0;\r\n}\r\nvoid ext4_release_system_zone(struct super_block *sb)\r\n{\r\nstruct ext4_system_zone *entry, *n;\r\nrbtree_postorder_for_each_entry_safe(entry, n,\r\n&EXT4_SB(sb)->system_blks, node)\r\nkmem_cache_free(ext4_system_zone_cachep, entry);\r\nEXT4_SB(sb)->system_blks = RB_ROOT;\r\n}\r\nint ext4_data_block_valid(struct ext4_sb_info *sbi, ext4_fsblk_t start_blk,\r\nunsigned int count)\r\n{\r\nstruct ext4_system_zone *entry;\r\nstruct rb_node *n = sbi->system_blks.rb_node;\r\nif ((start_blk <= le32_to_cpu(sbi->s_es->s_first_data_block)) ||\r\n(start_blk + count < start_blk) ||\r\n(start_blk + count > ext4_blocks_count(sbi->s_es))) {\r\nsbi->s_es->s_last_error_block = cpu_to_le64(start_blk);\r\nreturn 0;\r\n}\r\nwhile (n) {\r\nentry = rb_entry(n, struct ext4_system_zone, node);\r\nif (start_blk + count - 1 < entry->start_blk)\r\nn = n->rb_left;\r\nelse if (start_blk >= (entry->start_blk + entry->count))\r\nn = n->rb_right;\r\nelse {\r\nsbi->s_es->s_last_error_block = cpu_to_le64(start_blk);\r\nreturn 0;\r\n}\r\n}\r\nreturn 1;\r\n}\r\nint ext4_check_blockref(const char *function, unsigned int line,\r\nstruct inode *inode, __le32 *p, unsigned int max)\r\n{\r\nstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\r\n__le32 *bref = p;\r\nunsigned int blk;\r\nwhile (bref < p+max) {\r\nblk = le32_to_cpu(*bref++);\r\nif (blk &&\r\nunlikely(!ext4_data_block_valid(EXT4_SB(inode->i_sb),\r\nblk, 1))) {\r\nes->s_last_error_block = cpu_to_le64(blk);\r\next4_error_inode(inode, function, line, blk,\r\n"invalid block");\r\nreturn -EIO;\r\n}\r\n}\r\nreturn 0;\r\n}
