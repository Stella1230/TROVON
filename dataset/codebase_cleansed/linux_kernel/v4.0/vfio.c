static struct vfio_group *kvm_vfio_group_get_external_user(struct file *filep)\r\n{\r\nstruct vfio_group *vfio_group;\r\nstruct vfio_group *(*fn)(struct file *);\r\nfn = symbol_get(vfio_group_get_external_user);\r\nif (!fn)\r\nreturn ERR_PTR(-EINVAL);\r\nvfio_group = fn(filep);\r\nsymbol_put(vfio_group_get_external_user);\r\nreturn vfio_group;\r\n}\r\nstatic void kvm_vfio_group_put_external_user(struct vfio_group *vfio_group)\r\n{\r\nvoid (*fn)(struct vfio_group *);\r\nfn = symbol_get(vfio_group_put_external_user);\r\nif (!fn)\r\nreturn;\r\nfn(vfio_group);\r\nsymbol_put(vfio_group_put_external_user);\r\n}\r\nstatic bool kvm_vfio_group_is_coherent(struct vfio_group *vfio_group)\r\n{\r\nlong (*fn)(struct vfio_group *, unsigned long);\r\nlong ret;\r\nfn = symbol_get(vfio_external_check_extension);\r\nif (!fn)\r\nreturn false;\r\nret = fn(vfio_group, VFIO_DMA_CC_IOMMU);\r\nsymbol_put(vfio_external_check_extension);\r\nreturn ret > 0;\r\n}\r\nstatic void kvm_vfio_update_coherency(struct kvm_device *dev)\r\n{\r\nstruct kvm_vfio *kv = dev->private;\r\nbool noncoherent = false;\r\nstruct kvm_vfio_group *kvg;\r\nmutex_lock(&kv->lock);\r\nlist_for_each_entry(kvg, &kv->group_list, node) {\r\nif (!kvm_vfio_group_is_coherent(kvg->vfio_group)) {\r\nnoncoherent = true;\r\nbreak;\r\n}\r\n}\r\nif (noncoherent != kv->noncoherent) {\r\nkv->noncoherent = noncoherent;\r\nif (kv->noncoherent)\r\nkvm_arch_register_noncoherent_dma(dev->kvm);\r\nelse\r\nkvm_arch_unregister_noncoherent_dma(dev->kvm);\r\n}\r\nmutex_unlock(&kv->lock);\r\n}\r\nstatic int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)\r\n{\r\nstruct kvm_vfio *kv = dev->private;\r\nstruct vfio_group *vfio_group;\r\nstruct kvm_vfio_group *kvg;\r\nint32_t __user *argp = (int32_t __user *)(unsigned long)arg;\r\nstruct fd f;\r\nint32_t fd;\r\nint ret;\r\nswitch (attr) {\r\ncase KVM_DEV_VFIO_GROUP_ADD:\r\nif (get_user(fd, argp))\r\nreturn -EFAULT;\r\nf = fdget(fd);\r\nif (!f.file)\r\nreturn -EBADF;\r\nvfio_group = kvm_vfio_group_get_external_user(f.file);\r\nfdput(f);\r\nif (IS_ERR(vfio_group))\r\nreturn PTR_ERR(vfio_group);\r\nmutex_lock(&kv->lock);\r\nlist_for_each_entry(kvg, &kv->group_list, node) {\r\nif (kvg->vfio_group == vfio_group) {\r\nmutex_unlock(&kv->lock);\r\nkvm_vfio_group_put_external_user(vfio_group);\r\nreturn -EEXIST;\r\n}\r\n}\r\nkvg = kzalloc(sizeof(*kvg), GFP_KERNEL);\r\nif (!kvg) {\r\nmutex_unlock(&kv->lock);\r\nkvm_vfio_group_put_external_user(vfio_group);\r\nreturn -ENOMEM;\r\n}\r\nlist_add_tail(&kvg->node, &kv->group_list);\r\nkvg->vfio_group = vfio_group;\r\nmutex_unlock(&kv->lock);\r\nkvm_vfio_update_coherency(dev);\r\nreturn 0;\r\ncase KVM_DEV_VFIO_GROUP_DEL:\r\nif (get_user(fd, argp))\r\nreturn -EFAULT;\r\nf = fdget(fd);\r\nif (!f.file)\r\nreturn -EBADF;\r\nvfio_group = kvm_vfio_group_get_external_user(f.file);\r\nfdput(f);\r\nif (IS_ERR(vfio_group))\r\nreturn PTR_ERR(vfio_group);\r\nret = -ENOENT;\r\nmutex_lock(&kv->lock);\r\nlist_for_each_entry(kvg, &kv->group_list, node) {\r\nif (kvg->vfio_group != vfio_group)\r\ncontinue;\r\nlist_del(&kvg->node);\r\nkvm_vfio_group_put_external_user(kvg->vfio_group);\r\nkfree(kvg);\r\nret = 0;\r\nbreak;\r\n}\r\nmutex_unlock(&kv->lock);\r\nkvm_vfio_group_put_external_user(vfio_group);\r\nkvm_vfio_update_coherency(dev);\r\nreturn ret;\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int kvm_vfio_set_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nswitch (attr->group) {\r\ncase KVM_DEV_VFIO_GROUP:\r\nreturn kvm_vfio_set_group(dev, attr->attr, attr->addr);\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int kvm_vfio_has_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nswitch (attr->group) {\r\ncase KVM_DEV_VFIO_GROUP:\r\nswitch (attr->attr) {\r\ncase KVM_DEV_VFIO_GROUP_ADD:\r\ncase KVM_DEV_VFIO_GROUP_DEL:\r\nreturn 0;\r\n}\r\nbreak;\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic void kvm_vfio_destroy(struct kvm_device *dev)\r\n{\r\nstruct kvm_vfio *kv = dev->private;\r\nstruct kvm_vfio_group *kvg, *tmp;\r\nlist_for_each_entry_safe(kvg, tmp, &kv->group_list, node) {\r\nkvm_vfio_group_put_external_user(kvg->vfio_group);\r\nlist_del(&kvg->node);\r\nkfree(kvg);\r\n}\r\nkvm_vfio_update_coherency(dev);\r\nkfree(kv);\r\nkfree(dev);\r\n}\r\nstatic int kvm_vfio_create(struct kvm_device *dev, u32 type)\r\n{\r\nstruct kvm_device *tmp;\r\nstruct kvm_vfio *kv;\r\nlist_for_each_entry(tmp, &dev->kvm->devices, vm_node)\r\nif (tmp->ops == &kvm_vfio_ops)\r\nreturn -EBUSY;\r\nkv = kzalloc(sizeof(*kv), GFP_KERNEL);\r\nif (!kv)\r\nreturn -ENOMEM;\r\nINIT_LIST_HEAD(&kv->group_list);\r\nmutex_init(&kv->lock);\r\ndev->private = kv;\r\nreturn 0;\r\n}\r\nint kvm_vfio_ops_init(void)\r\n{\r\nreturn kvm_register_device_ops(&kvm_vfio_ops, KVM_DEV_TYPE_VFIO);\r\n}\r\nvoid kvm_vfio_ops_exit(void)\r\n{\r\nkvm_unregister_device_ops(KVM_DEV_TYPE_VFIO);\r\n}
