int nf_register_queue_handler(u_int8_t pf, const struct nf_queue_handler *qh)\r\n{\r\nint ret;\r\nconst struct nf_queue_handler *old;\r\nif (pf >= ARRAY_SIZE(queue_handler))\r\nreturn -EINVAL;\r\nmutex_lock(&queue_handler_mutex);\r\nold = rcu_dereference_protected(queue_handler[pf],\r\nlockdep_is_held(&queue_handler_mutex));\r\nif (old == qh)\r\nret = -EEXIST;\r\nelse if (old)\r\nret = -EBUSY;\r\nelse {\r\nrcu_assign_pointer(queue_handler[pf], qh);\r\nret = 0;\r\n}\r\nmutex_unlock(&queue_handler_mutex);\r\nreturn ret;\r\n}\r\nint nf_unregister_queue_handler(u_int8_t pf, const struct nf_queue_handler *qh)\r\n{\r\nconst struct nf_queue_handler *old;\r\nif (pf >= ARRAY_SIZE(queue_handler))\r\nreturn -EINVAL;\r\nmutex_lock(&queue_handler_mutex);\r\nold = rcu_dereference_protected(queue_handler[pf],\r\nlockdep_is_held(&queue_handler_mutex));\r\nif (old && old != qh) {\r\nmutex_unlock(&queue_handler_mutex);\r\nreturn -EINVAL;\r\n}\r\nRCU_INIT_POINTER(queue_handler[pf], NULL);\r\nmutex_unlock(&queue_handler_mutex);\r\nsynchronize_rcu();\r\nreturn 0;\r\n}\r\nvoid nf_unregister_queue_handlers(const struct nf_queue_handler *qh)\r\n{\r\nu_int8_t pf;\r\nmutex_lock(&queue_handler_mutex);\r\nfor (pf = 0; pf < ARRAY_SIZE(queue_handler); pf++) {\r\nif (rcu_dereference_protected(\r\nqueue_handler[pf],\r\nlockdep_is_held(&queue_handler_mutex)\r\n) == qh)\r\nRCU_INIT_POINTER(queue_handler[pf], NULL);\r\n}\r\nmutex_unlock(&queue_handler_mutex);\r\nsynchronize_rcu();\r\n}\r\nstatic void nf_queue_entry_release_refs(struct nf_queue_entry *entry)\r\n{\r\nif (entry->indev)\r\ndev_put(entry->indev);\r\nif (entry->outdev)\r\ndev_put(entry->outdev);\r\n#ifdef CONFIG_BRIDGE_NETFILTER\r\nif (entry->skb->nf_bridge) {\r\nstruct nf_bridge_info *nf_bridge = entry->skb->nf_bridge;\r\nif (nf_bridge->physindev)\r\ndev_put(nf_bridge->physindev);\r\nif (nf_bridge->physoutdev)\r\ndev_put(nf_bridge->physoutdev);\r\n}\r\n#endif\r\nmodule_put(entry->elem->owner);\r\n}\r\nstatic int __nf_queue(struct sk_buff *skb,\r\nstruct list_head *elem,\r\nu_int8_t pf, unsigned int hook,\r\nstruct net_device *indev,\r\nstruct net_device *outdev,\r\nint (*okfn)(struct sk_buff *),\r\nunsigned int queuenum)\r\n{\r\nint status = -ENOENT;\r\nstruct nf_queue_entry *entry = NULL;\r\n#ifdef CONFIG_BRIDGE_NETFILTER\r\nstruct net_device *physindev;\r\nstruct net_device *physoutdev;\r\n#endif\r\nconst struct nf_afinfo *afinfo;\r\nconst struct nf_queue_handler *qh;\r\nrcu_read_lock();\r\nqh = rcu_dereference(queue_handler[pf]);\r\nif (!qh) {\r\nstatus = -ESRCH;\r\ngoto err_unlock;\r\n}\r\nafinfo = nf_get_afinfo(pf);\r\nif (!afinfo)\r\ngoto err_unlock;\r\nentry = kmalloc(sizeof(*entry) + afinfo->route_key_size, GFP_ATOMIC);\r\nif (!entry) {\r\nstatus = -ENOMEM;\r\ngoto err_unlock;\r\n}\r\n*entry = (struct nf_queue_entry) {\r\n.skb = skb,\r\n.elem = list_entry(elem, struct nf_hook_ops, list),\r\n.pf = pf,\r\n.hook = hook,\r\n.indev = indev,\r\n.outdev = outdev,\r\n.okfn = okfn,\r\n};\r\nif (!try_module_get(entry->elem->owner)) {\r\nstatus = -ECANCELED;\r\ngoto err_unlock;\r\n}\r\nif (indev)\r\ndev_hold(indev);\r\nif (outdev)\r\ndev_hold(outdev);\r\n#ifdef CONFIG_BRIDGE_NETFILTER\r\nif (skb->nf_bridge) {\r\nphysindev = skb->nf_bridge->physindev;\r\nif (physindev)\r\ndev_hold(physindev);\r\nphysoutdev = skb->nf_bridge->physoutdev;\r\nif (physoutdev)\r\ndev_hold(physoutdev);\r\n}\r\n#endif\r\nskb_dst_force(skb);\r\nafinfo->saveroute(skb, entry);\r\nstatus = qh->outfn(entry, queuenum);\r\nrcu_read_unlock();\r\nif (status < 0) {\r\nnf_queue_entry_release_refs(entry);\r\ngoto err;\r\n}\r\nreturn 0;\r\nerr_unlock:\r\nrcu_read_unlock();\r\nerr:\r\nkfree(entry);\r\nreturn status;\r\n}\r\nstatic void nf_bridge_adjust_skb_data(struct sk_buff *skb)\r\n{\r\nif (skb->nf_bridge)\r\n__skb_push(skb, skb->network_header - skb->mac_header);\r\n}\r\nstatic void nf_bridge_adjust_segmented_data(struct sk_buff *skb)\r\n{\r\nif (skb->nf_bridge)\r\n__skb_pull(skb, skb->network_header - skb->mac_header);\r\n}\r\nint nf_queue(struct sk_buff *skb,\r\nstruct list_head *elem,\r\nu_int8_t pf, unsigned int hook,\r\nstruct net_device *indev,\r\nstruct net_device *outdev,\r\nint (*okfn)(struct sk_buff *),\r\nunsigned int queuenum)\r\n{\r\nstruct sk_buff *segs;\r\nint err = -EINVAL;\r\nunsigned int queued;\r\nif (!skb_is_gso(skb))\r\nreturn __nf_queue(skb, elem, pf, hook, indev, outdev, okfn,\r\nqueuenum);\r\nswitch (pf) {\r\ncase NFPROTO_IPV4:\r\nskb->protocol = htons(ETH_P_IP);\r\nbreak;\r\ncase NFPROTO_IPV6:\r\nskb->protocol = htons(ETH_P_IPV6);\r\nbreak;\r\n}\r\nnf_bridge_adjust_skb_data(skb);\r\nsegs = skb_gso_segment(skb, 0);\r\nif (IS_ERR(segs))\r\ngoto out_err;\r\nqueued = 0;\r\nerr = 0;\r\ndo {\r\nstruct sk_buff *nskb = segs->next;\r\nsegs->next = NULL;\r\nif (err == 0) {\r\nnf_bridge_adjust_segmented_data(segs);\r\nerr = __nf_queue(segs, elem, pf, hook, indev,\r\noutdev, okfn, queuenum);\r\n}\r\nif (err == 0)\r\nqueued++;\r\nelse\r\nkfree_skb(segs);\r\nsegs = nskb;\r\n} while (segs);\r\nif (queued) {\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nout_err:\r\nnf_bridge_adjust_segmented_data(skb);\r\nreturn err;\r\n}\r\nvoid nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)\r\n{\r\nstruct sk_buff *skb = entry->skb;\r\nstruct list_head *elem = &entry->elem->list;\r\nconst struct nf_afinfo *afinfo;\r\nint err;\r\nrcu_read_lock();\r\nnf_queue_entry_release_refs(entry);\r\nif (verdict == NF_REPEAT) {\r\nelem = elem->prev;\r\nverdict = NF_ACCEPT;\r\n}\r\nif (verdict == NF_ACCEPT) {\r\nafinfo = nf_get_afinfo(entry->pf);\r\nif (!afinfo || afinfo->reroute(skb, entry) < 0)\r\nverdict = NF_DROP;\r\n}\r\nif (verdict == NF_ACCEPT) {\r\nnext_hook:\r\nverdict = nf_iterate(&nf_hooks[entry->pf][entry->hook],\r\nskb, entry->hook,\r\nentry->indev, entry->outdev, &elem,\r\nentry->okfn, INT_MIN);\r\n}\r\nswitch (verdict & NF_VERDICT_MASK) {\r\ncase NF_ACCEPT:\r\ncase NF_STOP:\r\nlocal_bh_disable();\r\nentry->okfn(skb);\r\nlocal_bh_enable();\r\nbreak;\r\ncase NF_QUEUE:\r\nerr = __nf_queue(skb, elem, entry->pf, entry->hook,\r\nentry->indev, entry->outdev, entry->okfn,\r\nverdict >> NF_VERDICT_QBITS);\r\nif (err < 0) {\r\nif (err == -ECANCELED)\r\ngoto next_hook;\r\nif (err == -ESRCH &&\r\n(verdict & NF_VERDICT_FLAG_QUEUE_BYPASS))\r\ngoto next_hook;\r\nkfree_skb(skb);\r\n}\r\nbreak;\r\ncase NF_STOLEN:\r\nbreak;\r\ndefault:\r\nkfree_skb(skb);\r\n}\r\nrcu_read_unlock();\r\nkfree(entry);\r\n}\r\nstatic void *seq_start(struct seq_file *seq, loff_t *pos)\r\n{\r\nif (*pos >= ARRAY_SIZE(queue_handler))\r\nreturn NULL;\r\nreturn pos;\r\n}\r\nstatic void *seq_next(struct seq_file *s, void *v, loff_t *pos)\r\n{\r\n(*pos)++;\r\nif (*pos >= ARRAY_SIZE(queue_handler))\r\nreturn NULL;\r\nreturn pos;\r\n}\r\nstatic void seq_stop(struct seq_file *s, void *v)\r\n{\r\n}\r\nstatic int seq_show(struct seq_file *s, void *v)\r\n{\r\nint ret;\r\nloff_t *pos = v;\r\nconst struct nf_queue_handler *qh;\r\nrcu_read_lock();\r\nqh = rcu_dereference(queue_handler[*pos]);\r\nif (!qh)\r\nret = seq_printf(s, "%2lld NONE\n", *pos);\r\nelse\r\nret = seq_printf(s, "%2lld %s\n", *pos, qh->name);\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nstatic int nfqueue_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open(file, &nfqueue_seq_ops);\r\n}\r\nint __init netfilter_queue_init(void)\r\n{\r\n#ifdef CONFIG_PROC_FS\r\nif (!proc_create("nf_queue", S_IRUGO,\r\nproc_net_netfilter, &nfqueue_file_ops))\r\nreturn -1;\r\n#endif\r\nreturn 0;\r\n}
