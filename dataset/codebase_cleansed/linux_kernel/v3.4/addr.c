static int ceph_set_page_dirty(struct page *page)\r\n{\r\nstruct address_space *mapping = page->mapping;\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nint undo = 0;\r\nstruct ceph_snap_context *snapc;\r\nif (unlikely(!mapping))\r\nreturn !TestSetPageDirty(page);\r\nif (TestSetPageDirty(page)) {\r\ndout("%p set_page_dirty %p idx %lu -- already dirty\n",\r\nmapping->host, page, page->index);\r\nreturn 0;\r\n}\r\ninode = mapping->host;\r\nci = ceph_inode(inode);\r\nsnapc = ceph_get_snap_context(ci->i_snap_realm->cached_context);\r\nspin_lock(&ci->i_ceph_lock);\r\nif (ci->i_head_snapc == NULL)\r\nci->i_head_snapc = ceph_get_snap_context(snapc);\r\n++ci->i_wrbuffer_ref_head;\r\nif (ci->i_wrbuffer_ref == 0)\r\nihold(inode);\r\n++ci->i_wrbuffer_ref;\r\ndout("%p set_page_dirty %p idx %lu head %d/%d -> %d/%d "\r\n"snapc %p seq %lld (%d snaps)\n",\r\nmapping->host, page, page->index,\r\nci->i_wrbuffer_ref-1, ci->i_wrbuffer_ref_head-1,\r\nci->i_wrbuffer_ref, ci->i_wrbuffer_ref_head,\r\nsnapc, snapc->seq, snapc->num_snaps);\r\nspin_unlock(&ci->i_ceph_lock);\r\nspin_lock_irq(&mapping->tree_lock);\r\nif (page->mapping) {\r\nWARN_ON_ONCE(!PageUptodate(page));\r\naccount_page_dirtied(page, page->mapping);\r\nradix_tree_tag_set(&mapping->page_tree,\r\npage_index(page), PAGECACHE_TAG_DIRTY);\r\npage->private = (unsigned long)snapc;\r\nSetPagePrivate(page);\r\n} else {\r\ndout("ANON set_page_dirty %p (raced truncate?)\n", page);\r\nundo = 1;\r\n}\r\nspin_unlock_irq(&mapping->tree_lock);\r\nif (undo)\r\nceph_put_wrbuffer_cap_refs(ci, 1, snapc);\r\n__mark_inode_dirty(mapping->host, I_DIRTY_PAGES);\r\nBUG_ON(!PageDirty(page));\r\nreturn 1;\r\n}\r\nstatic void ceph_invalidatepage(struct page *page, unsigned long offset)\r\n{\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_snap_context *snapc = (void *)page->private;\r\nBUG_ON(!PageLocked(page));\r\nBUG_ON(!page->private);\r\nBUG_ON(!PagePrivate(page));\r\nBUG_ON(!page->mapping);\r\ninode = page->mapping->host;\r\nif (!PageDirty(page))\r\npr_err("%p invalidatepage %p page not dirty\n", inode, page);\r\nif (offset == 0)\r\nClearPageChecked(page);\r\nci = ceph_inode(inode);\r\nif (offset == 0) {\r\ndout("%p invalidatepage %p idx %lu full dirty page %lu\n",\r\ninode, page, page->index, offset);\r\nceph_put_wrbuffer_cap_refs(ci, 1, snapc);\r\nceph_put_snap_context(snapc);\r\npage->private = 0;\r\nClearPagePrivate(page);\r\n} else {\r\ndout("%p invalidatepage %p idx %lu partial dirty page\n",\r\ninode, page, page->index);\r\n}\r\n}\r\nstatic int ceph_releasepage(struct page *page, gfp_t g)\r\n{\r\nstruct inode *inode = page->mapping ? page->mapping->host : NULL;\r\ndout("%p releasepage %p idx %lu\n", inode, page, page->index);\r\nWARN_ON(PageDirty(page));\r\nWARN_ON(page->private);\r\nWARN_ON(PagePrivate(page));\r\nreturn 0;\r\n}\r\nstatic int readpage_nounlock(struct file *filp, struct page *page)\r\n{\r\nstruct inode *inode = filp->f_dentry->d_inode;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_osd_client *osdc =\r\n&ceph_inode_to_client(inode)->client->osdc;\r\nint err = 0;\r\nu64 len = PAGE_CACHE_SIZE;\r\ndout("readpage inode %p file %p page %p index %lu\n",\r\ninode, filp, page, page->index);\r\nerr = ceph_osdc_readpages(osdc, ceph_vino(inode), &ci->i_layout,\r\npage->index << PAGE_CACHE_SHIFT, &len,\r\nci->i_truncate_seq, ci->i_truncate_size,\r\n&page, 1, 0);\r\nif (err == -ENOENT)\r\nerr = 0;\r\nif (err < 0) {\r\nSetPageError(page);\r\ngoto out;\r\n} else if (err < PAGE_CACHE_SIZE) {\r\nzero_user_segment(page, err, PAGE_CACHE_SIZE);\r\n}\r\nSetPageUptodate(page);\r\nout:\r\nreturn err < 0 ? err : 0;\r\n}\r\nstatic int ceph_readpage(struct file *filp, struct page *page)\r\n{\r\nint r = readpage_nounlock(filp, page);\r\nunlock_page(page);\r\nreturn r;\r\n}\r\nstatic void finish_read(struct ceph_osd_request *req, struct ceph_msg *msg)\r\n{\r\nstruct inode *inode = req->r_inode;\r\nstruct ceph_osd_reply_head *replyhead;\r\nint rc, bytes;\r\nint i;\r\nreplyhead = msg->front.iov_base;\r\nWARN_ON(le32_to_cpu(replyhead->num_ops) == 0);\r\nrc = le32_to_cpu(replyhead->result);\r\nbytes = le32_to_cpu(msg->hdr.data_len);\r\ndout("finish_read %p req %p rc %d bytes %d\n", inode, req, rc, bytes);\r\nfor (i = 0; i < req->r_num_pages; i++, bytes -= PAGE_CACHE_SIZE) {\r\nstruct page *page = req->r_pages[i];\r\nif (bytes < (int)PAGE_CACHE_SIZE) {\r\nint s = bytes < 0 ? 0 : bytes;\r\nzero_user_segment(page, s, PAGE_CACHE_SIZE);\r\n}\r\ndout("finish_read %p uptodate %p idx %lu\n", inode, page,\r\npage->index);\r\nflush_dcache_page(page);\r\nSetPageUptodate(page);\r\nunlock_page(page);\r\npage_cache_release(page);\r\n}\r\nkfree(req->r_pages);\r\n}\r\nstatic int start_read(struct inode *inode, struct list_head *page_list, int max)\r\n{\r\nstruct ceph_osd_client *osdc =\r\n&ceph_inode_to_client(inode)->client->osdc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct page *page = list_entry(page_list->prev, struct page, lru);\r\nstruct ceph_osd_request *req;\r\nu64 off;\r\nu64 len;\r\nint i;\r\nstruct page **pages;\r\npgoff_t next_index;\r\nint nr_pages = 0;\r\nint ret;\r\noff = page->index << PAGE_CACHE_SHIFT;\r\nnext_index = page->index;\r\nlist_for_each_entry_reverse(page, page_list, lru) {\r\nif (page->index != next_index)\r\nbreak;\r\nnr_pages++;\r\nnext_index++;\r\nif (max && nr_pages == max)\r\nbreak;\r\n}\r\nlen = nr_pages << PAGE_CACHE_SHIFT;\r\ndout("start_read %p nr_pages %d is %lld~%lld\n", inode, nr_pages,\r\noff, len);\r\nreq = ceph_osdc_new_request(osdc, &ci->i_layout, ceph_vino(inode),\r\noff, &len,\r\nCEPH_OSD_OP_READ, CEPH_OSD_FLAG_READ,\r\nNULL, 0,\r\nci->i_truncate_seq, ci->i_truncate_size,\r\nNULL, false, 1, 0);\r\nif (!req)\r\nreturn -ENOMEM;\r\nnr_pages = len >> PAGE_CACHE_SHIFT;\r\npages = kmalloc(sizeof(*pages) * nr_pages, GFP_NOFS);\r\nret = -ENOMEM;\r\nif (!pages)\r\ngoto out;\r\nfor (i = 0; i < nr_pages; ++i) {\r\npage = list_entry(page_list->prev, struct page, lru);\r\nBUG_ON(PageLocked(page));\r\nlist_del(&page->lru);\r\ndout("start_read %p adding %p idx %lu\n", inode, page,\r\npage->index);\r\nif (add_to_page_cache_lru(page, &inode->i_data, page->index,\r\nGFP_NOFS)) {\r\npage_cache_release(page);\r\ndout("start_read %p add_to_page_cache failed %p\n",\r\ninode, page);\r\nnr_pages = i;\r\ngoto out_pages;\r\n}\r\npages[i] = page;\r\n}\r\nreq->r_pages = pages;\r\nreq->r_num_pages = nr_pages;\r\nreq->r_callback = finish_read;\r\nreq->r_inode = inode;\r\ndout("start_read %p starting %p %lld~%lld\n", inode, req, off, len);\r\nret = ceph_osdc_start_request(osdc, req, false);\r\nif (ret < 0)\r\ngoto out_pages;\r\nceph_osdc_put_request(req);\r\nreturn nr_pages;\r\nout_pages:\r\nceph_release_page_vector(pages, nr_pages);\r\nout:\r\nceph_osdc_put_request(req);\r\nreturn ret;\r\n}\r\nstatic int ceph_readpages(struct file *file, struct address_space *mapping,\r\nstruct list_head *page_list, unsigned nr_pages)\r\n{\r\nstruct inode *inode = file->f_dentry->d_inode;\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(inode);\r\nint rc = 0;\r\nint max = 0;\r\nif (fsc->mount_options->rsize >= PAGE_CACHE_SIZE)\r\nmax = (fsc->mount_options->rsize + PAGE_CACHE_SIZE - 1)\r\n>> PAGE_SHIFT;\r\ndout("readpages %p file %p nr_pages %d max %d\n", inode, file, nr_pages,\r\nmax);\r\nwhile (!list_empty(page_list)) {\r\nrc = start_read(inode, page_list, max);\r\nif (rc < 0)\r\ngoto out;\r\nBUG_ON(rc == 0);\r\n}\r\nout:\r\ndout("readpages %p file %p ret %d\n", inode, file, rc);\r\nreturn rc;\r\n}\r\nstatic struct ceph_snap_context *get_oldest_context(struct inode *inode,\r\nu64 *snap_size)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_snap_context *snapc = NULL;\r\nstruct ceph_cap_snap *capsnap = NULL;\r\nspin_lock(&ci->i_ceph_lock);\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\ndout(" cap_snap %p snapc %p has %d dirty pages\n", capsnap,\r\ncapsnap->context, capsnap->dirty_pages);\r\nif (capsnap->dirty_pages) {\r\nsnapc = ceph_get_snap_context(capsnap->context);\r\nif (snap_size)\r\n*snap_size = capsnap->size;\r\nbreak;\r\n}\r\n}\r\nif (!snapc && ci->i_wrbuffer_ref_head) {\r\nsnapc = ceph_get_snap_context(ci->i_head_snapc);\r\ndout(" head snapc %p has %d dirty pages\n",\r\nsnapc, ci->i_wrbuffer_ref_head);\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn snapc;\r\n}\r\nstatic int writepage_nounlock(struct page *page, struct writeback_control *wbc)\r\n{\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_fs_client *fsc;\r\nstruct ceph_osd_client *osdc;\r\nloff_t page_off = page->index << PAGE_CACHE_SHIFT;\r\nint len = PAGE_CACHE_SIZE;\r\nloff_t i_size;\r\nint err = 0;\r\nstruct ceph_snap_context *snapc, *oldest;\r\nu64 snap_size = 0;\r\nlong writeback_stat;\r\ndout("writepage %p idx %lu\n", page, page->index);\r\nif (!page->mapping || !page->mapping->host) {\r\ndout("writepage %p - no mapping\n", page);\r\nreturn -EFAULT;\r\n}\r\ninode = page->mapping->host;\r\nci = ceph_inode(inode);\r\nfsc = ceph_inode_to_client(inode);\r\nosdc = &fsc->client->osdc;\r\nsnapc = (void *)page->private;\r\nif (snapc == NULL) {\r\ndout("writepage %p page %p not dirty?\n", inode, page);\r\ngoto out;\r\n}\r\noldest = get_oldest_context(inode, &snap_size);\r\nif (snapc->seq > oldest->seq) {\r\ndout("writepage %p page %p snapc %p not writeable - noop\n",\r\ninode, page, (void *)page->private);\r\nWARN_ON((current->flags & PF_MEMALLOC) == 0);\r\nceph_put_snap_context(oldest);\r\ngoto out;\r\n}\r\nceph_put_snap_context(oldest);\r\nif (snap_size)\r\ni_size = snap_size;\r\nelse\r\ni_size = i_size_read(inode);\r\nif (i_size < page_off + len)\r\nlen = i_size - page_off;\r\ndout("writepage %p page %p index %lu on %llu~%u snapc %p\n",\r\ninode, page, page->index, page_off, len, snapc);\r\nwriteback_stat = atomic_long_inc_return(&fsc->writeback_count);\r\nif (writeback_stat >\r\nCONGESTION_ON_THRESH(fsc->mount_options->congestion_kb))\r\nset_bdi_congested(&fsc->backing_dev_info, BLK_RW_ASYNC);\r\nset_page_writeback(page);\r\nerr = ceph_osdc_writepages(osdc, ceph_vino(inode),\r\n&ci->i_layout, snapc,\r\npage_off, len,\r\nci->i_truncate_seq, ci->i_truncate_size,\r\n&inode->i_mtime,\r\n&page, 1, 0, 0, true);\r\nif (err < 0) {\r\ndout("writepage setting page/mapping error %d %p\n", err, page);\r\nSetPageError(page);\r\nmapping_set_error(&inode->i_data, err);\r\nif (wbc)\r\nwbc->pages_skipped++;\r\n} else {\r\ndout("writepage cleaned page %p\n", page);\r\nerr = 0;\r\n}\r\npage->private = 0;\r\nClearPagePrivate(page);\r\nend_page_writeback(page);\r\nceph_put_wrbuffer_cap_refs(ci, 1, snapc);\r\nceph_put_snap_context(snapc);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ceph_writepage(struct page *page, struct writeback_control *wbc)\r\n{\r\nint err;\r\nstruct inode *inode = page->mapping->host;\r\nBUG_ON(!inode);\r\nihold(inode);\r\nerr = writepage_nounlock(page, wbc);\r\nunlock_page(page);\r\niput(inode);\r\nreturn err;\r\n}\r\nstatic void ceph_release_pages(struct page **pages, int num)\r\n{\r\nstruct pagevec pvec;\r\nint i;\r\npagevec_init(&pvec, 0);\r\nfor (i = 0; i < num; i++) {\r\nif (pagevec_add(&pvec, pages[i]) == 0)\r\npagevec_release(&pvec);\r\n}\r\npagevec_release(&pvec);\r\n}\r\nstatic void writepages_finish(struct ceph_osd_request *req,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct inode *inode = req->r_inode;\r\nstruct ceph_osd_reply_head *replyhead;\r\nstruct ceph_osd_op *op;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nunsigned wrote;\r\nstruct page *page;\r\nint i;\r\nstruct ceph_snap_context *snapc = req->r_snapc;\r\nstruct address_space *mapping = inode->i_mapping;\r\n__s32 rc = -EIO;\r\nu64 bytes = 0;\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(inode);\r\nlong writeback_stat;\r\nunsigned issued = ceph_caps_issued(ci);\r\nreplyhead = msg->front.iov_base;\r\nWARN_ON(le32_to_cpu(replyhead->num_ops) == 0);\r\nop = (void *)(replyhead + 1);\r\nrc = le32_to_cpu(replyhead->result);\r\nbytes = le64_to_cpu(op->extent.length);\r\nif (rc >= 0) {\r\nwrote = req->r_num_pages;\r\n} else {\r\nwrote = 0;\r\nmapping_set_error(mapping, rc);\r\n}\r\ndout("writepages_finish %p rc %d bytes %llu wrote %d (pages)\n",\r\ninode, rc, bytes, wrote);\r\nfor (i = 0; i < req->r_num_pages; i++) {\r\npage = req->r_pages[i];\r\nBUG_ON(!page);\r\nWARN_ON(!PageUptodate(page));\r\nwriteback_stat =\r\natomic_long_dec_return(&fsc->writeback_count);\r\nif (writeback_stat <\r\nCONGESTION_OFF_THRESH(fsc->mount_options->congestion_kb))\r\nclear_bdi_congested(&fsc->backing_dev_info,\r\nBLK_RW_ASYNC);\r\nceph_put_snap_context((void *)page->private);\r\npage->private = 0;\r\nClearPagePrivate(page);\r\ndout("unlocking %d %p\n", i, page);\r\nend_page_writeback(page);\r\nif ((issued & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)) == 0)\r\ngeneric_error_remove_page(inode->i_mapping, page);\r\nunlock_page(page);\r\n}\r\ndout("%p wrote+cleaned %d pages\n", inode, wrote);\r\nceph_put_wrbuffer_cap_refs(ci, req->r_num_pages, snapc);\r\nceph_release_pages(req->r_pages, req->r_num_pages);\r\nif (req->r_pages_from_pool)\r\nmempool_free(req->r_pages,\r\nceph_sb_to_client(inode->i_sb)->wb_pagevec_pool);\r\nelse\r\nkfree(req->r_pages);\r\nceph_osdc_put_request(req);\r\n}\r\nstatic void alloc_page_vec(struct ceph_fs_client *fsc,\r\nstruct ceph_osd_request *req)\r\n{\r\nreq->r_pages = kmalloc(sizeof(struct page *) * req->r_num_pages,\r\nGFP_NOFS);\r\nif (!req->r_pages) {\r\nreq->r_pages = mempool_alloc(fsc->wb_pagevec_pool, GFP_NOFS);\r\nreq->r_pages_from_pool = 1;\r\nWARN_ON(!req->r_pages);\r\n}\r\n}\r\nstatic int ceph_writepages_start(struct address_space *mapping,\r\nstruct writeback_control *wbc)\r\n{\r\nstruct inode *inode = mapping->host;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_fs_client *fsc;\r\npgoff_t index, start, end;\r\nint range_whole = 0;\r\nint should_loop = 1;\r\npgoff_t max_pages = 0, max_pages_ever = 0;\r\nstruct ceph_snap_context *snapc = NULL, *last_snapc = NULL, *pgsnapc;\r\nstruct pagevec pvec;\r\nint done = 0;\r\nint rc = 0;\r\nunsigned wsize = 1 << inode->i_blkbits;\r\nstruct ceph_osd_request *req = NULL;\r\nint do_sync;\r\nu64 snap_size = 0;\r\ndo_sync = wbc->sync_mode == WB_SYNC_ALL;\r\nif (ceph_caps_revoking(ci, CEPH_CAP_FILE_BUFFER))\r\ndo_sync = 1;\r\ndout("writepages_start %p dosync=%d (mode=%s)\n",\r\ninode, do_sync,\r\nwbc->sync_mode == WB_SYNC_NONE ? "NONE" :\r\n(wbc->sync_mode == WB_SYNC_ALL ? "ALL" : "HOLD"));\r\nfsc = ceph_inode_to_client(inode);\r\nif (fsc->mount_state == CEPH_MOUNT_SHUTDOWN) {\r\npr_warning("writepage_start %p on forced umount\n", inode);\r\nreturn -EIO;\r\n}\r\nif (fsc->mount_options->wsize && fsc->mount_options->wsize < wsize)\r\nwsize = fsc->mount_options->wsize;\r\nif (wsize < PAGE_CACHE_SIZE)\r\nwsize = PAGE_CACHE_SIZE;\r\nmax_pages_ever = wsize >> PAGE_CACHE_SHIFT;\r\npagevec_init(&pvec, 0);\r\nif (wbc->range_cyclic) {\r\nstart = mapping->writeback_index;\r\nend = -1;\r\ndout(" cyclic, start at %lu\n", start);\r\n} else {\r\nstart = wbc->range_start >> PAGE_CACHE_SHIFT;\r\nend = wbc->range_end >> PAGE_CACHE_SHIFT;\r\nif (wbc->range_start == 0 && wbc->range_end == LLONG_MAX)\r\nrange_whole = 1;\r\nshould_loop = 0;\r\ndout(" not cyclic, %lu to %lu\n", start, end);\r\n}\r\nindex = start;\r\nretry:\r\nceph_put_snap_context(snapc);\r\nsnapc = get_oldest_context(inode, &snap_size);\r\nif (!snapc) {\r\ndout(" no snap context with dirty data?\n");\r\ngoto out;\r\n}\r\ndout(" oldest snapc is %p seq %lld (%d snaps)\n",\r\nsnapc, snapc->seq, snapc->num_snaps);\r\nif (last_snapc && snapc != last_snapc) {\r\ndout(" snapc differs from last pass, restarting at %lu\n",\r\nindex);\r\nindex = start;\r\n}\r\nlast_snapc = snapc;\r\nwhile (!done && index <= end) {\r\nunsigned i;\r\nint first;\r\npgoff_t next;\r\nint pvec_pages, locked_pages;\r\nstruct page *page;\r\nint want;\r\nu64 offset, len;\r\nstruct ceph_osd_request_head *reqhead;\r\nstruct ceph_osd_op *op;\r\nlong writeback_stat;\r\nnext = 0;\r\nlocked_pages = 0;\r\nmax_pages = max_pages_ever;\r\nget_more_pages:\r\nfirst = -1;\r\nwant = min(end - index,\r\nmin((pgoff_t)PAGEVEC_SIZE,\r\nmax_pages - (pgoff_t)locked_pages) - 1)\r\n+ 1;\r\npvec_pages = pagevec_lookup_tag(&pvec, mapping, &index,\r\nPAGECACHE_TAG_DIRTY,\r\nwant);\r\ndout("pagevec_lookup_tag got %d\n", pvec_pages);\r\nif (!pvec_pages && !locked_pages)\r\nbreak;\r\nfor (i = 0; i < pvec_pages && locked_pages < max_pages; i++) {\r\npage = pvec.pages[i];\r\ndout("? %p idx %lu\n", page, page->index);\r\nif (locked_pages == 0)\r\nlock_page(page);\r\nelse if (!trylock_page(page))\r\nbreak;\r\nif (unlikely(!PageDirty(page)) ||\r\nunlikely(page->mapping != mapping)) {\r\ndout("!dirty or !mapping %p\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (!wbc->range_cyclic && page->index > end) {\r\ndout("end of range %p\n", page);\r\ndone = 1;\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (next && (page->index != next)) {\r\ndout("not consecutive %p\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (wbc->sync_mode != WB_SYNC_NONE) {\r\ndout("waiting on writeback %p\n", page);\r\nwait_on_page_writeback(page);\r\n}\r\nif ((snap_size && page_offset(page) > snap_size) ||\r\n(!snap_size &&\r\npage_offset(page) > i_size_read(inode))) {\r\ndout("%p page eof %llu\n", page, snap_size ?\r\nsnap_size : i_size_read(inode));\r\ndone = 1;\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (PageWriteback(page)) {\r\ndout("%p under writeback\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\npgsnapc = (void *)page->private;\r\nif (pgsnapc->seq > snapc->seq) {\r\ndout("page snapc %p %lld > oldest %p %lld\n",\r\npgsnapc, pgsnapc->seq, snapc, snapc->seq);\r\nunlock_page(page);\r\nif (!locked_pages)\r\ncontinue;\r\nbreak;\r\n}\r\nif (!clear_page_dirty_for_io(page)) {\r\ndout("%p !clear_page_dirty_for_io\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (locked_pages == 0) {\r\noffset = (unsigned long long)page->index\r\n<< PAGE_CACHE_SHIFT;\r\nlen = wsize;\r\nreq = ceph_osdc_new_request(&fsc->client->osdc,\r\n&ci->i_layout,\r\nceph_vino(inode),\r\noffset, &len,\r\nCEPH_OSD_OP_WRITE,\r\nCEPH_OSD_FLAG_WRITE |\r\nCEPH_OSD_FLAG_ONDISK,\r\nsnapc, do_sync,\r\nci->i_truncate_seq,\r\nci->i_truncate_size,\r\n&inode->i_mtime, true, 1, 0);\r\nif (!req) {\r\nrc = -ENOMEM;\r\nunlock_page(page);\r\nbreak;\r\n}\r\nmax_pages = req->r_num_pages;\r\nalloc_page_vec(fsc, req);\r\nreq->r_callback = writepages_finish;\r\nreq->r_inode = inode;\r\n}\r\nif (first < 0)\r\nfirst = i;\r\ndout("%p will write page %p idx %lu\n",\r\ninode, page, page->index);\r\nwriteback_stat =\r\natomic_long_inc_return(&fsc->writeback_count);\r\nif (writeback_stat > CONGESTION_ON_THRESH(\r\nfsc->mount_options->congestion_kb)) {\r\nset_bdi_congested(&fsc->backing_dev_info,\r\nBLK_RW_ASYNC);\r\n}\r\nset_page_writeback(page);\r\nreq->r_pages[locked_pages] = page;\r\nlocked_pages++;\r\nnext = page->index + 1;\r\n}\r\nif (!locked_pages)\r\ngoto release_pvec_pages;\r\nif (i) {\r\nint j;\r\nBUG_ON(!locked_pages || first < 0);\r\nif (pvec_pages && i == pvec_pages &&\r\nlocked_pages < max_pages) {\r\ndout("reached end pvec, trying for more\n");\r\npagevec_reinit(&pvec);\r\ngoto get_more_pages;\r\n}\r\nfor (j = i; j < pvec_pages; j++) {\r\ndout(" pvec leftover page %p\n",\r\npvec.pages[j]);\r\npvec.pages[j-i+first] = pvec.pages[j];\r\n}\r\npvec.nr -= i-first;\r\n}\r\noffset = req->r_pages[0]->index << PAGE_CACHE_SHIFT;\r\nlen = min((snap_size ? snap_size : i_size_read(inode)) - offset,\r\n(u64)locked_pages << PAGE_CACHE_SHIFT);\r\ndout("writepages got %d pages at %llu~%llu\n",\r\nlocked_pages, offset, len);\r\nreq->r_num_pages = locked_pages;\r\nreqhead = req->r_request->front.iov_base;\r\nop = (void *)(reqhead + 1);\r\nop->extent.length = cpu_to_le64(len);\r\nop->payload_len = cpu_to_le32(len);\r\nreq->r_request->hdr.data_len = cpu_to_le32(len);\r\nrc = ceph_osdc_start_request(&fsc->client->osdc, req, true);\r\nBUG_ON(rc);\r\nreq = NULL;\r\nindex = next;\r\nwbc->nr_to_write -= locked_pages;\r\nif (wbc->nr_to_write <= 0)\r\ndone = 1;\r\nrelease_pvec_pages:\r\ndout("pagevec_release on %d pages (%p)\n", (int)pvec.nr,\r\npvec.nr ? pvec.pages[0] : NULL);\r\npagevec_release(&pvec);\r\nif (locked_pages && !done)\r\ngoto retry;\r\n}\r\nif (should_loop && !done) {\r\ndout("writepages looping back to beginning of file\n");\r\nshould_loop = 0;\r\nindex = 0;\r\ngoto retry;\r\n}\r\nif (wbc->range_cyclic || (range_whole && wbc->nr_to_write > 0))\r\nmapping->writeback_index = index;\r\nout:\r\nif (req)\r\nceph_osdc_put_request(req);\r\nceph_put_snap_context(snapc);\r\ndout("writepages done, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int context_is_writeable_or_written(struct inode *inode,\r\nstruct ceph_snap_context *snapc)\r\n{\r\nstruct ceph_snap_context *oldest = get_oldest_context(inode, NULL);\r\nint ret = !oldest || snapc->seq <= oldest->seq;\r\nceph_put_snap_context(oldest);\r\nreturn ret;\r\n}\r\nstatic int ceph_update_writeable_page(struct file *file,\r\nloff_t pos, unsigned len,\r\nstruct page *page)\r\n{\r\nstruct inode *inode = file->f_dentry->d_inode;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nloff_t page_off = pos & PAGE_CACHE_MASK;\r\nint pos_in_page = pos & ~PAGE_CACHE_MASK;\r\nint end_in_page = pos_in_page + len;\r\nloff_t i_size;\r\nint r;\r\nstruct ceph_snap_context *snapc, *oldest;\r\nretry_locked:\r\nwait_on_page_writeback(page);\r\nBUG_ON(!ci->i_snap_realm);\r\ndown_read(&mdsc->snap_rwsem);\r\nBUG_ON(!ci->i_snap_realm->cached_context);\r\nsnapc = (void *)page->private;\r\nif (snapc && snapc != ci->i_head_snapc) {\r\noldest = get_oldest_context(inode, NULL);\r\nup_read(&mdsc->snap_rwsem);\r\nif (snapc->seq > oldest->seq) {\r\nceph_put_snap_context(oldest);\r\ndout(" page %p snapc %p not current or oldest\n",\r\npage, snapc);\r\nsnapc = ceph_get_snap_context(snapc);\r\nunlock_page(page);\r\nceph_queue_writeback(inode);\r\nr = wait_event_interruptible(ci->i_cap_wq,\r\ncontext_is_writeable_or_written(inode, snapc));\r\nceph_put_snap_context(snapc);\r\nif (r == -ERESTARTSYS)\r\nreturn r;\r\nreturn -EAGAIN;\r\n}\r\nceph_put_snap_context(oldest);\r\ndout(" page %p snapc %p not current, but oldest\n",\r\npage, snapc);\r\nif (!clear_page_dirty_for_io(page))\r\ngoto retry_locked;\r\nr = writepage_nounlock(page, NULL);\r\nif (r < 0)\r\ngoto fail_nosnap;\r\ngoto retry_locked;\r\n}\r\nif (PageUptodate(page)) {\r\ndout(" page %p already uptodate\n", page);\r\nreturn 0;\r\n}\r\nif (pos_in_page == 0 && len == PAGE_CACHE_SIZE)\r\nreturn 0;\r\ni_size = inode->i_size;\r\nif (i_size + len > inode->i_sb->s_maxbytes) {\r\nr = -EINVAL;\r\ngoto fail;\r\n}\r\nif (page_off >= i_size ||\r\n(pos_in_page == 0 && (pos+len) >= i_size &&\r\nend_in_page - pos_in_page != PAGE_CACHE_SIZE)) {\r\ndout(" zeroing %p 0 - %d and %d - %d\n",\r\npage, pos_in_page, end_in_page, (int)PAGE_CACHE_SIZE);\r\nzero_user_segments(page,\r\n0, pos_in_page,\r\nend_in_page, PAGE_CACHE_SIZE);\r\nreturn 0;\r\n}\r\nup_read(&mdsc->snap_rwsem);\r\nr = readpage_nounlock(file, page);\r\nif (r < 0)\r\ngoto fail_nosnap;\r\ngoto retry_locked;\r\nfail:\r\nup_read(&mdsc->snap_rwsem);\r\nfail_nosnap:\r\nunlock_page(page);\r\nreturn r;\r\n}\r\nstatic int ceph_write_begin(struct file *file, struct address_space *mapping,\r\nloff_t pos, unsigned len, unsigned flags,\r\nstruct page **pagep, void **fsdata)\r\n{\r\nstruct inode *inode = file->f_dentry->d_inode;\r\nstruct page *page;\r\npgoff_t index = pos >> PAGE_CACHE_SHIFT;\r\nint r;\r\ndo {\r\npage = grab_cache_page_write_begin(mapping, index, 0);\r\nif (!page)\r\nreturn -ENOMEM;\r\n*pagep = page;\r\ndout("write_begin file %p inode %p page %p %d~%d\n", file,\r\ninode, page, (int)pos, (int)len);\r\nr = ceph_update_writeable_page(file, pos, len, page);\r\n} while (r == -EAGAIN);\r\nreturn r;\r\n}\r\nstatic int ceph_write_end(struct file *file, struct address_space *mapping,\r\nloff_t pos, unsigned len, unsigned copied,\r\nstruct page *page, void *fsdata)\r\n{\r\nstruct inode *inode = file->f_dentry->d_inode;\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(inode);\r\nstruct ceph_mds_client *mdsc = fsc->mdsc;\r\nunsigned from = pos & (PAGE_CACHE_SIZE - 1);\r\nint check_cap = 0;\r\ndout("write_end file %p inode %p page %p %d~%d (%d)\n", file,\r\ninode, page, (int)pos, (int)copied, (int)len);\r\nif (copied < len)\r\nzero_user_segment(page, from+copied, len);\r\nif (pos+copied > inode->i_size)\r\ncheck_cap = ceph_inode_set_size(inode, pos+copied);\r\nif (!PageUptodate(page))\r\nSetPageUptodate(page);\r\nset_page_dirty(page);\r\nunlock_page(page);\r\nup_read(&mdsc->snap_rwsem);\r\npage_cache_release(page);\r\nif (check_cap)\r\nceph_check_caps(ceph_inode(inode), CHECK_CAPS_AUTHONLY, NULL);\r\nreturn copied;\r\n}\r\nstatic ssize_t ceph_direct_io(int rw, struct kiocb *iocb,\r\nconst struct iovec *iov,\r\nloff_t pos, unsigned long nr_segs)\r\n{\r\nWARN_ON(1);\r\nreturn -EINVAL;\r\n}\r\nstatic int ceph_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct inode *inode = vma->vm_file->f_dentry->d_inode;\r\nstruct page *page = vmf->page;\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nloff_t off = page->index << PAGE_CACHE_SHIFT;\r\nloff_t size, len;\r\nint ret;\r\nsize = i_size_read(inode);\r\nif (off + PAGE_CACHE_SIZE <= size)\r\nlen = PAGE_CACHE_SIZE;\r\nelse\r\nlen = size & ~PAGE_CACHE_MASK;\r\ndout("page_mkwrite %p %llu~%llu page %p idx %lu\n", inode,\r\noff, len, page, page->index);\r\nlock_page(page);\r\nret = VM_FAULT_NOPAGE;\r\nif ((off > size) ||\r\n(page->mapping != inode->i_mapping))\r\ngoto out;\r\nret = ceph_update_writeable_page(vma->vm_file, off, len, page);\r\nif (ret == 0) {\r\nset_page_dirty(page);\r\nup_read(&mdsc->snap_rwsem);\r\nret = VM_FAULT_LOCKED;\r\n} else {\r\nif (ret == -ENOMEM)\r\nret = VM_FAULT_OOM;\r\nelse\r\nret = VM_FAULT_SIGBUS;\r\n}\r\nout:\r\ndout("page_mkwrite %p %llu~%llu = %d\n", inode, off, len, ret);\r\nif (ret != VM_FAULT_LOCKED)\r\nunlock_page(page);\r\nreturn ret;\r\n}\r\nint ceph_mmap(struct file *file, struct vm_area_struct *vma)\r\n{\r\nstruct address_space *mapping = file->f_mapping;\r\nif (!mapping->a_ops->readpage)\r\nreturn -ENOEXEC;\r\nfile_accessed(file);\r\nvma->vm_ops = &ceph_vmops;\r\nvma->vm_flags |= VM_CAN_NONLINEAR;\r\nreturn 0;\r\n}
