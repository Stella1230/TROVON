static int\r\nnv84_crypt_context_new(struct nouveau_channel *chan, int engine)\r\n{\r\nstruct drm_device *dev = chan->dev;\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj *ramin = chan->ramin;\r\nstruct nouveau_gpuobj *ctx;\r\nint ret;\r\nNV_DEBUG(dev, "ch%d\n", chan->id);\r\nret = nouveau_gpuobj_new(dev, chan, 256, 0, NVOBJ_FLAG_ZERO_ALLOC |\r\nNVOBJ_FLAG_ZERO_FREE, &ctx);\r\nif (ret)\r\nreturn ret;\r\nnv_wo32(ramin, 0xa0, 0x00190000);\r\nnv_wo32(ramin, 0xa4, ctx->vinst + ctx->size - 1);\r\nnv_wo32(ramin, 0xa8, ctx->vinst);\r\nnv_wo32(ramin, 0xac, 0);\r\nnv_wo32(ramin, 0xb0, 0);\r\nnv_wo32(ramin, 0xb4, 0);\r\ndev_priv->engine.instmem.flush(dev);\r\natomic_inc(&chan->vm->engref[engine]);\r\nchan->engctx[engine] = ctx;\r\nreturn 0;\r\n}\r\nstatic void\r\nnv84_crypt_context_del(struct nouveau_channel *chan, int engine)\r\n{\r\nstruct nouveau_gpuobj *ctx = chan->engctx[engine];\r\nstruct drm_device *dev = chan->dev;\r\nu32 inst;\r\ninst = (chan->ramin->vinst >> 12);\r\ninst |= 0x80000000;\r\nnv_wr32(dev, 0x10200c, 0x00000000);\r\nif (nv_rd32(dev, 0x102188) == inst)\r\nnv_mask(dev, 0x102188, 0x80000000, 0x00000000);\r\nif (nv_rd32(dev, 0x10218c) == inst)\r\nnv_mask(dev, 0x10218c, 0x80000000, 0x00000000);\r\nnv_wr32(dev, 0x10200c, 0x00000010);\r\nnouveau_gpuobj_ref(NULL, &ctx);\r\natomic_dec(&chan->vm->engref[engine]);\r\nchan->engctx[engine] = NULL;\r\n}\r\nstatic int\r\nnv84_crypt_object_new(struct nouveau_channel *chan, int engine,\r\nu32 handle, u16 class)\r\n{\r\nstruct drm_device *dev = chan->dev;\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj *obj = NULL;\r\nint ret;\r\nret = nouveau_gpuobj_new(dev, chan, 16, 16, NVOBJ_FLAG_ZERO_FREE, &obj);\r\nif (ret)\r\nreturn ret;\r\nobj->engine = 5;\r\nobj->class = class;\r\nnv_wo32(obj, 0x00, class);\r\ndev_priv->engine.instmem.flush(dev);\r\nret = nouveau_ramht_insert(chan, handle, obj);\r\nnouveau_gpuobj_ref(NULL, &obj);\r\nreturn ret;\r\n}\r\nstatic void\r\nnv84_crypt_tlb_flush(struct drm_device *dev, int engine)\r\n{\r\nnv50_vm_flush_engine(dev, 0x0a);\r\n}\r\nstatic void\r\nnv84_crypt_isr(struct drm_device *dev)\r\n{\r\nu32 stat = nv_rd32(dev, 0x102130);\r\nu32 mthd = nv_rd32(dev, 0x102190);\r\nu32 data = nv_rd32(dev, 0x102194);\r\nu32 inst = nv_rd32(dev, 0x102188) & 0x7fffffff;\r\nint show = nouveau_ratelimit();\r\nif (show) {\r\nNV_INFO(dev, "PCRYPT_INTR: 0x%08x 0x%08x 0x%08x 0x%08x\n",\r\nstat, mthd, data, inst);\r\n}\r\nnv_wr32(dev, 0x102130, stat);\r\nnv_wr32(dev, 0x10200c, 0x10);\r\nnv50_fb_vm_trap(dev, show);\r\n}\r\nstatic int\r\nnv84_crypt_fini(struct drm_device *dev, int engine, bool suspend)\r\n{\r\nnv_wr32(dev, 0x102140, 0x00000000);\r\nreturn 0;\r\n}\r\nstatic int\r\nnv84_crypt_init(struct drm_device *dev, int engine)\r\n{\r\nnv_mask(dev, 0x000200, 0x00004000, 0x00000000);\r\nnv_mask(dev, 0x000200, 0x00004000, 0x00004000);\r\nnv_wr32(dev, 0x102130, 0xffffffff);\r\nnv_wr32(dev, 0x102140, 0xffffffbf);\r\nnv_wr32(dev, 0x10200c, 0x00000010);\r\nreturn 0;\r\n}\r\nstatic void\r\nnv84_crypt_destroy(struct drm_device *dev, int engine)\r\n{\r\nstruct nv84_crypt_engine *pcrypt = nv_engine(dev, engine);\r\nNVOBJ_ENGINE_DEL(dev, CRYPT);\r\nnouveau_irq_unregister(dev, 14);\r\nkfree(pcrypt);\r\n}\r\nint\r\nnv84_crypt_create(struct drm_device *dev)\r\n{\r\nstruct nv84_crypt_engine *pcrypt;\r\npcrypt = kzalloc(sizeof(*pcrypt), GFP_KERNEL);\r\nif (!pcrypt)\r\nreturn -ENOMEM;\r\npcrypt->base.destroy = nv84_crypt_destroy;\r\npcrypt->base.init = nv84_crypt_init;\r\npcrypt->base.fini = nv84_crypt_fini;\r\npcrypt->base.context_new = nv84_crypt_context_new;\r\npcrypt->base.context_del = nv84_crypt_context_del;\r\npcrypt->base.object_new = nv84_crypt_object_new;\r\npcrypt->base.tlb_flush = nv84_crypt_tlb_flush;\r\nnouveau_irq_register(dev, 14, nv84_crypt_isr);\r\nNVOBJ_ENGINE_ADD(dev, CRYPT, &pcrypt->base);\r\nNVOBJ_CLASS (dev, 0x74c1, CRYPT);\r\nreturn 0;\r\n}
