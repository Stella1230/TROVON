static int op_needs_trail(int op)\r\n{\r\nswitch (op) {\r\ncase CEPH_OSD_OP_GETXATTR:\r\ncase CEPH_OSD_OP_SETXATTR:\r\ncase CEPH_OSD_OP_CMPXATTR:\r\ncase CEPH_OSD_OP_CALL:\r\ncase CEPH_OSD_OP_NOTIFY:\r\nreturn 1;\r\ndefault:\r\nreturn 0;\r\n}\r\n}\r\nstatic int op_has_extent(int op)\r\n{\r\nreturn (op == CEPH_OSD_OP_READ ||\r\nop == CEPH_OSD_OP_WRITE);\r\n}\r\nvoid ceph_calc_raw_layout(struct ceph_osd_client *osdc,\r\nstruct ceph_file_layout *layout,\r\nu64 snapid,\r\nu64 off, u64 *plen, u64 *bno,\r\nstruct ceph_osd_request *req,\r\nstruct ceph_osd_req_op *op)\r\n{\r\nstruct ceph_osd_request_head *reqhead = req->r_request->front.iov_base;\r\nu64 orig_len = *plen;\r\nu64 objoff, objlen;\r\nreqhead->snapid = cpu_to_le64(snapid);\r\nceph_calc_file_object_mapping(layout, off, plen, bno,\r\n&objoff, &objlen);\r\nif (*plen < orig_len)\r\ndout(" skipping last %llu, final file extent %llu~%llu\n",\r\norig_len - *plen, off, *plen);\r\nif (op_has_extent(op->op)) {\r\nop->extent.offset = objoff;\r\nop->extent.length = objlen;\r\n}\r\nreq->r_num_pages = calc_pages_for(off, *plen);\r\nreq->r_page_alignment = off & ~PAGE_MASK;\r\nif (op->op == CEPH_OSD_OP_WRITE)\r\nop->payload_len = *plen;\r\ndout("calc_layout bno=%llx %llu~%llu (%d pages)\n",\r\n*bno, objoff, objlen, req->r_num_pages);\r\n}\r\nstatic void calc_layout(struct ceph_osd_client *osdc,\r\nstruct ceph_vino vino,\r\nstruct ceph_file_layout *layout,\r\nu64 off, u64 *plen,\r\nstruct ceph_osd_request *req,\r\nstruct ceph_osd_req_op *op)\r\n{\r\nu64 bno;\r\nceph_calc_raw_layout(osdc, layout, vino.snap, off,\r\nplen, &bno, req, op);\r\nsnprintf(req->r_oid, sizeof(req->r_oid), "%llx.%08llx", vino.ino, bno);\r\nreq->r_oid_len = strlen(req->r_oid);\r\n}\r\nvoid ceph_osdc_release_request(struct kref *kref)\r\n{\r\nstruct ceph_osd_request *req = container_of(kref,\r\nstruct ceph_osd_request,\r\nr_kref);\r\nif (req->r_request)\r\nceph_msg_put(req->r_request);\r\nif (req->r_reply)\r\nceph_msg_put(req->r_reply);\r\nif (req->r_con_filling_msg) {\r\ndout("release_request revoking pages %p from con %p\n",\r\nreq->r_pages, req->r_con_filling_msg);\r\nceph_con_revoke_message(req->r_con_filling_msg,\r\nreq->r_reply);\r\nceph_con_put(req->r_con_filling_msg);\r\n}\r\nif (req->r_own_pages)\r\nceph_release_page_vector(req->r_pages,\r\nreq->r_num_pages);\r\n#ifdef CONFIG_BLOCK\r\nif (req->r_bio)\r\nbio_put(req->r_bio);\r\n#endif\r\nceph_put_snap_context(req->r_snapc);\r\nif (req->r_trail) {\r\nceph_pagelist_release(req->r_trail);\r\nkfree(req->r_trail);\r\n}\r\nif (req->r_mempool)\r\nmempool_free(req, req->r_osdc->req_mempool);\r\nelse\r\nkfree(req);\r\n}\r\nstatic int get_num_ops(struct ceph_osd_req_op *ops, int *needs_trail)\r\n{\r\nint i = 0;\r\nif (needs_trail)\r\n*needs_trail = 0;\r\nwhile (ops[i].op) {\r\nif (needs_trail && op_needs_trail(ops[i].op))\r\n*needs_trail = 1;\r\ni++;\r\n}\r\nreturn i;\r\n}\r\nstruct ceph_osd_request *ceph_osdc_alloc_request(struct ceph_osd_client *osdc,\r\nint flags,\r\nstruct ceph_snap_context *snapc,\r\nstruct ceph_osd_req_op *ops,\r\nbool use_mempool,\r\ngfp_t gfp_flags,\r\nstruct page **pages,\r\nstruct bio *bio)\r\n{\r\nstruct ceph_osd_request *req;\r\nstruct ceph_msg *msg;\r\nint needs_trail;\r\nint num_op = get_num_ops(ops, &needs_trail);\r\nsize_t msg_size = sizeof(struct ceph_osd_request_head);\r\nmsg_size += num_op*sizeof(struct ceph_osd_op);\r\nif (use_mempool) {\r\nreq = mempool_alloc(osdc->req_mempool, gfp_flags);\r\nmemset(req, 0, sizeof(*req));\r\n} else {\r\nreq = kzalloc(sizeof(*req), gfp_flags);\r\n}\r\nif (req == NULL)\r\nreturn NULL;\r\nreq->r_osdc = osdc;\r\nreq->r_mempool = use_mempool;\r\nkref_init(&req->r_kref);\r\ninit_completion(&req->r_completion);\r\ninit_completion(&req->r_safe_completion);\r\nINIT_LIST_HEAD(&req->r_unsafe_item);\r\nINIT_LIST_HEAD(&req->r_linger_item);\r\nINIT_LIST_HEAD(&req->r_linger_osd);\r\nINIT_LIST_HEAD(&req->r_req_lru_item);\r\nreq->r_flags = flags;\r\nWARN_ON((flags & (CEPH_OSD_FLAG_READ|CEPH_OSD_FLAG_WRITE)) == 0);\r\nif (use_mempool)\r\nmsg = ceph_msgpool_get(&osdc->msgpool_op_reply, 0);\r\nelse\r\nmsg = ceph_msg_new(CEPH_MSG_OSD_OPREPLY,\r\nOSD_OPREPLY_FRONT_LEN, gfp_flags, true);\r\nif (!msg) {\r\nceph_osdc_put_request(req);\r\nreturn NULL;\r\n}\r\nreq->r_reply = msg;\r\nif (needs_trail) {\r\nreq->r_trail = kmalloc(sizeof(struct ceph_pagelist), gfp_flags);\r\nif (!req->r_trail) {\r\nceph_osdc_put_request(req);\r\nreturn NULL;\r\n}\r\nceph_pagelist_init(req->r_trail);\r\n}\r\nmsg_size += MAX_OBJ_NAME_SIZE;\r\nif (snapc)\r\nmsg_size += sizeof(u64) * snapc->num_snaps;\r\nif (use_mempool)\r\nmsg = ceph_msgpool_get(&osdc->msgpool_op, 0);\r\nelse\r\nmsg = ceph_msg_new(CEPH_MSG_OSD_OP, msg_size, gfp_flags, true);\r\nif (!msg) {\r\nceph_osdc_put_request(req);\r\nreturn NULL;\r\n}\r\nmsg->hdr.type = cpu_to_le16(CEPH_MSG_OSD_OP);\r\nmemset(msg->front.iov_base, 0, msg->front.iov_len);\r\nreq->r_request = msg;\r\nreq->r_pages = pages;\r\n#ifdef CONFIG_BLOCK\r\nif (bio) {\r\nreq->r_bio = bio;\r\nbio_get(req->r_bio);\r\n}\r\n#endif\r\nreturn req;\r\n}\r\nstatic void osd_req_encode_op(struct ceph_osd_request *req,\r\nstruct ceph_osd_op *dst,\r\nstruct ceph_osd_req_op *src)\r\n{\r\ndst->op = cpu_to_le16(src->op);\r\nswitch (dst->op) {\r\ncase CEPH_OSD_OP_READ:\r\ncase CEPH_OSD_OP_WRITE:\r\ndst->extent.offset =\r\ncpu_to_le64(src->extent.offset);\r\ndst->extent.length =\r\ncpu_to_le64(src->extent.length);\r\ndst->extent.truncate_size =\r\ncpu_to_le64(src->extent.truncate_size);\r\ndst->extent.truncate_seq =\r\ncpu_to_le32(src->extent.truncate_seq);\r\nbreak;\r\ncase CEPH_OSD_OP_GETXATTR:\r\ncase CEPH_OSD_OP_SETXATTR:\r\ncase CEPH_OSD_OP_CMPXATTR:\r\nBUG_ON(!req->r_trail);\r\ndst->xattr.name_len = cpu_to_le32(src->xattr.name_len);\r\ndst->xattr.value_len = cpu_to_le32(src->xattr.value_len);\r\ndst->xattr.cmp_op = src->xattr.cmp_op;\r\ndst->xattr.cmp_mode = src->xattr.cmp_mode;\r\nceph_pagelist_append(req->r_trail, src->xattr.name,\r\nsrc->xattr.name_len);\r\nceph_pagelist_append(req->r_trail, src->xattr.val,\r\nsrc->xattr.value_len);\r\nbreak;\r\ncase CEPH_OSD_OP_CALL:\r\nBUG_ON(!req->r_trail);\r\ndst->cls.class_len = src->cls.class_len;\r\ndst->cls.method_len = src->cls.method_len;\r\ndst->cls.indata_len = cpu_to_le32(src->cls.indata_len);\r\nceph_pagelist_append(req->r_trail, src->cls.class_name,\r\nsrc->cls.class_len);\r\nceph_pagelist_append(req->r_trail, src->cls.method_name,\r\nsrc->cls.method_len);\r\nceph_pagelist_append(req->r_trail, src->cls.indata,\r\nsrc->cls.indata_len);\r\nbreak;\r\ncase CEPH_OSD_OP_ROLLBACK:\r\ndst->snap.snapid = cpu_to_le64(src->snap.snapid);\r\nbreak;\r\ncase CEPH_OSD_OP_STARTSYNC:\r\nbreak;\r\ncase CEPH_OSD_OP_NOTIFY:\r\n{\r\n__le32 prot_ver = cpu_to_le32(src->watch.prot_ver);\r\n__le32 timeout = cpu_to_le32(src->watch.timeout);\r\nBUG_ON(!req->r_trail);\r\nceph_pagelist_append(req->r_trail,\r\n&prot_ver, sizeof(prot_ver));\r\nceph_pagelist_append(req->r_trail,\r\n&timeout, sizeof(timeout));\r\n}\r\ncase CEPH_OSD_OP_NOTIFY_ACK:\r\ncase CEPH_OSD_OP_WATCH:\r\ndst->watch.cookie = cpu_to_le64(src->watch.cookie);\r\ndst->watch.ver = cpu_to_le64(src->watch.ver);\r\ndst->watch.flag = src->watch.flag;\r\nbreak;\r\ndefault:\r\npr_err("unrecognized osd opcode %d\n", dst->op);\r\nWARN_ON(1);\r\nbreak;\r\n}\r\ndst->payload_len = cpu_to_le32(src->payload_len);\r\n}\r\nvoid ceph_osdc_build_request(struct ceph_osd_request *req,\r\nu64 off, u64 *plen,\r\nstruct ceph_osd_req_op *src_ops,\r\nstruct ceph_snap_context *snapc,\r\nstruct timespec *mtime,\r\nconst char *oid,\r\nint oid_len)\r\n{\r\nstruct ceph_msg *msg = req->r_request;\r\nstruct ceph_osd_request_head *head;\r\nstruct ceph_osd_req_op *src_op;\r\nstruct ceph_osd_op *op;\r\nvoid *p;\r\nint num_op = get_num_ops(src_ops, NULL);\r\nsize_t msg_size = sizeof(*head) + num_op*sizeof(*op);\r\nint flags = req->r_flags;\r\nu64 data_len = 0;\r\nint i;\r\nhead = msg->front.iov_base;\r\nop = (void *)(head + 1);\r\np = (void *)(op + num_op);\r\nreq->r_snapc = ceph_get_snap_context(snapc);\r\nhead->client_inc = cpu_to_le32(1);\r\nhead->flags = cpu_to_le32(flags);\r\nif (flags & CEPH_OSD_FLAG_WRITE)\r\nceph_encode_timespec(&head->mtime, mtime);\r\nhead->num_ops = cpu_to_le16(num_op);\r\nhead->object_len = cpu_to_le32(oid_len);\r\nmemcpy(p, oid, oid_len);\r\np += oid_len;\r\nsrc_op = src_ops;\r\nwhile (src_op->op) {\r\nosd_req_encode_op(req, op, src_op);\r\nsrc_op++;\r\nop++;\r\n}\r\nif (req->r_trail)\r\ndata_len += req->r_trail->length;\r\nif (snapc) {\r\nhead->snap_seq = cpu_to_le64(snapc->seq);\r\nhead->num_snaps = cpu_to_le32(snapc->num_snaps);\r\nfor (i = 0; i < snapc->num_snaps; i++) {\r\nput_unaligned_le64(snapc->snaps[i], p);\r\np += sizeof(u64);\r\n}\r\n}\r\nif (flags & CEPH_OSD_FLAG_WRITE) {\r\nreq->r_request->hdr.data_off = cpu_to_le16(off);\r\nreq->r_request->hdr.data_len = cpu_to_le32(*plen + data_len);\r\n} else if (data_len) {\r\nreq->r_request->hdr.data_off = 0;\r\nreq->r_request->hdr.data_len = cpu_to_le32(data_len);\r\n}\r\nreq->r_request->page_alignment = req->r_page_alignment;\r\nBUG_ON(p > msg->front.iov_base + msg->front.iov_len);\r\nmsg_size = p - msg->front.iov_base;\r\nmsg->front.iov_len = msg_size;\r\nmsg->hdr.front_len = cpu_to_le32(msg_size);\r\nreturn;\r\n}\r\nstruct ceph_osd_request *ceph_osdc_new_request(struct ceph_osd_client *osdc,\r\nstruct ceph_file_layout *layout,\r\nstruct ceph_vino vino,\r\nu64 off, u64 *plen,\r\nint opcode, int flags,\r\nstruct ceph_snap_context *snapc,\r\nint do_sync,\r\nu32 truncate_seq,\r\nu64 truncate_size,\r\nstruct timespec *mtime,\r\nbool use_mempool, int num_reply,\r\nint page_align)\r\n{\r\nstruct ceph_osd_req_op ops[3];\r\nstruct ceph_osd_request *req;\r\nops[0].op = opcode;\r\nops[0].extent.truncate_seq = truncate_seq;\r\nops[0].extent.truncate_size = truncate_size;\r\nops[0].payload_len = 0;\r\nif (do_sync) {\r\nops[1].op = CEPH_OSD_OP_STARTSYNC;\r\nops[1].payload_len = 0;\r\nops[2].op = 0;\r\n} else\r\nops[1].op = 0;\r\nreq = ceph_osdc_alloc_request(osdc, flags,\r\nsnapc, ops,\r\nuse_mempool,\r\nGFP_NOFS, NULL, NULL);\r\nif (!req)\r\nreturn NULL;\r\ncalc_layout(osdc, vino, layout, off, plen, req, ops);\r\nreq->r_file_layout = *layout;\r\nreq->r_num_pages = calc_pages_for(page_align, *plen);\r\nreq->r_page_alignment = page_align;\r\nceph_osdc_build_request(req, off, plen, ops,\r\nsnapc,\r\nmtime,\r\nreq->r_oid, req->r_oid_len);\r\nreturn req;\r\n}\r\nstatic void __insert_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *new)\r\n{\r\nstruct rb_node **p = &osdc->requests.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd_request *req = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\nreq = rb_entry(parent, struct ceph_osd_request, r_node);\r\nif (new->r_tid < req->r_tid)\r\np = &(*p)->rb_left;\r\nelse if (new->r_tid > req->r_tid)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->r_node, parent, p);\r\nrb_insert_color(&new->r_node, &osdc->requests);\r\n}\r\nstatic struct ceph_osd_request *__lookup_request(struct ceph_osd_client *osdc,\r\nu64 tid)\r\n{\r\nstruct ceph_osd_request *req;\r\nstruct rb_node *n = osdc->requests.rb_node;\r\nwhile (n) {\r\nreq = rb_entry(n, struct ceph_osd_request, r_node);\r\nif (tid < req->r_tid)\r\nn = n->rb_left;\r\nelse if (tid > req->r_tid)\r\nn = n->rb_right;\r\nelse\r\nreturn req;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct ceph_osd_request *\r\n__lookup_request_ge(struct ceph_osd_client *osdc,\r\nu64 tid)\r\n{\r\nstruct ceph_osd_request *req;\r\nstruct rb_node *n = osdc->requests.rb_node;\r\nwhile (n) {\r\nreq = rb_entry(n, struct ceph_osd_request, r_node);\r\nif (tid < req->r_tid) {\r\nif (!n->rb_left)\r\nreturn req;\r\nn = n->rb_left;\r\n} else if (tid > req->r_tid) {\r\nn = n->rb_right;\r\n} else {\r\nreturn req;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic void __kick_osd_requests(struct ceph_osd_client *osdc,\r\nstruct ceph_osd *osd)\r\n{\r\nstruct ceph_osd_request *req, *nreq;\r\nint err;\r\ndout("__kick_osd_requests osd%d\n", osd->o_osd);\r\nerr = __reset_osd(osdc, osd);\r\nif (err == -EAGAIN)\r\nreturn;\r\nlist_for_each_entry(req, &osd->o_requests, r_osd_item) {\r\nlist_move(&req->r_req_lru_item, &osdc->req_unsent);\r\ndout("requeued %p tid %llu osd%d\n", req, req->r_tid,\r\nosd->o_osd);\r\nif (!req->r_linger)\r\nreq->r_flags |= CEPH_OSD_FLAG_RETRY;\r\n}\r\nlist_for_each_entry_safe(req, nreq, &osd->o_linger_requests,\r\nr_linger_osd) {\r\nBUG_ON(!list_empty(&req->r_req_lru_item));\r\n__register_request(osdc, req);\r\nlist_add(&req->r_req_lru_item, &osdc->req_unsent);\r\nlist_add(&req->r_osd_item, &req->r_osd->o_requests);\r\n__unregister_linger_request(osdc, req);\r\ndout("requeued lingering %p tid %llu osd%d\n", req, req->r_tid,\r\nosd->o_osd);\r\n}\r\n}\r\nstatic void kick_osd_requests(struct ceph_osd_client *osdc,\r\nstruct ceph_osd *kickosd)\r\n{\r\nmutex_lock(&osdc->request_mutex);\r\n__kick_osd_requests(osdc, kickosd);\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nstatic void osd_reset(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nstruct ceph_osd_client *osdc;\r\nif (!osd)\r\nreturn;\r\ndout("osd_reset osd%d\n", osd->o_osd);\r\nosdc = osd->o_osdc;\r\ndown_read(&osdc->map_sem);\r\nkick_osd_requests(osdc, osd);\r\nsend_queued(osdc);\r\nup_read(&osdc->map_sem);\r\n}\r\nstatic struct ceph_osd *create_osd(struct ceph_osd_client *osdc)\r\n{\r\nstruct ceph_osd *osd;\r\nosd = kzalloc(sizeof(*osd), GFP_NOFS);\r\nif (!osd)\r\nreturn NULL;\r\natomic_set(&osd->o_ref, 1);\r\nosd->o_osdc = osdc;\r\nINIT_LIST_HEAD(&osd->o_requests);\r\nINIT_LIST_HEAD(&osd->o_linger_requests);\r\nINIT_LIST_HEAD(&osd->o_osd_lru);\r\nosd->o_incarnation = 1;\r\nceph_con_init(osdc->client->msgr, &osd->o_con);\r\nosd->o_con.private = osd;\r\nosd->o_con.ops = &osd_con_ops;\r\nosd->o_con.peer_name.type = CEPH_ENTITY_TYPE_OSD;\r\nINIT_LIST_HEAD(&osd->o_keepalive_item);\r\nreturn osd;\r\n}\r\nstatic struct ceph_osd *get_osd(struct ceph_osd *osd)\r\n{\r\nif (atomic_inc_not_zero(&osd->o_ref)) {\r\ndout("get_osd %p %d -> %d\n", osd, atomic_read(&osd->o_ref)-1,\r\natomic_read(&osd->o_ref));\r\nreturn osd;\r\n} else {\r\ndout("get_osd %p FAIL\n", osd);\r\nreturn NULL;\r\n}\r\n}\r\nstatic void put_osd(struct ceph_osd *osd)\r\n{\r\ndout("put_osd %p %d -> %d\n", osd, atomic_read(&osd->o_ref),\r\natomic_read(&osd->o_ref) - 1);\r\nif (atomic_dec_and_test(&osd->o_ref)) {\r\nstruct ceph_auth_client *ac = osd->o_osdc->client->monc.auth;\r\nif (osd->o_authorizer)\r\nac->ops->destroy_authorizer(ac, osd->o_authorizer);\r\nkfree(osd);\r\n}\r\n}\r\nstatic void __remove_osd(struct ceph_osd_client *osdc, struct ceph_osd *osd)\r\n{\r\ndout("__remove_osd %p\n", osd);\r\nBUG_ON(!list_empty(&osd->o_requests));\r\nrb_erase(&osd->o_node, &osdc->osds);\r\nlist_del_init(&osd->o_osd_lru);\r\nceph_con_close(&osd->o_con);\r\nput_osd(osd);\r\n}\r\nstatic void remove_all_osds(struct ceph_osd_client *osdc)\r\n{\r\ndout("__remove_old_osds %p\n", osdc);\r\nmutex_lock(&osdc->request_mutex);\r\nwhile (!RB_EMPTY_ROOT(&osdc->osds)) {\r\nstruct ceph_osd *osd = rb_entry(rb_first(&osdc->osds),\r\nstruct ceph_osd, o_node);\r\n__remove_osd(osdc, osd);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nstatic void __move_osd_to_lru(struct ceph_osd_client *osdc,\r\nstruct ceph_osd *osd)\r\n{\r\ndout("__move_osd_to_lru %p\n", osd);\r\nBUG_ON(!list_empty(&osd->o_osd_lru));\r\nlist_add_tail(&osd->o_osd_lru, &osdc->osd_lru);\r\nosd->lru_ttl = jiffies + osdc->client->options->osd_idle_ttl * HZ;\r\n}\r\nstatic void __remove_osd_from_lru(struct ceph_osd *osd)\r\n{\r\ndout("__remove_osd_from_lru %p\n", osd);\r\nif (!list_empty(&osd->o_osd_lru))\r\nlist_del_init(&osd->o_osd_lru);\r\n}\r\nstatic void remove_old_osds(struct ceph_osd_client *osdc)\r\n{\r\nstruct ceph_osd *osd, *nosd;\r\ndout("__remove_old_osds %p\n", osdc);\r\nmutex_lock(&osdc->request_mutex);\r\nlist_for_each_entry_safe(osd, nosd, &osdc->osd_lru, o_osd_lru) {\r\nif (time_before(jiffies, osd->lru_ttl))\r\nbreak;\r\n__remove_osd(osdc, osd);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nstatic int __reset_osd(struct ceph_osd_client *osdc, struct ceph_osd *osd)\r\n{\r\nstruct ceph_osd_request *req;\r\nint ret = 0;\r\ndout("__reset_osd %p osd%d\n", osd, osd->o_osd);\r\nif (list_empty(&osd->o_requests) &&\r\nlist_empty(&osd->o_linger_requests)) {\r\n__remove_osd(osdc, osd);\r\n} else if (memcmp(&osdc->osdmap->osd_addr[osd->o_osd],\r\n&osd->o_con.peer_addr,\r\nsizeof(osd->o_con.peer_addr)) == 0 &&\r\n!ceph_con_opened(&osd->o_con)) {\r\ndout(" osd addr hasn't changed and connection never opened,"\r\n" letting msgr retry");\r\nlist_for_each_entry(req, &osd->o_requests, r_osd_item)\r\nreq->r_stamp = jiffies;\r\nret = -EAGAIN;\r\n} else {\r\nceph_con_close(&osd->o_con);\r\nceph_con_open(&osd->o_con, &osdc->osdmap->osd_addr[osd->o_osd]);\r\nosd->o_incarnation++;\r\n}\r\nreturn ret;\r\n}\r\nstatic void __insert_osd(struct ceph_osd_client *osdc, struct ceph_osd *new)\r\n{\r\nstruct rb_node **p = &osdc->osds.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd *osd = NULL;\r\ndout("__insert_osd %p osd%d\n", new, new->o_osd);\r\nwhile (*p) {\r\nparent = *p;\r\nosd = rb_entry(parent, struct ceph_osd, o_node);\r\nif (new->o_osd < osd->o_osd)\r\np = &(*p)->rb_left;\r\nelse if (new->o_osd > osd->o_osd)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->o_node, parent, p);\r\nrb_insert_color(&new->o_node, &osdc->osds);\r\n}\r\nstatic struct ceph_osd *__lookup_osd(struct ceph_osd_client *osdc, int o)\r\n{\r\nstruct ceph_osd *osd;\r\nstruct rb_node *n = osdc->osds.rb_node;\r\nwhile (n) {\r\nosd = rb_entry(n, struct ceph_osd, o_node);\r\nif (o < osd->o_osd)\r\nn = n->rb_left;\r\nelse if (o > osd->o_osd)\r\nn = n->rb_right;\r\nelse\r\nreturn osd;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void __schedule_osd_timeout(struct ceph_osd_client *osdc)\r\n{\r\nschedule_delayed_work(&osdc->timeout_work,\r\nosdc->client->options->osd_keepalive_timeout * HZ);\r\n}\r\nstatic void __cancel_osd_timeout(struct ceph_osd_client *osdc)\r\n{\r\ncancel_delayed_work(&osdc->timeout_work);\r\n}\r\nstatic void __register_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nreq->r_tid = ++osdc->last_tid;\r\nreq->r_request->hdr.tid = cpu_to_le64(req->r_tid);\r\ndout("__register_request %p tid %lld\n", req, req->r_tid);\r\n__insert_request(osdc, req);\r\nceph_osdc_get_request(req);\r\nosdc->num_requests++;\r\nif (osdc->num_requests == 1) {\r\ndout(" first request, scheduling timeout\n");\r\n__schedule_osd_timeout(osdc);\r\n}\r\n}\r\nstatic void register_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nmutex_lock(&osdc->request_mutex);\r\n__register_request(osdc, req);\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nstatic void __unregister_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\ndout("__unregister_request %p tid %lld\n", req, req->r_tid);\r\nrb_erase(&req->r_node, &osdc->requests);\r\nosdc->num_requests--;\r\nif (req->r_osd) {\r\nceph_con_revoke(&req->r_osd->o_con, req->r_request);\r\nlist_del_init(&req->r_osd_item);\r\nif (list_empty(&req->r_osd->o_requests) &&\r\nlist_empty(&req->r_osd->o_linger_requests)) {\r\ndout("moving osd to %p lru\n", req->r_osd);\r\n__move_osd_to_lru(osdc, req->r_osd);\r\n}\r\nif (list_empty(&req->r_linger_item))\r\nreq->r_osd = NULL;\r\n}\r\nceph_osdc_put_request(req);\r\nlist_del_init(&req->r_req_lru_item);\r\nif (osdc->num_requests == 0) {\r\ndout(" no requests, canceling timeout\n");\r\n__cancel_osd_timeout(osdc);\r\n}\r\n}\r\nstatic void __cancel_request(struct ceph_osd_request *req)\r\n{\r\nif (req->r_sent && req->r_osd) {\r\nceph_con_revoke(&req->r_osd->o_con, req->r_request);\r\nreq->r_sent = 0;\r\n}\r\n}\r\nstatic void __register_linger_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\ndout("__register_linger_request %p\n", req);\r\nlist_add_tail(&req->r_linger_item, &osdc->req_linger);\r\nlist_add_tail(&req->r_linger_osd, &req->r_osd->o_linger_requests);\r\n}\r\nstatic void __unregister_linger_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\ndout("__unregister_linger_request %p\n", req);\r\nif (req->r_osd) {\r\nlist_del_init(&req->r_linger_item);\r\nlist_del_init(&req->r_linger_osd);\r\nif (list_empty(&req->r_osd->o_requests) &&\r\nlist_empty(&req->r_osd->o_linger_requests)) {\r\ndout("moving osd to %p lru\n", req->r_osd);\r\n__move_osd_to_lru(osdc, req->r_osd);\r\n}\r\nif (list_empty(&req->r_osd_item))\r\nreq->r_osd = NULL;\r\n}\r\n}\r\nvoid ceph_osdc_unregister_linger_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nmutex_lock(&osdc->request_mutex);\r\nif (req->r_linger) {\r\n__unregister_linger_request(osdc, req);\r\nceph_osdc_put_request(req);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nvoid ceph_osdc_set_request_linger(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nif (!req->r_linger) {\r\ndout("set_request_linger %p\n", req);\r\nreq->r_linger = 1;\r\nceph_osdc_get_request(req);\r\n}\r\n}\r\nstatic int __map_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req, int force_resend)\r\n{\r\nstruct ceph_osd_request_head *reqhead = req->r_request->front.iov_base;\r\nstruct ceph_pg pgid;\r\nint acting[CEPH_PG_MAX_SIZE];\r\nint o = -1, num = 0;\r\nint err;\r\ndout("map_request %p tid %lld\n", req, req->r_tid);\r\nerr = ceph_calc_object_layout(&reqhead->layout, req->r_oid,\r\n&req->r_file_layout, osdc->osdmap);\r\nif (err) {\r\nlist_move(&req->r_req_lru_item, &osdc->req_notarget);\r\nreturn err;\r\n}\r\npgid = reqhead->layout.ol_pgid;\r\nreq->r_pgid = pgid;\r\nerr = ceph_calc_pg_acting(osdc->osdmap, pgid, acting);\r\nif (err > 0) {\r\no = acting[0];\r\nnum = err;\r\n}\r\nif ((!force_resend &&\r\nreq->r_osd && req->r_osd->o_osd == o &&\r\nreq->r_sent >= req->r_osd->o_incarnation &&\r\nreq->r_num_pg_osds == num &&\r\nmemcmp(req->r_pg_osds, acting, sizeof(acting[0])*num) == 0) ||\r\n(req->r_osd == NULL && o == -1))\r\nreturn 0;\r\ndout("map_request tid %llu pgid %d.%x osd%d (was osd%d)\n",\r\nreq->r_tid, le32_to_cpu(pgid.pool), le16_to_cpu(pgid.ps), o,\r\nreq->r_osd ? req->r_osd->o_osd : -1);\r\nmemcpy(req->r_pg_osds, acting, sizeof(acting[0]) * num);\r\nreq->r_num_pg_osds = num;\r\nif (req->r_osd) {\r\n__cancel_request(req);\r\nlist_del_init(&req->r_osd_item);\r\nreq->r_osd = NULL;\r\n}\r\nreq->r_osd = __lookup_osd(osdc, o);\r\nif (!req->r_osd && o >= 0) {\r\nerr = -ENOMEM;\r\nreq->r_osd = create_osd(osdc);\r\nif (!req->r_osd) {\r\nlist_move(&req->r_req_lru_item, &osdc->req_notarget);\r\ngoto out;\r\n}\r\ndout("map_request osd %p is osd%d\n", req->r_osd, o);\r\nreq->r_osd->o_osd = o;\r\nreq->r_osd->o_con.peer_name.num = cpu_to_le64(o);\r\n__insert_osd(osdc, req->r_osd);\r\nceph_con_open(&req->r_osd->o_con, &osdc->osdmap->osd_addr[o]);\r\n}\r\nif (req->r_osd) {\r\n__remove_osd_from_lru(req->r_osd);\r\nlist_add(&req->r_osd_item, &req->r_osd->o_requests);\r\nlist_move(&req->r_req_lru_item, &osdc->req_unsent);\r\n} else {\r\nlist_move(&req->r_req_lru_item, &osdc->req_notarget);\r\n}\r\nerr = 1;\r\nout:\r\nreturn err;\r\n}\r\nstatic void __send_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nstruct ceph_osd_request_head *reqhead;\r\ndout("send_request %p tid %llu to osd%d flags %d\n",\r\nreq, req->r_tid, req->r_osd->o_osd, req->r_flags);\r\nreqhead = req->r_request->front.iov_base;\r\nreqhead->osdmap_epoch = cpu_to_le32(osdc->osdmap->epoch);\r\nreqhead->flags |= cpu_to_le32(req->r_flags);\r\nreqhead->reassert_version = req->r_reassert_version;\r\nreq->r_stamp = jiffies;\r\nlist_move_tail(&req->r_req_lru_item, &osdc->req_lru);\r\nceph_msg_get(req->r_request);\r\nceph_con_send(&req->r_osd->o_con, req->r_request);\r\nreq->r_sent = req->r_osd->o_incarnation;\r\n}\r\nstatic void send_queued(struct ceph_osd_client *osdc)\r\n{\r\nstruct ceph_osd_request *req, *tmp;\r\ndout("send_queued\n");\r\nmutex_lock(&osdc->request_mutex);\r\nlist_for_each_entry_safe(req, tmp, &osdc->req_unsent, r_req_lru_item) {\r\n__send_request(osdc, req);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nstatic void handle_timeout(struct work_struct *work)\r\n{\r\nstruct ceph_osd_client *osdc =\r\ncontainer_of(work, struct ceph_osd_client, timeout_work.work);\r\nstruct ceph_osd_request *req, *last_req = NULL;\r\nstruct ceph_osd *osd;\r\nunsigned long timeout = osdc->client->options->osd_timeout * HZ;\r\nunsigned long keepalive =\r\nosdc->client->options->osd_keepalive_timeout * HZ;\r\nunsigned long last_stamp = 0;\r\nstruct list_head slow_osds;\r\ndout("timeout\n");\r\ndown_read(&osdc->map_sem);\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\nmutex_lock(&osdc->request_mutex);\r\nwhile (timeout && !list_empty(&osdc->req_lru)) {\r\nreq = list_entry(osdc->req_lru.next, struct ceph_osd_request,\r\nr_req_lru_item);\r\nif (time_before(jiffies, req->r_stamp + timeout))\r\nbreak;\r\nif (req->r_request->ack_stamp == 0 ||\r\ntime_before(jiffies, req->r_request->ack_stamp + timeout))\r\nbreak;\r\nBUG_ON(req == last_req && req->r_stamp == last_stamp);\r\nlast_req = req;\r\nlast_stamp = req->r_stamp;\r\nosd = req->r_osd;\r\nBUG_ON(!osd);\r\npr_warning(" tid %llu timed out on osd%d, will reset osd\n",\r\nreq->r_tid, osd->o_osd);\r\n__kick_osd_requests(osdc, osd);\r\n}\r\nINIT_LIST_HEAD(&slow_osds);\r\nlist_for_each_entry(req, &osdc->req_lru, r_req_lru_item) {\r\nif (time_before(jiffies, req->r_stamp + keepalive))\r\nbreak;\r\nosd = req->r_osd;\r\nBUG_ON(!osd);\r\ndout(" tid %llu is slow, will send keepalive on osd%d\n",\r\nreq->r_tid, osd->o_osd);\r\nlist_move_tail(&osd->o_keepalive_item, &slow_osds);\r\n}\r\nwhile (!list_empty(&slow_osds)) {\r\nosd = list_entry(slow_osds.next, struct ceph_osd,\r\no_keepalive_item);\r\nlist_del_init(&osd->o_keepalive_item);\r\nceph_con_keepalive(&osd->o_con);\r\n}\r\n__schedule_osd_timeout(osdc);\r\nmutex_unlock(&osdc->request_mutex);\r\nsend_queued(osdc);\r\nup_read(&osdc->map_sem);\r\n}\r\nstatic void handle_osds_timeout(struct work_struct *work)\r\n{\r\nstruct ceph_osd_client *osdc =\r\ncontainer_of(work, struct ceph_osd_client,\r\nosds_timeout_work.work);\r\nunsigned long delay =\r\nosdc->client->options->osd_idle_ttl * HZ >> 2;\r\ndout("osds timeout\n");\r\ndown_read(&osdc->map_sem);\r\nremove_old_osds(osdc);\r\nup_read(&osdc->map_sem);\r\nschedule_delayed_work(&osdc->osds_timeout_work,\r\nround_jiffies_relative(delay));\r\n}\r\nstatic void complete_request(struct ceph_osd_request *req)\r\n{\r\nif (req->r_safe_callback)\r\nreq->r_safe_callback(req, NULL);\r\ncomplete_all(&req->r_safe_completion);\r\n}\r\nstatic void handle_reply(struct ceph_osd_client *osdc, struct ceph_msg *msg,\r\nstruct ceph_connection *con)\r\n{\r\nstruct ceph_osd_reply_head *rhead = msg->front.iov_base;\r\nstruct ceph_osd_request *req;\r\nu64 tid;\r\nint numops, object_len, flags;\r\ns32 result;\r\ntid = le64_to_cpu(msg->hdr.tid);\r\nif (msg->front.iov_len < sizeof(*rhead))\r\ngoto bad;\r\nnumops = le32_to_cpu(rhead->num_ops);\r\nobject_len = le32_to_cpu(rhead->object_len);\r\nresult = le32_to_cpu(rhead->result);\r\nif (msg->front.iov_len != sizeof(*rhead) + object_len +\r\nnumops * sizeof(struct ceph_osd_op))\r\ngoto bad;\r\ndout("handle_reply %p tid %llu result %d\n", msg, tid, (int)result);\r\nmutex_lock(&osdc->request_mutex);\r\nreq = __lookup_request(osdc, tid);\r\nif (req == NULL) {\r\ndout("handle_reply tid %llu dne\n", tid);\r\nmutex_unlock(&osdc->request_mutex);\r\nreturn;\r\n}\r\nceph_osdc_get_request(req);\r\nflags = le32_to_cpu(rhead->flags);\r\nif (req->r_con_filling_msg == con && req->r_reply == msg) {\r\ndout(" dropping con_filling_msg ref %p\n", con);\r\nreq->r_con_filling_msg = NULL;\r\nceph_con_put(con);\r\n}\r\nif (!req->r_got_reply) {\r\nunsigned bytes;\r\nreq->r_result = le32_to_cpu(rhead->result);\r\nbytes = le32_to_cpu(msg->hdr.data_len);\r\ndout("handle_reply result %d bytes %d\n", req->r_result,\r\nbytes);\r\nif (req->r_result == 0)\r\nreq->r_result = bytes;\r\nreq->r_reassert_version = rhead->reassert_version;\r\nreq->r_got_reply = 1;\r\n} else if ((flags & CEPH_OSD_FLAG_ONDISK) == 0) {\r\ndout("handle_reply tid %llu dup ack\n", tid);\r\nmutex_unlock(&osdc->request_mutex);\r\ngoto done;\r\n}\r\ndout("handle_reply tid %llu flags %d\n", tid, flags);\r\nif (req->r_linger && (flags & CEPH_OSD_FLAG_ONDISK))\r\n__register_linger_request(osdc, req);\r\nif (result < 0 ||\r\n(flags & CEPH_OSD_FLAG_ONDISK) ||\r\n((flags & CEPH_OSD_FLAG_WRITE) == 0))\r\n__unregister_request(osdc, req);\r\nmutex_unlock(&osdc->request_mutex);\r\nif (req->r_callback)\r\nreq->r_callback(req, msg);\r\nelse\r\ncomplete_all(&req->r_completion);\r\nif (flags & CEPH_OSD_FLAG_ONDISK)\r\ncomplete_request(req);\r\ndone:\r\ndout("req=%p req->r_linger=%d\n", req, req->r_linger);\r\nceph_osdc_put_request(req);\r\nreturn;\r\nbad:\r\npr_err("corrupt osd_op_reply got %d %d expected %d\n",\r\n(int)msg->front.iov_len, le32_to_cpu(msg->hdr.front_len),\r\n(int)sizeof(*rhead));\r\nceph_msg_dump(msg);\r\n}\r\nstatic void reset_changed_osds(struct ceph_osd_client *osdc)\r\n{\r\nstruct rb_node *p, *n;\r\nfor (p = rb_first(&osdc->osds); p; p = n) {\r\nstruct ceph_osd *osd = rb_entry(p, struct ceph_osd, o_node);\r\nn = rb_next(p);\r\nif (!ceph_osd_is_up(osdc->osdmap, osd->o_osd) ||\r\nmemcmp(&osd->o_con.peer_addr,\r\nceph_osd_addr(osdc->osdmap,\r\nosd->o_osd),\r\nsizeof(struct ceph_entity_addr)) != 0)\r\n__reset_osd(osdc, osd);\r\n}\r\n}\r\nstatic void kick_requests(struct ceph_osd_client *osdc, int force_resend)\r\n{\r\nstruct ceph_osd_request *req, *nreq;\r\nstruct rb_node *p;\r\nint needmap = 0;\r\nint err;\r\ndout("kick_requests %s\n", force_resend ? " (force resend)" : "");\r\nmutex_lock(&osdc->request_mutex);\r\nfor (p = rb_first(&osdc->requests); p; p = rb_next(p)) {\r\nreq = rb_entry(p, struct ceph_osd_request, r_node);\r\nerr = __map_request(osdc, req, force_resend);\r\nif (err < 0)\r\ncontinue;\r\nif (req->r_osd == NULL) {\r\ndout("%p tid %llu maps to no osd\n", req, req->r_tid);\r\nneedmap++;\r\n} else if (err > 0) {\r\ndout("%p tid %llu requeued on osd%d\n", req, req->r_tid,\r\nreq->r_osd ? req->r_osd->o_osd : -1);\r\nif (!req->r_linger)\r\nreq->r_flags |= CEPH_OSD_FLAG_RETRY;\r\n}\r\n}\r\nlist_for_each_entry_safe(req, nreq, &osdc->req_linger,\r\nr_linger_item) {\r\ndout("linger req=%p req->r_osd=%p\n", req, req->r_osd);\r\nerr = __map_request(osdc, req, force_resend);\r\nif (err == 0)\r\ncontinue;\r\nif (err < 0)\r\ncontinue;\r\nif (req->r_osd == NULL) {\r\ndout("tid %llu maps to no valid osd\n", req->r_tid);\r\nneedmap++;\r\ncontinue;\r\n}\r\ndout("kicking lingering %p tid %llu osd%d\n", req, req->r_tid,\r\nreq->r_osd ? req->r_osd->o_osd : -1);\r\n__unregister_linger_request(osdc, req);\r\n__register_request(osdc, req);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\nif (needmap) {\r\ndout("%d requests for down osds, need new map\n", needmap);\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\n}\r\n}\r\nvoid ceph_osdc_handle_map(struct ceph_osd_client *osdc, struct ceph_msg *msg)\r\n{\r\nvoid *p, *end, *next;\r\nu32 nr_maps, maplen;\r\nu32 epoch;\r\nstruct ceph_osdmap *newmap = NULL, *oldmap;\r\nint err;\r\nstruct ceph_fsid fsid;\r\ndout("handle_map have %u\n", osdc->osdmap ? osdc->osdmap->epoch : 0);\r\np = msg->front.iov_base;\r\nend = p + msg->front.iov_len;\r\nceph_decode_need(&p, end, sizeof(fsid), bad);\r\nceph_decode_copy(&p, &fsid, sizeof(fsid));\r\nif (ceph_check_fsid(osdc->client, &fsid) < 0)\r\nreturn;\r\ndown_write(&osdc->map_sem);\r\nceph_decode_32_safe(&p, end, nr_maps, bad);\r\ndout(" %d inc maps\n", nr_maps);\r\nwhile (nr_maps > 0) {\r\nceph_decode_need(&p, end, 2*sizeof(u32), bad);\r\nepoch = ceph_decode_32(&p);\r\nmaplen = ceph_decode_32(&p);\r\nceph_decode_need(&p, end, maplen, bad);\r\nnext = p + maplen;\r\nif (osdc->osdmap && osdc->osdmap->epoch+1 == epoch) {\r\ndout("applying incremental map %u len %d\n",\r\nepoch, maplen);\r\nnewmap = osdmap_apply_incremental(&p, next,\r\nosdc->osdmap,\r\nosdc->client->msgr);\r\nif (IS_ERR(newmap)) {\r\nerr = PTR_ERR(newmap);\r\ngoto bad;\r\n}\r\nBUG_ON(!newmap);\r\nif (newmap != osdc->osdmap) {\r\nceph_osdmap_destroy(osdc->osdmap);\r\nosdc->osdmap = newmap;\r\n}\r\nkick_requests(osdc, 0);\r\nreset_changed_osds(osdc);\r\n} else {\r\ndout("ignoring incremental map %u len %d\n",\r\nepoch, maplen);\r\n}\r\np = next;\r\nnr_maps--;\r\n}\r\nif (newmap)\r\ngoto done;\r\nceph_decode_32_safe(&p, end, nr_maps, bad);\r\ndout(" %d full maps\n", nr_maps);\r\nwhile (nr_maps) {\r\nceph_decode_need(&p, end, 2*sizeof(u32), bad);\r\nepoch = ceph_decode_32(&p);\r\nmaplen = ceph_decode_32(&p);\r\nceph_decode_need(&p, end, maplen, bad);\r\nif (nr_maps > 1) {\r\ndout("skipping non-latest full map %u len %d\n",\r\nepoch, maplen);\r\n} else if (osdc->osdmap && osdc->osdmap->epoch >= epoch) {\r\ndout("skipping full map %u len %d, "\r\n"older than our %u\n", epoch, maplen,\r\nosdc->osdmap->epoch);\r\n} else {\r\nint skipped_map = 0;\r\ndout("taking full map %u len %d\n", epoch, maplen);\r\nnewmap = osdmap_decode(&p, p+maplen);\r\nif (IS_ERR(newmap)) {\r\nerr = PTR_ERR(newmap);\r\ngoto bad;\r\n}\r\nBUG_ON(!newmap);\r\noldmap = osdc->osdmap;\r\nosdc->osdmap = newmap;\r\nif (oldmap) {\r\nif (oldmap->epoch + 1 < newmap->epoch)\r\nskipped_map = 1;\r\nceph_osdmap_destroy(oldmap);\r\n}\r\nkick_requests(osdc, skipped_map);\r\n}\r\np += maplen;\r\nnr_maps--;\r\n}\r\ndone:\r\ndowngrade_write(&osdc->map_sem);\r\nceph_monc_got_osdmap(&osdc->client->monc, osdc->osdmap->epoch);\r\nif (ceph_osdmap_flag(osdc->osdmap, CEPH_OSDMAP_FULL))\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\nsend_queued(osdc);\r\nup_read(&osdc->map_sem);\r\nwake_up_all(&osdc->client->auth_wq);\r\nreturn;\r\nbad:\r\npr_err("osdc handle_map corrupt msg\n");\r\nceph_msg_dump(msg);\r\nup_write(&osdc->map_sem);\r\nreturn;\r\n}\r\nstatic void __release_event(struct kref *kref)\r\n{\r\nstruct ceph_osd_event *event =\r\ncontainer_of(kref, struct ceph_osd_event, kref);\r\ndout("__release_event %p\n", event);\r\nkfree(event);\r\n}\r\nstatic void get_event(struct ceph_osd_event *event)\r\n{\r\nkref_get(&event->kref);\r\n}\r\nvoid ceph_osdc_put_event(struct ceph_osd_event *event)\r\n{\r\nkref_put(&event->kref, __release_event);\r\n}\r\nstatic void __insert_event(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_event *new)\r\n{\r\nstruct rb_node **p = &osdc->event_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd_event *event = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\nevent = rb_entry(parent, struct ceph_osd_event, node);\r\nif (new->cookie < event->cookie)\r\np = &(*p)->rb_left;\r\nelse if (new->cookie > event->cookie)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, &osdc->event_tree);\r\n}\r\nstatic struct ceph_osd_event *__find_event(struct ceph_osd_client *osdc,\r\nu64 cookie)\r\n{\r\nstruct rb_node **p = &osdc->event_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd_event *event = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\nevent = rb_entry(parent, struct ceph_osd_event, node);\r\nif (cookie < event->cookie)\r\np = &(*p)->rb_left;\r\nelse if (cookie > event->cookie)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn event;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void __remove_event(struct ceph_osd_event *event)\r\n{\r\nstruct ceph_osd_client *osdc = event->osdc;\r\nif (!RB_EMPTY_NODE(&event->node)) {\r\ndout("__remove_event removed %p\n", event);\r\nrb_erase(&event->node, &osdc->event_tree);\r\nceph_osdc_put_event(event);\r\n} else {\r\ndout("__remove_event didn't remove %p\n", event);\r\n}\r\n}\r\nint ceph_osdc_create_event(struct ceph_osd_client *osdc,\r\nvoid (*event_cb)(u64, u64, u8, void *),\r\nint one_shot, void *data,\r\nstruct ceph_osd_event **pevent)\r\n{\r\nstruct ceph_osd_event *event;\r\nevent = kmalloc(sizeof(*event), GFP_NOIO);\r\nif (!event)\r\nreturn -ENOMEM;\r\ndout("create_event %p\n", event);\r\nevent->cb = event_cb;\r\nevent->one_shot = one_shot;\r\nevent->data = data;\r\nevent->osdc = osdc;\r\nINIT_LIST_HEAD(&event->osd_node);\r\nkref_init(&event->kref);\r\nkref_get(&event->kref);\r\ninit_completion(&event->completion);\r\nspin_lock(&osdc->event_lock);\r\nevent->cookie = ++osdc->event_count;\r\n__insert_event(osdc, event);\r\nspin_unlock(&osdc->event_lock);\r\n*pevent = event;\r\nreturn 0;\r\n}\r\nvoid ceph_osdc_cancel_event(struct ceph_osd_event *event)\r\n{\r\nstruct ceph_osd_client *osdc = event->osdc;\r\ndout("cancel_event %p\n", event);\r\nspin_lock(&osdc->event_lock);\r\n__remove_event(event);\r\nspin_unlock(&osdc->event_lock);\r\nceph_osdc_put_event(event);\r\n}\r\nstatic void do_event_work(struct work_struct *work)\r\n{\r\nstruct ceph_osd_event_work *event_work =\r\ncontainer_of(work, struct ceph_osd_event_work, work);\r\nstruct ceph_osd_event *event = event_work->event;\r\nu64 ver = event_work->ver;\r\nu64 notify_id = event_work->notify_id;\r\nu8 opcode = event_work->opcode;\r\ndout("do_event_work completing %p\n", event);\r\nevent->cb(ver, notify_id, opcode, event->data);\r\ncomplete(&event->completion);\r\ndout("do_event_work completed %p\n", event);\r\nceph_osdc_put_event(event);\r\nkfree(event_work);\r\n}\r\nvoid handle_watch_notify(struct ceph_osd_client *osdc, struct ceph_msg *msg)\r\n{\r\nvoid *p, *end;\r\nu8 proto_ver;\r\nu64 cookie, ver, notify_id;\r\nu8 opcode;\r\nstruct ceph_osd_event *event;\r\nstruct ceph_osd_event_work *event_work;\r\np = msg->front.iov_base;\r\nend = p + msg->front.iov_len;\r\nceph_decode_8_safe(&p, end, proto_ver, bad);\r\nceph_decode_8_safe(&p, end, opcode, bad);\r\nceph_decode_64_safe(&p, end, cookie, bad);\r\nceph_decode_64_safe(&p, end, ver, bad);\r\nceph_decode_64_safe(&p, end, notify_id, bad);\r\nspin_lock(&osdc->event_lock);\r\nevent = __find_event(osdc, cookie);\r\nif (event) {\r\nget_event(event);\r\nif (event->one_shot)\r\n__remove_event(event);\r\n}\r\nspin_unlock(&osdc->event_lock);\r\ndout("handle_watch_notify cookie %lld ver %lld event %p\n",\r\ncookie, ver, event);\r\nif (event) {\r\nevent_work = kmalloc(sizeof(*event_work), GFP_NOIO);\r\nif (!event_work) {\r\ndout("ERROR: could not allocate event_work\n");\r\ngoto done_err;\r\n}\r\nINIT_WORK(&event_work->work, do_event_work);\r\nevent_work->event = event;\r\nevent_work->ver = ver;\r\nevent_work->notify_id = notify_id;\r\nevent_work->opcode = opcode;\r\nif (!queue_work(osdc->notify_wq, &event_work->work)) {\r\ndout("WARNING: failed to queue notify event work\n");\r\ngoto done_err;\r\n}\r\n}\r\nreturn;\r\ndone_err:\r\ncomplete(&event->completion);\r\nceph_osdc_put_event(event);\r\nreturn;\r\nbad:\r\npr_err("osdc handle_watch_notify corrupt msg\n");\r\nreturn;\r\n}\r\nint ceph_osdc_wait_event(struct ceph_osd_event *event, unsigned long timeout)\r\n{\r\nint err;\r\ndout("wait_event %p\n", event);\r\nerr = wait_for_completion_interruptible_timeout(&event->completion,\r\ntimeout * HZ);\r\nceph_osdc_put_event(event);\r\nif (err > 0)\r\nerr = 0;\r\ndout("wait_event %p returns %d\n", event, err);\r\nreturn err;\r\n}\r\nint ceph_osdc_start_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req,\r\nbool nofail)\r\n{\r\nint rc = 0;\r\nreq->r_request->pages = req->r_pages;\r\nreq->r_request->nr_pages = req->r_num_pages;\r\n#ifdef CONFIG_BLOCK\r\nreq->r_request->bio = req->r_bio;\r\n#endif\r\nreq->r_request->trail = req->r_trail;\r\nregister_request(osdc, req);\r\ndown_read(&osdc->map_sem);\r\nmutex_lock(&osdc->request_mutex);\r\nif (req->r_sent == 0) {\r\nrc = __map_request(osdc, req, 0);\r\nif (rc < 0) {\r\nif (nofail) {\r\ndout("osdc_start_request failed map, "\r\n" will retry %lld\n", req->r_tid);\r\nrc = 0;\r\n}\r\ngoto out_unlock;\r\n}\r\nif (req->r_osd == NULL) {\r\ndout("send_request %p no up osds in pg\n", req);\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\n} else {\r\n__send_request(osdc, req);\r\n}\r\nrc = 0;\r\n}\r\nout_unlock:\r\nmutex_unlock(&osdc->request_mutex);\r\nup_read(&osdc->map_sem);\r\nreturn rc;\r\n}\r\nint ceph_osdc_wait_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nint rc;\r\nrc = wait_for_completion_interruptible(&req->r_completion);\r\nif (rc < 0) {\r\nmutex_lock(&osdc->request_mutex);\r\n__cancel_request(req);\r\n__unregister_request(osdc, req);\r\nmutex_unlock(&osdc->request_mutex);\r\ncomplete_request(req);\r\ndout("wait_request tid %llu canceled/timed out\n", req->r_tid);\r\nreturn rc;\r\n}\r\ndout("wait_request tid %llu result %d\n", req->r_tid, req->r_result);\r\nreturn req->r_result;\r\n}\r\nvoid ceph_osdc_sync(struct ceph_osd_client *osdc)\r\n{\r\nstruct ceph_osd_request *req;\r\nu64 last_tid, next_tid = 0;\r\nmutex_lock(&osdc->request_mutex);\r\nlast_tid = osdc->last_tid;\r\nwhile (1) {\r\nreq = __lookup_request_ge(osdc, next_tid);\r\nif (!req)\r\nbreak;\r\nif (req->r_tid > last_tid)\r\nbreak;\r\nnext_tid = req->r_tid + 1;\r\nif ((req->r_flags & CEPH_OSD_FLAG_WRITE) == 0)\r\ncontinue;\r\nceph_osdc_get_request(req);\r\nmutex_unlock(&osdc->request_mutex);\r\ndout("sync waiting on tid %llu (last is %llu)\n",\r\nreq->r_tid, last_tid);\r\nwait_for_completion(&req->r_safe_completion);\r\nmutex_lock(&osdc->request_mutex);\r\nceph_osdc_put_request(req);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\ndout("sync done (thru tid %llu)\n", last_tid);\r\n}\r\nint ceph_osdc_init(struct ceph_osd_client *osdc, struct ceph_client *client)\r\n{\r\nint err;\r\ndout("init\n");\r\nosdc->client = client;\r\nosdc->osdmap = NULL;\r\ninit_rwsem(&osdc->map_sem);\r\ninit_completion(&osdc->map_waiters);\r\nosdc->last_requested_map = 0;\r\nmutex_init(&osdc->request_mutex);\r\nosdc->last_tid = 0;\r\nosdc->osds = RB_ROOT;\r\nINIT_LIST_HEAD(&osdc->osd_lru);\r\nosdc->requests = RB_ROOT;\r\nINIT_LIST_HEAD(&osdc->req_lru);\r\nINIT_LIST_HEAD(&osdc->req_unsent);\r\nINIT_LIST_HEAD(&osdc->req_notarget);\r\nINIT_LIST_HEAD(&osdc->req_linger);\r\nosdc->num_requests = 0;\r\nINIT_DELAYED_WORK(&osdc->timeout_work, handle_timeout);\r\nINIT_DELAYED_WORK(&osdc->osds_timeout_work, handle_osds_timeout);\r\nspin_lock_init(&osdc->event_lock);\r\nosdc->event_tree = RB_ROOT;\r\nosdc->event_count = 0;\r\nschedule_delayed_work(&osdc->osds_timeout_work,\r\nround_jiffies_relative(osdc->client->options->osd_idle_ttl * HZ));\r\nerr = -ENOMEM;\r\nosdc->req_mempool = mempool_create_kmalloc_pool(10,\r\nsizeof(struct ceph_osd_request));\r\nif (!osdc->req_mempool)\r\ngoto out;\r\nerr = ceph_msgpool_init(&osdc->msgpool_op, OSD_OP_FRONT_LEN, 10, true,\r\n"osd_op");\r\nif (err < 0)\r\ngoto out_mempool;\r\nerr = ceph_msgpool_init(&osdc->msgpool_op_reply,\r\nOSD_OPREPLY_FRONT_LEN, 10, true,\r\n"osd_op_reply");\r\nif (err < 0)\r\ngoto out_msgpool;\r\nosdc->notify_wq = create_singlethread_workqueue("ceph-watch-notify");\r\nif (IS_ERR(osdc->notify_wq)) {\r\nerr = PTR_ERR(osdc->notify_wq);\r\nosdc->notify_wq = NULL;\r\ngoto out_msgpool;\r\n}\r\nreturn 0;\r\nout_msgpool:\r\nceph_msgpool_destroy(&osdc->msgpool_op);\r\nout_mempool:\r\nmempool_destroy(osdc->req_mempool);\r\nout:\r\nreturn err;\r\n}\r\nvoid ceph_osdc_stop(struct ceph_osd_client *osdc)\r\n{\r\nflush_workqueue(osdc->notify_wq);\r\ndestroy_workqueue(osdc->notify_wq);\r\ncancel_delayed_work_sync(&osdc->timeout_work);\r\ncancel_delayed_work_sync(&osdc->osds_timeout_work);\r\nif (osdc->osdmap) {\r\nceph_osdmap_destroy(osdc->osdmap);\r\nosdc->osdmap = NULL;\r\n}\r\nremove_all_osds(osdc);\r\nmempool_destroy(osdc->req_mempool);\r\nceph_msgpool_destroy(&osdc->msgpool_op);\r\nceph_msgpool_destroy(&osdc->msgpool_op_reply);\r\n}\r\nint ceph_osdc_readpages(struct ceph_osd_client *osdc,\r\nstruct ceph_vino vino, struct ceph_file_layout *layout,\r\nu64 off, u64 *plen,\r\nu32 truncate_seq, u64 truncate_size,\r\nstruct page **pages, int num_pages, int page_align)\r\n{\r\nstruct ceph_osd_request *req;\r\nint rc = 0;\r\ndout("readpages on ino %llx.%llx on %llu~%llu\n", vino.ino,\r\nvino.snap, off, *plen);\r\nreq = ceph_osdc_new_request(osdc, layout, vino, off, plen,\r\nCEPH_OSD_OP_READ, CEPH_OSD_FLAG_READ,\r\nNULL, 0, truncate_seq, truncate_size, NULL,\r\nfalse, 1, page_align);\r\nif (!req)\r\nreturn -ENOMEM;\r\nreq->r_pages = pages;\r\ndout("readpages final extent is %llu~%llu (%d pages align %d)\n",\r\noff, *plen, req->r_num_pages, page_align);\r\nrc = ceph_osdc_start_request(osdc, req, false);\r\nif (!rc)\r\nrc = ceph_osdc_wait_request(osdc, req);\r\nceph_osdc_put_request(req);\r\ndout("readpages result %d\n", rc);\r\nreturn rc;\r\n}\r\nint ceph_osdc_writepages(struct ceph_osd_client *osdc, struct ceph_vino vino,\r\nstruct ceph_file_layout *layout,\r\nstruct ceph_snap_context *snapc,\r\nu64 off, u64 len,\r\nu32 truncate_seq, u64 truncate_size,\r\nstruct timespec *mtime,\r\nstruct page **pages, int num_pages,\r\nint flags, int do_sync, bool nofail)\r\n{\r\nstruct ceph_osd_request *req;\r\nint rc = 0;\r\nint page_align = off & ~PAGE_MASK;\r\nBUG_ON(vino.snap != CEPH_NOSNAP);\r\nreq = ceph_osdc_new_request(osdc, layout, vino, off, &len,\r\nCEPH_OSD_OP_WRITE,\r\nflags | CEPH_OSD_FLAG_ONDISK |\r\nCEPH_OSD_FLAG_WRITE,\r\nsnapc, do_sync,\r\ntruncate_seq, truncate_size, mtime,\r\nnofail, 1, page_align);\r\nif (!req)\r\nreturn -ENOMEM;\r\nreq->r_pages = pages;\r\ndout("writepages %llu~%llu (%d pages)\n", off, len,\r\nreq->r_num_pages);\r\nrc = ceph_osdc_start_request(osdc, req, nofail);\r\nif (!rc)\r\nrc = ceph_osdc_wait_request(osdc, req);\r\nceph_osdc_put_request(req);\r\nif (rc == 0)\r\nrc = len;\r\ndout("writepages result %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic void dispatch(struct ceph_connection *con, struct ceph_msg *msg)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nstruct ceph_osd_client *osdc;\r\nint type = le16_to_cpu(msg->hdr.type);\r\nif (!osd)\r\ngoto out;\r\nosdc = osd->o_osdc;\r\nswitch (type) {\r\ncase CEPH_MSG_OSD_MAP:\r\nceph_osdc_handle_map(osdc, msg);\r\nbreak;\r\ncase CEPH_MSG_OSD_OPREPLY:\r\nhandle_reply(osdc, msg, con);\r\nbreak;\r\ncase CEPH_MSG_WATCH_NOTIFY:\r\nhandle_watch_notify(osdc, msg);\r\nbreak;\r\ndefault:\r\npr_err("received unknown message type %d %s\n", type,\r\nceph_msg_type_name(type));\r\n}\r\nout:\r\nceph_msg_put(msg);\r\n}\r\nstatic struct ceph_msg *get_reply(struct ceph_connection *con,\r\nstruct ceph_msg_header *hdr,\r\nint *skip)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nstruct ceph_osd_client *osdc = osd->o_osdc;\r\nstruct ceph_msg *m;\r\nstruct ceph_osd_request *req;\r\nint front = le32_to_cpu(hdr->front_len);\r\nint data_len = le32_to_cpu(hdr->data_len);\r\nu64 tid;\r\ntid = le64_to_cpu(hdr->tid);\r\nmutex_lock(&osdc->request_mutex);\r\nreq = __lookup_request(osdc, tid);\r\nif (!req) {\r\n*skip = 1;\r\nm = NULL;\r\npr_info("get_reply unknown tid %llu from osd%d\n", tid,\r\nosd->o_osd);\r\ngoto out;\r\n}\r\nif (req->r_con_filling_msg) {\r\ndout("get_reply revoking msg %p from old con %p\n",\r\nreq->r_reply, req->r_con_filling_msg);\r\nceph_con_revoke_message(req->r_con_filling_msg, req->r_reply);\r\nceph_con_put(req->r_con_filling_msg);\r\nreq->r_con_filling_msg = NULL;\r\n}\r\nif (front > req->r_reply->front.iov_len) {\r\npr_warning("get_reply front %d > preallocated %d\n",\r\nfront, (int)req->r_reply->front.iov_len);\r\nm = ceph_msg_new(CEPH_MSG_OSD_OPREPLY, front, GFP_NOFS, false);\r\nif (!m)\r\ngoto out;\r\nceph_msg_put(req->r_reply);\r\nreq->r_reply = m;\r\n}\r\nm = ceph_msg_get(req->r_reply);\r\nif (data_len > 0) {\r\nint want = calc_pages_for(req->r_page_alignment, data_len);\r\nif (unlikely(req->r_num_pages < want)) {\r\npr_warning("tid %lld reply has %d bytes %d pages, we"\r\n" had only %d pages ready\n", tid, data_len,\r\nwant, req->r_num_pages);\r\n*skip = 1;\r\nceph_msg_put(m);\r\nm = NULL;\r\ngoto out;\r\n}\r\nm->pages = req->r_pages;\r\nm->nr_pages = req->r_num_pages;\r\nm->page_alignment = req->r_page_alignment;\r\n#ifdef CONFIG_BLOCK\r\nm->bio = req->r_bio;\r\n#endif\r\n}\r\n*skip = 0;\r\nreq->r_con_filling_msg = ceph_con_get(con);\r\ndout("get_reply tid %lld %p\n", tid, m);\r\nout:\r\nmutex_unlock(&osdc->request_mutex);\r\nreturn m;\r\n}\r\nstatic struct ceph_msg *alloc_msg(struct ceph_connection *con,\r\nstruct ceph_msg_header *hdr,\r\nint *skip)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nint type = le16_to_cpu(hdr->type);\r\nint front = le32_to_cpu(hdr->front_len);\r\nswitch (type) {\r\ncase CEPH_MSG_OSD_MAP:\r\ncase CEPH_MSG_WATCH_NOTIFY:\r\nreturn ceph_msg_new(type, front, GFP_NOFS, false);\r\ncase CEPH_MSG_OSD_OPREPLY:\r\nreturn get_reply(con, hdr, skip);\r\ndefault:\r\npr_info("alloc_msg unexpected msg type %d from osd%d\n", type,\r\nosd->o_osd);\r\n*skip = 1;\r\nreturn NULL;\r\n}\r\n}\r\nstatic struct ceph_connection *get_osd_con(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nif (get_osd(osd))\r\nreturn con;\r\nreturn NULL;\r\n}\r\nstatic void put_osd_con(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nput_osd(osd);\r\n}\r\nstatic int get_authorizer(struct ceph_connection *con,\r\nvoid **buf, int *len, int *proto,\r\nvoid **reply_buf, int *reply_len, int force_new)\r\n{\r\nstruct ceph_osd *o = con->private;\r\nstruct ceph_osd_client *osdc = o->o_osdc;\r\nstruct ceph_auth_client *ac = osdc->client->monc.auth;\r\nint ret = 0;\r\nif (force_new && o->o_authorizer) {\r\nac->ops->destroy_authorizer(ac, o->o_authorizer);\r\no->o_authorizer = NULL;\r\n}\r\nif (o->o_authorizer == NULL) {\r\nret = ac->ops->create_authorizer(\r\nac, CEPH_ENTITY_TYPE_OSD,\r\n&o->o_authorizer,\r\n&o->o_authorizer_buf,\r\n&o->o_authorizer_buf_len,\r\n&o->o_authorizer_reply_buf,\r\n&o->o_authorizer_reply_buf_len);\r\nif (ret)\r\nreturn ret;\r\n}\r\n*proto = ac->protocol;\r\n*buf = o->o_authorizer_buf;\r\n*len = o->o_authorizer_buf_len;\r\n*reply_buf = o->o_authorizer_reply_buf;\r\n*reply_len = o->o_authorizer_reply_buf_len;\r\nreturn 0;\r\n}\r\nstatic int verify_authorizer_reply(struct ceph_connection *con, int len)\r\n{\r\nstruct ceph_osd *o = con->private;\r\nstruct ceph_osd_client *osdc = o->o_osdc;\r\nstruct ceph_auth_client *ac = osdc->client->monc.auth;\r\nreturn ac->ops->verify_authorizer_reply(ac, o->o_authorizer, len);\r\n}\r\nstatic int invalidate_authorizer(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *o = con->private;\r\nstruct ceph_osd_client *osdc = o->o_osdc;\r\nstruct ceph_auth_client *ac = osdc->client->monc.auth;\r\nif (ac->ops->invalidate_authorizer)\r\nac->ops->invalidate_authorizer(ac, CEPH_ENTITY_TYPE_OSD);\r\nreturn ceph_monc_validate_auth(&osdc->client->monc);\r\n}
