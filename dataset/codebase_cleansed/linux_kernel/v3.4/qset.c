struct whc_qset *qset_alloc(struct whc *whc, gfp_t mem_flags)\r\n{\r\nstruct whc_qset *qset;\r\ndma_addr_t dma;\r\nqset = dma_pool_alloc(whc->qset_pool, mem_flags, &dma);\r\nif (qset == NULL)\r\nreturn NULL;\r\nmemset(qset, 0, sizeof(struct whc_qset));\r\nqset->qset_dma = dma;\r\nqset->whc = whc;\r\nINIT_LIST_HEAD(&qset->list_node);\r\nINIT_LIST_HEAD(&qset->stds);\r\nreturn qset;\r\n}\r\nstatic void qset_fill_qh(struct whc *whc, struct whc_qset *qset, struct urb *urb)\r\n{\r\nstruct usb_device *usb_dev = urb->dev;\r\nstruct wusb_dev *wusb_dev = usb_dev->wusb_dev;\r\nstruct usb_wireless_ep_comp_descriptor *epcd;\r\nbool is_out;\r\nuint8_t phy_rate;\r\nis_out = usb_pipeout(urb->pipe);\r\nqset->max_packet = le16_to_cpu(urb->ep->desc.wMaxPacketSize);\r\nepcd = (struct usb_wireless_ep_comp_descriptor *)qset->ep->extra;\r\nif (epcd) {\r\nqset->max_seq = epcd->bMaxSequence;\r\nqset->max_burst = epcd->bMaxBurst;\r\n} else {\r\nqset->max_seq = 2;\r\nqset->max_burst = 1;\r\n}\r\nif (usb_pipecontrol(urb->pipe))\r\nphy_rate = UWB_PHY_RATE_53;\r\nelse {\r\nuint16_t phy_rates;\r\nphy_rates = le16_to_cpu(wusb_dev->wusb_cap_descr->wPHYRates);\r\nphy_rate = fls(phy_rates) - 1;\r\nif (phy_rate > whc->wusbhc.phy_rate)\r\nphy_rate = whc->wusbhc.phy_rate;\r\n}\r\nqset->qh.info1 = cpu_to_le32(\r\nQH_INFO1_EP(usb_pipeendpoint(urb->pipe))\r\n| (is_out ? QH_INFO1_DIR_OUT : QH_INFO1_DIR_IN)\r\n| usb_pipe_to_qh_type(urb->pipe)\r\n| QH_INFO1_DEV_INFO_IDX(wusb_port_no_to_idx(usb_dev->portnum))\r\n| QH_INFO1_MAX_PKT_LEN(qset->max_packet)\r\n);\r\nqset->qh.info2 = cpu_to_le32(\r\nQH_INFO2_BURST(qset->max_burst)\r\n| QH_INFO2_DBP(0)\r\n| QH_INFO2_MAX_COUNT(3)\r\n| QH_INFO2_MAX_RETRY(3)\r\n| QH_INFO2_MAX_SEQ(qset->max_seq - 1)\r\n);\r\nqset->qh.info3 = cpu_to_le32(\r\nQH_INFO3_TX_RATE(phy_rate)\r\n| QH_INFO3_TX_PWR(0)\r\n);\r\nqset->qh.cur_window = cpu_to_le32((1 << qset->max_burst) - 1);\r\n}\r\nvoid qset_clear(struct whc *whc, struct whc_qset *qset)\r\n{\r\nqset->td_start = qset->td_end = qset->ntds = 0;\r\nqset->qh.link = cpu_to_le64(QH_LINK_NTDS(8) | QH_LINK_T);\r\nqset->qh.status = qset->qh.status & QH_STATUS_SEQ_MASK;\r\nqset->qh.err_count = 0;\r\nqset->qh.scratch[0] = 0;\r\nqset->qh.scratch[1] = 0;\r\nqset->qh.scratch[2] = 0;\r\nmemset(&qset->qh.overlay, 0, sizeof(qset->qh.overlay));\r\ninit_completion(&qset->remove_complete);\r\n}\r\nvoid qset_reset(struct whc *whc, struct whc_qset *qset)\r\n{\r\nqset->reset = 0;\r\nqset->qh.status &= ~QH_STATUS_SEQ_MASK;\r\nqset->qh.cur_window = cpu_to_le32((1 << qset->max_burst) - 1);\r\n}\r\nstruct whc_qset *get_qset(struct whc *whc, struct urb *urb,\r\ngfp_t mem_flags)\r\n{\r\nstruct whc_qset *qset;\r\nqset = urb->ep->hcpriv;\r\nif (qset == NULL) {\r\nqset = qset_alloc(whc, mem_flags);\r\nif (qset == NULL)\r\nreturn NULL;\r\nqset->ep = urb->ep;\r\nurb->ep->hcpriv = qset;\r\nqset_fill_qh(whc, qset, urb);\r\n}\r\nreturn qset;\r\n}\r\nvoid qset_remove_complete(struct whc *whc, struct whc_qset *qset)\r\n{\r\nqset->remove = 0;\r\nlist_del_init(&qset->list_node);\r\ncomplete(&qset->remove_complete);\r\n}\r\nenum whc_update qset_add_qtds(struct whc *whc, struct whc_qset *qset)\r\n{\r\nstruct whc_std *std;\r\nenum whc_update update = 0;\r\nlist_for_each_entry(std, &qset->stds, list_node) {\r\nstruct whc_qtd *qtd;\r\nuint32_t status;\r\nif (qset->ntds >= WHCI_QSET_TD_MAX\r\n|| (qset->pause_after_urb && std->urb != qset->pause_after_urb))\r\nbreak;\r\nif (std->qtd)\r\ncontinue;\r\nqtd = std->qtd = &qset->qtd[qset->td_end];\r\nif (usb_pipecontrol(std->urb->pipe))\r\nmemcpy(qtd->setup, std->urb->setup_packet, 8);\r\nstatus = QTD_STS_ACTIVE | QTD_STS_LEN(std->len);\r\nif (whc_std_last(std) && usb_pipeout(std->urb->pipe))\r\nstatus |= QTD_STS_LAST_PKT;\r\nif (std->ntds_remaining < WHCI_QSET_TD_MAX) {\r\nint ialt;\r\nialt = (qset->td_end + std->ntds_remaining) % WHCI_QSET_TD_MAX;\r\nstatus |= QTD_STS_IALT(ialt);\r\n} else if (usb_pipein(std->urb->pipe))\r\nqset->pause_after_urb = std->urb;\r\nif (std->num_pointers)\r\nqtd->options = cpu_to_le32(QTD_OPT_IOC);\r\nelse\r\nqtd->options = cpu_to_le32(QTD_OPT_IOC | QTD_OPT_SMALL);\r\nqtd->page_list_ptr = cpu_to_le64(std->dma_addr);\r\nqtd->status = cpu_to_le32(status);\r\nif (QH_STATUS_TO_ICUR(qset->qh.status) == qset->td_end)\r\nupdate = WHC_UPDATE_UPDATED;\r\nif (++qset->td_end >= WHCI_QSET_TD_MAX)\r\nqset->td_end = 0;\r\nqset->ntds++;\r\n}\r\nreturn update;\r\n}\r\nstatic void qset_remove_qtd(struct whc *whc, struct whc_qset *qset)\r\n{\r\nqset->qtd[qset->td_start].status = 0;\r\nif (++qset->td_start >= WHCI_QSET_TD_MAX)\r\nqset->td_start = 0;\r\nqset->ntds--;\r\n}\r\nstatic void qset_copy_bounce_to_sg(struct whc *whc, struct whc_std *std)\r\n{\r\nstruct scatterlist *sg;\r\nvoid *bounce;\r\nsize_t remaining, offset;\r\nbounce = std->bounce_buf;\r\nremaining = std->len;\r\nsg = std->bounce_sg;\r\noffset = std->bounce_offset;\r\nwhile (remaining) {\r\nsize_t len;\r\nlen = min(sg->length - offset, remaining);\r\nmemcpy(sg_virt(sg) + offset, bounce, len);\r\nbounce += len;\r\nremaining -= len;\r\noffset += len;\r\nif (offset >= sg->length) {\r\nsg = sg_next(sg);\r\noffset = 0;\r\n}\r\n}\r\n}\r\nvoid qset_free_std(struct whc *whc, struct whc_std *std)\r\n{\r\nlist_del(&std->list_node);\r\nif (std->bounce_buf) {\r\nbool is_out = usb_pipeout(std->urb->pipe);\r\ndma_addr_t dma_addr;\r\nif (std->num_pointers)\r\ndma_addr = le64_to_cpu(std->pl_virt[0].buf_ptr);\r\nelse\r\ndma_addr = std->dma_addr;\r\ndma_unmap_single(whc->wusbhc.dev, dma_addr,\r\nstd->len, is_out ? DMA_TO_DEVICE : DMA_FROM_DEVICE);\r\nif (!is_out)\r\nqset_copy_bounce_to_sg(whc, std);\r\nkfree(std->bounce_buf);\r\n}\r\nif (std->pl_virt) {\r\nif (std->dma_addr)\r\ndma_unmap_single(whc->wusbhc.dev, std->dma_addr,\r\nstd->num_pointers * sizeof(struct whc_page_list_entry),\r\nDMA_TO_DEVICE);\r\nkfree(std->pl_virt);\r\nstd->pl_virt = NULL;\r\n}\r\nkfree(std);\r\n}\r\nstatic void qset_remove_qtds(struct whc *whc, struct whc_qset *qset,\r\nstruct urb *urb)\r\n{\r\nstruct whc_std *std, *t;\r\nlist_for_each_entry_safe(std, t, &qset->stds, list_node) {\r\nif (std->urb != urb)\r\nbreak;\r\nif (std->qtd != NULL)\r\nqset_remove_qtd(whc, qset);\r\nqset_free_std(whc, std);\r\n}\r\n}\r\nstatic void qset_free_stds(struct whc_qset *qset, struct urb *urb)\r\n{\r\nstruct whc_std *std, *t;\r\nlist_for_each_entry_safe(std, t, &qset->stds, list_node) {\r\nif (std->urb == urb)\r\nqset_free_std(qset->whc, std);\r\n}\r\n}\r\nstatic int qset_fill_page_list(struct whc *whc, struct whc_std *std, gfp_t mem_flags)\r\n{\r\ndma_addr_t dma_addr = std->dma_addr;\r\ndma_addr_t sp, ep;\r\nsize_t pl_len;\r\nint p;\r\nif (std->len <= WHCI_PAGE_SIZE) {\r\nstd->num_pointers = 0;\r\nreturn 0;\r\n}\r\nsp = dma_addr & ~(WHCI_PAGE_SIZE-1);\r\nep = dma_addr + std->len;\r\nstd->num_pointers = DIV_ROUND_UP(ep - sp, WHCI_PAGE_SIZE);\r\npl_len = std->num_pointers * sizeof(struct whc_page_list_entry);\r\nstd->pl_virt = kmalloc(pl_len, mem_flags);\r\nif (std->pl_virt == NULL)\r\nreturn -ENOMEM;\r\nstd->dma_addr = dma_map_single(whc->wusbhc.dev, std->pl_virt, pl_len, DMA_TO_DEVICE);\r\nfor (p = 0; p < std->num_pointers; p++) {\r\nstd->pl_virt[p].buf_ptr = cpu_to_le64(dma_addr);\r\ndma_addr = (dma_addr + WHCI_PAGE_SIZE) & ~(WHCI_PAGE_SIZE-1);\r\n}\r\nreturn 0;\r\n}\r\nstatic void urb_dequeue_work(struct work_struct *work)\r\n{\r\nstruct whc_urb *wurb = container_of(work, struct whc_urb, dequeue_work);\r\nstruct whc_qset *qset = wurb->qset;\r\nstruct whc *whc = qset->whc;\r\nunsigned long flags;\r\nif (wurb->is_async == true)\r\nasl_update(whc, WUSBCMD_ASYNC_UPDATED\r\n| WUSBCMD_ASYNC_SYNCED_DB\r\n| WUSBCMD_ASYNC_QSET_RM);\r\nelse\r\npzl_update(whc, WUSBCMD_PERIODIC_UPDATED\r\n| WUSBCMD_PERIODIC_SYNCED_DB\r\n| WUSBCMD_PERIODIC_QSET_RM);\r\nspin_lock_irqsave(&whc->lock, flags);\r\nqset_remove_urb(whc, qset, wurb->urb, wurb->status);\r\nspin_unlock_irqrestore(&whc->lock, flags);\r\n}\r\nstatic struct whc_std *qset_new_std(struct whc *whc, struct whc_qset *qset,\r\nstruct urb *urb, gfp_t mem_flags)\r\n{\r\nstruct whc_std *std;\r\nstd = kzalloc(sizeof(struct whc_std), mem_flags);\r\nif (std == NULL)\r\nreturn NULL;\r\nstd->urb = urb;\r\nstd->qtd = NULL;\r\nINIT_LIST_HEAD(&std->list_node);\r\nlist_add_tail(&std->list_node, &qset->stds);\r\nreturn std;\r\n}\r\nstatic int qset_add_urb_sg(struct whc *whc, struct whc_qset *qset, struct urb *urb,\r\ngfp_t mem_flags)\r\n{\r\nsize_t remaining;\r\nstruct scatterlist *sg;\r\nint i;\r\nint ntds = 0;\r\nstruct whc_std *std = NULL;\r\nstruct whc_page_list_entry *entry;\r\ndma_addr_t prev_end = 0;\r\nsize_t pl_len;\r\nint p = 0;\r\nremaining = urb->transfer_buffer_length;\r\nfor_each_sg(urb->sg, sg, urb->num_mapped_sgs, i) {\r\ndma_addr_t dma_addr;\r\nsize_t dma_remaining;\r\ndma_addr_t sp, ep;\r\nint num_pointers;\r\nif (remaining == 0) {\r\nbreak;\r\n}\r\ndma_addr = sg_dma_address(sg);\r\ndma_remaining = min_t(size_t, sg_dma_len(sg), remaining);\r\nwhile (dma_remaining) {\r\nsize_t dma_len;\r\nif (!std\r\n|| (prev_end & (WHCI_PAGE_SIZE-1))\r\n|| (dma_addr & (WHCI_PAGE_SIZE-1))\r\n|| std->len + WHCI_PAGE_SIZE > QTD_MAX_XFER_SIZE) {\r\nif (std && std->len % qset->max_packet != 0)\r\nreturn -EINVAL;\r\nstd = qset_new_std(whc, qset, urb, mem_flags);\r\nif (std == NULL) {\r\nreturn -ENOMEM;\r\n}\r\nntds++;\r\np = 0;\r\n}\r\ndma_len = dma_remaining;\r\nif (std->len + dma_len > QTD_MAX_XFER_SIZE) {\r\ndma_len = (QTD_MAX_XFER_SIZE / qset->max_packet)\r\n* qset->max_packet - std->len;\r\n}\r\nstd->len += dma_len;\r\nstd->ntds_remaining = -1;\r\nsp = dma_addr & ~(WHCI_PAGE_SIZE-1);\r\nep = dma_addr + dma_len;\r\nnum_pointers = DIV_ROUND_UP(ep - sp, WHCI_PAGE_SIZE);\r\nstd->num_pointers += num_pointers;\r\npl_len = std->num_pointers * sizeof(struct whc_page_list_entry);\r\nstd->pl_virt = krealloc(std->pl_virt, pl_len, mem_flags);\r\nif (std->pl_virt == NULL) {\r\nreturn -ENOMEM;\r\n}\r\nfor (;p < std->num_pointers; p++, entry++) {\r\nstd->pl_virt[p].buf_ptr = cpu_to_le64(dma_addr);\r\ndma_addr = (dma_addr + WHCI_PAGE_SIZE) & ~(WHCI_PAGE_SIZE-1);\r\n}\r\nprev_end = dma_addr = ep;\r\ndma_remaining -= dma_len;\r\nremaining -= dma_len;\r\n}\r\n}\r\nlist_for_each_entry(std, &qset->stds, list_node) {\r\nif (std->ntds_remaining == -1) {\r\npl_len = std->num_pointers * sizeof(struct whc_page_list_entry);\r\nstd->ntds_remaining = ntds--;\r\nstd->dma_addr = dma_map_single(whc->wusbhc.dev, std->pl_virt,\r\npl_len, DMA_TO_DEVICE);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int qset_add_urb_sg_linearize(struct whc *whc, struct whc_qset *qset,\r\nstruct urb *urb, gfp_t mem_flags)\r\n{\r\nbool is_out = usb_pipeout(urb->pipe);\r\nsize_t max_std_len;\r\nsize_t remaining;\r\nint ntds = 0;\r\nstruct whc_std *std = NULL;\r\nvoid *bounce = NULL;\r\nstruct scatterlist *sg;\r\nint i;\r\nmax_std_len = qset->max_burst * qset->max_packet;\r\nremaining = urb->transfer_buffer_length;\r\nfor_each_sg(urb->sg, sg, urb->num_mapped_sgs, i) {\r\nsize_t len;\r\nsize_t sg_remaining;\r\nvoid *orig;\r\nif (remaining == 0) {\r\nbreak;\r\n}\r\nsg_remaining = min_t(size_t, remaining, sg->length);\r\norig = sg_virt(sg);\r\nwhile (sg_remaining) {\r\nif (!std || std->len == max_std_len) {\r\nstd = qset_new_std(whc, qset, urb, mem_flags);\r\nif (std == NULL)\r\nreturn -ENOMEM;\r\nstd->bounce_buf = kmalloc(max_std_len, mem_flags);\r\nif (std->bounce_buf == NULL)\r\nreturn -ENOMEM;\r\nstd->bounce_sg = sg;\r\nstd->bounce_offset = orig - sg_virt(sg);\r\nbounce = std->bounce_buf;\r\nntds++;\r\n}\r\nlen = min(sg_remaining, max_std_len - std->len);\r\nif (is_out)\r\nmemcpy(bounce, orig, len);\r\nstd->len += len;\r\nstd->ntds_remaining = -1;\r\nbounce += len;\r\norig += len;\r\nsg_remaining -= len;\r\nremaining -= len;\r\n}\r\n}\r\nlist_for_each_entry(std, &qset->stds, list_node) {\r\nif (std->ntds_remaining != -1)\r\ncontinue;\r\nstd->dma_addr = dma_map_single(&whc->umc->dev, std->bounce_buf, std->len,\r\nis_out ? DMA_TO_DEVICE : DMA_FROM_DEVICE);\r\nif (qset_fill_page_list(whc, std, mem_flags) < 0)\r\nreturn -ENOMEM;\r\nstd->ntds_remaining = ntds--;\r\n}\r\nreturn 0;\r\n}\r\nint qset_add_urb(struct whc *whc, struct whc_qset *qset, struct urb *urb,\r\ngfp_t mem_flags)\r\n{\r\nstruct whc_urb *wurb;\r\nint remaining = urb->transfer_buffer_length;\r\nu64 transfer_dma = urb->transfer_dma;\r\nint ntds_remaining;\r\nint ret;\r\nwurb = kzalloc(sizeof(struct whc_urb), mem_flags);\r\nif (wurb == NULL)\r\ngoto err_no_mem;\r\nurb->hcpriv = wurb;\r\nwurb->qset = qset;\r\nwurb->urb = urb;\r\nINIT_WORK(&wurb->dequeue_work, urb_dequeue_work);\r\nif (urb->num_sgs) {\r\nret = qset_add_urb_sg(whc, qset, urb, mem_flags);\r\nif (ret == -EINVAL) {\r\nqset_free_stds(qset, urb);\r\nret = qset_add_urb_sg_linearize(whc, qset, urb, mem_flags);\r\n}\r\nif (ret < 0)\r\ngoto err_no_mem;\r\nreturn 0;\r\n}\r\nntds_remaining = DIV_ROUND_UP(remaining, QTD_MAX_XFER_SIZE);\r\nif (ntds_remaining == 0)\r\nntds_remaining = 1;\r\nwhile (ntds_remaining) {\r\nstruct whc_std *std;\r\nsize_t std_len;\r\nstd_len = remaining;\r\nif (std_len > QTD_MAX_XFER_SIZE)\r\nstd_len = QTD_MAX_XFER_SIZE;\r\nstd = qset_new_std(whc, qset, urb, mem_flags);\r\nif (std == NULL)\r\ngoto err_no_mem;\r\nstd->dma_addr = transfer_dma;\r\nstd->len = std_len;\r\nstd->ntds_remaining = ntds_remaining;\r\nif (qset_fill_page_list(whc, std, mem_flags) < 0)\r\ngoto err_no_mem;\r\nntds_remaining--;\r\nremaining -= std_len;\r\ntransfer_dma += std_len;\r\n}\r\nreturn 0;\r\nerr_no_mem:\r\nqset_free_stds(qset, urb);\r\nreturn -ENOMEM;\r\n}\r\nvoid qset_remove_urb(struct whc *whc, struct whc_qset *qset,\r\nstruct urb *urb, int status)\r\n{\r\nstruct wusbhc *wusbhc = &whc->wusbhc;\r\nstruct whc_urb *wurb = urb->hcpriv;\r\nusb_hcd_unlink_urb_from_ep(&wusbhc->usb_hcd, urb);\r\nspin_unlock(&whc->lock);\r\nwusbhc_giveback_urb(wusbhc, urb, status);\r\nspin_lock(&whc->lock);\r\nkfree(wurb);\r\n}\r\nstatic int get_urb_status_from_qtd(struct urb *urb, u32 status)\r\n{\r\nif (status & QTD_STS_HALTED) {\r\nif (status & QTD_STS_DBE)\r\nreturn usb_pipein(urb->pipe) ? -ENOSR : -ECOMM;\r\nelse if (status & QTD_STS_BABBLE)\r\nreturn -EOVERFLOW;\r\nelse if (status & QTD_STS_RCE)\r\nreturn -ETIME;\r\nreturn -EPIPE;\r\n}\r\nif (usb_pipein(urb->pipe)\r\n&& (urb->transfer_flags & URB_SHORT_NOT_OK)\r\n&& urb->actual_length < urb->transfer_buffer_length)\r\nreturn -EREMOTEIO;\r\nreturn 0;\r\n}\r\nvoid process_inactive_qtd(struct whc *whc, struct whc_qset *qset,\r\nstruct whc_qtd *qtd)\r\n{\r\nstruct whc_std *std = list_first_entry(&qset->stds, struct whc_std, list_node);\r\nstruct urb *urb = std->urb;\r\nuint32_t status;\r\nbool complete;\r\nstatus = le32_to_cpu(qtd->status);\r\nurb->actual_length += std->len - QTD_STS_TO_LEN(status);\r\nif (usb_pipein(urb->pipe) && (status & QTD_STS_LAST_PKT))\r\ncomplete = true;\r\nelse\r\ncomplete = whc_std_last(std);\r\nqset_remove_qtd(whc, qset);\r\nqset_free_std(whc, std);\r\nif (complete) {\r\nqset_remove_qtds(whc, qset, urb);\r\nqset_remove_urb(whc, qset, urb, get_urb_status_from_qtd(urb, status));\r\nif (!(status & QTD_STS_IALT_VALID))\r\nqset->td_start = qset->td_end\r\n= QH_STATUS_TO_ICUR(le16_to_cpu(qset->qh.status));\r\nqset->pause_after_urb = NULL;\r\n}\r\n}\r\nvoid process_halted_qtd(struct whc *whc, struct whc_qset *qset,\r\nstruct whc_qtd *qtd)\r\n{\r\nstruct whc_std *std = list_first_entry(&qset->stds, struct whc_std, list_node);\r\nstruct urb *urb = std->urb;\r\nint urb_status;\r\nurb_status = get_urb_status_from_qtd(urb, le32_to_cpu(qtd->status));\r\nqset_remove_qtds(whc, qset, urb);\r\nqset_remove_urb(whc, qset, urb, urb_status);\r\nlist_for_each_entry(std, &qset->stds, list_node) {\r\nif (qset->ntds == 0)\r\nbreak;\r\nqset_remove_qtd(whc, qset);\r\nstd->qtd = NULL;\r\n}\r\nqset->remove = 1;\r\n}\r\nvoid qset_free(struct whc *whc, struct whc_qset *qset)\r\n{\r\ndma_pool_free(whc->qset_pool, qset, qset->qset_dma);\r\n}\r\nvoid qset_delete(struct whc *whc, struct whc_qset *qset)\r\n{\r\nwait_for_completion(&qset->remove_complete);\r\nqset_free(whc, qset);\r\n}
