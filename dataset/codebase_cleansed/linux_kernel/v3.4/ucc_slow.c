u32 ucc_slow_get_qe_cr_subblock(int uccs_num)\r\n{\r\nswitch (uccs_num) {\r\ncase 0: return QE_CR_SUBBLOCK_UCCSLOW1;\r\ncase 1: return QE_CR_SUBBLOCK_UCCSLOW2;\r\ncase 2: return QE_CR_SUBBLOCK_UCCSLOW3;\r\ncase 3: return QE_CR_SUBBLOCK_UCCSLOW4;\r\ncase 4: return QE_CR_SUBBLOCK_UCCSLOW5;\r\ncase 5: return QE_CR_SUBBLOCK_UCCSLOW6;\r\ncase 6: return QE_CR_SUBBLOCK_UCCSLOW7;\r\ncase 7: return QE_CR_SUBBLOCK_UCCSLOW8;\r\ndefault: return QE_CR_SUBBLOCK_INVALID;\r\n}\r\n}\r\nvoid ucc_slow_poll_transmitter_now(struct ucc_slow_private * uccs)\r\n{\r\nout_be16(&uccs->us_regs->utodr, UCC_SLOW_TOD);\r\n}\r\nvoid ucc_slow_graceful_stop_tx(struct ucc_slow_private * uccs)\r\n{\r\nstruct ucc_slow_info *us_info = uccs->us_info;\r\nu32 id;\r\nid = ucc_slow_get_qe_cr_subblock(us_info->ucc_num);\r\nqe_issue_cmd(QE_GRACEFUL_STOP_TX, id,\r\nQE_CR_PROTOCOL_UNSPECIFIED, 0);\r\n}\r\nvoid ucc_slow_stop_tx(struct ucc_slow_private * uccs)\r\n{\r\nstruct ucc_slow_info *us_info = uccs->us_info;\r\nu32 id;\r\nid = ucc_slow_get_qe_cr_subblock(us_info->ucc_num);\r\nqe_issue_cmd(QE_STOP_TX, id, QE_CR_PROTOCOL_UNSPECIFIED, 0);\r\n}\r\nvoid ucc_slow_restart_tx(struct ucc_slow_private * uccs)\r\n{\r\nstruct ucc_slow_info *us_info = uccs->us_info;\r\nu32 id;\r\nid = ucc_slow_get_qe_cr_subblock(us_info->ucc_num);\r\nqe_issue_cmd(QE_RESTART_TX, id, QE_CR_PROTOCOL_UNSPECIFIED, 0);\r\n}\r\nvoid ucc_slow_enable(struct ucc_slow_private * uccs, enum comm_dir mode)\r\n{\r\nstruct ucc_slow *us_regs;\r\nu32 gumr_l;\r\nus_regs = uccs->us_regs;\r\ngumr_l = in_be32(&us_regs->gumr_l);\r\nif (mode & COMM_DIR_TX) {\r\ngumr_l |= UCC_SLOW_GUMR_L_ENT;\r\nuccs->enabled_tx = 1;\r\n}\r\nif (mode & COMM_DIR_RX) {\r\ngumr_l |= UCC_SLOW_GUMR_L_ENR;\r\nuccs->enabled_rx = 1;\r\n}\r\nout_be32(&us_regs->gumr_l, gumr_l);\r\n}\r\nvoid ucc_slow_disable(struct ucc_slow_private * uccs, enum comm_dir mode)\r\n{\r\nstruct ucc_slow *us_regs;\r\nu32 gumr_l;\r\nus_regs = uccs->us_regs;\r\ngumr_l = in_be32(&us_regs->gumr_l);\r\nif (mode & COMM_DIR_TX) {\r\ngumr_l &= ~UCC_SLOW_GUMR_L_ENT;\r\nuccs->enabled_tx = 0;\r\n}\r\nif (mode & COMM_DIR_RX) {\r\ngumr_l &= ~UCC_SLOW_GUMR_L_ENR;\r\nuccs->enabled_rx = 0;\r\n}\r\nout_be32(&us_regs->gumr_l, gumr_l);\r\n}\r\nint ucc_slow_init(struct ucc_slow_info * us_info, struct ucc_slow_private ** uccs_ret)\r\n{\r\nstruct ucc_slow_private *uccs;\r\nu32 i;\r\nstruct ucc_slow __iomem *us_regs;\r\nu32 gumr;\r\nstruct qe_bd *bd;\r\nu32 id;\r\nu32 command;\r\nint ret = 0;\r\nif (!us_info)\r\nreturn -EINVAL;\r\nif ((us_info->ucc_num < 0) || (us_info->ucc_num > UCC_MAX_NUM - 1)) {\r\nprintk(KERN_ERR "%s: illegal UCC number\n", __func__);\r\nreturn -EINVAL;\r\n}\r\nif ((!us_info->rfw) &&\r\n(us_info->max_rx_buf_length & (UCC_SLOW_MRBLR_ALIGNMENT - 1))) {\r\nprintk(KERN_ERR "max_rx_buf_length not aligned.\n");\r\nreturn -EINVAL;\r\n}\r\nuccs = kzalloc(sizeof(struct ucc_slow_private), GFP_KERNEL);\r\nif (!uccs) {\r\nprintk(KERN_ERR "%s: Cannot allocate private data\n",\r\n__func__);\r\nreturn -ENOMEM;\r\n}\r\nuccs->us_info = us_info;\r\nuccs->us_regs = ioremap(us_info->regs, sizeof(struct ucc_slow));\r\nif (uccs->us_regs == NULL) {\r\nprintk(KERN_ERR "%s: Cannot map UCC registers\n", __func__);\r\nkfree(uccs);\r\nreturn -ENOMEM;\r\n}\r\nuccs->saved_uccm = 0;\r\nuccs->p_rx_frame = 0;\r\nus_regs = uccs->us_regs;\r\nuccs->p_ucce = (u16 *) & (us_regs->ucce);\r\nuccs->p_uccm = (u16 *) & (us_regs->uccm);\r\n#ifdef STATISTICS\r\nuccs->rx_frames = 0;\r\nuccs->tx_frames = 0;\r\nuccs->rx_discarded = 0;\r\n#endif\r\nuccs->us_pram_offset =\r\nqe_muram_alloc(UCC_SLOW_PRAM_SIZE, ALIGNMENT_OF_UCC_SLOW_PRAM);\r\nif (IS_ERR_VALUE(uccs->us_pram_offset)) {\r\nprintk(KERN_ERR "%s: cannot allocate MURAM for PRAM", __func__);\r\nucc_slow_free(uccs);\r\nreturn -ENOMEM;\r\n}\r\nid = ucc_slow_get_qe_cr_subblock(us_info->ucc_num);\r\nqe_issue_cmd(QE_ASSIGN_PAGE_TO_DEVICE, id, us_info->protocol,\r\nuccs->us_pram_offset);\r\nuccs->us_pram = qe_muram_addr(uccs->us_pram_offset);\r\nret = ucc_set_type(us_info->ucc_num, UCC_SPEED_TYPE_SLOW);\r\nif (ret) {\r\nprintk(KERN_ERR "%s: cannot set UCC type", __func__);\r\nucc_slow_free(uccs);\r\nreturn ret;\r\n}\r\nout_be16(&uccs->us_pram->mrblr, us_info->max_rx_buf_length);\r\nINIT_LIST_HEAD(&uccs->confQ);\r\nuccs->rx_base_offset =\r\nqe_muram_alloc(us_info->rx_bd_ring_len * sizeof(struct qe_bd),\r\nQE_ALIGNMENT_OF_BD);\r\nif (IS_ERR_VALUE(uccs->rx_base_offset)) {\r\nprintk(KERN_ERR "%s: cannot allocate %u RX BDs\n", __func__,\r\nus_info->rx_bd_ring_len);\r\nuccs->rx_base_offset = 0;\r\nucc_slow_free(uccs);\r\nreturn -ENOMEM;\r\n}\r\nuccs->tx_base_offset =\r\nqe_muram_alloc(us_info->tx_bd_ring_len * sizeof(struct qe_bd),\r\nQE_ALIGNMENT_OF_BD);\r\nif (IS_ERR_VALUE(uccs->tx_base_offset)) {\r\nprintk(KERN_ERR "%s: cannot allocate TX BDs", __func__);\r\nuccs->tx_base_offset = 0;\r\nucc_slow_free(uccs);\r\nreturn -ENOMEM;\r\n}\r\nbd = uccs->confBd = uccs->tx_bd = qe_muram_addr(uccs->tx_base_offset);\r\nfor (i = 0; i < us_info->tx_bd_ring_len - 1; i++) {\r\nout_be32(&bd->buf, 0);\r\nout_be32((u32 *) bd, 0);\r\nbd++;\r\n}\r\nout_be32(&bd->buf, 0);\r\nout_be32((u32 *) bd, cpu_to_be32(T_W));\r\nbd = uccs->rx_bd = qe_muram_addr(uccs->rx_base_offset);\r\nfor (i = 0; i < us_info->rx_bd_ring_len - 1; i++) {\r\nout_be32((u32*)bd, 0);\r\nout_be32(&bd->buf, 0);\r\nbd++;\r\n}\r\nout_be32((u32*)bd, cpu_to_be32(R_W));\r\nout_be32(&bd->buf, 0);\r\ngumr = us_info->tcrc;\r\nif (us_info->cdp)\r\ngumr |= UCC_SLOW_GUMR_H_CDP;\r\nif (us_info->ctsp)\r\ngumr |= UCC_SLOW_GUMR_H_CTSP;\r\nif (us_info->cds)\r\ngumr |= UCC_SLOW_GUMR_H_CDS;\r\nif (us_info->ctss)\r\ngumr |= UCC_SLOW_GUMR_H_CTSS;\r\nif (us_info->tfl)\r\ngumr |= UCC_SLOW_GUMR_H_TFL;\r\nif (us_info->rfw)\r\ngumr |= UCC_SLOW_GUMR_H_RFW;\r\nif (us_info->txsy)\r\ngumr |= UCC_SLOW_GUMR_H_TXSY;\r\nif (us_info->rtsm)\r\ngumr |= UCC_SLOW_GUMR_H_RTSM;\r\nout_be32(&us_regs->gumr_h, gumr);\r\ngumr = us_info->tdcr | us_info->rdcr | us_info->tenc | us_info->renc |\r\nus_info->diag | us_info->mode;\r\nif (us_info->tci)\r\ngumr |= UCC_SLOW_GUMR_L_TCI;\r\nif (us_info->rinv)\r\ngumr |= UCC_SLOW_GUMR_L_RINV;\r\nif (us_info->tinv)\r\ngumr |= UCC_SLOW_GUMR_L_TINV;\r\nif (us_info->tend)\r\ngumr |= UCC_SLOW_GUMR_L_TEND;\r\nout_be32(&us_regs->gumr_l, gumr);\r\nuccs->us_pram->tbmr = UCC_BMR_BO_BE;\r\nuccs->us_pram->rbmr = UCC_BMR_BO_BE;\r\nout_be16(&uccs->us_pram->rbase, uccs->rx_base_offset);\r\nout_be16(&uccs->us_pram->tbase, uccs->tx_base_offset);\r\nucc_set_qe_mux_grant(us_info->ucc_num, us_info->grant_support);\r\nucc_set_qe_mux_bkpt(us_info->ucc_num, us_info->brkpt_support);\r\nucc_set_qe_mux_tsa(us_info->ucc_num, us_info->tsa);\r\nif (!us_info->tsa) {\r\nif (ucc_set_qe_mux_rxtx(us_info->ucc_num, us_info->rx_clock,\r\nCOMM_DIR_RX)) {\r\nprintk(KERN_ERR "%s: illegal value for RX clock\n",\r\n__func__);\r\nucc_slow_free(uccs);\r\nreturn -EINVAL;\r\n}\r\nif (ucc_set_qe_mux_rxtx(us_info->ucc_num, us_info->tx_clock,\r\nCOMM_DIR_TX)) {\r\nprintk(KERN_ERR "%s: illegal value for TX clock\n",\r\n__func__);\r\nucc_slow_free(uccs);\r\nreturn -EINVAL;\r\n}\r\n}\r\nout_be16(&us_regs->uccm, us_info->uccm_mask);\r\nout_be16(&us_regs->ucce, 0xffff);\r\nif (us_info->init_tx && us_info->init_rx)\r\ncommand = QE_INIT_TX_RX;\r\nelse if (us_info->init_tx)\r\ncommand = QE_INIT_TX;\r\nelse\r\ncommand = QE_INIT_RX;\r\nqe_issue_cmd(command, id, us_info->protocol, 0);\r\n*uccs_ret = uccs;\r\nreturn 0;\r\n}\r\nvoid ucc_slow_free(struct ucc_slow_private * uccs)\r\n{\r\nif (!uccs)\r\nreturn;\r\nif (uccs->rx_base_offset)\r\nqe_muram_free(uccs->rx_base_offset);\r\nif (uccs->tx_base_offset)\r\nqe_muram_free(uccs->tx_base_offset);\r\nif (uccs->us_pram)\r\nqe_muram_free(uccs->us_pram_offset);\r\nif (uccs->us_regs)\r\niounmap(uccs->us_regs);\r\nkfree(uccs);\r\n}
