int\r\nnouveau_gpuobj_class_new(struct drm_device *dev, u32 class, u32 engine)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj_class *oc;\r\noc = kzalloc(sizeof(*oc), GFP_KERNEL);\r\nif (!oc)\r\nreturn -ENOMEM;\r\nINIT_LIST_HEAD(&oc->methods);\r\noc->id = class;\r\noc->engine = engine;\r\nlist_add(&oc->head, &dev_priv->classes);\r\nreturn 0;\r\n}\r\nint\r\nnouveau_gpuobj_mthd_new(struct drm_device *dev, u32 class, u32 mthd,\r\nint (*exec)(struct nouveau_channel *, u32, u32, u32))\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj_method *om;\r\nstruct nouveau_gpuobj_class *oc;\r\nlist_for_each_entry(oc, &dev_priv->classes, head) {\r\nif (oc->id == class)\r\ngoto found;\r\n}\r\nreturn -EINVAL;\r\nfound:\r\nom = kzalloc(sizeof(*om), GFP_KERNEL);\r\nif (!om)\r\nreturn -ENOMEM;\r\nom->mthd = mthd;\r\nom->exec = exec;\r\nlist_add(&om->head, &oc->methods);\r\nreturn 0;\r\n}\r\nint\r\nnouveau_gpuobj_mthd_call(struct nouveau_channel *chan,\r\nu32 class, u32 mthd, u32 data)\r\n{\r\nstruct drm_nouveau_private *dev_priv = chan->dev->dev_private;\r\nstruct nouveau_gpuobj_method *om;\r\nstruct nouveau_gpuobj_class *oc;\r\nlist_for_each_entry(oc, &dev_priv->classes, head) {\r\nif (oc->id != class)\r\ncontinue;\r\nlist_for_each_entry(om, &oc->methods, head) {\r\nif (om->mthd == mthd)\r\nreturn om->exec(chan, class, mthd, data);\r\n}\r\n}\r\nreturn -ENOENT;\r\n}\r\nint\r\nnouveau_gpuobj_mthd_call2(struct drm_device *dev, int chid,\r\nu32 class, u32 mthd, u32 data)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_channel *chan = NULL;\r\nunsigned long flags;\r\nint ret = -EINVAL;\r\nspin_lock_irqsave(&dev_priv->channels.lock, flags);\r\nif (chid >= 0 && chid < dev_priv->engine.fifo.channels)\r\nchan = dev_priv->channels.ptr[chid];\r\nif (chan)\r\nret = nouveau_gpuobj_mthd_call(chan, class, mthd, data);\r\nspin_unlock_irqrestore(&dev_priv->channels.lock, flags);\r\nreturn ret;\r\n}\r\nint\r\nnouveau_gpuobj_new(struct drm_device *dev, struct nouveau_channel *chan,\r\nuint32_t size, int align, uint32_t flags,\r\nstruct nouveau_gpuobj **gpuobj_ret)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_instmem_engine *instmem = &dev_priv->engine.instmem;\r\nstruct nouveau_gpuobj *gpuobj;\r\nstruct drm_mm_node *ramin = NULL;\r\nint ret, i;\r\nNV_DEBUG(dev, "ch%d size=%u align=%d flags=0x%08x\n",\r\nchan ? chan->id : -1, size, align, flags);\r\ngpuobj = kzalloc(sizeof(*gpuobj), GFP_KERNEL);\r\nif (!gpuobj)\r\nreturn -ENOMEM;\r\nNV_DEBUG(dev, "gpuobj %p\n", gpuobj);\r\ngpuobj->dev = dev;\r\ngpuobj->flags = flags;\r\nkref_init(&gpuobj->refcount);\r\ngpuobj->size = size;\r\nspin_lock(&dev_priv->ramin_lock);\r\nlist_add_tail(&gpuobj->list, &dev_priv->gpuobj_list);\r\nspin_unlock(&dev_priv->ramin_lock);\r\nif (!(flags & NVOBJ_FLAG_VM) && chan) {\r\nramin = drm_mm_search_free(&chan->ramin_heap, size, align, 0);\r\nif (ramin)\r\nramin = drm_mm_get_block(ramin, size, align);\r\nif (!ramin) {\r\nnouveau_gpuobj_ref(NULL, &gpuobj);\r\nreturn -ENOMEM;\r\n}\r\ngpuobj->pinst = chan->ramin->pinst;\r\nif (gpuobj->pinst != ~0)\r\ngpuobj->pinst += ramin->start;\r\ngpuobj->cinst = ramin->start;\r\ngpuobj->vinst = ramin->start + chan->ramin->vinst;\r\ngpuobj->node = ramin;\r\n} else {\r\nret = instmem->get(gpuobj, chan, size, align);\r\nif (ret) {\r\nnouveau_gpuobj_ref(NULL, &gpuobj);\r\nreturn ret;\r\n}\r\nret = -ENOSYS;\r\nif (!(flags & NVOBJ_FLAG_DONT_MAP))\r\nret = instmem->map(gpuobj);\r\nif (ret)\r\ngpuobj->pinst = ~0;\r\ngpuobj->cinst = NVOBJ_CINST_GLOBAL;\r\n}\r\nif (gpuobj->flags & NVOBJ_FLAG_ZERO_ALLOC) {\r\nfor (i = 0; i < gpuobj->size; i += 4)\r\nnv_wo32(gpuobj, i, 0);\r\ninstmem->flush(dev);\r\n}\r\n*gpuobj_ret = gpuobj;\r\nreturn 0;\r\n}\r\nint\r\nnouveau_gpuobj_init(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nNV_DEBUG(dev, "\n");\r\nINIT_LIST_HEAD(&dev_priv->gpuobj_list);\r\nINIT_LIST_HEAD(&dev_priv->classes);\r\nspin_lock_init(&dev_priv->ramin_lock);\r\ndev_priv->ramin_base = ~0;\r\nreturn 0;\r\n}\r\nvoid\r\nnouveau_gpuobj_takedown(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj_method *om, *tm;\r\nstruct nouveau_gpuobj_class *oc, *tc;\r\nNV_DEBUG(dev, "\n");\r\nlist_for_each_entry_safe(oc, tc, &dev_priv->classes, head) {\r\nlist_for_each_entry_safe(om, tm, &oc->methods, head) {\r\nlist_del(&om->head);\r\nkfree(om);\r\n}\r\nlist_del(&oc->head);\r\nkfree(oc);\r\n}\r\nBUG_ON(!list_empty(&dev_priv->gpuobj_list));\r\n}\r\nstatic void\r\nnouveau_gpuobj_del(struct kref *ref)\r\n{\r\nstruct nouveau_gpuobj *gpuobj =\r\ncontainer_of(ref, struct nouveau_gpuobj, refcount);\r\nstruct drm_device *dev = gpuobj->dev;\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_instmem_engine *instmem = &dev_priv->engine.instmem;\r\nint i;\r\nNV_DEBUG(dev, "gpuobj %p\n", gpuobj);\r\nif (gpuobj->node && (gpuobj->flags & NVOBJ_FLAG_ZERO_FREE)) {\r\nfor (i = 0; i < gpuobj->size; i += 4)\r\nnv_wo32(gpuobj, i, 0);\r\ninstmem->flush(dev);\r\n}\r\nif (gpuobj->dtor)\r\ngpuobj->dtor(dev, gpuobj);\r\nif (gpuobj->cinst == NVOBJ_CINST_GLOBAL) {\r\nif (gpuobj->node) {\r\ninstmem->unmap(gpuobj);\r\ninstmem->put(gpuobj);\r\n}\r\n} else {\r\nif (gpuobj->node) {\r\nspin_lock(&dev_priv->ramin_lock);\r\ndrm_mm_put_block(gpuobj->node);\r\nspin_unlock(&dev_priv->ramin_lock);\r\n}\r\n}\r\nspin_lock(&dev_priv->ramin_lock);\r\nlist_del(&gpuobj->list);\r\nspin_unlock(&dev_priv->ramin_lock);\r\nkfree(gpuobj);\r\n}\r\nvoid\r\nnouveau_gpuobj_ref(struct nouveau_gpuobj *ref, struct nouveau_gpuobj **ptr)\r\n{\r\nif (ref)\r\nkref_get(&ref->refcount);\r\nif (*ptr)\r\nkref_put(&(*ptr)->refcount, nouveau_gpuobj_del);\r\n*ptr = ref;\r\n}\r\nint\r\nnouveau_gpuobj_new_fake(struct drm_device *dev, u32 pinst, u64 vinst,\r\nu32 size, u32 flags, struct nouveau_gpuobj **pgpuobj)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj *gpuobj = NULL;\r\nint i;\r\nNV_DEBUG(dev,\r\n"pinst=0x%08x vinst=0x%010llx size=0x%08x flags=0x%08x\n",\r\npinst, vinst, size, flags);\r\ngpuobj = kzalloc(sizeof(*gpuobj), GFP_KERNEL);\r\nif (!gpuobj)\r\nreturn -ENOMEM;\r\nNV_DEBUG(dev, "gpuobj %p\n", gpuobj);\r\ngpuobj->dev = dev;\r\ngpuobj->flags = flags;\r\nkref_init(&gpuobj->refcount);\r\ngpuobj->size = size;\r\ngpuobj->pinst = pinst;\r\ngpuobj->cinst = NVOBJ_CINST_GLOBAL;\r\ngpuobj->vinst = vinst;\r\nif (gpuobj->flags & NVOBJ_FLAG_ZERO_ALLOC) {\r\nfor (i = 0; i < gpuobj->size; i += 4)\r\nnv_wo32(gpuobj, i, 0);\r\ndev_priv->engine.instmem.flush(dev);\r\n}\r\nspin_lock(&dev_priv->ramin_lock);\r\nlist_add_tail(&gpuobj->list, &dev_priv->gpuobj_list);\r\nspin_unlock(&dev_priv->ramin_lock);\r\n*pgpuobj = gpuobj;\r\nreturn 0;\r\n}\r\nvoid\r\nnv50_gpuobj_dma_init(struct nouveau_gpuobj *obj, u32 offset, int class,\r\nu64 base, u64 size, int target, int access,\r\nu32 type, u32 comp)\r\n{\r\nstruct drm_nouveau_private *dev_priv = obj->dev->dev_private;\r\nstruct nouveau_instmem_engine *pinstmem = &dev_priv->engine.instmem;\r\nu32 flags0;\r\nflags0 = (comp << 29) | (type << 22) | class;\r\nflags0 |= 0x00100000;\r\nswitch (access) {\r\ncase NV_MEM_ACCESS_RO: flags0 |= 0x00040000; break;\r\ncase NV_MEM_ACCESS_RW:\r\ncase NV_MEM_ACCESS_WO: flags0 |= 0x00080000; break;\r\ndefault:\r\nbreak;\r\n}\r\nswitch (target) {\r\ncase NV_MEM_TARGET_VRAM:\r\nflags0 |= 0x00010000;\r\nbreak;\r\ncase NV_MEM_TARGET_PCI:\r\nflags0 |= 0x00020000;\r\nbreak;\r\ncase NV_MEM_TARGET_PCI_NOSNOOP:\r\nflags0 |= 0x00030000;\r\nbreak;\r\ncase NV_MEM_TARGET_GART:\r\nbase += dev_priv->gart_info.aper_base;\r\ndefault:\r\nflags0 &= ~0x00100000;\r\nbreak;\r\n}\r\nsize = (base + size) - 1;\r\nnv_wo32(obj, offset + 0x00, flags0);\r\nnv_wo32(obj, offset + 0x04, lower_32_bits(size));\r\nnv_wo32(obj, offset + 0x08, lower_32_bits(base));\r\nnv_wo32(obj, offset + 0x0c, upper_32_bits(size) << 24 |\r\nupper_32_bits(base));\r\nnv_wo32(obj, offset + 0x10, 0x00000000);\r\nnv_wo32(obj, offset + 0x14, 0x00000000);\r\npinstmem->flush(obj->dev);\r\n}\r\nint\r\nnv50_gpuobj_dma_new(struct nouveau_channel *chan, int class, u64 base, u64 size,\r\nint target, int access, u32 type, u32 comp,\r\nstruct nouveau_gpuobj **pobj)\r\n{\r\nstruct drm_device *dev = chan->dev;\r\nint ret;\r\nret = nouveau_gpuobj_new(dev, chan, 24, 16, NVOBJ_FLAG_ZERO_FREE, pobj);\r\nif (ret)\r\nreturn ret;\r\nnv50_gpuobj_dma_init(*pobj, 0, class, base, size, target,\r\naccess, type, comp);\r\nreturn 0;\r\n}\r\nint\r\nnouveau_gpuobj_dma_new(struct nouveau_channel *chan, int class, u64 base,\r\nu64 size, int access, int target,\r\nstruct nouveau_gpuobj **pobj)\r\n{\r\nstruct drm_nouveau_private *dev_priv = chan->dev->dev_private;\r\nstruct drm_device *dev = chan->dev;\r\nstruct nouveau_gpuobj *obj;\r\nu32 flags0, flags2;\r\nint ret;\r\nif (dev_priv->card_type >= NV_50) {\r\nu32 comp = (target == NV_MEM_TARGET_VM) ? NV_MEM_COMP_VM : 0;\r\nu32 type = (target == NV_MEM_TARGET_VM) ? NV_MEM_TYPE_VM : 0;\r\nreturn nv50_gpuobj_dma_new(chan, class, base, size,\r\ntarget, access, type, comp, pobj);\r\n}\r\nif (target == NV_MEM_TARGET_GART) {\r\nstruct nouveau_gpuobj *gart = dev_priv->gart_info.sg_ctxdma;\r\nif (dev_priv->gart_info.type == NOUVEAU_GART_PDMA) {\r\nif (base == 0) {\r\nnouveau_gpuobj_ref(gart, pobj);\r\nreturn 0;\r\n}\r\nbase = nouveau_sgdma_get_physical(dev, base);\r\ntarget = NV_MEM_TARGET_PCI;\r\n} else {\r\nbase += dev_priv->gart_info.aper_base;\r\nif (dev_priv->gart_info.type == NOUVEAU_GART_AGP)\r\ntarget = NV_MEM_TARGET_PCI_NOSNOOP;\r\nelse\r\ntarget = NV_MEM_TARGET_PCI;\r\n}\r\n}\r\nflags0 = class;\r\nflags0 |= 0x00003000;\r\nflags2 = 0;\r\nswitch (target) {\r\ncase NV_MEM_TARGET_PCI:\r\nflags0 |= 0x00020000;\r\nbreak;\r\ncase NV_MEM_TARGET_PCI_NOSNOOP:\r\nflags0 |= 0x00030000;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nswitch (access) {\r\ncase NV_MEM_ACCESS_RO:\r\nflags0 |= 0x00004000;\r\nbreak;\r\ncase NV_MEM_ACCESS_WO:\r\nflags0 |= 0x00008000;\r\ndefault:\r\nflags2 |= 0x00000002;\r\nbreak;\r\n}\r\nflags0 |= (base & 0x00000fff) << 20;\r\nflags2 |= (base & 0xfffff000);\r\nret = nouveau_gpuobj_new(dev, chan, 16, 16, NVOBJ_FLAG_ZERO_FREE, &obj);\r\nif (ret)\r\nreturn ret;\r\nnv_wo32(obj, 0x00, flags0);\r\nnv_wo32(obj, 0x04, size - 1);\r\nnv_wo32(obj, 0x08, flags2);\r\nnv_wo32(obj, 0x0c, flags2);\r\nobj->engine = NVOBJ_ENGINE_SW;\r\nobj->class = class;\r\n*pobj = obj;\r\nreturn 0;\r\n}\r\nstatic int\r\nnouveau_gpuobj_sw_new(struct nouveau_channel *chan, u32 handle, u16 class)\r\n{\r\nstruct drm_nouveau_private *dev_priv = chan->dev->dev_private;\r\nstruct nouveau_gpuobj *gpuobj;\r\nint ret;\r\ngpuobj = kzalloc(sizeof(*gpuobj), GFP_KERNEL);\r\nif (!gpuobj)\r\nreturn -ENOMEM;\r\ngpuobj->dev = chan->dev;\r\ngpuobj->engine = NVOBJ_ENGINE_SW;\r\ngpuobj->class = class;\r\nkref_init(&gpuobj->refcount);\r\ngpuobj->cinst = 0x40;\r\nspin_lock(&dev_priv->ramin_lock);\r\nlist_add_tail(&gpuobj->list, &dev_priv->gpuobj_list);\r\nspin_unlock(&dev_priv->ramin_lock);\r\nret = nouveau_ramht_insert(chan, handle, gpuobj);\r\nnouveau_gpuobj_ref(NULL, &gpuobj);\r\nreturn ret;\r\n}\r\nint\r\nnouveau_gpuobj_gr_new(struct nouveau_channel *chan, u32 handle, int class)\r\n{\r\nstruct drm_nouveau_private *dev_priv = chan->dev->dev_private;\r\nstruct drm_device *dev = chan->dev;\r\nstruct nouveau_gpuobj_class *oc;\r\nint ret;\r\nNV_DEBUG(dev, "ch%d class=0x%04x\n", chan->id, class);\r\nlist_for_each_entry(oc, &dev_priv->classes, head) {\r\nstruct nouveau_exec_engine *eng = dev_priv->eng[oc->engine];\r\nif (oc->id != class)\r\ncontinue;\r\nif (oc->engine == NVOBJ_ENGINE_SW)\r\nreturn nouveau_gpuobj_sw_new(chan, handle, class);\r\nif (!chan->engctx[oc->engine]) {\r\nret = eng->context_new(chan, oc->engine);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn eng->object_new(chan, oc->engine, handle, class);\r\n}\r\nNV_ERROR(dev, "illegal object class: 0x%x\n", class);\r\nreturn -EINVAL;\r\n}\r\nstatic int\r\nnouveau_gpuobj_channel_init_pramin(struct nouveau_channel *chan)\r\n{\r\nstruct drm_device *dev = chan->dev;\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nuint32_t size;\r\nuint32_t base;\r\nint ret;\r\nNV_DEBUG(dev, "ch%d\n", chan->id);\r\nsize = 0x2000;\r\nbase = 0;\r\nif (dev_priv->card_type == NV_50) {\r\nsize += 0x1400;\r\nsize += 0x4000;\r\nbase = 0x6000;\r\nsize += 0x8000;\r\nsize += 0x1000;\r\n}\r\nret = nouveau_gpuobj_new(dev, NULL, size, 0x1000, 0, &chan->ramin);\r\nif (ret) {\r\nNV_ERROR(dev, "Error allocating channel PRAMIN: %d\n", ret);\r\nreturn ret;\r\n}\r\nret = drm_mm_init(&chan->ramin_heap, base, size - base);\r\nif (ret) {\r\nNV_ERROR(dev, "Error creating PRAMIN heap: %d\n", ret);\r\nnouveau_gpuobj_ref(NULL, &chan->ramin);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nnvc0_gpuobj_channel_init(struct nouveau_channel *chan, struct nouveau_vm *vm)\r\n{\r\nstruct drm_nouveau_private *dev_priv = chan->dev->dev_private;\r\nstruct drm_device *dev = chan->dev;\r\nstruct nouveau_gpuobj *pgd = NULL;\r\nstruct nouveau_vm_pgd *vpgd;\r\nint ret, i;\r\nret = nouveau_gpuobj_new(dev, NULL, 4096, 0x1000, 0, &chan->ramin);\r\nif (ret)\r\nreturn ret;\r\nif (list_empty(&vm->pgd_list)) {\r\nret = nouveau_gpuobj_new(dev, NULL, 65536, 0x1000, 0, &pgd);\r\nif (ret)\r\nreturn ret;\r\n}\r\nnouveau_vm_ref(vm, &chan->vm, pgd);\r\nnouveau_gpuobj_ref(NULL, &pgd);\r\nvpgd = list_first_entry(&vm->pgd_list, struct nouveau_vm_pgd, head);\r\nnv_wo32(chan->ramin, 0x0200, lower_32_bits(vpgd->obj->vinst));\r\nnv_wo32(chan->ramin, 0x0204, upper_32_bits(vpgd->obj->vinst));\r\nnv_wo32(chan->ramin, 0x0208, 0xffffffff);\r\nnv_wo32(chan->ramin, 0x020c, 0x000000ff);\r\nfor (i = 0; i < dev->mode_config.num_crtc; i++) {\r\nstruct nouveau_bo *bo;\r\nif (dev_priv->card_type >= NV_D0)\r\nbo = nvd0_display_crtc_sema(dev, i);\r\nelse\r\nbo = nv50_display(dev)->crtc[i].sem.bo;\r\nret = nouveau_bo_vma_add(bo, chan->vm, &chan->dispc_vma[i]);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nnouveau_gpuobj_channel_init(struct nouveau_channel *chan,\r\nuint32_t vram_h, uint32_t tt_h)\r\n{\r\nstruct drm_device *dev = chan->dev;\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_fpriv *fpriv = nouveau_fpriv(chan->file_priv);\r\nstruct nouveau_vm *vm = fpriv ? fpriv->vm : dev_priv->chan_vm;\r\nstruct nouveau_gpuobj *vram = NULL, *tt = NULL;\r\nint ret, i;\r\nNV_DEBUG(dev, "ch%d vram=0x%08x tt=0x%08x\n", chan->id, vram_h, tt_h);\r\nif (dev_priv->card_type >= NV_C0)\r\nreturn nvc0_gpuobj_channel_init(chan, vm);\r\nret = nouveau_gpuobj_channel_init_pramin(chan);\r\nif (ret) {\r\nNV_ERROR(dev, "init pramin\n");\r\nreturn ret;\r\n}\r\nif (vm) {\r\nu32 pgd_offs = (dev_priv->chipset == 0x50) ? 0x1400 : 0x0200;\r\nu64 vm_vinst = chan->ramin->vinst + pgd_offs;\r\nu32 vm_pinst = chan->ramin->pinst;\r\nif (vm_pinst != ~0)\r\nvm_pinst += pgd_offs;\r\nret = nouveau_gpuobj_new_fake(dev, vm_pinst, vm_vinst, 0x4000,\r\n0, &chan->vm_pd);\r\nif (ret)\r\nreturn ret;\r\nnouveau_vm_ref(vm, &chan->vm, chan->vm_pd);\r\n}\r\nif (dev_priv->card_type < NV_50) {\r\nnouveau_ramht_ref(dev_priv->ramht, &chan->ramht, NULL);\r\n} else {\r\nstruct nouveau_gpuobj *ramht = NULL;\r\nret = nouveau_gpuobj_new(dev, chan, 0x8000, 16,\r\nNVOBJ_FLAG_ZERO_ALLOC, &ramht);\r\nif (ret)\r\nreturn ret;\r\nret = nouveau_ramht_new(dev, ramht, &chan->ramht);\r\nnouveau_gpuobj_ref(NULL, &ramht);\r\nif (ret)\r\nreturn ret;\r\nfor (i = 0; i < dev->mode_config.num_crtc; i++) {\r\nstruct nouveau_gpuobj *sem = NULL;\r\nstruct nv50_display_crtc *dispc =\r\n&nv50_display(dev)->crtc[i];\r\nu64 offset = dispc->sem.bo->bo.offset;\r\nret = nouveau_gpuobj_dma_new(chan, 0x3d, offset, 0xfff,\r\nNV_MEM_ACCESS_RW,\r\nNV_MEM_TARGET_VRAM, &sem);\r\nif (ret)\r\nreturn ret;\r\nret = nouveau_ramht_insert(chan, NvEvoSema0 + i, sem);\r\nnouveau_gpuobj_ref(NULL, &sem);\r\nif (ret)\r\nreturn ret;\r\n}\r\n}\r\nif (dev_priv->card_type >= NV_50) {\r\nret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,\r\n0, (1ULL << 40), NV_MEM_ACCESS_RW,\r\nNV_MEM_TARGET_VM, &vram);\r\nif (ret) {\r\nNV_ERROR(dev, "Error creating VRAM ctxdma: %d\n", ret);\r\nreturn ret;\r\n}\r\n} else {\r\nret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,\r\n0, dev_priv->fb_available_size,\r\nNV_MEM_ACCESS_RW,\r\nNV_MEM_TARGET_VRAM, &vram);\r\nif (ret) {\r\nNV_ERROR(dev, "Error creating VRAM ctxdma: %d\n", ret);\r\nreturn ret;\r\n}\r\n}\r\nret = nouveau_ramht_insert(chan, vram_h, vram);\r\nnouveau_gpuobj_ref(NULL, &vram);\r\nif (ret) {\r\nNV_ERROR(dev, "Error adding VRAM ctxdma to RAMHT: %d\n", ret);\r\nreturn ret;\r\n}\r\nif (dev_priv->card_type >= NV_50) {\r\nret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,\r\n0, (1ULL << 40), NV_MEM_ACCESS_RW,\r\nNV_MEM_TARGET_VM, &tt);\r\n} else {\r\nret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,\r\n0, dev_priv->gart_info.aper_size,\r\nNV_MEM_ACCESS_RW,\r\nNV_MEM_TARGET_GART, &tt);\r\n}\r\nif (ret) {\r\nNV_ERROR(dev, "Error creating TT ctxdma: %d\n", ret);\r\nreturn ret;\r\n}\r\nret = nouveau_ramht_insert(chan, tt_h, tt);\r\nnouveau_gpuobj_ref(NULL, &tt);\r\nif (ret) {\r\nNV_ERROR(dev, "Error adding TT ctxdma to RAMHT: %d\n", ret);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nnouveau_gpuobj_channel_takedown(struct nouveau_channel *chan)\r\n{\r\nstruct drm_device *dev = chan->dev;\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nint i;\r\nNV_DEBUG(dev, "ch%d\n", chan->id);\r\nif (dev_priv->card_type >= NV_D0) {\r\nfor (i = 0; i < dev->mode_config.num_crtc; i++) {\r\nstruct nouveau_bo *bo = nvd0_display_crtc_sema(dev, i);\r\nnouveau_bo_vma_del(bo, &chan->dispc_vma[i]);\r\n}\r\n} else\r\nif (dev_priv->card_type >= NV_50) {\r\nstruct nv50_display *disp = nv50_display(dev);\r\nfor (i = 0; i < dev->mode_config.num_crtc; i++) {\r\nstruct nv50_display_crtc *dispc = &disp->crtc[i];\r\nnouveau_bo_vma_del(dispc->sem.bo, &chan->dispc_vma[i]);\r\n}\r\n}\r\nnouveau_vm_ref(NULL, &chan->vm, chan->vm_pd);\r\nnouveau_gpuobj_ref(NULL, &chan->vm_pd);\r\nif (drm_mm_initialized(&chan->ramin_heap))\r\ndrm_mm_takedown(&chan->ramin_heap);\r\nnouveau_gpuobj_ref(NULL, &chan->ramin);\r\n}\r\nint\r\nnouveau_gpuobj_suspend(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj *gpuobj;\r\nint i;\r\nlist_for_each_entry(gpuobj, &dev_priv->gpuobj_list, list) {\r\nif (gpuobj->cinst != NVOBJ_CINST_GLOBAL)\r\ncontinue;\r\ngpuobj->suspend = vmalloc(gpuobj->size);\r\nif (!gpuobj->suspend) {\r\nnouveau_gpuobj_resume(dev);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < gpuobj->size; i += 4)\r\ngpuobj->suspend[i/4] = nv_ro32(gpuobj, i);\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nnouveau_gpuobj_resume(struct drm_device *dev)\r\n{\r\nstruct drm_nouveau_private *dev_priv = dev->dev_private;\r\nstruct nouveau_gpuobj *gpuobj;\r\nint i;\r\nlist_for_each_entry(gpuobj, &dev_priv->gpuobj_list, list) {\r\nif (!gpuobj->suspend)\r\ncontinue;\r\nfor (i = 0; i < gpuobj->size; i += 4)\r\nnv_wo32(gpuobj, i, gpuobj->suspend[i/4]);\r\nvfree(gpuobj->suspend);\r\ngpuobj->suspend = NULL;\r\n}\r\ndev_priv->engine.instmem.flush(dev);\r\n}\r\nint nouveau_ioctl_grobj_alloc(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_nouveau_grobj_alloc *init = data;\r\nstruct nouveau_channel *chan;\r\nint ret;\r\nif (init->handle == ~0)\r\nreturn -EINVAL;\r\nchan = nouveau_channel_get(file_priv, init->channel);\r\nif (IS_ERR(chan))\r\nreturn PTR_ERR(chan);\r\nif (nouveau_ramht_find(chan, init->handle)) {\r\nret = -EEXIST;\r\ngoto out;\r\n}\r\nret = nouveau_gpuobj_gr_new(chan, init->handle, init->class);\r\nif (ret) {\r\nNV_ERROR(dev, "Error creating object: %d (%d/0x%08x)\n",\r\nret, init->channel, init->handle);\r\n}\r\nout:\r\nnouveau_channel_put(&chan);\r\nreturn ret;\r\n}\r\nint nouveau_ioctl_gpuobj_free(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_nouveau_gpuobj_free *objfree = data;\r\nstruct nouveau_channel *chan;\r\nint ret;\r\nchan = nouveau_channel_get(file_priv, objfree->channel);\r\nif (IS_ERR(chan))\r\nreturn PTR_ERR(chan);\r\nnouveau_channel_idle(chan);\r\nret = nouveau_ramht_remove(chan, objfree->handle);\r\nnouveau_channel_put(&chan);\r\nreturn ret;\r\n}\r\nu32\r\nnv_ro32(struct nouveau_gpuobj *gpuobj, u32 offset)\r\n{\r\nstruct drm_nouveau_private *dev_priv = gpuobj->dev->dev_private;\r\nstruct drm_device *dev = gpuobj->dev;\r\nunsigned long flags;\r\nif (gpuobj->pinst == ~0 || !dev_priv->ramin_available) {\r\nu64 ptr = gpuobj->vinst + offset;\r\nu32 base = ptr >> 16;\r\nu32 val;\r\nspin_lock_irqsave(&dev_priv->vm_lock, flags);\r\nif (dev_priv->ramin_base != base) {\r\ndev_priv->ramin_base = base;\r\nnv_wr32(dev, 0x001700, dev_priv->ramin_base);\r\n}\r\nval = nv_rd32(dev, 0x700000 + (ptr & 0xffff));\r\nspin_unlock_irqrestore(&dev_priv->vm_lock, flags);\r\nreturn val;\r\n}\r\nreturn nv_ri32(dev, gpuobj->pinst + offset);\r\n}\r\nvoid\r\nnv_wo32(struct nouveau_gpuobj *gpuobj, u32 offset, u32 val)\r\n{\r\nstruct drm_nouveau_private *dev_priv = gpuobj->dev->dev_private;\r\nstruct drm_device *dev = gpuobj->dev;\r\nunsigned long flags;\r\nif (gpuobj->pinst == ~0 || !dev_priv->ramin_available) {\r\nu64 ptr = gpuobj->vinst + offset;\r\nu32 base = ptr >> 16;\r\nspin_lock_irqsave(&dev_priv->vm_lock, flags);\r\nif (dev_priv->ramin_base != base) {\r\ndev_priv->ramin_base = base;\r\nnv_wr32(dev, 0x001700, dev_priv->ramin_base);\r\n}\r\nnv_wr32(dev, 0x700000 + (ptr & 0xffff), val);\r\nspin_unlock_irqrestore(&dev_priv->vm_lock, flags);\r\nreturn;\r\n}\r\nnv_wi32(dev, gpuobj->pinst + offset, val);\r\n}
