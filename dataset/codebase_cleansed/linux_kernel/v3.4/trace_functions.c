static int function_trace_init(struct trace_array *tr)\r\n{\r\nfunc_trace = tr;\r\ntr->cpu = get_cpu();\r\nput_cpu();\r\ntracing_start_cmdline_record();\r\ntracing_start_function_trace();\r\nreturn 0;\r\n}\r\nstatic void function_trace_reset(struct trace_array *tr)\r\n{\r\ntracing_stop_function_trace();\r\ntracing_stop_cmdline_record();\r\n}\r\nstatic void function_trace_start(struct trace_array *tr)\r\n{\r\ntracing_reset_online_cpus(tr);\r\n}\r\nstatic void\r\nfunction_trace_call_preempt_only(unsigned long ip, unsigned long parent_ip)\r\n{\r\nstruct trace_array *tr = func_trace;\r\nstruct trace_array_cpu *data;\r\nunsigned long flags;\r\nlong disabled;\r\nint cpu;\r\nint pc;\r\nif (unlikely(!ftrace_function_enabled))\r\nreturn;\r\npc = preempt_count();\r\npreempt_disable_notrace();\r\nlocal_save_flags(flags);\r\ncpu = raw_smp_processor_id();\r\ndata = tr->data[cpu];\r\ndisabled = atomic_inc_return(&data->disabled);\r\nif (likely(disabled == 1))\r\ntrace_function(tr, ip, parent_ip, flags, pc);\r\natomic_dec(&data->disabled);\r\npreempt_enable_notrace();\r\n}\r\nstatic void\r\nfunction_trace_call(unsigned long ip, unsigned long parent_ip)\r\n{\r\nstruct trace_array *tr = func_trace;\r\nstruct trace_array_cpu *data;\r\nunsigned long flags;\r\nlong disabled;\r\nint cpu;\r\nint pc;\r\nif (unlikely(!ftrace_function_enabled))\r\nreturn;\r\nlocal_irq_save(flags);\r\ncpu = raw_smp_processor_id();\r\ndata = tr->data[cpu];\r\ndisabled = atomic_inc_return(&data->disabled);\r\nif (likely(disabled == 1)) {\r\npc = preempt_count();\r\ntrace_function(tr, ip, parent_ip, flags, pc);\r\n}\r\natomic_dec(&data->disabled);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic void\r\nfunction_stack_trace_call(unsigned long ip, unsigned long parent_ip)\r\n{\r\nstruct trace_array *tr = func_trace;\r\nstruct trace_array_cpu *data;\r\nunsigned long flags;\r\nlong disabled;\r\nint cpu;\r\nint pc;\r\nif (unlikely(!ftrace_function_enabled))\r\nreturn;\r\nlocal_irq_save(flags);\r\ncpu = raw_smp_processor_id();\r\ndata = tr->data[cpu];\r\ndisabled = atomic_inc_return(&data->disabled);\r\nif (likely(disabled == 1)) {\r\npc = preempt_count();\r\ntrace_function(tr, ip, parent_ip, flags, pc);\r\n__trace_stack(tr, flags, 5, pc);\r\n}\r\natomic_dec(&data->disabled);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic void tracing_start_function_trace(void)\r\n{\r\nftrace_function_enabled = 0;\r\nif (trace_flags & TRACE_ITER_PREEMPTONLY)\r\ntrace_ops.func = function_trace_call_preempt_only;\r\nelse\r\ntrace_ops.func = function_trace_call;\r\nif (func_flags.val & TRACE_FUNC_OPT_STACK)\r\nregister_ftrace_function(&trace_stack_ops);\r\nelse\r\nregister_ftrace_function(&trace_ops);\r\nftrace_function_enabled = 1;\r\n}\r\nstatic void tracing_stop_function_trace(void)\r\n{\r\nftrace_function_enabled = 0;\r\nif (func_flags.val & TRACE_FUNC_OPT_STACK)\r\nunregister_ftrace_function(&trace_stack_ops);\r\nelse\r\nunregister_ftrace_function(&trace_ops);\r\n}\r\nstatic int func_set_flag(u32 old_flags, u32 bit, int set)\r\n{\r\nif (bit == TRACE_FUNC_OPT_STACK) {\r\nif (!!set == !!(func_flags.val & TRACE_FUNC_OPT_STACK))\r\nreturn 0;\r\nif (set) {\r\nunregister_ftrace_function(&trace_ops);\r\nregister_ftrace_function(&trace_stack_ops);\r\n} else {\r\nunregister_ftrace_function(&trace_stack_ops);\r\nregister_ftrace_function(&trace_ops);\r\n}\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic void\r\nftrace_traceon(unsigned long ip, unsigned long parent_ip, void **data)\r\n{\r\nlong *count = (long *)data;\r\nif (tracing_is_on())\r\nreturn;\r\nif (!*count)\r\nreturn;\r\nif (*count != -1)\r\n(*count)--;\r\ntracing_on();\r\n}\r\nstatic void\r\nftrace_traceoff(unsigned long ip, unsigned long parent_ip, void **data)\r\n{\r\nlong *count = (long *)data;\r\nif (!tracing_is_on())\r\nreturn;\r\nif (!*count)\r\nreturn;\r\nif (*count != -1)\r\n(*count)--;\r\ntracing_off();\r\n}\r\nstatic int\r\nftrace_trace_onoff_print(struct seq_file *m, unsigned long ip,\r\nstruct ftrace_probe_ops *ops, void *data)\r\n{\r\nlong count = (long)data;\r\nseq_printf(m, "%ps:", (void *)ip);\r\nif (ops == &traceon_probe_ops)\r\nseq_printf(m, "traceon");\r\nelse\r\nseq_printf(m, "traceoff");\r\nif (count == -1)\r\nseq_printf(m, ":unlimited\n");\r\nelse\r\nseq_printf(m, ":count=%ld\n", count);\r\nreturn 0;\r\n}\r\nstatic int\r\nftrace_trace_onoff_unreg(char *glob, char *cmd, char *param)\r\n{\r\nstruct ftrace_probe_ops *ops;\r\nif (strcmp(cmd, "traceon") == 0)\r\nops = &traceon_probe_ops;\r\nelse\r\nops = &traceoff_probe_ops;\r\nunregister_ftrace_function_probe_func(glob, ops);\r\nreturn 0;\r\n}\r\nstatic int\r\nftrace_trace_onoff_callback(struct ftrace_hash *hash,\r\nchar *glob, char *cmd, char *param, int enable)\r\n{\r\nstruct ftrace_probe_ops *ops;\r\nvoid *count = (void *)-1;\r\nchar *number;\r\nint ret;\r\nif (!enable)\r\nreturn -EINVAL;\r\nif (glob[0] == '!')\r\nreturn ftrace_trace_onoff_unreg(glob+1, cmd, param);\r\nif (strcmp(cmd, "traceon") == 0)\r\nops = &traceon_probe_ops;\r\nelse\r\nops = &traceoff_probe_ops;\r\nif (!param)\r\ngoto out_reg;\r\nnumber = strsep(&param, ":");\r\nif (!strlen(number))\r\ngoto out_reg;\r\nret = strict_strtoul(number, 0, (unsigned long *)&count);\r\nif (ret)\r\nreturn ret;\r\nout_reg:\r\nret = register_ftrace_function_probe(glob, ops, count);\r\nreturn ret < 0 ? ret : 0;\r\n}\r\nstatic int __init init_func_cmd_traceon(void)\r\n{\r\nint ret;\r\nret = register_ftrace_command(&ftrace_traceoff_cmd);\r\nif (ret)\r\nreturn ret;\r\nret = register_ftrace_command(&ftrace_traceon_cmd);\r\nif (ret)\r\nunregister_ftrace_command(&ftrace_traceoff_cmd);\r\nreturn ret;\r\n}\r\nstatic inline int init_func_cmd_traceon(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic __init int init_function_trace(void)\r\n{\r\ninit_func_cmd_traceon();\r\nreturn register_tracer(&function_trace);\r\n}
