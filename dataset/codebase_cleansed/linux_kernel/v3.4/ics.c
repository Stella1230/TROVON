static u64 wsp_ics_get_xive(struct wsp_ics *ics, unsigned int irq)\r\n{\r\nunsigned long flags;\r\nu64 xive;\r\nspin_lock_irqsave(&ics->lock, flags);\r\nout_be64(IODA_TBL_ADDR_REG(ics->regs), TBL_SELECT_XIVT | IODA_IRQ(irq));\r\nxive = in_be64(IODA_TBL_DATA_REG(ics->regs));\r\nspin_unlock_irqrestore(&ics->lock, flags);\r\nreturn xive;\r\n}\r\nstatic void wsp_ics_set_xive(struct wsp_ics *ics, unsigned int irq, u64 xive)\r\n{\r\nxive &= ~XIVE_ADDR_MASK;\r\nxive |= (irq & XIVE_ADDR_MASK);\r\nxive |= XIVE_WRITE_ENABLE;\r\nout_be64(XIVE_UPDATE_REG(ics->regs), xive);\r\n}\r\nstatic u64 xive_set_server(u64 xive, unsigned int server)\r\n{\r\nu64 mask = ~(XIVE_SERVER_MASK << XIVE_SERVER_SHIFT);\r\nxive &= mask;\r\nxive |= (server & XIVE_SERVER_MASK) << XIVE_SERVER_SHIFT;\r\nreturn xive;\r\n}\r\nstatic u64 xive_set_priority(u64 xive, unsigned int priority)\r\n{\r\nu64 mask = ~(XIVE_PRIORITY_MASK << XIVE_PRIORITY_SHIFT);\r\nxive &= mask;\r\nxive |= (priority & XIVE_PRIORITY_MASK) << XIVE_PRIORITY_SHIFT;\r\nreturn xive;\r\n}\r\nvoid cpus_on_chip(int chip_id, cpumask_t *mask, cpumask_t *ret)\r\n{\r\nint cpu, chip;\r\nstruct device_node *cpu_dn, *dn;\r\nconst u32 *prop;\r\ncpumask_clear(ret);\r\nfor_each_cpu(cpu, mask) {\r\ncpu_dn = of_get_cpu_node(cpu, NULL);\r\nif (!cpu_dn)\r\ncontinue;\r\nprop = of_get_property(cpu_dn, "at-node", NULL);\r\nif (!prop) {\r\nof_node_put(cpu_dn);\r\ncontinue;\r\n}\r\ndn = of_find_node_by_phandle(*prop);\r\nof_node_put(cpu_dn);\r\nchip = wsp_get_chip_id(dn);\r\nif (chip == chip_id)\r\ncpumask_set_cpu(cpu, ret);\r\nof_node_put(dn);\r\n}\r\n}\r\nstatic int cache_hwirq_map(struct wsp_ics *ics, unsigned int hwirq,\r\nconst cpumask_t *affinity)\r\n{\r\ncpumask_var_t avail, newmask;\r\nint ret = -ENOMEM, cpu, cpu_rover = 0, target;\r\nint index = hwirq - ics->hwirq_start;\r\nunsigned int nodeid;\r\nBUG_ON(index < 0 || index >= ics->count);\r\nif (!ics->hwirq_cpu_map)\r\nreturn -ENOMEM;\r\nif (!distribute_irqs) {\r\nics->hwirq_cpu_map[hwirq - ics->hwirq_start] = xics_default_server;\r\nreturn 0;\r\n}\r\nif (!alloc_cpumask_var(&avail, GFP_KERNEL))\r\ngoto ret;\r\nif (!alloc_cpumask_var(&newmask, GFP_KERNEL))\r\ngoto freeavail;\r\nnodeid = (hwirq >> WSP_ICS_CHIP_SHIFT) & 0x3;\r\nif (affinity)\r\ncpumask_and(avail, cpu_online_mask, affinity);\r\nelse\r\ncpumask_copy(avail, cpu_online_mask);\r\ncpus_on_chip(nodeid, avail, newmask);\r\nif (unlikely(cpumask_empty(newmask))) {\r\nif (unlikely(cpumask_empty(avail))) {\r\nret = -1;\r\ngoto out;\r\n}\r\ncpumask_copy(newmask, avail);\r\n}\r\ntarget = hwirq % cpumask_weight(newmask);\r\nfor_each_cpu(cpu, newmask) {\r\nif (cpu_rover++ >= target) {\r\nics->hwirq_cpu_map[index] = get_hard_smp_processor_id(cpu);\r\nret = 0;\r\ngoto out;\r\n}\r\n}\r\nWARN_ON(1);\r\nout:\r\nfree_cpumask_var(newmask);\r\nfreeavail:\r\nfree_cpumask_var(avail);\r\nret:\r\nif (ret < 0) {\r\nics->hwirq_cpu_map[index] = cpumask_first(cpu_online_mask);\r\npr_warning("Error, falling hwirq 0x%x routing back to CPU %i\n",\r\nhwirq, ics->hwirq_cpu_map[index]);\r\n}\r\nreturn ret;\r\n}\r\nstatic void alloc_irq_map(struct wsp_ics *ics)\r\n{\r\nint i;\r\nics->hwirq_cpu_map = kmalloc(sizeof(int) * ics->count, GFP_KERNEL);\r\nif (!ics->hwirq_cpu_map) {\r\npr_warning("Allocate hwirq_cpu_map failed, "\r\n"IRQ balancing disabled\n");\r\nreturn;\r\n}\r\nfor (i=0; i < ics->count; i++)\r\nics->hwirq_cpu_map[i] = xics_default_server;\r\n}\r\nstatic int get_irq_server(struct wsp_ics *ics, unsigned int hwirq)\r\n{\r\nint index = hwirq - ics->hwirq_start;\r\nBUG_ON(index < 0 || index >= ics->count);\r\nif (!ics->hwirq_cpu_map)\r\nreturn xics_default_server;\r\nreturn ics->hwirq_cpu_map[index];\r\n}\r\nstatic int cache_hwirq_map(struct wsp_ics *ics, unsigned int hwirq,\r\nconst cpumask_t *affinity)\r\n{\r\nreturn 0;\r\n}\r\nstatic int get_irq_server(struct wsp_ics *ics, unsigned int hwirq)\r\n{\r\nreturn xics_default_server;\r\n}\r\nstatic void alloc_irq_map(struct wsp_ics *ics) { }\r\nstatic void wsp_chip_unmask_irq(struct irq_data *d)\r\n{\r\nunsigned int hw_irq = (unsigned int)irqd_to_hwirq(d);\r\nstruct wsp_ics *ics;\r\nint server;\r\nu64 xive;\r\nif (hw_irq == XICS_IPI || hw_irq == XICS_IRQ_SPURIOUS)\r\nreturn;\r\nics = d->chip_data;\r\nif (WARN_ON(!ics))\r\nreturn;\r\nserver = get_irq_server(ics, hw_irq);\r\nxive = wsp_ics_get_xive(ics, hw_irq);\r\nxive = xive_set_server(xive, server);\r\nxive = xive_set_priority(xive, DEFAULT_PRIORITY);\r\nwsp_ics_set_xive(ics, hw_irq, xive);\r\n}\r\nstatic unsigned int wsp_chip_startup(struct irq_data *d)\r\n{\r\nwsp_chip_unmask_irq(d);\r\nreturn 0;\r\n}\r\nstatic void wsp_mask_real_irq(unsigned int hw_irq, struct wsp_ics *ics)\r\n{\r\nu64 xive;\r\nif (hw_irq == XICS_IPI)\r\nreturn;\r\nif (WARN_ON(!ics))\r\nreturn;\r\nxive = wsp_ics_get_xive(ics, hw_irq);\r\nxive = xive_set_server(xive, xics_default_server);\r\nxive = xive_set_priority(xive, LOWEST_PRIORITY);\r\nwsp_ics_set_xive(ics, hw_irq, xive);\r\n}\r\nstatic void wsp_chip_mask_irq(struct irq_data *d)\r\n{\r\nunsigned int hw_irq = (unsigned int)irqd_to_hwirq(d);\r\nstruct wsp_ics *ics = d->chip_data;\r\nif (hw_irq == XICS_IPI || hw_irq == XICS_IRQ_SPURIOUS)\r\nreturn;\r\nwsp_mask_real_irq(hw_irq, ics);\r\n}\r\nstatic int wsp_chip_set_affinity(struct irq_data *d,\r\nconst struct cpumask *cpumask, bool force)\r\n{\r\nunsigned int hw_irq = (unsigned int)irqd_to_hwirq(d);\r\nstruct wsp_ics *ics;\r\nint ret;\r\nu64 xive;\r\nif (hw_irq == XICS_IPI || hw_irq == XICS_IRQ_SPURIOUS)\r\nreturn -1;\r\nics = d->chip_data;\r\nif (WARN_ON(!ics))\r\nreturn -1;\r\nxive = wsp_ics_get_xive(ics, hw_irq);\r\nret = cache_hwirq_map(ics, hw_irq, cpumask);\r\nif (ret == -1) {\r\nchar cpulist[128];\r\ncpumask_scnprintf(cpulist, sizeof(cpulist), cpumask);\r\npr_warning("%s: No online cpus in the mask %s for irq %d\n",\r\n__func__, cpulist, d->irq);\r\nreturn -1;\r\n} else if (ret == -ENOMEM) {\r\npr_warning("%s: Out of memory\n", __func__);\r\nreturn -1;\r\n}\r\nxive = xive_set_server(xive, get_irq_server(ics, hw_irq));\r\nwsp_ics_set_xive(ics, hw_irq, xive);\r\nreturn 0;\r\n}\r\nstatic int wsp_ics_host_match(struct ics *ics, struct device_node *dn)\r\n{\r\nreturn of_device_is_compatible(dn, "ibm,ppc-xics");\r\n}\r\nstatic int wsp_ics_match_hwirq(struct wsp_ics *wsp_ics, unsigned int hwirq)\r\n{\r\nif (hwirq >= wsp_ics->hwirq_start &&\r\nhwirq < wsp_ics->hwirq_start + wsp_ics->count)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int wsp_ics_map(struct ics *ics, unsigned int virq)\r\n{\r\nstruct wsp_ics *wsp_ics = to_wsp_ics(ics);\r\nunsigned int hw_irq = virq_to_hw(virq);\r\nunsigned long flags;\r\nif (!wsp_ics_match_hwirq(wsp_ics, hw_irq))\r\nreturn -ENOENT;\r\nirq_set_chip_and_handler(virq, &wsp_irq_chip, handle_fasteoi_irq);\r\nirq_set_chip_data(virq, wsp_ics);\r\nspin_lock_irqsave(&wsp_ics->lock, flags);\r\nbitmap_allocate_region(wsp_ics->bitmap, hw_irq - wsp_ics->hwirq_start, 0);\r\nspin_unlock_irqrestore(&wsp_ics->lock, flags);\r\nreturn 0;\r\n}\r\nstatic void wsp_ics_mask_unknown(struct ics *ics, unsigned long hw_irq)\r\n{\r\nstruct wsp_ics *wsp_ics = to_wsp_ics(ics);\r\nif (!wsp_ics_match_hwirq(wsp_ics, hw_irq))\r\nreturn;\r\npr_err("%s: IRQ %lu (real) is invalid, disabling it.\n", __func__, hw_irq);\r\nwsp_mask_real_irq(hw_irq, wsp_ics);\r\n}\r\nstatic long wsp_ics_get_server(struct ics *ics, unsigned long hw_irq)\r\n{\r\nstruct wsp_ics *wsp_ics = to_wsp_ics(ics);\r\nif (!wsp_ics_match_hwirq(wsp_ics, hw_irq))\r\nreturn -ENOENT;\r\nreturn get_irq_server(wsp_ics, hw_irq);\r\n}\r\nstatic struct wsp_ics *wsp_ics_find_dn_ics(struct device_node *dn)\r\n{\r\nstruct device_node *iparent;\r\nint i;\r\niparent = of_irq_find_parent(dn);\r\nif (!iparent) {\r\npr_err("wsp_ics: Failed to find interrupt parent!\n");\r\nreturn NULL;\r\n}\r\nfor(i = 0; i < num_ics; i++) {\r\nif(ics_list[i].dn == iparent)\r\nbreak;\r\n}\r\nif (i >= num_ics) {\r\npr_err("wsp_ics: Unable to find parent bitmap!\n");\r\nreturn NULL;\r\n}\r\nreturn &ics_list[i];\r\n}\r\nint wsp_ics_alloc_irq(struct device_node *dn, int num)\r\n{\r\nstruct wsp_ics *ics;\r\nint order, offset;\r\nics = wsp_ics_find_dn_ics(dn);\r\nif (!ics)\r\nreturn -ENODEV;\r\norder = get_count_order(num);\r\nspin_lock_irq(&ics->lock);\r\noffset = bitmap_find_free_region(ics->bitmap, ics->count, order);\r\nspin_unlock_irq(&ics->lock);\r\nif (offset < 0)\r\nreturn offset;\r\nreturn offset + ics->hwirq_start;\r\n}\r\nvoid wsp_ics_free_irq(struct device_node *dn, unsigned int irq)\r\n{\r\nstruct wsp_ics *ics;\r\nics = wsp_ics_find_dn_ics(dn);\r\nif (WARN_ON(!ics))\r\nreturn;\r\nspin_lock_irq(&ics->lock);\r\nbitmap_release_region(ics->bitmap, irq, 0);\r\nspin_unlock_irq(&ics->lock);\r\n}\r\nstatic int __init wsp_ics_bitmap_setup(struct wsp_ics *ics,\r\nstruct device_node *dn)\r\n{\r\nint len, i, j, size;\r\nu32 start, count;\r\nconst u32 *p;\r\nsize = BITS_TO_LONGS(ics->count) * sizeof(long);\r\nics->bitmap = kzalloc(size, GFP_KERNEL);\r\nif (!ics->bitmap) {\r\npr_err("wsp_ics: ENOMEM allocating IRQ bitmap!\n");\r\nreturn -ENOMEM;\r\n}\r\nspin_lock_init(&ics->lock);\r\np = of_get_property(dn, "available-ranges", &len);\r\nif (!p || !len) {\r\npr_err("wsp_ics: No available-ranges defined for %s\n",\r\ndn->full_name);\r\nreturn 0;\r\n}\r\nif (len % (2 * sizeof(u32)) != 0) {\r\npr_err("wsp_ics: Invalid available-ranges for %s\n",\r\ndn->full_name);\r\nreturn 0;\r\n}\r\nbitmap_fill(ics->bitmap, ics->count);\r\nfor (i = 0; i < len / sizeof(u32); i += 2) {\r\nstart = of_read_number(p + i, 1);\r\ncount = of_read_number(p + i + 1, 1);\r\npr_devel("%s: start: %d count: %d\n", __func__, start, count);\r\nif ((start + count) > (ics->hwirq_start + ics->count) ||\r\nstart < ics->hwirq_start) {\r\npr_err("wsp_ics: Invalid range! -> %d to %d\n",\r\nstart, start + count);\r\nbreak;\r\n}\r\nfor (j = 0; j < count; j++)\r\nbitmap_release_region(ics->bitmap,\r\n(start + j) - ics->hwirq_start, 0);\r\n}\r\nbitmap_allocate_region(ics->bitmap, ics->lsi_base,\r\nget_count_order(ics->lsi_count));\r\nreturn 0;\r\n}\r\nstatic int __init wsp_ics_setup(struct wsp_ics *ics, struct device_node *dn)\r\n{\r\nu32 lsi_buid, msi_buid, msi_base, msi_count;\r\nvoid __iomem *regs;\r\nconst u32 *p;\r\nint rc, len, i;\r\nu64 caps, buid;\r\np = of_get_property(dn, "interrupt-ranges", &len);\r\nif (!p || len < (2 * sizeof(u32))) {\r\npr_err("wsp_ics: No/bad interrupt-ranges found on %s\n",\r\ndn->full_name);\r\nreturn -ENOENT;\r\n}\r\nif (len > (2 * sizeof(u32))) {\r\npr_err("wsp_ics: Multiple ics ranges not supported.\n");\r\nreturn -EINVAL;\r\n}\r\nregs = of_iomap(dn, 0);\r\nif (!regs) {\r\npr_err("wsp_ics: of_iomap(%s) failed\n", dn->full_name);\r\nreturn -ENXIO;\r\n}\r\nics->hwirq_start = of_read_number(p, 1);\r\nics->count = of_read_number(p + 1, 1);\r\nics->regs = regs;\r\nics->chip_id = wsp_get_chip_id(dn);\r\nif (WARN_ON(ics->chip_id < 0))\r\nics->chip_id = 0;\r\ncaps = in_be64(ICS_INT_CAPS_REG(ics->regs));\r\nbuid = in_be64(INT_SRC_LAYER_BUID_REG(ics->regs));\r\nics->lsi_count = caps >> 56;\r\nmsi_count = (caps >> 44) & 0x7ff;\r\nlsi_buid = (buid >> 48) & 0x1ff;\r\nics->lsi_base = (ics->chip_id << WSP_ICS_CHIP_SHIFT) | lsi_buid << 5;\r\nmsi_buid = (buid >> 37) & 0x7;\r\nmsi_base = (ics->chip_id << WSP_ICS_CHIP_SHIFT) | msi_buid << 11;\r\npr_info("wsp_ics: Found %s\n", dn->full_name);\r\npr_info("wsp_ics: irq range : 0x%06llx..0x%06llx\n",\r\nics->hwirq_start, ics->hwirq_start + ics->count - 1);\r\npr_info("wsp_ics: %4d LSIs : 0x%06x..0x%06x\n",\r\nics->lsi_count, ics->lsi_base,\r\nics->lsi_base + ics->lsi_count - 1);\r\npr_info("wsp_ics: %4d MSIs : 0x%06x..0x%06x\n",\r\nmsi_count, msi_base,\r\nmsi_base + msi_count - 1);\r\nif (ics->lsi_base < ics->hwirq_start ||\r\n(ics->lsi_base + ics->lsi_count) > (ics->hwirq_start + ics->count))\r\npr_warning("wsp_ics: WARNING ! LSIs out of interrupt-ranges !\n");\r\nif (msi_base < ics->hwirq_start ||\r\n(msi_base + msi_count) > (ics->hwirq_start + ics->count))\r\npr_warning("wsp_ics: WARNING ! MSIs out of interrupt-ranges !\n");\r\nrc = wsp_ics_bitmap_setup(ics, dn);\r\nif (rc) {\r\niounmap(regs);\r\nreturn rc;\r\n}\r\nics->dn = of_node_get(dn);\r\nalloc_irq_map(ics);\r\nfor(i = 0; i < ics->count; i++)\r\nwsp_mask_real_irq(ics->hwirq_start + i, ics);\r\nics->ics.map = wsp_ics_map;\r\nics->ics.mask_unknown = wsp_ics_mask_unknown;\r\nics->ics.get_server = wsp_ics_get_server;\r\nics->ics.host_match = wsp_ics_host_match;\r\nxics_register_ics(&ics->ics);\r\nreturn 0;\r\n}\r\nstatic void __init wsp_ics_set_default_server(void)\r\n{\r\nstruct device_node *np;\r\nu32 hwid;\r\nnp = of_get_cpu_node(boot_cpuid, NULL);\r\nBUG_ON(!np);\r\nhwid = get_hard_smp_processor_id(boot_cpuid);\r\npr_info("wsp_ics: default server is %#x, CPU %s\n", hwid, np->full_name);\r\nxics_default_server = hwid;\r\nof_node_put(np);\r\n}\r\nstatic int __init wsp_ics_init(void)\r\n{\r\nstruct device_node *dn;\r\nstruct wsp_ics *ics;\r\nint rc, found;\r\nwsp_ics_set_default_server();\r\nfound = 0;\r\nfor_each_compatible_node(dn, NULL, "ibm,ppc-xics")\r\nfound++;\r\nif (found == 0) {\r\npr_err("wsp_ics: No ICS's found!\n");\r\nreturn -ENODEV;\r\n}\r\nics_list = kmalloc(sizeof(*ics) * found, GFP_KERNEL);\r\nif (!ics_list) {\r\npr_err("wsp_ics: No memory for structs.\n");\r\nreturn -ENOMEM;\r\n}\r\nnum_ics = 0;\r\nics = ics_list;\r\nfor_each_compatible_node(dn, NULL, "ibm,wsp-xics") {\r\nrc = wsp_ics_setup(ics, dn);\r\nif (rc == 0) {\r\nics++;\r\nnum_ics++;\r\n}\r\n}\r\nif (found != num_ics) {\r\npr_err("wsp_ics: Failed setting up %d ICS's\n",\r\nfound - num_ics);\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nvoid __init wsp_init_irq(void)\r\n{\r\nwsp_ics_init();\r\nxics_init();\r\nwsp_irq_chip.irq_eoi = icp_ops->eoi;\r\n}\r\nstatic void wsp_ics_msi_unmask_irq(struct irq_data *d)\r\n{\r\nwsp_chip_unmask_irq(d);\r\nunmask_msi_irq(d);\r\n}\r\nstatic unsigned int wsp_ics_msi_startup(struct irq_data *d)\r\n{\r\nwsp_ics_msi_unmask_irq(d);\r\nreturn 0;\r\n}\r\nstatic void wsp_ics_msi_mask_irq(struct irq_data *d)\r\n{\r\nmask_msi_irq(d);\r\nwsp_chip_mask_irq(d);\r\n}\r\nstatic void wsp_ics_eoi(struct irq_data *data)\r\n{\r\nwsp_irq_chip.irq_eoi(data);\r\n}\r\nvoid wsp_ics_set_msi_chip(unsigned int irq)\r\n{\r\nirq_set_chip(irq, &wsp_ics_msi);\r\n}\r\nvoid wsp_ics_set_std_chip(unsigned int irq)\r\n{\r\nirq_set_chip(irq, &wsp_irq_chip);\r\n}
