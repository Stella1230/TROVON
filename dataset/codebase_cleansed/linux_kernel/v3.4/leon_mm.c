unsigned long srmmu_swprobe(unsigned long vaddr, unsigned long *paddr)\r\n{\r\nunsigned int ctxtbl;\r\nunsigned int pgd, pmd, ped;\r\nunsigned int ptr;\r\nunsigned int lvl, pte, paddrbase;\r\nunsigned int ctx;\r\nunsigned int paddr_calc;\r\npaddrbase = 0;\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: trace on\n");\r\nctxtbl = srmmu_get_ctable_ptr();\r\nif (!(ctxtbl)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: srmmu_get_ctable_ptr returned 0=>0\n");\r\nreturn 0;\r\n}\r\nif (!_pfn_valid(PFN(ctxtbl))) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO\r\n"swprobe: !_pfn_valid(%x)=>0\n",\r\nPFN(ctxtbl));\r\nreturn 0;\r\n}\r\nctx = srmmu_get_context();\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: --- ctx (%x) ---\n", ctx);\r\npgd = LEON_BYPASS_LOAD_PA(ctxtbl + (ctx * 4));\r\nif (((pgd & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: pgd is entry level 3\n");\r\nlvl = 3;\r\npte = pgd;\r\npaddrbase = pgd & _SRMMU_PTE_PMASK_LEON;\r\ngoto ready;\r\n}\r\nif (((pgd & SRMMU_ET_MASK) != SRMMU_ET_PTD)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: pgd is invalid => 0\n");\r\nreturn 0;\r\n}\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: --- pgd (%x) ---\n", pgd);\r\nptr = (pgd & SRMMU_PTD_PMASK) << 4;\r\nptr += ((((vaddr) >> LEON_PGD_SH) & LEON_PGD_M) * 4);\r\nif (!_pfn_valid(PFN(ptr)))\r\nreturn 0;\r\npmd = LEON_BYPASS_LOAD_PA(ptr);\r\nif (((pmd & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: pmd is entry level 2\n");\r\nlvl = 2;\r\npte = pmd;\r\npaddrbase = pmd & _SRMMU_PTE_PMASK_LEON;\r\ngoto ready;\r\n}\r\nif (((pmd & SRMMU_ET_MASK) != SRMMU_ET_PTD)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: pmd is invalid => 0\n");\r\nreturn 0;\r\n}\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: --- pmd (%x) ---\n", pmd);\r\nptr = (pmd & SRMMU_PTD_PMASK) << 4;\r\nptr += (((vaddr >> LEON_PMD_SH) & LEON_PMD_M) * 4);\r\nif (!_pfn_valid(PFN(ptr))) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: !_pfn_valid(%x)=>0\n",\r\nPFN(ptr));\r\nreturn 0;\r\n}\r\nped = LEON_BYPASS_LOAD_PA(ptr);\r\nif (((ped & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: ped is entry level 1\n");\r\nlvl = 1;\r\npte = ped;\r\npaddrbase = ped & _SRMMU_PTE_PMASK_LEON;\r\ngoto ready;\r\n}\r\nif (((ped & SRMMU_ET_MASK) != SRMMU_ET_PTD)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: ped is invalid => 0\n");\r\nreturn 0;\r\n}\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: --- ped (%x) ---\n", ped);\r\nptr = (ped & SRMMU_PTD_PMASK) << 4;\r\nptr += (((vaddr >> LEON_PTE_SH) & LEON_PTE_M) * 4);\r\nif (!_pfn_valid(PFN(ptr)))\r\nreturn 0;\r\nptr = LEON_BYPASS_LOAD_PA(ptr);\r\nif (((ptr & SRMMU_ET_MASK) == SRMMU_ET_PTE)) {\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: ptr is entry level 0\n");\r\nlvl = 0;\r\npte = ptr;\r\npaddrbase = ptr & _SRMMU_PTE_PMASK_LEON;\r\ngoto ready;\r\n}\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: ptr is invalid => 0\n");\r\nreturn 0;\r\nready:\r\nswitch (lvl) {\r\ncase 0:\r\npaddr_calc =\r\n(vaddr & ~(-1 << LEON_PTE_SH)) | ((pte & ~0xff) << 4);\r\nbreak;\r\ncase 1:\r\npaddr_calc =\r\n(vaddr & ~(-1 << LEON_PMD_SH)) | ((pte & ~0xff) << 4);\r\nbreak;\r\ncase 2:\r\npaddr_calc =\r\n(vaddr & ~(-1 << LEON_PGD_SH)) | ((pte & ~0xff) << 4);\r\nbreak;\r\ndefault:\r\ncase 3:\r\npaddr_calc = vaddr;\r\nbreak;\r\n}\r\nif (srmmu_swprobe_trace)\r\nprintk(KERN_INFO "swprobe: padde %x\n", paddr_calc);\r\nif (paddr)\r\n*paddr = paddr_calc;\r\nreturn pte;\r\n}\r\nvoid leon_flush_icache_all(void)\r\n{\r\n__asm__ __volatile__(" flush ");\r\n}\r\nvoid leon_flush_dcache_all(void)\r\n{\r\n__asm__ __volatile__("sta %%g0, [%%g0] %0\n\t" : :\r\n"i"(ASI_LEON_DFLUSH) : "memory");\r\n}\r\nvoid leon_flush_pcache_all(struct vm_area_struct *vma, unsigned long page)\r\n{\r\nif (vma->vm_flags & VM_EXEC)\r\nleon_flush_icache_all();\r\nleon_flush_dcache_all();\r\n}\r\nvoid leon_flush_cache_all(void)\r\n{\r\n__asm__ __volatile__(" flush ");\r\n__asm__ __volatile__("sta %%g0, [%%g0] %0\n\t" : :\r\n"i"(ASI_LEON_DFLUSH) : "memory");\r\n}\r\nvoid leon_flush_tlb_all(void)\r\n{\r\nleon_flush_cache_all();\r\n__asm__ __volatile__("sta %%g0, [%0] %1\n\t" : : "r"(0x400),\r\n"i"(ASI_LEON_MMUFLUSH) : "memory");\r\n}\r\nvoid leon3_getCacheRegs(struct leon3_cacheregs *regs)\r\n{\r\nunsigned long ccr, iccr, dccr;\r\nif (!regs)\r\nreturn;\r\n__asm__ __volatile__("lda [%%g0] %3, %0\n\t"\r\n"mov 0x08, %%g1\n\t"\r\n"lda [%%g1] %3, %1\n\t"\r\n"mov 0x0c, %%g1\n\t"\r\n"lda [%%g1] %3, %2\n\t"\r\n: "=r"(ccr), "=r"(iccr), "=r"(dccr)\r\n: "i"(ASI_LEON_CACHEREGS)\r\n: "g1"\r\n);\r\nregs->ccr = ccr;\r\nregs->iccr = iccr;\r\nregs->dccr = dccr;\r\n}\r\nint __init leon_flush_needed(void)\r\n{\r\nint flush_needed = -1;\r\nunsigned int ssize, sets;\r\nchar *setStr[4] =\r\n{ "direct mapped", "2-way associative", "3-way associative",\r\n"4-way associative"\r\n};\r\nstruct leon3_cacheregs cregs;\r\nleon3_getCacheRegs(&cregs);\r\nsets = (cregs.dccr & LEON3_XCCR_SETS_MASK) >> 24;\r\nssize = 1 << ((cregs.dccr & LEON3_XCCR_SSIZE_MASK) >> 20);\r\nprintk(KERN_INFO "CACHE: %s cache, set size %dk\n",\r\nsets > 3 ? "unknown" : setStr[sets], ssize);\r\nif ((ssize <= (PAGE_SIZE / 1024)) && (sets == 0)) {\r\nflush_needed = 0;\r\nprintk(KERN_INFO "CACHE: not flushing on every context switch\n");\r\n}\r\nreturn flush_needed;\r\n}\r\nvoid leon_switch_mm(void)\r\n{\r\nflush_tlb_mm((void *)0);\r\nif (leon_flush_during_switch)\r\nleon_flush_cache_all();\r\n}
