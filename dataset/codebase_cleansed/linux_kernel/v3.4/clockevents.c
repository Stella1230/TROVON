u64 clockevent_delta2ns(unsigned long latch, struct clock_event_device *evt)\r\n{\r\nu64 clc = (u64) latch << evt->shift;\r\nif (unlikely(!evt->mult)) {\r\nevt->mult = 1;\r\nWARN_ON(1);\r\n}\r\ndo_div(clc, evt->mult);\r\nif (clc < 1000)\r\nclc = 1000;\r\nif (clc > KTIME_MAX)\r\nclc = KTIME_MAX;\r\nreturn clc;\r\n}\r\nvoid clockevents_set_mode(struct clock_event_device *dev,\r\nenum clock_event_mode mode)\r\n{\r\nif (dev->mode != mode) {\r\ndev->set_mode(mode, dev);\r\ndev->mode = mode;\r\nif (mode == CLOCK_EVT_MODE_ONESHOT) {\r\nif (unlikely(!dev->mult)) {\r\ndev->mult = 1;\r\nWARN_ON(1);\r\n}\r\n}\r\n}\r\n}\r\nvoid clockevents_shutdown(struct clock_event_device *dev)\r\n{\r\nclockevents_set_mode(dev, CLOCK_EVT_MODE_SHUTDOWN);\r\ndev->next_event.tv64 = KTIME_MAX;\r\n}\r\nstatic int clockevents_increase_min_delta(struct clock_event_device *dev)\r\n{\r\nif (dev->min_delta_ns >= MIN_DELTA_LIMIT) {\r\nprintk(KERN_WARNING "CE: Reprogramming failure. Giving up\n");\r\ndev->next_event.tv64 = KTIME_MAX;\r\nreturn -ETIME;\r\n}\r\nif (dev->min_delta_ns < 5000)\r\ndev->min_delta_ns = 5000;\r\nelse\r\ndev->min_delta_ns += dev->min_delta_ns >> 1;\r\nif (dev->min_delta_ns > MIN_DELTA_LIMIT)\r\ndev->min_delta_ns = MIN_DELTA_LIMIT;\r\nprintk(KERN_WARNING "CE: %s increased min_delta_ns to %llu nsec\n",\r\ndev->name ? dev->name : "?",\r\n(unsigned long long) dev->min_delta_ns);\r\nreturn 0;\r\n}\r\nstatic int clockevents_program_min_delta(struct clock_event_device *dev)\r\n{\r\nunsigned long long clc;\r\nint64_t delta;\r\nint i;\r\nfor (i = 0;;) {\r\ndelta = dev->min_delta_ns;\r\ndev->next_event = ktime_add_ns(ktime_get(), delta);\r\nif (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)\r\nreturn 0;\r\ndev->retries++;\r\nclc = ((unsigned long long) delta * dev->mult) >> dev->shift;\r\nif (dev->set_next_event((unsigned long) clc, dev) == 0)\r\nreturn 0;\r\nif (++i > 2) {\r\nif (clockevents_increase_min_delta(dev))\r\nreturn -ETIME;\r\ni = 0;\r\n}\r\n}\r\n}\r\nstatic int clockevents_program_min_delta(struct clock_event_device *dev)\r\n{\r\nunsigned long long clc;\r\nint64_t delta;\r\ndelta = dev->min_delta_ns;\r\ndev->next_event = ktime_add_ns(ktime_get(), delta);\r\nif (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)\r\nreturn 0;\r\ndev->retries++;\r\nclc = ((unsigned long long) delta * dev->mult) >> dev->shift;\r\nreturn dev->set_next_event((unsigned long) clc, dev);\r\n}\r\nint clockevents_program_event(struct clock_event_device *dev, ktime_t expires,\r\nbool force)\r\n{\r\nunsigned long long clc;\r\nint64_t delta;\r\nint rc;\r\nif (unlikely(expires.tv64 < 0)) {\r\nWARN_ON_ONCE(1);\r\nreturn -ETIME;\r\n}\r\ndev->next_event = expires;\r\nif (dev->mode == CLOCK_EVT_MODE_SHUTDOWN)\r\nreturn 0;\r\nif (dev->features & CLOCK_EVT_FEAT_KTIME)\r\nreturn dev->set_next_ktime(expires, dev);\r\ndelta = ktime_to_ns(ktime_sub(expires, ktime_get()));\r\nif (delta <= 0)\r\nreturn force ? clockevents_program_min_delta(dev) : -ETIME;\r\ndelta = min(delta, (int64_t) dev->max_delta_ns);\r\ndelta = max(delta, (int64_t) dev->min_delta_ns);\r\nclc = ((unsigned long long) delta * dev->mult) >> dev->shift;\r\nrc = dev->set_next_event((unsigned long) clc, dev);\r\nreturn (rc && force) ? clockevents_program_min_delta(dev) : rc;\r\n}\r\nint clockevents_register_notifier(struct notifier_block *nb)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nraw_spin_lock_irqsave(&clockevents_lock, flags);\r\nret = raw_notifier_chain_register(&clockevents_chain, nb);\r\nraw_spin_unlock_irqrestore(&clockevents_lock, flags);\r\nreturn ret;\r\n}\r\nstatic void clockevents_do_notify(unsigned long reason, void *dev)\r\n{\r\nraw_notifier_call_chain(&clockevents_chain, reason, dev);\r\n}\r\nstatic void clockevents_notify_released(void)\r\n{\r\nstruct clock_event_device *dev;\r\nwhile (!list_empty(&clockevents_released)) {\r\ndev = list_entry(clockevents_released.next,\r\nstruct clock_event_device, list);\r\nlist_del(&dev->list);\r\nlist_add(&dev->list, &clockevent_devices);\r\nclockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);\r\n}\r\n}\r\nvoid clockevents_register_device(struct clock_event_device *dev)\r\n{\r\nunsigned long flags;\r\nBUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);\r\nif (!dev->cpumask) {\r\nWARN_ON(num_possible_cpus() > 1);\r\ndev->cpumask = cpumask_of(smp_processor_id());\r\n}\r\nraw_spin_lock_irqsave(&clockevents_lock, flags);\r\nlist_add(&dev->list, &clockevent_devices);\r\nclockevents_do_notify(CLOCK_EVT_NOTIFY_ADD, dev);\r\nclockevents_notify_released();\r\nraw_spin_unlock_irqrestore(&clockevents_lock, flags);\r\n}\r\nstatic void clockevents_config(struct clock_event_device *dev,\r\nu32 freq)\r\n{\r\nu64 sec;\r\nif (!(dev->features & CLOCK_EVT_FEAT_ONESHOT))\r\nreturn;\r\nsec = dev->max_delta_ticks;\r\ndo_div(sec, freq);\r\nif (!sec)\r\nsec = 1;\r\nelse if (sec > 600 && dev->max_delta_ticks > UINT_MAX)\r\nsec = 600;\r\nclockevents_calc_mult_shift(dev, freq, sec);\r\ndev->min_delta_ns = clockevent_delta2ns(dev->min_delta_ticks, dev);\r\ndev->max_delta_ns = clockevent_delta2ns(dev->max_delta_ticks, dev);\r\n}\r\nvoid clockevents_config_and_register(struct clock_event_device *dev,\r\nu32 freq, unsigned long min_delta,\r\nunsigned long max_delta)\r\n{\r\ndev->min_delta_ticks = min_delta;\r\ndev->max_delta_ticks = max_delta;\r\nclockevents_config(dev, freq);\r\nclockevents_register_device(dev);\r\n}\r\nint clockevents_update_freq(struct clock_event_device *dev, u32 freq)\r\n{\r\nclockevents_config(dev, freq);\r\nif (dev->mode != CLOCK_EVT_MODE_ONESHOT)\r\nreturn 0;\r\nreturn clockevents_program_event(dev, dev->next_event, false);\r\n}\r\nvoid clockevents_handle_noop(struct clock_event_device *dev)\r\n{\r\n}\r\nvoid clockevents_exchange_device(struct clock_event_device *old,\r\nstruct clock_event_device *new)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nif (old) {\r\nclockevents_set_mode(old, CLOCK_EVT_MODE_UNUSED);\r\nlist_del(&old->list);\r\nlist_add(&old->list, &clockevents_released);\r\n}\r\nif (new) {\r\nBUG_ON(new->mode != CLOCK_EVT_MODE_UNUSED);\r\nclockevents_shutdown(new);\r\n}\r\nlocal_irq_restore(flags);\r\n}\r\nvoid clockevents_notify(unsigned long reason, void *arg)\r\n{\r\nstruct clock_event_device *dev, *tmp;\r\nunsigned long flags;\r\nint cpu;\r\nraw_spin_lock_irqsave(&clockevents_lock, flags);\r\nclockevents_do_notify(reason, arg);\r\nswitch (reason) {\r\ncase CLOCK_EVT_NOTIFY_CPU_DEAD:\r\nlist_for_each_entry_safe(dev, tmp, &clockevents_released, list)\r\nlist_del(&dev->list);\r\ncpu = *((int *)arg);\r\nlist_for_each_entry_safe(dev, tmp, &clockevent_devices, list) {\r\nif (cpumask_test_cpu(cpu, dev->cpumask) &&\r\ncpumask_weight(dev->cpumask) == 1 &&\r\n!tick_is_broadcast_device(dev)) {\r\nBUG_ON(dev->mode != CLOCK_EVT_MODE_UNUSED);\r\nlist_del(&dev->list);\r\n}\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nraw_spin_unlock_irqrestore(&clockevents_lock, flags);\r\n}
