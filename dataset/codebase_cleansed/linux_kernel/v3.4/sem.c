void sem_init_ns(struct ipc_namespace *ns)\r\n{\r\nns->sc_semmsl = SEMMSL;\r\nns->sc_semmns = SEMMNS;\r\nns->sc_semopm = SEMOPM;\r\nns->sc_semmni = SEMMNI;\r\nns->used_sems = 0;\r\nipc_init_ids(&ns->ids[IPC_SEM_IDS]);\r\n}\r\nvoid sem_exit_ns(struct ipc_namespace *ns)\r\n{\r\nfree_ipcs(ns, &sem_ids(ns), freeary);\r\nidr_destroy(&ns->ids[IPC_SEM_IDS].ipcs_idr);\r\n}\r\nvoid __init sem_init (void)\r\n{\r\nsem_init_ns(&init_ipc_ns);\r\nipc_init_proc_interface("sysvipc/sem",\r\n" key semid perms nsems uid gid cuid cgid otime ctime\n",\r\nIPC_SEM_IDS, sysvipc_sem_proc_show);\r\n}\r\nstatic inline struct sem_array *sem_lock(struct ipc_namespace *ns, int id)\r\n{\r\nstruct kern_ipc_perm *ipcp = ipc_lock(&sem_ids(ns), id);\r\nif (IS_ERR(ipcp))\r\nreturn (struct sem_array *)ipcp;\r\nreturn container_of(ipcp, struct sem_array, sem_perm);\r\n}\r\nstatic inline struct sem_array *sem_lock_check(struct ipc_namespace *ns,\r\nint id)\r\n{\r\nstruct kern_ipc_perm *ipcp = ipc_lock_check(&sem_ids(ns), id);\r\nif (IS_ERR(ipcp))\r\nreturn (struct sem_array *)ipcp;\r\nreturn container_of(ipcp, struct sem_array, sem_perm);\r\n}\r\nstatic inline void sem_lock_and_putref(struct sem_array *sma)\r\n{\r\nipc_lock_by_ptr(&sma->sem_perm);\r\nipc_rcu_putref(sma);\r\n}\r\nstatic inline void sem_getref_and_unlock(struct sem_array *sma)\r\n{\r\nipc_rcu_getref(sma);\r\nipc_unlock(&(sma)->sem_perm);\r\n}\r\nstatic inline void sem_putref(struct sem_array *sma)\r\n{\r\nipc_lock_by_ptr(&sma->sem_perm);\r\nipc_rcu_putref(sma);\r\nipc_unlock(&(sma)->sem_perm);\r\n}\r\nstatic inline void sem_rmid(struct ipc_namespace *ns, struct sem_array *s)\r\n{\r\nipc_rmid(&sem_ids(ns), &s->sem_perm);\r\n}\r\nstatic int newary(struct ipc_namespace *ns, struct ipc_params *params)\r\n{\r\nint id;\r\nint retval;\r\nstruct sem_array *sma;\r\nint size;\r\nkey_t key = params->key;\r\nint nsems = params->u.nsems;\r\nint semflg = params->flg;\r\nint i;\r\nif (!nsems)\r\nreturn -EINVAL;\r\nif (ns->used_sems + nsems > ns->sc_semmns)\r\nreturn -ENOSPC;\r\nsize = sizeof (*sma) + nsems * sizeof (struct sem);\r\nsma = ipc_rcu_alloc(size);\r\nif (!sma) {\r\nreturn -ENOMEM;\r\n}\r\nmemset (sma, 0, size);\r\nsma->sem_perm.mode = (semflg & S_IRWXUGO);\r\nsma->sem_perm.key = key;\r\nsma->sem_perm.security = NULL;\r\nretval = security_sem_alloc(sma);\r\nif (retval) {\r\nipc_rcu_putref(sma);\r\nreturn retval;\r\n}\r\nid = ipc_addid(&sem_ids(ns), &sma->sem_perm, ns->sc_semmni);\r\nif (id < 0) {\r\nsecurity_sem_free(sma);\r\nipc_rcu_putref(sma);\r\nreturn id;\r\n}\r\nns->used_sems += nsems;\r\nsma->sem_base = (struct sem *) &sma[1];\r\nfor (i = 0; i < nsems; i++)\r\nINIT_LIST_HEAD(&sma->sem_base[i].sem_pending);\r\nsma->complex_count = 0;\r\nINIT_LIST_HEAD(&sma->sem_pending);\r\nINIT_LIST_HEAD(&sma->list_id);\r\nsma->sem_nsems = nsems;\r\nsma->sem_ctime = get_seconds();\r\nsem_unlock(sma);\r\nreturn sma->sem_perm.id;\r\n}\r\nstatic inline int sem_security(struct kern_ipc_perm *ipcp, int semflg)\r\n{\r\nstruct sem_array *sma;\r\nsma = container_of(ipcp, struct sem_array, sem_perm);\r\nreturn security_sem_associate(sma, semflg);\r\n}\r\nstatic inline int sem_more_checks(struct kern_ipc_perm *ipcp,\r\nstruct ipc_params *params)\r\n{\r\nstruct sem_array *sma;\r\nsma = container_of(ipcp, struct sem_array, sem_perm);\r\nif (params->u.nsems > sma->sem_nsems)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int try_atomic_semop (struct sem_array * sma, struct sembuf * sops,\r\nint nsops, struct sem_undo *un, int pid)\r\n{\r\nint result, sem_op;\r\nstruct sembuf *sop;\r\nstruct sem * curr;\r\nfor (sop = sops; sop < sops + nsops; sop++) {\r\ncurr = sma->sem_base + sop->sem_num;\r\nsem_op = sop->sem_op;\r\nresult = curr->semval;\r\nif (!sem_op && result)\r\ngoto would_block;\r\nresult += sem_op;\r\nif (result < 0)\r\ngoto would_block;\r\nif (result > SEMVMX)\r\ngoto out_of_range;\r\nif (sop->sem_flg & SEM_UNDO) {\r\nint undo = un->semadj[sop->sem_num] - sem_op;\r\nif (undo < (-SEMAEM - 1) || undo > SEMAEM)\r\ngoto out_of_range;\r\n}\r\ncurr->semval = result;\r\n}\r\nsop--;\r\nwhile (sop >= sops) {\r\nsma->sem_base[sop->sem_num].sempid = pid;\r\nif (sop->sem_flg & SEM_UNDO)\r\nun->semadj[sop->sem_num] -= sop->sem_op;\r\nsop--;\r\n}\r\nreturn 0;\r\nout_of_range:\r\nresult = -ERANGE;\r\ngoto undo;\r\nwould_block:\r\nif (sop->sem_flg & IPC_NOWAIT)\r\nresult = -EAGAIN;\r\nelse\r\nresult = 1;\r\nundo:\r\nsop--;\r\nwhile (sop >= sops) {\r\nsma->sem_base[sop->sem_num].semval -= sop->sem_op;\r\nsop--;\r\n}\r\nreturn result;\r\n}\r\nstatic void wake_up_sem_queue_prepare(struct list_head *pt,\r\nstruct sem_queue *q, int error)\r\n{\r\nif (list_empty(pt)) {\r\npreempt_disable();\r\n}\r\nq->status = IN_WAKEUP;\r\nq->pid = error;\r\nlist_add_tail(&q->simple_list, pt);\r\n}\r\nstatic void wake_up_sem_queue_do(struct list_head *pt)\r\n{\r\nstruct sem_queue *q, *t;\r\nint did_something;\r\ndid_something = !list_empty(pt);\r\nlist_for_each_entry_safe(q, t, pt, simple_list) {\r\nwake_up_process(q->sleeper);\r\nsmp_wmb();\r\nq->status = q->pid;\r\n}\r\nif (did_something)\r\npreempt_enable();\r\n}\r\nstatic void unlink_queue(struct sem_array *sma, struct sem_queue *q)\r\n{\r\nlist_del(&q->list);\r\nif (q->nsops == 1)\r\nlist_del(&q->simple_list);\r\nelse\r\nsma->complex_count--;\r\n}\r\nstatic int check_restart(struct sem_array *sma, struct sem_queue *q)\r\n{\r\nstruct sem *curr;\r\nstruct sem_queue *h;\r\nif (q->alter == 0)\r\nreturn 0;\r\nif (sma->complex_count)\r\nreturn 1;\r\nif (q->nsops > 1)\r\nreturn 1;\r\ncurr = sma->sem_base + q->sops[0].sem_num;\r\nif (list_empty(&curr->sem_pending))\r\nreturn 0;\r\nif (curr->semval) {\r\nBUG_ON(q->sops[0].sem_op >= 0);\r\nreturn 0;\r\n}\r\nh = list_first_entry(&curr->sem_pending, struct sem_queue, simple_list);\r\nBUG_ON(h->nsops != 1);\r\nBUG_ON(h->sops[0].sem_num != q->sops[0].sem_num);\r\nif (h->sops[0].sem_op == 0)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int update_queue(struct sem_array *sma, int semnum, struct list_head *pt)\r\n{\r\nstruct sem_queue *q;\r\nstruct list_head *walk;\r\nstruct list_head *pending_list;\r\nint offset;\r\nint semop_completed = 0;\r\nif (sma->complex_count)\r\nsemnum = -1;\r\nif (semnum == -1) {\r\npending_list = &sma->sem_pending;\r\noffset = offsetof(struct sem_queue, list);\r\n} else {\r\npending_list = &sma->sem_base[semnum].sem_pending;\r\noffset = offsetof(struct sem_queue, simple_list);\r\n}\r\nagain:\r\nwalk = pending_list->next;\r\nwhile (walk != pending_list) {\r\nint error, restart;\r\nq = (struct sem_queue *)((char *)walk - offset);\r\nwalk = walk->next;\r\nif (semnum != -1 && sma->sem_base[semnum].semval == 0 &&\r\nq->alter)\r\nbreak;\r\nerror = try_atomic_semop(sma, q->sops, q->nsops,\r\nq->undo, q->pid);\r\nif (error > 0)\r\ncontinue;\r\nunlink_queue(sma, q);\r\nif (error) {\r\nrestart = 0;\r\n} else {\r\nsemop_completed = 1;\r\nrestart = check_restart(sma, q);\r\n}\r\nwake_up_sem_queue_prepare(pt, q, error);\r\nif (restart)\r\ngoto again;\r\n}\r\nreturn semop_completed;\r\n}\r\nstatic void do_smart_update(struct sem_array *sma, struct sembuf *sops, int nsops,\r\nint otime, struct list_head *pt)\r\n{\r\nint i;\r\nif (sma->complex_count || sops == NULL) {\r\nif (update_queue(sma, -1, pt))\r\notime = 1;\r\ngoto done;\r\n}\r\nfor (i = 0; i < nsops; i++) {\r\nif (sops[i].sem_op > 0 ||\r\n(sops[i].sem_op < 0 &&\r\nsma->sem_base[sops[i].sem_num].semval == 0))\r\nif (update_queue(sma, sops[i].sem_num, pt))\r\notime = 1;\r\n}\r\ndone:\r\nif (otime)\r\nsma->sem_otime = get_seconds();\r\n}\r\nstatic int count_semncnt (struct sem_array * sma, ushort semnum)\r\n{\r\nint semncnt;\r\nstruct sem_queue * q;\r\nsemncnt = 0;\r\nlist_for_each_entry(q, &sma->sem_pending, list) {\r\nstruct sembuf * sops = q->sops;\r\nint nsops = q->nsops;\r\nint i;\r\nfor (i = 0; i < nsops; i++)\r\nif (sops[i].sem_num == semnum\r\n&& (sops[i].sem_op < 0)\r\n&& !(sops[i].sem_flg & IPC_NOWAIT))\r\nsemncnt++;\r\n}\r\nreturn semncnt;\r\n}\r\nstatic int count_semzcnt (struct sem_array * sma, ushort semnum)\r\n{\r\nint semzcnt;\r\nstruct sem_queue * q;\r\nsemzcnt = 0;\r\nlist_for_each_entry(q, &sma->sem_pending, list) {\r\nstruct sembuf * sops = q->sops;\r\nint nsops = q->nsops;\r\nint i;\r\nfor (i = 0; i < nsops; i++)\r\nif (sops[i].sem_num == semnum\r\n&& (sops[i].sem_op == 0)\r\n&& !(sops[i].sem_flg & IPC_NOWAIT))\r\nsemzcnt++;\r\n}\r\nreturn semzcnt;\r\n}\r\nstatic void freeary(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)\r\n{\r\nstruct sem_undo *un, *tu;\r\nstruct sem_queue *q, *tq;\r\nstruct sem_array *sma = container_of(ipcp, struct sem_array, sem_perm);\r\nstruct list_head tasks;\r\nassert_spin_locked(&sma->sem_perm.lock);\r\nlist_for_each_entry_safe(un, tu, &sma->list_id, list_id) {\r\nlist_del(&un->list_id);\r\nspin_lock(&un->ulp->lock);\r\nun->semid = -1;\r\nlist_del_rcu(&un->list_proc);\r\nspin_unlock(&un->ulp->lock);\r\nkfree_rcu(un, rcu);\r\n}\r\nINIT_LIST_HEAD(&tasks);\r\nlist_for_each_entry_safe(q, tq, &sma->sem_pending, list) {\r\nunlink_queue(sma, q);\r\nwake_up_sem_queue_prepare(&tasks, q, -EIDRM);\r\n}\r\nsem_rmid(ns, sma);\r\nsem_unlock(sma);\r\nwake_up_sem_queue_do(&tasks);\r\nns->used_sems -= sma->sem_nsems;\r\nsecurity_sem_free(sma);\r\nipc_rcu_putref(sma);\r\n}\r\nstatic unsigned long copy_semid_to_user(void __user *buf, struct semid64_ds *in, int version)\r\n{\r\nswitch(version) {\r\ncase IPC_64:\r\nreturn copy_to_user(buf, in, sizeof(*in));\r\ncase IPC_OLD:\r\n{\r\nstruct semid_ds out;\r\nmemset(&out, 0, sizeof(out));\r\nipc64_perm_to_ipc_perm(&in->sem_perm, &out.sem_perm);\r\nout.sem_otime = in->sem_otime;\r\nout.sem_ctime = in->sem_ctime;\r\nout.sem_nsems = in->sem_nsems;\r\nreturn copy_to_user(buf, &out, sizeof(out));\r\n}\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int semctl_nolock(struct ipc_namespace *ns, int semid,\r\nint cmd, int version, union semun arg)\r\n{\r\nint err;\r\nstruct sem_array *sma;\r\nswitch(cmd) {\r\ncase IPC_INFO:\r\ncase SEM_INFO:\r\n{\r\nstruct seminfo seminfo;\r\nint max_id;\r\nerr = security_sem_semctl(NULL, cmd);\r\nif (err)\r\nreturn err;\r\nmemset(&seminfo,0,sizeof(seminfo));\r\nseminfo.semmni = ns->sc_semmni;\r\nseminfo.semmns = ns->sc_semmns;\r\nseminfo.semmsl = ns->sc_semmsl;\r\nseminfo.semopm = ns->sc_semopm;\r\nseminfo.semvmx = SEMVMX;\r\nseminfo.semmnu = SEMMNU;\r\nseminfo.semmap = SEMMAP;\r\nseminfo.semume = SEMUME;\r\ndown_read(&sem_ids(ns).rw_mutex);\r\nif (cmd == SEM_INFO) {\r\nseminfo.semusz = sem_ids(ns).in_use;\r\nseminfo.semaem = ns->used_sems;\r\n} else {\r\nseminfo.semusz = SEMUSZ;\r\nseminfo.semaem = SEMAEM;\r\n}\r\nmax_id = ipc_get_maxid(&sem_ids(ns));\r\nup_read(&sem_ids(ns).rw_mutex);\r\nif (copy_to_user (arg.__buf, &seminfo, sizeof(struct seminfo)))\r\nreturn -EFAULT;\r\nreturn (max_id < 0) ? 0: max_id;\r\n}\r\ncase IPC_STAT:\r\ncase SEM_STAT:\r\n{\r\nstruct semid64_ds tbuf;\r\nint id;\r\nif (cmd == SEM_STAT) {\r\nsma = sem_lock(ns, semid);\r\nif (IS_ERR(sma))\r\nreturn PTR_ERR(sma);\r\nid = sma->sem_perm.id;\r\n} else {\r\nsma = sem_lock_check(ns, semid);\r\nif (IS_ERR(sma))\r\nreturn PTR_ERR(sma);\r\nid = 0;\r\n}\r\nerr = -EACCES;\r\nif (ipcperms(ns, &sma->sem_perm, S_IRUGO))\r\ngoto out_unlock;\r\nerr = security_sem_semctl(sma, cmd);\r\nif (err)\r\ngoto out_unlock;\r\nmemset(&tbuf, 0, sizeof(tbuf));\r\nkernel_to_ipc64_perm(&sma->sem_perm, &tbuf.sem_perm);\r\ntbuf.sem_otime = sma->sem_otime;\r\ntbuf.sem_ctime = sma->sem_ctime;\r\ntbuf.sem_nsems = sma->sem_nsems;\r\nsem_unlock(sma);\r\nif (copy_semid_to_user (arg.buf, &tbuf, version))\r\nreturn -EFAULT;\r\nreturn id;\r\n}\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nout_unlock:\r\nsem_unlock(sma);\r\nreturn err;\r\n}\r\nstatic int semctl_main(struct ipc_namespace *ns, int semid, int semnum,\r\nint cmd, int version, union semun arg)\r\n{\r\nstruct sem_array *sma;\r\nstruct sem* curr;\r\nint err;\r\nushort fast_sem_io[SEMMSL_FAST];\r\nushort* sem_io = fast_sem_io;\r\nint nsems;\r\nstruct list_head tasks;\r\nsma = sem_lock_check(ns, semid);\r\nif (IS_ERR(sma))\r\nreturn PTR_ERR(sma);\r\nINIT_LIST_HEAD(&tasks);\r\nnsems = sma->sem_nsems;\r\nerr = -EACCES;\r\nif (ipcperms(ns, &sma->sem_perm,\r\n(cmd == SETVAL || cmd == SETALL) ? S_IWUGO : S_IRUGO))\r\ngoto out_unlock;\r\nerr = security_sem_semctl(sma, cmd);\r\nif (err)\r\ngoto out_unlock;\r\nerr = -EACCES;\r\nswitch (cmd) {\r\ncase GETALL:\r\n{\r\nushort __user *array = arg.array;\r\nint i;\r\nif(nsems > SEMMSL_FAST) {\r\nsem_getref_and_unlock(sma);\r\nsem_io = ipc_alloc(sizeof(ushort)*nsems);\r\nif(sem_io == NULL) {\r\nsem_putref(sma);\r\nreturn -ENOMEM;\r\n}\r\nsem_lock_and_putref(sma);\r\nif (sma->sem_perm.deleted) {\r\nsem_unlock(sma);\r\nerr = -EIDRM;\r\ngoto out_free;\r\n}\r\n}\r\nfor (i = 0; i < sma->sem_nsems; i++)\r\nsem_io[i] = sma->sem_base[i].semval;\r\nsem_unlock(sma);\r\nerr = 0;\r\nif(copy_to_user(array, sem_io, nsems*sizeof(ushort)))\r\nerr = -EFAULT;\r\ngoto out_free;\r\n}\r\ncase SETALL:\r\n{\r\nint i;\r\nstruct sem_undo *un;\r\nsem_getref_and_unlock(sma);\r\nif(nsems > SEMMSL_FAST) {\r\nsem_io = ipc_alloc(sizeof(ushort)*nsems);\r\nif(sem_io == NULL) {\r\nsem_putref(sma);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nif (copy_from_user (sem_io, arg.array, nsems*sizeof(ushort))) {\r\nsem_putref(sma);\r\nerr = -EFAULT;\r\ngoto out_free;\r\n}\r\nfor (i = 0; i < nsems; i++) {\r\nif (sem_io[i] > SEMVMX) {\r\nsem_putref(sma);\r\nerr = -ERANGE;\r\ngoto out_free;\r\n}\r\n}\r\nsem_lock_and_putref(sma);\r\nif (sma->sem_perm.deleted) {\r\nsem_unlock(sma);\r\nerr = -EIDRM;\r\ngoto out_free;\r\n}\r\nfor (i = 0; i < nsems; i++)\r\nsma->sem_base[i].semval = sem_io[i];\r\nassert_spin_locked(&sma->sem_perm.lock);\r\nlist_for_each_entry(un, &sma->list_id, list_id) {\r\nfor (i = 0; i < nsems; i++)\r\nun->semadj[i] = 0;\r\n}\r\nsma->sem_ctime = get_seconds();\r\ndo_smart_update(sma, NULL, 0, 0, &tasks);\r\nerr = 0;\r\ngoto out_unlock;\r\n}\r\n}\r\nerr = -EINVAL;\r\nif(semnum < 0 || semnum >= nsems)\r\ngoto out_unlock;\r\ncurr = &sma->sem_base[semnum];\r\nswitch (cmd) {\r\ncase GETVAL:\r\nerr = curr->semval;\r\ngoto out_unlock;\r\ncase GETPID:\r\nerr = curr->sempid;\r\ngoto out_unlock;\r\ncase GETNCNT:\r\nerr = count_semncnt(sma,semnum);\r\ngoto out_unlock;\r\ncase GETZCNT:\r\nerr = count_semzcnt(sma,semnum);\r\ngoto out_unlock;\r\ncase SETVAL:\r\n{\r\nint val = arg.val;\r\nstruct sem_undo *un;\r\nerr = -ERANGE;\r\nif (val > SEMVMX || val < 0)\r\ngoto out_unlock;\r\nassert_spin_locked(&sma->sem_perm.lock);\r\nlist_for_each_entry(un, &sma->list_id, list_id)\r\nun->semadj[semnum] = 0;\r\ncurr->semval = val;\r\ncurr->sempid = task_tgid_vnr(current);\r\nsma->sem_ctime = get_seconds();\r\ndo_smart_update(sma, NULL, 0, 0, &tasks);\r\nerr = 0;\r\ngoto out_unlock;\r\n}\r\n}\r\nout_unlock:\r\nsem_unlock(sma);\r\nwake_up_sem_queue_do(&tasks);\r\nout_free:\r\nif(sem_io != fast_sem_io)\r\nipc_free(sem_io, sizeof(ushort)*nsems);\r\nreturn err;\r\n}\r\nstatic inline unsigned long\r\ncopy_semid_from_user(struct semid64_ds *out, void __user *buf, int version)\r\n{\r\nswitch(version) {\r\ncase IPC_64:\r\nif (copy_from_user(out, buf, sizeof(*out)))\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase IPC_OLD:\r\n{\r\nstruct semid_ds tbuf_old;\r\nif(copy_from_user(&tbuf_old, buf, sizeof(tbuf_old)))\r\nreturn -EFAULT;\r\nout->sem_perm.uid = tbuf_old.sem_perm.uid;\r\nout->sem_perm.gid = tbuf_old.sem_perm.gid;\r\nout->sem_perm.mode = tbuf_old.sem_perm.mode;\r\nreturn 0;\r\n}\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int semctl_down(struct ipc_namespace *ns, int semid,\r\nint cmd, int version, union semun arg)\r\n{\r\nstruct sem_array *sma;\r\nint err;\r\nstruct semid64_ds semid64;\r\nstruct kern_ipc_perm *ipcp;\r\nif(cmd == IPC_SET) {\r\nif (copy_semid_from_user(&semid64, arg.buf, version))\r\nreturn -EFAULT;\r\n}\r\nipcp = ipcctl_pre_down(ns, &sem_ids(ns), semid, cmd,\r\n&semid64.sem_perm, 0);\r\nif (IS_ERR(ipcp))\r\nreturn PTR_ERR(ipcp);\r\nsma = container_of(ipcp, struct sem_array, sem_perm);\r\nerr = security_sem_semctl(sma, cmd);\r\nif (err)\r\ngoto out_unlock;\r\nswitch(cmd){\r\ncase IPC_RMID:\r\nfreeary(ns, ipcp);\r\ngoto out_up;\r\ncase IPC_SET:\r\nipc_update_perm(&semid64.sem_perm, ipcp);\r\nsma->sem_ctime = get_seconds();\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\n}\r\nout_unlock:\r\nsem_unlock(sma);\r\nout_up:\r\nup_write(&sem_ids(ns).rw_mutex);\r\nreturn err;\r\n}\r\nSYSCALL_DEFINE(semctl)(int semid, int semnum, int cmd, union semun arg)\r\n{\r\nint err = -EINVAL;\r\nint version;\r\nstruct ipc_namespace *ns;\r\nif (semid < 0)\r\nreturn -EINVAL;\r\nversion = ipc_parse_version(&cmd);\r\nns = current->nsproxy->ipc_ns;\r\nswitch(cmd) {\r\ncase IPC_INFO:\r\ncase SEM_INFO:\r\ncase IPC_STAT:\r\ncase SEM_STAT:\r\nerr = semctl_nolock(ns, semid, cmd, version, arg);\r\nreturn err;\r\ncase GETALL:\r\ncase GETVAL:\r\ncase GETPID:\r\ncase GETNCNT:\r\ncase GETZCNT:\r\ncase SETVAL:\r\ncase SETALL:\r\nerr = semctl_main(ns,semid,semnum,cmd,version,arg);\r\nreturn err;\r\ncase IPC_RMID:\r\ncase IPC_SET:\r\nerr = semctl_down(ns, semid, cmd, version, arg);\r\nreturn err;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nasmlinkage long SyS_semctl(int semid, int semnum, int cmd, union semun arg)\r\n{\r\nreturn SYSC_semctl((int) semid, (int) semnum, (int) cmd, arg);\r\n}\r\nstatic inline int get_undo_list(struct sem_undo_list **undo_listp)\r\n{\r\nstruct sem_undo_list *undo_list;\r\nundo_list = current->sysvsem.undo_list;\r\nif (!undo_list) {\r\nundo_list = kzalloc(sizeof(*undo_list), GFP_KERNEL);\r\nif (undo_list == NULL)\r\nreturn -ENOMEM;\r\nspin_lock_init(&undo_list->lock);\r\natomic_set(&undo_list->refcnt, 1);\r\nINIT_LIST_HEAD(&undo_list->list_proc);\r\ncurrent->sysvsem.undo_list = undo_list;\r\n}\r\n*undo_listp = undo_list;\r\nreturn 0;\r\n}\r\nstatic struct sem_undo *__lookup_undo(struct sem_undo_list *ulp, int semid)\r\n{\r\nstruct sem_undo *un;\r\nlist_for_each_entry_rcu(un, &ulp->list_proc, list_proc) {\r\nif (un->semid == semid)\r\nreturn un;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct sem_undo *lookup_undo(struct sem_undo_list *ulp, int semid)\r\n{\r\nstruct sem_undo *un;\r\nassert_spin_locked(&ulp->lock);\r\nun = __lookup_undo(ulp, semid);\r\nif (un) {\r\nlist_del_rcu(&un->list_proc);\r\nlist_add_rcu(&un->list_proc, &ulp->list_proc);\r\n}\r\nreturn un;\r\n}\r\nstatic struct sem_undo *find_alloc_undo(struct ipc_namespace *ns, int semid)\r\n{\r\nstruct sem_array *sma;\r\nstruct sem_undo_list *ulp;\r\nstruct sem_undo *un, *new;\r\nint nsems;\r\nint error;\r\nerror = get_undo_list(&ulp);\r\nif (error)\r\nreturn ERR_PTR(error);\r\nrcu_read_lock();\r\nspin_lock(&ulp->lock);\r\nun = lookup_undo(ulp, semid);\r\nspin_unlock(&ulp->lock);\r\nif (likely(un!=NULL))\r\ngoto out;\r\nrcu_read_unlock();\r\nsma = sem_lock_check(ns, semid);\r\nif (IS_ERR(sma))\r\nreturn ERR_CAST(sma);\r\nnsems = sma->sem_nsems;\r\nsem_getref_and_unlock(sma);\r\nnew = kzalloc(sizeof(struct sem_undo) + sizeof(short)*nsems, GFP_KERNEL);\r\nif (!new) {\r\nsem_putref(sma);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nsem_lock_and_putref(sma);\r\nif (sma->sem_perm.deleted) {\r\nsem_unlock(sma);\r\nkfree(new);\r\nun = ERR_PTR(-EIDRM);\r\ngoto out;\r\n}\r\nspin_lock(&ulp->lock);\r\nun = lookup_undo(ulp, semid);\r\nif (un) {\r\nkfree(new);\r\ngoto success;\r\n}\r\nnew->semadj = (short *) &new[1];\r\nnew->ulp = ulp;\r\nnew->semid = semid;\r\nassert_spin_locked(&ulp->lock);\r\nlist_add_rcu(&new->list_proc, &ulp->list_proc);\r\nassert_spin_locked(&sma->sem_perm.lock);\r\nlist_add(&new->list_id, &sma->list_id);\r\nun = new;\r\nsuccess:\r\nspin_unlock(&ulp->lock);\r\nrcu_read_lock();\r\nsem_unlock(sma);\r\nout:\r\nreturn un;\r\n}\r\nstatic int get_queue_result(struct sem_queue *q)\r\n{\r\nint error;\r\nerror = q->status;\r\nwhile (unlikely(error == IN_WAKEUP)) {\r\ncpu_relax();\r\nerror = q->status;\r\n}\r\nreturn error;\r\n}\r\nint copy_semundo(unsigned long clone_flags, struct task_struct *tsk)\r\n{\r\nstruct sem_undo_list *undo_list;\r\nint error;\r\nif (clone_flags & CLONE_SYSVSEM) {\r\nerror = get_undo_list(&undo_list);\r\nif (error)\r\nreturn error;\r\natomic_inc(&undo_list->refcnt);\r\ntsk->sysvsem.undo_list = undo_list;\r\n} else\r\ntsk->sysvsem.undo_list = NULL;\r\nreturn 0;\r\n}\r\nvoid exit_sem(struct task_struct *tsk)\r\n{\r\nstruct sem_undo_list *ulp;\r\nulp = tsk->sysvsem.undo_list;\r\nif (!ulp)\r\nreturn;\r\ntsk->sysvsem.undo_list = NULL;\r\nif (!atomic_dec_and_test(&ulp->refcnt))\r\nreturn;\r\nfor (;;) {\r\nstruct sem_array *sma;\r\nstruct sem_undo *un;\r\nstruct list_head tasks;\r\nint semid;\r\nint i;\r\nrcu_read_lock();\r\nun = list_entry_rcu(ulp->list_proc.next,\r\nstruct sem_undo, list_proc);\r\nif (&un->list_proc == &ulp->list_proc)\r\nsemid = -1;\r\nelse\r\nsemid = un->semid;\r\nrcu_read_unlock();\r\nif (semid == -1)\r\nbreak;\r\nsma = sem_lock_check(tsk->nsproxy->ipc_ns, un->semid);\r\nif (IS_ERR(sma))\r\ncontinue;\r\nun = __lookup_undo(ulp, semid);\r\nif (un == NULL) {\r\nsem_unlock(sma);\r\ncontinue;\r\n}\r\nassert_spin_locked(&sma->sem_perm.lock);\r\nlist_del(&un->list_id);\r\nspin_lock(&ulp->lock);\r\nlist_del_rcu(&un->list_proc);\r\nspin_unlock(&ulp->lock);\r\nfor (i = 0; i < sma->sem_nsems; i++) {\r\nstruct sem * semaphore = &sma->sem_base[i];\r\nif (un->semadj[i]) {\r\nsemaphore->semval += un->semadj[i];\r\nif (semaphore->semval < 0)\r\nsemaphore->semval = 0;\r\nif (semaphore->semval > SEMVMX)\r\nsemaphore->semval = SEMVMX;\r\nsemaphore->sempid = task_tgid_vnr(current);\r\n}\r\n}\r\nINIT_LIST_HEAD(&tasks);\r\ndo_smart_update(sma, NULL, 0, 1, &tasks);\r\nsem_unlock(sma);\r\nwake_up_sem_queue_do(&tasks);\r\nkfree_rcu(un, rcu);\r\n}\r\nkfree(ulp);\r\n}\r\nstatic int sysvipc_sem_proc_show(struct seq_file *s, void *it)\r\n{\r\nstruct sem_array *sma = it;\r\nreturn seq_printf(s,\r\n"%10d %10d %4o %10u %5u %5u %5u %5u %10lu %10lu\n",\r\nsma->sem_perm.key,\r\nsma->sem_perm.id,\r\nsma->sem_perm.mode,\r\nsma->sem_nsems,\r\nsma->sem_perm.uid,\r\nsma->sem_perm.gid,\r\nsma->sem_perm.cuid,\r\nsma->sem_perm.cgid,\r\nsma->sem_otime,\r\nsma->sem_ctime);\r\n}
