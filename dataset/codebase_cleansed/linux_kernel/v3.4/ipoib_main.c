int ipoib_open(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_dbg(priv, "bringing up interface\n");\r\nset_bit(IPOIB_FLAG_ADMIN_UP, &priv->flags);\r\nif (ipoib_pkey_dev_delay_open(dev))\r\nreturn 0;\r\nif (ipoib_ib_dev_open(dev))\r\ngoto err_disable;\r\nif (ipoib_ib_dev_up(dev))\r\ngoto err_stop;\r\nif (!test_bit(IPOIB_FLAG_SUBINTERFACE, &priv->flags)) {\r\nstruct ipoib_dev_priv *cpriv;\r\nmutex_lock(&priv->vlan_mutex);\r\nlist_for_each_entry(cpriv, &priv->child_intfs, list) {\r\nint flags;\r\nflags = cpriv->dev->flags;\r\nif (flags & IFF_UP)\r\ncontinue;\r\ndev_change_flags(cpriv->dev, flags | IFF_UP);\r\n}\r\nmutex_unlock(&priv->vlan_mutex);\r\n}\r\nnetif_start_queue(dev);\r\nreturn 0;\r\nerr_stop:\r\nipoib_ib_dev_stop(dev, 1);\r\nerr_disable:\r\nclear_bit(IPOIB_FLAG_ADMIN_UP, &priv->flags);\r\nreturn -EINVAL;\r\n}\r\nstatic int ipoib_stop(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_dbg(priv, "stopping interface\n");\r\nclear_bit(IPOIB_FLAG_ADMIN_UP, &priv->flags);\r\nnetif_stop_queue(dev);\r\nipoib_ib_dev_down(dev, 0);\r\nipoib_ib_dev_stop(dev, 0);\r\nif (!test_bit(IPOIB_FLAG_SUBINTERFACE, &priv->flags)) {\r\nstruct ipoib_dev_priv *cpriv;\r\nmutex_lock(&priv->vlan_mutex);\r\nlist_for_each_entry(cpriv, &priv->child_intfs, list) {\r\nint flags;\r\nflags = cpriv->dev->flags;\r\nif (!(flags & IFF_UP))\r\ncontinue;\r\ndev_change_flags(cpriv->dev, flags & ~IFF_UP);\r\n}\r\nmutex_unlock(&priv->vlan_mutex);\r\n}\r\nreturn 0;\r\n}\r\nstatic netdev_features_t ipoib_fix_features(struct net_device *dev, netdev_features_t features)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags))\r\nfeatures &= ~(NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_TSO);\r\nreturn features;\r\n}\r\nstatic int ipoib_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (ipoib_cm_admin_enabled(dev)) {\r\nif (new_mtu > ipoib_cm_max_mtu(dev))\r\nreturn -EINVAL;\r\nif (new_mtu > priv->mcast_mtu)\r\nipoib_warn(priv, "mtu > %d will cause multicast packet drops.\n",\r\npriv->mcast_mtu);\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nif (new_mtu > IPOIB_UD_MTU(priv->max_ib_mtu))\r\nreturn -EINVAL;\r\npriv->admin_mtu = new_mtu;\r\ndev->mtu = min(priv->mcast_mtu, priv->admin_mtu);\r\nreturn 0;\r\n}\r\nstatic struct ipoib_path *__path_find(struct net_device *dev, void *gid)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct rb_node *n = priv->path_tree.rb_node;\r\nstruct ipoib_path *path;\r\nint ret;\r\nwhile (n) {\r\npath = rb_entry(n, struct ipoib_path, rb_node);\r\nret = memcmp(gid, path->pathrec.dgid.raw,\r\nsizeof (union ib_gid));\r\nif (ret < 0)\r\nn = n->rb_left;\r\nelse if (ret > 0)\r\nn = n->rb_right;\r\nelse\r\nreturn path;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int __path_add(struct net_device *dev, struct ipoib_path *path)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct rb_node **n = &priv->path_tree.rb_node;\r\nstruct rb_node *pn = NULL;\r\nstruct ipoib_path *tpath;\r\nint ret;\r\nwhile (*n) {\r\npn = *n;\r\ntpath = rb_entry(pn, struct ipoib_path, rb_node);\r\nret = memcmp(path->pathrec.dgid.raw, tpath->pathrec.dgid.raw,\r\nsizeof (union ib_gid));\r\nif (ret < 0)\r\nn = &pn->rb_left;\r\nelse if (ret > 0)\r\nn = &pn->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&path->rb_node, pn, n);\r\nrb_insert_color(&path->rb_node, &priv->path_tree);\r\nlist_add_tail(&path->list, &priv->path_list);\r\nreturn 0;\r\n}\r\nstatic void path_free(struct net_device *dev, struct ipoib_path *path)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_neigh *neigh, *tn;\r\nstruct sk_buff *skb;\r\nunsigned long flags;\r\nwhile ((skb = __skb_dequeue(&path->queue)))\r\ndev_kfree_skb_irq(skb);\r\nspin_lock_irqsave(&priv->lock, flags);\r\nlist_for_each_entry_safe(neigh, tn, &path->neigh_list, list) {\r\nif (neigh->ah)\r\nipoib_put_ah(neigh->ah);\r\nipoib_neigh_free(dev, neigh);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (path->ah)\r\nipoib_put_ah(path->ah);\r\nkfree(path);\r\n}\r\nstruct ipoib_path_iter *ipoib_path_iter_init(struct net_device *dev)\r\n{\r\nstruct ipoib_path_iter *iter;\r\niter = kmalloc(sizeof *iter, GFP_KERNEL);\r\nif (!iter)\r\nreturn NULL;\r\niter->dev = dev;\r\nmemset(iter->path.pathrec.dgid.raw, 0, 16);\r\nif (ipoib_path_iter_next(iter)) {\r\nkfree(iter);\r\nreturn NULL;\r\n}\r\nreturn iter;\r\n}\r\nint ipoib_path_iter_next(struct ipoib_path_iter *iter)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(iter->dev);\r\nstruct rb_node *n;\r\nstruct ipoib_path *path;\r\nint ret = 1;\r\nspin_lock_irq(&priv->lock);\r\nn = rb_first(&priv->path_tree);\r\nwhile (n) {\r\npath = rb_entry(n, struct ipoib_path, rb_node);\r\nif (memcmp(iter->path.pathrec.dgid.raw, path->pathrec.dgid.raw,\r\nsizeof (union ib_gid)) < 0) {\r\niter->path = *path;\r\nret = 0;\r\nbreak;\r\n}\r\nn = rb_next(n);\r\n}\r\nspin_unlock_irq(&priv->lock);\r\nreturn ret;\r\n}\r\nvoid ipoib_path_iter_read(struct ipoib_path_iter *iter,\r\nstruct ipoib_path *path)\r\n{\r\n*path = iter->path;\r\n}\r\nvoid ipoib_mark_paths_invalid(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path, *tp;\r\nspin_lock_irq(&priv->lock);\r\nlist_for_each_entry_safe(path, tp, &priv->path_list, list) {\r\nipoib_dbg(priv, "mark path LID 0x%04x GID %pI6 invalid\n",\r\nbe16_to_cpu(path->pathrec.dlid),\r\npath->pathrec.dgid.raw);\r\npath->valid = 0;\r\n}\r\nspin_unlock_irq(&priv->lock);\r\n}\r\nvoid ipoib_flush_paths(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path, *tp;\r\nLIST_HEAD(remove_list);\r\nunsigned long flags;\r\nnetif_tx_lock_bh(dev);\r\nspin_lock_irqsave(&priv->lock, flags);\r\nlist_splice_init(&priv->path_list, &remove_list);\r\nlist_for_each_entry(path, &remove_list, list)\r\nrb_erase(&path->rb_node, &priv->path_tree);\r\nlist_for_each_entry_safe(path, tp, &remove_list, list) {\r\nif (path->query)\r\nib_sa_cancel_query(path->query_id, path->query);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nnetif_tx_unlock_bh(dev);\r\nwait_for_completion(&path->done);\r\npath_free(dev, path);\r\nnetif_tx_lock_bh(dev);\r\nspin_lock_irqsave(&priv->lock, flags);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nnetif_tx_unlock_bh(dev);\r\n}\r\nstatic void path_rec_completion(int status,\r\nstruct ib_sa_path_rec *pathrec,\r\nvoid *path_ptr)\r\n{\r\nstruct ipoib_path *path = path_ptr;\r\nstruct net_device *dev = path->dev;\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_ah *ah = NULL;\r\nstruct ipoib_ah *old_ah = NULL;\r\nstruct ipoib_neigh *neigh, *tn;\r\nstruct sk_buff_head skqueue;\r\nstruct sk_buff *skb;\r\nunsigned long flags;\r\nif (!status)\r\nipoib_dbg(priv, "PathRec LID 0x%04x for GID %pI6\n",\r\nbe16_to_cpu(pathrec->dlid), pathrec->dgid.raw);\r\nelse\r\nipoib_dbg(priv, "PathRec status %d for GID %pI6\n",\r\nstatus, path->pathrec.dgid.raw);\r\nskb_queue_head_init(&skqueue);\r\nif (!status) {\r\nstruct ib_ah_attr av;\r\nif (!ib_init_ah_from_path(priv->ca, priv->port, pathrec, &av))\r\nah = ipoib_create_ah(dev, priv->pd, &av);\r\n}\r\nspin_lock_irqsave(&priv->lock, flags);\r\nif (!IS_ERR_OR_NULL(ah)) {\r\npath->pathrec = *pathrec;\r\nold_ah = path->ah;\r\npath->ah = ah;\r\nipoib_dbg(priv, "created address handle %p for LID 0x%04x, SL %d\n",\r\nah, be16_to_cpu(pathrec->dlid), pathrec->sl);\r\nwhile ((skb = __skb_dequeue(&path->queue)))\r\n__skb_queue_tail(&skqueue, skb);\r\nlist_for_each_entry_safe(neigh, tn, &path->neigh_list, list) {\r\nif (neigh->ah) {\r\nWARN_ON(neigh->ah != old_ah);\r\nipoib_put_ah(neigh->ah);\r\n}\r\nkref_get(&path->ah->ref);\r\nneigh->ah = path->ah;\r\nmemcpy(&neigh->dgid.raw, &path->pathrec.dgid.raw,\r\nsizeof(union ib_gid));\r\nif (ipoib_cm_enabled(dev, neigh->neighbour)) {\r\nif (!ipoib_cm_get(neigh))\r\nipoib_cm_set(neigh, ipoib_cm_create_tx(dev,\r\npath,\r\nneigh));\r\nif (!ipoib_cm_get(neigh)) {\r\nlist_del(&neigh->list);\r\nif (neigh->ah)\r\nipoib_put_ah(neigh->ah);\r\nipoib_neigh_free(dev, neigh);\r\ncontinue;\r\n}\r\n}\r\nwhile ((skb = __skb_dequeue(&neigh->queue)))\r\n__skb_queue_tail(&skqueue, skb);\r\n}\r\npath->valid = 1;\r\n}\r\npath->query = NULL;\r\ncomplete(&path->done);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (old_ah)\r\nipoib_put_ah(old_ah);\r\nwhile ((skb = __skb_dequeue(&skqueue))) {\r\nskb->dev = dev;\r\nif (dev_queue_xmit(skb))\r\nipoib_warn(priv, "dev_queue_xmit failed "\r\n"to requeue packet\n");\r\n}\r\n}\r\nstatic struct ipoib_path *path_rec_create(struct net_device *dev, void *gid)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path;\r\nif (!priv->broadcast)\r\nreturn NULL;\r\npath = kzalloc(sizeof *path, GFP_ATOMIC);\r\nif (!path)\r\nreturn NULL;\r\npath->dev = dev;\r\nskb_queue_head_init(&path->queue);\r\nINIT_LIST_HEAD(&path->neigh_list);\r\nmemcpy(path->pathrec.dgid.raw, gid, sizeof (union ib_gid));\r\npath->pathrec.sgid = priv->local_gid;\r\npath->pathrec.pkey = cpu_to_be16(priv->pkey);\r\npath->pathrec.numb_path = 1;\r\npath->pathrec.traffic_class = priv->broadcast->mcmember.traffic_class;\r\nreturn path;\r\n}\r\nstatic int path_rec_start(struct net_device *dev,\r\nstruct ipoib_path *path)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_dbg(priv, "Start path record lookup for %pI6\n",\r\npath->pathrec.dgid.raw);\r\ninit_completion(&path->done);\r\npath->query_id =\r\nib_sa_path_rec_get(&ipoib_sa_client, priv->ca, priv->port,\r\n&path->pathrec,\r\nIB_SA_PATH_REC_DGID |\r\nIB_SA_PATH_REC_SGID |\r\nIB_SA_PATH_REC_NUMB_PATH |\r\nIB_SA_PATH_REC_TRAFFIC_CLASS |\r\nIB_SA_PATH_REC_PKEY,\r\n1000, GFP_ATOMIC,\r\npath_rec_completion,\r\npath, &path->query);\r\nif (path->query_id < 0) {\r\nipoib_warn(priv, "ib_sa_path_rec_get failed: %d\n", path->query_id);\r\npath->query = NULL;\r\ncomplete(&path->done);\r\nreturn path->query_id;\r\n}\r\nreturn 0;\r\n}\r\nstatic void neigh_add_path(struct sk_buff *skb, struct neighbour *n, struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path;\r\nstruct ipoib_neigh *neigh;\r\nunsigned long flags;\r\nneigh = ipoib_neigh_alloc(n, skb->dev);\r\nif (!neigh) {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\nreturn;\r\n}\r\nspin_lock_irqsave(&priv->lock, flags);\r\npath = __path_find(dev, n->ha + 4);\r\nif (!path) {\r\npath = path_rec_create(dev, n->ha + 4);\r\nif (!path)\r\ngoto err_path;\r\n__path_add(dev, path);\r\n}\r\nlist_add_tail(&neigh->list, &path->neigh_list);\r\nif (path->ah) {\r\nkref_get(&path->ah->ref);\r\nneigh->ah = path->ah;\r\nmemcpy(&neigh->dgid.raw, &path->pathrec.dgid.raw,\r\nsizeof(union ib_gid));\r\nif (ipoib_cm_enabled(dev, neigh->neighbour)) {\r\nif (!ipoib_cm_get(neigh))\r\nipoib_cm_set(neigh, ipoib_cm_create_tx(dev, path, neigh));\r\nif (!ipoib_cm_get(neigh)) {\r\nlist_del(&neigh->list);\r\nif (neigh->ah)\r\nipoib_put_ah(neigh->ah);\r\nipoib_neigh_free(dev, neigh);\r\ngoto err_drop;\r\n}\r\nif (skb_queue_len(&neigh->queue) < IPOIB_MAX_PATH_REC_QUEUE)\r\n__skb_queue_tail(&neigh->queue, skb);\r\nelse {\r\nipoib_warn(priv, "queue length limit %d. Packet drop.\n",\r\nskb_queue_len(&neigh->queue));\r\ngoto err_drop;\r\n}\r\n} else {\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nipoib_send(dev, skb, path->ah, IPOIB_QPN(n->ha));\r\nreturn;\r\n}\r\n} else {\r\nneigh->ah = NULL;\r\nif (!path->query && path_rec_start(dev, path))\r\ngoto err_list;\r\n__skb_queue_tail(&neigh->queue, skb);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nreturn;\r\nerr_list:\r\nlist_del(&neigh->list);\r\nerr_path:\r\nipoib_neigh_free(dev, neigh);\r\nerr_drop:\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic void ipoib_path_lookup(struct sk_buff *skb, struct neighbour *n, struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(skb->dev);\r\nif (n->ha[4] != 0xff) {\r\nneigh_add_path(skb, n, dev);\r\nreturn;\r\n}\r\nn->ha[8] = (priv->pkey >> 8) & 0xff;\r\nn->ha[9] = priv->pkey & 0xff;\r\nipoib_mcast_send(dev, n->ha + 4, skb);\r\n}\r\nstatic void unicast_arp_send(struct sk_buff *skb, struct net_device *dev,\r\nstruct ipoib_cb *cb)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path;\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\npath = __path_find(dev, cb->hwaddr + 4);\r\nif (!path || !path->valid) {\r\nint new_path = 0;\r\nif (!path) {\r\npath = path_rec_create(dev, cb->hwaddr + 4);\r\nnew_path = 1;\r\n}\r\nif (path) {\r\n__skb_queue_tail(&path->queue, skb);\r\nif (!path->query && path_rec_start(dev, path)) {\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (new_path)\r\npath_free(dev, path);\r\nreturn;\r\n} else\r\n__path_add(dev, path);\r\n} else {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nreturn;\r\n}\r\nif (path->ah) {\r\nipoib_dbg(priv, "Send unicast ARP to %04x\n",\r\nbe16_to_cpu(path->pathrec.dlid));\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nipoib_send(dev, skb, path->ah, IPOIB_QPN(cb->hwaddr));\r\nreturn;\r\n} else if ((path->query || !path_rec_start(dev, path)) &&\r\nskb_queue_len(&path->queue) < IPOIB_MAX_PATH_REC_QUEUE) {\r\n__skb_queue_tail(&path->queue, skb);\r\n} else {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic int ipoib_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_neigh *neigh;\r\nstruct neighbour *n = NULL;\r\nunsigned long flags;\r\nrcu_read_lock();\r\nif (likely(skb_dst(skb))) {\r\nn = dst_get_neighbour_noref(skb_dst(skb));\r\nif (!n) {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\ngoto unlock;\r\n}\r\n}\r\nif (likely(n)) {\r\nif (unlikely(!*to_ipoib_neigh(n))) {\r\nipoib_path_lookup(skb, n, dev);\r\ngoto unlock;\r\n}\r\nneigh = *to_ipoib_neigh(n);\r\nif (unlikely((memcmp(&neigh->dgid.raw,\r\nn->ha + 4,\r\nsizeof(union ib_gid))) ||\r\n(neigh->dev != dev))) {\r\nspin_lock_irqsave(&priv->lock, flags);\r\nif (neigh->ah)\r\nipoib_put_ah(neigh->ah);\r\nlist_del(&neigh->list);\r\nipoib_neigh_free(dev, neigh);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nipoib_path_lookup(skb, n, dev);\r\ngoto unlock;\r\n}\r\nif (ipoib_cm_get(neigh)) {\r\nif (ipoib_cm_up(neigh)) {\r\nipoib_cm_send(dev, skb, ipoib_cm_get(neigh));\r\ngoto unlock;\r\n}\r\n} else if (neigh->ah) {\r\nipoib_send(dev, skb, neigh->ah, IPOIB_QPN(n->ha));\r\ngoto unlock;\r\n}\r\nif (skb_queue_len(&neigh->queue) < IPOIB_MAX_PATH_REC_QUEUE) {\r\nspin_lock_irqsave(&priv->lock, flags);\r\n__skb_queue_tail(&neigh->queue, skb);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n} else {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\n} else {\r\nstruct ipoib_cb *cb = (struct ipoib_cb *) skb->cb;\r\nif (cb->hwaddr[4] == 0xff) {\r\ncb->hwaddr[8] = (priv->pkey >> 8) & 0xff;\r\ncb->hwaddr[9] = priv->pkey & 0xff;\r\nipoib_mcast_send(dev, cb->hwaddr + 4, skb);\r\n} else {\r\nif ((be16_to_cpup((__be16 *) skb->data) != ETH_P_ARP) &&\r\n(be16_to_cpup((__be16 *) skb->data) != ETH_P_RARP)) {\r\nipoib_warn(priv, "Unicast, no %s: type %04x, QPN %06x %pI6\n",\r\nskb_dst(skb) ? "neigh" : "dst",\r\nbe16_to_cpup((__be16 *) skb->data),\r\nIPOIB_QPN(cb->hwaddr),\r\ncb->hwaddr + 4);\r\ndev_kfree_skb_any(skb);\r\n++dev->stats.tx_dropped;\r\ngoto unlock;\r\n}\r\nunicast_arp_send(skb, dev, cb);\r\n}\r\n}\r\nunlock:\r\nrcu_read_unlock();\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void ipoib_timeout(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_warn(priv, "transmit timeout: latency %d msecs\n",\r\njiffies_to_msecs(jiffies - dev->trans_start));\r\nipoib_warn(priv, "queue stopped %d, tx_head %u, tx_tail %u\n",\r\nnetif_queue_stopped(dev),\r\npriv->tx_head, priv->tx_tail);\r\n}\r\nstatic int ipoib_hard_header(struct sk_buff *skb,\r\nstruct net_device *dev,\r\nunsigned short type,\r\nconst void *daddr, const void *saddr, unsigned len)\r\n{\r\nstruct ipoib_header *header;\r\nheader = (struct ipoib_header *) skb_push(skb, sizeof *header);\r\nheader->proto = htons(type);\r\nheader->reserved = 0;\r\nif (!skb_dst(skb)) {\r\nstruct ipoib_cb *cb = (struct ipoib_cb *) skb->cb;\r\nmemcpy(cb->hwaddr, daddr, INFINIBAND_ALEN);\r\n}\r\nreturn 0;\r\n}\r\nstatic void ipoib_set_mcast_list(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (!test_bit(IPOIB_FLAG_OPER_UP, &priv->flags)) {\r\nipoib_dbg(priv, "IPOIB_FLAG_OPER_UP not set");\r\nreturn;\r\n}\r\nqueue_work(ipoib_workqueue, &priv->restart_task);\r\n}\r\nstatic void ipoib_neigh_cleanup(struct neighbour *n)\r\n{\r\nstruct ipoib_neigh *neigh;\r\nstruct ipoib_dev_priv *priv = netdev_priv(n->dev);\r\nunsigned long flags;\r\nstruct ipoib_ah *ah = NULL;\r\nneigh = *to_ipoib_neigh(n);\r\nif (neigh)\r\npriv = netdev_priv(neigh->dev);\r\nelse\r\nreturn;\r\nipoib_dbg(priv,\r\n"neigh_cleanup for %06x %pI6\n",\r\nIPOIB_QPN(n->ha),\r\nn->ha + 4);\r\nspin_lock_irqsave(&priv->lock, flags);\r\nif (neigh->ah)\r\nah = neigh->ah;\r\nlist_del(&neigh->list);\r\nipoib_neigh_free(n->dev, neigh);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (ah)\r\nipoib_put_ah(ah);\r\n}\r\nstruct ipoib_neigh *ipoib_neigh_alloc(struct neighbour *neighbour,\r\nstruct net_device *dev)\r\n{\r\nstruct ipoib_neigh *neigh;\r\nneigh = kmalloc(sizeof *neigh, GFP_ATOMIC);\r\nif (!neigh)\r\nreturn NULL;\r\nneigh->neighbour = neighbour;\r\nneigh->dev = dev;\r\nmemset(&neigh->dgid.raw, 0, sizeof (union ib_gid));\r\n*to_ipoib_neigh(neighbour) = neigh;\r\nskb_queue_head_init(&neigh->queue);\r\nipoib_cm_set(neigh, NULL);\r\nreturn neigh;\r\n}\r\nvoid ipoib_neigh_free(struct net_device *dev, struct ipoib_neigh *neigh)\r\n{\r\nstruct sk_buff *skb;\r\n*to_ipoib_neigh(neigh->neighbour) = NULL;\r\nwhile ((skb = __skb_dequeue(&neigh->queue))) {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\nif (ipoib_cm_get(neigh))\r\nipoib_cm_destroy_tx(ipoib_cm_get(neigh));\r\nkfree(neigh);\r\n}\r\nstatic int ipoib_neigh_setup_dev(struct net_device *dev, struct neigh_parms *parms)\r\n{\r\nparms->neigh_cleanup = ipoib_neigh_cleanup;\r\nreturn 0;\r\n}\r\nint ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\npriv->rx_ring = kzalloc(ipoib_recvq_size * sizeof *priv->rx_ring,\r\nGFP_KERNEL);\r\nif (!priv->rx_ring) {\r\nprintk(KERN_WARNING "%s: failed to allocate RX ring (%d entries)\n",\r\nca->name, ipoib_recvq_size);\r\ngoto out;\r\n}\r\npriv->tx_ring = vzalloc(ipoib_sendq_size * sizeof *priv->tx_ring);\r\nif (!priv->tx_ring) {\r\nprintk(KERN_WARNING "%s: failed to allocate TX ring (%d entries)\n",\r\nca->name, ipoib_sendq_size);\r\ngoto out_rx_ring_cleanup;\r\n}\r\nif (ipoib_ib_dev_init(dev, ca, port))\r\ngoto out_tx_ring_cleanup;\r\nreturn 0;\r\nout_tx_ring_cleanup:\r\nvfree(priv->tx_ring);\r\nout_rx_ring_cleanup:\r\nkfree(priv->rx_ring);\r\nout:\r\nreturn -ENOMEM;\r\n}\r\nvoid ipoib_dev_cleanup(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev), *cpriv, *tcpriv;\r\nipoib_delete_debug_files(dev);\r\nlist_for_each_entry_safe(cpriv, tcpriv, &priv->child_intfs, list) {\r\nunregister_netdev(cpriv->dev);\r\nipoib_dev_cleanup(cpriv->dev);\r\nfree_netdev(cpriv->dev);\r\n}\r\nipoib_ib_dev_cleanup(dev);\r\nkfree(priv->rx_ring);\r\nvfree(priv->tx_ring);\r\npriv->rx_ring = NULL;\r\npriv->tx_ring = NULL;\r\n}\r\nstatic void ipoib_setup(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\ndev->netdev_ops = &ipoib_netdev_ops;\r\ndev->header_ops = &ipoib_header_ops;\r\nipoib_set_ethtool_ops(dev);\r\nnetif_napi_add(dev, &priv->napi, ipoib_poll, 100);\r\ndev->watchdog_timeo = HZ;\r\ndev->flags |= IFF_BROADCAST | IFF_MULTICAST;\r\ndev->hard_header_len = IPOIB_ENCAP_LEN;\r\ndev->addr_len = INFINIBAND_ALEN;\r\ndev->type = ARPHRD_INFINIBAND;\r\ndev->tx_queue_len = ipoib_sendq_size * 2;\r\ndev->features = (NETIF_F_VLAN_CHALLENGED |\r\nNETIF_F_HIGHDMA);\r\ndev->priv_flags &= ~IFF_XMIT_DST_RELEASE;\r\nmemcpy(dev->broadcast, ipv4_bcast_addr, INFINIBAND_ALEN);\r\nnetif_carrier_off(dev);\r\npriv->dev = dev;\r\nspin_lock_init(&priv->lock);\r\nmutex_init(&priv->vlan_mutex);\r\nINIT_LIST_HEAD(&priv->path_list);\r\nINIT_LIST_HEAD(&priv->child_intfs);\r\nINIT_LIST_HEAD(&priv->dead_ahs);\r\nINIT_LIST_HEAD(&priv->multicast_list);\r\nINIT_DELAYED_WORK(&priv->pkey_poll_task, ipoib_pkey_poll);\r\nINIT_DELAYED_WORK(&priv->mcast_task, ipoib_mcast_join_task);\r\nINIT_WORK(&priv->carrier_on_task, ipoib_mcast_carrier_on_task);\r\nINIT_WORK(&priv->flush_light, ipoib_ib_dev_flush_light);\r\nINIT_WORK(&priv->flush_normal, ipoib_ib_dev_flush_normal);\r\nINIT_WORK(&priv->flush_heavy, ipoib_ib_dev_flush_heavy);\r\nINIT_WORK(&priv->restart_task, ipoib_mcast_restart_task);\r\nINIT_DELAYED_WORK(&priv->ah_reap_task, ipoib_reap_ah);\r\n}\r\nstruct ipoib_dev_priv *ipoib_intf_alloc(const char *name)\r\n{\r\nstruct net_device *dev;\r\ndev = alloc_netdev((int) sizeof (struct ipoib_dev_priv), name,\r\nipoib_setup);\r\nif (!dev)\r\nreturn NULL;\r\nreturn netdev_priv(dev);\r\n}\r\nstatic ssize_t show_pkey(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(to_net_dev(dev));\r\nreturn sprintf(buf, "0x%04x\n", priv->pkey);\r\n}\r\nstatic ssize_t show_umcast(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(to_net_dev(dev));\r\nreturn sprintf(buf, "%d\n", test_bit(IPOIB_FLAG_UMCAST, &priv->flags));\r\n}\r\nstatic ssize_t set_umcast(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(to_net_dev(dev));\r\nunsigned long umcast_val = simple_strtoul(buf, NULL, 0);\r\nif (umcast_val > 0) {\r\nset_bit(IPOIB_FLAG_UMCAST, &priv->flags);\r\nipoib_warn(priv, "ignoring multicast groups joined directly "\r\n"by userspace\n");\r\n} else\r\nclear_bit(IPOIB_FLAG_UMCAST, &priv->flags);\r\nreturn count;\r\n}\r\nint ipoib_add_umcast_attr(struct net_device *dev)\r\n{\r\nreturn device_create_file(&dev->dev, &dev_attr_umcast);\r\n}\r\nstatic ssize_t create_child(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nint pkey;\r\nint ret;\r\nif (sscanf(buf, "%i", &pkey) != 1)\r\nreturn -EINVAL;\r\nif (pkey < 0 || pkey > 0xffff)\r\nreturn -EINVAL;\r\npkey |= 0x8000;\r\nret = ipoib_vlan_add(to_net_dev(dev), pkey);\r\nreturn ret ? ret : count;\r\n}\r\nstatic ssize_t delete_child(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nint pkey;\r\nint ret;\r\nif (sscanf(buf, "%i", &pkey) != 1)\r\nreturn -EINVAL;\r\nif (pkey < 0 || pkey > 0xffff)\r\nreturn -EINVAL;\r\nret = ipoib_vlan_delete(to_net_dev(dev), pkey);\r\nreturn ret ? ret : count;\r\n}\r\nint ipoib_add_pkey_attr(struct net_device *dev)\r\n{\r\nreturn device_create_file(&dev->dev, &dev_attr_pkey);\r\n}\r\nint ipoib_set_dev_features(struct ipoib_dev_priv *priv, struct ib_device *hca)\r\n{\r\nstruct ib_device_attr *device_attr;\r\nint result = -ENOMEM;\r\ndevice_attr = kmalloc(sizeof *device_attr, GFP_KERNEL);\r\nif (!device_attr) {\r\nprintk(KERN_WARNING "%s: allocation of %zu bytes failed\n",\r\nhca->name, sizeof *device_attr);\r\nreturn result;\r\n}\r\nresult = ib_query_device(hca, device_attr);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: ib_query_device failed (ret = %d)\n",\r\nhca->name, result);\r\nkfree(device_attr);\r\nreturn result;\r\n}\r\npriv->hca_caps = device_attr->device_cap_flags;\r\nkfree(device_attr);\r\nif (priv->hca_caps & IB_DEVICE_UD_IP_CSUM) {\r\npriv->dev->hw_features = NETIF_F_SG |\r\nNETIF_F_IP_CSUM | NETIF_F_RXCSUM;\r\nif (priv->hca_caps & IB_DEVICE_UD_TSO)\r\npriv->dev->hw_features |= NETIF_F_TSO;\r\npriv->dev->features |= priv->dev->hw_features;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct net_device *ipoib_add_port(const char *format,\r\nstruct ib_device *hca, u8 port)\r\n{\r\nstruct ipoib_dev_priv *priv;\r\nstruct ib_port_attr attr;\r\nint result = -ENOMEM;\r\npriv = ipoib_intf_alloc(format);\r\nif (!priv)\r\ngoto alloc_mem_failed;\r\nSET_NETDEV_DEV(priv->dev, hca->dma_device);\r\npriv->dev->dev_id = port - 1;\r\nif (!ib_query_port(hca, port, &attr))\r\npriv->max_ib_mtu = ib_mtu_enum_to_int(attr.max_mtu);\r\nelse {\r\nprintk(KERN_WARNING "%s: ib_query_port %d failed\n",\r\nhca->name, port);\r\ngoto device_init_failed;\r\n}\r\npriv->dev->mtu = IPOIB_UD_MTU(priv->max_ib_mtu);\r\npriv->mcast_mtu = priv->admin_mtu = priv->dev->mtu;\r\npriv->dev->neigh_priv_len = sizeof(struct ipoib_neigh);\r\nresult = ib_query_pkey(hca, port, 0, &priv->pkey);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: ib_query_pkey port %d failed (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto device_init_failed;\r\n}\r\nif (ipoib_set_dev_features(priv, hca))\r\ngoto device_init_failed;\r\npriv->pkey |= 0x8000;\r\npriv->dev->broadcast[8] = priv->pkey >> 8;\r\npriv->dev->broadcast[9] = priv->pkey & 0xff;\r\nresult = ib_query_gid(hca, port, 0, &priv->local_gid);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: ib_query_gid port %d failed (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto device_init_failed;\r\n} else\r\nmemcpy(priv->dev->dev_addr + 4, priv->local_gid.raw, sizeof (union ib_gid));\r\nresult = ipoib_dev_init(priv->dev, hca, port);\r\nif (result < 0) {\r\nprintk(KERN_WARNING "%s: failed to initialize port %d (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto device_init_failed;\r\n}\r\nINIT_IB_EVENT_HANDLER(&priv->event_handler,\r\npriv->ca, ipoib_event);\r\nresult = ib_register_event_handler(&priv->event_handler);\r\nif (result < 0) {\r\nprintk(KERN_WARNING "%s: ib_register_event_handler failed for "\r\n"port %d (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto event_failed;\r\n}\r\nresult = register_netdev(priv->dev);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: couldn't register ipoib port %d; error %d\n",\r\nhca->name, port, result);\r\ngoto register_failed;\r\n}\r\nipoib_create_debug_files(priv->dev);\r\nif (ipoib_cm_add_mode_attr(priv->dev))\r\ngoto sysfs_failed;\r\nif (ipoib_add_pkey_attr(priv->dev))\r\ngoto sysfs_failed;\r\nif (ipoib_add_umcast_attr(priv->dev))\r\ngoto sysfs_failed;\r\nif (device_create_file(&priv->dev->dev, &dev_attr_create_child))\r\ngoto sysfs_failed;\r\nif (device_create_file(&priv->dev->dev, &dev_attr_delete_child))\r\ngoto sysfs_failed;\r\nreturn priv->dev;\r\nsysfs_failed:\r\nipoib_delete_debug_files(priv->dev);\r\nunregister_netdev(priv->dev);\r\nregister_failed:\r\nib_unregister_event_handler(&priv->event_handler);\r\nflush_workqueue(ipoib_workqueue);\r\nevent_failed:\r\nipoib_dev_cleanup(priv->dev);\r\ndevice_init_failed:\r\nfree_netdev(priv->dev);\r\nalloc_mem_failed:\r\nreturn ERR_PTR(result);\r\n}\r\nstatic void ipoib_add_one(struct ib_device *device)\r\n{\r\nstruct list_head *dev_list;\r\nstruct net_device *dev;\r\nstruct ipoib_dev_priv *priv;\r\nint s, e, p;\r\nif (rdma_node_get_transport(device->node_type) != RDMA_TRANSPORT_IB)\r\nreturn;\r\ndev_list = kmalloc(sizeof *dev_list, GFP_KERNEL);\r\nif (!dev_list)\r\nreturn;\r\nINIT_LIST_HEAD(dev_list);\r\nif (device->node_type == RDMA_NODE_IB_SWITCH) {\r\ns = 0;\r\ne = 0;\r\n} else {\r\ns = 1;\r\ne = device->phys_port_cnt;\r\n}\r\nfor (p = s; p <= e; ++p) {\r\nif (rdma_port_get_link_layer(device, p) != IB_LINK_LAYER_INFINIBAND)\r\ncontinue;\r\ndev = ipoib_add_port("ib%d", device, p);\r\nif (!IS_ERR(dev)) {\r\npriv = netdev_priv(dev);\r\nlist_add_tail(&priv->list, dev_list);\r\n}\r\n}\r\nib_set_client_data(device, &ipoib_client, dev_list);\r\n}\r\nstatic void ipoib_remove_one(struct ib_device *device)\r\n{\r\nstruct ipoib_dev_priv *priv, *tmp;\r\nstruct list_head *dev_list;\r\nif (rdma_node_get_transport(device->node_type) != RDMA_TRANSPORT_IB)\r\nreturn;\r\ndev_list = ib_get_client_data(device, &ipoib_client);\r\nlist_for_each_entry_safe(priv, tmp, dev_list, list) {\r\nib_unregister_event_handler(&priv->event_handler);\r\nrtnl_lock();\r\ndev_change_flags(priv->dev, priv->dev->flags & ~IFF_UP);\r\nrtnl_unlock();\r\nflush_workqueue(ipoib_workqueue);\r\nunregister_netdev(priv->dev);\r\nipoib_dev_cleanup(priv->dev);\r\nfree_netdev(priv->dev);\r\n}\r\nkfree(dev_list);\r\n}\r\nstatic int __init ipoib_init_module(void)\r\n{\r\nint ret;\r\nipoib_recvq_size = roundup_pow_of_two(ipoib_recvq_size);\r\nipoib_recvq_size = min(ipoib_recvq_size, IPOIB_MAX_QUEUE_SIZE);\r\nipoib_recvq_size = max(ipoib_recvq_size, IPOIB_MIN_QUEUE_SIZE);\r\nipoib_sendq_size = roundup_pow_of_two(ipoib_sendq_size);\r\nipoib_sendq_size = min(ipoib_sendq_size, IPOIB_MAX_QUEUE_SIZE);\r\nipoib_sendq_size = max3(ipoib_sendq_size, 2 * MAX_SEND_CQE, IPOIB_MIN_QUEUE_SIZE);\r\n#ifdef CONFIG_INFINIBAND_IPOIB_CM\r\nipoib_max_conn_qp = min(ipoib_max_conn_qp, IPOIB_CM_MAX_CONN_QP);\r\n#endif\r\nBUILD_BUG_ON(IPOIB_CM_COPYBREAK > IPOIB_CM_HEAD_SIZE);\r\nret = ipoib_register_debugfs();\r\nif (ret)\r\nreturn ret;\r\nipoib_workqueue = create_singlethread_workqueue("ipoib");\r\nif (!ipoib_workqueue) {\r\nret = -ENOMEM;\r\ngoto err_fs;\r\n}\r\nib_sa_register_client(&ipoib_sa_client);\r\nret = ib_register_client(&ipoib_client);\r\nif (ret)\r\ngoto err_sa;\r\nreturn 0;\r\nerr_sa:\r\nib_sa_unregister_client(&ipoib_sa_client);\r\ndestroy_workqueue(ipoib_workqueue);\r\nerr_fs:\r\nipoib_unregister_debugfs();\r\nreturn ret;\r\n}\r\nstatic void __exit ipoib_cleanup_module(void)\r\n{\r\nib_unregister_client(&ipoib_client);\r\nib_sa_unregister_client(&ipoib_sa_client);\r\nipoib_unregister_debugfs();\r\ndestroy_workqueue(ipoib_workqueue);\r\n}
