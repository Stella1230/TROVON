static void __iomem *qs_mmio_base(struct ata_host *host)\r\n{\r\nreturn host->iomap[QS_MMIO_BAR];\r\n}\r\nstatic int qs_check_atapi_dma(struct ata_queued_cmd *qc)\r\n{\r\nreturn 1;\r\n}\r\nstatic inline void qs_enter_reg_mode(struct ata_port *ap)\r\n{\r\nu8 __iomem *chan = qs_mmio_base(ap->host) + (ap->port_no * 0x4000);\r\nstruct qs_port_priv *pp = ap->private_data;\r\npp->state = qs_state_mmio;\r\nwriteb(QS_CTR0_REG, chan + QS_CCT_CTR0);\r\nreadb(chan + QS_CCT_CTR0);\r\n}\r\nstatic inline void qs_reset_channel_logic(struct ata_port *ap)\r\n{\r\nu8 __iomem *chan = qs_mmio_base(ap->host) + (ap->port_no * 0x4000);\r\nwriteb(QS_CTR1_RCHN, chan + QS_CCT_CTR1);\r\nreadb(chan + QS_CCT_CTR0);\r\nqs_enter_reg_mode(ap);\r\n}\r\nstatic void qs_freeze(struct ata_port *ap)\r\n{\r\nu8 __iomem *mmio_base = qs_mmio_base(ap->host);\r\nwriteb(0, mmio_base + QS_HCT_CTRL);\r\nqs_enter_reg_mode(ap);\r\n}\r\nstatic void qs_thaw(struct ata_port *ap)\r\n{\r\nu8 __iomem *mmio_base = qs_mmio_base(ap->host);\r\nqs_enter_reg_mode(ap);\r\nwriteb(1, mmio_base + QS_HCT_CTRL);\r\n}\r\nstatic int qs_prereset(struct ata_link *link, unsigned long deadline)\r\n{\r\nstruct ata_port *ap = link->ap;\r\nqs_reset_channel_logic(ap);\r\nreturn ata_sff_prereset(link, deadline);\r\n}\r\nstatic int qs_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)\r\n{\r\nif (sc_reg > SCR_CONTROL)\r\nreturn -EINVAL;\r\n*val = readl(link->ap->ioaddr.scr_addr + (sc_reg * 8));\r\nreturn 0;\r\n}\r\nstatic void qs_error_handler(struct ata_port *ap)\r\n{\r\nqs_enter_reg_mode(ap);\r\nata_sff_error_handler(ap);\r\n}\r\nstatic int qs_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)\r\n{\r\nif (sc_reg > SCR_CONTROL)\r\nreturn -EINVAL;\r\nwritel(val, link->ap->ioaddr.scr_addr + (sc_reg * 8));\r\nreturn 0;\r\n}\r\nstatic unsigned int qs_fill_sg(struct ata_queued_cmd *qc)\r\n{\r\nstruct scatterlist *sg;\r\nstruct ata_port *ap = qc->ap;\r\nstruct qs_port_priv *pp = ap->private_data;\r\nu8 *prd = pp->pkt + QS_CPB_BYTES;\r\nunsigned int si;\r\nfor_each_sg(qc->sg, sg, qc->n_elem, si) {\r\nu64 addr;\r\nu32 len;\r\naddr = sg_dma_address(sg);\r\n*(__le64 *)prd = cpu_to_le64(addr);\r\nprd += sizeof(u64);\r\nlen = sg_dma_len(sg);\r\n*(__le32 *)prd = cpu_to_le32(len);\r\nprd += sizeof(u64);\r\nVPRINTK("PRD[%u] = (0x%llX, 0x%X)\n", si,\r\n(unsigned long long)addr, len);\r\n}\r\nreturn si;\r\n}\r\nstatic void qs_qc_prep(struct ata_queued_cmd *qc)\r\n{\r\nstruct qs_port_priv *pp = qc->ap->private_data;\r\nu8 dflags = QS_DF_PORD, *buf = pp->pkt;\r\nu8 hflags = QS_HF_DAT | QS_HF_IEN | QS_HF_VLD;\r\nu64 addr;\r\nunsigned int nelem;\r\nVPRINTK("ENTER\n");\r\nqs_enter_reg_mode(qc->ap);\r\nif (qc->tf.protocol != ATA_PROT_DMA)\r\nreturn;\r\nnelem = qs_fill_sg(qc);\r\nif ((qc->tf.flags & ATA_TFLAG_WRITE))\r\nhflags |= QS_HF_DIRO;\r\nif ((qc->tf.flags & ATA_TFLAG_LBA48))\r\ndflags |= QS_DF_ELBA;\r\nbuf[ 0] = QS_HCB_HDR;\r\nbuf[ 1] = hflags;\r\n*(__le32 *)(&buf[ 4]) = cpu_to_le32(qc->nbytes);\r\n*(__le32 *)(&buf[ 8]) = cpu_to_le32(nelem);\r\naddr = ((u64)pp->pkt_dma) + QS_CPB_BYTES;\r\n*(__le64 *)(&buf[16]) = cpu_to_le64(addr);\r\nbuf[24] = QS_DCB_HDR;\r\nbuf[28] = dflags;\r\nata_tf_to_fis(&qc->tf, 0, 1, &buf[32]);\r\n}\r\nstatic inline void qs_packet_start(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nu8 __iomem *chan = qs_mmio_base(ap->host) + (ap->port_no * 0x4000);\r\nVPRINTK("ENTER, ap %p\n", ap);\r\nwriteb(QS_CTR0_CLER, chan + QS_CCT_CTR0);\r\nwmb();\r\nwritel(QS_CCF_RUN_PKT, chan + QS_CCT_CFF);\r\nreadl(chan + QS_CCT_CFF);\r\n}\r\nstatic unsigned int qs_qc_issue(struct ata_queued_cmd *qc)\r\n{\r\nstruct qs_port_priv *pp = qc->ap->private_data;\r\nswitch (qc->tf.protocol) {\r\ncase ATA_PROT_DMA:\r\npp->state = qs_state_pkt;\r\nqs_packet_start(qc);\r\nreturn 0;\r\ncase ATAPI_PROT_DMA:\r\nBUG();\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\npp->state = qs_state_mmio;\r\nreturn ata_sff_qc_issue(qc);\r\n}\r\nstatic void qs_do_or_die(struct ata_queued_cmd *qc, u8 status)\r\n{\r\nqc->err_mask |= ac_err_mask(status);\r\nif (!qc->err_mask) {\r\nata_qc_complete(qc);\r\n} else {\r\nstruct ata_port *ap = qc->ap;\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nata_ehi_clear_desc(ehi);\r\nata_ehi_push_desc(ehi, "status 0x%02X", status);\r\nif (qc->err_mask == AC_ERR_DEV)\r\nata_port_abort(ap);\r\nelse\r\nata_port_freeze(ap);\r\n}\r\n}\r\nstatic inline unsigned int qs_intr_pkt(struct ata_host *host)\r\n{\r\nunsigned int handled = 0;\r\nu8 sFFE;\r\nu8 __iomem *mmio_base = qs_mmio_base(host);\r\ndo {\r\nu32 sff0 = readl(mmio_base + QS_HST_SFF);\r\nu32 sff1 = readl(mmio_base + QS_HST_SFF + 4);\r\nu8 sEVLD = (sff1 >> 30) & 0x01;\r\nsFFE = sff1 >> 31;\r\nif (sEVLD) {\r\nu8 sDST = sff0 >> 16;\r\nu8 sHST = sff1 & 0x3f;\r\nunsigned int port_no = (sff1 >> 8) & 0x03;\r\nstruct ata_port *ap = host->ports[port_no];\r\nstruct qs_port_priv *pp = ap->private_data;\r\nstruct ata_queued_cmd *qc;\r\nDPRINTK("SFF=%08x%08x: sCHAN=%u sHST=%d sDST=%02x\n",\r\nsff1, sff0, port_no, sHST, sDST);\r\nhandled = 1;\r\nif (!pp || pp->state != qs_state_pkt)\r\ncontinue;\r\nqc = ata_qc_from_tag(ap, ap->link.active_tag);\r\nif (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING))) {\r\nswitch (sHST) {\r\ncase 0:\r\ncase 3:\r\nqs_enter_reg_mode(qc->ap);\r\nqs_do_or_die(qc, sDST);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\n}\r\n} while (!sFFE);\r\nreturn handled;\r\n}\r\nstatic inline unsigned int qs_intr_mmio(struct ata_host *host)\r\n{\r\nunsigned int handled = 0, port_no;\r\nfor (port_no = 0; port_no < host->n_ports; ++port_no) {\r\nstruct ata_port *ap = host->ports[port_no];\r\nstruct qs_port_priv *pp = ap->private_data;\r\nstruct ata_queued_cmd *qc;\r\nqc = ata_qc_from_tag(ap, ap->link.active_tag);\r\nif (!qc) {\r\nata_sff_check_status(ap);\r\nhandled = 1;\r\ncontinue;\r\n}\r\nif (!pp || pp->state != qs_state_mmio)\r\ncontinue;\r\nif (!(qc->tf.flags & ATA_TFLAG_POLLING))\r\nhandled |= ata_sff_port_intr(ap, qc);\r\n}\r\nreturn handled;\r\n}\r\nstatic irqreturn_t qs_intr(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nunsigned int handled = 0;\r\nunsigned long flags;\r\nVPRINTK("ENTER\n");\r\nspin_lock_irqsave(&host->lock, flags);\r\nhandled = qs_intr_pkt(host) | qs_intr_mmio(host);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nVPRINTK("EXIT\n");\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic void qs_ata_setup_port(struct ata_ioports *port, void __iomem *base)\r\n{\r\nport->cmd_addr =\r\nport->data_addr = base + 0x400;\r\nport->error_addr =\r\nport->feature_addr = base + 0x408;\r\nport->nsect_addr = base + 0x410;\r\nport->lbal_addr = base + 0x418;\r\nport->lbam_addr = base + 0x420;\r\nport->lbah_addr = base + 0x428;\r\nport->device_addr = base + 0x430;\r\nport->status_addr =\r\nport->command_addr = base + 0x438;\r\nport->altstatus_addr =\r\nport->ctl_addr = base + 0x440;\r\nport->scr_addr = base + 0xc00;\r\n}\r\nstatic int qs_port_start(struct ata_port *ap)\r\n{\r\nstruct device *dev = ap->host->dev;\r\nstruct qs_port_priv *pp;\r\nvoid __iomem *mmio_base = qs_mmio_base(ap->host);\r\nvoid __iomem *chan = mmio_base + (ap->port_no * 0x4000);\r\nu64 addr;\r\npp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);\r\nif (!pp)\r\nreturn -ENOMEM;\r\npp->pkt = dmam_alloc_coherent(dev, QS_PKT_BYTES, &pp->pkt_dma,\r\nGFP_KERNEL);\r\nif (!pp->pkt)\r\nreturn -ENOMEM;\r\nmemset(pp->pkt, 0, QS_PKT_BYTES);\r\nap->private_data = pp;\r\nqs_enter_reg_mode(ap);\r\naddr = (u64)pp->pkt_dma;\r\nwritel((u32) addr, chan + QS_CCF_CPBA);\r\nwritel((u32)(addr >> 32), chan + QS_CCF_CPBA + 4);\r\nreturn 0;\r\n}\r\nstatic void qs_host_stop(struct ata_host *host)\r\n{\r\nvoid __iomem *mmio_base = qs_mmio_base(host);\r\nwriteb(0, mmio_base + QS_HCT_CTRL);\r\nwriteb(QS_CNFG3_GSRST, mmio_base + QS_HCF_CNFG3);\r\n}\r\nstatic void qs_host_init(struct ata_host *host, unsigned int chip_id)\r\n{\r\nvoid __iomem *mmio_base = host->iomap[QS_MMIO_BAR];\r\nunsigned int port_no;\r\nwriteb(0, mmio_base + QS_HCT_CTRL);\r\nwriteb(QS_CNFG3_GSRST, mmio_base + QS_HCF_CNFG3);\r\nfor (port_no = 0; port_no < host->n_ports; ++port_no) {\r\nu8 __iomem *chan = mmio_base + (port_no * 0x4000);\r\nwriteb(QS_CTR1_RDEV|QS_CTR1_RCHN, chan + QS_CCT_CTR1);\r\nwriteb(QS_CTR0_REG, chan + QS_CCT_CTR0);\r\nreadb(chan + QS_CCT_CTR0);\r\n}\r\nwriteb(QS_SERD3_PHY_ENA, mmio_base + QS_HVS_SERD3);\r\nfor (port_no = 0; port_no < host->n_ports; ++port_no) {\r\nu8 __iomem *chan = mmio_base + (port_no * 0x4000);\r\nwritew(32, chan + QS_CFC_HUFT);\r\nwritew(32, chan + QS_CFC_HDFT);\r\nwritew(10, chan + QS_CFC_DUFT);\r\nwritew( 8, chan + QS_CFC_DDFT);\r\nwriteb(QS_CPB_ORDER, chan + QS_CCF_CSEP);\r\n}\r\nwriteb(1, mmio_base + QS_HCT_CTRL);\r\n}\r\nstatic int qs_set_dma_masks(struct pci_dev *pdev, void __iomem *mmio_base)\r\n{\r\nu32 bus_info = readl(mmio_base + QS_HID_HPHY);\r\nint rc, have_64bit_bus = (bus_info & QS_HPHY_64BIT);\r\nif (have_64bit_bus &&\r\n!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {\r\nrc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (rc) {\r\nrc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc) {\r\ndev_err(&pdev->dev,\r\n"64-bit DMA enable failed\n");\r\nreturn rc;\r\n}\r\n}\r\n} else {\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc) {\r\ndev_err(&pdev->dev, "32-bit DMA enable failed\n");\r\nreturn rc;\r\n}\r\nrc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc) {\r\ndev_err(&pdev->dev,\r\n"32-bit consistent DMA enable failed\n");\r\nreturn rc;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int qs_ata_init_one(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nunsigned int board_idx = (unsigned int) ent->driver_data;\r\nconst struct ata_port_info *ppi[] = { &qs_port_info[board_idx], NULL };\r\nstruct ata_host *host;\r\nint rc, port_no;\r\nata_print_version_once(&pdev->dev, DRV_VERSION);\r\nhost = ata_host_alloc_pinfo(&pdev->dev, ppi, QS_PORTS);\r\nif (!host)\r\nreturn -ENOMEM;\r\nrc = pcim_enable_device(pdev);\r\nif (rc)\r\nreturn rc;\r\nif ((pci_resource_flags(pdev, QS_MMIO_BAR) & IORESOURCE_MEM) == 0)\r\nreturn -ENODEV;\r\nrc = pcim_iomap_regions(pdev, 1 << QS_MMIO_BAR, DRV_NAME);\r\nif (rc)\r\nreturn rc;\r\nhost->iomap = pcim_iomap_table(pdev);\r\nrc = qs_set_dma_masks(pdev, host->iomap[QS_MMIO_BAR]);\r\nif (rc)\r\nreturn rc;\r\nfor (port_no = 0; port_no < host->n_ports; ++port_no) {\r\nstruct ata_port *ap = host->ports[port_no];\r\nunsigned int offset = port_no * 0x4000;\r\nvoid __iomem *chan = host->iomap[QS_MMIO_BAR] + offset;\r\nqs_ata_setup_port(&ap->ioaddr, chan);\r\nata_port_pbar_desc(ap, QS_MMIO_BAR, -1, "mmio");\r\nata_port_pbar_desc(ap, QS_MMIO_BAR, offset, "port");\r\n}\r\nqs_host_init(host, board_idx);\r\npci_set_master(pdev);\r\nreturn ata_host_activate(host, pdev->irq, qs_intr, IRQF_SHARED,\r\n&qs_ata_sht);\r\n}\r\nstatic int __init qs_ata_init(void)\r\n{\r\nreturn pci_register_driver(&qs_ata_pci_driver);\r\n}\r\nstatic void __exit qs_ata_exit(void)\r\n{\r\npci_unregister_driver(&qs_ata_pci_driver);\r\n}
