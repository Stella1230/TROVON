static inline void unlock_timer(struct k_itimer *timr, unsigned long flags)\r\n{\r\nspin_unlock_irqrestore(&timr->it_lock, flags);\r\n}\r\nstatic int posix_clock_realtime_get(clockid_t which_clock, struct timespec *tp)\r\n{\r\nktime_get_real_ts(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_clock_realtime_set(const clockid_t which_clock,\r\nconst struct timespec *tp)\r\n{\r\nreturn do_sys_settimeofday(tp, NULL);\r\n}\r\nstatic int posix_clock_realtime_adj(const clockid_t which_clock,\r\nstruct timex *t)\r\n{\r\nreturn do_adjtimex(t);\r\n}\r\nstatic int posix_ktime_get_ts(clockid_t which_clock, struct timespec *tp)\r\n{\r\nktime_get_ts(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_get_monotonic_raw(clockid_t which_clock, struct timespec *tp)\r\n{\r\ngetrawmonotonic(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_get_realtime_coarse(clockid_t which_clock, struct timespec *tp)\r\n{\r\n*tp = current_kernel_time();\r\nreturn 0;\r\n}\r\nstatic int posix_get_monotonic_coarse(clockid_t which_clock,\r\nstruct timespec *tp)\r\n{\r\n*tp = get_monotonic_coarse();\r\nreturn 0;\r\n}\r\nstatic int posix_get_coarse_res(const clockid_t which_clock, struct timespec *tp)\r\n{\r\n*tp = ktime_to_timespec(KTIME_LOW_RES);\r\nreturn 0;\r\n}\r\nstatic int posix_get_boottime(const clockid_t which_clock, struct timespec *tp)\r\n{\r\nget_monotonic_boottime(tp);\r\nreturn 0;\r\n}\r\nstatic __init int init_posix_timers(void)\r\n{\r\nstruct k_clock clock_realtime = {\r\n.clock_getres = hrtimer_get_res,\r\n.clock_get = posix_clock_realtime_get,\r\n.clock_set = posix_clock_realtime_set,\r\n.clock_adj = posix_clock_realtime_adj,\r\n.nsleep = common_nsleep,\r\n.nsleep_restart = hrtimer_nanosleep_restart,\r\n.timer_create = common_timer_create,\r\n.timer_set = common_timer_set,\r\n.timer_get = common_timer_get,\r\n.timer_del = common_timer_del,\r\n};\r\nstruct k_clock clock_monotonic = {\r\n.clock_getres = hrtimer_get_res,\r\n.clock_get = posix_ktime_get_ts,\r\n.nsleep = common_nsleep,\r\n.nsleep_restart = hrtimer_nanosleep_restart,\r\n.timer_create = common_timer_create,\r\n.timer_set = common_timer_set,\r\n.timer_get = common_timer_get,\r\n.timer_del = common_timer_del,\r\n};\r\nstruct k_clock clock_monotonic_raw = {\r\n.clock_getres = hrtimer_get_res,\r\n.clock_get = posix_get_monotonic_raw,\r\n};\r\nstruct k_clock clock_realtime_coarse = {\r\n.clock_getres = posix_get_coarse_res,\r\n.clock_get = posix_get_realtime_coarse,\r\n};\r\nstruct k_clock clock_monotonic_coarse = {\r\n.clock_getres = posix_get_coarse_res,\r\n.clock_get = posix_get_monotonic_coarse,\r\n};\r\nstruct k_clock clock_boottime = {\r\n.clock_getres = hrtimer_get_res,\r\n.clock_get = posix_get_boottime,\r\n.nsleep = common_nsleep,\r\n.nsleep_restart = hrtimer_nanosleep_restart,\r\n.timer_create = common_timer_create,\r\n.timer_set = common_timer_set,\r\n.timer_get = common_timer_get,\r\n.timer_del = common_timer_del,\r\n};\r\nposix_timers_register_clock(CLOCK_REALTIME, &clock_realtime);\r\nposix_timers_register_clock(CLOCK_MONOTONIC, &clock_monotonic);\r\nposix_timers_register_clock(CLOCK_MONOTONIC_RAW, &clock_monotonic_raw);\r\nposix_timers_register_clock(CLOCK_REALTIME_COARSE, &clock_realtime_coarse);\r\nposix_timers_register_clock(CLOCK_MONOTONIC_COARSE, &clock_monotonic_coarse);\r\nposix_timers_register_clock(CLOCK_BOOTTIME, &clock_boottime);\r\nposix_timers_cache = kmem_cache_create("posix_timers_cache",\r\nsizeof (struct k_itimer), 0, SLAB_PANIC,\r\nNULL);\r\nidr_init(&posix_timers_id);\r\nreturn 0;\r\n}\r\nstatic void schedule_next_timer(struct k_itimer *timr)\r\n{\r\nstruct hrtimer *timer = &timr->it.real.timer;\r\nif (timr->it.real.interval.tv64 == 0)\r\nreturn;\r\ntimr->it_overrun += (unsigned int) hrtimer_forward(timer,\r\ntimer->base->get_time(),\r\ntimr->it.real.interval);\r\ntimr->it_overrun_last = timr->it_overrun;\r\ntimr->it_overrun = -1;\r\n++timr->it_requeue_pending;\r\nhrtimer_restart(timer);\r\n}\r\nvoid do_schedule_next_timer(struct siginfo *info)\r\n{\r\nstruct k_itimer *timr;\r\nunsigned long flags;\r\ntimr = lock_timer(info->si_tid, &flags);\r\nif (timr && timr->it_requeue_pending == info->si_sys_private) {\r\nif (timr->it_clock < 0)\r\nposix_cpu_timer_schedule(timr);\r\nelse\r\nschedule_next_timer(timr);\r\ninfo->si_overrun += timr->it_overrun_last;\r\n}\r\nif (timr)\r\nunlock_timer(timr, flags);\r\n}\r\nint posix_timer_event(struct k_itimer *timr, int si_private)\r\n{\r\nstruct task_struct *task;\r\nint shared, ret = -1;\r\ntimr->sigq->info.si_sys_private = si_private;\r\nrcu_read_lock();\r\ntask = pid_task(timr->it_pid, PIDTYPE_PID);\r\nif (task) {\r\nshared = !(timr->it_sigev_notify & SIGEV_THREAD_ID);\r\nret = send_sigqueue(timr->sigq, task, shared);\r\n}\r\nrcu_read_unlock();\r\nreturn ret > 0;\r\n}\r\nstatic enum hrtimer_restart posix_timer_fn(struct hrtimer *timer)\r\n{\r\nstruct k_itimer *timr;\r\nunsigned long flags;\r\nint si_private = 0;\r\nenum hrtimer_restart ret = HRTIMER_NORESTART;\r\ntimr = container_of(timer, struct k_itimer, it.real.timer);\r\nspin_lock_irqsave(&timr->it_lock, flags);\r\nif (timr->it.real.interval.tv64 != 0)\r\nsi_private = ++timr->it_requeue_pending;\r\nif (posix_timer_event(timr, si_private)) {\r\nif (timr->it.real.interval.tv64 != 0) {\r\nktime_t now = hrtimer_cb_get_time(timer);\r\n#ifdef CONFIG_HIGH_RES_TIMERS\r\n{\r\nktime_t kj = ktime_set(0, NSEC_PER_SEC / HZ);\r\nif (timr->it.real.interval.tv64 < kj.tv64)\r\nnow = ktime_add(now, kj);\r\n}\r\n#endif\r\ntimr->it_overrun += (unsigned int)\r\nhrtimer_forward(timer, now,\r\ntimr->it.real.interval);\r\nret = HRTIMER_RESTART;\r\n++timr->it_requeue_pending;\r\n}\r\n}\r\nunlock_timer(timr, flags);\r\nreturn ret;\r\n}\r\nstatic struct pid *good_sigevent(sigevent_t * event)\r\n{\r\nstruct task_struct *rtn = current->group_leader;\r\nif ((event->sigev_notify & SIGEV_THREAD_ID ) &&\r\n(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||\r\n!same_thread_group(rtn, current) ||\r\n(event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))\r\nreturn NULL;\r\nif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&\r\n((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))\r\nreturn NULL;\r\nreturn task_pid(rtn);\r\n}\r\nvoid posix_timers_register_clock(const clockid_t clock_id,\r\nstruct k_clock *new_clock)\r\n{\r\nif ((unsigned) clock_id >= MAX_CLOCKS) {\r\nprintk(KERN_WARNING "POSIX clock register failed for clock_id %d\n",\r\nclock_id);\r\nreturn;\r\n}\r\nif (!new_clock->clock_get) {\r\nprintk(KERN_WARNING "POSIX clock id %d lacks clock_get()\n",\r\nclock_id);\r\nreturn;\r\n}\r\nif (!new_clock->clock_getres) {\r\nprintk(KERN_WARNING "POSIX clock id %d lacks clock_getres()\n",\r\nclock_id);\r\nreturn;\r\n}\r\nposix_clocks[clock_id] = *new_clock;\r\n}\r\nstatic struct k_itimer * alloc_posix_timer(void)\r\n{\r\nstruct k_itimer *tmr;\r\ntmr = kmem_cache_zalloc(posix_timers_cache, GFP_KERNEL);\r\nif (!tmr)\r\nreturn tmr;\r\nif (unlikely(!(tmr->sigq = sigqueue_alloc()))) {\r\nkmem_cache_free(posix_timers_cache, tmr);\r\nreturn NULL;\r\n}\r\nmemset(&tmr->sigq->info, 0, sizeof(siginfo_t));\r\nreturn tmr;\r\n}\r\nstatic void k_itimer_rcu_free(struct rcu_head *head)\r\n{\r\nstruct k_itimer *tmr = container_of(head, struct k_itimer, it.rcu);\r\nkmem_cache_free(posix_timers_cache, tmr);\r\n}\r\nstatic void release_posix_timer(struct k_itimer *tmr, int it_id_set)\r\n{\r\nif (it_id_set) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&idr_lock, flags);\r\nidr_remove(&posix_timers_id, tmr->it_id);\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\n}\r\nput_pid(tmr->it_pid);\r\nsigqueue_free(tmr->sigq);\r\ncall_rcu(&tmr->it.rcu, k_itimer_rcu_free);\r\n}\r\nstatic struct k_clock *clockid_to_kclock(const clockid_t id)\r\n{\r\nif (id < 0)\r\nreturn (id & CLOCKFD_MASK) == CLOCKFD ?\r\n&clock_posix_dynamic : &clock_posix_cpu;\r\nif (id >= MAX_CLOCKS || !posix_clocks[id].clock_getres)\r\nreturn NULL;\r\nreturn &posix_clocks[id];\r\n}\r\nstatic int common_timer_create(struct k_itimer *new_timer)\r\n{\r\nhrtimer_init(&new_timer->it.real.timer, new_timer->it_clock, 0);\r\nreturn 0;\r\n}\r\nstatic struct k_itimer *__lock_timer(timer_t timer_id, unsigned long *flags)\r\n{\r\nstruct k_itimer *timr;\r\nrcu_read_lock();\r\ntimr = idr_find(&posix_timers_id, (int)timer_id);\r\nif (timr) {\r\nspin_lock_irqsave(&timr->it_lock, *flags);\r\nif (timr->it_signal == current->signal) {\r\nrcu_read_unlock();\r\nreturn timr;\r\n}\r\nspin_unlock_irqrestore(&timr->it_lock, *flags);\r\n}\r\nrcu_read_unlock();\r\nreturn NULL;\r\n}\r\nstatic void\r\ncommon_timer_get(struct k_itimer *timr, struct itimerspec *cur_setting)\r\n{\r\nktime_t now, remaining, iv;\r\nstruct hrtimer *timer = &timr->it.real.timer;\r\nmemset(cur_setting, 0, sizeof(struct itimerspec));\r\niv = timr->it.real.interval;\r\nif (iv.tv64)\r\ncur_setting->it_interval = ktime_to_timespec(iv);\r\nelse if (!hrtimer_active(timer) &&\r\n(timr->it_sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE)\r\nreturn;\r\nnow = timer->base->get_time();\r\nif (iv.tv64 && (timr->it_requeue_pending & REQUEUE_PENDING ||\r\n(timr->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE))\r\ntimr->it_overrun += (unsigned int) hrtimer_forward(timer, now, iv);\r\nremaining = ktime_sub(hrtimer_get_expires(timer), now);\r\nif (remaining.tv64 <= 0) {\r\nif ((timr->it_sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE)\r\ncur_setting->it_value.tv_nsec = 1;\r\n} else\r\ncur_setting->it_value = ktime_to_timespec(remaining);\r\n}\r\nstatic int\r\ncommon_timer_set(struct k_itimer *timr, int flags,\r\nstruct itimerspec *new_setting, struct itimerspec *old_setting)\r\n{\r\nstruct hrtimer *timer = &timr->it.real.timer;\r\nenum hrtimer_mode mode;\r\nif (old_setting)\r\ncommon_timer_get(timr, old_setting);\r\ntimr->it.real.interval.tv64 = 0;\r\nif (hrtimer_try_to_cancel(timer) < 0)\r\nreturn TIMER_RETRY;\r\ntimr->it_requeue_pending = (timr->it_requeue_pending + 2) &\r\n~REQUEUE_PENDING;\r\ntimr->it_overrun_last = 0;\r\nif (!new_setting->it_value.tv_sec && !new_setting->it_value.tv_nsec)\r\nreturn 0;\r\nmode = flags & TIMER_ABSTIME ? HRTIMER_MODE_ABS : HRTIMER_MODE_REL;\r\nhrtimer_init(&timr->it.real.timer, timr->it_clock, mode);\r\ntimr->it.real.timer.function = posix_timer_fn;\r\nhrtimer_set_expires(timer, timespec_to_ktime(new_setting->it_value));\r\ntimr->it.real.interval = timespec_to_ktime(new_setting->it_interval);\r\nif (((timr->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE)) {\r\nif (mode == HRTIMER_MODE_REL) {\r\nhrtimer_add_expires(timer, timer->base->get_time());\r\n}\r\nreturn 0;\r\n}\r\nhrtimer_start_expires(timer, mode);\r\nreturn 0;\r\n}\r\nstatic int common_timer_del(struct k_itimer *timer)\r\n{\r\ntimer->it.real.interval.tv64 = 0;\r\nif (hrtimer_try_to_cancel(&timer->it.real.timer) < 0)\r\nreturn TIMER_RETRY;\r\nreturn 0;\r\n}\r\nstatic inline int timer_delete_hook(struct k_itimer *timer)\r\n{\r\nstruct k_clock *kc = clockid_to_kclock(timer->it_clock);\r\nif (WARN_ON_ONCE(!kc || !kc->timer_del))\r\nreturn -EINVAL;\r\nreturn kc->timer_del(timer);\r\n}\r\nstatic void itimer_delete(struct k_itimer *timer)\r\n{\r\nunsigned long flags;\r\nretry_delete:\r\nspin_lock_irqsave(&timer->it_lock, flags);\r\nif (timer_delete_hook(timer) == TIMER_RETRY) {\r\nunlock_timer(timer, flags);\r\ngoto retry_delete;\r\n}\r\nlist_del(&timer->list);\r\ntimer->it_signal = NULL;\r\nunlock_timer(timer, flags);\r\nrelease_posix_timer(timer, IT_ID_SET);\r\n}\r\nvoid exit_itimers(struct signal_struct *sig)\r\n{\r\nstruct k_itimer *tmr;\r\nwhile (!list_empty(&sig->posix_timers)) {\r\ntmr = list_entry(sig->posix_timers.next, struct k_itimer, list);\r\nitimer_delete(tmr);\r\n}\r\n}\r\nstatic int common_nsleep(const clockid_t which_clock, int flags,\r\nstruct timespec *tsave, struct timespec __user *rmtp)\r\n{\r\nreturn hrtimer_nanosleep(tsave, rmtp, flags & TIMER_ABSTIME ?\r\nHRTIMER_MODE_ABS : HRTIMER_MODE_REL,\r\nwhich_clock);\r\n}\r\nlong clock_nanosleep_restart(struct restart_block *restart_block)\r\n{\r\nclockid_t which_clock = restart_block->nanosleep.clockid;\r\nstruct k_clock *kc = clockid_to_kclock(which_clock);\r\nif (WARN_ON_ONCE(!kc || !kc->nsleep_restart))\r\nreturn -EINVAL;\r\nreturn kc->nsleep_restart(restart_block);\r\n}
