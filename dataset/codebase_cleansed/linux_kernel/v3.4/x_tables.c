int\r\nxt_register_target(struct xt_target *target)\r\n{\r\nu_int8_t af = target->family;\r\nint ret;\r\nret = mutex_lock_interruptible(&xt[af].mutex);\r\nif (ret != 0)\r\nreturn ret;\r\nlist_add(&target->list, &xt[af].target);\r\nmutex_unlock(&xt[af].mutex);\r\nreturn ret;\r\n}\r\nvoid\r\nxt_unregister_target(struct xt_target *target)\r\n{\r\nu_int8_t af = target->family;\r\nmutex_lock(&xt[af].mutex);\r\nlist_del(&target->list);\r\nmutex_unlock(&xt[af].mutex);\r\n}\r\nint\r\nxt_register_targets(struct xt_target *target, unsigned int n)\r\n{\r\nunsigned int i;\r\nint err = 0;\r\nfor (i = 0; i < n; i++) {\r\nerr = xt_register_target(&target[i]);\r\nif (err)\r\ngoto err;\r\n}\r\nreturn err;\r\nerr:\r\nif (i > 0)\r\nxt_unregister_targets(target, i);\r\nreturn err;\r\n}\r\nvoid\r\nxt_unregister_targets(struct xt_target *target, unsigned int n)\r\n{\r\nwhile (n-- > 0)\r\nxt_unregister_target(&target[n]);\r\n}\r\nint\r\nxt_register_match(struct xt_match *match)\r\n{\r\nu_int8_t af = match->family;\r\nint ret;\r\nret = mutex_lock_interruptible(&xt[af].mutex);\r\nif (ret != 0)\r\nreturn ret;\r\nlist_add(&match->list, &xt[af].match);\r\nmutex_unlock(&xt[af].mutex);\r\nreturn ret;\r\n}\r\nvoid\r\nxt_unregister_match(struct xt_match *match)\r\n{\r\nu_int8_t af = match->family;\r\nmutex_lock(&xt[af].mutex);\r\nlist_del(&match->list);\r\nmutex_unlock(&xt[af].mutex);\r\n}\r\nint\r\nxt_register_matches(struct xt_match *match, unsigned int n)\r\n{\r\nunsigned int i;\r\nint err = 0;\r\nfor (i = 0; i < n; i++) {\r\nerr = xt_register_match(&match[i]);\r\nif (err)\r\ngoto err;\r\n}\r\nreturn err;\r\nerr:\r\nif (i > 0)\r\nxt_unregister_matches(match, i);\r\nreturn err;\r\n}\r\nvoid\r\nxt_unregister_matches(struct xt_match *match, unsigned int n)\r\n{\r\nwhile (n-- > 0)\r\nxt_unregister_match(&match[n]);\r\n}\r\nstruct xt_match *xt_find_match(u8 af, const char *name, u8 revision)\r\n{\r\nstruct xt_match *m;\r\nint err = -ENOENT;\r\nif (mutex_lock_interruptible(&xt[af].mutex) != 0)\r\nreturn ERR_PTR(-EINTR);\r\nlist_for_each_entry(m, &xt[af].match, list) {\r\nif (strcmp(m->name, name) == 0) {\r\nif (m->revision == revision) {\r\nif (try_module_get(m->me)) {\r\nmutex_unlock(&xt[af].mutex);\r\nreturn m;\r\n}\r\n} else\r\nerr = -EPROTOTYPE;\r\n}\r\n}\r\nmutex_unlock(&xt[af].mutex);\r\nif (af != NFPROTO_UNSPEC)\r\nreturn xt_find_match(NFPROTO_UNSPEC, name, revision);\r\nreturn ERR_PTR(err);\r\n}\r\nstruct xt_match *\r\nxt_request_find_match(uint8_t nfproto, const char *name, uint8_t revision)\r\n{\r\nstruct xt_match *match;\r\nmatch = xt_find_match(nfproto, name, revision);\r\nif (IS_ERR(match)) {\r\nrequest_module("%st_%s", xt_prefix[nfproto], name);\r\nmatch = xt_find_match(nfproto, name, revision);\r\n}\r\nreturn match;\r\n}\r\nstruct xt_target *xt_find_target(u8 af, const char *name, u8 revision)\r\n{\r\nstruct xt_target *t;\r\nint err = -ENOENT;\r\nif (mutex_lock_interruptible(&xt[af].mutex) != 0)\r\nreturn ERR_PTR(-EINTR);\r\nlist_for_each_entry(t, &xt[af].target, list) {\r\nif (strcmp(t->name, name) == 0) {\r\nif (t->revision == revision) {\r\nif (try_module_get(t->me)) {\r\nmutex_unlock(&xt[af].mutex);\r\nreturn t;\r\n}\r\n} else\r\nerr = -EPROTOTYPE;\r\n}\r\n}\r\nmutex_unlock(&xt[af].mutex);\r\nif (af != NFPROTO_UNSPEC)\r\nreturn xt_find_target(NFPROTO_UNSPEC, name, revision);\r\nreturn ERR_PTR(err);\r\n}\r\nstruct xt_target *xt_request_find_target(u8 af, const char *name, u8 revision)\r\n{\r\nstruct xt_target *target;\r\ntarget = xt_find_target(af, name, revision);\r\nif (IS_ERR(target)) {\r\nrequest_module("%st_%s", xt_prefix[af], name);\r\ntarget = xt_find_target(af, name, revision);\r\n}\r\nreturn target;\r\n}\r\nstatic int match_revfn(u8 af, const char *name, u8 revision, int *bestp)\r\n{\r\nconst struct xt_match *m;\r\nint have_rev = 0;\r\nlist_for_each_entry(m, &xt[af].match, list) {\r\nif (strcmp(m->name, name) == 0) {\r\nif (m->revision > *bestp)\r\n*bestp = m->revision;\r\nif (m->revision == revision)\r\nhave_rev = 1;\r\n}\r\n}\r\nif (af != NFPROTO_UNSPEC && !have_rev)\r\nreturn match_revfn(NFPROTO_UNSPEC, name, revision, bestp);\r\nreturn have_rev;\r\n}\r\nstatic int target_revfn(u8 af, const char *name, u8 revision, int *bestp)\r\n{\r\nconst struct xt_target *t;\r\nint have_rev = 0;\r\nlist_for_each_entry(t, &xt[af].target, list) {\r\nif (strcmp(t->name, name) == 0) {\r\nif (t->revision > *bestp)\r\n*bestp = t->revision;\r\nif (t->revision == revision)\r\nhave_rev = 1;\r\n}\r\n}\r\nif (af != NFPROTO_UNSPEC && !have_rev)\r\nreturn target_revfn(NFPROTO_UNSPEC, name, revision, bestp);\r\nreturn have_rev;\r\n}\r\nint xt_find_revision(u8 af, const char *name, u8 revision, int target,\r\nint *err)\r\n{\r\nint have_rev, best = -1;\r\nif (mutex_lock_interruptible(&xt[af].mutex) != 0) {\r\n*err = -EINTR;\r\nreturn 1;\r\n}\r\nif (target == 1)\r\nhave_rev = target_revfn(af, name, revision, &best);\r\nelse\r\nhave_rev = match_revfn(af, name, revision, &best);\r\nmutex_unlock(&xt[af].mutex);\r\nif (best == -1) {\r\n*err = -ENOENT;\r\nreturn 0;\r\n}\r\n*err = best;\r\nif (!have_rev)\r\n*err = -EPROTONOSUPPORT;\r\nreturn 1;\r\n}\r\nstatic char *textify_hooks(char *buf, size_t size, unsigned int mask)\r\n{\r\nstatic const char *const names[] = {\r\n"PREROUTING", "INPUT", "FORWARD",\r\n"OUTPUT", "POSTROUTING", "BROUTING",\r\n};\r\nunsigned int i;\r\nchar *p = buf;\r\nbool np = false;\r\nint res;\r\n*p = '\0';\r\nfor (i = 0; i < ARRAY_SIZE(names); ++i) {\r\nif (!(mask & (1 << i)))\r\ncontinue;\r\nres = snprintf(p, size, "%s%s", np ? "/" : "", names[i]);\r\nif (res > 0) {\r\nsize -= res;\r\np += res;\r\n}\r\nnp = true;\r\n}\r\nreturn buf;\r\n}\r\nint xt_check_match(struct xt_mtchk_param *par,\r\nunsigned int size, u_int8_t proto, bool inv_proto)\r\n{\r\nint ret;\r\nif (XT_ALIGN(par->match->matchsize) != size &&\r\npar->match->matchsize != -1) {\r\npr_err("%s_tables: %s.%u match: invalid size "\r\n"%u (kernel) != (user) %u\n",\r\nxt_prefix[par->family], par->match->name,\r\npar->match->revision,\r\nXT_ALIGN(par->match->matchsize), size);\r\nreturn -EINVAL;\r\n}\r\nif (par->match->table != NULL &&\r\nstrcmp(par->match->table, par->table) != 0) {\r\npr_err("%s_tables: %s match: only valid in %s table, not %s\n",\r\nxt_prefix[par->family], par->match->name,\r\npar->match->table, par->table);\r\nreturn -EINVAL;\r\n}\r\nif (par->match->hooks && (par->hook_mask & ~par->match->hooks) != 0) {\r\nchar used[64], allow[64];\r\npr_err("%s_tables: %s match: used from hooks %s, but only "\r\n"valid from %s\n",\r\nxt_prefix[par->family], par->match->name,\r\ntextify_hooks(used, sizeof(used), par->hook_mask),\r\ntextify_hooks(allow, sizeof(allow), par->match->hooks));\r\nreturn -EINVAL;\r\n}\r\nif (par->match->proto && (par->match->proto != proto || inv_proto)) {\r\npr_err("%s_tables: %s match: only valid for protocol %u\n",\r\nxt_prefix[par->family], par->match->name,\r\npar->match->proto);\r\nreturn -EINVAL;\r\n}\r\nif (par->match->checkentry != NULL) {\r\nret = par->match->checkentry(par);\r\nif (ret < 0)\r\nreturn ret;\r\nelse if (ret > 0)\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nint xt_compat_add_offset(u_int8_t af, unsigned int offset, int delta)\r\n{\r\nstruct xt_af *xp = &xt[af];\r\nif (!xp->compat_tab) {\r\nif (!xp->number)\r\nreturn -EINVAL;\r\nxp->compat_tab = vmalloc(sizeof(struct compat_delta) * xp->number);\r\nif (!xp->compat_tab)\r\nreturn -ENOMEM;\r\nxp->cur = 0;\r\n}\r\nif (xp->cur >= xp->number)\r\nreturn -EINVAL;\r\nif (xp->cur)\r\ndelta += xp->compat_tab[xp->cur - 1].delta;\r\nxp->compat_tab[xp->cur].offset = offset;\r\nxp->compat_tab[xp->cur].delta = delta;\r\nxp->cur++;\r\nreturn 0;\r\n}\r\nvoid xt_compat_flush_offsets(u_int8_t af)\r\n{\r\nif (xt[af].compat_tab) {\r\nvfree(xt[af].compat_tab);\r\nxt[af].compat_tab = NULL;\r\nxt[af].number = 0;\r\nxt[af].cur = 0;\r\n}\r\n}\r\nint xt_compat_calc_jump(u_int8_t af, unsigned int offset)\r\n{\r\nstruct compat_delta *tmp = xt[af].compat_tab;\r\nint mid, left = 0, right = xt[af].cur - 1;\r\nwhile (left <= right) {\r\nmid = (left + right) >> 1;\r\nif (offset > tmp[mid].offset)\r\nleft = mid + 1;\r\nelse if (offset < tmp[mid].offset)\r\nright = mid - 1;\r\nelse\r\nreturn mid ? tmp[mid - 1].delta : 0;\r\n}\r\nreturn left ? tmp[left - 1].delta : 0;\r\n}\r\nvoid xt_compat_init_offsets(u_int8_t af, unsigned int number)\r\n{\r\nxt[af].number = number;\r\nxt[af].cur = 0;\r\n}\r\nint xt_compat_match_offset(const struct xt_match *match)\r\n{\r\nu_int16_t csize = match->compatsize ? : match->matchsize;\r\nreturn XT_ALIGN(match->matchsize) - COMPAT_XT_ALIGN(csize);\r\n}\r\nint xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\r\nunsigned int *size)\r\n{\r\nconst struct xt_match *match = m->u.kernel.match;\r\nstruct compat_xt_entry_match *cm = (struct compat_xt_entry_match *)m;\r\nint pad, off = xt_compat_match_offset(match);\r\nu_int16_t msize = cm->u.user.match_size;\r\nm = *dstptr;\r\nmemcpy(m, cm, sizeof(*cm));\r\nif (match->compat_from_user)\r\nmatch->compat_from_user(m->data, cm->data);\r\nelse\r\nmemcpy(m->data, cm->data, msize - sizeof(*cm));\r\npad = XT_ALIGN(match->matchsize) - match->matchsize;\r\nif (pad > 0)\r\nmemset(m->data + match->matchsize, 0, pad);\r\nmsize += off;\r\nm->u.user.match_size = msize;\r\n*size += off;\r\n*dstptr += msize;\r\nreturn 0;\r\n}\r\nint xt_compat_match_to_user(const struct xt_entry_match *m,\r\nvoid __user **dstptr, unsigned int *size)\r\n{\r\nconst struct xt_match *match = m->u.kernel.match;\r\nstruct compat_xt_entry_match __user *cm = *dstptr;\r\nint off = xt_compat_match_offset(match);\r\nu_int16_t msize = m->u.user.match_size - off;\r\nif (copy_to_user(cm, m, sizeof(*cm)) ||\r\nput_user(msize, &cm->u.user.match_size) ||\r\ncopy_to_user(cm->u.user.name, m->u.kernel.match->name,\r\nstrlen(m->u.kernel.match->name) + 1))\r\nreturn -EFAULT;\r\nif (match->compat_to_user) {\r\nif (match->compat_to_user((void __user *)cm->data, m->data))\r\nreturn -EFAULT;\r\n} else {\r\nif (copy_to_user(cm->data, m->data, msize - sizeof(*cm)))\r\nreturn -EFAULT;\r\n}\r\n*size -= off;\r\n*dstptr += msize;\r\nreturn 0;\r\n}\r\nint xt_check_target(struct xt_tgchk_param *par,\r\nunsigned int size, u_int8_t proto, bool inv_proto)\r\n{\r\nint ret;\r\nif (XT_ALIGN(par->target->targetsize) != size) {\r\npr_err("%s_tables: %s.%u target: invalid size "\r\n"%u (kernel) != (user) %u\n",\r\nxt_prefix[par->family], par->target->name,\r\npar->target->revision,\r\nXT_ALIGN(par->target->targetsize), size);\r\nreturn -EINVAL;\r\n}\r\nif (par->target->table != NULL &&\r\nstrcmp(par->target->table, par->table) != 0) {\r\npr_err("%s_tables: %s target: only valid in %s table, not %s\n",\r\nxt_prefix[par->family], par->target->name,\r\npar->target->table, par->table);\r\nreturn -EINVAL;\r\n}\r\nif (par->target->hooks && (par->hook_mask & ~par->target->hooks) != 0) {\r\nchar used[64], allow[64];\r\npr_err("%s_tables: %s target: used from hooks %s, but only "\r\n"usable from %s\n",\r\nxt_prefix[par->family], par->target->name,\r\ntextify_hooks(used, sizeof(used), par->hook_mask),\r\ntextify_hooks(allow, sizeof(allow), par->target->hooks));\r\nreturn -EINVAL;\r\n}\r\nif (par->target->proto && (par->target->proto != proto || inv_proto)) {\r\npr_err("%s_tables: %s target: only valid for protocol %u\n",\r\nxt_prefix[par->family], par->target->name,\r\npar->target->proto);\r\nreturn -EINVAL;\r\n}\r\nif (par->target->checkentry != NULL) {\r\nret = par->target->checkentry(par);\r\nif (ret < 0)\r\nreturn ret;\r\nelse if (ret > 0)\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nint xt_compat_target_offset(const struct xt_target *target)\r\n{\r\nu_int16_t csize = target->compatsize ? : target->targetsize;\r\nreturn XT_ALIGN(target->targetsize) - COMPAT_XT_ALIGN(csize);\r\n}\r\nvoid xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\r\nunsigned int *size)\r\n{\r\nconst struct xt_target *target = t->u.kernel.target;\r\nstruct compat_xt_entry_target *ct = (struct compat_xt_entry_target *)t;\r\nint pad, off = xt_compat_target_offset(target);\r\nu_int16_t tsize = ct->u.user.target_size;\r\nt = *dstptr;\r\nmemcpy(t, ct, sizeof(*ct));\r\nif (target->compat_from_user)\r\ntarget->compat_from_user(t->data, ct->data);\r\nelse\r\nmemcpy(t->data, ct->data, tsize - sizeof(*ct));\r\npad = XT_ALIGN(target->targetsize) - target->targetsize;\r\nif (pad > 0)\r\nmemset(t->data + target->targetsize, 0, pad);\r\ntsize += off;\r\nt->u.user.target_size = tsize;\r\n*size += off;\r\n*dstptr += tsize;\r\n}\r\nint xt_compat_target_to_user(const struct xt_entry_target *t,\r\nvoid __user **dstptr, unsigned int *size)\r\n{\r\nconst struct xt_target *target = t->u.kernel.target;\r\nstruct compat_xt_entry_target __user *ct = *dstptr;\r\nint off = xt_compat_target_offset(target);\r\nu_int16_t tsize = t->u.user.target_size - off;\r\nif (copy_to_user(ct, t, sizeof(*ct)) ||\r\nput_user(tsize, &ct->u.user.target_size) ||\r\ncopy_to_user(ct->u.user.name, t->u.kernel.target->name,\r\nstrlen(t->u.kernel.target->name) + 1))\r\nreturn -EFAULT;\r\nif (target->compat_to_user) {\r\nif (target->compat_to_user((void __user *)ct->data, t->data))\r\nreturn -EFAULT;\r\n} else {\r\nif (copy_to_user(ct->data, t->data, tsize - sizeof(*ct)))\r\nreturn -EFAULT;\r\n}\r\n*size -= off;\r\n*dstptr += tsize;\r\nreturn 0;\r\n}\r\nstruct xt_table_info *xt_alloc_table_info(unsigned int size)\r\n{\r\nstruct xt_table_info *newinfo;\r\nint cpu;\r\nif ((SMP_ALIGN(size) >> PAGE_SHIFT) + 2 > totalram_pages)\r\nreturn NULL;\r\nnewinfo = kzalloc(XT_TABLE_INFO_SZ, GFP_KERNEL);\r\nif (!newinfo)\r\nreturn NULL;\r\nnewinfo->size = size;\r\nfor_each_possible_cpu(cpu) {\r\nif (size <= PAGE_SIZE)\r\nnewinfo->entries[cpu] = kmalloc_node(size,\r\nGFP_KERNEL,\r\ncpu_to_node(cpu));\r\nelse\r\nnewinfo->entries[cpu] = vmalloc_node(size,\r\ncpu_to_node(cpu));\r\nif (newinfo->entries[cpu] == NULL) {\r\nxt_free_table_info(newinfo);\r\nreturn NULL;\r\n}\r\n}\r\nreturn newinfo;\r\n}\r\nvoid xt_free_table_info(struct xt_table_info *info)\r\n{\r\nint cpu;\r\nfor_each_possible_cpu(cpu) {\r\nif (info->size <= PAGE_SIZE)\r\nkfree(info->entries[cpu]);\r\nelse\r\nvfree(info->entries[cpu]);\r\n}\r\nif (info->jumpstack != NULL) {\r\nif (sizeof(void *) * info->stacksize > PAGE_SIZE) {\r\nfor_each_possible_cpu(cpu)\r\nvfree(info->jumpstack[cpu]);\r\n} else {\r\nfor_each_possible_cpu(cpu)\r\nkfree(info->jumpstack[cpu]);\r\n}\r\n}\r\nif (sizeof(void **) * nr_cpu_ids > PAGE_SIZE)\r\nvfree(info->jumpstack);\r\nelse\r\nkfree(info->jumpstack);\r\nfree_percpu(info->stackptr);\r\nkfree(info);\r\n}\r\nstruct xt_table *xt_find_table_lock(struct net *net, u_int8_t af,\r\nconst char *name)\r\n{\r\nstruct xt_table *t;\r\nif (mutex_lock_interruptible(&xt[af].mutex) != 0)\r\nreturn ERR_PTR(-EINTR);\r\nlist_for_each_entry(t, &net->xt.tables[af], list)\r\nif (strcmp(t->name, name) == 0 && try_module_get(t->me))\r\nreturn t;\r\nmutex_unlock(&xt[af].mutex);\r\nreturn NULL;\r\n}\r\nvoid xt_table_unlock(struct xt_table *table)\r\n{\r\nmutex_unlock(&xt[table->af].mutex);\r\n}\r\nvoid xt_compat_lock(u_int8_t af)\r\n{\r\nmutex_lock(&xt[af].compat_mutex);\r\n}\r\nvoid xt_compat_unlock(u_int8_t af)\r\n{\r\nmutex_unlock(&xt[af].compat_mutex);\r\n}\r\nstatic int xt_jumpstack_alloc(struct xt_table_info *i)\r\n{\r\nunsigned int size;\r\nint cpu;\r\ni->stackptr = alloc_percpu(unsigned int);\r\nif (i->stackptr == NULL)\r\nreturn -ENOMEM;\r\nsize = sizeof(void **) * nr_cpu_ids;\r\nif (size > PAGE_SIZE)\r\ni->jumpstack = vzalloc(size);\r\nelse\r\ni->jumpstack = kzalloc(size, GFP_KERNEL);\r\nif (i->jumpstack == NULL)\r\nreturn -ENOMEM;\r\ni->stacksize *= xt_jumpstack_multiplier;\r\nsize = sizeof(void *) * i->stacksize;\r\nfor_each_possible_cpu(cpu) {\r\nif (size > PAGE_SIZE)\r\ni->jumpstack[cpu] = vmalloc_node(size,\r\ncpu_to_node(cpu));\r\nelse\r\ni->jumpstack[cpu] = kmalloc_node(size,\r\nGFP_KERNEL, cpu_to_node(cpu));\r\nif (i->jumpstack[cpu] == NULL)\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstruct xt_table_info *\r\nxt_replace_table(struct xt_table *table,\r\nunsigned int num_counters,\r\nstruct xt_table_info *newinfo,\r\nint *error)\r\n{\r\nstruct xt_table_info *private;\r\nint ret;\r\nret = xt_jumpstack_alloc(newinfo);\r\nif (ret < 0) {\r\n*error = ret;\r\nreturn NULL;\r\n}\r\nlocal_bh_disable();\r\nprivate = table->private;\r\nif (num_counters != private->number) {\r\npr_debug("num_counters != table->private->number (%u/%u)\n",\r\nnum_counters, private->number);\r\nlocal_bh_enable();\r\n*error = -EAGAIN;\r\nreturn NULL;\r\n}\r\ntable->private = newinfo;\r\nnewinfo->initial_entries = private->initial_entries;\r\nlocal_bh_enable();\r\n#ifdef CONFIG_AUDIT\r\nif (audit_enabled) {\r\nstruct audit_buffer *ab;\r\nab = audit_log_start(current->audit_context, GFP_KERNEL,\r\nAUDIT_NETFILTER_CFG);\r\nif (ab) {\r\naudit_log_format(ab, "table=%s family=%u entries=%u",\r\ntable->name, table->af,\r\nprivate->number);\r\naudit_log_end(ab);\r\n}\r\n}\r\n#endif\r\nreturn private;\r\n}\r\nstruct xt_table *xt_register_table(struct net *net,\r\nconst struct xt_table *input_table,\r\nstruct xt_table_info *bootstrap,\r\nstruct xt_table_info *newinfo)\r\n{\r\nint ret;\r\nstruct xt_table_info *private;\r\nstruct xt_table *t, *table;\r\ntable = kmemdup(input_table, sizeof(struct xt_table), GFP_KERNEL);\r\nif (!table) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nret = mutex_lock_interruptible(&xt[table->af].mutex);\r\nif (ret != 0)\r\ngoto out_free;\r\nlist_for_each_entry(t, &net->xt.tables[table->af], list) {\r\nif (strcmp(t->name, table->name) == 0) {\r\nret = -EEXIST;\r\ngoto unlock;\r\n}\r\n}\r\ntable->private = bootstrap;\r\nif (!xt_replace_table(table, 0, newinfo, &ret))\r\ngoto unlock;\r\nprivate = table->private;\r\npr_debug("table->private->number = %u\n", private->number);\r\nprivate->initial_entries = private->number;\r\nlist_add(&table->list, &net->xt.tables[table->af]);\r\nmutex_unlock(&xt[table->af].mutex);\r\nreturn table;\r\nunlock:\r\nmutex_unlock(&xt[table->af].mutex);\r\nout_free:\r\nkfree(table);\r\nout:\r\nreturn ERR_PTR(ret);\r\n}\r\nvoid *xt_unregister_table(struct xt_table *table)\r\n{\r\nstruct xt_table_info *private;\r\nmutex_lock(&xt[table->af].mutex);\r\nprivate = table->private;\r\nlist_del(&table->list);\r\nmutex_unlock(&xt[table->af].mutex);\r\nkfree(table);\r\nreturn private;\r\n}\r\nstatic void *xt_table_seq_start(struct seq_file *seq, loff_t *pos)\r\n{\r\nstruct xt_names_priv *priv = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nu_int8_t af = priv->af;\r\nmutex_lock(&xt[af].mutex);\r\nreturn seq_list_start(&net->xt.tables[af], *pos);\r\n}\r\nstatic void *xt_table_seq_next(struct seq_file *seq, void *v, loff_t *pos)\r\n{\r\nstruct xt_names_priv *priv = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nu_int8_t af = priv->af;\r\nreturn seq_list_next(v, &net->xt.tables[af], pos);\r\n}\r\nstatic void xt_table_seq_stop(struct seq_file *seq, void *v)\r\n{\r\nstruct xt_names_priv *priv = seq->private;\r\nu_int8_t af = priv->af;\r\nmutex_unlock(&xt[af].mutex);\r\n}\r\nstatic int xt_table_seq_show(struct seq_file *seq, void *v)\r\n{\r\nstruct xt_table *table = list_entry(v, struct xt_table, list);\r\nif (strlen(table->name))\r\nreturn seq_printf(seq, "%s\n", table->name);\r\nelse\r\nreturn 0;\r\n}\r\nstatic int xt_table_open(struct inode *inode, struct file *file)\r\n{\r\nint ret;\r\nstruct xt_names_priv *priv;\r\nret = seq_open_net(inode, file, &xt_table_seq_ops,\r\nsizeof(struct xt_names_priv));\r\nif (!ret) {\r\npriv = ((struct seq_file *)file->private_data)->private;\r\npriv->af = (unsigned long)PDE(inode)->data;\r\n}\r\nreturn ret;\r\n}\r\nstatic void *xt_mttg_seq_next(struct seq_file *seq, void *v, loff_t *ppos,\r\nbool is_target)\r\n{\r\nstatic const uint8_t next_class[] = {\r\n[MTTG_TRAV_NFP_UNSPEC] = MTTG_TRAV_NFP_SPEC,\r\n[MTTG_TRAV_NFP_SPEC] = MTTG_TRAV_DONE,\r\n};\r\nstruct nf_mttg_trav *trav = seq->private;\r\nswitch (trav->class) {\r\ncase MTTG_TRAV_INIT:\r\ntrav->class = MTTG_TRAV_NFP_UNSPEC;\r\nmutex_lock(&xt[NFPROTO_UNSPEC].mutex);\r\ntrav->head = trav->curr = is_target ?\r\n&xt[NFPROTO_UNSPEC].target : &xt[NFPROTO_UNSPEC].match;\r\nbreak;\r\ncase MTTG_TRAV_NFP_UNSPEC:\r\ntrav->curr = trav->curr->next;\r\nif (trav->curr != trav->head)\r\nbreak;\r\nmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\r\nmutex_lock(&xt[trav->nfproto].mutex);\r\ntrav->head = trav->curr = is_target ?\r\n&xt[trav->nfproto].target : &xt[trav->nfproto].match;\r\ntrav->class = next_class[trav->class];\r\nbreak;\r\ncase MTTG_TRAV_NFP_SPEC:\r\ntrav->curr = trav->curr->next;\r\nif (trav->curr != trav->head)\r\nbreak;\r\ndefault:\r\nreturn NULL;\r\n}\r\nif (ppos != NULL)\r\n++*ppos;\r\nreturn trav;\r\n}\r\nstatic void *xt_mttg_seq_start(struct seq_file *seq, loff_t *pos,\r\nbool is_target)\r\n{\r\nstruct nf_mttg_trav *trav = seq->private;\r\nunsigned int j;\r\ntrav->class = MTTG_TRAV_INIT;\r\nfor (j = 0; j < *pos; ++j)\r\nif (xt_mttg_seq_next(seq, NULL, NULL, is_target) == NULL)\r\nreturn NULL;\r\nreturn trav;\r\n}\r\nstatic void xt_mttg_seq_stop(struct seq_file *seq, void *v)\r\n{\r\nstruct nf_mttg_trav *trav = seq->private;\r\nswitch (trav->class) {\r\ncase MTTG_TRAV_NFP_UNSPEC:\r\nmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\r\nbreak;\r\ncase MTTG_TRAV_NFP_SPEC:\r\nmutex_unlock(&xt[trav->nfproto].mutex);\r\nbreak;\r\n}\r\n}\r\nstatic void *xt_match_seq_start(struct seq_file *seq, loff_t *pos)\r\n{\r\nreturn xt_mttg_seq_start(seq, pos, false);\r\n}\r\nstatic void *xt_match_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\r\n{\r\nreturn xt_mttg_seq_next(seq, v, ppos, false);\r\n}\r\nstatic int xt_match_seq_show(struct seq_file *seq, void *v)\r\n{\r\nconst struct nf_mttg_trav *trav = seq->private;\r\nconst struct xt_match *match;\r\nswitch (trav->class) {\r\ncase MTTG_TRAV_NFP_UNSPEC:\r\ncase MTTG_TRAV_NFP_SPEC:\r\nif (trav->curr == trav->head)\r\nreturn 0;\r\nmatch = list_entry(trav->curr, struct xt_match, list);\r\nreturn (*match->name == '\0') ? 0 :\r\nseq_printf(seq, "%s\n", match->name);\r\n}\r\nreturn 0;\r\n}\r\nstatic int xt_match_open(struct inode *inode, struct file *file)\r\n{\r\nstruct seq_file *seq;\r\nstruct nf_mttg_trav *trav;\r\nint ret;\r\ntrav = kmalloc(sizeof(*trav), GFP_KERNEL);\r\nif (trav == NULL)\r\nreturn -ENOMEM;\r\nret = seq_open(file, &xt_match_seq_ops);\r\nif (ret < 0) {\r\nkfree(trav);\r\nreturn ret;\r\n}\r\nseq = file->private_data;\r\nseq->private = trav;\r\ntrav->nfproto = (unsigned long)PDE(inode)->data;\r\nreturn 0;\r\n}\r\nstatic void *xt_target_seq_start(struct seq_file *seq, loff_t *pos)\r\n{\r\nreturn xt_mttg_seq_start(seq, pos, true);\r\n}\r\nstatic void *xt_target_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\r\n{\r\nreturn xt_mttg_seq_next(seq, v, ppos, true);\r\n}\r\nstatic int xt_target_seq_show(struct seq_file *seq, void *v)\r\n{\r\nconst struct nf_mttg_trav *trav = seq->private;\r\nconst struct xt_target *target;\r\nswitch (trav->class) {\r\ncase MTTG_TRAV_NFP_UNSPEC:\r\ncase MTTG_TRAV_NFP_SPEC:\r\nif (trav->curr == trav->head)\r\nreturn 0;\r\ntarget = list_entry(trav->curr, struct xt_target, list);\r\nreturn (*target->name == '\0') ? 0 :\r\nseq_printf(seq, "%s\n", target->name);\r\n}\r\nreturn 0;\r\n}\r\nstatic int xt_target_open(struct inode *inode, struct file *file)\r\n{\r\nstruct seq_file *seq;\r\nstruct nf_mttg_trav *trav;\r\nint ret;\r\ntrav = kmalloc(sizeof(*trav), GFP_KERNEL);\r\nif (trav == NULL)\r\nreturn -ENOMEM;\r\nret = seq_open(file, &xt_target_seq_ops);\r\nif (ret < 0) {\r\nkfree(trav);\r\nreturn ret;\r\n}\r\nseq = file->private_data;\r\nseq->private = trav;\r\ntrav->nfproto = (unsigned long)PDE(inode)->data;\r\nreturn 0;\r\n}\r\nstruct nf_hook_ops *xt_hook_link(const struct xt_table *table, nf_hookfn *fn)\r\n{\r\nunsigned int hook_mask = table->valid_hooks;\r\nuint8_t i, num_hooks = hweight32(hook_mask);\r\nuint8_t hooknum;\r\nstruct nf_hook_ops *ops;\r\nint ret;\r\nops = kmalloc(sizeof(*ops) * num_hooks, GFP_KERNEL);\r\nif (ops == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nfor (i = 0, hooknum = 0; i < num_hooks && hook_mask != 0;\r\nhook_mask >>= 1, ++hooknum) {\r\nif (!(hook_mask & 1))\r\ncontinue;\r\nops[i].hook = fn;\r\nops[i].owner = table->me;\r\nops[i].pf = table->af;\r\nops[i].hooknum = hooknum;\r\nops[i].priority = table->priority;\r\n++i;\r\n}\r\nret = nf_register_hooks(ops, num_hooks);\r\nif (ret < 0) {\r\nkfree(ops);\r\nreturn ERR_PTR(ret);\r\n}\r\nreturn ops;\r\n}\r\nvoid xt_hook_unlink(const struct xt_table *table, struct nf_hook_ops *ops)\r\n{\r\nnf_unregister_hooks(ops, hweight32(table->valid_hooks));\r\nkfree(ops);\r\n}\r\nint xt_proto_init(struct net *net, u_int8_t af)\r\n{\r\n#ifdef CONFIG_PROC_FS\r\nchar buf[XT_FUNCTION_MAXNAMELEN];\r\nstruct proc_dir_entry *proc;\r\n#endif\r\nif (af >= ARRAY_SIZE(xt_prefix))\r\nreturn -EINVAL;\r\n#ifdef CONFIG_PROC_FS\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_TABLES, sizeof(buf));\r\nproc = proc_create_data(buf, 0440, net->proc_net, &xt_table_ops,\r\n(void *)(unsigned long)af);\r\nif (!proc)\r\ngoto out;\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\r\nproc = proc_create_data(buf, 0440, net->proc_net, &xt_match_ops,\r\n(void *)(unsigned long)af);\r\nif (!proc)\r\ngoto out_remove_tables;\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\r\nproc = proc_create_data(buf, 0440, net->proc_net, &xt_target_ops,\r\n(void *)(unsigned long)af);\r\nif (!proc)\r\ngoto out_remove_matches;\r\n#endif\r\nreturn 0;\r\n#ifdef CONFIG_PROC_FS\r\nout_remove_matches:\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\r\nproc_net_remove(net, buf);\r\nout_remove_tables:\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_TABLES, sizeof(buf));\r\nproc_net_remove(net, buf);\r\nout:\r\nreturn -1;\r\n#endif\r\n}\r\nvoid xt_proto_fini(struct net *net, u_int8_t af)\r\n{\r\n#ifdef CONFIG_PROC_FS\r\nchar buf[XT_FUNCTION_MAXNAMELEN];\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_TABLES, sizeof(buf));\r\nproc_net_remove(net, buf);\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\r\nproc_net_remove(net, buf);\r\nstrlcpy(buf, xt_prefix[af], sizeof(buf));\r\nstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\r\nproc_net_remove(net, buf);\r\n#endif\r\n}\r\nstatic int __net_init xt_net_init(struct net *net)\r\n{\r\nint i;\r\nfor (i = 0; i < NFPROTO_NUMPROTO; i++)\r\nINIT_LIST_HEAD(&net->xt.tables[i]);\r\nreturn 0;\r\n}\r\nstatic int __init xt_init(void)\r\n{\r\nunsigned int i;\r\nint rv;\r\nfor_each_possible_cpu(i) {\r\nseqcount_init(&per_cpu(xt_recseq, i));\r\n}\r\nxt = kmalloc(sizeof(struct xt_af) * NFPROTO_NUMPROTO, GFP_KERNEL);\r\nif (!xt)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < NFPROTO_NUMPROTO; i++) {\r\nmutex_init(&xt[i].mutex);\r\n#ifdef CONFIG_COMPAT\r\nmutex_init(&xt[i].compat_mutex);\r\nxt[i].compat_tab = NULL;\r\n#endif\r\nINIT_LIST_HEAD(&xt[i].target);\r\nINIT_LIST_HEAD(&xt[i].match);\r\n}\r\nrv = register_pernet_subsys(&xt_net_ops);\r\nif (rv < 0)\r\nkfree(xt);\r\nreturn rv;\r\n}\r\nstatic void __exit xt_fini(void)\r\n{\r\nunregister_pernet_subsys(&xt_net_ops);\r\nkfree(xt);\r\n}
