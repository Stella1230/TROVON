static int __init bootonly(char *str)\r\n{\r\nsmp_alt_once = 1;\r\nreturn 1;\r\n}\r\nstatic int __init debug_alt(char *str)\r\n{\r\ndebug_alternative = 1;\r\nreturn 1;\r\n}\r\nstatic int __init setup_noreplace_smp(char *str)\r\n{\r\nnoreplace_smp = 1;\r\nreturn 1;\r\n}\r\nstatic int __init setup_noreplace_paravirt(char *str)\r\n{\r\nnoreplace_paravirt = 1;\r\nreturn 1;\r\n}\r\nvoid __init arch_init_ideal_nops(void)\r\n{\r\nswitch (boot_cpu_data.x86_vendor) {\r\ncase X86_VENDOR_INTEL:\r\nif (boot_cpu_data.x86 == 6 &&\r\nboot_cpu_data.x86_model >= 0x0f &&\r\nboot_cpu_data.x86_model != 0x1c &&\r\nboot_cpu_data.x86_model != 0x26 &&\r\nboot_cpu_data.x86_model != 0x27 &&\r\nboot_cpu_data.x86_model < 0x30) {\r\nideal_nops = k8_nops;\r\n} else if (boot_cpu_has(X86_FEATURE_NOPL)) {\r\nideal_nops = p6_nops;\r\n} else {\r\n#ifdef CONFIG_X86_64\r\nideal_nops = k8_nops;\r\n#else\r\nideal_nops = intel_nops;\r\n#endif\r\n}\r\ndefault:\r\n#ifdef CONFIG_X86_64\r\nideal_nops = k8_nops;\r\n#else\r\nif (boot_cpu_has(X86_FEATURE_K8))\r\nideal_nops = k8_nops;\r\nelse if (boot_cpu_has(X86_FEATURE_K7))\r\nideal_nops = k7_nops;\r\nelse\r\nideal_nops = intel_nops;\r\n#endif\r\n}\r\n}\r\nstatic void __init_or_module add_nops(void *insns, unsigned int len)\r\n{\r\nwhile (len > 0) {\r\nunsigned int noplen = len;\r\nif (noplen > ASM_NOP_MAX)\r\nnoplen = ASM_NOP_MAX;\r\nmemcpy(insns, ideal_nops[noplen], noplen);\r\ninsns += noplen;\r\nlen -= noplen;\r\n}\r\n}\r\nvoid __init_or_module apply_alternatives(struct alt_instr *start,\r\nstruct alt_instr *end)\r\n{\r\nstruct alt_instr *a;\r\nu8 *instr, *replacement;\r\nu8 insnbuf[MAX_PATCH_LEN];\r\nDPRINTK("%s: alt table %p -> %p\n", __func__, start, end);\r\nfor (a = start; a < end; a++) {\r\ninstr = (u8 *)&a->instr_offset + a->instr_offset;\r\nreplacement = (u8 *)&a->repl_offset + a->repl_offset;\r\nBUG_ON(a->replacementlen > a->instrlen);\r\nBUG_ON(a->instrlen > sizeof(insnbuf));\r\nBUG_ON(a->cpuid >= NCAPINTS*32);\r\nif (!boot_cpu_has(a->cpuid))\r\ncontinue;\r\nmemcpy(insnbuf, replacement, a->replacementlen);\r\nif (*insnbuf == 0xe8 && a->replacementlen == 5)\r\n*(s32 *)(insnbuf + 1) += replacement - instr;\r\nadd_nops(insnbuf + a->replacementlen,\r\na->instrlen - a->replacementlen);\r\ntext_poke_early(instr, insnbuf, a->instrlen);\r\n}\r\n}\r\nstatic void alternatives_smp_lock(const s32 *start, const s32 *end,\r\nu8 *text, u8 *text_end)\r\n{\r\nconst s32 *poff;\r\nmutex_lock(&text_mutex);\r\nfor (poff = start; poff < end; poff++) {\r\nu8 *ptr = (u8 *)poff + *poff;\r\nif (!*poff || ptr < text || ptr >= text_end)\r\ncontinue;\r\nif (*ptr == 0x3e)\r\ntext_poke(ptr, ((unsigned char []){0xf0}), 1);\r\n};\r\nmutex_unlock(&text_mutex);\r\n}\r\nstatic void alternatives_smp_unlock(const s32 *start, const s32 *end,\r\nu8 *text, u8 *text_end)\r\n{\r\nconst s32 *poff;\r\nif (noreplace_smp)\r\nreturn;\r\nmutex_lock(&text_mutex);\r\nfor (poff = start; poff < end; poff++) {\r\nu8 *ptr = (u8 *)poff + *poff;\r\nif (!*poff || ptr < text || ptr >= text_end)\r\ncontinue;\r\nif (*ptr == 0xf0)\r\ntext_poke(ptr, ((unsigned char []){0x3E}), 1);\r\n};\r\nmutex_unlock(&text_mutex);\r\n}\r\nvoid __init_or_module alternatives_smp_module_add(struct module *mod,\r\nchar *name,\r\nvoid *locks, void *locks_end,\r\nvoid *text, void *text_end)\r\n{\r\nstruct smp_alt_module *smp;\r\nif (noreplace_smp)\r\nreturn;\r\nif (smp_alt_once) {\r\nif (boot_cpu_has(X86_FEATURE_UP))\r\nalternatives_smp_unlock(locks, locks_end,\r\ntext, text_end);\r\nreturn;\r\n}\r\nsmp = kzalloc(sizeof(*smp), GFP_KERNEL);\r\nif (NULL == smp)\r\nreturn;\r\nsmp->mod = mod;\r\nsmp->name = name;\r\nsmp->locks = locks;\r\nsmp->locks_end = locks_end;\r\nsmp->text = text;\r\nsmp->text_end = text_end;\r\nDPRINTK("%s: locks %p -> %p, text %p -> %p, name %s\n",\r\n__func__, smp->locks, smp->locks_end,\r\nsmp->text, smp->text_end, smp->name);\r\nmutex_lock(&smp_alt);\r\nlist_add_tail(&smp->next, &smp_alt_modules);\r\nif (boot_cpu_has(X86_FEATURE_UP))\r\nalternatives_smp_unlock(smp->locks, smp->locks_end,\r\nsmp->text, smp->text_end);\r\nmutex_unlock(&smp_alt);\r\n}\r\nvoid __init_or_module alternatives_smp_module_del(struct module *mod)\r\n{\r\nstruct smp_alt_module *item;\r\nif (smp_alt_once || noreplace_smp)\r\nreturn;\r\nmutex_lock(&smp_alt);\r\nlist_for_each_entry(item, &smp_alt_modules, next) {\r\nif (mod != item->mod)\r\ncontinue;\r\nlist_del(&item->next);\r\nmutex_unlock(&smp_alt);\r\nDPRINTK("%s: %s\n", __func__, item->name);\r\nkfree(item);\r\nreturn;\r\n}\r\nmutex_unlock(&smp_alt);\r\n}\r\nvoid alternatives_smp_switch(int smp)\r\n{\r\nstruct smp_alt_module *mod;\r\n#ifdef CONFIG_LOCKDEP\r\nprintk("lockdep: fixing up alternatives.\n");\r\n#endif\r\nif (noreplace_smp || smp_alt_once || skip_smp_alternatives)\r\nreturn;\r\nBUG_ON(!smp && (num_online_cpus() > 1));\r\nmutex_lock(&smp_alt);\r\nif (smp == smp_mode) {\r\n} else if (smp) {\r\nprintk(KERN_INFO "SMP alternatives: switching to SMP code\n");\r\nclear_cpu_cap(&boot_cpu_data, X86_FEATURE_UP);\r\nclear_cpu_cap(&cpu_data(0), X86_FEATURE_UP);\r\nlist_for_each_entry(mod, &smp_alt_modules, next)\r\nalternatives_smp_lock(mod->locks, mod->locks_end,\r\nmod->text, mod->text_end);\r\n} else {\r\nprintk(KERN_INFO "SMP alternatives: switching to UP code\n");\r\nset_cpu_cap(&boot_cpu_data, X86_FEATURE_UP);\r\nset_cpu_cap(&cpu_data(0), X86_FEATURE_UP);\r\nlist_for_each_entry(mod, &smp_alt_modules, next)\r\nalternatives_smp_unlock(mod->locks, mod->locks_end,\r\nmod->text, mod->text_end);\r\n}\r\nsmp_mode = smp;\r\nmutex_unlock(&smp_alt);\r\n}\r\nint alternatives_text_reserved(void *start, void *end)\r\n{\r\nstruct smp_alt_module *mod;\r\nconst s32 *poff;\r\nu8 *text_start = start;\r\nu8 *text_end = end;\r\nlist_for_each_entry(mod, &smp_alt_modules, next) {\r\nif (mod->text > text_end || mod->text_end < text_start)\r\ncontinue;\r\nfor (poff = mod->locks; poff < mod->locks_end; poff++) {\r\nconst u8 *ptr = (const u8 *)poff + *poff;\r\nif (text_start <= ptr && text_end > ptr)\r\nreturn 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid __init_or_module apply_paravirt(struct paravirt_patch_site *start,\r\nstruct paravirt_patch_site *end)\r\n{\r\nstruct paravirt_patch_site *p;\r\nchar insnbuf[MAX_PATCH_LEN];\r\nif (noreplace_paravirt)\r\nreturn;\r\nfor (p = start; p < end; p++) {\r\nunsigned int used;\r\nBUG_ON(p->len > MAX_PATCH_LEN);\r\nmemcpy(insnbuf, p->instr, p->len);\r\nused = pv_init_ops.patch(p->instrtype, p->clobbers, insnbuf,\r\n(unsigned long)p->instr, p->len);\r\nBUG_ON(used > p->len);\r\nadd_nops(insnbuf + used, p->len - used);\r\ntext_poke_early(p->instr, insnbuf, p->len);\r\n}\r\n}\r\nvoid __init alternative_instructions(void)\r\n{\r\nstop_nmi();\r\napply_alternatives(__alt_instructions, __alt_instructions_end);\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nif (num_possible_cpus() < 2)\r\nsmp_alt_once = 1;\r\n#endif\r\n#ifdef CONFIG_SMP\r\nif (smp_alt_once) {\r\nif (1 == num_possible_cpus()) {\r\nprintk(KERN_INFO "SMP alternatives: switching to UP code\n");\r\nset_cpu_cap(&boot_cpu_data, X86_FEATURE_UP);\r\nset_cpu_cap(&cpu_data(0), X86_FEATURE_UP);\r\nalternatives_smp_unlock(__smp_locks, __smp_locks_end,\r\n_text, _etext);\r\n}\r\n} else {\r\nalternatives_smp_module_add(NULL, "core kernel",\r\n__smp_locks, __smp_locks_end,\r\n_text, _etext);\r\nif (num_present_cpus() == 1 || setup_max_cpus <= 1)\r\nalternatives_smp_switch(0);\r\n}\r\n#endif\r\napply_paravirt(__parainstructions, __parainstructions_end);\r\nif (smp_alt_once)\r\nfree_init_pages("SMP alternatives",\r\n(unsigned long)__smp_locks,\r\n(unsigned long)__smp_locks_end);\r\nrestart_nmi();\r\n}\r\nvoid *__init_or_module text_poke_early(void *addr, const void *opcode,\r\nsize_t len)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nmemcpy(addr, opcode, len);\r\nsync_core();\r\nlocal_irq_restore(flags);\r\nreturn addr;\r\n}\r\nvoid *__kprobes text_poke(void *addr, const void *opcode, size_t len)\r\n{\r\nunsigned long flags;\r\nchar *vaddr;\r\nstruct page *pages[2];\r\nint i;\r\nif (!core_kernel_text((unsigned long)addr)) {\r\npages[0] = vmalloc_to_page(addr);\r\npages[1] = vmalloc_to_page(addr + PAGE_SIZE);\r\n} else {\r\npages[0] = virt_to_page(addr);\r\nWARN_ON(!PageReserved(pages[0]));\r\npages[1] = virt_to_page(addr + PAGE_SIZE);\r\n}\r\nBUG_ON(!pages[0]);\r\nlocal_irq_save(flags);\r\nset_fixmap(FIX_TEXT_POKE0, page_to_phys(pages[0]));\r\nif (pages[1])\r\nset_fixmap(FIX_TEXT_POKE1, page_to_phys(pages[1]));\r\nvaddr = (char *)fix_to_virt(FIX_TEXT_POKE0);\r\nmemcpy(&vaddr[(unsigned long)addr & ~PAGE_MASK], opcode, len);\r\nclear_fixmap(FIX_TEXT_POKE0);\r\nif (pages[1])\r\nclear_fixmap(FIX_TEXT_POKE1);\r\nlocal_flush_tlb();\r\nsync_core();\r\nfor (i = 0; i < len; i++)\r\nBUG_ON(((char *)addr)[i] != ((char *)opcode)[i]);\r\nlocal_irq_restore(flags);\r\nreturn addr;\r\n}\r\nstatic int __kprobes stop_machine_text_poke(void *data)\r\n{\r\nstruct text_poke_params *tpp = data;\r\nstruct text_poke_param *p;\r\nint i;\r\nif (atomic_dec_and_test(&stop_machine_first)) {\r\nfor (i = 0; i < tpp->nparams; i++) {\r\np = &tpp->params[i];\r\ntext_poke(p->addr, p->opcode, p->len);\r\n}\r\nsmp_wmb();\r\nwrote_text = 1;\r\n} else {\r\nwhile (!wrote_text)\r\ncpu_relax();\r\nsmp_mb();\r\n}\r\nfor (i = 0; i < tpp->nparams; i++) {\r\np = &tpp->params[i];\r\nflush_icache_range((unsigned long)p->addr,\r\n(unsigned long)p->addr + p->len);\r\n}\r\nsync_core();\r\nreturn 0;\r\n}\r\nvoid *__kprobes text_poke_smp(void *addr, const void *opcode, size_t len)\r\n{\r\nstruct text_poke_params tpp;\r\nstruct text_poke_param p;\r\np.addr = addr;\r\np.opcode = opcode;\r\np.len = len;\r\ntpp.params = &p;\r\ntpp.nparams = 1;\r\natomic_set(&stop_machine_first, 1);\r\nwrote_text = 0;\r\n__stop_machine(stop_machine_text_poke, (void *)&tpp, cpu_online_mask);\r\nreturn addr;\r\n}\r\nvoid __kprobes text_poke_smp_batch(struct text_poke_param *params, int n)\r\n{\r\nstruct text_poke_params tpp = {.params = params, .nparams = n};\r\natomic_set(&stop_machine_first, 1);\r\nwrote_text = 0;\r\n__stop_machine(stop_machine_text_poke, (void *)&tpp, cpu_online_mask);\r\n}
