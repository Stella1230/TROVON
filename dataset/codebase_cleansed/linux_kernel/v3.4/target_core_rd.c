static int rd_attach_hba(struct se_hba *hba, u32 host_id)\r\n{\r\nstruct rd_host *rd_host;\r\nrd_host = kzalloc(sizeof(struct rd_host), GFP_KERNEL);\r\nif (!rd_host) {\r\npr_err("Unable to allocate memory for struct rd_host\n");\r\nreturn -ENOMEM;\r\n}\r\nrd_host->rd_host_id = host_id;\r\nhba->hba_ptr = rd_host;\r\npr_debug("CORE_HBA[%d] - TCM Ramdisk HBA Driver %s on"\r\n" Generic Target Core Stack %s\n", hba->hba_id,\r\nRD_HBA_VERSION, TARGET_CORE_MOD_VERSION);\r\npr_debug("CORE_HBA[%d] - Attached Ramdisk HBA: %u to Generic"\r\n" MaxSectors: %u\n", hba->hba_id,\r\nrd_host->rd_host_id, RD_MAX_SECTORS);\r\nreturn 0;\r\n}\r\nstatic void rd_detach_hba(struct se_hba *hba)\r\n{\r\nstruct rd_host *rd_host = hba->hba_ptr;\r\npr_debug("CORE_HBA[%d] - Detached Ramdisk HBA: %u from"\r\n" Generic Target Core\n", hba->hba_id, rd_host->rd_host_id);\r\nkfree(rd_host);\r\nhba->hba_ptr = NULL;\r\n}\r\nstatic void rd_release_device_space(struct rd_dev *rd_dev)\r\n{\r\nu32 i, j, page_count = 0, sg_per_table;\r\nstruct rd_dev_sg_table *sg_table;\r\nstruct page *pg;\r\nstruct scatterlist *sg;\r\nif (!rd_dev->sg_table_array || !rd_dev->sg_table_count)\r\nreturn;\r\nsg_table = rd_dev->sg_table_array;\r\nfor (i = 0; i < rd_dev->sg_table_count; i++) {\r\nsg = sg_table[i].sg_table;\r\nsg_per_table = sg_table[i].rd_sg_count;\r\nfor (j = 0; j < sg_per_table; j++) {\r\npg = sg_page(&sg[j]);\r\nif (pg) {\r\n__free_page(pg);\r\npage_count++;\r\n}\r\n}\r\nkfree(sg);\r\n}\r\npr_debug("CORE_RD[%u] - Released device space for Ramdisk"\r\n" Device ID: %u, pages %u in %u tables total bytes %lu\n",\r\nrd_dev->rd_host->rd_host_id, rd_dev->rd_dev_id, page_count,\r\nrd_dev->sg_table_count, (unsigned long)page_count * PAGE_SIZE);\r\nkfree(sg_table);\r\nrd_dev->sg_table_array = NULL;\r\nrd_dev->sg_table_count = 0;\r\n}\r\nstatic int rd_build_device_space(struct rd_dev *rd_dev)\r\n{\r\nu32 i = 0, j, page_offset = 0, sg_per_table, sg_tables, total_sg_needed;\r\nu32 max_sg_per_table = (RD_MAX_ALLOCATION_SIZE /\r\nsizeof(struct scatterlist));\r\nstruct rd_dev_sg_table *sg_table;\r\nstruct page *pg;\r\nstruct scatterlist *sg;\r\nif (rd_dev->rd_page_count <= 0) {\r\npr_err("Illegal page count: %u for Ramdisk device\n",\r\nrd_dev->rd_page_count);\r\nreturn -EINVAL;\r\n}\r\ntotal_sg_needed = rd_dev->rd_page_count;\r\nsg_tables = (total_sg_needed / max_sg_per_table) + 1;\r\nsg_table = kzalloc(sg_tables * sizeof(struct rd_dev_sg_table), GFP_KERNEL);\r\nif (!sg_table) {\r\npr_err("Unable to allocate memory for Ramdisk"\r\n" scatterlist tables\n");\r\nreturn -ENOMEM;\r\n}\r\nrd_dev->sg_table_array = sg_table;\r\nrd_dev->sg_table_count = sg_tables;\r\nwhile (total_sg_needed) {\r\nsg_per_table = (total_sg_needed > max_sg_per_table) ?\r\nmax_sg_per_table : total_sg_needed;\r\nsg = kzalloc(sg_per_table * sizeof(struct scatterlist),\r\nGFP_KERNEL);\r\nif (!sg) {\r\npr_err("Unable to allocate scatterlist array"\r\n" for struct rd_dev\n");\r\nreturn -ENOMEM;\r\n}\r\nsg_init_table(sg, sg_per_table);\r\nsg_table[i].sg_table = sg;\r\nsg_table[i].rd_sg_count = sg_per_table;\r\nsg_table[i].page_start_offset = page_offset;\r\nsg_table[i++].page_end_offset = (page_offset + sg_per_table)\r\n- 1;\r\nfor (j = 0; j < sg_per_table; j++) {\r\npg = alloc_pages(GFP_KERNEL, 0);\r\nif (!pg) {\r\npr_err("Unable to allocate scatterlist"\r\n" pages for struct rd_dev_sg_table\n");\r\nreturn -ENOMEM;\r\n}\r\nsg_assign_page(&sg[j], pg);\r\nsg[j].length = PAGE_SIZE;\r\n}\r\npage_offset += sg_per_table;\r\ntotal_sg_needed -= sg_per_table;\r\n}\r\npr_debug("CORE_RD[%u] - Built Ramdisk Device ID: %u space of"\r\n" %u pages in %u tables\n", rd_dev->rd_host->rd_host_id,\r\nrd_dev->rd_dev_id, rd_dev->rd_page_count,\r\nrd_dev->sg_table_count);\r\nreturn 0;\r\n}\r\nstatic void *rd_allocate_virtdevice(\r\nstruct se_hba *hba,\r\nconst char *name,\r\nint rd_direct)\r\n{\r\nstruct rd_dev *rd_dev;\r\nstruct rd_host *rd_host = hba->hba_ptr;\r\nrd_dev = kzalloc(sizeof(struct rd_dev), GFP_KERNEL);\r\nif (!rd_dev) {\r\npr_err("Unable to allocate memory for struct rd_dev\n");\r\nreturn NULL;\r\n}\r\nrd_dev->rd_host = rd_host;\r\nrd_dev->rd_direct = rd_direct;\r\nreturn rd_dev;\r\n}\r\nstatic void *rd_MEMCPY_allocate_virtdevice(struct se_hba *hba, const char *name)\r\n{\r\nreturn rd_allocate_virtdevice(hba, name, 0);\r\n}\r\nstatic struct se_device *rd_create_virtdevice(\r\nstruct se_hba *hba,\r\nstruct se_subsystem_dev *se_dev,\r\nvoid *p,\r\nint rd_direct)\r\n{\r\nstruct se_device *dev;\r\nstruct se_dev_limits dev_limits;\r\nstruct rd_dev *rd_dev = p;\r\nstruct rd_host *rd_host = hba->hba_ptr;\r\nint dev_flags = 0, ret;\r\nchar prod[16], rev[4];\r\nmemset(&dev_limits, 0, sizeof(struct se_dev_limits));\r\nret = rd_build_device_space(rd_dev);\r\nif (ret < 0)\r\ngoto fail;\r\nsnprintf(prod, 16, "RAMDISK-%s", (rd_dev->rd_direct) ? "DR" : "MCP");\r\nsnprintf(rev, 4, "%s", (rd_dev->rd_direct) ? RD_DR_VERSION :\r\nRD_MCP_VERSION);\r\ndev_limits.limits.logical_block_size = RD_BLOCKSIZE;\r\ndev_limits.limits.max_hw_sectors = RD_MAX_SECTORS;\r\ndev_limits.limits.max_sectors = RD_MAX_SECTORS;\r\ndev_limits.hw_queue_depth = RD_MAX_DEVICE_QUEUE_DEPTH;\r\ndev_limits.queue_depth = RD_DEVICE_QUEUE_DEPTH;\r\ndev = transport_add_device_to_core_hba(hba,\r\n&rd_mcp_template, se_dev, dev_flags, rd_dev,\r\n&dev_limits, prod, rev);\r\nif (!dev)\r\ngoto fail;\r\nrd_dev->rd_dev_id = rd_host->rd_host_dev_id_count++;\r\nrd_dev->rd_queue_depth = dev->queue_depth;\r\npr_debug("CORE_RD[%u] - Added TCM %s Ramdisk Device ID: %u of"\r\n" %u pages in %u tables, %lu total bytes\n",\r\nrd_host->rd_host_id, (!rd_dev->rd_direct) ? "MEMCPY" :\r\n"DIRECT", rd_dev->rd_dev_id, rd_dev->rd_page_count,\r\nrd_dev->sg_table_count,\r\n(unsigned long)(rd_dev->rd_page_count * PAGE_SIZE));\r\nreturn dev;\r\nfail:\r\nrd_release_device_space(rd_dev);\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic struct se_device *rd_MEMCPY_create_virtdevice(\r\nstruct se_hba *hba,\r\nstruct se_subsystem_dev *se_dev,\r\nvoid *p)\r\n{\r\nreturn rd_create_virtdevice(hba, se_dev, p, 0);\r\n}\r\nstatic void rd_free_device(void *p)\r\n{\r\nstruct rd_dev *rd_dev = p;\r\nrd_release_device_space(rd_dev);\r\nkfree(rd_dev);\r\n}\r\nstatic inline struct rd_request *RD_REQ(struct se_task *task)\r\n{\r\nreturn container_of(task, struct rd_request, rd_task);\r\n}\r\nstatic struct se_task *\r\nrd_alloc_task(unsigned char *cdb)\r\n{\r\nstruct rd_request *rd_req;\r\nrd_req = kzalloc(sizeof(struct rd_request), GFP_KERNEL);\r\nif (!rd_req) {\r\npr_err("Unable to allocate struct rd_request\n");\r\nreturn NULL;\r\n}\r\nreturn &rd_req->rd_task;\r\n}\r\nstatic struct rd_dev_sg_table *rd_get_sg_table(struct rd_dev *rd_dev, u32 page)\r\n{\r\nu32 i;\r\nstruct rd_dev_sg_table *sg_table;\r\nfor (i = 0; i < rd_dev->sg_table_count; i++) {\r\nsg_table = &rd_dev->sg_table_array[i];\r\nif ((sg_table->page_start_offset <= page) &&\r\n(sg_table->page_end_offset >= page))\r\nreturn sg_table;\r\n}\r\npr_err("Unable to locate struct rd_dev_sg_table for page: %u\n",\r\npage);\r\nreturn NULL;\r\n}\r\nstatic int rd_MEMCPY(struct rd_request *req, u32 read_rd)\r\n{\r\nstruct se_task *task = &req->rd_task;\r\nstruct rd_dev *dev = req->rd_task.task_se_cmd->se_dev->dev_ptr;\r\nstruct rd_dev_sg_table *table;\r\nstruct scatterlist *rd_sg;\r\nstruct sg_mapping_iter m;\r\nu32 rd_offset = req->rd_offset;\r\nu32 src_len;\r\ntable = rd_get_sg_table(dev, req->rd_page);\r\nif (!table)\r\nreturn -EINVAL;\r\nrd_sg = &table->sg_table[req->rd_page - table->page_start_offset];\r\npr_debug("RD[%u]: %s LBA: %llu, Size: %u Page: %u, Offset: %u\n",\r\ndev->rd_dev_id, read_rd ? "Read" : "Write",\r\ntask->task_lba, req->rd_size, req->rd_page,\r\nrd_offset);\r\nsrc_len = PAGE_SIZE - rd_offset;\r\nsg_miter_start(&m, task->task_sg, task->task_sg_nents,\r\nread_rd ? SG_MITER_TO_SG : SG_MITER_FROM_SG);\r\nwhile (req->rd_size) {\r\nu32 len;\r\nvoid *rd_addr;\r\nsg_miter_next(&m);\r\nlen = min((u32)m.length, src_len);\r\nm.consumed = len;\r\nrd_addr = sg_virt(rd_sg) + rd_offset;\r\nif (read_rd)\r\nmemcpy(m.addr, rd_addr, len);\r\nelse\r\nmemcpy(rd_addr, m.addr, len);\r\nreq->rd_size -= len;\r\nif (!req->rd_size)\r\ncontinue;\r\nsrc_len -= len;\r\nif (src_len) {\r\nrd_offset += len;\r\ncontinue;\r\n}\r\nreq->rd_page++;\r\nrd_offset = 0;\r\nsrc_len = PAGE_SIZE;\r\nif (req->rd_page <= table->page_end_offset) {\r\nrd_sg++;\r\ncontinue;\r\n}\r\ntable = rd_get_sg_table(dev, req->rd_page);\r\nif (!table) {\r\nsg_miter_stop(&m);\r\nreturn -EINVAL;\r\n}\r\nrd_sg = table->sg_table;\r\n}\r\nsg_miter_stop(&m);\r\nreturn 0;\r\n}\r\nstatic int rd_MEMCPY_do_task(struct se_task *task)\r\n{\r\nstruct se_device *dev = task->task_se_cmd->se_dev;\r\nstruct rd_request *req = RD_REQ(task);\r\nu64 tmp;\r\nint ret;\r\ntmp = task->task_lba * dev->se_sub_dev->se_dev_attrib.block_size;\r\nreq->rd_offset = do_div(tmp, PAGE_SIZE);\r\nreq->rd_page = tmp;\r\nreq->rd_size = task->task_size;\r\nret = rd_MEMCPY(req, task->task_data_direction == DMA_FROM_DEVICE);\r\nif (ret != 0)\r\nreturn ret;\r\ntask->task_scsi_status = GOOD;\r\ntransport_complete_task(task, 1);\r\nreturn 0;\r\n}\r\nstatic void rd_free_task(struct se_task *task)\r\n{\r\nkfree(RD_REQ(task));\r\n}\r\nstatic ssize_t rd_set_configfs_dev_params(\r\nstruct se_hba *hba,\r\nstruct se_subsystem_dev *se_dev,\r\nconst char *page,\r\nssize_t count)\r\n{\r\nstruct rd_dev *rd_dev = se_dev->se_dev_su_ptr;\r\nchar *orig, *ptr, *opts;\r\nsubstring_t args[MAX_OPT_ARGS];\r\nint ret = 0, arg, token;\r\nopts = kstrdup(page, GFP_KERNEL);\r\nif (!opts)\r\nreturn -ENOMEM;\r\norig = opts;\r\nwhile ((ptr = strsep(&opts, ",\n")) != NULL) {\r\nif (!*ptr)\r\ncontinue;\r\ntoken = match_token(ptr, tokens, args);\r\nswitch (token) {\r\ncase Opt_rd_pages:\r\nmatch_int(args, &arg);\r\nrd_dev->rd_page_count = arg;\r\npr_debug("RAMDISK: Referencing Page"\r\n" Count: %u\n", rd_dev->rd_page_count);\r\nrd_dev->rd_flags |= RDF_HAS_PAGE_COUNT;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nkfree(orig);\r\nreturn (!ret) ? count : ret;\r\n}\r\nstatic ssize_t rd_check_configfs_dev_params(struct se_hba *hba, struct se_subsystem_dev *se_dev)\r\n{\r\nstruct rd_dev *rd_dev = se_dev->se_dev_su_ptr;\r\nif (!(rd_dev->rd_flags & RDF_HAS_PAGE_COUNT)) {\r\npr_debug("Missing rd_pages= parameter\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic ssize_t rd_show_configfs_dev_params(\r\nstruct se_hba *hba,\r\nstruct se_subsystem_dev *se_dev,\r\nchar *b)\r\n{\r\nstruct rd_dev *rd_dev = se_dev->se_dev_su_ptr;\r\nssize_t bl = sprintf(b, "TCM RamDisk ID: %u RamDisk Makeup: %s\n",\r\nrd_dev->rd_dev_id, (rd_dev->rd_direct) ?\r\n"rd_direct" : "rd_mcp");\r\nbl += sprintf(b + bl, " PAGES/PAGE_SIZE: %u*%lu"\r\n" SG_table_count: %u\n", rd_dev->rd_page_count,\r\nPAGE_SIZE, rd_dev->sg_table_count);\r\nreturn bl;\r\n}\r\nstatic u32 rd_get_device_rev(struct se_device *dev)\r\n{\r\nreturn SCSI_SPC_2;\r\n}\r\nstatic u32 rd_get_device_type(struct se_device *dev)\r\n{\r\nreturn TYPE_DISK;\r\n}\r\nstatic sector_t rd_get_blocks(struct se_device *dev)\r\n{\r\nstruct rd_dev *rd_dev = dev->dev_ptr;\r\nunsigned long long blocks_long = ((rd_dev->rd_page_count * PAGE_SIZE) /\r\ndev->se_sub_dev->se_dev_attrib.block_size) - 1;\r\nreturn blocks_long;\r\n}\r\nint __init rd_module_init(void)\r\n{\r\nint ret;\r\nret = transport_subsystem_register(&rd_mcp_template);\r\nif (ret < 0) {\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nvoid rd_module_exit(void)\r\n{\r\ntransport_subsystem_release(&rd_mcp_template);\r\n}
