const struct isp_format_info *\r\nomap3isp_video_format_info(enum v4l2_mbus_pixelcode code)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(formats); ++i) {\r\nif (formats[i].code == code)\r\nreturn &formats[i];\r\n}\r\nreturn NULL;\r\n}\r\nstatic bool isp_video_is_shiftable(enum v4l2_mbus_pixelcode in,\r\nenum v4l2_mbus_pixelcode out,\r\nunsigned int additional_shift)\r\n{\r\nconst struct isp_format_info *in_info, *out_info;\r\nif (in == out)\r\nreturn true;\r\nin_info = omap3isp_video_format_info(in);\r\nout_info = omap3isp_video_format_info(out);\r\nif ((in_info->flavor == 0) || (out_info->flavor == 0))\r\nreturn false;\r\nif (in_info->flavor != out_info->flavor)\r\nreturn false;\r\nreturn in_info->bpp - out_info->bpp + additional_shift <= 6;\r\n}\r\nstatic unsigned int isp_video_mbus_to_pix(const struct isp_video *video,\r\nconst struct v4l2_mbus_framefmt *mbus,\r\nstruct v4l2_pix_format *pix)\r\n{\r\nunsigned int bpl = pix->bytesperline;\r\nunsigned int min_bpl;\r\nunsigned int i;\r\nmemset(pix, 0, sizeof(*pix));\r\npix->width = mbus->width;\r\npix->height = mbus->height;\r\nfor (i = 0; i < ARRAY_SIZE(formats); ++i) {\r\nif (formats[i].code == mbus->code)\r\nbreak;\r\n}\r\nif (WARN_ON(i == ARRAY_SIZE(formats)))\r\nreturn 0;\r\nmin_bpl = pix->width * ALIGN(formats[i].bpp, 8) / 8;\r\nif (video->bpl_max)\r\nbpl = clamp(bpl, min_bpl, video->bpl_max);\r\nelse\r\nbpl = min_bpl;\r\nif (!video->bpl_zero_padding || bpl != min_bpl)\r\nbpl = ALIGN(bpl, video->bpl_alignment);\r\npix->pixelformat = formats[i].pixelformat;\r\npix->bytesperline = bpl;\r\npix->sizeimage = pix->bytesperline * pix->height;\r\npix->colorspace = mbus->colorspace;\r\npix->field = mbus->field;\r\nreturn bpl - min_bpl;\r\n}\r\nstatic void isp_video_pix_to_mbus(const struct v4l2_pix_format *pix,\r\nstruct v4l2_mbus_framefmt *mbus)\r\n{\r\nunsigned int i;\r\nmemset(mbus, 0, sizeof(*mbus));\r\nmbus->width = pix->width;\r\nmbus->height = pix->height;\r\nfor (i = 0; i < ARRAY_SIZE(formats) - 1; ++i) {\r\nif (formats[i].pixelformat == pix->pixelformat)\r\nbreak;\r\n}\r\nmbus->code = formats[i].code;\r\nmbus->colorspace = pix->colorspace;\r\nmbus->field = pix->field;\r\n}\r\nstatic struct v4l2_subdev *\r\nisp_video_remote_subdev(struct isp_video *video, u32 *pad)\r\n{\r\nstruct media_pad *remote;\r\nremote = media_entity_remote_source(&video->pad);\r\nif (remote == NULL ||\r\nmedia_entity_type(remote->entity) != MEDIA_ENT_T_V4L2_SUBDEV)\r\nreturn NULL;\r\nif (pad)\r\n*pad = remote->index;\r\nreturn media_entity_to_v4l2_subdev(remote->entity);\r\n}\r\nstatic struct isp_video *\r\nisp_video_far_end(struct isp_video *video)\r\n{\r\nstruct media_entity_graph graph;\r\nstruct media_entity *entity = &video->video.entity;\r\nstruct media_device *mdev = entity->parent;\r\nstruct isp_video *far_end = NULL;\r\nmutex_lock(&mdev->graph_mutex);\r\nmedia_entity_graph_walk_start(&graph, entity);\r\nwhile ((entity = media_entity_graph_walk_next(&graph))) {\r\nif (entity == &video->video.entity)\r\ncontinue;\r\nif (media_entity_type(entity) != MEDIA_ENT_T_DEVNODE)\r\ncontinue;\r\nfar_end = to_isp_video(media_entity_to_video_device(entity));\r\nif (far_end->type != video->type)\r\nbreak;\r\nfar_end = NULL;\r\n}\r\nmutex_unlock(&mdev->graph_mutex);\r\nreturn far_end;\r\n}\r\nstatic int isp_video_validate_pipeline(struct isp_pipeline *pipe)\r\n{\r\nstruct isp_device *isp = pipe->output->isp;\r\nstruct v4l2_subdev_format fmt_source;\r\nstruct v4l2_subdev_format fmt_sink;\r\nstruct media_pad *pad;\r\nstruct v4l2_subdev *subdev;\r\nint ret;\r\npipe->max_rate = pipe->l3_ick;\r\nsubdev = isp_video_remote_subdev(pipe->output, NULL);\r\nif (subdev == NULL)\r\nreturn -EPIPE;\r\nwhile (1) {\r\nunsigned int shifter_link;\r\npad = &subdev->entity.pads[0];\r\nif (!(pad->flags & MEDIA_PAD_FL_SINK))\r\nbreak;\r\nfmt_sink.pad = pad->index;\r\nfmt_sink.which = V4L2_SUBDEV_FORMAT_ACTIVE;\r\nret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt_sink);\r\nif (ret < 0 && ret != -ENOIOCTLCMD)\r\nreturn -EPIPE;\r\nif (subdev == &isp->isp_res.subdev)\r\nomap3isp_resizer_max_rate(&isp->isp_res,\r\n&pipe->max_rate);\r\nif (subdev == &isp->isp_ccdc.subdev && pipe->input == NULL) {\r\nunsigned int rate = UINT_MAX;\r\nomap3isp_ccdc_max_rate(&isp->isp_ccdc, &rate);\r\nif (isp->isp_ccdc.vpcfg.pixelclk > rate)\r\nreturn -ENOSPC;\r\n}\r\nshifter_link = subdev == &isp->isp_ccdc.subdev;\r\npad = media_entity_remote_source(pad);\r\nif (pad == NULL)\r\nreturn -EPIPE;\r\nif (media_entity_type(pad->entity) != MEDIA_ENT_T_V4L2_SUBDEV)\r\nbreak;\r\nsubdev = media_entity_to_v4l2_subdev(pad->entity);\r\nfmt_source.pad = pad->index;\r\nfmt_source.which = V4L2_SUBDEV_FORMAT_ACTIVE;\r\nret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt_source);\r\nif (ret < 0 && ret != -ENOIOCTLCMD)\r\nreturn -EPIPE;\r\nif (fmt_source.format.width != fmt_sink.format.width ||\r\nfmt_source.format.height != fmt_sink.format.height)\r\nreturn -EPIPE;\r\nif (shifter_link) {\r\nunsigned int parallel_shift = 0;\r\nif (isp->isp_ccdc.input == CCDC_INPUT_PARALLEL) {\r\nstruct isp_parallel_platform_data *pdata =\r\n&((struct isp_v4l2_subdevs_group *)\r\nsubdev->host_priv)->bus.parallel;\r\nparallel_shift = pdata->data_lane_shift * 2;\r\n}\r\nif (!isp_video_is_shiftable(fmt_source.format.code,\r\nfmt_sink.format.code,\r\nparallel_shift))\r\nreturn -EPIPE;\r\n} else if (fmt_source.format.code != fmt_sink.format.code)\r\nreturn -EPIPE;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\n__isp_video_get_format(struct isp_video *video, struct v4l2_format *format)\r\n{\r\nstruct v4l2_subdev_format fmt;\r\nstruct v4l2_subdev *subdev;\r\nu32 pad;\r\nint ret;\r\nsubdev = isp_video_remote_subdev(video, &pad);\r\nif (subdev == NULL)\r\nreturn -EINVAL;\r\nmutex_lock(&video->mutex);\r\nfmt.pad = pad;\r\nfmt.which = V4L2_SUBDEV_FORMAT_ACTIVE;\r\nret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt);\r\nif (ret == -ENOIOCTLCMD)\r\nret = -EINVAL;\r\nmutex_unlock(&video->mutex);\r\nif (ret)\r\nreturn ret;\r\nformat->type = video->type;\r\nreturn isp_video_mbus_to_pix(video, &fmt.format, &format->fmt.pix);\r\n}\r\nstatic int\r\nisp_video_check_format(struct isp_video *video, struct isp_video_fh *vfh)\r\n{\r\nstruct v4l2_format format;\r\nint ret;\r\nmemcpy(&format, &vfh->format, sizeof(format));\r\nret = __isp_video_get_format(video, &format);\r\nif (ret < 0)\r\nreturn ret;\r\nif (vfh->format.fmt.pix.pixelformat != format.fmt.pix.pixelformat ||\r\nvfh->format.fmt.pix.height != format.fmt.pix.height ||\r\nvfh->format.fmt.pix.width != format.fmt.pix.width ||\r\nvfh->format.fmt.pix.bytesperline != format.fmt.pix.bytesperline ||\r\nvfh->format.fmt.pix.sizeimage != format.fmt.pix.sizeimage)\r\nreturn -EINVAL;\r\nreturn ret;\r\n}\r\nstatic dma_addr_t\r\nispmmu_vmap(struct isp_device *isp, const struct scatterlist *sglist, int sglen)\r\n{\r\nstruct sg_table *sgt;\r\nu32 da;\r\nsgt = kmalloc(sizeof(*sgt), GFP_KERNEL);\r\nif (sgt == NULL)\r\nreturn -ENOMEM;\r\nsgt->sgl = (struct scatterlist *)sglist;\r\nsgt->nents = sglen;\r\nsgt->orig_nents = sglen;\r\nda = omap_iommu_vmap(isp->domain, isp->dev, 0, sgt, IOMMU_FLAG);\r\nif (IS_ERR_VALUE(da))\r\nkfree(sgt);\r\nreturn da;\r\n}\r\nstatic void ispmmu_vunmap(struct isp_device *isp, dma_addr_t da)\r\n{\r\nstruct sg_table *sgt;\r\nsgt = omap_iommu_vunmap(isp->domain, isp->dev, (u32)da);\r\nkfree(sgt);\r\n}\r\nstatic void isp_video_queue_prepare(struct isp_video_queue *queue,\r\nunsigned int *nbuffers, unsigned int *size)\r\n{\r\nstruct isp_video_fh *vfh =\r\ncontainer_of(queue, struct isp_video_fh, queue);\r\nstruct isp_video *video = vfh->video;\r\n*size = vfh->format.fmt.pix.sizeimage;\r\nif (*size == 0)\r\nreturn;\r\n*nbuffers = min(*nbuffers, video->capture_mem / PAGE_ALIGN(*size));\r\n}\r\nstatic void isp_video_buffer_cleanup(struct isp_video_buffer *buf)\r\n{\r\nstruct isp_video_fh *vfh = isp_video_queue_to_isp_video_fh(buf->queue);\r\nstruct isp_buffer *buffer = to_isp_buffer(buf);\r\nstruct isp_video *video = vfh->video;\r\nif (buffer->isp_addr) {\r\nispmmu_vunmap(video->isp, buffer->isp_addr);\r\nbuffer->isp_addr = 0;\r\n}\r\n}\r\nstatic int isp_video_buffer_prepare(struct isp_video_buffer *buf)\r\n{\r\nstruct isp_video_fh *vfh = isp_video_queue_to_isp_video_fh(buf->queue);\r\nstruct isp_buffer *buffer = to_isp_buffer(buf);\r\nstruct isp_video *video = vfh->video;\r\nunsigned long addr;\r\naddr = ispmmu_vmap(video->isp, buf->sglist, buf->sglen);\r\nif (IS_ERR_VALUE(addr))\r\nreturn -EIO;\r\nif (!IS_ALIGNED(addr, 32)) {\r\ndev_dbg(video->isp->dev, "Buffer address must be "\r\n"aligned to 32 bytes boundary.\n");\r\nispmmu_vunmap(video->isp, buffer->isp_addr);\r\nreturn -EINVAL;\r\n}\r\nbuf->vbuf.bytesused = vfh->format.fmt.pix.sizeimage;\r\nbuffer->isp_addr = addr;\r\nreturn 0;\r\n}\r\nstatic void isp_video_buffer_queue(struct isp_video_buffer *buf)\r\n{\r\nstruct isp_video_fh *vfh = isp_video_queue_to_isp_video_fh(buf->queue);\r\nstruct isp_buffer *buffer = to_isp_buffer(buf);\r\nstruct isp_video *video = vfh->video;\r\nstruct isp_pipeline *pipe = to_isp_pipeline(&video->video.entity);\r\nenum isp_pipeline_state state;\r\nunsigned long flags;\r\nunsigned int empty;\r\nunsigned int start;\r\nempty = list_empty(&video->dmaqueue);\r\nlist_add_tail(&buffer->buffer.irqlist, &video->dmaqueue);\r\nif (empty) {\r\nif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nstate = ISP_PIPELINE_QUEUE_OUTPUT;\r\nelse\r\nstate = ISP_PIPELINE_QUEUE_INPUT;\r\nspin_lock_irqsave(&pipe->lock, flags);\r\npipe->state |= state;\r\nvideo->ops->queue(video, buffer);\r\nvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_QUEUED;\r\nstart = isp_pipeline_ready(pipe);\r\nif (start)\r\npipe->state |= ISP_PIPELINE_STREAM;\r\nspin_unlock_irqrestore(&pipe->lock, flags);\r\nif (start)\r\nomap3isp_pipeline_set_stream(pipe,\r\nISP_PIPELINE_STREAM_SINGLESHOT);\r\n}\r\n}\r\nstruct isp_buffer *omap3isp_video_buffer_next(struct isp_video *video)\r\n{\r\nstruct isp_pipeline *pipe = to_isp_pipeline(&video->video.entity);\r\nstruct isp_video_queue *queue = video->queue;\r\nenum isp_pipeline_state state;\r\nstruct isp_video_buffer *buf;\r\nunsigned long flags;\r\nstruct timespec ts;\r\nspin_lock_irqsave(&queue->irqlock, flags);\r\nif (WARN_ON(list_empty(&video->dmaqueue))) {\r\nspin_unlock_irqrestore(&queue->irqlock, flags);\r\nreturn NULL;\r\n}\r\nbuf = list_first_entry(&video->dmaqueue, struct isp_video_buffer,\r\nirqlist);\r\nlist_del(&buf->irqlist);\r\nspin_unlock_irqrestore(&queue->irqlock, flags);\r\nktime_get_ts(&ts);\r\nbuf->vbuf.timestamp.tv_sec = ts.tv_sec;\r\nbuf->vbuf.timestamp.tv_usec = ts.tv_nsec / NSEC_PER_USEC;\r\nif (video == pipe->output && !pipe->do_propagation)\r\nbuf->vbuf.sequence = atomic_inc_return(&pipe->frame_number);\r\nelse\r\nbuf->vbuf.sequence = atomic_read(&pipe->frame_number);\r\nif (queue->type == V4L2_BUF_TYPE_VIDEO_CAPTURE && pipe->error) {\r\nbuf->state = ISP_BUF_STATE_ERROR;\r\npipe->error = false;\r\n} else {\r\nbuf->state = ISP_BUF_STATE_DONE;\r\n}\r\nwake_up(&buf->wait);\r\nif (list_empty(&video->dmaqueue)) {\r\nif (queue->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nstate = ISP_PIPELINE_QUEUE_OUTPUT\r\n| ISP_PIPELINE_STREAM;\r\nelse\r\nstate = ISP_PIPELINE_QUEUE_INPUT\r\n| ISP_PIPELINE_STREAM;\r\nspin_lock_irqsave(&pipe->lock, flags);\r\npipe->state &= ~state;\r\nif (video->pipe.stream_state == ISP_PIPELINE_STREAM_CONTINUOUS)\r\nvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_UNDERRUN;\r\nspin_unlock_irqrestore(&pipe->lock, flags);\r\nreturn NULL;\r\n}\r\nif (queue->type == V4L2_BUF_TYPE_VIDEO_CAPTURE && pipe->input != NULL) {\r\nspin_lock_irqsave(&pipe->lock, flags);\r\npipe->state &= ~ISP_PIPELINE_STREAM;\r\nspin_unlock_irqrestore(&pipe->lock, flags);\r\n}\r\nbuf = list_first_entry(&video->dmaqueue, struct isp_video_buffer,\r\nirqlist);\r\nbuf->state = ISP_BUF_STATE_ACTIVE;\r\nreturn to_isp_buffer(buf);\r\n}\r\nvoid omap3isp_video_resume(struct isp_video *video, int continuous)\r\n{\r\nstruct isp_buffer *buf = NULL;\r\nif (continuous && video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nomap3isp_video_queue_discard_done(video->queue);\r\nif (!list_empty(&video->dmaqueue)) {\r\nbuf = list_first_entry(&video->dmaqueue,\r\nstruct isp_buffer, buffer.irqlist);\r\nvideo->ops->queue(video, buf);\r\nvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_QUEUED;\r\n} else {\r\nif (continuous)\r\nvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_UNDERRUN;\r\n}\r\n}\r\nstatic int\r\nisp_video_querycap(struct file *file, void *fh, struct v4l2_capability *cap)\r\n{\r\nstruct isp_video *video = video_drvdata(file);\r\nstrlcpy(cap->driver, ISP_VIDEO_DRIVER_NAME, sizeof(cap->driver));\r\nstrlcpy(cap->card, video->video.name, sizeof(cap->card));\r\nstrlcpy(cap->bus_info, "media", sizeof(cap->bus_info));\r\nif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\ncap->capabilities = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_STREAMING;\r\nelse\r\ncap->capabilities = V4L2_CAP_VIDEO_OUTPUT | V4L2_CAP_STREAMING;\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_get_format(struct file *file, void *fh, struct v4l2_format *format)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nstruct isp_video *video = video_drvdata(file);\r\nif (format->type != video->type)\r\nreturn -EINVAL;\r\nmutex_lock(&video->mutex);\r\n*format = vfh->format;\r\nmutex_unlock(&video->mutex);\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_set_format(struct file *file, void *fh, struct v4l2_format *format)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct v4l2_mbus_framefmt fmt;\r\nif (format->type != video->type)\r\nreturn -EINVAL;\r\nmutex_lock(&video->mutex);\r\nisp_video_pix_to_mbus(&format->fmt.pix, &fmt);\r\nisp_video_mbus_to_pix(video, &fmt, &format->fmt.pix);\r\nvfh->format = *format;\r\nmutex_unlock(&video->mutex);\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_try_format(struct file *file, void *fh, struct v4l2_format *format)\r\n{\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct v4l2_subdev_format fmt;\r\nstruct v4l2_subdev *subdev;\r\nu32 pad;\r\nint ret;\r\nif (format->type != video->type)\r\nreturn -EINVAL;\r\nsubdev = isp_video_remote_subdev(video, &pad);\r\nif (subdev == NULL)\r\nreturn -EINVAL;\r\nisp_video_pix_to_mbus(&format->fmt.pix, &fmt.format);\r\nfmt.pad = pad;\r\nfmt.which = V4L2_SUBDEV_FORMAT_ACTIVE;\r\nret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt);\r\nif (ret)\r\nreturn ret == -ENOIOCTLCMD ? -EINVAL : ret;\r\nisp_video_mbus_to_pix(video, &fmt.format, &format->fmt.pix);\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_cropcap(struct file *file, void *fh, struct v4l2_cropcap *cropcap)\r\n{\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct v4l2_subdev *subdev;\r\nint ret;\r\nsubdev = isp_video_remote_subdev(video, NULL);\r\nif (subdev == NULL)\r\nreturn -EINVAL;\r\nmutex_lock(&video->mutex);\r\nret = v4l2_subdev_call(subdev, video, cropcap, cropcap);\r\nmutex_unlock(&video->mutex);\r\nreturn ret == -ENOIOCTLCMD ? -EINVAL : ret;\r\n}\r\nstatic int\r\nisp_video_get_crop(struct file *file, void *fh, struct v4l2_crop *crop)\r\n{\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct v4l2_subdev_format format;\r\nstruct v4l2_subdev *subdev;\r\nu32 pad;\r\nint ret;\r\nsubdev = isp_video_remote_subdev(video, &pad);\r\nif (subdev == NULL)\r\nreturn -EINVAL;\r\nret = v4l2_subdev_call(subdev, video, g_crop, crop);\r\nif (ret != -ENOIOCTLCMD)\r\nreturn ret;\r\nformat.pad = pad;\r\nformat.which = V4L2_SUBDEV_FORMAT_ACTIVE;\r\nret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &format);\r\nif (ret < 0)\r\nreturn ret == -ENOIOCTLCMD ? -EINVAL : ret;\r\ncrop->c.left = 0;\r\ncrop->c.top = 0;\r\ncrop->c.width = format.format.width;\r\ncrop->c.height = format.format.height;\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_set_crop(struct file *file, void *fh, struct v4l2_crop *crop)\r\n{\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct v4l2_subdev *subdev;\r\nint ret;\r\nsubdev = isp_video_remote_subdev(video, NULL);\r\nif (subdev == NULL)\r\nreturn -EINVAL;\r\nmutex_lock(&video->mutex);\r\nret = v4l2_subdev_call(subdev, video, s_crop, crop);\r\nmutex_unlock(&video->mutex);\r\nreturn ret == -ENOIOCTLCMD ? -EINVAL : ret;\r\n}\r\nstatic int\r\nisp_video_get_param(struct file *file, void *fh, struct v4l2_streamparm *a)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nstruct isp_video *video = video_drvdata(file);\r\nif (video->type != V4L2_BUF_TYPE_VIDEO_OUTPUT ||\r\nvideo->type != a->type)\r\nreturn -EINVAL;\r\nmemset(a, 0, sizeof(*a));\r\na->type = V4L2_BUF_TYPE_VIDEO_OUTPUT;\r\na->parm.output.capability = V4L2_CAP_TIMEPERFRAME;\r\na->parm.output.timeperframe = vfh->timeperframe;\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_set_param(struct file *file, void *fh, struct v4l2_streamparm *a)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nstruct isp_video *video = video_drvdata(file);\r\nif (video->type != V4L2_BUF_TYPE_VIDEO_OUTPUT ||\r\nvideo->type != a->type)\r\nreturn -EINVAL;\r\nif (a->parm.output.timeperframe.denominator == 0)\r\na->parm.output.timeperframe.denominator = 1;\r\nvfh->timeperframe = a->parm.output.timeperframe;\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_reqbufs(struct file *file, void *fh, struct v4l2_requestbuffers *rb)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nreturn omap3isp_video_queue_reqbufs(&vfh->queue, rb);\r\n}\r\nstatic int\r\nisp_video_querybuf(struct file *file, void *fh, struct v4l2_buffer *b)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nreturn omap3isp_video_queue_querybuf(&vfh->queue, b);\r\n}\r\nstatic int\r\nisp_video_qbuf(struct file *file, void *fh, struct v4l2_buffer *b)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nreturn omap3isp_video_queue_qbuf(&vfh->queue, b);\r\n}\r\nstatic int\r\nisp_video_dqbuf(struct file *file, void *fh, struct v4l2_buffer *b)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nreturn omap3isp_video_queue_dqbuf(&vfh->queue, b,\r\nfile->f_flags & O_NONBLOCK);\r\n}\r\nstatic int\r\nisp_video_streamon(struct file *file, void *fh, enum v4l2_buf_type type)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nstruct isp_video *video = video_drvdata(file);\r\nenum isp_pipeline_state state;\r\nstruct isp_pipeline *pipe;\r\nstruct isp_video *far_end;\r\nunsigned long flags;\r\nint ret;\r\nif (type != video->type)\r\nreturn -EINVAL;\r\nmutex_lock(&video->stream_lock);\r\nif (video->streaming) {\r\nmutex_unlock(&video->stream_lock);\r\nreturn -EBUSY;\r\n}\r\npipe = video->video.entity.pipe\r\n? to_isp_pipeline(&video->video.entity) : &video->pipe;\r\nmedia_entity_pipeline_start(&video->video.entity, &pipe->pipe);\r\nret = isp_video_check_format(video, vfh);\r\nif (ret < 0)\r\ngoto error;\r\nvideo->bpl_padding = ret;\r\nvideo->bpl_value = vfh->format.fmt.pix.bytesperline;\r\nfar_end = isp_video_far_end(video);\r\nif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE) {\r\nstate = ISP_PIPELINE_STREAM_OUTPUT | ISP_PIPELINE_IDLE_OUTPUT;\r\npipe->input = far_end;\r\npipe->output = video;\r\n} else {\r\nif (far_end == NULL) {\r\nret = -EPIPE;\r\ngoto error;\r\n}\r\nstate = ISP_PIPELINE_STREAM_INPUT | ISP_PIPELINE_IDLE_INPUT;\r\npipe->input = video;\r\npipe->output = far_end;\r\n}\r\nif (video->isp->pdata->set_constraints)\r\nvideo->isp->pdata->set_constraints(video->isp, true);\r\npipe->l3_ick = clk_get_rate(video->isp->clock[ISP_CLK_L3_ICK]);\r\nret = isp_video_validate_pipeline(pipe);\r\nif (ret < 0)\r\ngoto error;\r\npipe->error = false;\r\nspin_lock_irqsave(&pipe->lock, flags);\r\npipe->state &= ~ISP_PIPELINE_STREAM;\r\npipe->state |= state;\r\nspin_unlock_irqrestore(&pipe->lock, flags);\r\nif (video->type == V4L2_BUF_TYPE_VIDEO_OUTPUT)\r\npipe->max_timeperframe = vfh->timeperframe;\r\nvideo->queue = &vfh->queue;\r\nINIT_LIST_HEAD(&video->dmaqueue);\r\natomic_set(&pipe->frame_number, -1);\r\nret = omap3isp_video_queue_streamon(&vfh->queue);\r\nif (ret < 0)\r\ngoto error;\r\nif (pipe->input == NULL) {\r\nret = omap3isp_pipeline_set_stream(pipe,\r\nISP_PIPELINE_STREAM_CONTINUOUS);\r\nif (ret < 0)\r\ngoto error;\r\nspin_lock_irqsave(&video->queue->irqlock, flags);\r\nif (list_empty(&video->dmaqueue))\r\nvideo->dmaqueue_flags |= ISP_VIDEO_DMAQUEUE_UNDERRUN;\r\nspin_unlock_irqrestore(&video->queue->irqlock, flags);\r\n}\r\nerror:\r\nif (ret < 0) {\r\nomap3isp_video_queue_streamoff(&vfh->queue);\r\nif (video->isp->pdata->set_constraints)\r\nvideo->isp->pdata->set_constraints(video->isp, false);\r\nmedia_entity_pipeline_stop(&video->video.entity);\r\nINIT_LIST_HEAD(&video->dmaqueue);\r\nvideo->queue = NULL;\r\n}\r\nif (!ret)\r\nvideo->streaming = 1;\r\nmutex_unlock(&video->stream_lock);\r\nreturn ret;\r\n}\r\nstatic int\r\nisp_video_streamoff(struct file *file, void *fh, enum v4l2_buf_type type)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(fh);\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct isp_pipeline *pipe = to_isp_pipeline(&video->video.entity);\r\nenum isp_pipeline_state state;\r\nunsigned int streaming;\r\nunsigned long flags;\r\nif (type != video->type)\r\nreturn -EINVAL;\r\nmutex_lock(&video->stream_lock);\r\nmutex_lock(&vfh->queue.lock);\r\nstreaming = vfh->queue.streaming;\r\nmutex_unlock(&vfh->queue.lock);\r\nif (!streaming)\r\ngoto done;\r\nif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nstate = ISP_PIPELINE_STREAM_OUTPUT\r\n| ISP_PIPELINE_QUEUE_OUTPUT;\r\nelse\r\nstate = ISP_PIPELINE_STREAM_INPUT\r\n| ISP_PIPELINE_QUEUE_INPUT;\r\nspin_lock_irqsave(&pipe->lock, flags);\r\npipe->state &= ~state;\r\nspin_unlock_irqrestore(&pipe->lock, flags);\r\nomap3isp_pipeline_set_stream(pipe, ISP_PIPELINE_STREAM_STOPPED);\r\nomap3isp_video_queue_streamoff(&vfh->queue);\r\nvideo->queue = NULL;\r\nvideo->streaming = 0;\r\nif (video->isp->pdata->set_constraints)\r\nvideo->isp->pdata->set_constraints(video->isp, false);\r\nmedia_entity_pipeline_stop(&video->video.entity);\r\ndone:\r\nmutex_unlock(&video->stream_lock);\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_enum_input(struct file *file, void *fh, struct v4l2_input *input)\r\n{\r\nif (input->index > 0)\r\nreturn -EINVAL;\r\nstrlcpy(input->name, "camera", sizeof(input->name));\r\ninput->type = V4L2_INPUT_TYPE_CAMERA;\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_g_input(struct file *file, void *fh, unsigned int *input)\r\n{\r\n*input = 0;\r\nreturn 0;\r\n}\r\nstatic int\r\nisp_video_s_input(struct file *file, void *fh, unsigned int input)\r\n{\r\nreturn input == 0 ? 0 : -EINVAL;\r\n}\r\nstatic int isp_video_open(struct file *file)\r\n{\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct isp_video_fh *handle;\r\nint ret = 0;\r\nhandle = kzalloc(sizeof(*handle), GFP_KERNEL);\r\nif (handle == NULL)\r\nreturn -ENOMEM;\r\nv4l2_fh_init(&handle->vfh, &video->video);\r\nv4l2_fh_add(&handle->vfh);\r\nif (omap3isp_get(video->isp) == NULL) {\r\nret = -EBUSY;\r\ngoto done;\r\n}\r\nret = omap3isp_pipeline_pm_use(&video->video.entity, 1);\r\nif (ret < 0) {\r\nomap3isp_put(video->isp);\r\ngoto done;\r\n}\r\nomap3isp_video_queue_init(&handle->queue, video->type,\r\n&isp_video_queue_ops, video->isp->dev,\r\nsizeof(struct isp_buffer));\r\nmemset(&handle->format, 0, sizeof(handle->format));\r\nhandle->format.type = video->type;\r\nhandle->timeperframe.denominator = 1;\r\nhandle->video = video;\r\nfile->private_data = &handle->vfh;\r\ndone:\r\nif (ret < 0) {\r\nv4l2_fh_del(&handle->vfh);\r\nkfree(handle);\r\n}\r\nreturn ret;\r\n}\r\nstatic int isp_video_release(struct file *file)\r\n{\r\nstruct isp_video *video = video_drvdata(file);\r\nstruct v4l2_fh *vfh = file->private_data;\r\nstruct isp_video_fh *handle = to_isp_video_fh(vfh);\r\nisp_video_streamoff(file, vfh, video->type);\r\nmutex_lock(&handle->queue.lock);\r\nomap3isp_video_queue_cleanup(&handle->queue);\r\nmutex_unlock(&handle->queue.lock);\r\nomap3isp_pipeline_pm_use(&video->video.entity, 0);\r\nv4l2_fh_del(vfh);\r\nkfree(handle);\r\nfile->private_data = NULL;\r\nomap3isp_put(video->isp);\r\nreturn 0;\r\n}\r\nstatic unsigned int isp_video_poll(struct file *file, poll_table *wait)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(file->private_data);\r\nstruct isp_video_queue *queue = &vfh->queue;\r\nreturn omap3isp_video_queue_poll(queue, file, wait);\r\n}\r\nstatic int isp_video_mmap(struct file *file, struct vm_area_struct *vma)\r\n{\r\nstruct isp_video_fh *vfh = to_isp_video_fh(file->private_data);\r\nreturn omap3isp_video_queue_mmap(&vfh->queue, vma);\r\n}\r\nint omap3isp_video_init(struct isp_video *video, const char *name)\r\n{\r\nconst char *direction;\r\nint ret;\r\nswitch (video->type) {\r\ncase V4L2_BUF_TYPE_VIDEO_CAPTURE:\r\ndirection = "output";\r\nvideo->pad.flags = MEDIA_PAD_FL_SINK;\r\nbreak;\r\ncase V4L2_BUF_TYPE_VIDEO_OUTPUT:\r\ndirection = "input";\r\nvideo->pad.flags = MEDIA_PAD_FL_SOURCE;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nret = media_entity_init(&video->video.entity, 1, &video->pad, 0);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_init(&video->mutex);\r\natomic_set(&video->active, 0);\r\nspin_lock_init(&video->pipe.lock);\r\nmutex_init(&video->stream_lock);\r\nif (video->ops == NULL)\r\nvideo->ops = &isp_video_dummy_ops;\r\nvideo->video.fops = &isp_video_fops;\r\nsnprintf(video->video.name, sizeof(video->video.name),\r\n"OMAP3 ISP %s %s", name, direction);\r\nvideo->video.vfl_type = VFL_TYPE_GRABBER;\r\nvideo->video.release = video_device_release_empty;\r\nvideo->video.ioctl_ops = &isp_video_ioctl_ops;\r\nvideo->pipe.stream_state = ISP_PIPELINE_STREAM_STOPPED;\r\nvideo_set_drvdata(&video->video, video);\r\nreturn 0;\r\n}\r\nvoid omap3isp_video_cleanup(struct isp_video *video)\r\n{\r\nmedia_entity_cleanup(&video->video.entity);\r\nmutex_destroy(&video->stream_lock);\r\nmutex_destroy(&video->mutex);\r\n}\r\nint omap3isp_video_register(struct isp_video *video, struct v4l2_device *vdev)\r\n{\r\nint ret;\r\nvideo->video.v4l2_dev = vdev;\r\nret = video_register_device(&video->video, VFL_TYPE_GRABBER, -1);\r\nif (ret < 0)\r\nprintk(KERN_ERR "%s: could not register video device (%d)\n",\r\n__func__, ret);\r\nreturn ret;\r\n}\r\nvoid omap3isp_video_unregister(struct isp_video *video)\r\n{\r\nif (video_is_registered(&video->video))\r\nvideo_unregister_device(&video->video);\r\n}
