static inline u8 LIH_INDEX(const u8 ctr)\r\n{\r\nreturn LIH_SIZE - 1 - (ctr % LIH_SIZE);\r\n}\r\nstatic inline struct tfrc_loss_interval *tfrc_lh_peek(struct tfrc_loss_hist *lh)\r\n{\r\nreturn lh->counter ? lh->ring[LIH_INDEX(lh->counter - 1)] : NULL;\r\n}\r\nstatic inline u32 tfrc_lh_get_interval(struct tfrc_loss_hist *lh, const u8 i)\r\n{\r\nBUG_ON(i >= lh->counter);\r\nreturn lh->ring[LIH_INDEX(lh->counter - i - 1)]->li_length;\r\n}\r\nstatic struct tfrc_loss_interval *tfrc_lh_demand_next(struct tfrc_loss_hist *lh)\r\n{\r\nif (lh->ring[LIH_INDEX(lh->counter)] == NULL)\r\nlh->ring[LIH_INDEX(lh->counter)] = kmem_cache_alloc(tfrc_lh_slab,\r\nGFP_ATOMIC);\r\nreturn lh->ring[LIH_INDEX(lh->counter)];\r\n}\r\nvoid tfrc_lh_cleanup(struct tfrc_loss_hist *lh)\r\n{\r\nif (!tfrc_lh_is_initialised(lh))\r\nreturn;\r\nfor (lh->counter = 0; lh->counter < LIH_SIZE; lh->counter++)\r\nif (lh->ring[LIH_INDEX(lh->counter)] != NULL) {\r\nkmem_cache_free(tfrc_lh_slab,\r\nlh->ring[LIH_INDEX(lh->counter)]);\r\nlh->ring[LIH_INDEX(lh->counter)] = NULL;\r\n}\r\n}\r\nstatic void tfrc_lh_calc_i_mean(struct tfrc_loss_hist *lh)\r\n{\r\nu32 i_i, i_tot0 = 0, i_tot1 = 0, w_tot = 0;\r\nint i, k = tfrc_lh_length(lh) - 1;\r\nif (k <= 0)\r\nreturn;\r\nfor (i = 0; i <= k; i++) {\r\ni_i = tfrc_lh_get_interval(lh, i);\r\nif (i < k) {\r\ni_tot0 += i_i * tfrc_lh_weights[i];\r\nw_tot += tfrc_lh_weights[i];\r\n}\r\nif (i > 0)\r\ni_tot1 += i_i * tfrc_lh_weights[i-1];\r\n}\r\nlh->i_mean = max(i_tot0, i_tot1) / w_tot;\r\n}\r\nu8 tfrc_lh_update_i_mean(struct tfrc_loss_hist *lh, struct sk_buff *skb)\r\n{\r\nstruct tfrc_loss_interval *cur = tfrc_lh_peek(lh);\r\nu32 old_i_mean = lh->i_mean;\r\ns64 len;\r\nif (cur == NULL)\r\nreturn 0;\r\nlen = dccp_delta_seqno(cur->li_seqno, DCCP_SKB_CB(skb)->dccpd_seq) + 1;\r\nif (len - (s64)cur->li_length <= 0)\r\nreturn 0;\r\nif (SUB16(dccp_hdr(skb)->dccph_ccval, cur->li_ccval) > 4)\r\ncur->li_is_closed = 1;\r\nif (tfrc_lh_length(lh) == 1)\r\nreturn 0;\r\ncur->li_length = len;\r\ntfrc_lh_calc_i_mean(lh);\r\nreturn lh->i_mean < old_i_mean;\r\n}\r\nstatic inline u8 tfrc_lh_is_new_loss(struct tfrc_loss_interval *cur,\r\nstruct tfrc_rx_hist_entry *new_loss)\r\n{\r\nreturn dccp_delta_seqno(cur->li_seqno, new_loss->tfrchrx_seqno) > 0 &&\r\n(cur->li_is_closed || SUB16(new_loss->tfrchrx_ccval, cur->li_ccval) > 4);\r\n}\r\nint tfrc_lh_interval_add(struct tfrc_loss_hist *lh, struct tfrc_rx_hist *rh,\r\nu32 (*calc_first_li)(struct sock *), struct sock *sk)\r\n{\r\nstruct tfrc_loss_interval *cur = tfrc_lh_peek(lh), *new;\r\nif (cur != NULL && !tfrc_lh_is_new_loss(cur, tfrc_rx_hist_loss_prev(rh)))\r\nreturn 0;\r\nnew = tfrc_lh_demand_next(lh);\r\nif (unlikely(new == NULL)) {\r\nDCCP_CRIT("Cannot allocate/add loss record.");\r\nreturn 0;\r\n}\r\nnew->li_seqno = tfrc_rx_hist_loss_prev(rh)->tfrchrx_seqno;\r\nnew->li_ccval = tfrc_rx_hist_loss_prev(rh)->tfrchrx_ccval;\r\nnew->li_is_closed = 0;\r\nif (++lh->counter == 1)\r\nlh->i_mean = new->li_length = (*calc_first_li)(sk);\r\nelse {\r\ncur->li_length = dccp_delta_seqno(cur->li_seqno, new->li_seqno);\r\nnew->li_length = dccp_delta_seqno(new->li_seqno,\r\ntfrc_rx_hist_last_rcv(rh)->tfrchrx_seqno) + 1;\r\nif (lh->counter > (2*LIH_SIZE))\r\nlh->counter -= LIH_SIZE;\r\ntfrc_lh_calc_i_mean(lh);\r\n}\r\nreturn 1;\r\n}\r\nint __init tfrc_li_init(void)\r\n{\r\ntfrc_lh_slab = kmem_cache_create("tfrc_li_hist",\r\nsizeof(struct tfrc_loss_interval), 0,\r\nSLAB_HWCACHE_ALIGN, NULL);\r\nreturn tfrc_lh_slab == NULL ? -ENOBUFS : 0;\r\n}\r\nvoid tfrc_li_exit(void)\r\n{\r\nif (tfrc_lh_slab != NULL) {\r\nkmem_cache_destroy(tfrc_lh_slab);\r\ntfrc_lh_slab = NULL;\r\n}\r\n}
