static void start_new_worker_func(struct btrfs_work *work)\r\n{\r\nstruct worker_start *start;\r\nstart = container_of(work, struct worker_start, work);\r\nbtrfs_start_workers(start->queue, 1);\r\nkfree(start);\r\n}\r\nstatic int start_new_worker(struct btrfs_workers *queue)\r\n{\r\nstruct worker_start *start;\r\nint ret;\r\nstart = kzalloc(sizeof(*start), GFP_NOFS);\r\nif (!start)\r\nreturn -ENOMEM;\r\nstart->work.func = start_new_worker_func;\r\nstart->queue = queue;\r\nret = btrfs_queue_worker(queue->atomic_worker_start, &start->work);\r\nif (ret)\r\nkfree(start);\r\nreturn ret;\r\n}\r\nstatic void check_idle_worker(struct btrfs_worker_thread *worker)\r\n{\r\nif (!worker->idle && atomic_read(&worker->num_pending) <\r\nworker->workers->idle_thresh / 2) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&worker->workers->lock, flags);\r\nworker->idle = 1;\r\nif (!list_empty(&worker->worker_list)) {\r\nlist_move(&worker->worker_list,\r\n&worker->workers->idle_list);\r\n}\r\nspin_unlock_irqrestore(&worker->workers->lock, flags);\r\n}\r\n}\r\nstatic void check_busy_worker(struct btrfs_worker_thread *worker)\r\n{\r\nif (worker->idle && atomic_read(&worker->num_pending) >=\r\nworker->workers->idle_thresh) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&worker->workers->lock, flags);\r\nworker->idle = 0;\r\nif (!list_empty(&worker->worker_list)) {\r\nlist_move_tail(&worker->worker_list,\r\n&worker->workers->worker_list);\r\n}\r\nspin_unlock_irqrestore(&worker->workers->lock, flags);\r\n}\r\n}\r\nstatic void check_pending_worker_creates(struct btrfs_worker_thread *worker)\r\n{\r\nstruct btrfs_workers *workers = worker->workers;\r\nunsigned long flags;\r\nrmb();\r\nif (!workers->atomic_start_pending)\r\nreturn;\r\nspin_lock_irqsave(&workers->lock, flags);\r\nif (!workers->atomic_start_pending)\r\ngoto out;\r\nworkers->atomic_start_pending = 0;\r\nif (workers->num_workers + workers->num_workers_starting >=\r\nworkers->max_workers)\r\ngoto out;\r\nworkers->num_workers_starting += 1;\r\nspin_unlock_irqrestore(&workers->lock, flags);\r\nstart_new_worker(workers);\r\nreturn;\r\nout:\r\nspin_unlock_irqrestore(&workers->lock, flags);\r\n}\r\nstatic noinline int run_ordered_completions(struct btrfs_workers *workers,\r\nstruct btrfs_work *work)\r\n{\r\nif (!workers->ordered)\r\nreturn 0;\r\nset_bit(WORK_DONE_BIT, &work->flags);\r\nspin_lock(&workers->order_lock);\r\nwhile (1) {\r\nif (!list_empty(&workers->prio_order_list)) {\r\nwork = list_entry(workers->prio_order_list.next,\r\nstruct btrfs_work, order_list);\r\n} else if (!list_empty(&workers->order_list)) {\r\nwork = list_entry(workers->order_list.next,\r\nstruct btrfs_work, order_list);\r\n} else {\r\nbreak;\r\n}\r\nif (!test_bit(WORK_DONE_BIT, &work->flags))\r\nbreak;\r\nif (test_and_set_bit(WORK_ORDER_DONE_BIT, &work->flags))\r\nbreak;\r\nspin_unlock(&workers->order_lock);\r\nwork->ordered_func(work);\r\nspin_lock(&workers->order_lock);\r\nlist_del(&work->order_list);\r\nwork->ordered_free(work);\r\n}\r\nspin_unlock(&workers->order_lock);\r\nreturn 0;\r\n}\r\nstatic void put_worker(struct btrfs_worker_thread *worker)\r\n{\r\nif (atomic_dec_and_test(&worker->refs))\r\nkfree(worker);\r\n}\r\nstatic int try_worker_shutdown(struct btrfs_worker_thread *worker)\r\n{\r\nint freeit = 0;\r\nspin_lock_irq(&worker->lock);\r\nspin_lock(&worker->workers->lock);\r\nif (worker->workers->num_workers > 1 &&\r\nworker->idle &&\r\n!worker->working &&\r\n!list_empty(&worker->worker_list) &&\r\nlist_empty(&worker->prio_pending) &&\r\nlist_empty(&worker->pending) &&\r\natomic_read(&worker->num_pending) == 0) {\r\nfreeit = 1;\r\nlist_del_init(&worker->worker_list);\r\nworker->workers->num_workers--;\r\n}\r\nspin_unlock(&worker->workers->lock);\r\nspin_unlock_irq(&worker->lock);\r\nif (freeit)\r\nput_worker(worker);\r\nreturn freeit;\r\n}\r\nstatic struct btrfs_work *get_next_work(struct btrfs_worker_thread *worker,\r\nstruct list_head *prio_head,\r\nstruct list_head *head)\r\n{\r\nstruct btrfs_work *work = NULL;\r\nstruct list_head *cur = NULL;\r\nif(!list_empty(prio_head))\r\ncur = prio_head->next;\r\nsmp_mb();\r\nif (!list_empty(&worker->prio_pending))\r\ngoto refill;\r\nif (!list_empty(head))\r\ncur = head->next;\r\nif (cur)\r\ngoto out;\r\nrefill:\r\nspin_lock_irq(&worker->lock);\r\nlist_splice_tail_init(&worker->prio_pending, prio_head);\r\nlist_splice_tail_init(&worker->pending, head);\r\nif (!list_empty(prio_head))\r\ncur = prio_head->next;\r\nelse if (!list_empty(head))\r\ncur = head->next;\r\nspin_unlock_irq(&worker->lock);\r\nif (!cur)\r\ngoto out_fail;\r\nout:\r\nwork = list_entry(cur, struct btrfs_work, list);\r\nout_fail:\r\nreturn work;\r\n}\r\nstatic int worker_loop(void *arg)\r\n{\r\nstruct btrfs_worker_thread *worker = arg;\r\nstruct list_head head;\r\nstruct list_head prio_head;\r\nstruct btrfs_work *work;\r\nINIT_LIST_HEAD(&head);\r\nINIT_LIST_HEAD(&prio_head);\r\ndo {\r\nagain:\r\nwhile (1) {\r\nwork = get_next_work(worker, &prio_head, &head);\r\nif (!work)\r\nbreak;\r\nlist_del(&work->list);\r\nclear_bit(WORK_QUEUED_BIT, &work->flags);\r\nwork->worker = worker;\r\nwork->func(work);\r\natomic_dec(&worker->num_pending);\r\nrun_ordered_completions(worker->workers, work);\r\ncheck_pending_worker_creates(worker);\r\n}\r\nspin_lock_irq(&worker->lock);\r\ncheck_idle_worker(worker);\r\nif (freezing(current)) {\r\nworker->working = 0;\r\nspin_unlock_irq(&worker->lock);\r\nrefrigerator();\r\n} else {\r\nspin_unlock_irq(&worker->lock);\r\nif (!kthread_should_stop()) {\r\ncpu_relax();\r\nsmp_mb();\r\nif (!list_empty(&worker->pending) ||\r\n!list_empty(&worker->prio_pending))\r\ncontinue;\r\nschedule_timeout(1);\r\nsmp_mb();\r\nif (!list_empty(&worker->pending) ||\r\n!list_empty(&worker->prio_pending))\r\ncontinue;\r\nif (kthread_should_stop())\r\nbreak;\r\nspin_lock_irq(&worker->lock);\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nif (!list_empty(&worker->pending) ||\r\n!list_empty(&worker->prio_pending)) {\r\nspin_unlock_irq(&worker->lock);\r\nset_current_state(TASK_RUNNING);\r\ngoto again;\r\n}\r\nworker->working = 0;\r\nspin_unlock_irq(&worker->lock);\r\nif (!kthread_should_stop()) {\r\nschedule_timeout(HZ * 120);\r\nif (!worker->working &&\r\ntry_worker_shutdown(worker)) {\r\nreturn 0;\r\n}\r\n}\r\n}\r\n__set_current_state(TASK_RUNNING);\r\n}\r\n} while (!kthread_should_stop());\r\nreturn 0;\r\n}\r\nint btrfs_stop_workers(struct btrfs_workers *workers)\r\n{\r\nstruct list_head *cur;\r\nstruct btrfs_worker_thread *worker;\r\nint can_stop;\r\nspin_lock_irq(&workers->lock);\r\nlist_splice_init(&workers->idle_list, &workers->worker_list);\r\nwhile (!list_empty(&workers->worker_list)) {\r\ncur = workers->worker_list.next;\r\nworker = list_entry(cur, struct btrfs_worker_thread,\r\nworker_list);\r\natomic_inc(&worker->refs);\r\nworkers->num_workers -= 1;\r\nif (!list_empty(&worker->worker_list)) {\r\nlist_del_init(&worker->worker_list);\r\nput_worker(worker);\r\ncan_stop = 1;\r\n} else\r\ncan_stop = 0;\r\nspin_unlock_irq(&workers->lock);\r\nif (can_stop)\r\nkthread_stop(worker->task);\r\nspin_lock_irq(&workers->lock);\r\nput_worker(worker);\r\n}\r\nspin_unlock_irq(&workers->lock);\r\nreturn 0;\r\n}\r\nvoid btrfs_init_workers(struct btrfs_workers *workers, char *name, int max,\r\nstruct btrfs_workers *async_helper)\r\n{\r\nworkers->num_workers = 0;\r\nworkers->num_workers_starting = 0;\r\nINIT_LIST_HEAD(&workers->worker_list);\r\nINIT_LIST_HEAD(&workers->idle_list);\r\nINIT_LIST_HEAD(&workers->order_list);\r\nINIT_LIST_HEAD(&workers->prio_order_list);\r\nspin_lock_init(&workers->lock);\r\nspin_lock_init(&workers->order_lock);\r\nworkers->max_workers = max;\r\nworkers->idle_thresh = 32;\r\nworkers->name = name;\r\nworkers->ordered = 0;\r\nworkers->atomic_start_pending = 0;\r\nworkers->atomic_worker_start = async_helper;\r\n}\r\nstatic int __btrfs_start_workers(struct btrfs_workers *workers,\r\nint num_workers)\r\n{\r\nstruct btrfs_worker_thread *worker;\r\nint ret = 0;\r\nint i;\r\nfor (i = 0; i < num_workers; i++) {\r\nworker = kzalloc(sizeof(*worker), GFP_NOFS);\r\nif (!worker) {\r\nret = -ENOMEM;\r\ngoto fail;\r\n}\r\nINIT_LIST_HEAD(&worker->pending);\r\nINIT_LIST_HEAD(&worker->prio_pending);\r\nINIT_LIST_HEAD(&worker->worker_list);\r\nspin_lock_init(&worker->lock);\r\natomic_set(&worker->num_pending, 0);\r\natomic_set(&worker->refs, 1);\r\nworker->workers = workers;\r\nworker->task = kthread_run(worker_loop, worker,\r\n"btrfs-%s-%d", workers->name,\r\nworkers->num_workers + i);\r\nif (IS_ERR(worker->task)) {\r\nret = PTR_ERR(worker->task);\r\nkfree(worker);\r\ngoto fail;\r\n}\r\nspin_lock_irq(&workers->lock);\r\nlist_add_tail(&worker->worker_list, &workers->idle_list);\r\nworker->idle = 1;\r\nworkers->num_workers++;\r\nworkers->num_workers_starting--;\r\nWARN_ON(workers->num_workers_starting < 0);\r\nspin_unlock_irq(&workers->lock);\r\n}\r\nreturn 0;\r\nfail:\r\nbtrfs_stop_workers(workers);\r\nreturn ret;\r\n}\r\nint btrfs_start_workers(struct btrfs_workers *workers, int num_workers)\r\n{\r\nspin_lock_irq(&workers->lock);\r\nworkers->num_workers_starting += num_workers;\r\nspin_unlock_irq(&workers->lock);\r\nreturn __btrfs_start_workers(workers, num_workers);\r\n}\r\nstatic struct btrfs_worker_thread *next_worker(struct btrfs_workers *workers)\r\n{\r\nstruct btrfs_worker_thread *worker;\r\nstruct list_head *next;\r\nint enforce_min;\r\nenforce_min = (workers->num_workers + workers->num_workers_starting) <\r\nworkers->max_workers;\r\nif (!list_empty(&workers->idle_list)) {\r\nnext = workers->idle_list.next;\r\nworker = list_entry(next, struct btrfs_worker_thread,\r\nworker_list);\r\nreturn worker;\r\n}\r\nif (enforce_min || list_empty(&workers->worker_list))\r\nreturn NULL;\r\nnext = workers->worker_list.next;\r\nworker = list_entry(next, struct btrfs_worker_thread, worker_list);\r\nworker->sequence++;\r\nif (worker->sequence % workers->idle_thresh == 0)\r\nlist_move_tail(next, &workers->worker_list);\r\nreturn worker;\r\n}\r\nstatic struct btrfs_worker_thread *find_worker(struct btrfs_workers *workers)\r\n{\r\nstruct btrfs_worker_thread *worker;\r\nunsigned long flags;\r\nstruct list_head *fallback;\r\nagain:\r\nspin_lock_irqsave(&workers->lock, flags);\r\nworker = next_worker(workers);\r\nif (!worker) {\r\nif (workers->num_workers + workers->num_workers_starting >=\r\nworkers->max_workers) {\r\ngoto fallback;\r\n} else if (workers->atomic_worker_start) {\r\nworkers->atomic_start_pending = 1;\r\ngoto fallback;\r\n} else {\r\nworkers->num_workers_starting++;\r\nspin_unlock_irqrestore(&workers->lock, flags);\r\n__btrfs_start_workers(workers, 1);\r\ngoto again;\r\n}\r\n}\r\ngoto found;\r\nfallback:\r\nfallback = NULL;\r\nif (!list_empty(&workers->worker_list))\r\nfallback = workers->worker_list.next;\r\nif (!list_empty(&workers->idle_list))\r\nfallback = workers->idle_list.next;\r\nBUG_ON(!fallback);\r\nworker = list_entry(fallback,\r\nstruct btrfs_worker_thread, worker_list);\r\nfound:\r\natomic_inc(&worker->num_pending);\r\nspin_unlock_irqrestore(&workers->lock, flags);\r\nreturn worker;\r\n}\r\nint btrfs_requeue_work(struct btrfs_work *work)\r\n{\r\nstruct btrfs_worker_thread *worker = work->worker;\r\nunsigned long flags;\r\nint wake = 0;\r\nif (test_and_set_bit(WORK_QUEUED_BIT, &work->flags))\r\ngoto out;\r\nspin_lock_irqsave(&worker->lock, flags);\r\nif (test_bit(WORK_HIGH_PRIO_BIT, &work->flags))\r\nlist_add_tail(&work->list, &worker->prio_pending);\r\nelse\r\nlist_add_tail(&work->list, &worker->pending);\r\natomic_inc(&worker->num_pending);\r\nif (worker->idle) {\r\nspin_lock(&worker->workers->lock);\r\nworker->idle = 0;\r\nlist_move_tail(&worker->worker_list,\r\n&worker->workers->worker_list);\r\nspin_unlock(&worker->workers->lock);\r\n}\r\nif (!worker->working) {\r\nwake = 1;\r\nworker->working = 1;\r\n}\r\nif (wake)\r\nwake_up_process(worker->task);\r\nspin_unlock_irqrestore(&worker->lock, flags);\r\nout:\r\nreturn 0;\r\n}\r\nvoid btrfs_set_work_high_prio(struct btrfs_work *work)\r\n{\r\nset_bit(WORK_HIGH_PRIO_BIT, &work->flags);\r\n}\r\nint btrfs_queue_worker(struct btrfs_workers *workers, struct btrfs_work *work)\r\n{\r\nstruct btrfs_worker_thread *worker;\r\nunsigned long flags;\r\nint wake = 0;\r\nif (test_and_set_bit(WORK_QUEUED_BIT, &work->flags))\r\ngoto out;\r\nworker = find_worker(workers);\r\nif (workers->ordered) {\r\nspin_lock(&workers->order_lock);\r\nif (test_bit(WORK_HIGH_PRIO_BIT, &work->flags)) {\r\nlist_add_tail(&work->order_list,\r\n&workers->prio_order_list);\r\n} else {\r\nlist_add_tail(&work->order_list, &workers->order_list);\r\n}\r\nspin_unlock(&workers->order_lock);\r\n} else {\r\nINIT_LIST_HEAD(&work->order_list);\r\n}\r\nspin_lock_irqsave(&worker->lock, flags);\r\nif (test_bit(WORK_HIGH_PRIO_BIT, &work->flags))\r\nlist_add_tail(&work->list, &worker->prio_pending);\r\nelse\r\nlist_add_tail(&work->list, &worker->pending);\r\ncheck_busy_worker(worker);\r\nif (!worker->working)\r\nwake = 1;\r\nworker->working = 1;\r\nif (wake)\r\nwake_up_process(worker->task);\r\nspin_unlock_irqrestore(&worker->lock, flags);\r\nout:\r\nreturn 0;\r\n}
