static int caching_kthread(void *data)\r\n{\r\nstruct btrfs_root *root = data;\r\nstruct btrfs_fs_info *fs_info = root->fs_info;\r\nstruct btrfs_free_space_ctl *ctl = root->free_ino_ctl;\r\nstruct btrfs_key key;\r\nstruct btrfs_path *path;\r\nstruct extent_buffer *leaf;\r\nu64 last = (u64)-1;\r\nint slot;\r\nint ret;\r\nif (!btrfs_test_opt(root, INODE_MAP_CACHE))\r\nreturn 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\npath->skip_locking = 1;\r\npath->search_commit_root = 1;\r\npath->reada = 2;\r\nkey.objectid = BTRFS_FIRST_FREE_OBJECTID;\r\nkey.offset = 0;\r\nkey.type = BTRFS_INODE_ITEM_KEY;\r\nagain:\r\nmutex_lock(&root->fs_commit_mutex);\r\nret = btrfs_search_slot(NULL, root, &key, path, 0, 0);\r\nif (ret < 0)\r\ngoto out;\r\nwhile (1) {\r\nif (btrfs_fs_closing(fs_info))\r\ngoto out;\r\nleaf = path->nodes[0];\r\nslot = path->slots[0];\r\nif (slot >= btrfs_header_nritems(leaf)) {\r\nret = btrfs_next_leaf(root, path);\r\nif (ret < 0)\r\ngoto out;\r\nelse if (ret > 0)\r\nbreak;\r\nif (need_resched() ||\r\nbtrfs_transaction_in_commit(fs_info)) {\r\nleaf = path->nodes[0];\r\nif (btrfs_header_nritems(leaf) == 0) {\r\nWARN_ON(1);\r\nbreak;\r\n}\r\nbtrfs_item_key_to_cpu(leaf, &key, 0);\r\nbtrfs_release_path(path);\r\nroot->cache_progress = last;\r\nmutex_unlock(&root->fs_commit_mutex);\r\nschedule_timeout(1);\r\ngoto again;\r\n} else\r\ncontinue;\r\n}\r\nbtrfs_item_key_to_cpu(leaf, &key, slot);\r\nif (key.type != BTRFS_INODE_ITEM_KEY)\r\ngoto next;\r\nif (key.objectid >= root->highest_objectid)\r\nbreak;\r\nif (last != (u64)-1 && last + 1 != key.objectid) {\r\n__btrfs_add_free_space(ctl, last + 1,\r\nkey.objectid - last - 1);\r\nwake_up(&root->cache_wait);\r\n}\r\nlast = key.objectid;\r\nnext:\r\npath->slots[0]++;\r\n}\r\nif (last < root->highest_objectid - 1) {\r\n__btrfs_add_free_space(ctl, last + 1,\r\nroot->highest_objectid - last - 1);\r\n}\r\nspin_lock(&root->cache_lock);\r\nroot->cached = BTRFS_CACHE_FINISHED;\r\nspin_unlock(&root->cache_lock);\r\nroot->cache_progress = (u64)-1;\r\nbtrfs_unpin_free_ino(root);\r\nout:\r\nwake_up(&root->cache_wait);\r\nmutex_unlock(&root->fs_commit_mutex);\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic void start_caching(struct btrfs_root *root)\r\n{\r\nstruct btrfs_free_space_ctl *ctl = root->free_ino_ctl;\r\nstruct task_struct *tsk;\r\nint ret;\r\nu64 objectid;\r\nif (!btrfs_test_opt(root, INODE_MAP_CACHE))\r\nreturn;\r\nspin_lock(&root->cache_lock);\r\nif (root->cached != BTRFS_CACHE_NO) {\r\nspin_unlock(&root->cache_lock);\r\nreturn;\r\n}\r\nroot->cached = BTRFS_CACHE_STARTED;\r\nspin_unlock(&root->cache_lock);\r\nret = load_free_ino_cache(root->fs_info, root);\r\nif (ret == 1) {\r\nspin_lock(&root->cache_lock);\r\nroot->cached = BTRFS_CACHE_FINISHED;\r\nspin_unlock(&root->cache_lock);\r\nreturn;\r\n}\r\nret = btrfs_find_free_objectid(root, &objectid);\r\nif (!ret && objectid <= BTRFS_LAST_FREE_OBJECTID) {\r\n__btrfs_add_free_space(ctl, objectid,\r\nBTRFS_LAST_FREE_OBJECTID - objectid + 1);\r\n}\r\ntsk = kthread_run(caching_kthread, root, "btrfs-ino-cache-%llu\n",\r\nroot->root_key.objectid);\r\nBUG_ON(IS_ERR(tsk));\r\n}\r\nint btrfs_find_free_ino(struct btrfs_root *root, u64 *objectid)\r\n{\r\nif (!btrfs_test_opt(root, INODE_MAP_CACHE))\r\nreturn btrfs_find_free_objectid(root, objectid);\r\nagain:\r\n*objectid = btrfs_find_ino_for_alloc(root);\r\nif (*objectid != 0)\r\nreturn 0;\r\nstart_caching(root);\r\nwait_event(root->cache_wait,\r\nroot->cached == BTRFS_CACHE_FINISHED ||\r\nroot->free_ino_ctl->free_space > 0);\r\nif (root->cached == BTRFS_CACHE_FINISHED &&\r\nroot->free_ino_ctl->free_space == 0)\r\nreturn -ENOSPC;\r\nelse\r\ngoto again;\r\n}\r\nvoid btrfs_return_ino(struct btrfs_root *root, u64 objectid)\r\n{\r\nstruct btrfs_free_space_ctl *ctl = root->free_ino_ctl;\r\nstruct btrfs_free_space_ctl *pinned = root->free_ino_pinned;\r\nif (!btrfs_test_opt(root, INODE_MAP_CACHE))\r\nreturn;\r\nagain:\r\nif (root->cached == BTRFS_CACHE_FINISHED) {\r\n__btrfs_add_free_space(ctl, objectid, 1);\r\n} else {\r\nmutex_lock(&root->fs_commit_mutex);\r\nspin_lock(&root->cache_lock);\r\nif (root->cached == BTRFS_CACHE_FINISHED) {\r\nspin_unlock(&root->cache_lock);\r\nmutex_unlock(&root->fs_commit_mutex);\r\ngoto again;\r\n}\r\nspin_unlock(&root->cache_lock);\r\nstart_caching(root);\r\nif (objectid <= root->cache_progress ||\r\nobjectid > root->highest_objectid)\r\n__btrfs_add_free_space(ctl, objectid, 1);\r\nelse\r\n__btrfs_add_free_space(pinned, objectid, 1);\r\nmutex_unlock(&root->fs_commit_mutex);\r\n}\r\n}\r\nvoid btrfs_unpin_free_ino(struct btrfs_root *root)\r\n{\r\nstruct btrfs_free_space_ctl *ctl = root->free_ino_ctl;\r\nstruct rb_root *rbroot = &root->free_ino_pinned->free_space_offset;\r\nstruct btrfs_free_space *info;\r\nstruct rb_node *n;\r\nu64 count;\r\nif (!btrfs_test_opt(root, INODE_MAP_CACHE))\r\nreturn;\r\nwhile (1) {\r\nn = rb_first(rbroot);\r\nif (!n)\r\nbreak;\r\ninfo = rb_entry(n, struct btrfs_free_space, offset_index);\r\nBUG_ON(info->bitmap);\r\nif (info->offset > root->cache_progress)\r\ngoto free;\r\nelse if (info->offset + info->bytes > root->cache_progress)\r\ncount = root->cache_progress - info->offset + 1;\r\nelse\r\ncount = info->bytes;\r\n__btrfs_add_free_space(ctl, info->offset, count);\r\nfree:\r\nrb_erase(&info->offset_index, rbroot);\r\nkfree(info);\r\n}\r\n}\r\nstatic void recalculate_thresholds(struct btrfs_free_space_ctl *ctl)\r\n{\r\nstruct btrfs_free_space *info;\r\nstruct rb_node *n;\r\nint max_ino;\r\nint max_bitmaps;\r\nn = rb_last(&ctl->free_space_offset);\r\nif (!n) {\r\nctl->extents_thresh = INIT_THRESHOLD;\r\nreturn;\r\n}\r\ninfo = rb_entry(n, struct btrfs_free_space, offset_index);\r\nmax_ino = info->bytes - 1;\r\nmax_bitmaps = ALIGN(max_ino, INODES_PER_BITMAP) / INODES_PER_BITMAP;\r\nif (max_bitmaps <= ctl->total_bitmaps) {\r\nctl->extents_thresh = 0;\r\nreturn;\r\n}\r\nctl->extents_thresh = (max_bitmaps - ctl->total_bitmaps) *\r\nPAGE_CACHE_SIZE / sizeof(*info);\r\n}\r\nstatic bool use_bitmap(struct btrfs_free_space_ctl *ctl,\r\nstruct btrfs_free_space *info)\r\n{\r\nif (ctl->free_extents < ctl->extents_thresh ||\r\ninfo->bytes > INODES_PER_BITMAP / 10)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void pinned_recalc_thresholds(struct btrfs_free_space_ctl *ctl)\r\n{\r\n}\r\nstatic bool pinned_use_bitmap(struct btrfs_free_space_ctl *ctl,\r\nstruct btrfs_free_space *info)\r\n{\r\nreturn false;\r\n}\r\nvoid btrfs_init_free_ino_ctl(struct btrfs_root *root)\r\n{\r\nstruct btrfs_free_space_ctl *ctl = root->free_ino_ctl;\r\nstruct btrfs_free_space_ctl *pinned = root->free_ino_pinned;\r\nspin_lock_init(&ctl->tree_lock);\r\nctl->unit = 1;\r\nctl->start = 0;\r\nctl->private = NULL;\r\nctl->op = &free_ino_op;\r\nctl->extents_thresh = INIT_THRESHOLD;\r\nspin_lock_init(&pinned->tree_lock);\r\npinned->unit = 1;\r\npinned->start = 0;\r\npinned->private = NULL;\r\npinned->extents_thresh = 0;\r\npinned->op = &pinned_free_ino_op;\r\n}\r\nint btrfs_save_ino_cache(struct btrfs_root *root,\r\nstruct btrfs_trans_handle *trans)\r\n{\r\nstruct btrfs_free_space_ctl *ctl = root->free_ino_ctl;\r\nstruct btrfs_path *path;\r\nstruct inode *inode;\r\nu64 alloc_hint = 0;\r\nint ret;\r\nint prealloc;\r\nbool retry = false;\r\nif (root->root_key.objectid != BTRFS_FS_TREE_OBJECTID &&\r\n(root->root_key.objectid < BTRFS_FIRST_FREE_OBJECTID ||\r\nroot->root_key.objectid > BTRFS_LAST_FREE_OBJECTID))\r\nreturn 0;\r\nif (btrfs_root_refs(&root->root_item) == 0 &&\r\nroot != root->fs_info->tree_root)\r\nreturn 0;\r\nif (!btrfs_test_opt(root, INODE_MAP_CACHE))\r\nreturn 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nagain:\r\ninode = lookup_free_ino_inode(root, path);\r\nif (IS_ERR(inode) && PTR_ERR(inode) != -ENOENT) {\r\nret = PTR_ERR(inode);\r\ngoto out;\r\n}\r\nif (IS_ERR(inode)) {\r\nBUG_ON(retry);\r\nretry = true;\r\nret = create_free_ino_inode(root, trans, path);\r\nif (ret)\r\ngoto out;\r\ngoto again;\r\n}\r\nBTRFS_I(inode)->generation = 0;\r\nret = btrfs_update_inode(trans, root, inode);\r\nWARN_ON(ret);\r\nif (i_size_read(inode) > 0) {\r\nret = btrfs_truncate_free_space_cache(root, trans, path, inode);\r\nif (ret)\r\ngoto out_put;\r\n}\r\nspin_lock(&root->cache_lock);\r\nif (root->cached != BTRFS_CACHE_FINISHED) {\r\nret = -1;\r\nspin_unlock(&root->cache_lock);\r\ngoto out_put;\r\n}\r\nspin_unlock(&root->cache_lock);\r\nspin_lock(&ctl->tree_lock);\r\nprealloc = sizeof(struct btrfs_free_space) * ctl->free_extents;\r\nprealloc = ALIGN(prealloc, PAGE_CACHE_SIZE);\r\nprealloc += ctl->total_bitmaps * PAGE_CACHE_SIZE;\r\nspin_unlock(&ctl->tree_lock);\r\nprealloc += 8 * PAGE_CACHE_SIZE;\r\nret = btrfs_check_data_free_space(inode, prealloc);\r\nif (ret)\r\ngoto out_put;\r\nret = btrfs_prealloc_file_range_trans(inode, trans, 0, 0, prealloc,\r\nprealloc, prealloc, &alloc_hint);\r\nif (ret)\r\ngoto out_put;\r\nbtrfs_free_reserved_data_space(inode, prealloc);\r\nout_put:\r\niput(inode);\r\nout:\r\nif (ret == 0)\r\nret = btrfs_write_out_ino_cache(root, trans, path);\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int btrfs_find_highest_objectid(struct btrfs_root *root, u64 *objectid)\r\n{\r\nstruct btrfs_path *path;\r\nint ret;\r\nstruct extent_buffer *l;\r\nstruct btrfs_key search_key;\r\nstruct btrfs_key found_key;\r\nint slot;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nsearch_key.objectid = BTRFS_LAST_FREE_OBJECTID;\r\nsearch_key.type = -1;\r\nsearch_key.offset = (u64)-1;\r\nret = btrfs_search_slot(NULL, root, &search_key, path, 0, 0);\r\nif (ret < 0)\r\ngoto error;\r\nBUG_ON(ret == 0);\r\nif (path->slots[0] > 0) {\r\nslot = path->slots[0] - 1;\r\nl = path->nodes[0];\r\nbtrfs_item_key_to_cpu(l, &found_key, slot);\r\n*objectid = max_t(u64, found_key.objectid,\r\nBTRFS_FIRST_FREE_OBJECTID - 1);\r\n} else {\r\n*objectid = BTRFS_FIRST_FREE_OBJECTID - 1;\r\n}\r\nret = 0;\r\nerror:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nint btrfs_find_free_objectid(struct btrfs_root *root, u64 *objectid)\r\n{\r\nint ret;\r\nmutex_lock(&root->objectid_mutex);\r\nif (unlikely(root->highest_objectid < BTRFS_FIRST_FREE_OBJECTID)) {\r\nret = btrfs_find_highest_objectid(root,\r\n&root->highest_objectid);\r\nif (ret)\r\ngoto out;\r\n}\r\nif (unlikely(root->highest_objectid >= BTRFS_LAST_FREE_OBJECTID)) {\r\nret = -ENOSPC;\r\ngoto out;\r\n}\r\n*objectid = ++root->highest_objectid;\r\nret = 0;\r\nout:\r\nmutex_unlock(&root->objectid_mutex);\r\nreturn ret;\r\n}
