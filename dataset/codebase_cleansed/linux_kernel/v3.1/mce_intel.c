static int cmci_supported(int *banks)\r\n{\r\nu64 cap;\r\nif (mce_cmci_disabled || mce_ignore_ce)\r\nreturn 0;\r\nif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\r\nreturn 0;\r\nif (!cpu_has_apic || lapic_get_maxlvt() < 6)\r\nreturn 0;\r\nrdmsrl(MSR_IA32_MCG_CAP, cap);\r\n*banks = min_t(unsigned, MAX_NR_BANKS, cap & 0xff);\r\nreturn !!(cap & MCG_CMCI_P);\r\n}\r\nstatic void intel_threshold_interrupt(void)\r\n{\r\nmachine_check_poll(MCP_TIMESTAMP, &__get_cpu_var(mce_banks_owned));\r\nmce_notify_irq();\r\n}\r\nstatic void print_update(char *type, int *hdr, int num)\r\n{\r\nif (*hdr == 0)\r\nprintk(KERN_INFO "CPU %d MCA banks", smp_processor_id());\r\n*hdr = 1;\r\nprintk(KERN_CONT " %s:%d", type, num);\r\n}\r\nstatic void cmci_discover(int banks, int boot)\r\n{\r\nunsigned long *owned = (void *)&__get_cpu_var(mce_banks_owned);\r\nunsigned long flags;\r\nint hdr = 0;\r\nint i;\r\nspin_lock_irqsave(&cmci_discover_lock, flags);\r\nfor (i = 0; i < banks; i++) {\r\nu64 val;\r\nif (test_bit(i, owned))\r\ncontinue;\r\nrdmsrl(MSR_IA32_MCx_CTL2(i), val);\r\nif (val & MCI_CTL2_CMCI_EN) {\r\nif (test_and_clear_bit(i, owned) && !boot)\r\nprint_update("SHD", &hdr, i);\r\n__clear_bit(i, __get_cpu_var(mce_poll_banks));\r\ncontinue;\r\n}\r\nval &= ~MCI_CTL2_CMCI_THRESHOLD_MASK;\r\nval |= MCI_CTL2_CMCI_EN | CMCI_THRESHOLD;\r\nwrmsrl(MSR_IA32_MCx_CTL2(i), val);\r\nrdmsrl(MSR_IA32_MCx_CTL2(i), val);\r\nif (val & MCI_CTL2_CMCI_EN) {\r\nif (!test_and_set_bit(i, owned) && !boot)\r\nprint_update("CMCI", &hdr, i);\r\n__clear_bit(i, __get_cpu_var(mce_poll_banks));\r\n} else {\r\nWARN_ON(!test_bit(i, __get_cpu_var(mce_poll_banks)));\r\n}\r\n}\r\nspin_unlock_irqrestore(&cmci_discover_lock, flags);\r\nif (hdr)\r\nprintk(KERN_CONT "\n");\r\n}\r\nvoid cmci_recheck(void)\r\n{\r\nunsigned long flags;\r\nint banks;\r\nif (!mce_available(__this_cpu_ptr(&cpu_info)) || !cmci_supported(&banks))\r\nreturn;\r\nlocal_irq_save(flags);\r\nmachine_check_poll(MCP_TIMESTAMP, &__get_cpu_var(mce_banks_owned));\r\nlocal_irq_restore(flags);\r\n}\r\nvoid cmci_clear(void)\r\n{\r\nunsigned long flags;\r\nint i;\r\nint banks;\r\nu64 val;\r\nif (!cmci_supported(&banks))\r\nreturn;\r\nspin_lock_irqsave(&cmci_discover_lock, flags);\r\nfor (i = 0; i < banks; i++) {\r\nif (!test_bit(i, __get_cpu_var(mce_banks_owned)))\r\ncontinue;\r\nrdmsrl(MSR_IA32_MCx_CTL2(i), val);\r\nval &= ~(MCI_CTL2_CMCI_EN|MCI_CTL2_CMCI_THRESHOLD_MASK);\r\nwrmsrl(MSR_IA32_MCx_CTL2(i), val);\r\n__clear_bit(i, __get_cpu_var(mce_banks_owned));\r\n}\r\nspin_unlock_irqrestore(&cmci_discover_lock, flags);\r\n}\r\nvoid cmci_rediscover(int dying)\r\n{\r\nint banks;\r\nint cpu;\r\ncpumask_var_t old;\r\nif (!cmci_supported(&banks))\r\nreturn;\r\nif (!alloc_cpumask_var(&old, GFP_KERNEL))\r\nreturn;\r\ncpumask_copy(old, &current->cpus_allowed);\r\nfor_each_online_cpu(cpu) {\r\nif (cpu == dying)\r\ncontinue;\r\nif (set_cpus_allowed_ptr(current, cpumask_of(cpu)))\r\ncontinue;\r\nif (cmci_supported(&banks))\r\ncmci_discover(banks, 0);\r\n}\r\nset_cpus_allowed_ptr(current, old);\r\nfree_cpumask_var(old);\r\n}\r\nvoid cmci_reenable(void)\r\n{\r\nint banks;\r\nif (cmci_supported(&banks))\r\ncmci_discover(banks, 0);\r\n}\r\nstatic void intel_init_cmci(void)\r\n{\r\nint banks;\r\nif (!cmci_supported(&banks))\r\nreturn;\r\nmce_threshold_vector = intel_threshold_interrupt;\r\ncmci_discover(banks, 1);\r\napic_write(APIC_LVTCMCI, THRESHOLD_APIC_VECTOR|APIC_DM_FIXED);\r\ncmci_recheck();\r\n}\r\nvoid mce_intel_feature_init(struct cpuinfo_x86 *c)\r\n{\r\nintel_init_thermal(c);\r\nintel_init_cmci();\r\n}
