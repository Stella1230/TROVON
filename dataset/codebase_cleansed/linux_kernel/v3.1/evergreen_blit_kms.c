static void\r\nset_render_target(struct radeon_device *rdev, int format,\r\nint w, int h, u64 gpu_addr)\r\n{\r\nu32 cb_color_info;\r\nint pitch, slice;\r\nh = ALIGN(h, 8);\r\nif (h < 8)\r\nh = 8;\r\ncb_color_info = ((format << 2) | (1 << 24) | (1 << 8));\r\npitch = (w / 8) - 1;\r\nslice = ((w * h) / 64) - 1;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 15));\r\nradeon_ring_write(rdev, (CB_COLOR0_BASE - PACKET3_SET_CONTEXT_REG_START) >> 2);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, pitch);\r\nradeon_ring_write(rdev, slice);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, cb_color_info);\r\nradeon_ring_write(rdev, (1 << 4));\r\nradeon_ring_write(rdev, (w - 1) | ((h - 1) << 16));\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\n}\r\nstatic void\r\ncp_set_surface_sync(struct radeon_device *rdev,\r\nu32 sync_type, u32 size,\r\nu64 mc_addr)\r\n{\r\nu32 cp_coher_size;\r\nif (size == 0xffffffff)\r\ncp_coher_size = 0xffffffff;\r\nelse\r\ncp_coher_size = ((size + 255) >> 8);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SURFACE_SYNC, 3));\r\nradeon_ring_write(rdev, sync_type);\r\nradeon_ring_write(rdev, cp_coher_size);\r\nradeon_ring_write(rdev, mc_addr >> 8);\r\nradeon_ring_write(rdev, 10);\r\n}\r\nstatic void\r\nset_shaders(struct radeon_device *rdev)\r\n{\r\nu64 gpu_addr;\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.vs_offset;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 3));\r\nradeon_ring_write(rdev, (SQ_PGM_START_VS - PACKET3_SET_CONTEXT_REG_START) >> 2);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, 2);\r\nradeon_ring_write(rdev, 0);\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.ps_offset;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 4));\r\nradeon_ring_write(rdev, (SQ_PGM_START_PS - PACKET3_SET_CONTEXT_REG_START) >> 2);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, 1);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 2);\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.vs_offset;\r\ncp_set_surface_sync(rdev, PACKET3_SH_ACTION_ENA, 512, gpu_addr);\r\n}\r\nstatic void\r\nset_vtx_resource(struct radeon_device *rdev, u64 gpu_addr)\r\n{\r\nu32 sq_vtx_constant_word2, sq_vtx_constant_word3;\r\nsq_vtx_constant_word2 = ((upper_32_bits(gpu_addr) & 0xff) | (16 << 8));\r\n#ifdef __BIG_ENDIAN\r\nsq_vtx_constant_word2 |= (2 << 30);\r\n#endif\r\nsq_vtx_constant_word3 = (0 << 3) | (1 << 6) | (2 << 9) | (3 << 12);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_RESOURCE, 8));\r\nradeon_ring_write(rdev, 0x580);\r\nradeon_ring_write(rdev, gpu_addr & 0xffffffff);\r\nradeon_ring_write(rdev, 48 - 1);\r\nradeon_ring_write(rdev, sq_vtx_constant_word2);\r\nradeon_ring_write(rdev, sq_vtx_constant_word3);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, SQ_TEX_VTX_VALID_BUFFER << 30);\r\nif ((rdev->family == CHIP_CEDAR) ||\r\n(rdev->family == CHIP_PALM) ||\r\n(rdev->family == CHIP_SUMO) ||\r\n(rdev->family == CHIP_SUMO2) ||\r\n(rdev->family == CHIP_CAICOS))\r\ncp_set_surface_sync(rdev,\r\nPACKET3_TC_ACTION_ENA, 48, gpu_addr);\r\nelse\r\ncp_set_surface_sync(rdev,\r\nPACKET3_VC_ACTION_ENA, 48, gpu_addr);\r\n}\r\nstatic void\r\nset_tex_resource(struct radeon_device *rdev,\r\nint format, int w, int h, int pitch,\r\nu64 gpu_addr)\r\n{\r\nu32 sq_tex_resource_word0, sq_tex_resource_word1;\r\nu32 sq_tex_resource_word4, sq_tex_resource_word7;\r\nif (h < 1)\r\nh = 1;\r\nsq_tex_resource_word0 = (1 << 0);\r\nsq_tex_resource_word0 |= ((((pitch >> 3) - 1) << 6) |\r\n((w - 1) << 18));\r\nsq_tex_resource_word1 = ((h - 1) << 0) | (1 << 28);\r\nsq_tex_resource_word4 = (0 << 16) | (1 << 19) | (2 << 22) | (3 << 25);\r\nsq_tex_resource_word7 = format | (SQ_TEX_VTX_VALID_TEXTURE << 30);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_RESOURCE, 8));\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, sq_tex_resource_word0);\r\nradeon_ring_write(rdev, sq_tex_resource_word1);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, sq_tex_resource_word4);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, sq_tex_resource_word7);\r\n}\r\nstatic void\r\nset_scissors(struct radeon_device *rdev, int x1, int y1,\r\nint x2, int y2)\r\n{\r\nif (x2 == 0)\r\nx1 = 1;\r\nif (y2 == 0)\r\ny1 = 1;\r\nif (rdev->family == CHIP_CAYMAN) {\r\nif ((x2 == 1) && (y2 == 1))\r\nx2 = 2;\r\n}\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 2));\r\nradeon_ring_write(rdev, (PA_SC_SCREEN_SCISSOR_TL - PACKET3_SET_CONTEXT_REG_START) >> 2);\r\nradeon_ring_write(rdev, (x1 << 0) | (y1 << 16));\r\nradeon_ring_write(rdev, (x2 << 0) | (y2 << 16));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 2));\r\nradeon_ring_write(rdev, (PA_SC_GENERIC_SCISSOR_TL - PACKET3_SET_CONTEXT_REG_START) >> 2);\r\nradeon_ring_write(rdev, (x1 << 0) | (y1 << 16) | (1 << 31));\r\nradeon_ring_write(rdev, (x2 << 0) | (y2 << 16));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 2));\r\nradeon_ring_write(rdev, (PA_SC_WINDOW_SCISSOR_TL - PACKET3_SET_CONTEXT_REG_START) >> 2);\r\nradeon_ring_write(rdev, (x1 << 0) | (y1 << 16) | (1 << 31));\r\nradeon_ring_write(rdev, (x2 << 0) | (y2 << 16));\r\n}\r\nstatic void\r\ndraw_auto(struct radeon_device *rdev)\r\n{\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(rdev, (VGT_PRIMITIVE_TYPE - PACKET3_SET_CONFIG_REG_START) >> 2);\r\nradeon_ring_write(rdev, DI_PT_RECTLIST);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_INDEX_TYPE, 0));\r\nradeon_ring_write(rdev,\r\n#ifdef __BIG_ENDIAN\r\n(2 << 2) |\r\n#endif\r\nDI_INDEX_SIZE_16_BIT);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_NUM_INSTANCES, 0));\r\nradeon_ring_write(rdev, 1);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_DRAW_INDEX_AUTO, 1));\r\nradeon_ring_write(rdev, 3);\r\nradeon_ring_write(rdev, DI_SRC_SEL_AUTO_INDEX);\r\n}\r\nstatic void\r\nset_default_state(struct radeon_device *rdev)\r\n{\r\nu32 sq_config, sq_gpr_resource_mgmt_1, sq_gpr_resource_mgmt_2, sq_gpr_resource_mgmt_3;\r\nu32 sq_thread_resource_mgmt, sq_thread_resource_mgmt_2;\r\nu32 sq_stack_resource_mgmt_1, sq_stack_resource_mgmt_2, sq_stack_resource_mgmt_3;\r\nint num_ps_gprs, num_vs_gprs, num_temp_gprs;\r\nint num_gs_gprs, num_es_gprs, num_hs_gprs, num_ls_gprs;\r\nint num_ps_threads, num_vs_threads, num_gs_threads, num_es_threads;\r\nint num_hs_threads, num_ls_threads;\r\nint num_ps_stack_entries, num_vs_stack_entries, num_gs_stack_entries, num_es_stack_entries;\r\nint num_hs_stack_entries, num_ls_stack_entries;\r\nu64 gpu_addr;\r\nint dwords;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_CLEAR_STATE, 0));\r\nradeon_ring_write(rdev, 0);\r\nif (rdev->family < CHIP_CAYMAN) {\r\nswitch (rdev->family) {\r\ncase CHIP_CEDAR:\r\ndefault:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 96;\r\nnum_vs_threads = 16;\r\nnum_gs_threads = 16;\r\nnum_es_threads = 16;\r\nnum_hs_threads = 16;\r\nnum_ls_threads = 16;\r\nnum_ps_stack_entries = 42;\r\nnum_vs_stack_entries = 42;\r\nnum_gs_stack_entries = 42;\r\nnum_es_stack_entries = 42;\r\nnum_hs_stack_entries = 42;\r\nnum_ls_stack_entries = 42;\r\nbreak;\r\ncase CHIP_REDWOOD:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 128;\r\nnum_vs_threads = 20;\r\nnum_gs_threads = 20;\r\nnum_es_threads = 20;\r\nnum_hs_threads = 20;\r\nnum_ls_threads = 20;\r\nnum_ps_stack_entries = 42;\r\nnum_vs_stack_entries = 42;\r\nnum_gs_stack_entries = 42;\r\nnum_es_stack_entries = 42;\r\nnum_hs_stack_entries = 42;\r\nnum_ls_stack_entries = 42;\r\nbreak;\r\ncase CHIP_JUNIPER:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 128;\r\nnum_vs_threads = 20;\r\nnum_gs_threads = 20;\r\nnum_es_threads = 20;\r\nnum_hs_threads = 20;\r\nnum_ls_threads = 20;\r\nnum_ps_stack_entries = 85;\r\nnum_vs_stack_entries = 85;\r\nnum_gs_stack_entries = 85;\r\nnum_es_stack_entries = 85;\r\nnum_hs_stack_entries = 85;\r\nnum_ls_stack_entries = 85;\r\nbreak;\r\ncase CHIP_CYPRESS:\r\ncase CHIP_HEMLOCK:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 128;\r\nnum_vs_threads = 20;\r\nnum_gs_threads = 20;\r\nnum_es_threads = 20;\r\nnum_hs_threads = 20;\r\nnum_ls_threads = 20;\r\nnum_ps_stack_entries = 85;\r\nnum_vs_stack_entries = 85;\r\nnum_gs_stack_entries = 85;\r\nnum_es_stack_entries = 85;\r\nnum_hs_stack_entries = 85;\r\nnum_ls_stack_entries = 85;\r\nbreak;\r\ncase CHIP_PALM:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 96;\r\nnum_vs_threads = 16;\r\nnum_gs_threads = 16;\r\nnum_es_threads = 16;\r\nnum_hs_threads = 16;\r\nnum_ls_threads = 16;\r\nnum_ps_stack_entries = 42;\r\nnum_vs_stack_entries = 42;\r\nnum_gs_stack_entries = 42;\r\nnum_es_stack_entries = 42;\r\nnum_hs_stack_entries = 42;\r\nnum_ls_stack_entries = 42;\r\nbreak;\r\ncase CHIP_SUMO:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 96;\r\nnum_vs_threads = 25;\r\nnum_gs_threads = 25;\r\nnum_es_threads = 25;\r\nnum_hs_threads = 25;\r\nnum_ls_threads = 25;\r\nnum_ps_stack_entries = 42;\r\nnum_vs_stack_entries = 42;\r\nnum_gs_stack_entries = 42;\r\nnum_es_stack_entries = 42;\r\nnum_hs_stack_entries = 42;\r\nnum_ls_stack_entries = 42;\r\nbreak;\r\ncase CHIP_SUMO2:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 96;\r\nnum_vs_threads = 25;\r\nnum_gs_threads = 25;\r\nnum_es_threads = 25;\r\nnum_hs_threads = 25;\r\nnum_ls_threads = 25;\r\nnum_ps_stack_entries = 85;\r\nnum_vs_stack_entries = 85;\r\nnum_gs_stack_entries = 85;\r\nnum_es_stack_entries = 85;\r\nnum_hs_stack_entries = 85;\r\nnum_ls_stack_entries = 85;\r\nbreak;\r\ncase CHIP_BARTS:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 128;\r\nnum_vs_threads = 20;\r\nnum_gs_threads = 20;\r\nnum_es_threads = 20;\r\nnum_hs_threads = 20;\r\nnum_ls_threads = 20;\r\nnum_ps_stack_entries = 85;\r\nnum_vs_stack_entries = 85;\r\nnum_gs_stack_entries = 85;\r\nnum_es_stack_entries = 85;\r\nnum_hs_stack_entries = 85;\r\nnum_ls_stack_entries = 85;\r\nbreak;\r\ncase CHIP_TURKS:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 128;\r\nnum_vs_threads = 20;\r\nnum_gs_threads = 20;\r\nnum_es_threads = 20;\r\nnum_hs_threads = 20;\r\nnum_ls_threads = 20;\r\nnum_ps_stack_entries = 42;\r\nnum_vs_stack_entries = 42;\r\nnum_gs_stack_entries = 42;\r\nnum_es_stack_entries = 42;\r\nnum_hs_stack_entries = 42;\r\nnum_ls_stack_entries = 42;\r\nbreak;\r\ncase CHIP_CAICOS:\r\nnum_ps_gprs = 93;\r\nnum_vs_gprs = 46;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 31;\r\nnum_es_gprs = 31;\r\nnum_hs_gprs = 23;\r\nnum_ls_gprs = 23;\r\nnum_ps_threads = 128;\r\nnum_vs_threads = 10;\r\nnum_gs_threads = 10;\r\nnum_es_threads = 10;\r\nnum_hs_threads = 10;\r\nnum_ls_threads = 10;\r\nnum_ps_stack_entries = 42;\r\nnum_vs_stack_entries = 42;\r\nnum_gs_stack_entries = 42;\r\nnum_es_stack_entries = 42;\r\nnum_hs_stack_entries = 42;\r\nnum_ls_stack_entries = 42;\r\nbreak;\r\n}\r\nif ((rdev->family == CHIP_CEDAR) ||\r\n(rdev->family == CHIP_PALM) ||\r\n(rdev->family == CHIP_SUMO) ||\r\n(rdev->family == CHIP_SUMO2) ||\r\n(rdev->family == CHIP_CAICOS))\r\nsq_config = 0;\r\nelse\r\nsq_config = VC_ENABLE;\r\nsq_config |= (EXPORT_SRC_C |\r\nCS_PRIO(0) |\r\nLS_PRIO(0) |\r\nHS_PRIO(0) |\r\nPS_PRIO(0) |\r\nVS_PRIO(1) |\r\nGS_PRIO(2) |\r\nES_PRIO(3));\r\nsq_gpr_resource_mgmt_1 = (NUM_PS_GPRS(num_ps_gprs) |\r\nNUM_VS_GPRS(num_vs_gprs) |\r\nNUM_CLAUSE_TEMP_GPRS(num_temp_gprs));\r\nsq_gpr_resource_mgmt_2 = (NUM_GS_GPRS(num_gs_gprs) |\r\nNUM_ES_GPRS(num_es_gprs));\r\nsq_gpr_resource_mgmt_3 = (NUM_HS_GPRS(num_hs_gprs) |\r\nNUM_LS_GPRS(num_ls_gprs));\r\nsq_thread_resource_mgmt = (NUM_PS_THREADS(num_ps_threads) |\r\nNUM_VS_THREADS(num_vs_threads) |\r\nNUM_GS_THREADS(num_gs_threads) |\r\nNUM_ES_THREADS(num_es_threads));\r\nsq_thread_resource_mgmt_2 = (NUM_HS_THREADS(num_hs_threads) |\r\nNUM_LS_THREADS(num_ls_threads));\r\nsq_stack_resource_mgmt_1 = (NUM_PS_STACK_ENTRIES(num_ps_stack_entries) |\r\nNUM_VS_STACK_ENTRIES(num_vs_stack_entries));\r\nsq_stack_resource_mgmt_2 = (NUM_GS_STACK_ENTRIES(num_gs_stack_entries) |\r\nNUM_ES_STACK_ENTRIES(num_es_stack_entries));\r\nsq_stack_resource_mgmt_3 = (NUM_HS_STACK_ENTRIES(num_hs_stack_entries) |\r\nNUM_LS_STACK_ENTRIES(num_ls_stack_entries));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(rdev, (SQ_DYN_GPR_CNTL_PS_FLUSH_REQ - PACKET3_SET_CONFIG_REG_START) >> 2);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(rdev, (SQ_LDS_RESOURCE_MGMT - PACKET3_SET_CONFIG_REG_START) >> 2);\r\nradeon_ring_write(rdev, 0x10001000);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONFIG_REG, 11));\r\nradeon_ring_write(rdev, (SQ_CONFIG - PACKET3_SET_CONFIG_REG_START) >> 2);\r\nradeon_ring_write(rdev, sq_config);\r\nradeon_ring_write(rdev, sq_gpr_resource_mgmt_1);\r\nradeon_ring_write(rdev, sq_gpr_resource_mgmt_2);\r\nradeon_ring_write(rdev, sq_gpr_resource_mgmt_3);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, sq_thread_resource_mgmt);\r\nradeon_ring_write(rdev, sq_thread_resource_mgmt_2);\r\nradeon_ring_write(rdev, sq_stack_resource_mgmt_1);\r\nradeon_ring_write(rdev, sq_stack_resource_mgmt_2);\r\nradeon_ring_write(rdev, sq_stack_resource_mgmt_3);\r\n}\r\nradeon_ring_write(rdev, 0xc0012800);\r\nradeon_ring_write(rdev, 0x80000000);\r\nradeon_ring_write(rdev, 0x80000000);\r\nradeon_ring_write(rdev, 0xc0026f00);\r\nradeon_ring_write(rdev, 0x00000000);\r\nradeon_ring_write(rdev, 0x00000000);\r\nradeon_ring_write(rdev, 0x00000000);\r\nradeon_ring_write(rdev, 0xc0036e00);\r\nradeon_ring_write(rdev, 0x00000000);\r\nradeon_ring_write(rdev, 0x00000012);\r\nradeon_ring_write(rdev, 0x00000000);\r\nradeon_ring_write(rdev, 0x00000000);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_MODE_CONTROL, 0));\r\nradeon_ring_write(rdev, 1);\r\ndwords = ALIGN(rdev->r600_blit.state_len, 0x10);\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.state_offset;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_INDIRECT_BUFFER, 2));\r\nradeon_ring_write(rdev, gpu_addr & 0xFFFFFFFC);\r\nradeon_ring_write(rdev, upper_32_bits(gpu_addr) & 0xFF);\r\nradeon_ring_write(rdev, dwords);\r\n}\r\nstatic inline uint32_t i2f(uint32_t input)\r\n{\r\nu32 result, i, exponent, fraction;\r\nif ((input & 0x3fff) == 0)\r\nresult = 0;\r\nelse {\r\nexponent = 140;\r\nfraction = (input & 0x3fff) << 10;\r\nfor (i = 0; i < 14; i++) {\r\nif (fraction & 0x800000)\r\nbreak;\r\nelse {\r\nfraction = fraction << 1;\r\nexponent = exponent - 1;\r\n}\r\n}\r\nresult = exponent << 23 | (fraction & 0x7fffff);\r\n}\r\nreturn result;\r\n}\r\nint evergreen_blit_init(struct radeon_device *rdev)\r\n{\r\nu32 obj_size;\r\nint i, r, dwords;\r\nvoid *ptr;\r\nu32 packet2s[16];\r\nint num_packet2s = 0;\r\nif (rdev->r600_blit.shader_obj)\r\ngoto done;\r\nmutex_init(&rdev->r600_blit.mutex);\r\nrdev->r600_blit.state_offset = 0;\r\nif (rdev->family < CHIP_CAYMAN)\r\nrdev->r600_blit.state_len = evergreen_default_size;\r\nelse\r\nrdev->r600_blit.state_len = cayman_default_size;\r\ndwords = rdev->r600_blit.state_len;\r\nwhile (dwords & 0xf) {\r\npacket2s[num_packet2s++] = cpu_to_le32(PACKET2(0));\r\ndwords++;\r\n}\r\nobj_size = dwords * 4;\r\nobj_size = ALIGN(obj_size, 256);\r\nrdev->r600_blit.vs_offset = obj_size;\r\nif (rdev->family < CHIP_CAYMAN)\r\nobj_size += evergreen_vs_size * 4;\r\nelse\r\nobj_size += cayman_vs_size * 4;\r\nobj_size = ALIGN(obj_size, 256);\r\nrdev->r600_blit.ps_offset = obj_size;\r\nif (rdev->family < CHIP_CAYMAN)\r\nobj_size += evergreen_ps_size * 4;\r\nelse\r\nobj_size += cayman_ps_size * 4;\r\nobj_size = ALIGN(obj_size, 256);\r\nr = radeon_bo_create(rdev, obj_size, PAGE_SIZE, true, RADEON_GEM_DOMAIN_VRAM,\r\n&rdev->r600_blit.shader_obj);\r\nif (r) {\r\nDRM_ERROR("evergreen failed to allocate shader\n");\r\nreturn r;\r\n}\r\nDRM_DEBUG("evergreen blit allocated bo %08x vs %08x ps %08x\n",\r\nobj_size,\r\nrdev->r600_blit.vs_offset, rdev->r600_blit.ps_offset);\r\nr = radeon_bo_reserve(rdev->r600_blit.shader_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_kmap(rdev->r600_blit.shader_obj, &ptr);\r\nif (r) {\r\nDRM_ERROR("failed to map blit object %d\n", r);\r\nreturn r;\r\n}\r\nif (rdev->family < CHIP_CAYMAN) {\r\nmemcpy_toio(ptr + rdev->r600_blit.state_offset,\r\nevergreen_default_state, rdev->r600_blit.state_len * 4);\r\nif (num_packet2s)\r\nmemcpy_toio(ptr + rdev->r600_blit.state_offset + (rdev->r600_blit.state_len * 4),\r\npacket2s, num_packet2s * 4);\r\nfor (i = 0; i < evergreen_vs_size; i++)\r\n*(u32 *)((unsigned long)ptr + rdev->r600_blit.vs_offset + i * 4) = cpu_to_le32(evergreen_vs[i]);\r\nfor (i = 0; i < evergreen_ps_size; i++)\r\n*(u32 *)((unsigned long)ptr + rdev->r600_blit.ps_offset + i * 4) = cpu_to_le32(evergreen_ps[i]);\r\n} else {\r\nmemcpy_toio(ptr + rdev->r600_blit.state_offset,\r\ncayman_default_state, rdev->r600_blit.state_len * 4);\r\nif (num_packet2s)\r\nmemcpy_toio(ptr + rdev->r600_blit.state_offset + (rdev->r600_blit.state_len * 4),\r\npacket2s, num_packet2s * 4);\r\nfor (i = 0; i < cayman_vs_size; i++)\r\n*(u32 *)((unsigned long)ptr + rdev->r600_blit.vs_offset + i * 4) = cpu_to_le32(cayman_vs[i]);\r\nfor (i = 0; i < cayman_ps_size; i++)\r\n*(u32 *)((unsigned long)ptr + rdev->r600_blit.ps_offset + i * 4) = cpu_to_le32(cayman_ps[i]);\r\n}\r\nradeon_bo_kunmap(rdev->r600_blit.shader_obj);\r\nradeon_bo_unreserve(rdev->r600_blit.shader_obj);\r\ndone:\r\nr = radeon_bo_reserve(rdev->r600_blit.shader_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_pin(rdev->r600_blit.shader_obj, RADEON_GEM_DOMAIN_VRAM,\r\n&rdev->r600_blit.shader_gpu_addr);\r\nradeon_bo_unreserve(rdev->r600_blit.shader_obj);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) pin blit object failed\n", r);\r\nreturn r;\r\n}\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);\r\nreturn 0;\r\n}\r\nvoid evergreen_blit_fini(struct radeon_device *rdev)\r\n{\r\nint r;\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);\r\nif (rdev->r600_blit.shader_obj == NULL)\r\nreturn;\r\nr = radeon_bo_reserve(rdev->r600_blit.shader_obj, false);\r\nif (!r) {\r\nradeon_bo_unpin(rdev->r600_blit.shader_obj);\r\nradeon_bo_unreserve(rdev->r600_blit.shader_obj);\r\n}\r\nradeon_bo_unref(&rdev->r600_blit.shader_obj);\r\n}\r\nstatic int evergreen_vb_ib_get(struct radeon_device *rdev)\r\n{\r\nint r;\r\nr = radeon_ib_get(rdev, &rdev->r600_blit.vb_ib);\r\nif (r) {\r\nDRM_ERROR("failed to get IB for vertex buffer\n");\r\nreturn r;\r\n}\r\nrdev->r600_blit.vb_total = 64*1024;\r\nrdev->r600_blit.vb_used = 0;\r\nreturn 0;\r\n}\r\nstatic void evergreen_vb_ib_put(struct radeon_device *rdev)\r\n{\r\nradeon_fence_emit(rdev, rdev->r600_blit.vb_ib->fence);\r\nradeon_ib_free(rdev, &rdev->r600_blit.vb_ib);\r\n}\r\nint evergreen_blit_prepare_copy(struct radeon_device *rdev, int size_bytes)\r\n{\r\nint r;\r\nint ring_size, line_size;\r\nint max_size;\r\nint dwords_per_loop = 74, num_loops;\r\nr = evergreen_vb_ib_get(rdev);\r\nif (r)\r\nreturn r;\r\nif (size_bytes & 3)\r\nline_size = 8192;\r\nelse\r\nline_size = 8192 * 4;\r\nmax_size = 8192 * line_size;\r\nnum_loops = ((size_bytes + max_size) / max_size);\r\nnum_loops += ((size_bytes % line_size) ? 1 : 0);\r\nring_size = num_loops * dwords_per_loop;\r\nring_size += 55;\r\nring_size += 10;\r\nring_size += 5;\r\nring_size += 10;\r\nr = radeon_ring_lock(rdev, ring_size);\r\nif (r)\r\nreturn r;\r\nset_default_state(rdev);\r\nset_shaders(rdev);\r\nreturn 0;\r\n}\r\nvoid evergreen_blit_done_copy(struct radeon_device *rdev, struct radeon_fence *fence)\r\n{\r\nint r;\r\nif (rdev->r600_blit.vb_ib)\r\nevergreen_vb_ib_put(rdev);\r\nif (fence)\r\nr = radeon_fence_emit(rdev, fence);\r\nradeon_ring_unlock_commit(rdev);\r\n}\r\nvoid evergreen_kms_blit_copy(struct radeon_device *rdev,\r\nu64 src_gpu_addr, u64 dst_gpu_addr,\r\nint size_bytes)\r\n{\r\nint max_bytes;\r\nu64 vb_gpu_addr;\r\nu32 *vb;\r\nDRM_DEBUG("emitting copy %16llx %16llx %d %d\n", src_gpu_addr, dst_gpu_addr,\r\nsize_bytes, rdev->r600_blit.vb_used);\r\nvb = (u32 *)(rdev->r600_blit.vb_ib->ptr + rdev->r600_blit.vb_used);\r\nif ((size_bytes & 3) || (src_gpu_addr & 3) || (dst_gpu_addr & 3)) {\r\nmax_bytes = 8192;\r\nwhile (size_bytes) {\r\nint cur_size = size_bytes;\r\nint src_x = src_gpu_addr & 255;\r\nint dst_x = dst_gpu_addr & 255;\r\nint h = 1;\r\nsrc_gpu_addr = src_gpu_addr & ~255ULL;\r\ndst_gpu_addr = dst_gpu_addr & ~255ULL;\r\nif (!src_x && !dst_x) {\r\nh = (cur_size / max_bytes);\r\nif (h > 8192)\r\nh = 8192;\r\nif (h == 0)\r\nh = 1;\r\nelse\r\ncur_size = max_bytes;\r\n} else {\r\nif (cur_size > max_bytes)\r\ncur_size = max_bytes;\r\nif (cur_size > (max_bytes - dst_x))\r\ncur_size = (max_bytes - dst_x);\r\nif (cur_size > (max_bytes - src_x))\r\ncur_size = (max_bytes - src_x);\r\n}\r\nif ((rdev->r600_blit.vb_used + 48) > rdev->r600_blit.vb_total) {\r\nWARN_ON(1);\r\n}\r\nvb[0] = i2f(dst_x);\r\nvb[1] = 0;\r\nvb[2] = i2f(src_x);\r\nvb[3] = 0;\r\nvb[4] = i2f(dst_x);\r\nvb[5] = i2f(h);\r\nvb[6] = i2f(src_x);\r\nvb[7] = i2f(h);\r\nvb[8] = i2f(dst_x + cur_size);\r\nvb[9] = i2f(h);\r\nvb[10] = i2f(src_x + cur_size);\r\nvb[11] = i2f(h);\r\nset_tex_resource(rdev, FMT_8,\r\nsrc_x + cur_size, h, src_x + cur_size,\r\nsrc_gpu_addr);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_TC_ACTION_ENA, (src_x + cur_size * h), src_gpu_addr);\r\nset_render_target(rdev, COLOR_8,\r\ndst_x + cur_size, h,\r\ndst_gpu_addr);\r\nset_scissors(rdev, dst_x, 0, dst_x + cur_size, h);\r\nvb_gpu_addr = rdev->r600_blit.vb_ib->gpu_addr + rdev->r600_blit.vb_used;\r\nset_vtx_resource(rdev, vb_gpu_addr);\r\ndraw_auto(rdev);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_CB_ACTION_ENA | PACKET3_CB0_DEST_BASE_ENA,\r\ncur_size * h, dst_gpu_addr);\r\nvb += 12;\r\nrdev->r600_blit.vb_used += 12 * 4;\r\nsrc_gpu_addr += cur_size * h;\r\ndst_gpu_addr += cur_size * h;\r\nsize_bytes -= cur_size * h;\r\n}\r\n} else {\r\nmax_bytes = 8192 * 4;\r\nwhile (size_bytes) {\r\nint cur_size = size_bytes;\r\nint src_x = (src_gpu_addr & 255);\r\nint dst_x = (dst_gpu_addr & 255);\r\nint h = 1;\r\nsrc_gpu_addr = src_gpu_addr & ~255ULL;\r\ndst_gpu_addr = dst_gpu_addr & ~255ULL;\r\nif (!src_x && !dst_x) {\r\nh = (cur_size / max_bytes);\r\nif (h > 8192)\r\nh = 8192;\r\nif (h == 0)\r\nh = 1;\r\nelse\r\ncur_size = max_bytes;\r\n} else {\r\nif (cur_size > max_bytes)\r\ncur_size = max_bytes;\r\nif (cur_size > (max_bytes - dst_x))\r\ncur_size = (max_bytes - dst_x);\r\nif (cur_size > (max_bytes - src_x))\r\ncur_size = (max_bytes - src_x);\r\n}\r\nif ((rdev->r600_blit.vb_used + 48) > rdev->r600_blit.vb_total) {\r\nWARN_ON(1);\r\n}\r\nvb[0] = i2f(dst_x / 4);\r\nvb[1] = 0;\r\nvb[2] = i2f(src_x / 4);\r\nvb[3] = 0;\r\nvb[4] = i2f(dst_x / 4);\r\nvb[5] = i2f(h);\r\nvb[6] = i2f(src_x / 4);\r\nvb[7] = i2f(h);\r\nvb[8] = i2f((dst_x + cur_size) / 4);\r\nvb[9] = i2f(h);\r\nvb[10] = i2f((src_x + cur_size) / 4);\r\nvb[11] = i2f(h);\r\nset_tex_resource(rdev, FMT_8_8_8_8,\r\n(src_x + cur_size) / 4,\r\nh, (src_x + cur_size) / 4,\r\nsrc_gpu_addr);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_TC_ACTION_ENA, (src_x + cur_size * h), src_gpu_addr);\r\nset_render_target(rdev, COLOR_8_8_8_8,\r\n(dst_x + cur_size) / 4, h,\r\ndst_gpu_addr);\r\nset_scissors(rdev, (dst_x / 4), 0, (dst_x + cur_size / 4), h);\r\nvb_gpu_addr = rdev->r600_blit.vb_ib->gpu_addr + rdev->r600_blit.vb_used;\r\nset_vtx_resource(rdev, vb_gpu_addr);\r\ndraw_auto(rdev);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_CB_ACTION_ENA | PACKET3_CB0_DEST_BASE_ENA,\r\ncur_size * h, dst_gpu_addr);\r\nvb += 12;\r\nrdev->r600_blit.vb_used += 12 * 4;\r\nsrc_gpu_addr += cur_size * h;\r\ndst_gpu_addr += cur_size * h;\r\nsize_bytes -= cur_size * h;\r\n}\r\n}\r\n}
