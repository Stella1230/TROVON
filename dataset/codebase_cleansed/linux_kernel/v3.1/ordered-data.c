static u64 entry_end(struct btrfs_ordered_extent *entry)\r\n{\r\nif (entry->file_offset + entry->len < entry->file_offset)\r\nreturn (u64)-1;\r\nreturn entry->file_offset + entry->len;\r\n}\r\nstatic struct rb_node *tree_insert(struct rb_root *root, u64 file_offset,\r\nstruct rb_node *node)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct btrfs_ordered_extent *entry;\r\nwhile (*p) {\r\nparent = *p;\r\nentry = rb_entry(parent, struct btrfs_ordered_extent, rb_node);\r\nif (file_offset < entry->file_offset)\r\np = &(*p)->rb_left;\r\nelse if (file_offset >= entry_end(entry))\r\np = &(*p)->rb_right;\r\nelse\r\nreturn parent;\r\n}\r\nrb_link_node(node, parent, p);\r\nrb_insert_color(node, root);\r\nreturn NULL;\r\n}\r\nstatic struct rb_node *__tree_search(struct rb_root *root, u64 file_offset,\r\nstruct rb_node **prev_ret)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct rb_node *prev = NULL;\r\nstruct rb_node *test;\r\nstruct btrfs_ordered_extent *entry;\r\nstruct btrfs_ordered_extent *prev_entry = NULL;\r\nwhile (n) {\r\nentry = rb_entry(n, struct btrfs_ordered_extent, rb_node);\r\nprev = n;\r\nprev_entry = entry;\r\nif (file_offset < entry->file_offset)\r\nn = n->rb_left;\r\nelse if (file_offset >= entry_end(entry))\r\nn = n->rb_right;\r\nelse\r\nreturn n;\r\n}\r\nif (!prev_ret)\r\nreturn NULL;\r\nwhile (prev && file_offset >= entry_end(prev_entry)) {\r\ntest = rb_next(prev);\r\nif (!test)\r\nbreak;\r\nprev_entry = rb_entry(test, struct btrfs_ordered_extent,\r\nrb_node);\r\nif (file_offset < entry_end(prev_entry))\r\nbreak;\r\nprev = test;\r\n}\r\nif (prev)\r\nprev_entry = rb_entry(prev, struct btrfs_ordered_extent,\r\nrb_node);\r\nwhile (prev && file_offset < entry_end(prev_entry)) {\r\ntest = rb_prev(prev);\r\nif (!test)\r\nbreak;\r\nprev_entry = rb_entry(test, struct btrfs_ordered_extent,\r\nrb_node);\r\nprev = test;\r\n}\r\n*prev_ret = prev;\r\nreturn NULL;\r\n}\r\nstatic int offset_in_entry(struct btrfs_ordered_extent *entry, u64 file_offset)\r\n{\r\nif (file_offset < entry->file_offset ||\r\nentry->file_offset + entry->len <= file_offset)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic int range_overlaps(struct btrfs_ordered_extent *entry, u64 file_offset,\r\nu64 len)\r\n{\r\nif (file_offset + len <= entry->file_offset ||\r\nentry->file_offset + entry->len <= file_offset)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic inline struct rb_node *tree_search(struct btrfs_ordered_inode_tree *tree,\r\nu64 file_offset)\r\n{\r\nstruct rb_root *root = &tree->tree;\r\nstruct rb_node *prev = NULL;\r\nstruct rb_node *ret;\r\nstruct btrfs_ordered_extent *entry;\r\nif (tree->last) {\r\nentry = rb_entry(tree->last, struct btrfs_ordered_extent,\r\nrb_node);\r\nif (offset_in_entry(entry, file_offset))\r\nreturn tree->last;\r\n}\r\nret = __tree_search(root, file_offset, &prev);\r\nif (!ret)\r\nret = prev;\r\nif (ret)\r\ntree->last = ret;\r\nreturn ret;\r\n}\r\nstatic int __btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len,\r\nint type, int dio, int compress_type)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nentry = kzalloc(sizeof(*entry), GFP_NOFS);\r\nif (!entry)\r\nreturn -ENOMEM;\r\nentry->file_offset = file_offset;\r\nentry->start = start;\r\nentry->len = len;\r\nentry->disk_len = disk_len;\r\nentry->bytes_left = len;\r\nentry->inode = inode;\r\nentry->compress_type = compress_type;\r\nif (type != BTRFS_ORDERED_IO_DONE && type != BTRFS_ORDERED_COMPLETE)\r\nset_bit(type, &entry->flags);\r\nif (dio)\r\nset_bit(BTRFS_ORDERED_DIRECT, &entry->flags);\r\natomic_set(&entry->refs, 1);\r\ninit_waitqueue_head(&entry->wait);\r\nINIT_LIST_HEAD(&entry->list);\r\nINIT_LIST_HEAD(&entry->root_extent_list);\r\ntrace_btrfs_ordered_extent_add(inode, entry);\r\nspin_lock(&tree->lock);\r\nnode = tree_insert(&tree->tree, file_offset,\r\n&entry->rb_node);\r\nBUG_ON(node);\r\nspin_unlock(&tree->lock);\r\nspin_lock(&BTRFS_I(inode)->root->fs_info->ordered_extent_lock);\r\nlist_add_tail(&entry->root_extent_list,\r\n&BTRFS_I(inode)->root->fs_info->ordered_extents);\r\nspin_unlock(&BTRFS_I(inode)->root->fs_info->ordered_extent_lock);\r\nBUG_ON(node);\r\nreturn 0;\r\n}\r\nint btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len, int type)\r\n{\r\nreturn __btrfs_add_ordered_extent(inode, file_offset, start, len,\r\ndisk_len, type, 0,\r\nBTRFS_COMPRESS_NONE);\r\n}\r\nint btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len, int type)\r\n{\r\nreturn __btrfs_add_ordered_extent(inode, file_offset, start, len,\r\ndisk_len, type, 1,\r\nBTRFS_COMPRESS_NONE);\r\n}\r\nint btrfs_add_ordered_extent_compress(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len,\r\nint type, int compress_type)\r\n{\r\nreturn __btrfs_add_ordered_extent(inode, file_offset, start, len,\r\ndisk_len, type, 0,\r\ncompress_type);\r\n}\r\nint btrfs_add_ordered_sum(struct inode *inode,\r\nstruct btrfs_ordered_extent *entry,\r\nstruct btrfs_ordered_sum *sum)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock(&tree->lock);\r\nlist_add_tail(&sum->list, &entry->list);\r\nspin_unlock(&tree->lock);\r\nreturn 0;\r\n}\r\nint btrfs_dec_test_first_ordered_pending(struct inode *inode,\r\nstruct btrfs_ordered_extent **cached,\r\nu64 *file_offset, u64 io_size)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\nint ret;\r\nu64 dec_end;\r\nu64 dec_start;\r\nu64 to_dec;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock(&tree->lock);\r\nnode = tree_search(tree, *file_offset);\r\nif (!node) {\r\nret = 1;\r\ngoto out;\r\n}\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (!offset_in_entry(entry, *file_offset)) {\r\nret = 1;\r\ngoto out;\r\n}\r\ndec_start = max(*file_offset, entry->file_offset);\r\ndec_end = min(*file_offset + io_size, entry->file_offset +\r\nentry->len);\r\n*file_offset = dec_end;\r\nif (dec_start > dec_end) {\r\nprintk(KERN_CRIT "bad ordering dec_start %llu end %llu\n",\r\n(unsigned long long)dec_start,\r\n(unsigned long long)dec_end);\r\n}\r\nto_dec = dec_end - dec_start;\r\nif (to_dec > entry->bytes_left) {\r\nprintk(KERN_CRIT "bad ordered accounting left %llu size %llu\n",\r\n(unsigned long long)entry->bytes_left,\r\n(unsigned long long)to_dec);\r\n}\r\nentry->bytes_left -= to_dec;\r\nif (entry->bytes_left == 0)\r\nret = test_and_set_bit(BTRFS_ORDERED_IO_DONE, &entry->flags);\r\nelse\r\nret = 1;\r\nout:\r\nif (!ret && cached && entry) {\r\n*cached = entry;\r\natomic_inc(&entry->refs);\r\n}\r\nspin_unlock(&tree->lock);\r\nreturn ret == 0;\r\n}\r\nint btrfs_dec_test_ordered_pending(struct inode *inode,\r\nstruct btrfs_ordered_extent **cached,\r\nu64 file_offset, u64 io_size)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\nint ret;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock(&tree->lock);\r\nnode = tree_search(tree, file_offset);\r\nif (!node) {\r\nret = 1;\r\ngoto out;\r\n}\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (!offset_in_entry(entry, file_offset)) {\r\nret = 1;\r\ngoto out;\r\n}\r\nif (io_size > entry->bytes_left) {\r\nprintk(KERN_CRIT "bad ordered accounting left %llu size %llu\n",\r\n(unsigned long long)entry->bytes_left,\r\n(unsigned long long)io_size);\r\n}\r\nentry->bytes_left -= io_size;\r\nif (entry->bytes_left == 0)\r\nret = test_and_set_bit(BTRFS_ORDERED_IO_DONE, &entry->flags);\r\nelse\r\nret = 1;\r\nout:\r\nif (!ret && cached && entry) {\r\n*cached = entry;\r\natomic_inc(&entry->refs);\r\n}\r\nspin_unlock(&tree->lock);\r\nreturn ret == 0;\r\n}\r\nint btrfs_put_ordered_extent(struct btrfs_ordered_extent *entry)\r\n{\r\nstruct list_head *cur;\r\nstruct btrfs_ordered_sum *sum;\r\ntrace_btrfs_ordered_extent_put(entry->inode, entry);\r\nif (atomic_dec_and_test(&entry->refs)) {\r\nwhile (!list_empty(&entry->list)) {\r\ncur = entry->list.next;\r\nsum = list_entry(cur, struct btrfs_ordered_sum, list);\r\nlist_del(&sum->list);\r\nkfree(sum);\r\n}\r\nkfree(entry);\r\n}\r\nreturn 0;\r\n}\r\nstatic int __btrfs_remove_ordered_extent(struct inode *inode,\r\nstruct btrfs_ordered_extent *entry)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct btrfs_root *root = BTRFS_I(inode)->root;\r\nstruct rb_node *node;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nnode = &entry->rb_node;\r\nrb_erase(node, &tree->tree);\r\ntree->last = NULL;\r\nset_bit(BTRFS_ORDERED_COMPLETE, &entry->flags);\r\nspin_lock(&root->fs_info->ordered_extent_lock);\r\nlist_del_init(&entry->root_extent_list);\r\ntrace_btrfs_ordered_extent_remove(inode, entry);\r\nif (RB_EMPTY_ROOT(&tree->tree) &&\r\n!mapping_tagged(inode->i_mapping, PAGECACHE_TAG_DIRTY)) {\r\nlist_del_init(&BTRFS_I(inode)->ordered_operations);\r\n}\r\nspin_unlock(&root->fs_info->ordered_extent_lock);\r\nreturn 0;\r\n}\r\nint btrfs_remove_ordered_extent(struct inode *inode,\r\nstruct btrfs_ordered_extent *entry)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nint ret;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock(&tree->lock);\r\nret = __btrfs_remove_ordered_extent(inode, entry);\r\nspin_unlock(&tree->lock);\r\nwake_up(&entry->wait);\r\nreturn ret;\r\n}\r\nint btrfs_wait_ordered_extents(struct btrfs_root *root,\r\nint nocow_only, int delay_iput)\r\n{\r\nstruct list_head splice;\r\nstruct list_head *cur;\r\nstruct btrfs_ordered_extent *ordered;\r\nstruct inode *inode;\r\nINIT_LIST_HEAD(&splice);\r\nspin_lock(&root->fs_info->ordered_extent_lock);\r\nlist_splice_init(&root->fs_info->ordered_extents, &splice);\r\nwhile (!list_empty(&splice)) {\r\ncur = splice.next;\r\nordered = list_entry(cur, struct btrfs_ordered_extent,\r\nroot_extent_list);\r\nif (nocow_only &&\r\n!test_bit(BTRFS_ORDERED_NOCOW, &ordered->flags) &&\r\n!test_bit(BTRFS_ORDERED_PREALLOC, &ordered->flags)) {\r\nlist_move(&ordered->root_extent_list,\r\n&root->fs_info->ordered_extents);\r\ncond_resched_lock(&root->fs_info->ordered_extent_lock);\r\ncontinue;\r\n}\r\nlist_del_init(&ordered->root_extent_list);\r\natomic_inc(&ordered->refs);\r\ninode = igrab(ordered->inode);\r\nspin_unlock(&root->fs_info->ordered_extent_lock);\r\nif (inode) {\r\nbtrfs_start_ordered_extent(inode, ordered, 1);\r\nbtrfs_put_ordered_extent(ordered);\r\nif (delay_iput)\r\nbtrfs_add_delayed_iput(inode);\r\nelse\r\niput(inode);\r\n} else {\r\nbtrfs_put_ordered_extent(ordered);\r\n}\r\nspin_lock(&root->fs_info->ordered_extent_lock);\r\n}\r\nspin_unlock(&root->fs_info->ordered_extent_lock);\r\nreturn 0;\r\n}\r\nint btrfs_run_ordered_operations(struct btrfs_root *root, int wait)\r\n{\r\nstruct btrfs_inode *btrfs_inode;\r\nstruct inode *inode;\r\nstruct list_head splice;\r\nINIT_LIST_HEAD(&splice);\r\nmutex_lock(&root->fs_info->ordered_operations_mutex);\r\nspin_lock(&root->fs_info->ordered_extent_lock);\r\nagain:\r\nlist_splice_init(&root->fs_info->ordered_operations, &splice);\r\nwhile (!list_empty(&splice)) {\r\nbtrfs_inode = list_entry(splice.next, struct btrfs_inode,\r\nordered_operations);\r\ninode = &btrfs_inode->vfs_inode;\r\nlist_del_init(&btrfs_inode->ordered_operations);\r\ninode = igrab(inode);\r\nif (!wait && inode) {\r\nlist_add_tail(&BTRFS_I(inode)->ordered_operations,\r\n&root->fs_info->ordered_operations);\r\n}\r\nspin_unlock(&root->fs_info->ordered_extent_lock);\r\nif (inode) {\r\nif (wait)\r\nbtrfs_wait_ordered_range(inode, 0, (u64)-1);\r\nelse\r\nfilemap_flush(inode->i_mapping);\r\nbtrfs_add_delayed_iput(inode);\r\n}\r\ncond_resched();\r\nspin_lock(&root->fs_info->ordered_extent_lock);\r\n}\r\nif (wait && !list_empty(&root->fs_info->ordered_operations))\r\ngoto again;\r\nspin_unlock(&root->fs_info->ordered_extent_lock);\r\nmutex_unlock(&root->fs_info->ordered_operations_mutex);\r\nreturn 0;\r\n}\r\nvoid btrfs_start_ordered_extent(struct inode *inode,\r\nstruct btrfs_ordered_extent *entry,\r\nint wait)\r\n{\r\nu64 start = entry->file_offset;\r\nu64 end = start + entry->len - 1;\r\ntrace_btrfs_ordered_extent_start(inode, entry);\r\nif (!test_bit(BTRFS_ORDERED_DIRECT, &entry->flags))\r\nfilemap_fdatawrite_range(inode->i_mapping, start, end);\r\nif (wait) {\r\nwait_event(entry->wait, test_bit(BTRFS_ORDERED_COMPLETE,\r\n&entry->flags));\r\n}\r\n}\r\nint btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len)\r\n{\r\nu64 end;\r\nu64 orig_end;\r\nstruct btrfs_ordered_extent *ordered;\r\nint found;\r\nif (start + len < start) {\r\norig_end = INT_LIMIT(loff_t);\r\n} else {\r\norig_end = start + len - 1;\r\nif (orig_end > INT_LIMIT(loff_t))\r\norig_end = INT_LIMIT(loff_t);\r\n}\r\nagain:\r\nfilemap_fdatawrite_range(inode->i_mapping, start, orig_end);\r\nfilemap_fdatawrite_range(inode->i_mapping, start, orig_end);\r\nfilemap_fdatawait_range(inode->i_mapping, start, orig_end);\r\nend = orig_end;\r\nfound = 0;\r\nwhile (1) {\r\nordered = btrfs_lookup_first_ordered_extent(inode, end);\r\nif (!ordered)\r\nbreak;\r\nif (ordered->file_offset > orig_end) {\r\nbtrfs_put_ordered_extent(ordered);\r\nbreak;\r\n}\r\nif (ordered->file_offset + ordered->len < start) {\r\nbtrfs_put_ordered_extent(ordered);\r\nbreak;\r\n}\r\nfound++;\r\nbtrfs_start_ordered_extent(inode, ordered, 1);\r\nend = ordered->file_offset;\r\nbtrfs_put_ordered_extent(ordered);\r\nif (end == 0 || end == start)\r\nbreak;\r\nend--;\r\n}\r\nif (found || test_range_bit(&BTRFS_I(inode)->io_tree, start, orig_end,\r\nEXTENT_DELALLOC, 0, NULL)) {\r\nschedule_timeout(1);\r\ngoto again;\r\n}\r\nreturn 0;\r\n}\r\nstruct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,\r\nu64 file_offset)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock(&tree->lock);\r\nnode = tree_search(tree, file_offset);\r\nif (!node)\r\ngoto out;\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (!offset_in_entry(entry, file_offset))\r\nentry = NULL;\r\nif (entry)\r\natomic_inc(&entry->refs);\r\nout:\r\nspin_unlock(&tree->lock);\r\nreturn entry;\r\n}\r\nstruct btrfs_ordered_extent *btrfs_lookup_ordered_range(struct inode *inode,\r\nu64 file_offset,\r\nu64 len)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock(&tree->lock);\r\nnode = tree_search(tree, file_offset);\r\nif (!node) {\r\nnode = tree_search(tree, file_offset + len);\r\nif (!node)\r\ngoto out;\r\n}\r\nwhile (1) {\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (range_overlaps(entry, file_offset, len))\r\nbreak;\r\nif (entry->file_offset >= file_offset + len) {\r\nentry = NULL;\r\nbreak;\r\n}\r\nentry = NULL;\r\nnode = rb_next(node);\r\nif (!node)\r\nbreak;\r\n}\r\nout:\r\nif (entry)\r\natomic_inc(&entry->refs);\r\nspin_unlock(&tree->lock);\r\nreturn entry;\r\n}\r\nstruct btrfs_ordered_extent *\r\nbtrfs_lookup_first_ordered_extent(struct inode *inode, u64 file_offset)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock(&tree->lock);\r\nnode = tree_search(tree, file_offset);\r\nif (!node)\r\ngoto out;\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\natomic_inc(&entry->refs);\r\nout:\r\nspin_unlock(&tree->lock);\r\nreturn entry;\r\n}\r\nint btrfs_ordered_update_i_size(struct inode *inode, u64 offset,\r\nstruct btrfs_ordered_extent *ordered)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree = &BTRFS_I(inode)->ordered_tree;\r\nstruct extent_io_tree *io_tree = &BTRFS_I(inode)->io_tree;\r\nu64 disk_i_size;\r\nu64 new_i_size;\r\nu64 i_size_test;\r\nu64 i_size = i_size_read(inode);\r\nstruct rb_node *node;\r\nstruct rb_node *prev = NULL;\r\nstruct btrfs_ordered_extent *test;\r\nint ret = 1;\r\nif (ordered)\r\noffset = entry_end(ordered);\r\nelse\r\noffset = ALIGN(offset, BTRFS_I(inode)->root->sectorsize);\r\nspin_lock(&tree->lock);\r\ndisk_i_size = BTRFS_I(inode)->disk_i_size;\r\nif (disk_i_size > i_size) {\r\nBTRFS_I(inode)->disk_i_size = i_size;\r\nret = 0;\r\ngoto out;\r\n}\r\nif (disk_i_size == i_size || offset <= disk_i_size) {\r\ngoto out;\r\n}\r\nif (test_range_bit(io_tree, disk_i_size, offset - 1,\r\nEXTENT_DELALLOC, 0, NULL)) {\r\ngoto out;\r\n}\r\nif (ordered) {\r\nnode = rb_prev(&ordered->rb_node);\r\n} else {\r\nprev = tree_search(tree, offset);\r\nif (prev) {\r\ntest = rb_entry(prev, struct btrfs_ordered_extent,\r\nrb_node);\r\nBUG_ON(offset_in_entry(test, offset));\r\n}\r\nnode = prev;\r\n}\r\nwhile (node) {\r\ntest = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (test->file_offset + test->len <= disk_i_size)\r\nbreak;\r\nif (test->file_offset >= i_size)\r\nbreak;\r\nif (test->file_offset >= disk_i_size)\r\ngoto out;\r\nnode = rb_prev(node);\r\n}\r\nnew_i_size = min_t(u64, offset, i_size);\r\nif (ordered) {\r\nnode = rb_next(&ordered->rb_node);\r\n} else {\r\nif (prev)\r\nnode = rb_next(prev);\r\nelse\r\nnode = rb_first(&tree->tree);\r\n}\r\ni_size_test = 0;\r\nif (node) {\r\ntest = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (test->file_offset > offset)\r\ni_size_test = test->file_offset;\r\n} else {\r\ni_size_test = i_size;\r\n}\r\nif (i_size_test > offset &&\r\n!test_range_bit(io_tree, offset, i_size_test - 1,\r\nEXTENT_DELALLOC, 0, NULL)) {\r\nnew_i_size = min_t(u64, i_size_test, i_size);\r\n}\r\nBTRFS_I(inode)->disk_i_size = new_i_size;\r\nret = 0;\r\nout:\r\nif (ordered)\r\n__btrfs_remove_ordered_extent(inode, ordered);\r\nspin_unlock(&tree->lock);\r\nif (ordered)\r\nwake_up(&ordered->wait);\r\nreturn ret;\r\n}\r\nint btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,\r\nu32 *sum)\r\n{\r\nstruct btrfs_ordered_sum *ordered_sum;\r\nstruct btrfs_sector_sum *sector_sums;\r\nstruct btrfs_ordered_extent *ordered;\r\nstruct btrfs_ordered_inode_tree *tree = &BTRFS_I(inode)->ordered_tree;\r\nunsigned long num_sectors;\r\nunsigned long i;\r\nu32 sectorsize = BTRFS_I(inode)->root->sectorsize;\r\nint ret = 1;\r\nordered = btrfs_lookup_ordered_extent(inode, offset);\r\nif (!ordered)\r\nreturn 1;\r\nspin_lock(&tree->lock);\r\nlist_for_each_entry_reverse(ordered_sum, &ordered->list, list) {\r\nif (disk_bytenr >= ordered_sum->bytenr) {\r\nnum_sectors = ordered_sum->len / sectorsize;\r\nsector_sums = ordered_sum->sums;\r\nfor (i = 0; i < num_sectors; i++) {\r\nif (sector_sums[i].bytenr == disk_bytenr) {\r\n*sum = sector_sums[i].sum;\r\nret = 0;\r\ngoto out;\r\n}\r\n}\r\n}\r\n}\r\nout:\r\nspin_unlock(&tree->lock);\r\nbtrfs_put_ordered_extent(ordered);\r\nreturn ret;\r\n}\r\nint btrfs_add_ordered_operation(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct inode *inode)\r\n{\r\nu64 last_mod;\r\nlast_mod = max(BTRFS_I(inode)->generation, BTRFS_I(inode)->last_trans);\r\nif (last_mod < root->fs_info->last_trans_committed)\r\nreturn 0;\r\nif (trans && root->fs_info->running_transaction->blocked) {\r\nbtrfs_wait_ordered_range(inode, 0, (u64)-1);\r\nreturn 0;\r\n}\r\nspin_lock(&root->fs_info->ordered_extent_lock);\r\nif (list_empty(&BTRFS_I(inode)->ordered_operations)) {\r\nlist_add_tail(&BTRFS_I(inode)->ordered_operations,\r\n&root->fs_info->ordered_operations);\r\n}\r\nspin_unlock(&root->fs_info->ordered_extent_lock);\r\nreturn 0;\r\n}
