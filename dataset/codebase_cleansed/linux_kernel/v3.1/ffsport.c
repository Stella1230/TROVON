int GLOB_Calc_Used_Bits(u32 n)\r\n{\r\nint tot_bits = 0;\r\nif (n >= 1 << 16) {\r\nn >>= 16;\r\ntot_bits += 16;\r\n}\r\nif (n >= 1 << 8) {\r\nn >>= 8;\r\ntot_bits += 8;\r\n}\r\nif (n >= 1 << 4) {\r\nn >>= 4;\r\ntot_bits += 4;\r\n}\r\nif (n >= 1 << 2) {\r\nn >>= 2;\r\ntot_bits += 2;\r\n}\r\nif (n >= 1 << 1)\r\ntot_bits += 1;\r\nreturn ((n == 0) ? (0) : tot_bits);\r\n}\r\nu64 GLOB_u64_Div(u64 addr, u32 divisor)\r\n{\r\nreturn (u64)(addr >> GLOB_Calc_Used_Bits(divisor));\r\n}\r\nu64 GLOB_u64_Remainder(u64 addr, u32 divisor_type)\r\n{\r\nu64 result = 0;\r\nif (divisor_type == 1) {\r\nresult = (addr >> DeviceInfo.nBitsInPageDataSize);\r\nresult = result * DeviceInfo.wPageDataSize;\r\n} else if (divisor_type == 2) {\r\nresult = (addr >> DeviceInfo.nBitsInBlockDataSize);\r\nresult = result * DeviceInfo.wBlockDataSize;\r\n}\r\nresult = addr - result;\r\nreturn result;\r\n}\r\nstatic int force_flush_cache(void)\r\n{\r\nnand_dbg_print(NAND_DBG_DEBUG, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nif (ERR == GLOB_FTL_Flush_Cache()) {\r\nprintk(KERN_ERR "Fail to Flush FTL Cache!\n");\r\nreturn -EFAULT;\r\n}\r\n#if CMD_DMA\r\nif (glob_ftl_execute_cmds())\r\nreturn -EIO;\r\nelse\r\nreturn 0;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int ioctl_read_page_data(unsigned long arg)\r\n{\r\nu8 *buf;\r\nstruct ioctl_rw_page_info info;\r\nint result = PASS;\r\nif (copy_from_user(&info, (void __user *)arg, sizeof(info)))\r\nreturn -EFAULT;\r\nbuf = kmalloc(IdentifyDeviceData.PageDataSize, GFP_ATOMIC);\r\nif (!buf) {\r\nprintk(KERN_ERR "ioctl_read_page_data: "\r\n"failed to allocate memory\n");\r\nreturn -ENOMEM;\r\n}\r\nmutex_lock(&spectra_lock);\r\nresult = GLOB_FTL_Page_Read(buf,\r\n(u64)info.page * IdentifyDeviceData.PageDataSize);\r\nmutex_unlock(&spectra_lock);\r\nif (copy_to_user((void __user *)info.data, buf,\r\nIdentifyDeviceData.PageDataSize)) {\r\nprintk(KERN_ERR "ioctl_read_page_data: "\r\n"failed to copy user data\n");\r\nkfree(buf);\r\nreturn -EFAULT;\r\n}\r\nkfree(buf);\r\nreturn result;\r\n}\r\nstatic int ioctl_write_page_data(unsigned long arg)\r\n{\r\nu8 *buf;\r\nstruct ioctl_rw_page_info info;\r\nint result = PASS;\r\nif (copy_from_user(&info, (void __user *)arg, sizeof(info)))\r\nreturn -EFAULT;\r\nbuf = kmalloc(IdentifyDeviceData.PageDataSize, GFP_ATOMIC);\r\nif (!buf) {\r\nprintk(KERN_ERR "ioctl_write_page_data: "\r\n"failed to allocate memory\n");\r\nreturn -ENOMEM;\r\n}\r\nif (copy_from_user(buf, (void __user *)info.data,\r\nIdentifyDeviceData.PageDataSize)) {\r\nprintk(KERN_ERR "ioctl_write_page_data: "\r\n"failed to copy user data\n");\r\nkfree(buf);\r\nreturn -EFAULT;\r\n}\r\nmutex_lock(&spectra_lock);\r\nresult = GLOB_FTL_Page_Write(buf,\r\n(u64)info.page * IdentifyDeviceData.PageDataSize);\r\nmutex_unlock(&spectra_lock);\r\nkfree(buf);\r\nreturn result;\r\n}\r\nstatic int get_res_blk_num_bad_blk(void)\r\n{\r\nreturn IdentifyDeviceData.wDataBlockNum / 10;\r\n}\r\nstatic int get_res_blk_num_os(void)\r\n{\r\nu32 res_blks, blk_size;\r\nblk_size = IdentifyDeviceData.PageDataSize *\r\nIdentifyDeviceData.PagesPerBlock;\r\nres_blks = (reserved_mb * 1024 * 1024) / blk_size;\r\nif ((res_blks < 1) || (res_blks >= IdentifyDeviceData.wDataBlockNum))\r\nres_blks = 1;\r\nreturn res_blks;\r\n}\r\nstatic int do_transfer(struct spectra_nand_dev *tr, struct request *req)\r\n{\r\nu64 start_addr, addr;\r\nu32 logical_start_sect, hd_start_sect;\r\nu32 nsect, hd_sects;\r\nu32 rsect, tsect = 0;\r\nchar *buf;\r\nu32 ratio = IdentifyDeviceData.PageDataSize >> 9;\r\nstart_addr = (u64)(blk_rq_pos(req)) << 9;\r\nstart_addr += IdentifyDeviceData.PageDataSize *\r\nIdentifyDeviceData.PagesPerBlock *\r\nres_blks_os;\r\nif (req->cmd_type & REQ_FLUSH) {\r\nif (force_flush_cache())\r\nreturn -EIO;\r\nelse\r\nreturn 0;\r\n}\r\nif (req->cmd_type != REQ_TYPE_FS)\r\nreturn -EIO;\r\nif (blk_rq_pos(req) + blk_rq_cur_sectors(req) > get_capacity(tr->gd)) {\r\nprintk(KERN_ERR "Spectra error: request over the NAND "\r\n"capacity!sector %d, current_nr_sectors %d, "\r\n"while capacity is %d\n",\r\n(int)blk_rq_pos(req),\r\nblk_rq_cur_sectors(req),\r\n(int)get_capacity(tr->gd));\r\nreturn -EIO;\r\n}\r\nlogical_start_sect = start_addr >> 9;\r\nhd_start_sect = logical_start_sect / ratio;\r\nrsect = logical_start_sect - hd_start_sect * ratio;\r\naddr = (u64)hd_start_sect * ratio * 512;\r\nbuf = req->buffer;\r\nnsect = blk_rq_cur_sectors(req);\r\nif (rsect)\r\ntsect = (ratio - rsect) < nsect ? (ratio - rsect) : nsect;\r\nswitch (rq_data_dir(req)) {\r\ncase READ:\r\nif (rsect) {\r\nif (GLOB_FTL_Page_Read(tr->tmp_buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\nmemcpy(buf, tr->tmp_buf + (rsect << 9), tsect << 9);\r\naddr += IdentifyDeviceData.PageDataSize;\r\nbuf += tsect << 9;\r\nnsect -= tsect;\r\n}\r\nfor (hd_sects = nsect / ratio; hd_sects > 0; hd_sects--) {\r\nif (GLOB_FTL_Page_Read(buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\naddr += IdentifyDeviceData.PageDataSize;\r\nbuf += IdentifyDeviceData.PageDataSize;\r\n}\r\nif (nsect % ratio) {\r\nif (GLOB_FTL_Page_Read(tr->tmp_buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\nmemcpy(buf, tr->tmp_buf, (nsect % ratio) << 9);\r\n}\r\n#if CMD_DMA\r\nif (glob_ftl_execute_cmds())\r\nreturn -EIO;\r\nelse\r\nreturn 0;\r\n#endif\r\nreturn 0;\r\ncase WRITE:\r\nif (rsect) {\r\nif (GLOB_FTL_Page_Read(tr->tmp_buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\nmemcpy(tr->tmp_buf + (rsect << 9), buf, tsect << 9);\r\nif (GLOB_FTL_Page_Write(tr->tmp_buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\naddr += IdentifyDeviceData.PageDataSize;\r\nbuf += tsect << 9;\r\nnsect -= tsect;\r\n}\r\nfor (hd_sects = nsect / ratio; hd_sects > 0; hd_sects--) {\r\nif (GLOB_FTL_Page_Write(buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\naddr += IdentifyDeviceData.PageDataSize;\r\nbuf += IdentifyDeviceData.PageDataSize;\r\n}\r\nif (nsect % ratio) {\r\nif (GLOB_FTL_Page_Read(tr->tmp_buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\nmemcpy(tr->tmp_buf, buf, (nsect % ratio) << 9);\r\nif (GLOB_FTL_Page_Write(tr->tmp_buf, addr)) {\r\nprintk(KERN_ERR "Error in %s, Line %d\n",\r\n__FILE__, __LINE__);\r\nreturn -EIO;\r\n}\r\n}\r\n#if CMD_DMA\r\nif (glob_ftl_execute_cmds())\r\nreturn -EIO;\r\nelse\r\nreturn 0;\r\n#endif\r\nreturn 0;\r\ndefault:\r\nprintk(KERN_NOTICE "Unknown request %u\n", rq_data_dir(req));\r\nreturn -EIO;\r\n}\r\n}\r\nstatic int spectra_trans_thread(void *arg)\r\n{\r\nstruct spectra_nand_dev *tr = arg;\r\nstruct request_queue *rq = tr->queue;\r\nstruct request *req = NULL;\r\ncurrent->flags |= PF_MEMALLOC;\r\nspin_lock_irq(rq->queue_lock);\r\nwhile (!kthread_should_stop()) {\r\nint res;\r\nif (!req) {\r\nreq = blk_fetch_request(rq);\r\nif (!req) {\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nspin_unlock_irq(rq->queue_lock);\r\nschedule();\r\nspin_lock_irq(rq->queue_lock);\r\ncontinue;\r\n}\r\n}\r\nspin_unlock_irq(rq->queue_lock);\r\nmutex_lock(&spectra_lock);\r\nres = do_transfer(tr, req);\r\nmutex_unlock(&spectra_lock);\r\nspin_lock_irq(rq->queue_lock);\r\nif (!__blk_end_request_cur(req, res))\r\nreq = NULL;\r\n}\r\nif (req)\r\n__blk_end_request_all(req, -EIO);\r\nspin_unlock_irq(rq->queue_lock);\r\nreturn 0;\r\n}\r\nstatic void GLOB_SBD_request(struct request_queue *rq)\r\n{\r\nstruct spectra_nand_dev *pdev = rq->queuedata;\r\nwake_up_process(pdev->thread);\r\n}\r\nstatic int GLOB_SBD_open(struct block_device *bdev, fmode_t mode)\r\n{\r\nnand_dbg_print(NAND_DBG_WARN, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nreturn 0;\r\n}\r\nstatic int GLOB_SBD_release(struct gendisk *disk, fmode_t mode)\r\n{\r\nint ret;\r\nnand_dbg_print(NAND_DBG_WARN, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nmutex_lock(&spectra_lock);\r\nret = force_flush_cache();\r\nmutex_unlock(&spectra_lock);\r\nreturn 0;\r\n}\r\nstatic int GLOB_SBD_getgeo(struct block_device *bdev, struct hd_geometry *geo)\r\n{\r\ngeo->heads = 4;\r\ngeo->sectors = 16;\r\ngeo->cylinders = get_capacity(bdev->bd_disk) / (4 * 16);\r\nnand_dbg_print(NAND_DBG_DEBUG,\r\n"heads: %d, sectors: %d, cylinders: %d\n",\r\ngeo->heads, geo->sectors, geo->cylinders);\r\nreturn 0;\r\n}\r\nint GLOB_SBD_ioctl(struct block_device *bdev, fmode_t mode,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nint ret;\r\nnand_dbg_print(NAND_DBG_TRACE, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nswitch (cmd) {\r\ncase GLOB_SBD_IOCTL_GC:\r\nnand_dbg_print(NAND_DBG_DEBUG,\r\n"Spectra IOCTL: Garbage Collection "\r\n"being performed\n");\r\nif (PASS != GLOB_FTL_Garbage_Collection())\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase GLOB_SBD_IOCTL_WL:\r\nnand_dbg_print(NAND_DBG_DEBUG,\r\n"Spectra IOCTL: Static Wear Leveling "\r\n"being performed\n");\r\nif (PASS != GLOB_FTL_Wear_Leveling())\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase GLOB_SBD_IOCTL_FORMAT:\r\nnand_dbg_print(NAND_DBG_DEBUG, "Spectra IOCTL: Flash format "\r\n"being performed\n");\r\nif (PASS != GLOB_FTL_Flash_Format())\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase GLOB_SBD_IOCTL_FLUSH_CACHE:\r\nnand_dbg_print(NAND_DBG_DEBUG, "Spectra IOCTL: Cache flush "\r\n"being performed\n");\r\nmutex_lock(&spectra_lock);\r\nret = force_flush_cache();\r\nmutex_unlock(&spectra_lock);\r\nreturn ret;\r\ncase GLOB_SBD_IOCTL_COPY_BLK_TABLE:\r\nnand_dbg_print(NAND_DBG_DEBUG, "Spectra IOCTL: "\r\n"Copy block table\n");\r\nif (copy_to_user((void __user *)arg,\r\nget_blk_table_start_addr(),\r\nget_blk_table_len()))\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase GLOB_SBD_IOCTL_COPY_WEAR_LEVELING_TABLE:\r\nnand_dbg_print(NAND_DBG_DEBUG, "Spectra IOCTL: "\r\n"Copy wear leveling table\n");\r\nif (copy_to_user((void __user *)arg,\r\nget_wear_leveling_table_start_addr(),\r\nget_wear_leveling_table_len()))\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase GLOB_SBD_IOCTL_GET_NAND_INFO:\r\nnand_dbg_print(NAND_DBG_DEBUG, "Spectra IOCTL: "\r\n"Get NAND info\n");\r\nif (copy_to_user((void __user *)arg, &IdentifyDeviceData,\r\nsizeof(IdentifyDeviceData)))\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase GLOB_SBD_IOCTL_WRITE_DATA:\r\nnand_dbg_print(NAND_DBG_DEBUG, "Spectra IOCTL: "\r\n"Write one page data\n");\r\nreturn ioctl_write_page_data(arg);\r\ncase GLOB_SBD_IOCTL_READ_DATA:\r\nnand_dbg_print(NAND_DBG_DEBUG, "Spectra IOCTL: "\r\n"Read one page data\n");\r\nreturn ioctl_read_page_data(arg);\r\n}\r\nreturn -ENOTTY;\r\n}\r\nint GLOB_SBD_unlocked_ioctl(struct block_device *bdev, fmode_t mode,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nint ret;\r\nmutex_lock(&ffsport_mutex);\r\nret = GLOB_SBD_ioctl(bdev, mode, cmd, arg);\r\nmutex_unlock(&ffsport_mutex);\r\nreturn ret;\r\n}\r\nstatic int SBD_setup_device(struct spectra_nand_dev *dev, int which)\r\n{\r\nint res_blks;\r\nu32 sects;\r\nnand_dbg_print(NAND_DBG_TRACE, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nmemset(dev, 0, sizeof(struct spectra_nand_dev));\r\nnand_dbg_print(NAND_DBG_WARN, "Reserved %d blocks "\r\n"for OS image, %d blocks for bad block replacement.\n",\r\nget_res_blk_num_os(),\r\nget_res_blk_num_bad_blk());\r\nres_blks = get_res_blk_num_bad_blk() + get_res_blk_num_os();\r\ndev->size = (u64)IdentifyDeviceData.PageDataSize *\r\nIdentifyDeviceData.PagesPerBlock *\r\n(IdentifyDeviceData.wDataBlockNum - res_blks);\r\nres_blks_os = get_res_blk_num_os();\r\nspin_lock_init(&dev->qlock);\r\ndev->tmp_buf = kmalloc(IdentifyDeviceData.PageDataSize, GFP_ATOMIC);\r\nif (!dev->tmp_buf) {\r\nprintk(KERN_ERR "Failed to kmalloc memory in %s Line %d, exit.\n",\r\n__FILE__, __LINE__);\r\ngoto out_vfree;\r\n}\r\ndev->queue = blk_init_queue(GLOB_SBD_request, &dev->qlock);\r\nif (dev->queue == NULL) {\r\nprintk(KERN_ERR\r\n"Spectra: Request queue could not be initialized."\r\n" Aborting\n ");\r\ngoto out_vfree;\r\n}\r\ndev->queue->queuedata = dev;\r\nblk_queue_logical_block_size(dev->queue, 512);\r\nblk_queue_flush(dev->queue, REQ_FLUSH);\r\ndev->thread = kthread_run(spectra_trans_thread, dev, "nand_thd");\r\nif (IS_ERR(dev->thread)) {\r\nblk_cleanup_queue(dev->queue);\r\nunregister_blkdev(GLOB_SBD_majornum, GLOB_SBD_NAME);\r\nreturn PTR_ERR(dev->thread);\r\n}\r\ndev->gd = alloc_disk(PARTITIONS);\r\nif (!dev->gd) {\r\nprintk(KERN_ERR\r\n"Spectra: Could not allocate disk. Aborting \n ");\r\ngoto out_vfree;\r\n}\r\ndev->gd->major = GLOB_SBD_majornum;\r\ndev->gd->first_minor = which * PARTITIONS;\r\ndev->gd->fops = &GLOB_SBD_ops;\r\ndev->gd->queue = dev->queue;\r\ndev->gd->private_data = dev;\r\nsnprintf(dev->gd->disk_name, 32, "%s%c", GLOB_SBD_NAME, which + 'a');\r\nsects = dev->size >> 9;\r\nnand_dbg_print(NAND_DBG_WARN, "Capacity sects: %d\n", sects);\r\nset_capacity(dev->gd, sects);\r\nadd_disk(dev->gd);\r\nreturn 0;\r\nout_vfree:\r\nreturn -ENOMEM;\r\n}\r\nstatic void register_spectra_ftl_async(void *unused, async_cookie_t cookie)\r\n{\r\nint i;\r\nif (PASS != GLOB_FTL_IdentifyDevice(&IdentifyDeviceData)) {\r\nprintk(KERN_ERR "Spectra: Unable to Read Flash Device. "\r\n"Aborting\n");\r\nreturn;\r\n} else {\r\nnand_dbg_print(NAND_DBG_WARN, "In GLOB_SBD_init: "\r\n"Num blocks=%d, pagesperblock=%d, "\r\n"pagedatasize=%d, ECCBytesPerSector=%d\n",\r\n(int)IdentifyDeviceData.NumBlocks,\r\n(int)IdentifyDeviceData.PagesPerBlock,\r\n(int)IdentifyDeviceData.PageDataSize,\r\n(int)IdentifyDeviceData.wECCBytesPerSector);\r\n}\r\nprintk(KERN_ALERT "Spectra: searching block table, please wait ...\n");\r\nif (GLOB_FTL_Init() != PASS) {\r\nprintk(KERN_ERR "Spectra: Unable to Initialize FTL Layer. "\r\n"Aborting\n");\r\ngoto out_ftl_flash_register;\r\n}\r\nprintk(KERN_ALERT "Spectra: block table has been found.\n");\r\nGLOB_SBD_majornum = register_blkdev(0, GLOB_SBD_NAME);\r\nif (GLOB_SBD_majornum <= 0) {\r\nprintk(KERN_ERR "Unable to get the major %d for Spectra",\r\nGLOB_SBD_majornum);\r\ngoto out_ftl_flash_register;\r\n}\r\nfor (i = 0; i < NUM_DEVICES; i++)\r\nif (SBD_setup_device(&nand_device[i], i) == -ENOMEM)\r\ngoto out_blk_register;\r\nnand_dbg_print(NAND_DBG_DEBUG,\r\n"Spectra: module loaded with major number %d\n",\r\nGLOB_SBD_majornum);\r\nreturn;\r\nout_blk_register:\r\nunregister_blkdev(GLOB_SBD_majornum, GLOB_SBD_NAME);\r\nout_ftl_flash_register:\r\nGLOB_FTL_Cache_Release();\r\nprintk(KERN_ERR "Spectra: Module load failed.\n");\r\n}\r\nint register_spectra_ftl()\r\n{\r\nasync_schedule(register_spectra_ftl_async, NULL);\r\nreturn 0;\r\n}\r\nstatic int GLOB_SBD_init(void)\r\n{\r\nprintk(KERN_ALERT "Spectra: %s\n", GLOB_version);\r\nmutex_init(&spectra_lock);\r\nif (PASS != GLOB_FTL_Flash_Init()) {\r\nprintk(KERN_ERR "Spectra: Unable to Initialize Flash Device. "\r\n"Aborting\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic void __exit GLOB_SBD_exit(void)\r\n{\r\nint i;\r\nnand_dbg_print(NAND_DBG_TRACE, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nfor (i = 0; i < NUM_DEVICES; i++) {\r\nstruct spectra_nand_dev *dev = &nand_device[i];\r\nif (dev->gd) {\r\ndel_gendisk(dev->gd);\r\nput_disk(dev->gd);\r\n}\r\nif (dev->queue)\r\nblk_cleanup_queue(dev->queue);\r\nkfree(dev->tmp_buf);\r\n}\r\nunregister_blkdev(GLOB_SBD_majornum, GLOB_SBD_NAME);\r\nmutex_lock(&spectra_lock);\r\nforce_flush_cache();\r\nmutex_unlock(&spectra_lock);\r\nGLOB_FTL_Cache_Release();\r\nGLOB_FTL_Flash_Release();\r\nnand_dbg_print(NAND_DBG_DEBUG,\r\n"Spectra FTL module (major number %d) unloaded.\n",\r\nGLOB_SBD_majornum);\r\n}
