static inline unsigned long srmmu_swap(unsigned long *addr, unsigned long value)\r\n{\r\n__asm__ __volatile__("swap [%2], %0" : "=&r" (value) : "0" (value), "r" (addr));\r\nreturn value;\r\n}\r\nstatic inline void srmmu_set_pte(pte_t *ptep, pte_t pteval)\r\n{\r\nsrmmu_swap((unsigned long *)ptep, pte_val(pteval));\r\n}\r\nstatic inline int srmmu_device_memory(unsigned long x)\r\n{\r\nreturn ((x & 0xF0000000) != 0);\r\n}\r\nstatic unsigned long srmmu_pte_pfn(pte_t pte)\r\n{\r\nif (srmmu_device_memory(pte_val(pte))) {\r\nreturn ~0UL;\r\n}\r\nreturn (pte_val(pte) & SRMMU_PTE_PMASK) >> (PAGE_SHIFT-4);\r\n}\r\nstatic struct page *srmmu_pmd_page(pmd_t pmd)\r\n{\r\nif (srmmu_device_memory(pmd_val(pmd)))\r\nBUG();\r\nreturn pfn_to_page((pmd_val(pmd) & SRMMU_PTD_PMASK) >> (PAGE_SHIFT-4));\r\n}\r\nstatic inline unsigned long srmmu_pgd_page(pgd_t pgd)\r\n{ return srmmu_device_memory(pgd_val(pgd))?~0:(unsigned long)__nocache_va((pgd_val(pgd) & SRMMU_PTD_PMASK) << 4); }\r\nstatic inline int srmmu_pte_none(pte_t pte)\r\n{ return !(pte_val(pte) & 0xFFFFFFF); }\r\nstatic inline int srmmu_pte_present(pte_t pte)\r\n{ return ((pte_val(pte) & SRMMU_ET_MASK) == SRMMU_ET_PTE); }\r\nstatic inline void srmmu_pte_clear(pte_t *ptep)\r\n{ srmmu_set_pte(ptep, __pte(0)); }\r\nstatic inline int srmmu_pmd_none(pmd_t pmd)\r\n{ return !(pmd_val(pmd) & 0xFFFFFFF); }\r\nstatic inline int srmmu_pmd_bad(pmd_t pmd)\r\n{ return (pmd_val(pmd) & SRMMU_ET_MASK) != SRMMU_ET_PTD; }\r\nstatic inline int srmmu_pmd_present(pmd_t pmd)\r\n{ return ((pmd_val(pmd) & SRMMU_ET_MASK) == SRMMU_ET_PTD); }\r\nstatic inline void srmmu_pmd_clear(pmd_t *pmdp) {\r\nint i;\r\nfor (i = 0; i < PTRS_PER_PTE/SRMMU_REAL_PTRS_PER_PTE; i++)\r\nsrmmu_set_pte((pte_t *)&pmdp->pmdv[i], __pte(0));\r\n}\r\nstatic inline int srmmu_pgd_none(pgd_t pgd)\r\n{ return !(pgd_val(pgd) & 0xFFFFFFF); }\r\nstatic inline int srmmu_pgd_bad(pgd_t pgd)\r\n{ return (pgd_val(pgd) & SRMMU_ET_MASK) != SRMMU_ET_PTD; }\r\nstatic inline int srmmu_pgd_present(pgd_t pgd)\r\n{ return ((pgd_val(pgd) & SRMMU_ET_MASK) == SRMMU_ET_PTD); }\r\nstatic inline void srmmu_pgd_clear(pgd_t * pgdp)\r\n{ srmmu_set_pte((pte_t *)pgdp, __pte(0)); }\r\nstatic inline pte_t srmmu_pte_wrprotect(pte_t pte)\r\n{ return __pte(pte_val(pte) & ~SRMMU_WRITE);}\r\nstatic inline pte_t srmmu_pte_mkclean(pte_t pte)\r\n{ return __pte(pte_val(pte) & ~SRMMU_DIRTY);}\r\nstatic inline pte_t srmmu_pte_mkold(pte_t pte)\r\n{ return __pte(pte_val(pte) & ~SRMMU_REF);}\r\nstatic inline pte_t srmmu_pte_mkwrite(pte_t pte)\r\n{ return __pte(pte_val(pte) | SRMMU_WRITE);}\r\nstatic inline pte_t srmmu_pte_mkdirty(pte_t pte)\r\n{ return __pte(pte_val(pte) | SRMMU_DIRTY);}\r\nstatic inline pte_t srmmu_pte_mkyoung(pte_t pte)\r\n{ return __pte(pte_val(pte) | SRMMU_REF);}\r\nstatic pte_t srmmu_mk_pte(struct page *page, pgprot_t pgprot)\r\n{ return __pte((page_to_pfn(page) << (PAGE_SHIFT-4)) | pgprot_val(pgprot)); }\r\nstatic pte_t srmmu_mk_pte_phys(unsigned long page, pgprot_t pgprot)\r\n{ return __pte(((page) >> 4) | pgprot_val(pgprot)); }\r\nstatic pte_t srmmu_mk_pte_io(unsigned long page, pgprot_t pgprot, int space)\r\n{ return __pte(((page) >> 4) | (space << 28) | pgprot_val(pgprot)); }\r\nstatic inline void srmmu_ctxd_set(ctxd_t *ctxp, pgd_t *pgdp)\r\n{ srmmu_set_pte((pte_t *)ctxp, (SRMMU_ET_PTD | (__nocache_pa((unsigned long) pgdp) >> 4))); }\r\nstatic inline void srmmu_pgd_set(pgd_t * pgdp, pmd_t * pmdp)\r\n{ srmmu_set_pte((pte_t *)pgdp, (SRMMU_ET_PTD | (__nocache_pa((unsigned long) pmdp) >> 4))); }\r\nstatic void srmmu_pmd_set(pmd_t *pmdp, pte_t *ptep)\r\n{\r\nunsigned long ptp;\r\nint i;\r\nptp = __nocache_pa((unsigned long) ptep) >> 4;\r\nfor (i = 0; i < PTRS_PER_PTE/SRMMU_REAL_PTRS_PER_PTE; i++) {\r\nsrmmu_set_pte((pte_t *)&pmdp->pmdv[i], SRMMU_ET_PTD | ptp);\r\nptp += (SRMMU_REAL_PTRS_PER_PTE*sizeof(pte_t) >> 4);\r\n}\r\n}\r\nstatic void srmmu_pmd_populate(pmd_t *pmdp, struct page *ptep)\r\n{\r\nunsigned long ptp;\r\nint i;\r\nptp = page_to_pfn(ptep) << (PAGE_SHIFT-4);\r\nfor (i = 0; i < PTRS_PER_PTE/SRMMU_REAL_PTRS_PER_PTE; i++) {\r\nsrmmu_set_pte((pte_t *)&pmdp->pmdv[i], SRMMU_ET_PTD | ptp);\r\nptp += (SRMMU_REAL_PTRS_PER_PTE*sizeof(pte_t) >> 4);\r\n}\r\n}\r\nstatic inline pte_t srmmu_pte_modify(pte_t pte, pgprot_t newprot)\r\n{ return __pte((pte_val(pte) & SRMMU_CHG_MASK) | pgprot_val(newprot)); }\r\nstatic inline pgd_t *srmmu_pgd_offset(struct mm_struct * mm, unsigned long address)\r\n{ return mm->pgd + (address >> SRMMU_PGDIR_SHIFT); }\r\nstatic inline pmd_t *srmmu_pmd_offset(pgd_t * dir, unsigned long address)\r\n{\r\nreturn (pmd_t *) srmmu_pgd_page(*dir) +\r\n((address >> PMD_SHIFT) & (PTRS_PER_PMD - 1));\r\n}\r\nstatic inline pte_t *srmmu_pte_offset(pmd_t * dir, unsigned long address)\r\n{\r\nvoid *pte;\r\npte = __nocache_va((dir->pmdv[0] & SRMMU_PTD_PMASK) << 4);\r\nreturn (pte_t *) pte +\r\n((address >> PAGE_SHIFT) & (PTRS_PER_PTE - 1));\r\n}\r\nstatic unsigned long srmmu_swp_type(swp_entry_t entry)\r\n{\r\nreturn (entry.val >> SRMMU_SWP_TYPE_SHIFT) & SRMMU_SWP_TYPE_MASK;\r\n}\r\nstatic unsigned long srmmu_swp_offset(swp_entry_t entry)\r\n{\r\nreturn (entry.val >> SRMMU_SWP_OFF_SHIFT) & SRMMU_SWP_OFF_MASK;\r\n}\r\nstatic swp_entry_t srmmu_swp_entry(unsigned long type, unsigned long offset)\r\n{\r\nreturn (swp_entry_t) {\r\n(type & SRMMU_SWP_TYPE_MASK) << SRMMU_SWP_TYPE_SHIFT\r\n| (offset & SRMMU_SWP_OFF_MASK) << SRMMU_SWP_OFF_SHIFT };\r\n}\r\nstatic unsigned long __srmmu_get_nocache(int size, int align)\r\n{\r\nint offset;\r\nif (size < SRMMU_NOCACHE_BITMAP_SHIFT) {\r\nprintk("Size 0x%x too small for nocache request\n", size);\r\nsize = SRMMU_NOCACHE_BITMAP_SHIFT;\r\n}\r\nif (size & (SRMMU_NOCACHE_BITMAP_SHIFT-1)) {\r\nprintk("Size 0x%x unaligned int nocache request\n", size);\r\nsize += SRMMU_NOCACHE_BITMAP_SHIFT-1;\r\n}\r\nBUG_ON(align > SRMMU_NOCACHE_ALIGN_MAX);\r\noffset = bit_map_string_get(&srmmu_nocache_map,\r\nsize >> SRMMU_NOCACHE_BITMAP_SHIFT,\r\nalign >> SRMMU_NOCACHE_BITMAP_SHIFT);\r\nif (offset == -1) {\r\nprintk("srmmu: out of nocache %d: %d/%d\n",\r\nsize, (int) srmmu_nocache_size,\r\nsrmmu_nocache_map.used << SRMMU_NOCACHE_BITMAP_SHIFT);\r\nreturn 0;\r\n}\r\nreturn (SRMMU_NOCACHE_VADDR + (offset << SRMMU_NOCACHE_BITMAP_SHIFT));\r\n}\r\nstatic unsigned long srmmu_get_nocache(int size, int align)\r\n{\r\nunsigned long tmp;\r\ntmp = __srmmu_get_nocache(size, align);\r\nif (tmp)\r\nmemset((void *)tmp, 0, size);\r\nreturn tmp;\r\n}\r\nstatic void srmmu_free_nocache(unsigned long vaddr, int size)\r\n{\r\nint offset;\r\nif (vaddr < SRMMU_NOCACHE_VADDR) {\r\nprintk("Vaddr %lx is smaller than nocache base 0x%lx\n",\r\nvaddr, (unsigned long)SRMMU_NOCACHE_VADDR);\r\nBUG();\r\n}\r\nif (vaddr+size > srmmu_nocache_end) {\r\nprintk("Vaddr %lx is bigger than nocache end 0x%lx\n",\r\nvaddr, srmmu_nocache_end);\r\nBUG();\r\n}\r\nif (!is_power_of_2(size)) {\r\nprintk("Size 0x%x is not a power of 2\n", size);\r\nBUG();\r\n}\r\nif (size < SRMMU_NOCACHE_BITMAP_SHIFT) {\r\nprintk("Size 0x%x is too small\n", size);\r\nBUG();\r\n}\r\nif (vaddr & (size-1)) {\r\nprintk("Vaddr %lx is not aligned to size 0x%x\n", vaddr, size);\r\nBUG();\r\n}\r\noffset = (vaddr - SRMMU_NOCACHE_VADDR) >> SRMMU_NOCACHE_BITMAP_SHIFT;\r\nsize = size >> SRMMU_NOCACHE_BITMAP_SHIFT;\r\nbit_map_clear(&srmmu_nocache_map, offset, size);\r\n}\r\nstatic void srmmu_nocache_calcsize(void)\r\n{\r\nunsigned long sysmemavail = probe_memory() / 1024;\r\nint srmmu_nocache_npages;\r\nsrmmu_nocache_npages =\r\nsysmemavail / SRMMU_NOCACHE_ALCRATIO / 1024 * 256;\r\nif (srmmu_nocache_npages < SRMMU_MIN_NOCACHE_PAGES)\r\nsrmmu_nocache_npages = SRMMU_MIN_NOCACHE_PAGES;\r\nif (srmmu_nocache_npages > SRMMU_MAX_NOCACHE_PAGES)\r\nsrmmu_nocache_npages = SRMMU_MAX_NOCACHE_PAGES;\r\nsrmmu_nocache_size = srmmu_nocache_npages * PAGE_SIZE;\r\nsrmmu_nocache_end = SRMMU_NOCACHE_VADDR + srmmu_nocache_size;\r\n}\r\nstatic void __init srmmu_nocache_init(void)\r\n{\r\nunsigned int bitmap_bits;\r\npgd_t *pgd;\r\npmd_t *pmd;\r\npte_t *pte;\r\nunsigned long paddr, vaddr;\r\nunsigned long pteval;\r\nbitmap_bits = srmmu_nocache_size >> SRMMU_NOCACHE_BITMAP_SHIFT;\r\nsrmmu_nocache_pool = __alloc_bootmem(srmmu_nocache_size,\r\nSRMMU_NOCACHE_ALIGN_MAX, 0UL);\r\nmemset(srmmu_nocache_pool, 0, srmmu_nocache_size);\r\nsrmmu_nocache_bitmap = __alloc_bootmem(bitmap_bits >> 3, SMP_CACHE_BYTES, 0UL);\r\nbit_map_init(&srmmu_nocache_map, srmmu_nocache_bitmap, bitmap_bits);\r\nsrmmu_swapper_pg_dir = (pgd_t *)__srmmu_get_nocache(SRMMU_PGD_TABLE_SIZE, SRMMU_PGD_TABLE_SIZE);\r\nmemset(__nocache_fix(srmmu_swapper_pg_dir), 0, SRMMU_PGD_TABLE_SIZE);\r\ninit_mm.pgd = srmmu_swapper_pg_dir;\r\nsrmmu_early_allocate_ptable_skeleton(SRMMU_NOCACHE_VADDR, srmmu_nocache_end);\r\npaddr = __pa((unsigned long)srmmu_nocache_pool);\r\nvaddr = SRMMU_NOCACHE_VADDR;\r\nwhile (vaddr < srmmu_nocache_end) {\r\npgd = pgd_offset_k(vaddr);\r\npmd = srmmu_pmd_offset(__nocache_fix(pgd), vaddr);\r\npte = srmmu_pte_offset(__nocache_fix(pmd), vaddr);\r\npteval = ((paddr >> 4) | SRMMU_ET_PTE | SRMMU_PRIV);\r\nif (srmmu_cache_pagetables)\r\npteval |= SRMMU_CACHE;\r\nsrmmu_set_pte(__nocache_fix(pte), __pte(pteval));\r\nvaddr += PAGE_SIZE;\r\npaddr += PAGE_SIZE;\r\n}\r\nflush_cache_all();\r\nflush_tlb_all();\r\n}\r\nstatic inline pgd_t *srmmu_get_pgd_fast(void)\r\n{\r\npgd_t *pgd = NULL;\r\npgd = (pgd_t *)__srmmu_get_nocache(SRMMU_PGD_TABLE_SIZE, SRMMU_PGD_TABLE_SIZE);\r\nif (pgd) {\r\npgd_t *init = pgd_offset_k(0);\r\nmemset(pgd, 0, USER_PTRS_PER_PGD * sizeof(pgd_t));\r\nmemcpy(pgd + USER_PTRS_PER_PGD, init + USER_PTRS_PER_PGD,\r\n(PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t));\r\n}\r\nreturn pgd;\r\n}\r\nstatic void srmmu_free_pgd_fast(pgd_t *pgd)\r\n{\r\nsrmmu_free_nocache((unsigned long)pgd, SRMMU_PGD_TABLE_SIZE);\r\n}\r\nstatic pmd_t *srmmu_pmd_alloc_one(struct mm_struct *mm, unsigned long address)\r\n{\r\nreturn (pmd_t *)srmmu_get_nocache(SRMMU_PMD_TABLE_SIZE, SRMMU_PMD_TABLE_SIZE);\r\n}\r\nstatic void srmmu_pmd_free(pmd_t * pmd)\r\n{\r\nsrmmu_free_nocache((unsigned long)pmd, SRMMU_PMD_TABLE_SIZE);\r\n}\r\nstatic pte_t *\r\nsrmmu_pte_alloc_one_kernel(struct mm_struct *mm, unsigned long address)\r\n{\r\nreturn (pte_t *)srmmu_get_nocache(PTE_SIZE, PTE_SIZE);\r\n}\r\nstatic pgtable_t\r\nsrmmu_pte_alloc_one(struct mm_struct *mm, unsigned long address)\r\n{\r\nunsigned long pte;\r\nstruct page *page;\r\nif ((pte = (unsigned long)srmmu_pte_alloc_one_kernel(mm, address)) == 0)\r\nreturn NULL;\r\npage = pfn_to_page( __nocache_pa(pte) >> PAGE_SHIFT );\r\npgtable_page_ctor(page);\r\nreturn page;\r\n}\r\nstatic void srmmu_free_pte_fast(pte_t *pte)\r\n{\r\nsrmmu_free_nocache((unsigned long)pte, PTE_SIZE);\r\n}\r\nstatic void srmmu_pte_free(pgtable_t pte)\r\n{\r\nunsigned long p;\r\npgtable_page_dtor(pte);\r\np = (unsigned long)page_address(pte);\r\nif (p == 0)\r\nBUG();\r\np = page_to_pfn(pte) << PAGE_SHIFT;\r\np = (unsigned long) __nocache_va(p);\r\nsrmmu_free_nocache(p, PTE_SIZE);\r\n}\r\nstatic inline void alloc_context(struct mm_struct *old_mm, struct mm_struct *mm)\r\n{\r\nstruct ctx_list *ctxp;\r\nctxp = ctx_free.next;\r\nif(ctxp != &ctx_free) {\r\nremove_from_ctx_list(ctxp);\r\nadd_to_used_ctxlist(ctxp);\r\nmm->context = ctxp->ctx_number;\r\nctxp->ctx_mm = mm;\r\nreturn;\r\n}\r\nctxp = ctx_used.next;\r\nif(ctxp->ctx_mm == old_mm)\r\nctxp = ctxp->next;\r\nif(ctxp == &ctx_used)\r\npanic("out of mmu contexts");\r\nflush_cache_mm(ctxp->ctx_mm);\r\nflush_tlb_mm(ctxp->ctx_mm);\r\nremove_from_ctx_list(ctxp);\r\nadd_to_used_ctxlist(ctxp);\r\nctxp->ctx_mm->context = NO_CONTEXT;\r\nctxp->ctx_mm = mm;\r\nmm->context = ctxp->ctx_number;\r\n}\r\nstatic inline void free_context(int context)\r\n{\r\nstruct ctx_list *ctx_old;\r\nctx_old = ctx_list_pool + context;\r\nremove_from_ctx_list(ctx_old);\r\nadd_to_free_ctxlist(ctx_old);\r\n}\r\nstatic void srmmu_switch_mm(struct mm_struct *old_mm, struct mm_struct *mm,\r\nstruct task_struct *tsk, int cpu)\r\n{\r\nif(mm->context == NO_CONTEXT) {\r\nspin_lock(&srmmu_context_spinlock);\r\nalloc_context(old_mm, mm);\r\nspin_unlock(&srmmu_context_spinlock);\r\nsrmmu_ctxd_set(&srmmu_context_table[mm->context], mm->pgd);\r\n}\r\nif (sparc_cpu_model == sparc_leon)\r\nleon_switch_mm();\r\nif (is_hypersparc)\r\nhyper_flush_whole_icache();\r\nsrmmu_set_context(mm->context);\r\n}\r\nstatic inline void srmmu_mapioaddr(unsigned long physaddr,\r\nunsigned long virt_addr, int bus_type)\r\n{\r\npgd_t *pgdp;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\nunsigned long tmp;\r\nphysaddr &= PAGE_MASK;\r\npgdp = pgd_offset_k(virt_addr);\r\npmdp = srmmu_pmd_offset(pgdp, virt_addr);\r\nptep = srmmu_pte_offset(pmdp, virt_addr);\r\ntmp = (physaddr >> 4) | SRMMU_ET_PTE;\r\ntmp |= (bus_type << 28);\r\ntmp |= SRMMU_PRIV;\r\n__flush_page_to_ram(virt_addr);\r\nsrmmu_set_pte(ptep, __pte(tmp));\r\n}\r\nstatic void srmmu_mapiorange(unsigned int bus, unsigned long xpa,\r\nunsigned long xva, unsigned int len)\r\n{\r\nwhile (len != 0) {\r\nlen -= PAGE_SIZE;\r\nsrmmu_mapioaddr(xpa, xva, bus);\r\nxva += PAGE_SIZE;\r\nxpa += PAGE_SIZE;\r\n}\r\nflush_tlb_all();\r\n}\r\nstatic inline void srmmu_unmapioaddr(unsigned long virt_addr)\r\n{\r\npgd_t *pgdp;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\npgdp = pgd_offset_k(virt_addr);\r\npmdp = srmmu_pmd_offset(pgdp, virt_addr);\r\nptep = srmmu_pte_offset(pmdp, virt_addr);\r\nsrmmu_pte_clear(ptep);\r\n}\r\nstatic void srmmu_unmapiorange(unsigned long virt_addr, unsigned int len)\r\n{\r\nwhile (len != 0) {\r\nlen -= PAGE_SIZE;\r\nsrmmu_unmapioaddr(virt_addr);\r\nvirt_addr += PAGE_SIZE;\r\n}\r\nflush_tlb_all();\r\n}\r\nstatic struct thread_info *srmmu_alloc_thread_info_node(int node)\r\n{\r\nstruct thread_info *ret;\r\nret = (struct thread_info *)__get_free_pages(GFP_KERNEL,\r\nTHREAD_INFO_ORDER);\r\n#ifdef CONFIG_DEBUG_STACK_USAGE\r\nif (ret)\r\nmemset(ret, 0, PAGE_SIZE << THREAD_INFO_ORDER);\r\n#endif\r\nreturn ret;\r\n}\r\nstatic void srmmu_free_thread_info(struct thread_info *ti)\r\n{\r\nfree_pages((unsigned long)ti, THREAD_INFO_ORDER);\r\n}\r\nstatic void swift_update_mmu_cache(struct vm_area_struct * vma, unsigned long address, pte_t *ptep)\r\n{\r\n#if 0\r\nstatic unsigned long last;\r\nunsigned int val;\r\nif (address == last) {\r\nval = srmmu_hwprobe(address);\r\nif (val != 0 && pte_val(*ptep) != val) {\r\nprintk("swift_update_mmu_cache: "\r\n"addr %lx put %08x probed %08x from %p\n",\r\naddress, pte_val(*ptep), val,\r\n__builtin_return_address(0));\r\nsrmmu_flush_whole_tlb();\r\n}\r\n}\r\nlast = address;\r\n#endif\r\n}\r\nstatic void cypress_flush_cache_all(void)\r\n{\r\nvolatile unsigned long cypress_sucks;\r\nunsigned long faddr, tagval;\r\nflush_user_windows();\r\nfor(faddr = 0; faddr < 0x10000; faddr += 0x20) {\r\n__asm__ __volatile__("lda [%1 + %2] %3, %0\n\t" :\r\n"=r" (tagval) :\r\n"r" (faddr), "r" (0x40000),\r\n"i" (ASI_M_DATAC_TAG));\r\nif((tagval & 0x60) == 0x60)\r\ncypress_sucks = *(unsigned long *)(0xf0020000 + faddr);\r\n}\r\n}\r\nstatic void cypress_flush_cache_mm(struct mm_struct *mm)\r\n{\r\nregister unsigned long a, b, c, d, e, f, g;\r\nunsigned long flags, faddr;\r\nint octx;\r\nFLUSH_BEGIN(mm)\r\nflush_user_windows();\r\nlocal_irq_save(flags);\r\noctx = srmmu_get_context();\r\nsrmmu_set_context(mm->context);\r\na = 0x20; b = 0x40; c = 0x60;\r\nd = 0x80; e = 0xa0; f = 0xc0; g = 0xe0;\r\nfaddr = (0x10000 - 0x100);\r\ngoto inside;\r\ndo {\r\nfaddr -= 0x100;\r\ninside:\r\n__asm__ __volatile__("sta %%g0, [%0] %1\n\t"\r\n"sta %%g0, [%0 + %2] %1\n\t"\r\n"sta %%g0, [%0 + %3] %1\n\t"\r\n"sta %%g0, [%0 + %4] %1\n\t"\r\n"sta %%g0, [%0 + %5] %1\n\t"\r\n"sta %%g0, [%0 + %6] %1\n\t"\r\n"sta %%g0, [%0 + %7] %1\n\t"\r\n"sta %%g0, [%0 + %8] %1\n\t" : :\r\n"r" (faddr), "i" (ASI_M_FLUSH_CTX),\r\n"r" (a), "r" (b), "r" (c), "r" (d),\r\n"r" (e), "r" (f), "r" (g));\r\n} while(faddr);\r\nsrmmu_set_context(octx);\r\nlocal_irq_restore(flags);\r\nFLUSH_END\r\n}\r\nstatic void cypress_flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)\r\n{\r\nstruct mm_struct *mm = vma->vm_mm;\r\nregister unsigned long a, b, c, d, e, f, g;\r\nunsigned long flags, faddr;\r\nint octx;\r\nFLUSH_BEGIN(mm)\r\nflush_user_windows();\r\nlocal_irq_save(flags);\r\noctx = srmmu_get_context();\r\nsrmmu_set_context(mm->context);\r\na = 0x20; b = 0x40; c = 0x60;\r\nd = 0x80; e = 0xa0; f = 0xc0; g = 0xe0;\r\nstart &= SRMMU_REAL_PMD_MASK;\r\nwhile(start < end) {\r\nfaddr = (start + (0x10000 - 0x100));\r\ngoto inside;\r\ndo {\r\nfaddr -= 0x100;\r\ninside:\r\n__asm__ __volatile__("sta %%g0, [%0] %1\n\t"\r\n"sta %%g0, [%0 + %2] %1\n\t"\r\n"sta %%g0, [%0 + %3] %1\n\t"\r\n"sta %%g0, [%0 + %4] %1\n\t"\r\n"sta %%g0, [%0 + %5] %1\n\t"\r\n"sta %%g0, [%0 + %6] %1\n\t"\r\n"sta %%g0, [%0 + %7] %1\n\t"\r\n"sta %%g0, [%0 + %8] %1\n\t" : :\r\n"r" (faddr),\r\n"i" (ASI_M_FLUSH_SEG),\r\n"r" (a), "r" (b), "r" (c), "r" (d),\r\n"r" (e), "r" (f), "r" (g));\r\n} while (faddr != start);\r\nstart += SRMMU_REAL_PMD_SIZE;\r\n}\r\nsrmmu_set_context(octx);\r\nlocal_irq_restore(flags);\r\nFLUSH_END\r\n}\r\nstatic void cypress_flush_cache_page(struct vm_area_struct *vma, unsigned long page)\r\n{\r\nregister unsigned long a, b, c, d, e, f, g;\r\nstruct mm_struct *mm = vma->vm_mm;\r\nunsigned long flags, line;\r\nint octx;\r\nFLUSH_BEGIN(mm)\r\nflush_user_windows();\r\nlocal_irq_save(flags);\r\noctx = srmmu_get_context();\r\nsrmmu_set_context(mm->context);\r\na = 0x20; b = 0x40; c = 0x60;\r\nd = 0x80; e = 0xa0; f = 0xc0; g = 0xe0;\r\npage &= PAGE_MASK;\r\nline = (page + PAGE_SIZE) - 0x100;\r\ngoto inside;\r\ndo {\r\nline -= 0x100;\r\ninside:\r\n__asm__ __volatile__("sta %%g0, [%0] %1\n\t"\r\n"sta %%g0, [%0 + %2] %1\n\t"\r\n"sta %%g0, [%0 + %3] %1\n\t"\r\n"sta %%g0, [%0 + %4] %1\n\t"\r\n"sta %%g0, [%0 + %5] %1\n\t"\r\n"sta %%g0, [%0 + %6] %1\n\t"\r\n"sta %%g0, [%0 + %7] %1\n\t"\r\n"sta %%g0, [%0 + %8] %1\n\t" : :\r\n"r" (line),\r\n"i" (ASI_M_FLUSH_PAGE),\r\n"r" (a), "r" (b), "r" (c), "r" (d),\r\n"r" (e), "r" (f), "r" (g));\r\n} while(line != page);\r\nsrmmu_set_context(octx);\r\nlocal_irq_restore(flags);\r\nFLUSH_END\r\n}\r\nstatic void cypress_flush_page_to_ram(unsigned long page)\r\n{\r\nregister unsigned long a, b, c, d, e, f, g;\r\nunsigned long line;\r\na = 0x20; b = 0x40; c = 0x60; d = 0x80; e = 0xa0; f = 0xc0; g = 0xe0;\r\npage &= PAGE_MASK;\r\nline = (page + PAGE_SIZE) - 0x100;\r\ngoto inside;\r\ndo {\r\nline -= 0x100;\r\ninside:\r\n__asm__ __volatile__("sta %%g0, [%0] %1\n\t"\r\n"sta %%g0, [%0 + %2] %1\n\t"\r\n"sta %%g0, [%0 + %3] %1\n\t"\r\n"sta %%g0, [%0 + %4] %1\n\t"\r\n"sta %%g0, [%0 + %5] %1\n\t"\r\n"sta %%g0, [%0 + %6] %1\n\t"\r\n"sta %%g0, [%0 + %7] %1\n\t"\r\n"sta %%g0, [%0 + %8] %1\n\t" : :\r\n"r" (line),\r\n"i" (ASI_M_FLUSH_PAGE),\r\n"r" (a), "r" (b), "r" (c), "r" (d),\r\n"r" (e), "r" (f), "r" (g));\r\n} while(line != page);\r\n}\r\nstatic void cypress_flush_page_for_dma(unsigned long page)\r\n{\r\n}\r\nstatic void cypress_flush_sig_insns(struct mm_struct *mm, unsigned long insn_addr)\r\n{\r\n}\r\nstatic void cypress_flush_tlb_all(void)\r\n{\r\nsrmmu_flush_whole_tlb();\r\n}\r\nstatic void cypress_flush_tlb_mm(struct mm_struct *mm)\r\n{\r\nFLUSH_BEGIN(mm)\r\n__asm__ __volatile__(\r\n"lda [%0] %3, %%g5\n\t"\r\n"sta %2, [%0] %3\n\t"\r\n"sta %%g0, [%1] %4\n\t"\r\n"sta %%g5, [%0] %3\n"\r\n:\r\n: "r" (SRMMU_CTX_REG), "r" (0x300), "r" (mm->context),\r\n"i" (ASI_M_MMUREGS), "i" (ASI_M_FLUSH_PROBE)\r\n: "g5");\r\nFLUSH_END\r\n}\r\nstatic void cypress_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)\r\n{\r\nstruct mm_struct *mm = vma->vm_mm;\r\nunsigned long size;\r\nFLUSH_BEGIN(mm)\r\nstart &= SRMMU_PGDIR_MASK;\r\nsize = SRMMU_PGDIR_ALIGN(end) - start;\r\n__asm__ __volatile__(\r\n"lda [%0] %5, %%g5\n\t"\r\n"sta %1, [%0] %5\n"\r\n"1:\n\t"\r\n"subcc %3, %4, %3\n\t"\r\n"bne 1b\n\t"\r\n" sta %%g0, [%2 + %3] %6\n\t"\r\n"sta %%g5, [%0] %5\n"\r\n:\r\n: "r" (SRMMU_CTX_REG), "r" (mm->context), "r" (start | 0x200),\r\n"r" (size), "r" (SRMMU_PGDIR_SIZE), "i" (ASI_M_MMUREGS),\r\n"i" (ASI_M_FLUSH_PROBE)\r\n: "g5", "cc");\r\nFLUSH_END\r\n}\r\nstatic void cypress_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)\r\n{\r\nstruct mm_struct *mm = vma->vm_mm;\r\nFLUSH_BEGIN(mm)\r\n__asm__ __volatile__(\r\n"lda [%0] %3, %%g5\n\t"\r\n"sta %1, [%0] %3\n\t"\r\n"sta %%g0, [%2] %4\n\t"\r\n"sta %%g5, [%0] %3\n"\r\n:\r\n: "r" (SRMMU_CTX_REG), "r" (mm->context), "r" (page & PAGE_MASK),\r\n"i" (ASI_M_MMUREGS), "i" (ASI_M_FLUSH_PROBE)\r\n: "g5");\r\nFLUSH_END\r\n}\r\nstatic void __init early_pgtable_allocfail(char *type)\r\n{\r\nprom_printf("inherit_prom_mappings: Cannot alloc kernel %s.\n", type);\r\nprom_halt();\r\n}\r\nstatic void __init srmmu_early_allocate_ptable_skeleton(unsigned long start,\r\nunsigned long end)\r\n{\r\npgd_t *pgdp;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\nwhile(start < end) {\r\npgdp = pgd_offset_k(start);\r\nif(srmmu_pgd_none(*(pgd_t *)__nocache_fix(pgdp))) {\r\npmdp = (pmd_t *) __srmmu_get_nocache(\r\nSRMMU_PMD_TABLE_SIZE, SRMMU_PMD_TABLE_SIZE);\r\nif (pmdp == NULL)\r\nearly_pgtable_allocfail("pmd");\r\nmemset(__nocache_fix(pmdp), 0, SRMMU_PMD_TABLE_SIZE);\r\nsrmmu_pgd_set(__nocache_fix(pgdp), pmdp);\r\n}\r\npmdp = srmmu_pmd_offset(__nocache_fix(pgdp), start);\r\nif(srmmu_pmd_none(*(pmd_t *)__nocache_fix(pmdp))) {\r\nptep = (pte_t *)__srmmu_get_nocache(PTE_SIZE, PTE_SIZE);\r\nif (ptep == NULL)\r\nearly_pgtable_allocfail("pte");\r\nmemset(__nocache_fix(ptep), 0, PTE_SIZE);\r\nsrmmu_pmd_set(__nocache_fix(pmdp), ptep);\r\n}\r\nif (start > (0xffffffffUL - PMD_SIZE))\r\nbreak;\r\nstart = (start + PMD_SIZE) & PMD_MASK;\r\n}\r\n}\r\nstatic void __init srmmu_allocate_ptable_skeleton(unsigned long start,\r\nunsigned long end)\r\n{\r\npgd_t *pgdp;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\nwhile(start < end) {\r\npgdp = pgd_offset_k(start);\r\nif(srmmu_pgd_none(*pgdp)) {\r\npmdp = (pmd_t *)__srmmu_get_nocache(SRMMU_PMD_TABLE_SIZE, SRMMU_PMD_TABLE_SIZE);\r\nif (pmdp == NULL)\r\nearly_pgtable_allocfail("pmd");\r\nmemset(pmdp, 0, SRMMU_PMD_TABLE_SIZE);\r\nsrmmu_pgd_set(pgdp, pmdp);\r\n}\r\npmdp = srmmu_pmd_offset(pgdp, start);\r\nif(srmmu_pmd_none(*pmdp)) {\r\nptep = (pte_t *) __srmmu_get_nocache(PTE_SIZE,\r\nPTE_SIZE);\r\nif (ptep == NULL)\r\nearly_pgtable_allocfail("pte");\r\nmemset(ptep, 0, PTE_SIZE);\r\nsrmmu_pmd_set(pmdp, ptep);\r\n}\r\nif (start > (0xffffffffUL - PMD_SIZE))\r\nbreak;\r\nstart = (start + PMD_SIZE) & PMD_MASK;\r\n}\r\n}\r\nstatic void __init srmmu_inherit_prom_mappings(unsigned long start,\r\nunsigned long end)\r\n{\r\npgd_t *pgdp;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\nint what = 0;\r\nunsigned long prompte;\r\nwhile(start <= end) {\r\nif (start == 0)\r\nbreak;\r\nif(start == 0xfef00000)\r\nstart = KADB_DEBUGGER_BEGVM;\r\nif(!(prompte = srmmu_hwprobe(start))) {\r\nstart += PAGE_SIZE;\r\ncontinue;\r\n}\r\nwhat = 0;\r\nif(!(start & ~(SRMMU_REAL_PMD_MASK))) {\r\nif(srmmu_hwprobe((start-PAGE_SIZE) + SRMMU_REAL_PMD_SIZE) == prompte)\r\nwhat = 1;\r\n}\r\nif(!(start & ~(SRMMU_PGDIR_MASK))) {\r\nif(srmmu_hwprobe((start-PAGE_SIZE) + SRMMU_PGDIR_SIZE) ==\r\nprompte)\r\nwhat = 2;\r\n}\r\npgdp = pgd_offset_k(start);\r\nif(what == 2) {\r\n*(pgd_t *)__nocache_fix(pgdp) = __pgd(prompte);\r\nstart += SRMMU_PGDIR_SIZE;\r\ncontinue;\r\n}\r\nif(srmmu_pgd_none(*(pgd_t *)__nocache_fix(pgdp))) {\r\npmdp = (pmd_t *)__srmmu_get_nocache(SRMMU_PMD_TABLE_SIZE, SRMMU_PMD_TABLE_SIZE);\r\nif (pmdp == NULL)\r\nearly_pgtable_allocfail("pmd");\r\nmemset(__nocache_fix(pmdp), 0, SRMMU_PMD_TABLE_SIZE);\r\nsrmmu_pgd_set(__nocache_fix(pgdp), pmdp);\r\n}\r\npmdp = srmmu_pmd_offset(__nocache_fix(pgdp), start);\r\nif(srmmu_pmd_none(*(pmd_t *)__nocache_fix(pmdp))) {\r\nptep = (pte_t *) __srmmu_get_nocache(PTE_SIZE,\r\nPTE_SIZE);\r\nif (ptep == NULL)\r\nearly_pgtable_allocfail("pte");\r\nmemset(__nocache_fix(ptep), 0, PTE_SIZE);\r\nsrmmu_pmd_set(__nocache_fix(pmdp), ptep);\r\n}\r\nif(what == 1) {\r\nunsigned int x;\r\nx = (start >> PMD_SHIFT) & 15;\r\n*(unsigned long *)__nocache_fix(&pmdp->pmdv[x]) = prompte;\r\nstart += SRMMU_REAL_PMD_SIZE;\r\ncontinue;\r\n}\r\nptep = srmmu_pte_offset(__nocache_fix(pmdp), start);\r\n*(pte_t *)__nocache_fix(ptep) = __pte(prompte);\r\nstart += PAGE_SIZE;\r\n}\r\n}\r\nstatic void __init do_large_mapping(unsigned long vaddr, unsigned long phys_base)\r\n{\r\npgd_t *pgdp = pgd_offset_k(vaddr);\r\nunsigned long big_pte;\r\nbig_pte = KERNEL_PTE(phys_base >> 4);\r\n*(pgd_t *)__nocache_fix(pgdp) = __pgd(big_pte);\r\n}\r\nstatic unsigned long __init map_spbank(unsigned long vbase, int sp_entry)\r\n{\r\nunsigned long pstart = (sp_banks[sp_entry].base_addr & SRMMU_PGDIR_MASK);\r\nunsigned long vstart = (vbase & SRMMU_PGDIR_MASK);\r\nunsigned long vend = SRMMU_PGDIR_ALIGN(vbase + sp_banks[sp_entry].num_bytes);\r\nconst unsigned long min_vaddr = PAGE_OFFSET;\r\nconst unsigned long max_vaddr = PAGE_OFFSET + SRMMU_MAXMEM;\r\nif (vstart < min_vaddr || vstart >= max_vaddr)\r\nreturn vstart;\r\nif (vend > max_vaddr || vend < min_vaddr)\r\nvend = max_vaddr;\r\nwhile(vstart < vend) {\r\ndo_large_mapping(vstart, pstart);\r\nvstart += SRMMU_PGDIR_SIZE; pstart += SRMMU_PGDIR_SIZE;\r\n}\r\nreturn vstart;\r\n}\r\nstatic inline void memprobe_error(char *msg)\r\n{\r\nprom_printf(msg);\r\nprom_printf("Halting now...\n");\r\nprom_halt();\r\n}\r\nstatic inline void map_kernel(void)\r\n{\r\nint i;\r\nif (phys_base > 0) {\r\ndo_large_mapping(PAGE_OFFSET, phys_base);\r\n}\r\nfor (i = 0; sp_banks[i].num_bytes != 0; i++) {\r\nmap_spbank((unsigned long)__va(sp_banks[i].base_addr), i);\r\n}\r\nBTFIXUPSET_SIMM13(user_ptrs_per_pgd, PAGE_OFFSET / SRMMU_PGDIR_SIZE);\r\n}\r\nvoid __init srmmu_paging_init(void)\r\n{\r\nint i;\r\nphandle cpunode;\r\nchar node_str[128];\r\npgd_t *pgd;\r\npmd_t *pmd;\r\npte_t *pte;\r\nunsigned long pages_avail;\r\nsparc_iomap.start = SUN4M_IOBASE_VADDR;\r\nif (sparc_cpu_model == sun4d)\r\nnum_contexts = 65536;\r\nelse {\r\ncpunode = prom_getchild(prom_root_node);\r\nnum_contexts = 0;\r\nwhile(cpunode != 0) {\r\nprom_getstring(cpunode, "device_type", node_str, sizeof(node_str));\r\nif(!strcmp(node_str, "cpu")) {\r\nnum_contexts = prom_getintdefault(cpunode, "mmu-nctx", 0x8);\r\nbreak;\r\n}\r\ncpunode = prom_getsibling(cpunode);\r\n}\r\n}\r\nif(!num_contexts) {\r\nprom_printf("Something wrong, can't find cpu node in paging_init.\n");\r\nprom_halt();\r\n}\r\npages_avail = 0;\r\nlast_valid_pfn = bootmem_init(&pages_avail);\r\nsrmmu_nocache_calcsize();\r\nsrmmu_nocache_init();\r\nsrmmu_inherit_prom_mappings(0xfe400000,(LINUX_OPPROM_ENDVM-PAGE_SIZE));\r\nmap_kernel();\r\nsrmmu_context_table = (ctxd_t *)__srmmu_get_nocache(num_contexts*sizeof(ctxd_t), num_contexts*sizeof(ctxd_t));\r\nsrmmu_ctx_table_phys = (ctxd_t *)__nocache_pa((unsigned long)srmmu_context_table);\r\nfor(i = 0; i < num_contexts; i++)\r\nsrmmu_ctxd_set((ctxd_t *)__nocache_fix(&srmmu_context_table[i]), srmmu_swapper_pg_dir);\r\nflush_cache_all();\r\nsrmmu_set_ctable_ptr((unsigned long)srmmu_ctx_table_phys);\r\n#ifdef CONFIG_SMP\r\nlocal_flush_tlb_all();\r\n#else\r\nflush_tlb_all();\r\n#endif\r\npoke_srmmu();\r\nsrmmu_allocate_ptable_skeleton(sparc_iomap.start, IOBASE_END);\r\nsrmmu_allocate_ptable_skeleton(DVMA_VADDR, DVMA_END);\r\nsrmmu_allocate_ptable_skeleton(\r\n__fix_to_virt(__end_of_fixed_addresses - 1), FIXADDR_TOP);\r\nsrmmu_allocate_ptable_skeleton(PKMAP_BASE, PKMAP_END);\r\npgd = pgd_offset_k(PKMAP_BASE);\r\npmd = srmmu_pmd_offset(pgd, PKMAP_BASE);\r\npte = srmmu_pte_offset(pmd, PKMAP_BASE);\r\npkmap_page_table = pte;\r\nflush_cache_all();\r\nflush_tlb_all();\r\nsparc_context_init(num_contexts);\r\nkmap_init();\r\n{\r\nunsigned long zones_size[MAX_NR_ZONES];\r\nunsigned long zholes_size[MAX_NR_ZONES];\r\nunsigned long npages;\r\nint znum;\r\nfor (znum = 0; znum < MAX_NR_ZONES; znum++)\r\nzones_size[znum] = zholes_size[znum] = 0;\r\nnpages = max_low_pfn - pfn_base;\r\nzones_size[ZONE_DMA] = npages;\r\nzholes_size[ZONE_DMA] = npages - pages_avail;\r\nnpages = highend_pfn - max_low_pfn;\r\nzones_size[ZONE_HIGHMEM] = npages;\r\nzholes_size[ZONE_HIGHMEM] = npages - calc_highpages();\r\nfree_area_init_node(0, zones_size, pfn_base, zholes_size);\r\n}\r\n}\r\nstatic void srmmu_mmu_info(struct seq_file *m)\r\n{\r\nseq_printf(m,\r\n"MMU type\t: %s\n"\r\n"contexts\t: %d\n"\r\n"nocache total\t: %ld\n"\r\n"nocache used\t: %d\n",\r\nsrmmu_name,\r\nnum_contexts,\r\nsrmmu_nocache_size,\r\nsrmmu_nocache_map.used << SRMMU_NOCACHE_BITMAP_SHIFT);\r\n}\r\nstatic void srmmu_update_mmu_cache(struct vm_area_struct * vma, unsigned long address, pte_t pte)\r\n{\r\n}\r\nstatic void srmmu_destroy_context(struct mm_struct *mm)\r\n{\r\nif(mm->context != NO_CONTEXT) {\r\nflush_cache_mm(mm);\r\nsrmmu_ctxd_set(&srmmu_context_table[mm->context], srmmu_swapper_pg_dir);\r\nflush_tlb_mm(mm);\r\nspin_lock(&srmmu_context_spinlock);\r\nfree_context(mm->context);\r\nspin_unlock(&srmmu_context_spinlock);\r\nmm->context = NO_CONTEXT;\r\n}\r\n}\r\nstatic void __init srmmu_is_bad(void)\r\n{\r\nprom_printf("Could not determine SRMMU chip type.\n");\r\nprom_halt();\r\n}\r\nstatic void __init init_vac_layout(void)\r\n{\r\nphandle nd;\r\nint cache_lines;\r\nchar node_str[128];\r\n#ifdef CONFIG_SMP\r\nint cpu = 0;\r\nunsigned long max_size = 0;\r\nunsigned long min_line_size = 0x10000000;\r\n#endif\r\nnd = prom_getchild(prom_root_node);\r\nwhile((nd = prom_getsibling(nd)) != 0) {\r\nprom_getstring(nd, "device_type", node_str, sizeof(node_str));\r\nif(!strcmp(node_str, "cpu")) {\r\nvac_line_size = prom_getint(nd, "cache-line-size");\r\nif (vac_line_size == -1) {\r\nprom_printf("can't determine cache-line-size, "\r\n"halting.\n");\r\nprom_halt();\r\n}\r\ncache_lines = prom_getint(nd, "cache-nlines");\r\nif (cache_lines == -1) {\r\nprom_printf("can't determine cache-nlines, halting.\n");\r\nprom_halt();\r\n}\r\nvac_cache_size = cache_lines * vac_line_size;\r\n#ifdef CONFIG_SMP\r\nif(vac_cache_size > max_size)\r\nmax_size = vac_cache_size;\r\nif(vac_line_size < min_line_size)\r\nmin_line_size = vac_line_size;\r\ncpu++;\r\nif (cpu >= nr_cpu_ids || !cpu_online(cpu))\r\nbreak;\r\n#else\r\nbreak;\r\n#endif\r\n}\r\n}\r\nif(nd == 0) {\r\nprom_printf("No CPU nodes found, halting.\n");\r\nprom_halt();\r\n}\r\n#ifdef CONFIG_SMP\r\nvac_cache_size = max_size;\r\nvac_line_size = min_line_size;\r\n#endif\r\nprintk("SRMMU: Using VAC size of %d bytes, line size %d bytes.\n",\r\n(int)vac_cache_size, (int)vac_line_size);\r\n}\r\nstatic void __cpuinit poke_hypersparc(void)\r\n{\r\nvolatile unsigned long clear;\r\nunsigned long mreg = srmmu_get_mmureg();\r\nhyper_flush_unconditional_combined();\r\nmreg &= ~(HYPERSPARC_CWENABLE);\r\nmreg |= (HYPERSPARC_CENABLE | HYPERSPARC_WBENABLE);\r\nmreg |= (HYPERSPARC_CMODE);\r\nsrmmu_set_mmureg(mreg);\r\n#if 0\r\nhyper_clear_all_tags();\r\n#endif\r\nput_ross_icr(HYPERSPARC_ICCR_FTD | HYPERSPARC_ICCR_ICE);\r\nhyper_flush_whole_icache();\r\nclear = srmmu_get_faddr();\r\nclear = srmmu_get_fstatus();\r\n}\r\nstatic void __init init_hypersparc(void)\r\n{\r\nsrmmu_name = "ROSS HyperSparc";\r\nsrmmu_modtype = HyperSparc;\r\ninit_vac_layout();\r\nis_hypersparc = 1;\r\nBTFIXUPSET_CALL(pte_clear, srmmu_pte_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_clear, srmmu_pmd_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_clear, srmmu_pgd_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_all, hypersparc_flush_cache_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, hypersparc_flush_cache_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, hypersparc_flush_cache_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, hypersparc_flush_cache_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_all, hypersparc_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, hypersparc_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, hypersparc_flush_tlb_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, hypersparc_flush_tlb_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__flush_page_to_ram, hypersparc_flush_page_to_ram, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_sig_insns, hypersparc_flush_sig_insns, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_page_for_dma, hypersparc_flush_page_for_dma, BTFIXUPCALL_NOP);\r\npoke_srmmu = poke_hypersparc;\r\nhypersparc_setup_blockops();\r\n}\r\nstatic void __cpuinit poke_cypress(void)\r\n{\r\nunsigned long mreg = srmmu_get_mmureg();\r\nunsigned long faddr, tagval;\r\nvolatile unsigned long cypress_sucks;\r\nvolatile unsigned long clear;\r\nclear = srmmu_get_faddr();\r\nclear = srmmu_get_fstatus();\r\nif (!(mreg & CYPRESS_CENABLE)) {\r\nfor(faddr = 0x0; faddr < 0x10000; faddr += 20) {\r\n__asm__ __volatile__("sta %%g0, [%0 + %1] %2\n\t"\r\n"sta %%g0, [%0] %2\n\t" : :\r\n"r" (faddr), "r" (0x40000),\r\n"i" (ASI_M_DATAC_TAG));\r\n}\r\n} else {\r\nfor(faddr = 0; faddr < 0x10000; faddr += 0x20) {\r\n__asm__ __volatile__("lda [%1 + %2] %3, %0\n\t" :\r\n"=r" (tagval) :\r\n"r" (faddr), "r" (0x40000),\r\n"i" (ASI_M_DATAC_TAG));\r\nif((tagval & 0x60) == 0x60)\r\ncypress_sucks = *(unsigned long *)\r\n(0xf0020000 + faddr);\r\n}\r\n}\r\nclear = srmmu_get_faddr();\r\nclear = srmmu_get_fstatus();\r\nmreg |= (CYPRESS_CENABLE | CYPRESS_CMODE);\r\nsrmmu_set_mmureg(mreg);\r\n}\r\nstatic void __init init_cypress_common(void)\r\n{\r\ninit_vac_layout();\r\nBTFIXUPSET_CALL(pte_clear, srmmu_pte_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_clear, srmmu_pmd_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_clear, srmmu_pgd_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_all, cypress_flush_cache_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, cypress_flush_cache_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, cypress_flush_cache_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, cypress_flush_cache_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_all, cypress_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, cypress_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, cypress_flush_tlb_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, cypress_flush_tlb_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__flush_page_to_ram, cypress_flush_page_to_ram, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_sig_insns, cypress_flush_sig_insns, BTFIXUPCALL_NOP);\r\nBTFIXUPSET_CALL(flush_page_for_dma, cypress_flush_page_for_dma, BTFIXUPCALL_NOP);\r\npoke_srmmu = poke_cypress;\r\n}\r\nstatic void __init init_cypress_604(void)\r\n{\r\nsrmmu_name = "ROSS Cypress-604(UP)";\r\nsrmmu_modtype = Cypress;\r\ninit_cypress_common();\r\n}\r\nstatic void __init init_cypress_605(unsigned long mrev)\r\n{\r\nsrmmu_name = "ROSS Cypress-605(MP)";\r\nif(mrev == 0xe) {\r\nsrmmu_modtype = Cypress_vE;\r\nhwbug_bitmask |= HWBUG_COPYBACK_BROKEN;\r\n} else {\r\nif(mrev == 0xd) {\r\nsrmmu_modtype = Cypress_vD;\r\nhwbug_bitmask |= HWBUG_ASIFLUSH_BROKEN;\r\n} else {\r\nsrmmu_modtype = Cypress;\r\n}\r\n}\r\ninit_cypress_common();\r\n}\r\nstatic void __cpuinit poke_swift(void)\r\n{\r\nunsigned long mreg;\r\nswift_flush_cache_all();\r\nmreg = srmmu_get_mmureg();\r\nmreg |= (SWIFT_IE | SWIFT_DE);\r\nmreg &= ~(SWIFT_BF);\r\nsrmmu_set_mmureg(mreg);\r\n}\r\nstatic void __init init_swift(void)\r\n{\r\nunsigned long swift_rev;\r\n__asm__ __volatile__("lda [%1] %2, %0\n\t"\r\n"srl %0, 0x18, %0\n\t" :\r\n"=r" (swift_rev) :\r\n"r" (SWIFT_MASKID_ADDR), "i" (ASI_M_BYPASS));\r\nsrmmu_name = "Fujitsu Swift";\r\nswitch(swift_rev) {\r\ncase 0x11:\r\ncase 0x20:\r\ncase 0x23:\r\ncase 0x30:\r\nsrmmu_modtype = Swift_lots_o_bugs;\r\nhwbug_bitmask |= (HWBUG_KERN_ACCBROKEN | HWBUG_KERN_CBITBROKEN);\r\nbreak;\r\ncase 0x25:\r\ncase 0x31:\r\nsrmmu_modtype = Swift_bad_c;\r\nhwbug_bitmask |= HWBUG_KERN_CBITBROKEN;\r\nbreak;\r\ndefault:\r\nsrmmu_modtype = Swift_ok;\r\nbreak;\r\n}\r\nBTFIXUPSET_CALL(flush_cache_all, swift_flush_cache_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, swift_flush_cache_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, swift_flush_cache_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, swift_flush_cache_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_all, swift_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, swift_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, swift_flush_tlb_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, swift_flush_tlb_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__flush_page_to_ram, swift_flush_page_to_ram, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_sig_insns, swift_flush_sig_insns, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_page_for_dma, swift_flush_page_for_dma, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(update_mmu_cache, swift_update_mmu_cache, BTFIXUPCALL_NORM);\r\nflush_page_for_dma_global = 0;\r\npoke_srmmu = poke_swift;\r\n}\r\nstatic void turbosparc_flush_cache_all(void)\r\n{\r\nflush_user_windows();\r\nturbosparc_idflash_clear();\r\n}\r\nstatic void turbosparc_flush_cache_mm(struct mm_struct *mm)\r\n{\r\nFLUSH_BEGIN(mm)\r\nflush_user_windows();\r\nturbosparc_idflash_clear();\r\nFLUSH_END\r\n}\r\nstatic void turbosparc_flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)\r\n{\r\nFLUSH_BEGIN(vma->vm_mm)\r\nflush_user_windows();\r\nturbosparc_idflash_clear();\r\nFLUSH_END\r\n}\r\nstatic void turbosparc_flush_cache_page(struct vm_area_struct *vma, unsigned long page)\r\n{\r\nFLUSH_BEGIN(vma->vm_mm)\r\nflush_user_windows();\r\nif (vma->vm_flags & VM_EXEC)\r\nturbosparc_flush_icache();\r\nturbosparc_flush_dcache();\r\nFLUSH_END\r\n}\r\nstatic void turbosparc_flush_page_to_ram(unsigned long page)\r\n{\r\n#ifdef TURBOSPARC_WRITEBACK\r\nvolatile unsigned long clear;\r\nif (srmmu_hwprobe(page))\r\nturbosparc_flush_page_cache(page);\r\nclear = srmmu_get_fstatus();\r\n#endif\r\n}\r\nstatic void turbosparc_flush_sig_insns(struct mm_struct *mm, unsigned long insn_addr)\r\n{\r\n}\r\nstatic void turbosparc_flush_page_for_dma(unsigned long page)\r\n{\r\nturbosparc_flush_dcache();\r\n}\r\nstatic void turbosparc_flush_tlb_all(void)\r\n{\r\nsrmmu_flush_whole_tlb();\r\n}\r\nstatic void turbosparc_flush_tlb_mm(struct mm_struct *mm)\r\n{\r\nFLUSH_BEGIN(mm)\r\nsrmmu_flush_whole_tlb();\r\nFLUSH_END\r\n}\r\nstatic void turbosparc_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)\r\n{\r\nFLUSH_BEGIN(vma->vm_mm)\r\nsrmmu_flush_whole_tlb();\r\nFLUSH_END\r\n}\r\nstatic void turbosparc_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)\r\n{\r\nFLUSH_BEGIN(vma->vm_mm)\r\nsrmmu_flush_whole_tlb();\r\nFLUSH_END\r\n}\r\nstatic void __cpuinit poke_turbosparc(void)\r\n{\r\nunsigned long mreg = srmmu_get_mmureg();\r\nunsigned long ccreg;\r\nturbosparc_flush_cache_all();\r\nmreg &= ~(TURBOSPARC_ICENABLE | TURBOSPARC_DCENABLE);\r\nmreg &= ~(TURBOSPARC_PCENABLE);\r\nsrmmu_set_mmureg(mreg);\r\nccreg = turbosparc_get_ccreg();\r\n#ifdef TURBOSPARC_WRITEBACK\r\nccreg |= (TURBOSPARC_SNENABLE);\r\nccreg &= ~(TURBOSPARC_uS2 | TURBOSPARC_WTENABLE);\r\n#else\r\nccreg |= (TURBOSPARC_SNENABLE | TURBOSPARC_WTENABLE);\r\nccreg &= ~(TURBOSPARC_uS2);\r\n#endif\r\nswitch (ccreg & 7) {\r\ncase 0:\r\ncase 7:\r\nbreak;\r\ndefault:\r\nccreg |= (TURBOSPARC_SCENABLE);\r\n}\r\nturbosparc_set_ccreg (ccreg);\r\nmreg |= (TURBOSPARC_ICENABLE | TURBOSPARC_DCENABLE);\r\nmreg |= (TURBOSPARC_ICSNOOP);\r\nsrmmu_set_mmureg(mreg);\r\n}\r\nstatic void __init init_turbosparc(void)\r\n{\r\nsrmmu_name = "Fujitsu TurboSparc";\r\nsrmmu_modtype = TurboSparc;\r\nBTFIXUPSET_CALL(flush_cache_all, turbosparc_flush_cache_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, turbosparc_flush_cache_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, turbosparc_flush_cache_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, turbosparc_flush_cache_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_all, turbosparc_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, turbosparc_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, turbosparc_flush_tlb_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, turbosparc_flush_tlb_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__flush_page_to_ram, turbosparc_flush_page_to_ram, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_sig_insns, turbosparc_flush_sig_insns, BTFIXUPCALL_NOP);\r\nBTFIXUPSET_CALL(flush_page_for_dma, turbosparc_flush_page_for_dma, BTFIXUPCALL_NORM);\r\npoke_srmmu = poke_turbosparc;\r\n}\r\nstatic void __cpuinit poke_tsunami(void)\r\n{\r\nunsigned long mreg = srmmu_get_mmureg();\r\ntsunami_flush_icache();\r\ntsunami_flush_dcache();\r\nmreg &= ~TSUNAMI_ITD;\r\nmreg |= (TSUNAMI_IENAB | TSUNAMI_DENAB);\r\nsrmmu_set_mmureg(mreg);\r\n}\r\nstatic void __init init_tsunami(void)\r\n{\r\nsrmmu_name = "TI Tsunami";\r\nsrmmu_modtype = Tsunami;\r\nBTFIXUPSET_CALL(flush_cache_all, tsunami_flush_cache_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, tsunami_flush_cache_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, tsunami_flush_cache_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, tsunami_flush_cache_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_all, tsunami_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, tsunami_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, tsunami_flush_tlb_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, tsunami_flush_tlb_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__flush_page_to_ram, tsunami_flush_page_to_ram, BTFIXUPCALL_NOP);\r\nBTFIXUPSET_CALL(flush_sig_insns, tsunami_flush_sig_insns, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_page_for_dma, tsunami_flush_page_for_dma, BTFIXUPCALL_NORM);\r\npoke_srmmu = poke_tsunami;\r\ntsunami_setup_blockops();\r\n}\r\nstatic void __cpuinit poke_viking(void)\r\n{\r\nunsigned long mreg = srmmu_get_mmureg();\r\nstatic int smp_catch;\r\nif(viking_mxcc_present) {\r\nunsigned long mxcc_control = mxcc_get_creg();\r\nmxcc_control |= (MXCC_CTL_ECE | MXCC_CTL_PRE | MXCC_CTL_MCE);\r\nmxcc_control &= ~(MXCC_CTL_RRC);\r\nmxcc_set_creg(mxcc_control);\r\nmreg |= VIKING_TCENABLE;\r\n} else {\r\nunsigned long bpreg;\r\nmreg &= ~(VIKING_TCENABLE);\r\nif(smp_catch++) {\r\nbpreg = viking_get_bpreg();\r\nbpreg &= ~(VIKING_ACTION_MIX);\r\nviking_set_bpreg(bpreg);\r\nmsi_set_sync();\r\n}\r\n}\r\nmreg |= VIKING_SPENABLE;\r\nmreg |= (VIKING_ICENABLE | VIKING_DCENABLE);\r\nmreg |= VIKING_SBENABLE;\r\nmreg &= ~(VIKING_ACENABLE);\r\nsrmmu_set_mmureg(mreg);\r\n}\r\nstatic void __init init_viking(void)\r\n{\r\nunsigned long mreg = srmmu_get_mmureg();\r\nif(mreg & VIKING_MMODE) {\r\nsrmmu_name = "TI Viking";\r\nviking_mxcc_present = 0;\r\nmsi_set_sync();\r\nBTFIXUPSET_CALL(pte_clear, srmmu_pte_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_clear, srmmu_pmd_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_clear, srmmu_pgd_clear, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_page_for_dma, viking_flush_page, BTFIXUPCALL_NORM);\r\nflush_page_for_dma_global = 0;\r\n} else {\r\nsrmmu_name = "TI Viking/MXCC";\r\nviking_mxcc_present = 1;\r\nsrmmu_cache_pagetables = 1;\r\nBTFIXUPSET_CALL(flush_page_for_dma, viking_flush_page_for_dma, BTFIXUPCALL_NOP);\r\n}\r\nBTFIXUPSET_CALL(flush_cache_all, viking_flush_cache_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, viking_flush_cache_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, viking_flush_cache_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, viking_flush_cache_range, BTFIXUPCALL_NORM);\r\n#ifdef CONFIG_SMP\r\nif (sparc_cpu_model == sun4d) {\r\nBTFIXUPSET_CALL(flush_tlb_all, sun4dsmp_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, sun4dsmp_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, sun4dsmp_flush_tlb_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, sun4dsmp_flush_tlb_range, BTFIXUPCALL_NORM);\r\n} else\r\n#endif\r\n{\r\nBTFIXUPSET_CALL(flush_tlb_all, viking_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, viking_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, viking_flush_tlb_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, viking_flush_tlb_range, BTFIXUPCALL_NORM);\r\n}\r\nBTFIXUPSET_CALL(__flush_page_to_ram, viking_flush_page_to_ram, BTFIXUPCALL_NOP);\r\nBTFIXUPSET_CALL(flush_sig_insns, viking_flush_sig_insns, BTFIXUPCALL_NOP);\r\npoke_srmmu = poke_viking;\r\n}\r\nvoid __init poke_leonsparc(void)\r\n{\r\n}\r\nvoid __init init_leon(void)\r\n{\r\nsrmmu_name = "LEON";\r\nBTFIXUPSET_CALL(flush_cache_all, leon_flush_cache_all,\r\nBTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, leon_flush_cache_all,\r\nBTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, leon_flush_pcache_all,\r\nBTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, leon_flush_cache_all,\r\nBTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_page_for_dma, leon_flush_dcache_all,\r\nBTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_all, leon_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, leon_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, leon_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, leon_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__flush_page_to_ram, leon_flush_cache_all,\r\nBTFIXUPCALL_NOP);\r\nBTFIXUPSET_CALL(flush_sig_insns, leon_flush_cache_all, BTFIXUPCALL_NOP);\r\npoke_srmmu = poke_leonsparc;\r\nsrmmu_cache_pagetables = 0;\r\nleon_flush_during_switch = leon_flush_needed();\r\n}\r\nstatic void __init get_srmmu_type(void)\r\n{\r\nunsigned long mreg, psr;\r\nunsigned long mod_typ, mod_rev, psr_typ, psr_vers;\r\nsrmmu_modtype = SRMMU_INVAL_MOD;\r\nhwbug_bitmask = 0;\r\nmreg = srmmu_get_mmureg(); psr = get_psr();\r\nmod_typ = (mreg & 0xf0000000) >> 28;\r\nmod_rev = (mreg & 0x0f000000) >> 24;\r\npsr_typ = (psr >> 28) & 0xf;\r\npsr_vers = (psr >> 24) & 0xf;\r\nif (sparc_cpu_model == sparc_leon) {\r\ninit_leon();\r\nreturn;\r\n}\r\nif(mod_typ == 1) {\r\nswitch(mod_rev) {\r\ncase 7:\r\ninit_hypersparc();\r\nbreak;\r\ncase 0:\r\ncase 2:\r\ninit_cypress_604();\r\nbreak;\r\ncase 10:\r\ncase 11:\r\ncase 12:\r\ncase 13:\r\ncase 14:\r\ncase 15:\r\ninit_cypress_605(mod_rev);\r\nbreak;\r\ndefault:\r\ninit_cypress_605(mod_rev);\r\nbreak;\r\n}\r\nreturn;\r\n}\r\nif (psr_typ == 0 && psr_vers == 5) {\r\ninit_turbosparc();\r\nreturn;\r\n}\r\nif(psr_typ == 0 && psr_vers == 4) {\r\nphandle cpunode;\r\nchar node_str[128];\r\ncpunode = prom_getchild(prom_root_node);\r\nwhile((cpunode = prom_getsibling(cpunode)) != 0) {\r\nprom_getstring(cpunode, "device_type", node_str, sizeof(node_str));\r\nif(!strcmp(node_str, "cpu")) {\r\nif (!prom_getintdefault(cpunode, "psr-implementation", 1) &&\r\nprom_getintdefault(cpunode, "psr-version", 1) == 5) {\r\ninit_turbosparc();\r\nreturn;\r\n}\r\nbreak;\r\n}\r\n}\r\ninit_swift();\r\nreturn;\r\n}\r\nif(psr_typ == 4 &&\r\n((psr_vers == 0) ||\r\n((psr_vers == 1) && (mod_typ == 0) && (mod_rev == 0)))) {\r\ninit_viking();\r\nreturn;\r\n}\r\nif(psr_typ == 4 && psr_vers == 1 && (mod_typ || mod_rev)) {\r\ninit_tsunami();\r\nreturn;\r\n}\r\nsrmmu_is_bad();\r\n}\r\nstatic void srmmu_check_pgt_cache(int low, int high)\r\n{\r\n}\r\nstatic void __init patch_window_trap_handlers(void)\r\n{\r\nunsigned long *iaddr, *daddr;\r\nPATCH_BRANCH(spwin_mmu_patchme, spwin_srmmu_stackchk);\r\nPATCH_BRANCH(fwin_mmu_patchme, srmmu_fwin_stackchk);\r\nPATCH_BRANCH(tsetup_mmu_patchme, tsetup_srmmu_stackchk);\r\nPATCH_BRANCH(rtrap_mmu_patchme, srmmu_rett_stackchk);\r\nPATCH_BRANCH(sparc_ttable[SP_TRAP_TFLT].inst_three, srmmu_fault);\r\nPATCH_BRANCH(sparc_ttable[SP_TRAP_DFLT].inst_three, srmmu_fault);\r\nPATCH_BRANCH(sparc_ttable[SP_TRAP_DACC].inst_three, srmmu_fault);\r\n}\r\nstatic void smp_flush_page_for_dma(unsigned long page)\r\n{\r\nxc1((smpfunc_t) BTFIXUP_CALL(local_flush_page_for_dma), page);\r\nlocal_flush_page_for_dma(page);\r\n}\r\nstatic pte_t srmmu_pgoff_to_pte(unsigned long pgoff)\r\n{\r\nreturn __pte((pgoff << SRMMU_PTE_FILE_SHIFT) | SRMMU_FILE);\r\n}\r\nstatic unsigned long srmmu_pte_to_pgoff(pte_t pte)\r\n{\r\nreturn pte_val(pte) >> SRMMU_PTE_FILE_SHIFT;\r\n}\r\nstatic pgprot_t srmmu_pgprot_noncached(pgprot_t prot)\r\n{\r\nprot &= ~__pgprot(SRMMU_CACHE);\r\nreturn prot;\r\n}\r\nvoid __init ld_mmu_srmmu(void)\r\n{\r\nextern void ld_mmu_iommu(void);\r\nextern void ld_mmu_iounit(void);\r\nextern void ___xchg32_sun4md(void);\r\nBTFIXUPSET_SIMM13(pgdir_shift, SRMMU_PGDIR_SHIFT);\r\nBTFIXUPSET_SETHI(pgdir_size, SRMMU_PGDIR_SIZE);\r\nBTFIXUPSET_SETHI(pgdir_mask, SRMMU_PGDIR_MASK);\r\nBTFIXUPSET_SIMM13(ptrs_per_pmd, SRMMU_PTRS_PER_PMD);\r\nBTFIXUPSET_SIMM13(ptrs_per_pgd, SRMMU_PTRS_PER_PGD);\r\nBTFIXUPSET_INT(page_none, pgprot_val(SRMMU_PAGE_NONE));\r\nPAGE_SHARED = pgprot_val(SRMMU_PAGE_SHARED);\r\nBTFIXUPSET_INT(page_copy, pgprot_val(SRMMU_PAGE_COPY));\r\nBTFIXUPSET_INT(page_readonly, pgprot_val(SRMMU_PAGE_RDONLY));\r\nBTFIXUPSET_INT(page_kernel, pgprot_val(SRMMU_PAGE_KERNEL));\r\npage_kernel = pgprot_val(SRMMU_PAGE_KERNEL);\r\nBTFIXUPSET_CALL(pgprot_noncached, srmmu_pgprot_noncached, BTFIXUPCALL_NORM);\r\n#ifndef CONFIG_SMP\r\nBTFIXUPSET_CALL(___xchg32, ___xchg32_sun4md, BTFIXUPCALL_SWAPG1G2);\r\n#endif\r\nBTFIXUPSET_CALL(do_check_pgt_cache, srmmu_check_pgt_cache, BTFIXUPCALL_NOP);\r\nBTFIXUPSET_CALL(set_pte, srmmu_set_pte, BTFIXUPCALL_SWAPO0O1);\r\nBTFIXUPSET_CALL(switch_mm, srmmu_switch_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_pfn, srmmu_pte_pfn, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_page, srmmu_pmd_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_page_vaddr, srmmu_pgd_page, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_present, srmmu_pte_present, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_clear, srmmu_pte_clear, BTFIXUPCALL_SWAPO0G0);\r\nBTFIXUPSET_CALL(pmd_bad, srmmu_pmd_bad, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_present, srmmu_pmd_present, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_clear, srmmu_pmd_clear, BTFIXUPCALL_SWAPO0G0);\r\nBTFIXUPSET_CALL(pgd_none, srmmu_pgd_none, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_bad, srmmu_pgd_bad, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_present, srmmu_pgd_present, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_clear, srmmu_pgd_clear, BTFIXUPCALL_SWAPO0G0);\r\nBTFIXUPSET_CALL(mk_pte, srmmu_mk_pte, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(mk_pte_phys, srmmu_mk_pte_phys, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(mk_pte_io, srmmu_mk_pte_io, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgd_set, srmmu_pgd_set, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_set, srmmu_pmd_set, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_populate, srmmu_pmd_populate, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_INT(pte_modify_mask, SRMMU_CHG_MASK);\r\nBTFIXUPSET_CALL(pmd_offset, srmmu_pmd_offset, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_offset_kernel, srmmu_pte_offset, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(free_pte_fast, srmmu_free_pte_fast, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_free, srmmu_pte_free, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_alloc_one_kernel, srmmu_pte_alloc_one_kernel, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_alloc_one, srmmu_pte_alloc_one, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(free_pmd_fast, srmmu_pmd_free, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pmd_alloc_one, srmmu_pmd_alloc_one, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(free_pgd_fast, srmmu_free_pgd_fast, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(get_pgd_fast, srmmu_get_pgd_fast, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_HALF(pte_writei, SRMMU_WRITE);\r\nBTFIXUPSET_HALF(pte_dirtyi, SRMMU_DIRTY);\r\nBTFIXUPSET_HALF(pte_youngi, SRMMU_REF);\r\nBTFIXUPSET_HALF(pte_filei, SRMMU_FILE);\r\nBTFIXUPSET_HALF(pte_wrprotecti, SRMMU_WRITE);\r\nBTFIXUPSET_HALF(pte_mkcleani, SRMMU_DIRTY);\r\nBTFIXUPSET_HALF(pte_mkoldi, SRMMU_REF);\r\nBTFIXUPSET_CALL(pte_mkwrite, srmmu_pte_mkwrite, BTFIXUPCALL_ORINT(SRMMU_WRITE));\r\nBTFIXUPSET_CALL(pte_mkdirty, srmmu_pte_mkdirty, BTFIXUPCALL_ORINT(SRMMU_DIRTY));\r\nBTFIXUPSET_CALL(pte_mkyoung, srmmu_pte_mkyoung, BTFIXUPCALL_ORINT(SRMMU_REF));\r\nBTFIXUPSET_CALL(update_mmu_cache, srmmu_update_mmu_cache, BTFIXUPCALL_NOP);\r\nBTFIXUPSET_CALL(destroy_context, srmmu_destroy_context, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(sparc_mapiorange, srmmu_mapiorange, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(sparc_unmapiorange, srmmu_unmapiorange, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__swp_type, srmmu_swp_type, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__swp_offset, srmmu_swp_offset, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(__swp_entry, srmmu_swp_entry, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(mmu_info, srmmu_mmu_info, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(alloc_thread_info_node, srmmu_alloc_thread_info_node, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(free_thread_info, srmmu_free_thread_info, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pte_to_pgoff, srmmu_pte_to_pgoff, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(pgoff_to_pte, srmmu_pgoff_to_pte, BTFIXUPCALL_NORM);\r\nget_srmmu_type();\r\npatch_window_trap_handlers();\r\n#ifdef CONFIG_SMP\r\nBTFIXUPCOPY_CALL(local_flush_cache_all, flush_cache_all);\r\nBTFIXUPCOPY_CALL(local_flush_cache_mm, flush_cache_mm);\r\nBTFIXUPCOPY_CALL(local_flush_cache_range, flush_cache_range);\r\nBTFIXUPCOPY_CALL(local_flush_cache_page, flush_cache_page);\r\nBTFIXUPCOPY_CALL(local_flush_tlb_all, flush_tlb_all);\r\nBTFIXUPCOPY_CALL(local_flush_tlb_mm, flush_tlb_mm);\r\nBTFIXUPCOPY_CALL(local_flush_tlb_range, flush_tlb_range);\r\nBTFIXUPCOPY_CALL(local_flush_tlb_page, flush_tlb_page);\r\nBTFIXUPCOPY_CALL(local_flush_page_to_ram, __flush_page_to_ram);\r\nBTFIXUPCOPY_CALL(local_flush_sig_insns, flush_sig_insns);\r\nBTFIXUPCOPY_CALL(local_flush_page_for_dma, flush_page_for_dma);\r\nBTFIXUPSET_CALL(flush_cache_all, smp_flush_cache_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_mm, smp_flush_cache_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_range, smp_flush_cache_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_cache_page, smp_flush_cache_page, BTFIXUPCALL_NORM);\r\nif (sparc_cpu_model != sun4d &&\r\nsparc_cpu_model != sparc_leon) {\r\nBTFIXUPSET_CALL(flush_tlb_all, smp_flush_tlb_all, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_mm, smp_flush_tlb_mm, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_range, smp_flush_tlb_range, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_tlb_page, smp_flush_tlb_page, BTFIXUPCALL_NORM);\r\n}\r\nBTFIXUPSET_CALL(__flush_page_to_ram, smp_flush_page_to_ram, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_sig_insns, smp_flush_sig_insns, BTFIXUPCALL_NORM);\r\nBTFIXUPSET_CALL(flush_page_for_dma, smp_flush_page_for_dma, BTFIXUPCALL_NORM);\r\nif (poke_srmmu == poke_viking) {\r\nBTFIXUPCOPY_CALL(flush_cache_all, local_flush_cache_all);\r\nBTFIXUPCOPY_CALL(flush_cache_mm, local_flush_cache_mm);\r\nBTFIXUPCOPY_CALL(flush_cache_range, local_flush_cache_range);\r\nBTFIXUPCOPY_CALL(flush_cache_page, local_flush_cache_page);\r\nBTFIXUPCOPY_CALL(__flush_page_to_ram, local_flush_page_to_ram);\r\nBTFIXUPCOPY_CALL(flush_sig_insns, local_flush_sig_insns);\r\nBTFIXUPCOPY_CALL(flush_page_for_dma, local_flush_page_for_dma);\r\n}\r\n#endif\r\nif (sparc_cpu_model == sun4d)\r\nld_mmu_iounit();\r\nelse\r\nld_mmu_iommu();\r\n#ifdef CONFIG_SMP\r\nif (sparc_cpu_model == sun4d)\r\nsun4d_init_smp();\r\nelse if (sparc_cpu_model == sparc_leon)\r\nleon_init_smp();\r\nelse\r\nsun4m_init_smp();\r\n#endif\r\n}
