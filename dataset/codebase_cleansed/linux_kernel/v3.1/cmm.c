void *cmm_calloc_buf(struct cmm_object *hcmm_mgr, u32 usize,\r\nstruct cmm_attrs *pattrs, void **pp_buf_va)\r\n{\r\nstruct cmm_object *cmm_mgr_obj = (struct cmm_object *)hcmm_mgr;\r\nvoid *buf_pa = NULL;\r\nstruct cmm_mnode *pnode = NULL;\r\nstruct cmm_mnode *new_node = NULL;\r\nstruct cmm_allocator *allocator = NULL;\r\nu32 delta_size;\r\nu8 *pbyte = NULL;\r\ns32 cnt;\r\nif (pattrs == NULL)\r\npattrs = &cmm_dfltalctattrs;\r\nif (pp_buf_va != NULL)\r\n*pp_buf_va = NULL;\r\nif (cmm_mgr_obj && (usize != 0)) {\r\nif (pattrs->seg_id > 0) {\r\nallocator =\r\nget_allocator(cmm_mgr_obj, pattrs->seg_id);\r\nusize =\r\n((usize - 1) & ~(cmm_mgr_obj->min_block_size -\r\n1))\r\n+ cmm_mgr_obj->min_block_size;\r\nmutex_lock(&cmm_mgr_obj->cmm_lock);\r\npnode = get_free_block(allocator, usize);\r\n}\r\nif (pnode) {\r\ndelta_size = (pnode->size - usize);\r\nif (delta_size >= cmm_mgr_obj->min_block_size) {\r\nnew_node =\r\nget_node(cmm_mgr_obj, pnode->pa + usize,\r\npnode->va + usize,\r\n(u32) delta_size);\r\nadd_to_free_list(allocator, new_node);\r\npnode->size = usize;\r\n}\r\npnode->client_proc = current->tgid;\r\nlist_add_tail(&pnode->link, &allocator->in_use_list);\r\nbuf_pa = (void *)pnode->pa;\r\npbyte = (u8 *) pnode->va;\r\nfor (cnt = 0; cnt < (s32) usize; cnt++, pbyte++)\r\n*pbyte = 0;\r\nif (pp_buf_va != NULL) {\r\n*pp_buf_va = (void *)pnode->va;\r\n}\r\n}\r\nmutex_unlock(&cmm_mgr_obj->cmm_lock);\r\n}\r\nreturn buf_pa;\r\n}\r\nint cmm_create(struct cmm_object **ph_cmm_mgr,\r\nstruct dev_object *hdev_obj,\r\nconst struct cmm_mgrattrs *mgr_attrts)\r\n{\r\nstruct cmm_object *cmm_obj = NULL;\r\nint status = 0;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(ph_cmm_mgr != NULL);\r\n*ph_cmm_mgr = NULL;\r\ncmm_obj = kzalloc(sizeof(struct cmm_object), GFP_KERNEL);\r\nif (!cmm_obj)\r\nreturn -ENOMEM;\r\nif (mgr_attrts == NULL)\r\nmgr_attrts = &cmm_dfltmgrattrs;\r\nDBC_ASSERT(mgr_attrts->min_block_size >= 4);\r\ncmm_obj->min_block_size = mgr_attrts->min_block_size;\r\ncmm_obj->page_size = PAGE_SIZE;\r\nINIT_LIST_HEAD(&cmm_obj->node_free_list);\r\nmutex_init(&cmm_obj->cmm_lock);\r\n*ph_cmm_mgr = cmm_obj;\r\nreturn status;\r\n}\r\nint cmm_destroy(struct cmm_object *hcmm_mgr, bool force)\r\n{\r\nstruct cmm_object *cmm_mgr_obj = (struct cmm_object *)hcmm_mgr;\r\nstruct cmm_info temp_info;\r\nint status = 0;\r\ns32 slot_seg;\r\nstruct cmm_mnode *node, *tmp;\r\nDBC_REQUIRE(refs > 0);\r\nif (!hcmm_mgr) {\r\nstatus = -EFAULT;\r\nreturn status;\r\n}\r\nmutex_lock(&cmm_mgr_obj->cmm_lock);\r\nif (!force) {\r\nstatus = cmm_get_info(hcmm_mgr, &temp_info);\r\nif (!status) {\r\nif (temp_info.total_in_use_cnt > 0) {\r\nstatus = -EPERM;\r\n}\r\n}\r\n}\r\nif (!status) {\r\nfor (slot_seg = 0; slot_seg < CMM_MAXGPPSEGS; slot_seg++) {\r\nif (cmm_mgr_obj->pa_gppsm_seg_tab[slot_seg] != NULL) {\r\nun_register_gppsm_seg\r\n(cmm_mgr_obj->pa_gppsm_seg_tab[slot_seg]);\r\ncmm_mgr_obj->pa_gppsm_seg_tab[slot_seg] = NULL;\r\n}\r\n}\r\n}\r\nlist_for_each_entry_safe(node, tmp, &cmm_mgr_obj->node_free_list,\r\nlink) {\r\nlist_del(&node->link);\r\nkfree(node);\r\n}\r\nmutex_unlock(&cmm_mgr_obj->cmm_lock);\r\nif (!status) {\r\nmutex_destroy(&cmm_mgr_obj->cmm_lock);\r\nkfree(cmm_mgr_obj);\r\n}\r\nreturn status;\r\n}\r\nvoid cmm_exit(void)\r\n{\r\nDBC_REQUIRE(refs > 0);\r\nrefs--;\r\n}\r\nint cmm_free_buf(struct cmm_object *hcmm_mgr, void *buf_pa, u32 ul_seg_id)\r\n{\r\nstruct cmm_object *cmm_mgr_obj = (struct cmm_object *)hcmm_mgr;\r\nint status = -EFAULT;\r\nstruct cmm_mnode *curr, *tmp;\r\nstruct cmm_allocator *allocator;\r\nstruct cmm_attrs *pattrs;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(buf_pa != NULL);\r\nif (ul_seg_id == 0) {\r\npattrs = &cmm_dfltalctattrs;\r\nul_seg_id = pattrs->seg_id;\r\n}\r\nif (!hcmm_mgr || !(ul_seg_id > 0)) {\r\nstatus = -EFAULT;\r\nreturn status;\r\n}\r\nallocator = get_allocator(cmm_mgr_obj, ul_seg_id);\r\nif (!allocator)\r\nreturn status;\r\nmutex_lock(&cmm_mgr_obj->cmm_lock);\r\nlist_for_each_entry_safe(curr, tmp, &allocator->in_use_list, link) {\r\nif (curr->pa == (u32) buf_pa) {\r\nlist_del(&curr->link);\r\nadd_to_free_list(allocator, curr);\r\nstatus = 0;\r\nbreak;\r\n}\r\n}\r\nmutex_unlock(&cmm_mgr_obj->cmm_lock);\r\nreturn status;\r\n}\r\nint cmm_get_handle(void *hprocessor, struct cmm_object ** ph_cmm_mgr)\r\n{\r\nint status = 0;\r\nstruct dev_object *hdev_obj;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(ph_cmm_mgr != NULL);\r\nif (hprocessor != NULL)\r\nstatus = proc_get_dev_object(hprocessor, &hdev_obj);\r\nelse\r\nhdev_obj = dev_get_first();\r\nif (!status)\r\nstatus = dev_get_cmm_mgr(hdev_obj, ph_cmm_mgr);\r\nreturn status;\r\n}\r\nint cmm_get_info(struct cmm_object *hcmm_mgr,\r\nstruct cmm_info *cmm_info_obj)\r\n{\r\nstruct cmm_object *cmm_mgr_obj = (struct cmm_object *)hcmm_mgr;\r\nu32 ul_seg;\r\nint status = 0;\r\nstruct cmm_allocator *altr;\r\nstruct cmm_mnode *curr;\r\nDBC_REQUIRE(cmm_info_obj != NULL);\r\nif (!hcmm_mgr) {\r\nstatus = -EFAULT;\r\nreturn status;\r\n}\r\nmutex_lock(&cmm_mgr_obj->cmm_lock);\r\ncmm_info_obj->num_gppsm_segs = 0;\r\ncmm_info_obj->total_in_use_cnt = 0;\r\ncmm_info_obj->min_block_size = cmm_mgr_obj->min_block_size;\r\nfor (ul_seg = 1; ul_seg <= CMM_MAXGPPSEGS; ul_seg++) {\r\naltr = get_allocator(cmm_mgr_obj, ul_seg);\r\nif (!altr)\r\ncontinue;\r\ncmm_info_obj->num_gppsm_segs++;\r\ncmm_info_obj->seg_info[ul_seg - 1].seg_base_pa =\r\naltr->shm_base - altr->dsp_size;\r\ncmm_info_obj->seg_info[ul_seg - 1].total_seg_size =\r\naltr->dsp_size + altr->sm_size;\r\ncmm_info_obj->seg_info[ul_seg - 1].gpp_base_pa =\r\naltr->shm_base;\r\ncmm_info_obj->seg_info[ul_seg - 1].gpp_size =\r\naltr->sm_size;\r\ncmm_info_obj->seg_info[ul_seg - 1].dsp_base_va =\r\naltr->dsp_base;\r\ncmm_info_obj->seg_info[ul_seg - 1].dsp_size =\r\naltr->dsp_size;\r\ncmm_info_obj->seg_info[ul_seg - 1].seg_base_va =\r\naltr->vm_base - altr->dsp_size;\r\ncmm_info_obj->seg_info[ul_seg - 1].in_use_cnt = 0;\r\nlist_for_each_entry(curr, &altr->in_use_list, link) {\r\ncmm_info_obj->total_in_use_cnt++;\r\ncmm_info_obj->seg_info[ul_seg - 1].in_use_cnt++;\r\n}\r\n}\r\nmutex_unlock(&cmm_mgr_obj->cmm_lock);\r\nreturn status;\r\n}\r\nbool cmm_init(void)\r\n{\r\nbool ret = true;\r\nDBC_REQUIRE(refs >= 0);\r\nif (ret)\r\nrefs++;\r\nDBC_ENSURE((ret && (refs > 0)) || (!ret && (refs >= 0)));\r\nreturn ret;\r\n}\r\nint cmm_register_gppsm_seg(struct cmm_object *hcmm_mgr,\r\nu32 dw_gpp_base_pa, u32 ul_size,\r\nu32 dsp_addr_offset, s8 c_factor,\r\nu32 dw_dsp_base, u32 ul_dsp_size,\r\nu32 *sgmt_id, u32 gpp_base_va)\r\n{\r\nstruct cmm_object *cmm_mgr_obj = (struct cmm_object *)hcmm_mgr;\r\nstruct cmm_allocator *psma = NULL;\r\nint status = 0;\r\nstruct cmm_mnode *new_node;\r\ns32 slot_seg;\r\nDBC_REQUIRE(ul_size > 0);\r\nDBC_REQUIRE(sgmt_id != NULL);\r\nDBC_REQUIRE(dw_gpp_base_pa != 0);\r\nDBC_REQUIRE(gpp_base_va != 0);\r\nDBC_REQUIRE((c_factor <= CMM_ADDTODSPPA) &&\r\n(c_factor >= CMM_SUBFROMDSPPA));\r\ndev_dbg(bridge, "%s: dw_gpp_base_pa %x ul_size %x dsp_addr_offset %x "\r\n"dw_dsp_base %x ul_dsp_size %x gpp_base_va %x\n",\r\n__func__, dw_gpp_base_pa, ul_size, dsp_addr_offset,\r\ndw_dsp_base, ul_dsp_size, gpp_base_va);\r\nif (!hcmm_mgr)\r\nreturn -EFAULT;\r\nmutex_lock(&cmm_mgr_obj->cmm_lock);\r\nslot_seg = get_slot(cmm_mgr_obj);\r\nif (slot_seg < 0) {\r\nstatus = -EPERM;\r\ngoto func_end;\r\n}\r\nif (ul_size < cmm_mgr_obj->min_block_size) {\r\nstatus = -EINVAL;\r\ngoto func_end;\r\n}\r\npsma = kzalloc(sizeof(struct cmm_allocator), GFP_KERNEL);\r\nif (!psma) {\r\nstatus = -ENOMEM;\r\ngoto func_end;\r\n}\r\npsma->cmm_mgr = hcmm_mgr;\r\npsma->shm_base = dw_gpp_base_pa;\r\npsma->sm_size = ul_size;\r\npsma->vm_base = gpp_base_va;\r\npsma->dsp_phys_addr_offset = dsp_addr_offset;\r\npsma->c_factor = c_factor;\r\npsma->dsp_base = dw_dsp_base;\r\npsma->dsp_size = ul_dsp_size;\r\nif (psma->vm_base == 0) {\r\nstatus = -EPERM;\r\ngoto func_end;\r\n}\r\n*sgmt_id = (u32) slot_seg + 1;\r\nINIT_LIST_HEAD(&psma->free_list);\r\nINIT_LIST_HEAD(&psma->in_use_list);\r\nnew_node = get_node(cmm_mgr_obj, dw_gpp_base_pa,\r\npsma->vm_base, ul_size);\r\nif (new_node) {\r\nlist_add_tail(&new_node->link, &psma->free_list);\r\n} else {\r\nstatus = -ENOMEM;\r\ngoto func_end;\r\n}\r\ncmm_mgr_obj->pa_gppsm_seg_tab[slot_seg] = psma;\r\nfunc_end:\r\nif (status && psma)\r\nun_register_gppsm_seg(psma);\r\nmutex_unlock(&cmm_mgr_obj->cmm_lock);\r\nreturn status;\r\n}\r\nint cmm_un_register_gppsm_seg(struct cmm_object *hcmm_mgr,\r\nu32 ul_seg_id)\r\n{\r\nstruct cmm_object *cmm_mgr_obj = (struct cmm_object *)hcmm_mgr;\r\nint status = 0;\r\nstruct cmm_allocator *psma;\r\nu32 ul_id = ul_seg_id;\r\nDBC_REQUIRE(ul_seg_id > 0);\r\nif (!hcmm_mgr)\r\nreturn -EFAULT;\r\nif (ul_seg_id == CMM_ALLSEGMENTS)\r\nul_id = 1;\r\nif ((ul_id <= 0) || (ul_id > CMM_MAXGPPSEGS))\r\nreturn -EINVAL;\r\nwhile (ul_id <= CMM_MAXGPPSEGS) {\r\nmutex_lock(&cmm_mgr_obj->cmm_lock);\r\npsma = cmm_mgr_obj->pa_gppsm_seg_tab[ul_id - 1];\r\nif (psma != NULL) {\r\nun_register_gppsm_seg(psma);\r\ncmm_mgr_obj->pa_gppsm_seg_tab[ul_id - 1] = NULL;\r\n} else if (ul_seg_id != CMM_ALLSEGMENTS) {\r\nstatus = -EPERM;\r\n}\r\nmutex_unlock(&cmm_mgr_obj->cmm_lock);\r\nif (ul_seg_id != CMM_ALLSEGMENTS)\r\nbreak;\r\nul_id++;\r\n}\r\nreturn status;\r\n}\r\nstatic void un_register_gppsm_seg(struct cmm_allocator *psma)\r\n{\r\nstruct cmm_mnode *curr, *tmp;\r\nDBC_REQUIRE(psma != NULL);\r\nlist_for_each_entry_safe(curr, tmp, &psma->free_list, link) {\r\nlist_del(&curr->link);\r\nkfree(curr);\r\n}\r\nlist_for_each_entry_safe(curr, tmp, &psma->in_use_list, link) {\r\nlist_del(&curr->link);\r\nkfree(curr);\r\n}\r\nif ((void *)psma->vm_base != NULL)\r\nMEM_UNMAP_LINEAR_ADDRESS((void *)psma->vm_base);\r\nkfree(psma);\r\n}\r\nstatic s32 get_slot(struct cmm_object *cmm_mgr_obj)\r\n{\r\ns32 slot_seg = -1;\r\nDBC_REQUIRE(cmm_mgr_obj != NULL);\r\nfor (slot_seg = 0; slot_seg < CMM_MAXGPPSEGS; slot_seg++) {\r\nif (cmm_mgr_obj->pa_gppsm_seg_tab[slot_seg] == NULL)\r\nbreak;\r\n}\r\nif (slot_seg == CMM_MAXGPPSEGS)\r\nslot_seg = -1;\r\nreturn slot_seg;\r\n}\r\nstatic struct cmm_mnode *get_node(struct cmm_object *cmm_mgr_obj, u32 dw_pa,\r\nu32 dw_va, u32 ul_size)\r\n{\r\nstruct cmm_mnode *pnode;\r\nDBC_REQUIRE(cmm_mgr_obj != NULL);\r\nDBC_REQUIRE(dw_pa != 0);\r\nDBC_REQUIRE(dw_va != 0);\r\nDBC_REQUIRE(ul_size != 0);\r\nif (list_empty(&cmm_mgr_obj->node_free_list)) {\r\npnode = kzalloc(sizeof(struct cmm_mnode), GFP_KERNEL);\r\nif (!pnode)\r\nreturn NULL;\r\n} else {\r\npnode = list_first_entry(&cmm_mgr_obj->node_free_list,\r\nstruct cmm_mnode, link);\r\nlist_del_init(&pnode->link);\r\n}\r\npnode->pa = dw_pa;\r\npnode->va = dw_va;\r\npnode->size = ul_size;\r\nreturn pnode;\r\n}\r\nstatic void delete_node(struct cmm_object *cmm_mgr_obj, struct cmm_mnode *pnode)\r\n{\r\nDBC_REQUIRE(pnode != NULL);\r\nlist_add_tail(&pnode->link, &cmm_mgr_obj->node_free_list);\r\n}\r\nstatic struct cmm_mnode *get_free_block(struct cmm_allocator *allocator,\r\nu32 usize)\r\n{\r\nstruct cmm_mnode *node, *tmp;\r\nif (!allocator)\r\nreturn NULL;\r\nlist_for_each_entry_safe(node, tmp, &allocator->free_list, link) {\r\nif (usize <= node->size) {\r\nlist_del(&node->link);\r\nreturn node;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic void add_to_free_list(struct cmm_allocator *allocator,\r\nstruct cmm_mnode *node)\r\n{\r\nstruct cmm_mnode *curr;\r\nif (!node) {\r\npr_err("%s: failed - node is NULL\n", __func__);\r\nreturn;\r\n}\r\nlist_for_each_entry(curr, &allocator->free_list, link) {\r\nif (NEXT_PA(curr) == node->pa) {\r\ncurr->size += node->size;\r\ndelete_node(allocator->cmm_mgr, node);\r\nreturn;\r\n}\r\nif (curr->pa == NEXT_PA(node)) {\r\ncurr->pa = node->pa;\r\ncurr->va = node->va;\r\ncurr->size += node->size;\r\ndelete_node(allocator->cmm_mgr, node);\r\nreturn;\r\n}\r\n}\r\nlist_for_each_entry(curr, &allocator->free_list, link) {\r\nif (curr->size >= node->size) {\r\nlist_add_tail(&node->link, &curr->link);\r\nreturn;\r\n}\r\n}\r\nlist_add_tail(&node->link, &allocator->free_list);\r\n}\r\nstatic struct cmm_allocator *get_allocator(struct cmm_object *cmm_mgr_obj,\r\nu32 ul_seg_id)\r\n{\r\nDBC_REQUIRE(cmm_mgr_obj != NULL);\r\nDBC_REQUIRE((ul_seg_id > 0) && (ul_seg_id <= CMM_MAXGPPSEGS));\r\nreturn cmm_mgr_obj->pa_gppsm_seg_tab[ul_seg_id - 1];\r\n}\r\nint cmm_xlator_create(struct cmm_xlatorobject **xlator,\r\nstruct cmm_object *hcmm_mgr,\r\nstruct cmm_xlatorattrs *xlator_attrs)\r\n{\r\nstruct cmm_xlator *xlator_object = NULL;\r\nint status = 0;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(xlator != NULL);\r\nDBC_REQUIRE(hcmm_mgr != NULL);\r\n*xlator = NULL;\r\nif (xlator_attrs == NULL)\r\nxlator_attrs = &cmm_dfltxlatorattrs;\r\nxlator_object = kzalloc(sizeof(struct cmm_xlator), GFP_KERNEL);\r\nif (xlator_object != NULL) {\r\nxlator_object->cmm_mgr = hcmm_mgr;\r\nxlator_object->seg_id = xlator_attrs->seg_id;\r\n} else {\r\nstatus = -ENOMEM;\r\n}\r\nif (!status)\r\n*xlator = (struct cmm_xlatorobject *)xlator_object;\r\nreturn status;\r\n}\r\nvoid *cmm_xlator_alloc_buf(struct cmm_xlatorobject *xlator, void *va_buf,\r\nu32 pa_size)\r\n{\r\nstruct cmm_xlator *xlator_obj = (struct cmm_xlator *)xlator;\r\nvoid *pbuf = NULL;\r\nvoid *tmp_va_buff;\r\nstruct cmm_attrs attrs;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(xlator != NULL);\r\nDBC_REQUIRE(xlator_obj->cmm_mgr != NULL);\r\nDBC_REQUIRE(va_buf != NULL);\r\nDBC_REQUIRE(pa_size > 0);\r\nDBC_REQUIRE(xlator_obj->seg_id > 0);\r\nif (xlator_obj) {\r\nattrs.seg_id = xlator_obj->seg_id;\r\n__raw_writel(0, va_buf);\r\npbuf =\r\ncmm_calloc_buf(xlator_obj->cmm_mgr, pa_size, &attrs, NULL);\r\nif (pbuf) {\r\ntmp_va_buff = cmm_xlator_translate(xlator,\r\npbuf, CMM_PA2VA);\r\n__raw_writel((u32)tmp_va_buff, va_buf);\r\n}\r\n}\r\nreturn pbuf;\r\n}\r\nint cmm_xlator_free_buf(struct cmm_xlatorobject *xlator, void *buf_va)\r\n{\r\nstruct cmm_xlator *xlator_obj = (struct cmm_xlator *)xlator;\r\nint status = -EPERM;\r\nvoid *buf_pa = NULL;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(buf_va != NULL);\r\nDBC_REQUIRE(xlator_obj->seg_id > 0);\r\nif (xlator_obj) {\r\nbuf_pa = cmm_xlator_translate(xlator, buf_va, CMM_VA2PA);\r\nif (buf_pa) {\r\nstatus = cmm_free_buf(xlator_obj->cmm_mgr, buf_pa,\r\nxlator_obj->seg_id);\r\nif (status) {\r\nDBC_ASSERT(false);\r\n}\r\n}\r\n}\r\nreturn status;\r\n}\r\nint cmm_xlator_info(struct cmm_xlatorobject *xlator, u8 ** paddr,\r\nu32 ul_size, u32 segm_id, bool set_info)\r\n{\r\nstruct cmm_xlator *xlator_obj = (struct cmm_xlator *)xlator;\r\nint status = 0;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(paddr != NULL);\r\nDBC_REQUIRE((segm_id > 0) && (segm_id <= CMM_MAXGPPSEGS));\r\nif (xlator_obj) {\r\nif (set_info) {\r\nxlator_obj->virt_base = (u32) *paddr;\r\nxlator_obj->virt_size = ul_size;\r\n} else {\r\n*paddr = (u8 *) xlator_obj->virt_base;\r\n}\r\n} else {\r\nstatus = -EFAULT;\r\n}\r\nreturn status;\r\n}\r\nvoid *cmm_xlator_translate(struct cmm_xlatorobject *xlator, void *paddr,\r\nenum cmm_xlatetype xtype)\r\n{\r\nu32 dw_addr_xlate = 0;\r\nstruct cmm_xlator *xlator_obj = (struct cmm_xlator *)xlator;\r\nstruct cmm_object *cmm_mgr_obj = NULL;\r\nstruct cmm_allocator *allocator = NULL;\r\nu32 dw_offset = 0;\r\nDBC_REQUIRE(refs > 0);\r\nDBC_REQUIRE(paddr != NULL);\r\nDBC_REQUIRE((xtype >= CMM_VA2PA) && (xtype <= CMM_DSPPA2PA));\r\nif (!xlator_obj)\r\ngoto loop_cont;\r\ncmm_mgr_obj = (struct cmm_object *)xlator_obj->cmm_mgr;\r\nDBC_ASSERT(xlator_obj->seg_id > 0);\r\nallocator = cmm_mgr_obj->pa_gppsm_seg_tab[xlator_obj->seg_id - 1];\r\nif (!allocator)\r\ngoto loop_cont;\r\nif ((xtype == CMM_VA2DSPPA) || (xtype == CMM_VA2PA) ||\r\n(xtype == CMM_PA2VA)) {\r\nif (xtype == CMM_PA2VA) {\r\ndw_offset = (u8 *) paddr - (u8 *) (allocator->shm_base -\r\nallocator->\r\ndsp_size);\r\ndw_addr_xlate = xlator_obj->virt_base + dw_offset;\r\nif ((dw_addr_xlate < xlator_obj->virt_base) ||\r\n(dw_addr_xlate >=\r\n(xlator_obj->virt_base +\r\nxlator_obj->virt_size))) {\r\ndw_addr_xlate = 0;\r\n}\r\n} else {\r\ndw_offset =\r\n(u8 *) paddr - (u8 *) xlator_obj->virt_base;\r\ndw_addr_xlate =\r\nallocator->shm_base - allocator->dsp_size +\r\ndw_offset;\r\n}\r\n} else {\r\ndw_addr_xlate = (u32) paddr;\r\n}\r\nif ((xtype == CMM_VA2DSPPA) || (xtype == CMM_PA2DSPPA)) {\r\ndw_addr_xlate =\r\nGPPPA2DSPPA((allocator->shm_base - allocator->dsp_size),\r\ndw_addr_xlate,\r\nallocator->dsp_phys_addr_offset *\r\nallocator->c_factor);\r\n} else if (xtype == CMM_DSPPA2PA) {\r\ndw_addr_xlate =\r\nDSPPA2GPPPA(allocator->shm_base - allocator->dsp_size,\r\ndw_addr_xlate,\r\nallocator->dsp_phys_addr_offset *\r\nallocator->c_factor);\r\n}\r\nloop_cont:\r\nreturn (void *)dw_addr_xlate;\r\n}
