int qib_alloc_lkey(struct qib_lkey_table *rkt, struct qib_mregion *mr)\r\n{\r\nunsigned long flags;\r\nu32 r;\r\nu32 n;\r\nint ret;\r\nspin_lock_irqsave(&rkt->lock, flags);\r\nr = rkt->next;\r\nn = r;\r\nfor (;;) {\r\nif (rkt->table[r] == NULL)\r\nbreak;\r\nr = (r + 1) & (rkt->max - 1);\r\nif (r == n) {\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\nret = 0;\r\ngoto bail;\r\n}\r\n}\r\nrkt->next = (r + 1) & (rkt->max - 1);\r\nrkt->gen++;\r\nmr->lkey = (r << (32 - ib_qib_lkey_table_size)) |\r\n((((1 << (24 - ib_qib_lkey_table_size)) - 1) & rkt->gen)\r\n<< 8);\r\nif (mr->lkey == 0) {\r\nmr->lkey |= 1 << 8;\r\nrkt->gen++;\r\n}\r\nrkt->table[r] = mr;\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\nret = 1;\r\nbail:\r\nreturn ret;\r\n}\r\nint qib_free_lkey(struct qib_ibdev *dev, struct qib_mregion *mr)\r\n{\r\nunsigned long flags;\r\nu32 lkey = mr->lkey;\r\nu32 r;\r\nint ret;\r\nspin_lock_irqsave(&dev->lk_table.lock, flags);\r\nif (lkey == 0) {\r\nif (dev->dma_mr && dev->dma_mr == mr) {\r\nret = atomic_read(&dev->dma_mr->refcount);\r\nif (!ret)\r\ndev->dma_mr = NULL;\r\n} else\r\nret = 0;\r\n} else {\r\nr = lkey >> (32 - ib_qib_lkey_table_size);\r\nret = atomic_read(&dev->lk_table.table[r]->refcount);\r\nif (!ret)\r\ndev->lk_table.table[r] = NULL;\r\n}\r\nspin_unlock_irqrestore(&dev->lk_table.lock, flags);\r\nif (ret)\r\nret = -EBUSY;\r\nreturn ret;\r\n}\r\nint qib_lkey_ok(struct qib_lkey_table *rkt, struct qib_pd *pd,\r\nstruct qib_sge *isge, struct ib_sge *sge, int acc)\r\n{\r\nstruct qib_mregion *mr;\r\nunsigned n, m;\r\nsize_t off;\r\nunsigned long flags;\r\nspin_lock_irqsave(&rkt->lock, flags);\r\nif (sge->lkey == 0) {\r\nstruct qib_ibdev *dev = to_idev(pd->ibpd.device);\r\nif (pd->user)\r\ngoto bail;\r\nif (!dev->dma_mr)\r\ngoto bail;\r\natomic_inc(&dev->dma_mr->refcount);\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\nisge->mr = dev->dma_mr;\r\nisge->vaddr = (void *) sge->addr;\r\nisge->length = sge->length;\r\nisge->sge_length = sge->length;\r\nisge->m = 0;\r\nisge->n = 0;\r\ngoto ok;\r\n}\r\nmr = rkt->table[(sge->lkey >> (32 - ib_qib_lkey_table_size))];\r\nif (unlikely(mr == NULL || mr->lkey != sge->lkey ||\r\nmr->pd != &pd->ibpd))\r\ngoto bail;\r\noff = sge->addr - mr->user_base;\r\nif (unlikely(sge->addr < mr->user_base ||\r\noff + sge->length > mr->length ||\r\n(mr->access_flags & acc) != acc))\r\ngoto bail;\r\natomic_inc(&mr->refcount);\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\noff += mr->offset;\r\nif (mr->page_shift) {\r\nsize_t entries_spanned_by_off;\r\nentries_spanned_by_off = off >> mr->page_shift;\r\noff -= (entries_spanned_by_off << mr->page_shift);\r\nm = entries_spanned_by_off/QIB_SEGSZ;\r\nn = entries_spanned_by_off%QIB_SEGSZ;\r\n} else {\r\nm = 0;\r\nn = 0;\r\nwhile (off >= mr->map[m]->segs[n].length) {\r\noff -= mr->map[m]->segs[n].length;\r\nn++;\r\nif (n >= QIB_SEGSZ) {\r\nm++;\r\nn = 0;\r\n}\r\n}\r\n}\r\nisge->mr = mr;\r\nisge->vaddr = mr->map[m]->segs[n].vaddr + off;\r\nisge->length = mr->map[m]->segs[n].length - off;\r\nisge->sge_length = sge->length;\r\nisge->m = m;\r\nisge->n = n;\r\nok:\r\nreturn 1;\r\nbail:\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\nreturn 0;\r\n}\r\nint qib_rkey_ok(struct qib_qp *qp, struct qib_sge *sge,\r\nu32 len, u64 vaddr, u32 rkey, int acc)\r\n{\r\nstruct qib_lkey_table *rkt = &to_idev(qp->ibqp.device)->lk_table;\r\nstruct qib_mregion *mr;\r\nunsigned n, m;\r\nsize_t off;\r\nunsigned long flags;\r\nspin_lock_irqsave(&rkt->lock, flags);\r\nif (rkey == 0) {\r\nstruct qib_pd *pd = to_ipd(qp->ibqp.pd);\r\nstruct qib_ibdev *dev = to_idev(pd->ibpd.device);\r\nif (pd->user)\r\ngoto bail;\r\nif (!dev->dma_mr)\r\ngoto bail;\r\natomic_inc(&dev->dma_mr->refcount);\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\nsge->mr = dev->dma_mr;\r\nsge->vaddr = (void *) vaddr;\r\nsge->length = len;\r\nsge->sge_length = len;\r\nsge->m = 0;\r\nsge->n = 0;\r\ngoto ok;\r\n}\r\nmr = rkt->table[(rkey >> (32 - ib_qib_lkey_table_size))];\r\nif (unlikely(mr == NULL || mr->lkey != rkey || qp->ibqp.pd != mr->pd))\r\ngoto bail;\r\noff = vaddr - mr->iova;\r\nif (unlikely(vaddr < mr->iova || off + len > mr->length ||\r\n(mr->access_flags & acc) == 0))\r\ngoto bail;\r\natomic_inc(&mr->refcount);\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\noff += mr->offset;\r\nif (mr->page_shift) {\r\nsize_t entries_spanned_by_off;\r\nentries_spanned_by_off = off >> mr->page_shift;\r\noff -= (entries_spanned_by_off << mr->page_shift);\r\nm = entries_spanned_by_off/QIB_SEGSZ;\r\nn = entries_spanned_by_off%QIB_SEGSZ;\r\n} else {\r\nm = 0;\r\nn = 0;\r\nwhile (off >= mr->map[m]->segs[n].length) {\r\noff -= mr->map[m]->segs[n].length;\r\nn++;\r\nif (n >= QIB_SEGSZ) {\r\nm++;\r\nn = 0;\r\n}\r\n}\r\n}\r\nsge->mr = mr;\r\nsge->vaddr = mr->map[m]->segs[n].vaddr + off;\r\nsge->length = mr->map[m]->segs[n].length - off;\r\nsge->sge_length = len;\r\nsge->m = m;\r\nsge->n = n;\r\nok:\r\nreturn 1;\r\nbail:\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\nreturn 0;\r\n}\r\nint qib_fast_reg_mr(struct qib_qp *qp, struct ib_send_wr *wr)\r\n{\r\nstruct qib_lkey_table *rkt = &to_idev(qp->ibqp.device)->lk_table;\r\nstruct qib_pd *pd = to_ipd(qp->ibqp.pd);\r\nstruct qib_mregion *mr;\r\nu32 rkey = wr->wr.fast_reg.rkey;\r\nunsigned i, n, m;\r\nint ret = -EINVAL;\r\nunsigned long flags;\r\nu64 *page_list;\r\nsize_t ps;\r\nspin_lock_irqsave(&rkt->lock, flags);\r\nif (pd->user || rkey == 0)\r\ngoto bail;\r\nmr = rkt->table[(rkey >> (32 - ib_qib_lkey_table_size))];\r\nif (unlikely(mr == NULL || qp->ibqp.pd != mr->pd))\r\ngoto bail;\r\nif (wr->wr.fast_reg.page_list_len > mr->max_segs)\r\ngoto bail;\r\nps = 1UL << wr->wr.fast_reg.page_shift;\r\nif (wr->wr.fast_reg.length > ps * wr->wr.fast_reg.page_list_len)\r\ngoto bail;\r\nmr->user_base = wr->wr.fast_reg.iova_start;\r\nmr->iova = wr->wr.fast_reg.iova_start;\r\nmr->lkey = rkey;\r\nmr->length = wr->wr.fast_reg.length;\r\nmr->access_flags = wr->wr.fast_reg.access_flags;\r\npage_list = wr->wr.fast_reg.page_list->page_list;\r\nm = 0;\r\nn = 0;\r\nfor (i = 0; i < wr->wr.fast_reg.page_list_len; i++) {\r\nmr->map[m]->segs[n].vaddr = (void *) page_list[i];\r\nmr->map[m]->segs[n].length = ps;\r\nif (++n == QIB_SEGSZ) {\r\nm++;\r\nn = 0;\r\n}\r\n}\r\nret = 0;\r\nbail:\r\nspin_unlock_irqrestore(&rkt->lock, flags);\r\nreturn ret;\r\n}
