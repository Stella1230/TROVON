static inline struct imx21 *hcd_to_imx21(struct usb_hcd *hcd)\r\n{\r\nreturn (struct imx21 *)hcd->hcd_priv;\r\n}\r\nstatic inline void set_register_bits(struct imx21 *imx21, u32 offset, u32 mask)\r\n{\r\nvoid __iomem *reg = imx21->regs + offset;\r\nwritel(readl(reg) | mask, reg);\r\n}\r\nstatic inline void clear_register_bits(struct imx21 *imx21,\r\nu32 offset, u32 mask)\r\n{\r\nvoid __iomem *reg = imx21->regs + offset;\r\nwritel(readl(reg) & ~mask, reg);\r\n}\r\nstatic inline void clear_toggle_bit(struct imx21 *imx21, u32 offset, u32 mask)\r\n{\r\nvoid __iomem *reg = imx21->regs + offset;\r\nif (readl(reg) & mask)\r\nwritel(mask, reg);\r\n}\r\nstatic inline void set_toggle_bit(struct imx21 *imx21, u32 offset, u32 mask)\r\n{\r\nvoid __iomem *reg = imx21->regs + offset;\r\nif (!(readl(reg) & mask))\r\nwritel(mask, reg);\r\n}\r\nstatic void etd_writel(struct imx21 *imx21, int etd_num, int dword, u32 value)\r\n{\r\nwritel(value, imx21->regs + USB_ETD_DWORD(etd_num, dword));\r\n}\r\nstatic u32 etd_readl(struct imx21 *imx21, int etd_num, int dword)\r\n{\r\nreturn readl(imx21->regs + USB_ETD_DWORD(etd_num, dword));\r\n}\r\nstatic inline int wrap_frame(int counter)\r\n{\r\nreturn counter & 0xFFFF;\r\n}\r\nstatic inline int frame_after(int frame, int after)\r\n{\r\nreturn (s16)((s16)after - (s16)frame) < 0;\r\n}\r\nstatic int imx21_hc_get_frame(struct usb_hcd *hcd)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nreturn wrap_frame(readl(imx21->regs + USBH_FRMNUB));\r\n}\r\nstatic inline bool unsuitable_for_dma(dma_addr_t addr)\r\n{\r\nreturn (addr & 3) != 0;\r\n}\r\nstatic int alloc_etd(struct imx21 *imx21)\r\n{\r\nint i;\r\nstruct etd_priv *etd = imx21->etd;\r\nfor (i = 0; i < USB_NUM_ETD; i++, etd++) {\r\nif (etd->alloc == 0) {\r\nmemset(etd, 0, sizeof(imx21->etd[0]));\r\netd->alloc = 1;\r\ndebug_etd_allocated(imx21);\r\nreturn i;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nstatic void disactivate_etd(struct imx21 *imx21, int num)\r\n{\r\nint etd_mask = (1 << num);\r\nstruct etd_priv *etd = &imx21->etd[num];\r\nwritel(etd_mask, imx21->regs + USBH_ETDENCLR);\r\nclear_register_bits(imx21, USBH_ETDDONEEN, etd_mask);\r\nwritel(etd_mask, imx21->regs + USB_ETDDMACHANLCLR);\r\nclear_toggle_bit(imx21, USBH_ETDDONESTAT, etd_mask);\r\netd->active_count = 0;\r\nDEBUG_LOG_FRAME(imx21, etd, disactivated);\r\n}\r\nstatic void reset_etd(struct imx21 *imx21, int num)\r\n{\r\nstruct etd_priv *etd = imx21->etd + num;\r\nint i;\r\ndisactivate_etd(imx21, num);\r\nfor (i = 0; i < 4; i++)\r\netd_writel(imx21, num, i, 0);\r\netd->urb = NULL;\r\netd->ep = NULL;\r\netd->td = NULL;\r\netd->bounce_buffer = NULL;\r\n}\r\nstatic void free_etd(struct imx21 *imx21, int num)\r\n{\r\nif (num < 0)\r\nreturn;\r\nif (num >= USB_NUM_ETD) {\r\ndev_err(imx21->dev, "BAD etd=%d!\n", num);\r\nreturn;\r\n}\r\nif (imx21->etd[num].alloc == 0) {\r\ndev_err(imx21->dev, "ETD %d already free!\n", num);\r\nreturn;\r\n}\r\ndebug_etd_freed(imx21);\r\nreset_etd(imx21, num);\r\nmemset(&imx21->etd[num], 0, sizeof(imx21->etd[0]));\r\n}\r\nstatic void setup_etd_dword0(struct imx21 *imx21,\r\nint etd_num, struct urb *urb, u8 dir, u16 maxpacket)\r\n{\r\netd_writel(imx21, etd_num, 0,\r\n((u32) usb_pipedevice(urb->pipe)) << DW0_ADDRESS |\r\n((u32) usb_pipeendpoint(urb->pipe) << DW0_ENDPNT) |\r\n((u32) dir << DW0_DIRECT) |\r\n((u32) ((urb->dev->speed == USB_SPEED_LOW) ?\r\n1 : 0) << DW0_SPEED) |\r\n((u32) fmt_urb_to_etd[usb_pipetype(urb->pipe)] << DW0_FORMAT) |\r\n((u32) maxpacket << DW0_MAXPKTSIZ));\r\n}\r\nstatic void copy_to_dmem(\r\nstruct imx21 *imx21, int dmem_offset, void *src, int count)\r\n{\r\nvoid __iomem *dmem = imx21->regs + USBOTG_DMEM + dmem_offset;\r\nu32 word = 0;\r\nu8 *p = src;\r\nint byte = 0;\r\nint i;\r\nfor (i = 0; i < count; i++) {\r\nbyte = i % 4;\r\nword += (*p++ << (byte * 8));\r\nif (byte == 3) {\r\nwritel(word, dmem);\r\ndmem += 4;\r\nword = 0;\r\n}\r\n}\r\nif (count && byte != 3)\r\nwritel(word, dmem);\r\n}\r\nstatic void activate_etd(struct imx21 *imx21, int etd_num, u8 dir)\r\n{\r\nu32 etd_mask = 1 << etd_num;\r\nstruct etd_priv *etd = &imx21->etd[etd_num];\r\nif (etd->dma_handle && unsuitable_for_dma(etd->dma_handle)) {\r\nif (etd->len <= etd->dmem_size) {\r\nif (dir != TD_DIR_IN) {\r\ncopy_to_dmem(imx21,\r\netd->dmem_offset,\r\netd->cpu_buffer, etd->len);\r\n}\r\netd->dma_handle = 0;\r\n} else {\r\nenum dma_data_direction dmadir;\r\nif (dir == TD_DIR_IN) {\r\ndmadir = DMA_FROM_DEVICE;\r\netd->bounce_buffer = kmalloc(etd->len,\r\nGFP_ATOMIC);\r\n} else {\r\ndmadir = DMA_TO_DEVICE;\r\netd->bounce_buffer = kmemdup(etd->cpu_buffer,\r\netd->len,\r\nGFP_ATOMIC);\r\n}\r\nif (!etd->bounce_buffer) {\r\ndev_err(imx21->dev, "failed bounce alloc\n");\r\ngoto err_bounce_alloc;\r\n}\r\netd->dma_handle =\r\ndma_map_single(imx21->dev,\r\netd->bounce_buffer,\r\netd->len,\r\ndmadir);\r\nif (dma_mapping_error(imx21->dev, etd->dma_handle)) {\r\ndev_err(imx21->dev, "failed bounce map\n");\r\ngoto err_bounce_map;\r\n}\r\n}\r\n}\r\nclear_toggle_bit(imx21, USBH_ETDDONESTAT, etd_mask);\r\nset_register_bits(imx21, USBH_ETDDONEEN, etd_mask);\r\nclear_toggle_bit(imx21, USBH_XFILLSTAT, etd_mask);\r\nclear_toggle_bit(imx21, USBH_YFILLSTAT, etd_mask);\r\nif (etd->dma_handle) {\r\nset_register_bits(imx21, USB_ETDDMACHANLCLR, etd_mask);\r\nclear_toggle_bit(imx21, USBH_XBUFSTAT, etd_mask);\r\nclear_toggle_bit(imx21, USBH_YBUFSTAT, etd_mask);\r\nwritel(etd->dma_handle, imx21->regs + USB_ETDSMSA(etd_num));\r\nset_register_bits(imx21, USB_ETDDMAEN, etd_mask);\r\n} else {\r\nif (dir != TD_DIR_IN) {\r\nset_toggle_bit(imx21, USBH_XFILLSTAT, etd_mask);\r\nset_toggle_bit(imx21, USBH_YFILLSTAT, etd_mask);\r\n}\r\n}\r\nDEBUG_LOG_FRAME(imx21, etd, activated);\r\n#ifdef DEBUG\r\nif (!etd->active_count) {\r\nint i;\r\netd->activated_frame = readl(imx21->regs + USBH_FRMNUB);\r\netd->disactivated_frame = -1;\r\netd->last_int_frame = -1;\r\netd->last_req_frame = -1;\r\nfor (i = 0; i < 4; i++)\r\netd->submitted_dwords[i] = etd_readl(imx21, etd_num, i);\r\n}\r\n#endif\r\netd->active_count = 1;\r\nwritel(etd_mask, imx21->regs + USBH_ETDENSET);\r\nreturn;\r\nerr_bounce_map:\r\nkfree(etd->bounce_buffer);\r\nerr_bounce_alloc:\r\nfree_dmem(imx21, etd);\r\nnonisoc_urb_completed_for_etd(imx21, etd, -ENOMEM);\r\n}\r\nstatic int alloc_dmem(struct imx21 *imx21, unsigned int size,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nunsigned int offset = 0;\r\nstruct imx21_dmem_area *area;\r\nstruct imx21_dmem_area *tmp;\r\nsize += (~size + 1) & 0x3;\r\nif (size > DMEM_SIZE) {\r\ndev_err(imx21->dev, "size=%d > DMEM_SIZE(%d)\n",\r\nsize, DMEM_SIZE);\r\nreturn -EINVAL;\r\n}\r\nlist_for_each_entry(tmp, &imx21->dmem_list, list) {\r\nif ((size + offset) < offset)\r\ngoto fail;\r\nif ((size + offset) <= tmp->offset)\r\nbreak;\r\noffset = tmp->size + tmp->offset;\r\nif ((offset + size) > DMEM_SIZE)\r\ngoto fail;\r\n}\r\narea = kmalloc(sizeof(struct imx21_dmem_area), GFP_ATOMIC);\r\nif (area == NULL)\r\nreturn -ENOMEM;\r\narea->ep = ep;\r\narea->offset = offset;\r\narea->size = size;\r\nlist_add_tail(&area->list, &tmp->list);\r\ndebug_dmem_allocated(imx21, size);\r\nreturn offset;\r\nfail:\r\nreturn -ENOMEM;\r\n}\r\nstatic void activate_queued_etd(struct imx21 *imx21,\r\nstruct etd_priv *etd, u32 dmem_offset)\r\n{\r\nstruct urb_priv *urb_priv = etd->urb->hcpriv;\r\nint etd_num = etd - &imx21->etd[0];\r\nu32 maxpacket = etd_readl(imx21, etd_num, 1) >> DW1_YBUFSRTAD;\r\nu8 dir = (etd_readl(imx21, etd_num, 2) >> DW2_DIRPID) & 0x03;\r\ndev_dbg(imx21->dev, "activating queued ETD %d now DMEM available\n",\r\netd_num);\r\netd_writel(imx21, etd_num, 1,\r\n((dmem_offset + maxpacket) << DW1_YBUFSRTAD) | dmem_offset);\r\netd->dmem_offset = dmem_offset;\r\nurb_priv->active = 1;\r\nactivate_etd(imx21, etd_num, dir);\r\n}\r\nstatic void free_dmem(struct imx21 *imx21, struct etd_priv *etd)\r\n{\r\nstruct imx21_dmem_area *area;\r\nstruct etd_priv *tmp;\r\nint found = 0;\r\nint offset;\r\nif (!etd->dmem_size)\r\nreturn;\r\netd->dmem_size = 0;\r\noffset = etd->dmem_offset;\r\nlist_for_each_entry(area, &imx21->dmem_list, list) {\r\nif (area->offset == offset) {\r\ndebug_dmem_freed(imx21, area->size);\r\nlist_del(&area->list);\r\nkfree(area);\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\ndev_err(imx21->dev,\r\n"Trying to free unallocated DMEM %d\n", offset);\r\nreturn;\r\n}\r\nlist_for_each_entry_safe(etd, tmp, &imx21->queue_for_dmem, queue) {\r\noffset = alloc_dmem(imx21, etd->dmem_size, etd->ep);\r\nif (offset >= 0) {\r\nlist_del(&etd->queue);\r\nactivate_queued_etd(imx21, etd, (u32)offset);\r\n}\r\n}\r\n}\r\nstatic void free_epdmem(struct imx21 *imx21, struct usb_host_endpoint *ep)\r\n{\r\nstruct imx21_dmem_area *area, *tmp;\r\nlist_for_each_entry_safe(area, tmp, &imx21->dmem_list, list) {\r\nif (area->ep == ep) {\r\ndev_err(imx21->dev,\r\n"Active DMEM %d for disabled ep=%p\n",\r\narea->offset, ep);\r\nlist_del(&area->list);\r\nkfree(area);\r\n}\r\n}\r\n}\r\nstatic void ep_idle(struct imx21 *imx21, struct ep_priv *ep_priv)\r\n{\r\nint i;\r\nfor (i = 0; i < NUM_ISO_ETDS; i++) {\r\nint etd_num = ep_priv->etd[i];\r\nstruct etd_priv *etd;\r\nif (etd_num < 0)\r\ncontinue;\r\netd = &imx21->etd[etd_num];\r\nep_priv->etd[i] = -1;\r\nfree_dmem(imx21, etd);\r\nif (list_empty(&imx21->queue_for_etd)) {\r\nfree_etd(imx21, etd_num);\r\ncontinue;\r\n}\r\ndev_dbg(imx21->dev,\r\n"assigning idle etd %d for queued request\n", etd_num);\r\nep_priv = list_first_entry(&imx21->queue_for_etd,\r\nstruct ep_priv, queue);\r\nlist_del(&ep_priv->queue);\r\nreset_etd(imx21, etd_num);\r\nep_priv->waiting_etd = 0;\r\nep_priv->etd[i] = etd_num;\r\nif (list_empty(&ep_priv->ep->urb_list)) {\r\ndev_err(imx21->dev, "No urb for queued ep!\n");\r\ncontinue;\r\n}\r\nschedule_nonisoc_etd(imx21, list_first_entry(\r\n&ep_priv->ep->urb_list, struct urb, urb_list));\r\n}\r\n}\r\nstatic void urb_done(struct usb_hcd *hcd, struct urb *urb, int status)\r\n__releases(imx21->lock)\r\n__acquires(imx21->lock)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nstruct ep_priv *ep_priv = urb->ep->hcpriv;\r\nstruct urb_priv *urb_priv = urb->hcpriv;\r\ndebug_urb_completed(imx21, urb, status);\r\ndev_vdbg(imx21->dev, "urb %p done %d\n", urb, status);\r\nkfree(urb_priv->isoc_td);\r\nkfree(urb->hcpriv);\r\nurb->hcpriv = NULL;\r\nusb_hcd_unlink_urb_from_ep(hcd, urb);\r\nspin_unlock(&imx21->lock);\r\nusb_hcd_giveback_urb(hcd, urb, status);\r\nspin_lock(&imx21->lock);\r\nif (list_empty(&ep_priv->ep->urb_list))\r\nep_idle(imx21, ep_priv);\r\n}\r\nstatic void nonisoc_urb_completed_for_etd(\r\nstruct imx21 *imx21, struct etd_priv *etd, int status)\r\n{\r\nstruct usb_host_endpoint *ep = etd->ep;\r\nurb_done(imx21->hcd, etd->urb, status);\r\netd->urb = NULL;\r\nif (!list_empty(&ep->urb_list)) {\r\nstruct urb *urb = list_first_entry(\r\n&ep->urb_list, struct urb, urb_list);\r\ndev_vdbg(imx21->dev, "next URB %p\n", urb);\r\nschedule_nonisoc_etd(imx21, urb);\r\n}\r\n}\r\nstatic void schedule_isoc_etds(struct usb_hcd *hcd,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nstruct ep_priv *ep_priv = ep->hcpriv;\r\nstruct etd_priv *etd;\r\nstruct urb_priv *urb_priv;\r\nstruct td *td;\r\nint etd_num;\r\nint i;\r\nint cur_frame;\r\nu8 dir;\r\nfor (i = 0; i < NUM_ISO_ETDS; i++) {\r\ntoo_late:\r\nif (list_empty(&ep_priv->td_list))\r\nbreak;\r\netd_num = ep_priv->etd[i];\r\nif (etd_num < 0)\r\nbreak;\r\netd = &imx21->etd[etd_num];\r\nif (etd->urb)\r\ncontinue;\r\ntd = list_entry(ep_priv->td_list.next, struct td, list);\r\nlist_del(&td->list);\r\nurb_priv = td->urb->hcpriv;\r\ncur_frame = imx21_hc_get_frame(hcd);\r\nif (frame_after(cur_frame, td->frame)) {\r\ndev_dbg(imx21->dev, "isoc too late frame %d > %d\n",\r\ncur_frame, td->frame);\r\nurb_priv->isoc_status = -EXDEV;\r\ntd->urb->iso_frame_desc[\r\ntd->isoc_index].actual_length = 0;\r\ntd->urb->iso_frame_desc[td->isoc_index].status = -EXDEV;\r\nif (--urb_priv->isoc_remaining == 0)\r\nurb_done(hcd, td->urb, urb_priv->isoc_status);\r\ngoto too_late;\r\n}\r\nurb_priv->active = 1;\r\netd->td = td;\r\netd->ep = td->ep;\r\netd->urb = td->urb;\r\netd->len = td->len;\r\netd->dma_handle = td->dma_handle;\r\netd->cpu_buffer = td->cpu_buffer;\r\ndebug_isoc_submitted(imx21, cur_frame, td);\r\ndir = usb_pipeout(td->urb->pipe) ? TD_DIR_OUT : TD_DIR_IN;\r\nsetup_etd_dword0(imx21, etd_num, td->urb, dir, etd->dmem_size);\r\netd_writel(imx21, etd_num, 1, etd->dmem_offset);\r\netd_writel(imx21, etd_num, 2,\r\n(TD_NOTACCESSED << DW2_COMPCODE) |\r\n((td->frame & 0xFFFF) << DW2_STARTFRM));\r\netd_writel(imx21, etd_num, 3,\r\n(TD_NOTACCESSED << DW3_COMPCODE0) |\r\n(td->len << DW3_PKTLEN0));\r\nactivate_etd(imx21, etd_num, dir);\r\n}\r\n}\r\nstatic void isoc_etd_done(struct usb_hcd *hcd, int etd_num)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nint etd_mask = 1 << etd_num;\r\nstruct etd_priv *etd = imx21->etd + etd_num;\r\nstruct urb *urb = etd->urb;\r\nstruct urb_priv *urb_priv = urb->hcpriv;\r\nstruct td *td = etd->td;\r\nstruct usb_host_endpoint *ep = etd->ep;\r\nint isoc_index = td->isoc_index;\r\nunsigned int pipe = urb->pipe;\r\nint dir_in = usb_pipein(pipe);\r\nint cc;\r\nint bytes_xfrd;\r\ndisactivate_etd(imx21, etd_num);\r\ncc = (etd_readl(imx21, etd_num, 3) >> DW3_COMPCODE0) & 0xf;\r\nbytes_xfrd = etd_readl(imx21, etd_num, 3) & 0x3ff;\r\nif (dir_in && (cc == TD_DATAUNDERRUN))\r\ncc = TD_CC_NOERROR;\r\nif (cc == TD_NOTACCESSED)\r\nbytes_xfrd = 0;\r\ndebug_isoc_completed(imx21,\r\nimx21_hc_get_frame(hcd), td, cc, bytes_xfrd);\r\nif (cc) {\r\nurb_priv->isoc_status = -EXDEV;\r\ndev_dbg(imx21->dev,\r\n"bad iso cc=0x%X frame=%d sched frame=%d "\r\n"cnt=%d len=%d urb=%p etd=%d index=%d\n",\r\ncc, imx21_hc_get_frame(hcd), td->frame,\r\nbytes_xfrd, td->len, urb, etd_num, isoc_index);\r\n}\r\nif (dir_in) {\r\nclear_toggle_bit(imx21, USBH_XFILLSTAT, etd_mask);\r\nif (!etd->dma_handle)\r\nmemcpy_fromio(etd->cpu_buffer,\r\nimx21->regs + USBOTG_DMEM + etd->dmem_offset,\r\nbytes_xfrd);\r\n}\r\nurb->actual_length += bytes_xfrd;\r\nurb->iso_frame_desc[isoc_index].actual_length = bytes_xfrd;\r\nurb->iso_frame_desc[isoc_index].status = cc_to_error[cc];\r\netd->td = NULL;\r\netd->urb = NULL;\r\netd->ep = NULL;\r\nif (--urb_priv->isoc_remaining == 0)\r\nurb_done(hcd, urb, urb_priv->isoc_status);\r\nschedule_isoc_etds(hcd, ep);\r\n}\r\nstatic struct ep_priv *alloc_isoc_ep(\r\nstruct imx21 *imx21, struct usb_host_endpoint *ep)\r\n{\r\nstruct ep_priv *ep_priv;\r\nint i;\r\nep_priv = kzalloc(sizeof(struct ep_priv), GFP_ATOMIC);\r\nif (!ep_priv)\r\nreturn NULL;\r\nfor (i = 0; i < NUM_ISO_ETDS; i++)\r\nep_priv->etd[i] = -1;\r\nINIT_LIST_HEAD(&ep_priv->td_list);\r\nep_priv->ep = ep;\r\nep->hcpriv = ep_priv;\r\nreturn ep_priv;\r\n}\r\nstatic int alloc_isoc_etds(struct imx21 *imx21, struct ep_priv *ep_priv)\r\n{\r\nint i, j;\r\nint etd_num;\r\nfor (i = 0; i < NUM_ISO_ETDS; i++) {\r\nif (ep_priv->etd[i] < 0) {\r\netd_num = alloc_etd(imx21);\r\nif (etd_num < 0)\r\ngoto alloc_etd_failed;\r\nep_priv->etd[i] = etd_num;\r\nimx21->etd[etd_num].ep = ep_priv->ep;\r\n}\r\n}\r\nreturn 0;\r\nalloc_etd_failed:\r\ndev_err(imx21->dev, "isoc: Couldn't allocate etd\n");\r\nfor (j = 0; j < i; j++) {\r\nfree_etd(imx21, ep_priv->etd[j]);\r\nep_priv->etd[j] = -1;\r\n}\r\nreturn -ENOMEM;\r\n}\r\nstatic int imx21_hc_urb_enqueue_isoc(struct usb_hcd *hcd,\r\nstruct usb_host_endpoint *ep,\r\nstruct urb *urb, gfp_t mem_flags)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nstruct urb_priv *urb_priv;\r\nunsigned long flags;\r\nstruct ep_priv *ep_priv;\r\nstruct td *td = NULL;\r\nint i;\r\nint ret;\r\nint cur_frame;\r\nu16 maxpacket;\r\nurb_priv = kzalloc(sizeof(struct urb_priv), mem_flags);\r\nif (urb_priv == NULL)\r\nreturn -ENOMEM;\r\nurb_priv->isoc_td = kzalloc(\r\nsizeof(struct td) * urb->number_of_packets, mem_flags);\r\nif (urb_priv->isoc_td == NULL) {\r\nret = -ENOMEM;\r\ngoto alloc_td_failed;\r\n}\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nif (ep->hcpriv == NULL) {\r\nep_priv = alloc_isoc_ep(imx21, ep);\r\nif (ep_priv == NULL) {\r\nret = -ENOMEM;\r\ngoto alloc_ep_failed;\r\n}\r\n} else {\r\nep_priv = ep->hcpriv;\r\n}\r\nret = alloc_isoc_etds(imx21, ep_priv);\r\nif (ret)\r\ngoto alloc_etd_failed;\r\nret = usb_hcd_link_urb_to_ep(hcd, urb);\r\nif (ret)\r\ngoto link_failed;\r\nurb->status = -EINPROGRESS;\r\nurb->actual_length = 0;\r\nurb->error_count = 0;\r\nurb->hcpriv = urb_priv;\r\nurb_priv->ep = ep;\r\nmaxpacket = usb_maxpacket(urb->dev, urb->pipe, usb_pipeout(urb->pipe));\r\nfor (i = 0; i < NUM_ISO_ETDS; i++) {\r\nstruct etd_priv *etd = &imx21->etd[ep_priv->etd[i]];\r\nif (etd->dmem_size > 0 && etd->dmem_size < maxpacket) {\r\ndev_err(imx21->dev, "increasing isoc buffer %d->%d\n",\r\netd->dmem_size, maxpacket);\r\nret = -EMSGSIZE;\r\ngoto alloc_dmem_failed;\r\n}\r\nif (etd->dmem_size == 0) {\r\netd->dmem_offset = alloc_dmem(imx21, maxpacket, ep);\r\nif (etd->dmem_offset < 0) {\r\ndev_dbg(imx21->dev, "failed alloc isoc dmem\n");\r\nret = -EAGAIN;\r\ngoto alloc_dmem_failed;\r\n}\r\netd->dmem_size = maxpacket;\r\n}\r\n}\r\ncur_frame = imx21_hc_get_frame(hcd);\r\nif (urb->transfer_flags & URB_ISO_ASAP) {\r\nif (list_empty(&ep_priv->td_list))\r\nurb->start_frame = cur_frame + 5;\r\nelse\r\nurb->start_frame = list_entry(\r\nep_priv->td_list.prev,\r\nstruct td, list)->frame + urb->interval;\r\n}\r\nurb->start_frame = wrap_frame(urb->start_frame);\r\nif (frame_after(cur_frame, urb->start_frame)) {\r\ndev_dbg(imx21->dev,\r\n"enqueue: adjusting iso start %d (cur=%d) asap=%d\n",\r\nurb->start_frame, cur_frame,\r\n(urb->transfer_flags & URB_ISO_ASAP) != 0);\r\nurb->start_frame = wrap_frame(cur_frame + 1);\r\n}\r\ntd = urb_priv->isoc_td;\r\nfor (i = 0; i < urb->number_of_packets; i++, td++) {\r\nunsigned int offset = urb->iso_frame_desc[i].offset;\r\ntd->ep = ep;\r\ntd->urb = urb;\r\ntd->len = urb->iso_frame_desc[i].length;\r\ntd->isoc_index = i;\r\ntd->frame = wrap_frame(urb->start_frame + urb->interval * i);\r\ntd->dma_handle = urb->transfer_dma + offset;\r\ntd->cpu_buffer = urb->transfer_buffer + offset;\r\nlist_add_tail(&td->list, &ep_priv->td_list);\r\n}\r\nurb_priv->isoc_remaining = urb->number_of_packets;\r\ndev_vdbg(imx21->dev, "setup %d packets for iso frame %d->%d\n",\r\nurb->number_of_packets, urb->start_frame, td->frame);\r\ndebug_urb_submitted(imx21, urb);\r\nschedule_isoc_etds(hcd, ep);\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nreturn 0;\r\nalloc_dmem_failed:\r\nusb_hcd_unlink_urb_from_ep(hcd, urb);\r\nlink_failed:\r\nalloc_etd_failed:\r\nalloc_ep_failed:\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nkfree(urb_priv->isoc_td);\r\nalloc_td_failed:\r\nkfree(urb_priv);\r\nreturn ret;\r\n}\r\nstatic void dequeue_isoc_urb(struct imx21 *imx21,\r\nstruct urb *urb, struct ep_priv *ep_priv)\r\n{\r\nstruct urb_priv *urb_priv = urb->hcpriv;\r\nstruct td *td, *tmp;\r\nint i;\r\nif (urb_priv->active) {\r\nfor (i = 0; i < NUM_ISO_ETDS; i++) {\r\nint etd_num = ep_priv->etd[i];\r\nif (etd_num != -1 && imx21->etd[etd_num].urb == urb) {\r\nstruct etd_priv *etd = imx21->etd + etd_num;\r\nreset_etd(imx21, etd_num);\r\nfree_dmem(imx21, etd);\r\n}\r\n}\r\n}\r\nlist_for_each_entry_safe(td, tmp, &ep_priv->td_list, list) {\r\nif (td->urb == urb) {\r\ndev_vdbg(imx21->dev, "removing td %p\n", td);\r\nlist_del(&td->list);\r\n}\r\n}\r\n}\r\nstatic void schedule_nonisoc_etd(struct imx21 *imx21, struct urb *urb)\r\n{\r\nunsigned int pipe = urb->pipe;\r\nstruct urb_priv *urb_priv = urb->hcpriv;\r\nstruct ep_priv *ep_priv = urb_priv->ep->hcpriv;\r\nint state = urb_priv->state;\r\nint etd_num = ep_priv->etd[0];\r\nstruct etd_priv *etd;\r\nu32 count;\r\nu16 etd_buf_size;\r\nu16 maxpacket;\r\nu8 dir;\r\nu8 bufround;\r\nu8 datatoggle;\r\nu8 interval = 0;\r\nu8 relpolpos = 0;\r\nif (etd_num < 0) {\r\ndev_err(imx21->dev, "No valid ETD\n");\r\nreturn;\r\n}\r\nif (readl(imx21->regs + USBH_ETDENSET) & (1 << etd_num))\r\ndev_err(imx21->dev, "submitting to active ETD %d\n", etd_num);\r\netd = &imx21->etd[etd_num];\r\nmaxpacket = usb_maxpacket(urb->dev, pipe, usb_pipeout(pipe));\r\nif (!maxpacket)\r\nmaxpacket = 8;\r\nif (usb_pipecontrol(pipe) && (state != US_CTRL_DATA)) {\r\nif (state == US_CTRL_SETUP) {\r\ndir = TD_DIR_SETUP;\r\nif (unsuitable_for_dma(urb->setup_dma))\r\nusb_hcd_unmap_urb_setup_for_dma(imx21->hcd,\r\nurb);\r\netd->dma_handle = urb->setup_dma;\r\netd->cpu_buffer = urb->setup_packet;\r\nbufround = 0;\r\ncount = 8;\r\ndatatoggle = TD_TOGGLE_DATA0;\r\n} else {\r\ndir = usb_pipeout(pipe) ? TD_DIR_IN : TD_DIR_OUT;\r\nbufround = 0;\r\ncount = 0;\r\ndatatoggle = TD_TOGGLE_DATA1;\r\n}\r\n} else {\r\ndir = usb_pipeout(pipe) ? TD_DIR_OUT : TD_DIR_IN;\r\nbufround = (dir == TD_DIR_IN) ? 1 : 0;\r\nif (unsuitable_for_dma(urb->transfer_dma))\r\nusb_hcd_unmap_urb_for_dma(imx21->hcd, urb);\r\netd->dma_handle = urb->transfer_dma;\r\netd->cpu_buffer = urb->transfer_buffer;\r\nif (usb_pipebulk(pipe) && (state == US_BULK0))\r\ncount = 0;\r\nelse\r\ncount = urb->transfer_buffer_length;\r\nif (usb_pipecontrol(pipe)) {\r\ndatatoggle = TD_TOGGLE_DATA1;\r\n} else {\r\nif (usb_gettoggle(\r\nurb->dev,\r\nusb_pipeendpoint(urb->pipe),\r\nusb_pipeout(urb->pipe)))\r\ndatatoggle = TD_TOGGLE_DATA1;\r\nelse\r\ndatatoggle = TD_TOGGLE_DATA0;\r\n}\r\n}\r\netd->urb = urb;\r\netd->ep = urb_priv->ep;\r\netd->len = count;\r\nif (usb_pipeint(pipe)) {\r\ninterval = urb->interval;\r\nrelpolpos = (readl(imx21->regs + USBH_FRMNUB) + 1) & 0xff;\r\n}\r\nsetup_etd_dword0(imx21, etd_num, urb, dir, maxpacket);\r\netd_writel(imx21, etd_num, 2,\r\n(u32) interval << DW2_POLINTERV |\r\n((u32) relpolpos << DW2_RELPOLPOS) |\r\n((u32) dir << DW2_DIRPID) |\r\n((u32) bufround << DW2_BUFROUND) |\r\n((u32) datatoggle << DW2_DATATOG) |\r\n((u32) TD_NOTACCESSED << DW2_COMPCODE));\r\nif (count && count < maxpacket)\r\netd_buf_size = count;\r\nelse\r\netd_buf_size = maxpacket;\r\netd_writel(imx21, etd_num, 3,\r\n((u32) (etd_buf_size - 1) << DW3_BUFSIZE) | (u32) count);\r\nif (!count)\r\netd->dma_handle = 0;\r\netd->dmem_size = (count > maxpacket) ? maxpacket * 2 : maxpacket;\r\netd->dmem_offset = alloc_dmem(imx21, etd->dmem_size, urb_priv->ep);\r\nif (etd->dmem_offset < 0) {\r\netd_writel(imx21, etd_num, 1, (u32)maxpacket << 16);\r\ndev_dbg(imx21->dev, "Queuing etd %d for DMEM\n", etd_num);\r\ndebug_urb_queued_for_dmem(imx21, urb);\r\nlist_add_tail(&etd->queue, &imx21->queue_for_dmem);\r\nreturn;\r\n}\r\netd_writel(imx21, etd_num, 1,\r\n(((u32) etd->dmem_offset + (u32) maxpacket) << DW1_YBUFSRTAD) |\r\n(u32) etd->dmem_offset);\r\nurb_priv->active = 1;\r\ndev_vdbg(imx21->dev, "Activating etd %d for %d bytes %s\n",\r\netd_num, count, dir != TD_DIR_IN ? "out" : "in");\r\nactivate_etd(imx21, etd_num, dir);\r\n}\r\nstatic void nonisoc_etd_done(struct usb_hcd *hcd, int etd_num)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nstruct etd_priv *etd = &imx21->etd[etd_num];\r\nstruct urb *urb = etd->urb;\r\nu32 etd_mask = 1 << etd_num;\r\nstruct urb_priv *urb_priv = urb->hcpriv;\r\nint dir;\r\nint cc;\r\nu32 bytes_xfrd;\r\nint etd_done;\r\ndisactivate_etd(imx21, etd_num);\r\ndir = (etd_readl(imx21, etd_num, 0) >> DW0_DIRECT) & 0x3;\r\ncc = (etd_readl(imx21, etd_num, 2) >> DW2_COMPCODE) & 0xf;\r\nbytes_xfrd = etd->len - (etd_readl(imx21, etd_num, 3) & 0x1fffff);\r\nusb_settoggle(urb->dev, usb_pipeendpoint(urb->pipe),\r\nusb_pipeout(urb->pipe),\r\n(etd_readl(imx21, etd_num, 0) >> DW0_TOGCRY) & 0x1);\r\nif (dir == TD_DIR_IN) {\r\nclear_toggle_bit(imx21, USBH_XFILLSTAT, etd_mask);\r\nclear_toggle_bit(imx21, USBH_YFILLSTAT, etd_mask);\r\nif (etd->bounce_buffer) {\r\nmemcpy(etd->cpu_buffer, etd->bounce_buffer, bytes_xfrd);\r\ndma_unmap_single(imx21->dev,\r\netd->dma_handle, etd->len, DMA_FROM_DEVICE);\r\n} else if (!etd->dma_handle && bytes_xfrd) {\r\nmemcpy_fromio(etd->cpu_buffer,\r\nimx21->regs + USBOTG_DMEM + etd->dmem_offset,\r\nbytes_xfrd);\r\n}\r\n}\r\nkfree(etd->bounce_buffer);\r\netd->bounce_buffer = NULL;\r\nfree_dmem(imx21, etd);\r\nurb->error_count = 0;\r\nif (!(urb->transfer_flags & URB_SHORT_NOT_OK)\r\n&& (cc == TD_DATAUNDERRUN))\r\ncc = TD_CC_NOERROR;\r\nif (cc != 0)\r\ndev_vdbg(imx21->dev, "cc is 0x%x\n", cc);\r\netd_done = (cc_to_error[cc] != 0);\r\nswitch (usb_pipetype(urb->pipe)) {\r\ncase PIPE_CONTROL:\r\nswitch (urb_priv->state) {\r\ncase US_CTRL_SETUP:\r\nif (urb->transfer_buffer_length > 0)\r\nurb_priv->state = US_CTRL_DATA;\r\nelse\r\nurb_priv->state = US_CTRL_ACK;\r\nbreak;\r\ncase US_CTRL_DATA:\r\nurb->actual_length += bytes_xfrd;\r\nurb_priv->state = US_CTRL_ACK;\r\nbreak;\r\ncase US_CTRL_ACK:\r\netd_done = 1;\r\nbreak;\r\ndefault:\r\ndev_err(imx21->dev,\r\n"Invalid pipe state %d\n", urb_priv->state);\r\netd_done = 1;\r\nbreak;\r\n}\r\nbreak;\r\ncase PIPE_BULK:\r\nurb->actual_length += bytes_xfrd;\r\nif ((urb_priv->state == US_BULK)\r\n&& (urb->transfer_flags & URB_ZERO_PACKET)\r\n&& urb->transfer_buffer_length > 0\r\n&& ((urb->transfer_buffer_length %\r\nusb_maxpacket(urb->dev, urb->pipe,\r\nusb_pipeout(urb->pipe))) == 0)) {\r\nurb_priv->state = US_BULK0;\r\n} else {\r\netd_done = 1;\r\n}\r\nbreak;\r\ncase PIPE_INTERRUPT:\r\nurb->actual_length += bytes_xfrd;\r\netd_done = 1;\r\nbreak;\r\n}\r\nif (etd_done)\r\nnonisoc_urb_completed_for_etd(imx21, etd, cc_to_error[cc]);\r\nelse {\r\ndev_vdbg(imx21->dev, "next state=%d\n", urb_priv->state);\r\nschedule_nonisoc_etd(imx21, urb);\r\n}\r\n}\r\nstatic struct ep_priv *alloc_ep(void)\r\n{\r\nint i;\r\nstruct ep_priv *ep_priv;\r\nep_priv = kzalloc(sizeof(struct ep_priv), GFP_ATOMIC);\r\nif (!ep_priv)\r\nreturn NULL;\r\nfor (i = 0; i < NUM_ISO_ETDS; ++i)\r\nep_priv->etd[i] = -1;\r\nreturn ep_priv;\r\n}\r\nstatic int imx21_hc_urb_enqueue(struct usb_hcd *hcd,\r\nstruct urb *urb, gfp_t mem_flags)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nstruct usb_host_endpoint *ep = urb->ep;\r\nstruct urb_priv *urb_priv;\r\nstruct ep_priv *ep_priv;\r\nstruct etd_priv *etd;\r\nint ret;\r\nunsigned long flags;\r\ndev_vdbg(imx21->dev,\r\n"enqueue urb=%p ep=%p len=%d "\r\n"buffer=%p dma=%08X setupBuf=%p setupDma=%08X\n",\r\nurb, ep,\r\nurb->transfer_buffer_length,\r\nurb->transfer_buffer, urb->transfer_dma,\r\nurb->setup_packet, urb->setup_dma);\r\nif (usb_pipeisoc(urb->pipe))\r\nreturn imx21_hc_urb_enqueue_isoc(hcd, ep, urb, mem_flags);\r\nurb_priv = kzalloc(sizeof(struct urb_priv), mem_flags);\r\nif (!urb_priv)\r\nreturn -ENOMEM;\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nep_priv = ep->hcpriv;\r\nif (ep_priv == NULL) {\r\nep_priv = alloc_ep();\r\nif (!ep_priv) {\r\nret = -ENOMEM;\r\ngoto failed_alloc_ep;\r\n}\r\nep->hcpriv = ep_priv;\r\nep_priv->ep = ep;\r\n}\r\nret = usb_hcd_link_urb_to_ep(hcd, urb);\r\nif (ret)\r\ngoto failed_link;\r\nurb->status = -EINPROGRESS;\r\nurb->actual_length = 0;\r\nurb->error_count = 0;\r\nurb->hcpriv = urb_priv;\r\nurb_priv->ep = ep;\r\nswitch (usb_pipetype(urb->pipe)) {\r\ncase PIPE_CONTROL:\r\nurb_priv->state = US_CTRL_SETUP;\r\nbreak;\r\ncase PIPE_BULK:\r\nurb_priv->state = US_BULK;\r\nbreak;\r\n}\r\ndebug_urb_submitted(imx21, urb);\r\nif (ep_priv->etd[0] < 0) {\r\nif (ep_priv->waiting_etd) {\r\ndev_dbg(imx21->dev,\r\n"no ETD available already queued %p\n",\r\nep_priv);\r\ndebug_urb_queued_for_etd(imx21, urb);\r\ngoto out;\r\n}\r\nep_priv->etd[0] = alloc_etd(imx21);\r\nif (ep_priv->etd[0] < 0) {\r\ndev_dbg(imx21->dev,\r\n"no ETD available queueing %p\n", ep_priv);\r\ndebug_urb_queued_for_etd(imx21, urb);\r\nlist_add_tail(&ep_priv->queue, &imx21->queue_for_etd);\r\nep_priv->waiting_etd = 1;\r\ngoto out;\r\n}\r\n}\r\netd = &imx21->etd[ep_priv->etd[0]];\r\nif (etd->urb == NULL) {\r\nDEBUG_LOG_FRAME(imx21, etd, last_req);\r\nschedule_nonisoc_etd(imx21, urb);\r\n}\r\nout:\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nreturn 0;\r\nfailed_link:\r\nfailed_alloc_ep:\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nkfree(urb_priv);\r\nreturn ret;\r\n}\r\nstatic int imx21_hc_urb_dequeue(struct usb_hcd *hcd, struct urb *urb,\r\nint status)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nunsigned long flags;\r\nstruct usb_host_endpoint *ep;\r\nstruct ep_priv *ep_priv;\r\nstruct urb_priv *urb_priv = urb->hcpriv;\r\nint ret = -EINVAL;\r\ndev_vdbg(imx21->dev, "dequeue urb=%p iso=%d status=%d\n",\r\nurb, usb_pipeisoc(urb->pipe), status);\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nret = usb_hcd_check_unlink_urb(hcd, urb, status);\r\nif (ret)\r\ngoto fail;\r\nep = urb_priv->ep;\r\nep_priv = ep->hcpriv;\r\ndebug_urb_unlinked(imx21, urb);\r\nif (usb_pipeisoc(urb->pipe)) {\r\ndequeue_isoc_urb(imx21, urb, ep_priv);\r\nschedule_isoc_etds(hcd, ep);\r\n} else if (urb_priv->active) {\r\nint etd_num = ep_priv->etd[0];\r\nif (etd_num != -1) {\r\nstruct etd_priv *etd = &imx21->etd[etd_num];\r\ndisactivate_etd(imx21, etd_num);\r\nfree_dmem(imx21, etd);\r\netd->urb = NULL;\r\nkfree(etd->bounce_buffer);\r\netd->bounce_buffer = NULL;\r\n}\r\n}\r\nurb_done(hcd, urb, status);\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nreturn 0;\r\nfail:\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nreturn ret;\r\n}\r\nstatic void process_etds(struct usb_hcd *hcd, struct imx21 *imx21, int sof)\r\n{\r\nint etd_num;\r\nint enable_sof_int = 0;\r\nunsigned long flags;\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nfor (etd_num = 0; etd_num < USB_NUM_ETD; etd_num++) {\r\nu32 etd_mask = 1 << etd_num;\r\nu32 enabled = readl(imx21->regs + USBH_ETDENSET) & etd_mask;\r\nu32 done = readl(imx21->regs + USBH_ETDDONESTAT) & etd_mask;\r\nstruct etd_priv *etd = &imx21->etd[etd_num];\r\nif (done) {\r\nDEBUG_LOG_FRAME(imx21, etd, last_int);\r\n} else {\r\nu32 dword0;\r\nint cc;\r\nif (etd->active_count && !enabled)\r\nenable_sof_int = 1;\r\nif (!sof || enabled || !etd->active_count)\r\ncontinue;\r\ncc = etd_readl(imx21, etd_num, 2) >> DW2_COMPCODE;\r\nif (cc == TD_NOTACCESSED)\r\ncontinue;\r\nif (++etd->active_count < 10)\r\ncontinue;\r\ndword0 = etd_readl(imx21, etd_num, 0);\r\ndev_dbg(imx21->dev,\r\n"unblock ETD %d dev=0x%X ep=0x%X cc=0x%02X!\n",\r\netd_num, dword0 & 0x7F,\r\n(dword0 >> DW0_ENDPNT) & 0x0F,\r\ncc);\r\n#ifdef DEBUG\r\ndev_dbg(imx21->dev,\r\n"frame: act=%d disact=%d"\r\n" int=%d req=%d cur=%d\n",\r\netd->activated_frame,\r\netd->disactivated_frame,\r\netd->last_int_frame,\r\netd->last_req_frame,\r\nreadl(imx21->regs + USBH_FRMNUB));\r\nimx21->debug_unblocks++;\r\n#endif\r\netd->active_count = 0;\r\n}\r\nif (etd->ep == NULL || etd->urb == NULL) {\r\ndev_dbg(imx21->dev,\r\n"Interrupt for unexpected etd %d"\r\n" ep=%p urb=%p\n",\r\netd_num, etd->ep, etd->urb);\r\ndisactivate_etd(imx21, etd_num);\r\ncontinue;\r\n}\r\nif (usb_pipeisoc(etd->urb->pipe))\r\nisoc_etd_done(hcd, etd_num);\r\nelse\r\nnonisoc_etd_done(hcd, etd_num);\r\n}\r\nif (enable_sof_int)\r\nset_register_bits(imx21, USBH_SYSIEN, USBH_SYSIEN_SOFINT);\r\nelse\r\nclear_register_bits(imx21, USBH_SYSIEN, USBH_SYSIEN_SOFINT);\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\n}\r\nstatic irqreturn_t imx21_irq(struct usb_hcd *hcd)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nu32 ints = readl(imx21->regs + USBH_SYSISR);\r\nif (ints & USBH_SYSIEN_HERRINT)\r\ndev_dbg(imx21->dev, "Scheduling error\n");\r\nif (ints & USBH_SYSIEN_SORINT)\r\ndev_dbg(imx21->dev, "Scheduling overrun\n");\r\nif (ints & (USBH_SYSISR_DONEINT | USBH_SYSISR_SOFINT))\r\nprocess_etds(hcd, imx21, ints & USBH_SYSISR_SOFINT);\r\nwritel(ints, imx21->regs + USBH_SYSISR);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void imx21_hc_endpoint_disable(struct usb_hcd *hcd,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nunsigned long flags;\r\nstruct ep_priv *ep_priv;\r\nint i;\r\nif (ep == NULL)\r\nreturn;\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nep_priv = ep->hcpriv;\r\ndev_vdbg(imx21->dev, "disable ep=%p, ep->hcpriv=%p\n", ep, ep_priv);\r\nif (!list_empty(&ep->urb_list))\r\ndev_dbg(imx21->dev, "ep's URB list is not empty\n");\r\nif (ep_priv != NULL) {\r\nfor (i = 0; i < NUM_ISO_ETDS; i++) {\r\nif (ep_priv->etd[i] > -1)\r\ndev_dbg(imx21->dev, "free etd %d for disable\n",\r\nep_priv->etd[i]);\r\nfree_etd(imx21, ep_priv->etd[i]);\r\n}\r\nkfree(ep_priv);\r\nep->hcpriv = NULL;\r\n}\r\nfor (i = 0; i < USB_NUM_ETD; i++) {\r\nif (imx21->etd[i].alloc && imx21->etd[i].ep == ep) {\r\ndev_err(imx21->dev,\r\n"Active etd %d for disabled ep=%p!\n", i, ep);\r\nfree_etd(imx21, i);\r\n}\r\n}\r\nfree_epdmem(imx21, ep);\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\n}\r\nstatic int get_hub_descriptor(struct usb_hcd *hcd,\r\nstruct usb_hub_descriptor *desc)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\ndesc->bDescriptorType = 0x29;\r\ndesc->bHubContrCurrent = 0;\r\ndesc->bNbrPorts = readl(imx21->regs + USBH_ROOTHUBA)\r\n& USBH_ROOTHUBA_NDNSTMPRT_MASK;\r\ndesc->bDescLength = 9;\r\ndesc->bPwrOn2PwrGood = 0;\r\ndesc->wHubCharacteristics = (__force __u16) cpu_to_le16(\r\n0x0002 |\r\n0x0010 |\r\n0);\r\ndesc->u.hs.DeviceRemovable[0] = 1 << 1;\r\ndesc->u.hs.DeviceRemovable[1] = ~0;\r\nreturn 0;\r\n}\r\nstatic int imx21_hc_hub_status_data(struct usb_hcd *hcd, char *buf)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nint ports;\r\nint changed = 0;\r\nint i;\r\nunsigned long flags;\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nports = readl(imx21->regs + USBH_ROOTHUBA)\r\n& USBH_ROOTHUBA_NDNSTMPRT_MASK;\r\nif (ports > 7) {\r\nports = 7;\r\ndev_err(imx21->dev, "ports %d > 7\n", ports);\r\n}\r\nfor (i = 0; i < ports; i++) {\r\nif (readl(imx21->regs + USBH_PORTSTAT(i)) &\r\n(USBH_PORTSTAT_CONNECTSC |\r\nUSBH_PORTSTAT_PRTENBLSC |\r\nUSBH_PORTSTAT_PRTSTATSC |\r\nUSBH_PORTSTAT_OVRCURIC |\r\nUSBH_PORTSTAT_PRTRSTSC)) {\r\nchanged = 1;\r\nbuf[0] |= 1 << (i + 1);\r\n}\r\n}\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nif (changed)\r\ndev_info(imx21->dev, "Hub status changed\n");\r\nreturn changed;\r\n}\r\nstatic int imx21_hc_hub_control(struct usb_hcd *hcd,\r\nu16 typeReq,\r\nu16 wValue, u16 wIndex, char *buf, u16 wLength)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nint rc = 0;\r\nu32 status_write = 0;\r\nswitch (typeReq) {\r\ncase ClearHubFeature:\r\ndev_dbg(imx21->dev, "ClearHubFeature\n");\r\nswitch (wValue) {\r\ncase C_HUB_OVER_CURRENT:\r\ndev_dbg(imx21->dev, " OVER_CURRENT\n");\r\nbreak;\r\ncase C_HUB_LOCAL_POWER:\r\ndev_dbg(imx21->dev, " LOCAL_POWER\n");\r\nbreak;\r\ndefault:\r\ndev_dbg(imx21->dev, " unknown\n");\r\nrc = -EINVAL;\r\nbreak;\r\n}\r\nbreak;\r\ncase ClearPortFeature:\r\ndev_dbg(imx21->dev, "ClearPortFeature\n");\r\nswitch (wValue) {\r\ncase USB_PORT_FEAT_ENABLE:\r\ndev_dbg(imx21->dev, " ENABLE\n");\r\nstatus_write = USBH_PORTSTAT_CURCONST;\r\nbreak;\r\ncase USB_PORT_FEAT_SUSPEND:\r\ndev_dbg(imx21->dev, " SUSPEND\n");\r\nstatus_write = USBH_PORTSTAT_PRTOVRCURI;\r\nbreak;\r\ncase USB_PORT_FEAT_POWER:\r\ndev_dbg(imx21->dev, " POWER\n");\r\nstatus_write = USBH_PORTSTAT_LSDEVCON;\r\nbreak;\r\ncase USB_PORT_FEAT_C_ENABLE:\r\ndev_dbg(imx21->dev, " C_ENABLE\n");\r\nstatus_write = USBH_PORTSTAT_PRTENBLSC;\r\nbreak;\r\ncase USB_PORT_FEAT_C_SUSPEND:\r\ndev_dbg(imx21->dev, " C_SUSPEND\n");\r\nstatus_write = USBH_PORTSTAT_PRTSTATSC;\r\nbreak;\r\ncase USB_PORT_FEAT_C_CONNECTION:\r\ndev_dbg(imx21->dev, " C_CONNECTION\n");\r\nstatus_write = USBH_PORTSTAT_CONNECTSC;\r\nbreak;\r\ncase USB_PORT_FEAT_C_OVER_CURRENT:\r\ndev_dbg(imx21->dev, " C_OVER_CURRENT\n");\r\nstatus_write = USBH_PORTSTAT_OVRCURIC;\r\nbreak;\r\ncase USB_PORT_FEAT_C_RESET:\r\ndev_dbg(imx21->dev, " C_RESET\n");\r\nstatus_write = USBH_PORTSTAT_PRTRSTSC;\r\nbreak;\r\ndefault:\r\ndev_dbg(imx21->dev, " unknown\n");\r\nrc = -EINVAL;\r\nbreak;\r\n}\r\nbreak;\r\ncase GetHubDescriptor:\r\ndev_dbg(imx21->dev, "GetHubDescriptor\n");\r\nrc = get_hub_descriptor(hcd, (void *)buf);\r\nbreak;\r\ncase GetHubStatus:\r\ndev_dbg(imx21->dev, " GetHubStatus\n");\r\n*(__le32 *) buf = 0;\r\nbreak;\r\ncase GetPortStatus:\r\ndev_dbg(imx21->dev, "GetPortStatus: port: %d, 0x%x\n",\r\nwIndex, USBH_PORTSTAT(wIndex - 1));\r\n*(__le32 *) buf = readl(imx21->regs +\r\nUSBH_PORTSTAT(wIndex - 1));\r\nbreak;\r\ncase SetHubFeature:\r\ndev_dbg(imx21->dev, "SetHubFeature\n");\r\nswitch (wValue) {\r\ncase C_HUB_OVER_CURRENT:\r\ndev_dbg(imx21->dev, " OVER_CURRENT\n");\r\nbreak;\r\ncase C_HUB_LOCAL_POWER:\r\ndev_dbg(imx21->dev, " LOCAL_POWER\n");\r\nbreak;\r\ndefault:\r\ndev_dbg(imx21->dev, " unknown\n");\r\nrc = -EINVAL;\r\nbreak;\r\n}\r\nbreak;\r\ncase SetPortFeature:\r\ndev_dbg(imx21->dev, "SetPortFeature\n");\r\nswitch (wValue) {\r\ncase USB_PORT_FEAT_SUSPEND:\r\ndev_dbg(imx21->dev, " SUSPEND\n");\r\nstatus_write = USBH_PORTSTAT_PRTSUSPST;\r\nbreak;\r\ncase USB_PORT_FEAT_POWER:\r\ndev_dbg(imx21->dev, " POWER\n");\r\nstatus_write = USBH_PORTSTAT_PRTPWRST;\r\nbreak;\r\ncase USB_PORT_FEAT_RESET:\r\ndev_dbg(imx21->dev, " RESET\n");\r\nstatus_write = USBH_PORTSTAT_PRTRSTST;\r\nbreak;\r\ndefault:\r\ndev_dbg(imx21->dev, " unknown\n");\r\nrc = -EINVAL;\r\nbreak;\r\n}\r\nbreak;\r\ndefault:\r\ndev_dbg(imx21->dev, " unknown\n");\r\nrc = -EINVAL;\r\nbreak;\r\n}\r\nif (status_write)\r\nwritel(status_write, imx21->regs + USBH_PORTSTAT(wIndex - 1));\r\nreturn rc;\r\n}\r\nstatic int imx21_hc_reset(struct usb_hcd *hcd)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nunsigned long timeout;\r\nunsigned long flags;\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nwritel(USBOTG_RST_RSTCTRL | USBOTG_RST_RSTRH |\r\nUSBOTG_RST_RSTHSIE | USBOTG_RST_RSTHC,\r\nimx21->regs + USBOTG_RST_CTRL);\r\ntimeout = jiffies + HZ;\r\nwhile (readl(imx21->regs + USBOTG_RST_CTRL) != 0) {\r\nif (time_after(jiffies, timeout)) {\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\ndev_err(imx21->dev, "timeout waiting for reset\n");\r\nreturn -ETIMEDOUT;\r\n}\r\nspin_unlock_irq(&imx21->lock);\r\nschedule_timeout_uninterruptible(1);\r\nspin_lock_irq(&imx21->lock);\r\n}\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nreturn 0;\r\n}\r\nstatic int __devinit imx21_hc_start(struct usb_hcd *hcd)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nunsigned long flags;\r\nint i, j;\r\nu32 hw_mode = USBOTG_HWMODE_CRECFG_HOST;\r\nu32 usb_control = 0;\r\nhw_mode |= ((imx21->pdata->host_xcvr << USBOTG_HWMODE_HOSTXCVR_SHIFT) &\r\nUSBOTG_HWMODE_HOSTXCVR_MASK);\r\nhw_mode |= ((imx21->pdata->otg_xcvr << USBOTG_HWMODE_OTGXCVR_SHIFT) &\r\nUSBOTG_HWMODE_OTGXCVR_MASK);\r\nif (imx21->pdata->host1_txenoe)\r\nusb_control |= USBCTRL_HOST1_TXEN_OE;\r\nif (!imx21->pdata->host1_xcverless)\r\nusb_control |= USBCTRL_HOST1_BYP_TLL;\r\nif (imx21->pdata->otg_ext_xcvr)\r\nusb_control |= USBCTRL_OTC_RCV_RXDP;\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nwritel((USBOTG_CLK_CTRL_HST | USBOTG_CLK_CTRL_MAIN),\r\nimx21->regs + USBOTG_CLK_CTRL);\r\nwritel(hw_mode, imx21->regs + USBOTG_HWMODE);\r\nwritel(usb_control, imx21->regs + USBCTRL);\r\nwritel(USB_MISCCONTROL_SKPRTRY | USB_MISCCONTROL_ARBMODE,\r\nimx21->regs + USB_MISCCONTROL);\r\nfor (i = 0; i < USB_NUM_ETD; i++)\r\nfor (j = 0; j < 4; j++)\r\netd_writel(imx21, i, j, 0);\r\nwritel(USBH_HOST_CTRL_HCUSBSTE_OPERATIONAL | USBH_HOST_CTRL_CTLBLKSR_1,\r\nimx21->regs + USBH_HOST_CTRL);\r\nif (imx21->pdata->enable_otg_host)\r\nwritel(USBH_PORTSTAT_PRTPWRST | USBH_PORTSTAT_PRTENABST,\r\nimx21->regs + USBH_PORTSTAT(0));\r\nif (imx21->pdata->enable_host1)\r\nwritel(USBH_PORTSTAT_PRTPWRST | USBH_PORTSTAT_PRTENABST,\r\nimx21->regs + USBH_PORTSTAT(1));\r\nif (imx21->pdata->enable_host2)\r\nwritel(USBH_PORTSTAT_PRTPWRST | USBH_PORTSTAT_PRTENABST,\r\nimx21->regs + USBH_PORTSTAT(2));\r\nhcd->state = HC_STATE_RUNNING;\r\nset_register_bits(imx21, USBH_SYSIEN,\r\nUSBH_SYSIEN_HERRINT |\r\nUSBH_SYSIEN_DONEINT | USBH_SYSIEN_SORINT);\r\nset_register_bits(imx21, USBOTG_CINT_STEN, USBOTG_HCINT);\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\nreturn 0;\r\n}\r\nstatic void imx21_hc_stop(struct usb_hcd *hcd)\r\n{\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nunsigned long flags;\r\nspin_lock_irqsave(&imx21->lock, flags);\r\nwritel(0, imx21->regs + USBH_SYSIEN);\r\nclear_register_bits(imx21, USBOTG_CINT_STEN, USBOTG_HCINT);\r\nclear_register_bits(imx21, USBOTG_CLK_CTRL_HST | USBOTG_CLK_CTRL_MAIN,\r\nUSBOTG_CLK_CTRL);\r\nspin_unlock_irqrestore(&imx21->lock, flags);\r\n}\r\nstatic int imx21_remove(struct platform_device *pdev)\r\n{\r\nstruct usb_hcd *hcd = platform_get_drvdata(pdev);\r\nstruct imx21 *imx21 = hcd_to_imx21(hcd);\r\nstruct resource *res = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nremove_debug_files(imx21);\r\nusb_remove_hcd(hcd);\r\nif (res != NULL) {\r\nclk_disable(imx21->clk);\r\nclk_put(imx21->clk);\r\niounmap(imx21->regs);\r\nrelease_mem_region(res->start, resource_size(res));\r\n}\r\nkfree(hcd);\r\nreturn 0;\r\n}\r\nstatic int imx21_probe(struct platform_device *pdev)\r\n{\r\nstruct usb_hcd *hcd;\r\nstruct imx21 *imx21;\r\nstruct resource *res;\r\nint ret;\r\nint irq;\r\nprintk(KERN_INFO "%s\n", imx21_hc_driver.product_desc);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res)\r\nreturn -ENODEV;\r\nirq = platform_get_irq(pdev, 0);\r\nif (irq < 0)\r\nreturn -ENXIO;\r\nhcd = usb_create_hcd(&imx21_hc_driver,\r\n&pdev->dev, dev_name(&pdev->dev));\r\nif (hcd == NULL) {\r\ndev_err(&pdev->dev, "Cannot create hcd (%s)\n",\r\ndev_name(&pdev->dev));\r\nreturn -ENOMEM;\r\n}\r\nimx21 = hcd_to_imx21(hcd);\r\nimx21->hcd = hcd;\r\nimx21->dev = &pdev->dev;\r\nimx21->pdata = pdev->dev.platform_data;\r\nif (!imx21->pdata)\r\nimx21->pdata = &default_pdata;\r\nspin_lock_init(&imx21->lock);\r\nINIT_LIST_HEAD(&imx21->dmem_list);\r\nINIT_LIST_HEAD(&imx21->queue_for_etd);\r\nINIT_LIST_HEAD(&imx21->queue_for_dmem);\r\ncreate_debug_files(imx21);\r\nres = request_mem_region(res->start, resource_size(res), hcd_name);\r\nif (!res) {\r\nret = -EBUSY;\r\ngoto failed_request_mem;\r\n}\r\nimx21->regs = ioremap(res->start, resource_size(res));\r\nif (imx21->regs == NULL) {\r\ndev_err(imx21->dev, "Cannot map registers\n");\r\nret = -ENOMEM;\r\ngoto failed_ioremap;\r\n}\r\nimx21->clk = clk_get(imx21->dev, NULL);\r\nif (IS_ERR(imx21->clk)) {\r\ndev_err(imx21->dev, "no clock found\n");\r\nret = PTR_ERR(imx21->clk);\r\ngoto failed_clock_get;\r\n}\r\nret = clk_set_rate(imx21->clk, clk_round_rate(imx21->clk, 48000000));\r\nif (ret)\r\ngoto failed_clock_set;\r\nret = clk_enable(imx21->clk);\r\nif (ret)\r\ngoto failed_clock_enable;\r\ndev_info(imx21->dev, "Hardware HC revision: 0x%02X\n",\r\n(readl(imx21->regs + USBOTG_HWMODE) >> 16) & 0xFF);\r\nret = usb_add_hcd(hcd, irq, IRQF_DISABLED);\r\nif (ret != 0) {\r\ndev_err(imx21->dev, "usb_add_hcd() returned %d\n", ret);\r\ngoto failed_add_hcd;\r\n}\r\nreturn 0;\r\nfailed_add_hcd:\r\nclk_disable(imx21->clk);\r\nfailed_clock_enable:\r\nfailed_clock_set:\r\nclk_put(imx21->clk);\r\nfailed_clock_get:\r\niounmap(imx21->regs);\r\nfailed_ioremap:\r\nrelease_mem_region(res->start, resource_size(res));\r\nfailed_request_mem:\r\nremove_debug_files(imx21);\r\nusb_put_hcd(hcd);\r\nreturn ret;\r\n}\r\nstatic int __init imx21_hcd_init(void)\r\n{\r\nreturn platform_driver_register(&imx21_hcd_driver);\r\n}\r\nstatic void __exit imx21_hcd_cleanup(void)\r\n{\r\nplatform_driver_unregister(&imx21_hcd_driver);\r\n}
