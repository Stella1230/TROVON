void __dlm_wait_on_lockres_flags(struct dlm_lock_resource *res, int flags)\r\n{\r\nDECLARE_WAITQUEUE(wait, current);\r\nassert_spin_locked(&res->spinlock);\r\nadd_wait_queue(&res->wq, &wait);\r\nrepeat:\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nif (res->state & flags) {\r\nspin_unlock(&res->spinlock);\r\nschedule();\r\nspin_lock(&res->spinlock);\r\ngoto repeat;\r\n}\r\nremove_wait_queue(&res->wq, &wait);\r\n__set_current_state(TASK_RUNNING);\r\n}\r\nint __dlm_lockres_has_locks(struct dlm_lock_resource *res)\r\n{\r\nif (list_empty(&res->granted) &&\r\nlist_empty(&res->converting) &&\r\nlist_empty(&res->blocked))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nint __dlm_lockres_unused(struct dlm_lock_resource *res)\r\n{\r\nint bit;\r\nif (__dlm_lockres_has_locks(res))\r\nreturn 0;\r\nif (!list_empty(&res->dirty) || res->state & DLM_LOCK_RES_DIRTY)\r\nreturn 0;\r\nif (res->state & DLM_LOCK_RES_RECOVERING)\r\nreturn 0;\r\nbit = find_next_bit(res->refmap, O2NM_MAX_NODES, 0);\r\nif (bit < O2NM_MAX_NODES)\r\nreturn 0;\r\nBUG_ON(res->inflight_locks != 0);\r\nreturn 1;\r\n}\r\nvoid __dlm_lockres_calc_usage(struct dlm_ctxt *dlm,\r\nstruct dlm_lock_resource *res)\r\n{\r\nassert_spin_locked(&dlm->spinlock);\r\nassert_spin_locked(&res->spinlock);\r\nif (__dlm_lockres_unused(res)){\r\nif (list_empty(&res->purge)) {\r\nmlog(0, "%s: Adding res %.*s to purge list\n",\r\ndlm->name, res->lockname.len, res->lockname.name);\r\nres->last_used = jiffies;\r\ndlm_lockres_get(res);\r\nlist_add_tail(&res->purge, &dlm->purge_list);\r\ndlm->purge_count++;\r\n}\r\n} else if (!list_empty(&res->purge)) {\r\nmlog(0, "%s: Removing res %.*s from purge list\n",\r\ndlm->name, res->lockname.len, res->lockname.name);\r\nlist_del_init(&res->purge);\r\ndlm_lockres_put(res);\r\ndlm->purge_count--;\r\n}\r\n}\r\nvoid dlm_lockres_calc_usage(struct dlm_ctxt *dlm,\r\nstruct dlm_lock_resource *res)\r\n{\r\nspin_lock(&dlm->spinlock);\r\nspin_lock(&res->spinlock);\r\n__dlm_lockres_calc_usage(dlm, res);\r\nspin_unlock(&res->spinlock);\r\nspin_unlock(&dlm->spinlock);\r\n}\r\nstatic void dlm_purge_lockres(struct dlm_ctxt *dlm,\r\nstruct dlm_lock_resource *res)\r\n{\r\nint master;\r\nint ret = 0;\r\nassert_spin_locked(&dlm->spinlock);\r\nassert_spin_locked(&res->spinlock);\r\nmaster = (res->owner == dlm->node_num);\r\nmlog(0, "%s: Purging res %.*s, master %d\n", dlm->name,\r\nres->lockname.len, res->lockname.name, master);\r\nif (!master) {\r\nres->state |= DLM_LOCK_RES_DROPPING_REF;\r\nspin_unlock(&res->spinlock);\r\nspin_unlock(&dlm->spinlock);\r\nspin_lock(&res->spinlock);\r\n__dlm_wait_on_lockres_flags(res, DLM_LOCK_RES_SETREF_INPROG);\r\nspin_unlock(&res->spinlock);\r\nret = dlm_drop_lockres_ref(dlm, res);\r\nif (ret < 0) {\r\nmlog(ML_ERROR, "%s: deref %.*s failed %d\n", dlm->name,\r\nres->lockname.len, res->lockname.name, ret);\r\nif (!dlm_is_host_down(ret))\r\nBUG();\r\n}\r\nspin_lock(&dlm->spinlock);\r\nspin_lock(&res->spinlock);\r\n}\r\nif (!list_empty(&res->purge)) {\r\nmlog(0, "%s: Removing res %.*s from purgelist, master %d\n",\r\ndlm->name, res->lockname.len, res->lockname.name, master);\r\nlist_del_init(&res->purge);\r\ndlm_lockres_put(res);\r\ndlm->purge_count--;\r\n}\r\nif (!__dlm_lockres_unused(res)) {\r\nmlog(ML_ERROR, "%s: res %.*s in use after deref\n",\r\ndlm->name, res->lockname.len, res->lockname.name);\r\n__dlm_print_one_lock_resource(res);\r\nBUG();\r\n}\r\n__dlm_unhash_lockres(res);\r\nif (!master) {\r\nres->state &= ~DLM_LOCK_RES_DROPPING_REF;\r\nspin_unlock(&res->spinlock);\r\nwake_up(&res->wq);\r\n} else\r\nspin_unlock(&res->spinlock);\r\n}\r\nstatic void dlm_run_purge_list(struct dlm_ctxt *dlm,\r\nint purge_now)\r\n{\r\nunsigned int run_max, unused;\r\nunsigned long purge_jiffies;\r\nstruct dlm_lock_resource *lockres;\r\nspin_lock(&dlm->spinlock);\r\nrun_max = dlm->purge_count;\r\nwhile(run_max && !list_empty(&dlm->purge_list)) {\r\nrun_max--;\r\nlockres = list_entry(dlm->purge_list.next,\r\nstruct dlm_lock_resource, purge);\r\nspin_lock(&lockres->spinlock);\r\npurge_jiffies = lockres->last_used +\r\nmsecs_to_jiffies(DLM_PURGE_INTERVAL_MS);\r\nif (!purge_now && time_after(purge_jiffies, jiffies)) {\r\nspin_unlock(&lockres->spinlock);\r\nbreak;\r\n}\r\nunused = __dlm_lockres_unused(lockres);\r\nif (!unused ||\r\n(lockres->state & DLM_LOCK_RES_MIGRATING)) {\r\nmlog(0, "%s: res %.*s is in use or being remastered, "\r\n"used %d, state %d\n", dlm->name,\r\nlockres->lockname.len, lockres->lockname.name,\r\n!unused, lockres->state);\r\nlist_move_tail(&dlm->purge_list, &lockres->purge);\r\nspin_unlock(&lockres->spinlock);\r\ncontinue;\r\n}\r\ndlm_lockres_get(lockres);\r\ndlm_purge_lockres(dlm, lockres);\r\ndlm_lockres_put(lockres);\r\ncond_resched_lock(&dlm->spinlock);\r\n}\r\nspin_unlock(&dlm->spinlock);\r\n}\r\nstatic void dlm_shuffle_lists(struct dlm_ctxt *dlm,\r\nstruct dlm_lock_resource *res)\r\n{\r\nstruct dlm_lock *lock, *target;\r\nstruct list_head *iter;\r\nstruct list_head *head;\r\nint can_grant = 1;\r\nassert_spin_locked(&dlm->ast_lock);\r\nassert_spin_locked(&res->spinlock);\r\nBUG_ON((res->state & (DLM_LOCK_RES_MIGRATING|\r\nDLM_LOCK_RES_RECOVERING|\r\nDLM_LOCK_RES_IN_PROGRESS)));\r\nconverting:\r\nif (list_empty(&res->converting))\r\ngoto blocked;\r\nmlog(0, "%s: res %.*s has locks on the convert queue\n", dlm->name,\r\nres->lockname.len, res->lockname.name);\r\ntarget = list_entry(res->converting.next, struct dlm_lock, list);\r\nif (target->ml.convert_type == LKM_IVMODE) {\r\nmlog(ML_ERROR, "%s: res %.*s converting lock to invalid mode\n",\r\ndlm->name, res->lockname.len, res->lockname.name);\r\nBUG();\r\n}\r\nhead = &res->granted;\r\nlist_for_each(iter, head) {\r\nlock = list_entry(iter, struct dlm_lock, list);\r\nif (lock==target)\r\ncontinue;\r\nif (!dlm_lock_compatible(lock->ml.type,\r\ntarget->ml.convert_type)) {\r\ncan_grant = 0;\r\nif (lock->ml.highest_blocked == LKM_IVMODE) {\r\n__dlm_lockres_reserve_ast(res);\r\n__dlm_queue_bast(dlm, lock);\r\n}\r\nif (lock->ml.highest_blocked < target->ml.convert_type)\r\nlock->ml.highest_blocked =\r\ntarget->ml.convert_type;\r\n}\r\n}\r\nhead = &res->converting;\r\nlist_for_each(iter, head) {\r\nlock = list_entry(iter, struct dlm_lock, list);\r\nif (lock==target)\r\ncontinue;\r\nif (!dlm_lock_compatible(lock->ml.type,\r\ntarget->ml.convert_type)) {\r\ncan_grant = 0;\r\nif (lock->ml.highest_blocked == LKM_IVMODE) {\r\n__dlm_lockres_reserve_ast(res);\r\n__dlm_queue_bast(dlm, lock);\r\n}\r\nif (lock->ml.highest_blocked < target->ml.convert_type)\r\nlock->ml.highest_blocked =\r\ntarget->ml.convert_type;\r\n}\r\n}\r\nif (can_grant) {\r\nspin_lock(&target->spinlock);\r\nBUG_ON(target->ml.highest_blocked != LKM_IVMODE);\r\nmlog(0, "%s: res %.*s, AST for Converting lock %u:%llu, type "\r\n"%d => %d, node %u\n", dlm->name, res->lockname.len,\r\nres->lockname.name,\r\ndlm_get_lock_cookie_node(be64_to_cpu(target->ml.cookie)),\r\ndlm_get_lock_cookie_seq(be64_to_cpu(target->ml.cookie)),\r\ntarget->ml.type,\r\ntarget->ml.convert_type, target->ml.node);\r\ntarget->ml.type = target->ml.convert_type;\r\ntarget->ml.convert_type = LKM_IVMODE;\r\nlist_move_tail(&target->list, &res->granted);\r\nBUG_ON(!target->lksb);\r\ntarget->lksb->status = DLM_NORMAL;\r\nspin_unlock(&target->spinlock);\r\n__dlm_lockres_reserve_ast(res);\r\n__dlm_queue_ast(dlm, target);\r\ngoto converting;\r\n}\r\nblocked:\r\nif (list_empty(&res->blocked))\r\ngoto leave;\r\ntarget = list_entry(res->blocked.next, struct dlm_lock, list);\r\nhead = &res->granted;\r\nlist_for_each(iter, head) {\r\nlock = list_entry(iter, struct dlm_lock, list);\r\nif (lock==target)\r\ncontinue;\r\nif (!dlm_lock_compatible(lock->ml.type, target->ml.type)) {\r\ncan_grant = 0;\r\nif (lock->ml.highest_blocked == LKM_IVMODE) {\r\n__dlm_lockres_reserve_ast(res);\r\n__dlm_queue_bast(dlm, lock);\r\n}\r\nif (lock->ml.highest_blocked < target->ml.type)\r\nlock->ml.highest_blocked = target->ml.type;\r\n}\r\n}\r\nhead = &res->converting;\r\nlist_for_each(iter, head) {\r\nlock = list_entry(iter, struct dlm_lock, list);\r\nif (lock==target)\r\ncontinue;\r\nif (!dlm_lock_compatible(lock->ml.type, target->ml.type)) {\r\ncan_grant = 0;\r\nif (lock->ml.highest_blocked == LKM_IVMODE) {\r\n__dlm_lockres_reserve_ast(res);\r\n__dlm_queue_bast(dlm, lock);\r\n}\r\nif (lock->ml.highest_blocked < target->ml.type)\r\nlock->ml.highest_blocked = target->ml.type;\r\n}\r\n}\r\nif (can_grant) {\r\nspin_lock(&target->spinlock);\r\nBUG_ON(target->ml.highest_blocked != LKM_IVMODE);\r\nmlog(0, "%s: res %.*s, AST for Blocked lock %u:%llu, type %d, "\r\n"node %u\n", dlm->name, res->lockname.len,\r\nres->lockname.name,\r\ndlm_get_lock_cookie_node(be64_to_cpu(target->ml.cookie)),\r\ndlm_get_lock_cookie_seq(be64_to_cpu(target->ml.cookie)),\r\ntarget->ml.type, target->ml.node);\r\nlist_move_tail(&target->list, &res->granted);\r\nBUG_ON(!target->lksb);\r\ntarget->lksb->status = DLM_NORMAL;\r\nspin_unlock(&target->spinlock);\r\n__dlm_lockres_reserve_ast(res);\r\n__dlm_queue_ast(dlm, target);\r\ngoto converting;\r\n}\r\nleave:\r\nreturn;\r\n}\r\nvoid dlm_kick_thread(struct dlm_ctxt *dlm, struct dlm_lock_resource *res)\r\n{\r\nif (res) {\r\nspin_lock(&dlm->spinlock);\r\nspin_lock(&res->spinlock);\r\n__dlm_dirty_lockres(dlm, res);\r\nspin_unlock(&res->spinlock);\r\nspin_unlock(&dlm->spinlock);\r\n}\r\nwake_up(&dlm->dlm_thread_wq);\r\n}\r\nvoid __dlm_dirty_lockres(struct dlm_ctxt *dlm, struct dlm_lock_resource *res)\r\n{\r\nassert_spin_locked(&dlm->spinlock);\r\nassert_spin_locked(&res->spinlock);\r\nif ((res->owner == dlm->node_num)) {\r\nif (res->state & (DLM_LOCK_RES_MIGRATING |\r\nDLM_LOCK_RES_BLOCK_DIRTY))\r\nreturn;\r\nif (list_empty(&res->dirty)) {\r\ndlm_lockres_get(res);\r\nlist_add_tail(&res->dirty, &dlm->dirty_list);\r\nres->state |= DLM_LOCK_RES_DIRTY;\r\n}\r\n}\r\nmlog(0, "%s: res %.*s\n", dlm->name, res->lockname.len,\r\nres->lockname.name);\r\n}\r\nint dlm_launch_thread(struct dlm_ctxt *dlm)\r\n{\r\nmlog(0, "Starting dlm_thread...\n");\r\ndlm->dlm_thread_task = kthread_run(dlm_thread, dlm, "dlm_thread");\r\nif (IS_ERR(dlm->dlm_thread_task)) {\r\nmlog_errno(PTR_ERR(dlm->dlm_thread_task));\r\ndlm->dlm_thread_task = NULL;\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nvoid dlm_complete_thread(struct dlm_ctxt *dlm)\r\n{\r\nif (dlm->dlm_thread_task) {\r\nmlog(ML_KTHREAD, "Waiting for dlm thread to exit\n");\r\nkthread_stop(dlm->dlm_thread_task);\r\ndlm->dlm_thread_task = NULL;\r\n}\r\n}\r\nstatic int dlm_dirty_list_empty(struct dlm_ctxt *dlm)\r\n{\r\nint empty;\r\nspin_lock(&dlm->spinlock);\r\nempty = list_empty(&dlm->dirty_list);\r\nspin_unlock(&dlm->spinlock);\r\nreturn empty;\r\n}\r\nstatic void dlm_flush_asts(struct dlm_ctxt *dlm)\r\n{\r\nint ret;\r\nstruct dlm_lock *lock;\r\nstruct dlm_lock_resource *res;\r\nu8 hi;\r\nspin_lock(&dlm->ast_lock);\r\nwhile (!list_empty(&dlm->pending_asts)) {\r\nlock = list_entry(dlm->pending_asts.next,\r\nstruct dlm_lock, ast_list);\r\ndlm_lock_get(lock);\r\nres = lock->lockres;\r\nmlog(0, "%s: res %.*s, Flush AST for lock %u:%llu, type %d, "\r\n"node %u\n", dlm->name, res->lockname.len,\r\nres->lockname.name,\r\ndlm_get_lock_cookie_node(be64_to_cpu(lock->ml.cookie)),\r\ndlm_get_lock_cookie_seq(be64_to_cpu(lock->ml.cookie)),\r\nlock->ml.type, lock->ml.node);\r\nBUG_ON(!lock->ast_pending);\r\nlist_del_init(&lock->ast_list);\r\ndlm_lock_put(lock);\r\nspin_unlock(&dlm->ast_lock);\r\nif (lock->ml.node != dlm->node_num) {\r\nret = dlm_do_remote_ast(dlm, res, lock);\r\nif (ret < 0)\r\nmlog_errno(ret);\r\n} else\r\ndlm_do_local_ast(dlm, res, lock);\r\nspin_lock(&dlm->ast_lock);\r\nif (!list_empty(&lock->ast_list)) {\r\nmlog(0, "%s: res %.*s, AST queued while flushing last "\r\n"one\n", dlm->name, res->lockname.len,\r\nres->lockname.name);\r\n} else\r\nlock->ast_pending = 0;\r\ndlm_lock_put(lock);\r\ndlm_lockres_release_ast(dlm, res);\r\n}\r\nwhile (!list_empty(&dlm->pending_basts)) {\r\nlock = list_entry(dlm->pending_basts.next,\r\nstruct dlm_lock, bast_list);\r\ndlm_lock_get(lock);\r\nres = lock->lockres;\r\nBUG_ON(!lock->bast_pending);\r\nspin_lock(&lock->spinlock);\r\nBUG_ON(lock->ml.highest_blocked <= LKM_IVMODE);\r\nhi = lock->ml.highest_blocked;\r\nlock->ml.highest_blocked = LKM_IVMODE;\r\nspin_unlock(&lock->spinlock);\r\nlist_del_init(&lock->bast_list);\r\ndlm_lock_put(lock);\r\nspin_unlock(&dlm->ast_lock);\r\nmlog(0, "%s: res %.*s, Flush BAST for lock %u:%llu, "\r\n"blocked %d, node %u\n",\r\ndlm->name, res->lockname.len, res->lockname.name,\r\ndlm_get_lock_cookie_node(be64_to_cpu(lock->ml.cookie)),\r\ndlm_get_lock_cookie_seq(be64_to_cpu(lock->ml.cookie)),\r\nhi, lock->ml.node);\r\nif (lock->ml.node != dlm->node_num) {\r\nret = dlm_send_proxy_bast(dlm, res, lock, hi);\r\nif (ret < 0)\r\nmlog_errno(ret);\r\n} else\r\ndlm_do_local_bast(dlm, res, lock, hi);\r\nspin_lock(&dlm->ast_lock);\r\nif (!list_empty(&lock->bast_list)) {\r\nmlog(0, "%s: res %.*s, BAST queued while flushing last "\r\n"one\n", dlm->name, res->lockname.len,\r\nres->lockname.name);\r\n} else\r\nlock->bast_pending = 0;\r\ndlm_lock_put(lock);\r\ndlm_lockres_release_ast(dlm, res);\r\n}\r\nwake_up(&dlm->ast_wq);\r\nspin_unlock(&dlm->ast_lock);\r\n}\r\nstatic int dlm_thread(void *data)\r\n{\r\nstruct dlm_lock_resource *res;\r\nstruct dlm_ctxt *dlm = data;\r\nunsigned long timeout = msecs_to_jiffies(DLM_THREAD_TIMEOUT_MS);\r\nmlog(0, "dlm thread running for %s...\n", dlm->name);\r\nwhile (!kthread_should_stop()) {\r\nint n = DLM_THREAD_MAX_DIRTY;\r\ndlm_run_purge_list(dlm, dlm_shutting_down(dlm));\r\nspin_lock(&dlm->spinlock);\r\nwhile (!list_empty(&dlm->dirty_list)) {\r\nint delay = 0;\r\nres = list_entry(dlm->dirty_list.next,\r\nstruct dlm_lock_resource, dirty);\r\nBUG_ON(!res);\r\ndlm_lockres_get(res);\r\nspin_lock(&res->spinlock);\r\nlist_del_init(&res->dirty);\r\nspin_unlock(&res->spinlock);\r\nspin_unlock(&dlm->spinlock);\r\ndlm_lockres_put(res);\r\nspin_lock(&dlm->ast_lock);\r\nspin_lock(&res->spinlock);\r\nif (res->owner != dlm->node_num) {\r\n__dlm_print_one_lock_resource(res);\r\nmlog(ML_ERROR, "%s: inprog %d, mig %d, reco %d,"\r\n" dirty %d\n", dlm->name,\r\n!!(res->state & DLM_LOCK_RES_IN_PROGRESS),\r\n!!(res->state & DLM_LOCK_RES_MIGRATING),\r\n!!(res->state & DLM_LOCK_RES_RECOVERING),\r\n!!(res->state & DLM_LOCK_RES_DIRTY));\r\n}\r\nBUG_ON(res->owner != dlm->node_num);\r\nBUG_ON(res->state & DLM_LOCK_RES_MIGRATING);\r\nif (res->state & (DLM_LOCK_RES_IN_PROGRESS |\r\nDLM_LOCK_RES_RECOVERING)) {\r\nres->state &= ~DLM_LOCK_RES_DIRTY;\r\nspin_unlock(&res->spinlock);\r\nspin_unlock(&dlm->ast_lock);\r\nmlog(0, "%s: res %.*s, inprogress, delay list "\r\n"shuffle, state %d\n", dlm->name,\r\nres->lockname.len, res->lockname.name,\r\nres->state);\r\ndelay = 1;\r\ngoto in_progress;\r\n}\r\ndlm_shuffle_lists(dlm, res);\r\nres->state &= ~DLM_LOCK_RES_DIRTY;\r\nspin_unlock(&res->spinlock);\r\nspin_unlock(&dlm->ast_lock);\r\ndlm_lockres_calc_usage(dlm, res);\r\nin_progress:\r\nspin_lock(&dlm->spinlock);\r\nif (delay) {\r\nspin_lock(&res->spinlock);\r\n__dlm_dirty_lockres(dlm, res);\r\nspin_unlock(&res->spinlock);\r\n}\r\ndlm_lockres_put(res);\r\nif (!--n) {\r\nmlog(0, "%s: Throttling dlm thread\n",\r\ndlm->name);\r\nbreak;\r\n}\r\n}\r\nspin_unlock(&dlm->spinlock);\r\ndlm_flush_asts(dlm);\r\nif (!n) {\r\ncond_resched();\r\ncontinue;\r\n}\r\nwait_event_interruptible_timeout(dlm->dlm_thread_wq,\r\n!dlm_dirty_list_empty(dlm) ||\r\nkthread_should_stop(),\r\ntimeout);\r\n}\r\nmlog(0, "quitting DLM thread\n");\r\nreturn 0;\r\n}
