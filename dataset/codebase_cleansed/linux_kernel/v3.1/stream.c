void sk_stream_write_space(struct sock *sk)\r\n{\r\nstruct socket *sock = sk->sk_socket;\r\nstruct socket_wq *wq;\r\nif (sk_stream_wspace(sk) >= sk_stream_min_wspace(sk) && sock) {\r\nclear_bit(SOCK_NOSPACE, &sock->flags);\r\nrcu_read_lock();\r\nwq = rcu_dereference(sk->sk_wq);\r\nif (wq_has_sleeper(wq))\r\nwake_up_interruptible_poll(&wq->wait, POLLOUT |\r\nPOLLWRNORM | POLLWRBAND);\r\nif (wq && wq->fasync_list && !(sk->sk_shutdown & SEND_SHUTDOWN))\r\nsock_wake_async(sock, SOCK_WAKE_SPACE, POLL_OUT);\r\nrcu_read_unlock();\r\n}\r\n}\r\nint sk_stream_wait_connect(struct sock *sk, long *timeo_p)\r\n{\r\nstruct task_struct *tsk = current;\r\nDEFINE_WAIT(wait);\r\nint done;\r\ndo {\r\nint err = sock_error(sk);\r\nif (err)\r\nreturn err;\r\nif ((1 << sk->sk_state) & ~(TCPF_SYN_SENT | TCPF_SYN_RECV))\r\nreturn -EPIPE;\r\nif (!*timeo_p)\r\nreturn -EAGAIN;\r\nif (signal_pending(tsk))\r\nreturn sock_intr_errno(*timeo_p);\r\nprepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);\r\nsk->sk_write_pending++;\r\ndone = sk_wait_event(sk, timeo_p,\r\n!sk->sk_err &&\r\n!((1 << sk->sk_state) &\r\n~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)));\r\nfinish_wait(sk_sleep(sk), &wait);\r\nsk->sk_write_pending--;\r\n} while (!done);\r\nreturn 0;\r\n}\r\nstatic inline int sk_stream_closing(struct sock *sk)\r\n{\r\nreturn (1 << sk->sk_state) &\r\n(TCPF_FIN_WAIT1 | TCPF_CLOSING | TCPF_LAST_ACK);\r\n}\r\nvoid sk_stream_wait_close(struct sock *sk, long timeout)\r\n{\r\nif (timeout) {\r\nDEFINE_WAIT(wait);\r\ndo {\r\nprepare_to_wait(sk_sleep(sk), &wait,\r\nTASK_INTERRUPTIBLE);\r\nif (sk_wait_event(sk, &timeout, !sk_stream_closing(sk)))\r\nbreak;\r\n} while (!signal_pending(current) && timeout);\r\nfinish_wait(sk_sleep(sk), &wait);\r\n}\r\n}\r\nint sk_stream_wait_memory(struct sock *sk, long *timeo_p)\r\n{\r\nint err = 0;\r\nlong vm_wait = 0;\r\nlong current_timeo = *timeo_p;\r\nDEFINE_WAIT(wait);\r\nif (sk_stream_memory_free(sk))\r\ncurrent_timeo = vm_wait = (net_random() % (HZ / 5)) + 2;\r\nwhile (1) {\r\nset_bit(SOCK_ASYNC_NOSPACE, &sk->sk_socket->flags);\r\nprepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);\r\nif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\r\ngoto do_error;\r\nif (!*timeo_p)\r\ngoto do_nonblock;\r\nif (signal_pending(current))\r\ngoto do_interrupted;\r\nclear_bit(SOCK_ASYNC_NOSPACE, &sk->sk_socket->flags);\r\nif (sk_stream_memory_free(sk) && !vm_wait)\r\nbreak;\r\nset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\r\nsk->sk_write_pending++;\r\nsk_wait_event(sk, &current_timeo, sk->sk_err ||\r\n(sk->sk_shutdown & SEND_SHUTDOWN) ||\r\n(sk_stream_memory_free(sk) &&\r\n!vm_wait));\r\nsk->sk_write_pending--;\r\nif (vm_wait) {\r\nvm_wait -= current_timeo;\r\ncurrent_timeo = *timeo_p;\r\nif (current_timeo != MAX_SCHEDULE_TIMEOUT &&\r\n(current_timeo -= vm_wait) < 0)\r\ncurrent_timeo = 0;\r\nvm_wait = 0;\r\n}\r\n*timeo_p = current_timeo;\r\n}\r\nout:\r\nfinish_wait(sk_sleep(sk), &wait);\r\nreturn err;\r\ndo_error:\r\nerr = -EPIPE;\r\ngoto out;\r\ndo_nonblock:\r\nerr = -EAGAIN;\r\ngoto out;\r\ndo_interrupted:\r\nerr = sock_intr_errno(*timeo_p);\r\ngoto out;\r\n}\r\nint sk_stream_error(struct sock *sk, int flags, int err)\r\n{\r\nif (err == -EPIPE)\r\nerr = sock_error(sk) ? : -EPIPE;\r\nif (err == -EPIPE && !(flags & MSG_NOSIGNAL))\r\nsend_sig(SIGPIPE, current, 0);\r\nreturn err;\r\n}\r\nvoid sk_stream_kill_queues(struct sock *sk)\r\n{\r\n__skb_queue_purge(&sk->sk_receive_queue);\r\n__skb_queue_purge(&sk->sk_error_queue);\r\nWARN_ON(!skb_queue_empty(&sk->sk_write_queue));\r\nsk_mem_reclaim(sk);\r\nWARN_ON(sk->sk_wmem_queued);\r\nWARN_ON(sk->sk_forward_alloc);\r\n}
