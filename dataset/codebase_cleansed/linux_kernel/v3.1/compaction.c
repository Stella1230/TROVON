static unsigned long release_freepages(struct list_head *freelist)\r\n{\r\nstruct page *page, *next;\r\nunsigned long count = 0;\r\nlist_for_each_entry_safe(page, next, freelist, lru) {\r\nlist_del(&page->lru);\r\n__free_page(page);\r\ncount++;\r\n}\r\nreturn count;\r\n}\r\nstatic unsigned long isolate_freepages_block(struct zone *zone,\r\nunsigned long blockpfn,\r\nstruct list_head *freelist)\r\n{\r\nunsigned long zone_end_pfn, end_pfn;\r\nint nr_scanned = 0, total_isolated = 0;\r\nstruct page *cursor;\r\nzone_end_pfn = zone->zone_start_pfn + zone->spanned_pages;\r\nend_pfn = min(blockpfn + pageblock_nr_pages, zone_end_pfn);\r\nfor (; blockpfn < end_pfn; blockpfn++) {\r\nif (pfn_valid_within(blockpfn))\r\nbreak;\r\n}\r\ncursor = pfn_to_page(blockpfn);\r\nfor (; blockpfn < end_pfn; blockpfn++, cursor++) {\r\nint isolated, i;\r\nstruct page *page = cursor;\r\nif (!pfn_valid_within(blockpfn))\r\ncontinue;\r\nnr_scanned++;\r\nif (!PageBuddy(page))\r\ncontinue;\r\nisolated = split_free_page(page);\r\ntotal_isolated += isolated;\r\nfor (i = 0; i < isolated; i++) {\r\nlist_add(&page->lru, freelist);\r\npage++;\r\n}\r\nif (isolated) {\r\nblockpfn += isolated - 1;\r\ncursor += isolated - 1;\r\n}\r\n}\r\ntrace_mm_compaction_isolate_freepages(nr_scanned, total_isolated);\r\nreturn total_isolated;\r\n}\r\nstatic bool suitable_migration_target(struct page *page)\r\n{\r\nint migratetype = get_pageblock_migratetype(page);\r\nif (migratetype == MIGRATE_ISOLATE || migratetype == MIGRATE_RESERVE)\r\nreturn false;\r\nif (PageBuddy(page) && page_order(page) >= pageblock_order)\r\nreturn true;\r\nif (migratetype == MIGRATE_MOVABLE)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void isolate_freepages(struct zone *zone,\r\nstruct compact_control *cc)\r\n{\r\nstruct page *page;\r\nunsigned long high_pfn, low_pfn, pfn;\r\nunsigned long flags;\r\nint nr_freepages = cc->nr_freepages;\r\nstruct list_head *freelist = &cc->freepages;\r\npfn = cc->free_pfn;\r\nlow_pfn = cc->migrate_pfn + pageblock_nr_pages;\r\nhigh_pfn = min(low_pfn, pfn);\r\nfor (; pfn > low_pfn && cc->nr_migratepages > nr_freepages;\r\npfn -= pageblock_nr_pages) {\r\nunsigned long isolated;\r\nif (!pfn_valid(pfn))\r\ncontinue;\r\npage = pfn_to_page(pfn);\r\nif (page_zone(page) != zone)\r\ncontinue;\r\nif (!suitable_migration_target(page))\r\ncontinue;\r\nisolated = 0;\r\nspin_lock_irqsave(&zone->lock, flags);\r\nif (suitable_migration_target(page)) {\r\nisolated = isolate_freepages_block(zone, pfn, freelist);\r\nnr_freepages += isolated;\r\n}\r\nspin_unlock_irqrestore(&zone->lock, flags);\r\nif (isolated)\r\nhigh_pfn = max(high_pfn, pfn);\r\n}\r\nlist_for_each_entry(page, freelist, lru) {\r\narch_alloc_page(page, 0);\r\nkernel_map_pages(page, 1, 1);\r\n}\r\ncc->free_pfn = high_pfn;\r\ncc->nr_freepages = nr_freepages;\r\n}\r\nstatic void acct_isolated(struct zone *zone, struct compact_control *cc)\r\n{\r\nstruct page *page;\r\nunsigned int count[NR_LRU_LISTS] = { 0, };\r\nlist_for_each_entry(page, &cc->migratepages, lru) {\r\nint lru = page_lru_base_type(page);\r\ncount[lru]++;\r\n}\r\ncc->nr_anon = count[LRU_ACTIVE_ANON] + count[LRU_INACTIVE_ANON];\r\ncc->nr_file = count[LRU_ACTIVE_FILE] + count[LRU_INACTIVE_FILE];\r\n__mod_zone_page_state(zone, NR_ISOLATED_ANON, cc->nr_anon);\r\n__mod_zone_page_state(zone, NR_ISOLATED_FILE, cc->nr_file);\r\n}\r\nstatic bool too_many_isolated(struct zone *zone)\r\n{\r\nunsigned long active, inactive, isolated;\r\ninactive = zone_page_state(zone, NR_INACTIVE_FILE) +\r\nzone_page_state(zone, NR_INACTIVE_ANON);\r\nactive = zone_page_state(zone, NR_ACTIVE_FILE) +\r\nzone_page_state(zone, NR_ACTIVE_ANON);\r\nisolated = zone_page_state(zone, NR_ISOLATED_FILE) +\r\nzone_page_state(zone, NR_ISOLATED_ANON);\r\nreturn isolated > (inactive + active) / 2;\r\n}\r\nstatic isolate_migrate_t isolate_migratepages(struct zone *zone,\r\nstruct compact_control *cc)\r\n{\r\nunsigned long low_pfn, end_pfn;\r\nunsigned long last_pageblock_nr = 0, pageblock_nr;\r\nunsigned long nr_scanned = 0, nr_isolated = 0;\r\nstruct list_head *migratelist = &cc->migratepages;\r\nlow_pfn = max(cc->migrate_pfn, zone->zone_start_pfn);\r\nend_pfn = ALIGN(low_pfn + pageblock_nr_pages, pageblock_nr_pages);\r\nif (end_pfn > cc->free_pfn || !pfn_valid(low_pfn)) {\r\ncc->migrate_pfn = end_pfn;\r\nreturn ISOLATE_NONE;\r\n}\r\nwhile (unlikely(too_many_isolated(zone))) {\r\nif (!cc->sync)\r\nreturn ISOLATE_ABORT;\r\ncongestion_wait(BLK_RW_ASYNC, HZ/10);\r\nif (fatal_signal_pending(current))\r\nreturn ISOLATE_ABORT;\r\n}\r\ncond_resched();\r\nspin_lock_irq(&zone->lru_lock);\r\nfor (; low_pfn < end_pfn; low_pfn++) {\r\nstruct page *page;\r\nbool locked = true;\r\nif (!((low_pfn+1) % SWAP_CLUSTER_MAX)) {\r\nspin_unlock_irq(&zone->lru_lock);\r\nlocked = false;\r\n}\r\nif (need_resched() || spin_is_contended(&zone->lru_lock)) {\r\nif (locked)\r\nspin_unlock_irq(&zone->lru_lock);\r\ncond_resched();\r\nspin_lock_irq(&zone->lru_lock);\r\nif (fatal_signal_pending(current))\r\nbreak;\r\n} else if (!locked)\r\nspin_lock_irq(&zone->lru_lock);\r\nif (!pfn_valid_within(low_pfn))\r\ncontinue;\r\nnr_scanned++;\r\npage = pfn_to_page(low_pfn);\r\nif (PageBuddy(page))\r\ncontinue;\r\npageblock_nr = low_pfn >> pageblock_order;\r\nif (!cc->sync && last_pageblock_nr != pageblock_nr &&\r\nget_pageblock_migratetype(page) != MIGRATE_MOVABLE) {\r\nlow_pfn += pageblock_nr_pages;\r\nlow_pfn = ALIGN(low_pfn, pageblock_nr_pages) - 1;\r\nlast_pageblock_nr = pageblock_nr;\r\ncontinue;\r\n}\r\nif (!PageLRU(page))\r\ncontinue;\r\nif (PageTransHuge(page)) {\r\nlow_pfn += (1 << compound_order(page)) - 1;\r\ncontinue;\r\n}\r\nif (__isolate_lru_page(page, ISOLATE_BOTH, 0) != 0)\r\ncontinue;\r\nVM_BUG_ON(PageTransCompound(page));\r\ndel_page_from_lru_list(zone, page, page_lru(page));\r\nlist_add(&page->lru, migratelist);\r\ncc->nr_migratepages++;\r\nnr_isolated++;\r\nif (cc->nr_migratepages == COMPACT_CLUSTER_MAX)\r\nbreak;\r\n}\r\nacct_isolated(zone, cc);\r\nspin_unlock_irq(&zone->lru_lock);\r\ncc->migrate_pfn = low_pfn;\r\ntrace_mm_compaction_isolate_migratepages(nr_scanned, nr_isolated);\r\nreturn ISOLATE_SUCCESS;\r\n}\r\nstatic struct page *compaction_alloc(struct page *migratepage,\r\nunsigned long data,\r\nint **result)\r\n{\r\nstruct compact_control *cc = (struct compact_control *)data;\r\nstruct page *freepage;\r\nif (list_empty(&cc->freepages)) {\r\nisolate_freepages(cc->zone, cc);\r\nif (list_empty(&cc->freepages))\r\nreturn NULL;\r\n}\r\nfreepage = list_entry(cc->freepages.next, struct page, lru);\r\nlist_del(&freepage->lru);\r\ncc->nr_freepages--;\r\nreturn freepage;\r\n}\r\nstatic void update_nr_listpages(struct compact_control *cc)\r\n{\r\nint nr_migratepages = 0;\r\nint nr_freepages = 0;\r\nstruct page *page;\r\nlist_for_each_entry(page, &cc->migratepages, lru)\r\nnr_migratepages++;\r\nlist_for_each_entry(page, &cc->freepages, lru)\r\nnr_freepages++;\r\ncc->nr_migratepages = nr_migratepages;\r\ncc->nr_freepages = nr_freepages;\r\n}\r\nstatic int compact_finished(struct zone *zone,\r\nstruct compact_control *cc)\r\n{\r\nunsigned int order;\r\nunsigned long watermark;\r\nif (fatal_signal_pending(current))\r\nreturn COMPACT_PARTIAL;\r\nif (cc->free_pfn <= cc->migrate_pfn)\r\nreturn COMPACT_COMPLETE;\r\nif (cc->order == -1)\r\nreturn COMPACT_CONTINUE;\r\nwatermark = low_wmark_pages(zone);\r\nwatermark += (1 << cc->order);\r\nif (!zone_watermark_ok(zone, cc->order, watermark, 0, 0))\r\nreturn COMPACT_CONTINUE;\r\nfor (order = cc->order; order < MAX_ORDER; order++) {\r\nif (!list_empty(&zone->free_area[order].free_list[cc->migratetype]))\r\nreturn COMPACT_PARTIAL;\r\nif (order >= pageblock_order && zone->free_area[order].nr_free)\r\nreturn COMPACT_PARTIAL;\r\n}\r\nreturn COMPACT_CONTINUE;\r\n}\r\nunsigned long compaction_suitable(struct zone *zone, int order)\r\n{\r\nint fragindex;\r\nunsigned long watermark;\r\nif (order == -1)\r\nreturn COMPACT_CONTINUE;\r\nwatermark = low_wmark_pages(zone) + (2UL << order);\r\nif (!zone_watermark_ok(zone, 0, watermark, 0, 0))\r\nreturn COMPACT_SKIPPED;\r\nfragindex = fragmentation_index(zone, order);\r\nif (fragindex >= 0 && fragindex <= sysctl_extfrag_threshold)\r\nreturn COMPACT_SKIPPED;\r\nif (fragindex == -1000 && zone_watermark_ok(zone, order, watermark,\r\n0, 0))\r\nreturn COMPACT_PARTIAL;\r\nreturn COMPACT_CONTINUE;\r\n}\r\nstatic int compact_zone(struct zone *zone, struct compact_control *cc)\r\n{\r\nint ret;\r\nret = compaction_suitable(zone, cc->order);\r\nswitch (ret) {\r\ncase COMPACT_PARTIAL:\r\ncase COMPACT_SKIPPED:\r\nreturn ret;\r\ncase COMPACT_CONTINUE:\r\n;\r\n}\r\ncc->migrate_pfn = zone->zone_start_pfn;\r\ncc->free_pfn = cc->migrate_pfn + zone->spanned_pages;\r\ncc->free_pfn &= ~(pageblock_nr_pages-1);\r\nmigrate_prep_local();\r\nwhile ((ret = compact_finished(zone, cc)) == COMPACT_CONTINUE) {\r\nunsigned long nr_migrate, nr_remaining;\r\nint err;\r\nswitch (isolate_migratepages(zone, cc)) {\r\ncase ISOLATE_ABORT:\r\nret = COMPACT_PARTIAL;\r\ngoto out;\r\ncase ISOLATE_NONE:\r\ncontinue;\r\ncase ISOLATE_SUCCESS:\r\n;\r\n}\r\nnr_migrate = cc->nr_migratepages;\r\nerr = migrate_pages(&cc->migratepages, compaction_alloc,\r\n(unsigned long)cc, false,\r\ncc->sync);\r\nupdate_nr_listpages(cc);\r\nnr_remaining = cc->nr_migratepages;\r\ncount_vm_event(COMPACTBLOCKS);\r\ncount_vm_events(COMPACTPAGES, nr_migrate - nr_remaining);\r\nif (nr_remaining)\r\ncount_vm_events(COMPACTPAGEFAILED, nr_remaining);\r\ntrace_mm_compaction_migratepages(nr_migrate - nr_remaining,\r\nnr_remaining);\r\nif (err) {\r\nputback_lru_pages(&cc->migratepages);\r\ncc->nr_migratepages = 0;\r\n}\r\n}\r\nout:\r\ncc->nr_freepages -= release_freepages(&cc->freepages);\r\nVM_BUG_ON(cc->nr_freepages != 0);\r\nreturn ret;\r\n}\r\nunsigned long compact_zone_order(struct zone *zone,\r\nint order, gfp_t gfp_mask,\r\nbool sync)\r\n{\r\nstruct compact_control cc = {\r\n.nr_freepages = 0,\r\n.nr_migratepages = 0,\r\n.order = order,\r\n.migratetype = allocflags_to_migratetype(gfp_mask),\r\n.zone = zone,\r\n.sync = sync,\r\n};\r\nINIT_LIST_HEAD(&cc.freepages);\r\nINIT_LIST_HEAD(&cc.migratepages);\r\nreturn compact_zone(zone, &cc);\r\n}\r\nunsigned long try_to_compact_pages(struct zonelist *zonelist,\r\nint order, gfp_t gfp_mask, nodemask_t *nodemask,\r\nbool sync)\r\n{\r\nenum zone_type high_zoneidx = gfp_zone(gfp_mask);\r\nint may_enter_fs = gfp_mask & __GFP_FS;\r\nint may_perform_io = gfp_mask & __GFP_IO;\r\nstruct zoneref *z;\r\nstruct zone *zone;\r\nint rc = COMPACT_SKIPPED;\r\nif (!order || !may_enter_fs || !may_perform_io)\r\nreturn rc;\r\ncount_vm_event(COMPACTSTALL);\r\nfor_each_zone_zonelist_nodemask(zone, z, zonelist, high_zoneidx,\r\nnodemask) {\r\nint status;\r\nstatus = compact_zone_order(zone, order, gfp_mask, sync);\r\nrc = max(status, rc);\r\nif (zone_watermark_ok(zone, order, low_wmark_pages(zone), 0, 0))\r\nbreak;\r\n}\r\nreturn rc;\r\n}\r\nstatic int compact_node(int nid)\r\n{\r\nint zoneid;\r\npg_data_t *pgdat;\r\nstruct zone *zone;\r\nif (nid < 0 || nid >= nr_node_ids || !node_online(nid))\r\nreturn -EINVAL;\r\npgdat = NODE_DATA(nid);\r\nlru_add_drain_all();\r\nfor (zoneid = 0; zoneid < MAX_NR_ZONES; zoneid++) {\r\nstruct compact_control cc = {\r\n.nr_freepages = 0,\r\n.nr_migratepages = 0,\r\n.order = -1,\r\n};\r\nzone = &pgdat->node_zones[zoneid];\r\nif (!populated_zone(zone))\r\ncontinue;\r\ncc.zone = zone;\r\nINIT_LIST_HEAD(&cc.freepages);\r\nINIT_LIST_HEAD(&cc.migratepages);\r\ncompact_zone(zone, &cc);\r\nVM_BUG_ON(!list_empty(&cc.freepages));\r\nVM_BUG_ON(!list_empty(&cc.migratepages));\r\n}\r\nreturn 0;\r\n}\r\nstatic int compact_nodes(void)\r\n{\r\nint nid;\r\nfor_each_online_node(nid)\r\ncompact_node(nid);\r\nreturn COMPACT_COMPLETE;\r\n}\r\nint sysctl_compaction_handler(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *length, loff_t *ppos)\r\n{\r\nif (write)\r\nreturn compact_nodes();\r\nreturn 0;\r\n}\r\nint sysctl_extfrag_handler(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *length, loff_t *ppos)\r\n{\r\nproc_dointvec_minmax(table, write, buffer, length, ppos);\r\nreturn 0;\r\n}\r\nssize_t sysfs_compact_node(struct sys_device *dev,\r\nstruct sysdev_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\ncompact_node(dev->id);\r\nreturn count;\r\n}\r\nint compaction_register_node(struct node *node)\r\n{\r\nreturn sysdev_create_file(&node->sysdev, &attr_compact);\r\n}\r\nvoid compaction_unregister_node(struct node *node)\r\n{\r\nreturn sysdev_remove_file(&node->sysdev, &attr_compact);\r\n}
