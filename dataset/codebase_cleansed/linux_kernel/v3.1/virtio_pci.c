static struct virtio_pci_device *to_vp_device(struct virtio_device *vdev)\r\n{\r\nreturn container_of(vdev, struct virtio_pci_device, vdev);\r\n}\r\nstatic u32 vp_get_features(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nreturn ioread32(vp_dev->ioaddr + VIRTIO_PCI_HOST_FEATURES);\r\n}\r\nstatic void vp_finalize_features(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nvring_transport_features(vdev);\r\nBUILD_BUG_ON(ARRAY_SIZE(vdev->features) != 1);\r\niowrite32(vdev->features[0], vp_dev->ioaddr+VIRTIO_PCI_GUEST_FEATURES);\r\n}\r\nstatic void vp_get(struct virtio_device *vdev, unsigned offset,\r\nvoid *buf, unsigned len)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nvoid __iomem *ioaddr = vp_dev->ioaddr +\r\nVIRTIO_PCI_CONFIG(vp_dev) + offset;\r\nu8 *ptr = buf;\r\nint i;\r\nfor (i = 0; i < len; i++)\r\nptr[i] = ioread8(ioaddr + i);\r\n}\r\nstatic void vp_set(struct virtio_device *vdev, unsigned offset,\r\nconst void *buf, unsigned len)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nvoid __iomem *ioaddr = vp_dev->ioaddr +\r\nVIRTIO_PCI_CONFIG(vp_dev) + offset;\r\nconst u8 *ptr = buf;\r\nint i;\r\nfor (i = 0; i < len; i++)\r\niowrite8(ptr[i], ioaddr + i);\r\n}\r\nstatic u8 vp_get_status(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nreturn ioread8(vp_dev->ioaddr + VIRTIO_PCI_STATUS);\r\n}\r\nstatic void vp_set_status(struct virtio_device *vdev, u8 status)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nBUG_ON(status == 0);\r\niowrite8(status, vp_dev->ioaddr + VIRTIO_PCI_STATUS);\r\n}\r\nstatic void vp_reset(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\niowrite8(0, vp_dev->ioaddr + VIRTIO_PCI_STATUS);\r\n}\r\nstatic void vp_notify(struct virtqueue *vq)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\r\nstruct virtio_pci_vq_info *info = vq->priv;\r\niowrite16(info->queue_index, vp_dev->ioaddr + VIRTIO_PCI_QUEUE_NOTIFY);\r\n}\r\nstatic irqreturn_t vp_config_changed(int irq, void *opaque)\r\n{\r\nstruct virtio_pci_device *vp_dev = opaque;\r\nstruct virtio_driver *drv;\r\ndrv = container_of(vp_dev->vdev.dev.driver,\r\nstruct virtio_driver, driver);\r\nif (drv && drv->config_changed)\r\ndrv->config_changed(&vp_dev->vdev);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t vp_vring_interrupt(int irq, void *opaque)\r\n{\r\nstruct virtio_pci_device *vp_dev = opaque;\r\nstruct virtio_pci_vq_info *info;\r\nirqreturn_t ret = IRQ_NONE;\r\nunsigned long flags;\r\nspin_lock_irqsave(&vp_dev->lock, flags);\r\nlist_for_each_entry(info, &vp_dev->virtqueues, node) {\r\nif (vring_interrupt(irq, info->vq) == IRQ_HANDLED)\r\nret = IRQ_HANDLED;\r\n}\r\nspin_unlock_irqrestore(&vp_dev->lock, flags);\r\nreturn ret;\r\n}\r\nstatic irqreturn_t vp_interrupt(int irq, void *opaque)\r\n{\r\nstruct virtio_pci_device *vp_dev = opaque;\r\nu8 isr;\r\nisr = ioread8(vp_dev->ioaddr + VIRTIO_PCI_ISR);\r\nif (!isr)\r\nreturn IRQ_NONE;\r\nif (isr & VIRTIO_PCI_ISR_CONFIG)\r\nvp_config_changed(irq, opaque);\r\nreturn vp_vring_interrupt(irq, opaque);\r\n}\r\nstatic void vp_free_vectors(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nint i;\r\nif (vp_dev->intx_enabled) {\r\nfree_irq(vp_dev->pci_dev->irq, vp_dev);\r\nvp_dev->intx_enabled = 0;\r\n}\r\nfor (i = 0; i < vp_dev->msix_used_vectors; ++i)\r\nfree_irq(vp_dev->msix_entries[i].vector, vp_dev);\r\nif (vp_dev->msix_enabled) {\r\niowrite16(VIRTIO_MSI_NO_VECTOR,\r\nvp_dev->ioaddr + VIRTIO_MSI_CONFIG_VECTOR);\r\nioread16(vp_dev->ioaddr + VIRTIO_MSI_CONFIG_VECTOR);\r\npci_disable_msix(vp_dev->pci_dev);\r\nvp_dev->msix_enabled = 0;\r\nvp_dev->msix_vectors = 0;\r\n}\r\nvp_dev->msix_used_vectors = 0;\r\nkfree(vp_dev->msix_names);\r\nvp_dev->msix_names = NULL;\r\nkfree(vp_dev->msix_entries);\r\nvp_dev->msix_entries = NULL;\r\n}\r\nstatic int vp_request_msix_vectors(struct virtio_device *vdev, int nvectors,\r\nbool per_vq_vectors)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nconst char *name = dev_name(&vp_dev->vdev.dev);\r\nunsigned i, v;\r\nint err = -ENOMEM;\r\nvp_dev->msix_entries = kmalloc(nvectors * sizeof *vp_dev->msix_entries,\r\nGFP_KERNEL);\r\nif (!vp_dev->msix_entries)\r\ngoto error;\r\nvp_dev->msix_names = kmalloc(nvectors * sizeof *vp_dev->msix_names,\r\nGFP_KERNEL);\r\nif (!vp_dev->msix_names)\r\ngoto error;\r\nfor (i = 0; i < nvectors; ++i)\r\nvp_dev->msix_entries[i].entry = i;\r\nerr = pci_enable_msix(vp_dev->pci_dev, vp_dev->msix_entries, nvectors);\r\nif (err > 0)\r\nerr = -ENOSPC;\r\nif (err)\r\ngoto error;\r\nvp_dev->msix_vectors = nvectors;\r\nvp_dev->msix_enabled = 1;\r\nv = vp_dev->msix_used_vectors;\r\nsnprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,\r\n"%s-config", name);\r\nerr = request_irq(vp_dev->msix_entries[v].vector,\r\nvp_config_changed, 0, vp_dev->msix_names[v],\r\nvp_dev);\r\nif (err)\r\ngoto error;\r\n++vp_dev->msix_used_vectors;\r\niowrite16(v, vp_dev->ioaddr + VIRTIO_MSI_CONFIG_VECTOR);\r\nv = ioread16(vp_dev->ioaddr + VIRTIO_MSI_CONFIG_VECTOR);\r\nif (v == VIRTIO_MSI_NO_VECTOR) {\r\nerr = -EBUSY;\r\ngoto error;\r\n}\r\nif (!per_vq_vectors) {\r\nv = vp_dev->msix_used_vectors;\r\nsnprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,\r\n"%s-virtqueues", name);\r\nerr = request_irq(vp_dev->msix_entries[v].vector,\r\nvp_vring_interrupt, 0, vp_dev->msix_names[v],\r\nvp_dev);\r\nif (err)\r\ngoto error;\r\n++vp_dev->msix_used_vectors;\r\n}\r\nreturn 0;\r\nerror:\r\nvp_free_vectors(vdev);\r\nreturn err;\r\n}\r\nstatic int vp_request_intx(struct virtio_device *vdev)\r\n{\r\nint err;\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nerr = request_irq(vp_dev->pci_dev->irq, vp_interrupt,\r\nIRQF_SHARED, dev_name(&vdev->dev), vp_dev);\r\nif (!err)\r\nvp_dev->intx_enabled = 1;\r\nreturn err;\r\n}\r\nstatic struct virtqueue *setup_vq(struct virtio_device *vdev, unsigned index,\r\nvoid (*callback)(struct virtqueue *vq),\r\nconst char *name,\r\nu16 msix_vec)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nstruct virtio_pci_vq_info *info;\r\nstruct virtqueue *vq;\r\nunsigned long flags, size;\r\nu16 num;\r\nint err;\r\niowrite16(index, vp_dev->ioaddr + VIRTIO_PCI_QUEUE_SEL);\r\nnum = ioread16(vp_dev->ioaddr + VIRTIO_PCI_QUEUE_NUM);\r\nif (!num || ioread32(vp_dev->ioaddr + VIRTIO_PCI_QUEUE_PFN))\r\nreturn ERR_PTR(-ENOENT);\r\ninfo = kmalloc(sizeof(struct virtio_pci_vq_info), GFP_KERNEL);\r\nif (!info)\r\nreturn ERR_PTR(-ENOMEM);\r\ninfo->queue_index = index;\r\ninfo->num = num;\r\ninfo->msix_vector = msix_vec;\r\nsize = PAGE_ALIGN(vring_size(num, VIRTIO_PCI_VRING_ALIGN));\r\ninfo->queue = alloc_pages_exact(size, GFP_KERNEL|__GFP_ZERO);\r\nif (info->queue == NULL) {\r\nerr = -ENOMEM;\r\ngoto out_info;\r\n}\r\niowrite32(virt_to_phys(info->queue) >> VIRTIO_PCI_QUEUE_ADDR_SHIFT,\r\nvp_dev->ioaddr + VIRTIO_PCI_QUEUE_PFN);\r\nvq = vring_new_virtqueue(info->num, VIRTIO_PCI_VRING_ALIGN,\r\nvdev, info->queue, vp_notify, callback, name);\r\nif (!vq) {\r\nerr = -ENOMEM;\r\ngoto out_activate_queue;\r\n}\r\nvq->priv = info;\r\ninfo->vq = vq;\r\nif (msix_vec != VIRTIO_MSI_NO_VECTOR) {\r\niowrite16(msix_vec, vp_dev->ioaddr + VIRTIO_MSI_QUEUE_VECTOR);\r\nmsix_vec = ioread16(vp_dev->ioaddr + VIRTIO_MSI_QUEUE_VECTOR);\r\nif (msix_vec == VIRTIO_MSI_NO_VECTOR) {\r\nerr = -EBUSY;\r\ngoto out_assign;\r\n}\r\n}\r\nspin_lock_irqsave(&vp_dev->lock, flags);\r\nlist_add(&info->node, &vp_dev->virtqueues);\r\nspin_unlock_irqrestore(&vp_dev->lock, flags);\r\nreturn vq;\r\nout_assign:\r\nvring_del_virtqueue(vq);\r\nout_activate_queue:\r\niowrite32(0, vp_dev->ioaddr + VIRTIO_PCI_QUEUE_PFN);\r\nfree_pages_exact(info->queue, size);\r\nout_info:\r\nkfree(info);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic void vp_del_vq(struct virtqueue *vq)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\r\nstruct virtio_pci_vq_info *info = vq->priv;\r\nunsigned long flags, size;\r\nspin_lock_irqsave(&vp_dev->lock, flags);\r\nlist_del(&info->node);\r\nspin_unlock_irqrestore(&vp_dev->lock, flags);\r\niowrite16(info->queue_index, vp_dev->ioaddr + VIRTIO_PCI_QUEUE_SEL);\r\nif (vp_dev->msix_enabled) {\r\niowrite16(VIRTIO_MSI_NO_VECTOR,\r\nvp_dev->ioaddr + VIRTIO_MSI_QUEUE_VECTOR);\r\nioread8(vp_dev->ioaddr + VIRTIO_PCI_ISR);\r\n}\r\nvring_del_virtqueue(vq);\r\niowrite32(0, vp_dev->ioaddr + VIRTIO_PCI_QUEUE_PFN);\r\nsize = PAGE_ALIGN(vring_size(info->num, VIRTIO_PCI_VRING_ALIGN));\r\nfree_pages_exact(info->queue, size);\r\nkfree(info);\r\n}\r\nstatic void vp_del_vqs(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nstruct virtqueue *vq, *n;\r\nstruct virtio_pci_vq_info *info;\r\nlist_for_each_entry_safe(vq, n, &vdev->vqs, list) {\r\ninfo = vq->priv;\r\nif (vp_dev->per_vq_vectors &&\r\ninfo->msix_vector != VIRTIO_MSI_NO_VECTOR)\r\nfree_irq(vp_dev->msix_entries[info->msix_vector].vector,\r\nvq);\r\nvp_del_vq(vq);\r\n}\r\nvp_dev->per_vq_vectors = false;\r\nvp_free_vectors(vdev);\r\n}\r\nstatic int vp_try_to_find_vqs(struct virtio_device *vdev, unsigned nvqs,\r\nstruct virtqueue *vqs[],\r\nvq_callback_t *callbacks[],\r\nconst char *names[],\r\nbool use_msix,\r\nbool per_vq_vectors)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nu16 msix_vec;\r\nint i, err, nvectors, allocated_vectors;\r\nif (!use_msix) {\r\nerr = vp_request_intx(vdev);\r\nif (err)\r\ngoto error_request;\r\n} else {\r\nif (per_vq_vectors) {\r\nnvectors = 1;\r\nfor (i = 0; i < nvqs; ++i)\r\nif (callbacks[i])\r\n++nvectors;\r\n} else {\r\nnvectors = 2;\r\n}\r\nerr = vp_request_msix_vectors(vdev, nvectors, per_vq_vectors);\r\nif (err)\r\ngoto error_request;\r\n}\r\nvp_dev->per_vq_vectors = per_vq_vectors;\r\nallocated_vectors = vp_dev->msix_used_vectors;\r\nfor (i = 0; i < nvqs; ++i) {\r\nif (!callbacks[i] || !vp_dev->msix_enabled)\r\nmsix_vec = VIRTIO_MSI_NO_VECTOR;\r\nelse if (vp_dev->per_vq_vectors)\r\nmsix_vec = allocated_vectors++;\r\nelse\r\nmsix_vec = VP_MSIX_VQ_VECTOR;\r\nvqs[i] = setup_vq(vdev, i, callbacks[i], names[i], msix_vec);\r\nif (IS_ERR(vqs[i])) {\r\nerr = PTR_ERR(vqs[i]);\r\ngoto error_find;\r\n}\r\nif (!vp_dev->per_vq_vectors || msix_vec == VIRTIO_MSI_NO_VECTOR)\r\ncontinue;\r\nsnprintf(vp_dev->msix_names[msix_vec],\r\nsizeof *vp_dev->msix_names,\r\n"%s-%s",\r\ndev_name(&vp_dev->vdev.dev), names[i]);\r\nerr = request_irq(vp_dev->msix_entries[msix_vec].vector,\r\nvring_interrupt, 0,\r\nvp_dev->msix_names[msix_vec],\r\nvqs[i]);\r\nif (err) {\r\nvp_del_vq(vqs[i]);\r\ngoto error_find;\r\n}\r\n}\r\nreturn 0;\r\nerror_find:\r\nvp_del_vqs(vdev);\r\nerror_request:\r\nreturn err;\r\n}\r\nstatic int vp_find_vqs(struct virtio_device *vdev, unsigned nvqs,\r\nstruct virtqueue *vqs[],\r\nvq_callback_t *callbacks[],\r\nconst char *names[])\r\n{\r\nint err;\r\nerr = vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names, true, true);\r\nif (!err)\r\nreturn 0;\r\nerr = vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names,\r\ntrue, false);\r\nif (!err)\r\nreturn 0;\r\nreturn vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names,\r\nfalse, false);\r\n}\r\nstatic void virtio_pci_release_dev(struct device *_d)\r\n{\r\nstruct virtio_device *dev = container_of(_d, struct virtio_device,\r\ndev);\r\nstruct virtio_pci_device *vp_dev = to_vp_device(dev);\r\nkfree(vp_dev);\r\n}\r\nstatic int __devinit virtio_pci_probe(struct pci_dev *pci_dev,\r\nconst struct pci_device_id *id)\r\n{\r\nstruct virtio_pci_device *vp_dev;\r\nint err;\r\nif (pci_dev->device < 0x1000 || pci_dev->device > 0x103f)\r\nreturn -ENODEV;\r\nif (pci_dev->revision != VIRTIO_PCI_ABI_VERSION) {\r\nprintk(KERN_ERR "virtio_pci: expected ABI version %d, got %d\n",\r\nVIRTIO_PCI_ABI_VERSION, pci_dev->revision);\r\nreturn -ENODEV;\r\n}\r\nvp_dev = kzalloc(sizeof(struct virtio_pci_device), GFP_KERNEL);\r\nif (vp_dev == NULL)\r\nreturn -ENOMEM;\r\nvp_dev->vdev.dev.parent = &pci_dev->dev;\r\nvp_dev->vdev.dev.release = virtio_pci_release_dev;\r\nvp_dev->vdev.config = &virtio_pci_config_ops;\r\nvp_dev->pci_dev = pci_dev;\r\nINIT_LIST_HEAD(&vp_dev->virtqueues);\r\nspin_lock_init(&vp_dev->lock);\r\npci_msi_off(pci_dev);\r\nerr = pci_enable_device(pci_dev);\r\nif (err)\r\ngoto out;\r\nerr = pci_request_regions(pci_dev, "virtio-pci");\r\nif (err)\r\ngoto out_enable_device;\r\nvp_dev->ioaddr = pci_iomap(pci_dev, 0, 0);\r\nif (vp_dev->ioaddr == NULL)\r\ngoto out_req_regions;\r\npci_set_drvdata(pci_dev, vp_dev);\r\npci_set_master(pci_dev);\r\nvp_dev->vdev.id.vendor = pci_dev->subsystem_vendor;\r\nvp_dev->vdev.id.device = pci_dev->subsystem_device;\r\nerr = register_virtio_device(&vp_dev->vdev);\r\nif (err)\r\ngoto out_set_drvdata;\r\nreturn 0;\r\nout_set_drvdata:\r\npci_set_drvdata(pci_dev, NULL);\r\npci_iounmap(pci_dev, vp_dev->ioaddr);\r\nout_req_regions:\r\npci_release_regions(pci_dev);\r\nout_enable_device:\r\npci_disable_device(pci_dev);\r\nout:\r\nkfree(vp_dev);\r\nreturn err;\r\n}\r\nstatic void __devexit virtio_pci_remove(struct pci_dev *pci_dev)\r\n{\r\nstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\r\nunregister_virtio_device(&vp_dev->vdev);\r\nvp_del_vqs(&vp_dev->vdev);\r\npci_set_drvdata(pci_dev, NULL);\r\npci_iounmap(pci_dev, vp_dev->ioaddr);\r\npci_release_regions(pci_dev);\r\npci_disable_device(pci_dev);\r\n}\r\nstatic int virtio_pci_suspend(struct pci_dev *pci_dev, pm_message_t state)\r\n{\r\npci_save_state(pci_dev);\r\npci_set_power_state(pci_dev, PCI_D3hot);\r\nreturn 0;\r\n}\r\nstatic int virtio_pci_resume(struct pci_dev *pci_dev)\r\n{\r\npci_restore_state(pci_dev);\r\npci_set_power_state(pci_dev, PCI_D0);\r\nreturn 0;\r\n}\r\nstatic int __init virtio_pci_init(void)\r\n{\r\nreturn pci_register_driver(&virtio_pci_driver);\r\n}\r\nstatic void __exit virtio_pci_exit(void)\r\n{\r\npci_unregister_driver(&virtio_pci_driver);\r\n}
