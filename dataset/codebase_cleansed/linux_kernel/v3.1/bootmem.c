static int __init bootmem_debug_setup(char *buf)\r\n{\r\nbootmem_debug = 1;\r\nreturn 0;\r\n}\r\nstatic unsigned long __init bootmap_bytes(unsigned long pages)\r\n{\r\nunsigned long bytes = (pages + 7) / 8;\r\nreturn ALIGN(bytes, sizeof(long));\r\n}\r\nunsigned long __init bootmem_bootmap_pages(unsigned long pages)\r\n{\r\nunsigned long bytes = bootmap_bytes(pages);\r\nreturn PAGE_ALIGN(bytes) >> PAGE_SHIFT;\r\n}\r\nstatic void __init link_bootmem(bootmem_data_t *bdata)\r\n{\r\nstruct list_head *iter;\r\nlist_for_each(iter, &bdata_list) {\r\nbootmem_data_t *ent;\r\nent = list_entry(iter, bootmem_data_t, list);\r\nif (bdata->node_min_pfn < ent->node_min_pfn)\r\nbreak;\r\n}\r\nlist_add_tail(&bdata->list, iter);\r\n}\r\nstatic unsigned long __init init_bootmem_core(bootmem_data_t *bdata,\r\nunsigned long mapstart, unsigned long start, unsigned long end)\r\n{\r\nunsigned long mapsize;\r\nmminit_validate_memmodel_limits(&start, &end);\r\nbdata->node_bootmem_map = phys_to_virt(PFN_PHYS(mapstart));\r\nbdata->node_min_pfn = start;\r\nbdata->node_low_pfn = end;\r\nlink_bootmem(bdata);\r\nmapsize = bootmap_bytes(end - start);\r\nmemset(bdata->node_bootmem_map, 0xff, mapsize);\r\nbdebug("nid=%td start=%lx map=%lx end=%lx mapsize=%lx\n",\r\nbdata - bootmem_node_data, start, mapstart, end, mapsize);\r\nreturn mapsize;\r\n}\r\nunsigned long __init init_bootmem_node(pg_data_t *pgdat, unsigned long freepfn,\r\nunsigned long startpfn, unsigned long endpfn)\r\n{\r\nreturn init_bootmem_core(pgdat->bdata, freepfn, startpfn, endpfn);\r\n}\r\nunsigned long __init init_bootmem(unsigned long start, unsigned long pages)\r\n{\r\nmax_low_pfn = pages;\r\nmin_low_pfn = start;\r\nreturn init_bootmem_core(NODE_DATA(0)->bdata, start, 0, pages);\r\n}\r\nvoid __init free_bootmem_late(unsigned long addr, unsigned long size)\r\n{\r\nunsigned long cursor, end;\r\nkmemleak_free_part(__va(addr), size);\r\ncursor = PFN_UP(addr);\r\nend = PFN_DOWN(addr + size);\r\nfor (; cursor < end; cursor++) {\r\n__free_pages_bootmem(pfn_to_page(cursor), 0);\r\ntotalram_pages++;\r\n}\r\n}\r\nstatic unsigned long __init free_all_bootmem_core(bootmem_data_t *bdata)\r\n{\r\nint aligned;\r\nstruct page *page;\r\nunsigned long start, end, pages, count = 0;\r\nif (!bdata->node_bootmem_map)\r\nreturn 0;\r\nstart = bdata->node_min_pfn;\r\nend = bdata->node_low_pfn;\r\naligned = !(start & (BITS_PER_LONG - 1));\r\nbdebug("nid=%td start=%lx end=%lx aligned=%d\n",\r\nbdata - bootmem_node_data, start, end, aligned);\r\nwhile (start < end) {\r\nunsigned long *map, idx, vec;\r\nmap = bdata->node_bootmem_map;\r\nidx = start - bdata->node_min_pfn;\r\nvec = ~map[idx / BITS_PER_LONG];\r\nif (aligned && vec == ~0UL && start + BITS_PER_LONG < end) {\r\nint order = ilog2(BITS_PER_LONG);\r\n__free_pages_bootmem(pfn_to_page(start), order);\r\ncount += BITS_PER_LONG;\r\n} else {\r\nunsigned long off = 0;\r\nwhile (vec && off < BITS_PER_LONG) {\r\nif (vec & 1) {\r\npage = pfn_to_page(start + off);\r\n__free_pages_bootmem(page, 0);\r\ncount++;\r\n}\r\nvec >>= 1;\r\noff++;\r\n}\r\n}\r\nstart += BITS_PER_LONG;\r\n}\r\npage = virt_to_page(bdata->node_bootmem_map);\r\npages = bdata->node_low_pfn - bdata->node_min_pfn;\r\npages = bootmem_bootmap_pages(pages);\r\ncount += pages;\r\nwhile (pages--)\r\n__free_pages_bootmem(page++, 0);\r\nbdebug("nid=%td released=%lx\n", bdata - bootmem_node_data, count);\r\nreturn count;\r\n}\r\nunsigned long __init free_all_bootmem_node(pg_data_t *pgdat)\r\n{\r\nregister_page_bootmem_info_node(pgdat);\r\nreturn free_all_bootmem_core(pgdat->bdata);\r\n}\r\nunsigned long __init free_all_bootmem(void)\r\n{\r\nunsigned long total_pages = 0;\r\nbootmem_data_t *bdata;\r\nlist_for_each_entry(bdata, &bdata_list, list)\r\ntotal_pages += free_all_bootmem_core(bdata);\r\nreturn total_pages;\r\n}\r\nstatic void __init __free(bootmem_data_t *bdata,\r\nunsigned long sidx, unsigned long eidx)\r\n{\r\nunsigned long idx;\r\nbdebug("nid=%td start=%lx end=%lx\n", bdata - bootmem_node_data,\r\nsidx + bdata->node_min_pfn,\r\neidx + bdata->node_min_pfn);\r\nif (bdata->hint_idx > sidx)\r\nbdata->hint_idx = sidx;\r\nfor (idx = sidx; idx < eidx; idx++)\r\nif (!test_and_clear_bit(idx, bdata->node_bootmem_map))\r\nBUG();\r\n}\r\nstatic int __init __reserve(bootmem_data_t *bdata, unsigned long sidx,\r\nunsigned long eidx, int flags)\r\n{\r\nunsigned long idx;\r\nint exclusive = flags & BOOTMEM_EXCLUSIVE;\r\nbdebug("nid=%td start=%lx end=%lx flags=%x\n",\r\nbdata - bootmem_node_data,\r\nsidx + bdata->node_min_pfn,\r\neidx + bdata->node_min_pfn,\r\nflags);\r\nfor (idx = sidx; idx < eidx; idx++)\r\nif (test_and_set_bit(idx, bdata->node_bootmem_map)) {\r\nif (exclusive) {\r\n__free(bdata, sidx, idx);\r\nreturn -EBUSY;\r\n}\r\nbdebug("silent double reserve of PFN %lx\n",\r\nidx + bdata->node_min_pfn);\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init mark_bootmem_node(bootmem_data_t *bdata,\r\nunsigned long start, unsigned long end,\r\nint reserve, int flags)\r\n{\r\nunsigned long sidx, eidx;\r\nbdebug("nid=%td start=%lx end=%lx reserve=%d flags=%x\n",\r\nbdata - bootmem_node_data, start, end, reserve, flags);\r\nBUG_ON(start < bdata->node_min_pfn);\r\nBUG_ON(end > bdata->node_low_pfn);\r\nsidx = start - bdata->node_min_pfn;\r\neidx = end - bdata->node_min_pfn;\r\nif (reserve)\r\nreturn __reserve(bdata, sidx, eidx, flags);\r\nelse\r\n__free(bdata, sidx, eidx);\r\nreturn 0;\r\n}\r\nstatic int __init mark_bootmem(unsigned long start, unsigned long end,\r\nint reserve, int flags)\r\n{\r\nunsigned long pos;\r\nbootmem_data_t *bdata;\r\npos = start;\r\nlist_for_each_entry(bdata, &bdata_list, list) {\r\nint err;\r\nunsigned long max;\r\nif (pos < bdata->node_min_pfn ||\r\npos >= bdata->node_low_pfn) {\r\nBUG_ON(pos != start);\r\ncontinue;\r\n}\r\nmax = min(bdata->node_low_pfn, end);\r\nerr = mark_bootmem_node(bdata, pos, max, reserve, flags);\r\nif (reserve && err) {\r\nmark_bootmem(start, pos, 0, 0);\r\nreturn err;\r\n}\r\nif (max == end)\r\nreturn 0;\r\npos = bdata->node_low_pfn;\r\n}\r\nBUG();\r\n}\r\nvoid __init free_bootmem_node(pg_data_t *pgdat, unsigned long physaddr,\r\nunsigned long size)\r\n{\r\nunsigned long start, end;\r\nkmemleak_free_part(__va(physaddr), size);\r\nstart = PFN_UP(physaddr);\r\nend = PFN_DOWN(physaddr + size);\r\nmark_bootmem_node(pgdat->bdata, start, end, 0, 0);\r\n}\r\nvoid __init free_bootmem(unsigned long addr, unsigned long size)\r\n{\r\nunsigned long start, end;\r\nkmemleak_free_part(__va(addr), size);\r\nstart = PFN_UP(addr);\r\nend = PFN_DOWN(addr + size);\r\nmark_bootmem(start, end, 0, 0);\r\n}\r\nint __init reserve_bootmem_node(pg_data_t *pgdat, unsigned long physaddr,\r\nunsigned long size, int flags)\r\n{\r\nunsigned long start, end;\r\nstart = PFN_DOWN(physaddr);\r\nend = PFN_UP(physaddr + size);\r\nreturn mark_bootmem_node(pgdat->bdata, start, end, 1, flags);\r\n}\r\nint __init reserve_bootmem(unsigned long addr, unsigned long size,\r\nint flags)\r\n{\r\nunsigned long start, end;\r\nstart = PFN_DOWN(addr);\r\nend = PFN_UP(addr + size);\r\nreturn mark_bootmem(start, end, 1, flags);\r\n}\r\nint __weak __init reserve_bootmem_generic(unsigned long phys, unsigned long len,\r\nint flags)\r\n{\r\nreturn reserve_bootmem(phys, len, flags);\r\n}\r\nstatic unsigned long __init align_idx(struct bootmem_data *bdata,\r\nunsigned long idx, unsigned long step)\r\n{\r\nunsigned long base = bdata->node_min_pfn;\r\nreturn ALIGN(base + idx, step) - base;\r\n}\r\nstatic unsigned long __init align_off(struct bootmem_data *bdata,\r\nunsigned long off, unsigned long align)\r\n{\r\nunsigned long base = PFN_PHYS(bdata->node_min_pfn);\r\nreturn ALIGN(base + off, align) - base;\r\n}\r\nstatic void * __init alloc_bootmem_core(struct bootmem_data *bdata,\r\nunsigned long size, unsigned long align,\r\nunsigned long goal, unsigned long limit)\r\n{\r\nunsigned long fallback = 0;\r\nunsigned long min, max, start, sidx, midx, step;\r\nbdebug("nid=%td size=%lx [%lu pages] align=%lx goal=%lx limit=%lx\n",\r\nbdata - bootmem_node_data, size, PAGE_ALIGN(size) >> PAGE_SHIFT,\r\nalign, goal, limit);\r\nBUG_ON(!size);\r\nBUG_ON(align & (align - 1));\r\nBUG_ON(limit && goal + size > limit);\r\nif (!bdata->node_bootmem_map)\r\nreturn NULL;\r\nmin = bdata->node_min_pfn;\r\nmax = bdata->node_low_pfn;\r\ngoal >>= PAGE_SHIFT;\r\nlimit >>= PAGE_SHIFT;\r\nif (limit && max > limit)\r\nmax = limit;\r\nif (max <= min)\r\nreturn NULL;\r\nstep = max(align >> PAGE_SHIFT, 1UL);\r\nif (goal && min < goal && goal < max)\r\nstart = ALIGN(goal, step);\r\nelse\r\nstart = ALIGN(min, step);\r\nsidx = start - bdata->node_min_pfn;\r\nmidx = max - bdata->node_min_pfn;\r\nif (bdata->hint_idx > sidx) {\r\nfallback = sidx + 1;\r\nsidx = align_idx(bdata, bdata->hint_idx, step);\r\n}\r\nwhile (1) {\r\nint merge;\r\nvoid *region;\r\nunsigned long eidx, i, start_off, end_off;\r\nfind_block:\r\nsidx = find_next_zero_bit(bdata->node_bootmem_map, midx, sidx);\r\nsidx = align_idx(bdata, sidx, step);\r\neidx = sidx + PFN_UP(size);\r\nif (sidx >= midx || eidx > midx)\r\nbreak;\r\nfor (i = sidx; i < eidx; i++)\r\nif (test_bit(i, bdata->node_bootmem_map)) {\r\nsidx = align_idx(bdata, i, step);\r\nif (sidx == i)\r\nsidx += step;\r\ngoto find_block;\r\n}\r\nif (bdata->last_end_off & (PAGE_SIZE - 1) &&\r\nPFN_DOWN(bdata->last_end_off) + 1 == sidx)\r\nstart_off = align_off(bdata, bdata->last_end_off, align);\r\nelse\r\nstart_off = PFN_PHYS(sidx);\r\nmerge = PFN_DOWN(start_off) < sidx;\r\nend_off = start_off + size;\r\nbdata->last_end_off = end_off;\r\nbdata->hint_idx = PFN_UP(end_off);\r\nif (__reserve(bdata, PFN_DOWN(start_off) + merge,\r\nPFN_UP(end_off), BOOTMEM_EXCLUSIVE))\r\nBUG();\r\nregion = phys_to_virt(PFN_PHYS(bdata->node_min_pfn) +\r\nstart_off);\r\nmemset(region, 0, size);\r\nkmemleak_alloc(region, size, 0, 0);\r\nreturn region;\r\n}\r\nif (fallback) {\r\nsidx = align_idx(bdata, fallback - 1, step);\r\nfallback = 0;\r\ngoto find_block;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void * __init alloc_arch_preferred_bootmem(bootmem_data_t *bdata,\r\nunsigned long size, unsigned long align,\r\nunsigned long goal, unsigned long limit)\r\n{\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc(size, GFP_NOWAIT);\r\n#ifdef CONFIG_HAVE_ARCH_BOOTMEM\r\n{\r\nbootmem_data_t *p_bdata;\r\np_bdata = bootmem_arch_preferred_node(bdata, size, align,\r\ngoal, limit);\r\nif (p_bdata)\r\nreturn alloc_bootmem_core(p_bdata, size, align,\r\ngoal, limit);\r\n}\r\n#endif\r\nreturn NULL;\r\n}\r\nstatic void * __init ___alloc_bootmem_nopanic(unsigned long size,\r\nunsigned long align,\r\nunsigned long goal,\r\nunsigned long limit)\r\n{\r\nbootmem_data_t *bdata;\r\nvoid *region;\r\nrestart:\r\nregion = alloc_arch_preferred_bootmem(NULL, size, align, goal, limit);\r\nif (region)\r\nreturn region;\r\nlist_for_each_entry(bdata, &bdata_list, list) {\r\nif (goal && bdata->node_low_pfn <= PFN_DOWN(goal))\r\ncontinue;\r\nif (limit && bdata->node_min_pfn >= PFN_DOWN(limit))\r\nbreak;\r\nregion = alloc_bootmem_core(bdata, size, align, goal, limit);\r\nif (region)\r\nreturn region;\r\n}\r\nif (goal) {\r\ngoal = 0;\r\ngoto restart;\r\n}\r\nreturn NULL;\r\n}\r\nvoid * __init __alloc_bootmem_nopanic(unsigned long size, unsigned long align,\r\nunsigned long goal)\r\n{\r\nunsigned long limit = 0;\r\nreturn ___alloc_bootmem_nopanic(size, align, goal, limit);\r\n}\r\nstatic void * __init ___alloc_bootmem(unsigned long size, unsigned long align,\r\nunsigned long goal, unsigned long limit)\r\n{\r\nvoid *mem = ___alloc_bootmem_nopanic(size, align, goal, limit);\r\nif (mem)\r\nreturn mem;\r\nprintk(KERN_ALERT "bootmem alloc of %lu bytes failed!\n", size);\r\npanic("Out of memory");\r\nreturn NULL;\r\n}\r\nvoid * __init __alloc_bootmem(unsigned long size, unsigned long align,\r\nunsigned long goal)\r\n{\r\nunsigned long limit = 0;\r\nreturn ___alloc_bootmem(size, align, goal, limit);\r\n}\r\nstatic void * __init ___alloc_bootmem_node(bootmem_data_t *bdata,\r\nunsigned long size, unsigned long align,\r\nunsigned long goal, unsigned long limit)\r\n{\r\nvoid *ptr;\r\nptr = alloc_arch_preferred_bootmem(bdata, size, align, goal, limit);\r\nif (ptr)\r\nreturn ptr;\r\nptr = alloc_bootmem_core(bdata, size, align, goal, limit);\r\nif (ptr)\r\nreturn ptr;\r\nreturn ___alloc_bootmem(size, align, goal, limit);\r\n}\r\nvoid * __init __alloc_bootmem_node(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);\r\nreturn ___alloc_bootmem_node(pgdat->bdata, size, align, goal, 0);\r\n}\r\nvoid * __init __alloc_bootmem_node_high(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\n#ifdef MAX_DMA32_PFN\r\nunsigned long end_pfn;\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);\r\nend_pfn = pgdat->node_start_pfn + pgdat->node_spanned_pages;\r\nif (end_pfn > MAX_DMA32_PFN + (128 >> (20 - PAGE_SHIFT)) &&\r\n(goal >> PAGE_SHIFT) < MAX_DMA32_PFN) {\r\nvoid *ptr;\r\nunsigned long new_goal;\r\nnew_goal = MAX_DMA32_PFN << PAGE_SHIFT;\r\nptr = alloc_bootmem_core(pgdat->bdata, size, align,\r\nnew_goal, 0);\r\nif (ptr)\r\nreturn ptr;\r\n}\r\n#endif\r\nreturn __alloc_bootmem_node(pgdat, size, align, goal);\r\n}\r\nvoid * __init alloc_bootmem_section(unsigned long size,\r\nunsigned long section_nr)\r\n{\r\nbootmem_data_t *bdata;\r\nunsigned long pfn, goal, limit;\r\npfn = section_nr_to_pfn(section_nr);\r\ngoal = pfn << PAGE_SHIFT;\r\nlimit = section_nr_to_pfn(section_nr + 1) << PAGE_SHIFT;\r\nbdata = &bootmem_node_data[early_pfn_to_nid(pfn)];\r\nreturn alloc_bootmem_core(bdata, size, SMP_CACHE_BYTES, goal, limit);\r\n}\r\nvoid * __init __alloc_bootmem_node_nopanic(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\nvoid *ptr;\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);\r\nptr = alloc_arch_preferred_bootmem(pgdat->bdata, size, align, goal, 0);\r\nif (ptr)\r\nreturn ptr;\r\nptr = alloc_bootmem_core(pgdat->bdata, size, align, goal, 0);\r\nif (ptr)\r\nreturn ptr;\r\nreturn __alloc_bootmem_nopanic(size, align, goal);\r\n}\r\nvoid * __init __alloc_bootmem_low(unsigned long size, unsigned long align,\r\nunsigned long goal)\r\n{\r\nreturn ___alloc_bootmem(size, align, goal, ARCH_LOW_ADDRESS_LIMIT);\r\n}\r\nvoid * __init __alloc_bootmem_low_node(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);\r\nreturn ___alloc_bootmem_node(pgdat->bdata, size, align,\r\ngoal, ARCH_LOW_ADDRESS_LIMIT);\r\n}
