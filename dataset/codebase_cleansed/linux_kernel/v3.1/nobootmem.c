static void * __init __alloc_memory_core_early(int nid, u64 size, u64 align,\r\nu64 goal, u64 limit)\r\n{\r\nvoid *ptr;\r\nu64 addr;\r\nif (limit > memblock.current_limit)\r\nlimit = memblock.current_limit;\r\naddr = find_memory_core_early(nid, size, align, goal, limit);\r\nif (addr == MEMBLOCK_ERROR)\r\nreturn NULL;\r\nptr = phys_to_virt(addr);\r\nmemset(ptr, 0, size);\r\nmemblock_x86_reserve_range(addr, addr + size, "BOOTMEM");\r\nkmemleak_alloc(ptr, size, 0, 0);\r\nreturn ptr;\r\n}\r\nvoid __init free_bootmem_late(unsigned long addr, unsigned long size)\r\n{\r\nunsigned long cursor, end;\r\nkmemleak_free_part(__va(addr), size);\r\ncursor = PFN_UP(addr);\r\nend = PFN_DOWN(addr + size);\r\nfor (; cursor < end; cursor++) {\r\n__free_pages_bootmem(pfn_to_page(cursor), 0);\r\ntotalram_pages++;\r\n}\r\n}\r\nstatic void __init __free_pages_memory(unsigned long start, unsigned long end)\r\n{\r\nint i;\r\nunsigned long start_aligned, end_aligned;\r\nint order = ilog2(BITS_PER_LONG);\r\nstart_aligned = (start + (BITS_PER_LONG - 1)) & ~(BITS_PER_LONG - 1);\r\nend_aligned = end & ~(BITS_PER_LONG - 1);\r\nif (end_aligned <= start_aligned) {\r\nfor (i = start; i < end; i++)\r\n__free_pages_bootmem(pfn_to_page(i), 0);\r\nreturn;\r\n}\r\nfor (i = start; i < start_aligned; i++)\r\n__free_pages_bootmem(pfn_to_page(i), 0);\r\nfor (i = start_aligned; i < end_aligned; i += BITS_PER_LONG)\r\n__free_pages_bootmem(pfn_to_page(i), order);\r\nfor (i = end_aligned; i < end; i++)\r\n__free_pages_bootmem(pfn_to_page(i), 0);\r\n}\r\nunsigned long __init free_all_memory_core_early(int nodeid)\r\n{\r\nint i;\r\nu64 start, end;\r\nunsigned long count = 0;\r\nstruct range *range = NULL;\r\nint nr_range;\r\nnr_range = get_free_all_memory_range(&range, nodeid);\r\nfor (i = 0; i < nr_range; i++) {\r\nstart = range[i].start;\r\nend = range[i].end;\r\ncount += end - start;\r\n__free_pages_memory(start, end);\r\n}\r\nreturn count;\r\n}\r\nunsigned long __init free_all_bootmem_node(pg_data_t *pgdat)\r\n{\r\nregister_page_bootmem_info_node(pgdat);\r\nreturn 0;\r\n}\r\nunsigned long __init free_all_bootmem(void)\r\n{\r\nreturn free_all_memory_core_early(MAX_NUMNODES);\r\n}\r\nvoid __init free_bootmem_node(pg_data_t *pgdat, unsigned long physaddr,\r\nunsigned long size)\r\n{\r\nkmemleak_free_part(__va(physaddr), size);\r\nmemblock_x86_free_range(physaddr, physaddr + size);\r\n}\r\nvoid __init free_bootmem(unsigned long addr, unsigned long size)\r\n{\r\nkmemleak_free_part(__va(addr), size);\r\nmemblock_x86_free_range(addr, addr + size);\r\n}\r\nstatic void * __init ___alloc_bootmem_nopanic(unsigned long size,\r\nunsigned long align,\r\nunsigned long goal,\r\nunsigned long limit)\r\n{\r\nvoid *ptr;\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc(size, GFP_NOWAIT);\r\nrestart:\r\nptr = __alloc_memory_core_early(MAX_NUMNODES, size, align, goal, limit);\r\nif (ptr)\r\nreturn ptr;\r\nif (goal != 0) {\r\ngoal = 0;\r\ngoto restart;\r\n}\r\nreturn NULL;\r\n}\r\nvoid * __init __alloc_bootmem_nopanic(unsigned long size, unsigned long align,\r\nunsigned long goal)\r\n{\r\nunsigned long limit = -1UL;\r\nreturn ___alloc_bootmem_nopanic(size, align, goal, limit);\r\n}\r\nstatic void * __init ___alloc_bootmem(unsigned long size, unsigned long align,\r\nunsigned long goal, unsigned long limit)\r\n{\r\nvoid *mem = ___alloc_bootmem_nopanic(size, align, goal, limit);\r\nif (mem)\r\nreturn mem;\r\nprintk(KERN_ALERT "bootmem alloc of %lu bytes failed!\n", size);\r\npanic("Out of memory");\r\nreturn NULL;\r\n}\r\nvoid * __init __alloc_bootmem(unsigned long size, unsigned long align,\r\nunsigned long goal)\r\n{\r\nunsigned long limit = -1UL;\r\nreturn ___alloc_bootmem(size, align, goal, limit);\r\n}\r\nvoid * __init __alloc_bootmem_node(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\nvoid *ptr;\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);\r\nptr = __alloc_memory_core_early(pgdat->node_id, size, align,\r\ngoal, -1ULL);\r\nif (ptr)\r\nreturn ptr;\r\nreturn __alloc_memory_core_early(MAX_NUMNODES, size, align,\r\ngoal, -1ULL);\r\n}\r\nvoid * __init __alloc_bootmem_node_high(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\nreturn __alloc_bootmem_node(pgdat, size, align, goal);\r\n}\r\nvoid * __init alloc_bootmem_section(unsigned long size,\r\nunsigned long section_nr)\r\n{\r\nunsigned long pfn, goal, limit;\r\npfn = section_nr_to_pfn(section_nr);\r\ngoal = pfn << PAGE_SHIFT;\r\nlimit = section_nr_to_pfn(section_nr + 1) << PAGE_SHIFT;\r\nreturn __alloc_memory_core_early(early_pfn_to_nid(pfn), size,\r\nSMP_CACHE_BYTES, goal, limit);\r\n}\r\nvoid * __init __alloc_bootmem_node_nopanic(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\nvoid *ptr;\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);\r\nptr = __alloc_memory_core_early(pgdat->node_id, size, align,\r\ngoal, -1ULL);\r\nif (ptr)\r\nreturn ptr;\r\nreturn __alloc_bootmem_nopanic(size, align, goal);\r\n}\r\nvoid * __init __alloc_bootmem_low(unsigned long size, unsigned long align,\r\nunsigned long goal)\r\n{\r\nreturn ___alloc_bootmem(size, align, goal, ARCH_LOW_ADDRESS_LIMIT);\r\n}\r\nvoid * __init __alloc_bootmem_low_node(pg_data_t *pgdat, unsigned long size,\r\nunsigned long align, unsigned long goal)\r\n{\r\nvoid *ptr;\r\nif (WARN_ON_ONCE(slab_is_available()))\r\nreturn kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);\r\nptr = __alloc_memory_core_early(pgdat->node_id, size, align,\r\ngoal, ARCH_LOW_ADDRESS_LIMIT);\r\nif (ptr)\r\nreturn ptr;\r\nreturn __alloc_memory_core_early(MAX_NUMNODES, size, align,\r\ngoal, ARCH_LOW_ADDRESS_LIMIT);\r\n}
