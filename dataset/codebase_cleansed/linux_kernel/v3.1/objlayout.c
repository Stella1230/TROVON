struct pnfs_layout_hdr *\r\nobjlayout_alloc_layout_hdr(struct inode *inode, gfp_t gfp_flags)\r\n{\r\nstruct objlayout *objlay;\r\nobjlay = kzalloc(sizeof(struct objlayout), gfp_flags);\r\nif (objlay) {\r\nspin_lock_init(&objlay->lock);\r\nINIT_LIST_HEAD(&objlay->err_list);\r\n}\r\ndprintk("%s: Return %p\n", __func__, objlay);\r\nreturn &objlay->pnfs_layout;\r\n}\r\nvoid\r\nobjlayout_free_layout_hdr(struct pnfs_layout_hdr *lo)\r\n{\r\nstruct objlayout *objlay = OBJLAYOUT(lo);\r\ndprintk("%s: objlay %p\n", __func__, objlay);\r\nWARN_ON(!list_empty(&objlay->err_list));\r\nkfree(objlay);\r\n}\r\nstruct pnfs_layout_segment *\r\nobjlayout_alloc_lseg(struct pnfs_layout_hdr *pnfslay,\r\nstruct nfs4_layoutget_res *lgr,\r\ngfp_t gfp_flags)\r\n{\r\nint status = -ENOMEM;\r\nstruct xdr_stream stream;\r\nstruct xdr_buf buf = {\r\n.pages = lgr->layoutp->pages,\r\n.page_len = lgr->layoutp->len,\r\n.buflen = lgr->layoutp->len,\r\n.len = lgr->layoutp->len,\r\n};\r\nstruct page *scratch;\r\nstruct pnfs_layout_segment *lseg;\r\ndprintk("%s: Begin pnfslay %p\n", __func__, pnfslay);\r\nscratch = alloc_page(gfp_flags);\r\nif (!scratch)\r\ngoto err_nofree;\r\nxdr_init_decode(&stream, &buf, NULL);\r\nxdr_set_scratch_buffer(&stream, page_address(scratch), PAGE_SIZE);\r\nstatus = objio_alloc_lseg(&lseg, pnfslay, &lgr->range, &stream, gfp_flags);\r\nif (unlikely(status)) {\r\ndprintk("%s: objio_alloc_lseg Return err %d\n", __func__,\r\nstatus);\r\ngoto err;\r\n}\r\n__free_page(scratch);\r\ndprintk("%s: Return %p\n", __func__, lseg);\r\nreturn lseg;\r\nerr:\r\n__free_page(scratch);\r\nerr_nofree:\r\ndprintk("%s: Err Return=>%d\n", __func__, status);\r\nreturn ERR_PTR(status);\r\n}\r\nvoid\r\nobjlayout_free_lseg(struct pnfs_layout_segment *lseg)\r\n{\r\ndprintk("%s: freeing layout segment %p\n", __func__, lseg);\r\nif (unlikely(!lseg))\r\nreturn;\r\nobjio_free_lseg(lseg);\r\n}\r\nstatic inline u64\r\nend_offset(u64 start, u64 len)\r\n{\r\nu64 end;\r\nend = start + len;\r\nreturn end >= start ? end : NFS4_MAX_UINT64;\r\n}\r\nstatic inline u64\r\nlast_byte_offset(u64 start, u64 len)\r\n{\r\nu64 end;\r\nBUG_ON(!len);\r\nend = start + len;\r\nreturn end > start ? end - 1 : NFS4_MAX_UINT64;\r\n}\r\nstatic struct objlayout_io_state *\r\nobjlayout_alloc_io_state(struct pnfs_layout_hdr *pnfs_layout_type,\r\nstruct page **pages,\r\nunsigned pgbase,\r\nloff_t offset,\r\nsize_t count,\r\nstruct pnfs_layout_segment *lseg,\r\nvoid *rpcdata,\r\ngfp_t gfp_flags)\r\n{\r\nstruct objlayout_io_state *state;\r\nu64 lseg_end_offset;\r\ndprintk("%s: allocating io_state\n", __func__);\r\nif (objio_alloc_io_state(lseg, &state, gfp_flags))\r\nreturn NULL;\r\nBUG_ON(offset < lseg->pls_range.offset);\r\nlseg_end_offset = end_offset(lseg->pls_range.offset,\r\nlseg->pls_range.length);\r\nBUG_ON(offset >= lseg_end_offset);\r\nif (offset + count > lseg_end_offset) {\r\ncount = lseg->pls_range.length -\r\n(offset - lseg->pls_range.offset);\r\ndprintk("%s: truncated count %Zd\n", __func__, count);\r\n}\r\nif (pgbase > PAGE_SIZE) {\r\npages += pgbase >> PAGE_SHIFT;\r\npgbase &= ~PAGE_MASK;\r\n}\r\nINIT_LIST_HEAD(&state->err_list);\r\nstate->lseg = lseg;\r\nstate->rpcdata = rpcdata;\r\nstate->pages = pages;\r\nstate->pgbase = pgbase;\r\nstate->nr_pages = (pgbase + count + PAGE_SIZE - 1) >> PAGE_SHIFT;\r\nstate->offset = offset;\r\nstate->count = count;\r\nstate->sync = 0;\r\nreturn state;\r\n}\r\nstatic void\r\nobjlayout_free_io_state(struct objlayout_io_state *state)\r\n{\r\ndprintk("%s: freeing io_state\n", __func__);\r\nif (unlikely(!state))\r\nreturn;\r\nobjio_free_io_state(state);\r\n}\r\nstatic void\r\nobjlayout_iodone(struct objlayout_io_state *state)\r\n{\r\ndprintk("%s: state %p status\n", __func__, state);\r\nif (likely(state->status >= 0)) {\r\nobjlayout_free_io_state(state);\r\n} else {\r\nstruct objlayout *objlay = OBJLAYOUT(state->lseg->pls_layout);\r\nspin_lock(&objlay->lock);\r\nobjlay->delta_space_valid = OBJ_DSU_INVALID;\r\nlist_add(&objlay->err_list, &state->err_list);\r\nspin_unlock(&objlay->lock);\r\n}\r\n}\r\nvoid\r\nobjlayout_io_set_result(struct objlayout_io_state *state, unsigned index,\r\nstruct pnfs_osd_objid *pooid, int osd_error,\r\nu64 offset, u64 length, bool is_write)\r\n{\r\nstruct pnfs_osd_ioerr *ioerr = &state->ioerrs[index];\r\nBUG_ON(index >= state->num_comps);\r\nif (osd_error) {\r\nioerr->oer_component = *pooid;\r\nioerr->oer_comp_offset = offset;\r\nioerr->oer_comp_length = length;\r\nioerr->oer_iswrite = is_write;\r\nioerr->oer_errno = osd_error;\r\ndprintk("%s: err[%d]: errno=%d is_write=%d dev(%llx:%llx) "\r\n"par=0x%llx obj=0x%llx offset=0x%llx length=0x%llx\n",\r\n__func__, index, ioerr->oer_errno,\r\nioerr->oer_iswrite,\r\n_DEVID_LO(&ioerr->oer_component.oid_device_id),\r\n_DEVID_HI(&ioerr->oer_component.oid_device_id),\r\nioerr->oer_component.oid_partition_id,\r\nioerr->oer_component.oid_object_id,\r\nioerr->oer_comp_offset,\r\nioerr->oer_comp_length);\r\n} else {\r\nioerr->oer_errno = 0;\r\n}\r\n}\r\nstatic void _rpc_read_complete(struct work_struct *work)\r\n{\r\nstruct rpc_task *task;\r\nstruct nfs_read_data *rdata;\r\ndprintk("%s enter\n", __func__);\r\ntask = container_of(work, struct rpc_task, u.tk_work);\r\nrdata = container_of(task, struct nfs_read_data, task);\r\npnfs_ld_read_done(rdata);\r\n}\r\nvoid\r\nobjlayout_read_done(struct objlayout_io_state *state, ssize_t status, bool sync)\r\n{\r\nint eof = state->eof;\r\nstruct nfs_read_data *rdata;\r\nstate->status = status;\r\ndprintk("%s: Begin status=%zd eof=%d\n", __func__, status, eof);\r\nrdata = state->rpcdata;\r\nrdata->task.tk_status = status;\r\nif (status >= 0) {\r\nrdata->res.count = status;\r\nrdata->res.eof = eof;\r\n}\r\nobjlayout_iodone(state);\r\nif (sync)\r\npnfs_ld_read_done(rdata);\r\nelse {\r\nINIT_WORK(&rdata->task.u.tk_work, _rpc_read_complete);\r\nschedule_work(&rdata->task.u.tk_work);\r\n}\r\n}\r\nenum pnfs_try_status\r\nobjlayout_read_pagelist(struct nfs_read_data *rdata)\r\n{\r\nloff_t offset = rdata->args.offset;\r\nsize_t count = rdata->args.count;\r\nstruct objlayout_io_state *state;\r\nssize_t status = 0;\r\nloff_t eof;\r\ndprintk("%s: Begin inode %p offset %llu count %d\n",\r\n__func__, rdata->inode, offset, (int)count);\r\neof = i_size_read(rdata->inode);\r\nif (unlikely(offset + count > eof)) {\r\nif (offset >= eof) {\r\nstatus = 0;\r\nrdata->res.count = 0;\r\nrdata->res.eof = 1;\r\ngoto out;\r\n}\r\ncount = eof - offset;\r\n}\r\nstate = objlayout_alloc_io_state(NFS_I(rdata->inode)->layout,\r\nrdata->args.pages, rdata->args.pgbase,\r\noffset, count,\r\nrdata->lseg, rdata,\r\nGFP_KERNEL);\r\nif (unlikely(!state)) {\r\nstatus = -ENOMEM;\r\ngoto out;\r\n}\r\nstate->eof = state->offset + state->count >= eof;\r\nstatus = objio_read_pagelist(state);\r\nout:\r\ndprintk("%s: Return status %Zd\n", __func__, status);\r\nrdata->pnfs_error = status;\r\nreturn PNFS_ATTEMPTED;\r\n}\r\nstatic void _rpc_write_complete(struct work_struct *work)\r\n{\r\nstruct rpc_task *task;\r\nstruct nfs_write_data *wdata;\r\ndprintk("%s enter\n", __func__);\r\ntask = container_of(work, struct rpc_task, u.tk_work);\r\nwdata = container_of(task, struct nfs_write_data, task);\r\npnfs_ld_write_done(wdata);\r\n}\r\nvoid\r\nobjlayout_write_done(struct objlayout_io_state *state, ssize_t status,\r\nbool sync)\r\n{\r\nstruct nfs_write_data *wdata;\r\ndprintk("%s: Begin\n", __func__);\r\nwdata = state->rpcdata;\r\nstate->status = status;\r\nwdata->task.tk_status = status;\r\nif (status >= 0) {\r\nwdata->res.count = status;\r\nwdata->verf.committed = state->committed;\r\ndprintk("%s: Return status %d committed %d\n",\r\n__func__, wdata->task.tk_status,\r\nwdata->verf.committed);\r\n} else\r\ndprintk("%s: Return status %d\n",\r\n__func__, wdata->task.tk_status);\r\nobjlayout_iodone(state);\r\nif (sync)\r\npnfs_ld_write_done(wdata);\r\nelse {\r\nINIT_WORK(&wdata->task.u.tk_work, _rpc_write_complete);\r\nschedule_work(&wdata->task.u.tk_work);\r\n}\r\n}\r\nenum pnfs_try_status\r\nobjlayout_write_pagelist(struct nfs_write_data *wdata,\r\nint how)\r\n{\r\nstruct objlayout_io_state *state;\r\nssize_t status;\r\ndprintk("%s: Begin inode %p offset %llu count %u\n",\r\n__func__, wdata->inode, wdata->args.offset, wdata->args.count);\r\nstate = objlayout_alloc_io_state(NFS_I(wdata->inode)->layout,\r\nwdata->args.pages,\r\nwdata->args.pgbase,\r\nwdata->args.offset,\r\nwdata->args.count,\r\nwdata->lseg, wdata,\r\nGFP_NOFS);\r\nif (unlikely(!state)) {\r\nstatus = -ENOMEM;\r\ngoto out;\r\n}\r\nstate->sync = how & FLUSH_SYNC;\r\nstatus = objio_write_pagelist(state, how & FLUSH_STABLE);\r\nout:\r\ndprintk("%s: Return status %Zd\n", __func__, status);\r\nwdata->pnfs_error = status;\r\nreturn PNFS_ATTEMPTED;\r\n}\r\nvoid\r\nobjlayout_encode_layoutcommit(struct pnfs_layout_hdr *pnfslay,\r\nstruct xdr_stream *xdr,\r\nconst struct nfs4_layoutcommit_args *args)\r\n{\r\nstruct objlayout *objlay = OBJLAYOUT(pnfslay);\r\nstruct pnfs_osd_layoutupdate lou;\r\n__be32 *start;\r\ndprintk("%s: Begin\n", __func__);\r\nspin_lock(&objlay->lock);\r\nlou.dsu_valid = (objlay->delta_space_valid == OBJ_DSU_VALID);\r\nlou.dsu_delta = objlay->delta_space_used;\r\nobjlay->delta_space_used = 0;\r\nobjlay->delta_space_valid = OBJ_DSU_INIT;\r\nlou.olu_ioerr_flag = !list_empty(&objlay->err_list);\r\nspin_unlock(&objlay->lock);\r\nstart = xdr_reserve_space(xdr, 4);\r\nBUG_ON(pnfs_osd_xdr_encode_layoutupdate(xdr, &lou));\r\n*start = cpu_to_be32((xdr->p - start - 1) * 4);\r\ndprintk("%s: Return delta_space_used %lld err %d\n", __func__,\r\nlou.dsu_delta, lou.olu_ioerr_flag);\r\n}\r\nstatic int\r\nerr_prio(u32 oer_errno)\r\n{\r\nswitch (oer_errno) {\r\ncase 0:\r\nreturn 0;\r\ncase PNFS_OSD_ERR_RESOURCE:\r\nreturn OSD_ERR_PRI_RESOURCE;\r\ncase PNFS_OSD_ERR_BAD_CRED:\r\nreturn OSD_ERR_PRI_BAD_CRED;\r\ncase PNFS_OSD_ERR_NO_ACCESS:\r\nreturn OSD_ERR_PRI_NO_ACCESS;\r\ncase PNFS_OSD_ERR_UNREACHABLE:\r\nreturn OSD_ERR_PRI_UNREACHABLE;\r\ncase PNFS_OSD_ERR_NOT_FOUND:\r\nreturn OSD_ERR_PRI_NOT_FOUND;\r\ncase PNFS_OSD_ERR_NO_SPACE:\r\nreturn OSD_ERR_PRI_NO_SPACE;\r\ndefault:\r\nWARN_ON(1);\r\ncase PNFS_OSD_ERR_EIO:\r\nreturn OSD_ERR_PRI_EIO;\r\n}\r\n}\r\nstatic void\r\nmerge_ioerr(struct pnfs_osd_ioerr *dest_err,\r\nconst struct pnfs_osd_ioerr *src_err)\r\n{\r\nu64 dest_end, src_end;\r\nif (!dest_err->oer_errno) {\r\n*dest_err = *src_err;\r\nmemset(&dest_err->oer_component.oid_device_id, 0,\r\nsizeof(dest_err->oer_component.oid_device_id));\r\nreturn;\r\n}\r\nif (dest_err->oer_component.oid_partition_id !=\r\nsrc_err->oer_component.oid_partition_id)\r\ndest_err->oer_component.oid_partition_id = 0;\r\nif (dest_err->oer_component.oid_object_id !=\r\nsrc_err->oer_component.oid_object_id)\r\ndest_err->oer_component.oid_object_id = 0;\r\nif (dest_err->oer_comp_offset > src_err->oer_comp_offset)\r\ndest_err->oer_comp_offset = src_err->oer_comp_offset;\r\ndest_end = end_offset(dest_err->oer_comp_offset,\r\ndest_err->oer_comp_length);\r\nsrc_end = end_offset(src_err->oer_comp_offset,\r\nsrc_err->oer_comp_length);\r\nif (dest_end < src_end)\r\ndest_end = src_end;\r\ndest_err->oer_comp_length = dest_end - dest_err->oer_comp_offset;\r\nif ((src_err->oer_iswrite == dest_err->oer_iswrite) &&\r\n(err_prio(src_err->oer_errno) > err_prio(dest_err->oer_errno))) {\r\ndest_err->oer_errno = src_err->oer_errno;\r\n} else if (src_err->oer_iswrite) {\r\ndest_err->oer_iswrite = true;\r\ndest_err->oer_errno = src_err->oer_errno;\r\n}\r\n}\r\nstatic void\r\nencode_accumulated_error(struct objlayout *objlay, __be32 *p)\r\n{\r\nstruct objlayout_io_state *state, *tmp;\r\nstruct pnfs_osd_ioerr accumulated_err = {.oer_errno = 0};\r\nlist_for_each_entry_safe(state, tmp, &objlay->err_list, err_list) {\r\nunsigned i;\r\nfor (i = 0; i < state->num_comps; i++) {\r\nstruct pnfs_osd_ioerr *ioerr = &state->ioerrs[i];\r\nif (!ioerr->oer_errno)\r\ncontinue;\r\nprintk(KERN_ERR "%s: err[%d]: errno=%d is_write=%d "\r\n"dev(%llx:%llx) par=0x%llx obj=0x%llx "\r\n"offset=0x%llx length=0x%llx\n",\r\n__func__, i, ioerr->oer_errno,\r\nioerr->oer_iswrite,\r\n_DEVID_LO(&ioerr->oer_component.oid_device_id),\r\n_DEVID_HI(&ioerr->oer_component.oid_device_id),\r\nioerr->oer_component.oid_partition_id,\r\nioerr->oer_component.oid_object_id,\r\nioerr->oer_comp_offset,\r\nioerr->oer_comp_length);\r\nmerge_ioerr(&accumulated_err, ioerr);\r\n}\r\nlist_del(&state->err_list);\r\nobjlayout_free_io_state(state);\r\n}\r\npnfs_osd_xdr_encode_ioerr(p, &accumulated_err);\r\n}\r\nvoid\r\nobjlayout_encode_layoutreturn(struct pnfs_layout_hdr *pnfslay,\r\nstruct xdr_stream *xdr,\r\nconst struct nfs4_layoutreturn_args *args)\r\n{\r\nstruct objlayout *objlay = OBJLAYOUT(pnfslay);\r\nstruct objlayout_io_state *state, *tmp;\r\n__be32 *start;\r\ndprintk("%s: Begin\n", __func__);\r\nstart = xdr_reserve_space(xdr, 4);\r\nBUG_ON(!start);\r\nspin_lock(&objlay->lock);\r\nlist_for_each_entry_safe(state, tmp, &objlay->err_list, err_list) {\r\n__be32 *last_xdr = NULL, *p;\r\nunsigned i;\r\nint res = 0;\r\nfor (i = 0; i < state->num_comps; i++) {\r\nstruct pnfs_osd_ioerr *ioerr = &state->ioerrs[i];\r\nif (!ioerr->oer_errno)\r\ncontinue;\r\ndprintk("%s: err[%d]: errno=%d is_write=%d "\r\n"dev(%llx:%llx) par=0x%llx obj=0x%llx "\r\n"offset=0x%llx length=0x%llx\n",\r\n__func__, i, ioerr->oer_errno,\r\nioerr->oer_iswrite,\r\n_DEVID_LO(&ioerr->oer_component.oid_device_id),\r\n_DEVID_HI(&ioerr->oer_component.oid_device_id),\r\nioerr->oer_component.oid_partition_id,\r\nioerr->oer_component.oid_object_id,\r\nioerr->oer_comp_offset,\r\nioerr->oer_comp_length);\r\np = pnfs_osd_xdr_ioerr_reserve_space(xdr);\r\nif (unlikely(!p)) {\r\nres = -E2BIG;\r\nbreak;\r\n}\r\nlast_xdr = p;\r\npnfs_osd_xdr_encode_ioerr(p, &state->ioerrs[i]);\r\n}\r\nif (unlikely(res)) {\r\nBUG_ON(!last_xdr);\r\nencode_accumulated_error(objlay, last_xdr);\r\ngoto loop_done;\r\n}\r\nlist_del(&state->err_list);\r\nobjlayout_free_io_state(state);\r\n}\r\nloop_done:\r\nspin_unlock(&objlay->lock);\r\n*start = cpu_to_be32((xdr->p - start - 1) * 4);\r\ndprintk("%s: Return\n", __func__);\r\n}\r\nint objlayout_get_deviceinfo(struct pnfs_layout_hdr *pnfslay,\r\nstruct nfs4_deviceid *d_id, struct pnfs_osd_deviceaddr **deviceaddr,\r\ngfp_t gfp_flags)\r\n{\r\nstruct objlayout_deviceinfo *odi;\r\nstruct pnfs_device pd;\r\nstruct super_block *sb;\r\nstruct page *page, **pages;\r\nu32 *p;\r\nint err;\r\npage = alloc_page(gfp_flags);\r\nif (!page)\r\nreturn -ENOMEM;\r\npages = &page;\r\npd.pages = pages;\r\nmemcpy(&pd.dev_id, d_id, sizeof(*d_id));\r\npd.layout_type = LAYOUT_OSD2_OBJECTS;\r\npd.pages = &page;\r\npd.pgbase = 0;\r\npd.pglen = PAGE_SIZE;\r\npd.mincount = 0;\r\nsb = pnfslay->plh_inode->i_sb;\r\nerr = nfs4_proc_getdeviceinfo(NFS_SERVER(pnfslay->plh_inode), &pd);\r\ndprintk("%s nfs_getdeviceinfo returned %d\n", __func__, err);\r\nif (err)\r\ngoto err_out;\r\np = page_address(page);\r\nodi = kzalloc(sizeof(*odi), gfp_flags);\r\nif (!odi) {\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\npnfs_osd_xdr_decode_deviceaddr(&odi->da, p);\r\nodi->page = page;\r\n*deviceaddr = &odi->da;\r\nreturn 0;\r\nerr_out:\r\n__free_page(page);\r\nreturn err;\r\n}\r\nvoid objlayout_put_deviceinfo(struct pnfs_osd_deviceaddr *deviceaddr)\r\n{\r\nstruct objlayout_deviceinfo *odi = container_of(deviceaddr,\r\nstruct objlayout_deviceinfo,\r\nda);\r\n__free_page(odi->page);\r\nkfree(odi);\r\n}
