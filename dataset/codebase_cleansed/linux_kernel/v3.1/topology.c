static cpumask_t cpu_group_map(struct mask_info *info, unsigned int cpu)\r\n{\r\ncpumask_t mask;\r\ncpumask_clear(&mask);\r\nif (!topology_enabled || !MACHINE_HAS_TOPOLOGY) {\r\ncpumask_copy(&mask, cpumask_of(cpu));\r\nreturn mask;\r\n}\r\nwhile (info) {\r\nif (cpumask_test_cpu(cpu, &info->mask)) {\r\nmask = info->mask;\r\nbreak;\r\n}\r\ninfo = info->next;\r\n}\r\nif (cpumask_empty(&mask))\r\ncpumask_copy(&mask, cpumask_of(cpu));\r\nreturn mask;\r\n}\r\nstatic void add_cpus_to_mask(struct topology_cpu *tl_cpu,\r\nstruct mask_info *book, struct mask_info *core)\r\n{\r\nunsigned int cpu;\r\nfor (cpu = find_first_bit(&tl_cpu->mask[0], TOPOLOGY_CPU_BITS);\r\ncpu < TOPOLOGY_CPU_BITS;\r\ncpu = find_next_bit(&tl_cpu->mask[0], TOPOLOGY_CPU_BITS, cpu + 1))\r\n{\r\nunsigned int rcpu, lcpu;\r\nrcpu = TOPOLOGY_CPU_BITS - 1 - cpu + tl_cpu->origin;\r\nfor_each_present_cpu(lcpu) {\r\nif (cpu_logical_map(lcpu) != rcpu)\r\ncontinue;\r\n#ifdef CONFIG_SCHED_BOOK\r\ncpumask_set_cpu(lcpu, &book->mask);\r\ncpu_book_id[lcpu] = book->id;\r\n#endif\r\ncpumask_set_cpu(lcpu, &core->mask);\r\ncpu_core_id[lcpu] = core->id;\r\nsmp_cpu_polarization[lcpu] = tl_cpu->pp;\r\n}\r\n}\r\n}\r\nstatic void clear_masks(void)\r\n{\r\nstruct mask_info *info;\r\ninfo = &core_info;\r\nwhile (info) {\r\ncpumask_clear(&info->mask);\r\ninfo = info->next;\r\n}\r\n#ifdef CONFIG_SCHED_BOOK\r\ninfo = &book_info;\r\nwhile (info) {\r\ncpumask_clear(&info->mask);\r\ninfo = info->next;\r\n}\r\n#endif\r\n}\r\nstatic union topology_entry *next_tle(union topology_entry *tle)\r\n{\r\nif (!tle->nl)\r\nreturn (union topology_entry *)((struct topology_cpu *)tle + 1);\r\nreturn (union topology_entry *)((struct topology_container *)tle + 1);\r\n}\r\nstatic void tl_to_cores(struct sysinfo_15_1_x *info)\r\n{\r\n#ifdef CONFIG_SCHED_BOOK\r\nstruct mask_info *book = &book_info;\r\n#else\r\nstruct mask_info *book = NULL;\r\n#endif\r\nstruct mask_info *core = &core_info;\r\nunion topology_entry *tle, *end;\r\nspin_lock_irq(&topology_lock);\r\nclear_masks();\r\ntle = info->tle;\r\nend = (union topology_entry *)((unsigned long)info + info->length);\r\nwhile (tle < end) {\r\nswitch (tle->nl) {\r\n#ifdef CONFIG_SCHED_BOOK\r\ncase 2:\r\nbook = book->next;\r\nbook->id = tle->container.id;\r\nbreak;\r\n#endif\r\ncase 1:\r\ncore = core->next;\r\ncore->id = tle->container.id;\r\nbreak;\r\ncase 0:\r\nadd_cpus_to_mask(&tle->cpu, book, core);\r\nbreak;\r\ndefault:\r\nclear_masks();\r\ngoto out;\r\n}\r\ntle = next_tle(tle);\r\n}\r\nout:\r\nspin_unlock_irq(&topology_lock);\r\n}\r\nstatic void topology_update_polarization_simple(void)\r\n{\r\nint cpu;\r\nmutex_lock(&smp_cpu_state_mutex);\r\nfor_each_possible_cpu(cpu)\r\nsmp_cpu_polarization[cpu] = POLARIZATION_HRZ;\r\nmutex_unlock(&smp_cpu_state_mutex);\r\n}\r\nstatic int ptf(unsigned long fc)\r\n{\r\nint rc;\r\nasm volatile(\r\n" .insn rre,0xb9a20000,%1,%1\n"\r\n" ipm %0\n"\r\n" srl %0,28\n"\r\n: "=d" (rc)\r\n: "d" (fc) : "cc");\r\nreturn rc;\r\n}\r\nint topology_set_cpu_management(int fc)\r\n{\r\nint cpu;\r\nint rc;\r\nif (!MACHINE_HAS_TOPOLOGY)\r\nreturn -EOPNOTSUPP;\r\nif (fc)\r\nrc = ptf(PTF_VERTICAL);\r\nelse\r\nrc = ptf(PTF_HORIZONTAL);\r\nif (rc)\r\nreturn -EBUSY;\r\nfor_each_possible_cpu(cpu)\r\nsmp_cpu_polarization[cpu] = POLARIZATION_UNKNWN;\r\nreturn rc;\r\n}\r\nstatic void update_cpu_core_map(void)\r\n{\r\nunsigned long flags;\r\nint cpu;\r\nspin_lock_irqsave(&topology_lock, flags);\r\nfor_each_possible_cpu(cpu) {\r\ncpu_core_map[cpu] = cpu_group_map(&core_info, cpu);\r\n#ifdef CONFIG_SCHED_BOOK\r\ncpu_book_map[cpu] = cpu_group_map(&book_info, cpu);\r\n#endif\r\n}\r\nspin_unlock_irqrestore(&topology_lock, flags);\r\n}\r\nvoid store_topology(struct sysinfo_15_1_x *info)\r\n{\r\n#ifdef CONFIG_SCHED_BOOK\r\nint rc;\r\nrc = stsi(info, 15, 1, 3);\r\nif (rc != -ENOSYS)\r\nreturn;\r\n#endif\r\nstsi(info, 15, 1, 2);\r\n}\r\nint arch_update_cpu_topology(void)\r\n{\r\nstruct sysinfo_15_1_x *info = tl_info;\r\nstruct sys_device *sysdev;\r\nint cpu;\r\nif (!MACHINE_HAS_TOPOLOGY) {\r\nupdate_cpu_core_map();\r\ntopology_update_polarization_simple();\r\nreturn 0;\r\n}\r\nstore_topology(info);\r\ntl_to_cores(info);\r\nupdate_cpu_core_map();\r\nfor_each_online_cpu(cpu) {\r\nsysdev = get_cpu_sysdev(cpu);\r\nkobject_uevent(&sysdev->kobj, KOBJ_CHANGE);\r\n}\r\nreturn 1;\r\n}\r\nstatic void topology_work_fn(struct work_struct *work)\r\n{\r\nrebuild_sched_domains();\r\n}\r\nvoid topology_schedule_update(void)\r\n{\r\nschedule_work(&topology_work);\r\n}\r\nstatic void topology_timer_fn(unsigned long ignored)\r\n{\r\nif (ptf(PTF_CHECK))\r\ntopology_schedule_update();\r\nset_topology_timer();\r\n}\r\nstatic void set_topology_timer(void)\r\n{\r\ntopology_timer.function = topology_timer_fn;\r\ntopology_timer.data = 0;\r\ntopology_timer.expires = jiffies + 60 * HZ;\r\nadd_timer(&topology_timer);\r\n}\r\nstatic int __init early_parse_topology(char *p)\r\n{\r\nif (strncmp(p, "off", 3))\r\nreturn 0;\r\ntopology_enabled = 0;\r\nreturn 0;\r\n}\r\nstatic int __init init_topology_update(void)\r\n{\r\nint rc;\r\nrc = 0;\r\nif (!MACHINE_HAS_TOPOLOGY) {\r\ntopology_update_polarization_simple();\r\ngoto out;\r\n}\r\ninit_timer_deferrable(&topology_timer);\r\nset_topology_timer();\r\nout:\r\nupdate_cpu_core_map();\r\nreturn rc;\r\n}\r\nstatic void alloc_masks(struct sysinfo_15_1_x *info, struct mask_info *mask,\r\nint offset)\r\n{\r\nint i, nr_masks;\r\nnr_masks = info->mag[TOPOLOGY_NR_MAG - offset];\r\nfor (i = 0; i < info->mnest - offset; i++)\r\nnr_masks *= info->mag[TOPOLOGY_NR_MAG - offset - 1 - i];\r\nnr_masks = max(nr_masks, 1);\r\nfor (i = 0; i < nr_masks; i++) {\r\nmask->next = alloc_bootmem(sizeof(struct mask_info));\r\nmask = mask->next;\r\n}\r\n}\r\nvoid __init s390_init_cpu_topology(void)\r\n{\r\nstruct sysinfo_15_1_x *info;\r\nint i;\r\nif (!MACHINE_HAS_TOPOLOGY)\r\nreturn;\r\ntl_info = alloc_bootmem_pages(PAGE_SIZE);\r\ninfo = tl_info;\r\nstore_topology(info);\r\npr_info("The CPU configuration topology of the machine is:");\r\nfor (i = 0; i < TOPOLOGY_NR_MAG; i++)\r\nprintk(" %d", info->mag[i]);\r\nprintk(" / %d\n", info->mnest);\r\nalloc_masks(info, &core_info, 2);\r\n#ifdef CONFIG_SCHED_BOOK\r\nalloc_masks(info, &book_info, 3);\r\n#endif\r\n}
