static inline cputime64_t get_cpu_idle_time_jiffy(unsigned int cpu,\r\ncputime64_t *wall)\r\n{\r\ncputime64_t idle_time;\r\ncputime64_t cur_wall_time;\r\ncputime64_t busy_time;\r\ncur_wall_time = jiffies64_to_cputime64(get_jiffies_64());\r\nbusy_time = cputime64_add(kstat_cpu(cpu).cpustat.user,\r\nkstat_cpu(cpu).cpustat.system);\r\nbusy_time = cputime64_add(busy_time, kstat_cpu(cpu).cpustat.irq);\r\nbusy_time = cputime64_add(busy_time, kstat_cpu(cpu).cpustat.softirq);\r\nbusy_time = cputime64_add(busy_time, kstat_cpu(cpu).cpustat.steal);\r\nbusy_time = cputime64_add(busy_time, kstat_cpu(cpu).cpustat.nice);\r\nidle_time = cputime64_sub(cur_wall_time, busy_time);\r\nif (wall)\r\n*wall = (cputime64_t)jiffies_to_usecs(cur_wall_time);\r\nreturn (cputime64_t)jiffies_to_usecs(idle_time);\r\n}\r\nstatic inline cputime64_t get_cpu_idle_time(unsigned int cpu, cputime64_t *wall)\r\n{\r\nu64 idle_time = get_cpu_idle_time_us(cpu, wall);\r\nif (idle_time == -1ULL)\r\nreturn get_cpu_idle_time_jiffy(cpu, wall);\r\nreturn idle_time;\r\n}\r\nstatic inline cputime64_t get_cpu_iowait_time(unsigned int cpu, cputime64_t *wall)\r\n{\r\nu64 iowait_time = get_cpu_iowait_time_us(cpu, wall);\r\nif (iowait_time == -1ULL)\r\nreturn 0;\r\nreturn iowait_time;\r\n}\r\nstatic unsigned int powersave_bias_target(struct cpufreq_policy *policy,\r\nunsigned int freq_next,\r\nunsigned int relation)\r\n{\r\nunsigned int freq_req, freq_reduc, freq_avg;\r\nunsigned int freq_hi, freq_lo;\r\nunsigned int index = 0;\r\nunsigned int jiffies_total, jiffies_hi, jiffies_lo;\r\nstruct cpu_dbs_info_s *dbs_info = &per_cpu(od_cpu_dbs_info,\r\npolicy->cpu);\r\nif (!dbs_info->freq_table) {\r\ndbs_info->freq_lo = 0;\r\ndbs_info->freq_lo_jiffies = 0;\r\nreturn freq_next;\r\n}\r\ncpufreq_frequency_table_target(policy, dbs_info->freq_table, freq_next,\r\nrelation, &index);\r\nfreq_req = dbs_info->freq_table[index].frequency;\r\nfreq_reduc = freq_req * dbs_tuners_ins.powersave_bias / 1000;\r\nfreq_avg = freq_req - freq_reduc;\r\nindex = 0;\r\ncpufreq_frequency_table_target(policy, dbs_info->freq_table, freq_avg,\r\nCPUFREQ_RELATION_H, &index);\r\nfreq_lo = dbs_info->freq_table[index].frequency;\r\nindex = 0;\r\ncpufreq_frequency_table_target(policy, dbs_info->freq_table, freq_avg,\r\nCPUFREQ_RELATION_L, &index);\r\nfreq_hi = dbs_info->freq_table[index].frequency;\r\nif (freq_hi == freq_lo) {\r\ndbs_info->freq_lo = 0;\r\ndbs_info->freq_lo_jiffies = 0;\r\nreturn freq_lo;\r\n}\r\njiffies_total = usecs_to_jiffies(dbs_tuners_ins.sampling_rate);\r\njiffies_hi = (freq_avg - freq_lo) * jiffies_total;\r\njiffies_hi += ((freq_hi - freq_lo) / 2);\r\njiffies_hi /= (freq_hi - freq_lo);\r\njiffies_lo = jiffies_total - jiffies_hi;\r\ndbs_info->freq_lo = freq_lo;\r\ndbs_info->freq_lo_jiffies = jiffies_lo;\r\ndbs_info->freq_hi_jiffies = jiffies_hi;\r\nreturn freq_hi;\r\n}\r\nstatic void ondemand_powersave_bias_init_cpu(int cpu)\r\n{\r\nstruct cpu_dbs_info_s *dbs_info = &per_cpu(od_cpu_dbs_info, cpu);\r\ndbs_info->freq_table = cpufreq_frequency_get_table(cpu);\r\ndbs_info->freq_lo = 0;\r\n}\r\nstatic void ondemand_powersave_bias_init(void)\r\n{\r\nint i;\r\nfor_each_online_cpu(i) {\r\nondemand_powersave_bias_init_cpu(i);\r\n}\r\n}\r\nstatic ssize_t show_sampling_rate_min(struct kobject *kobj,\r\nstruct attribute *attr, char *buf)\r\n{\r\nreturn sprintf(buf, "%u\n", min_sampling_rate);\r\n}\r\nstatic ssize_t store_sampling_rate(struct kobject *a, struct attribute *b,\r\nconst char *buf, size_t count)\r\n{\r\nunsigned int input;\r\nint ret;\r\nret = sscanf(buf, "%u", &input);\r\nif (ret != 1)\r\nreturn -EINVAL;\r\ndbs_tuners_ins.sampling_rate = max(input, min_sampling_rate);\r\nreturn count;\r\n}\r\nstatic ssize_t store_io_is_busy(struct kobject *a, struct attribute *b,\r\nconst char *buf, size_t count)\r\n{\r\nunsigned int input;\r\nint ret;\r\nret = sscanf(buf, "%u", &input);\r\nif (ret != 1)\r\nreturn -EINVAL;\r\ndbs_tuners_ins.io_is_busy = !!input;\r\nreturn count;\r\n}\r\nstatic ssize_t store_up_threshold(struct kobject *a, struct attribute *b,\r\nconst char *buf, size_t count)\r\n{\r\nunsigned int input;\r\nint ret;\r\nret = sscanf(buf, "%u", &input);\r\nif (ret != 1 || input > MAX_FREQUENCY_UP_THRESHOLD ||\r\ninput < MIN_FREQUENCY_UP_THRESHOLD) {\r\nreturn -EINVAL;\r\n}\r\ndbs_tuners_ins.up_threshold = input;\r\nreturn count;\r\n}\r\nstatic ssize_t store_sampling_down_factor(struct kobject *a,\r\nstruct attribute *b, const char *buf, size_t count)\r\n{\r\nunsigned int input, j;\r\nint ret;\r\nret = sscanf(buf, "%u", &input);\r\nif (ret != 1 || input > MAX_SAMPLING_DOWN_FACTOR || input < 1)\r\nreturn -EINVAL;\r\ndbs_tuners_ins.sampling_down_factor = input;\r\nfor_each_online_cpu(j) {\r\nstruct cpu_dbs_info_s *dbs_info;\r\ndbs_info = &per_cpu(od_cpu_dbs_info, j);\r\ndbs_info->rate_mult = 1;\r\n}\r\nreturn count;\r\n}\r\nstatic ssize_t store_ignore_nice_load(struct kobject *a, struct attribute *b,\r\nconst char *buf, size_t count)\r\n{\r\nunsigned int input;\r\nint ret;\r\nunsigned int j;\r\nret = sscanf(buf, "%u", &input);\r\nif (ret != 1)\r\nreturn -EINVAL;\r\nif (input > 1)\r\ninput = 1;\r\nif (input == dbs_tuners_ins.ignore_nice) {\r\nreturn count;\r\n}\r\ndbs_tuners_ins.ignore_nice = input;\r\nfor_each_online_cpu(j) {\r\nstruct cpu_dbs_info_s *dbs_info;\r\ndbs_info = &per_cpu(od_cpu_dbs_info, j);\r\ndbs_info->prev_cpu_idle = get_cpu_idle_time(j,\r\n&dbs_info->prev_cpu_wall);\r\nif (dbs_tuners_ins.ignore_nice)\r\ndbs_info->prev_cpu_nice = kstat_cpu(j).cpustat.nice;\r\n}\r\nreturn count;\r\n}\r\nstatic ssize_t store_powersave_bias(struct kobject *a, struct attribute *b,\r\nconst char *buf, size_t count)\r\n{\r\nunsigned int input;\r\nint ret;\r\nret = sscanf(buf, "%u", &input);\r\nif (ret != 1)\r\nreturn -EINVAL;\r\nif (input > 1000)\r\ninput = 1000;\r\ndbs_tuners_ins.powersave_bias = input;\r\nondemand_powersave_bias_init();\r\nreturn count;\r\n}\r\nstatic void dbs_freq_increase(struct cpufreq_policy *p, unsigned int freq)\r\n{\r\nif (dbs_tuners_ins.powersave_bias)\r\nfreq = powersave_bias_target(p, freq, CPUFREQ_RELATION_H);\r\nelse if (p->cur == p->max)\r\nreturn;\r\n__cpufreq_driver_target(p, freq, dbs_tuners_ins.powersave_bias ?\r\nCPUFREQ_RELATION_L : CPUFREQ_RELATION_H);\r\n}\r\nstatic void dbs_check_cpu(struct cpu_dbs_info_s *this_dbs_info)\r\n{\r\nunsigned int max_load_freq;\r\nstruct cpufreq_policy *policy;\r\nunsigned int j;\r\nthis_dbs_info->freq_lo = 0;\r\npolicy = this_dbs_info->cur_policy;\r\nmax_load_freq = 0;\r\nfor_each_cpu(j, policy->cpus) {\r\nstruct cpu_dbs_info_s *j_dbs_info;\r\ncputime64_t cur_wall_time, cur_idle_time, cur_iowait_time;\r\nunsigned int idle_time, wall_time, iowait_time;\r\nunsigned int load, load_freq;\r\nint freq_avg;\r\nj_dbs_info = &per_cpu(od_cpu_dbs_info, j);\r\ncur_idle_time = get_cpu_idle_time(j, &cur_wall_time);\r\ncur_iowait_time = get_cpu_iowait_time(j, &cur_wall_time);\r\nwall_time = (unsigned int) cputime64_sub(cur_wall_time,\r\nj_dbs_info->prev_cpu_wall);\r\nj_dbs_info->prev_cpu_wall = cur_wall_time;\r\nidle_time = (unsigned int) cputime64_sub(cur_idle_time,\r\nj_dbs_info->prev_cpu_idle);\r\nj_dbs_info->prev_cpu_idle = cur_idle_time;\r\niowait_time = (unsigned int) cputime64_sub(cur_iowait_time,\r\nj_dbs_info->prev_cpu_iowait);\r\nj_dbs_info->prev_cpu_iowait = cur_iowait_time;\r\nif (dbs_tuners_ins.ignore_nice) {\r\ncputime64_t cur_nice;\r\nunsigned long cur_nice_jiffies;\r\ncur_nice = cputime64_sub(kstat_cpu(j).cpustat.nice,\r\nj_dbs_info->prev_cpu_nice);\r\ncur_nice_jiffies = (unsigned long)\r\ncputime64_to_jiffies64(cur_nice);\r\nj_dbs_info->prev_cpu_nice = kstat_cpu(j).cpustat.nice;\r\nidle_time += jiffies_to_usecs(cur_nice_jiffies);\r\n}\r\nif (dbs_tuners_ins.io_is_busy && idle_time >= iowait_time)\r\nidle_time -= iowait_time;\r\nif (unlikely(!wall_time || wall_time < idle_time))\r\ncontinue;\r\nload = 100 * (wall_time - idle_time) / wall_time;\r\nfreq_avg = __cpufreq_driver_getavg(policy, j);\r\nif (freq_avg <= 0)\r\nfreq_avg = policy->cur;\r\nload_freq = load * freq_avg;\r\nif (load_freq > max_load_freq)\r\nmax_load_freq = load_freq;\r\n}\r\nif (max_load_freq > dbs_tuners_ins.up_threshold * policy->cur) {\r\nif (policy->cur < policy->max)\r\nthis_dbs_info->rate_mult =\r\ndbs_tuners_ins.sampling_down_factor;\r\ndbs_freq_increase(policy, policy->max);\r\nreturn;\r\n}\r\nif (policy->cur == policy->min)\r\nreturn;\r\nif (max_load_freq <\r\n(dbs_tuners_ins.up_threshold - dbs_tuners_ins.down_differential) *\r\npolicy->cur) {\r\nunsigned int freq_next;\r\nfreq_next = max_load_freq /\r\n(dbs_tuners_ins.up_threshold -\r\ndbs_tuners_ins.down_differential);\r\nthis_dbs_info->rate_mult = 1;\r\nif (freq_next < policy->min)\r\nfreq_next = policy->min;\r\nif (!dbs_tuners_ins.powersave_bias) {\r\n__cpufreq_driver_target(policy, freq_next,\r\nCPUFREQ_RELATION_L);\r\n} else {\r\nint freq = powersave_bias_target(policy, freq_next,\r\nCPUFREQ_RELATION_L);\r\n__cpufreq_driver_target(policy, freq,\r\nCPUFREQ_RELATION_L);\r\n}\r\n}\r\n}\r\nstatic void do_dbs_timer(struct work_struct *work)\r\n{\r\nstruct cpu_dbs_info_s *dbs_info =\r\ncontainer_of(work, struct cpu_dbs_info_s, work.work);\r\nunsigned int cpu = dbs_info->cpu;\r\nint sample_type = dbs_info->sample_type;\r\nint delay;\r\nmutex_lock(&dbs_info->timer_mutex);\r\ndbs_info->sample_type = DBS_NORMAL_SAMPLE;\r\nif (!dbs_tuners_ins.powersave_bias ||\r\nsample_type == DBS_NORMAL_SAMPLE) {\r\ndbs_check_cpu(dbs_info);\r\nif (dbs_info->freq_lo) {\r\ndbs_info->sample_type = DBS_SUB_SAMPLE;\r\ndelay = dbs_info->freq_hi_jiffies;\r\n} else {\r\ndelay = usecs_to_jiffies(dbs_tuners_ins.sampling_rate\r\n* dbs_info->rate_mult);\r\nif (num_online_cpus() > 1)\r\ndelay -= jiffies % delay;\r\n}\r\n} else {\r\n__cpufreq_driver_target(dbs_info->cur_policy,\r\ndbs_info->freq_lo, CPUFREQ_RELATION_H);\r\ndelay = dbs_info->freq_lo_jiffies;\r\n}\r\nschedule_delayed_work_on(cpu, &dbs_info->work, delay);\r\nmutex_unlock(&dbs_info->timer_mutex);\r\n}\r\nstatic inline void dbs_timer_init(struct cpu_dbs_info_s *dbs_info)\r\n{\r\nint delay = usecs_to_jiffies(dbs_tuners_ins.sampling_rate);\r\nif (num_online_cpus() > 1)\r\ndelay -= jiffies % delay;\r\ndbs_info->sample_type = DBS_NORMAL_SAMPLE;\r\nINIT_DELAYED_WORK_DEFERRABLE(&dbs_info->work, do_dbs_timer);\r\nschedule_delayed_work_on(dbs_info->cpu, &dbs_info->work, delay);\r\n}\r\nstatic inline void dbs_timer_exit(struct cpu_dbs_info_s *dbs_info)\r\n{\r\ncancel_delayed_work_sync(&dbs_info->work);\r\n}\r\nstatic int should_io_be_busy(void)\r\n{\r\n#if defined(CONFIG_X86)\r\nif (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &&\r\nboot_cpu_data.x86 == 6 &&\r\nboot_cpu_data.x86_model >= 15)\r\nreturn 1;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int cpufreq_governor_dbs(struct cpufreq_policy *policy,\r\nunsigned int event)\r\n{\r\nunsigned int cpu = policy->cpu;\r\nstruct cpu_dbs_info_s *this_dbs_info;\r\nunsigned int j;\r\nint rc;\r\nthis_dbs_info = &per_cpu(od_cpu_dbs_info, cpu);\r\nswitch (event) {\r\ncase CPUFREQ_GOV_START:\r\nif ((!cpu_online(cpu)) || (!policy->cur))\r\nreturn -EINVAL;\r\nmutex_lock(&dbs_mutex);\r\ndbs_enable++;\r\nfor_each_cpu(j, policy->cpus) {\r\nstruct cpu_dbs_info_s *j_dbs_info;\r\nj_dbs_info = &per_cpu(od_cpu_dbs_info, j);\r\nj_dbs_info->cur_policy = policy;\r\nj_dbs_info->prev_cpu_idle = get_cpu_idle_time(j,\r\n&j_dbs_info->prev_cpu_wall);\r\nif (dbs_tuners_ins.ignore_nice) {\r\nj_dbs_info->prev_cpu_nice =\r\nkstat_cpu(j).cpustat.nice;\r\n}\r\n}\r\nthis_dbs_info->cpu = cpu;\r\nthis_dbs_info->rate_mult = 1;\r\nondemand_powersave_bias_init_cpu(cpu);\r\nif (dbs_enable == 1) {\r\nunsigned int latency;\r\nrc = sysfs_create_group(cpufreq_global_kobject,\r\n&dbs_attr_group);\r\nif (rc) {\r\nmutex_unlock(&dbs_mutex);\r\nreturn rc;\r\n}\r\nlatency = policy->cpuinfo.transition_latency / 1000;\r\nif (latency == 0)\r\nlatency = 1;\r\nmin_sampling_rate = max(min_sampling_rate,\r\nMIN_LATENCY_MULTIPLIER * latency);\r\ndbs_tuners_ins.sampling_rate =\r\nmax(min_sampling_rate,\r\nlatency * LATENCY_MULTIPLIER);\r\ndbs_tuners_ins.io_is_busy = should_io_be_busy();\r\n}\r\nmutex_unlock(&dbs_mutex);\r\nmutex_init(&this_dbs_info->timer_mutex);\r\ndbs_timer_init(this_dbs_info);\r\nbreak;\r\ncase CPUFREQ_GOV_STOP:\r\ndbs_timer_exit(this_dbs_info);\r\nmutex_lock(&dbs_mutex);\r\nmutex_destroy(&this_dbs_info->timer_mutex);\r\ndbs_enable--;\r\nmutex_unlock(&dbs_mutex);\r\nif (!dbs_enable)\r\nsysfs_remove_group(cpufreq_global_kobject,\r\n&dbs_attr_group);\r\nbreak;\r\ncase CPUFREQ_GOV_LIMITS:\r\nmutex_lock(&this_dbs_info->timer_mutex);\r\nif (policy->max < this_dbs_info->cur_policy->cur)\r\n__cpufreq_driver_target(this_dbs_info->cur_policy,\r\npolicy->max, CPUFREQ_RELATION_H);\r\nelse if (policy->min > this_dbs_info->cur_policy->cur)\r\n__cpufreq_driver_target(this_dbs_info->cur_policy,\r\npolicy->min, CPUFREQ_RELATION_L);\r\nmutex_unlock(&this_dbs_info->timer_mutex);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init cpufreq_gov_dbs_init(void)\r\n{\r\ncputime64_t wall;\r\nu64 idle_time;\r\nint cpu = get_cpu();\r\nidle_time = get_cpu_idle_time_us(cpu, &wall);\r\nput_cpu();\r\nif (idle_time != -1ULL) {\r\ndbs_tuners_ins.up_threshold = MICRO_FREQUENCY_UP_THRESHOLD;\r\ndbs_tuners_ins.down_differential =\r\nMICRO_FREQUENCY_DOWN_DIFFERENTIAL;\r\nmin_sampling_rate = MICRO_FREQUENCY_MIN_SAMPLE_RATE;\r\n} else {\r\nmin_sampling_rate =\r\nMIN_SAMPLING_RATE_RATIO * jiffies_to_usecs(10);\r\n}\r\nreturn cpufreq_register_governor(&cpufreq_gov_ondemand);\r\n}\r\nstatic void __exit cpufreq_gov_dbs_exit(void)\r\n{\r\ncpufreq_unregister_governor(&cpufreq_gov_ondemand);\r\n}
