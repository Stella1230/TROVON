static double sym_weight(const struct sym_entry *sym, struct perf_top *top)\r\n{\r\ndouble weight = sym->snap_count;\r\nint counter;\r\nif (!top->display_weighted)\r\nreturn weight;\r\nfor (counter = 1; counter < top->evlist->nr_entries - 1; counter++)\r\nweight *= sym->count[counter];\r\nweight /= (sym->count[counter] + 1);\r\nreturn weight;\r\n}\r\nstatic void perf_top__remove_active_sym(struct perf_top *top, struct sym_entry *syme)\r\n{\r\npthread_mutex_lock(&top->active_symbols_lock);\r\nlist_del_init(&syme->node);\r\npthread_mutex_unlock(&top->active_symbols_lock);\r\n}\r\nstatic void rb_insert_active_sym(struct rb_root *tree, struct sym_entry *se)\r\n{\r\nstruct rb_node **p = &tree->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct sym_entry *iter;\r\nwhile (*p != NULL) {\r\nparent = *p;\r\niter = rb_entry(parent, struct sym_entry, rb_node);\r\nif (se->weight > iter->weight)\r\np = &(*p)->rb_left;\r\nelse\r\np = &(*p)->rb_right;\r\n}\r\nrb_link_node(&se->rb_node, parent, p);\r\nrb_insert_color(&se->rb_node, tree);\r\n}\r\nsize_t perf_top__header_snprintf(struct perf_top *top, char *bf, size_t size)\r\n{\r\nstruct perf_evsel *counter;\r\nfloat samples_per_sec = top->samples / top->delay_secs;\r\nfloat ksamples_per_sec = top->kernel_samples / top->delay_secs;\r\nfloat esamples_percent = (100.0 * top->exact_samples) / top->samples;\r\nsize_t ret = 0;\r\nif (!perf_guest) {\r\nret = SNPRINTF(bf, size,\r\n" PerfTop:%8.0f irqs/sec kernel:%4.1f%%"\r\n" exact: %4.1f%% [", samples_per_sec,\r\n100.0 - (100.0 * ((samples_per_sec - ksamples_per_sec) /\r\nsamples_per_sec)),\r\nesamples_percent);\r\n} else {\r\nfloat us_samples_per_sec = top->us_samples / top->delay_secs;\r\nfloat guest_kernel_samples_per_sec = top->guest_kernel_samples / top->delay_secs;\r\nfloat guest_us_samples_per_sec = top->guest_us_samples / top->delay_secs;\r\nret = SNPRINTF(bf, size,\r\n" PerfTop:%8.0f irqs/sec kernel:%4.1f%% us:%4.1f%%"\r\n" guest kernel:%4.1f%% guest us:%4.1f%%"\r\n" exact: %4.1f%% [", samples_per_sec,\r\n100.0 - (100.0 * ((samples_per_sec - ksamples_per_sec) /\r\nsamples_per_sec)),\r\n100.0 - (100.0 * ((samples_per_sec - us_samples_per_sec) /\r\nsamples_per_sec)),\r\n100.0 - (100.0 * ((samples_per_sec -\r\nguest_kernel_samples_per_sec) /\r\nsamples_per_sec)),\r\n100.0 - (100.0 * ((samples_per_sec -\r\nguest_us_samples_per_sec) /\r\nsamples_per_sec)),\r\nesamples_percent);\r\n}\r\nif (top->evlist->nr_entries == 1 || !top->display_weighted) {\r\nstruct perf_evsel *first;\r\nfirst = list_entry(top->evlist->entries.next, struct perf_evsel, node);\r\nret += SNPRINTF(bf + ret, size - ret, "%" PRIu64 "%s ",\r\n(uint64_t)first->attr.sample_period,\r\ntop->freq ? "Hz" : "");\r\n}\r\nif (!top->display_weighted) {\r\nret += SNPRINTF(bf + ret, size - ret, "%s",\r\nevent_name(top->sym_evsel));\r\n} else {\r\nsize_t last_pos = size - 30;\r\nlist_for_each_entry(counter, &top->evlist->entries, node) {\r\nret += SNPRINTF(bf + ret, size - ret, "%s%s",\r\ncounter->idx ? "/" : "",\r\nevent_name(counter));\r\nif (ret > last_pos) {\r\nsprintf(bf + last_pos - 3, "..");\r\nret = last_pos - 1;\r\nbreak;\r\n}\r\n}\r\n}\r\nret += SNPRINTF(bf + ret, size - ret, "], ");\r\nif (top->target_pid != -1)\r\nret += SNPRINTF(bf + ret, size - ret, " (target_pid: %d",\r\ntop->target_pid);\r\nelse if (top->target_tid != -1)\r\nret += SNPRINTF(bf + ret, size - ret, " (target_tid: %d",\r\ntop->target_tid);\r\nelse\r\nret += SNPRINTF(bf + ret, size - ret, " (all");\r\nif (top->cpu_list)\r\nret += SNPRINTF(bf + ret, size - ret, ", CPU%s: %s)",\r\ntop->evlist->cpus->nr > 1 ? "s" : "", top->cpu_list);\r\nelse {\r\nif (top->target_tid != -1)\r\nret += SNPRINTF(bf + ret, size - ret, ")");\r\nelse\r\nret += SNPRINTF(bf + ret, size - ret, ", %d CPU%s)",\r\ntop->evlist->cpus->nr,\r\ntop->evlist->cpus->nr > 1 ? "s" : "");\r\n}\r\nreturn ret;\r\n}\r\nvoid perf_top__reset_sample_counters(struct perf_top *top)\r\n{\r\ntop->samples = top->us_samples = top->kernel_samples =\r\ntop->exact_samples = top->guest_kernel_samples =\r\ntop->guest_us_samples = 0;\r\n}\r\nfloat perf_top__decay_samples(struct perf_top *top, struct rb_root *root)\r\n{\r\nstruct sym_entry *syme, *n;\r\nfloat sum_ksamples = 0.0;\r\nint snap = !top->display_weighted ? top->sym_evsel->idx : 0, j;\r\npthread_mutex_lock(&top->active_symbols_lock);\r\nsyme = list_entry(top->active_symbols.next, struct sym_entry, node);\r\npthread_mutex_unlock(&top->active_symbols_lock);\r\ntop->rb_entries = 0;\r\nlist_for_each_entry_safe_from(syme, n, &top->active_symbols, node) {\r\nsyme->snap_count = syme->count[snap];\r\nif (syme->snap_count != 0) {\r\nif ((top->hide_user_symbols &&\r\nsyme->map->dso->kernel == DSO_TYPE_USER) ||\r\n(top->hide_kernel_symbols &&\r\nsyme->map->dso->kernel == DSO_TYPE_KERNEL)) {\r\nperf_top__remove_active_sym(top, syme);\r\ncontinue;\r\n}\r\nsyme->weight = sym_weight(syme, top);\r\nif ((int)syme->snap_count >= top->count_filter) {\r\nrb_insert_active_sym(root, syme);\r\n++top->rb_entries;\r\n}\r\nsum_ksamples += syme->snap_count;\r\nfor (j = 0; j < top->evlist->nr_entries; j++)\r\nsyme->count[j] = top->zero ? 0 : syme->count[j] * 7 / 8;\r\n} else\r\nperf_top__remove_active_sym(top, syme);\r\n}\r\nreturn sum_ksamples;\r\n}\r\nvoid perf_top__find_widths(struct perf_top *top, struct rb_root *root,\r\nint *dso_width, int *dso_short_width, int *sym_width)\r\n{\r\nstruct rb_node *nd;\r\nint printed = 0;\r\n*sym_width = *dso_width = *dso_short_width = 0;\r\nfor (nd = rb_first(root); nd; nd = rb_next(nd)) {\r\nstruct sym_entry *syme = rb_entry(nd, struct sym_entry, rb_node);\r\nstruct symbol *sym = sym_entry__symbol(syme);\r\nif (++printed > top->print_entries ||\r\n(int)syme->snap_count < top->count_filter)\r\ncontinue;\r\nif (syme->map->dso->long_name_len > *dso_width)\r\n*dso_width = syme->map->dso->long_name_len;\r\nif (syme->map->dso->short_name_len > *dso_short_width)\r\n*dso_short_width = syme->map->dso->short_name_len;\r\nif (sym->namelen > *sym_width)\r\n*sym_width = sym->namelen;\r\n}\r\n}
