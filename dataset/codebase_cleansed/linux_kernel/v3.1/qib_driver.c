const char *qib_get_unit_name(int unit)\r\n{\r\nstatic char iname[16];\r\nsnprintf(iname, sizeof iname, "infinipath%u", unit);\r\nreturn iname;\r\n}\r\nint qib_count_active_units(void)\r\n{\r\nstruct qib_devdata *dd;\r\nstruct qib_pportdata *ppd;\r\nunsigned long flags;\r\nint pidx, nunits_active = 0;\r\nspin_lock_irqsave(&qib_devs_lock, flags);\r\nlist_for_each_entry(dd, &qib_dev_list, list) {\r\nif (!(dd->flags & QIB_PRESENT) || !dd->kregbase)\r\ncontinue;\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\r\nppd = dd->pport + pidx;\r\nif (ppd->lid && (ppd->lflags & (QIBL_LINKINIT |\r\nQIBL_LINKARMED | QIBL_LINKACTIVE))) {\r\nnunits_active++;\r\nbreak;\r\n}\r\n}\r\n}\r\nspin_unlock_irqrestore(&qib_devs_lock, flags);\r\nreturn nunits_active;\r\n}\r\nint qib_count_units(int *npresentp, int *nupp)\r\n{\r\nint nunits = 0, npresent = 0, nup = 0;\r\nstruct qib_devdata *dd;\r\nunsigned long flags;\r\nint pidx;\r\nstruct qib_pportdata *ppd;\r\nspin_lock_irqsave(&qib_devs_lock, flags);\r\nlist_for_each_entry(dd, &qib_dev_list, list) {\r\nnunits++;\r\nif ((dd->flags & QIB_PRESENT) && dd->kregbase)\r\nnpresent++;\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\r\nppd = dd->pport + pidx;\r\nif (ppd->lid && (ppd->lflags & (QIBL_LINKINIT |\r\nQIBL_LINKARMED | QIBL_LINKACTIVE)))\r\nnup++;\r\n}\r\n}\r\nspin_unlock_irqrestore(&qib_devs_lock, flags);\r\nif (npresentp)\r\n*npresentp = npresent;\r\nif (nupp)\r\n*nupp = nup;\r\nreturn nunits;\r\n}\r\nint qib_wait_linkstate(struct qib_pportdata *ppd, u32 state, int msecs)\r\n{\r\nint ret;\r\nunsigned long flags;\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nif (ppd->state_wanted) {\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nret = -EBUSY;\r\ngoto bail;\r\n}\r\nppd->state_wanted = state;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nwait_event_interruptible_timeout(ppd->state_wait,\r\n(ppd->lflags & state),\r\nmsecs_to_jiffies(msecs));\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->state_wanted = 0;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nif (!(ppd->lflags & state))\r\nret = -ETIMEDOUT;\r\nelse\r\nret = 0;\r\nbail:\r\nreturn ret;\r\n}\r\nint qib_set_linkstate(struct qib_pportdata *ppd, u8 newstate)\r\n{\r\nu32 lstate;\r\nint ret;\r\nstruct qib_devdata *dd = ppd->dd;\r\nunsigned long flags;\r\nswitch (newstate) {\r\ncase QIB_IB_LINKDOWN_ONLY:\r\ndd->f_set_ib_cfg(ppd, QIB_IB_CFG_LSTATE,\r\nIB_LINKCMD_DOWN | IB_LINKINITCMD_NOP);\r\nret = 0;\r\ngoto bail;\r\ncase QIB_IB_LINKDOWN:\r\ndd->f_set_ib_cfg(ppd, QIB_IB_CFG_LSTATE,\r\nIB_LINKCMD_DOWN | IB_LINKINITCMD_POLL);\r\nret = 0;\r\ngoto bail;\r\ncase QIB_IB_LINKDOWN_SLEEP:\r\ndd->f_set_ib_cfg(ppd, QIB_IB_CFG_LSTATE,\r\nIB_LINKCMD_DOWN | IB_LINKINITCMD_SLEEP);\r\nret = 0;\r\ngoto bail;\r\ncase QIB_IB_LINKDOWN_DISABLE:\r\ndd->f_set_ib_cfg(ppd, QIB_IB_CFG_LSTATE,\r\nIB_LINKCMD_DOWN | IB_LINKINITCMD_DISABLE);\r\nret = 0;\r\ngoto bail;\r\ncase QIB_IB_LINKARM:\r\nif (ppd->lflags & QIBL_LINKARMED) {\r\nret = 0;\r\ngoto bail;\r\n}\r\nif (!(ppd->lflags & (QIBL_LINKINIT | QIBL_LINKACTIVE))) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_LINKV;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\ndd->f_set_ib_cfg(ppd, QIB_IB_CFG_LSTATE,\r\nIB_LINKCMD_ARMED | IB_LINKINITCMD_NOP);\r\nlstate = QIBL_LINKV;\r\nbreak;\r\ncase QIB_IB_LINKACTIVE:\r\nif (ppd->lflags & QIBL_LINKACTIVE) {\r\nret = 0;\r\ngoto bail;\r\n}\r\nif (!(ppd->lflags & QIBL_LINKARMED)) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\ndd->f_set_ib_cfg(ppd, QIB_IB_CFG_LSTATE,\r\nIB_LINKCMD_ACTIVE | IB_LINKINITCMD_NOP);\r\nlstate = QIBL_LINKACTIVE;\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nret = qib_wait_linkstate(ppd, lstate, 10);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic inline void *qib_get_egrbuf(const struct qib_ctxtdata *rcd, u32 etail)\r\n{\r\nconst u32 chunk = etail / rcd->rcvegrbufs_perchunk;\r\nconst u32 idx = etail % rcd->rcvegrbufs_perchunk;\r\nreturn rcd->rcvegrbuf[chunk] + idx * rcd->dd->rcvegrbufsize;\r\n}\r\nstatic u32 qib_rcv_hdrerr(struct qib_ctxtdata *rcd, struct qib_pportdata *ppd,\r\nu32 ctxt, u32 eflags, u32 l, u32 etail,\r\n__le32 *rhf_addr, struct qib_message_header *rhdr)\r\n{\r\nu32 ret = 0;\r\nif (eflags & (QLOGIC_IB_RHF_H_ICRCERR | QLOGIC_IB_RHF_H_VCRCERR))\r\nret = 1;\r\nelse if (eflags == QLOGIC_IB_RHF_H_TIDERR) {\r\nstruct qib_ib_header *hdr = (struct qib_ib_header *) rhdr;\r\nstruct qib_other_headers *ohdr = NULL;\r\nstruct qib_ibport *ibp = &ppd->ibport_data;\r\nstruct qib_qp *qp = NULL;\r\nu32 tlen = qib_hdrget_length_in_bytes(rhf_addr);\r\nu16 lid = be16_to_cpu(hdr->lrh[1]);\r\nint lnh = be16_to_cpu(hdr->lrh[0]) & 3;\r\nu32 qp_num;\r\nu32 opcode;\r\nu32 psn;\r\nint diff;\r\nunsigned long flags;\r\nif (tlen < 24)\r\ngoto drop;\r\nif (lid < QIB_MULTICAST_LID_BASE) {\r\nlid &= ~((1 << ppd->lmc) - 1);\r\nif (unlikely(lid != ppd->lid))\r\ngoto drop;\r\n}\r\nif (lnh == QIB_LRH_BTH)\r\nohdr = &hdr->u.oth;\r\nelse if (lnh == QIB_LRH_GRH) {\r\nu32 vtf;\r\nohdr = &hdr->u.l.oth;\r\nif (hdr->u.l.grh.next_hdr != IB_GRH_NEXT_HDR)\r\ngoto drop;\r\nvtf = be32_to_cpu(hdr->u.l.grh.version_tclass_flow);\r\nif ((vtf >> IB_GRH_VERSION_SHIFT) != IB_GRH_VERSION)\r\ngoto drop;\r\n} else\r\ngoto drop;\r\nopcode = be32_to_cpu(ohdr->bth[0]);\r\nopcode >>= 24;\r\npsn = be32_to_cpu(ohdr->bth[2]);\r\nqp_num = be32_to_cpu(ohdr->bth[1]) & QIB_QPN_MASK;\r\nif (qp_num != QIB_MULTICAST_QPN) {\r\nint ruc_res;\r\nqp = qib_lookup_qpn(ibp, qp_num);\r\nif (!qp)\r\ngoto drop;\r\nspin_lock(&qp->r_lock);\r\nif (!(ib_qib_state_ops[qp->state] &\r\nQIB_PROCESS_RECV_OK)) {\r\nibp->n_pkt_drops++;\r\ngoto unlock;\r\n}\r\nswitch (qp->ibqp.qp_type) {\r\ncase IB_QPT_RC:\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nruc_res =\r\nqib_ruc_check_hdr(\r\nibp, hdr,\r\nlnh == QIB_LRH_GRH,\r\nqp,\r\nbe32_to_cpu(ohdr->bth[0]));\r\nif (ruc_res) {\r\nspin_unlock_irqrestore(&qp->s_lock,\r\nflags);\r\ngoto unlock;\r\n}\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nif (opcode <\r\nIB_OPCODE_RC_RDMA_READ_RESPONSE_FIRST) {\r\ndiff = qib_cmp24(psn, qp->r_psn);\r\nif (!qp->r_nak_state && diff >= 0) {\r\nibp->n_rc_seqnak++;\r\nqp->r_nak_state =\r\nIB_NAK_PSN_ERROR;\r\nqp->r_ack_psn = qp->r_psn;\r\nif (list_empty(&qp->rspwait)) {\r\nqp->r_flags |=\r\nQIB_R_RSP_NAK;\r\natomic_inc(\r\n&qp->refcount);\r\nlist_add_tail(\r\n&qp->rspwait,\r\n&rcd->qp_wait_list);\r\n}\r\n}\r\n}\r\nbreak;\r\ncase IB_QPT_SMI:\r\ncase IB_QPT_GSI:\r\ncase IB_QPT_UD:\r\ncase IB_QPT_UC:\r\ndefault:\r\nbreak;\r\n}\r\nunlock:\r\nspin_unlock(&qp->r_lock);\r\nif (atomic_dec_and_test(&qp->refcount))\r\nwake_up(&qp->wait);\r\n}\r\n}\r\ndrop:\r\nreturn ret;\r\n}\r\nu32 qib_kreceive(struct qib_ctxtdata *rcd, u32 *llic, u32 *npkts)\r\n{\r\nstruct qib_devdata *dd = rcd->dd;\r\nstruct qib_pportdata *ppd = rcd->ppd;\r\n__le32 *rhf_addr;\r\nvoid *ebuf;\r\nconst u32 rsize = dd->rcvhdrentsize;\r\nconst u32 maxcnt = dd->rcvhdrcnt * rsize;\r\nu32 etail = -1, l, hdrqtail;\r\nstruct qib_message_header *hdr;\r\nu32 eflags, etype, tlen, i = 0, updegr = 0, crcs = 0;\r\nint last;\r\nu64 lval;\r\nstruct qib_qp *qp, *nqp;\r\nl = rcd->head;\r\nrhf_addr = (__le32 *) rcd->rcvhdrq + l + dd->rhf_offset;\r\nif (dd->flags & QIB_NODMA_RTAIL) {\r\nu32 seq = qib_hdrget_seq(rhf_addr);\r\nif (seq != rcd->seq_cnt)\r\ngoto bail;\r\nhdrqtail = 0;\r\n} else {\r\nhdrqtail = qib_get_rcvhdrtail(rcd);\r\nif (l == hdrqtail)\r\ngoto bail;\r\nsmp_rmb();\r\n}\r\nfor (last = 0, i = 1; !last; i += !last) {\r\nhdr = dd->f_get_msgheader(dd, rhf_addr);\r\neflags = qib_hdrget_err_flags(rhf_addr);\r\netype = qib_hdrget_rcv_type(rhf_addr);\r\ntlen = qib_hdrget_length_in_bytes(rhf_addr);\r\nebuf = NULL;\r\nif ((dd->flags & QIB_NODMA_RTAIL) ?\r\nqib_hdrget_use_egr_buf(rhf_addr) :\r\n(etype != RCVHQ_RCV_TYPE_EXPECTED)) {\r\netail = qib_hdrget_index(rhf_addr);\r\nupdegr = 1;\r\nif (tlen > sizeof(*hdr) ||\r\netype >= RCVHQ_RCV_TYPE_NON_KD)\r\nebuf = qib_get_egrbuf(rcd, etail);\r\n}\r\nif (!eflags) {\r\nu16 lrh_len = be16_to_cpu(hdr->lrh[2]) << 2;\r\nif (lrh_len != tlen) {\r\nqib_stats.sps_lenerrs++;\r\ngoto move_along;\r\n}\r\n}\r\nif (etype == RCVHQ_RCV_TYPE_NON_KD && !eflags &&\r\nebuf == NULL &&\r\ntlen > (dd->rcvhdrentsize - 2 + 1 -\r\nqib_hdrget_offset(rhf_addr)) << 2) {\r\ngoto move_along;\r\n}\r\nif (unlikely(eflags))\r\ncrcs += qib_rcv_hdrerr(rcd, ppd, rcd->ctxt, eflags, l,\r\netail, rhf_addr, hdr);\r\nelse if (etype == RCVHQ_RCV_TYPE_NON_KD) {\r\nqib_ib_rcv(rcd, hdr, ebuf, tlen);\r\nif (crcs)\r\ncrcs--;\r\nelse if (llic && *llic)\r\n--*llic;\r\n}\r\nmove_along:\r\nl += rsize;\r\nif (l >= maxcnt)\r\nl = 0;\r\nif (i == QIB_MAX_PKT_RECV)\r\nlast = 1;\r\nrhf_addr = (__le32 *) rcd->rcvhdrq + l + dd->rhf_offset;\r\nif (dd->flags & QIB_NODMA_RTAIL) {\r\nu32 seq = qib_hdrget_seq(rhf_addr);\r\nif (++rcd->seq_cnt > 13)\r\nrcd->seq_cnt = 1;\r\nif (seq != rcd->seq_cnt)\r\nlast = 1;\r\n} else if (l == hdrqtail)\r\nlast = 1;\r\nlval = l;\r\nif (!last && !(i & 0xf)) {\r\ndd->f_update_usrhead(rcd, lval, updegr, etail, i);\r\nupdegr = 0;\r\n}\r\n}\r\nrcd->head = l;\r\nrcd->pkt_count += i;\r\nlist_for_each_entry_safe(qp, nqp, &rcd->qp_wait_list, rspwait) {\r\nlist_del_init(&qp->rspwait);\r\nif (qp->r_flags & QIB_R_RSP_NAK) {\r\nqp->r_flags &= ~QIB_R_RSP_NAK;\r\nqib_send_rc_ack(qp);\r\n}\r\nif (qp->r_flags & QIB_R_RSP_SEND) {\r\nunsigned long flags;\r\nqp->r_flags &= ~QIB_R_RSP_SEND;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif (ib_qib_state_ops[qp->state] &\r\nQIB_PROCESS_OR_FLUSH_SEND)\r\nqib_schedule_send(qp);\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\n}\r\nif (atomic_dec_and_test(&qp->refcount))\r\nwake_up(&qp->wait);\r\n}\r\nbail:\r\nif (npkts)\r\n*npkts = i;\r\nlval = (u64)rcd->head | dd->rhdrhead_intr_off;\r\ndd->f_update_usrhead(rcd, lval, updegr, etail, i);\r\nreturn crcs;\r\n}\r\nint qib_set_mtu(struct qib_pportdata *ppd, u16 arg)\r\n{\r\nu32 piosize;\r\nint ret, chk;\r\nif (arg != 256 && arg != 512 && arg != 1024 && arg != 2048 &&\r\narg != 4096) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nchk = ib_mtu_enum_to_int(qib_ibmtu);\r\nif (chk > 0 && arg > chk) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\npiosize = ppd->ibmaxlen;\r\nppd->ibmtu = arg;\r\nif (arg >= (piosize - QIB_PIO_MAXIBHDR)) {\r\nif (piosize != ppd->init_ibmaxlen) {\r\nif (arg > piosize && arg <= ppd->init_ibmaxlen)\r\npiosize = ppd->init_ibmaxlen - 2 * sizeof(u32);\r\nppd->ibmaxlen = piosize;\r\n}\r\n} else if ((arg + QIB_PIO_MAXIBHDR) != ppd->ibmaxlen) {\r\npiosize = arg + QIB_PIO_MAXIBHDR - 2 * sizeof(u32);\r\nppd->ibmaxlen = piosize;\r\n}\r\nppd->dd->f_set_ib_cfg(ppd, QIB_IB_CFG_MTU, 0);\r\nret = 0;\r\nbail:\r\nreturn ret;\r\n}\r\nint qib_set_lid(struct qib_pportdata *ppd, u32 lid, u8 lmc)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nppd->lid = lid;\r\nppd->lmc = lmc;\r\ndd->f_set_ib_cfg(ppd, QIB_IB_CFG_LIDLMC,\r\nlid | (~((1U << lmc) - 1)) << 16);\r\nqib_devinfo(dd->pcidev, "IB%u:%u got a lid: 0x%x\n",\r\ndd->unit, ppd->port, lid);\r\nreturn 0;\r\n}\r\nstatic void qib_run_led_override(unsigned long opaque)\r\n{\r\nstruct qib_pportdata *ppd = (struct qib_pportdata *)opaque;\r\nstruct qib_devdata *dd = ppd->dd;\r\nint timeoff;\r\nint ph_idx;\r\nif (!(dd->flags & QIB_INITTED))\r\nreturn;\r\nph_idx = ppd->led_override_phase++ & 1;\r\nppd->led_override = ppd->led_override_vals[ph_idx];\r\ntimeoff = ppd->led_override_timeoff;\r\ndd->f_setextled(ppd, 1);\r\nif (ppd->led_override_vals[0] || ppd->led_override_vals[1])\r\nmod_timer(&ppd->led_override_timer, jiffies + timeoff);\r\n}\r\nvoid qib_set_led_override(struct qib_pportdata *ppd, unsigned int val)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nint timeoff, freq;\r\nif (!(dd->flags & QIB_INITTED))\r\nreturn;\r\ntimeoff = HZ;\r\nfreq = (val & LED_OVER_FREQ_MASK) >> LED_OVER_FREQ_SHIFT;\r\nif (freq) {\r\nppd->led_override_vals[0] = val & 0xF;\r\nppd->led_override_vals[1] = (val >> 4) & 0xF;\r\ntimeoff = (HZ << 4)/freq;\r\n} else {\r\nppd->led_override_vals[0] = val & 0xF;\r\nppd->led_override_vals[1] = val & 0xF;\r\n}\r\nppd->led_override_timeoff = timeoff;\r\nif (atomic_inc_return(&ppd->led_override_timer_active) == 1) {\r\ninit_timer(&ppd->led_override_timer);\r\nppd->led_override_timer.function = qib_run_led_override;\r\nppd->led_override_timer.data = (unsigned long) ppd;\r\nppd->led_override_timer.expires = jiffies + 1;\r\nadd_timer(&ppd->led_override_timer);\r\n} else {\r\nif (ppd->led_override_vals[0] || ppd->led_override_vals[1])\r\nmod_timer(&ppd->led_override_timer, jiffies + 1);\r\natomic_dec(&ppd->led_override_timer_active);\r\n}\r\n}\r\nint qib_reset_device(int unit)\r\n{\r\nint ret, i;\r\nstruct qib_devdata *dd = qib_lookup(unit);\r\nstruct qib_pportdata *ppd;\r\nunsigned long flags;\r\nint pidx;\r\nif (!dd) {\r\nret = -ENODEV;\r\ngoto bail;\r\n}\r\nqib_devinfo(dd->pcidev, "Reset on unit %u requested\n", unit);\r\nif (!dd->kregbase || !(dd->flags & QIB_PRESENT)) {\r\nqib_devinfo(dd->pcidev, "Invalid unit number %u or "\r\n"not initialized or not present\n", unit);\r\nret = -ENXIO;\r\ngoto bail;\r\n}\r\nspin_lock_irqsave(&dd->uctxt_lock, flags);\r\nif (dd->rcd)\r\nfor (i = dd->first_user_ctxt; i < dd->cfgctxts; i++) {\r\nif (!dd->rcd[i] || !dd->rcd[i]->cnt)\r\ncontinue;\r\nspin_unlock_irqrestore(&dd->uctxt_lock, flags);\r\nret = -EBUSY;\r\ngoto bail;\r\n}\r\nspin_unlock_irqrestore(&dd->uctxt_lock, flags);\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\r\nppd = dd->pport + pidx;\r\nif (atomic_read(&ppd->led_override_timer_active)) {\r\ndel_timer_sync(&ppd->led_override_timer);\r\natomic_set(&ppd->led_override_timer_active, 0);\r\n}\r\nppd->led_override = LED_OVER_BOTH_OFF;\r\ndd->f_setextled(ppd, 0);\r\nif (dd->flags & QIB_HAS_SEND_DMA)\r\nqib_teardown_sdma(ppd);\r\n}\r\nret = dd->f_reset(dd);\r\nif (ret == 1)\r\nret = qib_init(dd, 1);\r\nelse\r\nret = -EAGAIN;\r\nif (ret)\r\nqib_dev_err(dd, "Reinitialize unit %u after "\r\n"reset failed with %d\n", unit, ret);\r\nelse\r\nqib_devinfo(dd->pcidev, "Reinitialized unit %u after "\r\n"resetting\n", unit);\r\nbail:\r\nreturn ret;\r\n}
