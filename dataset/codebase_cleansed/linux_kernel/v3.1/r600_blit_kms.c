static void\r\nset_render_target(struct radeon_device *rdev, int format,\r\nint w, int h, u64 gpu_addr)\r\n{\r\nu32 cb_color_info;\r\nint pitch, slice;\r\nh = ALIGN(h, 8);\r\nif (h < 8)\r\nh = 8;\r\ncb_color_info = ((format << 2) | (1 << 27) | (1 << 8));\r\npitch = (w / 8) - 1;\r\nslice = ((w * h) / 64) - 1;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (CB_COLOR0_BASE - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nif (rdev->family > CHIP_R600 && rdev->family < CHIP_RV770) {\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SURFACE_BASE_UPDATE, 0));\r\nradeon_ring_write(rdev, 2 << 0);\r\n}\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (CB_COLOR0_SIZE - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, (pitch << 0) | (slice << 10));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (CB_COLOR0_VIEW - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (CB_COLOR0_INFO - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, cb_color_info);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (CB_COLOR0_TILE - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (CB_COLOR0_FRAG - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (CB_COLOR0_MASK - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, 0);\r\n}\r\nstatic void\r\ncp_set_surface_sync(struct radeon_device *rdev,\r\nu32 sync_type, u32 size,\r\nu64 mc_addr)\r\n{\r\nu32 cp_coher_size;\r\nif (size == 0xffffffff)\r\ncp_coher_size = 0xffffffff;\r\nelse\r\ncp_coher_size = ((size + 255) >> 8);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SURFACE_SYNC, 3));\r\nradeon_ring_write(rdev, sync_type);\r\nradeon_ring_write(rdev, cp_coher_size);\r\nradeon_ring_write(rdev, mc_addr >> 8);\r\nradeon_ring_write(rdev, 10);\r\n}\r\nstatic void\r\nset_shaders(struct radeon_device *rdev)\r\n{\r\nu64 gpu_addr;\r\nu32 sq_pgm_resources;\r\nsq_pgm_resources = (1 << 0);\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.vs_offset;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (SQ_PGM_START_VS - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (SQ_PGM_RESOURCES_VS - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, sq_pgm_resources);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (SQ_PGM_CF_OFFSET_VS - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, 0);\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.ps_offset;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (SQ_PGM_START_PS - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (SQ_PGM_RESOURCES_PS - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, sq_pgm_resources | (1 << 28));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (SQ_PGM_EXPORTS_PS - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, 2);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 1));\r\nradeon_ring_write(rdev, (SQ_PGM_CF_OFFSET_PS - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, 0);\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.vs_offset;\r\ncp_set_surface_sync(rdev, PACKET3_SH_ACTION_ENA, 512, gpu_addr);\r\n}\r\nstatic void\r\nset_vtx_resource(struct radeon_device *rdev, u64 gpu_addr)\r\n{\r\nu32 sq_vtx_constant_word2;\r\nsq_vtx_constant_word2 = ((upper_32_bits(gpu_addr) & 0xff) | (16 << 8));\r\n#ifdef __BIG_ENDIAN\r\nsq_vtx_constant_word2 |= (2 << 30);\r\n#endif\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_RESOURCE, 7));\r\nradeon_ring_write(rdev, 0x460);\r\nradeon_ring_write(rdev, gpu_addr & 0xffffffff);\r\nradeon_ring_write(rdev, 48 - 1);\r\nradeon_ring_write(rdev, sq_vtx_constant_word2);\r\nradeon_ring_write(rdev, 1 << 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, SQ_TEX_VTX_VALID_BUFFER << 30);\r\nif ((rdev->family == CHIP_RV610) ||\r\n(rdev->family == CHIP_RV620) ||\r\n(rdev->family == CHIP_RS780) ||\r\n(rdev->family == CHIP_RS880) ||\r\n(rdev->family == CHIP_RV710))\r\ncp_set_surface_sync(rdev,\r\nPACKET3_TC_ACTION_ENA, 48, gpu_addr);\r\nelse\r\ncp_set_surface_sync(rdev,\r\nPACKET3_VC_ACTION_ENA, 48, gpu_addr);\r\n}\r\nstatic void\r\nset_tex_resource(struct radeon_device *rdev,\r\nint format, int w, int h, int pitch,\r\nu64 gpu_addr)\r\n{\r\nuint32_t sq_tex_resource_word0, sq_tex_resource_word1, sq_tex_resource_word4;\r\nif (h < 1)\r\nh = 1;\r\nsq_tex_resource_word0 = (1 << 0) | (1 << 3);\r\nsq_tex_resource_word0 |= ((((pitch >> 3) - 1) << 8) |\r\n((w - 1) << 19));\r\nsq_tex_resource_word1 = (format << 26);\r\nsq_tex_resource_word1 |= ((h - 1) << 0);\r\nsq_tex_resource_word4 = ((1 << 14) |\r\n(0 << 16) |\r\n(1 << 19) |\r\n(2 << 22) |\r\n(3 << 25));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_RESOURCE, 7));\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, sq_tex_resource_word0);\r\nradeon_ring_write(rdev, sq_tex_resource_word1);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, gpu_addr >> 8);\r\nradeon_ring_write(rdev, sq_tex_resource_word4);\r\nradeon_ring_write(rdev, 0);\r\nradeon_ring_write(rdev, SQ_TEX_VTX_VALID_TEXTURE << 30);\r\n}\r\nstatic void\r\nset_scissors(struct radeon_device *rdev, int x1, int y1,\r\nint x2, int y2)\r\n{\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 2));\r\nradeon_ring_write(rdev, (PA_SC_SCREEN_SCISSOR_TL - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, (x1 << 0) | (y1 << 16));\r\nradeon_ring_write(rdev, (x2 << 0) | (y2 << 16));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 2));\r\nradeon_ring_write(rdev, (PA_SC_GENERIC_SCISSOR_TL - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, (x1 << 0) | (y1 << 16) | (1 << 31));\r\nradeon_ring_write(rdev, (x2 << 0) | (y2 << 16));\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONTEXT_REG, 2));\r\nradeon_ring_write(rdev, (PA_SC_WINDOW_SCISSOR_TL - PACKET3_SET_CONTEXT_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, (x1 << 0) | (y1 << 16) | (1 << 31));\r\nradeon_ring_write(rdev, (x2 << 0) | (y2 << 16));\r\n}\r\nstatic void\r\ndraw_auto(struct radeon_device *rdev)\r\n{\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(rdev, (VGT_PRIMITIVE_TYPE - PACKET3_SET_CONFIG_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, DI_PT_RECTLIST);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_INDEX_TYPE, 0));\r\nradeon_ring_write(rdev,\r\n#ifdef __BIG_ENDIAN\r\n(2 << 2) |\r\n#endif\r\nDI_INDEX_SIZE_16_BIT);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_NUM_INSTANCES, 0));\r\nradeon_ring_write(rdev, 1);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_DRAW_INDEX_AUTO, 1));\r\nradeon_ring_write(rdev, 3);\r\nradeon_ring_write(rdev, DI_SRC_SEL_AUTO_INDEX);\r\n}\r\nstatic void\r\nset_default_state(struct radeon_device *rdev)\r\n{\r\nu32 sq_config, sq_gpr_resource_mgmt_1, sq_gpr_resource_mgmt_2;\r\nu32 sq_thread_resource_mgmt, sq_stack_resource_mgmt_1, sq_stack_resource_mgmt_2;\r\nint num_ps_gprs, num_vs_gprs, num_temp_gprs, num_gs_gprs, num_es_gprs;\r\nint num_ps_threads, num_vs_threads, num_gs_threads, num_es_threads;\r\nint num_ps_stack_entries, num_vs_stack_entries, num_gs_stack_entries, num_es_stack_entries;\r\nu64 gpu_addr;\r\nint dwords;\r\nswitch (rdev->family) {\r\ncase CHIP_R600:\r\nnum_ps_gprs = 192;\r\nnum_vs_gprs = 56;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 0;\r\nnum_es_gprs = 0;\r\nnum_ps_threads = 136;\r\nnum_vs_threads = 48;\r\nnum_gs_threads = 4;\r\nnum_es_threads = 4;\r\nnum_ps_stack_entries = 128;\r\nnum_vs_stack_entries = 128;\r\nnum_gs_stack_entries = 0;\r\nnum_es_stack_entries = 0;\r\nbreak;\r\ncase CHIP_RV630:\r\ncase CHIP_RV635:\r\nnum_ps_gprs = 84;\r\nnum_vs_gprs = 36;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 0;\r\nnum_es_gprs = 0;\r\nnum_ps_threads = 144;\r\nnum_vs_threads = 40;\r\nnum_gs_threads = 4;\r\nnum_es_threads = 4;\r\nnum_ps_stack_entries = 40;\r\nnum_vs_stack_entries = 40;\r\nnum_gs_stack_entries = 32;\r\nnum_es_stack_entries = 16;\r\nbreak;\r\ncase CHIP_RV610:\r\ncase CHIP_RV620:\r\ncase CHIP_RS780:\r\ncase CHIP_RS880:\r\ndefault:\r\nnum_ps_gprs = 84;\r\nnum_vs_gprs = 36;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 0;\r\nnum_es_gprs = 0;\r\nnum_ps_threads = 136;\r\nnum_vs_threads = 48;\r\nnum_gs_threads = 4;\r\nnum_es_threads = 4;\r\nnum_ps_stack_entries = 40;\r\nnum_vs_stack_entries = 40;\r\nnum_gs_stack_entries = 32;\r\nnum_es_stack_entries = 16;\r\nbreak;\r\ncase CHIP_RV670:\r\nnum_ps_gprs = 144;\r\nnum_vs_gprs = 40;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 0;\r\nnum_es_gprs = 0;\r\nnum_ps_threads = 136;\r\nnum_vs_threads = 48;\r\nnum_gs_threads = 4;\r\nnum_es_threads = 4;\r\nnum_ps_stack_entries = 40;\r\nnum_vs_stack_entries = 40;\r\nnum_gs_stack_entries = 32;\r\nnum_es_stack_entries = 16;\r\nbreak;\r\ncase CHIP_RV770:\r\nnum_ps_gprs = 192;\r\nnum_vs_gprs = 56;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 0;\r\nnum_es_gprs = 0;\r\nnum_ps_threads = 188;\r\nnum_vs_threads = 60;\r\nnum_gs_threads = 0;\r\nnum_es_threads = 0;\r\nnum_ps_stack_entries = 256;\r\nnum_vs_stack_entries = 256;\r\nnum_gs_stack_entries = 0;\r\nnum_es_stack_entries = 0;\r\nbreak;\r\ncase CHIP_RV730:\r\ncase CHIP_RV740:\r\nnum_ps_gprs = 84;\r\nnum_vs_gprs = 36;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 0;\r\nnum_es_gprs = 0;\r\nnum_ps_threads = 188;\r\nnum_vs_threads = 60;\r\nnum_gs_threads = 0;\r\nnum_es_threads = 0;\r\nnum_ps_stack_entries = 128;\r\nnum_vs_stack_entries = 128;\r\nnum_gs_stack_entries = 0;\r\nnum_es_stack_entries = 0;\r\nbreak;\r\ncase CHIP_RV710:\r\nnum_ps_gprs = 192;\r\nnum_vs_gprs = 56;\r\nnum_temp_gprs = 4;\r\nnum_gs_gprs = 0;\r\nnum_es_gprs = 0;\r\nnum_ps_threads = 144;\r\nnum_vs_threads = 48;\r\nnum_gs_threads = 0;\r\nnum_es_threads = 0;\r\nnum_ps_stack_entries = 128;\r\nnum_vs_stack_entries = 128;\r\nnum_gs_stack_entries = 0;\r\nnum_es_stack_entries = 0;\r\nbreak;\r\n}\r\nif ((rdev->family == CHIP_RV610) ||\r\n(rdev->family == CHIP_RV620) ||\r\n(rdev->family == CHIP_RS780) ||\r\n(rdev->family == CHIP_RS880) ||\r\n(rdev->family == CHIP_RV710))\r\nsq_config = 0;\r\nelse\r\nsq_config = VC_ENABLE;\r\nsq_config |= (DX9_CONSTS |\r\nALU_INST_PREFER_VECTOR |\r\nPS_PRIO(0) |\r\nVS_PRIO(1) |\r\nGS_PRIO(2) |\r\nES_PRIO(3));\r\nsq_gpr_resource_mgmt_1 = (NUM_PS_GPRS(num_ps_gprs) |\r\nNUM_VS_GPRS(num_vs_gprs) |\r\nNUM_CLAUSE_TEMP_GPRS(num_temp_gprs));\r\nsq_gpr_resource_mgmt_2 = (NUM_GS_GPRS(num_gs_gprs) |\r\nNUM_ES_GPRS(num_es_gprs));\r\nsq_thread_resource_mgmt = (NUM_PS_THREADS(num_ps_threads) |\r\nNUM_VS_THREADS(num_vs_threads) |\r\nNUM_GS_THREADS(num_gs_threads) |\r\nNUM_ES_THREADS(num_es_threads));\r\nsq_stack_resource_mgmt_1 = (NUM_PS_STACK_ENTRIES(num_ps_stack_entries) |\r\nNUM_VS_STACK_ENTRIES(num_vs_stack_entries));\r\nsq_stack_resource_mgmt_2 = (NUM_GS_STACK_ENTRIES(num_gs_stack_entries) |\r\nNUM_ES_STACK_ENTRIES(num_es_stack_entries));\r\ndwords = ALIGN(rdev->r600_blit.state_len, 0x10);\r\ngpu_addr = rdev->r600_blit.shader_gpu_addr + rdev->r600_blit.state_offset;\r\nradeon_ring_write(rdev, PACKET3(PACKET3_INDIRECT_BUFFER, 2));\r\nradeon_ring_write(rdev,\r\n#ifdef __BIG_ENDIAN\r\n(2 << 0) |\r\n#endif\r\n(gpu_addr & 0xFFFFFFFC));\r\nradeon_ring_write(rdev, upper_32_bits(gpu_addr) & 0xFF);\r\nradeon_ring_write(rdev, dwords);\r\nradeon_ring_write(rdev, PACKET3(PACKET3_SET_CONFIG_REG, 6));\r\nradeon_ring_write(rdev, (SQ_CONFIG - PACKET3_SET_CONFIG_REG_OFFSET) >> 2);\r\nradeon_ring_write(rdev, sq_config);\r\nradeon_ring_write(rdev, sq_gpr_resource_mgmt_1);\r\nradeon_ring_write(rdev, sq_gpr_resource_mgmt_2);\r\nradeon_ring_write(rdev, sq_thread_resource_mgmt);\r\nradeon_ring_write(rdev, sq_stack_resource_mgmt_1);\r\nradeon_ring_write(rdev, sq_stack_resource_mgmt_2);\r\n}\r\nstatic inline uint32_t i2f(uint32_t input)\r\n{\r\nu32 result, i, exponent, fraction;\r\nif ((input & 0x3fff) == 0)\r\nresult = 0;\r\nelse {\r\nexponent = 140;\r\nfraction = (input & 0x3fff) << 10;\r\nfor (i = 0; i < 14; i++) {\r\nif (fraction & 0x800000)\r\nbreak;\r\nelse {\r\nfraction = fraction << 1;\r\nexponent = exponent - 1;\r\n}\r\n}\r\nresult = exponent << 23 | (fraction & 0x7fffff);\r\n}\r\nreturn result;\r\n}\r\nint r600_blit_init(struct radeon_device *rdev)\r\n{\r\nu32 obj_size;\r\nint i, r, dwords;\r\nvoid *ptr;\r\nu32 packet2s[16];\r\nint num_packet2s = 0;\r\nif (rdev->r600_blit.shader_obj)\r\ngoto done;\r\nmutex_init(&rdev->r600_blit.mutex);\r\nrdev->r600_blit.state_offset = 0;\r\nif (rdev->family >= CHIP_RV770)\r\nrdev->r600_blit.state_len = r7xx_default_size;\r\nelse\r\nrdev->r600_blit.state_len = r6xx_default_size;\r\ndwords = rdev->r600_blit.state_len;\r\nwhile (dwords & 0xf) {\r\npacket2s[num_packet2s++] = cpu_to_le32(PACKET2(0));\r\ndwords++;\r\n}\r\nobj_size = dwords * 4;\r\nobj_size = ALIGN(obj_size, 256);\r\nrdev->r600_blit.vs_offset = obj_size;\r\nobj_size += r6xx_vs_size * 4;\r\nobj_size = ALIGN(obj_size, 256);\r\nrdev->r600_blit.ps_offset = obj_size;\r\nobj_size += r6xx_ps_size * 4;\r\nobj_size = ALIGN(obj_size, 256);\r\nr = radeon_bo_create(rdev, obj_size, PAGE_SIZE, true, RADEON_GEM_DOMAIN_VRAM,\r\n&rdev->r600_blit.shader_obj);\r\nif (r) {\r\nDRM_ERROR("r600 failed to allocate shader\n");\r\nreturn r;\r\n}\r\nDRM_DEBUG("r6xx blit allocated bo %08x vs %08x ps %08x\n",\r\nobj_size,\r\nrdev->r600_blit.vs_offset, rdev->r600_blit.ps_offset);\r\nr = radeon_bo_reserve(rdev->r600_blit.shader_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_kmap(rdev->r600_blit.shader_obj, &ptr);\r\nif (r) {\r\nDRM_ERROR("failed to map blit object %d\n", r);\r\nreturn r;\r\n}\r\nif (rdev->family >= CHIP_RV770)\r\nmemcpy_toio(ptr + rdev->r600_blit.state_offset,\r\nr7xx_default_state, rdev->r600_blit.state_len * 4);\r\nelse\r\nmemcpy_toio(ptr + rdev->r600_blit.state_offset,\r\nr6xx_default_state, rdev->r600_blit.state_len * 4);\r\nif (num_packet2s)\r\nmemcpy_toio(ptr + rdev->r600_blit.state_offset + (rdev->r600_blit.state_len * 4),\r\npacket2s, num_packet2s * 4);\r\nfor (i = 0; i < r6xx_vs_size; i++)\r\n*(u32 *)((unsigned long)ptr + rdev->r600_blit.vs_offset + i * 4) = cpu_to_le32(r6xx_vs[i]);\r\nfor (i = 0; i < r6xx_ps_size; i++)\r\n*(u32 *)((unsigned long)ptr + rdev->r600_blit.ps_offset + i * 4) = cpu_to_le32(r6xx_ps[i]);\r\nradeon_bo_kunmap(rdev->r600_blit.shader_obj);\r\nradeon_bo_unreserve(rdev->r600_blit.shader_obj);\r\ndone:\r\nr = radeon_bo_reserve(rdev->r600_blit.shader_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_pin(rdev->r600_blit.shader_obj, RADEON_GEM_DOMAIN_VRAM,\r\n&rdev->r600_blit.shader_gpu_addr);\r\nradeon_bo_unreserve(rdev->r600_blit.shader_obj);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) pin blit object failed\n", r);\r\nreturn r;\r\n}\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);\r\nreturn 0;\r\n}\r\nvoid r600_blit_fini(struct radeon_device *rdev)\r\n{\r\nint r;\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);\r\nif (rdev->r600_blit.shader_obj == NULL)\r\nreturn;\r\nr = radeon_bo_reserve(rdev->r600_blit.shader_obj, false);\r\nif (!r) {\r\nradeon_bo_unpin(rdev->r600_blit.shader_obj);\r\nradeon_bo_unreserve(rdev->r600_blit.shader_obj);\r\n}\r\nradeon_bo_unref(&rdev->r600_blit.shader_obj);\r\n}\r\nstatic int r600_vb_ib_get(struct radeon_device *rdev)\r\n{\r\nint r;\r\nr = radeon_ib_get(rdev, &rdev->r600_blit.vb_ib);\r\nif (r) {\r\nDRM_ERROR("failed to get IB for vertex buffer\n");\r\nreturn r;\r\n}\r\nrdev->r600_blit.vb_total = 64*1024;\r\nrdev->r600_blit.vb_used = 0;\r\nreturn 0;\r\n}\r\nstatic void r600_vb_ib_put(struct radeon_device *rdev)\r\n{\r\nradeon_fence_emit(rdev, rdev->r600_blit.vb_ib->fence);\r\nradeon_ib_free(rdev, &rdev->r600_blit.vb_ib);\r\n}\r\nint r600_blit_prepare_copy(struct radeon_device *rdev, int size_bytes)\r\n{\r\nint r;\r\nint ring_size, line_size;\r\nint max_size;\r\nint dwords_per_loop = 76, num_loops;\r\nr = r600_vb_ib_get(rdev);\r\nif (r)\r\nreturn r;\r\nif (rdev->family > CHIP_R600 && rdev->family < CHIP_RV770)\r\ndwords_per_loop += 2;\r\nif (size_bytes & 3)\r\nline_size = 8192;\r\nelse\r\nline_size = 8192*4;\r\nmax_size = 8192 * line_size;\r\nnum_loops = ((size_bytes + max_size) / max_size);\r\nnum_loops += ((size_bytes % line_size) ? 1 : 0);\r\nring_size = num_loops * dwords_per_loop;\r\nring_size += 40;\r\nring_size += 10;\r\nring_size += 5;\r\nring_size += 10;\r\nr = radeon_ring_lock(rdev, ring_size);\r\nif (r)\r\nreturn r;\r\nset_default_state(rdev);\r\nset_shaders(rdev);\r\nreturn 0;\r\n}\r\nvoid r600_blit_done_copy(struct radeon_device *rdev, struct radeon_fence *fence)\r\n{\r\nint r;\r\nif (rdev->r600_blit.vb_ib)\r\nr600_vb_ib_put(rdev);\r\nif (fence)\r\nr = radeon_fence_emit(rdev, fence);\r\nradeon_ring_unlock_commit(rdev);\r\n}\r\nvoid r600_kms_blit_copy(struct radeon_device *rdev,\r\nu64 src_gpu_addr, u64 dst_gpu_addr,\r\nint size_bytes)\r\n{\r\nint max_bytes;\r\nu64 vb_gpu_addr;\r\nu32 *vb;\r\nDRM_DEBUG("emitting copy %16llx %16llx %d %d\n", src_gpu_addr, dst_gpu_addr,\r\nsize_bytes, rdev->r600_blit.vb_used);\r\nvb = (u32 *)(rdev->r600_blit.vb_ib->ptr + rdev->r600_blit.vb_used);\r\nif ((size_bytes & 3) || (src_gpu_addr & 3) || (dst_gpu_addr & 3)) {\r\nmax_bytes = 8192;\r\nwhile (size_bytes) {\r\nint cur_size = size_bytes;\r\nint src_x = src_gpu_addr & 255;\r\nint dst_x = dst_gpu_addr & 255;\r\nint h = 1;\r\nsrc_gpu_addr = src_gpu_addr & ~255ULL;\r\ndst_gpu_addr = dst_gpu_addr & ~255ULL;\r\nif (!src_x && !dst_x) {\r\nh = (cur_size / max_bytes);\r\nif (h > 8192)\r\nh = 8192;\r\nif (h == 0)\r\nh = 1;\r\nelse\r\ncur_size = max_bytes;\r\n} else {\r\nif (cur_size > max_bytes)\r\ncur_size = max_bytes;\r\nif (cur_size > (max_bytes - dst_x))\r\ncur_size = (max_bytes - dst_x);\r\nif (cur_size > (max_bytes - src_x))\r\ncur_size = (max_bytes - src_x);\r\n}\r\nif ((rdev->r600_blit.vb_used + 48) > rdev->r600_blit.vb_total) {\r\nWARN_ON(1);\r\n}\r\nvb[0] = i2f(dst_x);\r\nvb[1] = 0;\r\nvb[2] = i2f(src_x);\r\nvb[3] = 0;\r\nvb[4] = i2f(dst_x);\r\nvb[5] = i2f(h);\r\nvb[6] = i2f(src_x);\r\nvb[7] = i2f(h);\r\nvb[8] = i2f(dst_x + cur_size);\r\nvb[9] = i2f(h);\r\nvb[10] = i2f(src_x + cur_size);\r\nvb[11] = i2f(h);\r\nset_tex_resource(rdev, FMT_8,\r\nsrc_x + cur_size, h, src_x + cur_size,\r\nsrc_gpu_addr);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_TC_ACTION_ENA, (src_x + cur_size * h), src_gpu_addr);\r\nset_render_target(rdev, COLOR_8,\r\ndst_x + cur_size, h,\r\ndst_gpu_addr);\r\nset_scissors(rdev, dst_x, 0, dst_x + cur_size, h);\r\nvb_gpu_addr = rdev->r600_blit.vb_ib->gpu_addr + rdev->r600_blit.vb_used;\r\nset_vtx_resource(rdev, vb_gpu_addr);\r\ndraw_auto(rdev);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_CB_ACTION_ENA | PACKET3_CB0_DEST_BASE_ENA,\r\ncur_size * h, dst_gpu_addr);\r\nvb += 12;\r\nrdev->r600_blit.vb_used += 12 * 4;\r\nsrc_gpu_addr += cur_size * h;\r\ndst_gpu_addr += cur_size * h;\r\nsize_bytes -= cur_size * h;\r\n}\r\n} else {\r\nmax_bytes = 8192 * 4;\r\nwhile (size_bytes) {\r\nint cur_size = size_bytes;\r\nint src_x = (src_gpu_addr & 255);\r\nint dst_x = (dst_gpu_addr & 255);\r\nint h = 1;\r\nsrc_gpu_addr = src_gpu_addr & ~255ULL;\r\ndst_gpu_addr = dst_gpu_addr & ~255ULL;\r\nif (!src_x && !dst_x) {\r\nh = (cur_size / max_bytes);\r\nif (h > 8192)\r\nh = 8192;\r\nif (h == 0)\r\nh = 1;\r\nelse\r\ncur_size = max_bytes;\r\n} else {\r\nif (cur_size > max_bytes)\r\ncur_size = max_bytes;\r\nif (cur_size > (max_bytes - dst_x))\r\ncur_size = (max_bytes - dst_x);\r\nif (cur_size > (max_bytes - src_x))\r\ncur_size = (max_bytes - src_x);\r\n}\r\nif ((rdev->r600_blit.vb_used + 48) > rdev->r600_blit.vb_total) {\r\nWARN_ON(1);\r\n}\r\nvb[0] = i2f(dst_x / 4);\r\nvb[1] = 0;\r\nvb[2] = i2f(src_x / 4);\r\nvb[3] = 0;\r\nvb[4] = i2f(dst_x / 4);\r\nvb[5] = i2f(h);\r\nvb[6] = i2f(src_x / 4);\r\nvb[7] = i2f(h);\r\nvb[8] = i2f((dst_x + cur_size) / 4);\r\nvb[9] = i2f(h);\r\nvb[10] = i2f((src_x + cur_size) / 4);\r\nvb[11] = i2f(h);\r\nset_tex_resource(rdev, FMT_8_8_8_8,\r\n(src_x + cur_size) / 4,\r\nh, (src_x + cur_size) / 4,\r\nsrc_gpu_addr);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_TC_ACTION_ENA, (src_x + cur_size * h), src_gpu_addr);\r\nset_render_target(rdev, COLOR_8_8_8_8,\r\n(dst_x + cur_size) / 4, h,\r\ndst_gpu_addr);\r\nset_scissors(rdev, (dst_x / 4), 0, (dst_x + cur_size / 4), h);\r\nvb_gpu_addr = rdev->r600_blit.vb_ib->gpu_addr + rdev->r600_blit.vb_used;\r\nset_vtx_resource(rdev, vb_gpu_addr);\r\ndraw_auto(rdev);\r\ncp_set_surface_sync(rdev,\r\nPACKET3_CB_ACTION_ENA | PACKET3_CB0_DEST_BASE_ENA,\r\ncur_size * h, dst_gpu_addr);\r\nvb += 12;\r\nrdev->r600_blit.vb_used += 12 * 4;\r\nsrc_gpu_addr += cur_size * h;\r\ndst_gpu_addr += cur_size * h;\r\nsize_bytes -= cur_size * h;\r\n}\r\n}\r\n}
