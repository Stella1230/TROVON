int tulip_refill_rx(struct net_device *dev)\r\n{\r\nstruct tulip_private *tp = netdev_priv(dev);\r\nint entry;\r\nint refilled = 0;\r\nfor (; tp->cur_rx - tp->dirty_rx > 0; tp->dirty_rx++) {\r\nentry = tp->dirty_rx % RX_RING_SIZE;\r\nif (tp->rx_buffers[entry].skb == NULL) {\r\nstruct sk_buff *skb;\r\ndma_addr_t mapping;\r\nskb = tp->rx_buffers[entry].skb = dev_alloc_skb(PKT_BUF_SZ);\r\nif (skb == NULL)\r\nbreak;\r\nmapping = pci_map_single(tp->pdev, skb->data, PKT_BUF_SZ,\r\nPCI_DMA_FROMDEVICE);\r\ntp->rx_buffers[entry].mapping = mapping;\r\nskb->dev = dev;\r\ntp->rx_ring[entry].buffer1 = cpu_to_le32(mapping);\r\nrefilled++;\r\n}\r\ntp->rx_ring[entry].status = cpu_to_le32(DescOwned);\r\n}\r\nif(tp->chip_id == LC82C168) {\r\nif(((ioread32(tp->base_addr + CSR5)>>17)&0x07) == 4) {\r\niowrite32(0x01, tp->base_addr + CSR2);\r\n}\r\n}\r\nreturn refilled;\r\n}\r\nvoid oom_timer(unsigned long data)\r\n{\r\nstruct net_device *dev = (struct net_device *)data;\r\nstruct tulip_private *tp = netdev_priv(dev);\r\nnapi_schedule(&tp->napi);\r\n}\r\nint tulip_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct tulip_private *tp = container_of(napi, struct tulip_private, napi);\r\nstruct net_device *dev = tp->dev;\r\nint entry = tp->cur_rx % RX_RING_SIZE;\r\nint work_done = 0;\r\n#ifdef CONFIG_TULIP_NAPI_HW_MITIGATION\r\nint received = 0;\r\n#endif\r\n#ifdef CONFIG_TULIP_NAPI_HW_MITIGATION\r\nif (budget >=RX_RING_SIZE) budget--;\r\n#endif\r\nif (tulip_debug > 4)\r\nnetdev_dbg(dev, " In tulip_rx(), entry %d %08x\n",\r\nentry, tp->rx_ring[entry].status);\r\ndo {\r\nif (ioread32(tp->base_addr + CSR5) == 0xffffffff) {\r\nnetdev_dbg(dev, " In tulip_poll(), hardware disappeared\n");\r\nbreak;\r\n}\r\niowrite32((RxIntr | RxNoBuf), tp->base_addr + CSR5);\r\nwhile ( ! (tp->rx_ring[entry].status & cpu_to_le32(DescOwned))) {\r\ns32 status = le32_to_cpu(tp->rx_ring[entry].status);\r\nshort pkt_len;\r\nif (tp->dirty_rx + RX_RING_SIZE == tp->cur_rx)\r\nbreak;\r\nif (tulip_debug > 5)\r\nnetdev_dbg(dev, "In tulip_rx(), entry %d %08x\n",\r\nentry, status);\r\nif (++work_done >= budget)\r\ngoto not_done;\r\npkt_len = ((status >> 16) & 0x7ff) - 4;\r\nif ((status & (RxLengthOver2047 |\r\nRxDescCRCError |\r\nRxDescCollisionSeen |\r\nRxDescRunt |\r\nRxDescDescErr |\r\nRxWholePkt)) != RxWholePkt ||\r\npkt_len > 1518) {\r\nif ((status & (RxLengthOver2047 |\r\nRxWholePkt)) != RxWholePkt) {\r\nif ((status & 0xffff) != 0x7fff) {\r\nif (tulip_debug > 1)\r\ndev_warn(&dev->dev,\r\n"Oversized Ethernet frame spanned multiple buffers, status %08x!\n",\r\nstatus);\r\ndev->stats.rx_length_errors++;\r\n}\r\n} else {\r\nif (tulip_debug > 2)\r\nnetdev_dbg(dev, "Receive error, Rx status %08x\n",\r\nstatus);\r\ndev->stats.rx_errors++;\r\nif (pkt_len > 1518 ||\r\n(status & RxDescRunt))\r\ndev->stats.rx_length_errors++;\r\nif (status & 0x0004)\r\ndev->stats.rx_frame_errors++;\r\nif (status & 0x0002)\r\ndev->stats.rx_crc_errors++;\r\nif (status & 0x0001)\r\ndev->stats.rx_fifo_errors++;\r\n}\r\n} else {\r\nstruct sk_buff *skb;\r\nif (pkt_len < tulip_rx_copybreak &&\r\n(skb = dev_alloc_skb(pkt_len + 2)) != NULL) {\r\nskb_reserve(skb, 2);\r\npci_dma_sync_single_for_cpu(tp->pdev,\r\ntp->rx_buffers[entry].mapping,\r\npkt_len, PCI_DMA_FROMDEVICE);\r\n#if ! defined(__alpha__)\r\nskb_copy_to_linear_data(skb, tp->rx_buffers[entry].skb->data,\r\npkt_len);\r\nskb_put(skb, pkt_len);\r\n#else\r\nmemcpy(skb_put(skb, pkt_len),\r\ntp->rx_buffers[entry].skb->data,\r\npkt_len);\r\n#endif\r\npci_dma_sync_single_for_device(tp->pdev,\r\ntp->rx_buffers[entry].mapping,\r\npkt_len, PCI_DMA_FROMDEVICE);\r\n} else {\r\nchar *temp = skb_put(skb = tp->rx_buffers[entry].skb,\r\npkt_len);\r\n#ifndef final_version\r\nif (tp->rx_buffers[entry].mapping !=\r\nle32_to_cpu(tp->rx_ring[entry].buffer1)) {\r\ndev_err(&dev->dev,\r\n"Internal fault: The skbuff addresses do not match in tulip_rx: %08x vs. %08llx %p / %p\n",\r\nle32_to_cpu(tp->rx_ring[entry].buffer1),\r\n(unsigned long long)tp->rx_buffers[entry].mapping,\r\nskb->head, temp);\r\n}\r\n#endif\r\npci_unmap_single(tp->pdev, tp->rx_buffers[entry].mapping,\r\nPKT_BUF_SZ, PCI_DMA_FROMDEVICE);\r\ntp->rx_buffers[entry].skb = NULL;\r\ntp->rx_buffers[entry].mapping = 0;\r\n}\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_receive_skb(skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += pkt_len;\r\n}\r\n#ifdef CONFIG_TULIP_NAPI_HW_MITIGATION\r\nreceived++;\r\n#endif\r\nentry = (++tp->cur_rx) % RX_RING_SIZE;\r\nif (tp->cur_rx - tp->dirty_rx > RX_RING_SIZE/4)\r\ntulip_refill_rx(dev);\r\n}\r\n} while ((ioread32(tp->base_addr + CSR5) & RxIntr));\r\n#ifdef CONFIG_TULIP_NAPI_HW_MITIGATION\r\nif( tp->flags & HAS_INTR_MITIGATION) {\r\nif( received > 1 ) {\r\nif( ! tp->mit_on ) {\r\ntp->mit_on = 1;\r\niowrite32(mit_table[MIT_TABLE], tp->base_addr + CSR11);\r\n}\r\n}\r\nelse {\r\nif( tp->mit_on ) {\r\ntp->mit_on = 0;\r\niowrite32(0, tp->base_addr + CSR11);\r\n}\r\n}\r\n}\r\n#endif\r\ntulip_refill_rx(dev);\r\nif (tp->rx_buffers[tp->dirty_rx % RX_RING_SIZE].skb == NULL)\r\ngoto oom;\r\nnapi_complete(napi);\r\niowrite32(tulip_tbl[tp->chip_id].valid_intrs, tp->base_addr+CSR7);\r\nreturn work_done;\r\nnot_done:\r\nif (tp->cur_rx - tp->dirty_rx > RX_RING_SIZE/2 ||\r\ntp->rx_buffers[tp->dirty_rx % RX_RING_SIZE].skb == NULL)\r\ntulip_refill_rx(dev);\r\nif (tp->rx_buffers[tp->dirty_rx % RX_RING_SIZE].skb == NULL)\r\ngoto oom;\r\nreturn work_done;\r\noom:\r\nmod_timer(&tp->oom_timer, jiffies+1);\r\nnapi_complete(napi);\r\nreturn work_done;\r\n}\r\nstatic int tulip_rx(struct net_device *dev)\r\n{\r\nstruct tulip_private *tp = netdev_priv(dev);\r\nint entry = tp->cur_rx % RX_RING_SIZE;\r\nint rx_work_limit = tp->dirty_rx + RX_RING_SIZE - tp->cur_rx;\r\nint received = 0;\r\nif (tulip_debug > 4)\r\nnetdev_dbg(dev, "In tulip_rx(), entry %d %08x\n",\r\nentry, tp->rx_ring[entry].status);\r\nwhile ( ! (tp->rx_ring[entry].status & cpu_to_le32(DescOwned))) {\r\ns32 status = le32_to_cpu(tp->rx_ring[entry].status);\r\nshort pkt_len;\r\nif (tulip_debug > 5)\r\nnetdev_dbg(dev, "In tulip_rx(), entry %d %08x\n",\r\nentry, status);\r\nif (--rx_work_limit < 0)\r\nbreak;\r\npkt_len = ((status >> 16) & 0x7ff) - 4;\r\nif ((status & (RxLengthOver2047 |\r\nRxDescCRCError |\r\nRxDescCollisionSeen |\r\nRxDescRunt |\r\nRxDescDescErr |\r\nRxWholePkt)) != RxWholePkt ||\r\npkt_len > 1518) {\r\nif ((status & (RxLengthOver2047 |\r\nRxWholePkt)) != RxWholePkt) {\r\nif ((status & 0xffff) != 0x7fff) {\r\nif (tulip_debug > 1)\r\nnetdev_warn(dev,\r\n"Oversized Ethernet frame spanned multiple buffers, status %08x!\n",\r\nstatus);\r\ndev->stats.rx_length_errors++;\r\n}\r\n} else {\r\nif (tulip_debug > 2)\r\nnetdev_dbg(dev, "Receive error, Rx status %08x\n",\r\nstatus);\r\ndev->stats.rx_errors++;\r\nif (pkt_len > 1518 ||\r\n(status & RxDescRunt))\r\ndev->stats.rx_length_errors++;\r\nif (status & 0x0004)\r\ndev->stats.rx_frame_errors++;\r\nif (status & 0x0002)\r\ndev->stats.rx_crc_errors++;\r\nif (status & 0x0001)\r\ndev->stats.rx_fifo_errors++;\r\n}\r\n} else {\r\nstruct sk_buff *skb;\r\nif (pkt_len < tulip_rx_copybreak &&\r\n(skb = dev_alloc_skb(pkt_len + 2)) != NULL) {\r\nskb_reserve(skb, 2);\r\npci_dma_sync_single_for_cpu(tp->pdev,\r\ntp->rx_buffers[entry].mapping,\r\npkt_len, PCI_DMA_FROMDEVICE);\r\n#if ! defined(__alpha__)\r\nskb_copy_to_linear_data(skb, tp->rx_buffers[entry].skb->data,\r\npkt_len);\r\nskb_put(skb, pkt_len);\r\n#else\r\nmemcpy(skb_put(skb, pkt_len),\r\ntp->rx_buffers[entry].skb->data,\r\npkt_len);\r\n#endif\r\npci_dma_sync_single_for_device(tp->pdev,\r\ntp->rx_buffers[entry].mapping,\r\npkt_len, PCI_DMA_FROMDEVICE);\r\n} else {\r\nchar *temp = skb_put(skb = tp->rx_buffers[entry].skb,\r\npkt_len);\r\n#ifndef final_version\r\nif (tp->rx_buffers[entry].mapping !=\r\nle32_to_cpu(tp->rx_ring[entry].buffer1)) {\r\ndev_err(&dev->dev,\r\n"Internal fault: The skbuff addresses do not match in tulip_rx: %08x vs. %Lx %p / %p\n",\r\nle32_to_cpu(tp->rx_ring[entry].buffer1),\r\n(long long)tp->rx_buffers[entry].mapping,\r\nskb->head, temp);\r\n}\r\n#endif\r\npci_unmap_single(tp->pdev, tp->rx_buffers[entry].mapping,\r\nPKT_BUF_SZ, PCI_DMA_FROMDEVICE);\r\ntp->rx_buffers[entry].skb = NULL;\r\ntp->rx_buffers[entry].mapping = 0;\r\n}\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_rx(skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += pkt_len;\r\n}\r\nreceived++;\r\nentry = (++tp->cur_rx) % RX_RING_SIZE;\r\n}\r\nreturn received;\r\n}\r\nstatic inline unsigned int phy_interrupt (struct net_device *dev)\r\n{\r\n#ifdef __hppa__\r\nstruct tulip_private *tp = netdev_priv(dev);\r\nint csr12 = ioread32(tp->base_addr + CSR12) & 0xff;\r\nif (csr12 != tp->csr12_shadow) {\r\niowrite32(csr12 | 0x02, tp->base_addr + CSR12);\r\ntp->csr12_shadow = csr12;\r\nspin_lock(&tp->lock);\r\ntulip_check_duplex(dev);\r\nspin_unlock(&tp->lock);\r\niowrite32(csr12 & ~0x02, tp->base_addr + CSR12);\r\nreturn 1;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nirqreturn_t tulip_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct net_device *dev = (struct net_device *)dev_instance;\r\nstruct tulip_private *tp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = tp->base_addr;\r\nint csr5;\r\nint missed;\r\nint rx = 0;\r\nint tx = 0;\r\nint oi = 0;\r\nint maxrx = RX_RING_SIZE;\r\nint maxtx = TX_RING_SIZE;\r\nint maxoi = TX_RING_SIZE;\r\n#ifdef CONFIG_TULIP_NAPI\r\nint rxd = 0;\r\n#else\r\nint entry;\r\n#endif\r\nunsigned int work_count = tulip_max_interrupt_work;\r\nunsigned int handled = 0;\r\ncsr5 = ioread32(ioaddr + CSR5);\r\nif (tp->flags & HAS_PHY_IRQ)\r\nhandled = phy_interrupt (dev);\r\nif ((csr5 & (NormalIntr|AbnormalIntr)) == 0)\r\nreturn IRQ_RETVAL(handled);\r\ntp->nir++;\r\ndo {\r\n#ifdef CONFIG_TULIP_NAPI\r\nif (!rxd && (csr5 & (RxIntr | RxNoBuf))) {\r\nrxd++;\r\niowrite32(tulip_tbl[tp->chip_id].valid_intrs&~RxPollInt, ioaddr + CSR7);\r\nnapi_schedule(&tp->napi);\r\nif (!(csr5&~(AbnormalIntr|NormalIntr|RxPollInt|TPLnkPass)))\r\nbreak;\r\n}\r\niowrite32(csr5 & 0x0001ff3f, ioaddr + CSR5);\r\n#else\r\niowrite32(csr5 & 0x0001ffff, ioaddr + CSR5);\r\nif (csr5 & (RxIntr | RxNoBuf)) {\r\nrx += tulip_rx(dev);\r\ntulip_refill_rx(dev);\r\n}\r\n#endif\r\nif (tulip_debug > 4)\r\nnetdev_dbg(dev, "interrupt csr5=%#8.8x new csr5=%#8.8x\n",\r\ncsr5, ioread32(ioaddr + CSR5));\r\nif (csr5 & (TxNoBuf | TxDied | TxIntr | TimerInt)) {\r\nunsigned int dirty_tx;\r\nspin_lock(&tp->lock);\r\nfor (dirty_tx = tp->dirty_tx; tp->cur_tx - dirty_tx > 0;\r\ndirty_tx++) {\r\nint entry = dirty_tx % TX_RING_SIZE;\r\nint status = le32_to_cpu(tp->tx_ring[entry].status);\r\nif (status < 0)\r\nbreak;\r\nif (tp->tx_buffers[entry].skb == NULL) {\r\nif (tp->tx_buffers[entry].mapping)\r\npci_unmap_single(tp->pdev,\r\ntp->tx_buffers[entry].mapping,\r\nsizeof(tp->setup_frame),\r\nPCI_DMA_TODEVICE);\r\ncontinue;\r\n}\r\nif (status & 0x8000) {\r\n#ifndef final_version\r\nif (tulip_debug > 1)\r\nnetdev_dbg(dev, "Transmit error, Tx status %08x\n",\r\nstatus);\r\n#endif\r\ndev->stats.tx_errors++;\r\nif (status & 0x4104)\r\ndev->stats.tx_aborted_errors++;\r\nif (status & 0x0C00)\r\ndev->stats.tx_carrier_errors++;\r\nif (status & 0x0200)\r\ndev->stats.tx_window_errors++;\r\nif (status & 0x0002)\r\ndev->stats.tx_fifo_errors++;\r\nif ((status & 0x0080) && tp->full_duplex == 0)\r\ndev->stats.tx_heartbeat_errors++;\r\n} else {\r\ndev->stats.tx_bytes +=\r\ntp->tx_buffers[entry].skb->len;\r\ndev->stats.collisions += (status >> 3) & 15;\r\ndev->stats.tx_packets++;\r\n}\r\npci_unmap_single(tp->pdev, tp->tx_buffers[entry].mapping,\r\ntp->tx_buffers[entry].skb->len,\r\nPCI_DMA_TODEVICE);\r\ndev_kfree_skb_irq(tp->tx_buffers[entry].skb);\r\ntp->tx_buffers[entry].skb = NULL;\r\ntp->tx_buffers[entry].mapping = 0;\r\ntx++;\r\n}\r\n#ifndef final_version\r\nif (tp->cur_tx - dirty_tx > TX_RING_SIZE) {\r\ndev_err(&dev->dev,\r\n"Out-of-sync dirty pointer, %d vs. %d\n",\r\ndirty_tx, tp->cur_tx);\r\ndirty_tx += TX_RING_SIZE;\r\n}\r\n#endif\r\nif (tp->cur_tx - dirty_tx < TX_RING_SIZE - 2)\r\nnetif_wake_queue(dev);\r\ntp->dirty_tx = dirty_tx;\r\nif (csr5 & TxDied) {\r\nif (tulip_debug > 2)\r\ndev_warn(&dev->dev,\r\n"The transmitter stopped. CSR5 is %x, CSR6 %x, new CSR6 %x\n",\r\ncsr5, ioread32(ioaddr + CSR6),\r\ntp->csr6);\r\ntulip_restart_rxtx(tp);\r\n}\r\nspin_unlock(&tp->lock);\r\n}\r\nif (csr5 & AbnormalIntr) {\r\nif (csr5 == 0xffffffff)\r\nbreak;\r\nif (csr5 & TxJabber)\r\ndev->stats.tx_errors++;\r\nif (csr5 & TxFIFOUnderflow) {\r\nif ((tp->csr6 & 0xC000) != 0xC000)\r\ntp->csr6 += 0x4000;\r\nelse\r\ntp->csr6 |= 0x00200000;\r\ntulip_restart_rxtx(tp);\r\niowrite32(0, ioaddr + CSR1);\r\n}\r\nif (csr5 & (RxDied | RxNoBuf)) {\r\nif (tp->flags & COMET_MAC_ADDR) {\r\niowrite32(tp->mc_filter[0], ioaddr + 0xAC);\r\niowrite32(tp->mc_filter[1], ioaddr + 0xB0);\r\n}\r\n}\r\nif (csr5 & RxDied) {\r\ndev->stats.rx_missed_errors += ioread32(ioaddr + CSR8) & 0xffff;\r\ndev->stats.rx_errors++;\r\ntulip_start_rxtx(tp);\r\n}\r\nif (csr5 & (TPLnkPass | TPLnkFail | 0x08000000)) {\r\nif (tp->link_change)\r\n(tp->link_change)(dev, csr5);\r\n}\r\nif (csr5 & SystemError) {\r\nint error = (csr5 >> 23) & 7;\r\ndev_err(&dev->dev,\r\n"(%lu) System Error occurred (%d)\n",\r\ntp->nir, error);\r\n}\r\niowrite32(0x0800f7ba, ioaddr + CSR5);\r\noi++;\r\n}\r\nif (csr5 & TimerInt) {\r\nif (tulip_debug > 2)\r\ndev_err(&dev->dev,\r\n"Re-enabling interrupts, %08x\n",\r\ncsr5);\r\niowrite32(tulip_tbl[tp->chip_id].valid_intrs, ioaddr + CSR7);\r\ntp->ttimer = 0;\r\noi++;\r\n}\r\nif (tx > maxtx || rx > maxrx || oi > maxoi) {\r\nif (tulip_debug > 1)\r\ndev_warn(&dev->dev, "Too much work during an interrupt, csr5=0x%08x. (%lu) (%d,%d,%d)\n",\r\ncsr5, tp->nir, tx, rx, oi);\r\niowrite32(0x8001ffff, ioaddr + CSR5);\r\nif (tp->flags & HAS_INTR_MITIGATION) {\r\niowrite32(0x8b240000, ioaddr + CSR11);\r\n} else if (tp->chip_id == LC82C168) {\r\niowrite32(0x00, ioaddr + CSR7);\r\nmod_timer(&tp->timer, RUN_AT(HZ/50));\r\n} else {\r\niowrite32(((~csr5) & 0x0001ebef) | AbnormalIntr | TimerInt, ioaddr + CSR7);\r\niowrite32(0x0012, ioaddr + CSR11);\r\n}\r\nbreak;\r\n}\r\nwork_count--;\r\nif (work_count == 0)\r\nbreak;\r\ncsr5 = ioread32(ioaddr + CSR5);\r\n#ifdef CONFIG_TULIP_NAPI\r\nif (rxd)\r\ncsr5 &= ~RxPollInt;\r\n} while ((csr5 & (TxNoBuf |\r\nTxDied |\r\nTxIntr |\r\nTimerInt |\r\nRxDied |\r\nTxFIFOUnderflow |\r\nTxJabber |\r\nTPLnkFail |\r\nSystemError )) != 0);\r\n#else\r\n}
