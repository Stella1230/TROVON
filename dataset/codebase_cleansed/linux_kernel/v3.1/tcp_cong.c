static struct tcp_congestion_ops *tcp_ca_find(const char *name)\r\n{\r\nstruct tcp_congestion_ops *e;\r\nlist_for_each_entry_rcu(e, &tcp_cong_list, list) {\r\nif (strcmp(e->name, name) == 0)\r\nreturn e;\r\n}\r\nreturn NULL;\r\n}\r\nint tcp_register_congestion_control(struct tcp_congestion_ops *ca)\r\n{\r\nint ret = 0;\r\nif (!ca->ssthresh || !ca->cong_avoid) {\r\nprintk(KERN_ERR "TCP %s does not implement required ops\n",\r\nca->name);\r\nreturn -EINVAL;\r\n}\r\nspin_lock(&tcp_cong_list_lock);\r\nif (tcp_ca_find(ca->name)) {\r\nprintk(KERN_NOTICE "TCP %s already registered\n", ca->name);\r\nret = -EEXIST;\r\n} else {\r\nlist_add_tail_rcu(&ca->list, &tcp_cong_list);\r\nprintk(KERN_INFO "TCP %s registered\n", ca->name);\r\n}\r\nspin_unlock(&tcp_cong_list_lock);\r\nreturn ret;\r\n}\r\nvoid tcp_unregister_congestion_control(struct tcp_congestion_ops *ca)\r\n{\r\nspin_lock(&tcp_cong_list_lock);\r\nlist_del_rcu(&ca->list);\r\nspin_unlock(&tcp_cong_list_lock);\r\n}\r\nvoid tcp_init_congestion_control(struct sock *sk)\r\n{\r\nstruct inet_connection_sock *icsk = inet_csk(sk);\r\nstruct tcp_congestion_ops *ca;\r\nif (icsk->icsk_ca_ops == &tcp_init_congestion_ops) {\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(ca, &tcp_cong_list, list) {\r\nif (try_module_get(ca->owner)) {\r\nicsk->icsk_ca_ops = ca;\r\nbreak;\r\n}\r\n}\r\nrcu_read_unlock();\r\n}\r\nif (icsk->icsk_ca_ops->init)\r\nicsk->icsk_ca_ops->init(sk);\r\n}\r\nvoid tcp_cleanup_congestion_control(struct sock *sk)\r\n{\r\nstruct inet_connection_sock *icsk = inet_csk(sk);\r\nif (icsk->icsk_ca_ops->release)\r\nicsk->icsk_ca_ops->release(sk);\r\nmodule_put(icsk->icsk_ca_ops->owner);\r\n}\r\nint tcp_set_default_congestion_control(const char *name)\r\n{\r\nstruct tcp_congestion_ops *ca;\r\nint ret = -ENOENT;\r\nspin_lock(&tcp_cong_list_lock);\r\nca = tcp_ca_find(name);\r\n#ifdef CONFIG_MODULES\r\nif (!ca && capable(CAP_NET_ADMIN)) {\r\nspin_unlock(&tcp_cong_list_lock);\r\nrequest_module("tcp_%s", name);\r\nspin_lock(&tcp_cong_list_lock);\r\nca = tcp_ca_find(name);\r\n}\r\n#endif\r\nif (ca) {\r\nca->flags |= TCP_CONG_NON_RESTRICTED;\r\nlist_move(&ca->list, &tcp_cong_list);\r\nret = 0;\r\n}\r\nspin_unlock(&tcp_cong_list_lock);\r\nreturn ret;\r\n}\r\nstatic int __init tcp_congestion_default(void)\r\n{\r\nreturn tcp_set_default_congestion_control(CONFIG_DEFAULT_TCP_CONG);\r\n}\r\nvoid tcp_get_available_congestion_control(char *buf, size_t maxlen)\r\n{\r\nstruct tcp_congestion_ops *ca;\r\nsize_t offs = 0;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(ca, &tcp_cong_list, list) {\r\noffs += snprintf(buf + offs, maxlen - offs,\r\n"%s%s",\r\noffs == 0 ? "" : " ", ca->name);\r\n}\r\nrcu_read_unlock();\r\n}\r\nvoid tcp_get_default_congestion_control(char *name)\r\n{\r\nstruct tcp_congestion_ops *ca;\r\nBUG_ON(list_empty(&tcp_cong_list));\r\nrcu_read_lock();\r\nca = list_entry(tcp_cong_list.next, struct tcp_congestion_ops, list);\r\nstrncpy(name, ca->name, TCP_CA_NAME_MAX);\r\nrcu_read_unlock();\r\n}\r\nvoid tcp_get_allowed_congestion_control(char *buf, size_t maxlen)\r\n{\r\nstruct tcp_congestion_ops *ca;\r\nsize_t offs = 0;\r\n*buf = '\0';\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(ca, &tcp_cong_list, list) {\r\nif (!(ca->flags & TCP_CONG_NON_RESTRICTED))\r\ncontinue;\r\noffs += snprintf(buf + offs, maxlen - offs,\r\n"%s%s",\r\noffs == 0 ? "" : " ", ca->name);\r\n}\r\nrcu_read_unlock();\r\n}\r\nint tcp_set_allowed_congestion_control(char *val)\r\n{\r\nstruct tcp_congestion_ops *ca;\r\nchar *saved_clone, *clone, *name;\r\nint ret = 0;\r\nsaved_clone = clone = kstrdup(val, GFP_USER);\r\nif (!clone)\r\nreturn -ENOMEM;\r\nspin_lock(&tcp_cong_list_lock);\r\nwhile ((name = strsep(&clone, " ")) && *name) {\r\nca = tcp_ca_find(name);\r\nif (!ca) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\n}\r\nlist_for_each_entry_rcu(ca, &tcp_cong_list, list)\r\nca->flags &= ~TCP_CONG_NON_RESTRICTED;\r\nwhile ((name = strsep(&val, " ")) && *name) {\r\nca = tcp_ca_find(name);\r\nWARN_ON(!ca);\r\nif (ca)\r\nca->flags |= TCP_CONG_NON_RESTRICTED;\r\n}\r\nout:\r\nspin_unlock(&tcp_cong_list_lock);\r\nkfree(saved_clone);\r\nreturn ret;\r\n}\r\nint tcp_set_congestion_control(struct sock *sk, const char *name)\r\n{\r\nstruct inet_connection_sock *icsk = inet_csk(sk);\r\nstruct tcp_congestion_ops *ca;\r\nint err = 0;\r\nrcu_read_lock();\r\nca = tcp_ca_find(name);\r\nif (ca == icsk->icsk_ca_ops)\r\ngoto out;\r\n#ifdef CONFIG_MODULES\r\nif (!ca && capable(CAP_NET_ADMIN)) {\r\nrcu_read_unlock();\r\nrequest_module("tcp_%s", name);\r\nrcu_read_lock();\r\nca = tcp_ca_find(name);\r\n}\r\n#endif\r\nif (!ca)\r\nerr = -ENOENT;\r\nelse if (!((ca->flags & TCP_CONG_NON_RESTRICTED) || capable(CAP_NET_ADMIN)))\r\nerr = -EPERM;\r\nelse if (!try_module_get(ca->owner))\r\nerr = -EBUSY;\r\nelse {\r\ntcp_cleanup_congestion_control(sk);\r\nicsk->icsk_ca_ops = ca;\r\nif (sk->sk_state != TCP_CLOSE && icsk->icsk_ca_ops->init)\r\nicsk->icsk_ca_ops->init(sk);\r\n}\r\nout:\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nint tcp_is_cwnd_limited(const struct sock *sk, u32 in_flight)\r\n{\r\nconst struct tcp_sock *tp = tcp_sk(sk);\r\nu32 left;\r\nif (in_flight >= tp->snd_cwnd)\r\nreturn 1;\r\nleft = tp->snd_cwnd - in_flight;\r\nif (sk_can_gso(sk) &&\r\nleft * sysctl_tcp_tso_win_divisor < tp->snd_cwnd &&\r\nleft * tp->mss_cache < sk->sk_gso_max_size)\r\nreturn 1;\r\nreturn left <= tcp_max_burst(tp);\r\n}\r\nvoid tcp_slow_start(struct tcp_sock *tp)\r\n{\r\nint cnt;\r\nif (sysctl_tcp_abc && tp->bytes_acked < tp->mss_cache)\r\nreturn;\r\nif (sysctl_tcp_max_ssthresh > 0 && tp->snd_cwnd > sysctl_tcp_max_ssthresh)\r\ncnt = sysctl_tcp_max_ssthresh >> 1;\r\nelse\r\ncnt = tp->snd_cwnd;\r\nif (sysctl_tcp_abc > 1 && tp->bytes_acked >= 2*tp->mss_cache)\r\ncnt <<= 1;\r\ntp->bytes_acked = 0;\r\ntp->snd_cwnd_cnt += cnt;\r\nwhile (tp->snd_cwnd_cnt >= tp->snd_cwnd) {\r\ntp->snd_cwnd_cnt -= tp->snd_cwnd;\r\nif (tp->snd_cwnd < tp->snd_cwnd_clamp)\r\ntp->snd_cwnd++;\r\n}\r\n}\r\nvoid tcp_cong_avoid_ai(struct tcp_sock *tp, u32 w)\r\n{\r\nif (tp->snd_cwnd_cnt >= w) {\r\nif (tp->snd_cwnd < tp->snd_cwnd_clamp)\r\ntp->snd_cwnd++;\r\ntp->snd_cwnd_cnt = 0;\r\n} else {\r\ntp->snd_cwnd_cnt++;\r\n}\r\n}\r\nvoid tcp_reno_cong_avoid(struct sock *sk, u32 ack, u32 in_flight)\r\n{\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nif (!tcp_is_cwnd_limited(sk, in_flight))\r\nreturn;\r\nif (tp->snd_cwnd <= tp->snd_ssthresh)\r\ntcp_slow_start(tp);\r\nelse if (sysctl_tcp_abc) {\r\nif (tp->bytes_acked >= tp->snd_cwnd*tp->mss_cache) {\r\ntp->bytes_acked -= tp->snd_cwnd*tp->mss_cache;\r\nif (tp->snd_cwnd < tp->snd_cwnd_clamp)\r\ntp->snd_cwnd++;\r\n}\r\n} else {\r\ntcp_cong_avoid_ai(tp, tp->snd_cwnd);\r\n}\r\n}\r\nu32 tcp_reno_ssthresh(struct sock *sk)\r\n{\r\nconst struct tcp_sock *tp = tcp_sk(sk);\r\nreturn max(tp->snd_cwnd >> 1U, 2U);\r\n}\r\nu32 tcp_reno_min_cwnd(const struct sock *sk)\r\n{\r\nconst struct tcp_sock *tp = tcp_sk(sk);\r\nreturn tp->snd_ssthresh/2;\r\n}
