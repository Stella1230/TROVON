irqreturn_t vmw_irq_handler(DRM_IRQ_ARGS)\r\n{\r\nstruct drm_device *dev = (struct drm_device *)arg;\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nuint32_t status;\r\nspin_lock(&dev_priv->irq_lock);\r\nstatus = inl(dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\nspin_unlock(&dev_priv->irq_lock);\r\nif (status & SVGA_IRQFLAG_ANY_FENCE)\r\nwake_up_all(&dev_priv->fence_queue);\r\nif (status & SVGA_IRQFLAG_FIFO_PROGRESS)\r\nwake_up_all(&dev_priv->fifo_queue);\r\nif (likely(status)) {\r\noutl(status, dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\nreturn IRQ_HANDLED;\r\n}\r\nreturn IRQ_NONE;\r\n}\r\nstatic bool vmw_fifo_idle(struct vmw_private *dev_priv, uint32_t sequence)\r\n{\r\nuint32_t busy;\r\nmutex_lock(&dev_priv->hw_mutex);\r\nbusy = vmw_read(dev_priv, SVGA_REG_BUSY);\r\nmutex_unlock(&dev_priv->hw_mutex);\r\nreturn (busy == 0);\r\n}\r\nvoid vmw_update_sequence(struct vmw_private *dev_priv,\r\nstruct vmw_fifo_state *fifo_state)\r\n{\r\n__le32 __iomem *fifo_mem = dev_priv->mmio_virt;\r\nuint32_t sequence = ioread32(fifo_mem + SVGA_FIFO_FENCE);\r\nif (dev_priv->last_read_sequence != sequence) {\r\ndev_priv->last_read_sequence = sequence;\r\nvmw_fence_pull(&fifo_state->fence_queue, sequence);\r\n}\r\n}\r\nbool vmw_fence_signaled(struct vmw_private *dev_priv,\r\nuint32_t sequence)\r\n{\r\nstruct vmw_fifo_state *fifo_state;\r\nbool ret;\r\nif (likely(dev_priv->last_read_sequence - sequence < VMW_FENCE_WRAP))\r\nreturn true;\r\nfifo_state = &dev_priv->fifo;\r\nvmw_update_sequence(dev_priv, fifo_state);\r\nif (likely(dev_priv->last_read_sequence - sequence < VMW_FENCE_WRAP))\r\nreturn true;\r\nif (!(fifo_state->capabilities & SVGA_FIFO_CAP_FENCE) &&\r\nvmw_fifo_idle(dev_priv, sequence))\r\nreturn true;\r\nret = ((atomic_read(&dev_priv->fence_seq) - sequence)\r\n> VMW_FENCE_WRAP);\r\nreturn ret;\r\n}\r\nint vmw_fallback_wait(struct vmw_private *dev_priv,\r\nbool lazy,\r\nbool fifo_idle,\r\nuint32_t sequence,\r\nbool interruptible,\r\nunsigned long timeout)\r\n{\r\nstruct vmw_fifo_state *fifo_state = &dev_priv->fifo;\r\nuint32_t count = 0;\r\nuint32_t signal_seq;\r\nint ret;\r\nunsigned long end_jiffies = jiffies + timeout;\r\nbool (*wait_condition)(struct vmw_private *, uint32_t);\r\nDEFINE_WAIT(__wait);\r\nwait_condition = (fifo_idle) ? &vmw_fifo_idle :\r\n&vmw_fence_signaled;\r\nif (fifo_idle)\r\ndown_read(&fifo_state->rwsem);\r\nsignal_seq = atomic_read(&dev_priv->fence_seq);\r\nret = 0;\r\nfor (;;) {\r\nprepare_to_wait(&dev_priv->fence_queue, &__wait,\r\n(interruptible) ?\r\nTASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);\r\nif (wait_condition(dev_priv, sequence))\r\nbreak;\r\nif (time_after_eq(jiffies, end_jiffies)) {\r\nDRM_ERROR("SVGA device lockup.\n");\r\nbreak;\r\n}\r\nif (lazy)\r\nschedule_timeout(1);\r\nelse if ((++count & 0x0F) == 0) {\r\n__set_current_state(TASK_RUNNING);\r\nschedule();\r\n__set_current_state((interruptible) ?\r\nTASK_INTERRUPTIBLE :\r\nTASK_UNINTERRUPTIBLE);\r\n}\r\nif (interruptible && signal_pending(current)) {\r\nret = -ERESTARTSYS;\r\nbreak;\r\n}\r\n}\r\nfinish_wait(&dev_priv->fence_queue, &__wait);\r\nif (ret == 0 && fifo_idle) {\r\n__le32 __iomem *fifo_mem = dev_priv->mmio_virt;\r\niowrite32(signal_seq, fifo_mem + SVGA_FIFO_FENCE);\r\n}\r\nwake_up_all(&dev_priv->fence_queue);\r\nif (fifo_idle)\r\nup_read(&fifo_state->rwsem);\r\nreturn ret;\r\n}\r\nint vmw_wait_fence(struct vmw_private *dev_priv,\r\nbool lazy, uint32_t sequence,\r\nbool interruptible, unsigned long timeout)\r\n{\r\nlong ret;\r\nunsigned long irq_flags;\r\nstruct vmw_fifo_state *fifo = &dev_priv->fifo;\r\nif (likely(dev_priv->last_read_sequence - sequence < VMW_FENCE_WRAP))\r\nreturn 0;\r\nif (likely(vmw_fence_signaled(dev_priv, sequence)))\r\nreturn 0;\r\nvmw_fifo_ping_host(dev_priv, SVGA_SYNC_GENERIC);\r\nif (!(fifo->capabilities & SVGA_FIFO_CAP_FENCE))\r\nreturn vmw_fallback_wait(dev_priv, lazy, true, sequence,\r\ninterruptible, timeout);\r\nif (!(dev_priv->capabilities & SVGA_CAP_IRQMASK))\r\nreturn vmw_fallback_wait(dev_priv, lazy, false, sequence,\r\ninterruptible, timeout);\r\nmutex_lock(&dev_priv->hw_mutex);\r\nif (atomic_add_return(1, &dev_priv->fence_queue_waiters) > 0) {\r\nspin_lock_irqsave(&dev_priv->irq_lock, irq_flags);\r\noutl(SVGA_IRQFLAG_ANY_FENCE,\r\ndev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK,\r\nvmw_read(dev_priv, SVGA_REG_IRQMASK) |\r\nSVGA_IRQFLAG_ANY_FENCE);\r\nspin_unlock_irqrestore(&dev_priv->irq_lock, irq_flags);\r\n}\r\nmutex_unlock(&dev_priv->hw_mutex);\r\nif (interruptible)\r\nret = wait_event_interruptible_timeout\r\n(dev_priv->fence_queue,\r\nvmw_fence_signaled(dev_priv, sequence),\r\ntimeout);\r\nelse\r\nret = wait_event_timeout\r\n(dev_priv->fence_queue,\r\nvmw_fence_signaled(dev_priv, sequence),\r\ntimeout);\r\nif (unlikely(ret == 0))\r\nret = -EBUSY;\r\nelse if (likely(ret > 0))\r\nret = 0;\r\nmutex_lock(&dev_priv->hw_mutex);\r\nif (atomic_dec_and_test(&dev_priv->fence_queue_waiters)) {\r\nspin_lock_irqsave(&dev_priv->irq_lock, irq_flags);\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK,\r\nvmw_read(dev_priv, SVGA_REG_IRQMASK) &\r\n~SVGA_IRQFLAG_ANY_FENCE);\r\nspin_unlock_irqrestore(&dev_priv->irq_lock, irq_flags);\r\n}\r\nmutex_unlock(&dev_priv->hw_mutex);\r\nreturn ret;\r\n}\r\nvoid vmw_irq_preinstall(struct drm_device *dev)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nuint32_t status;\r\nif (!(dev_priv->capabilities & SVGA_CAP_IRQMASK))\r\nreturn;\r\nspin_lock_init(&dev_priv->irq_lock);\r\nstatus = inl(dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\noutl(status, dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\n}\r\nint vmw_irq_postinstall(struct drm_device *dev)\r\n{\r\nreturn 0;\r\n}\r\nvoid vmw_irq_uninstall(struct drm_device *dev)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nuint32_t status;\r\nif (!(dev_priv->capabilities & SVGA_CAP_IRQMASK))\r\nreturn;\r\nmutex_lock(&dev_priv->hw_mutex);\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK, 0);\r\nmutex_unlock(&dev_priv->hw_mutex);\r\nstatus = inl(dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\noutl(status, dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\n}\r\nint vmw_fence_wait_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_vmw_fence_wait_arg *arg =\r\n(struct drm_vmw_fence_wait_arg *)data;\r\nunsigned long timeout;\r\nif (!arg->cookie_valid) {\r\narg->cookie_valid = 1;\r\narg->kernel_cookie = jiffies + VMW_FENCE_WAIT_TIMEOUT;\r\n}\r\ntimeout = jiffies;\r\nif (time_after_eq(timeout, (unsigned long)arg->kernel_cookie))\r\nreturn -EBUSY;\r\ntimeout = (unsigned long)arg->kernel_cookie - timeout;\r\nreturn vmw_wait_fence(vmw_priv(dev), true, arg->sequence, true, timeout);\r\n}
