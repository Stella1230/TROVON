int qib_post_srq_receive(struct ib_srq *ibsrq, struct ib_recv_wr *wr,\r\nstruct ib_recv_wr **bad_wr)\r\n{\r\nstruct qib_srq *srq = to_isrq(ibsrq);\r\nstruct qib_rwq *wq;\r\nunsigned long flags;\r\nint ret;\r\nfor (; wr; wr = wr->next) {\r\nstruct qib_rwqe *wqe;\r\nu32 next;\r\nint i;\r\nif ((unsigned) wr->num_sge > srq->rq.max_sge) {\r\n*bad_wr = wr;\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nspin_lock_irqsave(&srq->rq.lock, flags);\r\nwq = srq->rq.wq;\r\nnext = wq->head + 1;\r\nif (next >= srq->rq.size)\r\nnext = 0;\r\nif (next == wq->tail) {\r\nspin_unlock_irqrestore(&srq->rq.lock, flags);\r\n*bad_wr = wr;\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\nwqe = get_rwqe_ptr(&srq->rq, wq->head);\r\nwqe->wr_id = wr->wr_id;\r\nwqe->num_sge = wr->num_sge;\r\nfor (i = 0; i < wr->num_sge; i++)\r\nwqe->sg_list[i] = wr->sg_list[i];\r\nsmp_wmb();\r\nwq->head = next;\r\nspin_unlock_irqrestore(&srq->rq.lock, flags);\r\n}\r\nret = 0;\r\nbail:\r\nreturn ret;\r\n}\r\nstruct ib_srq *qib_create_srq(struct ib_pd *ibpd,\r\nstruct ib_srq_init_attr *srq_init_attr,\r\nstruct ib_udata *udata)\r\n{\r\nstruct qib_ibdev *dev = to_idev(ibpd->device);\r\nstruct qib_srq *srq;\r\nu32 sz;\r\nstruct ib_srq *ret;\r\nif (srq_init_attr->attr.max_sge == 0 ||\r\nsrq_init_attr->attr.max_sge > ib_qib_max_srq_sges ||\r\nsrq_init_attr->attr.max_wr == 0 ||\r\nsrq_init_attr->attr.max_wr > ib_qib_max_srq_wrs) {\r\nret = ERR_PTR(-EINVAL);\r\ngoto done;\r\n}\r\nsrq = kmalloc(sizeof(*srq), GFP_KERNEL);\r\nif (!srq) {\r\nret = ERR_PTR(-ENOMEM);\r\ngoto done;\r\n}\r\nsrq->rq.size = srq_init_attr->attr.max_wr + 1;\r\nsrq->rq.max_sge = srq_init_attr->attr.max_sge;\r\nsz = sizeof(struct ib_sge) * srq->rq.max_sge +\r\nsizeof(struct qib_rwqe);\r\nsrq->rq.wq = vmalloc_user(sizeof(struct qib_rwq) + srq->rq.size * sz);\r\nif (!srq->rq.wq) {\r\nret = ERR_PTR(-ENOMEM);\r\ngoto bail_srq;\r\n}\r\nif (udata && udata->outlen >= sizeof(__u64)) {\r\nint err;\r\nu32 s = sizeof(struct qib_rwq) + srq->rq.size * sz;\r\nsrq->ip =\r\nqib_create_mmap_info(dev, s, ibpd->uobject->context,\r\nsrq->rq.wq);\r\nif (!srq->ip) {\r\nret = ERR_PTR(-ENOMEM);\r\ngoto bail_wq;\r\n}\r\nerr = ib_copy_to_udata(udata, &srq->ip->offset,\r\nsizeof(srq->ip->offset));\r\nif (err) {\r\nret = ERR_PTR(err);\r\ngoto bail_ip;\r\n}\r\n} else\r\nsrq->ip = NULL;\r\nspin_lock_init(&srq->rq.lock);\r\nsrq->rq.wq->head = 0;\r\nsrq->rq.wq->tail = 0;\r\nsrq->limit = srq_init_attr->attr.srq_limit;\r\nspin_lock(&dev->n_srqs_lock);\r\nif (dev->n_srqs_allocated == ib_qib_max_srqs) {\r\nspin_unlock(&dev->n_srqs_lock);\r\nret = ERR_PTR(-ENOMEM);\r\ngoto bail_ip;\r\n}\r\ndev->n_srqs_allocated++;\r\nspin_unlock(&dev->n_srqs_lock);\r\nif (srq->ip) {\r\nspin_lock_irq(&dev->pending_lock);\r\nlist_add(&srq->ip->pending_mmaps, &dev->pending_mmaps);\r\nspin_unlock_irq(&dev->pending_lock);\r\n}\r\nret = &srq->ibsrq;\r\ngoto done;\r\nbail_ip:\r\nkfree(srq->ip);\r\nbail_wq:\r\nvfree(srq->rq.wq);\r\nbail_srq:\r\nkfree(srq);\r\ndone:\r\nreturn ret;\r\n}\r\nint qib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,\r\nenum ib_srq_attr_mask attr_mask,\r\nstruct ib_udata *udata)\r\n{\r\nstruct qib_srq *srq = to_isrq(ibsrq);\r\nstruct qib_rwq *wq;\r\nint ret = 0;\r\nif (attr_mask & IB_SRQ_MAX_WR) {\r\nstruct qib_rwq *owq;\r\nstruct qib_rwqe *p;\r\nu32 sz, size, n, head, tail;\r\nif ((attr->max_wr > ib_qib_max_srq_wrs) ||\r\n((attr_mask & IB_SRQ_LIMIT) ?\r\nattr->srq_limit : srq->limit) > attr->max_wr) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nsz = sizeof(struct qib_rwqe) +\r\nsrq->rq.max_sge * sizeof(struct ib_sge);\r\nsize = attr->max_wr + 1;\r\nwq = vmalloc_user(sizeof(struct qib_rwq) + size * sz);\r\nif (!wq) {\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\nif (udata && udata->inlen >= sizeof(__u64)) {\r\n__u64 offset_addr;\r\n__u64 offset = 0;\r\nret = ib_copy_from_udata(&offset_addr, udata,\r\nsizeof(offset_addr));\r\nif (ret)\r\ngoto bail_free;\r\nudata->outbuf =\r\n(void __user *) (unsigned long) offset_addr;\r\nret = ib_copy_to_udata(udata, &offset,\r\nsizeof(offset));\r\nif (ret)\r\ngoto bail_free;\r\n}\r\nspin_lock_irq(&srq->rq.lock);\r\nowq = srq->rq.wq;\r\nhead = owq->head;\r\ntail = owq->tail;\r\nif (head >= srq->rq.size || tail >= srq->rq.size) {\r\nret = -EINVAL;\r\ngoto bail_unlock;\r\n}\r\nn = head;\r\nif (n < tail)\r\nn += srq->rq.size - tail;\r\nelse\r\nn -= tail;\r\nif (size <= n) {\r\nret = -EINVAL;\r\ngoto bail_unlock;\r\n}\r\nn = 0;\r\np = wq->wq;\r\nwhile (tail != head) {\r\nstruct qib_rwqe *wqe;\r\nint i;\r\nwqe = get_rwqe_ptr(&srq->rq, tail);\r\np->wr_id = wqe->wr_id;\r\np->num_sge = wqe->num_sge;\r\nfor (i = 0; i < wqe->num_sge; i++)\r\np->sg_list[i] = wqe->sg_list[i];\r\nn++;\r\np = (struct qib_rwqe *)((char *) p + sz);\r\nif (++tail >= srq->rq.size)\r\ntail = 0;\r\n}\r\nsrq->rq.wq = wq;\r\nsrq->rq.size = size;\r\nwq->head = n;\r\nwq->tail = 0;\r\nif (attr_mask & IB_SRQ_LIMIT)\r\nsrq->limit = attr->srq_limit;\r\nspin_unlock_irq(&srq->rq.lock);\r\nvfree(owq);\r\nif (srq->ip) {\r\nstruct qib_mmap_info *ip = srq->ip;\r\nstruct qib_ibdev *dev = to_idev(srq->ibsrq.device);\r\nu32 s = sizeof(struct qib_rwq) + size * sz;\r\nqib_update_mmap_info(dev, ip, s, wq);\r\nif (udata && udata->inlen >= sizeof(__u64)) {\r\nret = ib_copy_to_udata(udata, &ip->offset,\r\nsizeof(ip->offset));\r\nif (ret)\r\ngoto bail;\r\n}\r\nspin_lock_irq(&dev->pending_lock);\r\nif (list_empty(&ip->pending_mmaps))\r\nlist_add(&ip->pending_mmaps,\r\n&dev->pending_mmaps);\r\nspin_unlock_irq(&dev->pending_lock);\r\n}\r\n} else if (attr_mask & IB_SRQ_LIMIT) {\r\nspin_lock_irq(&srq->rq.lock);\r\nif (attr->srq_limit >= srq->rq.size)\r\nret = -EINVAL;\r\nelse\r\nsrq->limit = attr->srq_limit;\r\nspin_unlock_irq(&srq->rq.lock);\r\n}\r\ngoto bail;\r\nbail_unlock:\r\nspin_unlock_irq(&srq->rq.lock);\r\nbail_free:\r\nvfree(wq);\r\nbail:\r\nreturn ret;\r\n}\r\nint qib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr)\r\n{\r\nstruct qib_srq *srq = to_isrq(ibsrq);\r\nattr->max_wr = srq->rq.size - 1;\r\nattr->max_sge = srq->rq.max_sge;\r\nattr->srq_limit = srq->limit;\r\nreturn 0;\r\n}\r\nint qib_destroy_srq(struct ib_srq *ibsrq)\r\n{\r\nstruct qib_srq *srq = to_isrq(ibsrq);\r\nstruct qib_ibdev *dev = to_idev(ibsrq->device);\r\nspin_lock(&dev->n_srqs_lock);\r\ndev->n_srqs_allocated--;\r\nspin_unlock(&dev->n_srqs_lock);\r\nif (srq->ip)\r\nkref_put(&srq->ip->ref, qib_release_mmap_info);\r\nelse\r\nvfree(srq->rq.wq);\r\nkfree(srq);\r\nreturn 0;\r\n}
