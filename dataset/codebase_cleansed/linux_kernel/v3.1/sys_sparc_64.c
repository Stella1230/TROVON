asmlinkage unsigned long sys_getpagesize(void)\r\n{\r\nreturn PAGE_SIZE;\r\n}\r\nstatic inline int invalid_64bit_range(unsigned long addr, unsigned long len)\r\n{\r\nunsigned long va_exclude_start, va_exclude_end;\r\nva_exclude_start = VA_EXCLUDE_START;\r\nva_exclude_end = VA_EXCLUDE_END;\r\nif (unlikely(len >= va_exclude_start))\r\nreturn 1;\r\nif (unlikely((addr + len) < addr))\r\nreturn 1;\r\nif (unlikely((addr >= va_exclude_start && addr < va_exclude_end) ||\r\n((addr + len) >= va_exclude_start &&\r\n(addr + len) < va_exclude_end)))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic inline int straddles_64bit_va_hole(unsigned long start, unsigned long end)\r\n{\r\nunsigned long va_exclude_start, va_exclude_end;\r\nva_exclude_start = VA_EXCLUDE_START;\r\nva_exclude_end = VA_EXCLUDE_END;\r\nif (likely(start < va_exclude_start && end < va_exclude_start))\r\nreturn 0;\r\nif (likely(start >= va_exclude_end && end >= va_exclude_end))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic inline unsigned long COLOUR_ALIGN(unsigned long addr,\r\nunsigned long pgoff)\r\n{\r\nunsigned long base = (addr+SHMLBA-1)&~(SHMLBA-1);\r\nunsigned long off = (pgoff<<PAGE_SHIFT) & (SHMLBA-1);\r\nreturn base + off;\r\n}\r\nstatic inline unsigned long COLOUR_ALIGN_DOWN(unsigned long addr,\r\nunsigned long pgoff)\r\n{\r\nunsigned long base = addr & ~(SHMLBA-1);\r\nunsigned long off = (pgoff<<PAGE_SHIFT) & (SHMLBA-1);\r\nif (base + off <= addr)\r\nreturn base + off;\r\nreturn base - off;\r\n}\r\nunsigned long arch_get_unmapped_area(struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nstruct vm_area_struct * vma;\r\nunsigned long task_size = TASK_SIZE;\r\nunsigned long start_addr;\r\nint do_color_align;\r\nif (flags & MAP_FIXED) {\r\nif ((flags & MAP_SHARED) &&\r\n((addr - (pgoff << PAGE_SHIFT)) & (SHMLBA - 1)))\r\nreturn -EINVAL;\r\nreturn addr;\r\n}\r\nif (test_thread_flag(TIF_32BIT))\r\ntask_size = STACK_TOP32;\r\nif (unlikely(len > task_size || len >= VA_EXCLUDE_START))\r\nreturn -ENOMEM;\r\ndo_color_align = 0;\r\nif (filp || (flags & MAP_SHARED))\r\ndo_color_align = 1;\r\nif (addr) {\r\nif (do_color_align)\r\naddr = COLOUR_ALIGN(addr, pgoff);\r\nelse\r\naddr = PAGE_ALIGN(addr);\r\nvma = find_vma(mm, addr);\r\nif (task_size - len >= addr &&\r\n(!vma || addr + len <= vma->vm_start))\r\nreturn addr;\r\n}\r\nif (len > mm->cached_hole_size) {\r\nstart_addr = addr = mm->free_area_cache;\r\n} else {\r\nstart_addr = addr = TASK_UNMAPPED_BASE;\r\nmm->cached_hole_size = 0;\r\n}\r\ntask_size -= len;\r\nfull_search:\r\nif (do_color_align)\r\naddr = COLOUR_ALIGN(addr, pgoff);\r\nelse\r\naddr = PAGE_ALIGN(addr);\r\nfor (vma = find_vma(mm, addr); ; vma = vma->vm_next) {\r\nif (addr < VA_EXCLUDE_START &&\r\n(addr + len) >= VA_EXCLUDE_START) {\r\naddr = VA_EXCLUDE_END;\r\nvma = find_vma(mm, VA_EXCLUDE_END);\r\n}\r\nif (unlikely(task_size < addr)) {\r\nif (start_addr != TASK_UNMAPPED_BASE) {\r\nstart_addr = addr = TASK_UNMAPPED_BASE;\r\nmm->cached_hole_size = 0;\r\ngoto full_search;\r\n}\r\nreturn -ENOMEM;\r\n}\r\nif (likely(!vma || addr + len <= vma->vm_start)) {\r\nmm->free_area_cache = addr + len;\r\nreturn addr;\r\n}\r\nif (addr + mm->cached_hole_size < vma->vm_start)\r\nmm->cached_hole_size = vma->vm_start - addr;\r\naddr = vma->vm_end;\r\nif (do_color_align)\r\naddr = COLOUR_ALIGN(addr, pgoff);\r\n}\r\n}\r\nunsigned long\r\narch_get_unmapped_area_topdown(struct file *filp, const unsigned long addr0,\r\nconst unsigned long len, const unsigned long pgoff,\r\nconst unsigned long flags)\r\n{\r\nstruct vm_area_struct *vma;\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long task_size = STACK_TOP32;\r\nunsigned long addr = addr0;\r\nint do_color_align;\r\nBUG_ON(!test_thread_flag(TIF_32BIT));\r\nif (flags & MAP_FIXED) {\r\nif ((flags & MAP_SHARED) &&\r\n((addr - (pgoff << PAGE_SHIFT)) & (SHMLBA - 1)))\r\nreturn -EINVAL;\r\nreturn addr;\r\n}\r\nif (unlikely(len > task_size))\r\nreturn -ENOMEM;\r\ndo_color_align = 0;\r\nif (filp || (flags & MAP_SHARED))\r\ndo_color_align = 1;\r\nif (addr) {\r\nif (do_color_align)\r\naddr = COLOUR_ALIGN(addr, pgoff);\r\nelse\r\naddr = PAGE_ALIGN(addr);\r\nvma = find_vma(mm, addr);\r\nif (task_size - len >= addr &&\r\n(!vma || addr + len <= vma->vm_start))\r\nreturn addr;\r\n}\r\nif (len <= mm->cached_hole_size) {\r\nmm->cached_hole_size = 0;\r\nmm->free_area_cache = mm->mmap_base;\r\n}\r\naddr = mm->free_area_cache;\r\nif (do_color_align) {\r\nunsigned long base = COLOUR_ALIGN_DOWN(addr-len, pgoff);\r\naddr = base + len;\r\n}\r\nif (likely(addr > len)) {\r\nvma = find_vma(mm, addr-len);\r\nif (!vma || addr <= vma->vm_start) {\r\nreturn (mm->free_area_cache = addr-len);\r\n}\r\n}\r\nif (unlikely(mm->mmap_base < len))\r\ngoto bottomup;\r\naddr = mm->mmap_base-len;\r\nif (do_color_align)\r\naddr = COLOUR_ALIGN_DOWN(addr, pgoff);\r\ndo {\r\nvma = find_vma(mm, addr);\r\nif (likely(!vma || addr+len <= vma->vm_start)) {\r\nreturn (mm->free_area_cache = addr);\r\n}\r\nif (addr + mm->cached_hole_size < vma->vm_start)\r\nmm->cached_hole_size = vma->vm_start - addr;\r\naddr = vma->vm_start-len;\r\nif (do_color_align)\r\naddr = COLOUR_ALIGN_DOWN(addr, pgoff);\r\n} while (likely(len < vma->vm_start));\r\nbottomup:\r\nmm->cached_hole_size = ~0UL;\r\nmm->free_area_cache = TASK_UNMAPPED_BASE;\r\naddr = arch_get_unmapped_area(filp, addr0, len, pgoff, flags);\r\nmm->free_area_cache = mm->mmap_base;\r\nmm->cached_hole_size = ~0UL;\r\nreturn addr;\r\n}\r\nunsigned long get_fb_unmapped_area(struct file *filp, unsigned long orig_addr, unsigned long len, unsigned long pgoff, unsigned long flags)\r\n{\r\nunsigned long align_goal, addr = -ENOMEM;\r\nunsigned long (*get_area)(struct file *, unsigned long,\r\nunsigned long, unsigned long, unsigned long);\r\nget_area = current->mm->get_unmapped_area;\r\nif (flags & MAP_FIXED) {\r\nreturn get_area(NULL, orig_addr, len, pgoff, flags);\r\n}\r\nflags &= ~MAP_SHARED;\r\nalign_goal = PAGE_SIZE;\r\nif (len >= (4UL * 1024 * 1024))\r\nalign_goal = (4UL * 1024 * 1024);\r\nelse if (len >= (512UL * 1024))\r\nalign_goal = (512UL * 1024);\r\nelse if (len >= (64UL * 1024))\r\nalign_goal = (64UL * 1024);\r\ndo {\r\naddr = get_area(NULL, orig_addr, len + (align_goal - PAGE_SIZE), pgoff, flags);\r\nif (!(addr & ~PAGE_MASK)) {\r\naddr = (addr + (align_goal - 1UL)) & ~(align_goal - 1UL);\r\nbreak;\r\n}\r\nif (align_goal == (4UL * 1024 * 1024))\r\nalign_goal = (512UL * 1024);\r\nelse if (align_goal == (512UL * 1024))\r\nalign_goal = (64UL * 1024);\r\nelse\r\nalign_goal = PAGE_SIZE;\r\n} while ((addr & ~PAGE_MASK) && align_goal > PAGE_SIZE);\r\nif (addr & ~PAGE_MASK)\r\naddr = get_area(NULL, orig_addr, len, pgoff, flags);\r\nreturn addr;\r\n}\r\nstatic unsigned long mmap_rnd(void)\r\n{\r\nunsigned long rnd = 0UL;\r\nif (current->flags & PF_RANDOMIZE) {\r\nunsigned long val = get_random_int();\r\nif (test_thread_flag(TIF_32BIT))\r\nrnd = (val % (1UL << (22UL-PAGE_SHIFT)));\r\nelse\r\nrnd = (val % (1UL << (29UL-PAGE_SHIFT)));\r\n}\r\nreturn (rnd << PAGE_SHIFT) * 2;\r\n}\r\nvoid arch_pick_mmap_layout(struct mm_struct *mm)\r\n{\r\nunsigned long random_factor = mmap_rnd();\r\nunsigned long gap;\r\ngap = rlimit(RLIMIT_STACK);\r\nif (!test_thread_flag(TIF_32BIT) ||\r\n(current->personality & ADDR_COMPAT_LAYOUT) ||\r\ngap == RLIM_INFINITY ||\r\nsysctl_legacy_va_layout) {\r\nmm->mmap_base = TASK_UNMAPPED_BASE + random_factor;\r\nmm->get_unmapped_area = arch_get_unmapped_area;\r\nmm->unmap_area = arch_unmap_area;\r\n} else {\r\nunsigned long task_size = STACK_TOP32;\r\nif (gap < 128 * 1024 * 1024)\r\ngap = 128 * 1024 * 1024;\r\nif (gap > (task_size / 6 * 5))\r\ngap = (task_size / 6 * 5);\r\nmm->mmap_base = PAGE_ALIGN(task_size - gap - random_factor);\r\nmm->get_unmapped_area = arch_get_unmapped_area_topdown;\r\nmm->unmap_area = arch_unmap_area_topdown;\r\n}\r\n}\r\nint sparc_mmap_check(unsigned long addr, unsigned long len)\r\n{\r\nif (test_thread_flag(TIF_32BIT)) {\r\nif (len >= STACK_TOP32)\r\nreturn -EINVAL;\r\nif (addr > STACK_TOP32 - len)\r\nreturn -EINVAL;\r\n} else {\r\nif (len >= VA_EXCLUDE_START)\r\nreturn -EINVAL;\r\nif (invalid_64bit_range(addr, len))\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nasmlinkage unsigned long c_sys_nis_syscall(struct pt_regs *regs)\r\n{\r\nstatic int count;\r\nif (count++ > 5)\r\nreturn -ENOSYS;\r\nprintk ("Unimplemented SPARC system call %ld\n",regs->u_regs[1]);\r\n#ifdef DEBUG_UNIMP_SYSCALL\r\nshow_regs (regs);\r\n#endif\r\nreturn -ENOSYS;\r\n}\r\nasmlinkage void sparc_breakpoint(struct pt_regs *regs)\r\n{\r\nsiginfo_t info;\r\nif (test_thread_flag(TIF_32BIT)) {\r\nregs->tpc &= 0xffffffff;\r\nregs->tnpc &= 0xffffffff;\r\n}\r\n#ifdef DEBUG_SPARC_BREAKPOINT\r\nprintk ("TRAP: Entering kernel PC=%lx, nPC=%lx\n", regs->tpc, regs->tnpc);\r\n#endif\r\ninfo.si_signo = SIGTRAP;\r\ninfo.si_errno = 0;\r\ninfo.si_code = TRAP_BRKPT;\r\ninfo.si_addr = (void __user *)regs->tpc;\r\ninfo.si_trapno = 0;\r\nforce_sig_info(SIGTRAP, &info, current);\r\n#ifdef DEBUG_SPARC_BREAKPOINT\r\nprintk ("TRAP: Returning to space: PC=%lx nPC=%lx\n", regs->tpc, regs->tnpc);\r\n#endif\r\n}\r\nasmlinkage long sparc_memory_ordering(unsigned long model,\r\nstruct pt_regs *regs)\r\n{\r\nif (model >= 3)\r\nreturn -EINVAL;\r\nregs->tstate = (regs->tstate & ~TSTATE_MM) | (model << 14);\r\nreturn 0;\r\n}\r\nint kernel_execve(const char *filename,\r\nconst char *const argv[],\r\nconst char *const envp[])\r\n{\r\nlong __res;\r\nregister long __g1 __asm__ ("g1") = __NR_execve;\r\nregister long __o0 __asm__ ("o0") = (long)(filename);\r\nregister long __o1 __asm__ ("o1") = (long)(argv);\r\nregister long __o2 __asm__ ("o2") = (long)(envp);\r\nasm volatile ("t 0x6d\n\t"\r\n"sub %%g0, %%o0, %0\n\t"\r\n"movcc %%xcc, %%o0, %0\n\t"\r\n: "=r" (__res), "=&r" (__o0)\r\n: "1" (__o0), "r" (__o1), "r" (__o2), "r" (__g1)\r\n: "cc");\r\nreturn __res;\r\n}
