static struct ttm_buffer_object *ttm_bo_vm_lookup_rb(struct ttm_bo_device *bdev,\r\nunsigned long page_start,\r\nunsigned long num_pages)\r\n{\r\nstruct rb_node *cur = bdev->addr_space_rb.rb_node;\r\nunsigned long cur_offset;\r\nstruct ttm_buffer_object *bo;\r\nstruct ttm_buffer_object *best_bo = NULL;\r\nwhile (likely(cur != NULL)) {\r\nbo = rb_entry(cur, struct ttm_buffer_object, vm_rb);\r\ncur_offset = bo->vm_node->start;\r\nif (page_start >= cur_offset) {\r\ncur = cur->rb_right;\r\nbest_bo = bo;\r\nif (page_start == cur_offset)\r\nbreak;\r\n} else\r\ncur = cur->rb_left;\r\n}\r\nif (unlikely(best_bo == NULL))\r\nreturn NULL;\r\nif (unlikely((best_bo->vm_node->start + best_bo->num_pages) <\r\n(page_start + num_pages)))\r\nreturn NULL;\r\nreturn best_bo;\r\n}\r\nstatic int ttm_bo_vm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct ttm_buffer_object *bo = (struct ttm_buffer_object *)\r\nvma->vm_private_data;\r\nstruct ttm_bo_device *bdev = bo->bdev;\r\nunsigned long page_offset;\r\nunsigned long page_last;\r\nunsigned long pfn;\r\nstruct ttm_tt *ttm = NULL;\r\nstruct page *page;\r\nint ret;\r\nint i;\r\nunsigned long address = (unsigned long)vmf->virtual_address;\r\nint retval = VM_FAULT_NOPAGE;\r\nstruct ttm_mem_type_manager *man =\r\n&bdev->man[bo->mem.mem_type];\r\nret = ttm_bo_reserve(bo, true, true, false, 0);\r\nif (unlikely(ret != 0)) {\r\nif (ret == -EBUSY)\r\nset_need_resched();\r\nreturn VM_FAULT_NOPAGE;\r\n}\r\nif (bdev->driver->fault_reserve_notify) {\r\nret = bdev->driver->fault_reserve_notify(bo);\r\nswitch (ret) {\r\ncase 0:\r\nbreak;\r\ncase -EBUSY:\r\nset_need_resched();\r\ncase -ERESTARTSYS:\r\nretval = VM_FAULT_NOPAGE;\r\ngoto out_unlock;\r\ndefault:\r\nretval = VM_FAULT_SIGBUS;\r\ngoto out_unlock;\r\n}\r\n}\r\nspin_lock(&bdev->fence_lock);\r\nif (test_bit(TTM_BO_PRIV_FLAG_MOVING, &bo->priv_flags)) {\r\nret = ttm_bo_wait(bo, false, true, false);\r\nspin_unlock(&bdev->fence_lock);\r\nif (unlikely(ret != 0)) {\r\nretval = (ret != -ERESTARTSYS) ?\r\nVM_FAULT_SIGBUS : VM_FAULT_NOPAGE;\r\ngoto out_unlock;\r\n}\r\n} else\r\nspin_unlock(&bdev->fence_lock);\r\nret = ttm_mem_io_lock(man, true);\r\nif (unlikely(ret != 0)) {\r\nretval = VM_FAULT_NOPAGE;\r\ngoto out_unlock;\r\n}\r\nret = ttm_mem_io_reserve_vm(bo);\r\nif (unlikely(ret != 0)) {\r\nretval = VM_FAULT_SIGBUS;\r\ngoto out_io_unlock;\r\n}\r\npage_offset = ((address - vma->vm_start) >> PAGE_SHIFT) +\r\nbo->vm_node->start - vma->vm_pgoff;\r\npage_last = ((vma->vm_end - vma->vm_start) >> PAGE_SHIFT) +\r\nbo->vm_node->start - vma->vm_pgoff;\r\nif (unlikely(page_offset >= bo->num_pages)) {\r\nretval = VM_FAULT_SIGBUS;\r\ngoto out_io_unlock;\r\n}\r\nif (bo->mem.bus.is_iomem) {\r\nvma->vm_page_prot = ttm_io_prot(bo->mem.placement,\r\nvma->vm_page_prot);\r\n} else {\r\nttm = bo->ttm;\r\nvma->vm_page_prot = (bo->mem.placement & TTM_PL_FLAG_CACHED) ?\r\nvm_get_page_prot(vma->vm_flags) :\r\nttm_io_prot(bo->mem.placement, vma->vm_page_prot);\r\n}\r\nfor (i = 0; i < TTM_BO_VM_NUM_PREFAULT; ++i) {\r\nif (bo->mem.bus.is_iomem)\r\npfn = ((bo->mem.bus.base + bo->mem.bus.offset) >> PAGE_SHIFT) + page_offset;\r\nelse {\r\npage = ttm_tt_get_page(ttm, page_offset);\r\nif (unlikely(!page && i == 0)) {\r\nretval = VM_FAULT_OOM;\r\ngoto out_io_unlock;\r\n} else if (unlikely(!page)) {\r\nbreak;\r\n}\r\npfn = page_to_pfn(page);\r\n}\r\nret = vm_insert_mixed(vma, address, pfn);\r\nif (unlikely((ret == -EBUSY) || (ret != 0 && i > 0)))\r\nbreak;\r\nelse if (unlikely(ret != 0)) {\r\nretval =\r\n(ret == -ENOMEM) ? VM_FAULT_OOM : VM_FAULT_SIGBUS;\r\ngoto out_io_unlock;\r\n}\r\naddress += PAGE_SIZE;\r\nif (unlikely(++page_offset >= page_last))\r\nbreak;\r\n}\r\nout_io_unlock:\r\nttm_mem_io_unlock(man);\r\nout_unlock:\r\nttm_bo_unreserve(bo);\r\nreturn retval;\r\n}\r\nstatic void ttm_bo_vm_open(struct vm_area_struct *vma)\r\n{\r\nstruct ttm_buffer_object *bo =\r\n(struct ttm_buffer_object *)vma->vm_private_data;\r\n(void)ttm_bo_reference(bo);\r\n}\r\nstatic void ttm_bo_vm_close(struct vm_area_struct *vma)\r\n{\r\nstruct ttm_buffer_object *bo = (struct ttm_buffer_object *)vma->vm_private_data;\r\nttm_bo_unref(&bo);\r\nvma->vm_private_data = NULL;\r\n}\r\nint ttm_bo_mmap(struct file *filp, struct vm_area_struct *vma,\r\nstruct ttm_bo_device *bdev)\r\n{\r\nstruct ttm_bo_driver *driver;\r\nstruct ttm_buffer_object *bo;\r\nint ret;\r\nread_lock(&bdev->vm_lock);\r\nbo = ttm_bo_vm_lookup_rb(bdev, vma->vm_pgoff,\r\n(vma->vm_end - vma->vm_start) >> PAGE_SHIFT);\r\nif (likely(bo != NULL))\r\nttm_bo_reference(bo);\r\nread_unlock(&bdev->vm_lock);\r\nif (unlikely(bo == NULL)) {\r\nprintk(KERN_ERR TTM_PFX\r\n"Could not find buffer object to map.\n");\r\nreturn -EINVAL;\r\n}\r\ndriver = bo->bdev->driver;\r\nif (unlikely(!driver->verify_access)) {\r\nret = -EPERM;\r\ngoto out_unref;\r\n}\r\nret = driver->verify_access(bo, filp);\r\nif (unlikely(ret != 0))\r\ngoto out_unref;\r\nvma->vm_ops = &ttm_bo_vm_ops;\r\nvma->vm_private_data = bo;\r\nvma->vm_flags |= VM_RESERVED | VM_IO | VM_MIXEDMAP | VM_DONTEXPAND;\r\nreturn 0;\r\nout_unref:\r\nttm_bo_unref(&bo);\r\nreturn ret;\r\n}\r\nint ttm_fbdev_mmap(struct vm_area_struct *vma, struct ttm_buffer_object *bo)\r\n{\r\nif (vma->vm_pgoff != 0)\r\nreturn -EACCES;\r\nvma->vm_ops = &ttm_bo_vm_ops;\r\nvma->vm_private_data = ttm_bo_reference(bo);\r\nvma->vm_flags |= VM_RESERVED | VM_IO | VM_MIXEDMAP | VM_DONTEXPAND;\r\nreturn 0;\r\n}\r\nssize_t ttm_bo_io(struct ttm_bo_device *bdev, struct file *filp,\r\nconst char __user *wbuf, char __user *rbuf, size_t count,\r\nloff_t *f_pos, bool write)\r\n{\r\nstruct ttm_buffer_object *bo;\r\nstruct ttm_bo_driver *driver;\r\nstruct ttm_bo_kmap_obj map;\r\nunsigned long dev_offset = (*f_pos >> PAGE_SHIFT);\r\nunsigned long kmap_offset;\r\nunsigned long kmap_end;\r\nunsigned long kmap_num;\r\nsize_t io_size;\r\nunsigned int page_offset;\r\nchar *virtual;\r\nint ret;\r\nbool no_wait = false;\r\nbool dummy;\r\nread_lock(&bdev->vm_lock);\r\nbo = ttm_bo_vm_lookup_rb(bdev, dev_offset, 1);\r\nif (likely(bo != NULL))\r\nttm_bo_reference(bo);\r\nread_unlock(&bdev->vm_lock);\r\nif (unlikely(bo == NULL))\r\nreturn -EFAULT;\r\ndriver = bo->bdev->driver;\r\nif (unlikely(!driver->verify_access)) {\r\nret = -EPERM;\r\ngoto out_unref;\r\n}\r\nret = driver->verify_access(bo, filp);\r\nif (unlikely(ret != 0))\r\ngoto out_unref;\r\nkmap_offset = dev_offset - bo->vm_node->start;\r\nif (unlikely(kmap_offset >= bo->num_pages)) {\r\nret = -EFBIG;\r\ngoto out_unref;\r\n}\r\npage_offset = *f_pos & ~PAGE_MASK;\r\nio_size = bo->num_pages - kmap_offset;\r\nio_size = (io_size << PAGE_SHIFT) - page_offset;\r\nif (count < io_size)\r\nio_size = count;\r\nkmap_end = (*f_pos + count - 1) >> PAGE_SHIFT;\r\nkmap_num = kmap_end - kmap_offset + 1;\r\nret = ttm_bo_reserve(bo, true, no_wait, false, 0);\r\nswitch (ret) {\r\ncase 0:\r\nbreak;\r\ncase -EBUSY:\r\nret = -EAGAIN;\r\ngoto out_unref;\r\ndefault:\r\ngoto out_unref;\r\n}\r\nret = ttm_bo_kmap(bo, kmap_offset, kmap_num, &map);\r\nif (unlikely(ret != 0)) {\r\nttm_bo_unreserve(bo);\r\ngoto out_unref;\r\n}\r\nvirtual = ttm_kmap_obj_virtual(&map, &dummy);\r\nvirtual += page_offset;\r\nif (write)\r\nret = copy_from_user(virtual, wbuf, io_size);\r\nelse\r\nret = copy_to_user(rbuf, virtual, io_size);\r\nttm_bo_kunmap(&map);\r\nttm_bo_unreserve(bo);\r\nttm_bo_unref(&bo);\r\nif (unlikely(ret != 0))\r\nreturn -EFBIG;\r\n*f_pos += io_size;\r\nreturn io_size;\r\nout_unref:\r\nttm_bo_unref(&bo);\r\nreturn ret;\r\n}\r\nssize_t ttm_bo_fbdev_io(struct ttm_buffer_object *bo, const char __user *wbuf,\r\nchar __user *rbuf, size_t count, loff_t *f_pos,\r\nbool write)\r\n{\r\nstruct ttm_bo_kmap_obj map;\r\nunsigned long kmap_offset;\r\nunsigned long kmap_end;\r\nunsigned long kmap_num;\r\nsize_t io_size;\r\nunsigned int page_offset;\r\nchar *virtual;\r\nint ret;\r\nbool no_wait = false;\r\nbool dummy;\r\nkmap_offset = (*f_pos >> PAGE_SHIFT);\r\nif (unlikely(kmap_offset >= bo->num_pages))\r\nreturn -EFBIG;\r\npage_offset = *f_pos & ~PAGE_MASK;\r\nio_size = bo->num_pages - kmap_offset;\r\nio_size = (io_size << PAGE_SHIFT) - page_offset;\r\nif (count < io_size)\r\nio_size = count;\r\nkmap_end = (*f_pos + count - 1) >> PAGE_SHIFT;\r\nkmap_num = kmap_end - kmap_offset + 1;\r\nret = ttm_bo_reserve(bo, true, no_wait, false, 0);\r\nswitch (ret) {\r\ncase 0:\r\nbreak;\r\ncase -EBUSY:\r\nreturn -EAGAIN;\r\ndefault:\r\nreturn ret;\r\n}\r\nret = ttm_bo_kmap(bo, kmap_offset, kmap_num, &map);\r\nif (unlikely(ret != 0)) {\r\nttm_bo_unreserve(bo);\r\nreturn ret;\r\n}\r\nvirtual = ttm_kmap_obj_virtual(&map, &dummy);\r\nvirtual += page_offset;\r\nif (write)\r\nret = copy_from_user(virtual, wbuf, io_size);\r\nelse\r\nret = copy_to_user(rbuf, virtual, io_size);\r\nttm_bo_kunmap(&map);\r\nttm_bo_unreserve(bo);\r\nttm_bo_unref(&bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n*f_pos += io_size;\r\nreturn io_size;\r\n}
