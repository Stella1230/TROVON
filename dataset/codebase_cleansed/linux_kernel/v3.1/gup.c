static inline void get_huge_page_tail(struct page *page)\r\n{\r\nVM_BUG_ON(atomic_read(&page->_count) < 0);\r\natomic_inc(&page->_count);\r\n}\r\nstatic noinline int gup_pte_range(pmd_t pmd, unsigned long addr,\r\nunsigned long end, int write, struct page **pages, int *nr)\r\n{\r\nunsigned long mask, result;\r\npte_t *ptep;\r\nresult = _PAGE_PRESENT|_PAGE_USER;\r\nif (write)\r\nresult |= _PAGE_RW;\r\nmask = result | _PAGE_SPECIAL;\r\nptep = pte_offset_kernel(&pmd, addr);\r\ndo {\r\npte_t pte = *ptep;\r\nstruct page *page;\r\nif ((pte_val(pte) & mask) != result)\r\nreturn 0;\r\nVM_BUG_ON(!pfn_valid(pte_pfn(pte)));\r\npage = pte_page(pte);\r\nif (!page_cache_get_speculative(page))\r\nreturn 0;\r\nif (unlikely(pte_val(pte) != pte_val(*ptep))) {\r\nput_page(page);\r\nreturn 0;\r\n}\r\nif (PageTail(page))\r\nget_huge_page_tail(page);\r\npages[*nr] = page;\r\n(*nr)++;\r\n} while (ptep++, addr += PAGE_SIZE, addr != end);\r\nreturn 1;\r\n}\r\nstatic int gup_pmd_range(pud_t pud, unsigned long addr, unsigned long end,\r\nint write, struct page **pages, int *nr)\r\n{\r\nunsigned long next;\r\npmd_t *pmdp;\r\npmdp = pmd_offset(&pud, addr);\r\ndo {\r\npmd_t pmd = *pmdp;\r\nnext = pmd_addr_end(addr, end);\r\nif (pmd_none(pmd))\r\nreturn 0;\r\nif (is_hugepd(pmdp)) {\r\nif (!gup_hugepd((hugepd_t *)pmdp, PMD_SHIFT,\r\naddr, next, write, pages, nr))\r\nreturn 0;\r\n} else if (!gup_pte_range(pmd, addr, next, write, pages, nr))\r\nreturn 0;\r\n} while (pmdp++, addr = next, addr != end);\r\nreturn 1;\r\n}\r\nstatic int gup_pud_range(pgd_t pgd, unsigned long addr, unsigned long end,\r\nint write, struct page **pages, int *nr)\r\n{\r\nunsigned long next;\r\npud_t *pudp;\r\npudp = pud_offset(&pgd, addr);\r\ndo {\r\npud_t pud = *pudp;\r\nnext = pud_addr_end(addr, end);\r\nif (pud_none(pud))\r\nreturn 0;\r\nif (is_hugepd(pudp)) {\r\nif (!gup_hugepd((hugepd_t *)pudp, PUD_SHIFT,\r\naddr, next, write, pages, nr))\r\nreturn 0;\r\n} else if (!gup_pmd_range(pud, addr, next, write, pages, nr))\r\nreturn 0;\r\n} while (pudp++, addr = next, addr != end);\r\nreturn 1;\r\n}\r\nint get_user_pages_fast(unsigned long start, int nr_pages, int write,\r\nstruct page **pages)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long addr, len, end;\r\nunsigned long next;\r\npgd_t *pgdp;\r\nint nr = 0;\r\npr_devel("%s(%lx,%x,%s)\n", __func__, start, nr_pages, write ? "write" : "read");\r\nstart &= PAGE_MASK;\r\naddr = start;\r\nlen = (unsigned long) nr_pages << PAGE_SHIFT;\r\nend = start + len;\r\nif (unlikely(!access_ok(write ? VERIFY_WRITE : VERIFY_READ,\r\nstart, len)))\r\ngoto slow_irqon;\r\npr_devel(" aligned: %lx .. %lx\n", start, end);\r\nlocal_irq_disable();\r\npgdp = pgd_offset(mm, addr);\r\ndo {\r\npgd_t pgd = *pgdp;\r\npr_devel(" %016lx: normal pgd %p\n", addr,\r\n(void *)pgd_val(pgd));\r\nnext = pgd_addr_end(addr, end);\r\nif (pgd_none(pgd))\r\ngoto slow;\r\nif (is_hugepd(pgdp)) {\r\nif (!gup_hugepd((hugepd_t *)pgdp, PGDIR_SHIFT,\r\naddr, next, write, pages, &nr))\r\ngoto slow;\r\n} else if (!gup_pud_range(pgd, addr, next, write, pages, &nr))\r\ngoto slow;\r\n} while (pgdp++, addr = next, addr != end);\r\nlocal_irq_enable();\r\nVM_BUG_ON(nr != (end - start) >> PAGE_SHIFT);\r\nreturn nr;\r\n{\r\nint ret;\r\nslow:\r\nlocal_irq_enable();\r\nslow_irqon:\r\npr_devel(" slow path ! nr = %d\n", nr);\r\nstart += nr << PAGE_SHIFT;\r\npages += nr;\r\ndown_read(&mm->mmap_sem);\r\nret = get_user_pages(current, mm, start,\r\n(end - start) >> PAGE_SHIFT, write, 0, pages, NULL);\r\nup_read(&mm->mmap_sem);\r\nif (nr > 0) {\r\nif (ret < 0)\r\nret = nr;\r\nelse\r\nret += nr;\r\n}\r\nreturn ret;\r\n}\r\n}
