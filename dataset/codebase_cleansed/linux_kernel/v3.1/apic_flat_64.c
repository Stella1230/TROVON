static int flat_acpi_madt_oem_check(char *oem_id, char *oem_table_id)\r\n{\r\nreturn 1;\r\n}\r\nstatic const struct cpumask *flat_target_cpus(void)\r\n{\r\nreturn cpu_online_mask;\r\n}\r\nstatic void flat_vector_allocation_domain(int cpu, struct cpumask *retmask)\r\n{\r\ncpumask_clear(retmask);\r\ncpumask_bits(retmask)[0] = APIC_ALL_CPUS;\r\n}\r\nstatic void flat_init_apic_ldr(void)\r\n{\r\nunsigned long val;\r\nunsigned long num, id;\r\nnum = smp_processor_id();\r\nid = 1UL << num;\r\napic_write(APIC_DFR, APIC_DFR_FLAT);\r\nval = apic_read(APIC_LDR) & ~APIC_LDR_MASK;\r\nval |= SET_APIC_LOGICAL_ID(id);\r\napic_write(APIC_LDR, val);\r\n}\r\nstatic inline void _flat_send_IPI_mask(unsigned long mask, int vector)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\n__default_send_IPI_dest_field(mask, vector, apic->dest_logical);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic void flat_send_IPI_mask(const struct cpumask *cpumask, int vector)\r\n{\r\nunsigned long mask = cpumask_bits(cpumask)[0];\r\n_flat_send_IPI_mask(mask, vector);\r\n}\r\nstatic void\r\nflat_send_IPI_mask_allbutself(const struct cpumask *cpumask, int vector)\r\n{\r\nunsigned long mask = cpumask_bits(cpumask)[0];\r\nint cpu = smp_processor_id();\r\nif (cpu < BITS_PER_LONG)\r\nclear_bit(cpu, &mask);\r\n_flat_send_IPI_mask(mask, vector);\r\n}\r\nstatic void flat_send_IPI_allbutself(int vector)\r\n{\r\nint cpu = smp_processor_id();\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nint hotplug = 1;\r\n#else\r\nint hotplug = 0;\r\n#endif\r\nif (hotplug || vector == NMI_VECTOR) {\r\nif (!cpumask_equal(cpu_online_mask, cpumask_of(cpu))) {\r\nunsigned long mask = cpumask_bits(cpu_online_mask)[0];\r\nif (cpu < BITS_PER_LONG)\r\nclear_bit(cpu, &mask);\r\n_flat_send_IPI_mask(mask, vector);\r\n}\r\n} else if (num_online_cpus() > 1) {\r\n__default_send_IPI_shortcut(APIC_DEST_ALLBUT,\r\nvector, apic->dest_logical);\r\n}\r\n}\r\nstatic void flat_send_IPI_all(int vector)\r\n{\r\nif (vector == NMI_VECTOR) {\r\nflat_send_IPI_mask(cpu_online_mask, vector);\r\n} else {\r\n__default_send_IPI_shortcut(APIC_DEST_ALLINC,\r\nvector, apic->dest_logical);\r\n}\r\n}\r\nstatic unsigned int flat_get_apic_id(unsigned long x)\r\n{\r\nunsigned int id;\r\nid = (((x)>>24) & 0xFFu);\r\nreturn id;\r\n}\r\nstatic unsigned long set_apic_id(unsigned int id)\r\n{\r\nunsigned long x;\r\nx = ((id & 0xFFu)<<24);\r\nreturn x;\r\n}\r\nstatic unsigned int read_xapic_id(void)\r\n{\r\nunsigned int id;\r\nid = flat_get_apic_id(apic_read(APIC_ID));\r\nreturn id;\r\n}\r\nstatic int flat_apic_id_registered(void)\r\n{\r\nreturn physid_isset(read_xapic_id(), phys_cpu_present_map);\r\n}\r\nstatic int flat_phys_pkg_id(int initial_apic_id, int index_msb)\r\n{\r\nreturn initial_apic_id >> index_msb;\r\n}\r\nstatic int physflat_acpi_madt_oem_check(char *oem_id, char *oem_table_id)\r\n{\r\n#ifdef CONFIG_ACPI\r\nif (acpi_gbl_FADT.header.revision >= FADT2_REVISION_ID &&\r\n(acpi_gbl_FADT.flags & ACPI_FADT_APIC_PHYSICAL)) {\r\nprintk(KERN_DEBUG "system APIC only can use physical flat");\r\nreturn 1;\r\n}\r\nif (!strncmp(oem_id, "IBM", 3) && !strncmp(oem_table_id, "EXA", 3)) {\r\nprintk(KERN_DEBUG "IBM Summit detected, will use apic physical");\r\nreturn 1;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic const struct cpumask *physflat_target_cpus(void)\r\n{\r\nreturn cpu_online_mask;\r\n}\r\nstatic void physflat_vector_allocation_domain(int cpu, struct cpumask *retmask)\r\n{\r\ncpumask_clear(retmask);\r\ncpumask_set_cpu(cpu, retmask);\r\n}\r\nstatic void physflat_send_IPI_mask(const struct cpumask *cpumask, int vector)\r\n{\r\ndefault_send_IPI_mask_sequence_phys(cpumask, vector);\r\n}\r\nstatic void physflat_send_IPI_mask_allbutself(const struct cpumask *cpumask,\r\nint vector)\r\n{\r\ndefault_send_IPI_mask_allbutself_phys(cpumask, vector);\r\n}\r\nstatic void physflat_send_IPI_allbutself(int vector)\r\n{\r\ndefault_send_IPI_mask_allbutself_phys(cpu_online_mask, vector);\r\n}\r\nstatic void physflat_send_IPI_all(int vector)\r\n{\r\nphysflat_send_IPI_mask(cpu_online_mask, vector);\r\n}\r\nstatic unsigned int physflat_cpu_mask_to_apicid(const struct cpumask *cpumask)\r\n{\r\nint cpu;\r\ncpu = cpumask_first(cpumask);\r\nif ((unsigned)cpu < nr_cpu_ids)\r\nreturn per_cpu(x86_cpu_to_apicid, cpu);\r\nelse\r\nreturn BAD_APICID;\r\n}\r\nstatic unsigned int\r\nphysflat_cpu_mask_to_apicid_and(const struct cpumask *cpumask,\r\nconst struct cpumask *andmask)\r\n{\r\nint cpu;\r\nfor_each_cpu_and(cpu, cpumask, andmask) {\r\nif (cpumask_test_cpu(cpu, cpu_online_mask))\r\nbreak;\r\n}\r\nreturn per_cpu(x86_cpu_to_apicid, cpu);\r\n}\r\nstatic int physflat_probe(void)\r\n{\r\nif (apic == &apic_physflat || num_possible_cpus() > 8)\r\nreturn 1;\r\nreturn 0;\r\n}
