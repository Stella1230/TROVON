static int vmw_cmd_invalid(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nreturn capable(CAP_SYS_ADMIN) ? : -EINVAL;\r\n}\r\nstatic int vmw_cmd_ok(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_cid_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_cid_cmd {\r\nSVGA3dCmdHeader header;\r\n__le32 cid;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_cid_cmd, header);\r\nif (likely(sw_context->cid_valid && cmd->cid == sw_context->last_cid))\r\nreturn 0;\r\nret = vmw_context_check(dev_priv, sw_context->tfile, cmd->cid);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or use context %u\n",\r\n(unsigned) cmd->cid);\r\nreturn ret;\r\n}\r\nsw_context->last_cid = cmd->cid;\r\nsw_context->cid_valid = true;\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_sid_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nuint32_t *sid)\r\n{\r\nif (*sid == SVGA3D_INVALID_ID)\r\nreturn 0;\r\nif (unlikely((!sw_context->sid_valid ||\r\n*sid != sw_context->last_sid))) {\r\nint real_id;\r\nint ret = vmw_surface_check(dev_priv, sw_context->tfile,\r\n*sid, &real_id);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could ot find or use surface 0x%08x "\r\n"address 0x%08lx\n",\r\n(unsigned int) *sid,\r\n(unsigned long) sid);\r\nreturn ret;\r\n}\r\nsw_context->last_sid = *sid;\r\nsw_context->sid_valid = true;\r\n*sid = real_id;\r\nsw_context->sid_translation = real_id;\r\n} else\r\n*sid = sw_context->sid_translation;\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_set_render_target_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetRenderTarget body;\r\n} *cmd;\r\nint ret;\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.target.sid);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_surface_copy_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceCopy body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.src.sid);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.dest.sid);\r\n}\r\nstatic int vmw_cmd_stretch_blt_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceStretchBlt body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.src.sid);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.dest.sid);\r\n}\r\nstatic int vmw_cmd_blt_surf_screen_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBlitSurfaceToScreen body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.srcImage.sid);\r\n}\r\nstatic int vmw_cmd_present_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdPresent body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.sid);\r\n}\r\nstatic int vmw_translate_guest_ptr(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGAGuestPtr *ptr,\r\nstruct vmw_dma_buffer **vmw_bo_p)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo = NULL;\r\nstruct ttm_buffer_object *bo;\r\nuint32_t handle = ptr->gmrId;\r\nstruct vmw_relocation *reloc;\r\nuint32_t cur_validate_node;\r\nstruct ttm_validate_buffer *val_buf;\r\nint ret;\r\nret = vmw_user_dmabuf_lookup(sw_context->tfile, handle, &vmw_bo);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or use GMR region.\n");\r\nreturn -EINVAL;\r\n}\r\nbo = &vmw_bo->base;\r\nif (unlikely(sw_context->cur_reloc >= VMWGFX_MAX_RELOCATIONS)) {\r\nDRM_ERROR("Max number relocations per submission"\r\n" exceeded\n");\r\nret = -EINVAL;\r\ngoto out_no_reloc;\r\n}\r\nreloc = &sw_context->relocs[sw_context->cur_reloc++];\r\nreloc->location = ptr;\r\ncur_validate_node = vmw_dmabuf_validate_node(bo, sw_context->cur_val_buf);\r\nif (unlikely(cur_validate_node >= VMWGFX_MAX_GMRS)) {\r\nDRM_ERROR("Max number of DMA buffers per submission"\r\n" exceeded.\n");\r\nret = -EINVAL;\r\ngoto out_no_reloc;\r\n}\r\nreloc->index = cur_validate_node;\r\nif (unlikely(cur_validate_node == sw_context->cur_val_buf)) {\r\nval_buf = &sw_context->val_bufs[cur_validate_node];\r\nval_buf->bo = ttm_bo_reference(bo);\r\nval_buf->new_sync_obj_arg = (void *) dev_priv;\r\nlist_add_tail(&val_buf->head, &sw_context->validate_nodes);\r\n++sw_context->cur_val_buf;\r\n}\r\n*vmw_bo_p = vmw_bo;\r\nreturn 0;\r\nout_no_reloc:\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nvmw_bo_p = NULL;\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_end_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdEndQuery q;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->q.guestResult,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_wait_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdWaitForQuery q;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->q.guestResult,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dma(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo = NULL;\r\nstruct ttm_buffer_object *bo;\r\nstruct vmw_surface *srf = NULL;\r\nstruct vmw_dma_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceDMA dma;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_dma_cmd, header);\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->dma.guest.ptr,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbo = &vmw_bo->base;\r\nret = vmw_user_surface_lookup_handle(dev_priv, sw_context->tfile,\r\ncmd->dma.host.sid, &srf);\r\nif (ret) {\r\nDRM_ERROR("could not find surface\n");\r\ngoto out_no_reloc;\r\n}\r\ncmd->dma.host.sid = srf->res.id;\r\nvmw_kms_cursor_snoop(srf, sw_context->tfile, bo, header);\r\nvmw_surface_unreference(&srf);\r\nout_no_reloc:\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_draw(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_draw_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDrawPrimitives body;\r\n} *cmd;\r\nSVGA3dVertexDecl *decl = (SVGA3dVertexDecl *)(\r\n(unsigned long)header + sizeof(*cmd));\r\nSVGA3dPrimitiveRange *range;\r\nuint32_t i;\r\nuint32_t maxnum;\r\nint ret;\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\ncmd = container_of(header, struct vmw_draw_cmd, header);\r\nmaxnum = (header->size - sizeof(cmd->body)) / sizeof(*decl);\r\nif (unlikely(cmd->body.numVertexDecls > maxnum)) {\r\nDRM_ERROR("Illegal number of vertex declarations.\n");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < cmd->body.numVertexDecls; ++i, ++decl) {\r\nret = vmw_cmd_sid_check(dev_priv, sw_context,\r\n&decl->array.surfaceId);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nmaxnum = (header->size - sizeof(cmd->body) -\r\ncmd->body.numVertexDecls * sizeof(*decl)) / sizeof(*range);\r\nif (unlikely(cmd->body.numRanges > maxnum)) {\r\nDRM_ERROR("Illegal number of index ranges.\n");\r\nreturn -EINVAL;\r\n}\r\nrange = (SVGA3dPrimitiveRange *) decl;\r\nfor (i = 0; i < cmd->body.numRanges; ++i, ++range) {\r\nret = vmw_cmd_sid_check(dev_priv, sw_context,\r\n&range->indexArray.surfaceId);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_tex_state(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_tex_state_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetTextureState state;\r\n};\r\nSVGA3dTextureState *last_state = (SVGA3dTextureState *)\r\n((unsigned long) header + header->size + sizeof(header));\r\nSVGA3dTextureState *cur_state = (SVGA3dTextureState *)\r\n((unsigned long) header + sizeof(struct vmw_tex_state_cmd));\r\nint ret;\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nfor (; cur_state < last_state; ++cur_state) {\r\nif (likely(cur_state->name != SVGA3D_TS_BIND_TEXTURE))\r\ncontinue;\r\nret = vmw_cmd_sid_check(dev_priv, sw_context,\r\n&cur_state->value);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf, uint32_t *size)\r\n{\r\nuint32_t cmd_id;\r\nuint32_t size_remaining = *size;\r\nSVGA3dCmdHeader *header = (SVGA3dCmdHeader *) buf;\r\nint ret;\r\ncmd_id = ((uint32_t *)buf)[0];\r\nif (cmd_id == SVGA_CMD_UPDATE) {\r\n*size = 5 << 2;\r\nreturn 0;\r\n}\r\ncmd_id = le32_to_cpu(header->id);\r\n*size = le32_to_cpu(header->size) + sizeof(SVGA3dCmdHeader);\r\ncmd_id -= SVGA_3D_CMD_BASE;\r\nif (unlikely(*size > size_remaining))\r\ngoto out_err;\r\nif (unlikely(cmd_id >= SVGA_3D_CMD_MAX - SVGA_3D_CMD_BASE))\r\ngoto out_err;\r\nret = vmw_cmd_funcs[cmd_id](dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nreturn 0;\r\nout_err:\r\nDRM_ERROR("Illegal / Invalid SVGA3D command: %d\n",\r\ncmd_id + SVGA_3D_CMD_BASE);\r\nreturn -EINVAL;\r\n}\r\nstatic int vmw_cmd_check_all(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf, uint32_t size)\r\n{\r\nint32_t cur_size = size;\r\nint ret;\r\nwhile (cur_size > 0) {\r\nsize = cur_size;\r\nret = vmw_cmd_check(dev_priv, sw_context, buf, &size);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbuf = (void *)((unsigned long) buf + size);\r\ncur_size -= size;\r\n}\r\nif (unlikely(cur_size != 0)) {\r\nDRM_ERROR("Command verifier out of sync.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmw_free_relocations(struct vmw_sw_context *sw_context)\r\n{\r\nsw_context->cur_reloc = 0;\r\n}\r\nstatic void vmw_apply_relocations(struct vmw_sw_context *sw_context)\r\n{\r\nuint32_t i;\r\nstruct vmw_relocation *reloc;\r\nstruct ttm_validate_buffer *validate;\r\nstruct ttm_buffer_object *bo;\r\nfor (i = 0; i < sw_context->cur_reloc; ++i) {\r\nreloc = &sw_context->relocs[i];\r\nvalidate = &sw_context->val_bufs[reloc->index];\r\nbo = validate->bo;\r\nif (bo->mem.mem_type == TTM_PL_VRAM) {\r\nreloc->location->offset += bo->offset;\r\nreloc->location->gmrId = SVGA_GMR_FRAMEBUFFER;\r\n} else\r\nreloc->location->gmrId = bo->mem.start;\r\n}\r\nvmw_free_relocations(sw_context);\r\n}\r\nstatic void vmw_clear_validations(struct vmw_sw_context *sw_context)\r\n{\r\nstruct ttm_validate_buffer *entry, *next;\r\nlist_for_each_entry_safe(entry, next, &sw_context->validate_nodes,\r\nhead) {\r\nlist_del(&entry->head);\r\nvmw_dmabuf_validate_clear(entry->bo);\r\nttm_bo_unref(&entry->bo);\r\nsw_context->cur_val_buf--;\r\n}\r\nBUG_ON(sw_context->cur_val_buf != 0);\r\n}\r\nstatic int vmw_validate_single_buffer(struct vmw_private *dev_priv,\r\nstruct ttm_buffer_object *bo)\r\n{\r\nint ret;\r\nret = ttm_bo_validate(bo, &vmw_vram_gmr_placement, true, false, false);\r\nif (likely(ret == 0 || ret == -ERESTARTSYS))\r\nreturn ret;\r\nDRM_INFO("Falling through to VRAM.\n");\r\nret = ttm_bo_validate(bo, &vmw_vram_placement, true, false, false);\r\nreturn ret;\r\n}\r\nstatic int vmw_validate_buffers(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nint ret;\r\nlist_for_each_entry(entry, &sw_context->validate_nodes, head) {\r\nret = vmw_validate_single_buffer(dev_priv, entry->bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint vmw_execbuf_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nstruct drm_vmw_execbuf_arg *arg = (struct drm_vmw_execbuf_arg *)data;\r\nstruct drm_vmw_fence_rep fence_rep;\r\nstruct drm_vmw_fence_rep __user *user_fence_rep;\r\nint ret;\r\nvoid *user_cmd;\r\nvoid *cmd;\r\nuint32_t sequence;\r\nstruct vmw_sw_context *sw_context = &dev_priv->ctx;\r\nstruct vmw_master *vmaster = vmw_master(file_priv->master);\r\nret = ttm_read_lock(&vmaster->lock, true);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = mutex_lock_interruptible(&dev_priv->cmdbuf_mutex);\r\nif (unlikely(ret != 0)) {\r\nret = -ERESTARTSYS;\r\ngoto out_no_cmd_mutex;\r\n}\r\ncmd = vmw_fifo_reserve(dev_priv, arg->command_size);\r\nif (unlikely(cmd == NULL)) {\r\nDRM_ERROR("Failed reserving fifo space for commands.\n");\r\nret = -ENOMEM;\r\ngoto out_unlock;\r\n}\r\nuser_cmd = (void __user *)(unsigned long)arg->commands;\r\nret = copy_from_user(cmd, user_cmd, arg->command_size);\r\nif (unlikely(ret != 0)) {\r\nret = -EFAULT;\r\nDRM_ERROR("Failed copying commands.\n");\r\ngoto out_commit;\r\n}\r\nsw_context->tfile = vmw_fpriv(file_priv)->tfile;\r\nsw_context->cid_valid = false;\r\nsw_context->sid_valid = false;\r\nsw_context->cur_reloc = 0;\r\nsw_context->cur_val_buf = 0;\r\nINIT_LIST_HEAD(&sw_context->validate_nodes);\r\nret = vmw_cmd_check_all(dev_priv, sw_context, cmd, arg->command_size);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nret = ttm_eu_reserve_buffers(&sw_context->validate_nodes);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nret = vmw_validate_buffers(dev_priv, sw_context);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nvmw_apply_relocations(sw_context);\r\nif (arg->throttle_us) {\r\nret = vmw_wait_lag(dev_priv, &dev_priv->fifo.fence_queue,\r\narg->throttle_us);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\n}\r\nvmw_fifo_commit(dev_priv, arg->command_size);\r\nret = vmw_fifo_send_fence(dev_priv, &sequence);\r\nttm_eu_fence_buffer_objects(&sw_context->validate_nodes,\r\n(void *)(unsigned long) sequence);\r\nvmw_clear_validations(sw_context);\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\nif (ret != 0)\r\nDRM_ERROR("Fence submission error. Syncing.\n");\r\nfence_rep.error = ret;\r\nfence_rep.fence_seq = (uint64_t) sequence;\r\nfence_rep.pad64 = 0;\r\nuser_fence_rep = (struct drm_vmw_fence_rep __user *)\r\n(unsigned long)arg->fence_rep;\r\nret = copy_to_user(user_fence_rep, &fence_rep, sizeof(fence_rep));\r\nvmw_kms_cursor_post_execbuf(dev_priv);\r\nttm_read_unlock(&vmaster->lock);\r\nreturn 0;\r\nout_err:\r\nvmw_free_relocations(sw_context);\r\nttm_eu_backoff_reservation(&sw_context->validate_nodes);\r\nvmw_clear_validations(sw_context);\r\nout_commit:\r\nvmw_fifo_commit(dev_priv, 0);\r\nout_unlock:\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\nout_no_cmd_mutex:\r\nttm_read_unlock(&vmaster->lock);\r\nreturn ret;\r\n}
