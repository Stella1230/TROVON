static inline struct throtl_grp *pd_to_tg(struct blkg_policy_data *pd)\r\n{\r\nreturn pd ? container_of(pd, struct throtl_grp, pd) : NULL;\r\n}\r\nstatic inline struct throtl_grp *blkg_to_tg(struct blkcg_gq *blkg)\r\n{\r\nreturn pd_to_tg(blkg_to_pd(blkg, &blkcg_policy_throtl));\r\n}\r\nstatic inline struct blkcg_gq *tg_to_blkg(struct throtl_grp *tg)\r\n{\r\nreturn pd_to_blkg(&tg->pd);\r\n}\r\nstatic struct throtl_grp *sq_to_tg(struct throtl_service_queue *sq)\r\n{\r\nif (sq && sq->parent_sq)\r\nreturn container_of(sq, struct throtl_grp, service_queue);\r\nelse\r\nreturn NULL;\r\n}\r\nstatic struct throtl_data *sq_to_td(struct throtl_service_queue *sq)\r\n{\r\nstruct throtl_grp *tg = sq_to_tg(sq);\r\nif (tg)\r\nreturn tg->td;\r\nelse\r\nreturn container_of(sq, struct throtl_data, service_queue);\r\n}\r\nstatic void throtl_qnode_init(struct throtl_qnode *qn, struct throtl_grp *tg)\r\n{\r\nINIT_LIST_HEAD(&qn->node);\r\nbio_list_init(&qn->bios);\r\nqn->tg = tg;\r\n}\r\nstatic void throtl_qnode_add_bio(struct bio *bio, struct throtl_qnode *qn,\r\nstruct list_head *queued)\r\n{\r\nbio_list_add(&qn->bios, bio);\r\nif (list_empty(&qn->node)) {\r\nlist_add_tail(&qn->node, queued);\r\nblkg_get(tg_to_blkg(qn->tg));\r\n}\r\n}\r\nstatic struct bio *throtl_peek_queued(struct list_head *queued)\r\n{\r\nstruct throtl_qnode *qn = list_first_entry(queued, struct throtl_qnode, node);\r\nstruct bio *bio;\r\nif (list_empty(queued))\r\nreturn NULL;\r\nbio = bio_list_peek(&qn->bios);\r\nWARN_ON_ONCE(!bio);\r\nreturn bio;\r\n}\r\nstatic struct bio *throtl_pop_queued(struct list_head *queued,\r\nstruct throtl_grp **tg_to_put)\r\n{\r\nstruct throtl_qnode *qn = list_first_entry(queued, struct throtl_qnode, node);\r\nstruct bio *bio;\r\nif (list_empty(queued))\r\nreturn NULL;\r\nbio = bio_list_pop(&qn->bios);\r\nWARN_ON_ONCE(!bio);\r\nif (bio_list_empty(&qn->bios)) {\r\nlist_del_init(&qn->node);\r\nif (tg_to_put)\r\n*tg_to_put = qn->tg;\r\nelse\r\nblkg_put(tg_to_blkg(qn->tg));\r\n} else {\r\nlist_move_tail(&qn->node, queued);\r\n}\r\nreturn bio;\r\n}\r\nstatic void throtl_service_queue_init(struct throtl_service_queue *sq)\r\n{\r\nINIT_LIST_HEAD(&sq->queued[0]);\r\nINIT_LIST_HEAD(&sq->queued[1]);\r\nsq->pending_tree = RB_ROOT;\r\nsetup_timer(&sq->pending_timer, throtl_pending_timer_fn,\r\n(unsigned long)sq);\r\n}\r\nstatic struct blkg_policy_data *throtl_pd_alloc(gfp_t gfp, int node)\r\n{\r\nstruct throtl_grp *tg;\r\nint rw;\r\ntg = kzalloc_node(sizeof(*tg), gfp, node);\r\nif (!tg)\r\nreturn NULL;\r\nthrotl_service_queue_init(&tg->service_queue);\r\nfor (rw = READ; rw <= WRITE; rw++) {\r\nthrotl_qnode_init(&tg->qnode_on_self[rw], tg);\r\nthrotl_qnode_init(&tg->qnode_on_parent[rw], tg);\r\n}\r\nRB_CLEAR_NODE(&tg->rb_node);\r\ntg->bps[READ] = -1;\r\ntg->bps[WRITE] = -1;\r\ntg->iops[READ] = -1;\r\ntg->iops[WRITE] = -1;\r\nreturn &tg->pd;\r\n}\r\nstatic void throtl_pd_init(struct blkg_policy_data *pd)\r\n{\r\nstruct throtl_grp *tg = pd_to_tg(pd);\r\nstruct blkcg_gq *blkg = tg_to_blkg(tg);\r\nstruct throtl_data *td = blkg->q->td;\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nsq->parent_sq = &td->service_queue;\r\nif (cgroup_subsys_on_dfl(io_cgrp_subsys) && blkg->parent)\r\nsq->parent_sq = &blkg_to_tg(blkg->parent)->service_queue;\r\ntg->td = td;\r\n}\r\nstatic void tg_update_has_rules(struct throtl_grp *tg)\r\n{\r\nstruct throtl_grp *parent_tg = sq_to_tg(tg->service_queue.parent_sq);\r\nint rw;\r\nfor (rw = READ; rw <= WRITE; rw++)\r\ntg->has_rules[rw] = (parent_tg && parent_tg->has_rules[rw]) ||\r\n(tg->bps[rw] != -1 || tg->iops[rw] != -1);\r\n}\r\nstatic void throtl_pd_online(struct blkg_policy_data *pd)\r\n{\r\ntg_update_has_rules(pd_to_tg(pd));\r\n}\r\nstatic void throtl_pd_free(struct blkg_policy_data *pd)\r\n{\r\nstruct throtl_grp *tg = pd_to_tg(pd);\r\ndel_timer_sync(&tg->service_queue.pending_timer);\r\nkfree(tg);\r\n}\r\nstatic struct throtl_grp *\r\nthrotl_rb_first(struct throtl_service_queue *parent_sq)\r\n{\r\nif (!parent_sq->nr_pending)\r\nreturn NULL;\r\nif (!parent_sq->first_pending)\r\nparent_sq->first_pending = rb_first(&parent_sq->pending_tree);\r\nif (parent_sq->first_pending)\r\nreturn rb_entry_tg(parent_sq->first_pending);\r\nreturn NULL;\r\n}\r\nstatic void rb_erase_init(struct rb_node *n, struct rb_root *root)\r\n{\r\nrb_erase(n, root);\r\nRB_CLEAR_NODE(n);\r\n}\r\nstatic void throtl_rb_erase(struct rb_node *n,\r\nstruct throtl_service_queue *parent_sq)\r\n{\r\nif (parent_sq->first_pending == n)\r\nparent_sq->first_pending = NULL;\r\nrb_erase_init(n, &parent_sq->pending_tree);\r\n--parent_sq->nr_pending;\r\n}\r\nstatic void update_min_dispatch_time(struct throtl_service_queue *parent_sq)\r\n{\r\nstruct throtl_grp *tg;\r\ntg = throtl_rb_first(parent_sq);\r\nif (!tg)\r\nreturn;\r\nparent_sq->first_pending_disptime = tg->disptime;\r\n}\r\nstatic void tg_service_queue_add(struct throtl_grp *tg)\r\n{\r\nstruct throtl_service_queue *parent_sq = tg->service_queue.parent_sq;\r\nstruct rb_node **node = &parent_sq->pending_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct throtl_grp *__tg;\r\nunsigned long key = tg->disptime;\r\nint left = 1;\r\nwhile (*node != NULL) {\r\nparent = *node;\r\n__tg = rb_entry_tg(parent);\r\nif (time_before(key, __tg->disptime))\r\nnode = &parent->rb_left;\r\nelse {\r\nnode = &parent->rb_right;\r\nleft = 0;\r\n}\r\n}\r\nif (left)\r\nparent_sq->first_pending = &tg->rb_node;\r\nrb_link_node(&tg->rb_node, parent, node);\r\nrb_insert_color(&tg->rb_node, &parent_sq->pending_tree);\r\n}\r\nstatic void __throtl_enqueue_tg(struct throtl_grp *tg)\r\n{\r\ntg_service_queue_add(tg);\r\ntg->flags |= THROTL_TG_PENDING;\r\ntg->service_queue.parent_sq->nr_pending++;\r\n}\r\nstatic void throtl_enqueue_tg(struct throtl_grp *tg)\r\n{\r\nif (!(tg->flags & THROTL_TG_PENDING))\r\n__throtl_enqueue_tg(tg);\r\n}\r\nstatic void __throtl_dequeue_tg(struct throtl_grp *tg)\r\n{\r\nthrotl_rb_erase(&tg->rb_node, tg->service_queue.parent_sq);\r\ntg->flags &= ~THROTL_TG_PENDING;\r\n}\r\nstatic void throtl_dequeue_tg(struct throtl_grp *tg)\r\n{\r\nif (tg->flags & THROTL_TG_PENDING)\r\n__throtl_dequeue_tg(tg);\r\n}\r\nstatic void throtl_schedule_pending_timer(struct throtl_service_queue *sq,\r\nunsigned long expires)\r\n{\r\nmod_timer(&sq->pending_timer, expires);\r\nthrotl_log(sq, "schedule timer. delay=%lu jiffies=%lu",\r\nexpires - jiffies, jiffies);\r\n}\r\nstatic bool throtl_schedule_next_dispatch(struct throtl_service_queue *sq,\r\nbool force)\r\n{\r\nif (!sq->nr_pending)\r\nreturn true;\r\nupdate_min_dispatch_time(sq);\r\nif (force || time_after(sq->first_pending_disptime, jiffies)) {\r\nthrotl_schedule_pending_timer(sq, sq->first_pending_disptime);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic inline void throtl_start_new_slice_with_credit(struct throtl_grp *tg,\r\nbool rw, unsigned long start)\r\n{\r\ntg->bytes_disp[rw] = 0;\r\ntg->io_disp[rw] = 0;\r\nif (time_after_eq(start, tg->slice_start[rw]))\r\ntg->slice_start[rw] = start;\r\ntg->slice_end[rw] = jiffies + throtl_slice;\r\nthrotl_log(&tg->service_queue,\r\n"[%c] new slice with credit start=%lu end=%lu jiffies=%lu",\r\nrw == READ ? 'R' : 'W', tg->slice_start[rw],\r\ntg->slice_end[rw], jiffies);\r\n}\r\nstatic inline void throtl_start_new_slice(struct throtl_grp *tg, bool rw)\r\n{\r\ntg->bytes_disp[rw] = 0;\r\ntg->io_disp[rw] = 0;\r\ntg->slice_start[rw] = jiffies;\r\ntg->slice_end[rw] = jiffies + throtl_slice;\r\nthrotl_log(&tg->service_queue,\r\n"[%c] new slice start=%lu end=%lu jiffies=%lu",\r\nrw == READ ? 'R' : 'W', tg->slice_start[rw],\r\ntg->slice_end[rw], jiffies);\r\n}\r\nstatic inline void throtl_set_slice_end(struct throtl_grp *tg, bool rw,\r\nunsigned long jiffy_end)\r\n{\r\ntg->slice_end[rw] = roundup(jiffy_end, throtl_slice);\r\n}\r\nstatic inline void throtl_extend_slice(struct throtl_grp *tg, bool rw,\r\nunsigned long jiffy_end)\r\n{\r\ntg->slice_end[rw] = roundup(jiffy_end, throtl_slice);\r\nthrotl_log(&tg->service_queue,\r\n"[%c] extend slice start=%lu end=%lu jiffies=%lu",\r\nrw == READ ? 'R' : 'W', tg->slice_start[rw],\r\ntg->slice_end[rw], jiffies);\r\n}\r\nstatic bool throtl_slice_used(struct throtl_grp *tg, bool rw)\r\n{\r\nif (time_in_range(jiffies, tg->slice_start[rw], tg->slice_end[rw]))\r\nreturn false;\r\nreturn 1;\r\n}\r\nstatic inline void throtl_trim_slice(struct throtl_grp *tg, bool rw)\r\n{\r\nunsigned long nr_slices, time_elapsed, io_trim;\r\nu64 bytes_trim, tmp;\r\nBUG_ON(time_before(tg->slice_end[rw], tg->slice_start[rw]));\r\nif (throtl_slice_used(tg, rw))\r\nreturn;\r\nthrotl_set_slice_end(tg, rw, jiffies + throtl_slice);\r\ntime_elapsed = jiffies - tg->slice_start[rw];\r\nnr_slices = time_elapsed / throtl_slice;\r\nif (!nr_slices)\r\nreturn;\r\ntmp = tg->bps[rw] * throtl_slice * nr_slices;\r\ndo_div(tmp, HZ);\r\nbytes_trim = tmp;\r\nio_trim = (tg->iops[rw] * throtl_slice * nr_slices)/HZ;\r\nif (!bytes_trim && !io_trim)\r\nreturn;\r\nif (tg->bytes_disp[rw] >= bytes_trim)\r\ntg->bytes_disp[rw] -= bytes_trim;\r\nelse\r\ntg->bytes_disp[rw] = 0;\r\nif (tg->io_disp[rw] >= io_trim)\r\ntg->io_disp[rw] -= io_trim;\r\nelse\r\ntg->io_disp[rw] = 0;\r\ntg->slice_start[rw] += nr_slices * throtl_slice;\r\nthrotl_log(&tg->service_queue,\r\n"[%c] trim slice nr=%lu bytes=%llu io=%lu start=%lu end=%lu jiffies=%lu",\r\nrw == READ ? 'R' : 'W', nr_slices, bytes_trim, io_trim,\r\ntg->slice_start[rw], tg->slice_end[rw], jiffies);\r\n}\r\nstatic bool tg_with_in_iops_limit(struct throtl_grp *tg, struct bio *bio,\r\nunsigned long *wait)\r\n{\r\nbool rw = bio_data_dir(bio);\r\nunsigned int io_allowed;\r\nunsigned long jiffy_elapsed, jiffy_wait, jiffy_elapsed_rnd;\r\nu64 tmp;\r\njiffy_elapsed = jiffy_elapsed_rnd = jiffies - tg->slice_start[rw];\r\nif (!jiffy_elapsed)\r\njiffy_elapsed_rnd = throtl_slice;\r\njiffy_elapsed_rnd = roundup(jiffy_elapsed_rnd, throtl_slice);\r\ntmp = (u64)tg->iops[rw] * jiffy_elapsed_rnd;\r\ndo_div(tmp, HZ);\r\nif (tmp > UINT_MAX)\r\nio_allowed = UINT_MAX;\r\nelse\r\nio_allowed = tmp;\r\nif (tg->io_disp[rw] + 1 <= io_allowed) {\r\nif (wait)\r\n*wait = 0;\r\nreturn true;\r\n}\r\njiffy_wait = ((tg->io_disp[rw] + 1) * HZ)/tg->iops[rw] + 1;\r\nif (jiffy_wait > jiffy_elapsed)\r\njiffy_wait = jiffy_wait - jiffy_elapsed;\r\nelse\r\njiffy_wait = 1;\r\nif (wait)\r\n*wait = jiffy_wait;\r\nreturn 0;\r\n}\r\nstatic bool tg_with_in_bps_limit(struct throtl_grp *tg, struct bio *bio,\r\nunsigned long *wait)\r\n{\r\nbool rw = bio_data_dir(bio);\r\nu64 bytes_allowed, extra_bytes, tmp;\r\nunsigned long jiffy_elapsed, jiffy_wait, jiffy_elapsed_rnd;\r\njiffy_elapsed = jiffy_elapsed_rnd = jiffies - tg->slice_start[rw];\r\nif (!jiffy_elapsed)\r\njiffy_elapsed_rnd = throtl_slice;\r\njiffy_elapsed_rnd = roundup(jiffy_elapsed_rnd, throtl_slice);\r\ntmp = tg->bps[rw] * jiffy_elapsed_rnd;\r\ndo_div(tmp, HZ);\r\nbytes_allowed = tmp;\r\nif (tg->bytes_disp[rw] + bio->bi_iter.bi_size <= bytes_allowed) {\r\nif (wait)\r\n*wait = 0;\r\nreturn true;\r\n}\r\nextra_bytes = tg->bytes_disp[rw] + bio->bi_iter.bi_size - bytes_allowed;\r\njiffy_wait = div64_u64(extra_bytes * HZ, tg->bps[rw]);\r\nif (!jiffy_wait)\r\njiffy_wait = 1;\r\njiffy_wait = jiffy_wait + (jiffy_elapsed_rnd - jiffy_elapsed);\r\nif (wait)\r\n*wait = jiffy_wait;\r\nreturn 0;\r\n}\r\nstatic bool tg_may_dispatch(struct throtl_grp *tg, struct bio *bio,\r\nunsigned long *wait)\r\n{\r\nbool rw = bio_data_dir(bio);\r\nunsigned long bps_wait = 0, iops_wait = 0, max_wait = 0;\r\nBUG_ON(tg->service_queue.nr_queued[rw] &&\r\nbio != throtl_peek_queued(&tg->service_queue.queued[rw]));\r\nif (tg->bps[rw] == -1 && tg->iops[rw] == -1) {\r\nif (wait)\r\n*wait = 0;\r\nreturn true;\r\n}\r\nif (throtl_slice_used(tg, rw))\r\nthrotl_start_new_slice(tg, rw);\r\nelse {\r\nif (time_before(tg->slice_end[rw], jiffies + throtl_slice))\r\nthrotl_extend_slice(tg, rw, jiffies + throtl_slice);\r\n}\r\nif (tg_with_in_bps_limit(tg, bio, &bps_wait) &&\r\ntg_with_in_iops_limit(tg, bio, &iops_wait)) {\r\nif (wait)\r\n*wait = 0;\r\nreturn 1;\r\n}\r\nmax_wait = max(bps_wait, iops_wait);\r\nif (wait)\r\n*wait = max_wait;\r\nif (time_before(tg->slice_end[rw], jiffies + max_wait))\r\nthrotl_extend_slice(tg, rw, jiffies + max_wait);\r\nreturn 0;\r\n}\r\nstatic void throtl_charge_bio(struct throtl_grp *tg, struct bio *bio)\r\n{\r\nbool rw = bio_data_dir(bio);\r\ntg->bytes_disp[rw] += bio->bi_iter.bi_size;\r\ntg->io_disp[rw]++;\r\nif (!(bio->bi_rw & REQ_THROTTLED))\r\nbio->bi_rw |= REQ_THROTTLED;\r\n}\r\nstatic void throtl_add_bio_tg(struct bio *bio, struct throtl_qnode *qn,\r\nstruct throtl_grp *tg)\r\n{\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nbool rw = bio_data_dir(bio);\r\nif (!qn)\r\nqn = &tg->qnode_on_self[rw];\r\nif (!sq->nr_queued[rw])\r\ntg->flags |= THROTL_TG_WAS_EMPTY;\r\nthrotl_qnode_add_bio(bio, qn, &sq->queued[rw]);\r\nsq->nr_queued[rw]++;\r\nthrotl_enqueue_tg(tg);\r\n}\r\nstatic void tg_update_disptime(struct throtl_grp *tg)\r\n{\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nunsigned long read_wait = -1, write_wait = -1, min_wait = -1, disptime;\r\nstruct bio *bio;\r\nif ((bio = throtl_peek_queued(&sq->queued[READ])))\r\ntg_may_dispatch(tg, bio, &read_wait);\r\nif ((bio = throtl_peek_queued(&sq->queued[WRITE])))\r\ntg_may_dispatch(tg, bio, &write_wait);\r\nmin_wait = min(read_wait, write_wait);\r\ndisptime = jiffies + min_wait;\r\nthrotl_dequeue_tg(tg);\r\ntg->disptime = disptime;\r\nthrotl_enqueue_tg(tg);\r\ntg->flags &= ~THROTL_TG_WAS_EMPTY;\r\n}\r\nstatic void start_parent_slice_with_credit(struct throtl_grp *child_tg,\r\nstruct throtl_grp *parent_tg, bool rw)\r\n{\r\nif (throtl_slice_used(parent_tg, rw)) {\r\nthrotl_start_new_slice_with_credit(parent_tg, rw,\r\nchild_tg->slice_start[rw]);\r\n}\r\n}\r\nstatic void tg_dispatch_one_bio(struct throtl_grp *tg, bool rw)\r\n{\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nstruct throtl_service_queue *parent_sq = sq->parent_sq;\r\nstruct throtl_grp *parent_tg = sq_to_tg(parent_sq);\r\nstruct throtl_grp *tg_to_put = NULL;\r\nstruct bio *bio;\r\nbio = throtl_pop_queued(&sq->queued[rw], &tg_to_put);\r\nsq->nr_queued[rw]--;\r\nthrotl_charge_bio(tg, bio);\r\nif (parent_tg) {\r\nthrotl_add_bio_tg(bio, &tg->qnode_on_parent[rw], parent_tg);\r\nstart_parent_slice_with_credit(tg, parent_tg, rw);\r\n} else {\r\nthrotl_qnode_add_bio(bio, &tg->qnode_on_parent[rw],\r\n&parent_sq->queued[rw]);\r\nBUG_ON(tg->td->nr_queued[rw] <= 0);\r\ntg->td->nr_queued[rw]--;\r\n}\r\nthrotl_trim_slice(tg, rw);\r\nif (tg_to_put)\r\nblkg_put(tg_to_blkg(tg_to_put));\r\n}\r\nstatic int throtl_dispatch_tg(struct throtl_grp *tg)\r\n{\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nunsigned int nr_reads = 0, nr_writes = 0;\r\nunsigned int max_nr_reads = throtl_grp_quantum*3/4;\r\nunsigned int max_nr_writes = throtl_grp_quantum - max_nr_reads;\r\nstruct bio *bio;\r\nwhile ((bio = throtl_peek_queued(&sq->queued[READ])) &&\r\ntg_may_dispatch(tg, bio, NULL)) {\r\ntg_dispatch_one_bio(tg, bio_data_dir(bio));\r\nnr_reads++;\r\nif (nr_reads >= max_nr_reads)\r\nbreak;\r\n}\r\nwhile ((bio = throtl_peek_queued(&sq->queued[WRITE])) &&\r\ntg_may_dispatch(tg, bio, NULL)) {\r\ntg_dispatch_one_bio(tg, bio_data_dir(bio));\r\nnr_writes++;\r\nif (nr_writes >= max_nr_writes)\r\nbreak;\r\n}\r\nreturn nr_reads + nr_writes;\r\n}\r\nstatic int throtl_select_dispatch(struct throtl_service_queue *parent_sq)\r\n{\r\nunsigned int nr_disp = 0;\r\nwhile (1) {\r\nstruct throtl_grp *tg = throtl_rb_first(parent_sq);\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nif (!tg)\r\nbreak;\r\nif (time_before(jiffies, tg->disptime))\r\nbreak;\r\nthrotl_dequeue_tg(tg);\r\nnr_disp += throtl_dispatch_tg(tg);\r\nif (sq->nr_queued[0] || sq->nr_queued[1])\r\ntg_update_disptime(tg);\r\nif (nr_disp >= throtl_quantum)\r\nbreak;\r\n}\r\nreturn nr_disp;\r\n}\r\nstatic void throtl_pending_timer_fn(unsigned long arg)\r\n{\r\nstruct throtl_service_queue *sq = (void *)arg;\r\nstruct throtl_grp *tg = sq_to_tg(sq);\r\nstruct throtl_data *td = sq_to_td(sq);\r\nstruct request_queue *q = td->queue;\r\nstruct throtl_service_queue *parent_sq;\r\nbool dispatched;\r\nint ret;\r\nspin_lock_irq(q->queue_lock);\r\nagain:\r\nparent_sq = sq->parent_sq;\r\ndispatched = false;\r\nwhile (true) {\r\nthrotl_log(sq, "dispatch nr_queued=%u read=%u write=%u",\r\nsq->nr_queued[READ] + sq->nr_queued[WRITE],\r\nsq->nr_queued[READ], sq->nr_queued[WRITE]);\r\nret = throtl_select_dispatch(sq);\r\nif (ret) {\r\nthrotl_log(sq, "bios disp=%u", ret);\r\ndispatched = true;\r\n}\r\nif (throtl_schedule_next_dispatch(sq, false))\r\nbreak;\r\nspin_unlock_irq(q->queue_lock);\r\ncpu_relax();\r\nspin_lock_irq(q->queue_lock);\r\n}\r\nif (!dispatched)\r\ngoto out_unlock;\r\nif (parent_sq) {\r\nif (tg->flags & THROTL_TG_WAS_EMPTY) {\r\ntg_update_disptime(tg);\r\nif (!throtl_schedule_next_dispatch(parent_sq, false)) {\r\nsq = parent_sq;\r\ntg = sq_to_tg(sq);\r\ngoto again;\r\n}\r\n}\r\n} else {\r\nqueue_work(kthrotld_workqueue, &td->dispatch_work);\r\n}\r\nout_unlock:\r\nspin_unlock_irq(q->queue_lock);\r\n}\r\nstatic void blk_throtl_dispatch_work_fn(struct work_struct *work)\r\n{\r\nstruct throtl_data *td = container_of(work, struct throtl_data,\r\ndispatch_work);\r\nstruct throtl_service_queue *td_sq = &td->service_queue;\r\nstruct request_queue *q = td->queue;\r\nstruct bio_list bio_list_on_stack;\r\nstruct bio *bio;\r\nstruct blk_plug plug;\r\nint rw;\r\nbio_list_init(&bio_list_on_stack);\r\nspin_lock_irq(q->queue_lock);\r\nfor (rw = READ; rw <= WRITE; rw++)\r\nwhile ((bio = throtl_pop_queued(&td_sq->queued[rw], NULL)))\r\nbio_list_add(&bio_list_on_stack, bio);\r\nspin_unlock_irq(q->queue_lock);\r\nif (!bio_list_empty(&bio_list_on_stack)) {\r\nblk_start_plug(&plug);\r\nwhile((bio = bio_list_pop(&bio_list_on_stack)))\r\ngeneric_make_request(bio);\r\nblk_finish_plug(&plug);\r\n}\r\n}\r\nstatic u64 tg_prfill_conf_u64(struct seq_file *sf, struct blkg_policy_data *pd,\r\nint off)\r\n{\r\nstruct throtl_grp *tg = pd_to_tg(pd);\r\nu64 v = *(u64 *)((void *)tg + off);\r\nif (v == -1)\r\nreturn 0;\r\nreturn __blkg_prfill_u64(sf, pd, v);\r\n}\r\nstatic u64 tg_prfill_conf_uint(struct seq_file *sf, struct blkg_policy_data *pd,\r\nint off)\r\n{\r\nstruct throtl_grp *tg = pd_to_tg(pd);\r\nunsigned int v = *(unsigned int *)((void *)tg + off);\r\nif (v == -1)\r\nreturn 0;\r\nreturn __blkg_prfill_u64(sf, pd, v);\r\n}\r\nstatic int tg_print_conf_u64(struct seq_file *sf, void *v)\r\n{\r\nblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)), tg_prfill_conf_u64,\r\n&blkcg_policy_throtl, seq_cft(sf)->private, false);\r\nreturn 0;\r\n}\r\nstatic int tg_print_conf_uint(struct seq_file *sf, void *v)\r\n{\r\nblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)), tg_prfill_conf_uint,\r\n&blkcg_policy_throtl, seq_cft(sf)->private, false);\r\nreturn 0;\r\n}\r\nstatic void tg_conf_updated(struct throtl_grp *tg)\r\n{\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nstruct cgroup_subsys_state *pos_css;\r\nstruct blkcg_gq *blkg;\r\nthrotl_log(&tg->service_queue,\r\n"limit change rbps=%llu wbps=%llu riops=%u wiops=%u",\r\ntg->bps[READ], tg->bps[WRITE],\r\ntg->iops[READ], tg->iops[WRITE]);\r\nblkg_for_each_descendant_pre(blkg, pos_css, tg_to_blkg(tg))\r\ntg_update_has_rules(blkg_to_tg(blkg));\r\nthrotl_start_new_slice(tg, 0);\r\nthrotl_start_new_slice(tg, 1);\r\nif (tg->flags & THROTL_TG_PENDING) {\r\ntg_update_disptime(tg);\r\nthrotl_schedule_next_dispatch(sq->parent_sq, true);\r\n}\r\n}\r\nstatic ssize_t tg_set_conf(struct kernfs_open_file *of,\r\nchar *buf, size_t nbytes, loff_t off, bool is_u64)\r\n{\r\nstruct blkcg *blkcg = css_to_blkcg(of_css(of));\r\nstruct blkg_conf_ctx ctx;\r\nstruct throtl_grp *tg;\r\nint ret;\r\nu64 v;\r\nret = blkg_conf_prep(blkcg, &blkcg_policy_throtl, buf, &ctx);\r\nif (ret)\r\nreturn ret;\r\nret = -EINVAL;\r\nif (sscanf(ctx.body, "%llu", &v) != 1)\r\ngoto out_finish;\r\nif (!v)\r\nv = -1;\r\ntg = blkg_to_tg(ctx.blkg);\r\nif (is_u64)\r\n*(u64 *)((void *)tg + of_cft(of)->private) = v;\r\nelse\r\n*(unsigned int *)((void *)tg + of_cft(of)->private) = v;\r\ntg_conf_updated(tg);\r\nret = 0;\r\nout_finish:\r\nblkg_conf_finish(&ctx);\r\nreturn ret ?: nbytes;\r\n}\r\nstatic ssize_t tg_set_conf_u64(struct kernfs_open_file *of,\r\nchar *buf, size_t nbytes, loff_t off)\r\n{\r\nreturn tg_set_conf(of, buf, nbytes, off, true);\r\n}\r\nstatic ssize_t tg_set_conf_uint(struct kernfs_open_file *of,\r\nchar *buf, size_t nbytes, loff_t off)\r\n{\r\nreturn tg_set_conf(of, buf, nbytes, off, false);\r\n}\r\nstatic u64 tg_prfill_max(struct seq_file *sf, struct blkg_policy_data *pd,\r\nint off)\r\n{\r\nstruct throtl_grp *tg = pd_to_tg(pd);\r\nconst char *dname = blkg_dev_name(pd->blkg);\r\nchar bufs[4][21] = { "max", "max", "max", "max" };\r\nif (!dname)\r\nreturn 0;\r\nif (tg->bps[READ] == -1 && tg->bps[WRITE] == -1 &&\r\ntg->iops[READ] == -1 && tg->iops[WRITE] == -1)\r\nreturn 0;\r\nif (tg->bps[READ] != -1)\r\nsnprintf(bufs[0], sizeof(bufs[0]), "%llu", tg->bps[READ]);\r\nif (tg->bps[WRITE] != -1)\r\nsnprintf(bufs[1], sizeof(bufs[1]), "%llu", tg->bps[WRITE]);\r\nif (tg->iops[READ] != -1)\r\nsnprintf(bufs[2], sizeof(bufs[2]), "%u", tg->iops[READ]);\r\nif (tg->iops[WRITE] != -1)\r\nsnprintf(bufs[3], sizeof(bufs[3]), "%u", tg->iops[WRITE]);\r\nseq_printf(sf, "%s rbps=%s wbps=%s riops=%s wiops=%s\n",\r\ndname, bufs[0], bufs[1], bufs[2], bufs[3]);\r\nreturn 0;\r\n}\r\nstatic int tg_print_max(struct seq_file *sf, void *v)\r\n{\r\nblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)), tg_prfill_max,\r\n&blkcg_policy_throtl, seq_cft(sf)->private, false);\r\nreturn 0;\r\n}\r\nstatic ssize_t tg_set_max(struct kernfs_open_file *of,\r\nchar *buf, size_t nbytes, loff_t off)\r\n{\r\nstruct blkcg *blkcg = css_to_blkcg(of_css(of));\r\nstruct blkg_conf_ctx ctx;\r\nstruct throtl_grp *tg;\r\nu64 v[4];\r\nint ret;\r\nret = blkg_conf_prep(blkcg, &blkcg_policy_throtl, buf, &ctx);\r\nif (ret)\r\nreturn ret;\r\ntg = blkg_to_tg(ctx.blkg);\r\nv[0] = tg->bps[READ];\r\nv[1] = tg->bps[WRITE];\r\nv[2] = tg->iops[READ];\r\nv[3] = tg->iops[WRITE];\r\nwhile (true) {\r\nchar tok[27];\r\nchar *p;\r\nu64 val = -1;\r\nint len;\r\nif (sscanf(ctx.body, "%26s%n", tok, &len) != 1)\r\nbreak;\r\nif (tok[0] == '\0')\r\nbreak;\r\nctx.body += len;\r\nret = -EINVAL;\r\np = tok;\r\nstrsep(&p, "=");\r\nif (!p || (sscanf(p, "%llu", &val) != 1 && strcmp(p, "max")))\r\ngoto out_finish;\r\nret = -ERANGE;\r\nif (!val)\r\ngoto out_finish;\r\nret = -EINVAL;\r\nif (!strcmp(tok, "rbps"))\r\nv[0] = val;\r\nelse if (!strcmp(tok, "wbps"))\r\nv[1] = val;\r\nelse if (!strcmp(tok, "riops"))\r\nv[2] = min_t(u64, val, UINT_MAX);\r\nelse if (!strcmp(tok, "wiops"))\r\nv[3] = min_t(u64, val, UINT_MAX);\r\nelse\r\ngoto out_finish;\r\n}\r\ntg->bps[READ] = v[0];\r\ntg->bps[WRITE] = v[1];\r\ntg->iops[READ] = v[2];\r\ntg->iops[WRITE] = v[3];\r\ntg_conf_updated(tg);\r\nret = 0;\r\nout_finish:\r\nblkg_conf_finish(&ctx);\r\nreturn ret ?: nbytes;\r\n}\r\nstatic void throtl_shutdown_wq(struct request_queue *q)\r\n{\r\nstruct throtl_data *td = q->td;\r\ncancel_work_sync(&td->dispatch_work);\r\n}\r\nbool blk_throtl_bio(struct request_queue *q, struct blkcg_gq *blkg,\r\nstruct bio *bio)\r\n{\r\nstruct throtl_qnode *qn = NULL;\r\nstruct throtl_grp *tg = blkg_to_tg(blkg ?: q->root_blkg);\r\nstruct throtl_service_queue *sq;\r\nbool rw = bio_data_dir(bio);\r\nbool throttled = false;\r\nWARN_ON_ONCE(!rcu_read_lock_held());\r\nif ((bio->bi_rw & REQ_THROTTLED) || !tg->has_rules[rw])\r\ngoto out;\r\nspin_lock_irq(q->queue_lock);\r\nif (unlikely(blk_queue_bypass(q)))\r\ngoto out_unlock;\r\nsq = &tg->service_queue;\r\nwhile (true) {\r\nif (sq->nr_queued[rw])\r\nbreak;\r\nif (!tg_may_dispatch(tg, bio, NULL))\r\nbreak;\r\nthrotl_charge_bio(tg, bio);\r\nthrotl_trim_slice(tg, rw);\r\nqn = &tg->qnode_on_parent[rw];\r\nsq = sq->parent_sq;\r\ntg = sq_to_tg(sq);\r\nif (!tg)\r\ngoto out_unlock;\r\n}\r\nthrotl_log(sq, "[%c] bio. bdisp=%llu sz=%u bps=%llu iodisp=%u iops=%u queued=%d/%d",\r\nrw == READ ? 'R' : 'W',\r\ntg->bytes_disp[rw], bio->bi_iter.bi_size, tg->bps[rw],\r\ntg->io_disp[rw], tg->iops[rw],\r\nsq->nr_queued[READ], sq->nr_queued[WRITE]);\r\nbio_associate_current(bio);\r\ntg->td->nr_queued[rw]++;\r\nthrotl_add_bio_tg(bio, qn, tg);\r\nthrottled = true;\r\nif (tg->flags & THROTL_TG_WAS_EMPTY) {\r\ntg_update_disptime(tg);\r\nthrotl_schedule_next_dispatch(tg->service_queue.parent_sq, true);\r\n}\r\nout_unlock:\r\nspin_unlock_irq(q->queue_lock);\r\nout:\r\nif (!throttled)\r\nbio->bi_rw &= ~REQ_THROTTLED;\r\nreturn throttled;\r\n}\r\nstatic void tg_drain_bios(struct throtl_service_queue *parent_sq)\r\n{\r\nstruct throtl_grp *tg;\r\nwhile ((tg = throtl_rb_first(parent_sq))) {\r\nstruct throtl_service_queue *sq = &tg->service_queue;\r\nstruct bio *bio;\r\nthrotl_dequeue_tg(tg);\r\nwhile ((bio = throtl_peek_queued(&sq->queued[READ])))\r\ntg_dispatch_one_bio(tg, bio_data_dir(bio));\r\nwhile ((bio = throtl_peek_queued(&sq->queued[WRITE])))\r\ntg_dispatch_one_bio(tg, bio_data_dir(bio));\r\n}\r\n}\r\nvoid blk_throtl_drain(struct request_queue *q)\r\n__releases(q->queue_lock) __acquires(q->queue_lock)\r\n{\r\nstruct throtl_data *td = q->td;\r\nstruct blkcg_gq *blkg;\r\nstruct cgroup_subsys_state *pos_css;\r\nstruct bio *bio;\r\nint rw;\r\nqueue_lockdep_assert_held(q);\r\nrcu_read_lock();\r\nblkg_for_each_descendant_post(blkg, pos_css, td->queue->root_blkg)\r\ntg_drain_bios(&blkg_to_tg(blkg)->service_queue);\r\ntg_drain_bios(&td->service_queue);\r\nrcu_read_unlock();\r\nspin_unlock_irq(q->queue_lock);\r\nfor (rw = READ; rw <= WRITE; rw++)\r\nwhile ((bio = throtl_pop_queued(&td->service_queue.queued[rw],\r\nNULL)))\r\ngeneric_make_request(bio);\r\nspin_lock_irq(q->queue_lock);\r\n}\r\nint blk_throtl_init(struct request_queue *q)\r\n{\r\nstruct throtl_data *td;\r\nint ret;\r\ntd = kzalloc_node(sizeof(*td), GFP_KERNEL, q->node);\r\nif (!td)\r\nreturn -ENOMEM;\r\nINIT_WORK(&td->dispatch_work, blk_throtl_dispatch_work_fn);\r\nthrotl_service_queue_init(&td->service_queue);\r\nq->td = td;\r\ntd->queue = q;\r\nret = blkcg_activate_policy(q, &blkcg_policy_throtl);\r\nif (ret)\r\nkfree(td);\r\nreturn ret;\r\n}\r\nvoid blk_throtl_exit(struct request_queue *q)\r\n{\r\nBUG_ON(!q->td);\r\nthrotl_shutdown_wq(q);\r\nblkcg_deactivate_policy(q, &blkcg_policy_throtl);\r\nkfree(q->td);\r\n}\r\nstatic int __init throtl_init(void)\r\n{\r\nkthrotld_workqueue = alloc_workqueue("kthrotld", WQ_MEM_RECLAIM, 0);\r\nif (!kthrotld_workqueue)\r\npanic("Failed to create kthrotld\n");\r\nreturn blkcg_policy_register(&blkcg_policy_throtl);\r\n}
