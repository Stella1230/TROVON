static struct device *chan2dev(struct dma_chan *chan)\r\n{\r\nreturn &chan->dev->device;\r\n}\r\nstatic inline struct moxart_chan *to_moxart_dma_chan(struct dma_chan *c)\r\n{\r\nreturn container_of(c, struct moxart_chan, vc.chan);\r\n}\r\nstatic inline struct moxart_desc *to_moxart_dma_desc(\r\nstruct dma_async_tx_descriptor *t)\r\n{\r\nreturn container_of(t, struct moxart_desc, vd.tx);\r\n}\r\nstatic void moxart_dma_desc_free(struct virt_dma_desc *vd)\r\n{\r\nkfree(container_of(vd, struct moxart_desc, vd));\r\n}\r\nstatic int moxart_terminate_all(struct dma_chan *chan)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\nunsigned long flags;\r\nLIST_HEAD(head);\r\nu32 ctrl;\r\ndev_dbg(chan2dev(chan), "%s: ch=%p\n", __func__, ch);\r\nspin_lock_irqsave(&ch->vc.lock, flags);\r\nif (ch->desc) {\r\nmoxart_dma_desc_free(&ch->desc->vd);\r\nch->desc = NULL;\r\n}\r\nctrl = readl(ch->base + REG_OFF_CTRL);\r\nctrl &= ~(APB_DMA_ENABLE | APB_DMA_FIN_INT_EN | APB_DMA_ERR_INT_EN);\r\nwritel(ctrl, ch->base + REG_OFF_CTRL);\r\nvchan_get_all_descriptors(&ch->vc, &head);\r\nspin_unlock_irqrestore(&ch->vc.lock, flags);\r\nvchan_dma_desc_free_list(&ch->vc, &head);\r\nreturn 0;\r\n}\r\nstatic int moxart_slave_config(struct dma_chan *chan,\r\nstruct dma_slave_config *cfg)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\nu32 ctrl;\r\nch->cfg = *cfg;\r\nctrl = readl(ch->base + REG_OFF_CTRL);\r\nctrl |= APB_DMA_BURST_MODE;\r\nctrl &= ~(APB_DMA_DEST_MASK | APB_DMA_SOURCE_MASK);\r\nctrl &= ~(APB_DMA_DEST_REQ_NO_MASK | APB_DMA_SOURCE_REQ_NO_MASK);\r\nswitch (ch->cfg.src_addr_width) {\r\ncase DMA_SLAVE_BUSWIDTH_1_BYTE:\r\nctrl |= APB_DMA_DATA_WIDTH_1;\r\nif (ch->cfg.direction != DMA_MEM_TO_DEV)\r\nctrl |= APB_DMA_DEST_INC_1_4;\r\nelse\r\nctrl |= APB_DMA_SOURCE_INC_1_4;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_2_BYTES:\r\nctrl |= APB_DMA_DATA_WIDTH_2;\r\nif (ch->cfg.direction != DMA_MEM_TO_DEV)\r\nctrl |= APB_DMA_DEST_INC_2_8;\r\nelse\r\nctrl |= APB_DMA_SOURCE_INC_2_8;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_4_BYTES:\r\nctrl &= ~APB_DMA_DATA_WIDTH;\r\nif (ch->cfg.direction != DMA_MEM_TO_DEV)\r\nctrl |= APB_DMA_DEST_INC_4_16;\r\nelse\r\nctrl |= APB_DMA_SOURCE_INC_4_16;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (ch->cfg.direction == DMA_MEM_TO_DEV) {\r\nctrl &= ~APB_DMA_DEST_SELECT;\r\nctrl |= APB_DMA_SOURCE_SELECT;\r\nctrl |= (ch->line_reqno << 16 &\r\nAPB_DMA_DEST_REQ_NO_MASK);\r\n} else {\r\nctrl |= APB_DMA_DEST_SELECT;\r\nctrl &= ~APB_DMA_SOURCE_SELECT;\r\nctrl |= (ch->line_reqno << 24 &\r\nAPB_DMA_SOURCE_REQ_NO_MASK);\r\n}\r\nwritel(ctrl, ch->base + REG_OFF_CTRL);\r\nreturn 0;\r\n}\r\nstatic struct dma_async_tx_descriptor *moxart_prep_slave_sg(\r\nstruct dma_chan *chan, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction dir,\r\nunsigned long tx_flags, void *context)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\nstruct moxart_desc *d;\r\nenum dma_slave_buswidth dev_width;\r\ndma_addr_t dev_addr;\r\nstruct scatterlist *sgent;\r\nunsigned int es;\r\nunsigned int i;\r\nif (!is_slave_direction(dir)) {\r\ndev_err(chan2dev(chan), "%s: invalid DMA direction\n",\r\n__func__);\r\nreturn NULL;\r\n}\r\nif (dir == DMA_DEV_TO_MEM) {\r\ndev_addr = ch->cfg.src_addr;\r\ndev_width = ch->cfg.src_addr_width;\r\n} else {\r\ndev_addr = ch->cfg.dst_addr;\r\ndev_width = ch->cfg.dst_addr_width;\r\n}\r\nswitch (dev_width) {\r\ncase DMA_SLAVE_BUSWIDTH_1_BYTE:\r\nes = MOXART_DMA_DATA_TYPE_S8;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_2_BYTES:\r\nes = MOXART_DMA_DATA_TYPE_S16;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_4_BYTES:\r\nes = MOXART_DMA_DATA_TYPE_S32;\r\nbreak;\r\ndefault:\r\ndev_err(chan2dev(chan), "%s: unsupported data width (%u)\n",\r\n__func__, dev_width);\r\nreturn NULL;\r\n}\r\nd = kzalloc(sizeof(*d) + sg_len * sizeof(d->sg[0]), GFP_ATOMIC);\r\nif (!d)\r\nreturn NULL;\r\nd->dma_dir = dir;\r\nd->dev_addr = dev_addr;\r\nd->es = es;\r\nfor_each_sg(sgl, sgent, sg_len, i) {\r\nd->sg[i].addr = sg_dma_address(sgent);\r\nd->sg[i].len = sg_dma_len(sgent);\r\n}\r\nd->sglen = sg_len;\r\nch->error = 0;\r\nreturn vchan_tx_prep(&ch->vc, &d->vd, tx_flags);\r\n}\r\nstatic struct dma_chan *moxart_of_xlate(struct of_phandle_args *dma_spec,\r\nstruct of_dma *ofdma)\r\n{\r\nstruct moxart_dmadev *mdc = ofdma->of_dma_data;\r\nstruct dma_chan *chan;\r\nstruct moxart_chan *ch;\r\nchan = dma_get_any_slave_channel(&mdc->dma_slave);\r\nif (!chan)\r\nreturn NULL;\r\nch = to_moxart_dma_chan(chan);\r\nch->line_reqno = dma_spec->args[0];\r\nreturn chan;\r\n}\r\nstatic int moxart_alloc_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\ndev_dbg(chan2dev(chan), "%s: allocating channel #%u\n",\r\n__func__, ch->ch_num);\r\nch->allocated = 1;\r\nreturn 0;\r\n}\r\nstatic void moxart_free_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\nvchan_free_chan_resources(&ch->vc);\r\ndev_dbg(chan2dev(chan), "%s: freeing channel #%u\n",\r\n__func__, ch->ch_num);\r\nch->allocated = 0;\r\n}\r\nstatic void moxart_dma_set_params(struct moxart_chan *ch, dma_addr_t src_addr,\r\ndma_addr_t dst_addr)\r\n{\r\nwritel(src_addr, ch->base + REG_OFF_ADDRESS_SOURCE);\r\nwritel(dst_addr, ch->base + REG_OFF_ADDRESS_DEST);\r\n}\r\nstatic void moxart_set_transfer_params(struct moxart_chan *ch, unsigned int len)\r\n{\r\nstruct moxart_desc *d = ch->desc;\r\nunsigned int sglen_div = es_bytes[d->es];\r\nd->dma_cycles = len >> sglen_div;\r\nwritel(d->dma_cycles, ch->base + REG_OFF_CYCLES);\r\ndev_dbg(chan2dev(&ch->vc.chan), "%s: set %u DMA cycles (len=%u)\n",\r\n__func__, d->dma_cycles, len);\r\n}\r\nstatic void moxart_start_dma(struct moxart_chan *ch)\r\n{\r\nu32 ctrl;\r\nctrl = readl(ch->base + REG_OFF_CTRL);\r\nctrl |= (APB_DMA_ENABLE | APB_DMA_FIN_INT_EN | APB_DMA_ERR_INT_EN);\r\nwritel(ctrl, ch->base + REG_OFF_CTRL);\r\n}\r\nstatic void moxart_dma_start_sg(struct moxart_chan *ch, unsigned int idx)\r\n{\r\nstruct moxart_desc *d = ch->desc;\r\nstruct moxart_sg *sg = ch->desc->sg + idx;\r\nif (ch->desc->dma_dir == DMA_MEM_TO_DEV)\r\nmoxart_dma_set_params(ch, sg->addr, d->dev_addr);\r\nelse if (ch->desc->dma_dir == DMA_DEV_TO_MEM)\r\nmoxart_dma_set_params(ch, d->dev_addr, sg->addr);\r\nmoxart_set_transfer_params(ch, sg->len);\r\nmoxart_start_dma(ch);\r\n}\r\nstatic void moxart_dma_start_desc(struct dma_chan *chan)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\nstruct virt_dma_desc *vd;\r\nvd = vchan_next_desc(&ch->vc);\r\nif (!vd) {\r\nch->desc = NULL;\r\nreturn;\r\n}\r\nlist_del(&vd->node);\r\nch->desc = to_moxart_dma_desc(&vd->tx);\r\nch->sgidx = 0;\r\nmoxart_dma_start_sg(ch, 0);\r\n}\r\nstatic void moxart_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&ch->vc.lock, flags);\r\nif (vchan_issue_pending(&ch->vc) && !ch->desc)\r\nmoxart_dma_start_desc(chan);\r\nspin_unlock_irqrestore(&ch->vc.lock, flags);\r\n}\r\nstatic size_t moxart_dma_desc_size(struct moxart_desc *d,\r\nunsigned int completed_sgs)\r\n{\r\nunsigned int i;\r\nsize_t size;\r\nfor (size = i = completed_sgs; i < d->sglen; i++)\r\nsize += d->sg[i].len;\r\nreturn size;\r\n}\r\nstatic size_t moxart_dma_desc_size_in_flight(struct moxart_chan *ch)\r\n{\r\nsize_t size;\r\nunsigned int completed_cycles, cycles;\r\nsize = moxart_dma_desc_size(ch->desc, ch->sgidx);\r\ncycles = readl(ch->base + REG_OFF_CYCLES);\r\ncompleted_cycles = (ch->desc->dma_cycles - cycles);\r\nsize -= completed_cycles << es_bytes[ch->desc->es];\r\ndev_dbg(chan2dev(&ch->vc.chan), "%s: size=%zu\n", __func__, size);\r\nreturn size;\r\n}\r\nstatic enum dma_status moxart_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie,\r\nstruct dma_tx_state *txstate)\r\n{\r\nstruct moxart_chan *ch = to_moxart_dma_chan(chan);\r\nstruct virt_dma_desc *vd;\r\nstruct moxart_desc *d;\r\nenum dma_status ret;\r\nunsigned long flags;\r\nret = dma_cookie_status(chan, cookie, txstate);\r\nspin_lock_irqsave(&ch->vc.lock, flags);\r\nvd = vchan_find_desc(&ch->vc, cookie);\r\nif (vd) {\r\nd = to_moxart_dma_desc(&vd->tx);\r\ntxstate->residue = moxart_dma_desc_size(d, 0);\r\n} else if (ch->desc && ch->desc->vd.tx.cookie == cookie) {\r\ntxstate->residue = moxart_dma_desc_size_in_flight(ch);\r\n}\r\nspin_unlock_irqrestore(&ch->vc.lock, flags);\r\nif (ch->error)\r\nreturn DMA_ERROR;\r\nreturn ret;\r\n}\r\nstatic void moxart_dma_init(struct dma_device *dma, struct device *dev)\r\n{\r\ndma->device_prep_slave_sg = moxart_prep_slave_sg;\r\ndma->device_alloc_chan_resources = moxart_alloc_chan_resources;\r\ndma->device_free_chan_resources = moxart_free_chan_resources;\r\ndma->device_issue_pending = moxart_issue_pending;\r\ndma->device_tx_status = moxart_tx_status;\r\ndma->device_config = moxart_slave_config;\r\ndma->device_terminate_all = moxart_terminate_all;\r\ndma->dev = dev;\r\nINIT_LIST_HEAD(&dma->channels);\r\n}\r\nstatic irqreturn_t moxart_dma_interrupt(int irq, void *devid)\r\n{\r\nstruct moxart_dmadev *mc = devid;\r\nstruct moxart_chan *ch = &mc->slave_chans[0];\r\nunsigned int i;\r\nunsigned long flags;\r\nu32 ctrl;\r\ndev_dbg(chan2dev(&ch->vc.chan), "%s\n", __func__);\r\nfor (i = 0; i < APB_DMA_MAX_CHANNEL; i++, ch++) {\r\nif (!ch->allocated)\r\ncontinue;\r\nctrl = readl(ch->base + REG_OFF_CTRL);\r\ndev_dbg(chan2dev(&ch->vc.chan), "%s: ch=%p ch->base=%p ctrl=%x\n",\r\n__func__, ch, ch->base, ctrl);\r\nif (ctrl & APB_DMA_FIN_INT_STS) {\r\nctrl &= ~APB_DMA_FIN_INT_STS;\r\nif (ch->desc) {\r\nspin_lock_irqsave(&ch->vc.lock, flags);\r\nif (++ch->sgidx < ch->desc->sglen) {\r\nmoxart_dma_start_sg(ch, ch->sgidx);\r\n} else {\r\nvchan_cookie_complete(&ch->desc->vd);\r\nmoxart_dma_start_desc(&ch->vc.chan);\r\n}\r\nspin_unlock_irqrestore(&ch->vc.lock, flags);\r\n}\r\n}\r\nif (ctrl & APB_DMA_ERR_INT_STS) {\r\nctrl &= ~APB_DMA_ERR_INT_STS;\r\nch->error = 1;\r\n}\r\nwritel(ctrl, ch->base + REG_OFF_CTRL);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int moxart_probe(struct platform_device *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct device_node *node = dev->of_node;\r\nstruct resource *res;\r\nstatic void __iomem *dma_base_addr;\r\nint ret, i;\r\nunsigned int irq;\r\nstruct moxart_chan *ch;\r\nstruct moxart_dmadev *mdc;\r\nmdc = devm_kzalloc(dev, sizeof(*mdc), GFP_KERNEL);\r\nif (!mdc) {\r\ndev_err(dev, "can't allocate DMA container\n");\r\nreturn -ENOMEM;\r\n}\r\nirq = irq_of_parse_and_map(node, 0);\r\nif (irq == NO_IRQ) {\r\ndev_err(dev, "no IRQ resource\n");\r\nreturn -EINVAL;\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\ndma_base_addr = devm_ioremap_resource(dev, res);\r\nif (IS_ERR(dma_base_addr))\r\nreturn PTR_ERR(dma_base_addr);\r\ndma_cap_zero(mdc->dma_slave.cap_mask);\r\ndma_cap_set(DMA_SLAVE, mdc->dma_slave.cap_mask);\r\ndma_cap_set(DMA_PRIVATE, mdc->dma_slave.cap_mask);\r\nmoxart_dma_init(&mdc->dma_slave, dev);\r\nch = &mdc->slave_chans[0];\r\nfor (i = 0; i < APB_DMA_MAX_CHANNEL; i++, ch++) {\r\nch->ch_num = i;\r\nch->base = dma_base_addr + i * REG_OFF_CHAN_SIZE;\r\nch->allocated = 0;\r\nch->vc.desc_free = moxart_dma_desc_free;\r\nvchan_init(&ch->vc, &mdc->dma_slave);\r\ndev_dbg(dev, "%s: chs[%d]: ch->ch_num=%u ch->base=%p\n",\r\n__func__, i, ch->ch_num, ch->base);\r\n}\r\nplatform_set_drvdata(pdev, mdc);\r\nret = devm_request_irq(dev, irq, moxart_dma_interrupt, 0,\r\n"moxart-dma-engine", mdc);\r\nif (ret) {\r\ndev_err(dev, "devm_request_irq failed\n");\r\nreturn ret;\r\n}\r\nret = dma_async_device_register(&mdc->dma_slave);\r\nif (ret) {\r\ndev_err(dev, "dma_async_device_register failed\n");\r\nreturn ret;\r\n}\r\nret = of_dma_controller_register(node, moxart_of_xlate, mdc);\r\nif (ret) {\r\ndev_err(dev, "of_dma_controller_register failed\n");\r\ndma_async_device_unregister(&mdc->dma_slave);\r\nreturn ret;\r\n}\r\ndev_dbg(dev, "%s: IRQ=%u\n", __func__, irq);\r\nreturn 0;\r\n}\r\nstatic int moxart_remove(struct platform_device *pdev)\r\n{\r\nstruct moxart_dmadev *m = platform_get_drvdata(pdev);\r\ndma_async_device_unregister(&m->dma_slave);\r\nif (pdev->dev.of_node)\r\nof_dma_controller_free(pdev->dev.of_node);\r\nreturn 0;\r\n}\r\nstatic int moxart_init(void)\r\n{\r\nreturn platform_driver_register(&moxart_driver);\r\n}\r\nstatic void __exit moxart_exit(void)\r\n{\r\nplatform_driver_unregister(&moxart_driver);\r\n}
