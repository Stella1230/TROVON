static bool ata_sstatus_online(u32 sstatus)\r\n{\r\nreturn (sstatus & 0xf) == 0x3;\r\n}\r\nstruct ata_link *ata_link_next(struct ata_link *link, struct ata_port *ap,\r\nenum ata_link_iter_mode mode)\r\n{\r\nBUG_ON(mode != ATA_LITER_EDGE &&\r\nmode != ATA_LITER_PMP_FIRST && mode != ATA_LITER_HOST_FIRST);\r\nif (!link)\r\nswitch (mode) {\r\ncase ATA_LITER_EDGE:\r\ncase ATA_LITER_PMP_FIRST:\r\nif (sata_pmp_attached(ap))\r\nreturn ap->pmp_link;\r\ncase ATA_LITER_HOST_FIRST:\r\nreturn &ap->link;\r\n}\r\nif (link == &ap->link)\r\nswitch (mode) {\r\ncase ATA_LITER_HOST_FIRST:\r\nif (sata_pmp_attached(ap))\r\nreturn ap->pmp_link;\r\ncase ATA_LITER_PMP_FIRST:\r\nif (unlikely(ap->slave_link))\r\nreturn ap->slave_link;\r\ncase ATA_LITER_EDGE:\r\nreturn NULL;\r\n}\r\nif (unlikely(link == ap->slave_link))\r\nreturn NULL;\r\nif (++link < ap->pmp_link + ap->nr_pmp_links)\r\nreturn link;\r\nif (mode == ATA_LITER_PMP_FIRST)\r\nreturn &ap->link;\r\nreturn NULL;\r\n}\r\nstruct ata_device *ata_dev_next(struct ata_device *dev, struct ata_link *link,\r\nenum ata_dev_iter_mode mode)\r\n{\r\nBUG_ON(mode != ATA_DITER_ENABLED && mode != ATA_DITER_ENABLED_REVERSE &&\r\nmode != ATA_DITER_ALL && mode != ATA_DITER_ALL_REVERSE);\r\nif (!dev)\r\nswitch (mode) {\r\ncase ATA_DITER_ENABLED:\r\ncase ATA_DITER_ALL:\r\ndev = link->device;\r\ngoto check;\r\ncase ATA_DITER_ENABLED_REVERSE:\r\ncase ATA_DITER_ALL_REVERSE:\r\ndev = link->device + ata_link_max_devices(link) - 1;\r\ngoto check;\r\n}\r\nnext:\r\nswitch (mode) {\r\ncase ATA_DITER_ENABLED:\r\ncase ATA_DITER_ALL:\r\nif (++dev < link->device + ata_link_max_devices(link))\r\ngoto check;\r\nreturn NULL;\r\ncase ATA_DITER_ENABLED_REVERSE:\r\ncase ATA_DITER_ALL_REVERSE:\r\nif (--dev >= link->device)\r\ngoto check;\r\nreturn NULL;\r\n}\r\ncheck:\r\nif ((mode == ATA_DITER_ENABLED || mode == ATA_DITER_ENABLED_REVERSE) &&\r\n!ata_dev_enabled(dev))\r\ngoto next;\r\nreturn dev;\r\n}\r\nstruct ata_link *ata_dev_phys_link(struct ata_device *dev)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nif (!ap->slave_link)\r\nreturn dev->link;\r\nif (!dev->devno)\r\nreturn &ap->link;\r\nreturn ap->slave_link;\r\n}\r\nvoid ata_force_cbl(struct ata_port *ap)\r\n{\r\nint i;\r\nfor (i = ata_force_tbl_size - 1; i >= 0; i--) {\r\nconst struct ata_force_ent *fe = &ata_force_tbl[i];\r\nif (fe->port != -1 && fe->port != ap->print_id)\r\ncontinue;\r\nif (fe->param.cbl == ATA_CBL_NONE)\r\ncontinue;\r\nap->cbl = fe->param.cbl;\r\nata_port_notice(ap, "FORCE: cable set to %s\n", fe->param.name);\r\nreturn;\r\n}\r\n}\r\nstatic void ata_force_link_limits(struct ata_link *link)\r\n{\r\nbool did_spd = false;\r\nint linkno = link->pmp;\r\nint i;\r\nif (ata_is_host_link(link))\r\nlinkno += 15;\r\nfor (i = ata_force_tbl_size - 1; i >= 0; i--) {\r\nconst struct ata_force_ent *fe = &ata_force_tbl[i];\r\nif (fe->port != -1 && fe->port != link->ap->print_id)\r\ncontinue;\r\nif (fe->device != -1 && fe->device != linkno)\r\ncontinue;\r\nif (!did_spd && fe->param.spd_limit) {\r\nlink->hw_sata_spd_limit = (1 << fe->param.spd_limit) - 1;\r\nata_link_notice(link, "FORCE: PHY spd limit set to %s\n",\r\nfe->param.name);\r\ndid_spd = true;\r\n}\r\nif (fe->param.lflags) {\r\nlink->flags |= fe->param.lflags;\r\nata_link_notice(link,\r\n"FORCE: link flag 0x%x forced -> 0x%x\n",\r\nfe->param.lflags, link->flags);\r\n}\r\n}\r\n}\r\nstatic void ata_force_xfermask(struct ata_device *dev)\r\n{\r\nint devno = dev->link->pmp + dev->devno;\r\nint alt_devno = devno;\r\nint i;\r\nif (ata_is_host_link(dev->link))\r\nalt_devno += 15;\r\nfor (i = ata_force_tbl_size - 1; i >= 0; i--) {\r\nconst struct ata_force_ent *fe = &ata_force_tbl[i];\r\nunsigned long pio_mask, mwdma_mask, udma_mask;\r\nif (fe->port != -1 && fe->port != dev->link->ap->print_id)\r\ncontinue;\r\nif (fe->device != -1 && fe->device != devno &&\r\nfe->device != alt_devno)\r\ncontinue;\r\nif (!fe->param.xfer_mask)\r\ncontinue;\r\nata_unpack_xfermask(fe->param.xfer_mask,\r\n&pio_mask, &mwdma_mask, &udma_mask);\r\nif (udma_mask)\r\ndev->udma_mask = udma_mask;\r\nelse if (mwdma_mask) {\r\ndev->udma_mask = 0;\r\ndev->mwdma_mask = mwdma_mask;\r\n} else {\r\ndev->udma_mask = 0;\r\ndev->mwdma_mask = 0;\r\ndev->pio_mask = pio_mask;\r\n}\r\nata_dev_notice(dev, "FORCE: xfer_mask set to %s\n",\r\nfe->param.name);\r\nreturn;\r\n}\r\n}\r\nstatic void ata_force_horkage(struct ata_device *dev)\r\n{\r\nint devno = dev->link->pmp + dev->devno;\r\nint alt_devno = devno;\r\nint i;\r\nif (ata_is_host_link(dev->link))\r\nalt_devno += 15;\r\nfor (i = 0; i < ata_force_tbl_size; i++) {\r\nconst struct ata_force_ent *fe = &ata_force_tbl[i];\r\nif (fe->port != -1 && fe->port != dev->link->ap->print_id)\r\ncontinue;\r\nif (fe->device != -1 && fe->device != devno &&\r\nfe->device != alt_devno)\r\ncontinue;\r\nif (!(~dev->horkage & fe->param.horkage_on) &&\r\n!(dev->horkage & fe->param.horkage_off))\r\ncontinue;\r\ndev->horkage |= fe->param.horkage_on;\r\ndev->horkage &= ~fe->param.horkage_off;\r\nata_dev_notice(dev, "FORCE: horkage modified (%s)\n",\r\nfe->param.name);\r\n}\r\n}\r\nint atapi_cmd_type(u8 opcode)\r\n{\r\nswitch (opcode) {\r\ncase GPCMD_READ_10:\r\ncase GPCMD_READ_12:\r\nreturn ATAPI_READ;\r\ncase GPCMD_WRITE_10:\r\ncase GPCMD_WRITE_12:\r\ncase GPCMD_WRITE_AND_VERIFY_10:\r\nreturn ATAPI_WRITE;\r\ncase GPCMD_READ_CD:\r\ncase GPCMD_READ_CD_MSF:\r\nreturn ATAPI_READ_CD;\r\ncase ATA_16:\r\ncase ATA_12:\r\nif (atapi_passthru16)\r\nreturn ATAPI_PASS_THRU;\r\ndefault:\r\nreturn ATAPI_MISC;\r\n}\r\n}\r\nvoid ata_tf_to_fis(const struct ata_taskfile *tf, u8 pmp, int is_cmd, u8 *fis)\r\n{\r\nfis[0] = 0x27;\r\nfis[1] = pmp & 0xf;\r\nif (is_cmd)\r\nfis[1] |= (1 << 7);\r\nfis[2] = tf->command;\r\nfis[3] = tf->feature;\r\nfis[4] = tf->lbal;\r\nfis[5] = tf->lbam;\r\nfis[6] = tf->lbah;\r\nfis[7] = tf->device;\r\nfis[8] = tf->hob_lbal;\r\nfis[9] = tf->hob_lbam;\r\nfis[10] = tf->hob_lbah;\r\nfis[11] = tf->hob_feature;\r\nfis[12] = tf->nsect;\r\nfis[13] = tf->hob_nsect;\r\nfis[14] = 0;\r\nfis[15] = tf->ctl;\r\nfis[16] = tf->auxiliary & 0xff;\r\nfis[17] = (tf->auxiliary >> 8) & 0xff;\r\nfis[18] = (tf->auxiliary >> 16) & 0xff;\r\nfis[19] = (tf->auxiliary >> 24) & 0xff;\r\n}\r\nvoid ata_tf_from_fis(const u8 *fis, struct ata_taskfile *tf)\r\n{\r\ntf->command = fis[2];\r\ntf->feature = fis[3];\r\ntf->lbal = fis[4];\r\ntf->lbam = fis[5];\r\ntf->lbah = fis[6];\r\ntf->device = fis[7];\r\ntf->hob_lbal = fis[8];\r\ntf->hob_lbam = fis[9];\r\ntf->hob_lbah = fis[10];\r\ntf->nsect = fis[12];\r\ntf->hob_nsect = fis[13];\r\n}\r\nstatic int ata_rwcmd_protocol(struct ata_taskfile *tf, struct ata_device *dev)\r\n{\r\nu8 cmd;\r\nint index, fua, lba48, write;\r\nfua = (tf->flags & ATA_TFLAG_FUA) ? 4 : 0;\r\nlba48 = (tf->flags & ATA_TFLAG_LBA48) ? 2 : 0;\r\nwrite = (tf->flags & ATA_TFLAG_WRITE) ? 1 : 0;\r\nif (dev->flags & ATA_DFLAG_PIO) {\r\ntf->protocol = ATA_PROT_PIO;\r\nindex = dev->multi_count ? 0 : 8;\r\n} else if (lba48 && (dev->link->ap->flags & ATA_FLAG_PIO_LBA48)) {\r\ntf->protocol = ATA_PROT_PIO;\r\nindex = dev->multi_count ? 0 : 8;\r\n} else {\r\ntf->protocol = ATA_PROT_DMA;\r\nindex = 16;\r\n}\r\ncmd = ata_rw_cmds[index + fua + lba48 + write];\r\nif (cmd) {\r\ntf->command = cmd;\r\nreturn 0;\r\n}\r\nreturn -1;\r\n}\r\nu64 ata_tf_read_block(struct ata_taskfile *tf, struct ata_device *dev)\r\n{\r\nu64 block = 0;\r\nif (tf->flags & ATA_TFLAG_LBA) {\r\nif (tf->flags & ATA_TFLAG_LBA48) {\r\nblock |= (u64)tf->hob_lbah << 40;\r\nblock |= (u64)tf->hob_lbam << 32;\r\nblock |= (u64)tf->hob_lbal << 24;\r\n} else\r\nblock |= (tf->device & 0xf) << 24;\r\nblock |= tf->lbah << 16;\r\nblock |= tf->lbam << 8;\r\nblock |= tf->lbal;\r\n} else {\r\nu32 cyl, head, sect;\r\ncyl = tf->lbam | (tf->lbah << 8);\r\nhead = tf->device & 0xf;\r\nsect = tf->lbal;\r\nif (!sect) {\r\nata_dev_warn(dev,\r\n"device reported invalid CHS sector 0\n");\r\nsect = 1;\r\n}\r\nblock = (cyl * dev->heads + head) * dev->sectors + sect - 1;\r\n}\r\nreturn block;\r\n}\r\nint ata_build_rw_tf(struct ata_taskfile *tf, struct ata_device *dev,\r\nu64 block, u32 n_block, unsigned int tf_flags,\r\nunsigned int tag)\r\n{\r\ntf->flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;\r\ntf->flags |= tf_flags;\r\nif (ata_ncq_enabled(dev) && likely(tag != ATA_TAG_INTERNAL)) {\r\nif (!lba_48_ok(block, n_block))\r\nreturn -ERANGE;\r\ntf->protocol = ATA_PROT_NCQ;\r\ntf->flags |= ATA_TFLAG_LBA | ATA_TFLAG_LBA48;\r\nif (tf->flags & ATA_TFLAG_WRITE)\r\ntf->command = ATA_CMD_FPDMA_WRITE;\r\nelse\r\ntf->command = ATA_CMD_FPDMA_READ;\r\ntf->nsect = tag << 3;\r\ntf->hob_feature = (n_block >> 8) & 0xff;\r\ntf->feature = n_block & 0xff;\r\ntf->hob_lbah = (block >> 40) & 0xff;\r\ntf->hob_lbam = (block >> 32) & 0xff;\r\ntf->hob_lbal = (block >> 24) & 0xff;\r\ntf->lbah = (block >> 16) & 0xff;\r\ntf->lbam = (block >> 8) & 0xff;\r\ntf->lbal = block & 0xff;\r\ntf->device = ATA_LBA;\r\nif (tf->flags & ATA_TFLAG_FUA)\r\ntf->device |= 1 << 7;\r\n} else if (dev->flags & ATA_DFLAG_LBA) {\r\ntf->flags |= ATA_TFLAG_LBA;\r\nif (lba_28_ok(block, n_block)) {\r\ntf->device |= (block >> 24) & 0xf;\r\n} else if (lba_48_ok(block, n_block)) {\r\nif (!(dev->flags & ATA_DFLAG_LBA48))\r\nreturn -ERANGE;\r\ntf->flags |= ATA_TFLAG_LBA48;\r\ntf->hob_nsect = (n_block >> 8) & 0xff;\r\ntf->hob_lbah = (block >> 40) & 0xff;\r\ntf->hob_lbam = (block >> 32) & 0xff;\r\ntf->hob_lbal = (block >> 24) & 0xff;\r\n} else\r\nreturn -ERANGE;\r\nif (unlikely(ata_rwcmd_protocol(tf, dev) < 0))\r\nreturn -EINVAL;\r\ntf->nsect = n_block & 0xff;\r\ntf->lbah = (block >> 16) & 0xff;\r\ntf->lbam = (block >> 8) & 0xff;\r\ntf->lbal = block & 0xff;\r\ntf->device |= ATA_LBA;\r\n} else {\r\nu32 sect, head, cyl, track;\r\nif (!lba_28_ok(block, n_block))\r\nreturn -ERANGE;\r\nif (unlikely(ata_rwcmd_protocol(tf, dev) < 0))\r\nreturn -EINVAL;\r\ntrack = (u32)block / dev->sectors;\r\ncyl = track / dev->heads;\r\nhead = track % dev->heads;\r\nsect = (u32)block % dev->sectors + 1;\r\nDPRINTK("block %u track %u cyl %u head %u sect %u\n",\r\n(u32)block, track, cyl, head, sect);\r\nif ((cyl >> 16) || (head >> 4) || (sect >> 8) || (!sect))\r\nreturn -ERANGE;\r\ntf->nsect = n_block & 0xff;\r\ntf->lbal = sect;\r\ntf->lbam = cyl;\r\ntf->lbah = cyl >> 8;\r\ntf->device |= head;\r\n}\r\nreturn 0;\r\n}\r\nunsigned long ata_pack_xfermask(unsigned long pio_mask,\r\nunsigned long mwdma_mask,\r\nunsigned long udma_mask)\r\n{\r\nreturn ((pio_mask << ATA_SHIFT_PIO) & ATA_MASK_PIO) |\r\n((mwdma_mask << ATA_SHIFT_MWDMA) & ATA_MASK_MWDMA) |\r\n((udma_mask << ATA_SHIFT_UDMA) & ATA_MASK_UDMA);\r\n}\r\nvoid ata_unpack_xfermask(unsigned long xfer_mask, unsigned long *pio_mask,\r\nunsigned long *mwdma_mask, unsigned long *udma_mask)\r\n{\r\nif (pio_mask)\r\n*pio_mask = (xfer_mask & ATA_MASK_PIO) >> ATA_SHIFT_PIO;\r\nif (mwdma_mask)\r\n*mwdma_mask = (xfer_mask & ATA_MASK_MWDMA) >> ATA_SHIFT_MWDMA;\r\nif (udma_mask)\r\n*udma_mask = (xfer_mask & ATA_MASK_UDMA) >> ATA_SHIFT_UDMA;\r\n}\r\nu8 ata_xfer_mask2mode(unsigned long xfer_mask)\r\n{\r\nint highbit = fls(xfer_mask) - 1;\r\nconst struct ata_xfer_ent *ent;\r\nfor (ent = ata_xfer_tbl; ent->shift >= 0; ent++)\r\nif (highbit >= ent->shift && highbit < ent->shift + ent->bits)\r\nreturn ent->base + highbit - ent->shift;\r\nreturn 0xff;\r\n}\r\nunsigned long ata_xfer_mode2mask(u8 xfer_mode)\r\n{\r\nconst struct ata_xfer_ent *ent;\r\nfor (ent = ata_xfer_tbl; ent->shift >= 0; ent++)\r\nif (xfer_mode >= ent->base && xfer_mode < ent->base + ent->bits)\r\nreturn ((2 << (ent->shift + xfer_mode - ent->base)) - 1)\r\n& ~((1 << ent->shift) - 1);\r\nreturn 0;\r\n}\r\nint ata_xfer_mode2shift(unsigned long xfer_mode)\r\n{\r\nconst struct ata_xfer_ent *ent;\r\nfor (ent = ata_xfer_tbl; ent->shift >= 0; ent++)\r\nif (xfer_mode >= ent->base && xfer_mode < ent->base + ent->bits)\r\nreturn ent->shift;\r\nreturn -1;\r\n}\r\nconst char *ata_mode_string(unsigned long xfer_mask)\r\n{\r\nstatic const char * const xfer_mode_str[] = {\r\n"PIO0",\r\n"PIO1",\r\n"PIO2",\r\n"PIO3",\r\n"PIO4",\r\n"PIO5",\r\n"PIO6",\r\n"MWDMA0",\r\n"MWDMA1",\r\n"MWDMA2",\r\n"MWDMA3",\r\n"MWDMA4",\r\n"UDMA/16",\r\n"UDMA/25",\r\n"UDMA/33",\r\n"UDMA/44",\r\n"UDMA/66",\r\n"UDMA/100",\r\n"UDMA/133",\r\n"UDMA7",\r\n};\r\nint highbit;\r\nhighbit = fls(xfer_mask) - 1;\r\nif (highbit >= 0 && highbit < ARRAY_SIZE(xfer_mode_str))\r\nreturn xfer_mode_str[highbit];\r\nreturn "<n/a>";\r\n}\r\nconst char *sata_spd_string(unsigned int spd)\r\n{\r\nstatic const char * const spd_str[] = {\r\n"1.5 Gbps",\r\n"3.0 Gbps",\r\n"6.0 Gbps",\r\n};\r\nif (spd == 0 || (spd - 1) >= ARRAY_SIZE(spd_str))\r\nreturn "<unknown>";\r\nreturn spd_str[spd - 1];\r\n}\r\nunsigned int ata_dev_classify(const struct ata_taskfile *tf)\r\n{\r\nif ((tf->lbam == 0) && (tf->lbah == 0)) {\r\nDPRINTK("found ATA device by sig\n");\r\nreturn ATA_DEV_ATA;\r\n}\r\nif ((tf->lbam == 0x14) && (tf->lbah == 0xeb)) {\r\nDPRINTK("found ATAPI device by sig\n");\r\nreturn ATA_DEV_ATAPI;\r\n}\r\nif ((tf->lbam == 0x69) && (tf->lbah == 0x96)) {\r\nDPRINTK("found PMP device by sig\n");\r\nreturn ATA_DEV_PMP;\r\n}\r\nif ((tf->lbam == 0x3c) && (tf->lbah == 0xc3)) {\r\nDPRINTK("found SEMB device by sig (could be ATA device)\n");\r\nreturn ATA_DEV_SEMB;\r\n}\r\nif ((tf->lbam == 0xcd) && (tf->lbah == 0xab)) {\r\nDPRINTK("found ZAC device by sig\n");\r\nreturn ATA_DEV_ZAC;\r\n}\r\nDPRINTK("unknown device\n");\r\nreturn ATA_DEV_UNKNOWN;\r\n}\r\nvoid ata_id_string(const u16 *id, unsigned char *s,\r\nunsigned int ofs, unsigned int len)\r\n{\r\nunsigned int c;\r\nBUG_ON(len & 1);\r\nwhile (len > 0) {\r\nc = id[ofs] >> 8;\r\n*s = c;\r\ns++;\r\nc = id[ofs] & 0xff;\r\n*s = c;\r\ns++;\r\nofs++;\r\nlen -= 2;\r\n}\r\n}\r\nvoid ata_id_c_string(const u16 *id, unsigned char *s,\r\nunsigned int ofs, unsigned int len)\r\n{\r\nunsigned char *p;\r\nata_id_string(id, s, ofs, len - 1);\r\np = s + strnlen(s, len - 1);\r\nwhile (p > s && p[-1] == ' ')\r\np--;\r\n*p = '\0';\r\n}\r\nstatic u64 ata_id_n_sectors(const u16 *id)\r\n{\r\nif (ata_id_has_lba(id)) {\r\nif (ata_id_has_lba48(id))\r\nreturn ata_id_u64(id, ATA_ID_LBA_CAPACITY_2);\r\nelse\r\nreturn ata_id_u32(id, ATA_ID_LBA_CAPACITY);\r\n} else {\r\nif (ata_id_current_chs_valid(id))\r\nreturn id[ATA_ID_CUR_CYLS] * id[ATA_ID_CUR_HEADS] *\r\nid[ATA_ID_CUR_SECTORS];\r\nelse\r\nreturn id[ATA_ID_CYLS] * id[ATA_ID_HEADS] *\r\nid[ATA_ID_SECTORS];\r\n}\r\n}\r\nu64 ata_tf_to_lba48(const struct ata_taskfile *tf)\r\n{\r\nu64 sectors = 0;\r\nsectors |= ((u64)(tf->hob_lbah & 0xff)) << 40;\r\nsectors |= ((u64)(tf->hob_lbam & 0xff)) << 32;\r\nsectors |= ((u64)(tf->hob_lbal & 0xff)) << 24;\r\nsectors |= (tf->lbah & 0xff) << 16;\r\nsectors |= (tf->lbam & 0xff) << 8;\r\nsectors |= (tf->lbal & 0xff);\r\nreturn sectors;\r\n}\r\nu64 ata_tf_to_lba(const struct ata_taskfile *tf)\r\n{\r\nu64 sectors = 0;\r\nsectors |= (tf->device & 0x0f) << 24;\r\nsectors |= (tf->lbah & 0xff) << 16;\r\nsectors |= (tf->lbam & 0xff) << 8;\r\nsectors |= (tf->lbal & 0xff);\r\nreturn sectors;\r\n}\r\nstatic int ata_read_native_max_address(struct ata_device *dev, u64 *max_sectors)\r\n{\r\nunsigned int err_mask;\r\nstruct ata_taskfile tf;\r\nint lba48 = ata_id_has_lba48(dev->id);\r\nata_tf_init(dev, &tf);\r\ntf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_ISADDR;\r\nif (lba48) {\r\ntf.command = ATA_CMD_READ_NATIVE_MAX_EXT;\r\ntf.flags |= ATA_TFLAG_LBA48;\r\n} else\r\ntf.command = ATA_CMD_READ_NATIVE_MAX;\r\ntf.protocol |= ATA_PROT_NODATA;\r\ntf.device |= ATA_LBA;\r\nerr_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);\r\nif (err_mask) {\r\nata_dev_warn(dev,\r\n"failed to read native max address (err_mask=0x%x)\n",\r\nerr_mask);\r\nif (err_mask == AC_ERR_DEV && (tf.feature & ATA_ABORTED))\r\nreturn -EACCES;\r\nreturn -EIO;\r\n}\r\nif (lba48)\r\n*max_sectors = ata_tf_to_lba48(&tf) + 1;\r\nelse\r\n*max_sectors = ata_tf_to_lba(&tf) + 1;\r\nif (dev->horkage & ATA_HORKAGE_HPA_SIZE)\r\n(*max_sectors)--;\r\nreturn 0;\r\n}\r\nstatic int ata_set_max_sectors(struct ata_device *dev, u64 new_sectors)\r\n{\r\nunsigned int err_mask;\r\nstruct ata_taskfile tf;\r\nint lba48 = ata_id_has_lba48(dev->id);\r\nnew_sectors--;\r\nata_tf_init(dev, &tf);\r\ntf.flags |= ATA_TFLAG_DEVICE | ATA_TFLAG_ISADDR;\r\nif (lba48) {\r\ntf.command = ATA_CMD_SET_MAX_EXT;\r\ntf.flags |= ATA_TFLAG_LBA48;\r\ntf.hob_lbal = (new_sectors >> 24) & 0xff;\r\ntf.hob_lbam = (new_sectors >> 32) & 0xff;\r\ntf.hob_lbah = (new_sectors >> 40) & 0xff;\r\n} else {\r\ntf.command = ATA_CMD_SET_MAX;\r\ntf.device |= (new_sectors >> 24) & 0xf;\r\n}\r\ntf.protocol |= ATA_PROT_NODATA;\r\ntf.device |= ATA_LBA;\r\ntf.lbal = (new_sectors >> 0) & 0xff;\r\ntf.lbam = (new_sectors >> 8) & 0xff;\r\ntf.lbah = (new_sectors >> 16) & 0xff;\r\nerr_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);\r\nif (err_mask) {\r\nata_dev_warn(dev,\r\n"failed to set max address (err_mask=0x%x)\n",\r\nerr_mask);\r\nif (err_mask == AC_ERR_DEV &&\r\n(tf.feature & (ATA_ABORTED | ATA_IDNF)))\r\nreturn -EACCES;\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ata_hpa_resize(struct ata_device *dev)\r\n{\r\nstruct ata_eh_context *ehc = &dev->link->eh_context;\r\nint print_info = ehc->i.flags & ATA_EHI_PRINTINFO;\r\nbool unlock_hpa = ata_ignore_hpa || dev->flags & ATA_DFLAG_UNLOCK_HPA;\r\nu64 sectors = ata_id_n_sectors(dev->id);\r\nu64 native_sectors;\r\nint rc;\r\nif ((dev->class != ATA_DEV_ATA && dev->class != ATA_DEV_ZAC) ||\r\n!ata_id_has_lba(dev->id) || !ata_id_hpa_enabled(dev->id) ||\r\n(dev->horkage & ATA_HORKAGE_BROKEN_HPA))\r\nreturn 0;\r\nrc = ata_read_native_max_address(dev, &native_sectors);\r\nif (rc) {\r\nif (rc == -EACCES || !unlock_hpa) {\r\nata_dev_warn(dev,\r\n"HPA support seems broken, skipping HPA handling\n");\r\ndev->horkage |= ATA_HORKAGE_BROKEN_HPA;\r\nif (rc == -EACCES)\r\nrc = 0;\r\n}\r\nreturn rc;\r\n}\r\ndev->n_native_sectors = native_sectors;\r\nif (native_sectors <= sectors || !unlock_hpa) {\r\nif (!print_info || native_sectors == sectors)\r\nreturn 0;\r\nif (native_sectors > sectors)\r\nata_dev_info(dev,\r\n"HPA detected: current %llu, native %llu\n",\r\n(unsigned long long)sectors,\r\n(unsigned long long)native_sectors);\r\nelse if (native_sectors < sectors)\r\nata_dev_warn(dev,\r\n"native sectors (%llu) is smaller than sectors (%llu)\n",\r\n(unsigned long long)native_sectors,\r\n(unsigned long long)sectors);\r\nreturn 0;\r\n}\r\nrc = ata_set_max_sectors(dev, native_sectors);\r\nif (rc == -EACCES) {\r\nata_dev_warn(dev,\r\n"device aborted resize (%llu -> %llu), skipping HPA handling\n",\r\n(unsigned long long)sectors,\r\n(unsigned long long)native_sectors);\r\ndev->horkage |= ATA_HORKAGE_BROKEN_HPA;\r\nreturn 0;\r\n} else if (rc)\r\nreturn rc;\r\nrc = ata_dev_reread_id(dev, 0);\r\nif (rc) {\r\nata_dev_err(dev,\r\n"failed to re-read IDENTIFY data after HPA resizing\n");\r\nreturn rc;\r\n}\r\nif (print_info) {\r\nu64 new_sectors = ata_id_n_sectors(dev->id);\r\nata_dev_info(dev,\r\n"HPA unlocked: %llu -> %llu, native %llu\n",\r\n(unsigned long long)sectors,\r\n(unsigned long long)new_sectors,\r\n(unsigned long long)native_sectors);\r\n}\r\nreturn 0;\r\n}\r\nstatic inline void ata_dump_id(const u16 *id)\r\n{\r\nDPRINTK("49==0x%04x "\r\n"53==0x%04x "\r\n"63==0x%04x "\r\n"64==0x%04x "\r\n"75==0x%04x \n",\r\nid[49],\r\nid[53],\r\nid[63],\r\nid[64],\r\nid[75]);\r\nDPRINTK("80==0x%04x "\r\n"81==0x%04x "\r\n"82==0x%04x "\r\n"83==0x%04x "\r\n"84==0x%04x \n",\r\nid[80],\r\nid[81],\r\nid[82],\r\nid[83],\r\nid[84]);\r\nDPRINTK("88==0x%04x "\r\n"93==0x%04x\n",\r\nid[88],\r\nid[93]);\r\n}\r\nunsigned long ata_id_xfermask(const u16 *id)\r\n{\r\nunsigned long pio_mask, mwdma_mask, udma_mask;\r\nif (id[ATA_ID_FIELD_VALID] & (1 << 1)) {\r\npio_mask = id[ATA_ID_PIO_MODES] & 0x03;\r\npio_mask <<= 3;\r\npio_mask |= 0x7;\r\n} else {\r\nu8 mode = (id[ATA_ID_OLD_PIO_MODES] >> 8) & 0xFF;\r\nif (mode < 5)\r\npio_mask = (2 << mode) - 1;\r\nelse\r\npio_mask = 1;\r\n}\r\nmwdma_mask = id[ATA_ID_MWDMA_MODES] & 0x07;\r\nif (ata_id_is_cfa(id)) {\r\nint pio = (id[ATA_ID_CFA_MODES] >> 0) & 0x7;\r\nint dma = (id[ATA_ID_CFA_MODES] >> 3) & 0x7;\r\nif (pio)\r\npio_mask |= (1 << 5);\r\nif (pio > 1)\r\npio_mask |= (1 << 6);\r\nif (dma)\r\nmwdma_mask |= (1 << 3);\r\nif (dma > 1)\r\nmwdma_mask |= (1 << 4);\r\n}\r\nudma_mask = 0;\r\nif (id[ATA_ID_FIELD_VALID] & (1 << 2))\r\nudma_mask = id[ATA_ID_UDMA_MODES] & 0xff;\r\nreturn ata_pack_xfermask(pio_mask, mwdma_mask, udma_mask);\r\n}\r\nstatic void ata_qc_complete_internal(struct ata_queued_cmd *qc)\r\n{\r\nstruct completion *waiting = qc->private_data;\r\ncomplete(waiting);\r\n}\r\nunsigned ata_exec_internal_sg(struct ata_device *dev,\r\nstruct ata_taskfile *tf, const u8 *cdb,\r\nint dma_dir, struct scatterlist *sgl,\r\nunsigned int n_elem, unsigned long timeout)\r\n{\r\nstruct ata_link *link = dev->link;\r\nstruct ata_port *ap = link->ap;\r\nu8 command = tf->command;\r\nint auto_timeout = 0;\r\nstruct ata_queued_cmd *qc;\r\nunsigned int tag, preempted_tag;\r\nu32 preempted_sactive, preempted_qc_active;\r\nint preempted_nr_active_links;\r\nDECLARE_COMPLETION_ONSTACK(wait);\r\nunsigned long flags;\r\nunsigned int err_mask;\r\nint rc;\r\nspin_lock_irqsave(ap->lock, flags);\r\nif (ap->pflags & ATA_PFLAG_FROZEN) {\r\nspin_unlock_irqrestore(ap->lock, flags);\r\nreturn AC_ERR_SYSTEM;\r\n}\r\nif (ap->ops->error_handler)\r\ntag = ATA_TAG_INTERNAL;\r\nelse\r\ntag = 0;\r\nqc = __ata_qc_from_tag(ap, tag);\r\nqc->tag = tag;\r\nqc->scsicmd = NULL;\r\nqc->ap = ap;\r\nqc->dev = dev;\r\nata_qc_reinit(qc);\r\npreempted_tag = link->active_tag;\r\npreempted_sactive = link->sactive;\r\npreempted_qc_active = ap->qc_active;\r\npreempted_nr_active_links = ap->nr_active_links;\r\nlink->active_tag = ATA_TAG_POISON;\r\nlink->sactive = 0;\r\nap->qc_active = 0;\r\nap->nr_active_links = 0;\r\nqc->tf = *tf;\r\nif (cdb)\r\nmemcpy(qc->cdb, cdb, ATAPI_CDB_LEN);\r\nif (tf->protocol == ATAPI_PROT_DMA && (dev->flags & ATA_DFLAG_DMADIR) &&\r\ndma_dir == DMA_FROM_DEVICE)\r\nqc->tf.feature |= ATAPI_DMADIR;\r\nqc->flags |= ATA_QCFLAG_RESULT_TF;\r\nqc->dma_dir = dma_dir;\r\nif (dma_dir != DMA_NONE) {\r\nunsigned int i, buflen = 0;\r\nstruct scatterlist *sg;\r\nfor_each_sg(sgl, sg, n_elem, i)\r\nbuflen += sg->length;\r\nata_sg_init(qc, sgl, n_elem);\r\nqc->nbytes = buflen;\r\n}\r\nqc->private_data = &wait;\r\nqc->complete_fn = ata_qc_complete_internal;\r\nata_qc_issue(qc);\r\nspin_unlock_irqrestore(ap->lock, flags);\r\nif (!timeout) {\r\nif (ata_probe_timeout)\r\ntimeout = ata_probe_timeout * 1000;\r\nelse {\r\ntimeout = ata_internal_cmd_timeout(dev, command);\r\nauto_timeout = 1;\r\n}\r\n}\r\nif (ap->ops->error_handler)\r\nata_eh_release(ap);\r\nrc = wait_for_completion_timeout(&wait, msecs_to_jiffies(timeout));\r\nif (ap->ops->error_handler)\r\nata_eh_acquire(ap);\r\nata_sff_flush_pio_task(ap);\r\nif (!rc) {\r\nspin_lock_irqsave(ap->lock, flags);\r\nif (qc->flags & ATA_QCFLAG_ACTIVE) {\r\nqc->err_mask |= AC_ERR_TIMEOUT;\r\nif (ap->ops->error_handler)\r\nata_port_freeze(ap);\r\nelse\r\nata_qc_complete(qc);\r\nif (ata_msg_warn(ap))\r\nata_dev_warn(dev, "qc timeout (cmd 0x%x)\n",\r\ncommand);\r\n}\r\nspin_unlock_irqrestore(ap->lock, flags);\r\n}\r\nif (ap->ops->post_internal_cmd)\r\nap->ops->post_internal_cmd(qc);\r\nif (qc->flags & ATA_QCFLAG_FAILED) {\r\nif (qc->result_tf.command & (ATA_ERR | ATA_DF))\r\nqc->err_mask |= AC_ERR_DEV;\r\nif (!qc->err_mask)\r\nqc->err_mask |= AC_ERR_OTHER;\r\nif (qc->err_mask & ~AC_ERR_OTHER)\r\nqc->err_mask &= ~AC_ERR_OTHER;\r\n}\r\nspin_lock_irqsave(ap->lock, flags);\r\n*tf = qc->result_tf;\r\nerr_mask = qc->err_mask;\r\nata_qc_free(qc);\r\nlink->active_tag = preempted_tag;\r\nlink->sactive = preempted_sactive;\r\nap->qc_active = preempted_qc_active;\r\nap->nr_active_links = preempted_nr_active_links;\r\nspin_unlock_irqrestore(ap->lock, flags);\r\nif ((err_mask & AC_ERR_TIMEOUT) && auto_timeout)\r\nata_internal_cmd_timed_out(dev, command);\r\nreturn err_mask;\r\n}\r\nunsigned ata_exec_internal(struct ata_device *dev,\r\nstruct ata_taskfile *tf, const u8 *cdb,\r\nint dma_dir, void *buf, unsigned int buflen,\r\nunsigned long timeout)\r\n{\r\nstruct scatterlist *psg = NULL, sg;\r\nunsigned int n_elem = 0;\r\nif (dma_dir != DMA_NONE) {\r\nWARN_ON(!buf);\r\nsg_init_one(&sg, buf, buflen);\r\npsg = &sg;\r\nn_elem++;\r\n}\r\nreturn ata_exec_internal_sg(dev, tf, cdb, dma_dir, psg, n_elem,\r\ntimeout);\r\n}\r\nunsigned int ata_pio_need_iordy(const struct ata_device *adev)\r\n{\r\nif (adev->link->ap->pflags & ATA_PFLAG_RESETTING)\r\nreturn 0;\r\nif (adev->link->ap->flags & ATA_FLAG_NO_IORDY)\r\nreturn 0;\r\nif (ata_id_is_cfa(adev->id)\r\n&& (adev->pio_mode == XFER_PIO_5 || adev->pio_mode == XFER_PIO_6))\r\nreturn 0;\r\nif (adev->pio_mode > XFER_PIO_2)\r\nreturn 1;\r\nif (ata_id_has_iordy(adev->id))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic u32 ata_pio_mask_no_iordy(const struct ata_device *adev)\r\n{\r\nif (adev->id[ATA_ID_FIELD_VALID] & 2) {\r\nu16 pio = adev->id[ATA_ID_EIDE_PIO];\r\nif (pio) {\r\nif (pio > 240)\r\nreturn 3 << ATA_SHIFT_PIO;\r\nreturn 7 << ATA_SHIFT_PIO;\r\n}\r\n}\r\nreturn 3 << ATA_SHIFT_PIO;\r\n}\r\nunsigned int ata_do_dev_read_id(struct ata_device *dev,\r\nstruct ata_taskfile *tf, u16 *id)\r\n{\r\nreturn ata_exec_internal(dev, tf, NULL, DMA_FROM_DEVICE,\r\nid, sizeof(id[0]) * ATA_ID_WORDS, 0);\r\n}\r\nint ata_dev_read_id(struct ata_device *dev, unsigned int *p_class,\r\nunsigned int flags, u16 *id)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nunsigned int class = *p_class;\r\nstruct ata_taskfile tf;\r\nunsigned int err_mask = 0;\r\nconst char *reason;\r\nbool is_semb = class == ATA_DEV_SEMB;\r\nint may_fallback = 1, tried_spinup = 0;\r\nint rc;\r\nif (ata_msg_ctl(ap))\r\nata_dev_dbg(dev, "%s: ENTER\n", __func__);\r\nretry:\r\nata_tf_init(dev, &tf);\r\nswitch (class) {\r\ncase ATA_DEV_SEMB:\r\nclass = ATA_DEV_ATA;\r\ncase ATA_DEV_ATA:\r\ncase ATA_DEV_ZAC:\r\ntf.command = ATA_CMD_ID_ATA;\r\nbreak;\r\ncase ATA_DEV_ATAPI:\r\ntf.command = ATA_CMD_ID_ATAPI;\r\nbreak;\r\ndefault:\r\nrc = -ENODEV;\r\nreason = "unsupported class";\r\ngoto err_out;\r\n}\r\ntf.protocol = ATA_PROT_PIO;\r\ntf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;\r\ntf.flags |= ATA_TFLAG_POLLING;\r\nif (ap->ops->read_id)\r\nerr_mask = ap->ops->read_id(dev, &tf, id);\r\nelse\r\nerr_mask = ata_do_dev_read_id(dev, &tf, id);\r\nif (err_mask) {\r\nif (err_mask & AC_ERR_NODEV_HINT) {\r\nata_dev_dbg(dev, "NODEV after polling detection\n");\r\nreturn -ENOENT;\r\n}\r\nif (is_semb) {\r\nata_dev_info(dev,\r\n"IDENTIFY failed on device w/ SEMB sig, disabled\n");\r\n*p_class = ATA_DEV_SEMB_UNSUP;\r\nreturn 0;\r\n}\r\nif ((err_mask == AC_ERR_DEV) && (tf.feature & ATA_ABORTED)) {\r\nif (may_fallback) {\r\nmay_fallback = 0;\r\nif (class == ATA_DEV_ATA)\r\nclass = ATA_DEV_ATAPI;\r\nelse\r\nclass = ATA_DEV_ATA;\r\ngoto retry;\r\n}\r\nata_dev_dbg(dev,\r\n"both IDENTIFYs aborted, assuming NODEV\n");\r\nreturn -ENOENT;\r\n}\r\nrc = -EIO;\r\nreason = "I/O error";\r\ngoto err_out;\r\n}\r\nif (dev->horkage & ATA_HORKAGE_DUMP_ID) {\r\nata_dev_dbg(dev, "dumping IDENTIFY data, "\r\n"class=%d may_fallback=%d tried_spinup=%d\n",\r\nclass, may_fallback, tried_spinup);\r\nprint_hex_dump(KERN_DEBUG, "", DUMP_PREFIX_OFFSET,\r\n16, 2, id, ATA_ID_WORDS * sizeof(*id), true);\r\n}\r\nmay_fallback = 0;\r\nswap_buf_le16(id, ATA_ID_WORDS);\r\nrc = -EINVAL;\r\nreason = "device reports invalid type";\r\nif (class == ATA_DEV_ATA || class == ATA_DEV_ZAC) {\r\nif (!ata_id_is_ata(id) && !ata_id_is_cfa(id))\r\ngoto err_out;\r\nif (ap->host->flags & ATA_HOST_IGNORE_ATA &&\r\nata_id_is_ata(id)) {\r\nata_dev_dbg(dev,\r\n"host indicates ignore ATA devices, ignored\n");\r\nreturn -ENOENT;\r\n}\r\n} else {\r\nif (ata_id_is_ata(id))\r\ngoto err_out;\r\n}\r\nif (!tried_spinup && (id[2] == 0x37c8 || id[2] == 0x738c)) {\r\ntried_spinup = 1;\r\nerr_mask = ata_dev_set_feature(dev, SETFEATURES_SPINUP, 0);\r\nif (err_mask && id[2] != 0x738c) {\r\nrc = -EIO;\r\nreason = "SPINUP failed";\r\ngoto err_out;\r\n}\r\nif (id[2] == 0x37c8)\r\ngoto retry;\r\n}\r\nif ((flags & ATA_READID_POSTRESET) &&\r\n(class == ATA_DEV_ATA || class == ATA_DEV_ZAC)) {\r\nif (ata_id_major_version(id) < 4 || !ata_id_has_lba(id)) {\r\nerr_mask = ata_dev_init_params(dev, id[3], id[6]);\r\nif (err_mask) {\r\nrc = -EIO;\r\nreason = "INIT_DEV_PARAMS failed";\r\ngoto err_out;\r\n}\r\nflags &= ~ATA_READID_POSTRESET;\r\ngoto retry;\r\n}\r\n}\r\n*p_class = class;\r\nreturn 0;\r\nerr_out:\r\nif (ata_msg_warn(ap))\r\nata_dev_warn(dev, "failed to IDENTIFY (%s, err_mask=0x%x)\n",\r\nreason, err_mask);\r\nreturn rc;\r\n}\r\nstatic int ata_do_link_spd_horkage(struct ata_device *dev)\r\n{\r\nstruct ata_link *plink = ata_dev_phys_link(dev);\r\nu32 target, target_limit;\r\nif (!sata_scr_valid(plink))\r\nreturn 0;\r\nif (dev->horkage & ATA_HORKAGE_1_5_GBPS)\r\ntarget = 1;\r\nelse\r\nreturn 0;\r\ntarget_limit = (1 << target) - 1;\r\nif (plink->sata_spd_limit <= target_limit)\r\nreturn 0;\r\nplink->sata_spd_limit = target_limit;\r\nif (plink->sata_spd > target) {\r\nata_dev_info(dev, "applying link speed limit horkage to %s\n",\r\nsata_spd_string(target));\r\nreturn -EAGAIN;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline u8 ata_dev_knobble(struct ata_device *dev)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nif (ata_dev_blacklisted(dev) & ATA_HORKAGE_BRIDGE_OK)\r\nreturn 0;\r\nreturn ((ap->cbl == ATA_CBL_SATA) && (!ata_id_is_sata(dev->id)));\r\n}\r\nstatic int ata_dev_config_ncq(struct ata_device *dev,\r\nchar *desc, size_t desc_sz)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nint hdepth = 0, ddepth = ata_id_queue_depth(dev->id);\r\nunsigned int err_mask;\r\nchar *aa_desc = "";\r\nif (!ata_id_has_ncq(dev->id)) {\r\ndesc[0] = '\0';\r\nreturn 0;\r\n}\r\nif (dev->horkage & ATA_HORKAGE_NONCQ) {\r\nsnprintf(desc, desc_sz, "NCQ (not used)");\r\nreturn 0;\r\n}\r\nif (ap->flags & ATA_FLAG_NCQ) {\r\nhdepth = min(ap->scsi_host->can_queue, ATA_MAX_QUEUE - 1);\r\ndev->flags |= ATA_DFLAG_NCQ;\r\n}\r\nif (!(dev->horkage & ATA_HORKAGE_BROKEN_FPDMA_AA) &&\r\n(ap->flags & ATA_FLAG_FPDMA_AA) &&\r\nata_id_has_fpdma_aa(dev->id)) {\r\nerr_mask = ata_dev_set_feature(dev, SETFEATURES_SATA_ENABLE,\r\nSATA_FPDMA_AA);\r\nif (err_mask) {\r\nata_dev_err(dev,\r\n"failed to enable AA (error_mask=0x%x)\n",\r\nerr_mask);\r\nif (err_mask != AC_ERR_DEV) {\r\ndev->horkage |= ATA_HORKAGE_BROKEN_FPDMA_AA;\r\nreturn -EIO;\r\n}\r\n} else\r\naa_desc = ", AA";\r\n}\r\nif (hdepth >= ddepth)\r\nsnprintf(desc, desc_sz, "NCQ (depth %d)%s", ddepth, aa_desc);\r\nelse\r\nsnprintf(desc, desc_sz, "NCQ (depth %d/%d)%s", hdepth,\r\nddepth, aa_desc);\r\nif ((ap->flags & ATA_FLAG_FPDMA_AUX) &&\r\nata_id_has_ncq_send_and_recv(dev->id)) {\r\nerr_mask = ata_read_log_page(dev, ATA_LOG_NCQ_SEND_RECV,\r\n0, ap->sector_buf, 1);\r\nif (err_mask) {\r\nata_dev_dbg(dev,\r\n"failed to get NCQ Send/Recv Log Emask 0x%x\n",\r\nerr_mask);\r\n} else {\r\nu8 *cmds = dev->ncq_send_recv_cmds;\r\ndev->flags |= ATA_DFLAG_NCQ_SEND_RECV;\r\nmemcpy(cmds, ap->sector_buf, ATA_LOG_NCQ_SEND_RECV_SIZE);\r\nif (dev->horkage & ATA_HORKAGE_NO_NCQ_TRIM) {\r\nata_dev_dbg(dev, "disabling queued TRIM support\n");\r\ncmds[ATA_LOG_NCQ_SEND_RECV_DSM_OFFSET] &=\r\n~ATA_LOG_NCQ_SEND_RECV_DSM_TRIM;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint ata_dev_configure(struct ata_device *dev)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nstruct ata_eh_context *ehc = &dev->link->eh_context;\r\nint print_info = ehc->i.flags & ATA_EHI_PRINTINFO;\r\nconst u16 *id = dev->id;\r\nunsigned long xfer_mask;\r\nunsigned int err_mask;\r\nchar revbuf[7];\r\nchar fwrevbuf[ATA_ID_FW_REV_LEN+1];\r\nchar modelbuf[ATA_ID_PROD_LEN+1];\r\nint rc;\r\nif (!ata_dev_enabled(dev) && ata_msg_info(ap)) {\r\nata_dev_info(dev, "%s: ENTER/EXIT -- nodev\n", __func__);\r\nreturn 0;\r\n}\r\nif (ata_msg_probe(ap))\r\nata_dev_dbg(dev, "%s: ENTER\n", __func__);\r\ndev->horkage |= ata_dev_blacklisted(dev);\r\nata_force_horkage(dev);\r\nif (dev->horkage & ATA_HORKAGE_DISABLE) {\r\nata_dev_info(dev, "unsupported device, disabling\n");\r\nata_dev_disable(dev);\r\nreturn 0;\r\n}\r\nif ((!atapi_enabled || (ap->flags & ATA_FLAG_NO_ATAPI)) &&\r\ndev->class == ATA_DEV_ATAPI) {\r\nata_dev_warn(dev, "WARNING: ATAPI is %s, device ignored\n",\r\natapi_enabled ? "not supported with this driver"\r\n: "disabled");\r\nata_dev_disable(dev);\r\nreturn 0;\r\n}\r\nrc = ata_do_link_spd_horkage(dev);\r\nif (rc)\r\nreturn rc;\r\nif ((dev->horkage & ATA_HORKAGE_WD_BROKEN_LPM) &&\r\n(id[ATA_ID_SATA_CAPABILITY] & 0xe) == 0x2)\r\ndev->horkage |= ATA_HORKAGE_NOLPM;\r\nif (dev->horkage & ATA_HORKAGE_NOLPM) {\r\nata_dev_warn(dev, "LPM support broken, forcing max_power\n");\r\ndev->link->ap->target_lpm_policy = ATA_LPM_MAX_POWER;\r\n}\r\nrc = ata_acpi_on_devcfg(dev);\r\nif (rc)\r\nreturn rc;\r\nrc = ata_hpa_resize(dev);\r\nif (rc)\r\nreturn rc;\r\nif (ata_msg_probe(ap))\r\nata_dev_dbg(dev,\r\n"%s: cfg 49:%04x 82:%04x 83:%04x 84:%04x "\r\n"85:%04x 86:%04x 87:%04x 88:%04x\n",\r\n__func__,\r\nid[49], id[82], id[83], id[84],\r\nid[85], id[86], id[87], id[88]);\r\ndev->flags &= ~ATA_DFLAG_CFG_MASK;\r\ndev->max_sectors = 0;\r\ndev->cdb_len = 0;\r\ndev->n_sectors = 0;\r\ndev->cylinders = 0;\r\ndev->heads = 0;\r\ndev->sectors = 0;\r\ndev->multi_count = 0;\r\nxfer_mask = ata_id_xfermask(id);\r\nif (ata_msg_probe(ap))\r\nata_dump_id(id);\r\nata_id_c_string(dev->id, fwrevbuf, ATA_ID_FW_REV,\r\nsizeof(fwrevbuf));\r\nata_id_c_string(dev->id, modelbuf, ATA_ID_PROD,\r\nsizeof(modelbuf));\r\nif (dev->class == ATA_DEV_ATA || dev->class == ATA_DEV_ZAC) {\r\nif (ata_id_is_cfa(id)) {\r\nif (id[ATA_ID_CFA_KEY_MGMT] & 1)\r\nata_dev_warn(dev,\r\n"supports DRM functions and may not be fully accessible\n");\r\nsnprintf(revbuf, 7, "CFA");\r\n} else {\r\nsnprintf(revbuf, 7, "ATA-%d", ata_id_major_version(id));\r\nif (ata_id_has_tpm(id))\r\nata_dev_warn(dev,\r\n"supports DRM functions and may not be fully accessible\n");\r\n}\r\ndev->n_sectors = ata_id_n_sectors(id);\r\nif ((dev->id[47] >> 8) == 0x80 && (dev->id[59] & 0x100)) {\r\nunsigned int max = dev->id[47] & 0xff;\r\nunsigned int cnt = dev->id[59] & 0xff;\r\nif (is_power_of_2(max) && is_power_of_2(cnt))\r\nif (cnt <= max)\r\ndev->multi_count = cnt;\r\n}\r\nif (ata_id_has_lba(id)) {\r\nconst char *lba_desc;\r\nchar ncq_desc[24];\r\nlba_desc = "LBA";\r\ndev->flags |= ATA_DFLAG_LBA;\r\nif (ata_id_has_lba48(id)) {\r\ndev->flags |= ATA_DFLAG_LBA48;\r\nlba_desc = "LBA48";\r\nif (dev->n_sectors >= (1UL << 28) &&\r\nata_id_has_flush_ext(id))\r\ndev->flags |= ATA_DFLAG_FLUSH_EXT;\r\n}\r\nrc = ata_dev_config_ncq(dev, ncq_desc, sizeof(ncq_desc));\r\nif (rc)\r\nreturn rc;\r\nif (ata_msg_drv(ap) && print_info) {\r\nata_dev_info(dev, "%s: %s, %s, max %s\n",\r\nrevbuf, modelbuf, fwrevbuf,\r\nata_mode_string(xfer_mask));\r\nata_dev_info(dev,\r\n"%llu sectors, multi %u: %s %s\n",\r\n(unsigned long long)dev->n_sectors,\r\ndev->multi_count, lba_desc, ncq_desc);\r\n}\r\n} else {\r\ndev->cylinders = id[1];\r\ndev->heads = id[3];\r\ndev->sectors = id[6];\r\nif (ata_id_current_chs_valid(id)) {\r\ndev->cylinders = id[54];\r\ndev->heads = id[55];\r\ndev->sectors = id[56];\r\n}\r\nif (ata_msg_drv(ap) && print_info) {\r\nata_dev_info(dev, "%s: %s, %s, max %s\n",\r\nrevbuf, modelbuf, fwrevbuf,\r\nata_mode_string(xfer_mask));\r\nata_dev_info(dev,\r\n"%llu sectors, multi %u, CHS %u/%u/%u\n",\r\n(unsigned long long)dev->n_sectors,\r\ndev->multi_count, dev->cylinders,\r\ndev->heads, dev->sectors);\r\n}\r\n}\r\nif (ata_id_has_devslp(dev->id)) {\r\nu8 *sata_setting = ap->sector_buf;\r\nint i, j;\r\ndev->flags |= ATA_DFLAG_DEVSLP;\r\nerr_mask = ata_read_log_page(dev,\r\nATA_LOG_SATA_ID_DEV_DATA,\r\nATA_LOG_SATA_SETTINGS,\r\nsata_setting,\r\n1);\r\nif (err_mask)\r\nata_dev_dbg(dev,\r\n"failed to get Identify Device Data, Emask 0x%x\n",\r\nerr_mask);\r\nelse\r\nfor (i = 0; i < ATA_LOG_DEVSLP_SIZE; i++) {\r\nj = ATA_LOG_DEVSLP_OFFSET + i;\r\ndev->devslp_timing[i] = sata_setting[j];\r\n}\r\n}\r\ndev->cdb_len = 16;\r\n}\r\nelse if (dev->class == ATA_DEV_ATAPI) {\r\nconst char *cdb_intr_string = "";\r\nconst char *atapi_an_string = "";\r\nconst char *dma_dir_string = "";\r\nu32 sntf;\r\nrc = atapi_cdb_len(id);\r\nif ((rc < 12) || (rc > ATAPI_CDB_LEN)) {\r\nif (ata_msg_warn(ap))\r\nata_dev_warn(dev, "unsupported CDB len\n");\r\nrc = -EINVAL;\r\ngoto err_out_nosup;\r\n}\r\ndev->cdb_len = (unsigned int) rc;\r\nif (atapi_an &&\r\n(ap->flags & ATA_FLAG_AN) && ata_id_has_atapi_AN(id) &&\r\n(!sata_pmp_attached(ap) ||\r\nsata_scr_read(&ap->link, SCR_NOTIFICATION, &sntf) == 0)) {\r\nerr_mask = ata_dev_set_feature(dev,\r\nSETFEATURES_SATA_ENABLE, SATA_AN);\r\nif (err_mask)\r\nata_dev_err(dev,\r\n"failed to enable ATAPI AN (err_mask=0x%x)\n",\r\nerr_mask);\r\nelse {\r\ndev->flags |= ATA_DFLAG_AN;\r\natapi_an_string = ", ATAPI AN";\r\n}\r\n}\r\nif (ata_id_cdb_intr(dev->id)) {\r\ndev->flags |= ATA_DFLAG_CDB_INTR;\r\ncdb_intr_string = ", CDB intr";\r\n}\r\nif (atapi_dmadir || (dev->horkage & ATA_HORKAGE_ATAPI_DMADIR) || atapi_id_dmadir(dev->id)) {\r\ndev->flags |= ATA_DFLAG_DMADIR;\r\ndma_dir_string = ", DMADIR";\r\n}\r\nif (ata_id_has_da(dev->id)) {\r\ndev->flags |= ATA_DFLAG_DA;\r\nzpodd_init(dev);\r\n}\r\nif (ata_msg_drv(ap) && print_info)\r\nata_dev_info(dev,\r\n"ATAPI: %s, %s, max %s%s%s%s\n",\r\nmodelbuf, fwrevbuf,\r\nata_mode_string(xfer_mask),\r\ncdb_intr_string, atapi_an_string,\r\ndma_dir_string);\r\n}\r\ndev->max_sectors = ATA_MAX_SECTORS;\r\nif (dev->flags & ATA_DFLAG_LBA48)\r\ndev->max_sectors = ATA_MAX_SECTORS_LBA48;\r\nif (ata_dev_knobble(dev)) {\r\nif (ata_msg_drv(ap) && print_info)\r\nata_dev_info(dev, "applying bridge limits\n");\r\ndev->udma_mask &= ATA_UDMA5;\r\ndev->max_sectors = ATA_MAX_SECTORS;\r\n}\r\nif ((dev->class == ATA_DEV_ATAPI) &&\r\n(atapi_command_packet_set(id) == TYPE_TAPE)) {\r\ndev->max_sectors = ATA_MAX_SECTORS_TAPE;\r\ndev->horkage |= ATA_HORKAGE_STUCK_ERR;\r\n}\r\nif (dev->horkage & ATA_HORKAGE_MAX_SEC_128)\r\ndev->max_sectors = min_t(unsigned int, ATA_MAX_SECTORS_128,\r\ndev->max_sectors);\r\nif (dev->horkage & ATA_HORKAGE_MAX_SEC_1024)\r\ndev->max_sectors = min_t(unsigned int, ATA_MAX_SECTORS_1024,\r\ndev->max_sectors);\r\nif (dev->horkage & ATA_HORKAGE_MAX_SEC_LBA48)\r\ndev->max_sectors = ATA_MAX_SECTORS_LBA48;\r\nif (ap->ops->dev_config)\r\nap->ops->dev_config(dev);\r\nif (dev->horkage & ATA_HORKAGE_DIAGNOSTIC) {\r\nif (print_info) {\r\nata_dev_warn(dev,\r\n"Drive reports diagnostics failure. This may indicate a drive\n");\r\nata_dev_warn(dev,\r\n"fault or invalid emulation. Contact drive vendor for information.\n");\r\n}\r\n}\r\nif ((dev->horkage & ATA_HORKAGE_FIRMWARE_WARN) && print_info) {\r\nata_dev_warn(dev, "WARNING: device requires firmware update to be fully functional\n");\r\nata_dev_warn(dev, " contact the vendor or visit http://ata.wiki.kernel.org\n");\r\n}\r\nreturn 0;\r\nerr_out_nosup:\r\nif (ata_msg_probe(ap))\r\nata_dev_dbg(dev, "%s: EXIT, err\n", __func__);\r\nreturn rc;\r\n}\r\nint ata_cable_40wire(struct ata_port *ap)\r\n{\r\nreturn ATA_CBL_PATA40;\r\n}\r\nint ata_cable_80wire(struct ata_port *ap)\r\n{\r\nreturn ATA_CBL_PATA80;\r\n}\r\nint ata_cable_unknown(struct ata_port *ap)\r\n{\r\nreturn ATA_CBL_PATA_UNK;\r\n}\r\nint ata_cable_ignore(struct ata_port *ap)\r\n{\r\nreturn ATA_CBL_PATA_IGN;\r\n}\r\nint ata_cable_sata(struct ata_port *ap)\r\n{\r\nreturn ATA_CBL_SATA;\r\n}\r\nint ata_bus_probe(struct ata_port *ap)\r\n{\r\nunsigned int classes[ATA_MAX_DEVICES];\r\nint tries[ATA_MAX_DEVICES];\r\nint rc;\r\nstruct ata_device *dev;\r\nata_for_each_dev(dev, &ap->link, ALL)\r\ntries[dev->devno] = ATA_PROBE_MAX_TRIES;\r\nretry:\r\nata_for_each_dev(dev, &ap->link, ALL) {\r\ndev->pio_mode = XFER_PIO_0;\r\ndev->dma_mode = 0xff;\r\nif (ap->ops->set_piomode)\r\nap->ops->set_piomode(ap, dev);\r\n}\r\nap->ops->phy_reset(ap);\r\nata_for_each_dev(dev, &ap->link, ALL) {\r\nif (dev->class != ATA_DEV_UNKNOWN)\r\nclasses[dev->devno] = dev->class;\r\nelse\r\nclasses[dev->devno] = ATA_DEV_NONE;\r\ndev->class = ATA_DEV_UNKNOWN;\r\n}\r\nata_for_each_dev(dev, &ap->link, ALL_REVERSE) {\r\nif (tries[dev->devno])\r\ndev->class = classes[dev->devno];\r\nif (!ata_dev_enabled(dev))\r\ncontinue;\r\nrc = ata_dev_read_id(dev, &dev->class, ATA_READID_POSTRESET,\r\ndev->id);\r\nif (rc)\r\ngoto fail;\r\n}\r\nif (ap->ops->cable_detect)\r\nap->cbl = ap->ops->cable_detect(ap);\r\nata_for_each_dev(dev, &ap->link, ENABLED)\r\nif (ata_id_is_sata(dev->id))\r\nap->cbl = ATA_CBL_SATA;\r\nata_for_each_dev(dev, &ap->link, ENABLED) {\r\nap->link.eh_context.i.flags |= ATA_EHI_PRINTINFO;\r\nrc = ata_dev_configure(dev);\r\nap->link.eh_context.i.flags &= ~ATA_EHI_PRINTINFO;\r\nif (rc)\r\ngoto fail;\r\n}\r\nrc = ata_set_mode(&ap->link, &dev);\r\nif (rc)\r\ngoto fail;\r\nata_for_each_dev(dev, &ap->link, ENABLED)\r\nreturn 0;\r\nreturn -ENODEV;\r\nfail:\r\ntries[dev->devno]--;\r\nswitch (rc) {\r\ncase -EINVAL:\r\ntries[dev->devno] = 0;\r\nbreak;\r\ncase -ENODEV:\r\ntries[dev->devno] = min(tries[dev->devno], 1);\r\ncase -EIO:\r\nif (tries[dev->devno] == 1) {\r\nsata_down_spd_limit(&ap->link, 0);\r\nata_down_xfermask_limit(dev, ATA_DNXFER_PIO);\r\n}\r\n}\r\nif (!tries[dev->devno])\r\nata_dev_disable(dev);\r\ngoto retry;\r\n}\r\nstatic void sata_print_link_status(struct ata_link *link)\r\n{\r\nu32 sstatus, scontrol, tmp;\r\nif (sata_scr_read(link, SCR_STATUS, &sstatus))\r\nreturn;\r\nsata_scr_read(link, SCR_CONTROL, &scontrol);\r\nif (ata_phys_link_online(link)) {\r\ntmp = (sstatus >> 4) & 0xf;\r\nata_link_info(link, "SATA link up %s (SStatus %X SControl %X)\n",\r\nsata_spd_string(tmp), sstatus, scontrol);\r\n} else {\r\nata_link_info(link, "SATA link down (SStatus %X SControl %X)\n",\r\nsstatus, scontrol);\r\n}\r\n}\r\nstruct ata_device *ata_dev_pair(struct ata_device *adev)\r\n{\r\nstruct ata_link *link = adev->link;\r\nstruct ata_device *pair = &link->device[1 - adev->devno];\r\nif (!ata_dev_enabled(pair))\r\nreturn NULL;\r\nreturn pair;\r\n}\r\nint sata_down_spd_limit(struct ata_link *link, u32 spd_limit)\r\n{\r\nu32 sstatus, spd, mask;\r\nint rc, bit;\r\nif (!sata_scr_valid(link))\r\nreturn -EOPNOTSUPP;\r\nrc = sata_scr_read(link, SCR_STATUS, &sstatus);\r\nif (rc == 0 && ata_sstatus_online(sstatus))\r\nspd = (sstatus >> 4) & 0xf;\r\nelse\r\nspd = link->sata_spd;\r\nmask = link->sata_spd_limit;\r\nif (mask <= 1)\r\nreturn -EINVAL;\r\nbit = fls(mask) - 1;\r\nmask &= ~(1 << bit);\r\nif (spd > 1)\r\nmask &= (1 << (spd - 1)) - 1;\r\nelse\r\nmask &= 1;\r\nif (!mask)\r\nreturn -EINVAL;\r\nif (spd_limit) {\r\nif (mask & ((1 << spd_limit) - 1))\r\nmask &= (1 << spd_limit) - 1;\r\nelse {\r\nbit = ffs(mask) - 1;\r\nmask = 1 << bit;\r\n}\r\n}\r\nlink->sata_spd_limit = mask;\r\nata_link_warn(link, "limiting SATA link speed to %s\n",\r\nsata_spd_string(fls(mask)));\r\nreturn 0;\r\n}\r\nstatic int __sata_set_spd_needed(struct ata_link *link, u32 *scontrol)\r\n{\r\nstruct ata_link *host_link = &link->ap->link;\r\nu32 limit, target, spd;\r\nlimit = link->sata_spd_limit;\r\nif (!ata_is_host_link(link) && host_link->sata_spd)\r\nlimit &= (1 << host_link->sata_spd) - 1;\r\nif (limit == UINT_MAX)\r\ntarget = 0;\r\nelse\r\ntarget = fls(limit);\r\nspd = (*scontrol >> 4) & 0xf;\r\n*scontrol = (*scontrol & ~0xf0) | ((target & 0xf) << 4);\r\nreturn spd != target;\r\n}\r\nstatic int sata_set_spd_needed(struct ata_link *link)\r\n{\r\nu32 scontrol;\r\nif (sata_scr_read(link, SCR_CONTROL, &scontrol))\r\nreturn 1;\r\nreturn __sata_set_spd_needed(link, &scontrol);\r\n}\r\nint sata_set_spd(struct ata_link *link)\r\n{\r\nu32 scontrol;\r\nint rc;\r\nif ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))\r\nreturn rc;\r\nif (!__sata_set_spd_needed(link, &scontrol))\r\nreturn 0;\r\nif ((rc = sata_scr_write(link, SCR_CONTROL, scontrol)))\r\nreturn rc;\r\nreturn 1;\r\n}\r\nstatic void ata_timing_quantize(const struct ata_timing *t, struct ata_timing *q, int T, int UT)\r\n{\r\nq->setup = EZ(t->setup * 1000, T);\r\nq->act8b = EZ(t->act8b * 1000, T);\r\nq->rec8b = EZ(t->rec8b * 1000, T);\r\nq->cyc8b = EZ(t->cyc8b * 1000, T);\r\nq->active = EZ(t->active * 1000, T);\r\nq->recover = EZ(t->recover * 1000, T);\r\nq->dmack_hold = EZ(t->dmack_hold * 1000, T);\r\nq->cycle = EZ(t->cycle * 1000, T);\r\nq->udma = EZ(t->udma * 1000, UT);\r\n}\r\nvoid ata_timing_merge(const struct ata_timing *a, const struct ata_timing *b,\r\nstruct ata_timing *m, unsigned int what)\r\n{\r\nif (what & ATA_TIMING_SETUP ) m->setup = max(a->setup, b->setup);\r\nif (what & ATA_TIMING_ACT8B ) m->act8b = max(a->act8b, b->act8b);\r\nif (what & ATA_TIMING_REC8B ) m->rec8b = max(a->rec8b, b->rec8b);\r\nif (what & ATA_TIMING_CYC8B ) m->cyc8b = max(a->cyc8b, b->cyc8b);\r\nif (what & ATA_TIMING_ACTIVE ) m->active = max(a->active, b->active);\r\nif (what & ATA_TIMING_RECOVER) m->recover = max(a->recover, b->recover);\r\nif (what & ATA_TIMING_DMACK_HOLD) m->dmack_hold = max(a->dmack_hold, b->dmack_hold);\r\nif (what & ATA_TIMING_CYCLE ) m->cycle = max(a->cycle, b->cycle);\r\nif (what & ATA_TIMING_UDMA ) m->udma = max(a->udma, b->udma);\r\n}\r\nconst struct ata_timing *ata_timing_find_mode(u8 xfer_mode)\r\n{\r\nconst struct ata_timing *t = ata_timing;\r\nwhile (xfer_mode > t->mode)\r\nt++;\r\nif (xfer_mode == t->mode)\r\nreturn t;\r\nWARN_ONCE(true, "%s: unable to find timing for xfer_mode 0x%x\n",\r\n__func__, xfer_mode);\r\nreturn NULL;\r\n}\r\nint ata_timing_compute(struct ata_device *adev, unsigned short speed,\r\nstruct ata_timing *t, int T, int UT)\r\n{\r\nconst u16 *id = adev->id;\r\nconst struct ata_timing *s;\r\nstruct ata_timing p;\r\nif (!(s = ata_timing_find_mode(speed)))\r\nreturn -EINVAL;\r\nmemcpy(t, s, sizeof(*s));\r\nif (id[ATA_ID_FIELD_VALID] & 2) {\r\nmemset(&p, 0, sizeof(p));\r\nif (speed >= XFER_PIO_0 && speed < XFER_SW_DMA_0) {\r\nif (speed <= XFER_PIO_2)\r\np.cycle = p.cyc8b = id[ATA_ID_EIDE_PIO];\r\nelse if ((speed <= XFER_PIO_4) ||\r\n(speed == XFER_PIO_5 && !ata_id_is_cfa(id)))\r\np.cycle = p.cyc8b = id[ATA_ID_EIDE_PIO_IORDY];\r\n} else if (speed >= XFER_MW_DMA_0 && speed <= XFER_MW_DMA_2)\r\np.cycle = id[ATA_ID_EIDE_DMA_MIN];\r\nata_timing_merge(&p, t, t, ATA_TIMING_CYCLE | ATA_TIMING_CYC8B);\r\n}\r\nata_timing_quantize(t, t, T, UT);\r\nif (speed > XFER_PIO_6) {\r\nata_timing_compute(adev, adev->pio_mode, &p, T, UT);\r\nata_timing_merge(&p, t, t, ATA_TIMING_ALL);\r\n}\r\nif (t->act8b + t->rec8b < t->cyc8b) {\r\nt->act8b += (t->cyc8b - (t->act8b + t->rec8b)) / 2;\r\nt->rec8b = t->cyc8b - t->act8b;\r\n}\r\nif (t->active + t->recover < t->cycle) {\r\nt->active += (t->cycle - (t->active + t->recover)) / 2;\r\nt->recover = t->cycle - t->active;\r\n}\r\nif (t->active + t->recover > t->cycle)\r\nt->cycle = t->active + t->recover;\r\nreturn 0;\r\n}\r\nu8 ata_timing_cycle2mode(unsigned int xfer_shift, int cycle)\r\n{\r\nu8 base_mode = 0xff, last_mode = 0xff;\r\nconst struct ata_xfer_ent *ent;\r\nconst struct ata_timing *t;\r\nfor (ent = ata_xfer_tbl; ent->shift >= 0; ent++)\r\nif (ent->shift == xfer_shift)\r\nbase_mode = ent->base;\r\nfor (t = ata_timing_find_mode(base_mode);\r\nt && ata_xfer_mode2shift(t->mode) == xfer_shift; t++) {\r\nunsigned short this_cycle;\r\nswitch (xfer_shift) {\r\ncase ATA_SHIFT_PIO:\r\ncase ATA_SHIFT_MWDMA:\r\nthis_cycle = t->cycle;\r\nbreak;\r\ncase ATA_SHIFT_UDMA:\r\nthis_cycle = t->udma;\r\nbreak;\r\ndefault:\r\nreturn 0xff;\r\n}\r\nif (cycle > this_cycle)\r\nbreak;\r\nlast_mode = t->mode;\r\n}\r\nreturn last_mode;\r\n}\r\nint ata_down_xfermask_limit(struct ata_device *dev, unsigned int sel)\r\n{\r\nchar buf[32];\r\nunsigned long orig_mask, xfer_mask;\r\nunsigned long pio_mask, mwdma_mask, udma_mask;\r\nint quiet, highbit;\r\nquiet = !!(sel & ATA_DNXFER_QUIET);\r\nsel &= ~ATA_DNXFER_QUIET;\r\nxfer_mask = orig_mask = ata_pack_xfermask(dev->pio_mask,\r\ndev->mwdma_mask,\r\ndev->udma_mask);\r\nata_unpack_xfermask(xfer_mask, &pio_mask, &mwdma_mask, &udma_mask);\r\nswitch (sel) {\r\ncase ATA_DNXFER_PIO:\r\nhighbit = fls(pio_mask) - 1;\r\npio_mask &= ~(1 << highbit);\r\nbreak;\r\ncase ATA_DNXFER_DMA:\r\nif (udma_mask) {\r\nhighbit = fls(udma_mask) - 1;\r\nudma_mask &= ~(1 << highbit);\r\nif (!udma_mask)\r\nreturn -ENOENT;\r\n} else if (mwdma_mask) {\r\nhighbit = fls(mwdma_mask) - 1;\r\nmwdma_mask &= ~(1 << highbit);\r\nif (!mwdma_mask)\r\nreturn -ENOENT;\r\n}\r\nbreak;\r\ncase ATA_DNXFER_40C:\r\nudma_mask &= ATA_UDMA_MASK_40C;\r\nbreak;\r\ncase ATA_DNXFER_FORCE_PIO0:\r\npio_mask &= 1;\r\ncase ATA_DNXFER_FORCE_PIO:\r\nmwdma_mask = 0;\r\nudma_mask = 0;\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nxfer_mask &= ata_pack_xfermask(pio_mask, mwdma_mask, udma_mask);\r\nif (!(xfer_mask & ATA_MASK_PIO) || xfer_mask == orig_mask)\r\nreturn -ENOENT;\r\nif (!quiet) {\r\nif (xfer_mask & (ATA_MASK_MWDMA | ATA_MASK_UDMA))\r\nsnprintf(buf, sizeof(buf), "%s:%s",\r\nata_mode_string(xfer_mask),\r\nata_mode_string(xfer_mask & ATA_MASK_PIO));\r\nelse\r\nsnprintf(buf, sizeof(buf), "%s",\r\nata_mode_string(xfer_mask));\r\nata_dev_warn(dev, "limiting speed to %s\n", buf);\r\n}\r\nata_unpack_xfermask(xfer_mask, &dev->pio_mask, &dev->mwdma_mask,\r\n&dev->udma_mask);\r\nreturn 0;\r\n}\r\nstatic int ata_dev_set_mode(struct ata_device *dev)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nstruct ata_eh_context *ehc = &dev->link->eh_context;\r\nconst bool nosetxfer = dev->horkage & ATA_HORKAGE_NOSETXFER;\r\nconst char *dev_err_whine = "";\r\nint ign_dev_err = 0;\r\nunsigned int err_mask = 0;\r\nint rc;\r\ndev->flags &= ~ATA_DFLAG_PIO;\r\nif (dev->xfer_shift == ATA_SHIFT_PIO)\r\ndev->flags |= ATA_DFLAG_PIO;\r\nif (nosetxfer && ap->flags & ATA_FLAG_SATA && ata_id_is_sata(dev->id))\r\ndev_err_whine = " (SET_XFERMODE skipped)";\r\nelse {\r\nif (nosetxfer)\r\nata_dev_warn(dev,\r\n"NOSETXFER but PATA detected - can't "\r\n"skip SETXFER, might malfunction\n");\r\nerr_mask = ata_dev_set_xfermode(dev);\r\n}\r\nif (err_mask & ~AC_ERR_DEV)\r\ngoto fail;\r\nehc->i.flags |= ATA_EHI_POST_SETMODE;\r\nrc = ata_dev_revalidate(dev, ATA_DEV_UNKNOWN, 0);\r\nehc->i.flags &= ~ATA_EHI_POST_SETMODE;\r\nif (rc)\r\nreturn rc;\r\nif (dev->xfer_shift == ATA_SHIFT_PIO) {\r\nif (ata_id_is_cfa(dev->id))\r\nign_dev_err = 1;\r\nif (ata_id_major_version(dev->id) == 0 &&\r\ndev->pio_mode <= XFER_PIO_2)\r\nign_dev_err = 1;\r\nif (!ata_id_has_iordy(dev->id) && dev->pio_mode <= XFER_PIO_2)\r\nign_dev_err = 1;\r\n}\r\nif (dev->xfer_shift == ATA_SHIFT_MWDMA &&\r\ndev->dma_mode == XFER_MW_DMA_0 &&\r\n(dev->id[63] >> 8) & 1)\r\nign_dev_err = 1;\r\nif (dev->xfer_mode == ata_xfer_mask2mode(ata_id_xfermask(dev->id)))\r\nign_dev_err = 1;\r\nif (err_mask & AC_ERR_DEV) {\r\nif (!ign_dev_err)\r\ngoto fail;\r\nelse\r\ndev_err_whine = " (device error ignored)";\r\n}\r\nDPRINTK("xfer_shift=%u, xfer_mode=0x%x\n",\r\ndev->xfer_shift, (int)dev->xfer_mode);\r\nata_dev_info(dev, "configured for %s%s\n",\r\nata_mode_string(ata_xfer_mode2mask(dev->xfer_mode)),\r\ndev_err_whine);\r\nreturn 0;\r\nfail:\r\nata_dev_err(dev, "failed to set xfermode (err_mask=0x%x)\n", err_mask);\r\nreturn -EIO;\r\n}\r\nint ata_do_set_mode(struct ata_link *link, struct ata_device **r_failed_dev)\r\n{\r\nstruct ata_port *ap = link->ap;\r\nstruct ata_device *dev;\r\nint rc = 0, used_dma = 0, found = 0;\r\nata_for_each_dev(dev, link, ENABLED) {\r\nunsigned long pio_mask, dma_mask;\r\nunsigned int mode_mask;\r\nmode_mask = ATA_DMA_MASK_ATA;\r\nif (dev->class == ATA_DEV_ATAPI)\r\nmode_mask = ATA_DMA_MASK_ATAPI;\r\nelse if (ata_id_is_cfa(dev->id))\r\nmode_mask = ATA_DMA_MASK_CFA;\r\nata_dev_xfermask(dev);\r\nata_force_xfermask(dev);\r\npio_mask = ata_pack_xfermask(dev->pio_mask, 0, 0);\r\nif (libata_dma_mask & mode_mask)\r\ndma_mask = ata_pack_xfermask(0, dev->mwdma_mask,\r\ndev->udma_mask);\r\nelse\r\ndma_mask = 0;\r\ndev->pio_mode = ata_xfer_mask2mode(pio_mask);\r\ndev->dma_mode = ata_xfer_mask2mode(dma_mask);\r\nfound = 1;\r\nif (ata_dma_enabled(dev))\r\nused_dma = 1;\r\n}\r\nif (!found)\r\ngoto out;\r\nata_for_each_dev(dev, link, ENABLED) {\r\nif (dev->pio_mode == 0xff) {\r\nata_dev_warn(dev, "no PIO support\n");\r\nrc = -EINVAL;\r\ngoto out;\r\n}\r\ndev->xfer_mode = dev->pio_mode;\r\ndev->xfer_shift = ATA_SHIFT_PIO;\r\nif (ap->ops->set_piomode)\r\nap->ops->set_piomode(ap, dev);\r\n}\r\nata_for_each_dev(dev, link, ENABLED) {\r\nif (!ata_dma_enabled(dev))\r\ncontinue;\r\ndev->xfer_mode = dev->dma_mode;\r\ndev->xfer_shift = ata_xfer_mode2shift(dev->dma_mode);\r\nif (ap->ops->set_dmamode)\r\nap->ops->set_dmamode(ap, dev);\r\n}\r\nata_for_each_dev(dev, link, ENABLED) {\r\nrc = ata_dev_set_mode(dev);\r\nif (rc)\r\ngoto out;\r\n}\r\nif (used_dma && (ap->host->flags & ATA_HOST_SIMPLEX))\r\nap->host->simplex_claimed = ap;\r\nout:\r\nif (rc)\r\n*r_failed_dev = dev;\r\nreturn rc;\r\n}\r\nint ata_wait_ready(struct ata_link *link, unsigned long deadline,\r\nint (*check_ready)(struct ata_link *link))\r\n{\r\nunsigned long start = jiffies;\r\nunsigned long nodev_deadline;\r\nint warned = 0;\r\nif (link->ap->host->flags & ATA_HOST_PARALLEL_SCAN)\r\nnodev_deadline = ata_deadline(start, ATA_TMOUT_FF_WAIT_LONG);\r\nelse\r\nnodev_deadline = ata_deadline(start, ATA_TMOUT_FF_WAIT);\r\nWARN_ON(link == link->ap->slave_link);\r\nif (time_after(nodev_deadline, deadline))\r\nnodev_deadline = deadline;\r\nwhile (1) {\r\nunsigned long now = jiffies;\r\nint ready, tmp;\r\nready = tmp = check_ready(link);\r\nif (ready > 0)\r\nreturn 0;\r\nif (ready == -ENODEV) {\r\nif (ata_link_online(link))\r\nready = 0;\r\nelse if ((link->ap->flags & ATA_FLAG_SATA) &&\r\n!ata_link_offline(link) &&\r\ntime_before(now, nodev_deadline))\r\nready = 0;\r\n}\r\nif (ready)\r\nreturn ready;\r\nif (time_after(now, deadline))\r\nreturn -EBUSY;\r\nif (!warned && time_after(now, start + 5 * HZ) &&\r\n(deadline - now > 3 * HZ)) {\r\nata_link_warn(link,\r\n"link is slow to respond, please be patient "\r\n"(ready=%d)\n", tmp);\r\nwarned = 1;\r\n}\r\nata_msleep(link->ap, 50);\r\n}\r\n}\r\nint ata_wait_after_reset(struct ata_link *link, unsigned long deadline,\r\nint (*check_ready)(struct ata_link *link))\r\n{\r\nata_msleep(link->ap, ATA_WAIT_AFTER_RESET);\r\nreturn ata_wait_ready(link, deadline, check_ready);\r\n}\r\nint sata_link_debounce(struct ata_link *link, const unsigned long *params,\r\nunsigned long deadline)\r\n{\r\nunsigned long interval = params[0];\r\nunsigned long duration = params[1];\r\nunsigned long last_jiffies, t;\r\nu32 last, cur;\r\nint rc;\r\nt = ata_deadline(jiffies, params[2]);\r\nif (time_before(t, deadline))\r\ndeadline = t;\r\nif ((rc = sata_scr_read(link, SCR_STATUS, &cur)))\r\nreturn rc;\r\ncur &= 0xf;\r\nlast = cur;\r\nlast_jiffies = jiffies;\r\nwhile (1) {\r\nata_msleep(link->ap, interval);\r\nif ((rc = sata_scr_read(link, SCR_STATUS, &cur)))\r\nreturn rc;\r\ncur &= 0xf;\r\nif (cur == last) {\r\nif (cur == 1 && time_before(jiffies, deadline))\r\ncontinue;\r\nif (time_after(jiffies,\r\nata_deadline(last_jiffies, duration)))\r\nreturn 0;\r\ncontinue;\r\n}\r\nlast = cur;\r\nlast_jiffies = jiffies;\r\nif (time_after(jiffies, deadline))\r\nreturn -EPIPE;\r\n}\r\n}\r\nint sata_link_resume(struct ata_link *link, const unsigned long *params,\r\nunsigned long deadline)\r\n{\r\nint tries = ATA_LINK_RESUME_TRIES;\r\nu32 scontrol, serror;\r\nint rc;\r\nif ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))\r\nreturn rc;\r\ndo {\r\nscontrol = (scontrol & 0x0f0) | 0x300;\r\nif ((rc = sata_scr_write(link, SCR_CONTROL, scontrol)))\r\nreturn rc;\r\nif (!(link->flags & ATA_LFLAG_NO_DB_DELAY))\r\nata_msleep(link->ap, 200);\r\nif ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))\r\nreturn rc;\r\n} while ((scontrol & 0xf0f) != 0x300 && --tries);\r\nif ((scontrol & 0xf0f) != 0x300) {\r\nata_link_warn(link, "failed to resume link (SControl %X)\n",\r\nscontrol);\r\nreturn 0;\r\n}\r\nif (tries < ATA_LINK_RESUME_TRIES)\r\nata_link_warn(link, "link resume succeeded after %d retries\n",\r\nATA_LINK_RESUME_TRIES - tries);\r\nif ((rc = sata_link_debounce(link, params, deadline)))\r\nreturn rc;\r\nif (!(rc = sata_scr_read(link, SCR_ERROR, &serror)))\r\nrc = sata_scr_write(link, SCR_ERROR, serror);\r\nreturn rc != -EINVAL ? rc : 0;\r\n}\r\nint sata_link_scr_lpm(struct ata_link *link, enum ata_lpm_policy policy,\r\nbool spm_wakeup)\r\n{\r\nstruct ata_eh_context *ehc = &link->eh_context;\r\nbool woken_up = false;\r\nu32 scontrol;\r\nint rc;\r\nrc = sata_scr_read(link, SCR_CONTROL, &scontrol);\r\nif (rc)\r\nreturn rc;\r\nswitch (policy) {\r\ncase ATA_LPM_MAX_POWER:\r\nscontrol |= (0x7 << 8);\r\nif (spm_wakeup) {\r\nscontrol |= (0x4 << 12);\r\nwoken_up = true;\r\n}\r\nbreak;\r\ncase ATA_LPM_MED_POWER:\r\nscontrol &= ~(0x1 << 8);\r\nscontrol |= (0x6 << 8);\r\nbreak;\r\ncase ATA_LPM_MIN_POWER:\r\nif (ata_link_nr_enabled(link) > 0)\r\nscontrol &= ~(0x7 << 8);\r\nelse {\r\nscontrol &= ~0xf;\r\nscontrol |= (0x1 << 2);\r\n}\r\nbreak;\r\ndefault:\r\nWARN_ON(1);\r\n}\r\nrc = sata_scr_write(link, SCR_CONTROL, scontrol);\r\nif (rc)\r\nreturn rc;\r\nif (woken_up)\r\nmsleep(10);\r\nehc->i.serror &= ~SERR_PHYRDY_CHG;\r\nreturn sata_scr_write(link, SCR_ERROR, SERR_PHYRDY_CHG);\r\n}\r\nint ata_std_prereset(struct ata_link *link, unsigned long deadline)\r\n{\r\nstruct ata_port *ap = link->ap;\r\nstruct ata_eh_context *ehc = &link->eh_context;\r\nconst unsigned long *timing = sata_ehc_deb_timing(ehc);\r\nint rc;\r\nif (ehc->i.action & ATA_EH_HARDRESET)\r\nreturn 0;\r\nif (ap->flags & ATA_FLAG_SATA) {\r\nrc = sata_link_resume(link, timing, deadline);\r\nif (rc && rc != -EOPNOTSUPP)\r\nata_link_warn(link,\r\n"failed to resume link for reset (errno=%d)\n",\r\nrc);\r\n}\r\nif (ata_phys_link_offline(link))\r\nehc->i.action &= ~ATA_EH_SOFTRESET;\r\nreturn 0;\r\n}\r\nint sata_link_hardreset(struct ata_link *link, const unsigned long *timing,\r\nunsigned long deadline,\r\nbool *online, int (*check_ready)(struct ata_link *))\r\n{\r\nu32 scontrol;\r\nint rc;\r\nDPRINTK("ENTER\n");\r\nif (online)\r\n*online = false;\r\nif (sata_set_spd_needed(link)) {\r\nif ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))\r\ngoto out;\r\nscontrol = (scontrol & 0x0f0) | 0x304;\r\nif ((rc = sata_scr_write(link, SCR_CONTROL, scontrol)))\r\ngoto out;\r\nsata_set_spd(link);\r\n}\r\nif ((rc = sata_scr_read(link, SCR_CONTROL, &scontrol)))\r\ngoto out;\r\nscontrol = (scontrol & 0x0f0) | 0x301;\r\nif ((rc = sata_scr_write_flush(link, SCR_CONTROL, scontrol)))\r\ngoto out;\r\nata_msleep(link->ap, 1);\r\nrc = sata_link_resume(link, timing, deadline);\r\nif (rc)\r\ngoto out;\r\nif (ata_phys_link_offline(link))\r\ngoto out;\r\nif (online)\r\n*online = true;\r\nif (sata_pmp_supported(link->ap) && ata_is_host_link(link)) {\r\nif (check_ready) {\r\nunsigned long pmp_deadline;\r\npmp_deadline = ata_deadline(jiffies,\r\nATA_TMOUT_PMP_SRST_WAIT);\r\nif (time_after(pmp_deadline, deadline))\r\npmp_deadline = deadline;\r\nata_wait_ready(link, pmp_deadline, check_ready);\r\n}\r\nrc = -EAGAIN;\r\ngoto out;\r\n}\r\nrc = 0;\r\nif (check_ready)\r\nrc = ata_wait_ready(link, deadline, check_ready);\r\nout:\r\nif (rc && rc != -EAGAIN) {\r\nif (online)\r\n*online = false;\r\nata_link_err(link, "COMRESET failed (errno=%d)\n", rc);\r\n}\r\nDPRINTK("EXIT, rc=%d\n", rc);\r\nreturn rc;\r\n}\r\nint sata_std_hardreset(struct ata_link *link, unsigned int *class,\r\nunsigned long deadline)\r\n{\r\nconst unsigned long *timing = sata_ehc_deb_timing(&link->eh_context);\r\nbool online;\r\nint rc;\r\nrc = sata_link_hardreset(link, timing, deadline, &online, NULL);\r\nreturn online ? -EAGAIN : rc;\r\n}\r\nvoid ata_std_postreset(struct ata_link *link, unsigned int *classes)\r\n{\r\nu32 serror;\r\nDPRINTK("ENTER\n");\r\nif (!sata_scr_read(link, SCR_ERROR, &serror))\r\nsata_scr_write(link, SCR_ERROR, serror);\r\nsata_print_link_status(link);\r\nDPRINTK("EXIT\n");\r\n}\r\nstatic int ata_dev_same_device(struct ata_device *dev, unsigned int new_class,\r\nconst u16 *new_id)\r\n{\r\nconst u16 *old_id = dev->id;\r\nunsigned char model[2][ATA_ID_PROD_LEN + 1];\r\nunsigned char serial[2][ATA_ID_SERNO_LEN + 1];\r\nif (dev->class != new_class) {\r\nata_dev_info(dev, "class mismatch %d != %d\n",\r\ndev->class, new_class);\r\nreturn 0;\r\n}\r\nata_id_c_string(old_id, model[0], ATA_ID_PROD, sizeof(model[0]));\r\nata_id_c_string(new_id, model[1], ATA_ID_PROD, sizeof(model[1]));\r\nata_id_c_string(old_id, serial[0], ATA_ID_SERNO, sizeof(serial[0]));\r\nata_id_c_string(new_id, serial[1], ATA_ID_SERNO, sizeof(serial[1]));\r\nif (strcmp(model[0], model[1])) {\r\nata_dev_info(dev, "model number mismatch '%s' != '%s'\n",\r\nmodel[0], model[1]);\r\nreturn 0;\r\n}\r\nif (strcmp(serial[0], serial[1])) {\r\nata_dev_info(dev, "serial number mismatch '%s' != '%s'\n",\r\nserial[0], serial[1]);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nint ata_dev_reread_id(struct ata_device *dev, unsigned int readid_flags)\r\n{\r\nunsigned int class = dev->class;\r\nu16 *id = (void *)dev->link->ap->sector_buf;\r\nint rc;\r\nrc = ata_dev_read_id(dev, &class, readid_flags, id);\r\nif (rc)\r\nreturn rc;\r\nif (!ata_dev_same_device(dev, class, id))\r\nreturn -ENODEV;\r\nmemcpy(dev->id, id, sizeof(id[0]) * ATA_ID_WORDS);\r\nreturn 0;\r\n}\r\nint ata_dev_revalidate(struct ata_device *dev, unsigned int new_class,\r\nunsigned int readid_flags)\r\n{\r\nu64 n_sectors = dev->n_sectors;\r\nu64 n_native_sectors = dev->n_native_sectors;\r\nint rc;\r\nif (!ata_dev_enabled(dev))\r\nreturn -ENODEV;\r\nif (ata_class_enabled(new_class) &&\r\nnew_class != ATA_DEV_ATA &&\r\nnew_class != ATA_DEV_ATAPI &&\r\nnew_class != ATA_DEV_ZAC &&\r\nnew_class != ATA_DEV_SEMB) {\r\nata_dev_info(dev, "class mismatch %u != %u\n",\r\ndev->class, new_class);\r\nrc = -ENODEV;\r\ngoto fail;\r\n}\r\nrc = ata_dev_reread_id(dev, readid_flags);\r\nif (rc)\r\ngoto fail;\r\nrc = ata_dev_configure(dev);\r\nif (rc)\r\ngoto fail;\r\nif (dev->class != ATA_DEV_ATA || !n_sectors ||\r\ndev->n_sectors == n_sectors)\r\nreturn 0;\r\nata_dev_warn(dev, "n_sectors mismatch %llu != %llu\n",\r\n(unsigned long long)n_sectors,\r\n(unsigned long long)dev->n_sectors);\r\nif (dev->n_native_sectors == n_native_sectors &&\r\ndev->n_sectors > n_sectors && dev->n_sectors == n_native_sectors) {\r\nata_dev_warn(dev,\r\n"new n_sectors matches native, probably "\r\n"late HPA unlock, n_sectors updated\n");\r\nreturn 0;\r\n}\r\nif (dev->n_native_sectors == n_native_sectors &&\r\ndev->n_sectors < n_sectors && n_sectors == n_native_sectors &&\r\n!(dev->horkage & ATA_HORKAGE_BROKEN_HPA)) {\r\nata_dev_warn(dev,\r\n"old n_sectors matches native, probably "\r\n"late HPA lock, will try to unlock HPA\n");\r\ndev->flags |= ATA_DFLAG_UNLOCK_HPA;\r\nrc = -EIO;\r\n} else\r\nrc = -ENODEV;\r\ndev->n_native_sectors = n_native_sectors;\r\ndev->n_sectors = n_sectors;\r\nfail:\r\nata_dev_err(dev, "revalidation failed (errno=%d)\n", rc);\r\nreturn rc;\r\n}\r\nstatic unsigned long ata_dev_blacklisted(const struct ata_device *dev)\r\n{\r\nunsigned char model_num[ATA_ID_PROD_LEN + 1];\r\nunsigned char model_rev[ATA_ID_FW_REV_LEN + 1];\r\nconst struct ata_blacklist_entry *ad = ata_device_blacklist;\r\nata_id_c_string(dev->id, model_num, ATA_ID_PROD, sizeof(model_num));\r\nata_id_c_string(dev->id, model_rev, ATA_ID_FW_REV, sizeof(model_rev));\r\nwhile (ad->model_num) {\r\nif (glob_match(ad->model_num, model_num)) {\r\nif (ad->model_rev == NULL)\r\nreturn ad->horkage;\r\nif (glob_match(ad->model_rev, model_rev))\r\nreturn ad->horkage;\r\n}\r\nad++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ata_dma_blacklisted(const struct ata_device *dev)\r\n{\r\nif ((dev->link->ap->flags & ATA_FLAG_PIO_POLLING) &&\r\n(dev->flags & ATA_DFLAG_CDB_INTR))\r\nreturn 1;\r\nreturn (dev->horkage & ATA_HORKAGE_NODMA) ? 1 : 0;\r\n}\r\nstatic int ata_is_40wire(struct ata_device *dev)\r\n{\r\nif (dev->horkage & ATA_HORKAGE_IVB)\r\nreturn ata_drive_40wire_relaxed(dev->id);\r\nreturn ata_drive_40wire(dev->id);\r\n}\r\nstatic int cable_is_40wire(struct ata_port *ap)\r\n{\r\nstruct ata_link *link;\r\nstruct ata_device *dev;\r\nif (ap->cbl == ATA_CBL_PATA40)\r\nreturn 1;\r\nif (ap->cbl == ATA_CBL_PATA80 || ap->cbl == ATA_CBL_SATA)\r\nreturn 0;\r\nif (ap->cbl == ATA_CBL_PATA40_SHORT)\r\nreturn 0;\r\nata_for_each_link(link, ap, EDGE) {\r\nata_for_each_dev(dev, link, ENABLED) {\r\nif (!ata_is_40wire(dev))\r\nreturn 0;\r\n}\r\n}\r\nreturn 1;\r\n}\r\nstatic void ata_dev_xfermask(struct ata_device *dev)\r\n{\r\nstruct ata_link *link = dev->link;\r\nstruct ata_port *ap = link->ap;\r\nstruct ata_host *host = ap->host;\r\nunsigned long xfer_mask;\r\nxfer_mask = ata_pack_xfermask(ap->pio_mask,\r\nap->mwdma_mask, ap->udma_mask);\r\nxfer_mask &= ata_pack_xfermask(dev->pio_mask,\r\ndev->mwdma_mask, dev->udma_mask);\r\nxfer_mask &= ata_id_xfermask(dev->id);\r\nif (ata_dev_pair(dev)) {\r\nxfer_mask &= ~(0x03 << (ATA_SHIFT_PIO + 5));\r\nxfer_mask &= ~(0x03 << (ATA_SHIFT_MWDMA + 3));\r\n}\r\nif (ata_dma_blacklisted(dev)) {\r\nxfer_mask &= ~(ATA_MASK_MWDMA | ATA_MASK_UDMA);\r\nata_dev_warn(dev,\r\n"device is on DMA blacklist, disabling DMA\n");\r\n}\r\nif ((host->flags & ATA_HOST_SIMPLEX) &&\r\nhost->simplex_claimed && host->simplex_claimed != ap) {\r\nxfer_mask &= ~(ATA_MASK_MWDMA | ATA_MASK_UDMA);\r\nata_dev_warn(dev,\r\n"simplex DMA is claimed by other device, disabling DMA\n");\r\n}\r\nif (ap->flags & ATA_FLAG_NO_IORDY)\r\nxfer_mask &= ata_pio_mask_no_iordy(dev);\r\nif (ap->ops->mode_filter)\r\nxfer_mask = ap->ops->mode_filter(dev, xfer_mask);\r\nif (xfer_mask & (0xF8 << ATA_SHIFT_UDMA))\r\nif (cable_is_40wire(ap)) {\r\nata_dev_warn(dev,\r\n"limited to UDMA/33 due to 40-wire cable\n");\r\nxfer_mask &= ~(0xF8 << ATA_SHIFT_UDMA);\r\n}\r\nata_unpack_xfermask(xfer_mask, &dev->pio_mask,\r\n&dev->mwdma_mask, &dev->udma_mask);\r\n}\r\nstatic unsigned int ata_dev_set_xfermode(struct ata_device *dev)\r\n{\r\nstruct ata_taskfile tf;\r\nunsigned int err_mask;\r\nDPRINTK("set features - xfer mode\n");\r\nata_tf_init(dev, &tf);\r\ntf.command = ATA_CMD_SET_FEATURES;\r\ntf.feature = SETFEATURES_XFER;\r\ntf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE | ATA_TFLAG_POLLING;\r\ntf.protocol = ATA_PROT_NODATA;\r\nif (ata_pio_need_iordy(dev))\r\ntf.nsect = dev->xfer_mode;\r\nelse if (ata_id_has_iordy(dev->id))\r\ntf.nsect = 0x01;\r\nelse\r\nreturn 0;\r\nerr_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 15000);\r\nDPRINTK("EXIT, err_mask=%x\n", err_mask);\r\nreturn err_mask;\r\n}\r\nunsigned int ata_dev_set_feature(struct ata_device *dev, u8 enable, u8 feature)\r\n{\r\nstruct ata_taskfile tf;\r\nunsigned int err_mask;\r\nDPRINTK("set features - SATA features\n");\r\nata_tf_init(dev, &tf);\r\ntf.command = ATA_CMD_SET_FEATURES;\r\ntf.feature = enable;\r\ntf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;\r\ntf.protocol = ATA_PROT_NODATA;\r\ntf.nsect = feature;\r\nerr_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);\r\nDPRINTK("EXIT, err_mask=%x\n", err_mask);\r\nreturn err_mask;\r\n}\r\nstatic unsigned int ata_dev_init_params(struct ata_device *dev,\r\nu16 heads, u16 sectors)\r\n{\r\nstruct ata_taskfile tf;\r\nunsigned int err_mask;\r\nif (sectors < 1 || sectors > 255 || heads < 1 || heads > 16)\r\nreturn AC_ERR_INVALID;\r\nDPRINTK("init dev params \n");\r\nata_tf_init(dev, &tf);\r\ntf.command = ATA_CMD_INIT_DEV_PARAMS;\r\ntf.flags |= ATA_TFLAG_ISADDR | ATA_TFLAG_DEVICE;\r\ntf.protocol = ATA_PROT_NODATA;\r\ntf.nsect = sectors;\r\ntf.device |= (heads - 1) & 0x0f;\r\nerr_mask = ata_exec_internal(dev, &tf, NULL, DMA_NONE, NULL, 0, 0);\r\nif (err_mask == AC_ERR_DEV && (tf.feature & ATA_ABORTED))\r\nerr_mask = 0;\r\nDPRINTK("EXIT, err_mask=%x\n", err_mask);\r\nreturn err_mask;\r\n}\r\nvoid ata_sg_clean(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nstruct scatterlist *sg = qc->sg;\r\nint dir = qc->dma_dir;\r\nWARN_ON_ONCE(sg == NULL);\r\nVPRINTK("unmapping %u sg elements\n", qc->n_elem);\r\nif (qc->n_elem)\r\ndma_unmap_sg(ap->dev, sg, qc->orig_n_elem, dir);\r\nqc->flags &= ~ATA_QCFLAG_DMAMAP;\r\nqc->sg = NULL;\r\n}\r\nint atapi_check_dma(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nif (!(qc->dev->horkage & ATA_HORKAGE_ATAPI_MOD16_DMA) &&\r\nunlikely(qc->nbytes & 15))\r\nreturn 1;\r\nif (ap->ops->check_atapi_dma)\r\nreturn ap->ops->check_atapi_dma(qc);\r\nreturn 0;\r\n}\r\nint ata_std_qc_defer(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_link *link = qc->dev->link;\r\nif (qc->tf.protocol == ATA_PROT_NCQ) {\r\nif (!ata_tag_valid(link->active_tag))\r\nreturn 0;\r\n} else {\r\nif (!ata_tag_valid(link->active_tag) && !link->sactive)\r\nreturn 0;\r\n}\r\nreturn ATA_DEFER_LINK;\r\n}\r\nvoid ata_noop_qc_prep(struct ata_queued_cmd *qc) { }\r\nvoid ata_sg_init(struct ata_queued_cmd *qc, struct scatterlist *sg,\r\nunsigned int n_elem)\r\n{\r\nqc->sg = sg;\r\nqc->n_elem = n_elem;\r\nqc->cursg = qc->sg;\r\n}\r\nstatic int ata_sg_setup(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nunsigned int n_elem;\r\nVPRINTK("ENTER, ata%u\n", ap->print_id);\r\nn_elem = dma_map_sg(ap->dev, qc->sg, qc->n_elem, qc->dma_dir);\r\nif (n_elem < 1)\r\nreturn -1;\r\nDPRINTK("%d sg elements mapped\n", n_elem);\r\nqc->orig_n_elem = qc->n_elem;\r\nqc->n_elem = n_elem;\r\nqc->flags |= ATA_QCFLAG_DMAMAP;\r\nreturn 0;\r\n}\r\nvoid swap_buf_le16(u16 *buf, unsigned int buf_words)\r\n{\r\n#ifdef __BIG_ENDIAN\r\nunsigned int i;\r\nfor (i = 0; i < buf_words; i++)\r\nbuf[i] = le16_to_cpu(buf[i]);\r\n#endif\r\n}\r\nstruct ata_queued_cmd *ata_qc_new_init(struct ata_device *dev, int tag)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nstruct ata_queued_cmd *qc;\r\nif (unlikely(ap->pflags & ATA_PFLAG_FROZEN))\r\nreturn NULL;\r\nif (ap->flags & ATA_FLAG_SAS_HOST) {\r\ntag = ata_sas_allocate_tag(ap);\r\nif (tag < 0)\r\nreturn NULL;\r\n}\r\nqc = __ata_qc_from_tag(ap, tag);\r\nqc->tag = tag;\r\nqc->scsicmd = NULL;\r\nqc->ap = ap;\r\nqc->dev = dev;\r\nata_qc_reinit(qc);\r\nreturn qc;\r\n}\r\nvoid ata_qc_free(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap;\r\nunsigned int tag;\r\nWARN_ON_ONCE(qc == NULL);\r\nap = qc->ap;\r\nqc->flags = 0;\r\ntag = qc->tag;\r\nif (likely(ata_tag_valid(tag))) {\r\nqc->tag = ATA_TAG_POISON;\r\nif (ap->flags & ATA_FLAG_SAS_HOST)\r\nata_sas_free_tag(tag, ap);\r\n}\r\n}\r\nvoid __ata_qc_complete(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap;\r\nstruct ata_link *link;\r\nWARN_ON_ONCE(qc == NULL);\r\nWARN_ON_ONCE(!(qc->flags & ATA_QCFLAG_ACTIVE));\r\nap = qc->ap;\r\nlink = qc->dev->link;\r\nif (likely(qc->flags & ATA_QCFLAG_DMAMAP))\r\nata_sg_clean(qc);\r\nif (qc->tf.protocol == ATA_PROT_NCQ) {\r\nlink->sactive &= ~(1 << qc->tag);\r\nif (!link->sactive)\r\nap->nr_active_links--;\r\n} else {\r\nlink->active_tag = ATA_TAG_POISON;\r\nap->nr_active_links--;\r\n}\r\nif (unlikely(qc->flags & ATA_QCFLAG_CLEAR_EXCL &&\r\nap->excl_link == link))\r\nap->excl_link = NULL;\r\nqc->flags &= ~ATA_QCFLAG_ACTIVE;\r\nap->qc_active &= ~(1 << qc->tag);\r\nqc->complete_fn(qc);\r\n}\r\nstatic void fill_result_tf(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nqc->result_tf.flags = qc->tf.flags;\r\nap->ops->qc_fill_rtf(qc);\r\n}\r\nstatic void ata_verify_xfer(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_device *dev = qc->dev;\r\nif (ata_is_nodata(qc->tf.protocol))\r\nreturn;\r\nif ((dev->mwdma_mask || dev->udma_mask) && ata_is_pio(qc->tf.protocol))\r\nreturn;\r\ndev->flags &= ~ATA_DFLAG_DUBIOUS_XFER;\r\n}\r\nvoid ata_qc_complete(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nif (ap->ops->error_handler) {\r\nstruct ata_device *dev = qc->dev;\r\nstruct ata_eh_info *ehi = &dev->link->eh_info;\r\nif (unlikely(qc->err_mask))\r\nqc->flags |= ATA_QCFLAG_FAILED;\r\nif (unlikely(ata_tag_internal(qc->tag))) {\r\nfill_result_tf(qc);\r\ntrace_ata_qc_complete_internal(qc);\r\n__ata_qc_complete(qc);\r\nreturn;\r\n}\r\nif (unlikely(qc->flags & ATA_QCFLAG_FAILED)) {\r\nfill_result_tf(qc);\r\ntrace_ata_qc_complete_failed(qc);\r\nata_qc_schedule_eh(qc);\r\nreturn;\r\n}\r\nWARN_ON_ONCE(ap->pflags & ATA_PFLAG_FROZEN);\r\nif (qc->flags & ATA_QCFLAG_RESULT_TF)\r\nfill_result_tf(qc);\r\ntrace_ata_qc_complete_done(qc);\r\nswitch (qc->tf.command) {\r\ncase ATA_CMD_SET_FEATURES:\r\nif (qc->tf.feature != SETFEATURES_WC_ON &&\r\nqc->tf.feature != SETFEATURES_WC_OFF)\r\nbreak;\r\ncase ATA_CMD_INIT_DEV_PARAMS:\r\ncase ATA_CMD_SET_MULTI:\r\nehi->dev_action[dev->devno] |= ATA_EH_REVALIDATE;\r\nata_port_schedule_eh(ap);\r\nbreak;\r\ncase ATA_CMD_SLEEP:\r\ndev->flags |= ATA_DFLAG_SLEEPING;\r\nbreak;\r\n}\r\nif (unlikely(dev->flags & ATA_DFLAG_DUBIOUS_XFER))\r\nata_verify_xfer(qc);\r\n__ata_qc_complete(qc);\r\n} else {\r\nif (qc->flags & ATA_QCFLAG_EH_SCHEDULED)\r\nreturn;\r\nif (qc->err_mask || qc->flags & ATA_QCFLAG_RESULT_TF)\r\nfill_result_tf(qc);\r\n__ata_qc_complete(qc);\r\n}\r\n}\r\nint ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active)\r\n{\r\nint nr_done = 0;\r\nu32 done_mask;\r\ndone_mask = ap->qc_active ^ qc_active;\r\nif (unlikely(done_mask & qc_active)) {\r\nata_port_err(ap, "illegal qc_active transition (%08x->%08x)\n",\r\nap->qc_active, qc_active);\r\nreturn -EINVAL;\r\n}\r\nwhile (done_mask) {\r\nstruct ata_queued_cmd *qc;\r\nunsigned int tag = __ffs(done_mask);\r\nqc = ata_qc_from_tag(ap, tag);\r\nif (qc) {\r\nata_qc_complete(qc);\r\nnr_done++;\r\n}\r\ndone_mask &= ~(1 << tag);\r\n}\r\nreturn nr_done;\r\n}\r\nvoid ata_qc_issue(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nstruct ata_link *link = qc->dev->link;\r\nu8 prot = qc->tf.protocol;\r\nWARN_ON_ONCE(ap->ops->error_handler && ata_tag_valid(link->active_tag));\r\nif (ata_is_ncq(prot)) {\r\nWARN_ON_ONCE(link->sactive & (1 << qc->tag));\r\nif (!link->sactive)\r\nap->nr_active_links++;\r\nlink->sactive |= 1 << qc->tag;\r\n} else {\r\nWARN_ON_ONCE(link->sactive);\r\nap->nr_active_links++;\r\nlink->active_tag = qc->tag;\r\n}\r\nqc->flags |= ATA_QCFLAG_ACTIVE;\r\nap->qc_active |= 1 << qc->tag;\r\nif (WARN_ON_ONCE(ata_is_data(prot) &&\r\n(!qc->sg || !qc->n_elem || !qc->nbytes)))\r\ngoto sys_err;\r\nif (ata_is_dma(prot) || (ata_is_pio(prot) &&\r\n(ap->flags & ATA_FLAG_PIO_DMA)))\r\nif (ata_sg_setup(qc))\r\ngoto sys_err;\r\nif (unlikely(qc->dev->flags & ATA_DFLAG_SLEEPING)) {\r\nlink->eh_info.action |= ATA_EH_RESET;\r\nata_ehi_push_desc(&link->eh_info, "waking up from sleep");\r\nata_link_abort(link);\r\nreturn;\r\n}\r\nap->ops->qc_prep(qc);\r\ntrace_ata_qc_issue(qc);\r\nqc->err_mask |= ap->ops->qc_issue(qc);\r\nif (unlikely(qc->err_mask))\r\ngoto err;\r\nreturn;\r\nsys_err:\r\nqc->err_mask |= AC_ERR_SYSTEM;\r\nerr:\r\nata_qc_complete(qc);\r\n}\r\nint sata_scr_valid(struct ata_link *link)\r\n{\r\nstruct ata_port *ap = link->ap;\r\nreturn (ap->flags & ATA_FLAG_SATA) && ap->ops->scr_read;\r\n}\r\nint sata_scr_read(struct ata_link *link, int reg, u32 *val)\r\n{\r\nif (ata_is_host_link(link)) {\r\nif (sata_scr_valid(link))\r\nreturn link->ap->ops->scr_read(link, reg, val);\r\nreturn -EOPNOTSUPP;\r\n}\r\nreturn sata_pmp_scr_read(link, reg, val);\r\n}\r\nint sata_scr_write(struct ata_link *link, int reg, u32 val)\r\n{\r\nif (ata_is_host_link(link)) {\r\nif (sata_scr_valid(link))\r\nreturn link->ap->ops->scr_write(link, reg, val);\r\nreturn -EOPNOTSUPP;\r\n}\r\nreturn sata_pmp_scr_write(link, reg, val);\r\n}\r\nint sata_scr_write_flush(struct ata_link *link, int reg, u32 val)\r\n{\r\nif (ata_is_host_link(link)) {\r\nint rc;\r\nif (sata_scr_valid(link)) {\r\nrc = link->ap->ops->scr_write(link, reg, val);\r\nif (rc == 0)\r\nrc = link->ap->ops->scr_read(link, reg, &val);\r\nreturn rc;\r\n}\r\nreturn -EOPNOTSUPP;\r\n}\r\nreturn sata_pmp_scr_write(link, reg, val);\r\n}\r\nbool ata_phys_link_online(struct ata_link *link)\r\n{\r\nu32 sstatus;\r\nif (sata_scr_read(link, SCR_STATUS, &sstatus) == 0 &&\r\nata_sstatus_online(sstatus))\r\nreturn true;\r\nreturn false;\r\n}\r\nbool ata_phys_link_offline(struct ata_link *link)\r\n{\r\nu32 sstatus;\r\nif (sata_scr_read(link, SCR_STATUS, &sstatus) == 0 &&\r\n!ata_sstatus_online(sstatus))\r\nreturn true;\r\nreturn false;\r\n}\r\nbool ata_link_online(struct ata_link *link)\r\n{\r\nstruct ata_link *slave = link->ap->slave_link;\r\nWARN_ON(link == slave);\r\nreturn ata_phys_link_online(link) ||\r\n(slave && ata_phys_link_online(slave));\r\n}\r\nbool ata_link_offline(struct ata_link *link)\r\n{\r\nstruct ata_link *slave = link->ap->slave_link;\r\nWARN_ON(link == slave);\r\nreturn ata_phys_link_offline(link) &&\r\n(!slave || ata_phys_link_offline(slave));\r\n}\r\nstatic void ata_port_request_pm(struct ata_port *ap, pm_message_t mesg,\r\nunsigned int action, unsigned int ehi_flags,\r\nbool async)\r\n{\r\nstruct ata_link *link;\r\nunsigned long flags;\r\nif (ap->pflags & ATA_PFLAG_PM_PENDING) {\r\nata_port_wait_eh(ap);\r\nWARN_ON(ap->pflags & ATA_PFLAG_PM_PENDING);\r\n}\r\nspin_lock_irqsave(ap->lock, flags);\r\nap->pm_mesg = mesg;\r\nap->pflags |= ATA_PFLAG_PM_PENDING;\r\nata_for_each_link(link, ap, HOST_FIRST) {\r\nlink->eh_info.action |= action;\r\nlink->eh_info.flags |= ehi_flags;\r\n}\r\nata_port_schedule_eh(ap);\r\nspin_unlock_irqrestore(ap->lock, flags);\r\nif (!async) {\r\nata_port_wait_eh(ap);\r\nWARN_ON(ap->pflags & ATA_PFLAG_PM_PENDING);\r\n}\r\n}\r\nstatic void ata_port_suspend(struct ata_port *ap, pm_message_t mesg)\r\n{\r\nata_port_request_pm(ap, mesg, 0, ata_port_suspend_ehi, false);\r\n}\r\nstatic void ata_port_suspend_async(struct ata_port *ap, pm_message_t mesg)\r\n{\r\nata_port_request_pm(ap, mesg, 0, ata_port_suspend_ehi, true);\r\n}\r\nstatic int ata_port_pm_suspend(struct device *dev)\r\n{\r\nstruct ata_port *ap = to_ata_port(dev);\r\nif (pm_runtime_suspended(dev))\r\nreturn 0;\r\nata_port_suspend(ap, PMSG_SUSPEND);\r\nreturn 0;\r\n}\r\nstatic int ata_port_pm_freeze(struct device *dev)\r\n{\r\nstruct ata_port *ap = to_ata_port(dev);\r\nif (pm_runtime_suspended(dev))\r\nreturn 0;\r\nata_port_suspend(ap, PMSG_FREEZE);\r\nreturn 0;\r\n}\r\nstatic int ata_port_pm_poweroff(struct device *dev)\r\n{\r\nata_port_suspend(to_ata_port(dev), PMSG_HIBERNATE);\r\nreturn 0;\r\n}\r\nstatic void ata_port_resume(struct ata_port *ap, pm_message_t mesg)\r\n{\r\nata_port_request_pm(ap, mesg, ATA_EH_RESET, ata_port_resume_ehi, false);\r\n}\r\nstatic void ata_port_resume_async(struct ata_port *ap, pm_message_t mesg)\r\n{\r\nata_port_request_pm(ap, mesg, ATA_EH_RESET, ata_port_resume_ehi, true);\r\n}\r\nstatic int ata_port_pm_resume(struct device *dev)\r\n{\r\nata_port_resume_async(to_ata_port(dev), PMSG_RESUME);\r\npm_runtime_disable(dev);\r\npm_runtime_set_active(dev);\r\npm_runtime_enable(dev);\r\nreturn 0;\r\n}\r\nstatic int ata_port_runtime_idle(struct device *dev)\r\n{\r\nstruct ata_port *ap = to_ata_port(dev);\r\nstruct ata_link *link;\r\nstruct ata_device *adev;\r\nata_for_each_link(link, ap, HOST_FIRST) {\r\nata_for_each_dev(adev, link, ENABLED)\r\nif (adev->class == ATA_DEV_ATAPI &&\r\n!zpodd_dev_enabled(adev))\r\nreturn -EBUSY;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ata_port_runtime_suspend(struct device *dev)\r\n{\r\nata_port_suspend(to_ata_port(dev), PMSG_AUTO_SUSPEND);\r\nreturn 0;\r\n}\r\nstatic int ata_port_runtime_resume(struct device *dev)\r\n{\r\nata_port_resume(to_ata_port(dev), PMSG_AUTO_RESUME);\r\nreturn 0;\r\n}\r\nvoid ata_sas_port_suspend(struct ata_port *ap)\r\n{\r\nata_port_suspend_async(ap, PMSG_SUSPEND);\r\n}\r\nvoid ata_sas_port_resume(struct ata_port *ap)\r\n{\r\nata_port_resume_async(ap, PMSG_RESUME);\r\n}\r\nint ata_host_suspend(struct ata_host *host, pm_message_t mesg)\r\n{\r\nhost->dev->power.power_state = mesg;\r\nreturn 0;\r\n}\r\nvoid ata_host_resume(struct ata_host *host)\r\n{\r\nhost->dev->power.power_state = PMSG_ON;\r\n}\r\nvoid ata_dev_init(struct ata_device *dev)\r\n{\r\nstruct ata_link *link = ata_dev_phys_link(dev);\r\nstruct ata_port *ap = link->ap;\r\nunsigned long flags;\r\nlink->sata_spd_limit = link->hw_sata_spd_limit;\r\nlink->sata_spd = 0;\r\nspin_lock_irqsave(ap->lock, flags);\r\ndev->flags &= ~ATA_DFLAG_INIT_MASK;\r\ndev->horkage = 0;\r\nspin_unlock_irqrestore(ap->lock, flags);\r\nmemset((void *)dev + ATA_DEVICE_CLEAR_BEGIN, 0,\r\nATA_DEVICE_CLEAR_END - ATA_DEVICE_CLEAR_BEGIN);\r\ndev->pio_mask = UINT_MAX;\r\ndev->mwdma_mask = UINT_MAX;\r\ndev->udma_mask = UINT_MAX;\r\n}\r\nvoid ata_link_init(struct ata_port *ap, struct ata_link *link, int pmp)\r\n{\r\nint i;\r\nmemset((void *)link + ATA_LINK_CLEAR_BEGIN, 0,\r\nATA_LINK_CLEAR_END - ATA_LINK_CLEAR_BEGIN);\r\nlink->ap = ap;\r\nlink->pmp = pmp;\r\nlink->active_tag = ATA_TAG_POISON;\r\nlink->hw_sata_spd_limit = UINT_MAX;\r\nfor (i = 0; i < ATA_MAX_DEVICES; i++) {\r\nstruct ata_device *dev = &link->device[i];\r\ndev->link = link;\r\ndev->devno = dev - link->device;\r\n#ifdef CONFIG_ATA_ACPI\r\ndev->gtf_filter = ata_acpi_gtf_filter;\r\n#endif\r\nata_dev_init(dev);\r\n}\r\n}\r\nint sata_link_init_spd(struct ata_link *link)\r\n{\r\nu8 spd;\r\nint rc;\r\nrc = sata_scr_read(link, SCR_CONTROL, &link->saved_scontrol);\r\nif (rc)\r\nreturn rc;\r\nspd = (link->saved_scontrol >> 4) & 0xf;\r\nif (spd)\r\nlink->hw_sata_spd_limit &= (1 << spd) - 1;\r\nata_force_link_limits(link);\r\nlink->sata_spd_limit = link->hw_sata_spd_limit;\r\nreturn 0;\r\n}\r\nstruct ata_port *ata_port_alloc(struct ata_host *host)\r\n{\r\nstruct ata_port *ap;\r\nDPRINTK("ENTER\n");\r\nap = kzalloc(sizeof(*ap), GFP_KERNEL);\r\nif (!ap)\r\nreturn NULL;\r\nap->pflags |= ATA_PFLAG_INITIALIZING | ATA_PFLAG_FROZEN;\r\nap->lock = &host->lock;\r\nap->print_id = -1;\r\nap->local_port_no = -1;\r\nap->host = host;\r\nap->dev = host->dev;\r\n#if defined(ATA_VERBOSE_DEBUG)\r\nap->msg_enable = 0x00FF;\r\n#elif defined(ATA_DEBUG)\r\nap->msg_enable = ATA_MSG_DRV | ATA_MSG_INFO | ATA_MSG_CTL | ATA_MSG_WARN | ATA_MSG_ERR;\r\n#else\r\nap->msg_enable = ATA_MSG_DRV | ATA_MSG_ERR | ATA_MSG_WARN;\r\n#endif\r\nmutex_init(&ap->scsi_scan_mutex);\r\nINIT_DELAYED_WORK(&ap->hotplug_task, ata_scsi_hotplug);\r\nINIT_WORK(&ap->scsi_rescan_task, ata_scsi_dev_rescan);\r\nINIT_LIST_HEAD(&ap->eh_done_q);\r\ninit_waitqueue_head(&ap->eh_wait_q);\r\ninit_completion(&ap->park_req_pending);\r\ninit_timer_deferrable(&ap->fastdrain_timer);\r\nap->fastdrain_timer.function = ata_eh_fastdrain_timerfn;\r\nap->fastdrain_timer.data = (unsigned long)ap;\r\nap->cbl = ATA_CBL_NONE;\r\nata_link_init(ap, &ap->link, 0);\r\n#ifdef ATA_IRQ_TRAP\r\nap->stats.unhandled_irq = 1;\r\nap->stats.idle_irq = 1;\r\n#endif\r\nata_sff_port_init(ap);\r\nreturn ap;\r\n}\r\nstatic void ata_host_release(struct device *gendev, void *res)\r\n{\r\nstruct ata_host *host = dev_get_drvdata(gendev);\r\nint i;\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nif (!ap)\r\ncontinue;\r\nif (ap->scsi_host)\r\nscsi_host_put(ap->scsi_host);\r\nkfree(ap->pmp_link);\r\nkfree(ap->slave_link);\r\nkfree(ap);\r\nhost->ports[i] = NULL;\r\n}\r\ndev_set_drvdata(gendev, NULL);\r\n}\r\nstruct ata_host *ata_host_alloc(struct device *dev, int max_ports)\r\n{\r\nstruct ata_host *host;\r\nsize_t sz;\r\nint i;\r\nDPRINTK("ENTER\n");\r\nif (!devres_open_group(dev, NULL, GFP_KERNEL))\r\nreturn NULL;\r\nsz = sizeof(struct ata_host) + (max_ports + 1) * sizeof(void *);\r\nhost = devres_alloc(ata_host_release, sz, GFP_KERNEL);\r\nif (!host)\r\ngoto err_out;\r\ndevres_add(dev, host);\r\ndev_set_drvdata(dev, host);\r\nspin_lock_init(&host->lock);\r\nmutex_init(&host->eh_mutex);\r\nhost->dev = dev;\r\nhost->n_ports = max_ports;\r\nfor (i = 0; i < max_ports; i++) {\r\nstruct ata_port *ap;\r\nap = ata_port_alloc(host);\r\nif (!ap)\r\ngoto err_out;\r\nap->port_no = i;\r\nhost->ports[i] = ap;\r\n}\r\ndevres_remove_group(dev, NULL);\r\nreturn host;\r\nerr_out:\r\ndevres_release_group(dev, NULL);\r\nreturn NULL;\r\n}\r\nstruct ata_host *ata_host_alloc_pinfo(struct device *dev,\r\nconst struct ata_port_info * const * ppi,\r\nint n_ports)\r\n{\r\nconst struct ata_port_info *pi;\r\nstruct ata_host *host;\r\nint i, j;\r\nhost = ata_host_alloc(dev, n_ports);\r\nif (!host)\r\nreturn NULL;\r\nfor (i = 0, j = 0, pi = NULL; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nif (ppi[j])\r\npi = ppi[j++];\r\nap->pio_mask = pi->pio_mask;\r\nap->mwdma_mask = pi->mwdma_mask;\r\nap->udma_mask = pi->udma_mask;\r\nap->flags |= pi->flags;\r\nap->link.flags |= pi->link_flags;\r\nap->ops = pi->port_ops;\r\nif (!host->ops && (pi->port_ops != &ata_dummy_port_ops))\r\nhost->ops = pi->port_ops;\r\n}\r\nreturn host;\r\n}\r\nint ata_slave_link_init(struct ata_port *ap)\r\n{\r\nstruct ata_link *link;\r\nWARN_ON(ap->slave_link);\r\nWARN_ON(ap->flags & ATA_FLAG_PMP);\r\nlink = kzalloc(sizeof(*link), GFP_KERNEL);\r\nif (!link)\r\nreturn -ENOMEM;\r\nata_link_init(ap, link, 1);\r\nap->slave_link = link;\r\nreturn 0;\r\n}\r\nstatic void ata_host_stop(struct device *gendev, void *res)\r\n{\r\nstruct ata_host *host = dev_get_drvdata(gendev);\r\nint i;\r\nWARN_ON(!(host->flags & ATA_HOST_STARTED));\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nif (ap->ops->port_stop)\r\nap->ops->port_stop(ap);\r\n}\r\nif (host->ops->host_stop)\r\nhost->ops->host_stop(host);\r\n}\r\nstatic void ata_finalize_port_ops(struct ata_port_operations *ops)\r\n{\r\nstatic DEFINE_SPINLOCK(lock);\r\nconst struct ata_port_operations *cur;\r\nvoid **begin = (void **)ops;\r\nvoid **end = (void **)&ops->inherits;\r\nvoid **pp;\r\nif (!ops || !ops->inherits)\r\nreturn;\r\nspin_lock(&lock);\r\nfor (cur = ops->inherits; cur; cur = cur->inherits) {\r\nvoid **inherit = (void **)cur;\r\nfor (pp = begin; pp < end; pp++, inherit++)\r\nif (!*pp)\r\n*pp = *inherit;\r\n}\r\nfor (pp = begin; pp < end; pp++)\r\nif (IS_ERR(*pp))\r\n*pp = NULL;\r\nops->inherits = NULL;\r\nspin_unlock(&lock);\r\n}\r\nint ata_host_start(struct ata_host *host)\r\n{\r\nint have_stop = 0;\r\nvoid *start_dr = NULL;\r\nint i, rc;\r\nif (host->flags & ATA_HOST_STARTED)\r\nreturn 0;\r\nata_finalize_port_ops(host->ops);\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nata_finalize_port_ops(ap->ops);\r\nif (!host->ops && !ata_port_is_dummy(ap))\r\nhost->ops = ap->ops;\r\nif (ap->ops->port_stop)\r\nhave_stop = 1;\r\n}\r\nif (host->ops->host_stop)\r\nhave_stop = 1;\r\nif (have_stop) {\r\nstart_dr = devres_alloc(ata_host_stop, 0, GFP_KERNEL);\r\nif (!start_dr)\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nif (ap->ops->port_start) {\r\nrc = ap->ops->port_start(ap);\r\nif (rc) {\r\nif (rc != -ENODEV)\r\ndev_err(host->dev,\r\n"failed to start port %d (errno=%d)\n",\r\ni, rc);\r\ngoto err_out;\r\n}\r\n}\r\nata_eh_freeze_port(ap);\r\n}\r\nif (start_dr)\r\ndevres_add(host->dev, start_dr);\r\nhost->flags |= ATA_HOST_STARTED;\r\nreturn 0;\r\nerr_out:\r\nwhile (--i >= 0) {\r\nstruct ata_port *ap = host->ports[i];\r\nif (ap->ops->port_stop)\r\nap->ops->port_stop(ap);\r\n}\r\ndevres_free(start_dr);\r\nreturn rc;\r\n}\r\nvoid ata_host_init(struct ata_host *host, struct device *dev,\r\nstruct ata_port_operations *ops)\r\n{\r\nspin_lock_init(&host->lock);\r\nmutex_init(&host->eh_mutex);\r\nhost->n_tags = ATA_MAX_QUEUE - 1;\r\nhost->dev = dev;\r\nhost->ops = ops;\r\n}\r\nvoid __ata_port_probe(struct ata_port *ap)\r\n{\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nunsigned long flags;\r\nspin_lock_irqsave(ap->lock, flags);\r\nehi->probe_mask |= ATA_ALL_DEVICES;\r\nehi->action |= ATA_EH_RESET;\r\nehi->flags |= ATA_EHI_NO_AUTOPSY | ATA_EHI_QUIET;\r\nap->pflags &= ~ATA_PFLAG_INITIALIZING;\r\nap->pflags |= ATA_PFLAG_LOADING;\r\nata_port_schedule_eh(ap);\r\nspin_unlock_irqrestore(ap->lock, flags);\r\n}\r\nint ata_port_probe(struct ata_port *ap)\r\n{\r\nint rc = 0;\r\nif (ap->ops->error_handler) {\r\n__ata_port_probe(ap);\r\nata_port_wait_eh(ap);\r\n} else {\r\nDPRINTK("ata%u: bus probe begin\n", ap->print_id);\r\nrc = ata_bus_probe(ap);\r\nDPRINTK("ata%u: bus probe end\n", ap->print_id);\r\n}\r\nreturn rc;\r\n}\r\nstatic void async_port_probe(void *data, async_cookie_t cookie)\r\n{\r\nstruct ata_port *ap = data;\r\nif (!(ap->host->flags & ATA_HOST_PARALLEL_SCAN) && ap->port_no != 0)\r\nasync_synchronize_cookie(cookie);\r\n(void)ata_port_probe(ap);\r\nasync_synchronize_cookie(cookie);\r\nata_scsi_scan_host(ap, 1);\r\n}\r\nint ata_host_register(struct ata_host *host, struct scsi_host_template *sht)\r\n{\r\nint i, rc;\r\nhost->n_tags = clamp(sht->can_queue, 1, ATA_MAX_QUEUE - 1);\r\nif (!(host->flags & ATA_HOST_STARTED)) {\r\ndev_err(host->dev, "BUG: trying to register unstarted host\n");\r\nWARN_ON(1);\r\nreturn -EINVAL;\r\n}\r\nfor (i = host->n_ports; host->ports[i]; i++)\r\nkfree(host->ports[i]);\r\nfor (i = 0; i < host->n_ports; i++) {\r\nhost->ports[i]->print_id = atomic_inc_return(&ata_print_id);\r\nhost->ports[i]->local_port_no = i + 1;\r\n}\r\nfor (i = 0; i < host->n_ports; i++) {\r\nrc = ata_tport_add(host->dev,host->ports[i]);\r\nif (rc) {\r\ngoto err_tadd;\r\n}\r\n}\r\nrc = ata_scsi_add_hosts(host, sht);\r\nif (rc)\r\ngoto err_tadd;\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nunsigned long xfer_mask;\r\nif (ap->cbl == ATA_CBL_NONE && (ap->flags & ATA_FLAG_SATA))\r\nap->cbl = ATA_CBL_SATA;\r\nsata_link_init_spd(&ap->link);\r\nif (ap->slave_link)\r\nsata_link_init_spd(ap->slave_link);\r\nxfer_mask = ata_pack_xfermask(ap->pio_mask, ap->mwdma_mask,\r\nap->udma_mask);\r\nif (!ata_port_is_dummy(ap)) {\r\nata_port_info(ap, "%cATA max %s %s\n",\r\n(ap->flags & ATA_FLAG_SATA) ? 'S' : 'P',\r\nata_mode_string(xfer_mask),\r\nap->link.eh_info.desc);\r\nata_ehi_clear_desc(&ap->link.eh_info);\r\n} else\r\nata_port_info(ap, "DUMMY\n");\r\n}\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nasync_schedule(async_port_probe, ap);\r\n}\r\nreturn 0;\r\nerr_tadd:\r\nwhile (--i >= 0) {\r\nata_tport_delete(host->ports[i]);\r\n}\r\nreturn rc;\r\n}\r\nint ata_host_activate(struct ata_host *host, int irq,\r\nirq_handler_t irq_handler, unsigned long irq_flags,\r\nstruct scsi_host_template *sht)\r\n{\r\nint i, rc;\r\nchar *irq_desc;\r\nrc = ata_host_start(host);\r\nif (rc)\r\nreturn rc;\r\nif (!irq) {\r\nWARN_ON(irq_handler);\r\nreturn ata_host_register(host, sht);\r\n}\r\nirq_desc = devm_kasprintf(host->dev, GFP_KERNEL, "%s[%s]",\r\ndev_driver_string(host->dev),\r\ndev_name(host->dev));\r\nif (!irq_desc)\r\nreturn -ENOMEM;\r\nrc = devm_request_irq(host->dev, irq, irq_handler, irq_flags,\r\nirq_desc, host);\r\nif (rc)\r\nreturn rc;\r\nfor (i = 0; i < host->n_ports; i++)\r\nata_port_desc(host->ports[i], "irq %d", irq);\r\nrc = ata_host_register(host, sht);\r\nif (rc)\r\ndevm_free_irq(host->dev, irq, host);\r\nreturn rc;\r\n}\r\nstatic void ata_port_detach(struct ata_port *ap)\r\n{\r\nunsigned long flags;\r\nstruct ata_link *link;\r\nstruct ata_device *dev;\r\nif (!ap->ops->error_handler)\r\ngoto skip_eh;\r\nspin_lock_irqsave(ap->lock, flags);\r\nap->pflags |= ATA_PFLAG_UNLOADING;\r\nata_port_schedule_eh(ap);\r\nspin_unlock_irqrestore(ap->lock, flags);\r\nata_port_wait_eh(ap);\r\nWARN_ON(!(ap->pflags & ATA_PFLAG_UNLOADED));\r\ncancel_delayed_work_sync(&ap->hotplug_task);\r\nskip_eh:\r\nata_for_each_link(link, ap, HOST_FIRST) {\r\nata_for_each_dev(dev, link, ALL) {\r\nif (zpodd_dev_enabled(dev))\r\nzpodd_exit(dev);\r\n}\r\n}\r\nif (ap->pmp_link) {\r\nint i;\r\nfor (i = 0; i < SATA_PMP_MAX_PORTS; i++)\r\nata_tlink_delete(&ap->pmp_link[i]);\r\n}\r\nscsi_remove_host(ap->scsi_host);\r\nata_tport_delete(ap);\r\n}\r\nvoid ata_host_detach(struct ata_host *host)\r\n{\r\nint i;\r\nfor (i = 0; i < host->n_ports; i++)\r\nata_port_detach(host->ports[i]);\r\nata_acpi_dissociate(host);\r\n}\r\nvoid ata_pci_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct ata_host *host = pci_get_drvdata(pdev);\r\nata_host_detach(host);\r\n}\r\nint pci_test_config_bits(struct pci_dev *pdev, const struct pci_bits *bits)\r\n{\r\nunsigned long tmp = 0;\r\nswitch (bits->width) {\r\ncase 1: {\r\nu8 tmp8 = 0;\r\npci_read_config_byte(pdev, bits->reg, &tmp8);\r\ntmp = tmp8;\r\nbreak;\r\n}\r\ncase 2: {\r\nu16 tmp16 = 0;\r\npci_read_config_word(pdev, bits->reg, &tmp16);\r\ntmp = tmp16;\r\nbreak;\r\n}\r\ncase 4: {\r\nu32 tmp32 = 0;\r\npci_read_config_dword(pdev, bits->reg, &tmp32);\r\ntmp = tmp32;\r\nbreak;\r\n}\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ntmp &= bits->mask;\r\nreturn (tmp == bits->val) ? 1 : 0;\r\n}\r\nvoid ata_pci_device_do_suspend(struct pci_dev *pdev, pm_message_t mesg)\r\n{\r\npci_save_state(pdev);\r\npci_disable_device(pdev);\r\nif (mesg.event & PM_EVENT_SLEEP)\r\npci_set_power_state(pdev, PCI_D3hot);\r\n}\r\nint ata_pci_device_do_resume(struct pci_dev *pdev)\r\n{\r\nint rc;\r\npci_set_power_state(pdev, PCI_D0);\r\npci_restore_state(pdev);\r\nrc = pcim_enable_device(pdev);\r\nif (rc) {\r\ndev_err(&pdev->dev,\r\n"failed to enable device after resume (%d)\n", rc);\r\nreturn rc;\r\n}\r\npci_set_master(pdev);\r\nreturn 0;\r\n}\r\nint ata_pci_device_suspend(struct pci_dev *pdev, pm_message_t mesg)\r\n{\r\nstruct ata_host *host = pci_get_drvdata(pdev);\r\nint rc = 0;\r\nrc = ata_host_suspend(host, mesg);\r\nif (rc)\r\nreturn rc;\r\nata_pci_device_do_suspend(pdev, mesg);\r\nreturn 0;\r\n}\r\nint ata_pci_device_resume(struct pci_dev *pdev)\r\n{\r\nstruct ata_host *host = pci_get_drvdata(pdev);\r\nint rc;\r\nrc = ata_pci_device_do_resume(pdev);\r\nif (rc == 0)\r\nata_host_resume(host);\r\nreturn rc;\r\n}\r\nint ata_platform_remove_one(struct platform_device *pdev)\r\n{\r\nstruct ata_host *host = platform_get_drvdata(pdev);\r\nata_host_detach(host);\r\nreturn 0;\r\n}\r\nstatic int __init ata_parse_force_one(char **cur,\r\nstruct ata_force_ent *force_ent,\r\nconst char **reason)\r\n{\r\nstatic const struct ata_force_param force_tbl[] __initconst = {\r\n{ "40c", .cbl = ATA_CBL_PATA40 },\r\n{ "80c", .cbl = ATA_CBL_PATA80 },\r\n{ "short40c", .cbl = ATA_CBL_PATA40_SHORT },\r\n{ "unk", .cbl = ATA_CBL_PATA_UNK },\r\n{ "ign", .cbl = ATA_CBL_PATA_IGN },\r\n{ "sata", .cbl = ATA_CBL_SATA },\r\n{ "1.5Gbps", .spd_limit = 1 },\r\n{ "3.0Gbps", .spd_limit = 2 },\r\n{ "noncq", .horkage_on = ATA_HORKAGE_NONCQ },\r\n{ "ncq", .horkage_off = ATA_HORKAGE_NONCQ },\r\n{ "noncqtrim", .horkage_on = ATA_HORKAGE_NO_NCQ_TRIM },\r\n{ "ncqtrim", .horkage_off = ATA_HORKAGE_NO_NCQ_TRIM },\r\n{ "dump_id", .horkage_on = ATA_HORKAGE_DUMP_ID },\r\n{ "pio0", .xfer_mask = 1 << (ATA_SHIFT_PIO + 0) },\r\n{ "pio1", .xfer_mask = 1 << (ATA_SHIFT_PIO + 1) },\r\n{ "pio2", .xfer_mask = 1 << (ATA_SHIFT_PIO + 2) },\r\n{ "pio3", .xfer_mask = 1 << (ATA_SHIFT_PIO + 3) },\r\n{ "pio4", .xfer_mask = 1 << (ATA_SHIFT_PIO + 4) },\r\n{ "pio5", .xfer_mask = 1 << (ATA_SHIFT_PIO + 5) },\r\n{ "pio6", .xfer_mask = 1 << (ATA_SHIFT_PIO + 6) },\r\n{ "mwdma0", .xfer_mask = 1 << (ATA_SHIFT_MWDMA + 0) },\r\n{ "mwdma1", .xfer_mask = 1 << (ATA_SHIFT_MWDMA + 1) },\r\n{ "mwdma2", .xfer_mask = 1 << (ATA_SHIFT_MWDMA + 2) },\r\n{ "mwdma3", .xfer_mask = 1 << (ATA_SHIFT_MWDMA + 3) },\r\n{ "mwdma4", .xfer_mask = 1 << (ATA_SHIFT_MWDMA + 4) },\r\n{ "udma0", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 0) },\r\n{ "udma16", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 0) },\r\n{ "udma/16", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 0) },\r\n{ "udma1", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 1) },\r\n{ "udma25", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 1) },\r\n{ "udma/25", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 1) },\r\n{ "udma2", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 2) },\r\n{ "udma33", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 2) },\r\n{ "udma/33", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 2) },\r\n{ "udma3", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 3) },\r\n{ "udma44", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 3) },\r\n{ "udma/44", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 3) },\r\n{ "udma4", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 4) },\r\n{ "udma66", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 4) },\r\n{ "udma/66", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 4) },\r\n{ "udma5", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 5) },\r\n{ "udma100", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 5) },\r\n{ "udma/100", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 5) },\r\n{ "udma6", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 6) },\r\n{ "udma133", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 6) },\r\n{ "udma/133", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 6) },\r\n{ "udma7", .xfer_mask = 1 << (ATA_SHIFT_UDMA + 7) },\r\n{ "nohrst", .lflags = ATA_LFLAG_NO_HRST },\r\n{ "nosrst", .lflags = ATA_LFLAG_NO_SRST },\r\n{ "norst", .lflags = ATA_LFLAG_NO_HRST | ATA_LFLAG_NO_SRST },\r\n{ "rstonce", .lflags = ATA_LFLAG_RST_ONCE },\r\n{ "atapi_dmadir", .horkage_on = ATA_HORKAGE_ATAPI_DMADIR },\r\n{ "disable", .horkage_on = ATA_HORKAGE_DISABLE },\r\n};\r\nchar *start = *cur, *p = *cur;\r\nchar *id, *val, *endp;\r\nconst struct ata_force_param *match_fp = NULL;\r\nint nr_matches = 0, i;\r\nwhile (*p != '\0' && *p != ',')\r\np++;\r\nif (*p == '\0')\r\n*cur = p;\r\nelse\r\n*cur = p + 1;\r\n*p = '\0';\r\np = strchr(start, ':');\r\nif (!p) {\r\nval = strstrip(start);\r\ngoto parse_val;\r\n}\r\n*p = '\0';\r\nid = strstrip(start);\r\nval = strstrip(p + 1);\r\np = strchr(id, '.');\r\nif (p) {\r\n*p++ = '\0';\r\nforce_ent->device = simple_strtoul(p, &endp, 10);\r\nif (p == endp || *endp != '\0') {\r\n*reason = "invalid device";\r\nreturn -EINVAL;\r\n}\r\n}\r\nforce_ent->port = simple_strtoul(id, &endp, 10);\r\nif (p == endp || *endp != '\0') {\r\n*reason = "invalid port/link";\r\nreturn -EINVAL;\r\n}\r\nparse_val:\r\nfor (i = 0; i < ARRAY_SIZE(force_tbl); i++) {\r\nconst struct ata_force_param *fp = &force_tbl[i];\r\nif (strncasecmp(val, fp->name, strlen(val)))\r\ncontinue;\r\nnr_matches++;\r\nmatch_fp = fp;\r\nif (strcasecmp(val, fp->name) == 0) {\r\nnr_matches = 1;\r\nbreak;\r\n}\r\n}\r\nif (!nr_matches) {\r\n*reason = "unknown value";\r\nreturn -EINVAL;\r\n}\r\nif (nr_matches > 1) {\r\n*reason = "ambigious value";\r\nreturn -EINVAL;\r\n}\r\nforce_ent->param = *match_fp;\r\nreturn 0;\r\n}\r\nstatic void __init ata_parse_force_param(void)\r\n{\r\nint idx = 0, size = 1;\r\nint last_port = -1, last_device = -1;\r\nchar *p, *cur, *next;\r\nfor (p = ata_force_param_buf; *p; p++)\r\nif (*p == ',')\r\nsize++;\r\nata_force_tbl = kzalloc(sizeof(ata_force_tbl[0]) * size, GFP_KERNEL);\r\nif (!ata_force_tbl) {\r\nprintk(KERN_WARNING "ata: failed to extend force table, "\r\n"libata.force ignored\n");\r\nreturn;\r\n}\r\nfor (cur = ata_force_param_buf; *cur != '\0'; cur = next) {\r\nconst char *reason = "";\r\nstruct ata_force_ent te = { .port = -1, .device = -1 };\r\nnext = cur;\r\nif (ata_parse_force_one(&next, &te, &reason)) {\r\nprintk(KERN_WARNING "ata: failed to parse force "\r\n"parameter \"%s\" (%s)\n",\r\ncur, reason);\r\ncontinue;\r\n}\r\nif (te.port == -1) {\r\nte.port = last_port;\r\nte.device = last_device;\r\n}\r\nata_force_tbl[idx++] = te;\r\nlast_port = te.port;\r\nlast_device = te.device;\r\n}\r\nata_force_tbl_size = idx;\r\n}\r\nstatic int __init ata_init(void)\r\n{\r\nint rc;\r\nata_parse_force_param();\r\nrc = ata_sff_init();\r\nif (rc) {\r\nkfree(ata_force_tbl);\r\nreturn rc;\r\n}\r\nlibata_transport_init();\r\nata_scsi_transport_template = ata_attach_transport();\r\nif (!ata_scsi_transport_template) {\r\nata_sff_exit();\r\nrc = -ENOMEM;\r\ngoto err_out;\r\n}\r\nprintk(KERN_DEBUG "libata version " DRV_VERSION " loaded.\n");\r\nreturn 0;\r\nerr_out:\r\nreturn rc;\r\n}\r\nstatic void __exit ata_exit(void)\r\n{\r\nata_release_transport(ata_scsi_transport_template);\r\nlibata_transport_exit();\r\nata_sff_exit();\r\nkfree(ata_force_tbl);\r\n}\r\nint ata_ratelimit(void)\r\n{\r\nreturn __ratelimit(&ratelimit);\r\n}\r\nvoid ata_msleep(struct ata_port *ap, unsigned int msecs)\r\n{\r\nbool owns_eh = ap && ap->host->eh_owner == current;\r\nif (owns_eh)\r\nata_eh_release(ap);\r\nif (msecs < 20) {\r\nunsigned long usecs = msecs * USEC_PER_MSEC;\r\nusleep_range(usecs, usecs + 50);\r\n} else {\r\nmsleep(msecs);\r\n}\r\nif (owns_eh)\r\nata_eh_acquire(ap);\r\n}\r\nu32 ata_wait_register(struct ata_port *ap, void __iomem *reg, u32 mask, u32 val,\r\nunsigned long interval, unsigned long timeout)\r\n{\r\nunsigned long deadline;\r\nu32 tmp;\r\ntmp = ioread32(reg);\r\ndeadline = ata_deadline(jiffies, timeout);\r\nwhile ((tmp & mask) == val && time_before(jiffies, deadline)) {\r\nata_msleep(ap, interval);\r\ntmp = ioread32(reg);\r\n}\r\nreturn tmp;\r\n}\r\nbool sata_lpm_ignore_phy_events(struct ata_link *link)\r\n{\r\nunsigned long lpm_timeout = link->last_lpm_change +\r\nmsecs_to_jiffies(ATA_TMOUT_SPURIOUS_PHY);\r\nif (link->lpm_policy > ATA_LPM_MAX_POWER)\r\nreturn true;\r\nif ((link->flags & ATA_LFLAG_CHANGED) &&\r\ntime_before(jiffies, lpm_timeout))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic unsigned int ata_dummy_qc_issue(struct ata_queued_cmd *qc)\r\n{\r\nreturn AC_ERR_SYSTEM;\r\n}\r\nstatic void ata_dummy_error_handler(struct ata_port *ap)\r\n{\r\n}\r\nvoid ata_port_printk(const struct ata_port *ap, const char *level,\r\nconst char *fmt, ...)\r\n{\r\nstruct va_format vaf;\r\nva_list args;\r\nva_start(args, fmt);\r\nvaf.fmt = fmt;\r\nvaf.va = &args;\r\nprintk("%sata%u: %pV", level, ap->print_id, &vaf);\r\nva_end(args);\r\n}\r\nvoid ata_link_printk(const struct ata_link *link, const char *level,\r\nconst char *fmt, ...)\r\n{\r\nstruct va_format vaf;\r\nva_list args;\r\nva_start(args, fmt);\r\nvaf.fmt = fmt;\r\nvaf.va = &args;\r\nif (sata_pmp_attached(link->ap) || link->ap->slave_link)\r\nprintk("%sata%u.%02u: %pV",\r\nlevel, link->ap->print_id, link->pmp, &vaf);\r\nelse\r\nprintk("%sata%u: %pV",\r\nlevel, link->ap->print_id, &vaf);\r\nva_end(args);\r\n}\r\nvoid ata_dev_printk(const struct ata_device *dev, const char *level,\r\nconst char *fmt, ...)\r\n{\r\nstruct va_format vaf;\r\nva_list args;\r\nva_start(args, fmt);\r\nvaf.fmt = fmt;\r\nvaf.va = &args;\r\nprintk("%sata%u.%02u: %pV",\r\nlevel, dev->link->ap->print_id, dev->link->pmp + dev->devno,\r\n&vaf);\r\nva_end(args);\r\n}\r\nvoid ata_print_version(const struct device *dev, const char *version)\r\n{\r\ndev_printk(KERN_DEBUG, dev, "version %s\n", version);\r\n}
