static inline u32 chnenbl_ofs(struct sdma_engine *sdma, unsigned int event)\r\n{\r\nu32 chnenbl0 = sdma->drvdata->chnenbl0;\r\nreturn chnenbl0 + event * 4;\r\n}\r\nstatic int sdma_config_ownership(struct sdma_channel *sdmac,\r\nbool event_override, bool mcu_override, bool dsp_override)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint channel = sdmac->channel;\r\nunsigned long evt, mcu, dsp;\r\nif (event_override && mcu_override && dsp_override)\r\nreturn -EINVAL;\r\nevt = readl_relaxed(sdma->regs + SDMA_H_EVTOVR);\r\nmcu = readl_relaxed(sdma->regs + SDMA_H_HOSTOVR);\r\ndsp = readl_relaxed(sdma->regs + SDMA_H_DSPOVR);\r\nif (dsp_override)\r\n__clear_bit(channel, &dsp);\r\nelse\r\n__set_bit(channel, &dsp);\r\nif (event_override)\r\n__clear_bit(channel, &evt);\r\nelse\r\n__set_bit(channel, &evt);\r\nif (mcu_override)\r\n__clear_bit(channel, &mcu);\r\nelse\r\n__set_bit(channel, &mcu);\r\nwritel_relaxed(evt, sdma->regs + SDMA_H_EVTOVR);\r\nwritel_relaxed(mcu, sdma->regs + SDMA_H_HOSTOVR);\r\nwritel_relaxed(dsp, sdma->regs + SDMA_H_DSPOVR);\r\nreturn 0;\r\n}\r\nstatic void sdma_enable_channel(struct sdma_engine *sdma, int channel)\r\n{\r\nwritel(BIT(channel), sdma->regs + SDMA_H_START);\r\n}\r\nstatic int sdma_run_channel0(struct sdma_engine *sdma)\r\n{\r\nint ret;\r\nunsigned long timeout = 500;\r\nsdma_enable_channel(sdma, 0);\r\nwhile (!(ret = readl_relaxed(sdma->regs + SDMA_H_INTR) & 1)) {\r\nif (timeout-- <= 0)\r\nbreak;\r\nudelay(1);\r\n}\r\nif (ret) {\r\nwritel_relaxed(ret, sdma->regs + SDMA_H_INTR);\r\n} else {\r\ndev_err(sdma->dev, "Timeout waiting for CH0 ready\n");\r\n}\r\nif (readl(sdma->regs + SDMA_H_CONFIG) == 0)\r\nwritel_relaxed(SDMA_H_CONFIG_CSM, sdma->regs + SDMA_H_CONFIG);\r\nreturn ret ? 0 : -ETIMEDOUT;\r\n}\r\nstatic int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,\r\nu32 address)\r\n{\r\nstruct sdma_buffer_descriptor *bd0 = sdma->channel[0].bd;\r\nvoid *buf_virt;\r\ndma_addr_t buf_phys;\r\nint ret;\r\nunsigned long flags;\r\nbuf_virt = dma_alloc_coherent(NULL,\r\nsize,\r\n&buf_phys, GFP_KERNEL);\r\nif (!buf_virt) {\r\nreturn -ENOMEM;\r\n}\r\nspin_lock_irqsave(&sdma->channel_0_lock, flags);\r\nbd0->mode.command = C0_SETPM;\r\nbd0->mode.status = BD_DONE | BD_INTR | BD_WRAP | BD_EXTD;\r\nbd0->mode.count = size / 2;\r\nbd0->buffer_addr = buf_phys;\r\nbd0->ext_buffer_addr = address;\r\nmemcpy(buf_virt, buf, size);\r\nret = sdma_run_channel0(sdma);\r\nspin_unlock_irqrestore(&sdma->channel_0_lock, flags);\r\ndma_free_coherent(NULL, size, buf_virt, buf_phys);\r\nreturn ret;\r\n}\r\nstatic void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint channel = sdmac->channel;\r\nunsigned long val;\r\nu32 chnenbl = chnenbl_ofs(sdma, event);\r\nval = readl_relaxed(sdma->regs + chnenbl);\r\n__set_bit(channel, &val);\r\nwritel_relaxed(val, sdma->regs + chnenbl);\r\n}\r\nstatic void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint channel = sdmac->channel;\r\nu32 chnenbl = chnenbl_ofs(sdma, event);\r\nunsigned long val;\r\nval = readl_relaxed(sdma->regs + chnenbl);\r\n__clear_bit(channel, &val);\r\nwritel_relaxed(val, sdma->regs + chnenbl);\r\n}\r\nstatic void sdma_handle_channel_loop(struct sdma_channel *sdmac)\r\n{\r\nif (sdmac->desc.callback)\r\nsdmac->desc.callback(sdmac->desc.callback_param);\r\n}\r\nstatic void sdma_update_channel_loop(struct sdma_channel *sdmac)\r\n{\r\nstruct sdma_buffer_descriptor *bd;\r\nwhile (1) {\r\nbd = &sdmac->bd[sdmac->buf_tail];\r\nif (bd->mode.status & BD_DONE)\r\nbreak;\r\nif (bd->mode.status & BD_RROR)\r\nsdmac->status = DMA_ERROR;\r\nbd->mode.status |= BD_DONE;\r\nsdmac->buf_tail++;\r\nsdmac->buf_tail %= sdmac->num_bd;\r\n}\r\n}\r\nstatic void mxc_sdma_handle_channel_normal(struct sdma_channel *sdmac)\r\n{\r\nstruct sdma_buffer_descriptor *bd;\r\nint i, error = 0;\r\nsdmac->chn_real_count = 0;\r\nfor (i = 0; i < sdmac->num_bd; i++) {\r\nbd = &sdmac->bd[i];\r\nif (bd->mode.status & (BD_DONE | BD_RROR))\r\nerror = -EIO;\r\nsdmac->chn_real_count += bd->mode.count;\r\n}\r\nif (error)\r\nsdmac->status = DMA_ERROR;\r\nelse\r\nsdmac->status = DMA_COMPLETE;\r\ndma_cookie_complete(&sdmac->desc);\r\nif (sdmac->desc.callback)\r\nsdmac->desc.callback(sdmac->desc.callback_param);\r\n}\r\nstatic void sdma_tasklet(unsigned long data)\r\n{\r\nstruct sdma_channel *sdmac = (struct sdma_channel *) data;\r\nif (sdmac->flags & IMX_DMA_SG_LOOP)\r\nsdma_handle_channel_loop(sdmac);\r\nelse\r\nmxc_sdma_handle_channel_normal(sdmac);\r\n}\r\nstatic irqreturn_t sdma_int_handler(int irq, void *dev_id)\r\n{\r\nstruct sdma_engine *sdma = dev_id;\r\nunsigned long stat;\r\nstat = readl_relaxed(sdma->regs + SDMA_H_INTR);\r\nstat &= ~1;\r\nwritel_relaxed(stat, sdma->regs + SDMA_H_INTR);\r\nwhile (stat) {\r\nint channel = fls(stat) - 1;\r\nstruct sdma_channel *sdmac = &sdma->channel[channel];\r\nif (sdmac->flags & IMX_DMA_SG_LOOP)\r\nsdma_update_channel_loop(sdmac);\r\ntasklet_schedule(&sdmac->tasklet);\r\n__clear_bit(channel, &stat);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void sdma_get_pc(struct sdma_channel *sdmac,\r\nenum sdma_peripheral_type peripheral_type)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint per_2_emi = 0, emi_2_per = 0;\r\nint per_2_per = 0, emi_2_emi = 0;\r\nsdmac->pc_from_device = 0;\r\nsdmac->pc_to_device = 0;\r\nsdmac->device_to_device = 0;\r\nswitch (peripheral_type) {\r\ncase IMX_DMATYPE_MEMORY:\r\nemi_2_emi = sdma->script_addrs->ap_2_ap_addr;\r\nbreak;\r\ncase IMX_DMATYPE_DSP:\r\nemi_2_per = sdma->script_addrs->bp_2_ap_addr;\r\nper_2_emi = sdma->script_addrs->ap_2_bp_addr;\r\nbreak;\r\ncase IMX_DMATYPE_FIRI:\r\nper_2_emi = sdma->script_addrs->firi_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_firi_addr;\r\nbreak;\r\ncase IMX_DMATYPE_UART:\r\nper_2_emi = sdma->script_addrs->uart_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_app_addr;\r\nbreak;\r\ncase IMX_DMATYPE_UART_SP:\r\nper_2_emi = sdma->script_addrs->uartsh_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_shp_addr;\r\nbreak;\r\ncase IMX_DMATYPE_ATA:\r\nper_2_emi = sdma->script_addrs->ata_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_ata_addr;\r\nbreak;\r\ncase IMX_DMATYPE_CSPI:\r\ncase IMX_DMATYPE_EXT:\r\ncase IMX_DMATYPE_SSI:\r\ncase IMX_DMATYPE_SAI:\r\nper_2_emi = sdma->script_addrs->app_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_app_addr;\r\nbreak;\r\ncase IMX_DMATYPE_SSI_DUAL:\r\nper_2_emi = sdma->script_addrs->ssish_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_ssish_addr;\r\nbreak;\r\ncase IMX_DMATYPE_SSI_SP:\r\ncase IMX_DMATYPE_MMC:\r\ncase IMX_DMATYPE_SDHC:\r\ncase IMX_DMATYPE_CSPI_SP:\r\ncase IMX_DMATYPE_ESAI:\r\ncase IMX_DMATYPE_MSHC_SP:\r\nper_2_emi = sdma->script_addrs->shp_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_shp_addr;\r\nbreak;\r\ncase IMX_DMATYPE_ASRC:\r\nper_2_emi = sdma->script_addrs->asrc_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->asrc_2_mcu_addr;\r\nper_2_per = sdma->script_addrs->per_2_per_addr;\r\nbreak;\r\ncase IMX_DMATYPE_ASRC_SP:\r\nper_2_emi = sdma->script_addrs->shp_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_shp_addr;\r\nper_2_per = sdma->script_addrs->per_2_per_addr;\r\nbreak;\r\ncase IMX_DMATYPE_MSHC:\r\nper_2_emi = sdma->script_addrs->mshc_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_mshc_addr;\r\nbreak;\r\ncase IMX_DMATYPE_CCM:\r\nper_2_emi = sdma->script_addrs->dptc_dvfs_addr;\r\nbreak;\r\ncase IMX_DMATYPE_SPDIF:\r\nper_2_emi = sdma->script_addrs->spdif_2_mcu_addr;\r\nemi_2_per = sdma->script_addrs->mcu_2_spdif_addr;\r\nbreak;\r\ncase IMX_DMATYPE_IPU_MEMORY:\r\nemi_2_per = sdma->script_addrs->ext_mem_2_ipu_addr;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nsdmac->pc_from_device = per_2_emi;\r\nsdmac->pc_to_device = emi_2_per;\r\nsdmac->device_to_device = per_2_per;\r\n}\r\nstatic int sdma_load_context(struct sdma_channel *sdmac)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint channel = sdmac->channel;\r\nint load_address;\r\nstruct sdma_context_data *context = sdma->context;\r\nstruct sdma_buffer_descriptor *bd0 = sdma->channel[0].bd;\r\nint ret;\r\nunsigned long flags;\r\nif (sdmac->direction == DMA_DEV_TO_MEM)\r\nload_address = sdmac->pc_from_device;\r\nelse if (sdmac->direction == DMA_DEV_TO_DEV)\r\nload_address = sdmac->device_to_device;\r\nelse\r\nload_address = sdmac->pc_to_device;\r\nif (load_address < 0)\r\nreturn load_address;\r\ndev_dbg(sdma->dev, "load_address = %d\n", load_address);\r\ndev_dbg(sdma->dev, "wml = 0x%08x\n", (u32)sdmac->watermark_level);\r\ndev_dbg(sdma->dev, "shp_addr = 0x%08x\n", sdmac->shp_addr);\r\ndev_dbg(sdma->dev, "per_addr = 0x%08x\n", sdmac->per_addr);\r\ndev_dbg(sdma->dev, "event_mask0 = 0x%08x\n", (u32)sdmac->event_mask[0]);\r\ndev_dbg(sdma->dev, "event_mask1 = 0x%08x\n", (u32)sdmac->event_mask[1]);\r\nspin_lock_irqsave(&sdma->channel_0_lock, flags);\r\nmemset(context, 0, sizeof(*context));\r\ncontext->channel_state.pc = load_address;\r\ncontext->gReg[0] = sdmac->event_mask[1];\r\ncontext->gReg[1] = sdmac->event_mask[0];\r\ncontext->gReg[2] = sdmac->per_addr;\r\ncontext->gReg[6] = sdmac->shp_addr;\r\ncontext->gReg[7] = sdmac->watermark_level;\r\nbd0->mode.command = C0_SETDM;\r\nbd0->mode.status = BD_DONE | BD_INTR | BD_WRAP | BD_EXTD;\r\nbd0->mode.count = sizeof(*context) / 4;\r\nbd0->buffer_addr = sdma->context_phys;\r\nbd0->ext_buffer_addr = 2048 + (sizeof(*context) / 4) * channel;\r\nret = sdma_run_channel0(sdma);\r\nspin_unlock_irqrestore(&sdma->channel_0_lock, flags);\r\nreturn ret;\r\n}\r\nstatic struct sdma_channel *to_sdma_chan(struct dma_chan *chan)\r\n{\r\nreturn container_of(chan, struct sdma_channel, chan);\r\n}\r\nstatic int sdma_disable_channel(struct dma_chan *chan)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint channel = sdmac->channel;\r\nwritel_relaxed(BIT(channel), sdma->regs + SDMA_H_STATSTOP);\r\nsdmac->status = DMA_ERROR;\r\nreturn 0;\r\n}\r\nstatic void sdma_set_watermarklevel_for_p2p(struct sdma_channel *sdmac)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint lwml = sdmac->watermark_level & SDMA_WATERMARK_LEVEL_LWML;\r\nint hwml = (sdmac->watermark_level & SDMA_WATERMARK_LEVEL_HWML) >> 16;\r\nset_bit(sdmac->event_id0 % 32, &sdmac->event_mask[1]);\r\nset_bit(sdmac->event_id1 % 32, &sdmac->event_mask[0]);\r\nif (sdmac->event_id0 > 31)\r\nsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_LWE;\r\nif (sdmac->event_id1 > 31)\r\nsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_HWE;\r\nif (lwml > hwml) {\r\nsdmac->watermark_level &= ~(SDMA_WATERMARK_LEVEL_LWML |\r\nSDMA_WATERMARK_LEVEL_HWML);\r\nsdmac->watermark_level |= hwml;\r\nsdmac->watermark_level |= lwml << 16;\r\nswap(sdmac->event_mask[0], sdmac->event_mask[1]);\r\n}\r\nif (sdmac->per_address2 >= sdma->spba_start_addr &&\r\nsdmac->per_address2 <= sdma->spba_end_addr)\r\nsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_SP;\r\nif (sdmac->per_address >= sdma->spba_start_addr &&\r\nsdmac->per_address <= sdma->spba_end_addr)\r\nsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_DP;\r\nsdmac->watermark_level |= SDMA_WATERMARK_LEVEL_CONT;\r\n}\r\nstatic int sdma_config_channel(struct dma_chan *chan)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nint ret;\r\nsdma_disable_channel(chan);\r\nsdmac->event_mask[0] = 0;\r\nsdmac->event_mask[1] = 0;\r\nsdmac->shp_addr = 0;\r\nsdmac->per_addr = 0;\r\nif (sdmac->event_id0) {\r\nif (sdmac->event_id0 >= sdmac->sdma->drvdata->num_events)\r\nreturn -EINVAL;\r\nsdma_event_enable(sdmac, sdmac->event_id0);\r\n}\r\nif (sdmac->event_id1) {\r\nif (sdmac->event_id1 >= sdmac->sdma->drvdata->num_events)\r\nreturn -EINVAL;\r\nsdma_event_enable(sdmac, sdmac->event_id1);\r\n}\r\nswitch (sdmac->peripheral_type) {\r\ncase IMX_DMATYPE_DSP:\r\nsdma_config_ownership(sdmac, false, true, true);\r\nbreak;\r\ncase IMX_DMATYPE_MEMORY:\r\nsdma_config_ownership(sdmac, false, true, false);\r\nbreak;\r\ndefault:\r\nsdma_config_ownership(sdmac, true, true, false);\r\nbreak;\r\n}\r\nsdma_get_pc(sdmac, sdmac->peripheral_type);\r\nif ((sdmac->peripheral_type != IMX_DMATYPE_MEMORY) &&\r\n(sdmac->peripheral_type != IMX_DMATYPE_DSP)) {\r\nif (sdmac->event_id1) {\r\nif (sdmac->peripheral_type == IMX_DMATYPE_ASRC_SP ||\r\nsdmac->peripheral_type == IMX_DMATYPE_ASRC)\r\nsdma_set_watermarklevel_for_p2p(sdmac);\r\n} else\r\n__set_bit(sdmac->event_id0, sdmac->event_mask);\r\nsdmac->watermark_level |= sdmac->watermark_level;\r\nsdmac->shp_addr = sdmac->per_address;\r\nsdmac->per_addr = sdmac->per_address2;\r\n} else {\r\nsdmac->watermark_level = 0;\r\n}\r\nret = sdma_load_context(sdmac);\r\nreturn ret;\r\n}\r\nstatic int sdma_set_channel_priority(struct sdma_channel *sdmac,\r\nunsigned int priority)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint channel = sdmac->channel;\r\nif (priority < MXC_SDMA_MIN_PRIORITY\r\n|| priority > MXC_SDMA_MAX_PRIORITY) {\r\nreturn -EINVAL;\r\n}\r\nwritel_relaxed(priority, sdma->regs + SDMA_CHNPRI_0 + 4 * channel);\r\nreturn 0;\r\n}\r\nstatic int sdma_request_channel(struct sdma_channel *sdmac)\r\n{\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint channel = sdmac->channel;\r\nint ret = -EBUSY;\r\nsdmac->bd = dma_zalloc_coherent(NULL, PAGE_SIZE, &sdmac->bd_phys,\r\nGFP_KERNEL);\r\nif (!sdmac->bd) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nsdma->channel_control[channel].base_bd_ptr = sdmac->bd_phys;\r\nsdma->channel_control[channel].current_bd_ptr = sdmac->bd_phys;\r\nsdma_set_channel_priority(sdmac, MXC_SDMA_DEFAULT_PRIORITY);\r\nreturn 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic dma_cookie_t sdma_tx_submit(struct dma_async_tx_descriptor *tx)\r\n{\r\nunsigned long flags;\r\nstruct sdma_channel *sdmac = to_sdma_chan(tx->chan);\r\ndma_cookie_t cookie;\r\nspin_lock_irqsave(&sdmac->lock, flags);\r\ncookie = dma_cookie_assign(tx);\r\nspin_unlock_irqrestore(&sdmac->lock, flags);\r\nreturn cookie;\r\n}\r\nstatic int sdma_alloc_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nstruct imx_dma_data *data = chan->private;\r\nint prio, ret;\r\nif (!data)\r\nreturn -EINVAL;\r\nswitch (data->priority) {\r\ncase DMA_PRIO_HIGH:\r\nprio = 3;\r\nbreak;\r\ncase DMA_PRIO_MEDIUM:\r\nprio = 2;\r\nbreak;\r\ncase DMA_PRIO_LOW:\r\ndefault:\r\nprio = 1;\r\nbreak;\r\n}\r\nsdmac->peripheral_type = data->peripheral_type;\r\nsdmac->event_id0 = data->dma_request;\r\nsdmac->event_id1 = data->dma_request2;\r\nret = clk_enable(sdmac->sdma->clk_ipg);\r\nif (ret)\r\nreturn ret;\r\nret = clk_enable(sdmac->sdma->clk_ahb);\r\nif (ret)\r\ngoto disable_clk_ipg;\r\nret = sdma_request_channel(sdmac);\r\nif (ret)\r\ngoto disable_clk_ahb;\r\nret = sdma_set_channel_priority(sdmac, prio);\r\nif (ret)\r\ngoto disable_clk_ahb;\r\ndma_async_tx_descriptor_init(&sdmac->desc, chan);\r\nsdmac->desc.tx_submit = sdma_tx_submit;\r\nsdmac->desc.flags = DMA_CTRL_ACK;\r\nreturn 0;\r\ndisable_clk_ahb:\r\nclk_disable(sdmac->sdma->clk_ahb);\r\ndisable_clk_ipg:\r\nclk_disable(sdmac->sdma->clk_ipg);\r\nreturn ret;\r\n}\r\nstatic void sdma_free_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nsdma_disable_channel(chan);\r\nif (sdmac->event_id0)\r\nsdma_event_disable(sdmac, sdmac->event_id0);\r\nif (sdmac->event_id1)\r\nsdma_event_disable(sdmac, sdmac->event_id1);\r\nsdmac->event_id0 = 0;\r\nsdmac->event_id1 = 0;\r\nsdma_set_channel_priority(sdmac, 0);\r\ndma_free_coherent(NULL, PAGE_SIZE, sdmac->bd, sdmac->bd_phys);\r\nclk_disable(sdma->clk_ipg);\r\nclk_disable(sdma->clk_ahb);\r\n}\r\nstatic struct dma_async_tx_descriptor *sdma_prep_slave_sg(\r\nstruct dma_chan *chan, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint ret, i, count;\r\nint channel = sdmac->channel;\r\nstruct scatterlist *sg;\r\nif (sdmac->status == DMA_IN_PROGRESS)\r\nreturn NULL;\r\nsdmac->status = DMA_IN_PROGRESS;\r\nsdmac->flags = 0;\r\nsdmac->buf_tail = 0;\r\ndev_dbg(sdma->dev, "setting up %d entries for channel %d.\n",\r\nsg_len, channel);\r\nsdmac->direction = direction;\r\nret = sdma_load_context(sdmac);\r\nif (ret)\r\ngoto err_out;\r\nif (sg_len > NUM_BD) {\r\ndev_err(sdma->dev, "SDMA channel %d: maximum number of sg exceeded: %d > %d\n",\r\nchannel, sg_len, NUM_BD);\r\nret = -EINVAL;\r\ngoto err_out;\r\n}\r\nsdmac->chn_count = 0;\r\nfor_each_sg(sgl, sg, sg_len, i) {\r\nstruct sdma_buffer_descriptor *bd = &sdmac->bd[i];\r\nint param;\r\nbd->buffer_addr = sg->dma_address;\r\ncount = sg_dma_len(sg);\r\nif (count > 0xffff) {\r\ndev_err(sdma->dev, "SDMA channel %d: maximum bytes for sg entry exceeded: %d > %d\n",\r\nchannel, count, 0xffff);\r\nret = -EINVAL;\r\ngoto err_out;\r\n}\r\nbd->mode.count = count;\r\nsdmac->chn_count += count;\r\nif (sdmac->word_size > DMA_SLAVE_BUSWIDTH_4_BYTES) {\r\nret = -EINVAL;\r\ngoto err_out;\r\n}\r\nswitch (sdmac->word_size) {\r\ncase DMA_SLAVE_BUSWIDTH_4_BYTES:\r\nbd->mode.command = 0;\r\nif (count & 3 || sg->dma_address & 3)\r\nreturn NULL;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_2_BYTES:\r\nbd->mode.command = 2;\r\nif (count & 1 || sg->dma_address & 1)\r\nreturn NULL;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_1_BYTE:\r\nbd->mode.command = 1;\r\nbreak;\r\ndefault:\r\nreturn NULL;\r\n}\r\nparam = BD_DONE | BD_EXTD | BD_CONT;\r\nif (i + 1 == sg_len) {\r\nparam |= BD_INTR;\r\nparam |= BD_LAST;\r\nparam &= ~BD_CONT;\r\n}\r\ndev_dbg(sdma->dev, "entry %d: count: %d dma: %#llx %s%s\n",\r\ni, count, (u64)sg->dma_address,\r\nparam & BD_WRAP ? "wrap" : "",\r\nparam & BD_INTR ? " intr" : "");\r\nbd->mode.status = param;\r\n}\r\nsdmac->num_bd = sg_len;\r\nsdma->channel_control[channel].current_bd_ptr = sdmac->bd_phys;\r\nreturn &sdmac->desc;\r\nerr_out:\r\nsdmac->status = DMA_ERROR;\r\nreturn NULL;\r\n}\r\nstatic struct dma_async_tx_descriptor *sdma_prep_dma_cyclic(\r\nstruct dma_chan *chan, dma_addr_t dma_addr, size_t buf_len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nint num_periods = buf_len / period_len;\r\nint channel = sdmac->channel;\r\nint ret, i = 0, buf = 0;\r\ndev_dbg(sdma->dev, "%s channel: %d\n", __func__, channel);\r\nif (sdmac->status == DMA_IN_PROGRESS)\r\nreturn NULL;\r\nsdmac->status = DMA_IN_PROGRESS;\r\nsdmac->buf_tail = 0;\r\nsdmac->period_len = period_len;\r\nsdmac->flags |= IMX_DMA_SG_LOOP;\r\nsdmac->direction = direction;\r\nret = sdma_load_context(sdmac);\r\nif (ret)\r\ngoto err_out;\r\nif (num_periods > NUM_BD) {\r\ndev_err(sdma->dev, "SDMA channel %d: maximum number of sg exceeded: %d > %d\n",\r\nchannel, num_periods, NUM_BD);\r\ngoto err_out;\r\n}\r\nif (period_len > 0xffff) {\r\ndev_err(sdma->dev, "SDMA channel %d: maximum period size exceeded: %d > %d\n",\r\nchannel, period_len, 0xffff);\r\ngoto err_out;\r\n}\r\nwhile (buf < buf_len) {\r\nstruct sdma_buffer_descriptor *bd = &sdmac->bd[i];\r\nint param;\r\nbd->buffer_addr = dma_addr;\r\nbd->mode.count = period_len;\r\nif (sdmac->word_size > DMA_SLAVE_BUSWIDTH_4_BYTES)\r\ngoto err_out;\r\nif (sdmac->word_size == DMA_SLAVE_BUSWIDTH_4_BYTES)\r\nbd->mode.command = 0;\r\nelse\r\nbd->mode.command = sdmac->word_size;\r\nparam = BD_DONE | BD_EXTD | BD_CONT | BD_INTR;\r\nif (i + 1 == num_periods)\r\nparam |= BD_WRAP;\r\ndev_dbg(sdma->dev, "entry %d: count: %d dma: %#llx %s%s\n",\r\ni, period_len, (u64)dma_addr,\r\nparam & BD_WRAP ? "wrap" : "",\r\nparam & BD_INTR ? " intr" : "");\r\nbd->mode.status = param;\r\ndma_addr += period_len;\r\nbuf += period_len;\r\ni++;\r\n}\r\nsdmac->num_bd = num_periods;\r\nsdma->channel_control[channel].current_bd_ptr = sdmac->bd_phys;\r\nreturn &sdmac->desc;\r\nerr_out:\r\nsdmac->status = DMA_ERROR;\r\nreturn NULL;\r\n}\r\nstatic int sdma_config(struct dma_chan *chan,\r\nstruct dma_slave_config *dmaengine_cfg)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nif (dmaengine_cfg->direction == DMA_DEV_TO_MEM) {\r\nsdmac->per_address = dmaengine_cfg->src_addr;\r\nsdmac->watermark_level = dmaengine_cfg->src_maxburst *\r\ndmaengine_cfg->src_addr_width;\r\nsdmac->word_size = dmaengine_cfg->src_addr_width;\r\n} else if (dmaengine_cfg->direction == DMA_DEV_TO_DEV) {\r\nsdmac->per_address2 = dmaengine_cfg->src_addr;\r\nsdmac->per_address = dmaengine_cfg->dst_addr;\r\nsdmac->watermark_level = dmaengine_cfg->src_maxburst &\r\nSDMA_WATERMARK_LEVEL_LWML;\r\nsdmac->watermark_level |= (dmaengine_cfg->dst_maxburst << 16) &\r\nSDMA_WATERMARK_LEVEL_HWML;\r\nsdmac->word_size = dmaengine_cfg->dst_addr_width;\r\n} else {\r\nsdmac->per_address = dmaengine_cfg->dst_addr;\r\nsdmac->watermark_level = dmaengine_cfg->dst_maxburst *\r\ndmaengine_cfg->dst_addr_width;\r\nsdmac->word_size = dmaengine_cfg->dst_addr_width;\r\n}\r\nsdmac->direction = dmaengine_cfg->direction;\r\nreturn sdma_config_channel(chan);\r\n}\r\nstatic enum dma_status sdma_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie,\r\nstruct dma_tx_state *txstate)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nu32 residue;\r\nif (sdmac->flags & IMX_DMA_SG_LOOP)\r\nresidue = (sdmac->num_bd - sdmac->buf_tail) * sdmac->period_len;\r\nelse\r\nresidue = sdmac->chn_count - sdmac->chn_real_count;\r\ndma_set_tx_state(txstate, chan->completed_cookie, chan->cookie,\r\nresidue);\r\nreturn sdmac->status;\r\n}\r\nstatic void sdma_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nstruct sdma_engine *sdma = sdmac->sdma;\r\nif (sdmac->status == DMA_IN_PROGRESS)\r\nsdma_enable_channel(sdma, sdmac->channel);\r\n}\r\nstatic void sdma_add_scripts(struct sdma_engine *sdma,\r\nconst struct sdma_script_start_addrs *addr)\r\n{\r\ns32 *addr_arr = (u32 *)addr;\r\ns32 *saddr_arr = (u32 *)sdma->script_addrs;\r\nint i;\r\nif (!sdma->script_number)\r\nsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V1;\r\nfor (i = 0; i < sdma->script_number; i++)\r\nif (addr_arr[i] > 0)\r\nsaddr_arr[i] = addr_arr[i];\r\n}\r\nstatic void sdma_load_firmware(const struct firmware *fw, void *context)\r\n{\r\nstruct sdma_engine *sdma = context;\r\nconst struct sdma_firmware_header *header;\r\nconst struct sdma_script_start_addrs *addr;\r\nunsigned short *ram_code;\r\nif (!fw) {\r\ndev_info(sdma->dev, "external firmware not found, using ROM firmware\n");\r\nreturn;\r\n}\r\nif (fw->size < sizeof(*header))\r\ngoto err_firmware;\r\nheader = (struct sdma_firmware_header *)fw->data;\r\nif (header->magic != SDMA_FIRMWARE_MAGIC)\r\ngoto err_firmware;\r\nif (header->ram_code_start + header->ram_code_size > fw->size)\r\ngoto err_firmware;\r\nswitch (header->version_major) {\r\ncase 1:\r\nsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V1;\r\nbreak;\r\ncase 2:\r\nsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V2;\r\nbreak;\r\ncase 3:\r\nsdma->script_number = SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V3;\r\nbreak;\r\ndefault:\r\ndev_err(sdma->dev, "unknown firmware version\n");\r\ngoto err_firmware;\r\n}\r\naddr = (void *)header + header->script_addrs_start;\r\nram_code = (void *)header + header->ram_code_start;\r\nclk_enable(sdma->clk_ipg);\r\nclk_enable(sdma->clk_ahb);\r\nsdma_load_script(sdma, ram_code,\r\nheader->ram_code_size,\r\naddr->ram_code_start_addr);\r\nclk_disable(sdma->clk_ipg);\r\nclk_disable(sdma->clk_ahb);\r\nsdma_add_scripts(sdma, addr);\r\ndev_info(sdma->dev, "loaded firmware %d.%d\n",\r\nheader->version_major,\r\nheader->version_minor);\r\nerr_firmware:\r\nrelease_firmware(fw);\r\n}\r\nstatic int sdma_event_remap(struct sdma_engine *sdma)\r\n{\r\nstruct device_node *np = sdma->dev->of_node;\r\nstruct device_node *gpr_np = of_parse_phandle(np, "gpr", 0);\r\nstruct property *event_remap;\r\nstruct regmap *gpr;\r\nchar propname[] = "fsl,sdma-event-remap";\r\nu32 reg, val, shift, num_map, i;\r\nint ret = 0;\r\nif (IS_ERR(np) || IS_ERR(gpr_np))\r\ngoto out;\r\nevent_remap = of_find_property(np, propname, NULL);\r\nnum_map = event_remap ? (event_remap->length / sizeof(u32)) : 0;\r\nif (!num_map) {\r\ndev_dbg(sdma->dev, "no event needs to be remapped\n");\r\ngoto out;\r\n} else if (num_map % EVENT_REMAP_CELLS) {\r\ndev_err(sdma->dev, "the property %s must modulo %d\n",\r\npropname, EVENT_REMAP_CELLS);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\ngpr = syscon_node_to_regmap(gpr_np);\r\nif (IS_ERR(gpr)) {\r\ndev_err(sdma->dev, "failed to get gpr regmap\n");\r\nret = PTR_ERR(gpr);\r\ngoto out;\r\n}\r\nfor (i = 0; i < num_map; i += EVENT_REMAP_CELLS) {\r\nret = of_property_read_u32_index(np, propname, i, &reg);\r\nif (ret) {\r\ndev_err(sdma->dev, "failed to read property %s index %d\n",\r\npropname, i);\r\ngoto out;\r\n}\r\nret = of_property_read_u32_index(np, propname, i + 1, &shift);\r\nif (ret) {\r\ndev_err(sdma->dev, "failed to read property %s index %d\n",\r\npropname, i + 1);\r\ngoto out;\r\n}\r\nret = of_property_read_u32_index(np, propname, i + 2, &val);\r\nif (ret) {\r\ndev_err(sdma->dev, "failed to read property %s index %d\n",\r\npropname, i + 2);\r\ngoto out;\r\n}\r\nregmap_update_bits(gpr, reg, BIT(shift), val << shift);\r\n}\r\nout:\r\nif (!IS_ERR(gpr_np))\r\nof_node_put(gpr_np);\r\nreturn ret;\r\n}\r\nstatic int sdma_get_firmware(struct sdma_engine *sdma,\r\nconst char *fw_name)\r\n{\r\nint ret;\r\nret = request_firmware_nowait(THIS_MODULE,\r\nFW_ACTION_HOTPLUG, fw_name, sdma->dev,\r\nGFP_KERNEL, sdma, sdma_load_firmware);\r\nreturn ret;\r\n}\r\nstatic int sdma_init(struct sdma_engine *sdma)\r\n{\r\nint i, ret;\r\ndma_addr_t ccb_phys;\r\nret = clk_enable(sdma->clk_ipg);\r\nif (ret)\r\nreturn ret;\r\nret = clk_enable(sdma->clk_ahb);\r\nif (ret)\r\ngoto disable_clk_ipg;\r\nwritel_relaxed(0, sdma->regs + SDMA_H_C0PTR);\r\nsdma->channel_control = dma_alloc_coherent(NULL,\r\nMAX_DMA_CHANNELS * sizeof (struct sdma_channel_control) +\r\nsizeof(struct sdma_context_data),\r\n&ccb_phys, GFP_KERNEL);\r\nif (!sdma->channel_control) {\r\nret = -ENOMEM;\r\ngoto err_dma_alloc;\r\n}\r\nsdma->context = (void *)sdma->channel_control +\r\nMAX_DMA_CHANNELS * sizeof (struct sdma_channel_control);\r\nsdma->context_phys = ccb_phys +\r\nMAX_DMA_CHANNELS * sizeof (struct sdma_channel_control);\r\nmemset(sdma->channel_control, 0,\r\nMAX_DMA_CHANNELS * sizeof (struct sdma_channel_control));\r\nfor (i = 0; i < sdma->drvdata->num_events; i++)\r\nwritel_relaxed(0, sdma->regs + chnenbl_ofs(sdma, i));\r\nfor (i = 0; i < MAX_DMA_CHANNELS; i++)\r\nwritel_relaxed(0, sdma->regs + SDMA_CHNPRI_0 + i * 4);\r\nret = sdma_request_channel(&sdma->channel[0]);\r\nif (ret)\r\ngoto err_dma_alloc;\r\nsdma_config_ownership(&sdma->channel[0], false, true, false);\r\nwritel_relaxed(0x4050, sdma->regs + SDMA_CHN0ADDR);\r\nwritel_relaxed(0, sdma->regs + SDMA_H_CONFIG);\r\nwritel_relaxed(ccb_phys, sdma->regs + SDMA_H_C0PTR);\r\nsdma_set_channel_priority(&sdma->channel[0], 7);\r\nclk_disable(sdma->clk_ipg);\r\nclk_disable(sdma->clk_ahb);\r\nreturn 0;\r\nerr_dma_alloc:\r\nclk_disable(sdma->clk_ahb);\r\ndisable_clk_ipg:\r\nclk_disable(sdma->clk_ipg);\r\ndev_err(sdma->dev, "initialisation failed with %d\n", ret);\r\nreturn ret;\r\n}\r\nstatic bool sdma_filter_fn(struct dma_chan *chan, void *fn_param)\r\n{\r\nstruct sdma_channel *sdmac = to_sdma_chan(chan);\r\nstruct imx_dma_data *data = fn_param;\r\nif (!imx_dma_is_general_purpose(chan))\r\nreturn false;\r\nsdmac->data = *data;\r\nchan->private = &sdmac->data;\r\nreturn true;\r\n}\r\nstatic struct dma_chan *sdma_xlate(struct of_phandle_args *dma_spec,\r\nstruct of_dma *ofdma)\r\n{\r\nstruct sdma_engine *sdma = ofdma->of_dma_data;\r\ndma_cap_mask_t mask = sdma->dma_device.cap_mask;\r\nstruct imx_dma_data data;\r\nif (dma_spec->args_count != 3)\r\nreturn NULL;\r\ndata.dma_request = dma_spec->args[0];\r\ndata.peripheral_type = dma_spec->args[1];\r\ndata.priority = dma_spec->args[2];\r\ndata.dma_request2 = 0;\r\nreturn dma_request_channel(mask, sdma_filter_fn, &data);\r\n}\r\nstatic int sdma_probe(struct platform_device *pdev)\r\n{\r\nconst struct of_device_id *of_id =\r\nof_match_device(sdma_dt_ids, &pdev->dev);\r\nstruct device_node *np = pdev->dev.of_node;\r\nstruct device_node *spba_bus;\r\nconst char *fw_name;\r\nint ret;\r\nint irq;\r\nstruct resource *iores;\r\nstruct resource spba_res;\r\nstruct sdma_platform_data *pdata = dev_get_platdata(&pdev->dev);\r\nint i;\r\nstruct sdma_engine *sdma;\r\ns32 *saddr_arr;\r\nconst struct sdma_driver_data *drvdata = NULL;\r\nif (of_id)\r\ndrvdata = of_id->data;\r\nelse if (pdev->id_entry)\r\ndrvdata = (void *)pdev->id_entry->driver_data;\r\nif (!drvdata) {\r\ndev_err(&pdev->dev, "unable to find driver data\n");\r\nreturn -EINVAL;\r\n}\r\nret = dma_coerce_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\r\nif (ret)\r\nreturn ret;\r\nsdma = devm_kzalloc(&pdev->dev, sizeof(*sdma), GFP_KERNEL);\r\nif (!sdma)\r\nreturn -ENOMEM;\r\nspin_lock_init(&sdma->channel_0_lock);\r\nsdma->dev = &pdev->dev;\r\nsdma->drvdata = drvdata;\r\nirq = platform_get_irq(pdev, 0);\r\nif (irq < 0)\r\nreturn irq;\r\niores = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nsdma->regs = devm_ioremap_resource(&pdev->dev, iores);\r\nif (IS_ERR(sdma->regs))\r\nreturn PTR_ERR(sdma->regs);\r\nsdma->clk_ipg = devm_clk_get(&pdev->dev, "ipg");\r\nif (IS_ERR(sdma->clk_ipg))\r\nreturn PTR_ERR(sdma->clk_ipg);\r\nsdma->clk_ahb = devm_clk_get(&pdev->dev, "ahb");\r\nif (IS_ERR(sdma->clk_ahb))\r\nreturn PTR_ERR(sdma->clk_ahb);\r\nclk_prepare(sdma->clk_ipg);\r\nclk_prepare(sdma->clk_ahb);\r\nret = devm_request_irq(&pdev->dev, irq, sdma_int_handler, 0, "sdma",\r\nsdma);\r\nif (ret)\r\nreturn ret;\r\nsdma->script_addrs = kzalloc(sizeof(*sdma->script_addrs), GFP_KERNEL);\r\nif (!sdma->script_addrs)\r\nreturn -ENOMEM;\r\nsaddr_arr = (s32 *)sdma->script_addrs;\r\nfor (i = 0; i < SDMA_SCRIPT_ADDRS_ARRAY_SIZE_V1; i++)\r\nsaddr_arr[i] = -EINVAL;\r\ndma_cap_set(DMA_SLAVE, sdma->dma_device.cap_mask);\r\ndma_cap_set(DMA_CYCLIC, sdma->dma_device.cap_mask);\r\nINIT_LIST_HEAD(&sdma->dma_device.channels);\r\nfor (i = 0; i < MAX_DMA_CHANNELS; i++) {\r\nstruct sdma_channel *sdmac = &sdma->channel[i];\r\nsdmac->sdma = sdma;\r\nspin_lock_init(&sdmac->lock);\r\nsdmac->chan.device = &sdma->dma_device;\r\ndma_cookie_init(&sdmac->chan);\r\nsdmac->channel = i;\r\ntasklet_init(&sdmac->tasklet, sdma_tasklet,\r\n(unsigned long) sdmac);\r\nif (i)\r\nlist_add_tail(&sdmac->chan.device_node,\r\n&sdma->dma_device.channels);\r\n}\r\nret = sdma_init(sdma);\r\nif (ret)\r\ngoto err_init;\r\nret = sdma_event_remap(sdma);\r\nif (ret)\r\ngoto err_init;\r\nif (sdma->drvdata->script_addrs)\r\nsdma_add_scripts(sdma, sdma->drvdata->script_addrs);\r\nif (pdata && pdata->script_addrs)\r\nsdma_add_scripts(sdma, pdata->script_addrs);\r\nif (pdata) {\r\nret = sdma_get_firmware(sdma, pdata->fw_name);\r\nif (ret)\r\ndev_warn(&pdev->dev, "failed to get firmware from platform data\n");\r\n} else {\r\nret = of_property_read_string(np, "fsl,sdma-ram-script-name",\r\n&fw_name);\r\nif (ret)\r\ndev_warn(&pdev->dev, "failed to get firmware name\n");\r\nelse {\r\nret = sdma_get_firmware(sdma, fw_name);\r\nif (ret)\r\ndev_warn(&pdev->dev, "failed to get firmware from device tree\n");\r\n}\r\n}\r\nsdma->dma_device.dev = &pdev->dev;\r\nsdma->dma_device.device_alloc_chan_resources = sdma_alloc_chan_resources;\r\nsdma->dma_device.device_free_chan_resources = sdma_free_chan_resources;\r\nsdma->dma_device.device_tx_status = sdma_tx_status;\r\nsdma->dma_device.device_prep_slave_sg = sdma_prep_slave_sg;\r\nsdma->dma_device.device_prep_dma_cyclic = sdma_prep_dma_cyclic;\r\nsdma->dma_device.device_config = sdma_config;\r\nsdma->dma_device.device_terminate_all = sdma_disable_channel;\r\nsdma->dma_device.src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\nsdma->dma_device.dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\nsdma->dma_device.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\r\nsdma->dma_device.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\r\nsdma->dma_device.device_issue_pending = sdma_issue_pending;\r\nsdma->dma_device.dev->dma_parms = &sdma->dma_parms;\r\ndma_set_max_seg_size(sdma->dma_device.dev, 65535);\r\nplatform_set_drvdata(pdev, sdma);\r\nret = dma_async_device_register(&sdma->dma_device);\r\nif (ret) {\r\ndev_err(&pdev->dev, "unable to register\n");\r\ngoto err_init;\r\n}\r\nif (np) {\r\nret = of_dma_controller_register(np, sdma_xlate, sdma);\r\nif (ret) {\r\ndev_err(&pdev->dev, "failed to register controller\n");\r\ngoto err_register;\r\n}\r\nspba_bus = of_find_compatible_node(NULL, NULL, "fsl,spba-bus");\r\nret = of_address_to_resource(spba_bus, 0, &spba_res);\r\nif (!ret) {\r\nsdma->spba_start_addr = spba_res.start;\r\nsdma->spba_end_addr = spba_res.end;\r\n}\r\nof_node_put(spba_bus);\r\n}\r\nreturn 0;\r\nerr_register:\r\ndma_async_device_unregister(&sdma->dma_device);\r\nerr_init:\r\nkfree(sdma->script_addrs);\r\nreturn ret;\r\n}\r\nstatic int sdma_remove(struct platform_device *pdev)\r\n{\r\nstruct sdma_engine *sdma = platform_get_drvdata(pdev);\r\nint i;\r\ndma_async_device_unregister(&sdma->dma_device);\r\nkfree(sdma->script_addrs);\r\nfor (i = 0; i < MAX_DMA_CHANNELS; i++) {\r\nstruct sdma_channel *sdmac = &sdma->channel[i];\r\ntasklet_kill(&sdmac->tasklet);\r\n}\r\nplatform_set_drvdata(pdev, NULL);\r\nreturn 0;\r\n}
