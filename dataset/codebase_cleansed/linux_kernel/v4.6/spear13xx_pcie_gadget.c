static void enable_dbi_access(struct pcie_app_reg __iomem *app_reg)\r\n{\r\nwritel(readl(&app_reg->slv_armisc) | (1 << AXI_OP_DBI_ACCESS_ID),\r\n&app_reg->slv_armisc);\r\nwritel(readl(&app_reg->slv_awmisc) | (1 << AXI_OP_DBI_ACCESS_ID),\r\n&app_reg->slv_awmisc);\r\n}\r\nstatic void disable_dbi_access(struct pcie_app_reg __iomem *app_reg)\r\n{\r\nwritel(readl(&app_reg->slv_armisc) & ~(1 << AXI_OP_DBI_ACCESS_ID),\r\n&app_reg->slv_armisc);\r\nwritel(readl(&app_reg->slv_awmisc) & ~(1 << AXI_OP_DBI_ACCESS_ID),\r\n&app_reg->slv_awmisc);\r\n}\r\nstatic void spear_dbi_read_reg(struct spear_pcie_gadget_config *config,\r\nint where, int size, u32 *val)\r\n{\r\nstruct pcie_app_reg __iomem *app_reg = config->va_app_base;\r\nulong va_address;\r\nenable_dbi_access(app_reg);\r\nva_address = (ulong)config->va_dbi_base + (where & ~0x3);\r\n*val = readl(va_address);\r\nif (size == 1)\r\n*val = (*val >> (8 * (where & 3))) & 0xff;\r\nelse if (size == 2)\r\n*val = (*val >> (8 * (where & 3))) & 0xffff;\r\ndisable_dbi_access(app_reg);\r\n}\r\nstatic void spear_dbi_write_reg(struct spear_pcie_gadget_config *config,\r\nint where, int size, u32 val)\r\n{\r\nstruct pcie_app_reg __iomem *app_reg = config->va_app_base;\r\nulong va_address;\r\nenable_dbi_access(app_reg);\r\nva_address = (ulong)config->va_dbi_base + (where & ~0x3);\r\nif (size == 4)\r\nwritel(val, va_address);\r\nelse if (size == 2)\r\nwritew(val, va_address + (where & 2));\r\nelse if (size == 1)\r\nwriteb(val, va_address + (where & 3));\r\ndisable_dbi_access(app_reg);\r\n}\r\nstatic int pci_find_own_next_cap_ttl(struct spear_pcie_gadget_config *config,\r\nu32 pos, int cap, int *ttl)\r\n{\r\nu32 id;\r\nwhile ((*ttl)--) {\r\nspear_dbi_read_reg(config, pos, 1, &pos);\r\nif (pos < 0x40)\r\nbreak;\r\npos &= ~3;\r\nspear_dbi_read_reg(config, pos + PCI_CAP_LIST_ID, 1, &id);\r\nif (id == 0xff)\r\nbreak;\r\nif (id == cap)\r\nreturn pos;\r\npos += PCI_CAP_LIST_NEXT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int pci_find_own_next_cap(struct spear_pcie_gadget_config *config,\r\nu32 pos, int cap)\r\n{\r\nint ttl = PCI_FIND_CAP_TTL;\r\nreturn pci_find_own_next_cap_ttl(config, pos, cap, &ttl);\r\n}\r\nstatic int pci_find_own_cap_start(struct spear_pcie_gadget_config *config,\r\nu8 hdr_type)\r\n{\r\nu32 status;\r\nspear_dbi_read_reg(config, PCI_STATUS, 2, &status);\r\nif (!(status & PCI_STATUS_CAP_LIST))\r\nreturn 0;\r\nswitch (hdr_type) {\r\ncase PCI_HEADER_TYPE_NORMAL:\r\ncase PCI_HEADER_TYPE_BRIDGE:\r\nreturn PCI_CAPABILITY_LIST;\r\ncase PCI_HEADER_TYPE_CARDBUS:\r\nreturn PCI_CB_CAPABILITY_LIST;\r\ndefault:\r\nreturn 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic int pci_find_own_capability(struct spear_pcie_gadget_config *config,\r\nint cap)\r\n{\r\nu32 pos;\r\nu32 hdr_type;\r\nspear_dbi_read_reg(config, PCI_HEADER_TYPE, 1, &hdr_type);\r\npos = pci_find_own_cap_start(config, hdr_type);\r\nif (pos)\r\npos = pci_find_own_next_cap(config, pos, cap);\r\nreturn pos;\r\n}\r\nstatic irqreturn_t spear_pcie_gadget_irq(int irq, void *dev_id)\r\n{\r\nreturn 0;\r\n}\r\nstatic struct pcie_gadget_target *to_target(struct config_item *item)\r\n{\r\nreturn item ?\r\ncontainer_of(to_configfs_subsystem(to_config_group(item)),\r\nstruct pcie_gadget_target, subsys) : NULL;\r\n}\r\nstatic ssize_t pcie_gadget_link_show(struct config_item *item, char *buf)\r\n{\r\nstruct pcie_app_reg __iomem *app_reg = to_target(item)->va_app_base;\r\nif (readl(&app_reg->app_status_1) & ((u32)1 << XMLH_LINK_UP_ID))\r\nreturn sprintf(buf, "UP");\r\nelse\r\nreturn sprintf(buf, "DOWN");\r\n}\r\nstatic ssize_t pcie_gadget_link_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nstruct pcie_app_reg __iomem *app_reg = to_target(item)->va_app_base;\r\nif (sysfs_streq(buf, "UP"))\r\nwritel(readl(&app_reg->app_ctrl_0) | (1 << APP_LTSSM_ENABLE_ID),\r\n&app_reg->app_ctrl_0);\r\nelse if (sysfs_streq(buf, "DOWN"))\r\nwritel(readl(&app_reg->app_ctrl_0)\r\n& ~(1 << APP_LTSSM_ENABLE_ID),\r\n&app_reg->app_ctrl_0);\r\nelse\r\nreturn -EINVAL;\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_int_type_show(struct config_item *item, char *buf)\r\n{\r\nreturn sprintf(buf, "%s", to_target(item)->int_type);\r\n}\r\nstatic ssize_t pcie_gadget_int_type_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nstruct spear_pcie_gadget_config *config = to_target(item)\r\nu32 cap, vec, flags;\r\nulong vector;\r\nif (sysfs_streq(buf, "INTA"))\r\nspear_dbi_write_reg(config, PCI_INTERRUPT_LINE, 1, 1);\r\nelse if (sysfs_streq(buf, "MSI")) {\r\nvector = config->requested_msi;\r\nvec = 0;\r\nwhile (vector > 1) {\r\nvector /= 2;\r\nvec++;\r\n}\r\nspear_dbi_write_reg(config, PCI_INTERRUPT_LINE, 1, 0);\r\ncap = pci_find_own_capability(config, PCI_CAP_ID_MSI);\r\nspear_dbi_read_reg(config, cap + PCI_MSI_FLAGS, 1, &flags);\r\nflags &= ~PCI_MSI_FLAGS_QMASK;\r\nflags |= vec << 1;\r\nspear_dbi_write_reg(config, cap + PCI_MSI_FLAGS, 1, flags);\r\n} else\r\nreturn -EINVAL;\r\nstrcpy(config->int_type, buf);\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_no_of_msi_show(struct config_item *item, char *buf)\r\n{\r\nstruct spear_pcie_gadget_config *config = to_target(item)\r\nstruct pcie_app_reg __iomem *app_reg = to_target(item)->va_app_base;\r\nu32 cap, vec, flags;\r\nulong vector;\r\nif ((readl(&app_reg->msg_status) & (1 << CFG_MSI_EN_ID))\r\n!= (1 << CFG_MSI_EN_ID))\r\nvector = 0;\r\nelse {\r\ncap = pci_find_own_capability(config, PCI_CAP_ID_MSI);\r\nspear_dbi_read_reg(config, cap + PCI_MSI_FLAGS, 1, &flags);\r\nflags &= ~PCI_MSI_FLAGS_QSIZE;\r\nvec = flags >> 4;\r\nvector = 1;\r\nwhile (vec--)\r\nvector *= 2;\r\n}\r\nconfig->configured_msi = vector;\r\nreturn sprintf(buf, "%lu", vector);\r\n}\r\nstatic ssize_t pcie_gadget_no_of_msi_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nint ret;\r\nret = kstrtoul(buf, 0, &to_target(item)->requested_msi);\r\nif (ret)\r\nreturn ret;\r\nif (config->requested_msi > 32)\r\nconfig->requested_msi = 32;\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_inta_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nstruct pcie_app_reg __iomem *app_reg = to_target(item)->va_app_base;\r\nulong en;\r\nint ret;\r\nret = kstrtoul(buf, 0, &en);\r\nif (ret)\r\nreturn ret;\r\nif (en)\r\nwritel(readl(&app_reg->app_ctrl_0) | (1 << SYS_INT_ID),\r\n&app_reg->app_ctrl_0);\r\nelse\r\nwritel(readl(&app_reg->app_ctrl_0) & ~(1 << SYS_INT_ID),\r\n&app_reg->app_ctrl_0);\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_send_msi_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nstruct spear_pcie_gadget_config *config = to_target(item)\r\nstruct pcie_app_reg __iomem *app_reg = config->va_app_base;\r\nulong vector;\r\nu32 ven_msi;\r\nint ret;\r\nret = kstrtoul(buf, 0, &vector);\r\nif (ret)\r\nreturn ret;\r\nif (!config->configured_msi)\r\nreturn -EINVAL;\r\nif (vector >= config->configured_msi)\r\nreturn -EINVAL;\r\nven_msi = readl(&app_reg->ven_msi_1);\r\nven_msi &= ~VEN_MSI_FUN_NUM_MASK;\r\nven_msi |= 0 << VEN_MSI_FUN_NUM_ID;\r\nven_msi &= ~VEN_MSI_TC_MASK;\r\nven_msi |= 0 << VEN_MSI_TC_ID;\r\nven_msi &= ~VEN_MSI_VECTOR_MASK;\r\nven_msi |= vector << VEN_MSI_VECTOR_ID;\r\nven_msi |= VEN_MSI_REQ_EN;\r\nwritel(ven_msi, &app_reg->ven_msi_1);\r\nudelay(1);\r\nven_msi &= ~VEN_MSI_REQ_EN;\r\nwritel(ven_msi, &app_reg->ven_msi_1);\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_vendor_id_show(struct config_item *item, char *buf)\r\n{\r\nu32 id;\r\nspear_dbi_read_reg(to_target(item), PCI_VENDOR_ID, 2, &id);\r\nreturn sprintf(buf, "%x", id);\r\n}\r\nstatic ssize_t pcie_gadget_vendor_id_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nulong id;\r\nint ret;\r\nret = kstrtoul(buf, 0, &id);\r\nif (ret)\r\nreturn ret;\r\nspear_dbi_write_reg(to_target(item), PCI_VENDOR_ID, 2, id);\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_device_id_show(struct config_item *item, char *buf)\r\n{\r\nu32 id;\r\nspear_dbi_read_reg(to_target(item), PCI_DEVICE_ID, 2, &id);\r\nreturn sprintf(buf, "%x", id);\r\n}\r\nstatic ssize_t pcie_gadget_device_id_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nulong id;\r\nint ret;\r\nret = kstrtoul(buf, 0, &id);\r\nif (ret)\r\nreturn ret;\r\nspear_dbi_write_reg(to_target(item), PCI_DEVICE_ID, 2, id);\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_bar0_size_show(struct config_item *item, char *buf)\r\n{\r\nreturn sprintf(buf, "%lx", to_target(item)->bar0_size);\r\n}\r\nstatic ssize_t pcie_gadget_bar0_size_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nstruct spear_pcie_gadget_config *config = to_target(item)\r\nulong size;\r\nu32 pos, pos1;\r\nu32 no_of_bit = 0;\r\nint ret;\r\nret = kstrtoul(buf, 0, &size);\r\nif (ret)\r\nreturn ret;\r\nif (size <= 0x100)\r\nsize = 0x100;\r\nelse if (size >= 0x100000)\r\nsize = 0x100000;\r\nelse {\r\npos = 0;\r\npos1 = 0;\r\nwhile (pos < 21) {\r\npos = find_next_bit((ulong *)&size, 21, pos);\r\nif (pos != 21)\r\npos1 = pos + 1;\r\npos++;\r\nno_of_bit++;\r\n}\r\nif (no_of_bit == 2)\r\npos1--;\r\nsize = 1 << pos1;\r\n}\r\nconfig->bar0_size = size;\r\nspear_dbi_write_reg(config, PCIE_BAR0_MASK_REG, 4, size - 1);\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_bar0_address_show(struct config_item *item,\r\nchar *buf)\r\n{\r\nstruct pcie_app_reg __iomem *app_reg = to_target(item)->va_app_base;\r\nu32 address = readl(&app_reg->pim0_mem_addr_start);\r\nreturn sprintf(buf, "%x", address);\r\n}\r\nstatic ssize_t pcie_gadget_bar0_address_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nstruct spear_pcie_gadget_config *config = to_target(item)\r\nstruct pcie_app_reg __iomem *app_reg = config->va_app_base;\r\nulong address;\r\nint ret;\r\nret = kstrtoul(buf, 0, &address);\r\nif (ret)\r\nreturn ret;\r\naddress &= ~(config->bar0_size - 1);\r\nif (config->va_bar0_address)\r\niounmap(config->va_bar0_address);\r\nconfig->va_bar0_address = ioremap(address, config->bar0_size);\r\nif (!config->va_bar0_address)\r\nreturn -ENOMEM;\r\nwritel(address, &app_reg->pim0_mem_addr_start);\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_bar0_rw_offset_show(struct config_item *item,\r\nchar *buf)\r\n{\r\nreturn sprintf(buf, "%lx", to_target(item)->bar0_rw_offset);\r\n}\r\nstatic ssize_t pcie_gadget_bar0_rw_offset_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nulong offset;\r\nint ret;\r\nret = kstrtoul(buf, 0, &offset);\r\nif (ret)\r\nreturn ret;\r\nif (offset % 4)\r\nreturn -EINVAL;\r\nto_target(item)->bar0_rw_offset = offset;\r\nreturn count;\r\n}\r\nstatic ssize_t pcie_gadget_bar0_data_show(struct config_item *item, char *buf)\r\n{\r\nstruct spear_pcie_gadget_config *config = to_target(item)\r\nulong data;\r\nif (!config->va_bar0_address)\r\nreturn -ENOMEM;\r\ndata = readl((ulong)config->va_bar0_address + config->bar0_rw_offset);\r\nreturn sprintf(buf, "%lx", data);\r\n}\r\nstatic ssize_t pcie_gadget_bar0_data_store(struct config_item *item,\r\nconst char *buf, size_t count)\r\n{\r\nstruct spear_pcie_gadget_config *config = to_target(item)\r\nulong data;\r\nint ret;\r\nret = kstrtoul(buf, 0, &data);\r\nif (ret)\r\nreturn ret;\r\nif (!config->va_bar0_address)\r\nreturn -ENOMEM;\r\nwritel(data, (ulong)config->va_bar0_address + config->bar0_rw_offset);\r\nreturn count;\r\n}\r\nstatic void spear13xx_pcie_device_init(struct spear_pcie_gadget_config *config)\r\n{\r\nstruct pcie_app_reg __iomem *app_reg = config->va_app_base;\r\nwritel(config->base, &app_reg->in0_mem_addr_start);\r\nwritel(app_reg->in0_mem_addr_start + IN0_MEM_SIZE,\r\n&app_reg->in0_mem_addr_limit);\r\nwritel(app_reg->in0_mem_addr_limit + 1, &app_reg->in1_mem_addr_start);\r\nwritel(app_reg->in1_mem_addr_start + IN1_MEM_SIZE,\r\n&app_reg->in1_mem_addr_limit);\r\nwritel(app_reg->in1_mem_addr_limit + 1, &app_reg->in_io_addr_start);\r\nwritel(app_reg->in_io_addr_start + IN_IO_SIZE,\r\n&app_reg->in_io_addr_limit);\r\nwritel(app_reg->in_io_addr_limit + 1, &app_reg->in_cfg0_addr_start);\r\nwritel(app_reg->in_cfg0_addr_start + IN_CFG0_SIZE,\r\n&app_reg->in_cfg0_addr_limit);\r\nwritel(app_reg->in_cfg0_addr_limit + 1, &app_reg->in_cfg1_addr_start);\r\nwritel(app_reg->in_cfg1_addr_start + IN_CFG1_SIZE,\r\n&app_reg->in_cfg1_addr_limit);\r\nwritel(app_reg->in_cfg1_addr_limit + 1, &app_reg->in_msg_addr_start);\r\nwritel(app_reg->in_msg_addr_start + IN_MSG_SIZE,\r\n&app_reg->in_msg_addr_limit);\r\nwritel(app_reg->in0_mem_addr_start, &app_reg->pom0_mem_addr_start);\r\nwritel(app_reg->in1_mem_addr_start, &app_reg->pom1_mem_addr_start);\r\nwritel(app_reg->in_io_addr_start, &app_reg->pom_io_addr_start);\r\nconfig->bar0_size = INBOUND_ADDR_MASK + 1;\r\nspear_dbi_write_reg(config, PCIE_BAR0_MASK_REG, 4, INBOUND_ADDR_MASK);\r\nspear_dbi_write_reg(config, PCI_BASE_ADDRESS_0, 4, 0xC);\r\nconfig->va_bar0_address = ioremap(SPEAR13XX_SYSRAM1_BASE,\r\nconfig->bar0_size);\r\nwritel(SPEAR13XX_SYSRAM1_BASE, &app_reg->pim0_mem_addr_start);\r\nwritel(0, &app_reg->pim1_mem_addr_start);\r\nwritel(INBOUND_ADDR_MASK + 1, &app_reg->mem0_addr_offset_limit);\r\nwritel(0x0, &app_reg->pim_io_addr_start);\r\nwritel(0x0, &app_reg->pim_io_addr_start);\r\nwritel(0x0, &app_reg->pim_rom_addr_start);\r\nwritel(DEVICE_TYPE_EP | (1 << MISCTRL_EN_ID)\r\n| ((u32)1 << REG_TRANSLATION_ENABLE),\r\n&app_reg->app_ctrl_0);\r\nwritel(0, &app_reg->int_mask);\r\nspear_dbi_write_reg(config, PCI_INTERRUPT_LINE, 1, 1);\r\n}\r\nstatic int spear_pcie_gadget_probe(struct platform_device *pdev)\r\n{\r\nstruct resource *res0, *res1;\r\nunsigned int status = 0;\r\nint irq;\r\nstruct clk *clk;\r\nstatic struct pcie_gadget_target *target;\r\nstruct spear_pcie_gadget_config *config;\r\nstruct config_item *cg_item;\r\nstruct configfs_subsystem *subsys;\r\ntarget = devm_kzalloc(&pdev->dev, sizeof(*target), GFP_KERNEL);\r\nif (!target) {\r\ndev_err(&pdev->dev, "out of memory\n");\r\nreturn -ENOMEM;\r\n}\r\ncg_item = &target->subsys.su_group.cg_item;\r\nsprintf(cg_item->ci_namebuf, "pcie_gadget.%d", pdev->id);\r\ncg_item->ci_type = &pcie_gadget_target_type;\r\nconfig = &target->config;\r\nres0 = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nconfig->va_app_base = devm_ioremap_resource(&pdev->dev, res0);\r\nif (IS_ERR(config->va_app_base)) {\r\ndev_err(&pdev->dev, "ioremap fail\n");\r\nreturn PTR_ERR(config->va_app_base);\r\n}\r\nres1 = platform_get_resource(pdev, IORESOURCE_MEM, 1);\r\nconfig->base = (void __iomem *)res1->start;\r\nconfig->va_dbi_base = devm_ioremap_resource(&pdev->dev, res1);\r\nif (IS_ERR(config->va_dbi_base)) {\r\ndev_err(&pdev->dev, "ioremap fail\n");\r\nreturn PTR_ERR(config->va_dbi_base);\r\n}\r\nplatform_set_drvdata(pdev, target);\r\nirq = platform_get_irq(pdev, 0);\r\nif (irq < 0) {\r\ndev_err(&pdev->dev, "no update irq?\n");\r\nreturn irq;\r\n}\r\nstatus = devm_request_irq(&pdev->dev, irq, spear_pcie_gadget_irq,\r\n0, pdev->name, NULL);\r\nif (status) {\r\ndev_err(&pdev->dev,\r\n"pcie gadget interrupt IRQ%d already claimed\n", irq);\r\nreturn status;\r\n}\r\nsubsys = &target->subsys;\r\nconfig_group_init(&subsys->su_group);\r\nmutex_init(&subsys->su_mutex);\r\nstatus = configfs_register_subsystem(subsys);\r\nif (status)\r\nreturn status;\r\nif (pdev->id == 1) {\r\nclk = clk_get_sys("pcie1", NULL);\r\nif (IS_ERR(clk)) {\r\npr_err("%s:couldn't get clk for pcie1\n", __func__);\r\nreturn PTR_ERR(clk);\r\n}\r\nstatus = clk_enable(clk);\r\nif (status) {\r\npr_err("%s:couldn't enable clk for pcie1\n", __func__);\r\nreturn status;\r\n}\r\n} else if (pdev->id == 2) {\r\nclk = clk_get_sys("pcie2", NULL);\r\nif (IS_ERR(clk)) {\r\npr_err("%s:couldn't get clk for pcie2\n", __func__);\r\nreturn PTR_ERR(clk);\r\n}\r\nstatus = clk_enable(clk);\r\nif (status) {\r\npr_err("%s:couldn't enable clk for pcie2\n", __func__);\r\nreturn status;\r\n}\r\n}\r\nspear13xx_pcie_device_init(config);\r\nreturn 0;\r\n}\r\nstatic int spear_pcie_gadget_remove(struct platform_device *pdev)\r\n{\r\nstatic struct pcie_gadget_target *target;\r\ntarget = platform_get_drvdata(pdev);\r\nconfigfs_unregister_subsystem(&target->subsys);\r\nreturn 0;\r\n}\r\nstatic void spear_pcie_gadget_shutdown(struct platform_device *pdev)\r\n{\r\n}
