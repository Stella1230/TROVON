static void __mcpm_cpu_going_down(unsigned int cpu, unsigned int cluster)\r\n{\r\nmcpm_sync.clusters[cluster].cpus[cpu].cpu = CPU_GOING_DOWN;\r\nsync_cache_w(&mcpm_sync.clusters[cluster].cpus[cpu].cpu);\r\n}\r\nstatic void __mcpm_cpu_down(unsigned int cpu, unsigned int cluster)\r\n{\r\ndmb();\r\nmcpm_sync.clusters[cluster].cpus[cpu].cpu = CPU_DOWN;\r\nsync_cache_w(&mcpm_sync.clusters[cluster].cpus[cpu].cpu);\r\nsev();\r\n}\r\nstatic void __mcpm_outbound_leave_critical(unsigned int cluster, int state)\r\n{\r\ndmb();\r\nmcpm_sync.clusters[cluster].cluster = state;\r\nsync_cache_w(&mcpm_sync.clusters[cluster].cluster);\r\nsev();\r\n}\r\nstatic bool __mcpm_outbound_enter_critical(unsigned int cpu, unsigned int cluster)\r\n{\r\nunsigned int i;\r\nstruct mcpm_sync_struct *c = &mcpm_sync.clusters[cluster];\r\nc->cluster = CLUSTER_GOING_DOWN;\r\nsync_cache_w(&c->cluster);\r\nsync_cache_r(&c->inbound);\r\nif (c->inbound == INBOUND_COMING_UP)\r\ngoto abort;\r\nsync_cache_r(&c->cpus);\r\nfor (i = 0; i < MAX_CPUS_PER_CLUSTER; i++) {\r\nint cpustate;\r\nif (i == cpu)\r\ncontinue;\r\nwhile (1) {\r\ncpustate = c->cpus[i].cpu;\r\nif (cpustate != CPU_GOING_DOWN)\r\nbreak;\r\nwfe();\r\nsync_cache_r(&c->cpus[i].cpu);\r\n}\r\nswitch (cpustate) {\r\ncase CPU_DOWN:\r\ncontinue;\r\ndefault:\r\ngoto abort;\r\n}\r\n}\r\nreturn true;\r\nabort:\r\n__mcpm_outbound_leave_critical(cluster, CLUSTER_UP);\r\nreturn false;\r\n}\r\nstatic int __mcpm_cluster_state(unsigned int cluster)\r\n{\r\nsync_cache_r(&mcpm_sync.clusters[cluster].cluster);\r\nreturn mcpm_sync.clusters[cluster].cluster;\r\n}\r\nvoid mcpm_set_entry_vector(unsigned cpu, unsigned cluster, void *ptr)\r\n{\r\nunsigned long val = ptr ? virt_to_phys(ptr) : 0;\r\nmcpm_entry_vectors[cluster][cpu] = val;\r\nsync_cache_w(&mcpm_entry_vectors[cluster][cpu]);\r\n}\r\nvoid mcpm_set_early_poke(unsigned cpu, unsigned cluster,\r\nunsigned long poke_phys_addr, unsigned long poke_val)\r\n{\r\nunsigned long *poke = &mcpm_entry_early_pokes[cluster][cpu][0];\r\npoke[0] = poke_phys_addr;\r\npoke[1] = poke_val;\r\n__sync_cache_range_w(poke, 2 * sizeof(*poke));\r\n}\r\nint __init mcpm_platform_register(const struct mcpm_platform_ops *ops)\r\n{\r\nif (platform_ops)\r\nreturn -EBUSY;\r\nplatform_ops = ops;\r\nreturn 0;\r\n}\r\nbool mcpm_is_available(void)\r\n{\r\nreturn (platform_ops) ? true : false;\r\n}\r\nstatic inline bool mcpm_cluster_unused(unsigned int cluster)\r\n{\r\nint i, cnt;\r\nfor (i = 0, cnt = 0; i < MAX_CPUS_PER_CLUSTER; i++)\r\ncnt |= mcpm_cpu_use_count[cluster][i];\r\nreturn !cnt;\r\n}\r\nint mcpm_cpu_power_up(unsigned int cpu, unsigned int cluster)\r\n{\r\nbool cpu_is_down, cluster_is_down;\r\nint ret = 0;\r\npr_debug("%s: cpu %u cluster %u\n", __func__, cpu, cluster);\r\nif (!platform_ops)\r\nreturn -EUNATCH;\r\nmight_sleep();\r\nlocal_irq_disable();\r\narch_spin_lock(&mcpm_lock);\r\ncpu_is_down = !mcpm_cpu_use_count[cluster][cpu];\r\ncluster_is_down = mcpm_cluster_unused(cluster);\r\nmcpm_cpu_use_count[cluster][cpu]++;\r\nBUG_ON(mcpm_cpu_use_count[cluster][cpu] != 1 &&\r\nmcpm_cpu_use_count[cluster][cpu] != 2);\r\nif (cluster_is_down)\r\nret = platform_ops->cluster_powerup(cluster);\r\nif (cpu_is_down && !ret)\r\nret = platform_ops->cpu_powerup(cpu, cluster);\r\narch_spin_unlock(&mcpm_lock);\r\nlocal_irq_enable();\r\nreturn ret;\r\n}\r\nvoid mcpm_cpu_power_down(void)\r\n{\r\nunsigned int mpidr, cpu, cluster;\r\nbool cpu_going_down, last_man;\r\nphys_reset_t phys_reset;\r\nmpidr = read_cpuid_mpidr();\r\ncpu = MPIDR_AFFINITY_LEVEL(mpidr, 0);\r\ncluster = MPIDR_AFFINITY_LEVEL(mpidr, 1);\r\npr_debug("%s: cpu %u cluster %u\n", __func__, cpu, cluster);\r\nif (WARN_ON_ONCE(!platform_ops))\r\nreturn;\r\nBUG_ON(!irqs_disabled());\r\nsetup_mm_for_reboot();\r\n__mcpm_cpu_going_down(cpu, cluster);\r\narch_spin_lock(&mcpm_lock);\r\nBUG_ON(__mcpm_cluster_state(cluster) != CLUSTER_UP);\r\nmcpm_cpu_use_count[cluster][cpu]--;\r\nBUG_ON(mcpm_cpu_use_count[cluster][cpu] != 0 &&\r\nmcpm_cpu_use_count[cluster][cpu] != 1);\r\ncpu_going_down = !mcpm_cpu_use_count[cluster][cpu];\r\nlast_man = mcpm_cluster_unused(cluster);\r\nif (last_man && __mcpm_outbound_enter_critical(cpu, cluster)) {\r\nplatform_ops->cpu_powerdown_prepare(cpu, cluster);\r\nplatform_ops->cluster_powerdown_prepare(cluster);\r\narch_spin_unlock(&mcpm_lock);\r\nplatform_ops->cluster_cache_disable();\r\n__mcpm_outbound_leave_critical(cluster, CLUSTER_DOWN);\r\n} else {\r\nif (cpu_going_down)\r\nplatform_ops->cpu_powerdown_prepare(cpu, cluster);\r\narch_spin_unlock(&mcpm_lock);\r\nplatform_ops->cpu_cache_disable();\r\n}\r\n__mcpm_cpu_down(cpu, cluster);\r\nif (cpu_going_down)\r\nwfi();\r\nphys_reset = (phys_reset_t)(unsigned long)virt_to_phys(cpu_reset);\r\nphys_reset(virt_to_phys(mcpm_entry_point));\r\nBUG();\r\n}\r\nint mcpm_wait_for_cpu_powerdown(unsigned int cpu, unsigned int cluster)\r\n{\r\nint ret;\r\nif (WARN_ON_ONCE(!platform_ops || !platform_ops->wait_for_powerdown))\r\nreturn -EUNATCH;\r\nret = platform_ops->wait_for_powerdown(cpu, cluster);\r\nif (ret)\r\npr_warn("%s: cpu %u, cluster %u failed to power down (%d)\n",\r\n__func__, cpu, cluster, ret);\r\nreturn ret;\r\n}\r\nvoid mcpm_cpu_suspend(void)\r\n{\r\nif (WARN_ON_ONCE(!platform_ops))\r\nreturn;\r\nif (platform_ops->cpu_suspend_prepare) {\r\nunsigned int mpidr = read_cpuid_mpidr();\r\nunsigned int cpu = MPIDR_AFFINITY_LEVEL(mpidr, 0);\r\nunsigned int cluster = MPIDR_AFFINITY_LEVEL(mpidr, 1);\r\narch_spin_lock(&mcpm_lock);\r\nplatform_ops->cpu_suspend_prepare(cpu, cluster);\r\narch_spin_unlock(&mcpm_lock);\r\n}\r\nmcpm_cpu_power_down();\r\n}\r\nint mcpm_cpu_powered_up(void)\r\n{\r\nunsigned int mpidr, cpu, cluster;\r\nbool cpu_was_down, first_man;\r\nunsigned long flags;\r\nif (!platform_ops)\r\nreturn -EUNATCH;\r\nmpidr = read_cpuid_mpidr();\r\ncpu = MPIDR_AFFINITY_LEVEL(mpidr, 0);\r\ncluster = MPIDR_AFFINITY_LEVEL(mpidr, 1);\r\nlocal_irq_save(flags);\r\narch_spin_lock(&mcpm_lock);\r\ncpu_was_down = !mcpm_cpu_use_count[cluster][cpu];\r\nfirst_man = mcpm_cluster_unused(cluster);\r\nif (first_man && platform_ops->cluster_is_up)\r\nplatform_ops->cluster_is_up(cluster);\r\nif (cpu_was_down)\r\nmcpm_cpu_use_count[cluster][cpu] = 1;\r\nif (platform_ops->cpu_is_up)\r\nplatform_ops->cpu_is_up(cpu, cluster);\r\narch_spin_unlock(&mcpm_lock);\r\nlocal_irq_restore(flags);\r\nreturn 0;\r\n}\r\nstatic int __init nocache_trampoline(unsigned long _arg)\r\n{\r\nvoid (*cache_disable)(void) = (void *)_arg;\r\nunsigned int mpidr = read_cpuid_mpidr();\r\nunsigned int cpu = MPIDR_AFFINITY_LEVEL(mpidr, 0);\r\nunsigned int cluster = MPIDR_AFFINITY_LEVEL(mpidr, 1);\r\nphys_reset_t phys_reset;\r\nmcpm_set_entry_vector(cpu, cluster, cpu_resume);\r\nsetup_mm_for_reboot();\r\n__mcpm_cpu_going_down(cpu, cluster);\r\nBUG_ON(!__mcpm_outbound_enter_critical(cpu, cluster));\r\ncache_disable();\r\n__mcpm_outbound_leave_critical(cluster, CLUSTER_DOWN);\r\n__mcpm_cpu_down(cpu, cluster);\r\nphys_reset = (phys_reset_t)(unsigned long)virt_to_phys(cpu_reset);\r\nphys_reset(virt_to_phys(mcpm_entry_point));\r\nBUG();\r\n}\r\nint __init mcpm_loopback(void (*cache_disable)(void))\r\n{\r\nint ret;\r\nlocal_irq_disable();\r\nlocal_fiq_disable();\r\nret = cpu_pm_enter();\r\nif (!ret) {\r\nret = cpu_suspend((unsigned long)cache_disable, nocache_trampoline);\r\ncpu_pm_exit();\r\n}\r\nlocal_fiq_enable();\r\nlocal_irq_enable();\r\nif (ret)\r\npr_err("%s returned %d\n", __func__, ret);\r\nreturn ret;\r\n}\r\nint __init mcpm_sync_init(\r\nvoid (*power_up_setup)(unsigned int affinity_level))\r\n{\r\nunsigned int i, j, mpidr, this_cluster;\r\nBUILD_BUG_ON(MCPM_SYNC_CLUSTER_SIZE * MAX_NR_CLUSTERS != sizeof mcpm_sync);\r\nBUG_ON((unsigned long)&mcpm_sync & (__CACHE_WRITEBACK_GRANULE - 1));\r\nfor (i = 0; i < MAX_NR_CLUSTERS; i++) {\r\nmcpm_sync.clusters[i].cluster = CLUSTER_DOWN;\r\nmcpm_sync.clusters[i].inbound = INBOUND_NOT_COMING_UP;\r\nfor (j = 0; j < MAX_CPUS_PER_CLUSTER; j++)\r\nmcpm_sync.clusters[i].cpus[j].cpu = CPU_DOWN;\r\n}\r\nmpidr = read_cpuid_mpidr();\r\nthis_cluster = MPIDR_AFFINITY_LEVEL(mpidr, 1);\r\nfor_each_online_cpu(i) {\r\nmcpm_cpu_use_count[this_cluster][i] = 1;\r\nmcpm_sync.clusters[this_cluster].cpus[i].cpu = CPU_UP;\r\n}\r\nmcpm_sync.clusters[this_cluster].cluster = CLUSTER_UP;\r\nsync_cache_w(&mcpm_sync);\r\nif (power_up_setup) {\r\nmcpm_power_up_setup_phys = virt_to_phys(power_up_setup);\r\nsync_cache_w(&mcpm_power_up_setup_phys);\r\n}\r\nreturn 0;\r\n}
