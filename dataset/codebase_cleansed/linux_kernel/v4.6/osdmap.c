char *ceph_osdmap_state_str(char *str, int len, int state)\r\n{\r\nif (!len)\r\nreturn str;\r\nif ((state & CEPH_OSD_EXISTS) && (state & CEPH_OSD_UP))\r\nsnprintf(str, len, "exists, up");\r\nelse if (state & CEPH_OSD_EXISTS)\r\nsnprintf(str, len, "exists");\r\nelse if (state & CEPH_OSD_UP)\r\nsnprintf(str, len, "up");\r\nelse\r\nsnprintf(str, len, "doesn't exist");\r\nreturn str;\r\n}\r\nstatic int calc_bits_of(unsigned int t)\r\n{\r\nint b = 0;\r\nwhile (t) {\r\nt = t >> 1;\r\nb++;\r\n}\r\nreturn b;\r\n}\r\nstatic void calc_pg_masks(struct ceph_pg_pool_info *pi)\r\n{\r\npi->pg_num_mask = (1 << calc_bits_of(pi->pg_num-1)) - 1;\r\npi->pgp_num_mask = (1 << calc_bits_of(pi->pgp_num-1)) - 1;\r\n}\r\nstatic int crush_decode_uniform_bucket(void **p, void *end,\r\nstruct crush_bucket_uniform *b)\r\n{\r\ndout("crush_decode_uniform_bucket %p to %p\n", *p, end);\r\nceph_decode_need(p, end, (1+b->h.size) * sizeof(u32), bad);\r\nb->item_weight = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_list_bucket(void **p, void *end,\r\nstruct crush_bucket_list *b)\r\n{\r\nint j;\r\ndout("crush_decode_list_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nb->sum_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->sum_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++) {\r\nb->item_weights[j] = ceph_decode_32(p);\r\nb->sum_weights[j] = ceph_decode_32(p);\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_tree_bucket(void **p, void *end,\r\nstruct crush_bucket_tree *b)\r\n{\r\nint j;\r\ndout("crush_decode_tree_bucket %p to %p\n", *p, end);\r\nceph_decode_8_safe(p, end, b->num_nodes, bad);\r\nb->node_weights = kcalloc(b->num_nodes, sizeof(u32), GFP_NOFS);\r\nif (b->node_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, b->num_nodes * sizeof(u32), bad);\r\nfor (j = 0; j < b->num_nodes; j++)\r\nb->node_weights[j] = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_straw_bucket(void **p, void *end,\r\nstruct crush_bucket_straw *b)\r\n{\r\nint j;\r\ndout("crush_decode_straw_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nb->straws = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->straws == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++) {\r\nb->item_weights[j] = ceph_decode_32(p);\r\nb->straws[j] = ceph_decode_32(p);\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_straw2_bucket(void **p, void *end,\r\nstruct crush_bucket_straw2 *b)\r\n{\r\nint j;\r\ndout("crush_decode_straw2_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++)\r\nb->item_weights[j] = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int skip_name_map(void **p, void *end)\r\n{\r\nint len;\r\nceph_decode_32_safe(p, end, len ,bad);\r\nwhile (len--) {\r\nint strlen;\r\n*p += sizeof(u32);\r\nceph_decode_32_safe(p, end, strlen, bad);\r\n*p += strlen;\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic struct crush_map *crush_decode(void *pbyval, void *end)\r\n{\r\nstruct crush_map *c;\r\nint err = -EINVAL;\r\nint i, j;\r\nvoid **p = &pbyval;\r\nvoid *start = pbyval;\r\nu32 magic;\r\nu32 num_name_maps;\r\ndout("crush_decode %p to %p len %d\n", *p, end, (int)(end - *p));\r\nc = kzalloc(sizeof(*c), GFP_NOFS);\r\nif (c == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nc->choose_local_tries = 2;\r\nc->choose_local_fallback_tries = 5;\r\nc->choose_total_tries = 19;\r\nc->chooseleaf_descend_once = 0;\r\nceph_decode_need(p, end, 4*sizeof(u32), bad);\r\nmagic = ceph_decode_32(p);\r\nif (magic != CRUSH_MAGIC) {\r\npr_err("crush_decode magic %x != current %x\n",\r\n(unsigned int)magic, (unsigned int)CRUSH_MAGIC);\r\ngoto bad;\r\n}\r\nc->max_buckets = ceph_decode_32(p);\r\nc->max_rules = ceph_decode_32(p);\r\nc->max_devices = ceph_decode_32(p);\r\nc->buckets = kcalloc(c->max_buckets, sizeof(*c->buckets), GFP_NOFS);\r\nif (c->buckets == NULL)\r\ngoto badmem;\r\nc->rules = kcalloc(c->max_rules, sizeof(*c->rules), GFP_NOFS);\r\nif (c->rules == NULL)\r\ngoto badmem;\r\nfor (i = 0; i < c->max_buckets; i++) {\r\nint size = 0;\r\nu32 alg;\r\nstruct crush_bucket *b;\r\nceph_decode_32_safe(p, end, alg, bad);\r\nif (alg == 0) {\r\nc->buckets[i] = NULL;\r\ncontinue;\r\n}\r\ndout("crush_decode bucket %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nswitch (alg) {\r\ncase CRUSH_BUCKET_UNIFORM:\r\nsize = sizeof(struct crush_bucket_uniform);\r\nbreak;\r\ncase CRUSH_BUCKET_LIST:\r\nsize = sizeof(struct crush_bucket_list);\r\nbreak;\r\ncase CRUSH_BUCKET_TREE:\r\nsize = sizeof(struct crush_bucket_tree);\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW:\r\nsize = sizeof(struct crush_bucket_straw);\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW2:\r\nsize = sizeof(struct crush_bucket_straw2);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto bad;\r\n}\r\nBUG_ON(size == 0);\r\nb = c->buckets[i] = kzalloc(size, GFP_NOFS);\r\nif (b == NULL)\r\ngoto badmem;\r\nceph_decode_need(p, end, 4*sizeof(u32), bad);\r\nb->id = ceph_decode_32(p);\r\nb->type = ceph_decode_16(p);\r\nb->alg = ceph_decode_8(p);\r\nb->hash = ceph_decode_8(p);\r\nb->weight = ceph_decode_32(p);\r\nb->size = ceph_decode_32(p);\r\ndout("crush_decode bucket size %d off %x %p to %p\n",\r\nb->size, (int)(*p-start), *p, end);\r\nb->items = kcalloc(b->size, sizeof(__s32), GFP_NOFS);\r\nif (b->items == NULL)\r\ngoto badmem;\r\nb->perm = kcalloc(b->size, sizeof(u32), GFP_NOFS);\r\nif (b->perm == NULL)\r\ngoto badmem;\r\nb->perm_n = 0;\r\nceph_decode_need(p, end, b->size*sizeof(u32), bad);\r\nfor (j = 0; j < b->size; j++)\r\nb->items[j] = ceph_decode_32(p);\r\nswitch (b->alg) {\r\ncase CRUSH_BUCKET_UNIFORM:\r\nerr = crush_decode_uniform_bucket(p, end,\r\n(struct crush_bucket_uniform *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_LIST:\r\nerr = crush_decode_list_bucket(p, end,\r\n(struct crush_bucket_list *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_TREE:\r\nerr = crush_decode_tree_bucket(p, end,\r\n(struct crush_bucket_tree *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW:\r\nerr = crush_decode_straw_bucket(p, end,\r\n(struct crush_bucket_straw *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW2:\r\nerr = crush_decode_straw2_bucket(p, end,\r\n(struct crush_bucket_straw2 *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\n}\r\n}\r\ndout("rule vec is %p\n", c->rules);\r\nfor (i = 0; i < c->max_rules; i++) {\r\nu32 yes;\r\nstruct crush_rule *r;\r\nceph_decode_32_safe(p, end, yes, bad);\r\nif (!yes) {\r\ndout("crush_decode NO rule %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nc->rules[i] = NULL;\r\ncontinue;\r\n}\r\ndout("crush_decode rule %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nceph_decode_32_safe(p, end, yes, bad);\r\n#if BITS_PER_LONG == 32\r\nerr = -EINVAL;\r\nif (yes > (ULONG_MAX - sizeof(*r))\r\n/ sizeof(struct crush_rule_step))\r\ngoto bad;\r\n#endif\r\nr = c->rules[i] = kmalloc(sizeof(*r) +\r\nyes*sizeof(struct crush_rule_step),\r\nGFP_NOFS);\r\nif (r == NULL)\r\ngoto badmem;\r\ndout(" rule %d is at %p\n", i, r);\r\nr->len = yes;\r\nceph_decode_copy_safe(p, end, &r->mask, 4, bad);\r\nceph_decode_need(p, end, r->len*3*sizeof(u32), bad);\r\nfor (j = 0; j < r->len; j++) {\r\nr->steps[j].op = ceph_decode_32(p);\r\nr->steps[j].arg1 = ceph_decode_32(p);\r\nr->steps[j].arg2 = ceph_decode_32(p);\r\n}\r\n}\r\nfor (num_name_maps = 0; num_name_maps < 3; num_name_maps++) {\r\nerr = skip_name_map(p, end);\r\nif (err < 0)\r\ngoto done;\r\n}\r\nceph_decode_need(p, end, 3*sizeof(u32), done);\r\nc->choose_local_tries = ceph_decode_32(p);\r\nc->choose_local_fallback_tries = ceph_decode_32(p);\r\nc->choose_total_tries = ceph_decode_32(p);\r\ndout("crush decode tunable choose_local_tries = %d\n",\r\nc->choose_local_tries);\r\ndout("crush decode tunable choose_local_fallback_tries = %d\n",\r\nc->choose_local_fallback_tries);\r\ndout("crush decode tunable choose_total_tries = %d\n",\r\nc->choose_total_tries);\r\nceph_decode_need(p, end, sizeof(u32), done);\r\nc->chooseleaf_descend_once = ceph_decode_32(p);\r\ndout("crush decode tunable chooseleaf_descend_once = %d\n",\r\nc->chooseleaf_descend_once);\r\nceph_decode_need(p, end, sizeof(u8), done);\r\nc->chooseleaf_vary_r = ceph_decode_8(p);\r\ndout("crush decode tunable chooseleaf_vary_r = %d\n",\r\nc->chooseleaf_vary_r);\r\nceph_decode_need(p, end, sizeof(u8) + sizeof(u32), done);\r\n*p += sizeof(u8) + sizeof(u32);\r\nceph_decode_need(p, end, sizeof(u8), done);\r\nc->chooseleaf_stable = ceph_decode_8(p);\r\ndout("crush decode tunable chooseleaf_stable = %d\n",\r\nc->chooseleaf_stable);\r\ndone:\r\ndout("crush_decode success\n");\r\nreturn c;\r\nbadmem:\r\nerr = -ENOMEM;\r\nbad:\r\ndout("crush_decode fail %d\n", err);\r\ncrush_destroy(c);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic int pgid_cmp(struct ceph_pg l, struct ceph_pg r)\r\n{\r\nif (l.pool < r.pool)\r\nreturn -1;\r\nif (l.pool > r.pool)\r\nreturn 1;\r\nif (l.seed < r.seed)\r\nreturn -1;\r\nif (l.seed > r.seed)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int __insert_pg_mapping(struct ceph_pg_mapping *new,\r\nstruct rb_root *root)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_pg_mapping *pg = NULL;\r\nint c;\r\ndout("__insert_pg_mapping %llx %p\n", *(u64 *)&new->pgid, new);\r\nwhile (*p) {\r\nparent = *p;\r\npg = rb_entry(parent, struct ceph_pg_mapping, node);\r\nc = pgid_cmp(new->pgid, pg->pgid);\r\nif (c < 0)\r\np = &(*p)->rb_left;\r\nelse if (c > 0)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, root);\r\nreturn 0;\r\n}\r\nstatic struct ceph_pg_mapping *__lookup_pg_mapping(struct rb_root *root,\r\nstruct ceph_pg pgid)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct ceph_pg_mapping *pg;\r\nint c;\r\nwhile (n) {\r\npg = rb_entry(n, struct ceph_pg_mapping, node);\r\nc = pgid_cmp(pgid, pg->pgid);\r\nif (c < 0) {\r\nn = n->rb_left;\r\n} else if (c > 0) {\r\nn = n->rb_right;\r\n} else {\r\ndout("__lookup_pg_mapping %lld.%x got %p\n",\r\npgid.pool, pgid.seed, pg);\r\nreturn pg;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic int __remove_pg_mapping(struct rb_root *root, struct ceph_pg pgid)\r\n{\r\nstruct ceph_pg_mapping *pg = __lookup_pg_mapping(root, pgid);\r\nif (pg) {\r\ndout("__remove_pg_mapping %lld.%x %p\n", pgid.pool, pgid.seed,\r\npg);\r\nrb_erase(&pg->node, root);\r\nkfree(pg);\r\nreturn 0;\r\n}\r\ndout("__remove_pg_mapping %lld.%x dne\n", pgid.pool, pgid.seed);\r\nreturn -ENOENT;\r\n}\r\nstatic int __insert_pg_pool(struct rb_root *root, struct ceph_pg_pool_info *new)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_pg_pool_info *pi = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\npi = rb_entry(parent, struct ceph_pg_pool_info, node);\r\nif (new->id < pi->id)\r\np = &(*p)->rb_left;\r\nelse if (new->id > pi->id)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, root);\r\nreturn 0;\r\n}\r\nstatic struct ceph_pg_pool_info *__lookup_pg_pool(struct rb_root *root, u64 id)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nstruct rb_node *n = root->rb_node;\r\nwhile (n) {\r\npi = rb_entry(n, struct ceph_pg_pool_info, node);\r\nif (id < pi->id)\r\nn = n->rb_left;\r\nelse if (id > pi->id)\r\nn = n->rb_right;\r\nelse\r\nreturn pi;\r\n}\r\nreturn NULL;\r\n}\r\nstruct ceph_pg_pool_info *ceph_pg_pool_by_id(struct ceph_osdmap *map, u64 id)\r\n{\r\nreturn __lookup_pg_pool(&map->pg_pools, id);\r\n}\r\nconst char *ceph_pg_pool_name_by_id(struct ceph_osdmap *map, u64 id)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nif (id == CEPH_NOPOOL)\r\nreturn NULL;\r\nif (WARN_ON_ONCE(id > (u64) INT_MAX))\r\nreturn NULL;\r\npi = __lookup_pg_pool(&map->pg_pools, (int) id);\r\nreturn pi ? pi->name : NULL;\r\n}\r\nint ceph_pg_poolid_by_name(struct ceph_osdmap *map, const char *name)\r\n{\r\nstruct rb_node *rbp;\r\nfor (rbp = rb_first(&map->pg_pools); rbp; rbp = rb_next(rbp)) {\r\nstruct ceph_pg_pool_info *pi =\r\nrb_entry(rbp, struct ceph_pg_pool_info, node);\r\nif (pi->name && strcmp(pi->name, name) == 0)\r\nreturn pi->id;\r\n}\r\nreturn -ENOENT;\r\n}\r\nstatic void __remove_pg_pool(struct rb_root *root, struct ceph_pg_pool_info *pi)\r\n{\r\nrb_erase(&pi->node, root);\r\nkfree(pi->name);\r\nkfree(pi);\r\n}\r\nstatic int decode_pool(void **p, void *end, struct ceph_pg_pool_info *pi)\r\n{\r\nu8 ev, cv;\r\nunsigned len, num;\r\nvoid *pool_end;\r\nceph_decode_need(p, end, 2 + 4, bad);\r\nev = ceph_decode_8(p);\r\ncv = ceph_decode_8(p);\r\nif (ev < 5) {\r\npr_warn("got v %d < 5 cv %d of ceph_pg_pool\n", ev, cv);\r\nreturn -EINVAL;\r\n}\r\nif (cv > 9) {\r\npr_warn("got v %d cv %d > 9 of ceph_pg_pool\n", ev, cv);\r\nreturn -EINVAL;\r\n}\r\nlen = ceph_decode_32(p);\r\nceph_decode_need(p, end, len, bad);\r\npool_end = *p + len;\r\npi->type = ceph_decode_8(p);\r\npi->size = ceph_decode_8(p);\r\npi->crush_ruleset = ceph_decode_8(p);\r\npi->object_hash = ceph_decode_8(p);\r\npi->pg_num = ceph_decode_32(p);\r\npi->pgp_num = ceph_decode_32(p);\r\n*p += 4 + 4;\r\n*p += 4;\r\n*p += 8 + 4;\r\nnum = ceph_decode_32(p);\r\nwhile (num--) {\r\n*p += 8;\r\n*p += 1 + 1;\r\nlen = ceph_decode_32(p);\r\n*p += len;\r\n}\r\nnum = ceph_decode_32(p);\r\n*p += num * (8 + 8);\r\n*p += 8;\r\npi->flags = ceph_decode_64(p);\r\n*p += 4;\r\nif (ev >= 7)\r\n*p += 1;\r\nif (ev >= 8)\r\n*p += 8 + 8;\r\nif (ev >= 9) {\r\nnum = ceph_decode_32(p);\r\n*p += num * 8;\r\n*p += 8;\r\n*p += 1;\r\npi->read_tier = ceph_decode_64(p);\r\npi->write_tier = ceph_decode_64(p);\r\n} else {\r\npi->read_tier = -1;\r\npi->write_tier = -1;\r\n}\r\n*p = pool_end;\r\ncalc_pg_masks(pi);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_pool_names(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nu32 num, len;\r\nu64 pool;\r\nceph_decode_32_safe(p, end, num, bad);\r\ndout(" %d pool names\n", num);\r\nwhile (num--) {\r\nceph_decode_64_safe(p, end, pool, bad);\r\nceph_decode_32_safe(p, end, len, bad);\r\ndout(" pool %llu len %d\n", pool, len);\r\nceph_decode_need(p, end, len, bad);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (pi) {\r\nchar *name = kstrndup(*p, len, GFP_NOFS);\r\nif (!name)\r\nreturn -ENOMEM;\r\nkfree(pi->name);\r\npi->name = name;\r\ndout(" name is %s\n", pi->name);\r\n}\r\n*p += len;\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nvoid ceph_osdmap_destroy(struct ceph_osdmap *map)\r\n{\r\ndout("osdmap_destroy %p\n", map);\r\nif (map->crush)\r\ncrush_destroy(map->crush);\r\nwhile (!RB_EMPTY_ROOT(&map->pg_temp)) {\r\nstruct ceph_pg_mapping *pg =\r\nrb_entry(rb_first(&map->pg_temp),\r\nstruct ceph_pg_mapping, node);\r\nrb_erase(&pg->node, &map->pg_temp);\r\nkfree(pg);\r\n}\r\nwhile (!RB_EMPTY_ROOT(&map->primary_temp)) {\r\nstruct ceph_pg_mapping *pg =\r\nrb_entry(rb_first(&map->primary_temp),\r\nstruct ceph_pg_mapping, node);\r\nrb_erase(&pg->node, &map->primary_temp);\r\nkfree(pg);\r\n}\r\nwhile (!RB_EMPTY_ROOT(&map->pg_pools)) {\r\nstruct ceph_pg_pool_info *pi =\r\nrb_entry(rb_first(&map->pg_pools),\r\nstruct ceph_pg_pool_info, node);\r\n__remove_pg_pool(&map->pg_pools, pi);\r\n}\r\nkfree(map->osd_state);\r\nkfree(map->osd_weight);\r\nkfree(map->osd_addr);\r\nkfree(map->osd_primary_affinity);\r\nkfree(map);\r\n}\r\nstatic int osdmap_set_max_osd(struct ceph_osdmap *map, int max)\r\n{\r\nu8 *state;\r\nu32 *weight;\r\nstruct ceph_entity_addr *addr;\r\nint i;\r\nstate = krealloc(map->osd_state, max*sizeof(*state), GFP_NOFS);\r\nif (!state)\r\nreturn -ENOMEM;\r\nmap->osd_state = state;\r\nweight = krealloc(map->osd_weight, max*sizeof(*weight), GFP_NOFS);\r\nif (!weight)\r\nreturn -ENOMEM;\r\nmap->osd_weight = weight;\r\naddr = krealloc(map->osd_addr, max*sizeof(*addr), GFP_NOFS);\r\nif (!addr)\r\nreturn -ENOMEM;\r\nmap->osd_addr = addr;\r\nfor (i = map->max_osd; i < max; i++) {\r\nmap->osd_state[i] = 0;\r\nmap->osd_weight[i] = CEPH_OSD_OUT;\r\nmemset(map->osd_addr + i, 0, sizeof(*map->osd_addr));\r\n}\r\nif (map->osd_primary_affinity) {\r\nu32 *affinity;\r\naffinity = krealloc(map->osd_primary_affinity,\r\nmax*sizeof(*affinity), GFP_NOFS);\r\nif (!affinity)\r\nreturn -ENOMEM;\r\nmap->osd_primary_affinity = affinity;\r\nfor (i = map->max_osd; i < max; i++)\r\nmap->osd_primary_affinity[i] =\r\nCEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\r\n}\r\nmap->max_osd = max;\r\nreturn 0;\r\n}\r\nstatic int get_osdmap_client_data_v(void **p, void *end,\r\nconst char *prefix, u8 *v)\r\n{\r\nu8 struct_v;\r\nceph_decode_8_safe(p, end, struct_v, e_inval);\r\nif (struct_v >= 7) {\r\nu8 struct_compat;\r\nceph_decode_8_safe(p, end, struct_compat, e_inval);\r\nif (struct_compat > OSDMAP_WRAPPER_COMPAT_VER) {\r\npr_warn("got v %d cv %d > %d of %s ceph_osdmap\n",\r\nstruct_v, struct_compat,\r\nOSDMAP_WRAPPER_COMPAT_VER, prefix);\r\nreturn -EINVAL;\r\n}\r\n*p += 4;\r\nceph_decode_8_safe(p, end, struct_v, e_inval);\r\nceph_decode_8_safe(p, end, struct_compat, e_inval);\r\nif (struct_compat > OSDMAP_CLIENT_DATA_COMPAT_VER) {\r\npr_warn("got v %d cv %d > %d of %s ceph_osdmap client data\n",\r\nstruct_v, struct_compat,\r\nOSDMAP_CLIENT_DATA_COMPAT_VER, prefix);\r\nreturn -EINVAL;\r\n}\r\n*p += 4;\r\n} else {\r\nu16 version;\r\n*p -= 1;\r\nceph_decode_16_safe(p, end, version, e_inval);\r\nif (version < 6) {\r\npr_warn("got v %d < 6 of %s ceph_osdmap\n",\r\nversion, prefix);\r\nreturn -EINVAL;\r\n}\r\nstruct_v = 0;\r\n}\r\n*v = struct_v;\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int __decode_pools(void **p, void *end, struct ceph_osdmap *map,\r\nbool incremental)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nstruct ceph_pg_pool_info *pi;\r\nu64 pool;\r\nint ret;\r\nceph_decode_64_safe(p, end, pool, e_inval);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (!incremental || !pi) {\r\npi = kzalloc(sizeof(*pi), GFP_NOFS);\r\nif (!pi)\r\nreturn -ENOMEM;\r\npi->id = pool;\r\nret = __insert_pg_pool(&map->pg_pools, pi);\r\nif (ret) {\r\nkfree(pi);\r\nreturn ret;\r\n}\r\n}\r\nret = decode_pool(p, end, pi);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_pools(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pools(p, end, map, false);\r\n}\r\nstatic int decode_new_pools(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pools(p, end, map, true);\r\n}\r\nstatic int __decode_pg_temp(void **p, void *end, struct ceph_osdmap *map,\r\nbool incremental)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nstruct ceph_pg pgid;\r\nu32 len, i;\r\nint ret;\r\nret = ceph_decode_pgid(p, end, &pgid);\r\nif (ret)\r\nreturn ret;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nret = __remove_pg_mapping(&map->pg_temp, pgid);\r\nBUG_ON(!incremental && ret != -ENOENT);\r\nif (!incremental || len > 0) {\r\nstruct ceph_pg_mapping *pg;\r\nceph_decode_need(p, end, len*sizeof(u32), e_inval);\r\nif (len > (UINT_MAX - sizeof(*pg)) / sizeof(u32))\r\nreturn -EINVAL;\r\npg = kzalloc(sizeof(*pg) + len*sizeof(u32), GFP_NOFS);\r\nif (!pg)\r\nreturn -ENOMEM;\r\npg->pgid = pgid;\r\npg->pg_temp.len = len;\r\nfor (i = 0; i < len; i++)\r\npg->pg_temp.osds[i] = ceph_decode_32(p);\r\nret = __insert_pg_mapping(pg, &map->pg_temp);\r\nif (ret) {\r\nkfree(pg);\r\nreturn ret;\r\n}\r\n}\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_pg_temp(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pg_temp(p, end, map, false);\r\n}\r\nstatic int decode_new_pg_temp(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pg_temp(p, end, map, true);\r\n}\r\nstatic int __decode_primary_temp(void **p, void *end, struct ceph_osdmap *map,\r\nbool incremental)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nstruct ceph_pg pgid;\r\nu32 osd;\r\nint ret;\r\nret = ceph_decode_pgid(p, end, &pgid);\r\nif (ret)\r\nreturn ret;\r\nceph_decode_32_safe(p, end, osd, e_inval);\r\nret = __remove_pg_mapping(&map->primary_temp, pgid);\r\nBUG_ON(!incremental && ret != -ENOENT);\r\nif (!incremental || osd != (u32)-1) {\r\nstruct ceph_pg_mapping *pg;\r\npg = kzalloc(sizeof(*pg), GFP_NOFS);\r\nif (!pg)\r\nreturn -ENOMEM;\r\npg->pgid = pgid;\r\npg->primary_temp.osd = osd;\r\nret = __insert_pg_mapping(pg, &map->primary_temp);\r\nif (ret) {\r\nkfree(pg);\r\nreturn ret;\r\n}\r\n}\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_primary_temp(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_primary_temp(p, end, map, false);\r\n}\r\nstatic int decode_new_primary_temp(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nreturn __decode_primary_temp(p, end, map, true);\r\n}\r\nu32 ceph_get_primary_affinity(struct ceph_osdmap *map, int osd)\r\n{\r\nBUG_ON(osd >= map->max_osd);\r\nif (!map->osd_primary_affinity)\r\nreturn CEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\r\nreturn map->osd_primary_affinity[osd];\r\n}\r\nstatic int set_primary_affinity(struct ceph_osdmap *map, int osd, u32 aff)\r\n{\r\nBUG_ON(osd >= map->max_osd);\r\nif (!map->osd_primary_affinity) {\r\nint i;\r\nmap->osd_primary_affinity = kmalloc(map->max_osd*sizeof(u32),\r\nGFP_NOFS);\r\nif (!map->osd_primary_affinity)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < map->max_osd; i++)\r\nmap->osd_primary_affinity[i] =\r\nCEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\r\n}\r\nmap->osd_primary_affinity[osd] = aff;\r\nreturn 0;\r\n}\r\nstatic int decode_primary_affinity(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nu32 len, i;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nif (len == 0) {\r\nkfree(map->osd_primary_affinity);\r\nmap->osd_primary_affinity = NULL;\r\nreturn 0;\r\n}\r\nif (len != map->max_osd)\r\ngoto e_inval;\r\nceph_decode_need(p, end, map->max_osd*sizeof(u32), e_inval);\r\nfor (i = 0; i < map->max_osd; i++) {\r\nint ret;\r\nret = set_primary_affinity(map, i, ceph_decode_32(p));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_new_primary_affinity(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nu32 osd, aff;\r\nint ret;\r\nceph_decode_32_safe(p, end, osd, e_inval);\r\nceph_decode_32_safe(p, end, aff, e_inval);\r\nret = set_primary_affinity(map, osd, aff);\r\nif (ret)\r\nreturn ret;\r\npr_info("osd%d primary-affinity 0x%x\n", osd, aff);\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int osdmap_decode(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nu8 struct_v;\r\nu32 epoch = 0;\r\nvoid *start = *p;\r\nu32 max;\r\nu32 len, i;\r\nint err;\r\ndout("%s %p to %p len %d\n", __func__, *p, end, (int)(end - *p));\r\nerr = get_osdmap_client_data_v(p, end, "full", &struct_v);\r\nif (err)\r\ngoto bad;\r\nceph_decode_need(p, end, sizeof(map->fsid) + sizeof(u32) +\r\nsizeof(map->created) + sizeof(map->modified), e_inval);\r\nceph_decode_copy(p, &map->fsid, sizeof(map->fsid));\r\nepoch = map->epoch = ceph_decode_32(p);\r\nceph_decode_copy(p, &map->created, sizeof(map->created));\r\nceph_decode_copy(p, &map->modified, sizeof(map->modified));\r\nerr = decode_pools(p, end, map);\r\nif (err)\r\ngoto bad;\r\nerr = decode_pool_names(p, end, map);\r\nif (err)\r\ngoto bad;\r\nceph_decode_32_safe(p, end, map->pool_max, e_inval);\r\nceph_decode_32_safe(p, end, map->flags, e_inval);\r\nceph_decode_32_safe(p, end, max, e_inval);\r\nerr = osdmap_set_max_osd(map, max);\r\nif (err)\r\ngoto bad;\r\nceph_decode_need(p, end, 3*sizeof(u32) +\r\nmap->max_osd*(1 + sizeof(*map->osd_weight) +\r\nsizeof(*map->osd_addr)), e_inval);\r\nif (ceph_decode_32(p) != map->max_osd)\r\ngoto e_inval;\r\nceph_decode_copy(p, map->osd_state, map->max_osd);\r\nif (ceph_decode_32(p) != map->max_osd)\r\ngoto e_inval;\r\nfor (i = 0; i < map->max_osd; i++)\r\nmap->osd_weight[i] = ceph_decode_32(p);\r\nif (ceph_decode_32(p) != map->max_osd)\r\ngoto e_inval;\r\nceph_decode_copy(p, map->osd_addr, map->max_osd*sizeof(*map->osd_addr));\r\nfor (i = 0; i < map->max_osd; i++)\r\nceph_decode_addr(&map->osd_addr[i]);\r\nerr = decode_pg_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\nif (struct_v >= 1) {\r\nerr = decode_primary_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\n}\r\nif (struct_v >= 2) {\r\nerr = decode_primary_affinity(p, end, map);\r\nif (err)\r\ngoto bad;\r\n} else {\r\nkfree(map->osd_primary_affinity);\r\nmap->osd_primary_affinity = NULL;\r\n}\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nmap->crush = crush_decode(*p, min(*p + len, end));\r\nif (IS_ERR(map->crush)) {\r\nerr = PTR_ERR(map->crush);\r\nmap->crush = NULL;\r\ngoto bad;\r\n}\r\n*p += len;\r\n*p = end;\r\ndout("full osdmap epoch %d max_osd %d\n", map->epoch, map->max_osd);\r\nreturn 0;\r\ne_inval:\r\nerr = -EINVAL;\r\nbad:\r\npr_err("corrupt full osdmap (%d) epoch %d off %d (%p of %p-%p)\n",\r\nerr, epoch, (int)(*p - start), *p, start, end);\r\nprint_hex_dump(KERN_DEBUG, "osdmap: ",\r\nDUMP_PREFIX_OFFSET, 16, 1,\r\nstart, end - start, true);\r\nreturn err;\r\n}\r\nstruct ceph_osdmap *ceph_osdmap_decode(void **p, void *end)\r\n{\r\nstruct ceph_osdmap *map;\r\nint ret;\r\nmap = kzalloc(sizeof(*map), GFP_NOFS);\r\nif (!map)\r\nreturn ERR_PTR(-ENOMEM);\r\nmap->pg_temp = RB_ROOT;\r\nmap->primary_temp = RB_ROOT;\r\nmutex_init(&map->crush_scratch_mutex);\r\nret = osdmap_decode(p, end, map);\r\nif (ret) {\r\nceph_osdmap_destroy(map);\r\nreturn ERR_PTR(ret);\r\n}\r\nreturn map;\r\n}\r\nstruct ceph_osdmap *osdmap_apply_incremental(void **p, void *end,\r\nstruct ceph_osdmap *map,\r\nstruct ceph_messenger *msgr)\r\n{\r\nstruct crush_map *newcrush = NULL;\r\nstruct ceph_fsid fsid;\r\nu32 epoch = 0;\r\nstruct ceph_timespec modified;\r\ns32 len;\r\nu64 pool;\r\n__s64 new_pool_max;\r\n__s32 new_flags, max;\r\nvoid *start = *p;\r\nint err;\r\nu8 struct_v;\r\ndout("%s %p to %p len %d\n", __func__, *p, end, (int)(end - *p));\r\nerr = get_osdmap_client_data_v(p, end, "inc", &struct_v);\r\nif (err)\r\ngoto bad;\r\nceph_decode_need(p, end, sizeof(fsid) + sizeof(u32) + sizeof(modified) +\r\nsizeof(u64) + sizeof(u32), e_inval);\r\nceph_decode_copy(p, &fsid, sizeof(fsid));\r\nepoch = ceph_decode_32(p);\r\nBUG_ON(epoch != map->epoch+1);\r\nceph_decode_copy(p, &modified, sizeof(modified));\r\nnew_pool_max = ceph_decode_64(p);\r\nnew_flags = ceph_decode_32(p);\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nif (len > 0) {\r\ndout("apply_incremental full map len %d, %p to %p\n",\r\nlen, *p, end);\r\nreturn ceph_osdmap_decode(p, min(*p+len, end));\r\n}\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nif (len > 0) {\r\nnewcrush = crush_decode(*p, min(*p+len, end));\r\nif (IS_ERR(newcrush)) {\r\nerr = PTR_ERR(newcrush);\r\nnewcrush = NULL;\r\ngoto bad;\r\n}\r\n*p += len;\r\n}\r\nif (new_flags >= 0)\r\nmap->flags = new_flags;\r\nif (new_pool_max >= 0)\r\nmap->pool_max = new_pool_max;\r\nceph_decode_32_safe(p, end, max, e_inval);\r\nif (max >= 0) {\r\nerr = osdmap_set_max_osd(map, max);\r\nif (err)\r\ngoto bad;\r\n}\r\nmap->epoch++;\r\nmap->modified = modified;\r\nif (newcrush) {\r\nif (map->crush)\r\ncrush_destroy(map->crush);\r\nmap->crush = newcrush;\r\nnewcrush = NULL;\r\n}\r\nerr = decode_new_pools(p, end, map);\r\nif (err)\r\ngoto bad;\r\nerr = decode_pool_names(p, end, map);\r\nif (err)\r\ngoto bad;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nwhile (len--) {\r\nstruct ceph_pg_pool_info *pi;\r\nceph_decode_64_safe(p, end, pool, e_inval);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (pi)\r\n__remove_pg_pool(&map->pg_pools, pi);\r\n}\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nwhile (len--) {\r\nu32 osd;\r\nstruct ceph_entity_addr addr;\r\nceph_decode_32_safe(p, end, osd, e_inval);\r\nceph_decode_copy_safe(p, end, &addr, sizeof(addr), e_inval);\r\nceph_decode_addr(&addr);\r\npr_info("osd%d up\n", osd);\r\nBUG_ON(osd >= map->max_osd);\r\nmap->osd_state[osd] |= CEPH_OSD_UP | CEPH_OSD_EXISTS;\r\nmap->osd_addr[osd] = addr;\r\n}\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nwhile (len--) {\r\nu32 osd;\r\nu8 xorstate;\r\nceph_decode_32_safe(p, end, osd, e_inval);\r\nxorstate = **(u8 **)p;\r\n(*p)++;\r\nif (xorstate == 0)\r\nxorstate = CEPH_OSD_UP;\r\nif (xorstate & CEPH_OSD_UP)\r\npr_info("osd%d down\n", osd);\r\nif (osd < map->max_osd)\r\nmap->osd_state[osd] ^= xorstate;\r\n}\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nwhile (len--) {\r\nu32 osd, off;\r\nceph_decode_need(p, end, sizeof(u32)*2, e_inval);\r\nosd = ceph_decode_32(p);\r\noff = ceph_decode_32(p);\r\npr_info("osd%d weight 0x%x %s\n", osd, off,\r\noff == CEPH_OSD_IN ? "(in)" :\r\n(off == CEPH_OSD_OUT ? "(out)" : ""));\r\nif (osd < map->max_osd)\r\nmap->osd_weight[osd] = off;\r\n}\r\nerr = decode_new_pg_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\nif (struct_v >= 1) {\r\nerr = decode_new_primary_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\n}\r\nif (struct_v >= 2) {\r\nerr = decode_new_primary_affinity(p, end, map);\r\nif (err)\r\ngoto bad;\r\n}\r\n*p = end;\r\ndout("inc osdmap epoch %d max_osd %d\n", map->epoch, map->max_osd);\r\nreturn map;\r\ne_inval:\r\nerr = -EINVAL;\r\nbad:\r\npr_err("corrupt inc osdmap (%d) epoch %d off %d (%p of %p-%p)\n",\r\nerr, epoch, (int)(*p - start), *p, start, end);\r\nprint_hex_dump(KERN_DEBUG, "osdmap: ",\r\nDUMP_PREFIX_OFFSET, 16, 1,\r\nstart, end - start, true);\r\nif (newcrush)\r\ncrush_destroy(newcrush);\r\nreturn ERR_PTR(err);\r\n}\r\nint ceph_calc_file_object_mapping(struct ceph_file_layout *layout,\r\nu64 off, u64 len,\r\nu64 *ono,\r\nu64 *oxoff, u64 *oxlen)\r\n{\r\nu32 osize = le32_to_cpu(layout->fl_object_size);\r\nu32 su = le32_to_cpu(layout->fl_stripe_unit);\r\nu32 sc = le32_to_cpu(layout->fl_stripe_count);\r\nu32 bl, stripeno, stripepos, objsetno;\r\nu32 su_per_object;\r\nu64 t, su_offset;\r\ndout("mapping %llu~%llu osize %u fl_su %u\n", off, len,\r\nosize, su);\r\nif (su == 0 || sc == 0)\r\ngoto invalid;\r\nsu_per_object = osize / su;\r\nif (su_per_object == 0)\r\ngoto invalid;\r\ndout("osize %u / su %u = su_per_object %u\n", osize, su,\r\nsu_per_object);\r\nif ((su & ~PAGE_MASK) != 0)\r\ngoto invalid;\r\nt = off;\r\ndo_div(t, su);\r\nbl = t;\r\ndout("off %llu / su %u = bl %u\n", off, su, bl);\r\nstripeno = bl / sc;\r\nstripepos = bl % sc;\r\nobjsetno = stripeno / su_per_object;\r\n*ono = objsetno * sc + stripepos;\r\ndout("objset %u * sc %u = ono %u\n", objsetno, sc, (unsigned int)*ono);\r\nt = off;\r\nsu_offset = do_div(t, su);\r\n*oxoff = su_offset + (stripeno % su_per_object) * su;\r\n*oxlen = min_t(u64, len, su - su_offset);\r\ndout(" obj extent %llu~%llu\n", *oxoff, *oxlen);\r\nreturn 0;\r\ninvalid:\r\ndout(" invalid layout\n");\r\n*ono = 0;\r\n*oxoff = 0;\r\n*oxlen = 0;\r\nreturn -EINVAL;\r\n}\r\nint ceph_oloc_oid_to_pg(struct ceph_osdmap *osdmap,\r\nstruct ceph_object_locator *oloc,\r\nstruct ceph_object_id *oid,\r\nstruct ceph_pg *pg_out)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\npi = __lookup_pg_pool(&osdmap->pg_pools, oloc->pool);\r\nif (!pi)\r\nreturn -EIO;\r\npg_out->pool = oloc->pool;\r\npg_out->seed = ceph_str_hash(pi->object_hash, oid->name,\r\noid->name_len);\r\ndout("%s '%.*s' pgid %llu.%x\n", __func__, oid->name_len, oid->name,\r\npg_out->pool, pg_out->seed);\r\nreturn 0;\r\n}\r\nstatic int do_crush(struct ceph_osdmap *map, int ruleno, int x,\r\nint *result, int result_max,\r\nconst __u32 *weight, int weight_max)\r\n{\r\nint r;\r\nBUG_ON(result_max > CEPH_PG_MAX_SIZE);\r\nmutex_lock(&map->crush_scratch_mutex);\r\nr = crush_do_rule(map->crush, ruleno, x, result, result_max,\r\nweight, weight_max, map->crush_scratch_ary);\r\nmutex_unlock(&map->crush_scratch_mutex);\r\nreturn r;\r\n}\r\nstatic int pg_to_raw_osds(struct ceph_osdmap *osdmap,\r\nstruct ceph_pg_pool_info *pool,\r\nstruct ceph_pg pgid, u32 pps, int *osds)\r\n{\r\nint ruleno;\r\nint len;\r\nruleno = crush_find_rule(osdmap->crush, pool->crush_ruleset,\r\npool->type, pool->size);\r\nif (ruleno < 0) {\r\npr_err("no crush rule: pool %lld ruleset %d type %d size %d\n",\r\npgid.pool, pool->crush_ruleset, pool->type,\r\npool->size);\r\nreturn -ENOENT;\r\n}\r\nlen = do_crush(osdmap, ruleno, pps, osds,\r\nmin_t(int, pool->size, CEPH_PG_MAX_SIZE),\r\nosdmap->osd_weight, osdmap->max_osd);\r\nif (len < 0) {\r\npr_err("error %d from crush rule %d: pool %lld ruleset %d type %d size %d\n",\r\nlen, ruleno, pgid.pool, pool->crush_ruleset,\r\npool->type, pool->size);\r\nreturn len;\r\n}\r\nreturn len;\r\n}\r\nstatic int raw_to_up_osds(struct ceph_osdmap *osdmap,\r\nstruct ceph_pg_pool_info *pool,\r\nint *osds, int len, int *primary)\r\n{\r\nint up_primary = -1;\r\nint i;\r\nif (ceph_can_shift_osds(pool)) {\r\nint removed = 0;\r\nfor (i = 0; i < len; i++) {\r\nif (ceph_osd_is_down(osdmap, osds[i])) {\r\nremoved++;\r\ncontinue;\r\n}\r\nif (removed)\r\nosds[i - removed] = osds[i];\r\n}\r\nlen -= removed;\r\nif (len > 0)\r\nup_primary = osds[0];\r\n} else {\r\nfor (i = len - 1; i >= 0; i--) {\r\nif (ceph_osd_is_down(osdmap, osds[i]))\r\nosds[i] = CRUSH_ITEM_NONE;\r\nelse\r\nup_primary = osds[i];\r\n}\r\n}\r\n*primary = up_primary;\r\nreturn len;\r\n}\r\nstatic void apply_primary_affinity(struct ceph_osdmap *osdmap, u32 pps,\r\nstruct ceph_pg_pool_info *pool,\r\nint *osds, int len, int *primary)\r\n{\r\nint i;\r\nint pos = -1;\r\nif (!osdmap->osd_primary_affinity)\r\nreturn;\r\nfor (i = 0; i < len; i++) {\r\nint osd = osds[i];\r\nif (osd != CRUSH_ITEM_NONE &&\r\nosdmap->osd_primary_affinity[osd] !=\r\nCEPH_OSD_DEFAULT_PRIMARY_AFFINITY) {\r\nbreak;\r\n}\r\n}\r\nif (i == len)\r\nreturn;\r\nfor (i = 0; i < len; i++) {\r\nint osd = osds[i];\r\nu32 aff;\r\nif (osd == CRUSH_ITEM_NONE)\r\ncontinue;\r\naff = osdmap->osd_primary_affinity[osd];\r\nif (aff < CEPH_OSD_MAX_PRIMARY_AFFINITY &&\r\n(crush_hash32_2(CRUSH_HASH_RJENKINS1,\r\npps, osd) >> 16) >= aff) {\r\nif (pos < 0)\r\npos = i;\r\n} else {\r\npos = i;\r\nbreak;\r\n}\r\n}\r\nif (pos < 0)\r\nreturn;\r\n*primary = osds[pos];\r\nif (ceph_can_shift_osds(pool) && pos > 0) {\r\nfor (i = pos; i > 0; i--)\r\nosds[i] = osds[i - 1];\r\nosds[0] = *primary;\r\n}\r\n}\r\nstatic int apply_temps(struct ceph_osdmap *osdmap,\r\nstruct ceph_pg_pool_info *pool, struct ceph_pg pgid,\r\nint *osds, int len, int *primary)\r\n{\r\nstruct ceph_pg_mapping *pg;\r\nint temp_len;\r\nint temp_primary;\r\nint i;\r\npgid.seed = ceph_stable_mod(pgid.seed, pool->pg_num,\r\npool->pg_num_mask);\r\npg = __lookup_pg_mapping(&osdmap->pg_temp, pgid);\r\nif (pg) {\r\ntemp_len = 0;\r\ntemp_primary = -1;\r\nfor (i = 0; i < pg->pg_temp.len; i++) {\r\nif (ceph_osd_is_down(osdmap, pg->pg_temp.osds[i])) {\r\nif (ceph_can_shift_osds(pool))\r\ncontinue;\r\nelse\r\nosds[temp_len++] = CRUSH_ITEM_NONE;\r\n} else {\r\nosds[temp_len++] = pg->pg_temp.osds[i];\r\n}\r\n}\r\nfor (i = 0; i < temp_len; i++) {\r\nif (osds[i] != CRUSH_ITEM_NONE) {\r\ntemp_primary = osds[i];\r\nbreak;\r\n}\r\n}\r\n} else {\r\ntemp_len = len;\r\ntemp_primary = *primary;\r\n}\r\npg = __lookup_pg_mapping(&osdmap->primary_temp, pgid);\r\nif (pg)\r\ntemp_primary = pg->primary_temp.osd;\r\n*primary = temp_primary;\r\nreturn temp_len;\r\n}\r\nint ceph_calc_pg_acting(struct ceph_osdmap *osdmap, struct ceph_pg pgid,\r\nint *osds, int *primary)\r\n{\r\nstruct ceph_pg_pool_info *pool;\r\nu32 pps;\r\nint len;\r\npool = __lookup_pg_pool(&osdmap->pg_pools, pgid.pool);\r\nif (!pool) {\r\n*primary = -1;\r\nreturn -ENOENT;\r\n}\r\nif (pool->flags & CEPH_POOL_FLAG_HASHPSPOOL) {\r\npps = crush_hash32_2(CRUSH_HASH_RJENKINS1,\r\nceph_stable_mod(pgid.seed, pool->pgp_num,\r\npool->pgp_num_mask),\r\npgid.pool);\r\n} else {\r\npps = ceph_stable_mod(pgid.seed, pool->pgp_num,\r\npool->pgp_num_mask) +\r\n(unsigned)pgid.pool;\r\n}\r\nlen = pg_to_raw_osds(osdmap, pool, pgid, pps, osds);\r\nif (len < 0) {\r\n*primary = -1;\r\nreturn len;\r\n}\r\nlen = raw_to_up_osds(osdmap, pool, osds, len, primary);\r\napply_primary_affinity(osdmap, pps, pool, osds, len, primary);\r\nlen = apply_temps(osdmap, pool, pgid, osds, len, primary);\r\nreturn len;\r\n}\r\nint ceph_calc_pg_primary(struct ceph_osdmap *osdmap, struct ceph_pg pgid)\r\n{\r\nint osds[CEPH_PG_MAX_SIZE];\r\nint primary;\r\nceph_calc_pg_acting(osdmap, pgid, osds, &primary);\r\nreturn primary;\r\n}
