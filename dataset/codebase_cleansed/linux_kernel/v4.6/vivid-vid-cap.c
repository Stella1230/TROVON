static int vid_cap_queue_setup(struct vb2_queue *vq,\r\nunsigned *nbuffers, unsigned *nplanes,\r\nunsigned sizes[], void *alloc_ctxs[])\r\n{\r\nstruct vivid_dev *dev = vb2_get_drv_priv(vq);\r\nunsigned buffers = tpg_g_buffers(&dev->tpg);\r\nunsigned h = dev->fmt_cap_rect.height;\r\nunsigned p;\r\nif (dev->field_cap == V4L2_FIELD_ALTERNATE) {\r\nif (vb2_fileio_is_active(vq))\r\nreturn -EINVAL;\r\n}\r\nif (dev->queue_setup_error) {\r\ndev->queue_setup_error = false;\r\nreturn -EINVAL;\r\n}\r\nif (*nplanes) {\r\nif (*nplanes != buffers)\r\nreturn -EINVAL;\r\nfor (p = 0; p < buffers; p++) {\r\nif (sizes[p] < tpg_g_line_width(&dev->tpg, p) * h +\r\ndev->fmt_cap->data_offset[p])\r\nreturn -EINVAL;\r\n}\r\n} else {\r\nfor (p = 0; p < buffers; p++)\r\nsizes[p] = tpg_g_line_width(&dev->tpg, p) * h +\r\ndev->fmt_cap->data_offset[p];\r\n}\r\nif (vq->num_buffers + *nbuffers < 2)\r\n*nbuffers = 2 - vq->num_buffers;\r\n*nplanes = buffers;\r\ndprintk(dev, 1, "%s: count=%d\n", __func__, *nbuffers);\r\nfor (p = 0; p < buffers; p++)\r\ndprintk(dev, 1, "%s: size[%u]=%u\n", __func__, p, sizes[p]);\r\nreturn 0;\r\n}\r\nstatic int vid_cap_buf_prepare(struct vb2_buffer *vb)\r\n{\r\nstruct vivid_dev *dev = vb2_get_drv_priv(vb->vb2_queue);\r\nunsigned long size;\r\nunsigned buffers = tpg_g_buffers(&dev->tpg);\r\nunsigned p;\r\ndprintk(dev, 1, "%s\n", __func__);\r\nif (WARN_ON(NULL == dev->fmt_cap))\r\nreturn -EINVAL;\r\nif (dev->buf_prepare_error) {\r\ndev->buf_prepare_error = false;\r\nreturn -EINVAL;\r\n}\r\nfor (p = 0; p < buffers; p++) {\r\nsize = tpg_g_line_width(&dev->tpg, p) * dev->fmt_cap_rect.height +\r\ndev->fmt_cap->data_offset[p];\r\nif (vb2_plane_size(vb, p) < size) {\r\ndprintk(dev, 1, "%s data will not fit into plane %u (%lu < %lu)\n",\r\n__func__, p, vb2_plane_size(vb, p), size);\r\nreturn -EINVAL;\r\n}\r\nvb2_set_plane_payload(vb, p, size);\r\nvb->planes[p].data_offset = dev->fmt_cap->data_offset[p];\r\n}\r\nreturn 0;\r\n}\r\nstatic void vid_cap_buf_finish(struct vb2_buffer *vb)\r\n{\r\nstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(vb);\r\nstruct vivid_dev *dev = vb2_get_drv_priv(vb->vb2_queue);\r\nstruct v4l2_timecode *tc = &vbuf->timecode;\r\nunsigned fps = 25;\r\nunsigned seq = vbuf->sequence;\r\nif (!vivid_is_sdtv_cap(dev))\r\nreturn;\r\nvbuf->flags |= V4L2_BUF_FLAG_TIMECODE;\r\nif (dev->std_cap & V4L2_STD_525_60)\r\nfps = 30;\r\ntc->type = (fps == 30) ? V4L2_TC_TYPE_30FPS : V4L2_TC_TYPE_25FPS;\r\ntc->flags = 0;\r\ntc->frames = seq % fps;\r\ntc->seconds = (seq / fps) % 60;\r\ntc->minutes = (seq / (60 * fps)) % 60;\r\ntc->hours = (seq / (60 * 60 * fps)) % 24;\r\n}\r\nstatic void vid_cap_buf_queue(struct vb2_buffer *vb)\r\n{\r\nstruct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(vb);\r\nstruct vivid_dev *dev = vb2_get_drv_priv(vb->vb2_queue);\r\nstruct vivid_buffer *buf = container_of(vbuf, struct vivid_buffer, vb);\r\ndprintk(dev, 1, "%s\n", __func__);\r\nspin_lock(&dev->slock);\r\nlist_add_tail(&buf->list, &dev->vid_cap_active);\r\nspin_unlock(&dev->slock);\r\n}\r\nstatic int vid_cap_start_streaming(struct vb2_queue *vq, unsigned count)\r\n{\r\nstruct vivid_dev *dev = vb2_get_drv_priv(vq);\r\nunsigned i;\r\nint err;\r\nif (vb2_is_streaming(&dev->vb_vid_out_q))\r\ndev->can_loop_video = vivid_vid_can_loop(dev);\r\nif (dev->kthread_vid_cap)\r\nreturn 0;\r\ndev->vid_cap_seq_count = 0;\r\ndprintk(dev, 1, "%s\n", __func__);\r\nfor (i = 0; i < VIDEO_MAX_FRAME; i++)\r\ndev->must_blank[i] = tpg_g_perc_fill(&dev->tpg) < 100;\r\nif (dev->start_streaming_error) {\r\ndev->start_streaming_error = false;\r\nerr = -EINVAL;\r\n} else {\r\nerr = vivid_start_generating_vid_cap(dev, &dev->vid_cap_streaming);\r\n}\r\nif (err) {\r\nstruct vivid_buffer *buf, *tmp;\r\nlist_for_each_entry_safe(buf, tmp, &dev->vid_cap_active, list) {\r\nlist_del(&buf->list);\r\nvb2_buffer_done(&buf->vb.vb2_buf,\r\nVB2_BUF_STATE_QUEUED);\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic void vid_cap_stop_streaming(struct vb2_queue *vq)\r\n{\r\nstruct vivid_dev *dev = vb2_get_drv_priv(vq);\r\ndprintk(dev, 1, "%s\n", __func__);\r\nvivid_stop_generating_vid_cap(dev, &dev->vid_cap_streaming);\r\ndev->can_loop_video = false;\r\n}\r\nvoid vivid_update_quality(struct vivid_dev *dev)\r\n{\r\nunsigned freq_modulus;\r\nif (dev->loop_video && (vivid_is_svid_cap(dev) || vivid_is_hdmi_cap(dev))) {\r\ntpg_s_quality(&dev->tpg, TPG_QUAL_NOISE, 0);\r\nreturn;\r\n}\r\nif (vivid_is_hdmi_cap(dev) && VIVID_INVALID_SIGNAL(dev->dv_timings_signal_mode)) {\r\ntpg_s_quality(&dev->tpg, TPG_QUAL_NOISE, 0);\r\nreturn;\r\n}\r\nif (vivid_is_sdtv_cap(dev) && VIVID_INVALID_SIGNAL(dev->std_signal_mode)) {\r\ntpg_s_quality(&dev->tpg, TPG_QUAL_NOISE, 0);\r\nreturn;\r\n}\r\nif (!vivid_is_tv_cap(dev)) {\r\ntpg_s_quality(&dev->tpg, TPG_QUAL_COLOR, 0);\r\nreturn;\r\n}\r\nfreq_modulus = (dev->tv_freq - 676 ) % (6 * 16);\r\nif (freq_modulus > 2 * 16) {\r\ntpg_s_quality(&dev->tpg, TPG_QUAL_NOISE,\r\nnext_pseudo_random32(dev->tv_freq ^ 0x55) & 0x3f);\r\nreturn;\r\n}\r\nif (freq_modulus < 12 || freq_modulus > 20 )\r\ntpg_s_quality(&dev->tpg, TPG_QUAL_GRAY, 0);\r\nelse\r\ntpg_s_quality(&dev->tpg, TPG_QUAL_COLOR, 0);\r\n}\r\nstatic enum tpg_quality vivid_get_quality(struct vivid_dev *dev, s32 *afc)\r\n{\r\nunsigned freq_modulus;\r\nif (afc)\r\n*afc = 0;\r\nif (tpg_g_quality(&dev->tpg) == TPG_QUAL_COLOR ||\r\ntpg_g_quality(&dev->tpg) == TPG_QUAL_NOISE)\r\nreturn tpg_g_quality(&dev->tpg);\r\nfreq_modulus = (dev->tv_freq - 676 ) % (6 * 16);\r\nif (afc)\r\n*afc = freq_modulus - 1 * 16;\r\nreturn TPG_QUAL_GRAY;\r\n}\r\nenum tpg_video_aspect vivid_get_video_aspect(const struct vivid_dev *dev)\r\n{\r\nif (vivid_is_sdtv_cap(dev))\r\nreturn dev->std_aspect_ratio;\r\nif (vivid_is_hdmi_cap(dev))\r\nreturn dev->dv_timings_aspect_ratio;\r\nreturn TPG_VIDEO_ASPECT_IMAGE;\r\n}\r\nstatic enum tpg_pixel_aspect vivid_get_pixel_aspect(const struct vivid_dev *dev)\r\n{\r\nif (vivid_is_sdtv_cap(dev))\r\nreturn (dev->std_cap & V4L2_STD_525_60) ?\r\nTPG_PIXEL_ASPECT_NTSC : TPG_PIXEL_ASPECT_PAL;\r\nif (vivid_is_hdmi_cap(dev) &&\r\ndev->src_rect.width == 720 && dev->src_rect.height <= 576)\r\nreturn dev->src_rect.height == 480 ?\r\nTPG_PIXEL_ASPECT_NTSC : TPG_PIXEL_ASPECT_PAL;\r\nreturn TPG_PIXEL_ASPECT_SQUARE;\r\n}\r\nvoid vivid_update_format_cap(struct vivid_dev *dev, bool keep_controls)\r\n{\r\nstruct v4l2_bt_timings *bt = &dev->dv_timings_cap.bt;\r\nunsigned size;\r\nu64 pixelclock;\r\nswitch (dev->input_type[dev->input]) {\r\ncase WEBCAM:\r\ndefault:\r\ndev->src_rect.width = webcam_sizes[dev->webcam_size_idx].width;\r\ndev->src_rect.height = webcam_sizes[dev->webcam_size_idx].height;\r\ndev->timeperframe_vid_cap = webcam_intervals[dev->webcam_ival_idx];\r\ndev->field_cap = V4L2_FIELD_NONE;\r\ntpg_s_rgb_range(&dev->tpg, V4L2_DV_RGB_RANGE_AUTO);\r\nbreak;\r\ncase TV:\r\ncase SVID:\r\ndev->field_cap = dev->tv_field_cap;\r\ndev->src_rect.width = 720;\r\nif (dev->std_cap & V4L2_STD_525_60) {\r\ndev->src_rect.height = 480;\r\ndev->timeperframe_vid_cap = (struct v4l2_fract) { 1001, 30000 };\r\ndev->service_set_cap = V4L2_SLICED_CAPTION_525;\r\n} else {\r\ndev->src_rect.height = 576;\r\ndev->timeperframe_vid_cap = (struct v4l2_fract) { 1000, 25000 };\r\ndev->service_set_cap = V4L2_SLICED_WSS_625 | V4L2_SLICED_TELETEXT_B;\r\n}\r\ntpg_s_rgb_range(&dev->tpg, V4L2_DV_RGB_RANGE_AUTO);\r\nbreak;\r\ncase HDMI:\r\ndev->src_rect.width = bt->width;\r\ndev->src_rect.height = bt->height;\r\nsize = V4L2_DV_BT_FRAME_WIDTH(bt) * V4L2_DV_BT_FRAME_HEIGHT(bt);\r\nif (dev->reduced_fps && can_reduce_fps(bt)) {\r\npixelclock = div_u64(bt->pixelclock * 1000, 1001);\r\nbt->flags |= V4L2_DV_FL_REDUCED_FPS;\r\n} else {\r\npixelclock = bt->pixelclock;\r\nbt->flags &= ~V4L2_DV_FL_REDUCED_FPS;\r\n}\r\ndev->timeperframe_vid_cap = (struct v4l2_fract) {\r\nsize / 100, (u32)pixelclock / 100\r\n};\r\nif (bt->interlaced)\r\ndev->field_cap = V4L2_FIELD_ALTERNATE;\r\nelse\r\ndev->field_cap = V4L2_FIELD_NONE;\r\nif (keep_controls || !dev->colorspace)\r\nbreak;\r\nif (bt->flags & V4L2_DV_FL_IS_CE_VIDEO) {\r\nif (bt->width == 720 && bt->height <= 576)\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_170M);\r\nelse\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_709);\r\nv4l2_ctrl_s_ctrl(dev->real_rgb_range_cap, 1);\r\n} else {\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_SRGB);\r\nv4l2_ctrl_s_ctrl(dev->real_rgb_range_cap, 0);\r\n}\r\ntpg_s_rgb_range(&dev->tpg, v4l2_ctrl_g_ctrl(dev->rgb_range_cap));\r\nbreak;\r\n}\r\nvivid_update_quality(dev);\r\ntpg_reset_source(&dev->tpg, dev->src_rect.width, dev->src_rect.height, dev->field_cap);\r\ndev->crop_cap = dev->src_rect;\r\ndev->crop_bounds_cap = dev->src_rect;\r\ndev->compose_cap = dev->crop_cap;\r\nif (V4L2_FIELD_HAS_T_OR_B(dev->field_cap))\r\ndev->compose_cap.height /= 2;\r\ndev->fmt_cap_rect = dev->compose_cap;\r\ntpg_s_video_aspect(&dev->tpg, vivid_get_video_aspect(dev));\r\ntpg_s_pixel_aspect(&dev->tpg, vivid_get_pixel_aspect(dev));\r\ntpg_update_mv_step(&dev->tpg);\r\n}\r\nstatic enum v4l2_field vivid_field_cap(struct vivid_dev *dev, enum v4l2_field field)\r\n{\r\nif (vivid_is_sdtv_cap(dev)) {\r\nswitch (field) {\r\ncase V4L2_FIELD_INTERLACED_TB:\r\ncase V4L2_FIELD_INTERLACED_BT:\r\ncase V4L2_FIELD_SEQ_TB:\r\ncase V4L2_FIELD_SEQ_BT:\r\ncase V4L2_FIELD_TOP:\r\ncase V4L2_FIELD_BOTTOM:\r\ncase V4L2_FIELD_ALTERNATE:\r\nreturn field;\r\ncase V4L2_FIELD_INTERLACED:\r\ndefault:\r\nreturn V4L2_FIELD_INTERLACED;\r\n}\r\n}\r\nif (vivid_is_hdmi_cap(dev))\r\nreturn dev->dv_timings_cap.bt.interlaced ? V4L2_FIELD_ALTERNATE :\r\nV4L2_FIELD_NONE;\r\nreturn V4L2_FIELD_NONE;\r\n}\r\nstatic unsigned vivid_colorspace_cap(struct vivid_dev *dev)\r\n{\r\nif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\r\nreturn tpg_g_colorspace(&dev->tpg);\r\nreturn dev->colorspace_out;\r\n}\r\nstatic unsigned vivid_xfer_func_cap(struct vivid_dev *dev)\r\n{\r\nif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\r\nreturn tpg_g_xfer_func(&dev->tpg);\r\nreturn dev->xfer_func_out;\r\n}\r\nstatic unsigned vivid_ycbcr_enc_cap(struct vivid_dev *dev)\r\n{\r\nif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\r\nreturn tpg_g_ycbcr_enc(&dev->tpg);\r\nreturn dev->ycbcr_enc_out;\r\n}\r\nstatic unsigned vivid_quantization_cap(struct vivid_dev *dev)\r\n{\r\nif (!dev->loop_video || vivid_is_webcam(dev) || vivid_is_tv_cap(dev))\r\nreturn tpg_g_quantization(&dev->tpg);\r\nreturn dev->quantization_out;\r\n}\r\nint vivid_g_fmt_vid_cap(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nstruct v4l2_pix_format_mplane *mp = &f->fmt.pix_mp;\r\nunsigned p;\r\nmp->width = dev->fmt_cap_rect.width;\r\nmp->height = dev->fmt_cap_rect.height;\r\nmp->field = dev->field_cap;\r\nmp->pixelformat = dev->fmt_cap->fourcc;\r\nmp->colorspace = vivid_colorspace_cap(dev);\r\nmp->xfer_func = vivid_xfer_func_cap(dev);\r\nmp->ycbcr_enc = vivid_ycbcr_enc_cap(dev);\r\nmp->quantization = vivid_quantization_cap(dev);\r\nmp->num_planes = dev->fmt_cap->buffers;\r\nfor (p = 0; p < mp->num_planes; p++) {\r\nmp->plane_fmt[p].bytesperline = tpg_g_bytesperline(&dev->tpg, p);\r\nmp->plane_fmt[p].sizeimage =\r\ntpg_g_line_width(&dev->tpg, p) * mp->height +\r\ndev->fmt_cap->data_offset[p];\r\n}\r\nreturn 0;\r\n}\r\nint vivid_try_fmt_vid_cap(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct v4l2_pix_format_mplane *mp = &f->fmt.pix_mp;\r\nstruct v4l2_plane_pix_format *pfmt = mp->plane_fmt;\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nconst struct vivid_fmt *fmt;\r\nunsigned bytesperline, max_bpl;\r\nunsigned factor = 1;\r\nunsigned w, h;\r\nunsigned p;\r\nfmt = vivid_get_format(dev, mp->pixelformat);\r\nif (!fmt) {\r\ndprintk(dev, 1, "Fourcc format (0x%08x) unknown.\n",\r\nmp->pixelformat);\r\nmp->pixelformat = V4L2_PIX_FMT_YUYV;\r\nfmt = vivid_get_format(dev, mp->pixelformat);\r\n}\r\nmp->field = vivid_field_cap(dev, mp->field);\r\nif (vivid_is_webcam(dev)) {\r\nconst struct v4l2_frmsize_discrete *sz =\r\nv4l2_find_nearest_format(&webcam_probe, mp->width, mp->height);\r\nw = sz->width;\r\nh = sz->height;\r\n} else if (vivid_is_sdtv_cap(dev)) {\r\nw = 720;\r\nh = (dev->std_cap & V4L2_STD_525_60) ? 480 : 576;\r\n} else {\r\nw = dev->src_rect.width;\r\nh = dev->src_rect.height;\r\n}\r\nif (V4L2_FIELD_HAS_T_OR_B(mp->field))\r\nfactor = 2;\r\nif (vivid_is_webcam(dev) ||\r\n(!dev->has_scaler_cap && !dev->has_crop_cap && !dev->has_compose_cap)) {\r\nmp->width = w;\r\nmp->height = h / factor;\r\n} else {\r\nstruct v4l2_rect r = { 0, 0, mp->width, mp->height * factor };\r\nrect_set_min_size(&r, &vivid_min_rect);\r\nrect_set_max_size(&r, &vivid_max_rect);\r\nif (dev->has_scaler_cap && !dev->has_compose_cap) {\r\nstruct v4l2_rect max_r = { 0, 0, MAX_ZOOM * w, MAX_ZOOM * h };\r\nrect_set_max_size(&r, &max_r);\r\n} else if (!dev->has_scaler_cap && dev->has_crop_cap && !dev->has_compose_cap) {\r\nrect_set_max_size(&r, &dev->src_rect);\r\n} else if (!dev->has_scaler_cap && !dev->has_crop_cap) {\r\nrect_set_min_size(&r, &dev->src_rect);\r\n}\r\nmp->width = r.width;\r\nmp->height = r.height / factor;\r\n}\r\nmp->num_planes = fmt->buffers;\r\nfor (p = 0; p < mp->num_planes; p++) {\r\nbytesperline = (mp->width * fmt->bit_depth[p]) >> 3;\r\nmax_bpl = (MAX_ZOOM * MAX_WIDTH * fmt->bit_depth[p]) >> 3;\r\nif (pfmt[p].bytesperline > max_bpl)\r\npfmt[p].bytesperline = max_bpl;\r\nif (pfmt[p].bytesperline < bytesperline)\r\npfmt[p].bytesperline = bytesperline;\r\npfmt[p].sizeimage = tpg_calc_line_width(&dev->tpg, p, pfmt[p].bytesperline) *\r\nmp->height + fmt->data_offset[p];\r\nmemset(pfmt[p].reserved, 0, sizeof(pfmt[p].reserved));\r\n}\r\nmp->colorspace = vivid_colorspace_cap(dev);\r\nmp->ycbcr_enc = vivid_ycbcr_enc_cap(dev);\r\nmp->xfer_func = vivid_xfer_func_cap(dev);\r\nmp->quantization = vivid_quantization_cap(dev);\r\nmemset(mp->reserved, 0, sizeof(mp->reserved));\r\nreturn 0;\r\n}\r\nint vivid_s_fmt_vid_cap(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct v4l2_pix_format_mplane *mp = &f->fmt.pix_mp;\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nstruct v4l2_rect *crop = &dev->crop_cap;\r\nstruct v4l2_rect *compose = &dev->compose_cap;\r\nstruct vb2_queue *q = &dev->vb_vid_cap_q;\r\nint ret = vivid_try_fmt_vid_cap(file, priv, f);\r\nunsigned factor = 1;\r\nunsigned p;\r\nunsigned i;\r\nif (ret < 0)\r\nreturn ret;\r\nif (vb2_is_busy(q)) {\r\ndprintk(dev, 1, "%s device busy\n", __func__);\r\nreturn -EBUSY;\r\n}\r\nif (dev->overlay_cap_owner && dev->fb_cap.fmt.pixelformat != mp->pixelformat) {\r\ndprintk(dev, 1, "overlay is active, can't change pixelformat\n");\r\nreturn -EBUSY;\r\n}\r\ndev->fmt_cap = vivid_get_format(dev, mp->pixelformat);\r\nif (V4L2_FIELD_HAS_T_OR_B(mp->field))\r\nfactor = 2;\r\nif (!vivid_is_webcam(dev) &&\r\n(dev->has_scaler_cap || dev->has_crop_cap || dev->has_compose_cap)) {\r\nstruct v4l2_rect r = { 0, 0, mp->width, mp->height };\r\nif (dev->has_scaler_cap) {\r\nif (dev->has_compose_cap)\r\nrect_map_inside(compose, &r);\r\nelse\r\n*compose = r;\r\nif (dev->has_crop_cap && !dev->has_compose_cap) {\r\nstruct v4l2_rect min_r = {\r\n0, 0,\r\nr.width / MAX_ZOOM,\r\nfactor * r.height / MAX_ZOOM\r\n};\r\nstruct v4l2_rect max_r = {\r\n0, 0,\r\nr.width * MAX_ZOOM,\r\nfactor * r.height * MAX_ZOOM\r\n};\r\nrect_set_min_size(crop, &min_r);\r\nrect_set_max_size(crop, &max_r);\r\nrect_map_inside(crop, &dev->crop_bounds_cap);\r\n} else if (dev->has_crop_cap) {\r\nstruct v4l2_rect min_r = {\r\n0, 0,\r\ncompose->width / MAX_ZOOM,\r\nfactor * compose->height / MAX_ZOOM\r\n};\r\nstruct v4l2_rect max_r = {\r\n0, 0,\r\ncompose->width * MAX_ZOOM,\r\nfactor * compose->height * MAX_ZOOM\r\n};\r\nrect_set_min_size(crop, &min_r);\r\nrect_set_max_size(crop, &max_r);\r\nrect_map_inside(crop, &dev->crop_bounds_cap);\r\n}\r\n} else if (dev->has_crop_cap && !dev->has_compose_cap) {\r\nr.height *= factor;\r\nrect_set_size_to(crop, &r);\r\nrect_map_inside(crop, &dev->crop_bounds_cap);\r\nr = *crop;\r\nr.height /= factor;\r\nrect_set_size_to(compose, &r);\r\n} else if (!dev->has_crop_cap) {\r\nrect_map_inside(compose, &r);\r\n} else {\r\nr.height *= factor;\r\nrect_set_max_size(crop, &r);\r\nrect_map_inside(crop, &dev->crop_bounds_cap);\r\ncompose->top *= factor;\r\ncompose->height *= factor;\r\nrect_set_size_to(compose, crop);\r\nrect_map_inside(compose, &r);\r\ncompose->top /= factor;\r\ncompose->height /= factor;\r\n}\r\n} else if (vivid_is_webcam(dev)) {\r\nfor (i = 0; i < ARRAY_SIZE(webcam_sizes); i++)\r\nif (webcam_sizes[i].width == mp->width &&\r\nwebcam_sizes[i].height == mp->height)\r\nbreak;\r\ndev->webcam_size_idx = i;\r\nif (dev->webcam_ival_idx >= 2 * (VIVID_WEBCAM_SIZES - i))\r\ndev->webcam_ival_idx = 2 * (VIVID_WEBCAM_SIZES - i) - 1;\r\nvivid_update_format_cap(dev, false);\r\n} else {\r\nstruct v4l2_rect r = { 0, 0, mp->width, mp->height };\r\nrect_set_size_to(compose, &r);\r\nr.height *= factor;\r\nrect_set_size_to(crop, &r);\r\n}\r\ndev->fmt_cap_rect.width = mp->width;\r\ndev->fmt_cap_rect.height = mp->height;\r\ntpg_s_buf_height(&dev->tpg, mp->height);\r\ntpg_s_fourcc(&dev->tpg, dev->fmt_cap->fourcc);\r\nfor (p = 0; p < tpg_g_buffers(&dev->tpg); p++)\r\ntpg_s_bytesperline(&dev->tpg, p, mp->plane_fmt[p].bytesperline);\r\ndev->field_cap = mp->field;\r\nif (dev->field_cap == V4L2_FIELD_ALTERNATE)\r\ntpg_s_field(&dev->tpg, V4L2_FIELD_TOP, true);\r\nelse\r\ntpg_s_field(&dev->tpg, dev->field_cap, false);\r\ntpg_s_crop_compose(&dev->tpg, &dev->crop_cap, &dev->compose_cap);\r\nif (vivid_is_sdtv_cap(dev))\r\ndev->tv_field_cap = mp->field;\r\ntpg_update_mv_step(&dev->tpg);\r\nreturn 0;\r\n}\r\nint vidioc_g_fmt_vid_cap_mplane(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!dev->multiplanar)\r\nreturn -ENOTTY;\r\nreturn vivid_g_fmt_vid_cap(file, priv, f);\r\n}\r\nint vidioc_try_fmt_vid_cap_mplane(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!dev->multiplanar)\r\nreturn -ENOTTY;\r\nreturn vivid_try_fmt_vid_cap(file, priv, f);\r\n}\r\nint vidioc_s_fmt_vid_cap_mplane(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!dev->multiplanar)\r\nreturn -ENOTTY;\r\nreturn vivid_s_fmt_vid_cap(file, priv, f);\r\n}\r\nint vidioc_g_fmt_vid_cap(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nreturn fmt_sp2mp_func(file, priv, f, vivid_g_fmt_vid_cap);\r\n}\r\nint vidioc_try_fmt_vid_cap(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nreturn fmt_sp2mp_func(file, priv, f, vivid_try_fmt_vid_cap);\r\n}\r\nint vidioc_s_fmt_vid_cap(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nreturn fmt_sp2mp_func(file, priv, f, vivid_s_fmt_vid_cap);\r\n}\r\nint vivid_vid_cap_g_selection(struct file *file, void *priv,\r\nstruct v4l2_selection *sel)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!dev->has_crop_cap && !dev->has_compose_cap)\r\nreturn -ENOTTY;\r\nif (sel->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nreturn -EINVAL;\r\nif (vivid_is_webcam(dev))\r\nreturn -EINVAL;\r\nsel->r.left = sel->r.top = 0;\r\nswitch (sel->target) {\r\ncase V4L2_SEL_TGT_CROP:\r\nif (!dev->has_crop_cap)\r\nreturn -EINVAL;\r\nsel->r = dev->crop_cap;\r\nbreak;\r\ncase V4L2_SEL_TGT_CROP_DEFAULT:\r\ncase V4L2_SEL_TGT_CROP_BOUNDS:\r\nif (!dev->has_crop_cap)\r\nreturn -EINVAL;\r\nsel->r = dev->src_rect;\r\nbreak;\r\ncase V4L2_SEL_TGT_COMPOSE_BOUNDS:\r\nif (!dev->has_compose_cap)\r\nreturn -EINVAL;\r\nsel->r = vivid_max_rect;\r\nbreak;\r\ncase V4L2_SEL_TGT_COMPOSE:\r\nif (!dev->has_compose_cap)\r\nreturn -EINVAL;\r\nsel->r = dev->compose_cap;\r\nbreak;\r\ncase V4L2_SEL_TGT_COMPOSE_DEFAULT:\r\nif (!dev->has_compose_cap)\r\nreturn -EINVAL;\r\nsel->r = dev->fmt_cap_rect;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_s_selection(struct file *file, void *fh, struct v4l2_selection *s)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nstruct v4l2_rect *crop = &dev->crop_cap;\r\nstruct v4l2_rect *compose = &dev->compose_cap;\r\nunsigned factor = V4L2_FIELD_HAS_T_OR_B(dev->field_cap) ? 2 : 1;\r\nint ret;\r\nif (!dev->has_crop_cap && !dev->has_compose_cap)\r\nreturn -ENOTTY;\r\nif (s->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nreturn -EINVAL;\r\nif (vivid_is_webcam(dev))\r\nreturn -EINVAL;\r\nswitch (s->target) {\r\ncase V4L2_SEL_TGT_CROP:\r\nif (!dev->has_crop_cap)\r\nreturn -EINVAL;\r\nret = vivid_vid_adjust_sel(s->flags, &s->r);\r\nif (ret)\r\nreturn ret;\r\nrect_set_min_size(&s->r, &vivid_min_rect);\r\nrect_set_max_size(&s->r, &dev->src_rect);\r\nrect_map_inside(&s->r, &dev->crop_bounds_cap);\r\ns->r.top /= factor;\r\ns->r.height /= factor;\r\nif (dev->has_scaler_cap) {\r\nstruct v4l2_rect fmt = dev->fmt_cap_rect;\r\nstruct v4l2_rect max_rect = {\r\n0, 0,\r\ns->r.width * MAX_ZOOM,\r\ns->r.height * MAX_ZOOM\r\n};\r\nstruct v4l2_rect min_rect = {\r\n0, 0,\r\ns->r.width / MAX_ZOOM,\r\ns->r.height / MAX_ZOOM\r\n};\r\nrect_set_min_size(&fmt, &min_rect);\r\nif (!dev->has_compose_cap)\r\nrect_set_max_size(&fmt, &max_rect);\r\nif (!rect_same_size(&dev->fmt_cap_rect, &fmt) &&\r\nvb2_is_busy(&dev->vb_vid_cap_q))\r\nreturn -EBUSY;\r\nif (dev->has_compose_cap) {\r\nrect_set_min_size(compose, &min_rect);\r\nrect_set_max_size(compose, &max_rect);\r\n}\r\ndev->fmt_cap_rect = fmt;\r\ntpg_s_buf_height(&dev->tpg, fmt.height);\r\n} else if (dev->has_compose_cap) {\r\nstruct v4l2_rect fmt = dev->fmt_cap_rect;\r\nrect_set_min_size(&fmt, &s->r);\r\nif (!rect_same_size(&dev->fmt_cap_rect, &fmt) &&\r\nvb2_is_busy(&dev->vb_vid_cap_q))\r\nreturn -EBUSY;\r\ndev->fmt_cap_rect = fmt;\r\ntpg_s_buf_height(&dev->tpg, fmt.height);\r\nrect_set_size_to(compose, &s->r);\r\nrect_map_inside(compose, &dev->fmt_cap_rect);\r\n} else {\r\nif (!rect_same_size(&s->r, &dev->fmt_cap_rect) &&\r\nvb2_is_busy(&dev->vb_vid_cap_q))\r\nreturn -EBUSY;\r\nrect_set_size_to(&dev->fmt_cap_rect, &s->r);\r\nrect_set_size_to(compose, &s->r);\r\nrect_map_inside(compose, &dev->fmt_cap_rect);\r\ntpg_s_buf_height(&dev->tpg, dev->fmt_cap_rect.height);\r\n}\r\ns->r.top *= factor;\r\ns->r.height *= factor;\r\n*crop = s->r;\r\nbreak;\r\ncase V4L2_SEL_TGT_COMPOSE:\r\nif (!dev->has_compose_cap)\r\nreturn -EINVAL;\r\nret = vivid_vid_adjust_sel(s->flags, &s->r);\r\nif (ret)\r\nreturn ret;\r\nrect_set_min_size(&s->r, &vivid_min_rect);\r\nrect_set_max_size(&s->r, &dev->fmt_cap_rect);\r\nif (dev->has_scaler_cap) {\r\nstruct v4l2_rect max_rect = {\r\n0, 0,\r\ndev->src_rect.width * MAX_ZOOM,\r\n(dev->src_rect.height / factor) * MAX_ZOOM\r\n};\r\nrect_set_max_size(&s->r, &max_rect);\r\nif (dev->has_crop_cap) {\r\nstruct v4l2_rect min_rect = {\r\n0, 0,\r\ns->r.width / MAX_ZOOM,\r\n(s->r.height * factor) / MAX_ZOOM\r\n};\r\nstruct v4l2_rect max_rect = {\r\n0, 0,\r\ns->r.width * MAX_ZOOM,\r\n(s->r.height * factor) * MAX_ZOOM\r\n};\r\nrect_set_min_size(crop, &min_rect);\r\nrect_set_max_size(crop, &max_rect);\r\nrect_map_inside(crop, &dev->crop_bounds_cap);\r\n}\r\n} else if (dev->has_crop_cap) {\r\ns->r.top *= factor;\r\ns->r.height *= factor;\r\nrect_set_max_size(&s->r, &dev->src_rect);\r\nrect_set_size_to(crop, &s->r);\r\nrect_map_inside(crop, &dev->crop_bounds_cap);\r\ns->r.top /= factor;\r\ns->r.height /= factor;\r\n} else {\r\nrect_set_size_to(&s->r, &dev->src_rect);\r\ns->r.height /= factor;\r\n}\r\nrect_map_inside(&s->r, &dev->fmt_cap_rect);\r\nif (dev->bitmap_cap && (compose->width != s->r.width ||\r\ncompose->height != s->r.height)) {\r\nkfree(dev->bitmap_cap);\r\ndev->bitmap_cap = NULL;\r\n}\r\n*compose = s->r;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ntpg_s_crop_compose(&dev->tpg, crop, compose);\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_cropcap(struct file *file, void *priv,\r\nstruct v4l2_cropcap *cap)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (cap->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nreturn -EINVAL;\r\nswitch (vivid_get_pixel_aspect(dev)) {\r\ncase TPG_PIXEL_ASPECT_NTSC:\r\ncap->pixelaspect.numerator = 11;\r\ncap->pixelaspect.denominator = 10;\r\nbreak;\r\ncase TPG_PIXEL_ASPECT_PAL:\r\ncap->pixelaspect.numerator = 54;\r\ncap->pixelaspect.denominator = 59;\r\nbreak;\r\ncase TPG_PIXEL_ASPECT_SQUARE:\r\ncap->pixelaspect.numerator = 1;\r\ncap->pixelaspect.denominator = 1;\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nint vidioc_enum_fmt_vid_overlay(struct file *file, void *priv,\r\nstruct v4l2_fmtdesc *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nconst struct vivid_fmt *fmt;\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nif (f->index >= ARRAY_SIZE(formats_ovl))\r\nreturn -EINVAL;\r\nfmt = &formats_ovl[f->index];\r\nf->pixelformat = fmt->fourcc;\r\nreturn 0;\r\n}\r\nint vidioc_g_fmt_vid_overlay(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nconst struct v4l2_rect *compose = &dev->compose_cap;\r\nstruct v4l2_window *win = &f->fmt.win;\r\nunsigned clipcount = win->clipcount;\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nwin->w.top = dev->overlay_cap_top;\r\nwin->w.left = dev->overlay_cap_left;\r\nwin->w.width = compose->width;\r\nwin->w.height = compose->height;\r\nwin->field = dev->overlay_cap_field;\r\nwin->clipcount = dev->clipcount_cap;\r\nif (clipcount > dev->clipcount_cap)\r\nclipcount = dev->clipcount_cap;\r\nif (dev->bitmap_cap == NULL)\r\nwin->bitmap = NULL;\r\nelse if (win->bitmap) {\r\nif (copy_to_user(win->bitmap, dev->bitmap_cap,\r\n((compose->width + 7) / 8) * compose->height))\r\nreturn -EFAULT;\r\n}\r\nif (clipcount && win->clips) {\r\nif (copy_to_user(win->clips, dev->clips_cap,\r\nclipcount * sizeof(dev->clips_cap[0])))\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nint vidioc_try_fmt_vid_overlay(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nconst struct v4l2_rect *compose = &dev->compose_cap;\r\nstruct v4l2_window *win = &f->fmt.win;\r\nint i, j;\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nwin->w.left = clamp_t(int, win->w.left,\r\n-dev->fb_cap.fmt.width, dev->fb_cap.fmt.width);\r\nwin->w.top = clamp_t(int, win->w.top,\r\n-dev->fb_cap.fmt.height, dev->fb_cap.fmt.height);\r\nwin->w.width = compose->width;\r\nwin->w.height = compose->height;\r\nif (win->field != V4L2_FIELD_BOTTOM && win->field != V4L2_FIELD_TOP)\r\nwin->field = V4L2_FIELD_ANY;\r\nwin->chromakey = 0;\r\nwin->global_alpha = 0;\r\nif (win->clipcount && !win->clips)\r\nwin->clipcount = 0;\r\nif (win->clipcount > MAX_CLIPS)\r\nwin->clipcount = MAX_CLIPS;\r\nif (win->clipcount) {\r\nif (copy_from_user(dev->try_clips_cap, win->clips,\r\nwin->clipcount * sizeof(dev->clips_cap[0])))\r\nreturn -EFAULT;\r\nfor (i = 0; i < win->clipcount; i++) {\r\nstruct v4l2_rect *r = &dev->try_clips_cap[i].c;\r\nr->top = clamp_t(s32, r->top, 0, dev->fb_cap.fmt.height - 1);\r\nr->height = clamp_t(s32, r->height, 1, dev->fb_cap.fmt.height - r->top);\r\nr->left = clamp_t(u32, r->left, 0, dev->fb_cap.fmt.width - 1);\r\nr->width = clamp_t(u32, r->width, 1, dev->fb_cap.fmt.width - r->left);\r\n}\r\nfor (i = 0; i < win->clipcount - 1; i++) {\r\nstruct v4l2_rect *r1 = &dev->try_clips_cap[i].c;\r\nfor (j = i + 1; j < win->clipcount; j++) {\r\nstruct v4l2_rect *r2 = &dev->try_clips_cap[j].c;\r\nif (rect_overlap(r1, r2))\r\nreturn -EINVAL;\r\n}\r\n}\r\nif (copy_to_user(win->clips, dev->try_clips_cap,\r\nwin->clipcount * sizeof(dev->clips_cap[0])))\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nint vidioc_s_fmt_vid_overlay(struct file *file, void *priv,\r\nstruct v4l2_format *f)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nconst struct v4l2_rect *compose = &dev->compose_cap;\r\nstruct v4l2_window *win = &f->fmt.win;\r\nint ret = vidioc_try_fmt_vid_overlay(file, priv, f);\r\nunsigned bitmap_size = ((compose->width + 7) / 8) * compose->height;\r\nunsigned clips_size = win->clipcount * sizeof(dev->clips_cap[0]);\r\nvoid *new_bitmap = NULL;\r\nif (ret)\r\nreturn ret;\r\nif (win->bitmap) {\r\nnew_bitmap = vzalloc(bitmap_size);\r\nif (new_bitmap == NULL)\r\nreturn -ENOMEM;\r\nif (copy_from_user(new_bitmap, win->bitmap, bitmap_size)) {\r\nvfree(new_bitmap);\r\nreturn -EFAULT;\r\n}\r\n}\r\ndev->overlay_cap_top = win->w.top;\r\ndev->overlay_cap_left = win->w.left;\r\ndev->overlay_cap_field = win->field;\r\nvfree(dev->bitmap_cap);\r\ndev->bitmap_cap = new_bitmap;\r\ndev->clipcount_cap = win->clipcount;\r\nif (dev->clipcount_cap)\r\nmemcpy(dev->clips_cap, dev->try_clips_cap, clips_size);\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_overlay(struct file *file, void *fh, unsigned i)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nif (i && dev->fb_vbase_cap == NULL)\r\nreturn -EINVAL;\r\nif (i && dev->fb_cap.fmt.pixelformat != dev->fmt_cap->fourcc) {\r\ndprintk(dev, 1, "mismatch between overlay and video capture pixelformats\n");\r\nreturn -EINVAL;\r\n}\r\nif (dev->overlay_cap_owner && dev->overlay_cap_owner != fh)\r\nreturn -EBUSY;\r\ndev->overlay_cap_owner = i ? fh : NULL;\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_g_fbuf(struct file *file, void *fh,\r\nstruct v4l2_framebuffer *a)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\n*a = dev->fb_cap;\r\na->capability = V4L2_FBUF_CAP_BITMAP_CLIPPING |\r\nV4L2_FBUF_CAP_LIST_CLIPPING;\r\na->flags = V4L2_FBUF_FLAG_PRIMARY;\r\na->fmt.field = V4L2_FIELD_NONE;\r\na->fmt.colorspace = V4L2_COLORSPACE_SRGB;\r\na->fmt.priv = 0;\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_s_fbuf(struct file *file, void *fh,\r\nconst struct v4l2_framebuffer *a)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nconst struct vivid_fmt *fmt;\r\nif (dev->multiplanar)\r\nreturn -ENOTTY;\r\nif (!capable(CAP_SYS_ADMIN) && !capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\nif (dev->overlay_cap_owner)\r\nreturn -EBUSY;\r\nif (a->base == NULL) {\r\ndev->fb_cap.base = NULL;\r\ndev->fb_vbase_cap = NULL;\r\nreturn 0;\r\n}\r\nif (a->fmt.width < 48 || a->fmt.height < 32)\r\nreturn -EINVAL;\r\nfmt = vivid_get_format(dev, a->fmt.pixelformat);\r\nif (!fmt || !fmt->can_do_overlay)\r\nreturn -EINVAL;\r\nif (a->fmt.bytesperline < (a->fmt.width * fmt->bit_depth[0]) / 8)\r\nreturn -EINVAL;\r\nif (a->fmt.height * a->fmt.bytesperline < a->fmt.sizeimage)\r\nreturn -EINVAL;\r\ndev->fb_vbase_cap = phys_to_virt((unsigned long)a->base);\r\ndev->fb_cap = *a;\r\ndev->overlay_cap_left = clamp_t(int, dev->overlay_cap_left,\r\n-dev->fb_cap.fmt.width, dev->fb_cap.fmt.width);\r\ndev->overlay_cap_top = clamp_t(int, dev->overlay_cap_top,\r\n-dev->fb_cap.fmt.height, dev->fb_cap.fmt.height);\r\nreturn 0;\r\n}\r\nint vidioc_enum_input(struct file *file, void *priv,\r\nstruct v4l2_input *inp)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (inp->index >= dev->num_inputs)\r\nreturn -EINVAL;\r\ninp->type = V4L2_INPUT_TYPE_CAMERA;\r\nswitch (dev->input_type[inp->index]) {\r\ncase WEBCAM:\r\nsnprintf(inp->name, sizeof(inp->name), "Webcam %u",\r\ndev->input_name_counter[inp->index]);\r\ninp->capabilities = 0;\r\nbreak;\r\ncase TV:\r\nsnprintf(inp->name, sizeof(inp->name), "TV %u",\r\ndev->input_name_counter[inp->index]);\r\ninp->type = V4L2_INPUT_TYPE_TUNER;\r\ninp->std = V4L2_STD_ALL;\r\nif (dev->has_audio_inputs)\r\ninp->audioset = (1 << ARRAY_SIZE(vivid_audio_inputs)) - 1;\r\ninp->capabilities = V4L2_IN_CAP_STD;\r\nbreak;\r\ncase SVID:\r\nsnprintf(inp->name, sizeof(inp->name), "S-Video %u",\r\ndev->input_name_counter[inp->index]);\r\ninp->std = V4L2_STD_ALL;\r\nif (dev->has_audio_inputs)\r\ninp->audioset = (1 << ARRAY_SIZE(vivid_audio_inputs)) - 1;\r\ninp->capabilities = V4L2_IN_CAP_STD;\r\nbreak;\r\ncase HDMI:\r\nsnprintf(inp->name, sizeof(inp->name), "HDMI %u",\r\ndev->input_name_counter[inp->index]);\r\ninp->capabilities = V4L2_IN_CAP_DV_TIMINGS;\r\nif (dev->edid_blocks == 0 ||\r\ndev->dv_timings_signal_mode == NO_SIGNAL)\r\ninp->status |= V4L2_IN_ST_NO_SIGNAL;\r\nelse if (dev->dv_timings_signal_mode == NO_LOCK ||\r\ndev->dv_timings_signal_mode == OUT_OF_RANGE)\r\ninp->status |= V4L2_IN_ST_NO_H_LOCK;\r\nbreak;\r\n}\r\nif (dev->sensor_hflip)\r\ninp->status |= V4L2_IN_ST_HFLIP;\r\nif (dev->sensor_vflip)\r\ninp->status |= V4L2_IN_ST_VFLIP;\r\nif (dev->input == inp->index && vivid_is_sdtv_cap(dev)) {\r\nif (dev->std_signal_mode == NO_SIGNAL) {\r\ninp->status |= V4L2_IN_ST_NO_SIGNAL;\r\n} else if (dev->std_signal_mode == NO_LOCK) {\r\ninp->status |= V4L2_IN_ST_NO_H_LOCK;\r\n} else if (vivid_is_tv_cap(dev)) {\r\nswitch (tpg_g_quality(&dev->tpg)) {\r\ncase TPG_QUAL_GRAY:\r\ninp->status |= V4L2_IN_ST_COLOR_KILL;\r\nbreak;\r\ncase TPG_QUAL_NOISE:\r\ninp->status |= V4L2_IN_ST_NO_H_LOCK;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint vidioc_g_input(struct file *file, void *priv, unsigned *i)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\n*i = dev->input;\r\nreturn 0;\r\n}\r\nint vidioc_s_input(struct file *file, void *priv, unsigned i)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nstruct v4l2_bt_timings *bt = &dev->dv_timings_cap.bt;\r\nunsigned brightness;\r\nif (i >= dev->num_inputs)\r\nreturn -EINVAL;\r\nif (i == dev->input)\r\nreturn 0;\r\nif (vb2_is_busy(&dev->vb_vid_cap_q) || vb2_is_busy(&dev->vb_vbi_cap_q))\r\nreturn -EBUSY;\r\ndev->input = i;\r\ndev->vid_cap_dev.tvnorms = 0;\r\nif (dev->input_type[i] == TV || dev->input_type[i] == SVID) {\r\ndev->tv_audio_input = (dev->input_type[i] == TV) ? 0 : 1;\r\ndev->vid_cap_dev.tvnorms = V4L2_STD_ALL;\r\n}\r\ndev->vbi_cap_dev.tvnorms = dev->vid_cap_dev.tvnorms;\r\nvivid_update_format_cap(dev, false);\r\nif (dev->colorspace) {\r\nswitch (dev->input_type[i]) {\r\ncase WEBCAM:\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_SRGB);\r\nbreak;\r\ncase TV:\r\ncase SVID:\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_170M);\r\nbreak;\r\ncase HDMI:\r\nif (bt->flags & V4L2_DV_FL_IS_CE_VIDEO) {\r\nif (dev->src_rect.width == 720 && dev->src_rect.height <= 576)\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_170M);\r\nelse\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_709);\r\n} else {\r\nv4l2_ctrl_s_ctrl(dev->colorspace, VIVID_CS_SRGB);\r\n}\r\nbreak;\r\n}\r\n}\r\nbrightness = 128 * i + dev->input_brightness[i];\r\nv4l2_ctrl_modify_range(dev->brightness,\r\n128 * i, 255 + 128 * i, 1, 128 + 128 * i);\r\nv4l2_ctrl_s_ctrl(dev->brightness, brightness);\r\nreturn 0;\r\n}\r\nint vidioc_enumaudio(struct file *file, void *fh, struct v4l2_audio *vin)\r\n{\r\nif (vin->index >= ARRAY_SIZE(vivid_audio_inputs))\r\nreturn -EINVAL;\r\n*vin = vivid_audio_inputs[vin->index];\r\nreturn 0;\r\n}\r\nint vidioc_g_audio(struct file *file, void *fh, struct v4l2_audio *vin)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!vivid_is_sdtv_cap(dev))\r\nreturn -EINVAL;\r\n*vin = vivid_audio_inputs[dev->tv_audio_input];\r\nreturn 0;\r\n}\r\nint vidioc_s_audio(struct file *file, void *fh, const struct v4l2_audio *vin)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!vivid_is_sdtv_cap(dev))\r\nreturn -EINVAL;\r\nif (vin->index >= ARRAY_SIZE(vivid_audio_inputs))\r\nreturn -EINVAL;\r\ndev->tv_audio_input = vin->index;\r\nreturn 0;\r\n}\r\nint vivid_video_g_frequency(struct file *file, void *fh, struct v4l2_frequency *vf)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (vf->tuner != 0)\r\nreturn -EINVAL;\r\nvf->frequency = dev->tv_freq;\r\nreturn 0;\r\n}\r\nint vivid_video_s_frequency(struct file *file, void *fh, const struct v4l2_frequency *vf)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (vf->tuner != 0)\r\nreturn -EINVAL;\r\ndev->tv_freq = clamp_t(unsigned, vf->frequency, MIN_TV_FREQ, MAX_TV_FREQ);\r\nif (vivid_is_tv_cap(dev))\r\nvivid_update_quality(dev);\r\nreturn 0;\r\n}\r\nint vivid_video_s_tuner(struct file *file, void *fh, const struct v4l2_tuner *vt)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (vt->index != 0)\r\nreturn -EINVAL;\r\nif (vt->audmode > V4L2_TUNER_MODE_LANG1_LANG2)\r\nreturn -EINVAL;\r\ndev->tv_audmode = vt->audmode;\r\nreturn 0;\r\n}\r\nint vivid_video_g_tuner(struct file *file, void *fh, struct v4l2_tuner *vt)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nenum tpg_quality qual;\r\nif (vt->index != 0)\r\nreturn -EINVAL;\r\nvt->capability = V4L2_TUNER_CAP_NORM | V4L2_TUNER_CAP_STEREO |\r\nV4L2_TUNER_CAP_LANG1 | V4L2_TUNER_CAP_LANG2;\r\nvt->audmode = dev->tv_audmode;\r\nvt->rangelow = MIN_TV_FREQ;\r\nvt->rangehigh = MAX_TV_FREQ;\r\nqual = vivid_get_quality(dev, &vt->afc);\r\nif (qual == TPG_QUAL_COLOR)\r\nvt->signal = 0xffff;\r\nelse if (qual == TPG_QUAL_GRAY)\r\nvt->signal = 0x8000;\r\nelse\r\nvt->signal = 0;\r\nif (qual == TPG_QUAL_NOISE) {\r\nvt->rxsubchans = 0;\r\n} else if (qual == TPG_QUAL_GRAY) {\r\nvt->rxsubchans = V4L2_TUNER_SUB_MONO;\r\n} else {\r\nunsigned channel_nr = dev->tv_freq / (6 * 16);\r\nunsigned options = (dev->std_cap & V4L2_STD_NTSC_M) ? 4 : 3;\r\nswitch (channel_nr % options) {\r\ncase 0:\r\nvt->rxsubchans = V4L2_TUNER_SUB_MONO;\r\nbreak;\r\ncase 1:\r\nvt->rxsubchans = V4L2_TUNER_SUB_STEREO;\r\nbreak;\r\ncase 2:\r\nif (dev->std_cap & V4L2_STD_NTSC_M)\r\nvt->rxsubchans = V4L2_TUNER_SUB_MONO | V4L2_TUNER_SUB_SAP;\r\nelse\r\nvt->rxsubchans = V4L2_TUNER_SUB_LANG1 | V4L2_TUNER_SUB_LANG2;\r\nbreak;\r\ncase 3:\r\nvt->rxsubchans = V4L2_TUNER_SUB_STEREO | V4L2_TUNER_SUB_SAP;\r\nbreak;\r\n}\r\n}\r\nstrlcpy(vt->name, "TV Tuner", sizeof(vt->name));\r\nreturn 0;\r\n}\r\nint vidioc_querystd(struct file *file, void *priv, v4l2_std_id *id)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!vivid_is_sdtv_cap(dev))\r\nreturn -ENODATA;\r\nif (dev->std_signal_mode == NO_SIGNAL ||\r\ndev->std_signal_mode == NO_LOCK) {\r\n*id = V4L2_STD_UNKNOWN;\r\nreturn 0;\r\n}\r\nif (vivid_is_tv_cap(dev) && tpg_g_quality(&dev->tpg) == TPG_QUAL_NOISE) {\r\n*id = V4L2_STD_UNKNOWN;\r\n} else if (dev->std_signal_mode == CURRENT_STD) {\r\n*id = dev->std_cap;\r\n} else if (dev->std_signal_mode == SELECTED_STD) {\r\n*id = dev->query_std;\r\n} else {\r\n*id = vivid_standard[dev->query_std_last];\r\ndev->query_std_last = (dev->query_std_last + 1) % ARRAY_SIZE(vivid_standard);\r\n}\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_s_std(struct file *file, void *priv, v4l2_std_id id)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!vivid_is_sdtv_cap(dev))\r\nreturn -ENODATA;\r\nif (dev->std_cap == id)\r\nreturn 0;\r\nif (vb2_is_busy(&dev->vb_vid_cap_q) || vb2_is_busy(&dev->vb_vbi_cap_q))\r\nreturn -EBUSY;\r\ndev->std_cap = id;\r\nvivid_update_format_cap(dev, false);\r\nreturn 0;\r\n}\r\nstatic void find_aspect_ratio(u32 width, u32 height,\r\nu32 *num, u32 *denom)\r\n{\r\nif (!(height % 3) && ((height * 4 / 3) == width)) {\r\n*num = 4;\r\n*denom = 3;\r\n} else if (!(height % 9) && ((height * 16 / 9) == width)) {\r\n*num = 16;\r\n*denom = 9;\r\n} else if (!(height % 10) && ((height * 16 / 10) == width)) {\r\n*num = 16;\r\n*denom = 10;\r\n} else if (!(height % 4) && ((height * 5 / 4) == width)) {\r\n*num = 5;\r\n*denom = 4;\r\n} else if (!(height % 9) && ((height * 15 / 9) == width)) {\r\n*num = 15;\r\n*denom = 9;\r\n} else {\r\n*num = 16;\r\n*denom = 9;\r\n}\r\n}\r\nstatic bool valid_cvt_gtf_timings(struct v4l2_dv_timings *timings)\r\n{\r\nstruct v4l2_bt_timings *bt = &timings->bt;\r\nu32 total_h_pixel;\r\nu32 total_v_lines;\r\nu32 h_freq;\r\nif (!v4l2_valid_dv_timings(timings, &vivid_dv_timings_cap,\r\nNULL, NULL))\r\nreturn false;\r\ntotal_h_pixel = V4L2_DV_BT_FRAME_WIDTH(bt);\r\ntotal_v_lines = V4L2_DV_BT_FRAME_HEIGHT(bt);\r\nh_freq = (u32)bt->pixelclock / total_h_pixel;\r\nif (bt->standards == 0 || (bt->standards & V4L2_DV_BT_STD_CVT)) {\r\nif (v4l2_detect_cvt(total_v_lines, h_freq, bt->vsync, bt->width,\r\nbt->polarities, bt->interlaced, timings))\r\nreturn true;\r\n}\r\nif (bt->standards == 0 || (bt->standards & V4L2_DV_BT_STD_GTF)) {\r\nstruct v4l2_fract aspect_ratio;\r\nfind_aspect_ratio(bt->width, bt->height,\r\n&aspect_ratio.numerator,\r\n&aspect_ratio.denominator);\r\nif (v4l2_detect_gtf(total_v_lines, h_freq, bt->vsync,\r\nbt->polarities, bt->interlaced,\r\naspect_ratio, timings))\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nint vivid_vid_cap_s_dv_timings(struct file *file, void *_fh,\r\nstruct v4l2_dv_timings *timings)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!vivid_is_hdmi_cap(dev))\r\nreturn -ENODATA;\r\nif (!v4l2_find_dv_timings_cap(timings, &vivid_dv_timings_cap,\r\n0, NULL, NULL) &&\r\n!valid_cvt_gtf_timings(timings))\r\nreturn -EINVAL;\r\nif (v4l2_match_dv_timings(timings, &dev->dv_timings_cap, 0, false))\r\nreturn 0;\r\nif (vb2_is_busy(&dev->vb_vid_cap_q))\r\nreturn -EBUSY;\r\ndev->dv_timings_cap = *timings;\r\nvivid_update_format_cap(dev, false);\r\nreturn 0;\r\n}\r\nint vidioc_query_dv_timings(struct file *file, void *_fh,\r\nstruct v4l2_dv_timings *timings)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!vivid_is_hdmi_cap(dev))\r\nreturn -ENODATA;\r\nif (dev->dv_timings_signal_mode == NO_SIGNAL ||\r\ndev->edid_blocks == 0)\r\nreturn -ENOLINK;\r\nif (dev->dv_timings_signal_mode == NO_LOCK)\r\nreturn -ENOLCK;\r\nif (dev->dv_timings_signal_mode == OUT_OF_RANGE) {\r\ntimings->bt.pixelclock = vivid_dv_timings_cap.bt.max_pixelclock * 2;\r\nreturn -ERANGE;\r\n}\r\nif (dev->dv_timings_signal_mode == CURRENT_DV_TIMINGS) {\r\n*timings = dev->dv_timings_cap;\r\n} else if (dev->dv_timings_signal_mode == SELECTED_DV_TIMINGS) {\r\n*timings = v4l2_dv_timings_presets[dev->query_dv_timings];\r\n} else {\r\n*timings = v4l2_dv_timings_presets[dev->query_dv_timings_last];\r\ndev->query_dv_timings_last = (dev->query_dv_timings_last + 1) %\r\ndev->query_dv_timings_size;\r\n}\r\nreturn 0;\r\n}\r\nint vidioc_s_edid(struct file *file, void *_fh,\r\nstruct v4l2_edid *edid)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nmemset(edid->reserved, 0, sizeof(edid->reserved));\r\nif (edid->pad >= dev->num_inputs)\r\nreturn -EINVAL;\r\nif (dev->input_type[edid->pad] != HDMI || edid->start_block)\r\nreturn -EINVAL;\r\nif (edid->blocks == 0) {\r\ndev->edid_blocks = 0;\r\nreturn 0;\r\n}\r\nif (edid->blocks > dev->edid_max_blocks) {\r\nedid->blocks = dev->edid_max_blocks;\r\nreturn -E2BIG;\r\n}\r\ndev->edid_blocks = edid->blocks;\r\nmemcpy(dev->edid, edid->edid, edid->blocks * 128);\r\nreturn 0;\r\n}\r\nint vidioc_enum_framesizes(struct file *file, void *fh,\r\nstruct v4l2_frmsizeenum *fsize)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (!vivid_is_webcam(dev) && !dev->has_scaler_cap)\r\nreturn -EINVAL;\r\nif (vivid_get_format(dev, fsize->pixel_format) == NULL)\r\nreturn -EINVAL;\r\nif (vivid_is_webcam(dev)) {\r\nif (fsize->index >= ARRAY_SIZE(webcam_sizes))\r\nreturn -EINVAL;\r\nfsize->type = V4L2_FRMSIZE_TYPE_DISCRETE;\r\nfsize->discrete = webcam_sizes[fsize->index];\r\nreturn 0;\r\n}\r\nif (fsize->index)\r\nreturn -EINVAL;\r\nfsize->type = V4L2_FRMSIZE_TYPE_STEPWISE;\r\nfsize->stepwise.min_width = MIN_WIDTH;\r\nfsize->stepwise.max_width = MAX_WIDTH * MAX_ZOOM;\r\nfsize->stepwise.step_width = 2;\r\nfsize->stepwise.min_height = MIN_HEIGHT;\r\nfsize->stepwise.max_height = MAX_HEIGHT * MAX_ZOOM;\r\nfsize->stepwise.step_height = 2;\r\nreturn 0;\r\n}\r\nint vidioc_enum_frameintervals(struct file *file, void *priv,\r\nstruct v4l2_frmivalenum *fival)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nconst struct vivid_fmt *fmt;\r\nint i;\r\nfmt = vivid_get_format(dev, fival->pixel_format);\r\nif (!fmt)\r\nreturn -EINVAL;\r\nif (!vivid_is_webcam(dev)) {\r\nif (fival->index)\r\nreturn -EINVAL;\r\nif (fival->width < MIN_WIDTH || fival->width > MAX_WIDTH * MAX_ZOOM)\r\nreturn -EINVAL;\r\nif (fival->height < MIN_HEIGHT || fival->height > MAX_HEIGHT * MAX_ZOOM)\r\nreturn -EINVAL;\r\nfival->type = V4L2_FRMIVAL_TYPE_DISCRETE;\r\nfival->discrete = dev->timeperframe_vid_cap;\r\nreturn 0;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(webcam_sizes); i++)\r\nif (fival->width == webcam_sizes[i].width &&\r\nfival->height == webcam_sizes[i].height)\r\nbreak;\r\nif (i == ARRAY_SIZE(webcam_sizes))\r\nreturn -EINVAL;\r\nif (fival->index >= 2 * (VIVID_WEBCAM_SIZES - i))\r\nreturn -EINVAL;\r\nfival->type = V4L2_FRMIVAL_TYPE_DISCRETE;\r\nfival->discrete = webcam_intervals[fival->index];\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_g_parm(struct file *file, void *priv,\r\nstruct v4l2_streamparm *parm)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nif (parm->type != (dev->multiplanar ?\r\nV4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE :\r\nV4L2_BUF_TYPE_VIDEO_CAPTURE))\r\nreturn -EINVAL;\r\nparm->parm.capture.capability = V4L2_CAP_TIMEPERFRAME;\r\nparm->parm.capture.timeperframe = dev->timeperframe_vid_cap;\r\nparm->parm.capture.readbuffers = 1;\r\nreturn 0;\r\n}\r\nint vivid_vid_cap_s_parm(struct file *file, void *priv,\r\nstruct v4l2_streamparm *parm)\r\n{\r\nstruct vivid_dev *dev = video_drvdata(file);\r\nunsigned ival_sz = 2 * (VIVID_WEBCAM_SIZES - dev->webcam_size_idx);\r\nstruct v4l2_fract tpf;\r\nunsigned i;\r\nif (parm->type != (dev->multiplanar ?\r\nV4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE :\r\nV4L2_BUF_TYPE_VIDEO_CAPTURE))\r\nreturn -EINVAL;\r\nif (!vivid_is_webcam(dev))\r\nreturn vivid_vid_cap_g_parm(file, priv, parm);\r\ntpf = parm->parm.capture.timeperframe;\r\nif (tpf.denominator == 0)\r\ntpf = webcam_intervals[ival_sz - 1];\r\nfor (i = 0; i < ival_sz; i++)\r\nif (FRACT_CMP(tpf, >=, webcam_intervals[i]))\r\nbreak;\r\nif (i == ival_sz)\r\ni = ival_sz - 1;\r\ndev->webcam_ival_idx = i;\r\ntpf = webcam_intervals[dev->webcam_ival_idx];\r\ntpf = FRACT_CMP(tpf, <, tpf_min) ? tpf_min : tpf;\r\ntpf = FRACT_CMP(tpf, >, tpf_max) ? tpf_max : tpf;\r\ndev->cap_seq_resync = true;\r\ndev->timeperframe_vid_cap = tpf;\r\nparm->parm.capture.timeperframe = tpf;\r\nparm->parm.capture.readbuffers = 1;\r\nreturn 0;\r\n}
