void __iomem *etnaviv_ioremap(struct platform_device *pdev, const char *name,\r\nconst char *dbgname)\r\n{\r\nstruct resource *res;\r\nvoid __iomem *ptr;\r\nif (name)\r\nres = platform_get_resource_byname(pdev, IORESOURCE_MEM, name);\r\nelse\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nptr = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(ptr)) {\r\ndev_err(&pdev->dev, "failed to ioremap %s: %ld\n", name,\r\nPTR_ERR(ptr));\r\nreturn ptr;\r\n}\r\nif (reglog)\r\ndev_printk(KERN_DEBUG, &pdev->dev, "IO:region %s 0x%p %08zx\n",\r\ndbgname, ptr, (size_t)resource_size(res));\r\nreturn ptr;\r\n}\r\nvoid etnaviv_writel(u32 data, void __iomem *addr)\r\n{\r\nif (reglog)\r\nprintk(KERN_DEBUG "IO:W %p %08x\n", addr, data);\r\nwritel(data, addr);\r\n}\r\nu32 etnaviv_readl(const void __iomem *addr)\r\n{\r\nu32 val = readl(addr);\r\nif (reglog)\r\nprintk(KERN_DEBUG "IO:R %p %08x\n", addr, val);\r\nreturn val;\r\n}\r\nstatic void load_gpu(struct drm_device *dev)\r\n{\r\nstruct etnaviv_drm_private *priv = dev->dev_private;\r\nunsigned int i;\r\nfor (i = 0; i < ETNA_MAX_PIPES; i++) {\r\nstruct etnaviv_gpu *g = priv->gpu[i];\r\nif (g) {\r\nint ret;\r\nret = etnaviv_gpu_init(g);\r\nif (ret) {\r\ndev_err(g->dev, "hw init failed: %d\n", ret);\r\npriv->gpu[i] = NULL;\r\n}\r\n}\r\n}\r\n}\r\nstatic int etnaviv_open(struct drm_device *dev, struct drm_file *file)\r\n{\r\nstruct etnaviv_file_private *ctx;\r\nctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\r\nif (!ctx)\r\nreturn -ENOMEM;\r\nfile->driver_priv = ctx;\r\nreturn 0;\r\n}\r\nstatic void etnaviv_preclose(struct drm_device *dev, struct drm_file *file)\r\n{\r\nstruct etnaviv_drm_private *priv = dev->dev_private;\r\nstruct etnaviv_file_private *ctx = file->driver_priv;\r\nunsigned int i;\r\nfor (i = 0; i < ETNA_MAX_PIPES; i++) {\r\nstruct etnaviv_gpu *gpu = priv->gpu[i];\r\nif (gpu) {\r\nmutex_lock(&gpu->lock);\r\nif (gpu->lastctx == ctx)\r\ngpu->lastctx = NULL;\r\nmutex_unlock(&gpu->lock);\r\n}\r\n}\r\nkfree(ctx);\r\n}\r\nstatic int etnaviv_gem_show(struct drm_device *dev, struct seq_file *m)\r\n{\r\nstruct etnaviv_drm_private *priv = dev->dev_private;\r\netnaviv_gem_describe_objects(priv, m);\r\nreturn 0;\r\n}\r\nstatic int etnaviv_mm_show(struct drm_device *dev, struct seq_file *m)\r\n{\r\nint ret;\r\nread_lock(&dev->vma_offset_manager->vm_lock);\r\nret = drm_mm_dump_table(m, &dev->vma_offset_manager->vm_addr_space_mm);\r\nread_unlock(&dev->vma_offset_manager->vm_lock);\r\nreturn ret;\r\n}\r\nstatic int etnaviv_mmu_show(struct etnaviv_gpu *gpu, struct seq_file *m)\r\n{\r\nseq_printf(m, "Active Objects (%s):\n", dev_name(gpu->dev));\r\nmutex_lock(&gpu->mmu->lock);\r\ndrm_mm_dump_table(m, &gpu->mmu->mm);\r\nmutex_unlock(&gpu->mmu->lock);\r\nreturn 0;\r\n}\r\nstatic void etnaviv_buffer_dump(struct etnaviv_gpu *gpu, struct seq_file *m)\r\n{\r\nstruct etnaviv_cmdbuf *buf = gpu->buffer;\r\nu32 size = buf->size;\r\nu32 *ptr = buf->vaddr;\r\nu32 i;\r\nseq_printf(m, "virt %p - phys 0x%llx - free 0x%08x\n",\r\nbuf->vaddr, (u64)buf->paddr, size - buf->user_size);\r\nfor (i = 0; i < size / 4; i++) {\r\nif (i && !(i % 4))\r\nseq_puts(m, "\n");\r\nif (i % 4 == 0)\r\nseq_printf(m, "\t0x%p: ", ptr + i);\r\nseq_printf(m, "%08x ", *(ptr + i));\r\n}\r\nseq_puts(m, "\n");\r\n}\r\nstatic int etnaviv_ring_show(struct etnaviv_gpu *gpu, struct seq_file *m)\r\n{\r\nseq_printf(m, "Ring Buffer (%s): ", dev_name(gpu->dev));\r\nmutex_lock(&gpu->lock);\r\netnaviv_buffer_dump(gpu, m);\r\nmutex_unlock(&gpu->lock);\r\nreturn 0;\r\n}\r\nstatic int show_unlocked(struct seq_file *m, void *arg)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nint (*show)(struct drm_device *dev, struct seq_file *m) =\r\nnode->info_ent->data;\r\nreturn show(dev, m);\r\n}\r\nstatic int show_each_gpu(struct seq_file *m, void *arg)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct etnaviv_drm_private *priv = dev->dev_private;\r\nstruct etnaviv_gpu *gpu;\r\nint (*show)(struct etnaviv_gpu *gpu, struct seq_file *m) =\r\nnode->info_ent->data;\r\nunsigned int i;\r\nint ret = 0;\r\nfor (i = 0; i < ETNA_MAX_PIPES; i++) {\r\ngpu = priv->gpu[i];\r\nif (!gpu)\r\ncontinue;\r\nret = show(gpu, m);\r\nif (ret < 0)\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int etnaviv_debugfs_init(struct drm_minor *minor)\r\n{\r\nstruct drm_device *dev = minor->dev;\r\nint ret;\r\nret = drm_debugfs_create_files(etnaviv_debugfs_list,\r\nARRAY_SIZE(etnaviv_debugfs_list),\r\nminor->debugfs_root, minor);\r\nif (ret) {\r\ndev_err(dev->dev, "could not install etnaviv_debugfs_list\n");\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic void etnaviv_debugfs_cleanup(struct drm_minor *minor)\r\n{\r\ndrm_debugfs_remove_files(etnaviv_debugfs_list,\r\nARRAY_SIZE(etnaviv_debugfs_list), minor);\r\n}\r\nstatic int etnaviv_ioctl_get_param(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct etnaviv_drm_private *priv = dev->dev_private;\r\nstruct drm_etnaviv_param *args = data;\r\nstruct etnaviv_gpu *gpu;\r\nif (args->pipe >= ETNA_MAX_PIPES)\r\nreturn -EINVAL;\r\ngpu = priv->gpu[args->pipe];\r\nif (!gpu)\r\nreturn -ENXIO;\r\nreturn etnaviv_gpu_get_param(gpu, args->param, &args->value);\r\n}\r\nstatic int etnaviv_ioctl_gem_new(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_etnaviv_gem_new *args = data;\r\nif (args->flags & ~(ETNA_BO_CACHED | ETNA_BO_WC | ETNA_BO_UNCACHED |\r\nETNA_BO_FORCE_MMU))\r\nreturn -EINVAL;\r\nreturn etnaviv_gem_new_handle(dev, file, args->size,\r\nargs->flags, &args->handle);\r\n}\r\nstatic int etnaviv_ioctl_gem_cpu_prep(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_etnaviv_gem_cpu_prep *args = data;\r\nstruct drm_gem_object *obj;\r\nint ret;\r\nif (args->op & ~(ETNA_PREP_READ | ETNA_PREP_WRITE | ETNA_PREP_NOSYNC))\r\nreturn -EINVAL;\r\nobj = drm_gem_object_lookup(dev, file, args->handle);\r\nif (!obj)\r\nreturn -ENOENT;\r\nret = etnaviv_gem_cpu_prep(obj, args->op, &TS(args->timeout));\r\ndrm_gem_object_unreference_unlocked(obj);\r\nreturn ret;\r\n}\r\nstatic int etnaviv_ioctl_gem_cpu_fini(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_etnaviv_gem_cpu_fini *args = data;\r\nstruct drm_gem_object *obj;\r\nint ret;\r\nif (args->flags)\r\nreturn -EINVAL;\r\nobj = drm_gem_object_lookup(dev, file, args->handle);\r\nif (!obj)\r\nreturn -ENOENT;\r\nret = etnaviv_gem_cpu_fini(obj);\r\ndrm_gem_object_unreference_unlocked(obj);\r\nreturn ret;\r\n}\r\nstatic int etnaviv_ioctl_gem_info(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_etnaviv_gem_info *args = data;\r\nstruct drm_gem_object *obj;\r\nint ret;\r\nif (args->pad)\r\nreturn -EINVAL;\r\nobj = drm_gem_object_lookup(dev, file, args->handle);\r\nif (!obj)\r\nreturn -ENOENT;\r\nret = etnaviv_gem_mmap_offset(obj, &args->offset);\r\ndrm_gem_object_unreference_unlocked(obj);\r\nreturn ret;\r\n}\r\nstatic int etnaviv_ioctl_wait_fence(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_etnaviv_wait_fence *args = data;\r\nstruct etnaviv_drm_private *priv = dev->dev_private;\r\nstruct timespec *timeout = &TS(args->timeout);\r\nstruct etnaviv_gpu *gpu;\r\nif (args->flags & ~(ETNA_WAIT_NONBLOCK))\r\nreturn -EINVAL;\r\nif (args->pipe >= ETNA_MAX_PIPES)\r\nreturn -EINVAL;\r\ngpu = priv->gpu[args->pipe];\r\nif (!gpu)\r\nreturn -ENXIO;\r\nif (args->flags & ETNA_WAIT_NONBLOCK)\r\ntimeout = NULL;\r\nreturn etnaviv_gpu_wait_fence_interruptible(gpu, args->fence,\r\ntimeout);\r\n}\r\nstatic int etnaviv_ioctl_gem_userptr(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_etnaviv_gem_userptr *args = data;\r\nint access;\r\nif (args->flags & ~(ETNA_USERPTR_READ|ETNA_USERPTR_WRITE) ||\r\nargs->flags == 0)\r\nreturn -EINVAL;\r\nif (offset_in_page(args->user_ptr | args->user_size) ||\r\n(uintptr_t)args->user_ptr != args->user_ptr ||\r\n(u32)args->user_size != args->user_size ||\r\nargs->user_ptr & ~PAGE_MASK)\r\nreturn -EINVAL;\r\nif (args->flags & ETNA_USERPTR_WRITE)\r\naccess = VERIFY_WRITE;\r\nelse\r\naccess = VERIFY_READ;\r\nif (!access_ok(access, (void __user *)(unsigned long)args->user_ptr,\r\nargs->user_size))\r\nreturn -EFAULT;\r\nreturn etnaviv_gem_new_userptr(dev, file, args->user_ptr,\r\nargs->user_size, args->flags,\r\n&args->handle);\r\n}\r\nstatic int etnaviv_ioctl_gem_wait(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct etnaviv_drm_private *priv = dev->dev_private;\r\nstruct drm_etnaviv_gem_wait *args = data;\r\nstruct timespec *timeout = &TS(args->timeout);\r\nstruct drm_gem_object *obj;\r\nstruct etnaviv_gpu *gpu;\r\nint ret;\r\nif (args->flags & ~(ETNA_WAIT_NONBLOCK))\r\nreturn -EINVAL;\r\nif (args->pipe >= ETNA_MAX_PIPES)\r\nreturn -EINVAL;\r\ngpu = priv->gpu[args->pipe];\r\nif (!gpu)\r\nreturn -ENXIO;\r\nobj = drm_gem_object_lookup(dev, file, args->handle);\r\nif (!obj)\r\nreturn -ENOENT;\r\nif (args->flags & ETNA_WAIT_NONBLOCK)\r\ntimeout = NULL;\r\nret = etnaviv_gem_wait_bo(gpu, obj, timeout);\r\ndrm_gem_object_unreference_unlocked(obj);\r\nreturn ret;\r\n}\r\nstatic int etnaviv_bind(struct device *dev)\r\n{\r\nstruct etnaviv_drm_private *priv;\r\nstruct drm_device *drm;\r\nint ret;\r\ndrm = drm_dev_alloc(&etnaviv_drm_driver, dev);\r\nif (!drm)\r\nreturn -ENOMEM;\r\ndrm->platformdev = to_platform_device(dev);\r\npriv = kzalloc(sizeof(*priv), GFP_KERNEL);\r\nif (!priv) {\r\ndev_err(dev, "failed to allocate private data\n");\r\nret = -ENOMEM;\r\ngoto out_unref;\r\n}\r\ndrm->dev_private = priv;\r\npriv->wq = alloc_ordered_workqueue("etnaviv", 0);\r\nif (!priv->wq) {\r\nret = -ENOMEM;\r\ngoto out_wq;\r\n}\r\nmutex_init(&priv->gem_lock);\r\nINIT_LIST_HEAD(&priv->gem_list);\r\npriv->num_gpus = 0;\r\ndev_set_drvdata(dev, drm);\r\nret = component_bind_all(dev, drm);\r\nif (ret < 0)\r\ngoto out_bind;\r\nload_gpu(drm);\r\nret = drm_dev_register(drm, 0);\r\nif (ret)\r\ngoto out_register;\r\nreturn 0;\r\nout_register:\r\ncomponent_unbind_all(dev, drm);\r\nout_bind:\r\nflush_workqueue(priv->wq);\r\ndestroy_workqueue(priv->wq);\r\nout_wq:\r\nkfree(priv);\r\nout_unref:\r\ndrm_dev_unref(drm);\r\nreturn ret;\r\n}\r\nstatic void etnaviv_unbind(struct device *dev)\r\n{\r\nstruct drm_device *drm = dev_get_drvdata(dev);\r\nstruct etnaviv_drm_private *priv = drm->dev_private;\r\ndrm_dev_unregister(drm);\r\nflush_workqueue(priv->wq);\r\ndestroy_workqueue(priv->wq);\r\ncomponent_unbind_all(dev, drm);\r\ndrm->dev_private = NULL;\r\nkfree(priv);\r\ndrm_put_dev(drm);\r\n}\r\nstatic int compare_of(struct device *dev, void *data)\r\n{\r\nstruct device_node *np = data;\r\nreturn dev->of_node == np;\r\n}\r\nstatic int compare_str(struct device *dev, void *data)\r\n{\r\nreturn !strcmp(dev_name(dev), data);\r\n}\r\nstatic int etnaviv_pdev_probe(struct platform_device *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct device_node *node = dev->of_node;\r\nstruct component_match *match = NULL;\r\ndma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(32));\r\nif (node) {\r\nstruct device_node *core_node;\r\nint i;\r\nfor (i = 0; ; i++) {\r\ncore_node = of_parse_phandle(node, "cores", i);\r\nif (!core_node)\r\nbreak;\r\ncomponent_match_add(&pdev->dev, &match, compare_of,\r\ncore_node);\r\nof_node_put(core_node);\r\n}\r\n} else if (dev->platform_data) {\r\nchar **names = dev->platform_data;\r\nunsigned i;\r\nfor (i = 0; names[i]; i++)\r\ncomponent_match_add(dev, &match, compare_str, names[i]);\r\n}\r\nreturn component_master_add_with_match(dev, &etnaviv_master_ops, match);\r\n}\r\nstatic int etnaviv_pdev_remove(struct platform_device *pdev)\r\n{\r\ncomponent_master_del(&pdev->dev, &etnaviv_master_ops);\r\nreturn 0;\r\n}\r\nstatic int __init etnaviv_init(void)\r\n{\r\nint ret;\r\netnaviv_validate_init();\r\nret = platform_driver_register(&etnaviv_gpu_driver);\r\nif (ret != 0)\r\nreturn ret;\r\nret = platform_driver_register(&etnaviv_platform_driver);\r\nif (ret != 0)\r\nplatform_driver_unregister(&etnaviv_gpu_driver);\r\nreturn ret;\r\n}\r\nstatic void __exit etnaviv_exit(void)\r\n{\r\nplatform_driver_unregister(&etnaviv_gpu_driver);\r\nplatform_driver_unregister(&etnaviv_platform_driver);\r\n}
