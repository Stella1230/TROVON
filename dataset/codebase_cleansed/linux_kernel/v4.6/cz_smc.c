uint32_t cz_get_argument(struct amdgpu_device *adev)\r\n{\r\nreturn RREG32(mmSMU_MP1_SRBM2P_ARG_0);\r\n}\r\nstatic struct cz_smu_private_data *cz_smu_get_priv(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv =\r\n(struct cz_smu_private_data *)(adev->smu.priv);\r\nreturn priv;\r\n}\r\nint cz_send_msg_to_smc_async(struct amdgpu_device *adev, u16 msg)\r\n{\r\nint i;\r\nu32 content = 0, tmp;\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\ntmp = REG_GET_FIELD(RREG32(mmSMU_MP1_SRBM2P_RESP_0),\r\nSMU_MP1_SRBM2P_RESP_0, CONTENT);\r\nif (content != tmp)\r\nbreak;\r\nudelay(1);\r\n}\r\nif (i == adev->usec_timeout)\r\nreturn -EINVAL;\r\nWREG32(mmSMU_MP1_SRBM2P_RESP_0, 0);\r\nWREG32(mmSMU_MP1_SRBM2P_MSG_0, msg);\r\nreturn 0;\r\n}\r\nint cz_send_msg_to_smc(struct amdgpu_device *adev, u16 msg)\r\n{\r\nint i;\r\nu32 content = 0, tmp = 0;\r\nif (cz_send_msg_to_smc_async(adev, msg))\r\nreturn -EINVAL;\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\ntmp = REG_GET_FIELD(RREG32(mmSMU_MP1_SRBM2P_RESP_0),\r\nSMU_MP1_SRBM2P_RESP_0, CONTENT);\r\nif (content != tmp)\r\nbreak;\r\nudelay(1);\r\n}\r\nif (i == adev->usec_timeout)\r\nreturn -EINVAL;\r\nif (PPSMC_Result_OK != tmp) {\r\ndev_err(adev->dev, "SMC Failed to send Message.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint cz_send_msg_to_smc_with_parameter_async(struct amdgpu_device *adev,\r\nu16 msg, u32 parameter)\r\n{\r\nWREG32(mmSMU_MP1_SRBM2P_ARG_0, parameter);\r\nreturn cz_send_msg_to_smc_async(adev, msg);\r\n}\r\nint cz_send_msg_to_smc_with_parameter(struct amdgpu_device *adev,\r\nu16 msg, u32 parameter)\r\n{\r\nWREG32(mmSMU_MP1_SRBM2P_ARG_0, parameter);\r\nreturn cz_send_msg_to_smc(adev, msg);\r\n}\r\nstatic int cz_set_smc_sram_address(struct amdgpu_device *adev,\r\nu32 smc_address, u32 limit)\r\n{\r\nif (smc_address & 3)\r\nreturn -EINVAL;\r\nif ((smc_address + 3) > limit)\r\nreturn -EINVAL;\r\nWREG32(mmMP0PUB_IND_INDEX_0, SMN_MP1_SRAM_START_ADDR + smc_address);\r\nreturn 0;\r\n}\r\nint cz_read_smc_sram_dword(struct amdgpu_device *adev, u32 smc_address,\r\nu32 *value, u32 limit)\r\n{\r\nint ret;\r\nret = cz_set_smc_sram_address(adev, smc_address, limit);\r\nif (ret)\r\nreturn ret;\r\n*value = RREG32(mmMP0PUB_IND_DATA_0);\r\nreturn 0;\r\n}\r\nint cz_write_smc_sram_dword(struct amdgpu_device *adev, u32 smc_address,\r\nu32 value, u32 limit)\r\n{\r\nint ret;\r\nret = cz_set_smc_sram_address(adev, smc_address, limit);\r\nif (ret)\r\nreturn ret;\r\nWREG32(mmMP0PUB_IND_DATA_0, value);\r\nreturn 0;\r\n}\r\nstatic int cz_smu_request_load_fw(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nuint32_t smc_addr = SMU8_FIRMWARE_HEADER_LOCATION +\r\noffsetof(struct SMU8_Firmware_Header, UcodeLoadStatus);\r\ncz_write_smc_sram_dword(adev, smc_addr, 0, smc_addr + 4);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_DriverDramAddrHi,\r\npriv->toc_buffer.mc_addr_high);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_DriverDramAddrLo,\r\npriv->toc_buffer.mc_addr_low);\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_InitJobs);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_ExecuteJob,\r\npriv->toc_entry_aram);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_ExecuteJob,\r\npriv->toc_entry_power_profiling_index);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_ExecuteJob,\r\npriv->toc_entry_initialize_index);\r\nreturn 0;\r\n}\r\nstatic int cz_smu_check_fw_load_finish(struct amdgpu_device *adev,\r\nuint32_t fw_mask)\r\n{\r\nint i;\r\nuint32_t index = SMN_MP1_SRAM_START_ADDR +\r\nSMU8_FIRMWARE_HEADER_LOCATION +\r\noffsetof(struct SMU8_Firmware_Header, UcodeLoadStatus);\r\nWREG32(mmMP0PUB_IND_INDEX, index);\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\nif (fw_mask == (RREG32(mmMP0PUB_IND_DATA) & fw_mask))\r\nbreak;\r\nudelay(1);\r\n}\r\nif (i >= adev->usec_timeout) {\r\ndev_err(adev->dev,\r\n"SMU check loaded firmware failed, expecting 0x%x, getting 0x%x",\r\nfw_mask, RREG32(mmMP0PUB_IND_DATA));\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cz_smu_check_finished(struct amdgpu_device *adev,\r\nenum AMDGPU_UCODE_ID id)\r\n{\r\nswitch (id) {\r\ncase AMDGPU_UCODE_ID_SDMA0:\r\nif (adev->smu.fw_flags & AMDGPU_SDMA0_UCODE_LOADED)\r\nreturn 0;\r\nbreak;\r\ncase AMDGPU_UCODE_ID_SDMA1:\r\nif (adev->smu.fw_flags & AMDGPU_SDMA1_UCODE_LOADED)\r\nreturn 0;\r\nbreak;\r\ncase AMDGPU_UCODE_ID_CP_CE:\r\nif (adev->smu.fw_flags & AMDGPU_CPCE_UCODE_LOADED)\r\nreturn 0;\r\nbreak;\r\ncase AMDGPU_UCODE_ID_CP_PFP:\r\nif (adev->smu.fw_flags & AMDGPU_CPPFP_UCODE_LOADED)\r\nreturn 0;\r\ncase AMDGPU_UCODE_ID_CP_ME:\r\nif (adev->smu.fw_flags & AMDGPU_CPME_UCODE_LOADED)\r\nreturn 0;\r\nbreak;\r\ncase AMDGPU_UCODE_ID_CP_MEC1:\r\nif (adev->smu.fw_flags & AMDGPU_CPMEC1_UCODE_LOADED)\r\nreturn 0;\r\nbreak;\r\ncase AMDGPU_UCODE_ID_CP_MEC2:\r\nif (adev->smu.fw_flags & AMDGPU_CPMEC2_UCODE_LOADED)\r\nreturn 0;\r\nbreak;\r\ncase AMDGPU_UCODE_ID_RLC_G:\r\nif (adev->smu.fw_flags & AMDGPU_CPRLC_UCODE_LOADED)\r\nreturn 0;\r\nbreak;\r\ncase AMDGPU_UCODE_ID_MAXIMUM:\r\ndefault:\r\nbreak;\r\n}\r\nreturn 1;\r\n}\r\nstatic int cz_load_mec_firmware(struct amdgpu_device *adev)\r\n{\r\nstruct amdgpu_firmware_info *ucode =\r\n&adev->firmware.ucode[AMDGPU_UCODE_ID_CP_MEC1];\r\nuint32_t reg_data;\r\nuint32_t tmp;\r\nif (ucode->fw == NULL)\r\nreturn -EINVAL;\r\ntmp = RREG32(mmCP_MEC_CNTL);\r\ntmp = REG_SET_FIELD(tmp, CP_MEC_CNTL, MEC_ME1_HALT, 1);\r\ntmp = REG_SET_FIELD(tmp, CP_MEC_CNTL, MEC_ME2_HALT, 1);\r\nWREG32(mmCP_MEC_CNTL, tmp);\r\ntmp = RREG32(mmCP_CPC_IC_BASE_CNTL);\r\ntmp = REG_SET_FIELD(tmp, CP_CPC_IC_BASE_CNTL, VMID, 0);\r\ntmp = REG_SET_FIELD(tmp, CP_CPC_IC_BASE_CNTL, ATC, 0);\r\ntmp = REG_SET_FIELD(tmp, CP_CPC_IC_BASE_CNTL, CACHE_POLICY, 0);\r\ntmp = REG_SET_FIELD(tmp, CP_CPC_IC_BASE_CNTL, MTYPE, 1);\r\nWREG32(mmCP_CPC_IC_BASE_CNTL, tmp);\r\nreg_data = lower_32_bits(ucode->mc_addr) &\r\nREG_FIELD_MASK(CP_CPC_IC_BASE_LO, IC_BASE_LO);\r\nWREG32(mmCP_CPC_IC_BASE_LO, reg_data);\r\nreg_data = upper_32_bits(ucode->mc_addr) &\r\nREG_FIELD_MASK(CP_CPC_IC_BASE_HI, IC_BASE_HI);\r\nWREG32(mmCP_CPC_IC_BASE_HI, reg_data);\r\nreturn 0;\r\n}\r\nint cz_smu_start(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nuint32_t fw_to_check = UCODE_ID_RLC_G_MASK |\r\nUCODE_ID_SDMA0_MASK |\r\nUCODE_ID_SDMA1_MASK |\r\nUCODE_ID_CP_CE_MASK |\r\nUCODE_ID_CP_ME_MASK |\r\nUCODE_ID_CP_PFP_MASK |\r\nUCODE_ID_CP_MEC_JT1_MASK |\r\nUCODE_ID_CP_MEC_JT2_MASK;\r\nif (adev->asic_type == CHIP_STONEY)\r\nfw_to_check &= ~(UCODE_ID_SDMA1_MASK | UCODE_ID_CP_MEC_JT2_MASK);\r\ncz_smu_request_load_fw(adev);\r\nret = cz_smu_check_fw_load_finish(adev, fw_to_check);\r\nif (ret)\r\nreturn ret;\r\nif (adev->asic_type == CHIP_CARRIZO || adev->asic_type == CHIP_STONEY) {\r\nret = cz_load_mec_firmware(adev);\r\nif (ret) {\r\ndev_err(adev->dev, "(%d) Mec Firmware load failed\n", ret);\r\nreturn ret;\r\n}\r\n}\r\nadev->smu.fw_flags = AMDGPU_SDMA0_UCODE_LOADED |\r\nAMDGPU_SDMA1_UCODE_LOADED |\r\nAMDGPU_CPCE_UCODE_LOADED |\r\nAMDGPU_CPPFP_UCODE_LOADED |\r\nAMDGPU_CPME_UCODE_LOADED |\r\nAMDGPU_CPMEC1_UCODE_LOADED |\r\nAMDGPU_CPMEC2_UCODE_LOADED |\r\nAMDGPU_CPRLC_UCODE_LOADED;\r\nif (adev->asic_type == CHIP_STONEY)\r\nadev->smu.fw_flags &= ~(AMDGPU_SDMA1_UCODE_LOADED | AMDGPU_CPMEC2_UCODE_LOADED);\r\nreturn ret;\r\n}\r\nstatic uint32_t cz_convert_fw_type(uint32_t fw_type)\r\n{\r\nenum AMDGPU_UCODE_ID result = AMDGPU_UCODE_ID_MAXIMUM;\r\nswitch (fw_type) {\r\ncase UCODE_ID_SDMA0:\r\nresult = AMDGPU_UCODE_ID_SDMA0;\r\nbreak;\r\ncase UCODE_ID_SDMA1:\r\nresult = AMDGPU_UCODE_ID_SDMA1;\r\nbreak;\r\ncase UCODE_ID_CP_CE:\r\nresult = AMDGPU_UCODE_ID_CP_CE;\r\nbreak;\r\ncase UCODE_ID_CP_PFP:\r\nresult = AMDGPU_UCODE_ID_CP_PFP;\r\nbreak;\r\ncase UCODE_ID_CP_ME:\r\nresult = AMDGPU_UCODE_ID_CP_ME;\r\nbreak;\r\ncase UCODE_ID_CP_MEC_JT1:\r\ncase UCODE_ID_CP_MEC_JT2:\r\nresult = AMDGPU_UCODE_ID_CP_MEC1;\r\nbreak;\r\ncase UCODE_ID_RLC_G:\r\nresult = AMDGPU_UCODE_ID_RLC_G;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("UCode type is out of range!");\r\n}\r\nreturn result;\r\n}\r\nstatic uint8_t cz_smu_translate_firmware_enum_to_arg(\r\nenum cz_scratch_entry firmware_enum)\r\n{\r\nuint8_t ret = 0;\r\nswitch (firmware_enum) {\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_SDMA0:\r\nret = UCODE_ID_SDMA0;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_SDMA1:\r\nret = UCODE_ID_SDMA1;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_CP_CE:\r\nret = UCODE_ID_CP_CE;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_CP_PFP:\r\nret = UCODE_ID_CP_PFP;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_CP_ME:\r\nret = UCODE_ID_CP_ME;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1:\r\nret = UCODE_ID_CP_MEC_JT1;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT2:\r\nret = UCODE_ID_CP_MEC_JT2;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_GMCON_RENG:\r\nret = UCODE_ID_GMCON_RENG;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_RLC_G:\r\nret = UCODE_ID_RLC_G;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_RLC_SCRATCH:\r\nret = UCODE_ID_RLC_SCRATCH;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_ARAM:\r\nret = UCODE_ID_RLC_SRM_ARAM;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_DRAM:\r\nret = UCODE_ID_RLC_SRM_DRAM;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_DMCU_ERAM:\r\nret = UCODE_ID_DMCU_ERAM;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_DMCU_IRAM:\r\nret = UCODE_ID_DMCU_IRAM;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_UCODE_ID_POWER_PROFILING:\r\nret = TASK_ARG_INIT_MM_PWR_LOG;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_DATA_ID_SDMA_HALT:\r\ncase CZ_SCRATCH_ENTRY_DATA_ID_SYS_CLOCKGATING:\r\ncase CZ_SCRATCH_ENTRY_DATA_ID_SDMA_RING_REGS:\r\ncase CZ_SCRATCH_ENTRY_DATA_ID_NONGFX_REINIT:\r\ncase CZ_SCRATCH_ENTRY_DATA_ID_SDMA_START:\r\ncase CZ_SCRATCH_ENTRY_DATA_ID_IH_REGISTERS:\r\nret = TASK_ARG_REG_MMIO;\r\nbreak;\r\ncase CZ_SCRATCH_ENTRY_SMU8_FUSION_CLKTABLE:\r\nret = TASK_ARG_INIT_CLK_TABLE;\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_smu_populate_single_firmware_entry(struct amdgpu_device *adev,\r\nenum cz_scratch_entry firmware_enum,\r\nstruct cz_buffer_entry *entry)\r\n{\r\nuint64_t gpu_addr;\r\nuint32_t data_size;\r\nuint8_t ucode_id = cz_smu_translate_firmware_enum_to_arg(firmware_enum);\r\nenum AMDGPU_UCODE_ID id = cz_convert_fw_type(ucode_id);\r\nstruct amdgpu_firmware_info *ucode = &adev->firmware.ucode[id];\r\nconst struct gfx_firmware_header_v1_0 *header;\r\nif (ucode->fw == NULL)\r\nreturn -EINVAL;\r\ngpu_addr = ucode->mc_addr;\r\nheader = (const struct gfx_firmware_header_v1_0 *)ucode->fw->data;\r\ndata_size = le32_to_cpu(header->header.ucode_size_bytes);\r\nif ((firmware_enum == CZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1) ||\r\n(firmware_enum == CZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT2)) {\r\ngpu_addr += le32_to_cpu(header->jt_offset) << 2;\r\ndata_size = le32_to_cpu(header->jt_size) << 2;\r\n}\r\nentry->mc_addr_low = lower_32_bits(gpu_addr);\r\nentry->mc_addr_high = upper_32_bits(gpu_addr);\r\nentry->data_size = data_size;\r\nentry->firmware_ID = firmware_enum;\r\nreturn 0;\r\n}\r\nstatic int cz_smu_populate_single_scratch_entry(struct amdgpu_device *adev,\r\nenum cz_scratch_entry scratch_type,\r\nuint32_t size_in_byte,\r\nstruct cz_buffer_entry *entry)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nuint64_t mc_addr = (((uint64_t) priv->smu_buffer.mc_addr_high) << 32) |\r\npriv->smu_buffer.mc_addr_low;\r\nmc_addr += size_in_byte;\r\npriv->smu_buffer_used_bytes += size_in_byte;\r\nentry->data_size = size_in_byte;\r\nentry->kaddr = priv->smu_buffer.kaddr + priv->smu_buffer_used_bytes;\r\nentry->mc_addr_low = lower_32_bits(mc_addr);\r\nentry->mc_addr_high = upper_32_bits(mc_addr);\r\nentry->firmware_ID = scratch_type;\r\nreturn 0;\r\n}\r\nstatic int cz_smu_populate_single_ucode_load_task(struct amdgpu_device *adev,\r\nenum cz_scratch_entry firmware_enum,\r\nbool is_last)\r\n{\r\nuint8_t i;\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nstruct TOC *toc = (struct TOC *)priv->toc_buffer.kaddr;\r\nstruct SMU_Task *task = &toc->tasks[priv->toc_entry_used_count++];\r\ntask->type = TASK_TYPE_UCODE_LOAD;\r\ntask->arg = cz_smu_translate_firmware_enum_to_arg(firmware_enum);\r\ntask->next = is_last ? END_OF_TASK_LIST : priv->toc_entry_used_count;\r\nfor (i = 0; i < priv->driver_buffer_length; i++)\r\nif (priv->driver_buffer[i].firmware_ID == firmware_enum)\r\nbreak;\r\nif (i >= priv->driver_buffer_length) {\r\ndev_err(adev->dev, "Invalid Firmware Type\n");\r\nreturn -EINVAL;\r\n}\r\ntask->addr.low = priv->driver_buffer[i].mc_addr_low;\r\ntask->addr.high = priv->driver_buffer[i].mc_addr_high;\r\ntask->size_bytes = priv->driver_buffer[i].data_size;\r\nreturn 0;\r\n}\r\nstatic int cz_smu_populate_single_scratch_task(struct amdgpu_device *adev,\r\nenum cz_scratch_entry firmware_enum,\r\nuint8_t type, bool is_last)\r\n{\r\nuint8_t i;\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nstruct TOC *toc = (struct TOC *)priv->toc_buffer.kaddr;\r\nstruct SMU_Task *task = &toc->tasks[priv->toc_entry_used_count++];\r\ntask->type = type;\r\ntask->arg = cz_smu_translate_firmware_enum_to_arg(firmware_enum);\r\ntask->next = is_last ? END_OF_TASK_LIST : priv->toc_entry_used_count;\r\nfor (i = 0; i < priv->scratch_buffer_length; i++)\r\nif (priv->scratch_buffer[i].firmware_ID == firmware_enum)\r\nbreak;\r\nif (i >= priv->scratch_buffer_length) {\r\ndev_err(adev->dev, "Invalid Firmware Type\n");\r\nreturn -EINVAL;\r\n}\r\ntask->addr.low = priv->scratch_buffer[i].mc_addr_low;\r\ntask->addr.high = priv->scratch_buffer[i].mc_addr_high;\r\ntask->size_bytes = priv->scratch_buffer[i].data_size;\r\nif (CZ_SCRATCH_ENTRY_DATA_ID_IH_REGISTERS == firmware_enum) {\r\nstruct cz_ih_meta_data *pIHReg_restore =\r\n(struct cz_ih_meta_data *)priv->scratch_buffer[i].kaddr;\r\npIHReg_restore->command =\r\nMETADATA_CMD_MODE0 | METADATA_PERFORM_ON_LOAD;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cz_smu_construct_toc_for_rlc_aram_save(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\npriv->toc_entry_aram = priv->toc_entry_used_count;\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_ARAM,\r\nTASK_TYPE_UCODE_SAVE, true);\r\nreturn 0;\r\n}\r\nstatic int cz_smu_construct_toc_for_vddgfx_enter(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nstruct TOC *toc = (struct TOC *)priv->toc_buffer.kaddr;\r\ntoc->JobList[JOB_GFX_SAVE] = (uint8_t)priv->toc_entry_used_count;\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SCRATCH,\r\nTASK_TYPE_UCODE_SAVE, false);\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_DRAM,\r\nTASK_TYPE_UCODE_SAVE, true);\r\nreturn 0;\r\n}\r\nstatic int cz_smu_construct_toc_for_vddgfx_exit(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nstruct TOC *toc = (struct TOC *)priv->toc_buffer.kaddr;\r\ntoc->JobList[JOB_GFX_RESTORE] = (uint8_t)priv->toc_entry_used_count;\r\nif (adev->firmware.smu_load) {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_CE, false);\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_PFP, false);\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_ME, false);\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1, false);\r\nif (adev->asic_type == CHIP_STONEY) {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1, false);\r\n} else {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT2, false);\r\n}\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_G, false);\r\n}\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SCRATCH,\r\nTASK_TYPE_UCODE_LOAD, false);\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_ARAM,\r\nTASK_TYPE_UCODE_LOAD, false);\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_DRAM,\r\nTASK_TYPE_UCODE_LOAD, true);\r\nreturn 0;\r\n}\r\nstatic int cz_smu_construct_toc_for_power_profiling(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\npriv->toc_entry_power_profiling_index = priv->toc_entry_used_count;\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_POWER_PROFILING,\r\nTASK_TYPE_INITIALIZE, true);\r\nreturn 0;\r\n}\r\nstatic int cz_smu_construct_toc_for_bootup(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\npriv->toc_entry_initialize_index = priv->toc_entry_used_count;\r\nif (adev->firmware.smu_load) {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_SDMA0, false);\r\nif (adev->asic_type == CHIP_STONEY) {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_SDMA0, false);\r\n} else {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_SDMA1, false);\r\n}\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_CE, false);\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_PFP, false);\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_ME, false);\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1, false);\r\nif (adev->asic_type == CHIP_STONEY) {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1, false);\r\n} else {\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT2, false);\r\n}\r\ncz_smu_populate_single_ucode_load_task(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_G, true);\r\n}\r\nreturn 0;\r\n}\r\nstatic int cz_smu_construct_toc_for_clock_table(struct amdgpu_device *adev)\r\n{\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\npriv->toc_entry_clock_table = priv->toc_entry_used_count;\r\ncz_smu_populate_single_scratch_task(adev,\r\nCZ_SCRATCH_ENTRY_SMU8_FUSION_CLKTABLE,\r\nTASK_TYPE_INITIALIZE, true);\r\nreturn 0;\r\n}\r\nstatic int cz_smu_initialize_toc_empty_job_list(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nstruct TOC *toc = (struct TOC *)priv->toc_buffer.kaddr;\r\nfor (i = 0; i < NUM_JOBLIST_ENTRIES; i++)\r\ntoc->JobList[i] = (uint8_t)IGNORE_JOB;\r\nreturn 0;\r\n}\r\nint cz_smu_fini(struct amdgpu_device *adev)\r\n{\r\namdgpu_bo_unref(&adev->smu.toc_buf);\r\namdgpu_bo_unref(&adev->smu.smu_buf);\r\nkfree(adev->smu.priv);\r\nadev->smu.priv = NULL;\r\nif (adev->firmware.smu_load)\r\namdgpu_ucode_fini_bo(adev);\r\nreturn 0;\r\n}\r\nint cz_smu_download_pptable(struct amdgpu_device *adev, void **table)\r\n{\r\nuint8_t i;\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nfor (i = 0; i < priv->scratch_buffer_length; i++)\r\nif (priv->scratch_buffer[i].firmware_ID ==\r\nCZ_SCRATCH_ENTRY_SMU8_FUSION_CLKTABLE)\r\nbreak;\r\nif (i >= priv->scratch_buffer_length) {\r\ndev_err(adev->dev, "Invalid Scratch Type\n");\r\nreturn -EINVAL;\r\n}\r\n*table = (struct SMU8_Fusion_ClkTable *)priv->scratch_buffer[i].kaddr;\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetClkTableAddrHi,\r\npriv->scratch_buffer[i].mc_addr_high);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetClkTableAddrLo,\r\npriv->scratch_buffer[i].mc_addr_low);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_ExecuteJob,\r\npriv->toc_entry_clock_table);\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_ClkTableXferToDram);\r\nreturn 0;\r\n}\r\nint cz_smu_upload_pptable(struct amdgpu_device *adev)\r\n{\r\nuint8_t i;\r\nstruct cz_smu_private_data *priv = cz_smu_get_priv(adev);\r\nfor (i = 0; i < priv->scratch_buffer_length; i++)\r\nif (priv->scratch_buffer[i].firmware_ID ==\r\nCZ_SCRATCH_ENTRY_SMU8_FUSION_CLKTABLE)\r\nbreak;\r\nif (i >= priv->scratch_buffer_length) {\r\ndev_err(adev->dev, "Invalid Scratch Type\n");\r\nreturn -EINVAL;\r\n}\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetClkTableAddrHi,\r\npriv->scratch_buffer[i].mc_addr_high);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetClkTableAddrLo,\r\npriv->scratch_buffer[i].mc_addr_low);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_ExecuteJob,\r\npriv->toc_entry_clock_table);\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_ClkTableXferToSmu);\r\nreturn 0;\r\n}\r\nint cz_smu_init(struct amdgpu_device *adev)\r\n{\r\nint ret = -EINVAL;\r\nuint64_t mc_addr = 0;\r\nstruct amdgpu_bo **toc_buf = &adev->smu.toc_buf;\r\nstruct amdgpu_bo **smu_buf = &adev->smu.smu_buf;\r\nvoid *toc_buf_ptr = NULL;\r\nvoid *smu_buf_ptr = NULL;\r\nstruct cz_smu_private_data *priv =\r\nkzalloc(sizeof(struct cz_smu_private_data), GFP_KERNEL);\r\nif (priv == NULL)\r\nreturn -ENOMEM;\r\nif (adev->firmware.smu_load)\r\namdgpu_ucode_init_bo(adev);\r\nadev->smu.priv = priv;\r\nadev->smu.fw_flags = 0;\r\npriv->toc_buffer.data_size = 4096;\r\npriv->smu_buffer.data_size =\r\nALIGN(UCODE_ID_RLC_SCRATCH_SIZE_BYTE, 32) +\r\nALIGN(UCODE_ID_RLC_SRM_ARAM_SIZE_BYTE, 32) +\r\nALIGN(UCODE_ID_RLC_SRM_DRAM_SIZE_BYTE, 32) +\r\nALIGN(sizeof(struct SMU8_MultimediaPowerLogData), 32) +\r\nALIGN(sizeof(struct SMU8_Fusion_ClkTable), 32);\r\nret = amdgpu_bo_create(adev, priv->toc_buffer.data_size, PAGE_SIZE,\r\ntrue, AMDGPU_GEM_DOMAIN_GTT, 0, NULL, NULL,\r\ntoc_buf);\r\nif (ret) {\r\ndev_err(adev->dev, "(%d) SMC TOC buffer allocation failed\n", ret);\r\nreturn ret;\r\n}\r\nret = amdgpu_bo_create(adev, priv->smu_buffer.data_size, PAGE_SIZE,\r\ntrue, AMDGPU_GEM_DOMAIN_GTT, 0, NULL, NULL,\r\nsmu_buf);\r\nif (ret) {\r\ndev_err(adev->dev, "(%d) SMC Internal buffer allocation failed\n", ret);\r\nreturn ret;\r\n}\r\nret = amdgpu_bo_reserve(adev->smu.toc_buf, false);\r\nif (ret) {\r\namdgpu_bo_unref(&adev->smu.toc_buf);\r\ndev_err(adev->dev, "(%d) SMC TOC buffer reserve failed\n", ret);\r\nreturn ret;\r\n}\r\nret = amdgpu_bo_pin(adev->smu.toc_buf, AMDGPU_GEM_DOMAIN_GTT, &mc_addr);\r\nif (ret) {\r\namdgpu_bo_unreserve(adev->smu.toc_buf);\r\namdgpu_bo_unref(&adev->smu.toc_buf);\r\ndev_err(adev->dev, "(%d) SMC TOC buffer pin failed\n", ret);\r\nreturn ret;\r\n}\r\nret = amdgpu_bo_kmap(*toc_buf, &toc_buf_ptr);\r\nif (ret)\r\ngoto smu_init_failed;\r\namdgpu_bo_unreserve(adev->smu.toc_buf);\r\npriv->toc_buffer.mc_addr_low = lower_32_bits(mc_addr);\r\npriv->toc_buffer.mc_addr_high = upper_32_bits(mc_addr);\r\npriv->toc_buffer.kaddr = toc_buf_ptr;\r\nret = amdgpu_bo_reserve(adev->smu.smu_buf, false);\r\nif (ret) {\r\namdgpu_bo_unref(&adev->smu.smu_buf);\r\ndev_err(adev->dev, "(%d) SMC Internal buffer reserve failed\n", ret);\r\nreturn ret;\r\n}\r\nret = amdgpu_bo_pin(adev->smu.smu_buf, AMDGPU_GEM_DOMAIN_GTT, &mc_addr);\r\nif (ret) {\r\namdgpu_bo_unreserve(adev->smu.smu_buf);\r\namdgpu_bo_unref(&adev->smu.smu_buf);\r\ndev_err(adev->dev, "(%d) SMC Internal buffer pin failed\n", ret);\r\nreturn ret;\r\n}\r\nret = amdgpu_bo_kmap(*smu_buf, &smu_buf_ptr);\r\nif (ret)\r\ngoto smu_init_failed;\r\namdgpu_bo_unreserve(adev->smu.smu_buf);\r\npriv->smu_buffer.mc_addr_low = lower_32_bits(mc_addr);\r\npriv->smu_buffer.mc_addr_high = upper_32_bits(mc_addr);\r\npriv->smu_buffer.kaddr = smu_buf_ptr;\r\nif (adev->firmware.smu_load) {\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_SDMA0,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (adev->asic_type == CHIP_STONEY) {\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_SDMA0,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\n} else {\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_SDMA1,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\n}\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_CE,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_PFP,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_ME,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (adev->asic_type == CHIP_STONEY) {\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT1,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\n} else {\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_CP_MEC_JT2,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\n}\r\nif (cz_smu_populate_single_firmware_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_G,\r\n&priv->driver_buffer[priv->driver_buffer_length++]))\r\ngoto smu_init_failed;\r\n}\r\nif (cz_smu_populate_single_scratch_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SCRATCH,\r\nUCODE_ID_RLC_SCRATCH_SIZE_BYTE,\r\n&priv->scratch_buffer[priv->scratch_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (cz_smu_populate_single_scratch_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_ARAM,\r\nUCODE_ID_RLC_SRM_ARAM_SIZE_BYTE,\r\n&priv->scratch_buffer[priv->scratch_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (cz_smu_populate_single_scratch_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_RLC_SRM_DRAM,\r\nUCODE_ID_RLC_SRM_DRAM_SIZE_BYTE,\r\n&priv->scratch_buffer[priv->scratch_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (cz_smu_populate_single_scratch_entry(adev,\r\nCZ_SCRATCH_ENTRY_UCODE_ID_POWER_PROFILING,\r\nsizeof(struct SMU8_MultimediaPowerLogData),\r\n&priv->scratch_buffer[priv->scratch_buffer_length++]))\r\ngoto smu_init_failed;\r\nif (cz_smu_populate_single_scratch_entry(adev,\r\nCZ_SCRATCH_ENTRY_SMU8_FUSION_CLKTABLE,\r\nsizeof(struct SMU8_Fusion_ClkTable),\r\n&priv->scratch_buffer[priv->scratch_buffer_length++]))\r\ngoto smu_init_failed;\r\ncz_smu_initialize_toc_empty_job_list(adev);\r\ncz_smu_construct_toc_for_rlc_aram_save(adev);\r\ncz_smu_construct_toc_for_vddgfx_enter(adev);\r\ncz_smu_construct_toc_for_vddgfx_exit(adev);\r\ncz_smu_construct_toc_for_power_profiling(adev);\r\ncz_smu_construct_toc_for_bootup(adev);\r\ncz_smu_construct_toc_for_clock_table(adev);\r\nadev->smu.smumgr_funcs = &cz_smumgr_funcs;\r\nreturn 0;\r\nsmu_init_failed:\r\namdgpu_bo_unref(toc_buf);\r\namdgpu_bo_unref(smu_buf);\r\nreturn ret;\r\n}
