int enic_addfltr_5t(struct enic *enic, struct flow_keys *keys, u16 rq)\r\n{\r\nint res;\r\nstruct filter data;\r\nswitch (keys->basic.ip_proto) {\r\ncase IPPROTO_TCP:\r\ndata.u.ipv4.protocol = PROTO_TCP;\r\nbreak;\r\ncase IPPROTO_UDP:\r\ndata.u.ipv4.protocol = PROTO_UDP;\r\nbreak;\r\ndefault:\r\nreturn -EPROTONOSUPPORT;\r\n};\r\ndata.type = FILTER_IPV4_5TUPLE;\r\ndata.u.ipv4.src_addr = ntohl(keys->addrs.v4addrs.src);\r\ndata.u.ipv4.dst_addr = ntohl(keys->addrs.v4addrs.dst);\r\ndata.u.ipv4.src_port = ntohs(keys->ports.src);\r\ndata.u.ipv4.dst_port = ntohs(keys->ports.dst);\r\ndata.u.ipv4.flags = FILTER_FIELDS_IPV4_5TUPLE;\r\nspin_lock_bh(&enic->devcmd_lock);\r\nres = vnic_dev_classifier(enic->vdev, CLSF_ADD, &rq, &data);\r\nspin_unlock_bh(&enic->devcmd_lock);\r\nres = (res == 0) ? rq : res;\r\nreturn res;\r\n}\r\nint enic_delfltr(struct enic *enic, u16 filter_id)\r\n{\r\nint ret;\r\nspin_lock_bh(&enic->devcmd_lock);\r\nret = vnic_dev_classifier(enic->vdev, CLSF_DEL, &filter_id, NULL);\r\nspin_unlock_bh(&enic->devcmd_lock);\r\nreturn ret;\r\n}\r\nvoid enic_rfs_flw_tbl_init(struct enic *enic)\r\n{\r\nint i;\r\nspin_lock_init(&enic->rfs_h.lock);\r\nfor (i = 0; i <= ENIC_RFS_FLW_MASK; i++)\r\nINIT_HLIST_HEAD(&enic->rfs_h.ht_head[i]);\r\nenic->rfs_h.max = enic->config.num_arfs;\r\nenic->rfs_h.free = enic->rfs_h.max;\r\nenic->rfs_h.toclean = 0;\r\nenic_rfs_timer_start(enic);\r\n}\r\nvoid enic_rfs_flw_tbl_free(struct enic *enic)\r\n{\r\nint i;\r\nenic_rfs_timer_stop(enic);\r\nspin_lock_bh(&enic->rfs_h.lock);\r\nenic->rfs_h.free = 0;\r\nfor (i = 0; i < (1 << ENIC_RFS_FLW_BITSHIFT); i++) {\r\nstruct hlist_head *hhead;\r\nstruct hlist_node *tmp;\r\nstruct enic_rfs_fltr_node *n;\r\nhhead = &enic->rfs_h.ht_head[i];\r\nhlist_for_each_entry_safe(n, tmp, hhead, node) {\r\nenic_delfltr(enic, n->fltr_id);\r\nhlist_del(&n->node);\r\nkfree(n);\r\n}\r\n}\r\nspin_unlock_bh(&enic->rfs_h.lock);\r\n}\r\nstruct enic_rfs_fltr_node *htbl_fltr_search(struct enic *enic, u16 fltr_id)\r\n{\r\nint i;\r\nfor (i = 0; i < (1 << ENIC_RFS_FLW_BITSHIFT); i++) {\r\nstruct hlist_head *hhead;\r\nstruct hlist_node *tmp;\r\nstruct enic_rfs_fltr_node *n;\r\nhhead = &enic->rfs_h.ht_head[i];\r\nhlist_for_each_entry_safe(n, tmp, hhead, node)\r\nif (n->fltr_id == fltr_id)\r\nreturn n;\r\n}\r\nreturn NULL;\r\n}\r\nvoid enic_flow_may_expire(unsigned long data)\r\n{\r\nstruct enic *enic = (struct enic *)data;\r\nbool res;\r\nint j;\r\nspin_lock_bh(&enic->rfs_h.lock);\r\nfor (j = 0; j < ENIC_CLSF_EXPIRE_COUNT; j++) {\r\nstruct hlist_head *hhead;\r\nstruct hlist_node *tmp;\r\nstruct enic_rfs_fltr_node *n;\r\nhhead = &enic->rfs_h.ht_head[enic->rfs_h.toclean++];\r\nhlist_for_each_entry_safe(n, tmp, hhead, node) {\r\nres = rps_may_expire_flow(enic->netdev, n->rq_id,\r\nn->flow_id, n->fltr_id);\r\nif (res) {\r\nres = enic_delfltr(enic, n->fltr_id);\r\nif (unlikely(res))\r\ncontinue;\r\nhlist_del(&n->node);\r\nkfree(n);\r\nenic->rfs_h.free++;\r\n}\r\n}\r\n}\r\nspin_unlock_bh(&enic->rfs_h.lock);\r\nmod_timer(&enic->rfs_h.rfs_may_expire, jiffies + HZ/4);\r\n}\r\nstatic struct enic_rfs_fltr_node *htbl_key_search(struct hlist_head *h,\r\nstruct flow_keys *k)\r\n{\r\nstruct enic_rfs_fltr_node *tpos;\r\nhlist_for_each_entry(tpos, h, node)\r\nif (tpos->keys.addrs.v4addrs.src == k->addrs.v4addrs.src &&\r\ntpos->keys.addrs.v4addrs.dst == k->addrs.v4addrs.dst &&\r\ntpos->keys.ports.ports == k->ports.ports &&\r\ntpos->keys.basic.ip_proto == k->basic.ip_proto &&\r\ntpos->keys.basic.n_proto == k->basic.n_proto)\r\nreturn tpos;\r\nreturn NULL;\r\n}\r\nint enic_rx_flow_steer(struct net_device *dev, const struct sk_buff *skb,\r\nu16 rxq_index, u32 flow_id)\r\n{\r\nstruct flow_keys keys;\r\nstruct enic_rfs_fltr_node *n;\r\nstruct enic *enic;\r\nu16 tbl_idx;\r\nint res, i;\r\nenic = netdev_priv(dev);\r\nres = skb_flow_dissect_flow_keys(skb, &keys, 0);\r\nif (!res || keys.basic.n_proto != htons(ETH_P_IP) ||\r\n(keys.basic.ip_proto != IPPROTO_TCP &&\r\nkeys.basic.ip_proto != IPPROTO_UDP))\r\nreturn -EPROTONOSUPPORT;\r\ntbl_idx = skb_get_hash_raw(skb) & ENIC_RFS_FLW_MASK;\r\nspin_lock_bh(&enic->rfs_h.lock);\r\nn = htbl_key_search(&enic->rfs_h.ht_head[tbl_idx], &keys);\r\nif (n) {\r\nif (rxq_index == n->rq_id) {\r\nres = -EEXIST;\r\ngoto ret_unlock;\r\n}\r\ni = --enic->rfs_h.free;\r\nif (unlikely(i < 0)) {\r\nenic->rfs_h.free++;\r\nres = enic_delfltr(enic, n->fltr_id);\r\nif (unlikely(res < 0))\r\ngoto ret_unlock;\r\nres = enic_addfltr_5t(enic, &keys, rxq_index);\r\nif (res < 0) {\r\nhlist_del(&n->node);\r\nenic->rfs_h.free++;\r\ngoto ret_unlock;\r\n}\r\n} else {\r\nint ret;\r\nres = enic_addfltr_5t(enic, &keys, rxq_index);\r\nif (res < 0) {\r\nenic->rfs_h.free++;\r\ngoto ret_unlock;\r\n}\r\nret = enic_delfltr(enic, n->fltr_id);\r\nif (unlikely(ret < 0)) {\r\nstruct enic_rfs_fltr_node *d;\r\nstruct hlist_head *head;\r\nhead = &enic->rfs_h.ht_head[tbl_idx];\r\nd = kmalloc(sizeof(*d), GFP_ATOMIC);\r\nif (d) {\r\nd->fltr_id = n->fltr_id;\r\nINIT_HLIST_NODE(&d->node);\r\nhlist_add_head(&d->node, head);\r\n}\r\n} else {\r\nenic->rfs_h.free++;\r\n}\r\n}\r\nn->rq_id = rxq_index;\r\nn->fltr_id = res;\r\nn->flow_id = flow_id;\r\n} else {\r\ni = --enic->rfs_h.free;\r\nif (i <= 0) {\r\nenic->rfs_h.free++;\r\nres = -EBUSY;\r\ngoto ret_unlock;\r\n}\r\nn = kmalloc(sizeof(*n), GFP_ATOMIC);\r\nif (!n) {\r\nres = -ENOMEM;\r\nenic->rfs_h.free++;\r\ngoto ret_unlock;\r\n}\r\nres = enic_addfltr_5t(enic, &keys, rxq_index);\r\nif (res < 0) {\r\nkfree(n);\r\nenic->rfs_h.free++;\r\ngoto ret_unlock;\r\n}\r\nn->rq_id = rxq_index;\r\nn->fltr_id = res;\r\nn->flow_id = flow_id;\r\nn->keys = keys;\r\nINIT_HLIST_NODE(&n->node);\r\nhlist_add_head(&n->node, &enic->rfs_h.ht_head[tbl_idx]);\r\n}\r\nret_unlock:\r\nspin_unlock_bh(&enic->rfs_h.lock);\r\nreturn res;\r\n}
