static void print_hw_id(struct pci_dev *pdev)\r\n{\r\nstruct pci_nic *nic = pci_get_drvdata(pdev);\r\nu16 pci_link_status = 0;\r\nu16 pci_ctrl = 0;\r\npci_read_config_word(pdev, PCI_LINK_STATUS_REG, &pci_link_status);\r\npci_read_config_word(pdev, PCI_DEV_CTRL_REG, &pci_ctrl);\r\npr_info("%s%s\n", BDX_NIC_NAME,\r\nnic->port_num == 1 ? "" : ", 2-Port");\r\npr_info("srom 0x%x fpga %d build %u lane# %d max_pl 0x%x mrrs 0x%x\n",\r\nreadl(nic->regs + SROM_VER), readl(nic->regs + FPGA_VER) & 0xFFF,\r\nreadl(nic->regs + FPGA_SEED),\r\nGET_LINK_STATUS_LANES(pci_link_status),\r\nGET_DEV_CTRL_MAXPL(pci_ctrl), GET_DEV_CTRL_MRRS(pci_ctrl));\r\n}\r\nstatic void print_fw_id(struct pci_nic *nic)\r\n{\r\npr_info("fw 0x%x\n", readl(nic->regs + FW_VER));\r\n}\r\nstatic void print_eth_id(struct net_device *ndev)\r\n{\r\nnetdev_info(ndev, "%s, Port %c\n",\r\nBDX_NIC_NAME, (ndev->if_port == 0) ? 'A' : 'B');\r\n}\r\nstatic int\r\nbdx_fifo_init(struct bdx_priv *priv, struct fifo *f, int fsz_type,\r\nu16 reg_CFG0, u16 reg_CFG1, u16 reg_RPTR, u16 reg_WPTR)\r\n{\r\nu16 memsz = FIFO_SIZE * (1 << fsz_type);\r\nmemset(f, 0, sizeof(struct fifo));\r\nf->va = pci_alloc_consistent(priv->pdev,\r\nmemsz + FIFO_EXTRA_SPACE, &f->da);\r\nif (!f->va) {\r\npr_err("pci_alloc_consistent failed\n");\r\nRET(-ENOMEM);\r\n}\r\nf->reg_CFG0 = reg_CFG0;\r\nf->reg_CFG1 = reg_CFG1;\r\nf->reg_RPTR = reg_RPTR;\r\nf->reg_WPTR = reg_WPTR;\r\nf->rptr = 0;\r\nf->wptr = 0;\r\nf->memsz = memsz;\r\nf->size_mask = memsz - 1;\r\nWRITE_REG(priv, reg_CFG0, (u32) ((f->da & TX_RX_CFG0_BASE) | fsz_type));\r\nWRITE_REG(priv, reg_CFG1, H32_64(f->da));\r\nRET(0);\r\n}\r\nstatic void bdx_fifo_free(struct bdx_priv *priv, struct fifo *f)\r\n{\r\nENTER;\r\nif (f->va) {\r\npci_free_consistent(priv->pdev,\r\nf->memsz + FIFO_EXTRA_SPACE, f->va, f->da);\r\nf->va = NULL;\r\n}\r\nRET();\r\n}\r\nstatic void bdx_link_changed(struct bdx_priv *priv)\r\n{\r\nu32 link = READ_REG(priv, regMAC_LNK_STAT) & MAC_LINK_STAT;\r\nif (!link) {\r\nif (netif_carrier_ok(priv->ndev)) {\r\nnetif_stop_queue(priv->ndev);\r\nnetif_carrier_off(priv->ndev);\r\nnetdev_err(priv->ndev, "Link Down\n");\r\n}\r\n} else {\r\nif (!netif_carrier_ok(priv->ndev)) {\r\nnetif_wake_queue(priv->ndev);\r\nnetif_carrier_on(priv->ndev);\r\nnetdev_err(priv->ndev, "Link Up\n");\r\n}\r\n}\r\n}\r\nstatic void bdx_isr_extra(struct bdx_priv *priv, u32 isr)\r\n{\r\nif (isr & IR_RX_FREE_0) {\r\nbdx_rx_alloc_skbs(priv, &priv->rxf_fifo0);\r\nDBG("RX_FREE_0\n");\r\n}\r\nif (isr & IR_LNKCHG0)\r\nbdx_link_changed(priv);\r\nif (isr & IR_PCIE_LINK)\r\nnetdev_err(priv->ndev, "PCI-E Link Fault\n");\r\nif (isr & IR_PCIE_TOUT)\r\nnetdev_err(priv->ndev, "PCI-E Time Out\n");\r\n}\r\nstatic irqreturn_t bdx_isr_napi(int irq, void *dev)\r\n{\r\nstruct net_device *ndev = dev;\r\nstruct bdx_priv *priv = netdev_priv(ndev);\r\nu32 isr;\r\nENTER;\r\nisr = (READ_REG(priv, regISR) & IR_RUN);\r\nif (unlikely(!isr)) {\r\nbdx_enable_interrupts(priv);\r\nreturn IRQ_NONE;\r\n}\r\nif (isr & IR_EXTRA)\r\nbdx_isr_extra(priv, isr);\r\nif (isr & (IR_RX_DESC_0 | IR_TX_FREE_0)) {\r\nif (likely(napi_schedule_prep(&priv->napi))) {\r\n__napi_schedule(&priv->napi);\r\nRET(IRQ_HANDLED);\r\n} else {\r\nREAD_REG(priv, regTXF_WPTR_0);\r\nREAD_REG(priv, regRXD_WPTR_0);\r\n}\r\n}\r\nbdx_enable_interrupts(priv);\r\nRET(IRQ_HANDLED);\r\n}\r\nstatic int bdx_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct bdx_priv *priv = container_of(napi, struct bdx_priv, napi);\r\nint work_done;\r\nENTER;\r\nbdx_tx_cleanup(priv);\r\nwork_done = bdx_rx_receive(priv, &priv->rxd_fifo0, budget);\r\nif ((work_done < budget) ||\r\n(priv->napi_stop++ >= 30)) {\r\nDBG("rx poll is done. backing to isr-driven\n");\r\npriv->napi_stop = 0;\r\nnapi_complete(napi);\r\nbdx_enable_interrupts(priv);\r\n}\r\nreturn work_done;\r\n}\r\nstatic int bdx_fw_load(struct bdx_priv *priv)\r\n{\r\nconst struct firmware *fw = NULL;\r\nint master, i;\r\nint rc;\r\nENTER;\r\nmaster = READ_REG(priv, regINIT_SEMAPHORE);\r\nif (!READ_REG(priv, regINIT_STATUS) && master) {\r\nrc = request_firmware(&fw, "tehuti/bdx.bin", &priv->pdev->dev);\r\nif (rc)\r\ngoto out;\r\nbdx_tx_push_desc_safe(priv, (char *)fw->data, fw->size);\r\nmdelay(100);\r\n}\r\nfor (i = 0; i < 200; i++) {\r\nif (READ_REG(priv, regINIT_STATUS)) {\r\nrc = 0;\r\ngoto out;\r\n}\r\nmdelay(2);\r\n}\r\nrc = -EIO;\r\nout:\r\nif (master)\r\nWRITE_REG(priv, regINIT_SEMAPHORE, 1);\r\nrelease_firmware(fw);\r\nif (rc) {\r\nnetdev_err(priv->ndev, "firmware loading failed\n");\r\nif (rc == -EIO)\r\nDBG("VPC = 0x%x VIC = 0x%x INIT_STATUS = 0x%x i=%d\n",\r\nREAD_REG(priv, regVPC),\r\nREAD_REG(priv, regVIC),\r\nREAD_REG(priv, regINIT_STATUS), i);\r\nRET(rc);\r\n} else {\r\nDBG("%s: firmware loading success\n", priv->ndev->name);\r\nRET(0);\r\n}\r\n}\r\nstatic void bdx_restore_mac(struct net_device *ndev, struct bdx_priv *priv)\r\n{\r\nu32 val;\r\nENTER;\r\nDBG("mac0=%x mac1=%x mac2=%x\n",\r\nREAD_REG(priv, regUNC_MAC0_A),\r\nREAD_REG(priv, regUNC_MAC1_A), READ_REG(priv, regUNC_MAC2_A));\r\nval = (ndev->dev_addr[0] << 8) | (ndev->dev_addr[1]);\r\nWRITE_REG(priv, regUNC_MAC2_A, val);\r\nval = (ndev->dev_addr[2] << 8) | (ndev->dev_addr[3]);\r\nWRITE_REG(priv, regUNC_MAC1_A, val);\r\nval = (ndev->dev_addr[4] << 8) | (ndev->dev_addr[5]);\r\nWRITE_REG(priv, regUNC_MAC0_A, val);\r\nDBG("mac0=%x mac1=%x mac2=%x\n",\r\nREAD_REG(priv, regUNC_MAC0_A),\r\nREAD_REG(priv, regUNC_MAC1_A), READ_REG(priv, regUNC_MAC2_A));\r\nRET();\r\n}\r\nstatic int bdx_hw_start(struct bdx_priv *priv)\r\n{\r\nint rc = -EIO;\r\nstruct net_device *ndev = priv->ndev;\r\nENTER;\r\nbdx_link_changed(priv);\r\nWRITE_REG(priv, regFRM_LENGTH, 0X3FE0);\r\nWRITE_REG(priv, regPAUSE_QUANT, 0x96);\r\nWRITE_REG(priv, regRX_FIFO_SECTION, 0x800010);\r\nWRITE_REG(priv, regTX_FIFO_SECTION, 0xE00010);\r\nWRITE_REG(priv, regRX_FULLNESS, 0);\r\nWRITE_REG(priv, regTX_FULLNESS, 0);\r\nWRITE_REG(priv, regCTRLST,\r\nregCTRLST_BASE | regCTRLST_RX_ENA | regCTRLST_TX_ENA);\r\nWRITE_REG(priv, regVGLB, 0);\r\nWRITE_REG(priv, regMAX_FRAME_A,\r\npriv->rxf_fifo0.m.pktsz & MAX_FRAME_AB_VAL);\r\nDBG("RDINTCM=%08x\n", priv->rdintcm);\r\nWRITE_REG(priv, regRDINTCM0, priv->rdintcm);\r\nWRITE_REG(priv, regRDINTCM2, 0);\r\nDBG("TDINTCM=%08x\n", priv->tdintcm);\r\nWRITE_REG(priv, regTDINTCM0, priv->tdintcm);\r\nbdx_restore_mac(priv->ndev, priv);\r\nWRITE_REG(priv, regGMAC_RXF_A, GMAC_RX_FILTER_OSEN |\r\nGMAC_RX_FILTER_AM | GMAC_RX_FILTER_AB);\r\n#define BDX_IRQ_TYPE ((priv->nic->irq_type == IRQ_MSI) ? 0 : IRQF_SHARED)\r\nrc = request_irq(priv->pdev->irq, bdx_isr_napi, BDX_IRQ_TYPE,\r\nndev->name, ndev);\r\nif (rc)\r\ngoto err_irq;\r\nbdx_enable_interrupts(priv);\r\nRET(0);\r\nerr_irq:\r\nRET(rc);\r\n}\r\nstatic void bdx_hw_stop(struct bdx_priv *priv)\r\n{\r\nENTER;\r\nbdx_disable_interrupts(priv);\r\nfree_irq(priv->pdev->irq, priv->ndev);\r\nnetif_carrier_off(priv->ndev);\r\nnetif_stop_queue(priv->ndev);\r\nRET();\r\n}\r\nstatic int bdx_hw_reset_direct(void __iomem *regs)\r\n{\r\nu32 val, i;\r\nENTER;\r\nval = readl(regs + regCLKPLL);\r\nwritel((val | CLKPLL_SFTRST) + 0x8, regs + regCLKPLL);\r\nudelay(50);\r\nval = readl(regs + regCLKPLL);\r\nwritel(val & ~CLKPLL_SFTRST, regs + regCLKPLL);\r\nfor (i = 0; i < 70; i++, mdelay(10))\r\nif ((readl(regs + regCLKPLL) & CLKPLL_LKD) == CLKPLL_LKD) {\r\nreadl(regs + regRXD_CFG0_0);\r\nreturn 0;\r\n}\r\npr_err("HW reset failed\n");\r\nreturn 1;\r\n}\r\nstatic int bdx_hw_reset(struct bdx_priv *priv)\r\n{\r\nu32 val, i;\r\nENTER;\r\nif (priv->port == 0) {\r\nval = READ_REG(priv, regCLKPLL);\r\nWRITE_REG(priv, regCLKPLL, (val | CLKPLL_SFTRST) + 0x8);\r\nudelay(50);\r\nval = READ_REG(priv, regCLKPLL);\r\nWRITE_REG(priv, regCLKPLL, val & ~CLKPLL_SFTRST);\r\n}\r\nfor (i = 0; i < 70; i++, mdelay(10))\r\nif ((READ_REG(priv, regCLKPLL) & CLKPLL_LKD) == CLKPLL_LKD) {\r\nREAD_REG(priv, regRXD_CFG0_0);\r\nreturn 0;\r\n}\r\npr_err("HW reset failed\n");\r\nreturn 1;\r\n}\r\nstatic int bdx_sw_reset(struct bdx_priv *priv)\r\n{\r\nint i;\r\nENTER;\r\nWRITE_REG(priv, regGMAC_RXF_A, 0);\r\nmdelay(100);\r\nWRITE_REG(priv, regDIS_PORT, 1);\r\nWRITE_REG(priv, regDIS_QU, 1);\r\nfor (i = 0; i < 50; i++) {\r\nif (READ_REG(priv, regRST_PORT) & 1)\r\nbreak;\r\nmdelay(10);\r\n}\r\nif (i == 50)\r\nnetdev_err(priv->ndev, "SW reset timeout. continuing anyway\n");\r\nWRITE_REG(priv, regRDINTCM0, 0);\r\nWRITE_REG(priv, regTDINTCM0, 0);\r\nWRITE_REG(priv, regIMR, 0);\r\nREAD_REG(priv, regISR);\r\nWRITE_REG(priv, regRST_QU, 1);\r\nWRITE_REG(priv, regRST_PORT, 1);\r\nfor (i = regTXD_WPTR_0; i <= regTXF_RPTR_3; i += 0x10)\r\nDBG("%x = %x\n", i, READ_REG(priv, i) & TXF_WPTR_WR_PTR);\r\nfor (i = regTXD_WPTR_0; i <= regTXF_RPTR_3; i += 0x10)\r\nWRITE_REG(priv, i, 0);\r\nWRITE_REG(priv, regDIS_PORT, 0);\r\nWRITE_REG(priv, regDIS_QU, 0);\r\nWRITE_REG(priv, regRST_QU, 0);\r\nWRITE_REG(priv, regRST_PORT, 0);\r\nfor (i = regTXD_WPTR_0; i <= regTXF_RPTR_3; i += 0x10)\r\nDBG("%x = %x\n", i, READ_REG(priv, i) & TXF_WPTR_WR_PTR);\r\nRET(0);\r\n}\r\nstatic int bdx_reset(struct bdx_priv *priv)\r\n{\r\nENTER;\r\nRET((priv->pdev->device == 0x3009)\r\n? bdx_hw_reset(priv)\r\n: bdx_sw_reset(priv));\r\n}\r\nstatic int bdx_close(struct net_device *ndev)\r\n{\r\nstruct bdx_priv *priv = NULL;\r\nENTER;\r\npriv = netdev_priv(ndev);\r\nnapi_disable(&priv->napi);\r\nbdx_reset(priv);\r\nbdx_hw_stop(priv);\r\nbdx_rx_free(priv);\r\nbdx_tx_free(priv);\r\nRET(0);\r\n}\r\nstatic int bdx_open(struct net_device *ndev)\r\n{\r\nstruct bdx_priv *priv;\r\nint rc;\r\nENTER;\r\npriv = netdev_priv(ndev);\r\nbdx_reset(priv);\r\nif (netif_running(ndev))\r\nnetif_stop_queue(priv->ndev);\r\nif ((rc = bdx_tx_init(priv)) ||\r\n(rc = bdx_rx_init(priv)) ||\r\n(rc = bdx_fw_load(priv)))\r\ngoto err;\r\nbdx_rx_alloc_skbs(priv, &priv->rxf_fifo0);\r\nrc = bdx_hw_start(priv);\r\nif (rc)\r\ngoto err;\r\nnapi_enable(&priv->napi);\r\nprint_fw_id(priv->nic);\r\nRET(0);\r\nerr:\r\nbdx_close(ndev);\r\nRET(rc);\r\n}\r\nstatic int bdx_range_check(struct bdx_priv *priv, u32 offset)\r\n{\r\nreturn (offset > (u32) (BDX_REGS_SIZE / priv->nic->port_num)) ?\r\n-EINVAL : 0;\r\n}\r\nstatic int bdx_ioctl_priv(struct net_device *ndev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(ndev);\r\nu32 data[3];\r\nint error;\r\nENTER;\r\nDBG("jiffies=%ld cmd=%d\n", jiffies, cmd);\r\nif (cmd != SIOCDEVPRIVATE) {\r\nerror = copy_from_user(data, ifr->ifr_data, sizeof(data));\r\nif (error) {\r\npr_err("can't copy from user\n");\r\nRET(-EFAULT);\r\n}\r\nDBG("%d 0x%x 0x%x\n", data[0], data[1], data[2]);\r\n}\r\nif (!capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\nswitch (data[0]) {\r\ncase BDX_OP_READ:\r\nerror = bdx_range_check(priv, data[1]);\r\nif (error < 0)\r\nreturn error;\r\ndata[2] = READ_REG(priv, data[1]);\r\nDBG("read_reg(0x%x)=0x%x (dec %d)\n", data[1], data[2],\r\ndata[2]);\r\nerror = copy_to_user(ifr->ifr_data, data, sizeof(data));\r\nif (error)\r\nRET(-EFAULT);\r\nbreak;\r\ncase BDX_OP_WRITE:\r\nerror = bdx_range_check(priv, data[1]);\r\nif (error < 0)\r\nreturn error;\r\nWRITE_REG(priv, data[1], data[2]);\r\nDBG("write_reg(0x%x, 0x%x)\n", data[1], data[2]);\r\nbreak;\r\ndefault:\r\nRET(-EOPNOTSUPP);\r\n}\r\nreturn 0;\r\n}\r\nstatic int bdx_ioctl(struct net_device *ndev, struct ifreq *ifr, int cmd)\r\n{\r\nENTER;\r\nif (cmd >= SIOCDEVPRIVATE && cmd <= (SIOCDEVPRIVATE + 15))\r\nRET(bdx_ioctl_priv(ndev, ifr, cmd));\r\nelse\r\nRET(-EOPNOTSUPP);\r\n}\r\nstatic void __bdx_vlan_rx_vid(struct net_device *ndev, uint16_t vid, int enable)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(ndev);\r\nu32 reg, bit, val;\r\nENTER;\r\nDBG2("vid=%d value=%d\n", (int)vid, enable);\r\nif (unlikely(vid >= 4096)) {\r\npr_err("invalid VID: %u (> 4096)\n", vid);\r\nRET();\r\n}\r\nreg = regVLAN_0 + (vid / 32) * 4;\r\nbit = 1 << vid % 32;\r\nval = READ_REG(priv, reg);\r\nDBG2("reg=%x, val=%x, bit=%d\n", reg, val, bit);\r\nif (enable)\r\nval |= bit;\r\nelse\r\nval &= ~bit;\r\nDBG2("new val %x\n", val);\r\nWRITE_REG(priv, reg, val);\r\nRET();\r\n}\r\nstatic int bdx_vlan_rx_add_vid(struct net_device *ndev, __be16 proto, u16 vid)\r\n{\r\n__bdx_vlan_rx_vid(ndev, vid, 1);\r\nreturn 0;\r\n}\r\nstatic int bdx_vlan_rx_kill_vid(struct net_device *ndev, __be16 proto, u16 vid)\r\n{\r\n__bdx_vlan_rx_vid(ndev, vid, 0);\r\nreturn 0;\r\n}\r\nstatic int bdx_change_mtu(struct net_device *ndev, int new_mtu)\r\n{\r\nENTER;\r\nif (new_mtu == ndev->mtu)\r\nRET(0);\r\nif (new_mtu < ETH_ZLEN) {\r\nnetdev_err(ndev, "mtu %d is less then minimal %d\n",\r\nnew_mtu, ETH_ZLEN);\r\nRET(-EINVAL);\r\n}\r\nndev->mtu = new_mtu;\r\nif (netif_running(ndev)) {\r\nbdx_close(ndev);\r\nbdx_open(ndev);\r\n}\r\nRET(0);\r\n}\r\nstatic void bdx_setmulti(struct net_device *ndev)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(ndev);\r\nu32 rxf_val =\r\nGMAC_RX_FILTER_AM | GMAC_RX_FILTER_AB | GMAC_RX_FILTER_OSEN;\r\nint i;\r\nENTER;\r\nif (ndev->flags & IFF_PROMISC) {\r\nrxf_val |= GMAC_RX_FILTER_PRM;\r\n} else if (ndev->flags & IFF_ALLMULTI) {\r\nfor (i = 0; i < MAC_MCST_HASH_NUM; i++)\r\nWRITE_REG(priv, regRX_MCST_HASH0 + i * 4, ~0);\r\n} else if (!netdev_mc_empty(ndev)) {\r\nu8 hash;\r\nstruct netdev_hw_addr *ha;\r\nu32 reg, val;\r\nfor (i = 0; i < MAC_MCST_HASH_NUM; i++)\r\nWRITE_REG(priv, regRX_MCST_HASH0 + i * 4, 0);\r\nfor (i = 0; i < MAC_MCST_NUM; i++) {\r\nWRITE_REG(priv, regRX_MAC_MCST0 + i * 8, 0);\r\nWRITE_REG(priv, regRX_MAC_MCST1 + i * 8, 0);\r\n}\r\nnetdev_for_each_mc_addr(ha, ndev) {\r\nhash = 0;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\nhash ^= ha->addr[i];\r\nreg = regRX_MCST_HASH0 + ((hash >> 5) << 2);\r\nval = READ_REG(priv, reg);\r\nval |= (1 << (hash % 32));\r\nWRITE_REG(priv, reg, val);\r\n}\r\n} else {\r\nDBG("only own mac %d\n", netdev_mc_count(ndev));\r\nrxf_val |= GMAC_RX_FILTER_AB;\r\n}\r\nWRITE_REG(priv, regGMAC_RXF_A, rxf_val);\r\nRET();\r\n}\r\nstatic int bdx_set_mac(struct net_device *ndev, void *p)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(ndev);\r\nstruct sockaddr *addr = p;\r\nENTER;\r\nmemcpy(ndev->dev_addr, addr->sa_data, ndev->addr_len);\r\nbdx_restore_mac(ndev, priv);\r\nRET(0);\r\n}\r\nstatic int bdx_read_mac(struct bdx_priv *priv)\r\n{\r\nu16 macAddress[3], i;\r\nENTER;\r\nmacAddress[2] = READ_REG(priv, regUNC_MAC0_A);\r\nmacAddress[2] = READ_REG(priv, regUNC_MAC0_A);\r\nmacAddress[1] = READ_REG(priv, regUNC_MAC1_A);\r\nmacAddress[1] = READ_REG(priv, regUNC_MAC1_A);\r\nmacAddress[0] = READ_REG(priv, regUNC_MAC2_A);\r\nmacAddress[0] = READ_REG(priv, regUNC_MAC2_A);\r\nfor (i = 0; i < 3; i++) {\r\npriv->ndev->dev_addr[i * 2 + 1] = macAddress[i];\r\npriv->ndev->dev_addr[i * 2] = macAddress[i] >> 8;\r\n}\r\nRET(0);\r\n}\r\nstatic u64 bdx_read_l2stat(struct bdx_priv *priv, int reg)\r\n{\r\nu64 val;\r\nval = READ_REG(priv, reg);\r\nval |= ((u64) READ_REG(priv, reg + 8)) << 32;\r\nreturn val;\r\n}\r\nstatic void bdx_update_stats(struct bdx_priv *priv)\r\n{\r\nstruct bdx_stats *stats = &priv->hw_stats;\r\nu64 *stats_vector = (u64 *) stats;\r\nint i;\r\nint addr;\r\naddr = 0x7200;\r\nfor (i = 0; i < 12; i++) {\r\nstats_vector[i] = bdx_read_l2stat(priv, addr);\r\naddr += 0x10;\r\n}\r\nBDX_ASSERT(addr != 0x72C0);\r\naddr = 0x72F0;\r\nfor (; i < 16; i++) {\r\nstats_vector[i] = bdx_read_l2stat(priv, addr);\r\naddr += 0x10;\r\n}\r\nBDX_ASSERT(addr != 0x7330);\r\naddr = 0x7370;\r\nfor (; i < 19; i++) {\r\nstats_vector[i] = bdx_read_l2stat(priv, addr);\r\naddr += 0x10;\r\n}\r\nBDX_ASSERT(addr != 0x73A0);\r\naddr = 0x73C0;\r\nfor (; i < 23; i++) {\r\nstats_vector[i] = bdx_read_l2stat(priv, addr);\r\naddr += 0x10;\r\n}\r\nBDX_ASSERT(addr != 0x7400);\r\nBDX_ASSERT((sizeof(struct bdx_stats) / sizeof(u64)) != i);\r\n}\r\nstatic void bdx_rxdb_destroy(struct rxdb *db)\r\n{\r\nvfree(db);\r\n}\r\nstatic struct rxdb *bdx_rxdb_create(int nelem)\r\n{\r\nstruct rxdb *db;\r\nint i;\r\ndb = vmalloc(sizeof(struct rxdb)\r\n+ (nelem * sizeof(int))\r\n+ (nelem * sizeof(struct rx_map)));\r\nif (likely(db != NULL)) {\r\ndb->stack = (int *)(db + 1);\r\ndb->elems = (void *)(db->stack + nelem);\r\ndb->nelem = nelem;\r\ndb->top = nelem;\r\nfor (i = 0; i < nelem; i++)\r\ndb->stack[i] = nelem - i - 1;\r\n}\r\nreturn db;\r\n}\r\nstatic inline int bdx_rxdb_alloc_elem(struct rxdb *db)\r\n{\r\nBDX_ASSERT(db->top <= 0);\r\nreturn db->stack[--(db->top)];\r\n}\r\nstatic inline void *bdx_rxdb_addr_elem(struct rxdb *db, int n)\r\n{\r\nBDX_ASSERT((n < 0) || (n >= db->nelem));\r\nreturn db->elems + n;\r\n}\r\nstatic inline int bdx_rxdb_available(struct rxdb *db)\r\n{\r\nreturn db->top;\r\n}\r\nstatic inline void bdx_rxdb_free_elem(struct rxdb *db, int n)\r\n{\r\nBDX_ASSERT((n >= db->nelem) || (n < 0));\r\ndb->stack[(db->top)++] = n;\r\n}\r\nstatic int bdx_rx_init(struct bdx_priv *priv)\r\n{\r\nENTER;\r\nif (bdx_fifo_init(priv, &priv->rxd_fifo0.m, priv->rxd_size,\r\nregRXD_CFG0_0, regRXD_CFG1_0,\r\nregRXD_RPTR_0, regRXD_WPTR_0))\r\ngoto err_mem;\r\nif (bdx_fifo_init(priv, &priv->rxf_fifo0.m, priv->rxf_size,\r\nregRXF_CFG0_0, regRXF_CFG1_0,\r\nregRXF_RPTR_0, regRXF_WPTR_0))\r\ngoto err_mem;\r\npriv->rxdb = bdx_rxdb_create(priv->rxf_fifo0.m.memsz /\r\nsizeof(struct rxf_desc));\r\nif (!priv->rxdb)\r\ngoto err_mem;\r\npriv->rxf_fifo0.m.pktsz = priv->ndev->mtu + VLAN_ETH_HLEN;\r\nreturn 0;\r\nerr_mem:\r\nnetdev_err(priv->ndev, "Rx init failed\n");\r\nreturn -ENOMEM;\r\n}\r\nstatic void bdx_rx_free_skbs(struct bdx_priv *priv, struct rxf_fifo *f)\r\n{\r\nstruct rx_map *dm;\r\nstruct rxdb *db = priv->rxdb;\r\nu16 i;\r\nENTER;\r\nDBG("total=%d free=%d busy=%d\n", db->nelem, bdx_rxdb_available(db),\r\ndb->nelem - bdx_rxdb_available(db));\r\nwhile (bdx_rxdb_available(db) > 0) {\r\ni = bdx_rxdb_alloc_elem(db);\r\ndm = bdx_rxdb_addr_elem(db, i);\r\ndm->dma = 0;\r\n}\r\nfor (i = 0; i < db->nelem; i++) {\r\ndm = bdx_rxdb_addr_elem(db, i);\r\nif (dm->dma) {\r\npci_unmap_single(priv->pdev,\r\ndm->dma, f->m.pktsz,\r\nPCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(dm->skb);\r\n}\r\n}\r\n}\r\nstatic void bdx_rx_free(struct bdx_priv *priv)\r\n{\r\nENTER;\r\nif (priv->rxdb) {\r\nbdx_rx_free_skbs(priv, &priv->rxf_fifo0);\r\nbdx_rxdb_destroy(priv->rxdb);\r\npriv->rxdb = NULL;\r\n}\r\nbdx_fifo_free(priv, &priv->rxf_fifo0.m);\r\nbdx_fifo_free(priv, &priv->rxd_fifo0.m);\r\nRET();\r\n}\r\nstatic void bdx_rx_alloc_skbs(struct bdx_priv *priv, struct rxf_fifo *f)\r\n{\r\nstruct sk_buff *skb;\r\nstruct rxf_desc *rxfd;\r\nstruct rx_map *dm;\r\nint dno, delta, idx;\r\nstruct rxdb *db = priv->rxdb;\r\nENTER;\r\ndno = bdx_rxdb_available(db) - 1;\r\nwhile (dno > 0) {\r\nskb = netdev_alloc_skb(priv->ndev, f->m.pktsz + NET_IP_ALIGN);\r\nif (!skb)\r\nbreak;\r\nskb_reserve(skb, NET_IP_ALIGN);\r\nidx = bdx_rxdb_alloc_elem(db);\r\ndm = bdx_rxdb_addr_elem(db, idx);\r\ndm->dma = pci_map_single(priv->pdev,\r\nskb->data, f->m.pktsz,\r\nPCI_DMA_FROMDEVICE);\r\ndm->skb = skb;\r\nrxfd = (struct rxf_desc *)(f->m.va + f->m.wptr);\r\nrxfd->info = CPU_CHIP_SWAP32(0x10003);\r\nrxfd->va_lo = idx;\r\nrxfd->pa_lo = CPU_CHIP_SWAP32(L32_64(dm->dma));\r\nrxfd->pa_hi = CPU_CHIP_SWAP32(H32_64(dm->dma));\r\nrxfd->len = CPU_CHIP_SWAP32(f->m.pktsz);\r\nprint_rxfd(rxfd);\r\nf->m.wptr += sizeof(struct rxf_desc);\r\ndelta = f->m.wptr - f->m.memsz;\r\nif (unlikely(delta >= 0)) {\r\nf->m.wptr = delta;\r\nif (delta > 0) {\r\nmemcpy(f->m.va, f->m.va + f->m.memsz, delta);\r\nDBG("wrapped descriptor\n");\r\n}\r\n}\r\ndno--;\r\n}\r\nWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\r\nRET();\r\n}\r\nstatic inline void\r\nNETIF_RX_MUX(struct bdx_priv *priv, u32 rxd_val1, u16 rxd_vlan,\r\nstruct sk_buff *skb)\r\n{\r\nENTER;\r\nDBG("rxdd->flags.bits.vtag=%d\n", GET_RXD_VTAG(rxd_val1));\r\nif (GET_RXD_VTAG(rxd_val1)) {\r\nDBG("%s: vlan rcv vlan '%x' vtag '%x'\n",\r\npriv->ndev->name,\r\nGET_RXD_VLAN_ID(rxd_vlan),\r\nGET_RXD_VTAG(rxd_val1));\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), GET_RXD_VLAN_TCI(rxd_vlan));\r\n}\r\nnetif_receive_skb(skb);\r\n}\r\nstatic void bdx_recycle_skb(struct bdx_priv *priv, struct rxd_desc *rxdd)\r\n{\r\nstruct rxf_desc *rxfd;\r\nstruct rx_map *dm;\r\nstruct rxf_fifo *f;\r\nstruct rxdb *db;\r\nstruct sk_buff *skb;\r\nint delta;\r\nENTER;\r\nDBG("priv=%p rxdd=%p\n", priv, rxdd);\r\nf = &priv->rxf_fifo0;\r\ndb = priv->rxdb;\r\nDBG("db=%p f=%p\n", db, f);\r\ndm = bdx_rxdb_addr_elem(db, rxdd->va_lo);\r\nDBG("dm=%p\n", dm);\r\nskb = dm->skb;\r\nrxfd = (struct rxf_desc *)(f->m.va + f->m.wptr);\r\nrxfd->info = CPU_CHIP_SWAP32(0x10003);\r\nrxfd->va_lo = rxdd->va_lo;\r\nrxfd->pa_lo = CPU_CHIP_SWAP32(L32_64(dm->dma));\r\nrxfd->pa_hi = CPU_CHIP_SWAP32(H32_64(dm->dma));\r\nrxfd->len = CPU_CHIP_SWAP32(f->m.pktsz);\r\nprint_rxfd(rxfd);\r\nf->m.wptr += sizeof(struct rxf_desc);\r\ndelta = f->m.wptr - f->m.memsz;\r\nif (unlikely(delta >= 0)) {\r\nf->m.wptr = delta;\r\nif (delta > 0) {\r\nmemcpy(f->m.va, f->m.va + f->m.memsz, delta);\r\nDBG("wrapped descriptor\n");\r\n}\r\n}\r\nRET();\r\n}\r\nstatic int bdx_rx_receive(struct bdx_priv *priv, struct rxd_fifo *f, int budget)\r\n{\r\nstruct net_device *ndev = priv->ndev;\r\nstruct sk_buff *skb, *skb2;\r\nstruct rxd_desc *rxdd;\r\nstruct rx_map *dm;\r\nstruct rxf_fifo *rxf_fifo;\r\nint tmp_len, size;\r\nint done = 0;\r\nint max_done = BDX_MAX_RX_DONE;\r\nstruct rxdb *db = NULL;\r\nu32 rxd_val1;\r\nu16 len;\r\nu16 rxd_vlan;\r\nENTER;\r\nmax_done = budget;\r\nf->m.wptr = READ_REG(priv, f->m.reg_WPTR) & TXF_WPTR_WR_PTR;\r\nsize = f->m.wptr - f->m.rptr;\r\nif (size < 0)\r\nsize = f->m.memsz + size;\r\nwhile (size > 0) {\r\nrxdd = (struct rxd_desc *)(f->m.va + f->m.rptr);\r\nrxd_val1 = CPU_CHIP_SWAP32(rxdd->rxd_val1);\r\nlen = CPU_CHIP_SWAP16(rxdd->len);\r\nrxd_vlan = CPU_CHIP_SWAP16(rxdd->rxd_vlan);\r\nprint_rxdd(rxdd, rxd_val1, len, rxd_vlan);\r\ntmp_len = GET_RXD_BC(rxd_val1) << 3;\r\nBDX_ASSERT(tmp_len <= 0);\r\nsize -= tmp_len;\r\nif (size < 0)\r\nbreak;\r\nf->m.rptr += tmp_len;\r\ntmp_len = f->m.rptr - f->m.memsz;\r\nif (unlikely(tmp_len >= 0)) {\r\nf->m.rptr = tmp_len;\r\nif (tmp_len > 0) {\r\nDBG("wrapped desc rptr=%d tmp_len=%d\n",\r\nf->m.rptr, tmp_len);\r\nmemcpy(f->m.va + f->m.memsz, f->m.va, tmp_len);\r\n}\r\n}\r\nif (unlikely(GET_RXD_ERR(rxd_val1))) {\r\nDBG("rxd_err = 0x%x\n", GET_RXD_ERR(rxd_val1));\r\nndev->stats.rx_errors++;\r\nbdx_recycle_skb(priv, rxdd);\r\ncontinue;\r\n}\r\nrxf_fifo = &priv->rxf_fifo0;\r\ndb = priv->rxdb;\r\ndm = bdx_rxdb_addr_elem(db, rxdd->va_lo);\r\nskb = dm->skb;\r\nif (len < BDX_COPYBREAK &&\r\n(skb2 = netdev_alloc_skb(priv->ndev, len + NET_IP_ALIGN))) {\r\nskb_reserve(skb2, NET_IP_ALIGN);\r\npci_dma_sync_single_for_cpu(priv->pdev,\r\ndm->dma, rxf_fifo->m.pktsz,\r\nPCI_DMA_FROMDEVICE);\r\nmemcpy(skb2->data, skb->data, len);\r\nbdx_recycle_skb(priv, rxdd);\r\nskb = skb2;\r\n} else {\r\npci_unmap_single(priv->pdev,\r\ndm->dma, rxf_fifo->m.pktsz,\r\nPCI_DMA_FROMDEVICE);\r\nbdx_rxdb_free_elem(db, rxdd->va_lo);\r\n}\r\nndev->stats.rx_bytes += len;\r\nskb_put(skb, len);\r\nskb->protocol = eth_type_trans(skb, ndev);\r\nif (GET_RXD_PKT_ID(rxd_val1) == 0)\r\nskb_checksum_none_assert(skb);\r\nelse\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nNETIF_RX_MUX(priv, rxd_val1, rxd_vlan, skb);\r\nif (++done >= max_done)\r\nbreak;\r\n}\r\nndev->stats.rx_packets += done;\r\nWRITE_REG(priv, f->m.reg_RPTR, f->m.rptr & TXF_WPTR_WR_PTR);\r\nbdx_rx_alloc_skbs(priv, &priv->rxf_fifo0);\r\nRET(done);\r\n}\r\nstatic void print_rxdd(struct rxd_desc *rxdd, u32 rxd_val1, u16 len,\r\nu16 rxd_vlan)\r\n{\r\nDBG("ERROR: rxdd bc %d rxfq %d to %d type %d err %d rxp %d pkt_id %d vtag %d len %d vlan_id %d cfi %d prio %d va_lo %d va_hi %d\n",\r\nGET_RXD_BC(rxd_val1), GET_RXD_RXFQ(rxd_val1), GET_RXD_TO(rxd_val1),\r\nGET_RXD_TYPE(rxd_val1), GET_RXD_ERR(rxd_val1),\r\nGET_RXD_RXP(rxd_val1), GET_RXD_PKT_ID(rxd_val1),\r\nGET_RXD_VTAG(rxd_val1), len, GET_RXD_VLAN_ID(rxd_vlan),\r\nGET_RXD_CFI(rxd_vlan), GET_RXD_PRIO(rxd_vlan), rxdd->va_lo,\r\nrxdd->va_hi);\r\n}\r\nstatic void print_rxfd(struct rxf_desc *rxfd)\r\n{\r\nDBG("=== RxF desc CHIP ORDER/ENDIANNESS =============\n"\r\n"info 0x%x va_lo %u pa_lo 0x%x pa_hi 0x%x len 0x%x\n",\r\nrxfd->info, rxfd->va_lo, rxfd->pa_lo, rxfd->pa_hi, rxfd->len);\r\n}\r\nstatic inline int bdx_tx_db_size(struct txdb *db)\r\n{\r\nint taken = db->wptr - db->rptr;\r\nif (taken < 0)\r\ntaken = db->size + 1 + taken;\r\nreturn db->size - taken;\r\n}\r\nstatic inline void __bdx_tx_db_ptr_next(struct txdb *db, struct tx_map **pptr)\r\n{\r\nBDX_ASSERT(db == NULL || pptr == NULL);\r\nBDX_ASSERT(*pptr != db->rptr &&\r\n*pptr != db->wptr);\r\nBDX_ASSERT(*pptr < db->start ||\r\n*pptr >= db->end);\r\n++*pptr;\r\nif (unlikely(*pptr == db->end))\r\n*pptr = db->start;\r\n}\r\nstatic inline void bdx_tx_db_inc_rptr(struct txdb *db)\r\n{\r\nBDX_ASSERT(db->rptr == db->wptr);\r\n__bdx_tx_db_ptr_next(db, &db->rptr);\r\n}\r\nstatic inline void bdx_tx_db_inc_wptr(struct txdb *db)\r\n{\r\n__bdx_tx_db_ptr_next(db, &db->wptr);\r\nBDX_ASSERT(db->rptr == db->wptr);\r\n}\r\nstatic int bdx_tx_db_init(struct txdb *d, int sz_type)\r\n{\r\nint memsz = FIFO_SIZE * (1 << (sz_type + 1));\r\nd->start = vmalloc(memsz);\r\nif (!d->start)\r\nreturn -ENOMEM;\r\nd->size = memsz / sizeof(struct tx_map) - 1;\r\nd->end = d->start + d->size + 1;\r\nd->rptr = d->start;\r\nd->wptr = d->start;\r\nreturn 0;\r\n}\r\nstatic void bdx_tx_db_close(struct txdb *d)\r\n{\r\nBDX_ASSERT(d == NULL);\r\nvfree(d->start);\r\nd->start = NULL;\r\n}\r\nstatic inline void\r\nbdx_tx_map_skb(struct bdx_priv *priv, struct sk_buff *skb,\r\nstruct txd_desc *txdd)\r\n{\r\nstruct txdb *db = &priv->txdb;\r\nstruct pbl *pbl = &txdd->pbl[0];\r\nint nr_frags = skb_shinfo(skb)->nr_frags;\r\nint i;\r\ndb->wptr->len = skb_headlen(skb);\r\ndb->wptr->addr.dma = pci_map_single(priv->pdev, skb->data,\r\ndb->wptr->len, PCI_DMA_TODEVICE);\r\npbl->len = CPU_CHIP_SWAP32(db->wptr->len);\r\npbl->pa_lo = CPU_CHIP_SWAP32(L32_64(db->wptr->addr.dma));\r\npbl->pa_hi = CPU_CHIP_SWAP32(H32_64(db->wptr->addr.dma));\r\nDBG("=== pbl len: 0x%x ================\n", pbl->len);\r\nDBG("=== pbl pa_lo: 0x%x ================\n", pbl->pa_lo);\r\nDBG("=== pbl pa_hi: 0x%x ================\n", pbl->pa_hi);\r\nbdx_tx_db_inc_wptr(db);\r\nfor (i = 0; i < nr_frags; i++) {\r\nconst struct skb_frag_struct *frag;\r\nfrag = &skb_shinfo(skb)->frags[i];\r\ndb->wptr->len = skb_frag_size(frag);\r\ndb->wptr->addr.dma = skb_frag_dma_map(&priv->pdev->dev, frag,\r\n0, skb_frag_size(frag),\r\nDMA_TO_DEVICE);\r\npbl++;\r\npbl->len = CPU_CHIP_SWAP32(db->wptr->len);\r\npbl->pa_lo = CPU_CHIP_SWAP32(L32_64(db->wptr->addr.dma));\r\npbl->pa_hi = CPU_CHIP_SWAP32(H32_64(db->wptr->addr.dma));\r\nbdx_tx_db_inc_wptr(db);\r\n}\r\ndb->wptr->len = -txd_sizes[nr_frags].bytes;\r\ndb->wptr->addr.skb = skb;\r\nbdx_tx_db_inc_wptr(db);\r\n}\r\nstatic void __init init_txd_sizes(void)\r\n{\r\nint i, lwords;\r\nfor (i = 0; i < MAX_SKB_FRAGS + 1; i++) {\r\nlwords = 7 + (i * 3);\r\nif (lwords & 1)\r\nlwords++;\r\ntxd_sizes[i].qwords = lwords >> 1;\r\ntxd_sizes[i].bytes = lwords << 2;\r\n}\r\n}\r\nstatic int bdx_tx_init(struct bdx_priv *priv)\r\n{\r\nif (bdx_fifo_init(priv, &priv->txd_fifo0.m, priv->txd_size,\r\nregTXD_CFG0_0,\r\nregTXD_CFG1_0, regTXD_RPTR_0, regTXD_WPTR_0))\r\ngoto err_mem;\r\nif (bdx_fifo_init(priv, &priv->txf_fifo0.m, priv->txf_size,\r\nregTXF_CFG0_0,\r\nregTXF_CFG1_0, regTXF_RPTR_0, regTXF_WPTR_0))\r\ngoto err_mem;\r\nif (bdx_tx_db_init(&priv->txdb, max(priv->txd_size, priv->txf_size)))\r\ngoto err_mem;\r\npriv->tx_level = BDX_MAX_TX_LEVEL;\r\n#ifdef BDX_DELAY_WPTR\r\npriv->tx_update_mark = priv->tx_level - 1024;\r\n#endif\r\nreturn 0;\r\nerr_mem:\r\nnetdev_err(priv->ndev, "Tx init failed\n");\r\nreturn -ENOMEM;\r\n}\r\nstatic inline int bdx_tx_space(struct bdx_priv *priv)\r\n{\r\nstruct txd_fifo *f = &priv->txd_fifo0;\r\nint fsize;\r\nf->m.rptr = READ_REG(priv, f->m.reg_RPTR) & TXF_WPTR_WR_PTR;\r\nfsize = f->m.rptr - f->m.wptr;\r\nif (fsize <= 0)\r\nfsize = f->m.memsz + fsize;\r\nreturn fsize;\r\n}\r\nstatic netdev_tx_t bdx_tx_transmit(struct sk_buff *skb,\r\nstruct net_device *ndev)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(ndev);\r\nstruct txd_fifo *f = &priv->txd_fifo0;\r\nint txd_checksum = 7;\r\nint txd_lgsnd = 0;\r\nint txd_vlan_id = 0;\r\nint txd_vtag = 0;\r\nint txd_mss = 0;\r\nint nr_frags = skb_shinfo(skb)->nr_frags;\r\nstruct txd_desc *txdd;\r\nint len;\r\nunsigned long flags;\r\nENTER;\r\nlocal_irq_save(flags);\r\nif (!spin_trylock(&priv->tx_lock)) {\r\nlocal_irq_restore(flags);\r\nDBG("%s[%s]: TX locked, returning NETDEV_TX_LOCKED\n",\r\nBDX_DRV_NAME, ndev->name);\r\nreturn NETDEV_TX_LOCKED;\r\n}\r\nBDX_ASSERT(f->m.wptr >= f->m.memsz);\r\ntxdd = (struct txd_desc *)(f->m.va + f->m.wptr);\r\nif (unlikely(skb->ip_summed != CHECKSUM_PARTIAL))\r\ntxd_checksum = 0;\r\nif (skb_shinfo(skb)->gso_size) {\r\ntxd_mss = skb_shinfo(skb)->gso_size;\r\ntxd_lgsnd = 1;\r\nDBG("skb %p skb len %d gso size = %d\n", skb, skb->len,\r\ntxd_mss);\r\n}\r\nif (skb_vlan_tag_present(skb)) {\r\ntxd_vlan_id = skb_vlan_tag_get(skb) & BITS_MASK(12);\r\ntxd_vtag = 1;\r\n}\r\ntxdd->length = CPU_CHIP_SWAP16(skb->len);\r\ntxdd->mss = CPU_CHIP_SWAP16(txd_mss);\r\ntxdd->txd_val1 =\r\nCPU_CHIP_SWAP32(TXD_W1_VAL\r\n(txd_sizes[nr_frags].qwords, txd_checksum, txd_vtag,\r\ntxd_lgsnd, txd_vlan_id));\r\nDBG("=== TxD desc =====================\n");\r\nDBG("=== w1: 0x%x ================\n", txdd->txd_val1);\r\nDBG("=== w2: mss 0x%x len 0x%x\n", txdd->mss, txdd->length);\r\nbdx_tx_map_skb(priv, skb, txdd);\r\nf->m.wptr += txd_sizes[nr_frags].bytes;\r\nlen = f->m.wptr - f->m.memsz;\r\nif (unlikely(len >= 0)) {\r\nf->m.wptr = len;\r\nif (len > 0) {\r\nBDX_ASSERT(len > f->m.memsz);\r\nmemcpy(f->m.va, f->m.va + f->m.memsz, len);\r\n}\r\n}\r\nBDX_ASSERT(f->m.wptr >= f->m.memsz);\r\npriv->tx_level -= txd_sizes[nr_frags].bytes;\r\nBDX_ASSERT(priv->tx_level <= 0 || priv->tx_level > BDX_MAX_TX_LEVEL);\r\n#ifdef BDX_DELAY_WPTR\r\nif (priv->tx_level > priv->tx_update_mark) {\r\nWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\r\n} else {\r\nif (priv->tx_noupd++ > BDX_NO_UPD_PACKETS) {\r\npriv->tx_noupd = 0;\r\nWRITE_REG(priv, f->m.reg_WPTR,\r\nf->m.wptr & TXF_WPTR_WR_PTR);\r\n}\r\n}\r\n#else\r\nWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\r\n#endif\r\n#ifdef BDX_LLTX\r\nndev->trans_start = jiffies;\r\n#endif\r\nndev->stats.tx_packets++;\r\nndev->stats.tx_bytes += skb->len;\r\nif (priv->tx_level < BDX_MIN_TX_LEVEL) {\r\nDBG("%s: %s: TX Q STOP level %d\n",\r\nBDX_DRV_NAME, ndev->name, priv->tx_level);\r\nnetif_stop_queue(ndev);\r\n}\r\nspin_unlock_irqrestore(&priv->tx_lock, flags);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void bdx_tx_cleanup(struct bdx_priv *priv)\r\n{\r\nstruct txf_fifo *f = &priv->txf_fifo0;\r\nstruct txdb *db = &priv->txdb;\r\nint tx_level = 0;\r\nENTER;\r\nf->m.wptr = READ_REG(priv, f->m.reg_WPTR) & TXF_WPTR_MASK;\r\nBDX_ASSERT(f->m.rptr >= f->m.memsz);\r\nwhile (f->m.wptr != f->m.rptr) {\r\nf->m.rptr += BDX_TXF_DESC_SZ;\r\nf->m.rptr &= f->m.size_mask;\r\nBDX_ASSERT(db->rptr->len == 0);\r\ndo {\r\nBDX_ASSERT(db->rptr->addr.dma == 0);\r\npci_unmap_page(priv->pdev, db->rptr->addr.dma,\r\ndb->rptr->len, PCI_DMA_TODEVICE);\r\nbdx_tx_db_inc_rptr(db);\r\n} while (db->rptr->len > 0);\r\ntx_level -= db->rptr->len;\r\ndev_kfree_skb_irq(db->rptr->addr.skb);\r\nbdx_tx_db_inc_rptr(db);\r\n}\r\nBDX_ASSERT((f->m.wptr & TXF_WPTR_WR_PTR) >= f->m.memsz);\r\nWRITE_REG(priv, f->m.reg_RPTR, f->m.rptr & TXF_WPTR_WR_PTR);\r\nspin_lock(&priv->tx_lock);\r\npriv->tx_level += tx_level;\r\nBDX_ASSERT(priv->tx_level <= 0 || priv->tx_level > BDX_MAX_TX_LEVEL);\r\n#ifdef BDX_DELAY_WPTR\r\nif (priv->tx_noupd) {\r\npriv->tx_noupd = 0;\r\nWRITE_REG(priv, priv->txd_fifo0.m.reg_WPTR,\r\npriv->txd_fifo0.m.wptr & TXF_WPTR_WR_PTR);\r\n}\r\n#endif\r\nif (unlikely(netif_queue_stopped(priv->ndev) &&\r\nnetif_carrier_ok(priv->ndev) &&\r\n(priv->tx_level >= BDX_MIN_TX_LEVEL))) {\r\nDBG("%s: %s: TX Q WAKE level %d\n",\r\nBDX_DRV_NAME, priv->ndev->name, priv->tx_level);\r\nnetif_wake_queue(priv->ndev);\r\n}\r\nspin_unlock(&priv->tx_lock);\r\n}\r\nstatic void bdx_tx_free_skbs(struct bdx_priv *priv)\r\n{\r\nstruct txdb *db = &priv->txdb;\r\nENTER;\r\nwhile (db->rptr != db->wptr) {\r\nif (likely(db->rptr->len))\r\npci_unmap_page(priv->pdev, db->rptr->addr.dma,\r\ndb->rptr->len, PCI_DMA_TODEVICE);\r\nelse\r\ndev_kfree_skb(db->rptr->addr.skb);\r\nbdx_tx_db_inc_rptr(db);\r\n}\r\nRET();\r\n}\r\nstatic void bdx_tx_free(struct bdx_priv *priv)\r\n{\r\nENTER;\r\nbdx_tx_free_skbs(priv);\r\nbdx_fifo_free(priv, &priv->txd_fifo0.m);\r\nbdx_fifo_free(priv, &priv->txf_fifo0.m);\r\nbdx_tx_db_close(&priv->txdb);\r\n}\r\nstatic void bdx_tx_push_desc(struct bdx_priv *priv, void *data, int size)\r\n{\r\nstruct txd_fifo *f = &priv->txd_fifo0;\r\nint i = f->m.memsz - f->m.wptr;\r\nif (size == 0)\r\nreturn;\r\nif (i > size) {\r\nmemcpy(f->m.va + f->m.wptr, data, size);\r\nf->m.wptr += size;\r\n} else {\r\nmemcpy(f->m.va + f->m.wptr, data, i);\r\nf->m.wptr = size - i;\r\nmemcpy(f->m.va, data + i, f->m.wptr);\r\n}\r\nWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\r\n}\r\nstatic void bdx_tx_push_desc_safe(struct bdx_priv *priv, void *data, int size)\r\n{\r\nint timer = 0;\r\nENTER;\r\nwhile (size > 0) {\r\nint avail = bdx_tx_space(priv) - 8;\r\nif (avail <= 0) {\r\nif (timer++ > 300) {\r\nDBG("timeout while writing desc to TxD fifo\n");\r\nbreak;\r\n}\r\nudelay(50);\r\ncontinue;\r\n}\r\navail = min(avail, size);\r\nDBG("about to push %d bytes starting %p size %d\n", avail,\r\ndata, size);\r\nbdx_tx_push_desc(priv, data, avail);\r\nsize -= avail;\r\ndata += avail;\r\n}\r\nRET();\r\n}\r\nstatic int\r\nbdx_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct net_device *ndev;\r\nstruct bdx_priv *priv;\r\nint err, pci_using_dac, port;\r\nunsigned long pciaddr;\r\nu32 regionSize;\r\nstruct pci_nic *nic;\r\nENTER;\r\nnic = vmalloc(sizeof(*nic));\r\nif (!nic)\r\nRET(-ENOMEM);\r\nerr = pci_enable_device(pdev);\r\nif (err)\r\ngoto err_pci;\r\nif (!(err = pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) &&\r\n!(err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64)))) {\r\npci_using_dac = 1;\r\n} else {\r\nif ((err = pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) ||\r\n(err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32)))) {\r\npr_err("No usable DMA configuration, aborting\n");\r\ngoto err_dma;\r\n}\r\npci_using_dac = 0;\r\n}\r\nerr = pci_request_regions(pdev, BDX_DRV_NAME);\r\nif (err)\r\ngoto err_dma;\r\npci_set_master(pdev);\r\npciaddr = pci_resource_start(pdev, 0);\r\nif (!pciaddr) {\r\nerr = -EIO;\r\npr_err("no MMIO resource\n");\r\ngoto err_out_res;\r\n}\r\nregionSize = pci_resource_len(pdev, 0);\r\nif (regionSize < BDX_REGS_SIZE) {\r\nerr = -EIO;\r\npr_err("MMIO resource (%x) too small\n", regionSize);\r\ngoto err_out_res;\r\n}\r\nnic->regs = ioremap(pciaddr, regionSize);\r\nif (!nic->regs) {\r\nerr = -EIO;\r\npr_err("ioremap failed\n");\r\ngoto err_out_res;\r\n}\r\nif (pdev->irq < 2) {\r\nerr = -EIO;\r\npr_err("invalid irq (%d)\n", pdev->irq);\r\ngoto err_out_iomap;\r\n}\r\npci_set_drvdata(pdev, nic);\r\nif (pdev->device == 0x3014)\r\nnic->port_num = 2;\r\nelse\r\nnic->port_num = 1;\r\nprint_hw_id(pdev);\r\nbdx_hw_reset_direct(nic->regs);\r\nnic->irq_type = IRQ_INTX;\r\n#ifdef BDX_MSI\r\nif ((readl(nic->regs + FPGA_VER) & 0xFFF) >= 378) {\r\nerr = pci_enable_msi(pdev);\r\nif (err)\r\npr_err("Can't eneble msi. error is %d\n", err);\r\nelse\r\nnic->irq_type = IRQ_MSI;\r\n} else\r\nDBG("HW does not support MSI\n");\r\n#endif\r\nfor (port = 0; port < nic->port_num; port++) {\r\nndev = alloc_etherdev(sizeof(struct bdx_priv));\r\nif (!ndev) {\r\nerr = -ENOMEM;\r\ngoto err_out_iomap;\r\n}\r\nndev->netdev_ops = &bdx_netdev_ops;\r\nndev->tx_queue_len = BDX_NDEV_TXQ_LEN;\r\nbdx_set_ethtool_ops(ndev);\r\nndev->if_port = port;\r\nndev->features = NETIF_F_IP_CSUM | NETIF_F_SG | NETIF_F_TSO\r\n| NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX |\r\nNETIF_F_HW_VLAN_CTAG_FILTER | NETIF_F_RXCSUM\r\n;\r\nndev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG |\r\nNETIF_F_TSO | NETIF_F_HW_VLAN_CTAG_TX;\r\nif (pci_using_dac)\r\nndev->features |= NETIF_F_HIGHDMA;\r\npriv = nic->priv[port] = netdev_priv(ndev);\r\npriv->pBdxRegs = nic->regs + port * 0x8000;\r\npriv->port = port;\r\npriv->pdev = pdev;\r\npriv->ndev = ndev;\r\npriv->nic = nic;\r\npriv->msg_enable = BDX_DEF_MSG_ENABLE;\r\nnetif_napi_add(ndev, &priv->napi, bdx_poll, 64);\r\nif ((readl(nic->regs + FPGA_VER) & 0xFFF) == 308) {\r\nDBG("HW statistics not supported\n");\r\npriv->stats_flag = 0;\r\n} else {\r\npriv->stats_flag = 1;\r\n}\r\npriv->txd_size = 2;\r\npriv->txf_size = 2;\r\npriv->rxd_size = 2;\r\npriv->rxf_size = 3;\r\npriv->rdintcm = INT_REG_VAL(0x20, 1, 4, 12);\r\npriv->tdintcm = INT_REG_VAL(0x20, 1, 0, 12);\r\n#ifdef BDX_LLTX\r\nndev->features |= NETIF_F_LLTX;\r\n#endif\r\nspin_lock_init(&priv->tx_lock);\r\nif (bdx_read_mac(priv)) {\r\npr_err("load MAC address failed\n");\r\ngoto err_out_iomap;\r\n}\r\nSET_NETDEV_DEV(ndev, &pdev->dev);\r\nerr = register_netdev(ndev);\r\nif (err) {\r\npr_err("register_netdev failed\n");\r\ngoto err_out_free;\r\n}\r\nnetif_carrier_off(ndev);\r\nnetif_stop_queue(ndev);\r\nprint_eth_id(ndev);\r\n}\r\nRET(0);\r\nerr_out_free:\r\nfree_netdev(ndev);\r\nerr_out_iomap:\r\niounmap(nic->regs);\r\nerr_out_res:\r\npci_release_regions(pdev);\r\nerr_dma:\r\npci_disable_device(pdev);\r\nerr_pci:\r\nvfree(nic);\r\nRET(err);\r\n}\r\nstatic int bdx_get_settings(struct net_device *netdev, struct ethtool_cmd *ecmd)\r\n{\r\nu32 rdintcm;\r\nu32 tdintcm;\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nrdintcm = priv->rdintcm;\r\ntdintcm = priv->tdintcm;\r\necmd->supported = (SUPPORTED_10000baseT_Full | SUPPORTED_FIBRE);\r\necmd->advertising = (ADVERTISED_10000baseT_Full | ADVERTISED_FIBRE);\r\nethtool_cmd_speed_set(ecmd, SPEED_10000);\r\necmd->duplex = DUPLEX_FULL;\r\necmd->port = PORT_FIBRE;\r\necmd->transceiver = XCVR_EXTERNAL;\r\necmd->autoneg = AUTONEG_DISABLE;\r\necmd->maxtxpkt =\r\n((GET_PCK_TH(tdintcm) * PCK_TH_MULT) / BDX_TXF_DESC_SZ);\r\necmd->maxrxpkt =\r\n((GET_PCK_TH(rdintcm) * PCK_TH_MULT) / sizeof(struct rxf_desc));\r\nreturn 0;\r\n}\r\nstatic void\r\nbdx_get_drvinfo(struct net_device *netdev, struct ethtool_drvinfo *drvinfo)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nstrlcpy(drvinfo->driver, BDX_DRV_NAME, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, BDX_DRV_VERSION, sizeof(drvinfo->version));\r\nstrlcpy(drvinfo->fw_version, "N/A", sizeof(drvinfo->fw_version));\r\nstrlcpy(drvinfo->bus_info, pci_name(priv->pdev),\r\nsizeof(drvinfo->bus_info));\r\n}\r\nstatic int\r\nbdx_get_coalesce(struct net_device *netdev, struct ethtool_coalesce *ecoal)\r\n{\r\nu32 rdintcm;\r\nu32 tdintcm;\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nrdintcm = priv->rdintcm;\r\ntdintcm = priv->tdintcm;\r\necoal->rx_coalesce_usecs = GET_INT_COAL(rdintcm) * INT_COAL_MULT;\r\necoal->rx_max_coalesced_frames =\r\n((GET_PCK_TH(rdintcm) * PCK_TH_MULT) / sizeof(struct rxf_desc));\r\necoal->tx_coalesce_usecs = GET_INT_COAL(tdintcm) * INT_COAL_MULT;\r\necoal->tx_max_coalesced_frames =\r\n((GET_PCK_TH(tdintcm) * PCK_TH_MULT) / BDX_TXF_DESC_SZ);\r\nreturn 0;\r\n}\r\nstatic int\r\nbdx_set_coalesce(struct net_device *netdev, struct ethtool_coalesce *ecoal)\r\n{\r\nu32 rdintcm;\r\nu32 tdintcm;\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nint rx_coal;\r\nint tx_coal;\r\nint rx_max_coal;\r\nint tx_max_coal;\r\nrx_coal = ecoal->rx_coalesce_usecs / INT_COAL_MULT;\r\ntx_coal = ecoal->tx_coalesce_usecs / INT_COAL_MULT;\r\nrx_max_coal = ecoal->rx_max_coalesced_frames;\r\ntx_max_coal = ecoal->tx_max_coalesced_frames;\r\nrx_max_coal =\r\n(((rx_max_coal * sizeof(struct rxf_desc)) + PCK_TH_MULT - 1)\r\n/ PCK_TH_MULT);\r\ntx_max_coal =\r\n(((tx_max_coal * BDX_TXF_DESC_SZ) + PCK_TH_MULT - 1)\r\n/ PCK_TH_MULT);\r\nif ((rx_coal > 0x7FFF) || (tx_coal > 0x7FFF) ||\r\n(rx_max_coal > 0xF) || (tx_max_coal > 0xF))\r\nreturn -EINVAL;\r\nrdintcm = INT_REG_VAL(rx_coal, GET_INT_COAL_RC(priv->rdintcm),\r\nGET_RXF_TH(priv->rdintcm), rx_max_coal);\r\ntdintcm = INT_REG_VAL(tx_coal, GET_INT_COAL_RC(priv->tdintcm), 0,\r\ntx_max_coal);\r\npriv->rdintcm = rdintcm;\r\npriv->tdintcm = tdintcm;\r\nWRITE_REG(priv, regRDINTCM0, rdintcm);\r\nWRITE_REG(priv, regTDINTCM0, tdintcm);\r\nreturn 0;\r\n}\r\nstatic inline int bdx_rx_fifo_size_to_packets(int rx_size)\r\n{\r\nreturn (FIFO_SIZE * (1 << rx_size)) / sizeof(struct rxf_desc);\r\n}\r\nstatic inline int bdx_tx_fifo_size_to_packets(int tx_size)\r\n{\r\nreturn (FIFO_SIZE * (1 << tx_size)) / BDX_TXF_DESC_SZ;\r\n}\r\nstatic void\r\nbdx_get_ringparam(struct net_device *netdev, struct ethtool_ringparam *ring)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nring->rx_max_pending = bdx_rx_fifo_size_to_packets(3);\r\nring->tx_max_pending = bdx_tx_fifo_size_to_packets(3);\r\nring->rx_pending = bdx_rx_fifo_size_to_packets(priv->rxf_size);\r\nring->tx_pending = bdx_tx_fifo_size_to_packets(priv->txd_size);\r\n}\r\nstatic int\r\nbdx_set_ringparam(struct net_device *netdev, struct ethtool_ringparam *ring)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nint rx_size = 0;\r\nint tx_size = 0;\r\nfor (; rx_size < 4; rx_size++) {\r\nif (bdx_rx_fifo_size_to_packets(rx_size) >= ring->rx_pending)\r\nbreak;\r\n}\r\nif (rx_size == 4)\r\nrx_size = 3;\r\nfor (; tx_size < 4; tx_size++) {\r\nif (bdx_tx_fifo_size_to_packets(tx_size) >= ring->tx_pending)\r\nbreak;\r\n}\r\nif (tx_size == 4)\r\ntx_size = 3;\r\nif ((rx_size == priv->rxf_size) &&\r\n(tx_size == priv->txd_size))\r\nreturn 0;\r\npriv->rxf_size = rx_size;\r\nif (rx_size > 1)\r\npriv->rxd_size = rx_size - 1;\r\nelse\r\npriv->rxd_size = rx_size;\r\npriv->txf_size = priv->txd_size = tx_size;\r\nif (netif_running(netdev)) {\r\nbdx_close(netdev);\r\nbdx_open(netdev);\r\n}\r\nreturn 0;\r\n}\r\nstatic void bdx_get_strings(struct net_device *netdev, u32 stringset, u8 *data)\r\n{\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nmemcpy(data, *bdx_stat_names, sizeof(bdx_stat_names));\r\nbreak;\r\n}\r\n}\r\nstatic int bdx_get_sset_count(struct net_device *netdev, int stringset)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nBDX_ASSERT(ARRAY_SIZE(bdx_stat_names)\r\n!= sizeof(struct bdx_stats) / sizeof(u64));\r\nreturn (priv->stats_flag) ? ARRAY_SIZE(bdx_stat_names) : 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic void bdx_get_ethtool_stats(struct net_device *netdev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct bdx_priv *priv = netdev_priv(netdev);\r\nif (priv->stats_flag) {\r\nbdx_update_stats(priv);\r\nmemcpy(data, &priv->hw_stats, sizeof(priv->hw_stats));\r\n}\r\n}\r\nstatic void bdx_set_ethtool_ops(struct net_device *netdev)\r\n{\r\nstatic const struct ethtool_ops bdx_ethtool_ops = {\r\n.get_settings = bdx_get_settings,\r\n.get_drvinfo = bdx_get_drvinfo,\r\n.get_link = ethtool_op_get_link,\r\n.get_coalesce = bdx_get_coalesce,\r\n.set_coalesce = bdx_set_coalesce,\r\n.get_ringparam = bdx_get_ringparam,\r\n.set_ringparam = bdx_set_ringparam,\r\n.get_strings = bdx_get_strings,\r\n.get_sset_count = bdx_get_sset_count,\r\n.get_ethtool_stats = bdx_get_ethtool_stats,\r\n};\r\nnetdev->ethtool_ops = &bdx_ethtool_ops;\r\n}\r\nstatic void bdx_remove(struct pci_dev *pdev)\r\n{\r\nstruct pci_nic *nic = pci_get_drvdata(pdev);\r\nstruct net_device *ndev;\r\nint port;\r\nfor (port = 0; port < nic->port_num; port++) {\r\nndev = nic->priv[port]->ndev;\r\nunregister_netdev(ndev);\r\nfree_netdev(ndev);\r\n}\r\n#ifdef BDX_MSI\r\nif (nic->irq_type == IRQ_MSI)\r\npci_disable_msi(pdev);\r\n#endif\r\niounmap(nic->regs);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\nvfree(nic);\r\nRET();\r\n}\r\nstatic void __init print_driver_id(void)\r\n{\r\npr_info("%s, %s\n", BDX_DRV_DESC, BDX_DRV_VERSION);\r\npr_info("Options: hw_csum %s\n", BDX_MSI_STRING);\r\n}\r\nstatic int __init bdx_module_init(void)\r\n{\r\nENTER;\r\ninit_txd_sizes();\r\nprint_driver_id();\r\nRET(pci_register_driver(&bdx_pci_driver));\r\n}\r\nstatic void __exit bdx_module_exit(void)\r\n{\r\nENTER;\r\npci_unregister_driver(&bdx_pci_driver);\r\nRET();\r\n}
