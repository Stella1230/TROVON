static struct cz_ps *cz_get_ps(struct amdgpu_ps *rps)\r\n{\r\nstruct cz_ps *ps = rps->ps_priv;\r\nreturn ps;\r\n}\r\nstatic struct cz_power_info *cz_get_pi(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = adev->pm.dpm.priv;\r\nreturn pi;\r\n}\r\nstatic uint16_t cz_convert_8bit_index_to_voltage(struct amdgpu_device *adev,\r\nuint16_t voltage)\r\n{\r\nuint16_t tmp = 6200 - voltage * 25;\r\nreturn tmp;\r\n}\r\nstatic void cz_construct_max_power_limits_table(struct amdgpu_device *adev,\r\nstruct amdgpu_clock_and_voltage_limits *table)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_clock_voltage_dependency_table *dep_table =\r\n&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\r\nif (dep_table->count > 0) {\r\ntable->sclk = dep_table->entries[dep_table->count - 1].clk;\r\ntable->vddc = cz_convert_8bit_index_to_voltage(adev,\r\ndep_table->entries[dep_table->count - 1].v);\r\n}\r\ntable->mclk = pi->sys_info.nbp_memory_clock[0];\r\n}\r\nstatic int cz_parse_sys_info_table(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_mode_info *mode_info = &adev->mode_info;\r\nint index = GetIndexIntoMasterTable(DATA, IntegratedSystemInfo);\r\nunion igp_info *igp_info;\r\nu8 frev, crev;\r\nu16 data_offset;\r\nint i = 0;\r\nif (amdgpu_atom_parse_data_header(mode_info->atom_context, index, NULL,\r\n&frev, &crev, &data_offset)) {\r\nigp_info = (union igp_info *)(mode_info->atom_context->bios +\r\ndata_offset);\r\nif (crev != 9) {\r\nDRM_ERROR("Unsupported IGP table: %d %d\n", frev, crev);\r\nreturn -EINVAL;\r\n}\r\npi->sys_info.bootup_sclk =\r\nle32_to_cpu(igp_info->info_9.ulBootUpEngineClock);\r\npi->sys_info.bootup_uma_clk =\r\nle32_to_cpu(igp_info->info_9.ulBootUpUMAClock);\r\npi->sys_info.dentist_vco_freq =\r\nle32_to_cpu(igp_info->info_9.ulDentistVCOFreq);\r\npi->sys_info.bootup_nb_voltage_index =\r\nle16_to_cpu(igp_info->info_9.usBootUpNBVoltage);\r\nif (igp_info->info_9.ucHtcTmpLmt == 0)\r\npi->sys_info.htc_tmp_lmt = 203;\r\nelse\r\npi->sys_info.htc_tmp_lmt = igp_info->info_9.ucHtcTmpLmt;\r\nif (igp_info->info_9.ucHtcHystLmt == 0)\r\npi->sys_info.htc_hyst_lmt = 5;\r\nelse\r\npi->sys_info.htc_hyst_lmt = igp_info->info_9.ucHtcHystLmt;\r\nif (pi->sys_info.htc_tmp_lmt <= pi->sys_info.htc_hyst_lmt) {\r\nDRM_ERROR("The htcTmpLmt should be larger than htcHystLmt.\n");\r\nreturn -EINVAL;\r\n}\r\nif (le32_to_cpu(igp_info->info_9.ulSystemConfig) & (1 << 3) &&\r\npi->enable_nb_ps_policy)\r\npi->sys_info.nb_dpm_enable = true;\r\nelse\r\npi->sys_info.nb_dpm_enable = false;\r\nfor (i = 0; i < CZ_NUM_NBPSTATES; i++) {\r\nif (i < CZ_NUM_NBPMEMORY_CLOCK)\r\npi->sys_info.nbp_memory_clock[i] =\r\nle32_to_cpu(igp_info->info_9.ulNbpStateMemclkFreq[i]);\r\npi->sys_info.nbp_n_clock[i] =\r\nle32_to_cpu(igp_info->info_9.ulNbpStateNClkFreq[i]);\r\n}\r\nfor (i = 0; i < CZ_MAX_DISPLAY_CLOCK_LEVEL; i++)\r\npi->sys_info.display_clock[i] =\r\nle32_to_cpu(igp_info->info_9.sDispClkVoltageMapping[i].ulMaximumSupportedCLK);\r\nfor (i = 0; i < CZ_NUM_NBPSTATES; i++)\r\npi->sys_info.nbp_voltage_index[i] =\r\nle32_to_cpu(igp_info->info_9.usNBPStateVoltage[i]);\r\nif (le32_to_cpu(igp_info->info_9.ulGPUCapInfo) &\r\nSYS_INFO_GPUCAPS__ENABEL_DFS_BYPASS)\r\npi->caps_enable_dfs_bypass = true;\r\npi->sys_info.uma_channel_number =\r\nigp_info->info_9.ucUMAChannelNumber;\r\ncz_construct_max_power_limits_table(adev,\r\n&adev->pm.dpm.dyn_state.max_clock_voltage_on_ac);\r\n}\r\nreturn 0;\r\n}\r\nstatic void cz_patch_voltage_values(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nstruct amdgpu_uvd_clock_voltage_dependency_table *uvd_table =\r\n&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\r\nstruct amdgpu_vce_clock_voltage_dependency_table *vce_table =\r\n&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nstruct amdgpu_clock_voltage_dependency_table *acp_table =\r\n&adev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table;\r\nif (uvd_table->count) {\r\nfor (i = 0; i < uvd_table->count; i++)\r\nuvd_table->entries[i].v =\r\ncz_convert_8bit_index_to_voltage(adev,\r\nuvd_table->entries[i].v);\r\n}\r\nif (vce_table->count) {\r\nfor (i = 0; i < vce_table->count; i++)\r\nvce_table->entries[i].v =\r\ncz_convert_8bit_index_to_voltage(adev,\r\nvce_table->entries[i].v);\r\n}\r\nif (acp_table->count) {\r\nfor (i = 0; i < acp_table->count; i++)\r\nacp_table->entries[i].v =\r\ncz_convert_8bit_index_to_voltage(adev,\r\nacp_table->entries[i].v);\r\n}\r\n}\r\nstatic void cz_construct_boot_state(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\npi->boot_pl.sclk = pi->sys_info.bootup_sclk;\r\npi->boot_pl.vddc_index = pi->sys_info.bootup_nb_voltage_index;\r\npi->boot_pl.ds_divider_index = 0;\r\npi->boot_pl.ss_divider_index = 0;\r\npi->boot_pl.allow_gnb_slow = 1;\r\npi->boot_pl.force_nbp_state = 0;\r\npi->boot_pl.display_wm = 0;\r\npi->boot_pl.vce_wm = 0;\r\n}\r\nstatic void cz_patch_boot_state(struct amdgpu_device *adev,\r\nstruct cz_ps *ps)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nps->num_levels = 1;\r\nps->levels[0] = pi->boot_pl;\r\n}\r\nstatic void cz_parse_pplib_clock_info(struct amdgpu_device *adev,\r\nstruct amdgpu_ps *rps, int index,\r\nunion pplib_clock_info *clock_info)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct cz_ps *ps = cz_get_ps(rps);\r\nstruct cz_pl *pl = &ps->levels[index];\r\nstruct amdgpu_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\r\npl->sclk = table->entries[clock_info->carrizo.index].clk;\r\npl->vddc_index = table->entries[clock_info->carrizo.index].v;\r\nps->num_levels = index + 1;\r\nif (pi->caps_sclk_ds) {\r\npl->ds_divider_index = 5;\r\npl->ss_divider_index = 5;\r\n}\r\n}\r\nstatic void cz_parse_pplib_non_clock_info(struct amdgpu_device *adev,\r\nstruct amdgpu_ps *rps,\r\nstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info,\r\nu8 table_rev)\r\n{\r\nstruct cz_ps *ps = cz_get_ps(rps);\r\nrps->caps = le32_to_cpu(non_clock_info->ulCapsAndSettings);\r\nrps->class = le16_to_cpu(non_clock_info->usClassification);\r\nrps->class2 = le16_to_cpu(non_clock_info->usClassification2);\r\nif (ATOM_PPLIB_NONCLOCKINFO_VER1 < table_rev) {\r\nrps->vclk = le32_to_cpu(non_clock_info->ulVCLK);\r\nrps->dclk = le32_to_cpu(non_clock_info->ulDCLK);\r\n} else {\r\nrps->vclk = 0;\r\nrps->dclk = 0;\r\n}\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT) {\r\nadev->pm.dpm.boot_ps = rps;\r\ncz_patch_boot_state(adev, ps);\r\n}\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_UVDSTATE)\r\nadev->pm.dpm.uvd_ps = rps;\r\n}\r\nstatic int cz_parse_power_table(struct amdgpu_device *adev)\r\n{\r\nstruct amdgpu_mode_info *mode_info = &adev->mode_info;\r\nstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info;\r\nunion pplib_power_state *power_state;\r\nint i, j, k, non_clock_array_index, clock_array_index;\r\nunion pplib_clock_info *clock_info;\r\nstruct _StateArray *state_array;\r\nstruct _ClockInfoArray *clock_info_array;\r\nstruct _NonClockInfoArray *non_clock_info_array;\r\nunion power_info *power_info;\r\nint index = GetIndexIntoMasterTable(DATA, PowerPlayInfo);\r\nu16 data_offset;\r\nu8 frev, crev;\r\nu8 *power_state_offset;\r\nstruct cz_ps *ps;\r\nif (!amdgpu_atom_parse_data_header(mode_info->atom_context, index, NULL,\r\n&frev, &crev, &data_offset))\r\nreturn -EINVAL;\r\npower_info = (union power_info *)(mode_info->atom_context->bios + data_offset);\r\nstate_array = (struct _StateArray *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usStateArrayOffset));\r\nclock_info_array = (struct _ClockInfoArray *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usClockInfoArrayOffset));\r\nnon_clock_info_array = (struct _NonClockInfoArray *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usNonClockInfoArrayOffset));\r\nadev->pm.dpm.ps = kzalloc(sizeof(struct amdgpu_ps) *\r\nstate_array->ucNumEntries, GFP_KERNEL);\r\nif (!adev->pm.dpm.ps)\r\nreturn -ENOMEM;\r\npower_state_offset = (u8 *)state_array->states;\r\nadev->pm.dpm.platform_caps =\r\nle32_to_cpu(power_info->pplib.ulPlatformCaps);\r\nadev->pm.dpm.backbias_response_time =\r\nle16_to_cpu(power_info->pplib.usBackbiasTime);\r\nadev->pm.dpm.voltage_response_time =\r\nle16_to_cpu(power_info->pplib.usVoltageTime);\r\nfor (i = 0; i < state_array->ucNumEntries; i++) {\r\npower_state = (union pplib_power_state *)power_state_offset;\r\nnon_clock_array_index = power_state->v2.nonClockInfoIndex;\r\nnon_clock_info = (struct _ATOM_PPLIB_NONCLOCK_INFO *)\r\n&non_clock_info_array->nonClockInfo[non_clock_array_index];\r\nps = kzalloc(sizeof(struct cz_ps), GFP_KERNEL);\r\nif (ps == NULL) {\r\nkfree(adev->pm.dpm.ps);\r\nreturn -ENOMEM;\r\n}\r\nadev->pm.dpm.ps[i].ps_priv = ps;\r\nk = 0;\r\nfor (j = 0; j < power_state->v2.ucNumDPMLevels; j++) {\r\nclock_array_index = power_state->v2.clockInfoIndex[j];\r\nif (clock_array_index >= clock_info_array->ucNumEntries)\r\ncontinue;\r\nif (k >= CZ_MAX_HARDWARE_POWERLEVELS)\r\nbreak;\r\nclock_info = (union pplib_clock_info *)\r\n&clock_info_array->clockInfo[clock_array_index *\r\nclock_info_array->ucEntrySize];\r\ncz_parse_pplib_clock_info(adev, &adev->pm.dpm.ps[i],\r\nk, clock_info);\r\nk++;\r\n}\r\ncz_parse_pplib_non_clock_info(adev, &adev->pm.dpm.ps[i],\r\nnon_clock_info,\r\nnon_clock_info_array->ucEntrySize);\r\npower_state_offset += 2 + power_state->v2.ucNumDPMLevels;\r\n}\r\nadev->pm.dpm.num_ps = state_array->ucNumEntries;\r\nreturn 0;\r\n}\r\nstatic int cz_process_firmware_header(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nu32 tmp;\r\nint ret;\r\nret = cz_read_smc_sram_dword(adev, SMU8_FIRMWARE_HEADER_LOCATION +\r\noffsetof(struct SMU8_Firmware_Header,\r\nDpmTable),\r\n&tmp, pi->sram_end);\r\nif (ret == 0)\r\npi->dpm_table_start = tmp;\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_init(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi;\r\nint ret, i;\r\npi = kzalloc(sizeof(struct cz_power_info), GFP_KERNEL);\r\nif (NULL == pi)\r\nreturn -ENOMEM;\r\nadev->pm.dpm.priv = pi;\r\nret = amdgpu_get_platform_caps(adev);\r\nif (ret)\r\nreturn ret;\r\nret = amdgpu_parse_extended_power_table(adev);\r\nif (ret)\r\nreturn ret;\r\npi->sram_end = SMC_RAM_END;\r\nfor (i = 0; i < CZ_MAX_HARDWARE_POWERLEVELS; i++)\r\npi->active_target[i] = CZ_AT_DFLT;\r\npi->mgcg_cgtt_local0 = 0x0;\r\npi->mgcg_cgtt_local1 = 0x0;\r\npi->clock_slow_down_step = 25000;\r\npi->skip_clock_slow_down = 1;\r\npi->enable_nb_ps_policy = 0;\r\npi->caps_power_containment = true;\r\npi->caps_cac = true;\r\npi->didt_enabled = false;\r\nif (pi->didt_enabled) {\r\npi->caps_sq_ramping = true;\r\npi->caps_db_ramping = true;\r\npi->caps_td_ramping = true;\r\npi->caps_tcp_ramping = true;\r\n}\r\npi->caps_sclk_ds = true;\r\npi->voting_clients = 0x00c00033;\r\npi->auto_thermal_throttling_enabled = true;\r\npi->bapm_enabled = false;\r\npi->disable_nb_ps3_in_battery = false;\r\npi->voltage_drop_threshold = 0;\r\npi->caps_sclk_throttle_low_notification = false;\r\npi->gfx_pg_threshold = 500;\r\npi->caps_fps = true;\r\npi->caps_uvd_pg = (adev->pg_flags & AMD_PG_SUPPORT_UVD) ? true : false;\r\npi->caps_uvd_dpm = true;\r\npi->caps_vce_pg = (adev->pg_flags & AMD_PG_SUPPORT_VCE) ? true : false;\r\npi->caps_vce_dpm = true;\r\npi->caps_acp_pg = (adev->pg_flags & AMD_PG_SUPPORT_ACP) ? true : false;\r\npi->caps_acp_dpm = true;\r\npi->caps_stable_power_state = false;\r\npi->nb_dpm_enabled_by_driver = true;\r\npi->nb_dpm_enabled = false;\r\npi->caps_voltage_island = false;\r\npi->need_pptable_upload = true;\r\nret = cz_parse_sys_info_table(adev);\r\nif (ret)\r\nreturn ret;\r\ncz_patch_voltage_values(adev);\r\ncz_construct_boot_state(adev);\r\nret = cz_parse_power_table(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_process_firmware_header(adev);\r\nif (ret)\r\nreturn ret;\r\npi->dpm_enabled = true;\r\npi->uvd_dynamic_pg = false;\r\nreturn 0;\r\n}\r\nstatic void cz_dpm_fini(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nfor (i = 0; i < adev->pm.dpm.num_ps; i++)\r\nkfree(adev->pm.dpm.ps[i].ps_priv);\r\nkfree(adev->pm.dpm.ps);\r\nkfree(adev->pm.dpm.priv);\r\namdgpu_free_extended_power_table(adev);\r\n}\r\nstatic void\r\ncz_dpm_debugfs_print_current_performance_level(struct amdgpu_device *adev,\r\nstruct seq_file *m)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\r\nstruct amdgpu_uvd_clock_voltage_dependency_table *uvd_table =\r\n&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\r\nstruct amdgpu_vce_clock_voltage_dependency_table *vce_table =\r\n&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nu32 sclk_index = REG_GET_FIELD(RREG32_SMC(ixTARGET_AND_CURRENT_PROFILE_INDEX),\r\nTARGET_AND_CURRENT_PROFILE_INDEX, CURR_SCLK_INDEX);\r\nu32 uvd_index = REG_GET_FIELD(RREG32_SMC(ixTARGET_AND_CURRENT_PROFILE_INDEX_2),\r\nTARGET_AND_CURRENT_PROFILE_INDEX_2, CURR_UVD_INDEX);\r\nu32 vce_index = REG_GET_FIELD(RREG32_SMC(ixTARGET_AND_CURRENT_PROFILE_INDEX_2),\r\nTARGET_AND_CURRENT_PROFILE_INDEX_2, CURR_VCE_INDEX);\r\nu32 sclk, vclk, dclk, ecclk, tmp;\r\nu16 vddnb, vddgfx;\r\nif (sclk_index >= NUM_SCLK_LEVELS) {\r\nseq_printf(m, "invalid sclk dpm profile %d\n", sclk_index);\r\n} else {\r\nsclk = table->entries[sclk_index].clk;\r\nseq_printf(m, "%u sclk: %u\n", sclk_index, sclk);\r\n}\r\ntmp = (RREG32_SMC(ixSMUSVI_NB_CURRENTVID) &\r\nCURRENT_NB_VID_MASK) >> CURRENT_NB_VID__SHIFT;\r\nvddnb = cz_convert_8bit_index_to_voltage(adev, (u16)tmp);\r\ntmp = (RREG32_SMC(ixSMUSVI_GFX_CURRENTVID) &\r\nCURRENT_GFX_VID_MASK) >> CURRENT_GFX_VID__SHIFT;\r\nvddgfx = cz_convert_8bit_index_to_voltage(adev, (u16)tmp);\r\nseq_printf(m, "vddnb: %u vddgfx: %u\n", vddnb, vddgfx);\r\nseq_printf(m, "uvd %sabled\n", pi->uvd_power_gated ? "dis" : "en");\r\nif (!pi->uvd_power_gated) {\r\nif (uvd_index >= CZ_MAX_HARDWARE_POWERLEVELS) {\r\nseq_printf(m, "invalid uvd dpm level %d\n", uvd_index);\r\n} else {\r\nvclk = uvd_table->entries[uvd_index].vclk;\r\ndclk = uvd_table->entries[uvd_index].dclk;\r\nseq_printf(m, "%u uvd vclk: %u dclk: %u\n", uvd_index, vclk, dclk);\r\n}\r\n}\r\nseq_printf(m, "vce %sabled\n", pi->vce_power_gated ? "dis" : "en");\r\nif (!pi->vce_power_gated) {\r\nif (vce_index >= CZ_MAX_HARDWARE_POWERLEVELS) {\r\nseq_printf(m, "invalid vce dpm level %d\n", vce_index);\r\n} else {\r\necclk = vce_table->entries[vce_index].ecclk;\r\nseq_printf(m, "%u vce ecclk: %u\n", vce_index, ecclk);\r\n}\r\n}\r\n}\r\nstatic void cz_dpm_print_power_state(struct amdgpu_device *adev,\r\nstruct amdgpu_ps *rps)\r\n{\r\nint i;\r\nstruct cz_ps *ps = cz_get_ps(rps);\r\namdgpu_dpm_print_class_info(rps->class, rps->class2);\r\namdgpu_dpm_print_cap_info(rps->caps);\r\nDRM_INFO("\tuvd vclk: %d dclk: %d\n", rps->vclk, rps->dclk);\r\nfor (i = 0; i < ps->num_levels; i++) {\r\nstruct cz_pl *pl = &ps->levels[i];\r\nDRM_INFO("\t\tpower level %d sclk: %u vddc: %u\n",\r\ni, pl->sclk,\r\ncz_convert_8bit_index_to_voltage(adev, pl->vddc_index));\r\n}\r\namdgpu_dpm_print_ps_status(adev, rps);\r\n}\r\nstatic int cz_dpm_early_init(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\ncz_dpm_set_funcs(adev);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_late_init(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nif (amdgpu_dpm) {\r\nint ret;\r\nret = amdgpu_pm_sysfs_init(adev);\r\nif (ret)\r\nreturn ret;\r\ncz_dpm_powergate_uvd(adev, true);\r\ncz_dpm_powergate_vce(adev, true);\r\n}\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_sw_init(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nint ret = 0;\r\nadev->pm.dpm.state = POWER_STATE_TYPE_BALANCED;\r\nadev->pm.dpm.user_state = POWER_STATE_TYPE_BALANCED;\r\nadev->pm.dpm.forced_level = AMDGPU_DPM_FORCED_LEVEL_AUTO;\r\nadev->pm.default_sclk = adev->clock.default_sclk;\r\nadev->pm.default_mclk = adev->clock.default_mclk;\r\nadev->pm.current_sclk = adev->clock.default_sclk;\r\nadev->pm.current_mclk = adev->clock.default_mclk;\r\nadev->pm.int_thermal_type = THERMAL_TYPE_NONE;\r\nif (amdgpu_dpm == 0)\r\nreturn 0;\r\nmutex_lock(&adev->pm.mutex);\r\nret = cz_dpm_init(adev);\r\nif (ret)\r\ngoto dpm_init_failed;\r\nadev->pm.dpm.current_ps = adev->pm.dpm.requested_ps = adev->pm.dpm.boot_ps;\r\nif (amdgpu_dpm == 1)\r\namdgpu_pm_print_power_states(adev);\r\nmutex_unlock(&adev->pm.mutex);\r\nDRM_INFO("amdgpu: dpm initialized\n");\r\nreturn 0;\r\ndpm_init_failed:\r\ncz_dpm_fini(adev);\r\nmutex_unlock(&adev->pm.mutex);\r\nDRM_ERROR("amdgpu: dpm initialization failed\n");\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_sw_fini(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nmutex_lock(&adev->pm.mutex);\r\namdgpu_pm_sysfs_fini(adev);\r\ncz_dpm_fini(adev);\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn 0;\r\n}\r\nstatic void cz_reset_ap_mask(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\npi->active_process_mask = 0;\r\n}\r\nstatic int cz_dpm_download_pptable_from_smu(struct amdgpu_device *adev,\r\nvoid **table)\r\n{\r\nint ret = 0;\r\nret = cz_smu_download_pptable(adev, table);\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_upload_pptable_to_smu(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct SMU8_Fusion_ClkTable *clock_table;\r\nstruct atom_clock_dividers dividers;\r\nvoid *table = NULL;\r\nuint8_t i = 0;\r\nint ret = 0;\r\nstruct amdgpu_clock_voltage_dependency_table *vddc_table =\r\n&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\r\nstruct amdgpu_clock_voltage_dependency_table *vddgfx_table =\r\n&adev->pm.dpm.dyn_state.vddgfx_dependency_on_sclk;\r\nstruct amdgpu_uvd_clock_voltage_dependency_table *uvd_table =\r\n&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\r\nstruct amdgpu_vce_clock_voltage_dependency_table *vce_table =\r\n&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nstruct amdgpu_clock_voltage_dependency_table *acp_table =\r\n&adev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table;\r\nif (!pi->need_pptable_upload)\r\nreturn 0;\r\nret = cz_dpm_download_pptable_from_smu(adev, &table);\r\nif (ret) {\r\nDRM_ERROR("amdgpu: Failed to get power play table from SMU!\n");\r\nreturn -EINVAL;\r\n}\r\nclock_table = (struct SMU8_Fusion_ClkTable *)table;\r\nif (vddc_table->count > CZ_MAX_HARDWARE_POWERLEVELS ||\r\nvddgfx_table->count > CZ_MAX_HARDWARE_POWERLEVELS ||\r\nuvd_table->count > CZ_MAX_HARDWARE_POWERLEVELS ||\r\nvce_table->count > CZ_MAX_HARDWARE_POWERLEVELS ||\r\nacp_table->count > CZ_MAX_HARDWARE_POWERLEVELS) {\r\nDRM_ERROR("amdgpu: Invalid Clock Voltage Dependency Table!\n");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < CZ_MAX_HARDWARE_POWERLEVELS; i++) {\r\nclock_table->SclkBreakdownTable.ClkLevel[i].GnbVid =\r\n(i < vddc_table->count) ? (uint8_t)vddc_table->entries[i].v : 0;\r\nclock_table->SclkBreakdownTable.ClkLevel[i].Frequency =\r\n(i < vddc_table->count) ? vddc_table->entries[i].clk : 0;\r\nret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\r\nclock_table->SclkBreakdownTable.ClkLevel[i].Frequency,\r\nfalse, &dividers);\r\nif (ret)\r\nreturn ret;\r\nclock_table->SclkBreakdownTable.ClkLevel[i].DfsDid =\r\n(uint8_t)dividers.post_divider;\r\nclock_table->SclkBreakdownTable.ClkLevel[i].GfxVid =\r\n(i < vddgfx_table->count) ? (uint8_t)vddgfx_table->entries[i].v : 0;\r\nclock_table->AclkBreakdownTable.ClkLevel[i].GfxVid =\r\n(i < acp_table->count) ? (uint8_t)acp_table->entries[i].v : 0;\r\nclock_table->AclkBreakdownTable.ClkLevel[i].Frequency =\r\n(i < acp_table->count) ? acp_table->entries[i].clk : 0;\r\nret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\r\nclock_table->SclkBreakdownTable.ClkLevel[i].Frequency,\r\nfalse, &dividers);\r\nif (ret)\r\nreturn ret;\r\nclock_table->AclkBreakdownTable.ClkLevel[i].DfsDid =\r\n(uint8_t)dividers.post_divider;\r\nclock_table->VclkBreakdownTable.ClkLevel[i].GfxVid =\r\n(i < uvd_table->count) ? (uint8_t)uvd_table->entries[i].v : 0;\r\nclock_table->VclkBreakdownTable.ClkLevel[i].Frequency =\r\n(i < uvd_table->count) ? uvd_table->entries[i].vclk : 0;\r\nret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\r\nclock_table->VclkBreakdownTable.ClkLevel[i].Frequency,\r\nfalse, &dividers);\r\nif (ret)\r\nreturn ret;\r\nclock_table->VclkBreakdownTable.ClkLevel[i].DfsDid =\r\n(uint8_t)dividers.post_divider;\r\nclock_table->DclkBreakdownTable.ClkLevel[i].GfxVid =\r\n(i < uvd_table->count) ? (uint8_t)uvd_table->entries[i].v : 0;\r\nclock_table->DclkBreakdownTable.ClkLevel[i].Frequency =\r\n(i < uvd_table->count) ? uvd_table->entries[i].dclk : 0;\r\nret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\r\nclock_table->DclkBreakdownTable.ClkLevel[i].Frequency,\r\nfalse, &dividers);\r\nif (ret)\r\nreturn ret;\r\nclock_table->DclkBreakdownTable.ClkLevel[i].DfsDid =\r\n(uint8_t)dividers.post_divider;\r\nclock_table->EclkBreakdownTable.ClkLevel[i].GfxVid =\r\n(i < vce_table->count) ? (uint8_t)vce_table->entries[i].v : 0;\r\nclock_table->EclkBreakdownTable.ClkLevel[i].Frequency =\r\n(i < vce_table->count) ? vce_table->entries[i].ecclk : 0;\r\nret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\r\nclock_table->EclkBreakdownTable.ClkLevel[i].Frequency,\r\nfalse, &dividers);\r\nif (ret)\r\nreturn ret;\r\nclock_table->EclkBreakdownTable.ClkLevel[i].DfsDid =\r\n(uint8_t)dividers.post_divider;\r\n}\r\nret = cz_smu_upload_pptable(adev);\r\nif (ret) {\r\nDRM_ERROR("amdgpu: Failed to put power play table to SMU!\n");\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void cz_init_sclk_limit(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\r\nuint32_t clock = 0, level;\r\nif (!table || !table->count) {\r\nDRM_ERROR("Invalid Voltage Dependency table.\n");\r\nreturn;\r\n}\r\npi->sclk_dpm.soft_min_clk = 0;\r\npi->sclk_dpm.hard_min_clk = 0;\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_GetMaxSclkLevel);\r\nlevel = cz_get_argument(adev);\r\nif (level < table->count)\r\nclock = table->entries[level].clk;\r\nelse {\r\nDRM_ERROR("Invalid SLCK Voltage Dependency table entry.\n");\r\nclock = table->entries[table->count - 1].clk;\r\n}\r\npi->sclk_dpm.soft_max_clk = clock;\r\npi->sclk_dpm.hard_max_clk = clock;\r\n}\r\nstatic void cz_init_uvd_limit(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_uvd_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\r\nuint32_t clock = 0, level;\r\nif (!table || !table->count) {\r\nDRM_ERROR("Invalid Voltage Dependency table.\n");\r\nreturn;\r\n}\r\npi->uvd_dpm.soft_min_clk = 0;\r\npi->uvd_dpm.hard_min_clk = 0;\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_GetMaxUvdLevel);\r\nlevel = cz_get_argument(adev);\r\nif (level < table->count)\r\nclock = table->entries[level].vclk;\r\nelse {\r\nDRM_ERROR("Invalid UVD Voltage Dependency table entry.\n");\r\nclock = table->entries[table->count - 1].vclk;\r\n}\r\npi->uvd_dpm.soft_max_clk = clock;\r\npi->uvd_dpm.hard_max_clk = clock;\r\n}\r\nstatic void cz_init_vce_limit(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_vce_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nuint32_t clock = 0, level;\r\nif (!table || !table->count) {\r\nDRM_ERROR("Invalid Voltage Dependency table.\n");\r\nreturn;\r\n}\r\npi->vce_dpm.soft_min_clk = table->entries[0].ecclk;\r\npi->vce_dpm.hard_min_clk = table->entries[0].ecclk;\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_GetMaxEclkLevel);\r\nlevel = cz_get_argument(adev);\r\nif (level < table->count)\r\nclock = table->entries[level].ecclk;\r\nelse {\r\nDRM_ERROR("Invalid VCE Voltage Dependency table entry.\n");\r\nclock = table->entries[table->count - 1].ecclk;\r\n}\r\npi->vce_dpm.soft_max_clk = clock;\r\npi->vce_dpm.hard_max_clk = clock;\r\n}\r\nstatic void cz_init_acp_limit(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table;\r\nuint32_t clock = 0, level;\r\nif (!table || !table->count) {\r\nDRM_ERROR("Invalid Voltage Dependency table.\n");\r\nreturn;\r\n}\r\npi->acp_dpm.soft_min_clk = 0;\r\npi->acp_dpm.hard_min_clk = 0;\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_GetMaxAclkLevel);\r\nlevel = cz_get_argument(adev);\r\nif (level < table->count)\r\nclock = table->entries[level].clk;\r\nelse {\r\nDRM_ERROR("Invalid ACP Voltage Dependency table entry.\n");\r\nclock = table->entries[table->count - 1].clk;\r\n}\r\npi->acp_dpm.soft_max_clk = clock;\r\npi->acp_dpm.hard_max_clk = clock;\r\n}\r\nstatic void cz_init_pg_state(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\npi->uvd_power_gated = false;\r\npi->vce_power_gated = false;\r\npi->acp_power_gated = false;\r\n}\r\nstatic void cz_init_sclk_threshold(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\npi->low_sclk_interrupt_threshold = 0;\r\n}\r\nstatic void cz_dpm_setup_asic(struct amdgpu_device *adev)\r\n{\r\ncz_reset_ap_mask(adev);\r\ncz_dpm_upload_pptable_to_smu(adev);\r\ncz_init_sclk_limit(adev);\r\ncz_init_uvd_limit(adev);\r\ncz_init_vce_limit(adev);\r\ncz_init_acp_limit(adev);\r\ncz_init_pg_state(adev);\r\ncz_init_sclk_threshold(adev);\r\n}\r\nstatic bool cz_check_smu_feature(struct amdgpu_device *adev,\r\nuint32_t feature)\r\n{\r\nuint32_t smu_feature = 0;\r\nint ret;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_GetFeatureStatus, 0);\r\nif (ret) {\r\nDRM_ERROR("Failed to get SMU features from SMC.\n");\r\nreturn false;\r\n} else {\r\nsmu_feature = cz_get_argument(adev);\r\nif (feature & smu_feature)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic bool cz_check_for_dpm_enabled(struct amdgpu_device *adev)\r\n{\r\nif (cz_check_smu_feature(adev,\r\nSMU_EnabledFeatureScoreboard_SclkDpmOn))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void cz_program_voting_clients(struct amdgpu_device *adev)\r\n{\r\nWREG32_SMC(ixCG_FREQ_TRAN_VOTING_0, PPCZ_VOTINGRIGHTSCLIENTS_DFLT0);\r\n}\r\nstatic void cz_clear_voting_clients(struct amdgpu_device *adev)\r\n{\r\nWREG32_SMC(ixCG_FREQ_TRAN_VOTING_0, 0);\r\n}\r\nstatic int cz_start_dpm(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nif (amdgpu_dpm) {\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_EnableAllSmuFeatures, SCLK_DPM_MASK);\r\nif (ret) {\r\nDRM_ERROR("SMU feature: SCLK_DPM enable failed\n");\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int cz_stop_dpm(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nif (amdgpu_dpm && adev->pm.dpm_enabled) {\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_DisableAllSmuFeatures, SCLK_DPM_MASK);\r\nif (ret) {\r\nDRM_ERROR("SMU feature: SCLK_DPM disable failed\n");\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic uint32_t cz_get_sclk_level(struct amdgpu_device *adev,\r\nuint32_t clock, uint16_t msg)\r\n{\r\nint i = 0;\r\nstruct amdgpu_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\r\nswitch (msg) {\r\ncase PPSMC_MSG_SetSclkSoftMin:\r\ncase PPSMC_MSG_SetSclkHardMin:\r\nfor (i = 0; i < table->count; i++)\r\nif (clock <= table->entries[i].clk)\r\nbreak;\r\nif (i == table->count)\r\ni = table->count - 1;\r\nbreak;\r\ncase PPSMC_MSG_SetSclkSoftMax:\r\ncase PPSMC_MSG_SetSclkHardMax:\r\nfor (i = table->count - 1; i >= 0; i--)\r\nif (clock >= table->entries[i].clk)\r\nbreak;\r\nif (i < 0)\r\ni = 0;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn i;\r\n}\r\nstatic uint32_t cz_get_eclk_level(struct amdgpu_device *adev,\r\nuint32_t clock, uint16_t msg)\r\n{\r\nint i = 0;\r\nstruct amdgpu_vce_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nif (table->count == 0)\r\nreturn 0;\r\nswitch (msg) {\r\ncase PPSMC_MSG_SetEclkSoftMin:\r\ncase PPSMC_MSG_SetEclkHardMin:\r\nfor (i = 0; i < table->count-1; i++)\r\nif (clock <= table->entries[i].ecclk)\r\nbreak;\r\nbreak;\r\ncase PPSMC_MSG_SetEclkSoftMax:\r\ncase PPSMC_MSG_SetEclkHardMax:\r\nfor (i = table->count - 1; i > 0; i--)\r\nif (clock >= table->entries[i].ecclk)\r\nbreak;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn i;\r\n}\r\nstatic uint32_t cz_get_uvd_level(struct amdgpu_device *adev,\r\nuint32_t clock, uint16_t msg)\r\n{\r\nint i = 0;\r\nstruct amdgpu_uvd_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\r\nswitch (msg) {\r\ncase PPSMC_MSG_SetUvdSoftMin:\r\ncase PPSMC_MSG_SetUvdHardMin:\r\nfor (i = 0; i < table->count; i++)\r\nif (clock <= table->entries[i].vclk)\r\nbreak;\r\nif (i == table->count)\r\ni = table->count - 1;\r\nbreak;\r\ncase PPSMC_MSG_SetUvdSoftMax:\r\ncase PPSMC_MSG_SetUvdHardMax:\r\nfor (i = table->count - 1; i >= 0; i--)\r\nif (clock >= table->entries[i].vclk)\r\nbreak;\r\nif (i < 0)\r\ni = 0;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn i;\r\n}\r\nstatic int cz_program_bootup_state(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nuint32_t soft_min_clk = 0;\r\nuint32_t soft_max_clk = 0;\r\nint ret = 0;\r\npi->sclk_dpm.soft_min_clk = pi->sys_info.bootup_sclk;\r\npi->sclk_dpm.soft_max_clk = pi->sys_info.bootup_sclk;\r\nsoft_min_clk = cz_get_sclk_level(adev,\r\npi->sclk_dpm.soft_min_clk,\r\nPPSMC_MSG_SetSclkSoftMin);\r\nsoft_max_clk = cz_get_sclk_level(adev,\r\npi->sclk_dpm.soft_max_clk,\r\nPPSMC_MSG_SetSclkSoftMax);\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMin, soft_min_clk);\r\nif (ret)\r\nreturn -EINVAL;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMax, soft_max_clk);\r\nif (ret)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int cz_disable_cgpg(struct amdgpu_device *adev)\r\n{\r\nreturn 0;\r\n}\r\nstatic int cz_enable_cgpg(struct amdgpu_device *adev)\r\n{\r\nreturn 0;\r\n}\r\nstatic int cz_program_pt_config_registers(struct amdgpu_device *adev)\r\n{\r\nreturn 0;\r\n}\r\nstatic void cz_do_enable_didt(struct amdgpu_device *adev, bool enable)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nuint32_t reg = 0;\r\nif (pi->caps_sq_ramping) {\r\nreg = RREG32_DIDT(ixDIDT_SQ_CTRL0);\r\nif (enable)\r\nreg = REG_SET_FIELD(reg, DIDT_SQ_CTRL0, DIDT_CTRL_EN, 1);\r\nelse\r\nreg = REG_SET_FIELD(reg, DIDT_SQ_CTRL0, DIDT_CTRL_EN, 0);\r\nWREG32_DIDT(ixDIDT_SQ_CTRL0, reg);\r\n}\r\nif (pi->caps_db_ramping) {\r\nreg = RREG32_DIDT(ixDIDT_DB_CTRL0);\r\nif (enable)\r\nreg = REG_SET_FIELD(reg, DIDT_DB_CTRL0, DIDT_CTRL_EN, 1);\r\nelse\r\nreg = REG_SET_FIELD(reg, DIDT_DB_CTRL0, DIDT_CTRL_EN, 0);\r\nWREG32_DIDT(ixDIDT_DB_CTRL0, reg);\r\n}\r\nif (pi->caps_td_ramping) {\r\nreg = RREG32_DIDT(ixDIDT_TD_CTRL0);\r\nif (enable)\r\nreg = REG_SET_FIELD(reg, DIDT_TD_CTRL0, DIDT_CTRL_EN, 1);\r\nelse\r\nreg = REG_SET_FIELD(reg, DIDT_TD_CTRL0, DIDT_CTRL_EN, 0);\r\nWREG32_DIDT(ixDIDT_TD_CTRL0, reg);\r\n}\r\nif (pi->caps_tcp_ramping) {\r\nreg = RREG32_DIDT(ixDIDT_TCP_CTRL0);\r\nif (enable)\r\nreg = REG_SET_FIELD(reg, DIDT_SQ_CTRL0, DIDT_CTRL_EN, 1);\r\nelse\r\nreg = REG_SET_FIELD(reg, DIDT_SQ_CTRL0, DIDT_CTRL_EN, 0);\r\nWREG32_DIDT(ixDIDT_TCP_CTRL0, reg);\r\n}\r\n}\r\nstatic int cz_enable_didt(struct amdgpu_device *adev, bool enable)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret;\r\nif (pi->caps_sq_ramping || pi->caps_db_ramping ||\r\npi->caps_td_ramping || pi->caps_tcp_ramping) {\r\nif (adev->gfx.gfx_current_status != AMDGPU_GFX_SAFE_MODE) {\r\nret = cz_disable_cgpg(adev);\r\nif (ret) {\r\nDRM_ERROR("Pre Di/Dt disable cg/pg failed\n");\r\nreturn -EINVAL;\r\n}\r\nadev->gfx.gfx_current_status = AMDGPU_GFX_SAFE_MODE;\r\n}\r\nret = cz_program_pt_config_registers(adev);\r\nif (ret) {\r\nDRM_ERROR("Di/Dt config failed\n");\r\nreturn -EINVAL;\r\n}\r\ncz_do_enable_didt(adev, enable);\r\nif (adev->gfx.gfx_current_status == AMDGPU_GFX_SAFE_MODE) {\r\nret = cz_enable_cgpg(adev);\r\nif (ret) {\r\nDRM_ERROR("Post Di/Dt enable cg/pg failed\n");\r\nreturn -EINVAL;\r\n}\r\nadev->gfx.gfx_current_status = AMDGPU_GFX_NORMAL_MODE;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void cz_reset_acp_boot_level(struct amdgpu_device *adev)\r\n{\r\n}\r\nstatic void cz_update_current_ps(struct amdgpu_device *adev,\r\nstruct amdgpu_ps *rps)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct cz_ps *ps = cz_get_ps(rps);\r\npi->current_ps = *ps;\r\npi->current_rps = *rps;\r\npi->current_rps.ps_priv = ps;\r\n}\r\nstatic void cz_update_requested_ps(struct amdgpu_device *adev,\r\nstruct amdgpu_ps *rps)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct cz_ps *ps = cz_get_ps(rps);\r\npi->requested_ps = *ps;\r\npi->requested_rps = *rps;\r\npi->requested_rps.ps_priv = ps;\r\n}\r\nstatic void cz_apply_state_adjust_rules(struct amdgpu_device *adev,\r\nstruct amdgpu_ps *new_rps,\r\nstruct amdgpu_ps *old_rps)\r\n{\r\nstruct cz_ps *ps = cz_get_ps(new_rps);\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_clock_and_voltage_limits *limits =\r\n&adev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\r\nuint32_t mclk = 0;\r\nps->force_high = false;\r\nps->need_dfs_bypass = true;\r\npi->video_start = new_rps->dclk || new_rps->vclk ||\r\nnew_rps->evclk || new_rps->ecclk;\r\nif ((new_rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) ==\r\nATOM_PPLIB_CLASSIFICATION_UI_BATTERY)\r\npi->battery_state = true;\r\nelse\r\npi->battery_state = false;\r\nif (pi->caps_stable_power_state)\r\nmclk = limits->mclk;\r\nif (mclk > pi->sys_info.nbp_memory_clock[CZ_NUM_NBPMEMORY_CLOCK - 1])\r\nps->force_high = true;\r\n}\r\nstatic int cz_dpm_enable(struct amdgpu_device *adev)\r\n{\r\nconst char *chip_name;\r\nint ret = 0;\r\nif (cz_check_for_dpm_enabled(adev))\r\nreturn -EINVAL;\r\ncz_program_voting_clients(adev);\r\nswitch (adev->asic_type) {\r\ncase CHIP_CARRIZO:\r\nchip_name = "carrizo";\r\nbreak;\r\ncase CHIP_STONEY:\r\nchip_name = "stoney";\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nret = cz_start_dpm(adev);\r\nif (ret) {\r\nDRM_ERROR("%s DPM enable failed\n", chip_name);\r\nreturn -EINVAL;\r\n}\r\nret = cz_program_bootup_state(adev);\r\nif (ret) {\r\nDRM_ERROR("%s bootup state program failed\n", chip_name);\r\nreturn -EINVAL;\r\n}\r\nret = cz_enable_didt(adev, true);\r\nif (ret) {\r\nDRM_ERROR("%s enable di/dt failed\n", chip_name);\r\nreturn -EINVAL;\r\n}\r\ncz_reset_acp_boot_level(adev);\r\ncz_update_current_ps(adev, adev->pm.dpm.boot_ps);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_hw_init(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nint ret = 0;\r\nmutex_lock(&adev->pm.mutex);\r\nret = cz_smu_init(adev);\r\nif (ret) {\r\nDRM_ERROR("amdgpu: smc initialization failed\n");\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn ret;\r\n}\r\nret = cz_smu_start(adev);\r\nif (ret) {\r\nDRM_ERROR("amdgpu: smc start failed\n");\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn ret;\r\n}\r\nif (!amdgpu_dpm) {\r\nadev->pm.dpm_enabled = false;\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn ret;\r\n}\r\ncz_dpm_setup_asic(adev);\r\nret = cz_dpm_enable(adev);\r\nif (ret)\r\nadev->pm.dpm_enabled = false;\r\nelse\r\nadev->pm.dpm_enabled = true;\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_disable(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nif (!cz_check_for_dpm_enabled(adev))\r\nreturn -EINVAL;\r\nret = cz_enable_didt(adev, false);\r\nif (ret) {\r\nDRM_ERROR("disable di/dt failed\n");\r\nreturn -EINVAL;\r\n}\r\ncz_dpm_powergate_uvd(adev, false);\r\ncz_dpm_powergate_vce(adev, false);\r\ncz_clear_voting_clients(adev);\r\ncz_stop_dpm(adev);\r\ncz_update_current_ps(adev, adev->pm.dpm.boot_ps);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_hw_fini(void *handle)\r\n{\r\nint ret = 0;\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nmutex_lock(&adev->pm.mutex);\r\ncz_smu_fini(adev);\r\nif (adev->pm.dpm_enabled) {\r\nret = cz_dpm_disable(adev);\r\nadev->pm.dpm.current_ps =\r\nadev->pm.dpm.requested_ps =\r\nadev->pm.dpm.boot_ps;\r\n}\r\nadev->pm.dpm_enabled = false;\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_suspend(void *handle)\r\n{\r\nint ret = 0;\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nif (adev->pm.dpm_enabled) {\r\nmutex_lock(&adev->pm.mutex);\r\nret = cz_dpm_disable(adev);\r\nadev->pm.dpm.current_ps =\r\nadev->pm.dpm.requested_ps =\r\nadev->pm.dpm.boot_ps;\r\nmutex_unlock(&adev->pm.mutex);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_resume(void *handle)\r\n{\r\nint ret = 0;\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nmutex_lock(&adev->pm.mutex);\r\nret = cz_smu_start(adev);\r\nif (ret) {\r\nDRM_ERROR("amdgpu: smc start failed\n");\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn ret;\r\n}\r\nif (!amdgpu_dpm) {\r\nadev->pm.dpm_enabled = false;\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn ret;\r\n}\r\ncz_dpm_setup_asic(adev);\r\nret = cz_dpm_enable(adev);\r\nif (ret)\r\nadev->pm.dpm_enabled = false;\r\nelse\r\nadev->pm.dpm_enabled = true;\r\nmutex_unlock(&adev->pm.mutex);\r\nif (adev->pm.dpm_enabled)\r\namdgpu_pm_compute_clocks(adev);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_set_clockgating_state(void *handle,\r\nenum amd_clockgating_state state)\r\n{\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_set_powergating_state(void *handle,\r\nenum amd_powergating_state state)\r\n{\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_get_temperature(struct amdgpu_device *adev)\r\n{\r\nint actual_temp = 0;\r\nuint32_t temp = RREG32_SMC(0xC0300E0C);\r\nif (temp)\r\nactual_temp = 1000 * ((temp / 8) - 49);\r\nreturn actual_temp;\r\n}\r\nstatic int cz_dpm_pre_set_power_state(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_ps requested_ps = *adev->pm.dpm.requested_ps;\r\nstruct amdgpu_ps *new_ps = &requested_ps;\r\ncz_update_requested_ps(adev, new_ps);\r\ncz_apply_state_adjust_rules(adev, &pi->requested_rps,\r\n&pi->current_rps);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_update_sclk_limit(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_clock_and_voltage_limits *limits =\r\n&adev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\r\nuint32_t clock, stable_ps_clock = 0;\r\nclock = pi->sclk_dpm.soft_min_clk;\r\nif (pi->caps_stable_power_state) {\r\nstable_ps_clock = limits->sclk * 75 / 100;\r\nif (clock < stable_ps_clock)\r\nclock = stable_ps_clock;\r\n}\r\nif (clock != pi->sclk_dpm.soft_min_clk) {\r\npi->sclk_dpm.soft_min_clk = clock;\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMin,\r\ncz_get_sclk_level(adev, clock,\r\nPPSMC_MSG_SetSclkSoftMin));\r\n}\r\nif (pi->caps_stable_power_state &&\r\npi->sclk_dpm.soft_max_clk != clock) {\r\npi->sclk_dpm.soft_max_clk = clock;\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMax,\r\ncz_get_sclk_level(adev, clock,\r\nPPSMC_MSG_SetSclkSoftMax));\r\n} else {\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMax,\r\ncz_get_sclk_level(adev,\r\npi->sclk_dpm.soft_max_clk,\r\nPPSMC_MSG_SetSclkSoftMax));\r\n}\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_set_deep_sleep_sclk_threshold(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nif (pi->caps_sclk_ds) {\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetMinDeepSleepSclk,\r\nCZ_MIN_DEEP_SLEEP_SCLK);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_set_watermark_threshold(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetWatermarkFrequency,\r\npi->sclk_dpm.soft_max_clk);\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_enable_nbdpm(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nif (pi->nb_dpm_enabled_by_driver && !pi->nb_dpm_enabled) {\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_EnableAllSmuFeatures,\r\nNB_DPM_MASK);\r\nif (ret) {\r\nDRM_ERROR("amdgpu: nb dpm enable failed\n");\r\nreturn ret;\r\n}\r\npi->nb_dpm_enabled = true;\r\n}\r\nreturn ret;\r\n}\r\nstatic void cz_dpm_nbdpm_lm_pstate_enable(struct amdgpu_device *adev,\r\nbool enable)\r\n{\r\nif (enable)\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_EnableLowMemoryPstate);\r\nelse\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_DisableLowMemoryPstate);\r\n}\r\nstatic int cz_dpm_update_low_memory_pstate(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct cz_ps *ps = &pi->requested_ps;\r\nif (pi->sys_info.nb_dpm_enable) {\r\nif (ps->force_high)\r\ncz_dpm_nbdpm_lm_pstate_enable(adev, false);\r\nelse\r\ncz_dpm_nbdpm_lm_pstate_enable(adev, true);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_set_power_state(struct amdgpu_device *adev)\r\n{\r\nint ret = 0;\r\ncz_dpm_update_sclk_limit(adev);\r\ncz_dpm_set_deep_sleep_sclk_threshold(adev);\r\ncz_dpm_set_watermark_threshold(adev);\r\ncz_dpm_enable_nbdpm(adev);\r\ncz_dpm_update_low_memory_pstate(adev);\r\nreturn ret;\r\n}\r\nstatic void cz_dpm_post_set_power_state(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_ps *ps = &pi->requested_rps;\r\ncz_update_current_ps(adev, ps);\r\n}\r\nstatic int cz_dpm_force_highest(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (pi->sclk_dpm.soft_min_clk != pi->sclk_dpm.soft_max_clk) {\r\npi->sclk_dpm.soft_min_clk =\r\npi->sclk_dpm.soft_max_clk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMin,\r\ncz_get_sclk_level(adev,\r\npi->sclk_dpm.soft_min_clk,\r\nPPSMC_MSG_SetSclkSoftMin));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_force_lowest(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (pi->sclk_dpm.soft_max_clk != pi->sclk_dpm.soft_min_clk) {\r\npi->sclk_dpm.soft_max_clk = pi->sclk_dpm.soft_min_clk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMax,\r\ncz_get_sclk_level(adev,\r\npi->sclk_dpm.soft_max_clk,\r\nPPSMC_MSG_SetSclkSoftMax));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic uint32_t cz_dpm_get_max_sclk_level(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nif (!pi->max_sclk_level) {\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_GetMaxSclkLevel);\r\npi->max_sclk_level = cz_get_argument(adev) + 1;\r\n}\r\nif (pi->max_sclk_level > CZ_MAX_HARDWARE_POWERLEVELS) {\r\nDRM_ERROR("Invalid max sclk level!\n");\r\nreturn -EINVAL;\r\n}\r\nreturn pi->max_sclk_level;\r\n}\r\nstatic int cz_dpm_unforce_dpm_levels(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_clock_voltage_dependency_table *dep_table =\r\n&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\r\nuint32_t level = 0;\r\nint ret = 0;\r\npi->sclk_dpm.soft_min_clk = dep_table->entries[0].clk;\r\nlevel = cz_dpm_get_max_sclk_level(adev) - 1;\r\nif (level < dep_table->count)\r\npi->sclk_dpm.soft_max_clk = dep_table->entries[level].clk;\r\nelse\r\npi->sclk_dpm.soft_max_clk =\r\ndep_table->entries[dep_table->count - 1].clk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMin,\r\ncz_get_sclk_level(adev,\r\npi->sclk_dpm.soft_min_clk,\r\nPPSMC_MSG_SetSclkSoftMin));\r\nif (ret)\r\nreturn ret;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetSclkSoftMax,\r\ncz_get_sclk_level(adev,\r\npi->sclk_dpm.soft_max_clk,\r\nPPSMC_MSG_SetSclkSoftMax));\r\nif (ret)\r\nreturn ret;\r\nDRM_DEBUG("DPM unforce state min=%d, max=%d.\n",\r\npi->sclk_dpm.soft_min_clk,\r\npi->sclk_dpm.soft_max_clk);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_uvd_force_highest(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (pi->uvd_dpm.soft_min_clk != pi->uvd_dpm.soft_max_clk) {\r\npi->uvd_dpm.soft_min_clk =\r\npi->uvd_dpm.soft_max_clk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetUvdSoftMin,\r\ncz_get_uvd_level(adev,\r\npi->uvd_dpm.soft_min_clk,\r\nPPSMC_MSG_SetUvdSoftMin));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_uvd_force_lowest(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (pi->uvd_dpm.soft_max_clk != pi->uvd_dpm.soft_min_clk) {\r\npi->uvd_dpm.soft_max_clk = pi->uvd_dpm.soft_min_clk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetUvdSoftMax,\r\ncz_get_uvd_level(adev,\r\npi->uvd_dpm.soft_max_clk,\r\nPPSMC_MSG_SetUvdSoftMax));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic uint32_t cz_dpm_get_max_uvd_level(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nif (!pi->max_uvd_level) {\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_GetMaxUvdLevel);\r\npi->max_uvd_level = cz_get_argument(adev) + 1;\r\n}\r\nif (pi->max_uvd_level > CZ_MAX_HARDWARE_POWERLEVELS) {\r\nDRM_ERROR("Invalid max uvd level!\n");\r\nreturn -EINVAL;\r\n}\r\nreturn pi->max_uvd_level;\r\n}\r\nstatic int cz_dpm_unforce_uvd_dpm_levels(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_uvd_clock_voltage_dependency_table *dep_table =\r\n&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\r\nuint32_t level = 0;\r\nint ret = 0;\r\npi->uvd_dpm.soft_min_clk = dep_table->entries[0].vclk;\r\nlevel = cz_dpm_get_max_uvd_level(adev) - 1;\r\nif (level < dep_table->count)\r\npi->uvd_dpm.soft_max_clk = dep_table->entries[level].vclk;\r\nelse\r\npi->uvd_dpm.soft_max_clk =\r\ndep_table->entries[dep_table->count - 1].vclk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetUvdSoftMin,\r\ncz_get_uvd_level(adev,\r\npi->uvd_dpm.soft_min_clk,\r\nPPSMC_MSG_SetUvdSoftMin));\r\nif (ret)\r\nreturn ret;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetUvdSoftMax,\r\ncz_get_uvd_level(adev,\r\npi->uvd_dpm.soft_max_clk,\r\nPPSMC_MSG_SetUvdSoftMax));\r\nif (ret)\r\nreturn ret;\r\nDRM_DEBUG("DPM uvd unforce state min=%d, max=%d.\n",\r\npi->uvd_dpm.soft_min_clk,\r\npi->uvd_dpm.soft_max_clk);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_vce_force_highest(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (pi->vce_dpm.soft_min_clk != pi->vce_dpm.soft_max_clk) {\r\npi->vce_dpm.soft_min_clk =\r\npi->vce_dpm.soft_max_clk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetEclkSoftMin,\r\ncz_get_eclk_level(adev,\r\npi->vce_dpm.soft_min_clk,\r\nPPSMC_MSG_SetEclkSoftMin));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_dpm_vce_force_lowest(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (pi->vce_dpm.soft_max_clk != pi->vce_dpm.soft_min_clk) {\r\npi->vce_dpm.soft_max_clk = pi->vce_dpm.soft_min_clk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetEclkSoftMax,\r\ncz_get_uvd_level(adev,\r\npi->vce_dpm.soft_max_clk,\r\nPPSMC_MSG_SetEclkSoftMax));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic uint32_t cz_dpm_get_max_vce_level(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nif (!pi->max_vce_level) {\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_GetMaxEclkLevel);\r\npi->max_vce_level = cz_get_argument(adev) + 1;\r\n}\r\nif (pi->max_vce_level > CZ_MAX_HARDWARE_POWERLEVELS) {\r\nDRM_ERROR("Invalid max vce level!\n");\r\nreturn -EINVAL;\r\n}\r\nreturn pi->max_vce_level;\r\n}\r\nstatic int cz_dpm_unforce_vce_dpm_levels(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_vce_clock_voltage_dependency_table *dep_table =\r\n&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nuint32_t level = 0;\r\nint ret = 0;\r\npi->vce_dpm.soft_min_clk = dep_table->entries[0].ecclk;\r\nlevel = cz_dpm_get_max_vce_level(adev) - 1;\r\nif (level < dep_table->count)\r\npi->vce_dpm.soft_max_clk = dep_table->entries[level].ecclk;\r\nelse\r\npi->vce_dpm.soft_max_clk =\r\ndep_table->entries[dep_table->count - 1].ecclk;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetEclkSoftMin,\r\ncz_get_eclk_level(adev,\r\npi->vce_dpm.soft_min_clk,\r\nPPSMC_MSG_SetEclkSoftMin));\r\nif (ret)\r\nreturn ret;\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetEclkSoftMax,\r\ncz_get_eclk_level(adev,\r\npi->vce_dpm.soft_max_clk,\r\nPPSMC_MSG_SetEclkSoftMax));\r\nif (ret)\r\nreturn ret;\r\nDRM_DEBUG("DPM vce unforce state min=%d, max=%d.\n",\r\npi->vce_dpm.soft_min_clk,\r\npi->vce_dpm.soft_max_clk);\r\nreturn 0;\r\n}\r\nstatic int cz_dpm_force_dpm_level(struct amdgpu_device *adev,\r\nenum amdgpu_dpm_forced_level level)\r\n{\r\nint ret = 0;\r\nswitch (level) {\r\ncase AMDGPU_DPM_FORCED_LEVEL_HIGH:\r\nret = cz_dpm_unforce_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_force_highest(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_unforce_uvd_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_uvd_force_highest(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_unforce_vce_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_vce_force_highest(adev);\r\nif (ret)\r\nreturn ret;\r\nbreak;\r\ncase AMDGPU_DPM_FORCED_LEVEL_LOW:\r\nret = cz_dpm_unforce_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_force_lowest(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_unforce_uvd_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_uvd_force_lowest(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_unforce_vce_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_vce_force_lowest(adev);\r\nif (ret)\r\nreturn ret;\r\nbreak;\r\ncase AMDGPU_DPM_FORCED_LEVEL_AUTO:\r\nret = cz_dpm_unforce_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_unforce_uvd_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nret = cz_dpm_unforce_vce_dpm_levels(adev);\r\nif (ret)\r\nreturn ret;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nadev->pm.dpm.forced_level = level;\r\nreturn ret;\r\n}\r\nstatic void cz_dpm_display_configuration_changed(struct amdgpu_device *adev)\r\n{\r\n}\r\nstatic uint32_t cz_dpm_get_sclk(struct amdgpu_device *adev, bool low)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct cz_ps *requested_state = cz_get_ps(&pi->requested_rps);\r\nif (low)\r\nreturn requested_state->levels[0].sclk;\r\nelse\r\nreturn requested_state->levels[requested_state->num_levels - 1].sclk;\r\n}\r\nstatic uint32_t cz_dpm_get_mclk(struct amdgpu_device *adev, bool low)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nreturn pi->sys_info.bootup_uma_clk;\r\n}\r\nstatic int cz_enable_uvd_dpm(struct amdgpu_device *adev, bool enable)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (enable && pi->caps_uvd_dpm ) {\r\npi->dpm_flags |= DPMFlags_UVD_Enabled;\r\nDRM_DEBUG("UVD DPM Enabled.\n");\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_EnableAllSmuFeatures, UVD_DPM_MASK);\r\n} else {\r\npi->dpm_flags &= ~DPMFlags_UVD_Enabled;\r\nDRM_DEBUG("UVD DPM Stopped\n");\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_DisableAllSmuFeatures, UVD_DPM_MASK);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_update_uvd_dpm(struct amdgpu_device *adev, bool gate)\r\n{\r\nreturn cz_enable_uvd_dpm(adev, !gate);\r\n}\r\nstatic void cz_dpm_powergate_uvd(struct amdgpu_device *adev, bool gate)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret;\r\nif (pi->uvd_power_gated == gate)\r\nreturn;\r\npi->uvd_power_gated = gate;\r\nif (gate) {\r\nif (pi->caps_uvd_pg) {\r\nret = amdgpu_set_clockgating_state(adev, AMD_IP_BLOCK_TYPE_UVD,\r\nAMD_CG_STATE_UNGATE);\r\nret = amdgpu_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_UVD,\r\nAMD_PG_STATE_GATE);\r\n}\r\ncz_update_uvd_dpm(adev, gate);\r\nif (pi->caps_uvd_pg)\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_UVDPowerOFF);\r\n} else {\r\nif (pi->caps_uvd_pg) {\r\nif (pi->uvd_dynamic_pg)\r\ncz_send_msg_to_smc_with_parameter(adev, PPSMC_MSG_UVDPowerON, 1);\r\nelse\r\ncz_send_msg_to_smc_with_parameter(adev, PPSMC_MSG_UVDPowerON, 0);\r\nret = amdgpu_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_UVD,\r\nAMD_PG_STATE_UNGATE);\r\nret = amdgpu_set_clockgating_state(adev, AMD_IP_BLOCK_TYPE_UVD,\r\nAMD_CG_STATE_GATE);\r\n}\r\ncz_update_uvd_dpm(adev, gate);\r\n}\r\n}\r\nstatic int cz_enable_vce_dpm(struct amdgpu_device *adev, bool enable)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nint ret = 0;\r\nif (enable && pi->caps_vce_dpm) {\r\npi->dpm_flags |= DPMFlags_VCE_Enabled;\r\nDRM_DEBUG("VCE DPM Enabled.\n");\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_EnableAllSmuFeatures, VCE_DPM_MASK);\r\n} else {\r\npi->dpm_flags &= ~DPMFlags_VCE_Enabled;\r\nDRM_DEBUG("VCE DPM Stopped\n");\r\nret = cz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_DisableAllSmuFeatures, VCE_DPM_MASK);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cz_update_vce_dpm(struct amdgpu_device *adev)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nstruct amdgpu_vce_clock_voltage_dependency_table *table =\r\n&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nif (pi->caps_stable_power_state) {\r\npi->vce_dpm.hard_min_clk = table->entries[table->count-1].ecclk;\r\n} else {\r\n}\r\ncz_send_msg_to_smc_with_parameter(adev,\r\nPPSMC_MSG_SetEclkHardMin,\r\ncz_get_eclk_level(adev,\r\npi->vce_dpm.hard_min_clk,\r\nPPSMC_MSG_SetEclkHardMin));\r\nreturn 0;\r\n}\r\nstatic void cz_dpm_powergate_vce(struct amdgpu_device *adev, bool gate)\r\n{\r\nstruct cz_power_info *pi = cz_get_pi(adev);\r\nif (pi->caps_vce_pg) {\r\nif (pi->vce_power_gated != gate) {\r\nif (gate) {\r\namdgpu_set_clockgating_state(adev, AMD_IP_BLOCK_TYPE_VCE,\r\nAMD_CG_STATE_UNGATE);\r\namdgpu_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_VCE,\r\nAMD_PG_STATE_GATE);\r\ncz_enable_vce_dpm(adev, false);\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_VCEPowerOFF);\r\npi->vce_power_gated = true;\r\n} else {\r\ncz_send_msg_to_smc(adev, PPSMC_MSG_VCEPowerON);\r\npi->vce_power_gated = false;\r\namdgpu_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_VCE,\r\nAMD_PG_STATE_UNGATE);\r\namdgpu_set_clockgating_state(adev, AMD_IP_BLOCK_TYPE_VCE,\r\nAMD_CG_STATE_GATE);\r\ncz_update_vce_dpm(adev);\r\ncz_enable_vce_dpm(adev, true);\r\n}\r\n} else {\r\nif (! pi->vce_power_gated) {\r\ncz_update_vce_dpm(adev);\r\n}\r\n}\r\n} else {\r\ncz_update_vce_dpm(adev);\r\ncz_enable_vce_dpm(adev, !gate);\r\n}\r\n}\r\nstatic void cz_dpm_set_funcs(struct amdgpu_device *adev)\r\n{\r\nif (NULL == adev->pm.funcs)\r\nadev->pm.funcs = &cz_dpm_funcs;\r\n}
