static unsigned int rest_of_page(void *data)\r\n{\r\nreturn PAGE_SIZE - offset_in_page(data);\r\n}\r\nstatic void p9_virtio_close(struct p9_client *client)\r\n{\r\nstruct virtio_chan *chan = client->trans;\r\nmutex_lock(&virtio_9p_lock);\r\nif (chan)\r\nchan->inuse = false;\r\nmutex_unlock(&virtio_9p_lock);\r\n}\r\nstatic void req_done(struct virtqueue *vq)\r\n{\r\nstruct virtio_chan *chan = vq->vdev->priv;\r\nunsigned int len;\r\nstruct p9_req_t *req;\r\nunsigned long flags;\r\np9_debug(P9_DEBUG_TRANS, ": request done\n");\r\nwhile (1) {\r\nspin_lock_irqsave(&chan->lock, flags);\r\nreq = virtqueue_get_buf(chan->vq, &len);\r\nif (req == NULL) {\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nbreak;\r\n}\r\nchan->ring_bufs_avail = 1;\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nwake_up(chan->vc_wq);\r\np9_client_cb(chan->client, req, REQ_STATUS_RCVD);\r\n}\r\n}\r\nstatic int pack_sg_list(struct scatterlist *sg, int start,\r\nint limit, char *data, int count)\r\n{\r\nint s;\r\nint index = start;\r\nwhile (count) {\r\ns = rest_of_page(data);\r\nif (s > count)\r\ns = count;\r\nBUG_ON(index > limit);\r\nsg_unmark_end(&sg[index]);\r\nsg_set_buf(&sg[index++], data, s);\r\ncount -= s;\r\ndata += s;\r\n}\r\nif (index-start)\r\nsg_mark_end(&sg[index - 1]);\r\nreturn index-start;\r\n}\r\nstatic int p9_virtio_cancel(struct p9_client *client, struct p9_req_t *req)\r\n{\r\nreturn 1;\r\n}\r\nstatic int\r\npack_sg_list_p(struct scatterlist *sg, int start, int limit,\r\nstruct page **pdata, int nr_pages, size_t offs, int count)\r\n{\r\nint i = 0, s;\r\nint data_off = offs;\r\nint index = start;\r\nBUG_ON(nr_pages > (limit - start));\r\nwhile (nr_pages) {\r\ns = PAGE_SIZE - data_off;\r\nif (s > count)\r\ns = count;\r\nsg_unmark_end(&sg[index]);\r\nsg_set_page(&sg[index++], pdata[i++], s, data_off);\r\ndata_off = 0;\r\ncount -= s;\r\nnr_pages--;\r\n}\r\nif (index-start)\r\nsg_mark_end(&sg[index - 1]);\r\nreturn index - start;\r\n}\r\nstatic int\r\np9_virtio_request(struct p9_client *client, struct p9_req_t *req)\r\n{\r\nint err;\r\nint in, out, out_sgs, in_sgs;\r\nunsigned long flags;\r\nstruct virtio_chan *chan = client->trans;\r\nstruct scatterlist *sgs[2];\r\np9_debug(P9_DEBUG_TRANS, "9p debug: virtio request\n");\r\nreq->status = REQ_STATUS_SENT;\r\nreq_retry:\r\nspin_lock_irqsave(&chan->lock, flags);\r\nout_sgs = in_sgs = 0;\r\nout = pack_sg_list(chan->sg, 0,\r\nVIRTQUEUE_NUM, req->tc->sdata, req->tc->size);\r\nif (out)\r\nsgs[out_sgs++] = chan->sg;\r\nin = pack_sg_list(chan->sg, out,\r\nVIRTQUEUE_NUM, req->rc->sdata, req->rc->capacity);\r\nif (in)\r\nsgs[out_sgs + in_sgs++] = chan->sg + out;\r\nerr = virtqueue_add_sgs(chan->vq, sgs, out_sgs, in_sgs, req,\r\nGFP_ATOMIC);\r\nif (err < 0) {\r\nif (err == -ENOSPC) {\r\nchan->ring_bufs_avail = 0;\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nerr = wait_event_interruptible(*chan->vc_wq,\r\nchan->ring_bufs_avail);\r\nif (err == -ERESTARTSYS)\r\nreturn err;\r\np9_debug(P9_DEBUG_TRANS, "Retry virtio request\n");\r\ngoto req_retry;\r\n} else {\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\np9_debug(P9_DEBUG_TRANS,\r\n"virtio rpc add_sgs returned failure\n");\r\nreturn -EIO;\r\n}\r\n}\r\nvirtqueue_kick(chan->vq);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\np9_debug(P9_DEBUG_TRANS, "virtio request kicked\n");\r\nreturn 0;\r\n}\r\nstatic int p9_get_mapped_pages(struct virtio_chan *chan,\r\nstruct page ***pages,\r\nstruct iov_iter *data,\r\nint count,\r\nsize_t *offs,\r\nint *need_drop)\r\n{\r\nint nr_pages;\r\nint err;\r\nif (!iov_iter_count(data))\r\nreturn 0;\r\nif (!(data->type & ITER_KVEC)) {\r\nint n;\r\nif (atomic_read(&vp_pinned) >= chan->p9_max_pages) {\r\nerr = wait_event_interruptible(vp_wq,\r\n(atomic_read(&vp_pinned) < chan->p9_max_pages));\r\nif (err == -ERESTARTSYS)\r\nreturn err;\r\n}\r\nn = iov_iter_get_pages_alloc(data, pages, count, offs);\r\nif (n < 0)\r\nreturn n;\r\n*need_drop = 1;\r\nnr_pages = DIV_ROUND_UP(n + *offs, PAGE_SIZE);\r\natomic_add(nr_pages, &vp_pinned);\r\nreturn n;\r\n} else {\r\nint index;\r\nsize_t len;\r\nvoid *p;\r\nwhile (1) {\r\nlen = iov_iter_single_seg_count(data);\r\nif (likely(len)) {\r\np = data->kvec->iov_base + data->iov_offset;\r\nbreak;\r\n}\r\niov_iter_advance(data, 0);\r\n}\r\nif (len > count)\r\nlen = count;\r\nnr_pages = DIV_ROUND_UP((unsigned long)p + len, PAGE_SIZE) -\r\n(unsigned long)p / PAGE_SIZE;\r\n*pages = kmalloc(sizeof(struct page *) * nr_pages, GFP_NOFS);\r\nif (!*pages)\r\nreturn -ENOMEM;\r\n*need_drop = 0;\r\np -= (*offs = offset_in_page(p));\r\nfor (index = 0; index < nr_pages; index++) {\r\nif (is_vmalloc_addr(p))\r\n(*pages)[index] = vmalloc_to_page(p);\r\nelse\r\n(*pages)[index] = kmap_to_page(p);\r\np += PAGE_SIZE;\r\n}\r\nreturn len;\r\n}\r\n}\r\nstatic int\r\np9_virtio_zc_request(struct p9_client *client, struct p9_req_t *req,\r\nstruct iov_iter *uidata, struct iov_iter *uodata,\r\nint inlen, int outlen, int in_hdr_len)\r\n{\r\nint in, out, err, out_sgs, in_sgs;\r\nunsigned long flags;\r\nint in_nr_pages = 0, out_nr_pages = 0;\r\nstruct page **in_pages = NULL, **out_pages = NULL;\r\nstruct virtio_chan *chan = client->trans;\r\nstruct scatterlist *sgs[4];\r\nsize_t offs;\r\nint need_drop = 0;\r\np9_debug(P9_DEBUG_TRANS, "virtio request\n");\r\nif (uodata) {\r\nint n = p9_get_mapped_pages(chan, &out_pages, uodata,\r\noutlen, &offs, &need_drop);\r\nif (n < 0)\r\nreturn n;\r\nout_nr_pages = DIV_ROUND_UP(n + offs, PAGE_SIZE);\r\nif (n != outlen) {\r\n__le32 v = cpu_to_le32(n);\r\nmemcpy(&req->tc->sdata[req->tc->size - 4], &v, 4);\r\noutlen = n;\r\n}\r\n} else if (uidata) {\r\nint n = p9_get_mapped_pages(chan, &in_pages, uidata,\r\ninlen, &offs, &need_drop);\r\nif (n < 0)\r\nreturn n;\r\nin_nr_pages = DIV_ROUND_UP(n + offs, PAGE_SIZE);\r\nif (n != inlen) {\r\n__le32 v = cpu_to_le32(n);\r\nmemcpy(&req->tc->sdata[req->tc->size - 4], &v, 4);\r\ninlen = n;\r\n}\r\n}\r\nreq->status = REQ_STATUS_SENT;\r\nreq_retry_pinned:\r\nspin_lock_irqsave(&chan->lock, flags);\r\nout_sgs = in_sgs = 0;\r\nout = pack_sg_list(chan->sg, 0,\r\nVIRTQUEUE_NUM, req->tc->sdata, req->tc->size);\r\nif (out)\r\nsgs[out_sgs++] = chan->sg;\r\nif (out_pages) {\r\nsgs[out_sgs++] = chan->sg + out;\r\nout += pack_sg_list_p(chan->sg, out, VIRTQUEUE_NUM,\r\nout_pages, out_nr_pages, offs, outlen);\r\n}\r\nin = pack_sg_list(chan->sg, out,\r\nVIRTQUEUE_NUM, req->rc->sdata, in_hdr_len);\r\nif (in)\r\nsgs[out_sgs + in_sgs++] = chan->sg + out;\r\nif (in_pages) {\r\nsgs[out_sgs + in_sgs++] = chan->sg + out + in;\r\nin += pack_sg_list_p(chan->sg, out + in, VIRTQUEUE_NUM,\r\nin_pages, in_nr_pages, offs, inlen);\r\n}\r\nBUG_ON(out_sgs + in_sgs > ARRAY_SIZE(sgs));\r\nerr = virtqueue_add_sgs(chan->vq, sgs, out_sgs, in_sgs, req,\r\nGFP_ATOMIC);\r\nif (err < 0) {\r\nif (err == -ENOSPC) {\r\nchan->ring_bufs_avail = 0;\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nerr = wait_event_interruptible(*chan->vc_wq,\r\nchan->ring_bufs_avail);\r\nif (err == -ERESTARTSYS)\r\ngoto err_out;\r\np9_debug(P9_DEBUG_TRANS, "Retry virtio request\n");\r\ngoto req_retry_pinned;\r\n} else {\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\np9_debug(P9_DEBUG_TRANS,\r\n"virtio rpc add_sgs returned failure\n");\r\nerr = -EIO;\r\ngoto err_out;\r\n}\r\n}\r\nvirtqueue_kick(chan->vq);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\np9_debug(P9_DEBUG_TRANS, "virtio request kicked\n");\r\nerr = wait_event_interruptible(*req->wq,\r\nreq->status >= REQ_STATUS_RCVD);\r\nerr_out:\r\nif (need_drop) {\r\nif (in_pages) {\r\np9_release_pages(in_pages, in_nr_pages);\r\natomic_sub(in_nr_pages, &vp_pinned);\r\n}\r\nif (out_pages) {\r\np9_release_pages(out_pages, out_nr_pages);\r\natomic_sub(out_nr_pages, &vp_pinned);\r\n}\r\nwake_up(&vp_wq);\r\n}\r\nkfree(in_pages);\r\nkfree(out_pages);\r\nreturn err;\r\n}\r\nstatic ssize_t p9_mount_tag_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct virtio_chan *chan;\r\nstruct virtio_device *vdev;\r\nvdev = dev_to_virtio(dev);\r\nchan = vdev->priv;\r\nmemcpy(buf, chan->tag, chan->tag_len);\r\nbuf[chan->tag_len] = 0;\r\nreturn chan->tag_len + 1;\r\n}\r\nstatic int p9_virtio_probe(struct virtio_device *vdev)\r\n{\r\n__u16 tag_len;\r\nchar *tag;\r\nint err;\r\nstruct virtio_chan *chan;\r\nif (!vdev->config->get) {\r\ndev_err(&vdev->dev, "%s failure: config access disabled\n",\r\n__func__);\r\nreturn -EINVAL;\r\n}\r\nchan = kmalloc(sizeof(struct virtio_chan), GFP_KERNEL);\r\nif (!chan) {\r\npr_err("Failed to allocate virtio 9P channel\n");\r\nerr = -ENOMEM;\r\ngoto fail;\r\n}\r\nchan->vdev = vdev;\r\nchan->vq = virtio_find_single_vq(vdev, req_done, "requests");\r\nif (IS_ERR(chan->vq)) {\r\nerr = PTR_ERR(chan->vq);\r\ngoto out_free_vq;\r\n}\r\nchan->vq->vdev->priv = chan;\r\nspin_lock_init(&chan->lock);\r\nsg_init_table(chan->sg, VIRTQUEUE_NUM);\r\nchan->inuse = false;\r\nif (virtio_has_feature(vdev, VIRTIO_9P_MOUNT_TAG)) {\r\nvirtio_cread(vdev, struct virtio_9p_config, tag_len, &tag_len);\r\n} else {\r\nerr = -EINVAL;\r\ngoto out_free_vq;\r\n}\r\ntag = kmalloc(tag_len, GFP_KERNEL);\r\nif (!tag) {\r\nerr = -ENOMEM;\r\ngoto out_free_vq;\r\n}\r\nvirtio_cread_bytes(vdev, offsetof(struct virtio_9p_config, tag),\r\ntag, tag_len);\r\nchan->tag = tag;\r\nchan->tag_len = tag_len;\r\nerr = sysfs_create_file(&(vdev->dev.kobj), &dev_attr_mount_tag.attr);\r\nif (err) {\r\ngoto out_free_tag;\r\n}\r\nchan->vc_wq = kmalloc(sizeof(wait_queue_head_t), GFP_KERNEL);\r\nif (!chan->vc_wq) {\r\nerr = -ENOMEM;\r\ngoto out_free_tag;\r\n}\r\ninit_waitqueue_head(chan->vc_wq);\r\nchan->ring_bufs_avail = 1;\r\nchan->p9_max_pages = nr_free_buffer_pages()/4;\r\nvirtio_device_ready(vdev);\r\nmutex_lock(&virtio_9p_lock);\r\nlist_add_tail(&chan->chan_list, &virtio_chan_list);\r\nmutex_unlock(&virtio_9p_lock);\r\nkobject_uevent(&(vdev->dev.kobj), KOBJ_CHANGE);\r\nreturn 0;\r\nout_free_tag:\r\nkfree(tag);\r\nout_free_vq:\r\nvdev->config->del_vqs(vdev);\r\nkfree(chan);\r\nfail:\r\nreturn err;\r\n}\r\nstatic int\r\np9_virtio_create(struct p9_client *client, const char *devname, char *args)\r\n{\r\nstruct virtio_chan *chan;\r\nint ret = -ENOENT;\r\nint found = 0;\r\nmutex_lock(&virtio_9p_lock);\r\nlist_for_each_entry(chan, &virtio_chan_list, chan_list) {\r\nif (!strncmp(devname, chan->tag, chan->tag_len) &&\r\nstrlen(devname) == chan->tag_len) {\r\nif (!chan->inuse) {\r\nchan->inuse = true;\r\nfound = 1;\r\nbreak;\r\n}\r\nret = -EBUSY;\r\n}\r\n}\r\nmutex_unlock(&virtio_9p_lock);\r\nif (!found) {\r\npr_err("no channels available for device %s\n", devname);\r\nreturn ret;\r\n}\r\nclient->trans = (void *)chan;\r\nclient->status = Connected;\r\nchan->client = client;\r\nreturn 0;\r\n}\r\nstatic void p9_virtio_remove(struct virtio_device *vdev)\r\n{\r\nstruct virtio_chan *chan = vdev->priv;\r\nunsigned long warning_time;\r\nmutex_lock(&virtio_9p_lock);\r\nlist_del(&chan->chan_list);\r\nwarning_time = jiffies;\r\nwhile (chan->inuse) {\r\nmutex_unlock(&virtio_9p_lock);\r\nmsleep(250);\r\nif (time_after(jiffies, warning_time + 10 * HZ)) {\r\ndev_emerg(&vdev->dev,\r\n"p9_virtio_remove: waiting for device in use.\n");\r\nwarning_time = jiffies;\r\n}\r\nmutex_lock(&virtio_9p_lock);\r\n}\r\nmutex_unlock(&virtio_9p_lock);\r\nvdev->config->reset(vdev);\r\nvdev->config->del_vqs(vdev);\r\nsysfs_remove_file(&(vdev->dev.kobj), &dev_attr_mount_tag.attr);\r\nkobject_uevent(&(vdev->dev.kobj), KOBJ_CHANGE);\r\nkfree(chan->tag);\r\nkfree(chan->vc_wq);\r\nkfree(chan);\r\n}\r\nstatic int __init p9_virtio_init(void)\r\n{\r\nINIT_LIST_HEAD(&virtio_chan_list);\r\nv9fs_register_trans(&p9_virtio_trans);\r\nreturn register_virtio_driver(&p9_virtio_drv);\r\n}\r\nstatic void __exit p9_virtio_cleanup(void)\r\n{\r\nunregister_virtio_driver(&p9_virtio_drv);\r\nv9fs_unregister_trans(&p9_virtio_trans);\r\n}
