void\r\nkiblnd_tx_done (lnet_ni_t *ni, kib_tx_t *tx)\r\n{\r\nlnet_msg_t *lntmsg[2];\r\nkib_net_t *net = ni->ni_data;\r\nint rc;\r\nint i;\r\nLASSERT (net != NULL);\r\nLASSERT (!in_interrupt());\r\nLASSERT (!tx->tx_queued);\r\nLASSERT (tx->tx_sending == 0);\r\nLASSERT (!tx->tx_waiting);\r\nLASSERT (tx->tx_pool != NULL);\r\nkiblnd_unmap_tx(ni, tx);\r\nlntmsg[0] = tx->tx_lntmsg[0]; tx->tx_lntmsg[0] = NULL;\r\nlntmsg[1] = tx->tx_lntmsg[1]; tx->tx_lntmsg[1] = NULL;\r\nrc = tx->tx_status;\r\nif (tx->tx_conn != NULL) {\r\nLASSERT (ni == tx->tx_conn->ibc_peer->ibp_ni);\r\nkiblnd_conn_decref(tx->tx_conn);\r\ntx->tx_conn = NULL;\r\n}\r\ntx->tx_nwrq = 0;\r\ntx->tx_status = 0;\r\nkiblnd_pool_free_node(&tx->tx_pool->tpo_pool, &tx->tx_list);\r\nfor (i = 0; i < 2; i++) {\r\nif (lntmsg[i] == NULL)\r\ncontinue;\r\nlnet_finalize(ni, lntmsg[i], rc);\r\n}\r\n}\r\nvoid\r\nkiblnd_txlist_done (lnet_ni_t *ni, struct list_head *txlist, int status)\r\n{\r\nkib_tx_t *tx;\r\nwhile (!list_empty (txlist)) {\r\ntx = list_entry (txlist->next, kib_tx_t, tx_list);\r\nlist_del(&tx->tx_list);\r\ntx->tx_waiting = 0;\r\ntx->tx_status = status;\r\nkiblnd_tx_done(ni, tx);\r\n}\r\n}\r\nkib_tx_t *\r\nkiblnd_get_idle_tx(lnet_ni_t *ni, lnet_nid_t target)\r\n{\r\nkib_net_t *net = (kib_net_t *)ni->ni_data;\r\nstruct list_head *node;\r\nkib_tx_t *tx;\r\nkib_tx_poolset_t *tps;\r\ntps = net->ibn_tx_ps[lnet_cpt_of_nid(target)];\r\nnode = kiblnd_pool_alloc_node(&tps->tps_poolset);\r\nif (node == NULL)\r\nreturn NULL;\r\ntx = container_of(node, kib_tx_t, tx_list);\r\nLASSERT (tx->tx_nwrq == 0);\r\nLASSERT (!tx->tx_queued);\r\nLASSERT (tx->tx_sending == 0);\r\nLASSERT (!tx->tx_waiting);\r\nLASSERT (tx->tx_status == 0);\r\nLASSERT (tx->tx_conn == NULL);\r\nLASSERT (tx->tx_lntmsg[0] == NULL);\r\nLASSERT (tx->tx_lntmsg[1] == NULL);\r\nLASSERT (tx->tx_u.pmr == NULL);\r\nLASSERT (tx->tx_nfrags == 0);\r\nreturn tx;\r\n}\r\nvoid\r\nkiblnd_drop_rx(kib_rx_t *rx)\r\n{\r\nkib_conn_t *conn = rx->rx_conn;\r\nstruct kib_sched_info *sched = conn->ibc_sched;\r\nunsigned long flags;\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\nLASSERT(conn->ibc_nrx > 0);\r\nconn->ibc_nrx--;\r\nspin_unlock_irqrestore(&sched->ibs_lock, flags);\r\nkiblnd_conn_decref(conn);\r\n}\r\nint\r\nkiblnd_post_rx (kib_rx_t *rx, int credit)\r\n{\r\nkib_conn_t *conn = rx->rx_conn;\r\nkib_net_t *net = conn->ibc_peer->ibp_ni->ni_data;\r\nstruct ib_recv_wr *bad_wrq = NULL;\r\nstruct ib_mr *mr;\r\nint rc;\r\nLASSERT (net != NULL);\r\nLASSERT (!in_interrupt());\r\nLASSERT (credit == IBLND_POSTRX_NO_CREDIT ||\r\ncredit == IBLND_POSTRX_PEER_CREDIT ||\r\ncredit == IBLND_POSTRX_RSRVD_CREDIT);\r\nmr = kiblnd_find_dma_mr(conn->ibc_hdev, rx->rx_msgaddr, IBLND_MSG_SIZE);\r\nLASSERT (mr != NULL);\r\nrx->rx_sge.lkey = mr->lkey;\r\nrx->rx_sge.addr = rx->rx_msgaddr;\r\nrx->rx_sge.length = IBLND_MSG_SIZE;\r\nrx->rx_wrq.next = NULL;\r\nrx->rx_wrq.sg_list = &rx->rx_sge;\r\nrx->rx_wrq.num_sge = 1;\r\nrx->rx_wrq.wr_id = kiblnd_ptr2wreqid(rx, IBLND_WID_RX);\r\nLASSERT (conn->ibc_state >= IBLND_CONN_INIT);\r\nLASSERT (rx->rx_nob >= 0);\r\nif (conn->ibc_state > IBLND_CONN_ESTABLISHED) {\r\nkiblnd_drop_rx(rx);\r\nreturn 0;\r\n}\r\nrx->rx_nob = -1;\r\nrc = ib_post_recv(conn->ibc_cmid->qp, &rx->rx_wrq, &bad_wrq);\r\nif (rc != 0) {\r\nCERROR("Can't post rx for %s: %d, bad_wrq: %p\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), rc, bad_wrq);\r\nrx->rx_nob = 0;\r\n}\r\nif (conn->ibc_state < IBLND_CONN_ESTABLISHED)\r\nreturn rc;\r\nif (rc != 0) {\r\nkiblnd_close_conn(conn, rc);\r\nkiblnd_drop_rx(rx);\r\nreturn rc;\r\n}\r\nif (credit == IBLND_POSTRX_NO_CREDIT)\r\nreturn 0;\r\nspin_lock(&conn->ibc_lock);\r\nif (credit == IBLND_POSTRX_PEER_CREDIT)\r\nconn->ibc_outstanding_credits++;\r\nelse\r\nconn->ibc_reserved_credits++;\r\nspin_unlock(&conn->ibc_lock);\r\nkiblnd_check_sends(conn);\r\nreturn 0;\r\n}\r\nkib_tx_t *\r\nkiblnd_find_waiting_tx_locked(kib_conn_t *conn, int txtype, __u64 cookie)\r\n{\r\nstruct list_head *tmp;\r\nlist_for_each(tmp, &conn->ibc_active_txs) {\r\nkib_tx_t *tx = list_entry(tmp, kib_tx_t, tx_list);\r\nLASSERT (!tx->tx_queued);\r\nLASSERT (tx->tx_sending != 0 || tx->tx_waiting);\r\nif (tx->tx_cookie != cookie)\r\ncontinue;\r\nif (tx->tx_waiting &&\r\ntx->tx_msg->ibm_type == txtype)\r\nreturn tx;\r\nCWARN("Bad completion: %swaiting, type %x (wanted %x)\n",\r\ntx->tx_waiting ? "" : "NOT ",\r\ntx->tx_msg->ibm_type, txtype);\r\n}\r\nreturn NULL;\r\n}\r\nvoid\r\nkiblnd_handle_completion(kib_conn_t *conn, int txtype, int status, __u64 cookie)\r\n{\r\nkib_tx_t *tx;\r\nlnet_ni_t *ni = conn->ibc_peer->ibp_ni;\r\nint idle;\r\nspin_lock(&conn->ibc_lock);\r\ntx = kiblnd_find_waiting_tx_locked(conn, txtype, cookie);\r\nif (tx == NULL) {\r\nspin_unlock(&conn->ibc_lock);\r\nCWARN("Unmatched completion type %x cookie "LPX64" from %s\n",\r\ntxtype, cookie, libcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nkiblnd_close_conn(conn, -EPROTO);\r\nreturn;\r\n}\r\nif (tx->tx_status == 0) {\r\nif (status < 0) {\r\ntx->tx_status = status;\r\n} else if (txtype == IBLND_MSG_GET_REQ) {\r\nlnet_set_reply_msg_len(ni, tx->tx_lntmsg[1], status);\r\n}\r\n}\r\ntx->tx_waiting = 0;\r\nidle = !tx->tx_queued && (tx->tx_sending == 0);\r\nif (idle)\r\nlist_del(&tx->tx_list);\r\nspin_unlock(&conn->ibc_lock);\r\nif (idle)\r\nkiblnd_tx_done(ni, tx);\r\n}\r\nvoid\r\nkiblnd_send_completion(kib_conn_t *conn, int type, int status, __u64 cookie)\r\n{\r\nlnet_ni_t *ni = conn->ibc_peer->ibp_ni;\r\nkib_tx_t *tx = kiblnd_get_idle_tx(ni, conn->ibc_peer->ibp_nid);\r\nif (tx == NULL) {\r\nCERROR("Can't get tx for completion %x for %s\n",\r\ntype, libcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nreturn;\r\n}\r\ntx->tx_msg->ibm_u.completion.ibcm_status = status;\r\ntx->tx_msg->ibm_u.completion.ibcm_cookie = cookie;\r\nkiblnd_init_tx_msg(ni, tx, type, sizeof(kib_completion_msg_t));\r\nkiblnd_queue_tx(tx, conn);\r\n}\r\nvoid\r\nkiblnd_handle_rx (kib_rx_t *rx)\r\n{\r\nkib_msg_t *msg = rx->rx_msg;\r\nkib_conn_t *conn = rx->rx_conn;\r\nlnet_ni_t *ni = conn->ibc_peer->ibp_ni;\r\nint credits = msg->ibm_credits;\r\nkib_tx_t *tx;\r\nint rc = 0;\r\nint rc2;\r\nint post_credit;\r\nLASSERT (conn->ibc_state >= IBLND_CONN_ESTABLISHED);\r\nCDEBUG (D_NET, "Received %x[%d] from %s\n",\r\nmsg->ibm_type, credits,\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nif (credits != 0) {\r\nspin_lock(&conn->ibc_lock);\r\nif (conn->ibc_credits + credits >\r\nIBLND_MSG_QUEUE_SIZE(conn->ibc_version)) {\r\nrc2 = conn->ibc_credits;\r\nspin_unlock(&conn->ibc_lock);\r\nCERROR("Bad credits from %s: %d + %d > %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid),\r\nrc2, credits,\r\nIBLND_MSG_QUEUE_SIZE(conn->ibc_version));\r\nkiblnd_close_conn(conn, -EPROTO);\r\nkiblnd_post_rx(rx, IBLND_POSTRX_NO_CREDIT);\r\nreturn;\r\n}\r\nconn->ibc_credits += credits;\r\nif (msg->ibm_type == IBLND_MSG_NOOP &&\r\n!IBLND_OOB_CAPABLE(conn->ibc_version))\r\nconn->ibc_outstanding_credits++;\r\nspin_unlock(&conn->ibc_lock);\r\nkiblnd_check_sends(conn);\r\n}\r\nswitch (msg->ibm_type) {\r\ndefault:\r\nCERROR("Bad IBLND message type %x from %s\n",\r\nmsg->ibm_type, libcfs_nid2str(conn->ibc_peer->ibp_nid));\r\npost_credit = IBLND_POSTRX_NO_CREDIT;\r\nrc = -EPROTO;\r\nbreak;\r\ncase IBLND_MSG_NOOP:\r\nif (IBLND_OOB_CAPABLE(conn->ibc_version)) {\r\npost_credit = IBLND_POSTRX_NO_CREDIT;\r\nbreak;\r\n}\r\nif (credits != 0)\r\npost_credit = IBLND_POSTRX_NO_CREDIT;\r\nelse\r\npost_credit = IBLND_POSTRX_PEER_CREDIT;\r\nbreak;\r\ncase IBLND_MSG_IMMEDIATE:\r\npost_credit = IBLND_POSTRX_DONT_POST;\r\nrc = lnet_parse(ni, &msg->ibm_u.immediate.ibim_hdr,\r\nmsg->ibm_srcnid, rx, 0);\r\nif (rc < 0)\r\npost_credit = IBLND_POSTRX_PEER_CREDIT;\r\nbreak;\r\ncase IBLND_MSG_PUT_REQ:\r\npost_credit = IBLND_POSTRX_DONT_POST;\r\nrc = lnet_parse(ni, &msg->ibm_u.putreq.ibprm_hdr,\r\nmsg->ibm_srcnid, rx, 1);\r\nif (rc < 0)\r\npost_credit = IBLND_POSTRX_PEER_CREDIT;\r\nbreak;\r\ncase IBLND_MSG_PUT_NAK:\r\nCWARN ("PUT_NACK from %s\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\npost_credit = IBLND_POSTRX_RSRVD_CREDIT;\r\nkiblnd_handle_completion(conn, IBLND_MSG_PUT_REQ,\r\nmsg->ibm_u.completion.ibcm_status,\r\nmsg->ibm_u.completion.ibcm_cookie);\r\nbreak;\r\ncase IBLND_MSG_PUT_ACK:\r\npost_credit = IBLND_POSTRX_RSRVD_CREDIT;\r\nspin_lock(&conn->ibc_lock);\r\ntx = kiblnd_find_waiting_tx_locked(conn, IBLND_MSG_PUT_REQ,\r\nmsg->ibm_u.putack.ibpam_src_cookie);\r\nif (tx != NULL)\r\nlist_del(&tx->tx_list);\r\nspin_unlock(&conn->ibc_lock);\r\nif (tx == NULL) {\r\nCERROR("Unmatched PUT_ACK from %s\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nrc = -EPROTO;\r\nbreak;\r\n}\r\nLASSERT (tx->tx_waiting);\r\ntx->tx_nwrq = 0;\r\nrc2 = kiblnd_init_rdma(conn, tx, IBLND_MSG_PUT_DONE,\r\nkiblnd_rd_size(&msg->ibm_u.putack.ibpam_rd),\r\n&msg->ibm_u.putack.ibpam_rd,\r\nmsg->ibm_u.putack.ibpam_dst_cookie);\r\nif (rc2 < 0)\r\nCERROR("Can't setup rdma for PUT to %s: %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), rc2);\r\nspin_lock(&conn->ibc_lock);\r\ntx->tx_waiting = 0;\r\nkiblnd_queue_tx_locked(tx, conn);\r\nspin_unlock(&conn->ibc_lock);\r\nbreak;\r\ncase IBLND_MSG_PUT_DONE:\r\npost_credit = IBLND_POSTRX_PEER_CREDIT;\r\nkiblnd_handle_completion(conn, IBLND_MSG_PUT_ACK,\r\nmsg->ibm_u.completion.ibcm_status,\r\nmsg->ibm_u.completion.ibcm_cookie);\r\nbreak;\r\ncase IBLND_MSG_GET_REQ:\r\npost_credit = IBLND_POSTRX_DONT_POST;\r\nrc = lnet_parse(ni, &msg->ibm_u.get.ibgm_hdr,\r\nmsg->ibm_srcnid, rx, 1);\r\nif (rc < 0)\r\npost_credit = IBLND_POSTRX_PEER_CREDIT;\r\nbreak;\r\ncase IBLND_MSG_GET_DONE:\r\npost_credit = IBLND_POSTRX_RSRVD_CREDIT;\r\nkiblnd_handle_completion(conn, IBLND_MSG_GET_REQ,\r\nmsg->ibm_u.completion.ibcm_status,\r\nmsg->ibm_u.completion.ibcm_cookie);\r\nbreak;\r\n}\r\nif (rc < 0)\r\nkiblnd_close_conn(conn, rc);\r\nif (post_credit != IBLND_POSTRX_DONT_POST)\r\nkiblnd_post_rx(rx, post_credit);\r\n}\r\nvoid\r\nkiblnd_rx_complete (kib_rx_t *rx, int status, int nob)\r\n{\r\nkib_msg_t *msg = rx->rx_msg;\r\nkib_conn_t *conn = rx->rx_conn;\r\nlnet_ni_t *ni = conn->ibc_peer->ibp_ni;\r\nkib_net_t *net = ni->ni_data;\r\nint rc;\r\nint err = -EIO;\r\nLASSERT (net != NULL);\r\nLASSERT (rx->rx_nob < 0);\r\nrx->rx_nob = 0;\r\nif (conn->ibc_state > IBLND_CONN_ESTABLISHED)\r\ngoto ignore;\r\nif (status != IB_WC_SUCCESS) {\r\nCNETERR("Rx from %s failed: %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), status);\r\ngoto failed;\r\n}\r\nLASSERT (nob >= 0);\r\nrx->rx_nob = nob;\r\nrc = kiblnd_unpack_msg(msg, rx->rx_nob);\r\nif (rc != 0) {\r\nCERROR ("Error %d unpacking rx from %s\n",\r\nrc, libcfs_nid2str(conn->ibc_peer->ibp_nid));\r\ngoto failed;\r\n}\r\nif (msg->ibm_srcnid != conn->ibc_peer->ibp_nid ||\r\nmsg->ibm_dstnid != ni->ni_nid ||\r\nmsg->ibm_srcstamp != conn->ibc_incarnation ||\r\nmsg->ibm_dststamp != net->ibn_incarnation) {\r\nCERROR ("Stale rx from %s\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nerr = -ESTALE;\r\ngoto failed;\r\n}\r\nkiblnd_peer_alive(conn->ibc_peer);\r\nif (conn->ibc_state < IBLND_CONN_ESTABLISHED) {\r\nrwlock_t *g_lock = &kiblnd_data.kib_global_lock;\r\nunsigned long flags;\r\nwrite_lock_irqsave(g_lock, flags);\r\nif (conn->ibc_state < IBLND_CONN_ESTABLISHED) {\r\nlist_add_tail(&rx->rx_list, &conn->ibc_early_rxs);\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nreturn;\r\n}\r\nwrite_unlock_irqrestore(g_lock, flags);\r\n}\r\nkiblnd_handle_rx(rx);\r\nreturn;\r\nfailed:\r\nCDEBUG(D_NET, "rx %p conn %p\n", rx, conn);\r\nkiblnd_close_conn(conn, err);\r\nignore:\r\nkiblnd_drop_rx(rx);\r\n}\r\nstruct page *\r\nkiblnd_kvaddr_to_page (unsigned long vaddr)\r\n{\r\nstruct page *page;\r\nif (vaddr >= VMALLOC_START &&\r\nvaddr < VMALLOC_END) {\r\npage = vmalloc_to_page ((void *)vaddr);\r\nLASSERT (page != NULL);\r\nreturn page;\r\n}\r\n#ifdef CONFIG_HIGHMEM\r\nif (vaddr >= PKMAP_BASE &&\r\nvaddr < (PKMAP_BASE + LAST_PKMAP * PAGE_SIZE)) {\r\nCERROR("find page for address in highmem\n");\r\nLBUG();\r\n}\r\n#endif\r\npage = virt_to_page (vaddr);\r\nLASSERT (page != NULL);\r\nreturn page;\r\n}\r\nstatic int\r\nkiblnd_fmr_map_tx(kib_net_t *net, kib_tx_t *tx, kib_rdma_desc_t *rd, int nob)\r\n{\r\nkib_hca_dev_t *hdev;\r\n__u64 *pages = tx->tx_pages;\r\nkib_fmr_poolset_t *fps;\r\nint npages;\r\nint size;\r\nint cpt;\r\nint rc;\r\nint i;\r\nLASSERT(tx->tx_pool != NULL);\r\nLASSERT(tx->tx_pool->tpo_pool.po_owner != NULL);\r\nhdev = tx->tx_pool->tpo_hdev;\r\nfor (i = 0, npages = 0; i < rd->rd_nfrags; i++) {\r\nfor (size = 0; size < rd->rd_frags[i].rf_nob;\r\nsize += hdev->ibh_page_size) {\r\npages[npages ++] = (rd->rd_frags[i].rf_addr &\r\nhdev->ibh_page_mask) + size;\r\n}\r\n}\r\ncpt = tx->tx_pool->tpo_pool.po_owner->ps_cpt;\r\nfps = net->ibn_fmr_ps[cpt];\r\nrc = kiblnd_fmr_pool_map(fps, pages, npages, 0, &tx->tx_u.fmr);\r\nif (rc != 0) {\r\nCERROR ("Can't map %d pages: %d\n", npages, rc);\r\nreturn rc;\r\n}\r\nrd->rd_key = (rd != tx->tx_rd) ? tx->tx_u.fmr.fmr_pfmr->fmr->rkey :\r\ntx->tx_u.fmr.fmr_pfmr->fmr->lkey;\r\nrd->rd_frags[0].rf_addr &= ~hdev->ibh_page_mask;\r\nrd->rd_frags[0].rf_nob = nob;\r\nrd->rd_nfrags = 1;\r\nreturn 0;\r\n}\r\nstatic int\r\nkiblnd_pmr_map_tx(kib_net_t *net, kib_tx_t *tx, kib_rdma_desc_t *rd, int nob)\r\n{\r\nkib_hca_dev_t *hdev;\r\nkib_pmr_poolset_t *pps;\r\n__u64 iova;\r\nint cpt;\r\nint rc;\r\nLASSERT(tx->tx_pool != NULL);\r\nLASSERT(tx->tx_pool->tpo_pool.po_owner != NULL);\r\nhdev = tx->tx_pool->tpo_hdev;\r\niova = rd->rd_frags[0].rf_addr & ~hdev->ibh_page_mask;\r\ncpt = tx->tx_pool->tpo_pool.po_owner->ps_cpt;\r\npps = net->ibn_pmr_ps[cpt];\r\nrc = kiblnd_pmr_pool_map(pps, hdev, rd, &iova, &tx->tx_u.pmr);\r\nif (rc != 0) {\r\nCERROR("Failed to create MR by phybuf: %d\n", rc);\r\nreturn rc;\r\n}\r\nrd->rd_key = (rd != tx->tx_rd) ? tx->tx_u.pmr->pmr_mr->rkey :\r\ntx->tx_u.pmr->pmr_mr->lkey;\r\nrd->rd_nfrags = 1;\r\nrd->rd_frags[0].rf_addr = iova;\r\nrd->rd_frags[0].rf_nob = nob;\r\nreturn 0;\r\n}\r\nvoid\r\nkiblnd_unmap_tx(lnet_ni_t *ni, kib_tx_t *tx)\r\n{\r\nkib_net_t *net = ni->ni_data;\r\nLASSERT(net != NULL);\r\nif (net->ibn_fmr_ps != NULL && tx->tx_u.fmr.fmr_pfmr != NULL) {\r\nkiblnd_fmr_pool_unmap(&tx->tx_u.fmr, tx->tx_status);\r\ntx->tx_u.fmr.fmr_pfmr = NULL;\r\n} else if (net->ibn_pmr_ps != NULL && tx->tx_u.pmr != NULL) {\r\nkiblnd_pmr_pool_unmap(tx->tx_u.pmr);\r\ntx->tx_u.pmr = NULL;\r\n}\r\nif (tx->tx_nfrags != 0) {\r\nkiblnd_dma_unmap_sg(tx->tx_pool->tpo_hdev->ibh_ibdev,\r\ntx->tx_frags, tx->tx_nfrags, tx->tx_dmadir);\r\ntx->tx_nfrags = 0;\r\n}\r\n}\r\nint\r\nkiblnd_map_tx(lnet_ni_t *ni, kib_tx_t *tx,\r\nkib_rdma_desc_t *rd, int nfrags)\r\n{\r\nkib_hca_dev_t *hdev = tx->tx_pool->tpo_hdev;\r\nkib_net_t *net = ni->ni_data;\r\nstruct ib_mr *mr = NULL;\r\n__u32 nob;\r\nint i;\r\ntx->tx_dmadir = (rd != tx->tx_rd) ? DMA_FROM_DEVICE : DMA_TO_DEVICE;\r\ntx->tx_nfrags = nfrags;\r\nrd->rd_nfrags =\r\nkiblnd_dma_map_sg(hdev->ibh_ibdev,\r\ntx->tx_frags, tx->tx_nfrags, tx->tx_dmadir);\r\nfor (i = 0, nob = 0; i < rd->rd_nfrags; i++) {\r\nrd->rd_frags[i].rf_nob = kiblnd_sg_dma_len(\r\nhdev->ibh_ibdev, &tx->tx_frags[i]);\r\nrd->rd_frags[i].rf_addr = kiblnd_sg_dma_address(\r\nhdev->ibh_ibdev, &tx->tx_frags[i]);\r\nnob += rd->rd_frags[i].rf_nob;\r\n}\r\nmr = kiblnd_find_rd_dma_mr(hdev, rd);\r\nif (mr != NULL) {\r\nrd->rd_key = (rd != tx->tx_rd) ? mr->rkey : mr->lkey;\r\nreturn 0;\r\n}\r\nif (net->ibn_fmr_ps != NULL)\r\nreturn kiblnd_fmr_map_tx(net, tx, rd, nob);\r\nelse if (net->ibn_pmr_ps != NULL)\r\nreturn kiblnd_pmr_map_tx(net, tx, rd, nob);\r\nreturn -EINVAL;\r\n}\r\nint\r\nkiblnd_setup_rd_iov(lnet_ni_t *ni, kib_tx_t *tx, kib_rdma_desc_t *rd,\r\nunsigned int niov, struct iovec *iov, int offset, int nob)\r\n{\r\nkib_net_t *net = ni->ni_data;\r\nstruct page *page;\r\nstruct scatterlist *sg;\r\nunsigned long vaddr;\r\nint fragnob;\r\nint page_offset;\r\nLASSERT (nob > 0);\r\nLASSERT (niov > 0);\r\nLASSERT (net != NULL);\r\nwhile (offset >= iov->iov_len) {\r\noffset -= iov->iov_len;\r\nniov--;\r\niov++;\r\nLASSERT (niov > 0);\r\n}\r\nsg = tx->tx_frags;\r\ndo {\r\nLASSERT (niov > 0);\r\nvaddr = ((unsigned long)iov->iov_base) + offset;\r\npage_offset = vaddr & (PAGE_SIZE - 1);\r\npage = kiblnd_kvaddr_to_page(vaddr);\r\nif (page == NULL) {\r\nCERROR ("Can't find page\n");\r\nreturn -EFAULT;\r\n}\r\nfragnob = min((int)(iov->iov_len - offset), nob);\r\nfragnob = min(fragnob, (int)PAGE_SIZE - page_offset);\r\nsg_set_page(sg, page, fragnob, page_offset);\r\nsg++;\r\nif (offset + fragnob < iov->iov_len) {\r\noffset += fragnob;\r\n} else {\r\noffset = 0;\r\niov++;\r\nniov--;\r\n}\r\nnob -= fragnob;\r\n} while (nob > 0);\r\nreturn kiblnd_map_tx(ni, tx, rd, sg - tx->tx_frags);\r\n}\r\nint\r\nkiblnd_setup_rd_kiov (lnet_ni_t *ni, kib_tx_t *tx, kib_rdma_desc_t *rd,\r\nint nkiov, lnet_kiov_t *kiov, int offset, int nob)\r\n{\r\nkib_net_t *net = ni->ni_data;\r\nstruct scatterlist *sg;\r\nint fragnob;\r\nCDEBUG(D_NET, "niov %d offset %d nob %d\n", nkiov, offset, nob);\r\nLASSERT (nob > 0);\r\nLASSERT (nkiov > 0);\r\nLASSERT (net != NULL);\r\nwhile (offset >= kiov->kiov_len) {\r\noffset -= kiov->kiov_len;\r\nnkiov--;\r\nkiov++;\r\nLASSERT (nkiov > 0);\r\n}\r\nsg = tx->tx_frags;\r\ndo {\r\nLASSERT (nkiov > 0);\r\nfragnob = min((int)(kiov->kiov_len - offset), nob);\r\nsg_set_page(sg, kiov->kiov_page, fragnob,\r\nkiov->kiov_offset + offset);\r\nsg++;\r\noffset = 0;\r\nkiov++;\r\nnkiov--;\r\nnob -= fragnob;\r\n} while (nob > 0);\r\nreturn kiblnd_map_tx(ni, tx, rd, sg - tx->tx_frags);\r\n}\r\nint\r\nkiblnd_post_tx_locked (kib_conn_t *conn, kib_tx_t *tx, int credit)\r\n{\r\nkib_msg_t *msg = tx->tx_msg;\r\nkib_peer_t *peer = conn->ibc_peer;\r\nint ver = conn->ibc_version;\r\nint rc;\r\nint done;\r\nstruct ib_send_wr *bad_wrq;\r\nLASSERT (tx->tx_queued);\r\nLASSERT (tx->tx_nwrq > 0);\r\nLASSERT (tx->tx_nwrq <= 1 + IBLND_RDMA_FRAGS(ver));\r\nLASSERT (credit == 0 || credit == 1);\r\nLASSERT (conn->ibc_outstanding_credits >= 0);\r\nLASSERT (conn->ibc_outstanding_credits <= IBLND_MSG_QUEUE_SIZE(ver));\r\nLASSERT (conn->ibc_credits >= 0);\r\nLASSERT (conn->ibc_credits <= IBLND_MSG_QUEUE_SIZE(ver));\r\nif (conn->ibc_nsends_posted == IBLND_CONCURRENT_SENDS(ver)) {\r\nCDEBUG(D_NET, "%s: posted enough\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\nreturn -EAGAIN;\r\n}\r\nif (credit != 0 && conn->ibc_credits == 0) {\r\nCDEBUG(D_NET, "%s: no credits\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\nreturn -EAGAIN;\r\n}\r\nif (credit != 0 && !IBLND_OOB_CAPABLE(ver) &&\r\nconn->ibc_credits == 1 &&\r\nmsg->ibm_type != IBLND_MSG_NOOP) {\r\nCDEBUG(D_NET, "%s: not using last credit\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\nreturn -EAGAIN;\r\n}\r\nlist_del(&tx->tx_list);\r\ntx->tx_queued = 0;\r\nif (msg->ibm_type == IBLND_MSG_NOOP &&\r\n(!kiblnd_need_noop(conn) ||\r\n(IBLND_OOB_CAPABLE(ver) &&\r\nconn->ibc_noops_posted == IBLND_OOB_MSGS(ver)))) {\r\nspin_unlock(&conn->ibc_lock);\r\nkiblnd_tx_done(peer->ibp_ni, tx);\r\nspin_lock(&conn->ibc_lock);\r\nCDEBUG(D_NET, "%s(%d): redundant or enough NOOP\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\nconn->ibc_noops_posted);\r\nreturn 0;\r\n}\r\nkiblnd_pack_msg(peer->ibp_ni, msg, ver, conn->ibc_outstanding_credits,\r\npeer->ibp_nid, conn->ibc_incarnation);\r\nconn->ibc_credits -= credit;\r\nconn->ibc_outstanding_credits = 0;\r\nconn->ibc_nsends_posted++;\r\nif (msg->ibm_type == IBLND_MSG_NOOP)\r\nconn->ibc_noops_posted++;\r\ntx->tx_sending++;\r\nlist_add(&tx->tx_list, &conn->ibc_active_txs);\r\nif (conn->ibc_state != IBLND_CONN_ESTABLISHED) {\r\nrc = -ECONNABORTED;\r\n} else if (tx->tx_pool->tpo_pool.po_failed ||\r\nconn->ibc_hdev != tx->tx_pool->tpo_hdev) {\r\nrc = -ENETDOWN;\r\n} else {\r\nrc = ib_post_send(conn->ibc_cmid->qp,\r\ntx->tx_wrq, &bad_wrq);\r\n}\r\nconn->ibc_last_send = jiffies;\r\nif (rc == 0)\r\nreturn 0;\r\nconn->ibc_credits += credit;\r\nconn->ibc_outstanding_credits += msg->ibm_credits;\r\nconn->ibc_nsends_posted--;\r\nif (msg->ibm_type == IBLND_MSG_NOOP)\r\nconn->ibc_noops_posted--;\r\ntx->tx_status = rc;\r\ntx->tx_waiting = 0;\r\ntx->tx_sending--;\r\ndone = (tx->tx_sending == 0);\r\nif (done)\r\nlist_del(&tx->tx_list);\r\nspin_unlock(&conn->ibc_lock);\r\nif (conn->ibc_state == IBLND_CONN_ESTABLISHED)\r\nCERROR("Error %d posting transmit to %s\n",\r\nrc, libcfs_nid2str(peer->ibp_nid));\r\nelse\r\nCDEBUG(D_NET, "Error %d posting transmit to %s\n",\r\nrc, libcfs_nid2str(peer->ibp_nid));\r\nkiblnd_close_conn(conn, rc);\r\nif (done)\r\nkiblnd_tx_done(peer->ibp_ni, tx);\r\nspin_lock(&conn->ibc_lock);\r\nreturn -EIO;\r\n}\r\nvoid\r\nkiblnd_check_sends (kib_conn_t *conn)\r\n{\r\nint ver = conn->ibc_version;\r\nlnet_ni_t *ni = conn->ibc_peer->ibp_ni;\r\nkib_tx_t *tx;\r\nif (conn->ibc_state < IBLND_CONN_ESTABLISHED) {\r\nCDEBUG(D_NET, "%s too soon\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nreturn;\r\n}\r\nspin_lock(&conn->ibc_lock);\r\nLASSERT (conn->ibc_nsends_posted <= IBLND_CONCURRENT_SENDS(ver));\r\nLASSERT (!IBLND_OOB_CAPABLE(ver) ||\r\nconn->ibc_noops_posted <= IBLND_OOB_MSGS(ver));\r\nLASSERT (conn->ibc_reserved_credits >= 0);\r\nwhile (conn->ibc_reserved_credits > 0 &&\r\n!list_empty(&conn->ibc_tx_queue_rsrvd)) {\r\ntx = list_entry(conn->ibc_tx_queue_rsrvd.next,\r\nkib_tx_t, tx_list);\r\nlist_del(&tx->tx_list);\r\nlist_add_tail(&tx->tx_list, &conn->ibc_tx_queue);\r\nconn->ibc_reserved_credits--;\r\n}\r\nif (kiblnd_need_noop(conn)) {\r\nspin_unlock(&conn->ibc_lock);\r\ntx = kiblnd_get_idle_tx(ni, conn->ibc_peer->ibp_nid);\r\nif (tx != NULL)\r\nkiblnd_init_tx_msg(ni, tx, IBLND_MSG_NOOP, 0);\r\nspin_lock(&conn->ibc_lock);\r\nif (tx != NULL)\r\nkiblnd_queue_tx_locked(tx, conn);\r\n}\r\nkiblnd_conn_addref(conn);\r\nfor (;;) {\r\nint credit;\r\nif (!list_empty(&conn->ibc_tx_queue_nocred)) {\r\ncredit = 0;\r\ntx = list_entry(conn->ibc_tx_queue_nocred.next,\r\nkib_tx_t, tx_list);\r\n} else if (!list_empty(&conn->ibc_tx_noops)) {\r\nLASSERT (!IBLND_OOB_CAPABLE(ver));\r\ncredit = 1;\r\ntx = list_entry(conn->ibc_tx_noops.next,\r\nkib_tx_t, tx_list);\r\n} else if (!list_empty(&conn->ibc_tx_queue)) {\r\ncredit = 1;\r\ntx = list_entry(conn->ibc_tx_queue.next,\r\nkib_tx_t, tx_list);\r\n} else\r\nbreak;\r\nif (kiblnd_post_tx_locked(conn, tx, credit) != 0)\r\nbreak;\r\n}\r\nspin_unlock(&conn->ibc_lock);\r\nkiblnd_conn_decref(conn);\r\n}\r\nvoid\r\nkiblnd_tx_complete (kib_tx_t *tx, int status)\r\n{\r\nint failed = (status != IB_WC_SUCCESS);\r\nkib_conn_t *conn = tx->tx_conn;\r\nint idle;\r\nLASSERT (tx->tx_sending > 0);\r\nif (failed) {\r\nif (conn->ibc_state == IBLND_CONN_ESTABLISHED)\r\nCNETERR("Tx -> %s cookie "LPX64\r\n" sending %d waiting %d: failed %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid),\r\ntx->tx_cookie, tx->tx_sending, tx->tx_waiting,\r\nstatus);\r\nkiblnd_close_conn(conn, -EIO);\r\n} else {\r\nkiblnd_peer_alive(conn->ibc_peer);\r\n}\r\nspin_lock(&conn->ibc_lock);\r\ntx->tx_sending--;\r\nconn->ibc_nsends_posted--;\r\nif (tx->tx_msg->ibm_type == IBLND_MSG_NOOP)\r\nconn->ibc_noops_posted--;\r\nif (failed) {\r\ntx->tx_waiting = 0;\r\ntx->tx_status = -EIO;\r\n}\r\nidle = (tx->tx_sending == 0) &&\r\n!tx->tx_waiting &&\r\n!tx->tx_queued;\r\nif (idle)\r\nlist_del(&tx->tx_list);\r\nkiblnd_conn_addref(conn);\r\nspin_unlock(&conn->ibc_lock);\r\nif (idle)\r\nkiblnd_tx_done(conn->ibc_peer->ibp_ni, tx);\r\nkiblnd_check_sends(conn);\r\nkiblnd_conn_decref(conn);\r\n}\r\nvoid\r\nkiblnd_init_tx_msg (lnet_ni_t *ni, kib_tx_t *tx, int type, int body_nob)\r\n{\r\nkib_hca_dev_t *hdev = tx->tx_pool->tpo_hdev;\r\nstruct ib_sge *sge = &tx->tx_sge[tx->tx_nwrq];\r\nstruct ib_send_wr *wrq = &tx->tx_wrq[tx->tx_nwrq];\r\nint nob = offsetof (kib_msg_t, ibm_u) + body_nob;\r\nstruct ib_mr *mr;\r\nLASSERT (tx->tx_nwrq >= 0);\r\nLASSERT (tx->tx_nwrq < IBLND_MAX_RDMA_FRAGS + 1);\r\nLASSERT (nob <= IBLND_MSG_SIZE);\r\nkiblnd_init_msg(tx->tx_msg, type, body_nob);\r\nmr = kiblnd_find_dma_mr(hdev, tx->tx_msgaddr, nob);\r\nLASSERT (mr != NULL);\r\nsge->lkey = mr->lkey;\r\nsge->addr = tx->tx_msgaddr;\r\nsge->length = nob;\r\nmemset(wrq, 0, sizeof(*wrq));\r\nwrq->next = NULL;\r\nwrq->wr_id = kiblnd_ptr2wreqid(tx, IBLND_WID_TX);\r\nwrq->sg_list = sge;\r\nwrq->num_sge = 1;\r\nwrq->opcode = IB_WR_SEND;\r\nwrq->send_flags = IB_SEND_SIGNALED;\r\ntx->tx_nwrq++;\r\n}\r\nint\r\nkiblnd_init_rdma (kib_conn_t *conn, kib_tx_t *tx, int type,\r\nint resid, kib_rdma_desc_t *dstrd, __u64 dstcookie)\r\n{\r\nkib_msg_t *ibmsg = tx->tx_msg;\r\nkib_rdma_desc_t *srcrd = tx->tx_rd;\r\nstruct ib_sge *sge = &tx->tx_sge[0];\r\nstruct ib_send_wr *wrq = &tx->tx_wrq[0];\r\nint rc = resid;\r\nint srcidx;\r\nint dstidx;\r\nint wrknob;\r\nLASSERT (!in_interrupt());\r\nLASSERT (tx->tx_nwrq == 0);\r\nLASSERT (type == IBLND_MSG_GET_DONE ||\r\ntype == IBLND_MSG_PUT_DONE);\r\nsrcidx = dstidx = 0;\r\nwhile (resid > 0) {\r\nif (srcidx >= srcrd->rd_nfrags) {\r\nCERROR("Src buffer exhausted: %d frags\n", srcidx);\r\nrc = -EPROTO;\r\nbreak;\r\n}\r\nif (dstidx == dstrd->rd_nfrags) {\r\nCERROR("Dst buffer exhausted: %d frags\n", dstidx);\r\nrc = -EPROTO;\r\nbreak;\r\n}\r\nif (tx->tx_nwrq == IBLND_RDMA_FRAGS(conn->ibc_version)) {\r\nCERROR("RDMA too fragmented for %s (%d): "\r\n"%d/%d src %d/%d dst frags\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid),\r\nIBLND_RDMA_FRAGS(conn->ibc_version),\r\nsrcidx, srcrd->rd_nfrags,\r\ndstidx, dstrd->rd_nfrags);\r\nrc = -EMSGSIZE;\r\nbreak;\r\n}\r\nwrknob = MIN(MIN(kiblnd_rd_frag_size(srcrd, srcidx),\r\nkiblnd_rd_frag_size(dstrd, dstidx)), resid);\r\nsge = &tx->tx_sge[tx->tx_nwrq];\r\nsge->addr = kiblnd_rd_frag_addr(srcrd, srcidx);\r\nsge->lkey = kiblnd_rd_frag_key(srcrd, srcidx);\r\nsge->length = wrknob;\r\nwrq = &tx->tx_wrq[tx->tx_nwrq];\r\nwrq->next = wrq + 1;\r\nwrq->wr_id = kiblnd_ptr2wreqid(tx, IBLND_WID_RDMA);\r\nwrq->sg_list = sge;\r\nwrq->num_sge = 1;\r\nwrq->opcode = IB_WR_RDMA_WRITE;\r\nwrq->send_flags = 0;\r\nwrq->wr.rdma.remote_addr = kiblnd_rd_frag_addr(dstrd, dstidx);\r\nwrq->wr.rdma.rkey = kiblnd_rd_frag_key(dstrd, dstidx);\r\nsrcidx = kiblnd_rd_consume_frag(srcrd, srcidx, wrknob);\r\ndstidx = kiblnd_rd_consume_frag(dstrd, dstidx, wrknob);\r\nresid -= wrknob;\r\ntx->tx_nwrq++;\r\nwrq++;\r\nsge++;\r\n}\r\nif (rc < 0)\r\ntx->tx_nwrq = 0;\r\nibmsg->ibm_u.completion.ibcm_status = rc;\r\nibmsg->ibm_u.completion.ibcm_cookie = dstcookie;\r\nkiblnd_init_tx_msg(conn->ibc_peer->ibp_ni, tx,\r\ntype, sizeof (kib_completion_msg_t));\r\nreturn rc;\r\n}\r\nvoid\r\nkiblnd_queue_tx_locked (kib_tx_t *tx, kib_conn_t *conn)\r\n{\r\nstruct list_head *q;\r\nLASSERT (tx->tx_nwrq > 0);\r\nLASSERT (!tx->tx_queued);\r\nLASSERT (conn->ibc_state >= IBLND_CONN_ESTABLISHED);\r\ntx->tx_queued = 1;\r\ntx->tx_deadline = jiffies + (*kiblnd_tunables.kib_timeout * HZ);\r\nif (tx->tx_conn == NULL) {\r\nkiblnd_conn_addref(conn);\r\ntx->tx_conn = conn;\r\nLASSERT (tx->tx_msg->ibm_type != IBLND_MSG_PUT_DONE);\r\n} else {\r\nLASSERT (tx->tx_conn == conn);\r\nLASSERT (tx->tx_msg->ibm_type == IBLND_MSG_PUT_DONE);\r\n}\r\nswitch (tx->tx_msg->ibm_type) {\r\ndefault:\r\nLBUG();\r\ncase IBLND_MSG_PUT_REQ:\r\ncase IBLND_MSG_GET_REQ:\r\nq = &conn->ibc_tx_queue_rsrvd;\r\nbreak;\r\ncase IBLND_MSG_PUT_NAK:\r\ncase IBLND_MSG_PUT_ACK:\r\ncase IBLND_MSG_PUT_DONE:\r\ncase IBLND_MSG_GET_DONE:\r\nq = &conn->ibc_tx_queue_nocred;\r\nbreak;\r\ncase IBLND_MSG_NOOP:\r\nif (IBLND_OOB_CAPABLE(conn->ibc_version))\r\nq = &conn->ibc_tx_queue_nocred;\r\nelse\r\nq = &conn->ibc_tx_noops;\r\nbreak;\r\ncase IBLND_MSG_IMMEDIATE:\r\nq = &conn->ibc_tx_queue;\r\nbreak;\r\n}\r\nlist_add_tail(&tx->tx_list, q);\r\n}\r\nvoid\r\nkiblnd_queue_tx (kib_tx_t *tx, kib_conn_t *conn)\r\n{\r\nspin_lock(&conn->ibc_lock);\r\nkiblnd_queue_tx_locked(tx, conn);\r\nspin_unlock(&conn->ibc_lock);\r\nkiblnd_check_sends(conn);\r\n}\r\nstatic int kiblnd_resolve_addr(struct rdma_cm_id *cmid,\r\nstruct sockaddr_in *srcaddr,\r\nstruct sockaddr_in *dstaddr,\r\nint timeout_ms)\r\n{\r\nunsigned short port;\r\nint rc;\r\nrc = rdma_set_reuseaddr(cmid, 1);\r\nif (rc != 0) {\r\nCERROR("Unable to set reuse on cmid: %d\n", rc);\r\nreturn rc;\r\n}\r\nfor (port = PROT_SOCK-1; port > 0; port--) {\r\nsrcaddr->sin_port = htons(port);\r\nrc = rdma_resolve_addr(cmid,\r\n(struct sockaddr *)srcaddr,\r\n(struct sockaddr *)dstaddr,\r\ntimeout_ms);\r\nif (rc == 0) {\r\nCDEBUG(D_NET, "bound to port %hu\n", port);\r\nreturn 0;\r\n} else if (rc == -EADDRINUSE || rc == -EADDRNOTAVAIL) {\r\nCDEBUG(D_NET, "bind to port %hu failed: %d\n",\r\nport, rc);\r\n} else {\r\nreturn rc;\r\n}\r\n}\r\nCERROR("Failed to bind to a free privileged port\n");\r\nreturn rc;\r\n}\r\nvoid\r\nkiblnd_connect_peer (kib_peer_t *peer)\r\n{\r\nstruct rdma_cm_id *cmid;\r\nkib_dev_t *dev;\r\nkib_net_t *net = peer->ibp_ni->ni_data;\r\nstruct sockaddr_in srcaddr;\r\nstruct sockaddr_in dstaddr;\r\nint rc;\r\nLASSERT (net != NULL);\r\nLASSERT (peer->ibp_connecting > 0);\r\ncmid = kiblnd_rdma_create_id(kiblnd_cm_callback, peer, RDMA_PS_TCP,\r\nIB_QPT_RC);\r\nif (IS_ERR(cmid)) {\r\nCERROR("Can't create CMID for %s: %ld\n",\r\nlibcfs_nid2str(peer->ibp_nid), PTR_ERR(cmid));\r\nrc = PTR_ERR(cmid);\r\ngoto failed;\r\n}\r\ndev = net->ibn_dev;\r\nmemset(&srcaddr, 0, sizeof(srcaddr));\r\nsrcaddr.sin_family = AF_INET;\r\nsrcaddr.sin_addr.s_addr = htonl(dev->ibd_ifip);\r\nmemset(&dstaddr, 0, sizeof(dstaddr));\r\ndstaddr.sin_family = AF_INET;\r\ndstaddr.sin_port = htons(*kiblnd_tunables.kib_service);\r\ndstaddr.sin_addr.s_addr = htonl(LNET_NIDADDR(peer->ibp_nid));\r\nkiblnd_peer_addref(peer);\r\nif (*kiblnd_tunables.kib_use_priv_port) {\r\nrc = kiblnd_resolve_addr(cmid, &srcaddr, &dstaddr,\r\n*kiblnd_tunables.kib_timeout * 1000);\r\n} else {\r\nrc = rdma_resolve_addr(cmid,\r\n(struct sockaddr *)&srcaddr,\r\n(struct sockaddr *)&dstaddr,\r\n*kiblnd_tunables.kib_timeout * 1000);\r\n}\r\nif (rc != 0) {\r\nCERROR("Can't resolve addr for %s: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), rc);\r\ngoto failed2;\r\n}\r\nLASSERT (cmid->device != NULL);\r\nCDEBUG(D_NET, "%s: connection bound to %s:%pI4h:%s\n",\r\nlibcfs_nid2str(peer->ibp_nid), dev->ibd_ifname,\r\n&dev->ibd_ifip, cmid->device->name);\r\nreturn;\r\nfailed2:\r\nkiblnd_peer_decref(peer);\r\nrdma_destroy_id(cmid);\r\nfailed:\r\nkiblnd_peer_connect_failed(peer, 1, rc);\r\n}\r\nvoid\r\nkiblnd_launch_tx (lnet_ni_t *ni, kib_tx_t *tx, lnet_nid_t nid)\r\n{\r\nkib_peer_t *peer;\r\nkib_peer_t *peer2;\r\nkib_conn_t *conn;\r\nrwlock_t *g_lock = &kiblnd_data.kib_global_lock;\r\nunsigned long flags;\r\nint rc;\r\nLASSERT (tx == NULL || tx->tx_conn == NULL);\r\nLASSERT (tx == NULL || tx->tx_nwrq > 0);\r\nread_lock_irqsave(g_lock, flags);\r\npeer = kiblnd_find_peer_locked(nid);\r\nif (peer != NULL && !list_empty(&peer->ibp_conns)) {\r\nconn = kiblnd_get_conn_locked(peer);\r\nkiblnd_conn_addref(conn);\r\nread_unlock_irqrestore(g_lock, flags);\r\nif (tx != NULL)\r\nkiblnd_queue_tx(tx, conn);\r\nkiblnd_conn_decref(conn);\r\nreturn;\r\n}\r\nread_unlock(g_lock);\r\nwrite_lock(g_lock);\r\npeer = kiblnd_find_peer_locked(nid);\r\nif (peer != NULL) {\r\nif (list_empty(&peer->ibp_conns)) {\r\nLASSERT (peer->ibp_connecting != 0 ||\r\npeer->ibp_accepting != 0);\r\nif (tx != NULL)\r\nlist_add_tail(&tx->tx_list,\r\n&peer->ibp_tx_queue);\r\nwrite_unlock_irqrestore(g_lock, flags);\r\n} else {\r\nconn = kiblnd_get_conn_locked(peer);\r\nkiblnd_conn_addref(conn);\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nif (tx != NULL)\r\nkiblnd_queue_tx(tx, conn);\r\nkiblnd_conn_decref(conn);\r\n}\r\nreturn;\r\n}\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nrc = kiblnd_create_peer(ni, &peer, nid);\r\nif (rc != 0) {\r\nCERROR("Can't create peer %s\n", libcfs_nid2str(nid));\r\nif (tx != NULL) {\r\ntx->tx_status = -EHOSTUNREACH;\r\ntx->tx_waiting = 0;\r\nkiblnd_tx_done(ni, tx);\r\n}\r\nreturn;\r\n}\r\nwrite_lock_irqsave(g_lock, flags);\r\npeer2 = kiblnd_find_peer_locked(nid);\r\nif (peer2 != NULL) {\r\nif (list_empty(&peer2->ibp_conns)) {\r\nLASSERT (peer2->ibp_connecting != 0 ||\r\npeer2->ibp_accepting != 0);\r\nif (tx != NULL)\r\nlist_add_tail(&tx->tx_list,\r\n&peer2->ibp_tx_queue);\r\nwrite_unlock_irqrestore(g_lock, flags);\r\n} else {\r\nconn = kiblnd_get_conn_locked(peer2);\r\nkiblnd_conn_addref(conn);\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nif (tx != NULL)\r\nkiblnd_queue_tx(tx, conn);\r\nkiblnd_conn_decref(conn);\r\n}\r\nkiblnd_peer_decref(peer);\r\nreturn;\r\n}\r\nLASSERT (peer->ibp_connecting == 0);\r\npeer->ibp_connecting = 1;\r\nLASSERT (((kib_net_t *)ni->ni_data)->ibn_shutdown == 0);\r\nif (tx != NULL)\r\nlist_add_tail(&tx->tx_list, &peer->ibp_tx_queue);\r\nkiblnd_peer_addref(peer);\r\nlist_add_tail(&peer->ibp_list, kiblnd_nid2peerlist(nid));\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nkiblnd_connect_peer(peer);\r\nkiblnd_peer_decref(peer);\r\n}\r\nint\r\nkiblnd_send (lnet_ni_t *ni, void *private, lnet_msg_t *lntmsg)\r\n{\r\nlnet_hdr_t *hdr = &lntmsg->msg_hdr;\r\nint type = lntmsg->msg_type;\r\nlnet_process_id_t target = lntmsg->msg_target;\r\nint target_is_router = lntmsg->msg_target_is_router;\r\nint routing = lntmsg->msg_routing;\r\nunsigned int payload_niov = lntmsg->msg_niov;\r\nstruct iovec *payload_iov = lntmsg->msg_iov;\r\nlnet_kiov_t *payload_kiov = lntmsg->msg_kiov;\r\nunsigned int payload_offset = lntmsg->msg_offset;\r\nunsigned int payload_nob = lntmsg->msg_len;\r\nkib_msg_t *ibmsg;\r\nkib_tx_t *tx;\r\nint nob;\r\nint rc;\r\nCDEBUG(D_NET, "sending %d bytes in %d frags to %s\n",\r\npayload_nob, payload_niov, libcfs_id2str(target));\r\nLASSERT (payload_nob == 0 || payload_niov > 0);\r\nLASSERT (payload_niov <= LNET_MAX_IOV);\r\nLASSERT (!in_interrupt());\r\nLASSERT (!(payload_kiov != NULL && payload_iov != NULL));\r\nswitch (type) {\r\ndefault:\r\nLBUG();\r\nreturn (-EIO);\r\ncase LNET_MSG_ACK:\r\nLASSERT (payload_nob == 0);\r\nbreak;\r\ncase LNET_MSG_GET:\r\nif (routing || target_is_router)\r\nbreak;\r\nnob = offsetof(kib_msg_t, ibm_u.immediate.ibim_payload[lntmsg->msg_md->md_length]);\r\nif (nob <= IBLND_MSG_SIZE)\r\nbreak;\r\ntx = kiblnd_get_idle_tx(ni, target.nid);\r\nif (tx == NULL) {\r\nCERROR("Can't allocate txd for GET to %s\n",\r\nlibcfs_nid2str(target.nid));\r\nreturn -ENOMEM;\r\n}\r\nibmsg = tx->tx_msg;\r\nif ((lntmsg->msg_md->md_options & LNET_MD_KIOV) == 0)\r\nrc = kiblnd_setup_rd_iov(ni, tx,\r\n&ibmsg->ibm_u.get.ibgm_rd,\r\nlntmsg->msg_md->md_niov,\r\nlntmsg->msg_md->md_iov.iov,\r\n0, lntmsg->msg_md->md_length);\r\nelse\r\nrc = kiblnd_setup_rd_kiov(ni, tx,\r\n&ibmsg->ibm_u.get.ibgm_rd,\r\nlntmsg->msg_md->md_niov,\r\nlntmsg->msg_md->md_iov.kiov,\r\n0, lntmsg->msg_md->md_length);\r\nif (rc != 0) {\r\nCERROR("Can't setup GET sink for %s: %d\n",\r\nlibcfs_nid2str(target.nid), rc);\r\nkiblnd_tx_done(ni, tx);\r\nreturn -EIO;\r\n}\r\nnob = offsetof(kib_get_msg_t, ibgm_rd.rd_frags[tx->tx_nfrags]);\r\nibmsg->ibm_u.get.ibgm_cookie = tx->tx_cookie;\r\nibmsg->ibm_u.get.ibgm_hdr = *hdr;\r\nkiblnd_init_tx_msg(ni, tx, IBLND_MSG_GET_REQ, nob);\r\ntx->tx_lntmsg[1] = lnet_create_reply_msg(ni, lntmsg);\r\nif (tx->tx_lntmsg[1] == NULL) {\r\nCERROR("Can't create reply for GET -> %s\n",\r\nlibcfs_nid2str(target.nid));\r\nkiblnd_tx_done(ni, tx);\r\nreturn -EIO;\r\n}\r\ntx->tx_lntmsg[0] = lntmsg;\r\ntx->tx_waiting = 1;\r\nkiblnd_launch_tx(ni, tx, target.nid);\r\nreturn 0;\r\ncase LNET_MSG_REPLY:\r\ncase LNET_MSG_PUT:\r\nnob = offsetof(kib_msg_t, ibm_u.immediate.ibim_payload[payload_nob]);\r\nif (nob <= IBLND_MSG_SIZE)\r\nbreak;\r\ntx = kiblnd_get_idle_tx(ni, target.nid);\r\nif (tx == NULL) {\r\nCERROR("Can't allocate %s txd for %s\n",\r\ntype == LNET_MSG_PUT ? "PUT" : "REPLY",\r\nlibcfs_nid2str(target.nid));\r\nreturn -ENOMEM;\r\n}\r\nif (payload_kiov == NULL)\r\nrc = kiblnd_setup_rd_iov(ni, tx, tx->tx_rd,\r\npayload_niov, payload_iov,\r\npayload_offset, payload_nob);\r\nelse\r\nrc = kiblnd_setup_rd_kiov(ni, tx, tx->tx_rd,\r\npayload_niov, payload_kiov,\r\npayload_offset, payload_nob);\r\nif (rc != 0) {\r\nCERROR("Can't setup PUT src for %s: %d\n",\r\nlibcfs_nid2str(target.nid), rc);\r\nkiblnd_tx_done(ni, tx);\r\nreturn -EIO;\r\n}\r\nibmsg = tx->tx_msg;\r\nibmsg->ibm_u.putreq.ibprm_hdr = *hdr;\r\nibmsg->ibm_u.putreq.ibprm_cookie = tx->tx_cookie;\r\nkiblnd_init_tx_msg(ni, tx, IBLND_MSG_PUT_REQ, sizeof(kib_putreq_msg_t));\r\ntx->tx_lntmsg[0] = lntmsg;\r\ntx->tx_waiting = 1;\r\nkiblnd_launch_tx(ni, tx, target.nid);\r\nreturn 0;\r\n}\r\nLASSERT (offsetof(kib_msg_t, ibm_u.immediate.ibim_payload[payload_nob])\r\n<= IBLND_MSG_SIZE);\r\ntx = kiblnd_get_idle_tx(ni, target.nid);\r\nif (tx == NULL) {\r\nCERROR ("Can't send %d to %s: tx descs exhausted\n",\r\ntype, libcfs_nid2str(target.nid));\r\nreturn -ENOMEM;\r\n}\r\nibmsg = tx->tx_msg;\r\nibmsg->ibm_u.immediate.ibim_hdr = *hdr;\r\nif (payload_kiov != NULL)\r\nlnet_copy_kiov2flat(IBLND_MSG_SIZE, ibmsg,\r\noffsetof(kib_msg_t, ibm_u.immediate.ibim_payload),\r\npayload_niov, payload_kiov,\r\npayload_offset, payload_nob);\r\nelse\r\nlnet_copy_iov2flat(IBLND_MSG_SIZE, ibmsg,\r\noffsetof(kib_msg_t, ibm_u.immediate.ibim_payload),\r\npayload_niov, payload_iov,\r\npayload_offset, payload_nob);\r\nnob = offsetof(kib_immediate_msg_t, ibim_payload[payload_nob]);\r\nkiblnd_init_tx_msg(ni, tx, IBLND_MSG_IMMEDIATE, nob);\r\ntx->tx_lntmsg[0] = lntmsg;\r\nkiblnd_launch_tx(ni, tx, target.nid);\r\nreturn 0;\r\n}\r\nvoid\r\nkiblnd_reply (lnet_ni_t *ni, kib_rx_t *rx, lnet_msg_t *lntmsg)\r\n{\r\nlnet_process_id_t target = lntmsg->msg_target;\r\nunsigned int niov = lntmsg->msg_niov;\r\nstruct iovec *iov = lntmsg->msg_iov;\r\nlnet_kiov_t *kiov = lntmsg->msg_kiov;\r\nunsigned int offset = lntmsg->msg_offset;\r\nunsigned int nob = lntmsg->msg_len;\r\nkib_tx_t *tx;\r\nint rc;\r\ntx = kiblnd_get_idle_tx(ni, rx->rx_conn->ibc_peer->ibp_nid);\r\nif (tx == NULL) {\r\nCERROR("Can't get tx for REPLY to %s\n",\r\nlibcfs_nid2str(target.nid));\r\ngoto failed_0;\r\n}\r\nif (nob == 0)\r\nrc = 0;\r\nelse if (kiov == NULL)\r\nrc = kiblnd_setup_rd_iov(ni, tx, tx->tx_rd,\r\nniov, iov, offset, nob);\r\nelse\r\nrc = kiblnd_setup_rd_kiov(ni, tx, tx->tx_rd,\r\nniov, kiov, offset, nob);\r\nif (rc != 0) {\r\nCERROR("Can't setup GET src for %s: %d\n",\r\nlibcfs_nid2str(target.nid), rc);\r\ngoto failed_1;\r\n}\r\nrc = kiblnd_init_rdma(rx->rx_conn, tx,\r\nIBLND_MSG_GET_DONE, nob,\r\n&rx->rx_msg->ibm_u.get.ibgm_rd,\r\nrx->rx_msg->ibm_u.get.ibgm_cookie);\r\nif (rc < 0) {\r\nCERROR("Can't setup rdma for GET from %s: %d\n",\r\nlibcfs_nid2str(target.nid), rc);\r\ngoto failed_1;\r\n}\r\nif (nob == 0) {\r\nlnet_finalize(ni, lntmsg, 0);\r\n} else {\r\ntx->tx_lntmsg[0] = lntmsg;\r\n}\r\nkiblnd_queue_tx(tx, rx->rx_conn);\r\nreturn;\r\nfailed_1:\r\nkiblnd_tx_done(ni, tx);\r\nfailed_0:\r\nlnet_finalize(ni, lntmsg, -EIO);\r\n}\r\nint\r\nkiblnd_recv (lnet_ni_t *ni, void *private, lnet_msg_t *lntmsg, int delayed,\r\nunsigned int niov, struct iovec *iov, lnet_kiov_t *kiov,\r\nunsigned int offset, unsigned int mlen, unsigned int rlen)\r\n{\r\nkib_rx_t *rx = private;\r\nkib_msg_t *rxmsg = rx->rx_msg;\r\nkib_conn_t *conn = rx->rx_conn;\r\nkib_tx_t *tx;\r\nkib_msg_t *txmsg;\r\nint nob;\r\nint post_credit = IBLND_POSTRX_PEER_CREDIT;\r\nint rc = 0;\r\nLASSERT (mlen <= rlen);\r\nLASSERT (!in_interrupt());\r\nLASSERT (!(kiov != NULL && iov != NULL));\r\nswitch (rxmsg->ibm_type) {\r\ndefault:\r\nLBUG();\r\ncase IBLND_MSG_IMMEDIATE:\r\nnob = offsetof(kib_msg_t, ibm_u.immediate.ibim_payload[rlen]);\r\nif (nob > rx->rx_nob) {\r\nCERROR ("Immediate message from %s too big: %d(%d)\n",\r\nlibcfs_nid2str(rxmsg->ibm_u.immediate.ibim_hdr.src_nid),\r\nnob, rx->rx_nob);\r\nrc = -EPROTO;\r\nbreak;\r\n}\r\nif (kiov != NULL)\r\nlnet_copy_flat2kiov(niov, kiov, offset,\r\nIBLND_MSG_SIZE, rxmsg,\r\noffsetof(kib_msg_t, ibm_u.immediate.ibim_payload),\r\nmlen);\r\nelse\r\nlnet_copy_flat2iov(niov, iov, offset,\r\nIBLND_MSG_SIZE, rxmsg,\r\noffsetof(kib_msg_t, ibm_u.immediate.ibim_payload),\r\nmlen);\r\nlnet_finalize (ni, lntmsg, 0);\r\nbreak;\r\ncase IBLND_MSG_PUT_REQ:\r\nif (mlen == 0) {\r\nlnet_finalize(ni, lntmsg, 0);\r\nkiblnd_send_completion(rx->rx_conn, IBLND_MSG_PUT_NAK, 0,\r\nrxmsg->ibm_u.putreq.ibprm_cookie);\r\nbreak;\r\n}\r\ntx = kiblnd_get_idle_tx(ni, conn->ibc_peer->ibp_nid);\r\nif (tx == NULL) {\r\nCERROR("Can't allocate tx for %s\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nrc = -ENOMEM;\r\nbreak;\r\n}\r\ntxmsg = tx->tx_msg;\r\nif (kiov == NULL)\r\nrc = kiblnd_setup_rd_iov(ni, tx,\r\n&txmsg->ibm_u.putack.ibpam_rd,\r\nniov, iov, offset, mlen);\r\nelse\r\nrc = kiblnd_setup_rd_kiov(ni, tx,\r\n&txmsg->ibm_u.putack.ibpam_rd,\r\nniov, kiov, offset, mlen);\r\nif (rc != 0) {\r\nCERROR("Can't setup PUT sink for %s: %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), rc);\r\nkiblnd_tx_done(ni, tx);\r\nkiblnd_send_completion(rx->rx_conn, IBLND_MSG_PUT_NAK, rc,\r\nrxmsg->ibm_u.putreq.ibprm_cookie);\r\nbreak;\r\n}\r\nnob = offsetof(kib_putack_msg_t, ibpam_rd.rd_frags[tx->tx_nfrags]);\r\ntxmsg->ibm_u.putack.ibpam_src_cookie = rxmsg->ibm_u.putreq.ibprm_cookie;\r\ntxmsg->ibm_u.putack.ibpam_dst_cookie = tx->tx_cookie;\r\nkiblnd_init_tx_msg(ni, tx, IBLND_MSG_PUT_ACK, nob);\r\ntx->tx_lntmsg[0] = lntmsg;\r\ntx->tx_waiting = 1;\r\nkiblnd_queue_tx(tx, conn);\r\npost_credit = IBLND_POSTRX_NO_CREDIT;\r\nbreak;\r\ncase IBLND_MSG_GET_REQ:\r\nif (lntmsg != NULL) {\r\nkiblnd_reply(ni, rx, lntmsg);\r\n} else {\r\nkiblnd_send_completion(rx->rx_conn, IBLND_MSG_GET_DONE,\r\n-ENODATA,\r\nrxmsg->ibm_u.get.ibgm_cookie);\r\n}\r\nbreak;\r\n}\r\nkiblnd_post_rx(rx, post_credit);\r\nreturn rc;\r\n}\r\nint\r\nkiblnd_thread_start(int (*fn)(void *arg), void *arg, char *name)\r\n{\r\nstruct task_struct *task = kthread_run(fn, arg, "%s", name);\r\nif (IS_ERR(task))\r\nreturn PTR_ERR(task);\r\natomic_inc(&kiblnd_data.kib_nthreads);\r\nreturn 0;\r\n}\r\nvoid\r\nkiblnd_thread_fini (void)\r\n{\r\natomic_dec (&kiblnd_data.kib_nthreads);\r\n}\r\nvoid\r\nkiblnd_peer_alive (kib_peer_t *peer)\r\n{\r\npeer->ibp_last_alive = cfs_time_current();\r\nmb();\r\n}\r\nvoid\r\nkiblnd_peer_notify (kib_peer_t *peer)\r\n{\r\nint error = 0;\r\ncfs_time_t last_alive = 0;\r\nunsigned long flags;\r\nread_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nif (list_empty(&peer->ibp_conns) &&\r\npeer->ibp_accepting == 0 &&\r\npeer->ibp_connecting == 0 &&\r\npeer->ibp_error != 0) {\r\nerror = peer->ibp_error;\r\npeer->ibp_error = 0;\r\nlast_alive = peer->ibp_last_alive;\r\n}\r\nread_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nif (error != 0)\r\nlnet_notify(peer->ibp_ni,\r\npeer->ibp_nid, 0, last_alive);\r\n}\r\nvoid\r\nkiblnd_close_conn_locked (kib_conn_t *conn, int error)\r\n{\r\nkib_peer_t *peer = conn->ibc_peer;\r\nkib_dev_t *dev;\r\nunsigned long flags;\r\nLASSERT (error != 0 || conn->ibc_state >= IBLND_CONN_ESTABLISHED);\r\nif (error != 0 && conn->ibc_comms_error == 0)\r\nconn->ibc_comms_error = error;\r\nif (conn->ibc_state != IBLND_CONN_ESTABLISHED)\r\nreturn;\r\nif (error == 0 &&\r\nlist_empty(&conn->ibc_tx_noops) &&\r\nlist_empty(&conn->ibc_tx_queue) &&\r\nlist_empty(&conn->ibc_tx_queue_rsrvd) &&\r\nlist_empty(&conn->ibc_tx_queue_nocred) &&\r\nlist_empty(&conn->ibc_active_txs)) {\r\nCDEBUG(D_NET, "closing conn to %s\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\n} else {\r\nCNETERR("Closing conn to %s: error %d%s%s%s%s%s\n",\r\nlibcfs_nid2str(peer->ibp_nid), error,\r\nlist_empty(&conn->ibc_tx_queue) ? "" : "(sending)",\r\nlist_empty(&conn->ibc_tx_noops) ? "" : "(sending_noops)",\r\nlist_empty(&conn->ibc_tx_queue_rsrvd) ? "" : "(sending_rsrvd)",\r\nlist_empty(&conn->ibc_tx_queue_nocred) ? "" : "(sending_nocred)",\r\nlist_empty(&conn->ibc_active_txs) ? "" : "(waiting)");\r\n}\r\ndev = ((kib_net_t *)peer->ibp_ni->ni_data)->ibn_dev;\r\nlist_del(&conn->ibc_list);\r\nif (list_empty (&peer->ibp_conns) &&\r\nkiblnd_peer_active(peer)) {\r\nkiblnd_unlink_peer_locked(peer);\r\npeer->ibp_error = conn->ibc_comms_error;\r\n}\r\nkiblnd_set_conn_state(conn, IBLND_CONN_CLOSING);\r\nif (error != 0 &&\r\nkiblnd_dev_can_failover(dev)) {\r\nlist_add_tail(&dev->ibd_fail_list,\r\n&kiblnd_data.kib_failed_devs);\r\nwake_up(&kiblnd_data.kib_failover_waitq);\r\n}\r\nspin_lock_irqsave(&kiblnd_data.kib_connd_lock, flags);\r\nlist_add_tail(&conn->ibc_list, &kiblnd_data.kib_connd_conns);\r\nwake_up(&kiblnd_data.kib_connd_waitq);\r\nspin_unlock_irqrestore(&kiblnd_data.kib_connd_lock, flags);\r\n}\r\nvoid\r\nkiblnd_close_conn(kib_conn_t *conn, int error)\r\n{\r\nunsigned long flags;\r\nwrite_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nkiblnd_close_conn_locked(conn, error);\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\n}\r\nvoid\r\nkiblnd_handle_early_rxs(kib_conn_t *conn)\r\n{\r\nunsigned long flags;\r\nkib_rx_t *rx;\r\nLASSERT(!in_interrupt());\r\nLASSERT(conn->ibc_state >= IBLND_CONN_ESTABLISHED);\r\nwrite_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nwhile (!list_empty(&conn->ibc_early_rxs)) {\r\nrx = list_entry(conn->ibc_early_rxs.next,\r\nkib_rx_t, rx_list);\r\nlist_del(&rx->rx_list);\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nkiblnd_handle_rx(rx);\r\nwrite_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\n}\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\n}\r\nvoid\r\nkiblnd_abort_txs(kib_conn_t *conn, struct list_head *txs)\r\n{\r\nLIST_HEAD (zombies);\r\nstruct list_head *tmp;\r\nstruct list_head *nxt;\r\nkib_tx_t *tx;\r\nspin_lock(&conn->ibc_lock);\r\nlist_for_each_safe (tmp, nxt, txs) {\r\ntx = list_entry (tmp, kib_tx_t, tx_list);\r\nif (txs == &conn->ibc_active_txs) {\r\nLASSERT (!tx->tx_queued);\r\nLASSERT (tx->tx_waiting ||\r\ntx->tx_sending != 0);\r\n} else {\r\nLASSERT (tx->tx_queued);\r\n}\r\ntx->tx_status = -ECONNABORTED;\r\ntx->tx_waiting = 0;\r\nif (tx->tx_sending == 0) {\r\ntx->tx_queued = 0;\r\nlist_del (&tx->tx_list);\r\nlist_add (&tx->tx_list, &zombies);\r\n}\r\n}\r\nspin_unlock(&conn->ibc_lock);\r\nkiblnd_txlist_done(conn->ibc_peer->ibp_ni, &zombies, -ECONNABORTED);\r\n}\r\nvoid\r\nkiblnd_finalise_conn (kib_conn_t *conn)\r\n{\r\nLASSERT (!in_interrupt());\r\nLASSERT (conn->ibc_state > IBLND_CONN_INIT);\r\nkiblnd_set_conn_state(conn, IBLND_CONN_DISCONNECTED);\r\nkiblnd_abort_receives(conn);\r\nkiblnd_abort_txs(conn, &conn->ibc_tx_noops);\r\nkiblnd_abort_txs(conn, &conn->ibc_tx_queue);\r\nkiblnd_abort_txs(conn, &conn->ibc_tx_queue_rsrvd);\r\nkiblnd_abort_txs(conn, &conn->ibc_tx_queue_nocred);\r\nkiblnd_abort_txs(conn, &conn->ibc_active_txs);\r\nkiblnd_handle_early_rxs(conn);\r\n}\r\nvoid\r\nkiblnd_peer_connect_failed (kib_peer_t *peer, int active, int error)\r\n{\r\nLIST_HEAD (zombies);\r\nunsigned long flags;\r\nLASSERT (error != 0);\r\nLASSERT (!in_interrupt());\r\nwrite_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nif (active) {\r\nLASSERT (peer->ibp_connecting > 0);\r\npeer->ibp_connecting--;\r\n} else {\r\nLASSERT (peer->ibp_accepting > 0);\r\npeer->ibp_accepting--;\r\n}\r\nif (peer->ibp_connecting != 0 ||\r\npeer->ibp_accepting != 0) {\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock,\r\nflags);\r\nreturn;\r\n}\r\nif (list_empty(&peer->ibp_conns)) {\r\nlist_add(&zombies, &peer->ibp_tx_queue);\r\nlist_del_init(&peer->ibp_tx_queue);\r\nif (kiblnd_peer_active(peer))\r\nkiblnd_unlink_peer_locked(peer);\r\npeer->ibp_error = error;\r\n} else {\r\nLASSERT (list_empty(&peer->ibp_tx_queue));\r\n}\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nkiblnd_peer_notify(peer);\r\nif (list_empty (&zombies))\r\nreturn;\r\nCNETERR("Deleting messages for %s: connection failed\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\nkiblnd_txlist_done(peer->ibp_ni, &zombies, -EHOSTUNREACH);\r\n}\r\nvoid\r\nkiblnd_connreq_done(kib_conn_t *conn, int status)\r\n{\r\nkib_peer_t *peer = conn->ibc_peer;\r\nkib_tx_t *tx;\r\nstruct list_head txs;\r\nunsigned long flags;\r\nint active;\r\nactive = (conn->ibc_state == IBLND_CONN_ACTIVE_CONNECT);\r\nCDEBUG(D_NET,"%s: active(%d), version(%x), status(%d)\n",\r\nlibcfs_nid2str(peer->ibp_nid), active,\r\nconn->ibc_version, status);\r\nLASSERT (!in_interrupt());\r\nLASSERT ((conn->ibc_state == IBLND_CONN_ACTIVE_CONNECT &&\r\npeer->ibp_connecting > 0) ||\r\n(conn->ibc_state == IBLND_CONN_PASSIVE_WAIT &&\r\npeer->ibp_accepting > 0));\r\nLIBCFS_FREE(conn->ibc_connvars, sizeof(*conn->ibc_connvars));\r\nconn->ibc_connvars = NULL;\r\nif (status != 0) {\r\nkiblnd_peer_connect_failed(peer, active, status);\r\nkiblnd_finalise_conn(conn);\r\nreturn;\r\n}\r\nwrite_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nconn->ibc_last_send = jiffies;\r\nkiblnd_set_conn_state(conn, IBLND_CONN_ESTABLISHED);\r\nkiblnd_peer_alive(peer);\r\nkiblnd_conn_addref(conn);\r\nlist_add(&conn->ibc_list, &peer->ibp_conns);\r\nif (active)\r\npeer->ibp_connecting--;\r\nelse\r\npeer->ibp_accepting--;\r\nif (peer->ibp_version == 0) {\r\npeer->ibp_version = conn->ibc_version;\r\npeer->ibp_incarnation = conn->ibc_incarnation;\r\n}\r\nif (peer->ibp_version != conn->ibc_version ||\r\npeer->ibp_incarnation != conn->ibc_incarnation) {\r\nkiblnd_close_stale_conns_locked(peer, conn->ibc_version,\r\nconn->ibc_incarnation);\r\npeer->ibp_version = conn->ibc_version;\r\npeer->ibp_incarnation = conn->ibc_incarnation;\r\n}\r\nlist_add(&txs, &peer->ibp_tx_queue);\r\nlist_del_init(&peer->ibp_tx_queue);\r\nif (!kiblnd_peer_active(peer) ||\r\nconn->ibc_comms_error != 0) {\r\nlnet_ni_t *ni = peer->ibp_ni;\r\nkiblnd_close_conn_locked(conn, -ECONNABORTED);\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nkiblnd_txlist_done(ni, &txs, -ECONNABORTED);\r\nreturn;\r\n}\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nspin_lock(&conn->ibc_lock);\r\nwhile (!list_empty(&txs)) {\r\ntx = list_entry(txs.next, kib_tx_t, tx_list);\r\nlist_del(&tx->tx_list);\r\nkiblnd_queue_tx_locked(tx, conn);\r\n}\r\nspin_unlock(&conn->ibc_lock);\r\nkiblnd_check_sends(conn);\r\nkiblnd_handle_early_rxs(conn);\r\n}\r\nvoid\r\nkiblnd_reject(struct rdma_cm_id *cmid, kib_rej_t *rej)\r\n{\r\nint rc;\r\nrc = rdma_reject(cmid, rej, sizeof(*rej));\r\nif (rc != 0)\r\nCWARN("Error %d sending reject\n", rc);\r\n}\r\nint\r\nkiblnd_passive_connect (struct rdma_cm_id *cmid, void *priv, int priv_nob)\r\n{\r\nrwlock_t *g_lock = &kiblnd_data.kib_global_lock;\r\nkib_msg_t *reqmsg = priv;\r\nkib_msg_t *ackmsg;\r\nkib_dev_t *ibdev;\r\nkib_peer_t *peer;\r\nkib_peer_t *peer2;\r\nkib_conn_t *conn;\r\nlnet_ni_t *ni = NULL;\r\nkib_net_t *net = NULL;\r\nlnet_nid_t nid;\r\nstruct rdma_conn_param cp;\r\nkib_rej_t rej;\r\nint version = IBLND_MSG_VERSION;\r\nunsigned long flags;\r\nint rc;\r\nstruct sockaddr_in *peer_addr;\r\nLASSERT (!in_interrupt());\r\nibdev = (kib_dev_t *)cmid->context;\r\nLASSERT (ibdev != NULL);\r\nmemset(&rej, 0, sizeof(rej));\r\nrej.ibr_magic = IBLND_MSG_MAGIC;\r\nrej.ibr_why = IBLND_REJECT_FATAL;\r\nrej.ibr_cp.ibcp_max_msg_size = IBLND_MSG_SIZE;\r\npeer_addr = (struct sockaddr_in *)&(cmid->route.addr.dst_addr);\r\nif (*kiblnd_tunables.kib_require_priv_port &&\r\nntohs(peer_addr->sin_port) >= PROT_SOCK) {\r\n__u32 ip = ntohl(peer_addr->sin_addr.s_addr);\r\nCERROR("Peer's port (%pI4h:%hu) is not privileged\n",\r\n&ip, ntohs(peer_addr->sin_port));\r\ngoto failed;\r\n}\r\nif (priv_nob < offsetof(kib_msg_t, ibm_type)) {\r\nCERROR("Short connection request\n");\r\ngoto failed;\r\n}\r\nif (reqmsg->ibm_magic == LNET_PROTO_MAGIC ||\r\nreqmsg->ibm_magic == __swab32(LNET_PROTO_MAGIC))\r\ngoto failed;\r\nif (reqmsg->ibm_magic == IBLND_MSG_MAGIC &&\r\nreqmsg->ibm_version != IBLND_MSG_VERSION &&\r\nreqmsg->ibm_version != IBLND_MSG_VERSION_1)\r\ngoto failed;\r\nif (reqmsg->ibm_magic == __swab32(IBLND_MSG_MAGIC) &&\r\nreqmsg->ibm_version != __swab16(IBLND_MSG_VERSION) &&\r\nreqmsg->ibm_version != __swab16(IBLND_MSG_VERSION_1))\r\ngoto failed;\r\nrc = kiblnd_unpack_msg(reqmsg, priv_nob);\r\nif (rc != 0) {\r\nCERROR("Can't parse connection request: %d\n", rc);\r\ngoto failed;\r\n}\r\nnid = reqmsg->ibm_srcnid;\r\nni = lnet_net2ni(LNET_NIDNET(reqmsg->ibm_dstnid));\r\nif (ni != NULL) {\r\nnet = (kib_net_t *)ni->ni_data;\r\nrej.ibr_incarnation = net->ibn_incarnation;\r\n}\r\nif (ni == NULL ||\r\nni->ni_nid != reqmsg->ibm_dstnid ||\r\nnet->ibn_dev != ibdev) {\r\nCERROR("Can't accept %s on %s (%s:%d:%pI4h): "\r\n"bad dst nid %s\n", libcfs_nid2str(nid),\r\nni == NULL ? "NA" : libcfs_nid2str(ni->ni_nid),\r\nibdev->ibd_ifname, ibdev->ibd_nnets,\r\n&ibdev->ibd_ifip,\r\nlibcfs_nid2str(reqmsg->ibm_dstnid));\r\ngoto failed;\r\n}\r\nif (reqmsg->ibm_dststamp != 0 &&\r\nreqmsg->ibm_dststamp != net->ibn_incarnation) {\r\nCWARN("Stale connection request\n");\r\nrej.ibr_why = IBLND_REJECT_CONN_STALE;\r\ngoto failed;\r\n}\r\nversion = reqmsg->ibm_version;\r\nif (reqmsg->ibm_type != IBLND_MSG_CONNREQ) {\r\nCERROR("Unexpected connreq msg type: %x from %s\n",\r\nreqmsg->ibm_type, libcfs_nid2str(nid));\r\ngoto failed;\r\n}\r\nif (reqmsg->ibm_u.connparams.ibcp_queue_depth !=\r\nIBLND_MSG_QUEUE_SIZE(version)) {\r\nCERROR("Can't accept %s: incompatible queue depth %d (%d wanted)\n",\r\nlibcfs_nid2str(nid), reqmsg->ibm_u.connparams.ibcp_queue_depth,\r\nIBLND_MSG_QUEUE_SIZE(version));\r\nif (version == IBLND_MSG_VERSION)\r\nrej.ibr_why = IBLND_REJECT_MSG_QUEUE_SIZE;\r\ngoto failed;\r\n}\r\nif (reqmsg->ibm_u.connparams.ibcp_max_frags !=\r\nIBLND_RDMA_FRAGS(version)) {\r\nCERROR("Can't accept %s(version %x): "\r\n"incompatible max_frags %d (%d wanted)\n",\r\nlibcfs_nid2str(nid), version,\r\nreqmsg->ibm_u.connparams.ibcp_max_frags,\r\nIBLND_RDMA_FRAGS(version));\r\nif (version == IBLND_MSG_VERSION)\r\nrej.ibr_why = IBLND_REJECT_RDMA_FRAGS;\r\ngoto failed;\r\n}\r\nif (reqmsg->ibm_u.connparams.ibcp_max_msg_size > IBLND_MSG_SIZE) {\r\nCERROR("Can't accept %s: message size %d too big (%d max)\n",\r\nlibcfs_nid2str(nid),\r\nreqmsg->ibm_u.connparams.ibcp_max_msg_size,\r\nIBLND_MSG_SIZE);\r\ngoto failed;\r\n}\r\nrc = kiblnd_create_peer(ni, &peer, nid);\r\nif (rc != 0) {\r\nCERROR("Can't create peer for %s\n", libcfs_nid2str(nid));\r\nrej.ibr_why = IBLND_REJECT_NO_RESOURCES;\r\ngoto failed;\r\n}\r\nwrite_lock_irqsave(g_lock, flags);\r\npeer2 = kiblnd_find_peer_locked(nid);\r\nif (peer2 != NULL) {\r\nif (peer2->ibp_version == 0) {\r\npeer2->ibp_version = version;\r\npeer2->ibp_incarnation = reqmsg->ibm_srcstamp;\r\n}\r\nif (peer2->ibp_incarnation != reqmsg->ibm_srcstamp ||\r\npeer2->ibp_version != version) {\r\nkiblnd_close_peer_conns_locked(peer2, -ESTALE);\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nCWARN("Conn stale %s [old ver: %x, new ver: %x]\n",\r\nlibcfs_nid2str(nid), peer2->ibp_version, version);\r\nkiblnd_peer_decref(peer);\r\nrej.ibr_why = IBLND_REJECT_CONN_STALE;\r\ngoto failed;\r\n}\r\nif (peer2->ibp_connecting != 0 &&\r\nnid < ni->ni_nid) {\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nCWARN("Conn race %s\n", libcfs_nid2str(peer2->ibp_nid));\r\nkiblnd_peer_decref(peer);\r\nrej.ibr_why = IBLND_REJECT_CONN_RACE;\r\ngoto failed;\r\n}\r\npeer2->ibp_accepting++;\r\nkiblnd_peer_addref(peer2);\r\nwrite_unlock_irqrestore(g_lock, flags);\r\nkiblnd_peer_decref(peer);\r\npeer = peer2;\r\n} else {\r\nLASSERT (peer->ibp_accepting == 0);\r\nLASSERT (peer->ibp_version == 0 &&\r\npeer->ibp_incarnation == 0);\r\npeer->ibp_accepting = 1;\r\npeer->ibp_version = version;\r\npeer->ibp_incarnation = reqmsg->ibm_srcstamp;\r\nLASSERT (net->ibn_shutdown == 0);\r\nkiblnd_peer_addref(peer);\r\nlist_add_tail(&peer->ibp_list, kiblnd_nid2peerlist(nid));\r\nwrite_unlock_irqrestore(g_lock, flags);\r\n}\r\nconn = kiblnd_create_conn(peer, cmid, IBLND_CONN_PASSIVE_WAIT, version);\r\nif (conn == NULL) {\r\nkiblnd_peer_connect_failed(peer, 0, -ENOMEM);\r\nkiblnd_peer_decref(peer);\r\nrej.ibr_why = IBLND_REJECT_NO_RESOURCES;\r\ngoto failed;\r\n}\r\nconn->ibc_incarnation = reqmsg->ibm_srcstamp;\r\nconn->ibc_credits = IBLND_MSG_QUEUE_SIZE(version);\r\nconn->ibc_reserved_credits = IBLND_MSG_QUEUE_SIZE(version);\r\nLASSERT (conn->ibc_credits + conn->ibc_reserved_credits + IBLND_OOB_MSGS(version)\r\n<= IBLND_RX_MSGS(version));\r\nackmsg = &conn->ibc_connvars->cv_msg;\r\nmemset(ackmsg, 0, sizeof(*ackmsg));\r\nkiblnd_init_msg(ackmsg, IBLND_MSG_CONNACK,\r\nsizeof(ackmsg->ibm_u.connparams));\r\nackmsg->ibm_u.connparams.ibcp_queue_depth = IBLND_MSG_QUEUE_SIZE(version);\r\nackmsg->ibm_u.connparams.ibcp_max_msg_size = IBLND_MSG_SIZE;\r\nackmsg->ibm_u.connparams.ibcp_max_frags = IBLND_RDMA_FRAGS(version);\r\nkiblnd_pack_msg(ni, ackmsg, version, 0, nid, reqmsg->ibm_srcstamp);\r\nmemset(&cp, 0, sizeof(cp));\r\ncp.private_data = ackmsg;\r\ncp.private_data_len = ackmsg->ibm_nob;\r\ncp.responder_resources = 0;\r\ncp.initiator_depth = 0;\r\ncp.flow_control = 1;\r\ncp.retry_count = *kiblnd_tunables.kib_retry_count;\r\ncp.rnr_retry_count = *kiblnd_tunables.kib_rnr_retry_count;\r\nCDEBUG(D_NET, "Accept %s\n", libcfs_nid2str(nid));\r\nrc = rdma_accept(cmid, &cp);\r\nif (rc != 0) {\r\nCERROR("Can't accept %s: %d\n", libcfs_nid2str(nid), rc);\r\nrej.ibr_version = version;\r\nrej.ibr_why = IBLND_REJECT_FATAL;\r\nkiblnd_reject(cmid, &rej);\r\nkiblnd_connreq_done(conn, rc);\r\nkiblnd_conn_decref(conn);\r\n}\r\nlnet_ni_decref(ni);\r\nreturn 0;\r\nfailed:\r\nif (ni != NULL)\r\nlnet_ni_decref(ni);\r\nrej.ibr_version = version;\r\nrej.ibr_cp.ibcp_queue_depth = IBLND_MSG_QUEUE_SIZE(version);\r\nrej.ibr_cp.ibcp_max_frags = IBLND_RDMA_FRAGS(version);\r\nkiblnd_reject(cmid, &rej);\r\nreturn -ECONNREFUSED;\r\n}\r\nvoid\r\nkiblnd_reconnect (kib_conn_t *conn, int version,\r\n__u64 incarnation, int why, kib_connparams_t *cp)\r\n{\r\nkib_peer_t *peer = conn->ibc_peer;\r\nchar *reason;\r\nint retry = 0;\r\nunsigned long flags;\r\nLASSERT (conn->ibc_state == IBLND_CONN_ACTIVE_CONNECT);\r\nLASSERT (peer->ibp_connecting > 0);\r\nwrite_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nif ((!list_empty(&peer->ibp_tx_queue) ||\r\npeer->ibp_version != version) &&\r\npeer->ibp_connecting == 1 &&\r\npeer->ibp_accepting == 0) {\r\nretry = 1;\r\npeer->ibp_connecting++;\r\npeer->ibp_version = version;\r\npeer->ibp_incarnation = incarnation;\r\n}\r\nwrite_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nif (!retry)\r\nreturn;\r\nswitch (why) {\r\ndefault:\r\nreason = "Unknown";\r\nbreak;\r\ncase IBLND_REJECT_CONN_STALE:\r\nreason = "stale";\r\nbreak;\r\ncase IBLND_REJECT_CONN_RACE:\r\nreason = "conn race";\r\nbreak;\r\ncase IBLND_REJECT_CONN_UNCOMPAT:\r\nreason = "version negotiation";\r\nbreak;\r\n}\r\nCNETERR("%s: retrying (%s), %x, %x, "\r\n"queue_dep: %d, max_frag: %d, msg_size: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\nreason, IBLND_MSG_VERSION, version,\r\ncp != NULL? cp->ibcp_queue_depth :IBLND_MSG_QUEUE_SIZE(version),\r\ncp != NULL? cp->ibcp_max_frags : IBLND_RDMA_FRAGS(version),\r\ncp != NULL? cp->ibcp_max_msg_size: IBLND_MSG_SIZE);\r\nkiblnd_connect_peer(peer);\r\n}\r\nvoid\r\nkiblnd_rejected (kib_conn_t *conn, int reason, void *priv, int priv_nob)\r\n{\r\nkib_peer_t *peer = conn->ibc_peer;\r\nLASSERT (!in_interrupt());\r\nLASSERT (conn->ibc_state == IBLND_CONN_ACTIVE_CONNECT);\r\nswitch (reason) {\r\ncase IB_CM_REJ_STALE_CONN:\r\nkiblnd_reconnect(conn, IBLND_MSG_VERSION, 0,\r\nIBLND_REJECT_CONN_STALE, NULL);\r\nbreak;\r\ncase IB_CM_REJ_INVALID_SERVICE_ID:\r\nCNETERR("%s rejected: no listener at %d\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\n*kiblnd_tunables.kib_service);\r\nbreak;\r\ncase IB_CM_REJ_CONSUMER_DEFINED:\r\nif (priv_nob >= offsetof(kib_rej_t, ibr_padding)) {\r\nkib_rej_t *rej = priv;\r\nkib_connparams_t *cp = NULL;\r\nint flip = 0;\r\n__u64 incarnation = -1;\r\nif (rej->ibr_magic == __swab32(IBLND_MSG_MAGIC) ||\r\nrej->ibr_magic == __swab32(LNET_PROTO_MAGIC)) {\r\n__swab32s(&rej->ibr_magic);\r\n__swab16s(&rej->ibr_version);\r\nflip = 1;\r\n}\r\nif (priv_nob >= sizeof(kib_rej_t) &&\r\nrej->ibr_version > IBLND_MSG_VERSION_1) {\r\ncp = &rej->ibr_cp;\r\nif (flip) {\r\n__swab64s(&rej->ibr_incarnation);\r\n__swab16s(&cp->ibcp_queue_depth);\r\n__swab16s(&cp->ibcp_max_frags);\r\n__swab32s(&cp->ibcp_max_msg_size);\r\n}\r\nincarnation = rej->ibr_incarnation;\r\n}\r\nif (rej->ibr_magic != IBLND_MSG_MAGIC &&\r\nrej->ibr_magic != LNET_PROTO_MAGIC) {\r\nCERROR("%s rejected: consumer defined fatal error\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\nbreak;\r\n}\r\nif (rej->ibr_version != IBLND_MSG_VERSION &&\r\nrej->ibr_version != IBLND_MSG_VERSION_1) {\r\nCERROR("%s rejected: o2iblnd version %x error\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\nrej->ibr_version);\r\nbreak;\r\n}\r\nif (rej->ibr_why == IBLND_REJECT_FATAL &&\r\nrej->ibr_version == IBLND_MSG_VERSION_1) {\r\nCDEBUG(D_NET, "rejected by old version peer %s: %x\n",\r\nlibcfs_nid2str(peer->ibp_nid), rej->ibr_version);\r\nif (conn->ibc_version != IBLND_MSG_VERSION_1)\r\nrej->ibr_why = IBLND_REJECT_CONN_UNCOMPAT;\r\n}\r\nswitch (rej->ibr_why) {\r\ncase IBLND_REJECT_CONN_RACE:\r\ncase IBLND_REJECT_CONN_STALE:\r\ncase IBLND_REJECT_CONN_UNCOMPAT:\r\nkiblnd_reconnect(conn, rej->ibr_version,\r\nincarnation, rej->ibr_why, cp);\r\nbreak;\r\ncase IBLND_REJECT_MSG_QUEUE_SIZE:\r\nCERROR("%s rejected: incompatible message queue depth %d, %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), cp->ibcp_queue_depth,\r\nIBLND_MSG_QUEUE_SIZE(conn->ibc_version));\r\nbreak;\r\ncase IBLND_REJECT_RDMA_FRAGS:\r\nCERROR("%s rejected: incompatible # of RDMA fragments %d, %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), cp->ibcp_max_frags,\r\nIBLND_RDMA_FRAGS(conn->ibc_version));\r\nbreak;\r\ncase IBLND_REJECT_NO_RESOURCES:\r\nCERROR("%s rejected: o2iblnd no resources\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\nbreak;\r\ncase IBLND_REJECT_FATAL:\r\nCERROR("%s rejected: o2iblnd fatal error\n",\r\nlibcfs_nid2str(peer->ibp_nid));\r\nbreak;\r\ndefault:\r\nCERROR("%s rejected: o2iblnd reason %d\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\nrej->ibr_why);\r\nbreak;\r\n}\r\nbreak;\r\n}\r\ndefault:\r\nCNETERR("%s rejected: reason %d, size %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), reason, priv_nob);\r\nbreak;\r\n}\r\nkiblnd_connreq_done(conn, -ECONNREFUSED);\r\n}\r\nvoid\r\nkiblnd_check_connreply (kib_conn_t *conn, void *priv, int priv_nob)\r\n{\r\nkib_peer_t *peer = conn->ibc_peer;\r\nlnet_ni_t *ni = peer->ibp_ni;\r\nkib_net_t *net = ni->ni_data;\r\nkib_msg_t *msg = priv;\r\nint ver = conn->ibc_version;\r\nint rc = kiblnd_unpack_msg(msg, priv_nob);\r\nunsigned long flags;\r\nLASSERT (net != NULL);\r\nif (rc != 0) {\r\nCERROR("Can't unpack connack from %s: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), rc);\r\ngoto failed;\r\n}\r\nif (msg->ibm_type != IBLND_MSG_CONNACK) {\r\nCERROR("Unexpected message %d from %s\n",\r\nmsg->ibm_type, libcfs_nid2str(peer->ibp_nid));\r\nrc = -EPROTO;\r\ngoto failed;\r\n}\r\nif (ver != msg->ibm_version) {\r\nCERROR("%s replied version %x is different with "\r\n"requested version %x\n",\r\nlibcfs_nid2str(peer->ibp_nid), msg->ibm_version, ver);\r\nrc = -EPROTO;\r\ngoto failed;\r\n}\r\nif (msg->ibm_u.connparams.ibcp_queue_depth !=\r\nIBLND_MSG_QUEUE_SIZE(ver)) {\r\nCERROR("%s has incompatible queue depth %d(%d wanted)\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\nmsg->ibm_u.connparams.ibcp_queue_depth,\r\nIBLND_MSG_QUEUE_SIZE(ver));\r\nrc = -EPROTO;\r\ngoto failed;\r\n}\r\nif (msg->ibm_u.connparams.ibcp_max_frags !=\r\nIBLND_RDMA_FRAGS(ver)) {\r\nCERROR("%s has incompatible max_frags %d (%d wanted)\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\nmsg->ibm_u.connparams.ibcp_max_frags,\r\nIBLND_RDMA_FRAGS(ver));\r\nrc = -EPROTO;\r\ngoto failed;\r\n}\r\nif (msg->ibm_u.connparams.ibcp_max_msg_size > IBLND_MSG_SIZE) {\r\nCERROR("%s max message size %d too big (%d max)\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\nmsg->ibm_u.connparams.ibcp_max_msg_size,\r\nIBLND_MSG_SIZE);\r\nrc = -EPROTO;\r\ngoto failed;\r\n}\r\nread_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nif (msg->ibm_dstnid == ni->ni_nid &&\r\nmsg->ibm_dststamp == net->ibn_incarnation)\r\nrc = 0;\r\nelse\r\nrc = -ESTALE;\r\nread_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nif (rc != 0) {\r\nCERROR("Bad connection reply from %s, rc = %d, "\r\n"version: %x max_frags: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), rc,\r\nmsg->ibm_version, msg->ibm_u.connparams.ibcp_max_frags);\r\ngoto failed;\r\n}\r\nconn->ibc_incarnation = msg->ibm_srcstamp;\r\nconn->ibc_credits =\r\nconn->ibc_reserved_credits = IBLND_MSG_QUEUE_SIZE(ver);\r\nLASSERT (conn->ibc_credits + conn->ibc_reserved_credits + IBLND_OOB_MSGS(ver)\r\n<= IBLND_RX_MSGS(ver));\r\nkiblnd_connreq_done(conn, 0);\r\nreturn;\r\nfailed:\r\nLASSERT (rc != 0);\r\nconn->ibc_comms_error = rc;\r\nkiblnd_connreq_done(conn, 0);\r\n}\r\nint\r\nkiblnd_active_connect (struct rdma_cm_id *cmid)\r\n{\r\nkib_peer_t *peer = (kib_peer_t *)cmid->context;\r\nkib_conn_t *conn;\r\nkib_msg_t *msg;\r\nstruct rdma_conn_param cp;\r\nint version;\r\n__u64 incarnation;\r\nunsigned long flags;\r\nint rc;\r\nread_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nincarnation = peer->ibp_incarnation;\r\nversion = (peer->ibp_version == 0) ? IBLND_MSG_VERSION :\r\npeer->ibp_version;\r\nread_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nconn = kiblnd_create_conn(peer, cmid, IBLND_CONN_ACTIVE_CONNECT, version);\r\nif (conn == NULL) {\r\nkiblnd_peer_connect_failed(peer, 1, -ENOMEM);\r\nkiblnd_peer_decref(peer);\r\nreturn -ENOMEM;\r\n}\r\nmsg = &conn->ibc_connvars->cv_msg;\r\nmemset(msg, 0, sizeof(*msg));\r\nkiblnd_init_msg(msg, IBLND_MSG_CONNREQ, sizeof(msg->ibm_u.connparams));\r\nmsg->ibm_u.connparams.ibcp_queue_depth = IBLND_MSG_QUEUE_SIZE(version);\r\nmsg->ibm_u.connparams.ibcp_max_frags = IBLND_RDMA_FRAGS(version);\r\nmsg->ibm_u.connparams.ibcp_max_msg_size = IBLND_MSG_SIZE;\r\nkiblnd_pack_msg(peer->ibp_ni, msg, version,\r\n0, peer->ibp_nid, incarnation);\r\nmemset(&cp, 0, sizeof(cp));\r\ncp.private_data = msg;\r\ncp.private_data_len = msg->ibm_nob;\r\ncp.responder_resources = 0;\r\ncp.initiator_depth = 0;\r\ncp.flow_control = 1;\r\ncp.retry_count = *kiblnd_tunables.kib_retry_count;\r\ncp.rnr_retry_count = *kiblnd_tunables.kib_rnr_retry_count;\r\nLASSERT(cmid->context == (void *)conn);\r\nLASSERT(conn->ibc_cmid == cmid);\r\nrc = rdma_connect(cmid, &cp);\r\nif (rc != 0) {\r\nCERROR("Can't connect to %s: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), rc);\r\nkiblnd_connreq_done(conn, rc);\r\nkiblnd_conn_decref(conn);\r\n}\r\nreturn 0;\r\n}\r\nint\r\nkiblnd_cm_callback(struct rdma_cm_id *cmid, struct rdma_cm_event *event)\r\n{\r\nkib_peer_t *peer;\r\nkib_conn_t *conn;\r\nint rc;\r\nswitch (event->event) {\r\ndefault:\r\nCERROR("Unexpected event: %d, status: %d\n",\r\nevent->event, event->status);\r\nLBUG();\r\ncase RDMA_CM_EVENT_CONNECT_REQUEST:\r\nrc = kiblnd_passive_connect(cmid,\r\n(void *)KIBLND_CONN_PARAM(event),\r\nKIBLND_CONN_PARAM_LEN(event));\r\nCDEBUG(D_NET, "connreq: %d\n", rc);\r\nreturn rc;\r\ncase RDMA_CM_EVENT_ADDR_ERROR:\r\npeer = (kib_peer_t *)cmid->context;\r\nCNETERR("%s: ADDR ERROR %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), event->status);\r\nkiblnd_peer_connect_failed(peer, 1, -EHOSTUNREACH);\r\nkiblnd_peer_decref(peer);\r\nreturn -EHOSTUNREACH;\r\ncase RDMA_CM_EVENT_ADDR_RESOLVED:\r\npeer = (kib_peer_t *)cmid->context;\r\nCDEBUG(D_NET,"%s Addr resolved: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), event->status);\r\nif (event->status != 0) {\r\nCNETERR("Can't resolve address for %s: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), event->status);\r\nrc = event->status;\r\n} else {\r\nrc = rdma_resolve_route(\r\ncmid, *kiblnd_tunables.kib_timeout * 1000);\r\nif (rc == 0)\r\nreturn 0;\r\nCERROR("Can't resolve route for %s: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), rc);\r\n}\r\nkiblnd_peer_connect_failed(peer, 1, rc);\r\nkiblnd_peer_decref(peer);\r\nreturn rc;\r\ncase RDMA_CM_EVENT_ROUTE_ERROR:\r\npeer = (kib_peer_t *)cmid->context;\r\nCNETERR("%s: ROUTE ERROR %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), event->status);\r\nkiblnd_peer_connect_failed(peer, 1, -EHOSTUNREACH);\r\nkiblnd_peer_decref(peer);\r\nreturn -EHOSTUNREACH;\r\ncase RDMA_CM_EVENT_ROUTE_RESOLVED:\r\npeer = (kib_peer_t *)cmid->context;\r\nCDEBUG(D_NET,"%s Route resolved: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), event->status);\r\nif (event->status == 0)\r\nreturn kiblnd_active_connect(cmid);\r\nCNETERR("Can't resolve route for %s: %d\n",\r\nlibcfs_nid2str(peer->ibp_nid), event->status);\r\nkiblnd_peer_connect_failed(peer, 1, event->status);\r\nkiblnd_peer_decref(peer);\r\nreturn event->status;\r\ncase RDMA_CM_EVENT_UNREACHABLE:\r\nconn = (kib_conn_t *)cmid->context;\r\nLASSERT(conn->ibc_state == IBLND_CONN_ACTIVE_CONNECT ||\r\nconn->ibc_state == IBLND_CONN_PASSIVE_WAIT);\r\nCNETERR("%s: UNREACHABLE %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), event->status);\r\nkiblnd_connreq_done(conn, -ENETDOWN);\r\nkiblnd_conn_decref(conn);\r\nreturn 0;\r\ncase RDMA_CM_EVENT_CONNECT_ERROR:\r\nconn = (kib_conn_t *)cmid->context;\r\nLASSERT(conn->ibc_state == IBLND_CONN_ACTIVE_CONNECT ||\r\nconn->ibc_state == IBLND_CONN_PASSIVE_WAIT);\r\nCNETERR("%s: CONNECT ERROR %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), event->status);\r\nkiblnd_connreq_done(conn, -ENOTCONN);\r\nkiblnd_conn_decref(conn);\r\nreturn 0;\r\ncase RDMA_CM_EVENT_REJECTED:\r\nconn = (kib_conn_t *)cmid->context;\r\nswitch (conn->ibc_state) {\r\ndefault:\r\nLBUG();\r\ncase IBLND_CONN_PASSIVE_WAIT:\r\nCERROR ("%s: REJECTED %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid),\r\nevent->status);\r\nkiblnd_connreq_done(conn, -ECONNRESET);\r\nbreak;\r\ncase IBLND_CONN_ACTIVE_CONNECT:\r\nkiblnd_rejected(conn, event->status,\r\n(void *)KIBLND_CONN_PARAM(event),\r\nKIBLND_CONN_PARAM_LEN(event));\r\nbreak;\r\n}\r\nkiblnd_conn_decref(conn);\r\nreturn 0;\r\ncase RDMA_CM_EVENT_ESTABLISHED:\r\nconn = (kib_conn_t *)cmid->context;\r\nswitch (conn->ibc_state) {\r\ndefault:\r\nLBUG();\r\ncase IBLND_CONN_PASSIVE_WAIT:\r\nCDEBUG(D_NET, "ESTABLISHED (passive): %s\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nkiblnd_connreq_done(conn, 0);\r\nbreak;\r\ncase IBLND_CONN_ACTIVE_CONNECT:\r\nCDEBUG(D_NET, "ESTABLISHED(active): %s\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nkiblnd_check_connreply(conn,\r\n(void *)KIBLND_CONN_PARAM(event),\r\nKIBLND_CONN_PARAM_LEN(event));\r\nbreak;\r\n}\r\nreturn 0;\r\ncase RDMA_CM_EVENT_TIMEWAIT_EXIT:\r\nCDEBUG(D_NET, "Ignore TIMEWAIT_EXIT event\n");\r\nreturn 0;\r\ncase RDMA_CM_EVENT_DISCONNECTED:\r\nconn = (kib_conn_t *)cmid->context;\r\nif (conn->ibc_state < IBLND_CONN_ESTABLISHED) {\r\nCERROR("%s DISCONNECTED\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nkiblnd_connreq_done(conn, -ECONNRESET);\r\n} else {\r\nkiblnd_close_conn(conn, 0);\r\n}\r\nkiblnd_conn_decref(conn);\r\ncmid->context = NULL;\r\nreturn 0;\r\ncase RDMA_CM_EVENT_DEVICE_REMOVAL:\r\nLCONSOLE_ERROR_MSG(0x131,\r\n"Received notification of device removal\n"\r\n"Please shutdown LNET to allow this to proceed\n");\r\nreturn 0;\r\ncase RDMA_CM_EVENT_ADDR_CHANGE:\r\nLCONSOLE_INFO("Physical link changed (eg hca/port)\n");\r\nreturn 0;\r\n}\r\n}\r\nstatic int\r\nkiblnd_check_txs_locked(kib_conn_t *conn, struct list_head *txs)\r\n{\r\nkib_tx_t *tx;\r\nstruct list_head *ttmp;\r\nlist_for_each (ttmp, txs) {\r\ntx = list_entry (ttmp, kib_tx_t, tx_list);\r\nif (txs != &conn->ibc_active_txs) {\r\nLASSERT (tx->tx_queued);\r\n} else {\r\nLASSERT (!tx->tx_queued);\r\nLASSERT (tx->tx_waiting || tx->tx_sending != 0);\r\n}\r\nif (cfs_time_aftereq (jiffies, tx->tx_deadline)) {\r\nCERROR("Timed out tx: %s, %lu seconds\n",\r\nkiblnd_queue2str(conn, txs),\r\ncfs_duration_sec(jiffies - tx->tx_deadline));\r\nreturn 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nkiblnd_conn_timed_out_locked(kib_conn_t *conn)\r\n{\r\nreturn kiblnd_check_txs_locked(conn, &conn->ibc_tx_queue) ||\r\nkiblnd_check_txs_locked(conn, &conn->ibc_tx_noops) ||\r\nkiblnd_check_txs_locked(conn, &conn->ibc_tx_queue_rsrvd) ||\r\nkiblnd_check_txs_locked(conn, &conn->ibc_tx_queue_nocred) ||\r\nkiblnd_check_txs_locked(conn, &conn->ibc_active_txs);\r\n}\r\nvoid\r\nkiblnd_check_conns (int idx)\r\n{\r\nLIST_HEAD (closes);\r\nLIST_HEAD (checksends);\r\nstruct list_head *peers = &kiblnd_data.kib_peers[idx];\r\nstruct list_head *ptmp;\r\nkib_peer_t *peer;\r\nkib_conn_t *conn;\r\nstruct list_head *ctmp;\r\nunsigned long flags;\r\nread_lock_irqsave(&kiblnd_data.kib_global_lock, flags);\r\nlist_for_each (ptmp, peers) {\r\npeer = list_entry (ptmp, kib_peer_t, ibp_list);\r\nlist_for_each (ctmp, &peer->ibp_conns) {\r\nint timedout;\r\nint sendnoop;\r\nconn = list_entry(ctmp, kib_conn_t, ibc_list);\r\nLASSERT (conn->ibc_state == IBLND_CONN_ESTABLISHED);\r\nspin_lock(&conn->ibc_lock);\r\nsendnoop = kiblnd_need_noop(conn);\r\ntimedout = kiblnd_conn_timed_out_locked(conn);\r\nif (!sendnoop && !timedout) {\r\nspin_unlock(&conn->ibc_lock);\r\ncontinue;\r\n}\r\nif (timedout) {\r\nCERROR("Timed out RDMA with %s (%lu): "\r\n"c: %u, oc: %u, rc: %u\n",\r\nlibcfs_nid2str(peer->ibp_nid),\r\ncfs_duration_sec(cfs_time_current() -\r\npeer->ibp_last_alive),\r\nconn->ibc_credits,\r\nconn->ibc_outstanding_credits,\r\nconn->ibc_reserved_credits);\r\nlist_add(&conn->ibc_connd_list, &closes);\r\n} else {\r\nlist_add(&conn->ibc_connd_list,\r\n&checksends);\r\n}\r\nkiblnd_conn_addref(conn);\r\nspin_unlock(&conn->ibc_lock);\r\n}\r\n}\r\nread_unlock_irqrestore(&kiblnd_data.kib_global_lock, flags);\r\nwhile (!list_empty(&closes)) {\r\nconn = list_entry(closes.next,\r\nkib_conn_t, ibc_connd_list);\r\nlist_del(&conn->ibc_connd_list);\r\nkiblnd_close_conn(conn, -ETIMEDOUT);\r\nkiblnd_conn_decref(conn);\r\n}\r\nwhile (!list_empty(&checksends)) {\r\nconn = list_entry(checksends.next,\r\nkib_conn_t, ibc_connd_list);\r\nlist_del(&conn->ibc_connd_list);\r\nkiblnd_check_sends(conn);\r\nkiblnd_conn_decref(conn);\r\n}\r\n}\r\nvoid\r\nkiblnd_disconnect_conn (kib_conn_t *conn)\r\n{\r\nLASSERT (!in_interrupt());\r\nLASSERT (current == kiblnd_data.kib_connd);\r\nLASSERT (conn->ibc_state == IBLND_CONN_CLOSING);\r\nrdma_disconnect(conn->ibc_cmid);\r\nkiblnd_finalise_conn(conn);\r\nkiblnd_peer_notify(conn->ibc_peer);\r\n}\r\nint\r\nkiblnd_connd (void *arg)\r\n{\r\nwait_queue_t wait;\r\nunsigned long flags;\r\nkib_conn_t *conn;\r\nint timeout;\r\nint i;\r\nint dropped_lock;\r\nint peer_index = 0;\r\nunsigned long deadline = jiffies;\r\ncfs_block_allsigs ();\r\ninit_waitqueue_entry_current (&wait);\r\nkiblnd_data.kib_connd = current;\r\nspin_lock_irqsave(&kiblnd_data.kib_connd_lock, flags);\r\nwhile (!kiblnd_data.kib_shutdown) {\r\ndropped_lock = 0;\r\nif (!list_empty (&kiblnd_data.kib_connd_zombies)) {\r\nconn = list_entry(kiblnd_data. \\r\nkib_connd_zombies.next,\r\nkib_conn_t, ibc_list);\r\nlist_del(&conn->ibc_list);\r\nspin_unlock_irqrestore(&kiblnd_data.kib_connd_lock,\r\nflags);\r\ndropped_lock = 1;\r\nkiblnd_destroy_conn(conn);\r\nspin_lock_irqsave(&kiblnd_data.kib_connd_lock, flags);\r\n}\r\nif (!list_empty(&kiblnd_data.kib_connd_conns)) {\r\nconn = list_entry(kiblnd_data.kib_connd_conns.next,\r\nkib_conn_t, ibc_list);\r\nlist_del(&conn->ibc_list);\r\nspin_unlock_irqrestore(&kiblnd_data.kib_connd_lock,\r\nflags);\r\ndropped_lock = 1;\r\nkiblnd_disconnect_conn(conn);\r\nkiblnd_conn_decref(conn);\r\nspin_lock_irqsave(&kiblnd_data.kib_connd_lock, flags);\r\n}\r\ntimeout = (int)(deadline - jiffies);\r\nif (timeout <= 0) {\r\nconst int n = 4;\r\nconst int p = 1;\r\nint chunk = kiblnd_data.kib_peer_hash_size;\r\nspin_unlock_irqrestore(&kiblnd_data.kib_connd_lock, flags);\r\ndropped_lock = 1;\r\nif (*kiblnd_tunables.kib_timeout > n * p)\r\nchunk = (chunk * n * p) /\r\n*kiblnd_tunables.kib_timeout;\r\nif (chunk == 0)\r\nchunk = 1;\r\nfor (i = 0; i < chunk; i++) {\r\nkiblnd_check_conns(peer_index);\r\npeer_index = (peer_index + 1) %\r\nkiblnd_data.kib_peer_hash_size;\r\n}\r\ndeadline += p * HZ;\r\nspin_lock_irqsave(&kiblnd_data.kib_connd_lock, flags);\r\n}\r\nif (dropped_lock)\r\ncontinue;\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nadd_wait_queue(&kiblnd_data.kib_connd_waitq, &wait);\r\nspin_unlock_irqrestore(&kiblnd_data.kib_connd_lock, flags);\r\nwaitq_timedwait(&wait, TASK_INTERRUPTIBLE, timeout);\r\nset_current_state(TASK_RUNNING);\r\nremove_wait_queue(&kiblnd_data.kib_connd_waitq, &wait);\r\nspin_lock_irqsave(&kiblnd_data.kib_connd_lock, flags);\r\n}\r\nspin_unlock_irqrestore(&kiblnd_data.kib_connd_lock, flags);\r\nkiblnd_thread_fini();\r\nreturn 0;\r\n}\r\nvoid\r\nkiblnd_qp_event(struct ib_event *event, void *arg)\r\n{\r\nkib_conn_t *conn = arg;\r\nswitch (event->event) {\r\ncase IB_EVENT_COMM_EST:\r\nCDEBUG(D_NET, "%s established\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid));\r\nreturn;\r\ndefault:\r\nCERROR("%s: Async QP event type %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), event->event);\r\nreturn;\r\n}\r\n}\r\nvoid\r\nkiblnd_complete (struct ib_wc *wc)\r\n{\r\nswitch (kiblnd_wreqid2type(wc->wr_id)) {\r\ndefault:\r\nLBUG();\r\ncase IBLND_WID_RDMA:\r\nCNETERR("RDMA (tx: %p) failed: %d\n",\r\nkiblnd_wreqid2ptr(wc->wr_id), wc->status);\r\nreturn;\r\ncase IBLND_WID_TX:\r\nkiblnd_tx_complete(kiblnd_wreqid2ptr(wc->wr_id), wc->status);\r\nreturn;\r\ncase IBLND_WID_RX:\r\nkiblnd_rx_complete(kiblnd_wreqid2ptr(wc->wr_id), wc->status,\r\nwc->byte_len);\r\nreturn;\r\n}\r\n}\r\nvoid\r\nkiblnd_cq_completion(struct ib_cq *cq, void *arg)\r\n{\r\nkib_conn_t *conn = (kib_conn_t *)arg;\r\nstruct kib_sched_info *sched = conn->ibc_sched;\r\nunsigned long flags;\r\nLASSERT(cq == conn->ibc_cq);\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\nconn->ibc_ready = 1;\r\nif (!conn->ibc_scheduled &&\r\n(conn->ibc_nrx > 0 ||\r\nconn->ibc_nsends_posted > 0)) {\r\nkiblnd_conn_addref(conn);\r\nconn->ibc_scheduled = 1;\r\nlist_add_tail(&conn->ibc_sched_list, &sched->ibs_conns);\r\nif (waitqueue_active(&sched->ibs_waitq))\r\nwake_up(&sched->ibs_waitq);\r\n}\r\nspin_unlock_irqrestore(&sched->ibs_lock, flags);\r\n}\r\nvoid\r\nkiblnd_cq_event(struct ib_event *event, void *arg)\r\n{\r\nkib_conn_t *conn = arg;\r\nCERROR("%s: async CQ event type %d\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), event->event);\r\n}\r\nint\r\nkiblnd_scheduler(void *arg)\r\n{\r\nlong id = (long)arg;\r\nstruct kib_sched_info *sched;\r\nkib_conn_t *conn;\r\nwait_queue_t wait;\r\nunsigned long flags;\r\nstruct ib_wc wc;\r\nint did_something;\r\nint busy_loops = 0;\r\nint rc;\r\ncfs_block_allsigs();\r\ninit_waitqueue_entry_current(&wait);\r\nsched = kiblnd_data.kib_scheds[KIB_THREAD_CPT(id)];\r\nrc = cfs_cpt_bind(lnet_cpt_table(), sched->ibs_cpt);\r\nif (rc != 0) {\r\nCWARN("Failed to bind on CPT %d, please verify whether "\r\n"all CPUs are healthy and reload modules if necessary, "\r\n"otherwise your system might under risk of low "\r\n"performance\n", sched->ibs_cpt);\r\n}\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\nwhile (!kiblnd_data.kib_shutdown) {\r\nif (busy_loops++ >= IBLND_RESCHED) {\r\nspin_unlock_irqrestore(&sched->ibs_lock, flags);\r\ncond_resched();\r\nbusy_loops = 0;\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\n}\r\ndid_something = 0;\r\nif (!list_empty(&sched->ibs_conns)) {\r\nconn = list_entry(sched->ibs_conns.next,\r\nkib_conn_t, ibc_sched_list);\r\nLASSERT(conn->ibc_scheduled);\r\nlist_del(&conn->ibc_sched_list);\r\nconn->ibc_ready = 0;\r\nspin_unlock_irqrestore(&sched->ibs_lock, flags);\r\nrc = ib_poll_cq(conn->ibc_cq, 1, &wc);\r\nif (rc == 0) {\r\nrc = ib_req_notify_cq(conn->ibc_cq,\r\nIB_CQ_NEXT_COMP);\r\nif (rc < 0) {\r\nCWARN("%s: ib_req_notify_cq failed: %d, "\r\n"closing connection\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid), rc);\r\nkiblnd_close_conn(conn, -EIO);\r\nkiblnd_conn_decref(conn);\r\nspin_lock_irqsave(&sched->ibs_lock,\r\nflags);\r\ncontinue;\r\n}\r\nrc = ib_poll_cq(conn->ibc_cq, 1, &wc);\r\n}\r\nif (rc < 0) {\r\nCWARN("%s: ib_poll_cq failed: %d, "\r\n"closing connection\n",\r\nlibcfs_nid2str(conn->ibc_peer->ibp_nid),\r\nrc);\r\nkiblnd_close_conn(conn, -EIO);\r\nkiblnd_conn_decref(conn);\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\ncontinue;\r\n}\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\nif (rc != 0 || conn->ibc_ready) {\r\nkiblnd_conn_addref(conn);\r\nlist_add_tail(&conn->ibc_sched_list,\r\n&sched->ibs_conns);\r\nif (waitqueue_active(&sched->ibs_waitq))\r\nwake_up(&sched->ibs_waitq);\r\n} else {\r\nconn->ibc_scheduled = 0;\r\n}\r\nif (rc != 0) {\r\nspin_unlock_irqrestore(&sched->ibs_lock, flags);\r\nkiblnd_complete(&wc);\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\n}\r\nkiblnd_conn_decref(conn);\r\ndid_something = 1;\r\n}\r\nif (did_something)\r\ncontinue;\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nadd_wait_queue_exclusive(&sched->ibs_waitq, &wait);\r\nspin_unlock_irqrestore(&sched->ibs_lock, flags);\r\nwaitq_wait(&wait, TASK_INTERRUPTIBLE);\r\nbusy_loops = 0;\r\nremove_wait_queue(&sched->ibs_waitq, &wait);\r\nset_current_state(TASK_RUNNING);\r\nspin_lock_irqsave(&sched->ibs_lock, flags);\r\n}\r\nspin_unlock_irqrestore(&sched->ibs_lock, flags);\r\nkiblnd_thread_fini();\r\nreturn 0;\r\n}\r\nint\r\nkiblnd_failover_thread(void *arg)\r\n{\r\nrwlock_t *glock = &kiblnd_data.kib_global_lock;\r\nkib_dev_t *dev;\r\nwait_queue_t wait;\r\nunsigned long flags;\r\nint rc;\r\nLASSERT (*kiblnd_tunables.kib_dev_failover != 0);\r\ncfs_block_allsigs ();\r\ninit_waitqueue_entry_current(&wait);\r\nwrite_lock_irqsave(glock, flags);\r\nwhile (!kiblnd_data.kib_shutdown) {\r\nint do_failover = 0;\r\nint long_sleep;\r\nlist_for_each_entry(dev, &kiblnd_data.kib_failed_devs,\r\nibd_fail_list) {\r\nif (cfs_time_before(cfs_time_current(),\r\ndev->ibd_next_failover))\r\ncontinue;\r\ndo_failover = 1;\r\nbreak;\r\n}\r\nif (do_failover) {\r\nlist_del_init(&dev->ibd_fail_list);\r\ndev->ibd_failover = 1;\r\nwrite_unlock_irqrestore(glock, flags);\r\nrc = kiblnd_dev_failover(dev);\r\nwrite_lock_irqsave(glock, flags);\r\nLASSERT (dev->ibd_failover);\r\ndev->ibd_failover = 0;\r\nif (rc >= 0) {\r\ndev->ibd_next_failover = cfs_time_shift(3);\r\ncontinue;\r\n}\r\ndev->ibd_next_failover =\r\ncfs_time_shift(min(dev->ibd_failed_failover, 10));\r\nif (kiblnd_dev_can_failover(dev)) {\r\nlist_add_tail(&dev->ibd_fail_list,\r\n&kiblnd_data.kib_failed_devs);\r\n}\r\ncontinue;\r\n}\r\nlong_sleep = list_empty(&kiblnd_data.kib_failed_devs);\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nadd_wait_queue(&kiblnd_data.kib_failover_waitq, &wait);\r\nwrite_unlock_irqrestore(glock, flags);\r\nrc = schedule_timeout(long_sleep ? cfs_time_seconds(10) :\r\ncfs_time_seconds(1));\r\nset_current_state(TASK_RUNNING);\r\nremove_wait_queue(&kiblnd_data.kib_failover_waitq, &wait);\r\nwrite_lock_irqsave(glock, flags);\r\nif (!long_sleep || rc != 0)\r\ncontinue;\r\nlist_for_each_entry(dev, &kiblnd_data.kib_devs, ibd_list) {\r\nif (kiblnd_dev_can_failover(dev)) {\r\nlist_add_tail(&dev->ibd_fail_list,\r\n&kiblnd_data.kib_failed_devs);\r\n}\r\n}\r\n}\r\nwrite_unlock_irqrestore(glock, flags);\r\nkiblnd_thread_fini();\r\nreturn 0;\r\n}
