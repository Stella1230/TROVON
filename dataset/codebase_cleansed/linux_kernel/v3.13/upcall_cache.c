static struct upcall_cache_entry *alloc_entry(struct upcall_cache *cache,\r\n__u64 key, void *args)\r\n{\r\nstruct upcall_cache_entry *entry;\r\nLIBCFS_ALLOC(entry, sizeof(*entry));\r\nif (!entry)\r\nreturn NULL;\r\nUC_CACHE_SET_NEW(entry);\r\nINIT_LIST_HEAD(&entry->ue_hash);\r\nentry->ue_key = key;\r\natomic_set(&entry->ue_refcount, 0);\r\ninit_waitqueue_head(&entry->ue_waitq);\r\nif (cache->uc_ops->init_entry)\r\ncache->uc_ops->init_entry(entry, args);\r\nreturn entry;\r\n}\r\nstatic void free_entry(struct upcall_cache *cache,\r\nstruct upcall_cache_entry *entry)\r\n{\r\nif (cache->uc_ops->free_entry)\r\ncache->uc_ops->free_entry(cache, entry);\r\nlist_del(&entry->ue_hash);\r\nCDEBUG(D_OTHER, "destroy cache entry %p for key "LPU64"\n",\r\nentry, entry->ue_key);\r\nLIBCFS_FREE(entry, sizeof(*entry));\r\n}\r\nstatic inline int upcall_compare(struct upcall_cache *cache,\r\nstruct upcall_cache_entry *entry,\r\n__u64 key, void *args)\r\n{\r\nif (entry->ue_key != key)\r\nreturn -1;\r\nif (cache->uc_ops->upcall_compare)\r\nreturn cache->uc_ops->upcall_compare(cache, entry, key, args);\r\nreturn 0;\r\n}\r\nstatic inline int downcall_compare(struct upcall_cache *cache,\r\nstruct upcall_cache_entry *entry,\r\n__u64 key, void *args)\r\n{\r\nif (entry->ue_key != key)\r\nreturn -1;\r\nif (cache->uc_ops->downcall_compare)\r\nreturn cache->uc_ops->downcall_compare(cache, entry, key, args);\r\nreturn 0;\r\n}\r\nstatic inline void get_entry(struct upcall_cache_entry *entry)\r\n{\r\natomic_inc(&entry->ue_refcount);\r\n}\r\nstatic inline void put_entry(struct upcall_cache *cache,\r\nstruct upcall_cache_entry *entry)\r\n{\r\nif (atomic_dec_and_test(&entry->ue_refcount) &&\r\n(UC_CACHE_IS_INVALID(entry) || UC_CACHE_IS_EXPIRED(entry))) {\r\nfree_entry(cache, entry);\r\n}\r\n}\r\nstatic int check_unlink_entry(struct upcall_cache *cache,\r\nstruct upcall_cache_entry *entry)\r\n{\r\nif (UC_CACHE_IS_VALID(entry) &&\r\ncfs_time_before(cfs_time_current(), entry->ue_expire))\r\nreturn 0;\r\nif (UC_CACHE_IS_ACQUIRING(entry)) {\r\nif (entry->ue_acquire_expire == 0 ||\r\ncfs_time_before(cfs_time_current(),\r\nentry->ue_acquire_expire))\r\nreturn 0;\r\nUC_CACHE_SET_EXPIRED(entry);\r\nwake_up_all(&entry->ue_waitq);\r\n} else if (!UC_CACHE_IS_INVALID(entry)) {\r\nUC_CACHE_SET_EXPIRED(entry);\r\n}\r\nlist_del_init(&entry->ue_hash);\r\nif (!atomic_read(&entry->ue_refcount))\r\nfree_entry(cache, entry);\r\nreturn 1;\r\n}\r\nstatic inline int refresh_entry(struct upcall_cache *cache,\r\nstruct upcall_cache_entry *entry)\r\n{\r\nLASSERT(cache->uc_ops->do_upcall);\r\nreturn cache->uc_ops->do_upcall(cache, entry);\r\n}\r\nstruct upcall_cache_entry *upcall_cache_get_entry(struct upcall_cache *cache,\r\n__u64 key, void *args)\r\n{\r\nstruct upcall_cache_entry *entry = NULL, *new = NULL, *next;\r\nstruct list_head *head;\r\nwait_queue_t wait;\r\nint rc, found;\r\nLASSERT(cache);\r\nhead = &cache->uc_hashtable[UC_CACHE_HASH_INDEX(key)];\r\nfind_again:\r\nfound = 0;\r\nspin_lock(&cache->uc_lock);\r\nlist_for_each_entry_safe(entry, next, head, ue_hash) {\r\nif (check_unlink_entry(cache, entry))\r\ncontinue;\r\nif (upcall_compare(cache, entry, key, args) == 0) {\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nif (!new) {\r\nspin_unlock(&cache->uc_lock);\r\nnew = alloc_entry(cache, key, args);\r\nif (!new) {\r\nCERROR("fail to alloc entry\n");\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\ngoto find_again;\r\n} else {\r\nlist_add(&new->ue_hash, head);\r\nentry = new;\r\n}\r\n} else {\r\nif (new) {\r\nfree_entry(cache, new);\r\nnew = NULL;\r\n}\r\nlist_move(&entry->ue_hash, head);\r\n}\r\nget_entry(entry);\r\nif (UC_CACHE_IS_NEW(entry)) {\r\nUC_CACHE_SET_ACQUIRING(entry);\r\nUC_CACHE_CLEAR_NEW(entry);\r\nspin_unlock(&cache->uc_lock);\r\nrc = refresh_entry(cache, entry);\r\nspin_lock(&cache->uc_lock);\r\nentry->ue_acquire_expire =\r\ncfs_time_shift(cache->uc_acquire_expire);\r\nif (rc < 0) {\r\nUC_CACHE_CLEAR_ACQUIRING(entry);\r\nUC_CACHE_SET_INVALID(entry);\r\nwake_up_all(&entry->ue_waitq);\r\nif (unlikely(rc == -EREMCHG)) {\r\nput_entry(cache, entry);\r\nGOTO(out, entry = ERR_PTR(rc));\r\n}\r\n}\r\n}\r\nif (UC_CACHE_IS_ACQUIRING(entry)) {\r\nlong expiry = (entry == new) ?\r\ncfs_time_seconds(cache->uc_acquire_expire) :\r\nMAX_SCHEDULE_TIMEOUT;\r\nlong left;\r\ninit_waitqueue_entry_current(&wait);\r\nadd_wait_queue(&entry->ue_waitq, &wait);\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nspin_unlock(&cache->uc_lock);\r\nleft = waitq_timedwait(&wait, TASK_INTERRUPTIBLE,\r\nexpiry);\r\nspin_lock(&cache->uc_lock);\r\nremove_wait_queue(&entry->ue_waitq, &wait);\r\nif (UC_CACHE_IS_ACQUIRING(entry)) {\r\nrc = left > 0 ? -EINTR : -ETIMEDOUT;\r\nCERROR("acquire for key "LPU64": error %d\n",\r\nentry->ue_key, rc);\r\nput_entry(cache, entry);\r\nGOTO(out, entry = ERR_PTR(rc));\r\n}\r\n}\r\nif (UC_CACHE_IS_INVALID(entry)) {\r\nput_entry(cache, entry);\r\nGOTO(out, entry = ERR_PTR(-EIDRM));\r\n}\r\nif (check_unlink_entry(cache, entry)) {\r\nif (entry != new) {\r\nput_entry(cache, entry);\r\nspin_unlock(&cache->uc_lock);\r\nnew = NULL;\r\ngoto find_again;\r\n}\r\n}\r\nout:\r\nspin_unlock(&cache->uc_lock);\r\nreturn entry;\r\n}\r\nvoid upcall_cache_put_entry(struct upcall_cache *cache,\r\nstruct upcall_cache_entry *entry)\r\n{\r\nif (!entry) {\r\nreturn;\r\n}\r\nLASSERT(atomic_read(&entry->ue_refcount) > 0);\r\nspin_lock(&cache->uc_lock);\r\nput_entry(cache, entry);\r\nspin_unlock(&cache->uc_lock);\r\n}\r\nint upcall_cache_downcall(struct upcall_cache *cache, __u32 err, __u64 key,\r\nvoid *args)\r\n{\r\nstruct upcall_cache_entry *entry = NULL;\r\nstruct list_head *head;\r\nint found = 0, rc = 0;\r\nLASSERT(cache);\r\nhead = &cache->uc_hashtable[UC_CACHE_HASH_INDEX(key)];\r\nspin_lock(&cache->uc_lock);\r\nlist_for_each_entry(entry, head, ue_hash) {\r\nif (downcall_compare(cache, entry, key, args) == 0) {\r\nfound = 1;\r\nget_entry(entry);\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nCDEBUG(D_OTHER, "%s: upcall for key "LPU64" not expected\n",\r\ncache->uc_name, key);\r\nspin_unlock(&cache->uc_lock);\r\nreturn -EINVAL;\r\n}\r\nif (err) {\r\nCDEBUG(D_OTHER, "%s: upcall for key "LPU64" returned %d\n",\r\ncache->uc_name, entry->ue_key, err);\r\nGOTO(out, rc = -EINVAL);\r\n}\r\nif (!UC_CACHE_IS_ACQUIRING(entry)) {\r\nCDEBUG(D_RPCTRACE,"%s: found uptodate entry %p (key "LPU64")\n",\r\ncache->uc_name, entry, entry->ue_key);\r\nGOTO(out, rc = 0);\r\n}\r\nif (UC_CACHE_IS_INVALID(entry) || UC_CACHE_IS_EXPIRED(entry)) {\r\nCERROR("%s: found a stale entry %p (key "LPU64") in ioctl\n",\r\ncache->uc_name, entry, entry->ue_key);\r\nGOTO(out, rc = -EINVAL);\r\n}\r\nspin_unlock(&cache->uc_lock);\r\nif (cache->uc_ops->parse_downcall)\r\nrc = cache->uc_ops->parse_downcall(cache, entry, args);\r\nspin_lock(&cache->uc_lock);\r\nif (rc)\r\nGOTO(out, rc);\r\nentry->ue_expire = cfs_time_shift(cache->uc_entry_expire);\r\nUC_CACHE_SET_VALID(entry);\r\nCDEBUG(D_OTHER, "%s: created upcall cache entry %p for key "LPU64"\n",\r\ncache->uc_name, entry, entry->ue_key);\r\nout:\r\nif (rc) {\r\nUC_CACHE_SET_INVALID(entry);\r\nlist_del_init(&entry->ue_hash);\r\n}\r\nUC_CACHE_CLEAR_ACQUIRING(entry);\r\nspin_unlock(&cache->uc_lock);\r\nwake_up_all(&entry->ue_waitq);\r\nput_entry(cache, entry);\r\nreturn rc;\r\n}\r\nstatic void cache_flush(struct upcall_cache *cache, int force)\r\n{\r\nstruct upcall_cache_entry *entry, *next;\r\nint i;\r\nspin_lock(&cache->uc_lock);\r\nfor (i = 0; i < UC_CACHE_HASH_SIZE; i++) {\r\nlist_for_each_entry_safe(entry, next,\r\n&cache->uc_hashtable[i], ue_hash) {\r\nif (!force && atomic_read(&entry->ue_refcount)) {\r\nUC_CACHE_SET_EXPIRED(entry);\r\ncontinue;\r\n}\r\nLASSERT(!atomic_read(&entry->ue_refcount));\r\nfree_entry(cache, entry);\r\n}\r\n}\r\nspin_unlock(&cache->uc_lock);\r\n}\r\nvoid upcall_cache_flush_idle(struct upcall_cache *cache)\r\n{\r\ncache_flush(cache, 0);\r\n}\r\nvoid upcall_cache_flush_all(struct upcall_cache *cache)\r\n{\r\ncache_flush(cache, 1);\r\n}\r\nvoid upcall_cache_flush_one(struct upcall_cache *cache, __u64 key, void *args)\r\n{\r\nstruct list_head *head;\r\nstruct upcall_cache_entry *entry;\r\nint found = 0;\r\nhead = &cache->uc_hashtable[UC_CACHE_HASH_INDEX(key)];\r\nspin_lock(&cache->uc_lock);\r\nlist_for_each_entry(entry, head, ue_hash) {\r\nif (upcall_compare(cache, entry, key, args) == 0) {\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (found) {\r\nCWARN("%s: flush entry %p: key "LPU64", ref %d, fl %x, "\r\n"cur %lu, ex %ld/%ld\n",\r\ncache->uc_name, entry, entry->ue_key,\r\natomic_read(&entry->ue_refcount), entry->ue_flags,\r\ncfs_time_current_sec(), entry->ue_acquire_expire,\r\nentry->ue_expire);\r\nUC_CACHE_SET_EXPIRED(entry);\r\nif (!atomic_read(&entry->ue_refcount))\r\nfree_entry(cache, entry);\r\n}\r\nspin_unlock(&cache->uc_lock);\r\n}\r\nstruct upcall_cache *upcall_cache_init(const char *name, const char *upcall,\r\nstruct upcall_cache_ops *ops)\r\n{\r\nstruct upcall_cache *cache;\r\nint i;\r\nLIBCFS_ALLOC(cache, sizeof(*cache));\r\nif (!cache)\r\nreturn ERR_PTR(-ENOMEM);\r\nspin_lock_init(&cache->uc_lock);\r\nrwlock_init(&cache->uc_upcall_rwlock);\r\nfor (i = 0; i < UC_CACHE_HASH_SIZE; i++)\r\nINIT_LIST_HEAD(&cache->uc_hashtable[i]);\r\nstrncpy(cache->uc_name, name, sizeof(cache->uc_name) - 1);\r\nstrncpy(cache->uc_upcall, upcall, sizeof(cache->uc_upcall) - 1);\r\ncache->uc_entry_expire = 20 * 60;\r\ncache->uc_acquire_expire = 30;\r\ncache->uc_ops = ops;\r\nreturn cache;\r\n}\r\nvoid upcall_cache_cleanup(struct upcall_cache *cache)\r\n{\r\nif (!cache)\r\nreturn;\r\nupcall_cache_flush_all(cache);\r\nLIBCFS_FREE(cache, sizeof(*cache));\r\n}
