static void a3xx_me_init(struct msm_gpu *gpu)\r\n{\r\nstruct msm_ringbuffer *ring = gpu->rb;\r\nOUT_PKT3(ring, CP_ME_INIT, 17);\r\nOUT_RING(ring, 0x000003f7);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000080);\r\nOUT_RING(ring, 0x00000100);\r\nOUT_RING(ring, 0x00000180);\r\nOUT_RING(ring, 0x00006600);\r\nOUT_RING(ring, 0x00000150);\r\nOUT_RING(ring, 0x0000014e);\r\nOUT_RING(ring, 0x00000154);\r\nOUT_RING(ring, 0x00000001);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\ngpu->funcs->flush(gpu);\r\ngpu->funcs->idle(gpu);\r\n}\r\nstatic int a3xx_hw_init(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nuint32_t *ptr, len;\r\nint i, ret;\r\nDBG("%s", gpu->name);\r\nif (adreno_is_a305(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_DDR_OUT_MAX_BURST, 0x0000303);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_GATE_OFF_WRREQ_EN, 0x0000ff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ARB_CTL, 0x00000030);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO_EN, 0x0000003c);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO, 0x003c003c);\r\n} else if (adreno_is_a320(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_DDR_OUT_MAX_BURST, 0x0000303);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_GATE_OFF_WRREQ_EN, 0x0000ff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ARB_CTL, 0x00000030);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO_EN, 0x0000003c);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO, 0x003c003c);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT, 0x000000ff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT_CONF, 0x000000a4);\r\n} else if (adreno_is_a330(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF1, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_RD_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_WR_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_DDR_OUT_MAX_BURST, 0x0000303);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF1, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_GATE_OFF_WRREQ_EN, 0x00003f);\r\ngpu_write(gpu, REG_A3XX_VBIF_ARB_CTL, 0x00000030);\r\ngpu_write(gpu, REG_A3XX_VBIF_ROUND_ROBIN_QOS_ARB, 0x0001);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO_EN, 0x0000ffff);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO, 0xffffffff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT, 0x0001ffff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT_CONF, 0x000000a4);\r\ngpu_write(gpu, REG_A3XX_VBIF_CLKON, 0x00000001);\r\n} else {\r\nBUG();\r\n}\r\ngpu_write(gpu, REG_A3XX_RBBM_GPU_BUSY_MASKED, 0xffffffff);\r\ngpu_write(gpu, REG_A3XX_RBBM_SP_HYST_CNT, 0x10);\r\ngpu_write(gpu, REG_A3XX_RBBM_WAIT_IDLE_CLOCKS_CTL, 0x10);\r\ngpu_write(gpu, REG_A3XX_RBBM_AHB_CTL0, 0x00000001);\r\ngpu_write(gpu, REG_A3XX_RBBM_AHB_CTL1, 0xa6ffffff);\r\ngpu_write(gpu, REG_A3XX_RBBM_RBBM_CTL, 0x00030000);\r\ngpu_write(gpu, REG_A3XX_RBBM_INTERFACE_HANG_INT_CTL, 0x00010fff);\r\ngpu_write(gpu, REG_A3XX_UCHE_CACHE_MODE_CONTROL_REG, 0x00000001);\r\ngpu_write(gpu, REG_A3XX_RBBM_CLOCK_CTL, 0xbfffffff);\r\ngpu_write(gpu, REG_A3XX_RBBM_PERFCTR_CTL, 0x01);\r\ngpu_write(gpu, REG_A3XX_SP_PERFCOUNTER7_SELECT,\r\nSP_FS_FULL_ALU_INSTRUCTIONS);\r\ngpu_write(gpu, REG_A3XX_RBBM_INT_0_MASK, A3XX_INT0_MASK);\r\nret = adreno_hw_init(gpu);\r\nif (ret)\r\nreturn ret;\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT_CTRL, 0x00000007);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(0), 0x63000040);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(1), 0x62000080);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(2), 0x600000cc);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(3), 0x60000108);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(4), 0x64000140);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(5), 0x66000400);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(6), 0x65000700);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(7), 0x610007d8);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(8), 0x620007e0);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(9), 0x61001178);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(10), 0x64001180);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(11), 0x60003300);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(12), 0x6b00c000);\r\nptr = (uint32_t *)(adreno_gpu->pm4->data);\r\nlen = adreno_gpu->pm4->size / 4;\r\nDBG("loading PM4 ucode version: %u", ptr[0]);\r\ngpu_write(gpu, REG_AXXX_CP_DEBUG,\r\nAXXX_CP_DEBUG_DYNAMIC_CLK_DISABLE |\r\nAXXX_CP_DEBUG_MIU_128BIT_WRITE_ENABLE);\r\ngpu_write(gpu, REG_AXXX_CP_ME_RAM_WADDR, 0);\r\nfor (i = 1; i < len; i++)\r\ngpu_write(gpu, REG_AXXX_CP_ME_RAM_DATA, ptr[i]);\r\nptr = (uint32_t *)(adreno_gpu->pfp->data);\r\nlen = adreno_gpu->pfp->size / 4;\r\nDBG("loading PFP ucode version: %u", ptr[0]);\r\ngpu_write(gpu, REG_A3XX_CP_PFP_UCODE_ADDR, 0);\r\nfor (i = 1; i < len; i++)\r\ngpu_write(gpu, REG_A3XX_CP_PFP_UCODE_DATA, ptr[i]);\r\nif (adreno_is_a305(adreno_gpu) || adreno_is_a320(adreno_gpu))\r\ngpu_write(gpu, REG_AXXX_CP_QUEUE_THRESHOLDS,\r\nAXXX_CP_QUEUE_THRESHOLDS_CSQ_IB1_START(2) |\r\nAXXX_CP_QUEUE_THRESHOLDS_CSQ_IB2_START(6) |\r\nAXXX_CP_QUEUE_THRESHOLDS_CSQ_ST_START(14));\r\ngpu_write(gpu, REG_AXXX_CP_ME_CNTL, 0);\r\na3xx_me_init(gpu);\r\nreturn 0;\r\n}\r\nstatic void a3xx_destroy(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a3xx_gpu *a3xx_gpu = to_a3xx_gpu(adreno_gpu);\r\nDBG("%s", gpu->name);\r\nadreno_gpu_cleanup(adreno_gpu);\r\nput_device(&a3xx_gpu->pdev->dev);\r\nkfree(a3xx_gpu);\r\n}\r\nstatic void a3xx_idle(struct msm_gpu *gpu)\r\n{\r\nunsigned long t;\r\nadreno_idle(gpu);\r\nt = jiffies + ADRENO_IDLE_TIMEOUT;\r\ndo {\r\nuint32_t rbbm_status = gpu_read(gpu, REG_A3XX_RBBM_STATUS);\r\nif (!(rbbm_status & A3XX_RBBM_STATUS_GPU_BUSY))\r\nreturn;\r\n} while(time_before(jiffies, t));\r\nDRM_ERROR("timeout waiting for %s to idle!\n", gpu->name);\r\n}\r\nstatic irqreturn_t a3xx_irq(struct msm_gpu *gpu)\r\n{\r\nuint32_t status;\r\nstatus = gpu_read(gpu, REG_A3XX_RBBM_INT_0_STATUS);\r\nDBG("%s: %08x", gpu->name, status);\r\ngpu_write(gpu, REG_A3XX_RBBM_INT_CLEAR_CMD, status);\r\nmsm_gpu_retire(gpu);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void a3xx_show(struct msm_gpu *gpu, struct seq_file *m)\r\n{\r\nint i;\r\nadreno_show(gpu, m);\r\nseq_printf(m, "status: %08x\n",\r\ngpu_read(gpu, REG_A3XX_RBBM_STATUS));\r\nseq_printf(m, "IO:region %s 00000000 00020000\n", gpu->name);\r\nfor (i = 0; i < ARRAY_SIZE(a3xx_registers); i += 2) {\r\nuint32_t start = a3xx_registers[i];\r\nuint32_t end = a3xx_registers[i+1];\r\nuint32_t addr;\r\nfor (addr = start; addr <= end; addr++) {\r\nuint32_t val = gpu_read(gpu, addr);\r\nseq_printf(m, "IO:R %08x %08x\n", addr<<2, val);\r\n}\r\n}\r\n}\r\nstruct msm_gpu *a3xx_gpu_init(struct drm_device *dev)\r\n{\r\nstruct a3xx_gpu *a3xx_gpu = NULL;\r\nstruct msm_gpu *gpu;\r\nstruct platform_device *pdev = a3xx_pdev;\r\nstruct adreno_platform_config *config;\r\nint ret;\r\nif (!pdev) {\r\ndev_err(dev->dev, "no a3xx device\n");\r\nret = -ENXIO;\r\ngoto fail;\r\n}\r\nconfig = pdev->dev.platform_data;\r\na3xx_gpu = kzalloc(sizeof(*a3xx_gpu), GFP_KERNEL);\r\nif (!a3xx_gpu) {\r\nret = -ENOMEM;\r\ngoto fail;\r\n}\r\ngpu = &a3xx_gpu->base.base;\r\nget_device(&pdev->dev);\r\na3xx_gpu->pdev = pdev;\r\ngpu->fast_rate = config->fast_rate;\r\ngpu->slow_rate = config->slow_rate;\r\ngpu->bus_freq = config->bus_freq;\r\nDBG("fast_rate=%u, slow_rate=%u, bus_freq=%u",\r\ngpu->fast_rate, gpu->slow_rate, gpu->bus_freq);\r\nret = adreno_gpu_init(dev, pdev, &a3xx_gpu->base,\r\n&funcs, config->rev);\r\nif (ret)\r\ngoto fail;\r\nreturn &a3xx_gpu->base.base;\r\nfail:\r\nif (a3xx_gpu)\r\na3xx_destroy(&a3xx_gpu->base.base);\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic int a3xx_probe(struct platform_device *pdev)\r\n{\r\nstatic struct adreno_platform_config config = {};\r\n#ifdef CONFIG_OF\r\n#else\r\nuint32_t version = socinfo_get_version();\r\nif (cpu_is_apq8064ab()) {\r\nconfig.fast_rate = 450000000;\r\nconfig.slow_rate = 27000000;\r\nconfig.bus_freq = 4;\r\nconfig.rev = ADRENO_REV(3, 2, 1, 0);\r\n} else if (cpu_is_apq8064() || cpu_is_msm8960ab()) {\r\nconfig.fast_rate = 400000000;\r\nconfig.slow_rate = 27000000;\r\nconfig.bus_freq = 4;\r\nif (SOCINFO_VERSION_MAJOR(version) == 2)\r\nconfig.rev = ADRENO_REV(3, 2, 0, 2);\r\nelse if ((SOCINFO_VERSION_MAJOR(version) == 1) &&\r\n(SOCINFO_VERSION_MINOR(version) == 1))\r\nconfig.rev = ADRENO_REV(3, 2, 0, 1);\r\nelse\r\nconfig.rev = ADRENO_REV(3, 2, 0, 0);\r\n} else if (cpu_is_msm8930()) {\r\nconfig.fast_rate = 400000000;\r\nconfig.slow_rate = 27000000;\r\nconfig.bus_freq = 3;\r\nif ((SOCINFO_VERSION_MAJOR(version) == 1) &&\r\n(SOCINFO_VERSION_MINOR(version) == 2))\r\nconfig.rev = ADRENO_REV(3, 0, 5, 2);\r\nelse\r\nconfig.rev = ADRENO_REV(3, 0, 5, 0);\r\n}\r\n#endif\r\npdev->dev.platform_data = &config;\r\na3xx_pdev = pdev;\r\nreturn 0;\r\n}\r\nstatic int a3xx_remove(struct platform_device *pdev)\r\n{\r\na3xx_pdev = NULL;\r\nreturn 0;\r\n}\r\nvoid __init a3xx_register(void)\r\n{\r\nplatform_driver_register(&a3xx_driver);\r\n}\r\nvoid __exit a3xx_unregister(void)\r\n{\r\nplatform_driver_unregister(&a3xx_driver);\r\n}
