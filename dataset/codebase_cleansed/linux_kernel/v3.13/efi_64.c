static void __init early_code_mapping_set_exec(int executable)\r\n{\r\nefi_memory_desc_t *md;\r\nvoid *p;\r\nif (!(__supported_pte_mask & _PAGE_NX))\r\nreturn;\r\nfor (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {\r\nmd = p;\r\nif (md->type == EFI_RUNTIME_SERVICES_CODE ||\r\nmd->type == EFI_BOOT_SERVICES_CODE)\r\nefi_set_executable(md, executable);\r\n}\r\n}\r\nvoid __init efi_call_phys_prelog(void)\r\n{\r\nunsigned long vaddress;\r\nint pgd;\r\nint n_pgds;\r\nearly_code_mapping_set_exec(1);\r\nlocal_irq_save(efi_flags);\r\nn_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT), PGDIR_SIZE);\r\nsave_pgd = kmalloc(n_pgds * sizeof(pgd_t), GFP_KERNEL);\r\nfor (pgd = 0; pgd < n_pgds; pgd++) {\r\nsave_pgd[pgd] = *pgd_offset_k(pgd * PGDIR_SIZE);\r\nvaddress = (unsigned long)__va(pgd * PGDIR_SIZE);\r\nset_pgd(pgd_offset_k(pgd * PGDIR_SIZE), *pgd_offset_k(vaddress));\r\n}\r\n__flush_tlb_all();\r\n}\r\nvoid __init efi_call_phys_epilog(void)\r\n{\r\nint pgd;\r\nint n_pgds = DIV_ROUND_UP((max_pfn << PAGE_SHIFT) , PGDIR_SIZE);\r\nfor (pgd = 0; pgd < n_pgds; pgd++)\r\nset_pgd(pgd_offset_k(pgd * PGDIR_SIZE), save_pgd[pgd]);\r\nkfree(save_pgd);\r\n__flush_tlb_all();\r\nlocal_irq_restore(efi_flags);\r\nearly_code_mapping_set_exec(0);\r\n}\r\nvoid __iomem *__init efi_ioremap(unsigned long phys_addr, unsigned long size,\r\nu32 type, u64 attribute)\r\n{\r\nunsigned long last_map_pfn;\r\nif (type == EFI_MEMORY_MAPPED_IO)\r\nreturn ioremap(phys_addr, size);\r\nlast_map_pfn = init_memory_mapping(phys_addr, phys_addr + size);\r\nif ((last_map_pfn << PAGE_SHIFT) < phys_addr + size) {\r\nunsigned long top = last_map_pfn << PAGE_SHIFT;\r\nefi_ioremap(top, size - (top - phys_addr), type, attribute);\r\n}\r\nif (!(attribute & EFI_MEMORY_WB))\r\nefi_memory_uc((u64)(unsigned long)__va(phys_addr), size);\r\nreturn (void __iomem *)__va(phys_addr);\r\n}
