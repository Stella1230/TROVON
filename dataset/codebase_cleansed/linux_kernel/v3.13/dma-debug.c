static inline void dump_entry_trace(struct dma_debug_entry *entry)\r\n{\r\n#ifdef CONFIG_STACKTRACE\r\nif (entry) {\r\npr_warning("Mapped at:\n");\r\nprint_stack_trace(&entry->stacktrace, 0);\r\n}\r\n#endif\r\n}\r\nstatic bool driver_filter(struct device *dev)\r\n{\r\nstruct device_driver *drv;\r\nunsigned long flags;\r\nbool ret;\r\nif (likely(!current_driver_name[0]))\r\nreturn true;\r\nif (current_driver && dev && dev->driver == current_driver)\r\nreturn true;\r\nif (!dev)\r\nreturn false;\r\nif (current_driver || !current_driver_name[0])\r\nreturn false;\r\ndrv = dev->driver;\r\nif (!drv)\r\nreturn false;\r\nread_lock_irqsave(&driver_name_lock, flags);\r\nret = false;\r\nif (drv->name &&\r\nstrncmp(current_driver_name, drv->name, NAME_MAX_LEN - 1) == 0) {\r\ncurrent_driver = drv;\r\nret = true;\r\n}\r\nread_unlock_irqrestore(&driver_name_lock, flags);\r\nreturn ret;\r\n}\r\nstatic int hash_fn(struct dma_debug_entry *entry)\r\n{\r\nreturn (entry->dev_addr >> HASH_FN_SHIFT) & HASH_FN_MASK;\r\n}\r\nstatic struct hash_bucket *get_hash_bucket(struct dma_debug_entry *entry,\r\nunsigned long *flags)\r\n{\r\nint idx = hash_fn(entry);\r\nunsigned long __flags;\r\nspin_lock_irqsave(&dma_entry_hash[idx].lock, __flags);\r\n*flags = __flags;\r\nreturn &dma_entry_hash[idx];\r\n}\r\nstatic void put_hash_bucket(struct hash_bucket *bucket,\r\nunsigned long *flags)\r\n{\r\nunsigned long __flags = *flags;\r\nspin_unlock_irqrestore(&bucket->lock, __flags);\r\n}\r\nstatic bool exact_match(struct dma_debug_entry *a, struct dma_debug_entry *b)\r\n{\r\nreturn ((a->dev_addr == b->dev_addr) &&\r\n(a->dev == b->dev)) ? true : false;\r\n}\r\nstatic bool containing_match(struct dma_debug_entry *a,\r\nstruct dma_debug_entry *b)\r\n{\r\nif (a->dev != b->dev)\r\nreturn false;\r\nif ((b->dev_addr <= a->dev_addr) &&\r\n((b->dev_addr + b->size) >= (a->dev_addr + a->size)))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic struct dma_debug_entry *__hash_bucket_find(struct hash_bucket *bucket,\r\nstruct dma_debug_entry *ref,\r\nmatch_fn match)\r\n{\r\nstruct dma_debug_entry *entry, *ret = NULL;\r\nint matches = 0, match_lvl, last_lvl = -1;\r\nlist_for_each_entry(entry, &bucket->list, list) {\r\nif (!match(ref, entry))\r\ncontinue;\r\nmatches += 1;\r\nmatch_lvl = 0;\r\nentry->size == ref->size ? ++match_lvl : 0;\r\nentry->type == ref->type ? ++match_lvl : 0;\r\nentry->direction == ref->direction ? ++match_lvl : 0;\r\nentry->sg_call_ents == ref->sg_call_ents ? ++match_lvl : 0;\r\nif (match_lvl == 4) {\r\nreturn entry;\r\n} else if (match_lvl > last_lvl) {\r\nlast_lvl = match_lvl;\r\nret = entry;\r\n}\r\n}\r\nret = (matches == 1) ? ret : NULL;\r\nreturn ret;\r\n}\r\nstatic struct dma_debug_entry *bucket_find_exact(struct hash_bucket *bucket,\r\nstruct dma_debug_entry *ref)\r\n{\r\nreturn __hash_bucket_find(bucket, ref, exact_match);\r\n}\r\nstatic struct dma_debug_entry *bucket_find_contain(struct hash_bucket **bucket,\r\nstruct dma_debug_entry *ref,\r\nunsigned long *flags)\r\n{\r\nunsigned int max_range = dma_get_max_seg_size(ref->dev);\r\nstruct dma_debug_entry *entry, index = *ref;\r\nunsigned int range = 0;\r\nwhile (range <= max_range) {\r\nentry = __hash_bucket_find(*bucket, &index, containing_match);\r\nif (entry)\r\nreturn entry;\r\nput_hash_bucket(*bucket, flags);\r\nrange += (1 << HASH_FN_SHIFT);\r\nindex.dev_addr -= (1 << HASH_FN_SHIFT);\r\n*bucket = get_hash_bucket(&index, flags);\r\n}\r\nreturn NULL;\r\n}\r\nstatic void hash_bucket_add(struct hash_bucket *bucket,\r\nstruct dma_debug_entry *entry)\r\n{\r\nlist_add_tail(&entry->list, &bucket->list);\r\n}\r\nstatic void hash_bucket_del(struct dma_debug_entry *entry)\r\n{\r\nlist_del(&entry->list);\r\n}\r\nvoid debug_dma_dump_mappings(struct device *dev)\r\n{\r\nint idx;\r\nfor (idx = 0; idx < HASH_SIZE; idx++) {\r\nstruct hash_bucket *bucket = &dma_entry_hash[idx];\r\nstruct dma_debug_entry *entry;\r\nunsigned long flags;\r\nspin_lock_irqsave(&bucket->lock, flags);\r\nlist_for_each_entry(entry, &bucket->list, list) {\r\nif (!dev || dev == entry->dev) {\r\ndev_info(entry->dev,\r\n"%s idx %d P=%Lx D=%Lx L=%Lx %s %s\n",\r\ntype2name[entry->type], idx,\r\n(unsigned long long)entry->paddr,\r\nentry->dev_addr, entry->size,\r\ndir2name[entry->direction],\r\nmaperr2str[entry->map_err_type]);\r\n}\r\n}\r\nspin_unlock_irqrestore(&bucket->lock, flags);\r\n}\r\n}\r\nstatic void add_dma_entry(struct dma_debug_entry *entry)\r\n{\r\nstruct hash_bucket *bucket;\r\nunsigned long flags;\r\nbucket = get_hash_bucket(entry, &flags);\r\nhash_bucket_add(bucket, entry);\r\nput_hash_bucket(bucket, &flags);\r\n}\r\nstatic struct dma_debug_entry *__dma_entry_alloc(void)\r\n{\r\nstruct dma_debug_entry *entry;\r\nentry = list_entry(free_entries.next, struct dma_debug_entry, list);\r\nlist_del(&entry->list);\r\nmemset(entry, 0, sizeof(*entry));\r\nnum_free_entries -= 1;\r\nif (num_free_entries < min_free_entries)\r\nmin_free_entries = num_free_entries;\r\nreturn entry;\r\n}\r\nstatic struct dma_debug_entry *dma_entry_alloc(void)\r\n{\r\nstruct dma_debug_entry *entry;\r\nunsigned long flags;\r\nspin_lock_irqsave(&free_entries_lock, flags);\r\nif (list_empty(&free_entries)) {\r\npr_err("DMA-API: debugging out of memory - disabling\n");\r\nglobal_disable = true;\r\nspin_unlock_irqrestore(&free_entries_lock, flags);\r\nreturn NULL;\r\n}\r\nentry = __dma_entry_alloc();\r\nspin_unlock_irqrestore(&free_entries_lock, flags);\r\n#ifdef CONFIG_STACKTRACE\r\nentry->stacktrace.max_entries = DMA_DEBUG_STACKTRACE_ENTRIES;\r\nentry->stacktrace.entries = entry->st_entries;\r\nentry->stacktrace.skip = 2;\r\nsave_stack_trace(&entry->stacktrace);\r\n#endif\r\nreturn entry;\r\n}\r\nstatic void dma_entry_free(struct dma_debug_entry *entry)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&free_entries_lock, flags);\r\nlist_add(&entry->list, &free_entries);\r\nnum_free_entries += 1;\r\nspin_unlock_irqrestore(&free_entries_lock, flags);\r\n}\r\nint dma_debug_resize_entries(u32 num_entries)\r\n{\r\nint i, delta, ret = 0;\r\nunsigned long flags;\r\nstruct dma_debug_entry *entry;\r\nLIST_HEAD(tmp);\r\nspin_lock_irqsave(&free_entries_lock, flags);\r\nif (nr_total_entries < num_entries) {\r\ndelta = num_entries - nr_total_entries;\r\nspin_unlock_irqrestore(&free_entries_lock, flags);\r\nfor (i = 0; i < delta; i++) {\r\nentry = kzalloc(sizeof(*entry), GFP_KERNEL);\r\nif (!entry)\r\nbreak;\r\nlist_add_tail(&entry->list, &tmp);\r\n}\r\nspin_lock_irqsave(&free_entries_lock, flags);\r\nlist_splice(&tmp, &free_entries);\r\nnr_total_entries += i;\r\nnum_free_entries += i;\r\n} else {\r\ndelta = nr_total_entries - num_entries;\r\nfor (i = 0; i < delta && !list_empty(&free_entries); i++) {\r\nentry = __dma_entry_alloc();\r\nkfree(entry);\r\n}\r\nnr_total_entries -= i;\r\n}\r\nif (nr_total_entries != num_entries)\r\nret = 1;\r\nspin_unlock_irqrestore(&free_entries_lock, flags);\r\nreturn ret;\r\n}\r\nstatic int prealloc_memory(u32 num_entries)\r\n{\r\nstruct dma_debug_entry *entry, *next_entry;\r\nint i;\r\nfor (i = 0; i < num_entries; ++i) {\r\nentry = kzalloc(sizeof(*entry), GFP_KERNEL);\r\nif (!entry)\r\ngoto out_err;\r\nlist_add_tail(&entry->list, &free_entries);\r\n}\r\nnum_free_entries = num_entries;\r\nmin_free_entries = num_entries;\r\npr_info("DMA-API: preallocated %d debug entries\n", num_entries);\r\nreturn 0;\r\nout_err:\r\nlist_for_each_entry_safe(entry, next_entry, &free_entries, list) {\r\nlist_del(&entry->list);\r\nkfree(entry);\r\n}\r\nreturn -ENOMEM;\r\n}\r\nstatic ssize_t filter_read(struct file *file, char __user *user_buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nchar buf[NAME_MAX_LEN + 1];\r\nunsigned long flags;\r\nint len;\r\nif (!current_driver_name[0])\r\nreturn 0;\r\nread_lock_irqsave(&driver_name_lock, flags);\r\nlen = scnprintf(buf, NAME_MAX_LEN + 1, "%s\n", current_driver_name);\r\nread_unlock_irqrestore(&driver_name_lock, flags);\r\nreturn simple_read_from_buffer(user_buf, count, ppos, buf, len);\r\n}\r\nstatic ssize_t filter_write(struct file *file, const char __user *userbuf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nchar buf[NAME_MAX_LEN];\r\nunsigned long flags;\r\nsize_t len;\r\nint i;\r\nlen = min(count, (size_t)(NAME_MAX_LEN - 1));\r\nif (copy_from_user(buf, userbuf, len))\r\nreturn -EFAULT;\r\nbuf[len] = 0;\r\nwrite_lock_irqsave(&driver_name_lock, flags);\r\nif (!isalnum(buf[0])) {\r\nif (current_driver_name[0])\r\npr_info("DMA-API: switching off dma-debug driver filter\n");\r\ncurrent_driver_name[0] = 0;\r\ncurrent_driver = NULL;\r\ngoto out_unlock;\r\n}\r\nfor (i = 0; i < NAME_MAX_LEN - 1; ++i) {\r\ncurrent_driver_name[i] = buf[i];\r\nif (isspace(buf[i]) || buf[i] == ' ' || buf[i] == 0)\r\nbreak;\r\n}\r\ncurrent_driver_name[i] = 0;\r\ncurrent_driver = NULL;\r\npr_info("DMA-API: enable driver filter for driver [%s]\n",\r\ncurrent_driver_name);\r\nout_unlock:\r\nwrite_unlock_irqrestore(&driver_name_lock, flags);\r\nreturn count;\r\n}\r\nstatic int dma_debug_fs_init(void)\r\n{\r\ndma_debug_dent = debugfs_create_dir("dma-api", NULL);\r\nif (!dma_debug_dent) {\r\npr_err("DMA-API: can not create debugfs directory\n");\r\nreturn -ENOMEM;\r\n}\r\nglobal_disable_dent = debugfs_create_bool("disabled", 0444,\r\ndma_debug_dent,\r\n&global_disable);\r\nif (!global_disable_dent)\r\ngoto out_err;\r\nerror_count_dent = debugfs_create_u32("error_count", 0444,\r\ndma_debug_dent, &error_count);\r\nif (!error_count_dent)\r\ngoto out_err;\r\nshow_all_errors_dent = debugfs_create_u32("all_errors", 0644,\r\ndma_debug_dent,\r\n&show_all_errors);\r\nif (!show_all_errors_dent)\r\ngoto out_err;\r\nshow_num_errors_dent = debugfs_create_u32("num_errors", 0644,\r\ndma_debug_dent,\r\n&show_num_errors);\r\nif (!show_num_errors_dent)\r\ngoto out_err;\r\nnum_free_entries_dent = debugfs_create_u32("num_free_entries", 0444,\r\ndma_debug_dent,\r\n&num_free_entries);\r\nif (!num_free_entries_dent)\r\ngoto out_err;\r\nmin_free_entries_dent = debugfs_create_u32("min_free_entries", 0444,\r\ndma_debug_dent,\r\n&min_free_entries);\r\nif (!min_free_entries_dent)\r\ngoto out_err;\r\nfilter_dent = debugfs_create_file("driver_filter", 0644,\r\ndma_debug_dent, NULL, &filter_fops);\r\nif (!filter_dent)\r\ngoto out_err;\r\nreturn 0;\r\nout_err:\r\ndebugfs_remove_recursive(dma_debug_dent);\r\nreturn -ENOMEM;\r\n}\r\nstatic int device_dma_allocations(struct device *dev, struct dma_debug_entry **out_entry)\r\n{\r\nstruct dma_debug_entry *entry;\r\nunsigned long flags;\r\nint count = 0, i;\r\nlocal_irq_save(flags);\r\nfor (i = 0; i < HASH_SIZE; ++i) {\r\nspin_lock(&dma_entry_hash[i].lock);\r\nlist_for_each_entry(entry, &dma_entry_hash[i].list, list) {\r\nif (entry->dev == dev) {\r\ncount += 1;\r\n*out_entry = entry;\r\n}\r\n}\r\nspin_unlock(&dma_entry_hash[i].lock);\r\n}\r\nlocal_irq_restore(flags);\r\nreturn count;\r\n}\r\nstatic int dma_debug_device_change(struct notifier_block *nb, unsigned long action, void *data)\r\n{\r\nstruct device *dev = data;\r\nstruct dma_debug_entry *uninitialized_var(entry);\r\nint count;\r\nif (global_disable)\r\nreturn 0;\r\nswitch (action) {\r\ncase BUS_NOTIFY_UNBOUND_DRIVER:\r\ncount = device_dma_allocations(dev, &entry);\r\nif (count == 0)\r\nbreak;\r\nerr_printk(dev, entry, "DMA-API: device driver has pending "\r\n"DMA allocations while released from device "\r\n"[count=%d]\n"\r\n"One of leaked entries details: "\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[mapped with %s] [mapped as %s]\n",\r\ncount, entry->dev_addr, entry->size,\r\ndir2name[entry->direction], type2name[entry->type]);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nvoid dma_debug_add_bus(struct bus_type *bus)\r\n{\r\nstruct notifier_block *nb;\r\nif (global_disable)\r\nreturn;\r\nnb = kzalloc(sizeof(struct notifier_block), GFP_KERNEL);\r\nif (nb == NULL) {\r\npr_err("dma_debug_add_bus: out of memory\n");\r\nreturn;\r\n}\r\nnb->notifier_call = dma_debug_device_change;\r\nbus_register_notifier(bus, nb);\r\n}\r\nvoid dma_debug_init(u32 num_entries)\r\n{\r\nint i;\r\nif (global_disable)\r\nreturn;\r\nfor (i = 0; i < HASH_SIZE; ++i) {\r\nINIT_LIST_HEAD(&dma_entry_hash[i].list);\r\nspin_lock_init(&dma_entry_hash[i].lock);\r\n}\r\nif (dma_debug_fs_init() != 0) {\r\npr_err("DMA-API: error creating debugfs entries - disabling\n");\r\nglobal_disable = true;\r\nreturn;\r\n}\r\nif (req_entries)\r\nnum_entries = req_entries;\r\nif (prealloc_memory(num_entries) != 0) {\r\npr_err("DMA-API: debugging out of memory error - disabled\n");\r\nglobal_disable = true;\r\nreturn;\r\n}\r\nnr_total_entries = num_free_entries;\r\npr_info("DMA-API: debugging enabled by kernel config\n");\r\n}\r\nstatic __init int dma_debug_cmdline(char *str)\r\n{\r\nif (!str)\r\nreturn -EINVAL;\r\nif (strncmp(str, "off", 3) == 0) {\r\npr_info("DMA-API: debugging disabled on kernel command line\n");\r\nglobal_disable = true;\r\n}\r\nreturn 0;\r\n}\r\nstatic __init int dma_debug_entries_cmdline(char *str)\r\n{\r\nint res;\r\nif (!str)\r\nreturn -EINVAL;\r\nres = get_option(&str, &req_entries);\r\nif (!res)\r\nreq_entries = 0;\r\nreturn 0;\r\n}\r\nstatic void check_unmap(struct dma_debug_entry *ref)\r\n{\r\nstruct dma_debug_entry *entry;\r\nstruct hash_bucket *bucket;\r\nunsigned long flags;\r\nbucket = get_hash_bucket(ref, &flags);\r\nentry = bucket_find_exact(bucket, ref);\r\nif (!entry) {\r\nput_hash_bucket(bucket, &flags);\r\nif (dma_mapping_error(ref->dev, ref->dev_addr)) {\r\nerr_printk(ref->dev, NULL,\r\n"DMA-API: device driver tries to free an "\r\n"invalid DMA memory address\n");\r\n} else {\r\nerr_printk(ref->dev, NULL,\r\n"DMA-API: device driver tries to free DMA "\r\n"memory it has not allocated [device "\r\n"address=0x%016llx] [size=%llu bytes]\n",\r\nref->dev_addr, ref->size);\r\n}\r\nreturn;\r\n}\r\nif (ref->size != entry->size) {\r\nerr_printk(ref->dev, entry, "DMA-API: device driver frees "\r\n"DMA memory with different size "\r\n"[device address=0x%016llx] [map size=%llu bytes] "\r\n"[unmap size=%llu bytes]\n",\r\nref->dev_addr, entry->size, ref->size);\r\n}\r\nif (ref->type != entry->type) {\r\nerr_printk(ref->dev, entry, "DMA-API: device driver frees "\r\n"DMA memory with wrong function "\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[mapped as %s] [unmapped as %s]\n",\r\nref->dev_addr, ref->size,\r\ntype2name[entry->type], type2name[ref->type]);\r\n} else if ((entry->type == dma_debug_coherent) &&\r\n(ref->paddr != entry->paddr)) {\r\nerr_printk(ref->dev, entry, "DMA-API: device driver frees "\r\n"DMA memory with different CPU address "\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[cpu alloc address=0x%016llx] "\r\n"[cpu free address=0x%016llx]",\r\nref->dev_addr, ref->size,\r\n(unsigned long long)entry->paddr,\r\n(unsigned long long)ref->paddr);\r\n}\r\nif (ref->sg_call_ents && ref->type == dma_debug_sg &&\r\nref->sg_call_ents != entry->sg_call_ents) {\r\nerr_printk(ref->dev, entry, "DMA-API: device driver frees "\r\n"DMA sg list with different entry count "\r\n"[map count=%d] [unmap count=%d]\n",\r\nentry->sg_call_ents, ref->sg_call_ents);\r\n}\r\nif (ref->direction != entry->direction) {\r\nerr_printk(ref->dev, entry, "DMA-API: device driver frees "\r\n"DMA memory with different direction "\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[mapped with %s] [unmapped with %s]\n",\r\nref->dev_addr, ref->size,\r\ndir2name[entry->direction],\r\ndir2name[ref->direction]);\r\n}\r\nif (entry->map_err_type == MAP_ERR_NOT_CHECKED) {\r\nerr_printk(ref->dev, entry,\r\n"DMA-API: device driver failed to check map error"\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[mapped as %s]",\r\nref->dev_addr, ref->size,\r\ntype2name[entry->type]);\r\n}\r\nhash_bucket_del(entry);\r\ndma_entry_free(entry);\r\nput_hash_bucket(bucket, &flags);\r\n}\r\nstatic void check_for_stack(struct device *dev, void *addr)\r\n{\r\nif (object_is_on_stack(addr))\r\nerr_printk(dev, NULL, "DMA-API: device driver maps memory from"\r\n"stack [addr=%p]\n", addr);\r\n}\r\nstatic inline bool overlap(void *addr, unsigned long len, void *start, void *end)\r\n{\r\nunsigned long a1 = (unsigned long)addr;\r\nunsigned long b1 = a1 + len;\r\nunsigned long a2 = (unsigned long)start;\r\nunsigned long b2 = (unsigned long)end;\r\nreturn !(b1 <= a2 || a1 >= b2);\r\n}\r\nstatic void check_for_illegal_area(struct device *dev, void *addr, unsigned long len)\r\n{\r\nif (overlap(addr, len, _text, _etext) ||\r\noverlap(addr, len, __start_rodata, __end_rodata))\r\nerr_printk(dev, NULL, "DMA-API: device driver maps memory from kernel text or rodata [addr=%p] [len=%lu]\n", addr, len);\r\n}\r\nstatic void check_sync(struct device *dev,\r\nstruct dma_debug_entry *ref,\r\nbool to_cpu)\r\n{\r\nstruct dma_debug_entry *entry;\r\nstruct hash_bucket *bucket;\r\nunsigned long flags;\r\nbucket = get_hash_bucket(ref, &flags);\r\nentry = bucket_find_contain(&bucket, ref, &flags);\r\nif (!entry) {\r\nerr_printk(dev, NULL, "DMA-API: device driver tries "\r\n"to sync DMA memory it has not allocated "\r\n"[device address=0x%016llx] [size=%llu bytes]\n",\r\n(unsigned long long)ref->dev_addr, ref->size);\r\ngoto out;\r\n}\r\nif (ref->size > entry->size) {\r\nerr_printk(dev, entry, "DMA-API: device driver syncs"\r\n" DMA memory outside allocated range "\r\n"[device address=0x%016llx] "\r\n"[allocation size=%llu bytes] "\r\n"[sync offset+size=%llu]\n",\r\nentry->dev_addr, entry->size,\r\nref->size);\r\n}\r\nif (entry->direction == DMA_BIDIRECTIONAL)\r\ngoto out;\r\nif (ref->direction != entry->direction) {\r\nerr_printk(dev, entry, "DMA-API: device driver syncs "\r\n"DMA memory with different direction "\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[mapped with %s] [synced with %s]\n",\r\n(unsigned long long)ref->dev_addr, entry->size,\r\ndir2name[entry->direction],\r\ndir2name[ref->direction]);\r\n}\r\nif (to_cpu && !(entry->direction == DMA_FROM_DEVICE) &&\r\n!(ref->direction == DMA_TO_DEVICE))\r\nerr_printk(dev, entry, "DMA-API: device driver syncs "\r\n"device read-only DMA memory for cpu "\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[mapped with %s] [synced with %s]\n",\r\n(unsigned long long)ref->dev_addr, entry->size,\r\ndir2name[entry->direction],\r\ndir2name[ref->direction]);\r\nif (!to_cpu && !(entry->direction == DMA_TO_DEVICE) &&\r\n!(ref->direction == DMA_FROM_DEVICE))\r\nerr_printk(dev, entry, "DMA-API: device driver syncs "\r\n"device write-only DMA memory to device "\r\n"[device address=0x%016llx] [size=%llu bytes] "\r\n"[mapped with %s] [synced with %s]\n",\r\n(unsigned long long)ref->dev_addr, entry->size,\r\ndir2name[entry->direction],\r\ndir2name[ref->direction]);\r\nout:\r\nput_hash_bucket(bucket, &flags);\r\n}\r\nvoid debug_dma_map_page(struct device *dev, struct page *page, size_t offset,\r\nsize_t size, int direction, dma_addr_t dma_addr,\r\nbool map_single)\r\n{\r\nstruct dma_debug_entry *entry;\r\nif (unlikely(global_disable))\r\nreturn;\r\nif (dma_mapping_error(dev, dma_addr))\r\nreturn;\r\nentry = dma_entry_alloc();\r\nif (!entry)\r\nreturn;\r\nentry->dev = dev;\r\nentry->type = dma_debug_page;\r\nentry->paddr = page_to_phys(page) + offset;\r\nentry->dev_addr = dma_addr;\r\nentry->size = size;\r\nentry->direction = direction;\r\nentry->map_err_type = MAP_ERR_NOT_CHECKED;\r\nif (map_single)\r\nentry->type = dma_debug_single;\r\nif (!PageHighMem(page)) {\r\nvoid *addr = page_address(page) + offset;\r\ncheck_for_stack(dev, addr);\r\ncheck_for_illegal_area(dev, addr, size);\r\n}\r\nadd_dma_entry(entry);\r\n}\r\nvoid debug_dma_mapping_error(struct device *dev, dma_addr_t dma_addr)\r\n{\r\nstruct dma_debug_entry ref;\r\nstruct dma_debug_entry *entry;\r\nstruct hash_bucket *bucket;\r\nunsigned long flags;\r\nif (unlikely(global_disable))\r\nreturn;\r\nref.dev = dev;\r\nref.dev_addr = dma_addr;\r\nbucket = get_hash_bucket(&ref, &flags);\r\nlist_for_each_entry(entry, &bucket->list, list) {\r\nif (!exact_match(&ref, entry))\r\ncontinue;\r\nif (entry->map_err_type == MAP_ERR_NOT_CHECKED) {\r\nentry->map_err_type = MAP_ERR_CHECKED;\r\nbreak;\r\n}\r\n}\r\nput_hash_bucket(bucket, &flags);\r\n}\r\nvoid debug_dma_unmap_page(struct device *dev, dma_addr_t addr,\r\nsize_t size, int direction, bool map_single)\r\n{\r\nstruct dma_debug_entry ref = {\r\n.type = dma_debug_page,\r\n.dev = dev,\r\n.dev_addr = addr,\r\n.size = size,\r\n.direction = direction,\r\n};\r\nif (unlikely(global_disable))\r\nreturn;\r\nif (map_single)\r\nref.type = dma_debug_single;\r\ncheck_unmap(&ref);\r\n}\r\nvoid debug_dma_map_sg(struct device *dev, struct scatterlist *sg,\r\nint nents, int mapped_ents, int direction)\r\n{\r\nstruct dma_debug_entry *entry;\r\nstruct scatterlist *s;\r\nint i;\r\nif (unlikely(global_disable))\r\nreturn;\r\nfor_each_sg(sg, s, mapped_ents, i) {\r\nentry = dma_entry_alloc();\r\nif (!entry)\r\nreturn;\r\nentry->type = dma_debug_sg;\r\nentry->dev = dev;\r\nentry->paddr = sg_phys(s);\r\nentry->size = sg_dma_len(s);\r\nentry->dev_addr = sg_dma_address(s);\r\nentry->direction = direction;\r\nentry->sg_call_ents = nents;\r\nentry->sg_mapped_ents = mapped_ents;\r\nif (!PageHighMem(sg_page(s))) {\r\ncheck_for_stack(dev, sg_virt(s));\r\ncheck_for_illegal_area(dev, sg_virt(s), sg_dma_len(s));\r\n}\r\nadd_dma_entry(entry);\r\n}\r\n}\r\nstatic int get_nr_mapped_entries(struct device *dev,\r\nstruct dma_debug_entry *ref)\r\n{\r\nstruct dma_debug_entry *entry;\r\nstruct hash_bucket *bucket;\r\nunsigned long flags;\r\nint mapped_ents;\r\nbucket = get_hash_bucket(ref, &flags);\r\nentry = bucket_find_exact(bucket, ref);\r\nmapped_ents = 0;\r\nif (entry)\r\nmapped_ents = entry->sg_mapped_ents;\r\nput_hash_bucket(bucket, &flags);\r\nreturn mapped_ents;\r\n}\r\nvoid debug_dma_unmap_sg(struct device *dev, struct scatterlist *sglist,\r\nint nelems, int dir)\r\n{\r\nstruct scatterlist *s;\r\nint mapped_ents = 0, i;\r\nif (unlikely(global_disable))\r\nreturn;\r\nfor_each_sg(sglist, s, nelems, i) {\r\nstruct dma_debug_entry ref = {\r\n.type = dma_debug_sg,\r\n.dev = dev,\r\n.paddr = sg_phys(s),\r\n.dev_addr = sg_dma_address(s),\r\n.size = sg_dma_len(s),\r\n.direction = dir,\r\n.sg_call_ents = nelems,\r\n};\r\nif (mapped_ents && i >= mapped_ents)\r\nbreak;\r\nif (!i)\r\nmapped_ents = get_nr_mapped_entries(dev, &ref);\r\ncheck_unmap(&ref);\r\n}\r\n}\r\nvoid debug_dma_alloc_coherent(struct device *dev, size_t size,\r\ndma_addr_t dma_addr, void *virt)\r\n{\r\nstruct dma_debug_entry *entry;\r\nif (unlikely(global_disable))\r\nreturn;\r\nif (unlikely(virt == NULL))\r\nreturn;\r\nentry = dma_entry_alloc();\r\nif (!entry)\r\nreturn;\r\nentry->type = dma_debug_coherent;\r\nentry->dev = dev;\r\nentry->paddr = virt_to_phys(virt);\r\nentry->size = size;\r\nentry->dev_addr = dma_addr;\r\nentry->direction = DMA_BIDIRECTIONAL;\r\nadd_dma_entry(entry);\r\n}\r\nvoid debug_dma_free_coherent(struct device *dev, size_t size,\r\nvoid *virt, dma_addr_t addr)\r\n{\r\nstruct dma_debug_entry ref = {\r\n.type = dma_debug_coherent,\r\n.dev = dev,\r\n.paddr = virt_to_phys(virt),\r\n.dev_addr = addr,\r\n.size = size,\r\n.direction = DMA_BIDIRECTIONAL,\r\n};\r\nif (unlikely(global_disable))\r\nreturn;\r\ncheck_unmap(&ref);\r\n}\r\nvoid debug_dma_sync_single_for_cpu(struct device *dev, dma_addr_t dma_handle,\r\nsize_t size, int direction)\r\n{\r\nstruct dma_debug_entry ref;\r\nif (unlikely(global_disable))\r\nreturn;\r\nref.type = dma_debug_single;\r\nref.dev = dev;\r\nref.dev_addr = dma_handle;\r\nref.size = size;\r\nref.direction = direction;\r\nref.sg_call_ents = 0;\r\ncheck_sync(dev, &ref, true);\r\n}\r\nvoid debug_dma_sync_single_for_device(struct device *dev,\r\ndma_addr_t dma_handle, size_t size,\r\nint direction)\r\n{\r\nstruct dma_debug_entry ref;\r\nif (unlikely(global_disable))\r\nreturn;\r\nref.type = dma_debug_single;\r\nref.dev = dev;\r\nref.dev_addr = dma_handle;\r\nref.size = size;\r\nref.direction = direction;\r\nref.sg_call_ents = 0;\r\ncheck_sync(dev, &ref, false);\r\n}\r\nvoid debug_dma_sync_single_range_for_cpu(struct device *dev,\r\ndma_addr_t dma_handle,\r\nunsigned long offset, size_t size,\r\nint direction)\r\n{\r\nstruct dma_debug_entry ref;\r\nif (unlikely(global_disable))\r\nreturn;\r\nref.type = dma_debug_single;\r\nref.dev = dev;\r\nref.dev_addr = dma_handle;\r\nref.size = offset + size;\r\nref.direction = direction;\r\nref.sg_call_ents = 0;\r\ncheck_sync(dev, &ref, true);\r\n}\r\nvoid debug_dma_sync_single_range_for_device(struct device *dev,\r\ndma_addr_t dma_handle,\r\nunsigned long offset,\r\nsize_t size, int direction)\r\n{\r\nstruct dma_debug_entry ref;\r\nif (unlikely(global_disable))\r\nreturn;\r\nref.type = dma_debug_single;\r\nref.dev = dev;\r\nref.dev_addr = dma_handle;\r\nref.size = offset + size;\r\nref.direction = direction;\r\nref.sg_call_ents = 0;\r\ncheck_sync(dev, &ref, false);\r\n}\r\nvoid debug_dma_sync_sg_for_cpu(struct device *dev, struct scatterlist *sg,\r\nint nelems, int direction)\r\n{\r\nstruct scatterlist *s;\r\nint mapped_ents = 0, i;\r\nif (unlikely(global_disable))\r\nreturn;\r\nfor_each_sg(sg, s, nelems, i) {\r\nstruct dma_debug_entry ref = {\r\n.type = dma_debug_sg,\r\n.dev = dev,\r\n.paddr = sg_phys(s),\r\n.dev_addr = sg_dma_address(s),\r\n.size = sg_dma_len(s),\r\n.direction = direction,\r\n.sg_call_ents = nelems,\r\n};\r\nif (!i)\r\nmapped_ents = get_nr_mapped_entries(dev, &ref);\r\nif (i >= mapped_ents)\r\nbreak;\r\ncheck_sync(dev, &ref, true);\r\n}\r\n}\r\nvoid debug_dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg,\r\nint nelems, int direction)\r\n{\r\nstruct scatterlist *s;\r\nint mapped_ents = 0, i;\r\nif (unlikely(global_disable))\r\nreturn;\r\nfor_each_sg(sg, s, nelems, i) {\r\nstruct dma_debug_entry ref = {\r\n.type = dma_debug_sg,\r\n.dev = dev,\r\n.paddr = sg_phys(s),\r\n.dev_addr = sg_dma_address(s),\r\n.size = sg_dma_len(s),\r\n.direction = direction,\r\n.sg_call_ents = nelems,\r\n};\r\nif (!i)\r\nmapped_ents = get_nr_mapped_entries(dev, &ref);\r\nif (i >= mapped_ents)\r\nbreak;\r\ncheck_sync(dev, &ref, false);\r\n}\r\n}\r\nstatic int __init dma_debug_driver_setup(char *str)\r\n{\r\nint i;\r\nfor (i = 0; i < NAME_MAX_LEN - 1; ++i, ++str) {\r\ncurrent_driver_name[i] = *str;\r\nif (*str == 0)\r\nbreak;\r\n}\r\nif (current_driver_name[0])\r\npr_info("DMA-API: enable driver filter for driver [%s]\n",\r\ncurrent_driver_name);\r\nreturn 1;\r\n}
