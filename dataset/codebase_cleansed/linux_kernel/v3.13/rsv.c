bool uwb_rsv_has_two_drp_ies(struct uwb_rsv *rsv)\r\n{\r\nstatic const bool has_two_drp_ies[] = {\r\n[UWB_RSV_STATE_O_INITIATED] = false,\r\n[UWB_RSV_STATE_O_PENDING] = false,\r\n[UWB_RSV_STATE_O_MODIFIED] = false,\r\n[UWB_RSV_STATE_O_ESTABLISHED] = false,\r\n[UWB_RSV_STATE_O_TO_BE_MOVED] = false,\r\n[UWB_RSV_STATE_O_MOVE_COMBINING] = false,\r\n[UWB_RSV_STATE_O_MOVE_REDUCING] = false,\r\n[UWB_RSV_STATE_O_MOVE_EXPANDING] = true,\r\n[UWB_RSV_STATE_T_ACCEPTED] = false,\r\n[UWB_RSV_STATE_T_CONFLICT] = false,\r\n[UWB_RSV_STATE_T_PENDING] = false,\r\n[UWB_RSV_STATE_T_DENIED] = false,\r\n[UWB_RSV_STATE_T_RESIZED] = false,\r\n[UWB_RSV_STATE_T_EXPANDING_ACCEPTED] = true,\r\n[UWB_RSV_STATE_T_EXPANDING_CONFLICT] = true,\r\n[UWB_RSV_STATE_T_EXPANDING_PENDING] = true,\r\n[UWB_RSV_STATE_T_EXPANDING_DENIED] = true,\r\n};\r\nreturn has_two_drp_ies[rsv->state];\r\n}\r\nconst char *uwb_rsv_state_str(enum uwb_rsv_state state)\r\n{\r\nif (state < UWB_RSV_STATE_NONE || state >= UWB_RSV_STATE_LAST)\r\nreturn "unknown";\r\nreturn rsv_states[state];\r\n}\r\nconst char *uwb_rsv_type_str(enum uwb_drp_type type)\r\n{\r\nif (type < UWB_DRP_TYPE_ALIEN_BP || type > UWB_DRP_TYPE_PCA)\r\nreturn "invalid";\r\nreturn rsv_types[type];\r\n}\r\nvoid uwb_rsv_dump(char *text, struct uwb_rsv *rsv)\r\n{\r\nstruct device *dev = &rsv->rc->uwb_dev.dev;\r\nstruct uwb_dev_addr devaddr;\r\nchar owner[UWB_ADDR_STRSIZE], target[UWB_ADDR_STRSIZE];\r\nuwb_dev_addr_print(owner, sizeof(owner), &rsv->owner->dev_addr);\r\nif (rsv->target.type == UWB_RSV_TARGET_DEV)\r\ndevaddr = rsv->target.dev->dev_addr;\r\nelse\r\ndevaddr = rsv->target.devaddr;\r\nuwb_dev_addr_print(target, sizeof(target), &devaddr);\r\ndev_dbg(dev, "rsv %s %s -> %s: %s\n",\r\ntext, owner, target, uwb_rsv_state_str(rsv->state));\r\n}\r\nstatic void uwb_rsv_release(struct kref *kref)\r\n{\r\nstruct uwb_rsv *rsv = container_of(kref, struct uwb_rsv, kref);\r\nkfree(rsv);\r\n}\r\nvoid uwb_rsv_get(struct uwb_rsv *rsv)\r\n{\r\nkref_get(&rsv->kref);\r\n}\r\nvoid uwb_rsv_put(struct uwb_rsv *rsv)\r\n{\r\nkref_put(&rsv->kref, uwb_rsv_release);\r\n}\r\nstatic int uwb_rsv_get_stream(struct uwb_rsv *rsv)\r\n{\r\nstruct uwb_rc *rc = rsv->rc;\r\nstruct device *dev = &rc->uwb_dev.dev;\r\nunsigned long *streams_bm;\r\nint stream;\r\nswitch (rsv->target.type) {\r\ncase UWB_RSV_TARGET_DEV:\r\nstreams_bm = rsv->target.dev->streams;\r\nbreak;\r\ncase UWB_RSV_TARGET_DEVADDR:\r\nstreams_bm = rc->uwb_dev.streams;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nstream = find_first_zero_bit(streams_bm, UWB_NUM_STREAMS);\r\nif (stream >= UWB_NUM_STREAMS)\r\nreturn -EBUSY;\r\nrsv->stream = stream;\r\nset_bit(stream, streams_bm);\r\ndev_dbg(dev, "get stream %d\n", rsv->stream);\r\nreturn 0;\r\n}\r\nstatic void uwb_rsv_put_stream(struct uwb_rsv *rsv)\r\n{\r\nstruct uwb_rc *rc = rsv->rc;\r\nstruct device *dev = &rc->uwb_dev.dev;\r\nunsigned long *streams_bm;\r\nswitch (rsv->target.type) {\r\ncase UWB_RSV_TARGET_DEV:\r\nstreams_bm = rsv->target.dev->streams;\r\nbreak;\r\ncase UWB_RSV_TARGET_DEVADDR:\r\nstreams_bm = rc->uwb_dev.streams;\r\nbreak;\r\ndefault:\r\nreturn;\r\n}\r\nclear_bit(rsv->stream, streams_bm);\r\ndev_dbg(dev, "put stream %d\n", rsv->stream);\r\n}\r\nvoid uwb_rsv_backoff_win_timer(unsigned long arg)\r\n{\r\nstruct uwb_drp_backoff_win *bow = (struct uwb_drp_backoff_win *)arg;\r\nstruct uwb_rc *rc = container_of(bow, struct uwb_rc, bow);\r\nstruct device *dev = &rc->uwb_dev.dev;\r\nbow->can_reserve_extra_mases = true;\r\nif (bow->total_expired <= 4) {\r\nbow->total_expired++;\r\n} else {\r\nbow->total_expired = 0;\r\nbow->window = UWB_DRP_BACKOFF_WIN_MIN >> 1;\r\n}\r\ndev_dbg(dev, "backoff_win_timer total_expired=%d, n=%d\n: ", bow->total_expired, bow->n);\r\nuwb_rsv_handle_drp_avail_change(rc);\r\n}\r\nvoid uwb_rsv_backoff_win_increment(struct uwb_rc *rc)\r\n{\r\nstruct uwb_drp_backoff_win *bow = &rc->bow;\r\nstruct device *dev = &rc->uwb_dev.dev;\r\nunsigned timeout_us;\r\ndev_dbg(dev, "backoff_win_increment: window=%d\n", bow->window);\r\nbow->can_reserve_extra_mases = false;\r\nif((bow->window << 1) == UWB_DRP_BACKOFF_WIN_MAX)\r\nreturn;\r\nbow->window <<= 1;\r\nbow->n = prandom_u32() & (bow->window - 1);\r\ndev_dbg(dev, "new_window=%d, n=%d\n: ", bow->window, bow->n);\r\ntimeout_us = bow->n * UWB_SUPERFRAME_LENGTH_US;\r\nbow->total_expired = 0;\r\nmod_timer(&bow->timer, jiffies + usecs_to_jiffies(timeout_us));\r\n}\r\nstatic void uwb_rsv_stroke_timer(struct uwb_rsv *rsv)\r\n{\r\nint sframes = UWB_MAX_LOST_BEACONS;\r\nif (rsv->is_multicast) {\r\nif (rsv->state == UWB_RSV_STATE_O_INITIATED\r\n|| rsv->state == UWB_RSV_STATE_O_MOVE_EXPANDING\r\n|| rsv->state == UWB_RSV_STATE_O_MOVE_COMBINING\r\n|| rsv->state == UWB_RSV_STATE_O_MOVE_REDUCING)\r\nsframes = 1;\r\nif (rsv->state == UWB_RSV_STATE_O_ESTABLISHED)\r\nsframes = 0;\r\n}\r\nif (sframes > 0) {\r\nunsigned timeout_us = (sframes + 2) * UWB_SUPERFRAME_LENGTH_US;\r\nmod_timer(&rsv->timer, jiffies + usecs_to_jiffies(timeout_us));\r\n} else\r\ndel_timer(&rsv->timer);\r\n}\r\nstatic void uwb_rsv_state_update(struct uwb_rsv *rsv,\r\nenum uwb_rsv_state new_state)\r\n{\r\nrsv->state = new_state;\r\nrsv->ie_valid = false;\r\nuwb_rsv_dump("SU", rsv);\r\nuwb_rsv_stroke_timer(rsv);\r\nuwb_rsv_sched_update(rsv->rc);\r\n}\r\nstatic void uwb_rsv_callback(struct uwb_rsv *rsv)\r\n{\r\nif (rsv->callback)\r\nrsv->callback(rsv);\r\n}\r\nvoid uwb_rsv_set_state(struct uwb_rsv *rsv, enum uwb_rsv_state new_state)\r\n{\r\nstruct uwb_rsv_move *mv = &rsv->mv;\r\nif (rsv->state == new_state) {\r\nswitch (rsv->state) {\r\ncase UWB_RSV_STATE_O_ESTABLISHED:\r\ncase UWB_RSV_STATE_O_MOVE_EXPANDING:\r\ncase UWB_RSV_STATE_O_MOVE_COMBINING:\r\ncase UWB_RSV_STATE_O_MOVE_REDUCING:\r\ncase UWB_RSV_STATE_T_ACCEPTED:\r\ncase UWB_RSV_STATE_T_EXPANDING_ACCEPTED:\r\ncase UWB_RSV_STATE_T_RESIZED:\r\ncase UWB_RSV_STATE_NONE:\r\nuwb_rsv_stroke_timer(rsv);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn;\r\n}\r\nuwb_rsv_dump("SC", rsv);\r\nswitch (new_state) {\r\ncase UWB_RSV_STATE_NONE:\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_NONE);\r\nuwb_rsv_callback(rsv);\r\nbreak;\r\ncase UWB_RSV_STATE_O_INITIATED:\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_O_INITIATED);\r\nbreak;\r\ncase UWB_RSV_STATE_O_PENDING:\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_O_PENDING);\r\nbreak;\r\ncase UWB_RSV_STATE_O_MODIFIED:\r\nbitmap_andnot(rsv->mas.bm, rsv->mas.bm, mv->companion_mas.bm, UWB_NUM_MAS);\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_O_MODIFIED);\r\nbreak;\r\ncase UWB_RSV_STATE_O_ESTABLISHED:\r\nif (rsv->state == UWB_RSV_STATE_O_MODIFIED\r\n|| rsv->state == UWB_RSV_STATE_O_MOVE_REDUCING) {\r\nuwb_drp_avail_release(rsv->rc, &mv->companion_mas);\r\nrsv->needs_release_companion_mas = false;\r\n}\r\nuwb_drp_avail_reserve(rsv->rc, &rsv->mas);\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_O_ESTABLISHED);\r\nuwb_rsv_callback(rsv);\r\nbreak;\r\ncase UWB_RSV_STATE_O_MOVE_EXPANDING:\r\nrsv->needs_release_companion_mas = true;\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_O_MOVE_EXPANDING);\r\nbreak;\r\ncase UWB_RSV_STATE_O_MOVE_COMBINING:\r\nrsv->needs_release_companion_mas = false;\r\nuwb_drp_avail_reserve(rsv->rc, &mv->companion_mas);\r\nbitmap_or(rsv->mas.bm, rsv->mas.bm, mv->companion_mas.bm, UWB_NUM_MAS);\r\nrsv->mas.safe += mv->companion_mas.safe;\r\nrsv->mas.unsafe += mv->companion_mas.unsafe;\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_O_MOVE_COMBINING);\r\nbreak;\r\ncase UWB_RSV_STATE_O_MOVE_REDUCING:\r\nbitmap_andnot(mv->companion_mas.bm, rsv->mas.bm, mv->final_mas.bm, UWB_NUM_MAS);\r\nrsv->needs_release_companion_mas = true;\r\nrsv->mas.safe = mv->final_mas.safe;\r\nrsv->mas.unsafe = mv->final_mas.unsafe;\r\nbitmap_copy(rsv->mas.bm, mv->final_mas.bm, UWB_NUM_MAS);\r\nbitmap_copy(rsv->mas.unsafe_bm, mv->final_mas.unsafe_bm, UWB_NUM_MAS);\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_O_MOVE_REDUCING);\r\nbreak;\r\ncase UWB_RSV_STATE_T_ACCEPTED:\r\ncase UWB_RSV_STATE_T_RESIZED:\r\nrsv->needs_release_companion_mas = false;\r\nuwb_drp_avail_reserve(rsv->rc, &rsv->mas);\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_T_ACCEPTED);\r\nuwb_rsv_callback(rsv);\r\nbreak;\r\ncase UWB_RSV_STATE_T_DENIED:\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_T_DENIED);\r\nbreak;\r\ncase UWB_RSV_STATE_T_CONFLICT:\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_T_CONFLICT);\r\nbreak;\r\ncase UWB_RSV_STATE_T_PENDING:\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_T_PENDING);\r\nbreak;\r\ncase UWB_RSV_STATE_T_EXPANDING_ACCEPTED:\r\nrsv->needs_release_companion_mas = true;\r\nuwb_drp_avail_reserve(rsv->rc, &mv->companion_mas);\r\nuwb_rsv_state_update(rsv, UWB_RSV_STATE_T_EXPANDING_ACCEPTED);\r\nbreak;\r\ndefault:\r\ndev_err(&rsv->rc->uwb_dev.dev, "unhandled state: %s (%d)\n",\r\nuwb_rsv_state_str(new_state), new_state);\r\n}\r\n}\r\nstatic void uwb_rsv_handle_timeout_work(struct work_struct *work)\r\n{\r\nstruct uwb_rsv *rsv = container_of(work, struct uwb_rsv,\r\nhandle_timeout_work);\r\nstruct uwb_rc *rc = rsv->rc;\r\nmutex_lock(&rc->rsvs_mutex);\r\nuwb_rsv_dump("TO", rsv);\r\nswitch (rsv->state) {\r\ncase UWB_RSV_STATE_O_INITIATED:\r\nif (rsv->is_multicast) {\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_O_ESTABLISHED);\r\ngoto unlock;\r\n}\r\nbreak;\r\ncase UWB_RSV_STATE_O_MOVE_EXPANDING:\r\nif (rsv->is_multicast) {\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_O_MOVE_COMBINING);\r\ngoto unlock;\r\n}\r\nbreak;\r\ncase UWB_RSV_STATE_O_MOVE_COMBINING:\r\nif (rsv->is_multicast) {\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_O_MOVE_REDUCING);\r\ngoto unlock;\r\n}\r\nbreak;\r\ncase UWB_RSV_STATE_O_MOVE_REDUCING:\r\nif (rsv->is_multicast) {\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_O_ESTABLISHED);\r\ngoto unlock;\r\n}\r\nbreak;\r\ncase UWB_RSV_STATE_O_ESTABLISHED:\r\nif (rsv->is_multicast)\r\ngoto unlock;\r\nbreak;\r\ncase UWB_RSV_STATE_T_EXPANDING_ACCEPTED:\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_T_ACCEPTED);\r\nuwb_drp_avail_release(rsv->rc, &rsv->mv.companion_mas);\r\ngoto unlock;\r\ndefault:\r\nbreak;\r\n}\r\nuwb_rsv_remove(rsv);\r\nunlock:\r\nmutex_unlock(&rc->rsvs_mutex);\r\n}\r\nstatic struct uwb_rsv *uwb_rsv_alloc(struct uwb_rc *rc)\r\n{\r\nstruct uwb_rsv *rsv;\r\nrsv = kzalloc(sizeof(struct uwb_rsv), GFP_KERNEL);\r\nif (!rsv)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&rsv->rc_node);\r\nINIT_LIST_HEAD(&rsv->pal_node);\r\nkref_init(&rsv->kref);\r\ninit_timer(&rsv->timer);\r\nrsv->timer.function = uwb_rsv_timer;\r\nrsv->timer.data = (unsigned long)rsv;\r\nrsv->rc = rc;\r\nINIT_WORK(&rsv->handle_timeout_work, uwb_rsv_handle_timeout_work);\r\nreturn rsv;\r\n}\r\nstruct uwb_rsv *uwb_rsv_create(struct uwb_rc *rc, uwb_rsv_cb_f cb, void *pal_priv)\r\n{\r\nstruct uwb_rsv *rsv;\r\nrsv = uwb_rsv_alloc(rc);\r\nif (!rsv)\r\nreturn NULL;\r\nrsv->callback = cb;\r\nrsv->pal_priv = pal_priv;\r\nreturn rsv;\r\n}\r\nvoid uwb_rsv_remove(struct uwb_rsv *rsv)\r\n{\r\nuwb_rsv_dump("RM", rsv);\r\nif (rsv->state != UWB_RSV_STATE_NONE)\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_NONE);\r\nif (rsv->needs_release_companion_mas)\r\nuwb_drp_avail_release(rsv->rc, &rsv->mv.companion_mas);\r\nuwb_drp_avail_release(rsv->rc, &rsv->mas);\r\nif (uwb_rsv_is_owner(rsv))\r\nuwb_rsv_put_stream(rsv);\r\nuwb_dev_put(rsv->owner);\r\nif (rsv->target.type == UWB_RSV_TARGET_DEV)\r\nuwb_dev_put(rsv->target.dev);\r\nlist_del_init(&rsv->rc_node);\r\nuwb_rsv_put(rsv);\r\n}\r\nvoid uwb_rsv_destroy(struct uwb_rsv *rsv)\r\n{\r\nuwb_rsv_put(rsv);\r\n}\r\nint uwb_rsv_establish(struct uwb_rsv *rsv)\r\n{\r\nstruct uwb_rc *rc = rsv->rc;\r\nstruct uwb_mas_bm available;\r\nint ret;\r\nmutex_lock(&rc->rsvs_mutex);\r\nret = uwb_rsv_get_stream(rsv);\r\nif (ret)\r\ngoto out;\r\nrsv->tiebreaker = prandom_u32() & 1;\r\nuwb_drp_available(rc, &available);\r\nret = uwb_rsv_find_best_allocation(rsv, &available, &rsv->mas);\r\nif (ret == UWB_RSV_ALLOC_NOT_FOUND) {\r\nret = -EBUSY;\r\nuwb_rsv_put_stream(rsv);\r\ngoto out;\r\n}\r\nret = uwb_drp_avail_reserve_pending(rc, &rsv->mas);\r\nif (ret != 0) {\r\nuwb_rsv_put_stream(rsv);\r\ngoto out;\r\n}\r\nuwb_rsv_get(rsv);\r\nlist_add_tail(&rsv->rc_node, &rc->reservations);\r\nrsv->owner = &rc->uwb_dev;\r\nuwb_dev_get(rsv->owner);\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_O_INITIATED);\r\nout:\r\nmutex_unlock(&rc->rsvs_mutex);\r\nreturn ret;\r\n}\r\nint uwb_rsv_modify(struct uwb_rsv *rsv, int max_mas, int min_mas, int max_interval)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nint uwb_rsv_try_move(struct uwb_rsv *rsv, struct uwb_mas_bm *available)\r\n{\r\nstruct uwb_rc *rc = rsv->rc;\r\nstruct uwb_drp_backoff_win *bow = &rc->bow;\r\nstruct device *dev = &rc->uwb_dev.dev;\r\nstruct uwb_rsv_move *mv;\r\nint ret = 0;\r\nif (bow->can_reserve_extra_mases == false)\r\nreturn -EBUSY;\r\nmv = &rsv->mv;\r\nif (uwb_rsv_find_best_allocation(rsv, available, &mv->final_mas) == UWB_RSV_ALLOC_FOUND) {\r\nif (!bitmap_equal(rsv->mas.bm, mv->final_mas.bm, UWB_NUM_MAS)) {\r\nbitmap_andnot(mv->companion_mas.bm, mv->final_mas.bm, rsv->mas.bm, UWB_NUM_MAS);\r\nuwb_drp_avail_reserve_pending(rc, &mv->companion_mas);\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_O_MOVE_EXPANDING);\r\n}\r\n} else {\r\ndev_dbg(dev, "new allocation not found\n");\r\n}\r\nreturn ret;\r\n}\r\nvoid uwb_rsv_handle_drp_avail_change(struct uwb_rc *rc)\r\n{\r\nstruct uwb_drp_backoff_win *bow = &rc->bow;\r\nstruct uwb_rsv *rsv;\r\nstruct uwb_mas_bm mas;\r\nif (bow->can_reserve_extra_mases == false)\r\nreturn;\r\nlist_for_each_entry(rsv, &rc->reservations, rc_node) {\r\nif (rsv->state == UWB_RSV_STATE_O_ESTABLISHED ||\r\nrsv->state == UWB_RSV_STATE_O_TO_BE_MOVED) {\r\nuwb_drp_available(rc, &mas);\r\nbitmap_or(mas.bm, mas.bm, rsv->mas.bm, UWB_NUM_MAS);\r\nuwb_rsv_try_move(rsv, &mas);\r\n}\r\n}\r\n}\r\nvoid uwb_rsv_terminate(struct uwb_rsv *rsv)\r\n{\r\nstruct uwb_rc *rc = rsv->rc;\r\nmutex_lock(&rc->rsvs_mutex);\r\nif (rsv->state != UWB_RSV_STATE_NONE)\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_NONE);\r\nmutex_unlock(&rc->rsvs_mutex);\r\n}\r\nvoid uwb_rsv_accept(struct uwb_rsv *rsv, uwb_rsv_cb_f cb, void *pal_priv)\r\n{\r\nuwb_rsv_get(rsv);\r\nrsv->callback = cb;\r\nrsv->pal_priv = pal_priv;\r\nrsv->state = UWB_RSV_STATE_T_ACCEPTED;\r\n}\r\nstatic bool uwb_rsv_match(struct uwb_rsv *rsv, struct uwb_dev *src,\r\nstruct uwb_ie_drp *drp_ie)\r\n{\r\nstruct uwb_dev_addr *rsv_src;\r\nint stream;\r\nstream = uwb_ie_drp_stream_index(drp_ie);\r\nif (rsv->stream != stream)\r\nreturn false;\r\nswitch (rsv->target.type) {\r\ncase UWB_RSV_TARGET_DEVADDR:\r\nreturn rsv->stream == stream;\r\ncase UWB_RSV_TARGET_DEV:\r\nif (uwb_ie_drp_owner(drp_ie))\r\nrsv_src = &rsv->owner->dev_addr;\r\nelse\r\nrsv_src = &rsv->target.dev->dev_addr;\r\nreturn uwb_dev_addr_cmp(&src->dev_addr, rsv_src) == 0;\r\n}\r\nreturn false;\r\n}\r\nstatic struct uwb_rsv *uwb_rsv_new_target(struct uwb_rc *rc,\r\nstruct uwb_dev *src,\r\nstruct uwb_ie_drp *drp_ie)\r\n{\r\nstruct uwb_rsv *rsv;\r\nstruct uwb_pal *pal;\r\nenum uwb_rsv_state state;\r\nrsv = uwb_rsv_alloc(rc);\r\nif (!rsv)\r\nreturn NULL;\r\nrsv->rc = rc;\r\nrsv->owner = src;\r\nuwb_dev_get(rsv->owner);\r\nrsv->target.type = UWB_RSV_TARGET_DEV;\r\nrsv->target.dev = &rc->uwb_dev;\r\nuwb_dev_get(&rc->uwb_dev);\r\nrsv->type = uwb_ie_drp_type(drp_ie);\r\nrsv->stream = uwb_ie_drp_stream_index(drp_ie);\r\nuwb_drp_ie_to_bm(&rsv->mas, drp_ie);\r\nrsv->state = UWB_RSV_STATE_T_DENIED;\r\nmutex_lock(&rc->uwb_dev.mutex);\r\nlist_for_each_entry(pal, &rc->pals, node) {\r\nif (pal->new_rsv)\r\npal->new_rsv(pal, rsv);\r\nif (rsv->state == UWB_RSV_STATE_T_ACCEPTED)\r\nbreak;\r\n}\r\nmutex_unlock(&rc->uwb_dev.mutex);\r\nlist_add_tail(&rsv->rc_node, &rc->reservations);\r\nstate = rsv->state;\r\nrsv->state = UWB_RSV_STATE_NONE;\r\nif (state == UWB_RSV_STATE_T_ACCEPTED\r\n&& uwb_drp_avail_reserve_pending(rc, &rsv->mas) == -EBUSY) {\r\n} else {\r\nuwb_rsv_set_state(rsv, state);\r\n}\r\nreturn rsv;\r\n}\r\nvoid uwb_rsv_get_usable_mas(struct uwb_rsv *rsv, struct uwb_mas_bm *mas)\r\n{\r\nbitmap_zero(mas->bm, UWB_NUM_MAS);\r\nbitmap_andnot(mas->bm, rsv->mas.bm, rsv->rc->cnflt_alien_bitmap.bm, UWB_NUM_MAS);\r\n}\r\nstruct uwb_rsv *uwb_rsv_find(struct uwb_rc *rc, struct uwb_dev *src,\r\nstruct uwb_ie_drp *drp_ie)\r\n{\r\nstruct uwb_rsv *rsv;\r\nlist_for_each_entry(rsv, &rc->reservations, rc_node) {\r\nif (uwb_rsv_match(rsv, src, drp_ie))\r\nreturn rsv;\r\n}\r\nif (uwb_ie_drp_owner(drp_ie))\r\nreturn uwb_rsv_new_target(rc, src, drp_ie);\r\nreturn NULL;\r\n}\r\nstatic bool uwb_rsv_update_all(struct uwb_rc *rc)\r\n{\r\nstruct uwb_rsv *rsv, *t;\r\nbool ie_updated = false;\r\nlist_for_each_entry_safe(rsv, t, &rc->reservations, rc_node) {\r\nif (!rsv->ie_valid) {\r\nuwb_drp_ie_update(rsv);\r\nie_updated = true;\r\n}\r\n}\r\nreturn ie_updated;\r\n}\r\nvoid uwb_rsv_queue_update(struct uwb_rc *rc)\r\n{\r\nunsigned long delay_us = UWB_MAS_LENGTH_US * UWB_MAS_PER_ZONE;\r\nqueue_delayed_work(rc->rsv_workq, &rc->rsv_update_work, usecs_to_jiffies(delay_us));\r\n}\r\nvoid uwb_rsv_sched_update(struct uwb_rc *rc)\r\n{\r\nspin_lock_irq(&rc->rsvs_lock);\r\nif (!delayed_work_pending(&rc->rsv_update_work)) {\r\nif (rc->set_drp_ie_pending > 0) {\r\nrc->set_drp_ie_pending++;\r\ngoto unlock;\r\n}\r\nuwb_rsv_queue_update(rc);\r\n}\r\nunlock:\r\nspin_unlock_irq(&rc->rsvs_lock);\r\n}\r\nstatic void uwb_rsv_update_work(struct work_struct *work)\r\n{\r\nstruct uwb_rc *rc = container_of(work, struct uwb_rc,\r\nrsv_update_work.work);\r\nbool ie_updated;\r\nmutex_lock(&rc->rsvs_mutex);\r\nie_updated = uwb_rsv_update_all(rc);\r\nif (!rc->drp_avail.ie_valid) {\r\nuwb_drp_avail_ie_update(rc);\r\nie_updated = true;\r\n}\r\nif (ie_updated && (rc->set_drp_ie_pending == 0))\r\nuwb_rc_send_all_drp_ie(rc);\r\nmutex_unlock(&rc->rsvs_mutex);\r\n}\r\nstatic void uwb_rsv_alien_bp_work(struct work_struct *work)\r\n{\r\nstruct uwb_rc *rc = container_of(work, struct uwb_rc,\r\nrsv_alien_bp_work.work);\r\nstruct uwb_rsv *rsv;\r\nmutex_lock(&rc->rsvs_mutex);\r\nlist_for_each_entry(rsv, &rc->reservations, rc_node) {\r\nif (rsv->type != UWB_DRP_TYPE_ALIEN_BP) {\r\nrsv->callback(rsv);\r\n}\r\n}\r\nmutex_unlock(&rc->rsvs_mutex);\r\n}\r\nstatic void uwb_rsv_timer(unsigned long arg)\r\n{\r\nstruct uwb_rsv *rsv = (struct uwb_rsv *)arg;\r\nqueue_work(rsv->rc->rsv_workq, &rsv->handle_timeout_work);\r\n}\r\nvoid uwb_rsv_remove_all(struct uwb_rc *rc)\r\n{\r\nstruct uwb_rsv *rsv, *t;\r\nmutex_lock(&rc->rsvs_mutex);\r\nlist_for_each_entry_safe(rsv, t, &rc->reservations, rc_node) {\r\nif (rsv->state != UWB_RSV_STATE_NONE)\r\nuwb_rsv_set_state(rsv, UWB_RSV_STATE_NONE);\r\ndel_timer_sync(&rsv->timer);\r\n}\r\nrc->set_drp_ie_pending = 0;\r\nmutex_unlock(&rc->rsvs_mutex);\r\ncancel_delayed_work_sync(&rc->rsv_update_work);\r\nflush_workqueue(rc->rsv_workq);\r\nmutex_lock(&rc->rsvs_mutex);\r\nlist_for_each_entry_safe(rsv, t, &rc->reservations, rc_node) {\r\nuwb_rsv_remove(rsv);\r\n}\r\nmutex_unlock(&rc->rsvs_mutex);\r\n}\r\nvoid uwb_rsv_init(struct uwb_rc *rc)\r\n{\r\nINIT_LIST_HEAD(&rc->reservations);\r\nINIT_LIST_HEAD(&rc->cnflt_alien_list);\r\nmutex_init(&rc->rsvs_mutex);\r\nspin_lock_init(&rc->rsvs_lock);\r\nINIT_DELAYED_WORK(&rc->rsv_update_work, uwb_rsv_update_work);\r\nINIT_DELAYED_WORK(&rc->rsv_alien_bp_work, uwb_rsv_alien_bp_work);\r\nrc->bow.can_reserve_extra_mases = true;\r\nrc->bow.total_expired = 0;\r\nrc->bow.window = UWB_DRP_BACKOFF_WIN_MIN >> 1;\r\ninit_timer(&rc->bow.timer);\r\nrc->bow.timer.function = uwb_rsv_backoff_win_timer;\r\nrc->bow.timer.data = (unsigned long)&rc->bow;\r\nbitmap_complement(rc->uwb_dev.streams, rc->uwb_dev.streams, UWB_NUM_STREAMS);\r\n}\r\nint uwb_rsv_setup(struct uwb_rc *rc)\r\n{\r\nchar name[16];\r\nsnprintf(name, sizeof(name), "%s_rsvd", dev_name(&rc->uwb_dev.dev));\r\nrc->rsv_workq = create_singlethread_workqueue(name);\r\nif (rc->rsv_workq == NULL)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid uwb_rsv_cleanup(struct uwb_rc *rc)\r\n{\r\nuwb_rsv_remove_all(rc);\r\ndestroy_workqueue(rc->rsv_workq);\r\n}
