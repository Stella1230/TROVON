struct pci_controller * __init\r\nalloc_pci_controller(void)\r\n{\r\nstruct pci_controller *hose;\r\nhose = alloc_bootmem(sizeof(*hose));\r\n*hose_tail = hose;\r\nhose_tail = &hose->next;\r\nreturn hose;\r\n}\r\nstruct resource * __init\r\nalloc_resource(void)\r\n{\r\nstruct resource *res;\r\nres = alloc_bootmem(sizeof(*res));\r\nreturn res;\r\n}\r\nasmlinkage long\r\nsys_pciconfig_iobase(long which, unsigned long bus, unsigned long dfn)\r\n{\r\nstruct pci_controller *hose;\r\nif (which & IOBASE_FROM_HOSE) {\r\nfor (hose = hose_head; hose; hose = hose->next)\r\nif (hose->index == bus)\r\nbreak;\r\nif (!hose)\r\nreturn -ENODEV;\r\n} else {\r\nif (bus == 0 && dfn == 0)\r\nhose = pci_isa_hose;\r\nelse\r\nreturn -ENODEV;\r\n}\r\nswitch (which & ~IOBASE_FROM_HOSE) {\r\ncase IOBASE_HOSE:\r\nreturn hose->index;\r\ncase IOBASE_SPARSE_MEM:\r\nreturn hose->sparse_mem_base;\r\ncase IOBASE_DENSE_MEM:\r\nreturn hose->dense_mem_base;\r\ncase IOBASE_SPARSE_IO:\r\nreturn hose->sparse_io_base;\r\ncase IOBASE_DENSE_IO:\r\nreturn hose->dense_io_base;\r\ncase IOBASE_ROOT_BUS:\r\nreturn hose->bus->number;\r\n}\r\nreturn -EOPNOTSUPP;\r\n}\r\nasmlinkage long\r\nsys_pciconfig_read(unsigned long bus, unsigned long dfn,\r\nunsigned long off, unsigned long len, void *buf)\r\n{\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\nelse\r\nreturn -ENODEV;\r\n}\r\nasmlinkage long\r\nsys_pciconfig_write(unsigned long bus, unsigned long dfn,\r\nunsigned long off, unsigned long len, void *buf)\r\n{\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\nelse\r\nreturn -ENODEV;\r\n}\r\nstatic void *alpha_noop_alloc_coherent(struct device *dev, size_t size,\r\ndma_addr_t *dma_handle, gfp_t gfp,\r\nstruct dma_attrs *attrs)\r\n{\r\nvoid *ret;\r\nif (!dev || *dev->dma_mask >= 0xffffffffUL)\r\ngfp &= ~GFP_DMA;\r\nret = (void *)__get_free_pages(gfp, get_order(size));\r\nif (ret) {\r\nmemset(ret, 0, size);\r\n*dma_handle = virt_to_phys(ret);\r\n}\r\nreturn ret;\r\n}\r\nstatic void alpha_noop_free_coherent(struct device *dev, size_t size,\r\nvoid *cpu_addr, dma_addr_t dma_addr,\r\nstruct dma_attrs *attrs)\r\n{\r\nfree_pages((unsigned long)cpu_addr, get_order(size));\r\n}\r\nstatic dma_addr_t alpha_noop_map_page(struct device *dev, struct page *page,\r\nunsigned long offset, size_t size,\r\nenum dma_data_direction dir,\r\nstruct dma_attrs *attrs)\r\n{\r\nreturn page_to_pa(page) + offset;\r\n}\r\nstatic int alpha_noop_map_sg(struct device *dev, struct scatterlist *sgl, int nents,\r\nenum dma_data_direction dir, struct dma_attrs *attrs)\r\n{\r\nint i;\r\nstruct scatterlist *sg;\r\nfor_each_sg(sgl, sg, nents, i) {\r\nvoid *va;\r\nBUG_ON(!sg_page(sg));\r\nva = sg_virt(sg);\r\nsg_dma_address(sg) = (dma_addr_t)virt_to_phys(va);\r\nsg_dma_len(sg) = sg->length;\r\n}\r\nreturn nents;\r\n}\r\nstatic int alpha_noop_mapping_error(struct device *dev, dma_addr_t dma_addr)\r\n{\r\nreturn 0;\r\n}\r\nstatic int alpha_noop_supported(struct device *dev, u64 mask)\r\n{\r\nreturn mask < 0x00ffffffUL ? 0 : 1;\r\n}\r\nstatic int alpha_noop_set_mask(struct device *dev, u64 mask)\r\n{\r\nif (!dev->dma_mask || !dma_supported(dev, mask))\r\nreturn -EIO;\r\n*dev->dma_mask = mask;\r\nreturn 0;\r\n}
