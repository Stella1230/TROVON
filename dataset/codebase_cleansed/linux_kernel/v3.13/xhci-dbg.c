void xhci_dbg_regs(struct xhci_hcd *xhci)\r\n{\r\nu32 temp;\r\nxhci_dbg(xhci, "// xHCI capability registers at %p:\n",\r\nxhci->cap_regs);\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->hc_capbase);\r\nxhci_dbg(xhci, "// @%p = 0x%x (CAPLENGTH AND HCIVERSION)\n",\r\n&xhci->cap_regs->hc_capbase, temp);\r\nxhci_dbg(xhci, "// CAPLENGTH: 0x%x\n",\r\n(unsigned int) HC_LENGTH(temp));\r\n#if 0\r\nxhci_dbg(xhci, "// HCIVERSION: 0x%x\n",\r\n(unsigned int) HC_VERSION(temp));\r\n#endif\r\nxhci_dbg(xhci, "// xHCI operational registers at %p:\n", xhci->op_regs);\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->run_regs_off);\r\nxhci_dbg(xhci, "// @%p = 0x%x RTSOFF\n",\r\n&xhci->cap_regs->run_regs_off,\r\n(unsigned int) temp & RTSOFF_MASK);\r\nxhci_dbg(xhci, "// xHCI runtime registers at %p:\n", xhci->run_regs);\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->db_off);\r\nxhci_dbg(xhci, "// @%p = 0x%x DBOFF\n", &xhci->cap_regs->db_off, temp);\r\nxhci_dbg(xhci, "// Doorbell array at %p:\n", xhci->dba);\r\n}\r\nstatic void xhci_print_cap_regs(struct xhci_hcd *xhci)\r\n{\r\nu32 temp;\r\nxhci_dbg(xhci, "xHCI capability registers at %p:\n", xhci->cap_regs);\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->hc_capbase);\r\nxhci_dbg(xhci, "CAPLENGTH AND HCIVERSION 0x%x:\n",\r\n(unsigned int) temp);\r\nxhci_dbg(xhci, "CAPLENGTH: 0x%x\n",\r\n(unsigned int) HC_LENGTH(temp));\r\nxhci_dbg(xhci, "HCIVERSION: 0x%x\n",\r\n(unsigned int) HC_VERSION(temp));\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->hcs_params1);\r\nxhci_dbg(xhci, "HCSPARAMS 1: 0x%x\n",\r\n(unsigned int) temp);\r\nxhci_dbg(xhci, " Max device slots: %u\n",\r\n(unsigned int) HCS_MAX_SLOTS(temp));\r\nxhci_dbg(xhci, " Max interrupters: %u\n",\r\n(unsigned int) HCS_MAX_INTRS(temp));\r\nxhci_dbg(xhci, " Max ports: %u\n",\r\n(unsigned int) HCS_MAX_PORTS(temp));\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->hcs_params2);\r\nxhci_dbg(xhci, "HCSPARAMS 2: 0x%x\n",\r\n(unsigned int) temp);\r\nxhci_dbg(xhci, " Isoc scheduling threshold: %u\n",\r\n(unsigned int) HCS_IST(temp));\r\nxhci_dbg(xhci, " Maximum allowed segments in event ring: %u\n",\r\n(unsigned int) HCS_ERST_MAX(temp));\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->hcs_params3);\r\nxhci_dbg(xhci, "HCSPARAMS 3 0x%x:\n",\r\n(unsigned int) temp);\r\nxhci_dbg(xhci, " Worst case U1 device exit latency: %u\n",\r\n(unsigned int) HCS_U1_LATENCY(temp));\r\nxhci_dbg(xhci, " Worst case U2 device exit latency: %u\n",\r\n(unsigned int) HCS_U2_LATENCY(temp));\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->hcc_params);\r\nxhci_dbg(xhci, "HCC PARAMS 0x%x:\n", (unsigned int) temp);\r\nxhci_dbg(xhci, " HC generates %s bit addresses\n",\r\nHCC_64BIT_ADDR(temp) ? "64" : "32");\r\nxhci_dbg(xhci, " FIXME: more HCCPARAMS debugging\n");\r\ntemp = xhci_readl(xhci, &xhci->cap_regs->run_regs_off);\r\nxhci_dbg(xhci, "RTSOFF 0x%x:\n", temp & RTSOFF_MASK);\r\n}\r\nstatic void xhci_print_command_reg(struct xhci_hcd *xhci)\r\n{\r\nu32 temp;\r\ntemp = xhci_readl(xhci, &xhci->op_regs->command);\r\nxhci_dbg(xhci, "USBCMD 0x%x:\n", temp);\r\nxhci_dbg(xhci, " HC is %s\n",\r\n(temp & CMD_RUN) ? "running" : "being stopped");\r\nxhci_dbg(xhci, " HC has %sfinished hard reset\n",\r\n(temp & CMD_RESET) ? "not " : "");\r\nxhci_dbg(xhci, " Event Interrupts %s\n",\r\n(temp & CMD_EIE) ? "enabled " : "disabled");\r\nxhci_dbg(xhci, " Host System Error Interrupts %s\n",\r\n(temp & CMD_HSEIE) ? "enabled " : "disabled");\r\nxhci_dbg(xhci, " HC has %sfinished light reset\n",\r\n(temp & CMD_LRESET) ? "not " : "");\r\n}\r\nstatic void xhci_print_status(struct xhci_hcd *xhci)\r\n{\r\nu32 temp;\r\ntemp = xhci_readl(xhci, &xhci->op_regs->status);\r\nxhci_dbg(xhci, "USBSTS 0x%x:\n", temp);\r\nxhci_dbg(xhci, " Event ring is %sempty\n",\r\n(temp & STS_EINT) ? "not " : "");\r\nxhci_dbg(xhci, " %sHost System Error\n",\r\n(temp & STS_FATAL) ? "WARNING: " : "No ");\r\nxhci_dbg(xhci, " HC is %s\n",\r\n(temp & STS_HALT) ? "halted" : "running");\r\n}\r\nstatic void xhci_print_op_regs(struct xhci_hcd *xhci)\r\n{\r\nxhci_dbg(xhci, "xHCI operational registers at %p:\n", xhci->op_regs);\r\nxhci_print_command_reg(xhci);\r\nxhci_print_status(xhci);\r\n}\r\nstatic void xhci_print_ports(struct xhci_hcd *xhci)\r\n{\r\n__le32 __iomem *addr;\r\nint i, j;\r\nint ports;\r\nchar *names[NUM_PORT_REGS] = {\r\n"status",\r\n"power",\r\n"link",\r\n"reserved",\r\n};\r\nports = HCS_MAX_PORTS(xhci->hcs_params1);\r\naddr = &xhci->op_regs->port_status_base;\r\nfor (i = 0; i < ports; i++) {\r\nfor (j = 0; j < NUM_PORT_REGS; ++j) {\r\nxhci_dbg(xhci, "%p port %s reg = 0x%x\n",\r\naddr, names[j],\r\n(unsigned int) xhci_readl(xhci, addr));\r\naddr++;\r\n}\r\n}\r\n}\r\nvoid xhci_print_ir_set(struct xhci_hcd *xhci, int set_num)\r\n{\r\nstruct xhci_intr_reg __iomem *ir_set = &xhci->run_regs->ir_set[set_num];\r\nvoid __iomem *addr;\r\nu32 temp;\r\nu64 temp_64;\r\naddr = &ir_set->irq_pending;\r\ntemp = xhci_readl(xhci, addr);\r\nif (temp == XHCI_INIT_VALUE)\r\nreturn;\r\nxhci_dbg(xhci, " %p: ir_set[%i]\n", ir_set, set_num);\r\nxhci_dbg(xhci, " %p: ir_set.pending = 0x%x\n", addr,\r\n(unsigned int)temp);\r\naddr = &ir_set->irq_control;\r\ntemp = xhci_readl(xhci, addr);\r\nxhci_dbg(xhci, " %p: ir_set.control = 0x%x\n", addr,\r\n(unsigned int)temp);\r\naddr = &ir_set->erst_size;\r\ntemp = xhci_readl(xhci, addr);\r\nxhci_dbg(xhci, " %p: ir_set.erst_size = 0x%x\n", addr,\r\n(unsigned int)temp);\r\naddr = &ir_set->rsvd;\r\ntemp = xhci_readl(xhci, addr);\r\nif (temp != XHCI_INIT_VALUE)\r\nxhci_dbg(xhci, " WARN: %p: ir_set.rsvd = 0x%x\n",\r\naddr, (unsigned int)temp);\r\naddr = &ir_set->erst_base;\r\ntemp_64 = xhci_read_64(xhci, addr);\r\nxhci_dbg(xhci, " %p: ir_set.erst_base = @%08llx\n",\r\naddr, temp_64);\r\naddr = &ir_set->erst_dequeue;\r\ntemp_64 = xhci_read_64(xhci, addr);\r\nxhci_dbg(xhci, " %p: ir_set.erst_dequeue = @%08llx\n",\r\naddr, temp_64);\r\n}\r\nvoid xhci_print_run_regs(struct xhci_hcd *xhci)\r\n{\r\nu32 temp;\r\nint i;\r\nxhci_dbg(xhci, "xHCI runtime registers at %p:\n", xhci->run_regs);\r\ntemp = xhci_readl(xhci, &xhci->run_regs->microframe_index);\r\nxhci_dbg(xhci, " %p: Microframe index = 0x%x\n",\r\n&xhci->run_regs->microframe_index,\r\n(unsigned int) temp);\r\nfor (i = 0; i < 7; ++i) {\r\ntemp = xhci_readl(xhci, &xhci->run_regs->rsvd[i]);\r\nif (temp != XHCI_INIT_VALUE)\r\nxhci_dbg(xhci, " WARN: %p: Rsvd[%i] = 0x%x\n",\r\n&xhci->run_regs->rsvd[i],\r\ni, (unsigned int) temp);\r\n}\r\n}\r\nvoid xhci_print_registers(struct xhci_hcd *xhci)\r\n{\r\nxhci_print_cap_regs(xhci);\r\nxhci_print_op_regs(xhci);\r\nxhci_print_ports(xhci);\r\n}\r\nvoid xhci_print_trb_offsets(struct xhci_hcd *xhci, union xhci_trb *trb)\r\n{\r\nint i;\r\nfor (i = 0; i < 4; ++i)\r\nxhci_dbg(xhci, "Offset 0x%x = 0x%x\n",\r\ni*4, trb->generic.field[i]);\r\n}\r\nvoid xhci_debug_trb(struct xhci_hcd *xhci, union xhci_trb *trb)\r\n{\r\nu64 address;\r\nu32 type = le32_to_cpu(trb->link.control) & TRB_TYPE_BITMASK;\r\nswitch (type) {\r\ncase TRB_TYPE(TRB_LINK):\r\nxhci_dbg(xhci, "Link TRB:\n");\r\nxhci_print_trb_offsets(xhci, trb);\r\naddress = le64_to_cpu(trb->link.segment_ptr);\r\nxhci_dbg(xhci, "Next ring segment DMA address = 0x%llx\n", address);\r\nxhci_dbg(xhci, "Interrupter target = 0x%x\n",\r\nGET_INTR_TARGET(le32_to_cpu(trb->link.intr_target)));\r\nxhci_dbg(xhci, "Cycle bit = %u\n",\r\nle32_to_cpu(trb->link.control) & TRB_CYCLE);\r\nxhci_dbg(xhci, "Toggle cycle bit = %u\n",\r\nle32_to_cpu(trb->link.control) & LINK_TOGGLE);\r\nxhci_dbg(xhci, "No Snoop bit = %u\n",\r\nle32_to_cpu(trb->link.control) & TRB_NO_SNOOP);\r\nbreak;\r\ncase TRB_TYPE(TRB_TRANSFER):\r\naddress = le64_to_cpu(trb->trans_event.buffer);\r\nxhci_dbg(xhci, "DMA address or buffer contents= %llu\n", address);\r\nbreak;\r\ncase TRB_TYPE(TRB_COMPLETION):\r\naddress = le64_to_cpu(trb->event_cmd.cmd_trb);\r\nxhci_dbg(xhci, "Command TRB pointer = %llu\n", address);\r\nxhci_dbg(xhci, "Completion status = %u\n",\r\nGET_COMP_CODE(le32_to_cpu(trb->event_cmd.status)));\r\nxhci_dbg(xhci, "Flags = 0x%x\n",\r\nle32_to_cpu(trb->event_cmd.flags));\r\nbreak;\r\ndefault:\r\nxhci_dbg(xhci, "Unknown TRB with TRB type ID %u\n",\r\n(unsigned int) type>>10);\r\nxhci_print_trb_offsets(xhci, trb);\r\nbreak;\r\n}\r\n}\r\nvoid xhci_debug_segment(struct xhci_hcd *xhci, struct xhci_segment *seg)\r\n{\r\nint i;\r\nu64 addr = seg->dma;\r\nunion xhci_trb *trb = seg->trbs;\r\nfor (i = 0; i < TRBS_PER_SEGMENT; ++i) {\r\ntrb = &seg->trbs[i];\r\nxhci_dbg(xhci, "@%016llx %08x %08x %08x %08x\n", addr,\r\nlower_32_bits(le64_to_cpu(trb->link.segment_ptr)),\r\nupper_32_bits(le64_to_cpu(trb->link.segment_ptr)),\r\nle32_to_cpu(trb->link.intr_target),\r\nle32_to_cpu(trb->link.control));\r\naddr += sizeof(*trb);\r\n}\r\n}\r\nvoid xhci_dbg_ring_ptrs(struct xhci_hcd *xhci, struct xhci_ring *ring)\r\n{\r\nxhci_dbg(xhci, "Ring deq = %p (virt), 0x%llx (dma)\n",\r\nring->dequeue,\r\n(unsigned long long)xhci_trb_virt_to_dma(ring->deq_seg,\r\nring->dequeue));\r\nxhci_dbg(xhci, "Ring deq updated %u times\n",\r\nring->deq_updates);\r\nxhci_dbg(xhci, "Ring enq = %p (virt), 0x%llx (dma)\n",\r\nring->enqueue,\r\n(unsigned long long)xhci_trb_virt_to_dma(ring->enq_seg,\r\nring->enqueue));\r\nxhci_dbg(xhci, "Ring enq updated %u times\n",\r\nring->enq_updates);\r\n}\r\nvoid xhci_debug_ring(struct xhci_hcd *xhci, struct xhci_ring *ring)\r\n{\r\nstruct xhci_segment *seg;\r\nstruct xhci_segment *first_seg = ring->first_seg;\r\nxhci_debug_segment(xhci, first_seg);\r\nif (!ring->enq_updates && !ring->deq_updates) {\r\nxhci_dbg(xhci, " Ring has not been updated\n");\r\nreturn;\r\n}\r\nfor (seg = first_seg->next; seg != first_seg; seg = seg->next)\r\nxhci_debug_segment(xhci, seg);\r\n}\r\nvoid xhci_dbg_ep_rings(struct xhci_hcd *xhci,\r\nunsigned int slot_id, unsigned int ep_index,\r\nstruct xhci_virt_ep *ep)\r\n{\r\nint i;\r\nstruct xhci_ring *ring;\r\nif (ep->ep_state & EP_HAS_STREAMS) {\r\nfor (i = 1; i < ep->stream_info->num_streams; i++) {\r\nring = ep->stream_info->stream_rings[i];\r\nxhci_dbg(xhci, "Dev %d endpoint %d stream ID %d:\n",\r\nslot_id, ep_index, i);\r\nxhci_debug_segment(xhci, ring->deq_seg);\r\n}\r\n} else {\r\nring = ep->ring;\r\nif (!ring)\r\nreturn;\r\nxhci_dbg(xhci, "Dev %d endpoint ring %d:\n",\r\nslot_id, ep_index);\r\nxhci_debug_segment(xhci, ring->deq_seg);\r\n}\r\n}\r\nvoid xhci_dbg_erst(struct xhci_hcd *xhci, struct xhci_erst *erst)\r\n{\r\nu64 addr = erst->erst_dma_addr;\r\nint i;\r\nstruct xhci_erst_entry *entry;\r\nfor (i = 0; i < erst->num_entries; ++i) {\r\nentry = &erst->entries[i];\r\nxhci_dbg(xhci, "@%016llx %08x %08x %08x %08x\n",\r\naddr,\r\nlower_32_bits(le64_to_cpu(entry->seg_addr)),\r\nupper_32_bits(le64_to_cpu(entry->seg_addr)),\r\nle32_to_cpu(entry->seg_size),\r\nle32_to_cpu(entry->rsvd));\r\naddr += sizeof(*entry);\r\n}\r\n}\r\nvoid xhci_dbg_cmd_ptrs(struct xhci_hcd *xhci)\r\n{\r\nu64 val;\r\nval = xhci_read_64(xhci, &xhci->op_regs->cmd_ring);\r\nxhci_dbg(xhci, "// xHC command ring deq ptr low bits + flags = @%08x\n",\r\nlower_32_bits(val));\r\nxhci_dbg(xhci, "// xHC command ring deq ptr high bits = @%08x\n",\r\nupper_32_bits(val));\r\n}\r\nstatic void dbg_rsvd64(struct xhci_hcd *xhci, u64 *ctx, dma_addr_t dma)\r\n{\r\nint i;\r\nfor (i = 0; i < 4; ++i) {\r\nxhci_dbg(xhci, "@%p (virt) @%08llx "\r\n"(dma) %#08llx - rsvd64[%d]\n",\r\n&ctx[4 + i], (unsigned long long)dma,\r\nctx[4 + i], i);\r\ndma += 8;\r\n}\r\n}\r\nchar *xhci_get_slot_state(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *ctx)\r\n{\r\nstruct xhci_slot_ctx *slot_ctx = xhci_get_slot_ctx(xhci, ctx);\r\nswitch (GET_SLOT_STATE(le32_to_cpu(slot_ctx->dev_state))) {\r\ncase SLOT_STATE_ENABLED:\r\nreturn "enabled/disabled";\r\ncase SLOT_STATE_DEFAULT:\r\nreturn "default";\r\ncase SLOT_STATE_ADDRESSED:\r\nreturn "addressed";\r\ncase SLOT_STATE_CONFIGURED:\r\nreturn "configured";\r\ndefault:\r\nreturn "reserved";\r\n}\r\n}\r\nstatic void xhci_dbg_slot_ctx(struct xhci_hcd *xhci, struct xhci_container_ctx *ctx)\r\n{\r\nint field_size = 32 / 8;\r\nint i;\r\nstruct xhci_slot_ctx *slot_ctx = xhci_get_slot_ctx(xhci, ctx);\r\ndma_addr_t dma = ctx->dma +\r\n((unsigned long)slot_ctx - (unsigned long)ctx->bytes);\r\nint csz = HCC_64BYTE_CONTEXT(xhci->hcc_params);\r\nxhci_dbg(xhci, "Slot Context:\n");\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - dev_info\n",\r\n&slot_ctx->dev_info,\r\n(unsigned long long)dma, slot_ctx->dev_info);\r\ndma += field_size;\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - dev_info2\n",\r\n&slot_ctx->dev_info2,\r\n(unsigned long long)dma, slot_ctx->dev_info2);\r\ndma += field_size;\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - tt_info\n",\r\n&slot_ctx->tt_info,\r\n(unsigned long long)dma, slot_ctx->tt_info);\r\ndma += field_size;\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - dev_state\n",\r\n&slot_ctx->dev_state,\r\n(unsigned long long)dma, slot_ctx->dev_state);\r\ndma += field_size;\r\nfor (i = 0; i < 4; ++i) {\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - rsvd[%d]\n",\r\n&slot_ctx->reserved[i], (unsigned long long)dma,\r\nslot_ctx->reserved[i], i);\r\ndma += field_size;\r\n}\r\nif (csz)\r\ndbg_rsvd64(xhci, (u64 *)slot_ctx, dma);\r\n}\r\nstatic void xhci_dbg_ep_ctx(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *ctx,\r\nunsigned int last_ep)\r\n{\r\nint i, j;\r\nint last_ep_ctx = 31;\r\nint field_size = 32 / 8;\r\nint csz = HCC_64BYTE_CONTEXT(xhci->hcc_params);\r\nif (last_ep < 31)\r\nlast_ep_ctx = last_ep + 1;\r\nfor (i = 0; i < last_ep_ctx; ++i) {\r\nunsigned int epaddr = xhci_get_endpoint_address(i);\r\nstruct xhci_ep_ctx *ep_ctx = xhci_get_ep_ctx(xhci, ctx, i);\r\ndma_addr_t dma = ctx->dma +\r\n((unsigned long)ep_ctx - (unsigned long)ctx->bytes);\r\nxhci_dbg(xhci, "%s Endpoint %02d Context (ep_index %02d):\n",\r\nusb_endpoint_out(epaddr) ? "OUT" : "IN",\r\nepaddr & USB_ENDPOINT_NUMBER_MASK, i);\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - ep_info\n",\r\n&ep_ctx->ep_info,\r\n(unsigned long long)dma, ep_ctx->ep_info);\r\ndma += field_size;\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - ep_info2\n",\r\n&ep_ctx->ep_info2,\r\n(unsigned long long)dma, ep_ctx->ep_info2);\r\ndma += field_size;\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08llx - deq\n",\r\n&ep_ctx->deq,\r\n(unsigned long long)dma, ep_ctx->deq);\r\ndma += 2*field_size;\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - tx_info\n",\r\n&ep_ctx->tx_info,\r\n(unsigned long long)dma, ep_ctx->tx_info);\r\ndma += field_size;\r\nfor (j = 0; j < 3; ++j) {\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - rsvd[%d]\n",\r\n&ep_ctx->reserved[j],\r\n(unsigned long long)dma,\r\nep_ctx->reserved[j], j);\r\ndma += field_size;\r\n}\r\nif (csz)\r\ndbg_rsvd64(xhci, (u64 *)ep_ctx, dma);\r\n}\r\n}\r\nvoid xhci_dbg_ctx(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *ctx,\r\nunsigned int last_ep)\r\n{\r\nint i;\r\nint field_size = 32 / 8;\r\ndma_addr_t dma = ctx->dma;\r\nint csz = HCC_64BYTE_CONTEXT(xhci->hcc_params);\r\nif (ctx->type == XHCI_CTX_TYPE_INPUT) {\r\nstruct xhci_input_control_ctx *ctrl_ctx =\r\nxhci_get_input_control_ctx(xhci, ctx);\r\nif (!ctrl_ctx) {\r\nxhci_warn(xhci, "Could not get input context, bad type.\n");\r\nreturn;\r\n}\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - drop flags\n",\r\n&ctrl_ctx->drop_flags, (unsigned long long)dma,\r\nctrl_ctx->drop_flags);\r\ndma += field_size;\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - add flags\n",\r\n&ctrl_ctx->add_flags, (unsigned long long)dma,\r\nctrl_ctx->add_flags);\r\ndma += field_size;\r\nfor (i = 0; i < 6; ++i) {\r\nxhci_dbg(xhci, "@%p (virt) @%08llx (dma) %#08x - rsvd2[%d]\n",\r\n&ctrl_ctx->rsvd2[i], (unsigned long long)dma,\r\nctrl_ctx->rsvd2[i], i);\r\ndma += field_size;\r\n}\r\nif (csz)\r\ndbg_rsvd64(xhci, (u64 *)ctrl_ctx, dma);\r\n}\r\nxhci_dbg_slot_ctx(xhci, ctx);\r\nxhci_dbg_ep_ctx(xhci, ctx, last_ep);\r\n}\r\nvoid xhci_dbg_trace(struct xhci_hcd *xhci, void (*trace)(struct va_format *),\r\nconst char *fmt, ...)\r\n{\r\nstruct va_format vaf;\r\nva_list args;\r\nva_start(args, fmt);\r\nvaf.fmt = fmt;\r\nvaf.va = &args;\r\nxhci_dbg(xhci, "%pV\n", &vaf);\r\ntrace(&vaf);\r\nva_end(args);\r\n}
