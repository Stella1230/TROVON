static int lustre_groups_search(const struct group_info *group_info, gid_t grp)\r\n{\r\nint left, right;\r\nif (!group_info)\r\nreturn 0;\r\nleft = 0;\r\nright = group_info->ngroups;\r\nwhile (left < right) {\r\nint mid = (left + right) / 2;\r\nint cmp = grp -\r\nfrom_kgid(&init_user_ns, CFS_GROUP_AT(group_info, mid));\r\nif (cmp > 0)\r\nleft = mid + 1;\r\nelse if (cmp < 0)\r\nright = mid;\r\nelse\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nvoid lustre_groups_from_list(struct group_info *ginfo, gid_t *glist)\r\n{\r\nint i;\r\nint count = ginfo->ngroups;\r\nfor (i = 0; i < ginfo->nblocks && count > 0; i++) {\r\nint cp_count = min(CFS_NGROUPS_PER_BLOCK, count);\r\nint off = i * CFS_NGROUPS_PER_BLOCK;\r\nint len = cp_count * sizeof(*glist);\r\nmemcpy(ginfo->blocks[i], glist + off, len);\r\ncount -= cp_count;\r\n}\r\n}\r\nvoid lustre_groups_sort(struct group_info *group_info)\r\n{\r\nint base, max, stride;\r\nint gidsetsize = group_info->ngroups;\r\nfor (stride = 1; stride < gidsetsize; stride = 3 * stride + 1)\r\n;\r\nstride /= 3;\r\nwhile (stride) {\r\nmax = gidsetsize - stride;\r\nfor (base = 0; base < max; base++) {\r\nint left = base;\r\nint right = left + stride;\r\ngid_t tmp = from_kgid(&init_user_ns,\r\nCFS_GROUP_AT(group_info, right));\r\nwhile (left >= 0 &&\r\ntmp < from_kgid(&init_user_ns,\r\nCFS_GROUP_AT(group_info, left))) {\r\nCFS_GROUP_AT(group_info, right) =\r\nCFS_GROUP_AT(group_info, left);\r\nright = left;\r\nleft -= stride;\r\n}\r\nCFS_GROUP_AT(group_info, right) =\r\nmake_kgid(&init_user_ns, tmp);\r\n}\r\nstride /= 3;\r\n}\r\n}\r\nint lustre_in_group_p(struct lu_ucred *mu, gid_t grp)\r\n{\r\nint rc = 1;\r\nif (grp != mu->uc_fsgid) {\r\nstruct group_info *group_info = NULL;\r\nif (mu->uc_ginfo || !mu->uc_identity ||\r\nmu->uc_valid == UCRED_OLD)\r\nif (grp == mu->uc_suppgids[0] ||\r\ngrp == mu->uc_suppgids[1])\r\nreturn 1;\r\nif (mu->uc_ginfo)\r\ngroup_info = mu->uc_ginfo;\r\nelse if (mu->uc_identity)\r\ngroup_info = mu->uc_identity->mi_ginfo;\r\nif (!group_info)\r\nreturn 0;\r\nlustre_get_group_info(group_info);\r\nrc = lustre_groups_search(group_info, grp);\r\nlustre_put_group_info(group_info);\r\n}\r\nreturn rc;\r\n}\r\nstatic inline __u32 lustre_idmap_hashfunc(__u32 id)\r\n{\r\nreturn id & (CFS_IDMAP_HASHSIZE - 1);\r\n}\r\nstatic\r\nstruct lustre_idmap_entry *idmap_entry_alloc(uid_t rmt_uid, uid_t lcl_uid,\r\ngid_t rmt_gid, gid_t lcl_gid)\r\n{\r\nstruct lustre_idmap_entry *e;\r\nOBD_ALLOC_PTR(e);\r\nif (e == NULL)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&e->lie_rmt_uid_hash);\r\nINIT_LIST_HEAD(&e->lie_lcl_uid_hash);\r\nINIT_LIST_HEAD(&e->lie_rmt_gid_hash);\r\nINIT_LIST_HEAD(&e->lie_lcl_gid_hash);\r\ne->lie_rmt_uid = rmt_uid;\r\ne->lie_lcl_uid = lcl_uid;\r\ne->lie_rmt_gid = rmt_gid;\r\ne->lie_lcl_gid = lcl_gid;\r\nreturn e;\r\n}\r\nstatic void idmap_entry_free(struct lustre_idmap_entry *e)\r\n{\r\nif (!list_empty(&e->lie_rmt_uid_hash))\r\nlist_del(&e->lie_rmt_uid_hash);\r\nif (!list_empty(&e->lie_lcl_uid_hash))\r\nlist_del(&e->lie_lcl_uid_hash);\r\nif (!list_empty(&e->lie_rmt_gid_hash))\r\nlist_del(&e->lie_rmt_gid_hash);\r\nif (!list_empty(&e->lie_lcl_gid_hash))\r\nlist_del(&e->lie_lcl_gid_hash);\r\nOBD_FREE_PTR(e);\r\n}\r\nstatic\r\nstruct lustre_idmap_entry *idmap_search_entry(struct lustre_idmap_table *t,\r\nuid_t rmt_uid, uid_t lcl_uid,\r\ngid_t rmt_gid, gid_t lcl_gid)\r\n{\r\nstruct list_head *head;\r\nstruct lustre_idmap_entry *e;\r\nhead = &t->lit_idmaps[RMT_UIDMAP_IDX][lustre_idmap_hashfunc(rmt_uid)];\r\nlist_for_each_entry(e, head, lie_rmt_uid_hash)\r\nif (e->lie_rmt_uid == rmt_uid) {\r\nif (e->lie_lcl_uid == lcl_uid) {\r\nif (e->lie_rmt_gid == rmt_gid &&\r\ne->lie_lcl_gid == lcl_gid)\r\nreturn e;\r\n} else {\r\nCERROR("rmt uid %u already be mapped to %u"\r\n" (new %u)\n", e->lie_rmt_uid,\r\ne->lie_lcl_uid, lcl_uid);\r\nreturn ERR_PTR(-EACCES);\r\n}\r\n}\r\nhead = &t->lit_idmaps[RMT_GIDMAP_IDX][lustre_idmap_hashfunc(rmt_gid)];\r\nlist_for_each_entry(e, head, lie_rmt_gid_hash)\r\nif (e->lie_rmt_gid == rmt_gid) {\r\nif (e->lie_lcl_gid == lcl_gid) {\r\nif (unlikely(e->lie_rmt_uid == rmt_uid &&\r\ne->lie_lcl_uid == lcl_uid))\r\nLBUG();\r\n} else {\r\nCERROR("rmt gid %u already be mapped to %u"\r\n" (new %u)\n", e->lie_rmt_gid,\r\ne->lie_lcl_gid, lcl_gid);\r\nreturn ERR_PTR(-EACCES);\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic __u32 idmap_lookup_uid(struct list_head *hash, int reverse,\r\n__u32 uid)\r\n{\r\nstruct list_head *head = &hash[lustre_idmap_hashfunc(uid)];\r\nstruct lustre_idmap_entry *e;\r\nif (!reverse) {\r\nlist_for_each_entry(e, head, lie_rmt_uid_hash)\r\nif (e->lie_rmt_uid == uid)\r\nreturn e->lie_lcl_uid;\r\n} else {\r\nlist_for_each_entry(e, head, lie_lcl_uid_hash)\r\nif (e->lie_lcl_uid == uid)\r\nreturn e->lie_rmt_uid;\r\n}\r\nreturn CFS_IDMAP_NOTFOUND;\r\n}\r\nstatic __u32 idmap_lookup_gid(struct list_head *hash, int reverse, __u32 gid)\r\n{\r\nstruct list_head *head = &hash[lustre_idmap_hashfunc(gid)];\r\nstruct lustre_idmap_entry *e;\r\nif (!reverse) {\r\nlist_for_each_entry(e, head, lie_rmt_gid_hash)\r\nif (e->lie_rmt_gid == gid)\r\nreturn e->lie_lcl_gid;\r\n} else {\r\nlist_for_each_entry(e, head, lie_lcl_gid_hash)\r\nif (e->lie_lcl_gid == gid)\r\nreturn e->lie_rmt_gid;\r\n}\r\nreturn CFS_IDMAP_NOTFOUND;\r\n}\r\nint lustre_idmap_add(struct lustre_idmap_table *t,\r\nuid_t ruid, uid_t luid,\r\ngid_t rgid, gid_t lgid)\r\n{\r\nstruct lustre_idmap_entry *e0, *e1;\r\nLASSERT(t);\r\nspin_lock(&t->lit_lock);\r\ne0 = idmap_search_entry(t, ruid, luid, rgid, lgid);\r\nspin_unlock(&t->lit_lock);\r\nif (!e0) {\r\ne0 = idmap_entry_alloc(ruid, luid, rgid, lgid);\r\nif (!e0)\r\nreturn -ENOMEM;\r\nspin_lock(&t->lit_lock);\r\ne1 = idmap_search_entry(t, ruid, luid, rgid, lgid);\r\nif (e1 == NULL) {\r\nlist_add_tail(&e0->lie_rmt_uid_hash,\r\n&t->lit_idmaps[RMT_UIDMAP_IDX]\r\n[lustre_idmap_hashfunc(ruid)]);\r\nlist_add_tail(&e0->lie_lcl_uid_hash,\r\n&t->lit_idmaps[LCL_UIDMAP_IDX]\r\n[lustre_idmap_hashfunc(luid)]);\r\nlist_add_tail(&e0->lie_rmt_gid_hash,\r\n&t->lit_idmaps[RMT_GIDMAP_IDX]\r\n[lustre_idmap_hashfunc(rgid)]);\r\nlist_add_tail(&e0->lie_lcl_gid_hash,\r\n&t->lit_idmaps[LCL_GIDMAP_IDX]\r\n[lustre_idmap_hashfunc(lgid)]);\r\n}\r\nspin_unlock(&t->lit_lock);\r\nif (e1 != NULL) {\r\nidmap_entry_free(e0);\r\nif (IS_ERR(e1))\r\nreturn PTR_ERR(e1);\r\n}\r\n} else if (IS_ERR(e0)) {\r\nreturn PTR_ERR(e0);\r\n}\r\nreturn 0;\r\n}\r\nint lustre_idmap_del(struct lustre_idmap_table *t,\r\nuid_t ruid, uid_t luid,\r\ngid_t rgid, gid_t lgid)\r\n{\r\nstruct lustre_idmap_entry *e;\r\nint rc = 0;\r\nLASSERT(t);\r\nspin_lock(&t->lit_lock);\r\ne = idmap_search_entry(t, ruid, luid, rgid, lgid);\r\nif (IS_ERR(e))\r\nrc = PTR_ERR(e);\r\nelse if (e)\r\nidmap_entry_free(e);\r\nspin_unlock(&t->lit_lock);\r\nreturn rc;\r\n}\r\nint lustre_idmap_lookup_uid(struct lu_ucred *mu,\r\nstruct lustre_idmap_table *t,\r\nint reverse, uid_t uid)\r\n{\r\nstruct list_head *hash;\r\nif (mu && (mu->uc_valid == UCRED_OLD || mu->uc_valid == UCRED_NEW)) {\r\nif (!reverse) {\r\nif (uid == mu->uc_o_uid)\r\nreturn mu->uc_uid;\r\nelse if (uid == mu->uc_o_fsuid)\r\nreturn mu->uc_fsuid;\r\n} else {\r\nif (uid == mu->uc_uid)\r\nreturn mu->uc_o_uid;\r\nelse if (uid == mu->uc_fsuid)\r\nreturn mu->uc_o_fsuid;\r\n}\r\n}\r\nif (t == NULL)\r\nreturn CFS_IDMAP_NOTFOUND;\r\nhash = t->lit_idmaps[reverse ? LCL_UIDMAP_IDX : RMT_UIDMAP_IDX];\r\nspin_lock(&t->lit_lock);\r\nuid = idmap_lookup_uid(hash, reverse, uid);\r\nspin_unlock(&t->lit_lock);\r\nreturn uid;\r\n}\r\nint lustre_idmap_lookup_gid(struct lu_ucred *mu, struct lustre_idmap_table *t,\r\nint reverse, gid_t gid)\r\n{\r\nstruct list_head *hash;\r\nif (mu && (mu->uc_valid == UCRED_OLD || mu->uc_valid == UCRED_NEW)) {\r\nif (!reverse) {\r\nif (gid == mu->uc_o_gid)\r\nreturn mu->uc_gid;\r\nelse if (gid == mu->uc_o_fsgid)\r\nreturn mu->uc_fsgid;\r\n} else {\r\nif (gid == mu->uc_gid)\r\nreturn mu->uc_o_gid;\r\nelse if (gid == mu->uc_fsgid)\r\nreturn mu->uc_o_fsgid;\r\n}\r\n}\r\nif (t == NULL)\r\nreturn CFS_IDMAP_NOTFOUND;\r\nhash = t->lit_idmaps[reverse ? LCL_GIDMAP_IDX : RMT_GIDMAP_IDX];\r\nspin_lock(&t->lit_lock);\r\ngid = idmap_lookup_gid(hash, reverse, gid);\r\nspin_unlock(&t->lit_lock);\r\nreturn gid;\r\n}\r\nstruct lustre_idmap_table *lustre_idmap_init(void)\r\n{\r\nstruct lustre_idmap_table *t;\r\nint i, j;\r\nOBD_ALLOC_PTR(t);\r\nif(unlikely(t == NULL))\r\nreturn (ERR_PTR(-ENOMEM));\r\nspin_lock_init(&t->lit_lock);\r\nfor (i = 0; i < ARRAY_SIZE(t->lit_idmaps); i++)\r\nfor (j = 0; j < ARRAY_SIZE(t->lit_idmaps[i]); j++)\r\nINIT_LIST_HEAD(&t->lit_idmaps[i][j]);\r\nreturn t;\r\n}\r\nvoid lustre_idmap_fini(struct lustre_idmap_table *t)\r\n{\r\nstruct list_head *list;\r\nstruct lustre_idmap_entry *e;\r\nint i;\r\nLASSERT(t);\r\nlist = t->lit_idmaps[RMT_UIDMAP_IDX];\r\nspin_lock(&t->lit_lock);\r\nfor (i = 0; i < CFS_IDMAP_HASHSIZE; i++)\r\nwhile (!list_empty(&list[i])) {\r\ne = list_entry(list[i].next,\r\nstruct lustre_idmap_entry,\r\nlie_rmt_uid_hash);\r\nidmap_entry_free(e);\r\n}\r\nspin_unlock(&t->lit_lock);\r\nOBD_FREE_PTR(t);\r\n}
