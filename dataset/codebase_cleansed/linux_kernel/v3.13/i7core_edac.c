static inline int numdimms(u32 dimms)\r\n{\r\nreturn (dimms & 0x3) + 1;\r\n}\r\nstatic inline int numrank(u32 rank)\r\n{\r\nstatic const int ranks[] = { 1, 2, 4, -EINVAL };\r\nreturn ranks[rank & 0x3];\r\n}\r\nstatic inline int numbank(u32 bank)\r\n{\r\nstatic const int banks[] = { 4, 8, 16, -EINVAL };\r\nreturn banks[bank & 0x3];\r\n}\r\nstatic inline int numrow(u32 row)\r\n{\r\nstatic const int rows[] = {\r\n1 << 12, 1 << 13, 1 << 14, 1 << 15,\r\n1 << 16, -EINVAL, -EINVAL, -EINVAL,\r\n};\r\nreturn rows[row & 0x7];\r\n}\r\nstatic inline int numcol(u32 col)\r\n{\r\nstatic const int cols[] = {\r\n1 << 10, 1 << 11, 1 << 12, -EINVAL,\r\n};\r\nreturn cols[col & 0x3];\r\n}\r\nstatic struct i7core_dev *get_i7core_dev(u8 socket)\r\n{\r\nstruct i7core_dev *i7core_dev;\r\nlist_for_each_entry(i7core_dev, &i7core_edac_list, list) {\r\nif (i7core_dev->socket == socket)\r\nreturn i7core_dev;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct i7core_dev *alloc_i7core_dev(u8 socket,\r\nconst struct pci_id_table *table)\r\n{\r\nstruct i7core_dev *i7core_dev;\r\ni7core_dev = kzalloc(sizeof(*i7core_dev), GFP_KERNEL);\r\nif (!i7core_dev)\r\nreturn NULL;\r\ni7core_dev->pdev = kzalloc(sizeof(*i7core_dev->pdev) * table->n_devs,\r\nGFP_KERNEL);\r\nif (!i7core_dev->pdev) {\r\nkfree(i7core_dev);\r\nreturn NULL;\r\n}\r\ni7core_dev->socket = socket;\r\ni7core_dev->n_devs = table->n_devs;\r\nlist_add_tail(&i7core_dev->list, &i7core_edac_list);\r\nreturn i7core_dev;\r\n}\r\nstatic void free_i7core_dev(struct i7core_dev *i7core_dev)\r\n{\r\nlist_del(&i7core_dev->list);\r\nkfree(i7core_dev->pdev);\r\nkfree(i7core_dev);\r\n}\r\nstatic int get_dimm_config(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nstruct pci_dev *pdev;\r\nint i, j;\r\nenum edac_type mode;\r\nenum mem_type mtype;\r\nstruct dimm_info *dimm;\r\npdev = pvt->pci_mcr[0];\r\nif (!pdev)\r\nreturn -ENODEV;\r\npci_read_config_dword(pdev, MC_CONTROL, &pvt->info.mc_control);\r\npci_read_config_dword(pdev, MC_STATUS, &pvt->info.mc_status);\r\npci_read_config_dword(pdev, MC_MAX_DOD, &pvt->info.max_dod);\r\npci_read_config_dword(pdev, MC_CHANNEL_MAPPER, &pvt->info.ch_map);\r\nedac_dbg(0, "QPI %d control=0x%08x status=0x%08x dod=0x%08x map=0x%08x\n",\r\npvt->i7core_dev->socket, pvt->info.mc_control,\r\npvt->info.mc_status, pvt->info.max_dod, pvt->info.ch_map);\r\nif (ECC_ENABLED(pvt)) {\r\nedac_dbg(0, "ECC enabled with x%d SDCC\n", ECCx8(pvt) ? 8 : 4);\r\nif (ECCx8(pvt))\r\nmode = EDAC_S8ECD8ED;\r\nelse\r\nmode = EDAC_S4ECD4ED;\r\n} else {\r\nedac_dbg(0, "ECC disabled\n");\r\nmode = EDAC_NONE;\r\n}\r\nedac_dbg(0, "DOD Max limits: DIMMS: %d, %d-ranked, %d-banked x%x x 0x%x\n",\r\nnumdimms(pvt->info.max_dod),\r\nnumrank(pvt->info.max_dod >> 2),\r\nnumbank(pvt->info.max_dod >> 4),\r\nnumrow(pvt->info.max_dod >> 6),\r\nnumcol(pvt->info.max_dod >> 9));\r\nfor (i = 0; i < NUM_CHANS; i++) {\r\nu32 data, dimm_dod[3], value[8];\r\nif (!pvt->pci_ch[i][0])\r\ncontinue;\r\nif (!CH_ACTIVE(pvt, i)) {\r\nedac_dbg(0, "Channel %i is not active\n", i);\r\ncontinue;\r\n}\r\nif (CH_DISABLED(pvt, i)) {\r\nedac_dbg(0, "Channel %i is disabled\n", i);\r\ncontinue;\r\n}\r\npci_read_config_dword(pvt->pci_ch[i][0],\r\nMC_CHANNEL_DIMM_INIT_PARAMS, &data);\r\nif (data & THREE_DIMMS_PRESENT)\r\npvt->channel[i].is_3dimms_present = true;\r\nif (data & SINGLE_QUAD_RANK_PRESENT)\r\npvt->channel[i].is_single_4rank = true;\r\nif (data & QUAD_RANK_PRESENT)\r\npvt->channel[i].has_4rank = true;\r\nif (data & REGISTERED_DIMM)\r\nmtype = MEM_RDDR3;\r\nelse\r\nmtype = MEM_DDR3;\r\npci_read_config_dword(pvt->pci_ch[i][1],\r\nMC_DOD_CH_DIMM0, &dimm_dod[0]);\r\npci_read_config_dword(pvt->pci_ch[i][1],\r\nMC_DOD_CH_DIMM1, &dimm_dod[1]);\r\npci_read_config_dword(pvt->pci_ch[i][1],\r\nMC_DOD_CH_DIMM2, &dimm_dod[2]);\r\nedac_dbg(0, "Ch%d phy rd%d, wr%d (0x%08x): %s%s%s%cDIMMs\n",\r\ni,\r\nRDLCH(pvt->info.ch_map, i), WRLCH(pvt->info.ch_map, i),\r\ndata,\r\npvt->channel[i].is_3dimms_present ? "3DIMMS " : "",\r\npvt->channel[i].is_3dimms_present ? "SINGLE_4R " : "",\r\npvt->channel[i].has_4rank ? "HAS_4R " : "",\r\n(data & REGISTERED_DIMM) ? 'R' : 'U');\r\nfor (j = 0; j < 3; j++) {\r\nu32 banks, ranks, rows, cols;\r\nu32 size, npages;\r\nif (!DIMM_PRESENT(dimm_dod[j]))\r\ncontinue;\r\ndimm = EDAC_DIMM_PTR(mci->layers, mci->dimms, mci->n_layers,\r\ni, j, 0);\r\nbanks = numbank(MC_DOD_NUMBANK(dimm_dod[j]));\r\nranks = numrank(MC_DOD_NUMRANK(dimm_dod[j]));\r\nrows = numrow(MC_DOD_NUMROW(dimm_dod[j]));\r\ncols = numcol(MC_DOD_NUMCOL(dimm_dod[j]));\r\nsize = (rows * cols * banks * ranks) >> (20 - 3);\r\nedac_dbg(0, "\tdimm %d %d Mb offset: %x, bank: %d, rank: %d, row: %#x, col: %#x\n",\r\nj, size,\r\nRANKOFFSET(dimm_dod[j]),\r\nbanks, ranks, rows, cols);\r\nnpages = MiB_TO_PAGES(size);\r\ndimm->nr_pages = npages;\r\nswitch (banks) {\r\ncase 4:\r\ndimm->dtype = DEV_X4;\r\nbreak;\r\ncase 8:\r\ndimm->dtype = DEV_X8;\r\nbreak;\r\ncase 16:\r\ndimm->dtype = DEV_X16;\r\nbreak;\r\ndefault:\r\ndimm->dtype = DEV_UNKNOWN;\r\n}\r\nsnprintf(dimm->label, sizeof(dimm->label),\r\n"CPU#%uChannel#%u_DIMM#%u",\r\npvt->i7core_dev->socket, i, j);\r\ndimm->grain = 8;\r\ndimm->edac_mode = mode;\r\ndimm->mtype = mtype;\r\n}\r\npci_read_config_dword(pdev, MC_SAG_CH_0, &value[0]);\r\npci_read_config_dword(pdev, MC_SAG_CH_1, &value[1]);\r\npci_read_config_dword(pdev, MC_SAG_CH_2, &value[2]);\r\npci_read_config_dword(pdev, MC_SAG_CH_3, &value[3]);\r\npci_read_config_dword(pdev, MC_SAG_CH_4, &value[4]);\r\npci_read_config_dword(pdev, MC_SAG_CH_5, &value[5]);\r\npci_read_config_dword(pdev, MC_SAG_CH_6, &value[6]);\r\npci_read_config_dword(pdev, MC_SAG_CH_7, &value[7]);\r\nedac_dbg(1, "\t[%i] DIVBY3\tREMOVED\tOFFSET\n", i);\r\nfor (j = 0; j < 8; j++)\r\nedac_dbg(1, "\t\t%#x\t%#x\t%#x\n",\r\n(value[j] >> 27) & 0x1,\r\n(value[j] >> 24) & 0x7,\r\n(value[j] & ((1 << 24) - 1)));\r\n}\r\nreturn 0;\r\n}\r\nstatic int disable_inject(const struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\npvt->inject.enable = 0;\r\nif (!pvt->pci_ch[pvt->inject.channel][0])\r\nreturn -ENODEV;\r\npci_write_config_dword(pvt->pci_ch[pvt->inject.channel][0],\r\nMC_CHANNEL_ERROR_INJECT, 0);\r\nreturn 0;\r\n}\r\nstatic ssize_t i7core_inject_section_store(struct device *dev,\r\nstruct device_attribute *mattr,\r\nconst char *data, size_t count)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nunsigned long value;\r\nint rc;\r\nif (pvt->inject.enable)\r\ndisable_inject(mci);\r\nrc = kstrtoul(data, 10, &value);\r\nif ((rc < 0) || (value > 3))\r\nreturn -EIO;\r\npvt->inject.section = (u32) value;\r\nreturn count;\r\n}\r\nstatic ssize_t i7core_inject_section_show(struct device *dev,\r\nstruct device_attribute *mattr,\r\nchar *data)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nreturn sprintf(data, "0x%08x\n", pvt->inject.section);\r\n}\r\nstatic ssize_t i7core_inject_type_store(struct device *dev,\r\nstruct device_attribute *mattr,\r\nconst char *data, size_t count)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nunsigned long value;\r\nint rc;\r\nif (pvt->inject.enable)\r\ndisable_inject(mci);\r\nrc = kstrtoul(data, 10, &value);\r\nif ((rc < 0) || (value > 7))\r\nreturn -EIO;\r\npvt->inject.type = (u32) value;\r\nreturn count;\r\n}\r\nstatic ssize_t i7core_inject_type_show(struct device *dev,\r\nstruct device_attribute *mattr,\r\nchar *data)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nreturn sprintf(data, "0x%08x\n", pvt->inject.type);\r\n}\r\nstatic ssize_t i7core_inject_eccmask_store(struct device *dev,\r\nstruct device_attribute *mattr,\r\nconst char *data, size_t count)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nunsigned long value;\r\nint rc;\r\nif (pvt->inject.enable)\r\ndisable_inject(mci);\r\nrc = kstrtoul(data, 10, &value);\r\nif (rc < 0)\r\nreturn -EIO;\r\npvt->inject.eccmask = (u32) value;\r\nreturn count;\r\n}\r\nstatic ssize_t i7core_inject_eccmask_show(struct device *dev,\r\nstruct device_attribute *mattr,\r\nchar *data)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nreturn sprintf(data, "0x%08x\n", pvt->inject.eccmask);\r\n}\r\nstatic int write_and_test(struct pci_dev *dev, const int where, const u32 val)\r\n{\r\nu32 read;\r\nint count;\r\nedac_dbg(0, "setting pci %02x:%02x.%x reg=%02x value=%08x\n",\r\ndev->bus->number, PCI_SLOT(dev->devfn), PCI_FUNC(dev->devfn),\r\nwhere, val);\r\nfor (count = 0; count < 10; count++) {\r\nif (count)\r\nmsleep(100);\r\npci_write_config_dword(dev, where, val);\r\npci_read_config_dword(dev, where, &read);\r\nif (read == val)\r\nreturn 0;\r\n}\r\ni7core_printk(KERN_ERR, "Error during set pci %02x:%02x.%x reg=%02x "\r\n"write=%08x. Read=%08x\n",\r\ndev->bus->number, PCI_SLOT(dev->devfn), PCI_FUNC(dev->devfn),\r\nwhere, val, read);\r\nreturn -EINVAL;\r\n}\r\nstatic ssize_t i7core_inject_enable_store(struct device *dev,\r\nstruct device_attribute *mattr,\r\nconst char *data, size_t count)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nu32 injectmask;\r\nu64 mask = 0;\r\nint rc;\r\nlong enable;\r\nif (!pvt->pci_ch[pvt->inject.channel][0])\r\nreturn 0;\r\nrc = kstrtoul(data, 10, &enable);\r\nif ((rc < 0))\r\nreturn 0;\r\nif (enable) {\r\npvt->inject.enable = 1;\r\n} else {\r\ndisable_inject(mci);\r\nreturn count;\r\n}\r\nif (pvt->inject.dimm < 0)\r\nmask |= 1LL << 41;\r\nelse {\r\nif (pvt->channel[pvt->inject.channel].dimms > 2)\r\nmask |= (pvt->inject.dimm & 0x3LL) << 35;\r\nelse\r\nmask |= (pvt->inject.dimm & 0x1LL) << 36;\r\n}\r\nif (pvt->inject.rank < 0)\r\nmask |= 1LL << 40;\r\nelse {\r\nif (pvt->channel[pvt->inject.channel].dimms > 2)\r\nmask |= (pvt->inject.rank & 0x1LL) << 34;\r\nelse\r\nmask |= (pvt->inject.rank & 0x3LL) << 34;\r\n}\r\nif (pvt->inject.bank < 0)\r\nmask |= 1LL << 39;\r\nelse\r\nmask |= (pvt->inject.bank & 0x15LL) << 30;\r\nif (pvt->inject.page < 0)\r\nmask |= 1LL << 38;\r\nelse\r\nmask |= (pvt->inject.page & 0xffff) << 14;\r\nif (pvt->inject.col < 0)\r\nmask |= 1LL << 37;\r\nelse\r\nmask |= (pvt->inject.col & 0x3fff);\r\ninjectmask = (pvt->inject.type & 1) |\r\n(pvt->inject.section & 0x3) << 1 |\r\n(pvt->inject.type & 0x6) << (3 - 1);\r\npci_write_config_dword(pvt->pci_noncore,\r\nMC_CFG_CONTROL, 0x2);\r\nwrite_and_test(pvt->pci_ch[pvt->inject.channel][0],\r\nMC_CHANNEL_ADDR_MATCH, mask);\r\nwrite_and_test(pvt->pci_ch[pvt->inject.channel][0],\r\nMC_CHANNEL_ADDR_MATCH + 4, mask >> 32L);\r\nwrite_and_test(pvt->pci_ch[pvt->inject.channel][0],\r\nMC_CHANNEL_ERROR_MASK, pvt->inject.eccmask);\r\nwrite_and_test(pvt->pci_ch[pvt->inject.channel][0],\r\nMC_CHANNEL_ERROR_INJECT, injectmask);\r\npci_write_config_dword(pvt->pci_noncore,\r\nMC_CFG_CONTROL, 8);\r\nedac_dbg(0, "Error inject addr match 0x%016llx, ecc 0x%08x, inject 0x%08x\n",\r\nmask, pvt->inject.eccmask, injectmask);\r\nreturn count;\r\n}\r\nstatic ssize_t i7core_inject_enable_show(struct device *dev,\r\nstruct device_attribute *mattr,\r\nchar *data)\r\n{\r\nstruct mem_ctl_info *mci = to_mci(dev);\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nu32 injectmask;\r\nif (!pvt->pci_ch[pvt->inject.channel][0])\r\nreturn 0;\r\npci_read_config_dword(pvt->pci_ch[pvt->inject.channel][0],\r\nMC_CHANNEL_ERROR_INJECT, &injectmask);\r\nedac_dbg(0, "Inject error read: 0x%018x\n", injectmask);\r\nif (injectmask & 0x0c)\r\npvt->inject.enable = 1;\r\nreturn sprintf(data, "%d\n", pvt->inject.enable);\r\n}\r\nstatic void addrmatch_release(struct device *device)\r\n{\r\nedac_dbg(1, "Releasing device %s\n", dev_name(device));\r\nkfree(device);\r\n}\r\nstatic void all_channel_counts_release(struct device *device)\r\n{\r\nedac_dbg(1, "Releasing device %s\n", dev_name(device));\r\nkfree(device);\r\n}\r\nstatic int i7core_create_sysfs_devices(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nint rc;\r\nrc = device_create_file(&mci->dev, &dev_attr_inject_section);\r\nif (rc < 0)\r\nreturn rc;\r\nrc = device_create_file(&mci->dev, &dev_attr_inject_type);\r\nif (rc < 0)\r\nreturn rc;\r\nrc = device_create_file(&mci->dev, &dev_attr_inject_eccmask);\r\nif (rc < 0)\r\nreturn rc;\r\nrc = device_create_file(&mci->dev, &dev_attr_inject_enable);\r\nif (rc < 0)\r\nreturn rc;\r\npvt->addrmatch_dev = kzalloc(sizeof(*pvt->addrmatch_dev), GFP_KERNEL);\r\nif (!pvt->addrmatch_dev)\r\nreturn rc;\r\npvt->addrmatch_dev->type = &addrmatch_type;\r\npvt->addrmatch_dev->bus = mci->dev.bus;\r\ndevice_initialize(pvt->addrmatch_dev);\r\npvt->addrmatch_dev->parent = &mci->dev;\r\ndev_set_name(pvt->addrmatch_dev, "inject_addrmatch");\r\ndev_set_drvdata(pvt->addrmatch_dev, mci);\r\nedac_dbg(1, "creating %s\n", dev_name(pvt->addrmatch_dev));\r\nrc = device_add(pvt->addrmatch_dev);\r\nif (rc < 0)\r\nreturn rc;\r\nif (!pvt->is_registered) {\r\npvt->chancounts_dev = kzalloc(sizeof(*pvt->chancounts_dev),\r\nGFP_KERNEL);\r\nif (!pvt->chancounts_dev) {\r\nput_device(pvt->addrmatch_dev);\r\ndevice_del(pvt->addrmatch_dev);\r\nreturn rc;\r\n}\r\npvt->chancounts_dev->type = &all_channel_counts_type;\r\npvt->chancounts_dev->bus = mci->dev.bus;\r\ndevice_initialize(pvt->chancounts_dev);\r\npvt->chancounts_dev->parent = &mci->dev;\r\ndev_set_name(pvt->chancounts_dev, "all_channel_counts");\r\ndev_set_drvdata(pvt->chancounts_dev, mci);\r\nedac_dbg(1, "creating %s\n", dev_name(pvt->chancounts_dev));\r\nrc = device_add(pvt->chancounts_dev);\r\nif (rc < 0)\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic void i7core_delete_sysfs_devices(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nedac_dbg(1, "\n");\r\ndevice_remove_file(&mci->dev, &dev_attr_inject_section);\r\ndevice_remove_file(&mci->dev, &dev_attr_inject_type);\r\ndevice_remove_file(&mci->dev, &dev_attr_inject_eccmask);\r\ndevice_remove_file(&mci->dev, &dev_attr_inject_enable);\r\nif (!pvt->is_registered) {\r\nput_device(pvt->chancounts_dev);\r\ndevice_del(pvt->chancounts_dev);\r\n}\r\nput_device(pvt->addrmatch_dev);\r\ndevice_del(pvt->addrmatch_dev);\r\n}\r\nstatic void i7core_put_devices(struct i7core_dev *i7core_dev)\r\n{\r\nint i;\r\nedac_dbg(0, "\n");\r\nfor (i = 0; i < i7core_dev->n_devs; i++) {\r\nstruct pci_dev *pdev = i7core_dev->pdev[i];\r\nif (!pdev)\r\ncontinue;\r\nedac_dbg(0, "Removing dev %02x:%02x.%d\n",\r\npdev->bus->number,\r\nPCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));\r\npci_dev_put(pdev);\r\n}\r\n}\r\nstatic void i7core_put_all_devices(void)\r\n{\r\nstruct i7core_dev *i7core_dev, *tmp;\r\nlist_for_each_entry_safe(i7core_dev, tmp, &i7core_edac_list, list) {\r\ni7core_put_devices(i7core_dev);\r\nfree_i7core_dev(i7core_dev);\r\n}\r\n}\r\nstatic void __init i7core_xeon_pci_fixup(const struct pci_id_table *table)\r\n{\r\nstruct pci_dev *pdev = NULL;\r\nint i;\r\nwhile (table && table->descr) {\r\npdev = pci_get_device(PCI_VENDOR_ID_INTEL, table->descr[0].dev_id, NULL);\r\nif (unlikely(!pdev)) {\r\nfor (i = 0; i < MAX_SOCKET_BUSES; i++)\r\npcibios_scan_specific_bus(255-i);\r\n}\r\npci_dev_put(pdev);\r\ntable++;\r\n}\r\n}\r\nstatic unsigned i7core_pci_lastbus(void)\r\n{\r\nint last_bus = 0, bus;\r\nstruct pci_bus *b = NULL;\r\nwhile ((b = pci_find_next_bus(b)) != NULL) {\r\nbus = b->number;\r\nedac_dbg(0, "Found bus %d\n", bus);\r\nif (bus > last_bus)\r\nlast_bus = bus;\r\n}\r\nedac_dbg(0, "Last bus %d\n", last_bus);\r\nreturn last_bus;\r\n}\r\nstatic int i7core_get_onedevice(struct pci_dev **prev,\r\nconst struct pci_id_table *table,\r\nconst unsigned devno,\r\nconst unsigned last_bus)\r\n{\r\nstruct i7core_dev *i7core_dev;\r\nconst struct pci_id_descr *dev_descr = &table->descr[devno];\r\nstruct pci_dev *pdev = NULL;\r\nu8 bus = 0;\r\nu8 socket = 0;\r\npdev = pci_get_device(PCI_VENDOR_ID_INTEL,\r\ndev_descr->dev_id, *prev);\r\nif (dev_descr->dev_id == PCI_DEVICE_ID_INTEL_I7_NONCORE && !pdev)\r\npdev = pci_get_device(PCI_VENDOR_ID_INTEL,\r\nPCI_DEVICE_ID_INTEL_I7_NONCORE_ALT, *prev);\r\nif (dev_descr->dev_id == PCI_DEVICE_ID_INTEL_LYNNFIELD_NONCORE && !pdev)\r\npdev = pci_get_device(PCI_VENDOR_ID_INTEL,\r\nPCI_DEVICE_ID_INTEL_LYNNFIELD_NONCORE_ALT,\r\n*prev);\r\nif (!pdev) {\r\nif (*prev) {\r\n*prev = pdev;\r\nreturn 0;\r\n}\r\nif (dev_descr->optional)\r\nreturn 0;\r\nif (devno == 0)\r\nreturn -ENODEV;\r\ni7core_printk(KERN_INFO,\r\n"Device not found: dev %02x.%d PCI ID %04x:%04x\n",\r\ndev_descr->dev, dev_descr->func,\r\nPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\r\nreturn -ENODEV;\r\n}\r\nbus = pdev->bus->number;\r\nsocket = last_bus - bus;\r\ni7core_dev = get_i7core_dev(socket);\r\nif (!i7core_dev) {\r\ni7core_dev = alloc_i7core_dev(socket, table);\r\nif (!i7core_dev) {\r\npci_dev_put(pdev);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nif (i7core_dev->pdev[devno]) {\r\ni7core_printk(KERN_ERR,\r\n"Duplicated device for "\r\n"dev %02x:%02x.%d PCI ID %04x:%04x\n",\r\nbus, dev_descr->dev, dev_descr->func,\r\nPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\r\npci_dev_put(pdev);\r\nreturn -ENODEV;\r\n}\r\ni7core_dev->pdev[devno] = pdev;\r\nif (unlikely(PCI_SLOT(pdev->devfn) != dev_descr->dev ||\r\nPCI_FUNC(pdev->devfn) != dev_descr->func)) {\r\ni7core_printk(KERN_ERR,\r\n"Device PCI ID %04x:%04x "\r\n"has dev %02x:%02x.%d instead of dev %02x:%02x.%d\n",\r\nPCI_VENDOR_ID_INTEL, dev_descr->dev_id,\r\nbus, PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn),\r\nbus, dev_descr->dev, dev_descr->func);\r\nreturn -ENODEV;\r\n}\r\nif (unlikely(pci_enable_device(pdev) < 0)) {\r\ni7core_printk(KERN_ERR,\r\n"Couldn't enable "\r\n"dev %02x:%02x.%d PCI ID %04x:%04x\n",\r\nbus, dev_descr->dev, dev_descr->func,\r\nPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\r\nreturn -ENODEV;\r\n}\r\nedac_dbg(0, "Detected socket %d dev %02x:%02x.%d PCI ID %04x:%04x\n",\r\nsocket, bus, dev_descr->dev,\r\ndev_descr->func,\r\nPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\r\npci_dev_get(pdev);\r\n*prev = pdev;\r\nreturn 0;\r\n}\r\nstatic int i7core_get_all_devices(void)\r\n{\r\nint i, rc, last_bus;\r\nstruct pci_dev *pdev = NULL;\r\nconst struct pci_id_table *table = pci_dev_table;\r\nlast_bus = i7core_pci_lastbus();\r\nwhile (table && table->descr) {\r\nfor (i = 0; i < table->n_devs; i++) {\r\npdev = NULL;\r\ndo {\r\nrc = i7core_get_onedevice(&pdev, table, i,\r\nlast_bus);\r\nif (rc < 0) {\r\nif (i == 0) {\r\ni = table->n_devs;\r\nbreak;\r\n}\r\ni7core_put_all_devices();\r\nreturn -ENODEV;\r\n}\r\n} while (pdev);\r\n}\r\ntable++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int mci_bind_devs(struct mem_ctl_info *mci,\r\nstruct i7core_dev *i7core_dev)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nstruct pci_dev *pdev;\r\nint i, func, slot;\r\nchar *family;\r\npvt->is_registered = false;\r\npvt->enable_scrub = false;\r\nfor (i = 0; i < i7core_dev->n_devs; i++) {\r\npdev = i7core_dev->pdev[i];\r\nif (!pdev)\r\ncontinue;\r\nfunc = PCI_FUNC(pdev->devfn);\r\nslot = PCI_SLOT(pdev->devfn);\r\nif (slot == 3) {\r\nif (unlikely(func > MAX_MCR_FUNC))\r\ngoto error;\r\npvt->pci_mcr[func] = pdev;\r\n} else if (likely(slot >= 4 && slot < 4 + NUM_CHANS)) {\r\nif (unlikely(func > MAX_CHAN_FUNC))\r\ngoto error;\r\npvt->pci_ch[slot - 4][func] = pdev;\r\n} else if (!slot && !func) {\r\npvt->pci_noncore = pdev;\r\nswitch (pdev->device) {\r\ncase PCI_DEVICE_ID_INTEL_I7_NONCORE:\r\nfamily = "Xeon 35xx/ i7core";\r\npvt->enable_scrub = false;\r\nbreak;\r\ncase PCI_DEVICE_ID_INTEL_LYNNFIELD_NONCORE_ALT:\r\nfamily = "i7-800/i5-700";\r\npvt->enable_scrub = false;\r\nbreak;\r\ncase PCI_DEVICE_ID_INTEL_LYNNFIELD_NONCORE:\r\nfamily = "Xeon 34xx";\r\npvt->enable_scrub = false;\r\nbreak;\r\ncase PCI_DEVICE_ID_INTEL_I7_NONCORE_ALT:\r\nfamily = "Xeon 55xx";\r\npvt->enable_scrub = true;\r\nbreak;\r\ncase PCI_DEVICE_ID_INTEL_LYNNFIELD_NONCORE_REV2:\r\nfamily = "Xeon 56xx / i7-900";\r\npvt->enable_scrub = true;\r\nbreak;\r\ndefault:\r\nfamily = "unknown";\r\npvt->enable_scrub = false;\r\n}\r\nedac_dbg(0, "Detected a processor type %s\n", family);\r\n} else\r\ngoto error;\r\nedac_dbg(0, "Associated fn %d.%d, dev = %p, socket %d\n",\r\nPCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn),\r\npdev, i7core_dev->socket);\r\nif (PCI_SLOT(pdev->devfn) == 3 &&\r\nPCI_FUNC(pdev->devfn) == 2)\r\npvt->is_registered = true;\r\n}\r\nreturn 0;\r\nerror:\r\ni7core_printk(KERN_ERR, "Device %d, function %d "\r\n"is out of the expected range\n",\r\nslot, func);\r\nreturn -EINVAL;\r\n}\r\nstatic void i7core_rdimm_update_ce_count(struct mem_ctl_info *mci,\r\nconst int chan,\r\nconst int new0,\r\nconst int new1,\r\nconst int new2)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nint add0 = 0, add1 = 0, add2 = 0;\r\nif (pvt->ce_count_available) {\r\nadd2 = new2 - pvt->rdimm_last_ce_count[chan][2];\r\nadd1 = new1 - pvt->rdimm_last_ce_count[chan][1];\r\nadd0 = new0 - pvt->rdimm_last_ce_count[chan][0];\r\nif (add2 < 0)\r\nadd2 += 0x7fff;\r\npvt->rdimm_ce_count[chan][2] += add2;\r\nif (add1 < 0)\r\nadd1 += 0x7fff;\r\npvt->rdimm_ce_count[chan][1] += add1;\r\nif (add0 < 0)\r\nadd0 += 0x7fff;\r\npvt->rdimm_ce_count[chan][0] += add0;\r\n} else\r\npvt->ce_count_available = 1;\r\npvt->rdimm_last_ce_count[chan][2] = new2;\r\npvt->rdimm_last_ce_count[chan][1] = new1;\r\npvt->rdimm_last_ce_count[chan][0] = new0;\r\nif (add0 != 0)\r\nedac_mc_handle_error(HW_EVENT_ERR_CORRECTED, mci, add0,\r\n0, 0, 0,\r\nchan, 0, -1, "error", "");\r\nif (add1 != 0)\r\nedac_mc_handle_error(HW_EVENT_ERR_CORRECTED, mci, add1,\r\n0, 0, 0,\r\nchan, 1, -1, "error", "");\r\nif (add2 != 0)\r\nedac_mc_handle_error(HW_EVENT_ERR_CORRECTED, mci, add2,\r\n0, 0, 0,\r\nchan, 2, -1, "error", "");\r\n}\r\nstatic void i7core_rdimm_check_mc_ecc_err(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nu32 rcv[3][2];\r\nint i, new0, new1, new2;\r\npci_read_config_dword(pvt->pci_mcr[2], MC_COR_ECC_CNT_0,\r\n&rcv[0][0]);\r\npci_read_config_dword(pvt->pci_mcr[2], MC_COR_ECC_CNT_1,\r\n&rcv[0][1]);\r\npci_read_config_dword(pvt->pci_mcr[2], MC_COR_ECC_CNT_2,\r\n&rcv[1][0]);\r\npci_read_config_dword(pvt->pci_mcr[2], MC_COR_ECC_CNT_3,\r\n&rcv[1][1]);\r\npci_read_config_dword(pvt->pci_mcr[2], MC_COR_ECC_CNT_4,\r\n&rcv[2][0]);\r\npci_read_config_dword(pvt->pci_mcr[2], MC_COR_ECC_CNT_5,\r\n&rcv[2][1]);\r\nfor (i = 0 ; i < 3; i++) {\r\nedac_dbg(3, "MC_COR_ECC_CNT%d = 0x%x; MC_COR_ECC_CNT%d = 0x%x\n",\r\n(i * 2), rcv[i][0], (i * 2) + 1, rcv[i][1]);\r\nif (pvt->channel[i].dimms > 2) {\r\nnew0 = DIMM_BOT_COR_ERR(rcv[i][0]);\r\nnew1 = DIMM_TOP_COR_ERR(rcv[i][0]);\r\nnew2 = DIMM_BOT_COR_ERR(rcv[i][1]);\r\n} else {\r\nnew0 = DIMM_TOP_COR_ERR(rcv[i][0]) +\r\nDIMM_BOT_COR_ERR(rcv[i][0]);\r\nnew1 = DIMM_TOP_COR_ERR(rcv[i][1]) +\r\nDIMM_BOT_COR_ERR(rcv[i][1]);\r\nnew2 = 0;\r\n}\r\ni7core_rdimm_update_ce_count(mci, i, new0, new1, new2);\r\n}\r\n}\r\nstatic void i7core_udimm_check_mc_ecc_err(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nu32 rcv1, rcv0;\r\nint new0, new1, new2;\r\nif (!pvt->pci_mcr[4]) {\r\nedac_dbg(0, "MCR registers not found\n");\r\nreturn;\r\n}\r\npci_read_config_dword(pvt->pci_mcr[4], MC_TEST_ERR_RCV1, &rcv1);\r\npci_read_config_dword(pvt->pci_mcr[4], MC_TEST_ERR_RCV0, &rcv0);\r\nnew2 = DIMM2_COR_ERR(rcv1);\r\nnew1 = DIMM1_COR_ERR(rcv0);\r\nnew0 = DIMM0_COR_ERR(rcv0);\r\nif (pvt->ce_count_available) {\r\nint add0, add1, add2;\r\nadd2 = new2 - pvt->udimm_last_ce_count[2];\r\nadd1 = new1 - pvt->udimm_last_ce_count[1];\r\nadd0 = new0 - pvt->udimm_last_ce_count[0];\r\nif (add2 < 0)\r\nadd2 += 0x7fff;\r\npvt->udimm_ce_count[2] += add2;\r\nif (add1 < 0)\r\nadd1 += 0x7fff;\r\npvt->udimm_ce_count[1] += add1;\r\nif (add0 < 0)\r\nadd0 += 0x7fff;\r\npvt->udimm_ce_count[0] += add0;\r\nif (add0 | add1 | add2)\r\ni7core_printk(KERN_ERR, "New Corrected error(s): "\r\n"dimm0: +%d, dimm1: +%d, dimm2 +%d\n",\r\nadd0, add1, add2);\r\n} else\r\npvt->ce_count_available = 1;\r\npvt->udimm_last_ce_count[2] = new2;\r\npvt->udimm_last_ce_count[1] = new1;\r\npvt->udimm_last_ce_count[0] = new0;\r\n}\r\nstatic void i7core_mce_output_error(struct mem_ctl_info *mci,\r\nconst struct mce *m)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nchar *type, *optype, *err;\r\nenum hw_event_mc_err_type tp_event;\r\nunsigned long error = m->status & 0x1ff0000l;\r\nbool uncorrected_error = m->mcgstatus & 1ll << 61;\r\nbool ripv = m->mcgstatus & 1;\r\nu32 optypenum = (m->status >> 4) & 0x07;\r\nu32 core_err_cnt = (m->status >> 38) & 0x7fff;\r\nu32 dimm = (m->misc >> 16) & 0x3;\r\nu32 channel = (m->misc >> 18) & 0x3;\r\nu32 syndrome = m->misc >> 32;\r\nu32 errnum = find_first_bit(&error, 32);\r\nif (uncorrected_error) {\r\nif (ripv) {\r\ntype = "FATAL";\r\ntp_event = HW_EVENT_ERR_FATAL;\r\n} else {\r\ntype = "NON_FATAL";\r\ntp_event = HW_EVENT_ERR_UNCORRECTED;\r\n}\r\n} else {\r\ntype = "CORRECTED";\r\ntp_event = HW_EVENT_ERR_CORRECTED;\r\n}\r\nswitch (optypenum) {\r\ncase 0:\r\noptype = "generic undef request";\r\nbreak;\r\ncase 1:\r\noptype = "read error";\r\nbreak;\r\ncase 2:\r\noptype = "write error";\r\nbreak;\r\ncase 3:\r\noptype = "addr/cmd error";\r\nbreak;\r\ncase 4:\r\noptype = "scrubbing error";\r\nbreak;\r\ndefault:\r\noptype = "reserved";\r\nbreak;\r\n}\r\nswitch (errnum) {\r\ncase 16:\r\nerr = "read ECC error";\r\nbreak;\r\ncase 17:\r\nerr = "RAS ECC error";\r\nbreak;\r\ncase 18:\r\nerr = "write parity error";\r\nbreak;\r\ncase 19:\r\nerr = "redundacy loss";\r\nbreak;\r\ncase 20:\r\nerr = "reserved";\r\nbreak;\r\ncase 21:\r\nerr = "memory range error";\r\nbreak;\r\ncase 22:\r\nerr = "RTID out of range";\r\nbreak;\r\ncase 23:\r\nerr = "address parity error";\r\nbreak;\r\ncase 24:\r\nerr = "byte enable parity error";\r\nbreak;\r\ndefault:\r\nerr = "unknown";\r\n}\r\nif (uncorrected_error || !pvt->is_registered)\r\nedac_mc_handle_error(tp_event, mci, core_err_cnt,\r\nm->addr >> PAGE_SHIFT,\r\nm->addr & ~PAGE_MASK,\r\nsyndrome,\r\nchannel, dimm, -1,\r\nerr, optype);\r\n}\r\nstatic void i7core_check_error(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nint i;\r\nunsigned count = 0;\r\nstruct mce *m;\r\nsmp_rmb();\r\ncount = (pvt->mce_out + MCE_LOG_LEN - pvt->mce_in)\r\n% MCE_LOG_LEN;\r\nif (!count)\r\ngoto check_ce_error;\r\nm = pvt->mce_outentry;\r\nif (pvt->mce_in + count > MCE_LOG_LEN) {\r\nunsigned l = MCE_LOG_LEN - pvt->mce_in;\r\nmemcpy(m, &pvt->mce_entry[pvt->mce_in], sizeof(*m) * l);\r\nsmp_wmb();\r\npvt->mce_in = 0;\r\ncount -= l;\r\nm += l;\r\n}\r\nmemcpy(m, &pvt->mce_entry[pvt->mce_in], sizeof(*m) * count);\r\nsmp_wmb();\r\npvt->mce_in += count;\r\nsmp_rmb();\r\nif (pvt->mce_overrun) {\r\ni7core_printk(KERN_ERR, "Lost %d memory errors\n",\r\npvt->mce_overrun);\r\nsmp_wmb();\r\npvt->mce_overrun = 0;\r\n}\r\nfor (i = 0; i < count; i++)\r\ni7core_mce_output_error(mci, &pvt->mce_outentry[i]);\r\ncheck_ce_error:\r\nif (!pvt->is_registered)\r\ni7core_udimm_check_mc_ecc_err(mci);\r\nelse\r\ni7core_rdimm_check_mc_ecc_err(mci);\r\n}\r\nstatic int i7core_mce_check_error(struct notifier_block *nb, unsigned long val,\r\nvoid *data)\r\n{\r\nstruct mce *mce = (struct mce *)data;\r\nstruct i7core_dev *i7_dev;\r\nstruct mem_ctl_info *mci;\r\nstruct i7core_pvt *pvt;\r\ni7_dev = get_i7core_dev(mce->socketid);\r\nif (!i7_dev)\r\nreturn NOTIFY_BAD;\r\nmci = i7_dev->mci;\r\npvt = mci->pvt_info;\r\nif (((mce->status & 0xffff) >> 7) != 1)\r\nreturn NOTIFY_DONE;\r\nif (mce->bank != 8)\r\nreturn NOTIFY_DONE;\r\nsmp_rmb();\r\nif ((pvt->mce_out + 1) % MCE_LOG_LEN == pvt->mce_in) {\r\nsmp_wmb();\r\npvt->mce_overrun++;\r\nreturn NOTIFY_DONE;\r\n}\r\nmemcpy(&pvt->mce_entry[pvt->mce_out], mce, sizeof(*mce));\r\nsmp_wmb();\r\npvt->mce_out = (pvt->mce_out + 1) % MCE_LOG_LEN;\r\nif (mce->mcgstatus & 1)\r\ni7core_check_error(mci);\r\nreturn NOTIFY_STOP;\r\n}\r\nstatic void decode_dclk(const struct dmi_header *dh, void *_dclk_freq)\r\n{\r\nint *dclk_freq = _dclk_freq;\r\nu16 dmi_mem_clk_speed;\r\nif (*dclk_freq == -1)\r\nreturn;\r\nif (dh->type == DMI_ENTRY_MEM_DEVICE) {\r\nstruct memdev_dmi_entry *memdev_dmi_entry =\r\n(struct memdev_dmi_entry *)dh;\r\nunsigned long conf_mem_clk_speed_offset =\r\n(unsigned long)&memdev_dmi_entry->conf_mem_clk_speed -\r\n(unsigned long)&memdev_dmi_entry->type;\r\nunsigned long speed_offset =\r\n(unsigned long)&memdev_dmi_entry->speed -\r\n(unsigned long)&memdev_dmi_entry->type;\r\nif (memdev_dmi_entry->size == 0)\r\nreturn;\r\nif (memdev_dmi_entry->length > conf_mem_clk_speed_offset) {\r\ndmi_mem_clk_speed =\r\nmemdev_dmi_entry->conf_mem_clk_speed;\r\n} else if (memdev_dmi_entry->length > speed_offset) {\r\ndmi_mem_clk_speed = memdev_dmi_entry->speed;\r\n} else {\r\n*dclk_freq = -1;\r\nreturn;\r\n}\r\nif (*dclk_freq == 0) {\r\nif (dmi_mem_clk_speed > 0) {\r\n*dclk_freq = dmi_mem_clk_speed;\r\n} else {\r\n*dclk_freq = -1;\r\n}\r\n} else if (*dclk_freq > 0 &&\r\n*dclk_freq != dmi_mem_clk_speed) {\r\n*dclk_freq = -1;\r\n}\r\n}\r\n}\r\nstatic int get_dclk_freq(void)\r\n{\r\nint dclk_freq = 0;\r\ndmi_walk(decode_dclk, (void *)&dclk_freq);\r\nif (dclk_freq < 1)\r\nreturn DEFAULT_DCLK_FREQ;\r\nreturn dclk_freq;\r\n}\r\nstatic int set_sdram_scrub_rate(struct mem_ctl_info *mci, u32 new_bw)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nstruct pci_dev *pdev;\r\nu32 dw_scrub;\r\nu32 dw_ssr;\r\npdev = pvt->pci_mcr[2];\r\nif (!pdev)\r\nreturn -ENODEV;\r\npci_read_config_dword(pdev, MC_SCRUB_CONTROL, &dw_scrub);\r\nif (new_bw == 0) {\r\ndw_scrub &= ~STARTSCRUB;\r\nwrite_and_test(pdev, MC_SCRUB_CONTROL,\r\ndw_scrub & ~SCRUBINTERVAL_MASK);\r\npci_read_config_dword(pdev, MC_SSRCONTROL, &dw_ssr);\r\ndw_ssr &= ~SSR_MODE_MASK;\r\ndw_ssr |= SSR_MODE_DISABLE;\r\n} else {\r\nconst int cache_line_size = 64;\r\nconst u32 freq_dclk_mhz = pvt->dclk_freq;\r\nunsigned long long scrub_interval;\r\nscrub_interval = (unsigned long long)freq_dclk_mhz *\r\ncache_line_size * 1000000;\r\ndo_div(scrub_interval, new_bw);\r\nif (!scrub_interval || scrub_interval > SCRUBINTERVAL_MASK)\r\nreturn -EINVAL;\r\ndw_scrub = SCRUBINTERVAL_MASK & scrub_interval;\r\npci_write_config_dword(pdev, MC_SCRUB_CONTROL,\r\nSTARTSCRUB | dw_scrub);\r\npci_read_config_dword(pdev, MC_SSRCONTROL, &dw_ssr);\r\ndw_ssr &= ~SSR_MODE_MASK;\r\ndw_ssr |= SSR_MODE_ENABLE;\r\n}\r\npci_write_config_dword(pdev, MC_SSRCONTROL, dw_ssr);\r\nreturn new_bw;\r\n}\r\nstatic int get_sdram_scrub_rate(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nstruct pci_dev *pdev;\r\nconst u32 cache_line_size = 64;\r\nconst u32 freq_dclk_mhz = pvt->dclk_freq;\r\nunsigned long long scrub_rate;\r\nu32 scrubval;\r\npdev = pvt->pci_mcr[2];\r\nif (!pdev)\r\nreturn -ENODEV;\r\npci_read_config_dword(pdev, MC_SCRUB_CONTROL, &scrubval);\r\nscrubval &= SCRUBINTERVAL_MASK;\r\nif (!scrubval)\r\nreturn 0;\r\nscrub_rate = (unsigned long long)freq_dclk_mhz *\r\n1000000 * cache_line_size;\r\ndo_div(scrub_rate, scrubval);\r\nreturn (int)scrub_rate;\r\n}\r\nstatic void enable_sdram_scrub_setting(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nu32 pci_lock;\r\npci_read_config_dword(pvt->pci_noncore, MC_CFG_CONTROL, &pci_lock);\r\npci_lock &= ~0x3;\r\npci_write_config_dword(pvt->pci_noncore, MC_CFG_CONTROL,\r\npci_lock | MC_CFG_UNLOCK);\r\nmci->set_sdram_scrub_rate = set_sdram_scrub_rate;\r\nmci->get_sdram_scrub_rate = get_sdram_scrub_rate;\r\n}\r\nstatic void disable_sdram_scrub_setting(struct mem_ctl_info *mci)\r\n{\r\nstruct i7core_pvt *pvt = mci->pvt_info;\r\nu32 pci_lock;\r\npci_read_config_dword(pvt->pci_noncore, MC_CFG_CONTROL, &pci_lock);\r\npci_lock &= ~0x3;\r\npci_write_config_dword(pvt->pci_noncore, MC_CFG_CONTROL,\r\npci_lock | MC_CFG_LOCK);\r\n}\r\nstatic void i7core_pci_ctl_create(struct i7core_pvt *pvt)\r\n{\r\npvt->i7core_pci = edac_pci_create_generic_ctl(\r\n&pvt->i7core_dev->pdev[0]->dev,\r\nEDAC_MOD_STR);\r\nif (unlikely(!pvt->i7core_pci))\r\ni7core_printk(KERN_WARNING,\r\n"Unable to setup PCI error report via EDAC\n");\r\n}\r\nstatic void i7core_pci_ctl_release(struct i7core_pvt *pvt)\r\n{\r\nif (likely(pvt->i7core_pci))\r\nedac_pci_release_generic_ctl(pvt->i7core_pci);\r\nelse\r\ni7core_printk(KERN_ERR,\r\n"Couldn't find mem_ctl_info for socket %d\n",\r\npvt->i7core_dev->socket);\r\npvt->i7core_pci = NULL;\r\n}\r\nstatic void i7core_unregister_mci(struct i7core_dev *i7core_dev)\r\n{\r\nstruct mem_ctl_info *mci = i7core_dev->mci;\r\nstruct i7core_pvt *pvt;\r\nif (unlikely(!mci || !mci->pvt_info)) {\r\nedac_dbg(0, "MC: dev = %p\n", &i7core_dev->pdev[0]->dev);\r\ni7core_printk(KERN_ERR, "Couldn't find mci handler\n");\r\nreturn;\r\n}\r\npvt = mci->pvt_info;\r\nedac_dbg(0, "MC: mci = %p, dev = %p\n", mci, &i7core_dev->pdev[0]->dev);\r\nif (pvt->enable_scrub)\r\ndisable_sdram_scrub_setting(mci);\r\ni7core_pci_ctl_release(pvt);\r\ni7core_delete_sysfs_devices(mci);\r\nedac_mc_del_mc(mci->pdev);\r\nedac_dbg(1, "%s: free mci struct\n", mci->ctl_name);\r\nkfree(mci->ctl_name);\r\nedac_mc_free(mci);\r\ni7core_dev->mci = NULL;\r\n}\r\nstatic int i7core_register_mci(struct i7core_dev *i7core_dev)\r\n{\r\nstruct mem_ctl_info *mci;\r\nstruct i7core_pvt *pvt;\r\nint rc;\r\nstruct edac_mc_layer layers[2];\r\nlayers[0].type = EDAC_MC_LAYER_CHANNEL;\r\nlayers[0].size = NUM_CHANS;\r\nlayers[0].is_virt_csrow = false;\r\nlayers[1].type = EDAC_MC_LAYER_SLOT;\r\nlayers[1].size = MAX_DIMMS;\r\nlayers[1].is_virt_csrow = true;\r\nmci = edac_mc_alloc(i7core_dev->socket, ARRAY_SIZE(layers), layers,\r\nsizeof(*pvt));\r\nif (unlikely(!mci))\r\nreturn -ENOMEM;\r\nedac_dbg(0, "MC: mci = %p, dev = %p\n", mci, &i7core_dev->pdev[0]->dev);\r\npvt = mci->pvt_info;\r\nmemset(pvt, 0, sizeof(*pvt));\r\npvt->i7core_dev = i7core_dev;\r\ni7core_dev->mci = mci;\r\nmci->mtype_cap = MEM_FLAG_DDR3;\r\nmci->edac_ctl_cap = EDAC_FLAG_NONE;\r\nmci->edac_cap = EDAC_FLAG_NONE;\r\nmci->mod_name = "i7core_edac.c";\r\nmci->mod_ver = I7CORE_REVISION;\r\nmci->ctl_name = kasprintf(GFP_KERNEL, "i7 core #%d",\r\ni7core_dev->socket);\r\nmci->dev_name = pci_name(i7core_dev->pdev[0]);\r\nmci->ctl_page_to_phys = NULL;\r\nrc = mci_bind_devs(mci, i7core_dev);\r\nif (unlikely(rc < 0))\r\ngoto fail0;\r\nget_dimm_config(mci);\r\nmci->pdev = &i7core_dev->pdev[0]->dev;\r\nmci->edac_check = i7core_check_error;\r\nif (pvt->enable_scrub)\r\nenable_sdram_scrub_setting(mci);\r\nif (unlikely(edac_mc_add_mc(mci))) {\r\nedac_dbg(0, "MC: failed edac_mc_add_mc()\n");\r\nrc = -EINVAL;\r\ngoto fail0;\r\n}\r\nif (i7core_create_sysfs_devices(mci)) {\r\nedac_dbg(0, "MC: failed to create sysfs nodes\n");\r\nedac_mc_del_mc(mci->pdev);\r\nrc = -EINVAL;\r\ngoto fail0;\r\n}\r\npvt->inject.channel = 0;\r\npvt->inject.dimm = -1;\r\npvt->inject.rank = -1;\r\npvt->inject.bank = -1;\r\npvt->inject.page = -1;\r\npvt->inject.col = -1;\r\ni7core_pci_ctl_create(pvt);\r\npvt->dclk_freq = get_dclk_freq();\r\nreturn 0;\r\nfail0:\r\nkfree(mci->ctl_name);\r\nedac_mc_free(mci);\r\ni7core_dev->mci = NULL;\r\nreturn rc;\r\n}\r\nstatic int i7core_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nint rc, count = 0;\r\nstruct i7core_dev *i7core_dev;\r\nmutex_lock(&i7core_edac_lock);\r\nif (unlikely(probed >= 1)) {\r\nmutex_unlock(&i7core_edac_lock);\r\nreturn -ENODEV;\r\n}\r\nprobed++;\r\nrc = i7core_get_all_devices();\r\nif (unlikely(rc < 0))\r\ngoto fail0;\r\nlist_for_each_entry(i7core_dev, &i7core_edac_list, list) {\r\ncount++;\r\nrc = i7core_register_mci(i7core_dev);\r\nif (unlikely(rc < 0))\r\ngoto fail1;\r\n}\r\nif (!count) {\r\nrc = -ENODEV;\r\ngoto fail1;\r\n}\r\ni7core_printk(KERN_INFO,\r\n"Driver loaded, %d memory controller(s) found.\n",\r\ncount);\r\nmutex_unlock(&i7core_edac_lock);\r\nreturn 0;\r\nfail1:\r\nlist_for_each_entry(i7core_dev, &i7core_edac_list, list)\r\ni7core_unregister_mci(i7core_dev);\r\ni7core_put_all_devices();\r\nfail0:\r\nmutex_unlock(&i7core_edac_lock);\r\nreturn rc;\r\n}\r\nstatic void i7core_remove(struct pci_dev *pdev)\r\n{\r\nstruct i7core_dev *i7core_dev;\r\nedac_dbg(0, "\n");\r\nmutex_lock(&i7core_edac_lock);\r\nif (unlikely(!probed)) {\r\nmutex_unlock(&i7core_edac_lock);\r\nreturn;\r\n}\r\nlist_for_each_entry(i7core_dev, &i7core_edac_list, list)\r\ni7core_unregister_mci(i7core_dev);\r\ni7core_put_all_devices();\r\nprobed--;\r\nmutex_unlock(&i7core_edac_lock);\r\n}\r\nstatic int __init i7core_init(void)\r\n{\r\nint pci_rc;\r\nedac_dbg(2, "\n");\r\nopstate_init();\r\nif (use_pci_fixup)\r\ni7core_xeon_pci_fixup(pci_dev_table);\r\npci_rc = pci_register_driver(&i7core_driver);\r\nif (pci_rc >= 0) {\r\nmce_register_decode_chain(&i7_mce_dec);\r\nreturn 0;\r\n}\r\ni7core_printk(KERN_ERR, "Failed to register device with error %d.\n",\r\npci_rc);\r\nreturn pci_rc;\r\n}\r\nstatic void __exit i7core_exit(void)\r\n{\r\nedac_dbg(2, "\n");\r\npci_unregister_driver(&i7core_driver);\r\nmce_unregister_decode_chain(&i7_mce_dec);\r\n}
