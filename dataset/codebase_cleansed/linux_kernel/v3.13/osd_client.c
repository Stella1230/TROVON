static int calc_layout(struct ceph_file_layout *layout, u64 off, u64 *plen,\r\nu64 *objnum, u64 *objoff, u64 *objlen)\r\n{\r\nu64 orig_len = *plen;\r\nint r;\r\nr = ceph_calc_file_object_mapping(layout, off, orig_len, objnum,\r\nobjoff, objlen);\r\nif (r < 0)\r\nreturn r;\r\nif (*objlen < orig_len) {\r\n*plen = *objlen;\r\ndout(" skipping last %llu, final file extent %llu~%llu\n",\r\norig_len - *plen, off, *plen);\r\n}\r\ndout("calc_layout objnum=%llx %llu~%llu\n", *objnum, *objoff, *objlen);\r\nreturn 0;\r\n}\r\nstatic void ceph_osd_data_init(struct ceph_osd_data *osd_data)\r\n{\r\nmemset(osd_data, 0, sizeof (*osd_data));\r\nosd_data->type = CEPH_OSD_DATA_TYPE_NONE;\r\n}\r\nstatic void ceph_osd_data_pages_init(struct ceph_osd_data *osd_data,\r\nstruct page **pages, u64 length, u32 alignment,\r\nbool pages_from_pool, bool own_pages)\r\n{\r\nosd_data->type = CEPH_OSD_DATA_TYPE_PAGES;\r\nosd_data->pages = pages;\r\nosd_data->length = length;\r\nosd_data->alignment = alignment;\r\nosd_data->pages_from_pool = pages_from_pool;\r\nosd_data->own_pages = own_pages;\r\n}\r\nstatic void ceph_osd_data_pagelist_init(struct ceph_osd_data *osd_data,\r\nstruct ceph_pagelist *pagelist)\r\n{\r\nosd_data->type = CEPH_OSD_DATA_TYPE_PAGELIST;\r\nosd_data->pagelist = pagelist;\r\n}\r\nstatic void ceph_osd_data_bio_init(struct ceph_osd_data *osd_data,\r\nstruct bio *bio, size_t bio_length)\r\n{\r\nosd_data->type = CEPH_OSD_DATA_TYPE_BIO;\r\nosd_data->bio = bio;\r\nosd_data->bio_length = bio_length;\r\n}\r\nstatic struct ceph_osd_data *\r\nosd_req_op_raw_data_in(struct ceph_osd_request *osd_req, unsigned int which)\r\n{\r\nBUG_ON(which >= osd_req->r_num_ops);\r\nreturn &osd_req->r_ops[which].raw_data_in;\r\n}\r\nstruct ceph_osd_data *\r\nosd_req_op_extent_osd_data(struct ceph_osd_request *osd_req,\r\nunsigned int which)\r\n{\r\nreturn osd_req_op_data(osd_req, which, extent, osd_data);\r\n}\r\nstruct ceph_osd_data *\r\nosd_req_op_cls_response_data(struct ceph_osd_request *osd_req,\r\nunsigned int which)\r\n{\r\nreturn osd_req_op_data(osd_req, which, cls, response_data);\r\n}\r\nvoid osd_req_op_raw_data_in_pages(struct ceph_osd_request *osd_req,\r\nunsigned int which, struct page **pages,\r\nu64 length, u32 alignment,\r\nbool pages_from_pool, bool own_pages)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_raw_data_in(osd_req, which);\r\nceph_osd_data_pages_init(osd_data, pages, length, alignment,\r\npages_from_pool, own_pages);\r\n}\r\nvoid osd_req_op_extent_osd_data_pages(struct ceph_osd_request *osd_req,\r\nunsigned int which, struct page **pages,\r\nu64 length, u32 alignment,\r\nbool pages_from_pool, bool own_pages)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_data(osd_req, which, extent, osd_data);\r\nceph_osd_data_pages_init(osd_data, pages, length, alignment,\r\npages_from_pool, own_pages);\r\n}\r\nvoid osd_req_op_extent_osd_data_pagelist(struct ceph_osd_request *osd_req,\r\nunsigned int which, struct ceph_pagelist *pagelist)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_data(osd_req, which, extent, osd_data);\r\nceph_osd_data_pagelist_init(osd_data, pagelist);\r\n}\r\nvoid osd_req_op_extent_osd_data_bio(struct ceph_osd_request *osd_req,\r\nunsigned int which, struct bio *bio, size_t bio_length)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_data(osd_req, which, extent, osd_data);\r\nceph_osd_data_bio_init(osd_data, bio, bio_length);\r\n}\r\nstatic void osd_req_op_cls_request_info_pagelist(\r\nstruct ceph_osd_request *osd_req,\r\nunsigned int which, struct ceph_pagelist *pagelist)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_data(osd_req, which, cls, request_info);\r\nceph_osd_data_pagelist_init(osd_data, pagelist);\r\n}\r\nvoid osd_req_op_cls_request_data_pagelist(\r\nstruct ceph_osd_request *osd_req,\r\nunsigned int which, struct ceph_pagelist *pagelist)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_data(osd_req, which, cls, request_data);\r\nceph_osd_data_pagelist_init(osd_data, pagelist);\r\n}\r\nvoid osd_req_op_cls_request_data_pages(struct ceph_osd_request *osd_req,\r\nunsigned int which, struct page **pages, u64 length,\r\nu32 alignment, bool pages_from_pool, bool own_pages)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_data(osd_req, which, cls, request_data);\r\nceph_osd_data_pages_init(osd_data, pages, length, alignment,\r\npages_from_pool, own_pages);\r\n}\r\nvoid osd_req_op_cls_response_data_pages(struct ceph_osd_request *osd_req,\r\nunsigned int which, struct page **pages, u64 length,\r\nu32 alignment, bool pages_from_pool, bool own_pages)\r\n{\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_data(osd_req, which, cls, response_data);\r\nceph_osd_data_pages_init(osd_data, pages, length, alignment,\r\npages_from_pool, own_pages);\r\n}\r\nstatic u64 ceph_osd_data_length(struct ceph_osd_data *osd_data)\r\n{\r\nswitch (osd_data->type) {\r\ncase CEPH_OSD_DATA_TYPE_NONE:\r\nreturn 0;\r\ncase CEPH_OSD_DATA_TYPE_PAGES:\r\nreturn osd_data->length;\r\ncase CEPH_OSD_DATA_TYPE_PAGELIST:\r\nreturn (u64)osd_data->pagelist->length;\r\n#ifdef CONFIG_BLOCK\r\ncase CEPH_OSD_DATA_TYPE_BIO:\r\nreturn (u64)osd_data->bio_length;\r\n#endif\r\ndefault:\r\nWARN(true, "unrecognized data type %d\n", (int)osd_data->type);\r\nreturn 0;\r\n}\r\n}\r\nstatic void ceph_osd_data_release(struct ceph_osd_data *osd_data)\r\n{\r\nif (osd_data->type == CEPH_OSD_DATA_TYPE_PAGES && osd_data->own_pages) {\r\nint num_pages;\r\nnum_pages = calc_pages_for((u64)osd_data->alignment,\r\n(u64)osd_data->length);\r\nceph_release_page_vector(osd_data->pages, num_pages);\r\n}\r\nceph_osd_data_init(osd_data);\r\n}\r\nstatic void osd_req_op_data_release(struct ceph_osd_request *osd_req,\r\nunsigned int which)\r\n{\r\nstruct ceph_osd_req_op *op;\r\nBUG_ON(which >= osd_req->r_num_ops);\r\nop = &osd_req->r_ops[which];\r\nswitch (op->op) {\r\ncase CEPH_OSD_OP_READ:\r\ncase CEPH_OSD_OP_WRITE:\r\nceph_osd_data_release(&op->extent.osd_data);\r\nbreak;\r\ncase CEPH_OSD_OP_CALL:\r\nceph_osd_data_release(&op->cls.request_info);\r\nceph_osd_data_release(&op->cls.request_data);\r\nceph_osd_data_release(&op->cls.response_data);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nvoid ceph_osdc_release_request(struct kref *kref)\r\n{\r\nstruct ceph_osd_request *req;\r\nunsigned int which;\r\nreq = container_of(kref, struct ceph_osd_request, r_kref);\r\nif (req->r_request)\r\nceph_msg_put(req->r_request);\r\nif (req->r_reply) {\r\nceph_msg_revoke_incoming(req->r_reply);\r\nceph_msg_put(req->r_reply);\r\n}\r\nfor (which = 0; which < req->r_num_ops; which++)\r\nosd_req_op_data_release(req, which);\r\nceph_put_snap_context(req->r_snapc);\r\nif (req->r_mempool)\r\nmempool_free(req, req->r_osdc->req_mempool);\r\nelse\r\nkmem_cache_free(ceph_osd_request_cache, req);\r\n}\r\nstruct ceph_osd_request *ceph_osdc_alloc_request(struct ceph_osd_client *osdc,\r\nstruct ceph_snap_context *snapc,\r\nunsigned int num_ops,\r\nbool use_mempool,\r\ngfp_t gfp_flags)\r\n{\r\nstruct ceph_osd_request *req;\r\nstruct ceph_msg *msg;\r\nsize_t msg_size;\r\nBUILD_BUG_ON(CEPH_OSD_MAX_OP > U16_MAX);\r\nBUG_ON(num_ops > CEPH_OSD_MAX_OP);\r\nmsg_size = 4 + 4 + 8 + 8 + 4+8;\r\nmsg_size += 2 + 4 + 8 + 4 + 4;\r\nmsg_size += 1 + 8 + 4 + 4;\r\nmsg_size += 4 + MAX_OBJ_NAME_SIZE;\r\nmsg_size += 2 + num_ops*sizeof(struct ceph_osd_op);\r\nmsg_size += 8;\r\nmsg_size += 8;\r\nmsg_size += 8 * (snapc ? snapc->num_snaps : 0);\r\nmsg_size += 4;\r\nif (use_mempool) {\r\nreq = mempool_alloc(osdc->req_mempool, gfp_flags);\r\nmemset(req, 0, sizeof(*req));\r\n} else {\r\nreq = kmem_cache_zalloc(ceph_osd_request_cache, gfp_flags);\r\n}\r\nif (req == NULL)\r\nreturn NULL;\r\nreq->r_osdc = osdc;\r\nreq->r_mempool = use_mempool;\r\nreq->r_num_ops = num_ops;\r\nkref_init(&req->r_kref);\r\ninit_completion(&req->r_completion);\r\ninit_completion(&req->r_safe_completion);\r\nRB_CLEAR_NODE(&req->r_node);\r\nINIT_LIST_HEAD(&req->r_unsafe_item);\r\nINIT_LIST_HEAD(&req->r_linger_item);\r\nINIT_LIST_HEAD(&req->r_linger_osd);\r\nINIT_LIST_HEAD(&req->r_req_lru_item);\r\nINIT_LIST_HEAD(&req->r_osd_item);\r\nif (use_mempool)\r\nmsg = ceph_msgpool_get(&osdc->msgpool_op_reply, 0);\r\nelse\r\nmsg = ceph_msg_new(CEPH_MSG_OSD_OPREPLY,\r\nOSD_OPREPLY_FRONT_LEN, gfp_flags, true);\r\nif (!msg) {\r\nceph_osdc_put_request(req);\r\nreturn NULL;\r\n}\r\nreq->r_reply = msg;\r\nif (use_mempool)\r\nmsg = ceph_msgpool_get(&osdc->msgpool_op, 0);\r\nelse\r\nmsg = ceph_msg_new(CEPH_MSG_OSD_OP, msg_size, gfp_flags, true);\r\nif (!msg) {\r\nceph_osdc_put_request(req);\r\nreturn NULL;\r\n}\r\nmemset(msg->front.iov_base, 0, msg->front.iov_len);\r\nreq->r_request = msg;\r\nreturn req;\r\n}\r\nstatic bool osd_req_opcode_valid(u16 opcode)\r\n{\r\nswitch (opcode) {\r\ncase CEPH_OSD_OP_READ:\r\ncase CEPH_OSD_OP_STAT:\r\ncase CEPH_OSD_OP_MAPEXT:\r\ncase CEPH_OSD_OP_MASKTRUNC:\r\ncase CEPH_OSD_OP_SPARSE_READ:\r\ncase CEPH_OSD_OP_NOTIFY:\r\ncase CEPH_OSD_OP_NOTIFY_ACK:\r\ncase CEPH_OSD_OP_ASSERT_VER:\r\ncase CEPH_OSD_OP_WRITE:\r\ncase CEPH_OSD_OP_WRITEFULL:\r\ncase CEPH_OSD_OP_TRUNCATE:\r\ncase CEPH_OSD_OP_ZERO:\r\ncase CEPH_OSD_OP_DELETE:\r\ncase CEPH_OSD_OP_APPEND:\r\ncase CEPH_OSD_OP_STARTSYNC:\r\ncase CEPH_OSD_OP_SETTRUNC:\r\ncase CEPH_OSD_OP_TRIMTRUNC:\r\ncase CEPH_OSD_OP_TMAPUP:\r\ncase CEPH_OSD_OP_TMAPPUT:\r\ncase CEPH_OSD_OP_TMAPGET:\r\ncase CEPH_OSD_OP_CREATE:\r\ncase CEPH_OSD_OP_ROLLBACK:\r\ncase CEPH_OSD_OP_WATCH:\r\ncase CEPH_OSD_OP_OMAPGETKEYS:\r\ncase CEPH_OSD_OP_OMAPGETVALS:\r\ncase CEPH_OSD_OP_OMAPGETHEADER:\r\ncase CEPH_OSD_OP_OMAPGETVALSBYKEYS:\r\ncase CEPH_OSD_OP_OMAPSETVALS:\r\ncase CEPH_OSD_OP_OMAPSETHEADER:\r\ncase CEPH_OSD_OP_OMAPCLEAR:\r\ncase CEPH_OSD_OP_OMAPRMKEYS:\r\ncase CEPH_OSD_OP_OMAP_CMP:\r\ncase CEPH_OSD_OP_CLONERANGE:\r\ncase CEPH_OSD_OP_ASSERT_SRC_VERSION:\r\ncase CEPH_OSD_OP_SRC_CMPXATTR:\r\ncase CEPH_OSD_OP_GETXATTR:\r\ncase CEPH_OSD_OP_GETXATTRS:\r\ncase CEPH_OSD_OP_CMPXATTR:\r\ncase CEPH_OSD_OP_SETXATTR:\r\ncase CEPH_OSD_OP_SETXATTRS:\r\ncase CEPH_OSD_OP_RESETXATTRS:\r\ncase CEPH_OSD_OP_RMXATTR:\r\ncase CEPH_OSD_OP_PULL:\r\ncase CEPH_OSD_OP_PUSH:\r\ncase CEPH_OSD_OP_BALANCEREADS:\r\ncase CEPH_OSD_OP_UNBALANCEREADS:\r\ncase CEPH_OSD_OP_SCRUB:\r\ncase CEPH_OSD_OP_SCRUB_RESERVE:\r\ncase CEPH_OSD_OP_SCRUB_UNRESERVE:\r\ncase CEPH_OSD_OP_SCRUB_STOP:\r\ncase CEPH_OSD_OP_SCRUB_MAP:\r\ncase CEPH_OSD_OP_WRLOCK:\r\ncase CEPH_OSD_OP_WRUNLOCK:\r\ncase CEPH_OSD_OP_RDLOCK:\r\ncase CEPH_OSD_OP_RDUNLOCK:\r\ncase CEPH_OSD_OP_UPLOCK:\r\ncase CEPH_OSD_OP_DNLOCK:\r\ncase CEPH_OSD_OP_CALL:\r\ncase CEPH_OSD_OP_PGLS:\r\ncase CEPH_OSD_OP_PGLS_FILTER:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nstatic struct ceph_osd_req_op *\r\n_osd_req_op_init(struct ceph_osd_request *osd_req, unsigned int which,\r\nu16 opcode)\r\n{\r\nstruct ceph_osd_req_op *op;\r\nBUG_ON(which >= osd_req->r_num_ops);\r\nBUG_ON(!osd_req_opcode_valid(opcode));\r\nop = &osd_req->r_ops[which];\r\nmemset(op, 0, sizeof (*op));\r\nop->op = opcode;\r\nreturn op;\r\n}\r\nvoid osd_req_op_init(struct ceph_osd_request *osd_req,\r\nunsigned int which, u16 opcode)\r\n{\r\n(void)_osd_req_op_init(osd_req, which, opcode);\r\n}\r\nvoid osd_req_op_extent_init(struct ceph_osd_request *osd_req,\r\nunsigned int which, u16 opcode,\r\nu64 offset, u64 length,\r\nu64 truncate_size, u32 truncate_seq)\r\n{\r\nstruct ceph_osd_req_op *op = _osd_req_op_init(osd_req, which, opcode);\r\nsize_t payload_len = 0;\r\nBUG_ON(opcode != CEPH_OSD_OP_READ && opcode != CEPH_OSD_OP_WRITE &&\r\nopcode != CEPH_OSD_OP_DELETE && opcode != CEPH_OSD_OP_ZERO &&\r\nopcode != CEPH_OSD_OP_TRUNCATE);\r\nop->extent.offset = offset;\r\nop->extent.length = length;\r\nop->extent.truncate_size = truncate_size;\r\nop->extent.truncate_seq = truncate_seq;\r\nif (opcode == CEPH_OSD_OP_WRITE)\r\npayload_len += length;\r\nop->payload_len = payload_len;\r\n}\r\nvoid osd_req_op_extent_update(struct ceph_osd_request *osd_req,\r\nunsigned int which, u64 length)\r\n{\r\nstruct ceph_osd_req_op *op;\r\nu64 previous;\r\nBUG_ON(which >= osd_req->r_num_ops);\r\nop = &osd_req->r_ops[which];\r\nprevious = op->extent.length;\r\nif (length == previous)\r\nreturn;\r\nBUG_ON(length > previous);\r\nop->extent.length = length;\r\nop->payload_len -= previous - length;\r\n}\r\nvoid osd_req_op_cls_init(struct ceph_osd_request *osd_req, unsigned int which,\r\nu16 opcode, const char *class, const char *method)\r\n{\r\nstruct ceph_osd_req_op *op = _osd_req_op_init(osd_req, which, opcode);\r\nstruct ceph_pagelist *pagelist;\r\nsize_t payload_len = 0;\r\nsize_t size;\r\nBUG_ON(opcode != CEPH_OSD_OP_CALL);\r\npagelist = kmalloc(sizeof (*pagelist), GFP_NOFS);\r\nBUG_ON(!pagelist);\r\nceph_pagelist_init(pagelist);\r\nop->cls.class_name = class;\r\nsize = strlen(class);\r\nBUG_ON(size > (size_t) U8_MAX);\r\nop->cls.class_len = size;\r\nceph_pagelist_append(pagelist, class, size);\r\npayload_len += size;\r\nop->cls.method_name = method;\r\nsize = strlen(method);\r\nBUG_ON(size > (size_t) U8_MAX);\r\nop->cls.method_len = size;\r\nceph_pagelist_append(pagelist, method, size);\r\npayload_len += size;\r\nosd_req_op_cls_request_info_pagelist(osd_req, which, pagelist);\r\nop->cls.argc = 0;\r\nop->payload_len = payload_len;\r\n}\r\nvoid osd_req_op_watch_init(struct ceph_osd_request *osd_req,\r\nunsigned int which, u16 opcode,\r\nu64 cookie, u64 version, int flag)\r\n{\r\nstruct ceph_osd_req_op *op = _osd_req_op_init(osd_req, which, opcode);\r\nBUG_ON(opcode != CEPH_OSD_OP_NOTIFY_ACK && opcode != CEPH_OSD_OP_WATCH);\r\nop->watch.cookie = cookie;\r\nop->watch.ver = version;\r\nif (opcode == CEPH_OSD_OP_WATCH && flag)\r\nop->watch.flag = (u8)1;\r\n}\r\nstatic void ceph_osdc_msg_data_add(struct ceph_msg *msg,\r\nstruct ceph_osd_data *osd_data)\r\n{\r\nu64 length = ceph_osd_data_length(osd_data);\r\nif (osd_data->type == CEPH_OSD_DATA_TYPE_PAGES) {\r\nBUG_ON(length > (u64) SIZE_MAX);\r\nif (length)\r\nceph_msg_data_add_pages(msg, osd_data->pages,\r\nlength, osd_data->alignment);\r\n} else if (osd_data->type == CEPH_OSD_DATA_TYPE_PAGELIST) {\r\nBUG_ON(!length);\r\nceph_msg_data_add_pagelist(msg, osd_data->pagelist);\r\n#ifdef CONFIG_BLOCK\r\n} else if (osd_data->type == CEPH_OSD_DATA_TYPE_BIO) {\r\nceph_msg_data_add_bio(msg, osd_data->bio, length);\r\n#endif\r\n} else {\r\nBUG_ON(osd_data->type != CEPH_OSD_DATA_TYPE_NONE);\r\n}\r\n}\r\nstatic u64 osd_req_encode_op(struct ceph_osd_request *req,\r\nstruct ceph_osd_op *dst, unsigned int which)\r\n{\r\nstruct ceph_osd_req_op *src;\r\nstruct ceph_osd_data *osd_data;\r\nu64 request_data_len = 0;\r\nu64 data_length;\r\nBUG_ON(which >= req->r_num_ops);\r\nsrc = &req->r_ops[which];\r\nif (WARN_ON(!osd_req_opcode_valid(src->op))) {\r\npr_err("unrecognized osd opcode %d\n", src->op);\r\nreturn 0;\r\n}\r\nswitch (src->op) {\r\ncase CEPH_OSD_OP_STAT:\r\nosd_data = &src->raw_data_in;\r\nceph_osdc_msg_data_add(req->r_reply, osd_data);\r\nbreak;\r\ncase CEPH_OSD_OP_READ:\r\ncase CEPH_OSD_OP_WRITE:\r\ncase CEPH_OSD_OP_ZERO:\r\ncase CEPH_OSD_OP_DELETE:\r\ncase CEPH_OSD_OP_TRUNCATE:\r\nif (src->op == CEPH_OSD_OP_WRITE)\r\nrequest_data_len = src->extent.length;\r\ndst->extent.offset = cpu_to_le64(src->extent.offset);\r\ndst->extent.length = cpu_to_le64(src->extent.length);\r\ndst->extent.truncate_size =\r\ncpu_to_le64(src->extent.truncate_size);\r\ndst->extent.truncate_seq =\r\ncpu_to_le32(src->extent.truncate_seq);\r\nosd_data = &src->extent.osd_data;\r\nif (src->op == CEPH_OSD_OP_WRITE)\r\nceph_osdc_msg_data_add(req->r_request, osd_data);\r\nelse\r\nceph_osdc_msg_data_add(req->r_reply, osd_data);\r\nbreak;\r\ncase CEPH_OSD_OP_CALL:\r\ndst->cls.class_len = src->cls.class_len;\r\ndst->cls.method_len = src->cls.method_len;\r\nosd_data = &src->cls.request_info;\r\nceph_osdc_msg_data_add(req->r_request, osd_data);\r\nBUG_ON(osd_data->type != CEPH_OSD_DATA_TYPE_PAGELIST);\r\nrequest_data_len = osd_data->pagelist->length;\r\nosd_data = &src->cls.request_data;\r\ndata_length = ceph_osd_data_length(osd_data);\r\nif (data_length) {\r\nBUG_ON(osd_data->type == CEPH_OSD_DATA_TYPE_NONE);\r\ndst->cls.indata_len = cpu_to_le32(data_length);\r\nceph_osdc_msg_data_add(req->r_request, osd_data);\r\nsrc->payload_len += data_length;\r\nrequest_data_len += data_length;\r\n}\r\nosd_data = &src->cls.response_data;\r\nceph_osdc_msg_data_add(req->r_reply, osd_data);\r\nbreak;\r\ncase CEPH_OSD_OP_STARTSYNC:\r\nbreak;\r\ncase CEPH_OSD_OP_NOTIFY_ACK:\r\ncase CEPH_OSD_OP_WATCH:\r\ndst->watch.cookie = cpu_to_le64(src->watch.cookie);\r\ndst->watch.ver = cpu_to_le64(src->watch.ver);\r\ndst->watch.flag = src->watch.flag;\r\nbreak;\r\ndefault:\r\npr_err("unsupported osd opcode %s\n",\r\nceph_osd_op_name(src->op));\r\nWARN_ON(1);\r\nreturn 0;\r\n}\r\ndst->op = cpu_to_le16(src->op);\r\ndst->payload_len = cpu_to_le32(src->payload_len);\r\nreturn request_data_len;\r\n}\r\nstruct ceph_osd_request *ceph_osdc_new_request(struct ceph_osd_client *osdc,\r\nstruct ceph_file_layout *layout,\r\nstruct ceph_vino vino,\r\nu64 off, u64 *plen, int num_ops,\r\nint opcode, int flags,\r\nstruct ceph_snap_context *snapc,\r\nu32 truncate_seq,\r\nu64 truncate_size,\r\nbool use_mempool)\r\n{\r\nstruct ceph_osd_request *req;\r\nu64 objnum = 0;\r\nu64 objoff = 0;\r\nu64 objlen = 0;\r\nu32 object_size;\r\nu64 object_base;\r\nint r;\r\nBUG_ON(opcode != CEPH_OSD_OP_READ && opcode != CEPH_OSD_OP_WRITE &&\r\nopcode != CEPH_OSD_OP_DELETE && opcode != CEPH_OSD_OP_ZERO &&\r\nopcode != CEPH_OSD_OP_TRUNCATE);\r\nreq = ceph_osdc_alloc_request(osdc, snapc, num_ops, use_mempool,\r\nGFP_NOFS);\r\nif (!req)\r\nreturn ERR_PTR(-ENOMEM);\r\nreq->r_flags = flags;\r\nr = calc_layout(layout, off, plen, &objnum, &objoff, &objlen);\r\nif (r < 0) {\r\nceph_osdc_put_request(req);\r\nreturn ERR_PTR(r);\r\n}\r\nobject_size = le32_to_cpu(layout->fl_object_size);\r\nobject_base = off - objoff;\r\nif (!(truncate_seq == 1 && truncate_size == -1ULL)) {\r\nif (truncate_size <= object_base) {\r\ntruncate_size = 0;\r\n} else {\r\ntruncate_size -= object_base;\r\nif (truncate_size > object_size)\r\ntruncate_size = object_size;\r\n}\r\n}\r\nosd_req_op_extent_init(req, 0, opcode, objoff, objlen,\r\ntruncate_size, truncate_seq);\r\nif (num_ops > 1)\r\nosd_req_op_init(req, 1, CEPH_OSD_OP_STARTSYNC);\r\nreq->r_file_layout = *layout;\r\nsnprintf(req->r_oid, sizeof(req->r_oid), "%llx.%08llx",\r\nvino.ino, objnum);\r\nreq->r_oid_len = strlen(req->r_oid);\r\nreturn req;\r\n}\r\nstatic void __insert_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *new)\r\n{\r\nstruct rb_node **p = &osdc->requests.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd_request *req = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\nreq = rb_entry(parent, struct ceph_osd_request, r_node);\r\nif (new->r_tid < req->r_tid)\r\np = &(*p)->rb_left;\r\nelse if (new->r_tid > req->r_tid)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->r_node, parent, p);\r\nrb_insert_color(&new->r_node, &osdc->requests);\r\n}\r\nstatic struct ceph_osd_request *__lookup_request(struct ceph_osd_client *osdc,\r\nu64 tid)\r\n{\r\nstruct ceph_osd_request *req;\r\nstruct rb_node *n = osdc->requests.rb_node;\r\nwhile (n) {\r\nreq = rb_entry(n, struct ceph_osd_request, r_node);\r\nif (tid < req->r_tid)\r\nn = n->rb_left;\r\nelse if (tid > req->r_tid)\r\nn = n->rb_right;\r\nelse\r\nreturn req;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct ceph_osd_request *\r\n__lookup_request_ge(struct ceph_osd_client *osdc,\r\nu64 tid)\r\n{\r\nstruct ceph_osd_request *req;\r\nstruct rb_node *n = osdc->requests.rb_node;\r\nwhile (n) {\r\nreq = rb_entry(n, struct ceph_osd_request, r_node);\r\nif (tid < req->r_tid) {\r\nif (!n->rb_left)\r\nreturn req;\r\nn = n->rb_left;\r\n} else if (tid > req->r_tid) {\r\nn = n->rb_right;\r\n} else {\r\nreturn req;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic void __kick_osd_requests(struct ceph_osd_client *osdc,\r\nstruct ceph_osd *osd)\r\n{\r\nstruct ceph_osd_request *req, *nreq;\r\nLIST_HEAD(resend);\r\nint err;\r\ndout("__kick_osd_requests osd%d\n", osd->o_osd);\r\nerr = __reset_osd(osdc, osd);\r\nif (err)\r\nreturn;\r\nlist_for_each_entry(req, &osd->o_requests, r_osd_item) {\r\nif (!req->r_sent)\r\nbreak;\r\nlist_move_tail(&req->r_req_lru_item, &resend);\r\ndout("requeueing %p tid %llu osd%d\n", req, req->r_tid,\r\nosd->o_osd);\r\nif (!req->r_linger)\r\nreq->r_flags |= CEPH_OSD_FLAG_RETRY;\r\n}\r\nlist_splice(&resend, &osdc->req_unsent);\r\nlist_for_each_entry_safe(req, nreq, &osd->o_linger_requests,\r\nr_linger_osd) {\r\nBUG_ON(!list_empty(&req->r_req_lru_item));\r\n__register_request(osdc, req);\r\nlist_add_tail(&req->r_req_lru_item, &osdc->req_unsent);\r\nlist_add_tail(&req->r_osd_item, &req->r_osd->o_requests);\r\n__unregister_linger_request(osdc, req);\r\ndout("requeued lingering %p tid %llu osd%d\n", req, req->r_tid,\r\nosd->o_osd);\r\n}\r\n}\r\nstatic void osd_reset(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nstruct ceph_osd_client *osdc;\r\nif (!osd)\r\nreturn;\r\ndout("osd_reset osd%d\n", osd->o_osd);\r\nosdc = osd->o_osdc;\r\ndown_read(&osdc->map_sem);\r\nmutex_lock(&osdc->request_mutex);\r\n__kick_osd_requests(osdc, osd);\r\n__send_queued(osdc);\r\nmutex_unlock(&osdc->request_mutex);\r\nup_read(&osdc->map_sem);\r\n}\r\nstatic struct ceph_osd *create_osd(struct ceph_osd_client *osdc, int onum)\r\n{\r\nstruct ceph_osd *osd;\r\nosd = kzalloc(sizeof(*osd), GFP_NOFS);\r\nif (!osd)\r\nreturn NULL;\r\natomic_set(&osd->o_ref, 1);\r\nosd->o_osdc = osdc;\r\nosd->o_osd = onum;\r\nRB_CLEAR_NODE(&osd->o_node);\r\nINIT_LIST_HEAD(&osd->o_requests);\r\nINIT_LIST_HEAD(&osd->o_linger_requests);\r\nINIT_LIST_HEAD(&osd->o_osd_lru);\r\nosd->o_incarnation = 1;\r\nceph_con_init(&osd->o_con, osd, &osd_con_ops, &osdc->client->msgr);\r\nINIT_LIST_HEAD(&osd->o_keepalive_item);\r\nreturn osd;\r\n}\r\nstatic struct ceph_osd *get_osd(struct ceph_osd *osd)\r\n{\r\nif (atomic_inc_not_zero(&osd->o_ref)) {\r\ndout("get_osd %p %d -> %d\n", osd, atomic_read(&osd->o_ref)-1,\r\natomic_read(&osd->o_ref));\r\nreturn osd;\r\n} else {\r\ndout("get_osd %p FAIL\n", osd);\r\nreturn NULL;\r\n}\r\n}\r\nstatic void put_osd(struct ceph_osd *osd)\r\n{\r\ndout("put_osd %p %d -> %d\n", osd, atomic_read(&osd->o_ref),\r\natomic_read(&osd->o_ref) - 1);\r\nif (atomic_dec_and_test(&osd->o_ref) && osd->o_auth.authorizer) {\r\nstruct ceph_auth_client *ac = osd->o_osdc->client->monc.auth;\r\nceph_auth_destroy_authorizer(ac, osd->o_auth.authorizer);\r\nkfree(osd);\r\n}\r\n}\r\nstatic void __remove_osd(struct ceph_osd_client *osdc, struct ceph_osd *osd)\r\n{\r\ndout("__remove_osd %p\n", osd);\r\nBUG_ON(!list_empty(&osd->o_requests));\r\nrb_erase(&osd->o_node, &osdc->osds);\r\nlist_del_init(&osd->o_osd_lru);\r\nceph_con_close(&osd->o_con);\r\nput_osd(osd);\r\n}\r\nstatic void remove_all_osds(struct ceph_osd_client *osdc)\r\n{\r\ndout("%s %p\n", __func__, osdc);\r\nmutex_lock(&osdc->request_mutex);\r\nwhile (!RB_EMPTY_ROOT(&osdc->osds)) {\r\nstruct ceph_osd *osd = rb_entry(rb_first(&osdc->osds),\r\nstruct ceph_osd, o_node);\r\n__remove_osd(osdc, osd);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nstatic void __move_osd_to_lru(struct ceph_osd_client *osdc,\r\nstruct ceph_osd *osd)\r\n{\r\ndout("__move_osd_to_lru %p\n", osd);\r\nBUG_ON(!list_empty(&osd->o_osd_lru));\r\nlist_add_tail(&osd->o_osd_lru, &osdc->osd_lru);\r\nosd->lru_ttl = jiffies + osdc->client->options->osd_idle_ttl * HZ;\r\n}\r\nstatic void __remove_osd_from_lru(struct ceph_osd *osd)\r\n{\r\ndout("__remove_osd_from_lru %p\n", osd);\r\nif (!list_empty(&osd->o_osd_lru))\r\nlist_del_init(&osd->o_osd_lru);\r\n}\r\nstatic void remove_old_osds(struct ceph_osd_client *osdc)\r\n{\r\nstruct ceph_osd *osd, *nosd;\r\ndout("__remove_old_osds %p\n", osdc);\r\nmutex_lock(&osdc->request_mutex);\r\nlist_for_each_entry_safe(osd, nosd, &osdc->osd_lru, o_osd_lru) {\r\nif (time_before(jiffies, osd->lru_ttl))\r\nbreak;\r\n__remove_osd(osdc, osd);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nstatic int __reset_osd(struct ceph_osd_client *osdc, struct ceph_osd *osd)\r\n{\r\nstruct ceph_entity_addr *peer_addr;\r\ndout("__reset_osd %p osd%d\n", osd, osd->o_osd);\r\nif (list_empty(&osd->o_requests) &&\r\nlist_empty(&osd->o_linger_requests)) {\r\n__remove_osd(osdc, osd);\r\nreturn -ENODEV;\r\n}\r\npeer_addr = &osdc->osdmap->osd_addr[osd->o_osd];\r\nif (!memcmp(peer_addr, &osd->o_con.peer_addr, sizeof (*peer_addr)) &&\r\n!ceph_con_opened(&osd->o_con)) {\r\nstruct ceph_osd_request *req;\r\ndout(" osd addr hasn't changed and connection never opened,"\r\n" letting msgr retry");\r\nlist_for_each_entry(req, &osd->o_requests, r_osd_item)\r\nreq->r_stamp = jiffies;\r\nreturn -EAGAIN;\r\n}\r\nceph_con_close(&osd->o_con);\r\nceph_con_open(&osd->o_con, CEPH_ENTITY_TYPE_OSD, osd->o_osd, peer_addr);\r\nosd->o_incarnation++;\r\nreturn 0;\r\n}\r\nstatic void __insert_osd(struct ceph_osd_client *osdc, struct ceph_osd *new)\r\n{\r\nstruct rb_node **p = &osdc->osds.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd *osd = NULL;\r\ndout("__insert_osd %p osd%d\n", new, new->o_osd);\r\nwhile (*p) {\r\nparent = *p;\r\nosd = rb_entry(parent, struct ceph_osd, o_node);\r\nif (new->o_osd < osd->o_osd)\r\np = &(*p)->rb_left;\r\nelse if (new->o_osd > osd->o_osd)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->o_node, parent, p);\r\nrb_insert_color(&new->o_node, &osdc->osds);\r\n}\r\nstatic struct ceph_osd *__lookup_osd(struct ceph_osd_client *osdc, int o)\r\n{\r\nstruct ceph_osd *osd;\r\nstruct rb_node *n = osdc->osds.rb_node;\r\nwhile (n) {\r\nosd = rb_entry(n, struct ceph_osd, o_node);\r\nif (o < osd->o_osd)\r\nn = n->rb_left;\r\nelse if (o > osd->o_osd)\r\nn = n->rb_right;\r\nelse\r\nreturn osd;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void __schedule_osd_timeout(struct ceph_osd_client *osdc)\r\n{\r\nschedule_delayed_work(&osdc->timeout_work,\r\nosdc->client->options->osd_keepalive_timeout * HZ);\r\n}\r\nstatic void __cancel_osd_timeout(struct ceph_osd_client *osdc)\r\n{\r\ncancel_delayed_work(&osdc->timeout_work);\r\n}\r\nstatic void __register_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nreq->r_tid = ++osdc->last_tid;\r\nreq->r_request->hdr.tid = cpu_to_le64(req->r_tid);\r\ndout("__register_request %p tid %lld\n", req, req->r_tid);\r\n__insert_request(osdc, req);\r\nceph_osdc_get_request(req);\r\nosdc->num_requests++;\r\nif (osdc->num_requests == 1) {\r\ndout(" first request, scheduling timeout\n");\r\n__schedule_osd_timeout(osdc);\r\n}\r\n}\r\nstatic void __unregister_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nif (RB_EMPTY_NODE(&req->r_node)) {\r\ndout("__unregister_request %p tid %lld not registered\n",\r\nreq, req->r_tid);\r\nreturn;\r\n}\r\ndout("__unregister_request %p tid %lld\n", req, req->r_tid);\r\nrb_erase(&req->r_node, &osdc->requests);\r\nosdc->num_requests--;\r\nif (req->r_osd) {\r\nceph_msg_revoke(req->r_request);\r\nlist_del_init(&req->r_osd_item);\r\nif (list_empty(&req->r_osd->o_requests) &&\r\nlist_empty(&req->r_osd->o_linger_requests)) {\r\ndout("moving osd to %p lru\n", req->r_osd);\r\n__move_osd_to_lru(osdc, req->r_osd);\r\n}\r\nif (list_empty(&req->r_linger_item))\r\nreq->r_osd = NULL;\r\n}\r\nlist_del_init(&req->r_req_lru_item);\r\nceph_osdc_put_request(req);\r\nif (osdc->num_requests == 0) {\r\ndout(" no requests, canceling timeout\n");\r\n__cancel_osd_timeout(osdc);\r\n}\r\n}\r\nstatic void __cancel_request(struct ceph_osd_request *req)\r\n{\r\nif (req->r_sent && req->r_osd) {\r\nceph_msg_revoke(req->r_request);\r\nreq->r_sent = 0;\r\n}\r\n}\r\nstatic void __register_linger_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\ndout("__register_linger_request %p\n", req);\r\nceph_osdc_get_request(req);\r\nlist_add_tail(&req->r_linger_item, &osdc->req_linger);\r\nif (req->r_osd)\r\nlist_add_tail(&req->r_linger_osd,\r\n&req->r_osd->o_linger_requests);\r\n}\r\nstatic void __unregister_linger_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\ndout("__unregister_linger_request %p\n", req);\r\nlist_del_init(&req->r_linger_item);\r\nif (req->r_osd) {\r\nlist_del_init(&req->r_linger_osd);\r\nif (list_empty(&req->r_osd->o_requests) &&\r\nlist_empty(&req->r_osd->o_linger_requests)) {\r\ndout("moving osd to %p lru\n", req->r_osd);\r\n__move_osd_to_lru(osdc, req->r_osd);\r\n}\r\nif (list_empty(&req->r_osd_item))\r\nreq->r_osd = NULL;\r\n}\r\nceph_osdc_put_request(req);\r\n}\r\nvoid ceph_osdc_unregister_linger_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nmutex_lock(&osdc->request_mutex);\r\nif (req->r_linger) {\r\nreq->r_linger = 0;\r\n__unregister_linger_request(osdc, req);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\n}\r\nvoid ceph_osdc_set_request_linger(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nif (!req->r_linger) {\r\ndout("set_request_linger %p\n", req);\r\nreq->r_linger = 1;\r\n}\r\n}\r\nstatic int __map_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req, int force_resend)\r\n{\r\nstruct ceph_pg pgid;\r\nint acting[CEPH_PG_MAX_SIZE];\r\nint o = -1, num = 0;\r\nint err;\r\ndout("map_request %p tid %lld\n", req, req->r_tid);\r\nerr = ceph_calc_ceph_pg(&pgid, req->r_oid, osdc->osdmap,\r\nceph_file_layout_pg_pool(req->r_file_layout));\r\nif (err) {\r\nlist_move(&req->r_req_lru_item, &osdc->req_notarget);\r\nreturn err;\r\n}\r\nreq->r_pgid = pgid;\r\nerr = ceph_calc_pg_acting(osdc->osdmap, pgid, acting);\r\nif (err > 0) {\r\no = acting[0];\r\nnum = err;\r\n}\r\nif ((!force_resend &&\r\nreq->r_osd && req->r_osd->o_osd == o &&\r\nreq->r_sent >= req->r_osd->o_incarnation &&\r\nreq->r_num_pg_osds == num &&\r\nmemcmp(req->r_pg_osds, acting, sizeof(acting[0])*num) == 0) ||\r\n(req->r_osd == NULL && o == -1))\r\nreturn 0;\r\ndout("map_request tid %llu pgid %lld.%x osd%d (was osd%d)\n",\r\nreq->r_tid, pgid.pool, pgid.seed, o,\r\nreq->r_osd ? req->r_osd->o_osd : -1);\r\nmemcpy(req->r_pg_osds, acting, sizeof(acting[0]) * num);\r\nreq->r_num_pg_osds = num;\r\nif (req->r_osd) {\r\n__cancel_request(req);\r\nlist_del_init(&req->r_osd_item);\r\nreq->r_osd = NULL;\r\n}\r\nreq->r_osd = __lookup_osd(osdc, o);\r\nif (!req->r_osd && o >= 0) {\r\nerr = -ENOMEM;\r\nreq->r_osd = create_osd(osdc, o);\r\nif (!req->r_osd) {\r\nlist_move(&req->r_req_lru_item, &osdc->req_notarget);\r\ngoto out;\r\n}\r\ndout("map_request osd %p is osd%d\n", req->r_osd, o);\r\n__insert_osd(osdc, req->r_osd);\r\nceph_con_open(&req->r_osd->o_con,\r\nCEPH_ENTITY_TYPE_OSD, o,\r\n&osdc->osdmap->osd_addr[o]);\r\n}\r\nif (req->r_osd) {\r\n__remove_osd_from_lru(req->r_osd);\r\nlist_add_tail(&req->r_osd_item, &req->r_osd->o_requests);\r\nlist_move_tail(&req->r_req_lru_item, &osdc->req_unsent);\r\n} else {\r\nlist_move_tail(&req->r_req_lru_item, &osdc->req_notarget);\r\n}\r\nerr = 1;\r\nout:\r\nreturn err;\r\n}\r\nstatic void __send_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nvoid *p;\r\ndout("send_request %p tid %llu to osd%d flags %d pg %lld.%x\n",\r\nreq, req->r_tid, req->r_osd->o_osd, req->r_flags,\r\n(unsigned long long)req->r_pgid.pool, req->r_pgid.seed);\r\nput_unaligned_le32(osdc->osdmap->epoch, req->r_request_osdmap_epoch);\r\nput_unaligned_le32(req->r_flags, req->r_request_flags);\r\nput_unaligned_le64(req->r_pgid.pool, req->r_request_pool);\r\np = req->r_request_pgid;\r\nceph_encode_64(&p, req->r_pgid.pool);\r\nceph_encode_32(&p, req->r_pgid.seed);\r\nput_unaligned_le64(1, req->r_request_attempts);\r\nmemcpy(req->r_request_reassert_version, &req->r_reassert_version,\r\nsizeof(req->r_reassert_version));\r\nreq->r_stamp = jiffies;\r\nlist_move_tail(&req->r_req_lru_item, &osdc->req_lru);\r\nceph_msg_get(req->r_request);\r\nreq->r_sent = req->r_osd->o_incarnation;\r\nceph_con_send(&req->r_osd->o_con, req->r_request);\r\n}\r\nstatic void __send_queued(struct ceph_osd_client *osdc)\r\n{\r\nstruct ceph_osd_request *req, *tmp;\r\ndout("__send_queued\n");\r\nlist_for_each_entry_safe(req, tmp, &osdc->req_unsent, r_req_lru_item)\r\n__send_request(osdc, req);\r\n}\r\nstatic void handle_timeout(struct work_struct *work)\r\n{\r\nstruct ceph_osd_client *osdc =\r\ncontainer_of(work, struct ceph_osd_client, timeout_work.work);\r\nstruct ceph_osd_request *req;\r\nstruct ceph_osd *osd;\r\nunsigned long keepalive =\r\nosdc->client->options->osd_keepalive_timeout * HZ;\r\nstruct list_head slow_osds;\r\ndout("timeout\n");\r\ndown_read(&osdc->map_sem);\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\nmutex_lock(&osdc->request_mutex);\r\nINIT_LIST_HEAD(&slow_osds);\r\nlist_for_each_entry(req, &osdc->req_lru, r_req_lru_item) {\r\nif (time_before(jiffies, req->r_stamp + keepalive))\r\nbreak;\r\nosd = req->r_osd;\r\nBUG_ON(!osd);\r\ndout(" tid %llu is slow, will send keepalive on osd%d\n",\r\nreq->r_tid, osd->o_osd);\r\nlist_move_tail(&osd->o_keepalive_item, &slow_osds);\r\n}\r\nwhile (!list_empty(&slow_osds)) {\r\nosd = list_entry(slow_osds.next, struct ceph_osd,\r\no_keepalive_item);\r\nlist_del_init(&osd->o_keepalive_item);\r\nceph_con_keepalive(&osd->o_con);\r\n}\r\n__schedule_osd_timeout(osdc);\r\n__send_queued(osdc);\r\nmutex_unlock(&osdc->request_mutex);\r\nup_read(&osdc->map_sem);\r\n}\r\nstatic void handle_osds_timeout(struct work_struct *work)\r\n{\r\nstruct ceph_osd_client *osdc =\r\ncontainer_of(work, struct ceph_osd_client,\r\nosds_timeout_work.work);\r\nunsigned long delay =\r\nosdc->client->options->osd_idle_ttl * HZ >> 2;\r\ndout("osds timeout\n");\r\ndown_read(&osdc->map_sem);\r\nremove_old_osds(osdc);\r\nup_read(&osdc->map_sem);\r\nschedule_delayed_work(&osdc->osds_timeout_work,\r\nround_jiffies_relative(delay));\r\n}\r\nstatic void complete_request(struct ceph_osd_request *req)\r\n{\r\ncomplete_all(&req->r_safe_completion);\r\n}\r\nstatic void handle_reply(struct ceph_osd_client *osdc, struct ceph_msg *msg,\r\nstruct ceph_connection *con)\r\n{\r\nvoid *p, *end;\r\nstruct ceph_osd_request *req;\r\nu64 tid;\r\nint object_len;\r\nunsigned int numops;\r\nint payload_len, flags;\r\ns32 result;\r\ns32 retry_attempt;\r\nstruct ceph_pg pg;\r\nint err;\r\nu32 reassert_epoch;\r\nu64 reassert_version;\r\nu32 osdmap_epoch;\r\nint already_completed;\r\nu32 bytes;\r\nunsigned int i;\r\ntid = le64_to_cpu(msg->hdr.tid);\r\ndout("handle_reply %p tid %llu\n", msg, tid);\r\np = msg->front.iov_base;\r\nend = p + msg->front.iov_len;\r\nceph_decode_need(&p, end, 4, bad);\r\nobject_len = ceph_decode_32(&p);\r\nceph_decode_need(&p, end, object_len, bad);\r\np += object_len;\r\nerr = ceph_decode_pgid(&p, end, &pg);\r\nif (err)\r\ngoto bad;\r\nceph_decode_need(&p, end, 8 + 4 + 4 + 8 + 4, bad);\r\nflags = ceph_decode_64(&p);\r\nresult = ceph_decode_32(&p);\r\nreassert_epoch = ceph_decode_32(&p);\r\nreassert_version = ceph_decode_64(&p);\r\nosdmap_epoch = ceph_decode_32(&p);\r\nmutex_lock(&osdc->request_mutex);\r\nreq = __lookup_request(osdc, tid);\r\nif (req == NULL) {\r\ndout("handle_reply tid %llu dne\n", tid);\r\ngoto bad_mutex;\r\n}\r\nceph_osdc_get_request(req);\r\ndout("handle_reply %p tid %llu req %p result %d\n", msg, tid,\r\nreq, result);\r\nceph_decode_need(&p, end, 4, bad_put);\r\nnumops = ceph_decode_32(&p);\r\nif (numops > CEPH_OSD_MAX_OP)\r\ngoto bad_put;\r\nif (numops != req->r_num_ops)\r\ngoto bad_put;\r\npayload_len = 0;\r\nceph_decode_need(&p, end, numops * sizeof(struct ceph_osd_op), bad_put);\r\nfor (i = 0; i < numops; i++) {\r\nstruct ceph_osd_op *op = p;\r\nint len;\r\nlen = le32_to_cpu(op->payload_len);\r\nreq->r_reply_op_len[i] = len;\r\ndout(" op %d has %d bytes\n", i, len);\r\npayload_len += len;\r\np += sizeof(*op);\r\n}\r\nbytes = le32_to_cpu(msg->hdr.data_len);\r\nif (payload_len != bytes) {\r\npr_warning("sum of op payload lens %d != data_len %d",\r\npayload_len, bytes);\r\ngoto bad_put;\r\n}\r\nceph_decode_need(&p, end, 4 + numops * 4, bad_put);\r\nretry_attempt = ceph_decode_32(&p);\r\nfor (i = 0; i < numops; i++)\r\nreq->r_reply_op_result[i] = ceph_decode_32(&p);\r\nalready_completed = req->r_got_reply;\r\nif (!req->r_got_reply) {\r\nreq->r_result = result;\r\ndout("handle_reply result %d bytes %d\n", req->r_result,\r\nbytes);\r\nif (req->r_result == 0)\r\nreq->r_result = bytes;\r\nreq->r_reassert_version.epoch = cpu_to_le32(reassert_epoch);\r\nreq->r_reassert_version.version = cpu_to_le64(reassert_version);\r\nreq->r_got_reply = 1;\r\n} else if ((flags & CEPH_OSD_FLAG_ONDISK) == 0) {\r\ndout("handle_reply tid %llu dup ack\n", tid);\r\nmutex_unlock(&osdc->request_mutex);\r\ngoto done;\r\n}\r\ndout("handle_reply tid %llu flags %d\n", tid, flags);\r\nif (req->r_linger && (flags & CEPH_OSD_FLAG_ONDISK))\r\n__register_linger_request(osdc, req);\r\nif (result < 0 ||\r\n(flags & CEPH_OSD_FLAG_ONDISK) ||\r\n((flags & CEPH_OSD_FLAG_WRITE) == 0))\r\n__unregister_request(osdc, req);\r\nmutex_unlock(&osdc->request_mutex);\r\nif (!already_completed) {\r\nif (req->r_unsafe_callback &&\r\nresult >= 0 && !(flags & CEPH_OSD_FLAG_ONDISK))\r\nreq->r_unsafe_callback(req, true);\r\nif (req->r_callback)\r\nreq->r_callback(req, msg);\r\nelse\r\ncomplete_all(&req->r_completion);\r\n}\r\nif (flags & CEPH_OSD_FLAG_ONDISK) {\r\nif (req->r_unsafe_callback && already_completed)\r\nreq->r_unsafe_callback(req, false);\r\ncomplete_request(req);\r\n}\r\ndone:\r\ndout("req=%p req->r_linger=%d\n", req, req->r_linger);\r\nceph_osdc_put_request(req);\r\nreturn;\r\nbad_put:\r\nceph_osdc_put_request(req);\r\nbad_mutex:\r\nmutex_unlock(&osdc->request_mutex);\r\nbad:\r\npr_err("corrupt osd_op_reply got %d %d\n",\r\n(int)msg->front.iov_len, le32_to_cpu(msg->hdr.front_len));\r\nceph_msg_dump(msg);\r\n}\r\nstatic void reset_changed_osds(struct ceph_osd_client *osdc)\r\n{\r\nstruct rb_node *p, *n;\r\nfor (p = rb_first(&osdc->osds); p; p = n) {\r\nstruct ceph_osd *osd = rb_entry(p, struct ceph_osd, o_node);\r\nn = rb_next(p);\r\nif (!ceph_osd_is_up(osdc->osdmap, osd->o_osd) ||\r\nmemcmp(&osd->o_con.peer_addr,\r\nceph_osd_addr(osdc->osdmap,\r\nosd->o_osd),\r\nsizeof(struct ceph_entity_addr)) != 0)\r\n__reset_osd(osdc, osd);\r\n}\r\n}\r\nstatic void kick_requests(struct ceph_osd_client *osdc, int force_resend)\r\n{\r\nstruct ceph_osd_request *req, *nreq;\r\nstruct rb_node *p;\r\nint needmap = 0;\r\nint err;\r\ndout("kick_requests %s\n", force_resend ? " (force resend)" : "");\r\nmutex_lock(&osdc->request_mutex);\r\nfor (p = rb_first(&osdc->requests); p; ) {\r\nreq = rb_entry(p, struct ceph_osd_request, r_node);\r\np = rb_next(p);\r\nif (req->r_linger && list_empty(&req->r_linger_item)) {\r\ndout("%p tid %llu restart on osd%d\n",\r\nreq, req->r_tid,\r\nreq->r_osd ? req->r_osd->o_osd : -1);\r\nceph_osdc_get_request(req);\r\n__unregister_request(osdc, req);\r\n__register_linger_request(osdc, req);\r\nceph_osdc_put_request(req);\r\ncontinue;\r\n}\r\nerr = __map_request(osdc, req, force_resend);\r\nif (err < 0)\r\ncontinue;\r\nif (req->r_osd == NULL) {\r\ndout("%p tid %llu maps to no osd\n", req, req->r_tid);\r\nneedmap++;\r\n} else if (err > 0) {\r\nif (!req->r_linger) {\r\ndout("%p tid %llu requeued on osd%d\n", req,\r\nreq->r_tid,\r\nreq->r_osd ? req->r_osd->o_osd : -1);\r\nreq->r_flags |= CEPH_OSD_FLAG_RETRY;\r\n}\r\n}\r\n}\r\nlist_for_each_entry_safe(req, nreq, &osdc->req_linger,\r\nr_linger_item) {\r\ndout("linger req=%p req->r_osd=%p\n", req, req->r_osd);\r\nerr = __map_request(osdc, req, force_resend);\r\ndout("__map_request returned %d\n", err);\r\nif (err == 0)\r\ncontinue;\r\nif (err < 0)\r\ncontinue;\r\nif (req->r_osd == NULL) {\r\ndout("tid %llu maps to no valid osd\n", req->r_tid);\r\nneedmap++;\r\ncontinue;\r\n}\r\ndout("kicking lingering %p tid %llu osd%d\n", req, req->r_tid,\r\nreq->r_osd ? req->r_osd->o_osd : -1);\r\n__register_request(osdc, req);\r\n__unregister_linger_request(osdc, req);\r\n}\r\nreset_changed_osds(osdc);\r\nmutex_unlock(&osdc->request_mutex);\r\nif (needmap) {\r\ndout("%d requests for down osds, need new map\n", needmap);\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\n}\r\n}\r\nvoid ceph_osdc_handle_map(struct ceph_osd_client *osdc, struct ceph_msg *msg)\r\n{\r\nvoid *p, *end, *next;\r\nu32 nr_maps, maplen;\r\nu32 epoch;\r\nstruct ceph_osdmap *newmap = NULL, *oldmap;\r\nint err;\r\nstruct ceph_fsid fsid;\r\ndout("handle_map have %u\n", osdc->osdmap ? osdc->osdmap->epoch : 0);\r\np = msg->front.iov_base;\r\nend = p + msg->front.iov_len;\r\nceph_decode_need(&p, end, sizeof(fsid), bad);\r\nceph_decode_copy(&p, &fsid, sizeof(fsid));\r\nif (ceph_check_fsid(osdc->client, &fsid) < 0)\r\nreturn;\r\ndown_write(&osdc->map_sem);\r\nceph_decode_32_safe(&p, end, nr_maps, bad);\r\ndout(" %d inc maps\n", nr_maps);\r\nwhile (nr_maps > 0) {\r\nceph_decode_need(&p, end, 2*sizeof(u32), bad);\r\nepoch = ceph_decode_32(&p);\r\nmaplen = ceph_decode_32(&p);\r\nceph_decode_need(&p, end, maplen, bad);\r\nnext = p + maplen;\r\nif (osdc->osdmap && osdc->osdmap->epoch+1 == epoch) {\r\ndout("applying incremental map %u len %d\n",\r\nepoch, maplen);\r\nnewmap = osdmap_apply_incremental(&p, next,\r\nosdc->osdmap,\r\n&osdc->client->msgr);\r\nif (IS_ERR(newmap)) {\r\nerr = PTR_ERR(newmap);\r\ngoto bad;\r\n}\r\nBUG_ON(!newmap);\r\nif (newmap != osdc->osdmap) {\r\nceph_osdmap_destroy(osdc->osdmap);\r\nosdc->osdmap = newmap;\r\n}\r\nkick_requests(osdc, 0);\r\n} else {\r\ndout("ignoring incremental map %u len %d\n",\r\nepoch, maplen);\r\n}\r\np = next;\r\nnr_maps--;\r\n}\r\nif (newmap)\r\ngoto done;\r\nceph_decode_32_safe(&p, end, nr_maps, bad);\r\ndout(" %d full maps\n", nr_maps);\r\nwhile (nr_maps) {\r\nceph_decode_need(&p, end, 2*sizeof(u32), bad);\r\nepoch = ceph_decode_32(&p);\r\nmaplen = ceph_decode_32(&p);\r\nceph_decode_need(&p, end, maplen, bad);\r\nif (nr_maps > 1) {\r\ndout("skipping non-latest full map %u len %d\n",\r\nepoch, maplen);\r\n} else if (osdc->osdmap && osdc->osdmap->epoch >= epoch) {\r\ndout("skipping full map %u len %d, "\r\n"older than our %u\n", epoch, maplen,\r\nosdc->osdmap->epoch);\r\n} else {\r\nint skipped_map = 0;\r\ndout("taking full map %u len %d\n", epoch, maplen);\r\nnewmap = osdmap_decode(&p, p+maplen);\r\nif (IS_ERR(newmap)) {\r\nerr = PTR_ERR(newmap);\r\ngoto bad;\r\n}\r\nBUG_ON(!newmap);\r\noldmap = osdc->osdmap;\r\nosdc->osdmap = newmap;\r\nif (oldmap) {\r\nif (oldmap->epoch + 1 < newmap->epoch)\r\nskipped_map = 1;\r\nceph_osdmap_destroy(oldmap);\r\n}\r\nkick_requests(osdc, skipped_map);\r\n}\r\np += maplen;\r\nnr_maps--;\r\n}\r\nif (!osdc->osdmap)\r\ngoto bad;\r\ndone:\r\ndowngrade_write(&osdc->map_sem);\r\nceph_monc_got_osdmap(&osdc->client->monc, osdc->osdmap->epoch);\r\nif (ceph_osdmap_flag(osdc->osdmap, CEPH_OSDMAP_FULL))\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\nmutex_lock(&osdc->request_mutex);\r\n__send_queued(osdc);\r\nmutex_unlock(&osdc->request_mutex);\r\nup_read(&osdc->map_sem);\r\nwake_up_all(&osdc->client->auth_wq);\r\nreturn;\r\nbad:\r\npr_err("osdc handle_map corrupt msg\n");\r\nceph_msg_dump(msg);\r\nup_write(&osdc->map_sem);\r\nreturn;\r\n}\r\nstatic void __release_event(struct kref *kref)\r\n{\r\nstruct ceph_osd_event *event =\r\ncontainer_of(kref, struct ceph_osd_event, kref);\r\ndout("__release_event %p\n", event);\r\nkfree(event);\r\n}\r\nstatic void get_event(struct ceph_osd_event *event)\r\n{\r\nkref_get(&event->kref);\r\n}\r\nvoid ceph_osdc_put_event(struct ceph_osd_event *event)\r\n{\r\nkref_put(&event->kref, __release_event);\r\n}\r\nstatic void __insert_event(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_event *new)\r\n{\r\nstruct rb_node **p = &osdc->event_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd_event *event = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\nevent = rb_entry(parent, struct ceph_osd_event, node);\r\nif (new->cookie < event->cookie)\r\np = &(*p)->rb_left;\r\nelse if (new->cookie > event->cookie)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, &osdc->event_tree);\r\n}\r\nstatic struct ceph_osd_event *__find_event(struct ceph_osd_client *osdc,\r\nu64 cookie)\r\n{\r\nstruct rb_node **p = &osdc->event_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_osd_event *event = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\nevent = rb_entry(parent, struct ceph_osd_event, node);\r\nif (cookie < event->cookie)\r\np = &(*p)->rb_left;\r\nelse if (cookie > event->cookie)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn event;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void __remove_event(struct ceph_osd_event *event)\r\n{\r\nstruct ceph_osd_client *osdc = event->osdc;\r\nif (!RB_EMPTY_NODE(&event->node)) {\r\ndout("__remove_event removed %p\n", event);\r\nrb_erase(&event->node, &osdc->event_tree);\r\nceph_osdc_put_event(event);\r\n} else {\r\ndout("__remove_event didn't remove %p\n", event);\r\n}\r\n}\r\nint ceph_osdc_create_event(struct ceph_osd_client *osdc,\r\nvoid (*event_cb)(u64, u64, u8, void *),\r\nvoid *data, struct ceph_osd_event **pevent)\r\n{\r\nstruct ceph_osd_event *event;\r\nevent = kmalloc(sizeof(*event), GFP_NOIO);\r\nif (!event)\r\nreturn -ENOMEM;\r\ndout("create_event %p\n", event);\r\nevent->cb = event_cb;\r\nevent->one_shot = 0;\r\nevent->data = data;\r\nevent->osdc = osdc;\r\nINIT_LIST_HEAD(&event->osd_node);\r\nRB_CLEAR_NODE(&event->node);\r\nkref_init(&event->kref);\r\nkref_get(&event->kref);\r\nspin_lock(&osdc->event_lock);\r\nevent->cookie = ++osdc->event_count;\r\n__insert_event(osdc, event);\r\nspin_unlock(&osdc->event_lock);\r\n*pevent = event;\r\nreturn 0;\r\n}\r\nvoid ceph_osdc_cancel_event(struct ceph_osd_event *event)\r\n{\r\nstruct ceph_osd_client *osdc = event->osdc;\r\ndout("cancel_event %p\n", event);\r\nspin_lock(&osdc->event_lock);\r\n__remove_event(event);\r\nspin_unlock(&osdc->event_lock);\r\nceph_osdc_put_event(event);\r\n}\r\nstatic void do_event_work(struct work_struct *work)\r\n{\r\nstruct ceph_osd_event_work *event_work =\r\ncontainer_of(work, struct ceph_osd_event_work, work);\r\nstruct ceph_osd_event *event = event_work->event;\r\nu64 ver = event_work->ver;\r\nu64 notify_id = event_work->notify_id;\r\nu8 opcode = event_work->opcode;\r\ndout("do_event_work completing %p\n", event);\r\nevent->cb(ver, notify_id, opcode, event->data);\r\ndout("do_event_work completed %p\n", event);\r\nceph_osdc_put_event(event);\r\nkfree(event_work);\r\n}\r\nstatic void handle_watch_notify(struct ceph_osd_client *osdc,\r\nstruct ceph_msg *msg)\r\n{\r\nvoid *p, *end;\r\nu8 proto_ver;\r\nu64 cookie, ver, notify_id;\r\nu8 opcode;\r\nstruct ceph_osd_event *event;\r\nstruct ceph_osd_event_work *event_work;\r\np = msg->front.iov_base;\r\nend = p + msg->front.iov_len;\r\nceph_decode_8_safe(&p, end, proto_ver, bad);\r\nceph_decode_8_safe(&p, end, opcode, bad);\r\nceph_decode_64_safe(&p, end, cookie, bad);\r\nceph_decode_64_safe(&p, end, ver, bad);\r\nceph_decode_64_safe(&p, end, notify_id, bad);\r\nspin_lock(&osdc->event_lock);\r\nevent = __find_event(osdc, cookie);\r\nif (event) {\r\nBUG_ON(event->one_shot);\r\nget_event(event);\r\n}\r\nspin_unlock(&osdc->event_lock);\r\ndout("handle_watch_notify cookie %lld ver %lld event %p\n",\r\ncookie, ver, event);\r\nif (event) {\r\nevent_work = kmalloc(sizeof(*event_work), GFP_NOIO);\r\nif (!event_work) {\r\ndout("ERROR: could not allocate event_work\n");\r\ngoto done_err;\r\n}\r\nINIT_WORK(&event_work->work, do_event_work);\r\nevent_work->event = event;\r\nevent_work->ver = ver;\r\nevent_work->notify_id = notify_id;\r\nevent_work->opcode = opcode;\r\nif (!queue_work(osdc->notify_wq, &event_work->work)) {\r\ndout("WARNING: failed to queue notify event work\n");\r\ngoto done_err;\r\n}\r\n}\r\nreturn;\r\ndone_err:\r\nceph_osdc_put_event(event);\r\nreturn;\r\nbad:\r\npr_err("osdc handle_watch_notify corrupt msg\n");\r\nreturn;\r\n}\r\nvoid ceph_osdc_build_request(struct ceph_osd_request *req, u64 off,\r\nstruct ceph_snap_context *snapc, u64 snap_id,\r\nstruct timespec *mtime)\r\n{\r\nstruct ceph_msg *msg = req->r_request;\r\nvoid *p;\r\nsize_t msg_size;\r\nint flags = req->r_flags;\r\nu64 data_len;\r\nunsigned int i;\r\nreq->r_snapid = snap_id;\r\nreq->r_snapc = ceph_get_snap_context(snapc);\r\nmsg->hdr.version = cpu_to_le16(4);\r\np = msg->front.iov_base;\r\nceph_encode_32(&p, 1);\r\nreq->r_request_osdmap_epoch = p;\r\np += 4;\r\nreq->r_request_flags = p;\r\np += 4;\r\nif (req->r_flags & CEPH_OSD_FLAG_WRITE)\r\nceph_encode_timespec(p, mtime);\r\np += sizeof(struct ceph_timespec);\r\nreq->r_request_reassert_version = p;\r\np += sizeof(struct ceph_eversion);\r\nceph_encode_8(&p, 4);\r\nceph_encode_8(&p, 4);\r\nceph_encode_32(&p, 8 + 4 + 4);\r\nreq->r_request_pool = p;\r\np += 8;\r\nceph_encode_32(&p, -1);\r\nceph_encode_32(&p, 0);\r\nceph_encode_8(&p, 1);\r\nreq->r_request_pgid = p;\r\np += 8 + 4;\r\nceph_encode_32(&p, -1);\r\nceph_encode_32(&p, req->r_oid_len);\r\nmemcpy(p, req->r_oid, req->r_oid_len);\r\ndout("oid '%.*s' len %d\n", req->r_oid_len, req->r_oid, req->r_oid_len);\r\np += req->r_oid_len;\r\nceph_encode_16(&p, (u16)req->r_num_ops);\r\ndata_len = 0;\r\nfor (i = 0; i < req->r_num_ops; i++) {\r\ndata_len += osd_req_encode_op(req, p, i);\r\np += sizeof(struct ceph_osd_op);\r\n}\r\nceph_encode_64(&p, req->r_snapid);\r\nceph_encode_64(&p, req->r_snapc ? req->r_snapc->seq : 0);\r\nceph_encode_32(&p, req->r_snapc ? req->r_snapc->num_snaps : 0);\r\nif (req->r_snapc) {\r\nfor (i = 0; i < snapc->num_snaps; i++) {\r\nceph_encode_64(&p, req->r_snapc->snaps[i]);\r\n}\r\n}\r\nreq->r_request_attempts = p;\r\np += 4;\r\nif (flags & CEPH_OSD_FLAG_WRITE) {\r\nu16 data_off;\r\ndata_off = (u16) (off & 0xffff);\r\nreq->r_request->hdr.data_off = cpu_to_le16(data_off);\r\n}\r\nreq->r_request->hdr.data_len = cpu_to_le32(data_len);\r\nBUG_ON(p > msg->front.iov_base + msg->front.iov_len);\r\nmsg_size = p - msg->front.iov_base;\r\nmsg->front.iov_len = msg_size;\r\nmsg->hdr.front_len = cpu_to_le32(msg_size);\r\ndout("build_request msg_size was %d\n", (int)msg_size);\r\n}\r\nint ceph_osdc_start_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req,\r\nbool nofail)\r\n{\r\nint rc = 0;\r\ndown_read(&osdc->map_sem);\r\nmutex_lock(&osdc->request_mutex);\r\n__register_request(osdc, req);\r\nreq->r_sent = 0;\r\nreq->r_got_reply = 0;\r\nrc = __map_request(osdc, req, 0);\r\nif (rc < 0) {\r\nif (nofail) {\r\ndout("osdc_start_request failed map, "\r\n" will retry %lld\n", req->r_tid);\r\nrc = 0;\r\n} else {\r\n__unregister_request(osdc, req);\r\n}\r\ngoto out_unlock;\r\n}\r\nif (req->r_osd == NULL) {\r\ndout("send_request %p no up osds in pg\n", req);\r\nceph_monc_request_next_osdmap(&osdc->client->monc);\r\n} else {\r\n__send_queued(osdc);\r\n}\r\nrc = 0;\r\nout_unlock:\r\nmutex_unlock(&osdc->request_mutex);\r\nup_read(&osdc->map_sem);\r\nreturn rc;\r\n}\r\nint ceph_osdc_wait_request(struct ceph_osd_client *osdc,\r\nstruct ceph_osd_request *req)\r\n{\r\nint rc;\r\nrc = wait_for_completion_interruptible(&req->r_completion);\r\nif (rc < 0) {\r\nmutex_lock(&osdc->request_mutex);\r\n__cancel_request(req);\r\n__unregister_request(osdc, req);\r\nmutex_unlock(&osdc->request_mutex);\r\ncomplete_request(req);\r\ndout("wait_request tid %llu canceled/timed out\n", req->r_tid);\r\nreturn rc;\r\n}\r\ndout("wait_request tid %llu result %d\n", req->r_tid, req->r_result);\r\nreturn req->r_result;\r\n}\r\nvoid ceph_osdc_sync(struct ceph_osd_client *osdc)\r\n{\r\nstruct ceph_osd_request *req;\r\nu64 last_tid, next_tid = 0;\r\nmutex_lock(&osdc->request_mutex);\r\nlast_tid = osdc->last_tid;\r\nwhile (1) {\r\nreq = __lookup_request_ge(osdc, next_tid);\r\nif (!req)\r\nbreak;\r\nif (req->r_tid > last_tid)\r\nbreak;\r\nnext_tid = req->r_tid + 1;\r\nif ((req->r_flags & CEPH_OSD_FLAG_WRITE) == 0)\r\ncontinue;\r\nceph_osdc_get_request(req);\r\nmutex_unlock(&osdc->request_mutex);\r\ndout("sync waiting on tid %llu (last is %llu)\n",\r\nreq->r_tid, last_tid);\r\nwait_for_completion(&req->r_safe_completion);\r\nmutex_lock(&osdc->request_mutex);\r\nceph_osdc_put_request(req);\r\n}\r\nmutex_unlock(&osdc->request_mutex);\r\ndout("sync done (thru tid %llu)\n", last_tid);\r\n}\r\nextern void ceph_osdc_flush_notifies(struct ceph_osd_client *osdc)\r\n{\r\nflush_workqueue(osdc->notify_wq);\r\n}\r\nint ceph_osdc_init(struct ceph_osd_client *osdc, struct ceph_client *client)\r\n{\r\nint err;\r\ndout("init\n");\r\nosdc->client = client;\r\nosdc->osdmap = NULL;\r\ninit_rwsem(&osdc->map_sem);\r\ninit_completion(&osdc->map_waiters);\r\nosdc->last_requested_map = 0;\r\nmutex_init(&osdc->request_mutex);\r\nosdc->last_tid = 0;\r\nosdc->osds = RB_ROOT;\r\nINIT_LIST_HEAD(&osdc->osd_lru);\r\nosdc->requests = RB_ROOT;\r\nINIT_LIST_HEAD(&osdc->req_lru);\r\nINIT_LIST_HEAD(&osdc->req_unsent);\r\nINIT_LIST_HEAD(&osdc->req_notarget);\r\nINIT_LIST_HEAD(&osdc->req_linger);\r\nosdc->num_requests = 0;\r\nINIT_DELAYED_WORK(&osdc->timeout_work, handle_timeout);\r\nINIT_DELAYED_WORK(&osdc->osds_timeout_work, handle_osds_timeout);\r\nspin_lock_init(&osdc->event_lock);\r\nosdc->event_tree = RB_ROOT;\r\nosdc->event_count = 0;\r\nschedule_delayed_work(&osdc->osds_timeout_work,\r\nround_jiffies_relative(osdc->client->options->osd_idle_ttl * HZ));\r\nerr = -ENOMEM;\r\nosdc->req_mempool = mempool_create_kmalloc_pool(10,\r\nsizeof(struct ceph_osd_request));\r\nif (!osdc->req_mempool)\r\ngoto out;\r\nerr = ceph_msgpool_init(&osdc->msgpool_op, CEPH_MSG_OSD_OP,\r\nOSD_OP_FRONT_LEN, 10, true,\r\n"osd_op");\r\nif (err < 0)\r\ngoto out_mempool;\r\nerr = ceph_msgpool_init(&osdc->msgpool_op_reply, CEPH_MSG_OSD_OPREPLY,\r\nOSD_OPREPLY_FRONT_LEN, 10, true,\r\n"osd_op_reply");\r\nif (err < 0)\r\ngoto out_msgpool;\r\nerr = -ENOMEM;\r\nosdc->notify_wq = create_singlethread_workqueue("ceph-watch-notify");\r\nif (!osdc->notify_wq)\r\ngoto out_msgpool;\r\nreturn 0;\r\nout_msgpool:\r\nceph_msgpool_destroy(&osdc->msgpool_op);\r\nout_mempool:\r\nmempool_destroy(osdc->req_mempool);\r\nout:\r\nreturn err;\r\n}\r\nvoid ceph_osdc_stop(struct ceph_osd_client *osdc)\r\n{\r\nflush_workqueue(osdc->notify_wq);\r\ndestroy_workqueue(osdc->notify_wq);\r\ncancel_delayed_work_sync(&osdc->timeout_work);\r\ncancel_delayed_work_sync(&osdc->osds_timeout_work);\r\nif (osdc->osdmap) {\r\nceph_osdmap_destroy(osdc->osdmap);\r\nosdc->osdmap = NULL;\r\n}\r\nremove_all_osds(osdc);\r\nmempool_destroy(osdc->req_mempool);\r\nceph_msgpool_destroy(&osdc->msgpool_op);\r\nceph_msgpool_destroy(&osdc->msgpool_op_reply);\r\n}\r\nint ceph_osdc_readpages(struct ceph_osd_client *osdc,\r\nstruct ceph_vino vino, struct ceph_file_layout *layout,\r\nu64 off, u64 *plen,\r\nu32 truncate_seq, u64 truncate_size,\r\nstruct page **pages, int num_pages, int page_align)\r\n{\r\nstruct ceph_osd_request *req;\r\nint rc = 0;\r\ndout("readpages on ino %llx.%llx on %llu~%llu\n", vino.ino,\r\nvino.snap, off, *plen);\r\nreq = ceph_osdc_new_request(osdc, layout, vino, off, plen, 1,\r\nCEPH_OSD_OP_READ, CEPH_OSD_FLAG_READ,\r\nNULL, truncate_seq, truncate_size,\r\nfalse);\r\nif (IS_ERR(req))\r\nreturn PTR_ERR(req);\r\nosd_req_op_extent_osd_data_pages(req, 0,\r\npages, *plen, page_align, false, false);\r\ndout("readpages final extent is %llu~%llu (%llu bytes align %d)\n",\r\noff, *plen, *plen, page_align);\r\nceph_osdc_build_request(req, off, NULL, vino.snap, NULL);\r\nrc = ceph_osdc_start_request(osdc, req, false);\r\nif (!rc)\r\nrc = ceph_osdc_wait_request(osdc, req);\r\nceph_osdc_put_request(req);\r\ndout("readpages result %d\n", rc);\r\nreturn rc;\r\n}\r\nint ceph_osdc_writepages(struct ceph_osd_client *osdc, struct ceph_vino vino,\r\nstruct ceph_file_layout *layout,\r\nstruct ceph_snap_context *snapc,\r\nu64 off, u64 len,\r\nu32 truncate_seq, u64 truncate_size,\r\nstruct timespec *mtime,\r\nstruct page **pages, int num_pages)\r\n{\r\nstruct ceph_osd_request *req;\r\nint rc = 0;\r\nint page_align = off & ~PAGE_MASK;\r\nBUG_ON(vino.snap != CEPH_NOSNAP);\r\nreq = ceph_osdc_new_request(osdc, layout, vino, off, &len, 1,\r\nCEPH_OSD_OP_WRITE,\r\nCEPH_OSD_FLAG_ONDISK | CEPH_OSD_FLAG_WRITE,\r\nsnapc, truncate_seq, truncate_size,\r\ntrue);\r\nif (IS_ERR(req))\r\nreturn PTR_ERR(req);\r\nosd_req_op_extent_osd_data_pages(req, 0, pages, len, page_align,\r\nfalse, false);\r\ndout("writepages %llu~%llu (%llu bytes)\n", off, len, len);\r\nceph_osdc_build_request(req, off, snapc, CEPH_NOSNAP, mtime);\r\nrc = ceph_osdc_start_request(osdc, req, true);\r\nif (!rc)\r\nrc = ceph_osdc_wait_request(osdc, req);\r\nceph_osdc_put_request(req);\r\nif (rc == 0)\r\nrc = len;\r\ndout("writepages result %d\n", rc);\r\nreturn rc;\r\n}\r\nint ceph_osdc_setup(void)\r\n{\r\nBUG_ON(ceph_osd_request_cache);\r\nceph_osd_request_cache = kmem_cache_create("ceph_osd_request",\r\nsizeof (struct ceph_osd_request),\r\n__alignof__(struct ceph_osd_request),\r\n0, NULL);\r\nreturn ceph_osd_request_cache ? 0 : -ENOMEM;\r\n}\r\nvoid ceph_osdc_cleanup(void)\r\n{\r\nBUG_ON(!ceph_osd_request_cache);\r\nkmem_cache_destroy(ceph_osd_request_cache);\r\nceph_osd_request_cache = NULL;\r\n}\r\nstatic void dispatch(struct ceph_connection *con, struct ceph_msg *msg)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nstruct ceph_osd_client *osdc;\r\nint type = le16_to_cpu(msg->hdr.type);\r\nif (!osd)\r\ngoto out;\r\nosdc = osd->o_osdc;\r\nswitch (type) {\r\ncase CEPH_MSG_OSD_MAP:\r\nceph_osdc_handle_map(osdc, msg);\r\nbreak;\r\ncase CEPH_MSG_OSD_OPREPLY:\r\nhandle_reply(osdc, msg, con);\r\nbreak;\r\ncase CEPH_MSG_WATCH_NOTIFY:\r\nhandle_watch_notify(osdc, msg);\r\nbreak;\r\ndefault:\r\npr_err("received unknown message type %d %s\n", type,\r\nceph_msg_type_name(type));\r\n}\r\nout:\r\nceph_msg_put(msg);\r\n}\r\nstatic struct ceph_msg *get_reply(struct ceph_connection *con,\r\nstruct ceph_msg_header *hdr,\r\nint *skip)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nstruct ceph_osd_client *osdc = osd->o_osdc;\r\nstruct ceph_msg *m;\r\nstruct ceph_osd_request *req;\r\nint front = le32_to_cpu(hdr->front_len);\r\nint data_len = le32_to_cpu(hdr->data_len);\r\nu64 tid;\r\ntid = le64_to_cpu(hdr->tid);\r\nmutex_lock(&osdc->request_mutex);\r\nreq = __lookup_request(osdc, tid);\r\nif (!req) {\r\n*skip = 1;\r\nm = NULL;\r\ndout("get_reply unknown tid %llu from osd%d\n", tid,\r\nosd->o_osd);\r\ngoto out;\r\n}\r\nif (req->r_reply->con)\r\ndout("%s revoking msg %p from old con %p\n", __func__,\r\nreq->r_reply, req->r_reply->con);\r\nceph_msg_revoke_incoming(req->r_reply);\r\nif (front > req->r_reply->front.iov_len) {\r\npr_warning("get_reply front %d > preallocated %d (%u#%llu)\n",\r\nfront, (int)req->r_reply->front.iov_len,\r\n(unsigned int)con->peer_name.type,\r\nle64_to_cpu(con->peer_name.num));\r\nm = ceph_msg_new(CEPH_MSG_OSD_OPREPLY, front, GFP_NOFS, false);\r\nif (!m)\r\ngoto out;\r\nceph_msg_put(req->r_reply);\r\nreq->r_reply = m;\r\n}\r\nm = ceph_msg_get(req->r_reply);\r\nif (data_len > 0) {\r\nstruct ceph_osd_data *osd_data;\r\nosd_data = osd_req_op_extent_osd_data(req, 0);\r\nif (osd_data->type == CEPH_OSD_DATA_TYPE_PAGES) {\r\nif (osd_data->pages &&\r\nunlikely(osd_data->length < data_len)) {\r\npr_warning("tid %lld reply has %d bytes "\r\n"we had only %llu bytes ready\n",\r\ntid, data_len, osd_data->length);\r\n*skip = 1;\r\nceph_msg_put(m);\r\nm = NULL;\r\ngoto out;\r\n}\r\n}\r\n}\r\n*skip = 0;\r\ndout("get_reply tid %lld %p\n", tid, m);\r\nout:\r\nmutex_unlock(&osdc->request_mutex);\r\nreturn m;\r\n}\r\nstatic struct ceph_msg *alloc_msg(struct ceph_connection *con,\r\nstruct ceph_msg_header *hdr,\r\nint *skip)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nint type = le16_to_cpu(hdr->type);\r\nint front = le32_to_cpu(hdr->front_len);\r\n*skip = 0;\r\nswitch (type) {\r\ncase CEPH_MSG_OSD_MAP:\r\ncase CEPH_MSG_WATCH_NOTIFY:\r\nreturn ceph_msg_new(type, front, GFP_NOFS, false);\r\ncase CEPH_MSG_OSD_OPREPLY:\r\nreturn get_reply(con, hdr, skip);\r\ndefault:\r\npr_info("alloc_msg unexpected msg type %d from osd%d\n", type,\r\nosd->o_osd);\r\n*skip = 1;\r\nreturn NULL;\r\n}\r\n}\r\nstatic struct ceph_connection *get_osd_con(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nif (get_osd(osd))\r\nreturn con;\r\nreturn NULL;\r\n}\r\nstatic void put_osd_con(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *osd = con->private;\r\nput_osd(osd);\r\n}\r\nstatic struct ceph_auth_handshake *get_authorizer(struct ceph_connection *con,\r\nint *proto, int force_new)\r\n{\r\nstruct ceph_osd *o = con->private;\r\nstruct ceph_osd_client *osdc = o->o_osdc;\r\nstruct ceph_auth_client *ac = osdc->client->monc.auth;\r\nstruct ceph_auth_handshake *auth = &o->o_auth;\r\nif (force_new && auth->authorizer) {\r\nceph_auth_destroy_authorizer(ac, auth->authorizer);\r\nauth->authorizer = NULL;\r\n}\r\nif (!auth->authorizer) {\r\nint ret = ceph_auth_create_authorizer(ac, CEPH_ENTITY_TYPE_OSD,\r\nauth);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\n} else {\r\nint ret = ceph_auth_update_authorizer(ac, CEPH_ENTITY_TYPE_OSD,\r\nauth);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\n}\r\n*proto = ac->protocol;\r\nreturn auth;\r\n}\r\nstatic int verify_authorizer_reply(struct ceph_connection *con, int len)\r\n{\r\nstruct ceph_osd *o = con->private;\r\nstruct ceph_osd_client *osdc = o->o_osdc;\r\nstruct ceph_auth_client *ac = osdc->client->monc.auth;\r\nreturn ceph_auth_verify_authorizer_reply(ac, o->o_auth.authorizer, len);\r\n}\r\nstatic int invalidate_authorizer(struct ceph_connection *con)\r\n{\r\nstruct ceph_osd *o = con->private;\r\nstruct ceph_osd_client *osdc = o->o_osdc;\r\nstruct ceph_auth_client *ac = osdc->client->monc.auth;\r\nceph_auth_invalidate_authorizer(ac, CEPH_ENTITY_TYPE_OSD);\r\nreturn ceph_monc_validate_auth(&osdc->client->monc);\r\n}
