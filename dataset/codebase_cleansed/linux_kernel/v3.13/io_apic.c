int mpc_ioapic_id(int ioapic_idx)\r\n{\r\nreturn ioapics[ioapic_idx].mp_config.apicid;\r\n}\r\nunsigned int mpc_ioapic_addr(int ioapic_idx)\r\n{\r\nreturn ioapics[ioapic_idx].mp_config.apicaddr;\r\n}\r\nstruct mp_ioapic_gsi *mp_ioapic_gsi_routing(int ioapic_idx)\r\n{\r\nreturn &ioapics[ioapic_idx].gsi_config;\r\n}\r\nvoid disable_ioapic_support(void)\r\n{\r\n#ifdef CONFIG_PCI\r\nnoioapicquirk = 1;\r\nnoioapicreroute = -1;\r\n#endif\r\nskip_ioapic_setup = 1;\r\n}\r\nstatic int __init parse_noapic(char *str)\r\n{\r\ndisable_ioapic_support();\r\nreturn 0;\r\n}\r\nvoid mp_save_irq(struct mpc_intsrc *m)\r\n{\r\nint i;\r\napic_printk(APIC_VERBOSE, "Int: type %d, pol %d, trig %d, bus %02x,"\r\n" IRQ %02x, APIC ID %x, APIC INT %02x\n",\r\nm->irqtype, m->irqflag & 3, (m->irqflag >> 2) & 3, m->srcbus,\r\nm->srcbusirq, m->dstapic, m->dstirq);\r\nfor (i = 0; i < mp_irq_entries; i++) {\r\nif (!memcmp(&mp_irqs[i], m, sizeof(*m)))\r\nreturn;\r\n}\r\nmemcpy(&mp_irqs[mp_irq_entries], m, sizeof(*m));\r\nif (++mp_irq_entries == MAX_IRQ_SOURCES)\r\npanic("Max # of irq sources exceeded!!\n");\r\n}\r\nstatic struct irq_pin_list *alloc_irq_pin_list(int node)\r\n{\r\nreturn kzalloc_node(sizeof(struct irq_pin_list), GFP_KERNEL, node);\r\n}\r\nint __init arch_early_irq_init(void)\r\n{\r\nstruct irq_cfg *cfg;\r\nint count, node, i;\r\nif (!legacy_pic->nr_legacy_irqs)\r\nio_apic_irqs = ~0UL;\r\nfor (i = 0; i < nr_ioapics; i++) {\r\nioapics[i].saved_registers =\r\nkzalloc(sizeof(struct IO_APIC_route_entry) *\r\nioapics[i].nr_registers, GFP_KERNEL);\r\nif (!ioapics[i].saved_registers)\r\npr_err("IOAPIC %d: suspend/resume impossible!\n", i);\r\n}\r\ncfg = irq_cfgx;\r\ncount = ARRAY_SIZE(irq_cfgx);\r\nnode = cpu_to_node(0);\r\nirq_reserve_irqs(0, legacy_pic->nr_legacy_irqs);\r\nfor (i = 0; i < count; i++) {\r\nirq_set_chip_data(i, &cfg[i]);\r\nzalloc_cpumask_var_node(&cfg[i].domain, GFP_KERNEL, node);\r\nzalloc_cpumask_var_node(&cfg[i].old_domain, GFP_KERNEL, node);\r\nif (i < legacy_pic->nr_legacy_irqs) {\r\ncfg[i].vector = IRQ0_VECTOR + i;\r\ncpumask_setall(cfg[i].domain);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic struct irq_cfg *irq_cfg(unsigned int irq)\r\n{\r\nreturn irq_get_chip_data(irq);\r\n}\r\nstatic struct irq_cfg *alloc_irq_cfg(unsigned int irq, int node)\r\n{\r\nstruct irq_cfg *cfg;\r\ncfg = kzalloc_node(sizeof(*cfg), GFP_KERNEL, node);\r\nif (!cfg)\r\nreturn NULL;\r\nif (!zalloc_cpumask_var_node(&cfg->domain, GFP_KERNEL, node))\r\ngoto out_cfg;\r\nif (!zalloc_cpumask_var_node(&cfg->old_domain, GFP_KERNEL, node))\r\ngoto out_domain;\r\nreturn cfg;\r\nout_domain:\r\nfree_cpumask_var(cfg->domain);\r\nout_cfg:\r\nkfree(cfg);\r\nreturn NULL;\r\n}\r\nstatic void free_irq_cfg(unsigned int at, struct irq_cfg *cfg)\r\n{\r\nif (!cfg)\r\nreturn;\r\nirq_set_chip_data(at, NULL);\r\nfree_cpumask_var(cfg->domain);\r\nfree_cpumask_var(cfg->old_domain);\r\nkfree(cfg);\r\n}\r\nstatic struct irq_cfg *alloc_irq_and_cfg_at(unsigned int at, int node)\r\n{\r\nint res = irq_alloc_desc_at(at, node);\r\nstruct irq_cfg *cfg;\r\nif (res < 0) {\r\nif (res != -EEXIST)\r\nreturn NULL;\r\ncfg = irq_get_chip_data(at);\r\nif (cfg)\r\nreturn cfg;\r\n}\r\ncfg = alloc_irq_cfg(at, node);\r\nif (cfg)\r\nirq_set_chip_data(at, cfg);\r\nelse\r\nirq_free_desc(at);\r\nreturn cfg;\r\n}\r\nstatic int alloc_irqs_from(unsigned int from, unsigned int count, int node)\r\n{\r\nreturn irq_alloc_descs_from(from, count, node);\r\n}\r\nstatic void free_irq_at(unsigned int at, struct irq_cfg *cfg)\r\n{\r\nfree_irq_cfg(at, cfg);\r\nirq_free_desc(at);\r\n}\r\nvoid io_apic_eoi(unsigned int apic, unsigned int vector)\r\n{\r\nstruct io_apic __iomem *io_apic = io_apic_base(apic);\r\nwritel(vector, &io_apic->eoi);\r\n}\r\nunsigned int native_io_apic_read(unsigned int apic, unsigned int reg)\r\n{\r\nstruct io_apic __iomem *io_apic = io_apic_base(apic);\r\nwritel(reg, &io_apic->index);\r\nreturn readl(&io_apic->data);\r\n}\r\nvoid native_io_apic_write(unsigned int apic, unsigned int reg, unsigned int value)\r\n{\r\nstruct io_apic __iomem *io_apic = io_apic_base(apic);\r\nwritel(reg, &io_apic->index);\r\nwritel(value, &io_apic->data);\r\n}\r\nvoid native_io_apic_modify(unsigned int apic, unsigned int reg, unsigned int value)\r\n{\r\nstruct io_apic __iomem *io_apic = io_apic_base(apic);\r\nif (sis_apic_bug)\r\nwritel(reg, &io_apic->index);\r\nwritel(value, &io_apic->data);\r\n}\r\nstatic struct IO_APIC_route_entry __ioapic_read_entry(int apic, int pin)\r\n{\r\nunion entry_union eu;\r\neu.w1 = io_apic_read(apic, 0x10 + 2 * pin);\r\neu.w2 = io_apic_read(apic, 0x11 + 2 * pin);\r\nreturn eu.entry;\r\n}\r\nstatic struct IO_APIC_route_entry ioapic_read_entry(int apic, int pin)\r\n{\r\nunion entry_union eu;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\neu.entry = __ioapic_read_entry(apic, pin);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nreturn eu.entry;\r\n}\r\nstatic void __ioapic_write_entry(int apic, int pin, struct IO_APIC_route_entry e)\r\n{\r\nunion entry_union eu = {{0, 0}};\r\neu.entry = e;\r\nio_apic_write(apic, 0x11 + 2*pin, eu.w2);\r\nio_apic_write(apic, 0x10 + 2*pin, eu.w1);\r\n}\r\nstatic void ioapic_write_entry(int apic, int pin, struct IO_APIC_route_entry e)\r\n{\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\n__ioapic_write_entry(apic, pin, e);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\n}\r\nstatic void ioapic_mask_entry(int apic, int pin)\r\n{\r\nunsigned long flags;\r\nunion entry_union eu = { .entry.mask = 1 };\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nio_apic_write(apic, 0x10 + 2*pin, eu.w1);\r\nio_apic_write(apic, 0x11 + 2*pin, eu.w2);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\n}\r\nstatic int __add_pin_to_irq_node(struct irq_cfg *cfg, int node, int apic, int pin)\r\n{\r\nstruct irq_pin_list **last, *entry;\r\nlast = &cfg->irq_2_pin;\r\nfor_each_irq_pin(entry, cfg->irq_2_pin) {\r\nif (entry->apic == apic && entry->pin == pin)\r\nreturn 0;\r\nlast = &entry->next;\r\n}\r\nentry = alloc_irq_pin_list(node);\r\nif (!entry) {\r\npr_err("can not alloc irq_pin_list (%d,%d,%d)\n",\r\nnode, apic, pin);\r\nreturn -ENOMEM;\r\n}\r\nentry->apic = apic;\r\nentry->pin = pin;\r\n*last = entry;\r\nreturn 0;\r\n}\r\nstatic void add_pin_to_irq_node(struct irq_cfg *cfg, int node, int apic, int pin)\r\n{\r\nif (__add_pin_to_irq_node(cfg, node, apic, pin))\r\npanic("IO-APIC: failed to add irq-pin. Can not proceed\n");\r\n}\r\nstatic void __init replace_pin_at_irq_node(struct irq_cfg *cfg, int node,\r\nint oldapic, int oldpin,\r\nint newapic, int newpin)\r\n{\r\nstruct irq_pin_list *entry;\r\nfor_each_irq_pin(entry, cfg->irq_2_pin) {\r\nif (entry->apic == oldapic && entry->pin == oldpin) {\r\nentry->apic = newapic;\r\nentry->pin = newpin;\r\nreturn;\r\n}\r\n}\r\nadd_pin_to_irq_node(cfg, node, newapic, newpin);\r\n}\r\nstatic void __io_apic_modify_irq(struct irq_pin_list *entry,\r\nint mask_and, int mask_or,\r\nvoid (*final)(struct irq_pin_list *entry))\r\n{\r\nunsigned int reg, pin;\r\npin = entry->pin;\r\nreg = io_apic_read(entry->apic, 0x10 + pin * 2);\r\nreg &= mask_and;\r\nreg |= mask_or;\r\nio_apic_modify(entry->apic, 0x10 + pin * 2, reg);\r\nif (final)\r\nfinal(entry);\r\n}\r\nstatic void io_apic_modify_irq(struct irq_cfg *cfg,\r\nint mask_and, int mask_or,\r\nvoid (*final)(struct irq_pin_list *entry))\r\n{\r\nstruct irq_pin_list *entry;\r\nfor_each_irq_pin(entry, cfg->irq_2_pin)\r\n__io_apic_modify_irq(entry, mask_and, mask_or, final);\r\n}\r\nstatic void io_apic_sync(struct irq_pin_list *entry)\r\n{\r\nstruct io_apic __iomem *io_apic;\r\nio_apic = io_apic_base(entry->apic);\r\nreadl(&io_apic->data);\r\n}\r\nstatic void mask_ioapic(struct irq_cfg *cfg)\r\n{\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nio_apic_modify_irq(cfg, ~0, IO_APIC_REDIR_MASKED, &io_apic_sync);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\n}\r\nstatic void mask_ioapic_irq(struct irq_data *data)\r\n{\r\nmask_ioapic(data->chip_data);\r\n}\r\nstatic void __unmask_ioapic(struct irq_cfg *cfg)\r\n{\r\nio_apic_modify_irq(cfg, ~IO_APIC_REDIR_MASKED, 0, NULL);\r\n}\r\nstatic void unmask_ioapic(struct irq_cfg *cfg)\r\n{\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\n__unmask_ioapic(cfg);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\n}\r\nstatic void unmask_ioapic_irq(struct irq_data *data)\r\n{\r\nunmask_ioapic(data->chip_data);\r\n}\r\nvoid native_eoi_ioapic_pin(int apic, int pin, int vector)\r\n{\r\nif (mpc_ioapic_ver(apic) >= 0x20) {\r\nio_apic_eoi(apic, vector);\r\n} else {\r\nstruct IO_APIC_route_entry entry, entry1;\r\nentry = entry1 = __ioapic_read_entry(apic, pin);\r\nentry1.mask = 1;\r\nentry1.trigger = IOAPIC_EDGE;\r\n__ioapic_write_entry(apic, pin, entry1);\r\n__ioapic_write_entry(apic, pin, entry);\r\n}\r\n}\r\nvoid eoi_ioapic_irq(unsigned int irq, struct irq_cfg *cfg)\r\n{\r\nstruct irq_pin_list *entry;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nfor_each_irq_pin(entry, cfg->irq_2_pin)\r\nx86_io_apic_ops.eoi_ioapic_pin(entry->apic, entry->pin,\r\ncfg->vector);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\n}\r\nstatic void clear_IO_APIC_pin(unsigned int apic, unsigned int pin)\r\n{\r\nstruct IO_APIC_route_entry entry;\r\nentry = ioapic_read_entry(apic, pin);\r\nif (entry.delivery_mode == dest_SMI)\r\nreturn;\r\nif (!entry.mask) {\r\nentry.mask = 1;\r\nioapic_write_entry(apic, pin, entry);\r\nentry = ioapic_read_entry(apic, pin);\r\n}\r\nif (entry.irr) {\r\nunsigned long flags;\r\nif (!entry.trigger) {\r\nentry.trigger = IOAPIC_LEVEL;\r\nioapic_write_entry(apic, pin, entry);\r\n}\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nx86_io_apic_ops.eoi_ioapic_pin(apic, pin, entry.vector);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\n}\r\nioapic_mask_entry(apic, pin);\r\nentry = ioapic_read_entry(apic, pin);\r\nif (entry.irr)\r\npr_err("Unable to reset IRR for apic: %d, pin :%d\n",\r\nmpc_ioapic_id(apic), pin);\r\n}\r\nstatic void clear_IO_APIC (void)\r\n{\r\nint apic, pin;\r\nfor (apic = 0; apic < nr_ioapics; apic++)\r\nfor (pin = 0; pin < ioapics[apic].nr_registers; pin++)\r\nclear_IO_APIC_pin(apic, pin);\r\n}\r\nstatic int __init ioapic_pirq_setup(char *str)\r\n{\r\nint i, max;\r\nint ints[MAX_PIRQS+1];\r\nget_options(str, ARRAY_SIZE(ints), ints);\r\napic_printk(APIC_VERBOSE, KERN_INFO\r\n"PIRQ redirection, working around broken MP-BIOS.\n");\r\nmax = MAX_PIRQS;\r\nif (ints[0] < MAX_PIRQS)\r\nmax = ints[0];\r\nfor (i = 0; i < max; i++) {\r\napic_printk(APIC_VERBOSE, KERN_DEBUG\r\n"... PIRQ%d -> IRQ %d\n", i, ints[i+1]);\r\npirq_entries[MAX_PIRQS-i-1] = ints[i+1];\r\n}\r\nreturn 1;\r\n}\r\nint save_ioapic_entries(void)\r\n{\r\nint apic, pin;\r\nint err = 0;\r\nfor (apic = 0; apic < nr_ioapics; apic++) {\r\nif (!ioapics[apic].saved_registers) {\r\nerr = -ENOMEM;\r\ncontinue;\r\n}\r\nfor (pin = 0; pin < ioapics[apic].nr_registers; pin++)\r\nioapics[apic].saved_registers[pin] =\r\nioapic_read_entry(apic, pin);\r\n}\r\nreturn err;\r\n}\r\nvoid mask_ioapic_entries(void)\r\n{\r\nint apic, pin;\r\nfor (apic = 0; apic < nr_ioapics; apic++) {\r\nif (!ioapics[apic].saved_registers)\r\ncontinue;\r\nfor (pin = 0; pin < ioapics[apic].nr_registers; pin++) {\r\nstruct IO_APIC_route_entry entry;\r\nentry = ioapics[apic].saved_registers[pin];\r\nif (!entry.mask) {\r\nentry.mask = 1;\r\nioapic_write_entry(apic, pin, entry);\r\n}\r\n}\r\n}\r\n}\r\nint restore_ioapic_entries(void)\r\n{\r\nint apic, pin;\r\nfor (apic = 0; apic < nr_ioapics; apic++) {\r\nif (!ioapics[apic].saved_registers)\r\ncontinue;\r\nfor (pin = 0; pin < ioapics[apic].nr_registers; pin++)\r\nioapic_write_entry(apic, pin,\r\nioapics[apic].saved_registers[pin]);\r\n}\r\nreturn 0;\r\n}\r\nstatic int find_irq_entry(int ioapic_idx, int pin, int type)\r\n{\r\nint i;\r\nfor (i = 0; i < mp_irq_entries; i++)\r\nif (mp_irqs[i].irqtype == type &&\r\n(mp_irqs[i].dstapic == mpc_ioapic_id(ioapic_idx) ||\r\nmp_irqs[i].dstapic == MP_APIC_ALL) &&\r\nmp_irqs[i].dstirq == pin)\r\nreturn i;\r\nreturn -1;\r\n}\r\nstatic int __init find_isa_irq_pin(int irq, int type)\r\n{\r\nint i;\r\nfor (i = 0; i < mp_irq_entries; i++) {\r\nint lbus = mp_irqs[i].srcbus;\r\nif (test_bit(lbus, mp_bus_not_pci) &&\r\n(mp_irqs[i].irqtype == type) &&\r\n(mp_irqs[i].srcbusirq == irq))\r\nreturn mp_irqs[i].dstirq;\r\n}\r\nreturn -1;\r\n}\r\nstatic int __init find_isa_irq_apic(int irq, int type)\r\n{\r\nint i;\r\nfor (i = 0; i < mp_irq_entries; i++) {\r\nint lbus = mp_irqs[i].srcbus;\r\nif (test_bit(lbus, mp_bus_not_pci) &&\r\n(mp_irqs[i].irqtype == type) &&\r\n(mp_irqs[i].srcbusirq == irq))\r\nbreak;\r\n}\r\nif (i < mp_irq_entries) {\r\nint ioapic_idx;\r\nfor (ioapic_idx = 0; ioapic_idx < nr_ioapics; ioapic_idx++)\r\nif (mpc_ioapic_id(ioapic_idx) == mp_irqs[i].dstapic)\r\nreturn ioapic_idx;\r\n}\r\nreturn -1;\r\n}\r\nstatic int EISA_ELCR(unsigned int irq)\r\n{\r\nif (irq < legacy_pic->nr_legacy_irqs) {\r\nunsigned int port = 0x4d0 + (irq >> 3);\r\nreturn (inb(port) >> (irq & 7)) & 1;\r\n}\r\napic_printk(APIC_VERBOSE, KERN_INFO\r\n"Broken MPtable reports ISA irq %d\n", irq);\r\nreturn 0;\r\n}\r\nstatic int irq_polarity(int idx)\r\n{\r\nint bus = mp_irqs[idx].srcbus;\r\nint polarity;\r\nswitch (mp_irqs[idx].irqflag & 3)\r\n{\r\ncase 0:\r\nif (test_bit(bus, mp_bus_not_pci))\r\npolarity = default_ISA_polarity(idx);\r\nelse\r\npolarity = default_PCI_polarity(idx);\r\nbreak;\r\ncase 1:\r\n{\r\npolarity = 0;\r\nbreak;\r\n}\r\ncase 2:\r\n{\r\npr_warn("broken BIOS!!\n");\r\npolarity = 1;\r\nbreak;\r\n}\r\ncase 3:\r\n{\r\npolarity = 1;\r\nbreak;\r\n}\r\ndefault:\r\n{\r\npr_warn("broken BIOS!!\n");\r\npolarity = 1;\r\nbreak;\r\n}\r\n}\r\nreturn polarity;\r\n}\r\nstatic int irq_trigger(int idx)\r\n{\r\nint bus = mp_irqs[idx].srcbus;\r\nint trigger;\r\nswitch ((mp_irqs[idx].irqflag>>2) & 3)\r\n{\r\ncase 0:\r\nif (test_bit(bus, mp_bus_not_pci))\r\ntrigger = default_ISA_trigger(idx);\r\nelse\r\ntrigger = default_PCI_trigger(idx);\r\n#ifdef CONFIG_EISA\r\nswitch (mp_bus_id_to_type[bus]) {\r\ncase MP_BUS_ISA:\r\n{\r\nbreak;\r\n}\r\ncase MP_BUS_EISA:\r\n{\r\ntrigger = default_EISA_trigger(idx);\r\nbreak;\r\n}\r\ncase MP_BUS_PCI:\r\n{\r\nbreak;\r\n}\r\ndefault:\r\n{\r\npr_warn("broken BIOS!!\n");\r\ntrigger = 1;\r\nbreak;\r\n}\r\n}\r\n#endif\r\nbreak;\r\ncase 1:\r\n{\r\ntrigger = 0;\r\nbreak;\r\n}\r\ncase 2:\r\n{\r\npr_warn("broken BIOS!!\n");\r\ntrigger = 1;\r\nbreak;\r\n}\r\ncase 3:\r\n{\r\ntrigger = 1;\r\nbreak;\r\n}\r\ndefault:\r\n{\r\npr_warn("broken BIOS!!\n");\r\ntrigger = 0;\r\nbreak;\r\n}\r\n}\r\nreturn trigger;\r\n}\r\nstatic int pin_2_irq(int idx, int apic, int pin)\r\n{\r\nint irq;\r\nint bus = mp_irqs[idx].srcbus;\r\nstruct mp_ioapic_gsi *gsi_cfg = mp_ioapic_gsi_routing(apic);\r\nif (mp_irqs[idx].dstirq != pin)\r\npr_err("broken BIOS or MPTABLE parser, ayiee!!\n");\r\nif (test_bit(bus, mp_bus_not_pci)) {\r\nirq = mp_irqs[idx].srcbusirq;\r\n} else {\r\nu32 gsi = gsi_cfg->gsi_base + pin;\r\nif (gsi >= NR_IRQS_LEGACY)\r\nirq = gsi;\r\nelse\r\nirq = gsi_top + gsi;\r\n}\r\n#ifdef CONFIG_X86_32\r\nif ((pin >= 16) && (pin <= 23)) {\r\nif (pirq_entries[pin-16] != -1) {\r\nif (!pirq_entries[pin-16]) {\r\napic_printk(APIC_VERBOSE, KERN_DEBUG\r\n"disabling PIRQ%d\n", pin-16);\r\n} else {\r\nirq = pirq_entries[pin-16];\r\napic_printk(APIC_VERBOSE, KERN_DEBUG\r\n"using PIRQ%d -> IRQ %d\n",\r\npin-16, irq);\r\n}\r\n}\r\n}\r\n#endif\r\nreturn irq;\r\n}\r\nint IO_APIC_get_PCI_irq_vector(int bus, int slot, int pin,\r\nstruct io_apic_irq_attr *irq_attr)\r\n{\r\nint ioapic_idx, i, best_guess = -1;\r\napic_printk(APIC_DEBUG,\r\n"querying PCI -> IRQ mapping bus:%d, slot:%d, pin:%d.\n",\r\nbus, slot, pin);\r\nif (test_bit(bus, mp_bus_not_pci)) {\r\napic_printk(APIC_VERBOSE,\r\n"PCI BIOS passed nonexistent PCI bus %d!\n", bus);\r\nreturn -1;\r\n}\r\nfor (i = 0; i < mp_irq_entries; i++) {\r\nint lbus = mp_irqs[i].srcbus;\r\nfor (ioapic_idx = 0; ioapic_idx < nr_ioapics; ioapic_idx++)\r\nif (mpc_ioapic_id(ioapic_idx) == mp_irqs[i].dstapic ||\r\nmp_irqs[i].dstapic == MP_APIC_ALL)\r\nbreak;\r\nif (!test_bit(lbus, mp_bus_not_pci) &&\r\n!mp_irqs[i].irqtype &&\r\n(bus == lbus) &&\r\n(slot == ((mp_irqs[i].srcbusirq >> 2) & 0x1f))) {\r\nint irq = pin_2_irq(i, ioapic_idx, mp_irqs[i].dstirq);\r\nif (!(ioapic_idx || IO_APIC_IRQ(irq)))\r\ncontinue;\r\nif (pin == (mp_irqs[i].srcbusirq & 3)) {\r\nset_io_apic_irq_attr(irq_attr, ioapic_idx,\r\nmp_irqs[i].dstirq,\r\nirq_trigger(i),\r\nirq_polarity(i));\r\nreturn irq;\r\n}\r\nif (best_guess < 0) {\r\nset_io_apic_irq_attr(irq_attr, ioapic_idx,\r\nmp_irqs[i].dstirq,\r\nirq_trigger(i),\r\nirq_polarity(i));\r\nbest_guess = irq;\r\n}\r\n}\r\n}\r\nreturn best_guess;\r\n}\r\nvoid lock_vector_lock(void)\r\n{\r\nraw_spin_lock(&vector_lock);\r\n}\r\nvoid unlock_vector_lock(void)\r\n{\r\nraw_spin_unlock(&vector_lock);\r\n}\r\nstatic int\r\n__assign_irq_vector(int irq, struct irq_cfg *cfg, const struct cpumask *mask)\r\n{\r\nstatic int current_vector = FIRST_EXTERNAL_VECTOR + VECTOR_OFFSET_START;\r\nstatic int current_offset = VECTOR_OFFSET_START % 16;\r\nint cpu, err;\r\ncpumask_var_t tmp_mask;\r\nif (cfg->move_in_progress)\r\nreturn -EBUSY;\r\nif (!alloc_cpumask_var(&tmp_mask, GFP_ATOMIC))\r\nreturn -ENOMEM;\r\nerr = -ENOSPC;\r\ncpumask_clear(cfg->old_domain);\r\ncpu = cpumask_first_and(mask, cpu_online_mask);\r\nwhile (cpu < nr_cpu_ids) {\r\nint new_cpu, vector, offset;\r\napic->vector_allocation_domain(cpu, tmp_mask, mask);\r\nif (cpumask_subset(tmp_mask, cfg->domain)) {\r\nerr = 0;\r\nif (cpumask_equal(tmp_mask, cfg->domain))\r\nbreak;\r\ncpumask_andnot(cfg->old_domain, cfg->domain, tmp_mask);\r\ncfg->move_in_progress =\r\ncpumask_intersects(cfg->old_domain, cpu_online_mask);\r\ncpumask_and(cfg->domain, cfg->domain, tmp_mask);\r\nbreak;\r\n}\r\nvector = current_vector;\r\noffset = current_offset;\r\nnext:\r\nvector += 16;\r\nif (vector >= first_system_vector) {\r\noffset = (offset + 1) % 16;\r\nvector = FIRST_EXTERNAL_VECTOR + offset;\r\n}\r\nif (unlikely(current_vector == vector)) {\r\ncpumask_or(cfg->old_domain, cfg->old_domain, tmp_mask);\r\ncpumask_andnot(tmp_mask, mask, cfg->old_domain);\r\ncpu = cpumask_first_and(tmp_mask, cpu_online_mask);\r\ncontinue;\r\n}\r\nif (test_bit(vector, used_vectors))\r\ngoto next;\r\nfor_each_cpu_and(new_cpu, tmp_mask, cpu_online_mask)\r\nif (per_cpu(vector_irq, new_cpu)[vector] != -1)\r\ngoto next;\r\ncurrent_vector = vector;\r\ncurrent_offset = offset;\r\nif (cfg->vector) {\r\ncpumask_copy(cfg->old_domain, cfg->domain);\r\ncfg->move_in_progress =\r\ncpumask_intersects(cfg->old_domain, cpu_online_mask);\r\n}\r\nfor_each_cpu_and(new_cpu, tmp_mask, cpu_online_mask)\r\nper_cpu(vector_irq, new_cpu)[vector] = irq;\r\ncfg->vector = vector;\r\ncpumask_copy(cfg->domain, tmp_mask);\r\nerr = 0;\r\nbreak;\r\n}\r\nfree_cpumask_var(tmp_mask);\r\nreturn err;\r\n}\r\nint assign_irq_vector(int irq, struct irq_cfg *cfg, const struct cpumask *mask)\r\n{\r\nint err;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&vector_lock, flags);\r\nerr = __assign_irq_vector(irq, cfg, mask);\r\nraw_spin_unlock_irqrestore(&vector_lock, flags);\r\nreturn err;\r\n}\r\nstatic void __clear_irq_vector(int irq, struct irq_cfg *cfg)\r\n{\r\nint cpu, vector;\r\nBUG_ON(!cfg->vector);\r\nvector = cfg->vector;\r\nfor_each_cpu_and(cpu, cfg->domain, cpu_online_mask)\r\nper_cpu(vector_irq, cpu)[vector] = -1;\r\ncfg->vector = 0;\r\ncpumask_clear(cfg->domain);\r\nif (likely(!cfg->move_in_progress))\r\nreturn;\r\nfor_each_cpu_and(cpu, cfg->old_domain, cpu_online_mask) {\r\nfor (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS;\r\nvector++) {\r\nif (per_cpu(vector_irq, cpu)[vector] != irq)\r\ncontinue;\r\nper_cpu(vector_irq, cpu)[vector] = -1;\r\nbreak;\r\n}\r\n}\r\ncfg->move_in_progress = 0;\r\n}\r\nvoid __setup_vector_irq(int cpu)\r\n{\r\nint irq, vector;\r\nstruct irq_cfg *cfg;\r\nraw_spin_lock(&vector_lock);\r\nfor_each_active_irq(irq) {\r\ncfg = irq_get_chip_data(irq);\r\nif (!cfg)\r\ncontinue;\r\nif (!cpumask_test_cpu(cpu, cfg->domain))\r\ncontinue;\r\nvector = cfg->vector;\r\nper_cpu(vector_irq, cpu)[vector] = irq;\r\n}\r\nfor (vector = 0; vector < NR_VECTORS; ++vector) {\r\nirq = per_cpu(vector_irq, cpu)[vector];\r\nif (irq < 0)\r\ncontinue;\r\ncfg = irq_cfg(irq);\r\nif (!cpumask_test_cpu(cpu, cfg->domain))\r\nper_cpu(vector_irq, cpu)[vector] = -1;\r\n}\r\nraw_spin_unlock(&vector_lock);\r\n}\r\nstatic inline int IO_APIC_irq_trigger(int irq)\r\n{\r\nint apic, idx, pin;\r\nfor (apic = 0; apic < nr_ioapics; apic++) {\r\nfor (pin = 0; pin < ioapics[apic].nr_registers; pin++) {\r\nidx = find_irq_entry(apic, pin, mp_INT);\r\nif ((idx != -1) && (irq == pin_2_irq(idx, apic, pin)))\r\nreturn irq_trigger(idx);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic inline int IO_APIC_irq_trigger(int irq)\r\n{\r\nreturn 1;\r\n}\r\nstatic void ioapic_register_intr(unsigned int irq, struct irq_cfg *cfg,\r\nunsigned long trigger)\r\n{\r\nstruct irq_chip *chip = &ioapic_chip;\r\nirq_flow_handler_t hdl;\r\nbool fasteoi;\r\nif ((trigger == IOAPIC_AUTO && IO_APIC_irq_trigger(irq)) ||\r\ntrigger == IOAPIC_LEVEL) {\r\nirq_set_status_flags(irq, IRQ_LEVEL);\r\nfasteoi = true;\r\n} else {\r\nirq_clear_status_flags(irq, IRQ_LEVEL);\r\nfasteoi = false;\r\n}\r\nif (setup_remapped_irq(irq, cfg, chip))\r\nfasteoi = trigger != 0;\r\nhdl = fasteoi ? handle_fasteoi_irq : handle_edge_irq;\r\nirq_set_chip_and_handler_name(irq, chip, hdl,\r\nfasteoi ? "fasteoi" : "edge");\r\n}\r\nint native_setup_ioapic_entry(int irq, struct IO_APIC_route_entry *entry,\r\nunsigned int destination, int vector,\r\nstruct io_apic_irq_attr *attr)\r\n{\r\nmemset(entry, 0, sizeof(*entry));\r\nentry->delivery_mode = apic->irq_delivery_mode;\r\nentry->dest_mode = apic->irq_dest_mode;\r\nentry->dest = destination;\r\nentry->vector = vector;\r\nentry->mask = 0;\r\nentry->trigger = attr->trigger;\r\nentry->polarity = attr->polarity;\r\nif (attr->trigger)\r\nentry->mask = 1;\r\nreturn 0;\r\n}\r\nstatic void setup_ioapic_irq(unsigned int irq, struct irq_cfg *cfg,\r\nstruct io_apic_irq_attr *attr)\r\n{\r\nstruct IO_APIC_route_entry entry;\r\nunsigned int dest;\r\nif (!IO_APIC_IRQ(irq))\r\nreturn;\r\nif (assign_irq_vector(irq, cfg, apic->target_cpus()))\r\nreturn;\r\nif (apic->cpu_mask_to_apicid_and(cfg->domain, apic->target_cpus(),\r\n&dest)) {\r\npr_warn("Failed to obtain apicid for ioapic %d, pin %d\n",\r\nmpc_ioapic_id(attr->ioapic), attr->ioapic_pin);\r\n__clear_irq_vector(irq, cfg);\r\nreturn;\r\n}\r\napic_printk(APIC_VERBOSE,KERN_DEBUG\r\n"IOAPIC[%d]: Set routing entry (%d-%d -> 0x%x -> "\r\n"IRQ %d Mode:%i Active:%i Dest:%d)\n",\r\nattr->ioapic, mpc_ioapic_id(attr->ioapic), attr->ioapic_pin,\r\ncfg->vector, irq, attr->trigger, attr->polarity, dest);\r\nif (x86_io_apic_ops.setup_entry(irq, &entry, dest, cfg->vector, attr)) {\r\npr_warn("Failed to setup ioapic entry for ioapic %d, pin %d\n",\r\nmpc_ioapic_id(attr->ioapic), attr->ioapic_pin);\r\n__clear_irq_vector(irq, cfg);\r\nreturn;\r\n}\r\nioapic_register_intr(irq, cfg, attr->trigger);\r\nif (irq < legacy_pic->nr_legacy_irqs)\r\nlegacy_pic->mask(irq);\r\nioapic_write_entry(attr->ioapic, attr->ioapic_pin, entry);\r\n}\r\nstatic bool __init io_apic_pin_not_connected(int idx, int ioapic_idx, int pin)\r\n{\r\nif (idx != -1)\r\nreturn false;\r\napic_printk(APIC_VERBOSE, KERN_DEBUG " apic %d pin %d not connected\n",\r\nmpc_ioapic_id(ioapic_idx), pin);\r\nreturn true;\r\n}\r\nstatic void __init __io_apic_setup_irqs(unsigned int ioapic_idx)\r\n{\r\nint idx, node = cpu_to_node(0);\r\nstruct io_apic_irq_attr attr;\r\nunsigned int pin, irq;\r\nfor (pin = 0; pin < ioapics[ioapic_idx].nr_registers; pin++) {\r\nidx = find_irq_entry(ioapic_idx, pin, mp_INT);\r\nif (io_apic_pin_not_connected(idx, ioapic_idx, pin))\r\ncontinue;\r\nirq = pin_2_irq(idx, ioapic_idx, pin);\r\nif ((ioapic_idx > 0) && (irq > 16))\r\ncontinue;\r\nif (apic->multi_timer_check &&\r\napic->multi_timer_check(ioapic_idx, irq))\r\ncontinue;\r\nset_io_apic_irq_attr(&attr, ioapic_idx, pin, irq_trigger(idx),\r\nirq_polarity(idx));\r\nio_apic_setup_irq_pin(irq, node, &attr);\r\n}\r\n}\r\nstatic void __init setup_IO_APIC_irqs(void)\r\n{\r\nunsigned int ioapic_idx;\r\napic_printk(APIC_VERBOSE, KERN_DEBUG "init IO_APIC IRQs\n");\r\nfor (ioapic_idx = 0; ioapic_idx < nr_ioapics; ioapic_idx++)\r\n__io_apic_setup_irqs(ioapic_idx);\r\n}\r\nvoid setup_IO_APIC_irq_extra(u32 gsi)\r\n{\r\nint ioapic_idx = 0, pin, idx, irq, node = cpu_to_node(0);\r\nstruct io_apic_irq_attr attr;\r\nioapic_idx = mp_find_ioapic(gsi);\r\nif (ioapic_idx < 0)\r\nreturn;\r\npin = mp_find_ioapic_pin(ioapic_idx, gsi);\r\nidx = find_irq_entry(ioapic_idx, pin, mp_INT);\r\nif (idx == -1)\r\nreturn;\r\nirq = pin_2_irq(idx, ioapic_idx, pin);\r\nif (ioapic_idx == 0 || irq < NR_IRQS_LEGACY)\r\nreturn;\r\nset_io_apic_irq_attr(&attr, ioapic_idx, pin, irq_trigger(idx),\r\nirq_polarity(idx));\r\nio_apic_setup_irq_pin_once(irq, node, &attr);\r\n}\r\nstatic void __init setup_timer_IRQ0_pin(unsigned int ioapic_idx,\r\nunsigned int pin, int vector)\r\n{\r\nstruct IO_APIC_route_entry entry;\r\nunsigned int dest;\r\nmemset(&entry, 0, sizeof(entry));\r\nif (unlikely(apic->cpu_mask_to_apicid_and(apic->target_cpus(),\r\napic->target_cpus(), &dest)))\r\ndest = BAD_APICID;\r\nentry.dest_mode = apic->irq_dest_mode;\r\nentry.mask = 0;\r\nentry.dest = dest;\r\nentry.delivery_mode = apic->irq_delivery_mode;\r\nentry.polarity = 0;\r\nentry.trigger = 0;\r\nentry.vector = vector;\r\nirq_set_chip_and_handler_name(0, &ioapic_chip, handle_edge_irq,\r\n"edge");\r\nioapic_write_entry(ioapic_idx, pin, entry);\r\n}\r\nvoid native_io_apic_print_entries(unsigned int apic, unsigned int nr_entries)\r\n{\r\nint i;\r\npr_debug(" NR Dst Mask Trig IRR Pol Stat Dmod Deli Vect:\n");\r\nfor (i = 0; i <= nr_entries; i++) {\r\nstruct IO_APIC_route_entry entry;\r\nentry = ioapic_read_entry(apic, i);\r\npr_debug(" %02x %02X ", i, entry.dest);\r\npr_cont("%1d %1d %1d %1d %1d "\r\n"%1d %1d %02X\n",\r\nentry.mask,\r\nentry.trigger,\r\nentry.irr,\r\nentry.polarity,\r\nentry.delivery_status,\r\nentry.dest_mode,\r\nentry.delivery_mode,\r\nentry.vector);\r\n}\r\n}\r\nvoid intel_ir_io_apic_print_entries(unsigned int apic,\r\nunsigned int nr_entries)\r\n{\r\nint i;\r\npr_debug(" NR Indx Fmt Mask Trig IRR Pol Stat Indx2 Zero Vect:\n");\r\nfor (i = 0; i <= nr_entries; i++) {\r\nstruct IR_IO_APIC_route_entry *ir_entry;\r\nstruct IO_APIC_route_entry entry;\r\nentry = ioapic_read_entry(apic, i);\r\nir_entry = (struct IR_IO_APIC_route_entry *)&entry;\r\npr_debug(" %02x %04X ", i, ir_entry->index);\r\npr_cont("%1d %1d %1d %1d %1d "\r\n"%1d %1d %X %02X\n",\r\nir_entry->format,\r\nir_entry->mask,\r\nir_entry->trigger,\r\nir_entry->irr,\r\nir_entry->polarity,\r\nir_entry->delivery_status,\r\nir_entry->index2,\r\nir_entry->zero,\r\nir_entry->vector);\r\n}\r\n}\r\nvoid ioapic_zap_locks(void)\r\n{\r\nraw_spin_lock_init(&ioapic_lock);\r\n}\r\nstatic __init int setup_show_lapic(char *arg)\r\n{\r\nint num = -1;\r\nif (strcmp(arg, "all") == 0) {\r\nshow_lapic = CONFIG_NR_CPUS;\r\n} else {\r\nget_option(&arg, &num);\r\nif (num >= 0)\r\nshow_lapic = num;\r\n}\r\nreturn 1;\r\n}\r\nvoid __init enable_IO_APIC(void)\r\n{\r\nint i8259_apic, i8259_pin;\r\nint apic;\r\nif (!legacy_pic->nr_legacy_irqs)\r\nreturn;\r\nfor(apic = 0; apic < nr_ioapics; apic++) {\r\nint pin;\r\nfor (pin = 0; pin < ioapics[apic].nr_registers; pin++) {\r\nstruct IO_APIC_route_entry entry;\r\nentry = ioapic_read_entry(apic, pin);\r\nif ((entry.mask == 0) && (entry.delivery_mode == dest_ExtINT)) {\r\nioapic_i8259.apic = apic;\r\nioapic_i8259.pin = pin;\r\ngoto found_i8259;\r\n}\r\n}\r\n}\r\nfound_i8259:\r\ni8259_pin = find_isa_irq_pin(0, mp_ExtINT);\r\ni8259_apic = find_isa_irq_apic(0, mp_ExtINT);\r\nif ((ioapic_i8259.pin == -1) && (i8259_pin >= 0)) {\r\nprintk(KERN_WARNING "ExtINT not setup in hardware but reported by MP table\n");\r\nioapic_i8259.pin = i8259_pin;\r\nioapic_i8259.apic = i8259_apic;\r\n}\r\nif (((ioapic_i8259.apic != i8259_apic) || (ioapic_i8259.pin != i8259_pin)) &&\r\n(i8259_pin >= 0) && (ioapic_i8259.pin >= 0))\r\n{\r\nprintk(KERN_WARNING "ExtINT in hardware and MP table differ\n");\r\n}\r\nclear_IO_APIC();\r\n}\r\nvoid native_disable_io_apic(void)\r\n{\r\nif (ioapic_i8259.pin != -1) {\r\nstruct IO_APIC_route_entry entry;\r\nmemset(&entry, 0, sizeof(entry));\r\nentry.mask = 0;\r\nentry.trigger = 0;\r\nentry.irr = 0;\r\nentry.polarity = 0;\r\nentry.delivery_status = 0;\r\nentry.dest_mode = 0;\r\nentry.delivery_mode = dest_ExtINT;\r\nentry.vector = 0;\r\nentry.dest = read_apic_id();\r\nioapic_write_entry(ioapic_i8259.apic, ioapic_i8259.pin, entry);\r\n}\r\nif (cpu_has_apic || apic_from_smp_config())\r\ndisconnect_bsp_APIC(ioapic_i8259.pin != -1);\r\n}\r\nvoid disable_IO_APIC(void)\r\n{\r\nclear_IO_APIC();\r\nif (!legacy_pic->nr_legacy_irqs)\r\nreturn;\r\nx86_io_apic_ops.disable();\r\n}\r\nvoid __init setup_ioapic_ids_from_mpc_nocheck(void)\r\n{\r\nunion IO_APIC_reg_00 reg_00;\r\nphysid_mask_t phys_id_present_map;\r\nint ioapic_idx;\r\nint i;\r\nunsigned char old_id;\r\nunsigned long flags;\r\napic->ioapic_phys_id_map(&phys_cpu_present_map, &phys_id_present_map);\r\nfor (ioapic_idx = 0; ioapic_idx < nr_ioapics; ioapic_idx++) {\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nreg_00.raw = io_apic_read(ioapic_idx, 0);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nold_id = mpc_ioapic_id(ioapic_idx);\r\nif (mpc_ioapic_id(ioapic_idx) >= get_physical_broadcast()) {\r\nprintk(KERN_ERR "BIOS bug, IO-APIC#%d ID is %d in the MPC table!...\n",\r\nioapic_idx, mpc_ioapic_id(ioapic_idx));\r\nprintk(KERN_ERR "... fixing up to %d. (tell your hw vendor)\n",\r\nreg_00.bits.ID);\r\nioapics[ioapic_idx].mp_config.apicid = reg_00.bits.ID;\r\n}\r\nif (apic->check_apicid_used(&phys_id_present_map,\r\nmpc_ioapic_id(ioapic_idx))) {\r\nprintk(KERN_ERR "BIOS bug, IO-APIC#%d ID %d is already used!...\n",\r\nioapic_idx, mpc_ioapic_id(ioapic_idx));\r\nfor (i = 0; i < get_physical_broadcast(); i++)\r\nif (!physid_isset(i, phys_id_present_map))\r\nbreak;\r\nif (i >= get_physical_broadcast())\r\npanic("Max APIC ID exceeded!\n");\r\nprintk(KERN_ERR "... fixing up to %d. (tell your hw vendor)\n",\r\ni);\r\nphysid_set(i, phys_id_present_map);\r\nioapics[ioapic_idx].mp_config.apicid = i;\r\n} else {\r\nphysid_mask_t tmp;\r\napic->apicid_to_cpu_present(mpc_ioapic_id(ioapic_idx),\r\n&tmp);\r\napic_printk(APIC_VERBOSE, "Setting %d in the "\r\n"phys_id_present_map\n",\r\nmpc_ioapic_id(ioapic_idx));\r\nphysids_or(phys_id_present_map, phys_id_present_map, tmp);\r\n}\r\nif (old_id != mpc_ioapic_id(ioapic_idx))\r\nfor (i = 0; i < mp_irq_entries; i++)\r\nif (mp_irqs[i].dstapic == old_id)\r\nmp_irqs[i].dstapic\r\n= mpc_ioapic_id(ioapic_idx);\r\nif (mpc_ioapic_id(ioapic_idx) == reg_00.bits.ID)\r\ncontinue;\r\napic_printk(APIC_VERBOSE, KERN_INFO\r\n"...changing IO-APIC physical APIC ID to %d ...",\r\nmpc_ioapic_id(ioapic_idx));\r\nreg_00.bits.ID = mpc_ioapic_id(ioapic_idx);\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nio_apic_write(ioapic_idx, 0, reg_00.raw);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nreg_00.raw = io_apic_read(ioapic_idx, 0);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nif (reg_00.bits.ID != mpc_ioapic_id(ioapic_idx))\r\npr_cont("could not set ID!\n");\r\nelse\r\napic_printk(APIC_VERBOSE, " ok.\n");\r\n}\r\n}\r\nvoid __init setup_ioapic_ids_from_mpc(void)\r\n{\r\nif (acpi_ioapic)\r\nreturn;\r\nif (!(boot_cpu_data.x86_vendor == X86_VENDOR_INTEL)\r\n|| APIC_XAPIC(apic_version[boot_cpu_physical_apicid]))\r\nreturn;\r\nsetup_ioapic_ids_from_mpc_nocheck();\r\n}\r\nstatic int __init notimercheck(char *s)\r\n{\r\nno_timer_check = 1;\r\nreturn 1;\r\n}\r\nstatic int __init timer_irq_works(void)\r\n{\r\nunsigned long t1 = jiffies;\r\nunsigned long flags;\r\nif (no_timer_check)\r\nreturn 1;\r\nlocal_save_flags(flags);\r\nlocal_irq_enable();\r\nmdelay((10 * 1000) / HZ);\r\nlocal_irq_restore(flags);\r\nif (time_after(jiffies, t1 + 4))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic unsigned int startup_ioapic_irq(struct irq_data *data)\r\n{\r\nint was_pending = 0, irq = data->irq;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nif (irq < legacy_pic->nr_legacy_irqs) {\r\nlegacy_pic->mask(irq);\r\nif (legacy_pic->irq_pending(irq))\r\nwas_pending = 1;\r\n}\r\n__unmask_ioapic(data->chip_data);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nreturn was_pending;\r\n}\r\nstatic int ioapic_retrigger_irq(struct irq_data *data)\r\n{\r\nstruct irq_cfg *cfg = data->chip_data;\r\nunsigned long flags;\r\nint cpu;\r\nraw_spin_lock_irqsave(&vector_lock, flags);\r\ncpu = cpumask_first_and(cfg->domain, cpu_online_mask);\r\napic->send_IPI_mask(cpumask_of(cpu), cfg->vector);\r\nraw_spin_unlock_irqrestore(&vector_lock, flags);\r\nreturn 1;\r\n}\r\nvoid send_cleanup_vector(struct irq_cfg *cfg)\r\n{\r\ncpumask_var_t cleanup_mask;\r\nif (unlikely(!alloc_cpumask_var(&cleanup_mask, GFP_ATOMIC))) {\r\nunsigned int i;\r\nfor_each_cpu_and(i, cfg->old_domain, cpu_online_mask)\r\napic->send_IPI_mask(cpumask_of(i), IRQ_MOVE_CLEANUP_VECTOR);\r\n} else {\r\ncpumask_and(cleanup_mask, cfg->old_domain, cpu_online_mask);\r\napic->send_IPI_mask(cleanup_mask, IRQ_MOVE_CLEANUP_VECTOR);\r\nfree_cpumask_var(cleanup_mask);\r\n}\r\ncfg->move_in_progress = 0;\r\n}\r\nasmlinkage void smp_irq_move_cleanup_interrupt(void)\r\n{\r\nunsigned vector, me;\r\nack_APIC_irq();\r\nirq_enter();\r\nexit_idle();\r\nme = smp_processor_id();\r\nfor (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {\r\nunsigned int irq;\r\nunsigned int irr;\r\nstruct irq_desc *desc;\r\nstruct irq_cfg *cfg;\r\nirq = __this_cpu_read(vector_irq[vector]);\r\nif (irq == -1)\r\ncontinue;\r\ndesc = irq_to_desc(irq);\r\nif (!desc)\r\ncontinue;\r\ncfg = irq_cfg(irq);\r\nif (!cfg)\r\ncontinue;\r\nraw_spin_lock(&desc->lock);\r\nif (cfg->move_in_progress)\r\ngoto unlock;\r\nif (vector == cfg->vector && cpumask_test_cpu(me, cfg->domain))\r\ngoto unlock;\r\nirr = apic_read(APIC_IRR + (vector / 32 * 0x10));\r\nif (irr & (1 << (vector % 32))) {\r\napic->send_IPI_self(IRQ_MOVE_CLEANUP_VECTOR);\r\ngoto unlock;\r\n}\r\n__this_cpu_write(vector_irq[vector], -1);\r\nunlock:\r\nraw_spin_unlock(&desc->lock);\r\n}\r\nirq_exit();\r\n}\r\nstatic void __irq_complete_move(struct irq_cfg *cfg, unsigned vector)\r\n{\r\nunsigned me;\r\nif (likely(!cfg->move_in_progress))\r\nreturn;\r\nme = smp_processor_id();\r\nif (vector == cfg->vector && cpumask_test_cpu(me, cfg->domain))\r\nsend_cleanup_vector(cfg);\r\n}\r\nstatic void irq_complete_move(struct irq_cfg *cfg)\r\n{\r\n__irq_complete_move(cfg, ~get_irq_regs()->orig_ax);\r\n}\r\nvoid irq_force_complete_move(int irq)\r\n{\r\nstruct irq_cfg *cfg = irq_get_chip_data(irq);\r\nif (!cfg)\r\nreturn;\r\n__irq_complete_move(cfg, cfg->vector);\r\n}\r\nstatic inline void irq_complete_move(struct irq_cfg *cfg) { }\r\nstatic void __target_IO_APIC_irq(unsigned int irq, unsigned int dest, struct irq_cfg *cfg)\r\n{\r\nint apic, pin;\r\nstruct irq_pin_list *entry;\r\nu8 vector = cfg->vector;\r\nfor_each_irq_pin(entry, cfg->irq_2_pin) {\r\nunsigned int reg;\r\napic = entry->apic;\r\npin = entry->pin;\r\nio_apic_write(apic, 0x11 + pin*2, dest);\r\nreg = io_apic_read(apic, 0x10 + pin*2);\r\nreg &= ~IO_APIC_REDIR_VECTOR_MASK;\r\nreg |= vector;\r\nio_apic_modify(apic, 0x10 + pin*2, reg);\r\n}\r\n}\r\nint __ioapic_set_affinity(struct irq_data *data, const struct cpumask *mask,\r\nunsigned int *dest_id)\r\n{\r\nstruct irq_cfg *cfg = data->chip_data;\r\nunsigned int irq = data->irq;\r\nint err;\r\nif (!config_enabled(CONFIG_SMP))\r\nreturn -1;\r\nif (!cpumask_intersects(mask, cpu_online_mask))\r\nreturn -EINVAL;\r\nerr = assign_irq_vector(irq, cfg, mask);\r\nif (err)\r\nreturn err;\r\nerr = apic->cpu_mask_to_apicid_and(mask, cfg->domain, dest_id);\r\nif (err) {\r\nif (assign_irq_vector(irq, cfg, data->affinity))\r\npr_err("Failed to recover vector for irq %d\n", irq);\r\nreturn err;\r\n}\r\ncpumask_copy(data->affinity, mask);\r\nreturn 0;\r\n}\r\nint native_ioapic_set_affinity(struct irq_data *data,\r\nconst struct cpumask *mask,\r\nbool force)\r\n{\r\nunsigned int dest, irq = data->irq;\r\nunsigned long flags;\r\nint ret;\r\nif (!config_enabled(CONFIG_SMP))\r\nreturn -1;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nret = __ioapic_set_affinity(data, mask, &dest);\r\nif (!ret) {\r\ndest = SET_APIC_LOGICAL_ID(dest);\r\n__target_IO_APIC_irq(irq, dest, data->chip_data);\r\nret = IRQ_SET_MASK_OK_NOCOPY;\r\n}\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nreturn ret;\r\n}\r\nstatic void ack_apic_edge(struct irq_data *data)\r\n{\r\nirq_complete_move(data->chip_data);\r\nirq_move_irq(data);\r\nack_APIC_irq();\r\n}\r\nstatic bool io_apic_level_ack_pending(struct irq_cfg *cfg)\r\n{\r\nstruct irq_pin_list *entry;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nfor_each_irq_pin(entry, cfg->irq_2_pin) {\r\nunsigned int reg;\r\nint pin;\r\npin = entry->pin;\r\nreg = io_apic_read(entry->apic, 0x10 + pin*2);\r\nif (reg & IO_APIC_REDIR_REMOTE_IRR) {\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nreturn true;\r\n}\r\n}\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nreturn false;\r\n}\r\nstatic inline bool ioapic_irqd_mask(struct irq_data *data, struct irq_cfg *cfg)\r\n{\r\nif (unlikely(irqd_is_setaffinity_pending(data))) {\r\nmask_ioapic(cfg);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic inline void ioapic_irqd_unmask(struct irq_data *data,\r\nstruct irq_cfg *cfg, bool masked)\r\n{\r\nif (unlikely(masked)) {\r\nif (!io_apic_level_ack_pending(cfg))\r\nirq_move_masked_irq(data);\r\nunmask_ioapic(cfg);\r\n}\r\n}\r\nstatic inline bool ioapic_irqd_mask(struct irq_data *data, struct irq_cfg *cfg)\r\n{\r\nreturn false;\r\n}\r\nstatic inline void ioapic_irqd_unmask(struct irq_data *data,\r\nstruct irq_cfg *cfg, bool masked)\r\n{\r\n}\r\nstatic void ack_apic_level(struct irq_data *data)\r\n{\r\nstruct irq_cfg *cfg = data->chip_data;\r\nint i, irq = data->irq;\r\nunsigned long v;\r\nbool masked;\r\nirq_complete_move(cfg);\r\nmasked = ioapic_irqd_mask(data, cfg);\r\ni = cfg->vector;\r\nv = apic_read(APIC_TMR + ((i & ~0x1f) >> 1));\r\nack_APIC_irq();\r\nif (!(v & (1 << (i & 0x1f)))) {\r\natomic_inc(&irq_mis_count);\r\neoi_ioapic_irq(irq, cfg);\r\n}\r\nioapic_irqd_unmask(data, cfg, masked);\r\n}\r\nstatic inline void init_IO_APIC_traps(void)\r\n{\r\nstruct irq_cfg *cfg;\r\nunsigned int irq;\r\nfor_each_active_irq(irq) {\r\ncfg = irq_get_chip_data(irq);\r\nif (IO_APIC_IRQ(irq) && cfg && !cfg->vector) {\r\nif (irq < legacy_pic->nr_legacy_irqs)\r\nlegacy_pic->make_irq(irq);\r\nelse\r\nirq_set_chip(irq, &no_irq_chip);\r\n}\r\n}\r\n}\r\nstatic void mask_lapic_irq(struct irq_data *data)\r\n{\r\nunsigned long v;\r\nv = apic_read(APIC_LVT0);\r\napic_write(APIC_LVT0, v | APIC_LVT_MASKED);\r\n}\r\nstatic void unmask_lapic_irq(struct irq_data *data)\r\n{\r\nunsigned long v;\r\nv = apic_read(APIC_LVT0);\r\napic_write(APIC_LVT0, v & ~APIC_LVT_MASKED);\r\n}\r\nstatic void ack_lapic_irq(struct irq_data *data)\r\n{\r\nack_APIC_irq();\r\n}\r\nstatic void lapic_register_intr(int irq)\r\n{\r\nirq_clear_status_flags(irq, IRQ_LEVEL);\r\nirq_set_chip_and_handler_name(irq, &lapic_chip, handle_edge_irq,\r\n"edge");\r\n}\r\nstatic inline void __init unlock_ExtINT_logic(void)\r\n{\r\nint apic, pin, i;\r\nstruct IO_APIC_route_entry entry0, entry1;\r\nunsigned char save_control, save_freq_select;\r\npin = find_isa_irq_pin(8, mp_INT);\r\nif (pin == -1) {\r\nWARN_ON_ONCE(1);\r\nreturn;\r\n}\r\napic = find_isa_irq_apic(8, mp_INT);\r\nif (apic == -1) {\r\nWARN_ON_ONCE(1);\r\nreturn;\r\n}\r\nentry0 = ioapic_read_entry(apic, pin);\r\nclear_IO_APIC_pin(apic, pin);\r\nmemset(&entry1, 0, sizeof(entry1));\r\nentry1.dest_mode = 0;\r\nentry1.mask = 0;\r\nentry1.dest = hard_smp_processor_id();\r\nentry1.delivery_mode = dest_ExtINT;\r\nentry1.polarity = entry0.polarity;\r\nentry1.trigger = 0;\r\nentry1.vector = 0;\r\nioapic_write_entry(apic, pin, entry1);\r\nsave_control = CMOS_READ(RTC_CONTROL);\r\nsave_freq_select = CMOS_READ(RTC_FREQ_SELECT);\r\nCMOS_WRITE((save_freq_select & ~RTC_RATE_SELECT) | 0x6,\r\nRTC_FREQ_SELECT);\r\nCMOS_WRITE(save_control | RTC_PIE, RTC_CONTROL);\r\ni = 100;\r\nwhile (i-- > 0) {\r\nmdelay(10);\r\nif ((CMOS_READ(RTC_INTR_FLAGS) & RTC_PF) == RTC_PF)\r\ni -= 10;\r\n}\r\nCMOS_WRITE(save_control, RTC_CONTROL);\r\nCMOS_WRITE(save_freq_select, RTC_FREQ_SELECT);\r\nclear_IO_APIC_pin(apic, pin);\r\nioapic_write_entry(apic, pin, entry0);\r\n}\r\nstatic int __init disable_timer_pin_setup(char *arg)\r\n{\r\ndisable_timer_pin_1 = 1;\r\nreturn 0;\r\n}\r\nstatic inline void __init check_timer(void)\r\n{\r\nstruct irq_cfg *cfg = irq_get_chip_data(0);\r\nint node = cpu_to_node(0);\r\nint apic1, pin1, apic2, pin2;\r\nunsigned long flags;\r\nint no_pin1 = 0;\r\nlocal_irq_save(flags);\r\nlegacy_pic->mask(0);\r\nassign_irq_vector(0, cfg, apic->target_cpus());\r\napic_write(APIC_LVT0, APIC_LVT_MASKED | APIC_DM_EXTINT);\r\nlegacy_pic->init(1);\r\npin1 = find_isa_irq_pin(0, mp_INT);\r\napic1 = find_isa_irq_apic(0, mp_INT);\r\npin2 = ioapic_i8259.pin;\r\napic2 = ioapic_i8259.apic;\r\napic_printk(APIC_QUIET, KERN_INFO "..TIMER: vector=0x%02X "\r\n"apic1=%d pin1=%d apic2=%d pin2=%d\n",\r\ncfg->vector, apic1, pin1, apic2, pin2);\r\nif (pin1 == -1) {\r\npanic_if_irq_remap("BIOS bug: timer not connected to IO-APIC");\r\npin1 = pin2;\r\napic1 = apic2;\r\nno_pin1 = 1;\r\n} else if (pin2 == -1) {\r\npin2 = pin1;\r\napic2 = apic1;\r\n}\r\nif (pin1 != -1) {\r\nif (no_pin1) {\r\nadd_pin_to_irq_node(cfg, node, apic1, pin1);\r\nsetup_timer_IRQ0_pin(apic1, pin1, cfg->vector);\r\n} else {\r\nint idx;\r\nidx = find_irq_entry(apic1, pin1, mp_INT);\r\nif (idx != -1 && irq_trigger(idx))\r\nunmask_ioapic(cfg);\r\n}\r\nif (timer_irq_works()) {\r\nif (disable_timer_pin_1 > 0)\r\nclear_IO_APIC_pin(0, pin1);\r\ngoto out;\r\n}\r\npanic_if_irq_remap("timer doesn't work through Interrupt-remapped IO-APIC");\r\nlocal_irq_disable();\r\nclear_IO_APIC_pin(apic1, pin1);\r\nif (!no_pin1)\r\napic_printk(APIC_QUIET, KERN_ERR "..MP-BIOS bug: "\r\n"8254 timer not connected to IO-APIC\n");\r\napic_printk(APIC_QUIET, KERN_INFO "...trying to set up timer "\r\n"(IRQ0) through the 8259A ...\n");\r\napic_printk(APIC_QUIET, KERN_INFO\r\n"..... (found apic %d pin %d) ...\n", apic2, pin2);\r\nreplace_pin_at_irq_node(cfg, node, apic1, pin1, apic2, pin2);\r\nsetup_timer_IRQ0_pin(apic2, pin2, cfg->vector);\r\nlegacy_pic->unmask(0);\r\nif (timer_irq_works()) {\r\napic_printk(APIC_QUIET, KERN_INFO "....... works.\n");\r\ntimer_through_8259 = 1;\r\ngoto out;\r\n}\r\nlocal_irq_disable();\r\nlegacy_pic->mask(0);\r\nclear_IO_APIC_pin(apic2, pin2);\r\napic_printk(APIC_QUIET, KERN_INFO "....... failed.\n");\r\n}\r\napic_printk(APIC_QUIET, KERN_INFO\r\n"...trying to set up timer as Virtual Wire IRQ...\n");\r\nlapic_register_intr(0);\r\napic_write(APIC_LVT0, APIC_DM_FIXED | cfg->vector);\r\nlegacy_pic->unmask(0);\r\nif (timer_irq_works()) {\r\napic_printk(APIC_QUIET, KERN_INFO "..... works.\n");\r\ngoto out;\r\n}\r\nlocal_irq_disable();\r\nlegacy_pic->mask(0);\r\napic_write(APIC_LVT0, APIC_LVT_MASKED | APIC_DM_FIXED | cfg->vector);\r\napic_printk(APIC_QUIET, KERN_INFO "..... failed.\n");\r\napic_printk(APIC_QUIET, KERN_INFO\r\n"...trying to set up timer as ExtINT IRQ...\n");\r\nlegacy_pic->init(0);\r\nlegacy_pic->make_irq(0);\r\napic_write(APIC_LVT0, APIC_DM_EXTINT);\r\nunlock_ExtINT_logic();\r\nif (timer_irq_works()) {\r\napic_printk(APIC_QUIET, KERN_INFO "..... works.\n");\r\ngoto out;\r\n}\r\nlocal_irq_disable();\r\napic_printk(APIC_QUIET, KERN_INFO "..... failed :(.\n");\r\nif (x2apic_preenabled)\r\napic_printk(APIC_QUIET, KERN_INFO\r\n"Perhaps problem with the pre-enabled x2apic mode\n"\r\n"Try booting with x2apic and interrupt-remapping disabled in the bios.\n");\r\npanic("IO-APIC + timer doesn't work! Boot with apic=debug and send a "\r\n"report. Then try booting with the 'noapic' option.\n");\r\nout:\r\nlocal_irq_restore(flags);\r\n}\r\nvoid __init setup_IO_APIC(void)\r\n{\r\nio_apic_irqs = legacy_pic->nr_legacy_irqs ? ~PIC_IRQS : ~0UL;\r\napic_printk(APIC_VERBOSE, "ENABLING IO-APIC IRQs\n");\r\nx86_init.mpparse.setup_ioapic_ids();\r\nsync_Arb_IDs();\r\nsetup_IO_APIC_irqs();\r\ninit_IO_APIC_traps();\r\nif (legacy_pic->nr_legacy_irqs)\r\ncheck_timer();\r\n}\r\nstatic int __init io_apic_bug_finalize(void)\r\n{\r\nif (sis_apic_bug == -1)\r\nsis_apic_bug = 0;\r\nreturn 0;\r\n}\r\nstatic void resume_ioapic_id(int ioapic_idx)\r\n{\r\nunsigned long flags;\r\nunion IO_APIC_reg_00 reg_00;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nreg_00.raw = io_apic_read(ioapic_idx, 0);\r\nif (reg_00.bits.ID != mpc_ioapic_id(ioapic_idx)) {\r\nreg_00.bits.ID = mpc_ioapic_id(ioapic_idx);\r\nio_apic_write(ioapic_idx, 0, reg_00.raw);\r\n}\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\n}\r\nstatic void ioapic_resume(void)\r\n{\r\nint ioapic_idx;\r\nfor (ioapic_idx = nr_ioapics - 1; ioapic_idx >= 0; ioapic_idx--)\r\nresume_ioapic_id(ioapic_idx);\r\nrestore_ioapic_entries();\r\n}\r\nstatic int __init ioapic_init_ops(void)\r\n{\r\nregister_syscore_ops(&ioapic_syscore_ops);\r\nreturn 0;\r\n}\r\nunsigned int __create_irqs(unsigned int from, unsigned int count, int node)\r\n{\r\nstruct irq_cfg **cfg;\r\nunsigned long flags;\r\nint irq, i;\r\nif (from < nr_irqs_gsi)\r\nfrom = nr_irqs_gsi;\r\ncfg = kzalloc_node(count * sizeof(cfg[0]), GFP_KERNEL, node);\r\nif (!cfg)\r\nreturn 0;\r\nirq = alloc_irqs_from(from, count, node);\r\nif (irq < 0)\r\ngoto out_cfgs;\r\nfor (i = 0; i < count; i++) {\r\ncfg[i] = alloc_irq_cfg(irq + i, node);\r\nif (!cfg[i])\r\ngoto out_irqs;\r\n}\r\nraw_spin_lock_irqsave(&vector_lock, flags);\r\nfor (i = 0; i < count; i++)\r\nif (__assign_irq_vector(irq + i, cfg[i], apic->target_cpus()))\r\ngoto out_vecs;\r\nraw_spin_unlock_irqrestore(&vector_lock, flags);\r\nfor (i = 0; i < count; i++) {\r\nirq_set_chip_data(irq + i, cfg[i]);\r\nirq_clear_status_flags(irq + i, IRQ_NOREQUEST);\r\n}\r\nkfree(cfg);\r\nreturn irq;\r\nout_vecs:\r\nfor (i--; i >= 0; i--)\r\n__clear_irq_vector(irq + i, cfg[i]);\r\nraw_spin_unlock_irqrestore(&vector_lock, flags);\r\nout_irqs:\r\nfor (i = 0; i < count; i++)\r\nfree_irq_at(irq + i, cfg[i]);\r\nout_cfgs:\r\nkfree(cfg);\r\nreturn 0;\r\n}\r\nunsigned int create_irq_nr(unsigned int from, int node)\r\n{\r\nreturn __create_irqs(from, 1, node);\r\n}\r\nint create_irq(void)\r\n{\r\nint node = cpu_to_node(0);\r\nunsigned int irq_want;\r\nint irq;\r\nirq_want = nr_irqs_gsi;\r\nirq = create_irq_nr(irq_want, node);\r\nif (irq == 0)\r\nirq = -1;\r\nreturn irq;\r\n}\r\nvoid destroy_irq(unsigned int irq)\r\n{\r\nstruct irq_cfg *cfg = irq_get_chip_data(irq);\r\nunsigned long flags;\r\nirq_set_status_flags(irq, IRQ_NOREQUEST|IRQ_NOPROBE);\r\nfree_remapped_irq(irq);\r\nraw_spin_lock_irqsave(&vector_lock, flags);\r\n__clear_irq_vector(irq, cfg);\r\nraw_spin_unlock_irqrestore(&vector_lock, flags);\r\nfree_irq_at(irq, cfg);\r\n}\r\nvoid destroy_irqs(unsigned int irq, unsigned int count)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < count; i++)\r\ndestroy_irq(irq + i);\r\n}\r\nvoid native_compose_msi_msg(struct pci_dev *pdev,\r\nunsigned int irq, unsigned int dest,\r\nstruct msi_msg *msg, u8 hpet_id)\r\n{\r\nstruct irq_cfg *cfg = irq_cfg(irq);\r\nmsg->address_hi = MSI_ADDR_BASE_HI;\r\nif (x2apic_enabled())\r\nmsg->address_hi |= MSI_ADDR_EXT_DEST_ID(dest);\r\nmsg->address_lo =\r\nMSI_ADDR_BASE_LO |\r\n((apic->irq_dest_mode == 0) ?\r\nMSI_ADDR_DEST_MODE_PHYSICAL:\r\nMSI_ADDR_DEST_MODE_LOGICAL) |\r\n((apic->irq_delivery_mode != dest_LowestPrio) ?\r\nMSI_ADDR_REDIRECTION_CPU:\r\nMSI_ADDR_REDIRECTION_LOWPRI) |\r\nMSI_ADDR_DEST_ID(dest);\r\nmsg->data =\r\nMSI_DATA_TRIGGER_EDGE |\r\nMSI_DATA_LEVEL_ASSERT |\r\n((apic->irq_delivery_mode != dest_LowestPrio) ?\r\nMSI_DATA_DELIVERY_FIXED:\r\nMSI_DATA_DELIVERY_LOWPRI) |\r\nMSI_DATA_VECTOR(cfg->vector);\r\n}\r\nstatic int msi_compose_msg(struct pci_dev *pdev, unsigned int irq,\r\nstruct msi_msg *msg, u8 hpet_id)\r\n{\r\nstruct irq_cfg *cfg;\r\nint err;\r\nunsigned dest;\r\nif (disable_apic)\r\nreturn -ENXIO;\r\ncfg = irq_cfg(irq);\r\nerr = assign_irq_vector(irq, cfg, apic->target_cpus());\r\nif (err)\r\nreturn err;\r\nerr = apic->cpu_mask_to_apicid_and(cfg->domain,\r\napic->target_cpus(), &dest);\r\nif (err)\r\nreturn err;\r\nx86_msi.compose_msi_msg(pdev, irq, dest, msg, hpet_id);\r\nreturn 0;\r\n}\r\nstatic int\r\nmsi_set_affinity(struct irq_data *data, const struct cpumask *mask, bool force)\r\n{\r\nstruct irq_cfg *cfg = data->chip_data;\r\nstruct msi_msg msg;\r\nunsigned int dest;\r\nif (__ioapic_set_affinity(data, mask, &dest))\r\nreturn -1;\r\n__get_cached_msi_msg(data->msi_desc, &msg);\r\nmsg.data &= ~MSI_DATA_VECTOR_MASK;\r\nmsg.data |= MSI_DATA_VECTOR(cfg->vector);\r\nmsg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;\r\nmsg.address_lo |= MSI_ADDR_DEST_ID(dest);\r\n__write_msi_msg(data->msi_desc, &msg);\r\nreturn IRQ_SET_MASK_OK_NOCOPY;\r\n}\r\nint setup_msi_irq(struct pci_dev *dev, struct msi_desc *msidesc,\r\nunsigned int irq_base, unsigned int irq_offset)\r\n{\r\nstruct irq_chip *chip = &msi_chip;\r\nstruct msi_msg msg;\r\nunsigned int irq = irq_base + irq_offset;\r\nint ret;\r\nret = msi_compose_msg(dev, irq, &msg, -1);\r\nif (ret < 0)\r\nreturn ret;\r\nirq_set_msi_desc_off(irq_base, irq_offset, msidesc);\r\nif (!irq_offset)\r\nwrite_msi_msg(irq, &msg);\r\nsetup_remapped_irq(irq, irq_get_chip_data(irq), chip);\r\nirq_set_chip_and_handler_name(irq, chip, handle_edge_irq, "edge");\r\ndev_printk(KERN_DEBUG, &dev->dev, "irq %d for MSI/MSI-X\n", irq);\r\nreturn 0;\r\n}\r\nint native_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)\r\n{\r\nunsigned int irq, irq_want;\r\nstruct msi_desc *msidesc;\r\nint node, ret;\r\nif (type == PCI_CAP_ID_MSI && nvec > 1)\r\nreturn 1;\r\nnode = dev_to_node(&dev->dev);\r\nirq_want = nr_irqs_gsi;\r\nlist_for_each_entry(msidesc, &dev->msi_list, list) {\r\nirq = create_irq_nr(irq_want, node);\r\nif (irq == 0)\r\nreturn -ENOSPC;\r\nirq_want = irq + 1;\r\nret = setup_msi_irq(dev, msidesc, irq, 0);\r\nif (ret < 0)\r\ngoto error;\r\n}\r\nreturn 0;\r\nerror:\r\ndestroy_irq(irq);\r\nreturn ret;\r\n}\r\nvoid native_teardown_msi_irq(unsigned int irq)\r\n{\r\ndestroy_irq(irq);\r\n}\r\nstatic int\r\ndmar_msi_set_affinity(struct irq_data *data, const struct cpumask *mask,\r\nbool force)\r\n{\r\nstruct irq_cfg *cfg = data->chip_data;\r\nunsigned int dest, irq = data->irq;\r\nstruct msi_msg msg;\r\nif (__ioapic_set_affinity(data, mask, &dest))\r\nreturn -1;\r\ndmar_msi_read(irq, &msg);\r\nmsg.data &= ~MSI_DATA_VECTOR_MASK;\r\nmsg.data |= MSI_DATA_VECTOR(cfg->vector);\r\nmsg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;\r\nmsg.address_lo |= MSI_ADDR_DEST_ID(dest);\r\nmsg.address_hi = MSI_ADDR_BASE_HI | MSI_ADDR_EXT_DEST_ID(dest);\r\ndmar_msi_write(irq, &msg);\r\nreturn IRQ_SET_MASK_OK_NOCOPY;\r\n}\r\nint arch_setup_dmar_msi(unsigned int irq)\r\n{\r\nint ret;\r\nstruct msi_msg msg;\r\nret = msi_compose_msg(NULL, irq, &msg, -1);\r\nif (ret < 0)\r\nreturn ret;\r\ndmar_msi_write(irq, &msg);\r\nirq_set_chip_and_handler_name(irq, &dmar_msi_type, handle_edge_irq,\r\n"edge");\r\nreturn 0;\r\n}\r\nstatic int hpet_msi_set_affinity(struct irq_data *data,\r\nconst struct cpumask *mask, bool force)\r\n{\r\nstruct irq_cfg *cfg = data->chip_data;\r\nstruct msi_msg msg;\r\nunsigned int dest;\r\nif (__ioapic_set_affinity(data, mask, &dest))\r\nreturn -1;\r\nhpet_msi_read(data->handler_data, &msg);\r\nmsg.data &= ~MSI_DATA_VECTOR_MASK;\r\nmsg.data |= MSI_DATA_VECTOR(cfg->vector);\r\nmsg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;\r\nmsg.address_lo |= MSI_ADDR_DEST_ID(dest);\r\nhpet_msi_write(data->handler_data, &msg);\r\nreturn IRQ_SET_MASK_OK_NOCOPY;\r\n}\r\nint default_setup_hpet_msi(unsigned int irq, unsigned int id)\r\n{\r\nstruct irq_chip *chip = &hpet_msi_type;\r\nstruct msi_msg msg;\r\nint ret;\r\nret = msi_compose_msg(NULL, irq, &msg, id);\r\nif (ret < 0)\r\nreturn ret;\r\nhpet_msi_write(irq_get_handler_data(irq), &msg);\r\nirq_set_status_flags(irq, IRQ_MOVE_PCNTXT);\r\nsetup_remapped_irq(irq, irq_get_chip_data(irq), chip);\r\nirq_set_chip_and_handler_name(irq, chip, handle_edge_irq, "edge");\r\nreturn 0;\r\n}\r\nstatic void target_ht_irq(unsigned int irq, unsigned int dest, u8 vector)\r\n{\r\nstruct ht_irq_msg msg;\r\nfetch_ht_irq_msg(irq, &msg);\r\nmsg.address_lo &= ~(HT_IRQ_LOW_VECTOR_MASK | HT_IRQ_LOW_DEST_ID_MASK);\r\nmsg.address_hi &= ~(HT_IRQ_HIGH_DEST_ID_MASK);\r\nmsg.address_lo |= HT_IRQ_LOW_VECTOR(vector) | HT_IRQ_LOW_DEST_ID(dest);\r\nmsg.address_hi |= HT_IRQ_HIGH_DEST_ID(dest);\r\nwrite_ht_irq_msg(irq, &msg);\r\n}\r\nstatic int\r\nht_set_affinity(struct irq_data *data, const struct cpumask *mask, bool force)\r\n{\r\nstruct irq_cfg *cfg = data->chip_data;\r\nunsigned int dest;\r\nif (__ioapic_set_affinity(data, mask, &dest))\r\nreturn -1;\r\ntarget_ht_irq(data->irq, dest, cfg->vector);\r\nreturn IRQ_SET_MASK_OK_NOCOPY;\r\n}\r\nint arch_setup_ht_irq(unsigned int irq, struct pci_dev *dev)\r\n{\r\nstruct irq_cfg *cfg;\r\nstruct ht_irq_msg msg;\r\nunsigned dest;\r\nint err;\r\nif (disable_apic)\r\nreturn -ENXIO;\r\ncfg = irq_cfg(irq);\r\nerr = assign_irq_vector(irq, cfg, apic->target_cpus());\r\nif (err)\r\nreturn err;\r\nerr = apic->cpu_mask_to_apicid_and(cfg->domain,\r\napic->target_cpus(), &dest);\r\nif (err)\r\nreturn err;\r\nmsg.address_hi = HT_IRQ_HIGH_DEST_ID(dest);\r\nmsg.address_lo =\r\nHT_IRQ_LOW_BASE |\r\nHT_IRQ_LOW_DEST_ID(dest) |\r\nHT_IRQ_LOW_VECTOR(cfg->vector) |\r\n((apic->irq_dest_mode == 0) ?\r\nHT_IRQ_LOW_DM_PHYSICAL :\r\nHT_IRQ_LOW_DM_LOGICAL) |\r\nHT_IRQ_LOW_RQEOI_EDGE |\r\n((apic->irq_delivery_mode != dest_LowestPrio) ?\r\nHT_IRQ_LOW_MT_FIXED :\r\nHT_IRQ_LOW_MT_ARBITRATED) |\r\nHT_IRQ_LOW_IRQ_MASKED;\r\nwrite_ht_irq_msg(irq, &msg);\r\nirq_set_chip_and_handler_name(irq, &ht_irq_chip,\r\nhandle_edge_irq, "edge");\r\ndev_printk(KERN_DEBUG, &dev->dev, "irq %d for HT\n", irq);\r\nreturn 0;\r\n}\r\nstatic int\r\nio_apic_setup_irq_pin(unsigned int irq, int node, struct io_apic_irq_attr *attr)\r\n{\r\nstruct irq_cfg *cfg = alloc_irq_and_cfg_at(irq, node);\r\nint ret;\r\nif (!cfg)\r\nreturn -EINVAL;\r\nret = __add_pin_to_irq_node(cfg, node, attr->ioapic, attr->ioapic_pin);\r\nif (!ret)\r\nsetup_ioapic_irq(irq, cfg, attr);\r\nreturn ret;\r\n}\r\nint io_apic_setup_irq_pin_once(unsigned int irq, int node,\r\nstruct io_apic_irq_attr *attr)\r\n{\r\nunsigned int ioapic_idx = attr->ioapic, pin = attr->ioapic_pin;\r\nint ret;\r\nstruct IO_APIC_route_entry orig_entry;\r\nif (test_bit(pin, ioapics[ioapic_idx].pin_programmed)) {\r\npr_debug("Pin %d-%d already programmed\n", mpc_ioapic_id(ioapic_idx), pin);\r\norig_entry = ioapic_read_entry(attr->ioapic, pin);\r\nif (attr->trigger == orig_entry.trigger && attr->polarity == orig_entry.polarity)\r\nreturn 0;\r\nreturn -EBUSY;\r\n}\r\nret = io_apic_setup_irq_pin(irq, node, attr);\r\nif (!ret)\r\nset_bit(pin, ioapics[ioapic_idx].pin_programmed);\r\nreturn ret;\r\n}\r\nstatic int __init io_apic_get_redir_entries(int ioapic)\r\n{\r\nunion IO_APIC_reg_01 reg_01;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nreg_01.raw = io_apic_read(ioapic, 1);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nreturn reg_01.bits.entries + 1;\r\n}\r\nstatic void __init probe_nr_irqs_gsi(void)\r\n{\r\nint nr;\r\nnr = gsi_top + NR_IRQS_LEGACY;\r\nif (nr > nr_irqs_gsi)\r\nnr_irqs_gsi = nr;\r\nprintk(KERN_DEBUG "nr_irqs_gsi: %d\n", nr_irqs_gsi);\r\n}\r\nint get_nr_irqs_gsi(void)\r\n{\r\nreturn nr_irqs_gsi;\r\n}\r\nint __init arch_probe_nr_irqs(void)\r\n{\r\nint nr;\r\nif (nr_irqs > (NR_VECTORS * nr_cpu_ids))\r\nnr_irqs = NR_VECTORS * nr_cpu_ids;\r\nnr = nr_irqs_gsi + 8 * nr_cpu_ids;\r\n#if defined(CONFIG_PCI_MSI) || defined(CONFIG_HT_IRQ)\r\nnr += nr_irqs_gsi * 16;\r\n#endif\r\nif (nr < nr_irqs)\r\nnr_irqs = nr;\r\nreturn NR_IRQS_LEGACY;\r\n}\r\nint io_apic_set_pci_routing(struct device *dev, int irq,\r\nstruct io_apic_irq_attr *irq_attr)\r\n{\r\nint node;\r\nif (!IO_APIC_IRQ(irq)) {\r\napic_printk(APIC_QUIET,KERN_ERR "IOAPIC[%d]: Invalid reference to IRQ 0\n",\r\nirq_attr->ioapic);\r\nreturn -EINVAL;\r\n}\r\nnode = dev ? dev_to_node(dev) : cpu_to_node(0);\r\nreturn io_apic_setup_irq_pin_once(irq, node, irq_attr);\r\n}\r\nstatic int __init io_apic_get_unique_id(int ioapic, int apic_id)\r\n{\r\nunion IO_APIC_reg_00 reg_00;\r\nstatic physid_mask_t apic_id_map = PHYSID_MASK_NONE;\r\nphysid_mask_t tmp;\r\nunsigned long flags;\r\nint i = 0;\r\nif (physids_empty(apic_id_map))\r\napic->ioapic_phys_id_map(&phys_cpu_present_map, &apic_id_map);\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nreg_00.raw = io_apic_read(ioapic, 0);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nif (apic_id >= get_physical_broadcast()) {\r\nprintk(KERN_WARNING "IOAPIC[%d]: Invalid apic_id %d, trying "\r\n"%d\n", ioapic, apic_id, reg_00.bits.ID);\r\napic_id = reg_00.bits.ID;\r\n}\r\nif (apic->check_apicid_used(&apic_id_map, apic_id)) {\r\nfor (i = 0; i < get_physical_broadcast(); i++) {\r\nif (!apic->check_apicid_used(&apic_id_map, i))\r\nbreak;\r\n}\r\nif (i == get_physical_broadcast())\r\npanic("Max apic_id exceeded!\n");\r\nprintk(KERN_WARNING "IOAPIC[%d]: apic_id %d already used, "\r\n"trying %d\n", ioapic, apic_id, i);\r\napic_id = i;\r\n}\r\napic->apicid_to_cpu_present(apic_id, &tmp);\r\nphysids_or(apic_id_map, apic_id_map, tmp);\r\nif (reg_00.bits.ID != apic_id) {\r\nreg_00.bits.ID = apic_id;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nio_apic_write(ioapic, 0, reg_00.raw);\r\nreg_00.raw = io_apic_read(ioapic, 0);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nif (reg_00.bits.ID != apic_id) {\r\npr_err("IOAPIC[%d]: Unable to change apic_id!\n",\r\nioapic);\r\nreturn -1;\r\n}\r\n}\r\napic_printk(APIC_VERBOSE, KERN_INFO\r\n"IOAPIC[%d]: Assigned apic_id %d\n", ioapic, apic_id);\r\nreturn apic_id;\r\n}\r\nstatic u8 __init io_apic_unique_id(u8 id)\r\n{\r\nif ((boot_cpu_data.x86_vendor == X86_VENDOR_INTEL) &&\r\n!APIC_XAPIC(apic_version[boot_cpu_physical_apicid]))\r\nreturn io_apic_get_unique_id(nr_ioapics, id);\r\nelse\r\nreturn id;\r\n}\r\nstatic u8 __init io_apic_unique_id(u8 id)\r\n{\r\nint i;\r\nDECLARE_BITMAP(used, 256);\r\nbitmap_zero(used, 256);\r\nfor (i = 0; i < nr_ioapics; i++) {\r\n__set_bit(mpc_ioapic_id(i), used);\r\n}\r\nif (!test_bit(id, used))\r\nreturn id;\r\nreturn find_first_zero_bit(used, 256);\r\n}\r\nstatic int __init io_apic_get_version(int ioapic)\r\n{\r\nunion IO_APIC_reg_01 reg_01;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&ioapic_lock, flags);\r\nreg_01.raw = io_apic_read(ioapic, 1);\r\nraw_spin_unlock_irqrestore(&ioapic_lock, flags);\r\nreturn reg_01.bits.version;\r\n}\r\nint acpi_get_override_irq(u32 gsi, int *trigger, int *polarity)\r\n{\r\nint ioapic, pin, idx;\r\nif (skip_ioapic_setup)\r\nreturn -1;\r\nioapic = mp_find_ioapic(gsi);\r\nif (ioapic < 0)\r\nreturn -1;\r\npin = mp_find_ioapic_pin(ioapic, gsi);\r\nif (pin < 0)\r\nreturn -1;\r\nidx = find_irq_entry(ioapic, pin, mp_INT);\r\nif (idx < 0)\r\nreturn -1;\r\n*trigger = irq_trigger(idx);\r\n*polarity = irq_polarity(idx);\r\nreturn 0;\r\n}\r\nvoid __init setup_ioapic_dest(void)\r\n{\r\nint pin, ioapic, irq, irq_entry;\r\nconst struct cpumask *mask;\r\nstruct irq_data *idata;\r\nif (skip_ioapic_setup == 1)\r\nreturn;\r\nfor (ioapic = 0; ioapic < nr_ioapics; ioapic++)\r\nfor (pin = 0; pin < ioapics[ioapic].nr_registers; pin++) {\r\nirq_entry = find_irq_entry(ioapic, pin, mp_INT);\r\nif (irq_entry == -1)\r\ncontinue;\r\nirq = pin_2_irq(irq_entry, ioapic, pin);\r\nif ((ioapic > 0) && (irq > 16))\r\ncontinue;\r\nidata = irq_get_irq_data(irq);\r\nif (!irqd_can_balance(idata) || irqd_affinity_was_set(idata))\r\nmask = idata->affinity;\r\nelse\r\nmask = apic->target_cpus();\r\nx86_io_apic_ops.set_affinity(idata, mask, false);\r\n}\r\n}\r\nstatic struct resource * __init ioapic_setup_resources(int nr_ioapics)\r\n{\r\nunsigned long n;\r\nstruct resource *res;\r\nchar *mem;\r\nint i;\r\nif (nr_ioapics <= 0)\r\nreturn NULL;\r\nn = IOAPIC_RESOURCE_NAME_SIZE + sizeof(struct resource);\r\nn *= nr_ioapics;\r\nmem = alloc_bootmem(n);\r\nres = (void *)mem;\r\nmem += sizeof(struct resource) * nr_ioapics;\r\nfor (i = 0; i < nr_ioapics; i++) {\r\nres[i].name = mem;\r\nres[i].flags = IORESOURCE_MEM | IORESOURCE_BUSY;\r\nsnprintf(mem, IOAPIC_RESOURCE_NAME_SIZE, "IOAPIC %u", i);\r\nmem += IOAPIC_RESOURCE_NAME_SIZE;\r\n}\r\nioapic_resources = res;\r\nreturn res;\r\n}\r\nvoid __init native_io_apic_init_mappings(void)\r\n{\r\nunsigned long ioapic_phys, idx = FIX_IO_APIC_BASE_0;\r\nstruct resource *ioapic_res;\r\nint i;\r\nioapic_res = ioapic_setup_resources(nr_ioapics);\r\nfor (i = 0; i < nr_ioapics; i++) {\r\nif (smp_found_config) {\r\nioapic_phys = mpc_ioapic_addr(i);\r\n#ifdef CONFIG_X86_32\r\nif (!ioapic_phys) {\r\nprintk(KERN_ERR\r\n"WARNING: bogus zero IO-APIC "\r\n"address found in MPTABLE, "\r\n"disabling IO/APIC support!\n");\r\nsmp_found_config = 0;\r\nskip_ioapic_setup = 1;\r\ngoto fake_ioapic_page;\r\n}\r\n#endif\r\n} else {\r\n#ifdef CONFIG_X86_32\r\nfake_ioapic_page:\r\n#endif\r\nioapic_phys = (unsigned long)alloc_bootmem_pages(PAGE_SIZE);\r\nioapic_phys = __pa(ioapic_phys);\r\n}\r\nset_fixmap_nocache(idx, ioapic_phys);\r\napic_printk(APIC_VERBOSE, "mapped IOAPIC to %08lx (%08lx)\n",\r\n__fix_to_virt(idx) + (ioapic_phys & ~PAGE_MASK),\r\nioapic_phys);\r\nidx++;\r\nioapic_res->start = ioapic_phys;\r\nioapic_res->end = ioapic_phys + IO_APIC_SLOT_SIZE - 1;\r\nioapic_res++;\r\n}\r\nprobe_nr_irqs_gsi();\r\n}\r\nvoid __init ioapic_insert_resources(void)\r\n{\r\nint i;\r\nstruct resource *r = ioapic_resources;\r\nif (!r) {\r\nif (nr_ioapics > 0)\r\nprintk(KERN_ERR\r\n"IO APIC resources couldn't be allocated.\n");\r\nreturn;\r\n}\r\nfor (i = 0; i < nr_ioapics; i++) {\r\ninsert_resource(&iomem_resource, r);\r\nr++;\r\n}\r\n}\r\nint mp_find_ioapic(u32 gsi)\r\n{\r\nint i = 0;\r\nif (nr_ioapics == 0)\r\nreturn -1;\r\nfor (i = 0; i < nr_ioapics; i++) {\r\nstruct mp_ioapic_gsi *gsi_cfg = mp_ioapic_gsi_routing(i);\r\nif ((gsi >= gsi_cfg->gsi_base)\r\n&& (gsi <= gsi_cfg->gsi_end))\r\nreturn i;\r\n}\r\nprintk(KERN_ERR "ERROR: Unable to locate IOAPIC for GSI %d\n", gsi);\r\nreturn -1;\r\n}\r\nint mp_find_ioapic_pin(int ioapic, u32 gsi)\r\n{\r\nstruct mp_ioapic_gsi *gsi_cfg;\r\nif (WARN_ON(ioapic == -1))\r\nreturn -1;\r\ngsi_cfg = mp_ioapic_gsi_routing(ioapic);\r\nif (WARN_ON(gsi > gsi_cfg->gsi_end))\r\nreturn -1;\r\nreturn gsi - gsi_cfg->gsi_base;\r\n}\r\nstatic __init int bad_ioapic(unsigned long address)\r\n{\r\nif (nr_ioapics >= MAX_IO_APICS) {\r\npr_warn("WARNING: Max # of I/O APICs (%d) exceeded (found %d), skipping\n",\r\nMAX_IO_APICS, nr_ioapics);\r\nreturn 1;\r\n}\r\nif (!address) {\r\npr_warn("WARNING: Bogus (zero) I/O APIC address found in table, skipping!\n");\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic __init int bad_ioapic_register(int idx)\r\n{\r\nunion IO_APIC_reg_00 reg_00;\r\nunion IO_APIC_reg_01 reg_01;\r\nunion IO_APIC_reg_02 reg_02;\r\nreg_00.raw = io_apic_read(idx, 0);\r\nreg_01.raw = io_apic_read(idx, 1);\r\nreg_02.raw = io_apic_read(idx, 2);\r\nif (reg_00.raw == -1 && reg_01.raw == -1 && reg_02.raw == -1) {\r\npr_warn("I/O APIC 0x%x registers return all ones, skipping!\n",\r\nmpc_ioapic_addr(idx));\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nvoid __init mp_register_ioapic(int id, u32 address, u32 gsi_base)\r\n{\r\nint idx = 0;\r\nint entries;\r\nstruct mp_ioapic_gsi *gsi_cfg;\r\nif (bad_ioapic(address))\r\nreturn;\r\nidx = nr_ioapics;\r\nioapics[idx].mp_config.type = MP_IOAPIC;\r\nioapics[idx].mp_config.flags = MPC_APIC_USABLE;\r\nioapics[idx].mp_config.apicaddr = address;\r\nset_fixmap_nocache(FIX_IO_APIC_BASE_0 + idx, address);\r\nif (bad_ioapic_register(idx)) {\r\nclear_fixmap(FIX_IO_APIC_BASE_0 + idx);\r\nreturn;\r\n}\r\nioapics[idx].mp_config.apicid = io_apic_unique_id(id);\r\nioapics[idx].mp_config.apicver = io_apic_get_version(idx);\r\nentries = io_apic_get_redir_entries(idx);\r\ngsi_cfg = mp_ioapic_gsi_routing(idx);\r\ngsi_cfg->gsi_base = gsi_base;\r\ngsi_cfg->gsi_end = gsi_base + entries - 1;\r\nioapics[idx].nr_registers = entries;\r\nif (gsi_cfg->gsi_end >= gsi_top)\r\ngsi_top = gsi_cfg->gsi_end + 1;\r\npr_info("IOAPIC[%d]: apic_id %d, version %d, address 0x%x, GSI %d-%d\n",\r\nidx, mpc_ioapic_id(idx),\r\nmpc_ioapic_ver(idx), mpc_ioapic_addr(idx),\r\ngsi_cfg->gsi_base, gsi_cfg->gsi_end);\r\nnr_ioapics++;\r\n}\r\nvoid __init pre_init_apic_IRQ0(void)\r\n{\r\nstruct io_apic_irq_attr attr = { 0, 0, 0, 0 };\r\nprintk(KERN_INFO "Early APIC setup for system timer0\n");\r\n#ifndef CONFIG_SMP\r\nphysid_set_mask_of_physid(boot_cpu_physical_apicid,\r\n&phys_cpu_present_map);\r\n#endif\r\nsetup_local_APIC();\r\nio_apic_setup_irq_pin(0, 0, &attr);\r\nirq_set_chip_and_handler_name(0, &ioapic_chip, handle_edge_irq,\r\n"edge");\r\n}
