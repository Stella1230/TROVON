static inline bool event_is_fab_match(u64 event)\r\n{\r\nevent &= 0xff0fe;\r\nreturn (event == 0x30056 || event == 0x4f052);\r\n}\r\nstatic int power8_get_constraint(u64 event, unsigned long *maskp, unsigned long *valp)\r\n{\r\nunsigned int unit, pmc, cache, ebb;\r\nunsigned long mask, value;\r\nmask = value = 0;\r\nif (event & ~EVENT_VALID_MASK)\r\nreturn -1;\r\npmc = (event >> EVENT_PMC_SHIFT) & EVENT_PMC_MASK;\r\nunit = (event >> EVENT_UNIT_SHIFT) & EVENT_UNIT_MASK;\r\ncache = (event >> EVENT_CACHE_SEL_SHIFT) & EVENT_CACHE_SEL_MASK;\r\nebb = (event >> PERF_EVENT_CONFIG_EBB_SHIFT) & EVENT_EBB_MASK;\r\nevent &= ~(EVENT_EBB_MASK << PERF_EVENT_CONFIG_EBB_SHIFT);\r\nif (pmc) {\r\nif (pmc > 6)\r\nreturn -1;\r\nmask |= CNST_PMC_MASK(pmc);\r\nvalue |= CNST_PMC_VAL(pmc);\r\nif (pmc >= 5 && event != 0x500fa && event != 0x600f4)\r\nreturn -1;\r\n}\r\nif (pmc <= 4) {\r\nmask |= CNST_NC_MASK;\r\nvalue |= CNST_NC_VAL;\r\n}\r\nif (unit >= 6 && unit <= 9) {\r\nif (cache)\r\nreturn -1;\r\n} else if (event & EVENT_IS_L1) {\r\nmask |= CNST_L1_QUAL_MASK;\r\nvalue |= CNST_L1_QUAL_VAL(cache);\r\n}\r\nif (event & EVENT_IS_MARKED) {\r\nmask |= CNST_SAMPLE_MASK;\r\nvalue |= CNST_SAMPLE_VAL(event >> EVENT_SAMPLE_SHIFT);\r\n}\r\nif (event_is_fab_match(event)) {\r\nmask |= CNST_FAB_MATCH_MASK;\r\nvalue |= CNST_FAB_MATCH_VAL(event >> EVENT_THR_CTL_SHIFT);\r\n} else {\r\nunsigned int cmp, exp;\r\ncmp = (event >> EVENT_THR_CMP_SHIFT) & EVENT_THR_CMP_MASK;\r\nexp = cmp >> 7;\r\nif (exp && (cmp & 0x60) == 0)\r\nreturn -1;\r\nmask |= CNST_THRESH_MASK;\r\nvalue |= CNST_THRESH_VAL(event >> EVENT_THRESH_SHIFT);\r\n}\r\nif (!pmc && ebb)\r\nreturn -1;\r\nmask |= CNST_EBB_VAL(ebb);\r\nvalue |= CNST_EBB_MASK;\r\n*maskp = mask;\r\n*valp = value;\r\nreturn 0;\r\n}\r\nstatic int power8_compute_mmcr(u64 event[], int n_ev,\r\nunsigned int hwc[], unsigned long mmcr[])\r\n{\r\nunsigned long mmcra, mmcr1, unit, combine, psel, cache, val;\r\nunsigned int pmc, pmc_inuse;\r\nint i;\r\npmc_inuse = 0;\r\nfor (i = 0; i < n_ev; ++i) {\r\npmc = (event[i] >> EVENT_PMC_SHIFT) & EVENT_PMC_MASK;\r\nif (pmc)\r\npmc_inuse |= 1 << pmc;\r\n}\r\nmmcra = MMCRA_SDAR_MODE_TLB;\r\nmmcr1 = 0;\r\nfor (i = 0; i < n_ev; ++i) {\r\npmc = (event[i] >> EVENT_PMC_SHIFT) & EVENT_PMC_MASK;\r\nunit = (event[i] >> EVENT_UNIT_SHIFT) & EVENT_UNIT_MASK;\r\ncombine = (event[i] >> EVENT_COMBINE_SHIFT) & EVENT_COMBINE_MASK;\r\npsel = event[i] & EVENT_PSEL_MASK;\r\nif (!pmc) {\r\nfor (pmc = 1; pmc <= 4; ++pmc) {\r\nif (!(pmc_inuse & (1 << pmc)))\r\nbreak;\r\n}\r\npmc_inuse |= 1 << pmc;\r\n}\r\nif (pmc <= 4) {\r\nmmcr1 |= unit << MMCR1_UNIT_SHIFT(pmc);\r\nmmcr1 |= combine << MMCR1_COMBINE_SHIFT(pmc);\r\nmmcr1 |= psel << MMCR1_PMCSEL_SHIFT(pmc);\r\n}\r\nif (event[i] & EVENT_IS_L1) {\r\ncache = event[i] >> EVENT_CACHE_SEL_SHIFT;\r\nmmcr1 |= (cache & 1) << MMCR1_IC_QUAL_SHIFT;\r\ncache >>= 1;\r\nmmcr1 |= (cache & 1) << MMCR1_DC_QUAL_SHIFT;\r\n}\r\nif (event[i] & EVENT_IS_MARKED) {\r\nmmcra |= MMCRA_SAMPLE_ENABLE;\r\nval = (event[i] >> EVENT_SAMPLE_SHIFT) & EVENT_SAMPLE_MASK;\r\nif (val) {\r\nmmcra |= (val & 3) << MMCRA_SAMP_MODE_SHIFT;\r\nmmcra |= (val >> 2) << MMCRA_SAMP_ELIG_SHIFT;\r\n}\r\n}\r\nif (event_is_fab_match(event[i])) {\r\nmmcr1 |= ((event[i] >> EVENT_THR_CTL_SHIFT) &\r\nEVENT_THR_CTL_MASK) << MMCR1_FAB_SHIFT;\r\n} else {\r\nval = (event[i] >> EVENT_THR_CTL_SHIFT) & EVENT_THR_CTL_MASK;\r\nmmcra |= val << MMCRA_THR_CTL_SHIFT;\r\nval = (event[i] >> EVENT_THR_SEL_SHIFT) & EVENT_THR_SEL_MASK;\r\nmmcra |= val << MMCRA_THR_SEL_SHIFT;\r\nval = (event[i] >> EVENT_THR_CMP_SHIFT) & EVENT_THR_CMP_MASK;\r\nmmcra |= val << MMCRA_THR_CMP_SHIFT;\r\n}\r\nhwc[i] = pmc - 1;\r\n}\r\nmmcr[0] = 0;\r\nif (pmc_inuse & 2)\r\nmmcr[0] = MMCR0_PMC1CE;\r\nif (pmc_inuse & 0x7c)\r\nmmcr[0] |= MMCR0_PMCjCE;\r\nif (!(pmc_inuse & 0x60))\r\nmmcr[0] |= MMCR0_FC56;\r\nmmcr[1] = mmcr1;\r\nmmcr[2] = mmcra;\r\nreturn 0;\r\n}\r\nstatic int find_alternative(u64 event)\r\n{\r\nint i, j;\r\nfor (i = 0; i < ARRAY_SIZE(event_alternatives); ++i) {\r\nif (event < event_alternatives[i][0])\r\nbreak;\r\nfor (j = 0; j < MAX_ALT && event_alternatives[i][j]; ++j)\r\nif (event == event_alternatives[i][j])\r\nreturn i;\r\n}\r\nreturn -1;\r\n}\r\nstatic int power8_get_alternatives(u64 event, unsigned int flags, u64 alt[])\r\n{\r\nint i, j, num_alt = 0;\r\nu64 alt_event;\r\nalt[num_alt++] = event;\r\ni = find_alternative(event);\r\nif (i >= 0) {\r\nfor (j = 0; j < MAX_ALT; ++j) {\r\nalt_event = event_alternatives[i][j];\r\nif (alt_event && alt_event != event)\r\nalt[num_alt++] = alt_event;\r\n}\r\n}\r\nif (flags & PPMU_ONLY_COUNT_RUN) {\r\nj = num_alt;\r\nfor (i = 0; i < num_alt; ++i) {\r\nswitch (alt[i]) {\r\ncase 0x1e:\r\nalt[j++] = 0x600f4;\r\nbreak;\r\ncase 0x600f4:\r\nalt[j++] = 0x1e;\r\nbreak;\r\ncase 0x2:\r\nalt[j++] = 0x500fa;\r\nbreak;\r\ncase 0x500fa:\r\nalt[j++] = 0x2;\r\nbreak;\r\n}\r\n}\r\nnum_alt = j;\r\n}\r\nreturn num_alt;\r\n}\r\nstatic void power8_disable_pmc(unsigned int pmc, unsigned long mmcr[])\r\n{\r\nif (pmc <= 3)\r\nmmcr[1] &= ~(0xffUL << MMCR1_PMCSEL_SHIFT(pmc + 1));\r\n}\r\nstatic u64 power8_bhrb_filter_map(u64 branch_sample_type)\r\n{\r\nu64 pmu_bhrb_filter = 0;\r\nif (branch_sample_type & PERF_SAMPLE_BRANCH_ANY)\r\nreturn pmu_bhrb_filter;\r\nif (branch_sample_type & PERF_SAMPLE_BRANCH_ANY_RETURN)\r\nreturn -1;\r\nif (branch_sample_type & PERF_SAMPLE_BRANCH_IND_CALL)\r\nreturn -1;\r\nif (branch_sample_type & PERF_SAMPLE_BRANCH_ANY_CALL) {\r\npmu_bhrb_filter |= POWER8_MMCRA_IFM1;\r\nreturn pmu_bhrb_filter;\r\n}\r\nreturn -1;\r\n}\r\nstatic void power8_config_bhrb(u64 pmu_bhrb_filter)\r\n{\r\nmtspr(SPRN_MMCRA, (mfspr(SPRN_MMCRA) | pmu_bhrb_filter));\r\n}\r\nstatic int __init init_power8_pmu(void)\r\n{\r\nint rc;\r\nif (!cur_cpu_spec->oprofile_cpu_type ||\r\nstrcmp(cur_cpu_spec->oprofile_cpu_type, "ppc64/power8"))\r\nreturn -ENODEV;\r\nrc = register_power_pmu(&power8_pmu);\r\nif (rc)\r\nreturn rc;\r\ncur_cpu_spec->cpu_user_features2 |= PPC_FEATURE2_EBB;\r\nreturn 0;\r\n}
