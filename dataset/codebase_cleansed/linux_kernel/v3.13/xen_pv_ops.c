static void __init\r\nxen_info_init(void)\r\n{\r\nunsigned long rsc = ia64_getreg(_IA64_REG_AR_RSC);\r\nunsigned int rpl = (rsc & IA64_RSC_PL_MASK) >> IA64_RSC_PL_SHIFT;\r\nxen_info.kernel_rpl = rpl;\r\n}\r\nstatic void\r\nxen_panic_hypercall(struct unw_frame_info *info, void *arg)\r\n{\r\ncurrent->thread.ksp = (__u64)info->sw - 16;\r\nHYPERVISOR_shutdown(SHUTDOWN_crash);\r\n}\r\nstatic int\r\nxen_panic_event(struct notifier_block *this, unsigned long event, void *ptr)\r\n{\r\nunw_init_running(xen_panic_hypercall, NULL);\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic void xen_pm_power_off(void)\r\n{\r\nlocal_irq_disable();\r\nHYPERVISOR_shutdown(SHUTDOWN_poweroff);\r\n}\r\nstatic void __init\r\nxen_banner(void)\r\n{\r\nprintk(KERN_INFO\r\n"Running on Xen! pl = %d start_info_pfn=0x%lx nr_pages=%ld "\r\n"flags=0x%x\n",\r\nxen_info.kernel_rpl,\r\nHYPERVISOR_shared_info->arch.start_info_pfn,\r\nxen_start_info->nr_pages, xen_start_info->flags);\r\n}\r\nstatic int __init\r\nxen_reserve_memory(struct rsvd_region *region)\r\n{\r\nregion->start = (unsigned long)__va(\r\n(HYPERVISOR_shared_info->arch.start_info_pfn << PAGE_SHIFT));\r\nregion->end = region->start + PAGE_SIZE;\r\nreturn 1;\r\n}\r\nstatic void __init\r\nxen_arch_setup_early(void)\r\n{\r\nstruct shared_info *s;\r\nBUG_ON(!xen_pv_domain());\r\ns = HYPERVISOR_shared_info;\r\nxen_start_info = __va(s->arch.start_info_pfn << PAGE_SHIFT);\r\nxencomm_initialize();\r\nxen_setup_features();\r\natomic_notifier_chain_register(&panic_notifier_list,\r\n&xen_panic_block);\r\npm_power_off = xen_pm_power_off;\r\nxen_ia64_enable_opt_feature();\r\n}\r\nstatic void __init\r\nxen_arch_setup_console(char **cmdline_p)\r\n{\r\nadd_preferred_console("xenboot", 0, NULL);\r\nadd_preferred_console("tty", 0, NULL);\r\nadd_preferred_console("hvc", 0, NULL);\r\n#if !defined(CONFIG_VT) || !defined(CONFIG_DUMMY_CONSOLE)\r\nconswitchp = NULL;\r\n#endif\r\n}\r\nstatic int __init\r\nxen_arch_setup_nomca(void)\r\n{\r\nreturn 1;\r\n}\r\nstatic void __init\r\nxen_post_smp_prepare_boot_cpu(void)\r\n{\r\nxen_setup_vcpu_info_placement();\r\n}\r\nstatic void\r\nxen_set_itm_with_offset(unsigned long val)\r\n{\r\nxen_set_itm(val - XEN_MAPPEDREGS->itc_offset);\r\n}\r\nstatic unsigned long\r\nxen_get_itm_with_offset(void)\r\n{\r\nprintk(KERN_DEBUG "%s is called.\n", __func__);\r\nWARN_ON(!irqs_disabled());\r\nreturn ia64_native_getreg(_IA64_REG_CR_ITM) +\r\nXEN_MAPPEDREGS->itc_offset;\r\n}\r\nstatic void\r\nxen_set_itc(unsigned long val)\r\n{\r\nunsigned long mitc;\r\nWARN_ON(!irqs_disabled());\r\nmitc = ia64_native_getreg(_IA64_REG_AR_ITC);\r\nXEN_MAPPEDREGS->itc_offset = val - mitc;\r\nXEN_MAPPEDREGS->itc_last = val;\r\n}\r\nstatic unsigned long\r\nxen_get_itc(void)\r\n{\r\nunsigned long res;\r\nunsigned long itc_offset;\r\nunsigned long itc_last;\r\nunsigned long ret_itc_last;\r\nitc_offset = XEN_MAPPEDREGS->itc_offset;\r\ndo {\r\nitc_last = XEN_MAPPEDREGS->itc_last;\r\nres = ia64_native_getreg(_IA64_REG_AR_ITC);\r\nres += itc_offset;\r\nif (itc_last >= res)\r\nres = itc_last + 1;\r\nret_itc_last = cmpxchg(&XEN_MAPPEDREGS->itc_last,\r\nitc_last, res);\r\n} while (unlikely(ret_itc_last != itc_last));\r\nreturn res;\r\n#if 0\r\nWARN_ON(!irqs_disabled());\r\nitc_offset = XEN_MAPPEDREGS->itc_offset;\r\nitc_last = XEN_MAPPEDREGS->itc_last;\r\nres = ia64_native_getreg(_IA64_REG_AR_ITC);\r\nres += itc_offset;\r\nif (itc_last >= res)\r\nres = itc_last + 1;\r\nXEN_MAPPEDREGS->itc_last = res;\r\nreturn res;\r\n#endif\r\n}\r\nstatic void xen_setreg(int regnum, unsigned long val)\r\n{\r\nswitch (regnum) {\r\ncase _IA64_REG_AR_KR0 ... _IA64_REG_AR_KR7:\r\nxen_set_kr(regnum - _IA64_REG_AR_KR0, val);\r\nbreak;\r\ncase _IA64_REG_AR_ITC:\r\nxen_set_itc(val);\r\nbreak;\r\ncase _IA64_REG_CR_TPR:\r\nxen_set_tpr(val);\r\nbreak;\r\ncase _IA64_REG_CR_ITM:\r\nxen_set_itm_with_offset(val);\r\nbreak;\r\ncase _IA64_REG_CR_EOI:\r\nxen_eoi(val);\r\nbreak;\r\ndefault:\r\nia64_native_setreg_func(regnum, val);\r\nbreak;\r\n}\r\n}\r\nstatic unsigned long xen_getreg(int regnum)\r\n{\r\nunsigned long res;\r\nswitch (regnum) {\r\ncase _IA64_REG_PSR:\r\nres = xen_get_psr();\r\nbreak;\r\ncase _IA64_REG_AR_ITC:\r\nres = xen_get_itc();\r\nbreak;\r\ncase _IA64_REG_CR_ITM:\r\nres = xen_get_itm_with_offset();\r\nbreak;\r\ncase _IA64_REG_CR_IVR:\r\nres = xen_get_ivr();\r\nbreak;\r\ncase _IA64_REG_CR_TPR:\r\nres = xen_get_tpr();\r\nbreak;\r\ndefault:\r\nres = ia64_native_getreg_func(regnum);\r\nbreak;\r\n}\r\nreturn res;\r\n}\r\nstatic void\r\nxen_ssm_i(void)\r\n{\r\nint old = xen_get_virtual_psr_i();\r\nxen_set_virtual_psr_i(1);\r\nbarrier();\r\nif (!old && xen_get_virtual_pend())\r\nxen_hyper_ssm_i();\r\n}\r\nstatic void\r\nxen_rsm_i(void)\r\n{\r\nxen_set_virtual_psr_i(0);\r\nbarrier();\r\n}\r\nstatic unsigned long\r\nxen_get_psr_i(void)\r\n{\r\nreturn xen_get_virtual_psr_i() ? IA64_PSR_I : 0;\r\n}\r\nstatic void\r\nxen_intrin_local_irq_restore(unsigned long mask)\r\n{\r\nif (mask & IA64_PSR_I)\r\nxen_ssm_i();\r\nelse\r\nxen_rsm_i();\r\n}\r\nstatic void\r\nxen_pcat_compat_init(void)\r\n{\r\n}\r\nstatic struct irq_chip*\r\nxen_iosapic_get_irq_chip(unsigned long trigger)\r\n{\r\nreturn NULL;\r\n}\r\nstatic unsigned int\r\nxen_iosapic_read(char __iomem *iosapic, unsigned int reg)\r\n{\r\nstruct physdev_apic apic_op;\r\nint ret;\r\napic_op.apic_physbase = (unsigned long)iosapic -\r\n__IA64_UNCACHED_OFFSET;\r\napic_op.reg = reg;\r\nret = HYPERVISOR_physdev_op(PHYSDEVOP_apic_read, &apic_op);\r\nif (ret)\r\nreturn ret;\r\nreturn apic_op.value;\r\n}\r\nstatic void\r\nxen_iosapic_write(char __iomem *iosapic, unsigned int reg, u32 val)\r\n{\r\nstruct physdev_apic apic_op;\r\napic_op.apic_physbase = (unsigned long)iosapic -\r\n__IA64_UNCACHED_OFFSET;\r\napic_op.reg = reg;\r\napic_op.value = val;\r\nHYPERVISOR_physdev_op(PHYSDEVOP_apic_write, &apic_op);\r\n}\r\nvoid __init\r\nxen_setup_pv_ops(void)\r\n{\r\nxen_info_init();\r\npv_info = xen_info;\r\npv_init_ops = xen_init_ops;\r\npv_fsys_data = xen_fsys_data;\r\npv_patchdata = xen_patchdata;\r\npv_cpu_ops = xen_cpu_ops;\r\npv_iosapic_ops = xen_iosapic_ops;\r\npv_irq_ops = xen_irq_ops;\r\npv_time_ops = xen_time_ops;\r\nparavirt_cpu_asm_init(&xen_cpu_asm_switch);\r\n}\r\nstatic unsigned long __init_or_module\r\nxen_patch_bundle(void *sbundle, void *ebundle, unsigned long type)\r\n{\r\nconst unsigned long nelems = sizeof(xen_patch_bundle_elems) /\r\nsizeof(xen_patch_bundle_elems[0]);\r\nunsigned long used;\r\nconst struct paravirt_patch_bundle_elem *found;\r\nused = __paravirt_patch_apply_bundle(sbundle, ebundle, type,\r\nxen_patch_bundle_elems, nelems,\r\n&found);\r\nif (found == NULL)\r\nreturn ia64_native_patch_bundle(sbundle, ebundle, type);\r\nif (used == 0)\r\nreturn used;\r\nswitch (type) {\r\ncase PARAVIRT_PATCH_TYPE_INTRIN_LOCAL_IRQ_RESTORE: {\r\nunsigned long reloc =\r\n__xen_intrin_local_irq_restore_direct_reloc;\r\nunsigned long reloc_offset = reloc - (unsigned long)\r\n__xen_intrin_local_irq_restore_direct_start;\r\nunsigned long tag = (unsigned long)sbundle + reloc_offset;\r\nparavirt_patch_reloc_brl(tag, xen_check_events);\r\nbreak;\r\n}\r\ndefault:\r\nbreak;\r\n}\r\nreturn used;\r\n}\r\nstatic void __init\r\nxen_patch_branch(unsigned long tag, unsigned long type)\r\n{\r\n__paravirt_patch_apply_branch(tag, type, xen_branch_target,\r\nARRAY_SIZE(xen_branch_target));\r\n}
