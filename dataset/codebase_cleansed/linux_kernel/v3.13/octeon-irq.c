static void octeon_irq_set_ciu_mapping(int irq, int line, int bit, int gpio_line,\r\nstruct irq_chip *chip,\r\nirq_flow_handler_t handler)\r\n{\r\nunion octeon_ciu_chip_data cd;\r\nirq_set_chip_and_handler(irq, chip, handler);\r\ncd.l = 0;\r\ncd.s.line = line;\r\ncd.s.bit = bit;\r\ncd.s.gpio_line = gpio_line;\r\nirq_set_chip_data(irq, cd.p);\r\nocteon_irq_ciu_to_irq[line][bit] = irq;\r\n}\r\nstatic void octeon_irq_force_ciu_mapping(struct irq_domain *domain,\r\nint irq, int line, int bit)\r\n{\r\nirq_domain_associate(domain, irq, line << 6 | bit);\r\n}\r\nstatic int octeon_coreid_for_cpu(int cpu)\r\n{\r\n#ifdef CONFIG_SMP\r\nreturn cpu_logical_map(cpu);\r\n#else\r\nreturn cvmx_get_core_num();\r\n#endif\r\n}\r\nstatic int octeon_cpu_for_coreid(int coreid)\r\n{\r\n#ifdef CONFIG_SMP\r\nreturn cpu_number_map(coreid);\r\n#else\r\nreturn smp_processor_id();\r\n#endif\r\n}\r\nstatic void octeon_irq_core_ack(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nunsigned int bit = cd->bit;\r\nclear_c0_status(0x100 << bit);\r\nif (bit < 2)\r\nclear_c0_cause(0x100 << bit);\r\n}\r\nstatic void octeon_irq_core_eoi(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nset_c0_status(0x100 << cd->bit);\r\n}\r\nstatic void octeon_irq_core_set_enable_local(void *arg)\r\n{\r\nstruct irq_data *data = arg;\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nunsigned int mask = 0x100 << cd->bit;\r\nif (cd->desired_en)\r\nset_c0_status(mask);\r\nelse\r\nclear_c0_status(mask);\r\n}\r\nstatic void octeon_irq_core_disable(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\ncd->desired_en = false;\r\n}\r\nstatic void octeon_irq_core_enable(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\ncd->desired_en = true;\r\n}\r\nstatic void octeon_irq_core_bus_lock(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nmutex_lock(&cd->core_irq_mutex);\r\n}\r\nstatic void octeon_irq_core_bus_sync_unlock(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nif (cd->desired_en != cd->current_en) {\r\non_each_cpu(octeon_irq_core_set_enable_local, data, 1);\r\ncd->current_en = cd->desired_en;\r\n}\r\nmutex_unlock(&cd->core_irq_mutex);\r\n}\r\nstatic void __init octeon_irq_init_core(void)\r\n{\r\nint i;\r\nint irq;\r\nstruct octeon_core_chip_data *cd;\r\nfor (i = 0; i < MIPS_CORE_IRQ_LINES; i++) {\r\ncd = &octeon_irq_core_chip_data[i];\r\ncd->current_en = false;\r\ncd->desired_en = false;\r\ncd->bit = i;\r\nmutex_init(&cd->core_irq_mutex);\r\nirq = OCTEON_IRQ_SW0 + i;\r\nirq_set_chip_data(irq, cd);\r\nirq_set_chip_and_handler(irq, &octeon_irq_chip_core,\r\nhandle_percpu_irq);\r\n}\r\n}\r\nstatic int next_cpu_for_irq(struct irq_data *data)\r\n{\r\n#ifdef CONFIG_SMP\r\nint cpu;\r\nint weight = cpumask_weight(data->affinity);\r\nif (weight > 1) {\r\ncpu = smp_processor_id();\r\nfor (;;) {\r\ncpu = cpumask_next(cpu, data->affinity);\r\nif (cpu >= nr_cpu_ids) {\r\ncpu = -1;\r\ncontinue;\r\n} else if (cpumask_test_cpu(cpu, cpu_online_mask)) {\r\nbreak;\r\n}\r\n}\r\n} else if (weight == 1) {\r\ncpu = cpumask_first(data->affinity);\r\n} else {\r\ncpu = smp_processor_id();\r\n}\r\nreturn cpu;\r\n#else\r\nreturn smp_processor_id();\r\n#endif\r\n}\r\nstatic void octeon_irq_ciu_enable(struct irq_data *data)\r\n{\r\nint cpu = next_cpu_for_irq(data);\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nunsigned long *pen;\r\nunsigned long flags;\r\nunion octeon_ciu_chip_data cd;\r\nraw_spinlock_t *lock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd.s.line == 0) {\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\n__set_bit(cd.s.bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\n} else {\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\n__set_bit(cd.s.bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\n}\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu_enable_local(struct irq_data *data)\r\n{\r\nunsigned long *pen;\r\nunsigned long flags;\r\nunion octeon_ciu_chip_data cd;\r\nraw_spinlock_t *lock = &__get_cpu_var(octeon_irq_ciu_spinlock);\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd.s.line == 0) {\r\npen = &__get_cpu_var(octeon_irq_ciu0_en_mirror);\r\n__set_bit(cd.s.bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(cvmx_get_core_num() * 2), *pen);\r\n} else {\r\npen = &__get_cpu_var(octeon_irq_ciu1_en_mirror);\r\n__set_bit(cd.s.bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(cvmx_get_core_num() * 2 + 1), *pen);\r\n}\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu_disable_local(struct irq_data *data)\r\n{\r\nunsigned long *pen;\r\nunsigned long flags;\r\nunion octeon_ciu_chip_data cd;\r\nraw_spinlock_t *lock = &__get_cpu_var(octeon_irq_ciu_spinlock);\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd.s.line == 0) {\r\npen = &__get_cpu_var(octeon_irq_ciu0_en_mirror);\r\n__clear_bit(cd.s.bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(cvmx_get_core_num() * 2), *pen);\r\n} else {\r\npen = &__get_cpu_var(octeon_irq_ciu1_en_mirror);\r\n__clear_bit(cd.s.bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(cvmx_get_core_num() * 2 + 1), *pen);\r\n}\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu_disable_all(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nunsigned long *pen;\r\nint cpu;\r\nunion octeon_ciu_chip_data cd;\r\nraw_spinlock_t *lock;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nfor_each_online_cpu(cpu) {\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nlock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nif (cd.s.line == 0)\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nelse\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\n__clear_bit(cd.s.bit, pen);\r\nwmb();\r\nif (cd.s.line == 0)\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\nelse\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_all(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nunsigned long *pen;\r\nint cpu;\r\nunion octeon_ciu_chip_data cd;\r\nraw_spinlock_t *lock;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nfor_each_online_cpu(cpu) {\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nlock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nif (cd.s.line == 0)\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nelse\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\n__set_bit(cd.s.bit, pen);\r\nwmb();\r\nif (cd.s.line == 0)\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\nelse\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_v2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nint cpu = next_cpu_for_irq(data);\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nif (cd.s.line == 0) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nset_bit(cd.s.bit, &per_cpu(octeon_irq_ciu0_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n} else {\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nset_bit(cd.s.bit, &per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_local_v2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nif (cd.s.line == 0) {\r\nint index = cvmx_get_core_num() * 2;\r\nset_bit(cd.s.bit, &__get_cpu_var(octeon_irq_ciu0_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n} else {\r\nint index = cvmx_get_core_num() * 2 + 1;\r\nset_bit(cd.s.bit, &__get_cpu_var(octeon_irq_ciu1_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_disable_local_v2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nif (cd.s.line == 0) {\r\nint index = cvmx_get_core_num() * 2;\r\nclear_bit(cd.s.bit, &__get_cpu_var(octeon_irq_ciu0_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1C(index), mask);\r\n} else {\r\nint index = cvmx_get_core_num() * 2 + 1;\r\nclear_bit(cd.s.bit, &__get_cpu_var(octeon_irq_ciu1_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1C(index), mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_ack(struct irq_data *data)\r\n{\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nif (cd.s.line == 0) {\r\nint index = cvmx_get_core_num() * 2;\r\ncvmx_write_csr(CVMX_CIU_INTX_SUM0(index), mask);\r\n} else {\r\ncvmx_write_csr(CVMX_CIU_INT_SUM1, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_disable_all_v2(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nif (cd.s.line == 0) {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nclear_bit(cd.s.bit, &per_cpu(octeon_irq_ciu0_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1C(index), mask);\r\n}\r\n} else {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nclear_bit(cd.s.bit, &per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1C(index), mask);\r\n}\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_all_v2(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nif (cd.s.line == 0) {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nset_bit(cd.s.bit, &per_cpu(octeon_irq_ciu0_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n}\r\n} else {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nset_bit(cd.s.bit, &per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n}\r\n}\r\n}\r\nstatic void octeon_irq_gpio_setup(struct irq_data *data)\r\n{\r\nunion cvmx_gpio_bit_cfgx cfg;\r\nunion octeon_ciu_chip_data cd;\r\nu32 t = irqd_get_trigger_type(data);\r\ncd.p = irq_data_get_irq_chip_data(data);\r\ncfg.u64 = 0;\r\ncfg.s.int_en = 1;\r\ncfg.s.int_type = (t & IRQ_TYPE_EDGE_BOTH) != 0;\r\ncfg.s.rx_xor = (t & (IRQ_TYPE_LEVEL_LOW | IRQ_TYPE_EDGE_FALLING)) != 0;\r\ncfg.s.fil_cnt = 7;\r\ncfg.s.fil_sel = 3;\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd.s.gpio_line), cfg.u64);\r\n}\r\nstatic void octeon_irq_ciu_enable_gpio_v2(struct irq_data *data)\r\n{\r\nocteon_irq_gpio_setup(data);\r\nocteon_irq_ciu_enable_v2(data);\r\n}\r\nstatic void octeon_irq_ciu_enable_gpio(struct irq_data *data)\r\n{\r\nocteon_irq_gpio_setup(data);\r\nocteon_irq_ciu_enable(data);\r\n}\r\nstatic int octeon_irq_ciu_gpio_set_type(struct irq_data *data, unsigned int t)\r\n{\r\nirqd_set_trigger_type(data, t);\r\nocteon_irq_gpio_setup(data);\r\nreturn IRQ_SET_MASK_OK;\r\n}\r\nstatic void octeon_irq_ciu_disable_gpio_v2(struct irq_data *data)\r\n{\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd.s.gpio_line), 0);\r\nocteon_irq_ciu_disable_all_v2(data);\r\n}\r\nstatic void octeon_irq_ciu_disable_gpio(struct irq_data *data)\r\n{\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd.s.gpio_line), 0);\r\nocteon_irq_ciu_disable_all(data);\r\n}\r\nstatic void octeon_irq_ciu_gpio_ack(struct irq_data *data)\r\n{\r\nunion octeon_ciu_chip_data cd;\r\nu64 mask;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.gpio_line);\r\ncvmx_write_csr(CVMX_GPIO_INT_CLR, mask);\r\n}\r\nstatic void octeon_irq_handle_gpio(unsigned int irq, struct irq_desc *desc)\r\n{\r\nif (irq_get_trigger_type(irq) & IRQ_TYPE_EDGE_BOTH)\r\nhandle_edge_irq(irq, desc);\r\nelse\r\nhandle_level_irq(irq, desc);\r\n}\r\nstatic void octeon_irq_cpu_offline_ciu(struct irq_data *data)\r\n{\r\nint cpu = smp_processor_id();\r\ncpumask_t new_affinity;\r\nif (!cpumask_test_cpu(cpu, data->affinity))\r\nreturn;\r\nif (cpumask_weight(data->affinity) > 1) {\r\ncpumask_copy(&new_affinity, data->affinity);\r\ncpumask_clear_cpu(cpu, &new_affinity);\r\n} else {\r\ncpumask_clear(&new_affinity);\r\ncpumask_set_cpu(cpumask_first(cpu_online_mask), &new_affinity);\r\n}\r\n__irq_set_affinity_locked(data, &new_affinity);\r\n}\r\nstatic int octeon_irq_ciu_set_affinity(struct irq_data *data,\r\nconst struct cpumask *dest, bool force)\r\n{\r\nint cpu;\r\nbool enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);\r\nunsigned long flags;\r\nunion octeon_ciu_chip_data cd;\r\nunsigned long *pen;\r\nraw_spinlock_t *lock;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nif (cpumask_weight(dest) != 1)\r\nreturn -EINVAL;\r\nif (!enable_one)\r\nreturn 0;\r\nfor_each_online_cpu(cpu) {\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nlock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd.s.line == 0)\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nelse\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = 0;\r\n__set_bit(cd.s.bit, pen);\r\n} else {\r\n__clear_bit(cd.s.bit, pen);\r\n}\r\nwmb();\r\nif (cd.s.line == 0)\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\nelse\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_ciu_set_affinity_v2(struct irq_data *data,\r\nconst struct cpumask *dest,\r\nbool force)\r\n{\r\nint cpu;\r\nbool enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\nif (!enable_one)\r\nreturn 0;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << cd.s.bit;\r\nif (cd.s.line == 0) {\r\nfor_each_online_cpu(cpu) {\r\nunsigned long *pen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = false;\r\nset_bit(cd.s.bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n} else {\r\nclear_bit(cd.s.bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1C(index), mask);\r\n}\r\n}\r\n} else {\r\nfor_each_online_cpu(cpu) {\r\nunsigned long *pen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = false;\r\nset_bit(cd.s.bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n} else {\r\nclear_bit(cd.s.bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1C(index), mask);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void octeon_irq_ciu_wd_enable(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nunsigned long *pen;\r\nint coreid = data->irq - OCTEON_IRQ_WDOG0;\r\nint cpu = octeon_cpu_for_coreid(coreid);\r\nraw_spinlock_t *lock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\n__set_bit(coreid, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu1_wd_enable_v2(struct irq_data *data)\r\n{\r\nint coreid = data->irq - OCTEON_IRQ_WDOG0;\r\nint cpu = octeon_cpu_for_coreid(coreid);\r\nset_bit(coreid, &per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(coreid * 2 + 1), 1ull << coreid);\r\n}\r\nstatic bool octeon_irq_ciu_is_edge(unsigned int line, unsigned int bit)\r\n{\r\nbool edge = false;\r\nif (line == 0)\r\nswitch (bit) {\r\ncase 48 ... 49:\r\ncase 50:\r\ncase 52 ... 55:\r\ncase 58:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nelse\r\nswitch (bit) {\r\ncase 47:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn edge;\r\n}\r\nstatic int octeon_irq_gpio_xlat(struct irq_domain *d,\r\nstruct device_node *node,\r\nconst u32 *intspec,\r\nunsigned int intsize,\r\nunsigned long *out_hwirq,\r\nunsigned int *out_type)\r\n{\r\nunsigned int type;\r\nunsigned int pin;\r\nunsigned int trigger;\r\nif (d->of_node != node)\r\nreturn -EINVAL;\r\nif (intsize < 2)\r\nreturn -EINVAL;\r\npin = intspec[0];\r\nif (pin >= 16)\r\nreturn -EINVAL;\r\ntrigger = intspec[1];\r\nswitch (trigger) {\r\ncase 1:\r\ntype = IRQ_TYPE_EDGE_RISING;\r\nbreak;\r\ncase 2:\r\ntype = IRQ_TYPE_EDGE_FALLING;\r\nbreak;\r\ncase 4:\r\ntype = IRQ_TYPE_LEVEL_HIGH;\r\nbreak;\r\ncase 8:\r\ntype = IRQ_TYPE_LEVEL_LOW;\r\nbreak;\r\ndefault:\r\npr_err("Error: (%s) Invalid irq trigger specification: %x\n",\r\nnode->name,\r\ntrigger);\r\ntype = IRQ_TYPE_LEVEL_LOW;\r\nbreak;\r\n}\r\n*out_type = type;\r\n*out_hwirq = pin;\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_ciu_xlat(struct irq_domain *d,\r\nstruct device_node *node,\r\nconst u32 *intspec,\r\nunsigned int intsize,\r\nunsigned long *out_hwirq,\r\nunsigned int *out_type)\r\n{\r\nunsigned int ciu, bit;\r\nciu = intspec[0];\r\nbit = intspec[1];\r\nif (ciu > 1 || bit > 63)\r\nreturn -EINVAL;\r\nif (ciu == 0 && bit >= 16 && bit < 32)\r\nreturn -EINVAL;\r\n*out_hwirq = (ciu << 6) | bit;\r\n*out_type = 0;\r\nreturn 0;\r\n}\r\nstatic bool octeon_irq_virq_in_range(unsigned int virq)\r\n{\r\nif (virq < (1ul << 8 * sizeof(octeon_irq_ciu_to_irq[0][0])))\r\nreturn true;\r\nWARN_ONCE(true, "virq out of range %u.\n", virq);\r\nreturn false;\r\n}\r\nstatic int octeon_irq_ciu_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nunsigned int line = hw >> 6;\r\nunsigned int bit = hw & 63;\r\nif (!octeon_irq_virq_in_range(virq))\r\nreturn -EINVAL;\r\nif (line > 1 || octeon_irq_ciu_to_irq[line][bit] != 0)\r\nreturn -EINVAL;\r\nif (octeon_irq_ciu_is_edge(line, bit))\r\nocteon_irq_set_ciu_mapping(virq, line, bit, 0,\r\nocteon_irq_ciu_chip,\r\nhandle_edge_irq);\r\nelse\r\nocteon_irq_set_ciu_mapping(virq, line, bit, 0,\r\nocteon_irq_ciu_chip,\r\nhandle_level_irq);\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_gpio_map_common(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw,\r\nint line_limit, struct irq_chip *chip)\r\n{\r\nstruct octeon_irq_gpio_domain_data *gpiod = d->host_data;\r\nunsigned int line, bit;\r\nif (!octeon_irq_virq_in_range(virq))\r\nreturn -EINVAL;\r\nline = (hw + gpiod->base_hwirq) >> 6;\r\nbit = (hw + gpiod->base_hwirq) & 63;\r\nif (line > line_limit || octeon_irq_ciu_to_irq[line][bit] != 0)\r\nreturn -EINVAL;\r\nocteon_irq_set_ciu_mapping(virq, line, bit, hw,\r\nchip, octeon_irq_handle_gpio);\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_gpio_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nreturn octeon_irq_gpio_map_common(d, virq, hw, 1, octeon_irq_gpio_chip);\r\n}\r\nstatic void octeon_irq_ip2_ciu(void)\r\n{\r\nconst unsigned long core_id = cvmx_get_core_num();\r\nu64 ciu_sum = cvmx_read_csr(CVMX_CIU_INTX_SUM0(core_id * 2));\r\nciu_sum &= __get_cpu_var(octeon_irq_ciu0_en_mirror);\r\nif (likely(ciu_sum)) {\r\nint bit = fls64(ciu_sum) - 1;\r\nint irq = octeon_irq_ciu_to_irq[0][bit];\r\nif (likely(irq))\r\ndo_IRQ(irq);\r\nelse\r\nspurious_interrupt();\r\n} else {\r\nspurious_interrupt();\r\n}\r\n}\r\nstatic void octeon_irq_ip3_ciu(void)\r\n{\r\nu64 ciu_sum = cvmx_read_csr(CVMX_CIU_INT_SUM1);\r\nciu_sum &= __get_cpu_var(octeon_irq_ciu1_en_mirror);\r\nif (likely(ciu_sum)) {\r\nint bit = fls64(ciu_sum) - 1;\r\nint irq = octeon_irq_ciu_to_irq[1][bit];\r\nif (likely(irq))\r\ndo_IRQ(irq);\r\nelse\r\nspurious_interrupt();\r\n} else {\r\nspurious_interrupt();\r\n}\r\n}\r\nstatic void octeon_irq_local_enable_ip4(void *arg)\r\n{\r\nset_c0_status(STATUSF_IP4);\r\n}\r\nstatic void octeon_irq_ip4_mask(void)\r\n{\r\nclear_c0_status(STATUSF_IP4);\r\nspurious_interrupt();\r\n}\r\nvoid octeon_irq_set_ip4_handler(octeon_irq_ip4_handler_t h)\r\n{\r\nocteon_irq_ip4 = h;\r\nocteon_irq_use_ip4 = true;\r\non_each_cpu(octeon_irq_local_enable_ip4, NULL, 1);\r\n}\r\nstatic void octeon_irq_percpu_enable(void)\r\n{\r\nirq_cpu_online();\r\n}\r\nstatic void octeon_irq_init_ciu_percpu(void)\r\n{\r\nint coreid = cvmx_get_core_num();\r\n__get_cpu_var(octeon_irq_ciu0_en_mirror) = 0;\r\n__get_cpu_var(octeon_irq_ciu1_en_mirror) = 0;\r\nwmb();\r\nraw_spin_lock_init(&__get_cpu_var(octeon_irq_ciu_spinlock));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2)), 0);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2 + 1)), 0);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2)), 0);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2 + 1)), 0);\r\ncvmx_read_csr(CVMX_CIU_INTX_SUM0((coreid * 2)));\r\n}\r\nstatic void octeon_irq_init_ciu2_percpu(void)\r\n{\r\nu64 regx, ipx;\r\nint coreid = cvmx_get_core_num();\r\nu64 base = CVMX_CIU2_EN_PPX_IP2_WRKQ(coreid);\r\nfor (regx = 0; regx <= 0x8000; regx += 0x1000) {\r\nfor (ipx = 0; ipx <= 0x400; ipx += 0x200)\r\ncvmx_write_csr(base + regx + ipx, 0);\r\n}\r\ncvmx_read_csr(CVMX_CIU2_SUM_PPX_IP2(coreid));\r\n}\r\nstatic void octeon_irq_setup_secondary_ciu(void)\r\n{\r\nocteon_irq_init_ciu_percpu();\r\nocteon_irq_percpu_enable();\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nclear_c0_status(STATUSF_IP4);\r\n}\r\nstatic void octeon_irq_setup_secondary_ciu2(void)\r\n{\r\nocteon_irq_init_ciu2_percpu();\r\nocteon_irq_percpu_enable();\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nif (octeon_irq_use_ip4)\r\nset_c0_status(STATUSF_IP4);\r\nelse\r\nclear_c0_status(STATUSF_IP4);\r\n}\r\nstatic void __init octeon_irq_init_ciu(void)\r\n{\r\nunsigned int i;\r\nstruct irq_chip *chip;\r\nstruct irq_chip *chip_mbox;\r\nstruct irq_chip *chip_wd;\r\nstruct device_node *gpio_node;\r\nstruct device_node *ciu_node;\r\nstruct irq_domain *ciu_domain = NULL;\r\nocteon_irq_init_ciu_percpu();\r\nocteon_irq_setup_secondary = octeon_irq_setup_secondary_ciu;\r\nocteon_irq_ip2 = octeon_irq_ip2_ciu;\r\nocteon_irq_ip3 = octeon_irq_ip3_ciu;\r\nif (OCTEON_IS_MODEL(OCTEON_CN58XX_PASS2_X) ||\r\nOCTEON_IS_MODEL(OCTEON_CN56XX_PASS2_X) ||\r\nOCTEON_IS_MODEL(OCTEON_CN52XX_PASS2_X) ||\r\nOCTEON_IS_MODEL(OCTEON_CN6XXX)) {\r\nchip = &octeon_irq_chip_ciu_v2;\r\nchip_mbox = &octeon_irq_chip_ciu_mbox_v2;\r\nchip_wd = &octeon_irq_chip_ciu_wd_v2;\r\nocteon_irq_gpio_chip = &octeon_irq_chip_ciu_gpio_v2;\r\n} else {\r\nchip = &octeon_irq_chip_ciu;\r\nchip_mbox = &octeon_irq_chip_ciu_mbox;\r\nchip_wd = &octeon_irq_chip_ciu_wd;\r\nocteon_irq_gpio_chip = &octeon_irq_chip_ciu_gpio;\r\n}\r\nocteon_irq_ciu_chip = chip;\r\nocteon_irq_ip4 = octeon_irq_ip4_mask;\r\nocteon_irq_init_core();\r\ngpio_node = of_find_compatible_node(NULL, NULL, "cavium,octeon-3860-gpio");\r\nif (gpio_node) {\r\nstruct octeon_irq_gpio_domain_data *gpiod;\r\ngpiod = kzalloc(sizeof(*gpiod), GFP_KERNEL);\r\nif (gpiod) {\r\ngpiod->base_hwirq = 16;\r\nirq_domain_add_linear(gpio_node, 16, &octeon_irq_domain_gpio_ops, gpiod);\r\nof_node_put(gpio_node);\r\n} else\r\npr_warn("Cannot allocate memory for GPIO irq_domain.\n");\r\n} else\r\npr_warn("Cannot find device node for cavium,octeon-3860-gpio.\n");\r\nciu_node = of_find_compatible_node(NULL, NULL, "cavium,octeon-3860-ciu");\r\nif (ciu_node) {\r\nciu_domain = irq_domain_add_tree(ciu_node, &octeon_irq_domain_ciu_ops, NULL);\r\nirq_set_default_host(ciu_domain);\r\nof_node_put(ciu_node);\r\n} else\r\npanic("Cannot find device node for cavium,octeon-3860-ciu.");\r\nfor (i = 0; i < 16; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_WORKQ0, 0, i + 0);\r\nocteon_irq_set_ciu_mapping(OCTEON_IRQ_MBOX0, 0, 32, 0, chip_mbox, handle_percpu_irq);\r\nocteon_irq_set_ciu_mapping(OCTEON_IRQ_MBOX1, 0, 33, 0, chip_mbox, handle_percpu_irq);\r\nfor (i = 0; i < 4; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_PCI_INT0, 0, i + 36);\r\nfor (i = 0; i < 4; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_PCI_MSI0, 0, i + 40);\r\nocteon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_RML, 0, 46);\r\nfor (i = 0; i < 4; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_TIMER0, 0, i + 52);\r\nocteon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_USB0, 0, 56);\r\nfor (i = 0; i < 16; i++)\r\nocteon_irq_set_ciu_mapping(i + OCTEON_IRQ_WDOG0, 1, i + 0, 0, chip_wd, handle_level_irq);\r\nocteon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_USB1, 1, 17);\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nclear_c0_status(STATUSF_IP4);\r\n}\r\nstatic void octeon_irq_ciu2_wd_enable(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = data->irq - OCTEON_IRQ_WDOG0;\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) + (0x1000ull * cd.s.line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_enable(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint cpu = next_cpu_for_irq(data);\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) + (0x1000ull * cd.s.line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_enable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) + (0x1000ull * cd.s.line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_disable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(coreid) + (0x1000ull * cd.s.line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_ack(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nen_addr = CVMX_CIU2_RAW_PPX_IP2_WRKQ(coreid) + (0x1000ull * cd.s.line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_disable_all(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd.s.bit);\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(octeon_coreid_for_cpu(cpu)) + (0x1000ull * cd.s.line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu2_mbox_enable_all(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1S(octeon_coreid_for_cpu(cpu));\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu2_mbox_disable_all(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1C(octeon_coreid_for_cpu(cpu));\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu2_mbox_enable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nen_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1S(coreid);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_mbox_disable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nen_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1C(coreid);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic int octeon_irq_ciu2_set_affinity(struct irq_data *data,\r\nconst struct cpumask *dest, bool force)\r\n{\r\nint cpu;\r\nbool enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);\r\nu64 mask;\r\nunion octeon_ciu_chip_data cd;\r\nif (!enable_one)\r\nreturn 0;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << cd.s.bit;\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr;\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = false;\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(octeon_coreid_for_cpu(cpu)) + (0x1000ull * cd.s.line);\r\n} else {\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(octeon_coreid_for_cpu(cpu)) + (0x1000ull * cd.s.line);\r\n}\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nreturn 0;\r\n}\r\nstatic void octeon_irq_ciu2_enable_gpio(struct irq_data *data)\r\n{\r\nocteon_irq_gpio_setup(data);\r\nocteon_irq_ciu2_enable(data);\r\n}\r\nstatic void octeon_irq_ciu2_disable_gpio(struct irq_data *data)\r\n{\r\nunion octeon_ciu_chip_data cd;\r\ncd.p = irq_data_get_irq_chip_data(data);\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd.s.gpio_line), 0);\r\nocteon_irq_ciu2_disable_all(data);\r\n}\r\nstatic int octeon_irq_ciu2_xlat(struct irq_domain *d,\r\nstruct device_node *node,\r\nconst u32 *intspec,\r\nunsigned int intsize,\r\nunsigned long *out_hwirq,\r\nunsigned int *out_type)\r\n{\r\nunsigned int ciu, bit;\r\nciu = intspec[0];\r\nbit = intspec[1];\r\nif (ciu > 6 || bit > 63)\r\nreturn -EINVAL;\r\n*out_hwirq = (ciu << 6) | bit;\r\n*out_type = 0;\r\nreturn 0;\r\n}\r\nstatic bool octeon_irq_ciu2_is_edge(unsigned int line, unsigned int bit)\r\n{\r\nbool edge = false;\r\nif (line == 3)\r\nswitch (bit) {\r\ncase 2:\r\ncase 8 ... 11:\r\ncase 48:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nelse if (line == 6)\r\nswitch (bit) {\r\ncase 52 ... 53:\r\ncase 8 ... 12:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn edge;\r\n}\r\nstatic int octeon_irq_ciu2_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nunsigned int line = hw >> 6;\r\nunsigned int bit = hw & 63;\r\nif (!octeon_irq_virq_in_range(virq))\r\nreturn -EINVAL;\r\nif (line > 6 || octeon_irq_ciu_to_irq[line][bit] != 0)\r\nreturn -EINVAL;\r\nif (octeon_irq_ciu2_is_edge(line, bit))\r\nocteon_irq_set_ciu_mapping(virq, line, bit, 0,\r\n&octeon_irq_chip_ciu2,\r\nhandle_edge_irq);\r\nelse\r\nocteon_irq_set_ciu_mapping(virq, line, bit, 0,\r\n&octeon_irq_chip_ciu2,\r\nhandle_level_irq);\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_ciu2_gpio_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nreturn octeon_irq_gpio_map_common(d, virq, hw, 7, &octeon_irq_chip_ciu2_gpio);\r\n}\r\nstatic void octeon_irq_ciu2(void)\r\n{\r\nint line;\r\nint bit;\r\nint irq;\r\nu64 src_reg, src, sum;\r\nconst unsigned long core_id = cvmx_get_core_num();\r\nsum = cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP2(core_id)) & 0xfful;\r\nif (unlikely(!sum))\r\ngoto spurious;\r\nline = fls64(sum) - 1;\r\nsrc_reg = CVMX_CIU2_SRC_PPX_IP2_WRKQ(core_id) + (0x1000 * line);\r\nsrc = cvmx_read_csr(src_reg);\r\nif (unlikely(!src))\r\ngoto spurious;\r\nbit = fls64(src) - 1;\r\nirq = octeon_irq_ciu_to_irq[line][bit];\r\nif (unlikely(!irq))\r\ngoto spurious;\r\ndo_IRQ(irq);\r\ngoto out;\r\nspurious:\r\nspurious_interrupt();\r\nout:\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX))\r\ncvmx_read_csr(CVMX_CIU2_INTR_CIU_READY);\r\nelse\r\ncvmx_read_csr(CVMX_CIU2_ACK_PPX_IP2(core_id));\r\nreturn;\r\n}\r\nstatic void octeon_irq_ciu2_mbox(void)\r\n{\r\nint line;\r\nconst unsigned long core_id = cvmx_get_core_num();\r\nu64 sum = cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP3(core_id)) >> 60;\r\nif (unlikely(!sum))\r\ngoto spurious;\r\nline = fls64(sum) - 1;\r\ndo_IRQ(OCTEON_IRQ_MBOX0 + line);\r\ngoto out;\r\nspurious:\r\nspurious_interrupt();\r\nout:\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX))\r\ncvmx_read_csr(CVMX_CIU2_INTR_CIU_READY);\r\nelse\r\ncvmx_read_csr(CVMX_CIU2_ACK_PPX_IP3(core_id));\r\nreturn;\r\n}\r\nstatic void __init octeon_irq_init_ciu2(void)\r\n{\r\nunsigned int i;\r\nstruct device_node *gpio_node;\r\nstruct device_node *ciu_node;\r\nstruct irq_domain *ciu_domain = NULL;\r\nocteon_irq_init_ciu2_percpu();\r\nocteon_irq_setup_secondary = octeon_irq_setup_secondary_ciu2;\r\nocteon_irq_ip2 = octeon_irq_ciu2;\r\nocteon_irq_ip3 = octeon_irq_ciu2_mbox;\r\nocteon_irq_ip4 = octeon_irq_ip4_mask;\r\nocteon_irq_init_core();\r\ngpio_node = of_find_compatible_node(NULL, NULL, "cavium,octeon-3860-gpio");\r\nif (gpio_node) {\r\nstruct octeon_irq_gpio_domain_data *gpiod;\r\ngpiod = kzalloc(sizeof(*gpiod), GFP_KERNEL);\r\nif (gpiod) {\r\ngpiod->base_hwirq = 7 << 6;\r\nirq_domain_add_linear(gpio_node, 16, &octeon_irq_domain_ciu2_gpio_ops, gpiod);\r\nof_node_put(gpio_node);\r\n} else\r\npr_warn("Cannot allocate memory for GPIO irq_domain.\n");\r\n} else\r\npr_warn("Cannot find device node for cavium,octeon-3860-gpio.\n");\r\nciu_node = of_find_compatible_node(NULL, NULL, "cavium,octeon-6880-ciu2");\r\nif (ciu_node) {\r\nciu_domain = irq_domain_add_tree(ciu_node, &octeon_irq_domain_ciu2_ops, NULL);\r\nirq_set_default_host(ciu_domain);\r\nof_node_put(ciu_node);\r\n} else\r\npanic("Cannot find device node for cavium,octeon-6880-ciu2.");\r\nfor (i = 0; i < 64; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_WORKQ0, 0, i);\r\nfor (i = 0; i < 32; i++)\r\nocteon_irq_set_ciu_mapping(i + OCTEON_IRQ_WDOG0, 1, i, 0,\r\n&octeon_irq_chip_ciu2_wd, handle_level_irq);\r\nfor (i = 0; i < 4; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_TIMER0, 3, i + 8);\r\nocteon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_USB0, 3, 44);\r\nfor (i = 0; i < 4; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_PCI_INT0, 4, i);\r\nfor (i = 0; i < 4; i++)\r\nocteon_irq_force_ciu_mapping(ciu_domain, i + OCTEON_IRQ_PCI_MSI0, 4, i + 8);\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX0, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX1, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX2, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX3, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nclear_c0_status(STATUSF_IP4);\r\n}\r\nvoid __init arch_init_irq(void)\r\n{\r\n#ifdef CONFIG_SMP\r\ncpumask_clear(irq_default_affinity);\r\ncpumask_set_cpu(smp_processor_id(), irq_default_affinity);\r\n#endif\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX))\r\nocteon_irq_init_ciu2();\r\nelse\r\nocteon_irq_init_ciu();\r\n}\r\nasmlinkage void plat_irq_dispatch(void)\r\n{\r\nunsigned long cop0_cause;\r\nunsigned long cop0_status;\r\nwhile (1) {\r\ncop0_cause = read_c0_cause();\r\ncop0_status = read_c0_status();\r\ncop0_cause &= cop0_status;\r\ncop0_cause &= ST0_IM;\r\nif (unlikely(cop0_cause & STATUSF_IP2))\r\nocteon_irq_ip2();\r\nelse if (unlikely(cop0_cause & STATUSF_IP3))\r\nocteon_irq_ip3();\r\nelse if (unlikely(cop0_cause & STATUSF_IP4))\r\nocteon_irq_ip4();\r\nelse if (likely(cop0_cause))\r\ndo_IRQ(fls(cop0_cause) - 9 + MIPS_CPU_IRQ_BASE);\r\nelse\r\nbreak;\r\n}\r\n}\r\nvoid octeon_fixup_irqs(void)\r\n{\r\nirq_cpu_offline();\r\n}
