static int lowlevel_buffer_allocate(struct drm_device *dev,\r\nunsigned int flags, struct exynos_drm_gem_buf *buf)\r\n{\r\nint ret = 0;\r\nenum dma_attr attr;\r\nunsigned int nr_pages;\r\nif (buf->dma_addr) {\r\nDRM_DEBUG_KMS("already allocated.\n");\r\nreturn 0;\r\n}\r\ninit_dma_attrs(&buf->dma_attrs);\r\nif (!(flags & EXYNOS_BO_NONCONTIG))\r\ndma_set_attr(DMA_ATTR_FORCE_CONTIGUOUS, &buf->dma_attrs);\r\nif (flags & EXYNOS_BO_WC || !(flags & EXYNOS_BO_CACHABLE))\r\nattr = DMA_ATTR_WRITE_COMBINE;\r\nelse\r\nattr = DMA_ATTR_NON_CONSISTENT;\r\ndma_set_attr(attr, &buf->dma_attrs);\r\ndma_set_attr(DMA_ATTR_NO_KERNEL_MAPPING, &buf->dma_attrs);\r\nnr_pages = buf->size >> PAGE_SHIFT;\r\nif (!is_drm_iommu_supported(dev)) {\r\ndma_addr_t start_addr;\r\nunsigned int i = 0;\r\nbuf->pages = drm_calloc_large(nr_pages, sizeof(struct page *));\r\nif (!buf->pages) {\r\nDRM_ERROR("failed to allocate pages.\n");\r\nreturn -ENOMEM;\r\n}\r\nbuf->kvaddr = (void __iomem *)dma_alloc_attrs(dev->dev,\r\nbuf->size,\r\n&buf->dma_addr, GFP_KERNEL,\r\n&buf->dma_attrs);\r\nif (!buf->kvaddr) {\r\nDRM_ERROR("failed to allocate buffer.\n");\r\nret = -ENOMEM;\r\ngoto err_free;\r\n}\r\nstart_addr = buf->dma_addr;\r\nwhile (i < nr_pages) {\r\nbuf->pages[i] = phys_to_page(start_addr);\r\nstart_addr += PAGE_SIZE;\r\ni++;\r\n}\r\n} else {\r\nbuf->pages = dma_alloc_attrs(dev->dev, buf->size,\r\n&buf->dma_addr, GFP_KERNEL,\r\n&buf->dma_attrs);\r\nif (!buf->pages) {\r\nDRM_ERROR("failed to allocate buffer.\n");\r\nreturn -ENOMEM;\r\n}\r\n}\r\nbuf->sgt = drm_prime_pages_to_sg(buf->pages, nr_pages);\r\nif (IS_ERR(buf->sgt)) {\r\nDRM_ERROR("failed to get sg table.\n");\r\nret = PTR_ERR(buf->sgt);\r\ngoto err_free_attrs;\r\n}\r\nDRM_DEBUG_KMS("dma_addr(0x%lx), size(0x%lx)\n",\r\n(unsigned long)buf->dma_addr,\r\nbuf->size);\r\nreturn ret;\r\nerr_free_attrs:\r\ndma_free_attrs(dev->dev, buf->size, buf->pages,\r\n(dma_addr_t)buf->dma_addr, &buf->dma_attrs);\r\nbuf->dma_addr = (dma_addr_t)NULL;\r\nerr_free:\r\nif (!is_drm_iommu_supported(dev))\r\ndrm_free_large(buf->pages);\r\nreturn ret;\r\n}\r\nstatic void lowlevel_buffer_deallocate(struct drm_device *dev,\r\nunsigned int flags, struct exynos_drm_gem_buf *buf)\r\n{\r\nif (!buf->dma_addr) {\r\nDRM_DEBUG_KMS("dma_addr is invalid.\n");\r\nreturn;\r\n}\r\nDRM_DEBUG_KMS("dma_addr(0x%lx), size(0x%lx)\n",\r\n(unsigned long)buf->dma_addr,\r\nbuf->size);\r\nsg_free_table(buf->sgt);\r\nkfree(buf->sgt);\r\nbuf->sgt = NULL;\r\nif (!is_drm_iommu_supported(dev)) {\r\ndma_free_attrs(dev->dev, buf->size, buf->kvaddr,\r\n(dma_addr_t)buf->dma_addr, &buf->dma_attrs);\r\ndrm_free_large(buf->pages);\r\n} else\r\ndma_free_attrs(dev->dev, buf->size, buf->pages,\r\n(dma_addr_t)buf->dma_addr, &buf->dma_attrs);\r\nbuf->dma_addr = (dma_addr_t)NULL;\r\n}\r\nstruct exynos_drm_gem_buf *exynos_drm_init_buf(struct drm_device *dev,\r\nunsigned int size)\r\n{\r\nstruct exynos_drm_gem_buf *buffer;\r\nDRM_DEBUG_KMS("desired size = 0x%x\n", size);\r\nbuffer = kzalloc(sizeof(*buffer), GFP_KERNEL);\r\nif (!buffer)\r\nreturn NULL;\r\nbuffer->size = size;\r\nreturn buffer;\r\n}\r\nvoid exynos_drm_fini_buf(struct drm_device *dev,\r\nstruct exynos_drm_gem_buf *buffer)\r\n{\r\nkfree(buffer);\r\nbuffer = NULL;\r\n}\r\nint exynos_drm_alloc_buf(struct drm_device *dev,\r\nstruct exynos_drm_gem_buf *buf, unsigned int flags)\r\n{\r\nif (lowlevel_buffer_allocate(dev, flags, buf) < 0)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid exynos_drm_free_buf(struct drm_device *dev,\r\nunsigned int flags, struct exynos_drm_gem_buf *buffer)\r\n{\r\nlowlevel_buffer_deallocate(dev, flags, buffer);\r\n}
