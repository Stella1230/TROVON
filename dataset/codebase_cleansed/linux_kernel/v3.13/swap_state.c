unsigned long total_swapcache_pages(void)\r\n{\r\nint i;\r\nunsigned long ret = 0;\r\nfor (i = 0; i < MAX_SWAPFILES; i++)\r\nret += swapper_spaces[i].nrpages;\r\nreturn ret;\r\n}\r\nvoid show_swap_cache_info(void)\r\n{\r\nprintk("%lu pages in swap cache\n", total_swapcache_pages());\r\nprintk("Swap cache stats: add %lu, delete %lu, find %lu/%lu\n",\r\nswap_cache_info.add_total, swap_cache_info.del_total,\r\nswap_cache_info.find_success, swap_cache_info.find_total);\r\nprintk("Free swap = %ldkB\n",\r\nget_nr_swap_pages() << (PAGE_SHIFT - 10));\r\nprintk("Total swap = %lukB\n", total_swap_pages << (PAGE_SHIFT - 10));\r\n}\r\nint __add_to_swap_cache(struct page *page, swp_entry_t entry)\r\n{\r\nint error;\r\nstruct address_space *address_space;\r\nVM_BUG_ON(!PageLocked(page));\r\nVM_BUG_ON(PageSwapCache(page));\r\nVM_BUG_ON(!PageSwapBacked(page));\r\npage_cache_get(page);\r\nSetPageSwapCache(page);\r\nset_page_private(page, entry.val);\r\naddress_space = swap_address_space(entry);\r\nspin_lock_irq(&address_space->tree_lock);\r\nerror = radix_tree_insert(&address_space->page_tree,\r\nentry.val, page);\r\nif (likely(!error)) {\r\naddress_space->nrpages++;\r\n__inc_zone_page_state(page, NR_FILE_PAGES);\r\nINC_CACHE_INFO(add_total);\r\n}\r\nspin_unlock_irq(&address_space->tree_lock);\r\nif (unlikely(error)) {\r\nVM_BUG_ON(error == -EEXIST);\r\nset_page_private(page, 0UL);\r\nClearPageSwapCache(page);\r\npage_cache_release(page);\r\n}\r\nreturn error;\r\n}\r\nint add_to_swap_cache(struct page *page, swp_entry_t entry, gfp_t gfp_mask)\r\n{\r\nint error;\r\nerror = radix_tree_maybe_preload(gfp_mask);\r\nif (!error) {\r\nerror = __add_to_swap_cache(page, entry);\r\nradix_tree_preload_end();\r\n}\r\nreturn error;\r\n}\r\nvoid __delete_from_swap_cache(struct page *page)\r\n{\r\nswp_entry_t entry;\r\nstruct address_space *address_space;\r\nVM_BUG_ON(!PageLocked(page));\r\nVM_BUG_ON(!PageSwapCache(page));\r\nVM_BUG_ON(PageWriteback(page));\r\nentry.val = page_private(page);\r\naddress_space = swap_address_space(entry);\r\nradix_tree_delete(&address_space->page_tree, page_private(page));\r\nset_page_private(page, 0);\r\nClearPageSwapCache(page);\r\naddress_space->nrpages--;\r\n__dec_zone_page_state(page, NR_FILE_PAGES);\r\nINC_CACHE_INFO(del_total);\r\n}\r\nint add_to_swap(struct page *page, struct list_head *list)\r\n{\r\nswp_entry_t entry;\r\nint err;\r\nVM_BUG_ON(!PageLocked(page));\r\nVM_BUG_ON(!PageUptodate(page));\r\nentry = get_swap_page();\r\nif (!entry.val)\r\nreturn 0;\r\nif (unlikely(PageTransHuge(page)))\r\nif (unlikely(split_huge_page_to_list(page, list))) {\r\nswapcache_free(entry, NULL);\r\nreturn 0;\r\n}\r\nerr = add_to_swap_cache(page, entry,\r\n__GFP_HIGH|__GFP_NOMEMALLOC|__GFP_NOWARN);\r\nif (!err) {\r\nSetPageDirty(page);\r\nreturn 1;\r\n} else {\r\nswapcache_free(entry, NULL);\r\nreturn 0;\r\n}\r\n}\r\nvoid delete_from_swap_cache(struct page *page)\r\n{\r\nswp_entry_t entry;\r\nstruct address_space *address_space;\r\nentry.val = page_private(page);\r\naddress_space = swap_address_space(entry);\r\nspin_lock_irq(&address_space->tree_lock);\r\n__delete_from_swap_cache(page);\r\nspin_unlock_irq(&address_space->tree_lock);\r\nswapcache_free(entry, page);\r\npage_cache_release(page);\r\n}\r\nstatic inline void free_swap_cache(struct page *page)\r\n{\r\nif (PageSwapCache(page) && !page_mapped(page) && trylock_page(page)) {\r\ntry_to_free_swap(page);\r\nunlock_page(page);\r\n}\r\n}\r\nvoid free_page_and_swap_cache(struct page *page)\r\n{\r\nfree_swap_cache(page);\r\npage_cache_release(page);\r\n}\r\nvoid free_pages_and_swap_cache(struct page **pages, int nr)\r\n{\r\nstruct page **pagep = pages;\r\nlru_add_drain();\r\nwhile (nr) {\r\nint todo = min(nr, PAGEVEC_SIZE);\r\nint i;\r\nfor (i = 0; i < todo; i++)\r\nfree_swap_cache(pagep[i]);\r\nrelease_pages(pagep, todo, 0);\r\npagep += todo;\r\nnr -= todo;\r\n}\r\n}\r\nstruct page * lookup_swap_cache(swp_entry_t entry)\r\n{\r\nstruct page *page;\r\npage = find_get_page(swap_address_space(entry), entry.val);\r\nif (page)\r\nINC_CACHE_INFO(find_success);\r\nINC_CACHE_INFO(find_total);\r\nreturn page;\r\n}\r\nstruct page *read_swap_cache_async(swp_entry_t entry, gfp_t gfp_mask,\r\nstruct vm_area_struct *vma, unsigned long addr)\r\n{\r\nstruct page *found_page, *new_page = NULL;\r\nint err;\r\ndo {\r\nfound_page = find_get_page(swap_address_space(entry),\r\nentry.val);\r\nif (found_page)\r\nbreak;\r\nif (!new_page) {\r\nnew_page = alloc_page_vma(gfp_mask, vma, addr);\r\nif (!new_page)\r\nbreak;\r\n}\r\nerr = radix_tree_maybe_preload(gfp_mask & GFP_KERNEL);\r\nif (err)\r\nbreak;\r\nerr = swapcache_prepare(entry);\r\nif (err == -EEXIST) {\r\nradix_tree_preload_end();\r\ncond_resched();\r\ncontinue;\r\n}\r\nif (err) {\r\nradix_tree_preload_end();\r\nbreak;\r\n}\r\n__set_page_locked(new_page);\r\nSetPageSwapBacked(new_page);\r\nerr = __add_to_swap_cache(new_page, entry);\r\nif (likely(!err)) {\r\nradix_tree_preload_end();\r\nlru_cache_add_anon(new_page);\r\nswap_readpage(new_page);\r\nreturn new_page;\r\n}\r\nradix_tree_preload_end();\r\nClearPageSwapBacked(new_page);\r\n__clear_page_locked(new_page);\r\nswapcache_free(entry, NULL);\r\n} while (err != -ENOMEM);\r\nif (new_page)\r\npage_cache_release(new_page);\r\nreturn found_page;\r\n}\r\nstruct page *swapin_readahead(swp_entry_t entry, gfp_t gfp_mask,\r\nstruct vm_area_struct *vma, unsigned long addr)\r\n{\r\nstruct page *page;\r\nunsigned long offset = swp_offset(entry);\r\nunsigned long start_offset, end_offset;\r\nunsigned long mask = (1UL << page_cluster) - 1;\r\nstruct blk_plug plug;\r\nstart_offset = offset & ~mask;\r\nend_offset = offset | mask;\r\nif (!start_offset)\r\nstart_offset++;\r\nblk_start_plug(&plug);\r\nfor (offset = start_offset; offset <= end_offset ; offset++) {\r\npage = read_swap_cache_async(swp_entry(swp_type(entry), offset),\r\ngfp_mask, vma, addr);\r\nif (!page)\r\ncontinue;\r\npage_cache_release(page);\r\n}\r\nblk_finish_plug(&plug);\r\nlru_add_drain();\r\nreturn read_swap_cache_async(entry, gfp_mask, vma, addr);\r\n}
