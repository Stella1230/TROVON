static int atomic_inc_return_safe(atomic_t *v)\r\n{\r\nunsigned int counter;\r\ncounter = (unsigned int)__atomic_add_unless(v, 1, 0);\r\nif (counter <= (unsigned int)INT_MAX)\r\nreturn (int)counter;\r\natomic_dec(v);\r\nreturn -EINVAL;\r\n}\r\nstatic int atomic_dec_return_safe(atomic_t *v)\r\n{\r\nint counter;\r\ncounter = atomic_dec_return(v);\r\nif (counter >= 0)\r\nreturn counter;\r\natomic_inc(v);\r\nreturn -EINVAL;\r\n}\r\nstatic void rbd_root_dev_release(struct device *dev)\r\n{\r\n}\r\nstatic int rbd_open(struct block_device *bdev, fmode_t mode)\r\n{\r\nstruct rbd_device *rbd_dev = bdev->bd_disk->private_data;\r\nbool removing = false;\r\nif ((mode & FMODE_WRITE) && rbd_dev->mapping.read_only)\r\nreturn -EROFS;\r\nspin_lock_irq(&rbd_dev->lock);\r\nif (test_bit(RBD_DEV_FLAG_REMOVING, &rbd_dev->flags))\r\nremoving = true;\r\nelse\r\nrbd_dev->open_count++;\r\nspin_unlock_irq(&rbd_dev->lock);\r\nif (removing)\r\nreturn -ENOENT;\r\n(void) get_device(&rbd_dev->dev);\r\nset_device_ro(bdev, rbd_dev->mapping.read_only);\r\nreturn 0;\r\n}\r\nstatic void rbd_release(struct gendisk *disk, fmode_t mode)\r\n{\r\nstruct rbd_device *rbd_dev = disk->private_data;\r\nunsigned long open_count_before;\r\nspin_lock_irq(&rbd_dev->lock);\r\nopen_count_before = rbd_dev->open_count--;\r\nspin_unlock_irq(&rbd_dev->lock);\r\nrbd_assert(open_count_before > 0);\r\nput_device(&rbd_dev->dev);\r\n}\r\nstatic struct rbd_client *rbd_client_create(struct ceph_options *ceph_opts)\r\n{\r\nstruct rbd_client *rbdc;\r\nint ret = -ENOMEM;\r\ndout("%s:\n", __func__);\r\nrbdc = kmalloc(sizeof(struct rbd_client), GFP_KERNEL);\r\nif (!rbdc)\r\ngoto out_opt;\r\nkref_init(&rbdc->kref);\r\nINIT_LIST_HEAD(&rbdc->node);\r\nrbdc->client = ceph_create_client(ceph_opts, rbdc, 0, 0);\r\nif (IS_ERR(rbdc->client))\r\ngoto out_rbdc;\r\nceph_opts = NULL;\r\nret = ceph_open_session(rbdc->client);\r\nif (ret < 0)\r\ngoto out_client;\r\nspin_lock(&rbd_client_list_lock);\r\nlist_add_tail(&rbdc->node, &rbd_client_list);\r\nspin_unlock(&rbd_client_list_lock);\r\ndout("%s: rbdc %p\n", __func__, rbdc);\r\nreturn rbdc;\r\nout_client:\r\nceph_destroy_client(rbdc->client);\r\nout_rbdc:\r\nkfree(rbdc);\r\nout_opt:\r\nif (ceph_opts)\r\nceph_destroy_options(ceph_opts);\r\ndout("%s: error %d\n", __func__, ret);\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic struct rbd_client *__rbd_get_client(struct rbd_client *rbdc)\r\n{\r\nkref_get(&rbdc->kref);\r\nreturn rbdc;\r\n}\r\nstatic struct rbd_client *rbd_client_find(struct ceph_options *ceph_opts)\r\n{\r\nstruct rbd_client *client_node;\r\nbool found = false;\r\nif (ceph_opts->flags & CEPH_OPT_NOSHARE)\r\nreturn NULL;\r\nspin_lock(&rbd_client_list_lock);\r\nlist_for_each_entry(client_node, &rbd_client_list, node) {\r\nif (!ceph_compare_options(ceph_opts, client_node->client)) {\r\n__rbd_get_client(client_node);\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nspin_unlock(&rbd_client_list_lock);\r\nreturn found ? client_node : NULL;\r\n}\r\nstatic int parse_rbd_opts_token(char *c, void *private)\r\n{\r\nstruct rbd_options *rbd_opts = private;\r\nsubstring_t argstr[MAX_OPT_ARGS];\r\nint token, intval, ret;\r\ntoken = match_token(c, rbd_opts_tokens, argstr);\r\nif (token < 0)\r\nreturn -EINVAL;\r\nif (token < Opt_last_int) {\r\nret = match_int(&argstr[0], &intval);\r\nif (ret < 0) {\r\npr_err("bad mount option arg (not int) "\r\n"at '%s'\n", c);\r\nreturn ret;\r\n}\r\ndout("got int token %d val %d\n", token, intval);\r\n} else if (token > Opt_last_int && token < Opt_last_string) {\r\ndout("got string token %d val %s\n", token,\r\nargstr[0].from);\r\n} else if (token > Opt_last_string && token < Opt_last_bool) {\r\ndout("got Boolean token %d\n", token);\r\n} else {\r\ndout("got token %d\n", token);\r\n}\r\nswitch (token) {\r\ncase Opt_read_only:\r\nrbd_opts->read_only = true;\r\nbreak;\r\ncase Opt_read_write:\r\nrbd_opts->read_only = false;\r\nbreak;\r\ndefault:\r\nrbd_assert(false);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct rbd_client *rbd_get_client(struct ceph_options *ceph_opts)\r\n{\r\nstruct rbd_client *rbdc;\r\nmutex_lock_nested(&client_mutex, SINGLE_DEPTH_NESTING);\r\nrbdc = rbd_client_find(ceph_opts);\r\nif (rbdc)\r\nceph_destroy_options(ceph_opts);\r\nelse\r\nrbdc = rbd_client_create(ceph_opts);\r\nmutex_unlock(&client_mutex);\r\nreturn rbdc;\r\n}\r\nstatic void rbd_client_release(struct kref *kref)\r\n{\r\nstruct rbd_client *rbdc = container_of(kref, struct rbd_client, kref);\r\ndout("%s: rbdc %p\n", __func__, rbdc);\r\nspin_lock(&rbd_client_list_lock);\r\nlist_del(&rbdc->node);\r\nspin_unlock(&rbd_client_list_lock);\r\nceph_destroy_client(rbdc->client);\r\nkfree(rbdc);\r\n}\r\nstatic void rbd_put_client(struct rbd_client *rbdc)\r\n{\r\nif (rbdc)\r\nkref_put(&rbdc->kref, rbd_client_release);\r\n}\r\nstatic bool rbd_image_format_valid(u32 image_format)\r\n{\r\nreturn image_format == 1 || image_format == 2;\r\n}\r\nstatic bool rbd_dev_ondisk_valid(struct rbd_image_header_ondisk *ondisk)\r\n{\r\nsize_t size;\r\nu32 snap_count;\r\nif (memcmp(&ondisk->text, RBD_HEADER_TEXT, sizeof (RBD_HEADER_TEXT)))\r\nreturn false;\r\nif (ondisk->options.order < SECTOR_SHIFT)\r\nreturn false;\r\nif (ondisk->options.order > 8 * sizeof (int) - 1)\r\nreturn false;\r\nsnap_count = le32_to_cpu(ondisk->snap_count);\r\nsize = SIZE_MAX - sizeof (struct ceph_snap_context);\r\nif (snap_count > size / sizeof (__le64))\r\nreturn false;\r\nsize -= snap_count * sizeof (__le64);\r\nif ((u64) size < le64_to_cpu(ondisk->snap_names_len))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int rbd_header_from_disk(struct rbd_device *rbd_dev,\r\nstruct rbd_image_header_ondisk *ondisk)\r\n{\r\nstruct rbd_image_header *header = &rbd_dev->header;\r\nbool first_time = header->object_prefix == NULL;\r\nstruct ceph_snap_context *snapc;\r\nchar *object_prefix = NULL;\r\nchar *snap_names = NULL;\r\nu64 *snap_sizes = NULL;\r\nu32 snap_count;\r\nsize_t size;\r\nint ret = -ENOMEM;\r\nu32 i;\r\nif (first_time) {\r\nsize_t len;\r\nlen = strnlen(ondisk->object_prefix,\r\nsizeof (ondisk->object_prefix));\r\nobject_prefix = kmalloc(len + 1, GFP_KERNEL);\r\nif (!object_prefix)\r\nreturn -ENOMEM;\r\nmemcpy(object_prefix, ondisk->object_prefix, len);\r\nobject_prefix[len] = '\0';\r\n}\r\nsnap_count = le32_to_cpu(ondisk->snap_count);\r\nsnapc = ceph_create_snap_context(snap_count, GFP_KERNEL);\r\nif (!snapc)\r\ngoto out_err;\r\nsnapc->seq = le64_to_cpu(ondisk->snap_seq);\r\nif (snap_count) {\r\nstruct rbd_image_snap_ondisk *snaps;\r\nu64 snap_names_len = le64_to_cpu(ondisk->snap_names_len);\r\nif (snap_names_len > (u64)SIZE_MAX)\r\ngoto out_2big;\r\nsnap_names = kmalloc(snap_names_len, GFP_KERNEL);\r\nif (!snap_names)\r\ngoto out_err;\r\nsize = snap_count * sizeof (*header->snap_sizes);\r\nsnap_sizes = kmalloc(size, GFP_KERNEL);\r\nif (!snap_sizes)\r\ngoto out_err;\r\nmemcpy(snap_names, &ondisk->snaps[snap_count], snap_names_len);\r\nsnaps = ondisk->snaps;\r\nfor (i = 0; i < snap_count; i++) {\r\nsnapc->snaps[i] = le64_to_cpu(snaps[i].id);\r\nsnap_sizes[i] = le64_to_cpu(snaps[i].image_size);\r\n}\r\n}\r\nif (first_time) {\r\nheader->object_prefix = object_prefix;\r\nheader->obj_order = ondisk->options.order;\r\nheader->crypt_type = ondisk->options.crypt_type;\r\nheader->comp_type = ondisk->options.comp_type;\r\nheader->stripe_unit = 0;\r\nheader->stripe_count = 0;\r\nheader->features = 0;\r\n} else {\r\nceph_put_snap_context(header->snapc);\r\nkfree(header->snap_names);\r\nkfree(header->snap_sizes);\r\n}\r\nheader->image_size = le64_to_cpu(ondisk->image_size);\r\nheader->snapc = snapc;\r\nheader->snap_names = snap_names;\r\nheader->snap_sizes = snap_sizes;\r\nif (rbd_dev->spec->snap_id == CEPH_NOSNAP || first_time)\r\nif (rbd_dev->mapping.size != header->image_size)\r\nrbd_dev->mapping.size = header->image_size;\r\nreturn 0;\r\nout_2big:\r\nret = -EIO;\r\nout_err:\r\nkfree(snap_sizes);\r\nkfree(snap_names);\r\nceph_put_snap_context(snapc);\r\nkfree(object_prefix);\r\nreturn ret;\r\n}\r\nstatic const char *_rbd_dev_v1_snap_name(struct rbd_device *rbd_dev, u32 which)\r\n{\r\nconst char *snap_name;\r\nrbd_assert(which < rbd_dev->header.snapc->num_snaps);\r\nsnap_name = rbd_dev->header.snap_names;\r\nwhile (which--)\r\nsnap_name += strlen(snap_name) + 1;\r\nreturn kstrdup(snap_name, GFP_KERNEL);\r\n}\r\nstatic int snapid_compare_reverse(const void *s1, const void *s2)\r\n{\r\nu64 snap_id1 = *(u64 *)s1;\r\nu64 snap_id2 = *(u64 *)s2;\r\nif (snap_id1 < snap_id2)\r\nreturn 1;\r\nreturn snap_id1 == snap_id2 ? 0 : -1;\r\n}\r\nstatic u32 rbd_dev_snap_index(struct rbd_device *rbd_dev, u64 snap_id)\r\n{\r\nstruct ceph_snap_context *snapc = rbd_dev->header.snapc;\r\nu64 *found;\r\nfound = bsearch(&snap_id, &snapc->snaps, snapc->num_snaps,\r\nsizeof (snap_id), snapid_compare_reverse);\r\nreturn found ? (u32)(found - &snapc->snaps[0]) : BAD_SNAP_INDEX;\r\n}\r\nstatic const char *rbd_dev_v1_snap_name(struct rbd_device *rbd_dev,\r\nu64 snap_id)\r\n{\r\nu32 which;\r\nconst char *snap_name;\r\nwhich = rbd_dev_snap_index(rbd_dev, snap_id);\r\nif (which == BAD_SNAP_INDEX)\r\nreturn ERR_PTR(-ENOENT);\r\nsnap_name = _rbd_dev_v1_snap_name(rbd_dev, which);\r\nreturn snap_name ? snap_name : ERR_PTR(-ENOMEM);\r\n}\r\nstatic const char *rbd_snap_name(struct rbd_device *rbd_dev, u64 snap_id)\r\n{\r\nif (snap_id == CEPH_NOSNAP)\r\nreturn RBD_SNAP_HEAD_NAME;\r\nrbd_assert(rbd_image_format_valid(rbd_dev->image_format));\r\nif (rbd_dev->image_format == 1)\r\nreturn rbd_dev_v1_snap_name(rbd_dev, snap_id);\r\nreturn rbd_dev_v2_snap_name(rbd_dev, snap_id);\r\n}\r\nstatic int rbd_snap_size(struct rbd_device *rbd_dev, u64 snap_id,\r\nu64 *snap_size)\r\n{\r\nrbd_assert(rbd_image_format_valid(rbd_dev->image_format));\r\nif (snap_id == CEPH_NOSNAP) {\r\n*snap_size = rbd_dev->header.image_size;\r\n} else if (rbd_dev->image_format == 1) {\r\nu32 which;\r\nwhich = rbd_dev_snap_index(rbd_dev, snap_id);\r\nif (which == BAD_SNAP_INDEX)\r\nreturn -ENOENT;\r\n*snap_size = rbd_dev->header.snap_sizes[which];\r\n} else {\r\nu64 size = 0;\r\nint ret;\r\nret = _rbd_dev_v2_snap_size(rbd_dev, snap_id, NULL, &size);\r\nif (ret)\r\nreturn ret;\r\n*snap_size = size;\r\n}\r\nreturn 0;\r\n}\r\nstatic int rbd_snap_features(struct rbd_device *rbd_dev, u64 snap_id,\r\nu64 *snap_features)\r\n{\r\nrbd_assert(rbd_image_format_valid(rbd_dev->image_format));\r\nif (snap_id == CEPH_NOSNAP) {\r\n*snap_features = rbd_dev->header.features;\r\n} else if (rbd_dev->image_format == 1) {\r\n*snap_features = 0;\r\n} else {\r\nu64 features = 0;\r\nint ret;\r\nret = _rbd_dev_v2_snap_features(rbd_dev, snap_id, &features);\r\nif (ret)\r\nreturn ret;\r\n*snap_features = features;\r\n}\r\nreturn 0;\r\n}\r\nstatic int rbd_dev_mapping_set(struct rbd_device *rbd_dev)\r\n{\r\nu64 snap_id = rbd_dev->spec->snap_id;\r\nu64 size = 0;\r\nu64 features = 0;\r\nint ret;\r\nret = rbd_snap_size(rbd_dev, snap_id, &size);\r\nif (ret)\r\nreturn ret;\r\nret = rbd_snap_features(rbd_dev, snap_id, &features);\r\nif (ret)\r\nreturn ret;\r\nrbd_dev->mapping.size = size;\r\nrbd_dev->mapping.features = features;\r\nreturn 0;\r\n}\r\nstatic void rbd_dev_mapping_clear(struct rbd_device *rbd_dev)\r\n{\r\nrbd_dev->mapping.size = 0;\r\nrbd_dev->mapping.features = 0;\r\n}\r\nstatic const char *rbd_segment_name(struct rbd_device *rbd_dev, u64 offset)\r\n{\r\nchar *name;\r\nu64 segment;\r\nint ret;\r\nchar *name_format;\r\nname = kmem_cache_alloc(rbd_segment_name_cache, GFP_NOIO);\r\nif (!name)\r\nreturn NULL;\r\nsegment = offset >> rbd_dev->header.obj_order;\r\nname_format = "%s.%012llx";\r\nif (rbd_dev->image_format == 2)\r\nname_format = "%s.%016llx";\r\nret = snprintf(name, MAX_OBJ_NAME_SIZE + 1, name_format,\r\nrbd_dev->header.object_prefix, segment);\r\nif (ret < 0 || ret > MAX_OBJ_NAME_SIZE) {\r\npr_err("error formatting segment name for #%llu (%d)\n",\r\nsegment, ret);\r\nkfree(name);\r\nname = NULL;\r\n}\r\nreturn name;\r\n}\r\nstatic void rbd_segment_name_free(const char *name)\r\n{\r\nkmem_cache_free(rbd_segment_name_cache, (void *)name);\r\n}\r\nstatic u64 rbd_segment_offset(struct rbd_device *rbd_dev, u64 offset)\r\n{\r\nu64 segment_size = (u64) 1 << rbd_dev->header.obj_order;\r\nreturn offset & (segment_size - 1);\r\n}\r\nstatic u64 rbd_segment_length(struct rbd_device *rbd_dev,\r\nu64 offset, u64 length)\r\n{\r\nu64 segment_size = (u64) 1 << rbd_dev->header.obj_order;\r\noffset &= segment_size - 1;\r\nrbd_assert(length <= U64_MAX - offset);\r\nif (offset + length > segment_size)\r\nlength = segment_size - offset;\r\nreturn length;\r\n}\r\nstatic u64 rbd_obj_bytes(struct rbd_image_header *header)\r\n{\r\nreturn 1 << header->obj_order;\r\n}\r\nstatic void bio_chain_put(struct bio *chain)\r\n{\r\nstruct bio *tmp;\r\nwhile (chain) {\r\ntmp = chain;\r\nchain = chain->bi_next;\r\nbio_put(tmp);\r\n}\r\n}\r\nstatic void zero_bio_chain(struct bio *chain, int start_ofs)\r\n{\r\nstruct bio_vec *bv;\r\nunsigned long flags;\r\nvoid *buf;\r\nint i;\r\nint pos = 0;\r\nwhile (chain) {\r\nbio_for_each_segment(bv, chain, i) {\r\nif (pos + bv->bv_len > start_ofs) {\r\nint remainder = max(start_ofs - pos, 0);\r\nbuf = bvec_kmap_irq(bv, &flags);\r\nmemset(buf + remainder, 0,\r\nbv->bv_len - remainder);\r\nflush_dcache_page(bv->bv_page);\r\nbvec_kunmap_irq(buf, &flags);\r\n}\r\npos += bv->bv_len;\r\n}\r\nchain = chain->bi_next;\r\n}\r\n}\r\nstatic void zero_pages(struct page **pages, u64 offset, u64 end)\r\n{\r\nstruct page **page = &pages[offset >> PAGE_SHIFT];\r\nrbd_assert(end > offset);\r\nrbd_assert(end - offset <= (u64)SIZE_MAX);\r\nwhile (offset < end) {\r\nsize_t page_offset;\r\nsize_t length;\r\nunsigned long flags;\r\nvoid *kaddr;\r\npage_offset = offset & ~PAGE_MASK;\r\nlength = min_t(size_t, PAGE_SIZE - page_offset, end - offset);\r\nlocal_irq_save(flags);\r\nkaddr = kmap_atomic(*page);\r\nmemset(kaddr + page_offset, 0, length);\r\nflush_dcache_page(*page);\r\nkunmap_atomic(kaddr);\r\nlocal_irq_restore(flags);\r\noffset += length;\r\npage++;\r\n}\r\n}\r\nstatic struct bio *bio_clone_range(struct bio *bio_src,\r\nunsigned int offset,\r\nunsigned int len,\r\ngfp_t gfpmask)\r\n{\r\nstruct bio_vec *bv;\r\nunsigned int resid;\r\nunsigned short idx;\r\nunsigned int voff;\r\nunsigned short end_idx;\r\nunsigned short vcnt;\r\nstruct bio *bio;\r\nif (!offset && len == bio_src->bi_size)\r\nreturn bio_clone(bio_src, gfpmask);\r\nif (WARN_ON_ONCE(!len))\r\nreturn NULL;\r\nif (WARN_ON_ONCE(len > bio_src->bi_size))\r\nreturn NULL;\r\nif (WARN_ON_ONCE(offset > bio_src->bi_size - len))\r\nreturn NULL;\r\nresid = offset;\r\nbio_for_each_segment(bv, bio_src, idx) {\r\nif (resid < bv->bv_len)\r\nbreak;\r\nresid -= bv->bv_len;\r\n}\r\nvoff = resid;\r\nresid += len;\r\n__bio_for_each_segment(bv, bio_src, end_idx, idx) {\r\nif (resid <= bv->bv_len)\r\nbreak;\r\nresid -= bv->bv_len;\r\n}\r\nvcnt = end_idx - idx + 1;\r\nbio = bio_alloc(gfpmask, (unsigned int) vcnt);\r\nif (!bio)\r\nreturn NULL;\r\nbio->bi_bdev = bio_src->bi_bdev;\r\nbio->bi_sector = bio_src->bi_sector + (offset >> SECTOR_SHIFT);\r\nbio->bi_rw = bio_src->bi_rw;\r\nbio->bi_flags |= 1 << BIO_CLONED;\r\nmemcpy(&bio->bi_io_vec[0], &bio_src->bi_io_vec[idx],\r\nvcnt * sizeof (struct bio_vec));\r\nbio->bi_io_vec[0].bv_offset += voff;\r\nif (vcnt > 1) {\r\nbio->bi_io_vec[0].bv_len -= voff;\r\nbio->bi_io_vec[vcnt - 1].bv_len = resid;\r\n} else {\r\nbio->bi_io_vec[0].bv_len = len;\r\n}\r\nbio->bi_vcnt = vcnt;\r\nbio->bi_size = len;\r\nbio->bi_idx = 0;\r\nreturn bio;\r\n}\r\nstatic struct bio *bio_chain_clone_range(struct bio **bio_src,\r\nunsigned int *offset,\r\nunsigned int len,\r\ngfp_t gfpmask)\r\n{\r\nstruct bio *bi = *bio_src;\r\nunsigned int off = *offset;\r\nstruct bio *chain = NULL;\r\nstruct bio **end;\r\nif (!bi || off >= bi->bi_size || !len)\r\nreturn NULL;\r\nend = &chain;\r\nwhile (len) {\r\nunsigned int bi_size;\r\nstruct bio *bio;\r\nif (!bi) {\r\nrbd_warn(NULL, "bio_chain exhausted with %u left", len);\r\ngoto out_err;\r\n}\r\nbi_size = min_t(unsigned int, bi->bi_size - off, len);\r\nbio = bio_clone_range(bi, off, bi_size, gfpmask);\r\nif (!bio)\r\ngoto out_err;\r\n*end = bio;\r\nend = &bio->bi_next;\r\noff += bi_size;\r\nif (off == bi->bi_size) {\r\nbi = bi->bi_next;\r\noff = 0;\r\n}\r\nlen -= bi_size;\r\n}\r\n*bio_src = bi;\r\n*offset = off;\r\nreturn chain;\r\nout_err:\r\nbio_chain_put(chain);\r\nreturn NULL;\r\n}\r\nstatic void obj_request_img_data_set(struct rbd_obj_request *obj_request)\r\n{\r\nif (test_and_set_bit(OBJ_REQ_IMG_DATA, &obj_request->flags)) {\r\nstruct rbd_device *rbd_dev;\r\nrbd_dev = obj_request->img_request->rbd_dev;\r\nrbd_warn(rbd_dev, "obj_request %p already marked img_data\n",\r\nobj_request);\r\n}\r\n}\r\nstatic bool obj_request_img_data_test(struct rbd_obj_request *obj_request)\r\n{\r\nsmp_mb();\r\nreturn test_bit(OBJ_REQ_IMG_DATA, &obj_request->flags) != 0;\r\n}\r\nstatic void obj_request_done_set(struct rbd_obj_request *obj_request)\r\n{\r\nif (test_and_set_bit(OBJ_REQ_DONE, &obj_request->flags)) {\r\nstruct rbd_device *rbd_dev = NULL;\r\nif (obj_request_img_data_test(obj_request))\r\nrbd_dev = obj_request->img_request->rbd_dev;\r\nrbd_warn(rbd_dev, "obj_request %p already marked done\n",\r\nobj_request);\r\n}\r\n}\r\nstatic bool obj_request_done_test(struct rbd_obj_request *obj_request)\r\n{\r\nsmp_mb();\r\nreturn test_bit(OBJ_REQ_DONE, &obj_request->flags) != 0;\r\n}\r\nstatic void obj_request_existence_set(struct rbd_obj_request *obj_request,\r\nbool exists)\r\n{\r\nif (exists)\r\nset_bit(OBJ_REQ_EXISTS, &obj_request->flags);\r\nset_bit(OBJ_REQ_KNOWN, &obj_request->flags);\r\nsmp_mb();\r\n}\r\nstatic bool obj_request_known_test(struct rbd_obj_request *obj_request)\r\n{\r\nsmp_mb();\r\nreturn test_bit(OBJ_REQ_KNOWN, &obj_request->flags) != 0;\r\n}\r\nstatic bool obj_request_exists_test(struct rbd_obj_request *obj_request)\r\n{\r\nsmp_mb();\r\nreturn test_bit(OBJ_REQ_EXISTS, &obj_request->flags) != 0;\r\n}\r\nstatic void rbd_obj_request_get(struct rbd_obj_request *obj_request)\r\n{\r\ndout("%s: obj %p (was %d)\n", __func__, obj_request,\r\natomic_read(&obj_request->kref.refcount));\r\nkref_get(&obj_request->kref);\r\n}\r\nstatic void rbd_obj_request_put(struct rbd_obj_request *obj_request)\r\n{\r\nrbd_assert(obj_request != NULL);\r\ndout("%s: obj %p (was %d)\n", __func__, obj_request,\r\natomic_read(&obj_request->kref.refcount));\r\nkref_put(&obj_request->kref, rbd_obj_request_destroy);\r\n}\r\nstatic void rbd_img_request_put(struct rbd_img_request *img_request)\r\n{\r\nrbd_assert(img_request != NULL);\r\ndout("%s: img %p (was %d)\n", __func__, img_request,\r\natomic_read(&img_request->kref.refcount));\r\nif (img_request_child_test(img_request))\r\nkref_put(&img_request->kref, rbd_parent_request_destroy);\r\nelse\r\nkref_put(&img_request->kref, rbd_img_request_destroy);\r\n}\r\nstatic inline void rbd_img_obj_request_add(struct rbd_img_request *img_request,\r\nstruct rbd_obj_request *obj_request)\r\n{\r\nrbd_assert(obj_request->img_request == NULL);\r\nobj_request->img_request = img_request;\r\nobj_request->which = img_request->obj_request_count;\r\nrbd_assert(!obj_request_img_data_test(obj_request));\r\nobj_request_img_data_set(obj_request);\r\nrbd_assert(obj_request->which != BAD_WHICH);\r\nimg_request->obj_request_count++;\r\nlist_add_tail(&obj_request->links, &img_request->obj_requests);\r\ndout("%s: img %p obj %p w=%u\n", __func__, img_request, obj_request,\r\nobj_request->which);\r\n}\r\nstatic inline void rbd_img_obj_request_del(struct rbd_img_request *img_request,\r\nstruct rbd_obj_request *obj_request)\r\n{\r\nrbd_assert(obj_request->which != BAD_WHICH);\r\ndout("%s: img %p obj %p w=%u\n", __func__, img_request, obj_request,\r\nobj_request->which);\r\nlist_del(&obj_request->links);\r\nrbd_assert(img_request->obj_request_count > 0);\r\nimg_request->obj_request_count--;\r\nrbd_assert(obj_request->which == img_request->obj_request_count);\r\nobj_request->which = BAD_WHICH;\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nrbd_assert(obj_request->img_request == img_request);\r\nobj_request->img_request = NULL;\r\nobj_request->callback = NULL;\r\nrbd_obj_request_put(obj_request);\r\n}\r\nstatic bool obj_request_type_valid(enum obj_request_type type)\r\n{\r\nswitch (type) {\r\ncase OBJ_REQUEST_NODATA:\r\ncase OBJ_REQUEST_BIO:\r\ncase OBJ_REQUEST_PAGES:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nstatic int rbd_obj_request_submit(struct ceph_osd_client *osdc,\r\nstruct rbd_obj_request *obj_request)\r\n{\r\ndout("%s: osdc %p obj %p\n", __func__, osdc, obj_request);\r\nreturn ceph_osdc_start_request(osdc, obj_request->osd_req, false);\r\n}\r\nstatic void rbd_img_request_complete(struct rbd_img_request *img_request)\r\n{\r\ndout("%s: img %p\n", __func__, img_request);\r\nif (!img_request->result) {\r\nstruct rbd_obj_request *obj_request;\r\nu64 xferred = 0;\r\nfor_each_obj_request(img_request, obj_request)\r\nxferred += obj_request->xferred;\r\nimg_request->xferred = xferred;\r\n}\r\nif (img_request->callback)\r\nimg_request->callback(img_request);\r\nelse\r\nrbd_img_request_put(img_request);\r\n}\r\nstatic int rbd_obj_request_wait(struct rbd_obj_request *obj_request)\r\n{\r\ndout("%s: obj %p\n", __func__, obj_request);\r\nreturn wait_for_completion_interruptible(&obj_request->completion);\r\n}\r\nstatic void img_request_write_set(struct rbd_img_request *img_request)\r\n{\r\nset_bit(IMG_REQ_WRITE, &img_request->flags);\r\nsmp_mb();\r\n}\r\nstatic bool img_request_write_test(struct rbd_img_request *img_request)\r\n{\r\nsmp_mb();\r\nreturn test_bit(IMG_REQ_WRITE, &img_request->flags) != 0;\r\n}\r\nstatic void img_request_child_set(struct rbd_img_request *img_request)\r\n{\r\nset_bit(IMG_REQ_CHILD, &img_request->flags);\r\nsmp_mb();\r\n}\r\nstatic void img_request_child_clear(struct rbd_img_request *img_request)\r\n{\r\nclear_bit(IMG_REQ_CHILD, &img_request->flags);\r\nsmp_mb();\r\n}\r\nstatic bool img_request_child_test(struct rbd_img_request *img_request)\r\n{\r\nsmp_mb();\r\nreturn test_bit(IMG_REQ_CHILD, &img_request->flags) != 0;\r\n}\r\nstatic void img_request_layered_set(struct rbd_img_request *img_request)\r\n{\r\nset_bit(IMG_REQ_LAYERED, &img_request->flags);\r\nsmp_mb();\r\n}\r\nstatic void img_request_layered_clear(struct rbd_img_request *img_request)\r\n{\r\nclear_bit(IMG_REQ_LAYERED, &img_request->flags);\r\nsmp_mb();\r\n}\r\nstatic bool img_request_layered_test(struct rbd_img_request *img_request)\r\n{\r\nsmp_mb();\r\nreturn test_bit(IMG_REQ_LAYERED, &img_request->flags) != 0;\r\n}\r\nstatic void\r\nrbd_img_obj_request_read_callback(struct rbd_obj_request *obj_request)\r\n{\r\nu64 xferred = obj_request->xferred;\r\nu64 length = obj_request->length;\r\ndout("%s: obj %p img %p result %d %llu/%llu\n", __func__,\r\nobj_request, obj_request->img_request, obj_request->result,\r\nxferred, length);\r\nrbd_assert(obj_request->type != OBJ_REQUEST_NODATA);\r\nif (obj_request->result == -ENOENT) {\r\nif (obj_request->type == OBJ_REQUEST_BIO)\r\nzero_bio_chain(obj_request->bio_list, 0);\r\nelse\r\nzero_pages(obj_request->pages, 0, length);\r\nobj_request->result = 0;\r\n} else if (xferred < length && !obj_request->result) {\r\nif (obj_request->type == OBJ_REQUEST_BIO)\r\nzero_bio_chain(obj_request->bio_list, xferred);\r\nelse\r\nzero_pages(obj_request->pages, xferred, length);\r\n}\r\nobj_request->xferred = length;\r\nobj_request_done_set(obj_request);\r\n}\r\nstatic void rbd_obj_request_complete(struct rbd_obj_request *obj_request)\r\n{\r\ndout("%s: obj %p cb %p\n", __func__, obj_request,\r\nobj_request->callback);\r\nif (obj_request->callback)\r\nobj_request->callback(obj_request);\r\nelse\r\ncomplete_all(&obj_request->completion);\r\n}\r\nstatic void rbd_osd_trivial_callback(struct rbd_obj_request *obj_request)\r\n{\r\ndout("%s: obj %p\n", __func__, obj_request);\r\nobj_request_done_set(obj_request);\r\n}\r\nstatic void rbd_osd_read_callback(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request = NULL;\r\nstruct rbd_device *rbd_dev = NULL;\r\nbool layered = false;\r\nif (obj_request_img_data_test(obj_request)) {\r\nimg_request = obj_request->img_request;\r\nlayered = img_request && img_request_layered_test(img_request);\r\nrbd_dev = img_request->rbd_dev;\r\n}\r\ndout("%s: obj %p img %p result %d %llu/%llu\n", __func__,\r\nobj_request, img_request, obj_request->result,\r\nobj_request->xferred, obj_request->length);\r\nif (layered && obj_request->result == -ENOENT &&\r\nobj_request->img_offset < rbd_dev->parent_overlap)\r\nrbd_img_parent_read(obj_request);\r\nelse if (img_request)\r\nrbd_img_obj_request_read_callback(obj_request);\r\nelse\r\nobj_request_done_set(obj_request);\r\n}\r\nstatic void rbd_osd_write_callback(struct rbd_obj_request *obj_request)\r\n{\r\ndout("%s: obj %p result %d %llu\n", __func__, obj_request,\r\nobj_request->result, obj_request->length);\r\nobj_request->xferred = obj_request->length;\r\nobj_request_done_set(obj_request);\r\n}\r\nstatic void rbd_osd_stat_callback(struct rbd_obj_request *obj_request)\r\n{\r\ndout("%s: obj %p\n", __func__, obj_request);\r\nobj_request_done_set(obj_request);\r\n}\r\nstatic void rbd_osd_req_callback(struct ceph_osd_request *osd_req,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct rbd_obj_request *obj_request = osd_req->r_priv;\r\nu16 opcode;\r\ndout("%s: osd_req %p msg %p\n", __func__, osd_req, msg);\r\nrbd_assert(osd_req == obj_request->osd_req);\r\nif (obj_request_img_data_test(obj_request)) {\r\nrbd_assert(obj_request->img_request);\r\nrbd_assert(obj_request->which != BAD_WHICH);\r\n} else {\r\nrbd_assert(obj_request->which == BAD_WHICH);\r\n}\r\nif (osd_req->r_result < 0)\r\nobj_request->result = osd_req->r_result;\r\nBUG_ON(osd_req->r_num_ops > 2);\r\nobj_request->xferred = osd_req->r_reply_op_len[0];\r\nrbd_assert(obj_request->xferred < (u64)UINT_MAX);\r\nopcode = osd_req->r_ops[0].op;\r\nswitch (opcode) {\r\ncase CEPH_OSD_OP_READ:\r\nrbd_osd_read_callback(obj_request);\r\nbreak;\r\ncase CEPH_OSD_OP_WRITE:\r\nrbd_osd_write_callback(obj_request);\r\nbreak;\r\ncase CEPH_OSD_OP_STAT:\r\nrbd_osd_stat_callback(obj_request);\r\nbreak;\r\ncase CEPH_OSD_OP_CALL:\r\ncase CEPH_OSD_OP_NOTIFY_ACK:\r\ncase CEPH_OSD_OP_WATCH:\r\nrbd_osd_trivial_callback(obj_request);\r\nbreak;\r\ndefault:\r\nrbd_warn(NULL, "%s: unsupported op %hu\n",\r\nobj_request->object_name, (unsigned short) opcode);\r\nbreak;\r\n}\r\nif (obj_request_done_test(obj_request))\r\nrbd_obj_request_complete(obj_request);\r\n}\r\nstatic void rbd_osd_req_format_read(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request = obj_request->img_request;\r\nstruct ceph_osd_request *osd_req = obj_request->osd_req;\r\nu64 snap_id;\r\nrbd_assert(osd_req != NULL);\r\nsnap_id = img_request ? img_request->snap_id : CEPH_NOSNAP;\r\nceph_osdc_build_request(osd_req, obj_request->offset,\r\nNULL, snap_id, NULL);\r\n}\r\nstatic void rbd_osd_req_format_write(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request = obj_request->img_request;\r\nstruct ceph_osd_request *osd_req = obj_request->osd_req;\r\nstruct ceph_snap_context *snapc;\r\nstruct timespec mtime = CURRENT_TIME;\r\nrbd_assert(osd_req != NULL);\r\nsnapc = img_request ? img_request->snapc : NULL;\r\nceph_osdc_build_request(osd_req, obj_request->offset,\r\nsnapc, CEPH_NOSNAP, &mtime);\r\n}\r\nstatic struct ceph_osd_request *rbd_osd_req_create(\r\nstruct rbd_device *rbd_dev,\r\nbool write_request,\r\nstruct rbd_obj_request *obj_request)\r\n{\r\nstruct ceph_snap_context *snapc = NULL;\r\nstruct ceph_osd_client *osdc;\r\nstruct ceph_osd_request *osd_req;\r\nif (obj_request_img_data_test(obj_request)) {\r\nstruct rbd_img_request *img_request = obj_request->img_request;\r\nrbd_assert(write_request ==\r\nimg_request_write_test(img_request));\r\nif (write_request)\r\nsnapc = img_request->snapc;\r\n}\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nosd_req = ceph_osdc_alloc_request(osdc, snapc, 1, false, GFP_ATOMIC);\r\nif (!osd_req)\r\nreturn NULL;\r\nif (write_request)\r\nosd_req->r_flags = CEPH_OSD_FLAG_WRITE | CEPH_OSD_FLAG_ONDISK;\r\nelse\r\nosd_req->r_flags = CEPH_OSD_FLAG_READ;\r\nosd_req->r_callback = rbd_osd_req_callback;\r\nosd_req->r_priv = obj_request;\r\nosd_req->r_oid_len = strlen(obj_request->object_name);\r\nrbd_assert(osd_req->r_oid_len < sizeof (osd_req->r_oid));\r\nmemcpy(osd_req->r_oid, obj_request->object_name, osd_req->r_oid_len);\r\nosd_req->r_file_layout = rbd_dev->layout;\r\nreturn osd_req;\r\n}\r\nstatic struct ceph_osd_request *\r\nrbd_osd_req_create_copyup(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request;\r\nstruct ceph_snap_context *snapc;\r\nstruct rbd_device *rbd_dev;\r\nstruct ceph_osd_client *osdc;\r\nstruct ceph_osd_request *osd_req;\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nimg_request = obj_request->img_request;\r\nrbd_assert(img_request);\r\nrbd_assert(img_request_write_test(img_request));\r\nsnapc = img_request->snapc;\r\nrbd_dev = img_request->rbd_dev;\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nosd_req = ceph_osdc_alloc_request(osdc, snapc, 2, false, GFP_ATOMIC);\r\nif (!osd_req)\r\nreturn NULL;\r\nosd_req->r_flags = CEPH_OSD_FLAG_WRITE | CEPH_OSD_FLAG_ONDISK;\r\nosd_req->r_callback = rbd_osd_req_callback;\r\nosd_req->r_priv = obj_request;\r\nosd_req->r_oid_len = strlen(obj_request->object_name);\r\nrbd_assert(osd_req->r_oid_len < sizeof (osd_req->r_oid));\r\nmemcpy(osd_req->r_oid, obj_request->object_name, osd_req->r_oid_len);\r\nosd_req->r_file_layout = rbd_dev->layout;\r\nreturn osd_req;\r\n}\r\nstatic void rbd_osd_req_destroy(struct ceph_osd_request *osd_req)\r\n{\r\nceph_osdc_put_request(osd_req);\r\n}\r\nstatic struct rbd_obj_request *rbd_obj_request_create(const char *object_name,\r\nu64 offset, u64 length,\r\nenum obj_request_type type)\r\n{\r\nstruct rbd_obj_request *obj_request;\r\nsize_t size;\r\nchar *name;\r\nrbd_assert(obj_request_type_valid(type));\r\nsize = strlen(object_name) + 1;\r\nname = kmalloc(size, GFP_KERNEL);\r\nif (!name)\r\nreturn NULL;\r\nobj_request = kmem_cache_zalloc(rbd_obj_request_cache, GFP_KERNEL);\r\nif (!obj_request) {\r\nkfree(name);\r\nreturn NULL;\r\n}\r\nobj_request->object_name = memcpy(name, object_name, size);\r\nobj_request->offset = offset;\r\nobj_request->length = length;\r\nobj_request->flags = 0;\r\nobj_request->which = BAD_WHICH;\r\nobj_request->type = type;\r\nINIT_LIST_HEAD(&obj_request->links);\r\ninit_completion(&obj_request->completion);\r\nkref_init(&obj_request->kref);\r\ndout("%s: \"%s\" %llu/%llu %d -> obj %p\n", __func__, object_name,\r\noffset, length, (int)type, obj_request);\r\nreturn obj_request;\r\n}\r\nstatic void rbd_obj_request_destroy(struct kref *kref)\r\n{\r\nstruct rbd_obj_request *obj_request;\r\nobj_request = container_of(kref, struct rbd_obj_request, kref);\r\ndout("%s: obj %p\n", __func__, obj_request);\r\nrbd_assert(obj_request->img_request == NULL);\r\nrbd_assert(obj_request->which == BAD_WHICH);\r\nif (obj_request->osd_req)\r\nrbd_osd_req_destroy(obj_request->osd_req);\r\nrbd_assert(obj_request_type_valid(obj_request->type));\r\nswitch (obj_request->type) {\r\ncase OBJ_REQUEST_NODATA:\r\nbreak;\r\ncase OBJ_REQUEST_BIO:\r\nif (obj_request->bio_list)\r\nbio_chain_put(obj_request->bio_list);\r\nbreak;\r\ncase OBJ_REQUEST_PAGES:\r\nif (obj_request->pages)\r\nceph_release_page_vector(obj_request->pages,\r\nobj_request->page_count);\r\nbreak;\r\n}\r\nkfree(obj_request->object_name);\r\nobj_request->object_name = NULL;\r\nkmem_cache_free(rbd_obj_request_cache, obj_request);\r\n}\r\nstatic void rbd_dev_unparent(struct rbd_device *rbd_dev)\r\n{\r\nrbd_dev_remove_parent(rbd_dev);\r\nrbd_spec_put(rbd_dev->parent_spec);\r\nrbd_dev->parent_spec = NULL;\r\nrbd_dev->parent_overlap = 0;\r\n}\r\nstatic void rbd_dev_parent_put(struct rbd_device *rbd_dev)\r\n{\r\nint counter;\r\nif (!rbd_dev->parent_spec)\r\nreturn;\r\ncounter = atomic_dec_return_safe(&rbd_dev->parent_ref);\r\nif (counter > 0)\r\nreturn;\r\nif (!counter)\r\nrbd_dev_unparent(rbd_dev);\r\nelse\r\nrbd_warn(rbd_dev, "parent reference underflow\n");\r\n}\r\nstatic bool rbd_dev_parent_get(struct rbd_device *rbd_dev)\r\n{\r\nint counter;\r\nif (!rbd_dev->parent_spec)\r\nreturn false;\r\ncounter = atomic_inc_return_safe(&rbd_dev->parent_ref);\r\nif (counter > 0 && rbd_dev->parent_overlap)\r\nreturn true;\r\nif (counter < 0)\r\nrbd_warn(rbd_dev, "parent reference overflow\n");\r\nreturn false;\r\n}\r\nstatic struct rbd_img_request *rbd_img_request_create(\r\nstruct rbd_device *rbd_dev,\r\nu64 offset, u64 length,\r\nbool write_request)\r\n{\r\nstruct rbd_img_request *img_request;\r\nimg_request = kmem_cache_alloc(rbd_img_request_cache, GFP_ATOMIC);\r\nif (!img_request)\r\nreturn NULL;\r\nif (write_request) {\r\ndown_read(&rbd_dev->header_rwsem);\r\nceph_get_snap_context(rbd_dev->header.snapc);\r\nup_read(&rbd_dev->header_rwsem);\r\n}\r\nimg_request->rq = NULL;\r\nimg_request->rbd_dev = rbd_dev;\r\nimg_request->offset = offset;\r\nimg_request->length = length;\r\nimg_request->flags = 0;\r\nif (write_request) {\r\nimg_request_write_set(img_request);\r\nimg_request->snapc = rbd_dev->header.snapc;\r\n} else {\r\nimg_request->snap_id = rbd_dev->spec->snap_id;\r\n}\r\nif (rbd_dev_parent_get(rbd_dev))\r\nimg_request_layered_set(img_request);\r\nspin_lock_init(&img_request->completion_lock);\r\nimg_request->next_completion = 0;\r\nimg_request->callback = NULL;\r\nimg_request->result = 0;\r\nimg_request->obj_request_count = 0;\r\nINIT_LIST_HEAD(&img_request->obj_requests);\r\nkref_init(&img_request->kref);\r\ndout("%s: rbd_dev %p %s %llu/%llu -> img %p\n", __func__, rbd_dev,\r\nwrite_request ? "write" : "read", offset, length,\r\nimg_request);\r\nreturn img_request;\r\n}\r\nstatic void rbd_img_request_destroy(struct kref *kref)\r\n{\r\nstruct rbd_img_request *img_request;\r\nstruct rbd_obj_request *obj_request;\r\nstruct rbd_obj_request *next_obj_request;\r\nimg_request = container_of(kref, struct rbd_img_request, kref);\r\ndout("%s: img %p\n", __func__, img_request);\r\nfor_each_obj_request_safe(img_request, obj_request, next_obj_request)\r\nrbd_img_obj_request_del(img_request, obj_request);\r\nrbd_assert(img_request->obj_request_count == 0);\r\nif (img_request_layered_test(img_request)) {\r\nimg_request_layered_clear(img_request);\r\nrbd_dev_parent_put(img_request->rbd_dev);\r\n}\r\nif (img_request_write_test(img_request))\r\nceph_put_snap_context(img_request->snapc);\r\nkmem_cache_free(rbd_img_request_cache, img_request);\r\n}\r\nstatic struct rbd_img_request *rbd_parent_request_create(\r\nstruct rbd_obj_request *obj_request,\r\nu64 img_offset, u64 length)\r\n{\r\nstruct rbd_img_request *parent_request;\r\nstruct rbd_device *rbd_dev;\r\nrbd_assert(obj_request->img_request);\r\nrbd_dev = obj_request->img_request->rbd_dev;\r\nparent_request = rbd_img_request_create(rbd_dev->parent,\r\nimg_offset, length, false);\r\nif (!parent_request)\r\nreturn NULL;\r\nimg_request_child_set(parent_request);\r\nrbd_obj_request_get(obj_request);\r\nparent_request->obj_request = obj_request;\r\nreturn parent_request;\r\n}\r\nstatic void rbd_parent_request_destroy(struct kref *kref)\r\n{\r\nstruct rbd_img_request *parent_request;\r\nstruct rbd_obj_request *orig_request;\r\nparent_request = container_of(kref, struct rbd_img_request, kref);\r\norig_request = parent_request->obj_request;\r\nparent_request->obj_request = NULL;\r\nrbd_obj_request_put(orig_request);\r\nimg_request_child_clear(parent_request);\r\nrbd_img_request_destroy(kref);\r\n}\r\nstatic bool rbd_img_obj_end_request(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request;\r\nunsigned int xferred;\r\nint result;\r\nbool more;\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nimg_request = obj_request->img_request;\r\nrbd_assert(obj_request->xferred <= (u64)UINT_MAX);\r\nxferred = (unsigned int)obj_request->xferred;\r\nresult = obj_request->result;\r\nif (result) {\r\nstruct rbd_device *rbd_dev = img_request->rbd_dev;\r\nrbd_warn(rbd_dev, "%s %llx at %llx (%llx)\n",\r\nimg_request_write_test(img_request) ? "write" : "read",\r\nobj_request->length, obj_request->img_offset,\r\nobj_request->offset);\r\nrbd_warn(rbd_dev, " result %d xferred %x\n",\r\nresult, xferred);\r\nif (!img_request->result)\r\nimg_request->result = result;\r\n}\r\nif (obj_request->type == OBJ_REQUEST_PAGES) {\r\nobj_request->pages = NULL;\r\nobj_request->page_count = 0;\r\n}\r\nif (img_request_child_test(img_request)) {\r\nrbd_assert(img_request->obj_request != NULL);\r\nmore = obj_request->which < img_request->obj_request_count - 1;\r\n} else {\r\nrbd_assert(img_request->rq != NULL);\r\nmore = blk_end_request(img_request->rq, result, xferred);\r\n}\r\nreturn more;\r\n}\r\nstatic void rbd_img_obj_callback(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request;\r\nu32 which = obj_request->which;\r\nbool more = true;\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nimg_request = obj_request->img_request;\r\ndout("%s: img %p obj %p\n", __func__, img_request, obj_request);\r\nrbd_assert(img_request != NULL);\r\nrbd_assert(img_request->obj_request_count > 0);\r\nrbd_assert(which != BAD_WHICH);\r\nrbd_assert(which < img_request->obj_request_count);\r\nrbd_assert(which >= img_request->next_completion);\r\nspin_lock_irq(&img_request->completion_lock);\r\nif (which != img_request->next_completion)\r\ngoto out;\r\nfor_each_obj_request_from(img_request, obj_request) {\r\nrbd_assert(more);\r\nrbd_assert(which < img_request->obj_request_count);\r\nif (!obj_request_done_test(obj_request))\r\nbreak;\r\nmore = rbd_img_obj_end_request(obj_request);\r\nwhich++;\r\n}\r\nrbd_assert(more ^ (which == img_request->obj_request_count));\r\nimg_request->next_completion = which;\r\nout:\r\nspin_unlock_irq(&img_request->completion_lock);\r\nif (!more)\r\nrbd_img_request_complete(img_request);\r\n}\r\nstatic int rbd_img_request_fill(struct rbd_img_request *img_request,\r\nenum obj_request_type type,\r\nvoid *data_desc)\r\n{\r\nstruct rbd_device *rbd_dev = img_request->rbd_dev;\r\nstruct rbd_obj_request *obj_request = NULL;\r\nstruct rbd_obj_request *next_obj_request;\r\nbool write_request = img_request_write_test(img_request);\r\nstruct bio *bio_list = NULL;\r\nunsigned int bio_offset = 0;\r\nstruct page **pages = NULL;\r\nu64 img_offset;\r\nu64 resid;\r\nu16 opcode;\r\ndout("%s: img %p type %d data_desc %p\n", __func__, img_request,\r\n(int)type, data_desc);\r\nopcode = write_request ? CEPH_OSD_OP_WRITE : CEPH_OSD_OP_READ;\r\nimg_offset = img_request->offset;\r\nresid = img_request->length;\r\nrbd_assert(resid > 0);\r\nif (type == OBJ_REQUEST_BIO) {\r\nbio_list = data_desc;\r\nrbd_assert(img_offset == bio_list->bi_sector << SECTOR_SHIFT);\r\n} else {\r\nrbd_assert(type == OBJ_REQUEST_PAGES);\r\npages = data_desc;\r\n}\r\nwhile (resid) {\r\nstruct ceph_osd_request *osd_req;\r\nconst char *object_name;\r\nu64 offset;\r\nu64 length;\r\nobject_name = rbd_segment_name(rbd_dev, img_offset);\r\nif (!object_name)\r\ngoto out_unwind;\r\noffset = rbd_segment_offset(rbd_dev, img_offset);\r\nlength = rbd_segment_length(rbd_dev, img_offset, resid);\r\nobj_request = rbd_obj_request_create(object_name,\r\noffset, length, type);\r\nrbd_segment_name_free(object_name);\r\nif (!obj_request)\r\ngoto out_unwind;\r\nrbd_img_obj_request_add(img_request, obj_request);\r\nif (type == OBJ_REQUEST_BIO) {\r\nunsigned int clone_size;\r\nrbd_assert(length <= (u64)UINT_MAX);\r\nclone_size = (unsigned int)length;\r\nobj_request->bio_list =\r\nbio_chain_clone_range(&bio_list,\r\n&bio_offset,\r\nclone_size,\r\nGFP_ATOMIC);\r\nif (!obj_request->bio_list)\r\ngoto out_partial;\r\n} else {\r\nunsigned int page_count;\r\nobj_request->pages = pages;\r\npage_count = (u32)calc_pages_for(offset, length);\r\nobj_request->page_count = page_count;\r\nif ((offset + length) & ~PAGE_MASK)\r\npage_count--;\r\npages += page_count;\r\n}\r\nosd_req = rbd_osd_req_create(rbd_dev, write_request,\r\nobj_request);\r\nif (!osd_req)\r\ngoto out_partial;\r\nobj_request->osd_req = osd_req;\r\nobj_request->callback = rbd_img_obj_callback;\r\nosd_req_op_extent_init(osd_req, 0, opcode, offset, length,\r\n0, 0);\r\nif (type == OBJ_REQUEST_BIO)\r\nosd_req_op_extent_osd_data_bio(osd_req, 0,\r\nobj_request->bio_list, length);\r\nelse\r\nosd_req_op_extent_osd_data_pages(osd_req, 0,\r\nobj_request->pages, length,\r\noffset & ~PAGE_MASK, false, false);\r\nif (write_request)\r\nrbd_osd_req_format_write(obj_request);\r\nelse\r\nrbd_osd_req_format_read(obj_request);\r\nobj_request->img_offset = img_offset;\r\nimg_offset += length;\r\nresid -= length;\r\n}\r\nreturn 0;\r\nout_partial:\r\nrbd_obj_request_put(obj_request);\r\nout_unwind:\r\nfor_each_obj_request_safe(img_request, obj_request, next_obj_request)\r\nrbd_obj_request_put(obj_request);\r\nreturn -ENOMEM;\r\n}\r\nstatic void\r\nrbd_img_obj_copyup_callback(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request;\r\nstruct rbd_device *rbd_dev;\r\nstruct page **pages;\r\nu32 page_count;\r\nrbd_assert(obj_request->type == OBJ_REQUEST_BIO);\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nimg_request = obj_request->img_request;\r\nrbd_assert(img_request);\r\nrbd_dev = img_request->rbd_dev;\r\nrbd_assert(rbd_dev);\r\npages = obj_request->copyup_pages;\r\nrbd_assert(pages != NULL);\r\nobj_request->copyup_pages = NULL;\r\npage_count = obj_request->copyup_page_count;\r\nrbd_assert(page_count);\r\nobj_request->copyup_page_count = 0;\r\nceph_release_page_vector(pages, page_count);\r\nif (!obj_request->result)\r\nobj_request->xferred = obj_request->length;\r\nrbd_img_obj_callback(obj_request);\r\n}\r\nstatic void\r\nrbd_img_obj_parent_read_full_callback(struct rbd_img_request *img_request)\r\n{\r\nstruct rbd_obj_request *orig_request;\r\nstruct ceph_osd_request *osd_req;\r\nstruct ceph_osd_client *osdc;\r\nstruct rbd_device *rbd_dev;\r\nstruct page **pages;\r\nu32 page_count;\r\nint img_result;\r\nu64 parent_length;\r\nu64 offset;\r\nu64 length;\r\nrbd_assert(img_request_child_test(img_request));\r\npages = img_request->copyup_pages;\r\nrbd_assert(pages != NULL);\r\nimg_request->copyup_pages = NULL;\r\npage_count = img_request->copyup_page_count;\r\nrbd_assert(page_count);\r\nimg_request->copyup_page_count = 0;\r\norig_request = img_request->obj_request;\r\nrbd_assert(orig_request != NULL);\r\nrbd_assert(obj_request_type_valid(orig_request->type));\r\nimg_result = img_request->result;\r\nparent_length = img_request->length;\r\nrbd_assert(parent_length == img_request->xferred);\r\nrbd_img_request_put(img_request);\r\nrbd_assert(orig_request->img_request);\r\nrbd_dev = orig_request->img_request->rbd_dev;\r\nrbd_assert(rbd_dev);\r\nif (!rbd_dev->parent_overlap) {\r\nstruct ceph_osd_client *osdc;\r\nceph_release_page_vector(pages, page_count);\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nimg_result = rbd_obj_request_submit(osdc, orig_request);\r\nif (!img_result)\r\nreturn;\r\n}\r\nif (img_result)\r\ngoto out_err;\r\nimg_result = -ENOMEM;\r\nosd_req = rbd_osd_req_create_copyup(orig_request);\r\nif (!osd_req)\r\ngoto out_err;\r\nrbd_osd_req_destroy(orig_request->osd_req);\r\norig_request->osd_req = osd_req;\r\norig_request->copyup_pages = pages;\r\norig_request->copyup_page_count = page_count;\r\nosd_req_op_cls_init(osd_req, 0, CEPH_OSD_OP_CALL, "rbd", "copyup");\r\nosd_req_op_cls_request_data_pages(osd_req, 0, pages, parent_length, 0,\r\nfalse, false);\r\noffset = orig_request->offset;\r\nlength = orig_request->length;\r\nosd_req_op_extent_init(osd_req, 1, CEPH_OSD_OP_WRITE,\r\noffset, length, 0, 0);\r\nif (orig_request->type == OBJ_REQUEST_BIO)\r\nosd_req_op_extent_osd_data_bio(osd_req, 1,\r\norig_request->bio_list, length);\r\nelse\r\nosd_req_op_extent_osd_data_pages(osd_req, 1,\r\norig_request->pages, length,\r\noffset & ~PAGE_MASK, false, false);\r\nrbd_osd_req_format_write(orig_request);\r\norig_request->callback = rbd_img_obj_copyup_callback;\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nimg_result = rbd_obj_request_submit(osdc, orig_request);\r\nif (!img_result)\r\nreturn;\r\nout_err:\r\norig_request->result = img_result;\r\norig_request->xferred = 0;\r\nobj_request_done_set(orig_request);\r\nrbd_obj_request_complete(orig_request);\r\n}\r\nstatic int rbd_img_obj_parent_read_full(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request = NULL;\r\nstruct rbd_img_request *parent_request = NULL;\r\nstruct rbd_device *rbd_dev;\r\nu64 img_offset;\r\nu64 length;\r\nstruct page **pages = NULL;\r\nu32 page_count;\r\nint result;\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nrbd_assert(obj_request_type_valid(obj_request->type));\r\nimg_request = obj_request->img_request;\r\nrbd_assert(img_request != NULL);\r\nrbd_dev = img_request->rbd_dev;\r\nrbd_assert(rbd_dev->parent != NULL);\r\nimg_offset = obj_request->img_offset - obj_request->offset;\r\nlength = (u64)1 << rbd_dev->header.obj_order;\r\nif (img_offset + length > rbd_dev->parent_overlap) {\r\nrbd_assert(img_offset < rbd_dev->parent_overlap);\r\nlength = rbd_dev->parent_overlap - img_offset;\r\n}\r\npage_count = (u32)calc_pages_for(0, length);\r\npages = ceph_alloc_page_vector(page_count, GFP_KERNEL);\r\nif (IS_ERR(pages)) {\r\nresult = PTR_ERR(pages);\r\npages = NULL;\r\ngoto out_err;\r\n}\r\nresult = -ENOMEM;\r\nparent_request = rbd_parent_request_create(obj_request,\r\nimg_offset, length);\r\nif (!parent_request)\r\ngoto out_err;\r\nresult = rbd_img_request_fill(parent_request, OBJ_REQUEST_PAGES, pages);\r\nif (result)\r\ngoto out_err;\r\nparent_request->copyup_pages = pages;\r\nparent_request->copyup_page_count = page_count;\r\nparent_request->callback = rbd_img_obj_parent_read_full_callback;\r\nresult = rbd_img_request_submit(parent_request);\r\nif (!result)\r\nreturn 0;\r\nparent_request->copyup_pages = NULL;\r\nparent_request->copyup_page_count = 0;\r\nparent_request->obj_request = NULL;\r\nrbd_obj_request_put(obj_request);\r\nout_err:\r\nif (pages)\r\nceph_release_page_vector(pages, page_count);\r\nif (parent_request)\r\nrbd_img_request_put(parent_request);\r\nobj_request->result = result;\r\nobj_request->xferred = 0;\r\nobj_request_done_set(obj_request);\r\nreturn result;\r\n}\r\nstatic void rbd_img_obj_exists_callback(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_obj_request *orig_request;\r\nstruct rbd_device *rbd_dev;\r\nint result;\r\nrbd_assert(!obj_request_img_data_test(obj_request));\r\norig_request = obj_request->obj_request;\r\nobj_request->obj_request = NULL;\r\nrbd_obj_request_put(orig_request);\r\nrbd_assert(orig_request);\r\nrbd_assert(orig_request->img_request);\r\nresult = obj_request->result;\r\nobj_request->result = 0;\r\ndout("%s: obj %p for obj %p result %d %llu/%llu\n", __func__,\r\nobj_request, orig_request, result,\r\nobj_request->xferred, obj_request->length);\r\nrbd_obj_request_put(obj_request);\r\nrbd_dev = orig_request->img_request->rbd_dev;\r\nif (!rbd_dev->parent_overlap) {\r\nstruct ceph_osd_client *osdc;\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nresult = rbd_obj_request_submit(osdc, orig_request);\r\nif (!result)\r\nreturn;\r\n}\r\nif (!result) {\r\nobj_request_existence_set(orig_request, true);\r\n} else if (result == -ENOENT) {\r\nobj_request_existence_set(orig_request, false);\r\n} else if (result) {\r\norig_request->result = result;\r\ngoto out;\r\n}\r\norig_request->result = rbd_img_obj_request_submit(orig_request);\r\nout:\r\nif (orig_request->result)\r\nrbd_obj_request_complete(orig_request);\r\n}\r\nstatic int rbd_img_obj_exists_submit(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_obj_request *stat_request;\r\nstruct rbd_device *rbd_dev;\r\nstruct ceph_osd_client *osdc;\r\nstruct page **pages = NULL;\r\nu32 page_count;\r\nsize_t size;\r\nint ret;\r\nsize = sizeof (__le64) + sizeof (__le32) + sizeof (__le32);\r\npage_count = (u32)calc_pages_for(0, size);\r\npages = ceph_alloc_page_vector(page_count, GFP_KERNEL);\r\nif (IS_ERR(pages))\r\nreturn PTR_ERR(pages);\r\nret = -ENOMEM;\r\nstat_request = rbd_obj_request_create(obj_request->object_name, 0, 0,\r\nOBJ_REQUEST_PAGES);\r\nif (!stat_request)\r\ngoto out;\r\nrbd_obj_request_get(obj_request);\r\nstat_request->obj_request = obj_request;\r\nstat_request->pages = pages;\r\nstat_request->page_count = page_count;\r\nrbd_assert(obj_request->img_request);\r\nrbd_dev = obj_request->img_request->rbd_dev;\r\nstat_request->osd_req = rbd_osd_req_create(rbd_dev, false,\r\nstat_request);\r\nif (!stat_request->osd_req)\r\ngoto out;\r\nstat_request->callback = rbd_img_obj_exists_callback;\r\nosd_req_op_init(stat_request->osd_req, 0, CEPH_OSD_OP_STAT);\r\nosd_req_op_raw_data_in_pages(stat_request->osd_req, 0, pages, size, 0,\r\nfalse, false);\r\nrbd_osd_req_format_read(stat_request);\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nret = rbd_obj_request_submit(osdc, stat_request);\r\nout:\r\nif (ret)\r\nrbd_obj_request_put(obj_request);\r\nreturn ret;\r\n}\r\nstatic int rbd_img_obj_request_submit(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request;\r\nstruct rbd_device *rbd_dev;\r\nbool known;\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nimg_request = obj_request->img_request;\r\nrbd_assert(img_request);\r\nrbd_dev = img_request->rbd_dev;\r\nif (!img_request_write_test(img_request) ||\r\n!img_request_layered_test(img_request) ||\r\nrbd_dev->parent_overlap <= obj_request->img_offset ||\r\n((known = obj_request_known_test(obj_request)) &&\r\nobj_request_exists_test(obj_request))) {\r\nstruct rbd_device *rbd_dev;\r\nstruct ceph_osd_client *osdc;\r\nrbd_dev = obj_request->img_request->rbd_dev;\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nreturn rbd_obj_request_submit(osdc, obj_request);\r\n}\r\nif (known)\r\nreturn rbd_img_obj_parent_read_full(obj_request);\r\nreturn rbd_img_obj_exists_submit(obj_request);\r\n}\r\nstatic int rbd_img_request_submit(struct rbd_img_request *img_request)\r\n{\r\nstruct rbd_obj_request *obj_request;\r\nstruct rbd_obj_request *next_obj_request;\r\ndout("%s: img %p\n", __func__, img_request);\r\nfor_each_obj_request_safe(img_request, obj_request, next_obj_request) {\r\nint ret;\r\nret = rbd_img_obj_request_submit(obj_request);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void rbd_img_parent_read_callback(struct rbd_img_request *img_request)\r\n{\r\nstruct rbd_obj_request *obj_request;\r\nstruct rbd_device *rbd_dev;\r\nu64 obj_end;\r\nu64 img_xferred;\r\nint img_result;\r\nrbd_assert(img_request_child_test(img_request));\r\nobj_request = img_request->obj_request;\r\nimg_xferred = img_request->xferred;\r\nimg_result = img_request->result;\r\nrbd_img_request_put(img_request);\r\nrbd_assert(obj_request);\r\nrbd_assert(obj_request->img_request);\r\nrbd_dev = obj_request->img_request->rbd_dev;\r\nif (!rbd_dev->parent_overlap) {\r\nstruct ceph_osd_client *osdc;\r\nosdc = &rbd_dev->rbd_client->client->osdc;\r\nimg_result = rbd_obj_request_submit(osdc, obj_request);\r\nif (!img_result)\r\nreturn;\r\n}\r\nobj_request->result = img_result;\r\nif (obj_request->result)\r\ngoto out;\r\nrbd_assert(obj_request->img_offset < U64_MAX - obj_request->length);\r\nobj_end = obj_request->img_offset + obj_request->length;\r\nif (obj_end > rbd_dev->parent_overlap) {\r\nu64 xferred = 0;\r\nif (obj_request->img_offset < rbd_dev->parent_overlap)\r\nxferred = rbd_dev->parent_overlap -\r\nobj_request->img_offset;\r\nobj_request->xferred = min(img_xferred, xferred);\r\n} else {\r\nobj_request->xferred = img_xferred;\r\n}\r\nout:\r\nrbd_img_obj_request_read_callback(obj_request);\r\nrbd_obj_request_complete(obj_request);\r\n}\r\nstatic void rbd_img_parent_read(struct rbd_obj_request *obj_request)\r\n{\r\nstruct rbd_img_request *img_request;\r\nint result;\r\nrbd_assert(obj_request_img_data_test(obj_request));\r\nrbd_assert(obj_request->img_request != NULL);\r\nrbd_assert(obj_request->result == (s32) -ENOENT);\r\nrbd_assert(obj_request_type_valid(obj_request->type));\r\nimg_request = rbd_parent_request_create(obj_request,\r\nobj_request->img_offset,\r\nobj_request->length);\r\nresult = -ENOMEM;\r\nif (!img_request)\r\ngoto out_err;\r\nif (obj_request->type == OBJ_REQUEST_BIO)\r\nresult = rbd_img_request_fill(img_request, OBJ_REQUEST_BIO,\r\nobj_request->bio_list);\r\nelse\r\nresult = rbd_img_request_fill(img_request, OBJ_REQUEST_PAGES,\r\nobj_request->pages);\r\nif (result)\r\ngoto out_err;\r\nimg_request->callback = rbd_img_parent_read_callback;\r\nresult = rbd_img_request_submit(img_request);\r\nif (result)\r\ngoto out_err;\r\nreturn;\r\nout_err:\r\nif (img_request)\r\nrbd_img_request_put(img_request);\r\nobj_request->result = result;\r\nobj_request->xferred = 0;\r\nobj_request_done_set(obj_request);\r\n}\r\nstatic int rbd_obj_notify_ack_sync(struct rbd_device *rbd_dev, u64 notify_id)\r\n{\r\nstruct rbd_obj_request *obj_request;\r\nstruct ceph_osd_client *osdc = &rbd_dev->rbd_client->client->osdc;\r\nint ret;\r\nobj_request = rbd_obj_request_create(rbd_dev->header_name, 0, 0,\r\nOBJ_REQUEST_NODATA);\r\nif (!obj_request)\r\nreturn -ENOMEM;\r\nret = -ENOMEM;\r\nobj_request->osd_req = rbd_osd_req_create(rbd_dev, false, obj_request);\r\nif (!obj_request->osd_req)\r\ngoto out;\r\nosd_req_op_watch_init(obj_request->osd_req, 0, CEPH_OSD_OP_NOTIFY_ACK,\r\nnotify_id, 0, 0);\r\nrbd_osd_req_format_read(obj_request);\r\nret = rbd_obj_request_submit(osdc, obj_request);\r\nif (ret)\r\ngoto out;\r\nret = rbd_obj_request_wait(obj_request);\r\nout:\r\nrbd_obj_request_put(obj_request);\r\nreturn ret;\r\n}\r\nstatic void rbd_watch_cb(u64 ver, u64 notify_id, u8 opcode, void *data)\r\n{\r\nstruct rbd_device *rbd_dev = (struct rbd_device *)data;\r\nint ret;\r\nif (!rbd_dev)\r\nreturn;\r\ndout("%s: \"%s\" notify_id %llu opcode %u\n", __func__,\r\nrbd_dev->header_name, (unsigned long long)notify_id,\r\n(unsigned int)opcode);\r\nret = rbd_dev_refresh(rbd_dev);\r\nif (ret)\r\nrbd_warn(rbd_dev, "header refresh error (%d)\n", ret);\r\nrbd_obj_notify_ack_sync(rbd_dev, notify_id);\r\n}\r\nstatic int rbd_dev_header_watch_sync(struct rbd_device *rbd_dev, bool start)\r\n{\r\nstruct ceph_osd_client *osdc = &rbd_dev->rbd_client->client->osdc;\r\nstruct rbd_obj_request *obj_request;\r\nint ret;\r\nrbd_assert(start ^ !!rbd_dev->watch_event);\r\nrbd_assert(start ^ !!rbd_dev->watch_request);\r\nif (start) {\r\nret = ceph_osdc_create_event(osdc, rbd_watch_cb, rbd_dev,\r\n&rbd_dev->watch_event);\r\nif (ret < 0)\r\nreturn ret;\r\nrbd_assert(rbd_dev->watch_event != NULL);\r\n}\r\nret = -ENOMEM;\r\nobj_request = rbd_obj_request_create(rbd_dev->header_name, 0, 0,\r\nOBJ_REQUEST_NODATA);\r\nif (!obj_request)\r\ngoto out_cancel;\r\nobj_request->osd_req = rbd_osd_req_create(rbd_dev, true, obj_request);\r\nif (!obj_request->osd_req)\r\ngoto out_cancel;\r\nif (start)\r\nceph_osdc_set_request_linger(osdc, obj_request->osd_req);\r\nelse\r\nceph_osdc_unregister_linger_request(osdc,\r\nrbd_dev->watch_request->osd_req);\r\nosd_req_op_watch_init(obj_request->osd_req, 0, CEPH_OSD_OP_WATCH,\r\nrbd_dev->watch_event->cookie, 0, start ? 1 : 0);\r\nrbd_osd_req_format_write(obj_request);\r\nret = rbd_obj_request_submit(osdc, obj_request);\r\nif (ret)\r\ngoto out_cancel;\r\nret = rbd_obj_request_wait(obj_request);\r\nif (ret)\r\ngoto out_cancel;\r\nret = obj_request->result;\r\nif (ret)\r\ngoto out_cancel;\r\nif (start) {\r\nrbd_dev->watch_request = obj_request;\r\nreturn 0;\r\n}\r\nrbd_obj_request_put(rbd_dev->watch_request);\r\nrbd_dev->watch_request = NULL;\r\nout_cancel:\r\nceph_osdc_cancel_event(rbd_dev->watch_event);\r\nrbd_dev->watch_event = NULL;\r\nif (obj_request)\r\nrbd_obj_request_put(obj_request);\r\nreturn ret;\r\n}\r\nstatic int rbd_obj_method_sync(struct rbd_device *rbd_dev,\r\nconst char *object_name,\r\nconst char *class_name,\r\nconst char *method_name,\r\nconst void *outbound,\r\nsize_t outbound_size,\r\nvoid *inbound,\r\nsize_t inbound_size)\r\n{\r\nstruct ceph_osd_client *osdc = &rbd_dev->rbd_client->client->osdc;\r\nstruct rbd_obj_request *obj_request;\r\nstruct page **pages;\r\nu32 page_count;\r\nint ret;\r\npage_count = (u32)calc_pages_for(0, inbound_size);\r\npages = ceph_alloc_page_vector(page_count, GFP_KERNEL);\r\nif (IS_ERR(pages))\r\nreturn PTR_ERR(pages);\r\nret = -ENOMEM;\r\nobj_request = rbd_obj_request_create(object_name, 0, inbound_size,\r\nOBJ_REQUEST_PAGES);\r\nif (!obj_request)\r\ngoto out;\r\nobj_request->pages = pages;\r\nobj_request->page_count = page_count;\r\nobj_request->osd_req = rbd_osd_req_create(rbd_dev, false, obj_request);\r\nif (!obj_request->osd_req)\r\ngoto out;\r\nosd_req_op_cls_init(obj_request->osd_req, 0, CEPH_OSD_OP_CALL,\r\nclass_name, method_name);\r\nif (outbound_size) {\r\nstruct ceph_pagelist *pagelist;\r\npagelist = kmalloc(sizeof (*pagelist), GFP_NOFS);\r\nif (!pagelist)\r\ngoto out;\r\nceph_pagelist_init(pagelist);\r\nceph_pagelist_append(pagelist, outbound, outbound_size);\r\nosd_req_op_cls_request_data_pagelist(obj_request->osd_req, 0,\r\npagelist);\r\n}\r\nosd_req_op_cls_response_data_pages(obj_request->osd_req, 0,\r\nobj_request->pages, inbound_size,\r\n0, false, false);\r\nrbd_osd_req_format_read(obj_request);\r\nret = rbd_obj_request_submit(osdc, obj_request);\r\nif (ret)\r\ngoto out;\r\nret = rbd_obj_request_wait(obj_request);\r\nif (ret)\r\ngoto out;\r\nret = obj_request->result;\r\nif (ret < 0)\r\ngoto out;\r\nrbd_assert(obj_request->xferred < (u64)INT_MAX);\r\nret = (int)obj_request->xferred;\r\nceph_copy_from_page_vector(pages, inbound, 0, obj_request->xferred);\r\nout:\r\nif (obj_request)\r\nrbd_obj_request_put(obj_request);\r\nelse\r\nceph_release_page_vector(pages, page_count);\r\nreturn ret;\r\n}\r\nstatic void rbd_request_fn(struct request_queue *q)\r\n__releases(q->queue_lock) __acquires(q->queue_lock)\r\n{\r\nstruct rbd_device *rbd_dev = q->queuedata;\r\nbool read_only = rbd_dev->mapping.read_only;\r\nstruct request *rq;\r\nint result;\r\nwhile ((rq = blk_fetch_request(q))) {\r\nbool write_request = rq_data_dir(rq) == WRITE;\r\nstruct rbd_img_request *img_request;\r\nu64 offset;\r\nu64 length;\r\nif (rq->cmd_type != REQ_TYPE_FS) {\r\ndout("%s: non-fs request type %d\n", __func__,\r\n(int) rq->cmd_type);\r\n__blk_end_request_all(rq, 0);\r\ncontinue;\r\n}\r\noffset = (u64) blk_rq_pos(rq) << SECTOR_SHIFT;\r\nlength = (u64) blk_rq_bytes(rq);\r\nif (!length) {\r\ndout("%s: zero-length request\n", __func__);\r\n__blk_end_request_all(rq, 0);\r\ncontinue;\r\n}\r\nspin_unlock_irq(q->queue_lock);\r\nif (write_request) {\r\nresult = -EROFS;\r\nif (read_only)\r\ngoto end_request;\r\nrbd_assert(rbd_dev->spec->snap_id == CEPH_NOSNAP);\r\n}\r\nif (!test_bit(RBD_DEV_FLAG_EXISTS, &rbd_dev->flags)) {\r\ndout("request for non-existent snapshot");\r\nrbd_assert(rbd_dev->spec->snap_id != CEPH_NOSNAP);\r\nresult = -ENXIO;\r\ngoto end_request;\r\n}\r\nresult = -EINVAL;\r\nif (offset && length > U64_MAX - offset + 1) {\r\nrbd_warn(rbd_dev, "bad request range (%llu~%llu)\n",\r\noffset, length);\r\ngoto end_request;\r\n}\r\nresult = -EIO;\r\nif (offset + length > rbd_dev->mapping.size) {\r\nrbd_warn(rbd_dev, "beyond EOD (%llu~%llu > %llu)\n",\r\noffset, length, rbd_dev->mapping.size);\r\ngoto end_request;\r\n}\r\nresult = -ENOMEM;\r\nimg_request = rbd_img_request_create(rbd_dev, offset, length,\r\nwrite_request);\r\nif (!img_request)\r\ngoto end_request;\r\nimg_request->rq = rq;\r\nresult = rbd_img_request_fill(img_request, OBJ_REQUEST_BIO,\r\nrq->bio);\r\nif (!result)\r\nresult = rbd_img_request_submit(img_request);\r\nif (result)\r\nrbd_img_request_put(img_request);\r\nend_request:\r\nspin_lock_irq(q->queue_lock);\r\nif (result < 0) {\r\nrbd_warn(rbd_dev, "%s %llx at %llx result %d\n",\r\nwrite_request ? "write" : "read",\r\nlength, offset, result);\r\n__blk_end_request_all(rq, result);\r\n}\r\n}\r\n}\r\nstatic int rbd_merge_bvec(struct request_queue *q, struct bvec_merge_data *bmd,\r\nstruct bio_vec *bvec)\r\n{\r\nstruct rbd_device *rbd_dev = q->queuedata;\r\nsector_t sector_offset;\r\nsector_t sectors_per_obj;\r\nsector_t obj_sector_offset;\r\nint ret;\r\nsector_offset = get_start_sect(bmd->bi_bdev) + bmd->bi_sector;\r\nsectors_per_obj = 1 << (rbd_dev->header.obj_order - SECTOR_SHIFT);\r\nobj_sector_offset = sector_offset & (sectors_per_obj - 1);\r\nret = (int) (sectors_per_obj - obj_sector_offset) << SECTOR_SHIFT;\r\nif (ret > bmd->bi_size)\r\nret -= bmd->bi_size;\r\nelse\r\nret = 0;\r\nrbd_assert(bvec->bv_len <= PAGE_SIZE);\r\nif (ret > (int) bvec->bv_len || !bmd->bi_size)\r\nret = (int) bvec->bv_len;\r\nreturn ret;\r\n}\r\nstatic void rbd_free_disk(struct rbd_device *rbd_dev)\r\n{\r\nstruct gendisk *disk = rbd_dev->disk;\r\nif (!disk)\r\nreturn;\r\nrbd_dev->disk = NULL;\r\nif (disk->flags & GENHD_FL_UP) {\r\ndel_gendisk(disk);\r\nif (disk->queue)\r\nblk_cleanup_queue(disk->queue);\r\n}\r\nput_disk(disk);\r\n}\r\nstatic int rbd_obj_read_sync(struct rbd_device *rbd_dev,\r\nconst char *object_name,\r\nu64 offset, u64 length, void *buf)\r\n{\r\nstruct ceph_osd_client *osdc = &rbd_dev->rbd_client->client->osdc;\r\nstruct rbd_obj_request *obj_request;\r\nstruct page **pages = NULL;\r\nu32 page_count;\r\nsize_t size;\r\nint ret;\r\npage_count = (u32) calc_pages_for(offset, length);\r\npages = ceph_alloc_page_vector(page_count, GFP_KERNEL);\r\nif (IS_ERR(pages))\r\nret = PTR_ERR(pages);\r\nret = -ENOMEM;\r\nobj_request = rbd_obj_request_create(object_name, offset, length,\r\nOBJ_REQUEST_PAGES);\r\nif (!obj_request)\r\ngoto out;\r\nobj_request->pages = pages;\r\nobj_request->page_count = page_count;\r\nobj_request->osd_req = rbd_osd_req_create(rbd_dev, false, obj_request);\r\nif (!obj_request->osd_req)\r\ngoto out;\r\nosd_req_op_extent_init(obj_request->osd_req, 0, CEPH_OSD_OP_READ,\r\noffset, length, 0, 0);\r\nosd_req_op_extent_osd_data_pages(obj_request->osd_req, 0,\r\nobj_request->pages,\r\nobj_request->length,\r\nobj_request->offset & ~PAGE_MASK,\r\nfalse, false);\r\nrbd_osd_req_format_read(obj_request);\r\nret = rbd_obj_request_submit(osdc, obj_request);\r\nif (ret)\r\ngoto out;\r\nret = rbd_obj_request_wait(obj_request);\r\nif (ret)\r\ngoto out;\r\nret = obj_request->result;\r\nif (ret < 0)\r\ngoto out;\r\nrbd_assert(obj_request->xferred <= (u64) SIZE_MAX);\r\nsize = (size_t) obj_request->xferred;\r\nceph_copy_from_page_vector(pages, buf, 0, size);\r\nrbd_assert(size <= (size_t)INT_MAX);\r\nret = (int)size;\r\nout:\r\nif (obj_request)\r\nrbd_obj_request_put(obj_request);\r\nelse\r\nceph_release_page_vector(pages, page_count);\r\nreturn ret;\r\n}\r\nstatic int rbd_dev_v1_header_info(struct rbd_device *rbd_dev)\r\n{\r\nstruct rbd_image_header_ondisk *ondisk = NULL;\r\nu32 snap_count = 0;\r\nu64 names_size = 0;\r\nu32 want_count;\r\nint ret;\r\ndo {\r\nsize_t size;\r\nkfree(ondisk);\r\nsize = sizeof (*ondisk);\r\nsize += snap_count * sizeof (struct rbd_image_snap_ondisk);\r\nsize += names_size;\r\nondisk = kmalloc(size, GFP_KERNEL);\r\nif (!ondisk)\r\nreturn -ENOMEM;\r\nret = rbd_obj_read_sync(rbd_dev, rbd_dev->header_name,\r\n0, size, ondisk);\r\nif (ret < 0)\r\ngoto out;\r\nif ((size_t)ret < size) {\r\nret = -ENXIO;\r\nrbd_warn(rbd_dev, "short header read (want %zd got %d)",\r\nsize, ret);\r\ngoto out;\r\n}\r\nif (!rbd_dev_ondisk_valid(ondisk)) {\r\nret = -ENXIO;\r\nrbd_warn(rbd_dev, "invalid header");\r\ngoto out;\r\n}\r\nnames_size = le64_to_cpu(ondisk->snap_names_len);\r\nwant_count = snap_count;\r\nsnap_count = le32_to_cpu(ondisk->snap_count);\r\n} while (snap_count != want_count);\r\nret = rbd_header_from_disk(rbd_dev, ondisk);\r\nout:\r\nkfree(ondisk);\r\nreturn ret;\r\n}\r\nstatic void rbd_exists_validate(struct rbd_device *rbd_dev)\r\n{\r\nu64 snap_id;\r\nif (!test_bit(RBD_DEV_FLAG_EXISTS, &rbd_dev->flags))\r\nreturn;\r\nsnap_id = rbd_dev->spec->snap_id;\r\nif (snap_id == CEPH_NOSNAP)\r\nreturn;\r\nif (rbd_dev_snap_index(rbd_dev, snap_id) == BAD_SNAP_INDEX)\r\nclear_bit(RBD_DEV_FLAG_EXISTS, &rbd_dev->flags);\r\n}\r\nstatic void rbd_dev_update_size(struct rbd_device *rbd_dev)\r\n{\r\nsector_t size;\r\nbool removing;\r\nspin_lock_irq(&rbd_dev->lock);\r\nremoving = test_bit(RBD_DEV_FLAG_REMOVING, &rbd_dev->flags);\r\nspin_unlock_irq(&rbd_dev->lock);\r\nif (!removing) {\r\nsize = (sector_t)rbd_dev->mapping.size / SECTOR_SIZE;\r\ndout("setting size to %llu sectors", (unsigned long long)size);\r\nset_capacity(rbd_dev->disk, size);\r\nrevalidate_disk(rbd_dev->disk);\r\n}\r\n}\r\nstatic int rbd_dev_refresh(struct rbd_device *rbd_dev)\r\n{\r\nu64 mapping_size;\r\nint ret;\r\nrbd_assert(rbd_image_format_valid(rbd_dev->image_format));\r\ndown_write(&rbd_dev->header_rwsem);\r\nmapping_size = rbd_dev->mapping.size;\r\nif (rbd_dev->image_format == 1)\r\nret = rbd_dev_v1_header_info(rbd_dev);\r\nelse\r\nret = rbd_dev_v2_header_info(rbd_dev);\r\nrbd_exists_validate(rbd_dev);\r\nup_write(&rbd_dev->header_rwsem);\r\nif (mapping_size != rbd_dev->mapping.size) {\r\nrbd_dev_update_size(rbd_dev);\r\n}\r\nreturn ret;\r\n}\r\nstatic int rbd_init_disk(struct rbd_device *rbd_dev)\r\n{\r\nstruct gendisk *disk;\r\nstruct request_queue *q;\r\nu64 segment_size;\r\ndisk = alloc_disk(RBD_MINORS_PER_MAJOR);\r\nif (!disk)\r\nreturn -ENOMEM;\r\nsnprintf(disk->disk_name, sizeof(disk->disk_name), RBD_DRV_NAME "%d",\r\nrbd_dev->dev_id);\r\ndisk->major = rbd_dev->major;\r\ndisk->first_minor = 0;\r\ndisk->fops = &rbd_bd_ops;\r\ndisk->private_data = rbd_dev;\r\nq = blk_init_queue(rbd_request_fn, &rbd_dev->lock);\r\nif (!q)\r\ngoto out_disk;\r\nblk_queue_physical_block_size(q, SECTOR_SIZE);\r\nsegment_size = rbd_obj_bytes(&rbd_dev->header);\r\nblk_queue_max_hw_sectors(q, segment_size / SECTOR_SIZE);\r\nblk_queue_max_segment_size(q, segment_size);\r\nblk_queue_io_min(q, segment_size);\r\nblk_queue_io_opt(q, segment_size);\r\nblk_queue_merge_bvec(q, rbd_merge_bvec);\r\ndisk->queue = q;\r\nq->queuedata = rbd_dev;\r\nrbd_dev->disk = disk;\r\nreturn 0;\r\nout_disk:\r\nput_disk(disk);\r\nreturn -ENOMEM;\r\n}\r\nstatic struct rbd_device *dev_to_rbd_dev(struct device *dev)\r\n{\r\nreturn container_of(dev, struct rbd_device, dev);\r\n}\r\nstatic ssize_t rbd_size_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nreturn sprintf(buf, "%llu\n",\r\n(unsigned long long)rbd_dev->mapping.size);\r\n}\r\nstatic ssize_t rbd_features_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nreturn sprintf(buf, "0x%016llx\n",\r\n(unsigned long long)rbd_dev->mapping.features);\r\n}\r\nstatic ssize_t rbd_major_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nif (rbd_dev->major)\r\nreturn sprintf(buf, "%d\n", rbd_dev->major);\r\nreturn sprintf(buf, "(none)\n");\r\n}\r\nstatic ssize_t rbd_client_id_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nreturn sprintf(buf, "client%lld\n",\r\nceph_client_id(rbd_dev->rbd_client->client));\r\n}\r\nstatic ssize_t rbd_pool_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nreturn sprintf(buf, "%s\n", rbd_dev->spec->pool_name);\r\n}\r\nstatic ssize_t rbd_pool_id_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nreturn sprintf(buf, "%llu\n",\r\n(unsigned long long) rbd_dev->spec->pool_id);\r\n}\r\nstatic ssize_t rbd_name_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nif (rbd_dev->spec->image_name)\r\nreturn sprintf(buf, "%s\n", rbd_dev->spec->image_name);\r\nreturn sprintf(buf, "(unknown)\n");\r\n}\r\nstatic ssize_t rbd_image_id_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nreturn sprintf(buf, "%s\n", rbd_dev->spec->image_id);\r\n}\r\nstatic ssize_t rbd_snap_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nreturn sprintf(buf, "%s\n", rbd_dev->spec->snap_name);\r\n}\r\nstatic ssize_t rbd_parent_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nstruct rbd_spec *spec = rbd_dev->parent_spec;\r\nint count;\r\nchar *bufp = buf;\r\nif (!spec)\r\nreturn sprintf(buf, "(no parent image)\n");\r\ncount = sprintf(bufp, "pool_id %llu\npool_name %s\n",\r\n(unsigned long long) spec->pool_id, spec->pool_name);\r\nif (count < 0)\r\nreturn count;\r\nbufp += count;\r\ncount = sprintf(bufp, "image_id %s\nimage_name %s\n", spec->image_id,\r\nspec->image_name ? spec->image_name : "(unknown)");\r\nif (count < 0)\r\nreturn count;\r\nbufp += count;\r\ncount = sprintf(bufp, "snap_id %llu\nsnap_name %s\n",\r\n(unsigned long long) spec->snap_id, spec->snap_name);\r\nif (count < 0)\r\nreturn count;\r\nbufp += count;\r\ncount = sprintf(bufp, "overlap %llu\n", rbd_dev->parent_overlap);\r\nif (count < 0)\r\nreturn count;\r\nbufp += count;\r\nreturn (ssize_t) (bufp - buf);\r\n}\r\nstatic ssize_t rbd_image_refresh(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t size)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nint ret;\r\nret = rbd_dev_refresh(rbd_dev);\r\nif (ret)\r\nrbd_warn(rbd_dev, ": manual header refresh error (%d)\n", ret);\r\nreturn ret < 0 ? ret : size;\r\n}\r\nstatic void rbd_sysfs_dev_release(struct device *dev)\r\n{\r\n}\r\nstatic struct rbd_spec *rbd_spec_get(struct rbd_spec *spec)\r\n{\r\nkref_get(&spec->kref);\r\nreturn spec;\r\n}\r\nstatic void rbd_spec_put(struct rbd_spec *spec)\r\n{\r\nif (spec)\r\nkref_put(&spec->kref, rbd_spec_free);\r\n}\r\nstatic struct rbd_spec *rbd_spec_alloc(void)\r\n{\r\nstruct rbd_spec *spec;\r\nspec = kzalloc(sizeof (*spec), GFP_KERNEL);\r\nif (!spec)\r\nreturn NULL;\r\nkref_init(&spec->kref);\r\nreturn spec;\r\n}\r\nstatic void rbd_spec_free(struct kref *kref)\r\n{\r\nstruct rbd_spec *spec = container_of(kref, struct rbd_spec, kref);\r\nkfree(spec->pool_name);\r\nkfree(spec->image_id);\r\nkfree(spec->image_name);\r\nkfree(spec->snap_name);\r\nkfree(spec);\r\n}\r\nstatic struct rbd_device *rbd_dev_create(struct rbd_client *rbdc,\r\nstruct rbd_spec *spec)\r\n{\r\nstruct rbd_device *rbd_dev;\r\nrbd_dev = kzalloc(sizeof (*rbd_dev), GFP_KERNEL);\r\nif (!rbd_dev)\r\nreturn NULL;\r\nspin_lock_init(&rbd_dev->lock);\r\nrbd_dev->flags = 0;\r\natomic_set(&rbd_dev->parent_ref, 0);\r\nINIT_LIST_HEAD(&rbd_dev->node);\r\ninit_rwsem(&rbd_dev->header_rwsem);\r\nrbd_dev->spec = spec;\r\nrbd_dev->rbd_client = rbdc;\r\nrbd_dev->layout.fl_stripe_unit = cpu_to_le32(1 << RBD_MAX_OBJ_ORDER);\r\nrbd_dev->layout.fl_stripe_count = cpu_to_le32(1);\r\nrbd_dev->layout.fl_object_size = cpu_to_le32(1 << RBD_MAX_OBJ_ORDER);\r\nrbd_dev->layout.fl_pg_pool = cpu_to_le32((u32) spec->pool_id);\r\nreturn rbd_dev;\r\n}\r\nstatic void rbd_dev_destroy(struct rbd_device *rbd_dev)\r\n{\r\nrbd_put_client(rbd_dev->rbd_client);\r\nrbd_spec_put(rbd_dev->spec);\r\nkfree(rbd_dev);\r\n}\r\nstatic int _rbd_dev_v2_snap_size(struct rbd_device *rbd_dev, u64 snap_id,\r\nu8 *order, u64 *snap_size)\r\n{\r\n__le64 snapid = cpu_to_le64(snap_id);\r\nint ret;\r\nstruct {\r\nu8 order;\r\n__le64 size;\r\n} __attribute__ ((packed)) size_buf = { 0 };\r\nret = rbd_obj_method_sync(rbd_dev, rbd_dev->header_name,\r\n"rbd", "get_size",\r\n&snapid, sizeof (snapid),\r\n&size_buf, sizeof (size_buf));\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret < 0)\r\nreturn ret;\r\nif (ret < sizeof (size_buf))\r\nreturn -ERANGE;\r\nif (order) {\r\n*order = size_buf.order;\r\ndout(" order %u", (unsigned int)*order);\r\n}\r\n*snap_size = le64_to_cpu(size_buf.size);\r\ndout(" snap_id 0x%016llx snap_size = %llu\n",\r\n(unsigned long long)snap_id,\r\n(unsigned long long)*snap_size);\r\nreturn 0;\r\n}\r\nstatic int rbd_dev_v2_image_size(struct rbd_device *rbd_dev)\r\n{\r\nreturn _rbd_dev_v2_snap_size(rbd_dev, CEPH_NOSNAP,\r\n&rbd_dev->header.obj_order,\r\n&rbd_dev->header.image_size);\r\n}\r\nstatic int rbd_dev_v2_object_prefix(struct rbd_device *rbd_dev)\r\n{\r\nvoid *reply_buf;\r\nint ret;\r\nvoid *p;\r\nreply_buf = kzalloc(RBD_OBJ_PREFIX_LEN_MAX, GFP_KERNEL);\r\nif (!reply_buf)\r\nreturn -ENOMEM;\r\nret = rbd_obj_method_sync(rbd_dev, rbd_dev->header_name,\r\n"rbd", "get_object_prefix", NULL, 0,\r\nreply_buf, RBD_OBJ_PREFIX_LEN_MAX);\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret < 0)\r\ngoto out;\r\np = reply_buf;\r\nrbd_dev->header.object_prefix = ceph_extract_encoded_string(&p,\r\np + ret, NULL, GFP_NOIO);\r\nret = 0;\r\nif (IS_ERR(rbd_dev->header.object_prefix)) {\r\nret = PTR_ERR(rbd_dev->header.object_prefix);\r\nrbd_dev->header.object_prefix = NULL;\r\n} else {\r\ndout(" object_prefix = %s\n", rbd_dev->header.object_prefix);\r\n}\r\nout:\r\nkfree(reply_buf);\r\nreturn ret;\r\n}\r\nstatic int _rbd_dev_v2_snap_features(struct rbd_device *rbd_dev, u64 snap_id,\r\nu64 *snap_features)\r\n{\r\n__le64 snapid = cpu_to_le64(snap_id);\r\nstruct {\r\n__le64 features;\r\n__le64 incompat;\r\n} __attribute__ ((packed)) features_buf = { 0 };\r\nu64 incompat;\r\nint ret;\r\nret = rbd_obj_method_sync(rbd_dev, rbd_dev->header_name,\r\n"rbd", "get_features",\r\n&snapid, sizeof (snapid),\r\n&features_buf, sizeof (features_buf));\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret < 0)\r\nreturn ret;\r\nif (ret < sizeof (features_buf))\r\nreturn -ERANGE;\r\nincompat = le64_to_cpu(features_buf.incompat);\r\nif (incompat & ~RBD_FEATURES_SUPPORTED)\r\nreturn -ENXIO;\r\n*snap_features = le64_to_cpu(features_buf.features);\r\ndout(" snap_id 0x%016llx features = 0x%016llx incompat = 0x%016llx\n",\r\n(unsigned long long)snap_id,\r\n(unsigned long long)*snap_features,\r\n(unsigned long long)le64_to_cpu(features_buf.incompat));\r\nreturn 0;\r\n}\r\nstatic int rbd_dev_v2_features(struct rbd_device *rbd_dev)\r\n{\r\nreturn _rbd_dev_v2_snap_features(rbd_dev, CEPH_NOSNAP,\r\n&rbd_dev->header.features);\r\n}\r\nstatic int rbd_dev_v2_parent_info(struct rbd_device *rbd_dev)\r\n{\r\nstruct rbd_spec *parent_spec;\r\nsize_t size;\r\nvoid *reply_buf = NULL;\r\n__le64 snapid;\r\nvoid *p;\r\nvoid *end;\r\nu64 pool_id;\r\nchar *image_id;\r\nu64 snap_id;\r\nu64 overlap;\r\nint ret;\r\nparent_spec = rbd_spec_alloc();\r\nif (!parent_spec)\r\nreturn -ENOMEM;\r\nsize = sizeof (__le64) +\r\nsizeof (__le32) + RBD_IMAGE_ID_LEN_MAX +\r\nsizeof (__le64) +\r\nsizeof (__le64);\r\nreply_buf = kmalloc(size, GFP_KERNEL);\r\nif (!reply_buf) {\r\nret = -ENOMEM;\r\ngoto out_err;\r\n}\r\nsnapid = cpu_to_le64(CEPH_NOSNAP);\r\nret = rbd_obj_method_sync(rbd_dev, rbd_dev->header_name,\r\n"rbd", "get_parent",\r\n&snapid, sizeof (snapid),\r\nreply_buf, size);\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret < 0)\r\ngoto out_err;\r\np = reply_buf;\r\nend = reply_buf + ret;\r\nret = -ERANGE;\r\nceph_decode_64_safe(&p, end, pool_id, out_err);\r\nif (pool_id == CEPH_NOPOOL) {\r\nif (rbd_dev->parent_overlap) {\r\nrbd_dev->parent_overlap = 0;\r\nsmp_mb();\r\nrbd_dev_parent_put(rbd_dev);\r\npr_info("%s: clone image has been flattened\n",\r\nrbd_dev->disk->disk_name);\r\n}\r\ngoto out;\r\n}\r\nret = -EIO;\r\nif (pool_id > (u64)U32_MAX) {\r\nrbd_warn(NULL, "parent pool id too large (%llu > %u)\n",\r\n(unsigned long long)pool_id, U32_MAX);\r\ngoto out_err;\r\n}\r\nimage_id = ceph_extract_encoded_string(&p, end, NULL, GFP_KERNEL);\r\nif (IS_ERR(image_id)) {\r\nret = PTR_ERR(image_id);\r\ngoto out_err;\r\n}\r\nceph_decode_64_safe(&p, end, snap_id, out_err);\r\nceph_decode_64_safe(&p, end, overlap, out_err);\r\nif (!rbd_dev->parent_spec) {\r\nparent_spec->pool_id = pool_id;\r\nparent_spec->image_id = image_id;\r\nparent_spec->snap_id = snap_id;\r\nrbd_dev->parent_spec = parent_spec;\r\nparent_spec = NULL;\r\n}\r\nrbd_dev->parent_overlap = overlap;\r\nsmp_mb();\r\nif (!overlap) {\r\nif (parent_spec) {\r\nrbd_dev_parent_put(rbd_dev);\r\npr_info("%s: clone image now standalone\n",\r\nrbd_dev->disk->disk_name);\r\n} else {\r\nrbd_warn(rbd_dev, "ignoring parent of "\r\n"clone with overlap 0\n");\r\n}\r\n}\r\nout:\r\nret = 0;\r\nout_err:\r\nkfree(reply_buf);\r\nrbd_spec_put(parent_spec);\r\nreturn ret;\r\n}\r\nstatic int rbd_dev_v2_striping_info(struct rbd_device *rbd_dev)\r\n{\r\nstruct {\r\n__le64 stripe_unit;\r\n__le64 stripe_count;\r\n} __attribute__ ((packed)) striping_info_buf = { 0 };\r\nsize_t size = sizeof (striping_info_buf);\r\nvoid *p;\r\nu64 obj_size;\r\nu64 stripe_unit;\r\nu64 stripe_count;\r\nint ret;\r\nret = rbd_obj_method_sync(rbd_dev, rbd_dev->header_name,\r\n"rbd", "get_stripe_unit_count", NULL, 0,\r\n(char *)&striping_info_buf, size);\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret < 0)\r\nreturn ret;\r\nif (ret < size)\r\nreturn -ERANGE;\r\nret = -EINVAL;\r\nobj_size = (u64)1 << rbd_dev->header.obj_order;\r\np = &striping_info_buf;\r\nstripe_unit = ceph_decode_64(&p);\r\nif (stripe_unit != obj_size) {\r\nrbd_warn(rbd_dev, "unsupported stripe unit "\r\n"(got %llu want %llu)",\r\nstripe_unit, obj_size);\r\nreturn -EINVAL;\r\n}\r\nstripe_count = ceph_decode_64(&p);\r\nif (stripe_count != 1) {\r\nrbd_warn(rbd_dev, "unsupported stripe count "\r\n"(got %llu want 1)", stripe_count);\r\nreturn -EINVAL;\r\n}\r\nrbd_dev->header.stripe_unit = stripe_unit;\r\nrbd_dev->header.stripe_count = stripe_count;\r\nreturn 0;\r\n}\r\nstatic char *rbd_dev_image_name(struct rbd_device *rbd_dev)\r\n{\r\nsize_t image_id_size;\r\nchar *image_id;\r\nvoid *p;\r\nvoid *end;\r\nsize_t size;\r\nvoid *reply_buf = NULL;\r\nsize_t len = 0;\r\nchar *image_name = NULL;\r\nint ret;\r\nrbd_assert(!rbd_dev->spec->image_name);\r\nlen = strlen(rbd_dev->spec->image_id);\r\nimage_id_size = sizeof (__le32) + len;\r\nimage_id = kmalloc(image_id_size, GFP_KERNEL);\r\nif (!image_id)\r\nreturn NULL;\r\np = image_id;\r\nend = image_id + image_id_size;\r\nceph_encode_string(&p, end, rbd_dev->spec->image_id, (u32)len);\r\nsize = sizeof (__le32) + RBD_IMAGE_NAME_LEN_MAX;\r\nreply_buf = kmalloc(size, GFP_KERNEL);\r\nif (!reply_buf)\r\ngoto out;\r\nret = rbd_obj_method_sync(rbd_dev, RBD_DIRECTORY,\r\n"rbd", "dir_get_name",\r\nimage_id, image_id_size,\r\nreply_buf, size);\r\nif (ret < 0)\r\ngoto out;\r\np = reply_buf;\r\nend = reply_buf + ret;\r\nimage_name = ceph_extract_encoded_string(&p, end, &len, GFP_KERNEL);\r\nif (IS_ERR(image_name))\r\nimage_name = NULL;\r\nelse\r\ndout("%s: name is %s len is %zd\n", __func__, image_name, len);\r\nout:\r\nkfree(reply_buf);\r\nkfree(image_id);\r\nreturn image_name;\r\n}\r\nstatic u64 rbd_v1_snap_id_by_name(struct rbd_device *rbd_dev, const char *name)\r\n{\r\nstruct ceph_snap_context *snapc = rbd_dev->header.snapc;\r\nconst char *snap_name;\r\nu32 which = 0;\r\nsnap_name = rbd_dev->header.snap_names;\r\nwhile (which < snapc->num_snaps) {\r\nif (!strcmp(name, snap_name))\r\nreturn snapc->snaps[which];\r\nsnap_name += strlen(snap_name) + 1;\r\nwhich++;\r\n}\r\nreturn CEPH_NOSNAP;\r\n}\r\nstatic u64 rbd_v2_snap_id_by_name(struct rbd_device *rbd_dev, const char *name)\r\n{\r\nstruct ceph_snap_context *snapc = rbd_dev->header.snapc;\r\nu32 which;\r\nbool found = false;\r\nu64 snap_id;\r\nfor (which = 0; !found && which < snapc->num_snaps; which++) {\r\nconst char *snap_name;\r\nsnap_id = snapc->snaps[which];\r\nsnap_name = rbd_dev_v2_snap_name(rbd_dev, snap_id);\r\nif (IS_ERR(snap_name)) {\r\nif (PTR_ERR(snap_name) == -ENOENT)\r\ncontinue;\r\nelse\r\nbreak;\r\n}\r\nfound = !strcmp(name, snap_name);\r\nkfree(snap_name);\r\n}\r\nreturn found ? snap_id : CEPH_NOSNAP;\r\n}\r\nstatic u64 rbd_snap_id_by_name(struct rbd_device *rbd_dev, const char *name)\r\n{\r\nif (rbd_dev->image_format == 1)\r\nreturn rbd_v1_snap_id_by_name(rbd_dev, name);\r\nreturn rbd_v2_snap_id_by_name(rbd_dev, name);\r\n}\r\nstatic int rbd_dev_spec_update(struct rbd_device *rbd_dev)\r\n{\r\nstruct ceph_osd_client *osdc = &rbd_dev->rbd_client->client->osdc;\r\nstruct rbd_spec *spec = rbd_dev->spec;\r\nconst char *pool_name;\r\nconst char *image_name;\r\nconst char *snap_name;\r\nint ret;\r\nif (spec->pool_name) {\r\nif (strcmp(spec->snap_name, RBD_SNAP_HEAD_NAME)) {\r\nu64 snap_id;\r\nsnap_id = rbd_snap_id_by_name(rbd_dev, spec->snap_name);\r\nif (snap_id == CEPH_NOSNAP)\r\nreturn -ENOENT;\r\nspec->snap_id = snap_id;\r\n} else {\r\nspec->snap_id = CEPH_NOSNAP;\r\n}\r\nreturn 0;\r\n}\r\npool_name = ceph_pg_pool_name_by_id(osdc->osdmap, spec->pool_id);\r\nif (!pool_name) {\r\nrbd_warn(rbd_dev, "no pool with id %llu", spec->pool_id);\r\nreturn -EIO;\r\n}\r\npool_name = kstrdup(pool_name, GFP_KERNEL);\r\nif (!pool_name)\r\nreturn -ENOMEM;\r\nimage_name = rbd_dev_image_name(rbd_dev);\r\nif (!image_name)\r\nrbd_warn(rbd_dev, "unable to get image name");\r\nsnap_name = rbd_snap_name(rbd_dev, spec->snap_id);\r\nif (IS_ERR(snap_name)) {\r\nret = PTR_ERR(snap_name);\r\ngoto out_err;\r\n}\r\nspec->pool_name = pool_name;\r\nspec->image_name = image_name;\r\nspec->snap_name = snap_name;\r\nreturn 0;\r\nout_err:\r\nkfree(image_name);\r\nkfree(pool_name);\r\nreturn ret;\r\n}\r\nstatic int rbd_dev_v2_snap_context(struct rbd_device *rbd_dev)\r\n{\r\nsize_t size;\r\nint ret;\r\nvoid *reply_buf;\r\nvoid *p;\r\nvoid *end;\r\nu64 seq;\r\nu32 snap_count;\r\nstruct ceph_snap_context *snapc;\r\nu32 i;\r\nsize = sizeof (__le64) + sizeof (__le32) +\r\nRBD_MAX_SNAP_COUNT * sizeof (__le64);\r\nreply_buf = kzalloc(size, GFP_KERNEL);\r\nif (!reply_buf)\r\nreturn -ENOMEM;\r\nret = rbd_obj_method_sync(rbd_dev, rbd_dev->header_name,\r\n"rbd", "get_snapcontext", NULL, 0,\r\nreply_buf, size);\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret < 0)\r\ngoto out;\r\np = reply_buf;\r\nend = reply_buf + ret;\r\nret = -ERANGE;\r\nceph_decode_64_safe(&p, end, seq, out);\r\nceph_decode_32_safe(&p, end, snap_count, out);\r\nif (snap_count > (SIZE_MAX - sizeof (struct ceph_snap_context))\r\n/ sizeof (u64)) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nif (!ceph_has_room(&p, end, snap_count * sizeof (__le64)))\r\ngoto out;\r\nret = 0;\r\nsnapc = ceph_create_snap_context(snap_count, GFP_KERNEL);\r\nif (!snapc) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nsnapc->seq = seq;\r\nfor (i = 0; i < snap_count; i++)\r\nsnapc->snaps[i] = ceph_decode_64(&p);\r\nceph_put_snap_context(rbd_dev->header.snapc);\r\nrbd_dev->header.snapc = snapc;\r\ndout(" snap context seq = %llu, snap_count = %u\n",\r\n(unsigned long long)seq, (unsigned int)snap_count);\r\nout:\r\nkfree(reply_buf);\r\nreturn ret;\r\n}\r\nstatic const char *rbd_dev_v2_snap_name(struct rbd_device *rbd_dev,\r\nu64 snap_id)\r\n{\r\nsize_t size;\r\nvoid *reply_buf;\r\n__le64 snapid;\r\nint ret;\r\nvoid *p;\r\nvoid *end;\r\nchar *snap_name;\r\nsize = sizeof (__le32) + RBD_MAX_SNAP_NAME_LEN;\r\nreply_buf = kmalloc(size, GFP_KERNEL);\r\nif (!reply_buf)\r\nreturn ERR_PTR(-ENOMEM);\r\nsnapid = cpu_to_le64(snap_id);\r\nret = rbd_obj_method_sync(rbd_dev, rbd_dev->header_name,\r\n"rbd", "get_snapshot_name",\r\n&snapid, sizeof (snapid),\r\nreply_buf, size);\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret < 0) {\r\nsnap_name = ERR_PTR(ret);\r\ngoto out;\r\n}\r\np = reply_buf;\r\nend = reply_buf + ret;\r\nsnap_name = ceph_extract_encoded_string(&p, end, NULL, GFP_KERNEL);\r\nif (IS_ERR(snap_name))\r\ngoto out;\r\ndout(" snap_id 0x%016llx snap_name = %s\n",\r\n(unsigned long long)snap_id, snap_name);\r\nout:\r\nkfree(reply_buf);\r\nreturn snap_name;\r\n}\r\nstatic int rbd_dev_v2_header_info(struct rbd_device *rbd_dev)\r\n{\r\nbool first_time = rbd_dev->header.object_prefix == NULL;\r\nint ret;\r\nret = rbd_dev_v2_image_size(rbd_dev);\r\nif (ret)\r\nreturn ret;\r\nif (first_time) {\r\nret = rbd_dev_v2_header_onetime(rbd_dev);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (rbd_dev->header.features & RBD_FEATURE_LAYERING &&\r\n(first_time || rbd_dev->parent_spec)) {\r\nbool warn;\r\nret = rbd_dev_v2_parent_info(rbd_dev);\r\nif (ret)\r\nreturn ret;\r\nwarn = rbd_dev->parent_spec && rbd_dev->spec->pool_name;\r\nif (first_time && warn)\r\nrbd_warn(rbd_dev, "WARNING: kernel layering "\r\n"is EXPERIMENTAL!");\r\n}\r\nif (rbd_dev->spec->snap_id == CEPH_NOSNAP)\r\nif (rbd_dev->mapping.size != rbd_dev->header.image_size)\r\nrbd_dev->mapping.size = rbd_dev->header.image_size;\r\nret = rbd_dev_v2_snap_context(rbd_dev);\r\ndout("rbd_dev_v2_snap_context returned %d\n", ret);\r\nreturn ret;\r\n}\r\nstatic int rbd_bus_add_dev(struct rbd_device *rbd_dev)\r\n{\r\nstruct device *dev;\r\nint ret;\r\ndev = &rbd_dev->dev;\r\ndev->bus = &rbd_bus_type;\r\ndev->type = &rbd_device_type;\r\ndev->parent = &rbd_root_dev;\r\ndev->release = rbd_dev_device_release;\r\ndev_set_name(dev, "%d", rbd_dev->dev_id);\r\nret = device_register(dev);\r\nreturn ret;\r\n}\r\nstatic void rbd_bus_del_dev(struct rbd_device *rbd_dev)\r\n{\r\ndevice_unregister(&rbd_dev->dev);\r\n}\r\nstatic void rbd_dev_id_get(struct rbd_device *rbd_dev)\r\n{\r\nrbd_dev->dev_id = atomic64_inc_return(&rbd_dev_id_max);\r\nspin_lock(&rbd_dev_list_lock);\r\nlist_add_tail(&rbd_dev->node, &rbd_dev_list);\r\nspin_unlock(&rbd_dev_list_lock);\r\ndout("rbd_dev %p given dev id %llu\n", rbd_dev,\r\n(unsigned long long) rbd_dev->dev_id);\r\n}\r\nstatic void rbd_dev_id_put(struct rbd_device *rbd_dev)\r\n{\r\nstruct list_head *tmp;\r\nint rbd_id = rbd_dev->dev_id;\r\nint max_id;\r\nrbd_assert(rbd_id > 0);\r\ndout("rbd_dev %p released dev id %llu\n", rbd_dev,\r\n(unsigned long long) rbd_dev->dev_id);\r\nspin_lock(&rbd_dev_list_lock);\r\nlist_del_init(&rbd_dev->node);\r\nif (rbd_id != atomic64_read(&rbd_dev_id_max)) {\r\nspin_unlock(&rbd_dev_list_lock);\r\nreturn;\r\n}\r\nmax_id = 0;\r\nlist_for_each_prev(tmp, &rbd_dev_list) {\r\nstruct rbd_device *rbd_dev;\r\nrbd_dev = list_entry(tmp, struct rbd_device, node);\r\nif (rbd_dev->dev_id > max_id)\r\nmax_id = rbd_dev->dev_id;\r\n}\r\nspin_unlock(&rbd_dev_list_lock);\r\natomic64_cmpxchg(&rbd_dev_id_max, rbd_id, max_id);\r\ndout(" max dev id has been reset\n");\r\n}\r\nstatic inline size_t next_token(const char **buf)\r\n{\r\nconst char *spaces = " \f\n\r\t\v";\r\n*buf += strspn(*buf, spaces);\r\nreturn strcspn(*buf, spaces);\r\n}\r\nstatic inline size_t copy_token(const char **buf,\r\nchar *token,\r\nsize_t token_size)\r\n{\r\nsize_t len;\r\nlen = next_token(buf);\r\nif (len < token_size) {\r\nmemcpy(token, *buf, len);\r\n*(token + len) = '\0';\r\n}\r\n*buf += len;\r\nreturn len;\r\n}\r\nstatic inline char *dup_token(const char **buf, size_t *lenp)\r\n{\r\nchar *dup;\r\nsize_t len;\r\nlen = next_token(buf);\r\ndup = kmemdup(*buf, len + 1, GFP_KERNEL);\r\nif (!dup)\r\nreturn NULL;\r\n*(dup + len) = '\0';\r\n*buf += len;\r\nif (lenp)\r\n*lenp = len;\r\nreturn dup;\r\n}\r\nstatic int rbd_add_parse_args(const char *buf,\r\nstruct ceph_options **ceph_opts,\r\nstruct rbd_options **opts,\r\nstruct rbd_spec **rbd_spec)\r\n{\r\nsize_t len;\r\nchar *options;\r\nconst char *mon_addrs;\r\nchar *snap_name;\r\nsize_t mon_addrs_size;\r\nstruct rbd_spec *spec = NULL;\r\nstruct rbd_options *rbd_opts = NULL;\r\nstruct ceph_options *copts;\r\nint ret;\r\nlen = next_token(&buf);\r\nif (!len) {\r\nrbd_warn(NULL, "no monitor address(es) provided");\r\nreturn -EINVAL;\r\n}\r\nmon_addrs = buf;\r\nmon_addrs_size = len + 1;\r\nbuf += len;\r\nret = -EINVAL;\r\noptions = dup_token(&buf, NULL);\r\nif (!options)\r\nreturn -ENOMEM;\r\nif (!*options) {\r\nrbd_warn(NULL, "no options provided");\r\ngoto out_err;\r\n}\r\nspec = rbd_spec_alloc();\r\nif (!spec)\r\ngoto out_mem;\r\nspec->pool_name = dup_token(&buf, NULL);\r\nif (!spec->pool_name)\r\ngoto out_mem;\r\nif (!*spec->pool_name) {\r\nrbd_warn(NULL, "no pool name provided");\r\ngoto out_err;\r\n}\r\nspec->image_name = dup_token(&buf, NULL);\r\nif (!spec->image_name)\r\ngoto out_mem;\r\nif (!*spec->image_name) {\r\nrbd_warn(NULL, "no image name provided");\r\ngoto out_err;\r\n}\r\nlen = next_token(&buf);\r\nif (!len) {\r\nbuf = RBD_SNAP_HEAD_NAME;\r\nlen = sizeof (RBD_SNAP_HEAD_NAME) - 1;\r\n} else if (len > RBD_MAX_SNAP_NAME_LEN) {\r\nret = -ENAMETOOLONG;\r\ngoto out_err;\r\n}\r\nsnap_name = kmemdup(buf, len + 1, GFP_KERNEL);\r\nif (!snap_name)\r\ngoto out_mem;\r\n*(snap_name + len) = '\0';\r\nspec->snap_name = snap_name;\r\nrbd_opts = kzalloc(sizeof (*rbd_opts), GFP_KERNEL);\r\nif (!rbd_opts)\r\ngoto out_mem;\r\nrbd_opts->read_only = RBD_READ_ONLY_DEFAULT;\r\ncopts = ceph_parse_options(options, mon_addrs,\r\nmon_addrs + mon_addrs_size - 1,\r\nparse_rbd_opts_token, rbd_opts);\r\nif (IS_ERR(copts)) {\r\nret = PTR_ERR(copts);\r\ngoto out_err;\r\n}\r\nkfree(options);\r\n*ceph_opts = copts;\r\n*opts = rbd_opts;\r\n*rbd_spec = spec;\r\nreturn 0;\r\nout_mem:\r\nret = -ENOMEM;\r\nout_err:\r\nkfree(rbd_opts);\r\nrbd_spec_put(spec);\r\nkfree(options);\r\nreturn ret;\r\n}\r\nstatic int rbd_dev_image_id(struct rbd_device *rbd_dev)\r\n{\r\nint ret;\r\nsize_t size;\r\nchar *object_name;\r\nvoid *response;\r\nchar *image_id;\r\nif (rbd_dev->spec->image_id) {\r\nrbd_dev->image_format = *rbd_dev->spec->image_id ? 2 : 1;\r\nreturn 0;\r\n}\r\nsize = sizeof (RBD_ID_PREFIX) + strlen(rbd_dev->spec->image_name);\r\nobject_name = kmalloc(size, GFP_NOIO);\r\nif (!object_name)\r\nreturn -ENOMEM;\r\nsprintf(object_name, "%s%s", RBD_ID_PREFIX, rbd_dev->spec->image_name);\r\ndout("rbd id object name is %s\n", object_name);\r\nsize = sizeof (__le32) + RBD_IMAGE_ID_LEN_MAX;\r\nresponse = kzalloc(size, GFP_NOIO);\r\nif (!response) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nret = rbd_obj_method_sync(rbd_dev, object_name,\r\n"rbd", "get_id", NULL, 0,\r\nresponse, RBD_IMAGE_ID_LEN_MAX);\r\ndout("%s: rbd_obj_method_sync returned %d\n", __func__, ret);\r\nif (ret == -ENOENT) {\r\nimage_id = kstrdup("", GFP_KERNEL);\r\nret = image_id ? 0 : -ENOMEM;\r\nif (!ret)\r\nrbd_dev->image_format = 1;\r\n} else if (ret > sizeof (__le32)) {\r\nvoid *p = response;\r\nimage_id = ceph_extract_encoded_string(&p, p + ret,\r\nNULL, GFP_NOIO);\r\nret = IS_ERR(image_id) ? PTR_ERR(image_id) : 0;\r\nif (!ret)\r\nrbd_dev->image_format = 2;\r\n} else {\r\nret = -EINVAL;\r\n}\r\nif (!ret) {\r\nrbd_dev->spec->image_id = image_id;\r\ndout("image_id is %s\n", image_id);\r\n}\r\nout:\r\nkfree(response);\r\nkfree(object_name);\r\nreturn ret;\r\n}\r\nstatic void rbd_dev_unprobe(struct rbd_device *rbd_dev)\r\n{\r\nstruct rbd_image_header *header;\r\nif (rbd_dev->parent_overlap)\r\nrbd_dev_parent_put(rbd_dev);\r\nheader = &rbd_dev->header;\r\nceph_put_snap_context(header->snapc);\r\nkfree(header->snap_sizes);\r\nkfree(header->snap_names);\r\nkfree(header->object_prefix);\r\nmemset(header, 0, sizeof (*header));\r\n}\r\nstatic int rbd_dev_v2_header_onetime(struct rbd_device *rbd_dev)\r\n{\r\nint ret;\r\nret = rbd_dev_v2_object_prefix(rbd_dev);\r\nif (ret)\r\ngoto out_err;\r\nret = rbd_dev_v2_features(rbd_dev);\r\nif (ret)\r\ngoto out_err;\r\nif (rbd_dev->header.features & RBD_FEATURE_STRIPINGV2) {\r\nret = rbd_dev_v2_striping_info(rbd_dev);\r\nif (ret < 0)\r\ngoto out_err;\r\n}\r\nreturn 0;\r\nout_err:\r\nrbd_dev->header.features = 0;\r\nkfree(rbd_dev->header.object_prefix);\r\nrbd_dev->header.object_prefix = NULL;\r\nreturn ret;\r\n}\r\nstatic int rbd_dev_probe_parent(struct rbd_device *rbd_dev)\r\n{\r\nstruct rbd_device *parent = NULL;\r\nstruct rbd_spec *parent_spec;\r\nstruct rbd_client *rbdc;\r\nint ret;\r\nif (!rbd_dev->parent_spec)\r\nreturn 0;\r\nparent_spec = rbd_spec_get(rbd_dev->parent_spec);\r\nrbdc = __rbd_get_client(rbd_dev->rbd_client);\r\nret = -ENOMEM;\r\nparent = rbd_dev_create(rbdc, parent_spec);\r\nif (!parent)\r\ngoto out_err;\r\nret = rbd_dev_image_probe(parent, false);\r\nif (ret < 0)\r\ngoto out_err;\r\nrbd_dev->parent = parent;\r\natomic_set(&rbd_dev->parent_ref, 1);\r\nreturn 0;\r\nout_err:\r\nif (parent) {\r\nrbd_dev_unparent(rbd_dev);\r\nkfree(rbd_dev->header_name);\r\nrbd_dev_destroy(parent);\r\n} else {\r\nrbd_put_client(rbdc);\r\nrbd_spec_put(parent_spec);\r\n}\r\nreturn ret;\r\n}\r\nstatic int rbd_dev_device_setup(struct rbd_device *rbd_dev)\r\n{\r\nint ret;\r\nrbd_dev_id_get(rbd_dev);\r\nBUILD_BUG_ON(DEV_NAME_LEN\r\n< sizeof (RBD_DRV_NAME) + MAX_INT_FORMAT_WIDTH);\r\nsprintf(rbd_dev->name, "%s%d", RBD_DRV_NAME, rbd_dev->dev_id);\r\nret = register_blkdev(0, rbd_dev->name);\r\nif (ret < 0)\r\ngoto err_out_id;\r\nrbd_dev->major = ret;\r\nret = rbd_init_disk(rbd_dev);\r\nif (ret)\r\ngoto err_out_blkdev;\r\nret = rbd_dev_mapping_set(rbd_dev);\r\nif (ret)\r\ngoto err_out_disk;\r\nset_capacity(rbd_dev->disk, rbd_dev->mapping.size / SECTOR_SIZE);\r\nret = rbd_bus_add_dev(rbd_dev);\r\nif (ret)\r\ngoto err_out_mapping;\r\nset_bit(RBD_DEV_FLAG_EXISTS, &rbd_dev->flags);\r\nadd_disk(rbd_dev->disk);\r\npr_info("%s: added with size 0x%llx\n", rbd_dev->disk->disk_name,\r\n(unsigned long long) rbd_dev->mapping.size);\r\nreturn ret;\r\nerr_out_mapping:\r\nrbd_dev_mapping_clear(rbd_dev);\r\nerr_out_disk:\r\nrbd_free_disk(rbd_dev);\r\nerr_out_blkdev:\r\nunregister_blkdev(rbd_dev->major, rbd_dev->name);\r\nerr_out_id:\r\nrbd_dev_id_put(rbd_dev);\r\nrbd_dev_mapping_clear(rbd_dev);\r\nreturn ret;\r\n}\r\nstatic int rbd_dev_header_name(struct rbd_device *rbd_dev)\r\n{\r\nstruct rbd_spec *spec = rbd_dev->spec;\r\nsize_t size;\r\nrbd_assert(rbd_image_format_valid(rbd_dev->image_format));\r\nif (rbd_dev->image_format == 1)\r\nsize = strlen(spec->image_name) + sizeof (RBD_SUFFIX);\r\nelse\r\nsize = sizeof (RBD_HEADER_PREFIX) + strlen(spec->image_id);\r\nrbd_dev->header_name = kmalloc(size, GFP_KERNEL);\r\nif (!rbd_dev->header_name)\r\nreturn -ENOMEM;\r\nif (rbd_dev->image_format == 1)\r\nsprintf(rbd_dev->header_name, "%s%s",\r\nspec->image_name, RBD_SUFFIX);\r\nelse\r\nsprintf(rbd_dev->header_name, "%s%s",\r\nRBD_HEADER_PREFIX, spec->image_id);\r\nreturn 0;\r\n}\r\nstatic void rbd_dev_image_release(struct rbd_device *rbd_dev)\r\n{\r\nrbd_dev_unprobe(rbd_dev);\r\nkfree(rbd_dev->header_name);\r\nrbd_dev->header_name = NULL;\r\nrbd_dev->image_format = 0;\r\nkfree(rbd_dev->spec->image_id);\r\nrbd_dev->spec->image_id = NULL;\r\nrbd_dev_destroy(rbd_dev);\r\n}\r\nstatic int rbd_dev_image_probe(struct rbd_device *rbd_dev, bool mapping)\r\n{\r\nint ret;\r\nint tmp;\r\nret = rbd_dev_image_id(rbd_dev);\r\nif (ret)\r\nreturn ret;\r\nrbd_assert(rbd_dev->spec->image_id);\r\nrbd_assert(rbd_image_format_valid(rbd_dev->image_format));\r\nret = rbd_dev_header_name(rbd_dev);\r\nif (ret)\r\ngoto err_out_format;\r\nif (mapping) {\r\nret = rbd_dev_header_watch_sync(rbd_dev, true);\r\nif (ret)\r\ngoto out_header_name;\r\n}\r\nif (rbd_dev->image_format == 1)\r\nret = rbd_dev_v1_header_info(rbd_dev);\r\nelse\r\nret = rbd_dev_v2_header_info(rbd_dev);\r\nif (ret)\r\ngoto err_out_watch;\r\nret = rbd_dev_spec_update(rbd_dev);\r\nif (ret)\r\ngoto err_out_probe;\r\nret = rbd_dev_probe_parent(rbd_dev);\r\nif (ret)\r\ngoto err_out_probe;\r\ndout("discovered format %u image, header name is %s\n",\r\nrbd_dev->image_format, rbd_dev->header_name);\r\nreturn 0;\r\nerr_out_probe:\r\nrbd_dev_unprobe(rbd_dev);\r\nerr_out_watch:\r\nif (mapping) {\r\ntmp = rbd_dev_header_watch_sync(rbd_dev, false);\r\nif (tmp)\r\nrbd_warn(rbd_dev, "unable to tear down "\r\n"watch request (%d)\n", tmp);\r\n}\r\nout_header_name:\r\nkfree(rbd_dev->header_name);\r\nrbd_dev->header_name = NULL;\r\nerr_out_format:\r\nrbd_dev->image_format = 0;\r\nkfree(rbd_dev->spec->image_id);\r\nrbd_dev->spec->image_id = NULL;\r\ndout("probe failed, returning %d\n", ret);\r\nreturn ret;\r\n}\r\nstatic ssize_t rbd_add(struct bus_type *bus,\r\nconst char *buf,\r\nsize_t count)\r\n{\r\nstruct rbd_device *rbd_dev = NULL;\r\nstruct ceph_options *ceph_opts = NULL;\r\nstruct rbd_options *rbd_opts = NULL;\r\nstruct rbd_spec *spec = NULL;\r\nstruct rbd_client *rbdc;\r\nstruct ceph_osd_client *osdc;\r\nbool read_only;\r\nint rc = -ENOMEM;\r\nif (!try_module_get(THIS_MODULE))\r\nreturn -ENODEV;\r\nrc = rbd_add_parse_args(buf, &ceph_opts, &rbd_opts, &spec);\r\nif (rc < 0)\r\ngoto err_out_module;\r\nread_only = rbd_opts->read_only;\r\nkfree(rbd_opts);\r\nrbd_opts = NULL;\r\nrbdc = rbd_get_client(ceph_opts);\r\nif (IS_ERR(rbdc)) {\r\nrc = PTR_ERR(rbdc);\r\ngoto err_out_args;\r\n}\r\nosdc = &rbdc->client->osdc;\r\nrc = ceph_pg_poolid_by_name(osdc->osdmap, spec->pool_name);\r\nif (rc < 0)\r\ngoto err_out_client;\r\nspec->pool_id = (u64)rc;\r\nif (spec->pool_id > (u64)U32_MAX) {\r\nrbd_warn(NULL, "pool id too large (%llu > %u)\n",\r\n(unsigned long long)spec->pool_id, U32_MAX);\r\nrc = -EIO;\r\ngoto err_out_client;\r\n}\r\nrbd_dev = rbd_dev_create(rbdc, spec);\r\nif (!rbd_dev)\r\ngoto err_out_client;\r\nrbdc = NULL;\r\nspec = NULL;\r\nrc = rbd_dev_image_probe(rbd_dev, true);\r\nif (rc < 0)\r\ngoto err_out_rbd_dev;\r\nif (rbd_dev->spec->snap_id != CEPH_NOSNAP)\r\nread_only = true;\r\nrbd_dev->mapping.read_only = read_only;\r\nrc = rbd_dev_device_setup(rbd_dev);\r\nif (rc) {\r\nrbd_dev_image_release(rbd_dev);\r\ngoto err_out_module;\r\n}\r\nreturn count;\r\nerr_out_rbd_dev:\r\nrbd_dev_destroy(rbd_dev);\r\nerr_out_client:\r\nrbd_put_client(rbdc);\r\nerr_out_args:\r\nrbd_spec_put(spec);\r\nerr_out_module:\r\nmodule_put(THIS_MODULE);\r\ndout("Error adding device %s\n", buf);\r\nreturn (ssize_t)rc;\r\n}\r\nstatic void rbd_dev_device_release(struct device *dev)\r\n{\r\nstruct rbd_device *rbd_dev = dev_to_rbd_dev(dev);\r\nrbd_free_disk(rbd_dev);\r\nclear_bit(RBD_DEV_FLAG_EXISTS, &rbd_dev->flags);\r\nrbd_dev_mapping_clear(rbd_dev);\r\nunregister_blkdev(rbd_dev->major, rbd_dev->name);\r\nrbd_dev->major = 0;\r\nrbd_dev_id_put(rbd_dev);\r\nrbd_dev_mapping_clear(rbd_dev);\r\n}\r\nstatic void rbd_dev_remove_parent(struct rbd_device *rbd_dev)\r\n{\r\nwhile (rbd_dev->parent) {\r\nstruct rbd_device *first = rbd_dev;\r\nstruct rbd_device *second = first->parent;\r\nstruct rbd_device *third;\r\nwhile (second && (third = second->parent)) {\r\nfirst = second;\r\nsecond = third;\r\n}\r\nrbd_assert(second);\r\nrbd_dev_image_release(second);\r\nfirst->parent = NULL;\r\nfirst->parent_overlap = 0;\r\nrbd_assert(first->parent_spec);\r\nrbd_spec_put(first->parent_spec);\r\nfirst->parent_spec = NULL;\r\n}\r\n}\r\nstatic ssize_t rbd_remove(struct bus_type *bus,\r\nconst char *buf,\r\nsize_t count)\r\n{\r\nstruct rbd_device *rbd_dev = NULL;\r\nstruct list_head *tmp;\r\nint dev_id;\r\nunsigned long ul;\r\nbool already = false;\r\nint ret;\r\nret = kstrtoul(buf, 10, &ul);\r\nif (ret)\r\nreturn ret;\r\ndev_id = (int)ul;\r\nif (dev_id != ul)\r\nreturn -EINVAL;\r\nret = -ENOENT;\r\nspin_lock(&rbd_dev_list_lock);\r\nlist_for_each(tmp, &rbd_dev_list) {\r\nrbd_dev = list_entry(tmp, struct rbd_device, node);\r\nif (rbd_dev->dev_id == dev_id) {\r\nret = 0;\r\nbreak;\r\n}\r\n}\r\nif (!ret) {\r\nspin_lock_irq(&rbd_dev->lock);\r\nif (rbd_dev->open_count)\r\nret = -EBUSY;\r\nelse\r\nalready = test_and_set_bit(RBD_DEV_FLAG_REMOVING,\r\n&rbd_dev->flags);\r\nspin_unlock_irq(&rbd_dev->lock);\r\n}\r\nspin_unlock(&rbd_dev_list_lock);\r\nif (ret < 0 || already)\r\nreturn ret;\r\nret = rbd_dev_header_watch_sync(rbd_dev, false);\r\nif (ret)\r\nrbd_warn(rbd_dev, "failed to cancel watch event (%d)\n", ret);\r\ndout("%s: flushing notifies", __func__);\r\nceph_osdc_flush_notifies(&rbd_dev->rbd_client->client->osdc);\r\nrbd_bus_del_dev(rbd_dev);\r\nrbd_dev_image_release(rbd_dev);\r\nmodule_put(THIS_MODULE);\r\nreturn count;\r\n}\r\nstatic int rbd_sysfs_init(void)\r\n{\r\nint ret;\r\nret = device_register(&rbd_root_dev);\r\nif (ret < 0)\r\nreturn ret;\r\nret = bus_register(&rbd_bus_type);\r\nif (ret < 0)\r\ndevice_unregister(&rbd_root_dev);\r\nreturn ret;\r\n}\r\nstatic void rbd_sysfs_cleanup(void)\r\n{\r\nbus_unregister(&rbd_bus_type);\r\ndevice_unregister(&rbd_root_dev);\r\n}\r\nstatic int rbd_slab_init(void)\r\n{\r\nrbd_assert(!rbd_img_request_cache);\r\nrbd_img_request_cache = kmem_cache_create("rbd_img_request",\r\nsizeof (struct rbd_img_request),\r\n__alignof__(struct rbd_img_request),\r\n0, NULL);\r\nif (!rbd_img_request_cache)\r\nreturn -ENOMEM;\r\nrbd_assert(!rbd_obj_request_cache);\r\nrbd_obj_request_cache = kmem_cache_create("rbd_obj_request",\r\nsizeof (struct rbd_obj_request),\r\n__alignof__(struct rbd_obj_request),\r\n0, NULL);\r\nif (!rbd_obj_request_cache)\r\ngoto out_err;\r\nrbd_assert(!rbd_segment_name_cache);\r\nrbd_segment_name_cache = kmem_cache_create("rbd_segment_name",\r\nMAX_OBJ_NAME_SIZE + 1, 1, 0, NULL);\r\nif (rbd_segment_name_cache)\r\nreturn 0;\r\nout_err:\r\nif (rbd_obj_request_cache) {\r\nkmem_cache_destroy(rbd_obj_request_cache);\r\nrbd_obj_request_cache = NULL;\r\n}\r\nkmem_cache_destroy(rbd_img_request_cache);\r\nrbd_img_request_cache = NULL;\r\nreturn -ENOMEM;\r\n}\r\nstatic void rbd_slab_exit(void)\r\n{\r\nrbd_assert(rbd_segment_name_cache);\r\nkmem_cache_destroy(rbd_segment_name_cache);\r\nrbd_segment_name_cache = NULL;\r\nrbd_assert(rbd_obj_request_cache);\r\nkmem_cache_destroy(rbd_obj_request_cache);\r\nrbd_obj_request_cache = NULL;\r\nrbd_assert(rbd_img_request_cache);\r\nkmem_cache_destroy(rbd_img_request_cache);\r\nrbd_img_request_cache = NULL;\r\n}\r\nstatic int __init rbd_init(void)\r\n{\r\nint rc;\r\nif (!libceph_compatible(NULL)) {\r\nrbd_warn(NULL, "libceph incompatibility (quitting)");\r\nreturn -EINVAL;\r\n}\r\nrc = rbd_slab_init();\r\nif (rc)\r\nreturn rc;\r\nrc = rbd_sysfs_init();\r\nif (rc)\r\nrbd_slab_exit();\r\nelse\r\npr_info("loaded " RBD_DRV_NAME_LONG "\n");\r\nreturn rc;\r\n}\r\nstatic void __exit rbd_exit(void)\r\n{\r\nrbd_sysfs_cleanup();\r\nrbd_slab_exit();\r\n}
