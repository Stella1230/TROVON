static int cmci_supported(int *banks)\r\n{\r\nu64 cap;\r\nif (mca_cfg.cmci_disabled || mca_cfg.ignore_ce)\r\nreturn 0;\r\nif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\r\nreturn 0;\r\nif (!cpu_has_apic || lapic_get_maxlvt() < 6)\r\nreturn 0;\r\nrdmsrl(MSR_IA32_MCG_CAP, cap);\r\n*banks = min_t(unsigned, MAX_NR_BANKS, cap & 0xff);\r\nreturn !!(cap & MCG_CMCI_P);\r\n}\r\nvoid mce_intel_cmci_poll(void)\r\n{\r\nif (__this_cpu_read(cmci_storm_state) == CMCI_STORM_NONE)\r\nreturn;\r\nmachine_check_poll(MCP_TIMESTAMP, &__get_cpu_var(mce_banks_owned));\r\n}\r\nvoid mce_intel_hcpu_update(unsigned long cpu)\r\n{\r\nif (per_cpu(cmci_storm_state, cpu) == CMCI_STORM_ACTIVE)\r\natomic_dec(&cmci_storm_on_cpus);\r\nper_cpu(cmci_storm_state, cpu) = CMCI_STORM_NONE;\r\n}\r\nunsigned long mce_intel_adjust_timer(unsigned long interval)\r\n{\r\nint r;\r\nif (interval < CMCI_POLL_INTERVAL)\r\nreturn interval;\r\nswitch (__this_cpu_read(cmci_storm_state)) {\r\ncase CMCI_STORM_ACTIVE:\r\n__this_cpu_write(cmci_storm_state, CMCI_STORM_SUBSIDED);\r\nr = atomic_sub_return(1, &cmci_storm_on_cpus);\r\nif (r == 0)\r\npr_notice("CMCI storm subsided: switching to interrupt mode\n");\r\ncase CMCI_STORM_SUBSIDED:\r\nif (!atomic_read(&cmci_storm_on_cpus)) {\r\n__this_cpu_write(cmci_storm_state, CMCI_STORM_NONE);\r\ncmci_reenable();\r\ncmci_recheck();\r\n}\r\nreturn CMCI_POLL_INTERVAL;\r\ndefault:\r\nreturn interval;\r\n}\r\n}\r\nstatic bool cmci_storm_detect(void)\r\n{\r\nunsigned int cnt = __this_cpu_read(cmci_storm_cnt);\r\nunsigned long ts = __this_cpu_read(cmci_time_stamp);\r\nunsigned long now = jiffies;\r\nint r;\r\nif (__this_cpu_read(cmci_storm_state) != CMCI_STORM_NONE)\r\nreturn true;\r\nif (time_before_eq(now, ts + CMCI_STORM_INTERVAL)) {\r\ncnt++;\r\n} else {\r\ncnt = 1;\r\n__this_cpu_write(cmci_time_stamp, now);\r\n}\r\n__this_cpu_write(cmci_storm_cnt, cnt);\r\nif (cnt <= CMCI_STORM_THRESHOLD)\r\nreturn false;\r\ncmci_clear();\r\n__this_cpu_write(cmci_storm_state, CMCI_STORM_ACTIVE);\r\nr = atomic_add_return(1, &cmci_storm_on_cpus);\r\nmce_timer_kick(CMCI_POLL_INTERVAL);\r\nif (r == 1)\r\npr_notice("CMCI storm detected: switching to poll mode\n");\r\nreturn true;\r\n}\r\nstatic void intel_threshold_interrupt(void)\r\n{\r\nif (cmci_storm_detect())\r\nreturn;\r\nmachine_check_poll(MCP_TIMESTAMP, &__get_cpu_var(mce_banks_owned));\r\nmce_notify_irq();\r\n}\r\nstatic void cmci_discover(int banks)\r\n{\r\nunsigned long *owned = (void *)&__get_cpu_var(mce_banks_owned);\r\nunsigned long flags;\r\nint i;\r\nint bios_wrong_thresh = 0;\r\nraw_spin_lock_irqsave(&cmci_discover_lock, flags);\r\nfor (i = 0; i < banks; i++) {\r\nu64 val;\r\nint bios_zero_thresh = 0;\r\nif (test_bit(i, owned))\r\ncontinue;\r\nif (test_bit(i, mce_banks_ce_disabled))\r\ncontinue;\r\nrdmsrl(MSR_IA32_MCx_CTL2(i), val);\r\nif (val & MCI_CTL2_CMCI_EN) {\r\nclear_bit(i, owned);\r\n__clear_bit(i, __get_cpu_var(mce_poll_banks));\r\ncontinue;\r\n}\r\nif (!mca_cfg.bios_cmci_threshold) {\r\nval &= ~MCI_CTL2_CMCI_THRESHOLD_MASK;\r\nval |= CMCI_THRESHOLD;\r\n} else if (!(val & MCI_CTL2_CMCI_THRESHOLD_MASK)) {\r\nbios_zero_thresh = 1;\r\nval |= CMCI_THRESHOLD;\r\n}\r\nval |= MCI_CTL2_CMCI_EN;\r\nwrmsrl(MSR_IA32_MCx_CTL2(i), val);\r\nrdmsrl(MSR_IA32_MCx_CTL2(i), val);\r\nif (val & MCI_CTL2_CMCI_EN) {\r\nset_bit(i, owned);\r\n__clear_bit(i, __get_cpu_var(mce_poll_banks));\r\nif (mca_cfg.bios_cmci_threshold && bios_zero_thresh &&\r\n(val & MCI_CTL2_CMCI_THRESHOLD_MASK))\r\nbios_wrong_thresh = 1;\r\n} else {\r\nWARN_ON(!test_bit(i, __get_cpu_var(mce_poll_banks)));\r\n}\r\n}\r\nraw_spin_unlock_irqrestore(&cmci_discover_lock, flags);\r\nif (mca_cfg.bios_cmci_threshold && bios_wrong_thresh) {\r\npr_info_once(\r\n"bios_cmci_threshold: Some banks do not have valid thresholds set\n");\r\npr_info_once(\r\n"bios_cmci_threshold: Make sure your BIOS supports this boot option\n");\r\n}\r\n}\r\nvoid cmci_recheck(void)\r\n{\r\nunsigned long flags;\r\nint banks;\r\nif (!mce_available(__this_cpu_ptr(&cpu_info)) || !cmci_supported(&banks))\r\nreturn;\r\nlocal_irq_save(flags);\r\nmachine_check_poll(MCP_TIMESTAMP, &__get_cpu_var(mce_banks_owned));\r\nlocal_irq_restore(flags);\r\n}\r\nstatic void __cmci_disable_bank(int bank)\r\n{\r\nu64 val;\r\nif (!test_bit(bank, __get_cpu_var(mce_banks_owned)))\r\nreturn;\r\nrdmsrl(MSR_IA32_MCx_CTL2(bank), val);\r\nval &= ~MCI_CTL2_CMCI_EN;\r\nwrmsrl(MSR_IA32_MCx_CTL2(bank), val);\r\n__clear_bit(bank, __get_cpu_var(mce_banks_owned));\r\n}\r\nvoid cmci_clear(void)\r\n{\r\nunsigned long flags;\r\nint i;\r\nint banks;\r\nif (!cmci_supported(&banks))\r\nreturn;\r\nraw_spin_lock_irqsave(&cmci_discover_lock, flags);\r\nfor (i = 0; i < banks; i++)\r\n__cmci_disable_bank(i);\r\nraw_spin_unlock_irqrestore(&cmci_discover_lock, flags);\r\n}\r\nstatic void cmci_rediscover_work_func(void *arg)\r\n{\r\nint banks;\r\nif (cmci_supported(&banks))\r\ncmci_discover(banks);\r\n}\r\nvoid cmci_rediscover(void)\r\n{\r\nint banks;\r\nif (!cmci_supported(&banks))\r\nreturn;\r\non_each_cpu(cmci_rediscover_work_func, NULL, 1);\r\n}\r\nvoid cmci_reenable(void)\r\n{\r\nint banks;\r\nif (cmci_supported(&banks))\r\ncmci_discover(banks);\r\n}\r\nvoid cmci_disable_bank(int bank)\r\n{\r\nint banks;\r\nunsigned long flags;\r\nif (!cmci_supported(&banks))\r\nreturn;\r\nraw_spin_lock_irqsave(&cmci_discover_lock, flags);\r\n__cmci_disable_bank(bank);\r\nraw_spin_unlock_irqrestore(&cmci_discover_lock, flags);\r\n}\r\nstatic void intel_init_cmci(void)\r\n{\r\nint banks;\r\nif (!cmci_supported(&banks))\r\nreturn;\r\nmce_threshold_vector = intel_threshold_interrupt;\r\ncmci_discover(banks);\r\napic_write(APIC_LVTCMCI, THRESHOLD_APIC_VECTOR|APIC_DM_FIXED);\r\ncmci_recheck();\r\n}\r\nvoid mce_intel_feature_init(struct cpuinfo_x86 *c)\r\n{\r\nintel_init_thermal(c);\r\nintel_init_cmci();\r\n}
