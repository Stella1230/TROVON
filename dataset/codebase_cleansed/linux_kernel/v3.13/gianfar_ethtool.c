static void gfar_gstrings(struct net_device *dev, u32 stringset, u8 * buf)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nif (priv->device_flags & FSL_GIANFAR_DEV_HAS_RMON)\r\nmemcpy(buf, stat_gstrings, GFAR_STATS_LEN * ETH_GSTRING_LEN);\r\nelse\r\nmemcpy(buf, stat_gstrings,\r\nGFAR_EXTRA_STATS_LEN * ETH_GSTRING_LEN);\r\n}\r\nstatic void gfar_fill_stats(struct net_device *dev, struct ethtool_stats *dummy,\r\nu64 *buf)\r\n{\r\nint i;\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nstruct gfar __iomem *regs = priv->gfargrp[0].regs;\r\natomic64_t *extra = (atomic64_t *)&priv->extra_stats;\r\nfor (i = 0; i < GFAR_EXTRA_STATS_LEN; i++)\r\nbuf[i] = atomic64_read(&extra[i]);\r\nif (priv->device_flags & FSL_GIANFAR_DEV_HAS_RMON) {\r\nu32 __iomem *rmon = (u32 __iomem *) &regs->rmon;\r\nfor (; i < GFAR_STATS_LEN; i++, rmon++)\r\nbuf[i] = (u64) gfar_read(rmon);\r\n}\r\n}\r\nstatic int gfar_sset_count(struct net_device *dev, int sset)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nif (priv->device_flags & FSL_GIANFAR_DEV_HAS_RMON)\r\nreturn GFAR_STATS_LEN;\r\nelse\r\nreturn GFAR_EXTRA_STATS_LEN;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void gfar_gdrvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *drvinfo)\r\n{\r\nstrlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, gfar_driver_version,\r\nsizeof(drvinfo->version));\r\nstrlcpy(drvinfo->fw_version, "N/A", sizeof(drvinfo->fw_version));\r\nstrlcpy(drvinfo->bus_info, "N/A", sizeof(drvinfo->bus_info));\r\ndrvinfo->regdump_len = 0;\r\ndrvinfo->eedump_len = 0;\r\n}\r\nstatic int gfar_ssettings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nstruct phy_device *phydev = priv->phydev;\r\nif (NULL == phydev)\r\nreturn -ENODEV;\r\nreturn phy_ethtool_sset(phydev, cmd);\r\n}\r\nstatic int gfar_gsettings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nstruct phy_device *phydev = priv->phydev;\r\nstruct gfar_priv_rx_q *rx_queue = NULL;\r\nstruct gfar_priv_tx_q *tx_queue = NULL;\r\nif (NULL == phydev)\r\nreturn -ENODEV;\r\ntx_queue = priv->tx_queue[0];\r\nrx_queue = priv->rx_queue[0];\r\ncmd->maxtxpkt = get_icft_value(tx_queue->txic);\r\ncmd->maxrxpkt = get_icft_value(rx_queue->rxic);\r\nreturn phy_ethtool_gset(phydev, cmd);\r\n}\r\nstatic int gfar_reglen(struct net_device *dev)\r\n{\r\nreturn sizeof (struct gfar);\r\n}\r\nstatic void gfar_get_regs(struct net_device *dev, struct ethtool_regs *regs,\r\nvoid *regbuf)\r\n{\r\nint i;\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nu32 __iomem *theregs = (u32 __iomem *) priv->gfargrp[0].regs;\r\nu32 *buf = (u32 *) regbuf;\r\nfor (i = 0; i < sizeof (struct gfar) / sizeof (u32); i++)\r\nbuf[i] = gfar_read(&theregs[i]);\r\n}\r\nstatic unsigned int gfar_usecs2ticks(struct gfar_private *priv,\r\nunsigned int usecs)\r\n{\r\nunsigned int count;\r\nswitch (priv->phydev->speed) {\r\ncase SPEED_1000:\r\ncount = GFAR_GBIT_TIME;\r\nbreak;\r\ncase SPEED_100:\r\ncount = GFAR_100_TIME;\r\nbreak;\r\ncase SPEED_10:\r\ndefault:\r\ncount = GFAR_10_TIME;\r\nbreak;\r\n}\r\nreturn (usecs * 1000 + count - 1) / count;\r\n}\r\nstatic unsigned int gfar_ticks2usecs(struct gfar_private *priv,\r\nunsigned int ticks)\r\n{\r\nunsigned int count;\r\nswitch (priv->phydev->speed) {\r\ncase SPEED_1000:\r\ncount = GFAR_GBIT_TIME;\r\nbreak;\r\ncase SPEED_100:\r\ncount = GFAR_100_TIME;\r\nbreak;\r\ncase SPEED_10:\r\ndefault:\r\ncount = GFAR_10_TIME;\r\nbreak;\r\n}\r\nreturn (ticks * count) / 1000;\r\n}\r\nstatic int gfar_gcoalesce(struct net_device *dev,\r\nstruct ethtool_coalesce *cvals)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nstruct gfar_priv_rx_q *rx_queue = NULL;\r\nstruct gfar_priv_tx_q *tx_queue = NULL;\r\nunsigned long rxtime;\r\nunsigned long rxcount;\r\nunsigned long txtime;\r\nunsigned long txcount;\r\nif (!(priv->device_flags & FSL_GIANFAR_DEV_HAS_COALESCE))\r\nreturn -EOPNOTSUPP;\r\nif (NULL == priv->phydev)\r\nreturn -ENODEV;\r\nrx_queue = priv->rx_queue[0];\r\ntx_queue = priv->tx_queue[0];\r\nrxtime = get_ictt_value(rx_queue->rxic);\r\nrxcount = get_icft_value(rx_queue->rxic);\r\ntxtime = get_ictt_value(tx_queue->txic);\r\ntxcount = get_icft_value(tx_queue->txic);\r\ncvals->rx_coalesce_usecs = gfar_ticks2usecs(priv, rxtime);\r\ncvals->rx_max_coalesced_frames = rxcount;\r\ncvals->tx_coalesce_usecs = gfar_ticks2usecs(priv, txtime);\r\ncvals->tx_max_coalesced_frames = txcount;\r\ncvals->use_adaptive_rx_coalesce = 0;\r\ncvals->use_adaptive_tx_coalesce = 0;\r\ncvals->pkt_rate_low = 0;\r\ncvals->rx_coalesce_usecs_low = 0;\r\ncvals->rx_max_coalesced_frames_low = 0;\r\ncvals->tx_coalesce_usecs_low = 0;\r\ncvals->tx_max_coalesced_frames_low = 0;\r\ncvals->pkt_rate_high = 0;\r\ncvals->rx_coalesce_usecs_high = 0;\r\ncvals->rx_max_coalesced_frames_high = 0;\r\ncvals->tx_coalesce_usecs_high = 0;\r\ncvals->tx_max_coalesced_frames_high = 0;\r\ncvals->rate_sample_interval = 0;\r\nreturn 0;\r\n}\r\nstatic int gfar_scoalesce(struct net_device *dev,\r\nstruct ethtool_coalesce *cvals)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nint i = 0;\r\nif (!(priv->device_flags & FSL_GIANFAR_DEV_HAS_COALESCE))\r\nreturn -EOPNOTSUPP;\r\nif ((cvals->rx_coalesce_usecs == 0) ||\r\n(cvals->rx_max_coalesced_frames == 0)) {\r\nfor (i = 0; i < priv->num_rx_queues; i++)\r\npriv->rx_queue[i]->rxcoalescing = 0;\r\n} else {\r\nfor (i = 0; i < priv->num_rx_queues; i++)\r\npriv->rx_queue[i]->rxcoalescing = 1;\r\n}\r\nif (NULL == priv->phydev)\r\nreturn -ENODEV;\r\nif (cvals->rx_coalesce_usecs > GFAR_MAX_COAL_USECS) {\r\nnetdev_info(dev, "Coalescing is limited to %d microseconds\n",\r\nGFAR_MAX_COAL_USECS);\r\nreturn -EINVAL;\r\n}\r\nif (cvals->rx_max_coalesced_frames > GFAR_MAX_COAL_FRAMES) {\r\nnetdev_info(dev, "Coalescing is limited to %d frames\n",\r\nGFAR_MAX_COAL_FRAMES);\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < priv->num_rx_queues; i++) {\r\npriv->rx_queue[i]->rxic = mk_ic_value(\r\ncvals->rx_max_coalesced_frames,\r\ngfar_usecs2ticks(priv, cvals->rx_coalesce_usecs));\r\n}\r\nif ((cvals->tx_coalesce_usecs == 0) ||\r\n(cvals->tx_max_coalesced_frames == 0)) {\r\nfor (i = 0; i < priv->num_tx_queues; i++)\r\npriv->tx_queue[i]->txcoalescing = 0;\r\n} else {\r\nfor (i = 0; i < priv->num_tx_queues; i++)\r\npriv->tx_queue[i]->txcoalescing = 1;\r\n}\r\nif (cvals->tx_coalesce_usecs > GFAR_MAX_COAL_USECS) {\r\nnetdev_info(dev, "Coalescing is limited to %d microseconds\n",\r\nGFAR_MAX_COAL_USECS);\r\nreturn -EINVAL;\r\n}\r\nif (cvals->tx_max_coalesced_frames > GFAR_MAX_COAL_FRAMES) {\r\nnetdev_info(dev, "Coalescing is limited to %d frames\n",\r\nGFAR_MAX_COAL_FRAMES);\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < priv->num_tx_queues; i++) {\r\npriv->tx_queue[i]->txic = mk_ic_value(\r\ncvals->tx_max_coalesced_frames,\r\ngfar_usecs2ticks(priv, cvals->tx_coalesce_usecs));\r\n}\r\ngfar_configure_coalescing_all(priv);\r\nreturn 0;\r\n}\r\nstatic void gfar_gringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *rvals)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nstruct gfar_priv_tx_q *tx_queue = NULL;\r\nstruct gfar_priv_rx_q *rx_queue = NULL;\r\ntx_queue = priv->tx_queue[0];\r\nrx_queue = priv->rx_queue[0];\r\nrvals->rx_max_pending = GFAR_RX_MAX_RING_SIZE;\r\nrvals->rx_mini_max_pending = GFAR_RX_MAX_RING_SIZE;\r\nrvals->rx_jumbo_max_pending = GFAR_RX_MAX_RING_SIZE;\r\nrvals->tx_max_pending = GFAR_TX_MAX_RING_SIZE;\r\nrvals->rx_pending = rx_queue->rx_ring_size;\r\nrvals->rx_mini_pending = rx_queue->rx_ring_size;\r\nrvals->rx_jumbo_pending = rx_queue->rx_ring_size;\r\nrvals->tx_pending = tx_queue->tx_ring_size;\r\n}\r\nstatic int gfar_sringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *rvals)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nint err = 0, i = 0;\r\nif (rvals->rx_pending > GFAR_RX_MAX_RING_SIZE)\r\nreturn -EINVAL;\r\nif (!is_power_of_2(rvals->rx_pending)) {\r\nnetdev_err(dev, "Ring sizes must be a power of 2\n");\r\nreturn -EINVAL;\r\n}\r\nif (rvals->tx_pending > GFAR_TX_MAX_RING_SIZE)\r\nreturn -EINVAL;\r\nif (!is_power_of_2(rvals->tx_pending)) {\r\nnetdev_err(dev, "Ring sizes must be a power of 2\n");\r\nreturn -EINVAL;\r\n}\r\nif (dev->flags & IFF_UP) {\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nlock_tx_qs(priv);\r\nlock_rx_qs(priv);\r\ngfar_halt(dev);\r\nunlock_rx_qs(priv);\r\nunlock_tx_qs(priv);\r\nlocal_irq_restore(flags);\r\nfor (i = 0; i < priv->num_rx_queues; i++)\r\ngfar_clean_rx_ring(priv->rx_queue[i],\r\npriv->rx_queue[i]->rx_ring_size);\r\nstop_gfar(dev);\r\n}\r\nfor (i = 0; i < priv->num_rx_queues; i++) {\r\npriv->rx_queue[i]->rx_ring_size = rvals->rx_pending;\r\npriv->tx_queue[i]->tx_ring_size = rvals->tx_pending;\r\npriv->tx_queue[i]->num_txbdfree =\r\npriv->tx_queue[i]->tx_ring_size;\r\n}\r\nif (dev->flags & IFF_UP) {\r\nerr = startup_gfar(dev);\r\nnetif_tx_wake_all_queues(dev);\r\n}\r\nreturn err;\r\n}\r\nstatic void gfar_gpauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *epause)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nepause->autoneg = !!priv->pause_aneg_en;\r\nepause->rx_pause = !!priv->rx_pause_en;\r\nepause->tx_pause = !!priv->tx_pause_en;\r\n}\r\nstatic int gfar_spauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *epause)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nstruct phy_device *phydev = priv->phydev;\r\nstruct gfar __iomem *regs = priv->gfargrp[0].regs;\r\nu32 oldadv, newadv;\r\nif (!(phydev->supported & SUPPORTED_Pause) ||\r\n(!(phydev->supported & SUPPORTED_Asym_Pause) &&\r\n(epause->rx_pause != epause->tx_pause)))\r\nreturn -EINVAL;\r\npriv->rx_pause_en = priv->tx_pause_en = 0;\r\nif (epause->rx_pause) {\r\npriv->rx_pause_en = 1;\r\nif (epause->tx_pause) {\r\npriv->tx_pause_en = 1;\r\nnewadv = ADVERTISED_Pause;\r\n} else\r\nnewadv = ADVERTISED_Pause | ADVERTISED_Asym_Pause;\r\n} else if (epause->tx_pause) {\r\npriv->tx_pause_en = 1;\r\nnewadv = ADVERTISED_Asym_Pause;\r\n} else\r\nnewadv = 0;\r\nif (epause->autoneg)\r\npriv->pause_aneg_en = 1;\r\nelse\r\npriv->pause_aneg_en = 0;\r\noldadv = phydev->advertising &\r\n(ADVERTISED_Pause | ADVERTISED_Asym_Pause);\r\nif (oldadv != newadv) {\r\nphydev->advertising &=\r\n~(ADVERTISED_Pause | ADVERTISED_Asym_Pause);\r\nphydev->advertising |= newadv;\r\nif (phydev->autoneg)\r\nreturn phy_start_aneg(phydev);\r\nif (!epause->autoneg) {\r\nu32 tempval;\r\ntempval = gfar_read(&regs->maccfg1);\r\ntempval &= ~(MACCFG1_TX_FLOW | MACCFG1_RX_FLOW);\r\nif (priv->tx_pause_en)\r\ntempval |= MACCFG1_TX_FLOW;\r\nif (priv->rx_pause_en)\r\ntempval |= MACCFG1_RX_FLOW;\r\ngfar_write(&regs->maccfg1, tempval);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint gfar_set_features(struct net_device *dev, netdev_features_t features)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nunsigned long flags;\r\nint err = 0, i = 0;\r\nnetdev_features_t changed = dev->features ^ features;\r\nif (changed & (NETIF_F_HW_VLAN_CTAG_TX|NETIF_F_HW_VLAN_CTAG_RX))\r\ngfar_vlan_mode(dev, features);\r\nif (!(changed & NETIF_F_RXCSUM))\r\nreturn 0;\r\nif (dev->flags & IFF_UP) {\r\nlocal_irq_save(flags);\r\nlock_tx_qs(priv);\r\nlock_rx_qs(priv);\r\ngfar_halt(dev);\r\nunlock_tx_qs(priv);\r\nunlock_rx_qs(priv);\r\nlocal_irq_restore(flags);\r\nfor (i = 0; i < priv->num_rx_queues; i++)\r\ngfar_clean_rx_ring(priv->rx_queue[i],\r\npriv->rx_queue[i]->rx_ring_size);\r\nstop_gfar(dev);\r\ndev->features = features;\r\nerr = startup_gfar(dev);\r\nnetif_tx_wake_all_queues(dev);\r\n}\r\nreturn err;\r\n}\r\nstatic uint32_t gfar_get_msglevel(struct net_device *dev)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nreturn priv->msg_enable;\r\n}\r\nstatic void gfar_set_msglevel(struct net_device *dev, uint32_t data)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\npriv->msg_enable = data;\r\n}\r\nstatic void gfar_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nif (priv->device_flags & FSL_GIANFAR_DEV_HAS_MAGIC_PACKET) {\r\nwol->supported = WAKE_MAGIC;\r\nwol->wolopts = priv->wol_en ? WAKE_MAGIC : 0;\r\n} else {\r\nwol->supported = wol->wolopts = 0;\r\n}\r\n}\r\nstatic int gfar_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nunsigned long flags;\r\nif (!(priv->device_flags & FSL_GIANFAR_DEV_HAS_MAGIC_PACKET) &&\r\nwol->wolopts != 0)\r\nreturn -EINVAL;\r\nif (wol->wolopts & ~WAKE_MAGIC)\r\nreturn -EINVAL;\r\ndevice_set_wakeup_enable(&dev->dev, wol->wolopts & WAKE_MAGIC);\r\nspin_lock_irqsave(&priv->bflock, flags);\r\npriv->wol_en = !!device_may_wakeup(&dev->dev);\r\nspin_unlock_irqrestore(&priv->bflock, flags);\r\nreturn 0;\r\n}\r\nstatic void ethflow_to_filer_rules (struct gfar_private *priv, u64 ethflow)\r\n{\r\nu32 fcr = 0x0, fpr = FPR_FILER_MASK;\r\nif (ethflow & RXH_L2DA) {\r\nfcr = RQFCR_PID_DAH |RQFCR_CMP_NOMATCH |\r\nRQFCR_HASH | RQFCR_AND | RQFCR_HASHTBL_0;\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\nfcr = RQFCR_PID_DAL | RQFCR_AND | RQFCR_CMP_NOMATCH |\r\nRQFCR_HASH | RQFCR_AND | RQFCR_HASHTBL_0;\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\nif (ethflow & RXH_VLAN) {\r\nfcr = RQFCR_PID_VID | RQFCR_CMP_NOMATCH | RQFCR_HASH |\r\nRQFCR_AND | RQFCR_HASHTBL_0;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\nif (ethflow & RXH_IP_SRC) {\r\nfcr = RQFCR_PID_SIA | RQFCR_CMP_NOMATCH | RQFCR_HASH |\r\nRQFCR_AND | RQFCR_HASHTBL_0;\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\nif (ethflow & (RXH_IP_DST)) {\r\nfcr = RQFCR_PID_DIA | RQFCR_CMP_NOMATCH | RQFCR_HASH |\r\nRQFCR_AND | RQFCR_HASHTBL_0;\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\nif (ethflow & RXH_L3_PROTO) {\r\nfcr = RQFCR_PID_L4P | RQFCR_CMP_NOMATCH | RQFCR_HASH |\r\nRQFCR_AND | RQFCR_HASHTBL_0;\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\nif (ethflow & RXH_L4_B_0_1) {\r\nfcr = RQFCR_PID_SPT | RQFCR_CMP_NOMATCH | RQFCR_HASH |\r\nRQFCR_AND | RQFCR_HASHTBL_0;\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\nif (ethflow & RXH_L4_B_2_3) {\r\nfcr = RQFCR_PID_DPT | RQFCR_CMP_NOMATCH | RQFCR_HASH |\r\nRQFCR_AND | RQFCR_HASHTBL_0;\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = fpr;\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = fcr;\r\ngfar_write_filer(priv, priv->cur_filer_idx, fcr, fpr);\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\n}\r\nstatic int gfar_ethflow_to_filer_table(struct gfar_private *priv, u64 ethflow,\r\nu64 class)\r\n{\r\nunsigned int last_rule_idx = priv->cur_filer_idx;\r\nunsigned int cmp_rqfpr;\r\nunsigned int *local_rqfpr;\r\nunsigned int *local_rqfcr;\r\nint i = 0x0, k = 0x0;\r\nint j = MAX_FILER_IDX, l = 0x0;\r\nint ret = 1;\r\nlocal_rqfpr = kmalloc_array(MAX_FILER_IDX + 1, sizeof(unsigned int),\r\nGFP_KERNEL);\r\nlocal_rqfcr = kmalloc_array(MAX_FILER_IDX + 1, sizeof(unsigned int),\r\nGFP_KERNEL);\r\nif (!local_rqfpr || !local_rqfcr) {\r\nret = 0;\r\ngoto err;\r\n}\r\nswitch (class) {\r\ncase TCP_V4_FLOW:\r\ncmp_rqfpr = RQFPR_IPV4 |RQFPR_TCP;\r\nbreak;\r\ncase UDP_V4_FLOW:\r\ncmp_rqfpr = RQFPR_IPV4 |RQFPR_UDP;\r\nbreak;\r\ncase TCP_V6_FLOW:\r\ncmp_rqfpr = RQFPR_IPV6 |RQFPR_TCP;\r\nbreak;\r\ncase UDP_V6_FLOW:\r\ncmp_rqfpr = RQFPR_IPV6 |RQFPR_UDP;\r\nbreak;\r\ndefault:\r\nnetdev_err(priv->ndev,\r\n"Right now this class is not supported\n");\r\nret = 0;\r\ngoto err;\r\n}\r\nfor (i = 0; i < MAX_FILER_IDX + 1; i++) {\r\nlocal_rqfpr[j] = priv->ftp_rqfpr[i];\r\nlocal_rqfcr[j] = priv->ftp_rqfcr[i];\r\nj--;\r\nif ((priv->ftp_rqfcr[i] ==\r\n(RQFCR_PID_PARSE | RQFCR_CLE | RQFCR_AND)) &&\r\n(priv->ftp_rqfpr[i] == cmp_rqfpr))\r\nbreak;\r\n}\r\nif (i == MAX_FILER_IDX + 1) {\r\nnetdev_err(priv->ndev,\r\n"No parse rule found, can't create hash rules\n");\r\nret = 0;\r\ngoto err;\r\n}\r\nfor (l = i+1; l < MAX_FILER_IDX; l++) {\r\nif ((priv->ftp_rqfcr[l] & RQFCR_CLE) &&\r\n!(priv->ftp_rqfcr[l] & RQFCR_AND)) {\r\npriv->ftp_rqfcr[l] = RQFCR_CLE | RQFCR_CMP_EXACT |\r\nRQFCR_HASHTBL_0 | RQFCR_PID_MASK;\r\npriv->ftp_rqfpr[l] = FPR_FILER_MASK;\r\ngfar_write_filer(priv, l, priv->ftp_rqfcr[l],\r\npriv->ftp_rqfpr[l]);\r\nbreak;\r\n}\r\nif (!(priv->ftp_rqfcr[l] & RQFCR_CLE) &&\r\n(priv->ftp_rqfcr[l] & RQFCR_AND))\r\ncontinue;\r\nelse {\r\nlocal_rqfpr[j] = priv->ftp_rqfpr[l];\r\nlocal_rqfcr[j] = priv->ftp_rqfcr[l];\r\nj--;\r\n}\r\n}\r\npriv->cur_filer_idx = l - 1;\r\nlast_rule_idx = l;\r\nethflow_to_filer_rules(priv, ethflow);\r\nfor (k = j+1; k < MAX_FILER_IDX; k++) {\r\npriv->ftp_rqfpr[priv->cur_filer_idx] = local_rqfpr[k];\r\npriv->ftp_rqfcr[priv->cur_filer_idx] = local_rqfcr[k];\r\ngfar_write_filer(priv, priv->cur_filer_idx,\r\nlocal_rqfcr[k], local_rqfpr[k]);\r\nif (!priv->cur_filer_idx)\r\nbreak;\r\npriv->cur_filer_idx = priv->cur_filer_idx - 1;\r\n}\r\nerr:\r\nkfree(local_rqfcr);\r\nkfree(local_rqfpr);\r\nreturn ret;\r\n}\r\nstatic int gfar_set_hash_opts(struct gfar_private *priv,\r\nstruct ethtool_rxnfc *cmd)\r\n{\r\nif (!gfar_ethflow_to_filer_table(priv, cmd->data, cmd->flow_type))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int gfar_check_filer_hardware(struct gfar_private *priv)\r\n{\r\nstruct gfar __iomem *regs = NULL;\r\nu32 i;\r\nregs = priv->gfargrp[0].regs;\r\ni = gfar_read(&regs->ecntrl);\r\ni &= ECNTRL_FIFM;\r\nif (i == ECNTRL_FIFM) {\r\nnetdev_notice(priv->ndev, "Interface in FIFO mode\n");\r\ni = gfar_read(&regs->rctrl);\r\ni &= RCTRL_PRSDEP_MASK | RCTRL_PRSFM;\r\nif (i == (RCTRL_PRSDEP_MASK | RCTRL_PRSFM)) {\r\nnetdev_info(priv->ndev,\r\n"Receive Queue Filtering enabled\n");\r\n} else {\r\nnetdev_warn(priv->ndev,\r\n"Receive Queue Filtering disabled\n");\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nelse {\r\ni = gfar_read(&regs->rctrl);\r\ni &= RCTRL_PRSDEP_MASK;\r\nif (i == RCTRL_PRSDEP_MASK) {\r\nnetdev_info(priv->ndev,\r\n"Receive Queue Filtering enabled\n");\r\n} else {\r\nnetdev_warn(priv->ndev,\r\n"Receive Queue Filtering disabled\n");\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nregs->rbifx = 0xC0C1C2C3;\r\nreturn 0;\r\n}\r\nstatic int gfar_comp_asc(const void *a, const void *b)\r\n{\r\nreturn memcmp(a, b, 4);\r\n}\r\nstatic int gfar_comp_desc(const void *a, const void *b)\r\n{\r\nreturn -memcmp(a, b, 4);\r\n}\r\nstatic void gfar_swap(void *a, void *b, int size)\r\n{\r\nu32 *_a = a;\r\nu32 *_b = b;\r\nswap(_a[0], _b[0]);\r\nswap(_a[1], _b[1]);\r\nswap(_a[2], _b[2]);\r\nswap(_a[3], _b[3]);\r\n}\r\nstatic void gfar_set_mask(u32 mask, struct filer_table *tab)\r\n{\r\ntab->fe[tab->index].ctrl = RQFCR_AND | RQFCR_PID_MASK | RQFCR_CMP_EXACT;\r\ntab->fe[tab->index].prop = mask;\r\ntab->index++;\r\n}\r\nstatic void gfar_set_parse_bits(u32 value, u32 mask, struct filer_table *tab)\r\n{\r\ngfar_set_mask(mask, tab);\r\ntab->fe[tab->index].ctrl = RQFCR_CMP_EXACT | RQFCR_PID_PARSE |\r\nRQFCR_AND;\r\ntab->fe[tab->index].prop = value;\r\ntab->index++;\r\n}\r\nstatic void gfar_set_general_attribute(u32 value, u32 mask, u32 flag,\r\nstruct filer_table *tab)\r\n{\r\ngfar_set_mask(mask, tab);\r\ntab->fe[tab->index].ctrl = RQFCR_CMP_EXACT | RQFCR_AND | flag;\r\ntab->fe[tab->index].prop = value;\r\ntab->index++;\r\n}\r\nstatic void gfar_set_attribute(u32 value, u32 mask, u32 flag,\r\nstruct filer_table *tab)\r\n{\r\nswitch (flag) {\r\ncase RQFCR_PID_PRI:\r\nif (!(value | mask))\r\nreturn;\r\nmask |= RQFCR_PID_PRI_MASK;\r\nbreak;\r\ncase RQFCR_PID_L4P:\r\ncase RQFCR_PID_TOS:\r\nif (!~(mask | RQFCR_PID_L4P_MASK))\r\nreturn;\r\nif (!mask)\r\nmask = ~0;\r\nelse\r\nmask |= RQFCR_PID_L4P_MASK;\r\nbreak;\r\ncase RQFCR_PID_VID:\r\nif (!(value | mask))\r\nreturn;\r\nmask |= RQFCR_PID_VID_MASK;\r\nbreak;\r\ncase RQFCR_PID_DPT:\r\ncase RQFCR_PID_SPT:\r\ncase RQFCR_PID_ETY:\r\nif (!~(mask | RQFCR_PID_PORT_MASK))\r\nreturn;\r\nif (!mask)\r\nmask = ~0;\r\nelse\r\nmask |= RQFCR_PID_PORT_MASK;\r\nbreak;\r\ncase RQFCR_PID_DAH:\r\ncase RQFCR_PID_DAL:\r\ncase RQFCR_PID_SAH:\r\ncase RQFCR_PID_SAL:\r\nif (!(value | mask))\r\nreturn;\r\nmask |= RQFCR_PID_MAC_MASK;\r\nbreak;\r\ndefault:\r\nif (!~mask)\r\nreturn;\r\nif (!mask)\r\nmask = ~0;\r\nbreak;\r\n}\r\ngfar_set_general_attribute(value, mask, flag, tab);\r\n}\r\nstatic void gfar_set_basic_ip(struct ethtool_tcpip4_spec *value,\r\nstruct ethtool_tcpip4_spec *mask,\r\nstruct filer_table *tab)\r\n{\r\ngfar_set_attribute(value->ip4src, mask->ip4src, RQFCR_PID_SIA, tab);\r\ngfar_set_attribute(value->ip4dst, mask->ip4dst, RQFCR_PID_DIA, tab);\r\ngfar_set_attribute(value->pdst, mask->pdst, RQFCR_PID_DPT, tab);\r\ngfar_set_attribute(value->psrc, mask->psrc, RQFCR_PID_SPT, tab);\r\ngfar_set_attribute(value->tos, mask->tos, RQFCR_PID_TOS, tab);\r\n}\r\nstatic void gfar_set_user_ip(struct ethtool_usrip4_spec *value,\r\nstruct ethtool_usrip4_spec *mask,\r\nstruct filer_table *tab)\r\n{\r\ngfar_set_attribute(value->ip4src, mask->ip4src, RQFCR_PID_SIA, tab);\r\ngfar_set_attribute(value->ip4dst, mask->ip4dst, RQFCR_PID_DIA, tab);\r\ngfar_set_attribute(value->tos, mask->tos, RQFCR_PID_TOS, tab);\r\ngfar_set_attribute(value->proto, mask->proto, RQFCR_PID_L4P, tab);\r\ngfar_set_attribute(value->l4_4_bytes, mask->l4_4_bytes, RQFCR_PID_ARB,\r\ntab);\r\n}\r\nstatic void gfar_set_ether(struct ethhdr *value, struct ethhdr *mask,\r\nstruct filer_table *tab)\r\n{\r\nu32 upper_temp_mask = 0;\r\nu32 lower_temp_mask = 0;\r\nif (!is_broadcast_ether_addr(mask->h_source)) {\r\nif (is_zero_ether_addr(mask->h_source)) {\r\nupper_temp_mask = 0xFFFFFFFF;\r\nlower_temp_mask = 0xFFFFFFFF;\r\n} else {\r\nupper_temp_mask = mask->h_source[0] << 16 |\r\nmask->h_source[1] << 8 |\r\nmask->h_source[2];\r\nlower_temp_mask = mask->h_source[3] << 16 |\r\nmask->h_source[4] << 8 |\r\nmask->h_source[5];\r\n}\r\ngfar_set_attribute(value->h_source[0] << 16 |\r\nvalue->h_source[1] << 8 |\r\nvalue->h_source[2],\r\nupper_temp_mask, RQFCR_PID_SAH, tab);\r\ngfar_set_attribute(value->h_source[3] << 16 |\r\nvalue->h_source[4] << 8 |\r\nvalue->h_source[5],\r\nlower_temp_mask, RQFCR_PID_SAL, tab);\r\n}\r\nif (!is_broadcast_ether_addr(mask->h_dest)) {\r\nif ((is_broadcast_ether_addr(value->h_dest) &&\r\nis_zero_ether_addr(mask->h_dest))) {\r\ngfar_set_parse_bits(RQFPR_EBC, RQFPR_EBC, tab);\r\n} else {\r\nif (is_zero_ether_addr(mask->h_dest)) {\r\nupper_temp_mask = 0xFFFFFFFF;\r\nlower_temp_mask = 0xFFFFFFFF;\r\n} else {\r\nupper_temp_mask = mask->h_dest[0] << 16 |\r\nmask->h_dest[1] << 8 |\r\nmask->h_dest[2];\r\nlower_temp_mask = mask->h_dest[3] << 16 |\r\nmask->h_dest[4] << 8 |\r\nmask->h_dest[5];\r\n}\r\ngfar_set_attribute(value->h_dest[0] << 16 |\r\nvalue->h_dest[1] << 8 |\r\nvalue->h_dest[2],\r\nupper_temp_mask, RQFCR_PID_DAH, tab);\r\ngfar_set_attribute(value->h_dest[3] << 16 |\r\nvalue->h_dest[4] << 8 |\r\nvalue->h_dest[5],\r\nlower_temp_mask, RQFCR_PID_DAL, tab);\r\n}\r\n}\r\ngfar_set_attribute(value->h_proto, mask->h_proto, RQFCR_PID_ETY, tab);\r\n}\r\nstatic int gfar_convert_to_filer(struct ethtool_rx_flow_spec *rule,\r\nstruct filer_table *tab)\r\n{\r\nu32 vlan = 0, vlan_mask = 0;\r\nu32 id = 0, id_mask = 0;\r\nu32 cfi = 0, cfi_mask = 0;\r\nu32 prio = 0, prio_mask = 0;\r\nu32 old_index = tab->index;\r\nif ((rule->flow_type & FLOW_EXT) && (rule->m_ext.vlan_tci != 0xFFFF)) {\r\nif (!rule->m_ext.vlan_tci)\r\nrule->m_ext.vlan_tci = 0xFFFF;\r\nvlan = RQFPR_VLN;\r\nvlan_mask = RQFPR_VLN;\r\nid = rule->h_ext.vlan_tci & VLAN_VID_MASK;\r\nid_mask = rule->m_ext.vlan_tci & VLAN_VID_MASK;\r\ncfi = rule->h_ext.vlan_tci & VLAN_CFI_MASK;\r\ncfi_mask = rule->m_ext.vlan_tci & VLAN_CFI_MASK;\r\nprio = (rule->h_ext.vlan_tci & VLAN_PRIO_MASK) >>\r\nVLAN_PRIO_SHIFT;\r\nprio_mask = (rule->m_ext.vlan_tci & VLAN_PRIO_MASK) >>\r\nVLAN_PRIO_SHIFT;\r\nif (cfi == VLAN_TAG_PRESENT && cfi_mask == VLAN_TAG_PRESENT) {\r\nvlan |= RQFPR_CFI;\r\nvlan_mask |= RQFPR_CFI;\r\n} else if (cfi != VLAN_TAG_PRESENT &&\r\ncfi_mask == VLAN_TAG_PRESENT) {\r\nvlan_mask |= RQFPR_CFI;\r\n}\r\n}\r\nswitch (rule->flow_type & ~FLOW_EXT) {\r\ncase TCP_V4_FLOW:\r\ngfar_set_parse_bits(RQFPR_IPV4 | RQFPR_TCP | vlan,\r\nRQFPR_IPV4 | RQFPR_TCP | vlan_mask, tab);\r\ngfar_set_basic_ip(&rule->h_u.tcp_ip4_spec,\r\n&rule->m_u.tcp_ip4_spec, tab);\r\nbreak;\r\ncase UDP_V4_FLOW:\r\ngfar_set_parse_bits(RQFPR_IPV4 | RQFPR_UDP | vlan,\r\nRQFPR_IPV4 | RQFPR_UDP | vlan_mask, tab);\r\ngfar_set_basic_ip(&rule->h_u.udp_ip4_spec,\r\n&rule->m_u.udp_ip4_spec, tab);\r\nbreak;\r\ncase SCTP_V4_FLOW:\r\ngfar_set_parse_bits(RQFPR_IPV4 | vlan, RQFPR_IPV4 | vlan_mask,\r\ntab);\r\ngfar_set_attribute(132, 0, RQFCR_PID_L4P, tab);\r\ngfar_set_basic_ip((struct ethtool_tcpip4_spec *)&rule->h_u,\r\n(struct ethtool_tcpip4_spec *)&rule->m_u,\r\ntab);\r\nbreak;\r\ncase IP_USER_FLOW:\r\ngfar_set_parse_bits(RQFPR_IPV4 | vlan, RQFPR_IPV4 | vlan_mask,\r\ntab);\r\ngfar_set_user_ip((struct ethtool_usrip4_spec *) &rule->h_u,\r\n(struct ethtool_usrip4_spec *) &rule->m_u,\r\ntab);\r\nbreak;\r\ncase ETHER_FLOW:\r\nif (vlan)\r\ngfar_set_parse_bits(vlan, vlan_mask, tab);\r\ngfar_set_ether((struct ethhdr *) &rule->h_u,\r\n(struct ethhdr *) &rule->m_u, tab);\r\nbreak;\r\ndefault:\r\nreturn -1;\r\n}\r\nif (vlan) {\r\ngfar_set_attribute(id, id_mask, RQFCR_PID_VID, tab);\r\ngfar_set_attribute(prio, prio_mask, RQFCR_PID_PRI, tab);\r\n}\r\nif (tab->index == old_index) {\r\ngfar_set_mask(0xFFFFFFFF, tab);\r\ntab->fe[tab->index].ctrl = 0x20;\r\ntab->fe[tab->index].prop = 0x0;\r\ntab->index++;\r\n}\r\ntab->fe[tab->index - 1].ctrl &= (~RQFCR_AND);\r\nif (rule->ring_cookie == RX_CLS_FLOW_DISC)\r\ntab->fe[tab->index - 1].ctrl |= RQFCR_RJE;\r\nelse\r\ntab->fe[tab->index - 1].ctrl |= (rule->ring_cookie << 10);\r\nif (tab->index > (old_index + 2)) {\r\ntab->fe[old_index + 1].ctrl |= RQFCR_CLE;\r\ntab->fe[tab->index - 1].ctrl |= RQFCR_CLE;\r\n}\r\nif (tab->index > MAX_FILER_CACHE_IDX - 1)\r\nreturn -EBUSY;\r\nreturn 0;\r\n}\r\nstatic void gfar_copy_filer_entries(struct gfar_filer_entry dst[0],\r\nstruct gfar_filer_entry src[0], s32 size)\r\n{\r\nwhile (size > 0) {\r\nsize--;\r\ndst[size].ctrl = src[size].ctrl;\r\ndst[size].prop = src[size].prop;\r\n}\r\n}\r\nstatic int gfar_trim_filer_entries(u32 begin, u32 end, struct filer_table *tab)\r\n{\r\nint length;\r\nif (end > MAX_FILER_CACHE_IDX || end < begin)\r\nreturn -EINVAL;\r\nend++;\r\nlength = end - begin;\r\nwhile (end < tab->index) {\r\ntab->fe[begin].ctrl = tab->fe[end].ctrl;\r\ntab->fe[begin++].prop = tab->fe[end++].prop;\r\n}\r\nwhile (begin < tab->index) {\r\ntab->fe[begin].ctrl = 0x60;\r\ntab->fe[begin].prop = 0xFFFFFFFF;\r\nbegin++;\r\n}\r\ntab->index -= length;\r\nreturn 0;\r\n}\r\nstatic int gfar_expand_filer_entries(u32 begin, u32 length,\r\nstruct filer_table *tab)\r\n{\r\nif (length == 0 || length + tab->index > MAX_FILER_CACHE_IDX ||\r\nbegin > MAX_FILER_CACHE_IDX)\r\nreturn -EINVAL;\r\ngfar_copy_filer_entries(&(tab->fe[begin + length]), &(tab->fe[begin]),\r\ntab->index - length + 1);\r\ntab->index += length;\r\nreturn 0;\r\n}\r\nstatic int gfar_get_next_cluster_start(int start, struct filer_table *tab)\r\n{\r\nfor (; (start < tab->index) && (start < MAX_FILER_CACHE_IDX - 1);\r\nstart++) {\r\nif ((tab->fe[start].ctrl & (RQFCR_AND | RQFCR_CLE)) ==\r\n(RQFCR_AND | RQFCR_CLE))\r\nreturn start;\r\n}\r\nreturn -1;\r\n}\r\nstatic int gfar_get_next_cluster_end(int start, struct filer_table *tab)\r\n{\r\nfor (; (start < tab->index) && (start < MAX_FILER_CACHE_IDX - 1);\r\nstart++) {\r\nif ((tab->fe[start].ctrl & (RQFCR_AND | RQFCR_CLE)) ==\r\n(RQFCR_CLE))\r\nreturn start;\r\n}\r\nreturn -1;\r\n}\r\nstatic void gfar_cluster_filer(struct filer_table *tab)\r\n{\r\ns32 i = -1, j, iend, jend;\r\nwhile ((i = gfar_get_next_cluster_start(++i, tab)) != -1) {\r\nj = i;\r\nwhile ((j = gfar_get_next_cluster_start(++j, tab)) != -1) {\r\nif (tab->fe[i].ctrl != tab->fe[j].ctrl)\r\nbreak;\r\nif (tab->fe[i].prop != tab->fe[j].prop)\r\nbreak;\r\nif (tab->fe[i - 1].ctrl != tab->fe[j - 1].ctrl)\r\nbreak;\r\nif (tab->fe[i - 1].prop != tab->fe[j - 1].prop)\r\nbreak;\r\niend = gfar_get_next_cluster_end(i, tab);\r\njend = gfar_get_next_cluster_end(j, tab);\r\nif (jend == -1 || iend == -1)\r\nbreak;\r\nif (gfar_expand_filer_entries(iend, (jend - j), tab) ==\r\n-EINVAL)\r\nbreak;\r\ngfar_copy_filer_entries(&(tab->fe[iend + 1]),\r\n&(tab->fe[jend + 1]), jend - j);\r\nif (gfar_trim_filer_entries(jend - 1,\r\njend + (jend - j),\r\ntab) == -EINVAL)\r\nreturn;\r\ntab->fe[iend].ctrl &= ~(RQFCR_CLE);\r\n}\r\n}\r\n}\r\nstatic void gfar_swap_bits(struct gfar_filer_entry *a1,\r\nstruct gfar_filer_entry *a2,\r\nstruct gfar_filer_entry *b1,\r\nstruct gfar_filer_entry *b2, u32 mask)\r\n{\r\nu32 temp[4];\r\ntemp[0] = a1->ctrl & mask;\r\ntemp[1] = a2->ctrl & mask;\r\ntemp[2] = b1->ctrl & mask;\r\ntemp[3] = b2->ctrl & mask;\r\na1->ctrl &= ~mask;\r\na2->ctrl &= ~mask;\r\nb1->ctrl &= ~mask;\r\nb2->ctrl &= ~mask;\r\na1->ctrl |= temp[1];\r\na2->ctrl |= temp[0];\r\nb1->ctrl |= temp[3];\r\nb2->ctrl |= temp[2];\r\n}\r\nstatic u32 gfar_generate_mask_table(struct gfar_mask_entry *mask_table,\r\nstruct filer_table *tab)\r\n{\r\nu32 i, and_index = 0, block_index = 1;\r\nfor (i = 0; i < tab->index; i++) {\r\nif (!(tab->fe[i].ctrl & 0xF)) {\r\nmask_table[and_index].mask = tab->fe[i].prop;\r\nmask_table[and_index].start = i;\r\nmask_table[and_index].block = block_index;\r\nif (and_index >= 1)\r\nmask_table[and_index - 1].end = i - 1;\r\nand_index++;\r\n}\r\nif (tab->fe[i].ctrl & RQFCR_CLE)\r\nblock_index++;\r\nif (!(tab->fe[i].ctrl & RQFCR_AND))\r\nblock_index++;\r\n}\r\nmask_table[and_index - 1].end = i - 1;\r\nreturn and_index;\r\n}\r\nstatic void gfar_sort_mask_table(struct gfar_mask_entry *mask_table,\r\nstruct filer_table *temp_table, u32 and_index)\r\n{\r\nint (*gfar_comp)(const void *, const void *);\r\nu32 i, size = 0, start = 0, prev = 1;\r\nu32 old_first, old_last, new_first, new_last;\r\ngfar_comp = &gfar_comp_desc;\r\nfor (i = 0; i < and_index; i++) {\r\nif (prev != mask_table[i].block) {\r\nold_first = mask_table[start].start + 1;\r\nold_last = mask_table[i - 1].end;\r\nsort(mask_table + start, size,\r\nsizeof(struct gfar_mask_entry),\r\ngfar_comp, &gfar_swap);\r\nif (gfar_comp == gfar_comp_desc)\r\ngfar_comp = &gfar_comp_asc;\r\nelse\r\ngfar_comp = &gfar_comp_desc;\r\nnew_first = mask_table[start].start + 1;\r\nnew_last = mask_table[i - 1].end;\r\ngfar_swap_bits(&temp_table->fe[new_first],\r\n&temp_table->fe[old_first],\r\n&temp_table->fe[new_last],\r\n&temp_table->fe[old_last],\r\nRQFCR_QUEUE | RQFCR_CLE |\r\nRQFCR_RJE | RQFCR_AND);\r\nstart = i;\r\nsize = 0;\r\n}\r\nsize++;\r\nprev = mask_table[i].block;\r\n}\r\n}\r\nstatic int gfar_optimize_filer_masks(struct filer_table *tab)\r\n{\r\nstruct filer_table *temp_table;\r\nstruct gfar_mask_entry *mask_table;\r\nu32 and_index = 0, previous_mask = 0, i = 0, j = 0, size = 0;\r\ns32 ret = 0;\r\ntemp_table = kmemdup(tab, sizeof(*temp_table), GFP_KERNEL);\r\nif (temp_table == NULL)\r\nreturn -ENOMEM;\r\nmask_table = kcalloc(MAX_FILER_CACHE_IDX / 2 + 1,\r\nsizeof(struct gfar_mask_entry), GFP_KERNEL);\r\nif (mask_table == NULL) {\r\nret = -ENOMEM;\r\ngoto end;\r\n}\r\nand_index = gfar_generate_mask_table(mask_table, tab);\r\ngfar_sort_mask_table(mask_table, temp_table, and_index);\r\nfor (i = 0; i < and_index; i++) {\r\nsize = mask_table[i].end - mask_table[i].start + 1;\r\ngfar_copy_filer_entries(&(tab->fe[j]),\r\n&(temp_table->fe[mask_table[i].start]), size);\r\nj += size;\r\n}\r\nfor (i = 0; i < tab->index && i < MAX_FILER_CACHE_IDX; i++) {\r\nif (tab->fe[i].ctrl == 0x80) {\r\nprevious_mask = i++;\r\nbreak;\r\n}\r\n}\r\nfor (; i < tab->index && i < MAX_FILER_CACHE_IDX; i++) {\r\nif (tab->fe[i].ctrl == 0x80) {\r\nif (tab->fe[i].prop == tab->fe[previous_mask].prop) {\r\ngfar_trim_filer_entries(i, i, tab);\r\n} else\r\nprevious_mask = i;\r\n}\r\n}\r\nkfree(mask_table);\r\nend: kfree(temp_table);\r\nreturn ret;\r\n}\r\nstatic int gfar_write_filer_table(struct gfar_private *priv,\r\nstruct filer_table *tab)\r\n{\r\nu32 i = 0;\r\nif (tab->index > MAX_FILER_IDX - 1)\r\nreturn -EBUSY;\r\nlock_rx_qs(priv);\r\nfor (; i < MAX_FILER_IDX - 1 && (tab->fe[i].ctrl | tab->fe[i].ctrl);\r\ni++)\r\ngfar_write_filer(priv, i, tab->fe[i].ctrl, tab->fe[i].prop);\r\nfor (; i < MAX_FILER_IDX - 1; i++)\r\ngfar_write_filer(priv, i, 0x60, 0xFFFFFFFF);\r\ngfar_write_filer(priv, i, 0x20, 0x0);\r\nunlock_rx_qs(priv);\r\nreturn 0;\r\n}\r\nstatic int gfar_check_capability(struct ethtool_rx_flow_spec *flow,\r\nstruct gfar_private *priv)\r\n{\r\nif (flow->flow_type & FLOW_EXT) {\r\nif (~flow->m_ext.data[0] || ~flow->m_ext.data[1])\r\nnetdev_warn(priv->ndev,\r\n"User-specific data not supported!\n");\r\nif (~flow->m_ext.vlan_etype)\r\nnetdev_warn(priv->ndev,\r\n"VLAN-etype not supported!\n");\r\n}\r\nif (flow->flow_type == IP_USER_FLOW)\r\nif (flow->h_u.usr_ip4_spec.ip_ver != ETH_RX_NFC_IP4)\r\nnetdev_warn(priv->ndev,\r\n"IP-Version differing from IPv4 not supported!\n");\r\nreturn 0;\r\n}\r\nstatic int gfar_process_filer_changes(struct gfar_private *priv)\r\n{\r\nstruct ethtool_flow_spec_container *j;\r\nstruct filer_table *tab;\r\ns32 i = 0;\r\ns32 ret = 0;\r\ntab = kzalloc(sizeof(*tab), GFP_KERNEL);\r\nif (tab == NULL)\r\nreturn -ENOMEM;\r\nlist_for_each_entry(j, &priv->rx_list.list, list) {\r\nret = gfar_convert_to_filer(&j->fs, tab);\r\nif (ret == -EBUSY) {\r\nnetdev_err(priv->ndev,\r\n"Rule not added: No free space!\n");\r\ngoto end;\r\n}\r\nif (ret == -1) {\r\nnetdev_err(priv->ndev,\r\n"Rule not added: Unsupported Flow-type!\n");\r\ngoto end;\r\n}\r\n}\r\ni = tab->index;\r\ngfar_cluster_filer(tab);\r\ngfar_optimize_filer_masks(tab);\r\npr_debug("\tSummary:\n"\r\n"\tData on hardware: %d\n"\r\n"\tCompression rate: %d%%\n",\r\ntab->index, 100 - (100 * tab->index) / i);\r\nret = gfar_write_filer_table(priv, tab);\r\nif (ret == -EBUSY) {\r\nnetdev_err(priv->ndev, "Rule not added: No free space!\n");\r\ngoto end;\r\n}\r\nend:\r\nkfree(tab);\r\nreturn ret;\r\n}\r\nstatic void gfar_invert_masks(struct ethtool_rx_flow_spec *flow)\r\n{\r\nu32 i = 0;\r\nfor (i = 0; i < sizeof(flow->m_u); i++)\r\nflow->m_u.hdata[i] ^= 0xFF;\r\nflow->m_ext.vlan_etype ^= 0xFFFF;\r\nflow->m_ext.vlan_tci ^= 0xFFFF;\r\nflow->m_ext.data[0] ^= ~0;\r\nflow->m_ext.data[1] ^= ~0;\r\n}\r\nstatic int gfar_add_cls(struct gfar_private *priv,\r\nstruct ethtool_rx_flow_spec *flow)\r\n{\r\nstruct ethtool_flow_spec_container *temp, *comp;\r\nint ret = 0;\r\ntemp = kmalloc(sizeof(*temp), GFP_KERNEL);\r\nif (temp == NULL)\r\nreturn -ENOMEM;\r\nmemcpy(&temp->fs, flow, sizeof(temp->fs));\r\ngfar_invert_masks(&temp->fs);\r\nret = gfar_check_capability(&temp->fs, priv);\r\nif (ret)\r\ngoto clean_mem;\r\nif (list_empty(&priv->rx_list.list)) {\r\nret = gfar_check_filer_hardware(priv);\r\nif (ret != 0)\r\ngoto clean_mem;\r\nlist_add(&temp->list, &priv->rx_list.list);\r\ngoto process;\r\n} else {\r\nlist_for_each_entry(comp, &priv->rx_list.list, list) {\r\nif (comp->fs.location > flow->location) {\r\nlist_add_tail(&temp->list, &comp->list);\r\ngoto process;\r\n}\r\nif (comp->fs.location == flow->location) {\r\nnetdev_err(priv->ndev,\r\n"Rule not added: ID %d not free!\n",\r\nflow->location);\r\nret = -EBUSY;\r\ngoto clean_mem;\r\n}\r\n}\r\nlist_add_tail(&temp->list, &priv->rx_list.list);\r\n}\r\nprocess:\r\nret = gfar_process_filer_changes(priv);\r\nif (ret)\r\ngoto clean_list;\r\npriv->rx_list.count++;\r\nreturn ret;\r\nclean_list:\r\nlist_del(&temp->list);\r\nclean_mem:\r\nkfree(temp);\r\nreturn ret;\r\n}\r\nstatic int gfar_del_cls(struct gfar_private *priv, u32 loc)\r\n{\r\nstruct ethtool_flow_spec_container *comp;\r\nu32 ret = -EINVAL;\r\nif (list_empty(&priv->rx_list.list))\r\nreturn ret;\r\nlist_for_each_entry(comp, &priv->rx_list.list, list) {\r\nif (comp->fs.location == loc) {\r\nlist_del(&comp->list);\r\nkfree(comp);\r\npriv->rx_list.count--;\r\ngfar_process_filer_changes(priv);\r\nret = 0;\r\nbreak;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int gfar_get_cls(struct gfar_private *priv, struct ethtool_rxnfc *cmd)\r\n{\r\nstruct ethtool_flow_spec_container *comp;\r\nu32 ret = -EINVAL;\r\nlist_for_each_entry(comp, &priv->rx_list.list, list) {\r\nif (comp->fs.location == cmd->fs.location) {\r\nmemcpy(&cmd->fs, &comp->fs, sizeof(cmd->fs));\r\ngfar_invert_masks(&cmd->fs);\r\nret = 0;\r\nbreak;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int gfar_get_cls_all(struct gfar_private *priv,\r\nstruct ethtool_rxnfc *cmd, u32 *rule_locs)\r\n{\r\nstruct ethtool_flow_spec_container *comp;\r\nu32 i = 0;\r\nlist_for_each_entry(comp, &priv->rx_list.list, list) {\r\nif (i == cmd->rule_cnt)\r\nreturn -EMSGSIZE;\r\nrule_locs[i] = comp->fs.location;\r\ni++;\r\n}\r\ncmd->data = MAX_FILER_IDX;\r\ncmd->rule_cnt = i;\r\nreturn 0;\r\n}\r\nstatic int gfar_set_nfc(struct net_device *dev, struct ethtool_rxnfc *cmd)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nint ret = 0;\r\nmutex_lock(&priv->rx_queue_access);\r\nswitch (cmd->cmd) {\r\ncase ETHTOOL_SRXFH:\r\nret = gfar_set_hash_opts(priv, cmd);\r\nbreak;\r\ncase ETHTOOL_SRXCLSRLINS:\r\nif ((cmd->fs.ring_cookie != RX_CLS_FLOW_DISC &&\r\ncmd->fs.ring_cookie >= priv->num_rx_queues) ||\r\ncmd->fs.location >= MAX_FILER_IDX) {\r\nret = -EINVAL;\r\nbreak;\r\n}\r\nret = gfar_add_cls(priv, &cmd->fs);\r\nbreak;\r\ncase ETHTOOL_SRXCLSRLDEL:\r\nret = gfar_del_cls(priv, cmd->fs.location);\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\n}\r\nmutex_unlock(&priv->rx_queue_access);\r\nreturn ret;\r\n}\r\nstatic int gfar_get_nfc(struct net_device *dev, struct ethtool_rxnfc *cmd,\r\nu32 *rule_locs)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nint ret = 0;\r\nswitch (cmd->cmd) {\r\ncase ETHTOOL_GRXRINGS:\r\ncmd->data = priv->num_rx_queues;\r\nbreak;\r\ncase ETHTOOL_GRXCLSRLCNT:\r\ncmd->rule_cnt = priv->rx_list.count;\r\nbreak;\r\ncase ETHTOOL_GRXCLSRULE:\r\nret = gfar_get_cls(priv, cmd);\r\nbreak;\r\ncase ETHTOOL_GRXCLSRLALL:\r\nret = gfar_get_cls_all(priv, cmd, rule_locs);\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int gfar_get_ts_info(struct net_device *dev,\r\nstruct ethtool_ts_info *info)\r\n{\r\nstruct gfar_private *priv = netdev_priv(dev);\r\nif (!(priv->device_flags & FSL_GIANFAR_DEV_HAS_TIMER)) {\r\ninfo->so_timestamping = SOF_TIMESTAMPING_RX_SOFTWARE |\r\nSOF_TIMESTAMPING_SOFTWARE;\r\ninfo->phc_index = -1;\r\nreturn 0;\r\n}\r\ninfo->so_timestamping = SOF_TIMESTAMPING_TX_HARDWARE |\r\nSOF_TIMESTAMPING_RX_HARDWARE |\r\nSOF_TIMESTAMPING_RAW_HARDWARE;\r\ninfo->phc_index = gfar_phc_index;\r\ninfo->tx_types = (1 << HWTSTAMP_TX_OFF) |\r\n(1 << HWTSTAMP_TX_ON);\r\ninfo->rx_filters = (1 << HWTSTAMP_FILTER_NONE) |\r\n(1 << HWTSTAMP_FILTER_ALL);\r\nreturn 0;\r\n}
