static int rps_sock_flow_sysctl(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nunsigned int orig_size, size;\r\nint ret, i;\r\nstruct ctl_table tmp = {\r\n.data = &size,\r\n.maxlen = sizeof(size),\r\n.mode = table->mode\r\n};\r\nstruct rps_sock_flow_table *orig_sock_table, *sock_table;\r\nstatic DEFINE_MUTEX(sock_flow_mutex);\r\nmutex_lock(&sock_flow_mutex);\r\norig_sock_table = rcu_dereference_protected(rps_sock_flow_table,\r\nlockdep_is_held(&sock_flow_mutex));\r\nsize = orig_size = orig_sock_table ? orig_sock_table->mask + 1 : 0;\r\nret = proc_dointvec(&tmp, write, buffer, lenp, ppos);\r\nif (write) {\r\nif (size) {\r\nif (size > 1<<30) {\r\nmutex_unlock(&sock_flow_mutex);\r\nreturn -EINVAL;\r\n}\r\nsize = roundup_pow_of_two(size);\r\nif (size != orig_size) {\r\nsock_table =\r\nvmalloc(RPS_SOCK_FLOW_TABLE_SIZE(size));\r\nif (!sock_table) {\r\nmutex_unlock(&sock_flow_mutex);\r\nreturn -ENOMEM;\r\n}\r\nsock_table->mask = size - 1;\r\n} else\r\nsock_table = orig_sock_table;\r\nfor (i = 0; i < size; i++)\r\nsock_table->ents[i] = RPS_NO_CPU;\r\n} else\r\nsock_table = NULL;\r\nif (sock_table != orig_sock_table) {\r\nrcu_assign_pointer(rps_sock_flow_table, sock_table);\r\nif (sock_table)\r\nstatic_key_slow_inc(&rps_needed);\r\nif (orig_sock_table) {\r\nstatic_key_slow_dec(&rps_needed);\r\nsynchronize_rcu();\r\nvfree(orig_sock_table);\r\n}\r\n}\r\n}\r\nmutex_unlock(&sock_flow_mutex);\r\nreturn ret;\r\n}\r\nstatic int flow_limit_cpu_sysctl(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp,\r\nloff_t *ppos)\r\n{\r\nstruct sd_flow_limit *cur;\r\nstruct softnet_data *sd;\r\ncpumask_var_t mask;\r\nint i, len, ret = 0;\r\nif (!alloc_cpumask_var(&mask, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nif (write) {\r\nret = cpumask_parse_user(buffer, *lenp, mask);\r\nif (ret)\r\ngoto done;\r\nmutex_lock(&flow_limit_update_mutex);\r\nlen = sizeof(*cur) + netdev_flow_limit_table_len;\r\nfor_each_possible_cpu(i) {\r\nsd = &per_cpu(softnet_data, i);\r\ncur = rcu_dereference_protected(sd->flow_limit,\r\nlockdep_is_held(&flow_limit_update_mutex));\r\nif (cur && !cpumask_test_cpu(i, mask)) {\r\nRCU_INIT_POINTER(sd->flow_limit, NULL);\r\nsynchronize_rcu();\r\nkfree(cur);\r\n} else if (!cur && cpumask_test_cpu(i, mask)) {\r\ncur = kzalloc(len, GFP_KERNEL);\r\nif (!cur) {\r\nret = -ENOMEM;\r\ngoto write_unlock;\r\n}\r\ncur->num_buckets = netdev_flow_limit_table_len;\r\nrcu_assign_pointer(sd->flow_limit, cur);\r\n}\r\n}\r\nwrite_unlock:\r\nmutex_unlock(&flow_limit_update_mutex);\r\n} else {\r\nchar kbuf[128];\r\nif (*ppos || !*lenp) {\r\n*lenp = 0;\r\ngoto done;\r\n}\r\ncpumask_clear(mask);\r\nrcu_read_lock();\r\nfor_each_possible_cpu(i) {\r\nsd = &per_cpu(softnet_data, i);\r\nif (rcu_dereference(sd->flow_limit))\r\ncpumask_set_cpu(i, mask);\r\n}\r\nrcu_read_unlock();\r\nlen = min(sizeof(kbuf) - 1, *lenp);\r\nlen = cpumask_scnprintf(kbuf, len, mask);\r\nif (!len) {\r\n*lenp = 0;\r\ngoto done;\r\n}\r\nif (len < *lenp)\r\nkbuf[len++] = '\n';\r\nif (copy_to_user(buffer, kbuf, len)) {\r\nret = -EFAULT;\r\ngoto done;\r\n}\r\n*lenp = len;\r\n*ppos += len;\r\n}\r\ndone:\r\nfree_cpumask_var(mask);\r\nreturn ret;\r\n}\r\nstatic int flow_limit_table_len_sysctl(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp,\r\nloff_t *ppos)\r\n{\r\nunsigned int old, *ptr;\r\nint ret;\r\nmutex_lock(&flow_limit_update_mutex);\r\nptr = table->data;\r\nold = *ptr;\r\nret = proc_dointvec(table, write, buffer, lenp, ppos);\r\nif (!ret && write && !is_power_of_2(*ptr)) {\r\n*ptr = old;\r\nret = -EINVAL;\r\n}\r\nmutex_unlock(&flow_limit_update_mutex);\r\nreturn ret;\r\n}\r\nstatic int set_default_qdisc(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nchar id[IFNAMSIZ];\r\nstruct ctl_table tbl = {\r\n.data = id,\r\n.maxlen = IFNAMSIZ,\r\n};\r\nint ret;\r\nqdisc_get_default(id, IFNAMSIZ);\r\nret = proc_dostring(&tbl, write, buffer, lenp, ppos);\r\nif (write && ret == 0)\r\nret = qdisc_set_default(id);\r\nreturn ret;\r\n}\r\nstatic __net_init int sysctl_core_net_init(struct net *net)\r\n{\r\nstruct ctl_table *tbl;\r\nnet->core.sysctl_somaxconn = SOMAXCONN;\r\ntbl = netns_core_table;\r\nif (!net_eq(net, &init_net)) {\r\ntbl = kmemdup(tbl, sizeof(netns_core_table), GFP_KERNEL);\r\nif (tbl == NULL)\r\ngoto err_dup;\r\ntbl[0].data = &net->core.sysctl_somaxconn;\r\nif (net->user_ns != &init_user_ns) {\r\ntbl[0].procname = NULL;\r\n}\r\n}\r\nnet->core.sysctl_hdr = register_net_sysctl(net, "net/core", tbl);\r\nif (net->core.sysctl_hdr == NULL)\r\ngoto err_reg;\r\nreturn 0;\r\nerr_reg:\r\nif (tbl != netns_core_table)\r\nkfree(tbl);\r\nerr_dup:\r\nreturn -ENOMEM;\r\n}\r\nstatic __net_exit void sysctl_core_net_exit(struct net *net)\r\n{\r\nstruct ctl_table *tbl;\r\ntbl = net->core.sysctl_hdr->ctl_table_arg;\r\nunregister_net_sysctl_table(net->core.sysctl_hdr);\r\nBUG_ON(tbl == netns_core_table);\r\nkfree(tbl);\r\n}\r\nstatic __init int sysctl_core_init(void)\r\n{\r\nregister_net_sysctl(&init_net, "net/core", net_core_table);\r\nreturn register_pernet_subsys(&sysctl_core_ops);\r\n}
