static inline struct dscc4_dev_priv *dscc4_priv(struct net_device *dev)\r\n{\r\nreturn dev_to_hdlc(dev)->priv;\r\n}\r\nstatic inline struct net_device *dscc4_to_dev(struct dscc4_dev_priv *p)\r\n{\r\nreturn p->dev;\r\n}\r\nstatic void scc_patchl(u32 mask, u32 value, struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev, int offset)\r\n{\r\nu32 state;\r\nstate = dpriv->scc_regs[offset >> 2];\r\nstate &= ~mask;\r\nstate |= value;\r\ndpriv->scc_regs[offset >> 2] = state;\r\nwritel(state, dpriv->base_addr + SCC_REG_START(dpriv) + offset);\r\n}\r\nstatic void scc_writel(u32 bits, struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev, int offset)\r\n{\r\ndpriv->scc_regs[offset >> 2] = bits;\r\nwritel(bits, dpriv->base_addr + SCC_REG_START(dpriv) + offset);\r\n}\r\nstatic inline u32 scc_readl(struct dscc4_dev_priv *dpriv, int offset)\r\n{\r\nreturn dpriv->scc_regs[offset >> 2];\r\n}\r\nstatic u32 scc_readl_star(struct dscc4_dev_priv *dpriv, struct net_device *dev)\r\n{\r\nreadl(dpriv->base_addr + SCC_REG_START(dpriv) + STAR);\r\nreturn readl(dpriv->base_addr + SCC_REG_START(dpriv) + STAR);\r\n}\r\nstatic inline void dscc4_do_tx(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\ndpriv->ltda = dpriv->tx_fd_dma +\r\n((dpriv->tx_current-1)%TX_RING_SIZE)*sizeof(struct TxFD);\r\nwritel(dpriv->ltda, dpriv->base_addr + CH0LTDA + dpriv->dev_id*4);\r\nreadl(dpriv->base_addr + CH0LTDA + dpriv->dev_id*4);\r\n}\r\nstatic inline void dscc4_rx_update(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\ndpriv->lrda = dpriv->rx_fd_dma +\r\n((dpriv->rx_dirty - 1)%RX_RING_SIZE)*sizeof(struct RxFD);\r\nwritel(dpriv->lrda, dpriv->base_addr + CH0LRDA + dpriv->dev_id*4);\r\n}\r\nstatic inline unsigned int dscc4_tx_done(struct dscc4_dev_priv *dpriv)\r\n{\r\nreturn dpriv->tx_current == dpriv->tx_dirty;\r\n}\r\nstatic inline unsigned int dscc4_tx_quiescent(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nreturn readl(dpriv->base_addr + CH0FTDA + dpriv->dev_id*4) == dpriv->ltda;\r\n}\r\nstatic int state_check(u32 state, struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev, const char *msg)\r\n{\r\nint ret = 0;\r\nif (debug > 1) {\r\nif (SOURCE_ID(state) != dpriv->dev_id) {\r\nprintk(KERN_DEBUG "%s (%s): Source Id=%d, state=%08x\n",\r\ndev->name, msg, SOURCE_ID(state), state );\r\nret = -1;\r\n}\r\nif (state & 0x0df80c00) {\r\nprintk(KERN_DEBUG "%s (%s): state=%08x (UFO alert)\n",\r\ndev->name, msg, state);\r\nret = -1;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic void dscc4_tx_print(struct net_device *dev,\r\nstruct dscc4_dev_priv *dpriv,\r\nchar *msg)\r\n{\r\nprintk(KERN_DEBUG "%s: tx_current=%02d tx_dirty=%02d (%s)\n",\r\ndev->name, dpriv->tx_current, dpriv->tx_dirty, msg);\r\n}\r\nstatic void dscc4_release_ring(struct dscc4_dev_priv *dpriv)\r\n{\r\nstruct pci_dev *pdev = dpriv->pci_priv->pdev;\r\nstruct TxFD *tx_fd = dpriv->tx_fd;\r\nstruct RxFD *rx_fd = dpriv->rx_fd;\r\nstruct sk_buff **skbuff;\r\nint i;\r\npci_free_consistent(pdev, TX_TOTAL_SIZE, tx_fd, dpriv->tx_fd_dma);\r\npci_free_consistent(pdev, RX_TOTAL_SIZE, rx_fd, dpriv->rx_fd_dma);\r\nskbuff = dpriv->tx_skbuff;\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nif (*skbuff) {\r\npci_unmap_single(pdev, le32_to_cpu(tx_fd->data),\r\n(*skbuff)->len, PCI_DMA_TODEVICE);\r\ndev_kfree_skb(*skbuff);\r\n}\r\nskbuff++;\r\ntx_fd++;\r\n}\r\nskbuff = dpriv->rx_skbuff;\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nif (*skbuff) {\r\npci_unmap_single(pdev, le32_to_cpu(rx_fd->data),\r\nRX_MAX(HDLC_MAX_MRU), PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(*skbuff);\r\n}\r\nskbuff++;\r\nrx_fd++;\r\n}\r\n}\r\nstatic inline int try_get_rx_skb(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nunsigned int dirty = dpriv->rx_dirty%RX_RING_SIZE;\r\nstruct RxFD *rx_fd = dpriv->rx_fd + dirty;\r\nconst int len = RX_MAX(HDLC_MAX_MRU);\r\nstruct sk_buff *skb;\r\nint ret = 0;\r\nskb = dev_alloc_skb(len);\r\ndpriv->rx_skbuff[dirty] = skb;\r\nif (skb) {\r\nskb->protocol = hdlc_type_trans(skb, dev);\r\nrx_fd->data = cpu_to_le32(pci_map_single(dpriv->pci_priv->pdev,\r\nskb->data, len, PCI_DMA_FROMDEVICE));\r\n} else {\r\nrx_fd->data = 0;\r\nret = -1;\r\n}\r\nreturn ret;\r\n}\r\nstatic int dscc4_wait_ack_cec(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev, char *msg)\r\n{\r\ns8 i = 0;\r\ndo {\r\nif (!(scc_readl_star(dpriv, dev) & SccBusy)) {\r\nprintk(KERN_DEBUG "%s: %s ack (%d try)\n", dev->name,\r\nmsg, i);\r\ngoto done;\r\n}\r\nschedule_timeout_uninterruptible(10);\r\nrmb();\r\n} while (++i > 0);\r\nnetdev_err(dev, "%s timeout\n", msg);\r\ndone:\r\nreturn (i >= 0) ? i : -EAGAIN;\r\n}\r\nstatic int dscc4_do_action(struct net_device *dev, char *msg)\r\n{\r\nvoid __iomem *ioaddr = dscc4_priv(dev)->base_addr;\r\ns16 i = 0;\r\nwritel(Action, ioaddr + GCMDR);\r\nioaddr += GSTAR;\r\ndo {\r\nu32 state = readl(ioaddr);\r\nif (state & ArAck) {\r\nnetdev_dbg(dev, "%s ack\n", msg);\r\nwritel(ArAck, ioaddr);\r\ngoto done;\r\n} else if (state & Arf) {\r\nnetdev_err(dev, "%s failed\n", msg);\r\nwritel(Arf, ioaddr);\r\ni = -1;\r\ngoto done;\r\n}\r\nrmb();\r\n} while (++i > 0);\r\nnetdev_err(dev, "%s timeout\n", msg);\r\ndone:\r\nreturn i;\r\n}\r\nstatic inline int dscc4_xpr_ack(struct dscc4_dev_priv *dpriv)\r\n{\r\nint cur = dpriv->iqtx_current%IRQ_RING_SIZE;\r\ns8 i = 0;\r\ndo {\r\nif (!(dpriv->flags & (NeedIDR | NeedIDT)) ||\r\n(dpriv->iqtx[cur] & cpu_to_le32(Xpr)))\r\nbreak;\r\nsmp_rmb();\r\nschedule_timeout_uninterruptible(10);\r\n} while (++i > 0);\r\nreturn (i >= 0 ) ? i : -EAGAIN;\r\n}\r\nstatic inline void dscc4_rx_skb(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nstruct RxFD *rx_fd = dpriv->rx_fd + dpriv->rx_current%RX_RING_SIZE;\r\nstruct pci_dev *pdev = dpriv->pci_priv->pdev;\r\nstruct sk_buff *skb;\r\nint pkt_len;\r\nskb = dpriv->rx_skbuff[dpriv->rx_current++%RX_RING_SIZE];\r\nif (!skb) {\r\nprintk(KERN_DEBUG "%s: skb=0 (%s)\n", dev->name, __func__);\r\ngoto refill;\r\n}\r\npkt_len = TO_SIZE(le32_to_cpu(rx_fd->state2));\r\npci_unmap_single(pdev, le32_to_cpu(rx_fd->data),\r\nRX_MAX(HDLC_MAX_MRU), PCI_DMA_FROMDEVICE);\r\nif ((skb->data[--pkt_len] & FrameOk) == FrameOk) {\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += pkt_len;\r\nskb_put(skb, pkt_len);\r\nif (netif_running(dev))\r\nskb->protocol = hdlc_type_trans(skb, dev);\r\nnetif_rx(skb);\r\n} else {\r\nif (skb->data[pkt_len] & FrameRdo)\r\ndev->stats.rx_fifo_errors++;\r\nelse if (!(skb->data[pkt_len] & FrameCrc))\r\ndev->stats.rx_crc_errors++;\r\nelse if ((skb->data[pkt_len] & (FrameVfr | FrameRab)) !=\r\n(FrameVfr | FrameRab))\r\ndev->stats.rx_length_errors++;\r\ndev->stats.rx_errors++;\r\ndev_kfree_skb_irq(skb);\r\n}\r\nrefill:\r\nwhile ((dpriv->rx_dirty - dpriv->rx_current) % RX_RING_SIZE) {\r\nif (try_get_rx_skb(dpriv, dev) < 0)\r\nbreak;\r\ndpriv->rx_dirty++;\r\n}\r\ndscc4_rx_update(dpriv, dev);\r\nrx_fd->state2 = 0x00000000;\r\nrx_fd->end = cpu_to_le32(0xbabeface);\r\n}\r\nstatic void dscc4_free1(struct pci_dev *pdev)\r\n{\r\nstruct dscc4_pci_priv *ppriv;\r\nstruct dscc4_dev_priv *root;\r\nint i;\r\nppriv = pci_get_drvdata(pdev);\r\nroot = ppriv->root;\r\nfor (i = 0; i < dev_per_card; i++)\r\nunregister_hdlc_device(dscc4_to_dev(root + i));\r\npci_set_drvdata(pdev, NULL);\r\nfor (i = 0; i < dev_per_card; i++)\r\nfree_netdev(root[i].dev);\r\nkfree(root);\r\nkfree(ppriv);\r\n}\r\nstatic int dscc4_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct dscc4_pci_priv *priv;\r\nstruct dscc4_dev_priv *dpriv;\r\nvoid __iomem *ioaddr;\r\nint i, rc;\r\nprintk(KERN_DEBUG "%s", version);\r\nrc = pci_enable_device(pdev);\r\nif (rc < 0)\r\ngoto out;\r\nrc = pci_request_region(pdev, 0, "registers");\r\nif (rc < 0) {\r\npr_err("can't reserve MMIO region (regs)\n");\r\ngoto err_disable_0;\r\n}\r\nrc = pci_request_region(pdev, 1, "LBI interface");\r\nif (rc < 0) {\r\npr_err("can't reserve MMIO region (lbi)\n");\r\ngoto err_free_mmio_region_1;\r\n}\r\nioaddr = pci_ioremap_bar(pdev, 0);\r\nif (!ioaddr) {\r\npr_err("cannot remap MMIO region %llx @ %llx\n",\r\n(unsigned long long)pci_resource_len(pdev, 0),\r\n(unsigned long long)pci_resource_start(pdev, 0));\r\nrc = -EIO;\r\ngoto err_free_mmio_regions_2;\r\n}\r\nprintk(KERN_DEBUG "Siemens DSCC4, MMIO at %#llx (regs), %#llx (lbi), IRQ %d\n",\r\n(unsigned long long)pci_resource_start(pdev, 0),\r\n(unsigned long long)pci_resource_start(pdev, 1), pdev->irq);\r\npci_write_config_byte(pdev, PCI_LATENCY_TIMER, 0xf8);\r\npci_set_master(pdev);\r\nrc = dscc4_found1(pdev, ioaddr);\r\nif (rc < 0)\r\ngoto err_iounmap_3;\r\npriv = pci_get_drvdata(pdev);\r\nrc = request_irq(pdev->irq, dscc4_irq, IRQF_SHARED, DRV_NAME, priv->root);\r\nif (rc < 0) {\r\npr_warn("IRQ %d busy\n", pdev->irq);\r\ngoto err_release_4;\r\n}\r\nwritel(0x00000001, ioaddr + GMODE);\r\n{\r\nu32 bits;\r\nbits = (IRQ_RING_SIZE >> 5) - 1;\r\nbits |= bits << 4;\r\nbits |= bits << 8;\r\nbits |= bits << 16;\r\nwritel(bits, ioaddr + IQLENR0);\r\n}\r\nwritel((u32)(((IRQ_RING_SIZE >> 5) - 1) << 20), ioaddr + IQLENR1);\r\nrc = -ENOMEM;\r\npriv->iqcfg = (__le32 *) pci_alloc_consistent(pdev,\r\nIRQ_RING_SIZE*sizeof(__le32), &priv->iqcfg_dma);\r\nif (!priv->iqcfg)\r\ngoto err_free_irq_5;\r\nwritel(priv->iqcfg_dma, ioaddr + IQCFG);\r\nfor (i = 0; i < dev_per_card; i++) {\r\ndpriv = priv->root + i;\r\ndpriv->iqtx = (__le32 *) pci_alloc_consistent(pdev,\r\nIRQ_RING_SIZE*sizeof(u32), &dpriv->iqtx_dma);\r\nif (!dpriv->iqtx)\r\ngoto err_free_iqtx_6;\r\nwritel(dpriv->iqtx_dma, ioaddr + IQTX0 + i*4);\r\n}\r\nfor (i = 0; i < dev_per_card; i++) {\r\ndpriv = priv->root + i;\r\ndpriv->iqrx = (__le32 *) pci_alloc_consistent(pdev,\r\nIRQ_RING_SIZE*sizeof(u32), &dpriv->iqrx_dma);\r\nif (!dpriv->iqrx)\r\ngoto err_free_iqrx_7;\r\nwritel(dpriv->iqrx_dma, ioaddr + IQRX0 + i*4);\r\n}\r\nwritel(0x42104000, ioaddr + FIFOCR1);\r\nwritel(0xdef6d800, ioaddr + FIFOCR2);\r\nwritel(0x18181818, ioaddr + FIFOCR4);\r\nwritel(0x0000000e, ioaddr + FIFOCR3);\r\nwritel(0xff200001, ioaddr + GCMDR);\r\nrc = 0;\r\nout:\r\nreturn rc;\r\nerr_free_iqrx_7:\r\nwhile (--i >= 0) {\r\ndpriv = priv->root + i;\r\npci_free_consistent(pdev, IRQ_RING_SIZE*sizeof(u32),\r\ndpriv->iqrx, dpriv->iqrx_dma);\r\n}\r\ni = dev_per_card;\r\nerr_free_iqtx_6:\r\nwhile (--i >= 0) {\r\ndpriv = priv->root + i;\r\npci_free_consistent(pdev, IRQ_RING_SIZE*sizeof(u32),\r\ndpriv->iqtx, dpriv->iqtx_dma);\r\n}\r\npci_free_consistent(pdev, IRQ_RING_SIZE*sizeof(u32), priv->iqcfg,\r\npriv->iqcfg_dma);\r\nerr_free_irq_5:\r\nfree_irq(pdev->irq, priv->root);\r\nerr_release_4:\r\ndscc4_free1(pdev);\r\nerr_iounmap_3:\r\niounmap (ioaddr);\r\nerr_free_mmio_regions_2:\r\npci_release_region(pdev, 1);\r\nerr_free_mmio_region_1:\r\npci_release_region(pdev, 0);\r\nerr_disable_0:\r\npci_disable_device(pdev);\r\ngoto out;\r\n}\r\nstatic void dscc4_init_registers(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nscc_writel(0x00000000, dpriv, dev, CCR0);\r\nscc_writel(LengthCheck | (HDLC_MAX_MRU >> 5), dpriv, dev, RLCR);\r\nscc_writel(0x02408000, dpriv, dev, CCR1);\r\nscc_writel(0x00050008 & ~RxActivate, dpriv, dev, CCR2);\r\n}\r\nstatic inline int dscc4_set_quartz(struct dscc4_dev_priv *dpriv, int hz)\r\n{\r\nint ret = 0;\r\nif ((hz < 0) || (hz > DSCC4_HZ_MAX))\r\nret = -EOPNOTSUPP;\r\nelse\r\ndpriv->pci_priv->xtal_hz = hz;\r\nreturn ret;\r\n}\r\nstatic int dscc4_found1(struct pci_dev *pdev, void __iomem *ioaddr)\r\n{\r\nstruct dscc4_pci_priv *ppriv;\r\nstruct dscc4_dev_priv *root;\r\nint i, ret = -ENOMEM;\r\nroot = kcalloc(dev_per_card, sizeof(*root), GFP_KERNEL);\r\nif (!root)\r\ngoto err_out;\r\nfor (i = 0; i < dev_per_card; i++) {\r\nroot[i].dev = alloc_hdlcdev(root + i);\r\nif (!root[i].dev)\r\ngoto err_free_dev;\r\n}\r\nppriv = kzalloc(sizeof(*ppriv), GFP_KERNEL);\r\nif (!ppriv)\r\ngoto err_free_dev;\r\nppriv->root = root;\r\nspin_lock_init(&ppriv->lock);\r\nfor (i = 0; i < dev_per_card; i++) {\r\nstruct dscc4_dev_priv *dpriv = root + i;\r\nstruct net_device *d = dscc4_to_dev(dpriv);\r\nhdlc_device *hdlc = dev_to_hdlc(d);\r\nd->base_addr = (unsigned long)ioaddr;\r\nd->irq = pdev->irq;\r\nd->netdev_ops = &dscc4_ops;\r\nd->watchdog_timeo = TX_TIMEOUT;\r\nSET_NETDEV_DEV(d, &pdev->dev);\r\ndpriv->dev_id = i;\r\ndpriv->pci_priv = ppriv;\r\ndpriv->base_addr = ioaddr;\r\nspin_lock_init(&dpriv->lock);\r\nhdlc->xmit = dscc4_start_xmit;\r\nhdlc->attach = dscc4_hdlc_attach;\r\ndscc4_init_registers(dpriv, d);\r\ndpriv->parity = PARITY_CRC16_PR0_CCITT;\r\ndpriv->encoding = ENCODING_NRZ;\r\nret = dscc4_init_ring(d);\r\nif (ret < 0)\r\ngoto err_unregister;\r\nret = register_hdlc_device(d);\r\nif (ret < 0) {\r\npr_err("unable to register\n");\r\ndscc4_release_ring(dpriv);\r\ngoto err_unregister;\r\n}\r\n}\r\nret = dscc4_set_quartz(root, quartz);\r\nif (ret < 0)\r\ngoto err_unregister;\r\npci_set_drvdata(pdev, ppriv);\r\nreturn ret;\r\nerr_unregister:\r\nwhile (i-- > 0) {\r\ndscc4_release_ring(root + i);\r\nunregister_hdlc_device(dscc4_to_dev(root + i));\r\n}\r\nkfree(ppriv);\r\ni = dev_per_card;\r\nerr_free_dev:\r\nwhile (i-- > 0)\r\nfree_netdev(root[i].dev);\r\nkfree(root);\r\nerr_out:\r\nreturn ret;\r\n}\r\nstatic void dscc4_timer(unsigned long data)\r\n{\r\nstruct net_device *dev = (struct net_device *)data;\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\ngoto done;\r\ndone:\r\ndpriv->timer.expires = jiffies + TX_TIMEOUT;\r\nadd_timer(&dpriv->timer);\r\n}\r\nstatic void dscc4_tx_timeout(struct net_device *dev)\r\n{\r\n}\r\nstatic int dscc4_loopback_check(struct dscc4_dev_priv *dpriv)\r\n{\r\nsync_serial_settings *settings = &dpriv->settings;\r\nif (settings->loopback && (settings->clock_type != CLOCK_INT)) {\r\nstruct net_device *dev = dscc4_to_dev(dpriv);\r\nnetdev_info(dev, "loopback requires clock\n");\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void dscc4_pci_reset(struct pci_dev *pdev, void __iomem *ioaddr)\r\n{\r\nint i;\r\nmutex_lock(&dscc4_mutex);\r\nfor (i = 0; i < 16; i++)\r\npci_read_config_dword(pdev, i << 2, dscc4_pci_config_store + i);\r\nwritel(0x001c0000, ioaddr + GMODE);\r\nwritel(0x0000ffff, ioaddr + GPDIR);\r\nwritel(0x0000ffff, ioaddr + GPIM);\r\nwritel(0x0000ffff, ioaddr + GPDATA);\r\nwritel(0x00000000, ioaddr + GPDATA);\r\nreadl(ioaddr + GSTAR);\r\nschedule_timeout_uninterruptible(10);\r\nfor (i = 0; i < 16; i++)\r\npci_write_config_dword(pdev, i << 2, dscc4_pci_config_store[i]);\r\nmutex_unlock(&dscc4_mutex);\r\n}\r\nstatic int dscc4_open(struct net_device *dev)\r\n{\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\nstruct dscc4_pci_priv *ppriv;\r\nint ret = -EAGAIN;\r\nif ((dscc4_loopback_check(dpriv) < 0))\r\ngoto err;\r\nif ((ret = hdlc_open(dev)))\r\ngoto err;\r\nppriv = dpriv->pci_priv;\r\nif (dpriv->flags & FakeReset) {\r\ndpriv->flags &= ~FakeReset;\r\nscc_patchl(0, PowerUp, dpriv, dev, CCR0);\r\nscc_patchl(0, 0x00050000, dpriv, dev, CCR2);\r\nscc_writel(EventsMask, dpriv, dev, IMR);\r\nnetdev_info(dev, "up again\n");\r\ngoto done;\r\n}\r\ndpriv->flags = NeedIDR | NeedIDT;\r\nscc_patchl(0, PowerUp | Vis, dpriv, dev, CCR0);\r\nif (scc_readl_star(dpriv, dev) & SccBusy) {\r\nnetdev_err(dev, "busy - try later\n");\r\nret = -EAGAIN;\r\ngoto err_out;\r\n} else\r\nnetdev_info(dev, "available - good\n");\r\nscc_writel(EventsMask, dpriv, dev, IMR);\r\nscc_writel(TxSccRes | RxSccRes, dpriv, dev, CMDR);\r\nif ((ret = dscc4_wait_ack_cec(dpriv, dev, "Cec")) < 0)\r\ngoto err_disable_scc_events;\r\nif ((ret = dscc4_xpr_ack(dpriv)) < 0) {\r\npr_err("XPR timeout\n");\r\ngoto err_disable_scc_events;\r\n}\r\nif (debug > 2)\r\ndscc4_tx_print(dev, dpriv, "Open");\r\ndone:\r\nnetif_start_queue(dev);\r\ninit_timer(&dpriv->timer);\r\ndpriv->timer.expires = jiffies + 10*HZ;\r\ndpriv->timer.data = (unsigned long)dev;\r\ndpriv->timer.function = dscc4_timer;\r\nadd_timer(&dpriv->timer);\r\nnetif_carrier_on(dev);\r\nreturn 0;\r\nerr_disable_scc_events:\r\nscc_writel(0xffffffff, dpriv, dev, IMR);\r\nscc_patchl(PowerUp | Vis, 0, dpriv, dev, CCR0);\r\nerr_out:\r\nhdlc_close(dev);\r\nerr:\r\nreturn ret;\r\n}\r\nstatic int dscc4_tx_poll(struct dscc4_dev_priv *dpriv, struct net_device *dev)\r\n{\r\n}\r\nstatic netdev_tx_t dscc4_start_xmit(struct sk_buff *skb,\r\nstruct net_device *dev)\r\n{\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\nstruct dscc4_pci_priv *ppriv = dpriv->pci_priv;\r\nstruct TxFD *tx_fd;\r\nint next;\r\nnext = dpriv->tx_current%TX_RING_SIZE;\r\ndpriv->tx_skbuff[next] = skb;\r\ntx_fd = dpriv->tx_fd + next;\r\ntx_fd->state = FrameEnd | TO_STATE_TX(skb->len);\r\ntx_fd->data = cpu_to_le32(pci_map_single(ppriv->pdev, skb->data, skb->len,\r\nPCI_DMA_TODEVICE));\r\ntx_fd->complete = 0x00000000;\r\ntx_fd->jiffies = jiffies;\r\nmb();\r\n#ifdef DSCC4_POLLING\r\nspin_lock(&dpriv->lock);\r\nwhile (dscc4_tx_poll(dpriv, dev));\r\nspin_unlock(&dpriv->lock);\r\n#endif\r\nif (debug > 2)\r\ndscc4_tx_print(dev, dpriv, "Xmit");\r\nif (!((++dpriv->tx_current - dpriv->tx_dirty)%TX_RING_SIZE))\r\nnetif_stop_queue(dev);\r\nif (dscc4_tx_quiescent(dpriv, dev))\r\ndscc4_do_tx(dpriv, dev);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int dscc4_close(struct net_device *dev)\r\n{\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\ndel_timer_sync(&dpriv->timer);\r\nnetif_stop_queue(dev);\r\nscc_patchl(PowerUp | Vis, 0, dpriv, dev, CCR0);\r\nscc_patchl(0x00050000, 0, dpriv, dev, CCR2);\r\nscc_writel(0xffffffff, dpriv, dev, IMR);\r\ndpriv->flags |= FakeReset;\r\nhdlc_close(dev);\r\nreturn 0;\r\n}\r\nstatic inline int dscc4_check_clock_ability(int port)\r\n{\r\nint ret = 0;\r\n#ifdef CONFIG_DSCC4_PCISYNC\r\nif (port >= 2)\r\nret = -1;\r\n#endif\r\nreturn ret;\r\n}\r\nstatic int dscc4_set_clock(struct net_device *dev, u32 *bps, u32 *state)\r\n{\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\nint ret = -1;\r\nu32 brr;\r\n*state &= ~Ccr0ClockMask;\r\nif (*bps) {\r\nu32 n = 0, m = 0, divider;\r\nint xtal;\r\nxtal = dpriv->pci_priv->xtal_hz;\r\nif (!xtal)\r\ngoto done;\r\nif (dscc4_check_clock_ability(dpriv->dev_id) < 0)\r\ngoto done;\r\ndivider = xtal / *bps;\r\nif (divider > BRR_DIVIDER_MAX) {\r\ndivider >>= 4;\r\n*state |= 0x00000036;\r\n} else\r\n*state |= 0x00000037;\r\nif (divider >> 22) {\r\nn = 63;\r\nm = 15;\r\n} else if (divider) {\r\nm = 0;\r\nwhile (0xffffffc0 & divider) {\r\nm++;\r\ndivider >>= 1;\r\n}\r\nn = divider;\r\n}\r\nbrr = (m << 8) | n;\r\ndivider = n << m;\r\nif (!(*state & 0x00000001))\r\ndivider <<= 4;\r\n*bps = xtal / divider;\r\n} else {\r\nbrr = 0;\r\n}\r\nscc_writel(brr, dpriv, dev, BRR);\r\nret = 0;\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int dscc4_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nsync_serial_settings __user *line = ifr->ifr_settings.ifs_ifsu.sync;\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\nconst size_t size = sizeof(dpriv->settings);\r\nint ret = 0;\r\nif (dev->flags & IFF_UP)\r\nreturn -EBUSY;\r\nif (cmd != SIOCWANDEV)\r\nreturn -EOPNOTSUPP;\r\nswitch(ifr->ifr_settings.type) {\r\ncase IF_GET_IFACE:\r\nifr->ifr_settings.type = IF_IFACE_SYNC_SERIAL;\r\nif (ifr->ifr_settings.size < size) {\r\nifr->ifr_settings.size = size;\r\nreturn -ENOBUFS;\r\n}\r\nif (copy_to_user(line, &dpriv->settings, size))\r\nreturn -EFAULT;\r\nbreak;\r\ncase IF_IFACE_SYNC_SERIAL:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (dpriv->flags & FakeReset) {\r\nnetdev_info(dev, "please reset the device before this command\n");\r\nreturn -EPERM;\r\n}\r\nif (copy_from_user(&dpriv->settings, line, size))\r\nreturn -EFAULT;\r\nret = dscc4_set_iface(dpriv, dev);\r\nbreak;\r\ndefault:\r\nret = hdlc_ioctl(dev, ifr, cmd);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int dscc4_match(const struct thingie *p, int value)\r\n{\r\nint i;\r\nfor (i = 0; p[i].define != -1; i++) {\r\nif (value == p[i].define)\r\nbreak;\r\n}\r\nif (p[i].define == -1)\r\nreturn -1;\r\nelse\r\nreturn i;\r\n}\r\nstatic int dscc4_clock_setting(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nsync_serial_settings *settings = &dpriv->settings;\r\nint ret = -EOPNOTSUPP;\r\nu32 bps, state;\r\nbps = settings->clock_rate;\r\nstate = scc_readl(dpriv, CCR0);\r\nif (dscc4_set_clock(dev, &bps, &state) < 0)\r\ngoto done;\r\nif (bps) {\r\nprintk(KERN_DEBUG "%s: generated RxClk (DCE)\n", dev->name);\r\nif (settings->clock_rate != bps) {\r\nprintk(KERN_DEBUG "%s: clock adjusted (%08d -> %08d)\n",\r\ndev->name, settings->clock_rate, bps);\r\nsettings->clock_rate = bps;\r\n}\r\n} else {\r\nstate |= PowerUp | Vis;\r\nprintk(KERN_DEBUG "%s: external RxClk (DTE)\n", dev->name);\r\n}\r\nscc_writel(state, dpriv, dev, CCR0);\r\nret = 0;\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int dscc4_encoding_setting(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nstatic const struct thingie encoding[] = {\r\n{ ENCODING_NRZ, 0x00000000 },\r\n{ ENCODING_NRZI, 0x00200000 },\r\n{ ENCODING_FM_MARK, 0x00400000 },\r\n{ ENCODING_FM_SPACE, 0x00500000 },\r\n{ ENCODING_MANCHESTER, 0x00600000 },\r\n{ -1, 0}\r\n};\r\nint i, ret = 0;\r\ni = dscc4_match(encoding, dpriv->encoding);\r\nif (i >= 0)\r\nscc_patchl(EncodingMask, encoding[i].bits, dpriv, dev, CCR0);\r\nelse\r\nret = -EOPNOTSUPP;\r\nreturn ret;\r\n}\r\nstatic int dscc4_loopback_setting(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nsync_serial_settings *settings = &dpriv->settings;\r\nu32 state;\r\nstate = scc_readl(dpriv, CCR1);\r\nif (settings->loopback) {\r\nprintk(KERN_DEBUG "%s: loopback\n", dev->name);\r\nstate |= 0x00000100;\r\n} else {\r\nprintk(KERN_DEBUG "%s: normal\n", dev->name);\r\nstate &= ~0x00000100;\r\n}\r\nscc_writel(state, dpriv, dev, CCR1);\r\nreturn 0;\r\n}\r\nstatic int dscc4_crc_setting(struct dscc4_dev_priv *dpriv,\r\nstruct net_device *dev)\r\n{\r\nstatic const struct thingie crc[] = {\r\n{ PARITY_CRC16_PR0_CCITT, 0x00000010 },\r\n{ PARITY_CRC16_PR1_CCITT, 0x00000000 },\r\n{ PARITY_CRC32_PR0_CCITT, 0x00000011 },\r\n{ PARITY_CRC32_PR1_CCITT, 0x00000001 }\r\n};\r\nint i, ret = 0;\r\ni = dscc4_match(crc, dpriv->parity);\r\nif (i >= 0)\r\nscc_patchl(CrcMask, crc[i].bits, dpriv, dev, CCR1);\r\nelse\r\nret = -EOPNOTSUPP;\r\nreturn ret;\r\n}\r\nstatic int dscc4_set_iface(struct dscc4_dev_priv *dpriv, struct net_device *dev)\r\n{\r\nstruct {\r\nint (*action)(struct dscc4_dev_priv *, struct net_device *);\r\n} *p, do_setting[] = {\r\n{ dscc4_encoding_setting },\r\n{ dscc4_clock_setting },\r\n{ dscc4_loopback_setting },\r\n{ dscc4_crc_setting },\r\n{ NULL }\r\n};\r\nint ret = 0;\r\nfor (p = do_setting; p->action; p++) {\r\nif ((ret = p->action(dpriv, dev)) < 0)\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic irqreturn_t dscc4_irq(int irq, void *token)\r\n{\r\nstruct dscc4_dev_priv *root = token;\r\nstruct dscc4_pci_priv *priv;\r\nstruct net_device *dev;\r\nvoid __iomem *ioaddr;\r\nu32 state;\r\nunsigned long flags;\r\nint i, handled = 1;\r\npriv = root->pci_priv;\r\ndev = dscc4_to_dev(root);\r\nspin_lock_irqsave(&priv->lock, flags);\r\nioaddr = root->base_addr;\r\nstate = readl(ioaddr + GSTAR);\r\nif (!state) {\r\nhandled = 0;\r\ngoto out;\r\n}\r\nif (debug > 3)\r\nprintk(KERN_DEBUG "%s: GSTAR = 0x%08x\n", DRV_NAME, state);\r\nwritel(state, ioaddr + GSTAR);\r\nif (state & Arf) {\r\nnetdev_err(dev, "failure (Arf). Harass the maintainer\n");\r\ngoto out;\r\n}\r\nstate &= ~ArAck;\r\nif (state & Cfg) {\r\nif (debug > 0)\r\nprintk(KERN_DEBUG "%s: CfgIV\n", DRV_NAME);\r\nif (priv->iqcfg[priv->cfg_cur++%IRQ_RING_SIZE] & cpu_to_le32(Arf))\r\nnetdev_err(dev, "CFG failed\n");\r\nif (!(state &= ~Cfg))\r\ngoto out;\r\n}\r\nif (state & RxEvt) {\r\ni = dev_per_card - 1;\r\ndo {\r\ndscc4_rx_irq(priv, root + i);\r\n} while (--i >= 0);\r\nstate &= ~RxEvt;\r\n}\r\nif (state & TxEvt) {\r\ni = dev_per_card - 1;\r\ndo {\r\ndscc4_tx_irq(priv, root + i);\r\n} while (--i >= 0);\r\nstate &= ~TxEvt;\r\n}\r\nout:\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic void dscc4_tx_irq(struct dscc4_pci_priv *ppriv,\r\nstruct dscc4_dev_priv *dpriv)\r\n{\r\nstruct net_device *dev = dscc4_to_dev(dpriv);\r\nu32 state;\r\nint cur, loop = 0;\r\ntry:\r\ncur = dpriv->iqtx_current%IRQ_RING_SIZE;\r\nstate = le32_to_cpu(dpriv->iqtx[cur]);\r\nif (!state) {\r\nif (debug > 4)\r\nprintk(KERN_DEBUG "%s: Tx ISR = 0x%08x\n", dev->name,\r\nstate);\r\nif ((debug > 1) && (loop > 1))\r\nprintk(KERN_DEBUG "%s: Tx irq loop=%d\n", dev->name, loop);\r\nif (loop && netif_queue_stopped(dev))\r\nif ((dpriv->tx_current - dpriv->tx_dirty)%TX_RING_SIZE)\r\nnetif_wake_queue(dev);\r\nif (netif_running(dev) && dscc4_tx_quiescent(dpriv, dev) &&\r\n!dscc4_tx_done(dpriv))\r\ndscc4_do_tx(dpriv, dev);\r\nreturn;\r\n}\r\nloop++;\r\ndpriv->iqtx[cur] = 0;\r\ndpriv->iqtx_current++;\r\nif (state_check(state, dpriv, dev, "Tx") < 0)\r\nreturn;\r\nif (state & SccEvt) {\r\nif (state & Alls) {\r\nstruct sk_buff *skb;\r\nstruct TxFD *tx_fd;\r\nif (debug > 2)\r\ndscc4_tx_print(dev, dpriv, "Alls");\r\ncur = dpriv->tx_dirty%TX_RING_SIZE;\r\ntx_fd = dpriv->tx_fd + cur;\r\nskb = dpriv->tx_skbuff[cur];\r\nif (skb) {\r\npci_unmap_single(ppriv->pdev, le32_to_cpu(tx_fd->data),\r\nskb->len, PCI_DMA_TODEVICE);\r\nif (tx_fd->state & FrameEnd) {\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += skb->len;\r\n}\r\ndev_kfree_skb_irq(skb);\r\ndpriv->tx_skbuff[cur] = NULL;\r\n++dpriv->tx_dirty;\r\n} else {\r\nif (debug > 1)\r\nnetdev_err(dev, "Tx: NULL skb %d\n",\r\ncur);\r\n}\r\ntx_fd->data = tx_fd->next;\r\ntx_fd->state = FrameEnd | TO_STATE_TX(2*DUMMY_SKB_SIZE);\r\ntx_fd->complete = 0x00000000;\r\ntx_fd->jiffies = 0;\r\nif (!(state &= ~Alls))\r\ngoto try;\r\n}\r\nif (state & Xdu) {\r\nnetdev_err(dev, "Tx Data Underrun. Ask maintainer\n");\r\ndpriv->flags = NeedIDT;\r\nwritel(MTFi | Rdt,\r\ndpriv->base_addr + 0x0c*dpriv->dev_id + CH0CFG);\r\nwritel(Action, dpriv->base_addr + GCMDR);\r\nreturn;\r\n}\r\nif (state & Cts) {\r\nnetdev_info(dev, "CTS transition\n");\r\nif (!(state &= ~Cts))\r\ngoto try;\r\n}\r\nif (state & Xmr) {\r\nnetdev_err(dev, "Tx ReTx. Ask maintainer\n");\r\nif (!(state &= ~Xmr))\r\ngoto try;\r\n}\r\nif (state & Xpr) {\r\nvoid __iomem *scc_addr;\r\nunsigned long ring;\r\nint i;\r\nfor (i = 1; i; i <<= 1) {\r\nif (!(scc_readl_star(dpriv, dev) & SccBusy))\r\nbreak;\r\n}\r\nif (!i)\r\nnetdev_info(dev, "busy in irq\n");\r\nscc_addr = dpriv->base_addr + 0x0c*dpriv->dev_id;\r\nif (dpriv->flags & NeedIDT) {\r\nif (debug > 2)\r\ndscc4_tx_print(dev, dpriv, "Xpr");\r\nring = dpriv->tx_fd_dma +\r\n(dpriv->tx_dirty%TX_RING_SIZE)*\r\nsizeof(struct TxFD);\r\nwritel(ring, scc_addr + CH0BTDA);\r\ndscc4_do_tx(dpriv, dev);\r\nwritel(MTFi | Idt, scc_addr + CH0CFG);\r\nif (dscc4_do_action(dev, "IDT") < 0)\r\ngoto err_xpr;\r\ndpriv->flags &= ~NeedIDT;\r\n}\r\nif (dpriv->flags & NeedIDR) {\r\nring = dpriv->rx_fd_dma +\r\n(dpriv->rx_current%RX_RING_SIZE)*\r\nsizeof(struct RxFD);\r\nwritel(ring, scc_addr + CH0BRDA);\r\ndscc4_rx_update(dpriv, dev);\r\nwritel(MTFi | Idr, scc_addr + CH0CFG);\r\nif (dscc4_do_action(dev, "IDR") < 0)\r\ngoto err_xpr;\r\ndpriv->flags &= ~NeedIDR;\r\nsmp_wmb();\r\nscc_writel(0x08050008, dpriv, dev, CCR2);\r\n}\r\nerr_xpr:\r\nif (!(state &= ~Xpr))\r\ngoto try;\r\n}\r\nif (state & Cd) {\r\nif (debug > 0)\r\nnetdev_info(dev, "CD transition\n");\r\nif (!(state &= ~Cd))\r\ngoto try;\r\n}\r\n} else {\r\nif (state & Hi) {\r\n#ifdef DSCC4_POLLING\r\nwhile (!dscc4_tx_poll(dpriv, dev));\r\n#endif\r\nnetdev_info(dev, "Tx Hi\n");\r\nstate &= ~Hi;\r\n}\r\nif (state & Err) {\r\nnetdev_info(dev, "Tx ERR\n");\r\ndev->stats.tx_errors++;\r\nstate &= ~Err;\r\n}\r\n}\r\ngoto try;\r\n}\r\nstatic void dscc4_rx_irq(struct dscc4_pci_priv *priv,\r\nstruct dscc4_dev_priv *dpriv)\r\n{\r\nstruct net_device *dev = dscc4_to_dev(dpriv);\r\nu32 state;\r\nint cur;\r\ntry:\r\ncur = dpriv->iqrx_current%IRQ_RING_SIZE;\r\nstate = le32_to_cpu(dpriv->iqrx[cur]);\r\nif (!state)\r\nreturn;\r\ndpriv->iqrx[cur] = 0;\r\ndpriv->iqrx_current++;\r\nif (state_check(state, dpriv, dev, "Rx") < 0)\r\nreturn;\r\nif (!(state & SccEvt)){\r\nstruct RxFD *rx_fd;\r\nif (debug > 4)\r\nprintk(KERN_DEBUG "%s: Rx ISR = 0x%08x\n", dev->name,\r\nstate);\r\nstate &= 0x00ffffff;\r\nif (state & Err) {\r\nprintk(KERN_DEBUG "%s: Rx ERR\n", dev->name);\r\ncur = dpriv->rx_current%RX_RING_SIZE;\r\nrx_fd = dpriv->rx_fd + cur;\r\nwhile (!(rx_fd->state1 & Hold)) {\r\nrx_fd++;\r\ncur++;\r\nif (!(cur = cur%RX_RING_SIZE))\r\nrx_fd = dpriv->rx_fd;\r\n}\r\ntry_get_rx_skb(dpriv, dev);\r\nif (!rx_fd->data)\r\ngoto try;\r\nrx_fd->state1 &= ~Hold;\r\nrx_fd->state2 = 0x00000000;\r\nrx_fd->end = cpu_to_le32(0xbabeface);\r\ngoto try;\r\n}\r\nif (state & Fi) {\r\ndscc4_rx_skb(dpriv, dev);\r\ngoto try;\r\n}\r\nif (state & Hi ) {\r\nnetdev_info(dev, "Rx Hi\n");\r\nstate &= ~Hi;\r\ngoto try;\r\n}\r\n} else {\r\nif (debug > 1) {\r\nstatic struct {\r\nu32 mask;\r\nconst char *irq_name;\r\n} evts[] = {\r\n{ 0x00008000, "TIN"},\r\n{ 0x00000020, "RSC"},\r\n{ 0x00000010, "PCE"},\r\n{ 0x00000008, "PLLA"},\r\n{ 0, NULL}\r\n}, *evt;\r\nfor (evt = evts; evt->irq_name; evt++) {\r\nif (state & evt->mask) {\r\nprintk(KERN_DEBUG "%s: %s\n",\r\ndev->name, evt->irq_name);\r\nif (!(state &= ~evt->mask))\r\ngoto try;\r\n}\r\n}\r\n} else {\r\nif (!(state &= ~0x0000c03c))\r\ngoto try;\r\n}\r\nif (state & Cts) {\r\nnetdev_info(dev, "CTS transition\n");\r\nif (!(state &= ~Cts))\r\ngoto try;\r\n}\r\nif (state & Rdo) {\r\nstruct RxFD *rx_fd;\r\nvoid __iomem *scc_addr;\r\nint cur;\r\nscc_addr = dpriv->base_addr + 0x0c*dpriv->dev_id;\r\nscc_patchl(RxActivate, 0, dpriv, dev, CCR2);\r\nscc_writel(RxSccRes, dpriv, dev, CMDR);\r\ndpriv->flags |= RdoSet;\r\ndo {\r\ncur = dpriv->rx_current++%RX_RING_SIZE;\r\nrx_fd = dpriv->rx_fd + cur;\r\nif (!(rx_fd->state2 & DataComplete))\r\nbreak;\r\nif (rx_fd->state2 & FrameAborted) {\r\ndev->stats.rx_over_errors++;\r\nrx_fd->state1 |= Hold;\r\nrx_fd->state2 = 0x00000000;\r\nrx_fd->end = cpu_to_le32(0xbabeface);\r\n} else\r\ndscc4_rx_skb(dpriv, dev);\r\n} while (1);\r\nif (debug > 0) {\r\nif (dpriv->flags & RdoSet)\r\nprintk(KERN_DEBUG\r\n"%s: no RDO in Rx data\n", DRV_NAME);\r\n}\r\n#ifdef DSCC4_RDO_EXPERIMENTAL_RECOVERY\r\n#warning "FIXME: CH0BRDA"\r\nwritel(dpriv->rx_fd_dma +\r\n(dpriv->rx_current%RX_RING_SIZE)*\r\nsizeof(struct RxFD), scc_addr + CH0BRDA);\r\nwritel(MTFi|Rdr|Idr, scc_addr + CH0CFG);\r\nif (dscc4_do_action(dev, "RDR") < 0) {\r\nnetdev_err(dev, "RDO recovery failed(RDR)\n");\r\ngoto rdo_end;\r\n}\r\nwritel(MTFi|Idr, scc_addr + CH0CFG);\r\nif (dscc4_do_action(dev, "IDR") < 0) {\r\nnetdev_err(dev, "RDO recovery failed(IDR)\n");\r\ngoto rdo_end;\r\n}\r\nrdo_end:\r\n#endif\r\nscc_patchl(0, RxActivate, dpriv, dev, CCR2);\r\ngoto try;\r\n}\r\nif (state & Cd) {\r\nnetdev_info(dev, "CD transition\n");\r\nif (!(state &= ~Cd))\r\ngoto try;\r\n}\r\nif (state & Flex) {\r\nprintk(KERN_DEBUG "%s: Flex. Ttttt...\n", DRV_NAME);\r\nif (!(state &= ~Flex))\r\ngoto try;\r\n}\r\n}\r\n}\r\nstatic struct sk_buff *dscc4_init_dummy_skb(struct dscc4_dev_priv *dpriv)\r\n{\r\nstruct sk_buff *skb;\r\nskb = dev_alloc_skb(DUMMY_SKB_SIZE);\r\nif (skb) {\r\nint last = dpriv->tx_dirty%TX_RING_SIZE;\r\nstruct TxFD *tx_fd = dpriv->tx_fd + last;\r\nskb->len = DUMMY_SKB_SIZE;\r\nskb_copy_to_linear_data(skb, version,\r\nstrlen(version) % DUMMY_SKB_SIZE);\r\ntx_fd->state = FrameEnd | TO_STATE_TX(DUMMY_SKB_SIZE);\r\ntx_fd->data = cpu_to_le32(pci_map_single(dpriv->pci_priv->pdev,\r\nskb->data, DUMMY_SKB_SIZE,\r\nPCI_DMA_TODEVICE));\r\ndpriv->tx_skbuff[last] = skb;\r\n}\r\nreturn skb;\r\n}\r\nstatic int dscc4_init_ring(struct net_device *dev)\r\n{\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\nstruct pci_dev *pdev = dpriv->pci_priv->pdev;\r\nstruct TxFD *tx_fd;\r\nstruct RxFD *rx_fd;\r\nvoid *ring;\r\nint i;\r\nring = pci_alloc_consistent(pdev, RX_TOTAL_SIZE, &dpriv->rx_fd_dma);\r\nif (!ring)\r\ngoto err_out;\r\ndpriv->rx_fd = rx_fd = (struct RxFD *) ring;\r\nring = pci_alloc_consistent(pdev, TX_TOTAL_SIZE, &dpriv->tx_fd_dma);\r\nif (!ring)\r\ngoto err_free_dma_rx;\r\ndpriv->tx_fd = tx_fd = (struct TxFD *) ring;\r\nmemset(dpriv->tx_skbuff, 0, sizeof(struct sk_buff *)*TX_RING_SIZE);\r\ndpriv->tx_dirty = 0xffffffff;\r\ni = dpriv->tx_current = 0;\r\ndo {\r\ntx_fd->state = FrameEnd | TO_STATE_TX(2*DUMMY_SKB_SIZE);\r\ntx_fd->complete = 0x00000000;\r\ntx_fd->data = cpu_to_le32(dpriv->tx_fd_dma);\r\n(tx_fd++)->next = cpu_to_le32(dpriv->tx_fd_dma +\r\n(++i%TX_RING_SIZE)*sizeof(*tx_fd));\r\n} while (i < TX_RING_SIZE);\r\nif (!dscc4_init_dummy_skb(dpriv))\r\ngoto err_free_dma_tx;\r\nmemset(dpriv->rx_skbuff, 0, sizeof(struct sk_buff *)*RX_RING_SIZE);\r\ni = dpriv->rx_dirty = dpriv->rx_current = 0;\r\ndo {\r\nrx_fd->state1 = HiDesc;\r\nrx_fd->state2 = 0x00000000;\r\nrx_fd->end = cpu_to_le32(0xbabeface);\r\nrx_fd->state1 |= TO_STATE_RX(HDLC_MAX_MRU);\r\nif (try_get_rx_skb(dpriv, dev) >= 0)\r\ndpriv->rx_dirty++;\r\n(rx_fd++)->next = cpu_to_le32(dpriv->rx_fd_dma +\r\n(++i%RX_RING_SIZE)*sizeof(*rx_fd));\r\n} while (i < RX_RING_SIZE);\r\nreturn 0;\r\nerr_free_dma_tx:\r\npci_free_consistent(pdev, TX_TOTAL_SIZE, ring, dpriv->tx_fd_dma);\r\nerr_free_dma_rx:\r\npci_free_consistent(pdev, RX_TOTAL_SIZE, rx_fd, dpriv->rx_fd_dma);\r\nerr_out:\r\nreturn -ENOMEM;\r\n}\r\nstatic void dscc4_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct dscc4_pci_priv *ppriv;\r\nstruct dscc4_dev_priv *root;\r\nvoid __iomem *ioaddr;\r\nint i;\r\nppriv = pci_get_drvdata(pdev);\r\nroot = ppriv->root;\r\nioaddr = root->base_addr;\r\ndscc4_pci_reset(pdev, ioaddr);\r\nfree_irq(pdev->irq, root);\r\npci_free_consistent(pdev, IRQ_RING_SIZE*sizeof(u32), ppriv->iqcfg,\r\nppriv->iqcfg_dma);\r\nfor (i = 0; i < dev_per_card; i++) {\r\nstruct dscc4_dev_priv *dpriv = root + i;\r\ndscc4_release_ring(dpriv);\r\npci_free_consistent(pdev, IRQ_RING_SIZE*sizeof(u32),\r\ndpriv->iqrx, dpriv->iqrx_dma);\r\npci_free_consistent(pdev, IRQ_RING_SIZE*sizeof(u32),\r\ndpriv->iqtx, dpriv->iqtx_dma);\r\n}\r\ndscc4_free1(pdev);\r\niounmap(ioaddr);\r\npci_release_region(pdev, 1);\r\npci_release_region(pdev, 0);\r\npci_disable_device(pdev);\r\n}\r\nstatic int dscc4_hdlc_attach(struct net_device *dev, unsigned short encoding,\r\nunsigned short parity)\r\n{\r\nstruct dscc4_dev_priv *dpriv = dscc4_priv(dev);\r\nif (encoding != ENCODING_NRZ &&\r\nencoding != ENCODING_NRZI &&\r\nencoding != ENCODING_FM_MARK &&\r\nencoding != ENCODING_FM_SPACE &&\r\nencoding != ENCODING_MANCHESTER)\r\nreturn -EINVAL;\r\nif (parity != PARITY_NONE &&\r\nparity != PARITY_CRC16_PR0_CCITT &&\r\nparity != PARITY_CRC16_PR1_CCITT &&\r\nparity != PARITY_CRC32_PR0_CCITT &&\r\nparity != PARITY_CRC32_PR1_CCITT)\r\nreturn -EINVAL;\r\ndpriv->encoding = encoding;\r\ndpriv->parity = parity;\r\nreturn 0;\r\n}\r\nstatic int __init dscc4_setup(char *str)\r\n{\r\nint *args[] = { &debug, &quartz, NULL }, **p = args;\r\nwhile (*p && (get_option(&str, *p) == 2))\r\np++;\r\nreturn 1;\r\n}
