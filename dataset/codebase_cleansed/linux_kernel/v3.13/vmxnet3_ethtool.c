struct rtnl_link_stats64 *\r\nvmxnet3_get_stats64(struct net_device *netdev,\r\nstruct rtnl_link_stats64 *stats)\r\n{\r\nstruct vmxnet3_adapter *adapter;\r\nstruct vmxnet3_tq_driver_stats *drvTxStats;\r\nstruct vmxnet3_rq_driver_stats *drvRxStats;\r\nstruct UPT1_TxStats *devTxStats;\r\nstruct UPT1_RxStats *devRxStats;\r\nunsigned long flags;\r\nint i;\r\nadapter = netdev_priv(netdev);\r\nspin_lock_irqsave(&adapter->cmd_lock, flags);\r\nVMXNET3_WRITE_BAR1_REG(adapter, VMXNET3_REG_CMD, VMXNET3_CMD_GET_STATS);\r\nspin_unlock_irqrestore(&adapter->cmd_lock, flags);\r\nfor (i = 0; i < adapter->num_tx_queues; i++) {\r\ndevTxStats = &adapter->tqd_start[i].stats;\r\ndrvTxStats = &adapter->tx_queue[i].stats;\r\nstats->tx_packets += devTxStats->ucastPktsTxOK +\r\ndevTxStats->mcastPktsTxOK +\r\ndevTxStats->bcastPktsTxOK;\r\nstats->tx_bytes += devTxStats->ucastBytesTxOK +\r\ndevTxStats->mcastBytesTxOK +\r\ndevTxStats->bcastBytesTxOK;\r\nstats->tx_errors += devTxStats->pktsTxError;\r\nstats->tx_dropped += drvTxStats->drop_total;\r\n}\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\ndevRxStats = &adapter->rqd_start[i].stats;\r\ndrvRxStats = &adapter->rx_queue[i].stats;\r\nstats->rx_packets += devRxStats->ucastPktsRxOK +\r\ndevRxStats->mcastPktsRxOK +\r\ndevRxStats->bcastPktsRxOK;\r\nstats->rx_bytes += devRxStats->ucastBytesRxOK +\r\ndevRxStats->mcastBytesRxOK +\r\ndevRxStats->bcastBytesRxOK;\r\nstats->rx_errors += devRxStats->pktsRxError;\r\nstats->rx_dropped += drvRxStats->drop_total;\r\nstats->multicast += devRxStats->mcastPktsRxOK;\r\n}\r\nreturn stats;\r\n}\r\nstatic int\r\nvmxnet3_get_sset_count(struct net_device *netdev, int sset)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn (ARRAY_SIZE(vmxnet3_tq_dev_stats) +\r\nARRAY_SIZE(vmxnet3_tq_driver_stats)) *\r\nadapter->num_tx_queues +\r\n(ARRAY_SIZE(vmxnet3_rq_dev_stats) +\r\nARRAY_SIZE(vmxnet3_rq_driver_stats)) *\r\nadapter->num_rx_queues +\r\nARRAY_SIZE(vmxnet3_global_stats);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic int\r\nvmxnet3_get_regs_len(struct net_device *netdev)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nreturn (adapter->num_tx_queues * NUM_TX_REGS * sizeof(u32) +\r\nadapter->num_rx_queues * NUM_RX_REGS * sizeof(u32));\r\n}\r\nstatic void\r\nvmxnet3_get_drvinfo(struct net_device *netdev, struct ethtool_drvinfo *drvinfo)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nstrlcpy(drvinfo->driver, vmxnet3_driver_name, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, VMXNET3_DRIVER_VERSION_REPORT,\r\nsizeof(drvinfo->version));\r\nstrlcpy(drvinfo->bus_info, pci_name(adapter->pdev),\r\nsizeof(drvinfo->bus_info));\r\ndrvinfo->n_stats = vmxnet3_get_sset_count(netdev, ETH_SS_STATS);\r\ndrvinfo->testinfo_len = 0;\r\ndrvinfo->eedump_len = 0;\r\ndrvinfo->regdump_len = vmxnet3_get_regs_len(netdev);\r\n}\r\nstatic void\r\nvmxnet3_get_strings(struct net_device *netdev, u32 stringset, u8 *buf)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nif (stringset == ETH_SS_STATS) {\r\nint i, j;\r\nfor (j = 0; j < adapter->num_tx_queues; j++) {\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_tq_dev_stats); i++) {\r\nmemcpy(buf, vmxnet3_tq_dev_stats[i].desc,\r\nETH_GSTRING_LEN);\r\nbuf += ETH_GSTRING_LEN;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_tq_driver_stats);\r\ni++) {\r\nmemcpy(buf, vmxnet3_tq_driver_stats[i].desc,\r\nETH_GSTRING_LEN);\r\nbuf += ETH_GSTRING_LEN;\r\n}\r\n}\r\nfor (j = 0; j < adapter->num_rx_queues; j++) {\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_rq_dev_stats); i++) {\r\nmemcpy(buf, vmxnet3_rq_dev_stats[i].desc,\r\nETH_GSTRING_LEN);\r\nbuf += ETH_GSTRING_LEN;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_rq_driver_stats);\r\ni++) {\r\nmemcpy(buf, vmxnet3_rq_driver_stats[i].desc,\r\nETH_GSTRING_LEN);\r\nbuf += ETH_GSTRING_LEN;\r\n}\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_global_stats); i++) {\r\nmemcpy(buf, vmxnet3_global_stats[i].desc,\r\nETH_GSTRING_LEN);\r\nbuf += ETH_GSTRING_LEN;\r\n}\r\n}\r\n}\r\nint vmxnet3_set_features(struct net_device *netdev, netdev_features_t features)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nunsigned long flags;\r\nnetdev_features_t changed = features ^ netdev->features;\r\nif (changed & (NETIF_F_RXCSUM | NETIF_F_LRO |\r\nNETIF_F_HW_VLAN_CTAG_RX)) {\r\nif (features & NETIF_F_RXCSUM)\r\nadapter->shared->devRead.misc.uptFeatures |=\r\nUPT1_F_RXCSUM;\r\nelse\r\nadapter->shared->devRead.misc.uptFeatures &=\r\n~UPT1_F_RXCSUM;\r\nif (features & NETIF_F_LRO)\r\nadapter->shared->devRead.misc.uptFeatures |=\r\nUPT1_F_LRO;\r\nelse\r\nadapter->shared->devRead.misc.uptFeatures &=\r\n~UPT1_F_LRO;\r\nif (features & NETIF_F_HW_VLAN_CTAG_RX)\r\nadapter->shared->devRead.misc.uptFeatures |=\r\nUPT1_F_RXVLAN;\r\nelse\r\nadapter->shared->devRead.misc.uptFeatures &=\r\n~UPT1_F_RXVLAN;\r\nspin_lock_irqsave(&adapter->cmd_lock, flags);\r\nVMXNET3_WRITE_BAR1_REG(adapter, VMXNET3_REG_CMD,\r\nVMXNET3_CMD_UPDATE_FEATURE);\r\nspin_unlock_irqrestore(&adapter->cmd_lock, flags);\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nvmxnet3_get_ethtool_stats(struct net_device *netdev,\r\nstruct ethtool_stats *stats, u64 *buf)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nunsigned long flags;\r\nu8 *base;\r\nint i;\r\nint j = 0;\r\nspin_lock_irqsave(&adapter->cmd_lock, flags);\r\nVMXNET3_WRITE_BAR1_REG(adapter, VMXNET3_REG_CMD, VMXNET3_CMD_GET_STATS);\r\nspin_unlock_irqrestore(&adapter->cmd_lock, flags);\r\nfor (j = 0; j < adapter->num_tx_queues; j++) {\r\nbase = (u8 *)&adapter->tqd_start[j].stats;\r\n*buf++ = (u64)j;\r\nfor (i = 1; i < ARRAY_SIZE(vmxnet3_tq_dev_stats); i++)\r\n*buf++ = *(u64 *)(base +\r\nvmxnet3_tq_dev_stats[i].offset);\r\nbase = (u8 *)&adapter->tx_queue[j].stats;\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_tq_driver_stats); i++)\r\n*buf++ = *(u64 *)(base +\r\nvmxnet3_tq_driver_stats[i].offset);\r\n}\r\nfor (j = 0; j < adapter->num_tx_queues; j++) {\r\nbase = (u8 *)&adapter->rqd_start[j].stats;\r\n*buf++ = (u64) j;\r\nfor (i = 1; i < ARRAY_SIZE(vmxnet3_rq_dev_stats); i++)\r\n*buf++ = *(u64 *)(base +\r\nvmxnet3_rq_dev_stats[i].offset);\r\nbase = (u8 *)&adapter->rx_queue[j].stats;\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_rq_driver_stats); i++)\r\n*buf++ = *(u64 *)(base +\r\nvmxnet3_rq_driver_stats[i].offset);\r\n}\r\nbase = (u8 *)adapter;\r\nfor (i = 0; i < ARRAY_SIZE(vmxnet3_global_stats); i++)\r\n*buf++ = *(u64 *)(base + vmxnet3_global_stats[i].offset);\r\n}\r\nstatic void\r\nvmxnet3_get_regs(struct net_device *netdev, struct ethtool_regs *regs, void *p)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nu32 *buf = p;\r\nint i = 0, j = 0;\r\nmemset(p, 0, vmxnet3_get_regs_len(netdev));\r\nregs->version = 1;\r\nfor (i = 0; i < adapter->num_tx_queues; i++) {\r\nbuf[j++] = adapter->tx_queue[i].tx_ring.next2fill;\r\nbuf[j++] = adapter->tx_queue[i].tx_ring.next2comp;\r\nbuf[j++] = adapter->tx_queue[i].tx_ring.gen;\r\nbuf[j++] = 0;\r\nbuf[j++] = adapter->tx_queue[i].comp_ring.next2proc;\r\nbuf[j++] = adapter->tx_queue[i].comp_ring.gen;\r\nbuf[j++] = adapter->tx_queue[i].stopped;\r\nbuf[j++] = 0;\r\n}\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\nbuf[j++] = adapter->rx_queue[i].rx_ring[0].next2fill;\r\nbuf[j++] = adapter->rx_queue[i].rx_ring[0].next2comp;\r\nbuf[j++] = adapter->rx_queue[i].rx_ring[0].gen;\r\nbuf[j++] = 0;\r\nbuf[j++] = adapter->rx_queue[i].rx_ring[1].next2fill;\r\nbuf[j++] = adapter->rx_queue[i].rx_ring[1].next2comp;\r\nbuf[j++] = adapter->rx_queue[i].rx_ring[1].gen;\r\nbuf[j++] = 0;\r\nbuf[j++] = adapter->rx_queue[i].comp_ring.next2proc;\r\nbuf[j++] = adapter->rx_queue[i].comp_ring.gen;\r\nbuf[j++] = 0;\r\nbuf[j++] = 0;\r\n}\r\n}\r\nstatic void\r\nvmxnet3_get_wol(struct net_device *netdev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nwol->supported = WAKE_UCAST | WAKE_ARP | WAKE_MAGIC;\r\nwol->wolopts = adapter->wol;\r\n}\r\nstatic int\r\nvmxnet3_set_wol(struct net_device *netdev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nif (wol->wolopts & (WAKE_PHY | WAKE_MCAST | WAKE_BCAST |\r\nWAKE_MAGICSECURE)) {\r\nreturn -EOPNOTSUPP;\r\n}\r\nadapter->wol = wol->wolopts;\r\ndevice_set_wakeup_enable(&adapter->pdev->dev, adapter->wol);\r\nreturn 0;\r\n}\r\nstatic int\r\nvmxnet3_get_settings(struct net_device *netdev, struct ethtool_cmd *ecmd)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\necmd->supported = SUPPORTED_10000baseT_Full | SUPPORTED_1000baseT_Full |\r\nSUPPORTED_TP;\r\necmd->advertising = ADVERTISED_TP;\r\necmd->port = PORT_TP;\r\necmd->transceiver = XCVR_INTERNAL;\r\nif (adapter->link_speed) {\r\nethtool_cmd_speed_set(ecmd, adapter->link_speed);\r\necmd->duplex = DUPLEX_FULL;\r\n} else {\r\nethtool_cmd_speed_set(ecmd, -1);\r\necmd->duplex = -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nvmxnet3_get_ringparam(struct net_device *netdev,\r\nstruct ethtool_ringparam *param)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nparam->rx_max_pending = VMXNET3_RX_RING_MAX_SIZE;\r\nparam->tx_max_pending = VMXNET3_TX_RING_MAX_SIZE;\r\nparam->rx_mini_max_pending = 0;\r\nparam->rx_jumbo_max_pending = 0;\r\nparam->rx_pending = adapter->rx_queue[0].rx_ring[0].size;\r\nparam->tx_pending = adapter->tx_queue[0].tx_ring.size;\r\nparam->rx_mini_pending = 0;\r\nparam->rx_jumbo_pending = 0;\r\n}\r\nstatic int\r\nvmxnet3_set_ringparam(struct net_device *netdev,\r\nstruct ethtool_ringparam *param)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nu32 new_tx_ring_size, new_rx_ring_size;\r\nu32 sz;\r\nint err = 0;\r\nif (param->tx_pending == 0 || param->tx_pending >\r\nVMXNET3_TX_RING_MAX_SIZE)\r\nreturn -EINVAL;\r\nif (param->rx_pending == 0 || param->rx_pending >\r\nVMXNET3_RX_RING_MAX_SIZE)\r\nreturn -EINVAL;\r\nif (adapter->rx_buf_per_pkt == 0) {\r\nnetdev_err(netdev, "adapter not completely initialized, "\r\n"ring size cannot be changed yet\n");\r\nreturn -EOPNOTSUPP;\r\n}\r\nnew_tx_ring_size = (param->tx_pending + VMXNET3_RING_SIZE_MASK) &\r\n~VMXNET3_RING_SIZE_MASK;\r\nnew_tx_ring_size = min_t(u32, new_tx_ring_size,\r\nVMXNET3_TX_RING_MAX_SIZE);\r\nif (new_tx_ring_size > VMXNET3_TX_RING_MAX_SIZE || (new_tx_ring_size %\r\nVMXNET3_RING_SIZE_ALIGN) != 0)\r\nreturn -EINVAL;\r\nsz = adapter->rx_buf_per_pkt * VMXNET3_RING_SIZE_ALIGN;\r\nnew_rx_ring_size = (param->rx_pending + sz - 1) / sz * sz;\r\nnew_rx_ring_size = min_t(u32, new_rx_ring_size,\r\nVMXNET3_RX_RING_MAX_SIZE / sz * sz);\r\nif (new_rx_ring_size > VMXNET3_RX_RING_MAX_SIZE || (new_rx_ring_size %\r\nsz) != 0)\r\nreturn -EINVAL;\r\nif (new_tx_ring_size == adapter->tx_queue[0].tx_ring.size &&\r\nnew_rx_ring_size == adapter->rx_queue[0].rx_ring[0].size) {\r\nreturn 0;\r\n}\r\nwhile (test_and_set_bit(VMXNET3_STATE_BIT_RESETTING, &adapter->state))\r\nmsleep(1);\r\nif (netif_running(netdev)) {\r\nvmxnet3_quiesce_dev(adapter);\r\nvmxnet3_reset_dev(adapter);\r\nvmxnet3_tq_destroy_all(adapter);\r\nvmxnet3_rq_destroy_all(adapter);\r\nerr = vmxnet3_create_queues(adapter, new_tx_ring_size,\r\nnew_rx_ring_size, VMXNET3_DEF_RX_RING_SIZE);\r\nif (err) {\r\nnetdev_err(netdev, "failed to apply new sizes, "\r\n"try the default ones\n");\r\nerr = vmxnet3_create_queues(adapter,\r\nVMXNET3_DEF_TX_RING_SIZE,\r\nVMXNET3_DEF_RX_RING_SIZE,\r\nVMXNET3_DEF_RX_RING_SIZE);\r\nif (err) {\r\nnetdev_err(netdev, "failed to create queues "\r\n"with default sizes. Closing it\n");\r\ngoto out;\r\n}\r\n}\r\nerr = vmxnet3_activate_dev(adapter);\r\nif (err)\r\nnetdev_err(netdev, "failed to re-activate, error %d."\r\n" Closing it\n", err);\r\n}\r\nout:\r\nclear_bit(VMXNET3_STATE_BIT_RESETTING, &adapter->state);\r\nif (err)\r\nvmxnet3_force_close(adapter);\r\nreturn err;\r\n}\r\nstatic int\r\nvmxnet3_get_rxnfc(struct net_device *netdev, struct ethtool_rxnfc *info,\r\nu32 *rules)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nswitch (info->cmd) {\r\ncase ETHTOOL_GRXRINGS:\r\ninfo->data = adapter->num_rx_queues;\r\nreturn 0;\r\n}\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic u32\r\nvmxnet3_get_rss_indir_size(struct net_device *netdev)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nstruct UPT1_RSSConf *rssConf = adapter->rss_conf;\r\nreturn rssConf->indTableSize;\r\n}\r\nstatic int\r\nvmxnet3_get_rss_indir(struct net_device *netdev, u32 *p)\r\n{\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nstruct UPT1_RSSConf *rssConf = adapter->rss_conf;\r\nunsigned int n = rssConf->indTableSize;\r\nwhile (n--)\r\np[n] = rssConf->indTable[n];\r\nreturn 0;\r\n}\r\nstatic int\r\nvmxnet3_set_rss_indir(struct net_device *netdev, const u32 *p)\r\n{\r\nunsigned int i;\r\nunsigned long flags;\r\nstruct vmxnet3_adapter *adapter = netdev_priv(netdev);\r\nstruct UPT1_RSSConf *rssConf = adapter->rss_conf;\r\nfor (i = 0; i < rssConf->indTableSize; i++)\r\nrssConf->indTable[i] = p[i];\r\nspin_lock_irqsave(&adapter->cmd_lock, flags);\r\nVMXNET3_WRITE_BAR1_REG(adapter, VMXNET3_REG_CMD,\r\nVMXNET3_CMD_UPDATE_RSSIDT);\r\nspin_unlock_irqrestore(&adapter->cmd_lock, flags);\r\nreturn 0;\r\n}\r\nvoid vmxnet3_set_ethtool_ops(struct net_device *netdev)\r\n{\r\nSET_ETHTOOL_OPS(netdev, &vmxnet3_ethtool_ops);\r\n}
