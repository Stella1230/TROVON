static void\r\nnvkm_mm_dump(struct nvkm_mm *mm, const char *header)\r\n{\r\nstruct nvkm_mm_node *node;\r\nprintk(KERN_ERR "nvkm: %s\n", header);\r\nprintk(KERN_ERR "nvkm: node list:\n");\r\nlist_for_each_entry(node, &mm->nodes, nl_entry) {\r\nprintk(KERN_ERR "nvkm: \t%08x %08x %d\n",\r\nnode->offset, node->length, node->type);\r\n}\r\nprintk(KERN_ERR "nvkm: free list:\n");\r\nlist_for_each_entry(node, &mm->free, fl_entry) {\r\nprintk(KERN_ERR "nvkm: \t%08x %08x %d\n",\r\nnode->offset, node->length, node->type);\r\n}\r\n}\r\nvoid\r\nnvkm_mm_free(struct nvkm_mm *mm, struct nvkm_mm_node **pthis)\r\n{\r\nstruct nvkm_mm_node *this = *pthis;\r\nif (this) {\r\nstruct nvkm_mm_node *prev = node(this, prev);\r\nstruct nvkm_mm_node *next = node(this, next);\r\nif (prev && prev->type == NVKM_MM_TYPE_NONE) {\r\nprev->length += this->length;\r\nlist_del(&this->nl_entry);\r\nkfree(this); this = prev;\r\n}\r\nif (next && next->type == NVKM_MM_TYPE_NONE) {\r\nnext->offset = this->offset;\r\nnext->length += this->length;\r\nif (this->type == NVKM_MM_TYPE_NONE)\r\nlist_del(&this->fl_entry);\r\nlist_del(&this->nl_entry);\r\nkfree(this); this = NULL;\r\n}\r\nif (this && this->type != NVKM_MM_TYPE_NONE) {\r\nlist_for_each_entry(prev, &mm->free, fl_entry) {\r\nif (this->offset < prev->offset)\r\nbreak;\r\n}\r\nlist_add_tail(&this->fl_entry, &prev->fl_entry);\r\nthis->type = NVKM_MM_TYPE_NONE;\r\n}\r\n}\r\n*pthis = NULL;\r\n}\r\nstatic struct nvkm_mm_node *\r\nregion_head(struct nvkm_mm *mm, struct nvkm_mm_node *a, u32 size)\r\n{\r\nstruct nvkm_mm_node *b;\r\nif (a->length == size)\r\nreturn a;\r\nb = kmalloc(sizeof(*b), GFP_KERNEL);\r\nif (unlikely(b == NULL))\r\nreturn NULL;\r\nb->offset = a->offset;\r\nb->length = size;\r\nb->heap = a->heap;\r\nb->type = a->type;\r\na->offset += size;\r\na->length -= size;\r\nlist_add_tail(&b->nl_entry, &a->nl_entry);\r\nif (b->type == NVKM_MM_TYPE_NONE)\r\nlist_add_tail(&b->fl_entry, &a->fl_entry);\r\nreturn b;\r\n}\r\nint\r\nnvkm_mm_head(struct nvkm_mm *mm, u8 heap, u8 type, u32 size_max, u32 size_min,\r\nu32 align, struct nvkm_mm_node **pnode)\r\n{\r\nstruct nvkm_mm_node *prev, *this, *next;\r\nu32 mask = align - 1;\r\nu32 splitoff;\r\nu32 s, e;\r\nBUG_ON(type == NVKM_MM_TYPE_NONE || type == NVKM_MM_TYPE_HOLE);\r\nlist_for_each_entry(this, &mm->free, fl_entry) {\r\nif (unlikely(heap != NVKM_MM_HEAP_ANY)) {\r\nif (this->heap != heap)\r\ncontinue;\r\n}\r\ne = this->offset + this->length;\r\ns = this->offset;\r\nprev = node(this, prev);\r\nif (prev && prev->type != type)\r\ns = roundup(s, mm->block_size);\r\nnext = node(this, next);\r\nif (next && next->type != type)\r\ne = rounddown(e, mm->block_size);\r\ns = (s + mask) & ~mask;\r\ne &= ~mask;\r\nif (s > e || e - s < size_min)\r\ncontinue;\r\nsplitoff = s - this->offset;\r\nif (splitoff && !region_head(mm, this, splitoff))\r\nreturn -ENOMEM;\r\nthis = region_head(mm, this, min(size_max, e - s));\r\nif (!this)\r\nreturn -ENOMEM;\r\nthis->type = type;\r\nlist_del(&this->fl_entry);\r\n*pnode = this;\r\nreturn 0;\r\n}\r\nreturn -ENOSPC;\r\n}\r\nstatic struct nvkm_mm_node *\r\nregion_tail(struct nvkm_mm *mm, struct nvkm_mm_node *a, u32 size)\r\n{\r\nstruct nvkm_mm_node *b;\r\nif (a->length == size)\r\nreturn a;\r\nb = kmalloc(sizeof(*b), GFP_KERNEL);\r\nif (unlikely(b == NULL))\r\nreturn NULL;\r\na->length -= size;\r\nb->offset = a->offset + a->length;\r\nb->length = size;\r\nb->heap = a->heap;\r\nb->type = a->type;\r\nlist_add(&b->nl_entry, &a->nl_entry);\r\nif (b->type == NVKM_MM_TYPE_NONE)\r\nlist_add(&b->fl_entry, &a->fl_entry);\r\nreturn b;\r\n}\r\nint\r\nnvkm_mm_tail(struct nvkm_mm *mm, u8 heap, u8 type, u32 size_max, u32 size_min,\r\nu32 align, struct nvkm_mm_node **pnode)\r\n{\r\nstruct nvkm_mm_node *prev, *this, *next;\r\nu32 mask = align - 1;\r\nBUG_ON(type == NVKM_MM_TYPE_NONE || type == NVKM_MM_TYPE_HOLE);\r\nlist_for_each_entry_reverse(this, &mm->free, fl_entry) {\r\nu32 e = this->offset + this->length;\r\nu32 s = this->offset;\r\nu32 c = 0, a;\r\nif (unlikely(heap != NVKM_MM_HEAP_ANY)) {\r\nif (this->heap != heap)\r\ncontinue;\r\n}\r\nprev = node(this, prev);\r\nif (prev && prev->type != type)\r\ns = roundup(s, mm->block_size);\r\nnext = node(this, next);\r\nif (next && next->type != type) {\r\ne = rounddown(e, mm->block_size);\r\nc = next->offset - e;\r\n}\r\ns = (s + mask) & ~mask;\r\na = e - s;\r\nif (s > e || a < size_min)\r\ncontinue;\r\na = min(a, size_max);\r\ns = (e - a) & ~mask;\r\nc += (e - s) - a;\r\nif (c && !region_tail(mm, this, c))\r\nreturn -ENOMEM;\r\nthis = region_tail(mm, this, a);\r\nif (!this)\r\nreturn -ENOMEM;\r\nthis->type = type;\r\nlist_del(&this->fl_entry);\r\n*pnode = this;\r\nreturn 0;\r\n}\r\nreturn -ENOSPC;\r\n}\r\nint\r\nnvkm_mm_init(struct nvkm_mm *mm, u32 offset, u32 length, u32 block)\r\n{\r\nstruct nvkm_mm_node *node, *prev;\r\nu32 next;\r\nif (nvkm_mm_initialised(mm)) {\r\nprev = list_last_entry(&mm->nodes, typeof(*node), nl_entry);\r\nnext = prev->offset + prev->length;\r\nif (next != offset) {\r\nBUG_ON(next > offset);\r\nif (!(node = kzalloc(sizeof(*node), GFP_KERNEL)))\r\nreturn -ENOMEM;\r\nnode->type = NVKM_MM_TYPE_HOLE;\r\nnode->offset = next;\r\nnode->length = offset - next;\r\nlist_add_tail(&node->nl_entry, &mm->nodes);\r\n}\r\nBUG_ON(block != mm->block_size);\r\n} else {\r\nINIT_LIST_HEAD(&mm->nodes);\r\nINIT_LIST_HEAD(&mm->free);\r\nmm->block_size = block;\r\nmm->heap_nodes = 0;\r\n}\r\nnode = kzalloc(sizeof(*node), GFP_KERNEL);\r\nif (!node)\r\nreturn -ENOMEM;\r\nif (length) {\r\nnode->offset = roundup(offset, mm->block_size);\r\nnode->length = rounddown(offset + length, mm->block_size);\r\nnode->length -= node->offset;\r\n}\r\nlist_add_tail(&node->nl_entry, &mm->nodes);\r\nlist_add_tail(&node->fl_entry, &mm->free);\r\nnode->heap = ++mm->heap_nodes;\r\nreturn 0;\r\n}\r\nint\r\nnvkm_mm_fini(struct nvkm_mm *mm)\r\n{\r\nstruct nvkm_mm_node *node, *temp;\r\nint nodes = 0;\r\nif (!nvkm_mm_initialised(mm))\r\nreturn 0;\r\nlist_for_each_entry(node, &mm->nodes, nl_entry) {\r\nif (node->type != NVKM_MM_TYPE_HOLE) {\r\nif (++nodes > mm->heap_nodes) {\r\nnvkm_mm_dump(mm, "mm not clean!");\r\nreturn -EBUSY;\r\n}\r\n}\r\n}\r\nlist_for_each_entry_safe(node, temp, &mm->nodes, nl_entry) {\r\nlist_del(&node->nl_entry);\r\nkfree(node);\r\n}\r\nmm->heap_nodes = 0;\r\nreturn 0;\r\n}
