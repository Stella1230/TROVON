STATIC int\r\nxfs_btree_check_lblock(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_btree_block *block,\r\nint level,\r\nstruct xfs_buf *bp)\r\n{\r\nint lblock_ok = 1;\r\nstruct xfs_mount *mp;\r\nmp = cur->bc_mp;\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nlblock_ok = lblock_ok &&\r\nuuid_equal(&block->bb_u.l.bb_uuid, &mp->m_sb.sb_uuid) &&\r\nblock->bb_u.l.bb_blkno == cpu_to_be64(\r\nbp ? bp->b_bn : XFS_BUF_DADDR_NULL);\r\n}\r\nlblock_ok = lblock_ok &&\r\nbe32_to_cpu(block->bb_magic) == xfs_btree_magic(cur) &&\r\nbe16_to_cpu(block->bb_level) == level &&\r\nbe16_to_cpu(block->bb_numrecs) <=\r\ncur->bc_ops->get_maxrecs(cur, level) &&\r\nblock->bb_u.l.bb_leftsib &&\r\n(block->bb_u.l.bb_leftsib == cpu_to_be64(NULLFSBLOCK) ||\r\nXFS_FSB_SANITY_CHECK(mp,\r\nbe64_to_cpu(block->bb_u.l.bb_leftsib))) &&\r\nblock->bb_u.l.bb_rightsib &&\r\n(block->bb_u.l.bb_rightsib == cpu_to_be64(NULLFSBLOCK) ||\r\nXFS_FSB_SANITY_CHECK(mp,\r\nbe64_to_cpu(block->bb_u.l.bb_rightsib)));\r\nif (unlikely(XFS_TEST_ERROR(!lblock_ok, mp,\r\nXFS_ERRTAG_BTREE_CHECK_LBLOCK,\r\nXFS_RANDOM_BTREE_CHECK_LBLOCK))) {\r\nif (bp)\r\ntrace_xfs_btree_corrupt(bp, _RET_IP_);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_LOW, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_check_sblock(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_btree_block *block,\r\nint level,\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp;\r\nstruct xfs_buf *agbp;\r\nstruct xfs_agf *agf;\r\nxfs_agblock_t agflen;\r\nint sblock_ok = 1;\r\nmp = cur->bc_mp;\r\nagbp = cur->bc_private.a.agbp;\r\nagf = XFS_BUF_TO_AGF(agbp);\r\nagflen = be32_to_cpu(agf->agf_length);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nsblock_ok = sblock_ok &&\r\nuuid_equal(&block->bb_u.s.bb_uuid, &mp->m_sb.sb_uuid) &&\r\nblock->bb_u.s.bb_blkno == cpu_to_be64(\r\nbp ? bp->b_bn : XFS_BUF_DADDR_NULL);\r\n}\r\nsblock_ok = sblock_ok &&\r\nbe32_to_cpu(block->bb_magic) == xfs_btree_magic(cur) &&\r\nbe16_to_cpu(block->bb_level) == level &&\r\nbe16_to_cpu(block->bb_numrecs) <=\r\ncur->bc_ops->get_maxrecs(cur, level) &&\r\n(block->bb_u.s.bb_leftsib == cpu_to_be32(NULLAGBLOCK) ||\r\nbe32_to_cpu(block->bb_u.s.bb_leftsib) < agflen) &&\r\nblock->bb_u.s.bb_leftsib &&\r\n(block->bb_u.s.bb_rightsib == cpu_to_be32(NULLAGBLOCK) ||\r\nbe32_to_cpu(block->bb_u.s.bb_rightsib) < agflen) &&\r\nblock->bb_u.s.bb_rightsib;\r\nif (unlikely(XFS_TEST_ERROR(!sblock_ok, mp,\r\nXFS_ERRTAG_BTREE_CHECK_SBLOCK,\r\nXFS_RANDOM_BTREE_CHECK_SBLOCK))) {\r\nif (bp)\r\ntrace_xfs_btree_corrupt(bp, _RET_IP_);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_LOW, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nxfs_btree_check_block(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_btree_block *block,\r\nint level,\r\nstruct xfs_buf *bp)\r\n{\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nreturn xfs_btree_check_lblock(cur, block, level, bp);\r\nelse\r\nreturn xfs_btree_check_sblock(cur, block, level, bp);\r\n}\r\nint\r\nxfs_btree_check_lptr(\r\nstruct xfs_btree_cur *cur,\r\nxfs_fsblock_t bno,\r\nint level)\r\n{\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp,\r\nlevel > 0 &&\r\nbno != NULLFSBLOCK &&\r\nXFS_FSB_SANITY_CHECK(cur->bc_mp, bno));\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_check_sptr(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agblock_t bno,\r\nint level)\r\n{\r\nxfs_agblock_t agblocks = cur->bc_mp->m_sb.sb_agblocks;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp,\r\nlevel > 0 &&\r\nbno != NULLAGBLOCK &&\r\nbno != 0 &&\r\nbno < agblocks);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_check_ptr(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr,\r\nint index,\r\nint level)\r\n{\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\r\nreturn xfs_btree_check_lptr(cur,\r\nbe64_to_cpu((&ptr->l)[index]), level);\r\n} else {\r\nreturn xfs_btree_check_sptr(cur,\r\nbe32_to_cpu((&ptr->s)[index]), level);\r\n}\r\n}\r\nvoid\r\nxfs_btree_lblock_calc_crc(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_btree_block *block = XFS_BUF_TO_BLOCK(bp);\r\nstruct xfs_buf_log_item *bip = bp->b_fspriv;\r\nif (!xfs_sb_version_hascrc(&bp->b_target->bt_mount->m_sb))\r\nreturn;\r\nif (bip)\r\nblock->bb_u.l.bb_lsn = cpu_to_be64(bip->bli_item.li_lsn);\r\nxfs_buf_update_cksum(bp, XFS_BTREE_LBLOCK_CRC_OFF);\r\n}\r\nbool\r\nxfs_btree_lblock_verify_crc(\r\nstruct xfs_buf *bp)\r\n{\r\nif (xfs_sb_version_hascrc(&bp->b_target->bt_mount->m_sb))\r\nreturn xfs_buf_verify_cksum(bp, XFS_BTREE_LBLOCK_CRC_OFF);\r\nreturn true;\r\n}\r\nvoid\r\nxfs_btree_sblock_calc_crc(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_btree_block *block = XFS_BUF_TO_BLOCK(bp);\r\nstruct xfs_buf_log_item *bip = bp->b_fspriv;\r\nif (!xfs_sb_version_hascrc(&bp->b_target->bt_mount->m_sb))\r\nreturn;\r\nif (bip)\r\nblock->bb_u.s.bb_lsn = cpu_to_be64(bip->bli_item.li_lsn);\r\nxfs_buf_update_cksum(bp, XFS_BTREE_SBLOCK_CRC_OFF);\r\n}\r\nbool\r\nxfs_btree_sblock_verify_crc(\r\nstruct xfs_buf *bp)\r\n{\r\nif (xfs_sb_version_hascrc(&bp->b_target->bt_mount->m_sb))\r\nreturn xfs_buf_verify_cksum(bp, XFS_BTREE_SBLOCK_CRC_OFF);\r\nreturn true;\r\n}\r\nvoid\r\nxfs_btree_del_cursor(\r\nxfs_btree_cur_t *cur,\r\nint error)\r\n{\r\nint i;\r\nfor (i = 0; i < cur->bc_nlevels; i++) {\r\nif (cur->bc_bufs[i])\r\nxfs_trans_brelse(cur->bc_tp, cur->bc_bufs[i]);\r\nelse if (!error)\r\nbreak;\r\n}\r\nASSERT(cur->bc_btnum != XFS_BTNUM_BMAP ||\r\ncur->bc_private.b.allocated == 0);\r\nkmem_zone_free(xfs_btree_cur_zone, cur);\r\n}\r\nint\r\nxfs_btree_dup_cursor(\r\nxfs_btree_cur_t *cur,\r\nxfs_btree_cur_t **ncur)\r\n{\r\nxfs_buf_t *bp;\r\nint error;\r\nint i;\r\nxfs_mount_t *mp;\r\nxfs_btree_cur_t *new;\r\nxfs_trans_t *tp;\r\ntp = cur->bc_tp;\r\nmp = cur->bc_mp;\r\nnew = cur->bc_ops->dup_cursor(cur);\r\nnew->bc_rec = cur->bc_rec;\r\nfor (i = 0; i < new->bc_nlevels; i++) {\r\nnew->bc_ptrs[i] = cur->bc_ptrs[i];\r\nnew->bc_ra[i] = cur->bc_ra[i];\r\nbp = cur->bc_bufs[i];\r\nif (bp) {\r\nerror = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp,\r\nXFS_BUF_ADDR(bp), mp->m_bsize,\r\n0, &bp,\r\ncur->bc_ops->buf_ops);\r\nif (error) {\r\nxfs_btree_del_cursor(new, error);\r\n*ncur = NULL;\r\nreturn error;\r\n}\r\n}\r\nnew->bc_bufs[i] = bp;\r\n}\r\n*ncur = new;\r\nreturn 0;\r\n}\r\nstatic inline size_t xfs_btree_block_len(struct xfs_btree_cur *cur)\r\n{\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\r\nif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS)\r\nreturn XFS_BTREE_LBLOCK_CRC_LEN;\r\nreturn XFS_BTREE_LBLOCK_LEN;\r\n}\r\nif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS)\r\nreturn XFS_BTREE_SBLOCK_CRC_LEN;\r\nreturn XFS_BTREE_SBLOCK_LEN;\r\n}\r\nstatic inline size_t xfs_btree_ptr_len(struct xfs_btree_cur *cur)\r\n{\r\nreturn (cur->bc_flags & XFS_BTREE_LONG_PTRS) ?\r\nsizeof(__be64) : sizeof(__be32);\r\n}\r\nSTATIC size_t\r\nxfs_btree_rec_offset(\r\nstruct xfs_btree_cur *cur,\r\nint n)\r\n{\r\nreturn xfs_btree_block_len(cur) +\r\n(n - 1) * cur->bc_ops->rec_len;\r\n}\r\nSTATIC size_t\r\nxfs_btree_key_offset(\r\nstruct xfs_btree_cur *cur,\r\nint n)\r\n{\r\nreturn xfs_btree_block_len(cur) +\r\n(n - 1) * cur->bc_ops->key_len;\r\n}\r\nSTATIC size_t\r\nxfs_btree_ptr_offset(\r\nstruct xfs_btree_cur *cur,\r\nint n,\r\nint level)\r\n{\r\nreturn xfs_btree_block_len(cur) +\r\ncur->bc_ops->get_maxrecs(cur, level) * cur->bc_ops->key_len +\r\n(n - 1) * xfs_btree_ptr_len(cur);\r\n}\r\nSTATIC union xfs_btree_rec *\r\nxfs_btree_rec_addr(\r\nstruct xfs_btree_cur *cur,\r\nint n,\r\nstruct xfs_btree_block *block)\r\n{\r\nreturn (union xfs_btree_rec *)\r\n((char *)block + xfs_btree_rec_offset(cur, n));\r\n}\r\nSTATIC union xfs_btree_key *\r\nxfs_btree_key_addr(\r\nstruct xfs_btree_cur *cur,\r\nint n,\r\nstruct xfs_btree_block *block)\r\n{\r\nreturn (union xfs_btree_key *)\r\n((char *)block + xfs_btree_key_offset(cur, n));\r\n}\r\nSTATIC union xfs_btree_ptr *\r\nxfs_btree_ptr_addr(\r\nstruct xfs_btree_cur *cur,\r\nint n,\r\nstruct xfs_btree_block *block)\r\n{\r\nint level = xfs_btree_get_level(block);\r\nASSERT(block->bb_level != 0);\r\nreturn (union xfs_btree_ptr *)\r\n((char *)block + xfs_btree_ptr_offset(cur, n, level));\r\n}\r\nSTATIC struct xfs_btree_block *\r\nxfs_btree_get_iroot(\r\nstruct xfs_btree_cur *cur)\r\n{\r\nstruct xfs_ifork *ifp;\r\nifp = XFS_IFORK_PTR(cur->bc_private.b.ip, cur->bc_private.b.whichfork);\r\nreturn (struct xfs_btree_block *)ifp->if_broot;\r\n}\r\nSTATIC struct xfs_btree_block *\r\nxfs_btree_get_block(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nstruct xfs_buf **bpp)\r\n{\r\nif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\r\n(level == cur->bc_nlevels - 1)) {\r\n*bpp = NULL;\r\nreturn xfs_btree_get_iroot(cur);\r\n}\r\n*bpp = cur->bc_bufs[level];\r\nreturn XFS_BUF_TO_BLOCK(*bpp);\r\n}\r\nxfs_buf_t *\r\nxfs_btree_get_bufl(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_fsblock_t fsbno,\r\nuint lock)\r\n{\r\nxfs_daddr_t d;\r\nASSERT(fsbno != NULLFSBLOCK);\r\nd = XFS_FSB_TO_DADDR(mp, fsbno);\r\nreturn xfs_trans_get_buf(tp, mp->m_ddev_targp, d, mp->m_bsize, lock);\r\n}\r\nxfs_buf_t *\r\nxfs_btree_get_bufs(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_agnumber_t agno,\r\nxfs_agblock_t agbno,\r\nuint lock)\r\n{\r\nxfs_daddr_t d;\r\nASSERT(agno != NULLAGNUMBER);\r\nASSERT(agbno != NULLAGBLOCK);\r\nd = XFS_AGB_TO_DADDR(mp, agno, agbno);\r\nreturn xfs_trans_get_buf(tp, mp->m_ddev_targp, d, mp->m_bsize, lock);\r\n}\r\nint\r\nxfs_btree_islastblock(\r\nxfs_btree_cur_t *cur,\r\nint level)\r\n{\r\nstruct xfs_btree_block *block;\r\nxfs_buf_t *bp;\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\nxfs_btree_check_block(cur, block, level, bp);\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nreturn block->bb_u.l.bb_rightsib == cpu_to_be64(NULLFSBLOCK);\r\nelse\r\nreturn block->bb_u.s.bb_rightsib == cpu_to_be32(NULLAGBLOCK);\r\n}\r\nSTATIC int\r\nxfs_btree_firstrec(\r\nxfs_btree_cur_t *cur,\r\nint level)\r\n{\r\nstruct xfs_btree_block *block;\r\nxfs_buf_t *bp;\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\nxfs_btree_check_block(cur, block, level, bp);\r\nif (!block->bb_numrecs)\r\nreturn 0;\r\ncur->bc_ptrs[level] = 1;\r\nreturn 1;\r\n}\r\nSTATIC int\r\nxfs_btree_lastrec(\r\nxfs_btree_cur_t *cur,\r\nint level)\r\n{\r\nstruct xfs_btree_block *block;\r\nxfs_buf_t *bp;\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\nxfs_btree_check_block(cur, block, level, bp);\r\nif (!block->bb_numrecs)\r\nreturn 0;\r\ncur->bc_ptrs[level] = be16_to_cpu(block->bb_numrecs);\r\nreturn 1;\r\n}\r\nvoid\r\nxfs_btree_offsets(\r\n__int64_t fields,\r\nconst short *offsets,\r\nint nbits,\r\nint *first,\r\nint *last)\r\n{\r\nint i;\r\n__int64_t imask;\r\nASSERT(fields != 0);\r\nfor (i = 0, imask = 1LL; ; i++, imask <<= 1) {\r\nif (imask & fields) {\r\n*first = offsets[i];\r\nbreak;\r\n}\r\n}\r\nfor (i = nbits - 1, imask = 1LL << i; ; i--, imask >>= 1) {\r\nif (imask & fields) {\r\n*last = offsets[i + 1] - 1;\r\nbreak;\r\n}\r\n}\r\n}\r\nint\r\nxfs_btree_read_bufl(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nxfs_fsblock_t fsbno,\r\nuint lock,\r\nstruct xfs_buf **bpp,\r\nint refval,\r\nconst struct xfs_buf_ops *ops)\r\n{\r\nstruct xfs_buf *bp;\r\nxfs_daddr_t d;\r\nint error;\r\nASSERT(fsbno != NULLFSBLOCK);\r\nd = XFS_FSB_TO_DADDR(mp, fsbno);\r\nerror = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp, d,\r\nmp->m_bsize, lock, &bp, ops);\r\nif (error)\r\nreturn error;\r\nif (bp)\r\nxfs_buf_set_ref(bp, refval);\r\n*bpp = bp;\r\nreturn 0;\r\n}\r\nvoid\r\nxfs_btree_reada_bufl(\r\nstruct xfs_mount *mp,\r\nxfs_fsblock_t fsbno,\r\nxfs_extlen_t count,\r\nconst struct xfs_buf_ops *ops)\r\n{\r\nxfs_daddr_t d;\r\nASSERT(fsbno != NULLFSBLOCK);\r\nd = XFS_FSB_TO_DADDR(mp, fsbno);\r\nxfs_buf_readahead(mp->m_ddev_targp, d, mp->m_bsize * count, ops);\r\n}\r\nvoid\r\nxfs_btree_reada_bufs(\r\nstruct xfs_mount *mp,\r\nxfs_agnumber_t agno,\r\nxfs_agblock_t agbno,\r\nxfs_extlen_t count,\r\nconst struct xfs_buf_ops *ops)\r\n{\r\nxfs_daddr_t d;\r\nASSERT(agno != NULLAGNUMBER);\r\nASSERT(agbno != NULLAGBLOCK);\r\nd = XFS_AGB_TO_DADDR(mp, agno, agbno);\r\nxfs_buf_readahead(mp->m_ddev_targp, d, mp->m_bsize * count, ops);\r\n}\r\nSTATIC int\r\nxfs_btree_readahead_lblock(\r\nstruct xfs_btree_cur *cur,\r\nint lr,\r\nstruct xfs_btree_block *block)\r\n{\r\nint rval = 0;\r\nxfs_fsblock_t left = be64_to_cpu(block->bb_u.l.bb_leftsib);\r\nxfs_fsblock_t right = be64_to_cpu(block->bb_u.l.bb_rightsib);\r\nif ((lr & XFS_BTCUR_LEFTRA) && left != NULLFSBLOCK) {\r\nxfs_btree_reada_bufl(cur->bc_mp, left, 1,\r\ncur->bc_ops->buf_ops);\r\nrval++;\r\n}\r\nif ((lr & XFS_BTCUR_RIGHTRA) && right != NULLFSBLOCK) {\r\nxfs_btree_reada_bufl(cur->bc_mp, right, 1,\r\ncur->bc_ops->buf_ops);\r\nrval++;\r\n}\r\nreturn rval;\r\n}\r\nSTATIC int\r\nxfs_btree_readahead_sblock(\r\nstruct xfs_btree_cur *cur,\r\nint lr,\r\nstruct xfs_btree_block *block)\r\n{\r\nint rval = 0;\r\nxfs_agblock_t left = be32_to_cpu(block->bb_u.s.bb_leftsib);\r\nxfs_agblock_t right = be32_to_cpu(block->bb_u.s.bb_rightsib);\r\nif ((lr & XFS_BTCUR_LEFTRA) && left != NULLAGBLOCK) {\r\nxfs_btree_reada_bufs(cur->bc_mp, cur->bc_private.a.agno,\r\nleft, 1, cur->bc_ops->buf_ops);\r\nrval++;\r\n}\r\nif ((lr & XFS_BTCUR_RIGHTRA) && right != NULLAGBLOCK) {\r\nxfs_btree_reada_bufs(cur->bc_mp, cur->bc_private.a.agno,\r\nright, 1, cur->bc_ops->buf_ops);\r\nrval++;\r\n}\r\nreturn rval;\r\n}\r\nSTATIC int\r\nxfs_btree_readahead(\r\nstruct xfs_btree_cur *cur,\r\nint lev,\r\nint lr)\r\n{\r\nstruct xfs_btree_block *block;\r\nif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\r\n(lev == cur->bc_nlevels - 1))\r\nreturn 0;\r\nif ((cur->bc_ra[lev] | lr) == cur->bc_ra[lev])\r\nreturn 0;\r\ncur->bc_ra[lev] |= lr;\r\nblock = XFS_BUF_TO_BLOCK(cur->bc_bufs[lev]);\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nreturn xfs_btree_readahead_lblock(cur, lr, block);\r\nreturn xfs_btree_readahead_sblock(cur, lr, block);\r\n}\r\nSTATIC xfs_daddr_t\r\nxfs_btree_ptr_to_daddr(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr)\r\n{\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\r\nASSERT(ptr->l != cpu_to_be64(NULLFSBLOCK));\r\nreturn XFS_FSB_TO_DADDR(cur->bc_mp, be64_to_cpu(ptr->l));\r\n} else {\r\nASSERT(cur->bc_private.a.agno != NULLAGNUMBER);\r\nASSERT(ptr->s != cpu_to_be32(NULLAGBLOCK));\r\nreturn XFS_AGB_TO_DADDR(cur->bc_mp, cur->bc_private.a.agno,\r\nbe32_to_cpu(ptr->s));\r\n}\r\n}\r\nSTATIC void\r\nxfs_btree_readahead_ptr(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr,\r\nxfs_extlen_t count)\r\n{\r\nxfs_buf_readahead(cur->bc_mp->m_ddev_targp,\r\nxfs_btree_ptr_to_daddr(cur, ptr),\r\ncur->bc_mp->m_bsize * count, cur->bc_ops->buf_ops);\r\n}\r\nSTATIC void\r\nxfs_btree_setbuf(\r\nxfs_btree_cur_t *cur,\r\nint lev,\r\nxfs_buf_t *bp)\r\n{\r\nstruct xfs_btree_block *b;\r\nif (cur->bc_bufs[lev])\r\nxfs_trans_brelse(cur->bc_tp, cur->bc_bufs[lev]);\r\ncur->bc_bufs[lev] = bp;\r\ncur->bc_ra[lev] = 0;\r\nb = XFS_BUF_TO_BLOCK(bp);\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\r\nif (b->bb_u.l.bb_leftsib == cpu_to_be64(NULLFSBLOCK))\r\ncur->bc_ra[lev] |= XFS_BTCUR_LEFTRA;\r\nif (b->bb_u.l.bb_rightsib == cpu_to_be64(NULLFSBLOCK))\r\ncur->bc_ra[lev] |= XFS_BTCUR_RIGHTRA;\r\n} else {\r\nif (b->bb_u.s.bb_leftsib == cpu_to_be32(NULLAGBLOCK))\r\ncur->bc_ra[lev] |= XFS_BTCUR_LEFTRA;\r\nif (b->bb_u.s.bb_rightsib == cpu_to_be32(NULLAGBLOCK))\r\ncur->bc_ra[lev] |= XFS_BTCUR_RIGHTRA;\r\n}\r\n}\r\nSTATIC int\r\nxfs_btree_ptr_is_null(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr)\r\n{\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nreturn ptr->l == cpu_to_be64(NULLFSBLOCK);\r\nelse\r\nreturn ptr->s == cpu_to_be32(NULLAGBLOCK);\r\n}\r\nSTATIC void\r\nxfs_btree_set_ptr_null(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr)\r\n{\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nptr->l = cpu_to_be64(NULLFSBLOCK);\r\nelse\r\nptr->s = cpu_to_be32(NULLAGBLOCK);\r\n}\r\nSTATIC void\r\nxfs_btree_get_sibling(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_btree_block *block,\r\nunion xfs_btree_ptr *ptr,\r\nint lr)\r\n{\r\nASSERT(lr == XFS_BB_LEFTSIB || lr == XFS_BB_RIGHTSIB);\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\r\nif (lr == XFS_BB_RIGHTSIB)\r\nptr->l = block->bb_u.l.bb_rightsib;\r\nelse\r\nptr->l = block->bb_u.l.bb_leftsib;\r\n} else {\r\nif (lr == XFS_BB_RIGHTSIB)\r\nptr->s = block->bb_u.s.bb_rightsib;\r\nelse\r\nptr->s = block->bb_u.s.bb_leftsib;\r\n}\r\n}\r\nSTATIC void\r\nxfs_btree_set_sibling(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_btree_block *block,\r\nunion xfs_btree_ptr *ptr,\r\nint lr)\r\n{\r\nASSERT(lr == XFS_BB_LEFTSIB || lr == XFS_BB_RIGHTSIB);\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\r\nif (lr == XFS_BB_RIGHTSIB)\r\nblock->bb_u.l.bb_rightsib = ptr->l;\r\nelse\r\nblock->bb_u.l.bb_leftsib = ptr->l;\r\n} else {\r\nif (lr == XFS_BB_RIGHTSIB)\r\nblock->bb_u.s.bb_rightsib = ptr->s;\r\nelse\r\nblock->bb_u.s.bb_leftsib = ptr->s;\r\n}\r\n}\r\nvoid\r\nxfs_btree_init_block_int(\r\nstruct xfs_mount *mp,\r\nstruct xfs_btree_block *buf,\r\nxfs_daddr_t blkno,\r\n__u32 magic,\r\n__u16 level,\r\n__u16 numrecs,\r\n__u64 owner,\r\nunsigned int flags)\r\n{\r\nbuf->bb_magic = cpu_to_be32(magic);\r\nbuf->bb_level = cpu_to_be16(level);\r\nbuf->bb_numrecs = cpu_to_be16(numrecs);\r\nif (flags & XFS_BTREE_LONG_PTRS) {\r\nbuf->bb_u.l.bb_leftsib = cpu_to_be64(NULLFSBLOCK);\r\nbuf->bb_u.l.bb_rightsib = cpu_to_be64(NULLFSBLOCK);\r\nif (flags & XFS_BTREE_CRC_BLOCKS) {\r\nbuf->bb_u.l.bb_blkno = cpu_to_be64(blkno);\r\nbuf->bb_u.l.bb_owner = cpu_to_be64(owner);\r\nuuid_copy(&buf->bb_u.l.bb_uuid, &mp->m_sb.sb_uuid);\r\nbuf->bb_u.l.bb_pad = 0;\r\nbuf->bb_u.l.bb_lsn = 0;\r\n}\r\n} else {\r\n__u32 __owner = (__u32)owner;\r\nbuf->bb_u.s.bb_leftsib = cpu_to_be32(NULLAGBLOCK);\r\nbuf->bb_u.s.bb_rightsib = cpu_to_be32(NULLAGBLOCK);\r\nif (flags & XFS_BTREE_CRC_BLOCKS) {\r\nbuf->bb_u.s.bb_blkno = cpu_to_be64(blkno);\r\nbuf->bb_u.s.bb_owner = cpu_to_be32(__owner);\r\nuuid_copy(&buf->bb_u.s.bb_uuid, &mp->m_sb.sb_uuid);\r\nbuf->bb_u.s.bb_lsn = 0;\r\n}\r\n}\r\n}\r\nvoid\r\nxfs_btree_init_block(\r\nstruct xfs_mount *mp,\r\nstruct xfs_buf *bp,\r\n__u32 magic,\r\n__u16 level,\r\n__u16 numrecs,\r\n__u64 owner,\r\nunsigned int flags)\r\n{\r\nxfs_btree_init_block_int(mp, XFS_BUF_TO_BLOCK(bp), bp->b_bn,\r\nmagic, level, numrecs, owner, flags);\r\n}\r\nSTATIC void\r\nxfs_btree_init_block_cur(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp,\r\nint level,\r\nint numrecs)\r\n{\r\n__u64 owner;\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nowner = cur->bc_private.b.ip->i_ino;\r\nelse\r\nowner = cur->bc_private.a.agno;\r\nxfs_btree_init_block_int(cur->bc_mp, XFS_BUF_TO_BLOCK(bp), bp->b_bn,\r\nxfs_btree_magic(cur), level, numrecs,\r\nowner, cur->bc_flags);\r\n}\r\nSTATIC int\r\nxfs_btree_is_lastrec(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_btree_block *block,\r\nint level)\r\n{\r\nunion xfs_btree_ptr ptr;\r\nif (level > 0)\r\nreturn 0;\r\nif (!(cur->bc_flags & XFS_BTREE_LASTREC_UPDATE))\r\nreturn 0;\r\nxfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\r\nif (!xfs_btree_ptr_is_null(cur, &ptr))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nSTATIC void\r\nxfs_btree_buf_to_ptr(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp,\r\nunion xfs_btree_ptr *ptr)\r\n{\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nptr->l = cpu_to_be64(XFS_DADDR_TO_FSB(cur->bc_mp,\r\nXFS_BUF_ADDR(bp)));\r\nelse {\r\nptr->s = cpu_to_be32(xfs_daddr_to_agbno(cur->bc_mp,\r\nXFS_BUF_ADDR(bp)));\r\n}\r\n}\r\nSTATIC void\r\nxfs_btree_set_refs(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp)\r\n{\r\nswitch (cur->bc_btnum) {\r\ncase XFS_BTNUM_BNO:\r\ncase XFS_BTNUM_CNT:\r\nxfs_buf_set_ref(bp, XFS_ALLOC_BTREE_REF);\r\nbreak;\r\ncase XFS_BTNUM_INO:\r\ncase XFS_BTNUM_FINO:\r\nxfs_buf_set_ref(bp, XFS_INO_BTREE_REF);\r\nbreak;\r\ncase XFS_BTNUM_BMAP:\r\nxfs_buf_set_ref(bp, XFS_BMAP_BTREE_REF);\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\n}\r\n}\r\nSTATIC int\r\nxfs_btree_get_buf_block(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr,\r\nint flags,\r\nstruct xfs_btree_block **block,\r\nstruct xfs_buf **bpp)\r\n{\r\nstruct xfs_mount *mp = cur->bc_mp;\r\nxfs_daddr_t d;\r\nASSERT(!(flags & XBF_TRYLOCK));\r\nd = xfs_btree_ptr_to_daddr(cur, ptr);\r\n*bpp = xfs_trans_get_buf(cur->bc_tp, mp->m_ddev_targp, d,\r\nmp->m_bsize, flags);\r\nif (!*bpp)\r\nreturn -ENOMEM;\r\n(*bpp)->b_ops = cur->bc_ops->buf_ops;\r\n*block = XFS_BUF_TO_BLOCK(*bpp);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_read_buf_block(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr,\r\nint flags,\r\nstruct xfs_btree_block **block,\r\nstruct xfs_buf **bpp)\r\n{\r\nstruct xfs_mount *mp = cur->bc_mp;\r\nxfs_daddr_t d;\r\nint error;\r\nASSERT(!(flags & XBF_TRYLOCK));\r\nd = xfs_btree_ptr_to_daddr(cur, ptr);\r\nerror = xfs_trans_read_buf(mp, cur->bc_tp, mp->m_ddev_targp, d,\r\nmp->m_bsize, flags, bpp,\r\ncur->bc_ops->buf_ops);\r\nif (error)\r\nreturn error;\r\nxfs_btree_set_refs(cur, *bpp);\r\n*block = XFS_BUF_TO_BLOCK(*bpp);\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxfs_btree_copy_keys(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_key *dst_key,\r\nunion xfs_btree_key *src_key,\r\nint numkeys)\r\n{\r\nASSERT(numkeys >= 0);\r\nmemcpy(dst_key, src_key, numkeys * cur->bc_ops->key_len);\r\n}\r\nSTATIC void\r\nxfs_btree_copy_recs(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec *dst_rec,\r\nunion xfs_btree_rec *src_rec,\r\nint numrecs)\r\n{\r\nASSERT(numrecs >= 0);\r\nmemcpy(dst_rec, src_rec, numrecs * cur->bc_ops->rec_len);\r\n}\r\nSTATIC void\r\nxfs_btree_copy_ptrs(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *dst_ptr,\r\nunion xfs_btree_ptr *src_ptr,\r\nint numptrs)\r\n{\r\nASSERT(numptrs >= 0);\r\nmemcpy(dst_ptr, src_ptr, numptrs * xfs_btree_ptr_len(cur));\r\n}\r\nSTATIC void\r\nxfs_btree_shift_keys(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_key *key,\r\nint dir,\r\nint numkeys)\r\n{\r\nchar *dst_key;\r\nASSERT(numkeys >= 0);\r\nASSERT(dir == 1 || dir == -1);\r\ndst_key = (char *)key + (dir * cur->bc_ops->key_len);\r\nmemmove(dst_key, key, numkeys * cur->bc_ops->key_len);\r\n}\r\nSTATIC void\r\nxfs_btree_shift_recs(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec *rec,\r\nint dir,\r\nint numrecs)\r\n{\r\nchar *dst_rec;\r\nASSERT(numrecs >= 0);\r\nASSERT(dir == 1 || dir == -1);\r\ndst_rec = (char *)rec + (dir * cur->bc_ops->rec_len);\r\nmemmove(dst_rec, rec, numrecs * cur->bc_ops->rec_len);\r\n}\r\nSTATIC void\r\nxfs_btree_shift_ptrs(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr,\r\nint dir,\r\nint numptrs)\r\n{\r\nchar *dst_ptr;\r\nASSERT(numptrs >= 0);\r\nASSERT(dir == 1 || dir == -1);\r\ndst_ptr = (char *)ptr + (dir * xfs_btree_ptr_len(cur));\r\nmemmove(dst_ptr, ptr, numptrs * xfs_btree_ptr_len(cur));\r\n}\r\nSTATIC void\r\nxfs_btree_log_keys(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp,\r\nint first,\r\nint last)\r\n{\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGBII(cur, bp, first, last);\r\nif (bp) {\r\nxfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\r\nxfs_trans_log_buf(cur->bc_tp, bp,\r\nxfs_btree_key_offset(cur, first),\r\nxfs_btree_key_offset(cur, last + 1) - 1);\r\n} else {\r\nxfs_trans_log_inode(cur->bc_tp, cur->bc_private.b.ip,\r\nxfs_ilog_fbroot(cur->bc_private.b.whichfork));\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n}\r\nvoid\r\nxfs_btree_log_recs(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp,\r\nint first,\r\nint last)\r\n{\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGBII(cur, bp, first, last);\r\nxfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\r\nxfs_trans_log_buf(cur->bc_tp, bp,\r\nxfs_btree_rec_offset(cur, first),\r\nxfs_btree_rec_offset(cur, last + 1) - 1);\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n}\r\nSTATIC void\r\nxfs_btree_log_ptrs(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp,\r\nint first,\r\nint last)\r\n{\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGBII(cur, bp, first, last);\r\nif (bp) {\r\nstruct xfs_btree_block *block = XFS_BUF_TO_BLOCK(bp);\r\nint level = xfs_btree_get_level(block);\r\nxfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\r\nxfs_trans_log_buf(cur->bc_tp, bp,\r\nxfs_btree_ptr_offset(cur, first, level),\r\nxfs_btree_ptr_offset(cur, last + 1, level) - 1);\r\n} else {\r\nxfs_trans_log_inode(cur->bc_tp, cur->bc_private.b.ip,\r\nxfs_ilog_fbroot(cur->bc_private.b.whichfork));\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n}\r\nvoid\r\nxfs_btree_log_block(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp,\r\nint fields)\r\n{\r\nint first;\r\nint last;\r\nstatic const short soffsets[] = {\r\noffsetof(struct xfs_btree_block, bb_magic),\r\noffsetof(struct xfs_btree_block, bb_level),\r\noffsetof(struct xfs_btree_block, bb_numrecs),\r\noffsetof(struct xfs_btree_block, bb_u.s.bb_leftsib),\r\noffsetof(struct xfs_btree_block, bb_u.s.bb_rightsib),\r\noffsetof(struct xfs_btree_block, bb_u.s.bb_blkno),\r\noffsetof(struct xfs_btree_block, bb_u.s.bb_lsn),\r\noffsetof(struct xfs_btree_block, bb_u.s.bb_uuid),\r\noffsetof(struct xfs_btree_block, bb_u.s.bb_owner),\r\noffsetof(struct xfs_btree_block, bb_u.s.bb_crc),\r\nXFS_BTREE_SBLOCK_CRC_LEN\r\n};\r\nstatic const short loffsets[] = {\r\noffsetof(struct xfs_btree_block, bb_magic),\r\noffsetof(struct xfs_btree_block, bb_level),\r\noffsetof(struct xfs_btree_block, bb_numrecs),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_leftsib),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_rightsib),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_blkno),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_lsn),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_uuid),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_owner),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_crc),\r\noffsetof(struct xfs_btree_block, bb_u.l.bb_pad),\r\nXFS_BTREE_LBLOCK_CRC_LEN\r\n};\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGBI(cur, bp, fields);\r\nif (bp) {\r\nint nbits;\r\nif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS) {\r\nif (fields == XFS_BB_ALL_BITS)\r\nfields = XFS_BB_ALL_BITS_CRC;\r\nnbits = XFS_BB_NUM_BITS_CRC;\r\n} else {\r\nnbits = XFS_BB_NUM_BITS;\r\n}\r\nxfs_btree_offsets(fields,\r\n(cur->bc_flags & XFS_BTREE_LONG_PTRS) ?\r\nloffsets : soffsets,\r\nnbits, &first, &last);\r\nxfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\r\nxfs_trans_log_buf(cur->bc_tp, bp, first, last);\r\n} else {\r\nxfs_trans_log_inode(cur->bc_tp, cur->bc_private.b.ip,\r\nxfs_ilog_fbroot(cur->bc_private.b.whichfork));\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n}\r\nint\r\nxfs_btree_increment(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint *stat)\r\n{\r\nstruct xfs_btree_block *block;\r\nunion xfs_btree_ptr ptr;\r\nstruct xfs_buf *bp;\r\nint error;\r\nint lev;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGI(cur, level);\r\nASSERT(level < cur->bc_nlevels);\r\nxfs_btree_readahead(cur, level, XFS_BTCUR_RIGHTRA);\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, level, bp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nif (++cur->bc_ptrs[level] <= xfs_btree_get_numrecs(block))\r\ngoto out1;\r\nxfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\r\nif (xfs_btree_ptr_is_null(cur, &ptr))\r\ngoto out0;\r\nXFS_BTREE_STATS_INC(cur, increment);\r\nfor (lev = level + 1; lev < cur->bc_nlevels; lev++) {\r\nblock = xfs_btree_get_block(cur, lev, &bp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, lev, bp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nif (++cur->bc_ptrs[lev] <= xfs_btree_get_numrecs(block))\r\nbreak;\r\nxfs_btree_readahead(cur, lev, XFS_BTCUR_RIGHTRA);\r\n}\r\nif (lev == cur->bc_nlevels) {\r\nif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE)\r\ngoto out0;\r\nASSERT(0);\r\nerror = -EFSCORRUPTED;\r\ngoto error0;\r\n}\r\nASSERT(lev < cur->bc_nlevels);\r\nfor (block = xfs_btree_get_block(cur, lev, &bp); lev > level; ) {\r\nunion xfs_btree_ptr *ptrp;\r\nptrp = xfs_btree_ptr_addr(cur, cur->bc_ptrs[lev], block);\r\n--lev;\r\nerror = xfs_btree_read_buf_block(cur, ptrp, 0, &block, &bp);\r\nif (error)\r\ngoto error0;\r\nxfs_btree_setbuf(cur, lev, bp);\r\ncur->bc_ptrs[lev] = 1;\r\n}\r\nout1:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\nout0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nint\r\nxfs_btree_decrement(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint *stat)\r\n{\r\nstruct xfs_btree_block *block;\r\nxfs_buf_t *bp;\r\nint error;\r\nint lev;\r\nunion xfs_btree_ptr ptr;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGI(cur, level);\r\nASSERT(level < cur->bc_nlevels);\r\nxfs_btree_readahead(cur, level, XFS_BTCUR_LEFTRA);\r\nif (--cur->bc_ptrs[level] > 0)\r\ngoto out1;\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, level, bp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_get_sibling(cur, block, &ptr, XFS_BB_LEFTSIB);\r\nif (xfs_btree_ptr_is_null(cur, &ptr))\r\ngoto out0;\r\nXFS_BTREE_STATS_INC(cur, decrement);\r\nfor (lev = level + 1; lev < cur->bc_nlevels; lev++) {\r\nif (--cur->bc_ptrs[lev] > 0)\r\nbreak;\r\nxfs_btree_readahead(cur, lev, XFS_BTCUR_LEFTRA);\r\n}\r\nif (lev == cur->bc_nlevels) {\r\nif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE)\r\ngoto out0;\r\nASSERT(0);\r\nerror = -EFSCORRUPTED;\r\ngoto error0;\r\n}\r\nASSERT(lev < cur->bc_nlevels);\r\nfor (block = xfs_btree_get_block(cur, lev, &bp); lev > level; ) {\r\nunion xfs_btree_ptr *ptrp;\r\nptrp = xfs_btree_ptr_addr(cur, cur->bc_ptrs[lev], block);\r\n--lev;\r\nerror = xfs_btree_read_buf_block(cur, ptrp, 0, &block, &bp);\r\nif (error)\r\ngoto error0;\r\nxfs_btree_setbuf(cur, lev, bp);\r\ncur->bc_ptrs[lev] = xfs_btree_get_numrecs(block);\r\n}\r\nout1:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\nout0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_btree_lookup_get_block(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nunion xfs_btree_ptr *pp,\r\nstruct xfs_btree_block **blkp)\r\n{\r\nstruct xfs_buf *bp;\r\nint error = 0;\r\nif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\r\n(level == cur->bc_nlevels - 1)) {\r\n*blkp = xfs_btree_get_iroot(cur);\r\nreturn 0;\r\n}\r\nbp = cur->bc_bufs[level];\r\nif (bp && XFS_BUF_ADDR(bp) == xfs_btree_ptr_to_daddr(cur, pp)) {\r\n*blkp = XFS_BUF_TO_BLOCK(bp);\r\nreturn 0;\r\n}\r\nerror = xfs_btree_read_buf_block(cur, pp, 0, blkp, &bp);\r\nif (error)\r\nreturn error;\r\nxfs_btree_setbuf(cur, level, bp);\r\nreturn 0;\r\n}\r\nSTATIC union xfs_btree_key *\r\nxfs_lookup_get_search_key(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint keyno,\r\nstruct xfs_btree_block *block,\r\nunion xfs_btree_key *kp)\r\n{\r\nif (level == 0) {\r\ncur->bc_ops->init_key_from_rec(kp,\r\nxfs_btree_rec_addr(cur, keyno, block));\r\nreturn kp;\r\n}\r\nreturn xfs_btree_key_addr(cur, keyno, block);\r\n}\r\nint\r\nxfs_btree_lookup(\r\nstruct xfs_btree_cur *cur,\r\nxfs_lookup_t dir,\r\nint *stat)\r\n{\r\nstruct xfs_btree_block *block;\r\n__int64_t diff;\r\nint error;\r\nint keyno;\r\nint level;\r\nunion xfs_btree_ptr *pp;\r\nunion xfs_btree_ptr ptr;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGI(cur, dir);\r\nXFS_BTREE_STATS_INC(cur, lookup);\r\nblock = NULL;\r\nkeyno = 0;\r\ncur->bc_ops->init_ptr_from_cur(cur, &ptr);\r\npp = &ptr;\r\nfor (level = cur->bc_nlevels - 1, diff = 1; level >= 0; level--) {\r\nerror = xfs_btree_lookup_get_block(cur, level, pp, &block);\r\nif (error)\r\ngoto error0;\r\nif (diff == 0) {\r\nkeyno = 1;\r\n} else {\r\nint high;\r\nint low;\r\nlow = 1;\r\nhigh = xfs_btree_get_numrecs(block);\r\nif (!high) {\r\nASSERT(level == 0 && cur->bc_nlevels == 1);\r\ncur->bc_ptrs[0] = dir != XFS_LOOKUP_LE;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\nwhile (low <= high) {\r\nunion xfs_btree_key key;\r\nunion xfs_btree_key *kp;\r\nXFS_BTREE_STATS_INC(cur, compare);\r\nkeyno = (low + high) >> 1;\r\nkp = xfs_lookup_get_search_key(cur, level,\r\nkeyno, block, &key);\r\ndiff = cur->bc_ops->key_diff(cur, kp);\r\nif (diff < 0)\r\nlow = keyno + 1;\r\nelse if (diff > 0)\r\nhigh = keyno - 1;\r\nelse\r\nbreak;\r\n}\r\n}\r\nif (level > 0) {\r\nif (diff > 0 && --keyno < 1)\r\nkeyno = 1;\r\npp = xfs_btree_ptr_addr(cur, keyno, block);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_ptr(cur, pp, 0, level);\r\nif (error)\r\ngoto error0;\r\n#endif\r\ncur->bc_ptrs[level] = keyno;\r\n}\r\n}\r\nif (dir != XFS_LOOKUP_LE && diff < 0) {\r\nkeyno++;\r\nxfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\r\nif (dir == XFS_LOOKUP_GE &&\r\nkeyno > xfs_btree_get_numrecs(block) &&\r\n!xfs_btree_ptr_is_null(cur, &ptr)) {\r\nint i;\r\ncur->bc_ptrs[0] = keyno;\r\nerror = xfs_btree_increment(cur, 0, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\n}\r\n} else if (dir == XFS_LOOKUP_LE && diff > 0)\r\nkeyno--;\r\ncur->bc_ptrs[0] = keyno;\r\nif (keyno == 0 || keyno > xfs_btree_get_numrecs(block))\r\n*stat = 0;\r\nelse if (dir != XFS_LOOKUP_EQ || diff == 0)\r\n*stat = 1;\r\nelse\r\n*stat = 0;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_btree_updkey(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_key *keyp,\r\nint level)\r\n{\r\nstruct xfs_btree_block *block;\r\nstruct xfs_buf *bp;\r\nunion xfs_btree_key *kp;\r\nint ptr;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGIK(cur, level, keyp);\r\nASSERT(!(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) || level >= 1);\r\nfor (ptr = 1; ptr == 1 && level < cur->bc_nlevels; level++) {\r\n#ifdef DEBUG\r\nint error;\r\n#endif\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, level, bp);\r\nif (error) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\n#endif\r\nptr = cur->bc_ptrs[level];\r\nkp = xfs_btree_key_addr(cur, ptr, block);\r\nxfs_btree_copy_keys(cur, kp, keyp, 1);\r\nxfs_btree_log_keys(cur, bp, ptr, ptr);\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn 0;\r\n}\r\nint\r\nxfs_btree_update(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec *rec)\r\n{\r\nstruct xfs_btree_block *block;\r\nstruct xfs_buf *bp;\r\nint error;\r\nint ptr;\r\nunion xfs_btree_rec *rp;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGR(cur, rec);\r\nblock = xfs_btree_get_block(cur, 0, &bp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, 0, bp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nptr = cur->bc_ptrs[0];\r\nrp = xfs_btree_rec_addr(cur, ptr, block);\r\nxfs_btree_copy_recs(cur, rp, rec, 1);\r\nxfs_btree_log_recs(cur, bp, ptr, ptr);\r\nif (xfs_btree_is_lastrec(cur, block, 0)) {\r\ncur->bc_ops->update_lastrec(cur, block, rec,\r\nptr, LASTREC_UPDATE);\r\n}\r\nif (ptr == 1) {\r\nunion xfs_btree_key key;\r\ncur->bc_ops->init_key_from_rec(&key, rec);\r\nerror = xfs_btree_updkey(cur, &key, 1);\r\nif (error)\r\ngoto error0;\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_btree_lshift(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint *stat)\r\n{\r\nunion xfs_btree_key key;\r\nstruct xfs_buf *lbp;\r\nstruct xfs_btree_block *left;\r\nint lrecs;\r\nstruct xfs_buf *rbp;\r\nstruct xfs_btree_block *right;\r\nint rrecs;\r\nunion xfs_btree_ptr lptr;\r\nunion xfs_btree_key *rkp = NULL;\r\nunion xfs_btree_ptr *rpp = NULL;\r\nunion xfs_btree_rec *rrp = NULL;\r\nint error;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGI(cur, level);\r\nif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\r\nlevel == cur->bc_nlevels - 1)\r\ngoto out0;\r\nright = xfs_btree_get_block(cur, level, &rbp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, right, level, rbp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_get_sibling(cur, right, &lptr, XFS_BB_LEFTSIB);\r\nif (xfs_btree_ptr_is_null(cur, &lptr))\r\ngoto out0;\r\nif (cur->bc_ptrs[level] <= 1)\r\ngoto out0;\r\nerror = xfs_btree_read_buf_block(cur, &lptr, 0, &left, &lbp);\r\nif (error)\r\ngoto error0;\r\nlrecs = xfs_btree_get_numrecs(left);\r\nif (lrecs == cur->bc_ops->get_maxrecs(cur, level))\r\ngoto out0;\r\nrrecs = xfs_btree_get_numrecs(right);\r\nlrecs++;\r\nrrecs--;\r\nXFS_BTREE_STATS_INC(cur, lshift);\r\nXFS_BTREE_STATS_ADD(cur, moves, 1);\r\nif (level > 0) {\r\nunion xfs_btree_key *lkp;\r\nunion xfs_btree_ptr *lpp;\r\nlkp = xfs_btree_key_addr(cur, lrecs, left);\r\nrkp = xfs_btree_key_addr(cur, 1, right);\r\nlpp = xfs_btree_ptr_addr(cur, lrecs, left);\r\nrpp = xfs_btree_ptr_addr(cur, 1, right);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_ptr(cur, rpp, 0, level);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_copy_keys(cur, lkp, rkp, 1);\r\nxfs_btree_copy_ptrs(cur, lpp, rpp, 1);\r\nxfs_btree_log_keys(cur, lbp, lrecs, lrecs);\r\nxfs_btree_log_ptrs(cur, lbp, lrecs, lrecs);\r\nASSERT(cur->bc_ops->keys_inorder(cur,\r\nxfs_btree_key_addr(cur, lrecs - 1, left), lkp));\r\n} else {\r\nunion xfs_btree_rec *lrp;\r\nlrp = xfs_btree_rec_addr(cur, lrecs, left);\r\nrrp = xfs_btree_rec_addr(cur, 1, right);\r\nxfs_btree_copy_recs(cur, lrp, rrp, 1);\r\nxfs_btree_log_recs(cur, lbp, lrecs, lrecs);\r\nASSERT(cur->bc_ops->recs_inorder(cur,\r\nxfs_btree_rec_addr(cur, lrecs - 1, left), lrp));\r\n}\r\nxfs_btree_set_numrecs(left, lrecs);\r\nxfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS);\r\nxfs_btree_set_numrecs(right, rrecs);\r\nxfs_btree_log_block(cur, rbp, XFS_BB_NUMRECS);\r\nXFS_BTREE_STATS_ADD(cur, moves, rrecs - 1);\r\nif (level > 0) {\r\n#ifdef DEBUG\r\nint i;\r\nfor (i = 0; i < rrecs; i++) {\r\nerror = xfs_btree_check_ptr(cur, rpp, i + 1, level);\r\nif (error)\r\ngoto error0;\r\n}\r\n#endif\r\nxfs_btree_shift_keys(cur,\r\nxfs_btree_key_addr(cur, 2, right),\r\n-1, rrecs);\r\nxfs_btree_shift_ptrs(cur,\r\nxfs_btree_ptr_addr(cur, 2, right),\r\n-1, rrecs);\r\nxfs_btree_log_keys(cur, rbp, 1, rrecs);\r\nxfs_btree_log_ptrs(cur, rbp, 1, rrecs);\r\n} else {\r\nxfs_btree_shift_recs(cur,\r\nxfs_btree_rec_addr(cur, 2, right),\r\n-1, rrecs);\r\nxfs_btree_log_recs(cur, rbp, 1, rrecs);\r\ncur->bc_ops->init_key_from_rec(&key,\r\nxfs_btree_rec_addr(cur, 1, right));\r\nrkp = &key;\r\n}\r\nerror = xfs_btree_updkey(cur, rkp, level + 1);\r\nif (error)\r\ngoto error0;\r\ncur->bc_ptrs[level]--;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\nout0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_btree_rshift(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint *stat)\r\n{\r\nunion xfs_btree_key key;\r\nstruct xfs_buf *lbp;\r\nstruct xfs_btree_block *left;\r\nstruct xfs_buf *rbp;\r\nstruct xfs_btree_block *right;\r\nstruct xfs_btree_cur *tcur;\r\nunion xfs_btree_ptr rptr;\r\nunion xfs_btree_key *rkp;\r\nint rrecs;\r\nint lrecs;\r\nint error;\r\nint i;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGI(cur, level);\r\nif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\r\n(level == cur->bc_nlevels - 1))\r\ngoto out0;\r\nleft = xfs_btree_get_block(cur, level, &lbp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, left, level, lbp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_get_sibling(cur, left, &rptr, XFS_BB_RIGHTSIB);\r\nif (xfs_btree_ptr_is_null(cur, &rptr))\r\ngoto out0;\r\nlrecs = xfs_btree_get_numrecs(left);\r\nif (cur->bc_ptrs[level] >= lrecs)\r\ngoto out0;\r\nerror = xfs_btree_read_buf_block(cur, &rptr, 0, &right, &rbp);\r\nif (error)\r\ngoto error0;\r\nrrecs = xfs_btree_get_numrecs(right);\r\nif (rrecs == cur->bc_ops->get_maxrecs(cur, level))\r\ngoto out0;\r\nXFS_BTREE_STATS_INC(cur, rshift);\r\nXFS_BTREE_STATS_ADD(cur, moves, rrecs);\r\nif (level > 0) {\r\nunion xfs_btree_key *lkp;\r\nunion xfs_btree_ptr *lpp;\r\nunion xfs_btree_ptr *rpp;\r\nlkp = xfs_btree_key_addr(cur, lrecs, left);\r\nlpp = xfs_btree_ptr_addr(cur, lrecs, left);\r\nrkp = xfs_btree_key_addr(cur, 1, right);\r\nrpp = xfs_btree_ptr_addr(cur, 1, right);\r\n#ifdef DEBUG\r\nfor (i = rrecs - 1; i >= 0; i--) {\r\nerror = xfs_btree_check_ptr(cur, rpp, i, level);\r\nif (error)\r\ngoto error0;\r\n}\r\n#endif\r\nxfs_btree_shift_keys(cur, rkp, 1, rrecs);\r\nxfs_btree_shift_ptrs(cur, rpp, 1, rrecs);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_ptr(cur, lpp, 0, level);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_copy_keys(cur, rkp, lkp, 1);\r\nxfs_btree_copy_ptrs(cur, rpp, lpp, 1);\r\nxfs_btree_log_keys(cur, rbp, 1, rrecs + 1);\r\nxfs_btree_log_ptrs(cur, rbp, 1, rrecs + 1);\r\nASSERT(cur->bc_ops->keys_inorder(cur, rkp,\r\nxfs_btree_key_addr(cur, 2, right)));\r\n} else {\r\nunion xfs_btree_rec *lrp;\r\nunion xfs_btree_rec *rrp;\r\nlrp = xfs_btree_rec_addr(cur, lrecs, left);\r\nrrp = xfs_btree_rec_addr(cur, 1, right);\r\nxfs_btree_shift_recs(cur, rrp, 1, rrecs);\r\nxfs_btree_copy_recs(cur, rrp, lrp, 1);\r\nxfs_btree_log_recs(cur, rbp, 1, rrecs + 1);\r\ncur->bc_ops->init_key_from_rec(&key, rrp);\r\nrkp = &key;\r\nASSERT(cur->bc_ops->recs_inorder(cur, rrp,\r\nxfs_btree_rec_addr(cur, 2, right)));\r\n}\r\nxfs_btree_set_numrecs(left, --lrecs);\r\nxfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS);\r\nxfs_btree_set_numrecs(right, ++rrecs);\r\nxfs_btree_log_block(cur, rbp, XFS_BB_NUMRECS);\r\nerror = xfs_btree_dup_cursor(cur, &tcur);\r\nif (error)\r\ngoto error0;\r\ni = xfs_btree_lastrec(tcur, level);\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\nerror = xfs_btree_increment(tcur, level, &i);\r\nif (error)\r\ngoto error1;\r\nerror = xfs_btree_updkey(tcur, rkp, level + 1);\r\nif (error)\r\ngoto error1;\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\nout0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\nerror1:\r\nXFS_BTREE_TRACE_CURSOR(tcur, XBT_ERROR);\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\n__xfs_btree_split(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nunion xfs_btree_ptr *ptrp,\r\nunion xfs_btree_key *key,\r\nstruct xfs_btree_cur **curp,\r\nint *stat)\r\n{\r\nunion xfs_btree_ptr lptr;\r\nstruct xfs_buf *lbp;\r\nstruct xfs_btree_block *left;\r\nunion xfs_btree_ptr rptr;\r\nstruct xfs_buf *rbp;\r\nstruct xfs_btree_block *right;\r\nunion xfs_btree_ptr rrptr;\r\nstruct xfs_buf *rrbp;\r\nstruct xfs_btree_block *rrblock;\r\nint lrecs;\r\nint rrecs;\r\nint src_index;\r\nint error;\r\n#ifdef DEBUG\r\nint i;\r\n#endif\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGIPK(cur, level, *ptrp, key);\r\nXFS_BTREE_STATS_INC(cur, split);\r\nleft = xfs_btree_get_block(cur, level, &lbp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, left, level, lbp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_buf_to_ptr(cur, lbp, &lptr);\r\nerror = cur->bc_ops->alloc_block(cur, &lptr, &rptr, stat);\r\nif (error)\r\ngoto error0;\r\nif (*stat == 0)\r\ngoto out0;\r\nXFS_BTREE_STATS_INC(cur, alloc);\r\nerror = xfs_btree_get_buf_block(cur, &rptr, 0, &right, &rbp);\r\nif (error)\r\ngoto error0;\r\nxfs_btree_init_block_cur(cur, rbp, xfs_btree_get_level(left), 0);\r\nlrecs = xfs_btree_get_numrecs(left);\r\nrrecs = lrecs / 2;\r\nif ((lrecs & 1) && cur->bc_ptrs[level] <= rrecs + 1)\r\nrrecs++;\r\nsrc_index = (lrecs - rrecs + 1);\r\nXFS_BTREE_STATS_ADD(cur, moves, rrecs);\r\nif (level > 0) {\r\nunion xfs_btree_key *lkp;\r\nunion xfs_btree_ptr *lpp;\r\nunion xfs_btree_key *rkp;\r\nunion xfs_btree_ptr *rpp;\r\nlkp = xfs_btree_key_addr(cur, src_index, left);\r\nlpp = xfs_btree_ptr_addr(cur, src_index, left);\r\nrkp = xfs_btree_key_addr(cur, 1, right);\r\nrpp = xfs_btree_ptr_addr(cur, 1, right);\r\n#ifdef DEBUG\r\nfor (i = src_index; i < rrecs; i++) {\r\nerror = xfs_btree_check_ptr(cur, lpp, i, level);\r\nif (error)\r\ngoto error0;\r\n}\r\n#endif\r\nxfs_btree_copy_keys(cur, rkp, lkp, rrecs);\r\nxfs_btree_copy_ptrs(cur, rpp, lpp, rrecs);\r\nxfs_btree_log_keys(cur, rbp, 1, rrecs);\r\nxfs_btree_log_ptrs(cur, rbp, 1, rrecs);\r\nxfs_btree_copy_keys(cur, key, rkp, 1);\r\n} else {\r\nunion xfs_btree_rec *lrp;\r\nunion xfs_btree_rec *rrp;\r\nlrp = xfs_btree_rec_addr(cur, src_index, left);\r\nrrp = xfs_btree_rec_addr(cur, 1, right);\r\nxfs_btree_copy_recs(cur, rrp, lrp, rrecs);\r\nxfs_btree_log_recs(cur, rbp, 1, rrecs);\r\ncur->bc_ops->init_key_from_rec(key,\r\nxfs_btree_rec_addr(cur, 1, right));\r\n}\r\nxfs_btree_get_sibling(cur, left, &rrptr, XFS_BB_RIGHTSIB);\r\nxfs_btree_set_sibling(cur, right, &rrptr, XFS_BB_RIGHTSIB);\r\nxfs_btree_set_sibling(cur, right, &lptr, XFS_BB_LEFTSIB);\r\nxfs_btree_set_sibling(cur, left, &rptr, XFS_BB_RIGHTSIB);\r\nlrecs -= rrecs;\r\nxfs_btree_set_numrecs(left, lrecs);\r\nxfs_btree_set_numrecs(right, xfs_btree_get_numrecs(right) + rrecs);\r\nxfs_btree_log_block(cur, rbp, XFS_BB_ALL_BITS);\r\nxfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS | XFS_BB_RIGHTSIB);\r\nif (!xfs_btree_ptr_is_null(cur, &rrptr)) {\r\nerror = xfs_btree_read_buf_block(cur, &rrptr,\r\n0, &rrblock, &rrbp);\r\nif (error)\r\ngoto error0;\r\nxfs_btree_set_sibling(cur, rrblock, &rptr, XFS_BB_LEFTSIB);\r\nxfs_btree_log_block(cur, rrbp, XFS_BB_LEFTSIB);\r\n}\r\nif (cur->bc_ptrs[level] > lrecs + 1) {\r\nxfs_btree_setbuf(cur, level, rbp);\r\ncur->bc_ptrs[level] -= lrecs;\r\n}\r\nif (level + 1 < cur->bc_nlevels) {\r\nerror = xfs_btree_dup_cursor(cur, curp);\r\nif (error)\r\ngoto error0;\r\n(*curp)->bc_ptrs[level + 1]++;\r\n}\r\n*ptrp = rptr;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\nout0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nstatic void\r\nxfs_btree_split_worker(\r\nstruct work_struct *work)\r\n{\r\nstruct xfs_btree_split_args *args = container_of(work,\r\nstruct xfs_btree_split_args, work);\r\nunsigned long pflags;\r\nunsigned long new_pflags = PF_FSTRANS;\r\nif (args->kswapd)\r\nnew_pflags |= PF_MEMALLOC | PF_SWAPWRITE | PF_KSWAPD;\r\ncurrent_set_flags_nested(&pflags, new_pflags);\r\nargs->result = __xfs_btree_split(args->cur, args->level, args->ptrp,\r\nargs->key, args->curp, args->stat);\r\ncomplete(args->done);\r\ncurrent_restore_flags_nested(&pflags, new_pflags);\r\n}\r\nSTATIC int\r\nxfs_btree_split(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nunion xfs_btree_ptr *ptrp,\r\nunion xfs_btree_key *key,\r\nstruct xfs_btree_cur **curp,\r\nint *stat)\r\n{\r\nstruct xfs_btree_split_args args;\r\nDECLARE_COMPLETION_ONSTACK(done);\r\nif (cur->bc_btnum != XFS_BTNUM_BMAP)\r\nreturn __xfs_btree_split(cur, level, ptrp, key, curp, stat);\r\nargs.cur = cur;\r\nargs.level = level;\r\nargs.ptrp = ptrp;\r\nargs.key = key;\r\nargs.curp = curp;\r\nargs.stat = stat;\r\nargs.done = &done;\r\nargs.kswapd = current_is_kswapd();\r\nINIT_WORK_ONSTACK(&args.work, xfs_btree_split_worker);\r\nqueue_work(xfs_alloc_wq, &args.work);\r\nwait_for_completion(&done);\r\ndestroy_work_on_stack(&args.work);\r\nreturn args.result;\r\n}\r\nint\r\nxfs_btree_new_iroot(\r\nstruct xfs_btree_cur *cur,\r\nint *logflags,\r\nint *stat)\r\n{\r\nstruct xfs_buf *cbp;\r\nstruct xfs_btree_block *block;\r\nstruct xfs_btree_block *cblock;\r\nunion xfs_btree_key *ckp;\r\nunion xfs_btree_ptr *cpp;\r\nunion xfs_btree_key *kp;\r\nunion xfs_btree_ptr *pp;\r\nunion xfs_btree_ptr nptr;\r\nint level;\r\nint error;\r\n#ifdef DEBUG\r\nint i;\r\n#endif\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_STATS_INC(cur, newroot);\r\nASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\r\nlevel = cur->bc_nlevels - 1;\r\nblock = xfs_btree_get_iroot(cur);\r\npp = xfs_btree_ptr_addr(cur, 1, block);\r\nerror = cur->bc_ops->alloc_block(cur, pp, &nptr, stat);\r\nif (error)\r\ngoto error0;\r\nif (*stat == 0) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn 0;\r\n}\r\nXFS_BTREE_STATS_INC(cur, alloc);\r\nerror = xfs_btree_get_buf_block(cur, &nptr, 0, &cblock, &cbp);\r\nif (error)\r\ngoto error0;\r\nmemcpy(cblock, block, xfs_btree_block_len(cur));\r\nif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS) {\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\ncblock->bb_u.l.bb_blkno = cpu_to_be64(cbp->b_bn);\r\nelse\r\ncblock->bb_u.s.bb_blkno = cpu_to_be64(cbp->b_bn);\r\n}\r\nbe16_add_cpu(&block->bb_level, 1);\r\nxfs_btree_set_numrecs(block, 1);\r\ncur->bc_nlevels++;\r\ncur->bc_ptrs[level + 1] = 1;\r\nkp = xfs_btree_key_addr(cur, 1, block);\r\nckp = xfs_btree_key_addr(cur, 1, cblock);\r\nxfs_btree_copy_keys(cur, ckp, kp, xfs_btree_get_numrecs(cblock));\r\ncpp = xfs_btree_ptr_addr(cur, 1, cblock);\r\n#ifdef DEBUG\r\nfor (i = 0; i < be16_to_cpu(cblock->bb_numrecs); i++) {\r\nerror = xfs_btree_check_ptr(cur, pp, i, level);\r\nif (error)\r\ngoto error0;\r\n}\r\n#endif\r\nxfs_btree_copy_ptrs(cur, cpp, pp, xfs_btree_get_numrecs(cblock));\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_ptr(cur, &nptr, 0, level);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_copy_ptrs(cur, pp, &nptr, 1);\r\nxfs_iroot_realloc(cur->bc_private.b.ip,\r\n1 - xfs_btree_get_numrecs(cblock),\r\ncur->bc_private.b.whichfork);\r\nxfs_btree_setbuf(cur, level, cbp);\r\nxfs_btree_log_block(cur, cbp, XFS_BB_ALL_BITS);\r\nxfs_btree_log_keys(cur, cbp, 1, be16_to_cpu(cblock->bb_numrecs));\r\nxfs_btree_log_ptrs(cur, cbp, 1, be16_to_cpu(cblock->bb_numrecs));\r\n*logflags |=\r\nXFS_ILOG_CORE | xfs_ilog_fbroot(cur->bc_private.b.whichfork);\r\n*stat = 1;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_btree_new_root(\r\nstruct xfs_btree_cur *cur,\r\nint *stat)\r\n{\r\nstruct xfs_btree_block *block;\r\nstruct xfs_buf *bp;\r\nint error;\r\nstruct xfs_buf *lbp;\r\nstruct xfs_btree_block *left;\r\nstruct xfs_buf *nbp;\r\nstruct xfs_btree_block *new;\r\nint nptr;\r\nstruct xfs_buf *rbp;\r\nstruct xfs_btree_block *right;\r\nunion xfs_btree_ptr rptr;\r\nunion xfs_btree_ptr lptr;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_STATS_INC(cur, newroot);\r\ncur->bc_ops->init_ptr_from_cur(cur, &rptr);\r\nerror = cur->bc_ops->alloc_block(cur, &rptr, &lptr, stat);\r\nif (error)\r\ngoto error0;\r\nif (*stat == 0)\r\ngoto out0;\r\nXFS_BTREE_STATS_INC(cur, alloc);\r\nerror = xfs_btree_get_buf_block(cur, &lptr, 0, &new, &nbp);\r\nif (error)\r\ngoto error0;\r\ncur->bc_ops->set_root(cur, &lptr, 1);\r\nblock = xfs_btree_get_block(cur, cur->bc_nlevels - 1, &bp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, cur->bc_nlevels - 1, bp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_get_sibling(cur, block, &rptr, XFS_BB_RIGHTSIB);\r\nif (!xfs_btree_ptr_is_null(cur, &rptr)) {\r\nlbp = bp;\r\nxfs_btree_buf_to_ptr(cur, lbp, &lptr);\r\nleft = block;\r\nerror = xfs_btree_read_buf_block(cur, &rptr, 0, &right, &rbp);\r\nif (error)\r\ngoto error0;\r\nbp = rbp;\r\nnptr = 1;\r\n} else {\r\nrbp = bp;\r\nxfs_btree_buf_to_ptr(cur, rbp, &rptr);\r\nright = block;\r\nxfs_btree_get_sibling(cur, right, &lptr, XFS_BB_LEFTSIB);\r\nerror = xfs_btree_read_buf_block(cur, &lptr, 0, &left, &lbp);\r\nif (error)\r\ngoto error0;\r\nbp = lbp;\r\nnptr = 2;\r\n}\r\nxfs_btree_init_block_cur(cur, nbp, cur->bc_nlevels, 2);\r\nxfs_btree_log_block(cur, nbp, XFS_BB_ALL_BITS);\r\nASSERT(!xfs_btree_ptr_is_null(cur, &lptr) &&\r\n!xfs_btree_ptr_is_null(cur, &rptr));\r\nif (xfs_btree_get_level(left) > 0) {\r\nxfs_btree_copy_keys(cur,\r\nxfs_btree_key_addr(cur, 1, new),\r\nxfs_btree_key_addr(cur, 1, left), 1);\r\nxfs_btree_copy_keys(cur,\r\nxfs_btree_key_addr(cur, 2, new),\r\nxfs_btree_key_addr(cur, 1, right), 1);\r\n} else {\r\ncur->bc_ops->init_key_from_rec(\r\nxfs_btree_key_addr(cur, 1, new),\r\nxfs_btree_rec_addr(cur, 1, left));\r\ncur->bc_ops->init_key_from_rec(\r\nxfs_btree_key_addr(cur, 2, new),\r\nxfs_btree_rec_addr(cur, 1, right));\r\n}\r\nxfs_btree_log_keys(cur, nbp, 1, 2);\r\nxfs_btree_copy_ptrs(cur,\r\nxfs_btree_ptr_addr(cur, 1, new), &lptr, 1);\r\nxfs_btree_copy_ptrs(cur,\r\nxfs_btree_ptr_addr(cur, 2, new), &rptr, 1);\r\nxfs_btree_log_ptrs(cur, nbp, 1, 2);\r\nxfs_btree_setbuf(cur, cur->bc_nlevels, nbp);\r\ncur->bc_ptrs[cur->bc_nlevels] = nptr;\r\ncur->bc_nlevels++;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\nout0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_make_block_unfull(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint numrecs,\r\nint *oindex,\r\nint *index,\r\nunion xfs_btree_ptr *nptr,\r\nstruct xfs_btree_cur **ncur,\r\nunion xfs_btree_rec *nrec,\r\nint *stat)\r\n{\r\nunion xfs_btree_key key;\r\nint error = 0;\r\nif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\r\nlevel == cur->bc_nlevels - 1) {\r\nstruct xfs_inode *ip = cur->bc_private.b.ip;\r\nif (numrecs < cur->bc_ops->get_dmaxrecs(cur, level)) {\r\nxfs_iroot_realloc(ip, 1, cur->bc_private.b.whichfork);\r\n} else {\r\nint logflags = 0;\r\nerror = xfs_btree_new_iroot(cur, &logflags, stat);\r\nif (error || *stat == 0)\r\nreturn error;\r\nxfs_trans_log_inode(cur->bc_tp, ip, logflags);\r\n}\r\nreturn 0;\r\n}\r\nerror = xfs_btree_rshift(cur, level, stat);\r\nif (error || *stat)\r\nreturn error;\r\nerror = xfs_btree_lshift(cur, level, stat);\r\nif (error)\r\nreturn error;\r\nif (*stat) {\r\n*oindex = *index = cur->bc_ptrs[level];\r\nreturn 0;\r\n}\r\nerror = xfs_btree_split(cur, level, nptr, &key, ncur, stat);\r\nif (error || *stat == 0)\r\nreturn error;\r\n*index = cur->bc_ptrs[level];\r\ncur->bc_ops->init_rec_from_key(&key, nrec);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_insrec(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nunion xfs_btree_ptr *ptrp,\r\nunion xfs_btree_rec *recp,\r\nstruct xfs_btree_cur **curp,\r\nint *stat)\r\n{\r\nstruct xfs_btree_block *block;\r\nstruct xfs_buf *bp;\r\nunion xfs_btree_key key;\r\nunion xfs_btree_ptr nptr;\r\nstruct xfs_btree_cur *ncur;\r\nunion xfs_btree_rec nrec;\r\nint optr;\r\nint ptr;\r\nint numrecs;\r\nint error;\r\n#ifdef DEBUG\r\nint i;\r\n#endif\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGIPR(cur, level, *ptrp, recp);\r\nncur = NULL;\r\nif (!(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\r\n(level >= cur->bc_nlevels)) {\r\nerror = xfs_btree_new_root(cur, stat);\r\nxfs_btree_set_ptr_null(cur, ptrp);\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn error;\r\n}\r\nptr = cur->bc_ptrs[level];\r\nif (ptr == 0) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\ncur->bc_ops->init_key_from_rec(&key, recp);\r\noptr = ptr;\r\nXFS_BTREE_STATS_INC(cur, insrec);\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\nnumrecs = xfs_btree_get_numrecs(block);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, level, bp);\r\nif (error)\r\ngoto error0;\r\nif (ptr <= numrecs) {\r\nif (level == 0) {\r\nASSERT(cur->bc_ops->recs_inorder(cur, recp,\r\nxfs_btree_rec_addr(cur, ptr, block)));\r\n} else {\r\nASSERT(cur->bc_ops->keys_inorder(cur, &key,\r\nxfs_btree_key_addr(cur, ptr, block)));\r\n}\r\n}\r\n#endif\r\nxfs_btree_set_ptr_null(cur, &nptr);\r\nif (numrecs == cur->bc_ops->get_maxrecs(cur, level)) {\r\nerror = xfs_btree_make_block_unfull(cur, level, numrecs,\r\n&optr, &ptr, &nptr, &ncur, &nrec, stat);\r\nif (error || *stat == 0)\r\ngoto error0;\r\n}\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\nnumrecs = xfs_btree_get_numrecs(block);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, level, bp);\r\nif (error)\r\nreturn error;\r\n#endif\r\nXFS_BTREE_STATS_ADD(cur, moves, numrecs - ptr + 1);\r\nif (level > 0) {\r\nunion xfs_btree_key *kp;\r\nunion xfs_btree_ptr *pp;\r\nkp = xfs_btree_key_addr(cur, ptr, block);\r\npp = xfs_btree_ptr_addr(cur, ptr, block);\r\n#ifdef DEBUG\r\nfor (i = numrecs - ptr; i >= 0; i--) {\r\nerror = xfs_btree_check_ptr(cur, pp, i, level);\r\nif (error)\r\nreturn error;\r\n}\r\n#endif\r\nxfs_btree_shift_keys(cur, kp, 1, numrecs - ptr + 1);\r\nxfs_btree_shift_ptrs(cur, pp, 1, numrecs - ptr + 1);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_ptr(cur, ptrp, 0, level);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_copy_keys(cur, kp, &key, 1);\r\nxfs_btree_copy_ptrs(cur, pp, ptrp, 1);\r\nnumrecs++;\r\nxfs_btree_set_numrecs(block, numrecs);\r\nxfs_btree_log_ptrs(cur, bp, ptr, numrecs);\r\nxfs_btree_log_keys(cur, bp, ptr, numrecs);\r\n#ifdef DEBUG\r\nif (ptr < numrecs) {\r\nASSERT(cur->bc_ops->keys_inorder(cur, kp,\r\nxfs_btree_key_addr(cur, ptr + 1, block)));\r\n}\r\n#endif\r\n} else {\r\nunion xfs_btree_rec *rp;\r\nrp = xfs_btree_rec_addr(cur, ptr, block);\r\nxfs_btree_shift_recs(cur, rp, 1, numrecs - ptr + 1);\r\nxfs_btree_copy_recs(cur, rp, recp, 1);\r\nxfs_btree_set_numrecs(block, ++numrecs);\r\nxfs_btree_log_recs(cur, bp, ptr, numrecs);\r\n#ifdef DEBUG\r\nif (ptr < numrecs) {\r\nASSERT(cur->bc_ops->recs_inorder(cur, rp,\r\nxfs_btree_rec_addr(cur, ptr + 1, block)));\r\n}\r\n#endif\r\n}\r\nxfs_btree_log_block(cur, bp, XFS_BB_NUMRECS);\r\nif (optr == 1) {\r\nerror = xfs_btree_updkey(cur, &key, level + 1);\r\nif (error)\r\ngoto error0;\r\n}\r\nif (xfs_btree_is_lastrec(cur, block, level)) {\r\ncur->bc_ops->update_lastrec(cur, block, recp,\r\nptr, LASTREC_INSREC);\r\n}\r\n*ptrp = nptr;\r\nif (!xfs_btree_ptr_is_null(cur, &nptr)) {\r\n*recp = nrec;\r\n*curp = ncur;\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nint\r\nxfs_btree_insert(\r\nstruct xfs_btree_cur *cur,\r\nint *stat)\r\n{\r\nint error;\r\nint i;\r\nint level;\r\nunion xfs_btree_ptr nptr;\r\nstruct xfs_btree_cur *ncur;\r\nstruct xfs_btree_cur *pcur;\r\nunion xfs_btree_rec rec;\r\nlevel = 0;\r\nncur = NULL;\r\npcur = cur;\r\nxfs_btree_set_ptr_null(cur, &nptr);\r\ncur->bc_ops->init_rec_from_cur(cur, &rec);\r\ndo {\r\nerror = xfs_btree_insrec(pcur, level, &nptr, &rec, &ncur, &i);\r\nif (error) {\r\nif (pcur != cur)\r\nxfs_btree_del_cursor(pcur, XFS_BTREE_ERROR);\r\ngoto error0;\r\n}\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\nlevel++;\r\nif (pcur != cur &&\r\n(ncur || xfs_btree_ptr_is_null(cur, &nptr))) {\r\nif (cur->bc_ops->update_cursor)\r\ncur->bc_ops->update_cursor(pcur, cur);\r\ncur->bc_nlevels = pcur->bc_nlevels;\r\nxfs_btree_del_cursor(pcur, XFS_BTREE_NOERROR);\r\n}\r\nif (ncur) {\r\npcur = ncur;\r\nncur = NULL;\r\n}\r\n} while (!xfs_btree_ptr_is_null(cur, &nptr));\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = i;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_btree_kill_iroot(\r\nstruct xfs_btree_cur *cur)\r\n{\r\nint whichfork = cur->bc_private.b.whichfork;\r\nstruct xfs_inode *ip = cur->bc_private.b.ip;\r\nstruct xfs_ifork *ifp = XFS_IFORK_PTR(ip, whichfork);\r\nstruct xfs_btree_block *block;\r\nstruct xfs_btree_block *cblock;\r\nunion xfs_btree_key *kp;\r\nunion xfs_btree_key *ckp;\r\nunion xfs_btree_ptr *pp;\r\nunion xfs_btree_ptr *cpp;\r\nstruct xfs_buf *cbp;\r\nint level;\r\nint index;\r\nint numrecs;\r\n#ifdef DEBUG\r\nunion xfs_btree_ptr ptr;\r\nint i;\r\n#endif\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\r\nASSERT(cur->bc_nlevels > 1);\r\nlevel = cur->bc_nlevels - 1;\r\nif (level == 1)\r\ngoto out0;\r\nblock = xfs_btree_get_iroot(cur);\r\nif (xfs_btree_get_numrecs(block) != 1)\r\ngoto out0;\r\ncblock = xfs_btree_get_block(cur, level - 1, &cbp);\r\nnumrecs = xfs_btree_get_numrecs(cblock);\r\nif (numrecs > cur->bc_ops->get_dmaxrecs(cur, level))\r\ngoto out0;\r\nXFS_BTREE_STATS_INC(cur, killroot);\r\n#ifdef DEBUG\r\nxfs_btree_get_sibling(cur, block, &ptr, XFS_BB_LEFTSIB);\r\nASSERT(xfs_btree_ptr_is_null(cur, &ptr));\r\nxfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\r\nASSERT(xfs_btree_ptr_is_null(cur, &ptr));\r\n#endif\r\nindex = numrecs - cur->bc_ops->get_maxrecs(cur, level);\r\nif (index) {\r\nxfs_iroot_realloc(cur->bc_private.b.ip, index,\r\ncur->bc_private.b.whichfork);\r\nblock = ifp->if_broot;\r\n}\r\nbe16_add_cpu(&block->bb_numrecs, index);\r\nASSERT(block->bb_numrecs == cblock->bb_numrecs);\r\nkp = xfs_btree_key_addr(cur, 1, block);\r\nckp = xfs_btree_key_addr(cur, 1, cblock);\r\nxfs_btree_copy_keys(cur, kp, ckp, numrecs);\r\npp = xfs_btree_ptr_addr(cur, 1, block);\r\ncpp = xfs_btree_ptr_addr(cur, 1, cblock);\r\n#ifdef DEBUG\r\nfor (i = 0; i < numrecs; i++) {\r\nint error;\r\nerror = xfs_btree_check_ptr(cur, cpp, i, level - 1);\r\nif (error) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\n}\r\n#endif\r\nxfs_btree_copy_ptrs(cur, pp, cpp, numrecs);\r\ncur->bc_ops->free_block(cur, cbp);\r\nXFS_BTREE_STATS_INC(cur, free);\r\ncur->bc_bufs[level - 1] = NULL;\r\nbe16_add_cpu(&block->bb_level, -1);\r\nxfs_trans_log_inode(cur->bc_tp, ip,\r\nXFS_ILOG_CORE | xfs_ilog_fbroot(cur->bc_private.b.whichfork));\r\ncur->bc_nlevels--;\r\nout0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_kill_root(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp,\r\nint level,\r\nunion xfs_btree_ptr *newroot)\r\n{\r\nint error;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_STATS_INC(cur, killroot);\r\ncur->bc_ops->set_root(cur, newroot, -1);\r\nerror = cur->bc_ops->free_block(cur, bp);\r\nif (error) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nXFS_BTREE_STATS_INC(cur, free);\r\ncur->bc_bufs[level] = NULL;\r\ncur->bc_ra[level] = 0;\r\ncur->bc_nlevels--;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_dec_cursor(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint *stat)\r\n{\r\nint error;\r\nint i;\r\nif (level > 0) {\r\nerror = xfs_btree_decrement(cur, level, &i);\r\nif (error)\r\nreturn error;\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_btree_delrec(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\nint *stat)\r\n{\r\nstruct xfs_btree_block *block;\r\nunion xfs_btree_ptr cptr;\r\nstruct xfs_buf *bp;\r\nint error;\r\nint i;\r\nunion xfs_btree_key key;\r\nunion xfs_btree_key *keyp = &key;\r\nunion xfs_btree_ptr lptr;\r\nstruct xfs_buf *lbp;\r\nstruct xfs_btree_block *left;\r\nint lrecs = 0;\r\nint ptr;\r\nunion xfs_btree_ptr rptr;\r\nstruct xfs_buf *rbp;\r\nstruct xfs_btree_block *right;\r\nstruct xfs_btree_block *rrblock;\r\nstruct xfs_buf *rrbp;\r\nint rrecs = 0;\r\nstruct xfs_btree_cur *tcur;\r\nint numrecs;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nXFS_BTREE_TRACE_ARGI(cur, level);\r\ntcur = NULL;\r\nptr = cur->bc_ptrs[level];\r\nif (ptr == 0) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\nnumrecs = xfs_btree_get_numrecs(block);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, level, bp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nif (ptr > numrecs) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\nXFS_BTREE_STATS_INC(cur, delrec);\r\nXFS_BTREE_STATS_ADD(cur, moves, numrecs - ptr);\r\nif (level > 0) {\r\nunion xfs_btree_key *lkp;\r\nunion xfs_btree_ptr *lpp;\r\nlkp = xfs_btree_key_addr(cur, ptr + 1, block);\r\nlpp = xfs_btree_ptr_addr(cur, ptr + 1, block);\r\n#ifdef DEBUG\r\nfor (i = 0; i < numrecs - ptr; i++) {\r\nerror = xfs_btree_check_ptr(cur, lpp, i, level);\r\nif (error)\r\ngoto error0;\r\n}\r\n#endif\r\nif (ptr < numrecs) {\r\nxfs_btree_shift_keys(cur, lkp, -1, numrecs - ptr);\r\nxfs_btree_shift_ptrs(cur, lpp, -1, numrecs - ptr);\r\nxfs_btree_log_keys(cur, bp, ptr, numrecs - 1);\r\nxfs_btree_log_ptrs(cur, bp, ptr, numrecs - 1);\r\n}\r\nif (ptr == 1)\r\nkeyp = xfs_btree_key_addr(cur, 1, block);\r\n} else {\r\nif (ptr < numrecs) {\r\nxfs_btree_shift_recs(cur,\r\nxfs_btree_rec_addr(cur, ptr + 1, block),\r\n-1, numrecs - ptr);\r\nxfs_btree_log_recs(cur, bp, ptr, numrecs - 1);\r\n}\r\nif (ptr == 1) {\r\ncur->bc_ops->init_key_from_rec(&key,\r\nxfs_btree_rec_addr(cur, 1, block));\r\nkeyp = &key;\r\n}\r\n}\r\nxfs_btree_set_numrecs(block, --numrecs);\r\nxfs_btree_log_block(cur, bp, XFS_BB_NUMRECS);\r\nif (xfs_btree_is_lastrec(cur, block, level)) {\r\ncur->bc_ops->update_lastrec(cur, block, NULL,\r\nptr, LASTREC_DELREC);\r\n}\r\nif (level == cur->bc_nlevels - 1) {\r\nif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) {\r\nxfs_iroot_realloc(cur->bc_private.b.ip, -1,\r\ncur->bc_private.b.whichfork);\r\nerror = xfs_btree_kill_iroot(cur);\r\nif (error)\r\ngoto error0;\r\nerror = xfs_btree_dec_cursor(cur, level, stat);\r\nif (error)\r\ngoto error0;\r\n*stat = 1;\r\nreturn 0;\r\n}\r\nif (numrecs == 1 && level > 0) {\r\nunion xfs_btree_ptr *pp;\r\npp = xfs_btree_ptr_addr(cur, 1, block);\r\nerror = xfs_btree_kill_root(cur, bp, level, pp);\r\nif (error)\r\ngoto error0;\r\n} else if (level > 0) {\r\nerror = xfs_btree_dec_cursor(cur, level, stat);\r\nif (error)\r\ngoto error0;\r\n}\r\n*stat = 1;\r\nreturn 0;\r\n}\r\nif (ptr == 1) {\r\nerror = xfs_btree_updkey(cur, keyp, level + 1);\r\nif (error)\r\ngoto error0;\r\n}\r\nif (numrecs >= cur->bc_ops->get_minrecs(cur, level)) {\r\nerror = xfs_btree_dec_cursor(cur, level, stat);\r\nif (error)\r\ngoto error0;\r\nreturn 0;\r\n}\r\nxfs_btree_get_sibling(cur, block, &rptr, XFS_BB_RIGHTSIB);\r\nxfs_btree_get_sibling(cur, block, &lptr, XFS_BB_LEFTSIB);\r\nif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) {\r\nif (xfs_btree_ptr_is_null(cur, &rptr) &&\r\nxfs_btree_ptr_is_null(cur, &lptr) &&\r\nlevel == cur->bc_nlevels - 2) {\r\nerror = xfs_btree_kill_iroot(cur);\r\nif (!error)\r\nerror = xfs_btree_dec_cursor(cur, level, stat);\r\nif (error)\r\ngoto error0;\r\nreturn 0;\r\n}\r\n}\r\nASSERT(!xfs_btree_ptr_is_null(cur, &rptr) ||\r\n!xfs_btree_ptr_is_null(cur, &lptr));\r\nerror = xfs_btree_dup_cursor(cur, &tcur);\r\nif (error)\r\ngoto error0;\r\nif (!xfs_btree_ptr_is_null(cur, &rptr)) {\r\ni = xfs_btree_lastrec(tcur, level);\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\nerror = xfs_btree_increment(tcur, level, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\ni = xfs_btree_lastrec(tcur, level);\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\nright = xfs_btree_get_block(tcur, level, &rbp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(tcur, right, level, rbp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_get_sibling(tcur, right, &cptr, XFS_BB_LEFTSIB);\r\nif (xfs_btree_get_numrecs(right) - 1 >=\r\ncur->bc_ops->get_minrecs(tcur, level)) {\r\nerror = xfs_btree_lshift(tcur, level, &i);\r\nif (error)\r\ngoto error0;\r\nif (i) {\r\nASSERT(xfs_btree_get_numrecs(block) >=\r\ncur->bc_ops->get_minrecs(tcur, level));\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\r\ntcur = NULL;\r\nerror = xfs_btree_dec_cursor(cur, level, stat);\r\nif (error)\r\ngoto error0;\r\nreturn 0;\r\n}\r\n}\r\nrrecs = xfs_btree_get_numrecs(right);\r\nif (!xfs_btree_ptr_is_null(cur, &lptr)) {\r\ni = xfs_btree_firstrec(tcur, level);\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\nerror = xfs_btree_decrement(tcur, level, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\n}\r\n}\r\nif (!xfs_btree_ptr_is_null(cur, &lptr)) {\r\ni = xfs_btree_firstrec(tcur, level);\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\nerror = xfs_btree_decrement(tcur, level, &i);\r\nif (error)\r\ngoto error0;\r\ni = xfs_btree_firstrec(tcur, level);\r\nXFS_WANT_CORRUPTED_GOTO(cur->bc_mp, i == 1, error0);\r\nleft = xfs_btree_get_block(tcur, level, &lbp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, left, level, lbp);\r\nif (error)\r\ngoto error0;\r\n#endif\r\nxfs_btree_get_sibling(tcur, left, &cptr, XFS_BB_RIGHTSIB);\r\nif (xfs_btree_get_numrecs(left) - 1 >=\r\ncur->bc_ops->get_minrecs(tcur, level)) {\r\nerror = xfs_btree_rshift(tcur, level, &i);\r\nif (error)\r\ngoto error0;\r\nif (i) {\r\nASSERT(xfs_btree_get_numrecs(block) >=\r\ncur->bc_ops->get_minrecs(tcur, level));\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\r\ntcur = NULL;\r\nif (level == 0)\r\ncur->bc_ptrs[0]++;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\n}\r\n}\r\nlrecs = xfs_btree_get_numrecs(left);\r\n}\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\r\ntcur = NULL;\r\nASSERT(!xfs_btree_ptr_is_null(cur, &cptr));\r\nif (!xfs_btree_ptr_is_null(cur, &lptr) &&\r\nlrecs + xfs_btree_get_numrecs(block) <=\r\ncur->bc_ops->get_maxrecs(cur, level)) {\r\nrptr = cptr;\r\nright = block;\r\nrbp = bp;\r\nerror = xfs_btree_read_buf_block(cur, &lptr, 0, &left, &lbp);\r\nif (error)\r\ngoto error0;\r\n} else if (!xfs_btree_ptr_is_null(cur, &rptr) &&\r\nrrecs + xfs_btree_get_numrecs(block) <=\r\ncur->bc_ops->get_maxrecs(cur, level)) {\r\nlptr = cptr;\r\nleft = block;\r\nlbp = bp;\r\nerror = xfs_btree_read_buf_block(cur, &rptr, 0, &right, &rbp);\r\nif (error)\r\ngoto error0;\r\n} else {\r\nerror = xfs_btree_dec_cursor(cur, level, stat);\r\nif (error)\r\ngoto error0;\r\nreturn 0;\r\n}\r\nrrecs = xfs_btree_get_numrecs(right);\r\nlrecs = xfs_btree_get_numrecs(left);\r\nXFS_BTREE_STATS_ADD(cur, moves, rrecs);\r\nif (level > 0) {\r\nunion xfs_btree_key *lkp;\r\nunion xfs_btree_ptr *lpp;\r\nunion xfs_btree_key *rkp;\r\nunion xfs_btree_ptr *rpp;\r\nlkp = xfs_btree_key_addr(cur, lrecs + 1, left);\r\nlpp = xfs_btree_ptr_addr(cur, lrecs + 1, left);\r\nrkp = xfs_btree_key_addr(cur, 1, right);\r\nrpp = xfs_btree_ptr_addr(cur, 1, right);\r\n#ifdef DEBUG\r\nfor (i = 1; i < rrecs; i++) {\r\nerror = xfs_btree_check_ptr(cur, rpp, i, level);\r\nif (error)\r\ngoto error0;\r\n}\r\n#endif\r\nxfs_btree_copy_keys(cur, lkp, rkp, rrecs);\r\nxfs_btree_copy_ptrs(cur, lpp, rpp, rrecs);\r\nxfs_btree_log_keys(cur, lbp, lrecs + 1, lrecs + rrecs);\r\nxfs_btree_log_ptrs(cur, lbp, lrecs + 1, lrecs + rrecs);\r\n} else {\r\nunion xfs_btree_rec *lrp;\r\nunion xfs_btree_rec *rrp;\r\nlrp = xfs_btree_rec_addr(cur, lrecs + 1, left);\r\nrrp = xfs_btree_rec_addr(cur, 1, right);\r\nxfs_btree_copy_recs(cur, lrp, rrp, rrecs);\r\nxfs_btree_log_recs(cur, lbp, lrecs + 1, lrecs + rrecs);\r\n}\r\nXFS_BTREE_STATS_INC(cur, join);\r\nxfs_btree_set_numrecs(left, lrecs + rrecs);\r\nxfs_btree_get_sibling(cur, right, &cptr, XFS_BB_RIGHTSIB),\r\nxfs_btree_set_sibling(cur, left, &cptr, XFS_BB_RIGHTSIB);\r\nxfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS | XFS_BB_RIGHTSIB);\r\nxfs_btree_get_sibling(cur, left, &cptr, XFS_BB_RIGHTSIB);\r\nif (!xfs_btree_ptr_is_null(cur, &cptr)) {\r\nerror = xfs_btree_read_buf_block(cur, &cptr, 0, &rrblock, &rrbp);\r\nif (error)\r\ngoto error0;\r\nxfs_btree_set_sibling(cur, rrblock, &lptr, XFS_BB_LEFTSIB);\r\nxfs_btree_log_block(cur, rrbp, XFS_BB_LEFTSIB);\r\n}\r\nerror = cur->bc_ops->free_block(cur, rbp);\r\nif (error)\r\ngoto error0;\r\nXFS_BTREE_STATS_INC(cur, free);\r\nif (bp != lbp) {\r\ncur->bc_bufs[level] = lbp;\r\ncur->bc_ptrs[level] += lrecs;\r\ncur->bc_ra[level] = 0;\r\n}\r\nelse if ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) ||\r\n(level + 1 < cur->bc_nlevels)) {\r\nerror = xfs_btree_increment(cur, level + 1, &i);\r\nif (error)\r\ngoto error0;\r\n}\r\nif (level > 0)\r\ncur->bc_ptrs[level]--;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 2;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nif (tcur)\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nint\r\nxfs_btree_delete(\r\nstruct xfs_btree_cur *cur,\r\nint *stat)\r\n{\r\nint error;\r\nint level;\r\nint i;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nfor (level = 0, i = 2; i == 2; level++) {\r\nerror = xfs_btree_delrec(cur, level, &i);\r\nif (error)\r\ngoto error0;\r\n}\r\nif (i == 0) {\r\nfor (level = 1; level < cur->bc_nlevels; level++) {\r\nif (cur->bc_ptrs[level] == 0) {\r\nerror = xfs_btree_decrement(cur, level, &i);\r\nif (error)\r\ngoto error0;\r\nbreak;\r\n}\r\n}\r\n}\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = i;\r\nreturn 0;\r\nerror0:\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nint\r\nxfs_btree_get_rec(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec **recp,\r\nint *stat)\r\n{\r\nstruct xfs_btree_block *block;\r\nstruct xfs_buf *bp;\r\nint ptr;\r\n#ifdef DEBUG\r\nint error;\r\n#endif\r\nptr = cur->bc_ptrs[0];\r\nblock = xfs_btree_get_block(cur, 0, &bp);\r\n#ifdef DEBUG\r\nerror = xfs_btree_check_block(cur, block, 0, bp);\r\nif (error)\r\nreturn error;\r\n#endif\r\nif (ptr > xfs_btree_get_numrecs(block) || ptr <= 0) {\r\n*stat = 0;\r\nreturn 0;\r\n}\r\n*recp = xfs_btree_rec_addr(cur, ptr, block);\r\n*stat = 1;\r\nreturn 0;\r\n}\r\nstatic int\r\nxfs_btree_block_change_owner(\r\nstruct xfs_btree_cur *cur,\r\nint level,\r\n__uint64_t new_owner,\r\nstruct list_head *buffer_list)\r\n{\r\nstruct xfs_btree_block *block;\r\nstruct xfs_buf *bp;\r\nunion xfs_btree_ptr rptr;\r\nxfs_btree_readahead(cur, level, XFS_BTCUR_RIGHTRA);\r\nblock = xfs_btree_get_block(cur, level, &bp);\r\nif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\r\nblock->bb_u.l.bb_owner = cpu_to_be64(new_owner);\r\nelse\r\nblock->bb_u.s.bb_owner = cpu_to_be32(new_owner);\r\nif (bp) {\r\nif (cur->bc_tp) {\r\nxfs_trans_ordered_buf(cur->bc_tp, bp);\r\nxfs_btree_log_block(cur, bp, XFS_BB_OWNER);\r\n} else {\r\nxfs_buf_delwri_queue(bp, buffer_list);\r\n}\r\n} else {\r\nASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\r\nASSERT(level == cur->bc_nlevels - 1);\r\n}\r\nxfs_btree_get_sibling(cur, block, &rptr, XFS_BB_RIGHTSIB);\r\nif (xfs_btree_ptr_is_null(cur, &rptr))\r\nreturn -ENOENT;\r\nreturn xfs_btree_lookup_get_block(cur, level, &rptr, &block);\r\n}\r\nint\r\nxfs_btree_change_owner(\r\nstruct xfs_btree_cur *cur,\r\n__uint64_t new_owner,\r\nstruct list_head *buffer_list)\r\n{\r\nunion xfs_btree_ptr lptr;\r\nint level;\r\nstruct xfs_btree_block *block = NULL;\r\nint error = 0;\r\ncur->bc_ops->init_ptr_from_cur(cur, &lptr);\r\nfor (level = cur->bc_nlevels - 1; level >= 0; level--) {\r\nerror = xfs_btree_lookup_get_block(cur, level, &lptr, &block);\r\nif (error)\r\nreturn error;\r\nif (level > 0) {\r\nunion xfs_btree_ptr *ptr;\r\nptr = xfs_btree_ptr_addr(cur, 1, block);\r\nxfs_btree_readahead_ptr(cur, ptr, 1);\r\nlptr = *ptr;\r\n}\r\ndo {\r\nerror = xfs_btree_block_change_owner(cur, level,\r\nnew_owner,\r\nbuffer_list);\r\n} while (!error);\r\nif (error != -ENOENT)\r\nreturn error;\r\n}\r\nreturn 0;\r\n}
