static struct vring_desc *alloc_indirect(struct virtqueue *_vq,\r\nunsigned int total_sg, gfp_t gfp)\r\n{\r\nstruct vring_desc *desc;\r\nunsigned int i;\r\ngfp &= ~(__GFP_HIGHMEM | __GFP_HIGH);\r\ndesc = kmalloc(total_sg * sizeof(struct vring_desc), gfp);\r\nif (!desc)\r\nreturn NULL;\r\nfor (i = 0; i < total_sg; i++)\r\ndesc[i].next = cpu_to_virtio16(_vq->vdev, i + 1);\r\nreturn desc;\r\n}\r\nstatic inline int virtqueue_add(struct virtqueue *_vq,\r\nstruct scatterlist *sgs[],\r\nunsigned int total_sg,\r\nunsigned int out_sgs,\r\nunsigned int in_sgs,\r\nvoid *data,\r\ngfp_t gfp)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nstruct scatterlist *sg;\r\nstruct vring_desc *desc;\r\nunsigned int i, n, avail, descs_used, uninitialized_var(prev);\r\nint head;\r\nbool indirect;\r\nSTART_USE(vq);\r\nBUG_ON(data == NULL);\r\nif (unlikely(vq->broken)) {\r\nEND_USE(vq);\r\nreturn -EIO;\r\n}\r\n#ifdef DEBUG\r\n{\r\nktime_t now = ktime_get();\r\nif (vq->last_add_time_valid)\r\nWARN_ON(ktime_to_ms(ktime_sub(now, vq->last_add_time))\r\n> 100);\r\nvq->last_add_time = now;\r\nvq->last_add_time_valid = true;\r\n}\r\n#endif\r\nBUG_ON(total_sg > vq->vring.num);\r\nBUG_ON(total_sg == 0);\r\nhead = vq->free_head;\r\nif (vq->indirect && total_sg > 1 && vq->vq.num_free)\r\ndesc = alloc_indirect(_vq, total_sg, gfp);\r\nelse\r\ndesc = NULL;\r\nif (desc) {\r\nvq->vring.desc[head].flags = cpu_to_virtio16(_vq->vdev, VRING_DESC_F_INDIRECT);\r\nvq->vring.desc[head].addr = cpu_to_virtio64(_vq->vdev, virt_to_phys(desc));\r\nkmemleak_ignore(desc);\r\nvq->vring.desc[head].len = cpu_to_virtio32(_vq->vdev, total_sg * sizeof(struct vring_desc));\r\ni = 0;\r\ndescs_used = 1;\r\nindirect = true;\r\n} else {\r\ndesc = vq->vring.desc;\r\ni = head;\r\ndescs_used = total_sg;\r\nindirect = false;\r\n}\r\nif (vq->vq.num_free < descs_used) {\r\npr_debug("Can't add buf len %i - avail = %i\n",\r\ndescs_used, vq->vq.num_free);\r\nif (out_sgs)\r\nvq->notify(&vq->vq);\r\nEND_USE(vq);\r\nreturn -ENOSPC;\r\n}\r\nvq->vq.num_free -= descs_used;\r\nfor (n = 0; n < out_sgs; n++) {\r\nfor (sg = sgs[n]; sg; sg = sg_next(sg)) {\r\ndesc[i].flags = cpu_to_virtio16(_vq->vdev, VRING_DESC_F_NEXT);\r\ndesc[i].addr = cpu_to_virtio64(_vq->vdev, sg_phys(sg));\r\ndesc[i].len = cpu_to_virtio32(_vq->vdev, sg->length);\r\nprev = i;\r\ni = virtio16_to_cpu(_vq->vdev, desc[i].next);\r\n}\r\n}\r\nfor (; n < (out_sgs + in_sgs); n++) {\r\nfor (sg = sgs[n]; sg; sg = sg_next(sg)) {\r\ndesc[i].flags = cpu_to_virtio16(_vq->vdev, VRING_DESC_F_NEXT | VRING_DESC_F_WRITE);\r\ndesc[i].addr = cpu_to_virtio64(_vq->vdev, sg_phys(sg));\r\ndesc[i].len = cpu_to_virtio32(_vq->vdev, sg->length);\r\nprev = i;\r\ni = virtio16_to_cpu(_vq->vdev, desc[i].next);\r\n}\r\n}\r\ndesc[prev].flags &= cpu_to_virtio16(_vq->vdev, ~VRING_DESC_F_NEXT);\r\nif (indirect)\r\nvq->free_head = virtio16_to_cpu(_vq->vdev, vq->vring.desc[head].next);\r\nelse\r\nvq->free_head = i;\r\nvq->data[head] = data;\r\navail = virtio16_to_cpu(_vq->vdev, vq->vring.avail->idx) & (vq->vring.num - 1);\r\nvq->vring.avail->ring[avail] = cpu_to_virtio16(_vq->vdev, head);\r\nvirtio_wmb(vq->weak_barriers);\r\nvq->vring.avail->idx = cpu_to_virtio16(_vq->vdev, virtio16_to_cpu(_vq->vdev, vq->vring.avail->idx) + 1);\r\nvq->num_added++;\r\npr_debug("Added buffer head %i to %p\n", head, vq);\r\nEND_USE(vq);\r\nif (unlikely(vq->num_added == (1 << 16) - 1))\r\nvirtqueue_kick(_vq);\r\nreturn 0;\r\n}\r\nint virtqueue_add_sgs(struct virtqueue *_vq,\r\nstruct scatterlist *sgs[],\r\nunsigned int out_sgs,\r\nunsigned int in_sgs,\r\nvoid *data,\r\ngfp_t gfp)\r\n{\r\nunsigned int i, total_sg = 0;\r\nfor (i = 0; i < out_sgs + in_sgs; i++) {\r\nstruct scatterlist *sg;\r\nfor (sg = sgs[i]; sg; sg = sg_next(sg))\r\ntotal_sg++;\r\n}\r\nreturn virtqueue_add(_vq, sgs, total_sg, out_sgs, in_sgs, data, gfp);\r\n}\r\nint virtqueue_add_outbuf(struct virtqueue *vq,\r\nstruct scatterlist *sg, unsigned int num,\r\nvoid *data,\r\ngfp_t gfp)\r\n{\r\nreturn virtqueue_add(vq, &sg, num, 1, 0, data, gfp);\r\n}\r\nint virtqueue_add_inbuf(struct virtqueue *vq,\r\nstruct scatterlist *sg, unsigned int num,\r\nvoid *data,\r\ngfp_t gfp)\r\n{\r\nreturn virtqueue_add(vq, &sg, num, 0, 1, data, gfp);\r\n}\r\nbool virtqueue_kick_prepare(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nu16 new, old;\r\nbool needs_kick;\r\nSTART_USE(vq);\r\nvirtio_mb(vq->weak_barriers);\r\nold = virtio16_to_cpu(_vq->vdev, vq->vring.avail->idx) - vq->num_added;\r\nnew = virtio16_to_cpu(_vq->vdev, vq->vring.avail->idx);\r\nvq->num_added = 0;\r\n#ifdef DEBUG\r\nif (vq->last_add_time_valid) {\r\nWARN_ON(ktime_to_ms(ktime_sub(ktime_get(),\r\nvq->last_add_time)) > 100);\r\n}\r\nvq->last_add_time_valid = false;\r\n#endif\r\nif (vq->event) {\r\nneeds_kick = vring_need_event(virtio16_to_cpu(_vq->vdev, vring_avail_event(&vq->vring)),\r\nnew, old);\r\n} else {\r\nneeds_kick = !(vq->vring.used->flags & cpu_to_virtio16(_vq->vdev, VRING_USED_F_NO_NOTIFY));\r\n}\r\nEND_USE(vq);\r\nreturn needs_kick;\r\n}\r\nbool virtqueue_notify(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nif (unlikely(vq->broken))\r\nreturn false;\r\nif (!vq->notify(_vq)) {\r\nvq->broken = true;\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nbool virtqueue_kick(struct virtqueue *vq)\r\n{\r\nif (virtqueue_kick_prepare(vq))\r\nreturn virtqueue_notify(vq);\r\nreturn true;\r\n}\r\nstatic void detach_buf(struct vring_virtqueue *vq, unsigned int head)\r\n{\r\nunsigned int i;\r\nvq->data[head] = NULL;\r\ni = head;\r\nif (vq->vring.desc[i].flags & cpu_to_virtio16(vq->vq.vdev, VRING_DESC_F_INDIRECT))\r\nkfree(phys_to_virt(virtio64_to_cpu(vq->vq.vdev, vq->vring.desc[i].addr)));\r\nwhile (vq->vring.desc[i].flags & cpu_to_virtio16(vq->vq.vdev, VRING_DESC_F_NEXT)) {\r\ni = virtio16_to_cpu(vq->vq.vdev, vq->vring.desc[i].next);\r\nvq->vq.num_free++;\r\n}\r\nvq->vring.desc[i].next = cpu_to_virtio16(vq->vq.vdev, vq->free_head);\r\nvq->free_head = head;\r\nvq->vq.num_free++;\r\n}\r\nstatic inline bool more_used(const struct vring_virtqueue *vq)\r\n{\r\nreturn vq->last_used_idx != virtio16_to_cpu(vq->vq.vdev, vq->vring.used->idx);\r\n}\r\nvoid *virtqueue_get_buf(struct virtqueue *_vq, unsigned int *len)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nvoid *ret;\r\nunsigned int i;\r\nu16 last_used;\r\nSTART_USE(vq);\r\nif (unlikely(vq->broken)) {\r\nEND_USE(vq);\r\nreturn NULL;\r\n}\r\nif (!more_used(vq)) {\r\npr_debug("No more buffers in queue\n");\r\nEND_USE(vq);\r\nreturn NULL;\r\n}\r\nvirtio_rmb(vq->weak_barriers);\r\nlast_used = (vq->last_used_idx & (vq->vring.num - 1));\r\ni = virtio32_to_cpu(_vq->vdev, vq->vring.used->ring[last_used].id);\r\n*len = virtio32_to_cpu(_vq->vdev, vq->vring.used->ring[last_used].len);\r\nif (unlikely(i >= vq->vring.num)) {\r\nBAD_RING(vq, "id %u out of range\n", i);\r\nreturn NULL;\r\n}\r\nif (unlikely(!vq->data[i])) {\r\nBAD_RING(vq, "id %u is not a head!\n", i);\r\nreturn NULL;\r\n}\r\nret = vq->data[i];\r\ndetach_buf(vq, i);\r\nvq->last_used_idx++;\r\nif (!(vq->vring.avail->flags & cpu_to_virtio16(_vq->vdev, VRING_AVAIL_F_NO_INTERRUPT))) {\r\nvring_used_event(&vq->vring) = cpu_to_virtio16(_vq->vdev, vq->last_used_idx);\r\nvirtio_mb(vq->weak_barriers);\r\n}\r\n#ifdef DEBUG\r\nvq->last_add_time_valid = false;\r\n#endif\r\nEND_USE(vq);\r\nreturn ret;\r\n}\r\nvoid virtqueue_disable_cb(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nvq->vring.avail->flags |= cpu_to_virtio16(_vq->vdev, VRING_AVAIL_F_NO_INTERRUPT);\r\n}\r\nunsigned virtqueue_enable_cb_prepare(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nu16 last_used_idx;\r\nSTART_USE(vq);\r\nvq->vring.avail->flags &= cpu_to_virtio16(_vq->vdev, ~VRING_AVAIL_F_NO_INTERRUPT);\r\nvring_used_event(&vq->vring) = cpu_to_virtio16(_vq->vdev, last_used_idx = vq->last_used_idx);\r\nEND_USE(vq);\r\nreturn last_used_idx;\r\n}\r\nbool virtqueue_poll(struct virtqueue *_vq, unsigned last_used_idx)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nvirtio_mb(vq->weak_barriers);\r\nreturn (u16)last_used_idx != virtio16_to_cpu(_vq->vdev, vq->vring.used->idx);\r\n}\r\nbool virtqueue_enable_cb(struct virtqueue *_vq)\r\n{\r\nunsigned last_used_idx = virtqueue_enable_cb_prepare(_vq);\r\nreturn !virtqueue_poll(_vq, last_used_idx);\r\n}\r\nbool virtqueue_enable_cb_delayed(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nu16 bufs;\r\nSTART_USE(vq);\r\nvq->vring.avail->flags &= cpu_to_virtio16(_vq->vdev, ~VRING_AVAIL_F_NO_INTERRUPT);\r\nbufs = (u16)(virtio16_to_cpu(_vq->vdev, vq->vring.avail->idx) - vq->last_used_idx) * 3 / 4;\r\nvring_used_event(&vq->vring) = cpu_to_virtio16(_vq->vdev, vq->last_used_idx + bufs);\r\nvirtio_mb(vq->weak_barriers);\r\nif (unlikely((u16)(virtio16_to_cpu(_vq->vdev, vq->vring.used->idx) - vq->last_used_idx) > bufs)) {\r\nEND_USE(vq);\r\nreturn false;\r\n}\r\nEND_USE(vq);\r\nreturn true;\r\n}\r\nvoid *virtqueue_detach_unused_buf(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nunsigned int i;\r\nvoid *buf;\r\nSTART_USE(vq);\r\nfor (i = 0; i < vq->vring.num; i++) {\r\nif (!vq->data[i])\r\ncontinue;\r\nbuf = vq->data[i];\r\ndetach_buf(vq, i);\r\nvq->vring.avail->idx = cpu_to_virtio16(_vq->vdev, virtio16_to_cpu(_vq->vdev, vq->vring.avail->idx) - 1);\r\nEND_USE(vq);\r\nreturn buf;\r\n}\r\nBUG_ON(vq->vq.num_free != vq->vring.num);\r\nEND_USE(vq);\r\nreturn NULL;\r\n}\r\nirqreturn_t vring_interrupt(int irq, void *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nif (!more_used(vq)) {\r\npr_debug("virtqueue interrupt with no work for %p\n", vq);\r\nreturn IRQ_NONE;\r\n}\r\nif (unlikely(vq->broken))\r\nreturn IRQ_HANDLED;\r\npr_debug("virtqueue callback for %p (%p)\n", vq, vq->vq.callback);\r\nif (vq->vq.callback)\r\nvq->vq.callback(&vq->vq);\r\nreturn IRQ_HANDLED;\r\n}\r\nstruct virtqueue *vring_new_virtqueue(unsigned int index,\r\nunsigned int num,\r\nunsigned int vring_align,\r\nstruct virtio_device *vdev,\r\nbool weak_barriers,\r\nvoid *pages,\r\nbool (*notify)(struct virtqueue *),\r\nvoid (*callback)(struct virtqueue *),\r\nconst char *name)\r\n{\r\nstruct vring_virtqueue *vq;\r\nunsigned int i;\r\nif (num & (num - 1)) {\r\ndev_warn(&vdev->dev, "Bad virtqueue length %u\n", num);\r\nreturn NULL;\r\n}\r\nvq = kmalloc(sizeof(*vq) + sizeof(void *)*num, GFP_KERNEL);\r\nif (!vq)\r\nreturn NULL;\r\nvring_init(&vq->vring, num, pages, vring_align);\r\nvq->vq.callback = callback;\r\nvq->vq.vdev = vdev;\r\nvq->vq.name = name;\r\nvq->vq.num_free = num;\r\nvq->vq.index = index;\r\nvq->notify = notify;\r\nvq->weak_barriers = weak_barriers;\r\nvq->broken = false;\r\nvq->last_used_idx = 0;\r\nvq->num_added = 0;\r\nlist_add_tail(&vq->vq.list, &vdev->vqs);\r\n#ifdef DEBUG\r\nvq->in_use = false;\r\nvq->last_add_time_valid = false;\r\n#endif\r\nvq->indirect = virtio_has_feature(vdev, VIRTIO_RING_F_INDIRECT_DESC);\r\nvq->event = virtio_has_feature(vdev, VIRTIO_RING_F_EVENT_IDX);\r\nif (!callback)\r\nvq->vring.avail->flags |= cpu_to_virtio16(vdev, VRING_AVAIL_F_NO_INTERRUPT);\r\nvq->free_head = 0;\r\nfor (i = 0; i < num-1; i++) {\r\nvq->vring.desc[i].next = cpu_to_virtio16(vdev, i + 1);\r\nvq->data[i] = NULL;\r\n}\r\nvq->data[i] = NULL;\r\nreturn &vq->vq;\r\n}\r\nvoid vring_del_virtqueue(struct virtqueue *vq)\r\n{\r\nlist_del(&vq->list);\r\nkfree(to_vvq(vq));\r\n}\r\nvoid vring_transport_features(struct virtio_device *vdev)\r\n{\r\nunsigned int i;\r\nfor (i = VIRTIO_TRANSPORT_F_START; i < VIRTIO_TRANSPORT_F_END; i++) {\r\nswitch (i) {\r\ncase VIRTIO_RING_F_INDIRECT_DESC:\r\nbreak;\r\ncase VIRTIO_RING_F_EVENT_IDX:\r\nbreak;\r\ncase VIRTIO_F_VERSION_1:\r\nbreak;\r\ndefault:\r\n__virtio_clear_bit(vdev, i);\r\n}\r\n}\r\n}\r\nunsigned int virtqueue_get_vring_size(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nreturn vq->vring.num;\r\n}\r\nbool virtqueue_is_broken(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nreturn vq->broken;\r\n}\r\nvoid virtio_break_device(struct virtio_device *dev)\r\n{\r\nstruct virtqueue *_vq;\r\nlist_for_each_entry(_vq, &dev->vqs, list) {\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nvq->broken = true;\r\n}\r\n}\r\nvoid *virtqueue_get_avail(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nreturn vq->vring.avail;\r\n}\r\nvoid *virtqueue_get_used(struct virtqueue *_vq)\r\n{\r\nstruct vring_virtqueue *vq = to_vvq(_vq);\r\nreturn vq->vring.used;\r\n}
