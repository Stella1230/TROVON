static struct mr_table *ipmr_get_table(struct net *net, u32 id)\r\n{\r\nstruct mr_table *mrt;\r\nipmr_for_each_table(mrt, net) {\r\nif (mrt->id == id)\r\nreturn mrt;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int ipmr_fib_lookup(struct net *net, struct flowi4 *flp4,\r\nstruct mr_table **mrt)\r\n{\r\nint err;\r\nstruct ipmr_result res;\r\nstruct fib_lookup_arg arg = {\r\n.result = &res,\r\n.flags = FIB_LOOKUP_NOREF,\r\n};\r\nerr = fib_rules_lookup(net->ipv4.mr_rules_ops,\r\nflowi4_to_flowi(flp4), 0, &arg);\r\nif (err < 0)\r\nreturn err;\r\n*mrt = res.mrt;\r\nreturn 0;\r\n}\r\nstatic int ipmr_rule_action(struct fib_rule *rule, struct flowi *flp,\r\nint flags, struct fib_lookup_arg *arg)\r\n{\r\nstruct ipmr_result *res = arg->result;\r\nstruct mr_table *mrt;\r\nswitch (rule->action) {\r\ncase FR_ACT_TO_TBL:\r\nbreak;\r\ncase FR_ACT_UNREACHABLE:\r\nreturn -ENETUNREACH;\r\ncase FR_ACT_PROHIBIT:\r\nreturn -EACCES;\r\ncase FR_ACT_BLACKHOLE:\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nmrt = ipmr_get_table(rule->fr_net, rule->table);\r\nif (!mrt)\r\nreturn -EAGAIN;\r\nres->mrt = mrt;\r\nreturn 0;\r\n}\r\nstatic int ipmr_rule_match(struct fib_rule *rule, struct flowi *fl, int flags)\r\n{\r\nreturn 1;\r\n}\r\nstatic int ipmr_rule_configure(struct fib_rule *rule, struct sk_buff *skb,\r\nstruct fib_rule_hdr *frh, struct nlattr **tb)\r\n{\r\nreturn 0;\r\n}\r\nstatic int ipmr_rule_compare(struct fib_rule *rule, struct fib_rule_hdr *frh,\r\nstruct nlattr **tb)\r\n{\r\nreturn 1;\r\n}\r\nstatic int ipmr_rule_fill(struct fib_rule *rule, struct sk_buff *skb,\r\nstruct fib_rule_hdr *frh)\r\n{\r\nfrh->dst_len = 0;\r\nfrh->src_len = 0;\r\nfrh->tos = 0;\r\nreturn 0;\r\n}\r\nstatic int __net_init ipmr_rules_init(struct net *net)\r\n{\r\nstruct fib_rules_ops *ops;\r\nstruct mr_table *mrt;\r\nint err;\r\nops = fib_rules_register(&ipmr_rules_ops_template, net);\r\nif (IS_ERR(ops))\r\nreturn PTR_ERR(ops);\r\nINIT_LIST_HEAD(&net->ipv4.mr_tables);\r\nmrt = ipmr_new_table(net, RT_TABLE_DEFAULT);\r\nif (!mrt) {\r\nerr = -ENOMEM;\r\ngoto err1;\r\n}\r\nerr = fib_default_rule_add(ops, 0x7fff, RT_TABLE_DEFAULT, 0);\r\nif (err < 0)\r\ngoto err2;\r\nnet->ipv4.mr_rules_ops = ops;\r\nreturn 0;\r\nerr2:\r\nipmr_free_table(mrt);\r\nerr1:\r\nfib_rules_unregister(ops);\r\nreturn err;\r\n}\r\nstatic void __net_exit ipmr_rules_exit(struct net *net)\r\n{\r\nstruct mr_table *mrt, *next;\r\nrtnl_lock();\r\nlist_for_each_entry_safe(mrt, next, &net->ipv4.mr_tables, list) {\r\nlist_del(&mrt->list);\r\nipmr_free_table(mrt);\r\n}\r\nfib_rules_unregister(net->ipv4.mr_rules_ops);\r\nrtnl_unlock();\r\n}\r\nstatic struct mr_table *ipmr_get_table(struct net *net, u32 id)\r\n{\r\nreturn net->ipv4.mrt;\r\n}\r\nstatic int ipmr_fib_lookup(struct net *net, struct flowi4 *flp4,\r\nstruct mr_table **mrt)\r\n{\r\n*mrt = net->ipv4.mrt;\r\nreturn 0;\r\n}\r\nstatic int __net_init ipmr_rules_init(struct net *net)\r\n{\r\nnet->ipv4.mrt = ipmr_new_table(net, RT_TABLE_DEFAULT);\r\nreturn net->ipv4.mrt ? 0 : -ENOMEM;\r\n}\r\nstatic void __net_exit ipmr_rules_exit(struct net *net)\r\n{\r\nrtnl_lock();\r\nipmr_free_table(net->ipv4.mrt);\r\nnet->ipv4.mrt = NULL;\r\nrtnl_unlock();\r\n}\r\nstatic struct mr_table *ipmr_new_table(struct net *net, u32 id)\r\n{\r\nstruct mr_table *mrt;\r\nunsigned int i;\r\nmrt = ipmr_get_table(net, id);\r\nif (mrt)\r\nreturn mrt;\r\nmrt = kzalloc(sizeof(*mrt), GFP_KERNEL);\r\nif (!mrt)\r\nreturn NULL;\r\nwrite_pnet(&mrt->net, net);\r\nmrt->id = id;\r\nfor (i = 0; i < MFC_LINES; i++)\r\nINIT_LIST_HEAD(&mrt->mfc_cache_array[i]);\r\nINIT_LIST_HEAD(&mrt->mfc_unres_queue);\r\nsetup_timer(&mrt->ipmr_expire_timer, ipmr_expire_process,\r\n(unsigned long)mrt);\r\n#ifdef CONFIG_IP_PIMSM\r\nmrt->mroute_reg_vif_num = -1;\r\n#endif\r\n#ifdef CONFIG_IP_MROUTE_MULTIPLE_TABLES\r\nlist_add_tail_rcu(&mrt->list, &net->ipv4.mr_tables);\r\n#endif\r\nreturn mrt;\r\n}\r\nstatic void ipmr_free_table(struct mr_table *mrt)\r\n{\r\ndel_timer_sync(&mrt->ipmr_expire_timer);\r\nmroute_clean_tables(mrt);\r\nkfree(mrt);\r\n}\r\nstatic void ipmr_del_tunnel(struct net_device *dev, struct vifctl *v)\r\n{\r\nstruct net *net = dev_net(dev);\r\ndev_close(dev);\r\ndev = __dev_get_by_name(net, "tunl0");\r\nif (dev) {\r\nconst struct net_device_ops *ops = dev->netdev_ops;\r\nstruct ifreq ifr;\r\nstruct ip_tunnel_parm p;\r\nmemset(&p, 0, sizeof(p));\r\np.iph.daddr = v->vifc_rmt_addr.s_addr;\r\np.iph.saddr = v->vifc_lcl_addr.s_addr;\r\np.iph.version = 4;\r\np.iph.ihl = 5;\r\np.iph.protocol = IPPROTO_IPIP;\r\nsprintf(p.name, "dvmrp%d", v->vifc_vifi);\r\nifr.ifr_ifru.ifru_data = (__force void __user *)&p;\r\nif (ops->ndo_do_ioctl) {\r\nmm_segment_t oldfs = get_fs();\r\nset_fs(KERNEL_DS);\r\nops->ndo_do_ioctl(dev, &ifr, SIOCDELTUNNEL);\r\nset_fs(oldfs);\r\n}\r\n}\r\n}\r\nstatic\r\nstruct net_device *ipmr_new_tunnel(struct net *net, struct vifctl *v)\r\n{\r\nstruct net_device *dev;\r\ndev = __dev_get_by_name(net, "tunl0");\r\nif (dev) {\r\nconst struct net_device_ops *ops = dev->netdev_ops;\r\nint err;\r\nstruct ifreq ifr;\r\nstruct ip_tunnel_parm p;\r\nstruct in_device *in_dev;\r\nmemset(&p, 0, sizeof(p));\r\np.iph.daddr = v->vifc_rmt_addr.s_addr;\r\np.iph.saddr = v->vifc_lcl_addr.s_addr;\r\np.iph.version = 4;\r\np.iph.ihl = 5;\r\np.iph.protocol = IPPROTO_IPIP;\r\nsprintf(p.name, "dvmrp%d", v->vifc_vifi);\r\nifr.ifr_ifru.ifru_data = (__force void __user *)&p;\r\nif (ops->ndo_do_ioctl) {\r\nmm_segment_t oldfs = get_fs();\r\nset_fs(KERNEL_DS);\r\nerr = ops->ndo_do_ioctl(dev, &ifr, SIOCADDTUNNEL);\r\nset_fs(oldfs);\r\n} else {\r\nerr = -EOPNOTSUPP;\r\n}\r\ndev = NULL;\r\nif (err == 0 &&\r\n(dev = __dev_get_by_name(net, p.name)) != NULL) {\r\ndev->flags |= IFF_MULTICAST;\r\nin_dev = __in_dev_get_rtnl(dev);\r\nif (!in_dev)\r\ngoto failure;\r\nipv4_devconf_setall(in_dev);\r\nneigh_parms_data_state_setall(in_dev->arp_parms);\r\nIPV4_DEVCONF(in_dev->cnf, RP_FILTER) = 0;\r\nif (dev_open(dev))\r\ngoto failure;\r\ndev_hold(dev);\r\n}\r\n}\r\nreturn dev;\r\nfailure:\r\nrtnl_unlock();\r\nrtnl_lock();\r\nunregister_netdevice(dev);\r\nreturn NULL;\r\n}\r\nstatic netdev_tx_t reg_vif_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct net *net = dev_net(dev);\r\nstruct mr_table *mrt;\r\nstruct flowi4 fl4 = {\r\n.flowi4_oif = dev->ifindex,\r\n.flowi4_iif = skb->skb_iif ? : LOOPBACK_IFINDEX,\r\n.flowi4_mark = skb->mark,\r\n};\r\nint err;\r\nerr = ipmr_fib_lookup(net, &fl4, &mrt);\r\nif (err < 0) {\r\nkfree_skb(skb);\r\nreturn err;\r\n}\r\nread_lock(&mrt_lock);\r\ndev->stats.tx_bytes += skb->len;\r\ndev->stats.tx_packets++;\r\nipmr_cache_report(mrt, skb, mrt->mroute_reg_vif_num, IGMPMSG_WHOLEPKT);\r\nread_unlock(&mrt_lock);\r\nkfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int reg_vif_get_iflink(const struct net_device *dev)\r\n{\r\nreturn 0;\r\n}\r\nstatic void reg_vif_setup(struct net_device *dev)\r\n{\r\ndev->type = ARPHRD_PIMREG;\r\ndev->mtu = ETH_DATA_LEN - sizeof(struct iphdr) - 8;\r\ndev->flags = IFF_NOARP;\r\ndev->netdev_ops = &reg_vif_netdev_ops;\r\ndev->destructor = free_netdev;\r\ndev->features |= NETIF_F_NETNS_LOCAL;\r\n}\r\nstatic struct net_device *ipmr_reg_vif(struct net *net, struct mr_table *mrt)\r\n{\r\nstruct net_device *dev;\r\nstruct in_device *in_dev;\r\nchar name[IFNAMSIZ];\r\nif (mrt->id == RT_TABLE_DEFAULT)\r\nsprintf(name, "pimreg");\r\nelse\r\nsprintf(name, "pimreg%u", mrt->id);\r\ndev = alloc_netdev(0, name, NET_NAME_UNKNOWN, reg_vif_setup);\r\nif (!dev)\r\nreturn NULL;\r\ndev_net_set(dev, net);\r\nif (register_netdevice(dev)) {\r\nfree_netdev(dev);\r\nreturn NULL;\r\n}\r\nrcu_read_lock();\r\nin_dev = __in_dev_get_rcu(dev);\r\nif (!in_dev) {\r\nrcu_read_unlock();\r\ngoto failure;\r\n}\r\nipv4_devconf_setall(in_dev);\r\nneigh_parms_data_state_setall(in_dev->arp_parms);\r\nIPV4_DEVCONF(in_dev->cnf, RP_FILTER) = 0;\r\nrcu_read_unlock();\r\nif (dev_open(dev))\r\ngoto failure;\r\ndev_hold(dev);\r\nreturn dev;\r\nfailure:\r\nrtnl_unlock();\r\nrtnl_lock();\r\nunregister_netdevice(dev);\r\nreturn NULL;\r\n}\r\nstatic int vif_delete(struct mr_table *mrt, int vifi, int notify,\r\nstruct list_head *head)\r\n{\r\nstruct vif_device *v;\r\nstruct net_device *dev;\r\nstruct in_device *in_dev;\r\nif (vifi < 0 || vifi >= mrt->maxvif)\r\nreturn -EADDRNOTAVAIL;\r\nv = &mrt->vif_table[vifi];\r\nwrite_lock_bh(&mrt_lock);\r\ndev = v->dev;\r\nv->dev = NULL;\r\nif (!dev) {\r\nwrite_unlock_bh(&mrt_lock);\r\nreturn -EADDRNOTAVAIL;\r\n}\r\n#ifdef CONFIG_IP_PIMSM\r\nif (vifi == mrt->mroute_reg_vif_num)\r\nmrt->mroute_reg_vif_num = -1;\r\n#endif\r\nif (vifi + 1 == mrt->maxvif) {\r\nint tmp;\r\nfor (tmp = vifi - 1; tmp >= 0; tmp--) {\r\nif (VIF_EXISTS(mrt, tmp))\r\nbreak;\r\n}\r\nmrt->maxvif = tmp+1;\r\n}\r\nwrite_unlock_bh(&mrt_lock);\r\ndev_set_allmulti(dev, -1);\r\nin_dev = __in_dev_get_rtnl(dev);\r\nif (in_dev) {\r\nIPV4_DEVCONF(in_dev->cnf, MC_FORWARDING)--;\r\ninet_netconf_notify_devconf(dev_net(dev),\r\nNETCONFA_MC_FORWARDING,\r\ndev->ifindex, &in_dev->cnf);\r\nip_rt_multicast_event(in_dev);\r\n}\r\nif (v->flags & (VIFF_TUNNEL | VIFF_REGISTER) && !notify)\r\nunregister_netdevice_queue(dev, head);\r\ndev_put(dev);\r\nreturn 0;\r\n}\r\nstatic void ipmr_cache_free_rcu(struct rcu_head *head)\r\n{\r\nstruct mfc_cache *c = container_of(head, struct mfc_cache, rcu);\r\nkmem_cache_free(mrt_cachep, c);\r\n}\r\nstatic inline void ipmr_cache_free(struct mfc_cache *c)\r\n{\r\ncall_rcu(&c->rcu, ipmr_cache_free_rcu);\r\n}\r\nstatic void ipmr_destroy_unres(struct mr_table *mrt, struct mfc_cache *c)\r\n{\r\nstruct net *net = read_pnet(&mrt->net);\r\nstruct sk_buff *skb;\r\nstruct nlmsgerr *e;\r\natomic_dec(&mrt->cache_resolve_queue_len);\r\nwhile ((skb = skb_dequeue(&c->mfc_un.unres.unresolved))) {\r\nif (ip_hdr(skb)->version == 0) {\r\nstruct nlmsghdr *nlh = (struct nlmsghdr *)skb_pull(skb, sizeof(struct iphdr));\r\nnlh->nlmsg_type = NLMSG_ERROR;\r\nnlh->nlmsg_len = nlmsg_msg_size(sizeof(struct nlmsgerr));\r\nskb_trim(skb, nlh->nlmsg_len);\r\ne = nlmsg_data(nlh);\r\ne->error = -ETIMEDOUT;\r\nmemset(&e->msg, 0, sizeof(e->msg));\r\nrtnl_unicast(skb, net, NETLINK_CB(skb).portid);\r\n} else {\r\nkfree_skb(skb);\r\n}\r\n}\r\nipmr_cache_free(c);\r\n}\r\nstatic void ipmr_expire_process(unsigned long arg)\r\n{\r\nstruct mr_table *mrt = (struct mr_table *)arg;\r\nunsigned long now;\r\nunsigned long expires;\r\nstruct mfc_cache *c, *next;\r\nif (!spin_trylock(&mfc_unres_lock)) {\r\nmod_timer(&mrt->ipmr_expire_timer, jiffies+HZ/10);\r\nreturn;\r\n}\r\nif (list_empty(&mrt->mfc_unres_queue))\r\ngoto out;\r\nnow = jiffies;\r\nexpires = 10*HZ;\r\nlist_for_each_entry_safe(c, next, &mrt->mfc_unres_queue, list) {\r\nif (time_after(c->mfc_un.unres.expires, now)) {\r\nunsigned long interval = c->mfc_un.unres.expires - now;\r\nif (interval < expires)\r\nexpires = interval;\r\ncontinue;\r\n}\r\nlist_del(&c->list);\r\nmroute_netlink_event(mrt, c, RTM_DELROUTE);\r\nipmr_destroy_unres(mrt, c);\r\n}\r\nif (!list_empty(&mrt->mfc_unres_queue))\r\nmod_timer(&mrt->ipmr_expire_timer, jiffies + expires);\r\nout:\r\nspin_unlock(&mfc_unres_lock);\r\n}\r\nstatic void ipmr_update_thresholds(struct mr_table *mrt, struct mfc_cache *cache,\r\nunsigned char *ttls)\r\n{\r\nint vifi;\r\ncache->mfc_un.res.minvif = MAXVIFS;\r\ncache->mfc_un.res.maxvif = 0;\r\nmemset(cache->mfc_un.res.ttls, 255, MAXVIFS);\r\nfor (vifi = 0; vifi < mrt->maxvif; vifi++) {\r\nif (VIF_EXISTS(mrt, vifi) &&\r\nttls[vifi] && ttls[vifi] < 255) {\r\ncache->mfc_un.res.ttls[vifi] = ttls[vifi];\r\nif (cache->mfc_un.res.minvif > vifi)\r\ncache->mfc_un.res.minvif = vifi;\r\nif (cache->mfc_un.res.maxvif <= vifi)\r\ncache->mfc_un.res.maxvif = vifi + 1;\r\n}\r\n}\r\n}\r\nstatic int vif_add(struct net *net, struct mr_table *mrt,\r\nstruct vifctl *vifc, int mrtsock)\r\n{\r\nint vifi = vifc->vifc_vifi;\r\nstruct vif_device *v = &mrt->vif_table[vifi];\r\nstruct net_device *dev;\r\nstruct in_device *in_dev;\r\nint err;\r\nif (VIF_EXISTS(mrt, vifi))\r\nreturn -EADDRINUSE;\r\nswitch (vifc->vifc_flags) {\r\n#ifdef CONFIG_IP_PIMSM\r\ncase VIFF_REGISTER:\r\nif (mrt->mroute_reg_vif_num >= 0)\r\nreturn -EADDRINUSE;\r\ndev = ipmr_reg_vif(net, mrt);\r\nif (!dev)\r\nreturn -ENOBUFS;\r\nerr = dev_set_allmulti(dev, 1);\r\nif (err) {\r\nunregister_netdevice(dev);\r\ndev_put(dev);\r\nreturn err;\r\n}\r\nbreak;\r\n#endif\r\ncase VIFF_TUNNEL:\r\ndev = ipmr_new_tunnel(net, vifc);\r\nif (!dev)\r\nreturn -ENOBUFS;\r\nerr = dev_set_allmulti(dev, 1);\r\nif (err) {\r\nipmr_del_tunnel(dev, vifc);\r\ndev_put(dev);\r\nreturn err;\r\n}\r\nbreak;\r\ncase VIFF_USE_IFINDEX:\r\ncase 0:\r\nif (vifc->vifc_flags == VIFF_USE_IFINDEX) {\r\ndev = dev_get_by_index(net, vifc->vifc_lcl_ifindex);\r\nif (dev && !__in_dev_get_rtnl(dev)) {\r\ndev_put(dev);\r\nreturn -EADDRNOTAVAIL;\r\n}\r\n} else {\r\ndev = ip_dev_find(net, vifc->vifc_lcl_addr.s_addr);\r\n}\r\nif (!dev)\r\nreturn -EADDRNOTAVAIL;\r\nerr = dev_set_allmulti(dev, 1);\r\nif (err) {\r\ndev_put(dev);\r\nreturn err;\r\n}\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nin_dev = __in_dev_get_rtnl(dev);\r\nif (!in_dev) {\r\ndev_put(dev);\r\nreturn -EADDRNOTAVAIL;\r\n}\r\nIPV4_DEVCONF(in_dev->cnf, MC_FORWARDING)++;\r\ninet_netconf_notify_devconf(net, NETCONFA_MC_FORWARDING, dev->ifindex,\r\n&in_dev->cnf);\r\nip_rt_multicast_event(in_dev);\r\nv->rate_limit = vifc->vifc_rate_limit;\r\nv->local = vifc->vifc_lcl_addr.s_addr;\r\nv->remote = vifc->vifc_rmt_addr.s_addr;\r\nv->flags = vifc->vifc_flags;\r\nif (!mrtsock)\r\nv->flags |= VIFF_STATIC;\r\nv->threshold = vifc->vifc_threshold;\r\nv->bytes_in = 0;\r\nv->bytes_out = 0;\r\nv->pkt_in = 0;\r\nv->pkt_out = 0;\r\nv->link = dev->ifindex;\r\nif (v->flags & (VIFF_TUNNEL | VIFF_REGISTER))\r\nv->link = dev_get_iflink(dev);\r\nwrite_lock_bh(&mrt_lock);\r\nv->dev = dev;\r\n#ifdef CONFIG_IP_PIMSM\r\nif (v->flags & VIFF_REGISTER)\r\nmrt->mroute_reg_vif_num = vifi;\r\n#endif\r\nif (vifi+1 > mrt->maxvif)\r\nmrt->maxvif = vifi+1;\r\nwrite_unlock_bh(&mrt_lock);\r\nreturn 0;\r\n}\r\nstatic struct mfc_cache *ipmr_cache_find(struct mr_table *mrt,\r\n__be32 origin,\r\n__be32 mcastgrp)\r\n{\r\nint line = MFC_HASH(mcastgrp, origin);\r\nstruct mfc_cache *c;\r\nlist_for_each_entry_rcu(c, &mrt->mfc_cache_array[line], list) {\r\nif (c->mfc_origin == origin && c->mfc_mcastgrp == mcastgrp)\r\nreturn c;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct mfc_cache *ipmr_cache_find_any_parent(struct mr_table *mrt,\r\nint vifi)\r\n{\r\nint line = MFC_HASH(htonl(INADDR_ANY), htonl(INADDR_ANY));\r\nstruct mfc_cache *c;\r\nlist_for_each_entry_rcu(c, &mrt->mfc_cache_array[line], list)\r\nif (c->mfc_origin == htonl(INADDR_ANY) &&\r\nc->mfc_mcastgrp == htonl(INADDR_ANY) &&\r\nc->mfc_un.res.ttls[vifi] < 255)\r\nreturn c;\r\nreturn NULL;\r\n}\r\nstatic struct mfc_cache *ipmr_cache_find_any(struct mr_table *mrt,\r\n__be32 mcastgrp, int vifi)\r\n{\r\nint line = MFC_HASH(mcastgrp, htonl(INADDR_ANY));\r\nstruct mfc_cache *c, *proxy;\r\nif (mcastgrp == htonl(INADDR_ANY))\r\ngoto skip;\r\nlist_for_each_entry_rcu(c, &mrt->mfc_cache_array[line], list)\r\nif (c->mfc_origin == htonl(INADDR_ANY) &&\r\nc->mfc_mcastgrp == mcastgrp) {\r\nif (c->mfc_un.res.ttls[vifi] < 255)\r\nreturn c;\r\nproxy = ipmr_cache_find_any_parent(mrt,\r\nc->mfc_parent);\r\nif (proxy && proxy->mfc_un.res.ttls[vifi] < 255)\r\nreturn c;\r\n}\r\nskip:\r\nreturn ipmr_cache_find_any_parent(mrt, vifi);\r\n}\r\nstatic struct mfc_cache *ipmr_cache_alloc(void)\r\n{\r\nstruct mfc_cache *c = kmem_cache_zalloc(mrt_cachep, GFP_KERNEL);\r\nif (c)\r\nc->mfc_un.res.minvif = MAXVIFS;\r\nreturn c;\r\n}\r\nstatic struct mfc_cache *ipmr_cache_alloc_unres(void)\r\n{\r\nstruct mfc_cache *c = kmem_cache_zalloc(mrt_cachep, GFP_ATOMIC);\r\nif (c) {\r\nskb_queue_head_init(&c->mfc_un.unres.unresolved);\r\nc->mfc_un.unres.expires = jiffies + 10*HZ;\r\n}\r\nreturn c;\r\n}\r\nstatic void ipmr_cache_resolve(struct net *net, struct mr_table *mrt,\r\nstruct mfc_cache *uc, struct mfc_cache *c)\r\n{\r\nstruct sk_buff *skb;\r\nstruct nlmsgerr *e;\r\nwhile ((skb = __skb_dequeue(&uc->mfc_un.unres.unresolved))) {\r\nif (ip_hdr(skb)->version == 0) {\r\nstruct nlmsghdr *nlh = (struct nlmsghdr *)skb_pull(skb, sizeof(struct iphdr));\r\nif (__ipmr_fill_mroute(mrt, skb, c, nlmsg_data(nlh)) > 0) {\r\nnlh->nlmsg_len = skb_tail_pointer(skb) -\r\n(u8 *)nlh;\r\n} else {\r\nnlh->nlmsg_type = NLMSG_ERROR;\r\nnlh->nlmsg_len = nlmsg_msg_size(sizeof(struct nlmsgerr));\r\nskb_trim(skb, nlh->nlmsg_len);\r\ne = nlmsg_data(nlh);\r\ne->error = -EMSGSIZE;\r\nmemset(&e->msg, 0, sizeof(e->msg));\r\n}\r\nrtnl_unicast(skb, net, NETLINK_CB(skb).portid);\r\n} else {\r\nip_mr_forward(net, mrt, skb, c, 0);\r\n}\r\n}\r\n}\r\nstatic int ipmr_cache_report(struct mr_table *mrt,\r\nstruct sk_buff *pkt, vifi_t vifi, int assert)\r\n{\r\nstruct sk_buff *skb;\r\nconst int ihl = ip_hdrlen(pkt);\r\nstruct igmphdr *igmp;\r\nstruct igmpmsg *msg;\r\nstruct sock *mroute_sk;\r\nint ret;\r\n#ifdef CONFIG_IP_PIMSM\r\nif (assert == IGMPMSG_WHOLEPKT)\r\nskb = skb_realloc_headroom(pkt, sizeof(struct iphdr));\r\nelse\r\n#endif\r\nskb = alloc_skb(128, GFP_ATOMIC);\r\nif (!skb)\r\nreturn -ENOBUFS;\r\n#ifdef CONFIG_IP_PIMSM\r\nif (assert == IGMPMSG_WHOLEPKT) {\r\nskb_push(skb, sizeof(struct iphdr));\r\nskb_reset_network_header(skb);\r\nskb_reset_transport_header(skb);\r\nmsg = (struct igmpmsg *)skb_network_header(skb);\r\nmemcpy(msg, skb_network_header(pkt), sizeof(struct iphdr));\r\nmsg->im_msgtype = IGMPMSG_WHOLEPKT;\r\nmsg->im_mbz = 0;\r\nmsg->im_vif = mrt->mroute_reg_vif_num;\r\nip_hdr(skb)->ihl = sizeof(struct iphdr) >> 2;\r\nip_hdr(skb)->tot_len = htons(ntohs(ip_hdr(pkt)->tot_len) +\r\nsizeof(struct iphdr));\r\n} else\r\n#endif\r\n{\r\nskb_set_network_header(skb, skb->len);\r\nskb_put(skb, ihl);\r\nskb_copy_to_linear_data(skb, pkt->data, ihl);\r\nip_hdr(skb)->protocol = 0;\r\nmsg = (struct igmpmsg *)skb_network_header(skb);\r\nmsg->im_vif = vifi;\r\nskb_dst_set(skb, dst_clone(skb_dst(pkt)));\r\nigmp = (struct igmphdr *)skb_put(skb, sizeof(struct igmphdr));\r\nigmp->type =\r\nmsg->im_msgtype = assert;\r\nigmp->code = 0;\r\nip_hdr(skb)->tot_len = htons(skb->len);\r\nskb->transport_header = skb->network_header;\r\n}\r\nrcu_read_lock();\r\nmroute_sk = rcu_dereference(mrt->mroute_sk);\r\nif (!mroute_sk) {\r\nrcu_read_unlock();\r\nkfree_skb(skb);\r\nreturn -EINVAL;\r\n}\r\nret = sock_queue_rcv_skb(mroute_sk, skb);\r\nrcu_read_unlock();\r\nif (ret < 0) {\r\nnet_warn_ratelimited("mroute: pending queue full, dropping entries\n");\r\nkfree_skb(skb);\r\n}\r\nreturn ret;\r\n}\r\nstatic int\r\nipmr_cache_unresolved(struct mr_table *mrt, vifi_t vifi, struct sk_buff *skb)\r\n{\r\nbool found = false;\r\nint err;\r\nstruct mfc_cache *c;\r\nconst struct iphdr *iph = ip_hdr(skb);\r\nspin_lock_bh(&mfc_unres_lock);\r\nlist_for_each_entry(c, &mrt->mfc_unres_queue, list) {\r\nif (c->mfc_mcastgrp == iph->daddr &&\r\nc->mfc_origin == iph->saddr) {\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nif (atomic_read(&mrt->cache_resolve_queue_len) >= 10 ||\r\n(c = ipmr_cache_alloc_unres()) == NULL) {\r\nspin_unlock_bh(&mfc_unres_lock);\r\nkfree_skb(skb);\r\nreturn -ENOBUFS;\r\n}\r\nc->mfc_parent = -1;\r\nc->mfc_origin = iph->saddr;\r\nc->mfc_mcastgrp = iph->daddr;\r\nerr = ipmr_cache_report(mrt, skb, vifi, IGMPMSG_NOCACHE);\r\nif (err < 0) {\r\nspin_unlock_bh(&mfc_unres_lock);\r\nipmr_cache_free(c);\r\nkfree_skb(skb);\r\nreturn err;\r\n}\r\natomic_inc(&mrt->cache_resolve_queue_len);\r\nlist_add(&c->list, &mrt->mfc_unres_queue);\r\nmroute_netlink_event(mrt, c, RTM_NEWROUTE);\r\nif (atomic_read(&mrt->cache_resolve_queue_len) == 1)\r\nmod_timer(&mrt->ipmr_expire_timer, c->mfc_un.unres.expires);\r\n}\r\nif (c->mfc_un.unres.unresolved.qlen > 3) {\r\nkfree_skb(skb);\r\nerr = -ENOBUFS;\r\n} else {\r\nskb_queue_tail(&c->mfc_un.unres.unresolved, skb);\r\nerr = 0;\r\n}\r\nspin_unlock_bh(&mfc_unres_lock);\r\nreturn err;\r\n}\r\nstatic int ipmr_mfc_delete(struct mr_table *mrt, struct mfcctl *mfc, int parent)\r\n{\r\nint line;\r\nstruct mfc_cache *c, *next;\r\nline = MFC_HASH(mfc->mfcc_mcastgrp.s_addr, mfc->mfcc_origin.s_addr);\r\nlist_for_each_entry_safe(c, next, &mrt->mfc_cache_array[line], list) {\r\nif (c->mfc_origin == mfc->mfcc_origin.s_addr &&\r\nc->mfc_mcastgrp == mfc->mfcc_mcastgrp.s_addr &&\r\n(parent == -1 || parent == c->mfc_parent)) {\r\nlist_del_rcu(&c->list);\r\nmroute_netlink_event(mrt, c, RTM_DELROUTE);\r\nipmr_cache_free(c);\r\nreturn 0;\r\n}\r\n}\r\nreturn -ENOENT;\r\n}\r\nstatic int ipmr_mfc_add(struct net *net, struct mr_table *mrt,\r\nstruct mfcctl *mfc, int mrtsock, int parent)\r\n{\r\nbool found = false;\r\nint line;\r\nstruct mfc_cache *uc, *c;\r\nif (mfc->mfcc_parent >= MAXVIFS)\r\nreturn -ENFILE;\r\nline = MFC_HASH(mfc->mfcc_mcastgrp.s_addr, mfc->mfcc_origin.s_addr);\r\nlist_for_each_entry(c, &mrt->mfc_cache_array[line], list) {\r\nif (c->mfc_origin == mfc->mfcc_origin.s_addr &&\r\nc->mfc_mcastgrp == mfc->mfcc_mcastgrp.s_addr &&\r\n(parent == -1 || parent == c->mfc_parent)) {\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (found) {\r\nwrite_lock_bh(&mrt_lock);\r\nc->mfc_parent = mfc->mfcc_parent;\r\nipmr_update_thresholds(mrt, c, mfc->mfcc_ttls);\r\nif (!mrtsock)\r\nc->mfc_flags |= MFC_STATIC;\r\nwrite_unlock_bh(&mrt_lock);\r\nmroute_netlink_event(mrt, c, RTM_NEWROUTE);\r\nreturn 0;\r\n}\r\nif (mfc->mfcc_mcastgrp.s_addr != htonl(INADDR_ANY) &&\r\n!ipv4_is_multicast(mfc->mfcc_mcastgrp.s_addr))\r\nreturn -EINVAL;\r\nc = ipmr_cache_alloc();\r\nif (!c)\r\nreturn -ENOMEM;\r\nc->mfc_origin = mfc->mfcc_origin.s_addr;\r\nc->mfc_mcastgrp = mfc->mfcc_mcastgrp.s_addr;\r\nc->mfc_parent = mfc->mfcc_parent;\r\nipmr_update_thresholds(mrt, c, mfc->mfcc_ttls);\r\nif (!mrtsock)\r\nc->mfc_flags |= MFC_STATIC;\r\nlist_add_rcu(&c->list, &mrt->mfc_cache_array[line]);\r\nfound = false;\r\nspin_lock_bh(&mfc_unres_lock);\r\nlist_for_each_entry(uc, &mrt->mfc_unres_queue, list) {\r\nif (uc->mfc_origin == c->mfc_origin &&\r\nuc->mfc_mcastgrp == c->mfc_mcastgrp) {\r\nlist_del(&uc->list);\r\natomic_dec(&mrt->cache_resolve_queue_len);\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (list_empty(&mrt->mfc_unres_queue))\r\ndel_timer(&mrt->ipmr_expire_timer);\r\nspin_unlock_bh(&mfc_unres_lock);\r\nif (found) {\r\nipmr_cache_resolve(net, mrt, uc, c);\r\nipmr_cache_free(uc);\r\n}\r\nmroute_netlink_event(mrt, c, RTM_NEWROUTE);\r\nreturn 0;\r\n}\r\nstatic void mroute_clean_tables(struct mr_table *mrt)\r\n{\r\nint i;\r\nLIST_HEAD(list);\r\nstruct mfc_cache *c, *next;\r\nfor (i = 0; i < mrt->maxvif; i++) {\r\nif (!(mrt->vif_table[i].flags & VIFF_STATIC))\r\nvif_delete(mrt, i, 0, &list);\r\n}\r\nunregister_netdevice_many(&list);\r\nfor (i = 0; i < MFC_LINES; i++) {\r\nlist_for_each_entry_safe(c, next, &mrt->mfc_cache_array[i], list) {\r\nif (c->mfc_flags & MFC_STATIC)\r\ncontinue;\r\nlist_del_rcu(&c->list);\r\nmroute_netlink_event(mrt, c, RTM_DELROUTE);\r\nipmr_cache_free(c);\r\n}\r\n}\r\nif (atomic_read(&mrt->cache_resolve_queue_len) != 0) {\r\nspin_lock_bh(&mfc_unres_lock);\r\nlist_for_each_entry_safe(c, next, &mrt->mfc_unres_queue, list) {\r\nlist_del(&c->list);\r\nmroute_netlink_event(mrt, c, RTM_DELROUTE);\r\nipmr_destroy_unres(mrt, c);\r\n}\r\nspin_unlock_bh(&mfc_unres_lock);\r\n}\r\n}\r\nstatic void mrtsock_destruct(struct sock *sk)\r\n{\r\nstruct net *net = sock_net(sk);\r\nstruct mr_table *mrt;\r\nrtnl_lock();\r\nipmr_for_each_table(mrt, net) {\r\nif (sk == rtnl_dereference(mrt->mroute_sk)) {\r\nIPV4_DEVCONF_ALL(net, MC_FORWARDING)--;\r\ninet_netconf_notify_devconf(net, NETCONFA_MC_FORWARDING,\r\nNETCONFA_IFINDEX_ALL,\r\nnet->ipv4.devconf_all);\r\nRCU_INIT_POINTER(mrt->mroute_sk, NULL);\r\nmroute_clean_tables(mrt);\r\n}\r\n}\r\nrtnl_unlock();\r\n}\r\nint ip_mroute_setsockopt(struct sock *sk, int optname, char __user *optval, unsigned int optlen)\r\n{\r\nint ret, parent = 0;\r\nstruct vifctl vif;\r\nstruct mfcctl mfc;\r\nstruct net *net = sock_net(sk);\r\nstruct mr_table *mrt;\r\nif (sk->sk_type != SOCK_RAW ||\r\ninet_sk(sk)->inet_num != IPPROTO_IGMP)\r\nreturn -EOPNOTSUPP;\r\nmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\r\nif (!mrt)\r\nreturn -ENOENT;\r\nif (optname != MRT_INIT) {\r\nif (sk != rcu_access_pointer(mrt->mroute_sk) &&\r\n!ns_capable(net->user_ns, CAP_NET_ADMIN))\r\nreturn -EACCES;\r\n}\r\nswitch (optname) {\r\ncase MRT_INIT:\r\nif (optlen != sizeof(int))\r\nreturn -EINVAL;\r\nrtnl_lock();\r\nif (rtnl_dereference(mrt->mroute_sk)) {\r\nrtnl_unlock();\r\nreturn -EADDRINUSE;\r\n}\r\nret = ip_ra_control(sk, 1, mrtsock_destruct);\r\nif (ret == 0) {\r\nrcu_assign_pointer(mrt->mroute_sk, sk);\r\nIPV4_DEVCONF_ALL(net, MC_FORWARDING)++;\r\ninet_netconf_notify_devconf(net, NETCONFA_MC_FORWARDING,\r\nNETCONFA_IFINDEX_ALL,\r\nnet->ipv4.devconf_all);\r\n}\r\nrtnl_unlock();\r\nreturn ret;\r\ncase MRT_DONE:\r\nif (sk != rcu_access_pointer(mrt->mroute_sk))\r\nreturn -EACCES;\r\nreturn ip_ra_control(sk, 0, NULL);\r\ncase MRT_ADD_VIF:\r\ncase MRT_DEL_VIF:\r\nif (optlen != sizeof(vif))\r\nreturn -EINVAL;\r\nif (copy_from_user(&vif, optval, sizeof(vif)))\r\nreturn -EFAULT;\r\nif (vif.vifc_vifi >= MAXVIFS)\r\nreturn -ENFILE;\r\nrtnl_lock();\r\nif (optname == MRT_ADD_VIF) {\r\nret = vif_add(net, mrt, &vif,\r\nsk == rtnl_dereference(mrt->mroute_sk));\r\n} else {\r\nret = vif_delete(mrt, vif.vifc_vifi, 0, NULL);\r\n}\r\nrtnl_unlock();\r\nreturn ret;\r\ncase MRT_ADD_MFC:\r\ncase MRT_DEL_MFC:\r\nparent = -1;\r\ncase MRT_ADD_MFC_PROXY:\r\ncase MRT_DEL_MFC_PROXY:\r\nif (optlen != sizeof(mfc))\r\nreturn -EINVAL;\r\nif (copy_from_user(&mfc, optval, sizeof(mfc)))\r\nreturn -EFAULT;\r\nif (parent == 0)\r\nparent = mfc.mfcc_parent;\r\nrtnl_lock();\r\nif (optname == MRT_DEL_MFC || optname == MRT_DEL_MFC_PROXY)\r\nret = ipmr_mfc_delete(mrt, &mfc, parent);\r\nelse\r\nret = ipmr_mfc_add(net, mrt, &mfc,\r\nsk == rtnl_dereference(mrt->mroute_sk),\r\nparent);\r\nrtnl_unlock();\r\nreturn ret;\r\ncase MRT_ASSERT:\r\n{\r\nint v;\r\nif (optlen != sizeof(v))\r\nreturn -EINVAL;\r\nif (get_user(v, (int __user *)optval))\r\nreturn -EFAULT;\r\nmrt->mroute_do_assert = v;\r\nreturn 0;\r\n}\r\n#ifdef CONFIG_IP_PIMSM\r\ncase MRT_PIM:\r\n{\r\nint v;\r\nif (optlen != sizeof(v))\r\nreturn -EINVAL;\r\nif (get_user(v, (int __user *)optval))\r\nreturn -EFAULT;\r\nv = !!v;\r\nrtnl_lock();\r\nret = 0;\r\nif (v != mrt->mroute_do_pim) {\r\nmrt->mroute_do_pim = v;\r\nmrt->mroute_do_assert = v;\r\n}\r\nrtnl_unlock();\r\nreturn ret;\r\n}\r\n#endif\r\n#ifdef CONFIG_IP_MROUTE_MULTIPLE_TABLES\r\ncase MRT_TABLE:\r\n{\r\nu32 v;\r\nif (optlen != sizeof(u32))\r\nreturn -EINVAL;\r\nif (get_user(v, (u32 __user *)optval))\r\nreturn -EFAULT;\r\nif (v != RT_TABLE_DEFAULT && v >= 1000000000)\r\nreturn -EINVAL;\r\nrtnl_lock();\r\nret = 0;\r\nif (sk == rtnl_dereference(mrt->mroute_sk)) {\r\nret = -EBUSY;\r\n} else {\r\nif (!ipmr_new_table(net, v))\r\nret = -ENOMEM;\r\nelse\r\nraw_sk(sk)->ipmr_table = v;\r\n}\r\nrtnl_unlock();\r\nreturn ret;\r\n}\r\n#endif\r\ndefault:\r\nreturn -ENOPROTOOPT;\r\n}\r\n}\r\nint ip_mroute_getsockopt(struct sock *sk, int optname, char __user *optval, int __user *optlen)\r\n{\r\nint olr;\r\nint val;\r\nstruct net *net = sock_net(sk);\r\nstruct mr_table *mrt;\r\nif (sk->sk_type != SOCK_RAW ||\r\ninet_sk(sk)->inet_num != IPPROTO_IGMP)\r\nreturn -EOPNOTSUPP;\r\nmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\r\nif (!mrt)\r\nreturn -ENOENT;\r\nif (optname != MRT_VERSION &&\r\n#ifdef CONFIG_IP_PIMSM\r\noptname != MRT_PIM &&\r\n#endif\r\noptname != MRT_ASSERT)\r\nreturn -ENOPROTOOPT;\r\nif (get_user(olr, optlen))\r\nreturn -EFAULT;\r\nolr = min_t(unsigned int, olr, sizeof(int));\r\nif (olr < 0)\r\nreturn -EINVAL;\r\nif (put_user(olr, optlen))\r\nreturn -EFAULT;\r\nif (optname == MRT_VERSION)\r\nval = 0x0305;\r\n#ifdef CONFIG_IP_PIMSM\r\nelse if (optname == MRT_PIM)\r\nval = mrt->mroute_do_pim;\r\n#endif\r\nelse\r\nval = mrt->mroute_do_assert;\r\nif (copy_to_user(optval, &val, olr))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nint ipmr_ioctl(struct sock *sk, int cmd, void __user *arg)\r\n{\r\nstruct sioc_sg_req sr;\r\nstruct sioc_vif_req vr;\r\nstruct vif_device *vif;\r\nstruct mfc_cache *c;\r\nstruct net *net = sock_net(sk);\r\nstruct mr_table *mrt;\r\nmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\r\nif (!mrt)\r\nreturn -ENOENT;\r\nswitch (cmd) {\r\ncase SIOCGETVIFCNT:\r\nif (copy_from_user(&vr, arg, sizeof(vr)))\r\nreturn -EFAULT;\r\nif (vr.vifi >= mrt->maxvif)\r\nreturn -EINVAL;\r\nread_lock(&mrt_lock);\r\nvif = &mrt->vif_table[vr.vifi];\r\nif (VIF_EXISTS(mrt, vr.vifi)) {\r\nvr.icount = vif->pkt_in;\r\nvr.ocount = vif->pkt_out;\r\nvr.ibytes = vif->bytes_in;\r\nvr.obytes = vif->bytes_out;\r\nread_unlock(&mrt_lock);\r\nif (copy_to_user(arg, &vr, sizeof(vr)))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nread_unlock(&mrt_lock);\r\nreturn -EADDRNOTAVAIL;\r\ncase SIOCGETSGCNT:\r\nif (copy_from_user(&sr, arg, sizeof(sr)))\r\nreturn -EFAULT;\r\nrcu_read_lock();\r\nc = ipmr_cache_find(mrt, sr.src.s_addr, sr.grp.s_addr);\r\nif (c) {\r\nsr.pktcnt = c->mfc_un.res.pkt;\r\nsr.bytecnt = c->mfc_un.res.bytes;\r\nsr.wrong_if = c->mfc_un.res.wrong_if;\r\nrcu_read_unlock();\r\nif (copy_to_user(arg, &sr, sizeof(sr)))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nrcu_read_unlock();\r\nreturn -EADDRNOTAVAIL;\r\ndefault:\r\nreturn -ENOIOCTLCMD;\r\n}\r\n}\r\nint ipmr_compat_ioctl(struct sock *sk, unsigned int cmd, void __user *arg)\r\n{\r\nstruct compat_sioc_sg_req sr;\r\nstruct compat_sioc_vif_req vr;\r\nstruct vif_device *vif;\r\nstruct mfc_cache *c;\r\nstruct net *net = sock_net(sk);\r\nstruct mr_table *mrt;\r\nmrt = ipmr_get_table(net, raw_sk(sk)->ipmr_table ? : RT_TABLE_DEFAULT);\r\nif (!mrt)\r\nreturn -ENOENT;\r\nswitch (cmd) {\r\ncase SIOCGETVIFCNT:\r\nif (copy_from_user(&vr, arg, sizeof(vr)))\r\nreturn -EFAULT;\r\nif (vr.vifi >= mrt->maxvif)\r\nreturn -EINVAL;\r\nread_lock(&mrt_lock);\r\nvif = &mrt->vif_table[vr.vifi];\r\nif (VIF_EXISTS(mrt, vr.vifi)) {\r\nvr.icount = vif->pkt_in;\r\nvr.ocount = vif->pkt_out;\r\nvr.ibytes = vif->bytes_in;\r\nvr.obytes = vif->bytes_out;\r\nread_unlock(&mrt_lock);\r\nif (copy_to_user(arg, &vr, sizeof(vr)))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nread_unlock(&mrt_lock);\r\nreturn -EADDRNOTAVAIL;\r\ncase SIOCGETSGCNT:\r\nif (copy_from_user(&sr, arg, sizeof(sr)))\r\nreturn -EFAULT;\r\nrcu_read_lock();\r\nc = ipmr_cache_find(mrt, sr.src.s_addr, sr.grp.s_addr);\r\nif (c) {\r\nsr.pktcnt = c->mfc_un.res.pkt;\r\nsr.bytecnt = c->mfc_un.res.bytes;\r\nsr.wrong_if = c->mfc_un.res.wrong_if;\r\nrcu_read_unlock();\r\nif (copy_to_user(arg, &sr, sizeof(sr)))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nrcu_read_unlock();\r\nreturn -EADDRNOTAVAIL;\r\ndefault:\r\nreturn -ENOIOCTLCMD;\r\n}\r\n}\r\nstatic int ipmr_device_event(struct notifier_block *this, unsigned long event, void *ptr)\r\n{\r\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\r\nstruct net *net = dev_net(dev);\r\nstruct mr_table *mrt;\r\nstruct vif_device *v;\r\nint ct;\r\nif (event != NETDEV_UNREGISTER)\r\nreturn NOTIFY_DONE;\r\nipmr_for_each_table(mrt, net) {\r\nv = &mrt->vif_table[0];\r\nfor (ct = 0; ct < mrt->maxvif; ct++, v++) {\r\nif (v->dev == dev)\r\nvif_delete(mrt, ct, 1, NULL);\r\n}\r\n}\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic void ip_encap(struct net *net, struct sk_buff *skb,\r\n__be32 saddr, __be32 daddr)\r\n{\r\nstruct iphdr *iph;\r\nconst struct iphdr *old_iph = ip_hdr(skb);\r\nskb_push(skb, sizeof(struct iphdr));\r\nskb->transport_header = skb->network_header;\r\nskb_reset_network_header(skb);\r\niph = ip_hdr(skb);\r\niph->version = 4;\r\niph->tos = old_iph->tos;\r\niph->ttl = old_iph->ttl;\r\niph->frag_off = 0;\r\niph->daddr = daddr;\r\niph->saddr = saddr;\r\niph->protocol = IPPROTO_IPIP;\r\niph->ihl = 5;\r\niph->tot_len = htons(skb->len);\r\nip_select_ident(net, skb, NULL);\r\nip_send_check(iph);\r\nmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\r\nnf_reset(skb);\r\n}\r\nstatic inline int ipmr_forward_finish(struct sock *sk, struct sk_buff *skb)\r\n{\r\nstruct ip_options *opt = &(IPCB(skb)->opt);\r\nIP_INC_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTFORWDATAGRAMS);\r\nIP_ADD_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTOCTETS, skb->len);\r\nif (unlikely(opt->optlen))\r\nip_forward_options(skb);\r\nreturn dst_output_sk(sk, skb);\r\n}\r\nstatic void ipmr_queue_xmit(struct net *net, struct mr_table *mrt,\r\nstruct sk_buff *skb, struct mfc_cache *c, int vifi)\r\n{\r\nconst struct iphdr *iph = ip_hdr(skb);\r\nstruct vif_device *vif = &mrt->vif_table[vifi];\r\nstruct net_device *dev;\r\nstruct rtable *rt;\r\nstruct flowi4 fl4;\r\nint encap = 0;\r\nif (!vif->dev)\r\ngoto out_free;\r\n#ifdef CONFIG_IP_PIMSM\r\nif (vif->flags & VIFF_REGISTER) {\r\nvif->pkt_out++;\r\nvif->bytes_out += skb->len;\r\nvif->dev->stats.tx_bytes += skb->len;\r\nvif->dev->stats.tx_packets++;\r\nipmr_cache_report(mrt, skb, vifi, IGMPMSG_WHOLEPKT);\r\ngoto out_free;\r\n}\r\n#endif\r\nif (vif->flags & VIFF_TUNNEL) {\r\nrt = ip_route_output_ports(net, &fl4, NULL,\r\nvif->remote, vif->local,\r\n0, 0,\r\nIPPROTO_IPIP,\r\nRT_TOS(iph->tos), vif->link);\r\nif (IS_ERR(rt))\r\ngoto out_free;\r\nencap = sizeof(struct iphdr);\r\n} else {\r\nrt = ip_route_output_ports(net, &fl4, NULL, iph->daddr, 0,\r\n0, 0,\r\nIPPROTO_IPIP,\r\nRT_TOS(iph->tos), vif->link);\r\nif (IS_ERR(rt))\r\ngoto out_free;\r\n}\r\ndev = rt->dst.dev;\r\nif (skb->len+encap > dst_mtu(&rt->dst) && (ntohs(iph->frag_off) & IP_DF)) {\r\nIP_INC_STATS_BH(dev_net(dev), IPSTATS_MIB_FRAGFAILS);\r\nip_rt_put(rt);\r\ngoto out_free;\r\n}\r\nencap += LL_RESERVED_SPACE(dev) + rt->dst.header_len;\r\nif (skb_cow(skb, encap)) {\r\nip_rt_put(rt);\r\ngoto out_free;\r\n}\r\nvif->pkt_out++;\r\nvif->bytes_out += skb->len;\r\nskb_dst_drop(skb);\r\nskb_dst_set(skb, &rt->dst);\r\nip_decrease_ttl(ip_hdr(skb));\r\nif (vif->flags & VIFF_TUNNEL) {\r\nip_encap(net, skb, vif->local, vif->remote);\r\nvif->dev->stats.tx_packets++;\r\nvif->dev->stats.tx_bytes += skb->len;\r\n}\r\nIPCB(skb)->flags |= IPSKB_FORWARDED;\r\nNF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD, NULL, skb,\r\nskb->dev, dev,\r\nipmr_forward_finish);\r\nreturn;\r\nout_free:\r\nkfree_skb(skb);\r\n}\r\nstatic int ipmr_find_vif(struct mr_table *mrt, struct net_device *dev)\r\n{\r\nint ct;\r\nfor (ct = mrt->maxvif-1; ct >= 0; ct--) {\r\nif (mrt->vif_table[ct].dev == dev)\r\nbreak;\r\n}\r\nreturn ct;\r\n}\r\nstatic void ip_mr_forward(struct net *net, struct mr_table *mrt,\r\nstruct sk_buff *skb, struct mfc_cache *cache,\r\nint local)\r\n{\r\nint psend = -1;\r\nint vif, ct;\r\nint true_vifi = ipmr_find_vif(mrt, skb->dev);\r\nvif = cache->mfc_parent;\r\ncache->mfc_un.res.pkt++;\r\ncache->mfc_un.res.bytes += skb->len;\r\nif (cache->mfc_origin == htonl(INADDR_ANY) && true_vifi >= 0) {\r\nstruct mfc_cache *cache_proxy;\r\ncache_proxy = ipmr_cache_find_any_parent(mrt, vif);\r\nif (cache_proxy &&\r\ncache_proxy->mfc_un.res.ttls[true_vifi] < 255)\r\ngoto forward;\r\n}\r\nif (mrt->vif_table[vif].dev != skb->dev) {\r\nif (rt_is_output_route(skb_rtable(skb))) {\r\ngoto dont_forward;\r\n}\r\ncache->mfc_un.res.wrong_if++;\r\nif (true_vifi >= 0 && mrt->mroute_do_assert &&\r\n(mrt->mroute_do_pim ||\r\ncache->mfc_un.res.ttls[true_vifi] < 255) &&\r\ntime_after(jiffies,\r\ncache->mfc_un.res.last_assert + MFC_ASSERT_THRESH)) {\r\ncache->mfc_un.res.last_assert = jiffies;\r\nipmr_cache_report(mrt, skb, true_vifi, IGMPMSG_WRONGVIF);\r\n}\r\ngoto dont_forward;\r\n}\r\nforward:\r\nmrt->vif_table[vif].pkt_in++;\r\nmrt->vif_table[vif].bytes_in += skb->len;\r\nif (cache->mfc_origin == htonl(INADDR_ANY) &&\r\ncache->mfc_mcastgrp == htonl(INADDR_ANY)) {\r\nif (true_vifi >= 0 &&\r\ntrue_vifi != cache->mfc_parent &&\r\nip_hdr(skb)->ttl >\r\ncache->mfc_un.res.ttls[cache->mfc_parent]) {\r\npsend = cache->mfc_parent;\r\ngoto last_forward;\r\n}\r\ngoto dont_forward;\r\n}\r\nfor (ct = cache->mfc_un.res.maxvif - 1;\r\nct >= cache->mfc_un.res.minvif; ct--) {\r\nif ((cache->mfc_origin != htonl(INADDR_ANY) ||\r\nct != true_vifi) &&\r\nip_hdr(skb)->ttl > cache->mfc_un.res.ttls[ct]) {\r\nif (psend != -1) {\r\nstruct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);\r\nif (skb2)\r\nipmr_queue_xmit(net, mrt, skb2, cache,\r\npsend);\r\n}\r\npsend = ct;\r\n}\r\n}\r\nlast_forward:\r\nif (psend != -1) {\r\nif (local) {\r\nstruct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);\r\nif (skb2)\r\nipmr_queue_xmit(net, mrt, skb2, cache, psend);\r\n} else {\r\nipmr_queue_xmit(net, mrt, skb, cache, psend);\r\nreturn;\r\n}\r\n}\r\ndont_forward:\r\nif (!local)\r\nkfree_skb(skb);\r\n}\r\nstatic struct mr_table *ipmr_rt_fib_lookup(struct net *net, struct sk_buff *skb)\r\n{\r\nstruct rtable *rt = skb_rtable(skb);\r\nstruct iphdr *iph = ip_hdr(skb);\r\nstruct flowi4 fl4 = {\r\n.daddr = iph->daddr,\r\n.saddr = iph->saddr,\r\n.flowi4_tos = RT_TOS(iph->tos),\r\n.flowi4_oif = (rt_is_output_route(rt) ?\r\nskb->dev->ifindex : 0),\r\n.flowi4_iif = (rt_is_output_route(rt) ?\r\nLOOPBACK_IFINDEX :\r\nskb->dev->ifindex),\r\n.flowi4_mark = skb->mark,\r\n};\r\nstruct mr_table *mrt;\r\nint err;\r\nerr = ipmr_fib_lookup(net, &fl4, &mrt);\r\nif (err)\r\nreturn ERR_PTR(err);\r\nreturn mrt;\r\n}\r\nint ip_mr_input(struct sk_buff *skb)\r\n{\r\nstruct mfc_cache *cache;\r\nstruct net *net = dev_net(skb->dev);\r\nint local = skb_rtable(skb)->rt_flags & RTCF_LOCAL;\r\nstruct mr_table *mrt;\r\nif (IPCB(skb)->flags & IPSKB_FORWARDED)\r\ngoto dont_forward;\r\nmrt = ipmr_rt_fib_lookup(net, skb);\r\nif (IS_ERR(mrt)) {\r\nkfree_skb(skb);\r\nreturn PTR_ERR(mrt);\r\n}\r\nif (!local) {\r\nif (IPCB(skb)->opt.router_alert) {\r\nif (ip_call_ra_chain(skb))\r\nreturn 0;\r\n} else if (ip_hdr(skb)->protocol == IPPROTO_IGMP) {\r\nstruct sock *mroute_sk;\r\nmroute_sk = rcu_dereference(mrt->mroute_sk);\r\nif (mroute_sk) {\r\nnf_reset(skb);\r\nraw_rcv(mroute_sk, skb);\r\nreturn 0;\r\n}\r\n}\r\n}\r\ncache = ipmr_cache_find(mrt, ip_hdr(skb)->saddr, ip_hdr(skb)->daddr);\r\nif (!cache) {\r\nint vif = ipmr_find_vif(mrt, skb->dev);\r\nif (vif >= 0)\r\ncache = ipmr_cache_find_any(mrt, ip_hdr(skb)->daddr,\r\nvif);\r\n}\r\nif (!cache) {\r\nint vif;\r\nif (local) {\r\nstruct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);\r\nip_local_deliver(skb);\r\nif (!skb2)\r\nreturn -ENOBUFS;\r\nskb = skb2;\r\n}\r\nread_lock(&mrt_lock);\r\nvif = ipmr_find_vif(mrt, skb->dev);\r\nif (vif >= 0) {\r\nint err2 = ipmr_cache_unresolved(mrt, vif, skb);\r\nread_unlock(&mrt_lock);\r\nreturn err2;\r\n}\r\nread_unlock(&mrt_lock);\r\nkfree_skb(skb);\r\nreturn -ENODEV;\r\n}\r\nread_lock(&mrt_lock);\r\nip_mr_forward(net, mrt, skb, cache, local);\r\nread_unlock(&mrt_lock);\r\nif (local)\r\nreturn ip_local_deliver(skb);\r\nreturn 0;\r\ndont_forward:\r\nif (local)\r\nreturn ip_local_deliver(skb);\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nstatic int __pim_rcv(struct mr_table *mrt, struct sk_buff *skb,\r\nunsigned int pimlen)\r\n{\r\nstruct net_device *reg_dev = NULL;\r\nstruct iphdr *encap;\r\nencap = (struct iphdr *)(skb_transport_header(skb) + pimlen);\r\nif (!ipv4_is_multicast(encap->daddr) ||\r\nencap->tot_len == 0 ||\r\nntohs(encap->tot_len) + pimlen > skb->len)\r\nreturn 1;\r\nread_lock(&mrt_lock);\r\nif (mrt->mroute_reg_vif_num >= 0)\r\nreg_dev = mrt->vif_table[mrt->mroute_reg_vif_num].dev;\r\nread_unlock(&mrt_lock);\r\nif (!reg_dev)\r\nreturn 1;\r\nskb->mac_header = skb->network_header;\r\nskb_pull(skb, (u8 *)encap - skb->data);\r\nskb_reset_network_header(skb);\r\nskb->protocol = htons(ETH_P_IP);\r\nskb->ip_summed = CHECKSUM_NONE;\r\nskb_tunnel_rx(skb, reg_dev, dev_net(reg_dev));\r\nnetif_rx(skb);\r\nreturn NET_RX_SUCCESS;\r\n}\r\nint pim_rcv_v1(struct sk_buff *skb)\r\n{\r\nstruct igmphdr *pim;\r\nstruct net *net = dev_net(skb->dev);\r\nstruct mr_table *mrt;\r\nif (!pskb_may_pull(skb, sizeof(*pim) + sizeof(struct iphdr)))\r\ngoto drop;\r\npim = igmp_hdr(skb);\r\nmrt = ipmr_rt_fib_lookup(net, skb);\r\nif (IS_ERR(mrt))\r\ngoto drop;\r\nif (!mrt->mroute_do_pim ||\r\npim->group != PIM_V1_VERSION || pim->code != PIM_V1_REGISTER)\r\ngoto drop;\r\nif (__pim_rcv(mrt, skb, sizeof(*pim))) {\r\ndrop:\r\nkfree_skb(skb);\r\n}\r\nreturn 0;\r\n}\r\nstatic int pim_rcv(struct sk_buff *skb)\r\n{\r\nstruct pimreghdr *pim;\r\nstruct net *net = dev_net(skb->dev);\r\nstruct mr_table *mrt;\r\nif (!pskb_may_pull(skb, sizeof(*pim) + sizeof(struct iphdr)))\r\ngoto drop;\r\npim = (struct pimreghdr *)skb_transport_header(skb);\r\nif (pim->type != ((PIM_VERSION << 4) | (PIM_REGISTER)) ||\r\n(pim->flags & PIM_NULL_REGISTER) ||\r\n(ip_compute_csum((void *)pim, sizeof(*pim)) != 0 &&\r\ncsum_fold(skb_checksum(skb, 0, skb->len, 0))))\r\ngoto drop;\r\nmrt = ipmr_rt_fib_lookup(net, skb);\r\nif (IS_ERR(mrt))\r\ngoto drop;\r\nif (__pim_rcv(mrt, skb, sizeof(*pim))) {\r\ndrop:\r\nkfree_skb(skb);\r\n}\r\nreturn 0;\r\n}\r\nstatic int __ipmr_fill_mroute(struct mr_table *mrt, struct sk_buff *skb,\r\nstruct mfc_cache *c, struct rtmsg *rtm)\r\n{\r\nint ct;\r\nstruct rtnexthop *nhp;\r\nstruct nlattr *mp_attr;\r\nstruct rta_mfc_stats mfcs;\r\nif (c->mfc_parent >= MAXVIFS)\r\nreturn -ENOENT;\r\nif (VIF_EXISTS(mrt, c->mfc_parent) &&\r\nnla_put_u32(skb, RTA_IIF, mrt->vif_table[c->mfc_parent].dev->ifindex) < 0)\r\nreturn -EMSGSIZE;\r\nif (!(mp_attr = nla_nest_start(skb, RTA_MULTIPATH)))\r\nreturn -EMSGSIZE;\r\nfor (ct = c->mfc_un.res.minvif; ct < c->mfc_un.res.maxvif; ct++) {\r\nif (VIF_EXISTS(mrt, ct) && c->mfc_un.res.ttls[ct] < 255) {\r\nif (!(nhp = nla_reserve_nohdr(skb, sizeof(*nhp)))) {\r\nnla_nest_cancel(skb, mp_attr);\r\nreturn -EMSGSIZE;\r\n}\r\nnhp->rtnh_flags = 0;\r\nnhp->rtnh_hops = c->mfc_un.res.ttls[ct];\r\nnhp->rtnh_ifindex = mrt->vif_table[ct].dev->ifindex;\r\nnhp->rtnh_len = sizeof(*nhp);\r\n}\r\n}\r\nnla_nest_end(skb, mp_attr);\r\nmfcs.mfcs_packets = c->mfc_un.res.pkt;\r\nmfcs.mfcs_bytes = c->mfc_un.res.bytes;\r\nmfcs.mfcs_wrong_if = c->mfc_un.res.wrong_if;\r\nif (nla_put(skb, RTA_MFC_STATS, sizeof(mfcs), &mfcs) < 0)\r\nreturn -EMSGSIZE;\r\nrtm->rtm_type = RTN_MULTICAST;\r\nreturn 1;\r\n}\r\nint ipmr_get_route(struct net *net, struct sk_buff *skb,\r\n__be32 saddr, __be32 daddr,\r\nstruct rtmsg *rtm, int nowait)\r\n{\r\nstruct mfc_cache *cache;\r\nstruct mr_table *mrt;\r\nint err;\r\nmrt = ipmr_get_table(net, RT_TABLE_DEFAULT);\r\nif (!mrt)\r\nreturn -ENOENT;\r\nrcu_read_lock();\r\ncache = ipmr_cache_find(mrt, saddr, daddr);\r\nif (!cache && skb->dev) {\r\nint vif = ipmr_find_vif(mrt, skb->dev);\r\nif (vif >= 0)\r\ncache = ipmr_cache_find_any(mrt, daddr, vif);\r\n}\r\nif (!cache) {\r\nstruct sk_buff *skb2;\r\nstruct iphdr *iph;\r\nstruct net_device *dev;\r\nint vif = -1;\r\nif (nowait) {\r\nrcu_read_unlock();\r\nreturn -EAGAIN;\r\n}\r\ndev = skb->dev;\r\nread_lock(&mrt_lock);\r\nif (dev)\r\nvif = ipmr_find_vif(mrt, dev);\r\nif (vif < 0) {\r\nread_unlock(&mrt_lock);\r\nrcu_read_unlock();\r\nreturn -ENODEV;\r\n}\r\nskb2 = skb_clone(skb, GFP_ATOMIC);\r\nif (!skb2) {\r\nread_unlock(&mrt_lock);\r\nrcu_read_unlock();\r\nreturn -ENOMEM;\r\n}\r\nskb_push(skb2, sizeof(struct iphdr));\r\nskb_reset_network_header(skb2);\r\niph = ip_hdr(skb2);\r\niph->ihl = sizeof(struct iphdr) >> 2;\r\niph->saddr = saddr;\r\niph->daddr = daddr;\r\niph->version = 0;\r\nerr = ipmr_cache_unresolved(mrt, vif, skb2);\r\nread_unlock(&mrt_lock);\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nread_lock(&mrt_lock);\r\nif (!nowait && (rtm->rtm_flags & RTM_F_NOTIFY))\r\ncache->mfc_flags |= MFC_NOTIFY;\r\nerr = __ipmr_fill_mroute(mrt, skb, cache, rtm);\r\nread_unlock(&mrt_lock);\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nstatic int ipmr_fill_mroute(struct mr_table *mrt, struct sk_buff *skb,\r\nu32 portid, u32 seq, struct mfc_cache *c, int cmd,\r\nint flags)\r\n{\r\nstruct nlmsghdr *nlh;\r\nstruct rtmsg *rtm;\r\nint err;\r\nnlh = nlmsg_put(skb, portid, seq, cmd, sizeof(*rtm), flags);\r\nif (!nlh)\r\nreturn -EMSGSIZE;\r\nrtm = nlmsg_data(nlh);\r\nrtm->rtm_family = RTNL_FAMILY_IPMR;\r\nrtm->rtm_dst_len = 32;\r\nrtm->rtm_src_len = 32;\r\nrtm->rtm_tos = 0;\r\nrtm->rtm_table = mrt->id;\r\nif (nla_put_u32(skb, RTA_TABLE, mrt->id))\r\ngoto nla_put_failure;\r\nrtm->rtm_type = RTN_MULTICAST;\r\nrtm->rtm_scope = RT_SCOPE_UNIVERSE;\r\nif (c->mfc_flags & MFC_STATIC)\r\nrtm->rtm_protocol = RTPROT_STATIC;\r\nelse\r\nrtm->rtm_protocol = RTPROT_MROUTED;\r\nrtm->rtm_flags = 0;\r\nif (nla_put_in_addr(skb, RTA_SRC, c->mfc_origin) ||\r\nnla_put_in_addr(skb, RTA_DST, c->mfc_mcastgrp))\r\ngoto nla_put_failure;\r\nerr = __ipmr_fill_mroute(mrt, skb, c, rtm);\r\nif (err < 0 && err != -ENOENT)\r\ngoto nla_put_failure;\r\nnlmsg_end(skb, nlh);\r\nreturn 0;\r\nnla_put_failure:\r\nnlmsg_cancel(skb, nlh);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic size_t mroute_msgsize(bool unresolved, int maxvif)\r\n{\r\nsize_t len =\r\nNLMSG_ALIGN(sizeof(struct rtmsg))\r\n+ nla_total_size(4)\r\n+ nla_total_size(4)\r\n+ nla_total_size(4)\r\n;\r\nif (!unresolved)\r\nlen = len\r\n+ nla_total_size(4)\r\n+ nla_total_size(0)\r\n+ maxvif * NLA_ALIGN(sizeof(struct rtnexthop))\r\n+ nla_total_size(sizeof(struct rta_mfc_stats))\r\n;\r\nreturn len;\r\n}\r\nstatic void mroute_netlink_event(struct mr_table *mrt, struct mfc_cache *mfc,\r\nint cmd)\r\n{\r\nstruct net *net = read_pnet(&mrt->net);\r\nstruct sk_buff *skb;\r\nint err = -ENOBUFS;\r\nskb = nlmsg_new(mroute_msgsize(mfc->mfc_parent >= MAXVIFS, mrt->maxvif),\r\nGFP_ATOMIC);\r\nif (!skb)\r\ngoto errout;\r\nerr = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd, 0);\r\nif (err < 0)\r\ngoto errout;\r\nrtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE, NULL, GFP_ATOMIC);\r\nreturn;\r\nerrout:\r\nkfree_skb(skb);\r\nif (err < 0)\r\nrtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE, err);\r\n}\r\nstatic int ipmr_rtm_dumproute(struct sk_buff *skb, struct netlink_callback *cb)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nstruct mr_table *mrt;\r\nstruct mfc_cache *mfc;\r\nunsigned int t = 0, s_t;\r\nunsigned int h = 0, s_h;\r\nunsigned int e = 0, s_e;\r\ns_t = cb->args[0];\r\ns_h = cb->args[1];\r\ns_e = cb->args[2];\r\nrcu_read_lock();\r\nipmr_for_each_table(mrt, net) {\r\nif (t < s_t)\r\ngoto next_table;\r\nif (t > s_t)\r\ns_h = 0;\r\nfor (h = s_h; h < MFC_LINES; h++) {\r\nlist_for_each_entry_rcu(mfc, &mrt->mfc_cache_array[h], list) {\r\nif (e < s_e)\r\ngoto next_entry;\r\nif (ipmr_fill_mroute(mrt, skb,\r\nNETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq,\r\nmfc, RTM_NEWROUTE,\r\nNLM_F_MULTI) < 0)\r\ngoto done;\r\nnext_entry:\r\ne++;\r\n}\r\ne = s_e = 0;\r\n}\r\nspin_lock_bh(&mfc_unres_lock);\r\nlist_for_each_entry(mfc, &mrt->mfc_unres_queue, list) {\r\nif (e < s_e)\r\ngoto next_entry2;\r\nif (ipmr_fill_mroute(mrt, skb,\r\nNETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq,\r\nmfc, RTM_NEWROUTE,\r\nNLM_F_MULTI) < 0) {\r\nspin_unlock_bh(&mfc_unres_lock);\r\ngoto done;\r\n}\r\nnext_entry2:\r\ne++;\r\n}\r\nspin_unlock_bh(&mfc_unres_lock);\r\ne = s_e = 0;\r\ns_h = 0;\r\nnext_table:\r\nt++;\r\n}\r\ndone:\r\nrcu_read_unlock();\r\ncb->args[2] = e;\r\ncb->args[1] = h;\r\ncb->args[0] = t;\r\nreturn skb->len;\r\n}\r\nstatic struct vif_device *ipmr_vif_seq_idx(struct net *net,\r\nstruct ipmr_vif_iter *iter,\r\nloff_t pos)\r\n{\r\nstruct mr_table *mrt = iter->mrt;\r\nfor (iter->ct = 0; iter->ct < mrt->maxvif; ++iter->ct) {\r\nif (!VIF_EXISTS(mrt, iter->ct))\r\ncontinue;\r\nif (pos-- == 0)\r\nreturn &mrt->vif_table[iter->ct];\r\n}\r\nreturn NULL;\r\n}\r\nstatic void *ipmr_vif_seq_start(struct seq_file *seq, loff_t *pos)\r\n__acquires(mrt_lock)\r\n{\r\nstruct ipmr_vif_iter *iter = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct mr_table *mrt;\r\nmrt = ipmr_get_table(net, RT_TABLE_DEFAULT);\r\nif (!mrt)\r\nreturn ERR_PTR(-ENOENT);\r\niter->mrt = mrt;\r\nread_lock(&mrt_lock);\r\nreturn *pos ? ipmr_vif_seq_idx(net, seq->private, *pos - 1)\r\n: SEQ_START_TOKEN;\r\n}\r\nstatic void *ipmr_vif_seq_next(struct seq_file *seq, void *v, loff_t *pos)\r\n{\r\nstruct ipmr_vif_iter *iter = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct mr_table *mrt = iter->mrt;\r\n++*pos;\r\nif (v == SEQ_START_TOKEN)\r\nreturn ipmr_vif_seq_idx(net, iter, 0);\r\nwhile (++iter->ct < mrt->maxvif) {\r\nif (!VIF_EXISTS(mrt, iter->ct))\r\ncontinue;\r\nreturn &mrt->vif_table[iter->ct];\r\n}\r\nreturn NULL;\r\n}\r\nstatic void ipmr_vif_seq_stop(struct seq_file *seq, void *v)\r\n__releases(mrt_lock)\r\n{\r\nread_unlock(&mrt_lock);\r\n}\r\nstatic int ipmr_vif_seq_show(struct seq_file *seq, void *v)\r\n{\r\nstruct ipmr_vif_iter *iter = seq->private;\r\nstruct mr_table *mrt = iter->mrt;\r\nif (v == SEQ_START_TOKEN) {\r\nseq_puts(seq,\r\n"Interface BytesIn PktsIn BytesOut PktsOut Flags Local Remote\n");\r\n} else {\r\nconst struct vif_device *vif = v;\r\nconst char *name = vif->dev ? vif->dev->name : "none";\r\nseq_printf(seq,\r\n"%2Zd %-10s %8ld %7ld %8ld %7ld %05X %08X %08X\n",\r\nvif - mrt->vif_table,\r\nname, vif->bytes_in, vif->pkt_in,\r\nvif->bytes_out, vif->pkt_out,\r\nvif->flags, vif->local, vif->remote);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ipmr_vif_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open_net(inode, file, &ipmr_vif_seq_ops,\r\nsizeof(struct ipmr_vif_iter));\r\n}\r\nstatic struct mfc_cache *ipmr_mfc_seq_idx(struct net *net,\r\nstruct ipmr_mfc_iter *it, loff_t pos)\r\n{\r\nstruct mr_table *mrt = it->mrt;\r\nstruct mfc_cache *mfc;\r\nrcu_read_lock();\r\nfor (it->ct = 0; it->ct < MFC_LINES; it->ct++) {\r\nit->cache = &mrt->mfc_cache_array[it->ct];\r\nlist_for_each_entry_rcu(mfc, it->cache, list)\r\nif (pos-- == 0)\r\nreturn mfc;\r\n}\r\nrcu_read_unlock();\r\nspin_lock_bh(&mfc_unres_lock);\r\nit->cache = &mrt->mfc_unres_queue;\r\nlist_for_each_entry(mfc, it->cache, list)\r\nif (pos-- == 0)\r\nreturn mfc;\r\nspin_unlock_bh(&mfc_unres_lock);\r\nit->cache = NULL;\r\nreturn NULL;\r\n}\r\nstatic void *ipmr_mfc_seq_start(struct seq_file *seq, loff_t *pos)\r\n{\r\nstruct ipmr_mfc_iter *it = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct mr_table *mrt;\r\nmrt = ipmr_get_table(net, RT_TABLE_DEFAULT);\r\nif (!mrt)\r\nreturn ERR_PTR(-ENOENT);\r\nit->mrt = mrt;\r\nit->cache = NULL;\r\nit->ct = 0;\r\nreturn *pos ? ipmr_mfc_seq_idx(net, seq->private, *pos - 1)\r\n: SEQ_START_TOKEN;\r\n}\r\nstatic void *ipmr_mfc_seq_next(struct seq_file *seq, void *v, loff_t *pos)\r\n{\r\nstruct mfc_cache *mfc = v;\r\nstruct ipmr_mfc_iter *it = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct mr_table *mrt = it->mrt;\r\n++*pos;\r\nif (v == SEQ_START_TOKEN)\r\nreturn ipmr_mfc_seq_idx(net, seq->private, 0);\r\nif (mfc->list.next != it->cache)\r\nreturn list_entry(mfc->list.next, struct mfc_cache, list);\r\nif (it->cache == &mrt->mfc_unres_queue)\r\ngoto end_of_list;\r\nBUG_ON(it->cache != &mrt->mfc_cache_array[it->ct]);\r\nwhile (++it->ct < MFC_LINES) {\r\nit->cache = &mrt->mfc_cache_array[it->ct];\r\nif (list_empty(it->cache))\r\ncontinue;\r\nreturn list_first_entry(it->cache, struct mfc_cache, list);\r\n}\r\nrcu_read_unlock();\r\nit->cache = &mrt->mfc_unres_queue;\r\nit->ct = 0;\r\nspin_lock_bh(&mfc_unres_lock);\r\nif (!list_empty(it->cache))\r\nreturn list_first_entry(it->cache, struct mfc_cache, list);\r\nend_of_list:\r\nspin_unlock_bh(&mfc_unres_lock);\r\nit->cache = NULL;\r\nreturn NULL;\r\n}\r\nstatic void ipmr_mfc_seq_stop(struct seq_file *seq, void *v)\r\n{\r\nstruct ipmr_mfc_iter *it = seq->private;\r\nstruct mr_table *mrt = it->mrt;\r\nif (it->cache == &mrt->mfc_unres_queue)\r\nspin_unlock_bh(&mfc_unres_lock);\r\nelse if (it->cache == &mrt->mfc_cache_array[it->ct])\r\nrcu_read_unlock();\r\n}\r\nstatic int ipmr_mfc_seq_show(struct seq_file *seq, void *v)\r\n{\r\nint n;\r\nif (v == SEQ_START_TOKEN) {\r\nseq_puts(seq,\r\n"Group Origin Iif Pkts Bytes Wrong Oifs\n");\r\n} else {\r\nconst struct mfc_cache *mfc = v;\r\nconst struct ipmr_mfc_iter *it = seq->private;\r\nconst struct mr_table *mrt = it->mrt;\r\nseq_printf(seq, "%08X %08X %-3hd",\r\n(__force u32) mfc->mfc_mcastgrp,\r\n(__force u32) mfc->mfc_origin,\r\nmfc->mfc_parent);\r\nif (it->cache != &mrt->mfc_unres_queue) {\r\nseq_printf(seq, " %8lu %8lu %8lu",\r\nmfc->mfc_un.res.pkt,\r\nmfc->mfc_un.res.bytes,\r\nmfc->mfc_un.res.wrong_if);\r\nfor (n = mfc->mfc_un.res.minvif;\r\nn < mfc->mfc_un.res.maxvif; n++) {\r\nif (VIF_EXISTS(mrt, n) &&\r\nmfc->mfc_un.res.ttls[n] < 255)\r\nseq_printf(seq,\r\n" %2d:%-3d",\r\nn, mfc->mfc_un.res.ttls[n]);\r\n}\r\n} else {\r\nseq_printf(seq, " %8lu %8lu %8lu", 0ul, 0ul, 0ul);\r\n}\r\nseq_putc(seq, '\n');\r\n}\r\nreturn 0;\r\n}\r\nstatic int ipmr_mfc_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open_net(inode, file, &ipmr_mfc_seq_ops,\r\nsizeof(struct ipmr_mfc_iter));\r\n}\r\nstatic int __net_init ipmr_net_init(struct net *net)\r\n{\r\nint err;\r\nerr = ipmr_rules_init(net);\r\nif (err < 0)\r\ngoto fail;\r\n#ifdef CONFIG_PROC_FS\r\nerr = -ENOMEM;\r\nif (!proc_create("ip_mr_vif", 0, net->proc_net, &ipmr_vif_fops))\r\ngoto proc_vif_fail;\r\nif (!proc_create("ip_mr_cache", 0, net->proc_net, &ipmr_mfc_fops))\r\ngoto proc_cache_fail;\r\n#endif\r\nreturn 0;\r\n#ifdef CONFIG_PROC_FS\r\nproc_cache_fail:\r\nremove_proc_entry("ip_mr_vif", net->proc_net);\r\nproc_vif_fail:\r\nipmr_rules_exit(net);\r\n#endif\r\nfail:\r\nreturn err;\r\n}\r\nstatic void __net_exit ipmr_net_exit(struct net *net)\r\n{\r\n#ifdef CONFIG_PROC_FS\r\nremove_proc_entry("ip_mr_cache", net->proc_net);\r\nremove_proc_entry("ip_mr_vif", net->proc_net);\r\n#endif\r\nipmr_rules_exit(net);\r\n}\r\nint __init ip_mr_init(void)\r\n{\r\nint err;\r\nmrt_cachep = kmem_cache_create("ip_mrt_cache",\r\nsizeof(struct mfc_cache),\r\n0, SLAB_HWCACHE_ALIGN | SLAB_PANIC,\r\nNULL);\r\nif (!mrt_cachep)\r\nreturn -ENOMEM;\r\nerr = register_pernet_subsys(&ipmr_net_ops);\r\nif (err)\r\ngoto reg_pernet_fail;\r\nerr = register_netdevice_notifier(&ip_mr_notifier);\r\nif (err)\r\ngoto reg_notif_fail;\r\n#ifdef CONFIG_IP_PIMSM_V2\r\nif (inet_add_protocol(&pim_protocol, IPPROTO_PIM) < 0) {\r\npr_err("%s: can't add PIM protocol\n", __func__);\r\nerr = -EAGAIN;\r\ngoto add_proto_fail;\r\n}\r\n#endif\r\nrtnl_register(RTNL_FAMILY_IPMR, RTM_GETROUTE,\r\nNULL, ipmr_rtm_dumproute, NULL);\r\nreturn 0;\r\n#ifdef CONFIG_IP_PIMSM_V2\r\nadd_proto_fail:\r\nunregister_netdevice_notifier(&ip_mr_notifier);\r\n#endif\r\nreg_notif_fail:\r\nunregister_pernet_subsys(&ipmr_net_ops);\r\nreg_pernet_fail:\r\nkmem_cache_destroy(mrt_cachep);\r\nreturn err;\r\n}
