static inline int\r\nnvkm_engctx_exists(struct nvkm_object *parent,\r\nstruct nvkm_engine *engine, void **pobject)\r\n{\r\nstruct nvkm_engctx *engctx;\r\nstruct nvkm_object *parctx;\r\nlist_for_each_entry(engctx, &engine->contexts, head) {\r\nparctx = nv_pclass(nv_object(engctx), NV_PARENT_CLASS);\r\nif (parctx == parent) {\r\natomic_inc(&nv_object(engctx)->refcount);\r\n*pobject = engctx;\r\nreturn 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint\r\nnvkm_engctx_create_(struct nvkm_object *parent, struct nvkm_object *engobj,\r\nstruct nvkm_oclass *oclass, struct nvkm_object *pargpu,\r\nu32 size, u32 align, u32 flags, int length, void **pobject)\r\n{\r\nstruct nvkm_client *client = nvkm_client(parent);\r\nstruct nvkm_engine *engine = nv_engine(engobj);\r\nstruct nvkm_object *engctx;\r\nunsigned long save;\r\nint ret;\r\nspin_lock_irqsave(&engine->lock, save);\r\nret = nvkm_engctx_exists(parent, engine, pobject);\r\nspin_unlock_irqrestore(&engine->lock, save);\r\nif (ret)\r\nreturn ret;\r\nif (size) {\r\nret = nvkm_gpuobj_create_(parent, engobj, oclass,\r\nNV_ENGCTX_CLASS, pargpu, size,\r\nalign, flags, length, pobject);\r\n} else {\r\nret = nvkm_object_create_(parent, engobj, oclass,\r\nNV_ENGCTX_CLASS, length, pobject);\r\n}\r\nengctx = *pobject;\r\nif (ret)\r\nreturn ret;\r\nspin_lock_irqsave(&engine->lock, save);\r\nret = nvkm_engctx_exists(parent, engine, pobject);\r\nif (ret) {\r\nspin_unlock_irqrestore(&engine->lock, save);\r\nnvkm_object_ref(NULL, &engctx);\r\nreturn ret;\r\n}\r\nif (client->vm)\r\natomic_inc(&client->vm->engref[nv_engidx(engine)]);\r\nlist_add(&nv_engctx(engctx)->head, &engine->contexts);\r\nnv_engctx(engctx)->addr = ~0ULL;\r\nspin_unlock_irqrestore(&engine->lock, save);\r\nreturn 0;\r\n}\r\nvoid\r\nnvkm_engctx_destroy(struct nvkm_engctx *engctx)\r\n{\r\nstruct nvkm_engine *engine = engctx->gpuobj.object.engine;\r\nstruct nvkm_client *client = nvkm_client(engctx);\r\nunsigned long save;\r\nnvkm_gpuobj_unmap(&engctx->vma);\r\nspin_lock_irqsave(&engine->lock, save);\r\nlist_del(&engctx->head);\r\nspin_unlock_irqrestore(&engine->lock, save);\r\nif (client->vm)\r\natomic_dec(&client->vm->engref[nv_engidx(engine)]);\r\nif (engctx->gpuobj.size)\r\nnvkm_gpuobj_destroy(&engctx->gpuobj);\r\nelse\r\nnvkm_object_destroy(&engctx->gpuobj.object);\r\n}\r\nint\r\nnvkm_engctx_init(struct nvkm_engctx *engctx)\r\n{\r\nstruct nvkm_object *object = nv_object(engctx);\r\nstruct nvkm_subdev *subdev = nv_subdev(object->engine);\r\nstruct nvkm_object *parent;\r\nstruct nvkm_subdev *pardev;\r\nint ret;\r\nret = nvkm_gpuobj_init(&engctx->gpuobj);\r\nif (ret)\r\nreturn ret;\r\nparent = nv_pclass(object->parent, NV_PARENT_CLASS);\r\npardev = nv_subdev(parent->engine);\r\nif (nv_parent(parent)->context_attach) {\r\nmutex_lock(&pardev->mutex);\r\nret = nv_parent(parent)->context_attach(parent, object);\r\nmutex_unlock(&pardev->mutex);\r\n}\r\nif (ret) {\r\nnv_error(parent, "failed to attach %s context, %d\n",\r\nsubdev->name, ret);\r\nreturn ret;\r\n}\r\nnv_debug(parent, "attached %s context\n", subdev->name);\r\nreturn 0;\r\n}\r\nint\r\nnvkm_engctx_fini(struct nvkm_engctx *engctx, bool suspend)\r\n{\r\nstruct nvkm_object *object = nv_object(engctx);\r\nstruct nvkm_subdev *subdev = nv_subdev(object->engine);\r\nstruct nvkm_object *parent;\r\nstruct nvkm_subdev *pardev;\r\nint ret = 0;\r\nparent = nv_pclass(object->parent, NV_PARENT_CLASS);\r\npardev = nv_subdev(parent->engine);\r\nif (nv_parent(parent)->context_detach) {\r\nmutex_lock(&pardev->mutex);\r\nret = nv_parent(parent)->context_detach(parent, suspend, object);\r\nmutex_unlock(&pardev->mutex);\r\n}\r\nif (ret) {\r\nnv_error(parent, "failed to detach %s context, %d\n",\r\nsubdev->name, ret);\r\nreturn ret;\r\n}\r\nnv_debug(parent, "detached %s context\n", subdev->name);\r\nreturn nvkm_gpuobj_fini(&engctx->gpuobj, suspend);\r\n}\r\nint\r\n_nvkm_engctx_ctor(struct nvkm_object *parent, struct nvkm_object *engine,\r\nstruct nvkm_oclass *oclass, void *data, u32 size,\r\nstruct nvkm_object **pobject)\r\n{\r\nstruct nvkm_engctx *engctx;\r\nint ret;\r\nret = nvkm_engctx_create(parent, engine, oclass, NULL, 256, 256,\r\nNVOBJ_FLAG_ZERO_ALLOC, &engctx);\r\n*pobject = nv_object(engctx);\r\nreturn ret;\r\n}\r\nvoid\r\n_nvkm_engctx_dtor(struct nvkm_object *object)\r\n{\r\nnvkm_engctx_destroy(nv_engctx(object));\r\n}\r\nint\r\n_nvkm_engctx_init(struct nvkm_object *object)\r\n{\r\nreturn nvkm_engctx_init(nv_engctx(object));\r\n}\r\nint\r\n_nvkm_engctx_fini(struct nvkm_object *object, bool suspend)\r\n{\r\nreturn nvkm_engctx_fini(nv_engctx(object), suspend);\r\n}\r\nstruct nvkm_object *\r\nnvkm_engctx_get(struct nvkm_engine *engine, u64 addr)\r\n{\r\nstruct nvkm_engctx *engctx;\r\nunsigned long flags;\r\nspin_lock_irqsave(&engine->lock, flags);\r\nlist_for_each_entry(engctx, &engine->contexts, head) {\r\nif (engctx->addr == addr) {\r\nengctx->save = flags;\r\nreturn nv_object(engctx);\r\n}\r\n}\r\nspin_unlock_irqrestore(&engine->lock, flags);\r\nreturn NULL;\r\n}\r\nvoid\r\nnvkm_engctx_put(struct nvkm_object *object)\r\n{\r\nif (object) {\r\nstruct nvkm_engine *engine = nv_engine(object->engine);\r\nstruct nvkm_engctx *engctx = nv_engctx(object);\r\nspin_unlock_irqrestore(&engine->lock, engctx->save);\r\n}\r\n}
