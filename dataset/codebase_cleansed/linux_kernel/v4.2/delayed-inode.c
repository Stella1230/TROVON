int __init btrfs_delayed_inode_init(void)\r\n{\r\ndelayed_node_cache = kmem_cache_create("btrfs_delayed_node",\r\nsizeof(struct btrfs_delayed_node),\r\n0,\r\nSLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD,\r\nNULL);\r\nif (!delayed_node_cache)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid btrfs_delayed_inode_exit(void)\r\n{\r\nif (delayed_node_cache)\r\nkmem_cache_destroy(delayed_node_cache);\r\n}\r\nstatic inline void btrfs_init_delayed_node(\r\nstruct btrfs_delayed_node *delayed_node,\r\nstruct btrfs_root *root, u64 inode_id)\r\n{\r\ndelayed_node->root = root;\r\ndelayed_node->inode_id = inode_id;\r\natomic_set(&delayed_node->refs, 0);\r\ndelayed_node->count = 0;\r\ndelayed_node->flags = 0;\r\ndelayed_node->ins_root = RB_ROOT;\r\ndelayed_node->del_root = RB_ROOT;\r\nmutex_init(&delayed_node->mutex);\r\ndelayed_node->index_cnt = 0;\r\nINIT_LIST_HEAD(&delayed_node->n_list);\r\nINIT_LIST_HEAD(&delayed_node->p_list);\r\ndelayed_node->bytes_reserved = 0;\r\nmemset(&delayed_node->inode_item, 0, sizeof(delayed_node->inode_item));\r\n}\r\nstatic inline int btrfs_is_continuous_delayed_item(\r\nstruct btrfs_delayed_item *item1,\r\nstruct btrfs_delayed_item *item2)\r\n{\r\nif (item1->key.type == BTRFS_DIR_INDEX_KEY &&\r\nitem1->key.objectid == item2->key.objectid &&\r\nitem1->key.type == item2->key.type &&\r\nitem1->key.offset + 1 == item2->key.offset)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic inline struct btrfs_delayed_root *btrfs_get_delayed_root(\r\nstruct btrfs_root *root)\r\n{\r\nreturn root->fs_info->delayed_root;\r\n}\r\nstatic struct btrfs_delayed_node *btrfs_get_delayed_node(struct inode *inode)\r\n{\r\nstruct btrfs_inode *btrfs_inode = BTRFS_I(inode);\r\nstruct btrfs_root *root = btrfs_inode->root;\r\nu64 ino = btrfs_ino(inode);\r\nstruct btrfs_delayed_node *node;\r\nnode = ACCESS_ONCE(btrfs_inode->delayed_node);\r\nif (node) {\r\natomic_inc(&node->refs);\r\nreturn node;\r\n}\r\nspin_lock(&root->inode_lock);\r\nnode = radix_tree_lookup(&root->delayed_nodes_tree, ino);\r\nif (node) {\r\nif (btrfs_inode->delayed_node) {\r\natomic_inc(&node->refs);\r\nBUG_ON(btrfs_inode->delayed_node != node);\r\nspin_unlock(&root->inode_lock);\r\nreturn node;\r\n}\r\nbtrfs_inode->delayed_node = node;\r\natomic_add(2, &node->refs);\r\nspin_unlock(&root->inode_lock);\r\nreturn node;\r\n}\r\nspin_unlock(&root->inode_lock);\r\nreturn NULL;\r\n}\r\nstatic struct btrfs_delayed_node *btrfs_get_or_create_delayed_node(\r\nstruct inode *inode)\r\n{\r\nstruct btrfs_delayed_node *node;\r\nstruct btrfs_inode *btrfs_inode = BTRFS_I(inode);\r\nstruct btrfs_root *root = btrfs_inode->root;\r\nu64 ino = btrfs_ino(inode);\r\nint ret;\r\nagain:\r\nnode = btrfs_get_delayed_node(inode);\r\nif (node)\r\nreturn node;\r\nnode = kmem_cache_alloc(delayed_node_cache, GFP_NOFS);\r\nif (!node)\r\nreturn ERR_PTR(-ENOMEM);\r\nbtrfs_init_delayed_node(node, root, ino);\r\natomic_add(2, &node->refs);\r\nret = radix_tree_preload(GFP_NOFS & ~__GFP_HIGHMEM);\r\nif (ret) {\r\nkmem_cache_free(delayed_node_cache, node);\r\nreturn ERR_PTR(ret);\r\n}\r\nspin_lock(&root->inode_lock);\r\nret = radix_tree_insert(&root->delayed_nodes_tree, ino, node);\r\nif (ret == -EEXIST) {\r\nspin_unlock(&root->inode_lock);\r\nkmem_cache_free(delayed_node_cache, node);\r\nradix_tree_preload_end();\r\ngoto again;\r\n}\r\nbtrfs_inode->delayed_node = node;\r\nspin_unlock(&root->inode_lock);\r\nradix_tree_preload_end();\r\nreturn node;\r\n}\r\nstatic void btrfs_queue_delayed_node(struct btrfs_delayed_root *root,\r\nstruct btrfs_delayed_node *node,\r\nint mod)\r\n{\r\nspin_lock(&root->lock);\r\nif (test_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags)) {\r\nif (!list_empty(&node->p_list))\r\nlist_move_tail(&node->p_list, &root->prepare_list);\r\nelse if (mod)\r\nlist_add_tail(&node->p_list, &root->prepare_list);\r\n} else {\r\nlist_add_tail(&node->n_list, &root->node_list);\r\nlist_add_tail(&node->p_list, &root->prepare_list);\r\natomic_inc(&node->refs);\r\nroot->nodes++;\r\nset_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags);\r\n}\r\nspin_unlock(&root->lock);\r\n}\r\nstatic void btrfs_dequeue_delayed_node(struct btrfs_delayed_root *root,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nspin_lock(&root->lock);\r\nif (test_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags)) {\r\nroot->nodes--;\r\natomic_dec(&node->refs);\r\nlist_del_init(&node->n_list);\r\nif (!list_empty(&node->p_list))\r\nlist_del_init(&node->p_list);\r\nclear_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags);\r\n}\r\nspin_unlock(&root->lock);\r\n}\r\nstatic struct btrfs_delayed_node *btrfs_first_delayed_node(\r\nstruct btrfs_delayed_root *delayed_root)\r\n{\r\nstruct list_head *p;\r\nstruct btrfs_delayed_node *node = NULL;\r\nspin_lock(&delayed_root->lock);\r\nif (list_empty(&delayed_root->node_list))\r\ngoto out;\r\np = delayed_root->node_list.next;\r\nnode = list_entry(p, struct btrfs_delayed_node, n_list);\r\natomic_inc(&node->refs);\r\nout:\r\nspin_unlock(&delayed_root->lock);\r\nreturn node;\r\n}\r\nstatic struct btrfs_delayed_node *btrfs_next_delayed_node(\r\nstruct btrfs_delayed_node *node)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\nstruct list_head *p;\r\nstruct btrfs_delayed_node *next = NULL;\r\ndelayed_root = node->root->fs_info->delayed_root;\r\nspin_lock(&delayed_root->lock);\r\nif (!test_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags)) {\r\nif (list_empty(&delayed_root->node_list))\r\ngoto out;\r\np = delayed_root->node_list.next;\r\n} else if (list_is_last(&node->n_list, &delayed_root->node_list))\r\ngoto out;\r\nelse\r\np = node->n_list.next;\r\nnext = list_entry(p, struct btrfs_delayed_node, n_list);\r\natomic_inc(&next->refs);\r\nout:\r\nspin_unlock(&delayed_root->lock);\r\nreturn next;\r\n}\r\nstatic void __btrfs_release_delayed_node(\r\nstruct btrfs_delayed_node *delayed_node,\r\nint mod)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\nif (!delayed_node)\r\nreturn;\r\ndelayed_root = delayed_node->root->fs_info->delayed_root;\r\nmutex_lock(&delayed_node->mutex);\r\nif (delayed_node->count)\r\nbtrfs_queue_delayed_node(delayed_root, delayed_node, mod);\r\nelse\r\nbtrfs_dequeue_delayed_node(delayed_root, delayed_node);\r\nmutex_unlock(&delayed_node->mutex);\r\nif (atomic_dec_and_test(&delayed_node->refs)) {\r\nbool free = false;\r\nstruct btrfs_root *root = delayed_node->root;\r\nspin_lock(&root->inode_lock);\r\nif (atomic_read(&delayed_node->refs) == 0) {\r\nradix_tree_delete(&root->delayed_nodes_tree,\r\ndelayed_node->inode_id);\r\nfree = true;\r\n}\r\nspin_unlock(&root->inode_lock);\r\nif (free)\r\nkmem_cache_free(delayed_node_cache, delayed_node);\r\n}\r\n}\r\nstatic inline void btrfs_release_delayed_node(struct btrfs_delayed_node *node)\r\n{\r\n__btrfs_release_delayed_node(node, 0);\r\n}\r\nstatic struct btrfs_delayed_node *btrfs_first_prepared_delayed_node(\r\nstruct btrfs_delayed_root *delayed_root)\r\n{\r\nstruct list_head *p;\r\nstruct btrfs_delayed_node *node = NULL;\r\nspin_lock(&delayed_root->lock);\r\nif (list_empty(&delayed_root->prepare_list))\r\ngoto out;\r\np = delayed_root->prepare_list.next;\r\nlist_del_init(p);\r\nnode = list_entry(p, struct btrfs_delayed_node, p_list);\r\natomic_inc(&node->refs);\r\nout:\r\nspin_unlock(&delayed_root->lock);\r\nreturn node;\r\n}\r\nstatic inline void btrfs_release_prepared_delayed_node(\r\nstruct btrfs_delayed_node *node)\r\n{\r\n__btrfs_release_delayed_node(node, 1);\r\n}\r\nstatic struct btrfs_delayed_item *btrfs_alloc_delayed_item(u32 data_len)\r\n{\r\nstruct btrfs_delayed_item *item;\r\nitem = kmalloc(sizeof(*item) + data_len, GFP_NOFS);\r\nif (item) {\r\nitem->data_len = data_len;\r\nitem->ins_or_del = 0;\r\nitem->bytes_reserved = 0;\r\nitem->delayed_node = NULL;\r\natomic_set(&item->refs, 1);\r\n}\r\nreturn item;\r\n}\r\nstatic struct btrfs_delayed_item *__btrfs_lookup_delayed_item(\r\nstruct rb_root *root,\r\nstruct btrfs_key *key,\r\nstruct btrfs_delayed_item **prev,\r\nstruct btrfs_delayed_item **next)\r\n{\r\nstruct rb_node *node, *prev_node = NULL;\r\nstruct btrfs_delayed_item *delayed_item = NULL;\r\nint ret = 0;\r\nnode = root->rb_node;\r\nwhile (node) {\r\ndelayed_item = rb_entry(node, struct btrfs_delayed_item,\r\nrb_node);\r\nprev_node = node;\r\nret = btrfs_comp_cpu_keys(&delayed_item->key, key);\r\nif (ret < 0)\r\nnode = node->rb_right;\r\nelse if (ret > 0)\r\nnode = node->rb_left;\r\nelse\r\nreturn delayed_item;\r\n}\r\nif (prev) {\r\nif (!prev_node)\r\n*prev = NULL;\r\nelse if (ret < 0)\r\n*prev = delayed_item;\r\nelse if ((node = rb_prev(prev_node)) != NULL) {\r\n*prev = rb_entry(node, struct btrfs_delayed_item,\r\nrb_node);\r\n} else\r\n*prev = NULL;\r\n}\r\nif (next) {\r\nif (!prev_node)\r\n*next = NULL;\r\nelse if (ret > 0)\r\n*next = delayed_item;\r\nelse if ((node = rb_next(prev_node)) != NULL) {\r\n*next = rb_entry(node, struct btrfs_delayed_item,\r\nrb_node);\r\n} else\r\n*next = NULL;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct btrfs_delayed_item *__btrfs_lookup_delayed_insertion_item(\r\nstruct btrfs_delayed_node *delayed_node,\r\nstruct btrfs_key *key)\r\n{\r\nstruct btrfs_delayed_item *item;\r\nitem = __btrfs_lookup_delayed_item(&delayed_node->ins_root, key,\r\nNULL, NULL);\r\nreturn item;\r\n}\r\nstatic int __btrfs_add_delayed_item(struct btrfs_delayed_node *delayed_node,\r\nstruct btrfs_delayed_item *ins,\r\nint action)\r\n{\r\nstruct rb_node **p, *node;\r\nstruct rb_node *parent_node = NULL;\r\nstruct rb_root *root;\r\nstruct btrfs_delayed_item *item;\r\nint cmp;\r\nif (action == BTRFS_DELAYED_INSERTION_ITEM)\r\nroot = &delayed_node->ins_root;\r\nelse if (action == BTRFS_DELAYED_DELETION_ITEM)\r\nroot = &delayed_node->del_root;\r\nelse\r\nBUG();\r\np = &root->rb_node;\r\nnode = &ins->rb_node;\r\nwhile (*p) {\r\nparent_node = *p;\r\nitem = rb_entry(parent_node, struct btrfs_delayed_item,\r\nrb_node);\r\ncmp = btrfs_comp_cpu_keys(&item->key, &ins->key);\r\nif (cmp < 0)\r\np = &(*p)->rb_right;\r\nelse if (cmp > 0)\r\np = &(*p)->rb_left;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(node, parent_node, p);\r\nrb_insert_color(node, root);\r\nins->delayed_node = delayed_node;\r\nins->ins_or_del = action;\r\nif (ins->key.type == BTRFS_DIR_INDEX_KEY &&\r\naction == BTRFS_DELAYED_INSERTION_ITEM &&\r\nins->key.offset >= delayed_node->index_cnt)\r\ndelayed_node->index_cnt = ins->key.offset + 1;\r\ndelayed_node->count++;\r\natomic_inc(&delayed_node->root->fs_info->delayed_root->items);\r\nreturn 0;\r\n}\r\nstatic int __btrfs_add_delayed_insertion_item(struct btrfs_delayed_node *node,\r\nstruct btrfs_delayed_item *item)\r\n{\r\nreturn __btrfs_add_delayed_item(node, item,\r\nBTRFS_DELAYED_INSERTION_ITEM);\r\n}\r\nstatic int __btrfs_add_delayed_deletion_item(struct btrfs_delayed_node *node,\r\nstruct btrfs_delayed_item *item)\r\n{\r\nreturn __btrfs_add_delayed_item(node, item,\r\nBTRFS_DELAYED_DELETION_ITEM);\r\n}\r\nstatic void finish_one_item(struct btrfs_delayed_root *delayed_root)\r\n{\r\nint seq = atomic_inc_return(&delayed_root->items_seq);\r\nif ((atomic_dec_return(&delayed_root->items) <\r\nBTRFS_DELAYED_BACKGROUND || seq % BTRFS_DELAYED_BATCH == 0) &&\r\nwaitqueue_active(&delayed_root->wait))\r\nwake_up(&delayed_root->wait);\r\n}\r\nstatic void __btrfs_remove_delayed_item(struct btrfs_delayed_item *delayed_item)\r\n{\r\nstruct rb_root *root;\r\nstruct btrfs_delayed_root *delayed_root;\r\ndelayed_root = delayed_item->delayed_node->root->fs_info->delayed_root;\r\nBUG_ON(!delayed_root);\r\nBUG_ON(delayed_item->ins_or_del != BTRFS_DELAYED_DELETION_ITEM &&\r\ndelayed_item->ins_or_del != BTRFS_DELAYED_INSERTION_ITEM);\r\nif (delayed_item->ins_or_del == BTRFS_DELAYED_INSERTION_ITEM)\r\nroot = &delayed_item->delayed_node->ins_root;\r\nelse\r\nroot = &delayed_item->delayed_node->del_root;\r\nrb_erase(&delayed_item->rb_node, root);\r\ndelayed_item->delayed_node->count--;\r\nfinish_one_item(delayed_root);\r\n}\r\nstatic void btrfs_release_delayed_item(struct btrfs_delayed_item *item)\r\n{\r\nif (item) {\r\n__btrfs_remove_delayed_item(item);\r\nif (atomic_dec_and_test(&item->refs))\r\nkfree(item);\r\n}\r\n}\r\nstatic struct btrfs_delayed_item *__btrfs_first_delayed_insertion_item(\r\nstruct btrfs_delayed_node *delayed_node)\r\n{\r\nstruct rb_node *p;\r\nstruct btrfs_delayed_item *item = NULL;\r\np = rb_first(&delayed_node->ins_root);\r\nif (p)\r\nitem = rb_entry(p, struct btrfs_delayed_item, rb_node);\r\nreturn item;\r\n}\r\nstatic struct btrfs_delayed_item *__btrfs_first_delayed_deletion_item(\r\nstruct btrfs_delayed_node *delayed_node)\r\n{\r\nstruct rb_node *p;\r\nstruct btrfs_delayed_item *item = NULL;\r\np = rb_first(&delayed_node->del_root);\r\nif (p)\r\nitem = rb_entry(p, struct btrfs_delayed_item, rb_node);\r\nreturn item;\r\n}\r\nstatic struct btrfs_delayed_item *__btrfs_next_delayed_item(\r\nstruct btrfs_delayed_item *item)\r\n{\r\nstruct rb_node *p;\r\nstruct btrfs_delayed_item *next = NULL;\r\np = rb_next(&item->rb_node);\r\nif (p)\r\nnext = rb_entry(p, struct btrfs_delayed_item, rb_node);\r\nreturn next;\r\n}\r\nstatic int btrfs_delayed_item_reserve_metadata(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct btrfs_delayed_item *item)\r\n{\r\nstruct btrfs_block_rsv *src_rsv;\r\nstruct btrfs_block_rsv *dst_rsv;\r\nu64 num_bytes;\r\nint ret;\r\nif (!trans->bytes_reserved)\r\nreturn 0;\r\nsrc_rsv = trans->block_rsv;\r\ndst_rsv = &root->fs_info->delayed_block_rsv;\r\nnum_bytes = btrfs_calc_trans_metadata_size(root, 1);\r\nret = btrfs_block_rsv_migrate(src_rsv, dst_rsv, num_bytes);\r\nif (!ret) {\r\ntrace_btrfs_space_reservation(root->fs_info, "delayed_item",\r\nitem->key.objectid,\r\nnum_bytes, 1);\r\nitem->bytes_reserved = num_bytes;\r\n}\r\nreturn ret;\r\n}\r\nstatic void btrfs_delayed_item_release_metadata(struct btrfs_root *root,\r\nstruct btrfs_delayed_item *item)\r\n{\r\nstruct btrfs_block_rsv *rsv;\r\nif (!item->bytes_reserved)\r\nreturn;\r\nrsv = &root->fs_info->delayed_block_rsv;\r\ntrace_btrfs_space_reservation(root->fs_info, "delayed_item",\r\nitem->key.objectid, item->bytes_reserved,\r\n0);\r\nbtrfs_block_rsv_release(root, rsv,\r\nitem->bytes_reserved);\r\n}\r\nstatic int btrfs_delayed_inode_reserve_metadata(\r\nstruct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct inode *inode,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nstruct btrfs_block_rsv *src_rsv;\r\nstruct btrfs_block_rsv *dst_rsv;\r\nu64 num_bytes;\r\nint ret;\r\nbool release = false;\r\nsrc_rsv = trans->block_rsv;\r\ndst_rsv = &root->fs_info->delayed_block_rsv;\r\nnum_bytes = btrfs_calc_trans_metadata_size(root, 1);\r\nif (!src_rsv || (!trans->bytes_reserved &&\r\nsrc_rsv->type != BTRFS_BLOCK_RSV_DELALLOC)) {\r\nret = btrfs_block_rsv_add(root, dst_rsv, num_bytes,\r\nBTRFS_RESERVE_NO_FLUSH);\r\nif (ret == -EAGAIN)\r\nret = -ENOSPC;\r\nif (!ret) {\r\nnode->bytes_reserved = num_bytes;\r\ntrace_btrfs_space_reservation(root->fs_info,\r\n"delayed_inode",\r\nbtrfs_ino(inode),\r\nnum_bytes, 1);\r\n}\r\nreturn ret;\r\n} else if (src_rsv->type == BTRFS_BLOCK_RSV_DELALLOC) {\r\nspin_lock(&BTRFS_I(inode)->lock);\r\nif (test_and_clear_bit(BTRFS_INODE_DELALLOC_META_RESERVED,\r\n&BTRFS_I(inode)->runtime_flags)) {\r\nspin_unlock(&BTRFS_I(inode)->lock);\r\nrelease = true;\r\ngoto migrate;\r\n}\r\nspin_unlock(&BTRFS_I(inode)->lock);\r\nret = btrfs_block_rsv_add(root, dst_rsv, num_bytes,\r\nBTRFS_RESERVE_NO_FLUSH);\r\nif (!ret)\r\ngoto out;\r\nret = btrfs_block_rsv_migrate(src_rsv, dst_rsv, num_bytes);\r\nif (!WARN_ON(ret))\r\ngoto out;\r\nret = btrfs_block_rsv_migrate(&root->fs_info->global_block_rsv,\r\ndst_rsv, num_bytes);\r\ngoto out;\r\n}\r\nmigrate:\r\nret = btrfs_block_rsv_migrate(src_rsv, dst_rsv, num_bytes);\r\nout:\r\nif (!ret) {\r\ntrace_btrfs_space_reservation(root->fs_info, "delayed_inode",\r\nbtrfs_ino(inode), num_bytes, 1);\r\nnode->bytes_reserved = num_bytes;\r\n}\r\nif (release) {\r\ntrace_btrfs_space_reservation(root->fs_info, "delalloc",\r\nbtrfs_ino(inode), num_bytes, 0);\r\nbtrfs_block_rsv_release(root, src_rsv, num_bytes);\r\n}\r\nreturn ret;\r\n}\r\nstatic void btrfs_delayed_inode_release_metadata(struct btrfs_root *root,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nstruct btrfs_block_rsv *rsv;\r\nif (!node->bytes_reserved)\r\nreturn;\r\nrsv = &root->fs_info->delayed_block_rsv;\r\ntrace_btrfs_space_reservation(root->fs_info, "delayed_inode",\r\nnode->inode_id, node->bytes_reserved, 0);\r\nbtrfs_block_rsv_release(root, rsv,\r\nnode->bytes_reserved);\r\nnode->bytes_reserved = 0;\r\n}\r\nstatic int btrfs_batch_insert_items(struct btrfs_root *root,\r\nstruct btrfs_path *path,\r\nstruct btrfs_delayed_item *item)\r\n{\r\nstruct btrfs_delayed_item *curr, *next;\r\nint free_space;\r\nint total_data_size = 0, total_size = 0;\r\nstruct extent_buffer *leaf;\r\nchar *data_ptr;\r\nstruct btrfs_key *keys;\r\nu32 *data_size;\r\nstruct list_head head;\r\nint slot;\r\nint nitems;\r\nint i;\r\nint ret = 0;\r\nBUG_ON(!path->nodes[0]);\r\nleaf = path->nodes[0];\r\nfree_space = btrfs_leaf_free_space(root, leaf);\r\nINIT_LIST_HEAD(&head);\r\nnext = item;\r\nnitems = 0;\r\nwhile (total_size + next->data_len + sizeof(struct btrfs_item) <=\r\nfree_space) {\r\ntotal_data_size += next->data_len;\r\ntotal_size += next->data_len + sizeof(struct btrfs_item);\r\nlist_add_tail(&next->tree_list, &head);\r\nnitems++;\r\ncurr = next;\r\nnext = __btrfs_next_delayed_item(curr);\r\nif (!next)\r\nbreak;\r\nif (!btrfs_is_continuous_delayed_item(curr, next))\r\nbreak;\r\n}\r\nif (!nitems) {\r\nret = 0;\r\ngoto out;\r\n}\r\nbtrfs_set_path_blocking(path);\r\nkeys = kmalloc_array(nitems, sizeof(struct btrfs_key), GFP_NOFS);\r\nif (!keys) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\ndata_size = kmalloc_array(nitems, sizeof(u32), GFP_NOFS);\r\nif (!data_size) {\r\nret = -ENOMEM;\r\ngoto error;\r\n}\r\ni = 0;\r\nlist_for_each_entry(next, &head, tree_list) {\r\nkeys[i] = next->key;\r\ndata_size[i] = next->data_len;\r\ni++;\r\n}\r\nbtrfs_clear_path_blocking(path, NULL, 0);\r\nsetup_items_for_insert(root, path, keys, data_size,\r\ntotal_data_size, total_size, nitems);\r\nslot = path->slots[0];\r\nlist_for_each_entry_safe(curr, next, &head, tree_list) {\r\ndata_ptr = btrfs_item_ptr(leaf, slot, char);\r\nwrite_extent_buffer(leaf, &curr->data,\r\n(unsigned long)data_ptr,\r\ncurr->data_len);\r\nslot++;\r\nbtrfs_delayed_item_release_metadata(root, curr);\r\nlist_del(&curr->tree_list);\r\nbtrfs_release_delayed_item(curr);\r\n}\r\nerror:\r\nkfree(data_size);\r\nkfree(keys);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int btrfs_insert_delayed_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct btrfs_path *path,\r\nstruct btrfs_delayed_item *delayed_item)\r\n{\r\nstruct extent_buffer *leaf;\r\nchar *ptr;\r\nint ret;\r\nret = btrfs_insert_empty_item(trans, root, path, &delayed_item->key,\r\ndelayed_item->data_len);\r\nif (ret < 0 && ret != -EEXIST)\r\nreturn ret;\r\nleaf = path->nodes[0];\r\nptr = btrfs_item_ptr(leaf, path->slots[0], char);\r\nwrite_extent_buffer(leaf, delayed_item->data, (unsigned long)ptr,\r\ndelayed_item->data_len);\r\nbtrfs_mark_buffer_dirty(leaf);\r\nbtrfs_delayed_item_release_metadata(root, delayed_item);\r\nreturn 0;\r\n}\r\nstatic int btrfs_insert_delayed_items(struct btrfs_trans_handle *trans,\r\nstruct btrfs_path *path,\r\nstruct btrfs_root *root,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nstruct btrfs_delayed_item *curr, *prev;\r\nint ret = 0;\r\ndo_again:\r\nmutex_lock(&node->mutex);\r\ncurr = __btrfs_first_delayed_insertion_item(node);\r\nif (!curr)\r\ngoto insert_end;\r\nret = btrfs_insert_delayed_item(trans, root, path, curr);\r\nif (ret < 0) {\r\nbtrfs_release_path(path);\r\ngoto insert_end;\r\n}\r\nprev = curr;\r\ncurr = __btrfs_next_delayed_item(prev);\r\nif (curr && btrfs_is_continuous_delayed_item(prev, curr)) {\r\npath->slots[0]++;\r\nbtrfs_batch_insert_items(root, path, curr);\r\n}\r\nbtrfs_release_delayed_item(prev);\r\nbtrfs_mark_buffer_dirty(path->nodes[0]);\r\nbtrfs_release_path(path);\r\nmutex_unlock(&node->mutex);\r\ngoto do_again;\r\ninsert_end:\r\nmutex_unlock(&node->mutex);\r\nreturn ret;\r\n}\r\nstatic int btrfs_batch_delete_items(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct btrfs_path *path,\r\nstruct btrfs_delayed_item *item)\r\n{\r\nstruct btrfs_delayed_item *curr, *next;\r\nstruct extent_buffer *leaf;\r\nstruct btrfs_key key;\r\nstruct list_head head;\r\nint nitems, i, last_item;\r\nint ret = 0;\r\nBUG_ON(!path->nodes[0]);\r\nleaf = path->nodes[0];\r\ni = path->slots[0];\r\nlast_item = btrfs_header_nritems(leaf) - 1;\r\nif (i > last_item)\r\nreturn -ENOENT;\r\nnext = item;\r\nINIT_LIST_HEAD(&head);\r\nbtrfs_item_key_to_cpu(leaf, &key, i);\r\nnitems = 0;\r\nwhile (btrfs_comp_cpu_keys(&next->key, &key) == 0) {\r\nlist_add_tail(&next->tree_list, &head);\r\nnitems++;\r\ncurr = next;\r\nnext = __btrfs_next_delayed_item(curr);\r\nif (!next)\r\nbreak;\r\nif (!btrfs_is_continuous_delayed_item(curr, next))\r\nbreak;\r\ni++;\r\nif (i > last_item)\r\nbreak;\r\nbtrfs_item_key_to_cpu(leaf, &key, i);\r\n}\r\nif (!nitems)\r\nreturn 0;\r\nret = btrfs_del_items(trans, root, path, path->slots[0], nitems);\r\nif (ret)\r\ngoto out;\r\nlist_for_each_entry_safe(curr, next, &head, tree_list) {\r\nbtrfs_delayed_item_release_metadata(root, curr);\r\nlist_del(&curr->tree_list);\r\nbtrfs_release_delayed_item(curr);\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic int btrfs_delete_delayed_items(struct btrfs_trans_handle *trans,\r\nstruct btrfs_path *path,\r\nstruct btrfs_root *root,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nstruct btrfs_delayed_item *curr, *prev;\r\nint ret = 0;\r\ndo_again:\r\nmutex_lock(&node->mutex);\r\ncurr = __btrfs_first_delayed_deletion_item(node);\r\nif (!curr)\r\ngoto delete_fail;\r\nret = btrfs_search_slot(trans, root, &curr->key, path, -1, 1);\r\nif (ret < 0)\r\ngoto delete_fail;\r\nelse if (ret > 0) {\r\nprev = curr;\r\ncurr = __btrfs_next_delayed_item(prev);\r\nbtrfs_release_delayed_item(prev);\r\nret = 0;\r\nbtrfs_release_path(path);\r\nif (curr) {\r\nmutex_unlock(&node->mutex);\r\ngoto do_again;\r\n} else\r\ngoto delete_fail;\r\n}\r\nbtrfs_batch_delete_items(trans, root, path, curr);\r\nbtrfs_release_path(path);\r\nmutex_unlock(&node->mutex);\r\ngoto do_again;\r\ndelete_fail:\r\nbtrfs_release_path(path);\r\nmutex_unlock(&node->mutex);\r\nreturn ret;\r\n}\r\nstatic void btrfs_release_delayed_inode(struct btrfs_delayed_node *delayed_node)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\nif (delayed_node &&\r\ntest_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\r\nBUG_ON(!delayed_node->root);\r\nclear_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags);\r\ndelayed_node->count--;\r\ndelayed_root = delayed_node->root->fs_info->delayed_root;\r\nfinish_one_item(delayed_root);\r\n}\r\n}\r\nstatic void btrfs_release_delayed_iref(struct btrfs_delayed_node *delayed_node)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\nASSERT(delayed_node->root);\r\nclear_bit(BTRFS_DELAYED_NODE_DEL_IREF, &delayed_node->flags);\r\ndelayed_node->count--;\r\ndelayed_root = delayed_node->root->fs_info->delayed_root;\r\nfinish_one_item(delayed_root);\r\n}\r\nstatic int __btrfs_update_delayed_inode(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct btrfs_path *path,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nstruct btrfs_key key;\r\nstruct btrfs_inode_item *inode_item;\r\nstruct extent_buffer *leaf;\r\nint mod;\r\nint ret;\r\nkey.objectid = node->inode_id;\r\nkey.type = BTRFS_INODE_ITEM_KEY;\r\nkey.offset = 0;\r\nif (test_bit(BTRFS_DELAYED_NODE_DEL_IREF, &node->flags))\r\nmod = -1;\r\nelse\r\nmod = 1;\r\nret = btrfs_lookup_inode(trans, root, path, &key, mod);\r\nif (ret > 0) {\r\nbtrfs_release_path(path);\r\nreturn -ENOENT;\r\n} else if (ret < 0) {\r\nreturn ret;\r\n}\r\nleaf = path->nodes[0];\r\ninode_item = btrfs_item_ptr(leaf, path->slots[0],\r\nstruct btrfs_inode_item);\r\nwrite_extent_buffer(leaf, &node->inode_item, (unsigned long)inode_item,\r\nsizeof(struct btrfs_inode_item));\r\nbtrfs_mark_buffer_dirty(leaf);\r\nif (!test_bit(BTRFS_DELAYED_NODE_DEL_IREF, &node->flags))\r\ngoto no_iref;\r\npath->slots[0]++;\r\nif (path->slots[0] >= btrfs_header_nritems(leaf))\r\ngoto search;\r\nagain:\r\nbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\r\nif (key.objectid != node->inode_id)\r\ngoto out;\r\nif (key.type != BTRFS_INODE_REF_KEY &&\r\nkey.type != BTRFS_INODE_EXTREF_KEY)\r\ngoto out;\r\nbtrfs_del_item(trans, root, path);\r\nout:\r\nbtrfs_release_delayed_iref(node);\r\nno_iref:\r\nbtrfs_release_path(path);\r\nerr_out:\r\nbtrfs_delayed_inode_release_metadata(root, node);\r\nbtrfs_release_delayed_inode(node);\r\nreturn ret;\r\nsearch:\r\nbtrfs_release_path(path);\r\nkey.type = BTRFS_INODE_EXTREF_KEY;\r\nkey.offset = -1;\r\nret = btrfs_search_slot(trans, root, &key, path, -1, 1);\r\nif (ret < 0)\r\ngoto err_out;\r\nASSERT(ret);\r\nret = 0;\r\nleaf = path->nodes[0];\r\npath->slots[0]--;\r\ngoto again;\r\n}\r\nstatic inline int btrfs_update_delayed_inode(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct btrfs_path *path,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nint ret;\r\nmutex_lock(&node->mutex);\r\nif (!test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &node->flags)) {\r\nmutex_unlock(&node->mutex);\r\nreturn 0;\r\n}\r\nret = __btrfs_update_delayed_inode(trans, root, path, node);\r\nmutex_unlock(&node->mutex);\r\nreturn ret;\r\n}\r\nstatic inline int\r\n__btrfs_commit_inode_delayed_items(struct btrfs_trans_handle *trans,\r\nstruct btrfs_path *path,\r\nstruct btrfs_delayed_node *node)\r\n{\r\nint ret;\r\nret = btrfs_insert_delayed_items(trans, path, node->root, node);\r\nif (ret)\r\nreturn ret;\r\nret = btrfs_delete_delayed_items(trans, path, node->root, node);\r\nif (ret)\r\nreturn ret;\r\nret = btrfs_update_delayed_inode(trans, node->root, path, node);\r\nreturn ret;\r\n}\r\nstatic int __btrfs_run_delayed_items(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, int nr)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\nstruct btrfs_delayed_node *curr_node, *prev_node;\r\nstruct btrfs_path *path;\r\nstruct btrfs_block_rsv *block_rsv;\r\nint ret = 0;\r\nbool count = (nr > 0);\r\nif (trans->aborted)\r\nreturn -EIO;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\npath->leave_spinning = 1;\r\nblock_rsv = trans->block_rsv;\r\ntrans->block_rsv = &root->fs_info->delayed_block_rsv;\r\ndelayed_root = btrfs_get_delayed_root(root);\r\ncurr_node = btrfs_first_delayed_node(delayed_root);\r\nwhile (curr_node && (!count || (count && nr--))) {\r\nret = __btrfs_commit_inode_delayed_items(trans, path,\r\ncurr_node);\r\nif (ret) {\r\nbtrfs_release_delayed_node(curr_node);\r\ncurr_node = NULL;\r\nbtrfs_abort_transaction(trans, root, ret);\r\nbreak;\r\n}\r\nprev_node = curr_node;\r\ncurr_node = btrfs_next_delayed_node(curr_node);\r\nbtrfs_release_delayed_node(prev_node);\r\n}\r\nif (curr_node)\r\nbtrfs_release_delayed_node(curr_node);\r\nbtrfs_free_path(path);\r\ntrans->block_rsv = block_rsv;\r\nreturn ret;\r\n}\r\nint btrfs_run_delayed_items(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root)\r\n{\r\nreturn __btrfs_run_delayed_items(trans, root, -1);\r\n}\r\nint btrfs_run_delayed_items_nr(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, int nr)\r\n{\r\nreturn __btrfs_run_delayed_items(trans, root, nr);\r\n}\r\nint btrfs_commit_inode_delayed_items(struct btrfs_trans_handle *trans,\r\nstruct inode *inode)\r\n{\r\nstruct btrfs_delayed_node *delayed_node = btrfs_get_delayed_node(inode);\r\nstruct btrfs_path *path;\r\nstruct btrfs_block_rsv *block_rsv;\r\nint ret;\r\nif (!delayed_node)\r\nreturn 0;\r\nmutex_lock(&delayed_node->mutex);\r\nif (!delayed_node->count) {\r\nmutex_unlock(&delayed_node->mutex);\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn 0;\r\n}\r\nmutex_unlock(&delayed_node->mutex);\r\npath = btrfs_alloc_path();\r\nif (!path) {\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn -ENOMEM;\r\n}\r\npath->leave_spinning = 1;\r\nblock_rsv = trans->block_rsv;\r\ntrans->block_rsv = &delayed_node->root->fs_info->delayed_block_rsv;\r\nret = __btrfs_commit_inode_delayed_items(trans, path, delayed_node);\r\nbtrfs_release_delayed_node(delayed_node);\r\nbtrfs_free_path(path);\r\ntrans->block_rsv = block_rsv;\r\nreturn ret;\r\n}\r\nint btrfs_commit_inode_delayed_inode(struct inode *inode)\r\n{\r\nstruct btrfs_trans_handle *trans;\r\nstruct btrfs_delayed_node *delayed_node = btrfs_get_delayed_node(inode);\r\nstruct btrfs_path *path;\r\nstruct btrfs_block_rsv *block_rsv;\r\nint ret;\r\nif (!delayed_node)\r\nreturn 0;\r\nmutex_lock(&delayed_node->mutex);\r\nif (!test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\r\nmutex_unlock(&delayed_node->mutex);\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn 0;\r\n}\r\nmutex_unlock(&delayed_node->mutex);\r\ntrans = btrfs_join_transaction(delayed_node->root);\r\nif (IS_ERR(trans)) {\r\nret = PTR_ERR(trans);\r\ngoto out;\r\n}\r\npath = btrfs_alloc_path();\r\nif (!path) {\r\nret = -ENOMEM;\r\ngoto trans_out;\r\n}\r\npath->leave_spinning = 1;\r\nblock_rsv = trans->block_rsv;\r\ntrans->block_rsv = &delayed_node->root->fs_info->delayed_block_rsv;\r\nmutex_lock(&delayed_node->mutex);\r\nif (test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags))\r\nret = __btrfs_update_delayed_inode(trans, delayed_node->root,\r\npath, delayed_node);\r\nelse\r\nret = 0;\r\nmutex_unlock(&delayed_node->mutex);\r\nbtrfs_free_path(path);\r\ntrans->block_rsv = block_rsv;\r\ntrans_out:\r\nbtrfs_end_transaction(trans, delayed_node->root);\r\nbtrfs_btree_balance_dirty(delayed_node->root);\r\nout:\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn ret;\r\n}\r\nvoid btrfs_remove_delayed_node(struct inode *inode)\r\n{\r\nstruct btrfs_delayed_node *delayed_node;\r\ndelayed_node = ACCESS_ONCE(BTRFS_I(inode)->delayed_node);\r\nif (!delayed_node)\r\nreturn;\r\nBTRFS_I(inode)->delayed_node = NULL;\r\nbtrfs_release_delayed_node(delayed_node);\r\n}\r\nstatic void btrfs_async_run_delayed_root(struct btrfs_work *work)\r\n{\r\nstruct btrfs_async_delayed_work *async_work;\r\nstruct btrfs_delayed_root *delayed_root;\r\nstruct btrfs_trans_handle *trans;\r\nstruct btrfs_path *path;\r\nstruct btrfs_delayed_node *delayed_node = NULL;\r\nstruct btrfs_root *root;\r\nstruct btrfs_block_rsv *block_rsv;\r\nint total_done = 0;\r\nasync_work = container_of(work, struct btrfs_async_delayed_work, work);\r\ndelayed_root = async_work->delayed_root;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\ngoto out;\r\nagain:\r\nif (atomic_read(&delayed_root->items) < BTRFS_DELAYED_BACKGROUND / 2)\r\ngoto free_path;\r\ndelayed_node = btrfs_first_prepared_delayed_node(delayed_root);\r\nif (!delayed_node)\r\ngoto free_path;\r\npath->leave_spinning = 1;\r\nroot = delayed_node->root;\r\ntrans = btrfs_join_transaction(root);\r\nif (IS_ERR(trans))\r\ngoto release_path;\r\nblock_rsv = trans->block_rsv;\r\ntrans->block_rsv = &root->fs_info->delayed_block_rsv;\r\n__btrfs_commit_inode_delayed_items(trans, path, delayed_node);\r\ntrans->block_rsv = block_rsv;\r\nbtrfs_end_transaction(trans, root);\r\nbtrfs_btree_balance_dirty_nodelay(root);\r\nrelease_path:\r\nbtrfs_release_path(path);\r\ntotal_done++;\r\nbtrfs_release_prepared_delayed_node(delayed_node);\r\nif (async_work->nr == 0 || total_done < async_work->nr)\r\ngoto again;\r\nfree_path:\r\nbtrfs_free_path(path);\r\nout:\r\nwake_up(&delayed_root->wait);\r\nkfree(async_work);\r\n}\r\nstatic int btrfs_wq_run_delayed_node(struct btrfs_delayed_root *delayed_root,\r\nstruct btrfs_fs_info *fs_info, int nr)\r\n{\r\nstruct btrfs_async_delayed_work *async_work;\r\nif (atomic_read(&delayed_root->items) < BTRFS_DELAYED_BACKGROUND)\r\nreturn 0;\r\nasync_work = kmalloc(sizeof(*async_work), GFP_NOFS);\r\nif (!async_work)\r\nreturn -ENOMEM;\r\nasync_work->delayed_root = delayed_root;\r\nbtrfs_init_work(&async_work->work, btrfs_delayed_meta_helper,\r\nbtrfs_async_run_delayed_root, NULL, NULL);\r\nasync_work->nr = nr;\r\nbtrfs_queue_work(fs_info->delayed_workers, &async_work->work);\r\nreturn 0;\r\n}\r\nvoid btrfs_assert_delayed_root_empty(struct btrfs_root *root)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\ndelayed_root = btrfs_get_delayed_root(root);\r\nWARN_ON(btrfs_first_delayed_node(delayed_root));\r\n}\r\nstatic int could_end_wait(struct btrfs_delayed_root *delayed_root, int seq)\r\n{\r\nint val = atomic_read(&delayed_root->items_seq);\r\nif (val < seq || val >= seq + BTRFS_DELAYED_BATCH)\r\nreturn 1;\r\nif (atomic_read(&delayed_root->items) < BTRFS_DELAYED_BACKGROUND)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nvoid btrfs_balance_delayed_items(struct btrfs_root *root)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\nstruct btrfs_fs_info *fs_info = root->fs_info;\r\ndelayed_root = btrfs_get_delayed_root(root);\r\nif (atomic_read(&delayed_root->items) < BTRFS_DELAYED_BACKGROUND)\r\nreturn;\r\nif (atomic_read(&delayed_root->items) >= BTRFS_DELAYED_WRITEBACK) {\r\nint seq;\r\nint ret;\r\nseq = atomic_read(&delayed_root->items_seq);\r\nret = btrfs_wq_run_delayed_node(delayed_root, fs_info, 0);\r\nif (ret)\r\nreturn;\r\nwait_event_interruptible(delayed_root->wait,\r\ncould_end_wait(delayed_root, seq));\r\nreturn;\r\n}\r\nbtrfs_wq_run_delayed_node(delayed_root, fs_info, BTRFS_DELAYED_BATCH);\r\n}\r\nint btrfs_insert_delayed_dir_index(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, const char *name,\r\nint name_len, struct inode *dir,\r\nstruct btrfs_disk_key *disk_key, u8 type,\r\nu64 index)\r\n{\r\nstruct btrfs_delayed_node *delayed_node;\r\nstruct btrfs_delayed_item *delayed_item;\r\nstruct btrfs_dir_item *dir_item;\r\nint ret;\r\ndelayed_node = btrfs_get_or_create_delayed_node(dir);\r\nif (IS_ERR(delayed_node))\r\nreturn PTR_ERR(delayed_node);\r\ndelayed_item = btrfs_alloc_delayed_item(sizeof(*dir_item) + name_len);\r\nif (!delayed_item) {\r\nret = -ENOMEM;\r\ngoto release_node;\r\n}\r\ndelayed_item->key.objectid = btrfs_ino(dir);\r\ndelayed_item->key.type = BTRFS_DIR_INDEX_KEY;\r\ndelayed_item->key.offset = index;\r\ndir_item = (struct btrfs_dir_item *)delayed_item->data;\r\ndir_item->location = *disk_key;\r\nbtrfs_set_stack_dir_transid(dir_item, trans->transid);\r\nbtrfs_set_stack_dir_data_len(dir_item, 0);\r\nbtrfs_set_stack_dir_name_len(dir_item, name_len);\r\nbtrfs_set_stack_dir_type(dir_item, type);\r\nmemcpy((char *)(dir_item + 1), name, name_len);\r\nret = btrfs_delayed_item_reserve_metadata(trans, root, delayed_item);\r\nBUG_ON(ret);\r\nmutex_lock(&delayed_node->mutex);\r\nret = __btrfs_add_delayed_insertion_item(delayed_node, delayed_item);\r\nif (unlikely(ret)) {\r\nbtrfs_err(root->fs_info, "err add delayed dir index item(name: %.*s) "\r\n"into the insertion tree of the delayed node"\r\n"(root id: %llu, inode id: %llu, errno: %d)",\r\nname_len, name, delayed_node->root->objectid,\r\ndelayed_node->inode_id, ret);\r\nBUG();\r\n}\r\nmutex_unlock(&delayed_node->mutex);\r\nrelease_node:\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn ret;\r\n}\r\nstatic int btrfs_delete_delayed_insertion_item(struct btrfs_root *root,\r\nstruct btrfs_delayed_node *node,\r\nstruct btrfs_key *key)\r\n{\r\nstruct btrfs_delayed_item *item;\r\nmutex_lock(&node->mutex);\r\nitem = __btrfs_lookup_delayed_insertion_item(node, key);\r\nif (!item) {\r\nmutex_unlock(&node->mutex);\r\nreturn 1;\r\n}\r\nbtrfs_delayed_item_release_metadata(root, item);\r\nbtrfs_release_delayed_item(item);\r\nmutex_unlock(&node->mutex);\r\nreturn 0;\r\n}\r\nint btrfs_delete_delayed_dir_index(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, struct inode *dir,\r\nu64 index)\r\n{\r\nstruct btrfs_delayed_node *node;\r\nstruct btrfs_delayed_item *item;\r\nstruct btrfs_key item_key;\r\nint ret;\r\nnode = btrfs_get_or_create_delayed_node(dir);\r\nif (IS_ERR(node))\r\nreturn PTR_ERR(node);\r\nitem_key.objectid = btrfs_ino(dir);\r\nitem_key.type = BTRFS_DIR_INDEX_KEY;\r\nitem_key.offset = index;\r\nret = btrfs_delete_delayed_insertion_item(root, node, &item_key);\r\nif (!ret)\r\ngoto end;\r\nitem = btrfs_alloc_delayed_item(0);\r\nif (!item) {\r\nret = -ENOMEM;\r\ngoto end;\r\n}\r\nitem->key = item_key;\r\nret = btrfs_delayed_item_reserve_metadata(trans, root, item);\r\nBUG_ON(ret);\r\nmutex_lock(&node->mutex);\r\nret = __btrfs_add_delayed_deletion_item(node, item);\r\nif (unlikely(ret)) {\r\nbtrfs_err(root->fs_info, "err add delayed dir index item(index: %llu) "\r\n"into the deletion tree of the delayed node"\r\n"(root id: %llu, inode id: %llu, errno: %d)",\r\nindex, node->root->objectid, node->inode_id,\r\nret);\r\nBUG();\r\n}\r\nmutex_unlock(&node->mutex);\r\nend:\r\nbtrfs_release_delayed_node(node);\r\nreturn ret;\r\n}\r\nint btrfs_inode_delayed_dir_index_count(struct inode *inode)\r\n{\r\nstruct btrfs_delayed_node *delayed_node = btrfs_get_delayed_node(inode);\r\nif (!delayed_node)\r\nreturn -ENOENT;\r\nif (!delayed_node->index_cnt) {\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn -EINVAL;\r\n}\r\nBTRFS_I(inode)->index_cnt = delayed_node->index_cnt;\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn 0;\r\n}\r\nvoid btrfs_get_delayed_items(struct inode *inode, struct list_head *ins_list,\r\nstruct list_head *del_list)\r\n{\r\nstruct btrfs_delayed_node *delayed_node;\r\nstruct btrfs_delayed_item *item;\r\ndelayed_node = btrfs_get_delayed_node(inode);\r\nif (!delayed_node)\r\nreturn;\r\nmutex_lock(&delayed_node->mutex);\r\nitem = __btrfs_first_delayed_insertion_item(delayed_node);\r\nwhile (item) {\r\natomic_inc(&item->refs);\r\nlist_add_tail(&item->readdir_list, ins_list);\r\nitem = __btrfs_next_delayed_item(item);\r\n}\r\nitem = __btrfs_first_delayed_deletion_item(delayed_node);\r\nwhile (item) {\r\natomic_inc(&item->refs);\r\nlist_add_tail(&item->readdir_list, del_list);\r\nitem = __btrfs_next_delayed_item(item);\r\n}\r\nmutex_unlock(&delayed_node->mutex);\r\natomic_dec(&delayed_node->refs);\r\n}\r\nvoid btrfs_put_delayed_items(struct list_head *ins_list,\r\nstruct list_head *del_list)\r\n{\r\nstruct btrfs_delayed_item *curr, *next;\r\nlist_for_each_entry_safe(curr, next, ins_list, readdir_list) {\r\nlist_del(&curr->readdir_list);\r\nif (atomic_dec_and_test(&curr->refs))\r\nkfree(curr);\r\n}\r\nlist_for_each_entry_safe(curr, next, del_list, readdir_list) {\r\nlist_del(&curr->readdir_list);\r\nif (atomic_dec_and_test(&curr->refs))\r\nkfree(curr);\r\n}\r\n}\r\nint btrfs_should_delete_dir_index(struct list_head *del_list,\r\nu64 index)\r\n{\r\nstruct btrfs_delayed_item *curr, *next;\r\nint ret;\r\nif (list_empty(del_list))\r\nreturn 0;\r\nlist_for_each_entry_safe(curr, next, del_list, readdir_list) {\r\nif (curr->key.offset > index)\r\nbreak;\r\nlist_del(&curr->readdir_list);\r\nret = (curr->key.offset == index);\r\nif (atomic_dec_and_test(&curr->refs))\r\nkfree(curr);\r\nif (ret)\r\nreturn 1;\r\nelse\r\ncontinue;\r\n}\r\nreturn 0;\r\n}\r\nint btrfs_readdir_delayed_dir_index(struct dir_context *ctx,\r\nstruct list_head *ins_list)\r\n{\r\nstruct btrfs_dir_item *di;\r\nstruct btrfs_delayed_item *curr, *next;\r\nstruct btrfs_key location;\r\nchar *name;\r\nint name_len;\r\nint over = 0;\r\nunsigned char d_type;\r\nif (list_empty(ins_list))\r\nreturn 0;\r\nlist_for_each_entry_safe(curr, next, ins_list, readdir_list) {\r\nlist_del(&curr->readdir_list);\r\nif (curr->key.offset < ctx->pos) {\r\nif (atomic_dec_and_test(&curr->refs))\r\nkfree(curr);\r\ncontinue;\r\n}\r\nctx->pos = curr->key.offset;\r\ndi = (struct btrfs_dir_item *)curr->data;\r\nname = (char *)(di + 1);\r\nname_len = btrfs_stack_dir_name_len(di);\r\nd_type = btrfs_filetype_table[di->type];\r\nbtrfs_disk_key_to_cpu(&location, &di->location);\r\nover = !dir_emit(ctx, name, name_len,\r\nlocation.objectid, d_type);\r\nif (atomic_dec_and_test(&curr->refs))\r\nkfree(curr);\r\nif (over)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void fill_stack_inode_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_inode_item *inode_item,\r\nstruct inode *inode)\r\n{\r\nbtrfs_set_stack_inode_uid(inode_item, i_uid_read(inode));\r\nbtrfs_set_stack_inode_gid(inode_item, i_gid_read(inode));\r\nbtrfs_set_stack_inode_size(inode_item, BTRFS_I(inode)->disk_i_size);\r\nbtrfs_set_stack_inode_mode(inode_item, inode->i_mode);\r\nbtrfs_set_stack_inode_nlink(inode_item, inode->i_nlink);\r\nbtrfs_set_stack_inode_nbytes(inode_item, inode_get_bytes(inode));\r\nbtrfs_set_stack_inode_generation(inode_item,\r\nBTRFS_I(inode)->generation);\r\nbtrfs_set_stack_inode_sequence(inode_item, inode->i_version);\r\nbtrfs_set_stack_inode_transid(inode_item, trans->transid);\r\nbtrfs_set_stack_inode_rdev(inode_item, inode->i_rdev);\r\nbtrfs_set_stack_inode_flags(inode_item, BTRFS_I(inode)->flags);\r\nbtrfs_set_stack_inode_block_group(inode_item, 0);\r\nbtrfs_set_stack_timespec_sec(&inode_item->atime,\r\ninode->i_atime.tv_sec);\r\nbtrfs_set_stack_timespec_nsec(&inode_item->atime,\r\ninode->i_atime.tv_nsec);\r\nbtrfs_set_stack_timespec_sec(&inode_item->mtime,\r\ninode->i_mtime.tv_sec);\r\nbtrfs_set_stack_timespec_nsec(&inode_item->mtime,\r\ninode->i_mtime.tv_nsec);\r\nbtrfs_set_stack_timespec_sec(&inode_item->ctime,\r\ninode->i_ctime.tv_sec);\r\nbtrfs_set_stack_timespec_nsec(&inode_item->ctime,\r\ninode->i_ctime.tv_nsec);\r\nbtrfs_set_stack_timespec_sec(&inode_item->otime,\r\nBTRFS_I(inode)->i_otime.tv_sec);\r\nbtrfs_set_stack_timespec_nsec(&inode_item->otime,\r\nBTRFS_I(inode)->i_otime.tv_nsec);\r\n}\r\nint btrfs_fill_inode(struct inode *inode, u32 *rdev)\r\n{\r\nstruct btrfs_delayed_node *delayed_node;\r\nstruct btrfs_inode_item *inode_item;\r\ndelayed_node = btrfs_get_delayed_node(inode);\r\nif (!delayed_node)\r\nreturn -ENOENT;\r\nmutex_lock(&delayed_node->mutex);\r\nif (!test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\r\nmutex_unlock(&delayed_node->mutex);\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn -ENOENT;\r\n}\r\ninode_item = &delayed_node->inode_item;\r\ni_uid_write(inode, btrfs_stack_inode_uid(inode_item));\r\ni_gid_write(inode, btrfs_stack_inode_gid(inode_item));\r\nbtrfs_i_size_write(inode, btrfs_stack_inode_size(inode_item));\r\ninode->i_mode = btrfs_stack_inode_mode(inode_item);\r\nset_nlink(inode, btrfs_stack_inode_nlink(inode_item));\r\ninode_set_bytes(inode, btrfs_stack_inode_nbytes(inode_item));\r\nBTRFS_I(inode)->generation = btrfs_stack_inode_generation(inode_item);\r\nBTRFS_I(inode)->last_trans = btrfs_stack_inode_transid(inode_item);\r\ninode->i_version = btrfs_stack_inode_sequence(inode_item);\r\ninode->i_rdev = 0;\r\n*rdev = btrfs_stack_inode_rdev(inode_item);\r\nBTRFS_I(inode)->flags = btrfs_stack_inode_flags(inode_item);\r\ninode->i_atime.tv_sec = btrfs_stack_timespec_sec(&inode_item->atime);\r\ninode->i_atime.tv_nsec = btrfs_stack_timespec_nsec(&inode_item->atime);\r\ninode->i_mtime.tv_sec = btrfs_stack_timespec_sec(&inode_item->mtime);\r\ninode->i_mtime.tv_nsec = btrfs_stack_timespec_nsec(&inode_item->mtime);\r\ninode->i_ctime.tv_sec = btrfs_stack_timespec_sec(&inode_item->ctime);\r\ninode->i_ctime.tv_nsec = btrfs_stack_timespec_nsec(&inode_item->ctime);\r\nBTRFS_I(inode)->i_otime.tv_sec =\r\nbtrfs_stack_timespec_sec(&inode_item->otime);\r\nBTRFS_I(inode)->i_otime.tv_nsec =\r\nbtrfs_stack_timespec_nsec(&inode_item->otime);\r\ninode->i_generation = BTRFS_I(inode)->generation;\r\nBTRFS_I(inode)->index_cnt = (u64)-1;\r\nmutex_unlock(&delayed_node->mutex);\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn 0;\r\n}\r\nint btrfs_delayed_update_inode(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, struct inode *inode)\r\n{\r\nstruct btrfs_delayed_node *delayed_node;\r\nint ret = 0;\r\ndelayed_node = btrfs_get_or_create_delayed_node(inode);\r\nif (IS_ERR(delayed_node))\r\nreturn PTR_ERR(delayed_node);\r\nmutex_lock(&delayed_node->mutex);\r\nif (test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\r\nfill_stack_inode_item(trans, &delayed_node->inode_item, inode);\r\ngoto release_node;\r\n}\r\nret = btrfs_delayed_inode_reserve_metadata(trans, root, inode,\r\ndelayed_node);\r\nif (ret)\r\ngoto release_node;\r\nfill_stack_inode_item(trans, &delayed_node->inode_item, inode);\r\nset_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags);\r\ndelayed_node->count++;\r\natomic_inc(&root->fs_info->delayed_root->items);\r\nrelease_node:\r\nmutex_unlock(&delayed_node->mutex);\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn ret;\r\n}\r\nint btrfs_delayed_delete_inode_ref(struct inode *inode)\r\n{\r\nstruct btrfs_delayed_node *delayed_node;\r\nif (BTRFS_I(inode)->root->fs_info->log_root_recovering)\r\nreturn -EAGAIN;\r\ndelayed_node = btrfs_get_or_create_delayed_node(inode);\r\nif (IS_ERR(delayed_node))\r\nreturn PTR_ERR(delayed_node);\r\nmutex_lock(&delayed_node->mutex);\r\nif (test_bit(BTRFS_DELAYED_NODE_DEL_IREF, &delayed_node->flags))\r\ngoto release_node;\r\nset_bit(BTRFS_DELAYED_NODE_DEL_IREF, &delayed_node->flags);\r\ndelayed_node->count++;\r\natomic_inc(&BTRFS_I(inode)->root->fs_info->delayed_root->items);\r\nrelease_node:\r\nmutex_unlock(&delayed_node->mutex);\r\nbtrfs_release_delayed_node(delayed_node);\r\nreturn 0;\r\n}\r\nstatic void __btrfs_kill_delayed_node(struct btrfs_delayed_node *delayed_node)\r\n{\r\nstruct btrfs_root *root = delayed_node->root;\r\nstruct btrfs_delayed_item *curr_item, *prev_item;\r\nmutex_lock(&delayed_node->mutex);\r\ncurr_item = __btrfs_first_delayed_insertion_item(delayed_node);\r\nwhile (curr_item) {\r\nbtrfs_delayed_item_release_metadata(root, curr_item);\r\nprev_item = curr_item;\r\ncurr_item = __btrfs_next_delayed_item(prev_item);\r\nbtrfs_release_delayed_item(prev_item);\r\n}\r\ncurr_item = __btrfs_first_delayed_deletion_item(delayed_node);\r\nwhile (curr_item) {\r\nbtrfs_delayed_item_release_metadata(root, curr_item);\r\nprev_item = curr_item;\r\ncurr_item = __btrfs_next_delayed_item(prev_item);\r\nbtrfs_release_delayed_item(prev_item);\r\n}\r\nif (test_bit(BTRFS_DELAYED_NODE_DEL_IREF, &delayed_node->flags))\r\nbtrfs_release_delayed_iref(delayed_node);\r\nif (test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\r\nbtrfs_delayed_inode_release_metadata(root, delayed_node);\r\nbtrfs_release_delayed_inode(delayed_node);\r\n}\r\nmutex_unlock(&delayed_node->mutex);\r\n}\r\nvoid btrfs_kill_delayed_inode_items(struct inode *inode)\r\n{\r\nstruct btrfs_delayed_node *delayed_node;\r\ndelayed_node = btrfs_get_delayed_node(inode);\r\nif (!delayed_node)\r\nreturn;\r\n__btrfs_kill_delayed_node(delayed_node);\r\nbtrfs_release_delayed_node(delayed_node);\r\n}\r\nvoid btrfs_kill_all_delayed_nodes(struct btrfs_root *root)\r\n{\r\nu64 inode_id = 0;\r\nstruct btrfs_delayed_node *delayed_nodes[8];\r\nint i, n;\r\nwhile (1) {\r\nspin_lock(&root->inode_lock);\r\nn = radix_tree_gang_lookup(&root->delayed_nodes_tree,\r\n(void **)delayed_nodes, inode_id,\r\nARRAY_SIZE(delayed_nodes));\r\nif (!n) {\r\nspin_unlock(&root->inode_lock);\r\nbreak;\r\n}\r\ninode_id = delayed_nodes[n - 1]->inode_id + 1;\r\nfor (i = 0; i < n; i++)\r\natomic_inc(&delayed_nodes[i]->refs);\r\nspin_unlock(&root->inode_lock);\r\nfor (i = 0; i < n; i++) {\r\n__btrfs_kill_delayed_node(delayed_nodes[i]);\r\nbtrfs_release_delayed_node(delayed_nodes[i]);\r\n}\r\n}\r\n}\r\nvoid btrfs_destroy_delayed_inodes(struct btrfs_root *root)\r\n{\r\nstruct btrfs_delayed_root *delayed_root;\r\nstruct btrfs_delayed_node *curr_node, *prev_node;\r\ndelayed_root = btrfs_get_delayed_root(root);\r\ncurr_node = btrfs_first_delayed_node(delayed_root);\r\nwhile (curr_node) {\r\n__btrfs_kill_delayed_node(curr_node);\r\nprev_node = curr_node;\r\ncurr_node = btrfs_next_delayed_node(curr_node);\r\nbtrfs_release_delayed_node(prev_node);\r\n}\r\n}
