unsigned int pasemi_read_iob_reg(unsigned int reg)\r\n{\r\nreturn in_le32(iob_regs+reg);\r\n}\r\nvoid pasemi_write_iob_reg(unsigned int reg, unsigned int val)\r\n{\r\nout_le32(iob_regs+reg, val);\r\n}\r\nunsigned int pasemi_read_mac_reg(int intf, unsigned int reg)\r\n{\r\nreturn in_le32(mac_regs[intf]+reg);\r\n}\r\nvoid pasemi_write_mac_reg(int intf, unsigned int reg, unsigned int val)\r\n{\r\nout_le32(mac_regs[intf]+reg, val);\r\n}\r\nunsigned int pasemi_read_dma_reg(unsigned int reg)\r\n{\r\nreturn in_le32(dma_regs+reg);\r\n}\r\nvoid pasemi_write_dma_reg(unsigned int reg, unsigned int val)\r\n{\r\nout_le32(dma_regs+reg, val);\r\n}\r\nstatic int pasemi_alloc_tx_chan(enum pasemi_dmachan_type type)\r\n{\r\nint bit;\r\nint start, limit;\r\nswitch (type & (TXCHAN_EVT0|TXCHAN_EVT1)) {\r\ncase TXCHAN_EVT0:\r\nstart = 0;\r\nlimit = 10;\r\nbreak;\r\ncase TXCHAN_EVT1:\r\nstart = 10;\r\nlimit = MAX_TXCH;\r\nbreak;\r\ndefault:\r\nstart = 0;\r\nlimit = MAX_TXCH;\r\nbreak;\r\n}\r\nretry:\r\nbit = find_next_bit(txch_free, MAX_TXCH, start);\r\nif (bit >= limit)\r\nreturn -ENOSPC;\r\nif (!test_and_clear_bit(bit, txch_free))\r\ngoto retry;\r\nreturn bit;\r\n}\r\nstatic void pasemi_free_tx_chan(int chan)\r\n{\r\nBUG_ON(test_bit(chan, txch_free));\r\nset_bit(chan, txch_free);\r\n}\r\nstatic int pasemi_alloc_rx_chan(void)\r\n{\r\nint bit;\r\nretry:\r\nbit = find_first_bit(rxch_free, MAX_RXCH);\r\nif (bit >= MAX_TXCH)\r\nreturn -ENOSPC;\r\nif (!test_and_clear_bit(bit, rxch_free))\r\ngoto retry;\r\nreturn bit;\r\n}\r\nstatic void pasemi_free_rx_chan(int chan)\r\n{\r\nBUG_ON(test_bit(chan, rxch_free));\r\nset_bit(chan, rxch_free);\r\n}\r\nvoid *pasemi_dma_alloc_chan(enum pasemi_dmachan_type type,\r\nint total_size, int offset)\r\n{\r\nvoid *buf;\r\nstruct pasemi_dmachan *chan;\r\nint chno;\r\nBUG_ON(total_size < sizeof(struct pasemi_dmachan));\r\nbuf = kzalloc(total_size, GFP_KERNEL);\r\nif (!buf)\r\nreturn NULL;\r\nchan = buf + offset;\r\nchan->priv = buf;\r\nswitch (type & (TXCHAN|RXCHAN)) {\r\ncase RXCHAN:\r\nchno = pasemi_alloc_rx_chan();\r\nchan->chno = chno;\r\nchan->irq = irq_create_mapping(NULL,\r\nbase_hw_irq + num_txch + chno);\r\nchan->status = &dma_status->rx_sta[chno];\r\nbreak;\r\ncase TXCHAN:\r\nchno = pasemi_alloc_tx_chan(type);\r\nchan->chno = chno;\r\nchan->irq = irq_create_mapping(NULL, base_hw_irq + chno);\r\nchan->status = &dma_status->tx_sta[chno];\r\nbreak;\r\n}\r\nchan->chan_type = type;\r\nreturn chan;\r\n}\r\nvoid pasemi_dma_free_chan(struct pasemi_dmachan *chan)\r\n{\r\nif (chan->ring_virt)\r\npasemi_dma_free_ring(chan);\r\nswitch (chan->chan_type & (RXCHAN|TXCHAN)) {\r\ncase RXCHAN:\r\npasemi_free_rx_chan(chan->chno);\r\nbreak;\r\ncase TXCHAN:\r\npasemi_free_tx_chan(chan->chno);\r\nbreak;\r\n}\r\nkfree(chan->priv);\r\n}\r\nint pasemi_dma_alloc_ring(struct pasemi_dmachan *chan, int ring_size)\r\n{\r\nBUG_ON(chan->ring_virt);\r\nchan->ring_size = ring_size;\r\nchan->ring_virt = dma_alloc_coherent(&dma_pdev->dev,\r\nring_size * sizeof(u64),\r\n&chan->ring_dma, GFP_KERNEL);\r\nif (!chan->ring_virt)\r\nreturn -ENOMEM;\r\nmemset(chan->ring_virt, 0, ring_size * sizeof(u64));\r\nreturn 0;\r\n}\r\nvoid pasemi_dma_free_ring(struct pasemi_dmachan *chan)\r\n{\r\nBUG_ON(!chan->ring_virt);\r\ndma_free_coherent(&dma_pdev->dev, chan->ring_size * sizeof(u64),\r\nchan->ring_virt, chan->ring_dma);\r\nchan->ring_virt = NULL;\r\nchan->ring_size = 0;\r\nchan->ring_dma = 0;\r\n}\r\nvoid pasemi_dma_start_chan(const struct pasemi_dmachan *chan, const u32 cmdsta)\r\n{\r\nif (chan->chan_type == RXCHAN)\r\npasemi_write_dma_reg(PAS_DMA_RXCHAN_CCMDSTA(chan->chno),\r\ncmdsta | PAS_DMA_RXCHAN_CCMDSTA_EN);\r\nelse\r\npasemi_write_dma_reg(PAS_DMA_TXCHAN_TCMDSTA(chan->chno),\r\ncmdsta | PAS_DMA_TXCHAN_TCMDSTA_EN);\r\n}\r\nint pasemi_dma_stop_chan(const struct pasemi_dmachan *chan)\r\n{\r\nint reg, retries;\r\nu32 sta;\r\nif (chan->chan_type == RXCHAN) {\r\nreg = PAS_DMA_RXCHAN_CCMDSTA(chan->chno);\r\npasemi_write_dma_reg(reg, PAS_DMA_RXCHAN_CCMDSTA_ST);\r\nfor (retries = 0; retries < MAX_RETRIES; retries++) {\r\nsta = pasemi_read_dma_reg(reg);\r\nif (!(sta & PAS_DMA_RXCHAN_CCMDSTA_ACT)) {\r\npasemi_write_dma_reg(reg, 0);\r\nreturn 1;\r\n}\r\ncond_resched();\r\n}\r\n} else {\r\nreg = PAS_DMA_TXCHAN_TCMDSTA(chan->chno);\r\npasemi_write_dma_reg(reg, PAS_DMA_TXCHAN_TCMDSTA_ST);\r\nfor (retries = 0; retries < MAX_RETRIES; retries++) {\r\nsta = pasemi_read_dma_reg(reg);\r\nif (!(sta & PAS_DMA_TXCHAN_TCMDSTA_ACT)) {\r\npasemi_write_dma_reg(reg, 0);\r\nreturn 1;\r\n}\r\ncond_resched();\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid *pasemi_dma_alloc_buf(struct pasemi_dmachan *chan, int size,\r\ndma_addr_t *handle)\r\n{\r\nreturn dma_alloc_coherent(&dma_pdev->dev, size, handle, GFP_KERNEL);\r\n}\r\nvoid pasemi_dma_free_buf(struct pasemi_dmachan *chan, int size,\r\ndma_addr_t *handle)\r\n{\r\ndma_free_coherent(&dma_pdev->dev, size, handle, GFP_KERNEL);\r\n}\r\nint pasemi_dma_alloc_flag(void)\r\n{\r\nint bit;\r\nretry:\r\nbit = find_next_bit(flags_free, MAX_FLAGS, 0);\r\nif (bit >= MAX_FLAGS)\r\nreturn -ENOSPC;\r\nif (!test_and_clear_bit(bit, flags_free))\r\ngoto retry;\r\nreturn bit;\r\n}\r\nvoid pasemi_dma_free_flag(int flag)\r\n{\r\nBUG_ON(test_bit(flag, flags_free));\r\nBUG_ON(flag >= MAX_FLAGS);\r\nset_bit(flag, flags_free);\r\n}\r\nvoid pasemi_dma_set_flag(int flag)\r\n{\r\nBUG_ON(flag >= MAX_FLAGS);\r\nif (flag < 32)\r\npasemi_write_dma_reg(PAS_DMA_TXF_SFLG0, 1 << flag);\r\nelse\r\npasemi_write_dma_reg(PAS_DMA_TXF_SFLG1, 1 << flag);\r\n}\r\nvoid pasemi_dma_clear_flag(int flag)\r\n{\r\nBUG_ON(flag >= MAX_FLAGS);\r\nif (flag < 32)\r\npasemi_write_dma_reg(PAS_DMA_TXF_CFLG0, 1 << flag);\r\nelse\r\npasemi_write_dma_reg(PAS_DMA_TXF_CFLG1, 1 << flag);\r\n}\r\nint pasemi_dma_alloc_fun(void)\r\n{\r\nint bit;\r\nretry:\r\nbit = find_next_bit(fun_free, MAX_FLAGS, 0);\r\nif (bit >= MAX_FLAGS)\r\nreturn -ENOSPC;\r\nif (!test_and_clear_bit(bit, fun_free))\r\ngoto retry;\r\nreturn bit;\r\n}\r\nvoid pasemi_dma_free_fun(int fun)\r\n{\r\nBUG_ON(test_bit(fun, fun_free));\r\nBUG_ON(fun >= MAX_FLAGS);\r\nset_bit(fun, fun_free);\r\n}\r\nstatic void *map_onedev(struct pci_dev *p, int index)\r\n{\r\nstruct device_node *dn;\r\nvoid __iomem *ret;\r\ndn = pci_device_to_OF_node(p);\r\nif (!dn)\r\ngoto fallback;\r\nret = of_iomap(dn, index);\r\nif (!ret)\r\ngoto fallback;\r\nreturn ret;\r\nfallback:\r\nreturn ioremap(0xe0000000 + (p->devfn << 12), 0x2000);\r\n}\r\nint pasemi_dma_init(void)\r\n{\r\nstatic DEFINE_SPINLOCK(init_lock);\r\nstruct pci_dev *iob_pdev;\r\nstruct pci_dev *pdev;\r\nstruct resource res;\r\nstruct device_node *dn;\r\nint i, intf, err = 0;\r\nunsigned long timeout;\r\nu32 tmp;\r\nif (!machine_is(pasemi))\r\nreturn -ENODEV;\r\nspin_lock(&init_lock);\r\nif (dma_pdev)\r\ngoto out;\r\niob_pdev = pci_get_device(PCI_VENDOR_ID_PASEMI, 0xa001, NULL);\r\nif (!iob_pdev) {\r\nBUG();\r\nprintk(KERN_WARNING "Can't find I/O Bridge\n");\r\nerr = -ENODEV;\r\ngoto out;\r\n}\r\niob_regs = map_onedev(iob_pdev, 0);\r\ndma_pdev = pci_get_device(PCI_VENDOR_ID_PASEMI, 0xa007, NULL);\r\nif (!dma_pdev) {\r\nBUG();\r\nprintk(KERN_WARNING "Can't find DMA controller\n");\r\nerr = -ENODEV;\r\ngoto out;\r\n}\r\ndma_regs = map_onedev(dma_pdev, 0);\r\nbase_hw_irq = virq_to_hw(dma_pdev->irq);\r\npci_read_config_dword(dma_pdev, PAS_DMA_CAP_TXCH, &tmp);\r\nnum_txch = (tmp & PAS_DMA_CAP_TXCH_TCHN_M) >> PAS_DMA_CAP_TXCH_TCHN_S;\r\npci_read_config_dword(dma_pdev, PAS_DMA_CAP_RXCH, &tmp);\r\nnum_rxch = (tmp & PAS_DMA_CAP_RXCH_RCHN_M) >> PAS_DMA_CAP_RXCH_RCHN_S;\r\nintf = 0;\r\nfor (pdev = pci_get_device(PCI_VENDOR_ID_PASEMI, 0xa006, NULL);\r\npdev;\r\npdev = pci_get_device(PCI_VENDOR_ID_PASEMI, 0xa006, pdev))\r\nmac_regs[intf++] = map_onedev(pdev, 0);\r\npci_dev_put(pdev);\r\nfor (pdev = pci_get_device(PCI_VENDOR_ID_PASEMI, 0xa005, NULL);\r\npdev;\r\npdev = pci_get_device(PCI_VENDOR_ID_PASEMI, 0xa005, pdev))\r\nmac_regs[intf++] = map_onedev(pdev, 0);\r\npci_dev_put(pdev);\r\ndn = pci_device_to_OF_node(iob_pdev);\r\nif (dn)\r\nerr = of_address_to_resource(dn, 1, &res);\r\nif (!dn || err) {\r\nres.start = 0xfd800000;\r\nres.end = res.start + 0x1000;\r\n}\r\ndma_status = __ioremap(res.start, resource_size(&res), 0);\r\npci_dev_put(iob_pdev);\r\nfor (i = 0; i < MAX_TXCH; i++)\r\n__set_bit(i, txch_free);\r\nfor (i = 0; i < MAX_RXCH; i++)\r\n__set_bit(i, rxch_free);\r\ntimeout = jiffies + HZ;\r\npasemi_write_dma_reg(PAS_DMA_COM_RXCMD, 0);\r\nwhile (pasemi_read_dma_reg(PAS_DMA_COM_RXSTA) & 1) {\r\nif (time_after(jiffies, timeout)) {\r\npr_warning("Warning: Could not disable RX section\n");\r\nbreak;\r\n}\r\n}\r\ntimeout = jiffies + HZ;\r\npasemi_write_dma_reg(PAS_DMA_COM_TXCMD, 0);\r\nwhile (pasemi_read_dma_reg(PAS_DMA_COM_TXSTA) & 1) {\r\nif (time_after(jiffies, timeout)) {\r\npr_warning("Warning: Could not disable TX section\n");\r\nbreak;\r\n}\r\n}\r\ntmp = pasemi_read_dma_reg(PAS_DMA_COM_CFG);\r\npasemi_write_dma_reg(PAS_DMA_COM_CFG, tmp | 0x18000000);\r\npasemi_write_dma_reg(PAS_DMA_COM_TXCMD, PAS_DMA_COM_TXCMD_EN);\r\npasemi_write_dma_reg(PAS_DMA_COM_RXCMD, PAS_DMA_COM_RXCMD_EN);\r\nfor (i = 0; i < MAX_FLAGS; i++)\r\n__set_bit(i, flags_free);\r\nfor (i = 0; i < MAX_FUN; i++)\r\n__set_bit(i, fun_free);\r\npasemi_write_dma_reg(PAS_DMA_TXF_CFLG0, 0xffffffff);\r\npasemi_write_dma_reg(PAS_DMA_TXF_CFLG1, 0xffffffff);\r\nprintk(KERN_INFO "PA Semi PWRficient DMA library initialized "\r\n"(%d tx, %d rx channels)\n", num_txch, num_rxch);\r\nout:\r\nspin_unlock(&init_lock);\r\nreturn err;\r\n}
