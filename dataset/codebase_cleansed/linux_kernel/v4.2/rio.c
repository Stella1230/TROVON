u16 rio_local_get_device_id(struct rio_mport *port)\r\n{\r\nu32 result;\r\nrio_local_read_config_32(port, RIO_DID_CSR, &result);\r\nreturn (RIO_GET_DID(port->sys_size, result));\r\n}\r\nint rio_add_device(struct rio_dev *rdev)\r\n{\r\nint err;\r\nerr = device_add(&rdev->dev);\r\nif (err)\r\nreturn err;\r\nspin_lock(&rio_global_list_lock);\r\nlist_add_tail(&rdev->global_list, &rio_devices);\r\nspin_unlock(&rio_global_list_lock);\r\nrio_create_sysfs_dev_files(rdev);\r\nreturn 0;\r\n}\r\nint rio_request_inb_mbox(struct rio_mport *mport,\r\nvoid *dev_id,\r\nint mbox,\r\nint entries,\r\nvoid (*minb) (struct rio_mport * mport, void *dev_id, int mbox,\r\nint slot))\r\n{\r\nint rc = -ENOSYS;\r\nstruct resource *res;\r\nif (mport->ops->open_inb_mbox == NULL)\r\ngoto out;\r\nres = kmalloc(sizeof(struct resource), GFP_KERNEL);\r\nif (res) {\r\nrio_init_mbox_res(res, mbox, mbox);\r\nif ((rc =\r\nrequest_resource(&mport->riores[RIO_INB_MBOX_RESOURCE],\r\nres)) < 0) {\r\nkfree(res);\r\ngoto out;\r\n}\r\nmport->inb_msg[mbox].res = res;\r\nmport->inb_msg[mbox].mcback = minb;\r\nrc = mport->ops->open_inb_mbox(mport, dev_id, mbox, entries);\r\n} else\r\nrc = -ENOMEM;\r\nout:\r\nreturn rc;\r\n}\r\nint rio_release_inb_mbox(struct rio_mport *mport, int mbox)\r\n{\r\nif (mport->ops->close_inb_mbox) {\r\nmport->ops->close_inb_mbox(mport, mbox);\r\nreturn release_resource(mport->inb_msg[mbox].res);\r\n} else\r\nreturn -ENOSYS;\r\n}\r\nint rio_request_outb_mbox(struct rio_mport *mport,\r\nvoid *dev_id,\r\nint mbox,\r\nint entries,\r\nvoid (*moutb) (struct rio_mport * mport, void *dev_id, int mbox, int slot))\r\n{\r\nint rc = -ENOSYS;\r\nstruct resource *res;\r\nif (mport->ops->open_outb_mbox == NULL)\r\ngoto out;\r\nres = kmalloc(sizeof(struct resource), GFP_KERNEL);\r\nif (res) {\r\nrio_init_mbox_res(res, mbox, mbox);\r\nif ((rc =\r\nrequest_resource(&mport->riores[RIO_OUTB_MBOX_RESOURCE],\r\nres)) < 0) {\r\nkfree(res);\r\ngoto out;\r\n}\r\nmport->outb_msg[mbox].res = res;\r\nmport->outb_msg[mbox].mcback = moutb;\r\nrc = mport->ops->open_outb_mbox(mport, dev_id, mbox, entries);\r\n} else\r\nrc = -ENOMEM;\r\nout:\r\nreturn rc;\r\n}\r\nint rio_release_outb_mbox(struct rio_mport *mport, int mbox)\r\n{\r\nif (mport->ops->close_outb_mbox) {\r\nmport->ops->close_outb_mbox(mport, mbox);\r\nreturn release_resource(mport->outb_msg[mbox].res);\r\n} else\r\nreturn -ENOSYS;\r\n}\r\nstatic int\r\nrio_setup_inb_dbell(struct rio_mport *mport, void *dev_id, struct resource *res,\r\nvoid (*dinb) (struct rio_mport * mport, void *dev_id, u16 src, u16 dst,\r\nu16 info))\r\n{\r\nint rc = 0;\r\nstruct rio_dbell *dbell;\r\nif (!(dbell = kmalloc(sizeof(struct rio_dbell), GFP_KERNEL))) {\r\nrc = -ENOMEM;\r\ngoto out;\r\n}\r\ndbell->res = res;\r\ndbell->dinb = dinb;\r\ndbell->dev_id = dev_id;\r\nlist_add_tail(&dbell->node, &mport->dbells);\r\nout:\r\nreturn rc;\r\n}\r\nint rio_request_inb_dbell(struct rio_mport *mport,\r\nvoid *dev_id,\r\nu16 start,\r\nu16 end,\r\nvoid (*dinb) (struct rio_mport * mport, void *dev_id, u16 src,\r\nu16 dst, u16 info))\r\n{\r\nint rc = 0;\r\nstruct resource *res = kmalloc(sizeof(struct resource), GFP_KERNEL);\r\nif (res) {\r\nrio_init_dbell_res(res, start, end);\r\nif ((rc =\r\nrequest_resource(&mport->riores[RIO_DOORBELL_RESOURCE],\r\nres)) < 0) {\r\nkfree(res);\r\ngoto out;\r\n}\r\nrc = rio_setup_inb_dbell(mport, dev_id, res, dinb);\r\n} else\r\nrc = -ENOMEM;\r\nout:\r\nreturn rc;\r\n}\r\nint rio_release_inb_dbell(struct rio_mport *mport, u16 start, u16 end)\r\n{\r\nint rc = 0, found = 0;\r\nstruct rio_dbell *dbell;\r\nlist_for_each_entry(dbell, &mport->dbells, node) {\r\nif ((dbell->res->start == start) && (dbell->res->end == end)) {\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nrc = -EINVAL;\r\ngoto out;\r\n}\r\nlist_del(&dbell->node);\r\nrc = release_resource(dbell->res);\r\nkfree(dbell);\r\nout:\r\nreturn rc;\r\n}\r\nstruct resource *rio_request_outb_dbell(struct rio_dev *rdev, u16 start,\r\nu16 end)\r\n{\r\nstruct resource *res = kmalloc(sizeof(struct resource), GFP_KERNEL);\r\nif (res) {\r\nrio_init_dbell_res(res, start, end);\r\nif (request_resource(&rdev->riores[RIO_DOORBELL_RESOURCE], res)\r\n< 0) {\r\nkfree(res);\r\nres = NULL;\r\n}\r\n}\r\nreturn res;\r\n}\r\nint rio_release_outb_dbell(struct rio_dev *rdev, struct resource *res)\r\n{\r\nint rc = release_resource(res);\r\nkfree(res);\r\nreturn rc;\r\n}\r\nint rio_request_inb_pwrite(struct rio_dev *rdev,\r\nint (*pwcback)(struct rio_dev *rdev, union rio_pw_msg *msg, int step))\r\n{\r\nint rc = 0;\r\nspin_lock(&rio_global_list_lock);\r\nif (rdev->pwcback != NULL)\r\nrc = -ENOMEM;\r\nelse\r\nrdev->pwcback = pwcback;\r\nspin_unlock(&rio_global_list_lock);\r\nreturn rc;\r\n}\r\nint rio_release_inb_pwrite(struct rio_dev *rdev)\r\n{\r\nint rc = -ENOMEM;\r\nspin_lock(&rio_global_list_lock);\r\nif (rdev->pwcback) {\r\nrdev->pwcback = NULL;\r\nrc = 0;\r\n}\r\nspin_unlock(&rio_global_list_lock);\r\nreturn rc;\r\n}\r\nint rio_map_inb_region(struct rio_mport *mport, dma_addr_t local,\r\nu64 rbase, u32 size, u32 rflags)\r\n{\r\nint rc = 0;\r\nunsigned long flags;\r\nif (!mport->ops->map_inb)\r\nreturn -1;\r\nspin_lock_irqsave(&rio_mmap_lock, flags);\r\nrc = mport->ops->map_inb(mport, local, rbase, size, rflags);\r\nspin_unlock_irqrestore(&rio_mmap_lock, flags);\r\nreturn rc;\r\n}\r\nvoid rio_unmap_inb_region(struct rio_mport *mport, dma_addr_t lstart)\r\n{\r\nunsigned long flags;\r\nif (!mport->ops->unmap_inb)\r\nreturn;\r\nspin_lock_irqsave(&rio_mmap_lock, flags);\r\nmport->ops->unmap_inb(mport, lstart);\r\nspin_unlock_irqrestore(&rio_mmap_lock, flags);\r\n}\r\nu32\r\nrio_mport_get_physefb(struct rio_mport *port, int local,\r\nu16 destid, u8 hopcount)\r\n{\r\nu32 ext_ftr_ptr;\r\nu32 ftr_header;\r\next_ftr_ptr = rio_mport_get_efb(port, local, destid, hopcount, 0);\r\nwhile (ext_ftr_ptr) {\r\nif (local)\r\nrio_local_read_config_32(port, ext_ftr_ptr,\r\n&ftr_header);\r\nelse\r\nrio_mport_read_config_32(port, destid, hopcount,\r\next_ftr_ptr, &ftr_header);\r\nftr_header = RIO_GET_BLOCK_ID(ftr_header);\r\nswitch (ftr_header) {\r\ncase RIO_EFB_SER_EP_ID_V13P:\r\ncase RIO_EFB_SER_EP_REC_ID_V13P:\r\ncase RIO_EFB_SER_EP_FREE_ID_V13P:\r\ncase RIO_EFB_SER_EP_ID:\r\ncase RIO_EFB_SER_EP_REC_ID:\r\ncase RIO_EFB_SER_EP_FREE_ID:\r\ncase RIO_EFB_SER_EP_FREC_ID:\r\nreturn ext_ftr_ptr;\r\ndefault:\r\nbreak;\r\n}\r\next_ftr_ptr = rio_mport_get_efb(port, local, destid,\r\nhopcount, ext_ftr_ptr);\r\n}\r\nreturn ext_ftr_ptr;\r\n}\r\nstruct rio_dev *rio_get_comptag(u32 comp_tag, struct rio_dev *from)\r\n{\r\nstruct list_head *n;\r\nstruct rio_dev *rdev;\r\nspin_lock(&rio_global_list_lock);\r\nn = from ? from->global_list.next : rio_devices.next;\r\nwhile (n && (n != &rio_devices)) {\r\nrdev = rio_dev_g(n);\r\nif (rdev->comp_tag == comp_tag)\r\ngoto exit;\r\nn = n->next;\r\n}\r\nrdev = NULL;\r\nexit:\r\nspin_unlock(&rio_global_list_lock);\r\nreturn rdev;\r\n}\r\nint rio_set_port_lockout(struct rio_dev *rdev, u32 pnum, int lock)\r\n{\r\nu32 regval;\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_CTL_CSR(pnum),\r\n&regval);\r\nif (lock)\r\nregval |= RIO_PORT_N_CTL_LOCKOUT;\r\nelse\r\nregval &= ~RIO_PORT_N_CTL_LOCKOUT;\r\nrio_write_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_CTL_CSR(pnum),\r\nregval);\r\nreturn 0;\r\n}\r\nint rio_enable_rx_tx_port(struct rio_mport *port,\r\nint local, u16 destid,\r\nu8 hopcount, u8 port_num)\r\n{\r\n#ifdef CONFIG_RAPIDIO_ENABLE_RX_TX_PORTS\r\nu32 regval;\r\nu32 ext_ftr_ptr;\r\npr_debug("rio_enable_rx_tx_port(local = %d, destid = %d, hopcount = "\r\n"%d, port_num = %d)\n", local, destid, hopcount, port_num);\r\next_ftr_ptr = rio_mport_get_physefb(port, local, destid, hopcount);\r\nif (local) {\r\nrio_local_read_config_32(port, ext_ftr_ptr +\r\nRIO_PORT_N_CTL_CSR(0),\r\n&regval);\r\n} else {\r\nif (rio_mport_read_config_32(port, destid, hopcount,\r\next_ftr_ptr + RIO_PORT_N_CTL_CSR(port_num), &regval) < 0)\r\nreturn -EIO;\r\n}\r\nif (regval & RIO_PORT_N_CTL_P_TYP_SER) {\r\nregval = regval | RIO_PORT_N_CTL_EN_RX_SER\r\n| RIO_PORT_N_CTL_EN_TX_SER;\r\n} else {\r\nregval = regval | RIO_PORT_N_CTL_EN_RX_PAR\r\n| RIO_PORT_N_CTL_EN_TX_PAR;\r\n}\r\nif (local) {\r\nrio_local_write_config_32(port, ext_ftr_ptr +\r\nRIO_PORT_N_CTL_CSR(0), regval);\r\n} else {\r\nif (rio_mport_write_config_32(port, destid, hopcount,\r\next_ftr_ptr + RIO_PORT_N_CTL_CSR(port_num), regval) < 0)\r\nreturn -EIO;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int\r\nrio_chk_dev_route(struct rio_dev *rdev, struct rio_dev **nrdev, int *npnum)\r\n{\r\nu32 result;\r\nint p_port, rc = -EIO;\r\nstruct rio_dev *prev = NULL;\r\nwhile (rdev->prev && (rdev->prev->pef & RIO_PEF_SWITCH)) {\r\nif (!rio_read_config_32(rdev->prev, RIO_DEV_ID_CAR, &result)) {\r\nprev = rdev->prev;\r\nbreak;\r\n}\r\nrdev = rdev->prev;\r\n}\r\nif (prev == NULL)\r\ngoto err_out;\r\np_port = prev->rswitch->route_table[rdev->destid];\r\nif (p_port != RIO_INVALID_ROUTE) {\r\npr_debug("RIO: link failed on [%s]-P%d\n",\r\nrio_name(prev), p_port);\r\n*nrdev = prev;\r\n*npnum = p_port;\r\nrc = 0;\r\n} else\r\npr_debug("RIO: failed to trace route to %s\n", rio_name(rdev));\r\nerr_out:\r\nreturn rc;\r\n}\r\nint\r\nrio_mport_chk_dev_access(struct rio_mport *mport, u16 destid, u8 hopcount)\r\n{\r\nint i = 0;\r\nu32 tmp;\r\nwhile (rio_mport_read_config_32(mport, destid, hopcount,\r\nRIO_DEV_ID_CAR, &tmp)) {\r\ni++;\r\nif (i == RIO_MAX_CHK_RETRY)\r\nreturn -EIO;\r\nmdelay(1);\r\n}\r\nreturn 0;\r\n}\r\nstatic int rio_chk_dev_access(struct rio_dev *rdev)\r\n{\r\nreturn rio_mport_chk_dev_access(rdev->net->hport,\r\nrdev->destid, rdev->hopcount);\r\n}\r\nstatic int\r\nrio_get_input_status(struct rio_dev *rdev, int pnum, u32 *lnkresp)\r\n{\r\nu32 regval;\r\nint checkcount;\r\nif (lnkresp) {\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_MNT_RSP_CSR(pnum),\r\n&regval);\r\nudelay(50);\r\n}\r\nrio_write_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_MNT_REQ_CSR(pnum),\r\nRIO_MNT_REQ_CMD_IS);\r\nif (lnkresp == NULL)\r\nreturn 0;\r\ncheckcount = 3;\r\nwhile (checkcount--) {\r\nudelay(50);\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_MNT_RSP_CSR(pnum),\r\n&regval);\r\nif (regval & RIO_PORT_N_MNT_RSP_RVAL) {\r\n*lnkresp = regval;\r\nreturn 0;\r\n}\r\n}\r\nreturn -EIO;\r\n}\r\nstatic int rio_clr_err_stopped(struct rio_dev *rdev, u32 pnum, u32 err_status)\r\n{\r\nstruct rio_dev *nextdev = rdev->rswitch->nextdev[pnum];\r\nu32 regval;\r\nu32 far_ackid, far_linkstat, near_ackid;\r\nif (err_status == 0)\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_ERR_STS_CSR(pnum),\r\n&err_status);\r\nif (err_status & RIO_PORT_N_ERR_STS_PW_OUT_ES) {\r\npr_debug("RIO_EM: servicing Output Error-Stopped state\n");\r\nif (rio_get_input_status(rdev, pnum, &regval)) {\r\npr_debug("RIO_EM: Input-status response timeout\n");\r\ngoto rd_err;\r\n}\r\npr_debug("RIO_EM: SP%d Input-status response=0x%08x\n",\r\npnum, regval);\r\nfar_ackid = (regval & RIO_PORT_N_MNT_RSP_ASTAT) >> 5;\r\nfar_linkstat = regval & RIO_PORT_N_MNT_RSP_LSTAT;\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_ACK_STS_CSR(pnum),\r\n&regval);\r\npr_debug("RIO_EM: SP%d_ACK_STS_CSR=0x%08x\n", pnum, regval);\r\nnear_ackid = (regval & RIO_PORT_N_ACK_INBOUND) >> 24;\r\npr_debug("RIO_EM: SP%d far_ackID=0x%02x far_linkstat=0x%02x" \\r\n" near_ackID=0x%02x\n",\r\npnum, far_ackid, far_linkstat, near_ackid);\r\nif ((far_ackid != ((regval & RIO_PORT_N_ACK_OUTSTAND) >> 8)) ||\r\n(far_ackid != (regval & RIO_PORT_N_ACK_OUTBOUND))) {\r\nrio_write_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_ACK_STS_CSR(pnum),\r\n(near_ackid << 24) |\r\n(far_ackid << 8) | far_ackid);\r\nfar_ackid++;\r\nif (nextdev)\r\nrio_write_config_32(nextdev,\r\nnextdev->phys_efptr +\r\nRIO_PORT_N_ACK_STS_CSR(RIO_GET_PORT_NUM(nextdev->swpinfo)),\r\n(far_ackid << 24) |\r\n(near_ackid << 8) | near_ackid);\r\nelse\r\npr_debug("RIO_EM: Invalid nextdev pointer (NULL)\n");\r\n}\r\nrd_err:\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_ERR_STS_CSR(pnum),\r\n&err_status);\r\npr_debug("RIO_EM: SP%d_ERR_STS_CSR=0x%08x\n", pnum, err_status);\r\n}\r\nif ((err_status & RIO_PORT_N_ERR_STS_PW_INP_ES) && nextdev) {\r\npr_debug("RIO_EM: servicing Input Error-Stopped state\n");\r\nrio_get_input_status(nextdev,\r\nRIO_GET_PORT_NUM(nextdev->swpinfo), NULL);\r\nudelay(50);\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_ERR_STS_CSR(pnum),\r\n&err_status);\r\npr_debug("RIO_EM: SP%d_ERR_STS_CSR=0x%08x\n", pnum, err_status);\r\n}\r\nreturn (err_status & (RIO_PORT_N_ERR_STS_PW_OUT_ES |\r\nRIO_PORT_N_ERR_STS_PW_INP_ES)) ? 1 : 0;\r\n}\r\nint rio_inb_pwrite_handler(union rio_pw_msg *pw_msg)\r\n{\r\nstruct rio_dev *rdev;\r\nu32 err_status, em_perrdet, em_ltlerrdet;\r\nint rc, portnum;\r\nrdev = rio_get_comptag((pw_msg->em.comptag & RIO_CTAG_UDEVID), NULL);\r\nif (rdev == NULL) {\r\npr_debug("RIO: %s No matching device for CTag 0x%08x\n",\r\n__func__, pw_msg->em.comptag);\r\nreturn -EIO;\r\n}\r\npr_debug("RIO: Port-Write message from %s\n", rio_name(rdev));\r\n#ifdef DEBUG_PW\r\n{\r\nu32 i;\r\nfor (i = 0; i < RIO_PW_MSG_SIZE/sizeof(u32);) {\r\npr_debug("0x%02x: %08x %08x %08x %08x\n",\r\ni*4, pw_msg->raw[i], pw_msg->raw[i + 1],\r\npw_msg->raw[i + 2], pw_msg->raw[i + 3]);\r\ni += 4;\r\n}\r\n}\r\n#endif\r\nif (rdev->pwcback != NULL) {\r\nrc = rdev->pwcback(rdev, pw_msg, 0);\r\nif (rc == 0)\r\nreturn 0;\r\n}\r\nportnum = pw_msg->em.is_port & 0xFF;\r\nif (rio_chk_dev_access(rdev)) {\r\npr_debug("RIO: device access failed - get link partner\n");\r\nif (rio_chk_dev_route(rdev, &rdev, &portnum)) {\r\npr_err("RIO: Route trace for %s failed\n",\r\nrio_name(rdev));\r\nreturn -EIO;\r\n}\r\npw_msg = NULL;\r\n}\r\nif (!(rdev->pef & RIO_PEF_SWITCH))\r\nreturn 0;\r\nif (rdev->phys_efptr == 0) {\r\npr_err("RIO_PW: Bad switch initialization for %s\n",\r\nrio_name(rdev));\r\nreturn 0;\r\n}\r\nif (rdev->rswitch->ops && rdev->rswitch->ops->em_handle)\r\nrdev->rswitch->ops->em_handle(rdev, portnum);\r\nrio_read_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_ERR_STS_CSR(portnum),\r\n&err_status);\r\npr_debug("RIO_PW: SP%d_ERR_STS_CSR=0x%08x\n", portnum, err_status);\r\nif (err_status & RIO_PORT_N_ERR_STS_PORT_OK) {\r\nif (!(rdev->rswitch->port_ok & (1 << portnum))) {\r\nrdev->rswitch->port_ok |= (1 << portnum);\r\nrio_set_port_lockout(rdev, portnum, 0);\r\npr_debug("RIO_PW: Device Insertion on [%s]-P%d\n",\r\nrio_name(rdev), portnum);\r\n}\r\nif (err_status & (RIO_PORT_N_ERR_STS_PW_OUT_ES |\r\nRIO_PORT_N_ERR_STS_PW_INP_ES)) {\r\nif (rio_clr_err_stopped(rdev, portnum, err_status))\r\nrio_clr_err_stopped(rdev, portnum, 0);\r\n}\r\n} else {\r\nif (rdev->rswitch->port_ok & (1 << portnum)) {\r\nrdev->rswitch->port_ok &= ~(1 << portnum);\r\nrio_set_port_lockout(rdev, portnum, 1);\r\nrio_write_config_32(rdev,\r\nrdev->phys_efptr +\r\nRIO_PORT_N_ACK_STS_CSR(portnum),\r\nRIO_PORT_N_ACK_CLEAR);\r\npr_debug("RIO_PW: Device Extraction on [%s]-P%d\n",\r\nrio_name(rdev), portnum);\r\n}\r\n}\r\nrio_read_config_32(rdev,\r\nrdev->em_efptr + RIO_EM_PN_ERR_DETECT(portnum), &em_perrdet);\r\nif (em_perrdet) {\r\npr_debug("RIO_PW: RIO_EM_P%d_ERR_DETECT=0x%08x\n",\r\nportnum, em_perrdet);\r\nrio_write_config_32(rdev,\r\nrdev->em_efptr + RIO_EM_PN_ERR_DETECT(portnum), 0);\r\n}\r\nrio_read_config_32(rdev,\r\nrdev->em_efptr + RIO_EM_LTL_ERR_DETECT, &em_ltlerrdet);\r\nif (em_ltlerrdet) {\r\npr_debug("RIO_PW: RIO_EM_LTL_ERR_DETECT=0x%08x\n",\r\nem_ltlerrdet);\r\nrio_write_config_32(rdev,\r\nrdev->em_efptr + RIO_EM_LTL_ERR_DETECT, 0);\r\n}\r\nrio_write_config_32(rdev,\r\nrdev->phys_efptr + RIO_PORT_N_ERR_STS_CSR(portnum),\r\nerr_status);\r\nreturn 0;\r\n}\r\nu32\r\nrio_mport_get_efb(struct rio_mport *port, int local, u16 destid,\r\nu8 hopcount, u32 from)\r\n{\r\nu32 reg_val;\r\nif (from == 0) {\r\nif (local)\r\nrio_local_read_config_32(port, RIO_ASM_INFO_CAR,\r\n&reg_val);\r\nelse\r\nrio_mport_read_config_32(port, destid, hopcount,\r\nRIO_ASM_INFO_CAR, &reg_val);\r\nreturn reg_val & RIO_EXT_FTR_PTR_MASK;\r\n} else {\r\nif (local)\r\nrio_local_read_config_32(port, from, &reg_val);\r\nelse\r\nrio_mport_read_config_32(port, destid, hopcount,\r\nfrom, &reg_val);\r\nreturn RIO_GET_BLOCK_ID(reg_val);\r\n}\r\n}\r\nu32\r\nrio_mport_get_feature(struct rio_mport * port, int local, u16 destid,\r\nu8 hopcount, int ftr)\r\n{\r\nu32 asm_info, ext_ftr_ptr, ftr_header;\r\nif (local)\r\nrio_local_read_config_32(port, RIO_ASM_INFO_CAR, &asm_info);\r\nelse\r\nrio_mport_read_config_32(port, destid, hopcount,\r\nRIO_ASM_INFO_CAR, &asm_info);\r\next_ftr_ptr = asm_info & RIO_EXT_FTR_PTR_MASK;\r\nwhile (ext_ftr_ptr) {\r\nif (local)\r\nrio_local_read_config_32(port, ext_ftr_ptr,\r\n&ftr_header);\r\nelse\r\nrio_mport_read_config_32(port, destid, hopcount,\r\next_ftr_ptr, &ftr_header);\r\nif (RIO_GET_BLOCK_ID(ftr_header) == ftr)\r\nreturn ext_ftr_ptr;\r\nif (!(ext_ftr_ptr = RIO_GET_BLOCK_PTR(ftr_header)))\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstruct rio_dev *rio_get_asm(u16 vid, u16 did,\r\nu16 asm_vid, u16 asm_did, struct rio_dev *from)\r\n{\r\nstruct list_head *n;\r\nstruct rio_dev *rdev;\r\nWARN_ON(in_interrupt());\r\nspin_lock(&rio_global_list_lock);\r\nn = from ? from->global_list.next : rio_devices.next;\r\nwhile (n && (n != &rio_devices)) {\r\nrdev = rio_dev_g(n);\r\nif ((vid == RIO_ANY_ID || rdev->vid == vid) &&\r\n(did == RIO_ANY_ID || rdev->did == did) &&\r\n(asm_vid == RIO_ANY_ID || rdev->asm_vid == asm_vid) &&\r\n(asm_did == RIO_ANY_ID || rdev->asm_did == asm_did))\r\ngoto exit;\r\nn = n->next;\r\n}\r\nrdev = NULL;\r\nexit:\r\nrio_dev_put(from);\r\nrdev = rio_dev_get(rdev);\r\nspin_unlock(&rio_global_list_lock);\r\nreturn rdev;\r\n}\r\nstruct rio_dev *rio_get_device(u16 vid, u16 did, struct rio_dev *from)\r\n{\r\nreturn rio_get_asm(vid, did, RIO_ANY_ID, RIO_ANY_ID, from);\r\n}\r\nstatic int\r\nrio_std_route_add_entry(struct rio_mport *mport, u16 destid, u8 hopcount,\r\nu16 table, u16 route_destid, u8 route_port)\r\n{\r\nif (table == RIO_GLOBAL_TABLE) {\r\nrio_mport_write_config_32(mport, destid, hopcount,\r\nRIO_STD_RTE_CONF_DESTID_SEL_CSR,\r\n(u32)route_destid);\r\nrio_mport_write_config_32(mport, destid, hopcount,\r\nRIO_STD_RTE_CONF_PORT_SEL_CSR,\r\n(u32)route_port);\r\n}\r\nudelay(10);\r\nreturn 0;\r\n}\r\nstatic int\r\nrio_std_route_get_entry(struct rio_mport *mport, u16 destid, u8 hopcount,\r\nu16 table, u16 route_destid, u8 *route_port)\r\n{\r\nu32 result;\r\nif (table == RIO_GLOBAL_TABLE) {\r\nrio_mport_write_config_32(mport, destid, hopcount,\r\nRIO_STD_RTE_CONF_DESTID_SEL_CSR, route_destid);\r\nrio_mport_read_config_32(mport, destid, hopcount,\r\nRIO_STD_RTE_CONF_PORT_SEL_CSR, &result);\r\n*route_port = (u8)result;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nrio_std_route_clr_table(struct rio_mport *mport, u16 destid, u8 hopcount,\r\nu16 table)\r\n{\r\nu32 max_destid = 0xff;\r\nu32 i, pef, id_inc = 1, ext_cfg = 0;\r\nu32 port_sel = RIO_INVALID_ROUTE;\r\nif (table == RIO_GLOBAL_TABLE) {\r\nrio_mport_read_config_32(mport, destid, hopcount,\r\nRIO_PEF_CAR, &pef);\r\nif (mport->sys_size) {\r\nrio_mport_read_config_32(mport, destid, hopcount,\r\nRIO_SWITCH_RT_LIMIT,\r\n&max_destid);\r\nmax_destid &= RIO_RT_MAX_DESTID;\r\n}\r\nif (pef & RIO_PEF_EXT_RT) {\r\next_cfg = 0x80000000;\r\nid_inc = 4;\r\nport_sel = (RIO_INVALID_ROUTE << 24) |\r\n(RIO_INVALID_ROUTE << 16) |\r\n(RIO_INVALID_ROUTE << 8) |\r\nRIO_INVALID_ROUTE;\r\n}\r\nfor (i = 0; i <= max_destid;) {\r\nrio_mport_write_config_32(mport, destid, hopcount,\r\nRIO_STD_RTE_CONF_DESTID_SEL_CSR,\r\next_cfg | i);\r\nrio_mport_write_config_32(mport, destid, hopcount,\r\nRIO_STD_RTE_CONF_PORT_SEL_CSR,\r\nport_sel);\r\ni += id_inc;\r\n}\r\n}\r\nudelay(10);\r\nreturn 0;\r\n}\r\nint rio_lock_device(struct rio_mport *port, u16 destid,\r\nu8 hopcount, int wait_ms)\r\n{\r\nu32 result;\r\nint tcnt = 0;\r\nrio_mport_write_config_32(port, destid, hopcount,\r\nRIO_HOST_DID_LOCK_CSR, port->host_deviceid);\r\nrio_mport_read_config_32(port, destid, hopcount,\r\nRIO_HOST_DID_LOCK_CSR, &result);\r\nwhile (result != port->host_deviceid) {\r\nif (wait_ms != 0 && tcnt == wait_ms) {\r\npr_debug("RIO: timeout when locking device %x:%x\n",\r\ndestid, hopcount);\r\nreturn -EINVAL;\r\n}\r\nmdelay(1);\r\ntcnt++;\r\nrio_mport_write_config_32(port, destid,\r\nhopcount,\r\nRIO_HOST_DID_LOCK_CSR,\r\nport->host_deviceid);\r\nrio_mport_read_config_32(port, destid,\r\nhopcount,\r\nRIO_HOST_DID_LOCK_CSR, &result);\r\n}\r\nreturn 0;\r\n}\r\nint rio_unlock_device(struct rio_mport *port, u16 destid, u8 hopcount)\r\n{\r\nu32 result;\r\nrio_mport_write_config_32(port, destid,\r\nhopcount,\r\nRIO_HOST_DID_LOCK_CSR,\r\nport->host_deviceid);\r\nrio_mport_read_config_32(port, destid, hopcount,\r\nRIO_HOST_DID_LOCK_CSR, &result);\r\nif ((result & 0xffff) != 0xffff) {\r\npr_debug("RIO: badness when releasing device lock %x:%x\n",\r\ndestid, hopcount);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint rio_route_add_entry(struct rio_dev *rdev,\r\nu16 table, u16 route_destid, u8 route_port, int lock)\r\n{\r\nint rc = -EINVAL;\r\nstruct rio_switch_ops *ops = rdev->rswitch->ops;\r\nif (lock) {\r\nrc = rio_lock_device(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, 1000);\r\nif (rc)\r\nreturn rc;\r\n}\r\nspin_lock(&rdev->rswitch->lock);\r\nif (ops == NULL || ops->add_entry == NULL) {\r\nrc = rio_std_route_add_entry(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, table,\r\nroute_destid, route_port);\r\n} else if (try_module_get(ops->owner)) {\r\nrc = ops->add_entry(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, table, route_destid,\r\nroute_port);\r\nmodule_put(ops->owner);\r\n}\r\nspin_unlock(&rdev->rswitch->lock);\r\nif (lock)\r\nrio_unlock_device(rdev->net->hport, rdev->destid,\r\nrdev->hopcount);\r\nreturn rc;\r\n}\r\nint rio_route_get_entry(struct rio_dev *rdev, u16 table,\r\nu16 route_destid, u8 *route_port, int lock)\r\n{\r\nint rc = -EINVAL;\r\nstruct rio_switch_ops *ops = rdev->rswitch->ops;\r\nif (lock) {\r\nrc = rio_lock_device(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, 1000);\r\nif (rc)\r\nreturn rc;\r\n}\r\nspin_lock(&rdev->rswitch->lock);\r\nif (ops == NULL || ops->get_entry == NULL) {\r\nrc = rio_std_route_get_entry(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, table,\r\nroute_destid, route_port);\r\n} else if (try_module_get(ops->owner)) {\r\nrc = ops->get_entry(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, table, route_destid,\r\nroute_port);\r\nmodule_put(ops->owner);\r\n}\r\nspin_unlock(&rdev->rswitch->lock);\r\nif (lock)\r\nrio_unlock_device(rdev->net->hport, rdev->destid,\r\nrdev->hopcount);\r\nreturn rc;\r\n}\r\nint rio_route_clr_table(struct rio_dev *rdev, u16 table, int lock)\r\n{\r\nint rc = -EINVAL;\r\nstruct rio_switch_ops *ops = rdev->rswitch->ops;\r\nif (lock) {\r\nrc = rio_lock_device(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, 1000);\r\nif (rc)\r\nreturn rc;\r\n}\r\nspin_lock(&rdev->rswitch->lock);\r\nif (ops == NULL || ops->clr_table == NULL) {\r\nrc = rio_std_route_clr_table(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, table);\r\n} else if (try_module_get(ops->owner)) {\r\nrc = ops->clr_table(rdev->net->hport, rdev->destid,\r\nrdev->hopcount, table);\r\nmodule_put(ops->owner);\r\n}\r\nspin_unlock(&rdev->rswitch->lock);\r\nif (lock)\r\nrio_unlock_device(rdev->net->hport, rdev->destid,\r\nrdev->hopcount);\r\nreturn rc;\r\n}\r\nstatic bool rio_chan_filter(struct dma_chan *chan, void *arg)\r\n{\r\nstruct rio_mport *mport = arg;\r\nreturn mport == container_of(chan->device, struct rio_mport, dma);\r\n}\r\nstruct dma_chan *rio_request_mport_dma(struct rio_mport *mport)\r\n{\r\ndma_cap_mask_t mask;\r\ndma_cap_zero(mask);\r\ndma_cap_set(DMA_SLAVE, mask);\r\nreturn dma_request_channel(mask, rio_chan_filter, mport);\r\n}\r\nstruct dma_chan *rio_request_dma(struct rio_dev *rdev)\r\n{\r\nreturn rio_request_mport_dma(rdev->net->hport);\r\n}\r\nvoid rio_release_dma(struct dma_chan *dchan)\r\n{\r\ndma_release_channel(dchan);\r\n}\r\nstruct dma_async_tx_descriptor *rio_dma_prep_xfer(struct dma_chan *dchan,\r\nu16 destid, struct rio_dma_data *data,\r\nenum dma_transfer_direction direction, unsigned long flags)\r\n{\r\nstruct rio_dma_ext rio_ext;\r\nif (dchan->device->device_prep_slave_sg == NULL) {\r\npr_err("%s: prep_rio_sg == NULL\n", __func__);\r\nreturn NULL;\r\n}\r\nrio_ext.destid = destid;\r\nrio_ext.rio_addr_u = data->rio_addr_u;\r\nrio_ext.rio_addr = data->rio_addr;\r\nrio_ext.wr_type = data->wr_type;\r\nreturn dmaengine_prep_rio_sg(dchan, data->sg, data->sg_len,\r\ndirection, flags, &rio_ext);\r\n}\r\nstruct dma_async_tx_descriptor *rio_dma_prep_slave_sg(struct rio_dev *rdev,\r\nstruct dma_chan *dchan, struct rio_dma_data *data,\r\nenum dma_transfer_direction direction, unsigned long flags)\r\n{\r\nreturn rio_dma_prep_xfer(dchan, rdev->destid, data, direction, flags);\r\n}\r\nstruct rio_mport *rio_find_mport(int mport_id)\r\n{\r\nstruct rio_mport *port;\r\nmutex_lock(&rio_mport_list_lock);\r\nlist_for_each_entry(port, &rio_mports, node) {\r\nif (port->id == mport_id)\r\ngoto found;\r\n}\r\nport = NULL;\r\nfound:\r\nmutex_unlock(&rio_mport_list_lock);\r\nreturn port;\r\n}\r\nint rio_register_scan(int mport_id, struct rio_scan *scan_ops)\r\n{\r\nstruct rio_mport *port;\r\nstruct rio_scan_node *scan;\r\nint rc = 0;\r\npr_debug("RIO: %s for mport_id=%d\n", __func__, mport_id);\r\nif ((mport_id != RIO_MPORT_ANY && mport_id >= RIO_MAX_MPORTS) ||\r\n!scan_ops)\r\nreturn -EINVAL;\r\nmutex_lock(&rio_mport_list_lock);\r\nlist_for_each_entry(scan, &rio_scans, node) {\r\nif (scan->mport_id == mport_id) {\r\nrc = -EBUSY;\r\ngoto err_out;\r\n}\r\n}\r\nscan = kzalloc(sizeof(*scan), GFP_KERNEL);\r\nif (!scan) {\r\nrc = -ENOMEM;\r\ngoto err_out;\r\n}\r\nscan->mport_id = mport_id;\r\nscan->ops = scan_ops;\r\nlist_for_each_entry(port, &rio_mports, node) {\r\nif (port->id == mport_id) {\r\nport->nscan = scan_ops;\r\nbreak;\r\n} else if (mport_id == RIO_MPORT_ANY && !port->nscan)\r\nport->nscan = scan_ops;\r\n}\r\nlist_add_tail(&scan->node, &rio_scans);\r\nerr_out:\r\nmutex_unlock(&rio_mport_list_lock);\r\nreturn rc;\r\n}\r\nint rio_unregister_scan(int mport_id, struct rio_scan *scan_ops)\r\n{\r\nstruct rio_mport *port;\r\nstruct rio_scan_node *scan;\r\npr_debug("RIO: %s for mport_id=%d\n", __func__, mport_id);\r\nif (mport_id != RIO_MPORT_ANY && mport_id >= RIO_MAX_MPORTS)\r\nreturn -EINVAL;\r\nmutex_lock(&rio_mport_list_lock);\r\nlist_for_each_entry(port, &rio_mports, node)\r\nif (port->id == mport_id ||\r\n(mport_id == RIO_MPORT_ANY && port->nscan == scan_ops))\r\nport->nscan = NULL;\r\nlist_for_each_entry(scan, &rio_scans, node) {\r\nif (scan->mport_id == mport_id) {\r\nlist_del(&scan->node);\r\nkfree(scan);\r\nbreak;\r\n}\r\n}\r\nmutex_unlock(&rio_mport_list_lock);\r\nreturn 0;\r\n}\r\nint rio_mport_scan(int mport_id)\r\n{\r\nstruct rio_mport *port = NULL;\r\nint rc;\r\nmutex_lock(&rio_mport_list_lock);\r\nlist_for_each_entry(port, &rio_mports, node) {\r\nif (port->id == mport_id)\r\ngoto found;\r\n}\r\nmutex_unlock(&rio_mport_list_lock);\r\nreturn -ENODEV;\r\nfound:\r\nif (!port->nscan) {\r\nmutex_unlock(&rio_mport_list_lock);\r\nreturn -EINVAL;\r\n}\r\nif (!try_module_get(port->nscan->owner)) {\r\nmutex_unlock(&rio_mport_list_lock);\r\nreturn -ENODEV;\r\n}\r\nmutex_unlock(&rio_mport_list_lock);\r\nif (port->host_deviceid >= 0)\r\nrc = port->nscan->enumerate(port, 0);\r\nelse\r\nrc = port->nscan->discover(port, RIO_SCAN_ENUM_NO_WAIT);\r\nmodule_put(port->nscan->owner);\r\nreturn rc;\r\n}\r\nstatic void rio_fixup_device(struct rio_dev *dev)\r\n{\r\n}\r\nstatic int rio_init(void)\r\n{\r\nstruct rio_dev *dev = NULL;\r\nwhile ((dev = rio_get_device(RIO_ANY_ID, RIO_ANY_ID, dev)) != NULL) {\r\nrio_fixup_device(dev);\r\n}\r\nreturn 0;\r\n}\r\nstatic void disc_work_handler(struct work_struct *_work)\r\n{\r\nstruct rio_disc_work *work;\r\nwork = container_of(_work, struct rio_disc_work, work);\r\npr_debug("RIO: discovery work for mport %d %s\n",\r\nwork->mport->id, work->mport->name);\r\nif (try_module_get(work->mport->nscan->owner)) {\r\nwork->mport->nscan->discover(work->mport, 0);\r\nmodule_put(work->mport->nscan->owner);\r\n}\r\n}\r\nint rio_init_mports(void)\r\n{\r\nstruct rio_mport *port;\r\nstruct rio_disc_work *work;\r\nint n = 0;\r\nif (!next_portid)\r\nreturn -ENODEV;\r\nmutex_lock(&rio_mport_list_lock);\r\nlist_for_each_entry(port, &rio_mports, node) {\r\nif (port->host_deviceid >= 0) {\r\nif (port->nscan && try_module_get(port->nscan->owner)) {\r\nport->nscan->enumerate(port, 0);\r\nmodule_put(port->nscan->owner);\r\n}\r\n} else\r\nn++;\r\n}\r\nmutex_unlock(&rio_mport_list_lock);\r\nif (!n)\r\ngoto no_disc;\r\nrio_wq = alloc_workqueue("riodisc", 0, 0);\r\nif (!rio_wq) {\r\npr_err("RIO: unable allocate rio_wq\n");\r\ngoto no_disc;\r\n}\r\nwork = kcalloc(n, sizeof *work, GFP_KERNEL);\r\nif (!work) {\r\npr_err("RIO: no memory for work struct\n");\r\ndestroy_workqueue(rio_wq);\r\ngoto no_disc;\r\n}\r\nn = 0;\r\nmutex_lock(&rio_mport_list_lock);\r\nlist_for_each_entry(port, &rio_mports, node) {\r\nif (port->host_deviceid < 0 && port->nscan) {\r\nwork[n].mport = port;\r\nINIT_WORK(&work[n].work, disc_work_handler);\r\nqueue_work(rio_wq, &work[n].work);\r\nn++;\r\n}\r\n}\r\nflush_workqueue(rio_wq);\r\nmutex_unlock(&rio_mport_list_lock);\r\npr_debug("RIO: destroy discovery workqueue\n");\r\ndestroy_workqueue(rio_wq);\r\nkfree(work);\r\nno_disc:\r\nrio_init();\r\nreturn 0;\r\n}\r\nstatic int rio_get_hdid(int index)\r\n{\r\nif (ids_num == 0 || ids_num <= index || index >= RIO_MAX_MPORTS)\r\nreturn -1;\r\nreturn hdid[index];\r\n}\r\nint rio_register_mport(struct rio_mport *port)\r\n{\r\nstruct rio_scan_node *scan = NULL;\r\nint res = 0;\r\nif (next_portid >= RIO_MAX_MPORTS) {\r\npr_err("RIO: reached specified max number of mports\n");\r\nreturn 1;\r\n}\r\nport->id = next_portid++;\r\nport->host_deviceid = rio_get_hdid(port->id);\r\nport->nscan = NULL;\r\ndev_set_name(&port->dev, "rapidio%d", port->id);\r\nport->dev.class = &rio_mport_class;\r\nres = device_register(&port->dev);\r\nif (res)\r\ndev_err(&port->dev, "RIO: mport%d registration failed ERR=%d\n",\r\nport->id, res);\r\nelse\r\ndev_dbg(&port->dev, "RIO: mport%d registered\n", port->id);\r\nmutex_lock(&rio_mport_list_lock);\r\nlist_add_tail(&port->node, &rio_mports);\r\nlist_for_each_entry(scan, &rio_scans, node) {\r\nif (port->id == scan->mport_id ||\r\nscan->mport_id == RIO_MPORT_ANY) {\r\nport->nscan = scan->ops;\r\nif (port->id == scan->mport_id)\r\nbreak;\r\n}\r\n}\r\nmutex_unlock(&rio_mport_list_lock);\r\npr_debug("RIO: %s %s id=%d\n", __func__, port->name, port->id);\r\nreturn 0;\r\n}
