static inline struct net *tm_net(struct tcp_metrics_block *tm)\r\n{\r\nreturn read_pnet(&tm->tcpm_net);\r\n}\r\nstatic bool tcp_metric_locked(struct tcp_metrics_block *tm,\r\nenum tcp_metric_index idx)\r\n{\r\nreturn tm->tcpm_lock & (1 << idx);\r\n}\r\nstatic u32 tcp_metric_get(struct tcp_metrics_block *tm,\r\nenum tcp_metric_index idx)\r\n{\r\nreturn tm->tcpm_vals[idx];\r\n}\r\nstatic void tcp_metric_set(struct tcp_metrics_block *tm,\r\nenum tcp_metric_index idx,\r\nu32 val)\r\n{\r\ntm->tcpm_vals[idx] = val;\r\n}\r\nstatic bool addr_same(const struct inetpeer_addr *a,\r\nconst struct inetpeer_addr *b)\r\n{\r\nif (a->family != b->family)\r\nreturn false;\r\nif (a->family == AF_INET)\r\nreturn a->addr.a4 == b->addr.a4;\r\nreturn ipv6_addr_equal(&a->addr.in6, &b->addr.in6);\r\n}\r\nstatic void tcpm_suck_dst(struct tcp_metrics_block *tm,\r\nconst struct dst_entry *dst,\r\nbool fastopen_clear)\r\n{\r\nu32 msval;\r\nu32 val;\r\ntm->tcpm_stamp = jiffies;\r\nval = 0;\r\nif (dst_metric_locked(dst, RTAX_RTT))\r\nval |= 1 << TCP_METRIC_RTT;\r\nif (dst_metric_locked(dst, RTAX_RTTVAR))\r\nval |= 1 << TCP_METRIC_RTTVAR;\r\nif (dst_metric_locked(dst, RTAX_SSTHRESH))\r\nval |= 1 << TCP_METRIC_SSTHRESH;\r\nif (dst_metric_locked(dst, RTAX_CWND))\r\nval |= 1 << TCP_METRIC_CWND;\r\nif (dst_metric_locked(dst, RTAX_REORDERING))\r\nval |= 1 << TCP_METRIC_REORDERING;\r\ntm->tcpm_lock = val;\r\nmsval = dst_metric_raw(dst, RTAX_RTT);\r\ntm->tcpm_vals[TCP_METRIC_RTT] = msval * USEC_PER_MSEC;\r\nmsval = dst_metric_raw(dst, RTAX_RTTVAR);\r\ntm->tcpm_vals[TCP_METRIC_RTTVAR] = msval * USEC_PER_MSEC;\r\ntm->tcpm_vals[TCP_METRIC_SSTHRESH] = dst_metric_raw(dst, RTAX_SSTHRESH);\r\ntm->tcpm_vals[TCP_METRIC_CWND] = dst_metric_raw(dst, RTAX_CWND);\r\ntm->tcpm_vals[TCP_METRIC_REORDERING] = dst_metric_raw(dst, RTAX_REORDERING);\r\ntm->tcpm_ts = 0;\r\ntm->tcpm_ts_stamp = 0;\r\nif (fastopen_clear) {\r\ntm->tcpm_fastopen.mss = 0;\r\ntm->tcpm_fastopen.syn_loss = 0;\r\ntm->tcpm_fastopen.try_exp = 0;\r\ntm->tcpm_fastopen.cookie.exp = false;\r\ntm->tcpm_fastopen.cookie.len = 0;\r\n}\r\n}\r\nstatic void tcpm_check_stamp(struct tcp_metrics_block *tm, struct dst_entry *dst)\r\n{\r\nif (tm && unlikely(time_after(jiffies, tm->tcpm_stamp + TCP_METRICS_TIMEOUT)))\r\ntcpm_suck_dst(tm, dst, false);\r\n}\r\nstatic struct tcp_metrics_block *tcpm_new(struct dst_entry *dst,\r\nstruct inetpeer_addr *saddr,\r\nstruct inetpeer_addr *daddr,\r\nunsigned int hash)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nstruct net *net;\r\nbool reclaim = false;\r\nspin_lock_bh(&tcp_metrics_lock);\r\nnet = dev_net(dst->dev);\r\ntm = __tcp_get_metrics(saddr, daddr, net, hash);\r\nif (tm == TCP_METRICS_RECLAIM_PTR) {\r\nreclaim = true;\r\ntm = NULL;\r\n}\r\nif (tm) {\r\ntcpm_check_stamp(tm, dst);\r\ngoto out_unlock;\r\n}\r\nif (unlikely(reclaim)) {\r\nstruct tcp_metrics_block *oldest;\r\noldest = deref_locked(tcp_metrics_hash[hash].chain);\r\nfor (tm = deref_locked(oldest->tcpm_next); tm;\r\ntm = deref_locked(tm->tcpm_next)) {\r\nif (time_before(tm->tcpm_stamp, oldest->tcpm_stamp))\r\noldest = tm;\r\n}\r\ntm = oldest;\r\n} else {\r\ntm = kmalloc(sizeof(*tm), GFP_ATOMIC);\r\nif (!tm)\r\ngoto out_unlock;\r\n}\r\nwrite_pnet(&tm->tcpm_net, net);\r\ntm->tcpm_saddr = *saddr;\r\ntm->tcpm_daddr = *daddr;\r\ntcpm_suck_dst(tm, dst, true);\r\nif (likely(!reclaim)) {\r\ntm->tcpm_next = tcp_metrics_hash[hash].chain;\r\nrcu_assign_pointer(tcp_metrics_hash[hash].chain, tm);\r\n}\r\nout_unlock:\r\nspin_unlock_bh(&tcp_metrics_lock);\r\nreturn tm;\r\n}\r\nstatic struct tcp_metrics_block *tcp_get_encode(struct tcp_metrics_block *tm, int depth)\r\n{\r\nif (tm)\r\nreturn tm;\r\nif (depth > TCP_METRICS_RECLAIM_DEPTH)\r\nreturn TCP_METRICS_RECLAIM_PTR;\r\nreturn NULL;\r\n}\r\nstatic struct tcp_metrics_block *__tcp_get_metrics(const struct inetpeer_addr *saddr,\r\nconst struct inetpeer_addr *daddr,\r\nstruct net *net, unsigned int hash)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nint depth = 0;\r\nfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;\r\ntm = rcu_dereference(tm->tcpm_next)) {\r\nif (addr_same(&tm->tcpm_saddr, saddr) &&\r\naddr_same(&tm->tcpm_daddr, daddr) &&\r\nnet_eq(tm_net(tm), net))\r\nbreak;\r\ndepth++;\r\n}\r\nreturn tcp_get_encode(tm, depth);\r\n}\r\nstatic struct tcp_metrics_block *__tcp_get_metrics_req(struct request_sock *req,\r\nstruct dst_entry *dst)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nstruct inetpeer_addr saddr, daddr;\r\nunsigned int hash;\r\nstruct net *net;\r\nsaddr.family = req->rsk_ops->family;\r\ndaddr.family = req->rsk_ops->family;\r\nswitch (daddr.family) {\r\ncase AF_INET:\r\nsaddr.addr.a4 = inet_rsk(req)->ir_loc_addr;\r\ndaddr.addr.a4 = inet_rsk(req)->ir_rmt_addr;\r\nhash = (__force unsigned int) daddr.addr.a4;\r\nbreak;\r\n#if IS_ENABLED(CONFIG_IPV6)\r\ncase AF_INET6:\r\nsaddr.addr.in6 = inet_rsk(req)->ir_v6_loc_addr;\r\ndaddr.addr.in6 = inet_rsk(req)->ir_v6_rmt_addr;\r\nhash = ipv6_addr_hash(&inet_rsk(req)->ir_v6_rmt_addr);\r\nbreak;\r\n#endif\r\ndefault:\r\nreturn NULL;\r\n}\r\nnet = dev_net(dst->dev);\r\nhash ^= net_hash_mix(net);\r\nhash = hash_32(hash, tcp_metrics_hash_log);\r\nfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;\r\ntm = rcu_dereference(tm->tcpm_next)) {\r\nif (addr_same(&tm->tcpm_saddr, &saddr) &&\r\naddr_same(&tm->tcpm_daddr, &daddr) &&\r\nnet_eq(tm_net(tm), net))\r\nbreak;\r\n}\r\ntcpm_check_stamp(tm, dst);\r\nreturn tm;\r\n}\r\nstatic struct tcp_metrics_block *__tcp_get_metrics_tw(struct inet_timewait_sock *tw)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nstruct inetpeer_addr saddr, daddr;\r\nunsigned int hash;\r\nstruct net *net;\r\nif (tw->tw_family == AF_INET) {\r\nsaddr.family = AF_INET;\r\nsaddr.addr.a4 = tw->tw_rcv_saddr;\r\ndaddr.family = AF_INET;\r\ndaddr.addr.a4 = tw->tw_daddr;\r\nhash = (__force unsigned int) daddr.addr.a4;\r\n}\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nelse if (tw->tw_family == AF_INET6) {\r\nif (ipv6_addr_v4mapped(&tw->tw_v6_daddr)) {\r\nsaddr.family = AF_INET;\r\nsaddr.addr.a4 = tw->tw_rcv_saddr;\r\ndaddr.family = AF_INET;\r\ndaddr.addr.a4 = tw->tw_daddr;\r\nhash = (__force unsigned int) daddr.addr.a4;\r\n} else {\r\nsaddr.family = AF_INET6;\r\nsaddr.addr.in6 = tw->tw_v6_rcv_saddr;\r\ndaddr.family = AF_INET6;\r\ndaddr.addr.in6 = tw->tw_v6_daddr;\r\nhash = ipv6_addr_hash(&tw->tw_v6_daddr);\r\n}\r\n}\r\n#endif\r\nelse\r\nreturn NULL;\r\nnet = twsk_net(tw);\r\nhash ^= net_hash_mix(net);\r\nhash = hash_32(hash, tcp_metrics_hash_log);\r\nfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;\r\ntm = rcu_dereference(tm->tcpm_next)) {\r\nif (addr_same(&tm->tcpm_saddr, &saddr) &&\r\naddr_same(&tm->tcpm_daddr, &daddr) &&\r\nnet_eq(tm_net(tm), net))\r\nbreak;\r\n}\r\nreturn tm;\r\n}\r\nstatic struct tcp_metrics_block *tcp_get_metrics(struct sock *sk,\r\nstruct dst_entry *dst,\r\nbool create)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nstruct inetpeer_addr saddr, daddr;\r\nunsigned int hash;\r\nstruct net *net;\r\nif (sk->sk_family == AF_INET) {\r\nsaddr.family = AF_INET;\r\nsaddr.addr.a4 = inet_sk(sk)->inet_saddr;\r\ndaddr.family = AF_INET;\r\ndaddr.addr.a4 = inet_sk(sk)->inet_daddr;\r\nhash = (__force unsigned int) daddr.addr.a4;\r\n}\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nelse if (sk->sk_family == AF_INET6) {\r\nif (ipv6_addr_v4mapped(&sk->sk_v6_daddr)) {\r\nsaddr.family = AF_INET;\r\nsaddr.addr.a4 = inet_sk(sk)->inet_saddr;\r\ndaddr.family = AF_INET;\r\ndaddr.addr.a4 = inet_sk(sk)->inet_daddr;\r\nhash = (__force unsigned int) daddr.addr.a4;\r\n} else {\r\nsaddr.family = AF_INET6;\r\nsaddr.addr.in6 = sk->sk_v6_rcv_saddr;\r\ndaddr.family = AF_INET6;\r\ndaddr.addr.in6 = sk->sk_v6_daddr;\r\nhash = ipv6_addr_hash(&sk->sk_v6_daddr);\r\n}\r\n}\r\n#endif\r\nelse\r\nreturn NULL;\r\nnet = dev_net(dst->dev);\r\nhash ^= net_hash_mix(net);\r\nhash = hash_32(hash, tcp_metrics_hash_log);\r\ntm = __tcp_get_metrics(&saddr, &daddr, net, hash);\r\nif (tm == TCP_METRICS_RECLAIM_PTR)\r\ntm = NULL;\r\nif (!tm && create)\r\ntm = tcpm_new(dst, &saddr, &daddr, hash);\r\nelse\r\ntcpm_check_stamp(tm, dst);\r\nreturn tm;\r\n}\r\nvoid tcp_update_metrics(struct sock *sk)\r\n{\r\nconst struct inet_connection_sock *icsk = inet_csk(sk);\r\nstruct dst_entry *dst = __sk_dst_get(sk);\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nstruct tcp_metrics_block *tm;\r\nunsigned long rtt;\r\nu32 val;\r\nint m;\r\nif (sysctl_tcp_nometrics_save || !dst)\r\nreturn;\r\nif (dst->flags & DST_HOST)\r\ndst_confirm(dst);\r\nrcu_read_lock();\r\nif (icsk->icsk_backoff || !tp->srtt_us) {\r\ntm = tcp_get_metrics(sk, dst, false);\r\nif (tm && !tcp_metric_locked(tm, TCP_METRIC_RTT))\r\ntcp_metric_set(tm, TCP_METRIC_RTT, 0);\r\ngoto out_unlock;\r\n} else\r\ntm = tcp_get_metrics(sk, dst, true);\r\nif (!tm)\r\ngoto out_unlock;\r\nrtt = tcp_metric_get(tm, TCP_METRIC_RTT);\r\nm = rtt - tp->srtt_us;\r\nif (!tcp_metric_locked(tm, TCP_METRIC_RTT)) {\r\nif (m <= 0)\r\nrtt = tp->srtt_us;\r\nelse\r\nrtt -= (m >> 3);\r\ntcp_metric_set(tm, TCP_METRIC_RTT, rtt);\r\n}\r\nif (!tcp_metric_locked(tm, TCP_METRIC_RTTVAR)) {\r\nunsigned long var;\r\nif (m < 0)\r\nm = -m;\r\nm >>= 1;\r\nif (m < tp->mdev_us)\r\nm = tp->mdev_us;\r\nvar = tcp_metric_get(tm, TCP_METRIC_RTTVAR);\r\nif (m >= var)\r\nvar = m;\r\nelse\r\nvar -= (var - m) >> 2;\r\ntcp_metric_set(tm, TCP_METRIC_RTTVAR, var);\r\n}\r\nif (tcp_in_initial_slowstart(tp)) {\r\nif (!tcp_metric_locked(tm, TCP_METRIC_SSTHRESH)) {\r\nval = tcp_metric_get(tm, TCP_METRIC_SSTHRESH);\r\nif (val && (tp->snd_cwnd >> 1) > val)\r\ntcp_metric_set(tm, TCP_METRIC_SSTHRESH,\r\ntp->snd_cwnd >> 1);\r\n}\r\nif (!tcp_metric_locked(tm, TCP_METRIC_CWND)) {\r\nval = tcp_metric_get(tm, TCP_METRIC_CWND);\r\nif (tp->snd_cwnd > val)\r\ntcp_metric_set(tm, TCP_METRIC_CWND,\r\ntp->snd_cwnd);\r\n}\r\n} else if (tp->snd_cwnd > tp->snd_ssthresh &&\r\nicsk->icsk_ca_state == TCP_CA_Open) {\r\nif (!tcp_metric_locked(tm, TCP_METRIC_SSTHRESH))\r\ntcp_metric_set(tm, TCP_METRIC_SSTHRESH,\r\nmax(tp->snd_cwnd >> 1, tp->snd_ssthresh));\r\nif (!tcp_metric_locked(tm, TCP_METRIC_CWND)) {\r\nval = tcp_metric_get(tm, TCP_METRIC_CWND);\r\ntcp_metric_set(tm, TCP_METRIC_CWND, (val + tp->snd_cwnd) >> 1);\r\n}\r\n} else {\r\nif (!tcp_metric_locked(tm, TCP_METRIC_CWND)) {\r\nval = tcp_metric_get(tm, TCP_METRIC_CWND);\r\ntcp_metric_set(tm, TCP_METRIC_CWND,\r\n(val + tp->snd_ssthresh) >> 1);\r\n}\r\nif (!tcp_metric_locked(tm, TCP_METRIC_SSTHRESH)) {\r\nval = tcp_metric_get(tm, TCP_METRIC_SSTHRESH);\r\nif (val && tp->snd_ssthresh > val)\r\ntcp_metric_set(tm, TCP_METRIC_SSTHRESH,\r\ntp->snd_ssthresh);\r\n}\r\nif (!tcp_metric_locked(tm, TCP_METRIC_REORDERING)) {\r\nval = tcp_metric_get(tm, TCP_METRIC_REORDERING);\r\nif (val < tp->reordering &&\r\ntp->reordering != sysctl_tcp_reordering)\r\ntcp_metric_set(tm, TCP_METRIC_REORDERING,\r\ntp->reordering);\r\n}\r\n}\r\ntm->tcpm_stamp = jiffies;\r\nout_unlock:\r\nrcu_read_unlock();\r\n}\r\nvoid tcp_init_metrics(struct sock *sk)\r\n{\r\nstruct dst_entry *dst = __sk_dst_get(sk);\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nstruct tcp_metrics_block *tm;\r\nu32 val, crtt = 0;\r\nif (!dst)\r\ngoto reset;\r\ndst_confirm(dst);\r\nrcu_read_lock();\r\ntm = tcp_get_metrics(sk, dst, true);\r\nif (!tm) {\r\nrcu_read_unlock();\r\ngoto reset;\r\n}\r\nif (tcp_metric_locked(tm, TCP_METRIC_CWND))\r\ntp->snd_cwnd_clamp = tcp_metric_get(tm, TCP_METRIC_CWND);\r\nval = tcp_metric_get(tm, TCP_METRIC_SSTHRESH);\r\nif (val) {\r\ntp->snd_ssthresh = val;\r\nif (tp->snd_ssthresh > tp->snd_cwnd_clamp)\r\ntp->snd_ssthresh = tp->snd_cwnd_clamp;\r\n} else {\r\ntp->snd_ssthresh = TCP_INFINITE_SSTHRESH;\r\n}\r\nval = tcp_metric_get(tm, TCP_METRIC_REORDERING);\r\nif (val && tp->reordering != val) {\r\ntcp_disable_fack(tp);\r\ntcp_disable_early_retrans(tp);\r\ntp->reordering = val;\r\n}\r\ncrtt = tcp_metric_get(tm, TCP_METRIC_RTT);\r\nrcu_read_unlock();\r\nreset:\r\nif (crtt > tp->srtt_us) {\r\ncrtt /= 8 * USEC_PER_MSEC;\r\ninet_csk(sk)->icsk_rto = crtt + max(2 * crtt, tcp_rto_min(sk));\r\n} else if (tp->srtt_us == 0) {\r\ntp->rttvar_us = jiffies_to_usecs(TCP_TIMEOUT_FALLBACK);\r\ntp->mdev_us = tp->mdev_max_us = tp->rttvar_us;\r\ninet_csk(sk)->icsk_rto = TCP_TIMEOUT_FALLBACK;\r\n}\r\nif (tp->total_retrans > 1)\r\ntp->snd_cwnd = 1;\r\nelse\r\ntp->snd_cwnd = tcp_init_cwnd(tp, dst);\r\ntp->snd_cwnd_stamp = tcp_time_stamp;\r\n}\r\nbool tcp_peer_is_proven(struct request_sock *req, struct dst_entry *dst,\r\nbool paws_check, bool timestamps)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nbool ret;\r\nif (!dst)\r\nreturn false;\r\nrcu_read_lock();\r\ntm = __tcp_get_metrics_req(req, dst);\r\nif (paws_check) {\r\nif (tm &&\r\n(u32)get_seconds() - tm->tcpm_ts_stamp < TCP_PAWS_MSL &&\r\n((s32)(tm->tcpm_ts - req->ts_recent) > TCP_PAWS_WINDOW ||\r\n!timestamps))\r\nret = false;\r\nelse\r\nret = true;\r\n} else {\r\nif (tm && tcp_metric_get(tm, TCP_METRIC_RTT) && tm->tcpm_ts_stamp)\r\nret = true;\r\nelse\r\nret = false;\r\n}\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nvoid tcp_fetch_timewait_stamp(struct sock *sk, struct dst_entry *dst)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nrcu_read_lock();\r\ntm = tcp_get_metrics(sk, dst, true);\r\nif (tm) {\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nif ((u32)get_seconds() - tm->tcpm_ts_stamp <= TCP_PAWS_MSL) {\r\ntp->rx_opt.ts_recent_stamp = tm->tcpm_ts_stamp;\r\ntp->rx_opt.ts_recent = tm->tcpm_ts;\r\n}\r\n}\r\nrcu_read_unlock();\r\n}\r\nbool tcp_remember_stamp(struct sock *sk)\r\n{\r\nstruct dst_entry *dst = __sk_dst_get(sk);\r\nbool ret = false;\r\nif (dst) {\r\nstruct tcp_metrics_block *tm;\r\nrcu_read_lock();\r\ntm = tcp_get_metrics(sk, dst, true);\r\nif (tm) {\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nif ((s32)(tm->tcpm_ts - tp->rx_opt.ts_recent) <= 0 ||\r\n((u32)get_seconds() - tm->tcpm_ts_stamp > TCP_PAWS_MSL &&\r\ntm->tcpm_ts_stamp <= (u32)tp->rx_opt.ts_recent_stamp)) {\r\ntm->tcpm_ts_stamp = (u32)tp->rx_opt.ts_recent_stamp;\r\ntm->tcpm_ts = tp->rx_opt.ts_recent;\r\n}\r\nret = true;\r\n}\r\nrcu_read_unlock();\r\n}\r\nreturn ret;\r\n}\r\nbool tcp_tw_remember_stamp(struct inet_timewait_sock *tw)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nbool ret = false;\r\nrcu_read_lock();\r\ntm = __tcp_get_metrics_tw(tw);\r\nif (tm) {\r\nconst struct tcp_timewait_sock *tcptw;\r\nstruct sock *sk = (struct sock *) tw;\r\ntcptw = tcp_twsk(sk);\r\nif ((s32)(tm->tcpm_ts - tcptw->tw_ts_recent) <= 0 ||\r\n((u32)get_seconds() - tm->tcpm_ts_stamp > TCP_PAWS_MSL &&\r\ntm->tcpm_ts_stamp <= (u32)tcptw->tw_ts_recent_stamp)) {\r\ntm->tcpm_ts_stamp = (u32)tcptw->tw_ts_recent_stamp;\r\ntm->tcpm_ts = tcptw->tw_ts_recent;\r\n}\r\nret = true;\r\n}\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nvoid tcp_fastopen_cache_get(struct sock *sk, u16 *mss,\r\nstruct tcp_fastopen_cookie *cookie,\r\nint *syn_loss, unsigned long *last_syn_loss)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nrcu_read_lock();\r\ntm = tcp_get_metrics(sk, __sk_dst_get(sk), false);\r\nif (tm) {\r\nstruct tcp_fastopen_metrics *tfom = &tm->tcpm_fastopen;\r\nunsigned int seq;\r\ndo {\r\nseq = read_seqbegin(&fastopen_seqlock);\r\nif (tfom->mss)\r\n*mss = tfom->mss;\r\n*cookie = tfom->cookie;\r\nif (cookie->len <= 0 && tfom->try_exp == 1)\r\ncookie->exp = true;\r\n*syn_loss = tfom->syn_loss;\r\n*last_syn_loss = *syn_loss ? tfom->last_syn_loss : 0;\r\n} while (read_seqretry(&fastopen_seqlock, seq));\r\n}\r\nrcu_read_unlock();\r\n}\r\nvoid tcp_fastopen_cache_set(struct sock *sk, u16 mss,\r\nstruct tcp_fastopen_cookie *cookie, bool syn_lost,\r\nu16 try_exp)\r\n{\r\nstruct dst_entry *dst = __sk_dst_get(sk);\r\nstruct tcp_metrics_block *tm;\r\nif (!dst)\r\nreturn;\r\nrcu_read_lock();\r\ntm = tcp_get_metrics(sk, dst, true);\r\nif (tm) {\r\nstruct tcp_fastopen_metrics *tfom = &tm->tcpm_fastopen;\r\nwrite_seqlock_bh(&fastopen_seqlock);\r\nif (mss)\r\ntfom->mss = mss;\r\nif (cookie && cookie->len > 0)\r\ntfom->cookie = *cookie;\r\nelse if (try_exp > tfom->try_exp &&\r\ntfom->cookie.len <= 0 && !tfom->cookie.exp)\r\ntfom->try_exp = try_exp;\r\nif (syn_lost) {\r\n++tfom->syn_loss;\r\ntfom->last_syn_loss = jiffies;\r\n} else\r\ntfom->syn_loss = 0;\r\nwrite_sequnlock_bh(&fastopen_seqlock);\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic int tcp_metrics_fill_info(struct sk_buff *msg,\r\nstruct tcp_metrics_block *tm)\r\n{\r\nstruct nlattr *nest;\r\nint i;\r\nswitch (tm->tcpm_daddr.family) {\r\ncase AF_INET:\r\nif (nla_put_in_addr(msg, TCP_METRICS_ATTR_ADDR_IPV4,\r\ntm->tcpm_daddr.addr.a4) < 0)\r\ngoto nla_put_failure;\r\nif (nla_put_in_addr(msg, TCP_METRICS_ATTR_SADDR_IPV4,\r\ntm->tcpm_saddr.addr.a4) < 0)\r\ngoto nla_put_failure;\r\nbreak;\r\ncase AF_INET6:\r\nif (nla_put_in6_addr(msg, TCP_METRICS_ATTR_ADDR_IPV6,\r\n&tm->tcpm_daddr.addr.in6) < 0)\r\ngoto nla_put_failure;\r\nif (nla_put_in6_addr(msg, TCP_METRICS_ATTR_SADDR_IPV6,\r\n&tm->tcpm_saddr.addr.in6) < 0)\r\ngoto nla_put_failure;\r\nbreak;\r\ndefault:\r\nreturn -EAFNOSUPPORT;\r\n}\r\nif (nla_put_msecs(msg, TCP_METRICS_ATTR_AGE,\r\njiffies - tm->tcpm_stamp) < 0)\r\ngoto nla_put_failure;\r\nif (tm->tcpm_ts_stamp) {\r\nif (nla_put_s32(msg, TCP_METRICS_ATTR_TW_TS_STAMP,\r\n(s32) (get_seconds() - tm->tcpm_ts_stamp)) < 0)\r\ngoto nla_put_failure;\r\nif (nla_put_u32(msg, TCP_METRICS_ATTR_TW_TSVAL,\r\ntm->tcpm_ts) < 0)\r\ngoto nla_put_failure;\r\n}\r\n{\r\nint n = 0;\r\nnest = nla_nest_start(msg, TCP_METRICS_ATTR_VALS);\r\nif (!nest)\r\ngoto nla_put_failure;\r\nfor (i = 0; i < TCP_METRIC_MAX_KERNEL + 1; i++) {\r\nu32 val = tm->tcpm_vals[i];\r\nif (!val)\r\ncontinue;\r\nif (i == TCP_METRIC_RTT) {\r\nif (nla_put_u32(msg, TCP_METRIC_RTT_US + 1,\r\nval) < 0)\r\ngoto nla_put_failure;\r\nn++;\r\nval = max(val / 1000, 1U);\r\n}\r\nif (i == TCP_METRIC_RTTVAR) {\r\nif (nla_put_u32(msg, TCP_METRIC_RTTVAR_US + 1,\r\nval) < 0)\r\ngoto nla_put_failure;\r\nn++;\r\nval = max(val / 1000, 1U);\r\n}\r\nif (nla_put_u32(msg, i + 1, val) < 0)\r\ngoto nla_put_failure;\r\nn++;\r\n}\r\nif (n)\r\nnla_nest_end(msg, nest);\r\nelse\r\nnla_nest_cancel(msg, nest);\r\n}\r\n{\r\nstruct tcp_fastopen_metrics tfom_copy[1], *tfom;\r\nunsigned int seq;\r\ndo {\r\nseq = read_seqbegin(&fastopen_seqlock);\r\ntfom_copy[0] = tm->tcpm_fastopen;\r\n} while (read_seqretry(&fastopen_seqlock, seq));\r\ntfom = tfom_copy;\r\nif (tfom->mss &&\r\nnla_put_u16(msg, TCP_METRICS_ATTR_FOPEN_MSS,\r\ntfom->mss) < 0)\r\ngoto nla_put_failure;\r\nif (tfom->syn_loss &&\r\n(nla_put_u16(msg, TCP_METRICS_ATTR_FOPEN_SYN_DROPS,\r\ntfom->syn_loss) < 0 ||\r\nnla_put_msecs(msg, TCP_METRICS_ATTR_FOPEN_SYN_DROP_TS,\r\njiffies - tfom->last_syn_loss) < 0))\r\ngoto nla_put_failure;\r\nif (tfom->cookie.len > 0 &&\r\nnla_put(msg, TCP_METRICS_ATTR_FOPEN_COOKIE,\r\ntfom->cookie.len, tfom->cookie.val) < 0)\r\ngoto nla_put_failure;\r\n}\r\nreturn 0;\r\nnla_put_failure:\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int tcp_metrics_dump_info(struct sk_buff *skb,\r\nstruct netlink_callback *cb,\r\nstruct tcp_metrics_block *tm)\r\n{\r\nvoid *hdr;\r\nhdr = genlmsg_put(skb, NETLINK_CB(cb->skb).portid, cb->nlh->nlmsg_seq,\r\n&tcp_metrics_nl_family, NLM_F_MULTI,\r\nTCP_METRICS_CMD_GET);\r\nif (!hdr)\r\nreturn -EMSGSIZE;\r\nif (tcp_metrics_fill_info(skb, tm) < 0)\r\ngoto nla_put_failure;\r\ngenlmsg_end(skb, hdr);\r\nreturn 0;\r\nnla_put_failure:\r\ngenlmsg_cancel(skb, hdr);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int tcp_metrics_nl_dump(struct sk_buff *skb,\r\nstruct netlink_callback *cb)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nunsigned int max_rows = 1U << tcp_metrics_hash_log;\r\nunsigned int row, s_row = cb->args[0];\r\nint s_col = cb->args[1], col = s_col;\r\nfor (row = s_row; row < max_rows; row++, s_col = 0) {\r\nstruct tcp_metrics_block *tm;\r\nstruct tcpm_hash_bucket *hb = tcp_metrics_hash + row;\r\nrcu_read_lock();\r\nfor (col = 0, tm = rcu_dereference(hb->chain); tm;\r\ntm = rcu_dereference(tm->tcpm_next), col++) {\r\nif (!net_eq(tm_net(tm), net))\r\ncontinue;\r\nif (col < s_col)\r\ncontinue;\r\nif (tcp_metrics_dump_info(skb, cb, tm) < 0) {\r\nrcu_read_unlock();\r\ngoto done;\r\n}\r\n}\r\nrcu_read_unlock();\r\n}\r\ndone:\r\ncb->args[0] = row;\r\ncb->args[1] = col;\r\nreturn skb->len;\r\n}\r\nstatic int __parse_nl_addr(struct genl_info *info, struct inetpeer_addr *addr,\r\nunsigned int *hash, int optional, int v4, int v6)\r\n{\r\nstruct nlattr *a;\r\na = info->attrs[v4];\r\nif (a) {\r\naddr->family = AF_INET;\r\naddr->addr.a4 = nla_get_in_addr(a);\r\nif (hash)\r\n*hash = (__force unsigned int) addr->addr.a4;\r\nreturn 0;\r\n}\r\na = info->attrs[v6];\r\nif (a) {\r\nif (nla_len(a) != sizeof(struct in6_addr))\r\nreturn -EINVAL;\r\naddr->family = AF_INET6;\r\naddr->addr.in6 = nla_get_in6_addr(a);\r\nif (hash)\r\n*hash = ipv6_addr_hash(&addr->addr.in6);\r\nreturn 0;\r\n}\r\nreturn optional ? 1 : -EAFNOSUPPORT;\r\n}\r\nstatic int parse_nl_addr(struct genl_info *info, struct inetpeer_addr *addr,\r\nunsigned int *hash, int optional)\r\n{\r\nreturn __parse_nl_addr(info, addr, hash, optional,\r\nTCP_METRICS_ATTR_ADDR_IPV4,\r\nTCP_METRICS_ATTR_ADDR_IPV6);\r\n}\r\nstatic int parse_nl_saddr(struct genl_info *info, struct inetpeer_addr *addr)\r\n{\r\nreturn __parse_nl_addr(info, addr, NULL, 0,\r\nTCP_METRICS_ATTR_SADDR_IPV4,\r\nTCP_METRICS_ATTR_SADDR_IPV6);\r\n}\r\nstatic int tcp_metrics_nl_cmd_get(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct tcp_metrics_block *tm;\r\nstruct inetpeer_addr saddr, daddr;\r\nunsigned int hash;\r\nstruct sk_buff *msg;\r\nstruct net *net = genl_info_net(info);\r\nvoid *reply;\r\nint ret;\r\nbool src = true;\r\nret = parse_nl_addr(info, &daddr, &hash, 0);\r\nif (ret < 0)\r\nreturn ret;\r\nret = parse_nl_saddr(info, &saddr);\r\nif (ret < 0)\r\nsrc = false;\r\nmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\r\nif (!msg)\r\nreturn -ENOMEM;\r\nreply = genlmsg_put_reply(msg, info, &tcp_metrics_nl_family, 0,\r\ninfo->genlhdr->cmd);\r\nif (!reply)\r\ngoto nla_put_failure;\r\nhash ^= net_hash_mix(net);\r\nhash = hash_32(hash, tcp_metrics_hash_log);\r\nret = -ESRCH;\r\nrcu_read_lock();\r\nfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;\r\ntm = rcu_dereference(tm->tcpm_next)) {\r\nif (addr_same(&tm->tcpm_daddr, &daddr) &&\r\n(!src || addr_same(&tm->tcpm_saddr, &saddr)) &&\r\nnet_eq(tm_net(tm), net)) {\r\nret = tcp_metrics_fill_info(msg, tm);\r\nbreak;\r\n}\r\n}\r\nrcu_read_unlock();\r\nif (ret < 0)\r\ngoto out_free;\r\ngenlmsg_end(msg, reply);\r\nreturn genlmsg_reply(msg, info);\r\nnla_put_failure:\r\nret = -EMSGSIZE;\r\nout_free:\r\nnlmsg_free(msg);\r\nreturn ret;\r\n}\r\nstatic void tcp_metrics_flush_all(struct net *net)\r\n{\r\nunsigned int max_rows = 1U << tcp_metrics_hash_log;\r\nstruct tcpm_hash_bucket *hb = tcp_metrics_hash;\r\nstruct tcp_metrics_block *tm;\r\nunsigned int row;\r\nfor (row = 0; row < max_rows; row++, hb++) {\r\nstruct tcp_metrics_block __rcu **pp;\r\nspin_lock_bh(&tcp_metrics_lock);\r\npp = &hb->chain;\r\nfor (tm = deref_locked(*pp); tm; tm = deref_locked(*pp)) {\r\nif (net_eq(tm_net(tm), net)) {\r\n*pp = tm->tcpm_next;\r\nkfree_rcu(tm, rcu_head);\r\n} else {\r\npp = &tm->tcpm_next;\r\n}\r\n}\r\nspin_unlock_bh(&tcp_metrics_lock);\r\n}\r\n}\r\nstatic int tcp_metrics_nl_cmd_del(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct tcpm_hash_bucket *hb;\r\nstruct tcp_metrics_block *tm;\r\nstruct tcp_metrics_block __rcu **pp;\r\nstruct inetpeer_addr saddr, daddr;\r\nunsigned int hash;\r\nstruct net *net = genl_info_net(info);\r\nint ret;\r\nbool src = true, found = false;\r\nret = parse_nl_addr(info, &daddr, &hash, 1);\r\nif (ret < 0)\r\nreturn ret;\r\nif (ret > 0) {\r\ntcp_metrics_flush_all(net);\r\nreturn 0;\r\n}\r\nret = parse_nl_saddr(info, &saddr);\r\nif (ret < 0)\r\nsrc = false;\r\nhash ^= net_hash_mix(net);\r\nhash = hash_32(hash, tcp_metrics_hash_log);\r\nhb = tcp_metrics_hash + hash;\r\npp = &hb->chain;\r\nspin_lock_bh(&tcp_metrics_lock);\r\nfor (tm = deref_locked(*pp); tm; tm = deref_locked(*pp)) {\r\nif (addr_same(&tm->tcpm_daddr, &daddr) &&\r\n(!src || addr_same(&tm->tcpm_saddr, &saddr)) &&\r\nnet_eq(tm_net(tm), net)) {\r\n*pp = tm->tcpm_next;\r\nkfree_rcu(tm, rcu_head);\r\nfound = true;\r\n} else {\r\npp = &tm->tcpm_next;\r\n}\r\n}\r\nspin_unlock_bh(&tcp_metrics_lock);\r\nif (!found)\r\nreturn -ESRCH;\r\nreturn 0;\r\n}\r\nstatic int __init set_tcpmhash_entries(char *str)\r\n{\r\nssize_t ret;\r\nif (!str)\r\nreturn 0;\r\nret = kstrtouint(str, 0, &tcpmhash_entries);\r\nif (ret)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic int __net_init tcp_net_metrics_init(struct net *net)\r\n{\r\nsize_t size;\r\nunsigned int slots;\r\nif (!net_eq(net, &init_net))\r\nreturn 0;\r\nslots = tcpmhash_entries;\r\nif (!slots) {\r\nif (totalram_pages >= 128 * 1024)\r\nslots = 16 * 1024;\r\nelse\r\nslots = 8 * 1024;\r\n}\r\ntcp_metrics_hash_log = order_base_2(slots);\r\nsize = sizeof(struct tcpm_hash_bucket) << tcp_metrics_hash_log;\r\ntcp_metrics_hash = kzalloc(size, GFP_KERNEL | __GFP_NOWARN);\r\nif (!tcp_metrics_hash)\r\ntcp_metrics_hash = vzalloc(size);\r\nif (!tcp_metrics_hash)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic void __net_exit tcp_net_metrics_exit(struct net *net)\r\n{\r\ntcp_metrics_flush_all(net);\r\n}\r\nvoid __init tcp_metrics_init(void)\r\n{\r\nint ret;\r\nret = register_pernet_subsys(&tcp_net_metrics_ops);\r\nif (ret < 0)\r\npanic("Could not allocate the tcp_metrics hash table\n");\r\nret = genl_register_family_with_ops(&tcp_metrics_nl_family,\r\ntcp_metrics_nl_ops);\r\nif (ret < 0)\r\npanic("Could not register tcp_metrics generic netlink\n");\r\n}
