static u32 calc_residency(struct drm_device *dev, const u32 reg)\r\n{\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nu64 raw_time;\r\nu64 units = 128ULL, div = 100000ULL, bias = 100ULL;\r\nu32 ret;\r\nif (!intel_enable_rc6(dev))\r\nreturn 0;\r\nintel_runtime_pm_get(dev_priv);\r\nif (IS_VALLEYVIEW(dev)) {\r\nu32 clk_reg, czcount_30ns;\r\nif (IS_CHERRYVIEW(dev))\r\nclk_reg = CHV_CLK_CTL1;\r\nelse\r\nclk_reg = VLV_CLK_CTL2;\r\nczcount_30ns = I915_READ(clk_reg) >> CLK_CTL2_CZCOUNT_30NS_SHIFT;\r\nif (!czcount_30ns) {\r\nWARN(!czcount_30ns, "bogus CZ count value");\r\nret = 0;\r\ngoto out;\r\n}\r\nunits = 0;\r\ndiv = 1000000ULL;\r\nif (IS_CHERRYVIEW(dev)) {\r\nif (czcount_30ns == 1) {\r\ndiv = 10000000ULL;\r\nunits = 3125ULL;\r\n} else {\r\nczcount_30ns += 1;\r\n}\r\n}\r\nif (units == 0)\r\nunits = DIV_ROUND_UP_ULL(30ULL * bias,\r\n(u64)czcount_30ns);\r\nif (I915_READ(VLV_COUNTER_CONTROL) & VLV_COUNT_RANGE_HIGH)\r\nunits <<= 8;\r\ndiv = div * bias;\r\n}\r\nraw_time = I915_READ(reg) * units;\r\nret = DIV_ROUND_UP_ULL(raw_time, div);\r\nout:\r\nintel_runtime_pm_put(dev_priv);\r\nreturn ret;\r\n}\r\nstatic ssize_t\r\nshow_rc6_mask(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *dminor = dev_to_drm_minor(kdev);\r\nreturn snprintf(buf, PAGE_SIZE, "%x\n", intel_enable_rc6(dminor->dev));\r\n}\r\nstatic ssize_t\r\nshow_rc6_ms(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *dminor = dev_get_drvdata(kdev);\r\nu32 rc6_residency = calc_residency(dminor->dev, GEN6_GT_GFX_RC6);\r\nreturn snprintf(buf, PAGE_SIZE, "%u\n", rc6_residency);\r\n}\r\nstatic ssize_t\r\nshow_rc6p_ms(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *dminor = dev_to_drm_minor(kdev);\r\nu32 rc6p_residency = calc_residency(dminor->dev, GEN6_GT_GFX_RC6p);\r\nreturn snprintf(buf, PAGE_SIZE, "%u\n", rc6p_residency);\r\n}\r\nstatic ssize_t\r\nshow_rc6pp_ms(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *dminor = dev_to_drm_minor(kdev);\r\nu32 rc6pp_residency = calc_residency(dminor->dev, GEN6_GT_GFX_RC6pp);\r\nreturn snprintf(buf, PAGE_SIZE, "%u\n", rc6pp_residency);\r\n}\r\nstatic ssize_t\r\nshow_media_rc6_ms(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *dminor = dev_get_drvdata(kdev);\r\nu32 rc6_residency = calc_residency(dminor->dev, VLV_GT_MEDIA_RC6);\r\nreturn snprintf(buf, PAGE_SIZE, "%u\n", rc6_residency);\r\n}\r\nstatic int l3_access_valid(struct drm_device *dev, loff_t offset)\r\n{\r\nif (!HAS_L3_DPF(dev))\r\nreturn -EPERM;\r\nif (offset % 4 != 0)\r\nreturn -EINVAL;\r\nif (offset >= GEN7_L3LOG_SIZE)\r\nreturn -ENXIO;\r\nreturn 0;\r\n}\r\nstatic ssize_t\r\ni915_l3_read(struct file *filp, struct kobject *kobj,\r\nstruct bin_attribute *attr, char *buf,\r\nloff_t offset, size_t count)\r\n{\r\nstruct device *dev = container_of(kobj, struct device, kobj);\r\nstruct drm_minor *dminor = dev_to_drm_minor(dev);\r\nstruct drm_device *drm_dev = dminor->dev;\r\nstruct drm_i915_private *dev_priv = drm_dev->dev_private;\r\nint slice = (int)(uintptr_t)attr->private;\r\nint ret;\r\ncount = round_down(count, 4);\r\nret = l3_access_valid(drm_dev, offset);\r\nif (ret)\r\nreturn ret;\r\ncount = min_t(size_t, GEN7_L3LOG_SIZE - offset, count);\r\nret = i915_mutex_lock_interruptible(drm_dev);\r\nif (ret)\r\nreturn ret;\r\nif (dev_priv->l3_parity.remap_info[slice])\r\nmemcpy(buf,\r\ndev_priv->l3_parity.remap_info[slice] + (offset/4),\r\ncount);\r\nelse\r\nmemset(buf, 0, count);\r\nmutex_unlock(&drm_dev->struct_mutex);\r\nreturn count;\r\n}\r\nstatic ssize_t\r\ni915_l3_write(struct file *filp, struct kobject *kobj,\r\nstruct bin_attribute *attr, char *buf,\r\nloff_t offset, size_t count)\r\n{\r\nstruct device *dev = container_of(kobj, struct device, kobj);\r\nstruct drm_minor *dminor = dev_to_drm_minor(dev);\r\nstruct drm_device *drm_dev = dminor->dev;\r\nstruct drm_i915_private *dev_priv = drm_dev->dev_private;\r\nstruct intel_context *ctx;\r\nu32 *temp = NULL;\r\nint slice = (int)(uintptr_t)attr->private;\r\nint ret;\r\nif (!HAS_HW_CONTEXTS(drm_dev))\r\nreturn -ENXIO;\r\nret = l3_access_valid(drm_dev, offset);\r\nif (ret)\r\nreturn ret;\r\nret = i915_mutex_lock_interruptible(drm_dev);\r\nif (ret)\r\nreturn ret;\r\nif (!dev_priv->l3_parity.remap_info[slice]) {\r\ntemp = kzalloc(GEN7_L3LOG_SIZE, GFP_KERNEL);\r\nif (!temp) {\r\nmutex_unlock(&drm_dev->struct_mutex);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nret = i915_gpu_idle(drm_dev);\r\nif (ret) {\r\nkfree(temp);\r\nmutex_unlock(&drm_dev->struct_mutex);\r\nreturn ret;\r\n}\r\nif (temp)\r\ndev_priv->l3_parity.remap_info[slice] = temp;\r\nmemcpy(dev_priv->l3_parity.remap_info[slice] + (offset/4), buf, count);\r\nlist_for_each_entry(ctx, &dev_priv->context_list, link)\r\nctx->remap_slice |= (1<<slice);\r\nmutex_unlock(&drm_dev->struct_mutex);\r\nreturn count;\r\n}\r\nstatic ssize_t gt_act_freq_mhz_show(struct device *kdev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nint ret;\r\nflush_delayed_work(&dev_priv->rps.delayed_resume_work);\r\nintel_runtime_pm_get(dev_priv);\r\nmutex_lock(&dev_priv->rps.hw_lock);\r\nif (IS_VALLEYVIEW(dev_priv->dev)) {\r\nu32 freq;\r\nfreq = vlv_punit_read(dev_priv, PUNIT_REG_GPU_FREQ_STS);\r\nret = intel_gpu_freq(dev_priv, (freq >> 8) & 0xff);\r\n} else {\r\nu32 rpstat = I915_READ(GEN6_RPSTAT1);\r\nif (IS_GEN9(dev_priv))\r\nret = (rpstat & GEN9_CAGF_MASK) >> GEN9_CAGF_SHIFT;\r\nelse if (IS_HASWELL(dev_priv) || IS_BROADWELL(dev_priv))\r\nret = (rpstat & HSW_CAGF_MASK) >> HSW_CAGF_SHIFT;\r\nelse\r\nret = (rpstat & GEN6_CAGF_MASK) >> GEN6_CAGF_SHIFT;\r\nret = intel_gpu_freq(dev_priv, ret);\r\n}\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nintel_runtime_pm_put(dev_priv);\r\nreturn snprintf(buf, PAGE_SIZE, "%d\n", ret);\r\n}\r\nstatic ssize_t gt_cur_freq_mhz_show(struct device *kdev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nint ret;\r\nflush_delayed_work(&dev_priv->rps.delayed_resume_work);\r\nintel_runtime_pm_get(dev_priv);\r\nmutex_lock(&dev_priv->rps.hw_lock);\r\nret = intel_gpu_freq(dev_priv, dev_priv->rps.cur_freq);\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nintel_runtime_pm_put(dev_priv);\r\nreturn snprintf(buf, PAGE_SIZE, "%d\n", ret);\r\n}\r\nstatic ssize_t vlv_rpe_freq_mhz_show(struct device *kdev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nreturn snprintf(buf, PAGE_SIZE,\r\n"%d\n",\r\nintel_gpu_freq(dev_priv, dev_priv->rps.efficient_freq));\r\n}\r\nstatic ssize_t gt_max_freq_mhz_show(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nint ret;\r\nflush_delayed_work(&dev_priv->rps.delayed_resume_work);\r\nmutex_lock(&dev_priv->rps.hw_lock);\r\nret = intel_gpu_freq(dev_priv, dev_priv->rps.max_freq_softlimit);\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nreturn snprintf(buf, PAGE_SIZE, "%d\n", ret);\r\n}\r\nstatic ssize_t gt_max_freq_mhz_store(struct device *kdev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nu32 val;\r\nssize_t ret;\r\nret = kstrtou32(buf, 0, &val);\r\nif (ret)\r\nreturn ret;\r\nflush_delayed_work(&dev_priv->rps.delayed_resume_work);\r\nmutex_lock(&dev_priv->rps.hw_lock);\r\nval = intel_freq_opcode(dev_priv, val);\r\nif (val < dev_priv->rps.min_freq ||\r\nval > dev_priv->rps.max_freq ||\r\nval < dev_priv->rps.min_freq_softlimit) {\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nreturn -EINVAL;\r\n}\r\nif (val > dev_priv->rps.rp0_freq)\r\nDRM_DEBUG("User requested overclocking to %d\n",\r\nintel_gpu_freq(dev_priv, val));\r\ndev_priv->rps.max_freq_softlimit = val;\r\nval = clamp_t(int, dev_priv->rps.cur_freq,\r\ndev_priv->rps.min_freq_softlimit,\r\ndev_priv->rps.max_freq_softlimit);\r\nintel_set_rps(dev, val);\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nreturn count;\r\n}\r\nstatic ssize_t gt_min_freq_mhz_show(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nint ret;\r\nflush_delayed_work(&dev_priv->rps.delayed_resume_work);\r\nmutex_lock(&dev_priv->rps.hw_lock);\r\nret = intel_gpu_freq(dev_priv, dev_priv->rps.min_freq_softlimit);\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nreturn snprintf(buf, PAGE_SIZE, "%d\n", ret);\r\n}\r\nstatic ssize_t gt_min_freq_mhz_store(struct device *kdev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nu32 val;\r\nssize_t ret;\r\nret = kstrtou32(buf, 0, &val);\r\nif (ret)\r\nreturn ret;\r\nflush_delayed_work(&dev_priv->rps.delayed_resume_work);\r\nmutex_lock(&dev_priv->rps.hw_lock);\r\nval = intel_freq_opcode(dev_priv, val);\r\nif (val < dev_priv->rps.min_freq ||\r\nval > dev_priv->rps.max_freq ||\r\nval > dev_priv->rps.max_freq_softlimit) {\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nreturn -EINVAL;\r\n}\r\ndev_priv->rps.min_freq_softlimit = val;\r\nval = clamp_t(int, dev_priv->rps.cur_freq,\r\ndev_priv->rps.min_freq_softlimit,\r\ndev_priv->rps.max_freq_softlimit);\r\nintel_set_rps(dev, val);\r\nmutex_unlock(&dev_priv->rps.hw_lock);\r\nreturn count;\r\n}\r\nstatic ssize_t gt_rp_mhz_show(struct device *kdev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct drm_i915_private *dev_priv = dev->dev_private;\r\nu32 val;\r\nif (attr == &dev_attr_gt_RP0_freq_mhz)\r\nval = intel_gpu_freq(dev_priv, dev_priv->rps.rp0_freq);\r\nelse if (attr == &dev_attr_gt_RP1_freq_mhz)\r\nval = intel_gpu_freq(dev_priv, dev_priv->rps.rp1_freq);\r\nelse if (attr == &dev_attr_gt_RPn_freq_mhz)\r\nval = intel_gpu_freq(dev_priv, dev_priv->rps.min_freq);\r\nelse\r\nBUG();\r\nreturn snprintf(buf, PAGE_SIZE, "%d\n", val);\r\n}\r\nstatic ssize_t error_state_read(struct file *filp, struct kobject *kobj,\r\nstruct bin_attribute *attr, char *buf,\r\nloff_t off, size_t count)\r\n{\r\nstruct device *kdev = container_of(kobj, struct device, kobj);\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nstruct i915_error_state_file_priv error_priv;\r\nstruct drm_i915_error_state_buf error_str;\r\nssize_t ret_count = 0;\r\nint ret;\r\nmemset(&error_priv, 0, sizeof(error_priv));\r\nret = i915_error_state_buf_init(&error_str, to_i915(dev), count, off);\r\nif (ret)\r\nreturn ret;\r\nerror_priv.dev = dev;\r\ni915_error_state_get(dev, &error_priv);\r\nret = i915_error_state_to_str(&error_str, &error_priv);\r\nif (ret)\r\ngoto out;\r\nret_count = count < error_str.bytes ? count : error_str.bytes;\r\nmemcpy(buf, error_str.buf, ret_count);\r\nout:\r\ni915_error_state_put(&error_priv);\r\ni915_error_state_buf_release(&error_str);\r\nreturn ret ?: ret_count;\r\n}\r\nstatic ssize_t error_state_write(struct file *file, struct kobject *kobj,\r\nstruct bin_attribute *attr, char *buf,\r\nloff_t off, size_t count)\r\n{\r\nstruct device *kdev = container_of(kobj, struct device, kobj);\r\nstruct drm_minor *minor = dev_to_drm_minor(kdev);\r\nstruct drm_device *dev = minor->dev;\r\nint ret;\r\nDRM_DEBUG_DRIVER("Resetting error state\n");\r\nret = mutex_lock_interruptible(&dev->struct_mutex);\r\nif (ret)\r\nreturn ret;\r\ni915_destroy_error_state(dev);\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn count;\r\n}\r\nvoid i915_setup_sysfs(struct drm_device *dev)\r\n{\r\nint ret;\r\n#ifdef CONFIG_PM\r\nif (HAS_RC6(dev)) {\r\nret = sysfs_merge_group(&dev->primary->kdev->kobj,\r\n&rc6_attr_group);\r\nif (ret)\r\nDRM_ERROR("RC6 residency sysfs setup failed\n");\r\n}\r\nif (HAS_RC6p(dev)) {\r\nret = sysfs_merge_group(&dev->primary->kdev->kobj,\r\n&rc6p_attr_group);\r\nif (ret)\r\nDRM_ERROR("RC6p residency sysfs setup failed\n");\r\n}\r\nif (IS_VALLEYVIEW(dev)) {\r\nret = sysfs_merge_group(&dev->primary->kdev->kobj,\r\n&media_rc6_attr_group);\r\nif (ret)\r\nDRM_ERROR("Media RC6 residency sysfs setup failed\n");\r\n}\r\n#endif\r\nif (HAS_L3_DPF(dev)) {\r\nret = device_create_bin_file(dev->primary->kdev, &dpf_attrs);\r\nif (ret)\r\nDRM_ERROR("l3 parity sysfs setup failed\n");\r\nif (NUM_L3_SLICES(dev) > 1) {\r\nret = device_create_bin_file(dev->primary->kdev,\r\n&dpf_attrs_1);\r\nif (ret)\r\nDRM_ERROR("l3 parity slice 1 setup failed\n");\r\n}\r\n}\r\nret = 0;\r\nif (IS_VALLEYVIEW(dev))\r\nret = sysfs_create_files(&dev->primary->kdev->kobj, vlv_attrs);\r\nelse if (INTEL_INFO(dev)->gen >= 6)\r\nret = sysfs_create_files(&dev->primary->kdev->kobj, gen6_attrs);\r\nif (ret)\r\nDRM_ERROR("RPS sysfs setup failed\n");\r\nret = sysfs_create_bin_file(&dev->primary->kdev->kobj,\r\n&error_state_attr);\r\nif (ret)\r\nDRM_ERROR("error_state sysfs setup failed\n");\r\n}\r\nvoid i915_teardown_sysfs(struct drm_device *dev)\r\n{\r\nsysfs_remove_bin_file(&dev->primary->kdev->kobj, &error_state_attr);\r\nif (IS_VALLEYVIEW(dev))\r\nsysfs_remove_files(&dev->primary->kdev->kobj, vlv_attrs);\r\nelse\r\nsysfs_remove_files(&dev->primary->kdev->kobj, gen6_attrs);\r\ndevice_remove_bin_file(dev->primary->kdev, &dpf_attrs_1);\r\ndevice_remove_bin_file(dev->primary->kdev, &dpf_attrs);\r\n#ifdef CONFIG_PM\r\nsysfs_unmerge_group(&dev->primary->kdev->kobj, &rc6_attr_group);\r\nsysfs_unmerge_group(&dev->primary->kdev->kobj, &rc6p_attr_group);\r\n#endif\r\n}
