static inline u64 get_vtimer(void)\r\n{\r\nu64 timer;\r\nasm volatile("stpt %0" : "=m" (timer));\r\nreturn timer;\r\n}\r\nstatic inline void set_vtimer(u64 expires)\r\n{\r\nu64 timer;\r\nasm volatile(\r\n" stpt %0\n"\r\n" spt %1"\r\n: "=m" (timer) : "m" (expires));\r\nS390_lowcore.system_timer += S390_lowcore.last_update_timer - timer;\r\nS390_lowcore.last_update_timer = expires;\r\n}\r\nstatic inline int virt_timer_forward(u64 elapsed)\r\n{\r\nBUG_ON(!irqs_disabled());\r\nif (list_empty(&virt_timer_list))\r\nreturn 0;\r\nelapsed = atomic64_add_return(elapsed, &virt_timer_elapsed);\r\nreturn elapsed >= atomic64_read(&virt_timer_current);\r\n}\r\nstatic int do_account_vtime(struct task_struct *tsk, int hardirq_offset)\r\n{\r\nstruct thread_info *ti = task_thread_info(tsk);\r\nu64 timer, clock, user, system, steal;\r\nu64 user_scaled, system_scaled;\r\nint i;\r\ntimer = S390_lowcore.last_update_timer;\r\nclock = S390_lowcore.last_update_clock;\r\nasm volatile(\r\n" stpt %0\n"\r\n#ifdef CONFIG_HAVE_MARCH_Z9_109_FEATURES\r\n" stckf %1"\r\n#else\r\n" stck %1"\r\n#endif\r\n: "=m" (S390_lowcore.last_update_timer),\r\n"=m" (S390_lowcore.last_update_clock));\r\nS390_lowcore.system_timer += timer - S390_lowcore.last_update_timer;\r\nS390_lowcore.steal_timer += S390_lowcore.last_update_clock - clock;\r\nif (smp_cpu_mtid) {\r\nu64 cycles_new[32], *cycles_old;\r\nu64 delta, mult, div;\r\ncycles_old = this_cpu_ptr(mt_cycles);\r\nif (stcctm5(smp_cpu_mtid + 1, cycles_new) < 2) {\r\nmult = div = 0;\r\nfor (i = 0; i <= smp_cpu_mtid; i++) {\r\ndelta = cycles_new[i] - cycles_old[i];\r\nmult += delta;\r\ndiv += (i + 1) * delta;\r\n}\r\nif (mult > 0) {\r\n__this_cpu_write(mt_scaling_mult, mult);\r\n__this_cpu_write(mt_scaling_div, div);\r\nmemcpy(cycles_old, cycles_new,\r\nsizeof(u64) * (smp_cpu_mtid + 1));\r\n}\r\n}\r\n}\r\nuser = S390_lowcore.user_timer - ti->user_timer;\r\nS390_lowcore.steal_timer -= user;\r\nti->user_timer = S390_lowcore.user_timer;\r\nsystem = S390_lowcore.system_timer - ti->system_timer;\r\nS390_lowcore.steal_timer -= system;\r\nti->system_timer = S390_lowcore.system_timer;\r\nuser_scaled = user;\r\nsystem_scaled = system;\r\nif (smp_cpu_mtid) {\r\nu64 mult = __this_cpu_read(mt_scaling_mult);\r\nu64 div = __this_cpu_read(mt_scaling_div);\r\nuser_scaled = (user_scaled * mult) / div;\r\nsystem_scaled = (system_scaled * mult) / div;\r\n}\r\naccount_user_time(tsk, user, user_scaled);\r\naccount_system_time(tsk, hardirq_offset, system, system_scaled);\r\nsteal = S390_lowcore.steal_timer;\r\nif ((s64) steal > 0) {\r\nS390_lowcore.steal_timer = 0;\r\naccount_steal_time(steal);\r\n}\r\nreturn virt_timer_forward(user + system);\r\n}\r\nvoid vtime_task_switch(struct task_struct *prev)\r\n{\r\nstruct thread_info *ti;\r\ndo_account_vtime(prev, 0);\r\nti = task_thread_info(prev);\r\nti->user_timer = S390_lowcore.user_timer;\r\nti->system_timer = S390_lowcore.system_timer;\r\nti = task_thread_info(current);\r\nS390_lowcore.user_timer = ti->user_timer;\r\nS390_lowcore.system_timer = ti->system_timer;\r\n}\r\nvoid vtime_account_user(struct task_struct *tsk)\r\n{\r\nif (do_account_vtime(tsk, HARDIRQ_OFFSET))\r\nvirt_timer_expire();\r\n}\r\nvoid vtime_account_irq_enter(struct task_struct *tsk)\r\n{\r\nstruct thread_info *ti = task_thread_info(tsk);\r\nu64 timer, system, system_scaled;\r\ntimer = S390_lowcore.last_update_timer;\r\nS390_lowcore.last_update_timer = get_vtimer();\r\nS390_lowcore.system_timer += timer - S390_lowcore.last_update_timer;\r\nsystem = S390_lowcore.system_timer - ti->system_timer;\r\nS390_lowcore.steal_timer -= system;\r\nti->system_timer = S390_lowcore.system_timer;\r\nsystem_scaled = system;\r\nif (smp_cpu_mtid) {\r\nu64 mult = __this_cpu_read(mt_scaling_mult);\r\nu64 div = __this_cpu_read(mt_scaling_div);\r\nsystem_scaled = (system_scaled * mult) / div;\r\n}\r\naccount_system_time(tsk, 0, system, system_scaled);\r\nvirt_timer_forward(system);\r\n}\r\nstatic void list_add_sorted(struct vtimer_list *timer, struct list_head *head)\r\n{\r\nstruct vtimer_list *tmp;\r\nlist_for_each_entry(tmp, head, entry) {\r\nif (tmp->expires > timer->expires) {\r\nlist_add_tail(&timer->entry, &tmp->entry);\r\nreturn;\r\n}\r\n}\r\nlist_add_tail(&timer->entry, head);\r\n}\r\nstatic void virt_timer_expire(void)\r\n{\r\nstruct vtimer_list *timer, *tmp;\r\nunsigned long elapsed;\r\nLIST_HEAD(cb_list);\r\nspin_lock(&virt_timer_lock);\r\nelapsed = atomic64_read(&virt_timer_elapsed);\r\nlist_for_each_entry_safe(timer, tmp, &virt_timer_list, entry) {\r\nif (timer->expires < elapsed)\r\nlist_move_tail(&timer->entry, &cb_list);\r\nelse\r\ntimer->expires -= elapsed;\r\n}\r\nif (!list_empty(&virt_timer_list)) {\r\ntimer = list_first_entry(&virt_timer_list,\r\nstruct vtimer_list, entry);\r\natomic64_set(&virt_timer_current, timer->expires);\r\n}\r\natomic64_sub(elapsed, &virt_timer_elapsed);\r\nspin_unlock(&virt_timer_lock);\r\nlist_for_each_entry_safe(timer, tmp, &cb_list, entry) {\r\nlist_del_init(&timer->entry);\r\ntimer->function(timer->data);\r\nif (timer->interval) {\r\ntimer->expires = timer->interval +\r\natomic64_read(&virt_timer_elapsed);\r\nspin_lock(&virt_timer_lock);\r\nlist_add_sorted(timer, &virt_timer_list);\r\nspin_unlock(&virt_timer_lock);\r\n}\r\n}\r\n}\r\nvoid init_virt_timer(struct vtimer_list *timer)\r\n{\r\ntimer->function = NULL;\r\nINIT_LIST_HEAD(&timer->entry);\r\n}\r\nstatic inline int vtimer_pending(struct vtimer_list *timer)\r\n{\r\nreturn !list_empty(&timer->entry);\r\n}\r\nstatic void internal_add_vtimer(struct vtimer_list *timer)\r\n{\r\nif (list_empty(&virt_timer_list)) {\r\natomic64_set(&virt_timer_current, timer->expires);\r\natomic64_set(&virt_timer_elapsed, 0);\r\nlist_add(&timer->entry, &virt_timer_list);\r\n} else {\r\ntimer->expires += atomic64_read(&virt_timer_elapsed);\r\nif (likely((s64) timer->expires <\r\n(s64) atomic64_read(&virt_timer_current)))\r\natomic64_set(&virt_timer_current, timer->expires);\r\nlist_add_sorted(timer, &virt_timer_list);\r\n}\r\n}\r\nstatic void __add_vtimer(struct vtimer_list *timer, int periodic)\r\n{\r\nunsigned long flags;\r\ntimer->interval = periodic ? timer->expires : 0;\r\nspin_lock_irqsave(&virt_timer_lock, flags);\r\ninternal_add_vtimer(timer);\r\nspin_unlock_irqrestore(&virt_timer_lock, flags);\r\n}\r\nvoid add_virt_timer(struct vtimer_list *timer)\r\n{\r\n__add_vtimer(timer, 0);\r\n}\r\nvoid add_virt_timer_periodic(struct vtimer_list *timer)\r\n{\r\n__add_vtimer(timer, 1);\r\n}\r\nstatic int __mod_vtimer(struct vtimer_list *timer, u64 expires, int periodic)\r\n{\r\nunsigned long flags;\r\nint rc;\r\nBUG_ON(!timer->function);\r\nif (timer->expires == expires && vtimer_pending(timer))\r\nreturn 1;\r\nspin_lock_irqsave(&virt_timer_lock, flags);\r\nrc = vtimer_pending(timer);\r\nif (rc)\r\nlist_del_init(&timer->entry);\r\ntimer->interval = periodic ? expires : 0;\r\ntimer->expires = expires;\r\ninternal_add_vtimer(timer);\r\nspin_unlock_irqrestore(&virt_timer_lock, flags);\r\nreturn rc;\r\n}\r\nint mod_virt_timer(struct vtimer_list *timer, u64 expires)\r\n{\r\nreturn __mod_vtimer(timer, expires, 0);\r\n}\r\nint mod_virt_timer_periodic(struct vtimer_list *timer, u64 expires)\r\n{\r\nreturn __mod_vtimer(timer, expires, 1);\r\n}\r\nint del_virt_timer(struct vtimer_list *timer)\r\n{\r\nunsigned long flags;\r\nif (!vtimer_pending(timer))\r\nreturn 0;\r\nspin_lock_irqsave(&virt_timer_lock, flags);\r\nlist_del_init(&timer->entry);\r\nspin_unlock_irqrestore(&virt_timer_lock, flags);\r\nreturn 1;\r\n}\r\nvoid vtime_init(void)\r\n{\r\nset_vtimer(VTIMER_MAX_SLICE);\r\n}
