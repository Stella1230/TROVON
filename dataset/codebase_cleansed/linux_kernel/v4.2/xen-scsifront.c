static void scsifront_wake_up(struct vscsifrnt_info *info)\r\n{\r\ninfo->wait_ring_available = 0;\r\nwake_up(&info->wq_sync);\r\n}\r\nstatic int scsifront_get_rqid(struct vscsifrnt_info *info)\r\n{\r\nunsigned long flags;\r\nint free;\r\nspin_lock_irqsave(&info->shadow_lock, flags);\r\nfree = find_first_bit(info->shadow_free_bitmap, VSCSIIF_MAX_REQS);\r\n__clear_bit(free, info->shadow_free_bitmap);\r\nspin_unlock_irqrestore(&info->shadow_lock, flags);\r\nreturn free;\r\n}\r\nstatic int _scsifront_put_rqid(struct vscsifrnt_info *info, uint32_t id)\r\n{\r\nint empty = bitmap_empty(info->shadow_free_bitmap, VSCSIIF_MAX_REQS);\r\n__set_bit(id, info->shadow_free_bitmap);\r\ninfo->shadow[id] = NULL;\r\nreturn empty || info->wait_ring_available;\r\n}\r\nstatic void scsifront_put_rqid(struct vscsifrnt_info *info, uint32_t id)\r\n{\r\nunsigned long flags;\r\nint kick;\r\nspin_lock_irqsave(&info->shadow_lock, flags);\r\nkick = _scsifront_put_rqid(info, id);\r\nspin_unlock_irqrestore(&info->shadow_lock, flags);\r\nif (kick)\r\nscsifront_wake_up(info);\r\n}\r\nstatic struct vscsiif_request *scsifront_pre_req(struct vscsifrnt_info *info)\r\n{\r\nstruct vscsiif_front_ring *ring = &(info->ring);\r\nstruct vscsiif_request *ring_req;\r\nuint32_t id;\r\nid = scsifront_get_rqid(info);\r\nif (id >= VSCSIIF_MAX_REQS)\r\nreturn NULL;\r\nring_req = RING_GET_REQUEST(&(info->ring), ring->req_prod_pvt);\r\nring->req_prod_pvt++;\r\nring_req->rqid = (uint16_t)id;\r\nreturn ring_req;\r\n}\r\nstatic void scsifront_do_request(struct vscsifrnt_info *info)\r\n{\r\nstruct vscsiif_front_ring *ring = &(info->ring);\r\nint notify;\r\nRING_PUSH_REQUESTS_AND_CHECK_NOTIFY(ring, notify);\r\nif (notify)\r\nnotify_remote_via_irq(info->irq);\r\n}\r\nstatic void scsifront_gnttab_done(struct vscsifrnt_info *info, uint32_t id)\r\n{\r\nstruct vscsifrnt_shadow *s = info->shadow[id];\r\nint i;\r\nif (s->sc->sc_data_direction == DMA_NONE)\r\nreturn;\r\nfor (i = 0; i < s->nr_grants; i++) {\r\nif (unlikely(gnttab_query_foreign_access(s->gref[i]) != 0)) {\r\nshost_printk(KERN_ALERT, info->host, KBUILD_MODNAME\r\n"grant still in use by backend\n");\r\nBUG();\r\n}\r\ngnttab_end_foreign_access(s->gref[i], 0, 0UL);\r\n}\r\nkfree(s->sg);\r\n}\r\nstatic void scsifront_cdb_cmd_done(struct vscsifrnt_info *info,\r\nstruct vscsiif_response *ring_rsp)\r\n{\r\nstruct scsi_cmnd *sc;\r\nuint32_t id;\r\nuint8_t sense_len;\r\nid = ring_rsp->rqid;\r\nsc = info->shadow[id]->sc;\r\nBUG_ON(sc == NULL);\r\nscsifront_gnttab_done(info, id);\r\nscsifront_put_rqid(info, id);\r\nsc->result = ring_rsp->rslt;\r\nscsi_set_resid(sc, ring_rsp->residual_len);\r\nsense_len = min_t(uint8_t, VSCSIIF_SENSE_BUFFERSIZE,\r\nring_rsp->sense_len);\r\nif (sense_len)\r\nmemcpy(sc->sense_buffer, ring_rsp->sense_buffer, sense_len);\r\nsc->scsi_done(sc);\r\n}\r\nstatic void scsifront_sync_cmd_done(struct vscsifrnt_info *info,\r\nstruct vscsiif_response *ring_rsp)\r\n{\r\nuint16_t id = ring_rsp->rqid;\r\nunsigned long flags;\r\nstruct vscsifrnt_shadow *shadow = info->shadow[id];\r\nint kick;\r\nspin_lock_irqsave(&info->shadow_lock, flags);\r\nshadow->wait_reset = 1;\r\nswitch (shadow->rslt_reset) {\r\ncase RSLT_RESET_WAITING:\r\nshadow->rslt_reset = ring_rsp->rslt;\r\nbreak;\r\ncase RSLT_RESET_ERR:\r\nkick = _scsifront_put_rqid(info, id);\r\nspin_unlock_irqrestore(&info->shadow_lock, flags);\r\nkfree(shadow);\r\nif (kick)\r\nscsifront_wake_up(info);\r\nreturn;\r\ndefault:\r\nshost_printk(KERN_ERR, info->host, KBUILD_MODNAME\r\n"bad reset state %d, possibly leaking %u\n",\r\nshadow->rslt_reset, id);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&info->shadow_lock, flags);\r\nwake_up(&shadow->wq_reset);\r\n}\r\nstatic void scsifront_do_response(struct vscsifrnt_info *info,\r\nstruct vscsiif_response *ring_rsp)\r\n{\r\nif (WARN(ring_rsp->rqid >= VSCSIIF_MAX_REQS ||\r\ntest_bit(ring_rsp->rqid, info->shadow_free_bitmap),\r\n"illegal rqid %u returned by backend!\n", ring_rsp->rqid))\r\nreturn;\r\nif (info->shadow[ring_rsp->rqid]->act == VSCSIIF_ACT_SCSI_CDB)\r\nscsifront_cdb_cmd_done(info, ring_rsp);\r\nelse\r\nscsifront_sync_cmd_done(info, ring_rsp);\r\n}\r\nstatic int scsifront_ring_drain(struct vscsifrnt_info *info)\r\n{\r\nstruct vscsiif_response *ring_rsp;\r\nRING_IDX i, rp;\r\nint more_to_do = 0;\r\nrp = info->ring.sring->rsp_prod;\r\nrmb();\r\nfor (i = info->ring.rsp_cons; i != rp; i++) {\r\nring_rsp = RING_GET_RESPONSE(&info->ring, i);\r\nscsifront_do_response(info, ring_rsp);\r\n}\r\ninfo->ring.rsp_cons = i;\r\nif (i != info->ring.req_prod_pvt)\r\nRING_FINAL_CHECK_FOR_RESPONSES(&info->ring, more_to_do);\r\nelse\r\ninfo->ring.sring->rsp_event = i + 1;\r\nreturn more_to_do;\r\n}\r\nstatic int scsifront_cmd_done(struct vscsifrnt_info *info)\r\n{\r\nint more_to_do;\r\nunsigned long flags;\r\nspin_lock_irqsave(info->host->host_lock, flags);\r\nmore_to_do = scsifront_ring_drain(info);\r\ninfo->wait_ring_available = 0;\r\nspin_unlock_irqrestore(info->host->host_lock, flags);\r\nwake_up(&info->wq_sync);\r\nreturn more_to_do;\r\n}\r\nstatic irqreturn_t scsifront_irq_fn(int irq, void *dev_id)\r\n{\r\nstruct vscsifrnt_info *info = dev_id;\r\nwhile (scsifront_cmd_done(info))\r\ncond_resched();\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void scsifront_finish_all(struct vscsifrnt_info *info)\r\n{\r\nunsigned i;\r\nstruct vscsiif_response resp;\r\nscsifront_ring_drain(info);\r\nfor (i = 0; i < VSCSIIF_MAX_REQS; i++) {\r\nif (test_bit(i, info->shadow_free_bitmap))\r\ncontinue;\r\nresp.rqid = i;\r\nresp.sense_len = 0;\r\nresp.rslt = DID_RESET << 16;\r\nresp.residual_len = 0;\r\nscsifront_do_response(info, &resp);\r\n}\r\n}\r\nstatic int map_data_for_request(struct vscsifrnt_info *info,\r\nstruct scsi_cmnd *sc,\r\nstruct vscsiif_request *ring_req,\r\nstruct vscsifrnt_shadow *shadow)\r\n{\r\ngrant_ref_t gref_head;\r\nstruct page *page;\r\nint err, ref, ref_cnt = 0;\r\nint grant_ro = (sc->sc_data_direction == DMA_TO_DEVICE);\r\nunsigned int i, off, len, bytes;\r\nunsigned int data_len = scsi_bufflen(sc);\r\nunsigned int data_grants = 0, seg_grants = 0;\r\nstruct scatterlist *sg;\r\nunsigned long mfn;\r\nstruct scsiif_request_segment *seg;\r\nring_req->nr_segments = 0;\r\nif (sc->sc_data_direction == DMA_NONE || !data_len)\r\nreturn 0;\r\nscsi_for_each_sg(sc, sg, scsi_sg_count(sc), i)\r\ndata_grants += PFN_UP(sg->offset + sg->length);\r\nif (data_grants > VSCSIIF_SG_TABLESIZE) {\r\nif (data_grants > info->host->sg_tablesize) {\r\nshost_printk(KERN_ERR, info->host, KBUILD_MODNAME\r\n"Unable to map request_buffer for command!\n");\r\nreturn -E2BIG;\r\n}\r\nseg_grants = vscsiif_grants_sg(data_grants);\r\nshadow->sg = kcalloc(data_grants,\r\nsizeof(struct scsiif_request_segment), GFP_ATOMIC);\r\nif (!shadow->sg)\r\nreturn -ENOMEM;\r\n}\r\nseg = shadow->sg ? : ring_req->seg;\r\nerr = gnttab_alloc_grant_references(seg_grants + data_grants,\r\n&gref_head);\r\nif (err) {\r\nkfree(shadow->sg);\r\nshost_printk(KERN_ERR, info->host, KBUILD_MODNAME\r\n"gnttab_alloc_grant_references() error\n");\r\nreturn -ENOMEM;\r\n}\r\nif (seg_grants) {\r\npage = virt_to_page(seg);\r\noff = (unsigned long)seg & ~PAGE_MASK;\r\nlen = sizeof(struct scsiif_request_segment) * data_grants;\r\nwhile (len > 0) {\r\nbytes = min_t(unsigned int, len, PAGE_SIZE - off);\r\nref = gnttab_claim_grant_reference(&gref_head);\r\nBUG_ON(ref == -ENOSPC);\r\nmfn = pfn_to_mfn(page_to_pfn(page));\r\ngnttab_grant_foreign_access_ref(ref,\r\ninfo->dev->otherend_id, mfn, 1);\r\nshadow->gref[ref_cnt] = ref;\r\nring_req->seg[ref_cnt].gref = ref;\r\nring_req->seg[ref_cnt].offset = (uint16_t)off;\r\nring_req->seg[ref_cnt].length = (uint16_t)bytes;\r\npage++;\r\nlen -= bytes;\r\noff = 0;\r\nref_cnt++;\r\n}\r\nBUG_ON(seg_grants < ref_cnt);\r\nseg_grants = ref_cnt;\r\n}\r\nscsi_for_each_sg(sc, sg, scsi_sg_count(sc), i) {\r\npage = sg_page(sg);\r\noff = sg->offset;\r\nlen = sg->length;\r\nwhile (len > 0 && data_len > 0) {\r\nbytes = min_t(unsigned int, len, PAGE_SIZE - off);\r\nbytes = min(bytes, data_len);\r\nref = gnttab_claim_grant_reference(&gref_head);\r\nBUG_ON(ref == -ENOSPC);\r\nmfn = pfn_to_mfn(page_to_pfn(page));\r\ngnttab_grant_foreign_access_ref(ref,\r\ninfo->dev->otherend_id, mfn, grant_ro);\r\nshadow->gref[ref_cnt] = ref;\r\nseg->gref = ref;\r\nseg->offset = (uint16_t)off;\r\nseg->length = (uint16_t)bytes;\r\npage++;\r\nseg++;\r\nlen -= bytes;\r\ndata_len -= bytes;\r\noff = 0;\r\nref_cnt++;\r\n}\r\n}\r\nif (seg_grants)\r\nring_req->nr_segments = VSCSIIF_SG_GRANT | seg_grants;\r\nelse\r\nring_req->nr_segments = (uint8_t)ref_cnt;\r\nshadow->nr_grants = ref_cnt;\r\nreturn 0;\r\n}\r\nstatic struct vscsiif_request *scsifront_command2ring(\r\nstruct vscsifrnt_info *info, struct scsi_cmnd *sc,\r\nstruct vscsifrnt_shadow *shadow)\r\n{\r\nstruct vscsiif_request *ring_req;\r\nmemset(shadow, 0, sizeof(*shadow));\r\nring_req = scsifront_pre_req(info);\r\nif (!ring_req)\r\nreturn NULL;\r\ninfo->shadow[ring_req->rqid] = shadow;\r\nshadow->rqid = ring_req->rqid;\r\nring_req->id = sc->device->id;\r\nring_req->lun = sc->device->lun;\r\nring_req->channel = sc->device->channel;\r\nring_req->cmd_len = sc->cmd_len;\r\nBUG_ON(sc->cmd_len > VSCSIIF_MAX_COMMAND_SIZE);\r\nmemcpy(ring_req->cmnd, sc->cmnd, sc->cmd_len);\r\nring_req->sc_data_direction = (uint8_t)sc->sc_data_direction;\r\nring_req->timeout_per_command = sc->request->timeout / HZ;\r\nreturn ring_req;\r\n}\r\nstatic int scsifront_enter(struct vscsifrnt_info *info)\r\n{\r\nif (info->pause)\r\nreturn 1;\r\ninfo->callers++;\r\nreturn 0;\r\n}\r\nstatic void scsifront_return(struct vscsifrnt_info *info)\r\n{\r\ninfo->callers--;\r\nif (info->callers)\r\nreturn;\r\nif (!info->waiting_pause)\r\nreturn;\r\ninfo->waiting_pause = 0;\r\nwake_up(&info->wq_pause);\r\n}\r\nstatic int scsifront_queuecommand(struct Scsi_Host *shost,\r\nstruct scsi_cmnd *sc)\r\n{\r\nstruct vscsifrnt_info *info = shost_priv(shost);\r\nstruct vscsiif_request *ring_req;\r\nstruct vscsifrnt_shadow *shadow = scsi_cmd_priv(sc);\r\nunsigned long flags;\r\nint err;\r\nuint16_t rqid;\r\nspin_lock_irqsave(shost->host_lock, flags);\r\nif (scsifront_enter(info)) {\r\nspin_unlock_irqrestore(shost->host_lock, flags);\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\n}\r\nif (RING_FULL(&info->ring))\r\ngoto busy;\r\nring_req = scsifront_command2ring(info, sc, shadow);\r\nif (!ring_req)\r\ngoto busy;\r\nsc->result = 0;\r\nrqid = ring_req->rqid;\r\nring_req->act = VSCSIIF_ACT_SCSI_CDB;\r\nshadow->sc = sc;\r\nshadow->act = VSCSIIF_ACT_SCSI_CDB;\r\nerr = map_data_for_request(info, sc, ring_req, shadow);\r\nif (err < 0) {\r\npr_debug("%s: err %d\n", __func__, err);\r\nscsifront_put_rqid(info, rqid);\r\nscsifront_return(info);\r\nspin_unlock_irqrestore(shost->host_lock, flags);\r\nif (err == -ENOMEM)\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\nsc->result = DID_ERROR << 16;\r\nsc->scsi_done(sc);\r\nreturn 0;\r\n}\r\nscsifront_do_request(info);\r\nscsifront_return(info);\r\nspin_unlock_irqrestore(shost->host_lock, flags);\r\nreturn 0;\r\nbusy:\r\nscsifront_return(info);\r\nspin_unlock_irqrestore(shost->host_lock, flags);\r\npr_debug("%s: busy\n", __func__);\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\n}\r\nstatic int scsifront_action_handler(struct scsi_cmnd *sc, uint8_t act)\r\n{\r\nstruct Scsi_Host *host = sc->device->host;\r\nstruct vscsifrnt_info *info = shost_priv(host);\r\nstruct vscsifrnt_shadow *shadow, *s = scsi_cmd_priv(sc);\r\nstruct vscsiif_request *ring_req;\r\nint err = 0;\r\nshadow = kmalloc(sizeof(*shadow), GFP_NOIO);\r\nif (!shadow)\r\nreturn FAILED;\r\nspin_lock_irq(host->host_lock);\r\nfor (;;) {\r\nif (!RING_FULL(&info->ring)) {\r\nring_req = scsifront_command2ring(info, sc, shadow);\r\nif (ring_req)\r\nbreak;\r\n}\r\nif (err || info->pause) {\r\nspin_unlock_irq(host->host_lock);\r\nkfree(shadow);\r\nreturn FAILED;\r\n}\r\ninfo->wait_ring_available = 1;\r\nspin_unlock_irq(host->host_lock);\r\nerr = wait_event_interruptible(info->wq_sync,\r\n!info->wait_ring_available);\r\nspin_lock_irq(host->host_lock);\r\n}\r\nif (scsifront_enter(info)) {\r\nspin_unlock_irq(host->host_lock);\r\nreturn FAILED;\r\n}\r\nring_req->act = act;\r\nring_req->ref_rqid = s->rqid;\r\nshadow->act = act;\r\nshadow->rslt_reset = RSLT_RESET_WAITING;\r\ninit_waitqueue_head(&shadow->wq_reset);\r\nring_req->nr_segments = 0;\r\nscsifront_do_request(info);\r\nspin_unlock_irq(host->host_lock);\r\nerr = wait_event_interruptible(shadow->wq_reset, shadow->wait_reset);\r\nspin_lock_irq(host->host_lock);\r\nif (!err) {\r\nerr = shadow->rslt_reset;\r\nscsifront_put_rqid(info, shadow->rqid);\r\nkfree(shadow);\r\n} else {\r\nspin_lock(&info->shadow_lock);\r\nshadow->rslt_reset = RSLT_RESET_ERR;\r\nspin_unlock(&info->shadow_lock);\r\nerr = FAILED;\r\n}\r\nscsifront_return(info);\r\nspin_unlock_irq(host->host_lock);\r\nreturn err;\r\n}\r\nstatic int scsifront_eh_abort_handler(struct scsi_cmnd *sc)\r\n{\r\npr_debug("%s\n", __func__);\r\nreturn scsifront_action_handler(sc, VSCSIIF_ACT_SCSI_ABORT);\r\n}\r\nstatic int scsifront_dev_reset_handler(struct scsi_cmnd *sc)\r\n{\r\npr_debug("%s\n", __func__);\r\nreturn scsifront_action_handler(sc, VSCSIIF_ACT_SCSI_RESET);\r\n}\r\nstatic int scsifront_sdev_configure(struct scsi_device *sdev)\r\n{\r\nstruct vscsifrnt_info *info = shost_priv(sdev->host);\r\nif (info && current == info->curr)\r\nxenbus_printf(XBT_NIL, info->dev->nodename,\r\ninfo->dev_state_path, "%d", XenbusStateConnected);\r\nreturn 0;\r\n}\r\nstatic void scsifront_sdev_destroy(struct scsi_device *sdev)\r\n{\r\nstruct vscsifrnt_info *info = shost_priv(sdev->host);\r\nif (info && current == info->curr)\r\nxenbus_printf(XBT_NIL, info->dev->nodename,\r\ninfo->dev_state_path, "%d", XenbusStateClosed);\r\n}\r\nstatic int scsifront_alloc_ring(struct vscsifrnt_info *info)\r\n{\r\nstruct xenbus_device *dev = info->dev;\r\nstruct vscsiif_sring *sring;\r\ngrant_ref_t gref;\r\nint err = -ENOMEM;\r\nsring = (struct vscsiif_sring *)__get_free_page(GFP_KERNEL);\r\nif (!sring) {\r\nxenbus_dev_fatal(dev, err,\r\n"fail to allocate shared ring (Front to Back)");\r\nreturn err;\r\n}\r\nSHARED_RING_INIT(sring);\r\nFRONT_RING_INIT(&info->ring, sring, PAGE_SIZE);\r\nerr = xenbus_grant_ring(dev, sring, 1, &gref);\r\nif (err < 0) {\r\nfree_page((unsigned long)sring);\r\nxenbus_dev_fatal(dev, err,\r\n"fail to grant shared ring (Front to Back)");\r\nreturn err;\r\n}\r\ninfo->ring_ref = gref;\r\nerr = xenbus_alloc_evtchn(dev, &info->evtchn);\r\nif (err) {\r\nxenbus_dev_fatal(dev, err, "xenbus_alloc_evtchn");\r\ngoto free_gnttab;\r\n}\r\nerr = bind_evtchn_to_irq(info->evtchn);\r\nif (err <= 0) {\r\nxenbus_dev_fatal(dev, err, "bind_evtchn_to_irq");\r\ngoto free_gnttab;\r\n}\r\ninfo->irq = err;\r\nerr = request_threaded_irq(info->irq, NULL, scsifront_irq_fn,\r\nIRQF_ONESHOT, "scsifront", info);\r\nif (err) {\r\nxenbus_dev_fatal(dev, err, "request_threaded_irq");\r\ngoto free_irq;\r\n}\r\nreturn 0;\r\nfree_irq:\r\nunbind_from_irqhandler(info->irq, info);\r\nfree_gnttab:\r\ngnttab_end_foreign_access(info->ring_ref, 0,\r\n(unsigned long)info->ring.sring);\r\nreturn err;\r\n}\r\nstatic void scsifront_free_ring(struct vscsifrnt_info *info)\r\n{\r\nunbind_from_irqhandler(info->irq, info);\r\ngnttab_end_foreign_access(info->ring_ref, 0,\r\n(unsigned long)info->ring.sring);\r\n}\r\nstatic int scsifront_init_ring(struct vscsifrnt_info *info)\r\n{\r\nstruct xenbus_device *dev = info->dev;\r\nstruct xenbus_transaction xbt;\r\nint err;\r\npr_debug("%s\n", __func__);\r\nerr = scsifront_alloc_ring(info);\r\nif (err)\r\nreturn err;\r\npr_debug("%s: %u %u\n", __func__, info->ring_ref, info->evtchn);\r\nagain:\r\nerr = xenbus_transaction_start(&xbt);\r\nif (err)\r\nxenbus_dev_fatal(dev, err, "starting transaction");\r\nerr = xenbus_printf(xbt, dev->nodename, "ring-ref", "%u",\r\ninfo->ring_ref);\r\nif (err) {\r\nxenbus_dev_fatal(dev, err, "%s", "writing ring-ref");\r\ngoto fail;\r\n}\r\nerr = xenbus_printf(xbt, dev->nodename, "event-channel", "%u",\r\ninfo->evtchn);\r\nif (err) {\r\nxenbus_dev_fatal(dev, err, "%s", "writing event-channel");\r\ngoto fail;\r\n}\r\nerr = xenbus_transaction_end(xbt, 0);\r\nif (err) {\r\nif (err == -EAGAIN)\r\ngoto again;\r\nxenbus_dev_fatal(dev, err, "completing transaction");\r\ngoto free_sring;\r\n}\r\nreturn 0;\r\nfail:\r\nxenbus_transaction_end(xbt, 1);\r\nfree_sring:\r\nscsifront_free_ring(info);\r\nreturn err;\r\n}\r\nstatic int scsifront_probe(struct xenbus_device *dev,\r\nconst struct xenbus_device_id *id)\r\n{\r\nstruct vscsifrnt_info *info;\r\nstruct Scsi_Host *host;\r\nint err = -ENOMEM;\r\nchar name[TASK_COMM_LEN];\r\nhost = scsi_host_alloc(&scsifront_sht, sizeof(*info));\r\nif (!host) {\r\nxenbus_dev_fatal(dev, err, "fail to allocate scsi host");\r\nreturn err;\r\n}\r\ninfo = (struct vscsifrnt_info *)host->hostdata;\r\ndev_set_drvdata(&dev->dev, info);\r\ninfo->dev = dev;\r\nbitmap_fill(info->shadow_free_bitmap, VSCSIIF_MAX_REQS);\r\nerr = scsifront_init_ring(info);\r\nif (err) {\r\nscsi_host_put(host);\r\nreturn err;\r\n}\r\ninit_waitqueue_head(&info->wq_sync);\r\ninit_waitqueue_head(&info->wq_pause);\r\nspin_lock_init(&info->shadow_lock);\r\nsnprintf(name, TASK_COMM_LEN, "vscsiif.%d", host->host_no);\r\nhost->max_id = VSCSIIF_MAX_TARGET;\r\nhost->max_channel = 0;\r\nhost->max_lun = VSCSIIF_MAX_LUN;\r\nhost->max_sectors = (host->sg_tablesize - 1) * PAGE_SIZE / 512;\r\nhost->max_cmd_len = VSCSIIF_MAX_COMMAND_SIZE;\r\nerr = scsi_add_host(host, &dev->dev);\r\nif (err) {\r\ndev_err(&dev->dev, "fail to add scsi host %d\n", err);\r\ngoto free_sring;\r\n}\r\ninfo->host = host;\r\ninfo->host_active = 1;\r\nxenbus_switch_state(dev, XenbusStateInitialised);\r\nreturn 0;\r\nfree_sring:\r\nscsifront_free_ring(info);\r\nscsi_host_put(host);\r\nreturn err;\r\n}\r\nstatic int scsifront_resume(struct xenbus_device *dev)\r\n{\r\nstruct vscsifrnt_info *info = dev_get_drvdata(&dev->dev);\r\nstruct Scsi_Host *host = info->host;\r\nint err;\r\nspin_lock_irq(host->host_lock);\r\nscsifront_finish_all(info);\r\nspin_unlock_irq(host->host_lock);\r\nscsifront_free_ring(info);\r\nerr = scsifront_init_ring(info);\r\nif (err) {\r\ndev_err(&dev->dev, "fail to resume %d\n", err);\r\nscsi_host_put(host);\r\nreturn err;\r\n}\r\nxenbus_switch_state(dev, XenbusStateInitialised);\r\nreturn 0;\r\n}\r\nstatic int scsifront_suspend(struct xenbus_device *dev)\r\n{\r\nstruct vscsifrnt_info *info = dev_get_drvdata(&dev->dev);\r\nstruct Scsi_Host *host = info->host;\r\nint err = 0;\r\nspin_lock_irq(host->host_lock);\r\ninfo->pause = 1;\r\nwhile (info->callers && !err) {\r\ninfo->waiting_pause = 1;\r\ninfo->wait_ring_available = 0;\r\nspin_unlock_irq(host->host_lock);\r\nwake_up(&info->wq_sync);\r\nerr = wait_event_interruptible(info->wq_pause,\r\n!info->waiting_pause);\r\nspin_lock_irq(host->host_lock);\r\n}\r\nspin_unlock_irq(host->host_lock);\r\nreturn err;\r\n}\r\nstatic int scsifront_remove(struct xenbus_device *dev)\r\n{\r\nstruct vscsifrnt_info *info = dev_get_drvdata(&dev->dev);\r\npr_debug("%s: %s removed\n", __func__, dev->nodename);\r\nmutex_lock(&scsifront_mutex);\r\nif (info->host_active) {\r\nscsi_remove_host(info->host);\r\ninfo->host_active = 0;\r\n}\r\nmutex_unlock(&scsifront_mutex);\r\nscsifront_free_ring(info);\r\nscsi_host_put(info->host);\r\nreturn 0;\r\n}\r\nstatic void scsifront_disconnect(struct vscsifrnt_info *info)\r\n{\r\nstruct xenbus_device *dev = info->dev;\r\nstruct Scsi_Host *host = info->host;\r\npr_debug("%s: %s disconnect\n", __func__, dev->nodename);\r\nmutex_lock(&scsifront_mutex);\r\nif (info->host_active) {\r\nscsi_remove_host(host);\r\ninfo->host_active = 0;\r\n}\r\nmutex_unlock(&scsifront_mutex);\r\nxenbus_frontend_closed(dev);\r\n}\r\nstatic void scsifront_do_lun_hotplug(struct vscsifrnt_info *info, int op)\r\n{\r\nstruct xenbus_device *dev = info->dev;\r\nint i, err = 0;\r\nchar str[64];\r\nchar **dir;\r\nunsigned int dir_n = 0;\r\nunsigned int device_state;\r\nunsigned int hst, chn, tgt, lun;\r\nstruct scsi_device *sdev;\r\ndir = xenbus_directory(XBT_NIL, dev->otherend, "vscsi-devs", &dir_n);\r\nif (IS_ERR(dir))\r\nreturn;\r\nBUG_ON(info->curr);\r\ninfo->curr = current;\r\nfor (i = 0; i < dir_n; i++) {\r\nsnprintf(str, sizeof(str), "vscsi-devs/%s/state", dir[i]);\r\nerr = xenbus_scanf(XBT_NIL, dev->otherend, str, "%u",\r\n&device_state);\r\nif (XENBUS_EXIST_ERR(err))\r\ncontinue;\r\nsnprintf(str, sizeof(str), "vscsi-devs/%s/v-dev", dir[i]);\r\nerr = xenbus_scanf(XBT_NIL, dev->otherend, str,\r\n"%u:%u:%u:%u", &hst, &chn, &tgt, &lun);\r\nif (XENBUS_EXIST_ERR(err))\r\ncontinue;\r\nsnprintf(info->dev_state_path, sizeof(info->dev_state_path),\r\n"vscsi-devs/%s/state", dir[i]);\r\nswitch (op) {\r\ncase VSCSIFRONT_OP_ADD_LUN:\r\nif (device_state != XenbusStateInitialised)\r\nbreak;\r\nif (scsi_add_device(info->host, chn, tgt, lun)) {\r\ndev_err(&dev->dev, "scsi_add_device\n");\r\nxenbus_printf(XBT_NIL, dev->nodename,\r\ninfo->dev_state_path,\r\n"%d", XenbusStateClosed);\r\n}\r\nbreak;\r\ncase VSCSIFRONT_OP_DEL_LUN:\r\nif (device_state != XenbusStateClosing)\r\nbreak;\r\nsdev = scsi_device_lookup(info->host, chn, tgt, lun);\r\nif (sdev) {\r\nscsi_remove_device(sdev);\r\nscsi_device_put(sdev);\r\n}\r\nbreak;\r\ncase VSCSIFRONT_OP_READD_LUN:\r\nif (device_state == XenbusStateConnected)\r\nxenbus_printf(XBT_NIL, dev->nodename,\r\ninfo->dev_state_path,\r\n"%d", XenbusStateConnected);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\ninfo->curr = NULL;\r\nkfree(dir);\r\n}\r\nstatic void scsifront_read_backend_params(struct xenbus_device *dev,\r\nstruct vscsifrnt_info *info)\r\n{\r\nunsigned int sg_grant, nr_segs;\r\nint ret;\r\nstruct Scsi_Host *host = info->host;\r\nret = xenbus_scanf(XBT_NIL, dev->otherend, "feature-sg-grant", "%u",\r\n&sg_grant);\r\nif (ret != 1)\r\nsg_grant = 0;\r\nnr_segs = min_t(unsigned int, sg_grant, SG_ALL);\r\nnr_segs = max_t(unsigned int, nr_segs, VSCSIIF_SG_TABLESIZE);\r\nnr_segs = min_t(unsigned int, nr_segs,\r\nVSCSIIF_SG_TABLESIZE * PAGE_SIZE /\r\nsizeof(struct scsiif_request_segment));\r\nif (!info->pause && sg_grant)\r\ndev_info(&dev->dev, "using up to %d SG entries\n", nr_segs);\r\nelse if (info->pause && nr_segs < host->sg_tablesize)\r\ndev_warn(&dev->dev,\r\n"SG entries decreased from %d to %u - device may not work properly anymore\n",\r\nhost->sg_tablesize, nr_segs);\r\nhost->sg_tablesize = nr_segs;\r\nhost->max_sectors = (nr_segs - 1) * PAGE_SIZE / 512;\r\n}\r\nstatic void scsifront_backend_changed(struct xenbus_device *dev,\r\nenum xenbus_state backend_state)\r\n{\r\nstruct vscsifrnt_info *info = dev_get_drvdata(&dev->dev);\r\npr_debug("%s: %p %u %u\n", __func__, dev, dev->state, backend_state);\r\nswitch (backend_state) {\r\ncase XenbusStateUnknown:\r\ncase XenbusStateInitialising:\r\ncase XenbusStateInitWait:\r\ncase XenbusStateInitialised:\r\nbreak;\r\ncase XenbusStateConnected:\r\nscsifront_read_backend_params(dev, info);\r\nif (info->pause) {\r\nscsifront_do_lun_hotplug(info, VSCSIFRONT_OP_READD_LUN);\r\nxenbus_switch_state(dev, XenbusStateConnected);\r\ninfo->pause = 0;\r\nreturn;\r\n}\r\nif (xenbus_read_driver_state(dev->nodename) ==\r\nXenbusStateInitialised)\r\nscsifront_do_lun_hotplug(info, VSCSIFRONT_OP_ADD_LUN);\r\nif (dev->state != XenbusStateConnected)\r\nxenbus_switch_state(dev, XenbusStateConnected);\r\nbreak;\r\ncase XenbusStateClosed:\r\nif (dev->state == XenbusStateClosed)\r\nbreak;\r\ncase XenbusStateClosing:\r\nscsifront_disconnect(info);\r\nbreak;\r\ncase XenbusStateReconfiguring:\r\nscsifront_do_lun_hotplug(info, VSCSIFRONT_OP_DEL_LUN);\r\nxenbus_switch_state(dev, XenbusStateReconfiguring);\r\nbreak;\r\ncase XenbusStateReconfigured:\r\nscsifront_do_lun_hotplug(info, VSCSIFRONT_OP_ADD_LUN);\r\nxenbus_switch_state(dev, XenbusStateConnected);\r\nbreak;\r\n}\r\n}\r\nstatic int __init scsifront_init(void)\r\n{\r\nif (!xen_domain())\r\nreturn -ENODEV;\r\nreturn xenbus_register_frontend(&scsifront_driver);\r\n}\r\nstatic void __exit scsifront_exit(void)\r\n{\r\nxenbus_unregister_driver(&scsifront_driver);\r\n}
