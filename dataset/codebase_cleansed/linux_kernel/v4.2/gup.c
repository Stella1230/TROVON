static inline pte_t gup_get_pte(pte_t *ptep)\r\n{\r\n#ifndef CONFIG_X86_PAE\r\nreturn READ_ONCE(*ptep);\r\n#else\r\npte_t pte;\r\nretry:\r\npte.pte_low = ptep->pte_low;\r\nsmp_rmb();\r\npte.pte_high = ptep->pte_high;\r\nsmp_rmb();\r\nif (unlikely(pte.pte_low != ptep->pte_low))\r\ngoto retry;\r\nreturn pte;\r\n#endif\r\n}\r\nstatic noinline int gup_pte_range(pmd_t pmd, unsigned long addr,\r\nunsigned long end, int write, struct page **pages, int *nr)\r\n{\r\nunsigned long mask;\r\npte_t *ptep;\r\nmask = _PAGE_PRESENT|_PAGE_USER;\r\nif (write)\r\nmask |= _PAGE_RW;\r\nptep = pte_offset_map(&pmd, addr);\r\ndo {\r\npte_t pte = gup_get_pte(ptep);\r\nstruct page *page;\r\nif (pte_protnone(pte)) {\r\npte_unmap(ptep);\r\nreturn 0;\r\n}\r\nif ((pte_flags(pte) & (mask | _PAGE_SPECIAL)) != mask) {\r\npte_unmap(ptep);\r\nreturn 0;\r\n}\r\nVM_BUG_ON(!pfn_valid(pte_pfn(pte)));\r\npage = pte_page(pte);\r\nget_page(page);\r\nSetPageReferenced(page);\r\npages[*nr] = page;\r\n(*nr)++;\r\n} while (ptep++, addr += PAGE_SIZE, addr != end);\r\npte_unmap(ptep - 1);\r\nreturn 1;\r\n}\r\nstatic inline void get_head_page_multiple(struct page *page, int nr)\r\n{\r\nVM_BUG_ON_PAGE(page != compound_head(page), page);\r\nVM_BUG_ON_PAGE(page_count(page) == 0, page);\r\natomic_add(nr, &page->_count);\r\nSetPageReferenced(page);\r\n}\r\nstatic noinline int gup_huge_pmd(pmd_t pmd, unsigned long addr,\r\nunsigned long end, int write, struct page **pages, int *nr)\r\n{\r\nunsigned long mask;\r\npte_t pte = *(pte_t *)&pmd;\r\nstruct page *head, *page;\r\nint refs;\r\nmask = _PAGE_PRESENT|_PAGE_USER;\r\nif (write)\r\nmask |= _PAGE_RW;\r\nif ((pte_flags(pte) & mask) != mask)\r\nreturn 0;\r\nVM_BUG_ON(pte_flags(pte) & _PAGE_SPECIAL);\r\nVM_BUG_ON(!pfn_valid(pte_pfn(pte)));\r\nrefs = 0;\r\nhead = pte_page(pte);\r\npage = head + ((addr & ~PMD_MASK) >> PAGE_SHIFT);\r\ndo {\r\nVM_BUG_ON_PAGE(compound_head(page) != head, page);\r\npages[*nr] = page;\r\nif (PageTail(page))\r\nget_huge_page_tail(page);\r\n(*nr)++;\r\npage++;\r\nrefs++;\r\n} while (addr += PAGE_SIZE, addr != end);\r\nget_head_page_multiple(head, refs);\r\nreturn 1;\r\n}\r\nstatic int gup_pmd_range(pud_t pud, unsigned long addr, unsigned long end,\r\nint write, struct page **pages, int *nr)\r\n{\r\nunsigned long next;\r\npmd_t *pmdp;\r\npmdp = pmd_offset(&pud, addr);\r\ndo {\r\npmd_t pmd = *pmdp;\r\nnext = pmd_addr_end(addr, end);\r\nif (pmd_none(pmd) || pmd_trans_splitting(pmd))\r\nreturn 0;\r\nif (unlikely(pmd_large(pmd) || !pmd_present(pmd))) {\r\nif (pmd_protnone(pmd))\r\nreturn 0;\r\nif (!gup_huge_pmd(pmd, addr, next, write, pages, nr))\r\nreturn 0;\r\n} else {\r\nif (!gup_pte_range(pmd, addr, next, write, pages, nr))\r\nreturn 0;\r\n}\r\n} while (pmdp++, addr = next, addr != end);\r\nreturn 1;\r\n}\r\nstatic noinline int gup_huge_pud(pud_t pud, unsigned long addr,\r\nunsigned long end, int write, struct page **pages, int *nr)\r\n{\r\nunsigned long mask;\r\npte_t pte = *(pte_t *)&pud;\r\nstruct page *head, *page;\r\nint refs;\r\nmask = _PAGE_PRESENT|_PAGE_USER;\r\nif (write)\r\nmask |= _PAGE_RW;\r\nif ((pte_flags(pte) & mask) != mask)\r\nreturn 0;\r\nVM_BUG_ON(pte_flags(pte) & _PAGE_SPECIAL);\r\nVM_BUG_ON(!pfn_valid(pte_pfn(pte)));\r\nrefs = 0;\r\nhead = pte_page(pte);\r\npage = head + ((addr & ~PUD_MASK) >> PAGE_SHIFT);\r\ndo {\r\nVM_BUG_ON_PAGE(compound_head(page) != head, page);\r\npages[*nr] = page;\r\nif (PageTail(page))\r\nget_huge_page_tail(page);\r\n(*nr)++;\r\npage++;\r\nrefs++;\r\n} while (addr += PAGE_SIZE, addr != end);\r\nget_head_page_multiple(head, refs);\r\nreturn 1;\r\n}\r\nstatic int gup_pud_range(pgd_t pgd, unsigned long addr, unsigned long end,\r\nint write, struct page **pages, int *nr)\r\n{\r\nunsigned long next;\r\npud_t *pudp;\r\npudp = pud_offset(&pgd, addr);\r\ndo {\r\npud_t pud = *pudp;\r\nnext = pud_addr_end(addr, end);\r\nif (pud_none(pud))\r\nreturn 0;\r\nif (unlikely(pud_large(pud))) {\r\nif (!gup_huge_pud(pud, addr, next, write, pages, nr))\r\nreturn 0;\r\n} else {\r\nif (!gup_pmd_range(pud, addr, next, write, pages, nr))\r\nreturn 0;\r\n}\r\n} while (pudp++, addr = next, addr != end);\r\nreturn 1;\r\n}\r\nint __get_user_pages_fast(unsigned long start, int nr_pages, int write,\r\nstruct page **pages)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long addr, len, end;\r\nunsigned long next;\r\nunsigned long flags;\r\npgd_t *pgdp;\r\nint nr = 0;\r\nstart &= PAGE_MASK;\r\naddr = start;\r\nlen = (unsigned long) nr_pages << PAGE_SHIFT;\r\nend = start + len;\r\nif (unlikely(!access_ok(write ? VERIFY_WRITE : VERIFY_READ,\r\n(void __user *)start, len)))\r\nreturn 0;\r\nlocal_irq_save(flags);\r\npgdp = pgd_offset(mm, addr);\r\ndo {\r\npgd_t pgd = *pgdp;\r\nnext = pgd_addr_end(addr, end);\r\nif (pgd_none(pgd))\r\nbreak;\r\nif (!gup_pud_range(pgd, addr, next, write, pages, &nr))\r\nbreak;\r\n} while (pgdp++, addr = next, addr != end);\r\nlocal_irq_restore(flags);\r\nreturn nr;\r\n}\r\nint get_user_pages_fast(unsigned long start, int nr_pages, int write,\r\nstruct page **pages)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long addr, len, end;\r\nunsigned long next;\r\npgd_t *pgdp;\r\nint nr = 0;\r\nstart &= PAGE_MASK;\r\naddr = start;\r\nlen = (unsigned long) nr_pages << PAGE_SHIFT;\r\nend = start + len;\r\nif (end < start)\r\ngoto slow_irqon;\r\n#ifdef CONFIG_X86_64\r\nif (end >> __VIRTUAL_MASK_SHIFT)\r\ngoto slow_irqon;\r\n#endif\r\nlocal_irq_disable();\r\npgdp = pgd_offset(mm, addr);\r\ndo {\r\npgd_t pgd = *pgdp;\r\nnext = pgd_addr_end(addr, end);\r\nif (pgd_none(pgd))\r\ngoto slow;\r\nif (!gup_pud_range(pgd, addr, next, write, pages, &nr))\r\ngoto slow;\r\n} while (pgdp++, addr = next, addr != end);\r\nlocal_irq_enable();\r\nVM_BUG_ON(nr != (end - start) >> PAGE_SHIFT);\r\nreturn nr;\r\n{\r\nint ret;\r\nslow:\r\nlocal_irq_enable();\r\nslow_irqon:\r\nstart += nr << PAGE_SHIFT;\r\npages += nr;\r\nret = get_user_pages_unlocked(current, mm, start,\r\n(end - start) >> PAGE_SHIFT,\r\nwrite, 0, pages);\r\nif (nr > 0) {\r\nif (ret < 0)\r\nret = nr;\r\nelse\r\nret += nr;\r\n}\r\nreturn ret;\r\n}\r\n}
