static struct audit_tree *alloc_tree(const char *s)\r\n{\r\nstruct audit_tree *tree;\r\ntree = kmalloc(sizeof(struct audit_tree) + strlen(s) + 1, GFP_KERNEL);\r\nif (tree) {\r\natomic_set(&tree->count, 1);\r\ntree->goner = 0;\r\nINIT_LIST_HEAD(&tree->chunks);\r\nINIT_LIST_HEAD(&tree->rules);\r\nINIT_LIST_HEAD(&tree->list);\r\nINIT_LIST_HEAD(&tree->same_root);\r\ntree->root = NULL;\r\nstrcpy(tree->pathname, s);\r\n}\r\nreturn tree;\r\n}\r\nstatic inline void get_tree(struct audit_tree *tree)\r\n{\r\natomic_inc(&tree->count);\r\n}\r\nstatic inline void put_tree(struct audit_tree *tree)\r\n{\r\nif (atomic_dec_and_test(&tree->count))\r\nkfree_rcu(tree, head);\r\n}\r\nconst char *audit_tree_path(struct audit_tree *tree)\r\n{\r\nreturn tree->pathname;\r\n}\r\nstatic void free_chunk(struct audit_chunk *chunk)\r\n{\r\nint i;\r\nfor (i = 0; i < chunk->count; i++) {\r\nif (chunk->owners[i].owner)\r\nput_tree(chunk->owners[i].owner);\r\n}\r\nkfree(chunk);\r\n}\r\nvoid audit_put_chunk(struct audit_chunk *chunk)\r\n{\r\nif (atomic_long_dec_and_test(&chunk->refs))\r\nfree_chunk(chunk);\r\n}\r\nstatic void __put_chunk(struct rcu_head *rcu)\r\n{\r\nstruct audit_chunk *chunk = container_of(rcu, struct audit_chunk, head);\r\naudit_put_chunk(chunk);\r\n}\r\nstatic void audit_tree_destroy_watch(struct fsnotify_mark *entry)\r\n{\r\nstruct audit_chunk *chunk = container_of(entry, struct audit_chunk, mark);\r\ncall_rcu(&chunk->head, __put_chunk);\r\n}\r\nstatic struct audit_chunk *alloc_chunk(int count)\r\n{\r\nstruct audit_chunk *chunk;\r\nsize_t size;\r\nint i;\r\nsize = offsetof(struct audit_chunk, owners) + count * sizeof(struct node);\r\nchunk = kzalloc(size, GFP_KERNEL);\r\nif (!chunk)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&chunk->hash);\r\nINIT_LIST_HEAD(&chunk->trees);\r\nchunk->count = count;\r\natomic_long_set(&chunk->refs, 1);\r\nfor (i = 0; i < count; i++) {\r\nINIT_LIST_HEAD(&chunk->owners[i].list);\r\nchunk->owners[i].index = i;\r\n}\r\nfsnotify_init_mark(&chunk->mark, audit_tree_destroy_watch);\r\nchunk->mark.mask = FS_IN_IGNORED;\r\nreturn chunk;\r\n}\r\nstatic inline struct list_head *chunk_hash(const struct inode *inode)\r\n{\r\nunsigned long n = (unsigned long)inode / L1_CACHE_BYTES;\r\nreturn chunk_hash_heads + n % HASH_SIZE;\r\n}\r\nstatic void insert_hash(struct audit_chunk *chunk)\r\n{\r\nstruct fsnotify_mark *entry = &chunk->mark;\r\nstruct list_head *list;\r\nif (!entry->inode)\r\nreturn;\r\nlist = chunk_hash(entry->inode);\r\nlist_add_rcu(&chunk->hash, list);\r\n}\r\nstruct audit_chunk *audit_tree_lookup(const struct inode *inode)\r\n{\r\nstruct list_head *list = chunk_hash(inode);\r\nstruct audit_chunk *p;\r\nlist_for_each_entry_rcu(p, list, hash) {\r\nif (p->mark.inode == inode) {\r\natomic_long_inc(&p->refs);\r\nreturn p;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nint audit_tree_match(struct audit_chunk *chunk, struct audit_tree *tree)\r\n{\r\nint n;\r\nfor (n = 0; n < chunk->count; n++)\r\nif (chunk->owners[n].owner == tree)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic struct audit_chunk *find_chunk(struct node *p)\r\n{\r\nint index = p->index & ~(1U<<31);\r\np -= index;\r\nreturn container_of(p, struct audit_chunk, owners[0]);\r\n}\r\nstatic void untag_chunk(struct node *p)\r\n{\r\nstruct audit_chunk *chunk = find_chunk(p);\r\nstruct fsnotify_mark *entry = &chunk->mark;\r\nstruct audit_chunk *new = NULL;\r\nstruct audit_tree *owner;\r\nint size = chunk->count - 1;\r\nint i, j;\r\nfsnotify_get_mark(entry);\r\nspin_unlock(&hash_lock);\r\nif (size)\r\nnew = alloc_chunk(size);\r\nspin_lock(&entry->lock);\r\nif (chunk->dead || !entry->inode) {\r\nspin_unlock(&entry->lock);\r\nif (new)\r\nfree_chunk(new);\r\ngoto out;\r\n}\r\nowner = p->owner;\r\nif (!size) {\r\nchunk->dead = 1;\r\nspin_lock(&hash_lock);\r\nlist_del_init(&chunk->trees);\r\nif (owner->root == chunk)\r\nowner->root = NULL;\r\nlist_del_init(&p->list);\r\nlist_del_rcu(&chunk->hash);\r\nspin_unlock(&hash_lock);\r\nspin_unlock(&entry->lock);\r\nfsnotify_destroy_mark(entry, audit_tree_group);\r\ngoto out;\r\n}\r\nif (!new)\r\ngoto Fallback;\r\nfsnotify_duplicate_mark(&new->mark, entry);\r\nif (fsnotify_add_mark(&new->mark, new->mark.group, new->mark.inode, NULL, 1)) {\r\nfsnotify_put_mark(&new->mark);\r\ngoto Fallback;\r\n}\r\nchunk->dead = 1;\r\nspin_lock(&hash_lock);\r\nlist_replace_init(&chunk->trees, &new->trees);\r\nif (owner->root == chunk) {\r\nlist_del_init(&owner->same_root);\r\nowner->root = NULL;\r\n}\r\nfor (i = j = 0; j <= size; i++, j++) {\r\nstruct audit_tree *s;\r\nif (&chunk->owners[j] == p) {\r\nlist_del_init(&p->list);\r\ni--;\r\ncontinue;\r\n}\r\ns = chunk->owners[j].owner;\r\nnew->owners[i].owner = s;\r\nnew->owners[i].index = chunk->owners[j].index - j + i;\r\nif (!s)\r\ncontinue;\r\nget_tree(s);\r\nlist_replace_init(&chunk->owners[j].list, &new->owners[i].list);\r\n}\r\nlist_replace_rcu(&chunk->hash, &new->hash);\r\nlist_for_each_entry(owner, &new->trees, same_root)\r\nowner->root = new;\r\nspin_unlock(&hash_lock);\r\nspin_unlock(&entry->lock);\r\nfsnotify_destroy_mark(entry, audit_tree_group);\r\nfsnotify_put_mark(&new->mark);\r\ngoto out;\r\nFallback:\r\nspin_lock(&hash_lock);\r\nif (owner->root == chunk) {\r\nlist_del_init(&owner->same_root);\r\nowner->root = NULL;\r\n}\r\nlist_del_init(&p->list);\r\np->owner = NULL;\r\nput_tree(owner);\r\nspin_unlock(&hash_lock);\r\nspin_unlock(&entry->lock);\r\nout:\r\nfsnotify_put_mark(entry);\r\nspin_lock(&hash_lock);\r\n}\r\nstatic int create_chunk(struct inode *inode, struct audit_tree *tree)\r\n{\r\nstruct fsnotify_mark *entry;\r\nstruct audit_chunk *chunk = alloc_chunk(1);\r\nif (!chunk)\r\nreturn -ENOMEM;\r\nentry = &chunk->mark;\r\nif (fsnotify_add_mark(entry, audit_tree_group, inode, NULL, 0)) {\r\nfsnotify_put_mark(entry);\r\nreturn -ENOSPC;\r\n}\r\nspin_lock(&entry->lock);\r\nspin_lock(&hash_lock);\r\nif (tree->goner) {\r\nspin_unlock(&hash_lock);\r\nchunk->dead = 1;\r\nspin_unlock(&entry->lock);\r\nfsnotify_destroy_mark(entry, audit_tree_group);\r\nfsnotify_put_mark(entry);\r\nreturn 0;\r\n}\r\nchunk->owners[0].index = (1U << 31);\r\nchunk->owners[0].owner = tree;\r\nget_tree(tree);\r\nlist_add(&chunk->owners[0].list, &tree->chunks);\r\nif (!tree->root) {\r\ntree->root = chunk;\r\nlist_add(&tree->same_root, &chunk->trees);\r\n}\r\ninsert_hash(chunk);\r\nspin_unlock(&hash_lock);\r\nspin_unlock(&entry->lock);\r\nfsnotify_put_mark(entry);\r\nreturn 0;\r\n}\r\nstatic int tag_chunk(struct inode *inode, struct audit_tree *tree)\r\n{\r\nstruct fsnotify_mark *old_entry, *chunk_entry;\r\nstruct audit_tree *owner;\r\nstruct audit_chunk *chunk, *old;\r\nstruct node *p;\r\nint n;\r\nold_entry = fsnotify_find_inode_mark(audit_tree_group, inode);\r\nif (!old_entry)\r\nreturn create_chunk(inode, tree);\r\nold = container_of(old_entry, struct audit_chunk, mark);\r\nspin_lock(&hash_lock);\r\nfor (n = 0; n < old->count; n++) {\r\nif (old->owners[n].owner == tree) {\r\nspin_unlock(&hash_lock);\r\nfsnotify_put_mark(old_entry);\r\nreturn 0;\r\n}\r\n}\r\nspin_unlock(&hash_lock);\r\nchunk = alloc_chunk(old->count + 1);\r\nif (!chunk) {\r\nfsnotify_put_mark(old_entry);\r\nreturn -ENOMEM;\r\n}\r\nchunk_entry = &chunk->mark;\r\nspin_lock(&old_entry->lock);\r\nif (!old_entry->inode) {\r\nspin_unlock(&old_entry->lock);\r\nfsnotify_put_mark(old_entry);\r\nfree_chunk(chunk);\r\nreturn -ENOENT;\r\n}\r\nfsnotify_duplicate_mark(chunk_entry, old_entry);\r\nif (fsnotify_add_mark(chunk_entry, chunk_entry->group, chunk_entry->inode, NULL, 1)) {\r\nspin_unlock(&old_entry->lock);\r\nfsnotify_put_mark(chunk_entry);\r\nfsnotify_put_mark(old_entry);\r\nreturn -ENOSPC;\r\n}\r\nspin_lock(&chunk_entry->lock);\r\nspin_lock(&hash_lock);\r\nif (tree->goner) {\r\nspin_unlock(&hash_lock);\r\nchunk->dead = 1;\r\nspin_unlock(&chunk_entry->lock);\r\nspin_unlock(&old_entry->lock);\r\nfsnotify_destroy_mark(chunk_entry, audit_tree_group);\r\nfsnotify_put_mark(chunk_entry);\r\nfsnotify_put_mark(old_entry);\r\nreturn 0;\r\n}\r\nlist_replace_init(&old->trees, &chunk->trees);\r\nfor (n = 0, p = chunk->owners; n < old->count; n++, p++) {\r\nstruct audit_tree *s = old->owners[n].owner;\r\np->owner = s;\r\np->index = old->owners[n].index;\r\nif (!s)\r\ncontinue;\r\nget_tree(s);\r\nlist_replace_init(&old->owners[n].list, &p->list);\r\n}\r\np->index = (chunk->count - 1) | (1U<<31);\r\np->owner = tree;\r\nget_tree(tree);\r\nlist_add(&p->list, &tree->chunks);\r\nlist_replace_rcu(&old->hash, &chunk->hash);\r\nlist_for_each_entry(owner, &chunk->trees, same_root)\r\nowner->root = chunk;\r\nold->dead = 1;\r\nif (!tree->root) {\r\ntree->root = chunk;\r\nlist_add(&tree->same_root, &chunk->trees);\r\n}\r\nspin_unlock(&hash_lock);\r\nspin_unlock(&chunk_entry->lock);\r\nspin_unlock(&old_entry->lock);\r\nfsnotify_destroy_mark(old_entry, audit_tree_group);\r\nfsnotify_put_mark(chunk_entry);\r\nfsnotify_put_mark(old_entry);\r\nreturn 0;\r\n}\r\nstatic void audit_tree_log_remove_rule(struct audit_krule *rule)\r\n{\r\nstruct audit_buffer *ab;\r\nab = audit_log_start(NULL, GFP_KERNEL, AUDIT_CONFIG_CHANGE);\r\nif (unlikely(!ab))\r\nreturn;\r\naudit_log_format(ab, "op=");\r\naudit_log_string(ab, "remove_rule");\r\naudit_log_format(ab, " dir=");\r\naudit_log_untrustedstring(ab, rule->tree->pathname);\r\naudit_log_key(ab, rule->filterkey);\r\naudit_log_format(ab, " list=%d res=1", rule->listnr);\r\naudit_log_end(ab);\r\n}\r\nstatic void kill_rules(struct audit_tree *tree)\r\n{\r\nstruct audit_krule *rule, *next;\r\nstruct audit_entry *entry;\r\nlist_for_each_entry_safe(rule, next, &tree->rules, rlist) {\r\nentry = container_of(rule, struct audit_entry, rule);\r\nlist_del_init(&rule->rlist);\r\nif (rule->tree) {\r\naudit_tree_log_remove_rule(rule);\r\nrule->tree = NULL;\r\nlist_del_rcu(&entry->list);\r\nlist_del(&entry->rule.list);\r\ncall_rcu(&entry->rcu, audit_free_rule_rcu);\r\n}\r\n}\r\n}\r\nstatic void prune_one(struct audit_tree *victim)\r\n{\r\nspin_lock(&hash_lock);\r\nwhile (!list_empty(&victim->chunks)) {\r\nstruct node *p;\r\np = list_entry(victim->chunks.next, struct node, list);\r\nuntag_chunk(p);\r\n}\r\nspin_unlock(&hash_lock);\r\nput_tree(victim);\r\n}\r\nstatic void trim_marked(struct audit_tree *tree)\r\n{\r\nstruct list_head *p, *q;\r\nspin_lock(&hash_lock);\r\nif (tree->goner) {\r\nspin_unlock(&hash_lock);\r\nreturn;\r\n}\r\nfor (p = tree->chunks.next; p != &tree->chunks; p = q) {\r\nstruct node *node = list_entry(p, struct node, list);\r\nq = p->next;\r\nif (node->index & (1U<<31)) {\r\nlist_del_init(p);\r\nlist_add(p, &tree->chunks);\r\n}\r\n}\r\nwhile (!list_empty(&tree->chunks)) {\r\nstruct node *node;\r\nnode = list_entry(tree->chunks.next, struct node, list);\r\nif (!(node->index & (1U<<31)))\r\nbreak;\r\nuntag_chunk(node);\r\n}\r\nif (!tree->root && !tree->goner) {\r\ntree->goner = 1;\r\nspin_unlock(&hash_lock);\r\nmutex_lock(&audit_filter_mutex);\r\nkill_rules(tree);\r\nlist_del_init(&tree->list);\r\nmutex_unlock(&audit_filter_mutex);\r\nprune_one(tree);\r\n} else {\r\nspin_unlock(&hash_lock);\r\n}\r\n}\r\nint audit_remove_tree_rule(struct audit_krule *rule)\r\n{\r\nstruct audit_tree *tree;\r\ntree = rule->tree;\r\nif (tree) {\r\nspin_lock(&hash_lock);\r\nlist_del_init(&rule->rlist);\r\nif (list_empty(&tree->rules) && !tree->goner) {\r\ntree->root = NULL;\r\nlist_del_init(&tree->same_root);\r\ntree->goner = 1;\r\nlist_move(&tree->list, &prune_list);\r\nrule->tree = NULL;\r\nspin_unlock(&hash_lock);\r\naudit_schedule_prune();\r\nreturn 1;\r\n}\r\nrule->tree = NULL;\r\nspin_unlock(&hash_lock);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int compare_root(struct vfsmount *mnt, void *arg)\r\n{\r\nreturn d_backing_inode(mnt->mnt_root) == arg;\r\n}\r\nvoid audit_trim_trees(void)\r\n{\r\nstruct list_head cursor;\r\nmutex_lock(&audit_filter_mutex);\r\nlist_add(&cursor, &tree_list);\r\nwhile (cursor.next != &tree_list) {\r\nstruct audit_tree *tree;\r\nstruct path path;\r\nstruct vfsmount *root_mnt;\r\nstruct node *node;\r\nint err;\r\ntree = container_of(cursor.next, struct audit_tree, list);\r\nget_tree(tree);\r\nlist_del(&cursor);\r\nlist_add(&cursor, &tree->list);\r\nmutex_unlock(&audit_filter_mutex);\r\nerr = kern_path(tree->pathname, 0, &path);\r\nif (err)\r\ngoto skip_it;\r\nroot_mnt = collect_mounts(&path);\r\npath_put(&path);\r\nif (IS_ERR(root_mnt))\r\ngoto skip_it;\r\nspin_lock(&hash_lock);\r\nlist_for_each_entry(node, &tree->chunks, list) {\r\nstruct audit_chunk *chunk = find_chunk(node);\r\nstruct inode *inode = chunk->mark.inode;\r\nnode->index |= 1U<<31;\r\nif (iterate_mounts(compare_root, inode, root_mnt))\r\nnode->index &= ~(1U<<31);\r\n}\r\nspin_unlock(&hash_lock);\r\ntrim_marked(tree);\r\ndrop_collected_mounts(root_mnt);\r\nskip_it:\r\nput_tree(tree);\r\nmutex_lock(&audit_filter_mutex);\r\n}\r\nlist_del(&cursor);\r\nmutex_unlock(&audit_filter_mutex);\r\n}\r\nint audit_make_tree(struct audit_krule *rule, char *pathname, u32 op)\r\n{\r\nif (pathname[0] != '/' ||\r\nrule->listnr != AUDIT_FILTER_EXIT ||\r\nop != Audit_equal ||\r\nrule->inode_f || rule->watch || rule->tree)\r\nreturn -EINVAL;\r\nrule->tree = alloc_tree(pathname);\r\nif (!rule->tree)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid audit_put_tree(struct audit_tree *tree)\r\n{\r\nput_tree(tree);\r\n}\r\nstatic int tag_mount(struct vfsmount *mnt, void *arg)\r\n{\r\nreturn tag_chunk(d_backing_inode(mnt->mnt_root), arg);\r\n}\r\nstatic int prune_tree_thread(void *unused)\r\n{\r\nfor (;;) {\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nif (list_empty(&prune_list))\r\nschedule();\r\n__set_current_state(TASK_RUNNING);\r\nmutex_lock(&audit_cmd_mutex);\r\nmutex_lock(&audit_filter_mutex);\r\nwhile (!list_empty(&prune_list)) {\r\nstruct audit_tree *victim;\r\nvictim = list_entry(prune_list.next,\r\nstruct audit_tree, list);\r\nlist_del_init(&victim->list);\r\nmutex_unlock(&audit_filter_mutex);\r\nprune_one(victim);\r\nmutex_lock(&audit_filter_mutex);\r\n}\r\nmutex_unlock(&audit_filter_mutex);\r\nmutex_unlock(&audit_cmd_mutex);\r\n}\r\nreturn 0;\r\n}\r\nstatic int audit_launch_prune(void)\r\n{\r\nif (prune_thread)\r\nreturn 0;\r\nprune_thread = kthread_create(prune_tree_thread, NULL,\r\n"audit_prune_tree");\r\nif (IS_ERR(prune_thread)) {\r\npr_err("cannot start thread audit_prune_tree");\r\nprune_thread = NULL;\r\nreturn -ENOMEM;\r\n} else {\r\nwake_up_process(prune_thread);\r\nreturn 0;\r\n}\r\n}\r\nint audit_add_tree_rule(struct audit_krule *rule)\r\n{\r\nstruct audit_tree *seed = rule->tree, *tree;\r\nstruct path path;\r\nstruct vfsmount *mnt;\r\nint err;\r\nrule->tree = NULL;\r\nlist_for_each_entry(tree, &tree_list, list) {\r\nif (!strcmp(seed->pathname, tree->pathname)) {\r\nput_tree(seed);\r\nrule->tree = tree;\r\nlist_add(&rule->rlist, &tree->rules);\r\nreturn 0;\r\n}\r\n}\r\ntree = seed;\r\nlist_add(&tree->list, &tree_list);\r\nlist_add(&rule->rlist, &tree->rules);\r\nmutex_unlock(&audit_filter_mutex);\r\nif (unlikely(!prune_thread)) {\r\nerr = audit_launch_prune();\r\nif (err)\r\ngoto Err;\r\n}\r\nerr = kern_path(tree->pathname, 0, &path);\r\nif (err)\r\ngoto Err;\r\nmnt = collect_mounts(&path);\r\npath_put(&path);\r\nif (IS_ERR(mnt)) {\r\nerr = PTR_ERR(mnt);\r\ngoto Err;\r\n}\r\nget_tree(tree);\r\nerr = iterate_mounts(tag_mount, tree, mnt);\r\ndrop_collected_mounts(mnt);\r\nif (!err) {\r\nstruct node *node;\r\nspin_lock(&hash_lock);\r\nlist_for_each_entry(node, &tree->chunks, list)\r\nnode->index &= ~(1U<<31);\r\nspin_unlock(&hash_lock);\r\n} else {\r\ntrim_marked(tree);\r\ngoto Err;\r\n}\r\nmutex_lock(&audit_filter_mutex);\r\nif (list_empty(&rule->rlist)) {\r\nput_tree(tree);\r\nreturn -ENOENT;\r\n}\r\nrule->tree = tree;\r\nput_tree(tree);\r\nreturn 0;\r\nErr:\r\nmutex_lock(&audit_filter_mutex);\r\nlist_del_init(&tree->list);\r\nlist_del_init(&tree->rules);\r\nput_tree(tree);\r\nreturn err;\r\n}\r\nint audit_tag_tree(char *old, char *new)\r\n{\r\nstruct list_head cursor, barrier;\r\nint failed = 0;\r\nstruct path path1, path2;\r\nstruct vfsmount *tagged;\r\nint err;\r\nerr = kern_path(new, 0, &path2);\r\nif (err)\r\nreturn err;\r\ntagged = collect_mounts(&path2);\r\npath_put(&path2);\r\nif (IS_ERR(tagged))\r\nreturn PTR_ERR(tagged);\r\nerr = kern_path(old, 0, &path1);\r\nif (err) {\r\ndrop_collected_mounts(tagged);\r\nreturn err;\r\n}\r\nmutex_lock(&audit_filter_mutex);\r\nlist_add(&barrier, &tree_list);\r\nlist_add(&cursor, &barrier);\r\nwhile (cursor.next != &tree_list) {\r\nstruct audit_tree *tree;\r\nint good_one = 0;\r\ntree = container_of(cursor.next, struct audit_tree, list);\r\nget_tree(tree);\r\nlist_del(&cursor);\r\nlist_add(&cursor, &tree->list);\r\nmutex_unlock(&audit_filter_mutex);\r\nerr = kern_path(tree->pathname, 0, &path2);\r\nif (!err) {\r\ngood_one = path_is_under(&path1, &path2);\r\npath_put(&path2);\r\n}\r\nif (!good_one) {\r\nput_tree(tree);\r\nmutex_lock(&audit_filter_mutex);\r\ncontinue;\r\n}\r\nfailed = iterate_mounts(tag_mount, tree, tagged);\r\nif (failed) {\r\nput_tree(tree);\r\nmutex_lock(&audit_filter_mutex);\r\nbreak;\r\n}\r\nmutex_lock(&audit_filter_mutex);\r\nspin_lock(&hash_lock);\r\nif (!tree->goner) {\r\nlist_del(&tree->list);\r\nlist_add(&tree->list, &tree_list);\r\n}\r\nspin_unlock(&hash_lock);\r\nput_tree(tree);\r\n}\r\nwhile (barrier.prev != &tree_list) {\r\nstruct audit_tree *tree;\r\ntree = container_of(barrier.prev, struct audit_tree, list);\r\nget_tree(tree);\r\nlist_del(&tree->list);\r\nlist_add(&tree->list, &barrier);\r\nmutex_unlock(&audit_filter_mutex);\r\nif (!failed) {\r\nstruct node *node;\r\nspin_lock(&hash_lock);\r\nlist_for_each_entry(node, &tree->chunks, list)\r\nnode->index &= ~(1U<<31);\r\nspin_unlock(&hash_lock);\r\n} else {\r\ntrim_marked(tree);\r\n}\r\nput_tree(tree);\r\nmutex_lock(&audit_filter_mutex);\r\n}\r\nlist_del(&barrier);\r\nlist_del(&cursor);\r\nmutex_unlock(&audit_filter_mutex);\r\npath_put(&path1);\r\ndrop_collected_mounts(tagged);\r\nreturn failed;\r\n}\r\nstatic void audit_schedule_prune(void)\r\n{\r\nwake_up_process(prune_thread);\r\n}\r\nvoid audit_kill_trees(struct list_head *list)\r\n{\r\nmutex_lock(&audit_cmd_mutex);\r\nmutex_lock(&audit_filter_mutex);\r\nwhile (!list_empty(list)) {\r\nstruct audit_tree *victim;\r\nvictim = list_entry(list->next, struct audit_tree, list);\r\nkill_rules(victim);\r\nlist_del_init(&victim->list);\r\nmutex_unlock(&audit_filter_mutex);\r\nprune_one(victim);\r\nmutex_lock(&audit_filter_mutex);\r\n}\r\nmutex_unlock(&audit_filter_mutex);\r\nmutex_unlock(&audit_cmd_mutex);\r\n}\r\nstatic void evict_chunk(struct audit_chunk *chunk)\r\n{\r\nstruct audit_tree *owner;\r\nstruct list_head *postponed = audit_killed_trees();\r\nint need_prune = 0;\r\nint n;\r\nif (chunk->dead)\r\nreturn;\r\nchunk->dead = 1;\r\nmutex_lock(&audit_filter_mutex);\r\nspin_lock(&hash_lock);\r\nwhile (!list_empty(&chunk->trees)) {\r\nowner = list_entry(chunk->trees.next,\r\nstruct audit_tree, same_root);\r\nowner->goner = 1;\r\nowner->root = NULL;\r\nlist_del_init(&owner->same_root);\r\nspin_unlock(&hash_lock);\r\nif (!postponed) {\r\nkill_rules(owner);\r\nlist_move(&owner->list, &prune_list);\r\nneed_prune = 1;\r\n} else {\r\nlist_move(&owner->list, postponed);\r\n}\r\nspin_lock(&hash_lock);\r\n}\r\nlist_del_rcu(&chunk->hash);\r\nfor (n = 0; n < chunk->count; n++)\r\nlist_del_init(&chunk->owners[n].list);\r\nspin_unlock(&hash_lock);\r\nmutex_unlock(&audit_filter_mutex);\r\nif (need_prune)\r\naudit_schedule_prune();\r\n}\r\nstatic int audit_tree_handle_event(struct fsnotify_group *group,\r\nstruct inode *to_tell,\r\nstruct fsnotify_mark *inode_mark,\r\nstruct fsnotify_mark *vfsmount_mark,\r\nu32 mask, void *data, int data_type,\r\nconst unsigned char *file_name, u32 cookie)\r\n{\r\nreturn 0;\r\n}\r\nstatic void audit_tree_freeing_mark(struct fsnotify_mark *entry, struct fsnotify_group *group)\r\n{\r\nstruct audit_chunk *chunk = container_of(entry, struct audit_chunk, mark);\r\nevict_chunk(chunk);\r\nBUG_ON(atomic_read(&entry->refcnt) < 1);\r\n}\r\nstatic int __init audit_tree_init(void)\r\n{\r\nint i;\r\naudit_tree_group = fsnotify_alloc_group(&audit_tree_ops);\r\nif (IS_ERR(audit_tree_group))\r\naudit_panic("cannot initialize fsnotify group for rectree watches");\r\nfor (i = 0; i < HASH_SIZE; i++)\r\nINIT_LIST_HEAD(&chunk_hash_heads[i]);\r\nreturn 0;\r\n}
