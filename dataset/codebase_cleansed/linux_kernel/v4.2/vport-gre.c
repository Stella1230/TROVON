static __be32 be64_get_low32(__be64 x)\r\n{\r\n#ifdef __BIG_ENDIAN\r\nreturn (__force __be32)x;\r\n#else\r\nreturn (__force __be32)((__force u64)x >> 32);\r\n#endif\r\n}\r\nstatic __be16 filter_tnl_flags(__be16 flags)\r\n{\r\nreturn flags & (TUNNEL_CSUM | TUNNEL_KEY);\r\n}\r\nstatic struct sk_buff *__build_header(struct sk_buff *skb,\r\nint tunnel_hlen)\r\n{\r\nstruct tnl_ptk_info tpi;\r\nconst struct ovs_key_ipv4_tunnel *tun_key;\r\ntun_key = &OVS_CB(skb)->egress_tun_info->tunnel;\r\nskb = gre_handle_offloads(skb, !!(tun_key->tun_flags & TUNNEL_CSUM));\r\nif (IS_ERR(skb))\r\nreturn skb;\r\ntpi.flags = filter_tnl_flags(tun_key->tun_flags);\r\ntpi.proto = htons(ETH_P_TEB);\r\ntpi.key = be64_get_low32(tun_key->tun_id);\r\ntpi.seq = 0;\r\ngre_build_header(skb, &tpi, tunnel_hlen);\r\nreturn skb;\r\n}\r\nstatic __be64 key_to_tunnel_id(__be32 key, __be32 seq)\r\n{\r\n#ifdef __BIG_ENDIAN\r\nreturn (__force __be64)((__force u64)seq << 32 | (__force u32)key);\r\n#else\r\nreturn (__force __be64)((__force u64)key << 32 | (__force u32)seq);\r\n#endif\r\n}\r\nstatic int gre_rcv(struct sk_buff *skb,\r\nconst struct tnl_ptk_info *tpi)\r\n{\r\nstruct ovs_tunnel_info tun_info;\r\nstruct ovs_net *ovs_net;\r\nstruct vport *vport;\r\n__be64 key;\r\novs_net = net_generic(dev_net(skb->dev), ovs_net_id);\r\nvport = rcu_dereference(ovs_net->vport_net.gre_vport);\r\nif (unlikely(!vport))\r\nreturn PACKET_REJECT;\r\nkey = key_to_tunnel_id(tpi->key, tpi->seq);\r\novs_flow_tun_info_init(&tun_info, ip_hdr(skb), 0, 0, key,\r\nfilter_tnl_flags(tpi->flags), NULL, 0);\r\novs_vport_receive(vport, skb, &tun_info);\r\nreturn PACKET_RCVD;\r\n}\r\nstatic int gre_err(struct sk_buff *skb, u32 info,\r\nconst struct tnl_ptk_info *tpi)\r\n{\r\nstruct ovs_net *ovs_net;\r\nstruct vport *vport;\r\novs_net = net_generic(dev_net(skb->dev), ovs_net_id);\r\nvport = rcu_dereference(ovs_net->vport_net.gre_vport);\r\nif (unlikely(!vport))\r\nreturn PACKET_REJECT;\r\nelse\r\nreturn PACKET_RCVD;\r\n}\r\nstatic int gre_tnl_send(struct vport *vport, struct sk_buff *skb)\r\n{\r\nstruct net *net = ovs_dp_get_net(vport->dp);\r\nconst struct ovs_key_ipv4_tunnel *tun_key;\r\nstruct flowi4 fl;\r\nstruct rtable *rt;\r\nint min_headroom;\r\nint tunnel_hlen;\r\n__be16 df;\r\nint err;\r\nif (unlikely(!OVS_CB(skb)->egress_tun_info)) {\r\nerr = -EINVAL;\r\ngoto err_free_skb;\r\n}\r\ntun_key = &OVS_CB(skb)->egress_tun_info->tunnel;\r\nrt = ovs_tunnel_route_lookup(net, tun_key, skb->mark, &fl, IPPROTO_GRE);\r\nif (IS_ERR(rt)) {\r\nerr = PTR_ERR(rt);\r\ngoto err_free_skb;\r\n}\r\ntunnel_hlen = ip_gre_calc_hlen(tun_key->tun_flags);\r\nmin_headroom = LL_RESERVED_SPACE(rt->dst.dev) + rt->dst.header_len\r\n+ tunnel_hlen + sizeof(struct iphdr)\r\n+ (skb_vlan_tag_present(skb) ? VLAN_HLEN : 0);\r\nif (skb_headroom(skb) < min_headroom || skb_header_cloned(skb)) {\r\nint head_delta = SKB_DATA_ALIGN(min_headroom -\r\nskb_headroom(skb) +\r\n16);\r\nerr = pskb_expand_head(skb, max_t(int, head_delta, 0),\r\n0, GFP_ATOMIC);\r\nif (unlikely(err))\r\ngoto err_free_rt;\r\n}\r\nskb = vlan_hwaccel_push_inside(skb);\r\nif (unlikely(!skb)) {\r\nerr = -ENOMEM;\r\ngoto err_free_rt;\r\n}\r\nskb = __build_header(skb, tunnel_hlen);\r\nif (IS_ERR(skb)) {\r\nerr = PTR_ERR(skb);\r\nskb = NULL;\r\ngoto err_free_rt;\r\n}\r\ndf = tun_key->tun_flags & TUNNEL_DONT_FRAGMENT ?\r\nhtons(IP_DF) : 0;\r\nskb->ignore_df = 1;\r\nreturn iptunnel_xmit(skb->sk, rt, skb, fl.saddr,\r\ntun_key->ipv4_dst, IPPROTO_GRE,\r\ntun_key->ipv4_tos, tun_key->ipv4_ttl, df, false);\r\nerr_free_rt:\r\nip_rt_put(rt);\r\nerr_free_skb:\r\nkfree_skb(skb);\r\nreturn err;\r\n}\r\nstatic int gre_init(void)\r\n{\r\nint err;\r\ngre_ports++;\r\nif (gre_ports > 1)\r\nreturn 0;\r\nerr = gre_cisco_register(&gre_protocol);\r\nif (err)\r\npr_warn("cannot register gre protocol handler\n");\r\nreturn err;\r\n}\r\nstatic void gre_exit(void)\r\n{\r\ngre_ports--;\r\nif (gre_ports > 0)\r\nreturn;\r\ngre_cisco_unregister(&gre_protocol);\r\n}\r\nstatic const char *gre_get_name(const struct vport *vport)\r\n{\r\nreturn vport_priv(vport);\r\n}\r\nstatic struct vport *gre_create(const struct vport_parms *parms)\r\n{\r\nstruct net *net = ovs_dp_get_net(parms->dp);\r\nstruct ovs_net *ovs_net;\r\nstruct vport *vport;\r\nint err;\r\nerr = gre_init();\r\nif (err)\r\nreturn ERR_PTR(err);\r\novs_net = net_generic(net, ovs_net_id);\r\nif (ovsl_dereference(ovs_net->vport_net.gre_vport)) {\r\nvport = ERR_PTR(-EEXIST);\r\ngoto error;\r\n}\r\nvport = ovs_vport_alloc(IFNAMSIZ, &ovs_gre_vport_ops, parms);\r\nif (IS_ERR(vport))\r\ngoto error;\r\nstrncpy(vport_priv(vport), parms->name, IFNAMSIZ);\r\nrcu_assign_pointer(ovs_net->vport_net.gre_vport, vport);\r\nreturn vport;\r\nerror:\r\ngre_exit();\r\nreturn vport;\r\n}\r\nstatic void gre_tnl_destroy(struct vport *vport)\r\n{\r\nstruct net *net = ovs_dp_get_net(vport->dp);\r\nstruct ovs_net *ovs_net;\r\novs_net = net_generic(net, ovs_net_id);\r\nRCU_INIT_POINTER(ovs_net->vport_net.gre_vport, NULL);\r\novs_vport_deferred_free(vport);\r\ngre_exit();\r\n}\r\nstatic int gre_get_egress_tun_info(struct vport *vport, struct sk_buff *skb,\r\nstruct ovs_tunnel_info *egress_tun_info)\r\n{\r\nreturn ovs_tunnel_get_egress_info(egress_tun_info,\r\novs_dp_get_net(vport->dp),\r\nOVS_CB(skb)->egress_tun_info,\r\nIPPROTO_GRE, skb->mark, 0, 0);\r\n}\r\nstatic int __init ovs_gre_tnl_init(void)\r\n{\r\nreturn ovs_vport_ops_register(&ovs_gre_vport_ops);\r\n}\r\nstatic void __exit ovs_gre_tnl_exit(void)\r\n{\r\novs_vport_ops_unregister(&ovs_gre_vport_ops);\r\n}
