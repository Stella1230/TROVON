static irqreturn_t\r\ncsio_nondata_isr(int irq, void *dev_id)\r\n{\r\nstruct csio_hw *hw = (struct csio_hw *) dev_id;\r\nint rv;\r\nunsigned long flags;\r\nif (unlikely(!hw))\r\nreturn IRQ_NONE;\r\nif (unlikely(pci_channel_offline(hw->pdev))) {\r\nCSIO_INC_STATS(hw, n_pcich_offline);\r\nreturn IRQ_NONE;\r\n}\r\nspin_lock_irqsave(&hw->lock, flags);\r\ncsio_hw_slow_intr_handler(hw);\r\nrv = csio_mb_isr_handler(hw);\r\nif (rv == 0 && !(hw->flags & CSIO_HWF_FWEVT_PENDING)) {\r\nhw->flags |= CSIO_HWF_FWEVT_PENDING;\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\nschedule_work(&hw->evtq_work);\r\nreturn IRQ_HANDLED;\r\n}\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void\r\ncsio_fwevt_handler(struct csio_hw *hw)\r\n{\r\nint rv;\r\nunsigned long flags;\r\nrv = csio_fwevtq_handler(hw);\r\nspin_lock_irqsave(&hw->lock, flags);\r\nif (rv == 0 && !(hw->flags & CSIO_HWF_FWEVT_PENDING)) {\r\nhw->flags |= CSIO_HWF_FWEVT_PENDING;\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\nschedule_work(&hw->evtq_work);\r\nreturn;\r\n}\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\n}\r\nstatic irqreturn_t\r\ncsio_fwevt_isr(int irq, void *dev_id)\r\n{\r\nstruct csio_hw *hw = (struct csio_hw *) dev_id;\r\nif (unlikely(!hw))\r\nreturn IRQ_NONE;\r\nif (unlikely(pci_channel_offline(hw->pdev))) {\r\nCSIO_INC_STATS(hw, n_pcich_offline);\r\nreturn IRQ_NONE;\r\n}\r\ncsio_fwevt_handler(hw);\r\nreturn IRQ_HANDLED;\r\n}\r\nvoid\r\ncsio_fwevt_intx_handler(struct csio_hw *hw, void *wr, uint32_t len,\r\nstruct csio_fl_dma_buf *flb, void *priv)\r\n{\r\ncsio_fwevt_handler(hw);\r\n}\r\nstatic void\r\ncsio_process_scsi_cmpl(struct csio_hw *hw, void *wr, uint32_t len,\r\nstruct csio_fl_dma_buf *flb, void *cbfn_q)\r\n{\r\nstruct csio_ioreq *ioreq;\r\nuint8_t *scsiwr;\r\nuint8_t subop;\r\nvoid *cmnd;\r\nunsigned long flags;\r\nioreq = csio_scsi_cmpl_handler(hw, wr, len, flb, NULL, &scsiwr);\r\nif (likely(ioreq)) {\r\nif (unlikely(*scsiwr == FW_SCSI_ABRT_CLS_WR)) {\r\nsubop = FW_SCSI_ABRT_CLS_WR_SUB_OPCODE_GET(\r\n((struct fw_scsi_abrt_cls_wr *)\r\nscsiwr)->sub_opcode_to_chk_all_io);\r\ncsio_dbg(hw, "%s cmpl recvd ioreq:%p status:%d\n",\r\nsubop ? "Close" : "Abort",\r\nioreq, ioreq->wr_status);\r\nspin_lock_irqsave(&hw->lock, flags);\r\nif (subop)\r\ncsio_scsi_closed(ioreq,\r\n(struct list_head *)cbfn_q);\r\nelse\r\ncsio_scsi_aborted(ioreq,\r\n(struct list_head *)cbfn_q);\r\ncmnd = csio_scsi_cmnd(ioreq);\r\nif (unlikely(cmnd == NULL))\r\nlist_del_init(&ioreq->sm.sm_list);\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\nif (unlikely(cmnd == NULL))\r\ncsio_put_scsi_ioreq_lock(hw,\r\ncsio_hw_to_scsim(hw), ioreq);\r\n} else {\r\nspin_lock_irqsave(&hw->lock, flags);\r\ncsio_scsi_completed(ioreq, (struct list_head *)cbfn_q);\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\n}\r\n}\r\n}\r\nstatic inline irqreturn_t\r\ncsio_scsi_isr_handler(struct csio_q *iq)\r\n{\r\nstruct csio_hw *hw = (struct csio_hw *)iq->owner;\r\nLIST_HEAD(cbfn_q);\r\nstruct list_head *tmp;\r\nstruct csio_scsim *scm;\r\nstruct csio_ioreq *ioreq;\r\nint isr_completions = 0;\r\nscm = csio_hw_to_scsim(hw);\r\nif (unlikely(csio_wr_process_iq(hw, iq, csio_process_scsi_cmpl,\r\n&cbfn_q) != 0))\r\nreturn IRQ_NONE;\r\nlist_for_each(tmp, &cbfn_q) {\r\nioreq = (struct csio_ioreq *)tmp;\r\nisr_completions++;\r\nioreq->io_cbfn(hw, ioreq);\r\nif (unlikely(ioreq->dcopy))\r\ncsio_put_scsi_ddp_list_lock(hw, scm, &ioreq->gen_list,\r\nioreq->nsge);\r\n}\r\nif (isr_completions) {\r\ncsio_put_scsi_ioreq_list_lock(hw, scm, &cbfn_q,\r\nisr_completions);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t\r\ncsio_scsi_isr(int irq, void *dev_id)\r\n{\r\nstruct csio_q *iq = (struct csio_q *) dev_id;\r\nstruct csio_hw *hw;\r\nif (unlikely(!iq))\r\nreturn IRQ_NONE;\r\nhw = (struct csio_hw *)iq->owner;\r\nif (unlikely(pci_channel_offline(hw->pdev))) {\r\nCSIO_INC_STATS(hw, n_pcich_offline);\r\nreturn IRQ_NONE;\r\n}\r\ncsio_scsi_isr_handler(iq);\r\nreturn IRQ_HANDLED;\r\n}\r\nvoid\r\ncsio_scsi_intx_handler(struct csio_hw *hw, void *wr, uint32_t len,\r\nstruct csio_fl_dma_buf *flb, void *priv)\r\n{\r\nstruct csio_q *iq = priv;\r\ncsio_scsi_isr_handler(iq);\r\n}\r\nstatic irqreturn_t\r\ncsio_fcoe_isr(int irq, void *dev_id)\r\n{\r\nstruct csio_hw *hw = (struct csio_hw *) dev_id;\r\nstruct csio_q *intx_q = NULL;\r\nint rv;\r\nirqreturn_t ret = IRQ_NONE;\r\nunsigned long flags;\r\nif (unlikely(!hw))\r\nreturn IRQ_NONE;\r\nif (unlikely(pci_channel_offline(hw->pdev))) {\r\nCSIO_INC_STATS(hw, n_pcich_offline);\r\nreturn IRQ_NONE;\r\n}\r\nif (hw->intr_mode == CSIO_IM_INTX)\r\ncsio_wr_reg32(hw, 0, MYPF_REG(PCIE_PF_CLI_A));\r\nif (csio_hw_slow_intr_handler(hw))\r\nret = IRQ_HANDLED;\r\nintx_q = csio_get_q(hw, hw->intr_iq_idx);\r\nCSIO_DB_ASSERT(intx_q);\r\nif (likely(csio_wr_process_iq(hw, intx_q, NULL, NULL) == 0))\r\nret = IRQ_HANDLED;\r\nspin_lock_irqsave(&hw->lock, flags);\r\nrv = csio_mb_isr_handler(hw);\r\nif (rv == 0 && !(hw->flags & CSIO_HWF_FWEVT_PENDING)) {\r\nhw->flags |= CSIO_HWF_FWEVT_PENDING;\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\nschedule_work(&hw->evtq_work);\r\nreturn IRQ_HANDLED;\r\n}\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\nreturn ret;\r\n}\r\nstatic void\r\ncsio_add_msix_desc(struct csio_hw *hw)\r\n{\r\nint i;\r\nstruct csio_msix_entries *entryp = &hw->msix_entries[0];\r\nint k = CSIO_EXTRA_VECS;\r\nint len = sizeof(entryp->desc) - 1;\r\nint cnt = hw->num_sqsets + k;\r\nmemset(entryp->desc, 0, len + 1);\r\nsnprintf(entryp->desc, len, "csio-%02x:%02x:%x-nondata",\r\nCSIO_PCI_BUS(hw), CSIO_PCI_DEV(hw), CSIO_PCI_FUNC(hw));\r\nentryp++;\r\nmemset(entryp->desc, 0, len + 1);\r\nsnprintf(entryp->desc, len, "csio-%02x:%02x:%x-fwevt",\r\nCSIO_PCI_BUS(hw), CSIO_PCI_DEV(hw), CSIO_PCI_FUNC(hw));\r\nentryp++;\r\nfor (i = k; i < cnt; i++, entryp++) {\r\nmemset(entryp->desc, 0, len + 1);\r\nsnprintf(entryp->desc, len, "csio-%02x:%02x:%x-scsi%d",\r\nCSIO_PCI_BUS(hw), CSIO_PCI_DEV(hw),\r\nCSIO_PCI_FUNC(hw), i - CSIO_EXTRA_VECS);\r\n}\r\n}\r\nint\r\ncsio_request_irqs(struct csio_hw *hw)\r\n{\r\nint rv, i, j, k = 0;\r\nstruct csio_msix_entries *entryp = &hw->msix_entries[0];\r\nstruct csio_scsi_cpu_info *info;\r\nif (hw->intr_mode != CSIO_IM_MSIX) {\r\nrv = request_irq(hw->pdev->irq, csio_fcoe_isr,\r\n(hw->intr_mode == CSIO_IM_MSI) ?\r\n0 : IRQF_SHARED,\r\nKBUILD_MODNAME, hw);\r\nif (rv) {\r\nif (hw->intr_mode == CSIO_IM_MSI)\r\npci_disable_msi(hw->pdev);\r\ncsio_err(hw, "Failed to allocate interrupt line.\n");\r\nreturn -EINVAL;\r\n}\r\ngoto out;\r\n}\r\ncsio_add_msix_desc(hw);\r\nrv = request_irq(entryp[k].vector, csio_nondata_isr, 0,\r\nentryp[k].desc, hw);\r\nif (rv) {\r\ncsio_err(hw, "IRQ request failed for vec %d err:%d\n",\r\nentryp[k].vector, rv);\r\ngoto err;\r\n}\r\nentryp[k++].dev_id = (void *)hw;\r\nrv = request_irq(entryp[k].vector, csio_fwevt_isr, 0,\r\nentryp[k].desc, hw);\r\nif (rv) {\r\ncsio_err(hw, "IRQ request failed for vec %d err:%d\n",\r\nentryp[k].vector, rv);\r\ngoto err;\r\n}\r\nentryp[k++].dev_id = (void *)hw;\r\nfor (i = 0; i < hw->num_pports; i++) {\r\ninfo = &hw->scsi_cpu_info[i];\r\nfor (j = 0; j < info->max_cpus; j++, k++) {\r\nstruct csio_scsi_qset *sqset = &hw->sqset[i][j];\r\nstruct csio_q *q = hw->wrm.q_arr[sqset->iq_idx];\r\nrv = request_irq(entryp[k].vector, csio_scsi_isr, 0,\r\nentryp[k].desc, q);\r\nif (rv) {\r\ncsio_err(hw,\r\n"IRQ request failed for vec %d err:%d\n",\r\nentryp[k].vector, rv);\r\ngoto err;\r\n}\r\nentryp[k].dev_id = (void *)q;\r\n}\r\n}\r\nout:\r\nhw->flags |= CSIO_HWF_HOST_INTR_ENABLED;\r\nreturn 0;\r\nerr:\r\nfor (i = 0; i < k; i++) {\r\nentryp = &hw->msix_entries[i];\r\nfree_irq(entryp->vector, entryp->dev_id);\r\n}\r\npci_disable_msix(hw->pdev);\r\nreturn -EINVAL;\r\n}\r\nstatic void\r\ncsio_disable_msix(struct csio_hw *hw, bool free)\r\n{\r\nint i;\r\nstruct csio_msix_entries *entryp;\r\nint cnt = hw->num_sqsets + CSIO_EXTRA_VECS;\r\nif (free) {\r\nfor (i = 0; i < cnt; i++) {\r\nentryp = &hw->msix_entries[i];\r\nfree_irq(entryp->vector, entryp->dev_id);\r\n}\r\n}\r\npci_disable_msix(hw->pdev);\r\n}\r\nstatic void\r\ncsio_reduce_sqsets(struct csio_hw *hw, int cnt)\r\n{\r\nint i;\r\nstruct csio_scsi_cpu_info *info;\r\nwhile (cnt < hw->num_sqsets) {\r\nfor (i = 0; i < hw->num_pports; i++) {\r\ninfo = &hw->scsi_cpu_info[i];\r\nif (info->max_cpus > 1) {\r\ninfo->max_cpus--;\r\nhw->num_sqsets--;\r\nif (hw->num_sqsets <= cnt)\r\nbreak;\r\n}\r\n}\r\n}\r\ncsio_dbg(hw, "Reduced sqsets to %d\n", hw->num_sqsets);\r\n}\r\nstatic int\r\ncsio_enable_msix(struct csio_hw *hw)\r\n{\r\nint i, j, k, n, min, cnt;\r\nstruct csio_msix_entries *entryp;\r\nstruct msix_entry *entries;\r\nint extra = CSIO_EXTRA_VECS;\r\nstruct csio_scsi_cpu_info *info;\r\nmin = hw->num_pports + extra;\r\ncnt = hw->num_sqsets + extra;\r\nif (hw->flags & CSIO_HWF_USING_SOFT_PARAMS || !csio_is_hw_master(hw))\r\ncnt = min_t(uint8_t, hw->cfg_niq, cnt);\r\nentries = kzalloc(sizeof(struct msix_entry) * cnt, GFP_KERNEL);\r\nif (!entries)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < cnt; i++)\r\nentries[i].entry = (uint16_t)i;\r\ncsio_dbg(hw, "FW supp #niq:%d, trying %d msix's\n", hw->cfg_niq, cnt);\r\ncnt = pci_enable_msix_range(hw->pdev, entries, min, cnt);\r\nif (cnt < 0) {\r\nkfree(entries);\r\nreturn cnt;\r\n}\r\nif (cnt < (hw->num_sqsets + extra)) {\r\ncsio_dbg(hw, "Reducing sqsets to %d\n", cnt - extra);\r\ncsio_reduce_sqsets(hw, cnt - extra);\r\n}\r\nfor (i = 0; i < cnt; i++) {\r\nentryp = &hw->msix_entries[i];\r\nentryp->vector = entries[i].vector;\r\n}\r\nk = 0;\r\ncsio_set_nondata_intr_idx(hw, entries[k].entry);\r\ncsio_set_mb_intr_idx(csio_hw_to_mbm(hw), entries[k++].entry);\r\ncsio_set_fwevt_intr_idx(hw, entries[k++].entry);\r\nfor (i = 0; i < hw->num_pports; i++) {\r\ninfo = &hw->scsi_cpu_info[i];\r\nfor (j = 0; j < hw->num_scsi_msix_cpus; j++) {\r\nn = (j % info->max_cpus) + k;\r\nhw->sqset[i][j].intr_idx = entries[n].entry;\r\n}\r\nk += info->max_cpus;\r\n}\r\nkfree(entries);\r\nreturn 0;\r\n}\r\nvoid\r\ncsio_intr_enable(struct csio_hw *hw)\r\n{\r\nhw->intr_mode = CSIO_IM_NONE;\r\nhw->flags &= ~CSIO_HWF_HOST_INTR_ENABLED;\r\nif ((csio_msi == 2) && !csio_enable_msix(hw))\r\nhw->intr_mode = CSIO_IM_MSIX;\r\nelse {\r\nif (hw->flags & CSIO_HWF_USING_SOFT_PARAMS ||\r\n!csio_is_hw_master(hw)) {\r\nint extra = CSIO_EXTRA_MSI_IQS;\r\nif (hw->cfg_niq < (hw->num_sqsets + extra)) {\r\ncsio_dbg(hw, "Reducing sqsets to %d\n",\r\nhw->cfg_niq - extra);\r\ncsio_reduce_sqsets(hw, hw->cfg_niq - extra);\r\n}\r\n}\r\nif ((csio_msi == 1) && !pci_enable_msi(hw->pdev))\r\nhw->intr_mode = CSIO_IM_MSI;\r\nelse\r\nhw->intr_mode = CSIO_IM_INTX;\r\n}\r\ncsio_dbg(hw, "Using %s interrupt mode.\n",\r\n(hw->intr_mode == CSIO_IM_MSIX) ? "MSIX" :\r\n((hw->intr_mode == CSIO_IM_MSI) ? "MSI" : "INTx"));\r\n}\r\nvoid\r\ncsio_intr_disable(struct csio_hw *hw, bool free)\r\n{\r\ncsio_hw_intr_disable(hw);\r\nswitch (hw->intr_mode) {\r\ncase CSIO_IM_MSIX:\r\ncsio_disable_msix(hw, free);\r\nbreak;\r\ncase CSIO_IM_MSI:\r\nif (free)\r\nfree_irq(hw->pdev->irq, hw);\r\npci_disable_msi(hw->pdev);\r\nbreak;\r\ncase CSIO_IM_INTX:\r\nif (free)\r\nfree_irq(hw->pdev->irq, hw);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nhw->intr_mode = CSIO_IM_NONE;\r\nhw->flags &= ~CSIO_HWF_HOST_INTR_ENABLED;\r\n}
