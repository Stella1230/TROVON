static int __sigp_sense(struct kvm_vcpu *vcpu, struct kvm_vcpu *dst_vcpu,\r\nu64 *reg)\r\n{\r\nstruct kvm_s390_local_interrupt *li;\r\nint cpuflags;\r\nint rc;\r\nint ext_call_pending;\r\nli = &dst_vcpu->arch.local_int;\r\ncpuflags = atomic_read(li->cpuflags);\r\next_call_pending = kvm_s390_ext_call_pending(dst_vcpu);\r\nif (!(cpuflags & CPUSTAT_STOPPED) && !ext_call_pending)\r\nrc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\nelse {\r\n*reg &= 0xffffffff00000000UL;\r\nif (ext_call_pending)\r\n*reg |= SIGP_STATUS_EXT_CALL_PENDING;\r\nif (cpuflags & CPUSTAT_STOPPED)\r\n*reg |= SIGP_STATUS_STOPPED;\r\nrc = SIGP_CC_STATUS_STORED;\r\n}\r\nVCPU_EVENT(vcpu, 4, "sensed status of cpu %x rc %x", dst_vcpu->vcpu_id,\r\nrc);\r\nreturn rc;\r\n}\r\nstatic int __inject_sigp_emergency(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu)\r\n{\r\nstruct kvm_s390_irq irq = {\r\n.type = KVM_S390_INT_EMERGENCY,\r\n.u.emerg.code = vcpu->vcpu_id,\r\n};\r\nint rc = 0;\r\nrc = kvm_s390_inject_vcpu(dst_vcpu, &irq);\r\nif (!rc)\r\nVCPU_EVENT(vcpu, 4, "sent sigp emerg to cpu %x",\r\ndst_vcpu->vcpu_id);\r\nreturn rc ? rc : SIGP_CC_ORDER_CODE_ACCEPTED;\r\n}\r\nstatic int __sigp_emergency(struct kvm_vcpu *vcpu, struct kvm_vcpu *dst_vcpu)\r\n{\r\nreturn __inject_sigp_emergency(vcpu, dst_vcpu);\r\n}\r\nstatic int __sigp_conditional_emergency(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu,\r\nu16 asn, u64 *reg)\r\n{\r\nconst u64 psw_int_mask = PSW_MASK_IO | PSW_MASK_EXT;\r\nu16 p_asn, s_asn;\r\npsw_t *psw;\r\nu32 flags;\r\nflags = atomic_read(&dst_vcpu->arch.sie_block->cpuflags);\r\npsw = &dst_vcpu->arch.sie_block->gpsw;\r\np_asn = dst_vcpu->arch.sie_block->gcr[4] & 0xffff;\r\ns_asn = dst_vcpu->arch.sie_block->gcr[3] & 0xffff;\r\nif (!(flags & CPUSTAT_STOPPED)\r\n|| (psw->mask & psw_int_mask) != psw_int_mask\r\n|| ((flags & CPUSTAT_WAIT) && psw->addr != 0)\r\n|| (!(flags & CPUSTAT_WAIT) && (asn == p_asn || asn == s_asn))) {\r\nreturn __inject_sigp_emergency(vcpu, dst_vcpu);\r\n} else {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INCORRECT_STATE;\r\nreturn SIGP_CC_STATUS_STORED;\r\n}\r\n}\r\nstatic int __sigp_external_call(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu, u64 *reg)\r\n{\r\nstruct kvm_s390_irq irq = {\r\n.type = KVM_S390_INT_EXTERNAL_CALL,\r\n.u.extcall.code = vcpu->vcpu_id,\r\n};\r\nint rc;\r\nrc = kvm_s390_inject_vcpu(dst_vcpu, &irq);\r\nif (rc == -EBUSY) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_EXT_CALL_PENDING;\r\nreturn SIGP_CC_STATUS_STORED;\r\n} else if (rc == 0) {\r\nVCPU_EVENT(vcpu, 4, "sent sigp ext call to cpu %x",\r\ndst_vcpu->vcpu_id);\r\n}\r\nreturn rc ? rc : SIGP_CC_ORDER_CODE_ACCEPTED;\r\n}\r\nstatic int __sigp_stop(struct kvm_vcpu *vcpu, struct kvm_vcpu *dst_vcpu)\r\n{\r\nstruct kvm_s390_irq irq = {\r\n.type = KVM_S390_SIGP_STOP,\r\n};\r\nint rc;\r\nrc = kvm_s390_inject_vcpu(dst_vcpu, &irq);\r\nif (rc == -EBUSY)\r\nrc = SIGP_CC_BUSY;\r\nelse if (rc == 0)\r\nVCPU_EVENT(vcpu, 4, "sent sigp stop to cpu %x",\r\ndst_vcpu->vcpu_id);\r\nreturn rc;\r\n}\r\nstatic int __sigp_stop_and_store_status(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu, u64 *reg)\r\n{\r\nstruct kvm_s390_irq irq = {\r\n.type = KVM_S390_SIGP_STOP,\r\n.u.stop.flags = KVM_S390_STOP_FLAG_STORE_STATUS,\r\n};\r\nint rc;\r\nrc = kvm_s390_inject_vcpu(dst_vcpu, &irq);\r\nif (rc == -EBUSY)\r\nrc = SIGP_CC_BUSY;\r\nelse if (rc == 0)\r\nVCPU_EVENT(vcpu, 4, "sent sigp stop and store status to cpu %x",\r\ndst_vcpu->vcpu_id);\r\nreturn rc;\r\n}\r\nstatic int __sigp_set_arch(struct kvm_vcpu *vcpu, u32 parameter)\r\n{\r\nint rc;\r\nunsigned int i;\r\nstruct kvm_vcpu *v;\r\nswitch (parameter & 0xff) {\r\ncase 0:\r\nrc = SIGP_CC_NOT_OPERATIONAL;\r\nbreak;\r\ncase 1:\r\ncase 2:\r\nkvm_for_each_vcpu(i, v, vcpu->kvm) {\r\nv->arch.pfault_token = KVM_S390_PFAULT_TOKEN_INVALID;\r\nkvm_clear_async_pf_completion_queue(v);\r\n}\r\nrc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\nbreak;\r\ndefault:\r\nrc = -EOPNOTSUPP;\r\n}\r\nreturn rc;\r\n}\r\nstatic int __sigp_set_prefix(struct kvm_vcpu *vcpu, struct kvm_vcpu *dst_vcpu,\r\nu32 address, u64 *reg)\r\n{\r\nstruct kvm_s390_irq irq = {\r\n.type = KVM_S390_SIGP_SET_PREFIX,\r\n.u.prefix.address = address & 0x7fffe000u,\r\n};\r\nint rc;\r\nif (kvm_is_error_gpa(vcpu->kvm, irq.u.prefix.address)) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INVALID_PARAMETER;\r\nreturn SIGP_CC_STATUS_STORED;\r\n}\r\nrc = kvm_s390_inject_vcpu(dst_vcpu, &irq);\r\nif (rc == -EBUSY) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INCORRECT_STATE;\r\nreturn SIGP_CC_STATUS_STORED;\r\n} else if (rc == 0) {\r\nVCPU_EVENT(vcpu, 4, "set prefix of cpu %02x to %x",\r\ndst_vcpu->vcpu_id, irq.u.prefix.address);\r\n}\r\nreturn rc;\r\n}\r\nstatic int __sigp_store_status_at_addr(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu,\r\nu32 addr, u64 *reg)\r\n{\r\nint flags;\r\nint rc;\r\nflags = atomic_read(dst_vcpu->arch.local_int.cpuflags);\r\nif (!(flags & CPUSTAT_STOPPED)) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INCORRECT_STATE;\r\nreturn SIGP_CC_STATUS_STORED;\r\n}\r\naddr &= 0x7ffffe00;\r\nrc = kvm_s390_store_status_unloaded(dst_vcpu, addr);\r\nif (rc == -EFAULT) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INVALID_PARAMETER;\r\nrc = SIGP_CC_STATUS_STORED;\r\n}\r\nreturn rc;\r\n}\r\nstatic int __sigp_sense_running(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu, u64 *reg)\r\n{\r\nstruct kvm_s390_local_interrupt *li;\r\nint rc;\r\nli = &dst_vcpu->arch.local_int;\r\nif (atomic_read(li->cpuflags) & CPUSTAT_RUNNING) {\r\nrc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\n} else {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_NOT_RUNNING;\r\nrc = SIGP_CC_STATUS_STORED;\r\n}\r\nVCPU_EVENT(vcpu, 4, "sensed running status of cpu %x rc %x",\r\ndst_vcpu->vcpu_id, rc);\r\nreturn rc;\r\n}\r\nstatic int __prepare_sigp_re_start(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu, u8 order_code)\r\n{\r\nstruct kvm_s390_local_interrupt *li = &dst_vcpu->arch.local_int;\r\nint rc = -EOPNOTSUPP;\r\nspin_lock(&li->lock);\r\nif (kvm_s390_is_stop_irq_pending(dst_vcpu))\r\nrc = SIGP_CC_BUSY;\r\nspin_unlock(&li->lock);\r\nreturn rc;\r\n}\r\nstatic int __prepare_sigp_cpu_reset(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu, u8 order_code)\r\n{\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic int __prepare_sigp_unknown(struct kvm_vcpu *vcpu,\r\nstruct kvm_vcpu *dst_vcpu)\r\n{\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic int handle_sigp_dst(struct kvm_vcpu *vcpu, u8 order_code,\r\nu16 cpu_addr, u32 parameter, u64 *status_reg)\r\n{\r\nint rc;\r\nstruct kvm_vcpu *dst_vcpu;\r\nif (cpu_addr >= KVM_MAX_VCPUS)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nswitch (order_code) {\r\ncase SIGP_SENSE:\r\nvcpu->stat.instruction_sigp_sense++;\r\nrc = __sigp_sense(vcpu, dst_vcpu, status_reg);\r\nbreak;\r\ncase SIGP_EXTERNAL_CALL:\r\nvcpu->stat.instruction_sigp_external_call++;\r\nrc = __sigp_external_call(vcpu, dst_vcpu, status_reg);\r\nbreak;\r\ncase SIGP_EMERGENCY_SIGNAL:\r\nvcpu->stat.instruction_sigp_emergency++;\r\nrc = __sigp_emergency(vcpu, dst_vcpu);\r\nbreak;\r\ncase SIGP_STOP:\r\nvcpu->stat.instruction_sigp_stop++;\r\nrc = __sigp_stop(vcpu, dst_vcpu);\r\nbreak;\r\ncase SIGP_STOP_AND_STORE_STATUS:\r\nvcpu->stat.instruction_sigp_stop_store_status++;\r\nrc = __sigp_stop_and_store_status(vcpu, dst_vcpu, status_reg);\r\nbreak;\r\ncase SIGP_STORE_STATUS_AT_ADDRESS:\r\nvcpu->stat.instruction_sigp_store_status++;\r\nrc = __sigp_store_status_at_addr(vcpu, dst_vcpu, parameter,\r\nstatus_reg);\r\nbreak;\r\ncase SIGP_SET_PREFIX:\r\nvcpu->stat.instruction_sigp_prefix++;\r\nrc = __sigp_set_prefix(vcpu, dst_vcpu, parameter, status_reg);\r\nbreak;\r\ncase SIGP_COND_EMERGENCY_SIGNAL:\r\nvcpu->stat.instruction_sigp_cond_emergency++;\r\nrc = __sigp_conditional_emergency(vcpu, dst_vcpu, parameter,\r\nstatus_reg);\r\nbreak;\r\ncase SIGP_SENSE_RUNNING:\r\nvcpu->stat.instruction_sigp_sense_running++;\r\nrc = __sigp_sense_running(vcpu, dst_vcpu, status_reg);\r\nbreak;\r\ncase SIGP_START:\r\nvcpu->stat.instruction_sigp_start++;\r\nrc = __prepare_sigp_re_start(vcpu, dst_vcpu, order_code);\r\nbreak;\r\ncase SIGP_RESTART:\r\nvcpu->stat.instruction_sigp_restart++;\r\nrc = __prepare_sigp_re_start(vcpu, dst_vcpu, order_code);\r\nbreak;\r\ncase SIGP_INITIAL_CPU_RESET:\r\nvcpu->stat.instruction_sigp_init_cpu_reset++;\r\nrc = __prepare_sigp_cpu_reset(vcpu, dst_vcpu, order_code);\r\nbreak;\r\ncase SIGP_CPU_RESET:\r\nvcpu->stat.instruction_sigp_cpu_reset++;\r\nrc = __prepare_sigp_cpu_reset(vcpu, dst_vcpu, order_code);\r\nbreak;\r\ndefault:\r\nvcpu->stat.instruction_sigp_unknown++;\r\nrc = __prepare_sigp_unknown(vcpu, dst_vcpu);\r\n}\r\nif (rc == -EOPNOTSUPP)\r\nVCPU_EVENT(vcpu, 4,\r\n"sigp order %u -> cpu %x: handled in user space",\r\norder_code, dst_vcpu->vcpu_id);\r\nreturn rc;\r\n}\r\nstatic int handle_sigp_order_in_user_space(struct kvm_vcpu *vcpu, u8 order_code)\r\n{\r\nif (!vcpu->kvm->arch.user_sigp)\r\nreturn 0;\r\nswitch (order_code) {\r\ncase SIGP_SENSE:\r\ncase SIGP_EXTERNAL_CALL:\r\ncase SIGP_EMERGENCY_SIGNAL:\r\ncase SIGP_COND_EMERGENCY_SIGNAL:\r\ncase SIGP_SENSE_RUNNING:\r\nreturn 0;\r\ncase SIGP_STOP:\r\nvcpu->stat.instruction_sigp_stop++;\r\nbreak;\r\ncase SIGP_STOP_AND_STORE_STATUS:\r\nvcpu->stat.instruction_sigp_stop_store_status++;\r\nbreak;\r\ncase SIGP_STORE_STATUS_AT_ADDRESS:\r\nvcpu->stat.instruction_sigp_store_status++;\r\nbreak;\r\ncase SIGP_STORE_ADDITIONAL_STATUS:\r\nvcpu->stat.instruction_sigp_store_adtl_status++;\r\nbreak;\r\ncase SIGP_SET_PREFIX:\r\nvcpu->stat.instruction_sigp_prefix++;\r\nbreak;\r\ncase SIGP_START:\r\nvcpu->stat.instruction_sigp_start++;\r\nbreak;\r\ncase SIGP_RESTART:\r\nvcpu->stat.instruction_sigp_restart++;\r\nbreak;\r\ncase SIGP_INITIAL_CPU_RESET:\r\nvcpu->stat.instruction_sigp_init_cpu_reset++;\r\nbreak;\r\ncase SIGP_CPU_RESET:\r\nvcpu->stat.instruction_sigp_cpu_reset++;\r\nbreak;\r\ndefault:\r\nvcpu->stat.instruction_sigp_unknown++;\r\n}\r\nVCPU_EVENT(vcpu, 4, "sigp order %u: completely handled in user space",\r\norder_code);\r\nreturn 1;\r\n}\r\nint kvm_s390_handle_sigp(struct kvm_vcpu *vcpu)\r\n{\r\nint r1 = (vcpu->arch.sie_block->ipa & 0x00f0) >> 4;\r\nint r3 = vcpu->arch.sie_block->ipa & 0x000f;\r\nu32 parameter;\r\nu16 cpu_addr = vcpu->run->s.regs.gprs[r3];\r\nu8 order_code;\r\nint rc;\r\nif (vcpu->arch.sie_block->gpsw.mask & PSW_MASK_PSTATE)\r\nreturn kvm_s390_inject_program_int(vcpu, PGM_PRIVILEGED_OP);\r\norder_code = kvm_s390_get_base_disp_rs(vcpu, NULL);\r\nif (handle_sigp_order_in_user_space(vcpu, order_code))\r\nreturn -EOPNOTSUPP;\r\nif (r1 % 2)\r\nparameter = vcpu->run->s.regs.gprs[r1];\r\nelse\r\nparameter = vcpu->run->s.regs.gprs[r1 + 1];\r\ntrace_kvm_s390_handle_sigp(vcpu, order_code, cpu_addr, parameter);\r\nswitch (order_code) {\r\ncase SIGP_SET_ARCHITECTURE:\r\nvcpu->stat.instruction_sigp_arch++;\r\nrc = __sigp_set_arch(vcpu, parameter);\r\nbreak;\r\ndefault:\r\nrc = handle_sigp_dst(vcpu, order_code, cpu_addr,\r\nparameter,\r\n&vcpu->run->s.regs.gprs[r1]);\r\n}\r\nif (rc < 0)\r\nreturn rc;\r\nkvm_s390_set_psw_cc(vcpu, rc);\r\nreturn 0;\r\n}\r\nint kvm_s390_handle_sigp_pei(struct kvm_vcpu *vcpu)\r\n{\r\nint r3 = vcpu->arch.sie_block->ipa & 0x000f;\r\nu16 cpu_addr = vcpu->run->s.regs.gprs[r3];\r\nstruct kvm_vcpu *dest_vcpu;\r\nu8 order_code = kvm_s390_get_base_disp_rs(vcpu, NULL);\r\ntrace_kvm_s390_handle_sigp_pei(vcpu, order_code, cpu_addr);\r\nif (order_code == SIGP_EXTERNAL_CALL) {\r\ndest_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nBUG_ON(dest_vcpu == NULL);\r\nkvm_s390_vcpu_wakeup(dest_vcpu);\r\nkvm_s390_set_psw_cc(vcpu, SIGP_CC_ORDER_CODE_ACCEPTED);\r\nreturn 0;\r\n}\r\nreturn -EOPNOTSUPP;\r\n}
