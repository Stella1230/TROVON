static void *is_irq_stack(void *p, void *irq)\r\n{\r\nif (p < irq || p >= (irq + THREAD_SIZE))\r\nreturn NULL;\r\nreturn irq + THREAD_SIZE;\r\n}\r\nstatic void *is_hardirq_stack(unsigned long *stack, int cpu)\r\n{\r\nvoid *irq = per_cpu(hardirq_stack, cpu);\r\nreturn is_irq_stack(stack, irq);\r\n}\r\nstatic void *is_softirq_stack(unsigned long *stack, int cpu)\r\n{\r\nvoid *irq = per_cpu(softirq_stack, cpu);\r\nreturn is_irq_stack(stack, irq);\r\n}\r\nvoid dump_trace(struct task_struct *task, struct pt_regs *regs,\r\nunsigned long *stack, unsigned long bp,\r\nconst struct stacktrace_ops *ops, void *data)\r\n{\r\nconst unsigned cpu = get_cpu();\r\nint graph = 0;\r\nu32 *prev_esp;\r\nif (!task)\r\ntask = current;\r\nif (!stack) {\r\nunsigned long dummy;\r\nstack = &dummy;\r\nif (task != current)\r\nstack = (unsigned long *)task->thread.sp;\r\n}\r\nif (!bp)\r\nbp = stack_frame(task, regs);\r\nfor (;;) {\r\nstruct thread_info *context;\r\nvoid *end_stack;\r\nend_stack = is_hardirq_stack(stack, cpu);\r\nif (!end_stack)\r\nend_stack = is_softirq_stack(stack, cpu);\r\ncontext = task_thread_info(task);\r\nbp = ops->walk_stack(context, stack, bp, ops, data,\r\nend_stack, &graph);\r\nif (!end_stack)\r\nbreak;\r\nprev_esp = (u32 *)(end_stack - THREAD_SIZE);\r\nstack = (unsigned long *)*prev_esp;\r\nif (!stack)\r\nbreak;\r\nif (ops->stack(data, "IRQ") < 0)\r\nbreak;\r\ntouch_nmi_watchdog();\r\n}\r\nput_cpu();\r\n}\r\nvoid\r\nshow_stack_log_lvl(struct task_struct *task, struct pt_regs *regs,\r\nunsigned long *sp, unsigned long bp, char *log_lvl)\r\n{\r\nunsigned long *stack;\r\nint i;\r\nif (sp == NULL) {\r\nif (task)\r\nsp = (unsigned long *)task->thread.sp;\r\nelse\r\nsp = (unsigned long *)&sp;\r\n}\r\nstack = sp;\r\nfor (i = 0; i < kstack_depth_to_print; i++) {\r\nif (kstack_end(stack))\r\nbreak;\r\nif ((i % STACKSLOTS_PER_LINE) == 0) {\r\nif (i != 0)\r\npr_cont("\n");\r\nprintk("%s %08lx", log_lvl, *stack++);\r\n} else\r\npr_cont(" %08lx", *stack++);\r\ntouch_nmi_watchdog();\r\n}\r\npr_cont("\n");\r\nshow_trace_log_lvl(task, regs, sp, bp, log_lvl);\r\n}\r\nvoid show_regs(struct pt_regs *regs)\r\n{\r\nint i;\r\nshow_regs_print_info(KERN_EMERG);\r\n__show_regs(regs, !user_mode(regs));\r\nif (!user_mode(regs)) {\r\nunsigned int code_prologue = code_bytes * 43 / 64;\r\nunsigned int code_len = code_bytes;\r\nunsigned char c;\r\nu8 *ip;\r\npr_emerg("Stack:\n");\r\nshow_stack_log_lvl(NULL, regs, &regs->sp, 0, KERN_EMERG);\r\npr_emerg("Code:");\r\nip = (u8 *)regs->ip - code_prologue;\r\nif (ip < (u8 *)PAGE_OFFSET || probe_kernel_address(ip, c)) {\r\nip = (u8 *)regs->ip;\r\ncode_len = code_len - code_prologue + 1;\r\n}\r\nfor (i = 0; i < code_len; i++, ip++) {\r\nif (ip < (u8 *)PAGE_OFFSET ||\r\nprobe_kernel_address(ip, c)) {\r\npr_cont(" Bad EIP value.");\r\nbreak;\r\n}\r\nif (ip == (u8 *)regs->ip)\r\npr_cont(" <%02x>", c);\r\nelse\r\npr_cont(" %02x", c);\r\n}\r\n}\r\npr_cont("\n");\r\n}\r\nint is_valid_bugaddr(unsigned long ip)\r\n{\r\nunsigned short ud2;\r\nif (ip < PAGE_OFFSET)\r\nreturn 0;\r\nif (probe_kernel_address((unsigned short *)ip, ud2))\r\nreturn 0;\r\nreturn ud2 == 0x0b0f;\r\n}
