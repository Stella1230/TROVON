static struct vmw_fence_manager *\r\nfman_from_fence(struct vmw_fence_obj *fence)\r\n{\r\nreturn container_of(fence->base.lock, struct vmw_fence_manager, lock);\r\n}\r\nstatic void vmw_fence_obj_destroy(struct fence *f)\r\n{\r\nstruct vmw_fence_obj *fence =\r\ncontainer_of(f, struct vmw_fence_obj, base);\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nlist_del_init(&fence->head);\r\n--fman->num_fence_objects;\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\nfence->destroy(fence);\r\n}\r\nstatic const char *vmw_fence_get_driver_name(struct fence *f)\r\n{\r\nreturn "vmwgfx";\r\n}\r\nstatic const char *vmw_fence_get_timeline_name(struct fence *f)\r\n{\r\nreturn "svga";\r\n}\r\nstatic bool vmw_fence_enable_signaling(struct fence *f)\r\n{\r\nstruct vmw_fence_obj *fence =\r\ncontainer_of(f, struct vmw_fence_obj, base);\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nstruct vmw_private *dev_priv = fman->dev_priv;\r\n__le32 __iomem *fifo_mem = dev_priv->mmio_virt;\r\nu32 seqno = ioread32(fifo_mem + SVGA_FIFO_FENCE);\r\nif (seqno - fence->base.seqno < VMW_FENCE_WRAP)\r\nreturn false;\r\nvmw_fifo_ping_host(dev_priv, SVGA_SYNC_GENERIC);\r\nreturn true;\r\n}\r\nstatic void\r\nvmwgfx_wait_cb(struct fence *fence, struct fence_cb *cb)\r\n{\r\nstruct vmwgfx_wait_cb *wait =\r\ncontainer_of(cb, struct vmwgfx_wait_cb, base);\r\nwake_up_process(wait->task);\r\n}\r\nstatic long vmw_fence_wait(struct fence *f, bool intr, signed long timeout)\r\n{\r\nstruct vmw_fence_obj *fence =\r\ncontainer_of(f, struct vmw_fence_obj, base);\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nstruct vmw_private *dev_priv = fman->dev_priv;\r\nstruct vmwgfx_wait_cb cb;\r\nlong ret = timeout;\r\nunsigned long irq_flags;\r\nif (likely(vmw_fence_obj_signaled(fence)))\r\nreturn timeout;\r\nvmw_fifo_ping_host(dev_priv, SVGA_SYNC_GENERIC);\r\nvmw_seqno_waiter_add(dev_priv);\r\nspin_lock_irqsave(f->lock, irq_flags);\r\nif (intr && signal_pending(current)) {\r\nret = -ERESTARTSYS;\r\ngoto out;\r\n}\r\ncb.base.func = vmwgfx_wait_cb;\r\ncb.task = current;\r\nlist_add(&cb.base.node, &f->cb_list);\r\nwhile (ret > 0) {\r\n__vmw_fences_update(fman);\r\nif (test_bit(FENCE_FLAG_SIGNALED_BIT, &f->flags))\r\nbreak;\r\nif (intr)\r\n__set_current_state(TASK_INTERRUPTIBLE);\r\nelse\r\n__set_current_state(TASK_UNINTERRUPTIBLE);\r\nspin_unlock_irqrestore(f->lock, irq_flags);\r\nret = schedule_timeout(ret);\r\nspin_lock_irqsave(f->lock, irq_flags);\r\nif (ret > 0 && intr && signal_pending(current))\r\nret = -ERESTARTSYS;\r\n}\r\nif (!list_empty(&cb.base.node))\r\nlist_del(&cb.base.node);\r\n__set_current_state(TASK_RUNNING);\r\nout:\r\nspin_unlock_irqrestore(f->lock, irq_flags);\r\nvmw_seqno_waiter_remove(dev_priv);\r\nreturn ret;\r\n}\r\nstatic void vmw_fence_work_func(struct work_struct *work)\r\n{\r\nstruct vmw_fence_manager *fman =\r\ncontainer_of(work, struct vmw_fence_manager, work);\r\nstruct list_head list;\r\nstruct vmw_fence_action *action, *next_action;\r\nbool seqno_valid;\r\ndo {\r\nINIT_LIST_HEAD(&list);\r\nmutex_lock(&fman->goal_irq_mutex);\r\nspin_lock_irq(&fman->lock);\r\nlist_splice_init(&fman->cleanup_list, &list);\r\nseqno_valid = fman->seqno_valid;\r\nspin_unlock_irq(&fman->lock);\r\nif (!seqno_valid && fman->goal_irq_on) {\r\nfman->goal_irq_on = false;\r\nvmw_goal_waiter_remove(fman->dev_priv);\r\n}\r\nmutex_unlock(&fman->goal_irq_mutex);\r\nif (list_empty(&list))\r\nreturn;\r\nlist_for_each_entry_safe(action, next_action, &list, head) {\r\nlist_del_init(&action->head);\r\nif (action->cleanup)\r\naction->cleanup(action);\r\n}\r\n} while (1);\r\n}\r\nstruct vmw_fence_manager *vmw_fence_manager_init(struct vmw_private *dev_priv)\r\n{\r\nstruct vmw_fence_manager *fman = kzalloc(sizeof(*fman), GFP_KERNEL);\r\nif (unlikely(fman == NULL))\r\nreturn NULL;\r\nfman->dev_priv = dev_priv;\r\nspin_lock_init(&fman->lock);\r\nINIT_LIST_HEAD(&fman->fence_list);\r\nINIT_LIST_HEAD(&fman->cleanup_list);\r\nINIT_WORK(&fman->work, &vmw_fence_work_func);\r\nfman->fifo_down = true;\r\nfman->user_fence_size = ttm_round_pot(sizeof(struct vmw_user_fence));\r\nfman->fence_size = ttm_round_pot(sizeof(struct vmw_fence_obj));\r\nfman->event_fence_action_size =\r\nttm_round_pot(sizeof(struct vmw_event_fence_action));\r\nmutex_init(&fman->goal_irq_mutex);\r\nfman->ctx = fence_context_alloc(1);\r\nreturn fman;\r\n}\r\nvoid vmw_fence_manager_takedown(struct vmw_fence_manager *fman)\r\n{\r\nunsigned long irq_flags;\r\nbool lists_empty;\r\n(void) cancel_work_sync(&fman->work);\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nlists_empty = list_empty(&fman->fence_list) &&\r\nlist_empty(&fman->cleanup_list);\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\nBUG_ON(!lists_empty);\r\nkfree(fman);\r\n}\r\nstatic int vmw_fence_obj_init(struct vmw_fence_manager *fman,\r\nstruct vmw_fence_obj *fence, u32 seqno,\r\nvoid (*destroy) (struct vmw_fence_obj *fence))\r\n{\r\nunsigned long irq_flags;\r\nint ret = 0;\r\nfence_init(&fence->base, &vmw_fence_ops, &fman->lock,\r\nfman->ctx, seqno);\r\nINIT_LIST_HEAD(&fence->seq_passed_actions);\r\nfence->destroy = destroy;\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nif (unlikely(fman->fifo_down)) {\r\nret = -EBUSY;\r\ngoto out_unlock;\r\n}\r\nlist_add_tail(&fence->head, &fman->fence_list);\r\n++fman->num_fence_objects;\r\nout_unlock:\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\nreturn ret;\r\n}\r\nstatic void vmw_fences_perform_actions(struct vmw_fence_manager *fman,\r\nstruct list_head *list)\r\n{\r\nstruct vmw_fence_action *action, *next_action;\r\nlist_for_each_entry_safe(action, next_action, list, head) {\r\nlist_del_init(&action->head);\r\nfman->pending_actions[action->type]--;\r\nif (action->seq_passed != NULL)\r\naction->seq_passed(action);\r\nlist_add_tail(&action->head, &fman->cleanup_list);\r\n}\r\n}\r\nstatic bool vmw_fence_goal_new_locked(struct vmw_fence_manager *fman,\r\nu32 passed_seqno)\r\n{\r\nu32 goal_seqno;\r\n__le32 __iomem *fifo_mem;\r\nstruct vmw_fence_obj *fence;\r\nif (likely(!fman->seqno_valid))\r\nreturn false;\r\nfifo_mem = fman->dev_priv->mmio_virt;\r\ngoal_seqno = ioread32(fifo_mem + SVGA_FIFO_FENCE_GOAL);\r\nif (likely(passed_seqno - goal_seqno >= VMW_FENCE_WRAP))\r\nreturn false;\r\nfman->seqno_valid = false;\r\nlist_for_each_entry(fence, &fman->fence_list, head) {\r\nif (!list_empty(&fence->seq_passed_actions)) {\r\nfman->seqno_valid = true;\r\niowrite32(fence->base.seqno,\r\nfifo_mem + SVGA_FIFO_FENCE_GOAL);\r\nbreak;\r\n}\r\n}\r\nreturn true;\r\n}\r\nstatic bool vmw_fence_goal_check_locked(struct vmw_fence_obj *fence)\r\n{\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nu32 goal_seqno;\r\n__le32 __iomem *fifo_mem;\r\nif (fence_is_signaled_locked(&fence->base))\r\nreturn false;\r\nfifo_mem = fman->dev_priv->mmio_virt;\r\ngoal_seqno = ioread32(fifo_mem + SVGA_FIFO_FENCE_GOAL);\r\nif (likely(fman->seqno_valid &&\r\ngoal_seqno - fence->base.seqno < VMW_FENCE_WRAP))\r\nreturn false;\r\niowrite32(fence->base.seqno, fifo_mem + SVGA_FIFO_FENCE_GOAL);\r\nfman->seqno_valid = true;\r\nreturn true;\r\n}\r\nstatic void __vmw_fences_update(struct vmw_fence_manager *fman)\r\n{\r\nstruct vmw_fence_obj *fence, *next_fence;\r\nstruct list_head action_list;\r\nbool needs_rerun;\r\nuint32_t seqno, new_seqno;\r\n__le32 __iomem *fifo_mem = fman->dev_priv->mmio_virt;\r\nseqno = ioread32(fifo_mem + SVGA_FIFO_FENCE);\r\nrerun:\r\nlist_for_each_entry_safe(fence, next_fence, &fman->fence_list, head) {\r\nif (seqno - fence->base.seqno < VMW_FENCE_WRAP) {\r\nlist_del_init(&fence->head);\r\nfence_signal_locked(&fence->base);\r\nINIT_LIST_HEAD(&action_list);\r\nlist_splice_init(&fence->seq_passed_actions,\r\n&action_list);\r\nvmw_fences_perform_actions(fman, &action_list);\r\n} else\r\nbreak;\r\n}\r\nneeds_rerun = vmw_fence_goal_new_locked(fman, seqno);\r\nif (unlikely(needs_rerun)) {\r\nnew_seqno = ioread32(fifo_mem + SVGA_FIFO_FENCE);\r\nif (new_seqno != seqno) {\r\nseqno = new_seqno;\r\ngoto rerun;\r\n}\r\n}\r\nif (!list_empty(&fman->cleanup_list))\r\n(void) schedule_work(&fman->work);\r\n}\r\nvoid vmw_fences_update(struct vmw_fence_manager *fman)\r\n{\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\n__vmw_fences_update(fman);\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\n}\r\nbool vmw_fence_obj_signaled(struct vmw_fence_obj *fence)\r\n{\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nif (test_bit(FENCE_FLAG_SIGNALED_BIT, &fence->base.flags))\r\nreturn 1;\r\nvmw_fences_update(fman);\r\nreturn fence_is_signaled(&fence->base);\r\n}\r\nint vmw_fence_obj_wait(struct vmw_fence_obj *fence, bool lazy,\r\nbool interruptible, unsigned long timeout)\r\n{\r\nlong ret = fence_wait_timeout(&fence->base, interruptible, timeout);\r\nif (likely(ret > 0))\r\nreturn 0;\r\nelse if (ret == 0)\r\nreturn -EBUSY;\r\nelse\r\nreturn ret;\r\n}\r\nvoid vmw_fence_obj_flush(struct vmw_fence_obj *fence)\r\n{\r\nstruct vmw_private *dev_priv = fman_from_fence(fence)->dev_priv;\r\nvmw_fifo_ping_host(dev_priv, SVGA_SYNC_GENERIC);\r\n}\r\nstatic void vmw_fence_destroy(struct vmw_fence_obj *fence)\r\n{\r\nfence_free(&fence->base);\r\n}\r\nint vmw_fence_create(struct vmw_fence_manager *fman,\r\nuint32_t seqno,\r\nstruct vmw_fence_obj **p_fence)\r\n{\r\nstruct vmw_fence_obj *fence;\r\nint ret;\r\nfence = kzalloc(sizeof(*fence), GFP_KERNEL);\r\nif (unlikely(fence == NULL))\r\nreturn -ENOMEM;\r\nret = vmw_fence_obj_init(fman, fence, seqno,\r\nvmw_fence_destroy);\r\nif (unlikely(ret != 0))\r\ngoto out_err_init;\r\n*p_fence = fence;\r\nreturn 0;\r\nout_err_init:\r\nkfree(fence);\r\nreturn ret;\r\n}\r\nstatic void vmw_user_fence_destroy(struct vmw_fence_obj *fence)\r\n{\r\nstruct vmw_user_fence *ufence =\r\ncontainer_of(fence, struct vmw_user_fence, fence);\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nttm_base_object_kfree(ufence, base);\r\nttm_mem_global_free(vmw_mem_glob(fman->dev_priv),\r\nfman->user_fence_size);\r\n}\r\nstatic void vmw_user_fence_base_release(struct ttm_base_object **p_base)\r\n{\r\nstruct ttm_base_object *base = *p_base;\r\nstruct vmw_user_fence *ufence =\r\ncontainer_of(base, struct vmw_user_fence, base);\r\nstruct vmw_fence_obj *fence = &ufence->fence;\r\n*p_base = NULL;\r\nvmw_fence_obj_unreference(&fence);\r\n}\r\nint vmw_user_fence_create(struct drm_file *file_priv,\r\nstruct vmw_fence_manager *fman,\r\nuint32_t seqno,\r\nstruct vmw_fence_obj **p_fence,\r\nuint32_t *p_handle)\r\n{\r\nstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\r\nstruct vmw_user_fence *ufence;\r\nstruct vmw_fence_obj *tmp;\r\nstruct ttm_mem_global *mem_glob = vmw_mem_glob(fman->dev_priv);\r\nint ret;\r\nret = ttm_mem_global_alloc(mem_glob, fman->user_fence_size,\r\nfalse, false);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nufence = kzalloc(sizeof(*ufence), GFP_KERNEL);\r\nif (unlikely(ufence == NULL)) {\r\nret = -ENOMEM;\r\ngoto out_no_object;\r\n}\r\nret = vmw_fence_obj_init(fman, &ufence->fence, seqno,\r\nvmw_user_fence_destroy);\r\nif (unlikely(ret != 0)) {\r\nkfree(ufence);\r\ngoto out_no_object;\r\n}\r\ntmp = vmw_fence_obj_reference(&ufence->fence);\r\nret = ttm_base_object_init(tfile, &ufence->base, false,\r\nVMW_RES_FENCE,\r\n&vmw_user_fence_base_release, NULL);\r\nif (unlikely(ret != 0)) {\r\nvmw_fence_obj_unreference(&tmp);\r\ngoto out_err;\r\n}\r\n*p_fence = &ufence->fence;\r\n*p_handle = ufence->base.hash.key;\r\nreturn 0;\r\nout_err:\r\ntmp = &ufence->fence;\r\nvmw_fence_obj_unreference(&tmp);\r\nout_no_object:\r\nttm_mem_global_free(mem_glob, fman->user_fence_size);\r\nreturn ret;\r\n}\r\nvoid vmw_fence_fifo_down(struct vmw_fence_manager *fman)\r\n{\r\nstruct list_head action_list;\r\nint ret;\r\nspin_lock_irq(&fman->lock);\r\nfman->fifo_down = true;\r\nwhile (!list_empty(&fman->fence_list)) {\r\nstruct vmw_fence_obj *fence =\r\nlist_entry(fman->fence_list.prev, struct vmw_fence_obj,\r\nhead);\r\nfence_get(&fence->base);\r\nspin_unlock_irq(&fman->lock);\r\nret = vmw_fence_obj_wait(fence, false, false,\r\nVMW_FENCE_WAIT_TIMEOUT);\r\nif (unlikely(ret != 0)) {\r\nlist_del_init(&fence->head);\r\nfence_signal(&fence->base);\r\nINIT_LIST_HEAD(&action_list);\r\nlist_splice_init(&fence->seq_passed_actions,\r\n&action_list);\r\nvmw_fences_perform_actions(fman, &action_list);\r\n}\r\nBUG_ON(!list_empty(&fence->head));\r\nfence_put(&fence->base);\r\nspin_lock_irq(&fman->lock);\r\n}\r\nspin_unlock_irq(&fman->lock);\r\n}\r\nvoid vmw_fence_fifo_up(struct vmw_fence_manager *fman)\r\n{\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nfman->fifo_down = false;\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\n}\r\nint vmw_fence_obj_wait_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_vmw_fence_wait_arg *arg =\r\n(struct drm_vmw_fence_wait_arg *)data;\r\nunsigned long timeout;\r\nstruct ttm_base_object *base;\r\nstruct vmw_fence_obj *fence;\r\nstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\r\nint ret;\r\nuint64_t wait_timeout = ((uint64_t)arg->timeout_us * HZ);\r\nwait_timeout = (wait_timeout >> 20) + (wait_timeout >> 24) -\r\n(wait_timeout >> 26);\r\nif (!arg->cookie_valid) {\r\narg->cookie_valid = 1;\r\narg->kernel_cookie = jiffies + wait_timeout;\r\n}\r\nbase = ttm_base_object_lookup(tfile, arg->handle);\r\nif (unlikely(base == NULL)) {\r\nprintk(KERN_ERR "Wait invalid fence object handle "\r\n"0x%08lx.\n",\r\n(unsigned long)arg->handle);\r\nreturn -EINVAL;\r\n}\r\nfence = &(container_of(base, struct vmw_user_fence, base)->fence);\r\ntimeout = jiffies;\r\nif (time_after_eq(timeout, (unsigned long)arg->kernel_cookie)) {\r\nret = ((vmw_fence_obj_signaled(fence)) ?\r\n0 : -EBUSY);\r\ngoto out;\r\n}\r\ntimeout = (unsigned long)arg->kernel_cookie - timeout;\r\nret = vmw_fence_obj_wait(fence, arg->lazy, true, timeout);\r\nout:\r\nttm_base_object_unref(&base);\r\nif (ret == 0 && (arg->wait_options & DRM_VMW_WAIT_OPTION_UNREF))\r\nreturn ttm_ref_object_base_unref(tfile, arg->handle,\r\nTTM_REF_USAGE);\r\nreturn ret;\r\n}\r\nint vmw_fence_obj_signaled_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_vmw_fence_signaled_arg *arg =\r\n(struct drm_vmw_fence_signaled_arg *) data;\r\nstruct ttm_base_object *base;\r\nstruct vmw_fence_obj *fence;\r\nstruct vmw_fence_manager *fman;\r\nstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nbase = ttm_base_object_lookup(tfile, arg->handle);\r\nif (unlikely(base == NULL)) {\r\nprintk(KERN_ERR "Fence signaled invalid fence object handle "\r\n"0x%08lx.\n",\r\n(unsigned long)arg->handle);\r\nreturn -EINVAL;\r\n}\r\nfence = &(container_of(base, struct vmw_user_fence, base)->fence);\r\nfman = fman_from_fence(fence);\r\narg->signaled = vmw_fence_obj_signaled(fence);\r\narg->signaled_flags = arg->flags;\r\nspin_lock_irq(&fman->lock);\r\narg->passed_seqno = dev_priv->last_read_seqno;\r\nspin_unlock_irq(&fman->lock);\r\nttm_base_object_unref(&base);\r\nreturn 0;\r\n}\r\nint vmw_fence_obj_unref_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_vmw_fence_arg *arg =\r\n(struct drm_vmw_fence_arg *) data;\r\nreturn ttm_ref_object_base_unref(vmw_fpriv(file_priv)->tfile,\r\narg->handle,\r\nTTM_REF_USAGE);\r\n}\r\nvoid vmw_event_fence_fpriv_gone(struct vmw_fence_manager *fman,\r\nstruct list_head *event_list)\r\n{\r\nstruct vmw_event_fence_action *eaction;\r\nstruct drm_pending_event *event;\r\nunsigned long irq_flags;\r\nwhile (1) {\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nif (list_empty(event_list))\r\ngoto out_unlock;\r\neaction = list_first_entry(event_list,\r\nstruct vmw_event_fence_action,\r\nfpriv_head);\r\nlist_del_init(&eaction->fpriv_head);\r\nevent = eaction->event;\r\neaction->event = NULL;\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\nevent->destroy(event);\r\n}\r\nout_unlock:\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\n}\r\nstatic void vmw_event_fence_action_seq_passed(struct vmw_fence_action *action)\r\n{\r\nstruct vmw_event_fence_action *eaction =\r\ncontainer_of(action, struct vmw_event_fence_action, action);\r\nstruct drm_device *dev = eaction->dev;\r\nstruct drm_pending_event *event = eaction->event;\r\nstruct drm_file *file_priv;\r\nunsigned long irq_flags;\r\nif (unlikely(event == NULL))\r\nreturn;\r\nfile_priv = event->file_priv;\r\nspin_lock_irqsave(&dev->event_lock, irq_flags);\r\nif (likely(eaction->tv_sec != NULL)) {\r\nstruct timeval tv;\r\ndo_gettimeofday(&tv);\r\n*eaction->tv_sec = tv.tv_sec;\r\n*eaction->tv_usec = tv.tv_usec;\r\n}\r\nlist_del_init(&eaction->fpriv_head);\r\nlist_add_tail(&eaction->event->link, &file_priv->event_list);\r\neaction->event = NULL;\r\nwake_up_all(&file_priv->event_wait);\r\nspin_unlock_irqrestore(&dev->event_lock, irq_flags);\r\n}\r\nstatic void vmw_event_fence_action_cleanup(struct vmw_fence_action *action)\r\n{\r\nstruct vmw_event_fence_action *eaction =\r\ncontainer_of(action, struct vmw_event_fence_action, action);\r\nstruct vmw_fence_manager *fman = fman_from_fence(eaction->fence);\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nlist_del(&eaction->fpriv_head);\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\nvmw_fence_obj_unreference(&eaction->fence);\r\nkfree(eaction);\r\n}\r\nstatic void vmw_fence_obj_add_action(struct vmw_fence_obj *fence,\r\nstruct vmw_fence_action *action)\r\n{\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nunsigned long irq_flags;\r\nbool run_update = false;\r\nmutex_lock(&fman->goal_irq_mutex);\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nfman->pending_actions[action->type]++;\r\nif (fence_is_signaled_locked(&fence->base)) {\r\nstruct list_head action_list;\r\nINIT_LIST_HEAD(&action_list);\r\nlist_add_tail(&action->head, &action_list);\r\nvmw_fences_perform_actions(fman, &action_list);\r\n} else {\r\nlist_add_tail(&action->head, &fence->seq_passed_actions);\r\nrun_update = vmw_fence_goal_check_locked(fence);\r\n}\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\nif (run_update) {\r\nif (!fman->goal_irq_on) {\r\nfman->goal_irq_on = true;\r\nvmw_goal_waiter_add(fman->dev_priv);\r\n}\r\nvmw_fences_update(fman);\r\n}\r\nmutex_unlock(&fman->goal_irq_mutex);\r\n}\r\nint vmw_event_fence_action_queue(struct drm_file *file_priv,\r\nstruct vmw_fence_obj *fence,\r\nstruct drm_pending_event *event,\r\nuint32_t *tv_sec,\r\nuint32_t *tv_usec,\r\nbool interruptible)\r\n{\r\nstruct vmw_event_fence_action *eaction;\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nstruct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);\r\nunsigned long irq_flags;\r\neaction = kzalloc(sizeof(*eaction), GFP_KERNEL);\r\nif (unlikely(eaction == NULL))\r\nreturn -ENOMEM;\r\neaction->event = event;\r\neaction->action.seq_passed = vmw_event_fence_action_seq_passed;\r\neaction->action.cleanup = vmw_event_fence_action_cleanup;\r\neaction->action.type = VMW_ACTION_EVENT;\r\neaction->fence = vmw_fence_obj_reference(fence);\r\neaction->dev = fman->dev_priv->dev;\r\neaction->tv_sec = tv_sec;\r\neaction->tv_usec = tv_usec;\r\nspin_lock_irqsave(&fman->lock, irq_flags);\r\nlist_add_tail(&eaction->fpriv_head, &vmw_fp->fence_events);\r\nspin_unlock_irqrestore(&fman->lock, irq_flags);\r\nvmw_fence_obj_add_action(fence, &eaction->action);\r\nreturn 0;\r\n}\r\nstatic int vmw_event_fence_action_create(struct drm_file *file_priv,\r\nstruct vmw_fence_obj *fence,\r\nuint32_t flags,\r\nuint64_t user_data,\r\nbool interruptible)\r\n{\r\nstruct vmw_event_fence_pending *event;\r\nstruct vmw_fence_manager *fman = fman_from_fence(fence);\r\nstruct drm_device *dev = fman->dev_priv->dev;\r\nunsigned long irq_flags;\r\nint ret;\r\nspin_lock_irqsave(&dev->event_lock, irq_flags);\r\nret = (file_priv->event_space < sizeof(event->event)) ? -EBUSY : 0;\r\nif (likely(ret == 0))\r\nfile_priv->event_space -= sizeof(event->event);\r\nspin_unlock_irqrestore(&dev->event_lock, irq_flags);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Failed to allocate event space for this file.\n");\r\ngoto out_no_space;\r\n}\r\nevent = kzalloc(sizeof(*event), GFP_KERNEL);\r\nif (unlikely(event == NULL)) {\r\nDRM_ERROR("Failed to allocate an event.\n");\r\nret = -ENOMEM;\r\ngoto out_no_event;\r\n}\r\nevent->event.base.type = DRM_VMW_EVENT_FENCE_SIGNALED;\r\nevent->event.base.length = sizeof(*event);\r\nevent->event.user_data = user_data;\r\nevent->base.event = &event->event.base;\r\nevent->base.file_priv = file_priv;\r\nevent->base.destroy = (void (*) (struct drm_pending_event *)) kfree;\r\nif (flags & DRM_VMW_FE_FLAG_REQ_TIME)\r\nret = vmw_event_fence_action_queue(file_priv, fence,\r\n&event->base,\r\n&event->event.tv_sec,\r\n&event->event.tv_usec,\r\ninterruptible);\r\nelse\r\nret = vmw_event_fence_action_queue(file_priv, fence,\r\n&event->base,\r\nNULL,\r\nNULL,\r\ninterruptible);\r\nif (ret != 0)\r\ngoto out_no_queue;\r\nreturn 0;\r\nout_no_queue:\r\nevent->base.destroy(&event->base);\r\nout_no_event:\r\nspin_lock_irqsave(&dev->event_lock, irq_flags);\r\nfile_priv->event_space += sizeof(*event);\r\nspin_unlock_irqrestore(&dev->event_lock, irq_flags);\r\nout_no_space:\r\nreturn ret;\r\n}\r\nint vmw_fence_event_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nstruct drm_vmw_fence_event_arg *arg =\r\n(struct drm_vmw_fence_event_arg *) data;\r\nstruct vmw_fence_obj *fence = NULL;\r\nstruct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);\r\nstruct drm_vmw_fence_rep __user *user_fence_rep =\r\n(struct drm_vmw_fence_rep __user *)(unsigned long)\r\narg->fence_rep;\r\nuint32_t handle;\r\nint ret;\r\nif (arg->handle) {\r\nstruct ttm_base_object *base =\r\nttm_base_object_lookup_for_ref(dev_priv->tdev,\r\narg->handle);\r\nif (unlikely(base == NULL)) {\r\nDRM_ERROR("Fence event invalid fence object handle "\r\n"0x%08lx.\n",\r\n(unsigned long)arg->handle);\r\nreturn -EINVAL;\r\n}\r\nfence = &(container_of(base, struct vmw_user_fence,\r\nbase)->fence);\r\n(void) vmw_fence_obj_reference(fence);\r\nif (user_fence_rep != NULL) {\r\nbool existed;\r\nret = ttm_ref_object_add(vmw_fp->tfile, base,\r\nTTM_REF_USAGE, &existed);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Failed to reference a fence "\r\n"object.\n");\r\ngoto out_no_ref_obj;\r\n}\r\nhandle = base->hash.key;\r\n}\r\nttm_base_object_unref(&base);\r\n}\r\nif (!fence) {\r\nret = vmw_execbuf_fence_commands(file_priv, dev_priv,\r\n&fence,\r\n(user_fence_rep) ?\r\n&handle : NULL);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Fence event failed to create fence.\n");\r\nreturn ret;\r\n}\r\n}\r\nBUG_ON(fence == NULL);\r\nret = vmw_event_fence_action_create(file_priv, fence,\r\narg->flags,\r\narg->user_data,\r\ntrue);\r\nif (unlikely(ret != 0)) {\r\nif (ret != -ERESTARTSYS)\r\nDRM_ERROR("Failed to attach event to fence.\n");\r\ngoto out_no_create;\r\n}\r\nvmw_execbuf_copy_fence_user(dev_priv, vmw_fp, 0, user_fence_rep, fence,\r\nhandle);\r\nvmw_fence_obj_unreference(&fence);\r\nreturn 0;\r\nout_no_create:\r\nif (user_fence_rep != NULL)\r\nttm_ref_object_base_unref(vmw_fpriv(file_priv)->tfile,\r\nhandle, TTM_REF_USAGE);\r\nout_no_ref_obj:\r\nvmw_fence_obj_unreference(&fence);\r\nreturn ret;\r\n}
