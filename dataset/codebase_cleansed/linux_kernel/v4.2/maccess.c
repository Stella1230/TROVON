static notrace long s390_kernel_write_odd(void *dst, const void *src, size_t size)\r\n{\r\nunsigned long aligned, offset, count;\r\nchar tmp[8];\r\naligned = (unsigned long) dst & ~7UL;\r\noffset = (unsigned long) dst & 7UL;\r\nsize = min(8UL - offset, size);\r\ncount = size - 1;\r\nasm volatile(\r\n" bras 1,0f\n"\r\n" mvc 0(1,%4),0(%5)\n"\r\n"0: mvc 0(8,%3),0(%0)\n"\r\n" ex %1,0(1)\n"\r\n" lg %1,0(%3)\n"\r\n" lra %0,0(%0)\n"\r\n" sturg %1,%0\n"\r\n: "+&a" (aligned), "+&a" (count), "=m" (tmp)\r\n: "a" (&tmp), "a" (&tmp[offset]), "a" (src)\r\n: "cc", "memory", "1");\r\nreturn size;\r\n}\r\nvoid notrace s390_kernel_write(void *dst, const void *src, size_t size)\r\n{\r\nlong copied;\r\nwhile (size) {\r\ncopied = s390_kernel_write_odd(dst, src, size);\r\ndst += copied;\r\nsrc += copied;\r\nsize -= copied;\r\n}\r\n}\r\nstatic int __memcpy_real(void *dest, void *src, size_t count)\r\n{\r\nregister unsigned long _dest asm("2") = (unsigned long) dest;\r\nregister unsigned long _len1 asm("3") = (unsigned long) count;\r\nregister unsigned long _src asm("4") = (unsigned long) src;\r\nregister unsigned long _len2 asm("5") = (unsigned long) count;\r\nint rc = -EFAULT;\r\nasm volatile (\r\n"0: mvcle %1,%2,0x0\n"\r\n"1: jo 0b\n"\r\n" lhi %0,0x0\n"\r\n"2:\n"\r\nEX_TABLE(1b,2b)\r\n: "+d" (rc), "+d" (_dest), "+d" (_src), "+d" (_len1),\r\n"+d" (_len2), "=m" (*((long *) dest))\r\n: "m" (*((long *) src))\r\n: "cc", "memory");\r\nreturn rc;\r\n}\r\nint memcpy_real(void *dest, void *src, size_t count)\r\n{\r\nunsigned long flags;\r\nint rc;\r\nif (!count)\r\nreturn 0;\r\nlocal_irq_save(flags);\r\n__arch_local_irq_stnsm(0xfbUL);\r\nrc = __memcpy_real(dest, src, count);\r\nlocal_irq_restore(flags);\r\nreturn rc;\r\n}\r\nvoid memcpy_absolute(void *dest, void *src, size_t count)\r\n{\r\nunsigned long cr0, flags, prefix;\r\nflags = arch_local_irq_save();\r\n__ctl_store(cr0, 0, 0);\r\n__ctl_clear_bit(0, 28);\r\nprefix = store_prefix();\r\nif (prefix) {\r\nlocal_mcck_disable();\r\nset_prefix(0);\r\nmemcpy(dest, src, count);\r\nset_prefix(prefix);\r\nlocal_mcck_enable();\r\n} else {\r\nmemcpy(dest, src, count);\r\n}\r\n__ctl_load(cr0, 0, 0);\r\narch_local_irq_restore(flags);\r\n}\r\nint copy_to_user_real(void __user *dest, void *src, unsigned long count)\r\n{\r\nint offs = 0, size, rc;\r\nchar *buf;\r\nbuf = (char *) __get_free_page(GFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\nrc = -EFAULT;\r\nwhile (offs < count) {\r\nsize = min(PAGE_SIZE, count - offs);\r\nif (memcpy_real(buf, src + offs, size))\r\ngoto out;\r\nif (copy_to_user(dest + offs, buf, size))\r\ngoto out;\r\noffs += size;\r\n}\r\nrc = 0;\r\nout:\r\nfree_page((unsigned long) buf);\r\nreturn rc;\r\n}\r\nstatic int is_swapped(unsigned long addr)\r\n{\r\nunsigned long lc;\r\nint cpu;\r\nif (addr < sizeof(struct _lowcore))\r\nreturn 1;\r\nfor_each_online_cpu(cpu) {\r\nlc = (unsigned long) lowcore_ptr[cpu];\r\nif (addr > lc + sizeof(struct _lowcore) - 1 || addr < lc)\r\ncontinue;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nvoid *xlate_dev_mem_ptr(phys_addr_t addr)\r\n{\r\nvoid *bounce = (void *) addr;\r\nunsigned long size;\r\nget_online_cpus();\r\npreempt_disable();\r\nif (is_swapped(addr)) {\r\nsize = PAGE_SIZE - (addr & ~PAGE_MASK);\r\nbounce = (void *) __get_free_page(GFP_ATOMIC);\r\nif (bounce)\r\nmemcpy_absolute(bounce, (void *) addr, size);\r\n}\r\npreempt_enable();\r\nput_online_cpus();\r\nreturn bounce;\r\n}\r\nvoid unxlate_dev_mem_ptr(phys_addr_t addr, void *buf)\r\n{\r\nif ((void *) addr != buf)\r\nfree_page((unsigned long) buf);\r\n}
