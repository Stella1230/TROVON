static inline u32 ethoc_read(struct ethoc *dev, loff_t offset)\r\n{\r\nreturn ioread32(dev->iobase + offset);\r\n}\r\nstatic inline void ethoc_write(struct ethoc *dev, loff_t offset, u32 data)\r\n{\r\niowrite32(data, dev->iobase + offset);\r\n}\r\nstatic inline void ethoc_read_bd(struct ethoc *dev, int index,\r\nstruct ethoc_bd *bd)\r\n{\r\nloff_t offset = ETHOC_BD_BASE + (index * sizeof(struct ethoc_bd));\r\nbd->stat = ethoc_read(dev, offset + 0);\r\nbd->addr = ethoc_read(dev, offset + 4);\r\n}\r\nstatic inline void ethoc_write_bd(struct ethoc *dev, int index,\r\nconst struct ethoc_bd *bd)\r\n{\r\nloff_t offset = ETHOC_BD_BASE + (index * sizeof(struct ethoc_bd));\r\nethoc_write(dev, offset + 0, bd->stat);\r\nethoc_write(dev, offset + 4, bd->addr);\r\n}\r\nstatic inline void ethoc_enable_irq(struct ethoc *dev, u32 mask)\r\n{\r\nu32 imask = ethoc_read(dev, INT_MASK);\r\nimask |= mask;\r\nethoc_write(dev, INT_MASK, imask);\r\n}\r\nstatic inline void ethoc_disable_irq(struct ethoc *dev, u32 mask)\r\n{\r\nu32 imask = ethoc_read(dev, INT_MASK);\r\nimask &= ~mask;\r\nethoc_write(dev, INT_MASK, imask);\r\n}\r\nstatic inline void ethoc_ack_irq(struct ethoc *dev, u32 mask)\r\n{\r\nethoc_write(dev, INT_SOURCE, mask);\r\n}\r\nstatic inline void ethoc_enable_rx_and_tx(struct ethoc *dev)\r\n{\r\nu32 mode = ethoc_read(dev, MODER);\r\nmode |= MODER_RXEN | MODER_TXEN;\r\nethoc_write(dev, MODER, mode);\r\n}\r\nstatic inline void ethoc_disable_rx_and_tx(struct ethoc *dev)\r\n{\r\nu32 mode = ethoc_read(dev, MODER);\r\nmode &= ~(MODER_RXEN | MODER_TXEN);\r\nethoc_write(dev, MODER, mode);\r\n}\r\nstatic int ethoc_init_ring(struct ethoc *dev, unsigned long mem_start)\r\n{\r\nstruct ethoc_bd bd;\r\nint i;\r\nvoid *vma;\r\ndev->cur_tx = 0;\r\ndev->dty_tx = 0;\r\ndev->cur_rx = 0;\r\nethoc_write(dev, TX_BD_NUM, dev->num_tx);\r\nbd.addr = mem_start;\r\nbd.stat = TX_BD_IRQ | TX_BD_CRC;\r\nvma = dev->membase;\r\nfor (i = 0; i < dev->num_tx; i++) {\r\nif (i == dev->num_tx - 1)\r\nbd.stat |= TX_BD_WRAP;\r\nethoc_write_bd(dev, i, &bd);\r\nbd.addr += ETHOC_BUFSIZ;\r\ndev->vma[i] = vma;\r\nvma += ETHOC_BUFSIZ;\r\n}\r\nbd.stat = RX_BD_EMPTY | RX_BD_IRQ;\r\nfor (i = 0; i < dev->num_rx; i++) {\r\nif (i == dev->num_rx - 1)\r\nbd.stat |= RX_BD_WRAP;\r\nethoc_write_bd(dev, dev->num_tx + i, &bd);\r\nbd.addr += ETHOC_BUFSIZ;\r\ndev->vma[dev->num_tx + i] = vma;\r\nvma += ETHOC_BUFSIZ;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ethoc_reset(struct ethoc *dev)\r\n{\r\nu32 mode;\r\nethoc_disable_rx_and_tx(dev);\r\nmode = ethoc_read(dev, MODER);\r\nmode |= MODER_CRC | MODER_PAD;\r\nethoc_write(dev, MODER, mode);\r\nmode = ethoc_read(dev, MODER);\r\nmode |= MODER_FULLD;\r\nethoc_write(dev, MODER, mode);\r\nethoc_write(dev, IPGT, 0x15);\r\nethoc_ack_irq(dev, INT_MASK_ALL);\r\nethoc_enable_irq(dev, INT_MASK_ALL);\r\nethoc_enable_rx_and_tx(dev);\r\nreturn 0;\r\n}\r\nstatic unsigned int ethoc_update_rx_stats(struct ethoc *dev,\r\nstruct ethoc_bd *bd)\r\n{\r\nstruct net_device *netdev = dev->netdev;\r\nunsigned int ret = 0;\r\nif (bd->stat & RX_BD_TL) {\r\ndev_err(&netdev->dev, "RX: frame too long\n");\r\nnetdev->stats.rx_length_errors++;\r\nret++;\r\n}\r\nif (bd->stat & RX_BD_SF) {\r\ndev_err(&netdev->dev, "RX: frame too short\n");\r\nnetdev->stats.rx_length_errors++;\r\nret++;\r\n}\r\nif (bd->stat & RX_BD_DN) {\r\ndev_err(&netdev->dev, "RX: dribble nibble\n");\r\nnetdev->stats.rx_frame_errors++;\r\n}\r\nif (bd->stat & RX_BD_CRC) {\r\ndev_err(&netdev->dev, "RX: wrong CRC\n");\r\nnetdev->stats.rx_crc_errors++;\r\nret++;\r\n}\r\nif (bd->stat & RX_BD_OR) {\r\ndev_err(&netdev->dev, "RX: overrun\n");\r\nnetdev->stats.rx_over_errors++;\r\nret++;\r\n}\r\nif (bd->stat & RX_BD_MISS)\r\nnetdev->stats.rx_missed_errors++;\r\nif (bd->stat & RX_BD_LC) {\r\ndev_err(&netdev->dev, "RX: late collision\n");\r\nnetdev->stats.collisions++;\r\nret++;\r\n}\r\nreturn ret;\r\n}\r\nstatic int ethoc_rx(struct net_device *dev, int limit)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nint count;\r\nfor (count = 0; count < limit; ++count) {\r\nunsigned int entry;\r\nstruct ethoc_bd bd;\r\nentry = priv->num_tx + priv->cur_rx;\r\nethoc_read_bd(priv, entry, &bd);\r\nif (bd.stat & RX_BD_EMPTY) {\r\nethoc_ack_irq(priv, INT_MASK_RX);\r\nethoc_read_bd(priv, entry, &bd);\r\nif (bd.stat & RX_BD_EMPTY)\r\nbreak;\r\n}\r\nif (ethoc_update_rx_stats(priv, &bd) == 0) {\r\nint size = bd.stat >> 16;\r\nstruct sk_buff *skb;\r\nsize -= 4;\r\nskb = netdev_alloc_skb_ip_align(dev, size);\r\nif (likely(skb)) {\r\nvoid *src = priv->vma[entry];\r\nmemcpy_fromio(skb_put(skb, size), src, size);\r\nskb->protocol = eth_type_trans(skb, dev);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += size;\r\nnetif_receive_skb(skb);\r\n} else {\r\nif (net_ratelimit())\r\ndev_warn(&dev->dev,\r\n"low on memory - packet dropped\n");\r\ndev->stats.rx_dropped++;\r\nbreak;\r\n}\r\n}\r\nbd.stat &= ~RX_BD_STATS;\r\nbd.stat |= RX_BD_EMPTY;\r\nethoc_write_bd(priv, entry, &bd);\r\nif (++priv->cur_rx == priv->num_rx)\r\npriv->cur_rx = 0;\r\n}\r\nreturn count;\r\n}\r\nstatic void ethoc_update_tx_stats(struct ethoc *dev, struct ethoc_bd *bd)\r\n{\r\nstruct net_device *netdev = dev->netdev;\r\nif (bd->stat & TX_BD_LC) {\r\ndev_err(&netdev->dev, "TX: late collision\n");\r\nnetdev->stats.tx_window_errors++;\r\n}\r\nif (bd->stat & TX_BD_RL) {\r\ndev_err(&netdev->dev, "TX: retransmit limit\n");\r\nnetdev->stats.tx_aborted_errors++;\r\n}\r\nif (bd->stat & TX_BD_UR) {\r\ndev_err(&netdev->dev, "TX: underrun\n");\r\nnetdev->stats.tx_fifo_errors++;\r\n}\r\nif (bd->stat & TX_BD_CS) {\r\ndev_err(&netdev->dev, "TX: carrier sense lost\n");\r\nnetdev->stats.tx_carrier_errors++;\r\n}\r\nif (bd->stat & TX_BD_STATS)\r\nnetdev->stats.tx_errors++;\r\nnetdev->stats.collisions += (bd->stat >> 4) & 0xf;\r\nnetdev->stats.tx_bytes += bd->stat >> 16;\r\nnetdev->stats.tx_packets++;\r\n}\r\nstatic int ethoc_tx(struct net_device *dev, int limit)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nint count;\r\nstruct ethoc_bd bd;\r\nfor (count = 0; count < limit; ++count) {\r\nunsigned int entry;\r\nentry = priv->dty_tx & (priv->num_tx-1);\r\nethoc_read_bd(priv, entry, &bd);\r\nif (bd.stat & TX_BD_READY || (priv->dty_tx == priv->cur_tx)) {\r\nethoc_ack_irq(priv, INT_MASK_TX);\r\nethoc_read_bd(priv, entry, &bd);\r\nif (bd.stat & TX_BD_READY ||\r\n(priv->dty_tx == priv->cur_tx))\r\nbreak;\r\n}\r\nethoc_update_tx_stats(priv, &bd);\r\npriv->dty_tx++;\r\n}\r\nif ((priv->cur_tx - priv->dty_tx) <= (priv->num_tx / 2))\r\nnetif_wake_queue(dev);\r\nreturn count;\r\n}\r\nstatic irqreturn_t ethoc_interrupt(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = dev_id;\r\nstruct ethoc *priv = netdev_priv(dev);\r\nu32 pending;\r\nu32 mask;\r\nmask = ethoc_read(priv, INT_MASK);\r\npending = ethoc_read(priv, INT_SOURCE);\r\npending &= mask;\r\nif (unlikely(pending == 0))\r\nreturn IRQ_NONE;\r\nethoc_ack_irq(priv, pending);\r\nif (pending & INT_MASK_BUSY) {\r\ndev_err(&dev->dev, "packet dropped\n");\r\ndev->stats.rx_dropped++;\r\n}\r\nif (pending & (INT_MASK_TX | INT_MASK_RX)) {\r\nethoc_disable_irq(priv, INT_MASK_TX | INT_MASK_RX);\r\nnapi_schedule(&priv->napi);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int ethoc_get_mac_address(struct net_device *dev, void *addr)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nu8 *mac = (u8 *)addr;\r\nu32 reg;\r\nreg = ethoc_read(priv, MAC_ADDR0);\r\nmac[2] = (reg >> 24) & 0xff;\r\nmac[3] = (reg >> 16) & 0xff;\r\nmac[4] = (reg >> 8) & 0xff;\r\nmac[5] = (reg >> 0) & 0xff;\r\nreg = ethoc_read(priv, MAC_ADDR1);\r\nmac[0] = (reg >> 8) & 0xff;\r\nmac[1] = (reg >> 0) & 0xff;\r\nreturn 0;\r\n}\r\nstatic int ethoc_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct ethoc *priv = container_of(napi, struct ethoc, napi);\r\nint rx_work_done = 0;\r\nint tx_work_done = 0;\r\nrx_work_done = ethoc_rx(priv->netdev, budget);\r\ntx_work_done = ethoc_tx(priv->netdev, budget);\r\nif (rx_work_done < budget && tx_work_done < budget) {\r\nnapi_complete(napi);\r\nethoc_enable_irq(priv, INT_MASK_TX | INT_MASK_RX);\r\n}\r\nreturn rx_work_done;\r\n}\r\nstatic int ethoc_mdio_read(struct mii_bus *bus, int phy, int reg)\r\n{\r\nstruct ethoc *priv = bus->priv;\r\nint i;\r\nethoc_write(priv, MIIADDRESS, MIIADDRESS_ADDR(phy, reg));\r\nethoc_write(priv, MIICOMMAND, MIICOMMAND_READ);\r\nfor (i = 0; i < 5; i++) {\r\nu32 status = ethoc_read(priv, MIISTATUS);\r\nif (!(status & MIISTATUS_BUSY)) {\r\nu32 data = ethoc_read(priv, MIIRX_DATA);\r\nethoc_write(priv, MIICOMMAND, 0);\r\nreturn data;\r\n}\r\nusleep_range(100, 200);\r\n}\r\nreturn -EBUSY;\r\n}\r\nstatic int ethoc_mdio_write(struct mii_bus *bus, int phy, int reg, u16 val)\r\n{\r\nstruct ethoc *priv = bus->priv;\r\nint i;\r\nethoc_write(priv, MIIADDRESS, MIIADDRESS_ADDR(phy, reg));\r\nethoc_write(priv, MIITX_DATA, val);\r\nethoc_write(priv, MIICOMMAND, MIICOMMAND_WRITE);\r\nfor (i = 0; i < 5; i++) {\r\nu32 stat = ethoc_read(priv, MIISTATUS);\r\nif (!(stat & MIISTATUS_BUSY)) {\r\nethoc_write(priv, MIICOMMAND, 0);\r\nreturn 0;\r\n}\r\nusleep_range(100, 200);\r\n}\r\nreturn -EBUSY;\r\n}\r\nstatic void ethoc_mdio_poll(struct net_device *dev)\r\n{\r\n}\r\nstatic int ethoc_mdio_probe(struct net_device *dev)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nstruct phy_device *phy;\r\nint err;\r\nif (priv->phy_id != -1)\r\nphy = priv->mdio->phy_map[priv->phy_id];\r\nelse\r\nphy = phy_find_first(priv->mdio);\r\nif (!phy) {\r\ndev_err(&dev->dev, "no PHY found\n");\r\nreturn -ENXIO;\r\n}\r\nerr = phy_connect_direct(dev, phy, ethoc_mdio_poll,\r\nPHY_INTERFACE_MODE_GMII);\r\nif (err) {\r\ndev_err(&dev->dev, "could not attach to PHY\n");\r\nreturn err;\r\n}\r\npriv->phy = phy;\r\nphy->advertising &= ~(ADVERTISED_1000baseT_Full |\r\nADVERTISED_1000baseT_Half);\r\nphy->supported &= ~(SUPPORTED_1000baseT_Full |\r\nSUPPORTED_1000baseT_Half);\r\nreturn 0;\r\n}\r\nstatic int ethoc_open(struct net_device *dev)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nint ret;\r\nret = request_irq(dev->irq, ethoc_interrupt, IRQF_SHARED,\r\ndev->name, dev);\r\nif (ret)\r\nreturn ret;\r\nethoc_init_ring(priv, dev->mem_start);\r\nethoc_reset(priv);\r\nif (netif_queue_stopped(dev)) {\r\ndev_dbg(&dev->dev, " resuming queue\n");\r\nnetif_wake_queue(dev);\r\n} else {\r\ndev_dbg(&dev->dev, " starting queue\n");\r\nnetif_start_queue(dev);\r\n}\r\nphy_start(priv->phy);\r\nnapi_enable(&priv->napi);\r\nif (netif_msg_ifup(priv)) {\r\ndev_info(&dev->dev, "I/O: %08lx Memory: %08lx-%08lx\n",\r\ndev->base_addr, dev->mem_start, dev->mem_end);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ethoc_stop(struct net_device *dev)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nnapi_disable(&priv->napi);\r\nif (priv->phy)\r\nphy_stop(priv->phy);\r\nethoc_disable_rx_and_tx(priv);\r\nfree_irq(dev->irq, dev);\r\nif (!netif_queue_stopped(dev))\r\nnetif_stop_queue(dev);\r\nreturn 0;\r\n}\r\nstatic int ethoc_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nstruct mii_ioctl_data *mdio = if_mii(ifr);\r\nstruct phy_device *phy = NULL;\r\nif (!netif_running(dev))\r\nreturn -EINVAL;\r\nif (cmd != SIOCGMIIPHY) {\r\nif (mdio->phy_id >= PHY_MAX_ADDR)\r\nreturn -ERANGE;\r\nphy = priv->mdio->phy_map[mdio->phy_id];\r\nif (!phy)\r\nreturn -ENODEV;\r\n} else {\r\nphy = priv->phy;\r\n}\r\nreturn phy_mii_ioctl(phy, ifr, cmd);\r\n}\r\nstatic void ethoc_do_set_mac_address(struct net_device *dev)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nunsigned char *mac = dev->dev_addr;\r\nethoc_write(priv, MAC_ADDR0, (mac[2] << 24) | (mac[3] << 16) |\r\n(mac[4] << 8) | (mac[5] << 0));\r\nethoc_write(priv, MAC_ADDR1, (mac[0] << 8) | (mac[1] << 0));\r\n}\r\nstatic int ethoc_set_mac_address(struct net_device *dev, void *p)\r\n{\r\nconst struct sockaddr *addr = p;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(dev->dev_addr, addr->sa_data, ETH_ALEN);\r\nethoc_do_set_mac_address(dev);\r\nreturn 0;\r\n}\r\nstatic void ethoc_set_multicast_list(struct net_device *dev)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nu32 mode = ethoc_read(priv, MODER);\r\nstruct netdev_hw_addr *ha;\r\nu32 hash[2] = { 0, 0 };\r\nif (dev->flags & IFF_LOOPBACK)\r\nmode |= MODER_LOOP;\r\nelse\r\nmode &= ~MODER_LOOP;\r\nif (dev->flags & IFF_BROADCAST)\r\nmode &= ~MODER_BRO;\r\nelse\r\nmode |= MODER_BRO;\r\nif (dev->flags & IFF_PROMISC)\r\nmode |= MODER_PRO;\r\nelse\r\nmode &= ~MODER_PRO;\r\nethoc_write(priv, MODER, mode);\r\nif (dev->flags & IFF_ALLMULTI) {\r\nhash[0] = 0xffffffff;\r\nhash[1] = 0xffffffff;\r\n} else {\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nu32 crc = ether_crc(ETH_ALEN, ha->addr);\r\nint bit = (crc >> 26) & 0x3f;\r\nhash[bit >> 5] |= 1 << (bit & 0x1f);\r\n}\r\n}\r\nethoc_write(priv, ETH_HASH0, hash[0]);\r\nethoc_write(priv, ETH_HASH1, hash[1]);\r\n}\r\nstatic int ethoc_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic void ethoc_tx_timeout(struct net_device *dev)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nu32 pending = ethoc_read(priv, INT_SOURCE);\r\nif (likely(pending))\r\nethoc_interrupt(dev->irq, dev);\r\n}\r\nstatic netdev_tx_t ethoc_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nstruct ethoc_bd bd;\r\nunsigned int entry;\r\nvoid *dest;\r\nif (unlikely(skb->len > ETHOC_BUFSIZ)) {\r\ndev->stats.tx_errors++;\r\ngoto out;\r\n}\r\nentry = priv->cur_tx % priv->num_tx;\r\nspin_lock_irq(&priv->lock);\r\npriv->cur_tx++;\r\nethoc_read_bd(priv, entry, &bd);\r\nif (unlikely(skb->len < ETHOC_ZLEN))\r\nbd.stat |= TX_BD_PAD;\r\nelse\r\nbd.stat &= ~TX_BD_PAD;\r\ndest = priv->vma[entry];\r\nmemcpy_toio(dest, skb->data, skb->len);\r\nbd.stat &= ~(TX_BD_STATS | TX_BD_LEN_MASK);\r\nbd.stat |= TX_BD_LEN(skb->len);\r\nethoc_write_bd(priv, entry, &bd);\r\nbd.stat |= TX_BD_READY;\r\nethoc_write_bd(priv, entry, &bd);\r\nif (priv->cur_tx == (priv->dty_tx + priv->num_tx)) {\r\ndev_dbg(&dev->dev, "stopping queue\n");\r\nnetif_stop_queue(dev);\r\n}\r\nspin_unlock_irq(&priv->lock);\r\nskb_tx_timestamp(skb);\r\nout:\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int ethoc_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nstruct phy_device *phydev = priv->phy;\r\nif (!phydev)\r\nreturn -EOPNOTSUPP;\r\nreturn phy_ethtool_gset(phydev, cmd);\r\n}\r\nstatic int ethoc_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nstruct phy_device *phydev = priv->phy;\r\nif (!phydev)\r\nreturn -EOPNOTSUPP;\r\nreturn phy_ethtool_sset(phydev, cmd);\r\n}\r\nstatic int ethoc_get_regs_len(struct net_device *netdev)\r\n{\r\nreturn ETH_END;\r\n}\r\nstatic void ethoc_get_regs(struct net_device *dev, struct ethtool_regs *regs,\r\nvoid *p)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nu32 *regs_buff = p;\r\nunsigned i;\r\nregs->version = 0;\r\nfor (i = 0; i < ETH_END / sizeof(u32); ++i)\r\nregs_buff[i] = ethoc_read(priv, i * sizeof(u32));\r\n}\r\nstatic void ethoc_get_ringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *ring)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nring->rx_max_pending = priv->num_bd - 1;\r\nring->rx_mini_max_pending = 0;\r\nring->rx_jumbo_max_pending = 0;\r\nring->tx_max_pending = priv->num_bd - 1;\r\nring->rx_pending = priv->num_rx;\r\nring->rx_mini_pending = 0;\r\nring->rx_jumbo_pending = 0;\r\nring->tx_pending = priv->num_tx;\r\n}\r\nstatic int ethoc_set_ringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *ring)\r\n{\r\nstruct ethoc *priv = netdev_priv(dev);\r\nif (ring->tx_pending < 1 || ring->rx_pending < 1 ||\r\nring->tx_pending + ring->rx_pending > priv->num_bd)\r\nreturn -EINVAL;\r\nif (ring->rx_mini_pending || ring->rx_jumbo_pending)\r\nreturn -EINVAL;\r\nif (netif_running(dev)) {\r\nnetif_tx_disable(dev);\r\nethoc_disable_rx_and_tx(priv);\r\nethoc_disable_irq(priv, INT_MASK_TX | INT_MASK_RX);\r\nsynchronize_irq(dev->irq);\r\n}\r\npriv->num_tx = rounddown_pow_of_two(ring->tx_pending);\r\npriv->num_rx = ring->rx_pending;\r\nethoc_init_ring(priv, dev->mem_start);\r\nif (netif_running(dev)) {\r\nethoc_enable_irq(priv, INT_MASK_TX | INT_MASK_RX);\r\nethoc_enable_rx_and_tx(priv);\r\nnetif_wake_queue(dev);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ethoc_probe(struct platform_device *pdev)\r\n{\r\nstruct net_device *netdev = NULL;\r\nstruct resource *res = NULL;\r\nstruct resource *mmio = NULL;\r\nstruct resource *mem = NULL;\r\nstruct ethoc *priv = NULL;\r\nunsigned int phy;\r\nint num_bd;\r\nint ret = 0;\r\nbool random_mac = false;\r\nstruct ethoc_platform_data *pdata = dev_get_platdata(&pdev->dev);\r\nu32 eth_clkfreq = pdata ? pdata->eth_clkfreq : 0;\r\nnetdev = alloc_etherdev(sizeof(struct ethoc));\r\nif (!netdev) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\nplatform_set_drvdata(pdev, netdev);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(&pdev->dev, "cannot obtain I/O memory space\n");\r\nret = -ENXIO;\r\ngoto free;\r\n}\r\nmmio = devm_request_mem_region(&pdev->dev, res->start,\r\nresource_size(res), res->name);\r\nif (!mmio) {\r\ndev_err(&pdev->dev, "cannot request I/O memory space\n");\r\nret = -ENXIO;\r\ngoto free;\r\n}\r\nnetdev->base_addr = mmio->start;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 1);\r\nif (res) {\r\nmem = devm_request_mem_region(&pdev->dev, res->start,\r\nresource_size(res), res->name);\r\nif (!mem) {\r\ndev_err(&pdev->dev, "cannot request memory space\n");\r\nret = -ENXIO;\r\ngoto free;\r\n}\r\nnetdev->mem_start = mem->start;\r\nnetdev->mem_end = mem->end;\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\r\nif (!res) {\r\ndev_err(&pdev->dev, "cannot obtain IRQ\n");\r\nret = -ENXIO;\r\ngoto free;\r\n}\r\nnetdev->irq = res->start;\r\npriv = netdev_priv(netdev);\r\npriv->netdev = netdev;\r\npriv->dma_alloc = 0;\r\npriv->io_region_size = resource_size(mmio);\r\npriv->iobase = devm_ioremap_nocache(&pdev->dev, netdev->base_addr,\r\nresource_size(mmio));\r\nif (!priv->iobase) {\r\ndev_err(&pdev->dev, "cannot remap I/O memory space\n");\r\nret = -ENXIO;\r\ngoto error;\r\n}\r\nif (netdev->mem_end) {\r\npriv->membase = devm_ioremap_nocache(&pdev->dev,\r\nnetdev->mem_start, resource_size(mem));\r\nif (!priv->membase) {\r\ndev_err(&pdev->dev, "cannot remap memory space\n");\r\nret = -ENXIO;\r\ngoto error;\r\n}\r\n} else {\r\npriv->membase = dmam_alloc_coherent(&pdev->dev,\r\nbuffer_size, (void *)&netdev->mem_start,\r\nGFP_KERNEL);\r\nif (!priv->membase) {\r\ndev_err(&pdev->dev, "cannot allocate %dB buffer\n",\r\nbuffer_size);\r\nret = -ENOMEM;\r\ngoto error;\r\n}\r\nnetdev->mem_end = netdev->mem_start + buffer_size;\r\npriv->dma_alloc = buffer_size;\r\n}\r\nnum_bd = min_t(unsigned int,\r\n128, (netdev->mem_end - netdev->mem_start + 1) / ETHOC_BUFSIZ);\r\nif (num_bd < 4) {\r\nret = -ENODEV;\r\ngoto error;\r\n}\r\npriv->num_bd = num_bd;\r\npriv->num_tx = rounddown_pow_of_two(num_bd >> 1);\r\npriv->num_rx = num_bd - priv->num_tx;\r\ndev_dbg(&pdev->dev, "ethoc: num_tx: %d num_rx: %d\n",\r\npriv->num_tx, priv->num_rx);\r\npriv->vma = devm_kzalloc(&pdev->dev, num_bd*sizeof(void *), GFP_KERNEL);\r\nif (!priv->vma) {\r\nret = -ENOMEM;\r\ngoto error;\r\n}\r\nif (pdata) {\r\nmemcpy(netdev->dev_addr, pdata->hwaddr, IFHWADDRLEN);\r\npriv->phy_id = pdata->phy_id;\r\n} else {\r\npriv->phy_id = -1;\r\n#ifdef CONFIG_OF\r\n{\r\nconst uint8_t *mac;\r\nmac = of_get_property(pdev->dev.of_node,\r\n"local-mac-address",\r\nNULL);\r\nif (mac)\r\nmemcpy(netdev->dev_addr, mac, IFHWADDRLEN);\r\n}\r\n#endif\r\n}\r\nif (!is_valid_ether_addr(netdev->dev_addr))\r\nethoc_get_mac_address(netdev, netdev->dev_addr);\r\nif (!is_valid_ether_addr(netdev->dev_addr)) {\r\neth_random_addr(netdev->dev_addr);\r\nrandom_mac = true;\r\n}\r\nethoc_do_set_mac_address(netdev);\r\nif (random_mac)\r\nnetdev->addr_assign_type = NET_ADDR_RANDOM;\r\nif (!eth_clkfreq) {\r\nstruct clk *clk = devm_clk_get(&pdev->dev, NULL);\r\nif (!IS_ERR(clk)) {\r\npriv->clk = clk;\r\nclk_prepare_enable(clk);\r\neth_clkfreq = clk_get_rate(clk);\r\n}\r\n}\r\nif (eth_clkfreq) {\r\nu32 clkdiv = MIIMODER_CLKDIV(eth_clkfreq / 2500000 + 1);\r\nif (!clkdiv)\r\nclkdiv = 2;\r\ndev_dbg(&pdev->dev, "setting MII clkdiv to %u\n", clkdiv);\r\nethoc_write(priv, MIIMODER,\r\n(ethoc_read(priv, MIIMODER) & MIIMODER_NOPRE) |\r\nclkdiv);\r\n}\r\npriv->mdio = mdiobus_alloc();\r\nif (!priv->mdio) {\r\nret = -ENOMEM;\r\ngoto free;\r\n}\r\npriv->mdio->name = "ethoc-mdio";\r\nsnprintf(priv->mdio->id, MII_BUS_ID_SIZE, "%s-%d",\r\npriv->mdio->name, pdev->id);\r\npriv->mdio->read = ethoc_mdio_read;\r\npriv->mdio->write = ethoc_mdio_write;\r\npriv->mdio->priv = priv;\r\npriv->mdio->irq = kmalloc(sizeof(int) * PHY_MAX_ADDR, GFP_KERNEL);\r\nif (!priv->mdio->irq) {\r\nret = -ENOMEM;\r\ngoto free_mdio;\r\n}\r\nfor (phy = 0; phy < PHY_MAX_ADDR; phy++)\r\npriv->mdio->irq[phy] = PHY_POLL;\r\nret = mdiobus_register(priv->mdio);\r\nif (ret) {\r\ndev_err(&netdev->dev, "failed to register MDIO bus\n");\r\ngoto free_mdio;\r\n}\r\nret = ethoc_mdio_probe(netdev);\r\nif (ret) {\r\ndev_err(&netdev->dev, "failed to probe MDIO bus\n");\r\ngoto error;\r\n}\r\nnetdev->netdev_ops = &ethoc_netdev_ops;\r\nnetdev->watchdog_timeo = ETHOC_TIMEOUT;\r\nnetdev->features |= 0;\r\nnetdev->ethtool_ops = &ethoc_ethtool_ops;\r\nnetif_napi_add(netdev, &priv->napi, ethoc_poll, 64);\r\nspin_lock_init(&priv->lock);\r\nret = register_netdev(netdev);\r\nif (ret < 0) {\r\ndev_err(&netdev->dev, "failed to register interface\n");\r\ngoto error2;\r\n}\r\ngoto out;\r\nerror2:\r\nnetif_napi_del(&priv->napi);\r\nerror:\r\nmdiobus_unregister(priv->mdio);\r\nfree_mdio:\r\nkfree(priv->mdio->irq);\r\nmdiobus_free(priv->mdio);\r\nfree:\r\nif (priv->clk)\r\nclk_disable_unprepare(priv->clk);\r\nfree_netdev(netdev);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int ethoc_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *netdev = platform_get_drvdata(pdev);\r\nstruct ethoc *priv = netdev_priv(netdev);\r\nif (netdev) {\r\nnetif_napi_del(&priv->napi);\r\nphy_disconnect(priv->phy);\r\npriv->phy = NULL;\r\nif (priv->mdio) {\r\nmdiobus_unregister(priv->mdio);\r\nkfree(priv->mdio->irq);\r\nmdiobus_free(priv->mdio);\r\n}\r\nif (priv->clk)\r\nclk_disable_unprepare(priv->clk);\r\nunregister_netdev(netdev);\r\nfree_netdev(netdev);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ethoc_suspend(struct platform_device *pdev, pm_message_t state)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic int ethoc_resume(struct platform_device *pdev)\r\n{\r\nreturn -ENOSYS;\r\n}
