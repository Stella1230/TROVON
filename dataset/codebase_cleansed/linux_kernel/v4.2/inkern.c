int iio_map_array_register(struct iio_dev *indio_dev, struct iio_map *maps)\r\n{\r\nint i = 0, ret = 0;\r\nstruct iio_map_internal *mapi;\r\nif (maps == NULL)\r\nreturn 0;\r\nmutex_lock(&iio_map_list_lock);\r\nwhile (maps[i].consumer_dev_name != NULL) {\r\nmapi = kzalloc(sizeof(*mapi), GFP_KERNEL);\r\nif (mapi == NULL) {\r\nret = -ENOMEM;\r\ngoto error_ret;\r\n}\r\nmapi->map = &maps[i];\r\nmapi->indio_dev = indio_dev;\r\nlist_add(&mapi->l, &iio_map_list);\r\ni++;\r\n}\r\nerror_ret:\r\nmutex_unlock(&iio_map_list_lock);\r\nreturn ret;\r\n}\r\nint iio_map_array_unregister(struct iio_dev *indio_dev)\r\n{\r\nint ret = -ENODEV;\r\nstruct iio_map_internal *mapi;\r\nstruct list_head *pos, *tmp;\r\nmutex_lock(&iio_map_list_lock);\r\nlist_for_each_safe(pos, tmp, &iio_map_list) {\r\nmapi = list_entry(pos, struct iio_map_internal, l);\r\nif (indio_dev == mapi->indio_dev) {\r\nlist_del(&mapi->l);\r\nkfree(mapi);\r\nret = 0;\r\n}\r\n}\r\nmutex_unlock(&iio_map_list_lock);\r\nreturn ret;\r\n}\r\nstatic const struct iio_chan_spec\r\n*iio_chan_spec_from_name(const struct iio_dev *indio_dev, const char *name)\r\n{\r\nint i;\r\nconst struct iio_chan_spec *chan = NULL;\r\nfor (i = 0; i < indio_dev->num_channels; i++)\r\nif (indio_dev->channels[i].datasheet_name &&\r\nstrcmp(name, indio_dev->channels[i].datasheet_name) == 0) {\r\nchan = &indio_dev->channels[i];\r\nbreak;\r\n}\r\nreturn chan;\r\n}\r\nstatic int iio_dev_node_match(struct device *dev, void *data)\r\n{\r\nreturn dev->of_node == data && dev->type == &iio_device_type;\r\n}\r\nstatic int __of_iio_simple_xlate(struct iio_dev *indio_dev,\r\nconst struct of_phandle_args *iiospec)\r\n{\r\nif (!iiospec->args_count)\r\nreturn 0;\r\nif (iiospec->args[0] >= indio_dev->num_channels) {\r\ndev_err(&indio_dev->dev, "invalid channel index %u\n",\r\niiospec->args[0]);\r\nreturn -EINVAL;\r\n}\r\nreturn iiospec->args[0];\r\n}\r\nstatic int __of_iio_channel_get(struct iio_channel *channel,\r\nstruct device_node *np, int index)\r\n{\r\nstruct device *idev;\r\nstruct iio_dev *indio_dev;\r\nint err;\r\nstruct of_phandle_args iiospec;\r\nerr = of_parse_phandle_with_args(np, "io-channels",\r\n"#io-channel-cells",\r\nindex, &iiospec);\r\nif (err)\r\nreturn err;\r\nidev = bus_find_device(&iio_bus_type, NULL, iiospec.np,\r\niio_dev_node_match);\r\nof_node_put(iiospec.np);\r\nif (idev == NULL)\r\nreturn -EPROBE_DEFER;\r\nindio_dev = dev_to_iio_dev(idev);\r\nchannel->indio_dev = indio_dev;\r\nif (indio_dev->info->of_xlate)\r\nindex = indio_dev->info->of_xlate(indio_dev, &iiospec);\r\nelse\r\nindex = __of_iio_simple_xlate(indio_dev, &iiospec);\r\nif (index < 0)\r\ngoto err_put;\r\nchannel->channel = &indio_dev->channels[index];\r\nreturn 0;\r\nerr_put:\r\niio_device_put(indio_dev);\r\nreturn index;\r\n}\r\nstatic struct iio_channel *of_iio_channel_get(struct device_node *np, int index)\r\n{\r\nstruct iio_channel *channel;\r\nint err;\r\nif (index < 0)\r\nreturn ERR_PTR(-EINVAL);\r\nchannel = kzalloc(sizeof(*channel), GFP_KERNEL);\r\nif (channel == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nerr = __of_iio_channel_get(channel, np, index);\r\nif (err)\r\ngoto err_free_channel;\r\nreturn channel;\r\nerr_free_channel:\r\nkfree(channel);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic struct iio_channel *of_iio_channel_get_by_name(struct device_node *np,\r\nconst char *name)\r\n{\r\nstruct iio_channel *chan = NULL;\r\nwhile (np) {\r\nint index = 0;\r\nif (name)\r\nindex = of_property_match_string(np, "io-channel-names",\r\nname);\r\nchan = of_iio_channel_get(np, index);\r\nif (!IS_ERR(chan) || PTR_ERR(chan) == -EPROBE_DEFER)\r\nbreak;\r\nelse if (name && index >= 0) {\r\npr_err("ERROR: could not get IIO channel %s:%s(%i)\n",\r\nnp->full_name, name ? name : "", index);\r\nreturn NULL;\r\n}\r\nnp = np->parent;\r\nif (np && !of_get_property(np, "io-channel-ranges", NULL))\r\nreturn NULL;\r\n}\r\nreturn chan;\r\n}\r\nstatic struct iio_channel *of_iio_channel_get_all(struct device *dev)\r\n{\r\nstruct iio_channel *chans;\r\nint i, mapind, nummaps = 0;\r\nint ret;\r\ndo {\r\nret = of_parse_phandle_with_args(dev->of_node,\r\n"io-channels",\r\n"#io-channel-cells",\r\nnummaps, NULL);\r\nif (ret < 0)\r\nbreak;\r\n} while (++nummaps);\r\nif (nummaps == 0)\r\nreturn NULL;\r\nchans = kcalloc(nummaps + 1, sizeof(*chans), GFP_KERNEL);\r\nif (chans == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nfor (mapind = 0; mapind < nummaps; mapind++) {\r\nret = __of_iio_channel_get(&chans[mapind], dev->of_node,\r\nmapind);\r\nif (ret)\r\ngoto error_free_chans;\r\n}\r\nreturn chans;\r\nerror_free_chans:\r\nfor (i = 0; i < mapind; i++)\r\niio_device_put(chans[i].indio_dev);\r\nkfree(chans);\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic inline struct iio_channel *\r\nof_iio_channel_get_by_name(struct device_node *np, const char *name)\r\n{\r\nreturn NULL;\r\n}\r\nstatic inline struct iio_channel *of_iio_channel_get_all(struct device *dev)\r\n{\r\nreturn NULL;\r\n}\r\nstatic struct iio_channel *iio_channel_get_sys(const char *name,\r\nconst char *channel_name)\r\n{\r\nstruct iio_map_internal *c_i = NULL, *c = NULL;\r\nstruct iio_channel *channel;\r\nint err;\r\nif (name == NULL && channel_name == NULL)\r\nreturn ERR_PTR(-ENODEV);\r\nmutex_lock(&iio_map_list_lock);\r\nlist_for_each_entry(c_i, &iio_map_list, l) {\r\nif ((name && strcmp(name, c_i->map->consumer_dev_name) != 0) ||\r\n(channel_name &&\r\nstrcmp(channel_name, c_i->map->consumer_channel) != 0))\r\ncontinue;\r\nc = c_i;\r\niio_device_get(c->indio_dev);\r\nbreak;\r\n}\r\nmutex_unlock(&iio_map_list_lock);\r\nif (c == NULL)\r\nreturn ERR_PTR(-ENODEV);\r\nchannel = kzalloc(sizeof(*channel), GFP_KERNEL);\r\nif (channel == NULL) {\r\nerr = -ENOMEM;\r\ngoto error_no_mem;\r\n}\r\nchannel->indio_dev = c->indio_dev;\r\nif (c->map->adc_channel_label) {\r\nchannel->channel =\r\niio_chan_spec_from_name(channel->indio_dev,\r\nc->map->adc_channel_label);\r\nif (channel->channel == NULL) {\r\nerr = -EINVAL;\r\ngoto error_no_chan;\r\n}\r\n}\r\nreturn channel;\r\nerror_no_chan:\r\nkfree(channel);\r\nerror_no_mem:\r\niio_device_put(c->indio_dev);\r\nreturn ERR_PTR(err);\r\n}\r\nstruct iio_channel *iio_channel_get(struct device *dev,\r\nconst char *channel_name)\r\n{\r\nconst char *name = dev ? dev_name(dev) : NULL;\r\nstruct iio_channel *channel;\r\nif (dev) {\r\nchannel = of_iio_channel_get_by_name(dev->of_node,\r\nchannel_name);\r\nif (channel != NULL)\r\nreturn channel;\r\n}\r\nreturn iio_channel_get_sys(name, channel_name);\r\n}\r\nvoid iio_channel_release(struct iio_channel *channel)\r\n{\r\niio_device_put(channel->indio_dev);\r\nkfree(channel);\r\n}\r\nstruct iio_channel *iio_channel_get_all(struct device *dev)\r\n{\r\nconst char *name;\r\nstruct iio_channel *chans;\r\nstruct iio_map_internal *c = NULL;\r\nint nummaps = 0;\r\nint mapind = 0;\r\nint i, ret;\r\nif (dev == NULL)\r\nreturn ERR_PTR(-EINVAL);\r\nchans = of_iio_channel_get_all(dev);\r\nif (chans)\r\nreturn chans;\r\nname = dev_name(dev);\r\nmutex_lock(&iio_map_list_lock);\r\nlist_for_each_entry(c, &iio_map_list, l)\r\nif (name && strcmp(name, c->map->consumer_dev_name) != 0)\r\ncontinue;\r\nelse\r\nnummaps++;\r\nif (nummaps == 0) {\r\nret = -ENODEV;\r\ngoto error_ret;\r\n}\r\nchans = kzalloc(sizeof(*chans)*(nummaps + 1), GFP_KERNEL);\r\nif (chans == NULL) {\r\nret = -ENOMEM;\r\ngoto error_ret;\r\n}\r\nlist_for_each_entry(c, &iio_map_list, l) {\r\nif (name && strcmp(name, c->map->consumer_dev_name) != 0)\r\ncontinue;\r\nchans[mapind].indio_dev = c->indio_dev;\r\nchans[mapind].data = c->map->consumer_data;\r\nchans[mapind].channel =\r\niio_chan_spec_from_name(chans[mapind].indio_dev,\r\nc->map->adc_channel_label);\r\nif (chans[mapind].channel == NULL) {\r\nret = -EINVAL;\r\ngoto error_free_chans;\r\n}\r\niio_device_get(chans[mapind].indio_dev);\r\nmapind++;\r\n}\r\nif (mapind == 0) {\r\nret = -ENODEV;\r\ngoto error_free_chans;\r\n}\r\nmutex_unlock(&iio_map_list_lock);\r\nreturn chans;\r\nerror_free_chans:\r\nfor (i = 0; i < nummaps; i++)\r\niio_device_put(chans[i].indio_dev);\r\nkfree(chans);\r\nerror_ret:\r\nmutex_unlock(&iio_map_list_lock);\r\nreturn ERR_PTR(ret);\r\n}\r\nvoid iio_channel_release_all(struct iio_channel *channels)\r\n{\r\nstruct iio_channel *chan = &channels[0];\r\nwhile (chan->indio_dev) {\r\niio_device_put(chan->indio_dev);\r\nchan++;\r\n}\r\nkfree(channels);\r\n}\r\nstatic int iio_channel_read(struct iio_channel *chan, int *val, int *val2,\r\nenum iio_chan_info_enum info)\r\n{\r\nint unused;\r\nint vals[INDIO_MAX_RAW_ELEMENTS];\r\nint ret;\r\nint val_len = 2;\r\nif (val2 == NULL)\r\nval2 = &unused;\r\nif(!iio_channel_has_info(chan->channel, info))\r\nreturn -EINVAL;\r\nif (chan->indio_dev->info->read_raw_multi) {\r\nret = chan->indio_dev->info->read_raw_multi(chan->indio_dev,\r\nchan->channel, INDIO_MAX_RAW_ELEMENTS,\r\nvals, &val_len, info);\r\n*val = vals[0];\r\n*val2 = vals[1];\r\n} else\r\nret = chan->indio_dev->info->read_raw(chan->indio_dev,\r\nchan->channel, val, val2, info);\r\nreturn ret;\r\n}\r\nint iio_read_channel_raw(struct iio_channel *chan, int *val)\r\n{\r\nint ret;\r\nmutex_lock(&chan->indio_dev->info_exist_lock);\r\nif (chan->indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto err_unlock;\r\n}\r\nret = iio_channel_read(chan, val, NULL, IIO_CHAN_INFO_RAW);\r\nerr_unlock:\r\nmutex_unlock(&chan->indio_dev->info_exist_lock);\r\nreturn ret;\r\n}\r\nint iio_read_channel_average_raw(struct iio_channel *chan, int *val)\r\n{\r\nint ret;\r\nmutex_lock(&chan->indio_dev->info_exist_lock);\r\nif (chan->indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto err_unlock;\r\n}\r\nret = iio_channel_read(chan, val, NULL, IIO_CHAN_INFO_AVERAGE_RAW);\r\nerr_unlock:\r\nmutex_unlock(&chan->indio_dev->info_exist_lock);\r\nreturn ret;\r\n}\r\nstatic int iio_convert_raw_to_processed_unlocked(struct iio_channel *chan,\r\nint raw, int *processed, unsigned int scale)\r\n{\r\nint scale_type, scale_val, scale_val2, offset;\r\ns64 raw64 = raw;\r\nint ret;\r\nret = iio_channel_read(chan, &offset, NULL, IIO_CHAN_INFO_OFFSET);\r\nif (ret >= 0)\r\nraw64 += offset;\r\nscale_type = iio_channel_read(chan, &scale_val, &scale_val2,\r\nIIO_CHAN_INFO_SCALE);\r\nif (scale_type < 0)\r\nreturn scale_type;\r\nswitch (scale_type) {\r\ncase IIO_VAL_INT:\r\n*processed = raw64 * scale_val;\r\nbreak;\r\ncase IIO_VAL_INT_PLUS_MICRO:\r\nif (scale_val2 < 0)\r\n*processed = -raw64 * scale_val;\r\nelse\r\n*processed = raw64 * scale_val;\r\n*processed += div_s64(raw64 * (s64)scale_val2 * scale,\r\n1000000LL);\r\nbreak;\r\ncase IIO_VAL_INT_PLUS_NANO:\r\nif (scale_val2 < 0)\r\n*processed = -raw64 * scale_val;\r\nelse\r\n*processed = raw64 * scale_val;\r\n*processed += div_s64(raw64 * (s64)scale_val2 * scale,\r\n1000000000LL);\r\nbreak;\r\ncase IIO_VAL_FRACTIONAL:\r\n*processed = div_s64(raw64 * (s64)scale_val * scale,\r\nscale_val2);\r\nbreak;\r\ncase IIO_VAL_FRACTIONAL_LOG2:\r\n*processed = (raw64 * (s64)scale_val * scale) >> scale_val2;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint iio_convert_raw_to_processed(struct iio_channel *chan, int raw,\r\nint *processed, unsigned int scale)\r\n{\r\nint ret;\r\nmutex_lock(&chan->indio_dev->info_exist_lock);\r\nif (chan->indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto err_unlock;\r\n}\r\nret = iio_convert_raw_to_processed_unlocked(chan, raw, processed,\r\nscale);\r\nerr_unlock:\r\nmutex_unlock(&chan->indio_dev->info_exist_lock);\r\nreturn ret;\r\n}\r\nint iio_read_channel_processed(struct iio_channel *chan, int *val)\r\n{\r\nint ret;\r\nmutex_lock(&chan->indio_dev->info_exist_lock);\r\nif (chan->indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto err_unlock;\r\n}\r\nif (iio_channel_has_info(chan->channel, IIO_CHAN_INFO_PROCESSED)) {\r\nret = iio_channel_read(chan, val, NULL,\r\nIIO_CHAN_INFO_PROCESSED);\r\n} else {\r\nret = iio_channel_read(chan, val, NULL, IIO_CHAN_INFO_RAW);\r\nif (ret < 0)\r\ngoto err_unlock;\r\nret = iio_convert_raw_to_processed_unlocked(chan, *val, val, 1);\r\n}\r\nerr_unlock:\r\nmutex_unlock(&chan->indio_dev->info_exist_lock);\r\nreturn ret;\r\n}\r\nint iio_read_channel_scale(struct iio_channel *chan, int *val, int *val2)\r\n{\r\nint ret;\r\nmutex_lock(&chan->indio_dev->info_exist_lock);\r\nif (chan->indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto err_unlock;\r\n}\r\nret = iio_channel_read(chan, val, val2, IIO_CHAN_INFO_SCALE);\r\nerr_unlock:\r\nmutex_unlock(&chan->indio_dev->info_exist_lock);\r\nreturn ret;\r\n}\r\nint iio_get_channel_type(struct iio_channel *chan, enum iio_chan_type *type)\r\n{\r\nint ret = 0;\r\nmutex_lock(&chan->indio_dev->info_exist_lock);\r\nif (chan->indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto err_unlock;\r\n}\r\n*type = chan->channel->type;\r\nerr_unlock:\r\nmutex_unlock(&chan->indio_dev->info_exist_lock);\r\nreturn ret;\r\n}\r\nstatic int iio_channel_write(struct iio_channel *chan, int val, int val2,\r\nenum iio_chan_info_enum info)\r\n{\r\nreturn chan->indio_dev->info->write_raw(chan->indio_dev,\r\nchan->channel, val, val2, info);\r\n}\r\nint iio_write_channel_raw(struct iio_channel *chan, int val)\r\n{\r\nint ret;\r\nmutex_lock(&chan->indio_dev->info_exist_lock);\r\nif (chan->indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto err_unlock;\r\n}\r\nret = iio_channel_write(chan, val, 0, IIO_CHAN_INFO_RAW);\r\nerr_unlock:\r\nmutex_unlock(&chan->indio_dev->info_exist_lock);\r\nreturn ret;\r\n}
