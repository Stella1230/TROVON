static void sxgbe_mtl_init(void __iomem *ioaddr, unsigned int etsalg,\r\nunsigned int raa)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_OP_MODE_REG);\r\nreg_val &= ETS_RST;\r\nswitch (etsalg & SXGBE_MTL_OPMODE_ESTMASK) {\r\ncase ETS_WRR:\r\nreg_val &= ETS_WRR;\r\nbreak;\r\ncase ETS_WFQ:\r\nreg_val |= ETS_WFQ;\r\nbreak;\r\ncase ETS_DWRR:\r\nreg_val |= ETS_DWRR;\r\nbreak;\r\n}\r\nwritel(reg_val, ioaddr + SXGBE_MTL_OP_MODE_REG);\r\nswitch (raa & SXGBE_MTL_OPMODE_RAAMASK) {\r\ncase RAA_SP:\r\nreg_val &= RAA_SP;\r\nbreak;\r\ncase RAA_WSP:\r\nreg_val |= RAA_WSP;\r\nbreak;\r\n}\r\nwritel(reg_val, ioaddr + SXGBE_MTL_OP_MODE_REG);\r\n}\r\nstatic void sxgbe_mtl_dma_dm_rxqueue(void __iomem *ioaddr)\r\n{\r\nwritel(RX_QUEUE_DYNAMIC, ioaddr + SXGBE_MTL_RXQ_DMAMAP0_REG);\r\nwritel(RX_QUEUE_DYNAMIC, ioaddr + SXGBE_MTL_RXQ_DMAMAP1_REG);\r\nwritel(RX_QUEUE_DYNAMIC, ioaddr + SXGBE_MTL_RXQ_DMAMAP2_REG);\r\n}\r\nstatic void sxgbe_mtl_set_txfifosize(void __iomem *ioaddr, int queue_num,\r\nint queue_fifo)\r\n{\r\nu32 fifo_bits, reg_val;\r\nfifo_bits = (queue_fifo / SXGBE_MTL_TX_FIFO_DIV) - 1;\r\nreg_val = readl(ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\nreg_val |= (fifo_bits << SXGBE_MTL_FIFO_LSHIFT);\r\nwritel(reg_val, ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_set_rxfifosize(void __iomem *ioaddr, int queue_num,\r\nint queue_fifo)\r\n{\r\nu32 fifo_bits, reg_val;\r\nfifo_bits = (queue_fifo / SXGBE_MTL_RX_FIFO_DIV)-1;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val |= (fifo_bits << SXGBE_MTL_FIFO_LSHIFT);\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_enable_txqueue(void __iomem *ioaddr, int queue_num)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\nreg_val |= SXGBE_MTL_ENABLE_QUEUE;\r\nwritel(reg_val, ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_disable_txqueue(void __iomem *ioaddr, int queue_num)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\nreg_val &= ~SXGBE_MTL_ENABLE_QUEUE;\r\nwritel(reg_val, ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_fc_active(void __iomem *ioaddr, int queue_num,\r\nint threshold)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val &= ~(SXGBE_MTL_FCMASK << RX_FC_ACTIVE);\r\nreg_val |= (threshold << RX_FC_ACTIVE);\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_fc_enable(void __iomem *ioaddr, int queue_num)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val |= SXGBE_MTL_ENABLE_FC;\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_fc_deactive(void __iomem *ioaddr, int queue_num,\r\nint threshold)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val &= ~(SXGBE_MTL_FCMASK << RX_FC_DEACTIVE);\r\nreg_val |= (threshold << RX_FC_DEACTIVE);\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_fep_enable(void __iomem *ioaddr, int queue_num)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val |= SXGBE_MTL_RXQ_OP_FEP;\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_fep_disable(void __iomem *ioaddr, int queue_num)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val &= ~(SXGBE_MTL_RXQ_OP_FEP);\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_fup_enable(void __iomem *ioaddr, int queue_num)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val |= SXGBE_MTL_RXQ_OP_FUP;\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_mtl_fup_disable(void __iomem *ioaddr, int queue_num)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nreg_val &= ~(SXGBE_MTL_RXQ_OP_FUP);\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_set_tx_mtl_mode(void __iomem *ioaddr, int queue_num,\r\nint tx_mode)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\nif (tx_mode == SXGBE_MTL_SFMODE) {\r\nreg_val |= SXGBE_MTL_SFMODE;\r\n} else {\r\nif (tx_mode <= 64)\r\nreg_val |= MTL_CONTROL_TTC_64;\r\nelse if (tx_mode <= 96)\r\nreg_val |= MTL_CONTROL_TTC_96;\r\nelse if (tx_mode <= 128)\r\nreg_val |= MTL_CONTROL_TTC_128;\r\nelse if (tx_mode <= 192)\r\nreg_val |= MTL_CONTROL_TTC_192;\r\nelse if (tx_mode <= 256)\r\nreg_val |= MTL_CONTROL_TTC_256;\r\nelse if (tx_mode <= 384)\r\nreg_val |= MTL_CONTROL_TTC_384;\r\nelse\r\nreg_val |= MTL_CONTROL_TTC_512;\r\n}\r\nwritel(reg_val, ioaddr + SXGBE_MTL_TXQ_OPMODE_REG(queue_num));\r\n}\r\nstatic void sxgbe_set_rx_mtl_mode(void __iomem *ioaddr, int queue_num,\r\nint rx_mode)\r\n{\r\nu32 reg_val;\r\nreg_val = readl(ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\nif (rx_mode == SXGBE_RX_MTL_SFMODE) {\r\nreg_val |= SXGBE_RX_MTL_SFMODE;\r\n} else {\r\nif (rx_mode <= 64)\r\nreg_val |= MTL_CONTROL_RTC_64;\r\nelse if (rx_mode <= 96)\r\nreg_val |= MTL_CONTROL_RTC_96;\r\nelse if (rx_mode <= 128)\r\nreg_val |= MTL_CONTROL_RTC_128;\r\n}\r\nwritel(reg_val, ioaddr + SXGBE_MTL_RXQ_OPMODE_REG(queue_num));\r\n}\r\nconst struct sxgbe_mtl_ops *sxgbe_get_mtl_ops(void)\r\n{\r\nreturn &mtl_ops;\r\n}
