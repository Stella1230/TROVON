struct xfs_inode *\r\nxfs_inode_alloc(\r\nstruct xfs_mount *mp,\r\nxfs_ino_t ino)\r\n{\r\nstruct xfs_inode *ip;\r\nip = kmem_zone_alloc(xfs_inode_zone, KM_SLEEP);\r\nif (!ip)\r\nreturn NULL;\r\nif (inode_init_always(mp->m_super, VFS_I(ip))) {\r\nkmem_zone_free(xfs_inode_zone, ip);\r\nreturn NULL;\r\n}\r\nXFS_STATS_INC(vn_active);\r\nASSERT(atomic_read(&ip->i_pincount) == 0);\r\nASSERT(!spin_is_locked(&ip->i_flags_lock));\r\nASSERT(!xfs_isiflocked(ip));\r\nASSERT(ip->i_ino == 0);\r\nmrlock_init(&ip->i_iolock, MRLOCK_BARRIER, "xfsio", ip->i_ino);\r\nip->i_ino = ino;\r\nip->i_mount = mp;\r\nmemset(&ip->i_imap, 0, sizeof(struct xfs_imap));\r\nip->i_afp = NULL;\r\nmemset(&ip->i_df, 0, sizeof(xfs_ifork_t));\r\nip->i_flags = 0;\r\nip->i_delayed_blks = 0;\r\nmemset(&ip->i_d, 0, sizeof(xfs_icdinode_t));\r\nreturn ip;\r\n}\r\nSTATIC void\r\nxfs_inode_free_callback(\r\nstruct rcu_head *head)\r\n{\r\nstruct inode *inode = container_of(head, struct inode, i_rcu);\r\nstruct xfs_inode *ip = XFS_I(inode);\r\nkmem_zone_free(xfs_inode_zone, ip);\r\n}\r\nvoid\r\nxfs_inode_free(\r\nstruct xfs_inode *ip)\r\n{\r\nswitch (ip->i_d.di_mode & S_IFMT) {\r\ncase S_IFREG:\r\ncase S_IFDIR:\r\ncase S_IFLNK:\r\nxfs_idestroy_fork(ip, XFS_DATA_FORK);\r\nbreak;\r\n}\r\nif (ip->i_afp)\r\nxfs_idestroy_fork(ip, XFS_ATTR_FORK);\r\nif (ip->i_itemp) {\r\nASSERT(!(ip->i_itemp->ili_item.li_flags & XFS_LI_IN_AIL));\r\nxfs_inode_item_destroy(ip);\r\nip->i_itemp = NULL;\r\n}\r\nspin_lock(&ip->i_flags_lock);\r\nip->i_flags = XFS_IRECLAIM;\r\nip->i_ino = 0;\r\nspin_unlock(&ip->i_flags_lock);\r\nASSERT(atomic_read(&ip->i_pincount) == 0);\r\nASSERT(!xfs_isiflocked(ip));\r\nXFS_STATS_DEC(vn_active);\r\ncall_rcu(&VFS_I(ip)->i_rcu, xfs_inode_free_callback);\r\n}\r\nstatic int\r\nxfs_iget_cache_hit(\r\nstruct xfs_perag *pag,\r\nstruct xfs_inode *ip,\r\nxfs_ino_t ino,\r\nint flags,\r\nint lock_flags) __releases(RCU)\r\n{\r\nstruct inode *inode = VFS_I(ip);\r\nstruct xfs_mount *mp = ip->i_mount;\r\nint error;\r\nspin_lock(&ip->i_flags_lock);\r\nif (ip->i_ino != ino) {\r\ntrace_xfs_iget_skip(ip);\r\nXFS_STATS_INC(xs_ig_frecycle);\r\nerror = -EAGAIN;\r\ngoto out_error;\r\n}\r\nif (ip->i_flags & (XFS_INEW|XFS_IRECLAIM)) {\r\ntrace_xfs_iget_skip(ip);\r\nXFS_STATS_INC(xs_ig_frecycle);\r\nerror = -EAGAIN;\r\ngoto out_error;\r\n}\r\nif (ip->i_d.di_mode == 0 && !(flags & XFS_IGET_CREATE)) {\r\nerror = -ENOENT;\r\ngoto out_error;\r\n}\r\nif (ip->i_flags & XFS_IRECLAIMABLE) {\r\ntrace_xfs_iget_reclaim(ip);\r\nip->i_flags |= XFS_IRECLAIM;\r\nspin_unlock(&ip->i_flags_lock);\r\nrcu_read_unlock();\r\nerror = inode_init_always(mp->m_super, inode);\r\nif (error) {\r\nrcu_read_lock();\r\nspin_lock(&ip->i_flags_lock);\r\nip->i_flags &= ~(XFS_INEW | XFS_IRECLAIM);\r\nASSERT(ip->i_flags & XFS_IRECLAIMABLE);\r\ntrace_xfs_iget_reclaim_fail(ip);\r\ngoto out_error;\r\n}\r\nspin_lock(&pag->pag_ici_lock);\r\nspin_lock(&ip->i_flags_lock);\r\nip->i_flags &= ~XFS_IRECLAIM_RESET_FLAGS;\r\nip->i_flags |= XFS_INEW;\r\n__xfs_inode_clear_reclaim_tag(mp, pag, ip);\r\ninode->i_state = I_NEW;\r\nASSERT(!rwsem_is_locked(&ip->i_iolock.mr_lock));\r\nmrlock_init(&ip->i_iolock, MRLOCK_BARRIER, "xfsio", ip->i_ino);\r\nspin_unlock(&ip->i_flags_lock);\r\nspin_unlock(&pag->pag_ici_lock);\r\n} else {\r\nif (!igrab(inode)) {\r\ntrace_xfs_iget_skip(ip);\r\nerror = -EAGAIN;\r\ngoto out_error;\r\n}\r\nspin_unlock(&ip->i_flags_lock);\r\nrcu_read_unlock();\r\ntrace_xfs_iget_hit(ip);\r\n}\r\nif (lock_flags != 0)\r\nxfs_ilock(ip, lock_flags);\r\nxfs_iflags_clear(ip, XFS_ISTALE | XFS_IDONTCACHE);\r\nXFS_STATS_INC(xs_ig_found);\r\nreturn 0;\r\nout_error:\r\nspin_unlock(&ip->i_flags_lock);\r\nrcu_read_unlock();\r\nreturn error;\r\n}\r\nstatic int\r\nxfs_iget_cache_miss(\r\nstruct xfs_mount *mp,\r\nstruct xfs_perag *pag,\r\nxfs_trans_t *tp,\r\nxfs_ino_t ino,\r\nstruct xfs_inode **ipp,\r\nint flags,\r\nint lock_flags)\r\n{\r\nstruct xfs_inode *ip;\r\nint error;\r\nxfs_agino_t agino = XFS_INO_TO_AGINO(mp, ino);\r\nint iflags;\r\nip = xfs_inode_alloc(mp, ino);\r\nif (!ip)\r\nreturn -ENOMEM;\r\nerror = xfs_iread(mp, tp, ip, flags);\r\nif (error)\r\ngoto out_destroy;\r\ntrace_xfs_iget_miss(ip);\r\nif ((ip->i_d.di_mode == 0) && !(flags & XFS_IGET_CREATE)) {\r\nerror = -ENOENT;\r\ngoto out_destroy;\r\n}\r\nif (radix_tree_preload(GFP_NOFS)) {\r\nerror = -EAGAIN;\r\ngoto out_destroy;\r\n}\r\nif (lock_flags) {\r\nif (!xfs_ilock_nowait(ip, lock_flags))\r\nBUG();\r\n}\r\niflags = XFS_INEW;\r\nif (flags & XFS_IGET_DONTCACHE)\r\niflags |= XFS_IDONTCACHE;\r\nip->i_udquot = NULL;\r\nip->i_gdquot = NULL;\r\nip->i_pdquot = NULL;\r\nxfs_iflags_set(ip, iflags);\r\nspin_lock(&pag->pag_ici_lock);\r\nerror = radix_tree_insert(&pag->pag_ici_root, agino, ip);\r\nif (unlikely(error)) {\r\nWARN_ON(error != -EEXIST);\r\nXFS_STATS_INC(xs_ig_dup);\r\nerror = -EAGAIN;\r\ngoto out_preload_end;\r\n}\r\nspin_unlock(&pag->pag_ici_lock);\r\nradix_tree_preload_end();\r\n*ipp = ip;\r\nreturn 0;\r\nout_preload_end:\r\nspin_unlock(&pag->pag_ici_lock);\r\nradix_tree_preload_end();\r\nif (lock_flags)\r\nxfs_iunlock(ip, lock_flags);\r\nout_destroy:\r\n__destroy_inode(VFS_I(ip));\r\nxfs_inode_free(ip);\r\nreturn error;\r\n}\r\nint\r\nxfs_iget(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_ino_t ino,\r\nuint flags,\r\nuint lock_flags,\r\nxfs_inode_t **ipp)\r\n{\r\nxfs_inode_t *ip;\r\nint error;\r\nxfs_perag_t *pag;\r\nxfs_agino_t agino;\r\nASSERT((lock_flags & (XFS_IOLOCK_EXCL | XFS_IOLOCK_SHARED)) == 0);\r\nif (!ino || XFS_INO_TO_AGNO(mp, ino) >= mp->m_sb.sb_agcount)\r\nreturn -EINVAL;\r\npag = xfs_perag_get(mp, XFS_INO_TO_AGNO(mp, ino));\r\nagino = XFS_INO_TO_AGINO(mp, ino);\r\nagain:\r\nerror = 0;\r\nrcu_read_lock();\r\nip = radix_tree_lookup(&pag->pag_ici_root, agino);\r\nif (ip) {\r\nerror = xfs_iget_cache_hit(pag, ip, ino, flags, lock_flags);\r\nif (error)\r\ngoto out_error_or_again;\r\n} else {\r\nrcu_read_unlock();\r\nXFS_STATS_INC(xs_ig_missed);\r\nerror = xfs_iget_cache_miss(mp, pag, tp, ino, &ip,\r\nflags, lock_flags);\r\nif (error)\r\ngoto out_error_or_again;\r\n}\r\nxfs_perag_put(pag);\r\n*ipp = ip;\r\nif (xfs_iflags_test(ip, XFS_INEW) && ip->i_d.di_mode != 0)\r\nxfs_setup_existing_inode(ip);\r\nreturn 0;\r\nout_error_or_again:\r\nif (error == -EAGAIN) {\r\ndelay(1);\r\ngoto again;\r\n}\r\nxfs_perag_put(pag);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_inode_ag_walk_grab(\r\nstruct xfs_inode *ip)\r\n{\r\nstruct inode *inode = VFS_I(ip);\r\nASSERT(rcu_read_lock_held());\r\nspin_lock(&ip->i_flags_lock);\r\nif (!ip->i_ino)\r\ngoto out_unlock_noent;\r\nif (__xfs_iflags_test(ip, XFS_INEW | XFS_IRECLAIMABLE | XFS_IRECLAIM))\r\ngoto out_unlock_noent;\r\nspin_unlock(&ip->i_flags_lock);\r\nif (XFS_FORCED_SHUTDOWN(ip->i_mount))\r\nreturn -EFSCORRUPTED;\r\nif (!igrab(inode))\r\nreturn -ENOENT;\r\nreturn 0;\r\nout_unlock_noent:\r\nspin_unlock(&ip->i_flags_lock);\r\nreturn -ENOENT;\r\n}\r\nSTATIC int\r\nxfs_inode_ag_walk(\r\nstruct xfs_mount *mp,\r\nstruct xfs_perag *pag,\r\nint (*execute)(struct xfs_inode *ip, int flags,\r\nvoid *args),\r\nint flags,\r\nvoid *args,\r\nint tag)\r\n{\r\nuint32_t first_index;\r\nint last_error = 0;\r\nint skipped;\r\nint done;\r\nint nr_found;\r\nrestart:\r\ndone = 0;\r\nskipped = 0;\r\nfirst_index = 0;\r\nnr_found = 0;\r\ndo {\r\nstruct xfs_inode *batch[XFS_LOOKUP_BATCH];\r\nint error = 0;\r\nint i;\r\nrcu_read_lock();\r\nif (tag == -1)\r\nnr_found = radix_tree_gang_lookup(&pag->pag_ici_root,\r\n(void **)batch, first_index,\r\nXFS_LOOKUP_BATCH);\r\nelse\r\nnr_found = radix_tree_gang_lookup_tag(\r\n&pag->pag_ici_root,\r\n(void **) batch, first_index,\r\nXFS_LOOKUP_BATCH, tag);\r\nif (!nr_found) {\r\nrcu_read_unlock();\r\nbreak;\r\n}\r\nfor (i = 0; i < nr_found; i++) {\r\nstruct xfs_inode *ip = batch[i];\r\nif (done || xfs_inode_ag_walk_grab(ip))\r\nbatch[i] = NULL;\r\nif (XFS_INO_TO_AGNO(mp, ip->i_ino) != pag->pag_agno)\r\ncontinue;\r\nfirst_index = XFS_INO_TO_AGINO(mp, ip->i_ino + 1);\r\nif (first_index < XFS_INO_TO_AGINO(mp, ip->i_ino))\r\ndone = 1;\r\n}\r\nrcu_read_unlock();\r\nfor (i = 0; i < nr_found; i++) {\r\nif (!batch[i])\r\ncontinue;\r\nerror = execute(batch[i], flags, args);\r\nIRELE(batch[i]);\r\nif (error == -EAGAIN) {\r\nskipped++;\r\ncontinue;\r\n}\r\nif (error && last_error != -EFSCORRUPTED)\r\nlast_error = error;\r\n}\r\nif (error == -EFSCORRUPTED)\r\nbreak;\r\ncond_resched();\r\n} while (nr_found && !done);\r\nif (skipped) {\r\ndelay(1);\r\ngoto restart;\r\n}\r\nreturn last_error;\r\n}\r\nSTATIC void\r\nxfs_queue_eofblocks(\r\nstruct xfs_mount *mp)\r\n{\r\nrcu_read_lock();\r\nif (radix_tree_tagged(&mp->m_perag_tree, XFS_ICI_EOFBLOCKS_TAG))\r\nqueue_delayed_work(mp->m_eofblocks_workqueue,\r\n&mp->m_eofblocks_work,\r\nmsecs_to_jiffies(xfs_eofb_secs * 1000));\r\nrcu_read_unlock();\r\n}\r\nvoid\r\nxfs_eofblocks_worker(\r\nstruct work_struct *work)\r\n{\r\nstruct xfs_mount *mp = container_of(to_delayed_work(work),\r\nstruct xfs_mount, m_eofblocks_work);\r\nxfs_icache_free_eofblocks(mp, NULL);\r\nxfs_queue_eofblocks(mp);\r\n}\r\nint\r\nxfs_inode_ag_iterator(\r\nstruct xfs_mount *mp,\r\nint (*execute)(struct xfs_inode *ip, int flags,\r\nvoid *args),\r\nint flags,\r\nvoid *args)\r\n{\r\nstruct xfs_perag *pag;\r\nint error = 0;\r\nint last_error = 0;\r\nxfs_agnumber_t ag;\r\nag = 0;\r\nwhile ((pag = xfs_perag_get(mp, ag))) {\r\nag = pag->pag_agno + 1;\r\nerror = xfs_inode_ag_walk(mp, pag, execute, flags, args, -1);\r\nxfs_perag_put(pag);\r\nif (error) {\r\nlast_error = error;\r\nif (error == -EFSCORRUPTED)\r\nbreak;\r\n}\r\n}\r\nreturn last_error;\r\n}\r\nint\r\nxfs_inode_ag_iterator_tag(\r\nstruct xfs_mount *mp,\r\nint (*execute)(struct xfs_inode *ip, int flags,\r\nvoid *args),\r\nint flags,\r\nvoid *args,\r\nint tag)\r\n{\r\nstruct xfs_perag *pag;\r\nint error = 0;\r\nint last_error = 0;\r\nxfs_agnumber_t ag;\r\nag = 0;\r\nwhile ((pag = xfs_perag_get_tag(mp, ag, tag))) {\r\nag = pag->pag_agno + 1;\r\nerror = xfs_inode_ag_walk(mp, pag, execute, flags, args, tag);\r\nxfs_perag_put(pag);\r\nif (error) {\r\nlast_error = error;\r\nif (error == -EFSCORRUPTED)\r\nbreak;\r\n}\r\n}\r\nreturn last_error;\r\n}\r\nstatic void\r\nxfs_reclaim_work_queue(\r\nstruct xfs_mount *mp)\r\n{\r\nrcu_read_lock();\r\nif (radix_tree_tagged(&mp->m_perag_tree, XFS_ICI_RECLAIM_TAG)) {\r\nqueue_delayed_work(mp->m_reclaim_workqueue, &mp->m_reclaim_work,\r\nmsecs_to_jiffies(xfs_syncd_centisecs / 6 * 10));\r\n}\r\nrcu_read_unlock();\r\n}\r\nvoid\r\nxfs_reclaim_worker(\r\nstruct work_struct *work)\r\n{\r\nstruct xfs_mount *mp = container_of(to_delayed_work(work),\r\nstruct xfs_mount, m_reclaim_work);\r\nxfs_reclaim_inodes(mp, SYNC_TRYLOCK);\r\nxfs_reclaim_work_queue(mp);\r\n}\r\nstatic void\r\n__xfs_inode_set_reclaim_tag(\r\nstruct xfs_perag *pag,\r\nstruct xfs_inode *ip)\r\n{\r\nradix_tree_tag_set(&pag->pag_ici_root,\r\nXFS_INO_TO_AGINO(ip->i_mount, ip->i_ino),\r\nXFS_ICI_RECLAIM_TAG);\r\nif (!pag->pag_ici_reclaimable) {\r\nspin_lock(&ip->i_mount->m_perag_lock);\r\nradix_tree_tag_set(&ip->i_mount->m_perag_tree,\r\nXFS_INO_TO_AGNO(ip->i_mount, ip->i_ino),\r\nXFS_ICI_RECLAIM_TAG);\r\nspin_unlock(&ip->i_mount->m_perag_lock);\r\nxfs_reclaim_work_queue(ip->i_mount);\r\ntrace_xfs_perag_set_reclaim(ip->i_mount, pag->pag_agno,\r\n-1, _RET_IP_);\r\n}\r\npag->pag_ici_reclaimable++;\r\n}\r\nvoid\r\nxfs_inode_set_reclaim_tag(\r\nxfs_inode_t *ip)\r\n{\r\nstruct xfs_mount *mp = ip->i_mount;\r\nstruct xfs_perag *pag;\r\npag = xfs_perag_get(mp, XFS_INO_TO_AGNO(mp, ip->i_ino));\r\nspin_lock(&pag->pag_ici_lock);\r\nspin_lock(&ip->i_flags_lock);\r\n__xfs_inode_set_reclaim_tag(pag, ip);\r\n__xfs_iflags_set(ip, XFS_IRECLAIMABLE);\r\nspin_unlock(&ip->i_flags_lock);\r\nspin_unlock(&pag->pag_ici_lock);\r\nxfs_perag_put(pag);\r\n}\r\nSTATIC void\r\n__xfs_inode_clear_reclaim(\r\nxfs_perag_t *pag,\r\nxfs_inode_t *ip)\r\n{\r\npag->pag_ici_reclaimable--;\r\nif (!pag->pag_ici_reclaimable) {\r\nspin_lock(&ip->i_mount->m_perag_lock);\r\nradix_tree_tag_clear(&ip->i_mount->m_perag_tree,\r\nXFS_INO_TO_AGNO(ip->i_mount, ip->i_ino),\r\nXFS_ICI_RECLAIM_TAG);\r\nspin_unlock(&ip->i_mount->m_perag_lock);\r\ntrace_xfs_perag_clear_reclaim(ip->i_mount, pag->pag_agno,\r\n-1, _RET_IP_);\r\n}\r\n}\r\nSTATIC void\r\n__xfs_inode_clear_reclaim_tag(\r\nxfs_mount_t *mp,\r\nxfs_perag_t *pag,\r\nxfs_inode_t *ip)\r\n{\r\nradix_tree_tag_clear(&pag->pag_ici_root,\r\nXFS_INO_TO_AGINO(mp, ip->i_ino), XFS_ICI_RECLAIM_TAG);\r\n__xfs_inode_clear_reclaim(pag, ip);\r\n}\r\nSTATIC int\r\nxfs_reclaim_inode_grab(\r\nstruct xfs_inode *ip,\r\nint flags)\r\n{\r\nASSERT(rcu_read_lock_held());\r\nif (!ip->i_ino)\r\nreturn 1;\r\nif ((flags & SYNC_TRYLOCK) &&\r\n__xfs_iflags_test(ip, XFS_IFLOCK | XFS_IRECLAIM))\r\nreturn 1;\r\nspin_lock(&ip->i_flags_lock);\r\nif (!__xfs_iflags_test(ip, XFS_IRECLAIMABLE) ||\r\n__xfs_iflags_test(ip, XFS_IRECLAIM)) {\r\nspin_unlock(&ip->i_flags_lock);\r\nreturn 1;\r\n}\r\n__xfs_iflags_set(ip, XFS_IRECLAIM);\r\nspin_unlock(&ip->i_flags_lock);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_reclaim_inode(\r\nstruct xfs_inode *ip,\r\nstruct xfs_perag *pag,\r\nint sync_mode)\r\n{\r\nstruct xfs_buf *bp = NULL;\r\nint error;\r\nrestart:\r\nerror = 0;\r\nxfs_ilock(ip, XFS_ILOCK_EXCL);\r\nif (!xfs_iflock_nowait(ip)) {\r\nif (!(sync_mode & SYNC_WAIT))\r\ngoto out;\r\nxfs_iflock(ip);\r\n}\r\nif (XFS_FORCED_SHUTDOWN(ip->i_mount)) {\r\nxfs_iunpin_wait(ip);\r\nxfs_iflush_abort(ip, false);\r\ngoto reclaim;\r\n}\r\nif (xfs_ipincount(ip)) {\r\nif (!(sync_mode & SYNC_WAIT))\r\ngoto out_ifunlock;\r\nxfs_iunpin_wait(ip);\r\n}\r\nif (xfs_iflags_test(ip, XFS_ISTALE))\r\ngoto reclaim;\r\nif (xfs_inode_clean(ip))\r\ngoto reclaim;\r\nif (!(sync_mode & SYNC_WAIT))\r\ngoto out_ifunlock;\r\nerror = xfs_iflush(ip, &bp);\r\nif (error == -EAGAIN) {\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\ndelay(2);\r\ngoto restart;\r\n}\r\nif (!error) {\r\nerror = xfs_bwrite(bp);\r\nxfs_buf_relse(bp);\r\n}\r\nxfs_iflock(ip);\r\nreclaim:\r\nxfs_ifunlock(ip);\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\nXFS_STATS_INC(xs_ig_reclaims);\r\nspin_lock(&pag->pag_ici_lock);\r\nif (!radix_tree_delete(&pag->pag_ici_root,\r\nXFS_INO_TO_AGINO(ip->i_mount, ip->i_ino)))\r\nASSERT(0);\r\n__xfs_inode_clear_reclaim(pag, ip);\r\nspin_unlock(&pag->pag_ici_lock);\r\nxfs_ilock(ip, XFS_ILOCK_EXCL);\r\nxfs_qm_dqdetach(ip);\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\nxfs_inode_free(ip);\r\nreturn error;\r\nout_ifunlock:\r\nxfs_ifunlock(ip);\r\nout:\r\nxfs_iflags_clear(ip, XFS_IRECLAIM);\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_reclaim_inodes_ag(\r\nstruct xfs_mount *mp,\r\nint flags,\r\nint *nr_to_scan)\r\n{\r\nstruct xfs_perag *pag;\r\nint error = 0;\r\nint last_error = 0;\r\nxfs_agnumber_t ag;\r\nint trylock = flags & SYNC_TRYLOCK;\r\nint skipped;\r\nrestart:\r\nag = 0;\r\nskipped = 0;\r\nwhile ((pag = xfs_perag_get_tag(mp, ag, XFS_ICI_RECLAIM_TAG))) {\r\nunsigned long first_index = 0;\r\nint done = 0;\r\nint nr_found = 0;\r\nag = pag->pag_agno + 1;\r\nif (trylock) {\r\nif (!mutex_trylock(&pag->pag_ici_reclaim_lock)) {\r\nskipped++;\r\nxfs_perag_put(pag);\r\ncontinue;\r\n}\r\nfirst_index = pag->pag_ici_reclaim_cursor;\r\n} else\r\nmutex_lock(&pag->pag_ici_reclaim_lock);\r\ndo {\r\nstruct xfs_inode *batch[XFS_LOOKUP_BATCH];\r\nint i;\r\nrcu_read_lock();\r\nnr_found = radix_tree_gang_lookup_tag(\r\n&pag->pag_ici_root,\r\n(void **)batch, first_index,\r\nXFS_LOOKUP_BATCH,\r\nXFS_ICI_RECLAIM_TAG);\r\nif (!nr_found) {\r\ndone = 1;\r\nrcu_read_unlock();\r\nbreak;\r\n}\r\nfor (i = 0; i < nr_found; i++) {\r\nstruct xfs_inode *ip = batch[i];\r\nif (done || xfs_reclaim_inode_grab(ip, flags))\r\nbatch[i] = NULL;\r\nif (XFS_INO_TO_AGNO(mp, ip->i_ino) !=\r\npag->pag_agno)\r\ncontinue;\r\nfirst_index = XFS_INO_TO_AGINO(mp, ip->i_ino + 1);\r\nif (first_index < XFS_INO_TO_AGINO(mp, ip->i_ino))\r\ndone = 1;\r\n}\r\nrcu_read_unlock();\r\nfor (i = 0; i < nr_found; i++) {\r\nif (!batch[i])\r\ncontinue;\r\nerror = xfs_reclaim_inode(batch[i], pag, flags);\r\nif (error && last_error != -EFSCORRUPTED)\r\nlast_error = error;\r\n}\r\n*nr_to_scan -= XFS_LOOKUP_BATCH;\r\ncond_resched();\r\n} while (nr_found && !done && *nr_to_scan > 0);\r\nif (trylock && !done)\r\npag->pag_ici_reclaim_cursor = first_index;\r\nelse\r\npag->pag_ici_reclaim_cursor = 0;\r\nmutex_unlock(&pag->pag_ici_reclaim_lock);\r\nxfs_perag_put(pag);\r\n}\r\nif (skipped && (flags & SYNC_WAIT) && *nr_to_scan > 0) {\r\ntrylock = 0;\r\ngoto restart;\r\n}\r\nreturn last_error;\r\n}\r\nint\r\nxfs_reclaim_inodes(\r\nxfs_mount_t *mp,\r\nint mode)\r\n{\r\nint nr_to_scan = INT_MAX;\r\nreturn xfs_reclaim_inodes_ag(mp, mode, &nr_to_scan);\r\n}\r\nlong\r\nxfs_reclaim_inodes_nr(\r\nstruct xfs_mount *mp,\r\nint nr_to_scan)\r\n{\r\nxfs_reclaim_work_queue(mp);\r\nxfs_ail_push_all(mp->m_ail);\r\nreturn xfs_reclaim_inodes_ag(mp, SYNC_TRYLOCK | SYNC_WAIT, &nr_to_scan);\r\n}\r\nint\r\nxfs_reclaim_inodes_count(\r\nstruct xfs_mount *mp)\r\n{\r\nstruct xfs_perag *pag;\r\nxfs_agnumber_t ag = 0;\r\nint reclaimable = 0;\r\nwhile ((pag = xfs_perag_get_tag(mp, ag, XFS_ICI_RECLAIM_TAG))) {\r\nag = pag->pag_agno + 1;\r\nreclaimable += pag->pag_ici_reclaimable;\r\nxfs_perag_put(pag);\r\n}\r\nreturn reclaimable;\r\n}\r\nSTATIC int\r\nxfs_inode_match_id(\r\nstruct xfs_inode *ip,\r\nstruct xfs_eofblocks *eofb)\r\n{\r\nif ((eofb->eof_flags & XFS_EOF_FLAGS_UID) &&\r\n!uid_eq(VFS_I(ip)->i_uid, eofb->eof_uid))\r\nreturn 0;\r\nif ((eofb->eof_flags & XFS_EOF_FLAGS_GID) &&\r\n!gid_eq(VFS_I(ip)->i_gid, eofb->eof_gid))\r\nreturn 0;\r\nif ((eofb->eof_flags & XFS_EOF_FLAGS_PRID) &&\r\nxfs_get_projid(ip) != eofb->eof_prid)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nSTATIC int\r\nxfs_inode_match_id_union(\r\nstruct xfs_inode *ip,\r\nstruct xfs_eofblocks *eofb)\r\n{\r\nif ((eofb->eof_flags & XFS_EOF_FLAGS_UID) &&\r\nuid_eq(VFS_I(ip)->i_uid, eofb->eof_uid))\r\nreturn 1;\r\nif ((eofb->eof_flags & XFS_EOF_FLAGS_GID) &&\r\ngid_eq(VFS_I(ip)->i_gid, eofb->eof_gid))\r\nreturn 1;\r\nif ((eofb->eof_flags & XFS_EOF_FLAGS_PRID) &&\r\nxfs_get_projid(ip) == eofb->eof_prid)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_inode_free_eofblocks(\r\nstruct xfs_inode *ip,\r\nint flags,\r\nvoid *args)\r\n{\r\nint ret;\r\nstruct xfs_eofblocks *eofb = args;\r\nbool need_iolock = true;\r\nint match;\r\nASSERT(!eofb || (eofb && eofb->eof_scan_owner != 0));\r\nif (!xfs_can_free_eofblocks(ip, false)) {\r\ntrace_xfs_inode_free_eofblocks_invalid(ip);\r\nxfs_inode_clear_eofblocks_tag(ip);\r\nreturn 0;\r\n}\r\nif (!(flags & SYNC_WAIT) &&\r\nmapping_tagged(VFS_I(ip)->i_mapping, PAGECACHE_TAG_DIRTY))\r\nreturn 0;\r\nif (eofb) {\r\nif (eofb->eof_flags & XFS_EOF_FLAGS_UNION)\r\nmatch = xfs_inode_match_id_union(ip, eofb);\r\nelse\r\nmatch = xfs_inode_match_id(ip, eofb);\r\nif (!match)\r\nreturn 0;\r\nif (eofb->eof_flags & XFS_EOF_FLAGS_MINFILESIZE &&\r\nXFS_ISIZE(ip) < eofb->eof_min_file_size)\r\nreturn 0;\r\nif (eofb->eof_scan_owner == ip->i_ino)\r\nneed_iolock = false;\r\n}\r\nret = xfs_free_eofblocks(ip->i_mount, ip, need_iolock);\r\nif (ret == -EAGAIN && !(flags & SYNC_WAIT))\r\nret = 0;\r\nreturn ret;\r\n}\r\nint\r\nxfs_icache_free_eofblocks(\r\nstruct xfs_mount *mp,\r\nstruct xfs_eofblocks *eofb)\r\n{\r\nint flags = SYNC_TRYLOCK;\r\nif (eofb && (eofb->eof_flags & XFS_EOF_FLAGS_SYNC))\r\nflags = SYNC_WAIT;\r\nreturn xfs_inode_ag_iterator_tag(mp, xfs_inode_free_eofblocks, flags,\r\neofb, XFS_ICI_EOFBLOCKS_TAG);\r\n}\r\nint\r\nxfs_inode_free_quota_eofblocks(\r\nstruct xfs_inode *ip)\r\n{\r\nint scan = 0;\r\nstruct xfs_eofblocks eofb = {0};\r\nstruct xfs_dquot *dq;\r\nASSERT(xfs_isilocked(ip, XFS_IOLOCK_EXCL));\r\neofb.eof_scan_owner = ip->i_ino;\r\neofb.eof_flags = XFS_EOF_FLAGS_UNION|XFS_EOF_FLAGS_SYNC;\r\nif (XFS_IS_UQUOTA_ENFORCED(ip->i_mount)) {\r\ndq = xfs_inode_dquot(ip, XFS_DQ_USER);\r\nif (dq && xfs_dquot_lowsp(dq)) {\r\neofb.eof_uid = VFS_I(ip)->i_uid;\r\neofb.eof_flags |= XFS_EOF_FLAGS_UID;\r\nscan = 1;\r\n}\r\n}\r\nif (XFS_IS_GQUOTA_ENFORCED(ip->i_mount)) {\r\ndq = xfs_inode_dquot(ip, XFS_DQ_GROUP);\r\nif (dq && xfs_dquot_lowsp(dq)) {\r\neofb.eof_gid = VFS_I(ip)->i_gid;\r\neofb.eof_flags |= XFS_EOF_FLAGS_GID;\r\nscan = 1;\r\n}\r\n}\r\nif (scan)\r\nxfs_icache_free_eofblocks(ip->i_mount, &eofb);\r\nreturn scan;\r\n}\r\nvoid\r\nxfs_inode_set_eofblocks_tag(\r\nxfs_inode_t *ip)\r\n{\r\nstruct xfs_mount *mp = ip->i_mount;\r\nstruct xfs_perag *pag;\r\nint tagged;\r\npag = xfs_perag_get(mp, XFS_INO_TO_AGNO(mp, ip->i_ino));\r\nspin_lock(&pag->pag_ici_lock);\r\ntrace_xfs_inode_set_eofblocks_tag(ip);\r\ntagged = radix_tree_tagged(&pag->pag_ici_root,\r\nXFS_ICI_EOFBLOCKS_TAG);\r\nradix_tree_tag_set(&pag->pag_ici_root,\r\nXFS_INO_TO_AGINO(ip->i_mount, ip->i_ino),\r\nXFS_ICI_EOFBLOCKS_TAG);\r\nif (!tagged) {\r\nspin_lock(&ip->i_mount->m_perag_lock);\r\nradix_tree_tag_set(&ip->i_mount->m_perag_tree,\r\nXFS_INO_TO_AGNO(ip->i_mount, ip->i_ino),\r\nXFS_ICI_EOFBLOCKS_TAG);\r\nspin_unlock(&ip->i_mount->m_perag_lock);\r\nxfs_queue_eofblocks(ip->i_mount);\r\ntrace_xfs_perag_set_eofblocks(ip->i_mount, pag->pag_agno,\r\n-1, _RET_IP_);\r\n}\r\nspin_unlock(&pag->pag_ici_lock);\r\nxfs_perag_put(pag);\r\n}\r\nvoid\r\nxfs_inode_clear_eofblocks_tag(\r\nxfs_inode_t *ip)\r\n{\r\nstruct xfs_mount *mp = ip->i_mount;\r\nstruct xfs_perag *pag;\r\npag = xfs_perag_get(mp, XFS_INO_TO_AGNO(mp, ip->i_ino));\r\nspin_lock(&pag->pag_ici_lock);\r\ntrace_xfs_inode_clear_eofblocks_tag(ip);\r\nradix_tree_tag_clear(&pag->pag_ici_root,\r\nXFS_INO_TO_AGINO(ip->i_mount, ip->i_ino),\r\nXFS_ICI_EOFBLOCKS_TAG);\r\nif (!radix_tree_tagged(&pag->pag_ici_root, XFS_ICI_EOFBLOCKS_TAG)) {\r\nspin_lock(&ip->i_mount->m_perag_lock);\r\nradix_tree_tag_clear(&ip->i_mount->m_perag_tree,\r\nXFS_INO_TO_AGNO(ip->i_mount, ip->i_ino),\r\nXFS_ICI_EOFBLOCKS_TAG);\r\nspin_unlock(&ip->i_mount->m_perag_lock);\r\ntrace_xfs_perag_clear_eofblocks(ip->i_mount, pag->pag_agno,\r\n-1, _RET_IP_);\r\n}\r\nspin_unlock(&pag->pag_ici_lock);\r\nxfs_perag_put(pag);\r\n}
