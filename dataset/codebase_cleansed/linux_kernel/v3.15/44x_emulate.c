static int emulate_mtdcr(struct kvm_vcpu *vcpu, int rs, int dcrn)\r\n{\r\nswitch (dcrn) {\r\ncase DCRN_CPR0_CONFIG_ADDR:\r\nvcpu->arch.cpr0_cfgaddr = kvmppc_get_gpr(vcpu, rs);\r\nreturn EMULATE_DONE;\r\ndefault:\r\nvcpu->run->dcr.dcrn = dcrn;\r\nvcpu->run->dcr.data = kvmppc_get_gpr(vcpu, rs);\r\nvcpu->run->dcr.is_write = 1;\r\nvcpu->arch.dcr_is_write = 1;\r\nvcpu->arch.dcr_needed = 1;\r\nkvmppc_account_exit(vcpu, DCR_EXITS);\r\nreturn EMULATE_DO_DCR;\r\n}\r\n}\r\nstatic int emulate_mfdcr(struct kvm_vcpu *vcpu, int rt, int dcrn)\r\n{\r\nswitch (dcrn) {\r\ncase DCRN_CPR0_CONFIG_ADDR:\r\nkvmppc_set_gpr(vcpu, rt, vcpu->arch.cpr0_cfgaddr);\r\nbreak;\r\ncase DCRN_CPR0_CONFIG_DATA:\r\nlocal_irq_disable();\r\nmtdcr(DCRN_CPR0_CONFIG_ADDR,\r\nvcpu->arch.cpr0_cfgaddr);\r\nkvmppc_set_gpr(vcpu, rt,\r\nmfdcr(DCRN_CPR0_CONFIG_DATA));\r\nlocal_irq_enable();\r\nbreak;\r\ndefault:\r\nvcpu->run->dcr.dcrn = dcrn;\r\nvcpu->run->dcr.data = 0;\r\nvcpu->run->dcr.is_write = 0;\r\nvcpu->arch.dcr_is_write = 0;\r\nvcpu->arch.io_gpr = rt;\r\nvcpu->arch.dcr_needed = 1;\r\nkvmppc_account_exit(vcpu, DCR_EXITS);\r\nreturn EMULATE_DO_DCR;\r\n}\r\nreturn EMULATE_DONE;\r\n}\r\nint kvmppc_core_emulate_op_44x(struct kvm_run *run, struct kvm_vcpu *vcpu,\r\nunsigned int inst, int *advance)\r\n{\r\nint emulated = EMULATE_DONE;\r\nint dcrn = get_dcrn(inst);\r\nint ra = get_ra(inst);\r\nint rb = get_rb(inst);\r\nint rc = get_rc(inst);\r\nint rs = get_rs(inst);\r\nint rt = get_rt(inst);\r\nint ws = get_ws(inst);\r\nswitch (get_op(inst)) {\r\ncase 31:\r\nswitch (get_xop(inst)) {\r\ncase XOP_MFDCR:\r\nemulated = emulate_mfdcr(vcpu, rt, dcrn);\r\nbreak;\r\ncase XOP_MFDCRX:\r\nemulated = emulate_mfdcr(vcpu, rt,\r\nkvmppc_get_gpr(vcpu, ra));\r\nbreak;\r\ncase XOP_MTDCR:\r\nemulated = emulate_mtdcr(vcpu, rs, dcrn);\r\nbreak;\r\ncase XOP_MTDCRX:\r\nemulated = emulate_mtdcr(vcpu, rs,\r\nkvmppc_get_gpr(vcpu, ra));\r\nbreak;\r\ncase XOP_TLBWE:\r\nemulated = kvmppc_44x_emul_tlbwe(vcpu, ra, rs, ws);\r\nbreak;\r\ncase XOP_TLBSX:\r\nemulated = kvmppc_44x_emul_tlbsx(vcpu, rt, ra, rb, rc);\r\nbreak;\r\ncase XOP_ICCCI:\r\nbreak;\r\ndefault:\r\nemulated = EMULATE_FAIL;\r\n}\r\nbreak;\r\ndefault:\r\nemulated = EMULATE_FAIL;\r\n}\r\nif (emulated == EMULATE_FAIL)\r\nemulated = kvmppc_booke_emulate_op(run, vcpu, inst, advance);\r\nreturn emulated;\r\n}\r\nint kvmppc_core_emulate_mtspr_44x(struct kvm_vcpu *vcpu, int sprn, ulong spr_val)\r\n{\r\nint emulated = EMULATE_DONE;\r\nswitch (sprn) {\r\ncase SPRN_PID:\r\nkvmppc_set_pid(vcpu, spr_val); break;\r\ncase SPRN_MMUCR:\r\nvcpu->arch.mmucr = spr_val; break;\r\ncase SPRN_CCR0:\r\nvcpu->arch.ccr0 = spr_val; break;\r\ncase SPRN_CCR1:\r\nvcpu->arch.ccr1 = spr_val; break;\r\ndefault:\r\nemulated = kvmppc_booke_emulate_mtspr(vcpu, sprn, spr_val);\r\n}\r\nreturn emulated;\r\n}\r\nint kvmppc_core_emulate_mfspr_44x(struct kvm_vcpu *vcpu, int sprn, ulong *spr_val)\r\n{\r\nint emulated = EMULATE_DONE;\r\nswitch (sprn) {\r\ncase SPRN_PID:\r\n*spr_val = vcpu->arch.pid; break;\r\ncase SPRN_MMUCR:\r\n*spr_val = vcpu->arch.mmucr; break;\r\ncase SPRN_CCR0:\r\n*spr_val = vcpu->arch.ccr0; break;\r\ncase SPRN_CCR1:\r\n*spr_val = vcpu->arch.ccr1; break;\r\ndefault:\r\nemulated = kvmppc_booke_emulate_mfspr(vcpu, sprn, spr_val);\r\n}\r\nreturn emulated;\r\n}
