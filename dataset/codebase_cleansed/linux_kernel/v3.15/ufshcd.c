static int ufshcd_wait_for_register(struct ufs_hba *hba, u32 reg, u32 mask,\r\nu32 val, unsigned long interval_us, unsigned long timeout_ms)\r\n{\r\nint err = 0;\r\nunsigned long timeout = jiffies + msecs_to_jiffies(timeout_ms);\r\nval = val & mask;\r\nwhile ((ufshcd_readl(hba, reg) & mask) != val) {\r\nusleep_range(interval_us, interval_us + 50);\r\nif (time_after(jiffies, timeout)) {\r\nif ((ufshcd_readl(hba, reg) & mask) != val)\r\nerr = -ETIMEDOUT;\r\nbreak;\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic inline u32 ufshcd_get_intr_mask(struct ufs_hba *hba)\r\n{\r\nif (hba->ufs_version == UFSHCI_VERSION_10)\r\nreturn INTERRUPT_MASK_ALL_VER_10;\r\nelse\r\nreturn INTERRUPT_MASK_ALL_VER_11;\r\n}\r\nstatic inline u32 ufshcd_get_ufs_version(struct ufs_hba *hba)\r\n{\r\nreturn ufshcd_readl(hba, REG_UFS_VERSION);\r\n}\r\nstatic inline int ufshcd_is_device_present(u32 reg_hcs)\r\n{\r\nreturn (DEVICE_PRESENT & reg_hcs) ? 1 : 0;\r\n}\r\nstatic inline int ufshcd_get_tr_ocs(struct ufshcd_lrb *lrbp)\r\n{\r\nreturn lrbp->utr_descriptor_ptr->header.dword_2 & MASK_OCS;\r\n}\r\nstatic inline int\r\nufshcd_get_tmr_ocs(struct utp_task_req_desc *task_req_descp)\r\n{\r\nreturn task_req_descp->header.dword_2 & MASK_OCS;\r\n}\r\nstatic inline int ufshcd_get_tm_free_slot(struct ufs_hba *hba)\r\n{\r\nreturn find_first_zero_bit(&hba->outstanding_tasks, hba->nutmrs);\r\n}\r\nstatic inline void ufshcd_utrl_clear(struct ufs_hba *hba, u32 pos)\r\n{\r\nufshcd_writel(hba, ~(1 << pos), REG_UTP_TRANSFER_REQ_LIST_CLEAR);\r\n}\r\nstatic inline int ufshcd_get_lists_status(u32 reg)\r\n{\r\nreturn (((reg) & (0xFF)) >> 1) ^ (0x07);\r\n}\r\nstatic inline int ufshcd_get_uic_cmd_result(struct ufs_hba *hba)\r\n{\r\nreturn ufshcd_readl(hba, REG_UIC_COMMAND_ARG_2) &\r\nMASK_UIC_COMMAND_RESULT;\r\n}\r\nstatic inline u32 ufshcd_get_dme_attr_val(struct ufs_hba *hba)\r\n{\r\nreturn ufshcd_readl(hba, REG_UIC_COMMAND_ARG_3);\r\n}\r\nstatic inline int\r\nufshcd_get_req_rsp(struct utp_upiu_rsp *ucd_rsp_ptr)\r\n{\r\nreturn be32_to_cpu(ucd_rsp_ptr->header.dword_0) >> 24;\r\n}\r\nstatic inline int\r\nufshcd_get_rsp_upiu_result(struct utp_upiu_rsp *ucd_rsp_ptr)\r\n{\r\nreturn be32_to_cpu(ucd_rsp_ptr->header.dword_1) & MASK_RSP_UPIU_RESULT;\r\n}\r\nstatic inline unsigned int\r\nufshcd_get_rsp_upiu_data_seg_len(struct utp_upiu_rsp *ucd_rsp_ptr)\r\n{\r\nreturn be32_to_cpu(ucd_rsp_ptr->header.dword_2) &\r\nMASK_RSP_UPIU_DATA_SEG_LEN;\r\n}\r\nstatic inline bool ufshcd_is_exception_event(struct utp_upiu_rsp *ucd_rsp_ptr)\r\n{\r\nreturn be32_to_cpu(ucd_rsp_ptr->header.dword_2) &\r\nMASK_RSP_EXCEPTION_EVENT ? true : false;\r\n}\r\nstatic inline void\r\nufshcd_reset_intr_aggr(struct ufs_hba *hba)\r\n{\r\nufshcd_writel(hba, INT_AGGR_ENABLE |\r\nINT_AGGR_COUNTER_AND_TIMER_RESET,\r\nREG_UTP_TRANSFER_REQ_INT_AGG_CONTROL);\r\n}\r\nstatic inline void\r\nufshcd_config_intr_aggr(struct ufs_hba *hba, u8 cnt, u8 tmout)\r\n{\r\nufshcd_writel(hba, INT_AGGR_ENABLE | INT_AGGR_PARAM_WRITE |\r\nINT_AGGR_COUNTER_THLD_VAL(cnt) |\r\nINT_AGGR_TIMEOUT_VAL(tmout),\r\nREG_UTP_TRANSFER_REQ_INT_AGG_CONTROL);\r\n}\r\nstatic void ufshcd_enable_run_stop_reg(struct ufs_hba *hba)\r\n{\r\nufshcd_writel(hba, UTP_TASK_REQ_LIST_RUN_STOP_BIT,\r\nREG_UTP_TASK_REQ_LIST_RUN_STOP);\r\nufshcd_writel(hba, UTP_TRANSFER_REQ_LIST_RUN_STOP_BIT,\r\nREG_UTP_TRANSFER_REQ_LIST_RUN_STOP);\r\n}\r\nstatic inline void ufshcd_hba_start(struct ufs_hba *hba)\r\n{\r\nufshcd_writel(hba, CONTROLLER_ENABLE, REG_CONTROLLER_ENABLE);\r\n}\r\nstatic inline int ufshcd_is_hba_active(struct ufs_hba *hba)\r\n{\r\nreturn (ufshcd_readl(hba, REG_CONTROLLER_ENABLE) & 0x1) ? 0 : 1;\r\n}\r\nstatic inline\r\nvoid ufshcd_send_command(struct ufs_hba *hba, unsigned int task_tag)\r\n{\r\n__set_bit(task_tag, &hba->outstanding_reqs);\r\nufshcd_writel(hba, 1 << task_tag, REG_UTP_TRANSFER_REQ_DOOR_BELL);\r\n}\r\nstatic inline void ufshcd_copy_sense_data(struct ufshcd_lrb *lrbp)\r\n{\r\nint len;\r\nif (lrbp->sense_buffer &&\r\nufshcd_get_rsp_upiu_data_seg_len(lrbp->ucd_rsp_ptr)) {\r\nlen = be16_to_cpu(lrbp->ucd_rsp_ptr->sr.sense_data_len);\r\nmemcpy(lrbp->sense_buffer,\r\nlrbp->ucd_rsp_ptr->sr.sense_data,\r\nmin_t(int, len, SCSI_SENSE_BUFFERSIZE));\r\n}\r\n}\r\nstatic inline void ufshcd_query_to_cpu(struct utp_upiu_query *response)\r\n{\r\nresponse->length = be16_to_cpu(response->length);\r\nresponse->value = be32_to_cpu(response->value);\r\n}\r\nstatic inline void ufshcd_query_to_be(struct utp_upiu_query *request)\r\n{\r\nrequest->length = cpu_to_be16(request->length);\r\nrequest->value = cpu_to_be32(request->value);\r\n}\r\nstatic\r\nvoid ufshcd_copy_query_response(struct ufs_hba *hba, struct ufshcd_lrb *lrbp)\r\n{\r\nstruct ufs_query_res *query_res = &hba->dev_cmd.query.response;\r\nquery_res->response = ufshcd_get_rsp_upiu_result(lrbp->ucd_rsp_ptr) >>\r\nUPIU_RSP_CODE_OFFSET;\r\nmemcpy(&query_res->upiu_res, &lrbp->ucd_rsp_ptr->qr, QUERY_OSF_SIZE);\r\nufshcd_query_to_cpu(&query_res->upiu_res);\r\nif (lrbp->ucd_rsp_ptr->qr.opcode == UPIU_QUERY_OPCODE_READ_DESC) {\r\nu8 *descp = (u8 *)&lrbp->ucd_rsp_ptr +\r\nGENERAL_UPIU_REQUEST_SIZE;\r\nu16 len;\r\nlen = be32_to_cpu(lrbp->ucd_rsp_ptr->header.dword_2) &\r\nMASK_QUERY_DATA_SEG_LEN;\r\nmemcpy(hba->dev_cmd.query.descriptor, descp,\r\nmin_t(u16, len, QUERY_DESC_MAX_SIZE));\r\n}\r\n}\r\nstatic inline void ufshcd_hba_capabilities(struct ufs_hba *hba)\r\n{\r\nhba->capabilities = ufshcd_readl(hba, REG_CONTROLLER_CAPABILITIES);\r\nhba->nutrs = (hba->capabilities & MASK_TRANSFER_REQUESTS_SLOTS) + 1;\r\nhba->nutmrs =\r\n((hba->capabilities & MASK_TASK_MANAGEMENT_REQUEST_SLOTS) >> 16) + 1;\r\n}\r\nstatic inline bool ufshcd_ready_for_uic_cmd(struct ufs_hba *hba)\r\n{\r\nif (ufshcd_readl(hba, REG_CONTROLLER_STATUS) & UIC_COMMAND_READY)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nstatic inline u8 ufshcd_get_upmcrs(struct ufs_hba *hba)\r\n{\r\nreturn (ufshcd_readl(hba, REG_CONTROLLER_STATUS) >> 8) & 0x7;\r\n}\r\nstatic inline void\r\nufshcd_dispatch_uic_cmd(struct ufs_hba *hba, struct uic_command *uic_cmd)\r\n{\r\nWARN_ON(hba->active_uic_cmd);\r\nhba->active_uic_cmd = uic_cmd;\r\nufshcd_writel(hba, uic_cmd->argument1, REG_UIC_COMMAND_ARG_1);\r\nufshcd_writel(hba, uic_cmd->argument2, REG_UIC_COMMAND_ARG_2);\r\nufshcd_writel(hba, uic_cmd->argument3, REG_UIC_COMMAND_ARG_3);\r\nufshcd_writel(hba, uic_cmd->command & COMMAND_OPCODE_MASK,\r\nREG_UIC_COMMAND);\r\n}\r\nstatic int\r\nufshcd_wait_for_uic_cmd(struct ufs_hba *hba, struct uic_command *uic_cmd)\r\n{\r\nint ret;\r\nunsigned long flags;\r\nif (wait_for_completion_timeout(&uic_cmd->done,\r\nmsecs_to_jiffies(UIC_CMD_TIMEOUT)))\r\nret = uic_cmd->argument2 & MASK_UIC_COMMAND_RESULT;\r\nelse\r\nret = -ETIMEDOUT;\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nhba->active_uic_cmd = NULL;\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nreturn ret;\r\n}\r\nstatic int\r\n__ufshcd_send_uic_cmd(struct ufs_hba *hba, struct uic_command *uic_cmd)\r\n{\r\nint ret;\r\nunsigned long flags;\r\nif (!ufshcd_ready_for_uic_cmd(hba)) {\r\ndev_err(hba->dev,\r\n"Controller not ready to accept UIC commands\n");\r\nreturn -EIO;\r\n}\r\ninit_completion(&uic_cmd->done);\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nufshcd_dispatch_uic_cmd(hba, uic_cmd);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nret = ufshcd_wait_for_uic_cmd(hba, uic_cmd);\r\nreturn ret;\r\n}\r\nstatic int\r\nufshcd_send_uic_cmd(struct ufs_hba *hba, struct uic_command *uic_cmd)\r\n{\r\nint ret;\r\nmutex_lock(&hba->uic_cmd_mutex);\r\nret = __ufshcd_send_uic_cmd(hba, uic_cmd);\r\nmutex_unlock(&hba->uic_cmd_mutex);\r\nreturn ret;\r\n}\r\nstatic int ufshcd_map_sg(struct ufshcd_lrb *lrbp)\r\n{\r\nstruct ufshcd_sg_entry *prd_table;\r\nstruct scatterlist *sg;\r\nstruct scsi_cmnd *cmd;\r\nint sg_segments;\r\nint i;\r\ncmd = lrbp->cmd;\r\nsg_segments = scsi_dma_map(cmd);\r\nif (sg_segments < 0)\r\nreturn sg_segments;\r\nif (sg_segments) {\r\nlrbp->utr_descriptor_ptr->prd_table_length =\r\ncpu_to_le16((u16) (sg_segments));\r\nprd_table = (struct ufshcd_sg_entry *)lrbp->ucd_prdt_ptr;\r\nscsi_for_each_sg(cmd, sg, sg_segments, i) {\r\nprd_table[i].size =\r\ncpu_to_le32(((u32) sg_dma_len(sg))-1);\r\nprd_table[i].base_addr =\r\ncpu_to_le32(lower_32_bits(sg->dma_address));\r\nprd_table[i].upper_addr =\r\ncpu_to_le32(upper_32_bits(sg->dma_address));\r\n}\r\n} else {\r\nlrbp->utr_descriptor_ptr->prd_table_length = 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic void ufshcd_enable_intr(struct ufs_hba *hba, u32 intrs)\r\n{\r\nu32 set = ufshcd_readl(hba, REG_INTERRUPT_ENABLE);\r\nif (hba->ufs_version == UFSHCI_VERSION_10) {\r\nu32 rw;\r\nrw = set & INTERRUPT_MASK_RW_VER_10;\r\nset = rw | ((set ^ intrs) & intrs);\r\n} else {\r\nset |= intrs;\r\n}\r\nufshcd_writel(hba, set, REG_INTERRUPT_ENABLE);\r\n}\r\nstatic void ufshcd_disable_intr(struct ufs_hba *hba, u32 intrs)\r\n{\r\nu32 set = ufshcd_readl(hba, REG_INTERRUPT_ENABLE);\r\nif (hba->ufs_version == UFSHCI_VERSION_10) {\r\nu32 rw;\r\nrw = (set & INTERRUPT_MASK_RW_VER_10) &\r\n~(intrs & INTERRUPT_MASK_RW_VER_10);\r\nset = rw | ((set & intrs) & ~INTERRUPT_MASK_RW_VER_10);\r\n} else {\r\nset &= ~intrs;\r\n}\r\nufshcd_writel(hba, set, REG_INTERRUPT_ENABLE);\r\n}\r\nstatic void ufshcd_prepare_req_desc_hdr(struct ufshcd_lrb *lrbp,\r\nu32 *upiu_flags, enum dma_data_direction cmd_dir)\r\n{\r\nstruct utp_transfer_req_desc *req_desc = lrbp->utr_descriptor_ptr;\r\nu32 data_direction;\r\nu32 dword_0;\r\nif (cmd_dir == DMA_FROM_DEVICE) {\r\ndata_direction = UTP_DEVICE_TO_HOST;\r\n*upiu_flags = UPIU_CMD_FLAGS_READ;\r\n} else if (cmd_dir == DMA_TO_DEVICE) {\r\ndata_direction = UTP_HOST_TO_DEVICE;\r\n*upiu_flags = UPIU_CMD_FLAGS_WRITE;\r\n} else {\r\ndata_direction = UTP_NO_DATA_TRANSFER;\r\n*upiu_flags = UPIU_CMD_FLAGS_NONE;\r\n}\r\ndword_0 = data_direction | (lrbp->command_type\r\n<< UPIU_COMMAND_TYPE_OFFSET);\r\nif (lrbp->intr_cmd)\r\ndword_0 |= UTP_REQ_DESC_INT_CMD;\r\nreq_desc->header.dword_0 = cpu_to_le32(dword_0);\r\nreq_desc->header.dword_2 =\r\ncpu_to_le32(OCS_INVALID_COMMAND_STATUS);\r\n}\r\nstatic\r\nvoid ufshcd_prepare_utp_scsi_cmd_upiu(struct ufshcd_lrb *lrbp, u32 upiu_flags)\r\n{\r\nstruct utp_upiu_req *ucd_req_ptr = lrbp->ucd_req_ptr;\r\nucd_req_ptr->header.dword_0 = UPIU_HEADER_DWORD(\r\nUPIU_TRANSACTION_COMMAND, upiu_flags,\r\nlrbp->lun, lrbp->task_tag);\r\nucd_req_ptr->header.dword_1 = UPIU_HEADER_DWORD(\r\nUPIU_COMMAND_SET_TYPE_SCSI, 0, 0, 0);\r\nucd_req_ptr->header.dword_2 = 0;\r\nucd_req_ptr->sc.exp_data_transfer_len =\r\ncpu_to_be32(lrbp->cmd->sdb.length);\r\nmemcpy(ucd_req_ptr->sc.cdb, lrbp->cmd->cmnd,\r\n(min_t(unsigned short, lrbp->cmd->cmd_len, MAX_CDB_SIZE)));\r\n}\r\nstatic void ufshcd_prepare_utp_query_req_upiu(struct ufs_hba *hba,\r\nstruct ufshcd_lrb *lrbp, u32 upiu_flags)\r\n{\r\nstruct utp_upiu_req *ucd_req_ptr = lrbp->ucd_req_ptr;\r\nstruct ufs_query *query = &hba->dev_cmd.query;\r\nu16 len = query->request.upiu_req.length;\r\nu8 *descp = (u8 *)lrbp->ucd_req_ptr + GENERAL_UPIU_REQUEST_SIZE;\r\nucd_req_ptr->header.dword_0 = UPIU_HEADER_DWORD(\r\nUPIU_TRANSACTION_QUERY_REQ, upiu_flags,\r\nlrbp->lun, lrbp->task_tag);\r\nucd_req_ptr->header.dword_1 = UPIU_HEADER_DWORD(\r\n0, query->request.query_func, 0, 0);\r\nucd_req_ptr->header.dword_2 = UPIU_HEADER_DWORD(\r\n0, 0, len >> 8, (u8)len);\r\nmemcpy(&ucd_req_ptr->qr, &query->request.upiu_req,\r\nQUERY_OSF_SIZE);\r\nufshcd_query_to_be(&ucd_req_ptr->qr);\r\nif ((len > 0) && (query->request.upiu_req.opcode ==\r\nUPIU_QUERY_OPCODE_WRITE_DESC)) {\r\nmemcpy(descp, query->descriptor,\r\nmin_t(u16, len, QUERY_DESC_MAX_SIZE));\r\n}\r\n}\r\nstatic inline void ufshcd_prepare_utp_nop_upiu(struct ufshcd_lrb *lrbp)\r\n{\r\nstruct utp_upiu_req *ucd_req_ptr = lrbp->ucd_req_ptr;\r\nmemset(ucd_req_ptr, 0, sizeof(struct utp_upiu_req));\r\nucd_req_ptr->header.dword_0 =\r\nUPIU_HEADER_DWORD(\r\nUPIU_TRANSACTION_NOP_OUT, 0, 0, lrbp->task_tag);\r\n}\r\nstatic int ufshcd_compose_upiu(struct ufs_hba *hba, struct ufshcd_lrb *lrbp)\r\n{\r\nu32 upiu_flags;\r\nint ret = 0;\r\nswitch (lrbp->command_type) {\r\ncase UTP_CMD_TYPE_SCSI:\r\nif (likely(lrbp->cmd)) {\r\nufshcd_prepare_req_desc_hdr(lrbp, &upiu_flags,\r\nlrbp->cmd->sc_data_direction);\r\nufshcd_prepare_utp_scsi_cmd_upiu(lrbp, upiu_flags);\r\n} else {\r\nret = -EINVAL;\r\n}\r\nbreak;\r\ncase UTP_CMD_TYPE_DEV_MANAGE:\r\nufshcd_prepare_req_desc_hdr(lrbp, &upiu_flags, DMA_NONE);\r\nif (hba->dev_cmd.type == DEV_CMD_TYPE_QUERY)\r\nufshcd_prepare_utp_query_req_upiu(\r\nhba, lrbp, upiu_flags);\r\nelse if (hba->dev_cmd.type == DEV_CMD_TYPE_NOP)\r\nufshcd_prepare_utp_nop_upiu(lrbp);\r\nelse\r\nret = -EINVAL;\r\nbreak;\r\ncase UTP_CMD_TYPE_UFS:\r\nret = -ENOTSUPP;\r\ndev_err(hba->dev, "%s: UFS native command are not supported\n",\r\n__func__);\r\nbreak;\r\ndefault:\r\nret = -ENOTSUPP;\r\ndev_err(hba->dev, "%s: unknown command type: 0x%x\n",\r\n__func__, lrbp->command_type);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int ufshcd_queuecommand(struct Scsi_Host *host, struct scsi_cmnd *cmd)\r\n{\r\nstruct ufshcd_lrb *lrbp;\r\nstruct ufs_hba *hba;\r\nunsigned long flags;\r\nint tag;\r\nint err = 0;\r\nhba = shost_priv(host);\r\ntag = cmd->request->tag;\r\nif (hba->ufshcd_state != UFSHCD_STATE_OPERATIONAL) {\r\nerr = SCSI_MLQUEUE_HOST_BUSY;\r\ngoto out;\r\n}\r\nif (test_and_set_bit_lock(tag, &hba->lrb_in_use)) {\r\nerr = SCSI_MLQUEUE_HOST_BUSY;\r\ngoto out;\r\n}\r\nlrbp = &hba->lrb[tag];\r\nWARN_ON(lrbp->cmd);\r\nlrbp->cmd = cmd;\r\nlrbp->sense_bufflen = SCSI_SENSE_BUFFERSIZE;\r\nlrbp->sense_buffer = cmd->sense_buffer;\r\nlrbp->task_tag = tag;\r\nlrbp->lun = cmd->device->lun;\r\nlrbp->intr_cmd = false;\r\nlrbp->command_type = UTP_CMD_TYPE_SCSI;\r\nufshcd_compose_upiu(hba, lrbp);\r\nerr = ufshcd_map_sg(lrbp);\r\nif (err) {\r\nlrbp->cmd = NULL;\r\nclear_bit_unlock(tag, &hba->lrb_in_use);\r\ngoto out;\r\n}\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nufshcd_send_command(hba, tag);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_compose_dev_cmd(struct ufs_hba *hba,\r\nstruct ufshcd_lrb *lrbp, enum dev_cmd_type cmd_type, int tag)\r\n{\r\nlrbp->cmd = NULL;\r\nlrbp->sense_bufflen = 0;\r\nlrbp->sense_buffer = NULL;\r\nlrbp->task_tag = tag;\r\nlrbp->lun = 0;\r\nlrbp->command_type = UTP_CMD_TYPE_DEV_MANAGE;\r\nlrbp->intr_cmd = true;\r\nhba->dev_cmd.type = cmd_type;\r\nreturn ufshcd_compose_upiu(hba, lrbp);\r\n}\r\nstatic int\r\nufshcd_clear_cmd(struct ufs_hba *hba, int tag)\r\n{\r\nint err = 0;\r\nunsigned long flags;\r\nu32 mask = 1 << tag;\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nufshcd_utrl_clear(hba, tag);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nerr = ufshcd_wait_for_register(hba,\r\nREG_UTP_TRANSFER_REQ_DOOR_BELL,\r\nmask, ~mask, 1000, 1000);\r\nreturn err;\r\n}\r\nstatic int\r\nufshcd_dev_cmd_completion(struct ufs_hba *hba, struct ufshcd_lrb *lrbp)\r\n{\r\nint resp;\r\nint err = 0;\r\nresp = ufshcd_get_req_rsp(lrbp->ucd_rsp_ptr);\r\nswitch (resp) {\r\ncase UPIU_TRANSACTION_NOP_IN:\r\nif (hba->dev_cmd.type != DEV_CMD_TYPE_NOP) {\r\nerr = -EINVAL;\r\ndev_err(hba->dev, "%s: unexpected response %x\n",\r\n__func__, resp);\r\n}\r\nbreak;\r\ncase UPIU_TRANSACTION_QUERY_RSP:\r\nufshcd_copy_query_response(hba, lrbp);\r\nbreak;\r\ncase UPIU_TRANSACTION_REJECT_UPIU:\r\nerr = -EPERM;\r\ndev_err(hba->dev, "%s: Reject UPIU not fully implemented\n",\r\n__func__);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ndev_err(hba->dev, "%s: Invalid device management cmd response: %x\n",\r\n__func__, resp);\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic int ufshcd_wait_for_dev_cmd(struct ufs_hba *hba,\r\nstruct ufshcd_lrb *lrbp, int max_timeout)\r\n{\r\nint err = 0;\r\nunsigned long time_left;\r\nunsigned long flags;\r\ntime_left = wait_for_completion_timeout(hba->dev_cmd.complete,\r\nmsecs_to_jiffies(max_timeout));\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nhba->dev_cmd.complete = NULL;\r\nif (likely(time_left)) {\r\nerr = ufshcd_get_tr_ocs(lrbp);\r\nif (!err)\r\nerr = ufshcd_dev_cmd_completion(hba, lrbp);\r\n}\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nif (!time_left) {\r\nerr = -ETIMEDOUT;\r\nif (!ufshcd_clear_cmd(hba, lrbp->task_tag))\r\nerr = -EAGAIN;\r\n}\r\nreturn err;\r\n}\r\nstatic bool ufshcd_get_dev_cmd_tag(struct ufs_hba *hba, int *tag_out)\r\n{\r\nint tag;\r\nbool ret = false;\r\nunsigned long tmp;\r\nif (!tag_out)\r\ngoto out;\r\ndo {\r\ntmp = ~hba->lrb_in_use;\r\ntag = find_last_bit(&tmp, hba->nutrs);\r\nif (tag >= hba->nutrs)\r\ngoto out;\r\n} while (test_and_set_bit_lock(tag, &hba->lrb_in_use));\r\n*tag_out = tag;\r\nret = true;\r\nout:\r\nreturn ret;\r\n}\r\nstatic inline void ufshcd_put_dev_cmd_tag(struct ufs_hba *hba, int tag)\r\n{\r\nclear_bit_unlock(tag, &hba->lrb_in_use);\r\n}\r\nstatic int ufshcd_exec_dev_cmd(struct ufs_hba *hba,\r\nenum dev_cmd_type cmd_type, int timeout)\r\n{\r\nstruct ufshcd_lrb *lrbp;\r\nint err;\r\nint tag;\r\nstruct completion wait;\r\nunsigned long flags;\r\nwait_event(hba->dev_cmd.tag_wq, ufshcd_get_dev_cmd_tag(hba, &tag));\r\ninit_completion(&wait);\r\nlrbp = &hba->lrb[tag];\r\nWARN_ON(lrbp->cmd);\r\nerr = ufshcd_compose_dev_cmd(hba, lrbp, cmd_type, tag);\r\nif (unlikely(err))\r\ngoto out_put_tag;\r\nhba->dev_cmd.complete = &wait;\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nufshcd_send_command(hba, tag);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nerr = ufshcd_wait_for_dev_cmd(hba, lrbp, timeout);\r\nout_put_tag:\r\nufshcd_put_dev_cmd_tag(hba, tag);\r\nwake_up(&hba->dev_cmd.tag_wq);\r\nreturn err;\r\n}\r\nstatic int ufshcd_query_flag(struct ufs_hba *hba, enum query_opcode opcode,\r\nenum flag_idn idn, bool *flag_res)\r\n{\r\nstruct ufs_query_req *request;\r\nstruct ufs_query_res *response;\r\nint err;\r\nBUG_ON(!hba);\r\nmutex_lock(&hba->dev_cmd.lock);\r\nrequest = &hba->dev_cmd.query.request;\r\nresponse = &hba->dev_cmd.query.response;\r\nmemset(request, 0, sizeof(struct ufs_query_req));\r\nmemset(response, 0, sizeof(struct ufs_query_res));\r\nswitch (opcode) {\r\ncase UPIU_QUERY_OPCODE_SET_FLAG:\r\ncase UPIU_QUERY_OPCODE_CLEAR_FLAG:\r\ncase UPIU_QUERY_OPCODE_TOGGLE_FLAG:\r\nrequest->query_func = UPIU_QUERY_FUNC_STANDARD_WRITE_REQUEST;\r\nbreak;\r\ncase UPIU_QUERY_OPCODE_READ_FLAG:\r\nrequest->query_func = UPIU_QUERY_FUNC_STANDARD_READ_REQUEST;\r\nif (!flag_res) {\r\ndev_err(hba->dev, "%s: Invalid argument for read request\n",\r\n__func__);\r\nerr = -EINVAL;\r\ngoto out_unlock;\r\n}\r\nbreak;\r\ndefault:\r\ndev_err(hba->dev,\r\n"%s: Expected query flag opcode but got = %d\n",\r\n__func__, opcode);\r\nerr = -EINVAL;\r\ngoto out_unlock;\r\n}\r\nrequest->upiu_req.opcode = opcode;\r\nrequest->upiu_req.idn = idn;\r\nerr = ufshcd_exec_dev_cmd(hba, DEV_CMD_TYPE_QUERY,\r\nQUERY_REQ_TIMEOUT);\r\nif (err) {\r\ndev_err(hba->dev,\r\n"%s: Sending flag query for idn %d failed, err = %d\n",\r\n__func__, idn, err);\r\ngoto out_unlock;\r\n}\r\nif (flag_res)\r\n*flag_res = (response->upiu_res.value &\r\nMASK_QUERY_UPIU_FLAG_LOC) & 0x1;\r\nout_unlock:\r\nmutex_unlock(&hba->dev_cmd.lock);\r\nreturn err;\r\n}\r\nint ufshcd_query_attr(struct ufs_hba *hba, enum query_opcode opcode,\r\nenum attr_idn idn, u8 index, u8 selector, u32 *attr_val)\r\n{\r\nstruct ufs_query_req *request;\r\nstruct ufs_query_res *response;\r\nint err;\r\nBUG_ON(!hba);\r\nif (!attr_val) {\r\ndev_err(hba->dev, "%s: attribute value required for opcode 0x%x\n",\r\n__func__, opcode);\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\nmutex_lock(&hba->dev_cmd.lock);\r\nrequest = &hba->dev_cmd.query.request;\r\nresponse = &hba->dev_cmd.query.response;\r\nmemset(request, 0, sizeof(struct ufs_query_req));\r\nmemset(response, 0, sizeof(struct ufs_query_res));\r\nswitch (opcode) {\r\ncase UPIU_QUERY_OPCODE_WRITE_ATTR:\r\nrequest->query_func = UPIU_QUERY_FUNC_STANDARD_WRITE_REQUEST;\r\nrequest->upiu_req.value = *attr_val;\r\nbreak;\r\ncase UPIU_QUERY_OPCODE_READ_ATTR:\r\nrequest->query_func = UPIU_QUERY_FUNC_STANDARD_READ_REQUEST;\r\nbreak;\r\ndefault:\r\ndev_err(hba->dev, "%s: Expected query attr opcode but got = 0x%.2x\n",\r\n__func__, opcode);\r\nerr = -EINVAL;\r\ngoto out_unlock;\r\n}\r\nrequest->upiu_req.opcode = opcode;\r\nrequest->upiu_req.idn = idn;\r\nrequest->upiu_req.index = index;\r\nrequest->upiu_req.selector = selector;\r\nerr = ufshcd_exec_dev_cmd(hba, DEV_CMD_TYPE_QUERY,\r\nQUERY_REQ_TIMEOUT);\r\nif (err) {\r\ndev_err(hba->dev, "%s: opcode 0x%.2x for idn %d failed, err = %d\n",\r\n__func__, opcode, idn, err);\r\ngoto out_unlock;\r\n}\r\n*attr_val = response->upiu_res.value;\r\nout_unlock:\r\nmutex_unlock(&hba->dev_cmd.lock);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_memory_alloc(struct ufs_hba *hba)\r\n{\r\nsize_t utmrdl_size, utrdl_size, ucdl_size;\r\nucdl_size = (sizeof(struct utp_transfer_cmd_desc) * hba->nutrs);\r\nhba->ucdl_base_addr = dmam_alloc_coherent(hba->dev,\r\nucdl_size,\r\n&hba->ucdl_dma_addr,\r\nGFP_KERNEL);\r\nif (!hba->ucdl_base_addr ||\r\nWARN_ON(hba->ucdl_dma_addr & (PAGE_SIZE - 1))) {\r\ndev_err(hba->dev,\r\n"Command Descriptor Memory allocation failed\n");\r\ngoto out;\r\n}\r\nutrdl_size = (sizeof(struct utp_transfer_req_desc) * hba->nutrs);\r\nhba->utrdl_base_addr = dmam_alloc_coherent(hba->dev,\r\nutrdl_size,\r\n&hba->utrdl_dma_addr,\r\nGFP_KERNEL);\r\nif (!hba->utrdl_base_addr ||\r\nWARN_ON(hba->utrdl_dma_addr & (PAGE_SIZE - 1))) {\r\ndev_err(hba->dev,\r\n"Transfer Descriptor Memory allocation failed\n");\r\ngoto out;\r\n}\r\nutmrdl_size = sizeof(struct utp_task_req_desc) * hba->nutmrs;\r\nhba->utmrdl_base_addr = dmam_alloc_coherent(hba->dev,\r\nutmrdl_size,\r\n&hba->utmrdl_dma_addr,\r\nGFP_KERNEL);\r\nif (!hba->utmrdl_base_addr ||\r\nWARN_ON(hba->utmrdl_dma_addr & (PAGE_SIZE - 1))) {\r\ndev_err(hba->dev,\r\n"Task Management Descriptor Memory allocation failed\n");\r\ngoto out;\r\n}\r\nhba->lrb = devm_kzalloc(hba->dev,\r\nhba->nutrs * sizeof(struct ufshcd_lrb),\r\nGFP_KERNEL);\r\nif (!hba->lrb) {\r\ndev_err(hba->dev, "LRB Memory allocation failed\n");\r\ngoto out;\r\n}\r\nreturn 0;\r\nout:\r\nreturn -ENOMEM;\r\n}\r\nstatic void ufshcd_host_memory_configure(struct ufs_hba *hba)\r\n{\r\nstruct utp_transfer_cmd_desc *cmd_descp;\r\nstruct utp_transfer_req_desc *utrdlp;\r\ndma_addr_t cmd_desc_dma_addr;\r\ndma_addr_t cmd_desc_element_addr;\r\nu16 response_offset;\r\nu16 prdt_offset;\r\nint cmd_desc_size;\r\nint i;\r\nutrdlp = hba->utrdl_base_addr;\r\ncmd_descp = hba->ucdl_base_addr;\r\nresponse_offset =\r\noffsetof(struct utp_transfer_cmd_desc, response_upiu);\r\nprdt_offset =\r\noffsetof(struct utp_transfer_cmd_desc, prd_table);\r\ncmd_desc_size = sizeof(struct utp_transfer_cmd_desc);\r\ncmd_desc_dma_addr = hba->ucdl_dma_addr;\r\nfor (i = 0; i < hba->nutrs; i++) {\r\ncmd_desc_element_addr =\r\n(cmd_desc_dma_addr + (cmd_desc_size * i));\r\nutrdlp[i].command_desc_base_addr_lo =\r\ncpu_to_le32(lower_32_bits(cmd_desc_element_addr));\r\nutrdlp[i].command_desc_base_addr_hi =\r\ncpu_to_le32(upper_32_bits(cmd_desc_element_addr));\r\nutrdlp[i].response_upiu_offset =\r\ncpu_to_le16((response_offset >> 2));\r\nutrdlp[i].prd_table_offset =\r\ncpu_to_le16((prdt_offset >> 2));\r\nutrdlp[i].response_upiu_length =\r\ncpu_to_le16(ALIGNED_UPIU_SIZE >> 2);\r\nhba->lrb[i].utr_descriptor_ptr = (utrdlp + i);\r\nhba->lrb[i].ucd_req_ptr =\r\n(struct utp_upiu_req *)(cmd_descp + i);\r\nhba->lrb[i].ucd_rsp_ptr =\r\n(struct utp_upiu_rsp *)cmd_descp[i].response_upiu;\r\nhba->lrb[i].ucd_prdt_ptr =\r\n(struct ufshcd_sg_entry *)cmd_descp[i].prd_table;\r\n}\r\n}\r\nstatic int ufshcd_dme_link_startup(struct ufs_hba *hba)\r\n{\r\nstruct uic_command uic_cmd = {0};\r\nint ret;\r\nuic_cmd.command = UIC_CMD_DME_LINK_STARTUP;\r\nret = ufshcd_send_uic_cmd(hba, &uic_cmd);\r\nif (ret)\r\ndev_err(hba->dev,\r\n"dme-link-startup: error code %d\n", ret);\r\nreturn ret;\r\n}\r\nint ufshcd_dme_set_attr(struct ufs_hba *hba, u32 attr_sel,\r\nu8 attr_set, u32 mib_val, u8 peer)\r\n{\r\nstruct uic_command uic_cmd = {0};\r\nstatic const char *const action[] = {\r\n"dme-set",\r\n"dme-peer-set"\r\n};\r\nconst char *set = action[!!peer];\r\nint ret;\r\nuic_cmd.command = peer ?\r\nUIC_CMD_DME_PEER_SET : UIC_CMD_DME_SET;\r\nuic_cmd.argument1 = attr_sel;\r\nuic_cmd.argument2 = UIC_ARG_ATTR_TYPE(attr_set);\r\nuic_cmd.argument3 = mib_val;\r\nret = ufshcd_send_uic_cmd(hba, &uic_cmd);\r\nif (ret)\r\ndev_err(hba->dev, "%s: attr-id 0x%x val 0x%x error code %d\n",\r\nset, UIC_GET_ATTR_ID(attr_sel), mib_val, ret);\r\nreturn ret;\r\n}\r\nint ufshcd_dme_get_attr(struct ufs_hba *hba, u32 attr_sel,\r\nu32 *mib_val, u8 peer)\r\n{\r\nstruct uic_command uic_cmd = {0};\r\nstatic const char *const action[] = {\r\n"dme-get",\r\n"dme-peer-get"\r\n};\r\nconst char *get = action[!!peer];\r\nint ret;\r\nuic_cmd.command = peer ?\r\nUIC_CMD_DME_PEER_GET : UIC_CMD_DME_GET;\r\nuic_cmd.argument1 = attr_sel;\r\nret = ufshcd_send_uic_cmd(hba, &uic_cmd);\r\nif (ret) {\r\ndev_err(hba->dev, "%s: attr-id 0x%x error code %d\n",\r\nget, UIC_GET_ATTR_ID(attr_sel), ret);\r\ngoto out;\r\n}\r\nif (mib_val)\r\n*mib_val = uic_cmd.argument3;\r\nout:\r\nreturn ret;\r\n}\r\nint ufshcd_uic_change_pwr_mode(struct ufs_hba *hba, u8 mode)\r\n{\r\nstruct uic_command uic_cmd = {0};\r\nstruct completion pwr_done;\r\nunsigned long flags;\r\nu8 status;\r\nint ret;\r\nuic_cmd.command = UIC_CMD_DME_SET;\r\nuic_cmd.argument1 = UIC_ARG_MIB(PA_PWRMODE);\r\nuic_cmd.argument3 = mode;\r\ninit_completion(&pwr_done);\r\nmutex_lock(&hba->uic_cmd_mutex);\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nhba->pwr_done = &pwr_done;\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nret = __ufshcd_send_uic_cmd(hba, &uic_cmd);\r\nif (ret) {\r\ndev_err(hba->dev,\r\n"pwr mode change with mode 0x%x uic error %d\n",\r\nmode, ret);\r\ngoto out;\r\n}\r\nif (!wait_for_completion_timeout(hba->pwr_done,\r\nmsecs_to_jiffies(UIC_CMD_TIMEOUT))) {\r\ndev_err(hba->dev,\r\n"pwr mode change with mode 0x%x completion timeout\n",\r\nmode);\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nstatus = ufshcd_get_upmcrs(hba);\r\nif (status != PWR_LOCAL) {\r\ndev_err(hba->dev,\r\n"pwr mode change failed, host umpcrs:0x%x\n",\r\nstatus);\r\nret = (status != PWR_OK) ? status : -1;\r\n}\r\nout:\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nhba->pwr_done = NULL;\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nmutex_unlock(&hba->uic_cmd_mutex);\r\nreturn ret;\r\n}\r\nstatic int ufshcd_config_max_pwr_mode(struct ufs_hba *hba)\r\n{\r\nenum {RX = 0, TX = 1};\r\nu32 lanes[] = {1, 1};\r\nu32 gear[] = {1, 1};\r\nu8 pwr[] = {FASTAUTO_MODE, FASTAUTO_MODE};\r\nint ret;\r\nufshcd_dme_get(hba, UIC_ARG_MIB(PA_CONNECTEDRXDATALANES), &lanes[RX]);\r\nufshcd_dme_get(hba, UIC_ARG_MIB(PA_CONNECTEDTXDATALANES), &lanes[TX]);\r\nufshcd_dme_get(hba, UIC_ARG_MIB(PA_MAXRXHSGEAR), &gear[RX]);\r\nif (!gear[RX]) {\r\nufshcd_dme_get(hba, UIC_ARG_MIB(PA_MAXRXPWMGEAR), &gear[RX]);\r\npwr[RX] = SLOWAUTO_MODE;\r\n}\r\nufshcd_dme_peer_get(hba, UIC_ARG_MIB(PA_MAXRXHSGEAR), &gear[TX]);\r\nif (!gear[TX]) {\r\nufshcd_dme_peer_get(hba, UIC_ARG_MIB(PA_MAXRXPWMGEAR),\r\n&gear[TX]);\r\npwr[TX] = SLOWAUTO_MODE;\r\n}\r\nufshcd_dme_set(hba, UIC_ARG_MIB(PA_RXGEAR), gear[RX]);\r\nufshcd_dme_set(hba, UIC_ARG_MIB(PA_ACTIVERXDATALANES), lanes[RX]);\r\nif (pwr[RX] == FASTAUTO_MODE)\r\nufshcd_dme_set(hba, UIC_ARG_MIB(PA_RXTERMINATION), TRUE);\r\nufshcd_dme_set(hba, UIC_ARG_MIB(PA_TXGEAR), gear[TX]);\r\nufshcd_dme_set(hba, UIC_ARG_MIB(PA_ACTIVETXDATALANES), lanes[TX]);\r\nif (pwr[TX] == FASTAUTO_MODE)\r\nufshcd_dme_set(hba, UIC_ARG_MIB(PA_TXTERMINATION), TRUE);\r\nif (pwr[RX] == FASTAUTO_MODE || pwr[TX] == FASTAUTO_MODE)\r\nufshcd_dme_set(hba, UIC_ARG_MIB(PA_HSSERIES), PA_HS_MODE_B);\r\nret = ufshcd_uic_change_pwr_mode(hba, pwr[RX] << 4 | pwr[TX]);\r\nif (ret)\r\ndev_err(hba->dev,\r\n"pwr_mode: power mode change failed %d\n", ret);\r\nreturn ret;\r\n}\r\nstatic int ufshcd_complete_dev_init(struct ufs_hba *hba)\r\n{\r\nint i, retries, err = 0;\r\nbool flag_res = 1;\r\nfor (retries = QUERY_REQ_RETRIES; retries > 0; retries--) {\r\nerr = ufshcd_query_flag(hba, UPIU_QUERY_OPCODE_SET_FLAG,\r\nQUERY_FLAG_IDN_FDEVICEINIT, NULL);\r\nif (!err || err == -ETIMEDOUT)\r\nbreak;\r\ndev_dbg(hba->dev, "%s: error %d retrying\n", __func__, err);\r\n}\r\nif (err) {\r\ndev_err(hba->dev,\r\n"%s setting fDeviceInit flag failed with error %d\n",\r\n__func__, err);\r\ngoto out;\r\n}\r\nfor (i = 0; i < 100 && !err && flag_res; i++) {\r\nfor (retries = QUERY_REQ_RETRIES; retries > 0; retries--) {\r\nerr = ufshcd_query_flag(hba,\r\nUPIU_QUERY_OPCODE_READ_FLAG,\r\nQUERY_FLAG_IDN_FDEVICEINIT, &flag_res);\r\nif (!err || err == -ETIMEDOUT)\r\nbreak;\r\ndev_dbg(hba->dev, "%s: error %d retrying\n", __func__,\r\nerr);\r\n}\r\n}\r\nif (err)\r\ndev_err(hba->dev,\r\n"%s reading fDeviceInit flag failed with error %d\n",\r\n__func__, err);\r\nelse if (flag_res)\r\ndev_err(hba->dev,\r\n"%s fDeviceInit was not cleared by the device\n",\r\n__func__);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_make_hba_operational(struct ufs_hba *hba)\r\n{\r\nint err = 0;\r\nu32 reg;\r\nreg = ufshcd_readl(hba, REG_CONTROLLER_STATUS);\r\nif (!ufshcd_is_device_present(reg)) {\r\ndev_err(hba->dev, "cc: Device not present\n");\r\nerr = -ENXIO;\r\ngoto out;\r\n}\r\nufshcd_enable_intr(hba, UFSHCD_ENABLE_INTRS);\r\nufshcd_config_intr_aggr(hba, hba->nutrs - 1, INT_AGGR_DEF_TO);\r\nufshcd_writel(hba, lower_32_bits(hba->utrdl_dma_addr),\r\nREG_UTP_TRANSFER_REQ_LIST_BASE_L);\r\nufshcd_writel(hba, upper_32_bits(hba->utrdl_dma_addr),\r\nREG_UTP_TRANSFER_REQ_LIST_BASE_H);\r\nufshcd_writel(hba, lower_32_bits(hba->utmrdl_dma_addr),\r\nREG_UTP_TASK_REQ_LIST_BASE_L);\r\nufshcd_writel(hba, upper_32_bits(hba->utmrdl_dma_addr),\r\nREG_UTP_TASK_REQ_LIST_BASE_H);\r\nif (!(ufshcd_get_lists_status(reg))) {\r\nufshcd_enable_run_stop_reg(hba);\r\n} else {\r\ndev_err(hba->dev,\r\n"Host controller not ready to process requests");\r\nerr = -EIO;\r\ngoto out;\r\n}\r\nif (hba->ufshcd_state == UFSHCD_STATE_RESET)\r\nscsi_unblock_requests(hba->host);\r\nhba->ufshcd_state = UFSHCD_STATE_OPERATIONAL;\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_hba_enable(struct ufs_hba *hba)\r\n{\r\nint retry;\r\nif (!ufshcd_is_hba_active(hba)) {\r\nufshcd_hba_stop(hba);\r\nmsleep(5);\r\n}\r\nufshcd_hba_start(hba);\r\nmsleep(1);\r\nretry = 10;\r\nwhile (ufshcd_is_hba_active(hba)) {\r\nif (retry) {\r\nretry--;\r\n} else {\r\ndev_err(hba->dev,\r\n"Controller enable failed\n");\r\nreturn -EIO;\r\n}\r\nmsleep(5);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ufshcd_link_startup(struct ufs_hba *hba)\r\n{\r\nint ret;\r\nufshcd_enable_intr(hba, UIC_COMMAND_COMPL);\r\nret = ufshcd_dme_link_startup(hba);\r\nif (ret)\r\ngoto out;\r\nret = ufshcd_make_hba_operational(hba);\r\nout:\r\nif (ret)\r\ndev_err(hba->dev, "link startup failed %d\n", ret);\r\nreturn ret;\r\n}\r\nstatic int ufshcd_verify_dev_init(struct ufs_hba *hba)\r\n{\r\nint err = 0;\r\nint retries;\r\nmutex_lock(&hba->dev_cmd.lock);\r\nfor (retries = NOP_OUT_RETRIES; retries > 0; retries--) {\r\nerr = ufshcd_exec_dev_cmd(hba, DEV_CMD_TYPE_NOP,\r\nNOP_OUT_TIMEOUT);\r\nif (!err || err == -ETIMEDOUT)\r\nbreak;\r\ndev_dbg(hba->dev, "%s: error %d retrying\n", __func__, err);\r\n}\r\nmutex_unlock(&hba->dev_cmd.lock);\r\nif (err)\r\ndev_err(hba->dev, "%s: NOP OUT failed %d\n", __func__, err);\r\nreturn err;\r\n}\r\nstatic int ufshcd_do_reset(struct ufs_hba *hba)\r\n{\r\nstruct ufshcd_lrb *lrbp;\r\nunsigned long flags;\r\nint tag;\r\nscsi_block_requests(hba->host);\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nhba->ufshcd_state = UFSHCD_STATE_RESET;\r\nufshcd_hba_stop(hba);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nfor (tag = 0; tag < hba->nutrs; tag++) {\r\nif (test_bit(tag, &hba->outstanding_reqs)) {\r\nlrbp = &hba->lrb[tag];\r\nif (lrbp->cmd) {\r\nscsi_dma_unmap(lrbp->cmd);\r\nlrbp->cmd->result = DID_RESET << 16;\r\nlrbp->cmd->scsi_done(lrbp->cmd);\r\nlrbp->cmd = NULL;\r\nclear_bit_unlock(tag, &hba->lrb_in_use);\r\n}\r\n}\r\n}\r\nif (hba->dev_cmd.complete)\r\ncomplete(hba->dev_cmd.complete);\r\nhba->outstanding_reqs = 0;\r\nhba->outstanding_tasks = 0;\r\nif (ufshcd_hba_enable(hba)) {\r\ndev_err(hba->dev,\r\n"Reset: Controller initialization failed\n");\r\nreturn FAILED;\r\n}\r\nif (ufshcd_link_startup(hba)) {\r\ndev_err(hba->dev,\r\n"Reset: Link start-up failed\n");\r\nreturn FAILED;\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int ufshcd_slave_alloc(struct scsi_device *sdev)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = shost_priv(sdev->host);\r\nsdev->tagged_supported = 1;\r\nsdev->use_10_for_ms = 1;\r\nscsi_set_tag_type(sdev, MSG_SIMPLE_TAG);\r\nscsi_activate_tcq(sdev, hba->nutrs);\r\nreturn 0;\r\n}\r\nstatic void ufshcd_slave_destroy(struct scsi_device *sdev)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = shost_priv(sdev->host);\r\nscsi_deactivate_tcq(sdev, hba->nutrs);\r\n}\r\nstatic int ufshcd_task_req_compl(struct ufs_hba *hba, u32 index)\r\n{\r\nstruct utp_task_req_desc *task_req_descp;\r\nstruct utp_upiu_task_rsp *task_rsp_upiup;\r\nunsigned long flags;\r\nint ocs_value;\r\nint task_result;\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\n__clear_bit(index, &hba->outstanding_tasks);\r\ntask_req_descp = hba->utmrdl_base_addr;\r\nocs_value = ufshcd_get_tmr_ocs(&task_req_descp[index]);\r\nif (ocs_value == OCS_SUCCESS) {\r\ntask_rsp_upiup = (struct utp_upiu_task_rsp *)\r\ntask_req_descp[index].task_rsp_upiu;\r\ntask_result = be32_to_cpu(task_rsp_upiup->header.dword_1);\r\ntask_result = ((task_result & MASK_TASK_RESPONSE) >> 8);\r\nif (task_result != UPIU_TASK_MANAGEMENT_FUNC_COMPL &&\r\ntask_result != UPIU_TASK_MANAGEMENT_FUNC_SUCCEEDED)\r\ntask_result = FAILED;\r\nelse\r\ntask_result = SUCCESS;\r\n} else {\r\ntask_result = FAILED;\r\ndev_err(hba->dev,\r\n"trc: Invalid ocs = %x\n", ocs_value);\r\n}\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nreturn task_result;\r\n}\r\nstatic void ufshcd_adjust_lun_qdepth(struct scsi_cmnd *cmd)\r\n{\r\nstruct ufs_hba *hba;\r\nint i;\r\nint lun_qdepth = 0;\r\nhba = shost_priv(cmd->device->host);\r\nfor (i = 0; i < hba->nutrs; i++) {\r\nif (test_bit(i, &hba->outstanding_reqs)) {\r\nif (cmd->device->lun == hba->lrb[i].lun)\r\nlun_qdepth++;\r\n}\r\n}\r\nscsi_adjust_queue_depth(cmd->device, MSG_SIMPLE_TAG, lun_qdepth - 1);\r\n}\r\nstatic inline int\r\nufshcd_scsi_cmd_status(struct ufshcd_lrb *lrbp, int scsi_status)\r\n{\r\nint result = 0;\r\nswitch (scsi_status) {\r\ncase SAM_STAT_CHECK_CONDITION:\r\nufshcd_copy_sense_data(lrbp);\r\ncase SAM_STAT_GOOD:\r\nresult |= DID_OK << 16 |\r\nCOMMAND_COMPLETE << 8 |\r\nscsi_status;\r\nbreak;\r\ncase SAM_STAT_TASK_SET_FULL:\r\nufshcd_adjust_lun_qdepth(lrbp->cmd);\r\ncase SAM_STAT_BUSY:\r\ncase SAM_STAT_TASK_ABORTED:\r\nufshcd_copy_sense_data(lrbp);\r\nresult |= scsi_status;\r\nbreak;\r\ndefault:\r\nresult |= DID_ERROR << 16;\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic inline int\r\nufshcd_transfer_rsp_status(struct ufs_hba *hba, struct ufshcd_lrb *lrbp)\r\n{\r\nint result = 0;\r\nint scsi_status;\r\nint ocs;\r\nocs = ufshcd_get_tr_ocs(lrbp);\r\nswitch (ocs) {\r\ncase OCS_SUCCESS:\r\nresult = ufshcd_get_req_rsp(lrbp->ucd_rsp_ptr);\r\nswitch (result) {\r\ncase UPIU_TRANSACTION_RESPONSE:\r\nresult = ufshcd_get_rsp_upiu_result(lrbp->ucd_rsp_ptr);\r\nscsi_status = result & MASK_SCSI_STATUS;\r\nresult = ufshcd_scsi_cmd_status(lrbp, scsi_status);\r\nif (ufshcd_is_exception_event(lrbp->ucd_rsp_ptr))\r\nschedule_work(&hba->eeh_work);\r\nbreak;\r\ncase UPIU_TRANSACTION_REJECT_UPIU:\r\nresult = DID_ERROR << 16;\r\ndev_err(hba->dev,\r\n"Reject UPIU not fully implemented\n");\r\nbreak;\r\ndefault:\r\nresult = DID_ERROR << 16;\r\ndev_err(hba->dev,\r\n"Unexpected request response code = %x\n",\r\nresult);\r\nbreak;\r\n}\r\nbreak;\r\ncase OCS_ABORTED:\r\nresult |= DID_ABORT << 16;\r\nbreak;\r\ncase OCS_INVALID_CMD_TABLE_ATTR:\r\ncase OCS_INVALID_PRDT_ATTR:\r\ncase OCS_MISMATCH_DATA_BUF_SIZE:\r\ncase OCS_MISMATCH_RESP_UPIU_SIZE:\r\ncase OCS_PEER_COMM_FAILURE:\r\ncase OCS_FATAL_ERROR:\r\ndefault:\r\nresult |= DID_ERROR << 16;\r\ndev_err(hba->dev,\r\n"OCS error from controller = %x\n", ocs);\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic void ufshcd_uic_cmd_compl(struct ufs_hba *hba, u32 intr_status)\r\n{\r\nif ((intr_status & UIC_COMMAND_COMPL) && hba->active_uic_cmd) {\r\nhba->active_uic_cmd->argument2 |=\r\nufshcd_get_uic_cmd_result(hba);\r\nhba->active_uic_cmd->argument3 =\r\nufshcd_get_dme_attr_val(hba);\r\ncomplete(&hba->active_uic_cmd->done);\r\n}\r\nif ((intr_status & UIC_POWER_MODE) && hba->pwr_done)\r\ncomplete(hba->pwr_done);\r\n}\r\nstatic void ufshcd_transfer_req_compl(struct ufs_hba *hba)\r\n{\r\nstruct ufshcd_lrb *lrbp;\r\nstruct scsi_cmnd *cmd;\r\nunsigned long completed_reqs;\r\nu32 tr_doorbell;\r\nint result;\r\nint index;\r\nbool int_aggr_reset = false;\r\ntr_doorbell = ufshcd_readl(hba, REG_UTP_TRANSFER_REQ_DOOR_BELL);\r\ncompleted_reqs = tr_doorbell ^ hba->outstanding_reqs;\r\nfor (index = 0; index < hba->nutrs; index++) {\r\nif (test_bit(index, &completed_reqs)) {\r\nlrbp = &hba->lrb[index];\r\ncmd = lrbp->cmd;\r\nint_aggr_reset |= !lrbp->intr_cmd;\r\nif (cmd) {\r\nresult = ufshcd_transfer_rsp_status(hba, lrbp);\r\nscsi_dma_unmap(cmd);\r\ncmd->result = result;\r\nlrbp->cmd = NULL;\r\nclear_bit_unlock(index, &hba->lrb_in_use);\r\ncmd->scsi_done(cmd);\r\n} else if (lrbp->command_type ==\r\nUTP_CMD_TYPE_DEV_MANAGE) {\r\nif (hba->dev_cmd.complete)\r\ncomplete(hba->dev_cmd.complete);\r\n}\r\n}\r\n}\r\nhba->outstanding_reqs ^= completed_reqs;\r\nwake_up(&hba->dev_cmd.tag_wq);\r\nif (int_aggr_reset)\r\nufshcd_reset_intr_aggr(hba);\r\n}\r\nstatic int ufshcd_disable_ee(struct ufs_hba *hba, u16 mask)\r\n{\r\nint err = 0;\r\nu32 val;\r\nif (!(hba->ee_ctrl_mask & mask))\r\ngoto out;\r\nval = hba->ee_ctrl_mask & ~mask;\r\nval &= 0xFFFF;\r\nerr = ufshcd_query_attr(hba, UPIU_QUERY_OPCODE_WRITE_ATTR,\r\nQUERY_ATTR_IDN_EE_CONTROL, 0, 0, &val);\r\nif (!err)\r\nhba->ee_ctrl_mask &= ~mask;\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_enable_ee(struct ufs_hba *hba, u16 mask)\r\n{\r\nint err = 0;\r\nu32 val;\r\nif (hba->ee_ctrl_mask & mask)\r\ngoto out;\r\nval = hba->ee_ctrl_mask | mask;\r\nval &= 0xFFFF;\r\nerr = ufshcd_query_attr(hba, UPIU_QUERY_OPCODE_WRITE_ATTR,\r\nQUERY_ATTR_IDN_EE_CONTROL, 0, 0, &val);\r\nif (!err)\r\nhba->ee_ctrl_mask |= mask;\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_enable_auto_bkops(struct ufs_hba *hba)\r\n{\r\nint err = 0;\r\nif (hba->auto_bkops_enabled)\r\ngoto out;\r\nerr = ufshcd_query_flag(hba, UPIU_QUERY_OPCODE_SET_FLAG,\r\nQUERY_FLAG_IDN_BKOPS_EN, NULL);\r\nif (err) {\r\ndev_err(hba->dev, "%s: failed to enable bkops %d\n",\r\n__func__, err);\r\ngoto out;\r\n}\r\nhba->auto_bkops_enabled = true;\r\nerr = ufshcd_disable_ee(hba, MASK_EE_URGENT_BKOPS);\r\nif (err)\r\ndev_err(hba->dev, "%s: failed to disable exception event %d\n",\r\n__func__, err);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_disable_auto_bkops(struct ufs_hba *hba)\r\n{\r\nint err = 0;\r\nif (!hba->auto_bkops_enabled)\r\ngoto out;\r\nerr = ufshcd_enable_ee(hba, MASK_EE_URGENT_BKOPS);\r\nif (err) {\r\ndev_err(hba->dev, "%s: failed to enable exception event %d\n",\r\n__func__, err);\r\ngoto out;\r\n}\r\nerr = ufshcd_query_flag(hba, UPIU_QUERY_OPCODE_CLEAR_FLAG,\r\nQUERY_FLAG_IDN_BKOPS_EN, NULL);\r\nif (err) {\r\ndev_err(hba->dev, "%s: failed to disable bkops %d\n",\r\n__func__, err);\r\nufshcd_disable_ee(hba, MASK_EE_URGENT_BKOPS);\r\ngoto out;\r\n}\r\nhba->auto_bkops_enabled = false;\r\nout:\r\nreturn err;\r\n}\r\nstatic void ufshcd_force_reset_auto_bkops(struct ufs_hba *hba)\r\n{\r\nhba->auto_bkops_enabled = false;\r\nhba->ee_ctrl_mask |= MASK_EE_URGENT_BKOPS;\r\nufshcd_enable_auto_bkops(hba);\r\n}\r\nstatic inline int ufshcd_get_bkops_status(struct ufs_hba *hba, u32 *status)\r\n{\r\nreturn ufshcd_query_attr(hba, UPIU_QUERY_OPCODE_READ_ATTR,\r\nQUERY_ATTR_IDN_BKOPS_STATUS, 0, 0, status);\r\n}\r\nstatic int ufshcd_urgent_bkops(struct ufs_hba *hba)\r\n{\r\nint err;\r\nu32 status = 0;\r\nerr = ufshcd_get_bkops_status(hba, &status);\r\nif (err) {\r\ndev_err(hba->dev, "%s: failed to get BKOPS status %d\n",\r\n__func__, err);\r\ngoto out;\r\n}\r\nstatus = status & 0xF;\r\nif (status >= BKOPS_STATUS_PERF_IMPACT)\r\nerr = ufshcd_enable_auto_bkops(hba);\r\nout:\r\nreturn err;\r\n}\r\nstatic inline int ufshcd_get_ee_status(struct ufs_hba *hba, u32 *status)\r\n{\r\nreturn ufshcd_query_attr(hba, UPIU_QUERY_OPCODE_READ_ATTR,\r\nQUERY_ATTR_IDN_EE_STATUS, 0, 0, status);\r\n}\r\nstatic void ufshcd_exception_event_handler(struct work_struct *work)\r\n{\r\nstruct ufs_hba *hba;\r\nint err;\r\nu32 status = 0;\r\nhba = container_of(work, struct ufs_hba, eeh_work);\r\npm_runtime_get_sync(hba->dev);\r\nerr = ufshcd_get_ee_status(hba, &status);\r\nif (err) {\r\ndev_err(hba->dev, "%s: failed to get exception status %d\n",\r\n__func__, err);\r\ngoto out;\r\n}\r\nstatus &= hba->ee_ctrl_mask;\r\nif (status & MASK_EE_URGENT_BKOPS) {\r\nerr = ufshcd_urgent_bkops(hba);\r\nif (err)\r\ndev_err(hba->dev, "%s: failed to handle urgent bkops %d\n",\r\n__func__, err);\r\n}\r\nout:\r\npm_runtime_put_sync(hba->dev);\r\nreturn;\r\n}\r\nstatic void ufshcd_fatal_err_handler(struct work_struct *work)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = container_of(work, struct ufs_hba, feh_workq);\r\npm_runtime_get_sync(hba->dev);\r\nif (hba->ufshcd_state != UFSHCD_STATE_RESET)\r\nufshcd_do_reset(hba);\r\npm_runtime_put_sync(hba->dev);\r\n}\r\nstatic void ufshcd_err_handler(struct ufs_hba *hba)\r\n{\r\nu32 reg;\r\nif (hba->errors & INT_FATAL_ERRORS)\r\ngoto fatal_eh;\r\nif (hba->errors & UIC_ERROR) {\r\nreg = ufshcd_readl(hba, REG_UIC_ERROR_CODE_DATA_LINK_LAYER);\r\nif (reg & UIC_DATA_LINK_LAYER_ERROR_PA_INIT)\r\ngoto fatal_eh;\r\n}\r\nreturn;\r\nfatal_eh:\r\nhba->ufshcd_state = UFSHCD_STATE_ERROR;\r\nschedule_work(&hba->feh_workq);\r\n}\r\nstatic void ufshcd_tmc_handler(struct ufs_hba *hba)\r\n{\r\nu32 tm_doorbell;\r\ntm_doorbell = ufshcd_readl(hba, REG_UTP_TASK_REQ_DOOR_BELL);\r\nhba->tm_condition = tm_doorbell ^ hba->outstanding_tasks;\r\nwake_up_interruptible(&hba->ufshcd_tm_wait_queue);\r\n}\r\nstatic void ufshcd_sl_intr(struct ufs_hba *hba, u32 intr_status)\r\n{\r\nhba->errors = UFSHCD_ERROR_MASK & intr_status;\r\nif (hba->errors)\r\nufshcd_err_handler(hba);\r\nif (intr_status & UFSHCD_UIC_MASK)\r\nufshcd_uic_cmd_compl(hba, intr_status);\r\nif (intr_status & UTP_TASK_REQ_COMPL)\r\nufshcd_tmc_handler(hba);\r\nif (intr_status & UTP_TRANSFER_REQ_COMPL)\r\nufshcd_transfer_req_compl(hba);\r\n}\r\nstatic irqreturn_t ufshcd_intr(int irq, void *__hba)\r\n{\r\nu32 intr_status;\r\nirqreturn_t retval = IRQ_NONE;\r\nstruct ufs_hba *hba = __hba;\r\nspin_lock(hba->host->host_lock);\r\nintr_status = ufshcd_readl(hba, REG_INTERRUPT_STATUS);\r\nif (intr_status) {\r\nufshcd_writel(hba, intr_status, REG_INTERRUPT_STATUS);\r\nufshcd_sl_intr(hba, intr_status);\r\nretval = IRQ_HANDLED;\r\n}\r\nspin_unlock(hba->host->host_lock);\r\nreturn retval;\r\n}\r\nstatic int\r\nufshcd_issue_tm_cmd(struct ufs_hba *hba,\r\nstruct ufshcd_lrb *lrbp,\r\nu8 tm_function)\r\n{\r\nstruct utp_task_req_desc *task_req_descp;\r\nstruct utp_upiu_task_req *task_req_upiup;\r\nstruct Scsi_Host *host;\r\nunsigned long flags;\r\nint free_slot = 0;\r\nint err;\r\nhost = hba->host;\r\nspin_lock_irqsave(host->host_lock, flags);\r\nfree_slot = ufshcd_get_tm_free_slot(hba);\r\nif (free_slot >= hba->nutmrs) {\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\ndev_err(hba->dev, "Task management queue full\n");\r\nerr = FAILED;\r\ngoto out;\r\n}\r\ntask_req_descp = hba->utmrdl_base_addr;\r\ntask_req_descp += free_slot;\r\ntask_req_descp->header.dword_0 = cpu_to_le32(UTP_REQ_DESC_INT_CMD);\r\ntask_req_descp->header.dword_2 =\r\ncpu_to_le32(OCS_INVALID_COMMAND_STATUS);\r\ntask_req_upiup =\r\n(struct utp_upiu_task_req *) task_req_descp->task_req_upiu;\r\ntask_req_upiup->header.dword_0 =\r\nUPIU_HEADER_DWORD(UPIU_TRANSACTION_TASK_REQ, 0,\r\nlrbp->lun, lrbp->task_tag);\r\ntask_req_upiup->header.dword_1 =\r\nUPIU_HEADER_DWORD(0, tm_function, 0, 0);\r\ntask_req_upiup->input_param1 = lrbp->lun;\r\ntask_req_upiup->input_param1 =\r\ncpu_to_be32(task_req_upiup->input_param1);\r\ntask_req_upiup->input_param2 = lrbp->task_tag;\r\ntask_req_upiup->input_param2 =\r\ncpu_to_be32(task_req_upiup->input_param2);\r\n__set_bit(free_slot, &hba->outstanding_tasks);\r\nufshcd_writel(hba, 1 << free_slot, REG_UTP_TASK_REQ_DOOR_BELL);\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nerr =\r\nwait_event_interruptible_timeout(hba->ufshcd_tm_wait_queue,\r\n(test_bit(free_slot,\r\n&hba->tm_condition) != 0),\r\n60 * HZ);\r\nif (!err) {\r\ndev_err(hba->dev,\r\n"Task management command timed-out\n");\r\nerr = FAILED;\r\ngoto out;\r\n}\r\nclear_bit(free_slot, &hba->tm_condition);\r\nerr = ufshcd_task_req_compl(hba, free_slot);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_device_reset(struct scsi_cmnd *cmd)\r\n{\r\nstruct Scsi_Host *host;\r\nstruct ufs_hba *hba;\r\nunsigned int tag;\r\nu32 pos;\r\nint err;\r\nhost = cmd->device->host;\r\nhba = shost_priv(host);\r\ntag = cmd->request->tag;\r\nerr = ufshcd_issue_tm_cmd(hba, &hba->lrb[tag], UFS_LOGICAL_RESET);\r\nif (err == FAILED)\r\ngoto out;\r\nfor (pos = 0; pos < hba->nutrs; pos++) {\r\nif (test_bit(pos, &hba->outstanding_reqs) &&\r\n(hba->lrb[tag].lun == hba->lrb[pos].lun)) {\r\nufshcd_utrl_clear(hba, pos);\r\nclear_bit(pos, &hba->outstanding_reqs);\r\nif (hba->lrb[pos].cmd) {\r\nscsi_dma_unmap(hba->lrb[pos].cmd);\r\nhba->lrb[pos].cmd->result =\r\nDID_ABORT << 16;\r\nhba->lrb[pos].cmd->scsi_done(cmd);\r\nhba->lrb[pos].cmd = NULL;\r\nclear_bit_unlock(pos, &hba->lrb_in_use);\r\nwake_up(&hba->dev_cmd.tag_wq);\r\n}\r\n}\r\n}\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_host_reset(struct scsi_cmnd *cmd)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = shost_priv(cmd->device->host);\r\nif (hba->ufshcd_state == UFSHCD_STATE_RESET)\r\nreturn SUCCESS;\r\nreturn ufshcd_do_reset(hba);\r\n}\r\nstatic int ufshcd_abort(struct scsi_cmnd *cmd)\r\n{\r\nstruct Scsi_Host *host;\r\nstruct ufs_hba *hba;\r\nunsigned long flags;\r\nunsigned int tag;\r\nint err;\r\nhost = cmd->device->host;\r\nhba = shost_priv(host);\r\ntag = cmd->request->tag;\r\nspin_lock_irqsave(host->host_lock, flags);\r\nif (!(test_bit(tag, &hba->outstanding_reqs))) {\r\nerr = FAILED;\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\ngoto out;\r\n}\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nerr = ufshcd_issue_tm_cmd(hba, &hba->lrb[tag], UFS_ABORT_TASK);\r\nif (err == FAILED)\r\ngoto out;\r\nscsi_dma_unmap(cmd);\r\nspin_lock_irqsave(host->host_lock, flags);\r\nufshcd_utrl_clear(hba, tag);\r\n__clear_bit(tag, &hba->outstanding_reqs);\r\nhba->lrb[tag].cmd = NULL;\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nclear_bit_unlock(tag, &hba->lrb_in_use);\r\nwake_up(&hba->dev_cmd.tag_wq);\r\nout:\r\nreturn err;\r\n}\r\nstatic void ufshcd_async_scan(void *data, async_cookie_t cookie)\r\n{\r\nstruct ufs_hba *hba = (struct ufs_hba *)data;\r\nint ret;\r\nret = ufshcd_link_startup(hba);\r\nif (ret)\r\ngoto out;\r\nufshcd_config_max_pwr_mode(hba);\r\nret = ufshcd_verify_dev_init(hba);\r\nif (ret)\r\ngoto out;\r\nret = ufshcd_complete_dev_init(hba);\r\nif (ret)\r\ngoto out;\r\nufshcd_force_reset_auto_bkops(hba);\r\nscsi_scan_host(hba->host);\r\npm_runtime_put_sync(hba->dev);\r\nout:\r\nreturn;\r\n}\r\nint ufshcd_suspend(struct ufs_hba *hba, pm_message_t state)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nint ufshcd_resume(struct ufs_hba *hba)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nint ufshcd_runtime_suspend(struct ufs_hba *hba)\r\n{\r\nif (!hba)\r\nreturn 0;\r\nreturn ufshcd_enable_auto_bkops(hba);\r\n}\r\nint ufshcd_runtime_resume(struct ufs_hba *hba)\r\n{\r\nif (!hba)\r\nreturn 0;\r\nreturn ufshcd_disable_auto_bkops(hba);\r\n}\r\nint ufshcd_runtime_idle(struct ufs_hba *hba)\r\n{\r\nreturn 0;\r\n}\r\nvoid ufshcd_remove(struct ufs_hba *hba)\r\n{\r\nscsi_remove_host(hba->host);\r\nufshcd_disable_intr(hba, hba->intr_mask);\r\nufshcd_hba_stop(hba);\r\nscsi_host_put(hba->host);\r\n}\r\nint ufshcd_init(struct device *dev, struct ufs_hba **hba_handle,\r\nvoid __iomem *mmio_base, unsigned int irq)\r\n{\r\nstruct Scsi_Host *host;\r\nstruct ufs_hba *hba;\r\nint err;\r\nif (!dev) {\r\ndev_err(dev,\r\n"Invalid memory reference for dev is NULL\n");\r\nerr = -ENODEV;\r\ngoto out_error;\r\n}\r\nif (!mmio_base) {\r\ndev_err(dev,\r\n"Invalid memory reference for mmio_base is NULL\n");\r\nerr = -ENODEV;\r\ngoto out_error;\r\n}\r\nhost = scsi_host_alloc(&ufshcd_driver_template,\r\nsizeof(struct ufs_hba));\r\nif (!host) {\r\ndev_err(dev, "scsi_host_alloc failed\n");\r\nerr = -ENOMEM;\r\ngoto out_error;\r\n}\r\nhba = shost_priv(host);\r\nhba->host = host;\r\nhba->dev = dev;\r\nhba->mmio_base = mmio_base;\r\nhba->irq = irq;\r\nufshcd_hba_capabilities(hba);\r\nhba->ufs_version = ufshcd_get_ufs_version(hba);\r\nhba->intr_mask = ufshcd_get_intr_mask(hba);\r\nerr = ufshcd_memory_alloc(hba);\r\nif (err) {\r\ndev_err(hba->dev, "Memory allocation failed\n");\r\ngoto out_disable;\r\n}\r\nufshcd_host_memory_configure(hba);\r\nhost->can_queue = hba->nutrs;\r\nhost->cmd_per_lun = hba->nutrs;\r\nhost->max_id = UFSHCD_MAX_ID;\r\nhost->max_lun = UFSHCD_MAX_LUNS;\r\nhost->max_channel = UFSHCD_MAX_CHANNEL;\r\nhost->unique_id = host->host_no;\r\nhost->max_cmd_len = MAX_CDB_SIZE;\r\ninit_waitqueue_head(&hba->ufshcd_tm_wait_queue);\r\nINIT_WORK(&hba->feh_workq, ufshcd_fatal_err_handler);\r\nINIT_WORK(&hba->eeh_work, ufshcd_exception_event_handler);\r\nmutex_init(&hba->uic_cmd_mutex);\r\nmutex_init(&hba->dev_cmd.lock);\r\ninit_waitqueue_head(&hba->dev_cmd.tag_wq);\r\nerr = devm_request_irq(dev, irq, ufshcd_intr, IRQF_SHARED, UFSHCD, hba);\r\nif (err) {\r\ndev_err(hba->dev, "request irq failed\n");\r\ngoto out_disable;\r\n}\r\nerr = scsi_init_shared_tag_map(host, host->can_queue);\r\nif (err) {\r\ndev_err(hba->dev, "init shared queue failed\n");\r\ngoto out_disable;\r\n}\r\nerr = scsi_add_host(host, hba->dev);\r\nif (err) {\r\ndev_err(hba->dev, "scsi_add_host failed\n");\r\ngoto out_disable;\r\n}\r\nerr = ufshcd_hba_enable(hba);\r\nif (err) {\r\ndev_err(hba->dev, "Host controller enable failed\n");\r\ngoto out_remove_scsi_host;\r\n}\r\n*hba_handle = hba;\r\npm_runtime_get_sync(dev);\r\nasync_schedule(ufshcd_async_scan, hba);\r\nreturn 0;\r\nout_remove_scsi_host:\r\nscsi_remove_host(hba->host);\r\nout_disable:\r\nscsi_host_put(host);\r\nout_error:\r\nreturn err;\r\n}
