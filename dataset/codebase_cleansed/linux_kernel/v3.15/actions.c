static int make_writable(struct sk_buff *skb, int write_len)\r\n{\r\nif (!skb_cloned(skb) || skb_clone_writable(skb, write_len))\r\nreturn 0;\r\nreturn pskb_expand_head(skb, 0, 0, GFP_ATOMIC);\r\n}\r\nstatic int __pop_vlan_tci(struct sk_buff *skb, __be16 *current_tci)\r\n{\r\nstruct vlan_hdr *vhdr;\r\nint err;\r\nerr = make_writable(skb, VLAN_ETH_HLEN);\r\nif (unlikely(err))\r\nreturn err;\r\nif (skb->ip_summed == CHECKSUM_COMPLETE)\r\nskb->csum = csum_sub(skb->csum, csum_partial(skb->data\r\n+ (2 * ETH_ALEN), VLAN_HLEN, 0));\r\nvhdr = (struct vlan_hdr *)(skb->data + ETH_HLEN);\r\n*current_tci = vhdr->h_vlan_TCI;\r\nmemmove(skb->data + VLAN_HLEN, skb->data, 2 * ETH_ALEN);\r\n__skb_pull(skb, VLAN_HLEN);\r\nvlan_set_encap_proto(skb, vhdr);\r\nskb->mac_header += VLAN_HLEN;\r\nskb_reset_mac_len(skb);\r\nreturn 0;\r\n}\r\nstatic int pop_vlan(struct sk_buff *skb)\r\n{\r\n__be16 tci;\r\nint err;\r\nif (likely(vlan_tx_tag_present(skb))) {\r\nskb->vlan_tci = 0;\r\n} else {\r\nif (unlikely(skb->protocol != htons(ETH_P_8021Q) ||\r\nskb->len < VLAN_ETH_HLEN))\r\nreturn 0;\r\nerr = __pop_vlan_tci(skb, &tci);\r\nif (err)\r\nreturn err;\r\n}\r\nif (likely(skb->protocol != htons(ETH_P_8021Q) ||\r\nskb->len < VLAN_ETH_HLEN))\r\nreturn 0;\r\nerr = __pop_vlan_tci(skb, &tci);\r\nif (unlikely(err))\r\nreturn err;\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), ntohs(tci));\r\nreturn 0;\r\n}\r\nstatic int push_vlan(struct sk_buff *skb, const struct ovs_action_push_vlan *vlan)\r\n{\r\nif (unlikely(vlan_tx_tag_present(skb))) {\r\nu16 current_tag;\r\ncurrent_tag = vlan_tx_tag_get(skb);\r\nif (!__vlan_put_tag(skb, skb->vlan_proto, current_tag))\r\nreturn -ENOMEM;\r\nif (skb->ip_summed == CHECKSUM_COMPLETE)\r\nskb->csum = csum_add(skb->csum, csum_partial(skb->data\r\n+ (2 * ETH_ALEN), VLAN_HLEN, 0));\r\n}\r\n__vlan_hwaccel_put_tag(skb, vlan->vlan_tpid, ntohs(vlan->vlan_tci) & ~VLAN_TAG_PRESENT);\r\nreturn 0;\r\n}\r\nstatic int set_eth_addr(struct sk_buff *skb,\r\nconst struct ovs_key_ethernet *eth_key)\r\n{\r\nint err;\r\nerr = make_writable(skb, ETH_HLEN);\r\nif (unlikely(err))\r\nreturn err;\r\nskb_postpull_rcsum(skb, eth_hdr(skb), ETH_ALEN * 2);\r\nmemcpy(eth_hdr(skb)->h_source, eth_key->eth_src, ETH_ALEN);\r\nmemcpy(eth_hdr(skb)->h_dest, eth_key->eth_dst, ETH_ALEN);\r\novs_skb_postpush_rcsum(skb, eth_hdr(skb), ETH_ALEN * 2);\r\nreturn 0;\r\n}\r\nstatic void set_ip_addr(struct sk_buff *skb, struct iphdr *nh,\r\n__be32 *addr, __be32 new_addr)\r\n{\r\nint transport_len = skb->len - skb_transport_offset(skb);\r\nif (nh->protocol == IPPROTO_TCP) {\r\nif (likely(transport_len >= sizeof(struct tcphdr)))\r\ninet_proto_csum_replace4(&tcp_hdr(skb)->check, skb,\r\n*addr, new_addr, 1);\r\n} else if (nh->protocol == IPPROTO_UDP) {\r\nif (likely(transport_len >= sizeof(struct udphdr))) {\r\nstruct udphdr *uh = udp_hdr(skb);\r\nif (uh->check || skb->ip_summed == CHECKSUM_PARTIAL) {\r\ninet_proto_csum_replace4(&uh->check, skb,\r\n*addr, new_addr, 1);\r\nif (!uh->check)\r\nuh->check = CSUM_MANGLED_0;\r\n}\r\n}\r\n}\r\ncsum_replace4(&nh->check, *addr, new_addr);\r\nskb_clear_hash(skb);\r\n*addr = new_addr;\r\n}\r\nstatic void update_ipv6_checksum(struct sk_buff *skb, u8 l4_proto,\r\n__be32 addr[4], const __be32 new_addr[4])\r\n{\r\nint transport_len = skb->len - skb_transport_offset(skb);\r\nif (l4_proto == IPPROTO_TCP) {\r\nif (likely(transport_len >= sizeof(struct tcphdr)))\r\ninet_proto_csum_replace16(&tcp_hdr(skb)->check, skb,\r\naddr, new_addr, 1);\r\n} else if (l4_proto == IPPROTO_UDP) {\r\nif (likely(transport_len >= sizeof(struct udphdr))) {\r\nstruct udphdr *uh = udp_hdr(skb);\r\nif (uh->check || skb->ip_summed == CHECKSUM_PARTIAL) {\r\ninet_proto_csum_replace16(&uh->check, skb,\r\naddr, new_addr, 1);\r\nif (!uh->check)\r\nuh->check = CSUM_MANGLED_0;\r\n}\r\n}\r\n}\r\n}\r\nstatic void set_ipv6_addr(struct sk_buff *skb, u8 l4_proto,\r\n__be32 addr[4], const __be32 new_addr[4],\r\nbool recalculate_csum)\r\n{\r\nif (recalculate_csum)\r\nupdate_ipv6_checksum(skb, l4_proto, addr, new_addr);\r\nskb_clear_hash(skb);\r\nmemcpy(addr, new_addr, sizeof(__be32[4]));\r\n}\r\nstatic void set_ipv6_tc(struct ipv6hdr *nh, u8 tc)\r\n{\r\nnh->priority = tc >> 4;\r\nnh->flow_lbl[0] = (nh->flow_lbl[0] & 0x0F) | ((tc & 0x0F) << 4);\r\n}\r\nstatic void set_ipv6_fl(struct ipv6hdr *nh, u32 fl)\r\n{\r\nnh->flow_lbl[0] = (nh->flow_lbl[0] & 0xF0) | (fl & 0x000F0000) >> 16;\r\nnh->flow_lbl[1] = (fl & 0x0000FF00) >> 8;\r\nnh->flow_lbl[2] = fl & 0x000000FF;\r\n}\r\nstatic void set_ip_ttl(struct sk_buff *skb, struct iphdr *nh, u8 new_ttl)\r\n{\r\ncsum_replace2(&nh->check, htons(nh->ttl << 8), htons(new_ttl << 8));\r\nnh->ttl = new_ttl;\r\n}\r\nstatic int set_ipv4(struct sk_buff *skb, const struct ovs_key_ipv4 *ipv4_key)\r\n{\r\nstruct iphdr *nh;\r\nint err;\r\nerr = make_writable(skb, skb_network_offset(skb) +\r\nsizeof(struct iphdr));\r\nif (unlikely(err))\r\nreturn err;\r\nnh = ip_hdr(skb);\r\nif (ipv4_key->ipv4_src != nh->saddr)\r\nset_ip_addr(skb, nh, &nh->saddr, ipv4_key->ipv4_src);\r\nif (ipv4_key->ipv4_dst != nh->daddr)\r\nset_ip_addr(skb, nh, &nh->daddr, ipv4_key->ipv4_dst);\r\nif (ipv4_key->ipv4_tos != nh->tos)\r\nipv4_change_dsfield(nh, 0, ipv4_key->ipv4_tos);\r\nif (ipv4_key->ipv4_ttl != nh->ttl)\r\nset_ip_ttl(skb, nh, ipv4_key->ipv4_ttl);\r\nreturn 0;\r\n}\r\nstatic int set_ipv6(struct sk_buff *skb, const struct ovs_key_ipv6 *ipv6_key)\r\n{\r\nstruct ipv6hdr *nh;\r\nint err;\r\n__be32 *saddr;\r\n__be32 *daddr;\r\nerr = make_writable(skb, skb_network_offset(skb) +\r\nsizeof(struct ipv6hdr));\r\nif (unlikely(err))\r\nreturn err;\r\nnh = ipv6_hdr(skb);\r\nsaddr = (__be32 *)&nh->saddr;\r\ndaddr = (__be32 *)&nh->daddr;\r\nif (memcmp(ipv6_key->ipv6_src, saddr, sizeof(ipv6_key->ipv6_src)))\r\nset_ipv6_addr(skb, ipv6_key->ipv6_proto, saddr,\r\nipv6_key->ipv6_src, true);\r\nif (memcmp(ipv6_key->ipv6_dst, daddr, sizeof(ipv6_key->ipv6_dst))) {\r\nunsigned int offset = 0;\r\nint flags = IP6_FH_F_SKIP_RH;\r\nbool recalc_csum = true;\r\nif (ipv6_ext_hdr(nh->nexthdr))\r\nrecalc_csum = ipv6_find_hdr(skb, &offset,\r\nNEXTHDR_ROUTING, NULL,\r\n&flags) != NEXTHDR_ROUTING;\r\nset_ipv6_addr(skb, ipv6_key->ipv6_proto, daddr,\r\nipv6_key->ipv6_dst, recalc_csum);\r\n}\r\nset_ipv6_tc(nh, ipv6_key->ipv6_tclass);\r\nset_ipv6_fl(nh, ntohl(ipv6_key->ipv6_label));\r\nnh->hop_limit = ipv6_key->ipv6_hlimit;\r\nreturn 0;\r\n}\r\nstatic void set_tp_port(struct sk_buff *skb, __be16 *port,\r\n__be16 new_port, __sum16 *check)\r\n{\r\ninet_proto_csum_replace2(check, skb, *port, new_port, 0);\r\n*port = new_port;\r\nskb_clear_hash(skb);\r\n}\r\nstatic void set_udp_port(struct sk_buff *skb, __be16 *port, __be16 new_port)\r\n{\r\nstruct udphdr *uh = udp_hdr(skb);\r\nif (uh->check && skb->ip_summed != CHECKSUM_PARTIAL) {\r\nset_tp_port(skb, port, new_port, &uh->check);\r\nif (!uh->check)\r\nuh->check = CSUM_MANGLED_0;\r\n} else {\r\n*port = new_port;\r\nskb_clear_hash(skb);\r\n}\r\n}\r\nstatic int set_udp(struct sk_buff *skb, const struct ovs_key_udp *udp_port_key)\r\n{\r\nstruct udphdr *uh;\r\nint err;\r\nerr = make_writable(skb, skb_transport_offset(skb) +\r\nsizeof(struct udphdr));\r\nif (unlikely(err))\r\nreturn err;\r\nuh = udp_hdr(skb);\r\nif (udp_port_key->udp_src != uh->source)\r\nset_udp_port(skb, &uh->source, udp_port_key->udp_src);\r\nif (udp_port_key->udp_dst != uh->dest)\r\nset_udp_port(skb, &uh->dest, udp_port_key->udp_dst);\r\nreturn 0;\r\n}\r\nstatic int set_tcp(struct sk_buff *skb, const struct ovs_key_tcp *tcp_port_key)\r\n{\r\nstruct tcphdr *th;\r\nint err;\r\nerr = make_writable(skb, skb_transport_offset(skb) +\r\nsizeof(struct tcphdr));\r\nif (unlikely(err))\r\nreturn err;\r\nth = tcp_hdr(skb);\r\nif (tcp_port_key->tcp_src != th->source)\r\nset_tp_port(skb, &th->source, tcp_port_key->tcp_src, &th->check);\r\nif (tcp_port_key->tcp_dst != th->dest)\r\nset_tp_port(skb, &th->dest, tcp_port_key->tcp_dst, &th->check);\r\nreturn 0;\r\n}\r\nstatic int set_sctp(struct sk_buff *skb,\r\nconst struct ovs_key_sctp *sctp_port_key)\r\n{\r\nstruct sctphdr *sh;\r\nint err;\r\nunsigned int sctphoff = skb_transport_offset(skb);\r\nerr = make_writable(skb, sctphoff + sizeof(struct sctphdr));\r\nif (unlikely(err))\r\nreturn err;\r\nsh = sctp_hdr(skb);\r\nif (sctp_port_key->sctp_src != sh->source ||\r\nsctp_port_key->sctp_dst != sh->dest) {\r\n__le32 old_correct_csum, new_csum, old_csum;\r\nold_csum = sh->checksum;\r\nold_correct_csum = sctp_compute_cksum(skb, sctphoff);\r\nsh->source = sctp_port_key->sctp_src;\r\nsh->dest = sctp_port_key->sctp_dst;\r\nnew_csum = sctp_compute_cksum(skb, sctphoff);\r\nsh->checksum = old_csum ^ old_correct_csum ^ new_csum;\r\nskb_clear_hash(skb);\r\n}\r\nreturn 0;\r\n}\r\nstatic int do_output(struct datapath *dp, struct sk_buff *skb, int out_port)\r\n{\r\nstruct vport *vport;\r\nif (unlikely(!skb))\r\nreturn -ENOMEM;\r\nvport = ovs_vport_rcu(dp, out_port);\r\nif (unlikely(!vport)) {\r\nkfree_skb(skb);\r\nreturn -ENODEV;\r\n}\r\novs_vport_send(vport, skb);\r\nreturn 0;\r\n}\r\nstatic int output_userspace(struct datapath *dp, struct sk_buff *skb,\r\nconst struct nlattr *attr)\r\n{\r\nstruct dp_upcall_info upcall;\r\nconst struct nlattr *a;\r\nint rem;\r\nBUG_ON(!OVS_CB(skb)->pkt_key);\r\nupcall.cmd = OVS_PACKET_CMD_ACTION;\r\nupcall.key = OVS_CB(skb)->pkt_key;\r\nupcall.userdata = NULL;\r\nupcall.portid = 0;\r\nfor (a = nla_data(attr), rem = nla_len(attr); rem > 0;\r\na = nla_next(a, &rem)) {\r\nswitch (nla_type(a)) {\r\ncase OVS_USERSPACE_ATTR_USERDATA:\r\nupcall.userdata = a;\r\nbreak;\r\ncase OVS_USERSPACE_ATTR_PID:\r\nupcall.portid = nla_get_u32(a);\r\nbreak;\r\n}\r\n}\r\nreturn ovs_dp_upcall(dp, skb, &upcall);\r\n}\r\nstatic int sample(struct datapath *dp, struct sk_buff *skb,\r\nconst struct nlattr *attr)\r\n{\r\nconst struct nlattr *acts_list = NULL;\r\nconst struct nlattr *a;\r\nint rem;\r\nfor (a = nla_data(attr), rem = nla_len(attr); rem > 0;\r\na = nla_next(a, &rem)) {\r\nswitch (nla_type(a)) {\r\ncase OVS_SAMPLE_ATTR_PROBABILITY:\r\nif (prandom_u32() >= nla_get_u32(a))\r\nreturn 0;\r\nbreak;\r\ncase OVS_SAMPLE_ATTR_ACTIONS:\r\nacts_list = a;\r\nbreak;\r\n}\r\n}\r\nreturn do_execute_actions(dp, skb, nla_data(acts_list),\r\nnla_len(acts_list), true);\r\n}\r\nstatic int execute_set_action(struct sk_buff *skb,\r\nconst struct nlattr *nested_attr)\r\n{\r\nint err = 0;\r\nswitch (nla_type(nested_attr)) {\r\ncase OVS_KEY_ATTR_PRIORITY:\r\nskb->priority = nla_get_u32(nested_attr);\r\nbreak;\r\ncase OVS_KEY_ATTR_SKB_MARK:\r\nskb->mark = nla_get_u32(nested_attr);\r\nbreak;\r\ncase OVS_KEY_ATTR_IPV4_TUNNEL:\r\nOVS_CB(skb)->tun_key = nla_data(nested_attr);\r\nbreak;\r\ncase OVS_KEY_ATTR_ETHERNET:\r\nerr = set_eth_addr(skb, nla_data(nested_attr));\r\nbreak;\r\ncase OVS_KEY_ATTR_IPV4:\r\nerr = set_ipv4(skb, nla_data(nested_attr));\r\nbreak;\r\ncase OVS_KEY_ATTR_IPV6:\r\nerr = set_ipv6(skb, nla_data(nested_attr));\r\nbreak;\r\ncase OVS_KEY_ATTR_TCP:\r\nerr = set_tcp(skb, nla_data(nested_attr));\r\nbreak;\r\ncase OVS_KEY_ATTR_UDP:\r\nerr = set_udp(skb, nla_data(nested_attr));\r\nbreak;\r\ncase OVS_KEY_ATTR_SCTP:\r\nerr = set_sctp(skb, nla_data(nested_attr));\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic int do_execute_actions(struct datapath *dp, struct sk_buff *skb,\r\nconst struct nlattr *attr, int len, bool keep_skb)\r\n{\r\nint prev_port = -1;\r\nconst struct nlattr *a;\r\nint rem;\r\nfor (a = attr, rem = len; rem > 0;\r\na = nla_next(a, &rem)) {\r\nint err = 0;\r\nif (prev_port != -1) {\r\ndo_output(dp, skb_clone(skb, GFP_ATOMIC), prev_port);\r\nprev_port = -1;\r\n}\r\nswitch (nla_type(a)) {\r\ncase OVS_ACTION_ATTR_OUTPUT:\r\nprev_port = nla_get_u32(a);\r\nbreak;\r\ncase OVS_ACTION_ATTR_USERSPACE:\r\noutput_userspace(dp, skb, a);\r\nbreak;\r\ncase OVS_ACTION_ATTR_PUSH_VLAN:\r\nerr = push_vlan(skb, nla_data(a));\r\nif (unlikely(err))\r\nreturn err;\r\nbreak;\r\ncase OVS_ACTION_ATTR_POP_VLAN:\r\nerr = pop_vlan(skb);\r\nbreak;\r\ncase OVS_ACTION_ATTR_SET:\r\nerr = execute_set_action(skb, nla_data(a));\r\nbreak;\r\ncase OVS_ACTION_ATTR_SAMPLE:\r\nerr = sample(dp, skb, a);\r\nbreak;\r\n}\r\nif (unlikely(err)) {\r\nkfree_skb(skb);\r\nreturn err;\r\n}\r\n}\r\nif (prev_port != -1) {\r\nif (keep_skb)\r\nskb = skb_clone(skb, GFP_ATOMIC);\r\ndo_output(dp, skb, prev_port);\r\n} else if (!keep_skb)\r\nconsume_skb(skb);\r\nreturn 0;\r\n}\r\nint ovs_execute_actions(struct datapath *dp, struct sk_buff *skb)\r\n{\r\nstruct sw_flow_actions *acts = rcu_dereference(OVS_CB(skb)->flow->sf_acts);\r\nOVS_CB(skb)->tun_key = NULL;\r\nreturn do_execute_actions(dp, skb, acts->actions,\r\nacts->actions_len, false);\r\n}
