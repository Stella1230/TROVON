static int nothing_to_commit(struct ubifs_info *c)\r\n{\r\nif (c->mounting || c->remounting_rw)\r\nreturn 0;\r\nif (c->zroot.znode && ubifs_zn_dirty(c->zroot.znode))\r\nreturn 0;\r\nif (c->nroot && test_bit(DIRTY_CNODE, &c->nroot->flags))\r\nreturn 0;\r\nubifs_assert(atomic_long_read(&c->dirty_zn_cnt) == 0);\r\nubifs_assert(c->dirty_pn_cnt == 0);\r\nubifs_assert(c->dirty_nn_cnt == 0);\r\nreturn 1;\r\n}\r\nstatic int do_commit(struct ubifs_info *c)\r\n{\r\nint err, new_ltail_lnum, old_ltail_lnum, i;\r\nstruct ubifs_zbranch zroot;\r\nstruct ubifs_lp_stats lst;\r\ndbg_cmt("start");\r\nubifs_assert(!c->ro_media && !c->ro_mount);\r\nif (c->ro_error) {\r\nerr = -EROFS;\r\ngoto out_up;\r\n}\r\nif (nothing_to_commit(c)) {\r\nup_write(&c->commit_sem);\r\nerr = 0;\r\ngoto out_cancel;\r\n}\r\nfor (i = 0; i < c->jhead_cnt; i++) {\r\nerr = ubifs_wbuf_sync(&c->jheads[i].wbuf);\r\nif (err)\r\ngoto out_up;\r\n}\r\nc->cmt_no += 1;\r\nerr = ubifs_gc_start_commit(c);\r\nif (err)\r\ngoto out_up;\r\nerr = dbg_check_lprops(c);\r\nif (err)\r\ngoto out_up;\r\nerr = ubifs_log_start_commit(c, &new_ltail_lnum);\r\nif (err)\r\ngoto out_up;\r\nerr = ubifs_tnc_start_commit(c, &zroot);\r\nif (err)\r\ngoto out_up;\r\nerr = ubifs_lpt_start_commit(c);\r\nif (err)\r\ngoto out_up;\r\nerr = ubifs_orphan_start_commit(c);\r\nif (err)\r\ngoto out_up;\r\nubifs_get_lp_stats(c, &lst);\r\nup_write(&c->commit_sem);\r\nerr = ubifs_tnc_end_commit(c);\r\nif (err)\r\ngoto out;\r\nerr = ubifs_lpt_end_commit(c);\r\nif (err)\r\ngoto out;\r\nerr = ubifs_orphan_end_commit(c);\r\nif (err)\r\ngoto out;\r\nold_ltail_lnum = c->ltail_lnum;\r\nerr = ubifs_log_end_commit(c, new_ltail_lnum);\r\nif (err)\r\ngoto out;\r\nerr = dbg_check_old_index(c, &zroot);\r\nif (err)\r\ngoto out;\r\nmutex_lock(&c->mst_mutex);\r\nc->mst_node->cmt_no = cpu_to_le64(c->cmt_no);\r\nc->mst_node->log_lnum = cpu_to_le32(new_ltail_lnum);\r\nc->mst_node->root_lnum = cpu_to_le32(zroot.lnum);\r\nc->mst_node->root_offs = cpu_to_le32(zroot.offs);\r\nc->mst_node->root_len = cpu_to_le32(zroot.len);\r\nc->mst_node->ihead_lnum = cpu_to_le32(c->ihead_lnum);\r\nc->mst_node->ihead_offs = cpu_to_le32(c->ihead_offs);\r\nc->mst_node->index_size = cpu_to_le64(c->bi.old_idx_sz);\r\nc->mst_node->lpt_lnum = cpu_to_le32(c->lpt_lnum);\r\nc->mst_node->lpt_offs = cpu_to_le32(c->lpt_offs);\r\nc->mst_node->nhead_lnum = cpu_to_le32(c->nhead_lnum);\r\nc->mst_node->nhead_offs = cpu_to_le32(c->nhead_offs);\r\nc->mst_node->ltab_lnum = cpu_to_le32(c->ltab_lnum);\r\nc->mst_node->ltab_offs = cpu_to_le32(c->ltab_offs);\r\nc->mst_node->lsave_lnum = cpu_to_le32(c->lsave_lnum);\r\nc->mst_node->lsave_offs = cpu_to_le32(c->lsave_offs);\r\nc->mst_node->lscan_lnum = cpu_to_le32(c->lscan_lnum);\r\nc->mst_node->empty_lebs = cpu_to_le32(lst.empty_lebs);\r\nc->mst_node->idx_lebs = cpu_to_le32(lst.idx_lebs);\r\nc->mst_node->total_free = cpu_to_le64(lst.total_free);\r\nc->mst_node->total_dirty = cpu_to_le64(lst.total_dirty);\r\nc->mst_node->total_used = cpu_to_le64(lst.total_used);\r\nc->mst_node->total_dead = cpu_to_le64(lst.total_dead);\r\nc->mst_node->total_dark = cpu_to_le64(lst.total_dark);\r\nif (c->no_orphs)\r\nc->mst_node->flags |= cpu_to_le32(UBIFS_MST_NO_ORPHS);\r\nelse\r\nc->mst_node->flags &= ~cpu_to_le32(UBIFS_MST_NO_ORPHS);\r\nerr = ubifs_write_master(c);\r\nmutex_unlock(&c->mst_mutex);\r\nif (err)\r\ngoto out;\r\nerr = ubifs_log_post_commit(c, old_ltail_lnum);\r\nif (err)\r\ngoto out;\r\nerr = ubifs_gc_end_commit(c);\r\nif (err)\r\ngoto out;\r\nerr = ubifs_lpt_post_commit(c);\r\nif (err)\r\ngoto out;\r\nout_cancel:\r\nspin_lock(&c->cs_lock);\r\nc->cmt_state = COMMIT_RESTING;\r\nwake_up(&c->cmt_wq);\r\ndbg_cmt("commit end");\r\nspin_unlock(&c->cs_lock);\r\nreturn 0;\r\nout_up:\r\nup_write(&c->commit_sem);\r\nout:\r\nubifs_err("commit failed, error %d", err);\r\nspin_lock(&c->cs_lock);\r\nc->cmt_state = COMMIT_BROKEN;\r\nwake_up(&c->cmt_wq);\r\nspin_unlock(&c->cs_lock);\r\nubifs_ro_mode(c, err);\r\nreturn err;\r\n}\r\nstatic int run_bg_commit(struct ubifs_info *c)\r\n{\r\nspin_lock(&c->cs_lock);\r\nif (c->cmt_state != COMMIT_BACKGROUND &&\r\nc->cmt_state != COMMIT_REQUIRED)\r\ngoto out;\r\nspin_unlock(&c->cs_lock);\r\ndown_write(&c->commit_sem);\r\nspin_lock(&c->cs_lock);\r\nif (c->cmt_state == COMMIT_REQUIRED)\r\nc->cmt_state = COMMIT_RUNNING_REQUIRED;\r\nelse if (c->cmt_state == COMMIT_BACKGROUND)\r\nc->cmt_state = COMMIT_RUNNING_BACKGROUND;\r\nelse\r\ngoto out_cmt_unlock;\r\nspin_unlock(&c->cs_lock);\r\nreturn do_commit(c);\r\nout_cmt_unlock:\r\nup_write(&c->commit_sem);\r\nout:\r\nspin_unlock(&c->cs_lock);\r\nreturn 0;\r\n}\r\nint ubifs_bg_thread(void *info)\r\n{\r\nint err;\r\nstruct ubifs_info *c = info;\r\nubifs_msg("background thread \"%s\" started, PID %d",\r\nc->bgt_name, current->pid);\r\nset_freezable();\r\nwhile (1) {\r\nif (kthread_should_stop())\r\nbreak;\r\nif (try_to_freeze())\r\ncontinue;\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nif (!c->need_bgt) {\r\nif (kthread_should_stop())\r\nbreak;\r\nschedule();\r\ncontinue;\r\n} else\r\n__set_current_state(TASK_RUNNING);\r\nc->need_bgt = 0;\r\nerr = ubifs_bg_wbufs_sync(c);\r\nif (err)\r\nubifs_ro_mode(c, err);\r\nrun_bg_commit(c);\r\ncond_resched();\r\n}\r\nubifs_msg("background thread \"%s\" stops", c->bgt_name);\r\nreturn 0;\r\n}\r\nvoid ubifs_commit_required(struct ubifs_info *c)\r\n{\r\nspin_lock(&c->cs_lock);\r\nswitch (c->cmt_state) {\r\ncase COMMIT_RESTING:\r\ncase COMMIT_BACKGROUND:\r\ndbg_cmt("old: %s, new: %s", dbg_cstate(c->cmt_state),\r\ndbg_cstate(COMMIT_REQUIRED));\r\nc->cmt_state = COMMIT_REQUIRED;\r\nbreak;\r\ncase COMMIT_RUNNING_BACKGROUND:\r\ndbg_cmt("old: %s, new: %s", dbg_cstate(c->cmt_state),\r\ndbg_cstate(COMMIT_RUNNING_REQUIRED));\r\nc->cmt_state = COMMIT_RUNNING_REQUIRED;\r\nbreak;\r\ncase COMMIT_REQUIRED:\r\ncase COMMIT_RUNNING_REQUIRED:\r\ncase COMMIT_BROKEN:\r\nbreak;\r\n}\r\nspin_unlock(&c->cs_lock);\r\n}\r\nvoid ubifs_request_bg_commit(struct ubifs_info *c)\r\n{\r\nspin_lock(&c->cs_lock);\r\nif (c->cmt_state == COMMIT_RESTING) {\r\ndbg_cmt("old: %s, new: %s", dbg_cstate(c->cmt_state),\r\ndbg_cstate(COMMIT_BACKGROUND));\r\nc->cmt_state = COMMIT_BACKGROUND;\r\nspin_unlock(&c->cs_lock);\r\nubifs_wake_up_bgt(c);\r\n} else\r\nspin_unlock(&c->cs_lock);\r\n}\r\nstatic int wait_for_commit(struct ubifs_info *c)\r\n{\r\ndbg_cmt("pid %d goes sleep", current->pid);\r\nwait_event(c->cmt_wq, c->cmt_state != COMMIT_RUNNING_BACKGROUND &&\r\nc->cmt_state != COMMIT_RUNNING_REQUIRED);\r\ndbg_cmt("commit finished, pid %d woke up", current->pid);\r\nreturn 0;\r\n}\r\nint ubifs_run_commit(struct ubifs_info *c)\r\n{\r\nint err = 0;\r\nspin_lock(&c->cs_lock);\r\nif (c->cmt_state == COMMIT_BROKEN) {\r\nerr = -EROFS;\r\ngoto out;\r\n}\r\nif (c->cmt_state == COMMIT_RUNNING_BACKGROUND)\r\nc->cmt_state = COMMIT_RUNNING_REQUIRED;\r\nif (c->cmt_state == COMMIT_RUNNING_REQUIRED) {\r\nspin_unlock(&c->cs_lock);\r\nreturn wait_for_commit(c);\r\n}\r\nspin_unlock(&c->cs_lock);\r\ndown_write(&c->commit_sem);\r\nspin_lock(&c->cs_lock);\r\nif (c->cmt_state == COMMIT_BROKEN) {\r\nerr = -EROFS;\r\ngoto out_cmt_unlock;\r\n}\r\nif (c->cmt_state == COMMIT_RUNNING_BACKGROUND)\r\nc->cmt_state = COMMIT_RUNNING_REQUIRED;\r\nif (c->cmt_state == COMMIT_RUNNING_REQUIRED) {\r\nup_write(&c->commit_sem);\r\nspin_unlock(&c->cs_lock);\r\nreturn wait_for_commit(c);\r\n}\r\nc->cmt_state = COMMIT_RUNNING_REQUIRED;\r\nspin_unlock(&c->cs_lock);\r\nerr = do_commit(c);\r\nreturn err;\r\nout_cmt_unlock:\r\nup_write(&c->commit_sem);\r\nout:\r\nspin_unlock(&c->cs_lock);\r\nreturn err;\r\n}\r\nint ubifs_gc_should_commit(struct ubifs_info *c)\r\n{\r\nint ret = 0;\r\nspin_lock(&c->cs_lock);\r\nif (c->cmt_state == COMMIT_BACKGROUND) {\r\ndbg_cmt("commit required now");\r\nc->cmt_state = COMMIT_REQUIRED;\r\n} else\r\ndbg_cmt("commit not requested");\r\nif (c->cmt_state == COMMIT_REQUIRED)\r\nret = 1;\r\nspin_unlock(&c->cs_lock);\r\nreturn ret;\r\n}\r\nint dbg_old_index_check_init(struct ubifs_info *c, struct ubifs_zbranch *zroot)\r\n{\r\nstruct ubifs_idx_node *idx;\r\nint lnum, offs, len, err = 0;\r\nstruct ubifs_debug_info *d = c->dbg;\r\nd->old_zroot = *zroot;\r\nlnum = d->old_zroot.lnum;\r\noffs = d->old_zroot.offs;\r\nlen = d->old_zroot.len;\r\nidx = kmalloc(c->max_idx_node_sz, GFP_NOFS);\r\nif (!idx)\r\nreturn -ENOMEM;\r\nerr = ubifs_read_node(c, idx, UBIFS_IDX_NODE, len, lnum, offs);\r\nif (err)\r\ngoto out;\r\nd->old_zroot_level = le16_to_cpu(idx->level);\r\nd->old_zroot_sqnum = le64_to_cpu(idx->ch.sqnum);\r\nout:\r\nkfree(idx);\r\nreturn err;\r\n}\r\nint dbg_check_old_index(struct ubifs_info *c, struct ubifs_zbranch *zroot)\r\n{\r\nint lnum, offs, len, err = 0, uninitialized_var(last_level), child_cnt;\r\nint first = 1, iip;\r\nstruct ubifs_debug_info *d = c->dbg;\r\nunion ubifs_key uninitialized_var(lower_key), upper_key, l_key, u_key;\r\nunsigned long long uninitialized_var(last_sqnum);\r\nstruct ubifs_idx_node *idx;\r\nstruct list_head list;\r\nstruct idx_node *i;\r\nsize_t sz;\r\nif (!dbg_is_chk_index(c))\r\nreturn 0;\r\nINIT_LIST_HEAD(&list);\r\nsz = sizeof(struct idx_node) + ubifs_idx_node_sz(c, c->fanout) -\r\nUBIFS_IDX_NODE_SZ;\r\nlnum = d->old_zroot.lnum;\r\noffs = d->old_zroot.offs;\r\nlen = d->old_zroot.len;\r\niip = 0;\r\nwhile (1) {\r\nstruct ubifs_branch *br;\r\ni = kmalloc(sz, GFP_NOFS);\r\nif (!i) {\r\nerr = -ENOMEM;\r\ngoto out_free;\r\n}\r\ni->iip = iip;\r\nlist_add_tail(&i->list, &list);\r\nidx = &i->idx;\r\nerr = ubifs_read_node(c, idx, UBIFS_IDX_NODE, len, lnum, offs);\r\nif (err)\r\ngoto out_free;\r\nchild_cnt = le16_to_cpu(idx->child_cnt);\r\nif (child_cnt < 1 || child_cnt > c->fanout) {\r\nerr = 1;\r\ngoto out_dump;\r\n}\r\nif (first) {\r\nfirst = 0;\r\nif (le16_to_cpu(idx->level) != d->old_zroot_level) {\r\nerr = 2;\r\ngoto out_dump;\r\n}\r\nif (le64_to_cpu(idx->ch.sqnum) != d->old_zroot_sqnum) {\r\nerr = 3;\r\ngoto out_dump;\r\n}\r\nlast_level = le16_to_cpu(idx->level) + 1;\r\nlast_sqnum = le64_to_cpu(idx->ch.sqnum) + 1;\r\nkey_read(c, ubifs_idx_key(c, idx), &lower_key);\r\nhighest_ino_key(c, &upper_key, INUM_WATERMARK);\r\n}\r\nkey_copy(c, &upper_key, &i->upper_key);\r\nif (le16_to_cpu(idx->level) != last_level - 1) {\r\nerr = 3;\r\ngoto out_dump;\r\n}\r\nif (le64_to_cpu(idx->ch.sqnum) >= last_sqnum) {\r\nerr = 4;\r\ngoto out_dump;\r\n}\r\nkey_read(c, ubifs_idx_key(c, idx), &l_key);\r\nbr = ubifs_idx_branch(c, idx, child_cnt - 1);\r\nkey_read(c, &br->key, &u_key);\r\nif (keys_cmp(c, &lower_key, &l_key) > 0) {\r\nerr = 5;\r\ngoto out_dump;\r\n}\r\nif (keys_cmp(c, &upper_key, &u_key) < 0) {\r\nerr = 6;\r\ngoto out_dump;\r\n}\r\nif (keys_cmp(c, &upper_key, &u_key) == 0)\r\nif (!is_hash_key(c, &u_key)) {\r\nerr = 7;\r\ngoto out_dump;\r\n}\r\nif (le16_to_cpu(idx->level) == 0) {\r\nwhile (1) {\r\nlist_del(&i->list);\r\nkfree(i);\r\nif (list_empty(&list))\r\ngoto out;\r\ni = list_entry(list.prev, struct idx_node,\r\nlist);\r\nidx = &i->idx;\r\nif (iip + 1 < le16_to_cpu(idx->child_cnt)) {\r\niip = iip + 1;\r\nbreak;\r\n} else\r\niip = i->iip;\r\n}\r\n} else\r\niip = 0;\r\nlast_level = le16_to_cpu(idx->level);\r\nlast_sqnum = le64_to_cpu(idx->ch.sqnum);\r\nbr = ubifs_idx_branch(c, idx, iip);\r\nlnum = le32_to_cpu(br->lnum);\r\noffs = le32_to_cpu(br->offs);\r\nlen = le32_to_cpu(br->len);\r\nkey_read(c, &br->key, &lower_key);\r\nif (iip + 1 < le16_to_cpu(idx->child_cnt)) {\r\nbr = ubifs_idx_branch(c, idx, iip + 1);\r\nkey_read(c, &br->key, &upper_key);\r\n} else\r\nkey_copy(c, &i->upper_key, &upper_key);\r\n}\r\nout:\r\nerr = dbg_old_index_check_init(c, zroot);\r\nif (err)\r\ngoto out_free;\r\nreturn 0;\r\nout_dump:\r\nubifs_err("dumping index node (iip=%d)", i->iip);\r\nubifs_dump_node(c, idx);\r\nlist_del(&i->list);\r\nkfree(i);\r\nif (!list_empty(&list)) {\r\ni = list_entry(list.prev, struct idx_node, list);\r\nubifs_err("dumping parent index node");\r\nubifs_dump_node(c, &i->idx);\r\n}\r\nout_free:\r\nwhile (!list_empty(&list)) {\r\ni = list_entry(list.next, struct idx_node, list);\r\nlist_del(&i->list);\r\nkfree(i);\r\n}\r\nubifs_err("failed, error %d", err);\r\nif (err > 0)\r\nerr = -EINVAL;\r\nreturn err;\r\n}
