unsigned int tipc_k_signal(Handler routine, unsigned long argument)\r\n{\r\nstruct queue_item *item;\r\nspin_lock_bh(&qitem_lock);\r\nif (!handler_enabled) {\r\nspin_unlock_bh(&qitem_lock);\r\nreturn -ENOPROTOOPT;\r\n}\r\nitem = kmem_cache_alloc(tipc_queue_item_cache, GFP_ATOMIC);\r\nif (!item) {\r\npr_err("Signal queue out of memory\n");\r\nspin_unlock_bh(&qitem_lock);\r\nreturn -ENOMEM;\r\n}\r\nitem->handler = routine;\r\nitem->data = argument;\r\nlist_add_tail(&item->next_signal, &signal_queue_head);\r\nspin_unlock_bh(&qitem_lock);\r\ntasklet_schedule(&tipc_tasklet);\r\nreturn 0;\r\n}\r\nstatic void process_signal_queue(unsigned long dummy)\r\n{\r\nstruct queue_item *__volatile__ item;\r\nstruct list_head *l, *n;\r\nspin_lock_bh(&qitem_lock);\r\nlist_for_each_safe(l, n, &signal_queue_head) {\r\nitem = list_entry(l, struct queue_item, next_signal);\r\nlist_del(&item->next_signal);\r\nspin_unlock_bh(&qitem_lock);\r\nitem->handler(item->data);\r\nspin_lock_bh(&qitem_lock);\r\nkmem_cache_free(tipc_queue_item_cache, item);\r\n}\r\nspin_unlock_bh(&qitem_lock);\r\n}\r\nint tipc_handler_start(void)\r\n{\r\ntipc_queue_item_cache =\r\nkmem_cache_create("tipc_queue_items", sizeof(struct queue_item),\r\n0, SLAB_HWCACHE_ALIGN, NULL);\r\nif (!tipc_queue_item_cache)\r\nreturn -ENOMEM;\r\nINIT_LIST_HEAD(&signal_queue_head);\r\ntasklet_enable(&tipc_tasklet);\r\nhandler_enabled = 1;\r\nreturn 0;\r\n}\r\nvoid tipc_handler_stop(void)\r\n{\r\nstruct list_head *l, *n;\r\nstruct queue_item *item;\r\nspin_lock_bh(&qitem_lock);\r\nif (!handler_enabled) {\r\nspin_unlock_bh(&qitem_lock);\r\nreturn;\r\n}\r\nhandler_enabled = 0;\r\nspin_unlock_bh(&qitem_lock);\r\ntasklet_kill(&tipc_tasklet);\r\nspin_lock_bh(&qitem_lock);\r\nlist_for_each_safe(l, n, &signal_queue_head) {\r\nitem = list_entry(l, struct queue_item, next_signal);\r\nlist_del(&item->next_signal);\r\nkmem_cache_free(tipc_queue_item_cache, item);\r\n}\r\nspin_unlock_bh(&qitem_lock);\r\nkmem_cache_destroy(tipc_queue_item_cache);\r\n}
