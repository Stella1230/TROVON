static inline void\r\ncfs_hash_nl_lock(union cfs_hash_lock *lock, int exclusive) {}\r\nstatic inline void\r\ncfs_hash_nl_unlock(union cfs_hash_lock *lock, int exclusive) {}\r\nstatic inline void\r\ncfs_hash_spin_lock(union cfs_hash_lock *lock, int exclusive)\r\n{\r\nspin_lock(&lock->spin);\r\n}\r\nstatic inline void\r\ncfs_hash_spin_unlock(union cfs_hash_lock *lock, int exclusive)\r\n{\r\nspin_unlock(&lock->spin);\r\n}\r\nstatic inline void\r\ncfs_hash_rw_lock(union cfs_hash_lock *lock, int exclusive)\r\n{\r\nif (!exclusive)\r\nread_lock(&lock->rw);\r\nelse\r\nwrite_lock(&lock->rw);\r\n}\r\nstatic inline void\r\ncfs_hash_rw_unlock(union cfs_hash_lock *lock, int exclusive)\r\n{\r\nif (!exclusive)\r\nread_unlock(&lock->rw);\r\nelse\r\nwrite_unlock(&lock->rw);\r\n}\r\nstatic void\r\ncfs_hash_lock_setup(struct cfs_hash *hs)\r\n{\r\nif (cfs_hash_with_no_lock(hs)) {\r\nhs->hs_lops = &cfs_hash_nl_lops;\r\n} else if (cfs_hash_with_no_bktlock(hs)) {\r\nhs->hs_lops = &cfs_hash_nbl_lops;\r\nspin_lock_init(&hs->hs_lock.spin);\r\n} else if (cfs_hash_with_rehash(hs)) {\r\nrwlock_init(&hs->hs_lock.rw);\r\nif (cfs_hash_with_rw_bktlock(hs))\r\nhs->hs_lops = &cfs_hash_bkt_rw_lops;\r\nelse if (cfs_hash_with_spin_bktlock(hs))\r\nhs->hs_lops = &cfs_hash_bkt_spin_lops;\r\nelse\r\nLBUG();\r\n} else {\r\nif (cfs_hash_with_rw_bktlock(hs))\r\nhs->hs_lops = &cfs_hash_nr_bkt_rw_lops;\r\nelse if (cfs_hash_with_spin_bktlock(hs))\r\nhs->hs_lops = &cfs_hash_nr_bkt_spin_lops;\r\nelse\r\nLBUG();\r\n}\r\n}\r\nstatic int\r\ncfs_hash_hh_hhead_size(struct cfs_hash *hs)\r\n{\r\nreturn sizeof(cfs_hash_head_t);\r\n}\r\nstatic struct hlist_head *\r\ncfs_hash_hh_hhead(struct cfs_hash *hs, struct cfs_hash_bd *bd)\r\n{\r\ncfs_hash_head_t *head = (cfs_hash_head_t *)&bd->bd_bucket->hsb_head[0];\r\nreturn &head[bd->bd_offset].hh_head;\r\n}\r\nstatic int\r\ncfs_hash_hh_hnode_add(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\nhlist_add_head(hnode, cfs_hash_hh_hhead(hs, bd));\r\nreturn -1;\r\n}\r\nstatic int\r\ncfs_hash_hh_hnode_del(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\nhlist_del_init(hnode);\r\nreturn -1;\r\n}\r\nstatic int\r\ncfs_hash_hd_hhead_size(struct cfs_hash *hs)\r\n{\r\nreturn sizeof(cfs_hash_head_dep_t);\r\n}\r\nstatic struct hlist_head *\r\ncfs_hash_hd_hhead(struct cfs_hash *hs, struct cfs_hash_bd *bd)\r\n{\r\ncfs_hash_head_dep_t *head;\r\nhead = (cfs_hash_head_dep_t *)&bd->bd_bucket->hsb_head[0];\r\nreturn &head[bd->bd_offset].hd_head;\r\n}\r\nstatic int\r\ncfs_hash_hd_hnode_add(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\ncfs_hash_head_dep_t *hh = container_of(cfs_hash_hd_hhead(hs, bd),\r\ncfs_hash_head_dep_t, hd_head);\r\nhlist_add_head(hnode, &hh->hd_head);\r\nreturn ++hh->hd_depth;\r\n}\r\nstatic int\r\ncfs_hash_hd_hnode_del(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\ncfs_hash_head_dep_t *hh = container_of(cfs_hash_hd_hhead(hs, bd),\r\ncfs_hash_head_dep_t, hd_head);\r\nhlist_del_init(hnode);\r\nreturn --hh->hd_depth;\r\n}\r\nstatic int\r\ncfs_hash_dh_hhead_size(struct cfs_hash *hs)\r\n{\r\nreturn sizeof(cfs_hash_dhead_t);\r\n}\r\nstatic struct hlist_head *\r\ncfs_hash_dh_hhead(struct cfs_hash *hs, struct cfs_hash_bd *bd)\r\n{\r\ncfs_hash_dhead_t *head;\r\nhead = (cfs_hash_dhead_t *)&bd->bd_bucket->hsb_head[0];\r\nreturn &head[bd->bd_offset].dh_head;\r\n}\r\nstatic int\r\ncfs_hash_dh_hnode_add(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\ncfs_hash_dhead_t *dh = container_of(cfs_hash_dh_hhead(hs, bd),\r\ncfs_hash_dhead_t, dh_head);\r\nif (dh->dh_tail != NULL)\r\nhlist_add_after(dh->dh_tail, hnode);\r\nelse\r\nhlist_add_head(hnode, &dh->dh_head);\r\ndh->dh_tail = hnode;\r\nreturn -1;\r\n}\r\nstatic int\r\ncfs_hash_dh_hnode_del(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnd)\r\n{\r\ncfs_hash_dhead_t *dh = container_of(cfs_hash_dh_hhead(hs, bd),\r\ncfs_hash_dhead_t, dh_head);\r\nif (hnd->next == NULL) {\r\ndh->dh_tail = (hnd->pprev == &dh->dh_head.first) ? NULL :\r\ncontainer_of(hnd->pprev, struct hlist_node, next);\r\n}\r\nhlist_del_init(hnd);\r\nreturn -1;\r\n}\r\nstatic int\r\ncfs_hash_dd_hhead_size(struct cfs_hash *hs)\r\n{\r\nreturn sizeof(cfs_hash_dhead_dep_t);\r\n}\r\nstatic struct hlist_head *\r\ncfs_hash_dd_hhead(struct cfs_hash *hs, struct cfs_hash_bd *bd)\r\n{\r\ncfs_hash_dhead_dep_t *head;\r\nhead = (cfs_hash_dhead_dep_t *)&bd->bd_bucket->hsb_head[0];\r\nreturn &head[bd->bd_offset].dd_head;\r\n}\r\nstatic int\r\ncfs_hash_dd_hnode_add(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\ncfs_hash_dhead_dep_t *dh = container_of(cfs_hash_dd_hhead(hs, bd),\r\ncfs_hash_dhead_dep_t, dd_head);\r\nif (dh->dd_tail != NULL)\r\nhlist_add_after(dh->dd_tail, hnode);\r\nelse\r\nhlist_add_head(hnode, &dh->dd_head);\r\ndh->dd_tail = hnode;\r\nreturn ++dh->dd_depth;\r\n}\r\nstatic int\r\ncfs_hash_dd_hnode_del(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnd)\r\n{\r\ncfs_hash_dhead_dep_t *dh = container_of(cfs_hash_dd_hhead(hs, bd),\r\ncfs_hash_dhead_dep_t, dd_head);\r\nif (hnd->next == NULL) {\r\ndh->dd_tail = (hnd->pprev == &dh->dd_head.first) ? NULL :\r\ncontainer_of(hnd->pprev, struct hlist_node, next);\r\n}\r\nhlist_del_init(hnd);\r\nreturn --dh->dd_depth;\r\n}\r\nstatic void\r\ncfs_hash_hlist_setup(struct cfs_hash *hs)\r\n{\r\nif (cfs_hash_with_add_tail(hs)) {\r\nhs->hs_hops = cfs_hash_with_depth(hs) ?\r\n&cfs_hash_dd_hops : &cfs_hash_dh_hops;\r\n} else {\r\nhs->hs_hops = cfs_hash_with_depth(hs) ?\r\n&cfs_hash_hd_hops : &cfs_hash_hh_hops;\r\n}\r\n}\r\nstatic void\r\ncfs_hash_bd_from_key(struct cfs_hash *hs, struct cfs_hash_bucket **bkts,\r\nunsigned int bits, const void *key, struct cfs_hash_bd *bd)\r\n{\r\nunsigned int index = cfs_hash_id(hs, key, (1U << bits) - 1);\r\nLASSERT(bits == hs->hs_cur_bits || bits == hs->hs_rehash_bits);\r\nbd->bd_bucket = bkts[index & ((1U << (bits - hs->hs_bkt_bits)) - 1)];\r\nbd->bd_offset = index >> (bits - hs->hs_bkt_bits);\r\n}\r\nvoid\r\ncfs_hash_bd_get(struct cfs_hash *hs, const void *key, struct cfs_hash_bd *bd)\r\n{\r\nif (likely(hs->hs_rehash_buckets == NULL)) {\r\ncfs_hash_bd_from_key(hs, hs->hs_buckets,\r\nhs->hs_cur_bits, key, bd);\r\n} else {\r\nLASSERT(hs->hs_rehash_bits != 0);\r\ncfs_hash_bd_from_key(hs, hs->hs_rehash_buckets,\r\nhs->hs_rehash_bits, key, bd);\r\n}\r\n}\r\nstatic inline void\r\ncfs_hash_bd_dep_record(struct cfs_hash *hs, struct cfs_hash_bd *bd, int dep_cur)\r\n{\r\nif (likely(dep_cur <= bd->bd_bucket->hsb_depmax))\r\nreturn;\r\nbd->bd_bucket->hsb_depmax = dep_cur;\r\n# if CFS_HASH_DEBUG_LEVEL >= CFS_HASH_DEBUG_1\r\nif (likely(warn_on_depth == 0 ||\r\nmax(warn_on_depth, hs->hs_dep_max) >= dep_cur))\r\nreturn;\r\nspin_lock(&hs->hs_dep_lock);\r\nhs->hs_dep_max = dep_cur;\r\nhs->hs_dep_bkt = bd->bd_bucket->hsb_index;\r\nhs->hs_dep_off = bd->bd_offset;\r\nhs->hs_dep_bits = hs->hs_cur_bits;\r\nspin_unlock(&hs->hs_dep_lock);\r\ncfs_wi_schedule(cfs_sched_rehash, &hs->hs_dep_wi);\r\n# endif\r\n}\r\nvoid\r\ncfs_hash_bd_add_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\nint rc;\r\nrc = hs->hs_hops->hop_hnode_add(hs, bd, hnode);\r\ncfs_hash_bd_dep_record(hs, bd, rc);\r\nbd->bd_bucket->hsb_version++;\r\nif (unlikely(bd->bd_bucket->hsb_version == 0))\r\nbd->bd_bucket->hsb_version++;\r\nbd->bd_bucket->hsb_count++;\r\nif (cfs_hash_with_counter(hs))\r\natomic_inc(&hs->hs_count);\r\nif (!cfs_hash_with_no_itemref(hs))\r\ncfs_hash_get(hs, hnode);\r\n}\r\nvoid\r\ncfs_hash_bd_del_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode)\r\n{\r\nhs->hs_hops->hop_hnode_del(hs, bd, hnode);\r\nLASSERT(bd->bd_bucket->hsb_count > 0);\r\nbd->bd_bucket->hsb_count--;\r\nbd->bd_bucket->hsb_version++;\r\nif (unlikely(bd->bd_bucket->hsb_version == 0))\r\nbd->bd_bucket->hsb_version++;\r\nif (cfs_hash_with_counter(hs)) {\r\nLASSERT(atomic_read(&hs->hs_count) > 0);\r\natomic_dec(&hs->hs_count);\r\n}\r\nif (!cfs_hash_with_no_itemref(hs))\r\ncfs_hash_put_locked(hs, hnode);\r\n}\r\nvoid\r\ncfs_hash_bd_move_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd_old,\r\nstruct cfs_hash_bd *bd_new, struct hlist_node *hnode)\r\n{\r\nstruct cfs_hash_bucket *obkt = bd_old->bd_bucket;\r\nstruct cfs_hash_bucket *nbkt = bd_new->bd_bucket;\r\nint rc;\r\nif (cfs_hash_bd_compare(bd_old, bd_new) == 0)\r\nreturn;\r\nhs->hs_hops->hop_hnode_del(hs, bd_old, hnode);\r\nrc = hs->hs_hops->hop_hnode_add(hs, bd_new, hnode);\r\ncfs_hash_bd_dep_record(hs, bd_new, rc);\r\nLASSERT(obkt->hsb_count > 0);\r\nobkt->hsb_count--;\r\nobkt->hsb_version++;\r\nif (unlikely(obkt->hsb_version == 0))\r\nobkt->hsb_version++;\r\nnbkt->hsb_count++;\r\nnbkt->hsb_version++;\r\nif (unlikely(nbkt->hsb_version == 0))\r\nnbkt->hsb_version++;\r\n}\r\nstatic struct hlist_node *\r\ncfs_hash_bd_lookup_intent(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nconst void *key, struct hlist_node *hnode,\r\ncfs_hash_lookup_intent_t intent)\r\n{\r\nstruct hlist_head *hhead = cfs_hash_bd_hhead(hs, bd);\r\nstruct hlist_node *ehnode;\r\nstruct hlist_node *match;\r\nint intent_add = (intent & CFS_HS_LOOKUP_MASK_ADD) != 0;\r\nmatch = intent_add ? NULL : hnode;\r\nhlist_for_each(ehnode, hhead) {\r\nif (!cfs_hash_keycmp(hs, key, ehnode))\r\ncontinue;\r\nif (match != NULL && match != ehnode)\r\ncontinue;\r\nif ((intent & CFS_HS_LOOKUP_MASK_DEL) != 0) {\r\ncfs_hash_bd_del_locked(hs, bd, ehnode);\r\nreturn ehnode;\r\n}\r\nif ((intent & CFS_HS_LOOKUP_MASK_REF) != 0)\r\ncfs_hash_get(hs, ehnode);\r\nreturn ehnode;\r\n}\r\nif (!intent_add)\r\nreturn NULL;\r\nLASSERT(hnode != NULL);\r\ncfs_hash_bd_add_locked(hs, bd, hnode);\r\nreturn hnode;\r\n}\r\nstruct hlist_node *\r\ncfs_hash_bd_lookup_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd, const void *key)\r\n{\r\nreturn cfs_hash_bd_lookup_intent(hs, bd, key, NULL,\r\nCFS_HS_LOOKUP_IT_FIND);\r\n}\r\nstruct hlist_node *\r\ncfs_hash_bd_peek_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd, const void *key)\r\n{\r\nreturn cfs_hash_bd_lookup_intent(hs, bd, key, NULL,\r\nCFS_HS_LOOKUP_IT_PEEK);\r\n}\r\nstruct hlist_node *\r\ncfs_hash_bd_findadd_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nconst void *key, struct hlist_node *hnode,\r\nint noref)\r\n{\r\nreturn cfs_hash_bd_lookup_intent(hs, bd, key, hnode,\r\nCFS_HS_LOOKUP_IT_ADD |\r\n(!noref * CFS_HS_LOOKUP_MASK_REF));\r\n}\r\nstruct hlist_node *\r\ncfs_hash_bd_finddel_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nconst void *key, struct hlist_node *hnode)\r\n{\r\nreturn cfs_hash_bd_lookup_intent(hs, bd, key, hnode,\r\nCFS_HS_LOOKUP_IT_FINDDEL);\r\n}\r\nstatic void\r\ncfs_hash_multi_bd_lock(struct cfs_hash *hs, struct cfs_hash_bd *bds,\r\nunsigned n, int excl)\r\n{\r\nstruct cfs_hash_bucket *prev = NULL;\r\nint i;\r\ncfs_hash_for_each_bd(bds, n, i) {\r\nif (prev == bds[i].bd_bucket)\r\ncontinue;\r\nLASSERT(prev == NULL ||\r\nprev->hsb_index < bds[i].bd_bucket->hsb_index);\r\ncfs_hash_bd_lock(hs, &bds[i], excl);\r\nprev = bds[i].bd_bucket;\r\n}\r\n}\r\nstatic void\r\ncfs_hash_multi_bd_unlock(struct cfs_hash *hs, struct cfs_hash_bd *bds,\r\nunsigned n, int excl)\r\n{\r\nstruct cfs_hash_bucket *prev = NULL;\r\nint i;\r\ncfs_hash_for_each_bd(bds, n, i) {\r\nif (prev != bds[i].bd_bucket) {\r\ncfs_hash_bd_unlock(hs, &bds[i], excl);\r\nprev = bds[i].bd_bucket;\r\n}\r\n}\r\n}\r\nstatic struct hlist_node *\r\ncfs_hash_multi_bd_lookup_locked(struct cfs_hash *hs, struct cfs_hash_bd *bds,\r\nunsigned n, const void *key)\r\n{\r\nstruct hlist_node *ehnode;\r\nunsigned i;\r\ncfs_hash_for_each_bd(bds, n, i) {\r\nehnode = cfs_hash_bd_lookup_intent(hs, &bds[i], key, NULL,\r\nCFS_HS_LOOKUP_IT_FIND);\r\nif (ehnode != NULL)\r\nreturn ehnode;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct hlist_node *\r\ncfs_hash_multi_bd_findadd_locked(struct cfs_hash *hs,\r\nstruct cfs_hash_bd *bds, unsigned n, const void *key,\r\nstruct hlist_node *hnode, int noref)\r\n{\r\nstruct hlist_node *ehnode;\r\nint intent;\r\nunsigned i;\r\nLASSERT(hnode != NULL);\r\nintent = CFS_HS_LOOKUP_IT_PEEK | (!noref * CFS_HS_LOOKUP_MASK_REF);\r\ncfs_hash_for_each_bd(bds, n, i) {\r\nehnode = cfs_hash_bd_lookup_intent(hs, &bds[i], key,\r\nNULL, intent);\r\nif (ehnode != NULL)\r\nreturn ehnode;\r\n}\r\nif (i == 1) {\r\ncfs_hash_bd_add_locked(hs, &bds[0], hnode);\r\n} else {\r\nstruct cfs_hash_bd mybd;\r\ncfs_hash_bd_get(hs, key, &mybd);\r\ncfs_hash_bd_add_locked(hs, &mybd, hnode);\r\n}\r\nreturn hnode;\r\n}\r\nstatic struct hlist_node *\r\ncfs_hash_multi_bd_finddel_locked(struct cfs_hash *hs, struct cfs_hash_bd *bds,\r\nunsigned n, const void *key,\r\nstruct hlist_node *hnode)\r\n{\r\nstruct hlist_node *ehnode;\r\nunsigned i;\r\ncfs_hash_for_each_bd(bds, n, i) {\r\nehnode = cfs_hash_bd_lookup_intent(hs, &bds[i], key, hnode,\r\nCFS_HS_LOOKUP_IT_FINDDEL);\r\nif (ehnode != NULL)\r\nreturn ehnode;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void\r\ncfs_hash_bd_order(struct cfs_hash_bd *bd1, struct cfs_hash_bd *bd2)\r\n{\r\nint rc;\r\nif (bd2->bd_bucket == NULL)\r\nreturn;\r\nif (bd1->bd_bucket == NULL) {\r\n*bd1 = *bd2;\r\nbd2->bd_bucket = NULL;\r\nreturn;\r\n}\r\nrc = cfs_hash_bd_compare(bd1, bd2);\r\nif (rc == 0) {\r\nbd2->bd_bucket = NULL;\r\n} else if (rc > 0) {\r\nstruct cfs_hash_bd tmp;\r\ntmp = *bd2;\r\n*bd2 = *bd1;\r\n*bd1 = tmp;\r\n}\r\n}\r\nvoid\r\ncfs_hash_dual_bd_get(struct cfs_hash *hs, const void *key, struct cfs_hash_bd *bds)\r\n{\r\ncfs_hash_bd_from_key(hs, hs->hs_buckets,\r\nhs->hs_cur_bits, key, &bds[0]);\r\nif (likely(hs->hs_rehash_buckets == NULL)) {\r\nbds[1].bd_bucket = NULL;\r\nreturn;\r\n}\r\nLASSERT(hs->hs_rehash_bits != 0);\r\ncfs_hash_bd_from_key(hs, hs->hs_rehash_buckets,\r\nhs->hs_rehash_bits, key, &bds[1]);\r\ncfs_hash_bd_order(&bds[0], &bds[1]);\r\n}\r\nvoid\r\ncfs_hash_dual_bd_lock(struct cfs_hash *hs, struct cfs_hash_bd *bds, int excl)\r\n{\r\ncfs_hash_multi_bd_lock(hs, bds, 2, excl);\r\n}\r\nvoid\r\ncfs_hash_dual_bd_unlock(struct cfs_hash *hs, struct cfs_hash_bd *bds, int excl)\r\n{\r\ncfs_hash_multi_bd_unlock(hs, bds, 2, excl);\r\n}\r\nstruct hlist_node *\r\ncfs_hash_dual_bd_lookup_locked(struct cfs_hash *hs, struct cfs_hash_bd *bds,\r\nconst void *key)\r\n{\r\nreturn cfs_hash_multi_bd_lookup_locked(hs, bds, 2, key);\r\n}\r\nstruct hlist_node *\r\ncfs_hash_dual_bd_findadd_locked(struct cfs_hash *hs, struct cfs_hash_bd *bds,\r\nconst void *key, struct hlist_node *hnode,\r\nint noref)\r\n{\r\nreturn cfs_hash_multi_bd_findadd_locked(hs, bds, 2, key,\r\nhnode, noref);\r\n}\r\nstruct hlist_node *\r\ncfs_hash_dual_bd_finddel_locked(struct cfs_hash *hs, struct cfs_hash_bd *bds,\r\nconst void *key, struct hlist_node *hnode)\r\n{\r\nreturn cfs_hash_multi_bd_finddel_locked(hs, bds, 2, key, hnode);\r\n}\r\nstatic void\r\ncfs_hash_buckets_free(struct cfs_hash_bucket **buckets,\r\nint bkt_size, int prev_size, int size)\r\n{\r\nint i;\r\nfor (i = prev_size; i < size; i++) {\r\nif (buckets[i] != NULL)\r\nLIBCFS_FREE(buckets[i], bkt_size);\r\n}\r\nLIBCFS_FREE(buckets, sizeof(buckets[0]) * size);\r\n}\r\nstatic struct cfs_hash_bucket **\r\ncfs_hash_buckets_realloc(struct cfs_hash *hs, struct cfs_hash_bucket **old_bkts,\r\nunsigned int old_size, unsigned int new_size)\r\n{\r\nstruct cfs_hash_bucket **new_bkts;\r\nint i;\r\nLASSERT(old_size == 0 || old_bkts != NULL);\r\nif (old_bkts != NULL && old_size == new_size)\r\nreturn old_bkts;\r\nLIBCFS_ALLOC(new_bkts, sizeof(new_bkts[0]) * new_size);\r\nif (new_bkts == NULL)\r\nreturn NULL;\r\nif (old_bkts != NULL) {\r\nmemcpy(new_bkts, old_bkts,\r\nmin(old_size, new_size) * sizeof(*old_bkts));\r\n}\r\nfor (i = old_size; i < new_size; i++) {\r\nstruct hlist_head *hhead;\r\nstruct cfs_hash_bd bd;\r\nLIBCFS_ALLOC(new_bkts[i], cfs_hash_bkt_size(hs));\r\nif (new_bkts[i] == NULL) {\r\ncfs_hash_buckets_free(new_bkts, cfs_hash_bkt_size(hs),\r\nold_size, new_size);\r\nreturn NULL;\r\n}\r\nnew_bkts[i]->hsb_index = i;\r\nnew_bkts[i]->hsb_version = 1;\r\nnew_bkts[i]->hsb_depmax = -1;\r\nbd.bd_bucket = new_bkts[i];\r\ncfs_hash_bd_for_each_hlist(hs, &bd, hhead)\r\nINIT_HLIST_HEAD(hhead);\r\nif (cfs_hash_with_no_lock(hs) ||\r\ncfs_hash_with_no_bktlock(hs))\r\ncontinue;\r\nif (cfs_hash_with_rw_bktlock(hs))\r\nrwlock_init(&new_bkts[i]->hsb_lock.rw);\r\nelse if (cfs_hash_with_spin_bktlock(hs))\r\nspin_lock_init(&new_bkts[i]->hsb_lock.spin);\r\nelse\r\nLBUG();\r\n}\r\nreturn new_bkts;\r\n}\r\nstatic int cfs_hash_dep_print(cfs_workitem_t *wi)\r\n{\r\nstruct cfs_hash *hs = container_of(wi, struct cfs_hash, hs_dep_wi);\r\nint dep;\r\nint bkt;\r\nint off;\r\nint bits;\r\nspin_lock(&hs->hs_dep_lock);\r\ndep = hs->hs_dep_max;\r\nbkt = hs->hs_dep_bkt;\r\noff = hs->hs_dep_off;\r\nbits = hs->hs_dep_bits;\r\nspin_unlock(&hs->hs_dep_lock);\r\nLCONSOLE_WARN("#### HASH %s (bits: %d): max depth %d at bucket %d/%d\n",\r\nhs->hs_name, bits, dep, bkt, off);\r\nspin_lock(&hs->hs_dep_lock);\r\nhs->hs_dep_bits = 0;\r\nspin_unlock(&hs->hs_dep_lock);\r\nreturn 0;\r\n}\r\nstatic void cfs_hash_depth_wi_init(struct cfs_hash *hs)\r\n{\r\nspin_lock_init(&hs->hs_dep_lock);\r\ncfs_wi_init(&hs->hs_dep_wi, hs, cfs_hash_dep_print);\r\n}\r\nstatic void cfs_hash_depth_wi_cancel(struct cfs_hash *hs)\r\n{\r\nif (cfs_wi_deschedule(cfs_sched_rehash, &hs->hs_dep_wi))\r\nreturn;\r\nspin_lock(&hs->hs_dep_lock);\r\nwhile (hs->hs_dep_bits != 0) {\r\nspin_unlock(&hs->hs_dep_lock);\r\ncond_resched();\r\nspin_lock(&hs->hs_dep_lock);\r\n}\r\nspin_unlock(&hs->hs_dep_lock);\r\n}\r\nstatic inline void cfs_hash_depth_wi_init(struct cfs_hash *hs) {}\r\nstatic inline void cfs_hash_depth_wi_cancel(struct cfs_hash *hs) {}\r\nstruct cfs_hash *\r\ncfs_hash_create(char *name, unsigned cur_bits, unsigned max_bits,\r\nunsigned bkt_bits, unsigned extra_bytes,\r\nunsigned min_theta, unsigned max_theta,\r\ncfs_hash_ops_t *ops, unsigned flags)\r\n{\r\nstruct cfs_hash *hs;\r\nint len;\r\nCLASSERT(CFS_HASH_THETA_BITS < 15);\r\nLASSERT(name != NULL);\r\nLASSERT(ops != NULL);\r\nLASSERT(ops->hs_key);\r\nLASSERT(ops->hs_hash);\r\nLASSERT(ops->hs_object);\r\nLASSERT(ops->hs_keycmp);\r\nLASSERT(ops->hs_get != NULL);\r\nLASSERT(ops->hs_put_locked != NULL);\r\nif ((flags & CFS_HASH_REHASH) != 0)\r\nflags |= CFS_HASH_COUNTER;\r\nLASSERT(cur_bits > 0);\r\nLASSERT(cur_bits >= bkt_bits);\r\nLASSERT(max_bits >= cur_bits && max_bits < 31);\r\nLASSERT(ergo((flags & CFS_HASH_REHASH) == 0, cur_bits == max_bits));\r\nLASSERT(ergo((flags & CFS_HASH_REHASH) != 0,\r\n(flags & CFS_HASH_NO_LOCK) == 0));\r\nLASSERT(ergo((flags & CFS_HASH_REHASH_KEY) != 0,\r\nops->hs_keycpy != NULL));\r\nlen = (flags & CFS_HASH_BIGNAME) == 0 ?\r\nCFS_HASH_NAME_LEN : CFS_HASH_BIGNAME_LEN;\r\nLIBCFS_ALLOC(hs, offsetof(struct cfs_hash, hs_name[len]));\r\nif (hs == NULL)\r\nreturn NULL;\r\nstrncpy(hs->hs_name, name, len);\r\nhs->hs_name[len - 1] = '\0';\r\nhs->hs_flags = flags;\r\natomic_set(&hs->hs_refcount, 1);\r\natomic_set(&hs->hs_count, 0);\r\ncfs_hash_lock_setup(hs);\r\ncfs_hash_hlist_setup(hs);\r\nhs->hs_cur_bits = (__u8)cur_bits;\r\nhs->hs_min_bits = (__u8)cur_bits;\r\nhs->hs_max_bits = (__u8)max_bits;\r\nhs->hs_bkt_bits = (__u8)bkt_bits;\r\nhs->hs_ops = ops;\r\nhs->hs_extra_bytes = extra_bytes;\r\nhs->hs_rehash_bits = 0;\r\ncfs_wi_init(&hs->hs_rehash_wi, hs, cfs_hash_rehash_worker);\r\ncfs_hash_depth_wi_init(hs);\r\nif (cfs_hash_with_rehash(hs))\r\n__cfs_hash_set_theta(hs, min_theta, max_theta);\r\nhs->hs_buckets = cfs_hash_buckets_realloc(hs, NULL, 0,\r\nCFS_HASH_NBKT(hs));\r\nif (hs->hs_buckets != NULL)\r\nreturn hs;\r\nLIBCFS_FREE(hs, offsetof(struct cfs_hash, hs_name[len]));\r\nreturn NULL;\r\n}\r\nstatic void\r\ncfs_hash_destroy(struct cfs_hash *hs)\r\n{\r\nstruct hlist_node *hnode;\r\nstruct hlist_node *pos;\r\nstruct cfs_hash_bd bd;\r\nint i;\r\nLASSERT(hs != NULL);\r\nLASSERT(!cfs_hash_is_exiting(hs) &&\r\n!cfs_hash_is_iterating(hs));\r\nhs->hs_exiting = 1;\r\nif (cfs_hash_with_rehash(hs))\r\ncfs_hash_rehash_cancel(hs);\r\ncfs_hash_depth_wi_cancel(hs);\r\nLASSERT(hs->hs_buckets != NULL &&\r\nhs->hs_rehash_buckets == NULL);\r\ncfs_hash_for_each_bucket(hs, &bd, i) {\r\nstruct hlist_head *hhead;\r\nLASSERT(bd.bd_bucket != NULL);\r\ncfs_hash_bd_lock(hs, &bd, 1);\r\ncfs_hash_bd_for_each_hlist(hs, &bd, hhead) {\r\nhlist_for_each_safe(hnode, pos, hhead) {\r\nLASSERTF(!cfs_hash_with_assert_empty(hs),\r\n"hash %s bucket %u(%u) is not "\r\n" empty: %u items left\n",\r\nhs->hs_name, bd.bd_bucket->hsb_index,\r\nbd.bd_offset, bd.bd_bucket->hsb_count);\r\ncfs_hash_bd_del_locked(hs, &bd, hnode);\r\ncfs_hash_exit(hs, hnode);\r\n}\r\n}\r\nLASSERT(bd.bd_bucket->hsb_count == 0);\r\ncfs_hash_bd_unlock(hs, &bd, 1);\r\ncond_resched();\r\n}\r\nLASSERT(atomic_read(&hs->hs_count) == 0);\r\ncfs_hash_buckets_free(hs->hs_buckets, cfs_hash_bkt_size(hs),\r\n0, CFS_HASH_NBKT(hs));\r\ni = cfs_hash_with_bigname(hs) ?\r\nCFS_HASH_BIGNAME_LEN : CFS_HASH_NAME_LEN;\r\nLIBCFS_FREE(hs, offsetof(struct cfs_hash, hs_name[i]));\r\n}\r\nstruct cfs_hash *cfs_hash_getref(struct cfs_hash *hs)\r\n{\r\nif (atomic_inc_not_zero(&hs->hs_refcount))\r\nreturn hs;\r\nreturn NULL;\r\n}\r\nvoid cfs_hash_putref(struct cfs_hash *hs)\r\n{\r\nif (atomic_dec_and_test(&hs->hs_refcount))\r\ncfs_hash_destroy(hs);\r\n}\r\nstatic inline int\r\ncfs_hash_rehash_bits(struct cfs_hash *hs)\r\n{\r\nif (cfs_hash_with_no_lock(hs) ||\r\n!cfs_hash_with_rehash(hs))\r\nreturn -EOPNOTSUPP;\r\nif (unlikely(cfs_hash_is_exiting(hs)))\r\nreturn -ESRCH;\r\nif (unlikely(cfs_hash_is_rehashing(hs)))\r\nreturn -EALREADY;\r\nif (unlikely(cfs_hash_is_iterating(hs)))\r\nreturn -EAGAIN;\r\nif ((hs->hs_cur_bits < hs->hs_max_bits) &&\r\n(__cfs_hash_theta(hs) > hs->hs_max_theta))\r\nreturn hs->hs_cur_bits + 1;\r\nif (!cfs_hash_with_shrink(hs))\r\nreturn 0;\r\nif ((hs->hs_cur_bits > hs->hs_min_bits) &&\r\n(__cfs_hash_theta(hs) < hs->hs_min_theta))\r\nreturn hs->hs_cur_bits - 1;\r\nreturn 0;\r\n}\r\nstatic inline int\r\ncfs_hash_rehash_inline(struct cfs_hash *hs)\r\n{\r\nreturn !cfs_hash_with_nblk_change(hs) &&\r\natomic_read(&hs->hs_count) < CFS_HASH_LOOP_HOG;\r\n}\r\nvoid\r\ncfs_hash_add(struct cfs_hash *hs, const void *key, struct hlist_node *hnode)\r\n{\r\nstruct cfs_hash_bd bd;\r\nint bits;\r\nLASSERT(hlist_unhashed(hnode));\r\ncfs_hash_lock(hs, 0);\r\ncfs_hash_bd_get_and_lock(hs, key, &bd, 1);\r\ncfs_hash_key_validate(hs, key, hnode);\r\ncfs_hash_bd_add_locked(hs, &bd, hnode);\r\ncfs_hash_bd_unlock(hs, &bd, 1);\r\nbits = cfs_hash_rehash_bits(hs);\r\ncfs_hash_unlock(hs, 0);\r\nif (bits > 0)\r\ncfs_hash_rehash(hs, cfs_hash_rehash_inline(hs));\r\n}\r\nstatic struct hlist_node *\r\ncfs_hash_find_or_add(struct cfs_hash *hs, const void *key,\r\nstruct hlist_node *hnode, int noref)\r\n{\r\nstruct hlist_node *ehnode;\r\nstruct cfs_hash_bd bds[2];\r\nint bits = 0;\r\nLASSERT(hlist_unhashed(hnode));\r\ncfs_hash_lock(hs, 0);\r\ncfs_hash_dual_bd_get_and_lock(hs, key, bds, 1);\r\ncfs_hash_key_validate(hs, key, hnode);\r\nehnode = cfs_hash_dual_bd_findadd_locked(hs, bds, key,\r\nhnode, noref);\r\ncfs_hash_dual_bd_unlock(hs, bds, 1);\r\nif (ehnode == hnode)\r\nbits = cfs_hash_rehash_bits(hs);\r\ncfs_hash_unlock(hs, 0);\r\nif (bits > 0)\r\ncfs_hash_rehash(hs, cfs_hash_rehash_inline(hs));\r\nreturn ehnode;\r\n}\r\nint\r\ncfs_hash_add_unique(struct cfs_hash *hs, const void *key, struct hlist_node *hnode)\r\n{\r\nreturn cfs_hash_find_or_add(hs, key, hnode, 1) != hnode ?\r\n-EALREADY : 0;\r\n}\r\nvoid *\r\ncfs_hash_findadd_unique(struct cfs_hash *hs, const void *key,\r\nstruct hlist_node *hnode)\r\n{\r\nhnode = cfs_hash_find_or_add(hs, key, hnode, 0);\r\nreturn cfs_hash_object(hs, hnode);\r\n}\r\nvoid *\r\ncfs_hash_del(struct cfs_hash *hs, const void *key, struct hlist_node *hnode)\r\n{\r\nvoid *obj = NULL;\r\nint bits = 0;\r\nstruct cfs_hash_bd bds[2];\r\ncfs_hash_lock(hs, 0);\r\ncfs_hash_dual_bd_get_and_lock(hs, key, bds, 1);\r\nif (hnode == NULL || !hlist_unhashed(hnode)) {\r\nif (bds[1].bd_bucket == NULL && hnode != NULL) {\r\ncfs_hash_bd_del_locked(hs, &bds[0], hnode);\r\n} else {\r\nhnode = cfs_hash_dual_bd_finddel_locked(hs, bds,\r\nkey, hnode);\r\n}\r\n}\r\nif (hnode != NULL) {\r\nobj = cfs_hash_object(hs, hnode);\r\nbits = cfs_hash_rehash_bits(hs);\r\n}\r\ncfs_hash_dual_bd_unlock(hs, bds, 1);\r\ncfs_hash_unlock(hs, 0);\r\nif (bits > 0)\r\ncfs_hash_rehash(hs, cfs_hash_rehash_inline(hs));\r\nreturn obj;\r\n}\r\nvoid *\r\ncfs_hash_del_key(struct cfs_hash *hs, const void *key)\r\n{\r\nreturn cfs_hash_del(hs, key, NULL);\r\n}\r\nvoid *\r\ncfs_hash_lookup(struct cfs_hash *hs, const void *key)\r\n{\r\nvoid *obj = NULL;\r\nstruct hlist_node *hnode;\r\nstruct cfs_hash_bd bds[2];\r\ncfs_hash_lock(hs, 0);\r\ncfs_hash_dual_bd_get_and_lock(hs, key, bds, 0);\r\nhnode = cfs_hash_dual_bd_lookup_locked(hs, bds, key);\r\nif (hnode != NULL)\r\nobj = cfs_hash_object(hs, hnode);\r\ncfs_hash_dual_bd_unlock(hs, bds, 0);\r\ncfs_hash_unlock(hs, 0);\r\nreturn obj;\r\n}\r\nstatic void\r\ncfs_hash_for_each_enter(struct cfs_hash *hs)\r\n{\r\nLASSERT(!cfs_hash_is_exiting(hs));\r\nif (!cfs_hash_with_rehash(hs))\r\nreturn;\r\nhs->hs_iterating = 1;\r\ncfs_hash_lock(hs, 1);\r\nhs->hs_iterators++;\r\nif (cfs_hash_is_rehashing(hs))\r\ncfs_hash_rehash_cancel_locked(hs);\r\ncfs_hash_unlock(hs, 1);\r\n}\r\nstatic void\r\ncfs_hash_for_each_exit(struct cfs_hash *hs)\r\n{\r\nint remained;\r\nint bits;\r\nif (!cfs_hash_with_rehash(hs))\r\nreturn;\r\ncfs_hash_lock(hs, 1);\r\nremained = --hs->hs_iterators;\r\nbits = cfs_hash_rehash_bits(hs);\r\ncfs_hash_unlock(hs, 1);\r\nif (remained == 0)\r\nhs->hs_iterating = 0;\r\nif (bits > 0) {\r\ncfs_hash_rehash(hs, atomic_read(&hs->hs_count) <\r\nCFS_HASH_LOOP_HOG);\r\n}\r\n}\r\nstatic __u64\r\ncfs_hash_for_each_tight(struct cfs_hash *hs, cfs_hash_for_each_cb_t func,\r\nvoid *data, int remove_safe)\r\n{\r\nstruct hlist_node *hnode;\r\nstruct hlist_node *pos;\r\nstruct cfs_hash_bd bd;\r\n__u64 count = 0;\r\nint excl = !!remove_safe;\r\nint loop = 0;\r\nint i;\r\ncfs_hash_for_each_enter(hs);\r\ncfs_hash_lock(hs, 0);\r\nLASSERT(!cfs_hash_is_rehashing(hs));\r\ncfs_hash_for_each_bucket(hs, &bd, i) {\r\nstruct hlist_head *hhead;\r\ncfs_hash_bd_lock(hs, &bd, excl);\r\nif (func == NULL) {\r\ncount += bd.bd_bucket->hsb_count;\r\ncfs_hash_bd_unlock(hs, &bd, excl);\r\ncontinue;\r\n}\r\ncfs_hash_bd_for_each_hlist(hs, &bd, hhead) {\r\nhlist_for_each_safe(hnode, pos, hhead) {\r\ncfs_hash_bucket_validate(hs, &bd, hnode);\r\ncount++;\r\nloop++;\r\nif (func(hs, &bd, hnode, data)) {\r\ncfs_hash_bd_unlock(hs, &bd, excl);\r\ngoto out;\r\n}\r\n}\r\n}\r\ncfs_hash_bd_unlock(hs, &bd, excl);\r\nif (loop < CFS_HASH_LOOP_HOG)\r\ncontinue;\r\nloop = 0;\r\ncfs_hash_unlock(hs, 0);\r\ncond_resched();\r\ncfs_hash_lock(hs, 0);\r\n}\r\nout:\r\ncfs_hash_unlock(hs, 0);\r\ncfs_hash_for_each_exit(hs);\r\nreturn count;\r\n}\r\nstatic int\r\ncfs_hash_cond_del_locked(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode, void *data)\r\n{\r\ncfs_hash_cond_arg_t *cond = data;\r\nif (cond->func(cfs_hash_object(hs, hnode), cond->arg))\r\ncfs_hash_bd_del_locked(hs, bd, hnode);\r\nreturn 0;\r\n}\r\nvoid\r\ncfs_hash_cond_del(struct cfs_hash *hs, cfs_hash_cond_opt_cb_t func, void *data)\r\n{\r\ncfs_hash_cond_arg_t arg = {\r\n.func = func,\r\n.arg = data,\r\n};\r\ncfs_hash_for_each_tight(hs, cfs_hash_cond_del_locked, &arg, 1);\r\n}\r\nvoid\r\ncfs_hash_for_each(struct cfs_hash *hs,\r\ncfs_hash_for_each_cb_t func, void *data)\r\n{\r\ncfs_hash_for_each_tight(hs, func, data, 0);\r\n}\r\nvoid\r\ncfs_hash_for_each_safe(struct cfs_hash *hs,\r\ncfs_hash_for_each_cb_t func, void *data)\r\n{\r\ncfs_hash_for_each_tight(hs, func, data, 1);\r\n}\r\nstatic int\r\ncfs_hash_peek(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode, void *data)\r\n{\r\n*(int *)data = 0;\r\nreturn 1;\r\n}\r\nint\r\ncfs_hash_is_empty(struct cfs_hash *hs)\r\n{\r\nint empty = 1;\r\ncfs_hash_for_each_tight(hs, cfs_hash_peek, &empty, 0);\r\nreturn empty;\r\n}\r\n__u64\r\ncfs_hash_size_get(struct cfs_hash *hs)\r\n{\r\nreturn cfs_hash_with_counter(hs) ?\r\natomic_read(&hs->hs_count) :\r\ncfs_hash_for_each_tight(hs, NULL, NULL, 0);\r\n}\r\nstatic int\r\ncfs_hash_for_each_relax(struct cfs_hash *hs, cfs_hash_for_each_cb_t func, void *data)\r\n{\r\nstruct hlist_node *hnode;\r\nstruct hlist_node *tmp;\r\nstruct cfs_hash_bd bd;\r\n__u32 version;\r\nint count = 0;\r\nint stop_on_change;\r\nint rc;\r\nint i;\r\nstop_on_change = cfs_hash_with_rehash_key(hs) ||\r\n!cfs_hash_with_no_itemref(hs) ||\r\nCFS_HOP(hs, put_locked) == NULL;\r\ncfs_hash_lock(hs, 0);\r\nLASSERT(!cfs_hash_is_rehashing(hs));\r\ncfs_hash_for_each_bucket(hs, &bd, i) {\r\nstruct hlist_head *hhead;\r\ncfs_hash_bd_lock(hs, &bd, 0);\r\nversion = cfs_hash_bd_version_get(&bd);\r\ncfs_hash_bd_for_each_hlist(hs, &bd, hhead) {\r\nfor (hnode = hhead->first; hnode != NULL;) {\r\ncfs_hash_bucket_validate(hs, &bd, hnode);\r\ncfs_hash_get(hs, hnode);\r\ncfs_hash_bd_unlock(hs, &bd, 0);\r\ncfs_hash_unlock(hs, 0);\r\nrc = func(hs, &bd, hnode, data);\r\nif (stop_on_change)\r\ncfs_hash_put(hs, hnode);\r\ncond_resched();\r\ncount++;\r\ncfs_hash_lock(hs, 0);\r\ncfs_hash_bd_lock(hs, &bd, 0);\r\nif (!stop_on_change) {\r\ntmp = hnode->next;\r\ncfs_hash_put_locked(hs, hnode);\r\nhnode = tmp;\r\n} else {\r\nif (version !=\r\ncfs_hash_bd_version_get(&bd))\r\nbreak;\r\nhnode = hnode->next;\r\n}\r\nif (rc)\r\nbreak;\r\n}\r\n}\r\ncfs_hash_bd_unlock(hs, &bd, 0);\r\n}\r\ncfs_hash_unlock(hs, 0);\r\nreturn count;\r\n}\r\nint\r\ncfs_hash_for_each_nolock(struct cfs_hash *hs,\r\ncfs_hash_for_each_cb_t func, void *data)\r\n{\r\nif (cfs_hash_with_no_lock(hs) ||\r\ncfs_hash_with_rehash_key(hs) ||\r\n!cfs_hash_with_no_itemref(hs))\r\nreturn -EOPNOTSUPP;\r\nif (CFS_HOP(hs, get) == NULL ||\r\n(CFS_HOP(hs, put) == NULL &&\r\nCFS_HOP(hs, put_locked) == NULL))\r\nreturn -EOPNOTSUPP;\r\ncfs_hash_for_each_enter(hs);\r\ncfs_hash_for_each_relax(hs, func, data);\r\ncfs_hash_for_each_exit(hs);\r\nreturn 0;\r\n}\r\nint\r\ncfs_hash_for_each_empty(struct cfs_hash *hs,\r\ncfs_hash_for_each_cb_t func, void *data)\r\n{\r\nunsigned i = 0;\r\nif (cfs_hash_with_no_lock(hs))\r\nreturn -EOPNOTSUPP;\r\nif (CFS_HOP(hs, get) == NULL ||\r\n(CFS_HOP(hs, put) == NULL &&\r\nCFS_HOP(hs, put_locked) == NULL))\r\nreturn -EOPNOTSUPP;\r\ncfs_hash_for_each_enter(hs);\r\nwhile (cfs_hash_for_each_relax(hs, func, data)) {\r\nCDEBUG(D_INFO, "Try to empty hash: %s, loop: %u\n",\r\nhs->hs_name, i++);\r\n}\r\ncfs_hash_for_each_exit(hs);\r\nreturn 0;\r\n}\r\nvoid\r\ncfs_hash_hlist_for_each(struct cfs_hash *hs, unsigned hindex,\r\ncfs_hash_for_each_cb_t func, void *data)\r\n{\r\nstruct hlist_head *hhead;\r\nstruct hlist_node *hnode;\r\nstruct cfs_hash_bd bd;\r\ncfs_hash_for_each_enter(hs);\r\ncfs_hash_lock(hs, 0);\r\nif (hindex >= CFS_HASH_NHLIST(hs))\r\ngoto out;\r\ncfs_hash_bd_index_set(hs, hindex, &bd);\r\ncfs_hash_bd_lock(hs, &bd, 0);\r\nhhead = cfs_hash_bd_hhead(hs, &bd);\r\nhlist_for_each(hnode, hhead) {\r\nif (func(hs, &bd, hnode, data))\r\nbreak;\r\n}\r\ncfs_hash_bd_unlock(hs, &bd, 0);\r\nout:\r\ncfs_hash_unlock(hs, 0);\r\ncfs_hash_for_each_exit(hs);\r\n}\r\nvoid\r\ncfs_hash_for_each_key(struct cfs_hash *hs, const void *key,\r\ncfs_hash_for_each_cb_t func, void *data)\r\n{\r\nstruct hlist_node *hnode;\r\nstruct cfs_hash_bd bds[2];\r\nunsigned i;\r\ncfs_hash_lock(hs, 0);\r\ncfs_hash_dual_bd_get_and_lock(hs, key, bds, 0);\r\ncfs_hash_for_each_bd(bds, 2, i) {\r\nstruct hlist_head *hlist = cfs_hash_bd_hhead(hs, &bds[i]);\r\nhlist_for_each(hnode, hlist) {\r\ncfs_hash_bucket_validate(hs, &bds[i], hnode);\r\nif (cfs_hash_keycmp(hs, key, hnode)) {\r\nif (func(hs, &bds[i], hnode, data))\r\nbreak;\r\n}\r\n}\r\n}\r\ncfs_hash_dual_bd_unlock(hs, bds, 0);\r\ncfs_hash_unlock(hs, 0);\r\n}\r\nvoid\r\ncfs_hash_rehash_cancel_locked(struct cfs_hash *hs)\r\n{\r\nint i;\r\nLASSERT(cfs_hash_with_rehash(hs) &&\r\n!cfs_hash_with_no_lock(hs));\r\nif (!cfs_hash_is_rehashing(hs))\r\nreturn;\r\nif (cfs_wi_deschedule(cfs_sched_rehash, &hs->hs_rehash_wi)) {\r\nhs->hs_rehash_bits = 0;\r\nreturn;\r\n}\r\nfor (i = 2; cfs_hash_is_rehashing(hs); i++) {\r\ncfs_hash_unlock(hs, 1);\r\nCDEBUG(IS_PO2(i >> 3) ? D_WARNING : D_INFO,\r\n"hash %s is still rehashing, rescheded %d\n",\r\nhs->hs_name, i - 1);\r\ncond_resched();\r\ncfs_hash_lock(hs, 1);\r\n}\r\n}\r\nvoid\r\ncfs_hash_rehash_cancel(struct cfs_hash *hs)\r\n{\r\ncfs_hash_lock(hs, 1);\r\ncfs_hash_rehash_cancel_locked(hs);\r\ncfs_hash_unlock(hs, 1);\r\n}\r\nint\r\ncfs_hash_rehash(struct cfs_hash *hs, int do_rehash)\r\n{\r\nint rc;\r\nLASSERT(cfs_hash_with_rehash(hs) && !cfs_hash_with_no_lock(hs));\r\ncfs_hash_lock(hs, 1);\r\nrc = cfs_hash_rehash_bits(hs);\r\nif (rc <= 0) {\r\ncfs_hash_unlock(hs, 1);\r\nreturn rc;\r\n}\r\nhs->hs_rehash_bits = rc;\r\nif (!do_rehash) {\r\ncfs_wi_schedule(cfs_sched_rehash, &hs->hs_rehash_wi);\r\ncfs_hash_unlock(hs, 1);\r\nreturn 0;\r\n}\r\ncfs_hash_unlock(hs, 1);\r\nreturn cfs_hash_rehash_worker(&hs->hs_rehash_wi);\r\n}\r\nstatic int\r\ncfs_hash_rehash_bd(struct cfs_hash *hs, struct cfs_hash_bd *old)\r\n{\r\nstruct cfs_hash_bd new;\r\nstruct hlist_head *hhead;\r\nstruct hlist_node *hnode;\r\nstruct hlist_node *pos;\r\nvoid *key;\r\nint c = 0;\r\ncfs_hash_bd_for_each_hlist(hs, old, hhead) {\r\nhlist_for_each_safe(hnode, pos, hhead) {\r\nkey = cfs_hash_key(hs, hnode);\r\nLASSERT(key != NULL);\r\ncfs_hash_bucket_validate(hs, old, hnode);\r\ncfs_hash_bd_from_key(hs, hs->hs_rehash_buckets,\r\nhs->hs_rehash_bits, key, &new);\r\ncfs_hash_bd_move_locked(hs, old, &new, hnode);\r\nc++;\r\n}\r\n}\r\nreturn c;\r\n}\r\nstatic int\r\ncfs_hash_rehash_worker(cfs_workitem_t *wi)\r\n{\r\nstruct cfs_hash *hs = container_of(wi, struct cfs_hash, hs_rehash_wi);\r\nstruct cfs_hash_bucket **bkts;\r\nstruct cfs_hash_bd bd;\r\nunsigned int old_size;\r\nunsigned int new_size;\r\nint bsize;\r\nint count = 0;\r\nint rc = 0;\r\nint i;\r\nLASSERT (hs != NULL && cfs_hash_with_rehash(hs));\r\ncfs_hash_lock(hs, 0);\r\nLASSERT(cfs_hash_is_rehashing(hs));\r\nold_size = CFS_HASH_NBKT(hs);\r\nnew_size = CFS_HASH_RH_NBKT(hs);\r\ncfs_hash_unlock(hs, 0);\r\nbkts = cfs_hash_buckets_realloc(hs, hs->hs_buckets,\r\nold_size, new_size);\r\ncfs_hash_lock(hs, 1);\r\nif (bkts == NULL) {\r\nrc = -ENOMEM;\r\ngoto out;\r\n}\r\nif (bkts == hs->hs_buckets) {\r\nbkts = NULL;\r\ngoto out;\r\n}\r\nrc = __cfs_hash_theta(hs);\r\nif ((rc >= hs->hs_min_theta) && (rc <= hs->hs_max_theta)) {\r\nold_size = new_size;\r\nnew_size = CFS_HASH_NBKT(hs);\r\nrc = -EALREADY;\r\ngoto out;\r\n}\r\nLASSERT(hs->hs_rehash_buckets == NULL);\r\nhs->hs_rehash_buckets = bkts;\r\nrc = 0;\r\ncfs_hash_for_each_bucket(hs, &bd, i) {\r\nif (cfs_hash_is_exiting(hs)) {\r\nrc = -ESRCH;\r\nif (old_size < new_size)\r\nbreak;\r\nhs->hs_rehash_buckets = NULL;\r\nold_size = new_size;\r\nnew_size = CFS_HASH_NBKT(hs);\r\ngoto out;\r\n}\r\ncount += cfs_hash_rehash_bd(hs, &bd);\r\nif (count < CFS_HASH_LOOP_HOG ||\r\ncfs_hash_is_iterating(hs)) {\r\ncontinue;\r\n}\r\ncount = 0;\r\ncfs_hash_unlock(hs, 1);\r\ncond_resched();\r\ncfs_hash_lock(hs, 1);\r\n}\r\nhs->hs_rehash_count++;\r\nbkts = hs->hs_buckets;\r\nhs->hs_buckets = hs->hs_rehash_buckets;\r\nhs->hs_rehash_buckets = NULL;\r\nhs->hs_cur_bits = hs->hs_rehash_bits;\r\nout:\r\nhs->hs_rehash_bits = 0;\r\nif (rc == -ESRCH)\r\ncfs_wi_exit(cfs_sched_rehash, wi);\r\nbsize = cfs_hash_bkt_size(hs);\r\ncfs_hash_unlock(hs, 1);\r\nif (bkts != NULL)\r\ncfs_hash_buckets_free(bkts, bsize, new_size, old_size);\r\nif (rc != 0)\r\nCDEBUG(D_INFO, "early quit of rehashing: %d\n", rc);\r\nreturn rc == -ESRCH;\r\n}\r\nvoid cfs_hash_rehash_key(struct cfs_hash *hs, const void *old_key,\r\nvoid *new_key, struct hlist_node *hnode)\r\n{\r\nstruct cfs_hash_bd bds[3];\r\nstruct cfs_hash_bd old_bds[2];\r\nstruct cfs_hash_bd new_bd;\r\nLASSERT(!hlist_unhashed(hnode));\r\ncfs_hash_lock(hs, 0);\r\ncfs_hash_dual_bd_get(hs, old_key, old_bds);\r\ncfs_hash_bd_get(hs, new_key, &new_bd);\r\nbds[0] = old_bds[0];\r\nbds[1] = old_bds[1];\r\nbds[2] = new_bd;\r\ncfs_hash_bd_order(&bds[1], &bds[2]);\r\ncfs_hash_bd_order(&bds[0], &bds[1]);\r\ncfs_hash_multi_bd_lock(hs, bds, 3, 1);\r\nif (likely(old_bds[1].bd_bucket == NULL)) {\r\ncfs_hash_bd_move_locked(hs, &old_bds[0], &new_bd, hnode);\r\n} else {\r\ncfs_hash_dual_bd_finddel_locked(hs, old_bds, old_key, hnode);\r\ncfs_hash_bd_add_locked(hs, &new_bd, hnode);\r\n}\r\ncfs_hash_keycpy(hs, new_key, hnode);\r\ncfs_hash_multi_bd_unlock(hs, bds, 3, 1);\r\ncfs_hash_unlock(hs, 0);\r\n}\r\nint cfs_hash_debug_header(struct seq_file *m)\r\n{\r\nreturn seq_printf(m, "%-*s%6s%6s%6s%6s%6s%6s%6s%7s%8s%8s%8s%s\n",\r\nCFS_HASH_BIGNAME_LEN,\r\n"name", "cur", "min", "max", "theta", "t-min", "t-max",\r\n"flags", "rehash", "count", "maxdep", "maxdepb",\r\n" distribution");\r\n}\r\nstatic struct cfs_hash_bucket **\r\ncfs_hash_full_bkts(struct cfs_hash *hs)\r\n{\r\nif (hs->hs_rehash_buckets == NULL)\r\nreturn hs->hs_buckets;\r\nLASSERT(hs->hs_rehash_bits != 0);\r\nreturn hs->hs_rehash_bits > hs->hs_cur_bits ?\r\nhs->hs_rehash_buckets : hs->hs_buckets;\r\n}\r\nstatic unsigned int\r\ncfs_hash_full_nbkt(struct cfs_hash *hs)\r\n{\r\nif (hs->hs_rehash_buckets == NULL)\r\nreturn CFS_HASH_NBKT(hs);\r\nLASSERT(hs->hs_rehash_bits != 0);\r\nreturn hs->hs_rehash_bits > hs->hs_cur_bits ?\r\nCFS_HASH_RH_NBKT(hs) : CFS_HASH_NBKT(hs);\r\n}\r\nint cfs_hash_debug_str(struct cfs_hash *hs, struct seq_file *m)\r\n{\r\nint dist[8] = { 0, };\r\nint maxdep = -1;\r\nint maxdepb = -1;\r\nint total = 0;\r\nint theta;\r\nint i;\r\ncfs_hash_lock(hs, 0);\r\ntheta = __cfs_hash_theta(hs);\r\nseq_printf(m, "%-*s %5d %5d %5d %d.%03d %d.%03d %d.%03d 0x%02x %6d ",\r\nCFS_HASH_BIGNAME_LEN, hs->hs_name,\r\n1 << hs->hs_cur_bits, 1 << hs->hs_min_bits,\r\n1 << hs->hs_max_bits,\r\n__cfs_hash_theta_int(theta), __cfs_hash_theta_frac(theta),\r\n__cfs_hash_theta_int(hs->hs_min_theta),\r\n__cfs_hash_theta_frac(hs->hs_min_theta),\r\n__cfs_hash_theta_int(hs->hs_max_theta),\r\n__cfs_hash_theta_frac(hs->hs_max_theta),\r\nhs->hs_flags, hs->hs_rehash_count);\r\nfor (i = 0; i < cfs_hash_full_nbkt(hs); i++) {\r\nstruct cfs_hash_bd bd;\r\nbd.bd_bucket = cfs_hash_full_bkts(hs)[i];\r\ncfs_hash_bd_lock(hs, &bd, 0);\r\nif (maxdep < bd.bd_bucket->hsb_depmax) {\r\nmaxdep = bd.bd_bucket->hsb_depmax;\r\nmaxdepb = ffz(~maxdep);\r\n}\r\ntotal += bd.bd_bucket->hsb_count;\r\ndist[min(__cfs_fls(bd.bd_bucket->hsb_count/max(theta,1)),7)]++;\r\ncfs_hash_bd_unlock(hs, &bd, 0);\r\n}\r\nseq_printf(m, "%7d %7d %7d ", total, maxdep, maxdepb);\r\nfor (i = 0; i < 8; i++)\r\nseq_printf(m, "%d%c", dist[i], (i == 7) ? '\n' : '/');\r\ncfs_hash_unlock(hs, 0);\r\nreturn 0;\r\n}
