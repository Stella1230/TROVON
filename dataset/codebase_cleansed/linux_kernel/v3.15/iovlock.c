static int num_pages_spanned(struct iovec *iov)\r\n{\r\nreturn\r\n((PAGE_ALIGN((unsigned long)iov->iov_base + iov->iov_len) -\r\n((unsigned long)iov->iov_base & PAGE_MASK)) >> PAGE_SHIFT);\r\n}\r\nstruct dma_pinned_list *dma_pin_iovec_pages(struct iovec *iov, size_t len)\r\n{\r\nstruct dma_pinned_list *local_list;\r\nstruct page **pages;\r\nint i;\r\nint ret;\r\nint nr_iovecs = 0;\r\nint iovec_len_used = 0;\r\nint iovec_pages_used = 0;\r\nif (segment_eq(get_fs(), KERNEL_DS))\r\nreturn NULL;\r\ndo {\r\niovec_len_used += iov[nr_iovecs].iov_len;\r\niovec_pages_used += num_pages_spanned(&iov[nr_iovecs]);\r\nnr_iovecs++;\r\n} while (iovec_len_used < len);\r\nlocal_list = kmalloc(sizeof(*local_list)\r\n+ (nr_iovecs * sizeof (struct dma_page_list))\r\n+ (iovec_pages_used * sizeof (struct page*)), GFP_KERNEL);\r\nif (!local_list)\r\ngoto out;\r\npages = (struct page **) &local_list->page_list[nr_iovecs];\r\nlocal_list->nr_iovecs = 0;\r\nfor (i = 0; i < nr_iovecs; i++) {\r\nstruct dma_page_list *page_list = &local_list->page_list[i];\r\nlen -= iov[i].iov_len;\r\nif (!access_ok(VERIFY_WRITE, iov[i].iov_base, iov[i].iov_len))\r\ngoto unpin;\r\npage_list->nr_pages = num_pages_spanned(&iov[i]);\r\npage_list->base_address = iov[i].iov_base;\r\npage_list->pages = pages;\r\npages += page_list->nr_pages;\r\ndown_read(&current->mm->mmap_sem);\r\nret = get_user_pages(\r\ncurrent,\r\ncurrent->mm,\r\n(unsigned long) iov[i].iov_base,\r\npage_list->nr_pages,\r\n1,\r\n0,\r\npage_list->pages,\r\nNULL);\r\nup_read(&current->mm->mmap_sem);\r\nif (ret != page_list->nr_pages)\r\ngoto unpin;\r\nlocal_list->nr_iovecs = i + 1;\r\n}\r\nreturn local_list;\r\nunpin:\r\ndma_unpin_iovec_pages(local_list);\r\nout:\r\nreturn NULL;\r\n}\r\nvoid dma_unpin_iovec_pages(struct dma_pinned_list *pinned_list)\r\n{\r\nint i, j;\r\nif (!pinned_list)\r\nreturn;\r\nfor (i = 0; i < pinned_list->nr_iovecs; i++) {\r\nstruct dma_page_list *page_list = &pinned_list->page_list[i];\r\nfor (j = 0; j < page_list->nr_pages; j++) {\r\nset_page_dirty_lock(page_list->pages[j]);\r\npage_cache_release(page_list->pages[j]);\r\n}\r\n}\r\nkfree(pinned_list);\r\n}\r\ndma_cookie_t dma_memcpy_to_iovec(struct dma_chan *chan, struct iovec *iov,\r\nstruct dma_pinned_list *pinned_list, unsigned char *kdata, size_t len)\r\n{\r\nint iov_byte_offset;\r\nint copy;\r\ndma_cookie_t dma_cookie = 0;\r\nint iovec_idx;\r\nint page_idx;\r\nif (!chan)\r\nreturn memcpy_toiovec(iov, kdata, len);\r\niovec_idx = 0;\r\nwhile (iovec_idx < pinned_list->nr_iovecs) {\r\nstruct dma_page_list *page_list;\r\nwhile (!iov[iovec_idx].iov_len)\r\niovec_idx++;\r\npage_list = &pinned_list->page_list[iovec_idx];\r\niov_byte_offset = ((unsigned long)iov[iovec_idx].iov_base & ~PAGE_MASK);\r\npage_idx = (((unsigned long)iov[iovec_idx].iov_base & PAGE_MASK)\r\n- ((unsigned long)page_list->base_address & PAGE_MASK)) >> PAGE_SHIFT;\r\nwhile (iov[iovec_idx].iov_len) {\r\ncopy = min_t(int, PAGE_SIZE - iov_byte_offset, len);\r\ncopy = min_t(int, copy, iov[iovec_idx].iov_len);\r\ndma_cookie = dma_async_memcpy_buf_to_pg(chan,\r\npage_list->pages[page_idx],\r\niov_byte_offset,\r\nkdata,\r\ncopy);\r\nif (unlikely(dma_cookie < 0)) {\r\ndma_async_issue_pending(chan);\r\ncontinue;\r\n}\r\nlen -= copy;\r\niov[iovec_idx].iov_len -= copy;\r\niov[iovec_idx].iov_base += copy;\r\nif (!len)\r\nreturn dma_cookie;\r\nkdata += copy;\r\niov_byte_offset = 0;\r\npage_idx++;\r\n}\r\niovec_idx++;\r\n}\r\nBUG();\r\nreturn -EFAULT;\r\n}\r\ndma_cookie_t dma_memcpy_pg_to_iovec(struct dma_chan *chan, struct iovec *iov,\r\nstruct dma_pinned_list *pinned_list, struct page *page,\r\nunsigned int offset, size_t len)\r\n{\r\nint iov_byte_offset;\r\nint copy;\r\ndma_cookie_t dma_cookie = 0;\r\nint iovec_idx;\r\nint page_idx;\r\nint err;\r\nif (!chan || !pinned_list) {\r\nu8 *vaddr = kmap(page);\r\nerr = memcpy_toiovec(iov, vaddr + offset, len);\r\nkunmap(page);\r\nreturn err;\r\n}\r\niovec_idx = 0;\r\nwhile (iovec_idx < pinned_list->nr_iovecs) {\r\nstruct dma_page_list *page_list;\r\nwhile (!iov[iovec_idx].iov_len)\r\niovec_idx++;\r\npage_list = &pinned_list->page_list[iovec_idx];\r\niov_byte_offset = ((unsigned long)iov[iovec_idx].iov_base & ~PAGE_MASK);\r\npage_idx = (((unsigned long)iov[iovec_idx].iov_base & PAGE_MASK)\r\n- ((unsigned long)page_list->base_address & PAGE_MASK)) >> PAGE_SHIFT;\r\nwhile (iov[iovec_idx].iov_len) {\r\ncopy = min_t(int, PAGE_SIZE - iov_byte_offset, len);\r\ncopy = min_t(int, copy, iov[iovec_idx].iov_len);\r\ndma_cookie = dma_async_memcpy_pg_to_pg(chan,\r\npage_list->pages[page_idx],\r\niov_byte_offset,\r\npage,\r\noffset,\r\ncopy);\r\nif (unlikely(dma_cookie < 0)) {\r\ndma_async_issue_pending(chan);\r\ncontinue;\r\n}\r\nlen -= copy;\r\niov[iovec_idx].iov_len -= copy;\r\niov[iovec_idx].iov_base += copy;\r\nif (!len)\r\nreturn dma_cookie;\r\noffset += copy;\r\niov_byte_offset = 0;\r\npage_idx++;\r\n}\r\niovec_idx++;\r\n}\r\nBUG();\r\nreturn -EFAULT;\r\n}
