static int vfio_pci_enable(struct vfio_pci_device *vdev)\r\n{\r\nstruct pci_dev *pdev = vdev->pdev;\r\nint ret;\r\nu16 cmd;\r\nu8 msix_pos;\r\nret = pci_enable_device(pdev);\r\nif (ret)\r\nreturn ret;\r\nvdev->reset_works = (pci_reset_function(pdev) == 0);\r\npci_save_state(pdev);\r\nvdev->pci_saved_state = pci_store_saved_state(pdev);\r\nif (!vdev->pci_saved_state)\r\npr_debug("%s: Couldn't store %s saved state\n",\r\n__func__, dev_name(&pdev->dev));\r\nret = vfio_config_init(vdev);\r\nif (ret) {\r\npci_load_and_free_saved_state(pdev, &vdev->pci_saved_state);\r\npci_disable_device(pdev);\r\nreturn ret;\r\n}\r\nif (likely(!nointxmask))\r\nvdev->pci_2_3 = pci_intx_mask_supported(pdev);\r\npci_read_config_word(pdev, PCI_COMMAND, &cmd);\r\nif (vdev->pci_2_3 && (cmd & PCI_COMMAND_INTX_DISABLE)) {\r\ncmd &= ~PCI_COMMAND_INTX_DISABLE;\r\npci_write_config_word(pdev, PCI_COMMAND, cmd);\r\n}\r\nmsix_pos = pdev->msix_cap;\r\nif (msix_pos) {\r\nu16 flags;\r\nu32 table;\r\npci_read_config_word(pdev, msix_pos + PCI_MSIX_FLAGS, &flags);\r\npci_read_config_dword(pdev, msix_pos + PCI_MSIX_TABLE, &table);\r\nvdev->msix_bar = table & PCI_MSIX_TABLE_BIR;\r\nvdev->msix_offset = table & PCI_MSIX_TABLE_OFFSET;\r\nvdev->msix_size = ((flags & PCI_MSIX_FLAGS_QSIZE) + 1) * 16;\r\n} else\r\nvdev->msix_bar = 0xFF;\r\n#ifdef CONFIG_VFIO_PCI_VGA\r\nif ((pdev->class >> 8) == PCI_CLASS_DISPLAY_VGA)\r\nvdev->has_vga = true;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void vfio_pci_disable(struct vfio_pci_device *vdev)\r\n{\r\nstruct pci_dev *pdev = vdev->pdev;\r\nint bar;\r\npci_disable_device(pdev);\r\nvfio_pci_set_irqs_ioctl(vdev, VFIO_IRQ_SET_DATA_NONE |\r\nVFIO_IRQ_SET_ACTION_TRIGGER,\r\nvdev->irq_type, 0, 0, NULL);\r\nvdev->virq_disabled = false;\r\nvfio_config_free(vdev);\r\nfor (bar = PCI_STD_RESOURCES; bar <= PCI_STD_RESOURCE_END; bar++) {\r\nif (!vdev->barmap[bar])\r\ncontinue;\r\npci_iounmap(pdev, vdev->barmap[bar]);\r\npci_release_selected_regions(pdev, 1 << bar);\r\nvdev->barmap[bar] = NULL;\r\n}\r\nif (pci_load_and_free_saved_state(pdev, &vdev->pci_saved_state)) {\r\npr_info("%s: Couldn't reload %s saved state\n",\r\n__func__, dev_name(&pdev->dev));\r\nif (!vdev->reset_works)\r\nreturn;\r\npci_save_state(pdev);\r\n}\r\npci_write_config_word(pdev, PCI_COMMAND, PCI_COMMAND_INTX_DISABLE);\r\nif (vdev->reset_works) {\r\nint ret = pci_try_reset_function(pdev);\r\nif (ret)\r\npr_warn("%s: Failed to reset device %s (%d)\n",\r\n__func__, dev_name(&pdev->dev), ret);\r\n}\r\npci_restore_state(pdev);\r\n}\r\nstatic void vfio_pci_release(void *device_data)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nif (atomic_dec_and_test(&vdev->refcnt))\r\nvfio_pci_disable(vdev);\r\nmodule_put(THIS_MODULE);\r\n}\r\nstatic int vfio_pci_open(void *device_data)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nif (!try_module_get(THIS_MODULE))\r\nreturn -ENODEV;\r\nif (atomic_inc_return(&vdev->refcnt) == 1) {\r\nint ret = vfio_pci_enable(vdev);\r\nif (ret) {\r\nmodule_put(THIS_MODULE);\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int vfio_pci_get_irq_count(struct vfio_pci_device *vdev, int irq_type)\r\n{\r\nif (irq_type == VFIO_PCI_INTX_IRQ_INDEX) {\r\nu8 pin;\r\npci_read_config_byte(vdev->pdev, PCI_INTERRUPT_PIN, &pin);\r\nif (pin)\r\nreturn 1;\r\n} else if (irq_type == VFIO_PCI_MSI_IRQ_INDEX) {\r\nu8 pos;\r\nu16 flags;\r\npos = vdev->pdev->msi_cap;\r\nif (pos) {\r\npci_read_config_word(vdev->pdev,\r\npos + PCI_MSI_FLAGS, &flags);\r\nreturn 1 << (flags & PCI_MSI_FLAGS_QMASK);\r\n}\r\n} else if (irq_type == VFIO_PCI_MSIX_IRQ_INDEX) {\r\nu8 pos;\r\nu16 flags;\r\npos = vdev->pdev->msix_cap;\r\nif (pos) {\r\npci_read_config_word(vdev->pdev,\r\npos + PCI_MSIX_FLAGS, &flags);\r\nreturn (flags & PCI_MSIX_FLAGS_QSIZE) + 1;\r\n}\r\n} else if (irq_type == VFIO_PCI_ERR_IRQ_INDEX)\r\nif (pci_is_pcie(vdev->pdev))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int vfio_pci_count_devs(struct pci_dev *pdev, void *data)\r\n{\r\n(*(int *)data)++;\r\nreturn 0;\r\n}\r\nstatic int vfio_pci_fill_devs(struct pci_dev *pdev, void *data)\r\n{\r\nstruct vfio_pci_fill_info *fill = data;\r\nstruct iommu_group *iommu_group;\r\nif (fill->cur == fill->max)\r\nreturn -EAGAIN;\r\niommu_group = iommu_group_get(&pdev->dev);\r\nif (!iommu_group)\r\nreturn -EPERM;\r\nfill->devices[fill->cur].group_id = iommu_group_id(iommu_group);\r\nfill->devices[fill->cur].segment = pci_domain_nr(pdev->bus);\r\nfill->devices[fill->cur].bus = pdev->bus->number;\r\nfill->devices[fill->cur].devfn = pdev->devfn;\r\nfill->cur++;\r\niommu_group_put(iommu_group);\r\nreturn 0;\r\n}\r\nstatic int vfio_pci_validate_devs(struct pci_dev *pdev, void *data)\r\n{\r\nstruct vfio_pci_group_info *info = data;\r\nstruct iommu_group *group;\r\nint id, i;\r\ngroup = iommu_group_get(&pdev->dev);\r\nif (!group)\r\nreturn -EPERM;\r\nid = iommu_group_id(group);\r\nfor (i = 0; i < info->count; i++)\r\nif (info->groups[i].id == id)\r\nbreak;\r\niommu_group_put(group);\r\nreturn (i == info->count) ? -EINVAL : 0;\r\n}\r\nstatic bool vfio_pci_dev_below_slot(struct pci_dev *pdev, struct pci_slot *slot)\r\n{\r\nfor (; pdev; pdev = pdev->bus->self)\r\nif (pdev->bus == slot->bus)\r\nreturn (pdev->slot == slot);\r\nreturn false;\r\n}\r\nstatic int vfio_pci_walk_wrapper(struct pci_dev *pdev, void *data)\r\n{\r\nstruct vfio_pci_walk_info *walk = data;\r\nif (!walk->slot || vfio_pci_dev_below_slot(pdev, walk->pdev->slot))\r\nwalk->ret = walk->fn(pdev, walk->data);\r\nreturn walk->ret;\r\n}\r\nstatic int vfio_pci_for_each_slot_or_bus(struct pci_dev *pdev,\r\nint (*fn)(struct pci_dev *,\r\nvoid *data), void *data,\r\nbool slot)\r\n{\r\nstruct vfio_pci_walk_info walk = {\r\n.fn = fn, .data = data, .pdev = pdev, .slot = slot, .ret = 0,\r\n};\r\npci_walk_bus(pdev->bus, vfio_pci_walk_wrapper, &walk);\r\nreturn walk.ret;\r\n}\r\nstatic long vfio_pci_ioctl(void *device_data,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nunsigned long minsz;\r\nif (cmd == VFIO_DEVICE_GET_INFO) {\r\nstruct vfio_device_info info;\r\nminsz = offsetofend(struct vfio_device_info, num_irqs);\r\nif (copy_from_user(&info, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (info.argsz < minsz)\r\nreturn -EINVAL;\r\ninfo.flags = VFIO_DEVICE_FLAGS_PCI;\r\nif (vdev->reset_works)\r\ninfo.flags |= VFIO_DEVICE_FLAGS_RESET;\r\ninfo.num_regions = VFIO_PCI_NUM_REGIONS;\r\ninfo.num_irqs = VFIO_PCI_NUM_IRQS;\r\nreturn copy_to_user((void __user *)arg, &info, minsz);\r\n} else if (cmd == VFIO_DEVICE_GET_REGION_INFO) {\r\nstruct pci_dev *pdev = vdev->pdev;\r\nstruct vfio_region_info info;\r\nminsz = offsetofend(struct vfio_region_info, offset);\r\nif (copy_from_user(&info, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (info.argsz < minsz)\r\nreturn -EINVAL;\r\nswitch (info.index) {\r\ncase VFIO_PCI_CONFIG_REGION_INDEX:\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.size = pdev->cfg_size;\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\r\nVFIO_REGION_INFO_FLAG_WRITE;\r\nbreak;\r\ncase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.size = pci_resource_len(pdev, info.index);\r\nif (!info.size) {\r\ninfo.flags = 0;\r\nbreak;\r\n}\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\r\nVFIO_REGION_INFO_FLAG_WRITE;\r\nif (pci_resource_flags(pdev, info.index) &\r\nIORESOURCE_MEM && info.size >= PAGE_SIZE)\r\ninfo.flags |= VFIO_REGION_INFO_FLAG_MMAP;\r\nbreak;\r\ncase VFIO_PCI_ROM_REGION_INDEX:\r\n{\r\nvoid __iomem *io;\r\nsize_t size;\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.flags = 0;\r\ninfo.size = pci_resource_len(pdev, info.index);\r\nif (!info.size)\r\nbreak;\r\nio = pci_map_rom(pdev, &size);\r\nif (!io || !size) {\r\ninfo.size = 0;\r\nbreak;\r\n}\r\npci_unmap_rom(pdev, io);\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ;\r\nbreak;\r\n}\r\ncase VFIO_PCI_VGA_REGION_INDEX:\r\nif (!vdev->has_vga)\r\nreturn -EINVAL;\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.size = 0xc0000;\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\r\nVFIO_REGION_INFO_FLAG_WRITE;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn copy_to_user((void __user *)arg, &info, minsz);\r\n} else if (cmd == VFIO_DEVICE_GET_IRQ_INFO) {\r\nstruct vfio_irq_info info;\r\nminsz = offsetofend(struct vfio_irq_info, count);\r\nif (copy_from_user(&info, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (info.argsz < minsz || info.index >= VFIO_PCI_NUM_IRQS)\r\nreturn -EINVAL;\r\nswitch (info.index) {\r\ncase VFIO_PCI_INTX_IRQ_INDEX ... VFIO_PCI_MSIX_IRQ_INDEX:\r\nbreak;\r\ncase VFIO_PCI_ERR_IRQ_INDEX:\r\nif (pci_is_pcie(vdev->pdev))\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ninfo.flags = VFIO_IRQ_INFO_EVENTFD;\r\ninfo.count = vfio_pci_get_irq_count(vdev, info.index);\r\nif (info.index == VFIO_PCI_INTX_IRQ_INDEX)\r\ninfo.flags |= (VFIO_IRQ_INFO_MASKABLE |\r\nVFIO_IRQ_INFO_AUTOMASKED);\r\nelse\r\ninfo.flags |= VFIO_IRQ_INFO_NORESIZE;\r\nreturn copy_to_user((void __user *)arg, &info, minsz);\r\n} else if (cmd == VFIO_DEVICE_SET_IRQS) {\r\nstruct vfio_irq_set hdr;\r\nu8 *data = NULL;\r\nint ret = 0;\r\nminsz = offsetofend(struct vfio_irq_set, count);\r\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (hdr.argsz < minsz || hdr.index >= VFIO_PCI_NUM_IRQS ||\r\nhdr.flags & ~(VFIO_IRQ_SET_DATA_TYPE_MASK |\r\nVFIO_IRQ_SET_ACTION_TYPE_MASK))\r\nreturn -EINVAL;\r\nif (!(hdr.flags & VFIO_IRQ_SET_DATA_NONE)) {\r\nsize_t size;\r\nint max = vfio_pci_get_irq_count(vdev, hdr.index);\r\nif (hdr.flags & VFIO_IRQ_SET_DATA_BOOL)\r\nsize = sizeof(uint8_t);\r\nelse if (hdr.flags & VFIO_IRQ_SET_DATA_EVENTFD)\r\nsize = sizeof(int32_t);\r\nelse\r\nreturn -EINVAL;\r\nif (hdr.argsz - minsz < hdr.count * size ||\r\nhdr.start >= max || hdr.start + hdr.count > max)\r\nreturn -EINVAL;\r\ndata = memdup_user((void __user *)(arg + minsz),\r\nhdr.count * size);\r\nif (IS_ERR(data))\r\nreturn PTR_ERR(data);\r\n}\r\nmutex_lock(&vdev->igate);\r\nret = vfio_pci_set_irqs_ioctl(vdev, hdr.flags, hdr.index,\r\nhdr.start, hdr.count, data);\r\nmutex_unlock(&vdev->igate);\r\nkfree(data);\r\nreturn ret;\r\n} else if (cmd == VFIO_DEVICE_RESET) {\r\nreturn vdev->reset_works ?\r\npci_try_reset_function(vdev->pdev) : -EINVAL;\r\n} else if (cmd == VFIO_DEVICE_GET_PCI_HOT_RESET_INFO) {\r\nstruct vfio_pci_hot_reset_info hdr;\r\nstruct vfio_pci_fill_info fill = { 0 };\r\nstruct vfio_pci_dependent_device *devices = NULL;\r\nbool slot = false;\r\nint ret = 0;\r\nminsz = offsetofend(struct vfio_pci_hot_reset_info, count);\r\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (hdr.argsz < minsz)\r\nreturn -EINVAL;\r\nhdr.flags = 0;\r\nif (!pci_probe_reset_slot(vdev->pdev->slot))\r\nslot = true;\r\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\r\nreturn -ENODEV;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_count_devs,\r\n&fill.max, slot);\r\nif (ret)\r\nreturn ret;\r\nWARN_ON(!fill.max);\r\nif (hdr.argsz < sizeof(hdr) + (fill.max * sizeof(*devices))) {\r\nret = -ENOSPC;\r\nhdr.count = fill.max;\r\ngoto reset_info_exit;\r\n}\r\ndevices = kcalloc(fill.max, sizeof(*devices), GFP_KERNEL);\r\nif (!devices)\r\nreturn -ENOMEM;\r\nfill.devices = devices;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_fill_devs,\r\n&fill, slot);\r\nif (!ret)\r\nhdr.count = fill.cur;\r\nreset_info_exit:\r\nif (copy_to_user((void __user *)arg, &hdr, minsz))\r\nret = -EFAULT;\r\nif (!ret) {\r\nif (copy_to_user((void __user *)(arg + minsz), devices,\r\nhdr.count * sizeof(*devices)))\r\nret = -EFAULT;\r\n}\r\nkfree(devices);\r\nreturn ret;\r\n} else if (cmd == VFIO_DEVICE_PCI_HOT_RESET) {\r\nstruct vfio_pci_hot_reset hdr;\r\nint32_t *group_fds;\r\nstruct vfio_pci_group_entry *groups;\r\nstruct vfio_pci_group_info info;\r\nbool slot = false;\r\nint i, count = 0, ret = 0;\r\nminsz = offsetofend(struct vfio_pci_hot_reset, count);\r\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (hdr.argsz < minsz || hdr.flags)\r\nreturn -EINVAL;\r\nif (!pci_probe_reset_slot(vdev->pdev->slot))\r\nslot = true;\r\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\r\nreturn -ENODEV;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_count_devs,\r\n&count, slot);\r\nif (ret)\r\nreturn ret;\r\nif (!hdr.count || hdr.count > count)\r\nreturn -EINVAL;\r\ngroup_fds = kcalloc(hdr.count, sizeof(*group_fds), GFP_KERNEL);\r\ngroups = kcalloc(hdr.count, sizeof(*groups), GFP_KERNEL);\r\nif (!group_fds || !groups) {\r\nkfree(group_fds);\r\nkfree(groups);\r\nreturn -ENOMEM;\r\n}\r\nif (copy_from_user(group_fds, (void __user *)(arg + minsz),\r\nhdr.count * sizeof(*group_fds))) {\r\nkfree(group_fds);\r\nkfree(groups);\r\nreturn -EFAULT;\r\n}\r\nfor (i = 0; i < hdr.count; i++) {\r\nstruct vfio_group *group;\r\nstruct fd f = fdget(group_fds[i]);\r\nif (!f.file) {\r\nret = -EBADF;\r\nbreak;\r\n}\r\ngroup = vfio_group_get_external_user(f.file);\r\nfdput(f);\r\nif (IS_ERR(group)) {\r\nret = PTR_ERR(group);\r\nbreak;\r\n}\r\ngroups[i].group = group;\r\ngroups[i].id = vfio_external_user_iommu_id(group);\r\n}\r\nkfree(group_fds);\r\nif (ret)\r\ngoto hot_reset_release;\r\ninfo.count = hdr.count;\r\ninfo.groups = groups;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_validate_devs,\r\n&info, slot);\r\nif (!ret)\r\nret = slot ? pci_try_reset_slot(vdev->pdev->slot) :\r\npci_try_reset_bus(vdev->pdev->bus);\r\nhot_reset_release:\r\nfor (i--; i >= 0; i--)\r\nvfio_group_put_external_user(groups[i].group);\r\nkfree(groups);\r\nreturn ret;\r\n}\r\nreturn -ENOTTY;\r\n}\r\nstatic ssize_t vfio_pci_rw(void *device_data, char __user *buf,\r\nsize_t count, loff_t *ppos, bool iswrite)\r\n{\r\nunsigned int index = VFIO_PCI_OFFSET_TO_INDEX(*ppos);\r\nstruct vfio_pci_device *vdev = device_data;\r\nif (index >= VFIO_PCI_NUM_REGIONS)\r\nreturn -EINVAL;\r\nswitch (index) {\r\ncase VFIO_PCI_CONFIG_REGION_INDEX:\r\nreturn vfio_pci_config_rw(vdev, buf, count, ppos, iswrite);\r\ncase VFIO_PCI_ROM_REGION_INDEX:\r\nif (iswrite)\r\nreturn -EINVAL;\r\nreturn vfio_pci_bar_rw(vdev, buf, count, ppos, false);\r\ncase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\r\nreturn vfio_pci_bar_rw(vdev, buf, count, ppos, iswrite);\r\ncase VFIO_PCI_VGA_REGION_INDEX:\r\nreturn vfio_pci_vga_rw(vdev, buf, count, ppos, iswrite);\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic ssize_t vfio_pci_read(void *device_data, char __user *buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nif (!count)\r\nreturn 0;\r\nreturn vfio_pci_rw(device_data, buf, count, ppos, false);\r\n}\r\nstatic ssize_t vfio_pci_write(void *device_data, const char __user *buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nif (!count)\r\nreturn 0;\r\nreturn vfio_pci_rw(device_data, (char __user *)buf, count, ppos, true);\r\n}\r\nstatic int vfio_pci_mmap(void *device_data, struct vm_area_struct *vma)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nstruct pci_dev *pdev = vdev->pdev;\r\nunsigned int index;\r\nu64 phys_len, req_len, pgoff, req_start;\r\nint ret;\r\nindex = vma->vm_pgoff >> (VFIO_PCI_OFFSET_SHIFT - PAGE_SHIFT);\r\nif (vma->vm_end < vma->vm_start)\r\nreturn -EINVAL;\r\nif ((vma->vm_flags & VM_SHARED) == 0)\r\nreturn -EINVAL;\r\nif (index >= VFIO_PCI_ROM_REGION_INDEX)\r\nreturn -EINVAL;\r\nif (!(pci_resource_flags(pdev, index) & IORESOURCE_MEM))\r\nreturn -EINVAL;\r\nphys_len = pci_resource_len(pdev, index);\r\nreq_len = vma->vm_end - vma->vm_start;\r\npgoff = vma->vm_pgoff &\r\n((1U << (VFIO_PCI_OFFSET_SHIFT - PAGE_SHIFT)) - 1);\r\nreq_start = pgoff << PAGE_SHIFT;\r\nif (phys_len < PAGE_SIZE || req_start + req_len > phys_len)\r\nreturn -EINVAL;\r\nif (index == vdev->msix_bar) {\r\nif (!(req_start >= vdev->msix_offset + vdev->msix_size ||\r\nreq_start + req_len <= vdev->msix_offset))\r\nreturn -EINVAL;\r\n}\r\nif (!vdev->barmap[index]) {\r\nret = pci_request_selected_regions(pdev,\r\n1 << index, "vfio-pci");\r\nif (ret)\r\nreturn ret;\r\nvdev->barmap[index] = pci_iomap(pdev, index, 0);\r\n}\r\nvma->vm_private_data = vdev;\r\nvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\r\nvma->vm_pgoff = (pci_resource_start(pdev, index) >> PAGE_SHIFT) + pgoff;\r\nreturn remap_pfn_range(vma, vma->vm_start, vma->vm_pgoff,\r\nreq_len, vma->vm_page_prot);\r\n}\r\nstatic int vfio_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nu8 type;\r\nstruct vfio_pci_device *vdev;\r\nstruct iommu_group *group;\r\nint ret;\r\npci_read_config_byte(pdev, PCI_HEADER_TYPE, &type);\r\nif ((type & PCI_HEADER_TYPE) != PCI_HEADER_TYPE_NORMAL)\r\nreturn -EINVAL;\r\ngroup = iommu_group_get(&pdev->dev);\r\nif (!group)\r\nreturn -EINVAL;\r\nvdev = kzalloc(sizeof(*vdev), GFP_KERNEL);\r\nif (!vdev) {\r\niommu_group_put(group);\r\nreturn -ENOMEM;\r\n}\r\nvdev->pdev = pdev;\r\nvdev->irq_type = VFIO_PCI_NUM_IRQS;\r\nmutex_init(&vdev->igate);\r\nspin_lock_init(&vdev->irqlock);\r\natomic_set(&vdev->refcnt, 0);\r\nret = vfio_add_group_dev(&pdev->dev, &vfio_pci_ops, vdev);\r\nif (ret) {\r\niommu_group_put(group);\r\nkfree(vdev);\r\n}\r\nreturn ret;\r\n}\r\nstatic void vfio_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct vfio_pci_device *vdev;\r\nvdev = vfio_del_group_dev(&pdev->dev);\r\nif (!vdev)\r\nreturn;\r\niommu_group_put(pdev->dev.iommu_group);\r\nkfree(vdev);\r\n}\r\nstatic pci_ers_result_t vfio_pci_aer_err_detected(struct pci_dev *pdev,\r\npci_channel_state_t state)\r\n{\r\nstruct vfio_pci_device *vdev;\r\nstruct vfio_device *device;\r\ndevice = vfio_device_get_from_dev(&pdev->dev);\r\nif (device == NULL)\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\nvdev = vfio_device_data(device);\r\nif (vdev == NULL) {\r\nvfio_device_put(device);\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nmutex_lock(&vdev->igate);\r\nif (vdev->err_trigger)\r\neventfd_signal(vdev->err_trigger, 1);\r\nmutex_unlock(&vdev->igate);\r\nvfio_device_put(device);\r\nreturn PCI_ERS_RESULT_CAN_RECOVER;\r\n}\r\nstatic void __exit vfio_pci_cleanup(void)\r\n{\r\npci_unregister_driver(&vfio_pci_driver);\r\nvfio_pci_virqfd_exit();\r\nvfio_pci_uninit_perm_bits();\r\n}\r\nstatic int __init vfio_pci_init(void)\r\n{\r\nint ret;\r\nret = vfio_pci_init_perm_bits();\r\nif (ret)\r\nreturn ret;\r\nret = vfio_pci_virqfd_init();\r\nif (ret)\r\ngoto out_virqfd;\r\nret = pci_register_driver(&vfio_pci_driver);\r\nif (ret)\r\ngoto out_driver;\r\nreturn 0;\r\nout_driver:\r\nvfio_pci_virqfd_exit();\r\nout_virqfd:\r\nvfio_pci_uninit_perm_bits();\r\nreturn ret;\r\n}
