static void index_addr(struct denali_nand_info *denali,\r\nuint32_t address, uint32_t data)\r\n{\r\niowrite32(address, denali->flash_mem);\r\niowrite32(data, denali->flash_mem + 0x10);\r\n}\r\nstatic void index_addr_read_data(struct denali_nand_info *denali,\r\nuint32_t address, uint32_t *pdata)\r\n{\r\niowrite32(address, denali->flash_mem);\r\n*pdata = ioread32(denali->flash_mem + 0x10);\r\n}\r\nstatic void reset_buf(struct denali_nand_info *denali)\r\n{\r\ndenali->buf.head = denali->buf.tail = 0;\r\n}\r\nstatic void write_byte_to_buf(struct denali_nand_info *denali, uint8_t byte)\r\n{\r\ndenali->buf.buf[denali->buf.tail++] = byte;\r\n}\r\nstatic void read_status(struct denali_nand_info *denali)\r\n{\r\nuint32_t cmd = 0x0;\r\nreset_buf(denali);\r\ncmd = ioread32(denali->flash_reg + WRITE_PROTECT);\r\nif (cmd)\r\nwrite_byte_to_buf(denali, NAND_STATUS_WP);\r\nelse\r\nwrite_byte_to_buf(denali, 0);\r\n}\r\nstatic void reset_bank(struct denali_nand_info *denali)\r\n{\r\nuint32_t irq_status = 0;\r\nuint32_t irq_mask = INTR_STATUS__RST_COMP |\r\nINTR_STATUS__TIME_OUT;\r\nclear_interrupts(denali);\r\niowrite32(1 << denali->flash_bank, denali->flash_reg + DEVICE_RESET);\r\nirq_status = wait_for_irq(denali, irq_mask);\r\nif (irq_status & INTR_STATUS__TIME_OUT)\r\ndev_err(denali->dev, "reset bank failed.\n");\r\n}\r\nstatic uint16_t denali_nand_reset(struct denali_nand_info *denali)\r\n{\r\nuint32_t i;\r\ndev_dbg(denali->dev, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nfor (i = 0 ; i < denali->max_banks; i++)\r\niowrite32(INTR_STATUS__RST_COMP | INTR_STATUS__TIME_OUT,\r\ndenali->flash_reg + INTR_STATUS(i));\r\nfor (i = 0 ; i < denali->max_banks; i++) {\r\niowrite32(1 << i, denali->flash_reg + DEVICE_RESET);\r\nwhile (!(ioread32(denali->flash_reg +\r\nINTR_STATUS(i)) &\r\n(INTR_STATUS__RST_COMP | INTR_STATUS__TIME_OUT)))\r\ncpu_relax();\r\nif (ioread32(denali->flash_reg + INTR_STATUS(i)) &\r\nINTR_STATUS__TIME_OUT)\r\ndev_dbg(denali->dev,\r\n"NAND Reset operation timed out on bank %d\n", i);\r\n}\r\nfor (i = 0; i < denali->max_banks; i++)\r\niowrite32(INTR_STATUS__RST_COMP | INTR_STATUS__TIME_OUT,\r\ndenali->flash_reg + INTR_STATUS(i));\r\nreturn PASS;\r\n}\r\nstatic void nand_onfi_timing_set(struct denali_nand_info *denali,\r\nuint16_t mode)\r\n{\r\nuint16_t Trea[6] = {40, 30, 25, 20, 20, 16};\r\nuint16_t Trp[6] = {50, 25, 17, 15, 12, 10};\r\nuint16_t Treh[6] = {30, 15, 15, 10, 10, 7};\r\nuint16_t Trc[6] = {100, 50, 35, 30, 25, 20};\r\nuint16_t Trhoh[6] = {0, 15, 15, 15, 15, 15};\r\nuint16_t Trloh[6] = {0, 0, 0, 0, 5, 5};\r\nuint16_t Tcea[6] = {100, 45, 30, 25, 25, 25};\r\nuint16_t Tadl[6] = {200, 100, 100, 100, 70, 70};\r\nuint16_t Trhw[6] = {200, 100, 100, 100, 100, 100};\r\nuint16_t Trhz[6] = {200, 100, 100, 100, 100, 100};\r\nuint16_t Twhr[6] = {120, 80, 80, 60, 60, 60};\r\nuint16_t Tcs[6] = {70, 35, 25, 25, 20, 15};\r\nuint16_t TclsRising = 1;\r\nuint16_t data_invalid_rhoh, data_invalid_rloh, data_invalid;\r\nuint16_t dv_window = 0;\r\nuint16_t en_lo, en_hi;\r\nuint16_t acc_clks;\r\nuint16_t addr_2_data, re_2_we, re_2_re, we_2_re, cs_cnt;\r\ndev_dbg(denali->dev, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nen_lo = CEIL_DIV(Trp[mode], CLK_X);\r\nen_hi = CEIL_DIV(Treh[mode], CLK_X);\r\n#if ONFI_BLOOM_TIME\r\nif ((en_hi * CLK_X) < (Treh[mode] + 2))\r\nen_hi++;\r\n#endif\r\nif ((en_lo + en_hi) * CLK_X < Trc[mode])\r\nen_lo += CEIL_DIV((Trc[mode] - (en_lo + en_hi) * CLK_X), CLK_X);\r\nif ((en_lo + en_hi) < CLK_MULTI)\r\nen_lo += CLK_MULTI - en_lo - en_hi;\r\nwhile (dv_window < 8) {\r\ndata_invalid_rhoh = en_lo * CLK_X + Trhoh[mode];\r\ndata_invalid_rloh = (en_lo + en_hi) * CLK_X + Trloh[mode];\r\ndata_invalid =\r\ndata_invalid_rhoh <\r\ndata_invalid_rloh ? data_invalid_rhoh : data_invalid_rloh;\r\ndv_window = data_invalid - Trea[mode];\r\nif (dv_window < 8)\r\nen_lo++;\r\n}\r\nacc_clks = CEIL_DIV(Trea[mode], CLK_X);\r\nwhile (((acc_clks * CLK_X) - Trea[mode]) < 3)\r\nacc_clks++;\r\nif ((data_invalid - acc_clks * CLK_X) < 2)\r\ndev_warn(denali->dev, "%s, Line %d: Warning!\n",\r\n__FILE__, __LINE__);\r\naddr_2_data = CEIL_DIV(Tadl[mode], CLK_X);\r\nre_2_we = CEIL_DIV(Trhw[mode], CLK_X);\r\nre_2_re = CEIL_DIV(Trhz[mode], CLK_X);\r\nwe_2_re = CEIL_DIV(Twhr[mode], CLK_X);\r\ncs_cnt = CEIL_DIV((Tcs[mode] - Trp[mode]), CLK_X);\r\nif (!TclsRising)\r\ncs_cnt = CEIL_DIV(Tcs[mode], CLK_X);\r\nif (cs_cnt == 0)\r\ncs_cnt = 1;\r\nif (Tcea[mode]) {\r\nwhile (((cs_cnt * CLK_X) + Trea[mode]) < Tcea[mode])\r\ncs_cnt++;\r\n}\r\n#if MODE5_WORKAROUND\r\nif (mode == 5)\r\nacc_clks = 5;\r\n#endif\r\nif ((ioread32(denali->flash_reg + MANUFACTURER_ID) == 0) &&\r\n(ioread32(denali->flash_reg + DEVICE_ID) == 0x88))\r\nacc_clks = 6;\r\niowrite32(acc_clks, denali->flash_reg + ACC_CLKS);\r\niowrite32(re_2_we, denali->flash_reg + RE_2_WE);\r\niowrite32(re_2_re, denali->flash_reg + RE_2_RE);\r\niowrite32(we_2_re, denali->flash_reg + WE_2_RE);\r\niowrite32(addr_2_data, denali->flash_reg + ADDR_2_DATA);\r\niowrite32(en_lo, denali->flash_reg + RDWR_EN_LO_CNT);\r\niowrite32(en_hi, denali->flash_reg + RDWR_EN_HI_CNT);\r\niowrite32(cs_cnt, denali->flash_reg + CS_SETUP_CNT);\r\n}\r\nstatic uint16_t get_onfi_nand_para(struct denali_nand_info *denali)\r\n{\r\nint i;\r\nif (!(ioread32(denali->flash_reg + ONFI_TIMING_MODE) &\r\nONFI_TIMING_MODE__VALUE))\r\nreturn FAIL;\r\nfor (i = 5; i > 0; i--) {\r\nif (ioread32(denali->flash_reg + ONFI_TIMING_MODE) &\r\n(0x01 << i))\r\nbreak;\r\n}\r\nnand_onfi_timing_set(denali, i);\r\nreturn PASS;\r\n}\r\nstatic void get_samsung_nand_para(struct denali_nand_info *denali,\r\nuint8_t device_id)\r\n{\r\nif (device_id == 0xd3) {\r\niowrite32(5, denali->flash_reg + ACC_CLKS);\r\niowrite32(20, denali->flash_reg + RE_2_WE);\r\niowrite32(12, denali->flash_reg + WE_2_RE);\r\niowrite32(14, denali->flash_reg + ADDR_2_DATA);\r\niowrite32(3, denali->flash_reg + RDWR_EN_LO_CNT);\r\niowrite32(2, denali->flash_reg + RDWR_EN_HI_CNT);\r\niowrite32(2, denali->flash_reg + CS_SETUP_CNT);\r\n}\r\n}\r\nstatic void get_toshiba_nand_para(struct denali_nand_info *denali)\r\n{\r\nuint32_t tmp;\r\nif ((ioread32(denali->flash_reg + DEVICE_MAIN_AREA_SIZE) == 4096) &&\r\n(ioread32(denali->flash_reg + DEVICE_SPARE_AREA_SIZE) == 64)) {\r\niowrite32(216, denali->flash_reg + DEVICE_SPARE_AREA_SIZE);\r\ntmp = ioread32(denali->flash_reg + DEVICES_CONNECTED) *\r\nioread32(denali->flash_reg + DEVICE_SPARE_AREA_SIZE);\r\niowrite32(tmp,\r\ndenali->flash_reg + LOGICAL_PAGE_SPARE_SIZE);\r\n#if SUPPORT_15BITECC\r\niowrite32(15, denali->flash_reg + ECC_CORRECTION);\r\n#elif SUPPORT_8BITECC\r\niowrite32(8, denali->flash_reg + ECC_CORRECTION);\r\n#endif\r\n}\r\n}\r\nstatic void get_hynix_nand_para(struct denali_nand_info *denali,\r\nuint8_t device_id)\r\n{\r\nuint32_t main_size, spare_size;\r\nswitch (device_id) {\r\ncase 0xD5:\r\ncase 0xD7:\r\niowrite32(128, denali->flash_reg + PAGES_PER_BLOCK);\r\niowrite32(4096, denali->flash_reg + DEVICE_MAIN_AREA_SIZE);\r\niowrite32(224, denali->flash_reg + DEVICE_SPARE_AREA_SIZE);\r\nmain_size = 4096 *\r\nioread32(denali->flash_reg + DEVICES_CONNECTED);\r\nspare_size = 224 *\r\nioread32(denali->flash_reg + DEVICES_CONNECTED);\r\niowrite32(main_size,\r\ndenali->flash_reg + LOGICAL_PAGE_DATA_SIZE);\r\niowrite32(spare_size,\r\ndenali->flash_reg + LOGICAL_PAGE_SPARE_SIZE);\r\niowrite32(0, denali->flash_reg + DEVICE_WIDTH);\r\n#if SUPPORT_15BITECC\r\niowrite32(15, denali->flash_reg + ECC_CORRECTION);\r\n#elif SUPPORT_8BITECC\r\niowrite32(8, denali->flash_reg + ECC_CORRECTION);\r\n#endif\r\nbreak;\r\ndefault:\r\ndev_warn(denali->dev,\r\n"Spectra: Unknown Hynix NAND (Device ID: 0x%x)."\r\n"Will use default parameter values instead.\n",\r\ndevice_id);\r\n}\r\n}\r\nstatic void find_valid_banks(struct denali_nand_info *denali)\r\n{\r\nuint32_t id[denali->max_banks];\r\nint i;\r\ndenali->total_used_banks = 1;\r\nfor (i = 0; i < denali->max_banks; i++) {\r\nindex_addr(denali, (uint32_t)(MODE_11 | (i << 24) | 0), 0x90);\r\nindex_addr(denali, (uint32_t)(MODE_11 | (i << 24) | 1), 0);\r\nindex_addr_read_data(denali,\r\n(uint32_t)(MODE_11 | (i << 24) | 2), &id[i]);\r\ndev_dbg(denali->dev,\r\n"Return 1st ID for bank[%d]: %x\n", i, id[i]);\r\nif (i == 0) {\r\nif (!(id[i] & 0x0ff))\r\nbreak;\r\n} else {\r\nif ((id[i] & 0x0ff) == (id[0] & 0x0ff))\r\ndenali->total_used_banks++;\r\nelse\r\nbreak;\r\n}\r\n}\r\nif (denali->platform == INTEL_CE4100) {\r\nif (denali->total_used_banks != 1) {\r\ndev_err(denali->dev,\r\n"Sorry, Intel CE4100 only supports "\r\n"a single NAND device.\n");\r\nBUG();\r\n}\r\n}\r\ndev_dbg(denali->dev,\r\n"denali->total_used_banks: %d\n", denali->total_used_banks);\r\n}\r\nstatic void detect_max_banks(struct denali_nand_info *denali)\r\n{\r\nuint32_t features = ioread32(denali->flash_reg + FEATURES);\r\ndenali->max_banks = 2 << (features & FEATURES__N_BANKS);\r\n}\r\nstatic void detect_partition_feature(struct denali_nand_info *denali)\r\n{\r\nif (ioread32(denali->flash_reg + FEATURES) & FEATURES__PARTITION) {\r\nif ((ioread32(denali->flash_reg + PERM_SRC_ID(1)) &\r\nPERM_SRC_ID__SRCID) == SPECTRA_PARTITION_ID) {\r\ndenali->fwblks =\r\n((ioread32(denali->flash_reg + MIN_MAX_BANK(1)) &\r\nMIN_MAX_BANK__MIN_VALUE) *\r\ndenali->blksperchip)\r\n+\r\n(ioread32(denali->flash_reg + MIN_BLK_ADDR(1)) &\r\nMIN_BLK_ADDR__VALUE);\r\n} else\r\ndenali->fwblks = SPECTRA_START_BLOCK;\r\n} else\r\ndenali->fwblks = SPECTRA_START_BLOCK;\r\n}\r\nstatic uint16_t denali_nand_timing_set(struct denali_nand_info *denali)\r\n{\r\nuint16_t status = PASS;\r\nuint32_t id_bytes[5], addr;\r\nuint8_t i, maf_id, device_id;\r\ndev_dbg(denali->dev,\r\n"%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\naddr = (uint32_t)MODE_11 | BANK(denali->flash_bank);\r\nindex_addr(denali, (uint32_t)addr | 0, 0x90);\r\nindex_addr(denali, (uint32_t)addr | 1, 0);\r\nfor (i = 0; i < 5; i++)\r\nindex_addr_read_data(denali, addr | 2, &id_bytes[i]);\r\nmaf_id = id_bytes[0];\r\ndevice_id = id_bytes[1];\r\nif (ioread32(denali->flash_reg + ONFI_DEVICE_NO_OF_LUNS) &\r\nONFI_DEVICE_NO_OF_LUNS__ONFI_DEVICE) {\r\nif (FAIL == get_onfi_nand_para(denali))\r\nreturn FAIL;\r\n} else if (maf_id == 0xEC) {\r\nget_samsung_nand_para(denali, device_id);\r\n} else if (maf_id == 0x98) {\r\nget_toshiba_nand_para(denali);\r\n} else if (maf_id == 0xAD) {\r\nget_hynix_nand_para(denali, device_id);\r\n}\r\ndev_info(denali->dev,\r\n"Dump timing register values:"\r\n"acc_clks: %d, re_2_we: %d, re_2_re: %d\n"\r\n"we_2_re: %d, addr_2_data: %d, rdwr_en_lo_cnt: %d\n"\r\n"rdwr_en_hi_cnt: %d, cs_setup_cnt: %d\n",\r\nioread32(denali->flash_reg + ACC_CLKS),\r\nioread32(denali->flash_reg + RE_2_WE),\r\nioread32(denali->flash_reg + RE_2_RE),\r\nioread32(denali->flash_reg + WE_2_RE),\r\nioread32(denali->flash_reg + ADDR_2_DATA),\r\nioread32(denali->flash_reg + RDWR_EN_LO_CNT),\r\nioread32(denali->flash_reg + RDWR_EN_HI_CNT),\r\nioread32(denali->flash_reg + CS_SETUP_CNT));\r\nfind_valid_banks(denali);\r\ndetect_partition_feature(denali);\r\nif (onfi_timing_mode != NAND_DEFAULT_TIMINGS)\r\nnand_onfi_timing_set(denali, onfi_timing_mode);\r\nreturn status;\r\n}\r\nstatic void denali_set_intr_modes(struct denali_nand_info *denali,\r\nuint16_t INT_ENABLE)\r\n{\r\ndev_dbg(denali->dev, "%s, Line %d, Function: %s\n",\r\n__FILE__, __LINE__, __func__);\r\nif (INT_ENABLE)\r\niowrite32(1, denali->flash_reg + GLOBAL_INT_ENABLE);\r\nelse\r\niowrite32(0, denali->flash_reg + GLOBAL_INT_ENABLE);\r\n}\r\nstatic inline bool is_flash_bank_valid(int flash_bank)\r\n{\r\nreturn (flash_bank >= 0 && flash_bank < 4);\r\n}\r\nstatic void denali_irq_init(struct denali_nand_info *denali)\r\n{\r\nuint32_t int_mask = 0;\r\nint i;\r\ndenali_set_intr_modes(denali, false);\r\nint_mask = DENALI_IRQ_ALL;\r\nfor (i = 0; i < denali->max_banks; ++i)\r\niowrite32(0xFFFF, denali->flash_reg + INTR_STATUS(i));\r\ndenali_irq_enable(denali, int_mask);\r\n}\r\nstatic void denali_irq_cleanup(int irqnum, struct denali_nand_info *denali)\r\n{\r\ndenali_set_intr_modes(denali, false);\r\nfree_irq(irqnum, denali);\r\n}\r\nstatic void denali_irq_enable(struct denali_nand_info *denali,\r\nuint32_t int_mask)\r\n{\r\nint i;\r\nfor (i = 0; i < denali->max_banks; ++i)\r\niowrite32(int_mask, denali->flash_reg + INTR_EN(i));\r\n}\r\nstatic inline uint32_t denali_irq_detected(struct denali_nand_info *denali)\r\n{\r\nreturn read_interrupt_status(denali) & DENALI_IRQ_ALL;\r\n}\r\nstatic inline void clear_interrupt(struct denali_nand_info *denali,\r\nuint32_t irq_mask)\r\n{\r\nuint32_t intr_status_reg = 0;\r\nintr_status_reg = INTR_STATUS(denali->flash_bank);\r\niowrite32(irq_mask, denali->flash_reg + intr_status_reg);\r\n}\r\nstatic void clear_interrupts(struct denali_nand_info *denali)\r\n{\r\nuint32_t status = 0x0;\r\nspin_lock_irq(&denali->irq_lock);\r\nstatus = read_interrupt_status(denali);\r\nclear_interrupt(denali, status);\r\ndenali->irq_status = 0x0;\r\nspin_unlock_irq(&denali->irq_lock);\r\n}\r\nstatic uint32_t read_interrupt_status(struct denali_nand_info *denali)\r\n{\r\nuint32_t intr_status_reg = 0;\r\nintr_status_reg = INTR_STATUS(denali->flash_bank);\r\nreturn ioread32(denali->flash_reg + intr_status_reg);\r\n}\r\nstatic irqreturn_t denali_isr(int irq, void *dev_id)\r\n{\r\nstruct denali_nand_info *denali = dev_id;\r\nuint32_t irq_status = 0x0;\r\nirqreturn_t result = IRQ_NONE;\r\nspin_lock(&denali->irq_lock);\r\nif (is_flash_bank_valid(denali->flash_bank)) {\r\nirq_status = denali_irq_detected(denali);\r\nif (irq_status != 0) {\r\nclear_interrupt(denali, irq_status);\r\ndenali->irq_status |= irq_status;\r\ncomplete(&denali->complete);\r\nresult = IRQ_HANDLED;\r\n}\r\n}\r\nspin_unlock(&denali->irq_lock);\r\nreturn result;\r\n}\r\nstatic uint32_t wait_for_irq(struct denali_nand_info *denali, uint32_t irq_mask)\r\n{\r\nunsigned long comp_res = 0;\r\nuint32_t intr_status = 0;\r\nbool retry = false;\r\nunsigned long timeout = msecs_to_jiffies(1000);\r\ndo {\r\ncomp_res =\r\nwait_for_completion_timeout(&denali->complete, timeout);\r\nspin_lock_irq(&denali->irq_lock);\r\nintr_status = denali->irq_status;\r\nif (intr_status & irq_mask) {\r\ndenali->irq_status &= ~irq_mask;\r\nspin_unlock_irq(&denali->irq_lock);\r\nbreak;\r\n} else {\r\nspin_unlock_irq(&denali->irq_lock);\r\nretry = true;\r\n}\r\n} while (comp_res != 0);\r\nif (comp_res == 0) {\r\npr_err("timeout occurred, status = 0x%x, mask = 0x%x\n",\r\nintr_status, irq_mask);\r\nintr_status = 0;\r\n}\r\nreturn intr_status;\r\n}\r\nstatic void setup_ecc_for_xfer(struct denali_nand_info *denali, bool ecc_en,\r\nbool transfer_spare)\r\n{\r\nint ecc_en_flag = 0, transfer_spare_flag = 0;\r\necc_en_flag = ecc_en ? ECC_ENABLE__FLAG : 0;\r\ntransfer_spare_flag = transfer_spare ? TRANSFER_SPARE_REG__FLAG : 0;\r\niowrite32(ecc_en_flag, denali->flash_reg + ECC_ENABLE);\r\niowrite32(transfer_spare_flag,\r\ndenali->flash_reg + TRANSFER_SPARE_REG);\r\n}\r\nstatic int denali_send_pipeline_cmd(struct denali_nand_info *denali,\r\nbool ecc_en,\r\nbool transfer_spare,\r\nint access_type,\r\nint op)\r\n{\r\nint status = PASS;\r\nuint32_t addr = 0x0, cmd = 0x0, page_count = 1, irq_status = 0,\r\nirq_mask = 0;\r\nif (op == DENALI_READ)\r\nirq_mask = INTR_STATUS__LOAD_COMP;\r\nelse if (op == DENALI_WRITE)\r\nirq_mask = 0;\r\nelse\r\nBUG();\r\nsetup_ecc_for_xfer(denali, ecc_en, transfer_spare);\r\nclear_interrupts(denali);\r\naddr = BANK(denali->flash_bank) | denali->page;\r\nif (op == DENALI_WRITE && access_type != SPARE_ACCESS) {\r\ncmd = MODE_01 | addr;\r\niowrite32(cmd, denali->flash_mem);\r\n} else if (op == DENALI_WRITE && access_type == SPARE_ACCESS) {\r\ncmd = MODE_10 | addr;\r\nindex_addr(denali, (uint32_t)cmd, access_type);\r\ncmd = MODE_01 | addr;\r\niowrite32(cmd, denali->flash_mem);\r\n} else if (op == DENALI_READ) {\r\ncmd = MODE_10 | addr;\r\nindex_addr(denali, (uint32_t)cmd, access_type);\r\nif (access_type == SPARE_ACCESS) {\r\ncmd = MODE_01 | addr;\r\niowrite32(cmd, denali->flash_mem);\r\n} else {\r\nindex_addr(denali, (uint32_t)cmd,\r\n0x2000 | op | page_count);\r\nirq_status = wait_for_irq(denali, irq_mask);\r\nif (irq_status == 0) {\r\ndev_err(denali->dev,\r\n"cmd, page, addr on timeout "\r\n"(0x%x, 0x%x, 0x%x)\n",\r\ncmd, denali->page, addr);\r\nstatus = FAIL;\r\n} else {\r\ncmd = MODE_01 | addr;\r\niowrite32(cmd, denali->flash_mem);\r\n}\r\n}\r\n}\r\nreturn status;\r\n}\r\nstatic int write_data_to_flash_mem(struct denali_nand_info *denali,\r\nconst uint8_t *buf,\r\nint len)\r\n{\r\nuint32_t i = 0, *buf32;\r\nBUG_ON((len % 4) != 0);\r\nbuf32 = (uint32_t *)buf;\r\nfor (i = 0; i < len / 4; i++)\r\niowrite32(*buf32++, denali->flash_mem + 0x10);\r\nreturn i*4;\r\n}\r\nstatic int read_data_from_flash_mem(struct denali_nand_info *denali,\r\nuint8_t *buf,\r\nint len)\r\n{\r\nuint32_t i = 0, *buf32;\r\nBUG_ON((len % 4) != 0);\r\nbuf32 = (uint32_t *)buf;\r\nfor (i = 0; i < len / 4; i++)\r\n*buf32++ = ioread32(denali->flash_mem + 0x10);\r\nreturn i*4;\r\n}\r\nstatic int write_oob_data(struct mtd_info *mtd, uint8_t *buf, int page)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\nuint32_t irq_status = 0;\r\nuint32_t irq_mask = INTR_STATUS__PROGRAM_COMP |\r\nINTR_STATUS__PROGRAM_FAIL;\r\nint status = 0;\r\ndenali->page = page;\r\nif (denali_send_pipeline_cmd(denali, false, false, SPARE_ACCESS,\r\nDENALI_WRITE) == PASS) {\r\nwrite_data_to_flash_mem(denali, buf, mtd->oobsize);\r\nirq_status = wait_for_irq(denali, irq_mask);\r\nif (irq_status == 0) {\r\ndev_err(denali->dev, "OOB write failed\n");\r\nstatus = -EIO;\r\n}\r\n} else {\r\ndev_err(denali->dev, "unable to send pipeline command\n");\r\nstatus = -EIO;\r\n}\r\nreturn status;\r\n}\r\nstatic void read_oob_data(struct mtd_info *mtd, uint8_t *buf, int page)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\nuint32_t irq_mask = INTR_STATUS__LOAD_COMP,\r\nirq_status = 0, addr = 0x0, cmd = 0x0;\r\ndenali->page = page;\r\nif (denali_send_pipeline_cmd(denali, false, true, SPARE_ACCESS,\r\nDENALI_READ) == PASS) {\r\nread_data_from_flash_mem(denali, buf, mtd->oobsize);\r\nirq_status = wait_for_irq(denali, irq_mask);\r\nif (irq_status == 0)\r\ndev_err(denali->dev, "page on OOB timeout %d\n",\r\ndenali->page);\r\naddr = BANK(denali->flash_bank) | denali->page;\r\ncmd = MODE_10 | addr;\r\nindex_addr(denali, (uint32_t)cmd, MAIN_ACCESS);\r\n}\r\n}\r\nstatic bool is_erased(uint8_t *buf, int len)\r\n{\r\nint i = 0;\r\nfor (i = 0; i < len; i++)\r\nif (buf[i] != 0xFF)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic bool handle_ecc(struct denali_nand_info *denali, uint8_t *buf,\r\nuint32_t irq_status, unsigned int *max_bitflips)\r\n{\r\nbool check_erased_page = false;\r\nunsigned int bitflips = 0;\r\nif (irq_status & INTR_STATUS__ECC_ERR) {\r\nuint32_t err_address = 0, err_correction_info = 0;\r\nuint32_t err_byte = 0, err_sector = 0, err_device = 0;\r\nuint32_t err_correction_value = 0;\r\ndenali_set_intr_modes(denali, false);\r\ndo {\r\nerr_address = ioread32(denali->flash_reg +\r\nECC_ERROR_ADDRESS);\r\nerr_sector = ECC_SECTOR(err_address);\r\nerr_byte = ECC_BYTE(err_address);\r\nerr_correction_info = ioread32(denali->flash_reg +\r\nERR_CORRECTION_INFO);\r\nerr_correction_value =\r\nECC_CORRECTION_VALUE(err_correction_info);\r\nerr_device = ECC_ERR_DEVICE(err_correction_info);\r\nif (ECC_ERROR_CORRECTABLE(err_correction_info)) {\r\nif (err_byte < ECC_SECTOR_SIZE) {\r\nint offset;\r\noffset = (err_sector *\r\nECC_SECTOR_SIZE +\r\nerr_byte) *\r\ndenali->devnum +\r\nerr_device;\r\nbuf[offset] ^= err_correction_value;\r\ndenali->mtd.ecc_stats.corrected++;\r\nbitflips++;\r\n}\r\n} else {\r\ncheck_erased_page = true;\r\n}\r\n} while (!ECC_LAST_ERR(err_correction_info));\r\nwhile (!(read_interrupt_status(denali) &\r\nINTR_STATUS__ECC_TRANSACTION_DONE))\r\ncpu_relax();\r\nclear_interrupts(denali);\r\ndenali_set_intr_modes(denali, true);\r\n}\r\n*max_bitflips = bitflips;\r\nreturn check_erased_page;\r\n}\r\nstatic void denali_enable_dma(struct denali_nand_info *denali, bool en)\r\n{\r\nuint32_t reg_val = 0x0;\r\nif (en)\r\nreg_val = DMA_ENABLE__FLAG;\r\niowrite32(reg_val, denali->flash_reg + DMA_ENABLE);\r\nioread32(denali->flash_reg + DMA_ENABLE);\r\n}\r\nstatic void denali_setup_dma(struct denali_nand_info *denali, int op)\r\n{\r\nuint32_t mode = 0x0;\r\nconst int page_count = 1;\r\ndma_addr_t addr = denali->buf.dma_buf;\r\nmode = MODE_10 | BANK(denali->flash_bank);\r\nindex_addr(denali, mode | denali->page, 0x2000 | op | page_count);\r\nindex_addr(denali, mode | ((uint16_t)(addr >> 16) << 8), 0x2200);\r\nindex_addr(denali, mode | ((uint16_t)addr << 8), 0x2300);\r\nindex_addr(denali, mode | 0x14000, 0x2400);\r\n}\r\nstatic int write_page(struct mtd_info *mtd, struct nand_chip *chip,\r\nconst uint8_t *buf, bool raw_xfer)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\ndma_addr_t addr = denali->buf.dma_buf;\r\nsize_t size = denali->mtd.writesize + denali->mtd.oobsize;\r\nuint32_t irq_status = 0;\r\nuint32_t irq_mask = INTR_STATUS__DMA_CMD_COMP |\r\nINTR_STATUS__PROGRAM_FAIL;\r\nsetup_ecc_for_xfer(denali, !raw_xfer, raw_xfer);\r\nmemcpy(denali->buf.buf, buf, mtd->writesize);\r\nif (raw_xfer) {\r\nmemcpy(denali->buf.buf + mtd->writesize,\r\nchip->oob_poi,\r\nmtd->oobsize);\r\n}\r\ndma_sync_single_for_device(denali->dev, addr, size, DMA_TO_DEVICE);\r\nclear_interrupts(denali);\r\ndenali_enable_dma(denali, true);\r\ndenali_setup_dma(denali, DENALI_WRITE);\r\nirq_status = wait_for_irq(denali, irq_mask);\r\nif (irq_status == 0) {\r\ndev_err(denali->dev,\r\n"timeout on write_page (type = %d)\n",\r\nraw_xfer);\r\ndenali->status =\r\n(irq_status & INTR_STATUS__PROGRAM_FAIL) ?\r\nNAND_STATUS_FAIL : PASS;\r\n}\r\ndenali_enable_dma(denali, false);\r\ndma_sync_single_for_cpu(denali->dev, addr, size, DMA_TO_DEVICE);\r\nreturn 0;\r\n}\r\nstatic int denali_write_page(struct mtd_info *mtd, struct nand_chip *chip,\r\nconst uint8_t *buf, int oob_required)\r\n{\r\nreturn write_page(mtd, chip, buf, false);\r\n}\r\nstatic int denali_write_page_raw(struct mtd_info *mtd, struct nand_chip *chip,\r\nconst uint8_t *buf, int oob_required)\r\n{\r\nreturn write_page(mtd, chip, buf, true);\r\n}\r\nstatic int denali_write_oob(struct mtd_info *mtd, struct nand_chip *chip,\r\nint page)\r\n{\r\nreturn write_oob_data(mtd, chip->oob_poi, page);\r\n}\r\nstatic int denali_read_oob(struct mtd_info *mtd, struct nand_chip *chip,\r\nint page)\r\n{\r\nread_oob_data(mtd, chip->oob_poi, page);\r\nreturn 0;\r\n}\r\nstatic int denali_read_page(struct mtd_info *mtd, struct nand_chip *chip,\r\nuint8_t *buf, int oob_required, int page)\r\n{\r\nunsigned int max_bitflips;\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\ndma_addr_t addr = denali->buf.dma_buf;\r\nsize_t size = denali->mtd.writesize + denali->mtd.oobsize;\r\nuint32_t irq_status = 0;\r\nuint32_t irq_mask = INTR_STATUS__ECC_TRANSACTION_DONE |\r\nINTR_STATUS__ECC_ERR;\r\nbool check_erased_page = false;\r\nif (page != denali->page) {\r\ndev_err(denali->dev, "IN %s: page %d is not"\r\n" equal to denali->page %d, investigate!!",\r\n__func__, page, denali->page);\r\nBUG();\r\n}\r\nsetup_ecc_for_xfer(denali, true, false);\r\ndenali_enable_dma(denali, true);\r\ndma_sync_single_for_device(denali->dev, addr, size, DMA_FROM_DEVICE);\r\nclear_interrupts(denali);\r\ndenali_setup_dma(denali, DENALI_READ);\r\nirq_status = wait_for_irq(denali, irq_mask);\r\ndma_sync_single_for_cpu(denali->dev, addr, size, DMA_FROM_DEVICE);\r\nmemcpy(buf, denali->buf.buf, mtd->writesize);\r\ncheck_erased_page = handle_ecc(denali, buf, irq_status, &max_bitflips);\r\ndenali_enable_dma(denali, false);\r\nif (check_erased_page) {\r\nread_oob_data(&denali->mtd, chip->oob_poi, denali->page);\r\nif (check_erased_page) {\r\nif (!is_erased(buf, denali->mtd.writesize))\r\ndenali->mtd.ecc_stats.failed++;\r\nif (!is_erased(buf, denali->mtd.oobsize))\r\ndenali->mtd.ecc_stats.failed++;\r\n}\r\n}\r\nreturn max_bitflips;\r\n}\r\nstatic int denali_read_page_raw(struct mtd_info *mtd, struct nand_chip *chip,\r\nuint8_t *buf, int oob_required, int page)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\ndma_addr_t addr = denali->buf.dma_buf;\r\nsize_t size = denali->mtd.writesize + denali->mtd.oobsize;\r\nuint32_t irq_status = 0;\r\nuint32_t irq_mask = INTR_STATUS__DMA_CMD_COMP;\r\nif (page != denali->page) {\r\ndev_err(denali->dev, "IN %s: page %d is not"\r\n" equal to denali->page %d, investigate!!",\r\n__func__, page, denali->page);\r\nBUG();\r\n}\r\nsetup_ecc_for_xfer(denali, false, true);\r\ndenali_enable_dma(denali, true);\r\ndma_sync_single_for_device(denali->dev, addr, size, DMA_FROM_DEVICE);\r\nclear_interrupts(denali);\r\ndenali_setup_dma(denali, DENALI_READ);\r\nirq_status = wait_for_irq(denali, irq_mask);\r\ndma_sync_single_for_cpu(denali->dev, addr, size, DMA_FROM_DEVICE);\r\ndenali_enable_dma(denali, false);\r\nmemcpy(buf, denali->buf.buf, mtd->writesize);\r\nmemcpy(chip->oob_poi, denali->buf.buf + mtd->writesize, mtd->oobsize);\r\nreturn 0;\r\n}\r\nstatic uint8_t denali_read_byte(struct mtd_info *mtd)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\nuint8_t result = 0xff;\r\nif (denali->buf.head < denali->buf.tail)\r\nresult = denali->buf.buf[denali->buf.head++];\r\nreturn result;\r\n}\r\nstatic void denali_select_chip(struct mtd_info *mtd, int chip)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\nspin_lock_irq(&denali->irq_lock);\r\ndenali->flash_bank = chip;\r\nspin_unlock_irq(&denali->irq_lock);\r\n}\r\nstatic int denali_waitfunc(struct mtd_info *mtd, struct nand_chip *chip)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\nint status = denali->status;\r\ndenali->status = 0;\r\nreturn status;\r\n}\r\nstatic void denali_erase(struct mtd_info *mtd, int page)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\nuint32_t cmd = 0x0, irq_status = 0;\r\nclear_interrupts(denali);\r\ncmd = MODE_10 | BANK(denali->flash_bank) | page;\r\nindex_addr(denali, (uint32_t)cmd, 0x1);\r\nirq_status = wait_for_irq(denali, INTR_STATUS__ERASE_COMP |\r\nINTR_STATUS__ERASE_FAIL);\r\ndenali->status = (irq_status & INTR_STATUS__ERASE_FAIL) ?\r\nNAND_STATUS_FAIL : PASS;\r\n}\r\nstatic void denali_cmdfunc(struct mtd_info *mtd, unsigned int cmd, int col,\r\nint page)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\nuint32_t addr, id;\r\nint i;\r\nswitch (cmd) {\r\ncase NAND_CMD_PAGEPROG:\r\nbreak;\r\ncase NAND_CMD_STATUS:\r\nread_status(denali);\r\nbreak;\r\ncase NAND_CMD_READID:\r\ncase NAND_CMD_PARAM:\r\nreset_buf(denali);\r\naddr = (uint32_t)MODE_11 | BANK(denali->flash_bank);\r\nindex_addr(denali, (uint32_t)addr | 0, 0x90);\r\nindex_addr(denali, (uint32_t)addr | 1, 0);\r\nfor (i = 0; i < 5; i++) {\r\nindex_addr_read_data(denali,\r\n(uint32_t)addr | 2,\r\n&id);\r\nwrite_byte_to_buf(denali, id);\r\n}\r\nbreak;\r\ncase NAND_CMD_READ0:\r\ncase NAND_CMD_SEQIN:\r\ndenali->page = page;\r\nbreak;\r\ncase NAND_CMD_RESET:\r\nreset_bank(denali);\r\nbreak;\r\ncase NAND_CMD_READOOB:\r\nbreak;\r\ndefault:\r\npr_err(": unsupported command received 0x%x\n", cmd);\r\nbreak;\r\n}\r\n}\r\nstatic int denali_ecc_calculate(struct mtd_info *mtd, const uint8_t *data,\r\nuint8_t *ecc_code)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\ndev_err(denali->dev,\r\n"denali_ecc_calculate called unexpectedly\n");\r\nBUG();\r\nreturn -EIO;\r\n}\r\nstatic int denali_ecc_correct(struct mtd_info *mtd, uint8_t *data,\r\nuint8_t *read_ecc, uint8_t *calc_ecc)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\ndev_err(denali->dev,\r\n"denali_ecc_correct called unexpectedly\n");\r\nBUG();\r\nreturn -EIO;\r\n}\r\nstatic void denali_ecc_hwctl(struct mtd_info *mtd, int mode)\r\n{\r\nstruct denali_nand_info *denali = mtd_to_denali(mtd);\r\ndev_err(denali->dev,\r\n"denali_ecc_hwctl called unexpectedly\n");\r\nBUG();\r\n}\r\nstatic void denali_hw_init(struct denali_nand_info *denali)\r\n{\r\ndenali->bbtskipbytes = ioread32(denali->flash_reg +\r\nSPARE_AREA_SKIP_BYTES);\r\ndetect_max_banks(denali);\r\ndenali_nand_reset(denali);\r\niowrite32(0x0F, denali->flash_reg + RB_PIN_ENABLED);\r\niowrite32(CHIP_EN_DONT_CARE__FLAG,\r\ndenali->flash_reg + CHIP_ENABLE_DONT_CARE);\r\niowrite32(0xffff, denali->flash_reg + SPARE_AREA_MARKER);\r\niowrite32(0, denali->flash_reg + TWO_ROW_ADDR_CYCLES);\r\niowrite32(1, denali->flash_reg + ECC_ENABLE);\r\ndenali_nand_timing_set(denali);\r\ndenali_irq_init(denali);\r\n}\r\nstatic void denali_drv_init(struct denali_nand_info *denali)\r\n{\r\ndenali->idx = 0;\r\ninit_completion(&denali->complete);\r\nspin_lock_init(&denali->irq_lock);\r\ndenali->flash_bank = CHIP_SELECT_INVALID;\r\ndenali->irq_status = 0;\r\n}\r\nint denali_init(struct denali_nand_info *denali)\r\n{\r\nint ret;\r\nif (denali->platform == INTEL_CE4100) {\r\nif (onfi_timing_mode < -1 || onfi_timing_mode > 1) {\r\npr_err("Intel CE4100 only supports ONFI timing mode 1 or below\n");\r\nreturn -EINVAL;\r\n}\r\n}\r\ndenali->buf.buf = devm_kzalloc(denali->dev, PAGE_SIZE,\r\nGFP_DMA | GFP_KERNEL);\r\nif (!denali->buf.buf)\r\nreturn -ENOMEM;\r\ndenali->mtd.dev.parent = denali->dev;\r\ndenali_hw_init(denali);\r\ndenali_drv_init(denali);\r\nif (request_irq(denali->irq, denali_isr, IRQF_SHARED,\r\nDENALI_NAND_NAME, denali)) {\r\npr_err("Spectra: Unable to allocate IRQ\n");\r\nreturn -ENODEV;\r\n}\r\ndenali_set_intr_modes(denali, true);\r\ndenali->mtd.name = "denali-nand";\r\ndenali->mtd.owner = THIS_MODULE;\r\ndenali->mtd.priv = &denali->nand;\r\ndenali->nand.select_chip = denali_select_chip;\r\ndenali->nand.cmdfunc = denali_cmdfunc;\r\ndenali->nand.read_byte = denali_read_byte;\r\ndenali->nand.waitfunc = denali_waitfunc;\r\nif (nand_scan_ident(&denali->mtd, denali->max_banks, NULL)) {\r\nret = -ENXIO;\r\ngoto failed_req_irq;\r\n}\r\ndevm_kfree(denali->dev, denali->buf.buf);\r\ndenali->buf.buf = devm_kzalloc(denali->dev,\r\ndenali->mtd.writesize + denali->mtd.oobsize,\r\nGFP_KERNEL);\r\nif (!denali->buf.buf) {\r\nret = -ENOMEM;\r\ngoto failed_req_irq;\r\n}\r\nret = dma_set_mask(denali->dev, DMA_BIT_MASK(32));\r\nif (ret) {\r\npr_err("Spectra: no usable DMA configuration\n");\r\ngoto failed_req_irq;\r\n}\r\ndenali->buf.dma_buf = dma_map_single(denali->dev, denali->buf.buf,\r\ndenali->mtd.writesize + denali->mtd.oobsize,\r\nDMA_BIDIRECTIONAL);\r\nif (dma_mapping_error(denali->dev, denali->buf.dma_buf)) {\r\ndev_err(denali->dev, "Spectra: failed to map DMA buffer\n");\r\nret = -EIO;\r\ngoto failed_req_irq;\r\n}\r\ndenali->devnum = ioread32(denali->flash_reg + DEVICES_CONNECTED);\r\ndenali->nand.chipsize <<= (denali->devnum - 1);\r\ndenali->nand.page_shift += (denali->devnum - 1);\r\ndenali->nand.pagemask = (denali->nand.chipsize >>\r\ndenali->nand.page_shift) - 1;\r\ndenali->nand.bbt_erase_shift += (denali->devnum - 1);\r\ndenali->nand.phys_erase_shift = denali->nand.bbt_erase_shift;\r\ndenali->nand.chip_shift += (denali->devnum - 1);\r\ndenali->mtd.writesize <<= (denali->devnum - 1);\r\ndenali->mtd.oobsize <<= (denali->devnum - 1);\r\ndenali->mtd.erasesize <<= (denali->devnum - 1);\r\ndenali->mtd.size = denali->nand.numchips * denali->nand.chipsize;\r\ndenali->bbtskipbytes *= denali->devnum;\r\ndenali->nand.bbt_td = &bbt_main_descr;\r\ndenali->nand.bbt_md = &bbt_mirror_descr;\r\ndenali->nand.bbt_options |= NAND_BBT_USE_FLASH;\r\ndenali->nand.options |= NAND_SKIP_BBTSCAN;\r\ndenali->nand.ecc.mode = NAND_ECC_HW_SYNDROME;\r\nif (!nand_is_slc(&denali->nand) &&\r\n(denali->mtd.oobsize > (denali->bbtskipbytes +\r\nECC_15BITS * (denali->mtd.writesize /\r\nECC_SECTOR_SIZE)))) {\r\ndenali->nand.ecc.strength = 15;\r\ndenali->nand.ecc.layout = &nand_15bit_oob;\r\ndenali->nand.ecc.bytes = ECC_15BITS;\r\niowrite32(15, denali->flash_reg + ECC_CORRECTION);\r\n} else if (denali->mtd.oobsize < (denali->bbtskipbytes +\r\nECC_8BITS * (denali->mtd.writesize /\r\nECC_SECTOR_SIZE))) {\r\npr_err("Your NAND chip OOB is not large enough to \\r\ncontain 8bit ECC correction codes");\r\ngoto failed_req_irq;\r\n} else {\r\ndenali->nand.ecc.strength = 8;\r\ndenali->nand.ecc.layout = &nand_8bit_oob;\r\ndenali->nand.ecc.bytes = ECC_8BITS;\r\niowrite32(8, denali->flash_reg + ECC_CORRECTION);\r\n}\r\ndenali->nand.ecc.bytes *= denali->devnum;\r\ndenali->nand.ecc.strength *= denali->devnum;\r\ndenali->nand.ecc.layout->eccbytes *=\r\ndenali->mtd.writesize / ECC_SECTOR_SIZE;\r\ndenali->nand.ecc.layout->oobfree[0].offset =\r\ndenali->bbtskipbytes + denali->nand.ecc.layout->eccbytes;\r\ndenali->nand.ecc.layout->oobfree[0].length =\r\ndenali->mtd.oobsize - denali->nand.ecc.layout->eccbytes -\r\ndenali->bbtskipbytes;\r\ndenali->totalblks = denali->mtd.size >>\r\ndenali->nand.phys_erase_shift;\r\ndenali->blksperchip = denali->totalblks / denali->nand.numchips;\r\ndenali->nand.ecc.calculate = denali_ecc_calculate;\r\ndenali->nand.ecc.correct = denali_ecc_correct;\r\ndenali->nand.ecc.hwctl = denali_ecc_hwctl;\r\ndenali->nand.ecc.size = ECC_SECTOR_SIZE * denali->devnum;\r\ndenali->nand.ecc.read_page = denali_read_page;\r\ndenali->nand.ecc.read_page_raw = denali_read_page_raw;\r\ndenali->nand.ecc.write_page = denali_write_page;\r\ndenali->nand.ecc.write_page_raw = denali_write_page_raw;\r\ndenali->nand.ecc.read_oob = denali_read_oob;\r\ndenali->nand.ecc.write_oob = denali_write_oob;\r\ndenali->nand.erase_cmd = denali_erase;\r\nif (nand_scan_tail(&denali->mtd)) {\r\nret = -ENXIO;\r\ngoto failed_req_irq;\r\n}\r\nret = mtd_device_register(&denali->mtd, NULL, 0);\r\nif (ret) {\r\ndev_err(denali->dev, "Spectra: Failed to register MTD: %d\n",\r\nret);\r\ngoto failed_req_irq;\r\n}\r\nreturn 0;\r\nfailed_req_irq:\r\ndenali_irq_cleanup(denali->irq, denali);\r\nreturn ret;\r\n}\r\nvoid denali_remove(struct denali_nand_info *denali)\r\n{\r\ndenali_irq_cleanup(denali->irq, denali);\r\ndma_unmap_single(denali->dev, denali->buf.dma_buf,\r\ndenali->mtd.writesize + denali->mtd.oobsize,\r\nDMA_BIDIRECTIONAL);\r\n}
