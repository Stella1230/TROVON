static int padata_index_to_cpu(struct parallel_data *pd, int cpu_index)\r\n{\r\nint cpu, target_cpu;\r\ntarget_cpu = cpumask_first(pd->cpumask.pcpu);\r\nfor (cpu = 0; cpu < cpu_index; cpu++)\r\ntarget_cpu = cpumask_next(target_cpu, pd->cpumask.pcpu);\r\nreturn target_cpu;\r\n}\r\nstatic int padata_cpu_hash(struct parallel_data *pd)\r\n{\r\nunsigned int seq_nr;\r\nint cpu_index;\r\nseq_nr = atomic_inc_return(&pd->seq_nr);\r\ncpu_index = seq_nr % cpumask_weight(pd->cpumask.pcpu);\r\nreturn padata_index_to_cpu(pd, cpu_index);\r\n}\r\nstatic void padata_parallel_worker(struct work_struct *parallel_work)\r\n{\r\nstruct padata_parallel_queue *pqueue;\r\nstruct parallel_data *pd;\r\nstruct padata_instance *pinst;\r\nLIST_HEAD(local_list);\r\nlocal_bh_disable();\r\npqueue = container_of(parallel_work,\r\nstruct padata_parallel_queue, work);\r\npd = pqueue->pd;\r\npinst = pd->pinst;\r\nspin_lock(&pqueue->parallel.lock);\r\nlist_replace_init(&pqueue->parallel.list, &local_list);\r\nspin_unlock(&pqueue->parallel.lock);\r\nwhile (!list_empty(&local_list)) {\r\nstruct padata_priv *padata;\r\npadata = list_entry(local_list.next,\r\nstruct padata_priv, list);\r\nlist_del_init(&padata->list);\r\npadata->parallel(padata);\r\n}\r\nlocal_bh_enable();\r\n}\r\nint padata_do_parallel(struct padata_instance *pinst,\r\nstruct padata_priv *padata, int cb_cpu)\r\n{\r\nint target_cpu, err;\r\nstruct padata_parallel_queue *queue;\r\nstruct parallel_data *pd;\r\nrcu_read_lock_bh();\r\npd = rcu_dereference_bh(pinst->pd);\r\nerr = -EINVAL;\r\nif (!(pinst->flags & PADATA_INIT) || pinst->flags & PADATA_INVALID)\r\ngoto out;\r\nif (!cpumask_test_cpu(cb_cpu, pd->cpumask.cbcpu))\r\ngoto out;\r\nerr = -EBUSY;\r\nif ((pinst->flags & PADATA_RESET))\r\ngoto out;\r\nif (atomic_read(&pd->refcnt) >= MAX_OBJ_NUM)\r\ngoto out;\r\nerr = 0;\r\natomic_inc(&pd->refcnt);\r\npadata->pd = pd;\r\npadata->cb_cpu = cb_cpu;\r\ntarget_cpu = padata_cpu_hash(pd);\r\nqueue = per_cpu_ptr(pd->pqueue, target_cpu);\r\nspin_lock(&queue->parallel.lock);\r\nlist_add_tail(&padata->list, &queue->parallel.list);\r\nspin_unlock(&queue->parallel.lock);\r\nqueue_work_on(target_cpu, pinst->wq, &queue->work);\r\nout:\r\nrcu_read_unlock_bh();\r\nreturn err;\r\n}\r\nstatic struct padata_priv *padata_get_next(struct parallel_data *pd)\r\n{\r\nint cpu, num_cpus;\r\nunsigned int next_nr, next_index;\r\nstruct padata_parallel_queue *next_queue;\r\nstruct padata_priv *padata;\r\nstruct padata_list *reorder;\r\nnum_cpus = cpumask_weight(pd->cpumask.pcpu);\r\nnext_nr = pd->processed;\r\nnext_index = next_nr % num_cpus;\r\ncpu = padata_index_to_cpu(pd, next_index);\r\nnext_queue = per_cpu_ptr(pd->pqueue, cpu);\r\npadata = NULL;\r\nreorder = &next_queue->reorder;\r\nif (!list_empty(&reorder->list)) {\r\npadata = list_entry(reorder->list.next,\r\nstruct padata_priv, list);\r\nspin_lock(&reorder->lock);\r\nlist_del_init(&padata->list);\r\natomic_dec(&pd->reorder_objects);\r\nspin_unlock(&reorder->lock);\r\npd->processed++;\r\ngoto out;\r\n}\r\nif (__this_cpu_read(pd->pqueue->cpu_index) == next_queue->cpu_index) {\r\npadata = ERR_PTR(-ENODATA);\r\ngoto out;\r\n}\r\npadata = ERR_PTR(-EINPROGRESS);\r\nout:\r\nreturn padata;\r\n}\r\nstatic void padata_reorder(struct parallel_data *pd)\r\n{\r\nint cb_cpu;\r\nstruct padata_priv *padata;\r\nstruct padata_serial_queue *squeue;\r\nstruct padata_instance *pinst = pd->pinst;\r\nif (!spin_trylock_bh(&pd->lock))\r\nreturn;\r\nwhile (1) {\r\npadata = padata_get_next(pd);\r\nif (!padata || PTR_ERR(padata) == -EINPROGRESS)\r\nbreak;\r\nif (PTR_ERR(padata) == -ENODATA) {\r\ndel_timer(&pd->timer);\r\nspin_unlock_bh(&pd->lock);\r\nreturn;\r\n}\r\ncb_cpu = padata->cb_cpu;\r\nsqueue = per_cpu_ptr(pd->squeue, cb_cpu);\r\nspin_lock(&squeue->serial.lock);\r\nlist_add_tail(&padata->list, &squeue->serial.list);\r\nspin_unlock(&squeue->serial.lock);\r\nqueue_work_on(cb_cpu, pinst->wq, &squeue->work);\r\n}\r\nspin_unlock_bh(&pd->lock);\r\nif (atomic_read(&pd->reorder_objects)\r\n&& !(pinst->flags & PADATA_RESET))\r\nmod_timer(&pd->timer, jiffies + HZ);\r\nelse\r\ndel_timer(&pd->timer);\r\nreturn;\r\n}\r\nstatic void padata_reorder_timer(unsigned long arg)\r\n{\r\nstruct parallel_data *pd = (struct parallel_data *)arg;\r\npadata_reorder(pd);\r\n}\r\nstatic void padata_serial_worker(struct work_struct *serial_work)\r\n{\r\nstruct padata_serial_queue *squeue;\r\nstruct parallel_data *pd;\r\nLIST_HEAD(local_list);\r\nlocal_bh_disable();\r\nsqueue = container_of(serial_work, struct padata_serial_queue, work);\r\npd = squeue->pd;\r\nspin_lock(&squeue->serial.lock);\r\nlist_replace_init(&squeue->serial.list, &local_list);\r\nspin_unlock(&squeue->serial.lock);\r\nwhile (!list_empty(&local_list)) {\r\nstruct padata_priv *padata;\r\npadata = list_entry(local_list.next,\r\nstruct padata_priv, list);\r\nlist_del_init(&padata->list);\r\npadata->serial(padata);\r\natomic_dec(&pd->refcnt);\r\n}\r\nlocal_bh_enable();\r\n}\r\nvoid padata_do_serial(struct padata_priv *padata)\r\n{\r\nint cpu;\r\nstruct padata_parallel_queue *pqueue;\r\nstruct parallel_data *pd;\r\npd = padata->pd;\r\ncpu = get_cpu();\r\npqueue = per_cpu_ptr(pd->pqueue, cpu);\r\nspin_lock(&pqueue->reorder.lock);\r\natomic_inc(&pd->reorder_objects);\r\nlist_add_tail(&padata->list, &pqueue->reorder.list);\r\nspin_unlock(&pqueue->reorder.lock);\r\nput_cpu();\r\npadata_reorder(pd);\r\n}\r\nstatic int padata_setup_cpumasks(struct parallel_data *pd,\r\nconst struct cpumask *pcpumask,\r\nconst struct cpumask *cbcpumask)\r\n{\r\nif (!alloc_cpumask_var(&pd->cpumask.pcpu, GFP_KERNEL))\r\nreturn -ENOMEM;\r\ncpumask_and(pd->cpumask.pcpu, pcpumask, cpu_online_mask);\r\nif (!alloc_cpumask_var(&pd->cpumask.cbcpu, GFP_KERNEL)) {\r\nfree_cpumask_var(pd->cpumask.cbcpu);\r\nreturn -ENOMEM;\r\n}\r\ncpumask_and(pd->cpumask.cbcpu, cbcpumask, cpu_online_mask);\r\nreturn 0;\r\n}\r\nstatic void __padata_list_init(struct padata_list *pd_list)\r\n{\r\nINIT_LIST_HEAD(&pd_list->list);\r\nspin_lock_init(&pd_list->lock);\r\n}\r\nstatic void padata_init_squeues(struct parallel_data *pd)\r\n{\r\nint cpu;\r\nstruct padata_serial_queue *squeue;\r\nfor_each_cpu(cpu, pd->cpumask.cbcpu) {\r\nsqueue = per_cpu_ptr(pd->squeue, cpu);\r\nsqueue->pd = pd;\r\n__padata_list_init(&squeue->serial);\r\nINIT_WORK(&squeue->work, padata_serial_worker);\r\n}\r\n}\r\nstatic void padata_init_pqueues(struct parallel_data *pd)\r\n{\r\nint cpu_index, cpu;\r\nstruct padata_parallel_queue *pqueue;\r\ncpu_index = 0;\r\nfor_each_cpu(cpu, pd->cpumask.pcpu) {\r\npqueue = per_cpu_ptr(pd->pqueue, cpu);\r\npqueue->pd = pd;\r\npqueue->cpu_index = cpu_index;\r\ncpu_index++;\r\n__padata_list_init(&pqueue->reorder);\r\n__padata_list_init(&pqueue->parallel);\r\nINIT_WORK(&pqueue->work, padata_parallel_worker);\r\natomic_set(&pqueue->num_obj, 0);\r\n}\r\n}\r\nstatic struct parallel_data *padata_alloc_pd(struct padata_instance *pinst,\r\nconst struct cpumask *pcpumask,\r\nconst struct cpumask *cbcpumask)\r\n{\r\nstruct parallel_data *pd;\r\npd = kzalloc(sizeof(struct parallel_data), GFP_KERNEL);\r\nif (!pd)\r\ngoto err;\r\npd->pqueue = alloc_percpu(struct padata_parallel_queue);\r\nif (!pd->pqueue)\r\ngoto err_free_pd;\r\npd->squeue = alloc_percpu(struct padata_serial_queue);\r\nif (!pd->squeue)\r\ngoto err_free_pqueue;\r\nif (padata_setup_cpumasks(pd, pcpumask, cbcpumask) < 0)\r\ngoto err_free_squeue;\r\npadata_init_pqueues(pd);\r\npadata_init_squeues(pd);\r\nsetup_timer(&pd->timer, padata_reorder_timer, (unsigned long)pd);\r\natomic_set(&pd->seq_nr, -1);\r\natomic_set(&pd->reorder_objects, 0);\r\natomic_set(&pd->refcnt, 0);\r\npd->pinst = pinst;\r\nspin_lock_init(&pd->lock);\r\nreturn pd;\r\nerr_free_squeue:\r\nfree_percpu(pd->squeue);\r\nerr_free_pqueue:\r\nfree_percpu(pd->pqueue);\r\nerr_free_pd:\r\nkfree(pd);\r\nerr:\r\nreturn NULL;\r\n}\r\nstatic void padata_free_pd(struct parallel_data *pd)\r\n{\r\nfree_cpumask_var(pd->cpumask.pcpu);\r\nfree_cpumask_var(pd->cpumask.cbcpu);\r\nfree_percpu(pd->pqueue);\r\nfree_percpu(pd->squeue);\r\nkfree(pd);\r\n}\r\nstatic void padata_flush_queues(struct parallel_data *pd)\r\n{\r\nint cpu;\r\nstruct padata_parallel_queue *pqueue;\r\nstruct padata_serial_queue *squeue;\r\nfor_each_cpu(cpu, pd->cpumask.pcpu) {\r\npqueue = per_cpu_ptr(pd->pqueue, cpu);\r\nflush_work(&pqueue->work);\r\n}\r\ndel_timer_sync(&pd->timer);\r\nif (atomic_read(&pd->reorder_objects))\r\npadata_reorder(pd);\r\nfor_each_cpu(cpu, pd->cpumask.cbcpu) {\r\nsqueue = per_cpu_ptr(pd->squeue, cpu);\r\nflush_work(&squeue->work);\r\n}\r\nBUG_ON(atomic_read(&pd->refcnt) != 0);\r\n}\r\nstatic void __padata_start(struct padata_instance *pinst)\r\n{\r\npinst->flags |= PADATA_INIT;\r\n}\r\nstatic void __padata_stop(struct padata_instance *pinst)\r\n{\r\nif (!(pinst->flags & PADATA_INIT))\r\nreturn;\r\npinst->flags &= ~PADATA_INIT;\r\nsynchronize_rcu();\r\nget_online_cpus();\r\npadata_flush_queues(pinst->pd);\r\nput_online_cpus();\r\n}\r\nstatic void padata_replace(struct padata_instance *pinst,\r\nstruct parallel_data *pd_new)\r\n{\r\nstruct parallel_data *pd_old = pinst->pd;\r\nint notification_mask = 0;\r\npinst->flags |= PADATA_RESET;\r\nrcu_assign_pointer(pinst->pd, pd_new);\r\nsynchronize_rcu();\r\nif (!cpumask_equal(pd_old->cpumask.pcpu, pd_new->cpumask.pcpu))\r\nnotification_mask |= PADATA_CPU_PARALLEL;\r\nif (!cpumask_equal(pd_old->cpumask.cbcpu, pd_new->cpumask.cbcpu))\r\nnotification_mask |= PADATA_CPU_SERIAL;\r\npadata_flush_queues(pd_old);\r\npadata_free_pd(pd_old);\r\nif (notification_mask)\r\nblocking_notifier_call_chain(&pinst->cpumask_change_notifier,\r\nnotification_mask,\r\n&pd_new->cpumask);\r\npinst->flags &= ~PADATA_RESET;\r\n}\r\nint padata_register_cpumask_notifier(struct padata_instance *pinst,\r\nstruct notifier_block *nblock)\r\n{\r\nreturn blocking_notifier_chain_register(&pinst->cpumask_change_notifier,\r\nnblock);\r\n}\r\nint padata_unregister_cpumask_notifier(struct padata_instance *pinst,\r\nstruct notifier_block *nblock)\r\n{\r\nreturn blocking_notifier_chain_unregister(\r\n&pinst->cpumask_change_notifier,\r\nnblock);\r\n}\r\nstatic bool padata_validate_cpumask(struct padata_instance *pinst,\r\nconst struct cpumask *cpumask)\r\n{\r\nif (!cpumask_intersects(cpumask, cpu_online_mask)) {\r\npinst->flags |= PADATA_INVALID;\r\nreturn false;\r\n}\r\npinst->flags &= ~PADATA_INVALID;\r\nreturn true;\r\n}\r\nstatic int __padata_set_cpumasks(struct padata_instance *pinst,\r\ncpumask_var_t pcpumask,\r\ncpumask_var_t cbcpumask)\r\n{\r\nint valid;\r\nstruct parallel_data *pd;\r\nvalid = padata_validate_cpumask(pinst, pcpumask);\r\nif (!valid) {\r\n__padata_stop(pinst);\r\ngoto out_replace;\r\n}\r\nvalid = padata_validate_cpumask(pinst, cbcpumask);\r\nif (!valid)\r\n__padata_stop(pinst);\r\nout_replace:\r\npd = padata_alloc_pd(pinst, pcpumask, cbcpumask);\r\nif (!pd)\r\nreturn -ENOMEM;\r\ncpumask_copy(pinst->cpumask.pcpu, pcpumask);\r\ncpumask_copy(pinst->cpumask.cbcpu, cbcpumask);\r\npadata_replace(pinst, pd);\r\nif (valid)\r\n__padata_start(pinst);\r\nreturn 0;\r\n}\r\nint padata_set_cpumasks(struct padata_instance *pinst, cpumask_var_t pcpumask,\r\ncpumask_var_t cbcpumask)\r\n{\r\nint err;\r\nmutex_lock(&pinst->lock);\r\nget_online_cpus();\r\nerr = __padata_set_cpumasks(pinst, pcpumask, cbcpumask);\r\nput_online_cpus();\r\nmutex_unlock(&pinst->lock);\r\nreturn err;\r\n}\r\nint padata_set_cpumask(struct padata_instance *pinst, int cpumask_type,\r\ncpumask_var_t cpumask)\r\n{\r\nstruct cpumask *serial_mask, *parallel_mask;\r\nint err = -EINVAL;\r\nmutex_lock(&pinst->lock);\r\nget_online_cpus();\r\nswitch (cpumask_type) {\r\ncase PADATA_CPU_PARALLEL:\r\nserial_mask = pinst->cpumask.cbcpu;\r\nparallel_mask = cpumask;\r\nbreak;\r\ncase PADATA_CPU_SERIAL:\r\nparallel_mask = pinst->cpumask.pcpu;\r\nserial_mask = cpumask;\r\nbreak;\r\ndefault:\r\ngoto out;\r\n}\r\nerr = __padata_set_cpumasks(pinst, parallel_mask, serial_mask);\r\nout:\r\nput_online_cpus();\r\nmutex_unlock(&pinst->lock);\r\nreturn err;\r\n}\r\nstatic int __padata_add_cpu(struct padata_instance *pinst, int cpu)\r\n{\r\nstruct parallel_data *pd;\r\nif (cpumask_test_cpu(cpu, cpu_online_mask)) {\r\npd = padata_alloc_pd(pinst, pinst->cpumask.pcpu,\r\npinst->cpumask.cbcpu);\r\nif (!pd)\r\nreturn -ENOMEM;\r\npadata_replace(pinst, pd);\r\nif (padata_validate_cpumask(pinst, pinst->cpumask.pcpu) &&\r\npadata_validate_cpumask(pinst, pinst->cpumask.cbcpu))\r\n__padata_start(pinst);\r\n}\r\nreturn 0;\r\n}\r\nint padata_add_cpu(struct padata_instance *pinst, int cpu, int mask)\r\n{\r\nint err;\r\nif (!(mask & (PADATA_CPU_SERIAL | PADATA_CPU_PARALLEL)))\r\nreturn -EINVAL;\r\nmutex_lock(&pinst->lock);\r\nget_online_cpus();\r\nif (mask & PADATA_CPU_SERIAL)\r\ncpumask_set_cpu(cpu, pinst->cpumask.cbcpu);\r\nif (mask & PADATA_CPU_PARALLEL)\r\ncpumask_set_cpu(cpu, pinst->cpumask.pcpu);\r\nerr = __padata_add_cpu(pinst, cpu);\r\nput_online_cpus();\r\nmutex_unlock(&pinst->lock);\r\nreturn err;\r\n}\r\nstatic int __padata_remove_cpu(struct padata_instance *pinst, int cpu)\r\n{\r\nstruct parallel_data *pd = NULL;\r\nif (cpumask_test_cpu(cpu, cpu_online_mask)) {\r\nif (!padata_validate_cpumask(pinst, pinst->cpumask.pcpu) ||\r\n!padata_validate_cpumask(pinst, pinst->cpumask.cbcpu))\r\n__padata_stop(pinst);\r\npd = padata_alloc_pd(pinst, pinst->cpumask.pcpu,\r\npinst->cpumask.cbcpu);\r\nif (!pd)\r\nreturn -ENOMEM;\r\npadata_replace(pinst, pd);\r\ncpumask_clear_cpu(cpu, pd->cpumask.cbcpu);\r\ncpumask_clear_cpu(cpu, pd->cpumask.pcpu);\r\n}\r\nreturn 0;\r\n}\r\nint padata_remove_cpu(struct padata_instance *pinst, int cpu, int mask)\r\n{\r\nint err;\r\nif (!(mask & (PADATA_CPU_SERIAL | PADATA_CPU_PARALLEL)))\r\nreturn -EINVAL;\r\nmutex_lock(&pinst->lock);\r\nget_online_cpus();\r\nif (mask & PADATA_CPU_SERIAL)\r\ncpumask_clear_cpu(cpu, pinst->cpumask.cbcpu);\r\nif (mask & PADATA_CPU_PARALLEL)\r\ncpumask_clear_cpu(cpu, pinst->cpumask.pcpu);\r\nerr = __padata_remove_cpu(pinst, cpu);\r\nput_online_cpus();\r\nmutex_unlock(&pinst->lock);\r\nreturn err;\r\n}\r\nint padata_start(struct padata_instance *pinst)\r\n{\r\nint err = 0;\r\nmutex_lock(&pinst->lock);\r\nif (pinst->flags & PADATA_INVALID)\r\nerr =-EINVAL;\r\n__padata_start(pinst);\r\nmutex_unlock(&pinst->lock);\r\nreturn err;\r\n}\r\nvoid padata_stop(struct padata_instance *pinst)\r\n{\r\nmutex_lock(&pinst->lock);\r\n__padata_stop(pinst);\r\nmutex_unlock(&pinst->lock);\r\n}\r\nstatic inline int pinst_has_cpu(struct padata_instance *pinst, int cpu)\r\n{\r\nreturn cpumask_test_cpu(cpu, pinst->cpumask.pcpu) ||\r\ncpumask_test_cpu(cpu, pinst->cpumask.cbcpu);\r\n}\r\nstatic int padata_cpu_callback(struct notifier_block *nfb,\r\nunsigned long action, void *hcpu)\r\n{\r\nint err;\r\nstruct padata_instance *pinst;\r\nint cpu = (unsigned long)hcpu;\r\npinst = container_of(nfb, struct padata_instance, cpu_notifier);\r\nswitch (action) {\r\ncase CPU_ONLINE:\r\ncase CPU_ONLINE_FROZEN:\r\ncase CPU_DOWN_FAILED:\r\ncase CPU_DOWN_FAILED_FROZEN:\r\nif (!pinst_has_cpu(pinst, cpu))\r\nbreak;\r\nmutex_lock(&pinst->lock);\r\nerr = __padata_add_cpu(pinst, cpu);\r\nmutex_unlock(&pinst->lock);\r\nif (err)\r\nreturn notifier_from_errno(err);\r\nbreak;\r\ncase CPU_DOWN_PREPARE:\r\ncase CPU_DOWN_PREPARE_FROZEN:\r\ncase CPU_UP_CANCELED:\r\ncase CPU_UP_CANCELED_FROZEN:\r\nif (!pinst_has_cpu(pinst, cpu))\r\nbreak;\r\nmutex_lock(&pinst->lock);\r\nerr = __padata_remove_cpu(pinst, cpu);\r\nmutex_unlock(&pinst->lock);\r\nif (err)\r\nreturn notifier_from_errno(err);\r\nbreak;\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic void __padata_free(struct padata_instance *pinst)\r\n{\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nunregister_hotcpu_notifier(&pinst->cpu_notifier);\r\n#endif\r\npadata_stop(pinst);\r\npadata_free_pd(pinst->pd);\r\nfree_cpumask_var(pinst->cpumask.pcpu);\r\nfree_cpumask_var(pinst->cpumask.cbcpu);\r\nkfree(pinst);\r\n}\r\nstatic void padata_sysfs_release(struct kobject *kobj)\r\n{\r\nstruct padata_instance *pinst = kobj2pinst(kobj);\r\n__padata_free(pinst);\r\n}\r\nstatic ssize_t show_cpumask(struct padata_instance *pinst,\r\nstruct attribute *attr, char *buf)\r\n{\r\nstruct cpumask *cpumask;\r\nssize_t len;\r\nmutex_lock(&pinst->lock);\r\nif (!strcmp(attr->name, "serial_cpumask"))\r\ncpumask = pinst->cpumask.cbcpu;\r\nelse\r\ncpumask = pinst->cpumask.pcpu;\r\nlen = bitmap_scnprintf(buf, PAGE_SIZE, cpumask_bits(cpumask),\r\nnr_cpu_ids);\r\nif (PAGE_SIZE - len < 2)\r\nlen = -EINVAL;\r\nelse\r\nlen += sprintf(buf + len, "\n");\r\nmutex_unlock(&pinst->lock);\r\nreturn len;\r\n}\r\nstatic ssize_t store_cpumask(struct padata_instance *pinst,\r\nstruct attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\ncpumask_var_t new_cpumask;\r\nssize_t ret;\r\nint mask_type;\r\nif (!alloc_cpumask_var(&new_cpumask, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nret = bitmap_parse(buf, count, cpumask_bits(new_cpumask),\r\nnr_cpumask_bits);\r\nif (ret < 0)\r\ngoto out;\r\nmask_type = !strcmp(attr->name, "serial_cpumask") ?\r\nPADATA_CPU_SERIAL : PADATA_CPU_PARALLEL;\r\nret = padata_set_cpumask(pinst, mask_type, new_cpumask);\r\nif (!ret)\r\nret = count;\r\nout:\r\nfree_cpumask_var(new_cpumask);\r\nreturn ret;\r\n}\r\nstatic ssize_t padata_sysfs_show(struct kobject *kobj,\r\nstruct attribute *attr, char *buf)\r\n{\r\nstruct padata_instance *pinst;\r\nstruct padata_sysfs_entry *pentry;\r\nssize_t ret = -EIO;\r\npinst = kobj2pinst(kobj);\r\npentry = attr2pentry(attr);\r\nif (pentry->show)\r\nret = pentry->show(pinst, attr, buf);\r\nreturn ret;\r\n}\r\nstatic ssize_t padata_sysfs_store(struct kobject *kobj, struct attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct padata_instance *pinst;\r\nstruct padata_sysfs_entry *pentry;\r\nssize_t ret = -EIO;\r\npinst = kobj2pinst(kobj);\r\npentry = attr2pentry(attr);\r\nif (pentry->show)\r\nret = pentry->store(pinst, attr, buf, count);\r\nreturn ret;\r\n}\r\nstruct padata_instance *padata_alloc_possible(struct workqueue_struct *wq)\r\n{\r\nreturn padata_alloc(wq, cpu_possible_mask, cpu_possible_mask);\r\n}\r\nstruct padata_instance *padata_alloc(struct workqueue_struct *wq,\r\nconst struct cpumask *pcpumask,\r\nconst struct cpumask *cbcpumask)\r\n{\r\nstruct padata_instance *pinst;\r\nstruct parallel_data *pd = NULL;\r\npinst = kzalloc(sizeof(struct padata_instance), GFP_KERNEL);\r\nif (!pinst)\r\ngoto err;\r\nget_online_cpus();\r\nif (!alloc_cpumask_var(&pinst->cpumask.pcpu, GFP_KERNEL))\r\ngoto err_free_inst;\r\nif (!alloc_cpumask_var(&pinst->cpumask.cbcpu, GFP_KERNEL)) {\r\nfree_cpumask_var(pinst->cpumask.pcpu);\r\ngoto err_free_inst;\r\n}\r\nif (!padata_validate_cpumask(pinst, pcpumask) ||\r\n!padata_validate_cpumask(pinst, cbcpumask))\r\ngoto err_free_masks;\r\npd = padata_alloc_pd(pinst, pcpumask, cbcpumask);\r\nif (!pd)\r\ngoto err_free_masks;\r\nrcu_assign_pointer(pinst->pd, pd);\r\npinst->wq = wq;\r\ncpumask_copy(pinst->cpumask.pcpu, pcpumask);\r\ncpumask_copy(pinst->cpumask.cbcpu, cbcpumask);\r\npinst->flags = 0;\r\nput_online_cpus();\r\nBLOCKING_INIT_NOTIFIER_HEAD(&pinst->cpumask_change_notifier);\r\nkobject_init(&pinst->kobj, &padata_attr_type);\r\nmutex_init(&pinst->lock);\r\n#ifdef CONFIG_HOTPLUG_CPU\r\npinst->cpu_notifier.notifier_call = padata_cpu_callback;\r\npinst->cpu_notifier.priority = 0;\r\nregister_hotcpu_notifier(&pinst->cpu_notifier);\r\n#endif\r\nreturn pinst;\r\nerr_free_masks:\r\nfree_cpumask_var(pinst->cpumask.pcpu);\r\nfree_cpumask_var(pinst->cpumask.cbcpu);\r\nerr_free_inst:\r\nkfree(pinst);\r\nput_online_cpus();\r\nerr:\r\nreturn NULL;\r\n}\r\nvoid padata_free(struct padata_instance *pinst)\r\n{\r\nkobject_put(&pinst->kobj);\r\n}
