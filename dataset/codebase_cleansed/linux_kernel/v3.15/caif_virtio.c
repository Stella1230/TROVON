static void cfv_release_cb(struct virtqueue *vq_tx)\r\n{\r\nstruct cfv_info *cfv = vq_tx->vdev->priv;\r\n++cfv->stats.tx_kicks;\r\ntasklet_schedule(&cfv->tx_release_tasklet);\r\n}\r\nstatic void free_buf_info(struct cfv_info *cfv, struct buf_info *buf_info)\r\n{\r\nif (!buf_info)\r\nreturn;\r\ngen_pool_free(cfv->genpool, (unsigned long) buf_info->vaddr,\r\nbuf_info->size);\r\nkfree(buf_info);\r\n}\r\nstatic void cfv_release_used_buf(struct virtqueue *vq_tx)\r\n{\r\nstruct cfv_info *cfv = vq_tx->vdev->priv;\r\nunsigned long flags;\r\nBUG_ON(vq_tx != cfv->vq_tx);\r\nfor (;;) {\r\nunsigned int len;\r\nstruct buf_info *buf_info;\r\nspin_lock_irqsave(&cfv->tx_lock, flags);\r\nbuf_info = virtqueue_get_buf(vq_tx, &len);\r\nspin_unlock_irqrestore(&cfv->tx_lock, flags);\r\nif (!buf_info)\r\nbreak;\r\nfree_buf_info(cfv, buf_info);\r\nif (cfv->vq_tx->num_free <= cfv->watermark_tx)\r\ncontinue;\r\nif (cfv->reserved_mem == 0 && cfv->genpool)\r\ncfv->reserved_mem =\r\ngen_pool_alloc(cfv->genpool,\r\ncfv->reserved_size);\r\nif (cfv->reserved_mem) {\r\ncfv->watermark_tx =\r\nvirtqueue_get_vring_size(cfv->vq_tx);\r\nnetif_tx_wake_all_queues(cfv->ndev);\r\nvirtqueue_disable_cb(cfv->vq_tx);\r\n++cfv->stats.tx_flow_on;\r\n} else {\r\nWARN_ON(cfv->watermark_tx >\r\nvirtqueue_get_vring_size(cfv->vq_tx));\r\ncfv->watermark_tx +=\r\nvirtqueue_get_vring_size(cfv->vq_tx) / 4;\r\n}\r\n}\r\n}\r\nstatic struct sk_buff *cfv_alloc_and_copy_skb(int *err,\r\nstruct cfv_info *cfv,\r\nu8 *frm, u32 frm_len)\r\n{\r\nstruct sk_buff *skb;\r\nu32 cfpkt_len, pad_len;\r\n*err = 0;\r\nif (frm_len > cfv->mru || frm_len <= cfv->rx_hr + cfv->rx_tr) {\r\nnetdev_err(cfv->ndev,\r\n"Invalid frmlen:%u mtu:%u hr:%d tr:%d\n",\r\nfrm_len, cfv->mru, cfv->rx_hr,\r\ncfv->rx_tr);\r\n*err = -EPROTO;\r\nreturn NULL;\r\n}\r\ncfpkt_len = frm_len - (cfv->rx_hr + cfv->rx_tr);\r\npad_len = (unsigned long)(frm + cfv->rx_hr) & (IP_HDR_ALIGN - 1);\r\nskb = netdev_alloc_skb(cfv->ndev, frm_len + pad_len);\r\nif (!skb) {\r\n*err = -ENOMEM;\r\nreturn NULL;\r\n}\r\nskb_reserve(skb, cfv->rx_hr + pad_len);\r\nmemcpy(skb_put(skb, cfpkt_len), frm + cfv->rx_hr, cfpkt_len);\r\nreturn skb;\r\n}\r\nstatic int cfv_rx_poll(struct napi_struct *napi, int quota)\r\n{\r\nstruct cfv_info *cfv = container_of(napi, struct cfv_info, napi);\r\nint rxcnt = 0;\r\nint err = 0;\r\nvoid *buf;\r\nstruct sk_buff *skb;\r\nstruct vringh_kiov *riov = &cfv->ctx.riov;\r\nunsigned int skb_len;\r\nagain:\r\ndo {\r\nskb = NULL;\r\nif (riov->i == riov->used) {\r\nif (cfv->ctx.head != USHRT_MAX) {\r\nvringh_complete_kern(cfv->vr_rx,\r\ncfv->ctx.head,\r\n0);\r\ncfv->ctx.head = USHRT_MAX;\r\n}\r\nerr = vringh_getdesc_kern(\r\ncfv->vr_rx,\r\nriov,\r\nNULL,\r\n&cfv->ctx.head,\r\nGFP_ATOMIC);\r\nif (err <= 0)\r\ngoto exit;\r\n}\r\nbuf = phys_to_virt((unsigned long) riov->iov[riov->i].iov_base);\r\nskb = cfv_alloc_and_copy_skb(&err, cfv, buf,\r\nriov->iov[riov->i].iov_len);\r\nif (unlikely(err))\r\ngoto exit;\r\nskb_len = skb->len;\r\nskb->protocol = htons(ETH_P_CAIF);\r\nskb_reset_mac_header(skb);\r\nskb->dev = cfv->ndev;\r\nerr = netif_receive_skb(skb);\r\nif (unlikely(err)) {\r\n++cfv->ndev->stats.rx_dropped;\r\n} else {\r\n++cfv->ndev->stats.rx_packets;\r\ncfv->ndev->stats.rx_bytes += skb_len;\r\n}\r\n++riov->i;\r\n++rxcnt;\r\n} while (rxcnt < quota);\r\n++cfv->stats.rx_napi_resched;\r\ngoto out;\r\nexit:\r\nswitch (err) {\r\ncase 0:\r\n++cfv->stats.rx_napi_complete;\r\nnapi_complete(napi);\r\nif (unlikely(!vringh_notify_enable_kern(cfv->vr_rx)) &&\r\nnapi_schedule_prep(napi)) {\r\nvringh_notify_disable_kern(cfv->vr_rx);\r\n__napi_schedule(napi);\r\ngoto again;\r\n}\r\nbreak;\r\ncase -ENOMEM:\r\n++cfv->stats.rx_nomem;\r\ndev_kfree_skb(skb);\r\nnapi_complete(napi);\r\nvringh_notify_enable_kern(cfv->vr_rx);\r\nbreak;\r\ndefault:\r\nnetdev_warn(cfv->ndev, "Bad ring, disable device\n");\r\ncfv->ndev->stats.rx_dropped = riov->used - riov->i;\r\nnapi_complete(napi);\r\nvringh_notify_disable_kern(cfv->vr_rx);\r\nnetif_carrier_off(cfv->ndev);\r\nbreak;\r\n}\r\nout:\r\nif (rxcnt && vringh_need_notify_kern(cfv->vr_rx) > 0)\r\nvringh_notify(cfv->vr_rx);\r\nreturn rxcnt;\r\n}\r\nstatic void cfv_recv(struct virtio_device *vdev, struct vringh *vr_rx)\r\n{\r\nstruct cfv_info *cfv = vdev->priv;\r\n++cfv->stats.rx_kicks;\r\nvringh_notify_disable_kern(cfv->vr_rx);\r\nnapi_schedule(&cfv->napi);\r\n}\r\nstatic void cfv_destroy_genpool(struct cfv_info *cfv)\r\n{\r\nif (cfv->alloc_addr)\r\ndma_free_coherent(cfv->vdev->dev.parent->parent,\r\ncfv->allocsz, cfv->alloc_addr,\r\ncfv->alloc_dma);\r\nif (!cfv->genpool)\r\nreturn;\r\ngen_pool_free(cfv->genpool, cfv->reserved_mem,\r\ncfv->reserved_size);\r\ngen_pool_destroy(cfv->genpool);\r\ncfv->genpool = NULL;\r\n}\r\nstatic int cfv_create_genpool(struct cfv_info *cfv)\r\n{\r\nint err;\r\nerr = -ENOMEM;\r\ncfv->allocsz = (virtqueue_get_vring_size(cfv->vq_tx) *\r\n(ETH_DATA_LEN + cfv->tx_hr + cfv->tx_tr) * 11)/10;\r\nif (cfv->allocsz <= (num_possible_cpus() + 1) * cfv->ndev->mtu)\r\nreturn -EINVAL;\r\nfor (;;) {\r\nif (cfv->allocsz <= num_possible_cpus() * cfv->ndev->mtu) {\r\nnetdev_info(cfv->ndev, "Not enough device memory\n");\r\nreturn -ENOMEM;\r\n}\r\ncfv->alloc_addr = dma_alloc_coherent(\r\ncfv->vdev->dev.parent->parent,\r\ncfv->allocsz, &cfv->alloc_dma,\r\nGFP_ATOMIC);\r\nif (cfv->alloc_addr)\r\nbreak;\r\ncfv->allocsz = (cfv->allocsz * 3) >> 2;\r\n}\r\nnetdev_dbg(cfv->ndev, "Allocated %zd bytes from dma-memory\n",\r\ncfv->allocsz);\r\ncfv->genpool = gen_pool_create(7, -1);\r\nif (!cfv->genpool)\r\ngoto err;\r\nerr = gen_pool_add_virt(cfv->genpool, (unsigned long)cfv->alloc_addr,\r\n(phys_addr_t)virt_to_phys(cfv->alloc_addr),\r\ncfv->allocsz, -1);\r\nif (err)\r\ngoto err;\r\ncfv->reserved_size = num_possible_cpus() * cfv->ndev->mtu;\r\ncfv->reserved_mem = gen_pool_alloc(cfv->genpool,\r\ncfv->reserved_size);\r\nif (!cfv->reserved_mem) {\r\nerr = -ENOMEM;\r\ngoto err;\r\n}\r\ncfv->watermark_tx = virtqueue_get_vring_size(cfv->vq_tx);\r\nreturn 0;\r\nerr:\r\ncfv_destroy_genpool(cfv);\r\nreturn err;\r\n}\r\nstatic int cfv_netdev_open(struct net_device *netdev)\r\n{\r\nstruct cfv_info *cfv = netdev_priv(netdev);\r\nif (cfv_create_genpool(cfv))\r\nreturn -ENOMEM;\r\nnetif_carrier_on(netdev);\r\nnapi_enable(&cfv->napi);\r\nnapi_schedule(&cfv->napi);\r\nreturn 0;\r\n}\r\nstatic int cfv_netdev_close(struct net_device *netdev)\r\n{\r\nstruct cfv_info *cfv = netdev_priv(netdev);\r\nunsigned long flags;\r\nstruct buf_info *buf_info;\r\nnetif_carrier_off(netdev);\r\nvirtqueue_disable_cb(cfv->vq_tx);\r\nvringh_notify_disable_kern(cfv->vr_rx);\r\nnapi_disable(&cfv->napi);\r\ncfv_release_used_buf(cfv->vq_tx);\r\nspin_lock_irqsave(&cfv->tx_lock, flags);\r\nwhile ((buf_info = virtqueue_detach_unused_buf(cfv->vq_tx)))\r\nfree_buf_info(cfv, buf_info);\r\nspin_unlock_irqrestore(&cfv->tx_lock, flags);\r\ncfv_destroy_genpool(cfv);\r\nreturn 0;\r\n}\r\nstatic struct buf_info *cfv_alloc_and_copy_to_shm(struct cfv_info *cfv,\r\nstruct sk_buff *skb,\r\nstruct scatterlist *sg)\r\n{\r\nstruct caif_payload_info *info = (void *)&skb->cb;\r\nstruct buf_info *buf_info = NULL;\r\nu8 pad_len, hdr_ofs;\r\nif (!cfv->genpool)\r\ngoto err;\r\nif (unlikely(cfv->tx_hr + skb->len + cfv->tx_tr > cfv->mtu)) {\r\nnetdev_warn(cfv->ndev, "Invalid packet len (%d > %d)\n",\r\ncfv->tx_hr + skb->len + cfv->tx_tr, cfv->mtu);\r\ngoto err;\r\n}\r\nbuf_info = kmalloc(sizeof(struct buf_info), GFP_ATOMIC);\r\nif (unlikely(!buf_info))\r\ngoto err;\r\nhdr_ofs = cfv->tx_hr + info->hdr_len;\r\npad_len = hdr_ofs & (IP_HDR_ALIGN - 1);\r\nbuf_info->size = cfv->tx_hr + skb->len + cfv->tx_tr + pad_len;\r\nbuf_info->vaddr = (void *)gen_pool_alloc(cfv->genpool, buf_info->size);\r\nif (unlikely(!buf_info->vaddr))\r\ngoto err;\r\nskb_copy_bits(skb, 0, buf_info->vaddr + cfv->tx_hr + pad_len, skb->len);\r\nsg_init_one(sg, buf_info->vaddr + pad_len,\r\nskb->len + cfv->tx_hr + cfv->rx_hr);\r\nreturn buf_info;\r\nerr:\r\nkfree(buf_info);\r\nreturn NULL;\r\n}\r\nstatic int cfv_netdev_tx(struct sk_buff *skb, struct net_device *netdev)\r\n{\r\nstruct cfv_info *cfv = netdev_priv(netdev);\r\nstruct buf_info *buf_info;\r\nstruct scatterlist sg;\r\nunsigned long flags;\r\nbool flow_off = false;\r\nint ret;\r\ncfv_release_used_buf(cfv->vq_tx);\r\nspin_lock_irqsave(&cfv->tx_lock, flags);\r\nif (unlikely(cfv->vq_tx->num_free <= num_present_cpus())) {\r\nflow_off = true;\r\ncfv->stats.tx_full_ring++;\r\n}\r\nbuf_info = cfv_alloc_and_copy_to_shm(cfv, skb, &sg);\r\nif (unlikely(!buf_info)) {\r\ncfv->stats.tx_no_mem++;\r\nflow_off = true;\r\nif (cfv->reserved_mem && cfv->genpool) {\r\ngen_pool_free(cfv->genpool, cfv->reserved_mem,\r\ncfv->reserved_size);\r\ncfv->reserved_mem = 0;\r\nbuf_info = cfv_alloc_and_copy_to_shm(cfv, skb, &sg);\r\n}\r\n}\r\nif (unlikely(flow_off)) {\r\ncfv->watermark_tx = virtqueue_get_vring_size(cfv->vq_tx) / 4;\r\nvirtqueue_enable_cb(cfv->vq_tx);\r\nnetif_tx_stop_all_queues(netdev);\r\n}\r\nif (unlikely(!buf_info)) {\r\nnetdev_warn(cfv->ndev, "Out of gen_pool memory\n");\r\ngoto err;\r\n}\r\nret = virtqueue_add_outbuf(cfv->vq_tx, &sg, 1, buf_info, GFP_ATOMIC);\r\nif (unlikely((ret < 0))) {\r\nnetdev_warn(cfv->ndev, "Failed adding buffer to TX vring:%d\n",\r\nret);\r\ngoto err;\r\n}\r\ncfv->ndev->stats.tx_packets++;\r\ncfv->ndev->stats.tx_bytes += skb->len;\r\nspin_unlock_irqrestore(&cfv->tx_lock, flags);\r\nvirtqueue_kick(cfv->vq_tx);\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\nerr:\r\nspin_unlock_irqrestore(&cfv->tx_lock, flags);\r\ncfv->ndev->stats.tx_dropped++;\r\nfree_buf_info(cfv, buf_info);\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void cfv_tx_release_tasklet(unsigned long drv)\r\n{\r\nstruct cfv_info *cfv = (struct cfv_info *)drv;\r\ncfv_release_used_buf(cfv->vq_tx);\r\n}\r\nstatic void cfv_netdev_setup(struct net_device *netdev)\r\n{\r\nnetdev->netdev_ops = &cfv_netdev_ops;\r\nnetdev->type = ARPHRD_CAIF;\r\nnetdev->tx_queue_len = 100;\r\nnetdev->flags = IFF_POINTOPOINT | IFF_NOARP;\r\nnetdev->mtu = CFV_DEF_MTU_SIZE;\r\nnetdev->destructor = free_netdev;\r\n}\r\nstatic inline void debugfs_init(struct cfv_info *cfv)\r\n{\r\ncfv->debugfs =\r\ndebugfs_create_dir(netdev_name(cfv->ndev), NULL);\r\nif (IS_ERR(cfv->debugfs))\r\nreturn;\r\ndebugfs_create_u32("rx-napi-complete", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.rx_napi_complete);\r\ndebugfs_create_u32("rx-napi-resched", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.rx_napi_resched);\r\ndebugfs_create_u32("rx-nomem", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.rx_nomem);\r\ndebugfs_create_u32("rx-kicks", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.rx_kicks);\r\ndebugfs_create_u32("tx-full-ring", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.tx_full_ring);\r\ndebugfs_create_u32("tx-no-mem", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.tx_no_mem);\r\ndebugfs_create_u32("tx-kicks", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.tx_kicks);\r\ndebugfs_create_u32("tx-flow-on", S_IRUSR, cfv->debugfs,\r\n&cfv->stats.tx_flow_on);\r\n}\r\nstatic int cfv_probe(struct virtio_device *vdev)\r\n{\r\nvq_callback_t *vq_cbs = cfv_release_cb;\r\nvrh_callback_t *vrh_cbs = cfv_recv;\r\nconst char *names = "output";\r\nconst char *cfv_netdev_name = "cfvrt";\r\nstruct net_device *netdev;\r\nstruct cfv_info *cfv;\r\nint err = -EINVAL;\r\nnetdev = alloc_netdev(sizeof(struct cfv_info), cfv_netdev_name,\r\ncfv_netdev_setup);\r\nif (!netdev)\r\nreturn -ENOMEM;\r\ncfv = netdev_priv(netdev);\r\ncfv->vdev = vdev;\r\ncfv->ndev = netdev;\r\nspin_lock_init(&cfv->tx_lock);\r\nerr = -ENODEV;\r\nif (!vdev->vringh_config || !vdev->vringh_config->find_vrhs)\r\ngoto err;\r\nerr = vdev->vringh_config->find_vrhs(vdev, 1, &cfv->vr_rx, &vrh_cbs);\r\nif (err)\r\ngoto err;\r\nerr = vdev->config->find_vqs(vdev, 1, &cfv->vq_tx, &vq_cbs, &names);\r\nif (err)\r\ngoto err;\r\nif (vdev->config->get) {\r\nvirtio_cread(vdev, struct virtio_caif_transf_config, headroom,\r\n&cfv->tx_hr);\r\nvirtio_cread(vdev, struct virtio_caif_transf_config, headroom,\r\n&cfv->rx_hr);\r\nvirtio_cread(vdev, struct virtio_caif_transf_config, tailroom,\r\n&cfv->tx_tr);\r\nvirtio_cread(vdev, struct virtio_caif_transf_config, tailroom,\r\n&cfv->rx_tr);\r\nvirtio_cread(vdev, struct virtio_caif_transf_config, mtu,\r\n&cfv->mtu);\r\nvirtio_cread(vdev, struct virtio_caif_transf_config, mtu,\r\n&cfv->mru);\r\n} else {\r\ncfv->tx_hr = CFV_DEF_HEADROOM;\r\ncfv->rx_hr = CFV_DEF_HEADROOM;\r\ncfv->tx_tr = CFV_DEF_TAILROOM;\r\ncfv->rx_tr = CFV_DEF_TAILROOM;\r\ncfv->mtu = CFV_DEF_MTU_SIZE;\r\ncfv->mru = CFV_DEF_MTU_SIZE;\r\n}\r\nnetdev->needed_headroom = cfv->tx_hr;\r\nnetdev->needed_tailroom = cfv->tx_tr;\r\nvirtqueue_disable_cb(cfv->vq_tx);\r\nnetdev->mtu = cfv->mtu - cfv->tx_tr;\r\nvdev->priv = cfv;\r\nvringh_kiov_init(&cfv->ctx.riov, NULL, 0);\r\ncfv->ctx.head = USHRT_MAX;\r\nnetif_napi_add(netdev, &cfv->napi, cfv_rx_poll, CFV_DEFAULT_QUOTA);\r\ntasklet_init(&cfv->tx_release_tasklet,\r\ncfv_tx_release_tasklet,\r\n(unsigned long)cfv);\r\nnetif_carrier_off(netdev);\r\nerr = register_netdev(netdev);\r\nif (err) {\r\ndev_err(&vdev->dev, "Unable to register netdev (%d)\n", err);\r\ngoto err;\r\n}\r\ndebugfs_init(cfv);\r\nreturn 0;\r\nerr:\r\nnetdev_warn(cfv->ndev, "CAIF Virtio probe failed:%d\n", err);\r\nif (cfv->vr_rx)\r\nvdev->vringh_config->del_vrhs(cfv->vdev);\r\nif (cfv->vdev)\r\nvdev->config->del_vqs(cfv->vdev);\r\nfree_netdev(netdev);\r\nreturn err;\r\n}\r\nstatic void cfv_remove(struct virtio_device *vdev)\r\n{\r\nstruct cfv_info *cfv = vdev->priv;\r\nrtnl_lock();\r\ndev_close(cfv->ndev);\r\nrtnl_unlock();\r\ntasklet_kill(&cfv->tx_release_tasklet);\r\ndebugfs_remove_recursive(cfv->debugfs);\r\nvringh_kiov_cleanup(&cfv->ctx.riov);\r\nvdev->config->reset(vdev);\r\nvdev->vringh_config->del_vrhs(cfv->vdev);\r\ncfv->vr_rx = NULL;\r\nvdev->config->del_vqs(cfv->vdev);\r\nunregister_netdev(cfv->ndev);\r\n}
