static int get_idr(struct idr *idr, int *id)\r\n{\r\nint ret;\r\nmutex_lock(&cooling_cpufreq_lock);\r\nret = idr_alloc(idr, NULL, 0, 0, GFP_KERNEL);\r\nmutex_unlock(&cooling_cpufreq_lock);\r\nif (unlikely(ret < 0))\r\nreturn ret;\r\n*id = ret;\r\nreturn 0;\r\n}\r\nstatic void release_idr(struct idr *idr, int id)\r\n{\r\nmutex_lock(&cooling_cpufreq_lock);\r\nidr_remove(idr, id);\r\nmutex_unlock(&cooling_cpufreq_lock);\r\n}\r\nstatic int is_cpufreq_valid(int cpu)\r\n{\r\nstruct cpufreq_policy policy;\r\nreturn !cpufreq_get_policy(&policy, cpu);\r\n}\r\nstatic int get_property(unsigned int cpu, unsigned long input,\r\nunsigned int *output,\r\nenum cpufreq_cooling_property property)\r\n{\r\nint i, j;\r\nunsigned long max_level = 0, level = 0;\r\nunsigned int freq = CPUFREQ_ENTRY_INVALID;\r\nint descend = -1;\r\nstruct cpufreq_frequency_table *table =\r\ncpufreq_frequency_get_table(cpu);\r\nif (!output)\r\nreturn -EINVAL;\r\nif (!table)\r\nreturn -EINVAL;\r\nfor (i = 0; table[i].frequency != CPUFREQ_TABLE_END; i++) {\r\nif (table[i].frequency == CPUFREQ_ENTRY_INVALID)\r\ncontinue;\r\nif (freq == table[i].frequency)\r\ncontinue;\r\nif (freq != CPUFREQ_ENTRY_INVALID && descend == -1)\r\ndescend = !!(freq > table[i].frequency);\r\nfreq = table[i].frequency;\r\nmax_level++;\r\n}\r\nif (max_level == 0)\r\nreturn -EINVAL;\r\nmax_level--;\r\nif (property == GET_MAXL) {\r\n*output = (unsigned int)max_level;\r\nreturn 0;\r\n}\r\nif (property == GET_FREQ)\r\nlevel = descend ? input : (max_level - input);\r\nfor (i = 0, j = 0; table[i].frequency != CPUFREQ_TABLE_END; i++) {\r\nif (table[i].frequency == CPUFREQ_ENTRY_INVALID)\r\ncontinue;\r\nif (freq == table[i].frequency)\r\ncontinue;\r\nfreq = table[i].frequency;\r\nif (property == GET_LEVEL && (unsigned int)input == freq) {\r\n*output = descend ? j : (max_level - j);\r\nreturn 0;\r\n}\r\nif (property == GET_FREQ && level == j) {\r\n*output = freq;\r\nreturn 0;\r\n}\r\nj++;\r\n}\r\nreturn -EINVAL;\r\n}\r\nunsigned long cpufreq_cooling_get_level(unsigned int cpu, unsigned int freq)\r\n{\r\nunsigned int val;\r\nif (get_property(cpu, (unsigned long)freq, &val, GET_LEVEL))\r\nreturn THERMAL_CSTATE_INVALID;\r\nreturn (unsigned long)val;\r\n}\r\nstatic unsigned int get_cpu_frequency(unsigned int cpu, unsigned long level)\r\n{\r\nint ret = 0;\r\nunsigned int freq;\r\nret = get_property(cpu, level, &freq, GET_FREQ);\r\nif (ret)\r\nreturn 0;\r\nreturn freq;\r\n}\r\nstatic int cpufreq_apply_cooling(struct cpufreq_cooling_device *cpufreq_device,\r\nunsigned long cooling_state)\r\n{\r\nunsigned int cpuid, clip_freq;\r\nstruct cpumask *mask = &cpufreq_device->allowed_cpus;\r\nunsigned int cpu = cpumask_any(mask);\r\nif (cpufreq_device->cpufreq_state == cooling_state)\r\nreturn 0;\r\nclip_freq = get_cpu_frequency(cpu, cooling_state);\r\nif (!clip_freq)\r\nreturn -EINVAL;\r\ncpufreq_device->cpufreq_state = cooling_state;\r\ncpufreq_device->cpufreq_val = clip_freq;\r\nnotify_device = cpufreq_device;\r\nfor_each_cpu(cpuid, mask) {\r\nif (is_cpufreq_valid(cpuid))\r\ncpufreq_update_policy(cpuid);\r\n}\r\nnotify_device = NOTIFY_INVALID;\r\nreturn 0;\r\n}\r\nstatic int cpufreq_thermal_notifier(struct notifier_block *nb,\r\nunsigned long event, void *data)\r\n{\r\nstruct cpufreq_policy *policy = data;\r\nunsigned long max_freq = 0;\r\nif (event != CPUFREQ_ADJUST || notify_device == NOTIFY_INVALID)\r\nreturn 0;\r\nif (cpumask_test_cpu(policy->cpu, &notify_device->allowed_cpus))\r\nmax_freq = notify_device->cpufreq_val;\r\nelse\r\nreturn 0;\r\nif (max_freq > policy->user_policy.max)\r\nmax_freq = policy->user_policy.max;\r\nif (policy->max != max_freq)\r\ncpufreq_verify_within_limits(policy, 0, max_freq);\r\nreturn 0;\r\n}\r\nstatic int cpufreq_get_max_state(struct thermal_cooling_device *cdev,\r\nunsigned long *state)\r\n{\r\nstruct cpufreq_cooling_device *cpufreq_device = cdev->devdata;\r\nstruct cpumask *mask = &cpufreq_device->allowed_cpus;\r\nunsigned int cpu;\r\nunsigned int count = 0;\r\nint ret;\r\ncpu = cpumask_any(mask);\r\nret = get_property(cpu, 0, &count, GET_MAXL);\r\nif (count > 0)\r\n*state = count;\r\nreturn ret;\r\n}\r\nstatic int cpufreq_get_cur_state(struct thermal_cooling_device *cdev,\r\nunsigned long *state)\r\n{\r\nstruct cpufreq_cooling_device *cpufreq_device = cdev->devdata;\r\n*state = cpufreq_device->cpufreq_state;\r\nreturn 0;\r\n}\r\nstatic int cpufreq_set_cur_state(struct thermal_cooling_device *cdev,\r\nunsigned long state)\r\n{\r\nstruct cpufreq_cooling_device *cpufreq_device = cdev->devdata;\r\nreturn cpufreq_apply_cooling(cpufreq_device, state);\r\n}\r\nstatic struct thermal_cooling_device *\r\n__cpufreq_cooling_register(struct device_node *np,\r\nconst struct cpumask *clip_cpus)\r\n{\r\nstruct thermal_cooling_device *cool_dev;\r\nstruct cpufreq_cooling_device *cpufreq_dev = NULL;\r\nunsigned int min = 0, max = 0;\r\nchar dev_name[THERMAL_NAME_LENGTH];\r\nint ret = 0, i;\r\nstruct cpufreq_policy policy;\r\nfor_each_cpu(i, clip_cpus) {\r\nif (!cpufreq_get_policy(&policy, i))\r\ncontinue;\r\nif (min == 0 && max == 0) {\r\nmin = policy.cpuinfo.min_freq;\r\nmax = policy.cpuinfo.max_freq;\r\n} else {\r\nif (min != policy.cpuinfo.min_freq ||\r\nmax != policy.cpuinfo.max_freq)\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\n}\r\ncpufreq_dev = kzalloc(sizeof(struct cpufreq_cooling_device),\r\nGFP_KERNEL);\r\nif (!cpufreq_dev)\r\nreturn ERR_PTR(-ENOMEM);\r\ncpumask_copy(&cpufreq_dev->allowed_cpus, clip_cpus);\r\nret = get_idr(&cpufreq_idr, &cpufreq_dev->id);\r\nif (ret) {\r\nkfree(cpufreq_dev);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nsnprintf(dev_name, sizeof(dev_name), "thermal-cpufreq-%d",\r\ncpufreq_dev->id);\r\ncool_dev = thermal_of_cooling_device_register(np, dev_name, cpufreq_dev,\r\n&cpufreq_cooling_ops);\r\nif (IS_ERR(cool_dev)) {\r\nrelease_idr(&cpufreq_idr, cpufreq_dev->id);\r\nkfree(cpufreq_dev);\r\nreturn cool_dev;\r\n}\r\ncpufreq_dev->cool_dev = cool_dev;\r\ncpufreq_dev->cpufreq_state = 0;\r\nmutex_lock(&cooling_cpufreq_lock);\r\nif (cpufreq_dev_count == 0)\r\ncpufreq_register_notifier(&thermal_cpufreq_notifier_block,\r\nCPUFREQ_POLICY_NOTIFIER);\r\ncpufreq_dev_count++;\r\nmutex_unlock(&cooling_cpufreq_lock);\r\nreturn cool_dev;\r\n}\r\nstruct thermal_cooling_device *\r\ncpufreq_cooling_register(const struct cpumask *clip_cpus)\r\n{\r\nreturn __cpufreq_cooling_register(NULL, clip_cpus);\r\n}\r\nstruct thermal_cooling_device *\r\nof_cpufreq_cooling_register(struct device_node *np,\r\nconst struct cpumask *clip_cpus)\r\n{\r\nif (!np)\r\nreturn ERR_PTR(-EINVAL);\r\nreturn __cpufreq_cooling_register(np, clip_cpus);\r\n}\r\nvoid cpufreq_cooling_unregister(struct thermal_cooling_device *cdev)\r\n{\r\nstruct cpufreq_cooling_device *cpufreq_dev;\r\nif (!cdev)\r\nreturn;\r\ncpufreq_dev = cdev->devdata;\r\nmutex_lock(&cooling_cpufreq_lock);\r\ncpufreq_dev_count--;\r\nif (cpufreq_dev_count == 0)\r\ncpufreq_unregister_notifier(&thermal_cpufreq_notifier_block,\r\nCPUFREQ_POLICY_NOTIFIER);\r\nmutex_unlock(&cooling_cpufreq_lock);\r\nthermal_cooling_device_unregister(cpufreq_dev->cool_dev);\r\nrelease_idr(&cpufreq_idr, cpufreq_dev->id);\r\nkfree(cpufreq_dev);\r\n}
