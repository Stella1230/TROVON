static void ll_invalidatepage(struct page *vmpage, unsigned int offset,\r\nunsigned int length)\r\n{\r\nstruct inode *inode;\r\nstruct lu_env *env;\r\nstruct cl_page *page;\r\nstruct cl_object *obj;\r\nint refcheck;\r\nLASSERT(PageLocked(vmpage));\r\nLASSERT(!PageWriteback(vmpage));\r\nif (offset == 0 && length == PAGE_CACHE_SIZE) {\r\nenv = cl_env_get(&refcheck);\r\nif (!IS_ERR(env)) {\r\ninode = vmpage->mapping->host;\r\nobj = ll_i2info(inode)->lli_clob;\r\nif (obj != NULL) {\r\npage = cl_vmpage_page(vmpage, obj);\r\nif (page != NULL) {\r\nlu_ref_add(&page->cp_reference,\r\n"delete", vmpage);\r\ncl_page_delete(env, page);\r\nlu_ref_del(&page->cp_reference,\r\n"delete", vmpage);\r\ncl_page_put(env, page);\r\n}\r\n} else\r\nLASSERT(vmpage->private == 0);\r\ncl_env_put(env, &refcheck);\r\n}\r\n}\r\n}\r\nstatic int ll_releasepage(struct page *vmpage, RELEASEPAGE_ARG_TYPE gfp_mask)\r\n{\r\nstruct cl_env_nest nest;\r\nstruct lu_env *env;\r\nstruct cl_object *obj;\r\nstruct cl_page *page;\r\nstruct address_space *mapping;\r\nint result;\r\nLASSERT(PageLocked(vmpage));\r\nif (PageWriteback(vmpage) || PageDirty(vmpage))\r\nreturn 0;\r\nmapping = vmpage->mapping;\r\nif (mapping == NULL)\r\nreturn 1;\r\nobj = ll_i2info(mapping->host)->lli_clob;\r\nif (obj == NULL)\r\nreturn 1;\r\nif (page_count(vmpage) > 3)\r\nreturn 0;\r\nenv = cl_env_nested_get(&nest);\r\nif (IS_ERR(env))\r\nreturn 0;\r\npage = cl_vmpage_page(vmpage, obj);\r\nresult = page == NULL;\r\nif (page != NULL) {\r\nif (!cl_page_in_use(page)) {\r\nresult = 1;\r\ncl_page_delete(env, page);\r\n}\r\ncl_page_put(env, page);\r\n}\r\ncl_env_nested_put(&nest, env);\r\nreturn result;\r\n}\r\nstatic int ll_set_page_dirty(struct page *vmpage)\r\n{\r\n#if 0\r\nstruct cl_page *page = vvp_vmpage_page_transient(vmpage);\r\nstruct vvp_object *obj = cl_inode2vvp(vmpage->mapping->host);\r\nstruct vvp_page *cpg;\r\nLASSERT(&obj->co_cl == page->cp_obj);\r\ncpg = cl2vvp_page(cl_page_at(page, &vvp_device_type));\r\nvvp_write_pending(obj, cpg);\r\n#endif\r\nreturn __set_page_dirty_nobuffers(vmpage);\r\n}\r\nstatic inline int ll_get_user_pages(int rw, unsigned long user_addr,\r\nsize_t size, struct page ***pages,\r\nint *max_pages)\r\n{\r\nint result = -ENOMEM;\r\nif (size > MAX_DIRECTIO_SIZE) {\r\n*pages = NULL;\r\nreturn -EFBIG;\r\n}\r\n*max_pages = (user_addr + size + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT;\r\n*max_pages -= user_addr >> PAGE_CACHE_SHIFT;\r\nOBD_ALLOC_LARGE(*pages, *max_pages * sizeof(**pages));\r\nif (*pages) {\r\nresult = get_user_pages_fast(user_addr, *max_pages,\r\n(rw == READ), *pages);\r\nif (unlikely(result <= 0))\r\nOBD_FREE_LARGE(*pages, *max_pages * sizeof(**pages));\r\n}\r\nreturn result;\r\n}\r\nstatic void ll_free_user_pages(struct page **pages, int npages, int do_dirty)\r\n{\r\nint i;\r\nfor (i = 0; i < npages; i++) {\r\nif (pages[i] == NULL)\r\nbreak;\r\nif (do_dirty)\r\nset_page_dirty_lock(pages[i]);\r\npage_cache_release(pages[i]);\r\n}\r\nOBD_FREE_LARGE(pages, npages * sizeof(*pages));\r\n}\r\nssize_t ll_direct_rw_pages(const struct lu_env *env, struct cl_io *io,\r\nint rw, struct inode *inode,\r\nstruct ll_dio_pages *pv)\r\n{\r\nstruct cl_page *clp;\r\nstruct cl_2queue *queue;\r\nstruct cl_object *obj = io->ci_obj;\r\nint i;\r\nssize_t rc = 0;\r\nloff_t file_offset = pv->ldp_start_offset;\r\nlong size = pv->ldp_size;\r\nint page_count = pv->ldp_nr;\r\nstruct page **pages = pv->ldp_pages;\r\nlong page_size = cl_page_size(obj);\r\nbool do_io;\r\nint io_pages = 0;\r\nqueue = &io->ci_queue;\r\ncl_2queue_init(queue);\r\nfor (i = 0; i < page_count; i++) {\r\nif (pv->ldp_offsets)\r\nfile_offset = pv->ldp_offsets[i];\r\nLASSERT(!(file_offset & (page_size - 1)));\r\nclp = cl_page_find(env, obj, cl_index(obj, file_offset),\r\npv->ldp_pages[i], CPT_TRANSIENT);\r\nif (IS_ERR(clp)) {\r\nrc = PTR_ERR(clp);\r\nbreak;\r\n}\r\nrc = cl_page_own(env, io, clp);\r\nif (rc) {\r\nLASSERT(clp->cp_state == CPS_FREEING);\r\ncl_page_put(env, clp);\r\nbreak;\r\n}\r\ndo_io = true;\r\nif (clp->cp_type == CPT_CACHEABLE) {\r\nstruct page *vmpage = cl_page_vmpage(env, clp);\r\nstruct page *src_page;\r\nstruct page *dst_page;\r\nvoid *src;\r\nvoid *dst;\r\nsrc_page = (rw == WRITE) ? pages[i] : vmpage;\r\ndst_page = (rw == WRITE) ? vmpage : pages[i];\r\nsrc = kmap_atomic(src_page);\r\ndst = kmap_atomic(dst_page);\r\nmemcpy(dst, src, min(page_size, size));\r\nkunmap_atomic(dst);\r\nkunmap_atomic(src);\r\nif (rw == WRITE)\r\nset_page_dirty(vmpage);\r\nif (rw == READ) {\r\ncl_page_disown(env, io, clp);\r\ndo_io = false;\r\n}\r\n}\r\nif (likely(do_io)) {\r\ncl_2queue_add(queue, clp);\r\ncl_page_clip(env, clp, 0, min(size, page_size));\r\n++io_pages;\r\n}\r\ncl_page_put(env, clp);\r\nsize -= page_size;\r\nfile_offset += page_size;\r\n}\r\nif (rc == 0 && io_pages) {\r\nrc = cl_io_submit_sync(env, io,\r\nrw == READ ? CRT_READ : CRT_WRITE,\r\nqueue, 0);\r\n}\r\nif (rc == 0)\r\nrc = pv->ldp_size;\r\ncl_2queue_discard(env, io, queue);\r\ncl_2queue_disown(env, io, queue);\r\ncl_2queue_fini(env, queue);\r\nreturn rc;\r\n}\r\nstatic ssize_t ll_direct_IO_26_seg(const struct lu_env *env, struct cl_io *io,\r\nint rw, struct inode *inode,\r\nstruct address_space *mapping,\r\nsize_t size, loff_t file_offset,\r\nstruct page **pages, int page_count)\r\n{\r\nstruct ll_dio_pages pvec = { .ldp_pages = pages,\r\n.ldp_nr = page_count,\r\n.ldp_size = size,\r\n.ldp_offsets = NULL,\r\n.ldp_start_offset = file_offset\r\n};\r\nreturn ll_direct_rw_pages(env, io, rw, inode, &pvec);\r\n}\r\nstatic ssize_t ll_direct_IO_26(int rw, struct kiocb *iocb,\r\nconst struct iovec *iov, loff_t file_offset,\r\nunsigned long nr_segs)\r\n{\r\nstruct lu_env *env;\r\nstruct cl_io *io;\r\nstruct file *file = iocb->ki_filp;\r\nstruct inode *inode = file->f_mapping->host;\r\nstruct ccc_object *obj = cl_inode2ccc(inode);\r\nlong count = iov_length(iov, nr_segs);\r\nlong tot_bytes = 0, result = 0;\r\nstruct ll_inode_info *lli = ll_i2info(inode);\r\nunsigned long seg = 0;\r\nlong size = MAX_DIO_SIZE;\r\nint refcheck;\r\nif (!lli->lli_has_smd)\r\nreturn -EBADF;\r\nif ((file_offset & ~CFS_PAGE_MASK) || (count & ~CFS_PAGE_MASK))\r\nreturn -EINVAL;\r\nCDEBUG(D_VFSTRACE, "VFS Op:inode=%lu/%u(%p), size=%lu (max %lu), "\r\n"offset=%lld=%llx, pages %lu (max %lu)\n",\r\ninode->i_ino, inode->i_generation, inode, count, MAX_DIO_SIZE,\r\nfile_offset, file_offset, count >> PAGE_CACHE_SHIFT,\r\nMAX_DIO_SIZE >> PAGE_CACHE_SHIFT);\r\nfor (seg = 0; seg < nr_segs; seg++) {\r\nif (((unsigned long)iov[seg].iov_base & ~CFS_PAGE_MASK) ||\r\n(iov[seg].iov_len & ~CFS_PAGE_MASK))\r\nreturn -EINVAL;\r\n}\r\nenv = cl_env_get(&refcheck);\r\nLASSERT(!IS_ERR(env));\r\nio = ccc_env_io(env)->cui_cl.cis_io;\r\nLASSERT(io != NULL);\r\nif (rw == READ)\r\nmutex_lock(&inode->i_mutex);\r\nLASSERT(obj->cob_transient_pages == 0);\r\nfor (seg = 0; seg < nr_segs; seg++) {\r\nlong iov_left = iov[seg].iov_len;\r\nunsigned long user_addr = (unsigned long)iov[seg].iov_base;\r\nif (rw == READ) {\r\nif (file_offset >= i_size_read(inode))\r\nbreak;\r\nif (file_offset + iov_left > i_size_read(inode))\r\niov_left = i_size_read(inode) - file_offset;\r\n}\r\nwhile (iov_left > 0) {\r\nstruct page **pages;\r\nint page_count, max_pages = 0;\r\nlong bytes;\r\nbytes = min(size, iov_left);\r\npage_count = ll_get_user_pages(rw, user_addr, bytes,\r\n&pages, &max_pages);\r\nif (likely(page_count > 0)) {\r\nif (unlikely(page_count < max_pages))\r\nbytes = page_count << PAGE_CACHE_SHIFT;\r\nresult = ll_direct_IO_26_seg(env, io, rw, inode,\r\nfile->f_mapping,\r\nbytes, file_offset,\r\npages, page_count);\r\nll_free_user_pages(pages, max_pages, rw==READ);\r\n} else if (page_count == 0) {\r\nGOTO(out, result = -EFAULT);\r\n} else {\r\nresult = page_count;\r\n}\r\nif (unlikely(result <= 0)) {\r\nif (result == -ENOMEM &&\r\nsize > (PAGE_CACHE_SIZE / sizeof(*pages)) *\r\nPAGE_CACHE_SIZE) {\r\nsize = ((((size / 2) - 1) |\r\n~CFS_PAGE_MASK) + 1) &\r\nCFS_PAGE_MASK;\r\nCDEBUG(D_VFSTRACE,"DIO size now %lu\n",\r\nsize);\r\ncontinue;\r\n}\r\nGOTO(out, result);\r\n}\r\ntot_bytes += result;\r\nfile_offset += result;\r\niov_left -= result;\r\nuser_addr += result;\r\n}\r\n}\r\nout:\r\nLASSERT(obj->cob_transient_pages == 0);\r\nif (rw == READ)\r\nmutex_unlock(&inode->i_mutex);\r\nif (tot_bytes > 0) {\r\nif (rw == WRITE) {\r\nstruct lov_stripe_md *lsm;\r\nlsm = ccc_inode_lsm_get(inode);\r\nLASSERT(lsm != NULL);\r\nlov_stripe_lock(lsm);\r\nobd_adjust_kms(ll_i2dtexp(inode), lsm, file_offset, 0);\r\nlov_stripe_unlock(lsm);\r\nccc_inode_lsm_put(inode, lsm);\r\n}\r\n}\r\ncl_env_put(env, &refcheck);\r\nreturn tot_bytes ? : result;\r\n}\r\nstatic int ll_write_begin(struct file *file, struct address_space *mapping,\r\nloff_t pos, unsigned len, unsigned flags,\r\nstruct page **pagep, void **fsdata)\r\n{\r\npgoff_t index = pos >> PAGE_CACHE_SHIFT;\r\nstruct page *page;\r\nint rc;\r\nunsigned from = pos & (PAGE_CACHE_SIZE - 1);\r\npage = grab_cache_page_write_begin(mapping, index, flags);\r\nif (!page)\r\nreturn -ENOMEM;\r\n*pagep = page;\r\nrc = ll_prepare_write(file, page, from, from + len);\r\nif (rc) {\r\nunlock_page(page);\r\npage_cache_release(page);\r\n}\r\nreturn rc;\r\n}\r\nstatic int ll_write_end(struct file *file, struct address_space *mapping,\r\nloff_t pos, unsigned len, unsigned copied,\r\nstruct page *page, void *fsdata)\r\n{\r\nunsigned from = pos & (PAGE_CACHE_SIZE - 1);\r\nint rc;\r\nrc = ll_commit_write(file, page, from, from + copied);\r\nunlock_page(page);\r\npage_cache_release(page);\r\nreturn rc ?: copied;\r\n}\r\nint ll_migratepage(struct address_space *mapping,\r\nstruct page *newpage, struct page *page\r\n, enum migrate_mode mode\r\n)\r\n{\r\nreturn -EIO;\r\n}
