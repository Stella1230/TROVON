static void init_buckets(struct list_head *buckets)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < NUM_BUCKETS; i++)\r\nINIT_LIST_HEAD(buckets + i);\r\n}\r\nstatic int dm_hash_init(void)\r\n{\r\ninit_buckets(_name_buckets);\r\ninit_buckets(_uuid_buckets);\r\nreturn 0;\r\n}\r\nstatic void dm_hash_exit(void)\r\n{\r\ndm_hash_remove_all(false, false, false);\r\n}\r\nstatic unsigned int hash_str(const char *str)\r\n{\r\nconst unsigned int hash_mult = 2654435387U;\r\nunsigned int h = 0;\r\nwhile (*str)\r\nh = (h + (unsigned int) *str++) * hash_mult;\r\nreturn h & MASK_BUCKETS;\r\n}\r\nstatic struct hash_cell *__get_name_cell(const char *str)\r\n{\r\nstruct hash_cell *hc;\r\nunsigned int h = hash_str(str);\r\nlist_for_each_entry (hc, _name_buckets + h, name_list)\r\nif (!strcmp(hc->name, str)) {\r\ndm_get(hc->md);\r\nreturn hc;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct hash_cell *__get_uuid_cell(const char *str)\r\n{\r\nstruct hash_cell *hc;\r\nunsigned int h = hash_str(str);\r\nlist_for_each_entry (hc, _uuid_buckets + h, uuid_list)\r\nif (!strcmp(hc->uuid, str)) {\r\ndm_get(hc->md);\r\nreturn hc;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct hash_cell *__get_dev_cell(uint64_t dev)\r\n{\r\nstruct mapped_device *md;\r\nstruct hash_cell *hc;\r\nmd = dm_get_md(huge_decode_dev(dev));\r\nif (!md)\r\nreturn NULL;\r\nhc = dm_get_mdptr(md);\r\nif (!hc) {\r\ndm_put(md);\r\nreturn NULL;\r\n}\r\nreturn hc;\r\n}\r\nstatic struct hash_cell *alloc_cell(const char *name, const char *uuid,\r\nstruct mapped_device *md)\r\n{\r\nstruct hash_cell *hc;\r\nhc = kmalloc(sizeof(*hc), GFP_KERNEL);\r\nif (!hc)\r\nreturn NULL;\r\nhc->name = kstrdup(name, GFP_KERNEL);\r\nif (!hc->name) {\r\nkfree(hc);\r\nreturn NULL;\r\n}\r\nif (!uuid)\r\nhc->uuid = NULL;\r\nelse {\r\nhc->uuid = kstrdup(uuid, GFP_KERNEL);\r\nif (!hc->uuid) {\r\nkfree(hc->name);\r\nkfree(hc);\r\nreturn NULL;\r\n}\r\n}\r\nINIT_LIST_HEAD(&hc->name_list);\r\nINIT_LIST_HEAD(&hc->uuid_list);\r\nhc->md = md;\r\nhc->new_map = NULL;\r\nreturn hc;\r\n}\r\nstatic void free_cell(struct hash_cell *hc)\r\n{\r\nif (hc) {\r\nkfree(hc->name);\r\nkfree(hc->uuid);\r\nkfree(hc);\r\n}\r\n}\r\nstatic int dm_hash_insert(const char *name, const char *uuid, struct mapped_device *md)\r\n{\r\nstruct hash_cell *cell, *hc;\r\ncell = alloc_cell(name, uuid, md);\r\nif (!cell)\r\nreturn -ENOMEM;\r\ndown_write(&_hash_lock);\r\nhc = __get_name_cell(name);\r\nif (hc) {\r\ndm_put(hc->md);\r\ngoto bad;\r\n}\r\nlist_add(&cell->name_list, _name_buckets + hash_str(name));\r\nif (uuid) {\r\nhc = __get_uuid_cell(uuid);\r\nif (hc) {\r\nlist_del(&cell->name_list);\r\ndm_put(hc->md);\r\ngoto bad;\r\n}\r\nlist_add(&cell->uuid_list, _uuid_buckets + hash_str(uuid));\r\n}\r\ndm_get(md);\r\nmutex_lock(&dm_hash_cells_mutex);\r\ndm_set_mdptr(md, cell);\r\nmutex_unlock(&dm_hash_cells_mutex);\r\nup_write(&_hash_lock);\r\nreturn 0;\r\nbad:\r\nup_write(&_hash_lock);\r\nfree_cell(cell);\r\nreturn -EBUSY;\r\n}\r\nstatic struct dm_table *__hash_remove(struct hash_cell *hc)\r\n{\r\nstruct dm_table *table;\r\nint srcu_idx;\r\nlist_del(&hc->uuid_list);\r\nlist_del(&hc->name_list);\r\nmutex_lock(&dm_hash_cells_mutex);\r\ndm_set_mdptr(hc->md, NULL);\r\nmutex_unlock(&dm_hash_cells_mutex);\r\ntable = dm_get_live_table(hc->md, &srcu_idx);\r\nif (table)\r\ndm_table_event(table);\r\ndm_put_live_table(hc->md, srcu_idx);\r\ntable = NULL;\r\nif (hc->new_map)\r\ntable = hc->new_map;\r\ndm_put(hc->md);\r\nfree_cell(hc);\r\nreturn table;\r\n}\r\nstatic void dm_hash_remove_all(bool keep_open_devices, bool mark_deferred, bool only_deferred)\r\n{\r\nint i, dev_skipped;\r\nstruct hash_cell *hc;\r\nstruct mapped_device *md;\r\nstruct dm_table *t;\r\nretry:\r\ndev_skipped = 0;\r\ndown_write(&_hash_lock);\r\nfor (i = 0; i < NUM_BUCKETS; i++) {\r\nlist_for_each_entry(hc, _name_buckets + i, name_list) {\r\nmd = hc->md;\r\ndm_get(md);\r\nif (keep_open_devices &&\r\ndm_lock_for_deletion(md, mark_deferred, only_deferred)) {\r\ndm_put(md);\r\ndev_skipped++;\r\ncontinue;\r\n}\r\nt = __hash_remove(hc);\r\nup_write(&_hash_lock);\r\nif (t) {\r\ndm_sync_table(md);\r\ndm_table_destroy(t);\r\n}\r\ndm_put(md);\r\nif (likely(keep_open_devices))\r\ndm_destroy(md);\r\nelse\r\ndm_destroy_immediate(md);\r\ngoto retry;\r\n}\r\n}\r\nup_write(&_hash_lock);\r\nif (dev_skipped)\r\nDMWARN("remove_all left %d open device(s)", dev_skipped);\r\n}\r\nstatic void __set_cell_uuid(struct hash_cell *hc, char *new_uuid)\r\n{\r\nmutex_lock(&dm_hash_cells_mutex);\r\nhc->uuid = new_uuid;\r\nmutex_unlock(&dm_hash_cells_mutex);\r\nlist_add(&hc->uuid_list, _uuid_buckets + hash_str(new_uuid));\r\n}\r\nstatic char *__change_cell_name(struct hash_cell *hc, char *new_name)\r\n{\r\nchar *old_name;\r\nlist_del(&hc->name_list);\r\nold_name = hc->name;\r\nmutex_lock(&dm_hash_cells_mutex);\r\nhc->name = new_name;\r\nmutex_unlock(&dm_hash_cells_mutex);\r\nlist_add(&hc->name_list, _name_buckets + hash_str(new_name));\r\nreturn old_name;\r\n}\r\nstatic struct mapped_device *dm_hash_rename(struct dm_ioctl *param,\r\nconst char *new)\r\n{\r\nchar *new_data, *old_name = NULL;\r\nstruct hash_cell *hc;\r\nstruct dm_table *table;\r\nstruct mapped_device *md;\r\nunsigned change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\r\nint srcu_idx;\r\nnew_data = kstrdup(new, GFP_KERNEL);\r\nif (!new_data)\r\nreturn ERR_PTR(-ENOMEM);\r\ndown_write(&_hash_lock);\r\nif (change_uuid)\r\nhc = __get_uuid_cell(new);\r\nelse\r\nhc = __get_name_cell(new);\r\nif (hc) {\r\nDMWARN("Unable to change %s on mapped device %s to one that "\r\n"already exists: %s",\r\nchange_uuid ? "uuid" : "name",\r\nparam->name, new);\r\ndm_put(hc->md);\r\nup_write(&_hash_lock);\r\nkfree(new_data);\r\nreturn ERR_PTR(-EBUSY);\r\n}\r\nhc = __get_name_cell(param->name);\r\nif (!hc) {\r\nDMWARN("Unable to rename non-existent device, %s to %s%s",\r\nparam->name, change_uuid ? "uuid " : "", new);\r\nup_write(&_hash_lock);\r\nkfree(new_data);\r\nreturn ERR_PTR(-ENXIO);\r\n}\r\nif (change_uuid && hc->uuid) {\r\nDMWARN("Unable to change uuid of mapped device %s to %s "\r\n"because uuid is already set to %s",\r\nparam->name, new, hc->uuid);\r\ndm_put(hc->md);\r\nup_write(&_hash_lock);\r\nkfree(new_data);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nif (change_uuid)\r\n__set_cell_uuid(hc, new_data);\r\nelse\r\nold_name = __change_cell_name(hc, new_data);\r\ntable = dm_get_live_table(hc->md, &srcu_idx);\r\nif (table)\r\ndm_table_event(table);\r\ndm_put_live_table(hc->md, srcu_idx);\r\nif (!dm_kobject_uevent(hc->md, KOBJ_CHANGE, param->event_nr))\r\nparam->flags |= DM_UEVENT_GENERATED_FLAG;\r\nmd = hc->md;\r\nup_write(&_hash_lock);\r\nkfree(old_name);\r\nreturn md;\r\n}\r\nvoid dm_deferred_remove(void)\r\n{\r\ndm_hash_remove_all(true, false, true);\r\n}\r\nstatic int remove_all(struct dm_ioctl *param, size_t param_size)\r\n{\r\ndm_hash_remove_all(true, !!(param->flags & DM_DEFERRED_REMOVE), false);\r\nparam->data_size = 0;\r\nreturn 0;\r\n}\r\nstatic inline void *align_ptr(void *ptr)\r\n{\r\nreturn (void *) (((size_t) (ptr + ALIGN_MASK)) & ~ALIGN_MASK);\r\n}\r\nstatic void *get_result_buffer(struct dm_ioctl *param, size_t param_size,\r\nsize_t *len)\r\n{\r\nparam->data_start = align_ptr(param + 1) - (void *) param;\r\nif (param->data_start < param_size)\r\n*len = param_size - param->data_start;\r\nelse\r\n*len = 0;\r\nreturn ((void *) param) + param->data_start;\r\n}\r\nstatic int list_devices(struct dm_ioctl *param, size_t param_size)\r\n{\r\nunsigned int i;\r\nstruct hash_cell *hc;\r\nsize_t len, needed = 0;\r\nstruct gendisk *disk;\r\nstruct dm_name_list *nl, *old_nl = NULL;\r\ndown_write(&_hash_lock);\r\nfor (i = 0; i < NUM_BUCKETS; i++) {\r\nlist_for_each_entry (hc, _name_buckets + i, name_list) {\r\nneeded += sizeof(struct dm_name_list);\r\nneeded += strlen(hc->name) + 1;\r\nneeded += ALIGN_MASK;\r\n}\r\n}\r\nnl = get_result_buffer(param, param_size, &len);\r\nif (len < needed) {\r\nparam->flags |= DM_BUFFER_FULL_FLAG;\r\ngoto out;\r\n}\r\nparam->data_size = param->data_start + needed;\r\nnl->dev = 0;\r\nfor (i = 0; i < NUM_BUCKETS; i++) {\r\nlist_for_each_entry (hc, _name_buckets + i, name_list) {\r\nif (old_nl)\r\nold_nl->next = (uint32_t) ((void *) nl -\r\n(void *) old_nl);\r\ndisk = dm_disk(hc->md);\r\nnl->dev = huge_encode_dev(disk_devt(disk));\r\nnl->next = 0;\r\nstrcpy(nl->name, hc->name);\r\nold_nl = nl;\r\nnl = align_ptr(((void *) ++nl) + strlen(hc->name) + 1);\r\n}\r\n}\r\nout:\r\nup_write(&_hash_lock);\r\nreturn 0;\r\n}\r\nstatic void list_version_get_needed(struct target_type *tt, void *needed_param)\r\n{\r\nsize_t *needed = needed_param;\r\n*needed += sizeof(struct dm_target_versions);\r\n*needed += strlen(tt->name);\r\n*needed += ALIGN_MASK;\r\n}\r\nstatic void list_version_get_info(struct target_type *tt, void *param)\r\n{\r\nstruct vers_iter *info = param;\r\nif ((char *)info->vers + sizeof(tt->version) + strlen(tt->name) + 1 >\r\ninfo->end) {\r\ninfo->flags = DM_BUFFER_FULL_FLAG;\r\nreturn;\r\n}\r\nif (info->old_vers)\r\ninfo->old_vers->next = (uint32_t) ((void *)info->vers -\r\n(void *)info->old_vers);\r\ninfo->vers->version[0] = tt->version[0];\r\ninfo->vers->version[1] = tt->version[1];\r\ninfo->vers->version[2] = tt->version[2];\r\ninfo->vers->next = 0;\r\nstrcpy(info->vers->name, tt->name);\r\ninfo->old_vers = info->vers;\r\ninfo->vers = align_ptr(((void *) ++info->vers) + strlen(tt->name) + 1);\r\n}\r\nstatic int list_versions(struct dm_ioctl *param, size_t param_size)\r\n{\r\nsize_t len, needed = 0;\r\nstruct dm_target_versions *vers;\r\nstruct vers_iter iter_info;\r\ndm_target_iterate(list_version_get_needed, &needed);\r\nvers = get_result_buffer(param, param_size, &len);\r\nif (len < needed) {\r\nparam->flags |= DM_BUFFER_FULL_FLAG;\r\ngoto out;\r\n}\r\nparam->data_size = param->data_start + needed;\r\niter_info.param_size = param_size;\r\niter_info.old_vers = NULL;\r\niter_info.vers = vers;\r\niter_info.flags = 0;\r\niter_info.end = (char *)vers+len;\r\ndm_target_iterate(list_version_get_info, &iter_info);\r\nparam->flags |= iter_info.flags;\r\nout:\r\nreturn 0;\r\n}\r\nstatic int check_name(const char *name)\r\n{\r\nif (strchr(name, '/')) {\r\nDMWARN("invalid device name");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct dm_table *dm_get_inactive_table(struct mapped_device *md, int *srcu_idx)\r\n{\r\nstruct hash_cell *hc;\r\nstruct dm_table *table = NULL;\r\ndm_get_live_table(md, srcu_idx);\r\ndown_read(&_hash_lock);\r\nhc = dm_get_mdptr(md);\r\nif (!hc || hc->md != md) {\r\nDMWARN("device has been removed from the dev hash table.");\r\ngoto out;\r\n}\r\ntable = hc->new_map;\r\nout:\r\nup_read(&_hash_lock);\r\nreturn table;\r\n}\r\nstatic struct dm_table *dm_get_live_or_inactive_table(struct mapped_device *md,\r\nstruct dm_ioctl *param,\r\nint *srcu_idx)\r\n{\r\nreturn (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) ?\r\ndm_get_inactive_table(md, srcu_idx) : dm_get_live_table(md, srcu_idx);\r\n}\r\nstatic void __dev_status(struct mapped_device *md, struct dm_ioctl *param)\r\n{\r\nstruct gendisk *disk = dm_disk(md);\r\nstruct dm_table *table;\r\nint srcu_idx;\r\nparam->flags &= ~(DM_SUSPEND_FLAG | DM_READONLY_FLAG |\r\nDM_ACTIVE_PRESENT_FLAG);\r\nif (dm_suspended_md(md))\r\nparam->flags |= DM_SUSPEND_FLAG;\r\nif (dm_test_deferred_remove_flag(md))\r\nparam->flags |= DM_DEFERRED_REMOVE;\r\nparam->dev = huge_encode_dev(disk_devt(disk));\r\nparam->open_count = dm_open_count(md);\r\nparam->event_nr = dm_get_event_nr(md);\r\nparam->target_count = 0;\r\ntable = dm_get_live_table(md, &srcu_idx);\r\nif (table) {\r\nif (!(param->flags & DM_QUERY_INACTIVE_TABLE_FLAG)) {\r\nif (get_disk_ro(disk))\r\nparam->flags |= DM_READONLY_FLAG;\r\nparam->target_count = dm_table_get_num_targets(table);\r\n}\r\nparam->flags |= DM_ACTIVE_PRESENT_FLAG;\r\n}\r\ndm_put_live_table(md, srcu_idx);\r\nif (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) {\r\nint srcu_idx;\r\ntable = dm_get_inactive_table(md, &srcu_idx);\r\nif (table) {\r\nif (!(dm_table_get_mode(table) & FMODE_WRITE))\r\nparam->flags |= DM_READONLY_FLAG;\r\nparam->target_count = dm_table_get_num_targets(table);\r\n}\r\ndm_put_live_table(md, srcu_idx);\r\n}\r\n}\r\nstatic int dev_create(struct dm_ioctl *param, size_t param_size)\r\n{\r\nint r, m = DM_ANY_MINOR;\r\nstruct mapped_device *md;\r\nr = check_name(param->name);\r\nif (r)\r\nreturn r;\r\nif (param->flags & DM_PERSISTENT_DEV_FLAG)\r\nm = MINOR(huge_decode_dev(param->dev));\r\nr = dm_create(m, &md);\r\nif (r)\r\nreturn r;\r\nr = dm_hash_insert(param->name, *param->uuid ? param->uuid : NULL, md);\r\nif (r) {\r\ndm_put(md);\r\ndm_destroy(md);\r\nreturn r;\r\n}\r\nparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\r\n__dev_status(md, param);\r\ndm_put(md);\r\nreturn 0;\r\n}\r\nstatic struct hash_cell *__find_device_hash_cell(struct dm_ioctl *param)\r\n{\r\nstruct hash_cell *hc = NULL;\r\nif (*param->uuid) {\r\nif (*param->name || param->dev)\r\nreturn NULL;\r\nhc = __get_uuid_cell(param->uuid);\r\nif (!hc)\r\nreturn NULL;\r\n} else if (*param->name) {\r\nif (param->dev)\r\nreturn NULL;\r\nhc = __get_name_cell(param->name);\r\nif (!hc)\r\nreturn NULL;\r\n} else if (param->dev) {\r\nhc = __get_dev_cell(param->dev);\r\nif (!hc)\r\nreturn NULL;\r\n} else\r\nreturn NULL;\r\nstrlcpy(param->name, hc->name, sizeof(param->name));\r\nif (hc->uuid)\r\nstrlcpy(param->uuid, hc->uuid, sizeof(param->uuid));\r\nelse\r\nparam->uuid[0] = '\0';\r\nif (hc->new_map)\r\nparam->flags |= DM_INACTIVE_PRESENT_FLAG;\r\nelse\r\nparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\r\nreturn hc;\r\n}\r\nstatic struct mapped_device *find_device(struct dm_ioctl *param)\r\n{\r\nstruct hash_cell *hc;\r\nstruct mapped_device *md = NULL;\r\ndown_read(&_hash_lock);\r\nhc = __find_device_hash_cell(param);\r\nif (hc)\r\nmd = hc->md;\r\nup_read(&_hash_lock);\r\nreturn md;\r\n}\r\nstatic int dev_remove(struct dm_ioctl *param, size_t param_size)\r\n{\r\nstruct hash_cell *hc;\r\nstruct mapped_device *md;\r\nint r;\r\nstruct dm_table *t;\r\ndown_write(&_hash_lock);\r\nhc = __find_device_hash_cell(param);\r\nif (!hc) {\r\nDMDEBUG_LIMIT("device doesn't appear to be in the dev hash table.");\r\nup_write(&_hash_lock);\r\nreturn -ENXIO;\r\n}\r\nmd = hc->md;\r\nr = dm_lock_for_deletion(md, !!(param->flags & DM_DEFERRED_REMOVE), false);\r\nif (r) {\r\nif (r == -EBUSY && param->flags & DM_DEFERRED_REMOVE) {\r\nup_write(&_hash_lock);\r\ndm_put(md);\r\nreturn 0;\r\n}\r\nDMDEBUG_LIMIT("unable to remove open device %s", hc->name);\r\nup_write(&_hash_lock);\r\ndm_put(md);\r\nreturn r;\r\n}\r\nt = __hash_remove(hc);\r\nup_write(&_hash_lock);\r\nif (t) {\r\ndm_sync_table(md);\r\ndm_table_destroy(t);\r\n}\r\nparam->flags &= ~DM_DEFERRED_REMOVE;\r\nif (!dm_kobject_uevent(md, KOBJ_REMOVE, param->event_nr))\r\nparam->flags |= DM_UEVENT_GENERATED_FLAG;\r\ndm_put(md);\r\ndm_destroy(md);\r\nreturn 0;\r\n}\r\nstatic int invalid_str(char *str, void *end)\r\n{\r\nwhile ((void *) str < end)\r\nif (!*str++)\r\nreturn 0;\r\nreturn -EINVAL;\r\n}\r\nstatic int dev_rename(struct dm_ioctl *param, size_t param_size)\r\n{\r\nint r;\r\nchar *new_data = (char *) param + param->data_start;\r\nstruct mapped_device *md;\r\nunsigned change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\r\nif (new_data < param->data ||\r\ninvalid_str(new_data, (void *) param + param_size) || !*new_data ||\r\nstrlen(new_data) > (change_uuid ? DM_UUID_LEN - 1 : DM_NAME_LEN - 1)) {\r\nDMWARN("Invalid new mapped device name or uuid string supplied.");\r\nreturn -EINVAL;\r\n}\r\nif (!change_uuid) {\r\nr = check_name(new_data);\r\nif (r)\r\nreturn r;\r\n}\r\nmd = dm_hash_rename(param, new_data);\r\nif (IS_ERR(md))\r\nreturn PTR_ERR(md);\r\n__dev_status(md, param);\r\ndm_put(md);\r\nreturn 0;\r\n}\r\nstatic int dev_set_geometry(struct dm_ioctl *param, size_t param_size)\r\n{\r\nint r = -EINVAL, x;\r\nstruct mapped_device *md;\r\nstruct hd_geometry geometry;\r\nunsigned long indata[4];\r\nchar *geostr = (char *) param + param->data_start;\r\nchar dummy;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\nif (geostr < param->data ||\r\ninvalid_str(geostr, (void *) param + param_size)) {\r\nDMWARN("Invalid geometry supplied.");\r\ngoto out;\r\n}\r\nx = sscanf(geostr, "%lu %lu %lu %lu%c", indata,\r\nindata + 1, indata + 2, indata + 3, &dummy);\r\nif (x != 4) {\r\nDMWARN("Unable to interpret geometry settings.");\r\ngoto out;\r\n}\r\nif (indata[0] > 65535 || indata[1] > 255 ||\r\nindata[2] > 255 || indata[3] > ULONG_MAX) {\r\nDMWARN("Geometry exceeds range limits.");\r\ngoto out;\r\n}\r\ngeometry.cylinders = indata[0];\r\ngeometry.heads = indata[1];\r\ngeometry.sectors = indata[2];\r\ngeometry.start = indata[3];\r\nr = dm_set_geometry(md, &geometry);\r\nparam->data_size = 0;\r\nout:\r\ndm_put(md);\r\nreturn r;\r\n}\r\nstatic int do_suspend(struct dm_ioctl *param)\r\n{\r\nint r = 0;\r\nunsigned suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\r\nstruct mapped_device *md;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\nif (param->flags & DM_SKIP_LOCKFS_FLAG)\r\nsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\r\nif (param->flags & DM_NOFLUSH_FLAG)\r\nsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\r\nif (!dm_suspended_md(md)) {\r\nr = dm_suspend(md, suspend_flags);\r\nif (r)\r\ngoto out;\r\n}\r\n__dev_status(md, param);\r\nout:\r\ndm_put(md);\r\nreturn r;\r\n}\r\nstatic int do_resume(struct dm_ioctl *param)\r\n{\r\nint r = 0;\r\nunsigned suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\r\nstruct hash_cell *hc;\r\nstruct mapped_device *md;\r\nstruct dm_table *new_map, *old_map = NULL;\r\ndown_write(&_hash_lock);\r\nhc = __find_device_hash_cell(param);\r\nif (!hc) {\r\nDMDEBUG_LIMIT("device doesn't appear to be in the dev hash table.");\r\nup_write(&_hash_lock);\r\nreturn -ENXIO;\r\n}\r\nmd = hc->md;\r\nnew_map = hc->new_map;\r\nhc->new_map = NULL;\r\nparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\r\nup_write(&_hash_lock);\r\nif (new_map) {\r\nif (param->flags & DM_SKIP_LOCKFS_FLAG)\r\nsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\r\nif (param->flags & DM_NOFLUSH_FLAG)\r\nsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\r\nif (!dm_suspended_md(md))\r\ndm_suspend(md, suspend_flags);\r\nold_map = dm_swap_table(md, new_map);\r\nif (IS_ERR(old_map)) {\r\ndm_sync_table(md);\r\ndm_table_destroy(new_map);\r\ndm_put(md);\r\nreturn PTR_ERR(old_map);\r\n}\r\nif (dm_table_get_mode(new_map) & FMODE_WRITE)\r\nset_disk_ro(dm_disk(md), 0);\r\nelse\r\nset_disk_ro(dm_disk(md), 1);\r\n}\r\nif (dm_suspended_md(md)) {\r\nr = dm_resume(md);\r\nif (!r && !dm_kobject_uevent(md, KOBJ_CHANGE, param->event_nr))\r\nparam->flags |= DM_UEVENT_GENERATED_FLAG;\r\n}\r\nif (old_map)\r\ndm_table_destroy(old_map);\r\nif (!r)\r\n__dev_status(md, param);\r\ndm_put(md);\r\nreturn r;\r\n}\r\nstatic int dev_suspend(struct dm_ioctl *param, size_t param_size)\r\n{\r\nif (param->flags & DM_SUSPEND_FLAG)\r\nreturn do_suspend(param);\r\nreturn do_resume(param);\r\n}\r\nstatic int dev_status(struct dm_ioctl *param, size_t param_size)\r\n{\r\nstruct mapped_device *md;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\n__dev_status(md, param);\r\ndm_put(md);\r\nreturn 0;\r\n}\r\nstatic void retrieve_status(struct dm_table *table,\r\nstruct dm_ioctl *param, size_t param_size)\r\n{\r\nunsigned int i, num_targets;\r\nstruct dm_target_spec *spec;\r\nchar *outbuf, *outptr;\r\nstatus_type_t type;\r\nsize_t remaining, len, used = 0;\r\nunsigned status_flags = 0;\r\noutptr = outbuf = get_result_buffer(param, param_size, &len);\r\nif (param->flags & DM_STATUS_TABLE_FLAG)\r\ntype = STATUSTYPE_TABLE;\r\nelse\r\ntype = STATUSTYPE_INFO;\r\nnum_targets = dm_table_get_num_targets(table);\r\nfor (i = 0; i < num_targets; i++) {\r\nstruct dm_target *ti = dm_table_get_target(table, i);\r\nsize_t l;\r\nremaining = len - (outptr - outbuf);\r\nif (remaining <= sizeof(struct dm_target_spec)) {\r\nparam->flags |= DM_BUFFER_FULL_FLAG;\r\nbreak;\r\n}\r\nspec = (struct dm_target_spec *) outptr;\r\nspec->status = 0;\r\nspec->sector_start = ti->begin;\r\nspec->length = ti->len;\r\nstrncpy(spec->target_type, ti->type->name,\r\nsizeof(spec->target_type));\r\noutptr += sizeof(struct dm_target_spec);\r\nremaining = len - (outptr - outbuf);\r\nif (remaining <= 0) {\r\nparam->flags |= DM_BUFFER_FULL_FLAG;\r\nbreak;\r\n}\r\nif (ti->type->status) {\r\nif (param->flags & DM_NOFLUSH_FLAG)\r\nstatus_flags |= DM_STATUS_NOFLUSH_FLAG;\r\nti->type->status(ti, type, status_flags, outptr, remaining);\r\n} else\r\noutptr[0] = '\0';\r\nl = strlen(outptr) + 1;\r\nif (l == remaining) {\r\nparam->flags |= DM_BUFFER_FULL_FLAG;\r\nbreak;\r\n}\r\noutptr += l;\r\nused = param->data_start + (outptr - outbuf);\r\noutptr = align_ptr(outptr);\r\nspec->next = outptr - outbuf;\r\n}\r\nif (used)\r\nparam->data_size = used;\r\nparam->target_count = num_targets;\r\n}\r\nstatic int dev_wait(struct dm_ioctl *param, size_t param_size)\r\n{\r\nint r = 0;\r\nstruct mapped_device *md;\r\nstruct dm_table *table;\r\nint srcu_idx;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\nif (dm_wait_event(md, param->event_nr)) {\r\nr = -ERESTARTSYS;\r\ngoto out;\r\n}\r\n__dev_status(md, param);\r\ntable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\r\nif (table)\r\nretrieve_status(table, param, param_size);\r\ndm_put_live_table(md, srcu_idx);\r\nout:\r\ndm_put(md);\r\nreturn r;\r\n}\r\nstatic inline fmode_t get_mode(struct dm_ioctl *param)\r\n{\r\nfmode_t mode = FMODE_READ | FMODE_WRITE;\r\nif (param->flags & DM_READONLY_FLAG)\r\nmode = FMODE_READ;\r\nreturn mode;\r\n}\r\nstatic int next_target(struct dm_target_spec *last, uint32_t next, void *end,\r\nstruct dm_target_spec **spec, char **target_params)\r\n{\r\n*spec = (struct dm_target_spec *) ((unsigned char *) last + next);\r\n*target_params = (char *) (*spec + 1);\r\nif (*spec < (last + 1))\r\nreturn -EINVAL;\r\nreturn invalid_str(*target_params, end);\r\n}\r\nstatic int populate_table(struct dm_table *table,\r\nstruct dm_ioctl *param, size_t param_size)\r\n{\r\nint r;\r\nunsigned int i = 0;\r\nstruct dm_target_spec *spec = (struct dm_target_spec *) param;\r\nuint32_t next = param->data_start;\r\nvoid *end = (void *) param + param_size;\r\nchar *target_params;\r\nif (!param->target_count) {\r\nDMWARN("populate_table: no targets specified");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < param->target_count; i++) {\r\nr = next_target(spec, next, end, &spec, &target_params);\r\nif (r) {\r\nDMWARN("unable to find target");\r\nreturn r;\r\n}\r\nr = dm_table_add_target(table, spec->target_type,\r\n(sector_t) spec->sector_start,\r\n(sector_t) spec->length,\r\ntarget_params);\r\nif (r) {\r\nDMWARN("error adding target to table");\r\nreturn r;\r\n}\r\nnext = spec->next;\r\n}\r\nreturn dm_table_complete(table);\r\n}\r\nstatic int table_load(struct dm_ioctl *param, size_t param_size)\r\n{\r\nint r;\r\nstruct hash_cell *hc;\r\nstruct dm_table *t, *old_map = NULL;\r\nstruct mapped_device *md;\r\nstruct target_type *immutable_target_type;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\nr = dm_table_create(&t, get_mode(param), param->target_count, md);\r\nif (r)\r\ngoto err;\r\ndm_lock_md_type(md);\r\nr = populate_table(t, param, param_size);\r\nif (r)\r\ngoto err_unlock_md_type;\r\nimmutable_target_type = dm_get_immutable_target_type(md);\r\nif (immutable_target_type &&\r\n(immutable_target_type != dm_table_get_immutable_target_type(t))) {\r\nDMWARN("can't replace immutable target type %s",\r\nimmutable_target_type->name);\r\nr = -EINVAL;\r\ngoto err_unlock_md_type;\r\n}\r\nif (dm_get_md_type(md) == DM_TYPE_NONE)\r\ndm_set_md_type(md, dm_table_get_type(t));\r\nelse if (dm_get_md_type(md) != dm_table_get_type(t)) {\r\nDMWARN("can't change device type after initial table load.");\r\nr = -EINVAL;\r\ngoto err_unlock_md_type;\r\n}\r\nr = dm_setup_md_queue(md);\r\nif (r) {\r\nDMWARN("unable to set up device queue for new table.");\r\ngoto err_unlock_md_type;\r\n}\r\ndm_unlock_md_type(md);\r\ndown_write(&_hash_lock);\r\nhc = dm_get_mdptr(md);\r\nif (!hc || hc->md != md) {\r\nDMWARN("device has been removed from the dev hash table.");\r\nup_write(&_hash_lock);\r\nr = -ENXIO;\r\ngoto err_destroy_table;\r\n}\r\nif (hc->new_map)\r\nold_map = hc->new_map;\r\nhc->new_map = t;\r\nup_write(&_hash_lock);\r\nparam->flags |= DM_INACTIVE_PRESENT_FLAG;\r\n__dev_status(md, param);\r\nif (old_map) {\r\ndm_sync_table(md);\r\ndm_table_destroy(old_map);\r\n}\r\ndm_put(md);\r\nreturn 0;\r\nerr_unlock_md_type:\r\ndm_unlock_md_type(md);\r\nerr_destroy_table:\r\ndm_table_destroy(t);\r\nerr:\r\ndm_put(md);\r\nreturn r;\r\n}\r\nstatic int table_clear(struct dm_ioctl *param, size_t param_size)\r\n{\r\nstruct hash_cell *hc;\r\nstruct mapped_device *md;\r\nstruct dm_table *old_map = NULL;\r\ndown_write(&_hash_lock);\r\nhc = __find_device_hash_cell(param);\r\nif (!hc) {\r\nDMDEBUG_LIMIT("device doesn't appear to be in the dev hash table.");\r\nup_write(&_hash_lock);\r\nreturn -ENXIO;\r\n}\r\nif (hc->new_map) {\r\nold_map = hc->new_map;\r\nhc->new_map = NULL;\r\n}\r\nparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\r\n__dev_status(hc->md, param);\r\nmd = hc->md;\r\nup_write(&_hash_lock);\r\nif (old_map) {\r\ndm_sync_table(md);\r\ndm_table_destroy(old_map);\r\n}\r\ndm_put(md);\r\nreturn 0;\r\n}\r\nstatic void retrieve_deps(struct dm_table *table,\r\nstruct dm_ioctl *param, size_t param_size)\r\n{\r\nunsigned int count = 0;\r\nstruct list_head *tmp;\r\nsize_t len, needed;\r\nstruct dm_dev_internal *dd;\r\nstruct dm_target_deps *deps;\r\ndeps = get_result_buffer(param, param_size, &len);\r\nlist_for_each (tmp, dm_table_get_devices(table))\r\ncount++;\r\nneeded = sizeof(*deps) + (sizeof(*deps->dev) * count);\r\nif (len < needed) {\r\nparam->flags |= DM_BUFFER_FULL_FLAG;\r\nreturn;\r\n}\r\ndeps->count = count;\r\ncount = 0;\r\nlist_for_each_entry (dd, dm_table_get_devices(table), list)\r\ndeps->dev[count++] = huge_encode_dev(dd->dm_dev.bdev->bd_dev);\r\nparam->data_size = param->data_start + needed;\r\n}\r\nstatic int table_deps(struct dm_ioctl *param, size_t param_size)\r\n{\r\nstruct mapped_device *md;\r\nstruct dm_table *table;\r\nint srcu_idx;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\n__dev_status(md, param);\r\ntable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\r\nif (table)\r\nretrieve_deps(table, param, param_size);\r\ndm_put_live_table(md, srcu_idx);\r\ndm_put(md);\r\nreturn 0;\r\n}\r\nstatic int table_status(struct dm_ioctl *param, size_t param_size)\r\n{\r\nstruct mapped_device *md;\r\nstruct dm_table *table;\r\nint srcu_idx;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\n__dev_status(md, param);\r\ntable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\r\nif (table)\r\nretrieve_status(table, param, param_size);\r\ndm_put_live_table(md, srcu_idx);\r\ndm_put(md);\r\nreturn 0;\r\n}\r\nstatic int message_for_md(struct mapped_device *md, unsigned argc, char **argv,\r\nchar *result, unsigned maxlen)\r\n{\r\nint r;\r\nif (**argv != '@')\r\nreturn 2;\r\nif (!strcasecmp(argv[0], "@cancel_deferred_remove")) {\r\nif (argc != 1) {\r\nDMERR("Invalid arguments for @cancel_deferred_remove");\r\nreturn -EINVAL;\r\n}\r\nreturn dm_cancel_deferred_remove(md);\r\n}\r\nr = dm_stats_message(md, argc, argv, result, maxlen);\r\nif (r < 2)\r\nreturn r;\r\nDMERR("Unsupported message sent to DM core: %s", argv[0]);\r\nreturn -EINVAL;\r\n}\r\nstatic int target_message(struct dm_ioctl *param, size_t param_size)\r\n{\r\nint r, argc;\r\nchar **argv;\r\nstruct mapped_device *md;\r\nstruct dm_table *table;\r\nstruct dm_target *ti;\r\nstruct dm_target_msg *tmsg = (void *) param + param->data_start;\r\nsize_t maxlen;\r\nchar *result = get_result_buffer(param, param_size, &maxlen);\r\nint srcu_idx;\r\nmd = find_device(param);\r\nif (!md)\r\nreturn -ENXIO;\r\nif (tmsg < (struct dm_target_msg *) param->data ||\r\ninvalid_str(tmsg->message, (void *) param + param_size)) {\r\nDMWARN("Invalid target message parameters.");\r\nr = -EINVAL;\r\ngoto out;\r\n}\r\nr = dm_split_args(&argc, &argv, tmsg->message);\r\nif (r) {\r\nDMWARN("Failed to split target message parameters");\r\ngoto out;\r\n}\r\nif (!argc) {\r\nDMWARN("Empty message received.");\r\ngoto out_argv;\r\n}\r\nr = message_for_md(md, argc, argv, result, maxlen);\r\nif (r <= 1)\r\ngoto out_argv;\r\ntable = dm_get_live_table(md, &srcu_idx);\r\nif (!table)\r\ngoto out_table;\r\nif (dm_deleting_md(md)) {\r\nr = -ENXIO;\r\ngoto out_table;\r\n}\r\nti = dm_table_find_target(table, tmsg->sector);\r\nif (!dm_target_is_valid(ti)) {\r\nDMWARN("Target message sector outside device.");\r\nr = -EINVAL;\r\n} else if (ti->type->message)\r\nr = ti->type->message(ti, argc, argv);\r\nelse {\r\nDMWARN("Target type does not support messages");\r\nr = -EINVAL;\r\n}\r\nout_table:\r\ndm_put_live_table(md, srcu_idx);\r\nout_argv:\r\nkfree(argv);\r\nout:\r\nif (r >= 0)\r\n__dev_status(md, param);\r\nif (r == 1) {\r\nparam->flags |= DM_DATA_OUT_FLAG;\r\nif (dm_message_test_buffer_overflow(result, maxlen))\r\nparam->flags |= DM_BUFFER_FULL_FLAG;\r\nelse\r\nparam->data_size = param->data_start + strlen(result) + 1;\r\nr = 0;\r\n}\r\ndm_put(md);\r\nreturn r;\r\n}\r\nstatic ioctl_fn lookup_ioctl(unsigned int cmd, int *ioctl_flags)\r\n{\r\nstatic struct {\r\nint cmd;\r\nint flags;\r\nioctl_fn fn;\r\n} _ioctls[] = {\r\n{DM_VERSION_CMD, 0, NULL},\r\n{DM_REMOVE_ALL_CMD, IOCTL_FLAGS_NO_PARAMS, remove_all},\r\n{DM_LIST_DEVICES_CMD, 0, list_devices},\r\n{DM_DEV_CREATE_CMD, IOCTL_FLAGS_NO_PARAMS, dev_create},\r\n{DM_DEV_REMOVE_CMD, IOCTL_FLAGS_NO_PARAMS, dev_remove},\r\n{DM_DEV_RENAME_CMD, 0, dev_rename},\r\n{DM_DEV_SUSPEND_CMD, IOCTL_FLAGS_NO_PARAMS, dev_suspend},\r\n{DM_DEV_STATUS_CMD, IOCTL_FLAGS_NO_PARAMS, dev_status},\r\n{DM_DEV_WAIT_CMD, 0, dev_wait},\r\n{DM_TABLE_LOAD_CMD, 0, table_load},\r\n{DM_TABLE_CLEAR_CMD, IOCTL_FLAGS_NO_PARAMS, table_clear},\r\n{DM_TABLE_DEPS_CMD, 0, table_deps},\r\n{DM_TABLE_STATUS_CMD, 0, table_status},\r\n{DM_LIST_VERSIONS_CMD, 0, list_versions},\r\n{DM_TARGET_MSG_CMD, 0, target_message},\r\n{DM_DEV_SET_GEOMETRY_CMD, 0, dev_set_geometry}\r\n};\r\nif (unlikely(cmd >= ARRAY_SIZE(_ioctls)))\r\nreturn NULL;\r\n*ioctl_flags = _ioctls[cmd].flags;\r\nreturn _ioctls[cmd].fn;\r\n}\r\nstatic int check_version(unsigned int cmd, struct dm_ioctl __user *user)\r\n{\r\nuint32_t version[3];\r\nint r = 0;\r\nif (copy_from_user(version, user->version, sizeof(version)))\r\nreturn -EFAULT;\r\nif ((DM_VERSION_MAJOR != version[0]) ||\r\n(DM_VERSION_MINOR < version[1])) {\r\nDMWARN("ioctl interface mismatch: "\r\n"kernel(%u.%u.%u), user(%u.%u.%u), cmd(%d)",\r\nDM_VERSION_MAJOR, DM_VERSION_MINOR,\r\nDM_VERSION_PATCHLEVEL,\r\nversion[0], version[1], version[2], cmd);\r\nr = -EINVAL;\r\n}\r\nversion[0] = DM_VERSION_MAJOR;\r\nversion[1] = DM_VERSION_MINOR;\r\nversion[2] = DM_VERSION_PATCHLEVEL;\r\nif (copy_to_user(user->version, version, sizeof(version)))\r\nreturn -EFAULT;\r\nreturn r;\r\n}\r\nstatic void free_params(struct dm_ioctl *param, size_t param_size, int param_flags)\r\n{\r\nif (param_flags & DM_WIPE_BUFFER)\r\nmemset(param, 0, param_size);\r\nif (param_flags & DM_PARAMS_KMALLOC)\r\nkfree(param);\r\nif (param_flags & DM_PARAMS_VMALLOC)\r\nvfree(param);\r\n}\r\nstatic int copy_params(struct dm_ioctl __user *user, struct dm_ioctl *param_kernel,\r\nint ioctl_flags,\r\nstruct dm_ioctl **param, int *param_flags)\r\n{\r\nstruct dm_ioctl *dmi;\r\nint secure_data;\r\nconst size_t minimum_data_size = sizeof(*param_kernel) - sizeof(param_kernel->data);\r\nif (copy_from_user(param_kernel, user, minimum_data_size))\r\nreturn -EFAULT;\r\nif (param_kernel->data_size < minimum_data_size)\r\nreturn -EINVAL;\r\nsecure_data = param_kernel->flags & DM_SECURE_DATA_FLAG;\r\n*param_flags = secure_data ? DM_WIPE_BUFFER : 0;\r\nif (ioctl_flags & IOCTL_FLAGS_NO_PARAMS) {\r\ndmi = param_kernel;\r\ndmi->data_size = minimum_data_size;\r\ngoto data_copied;\r\n}\r\ndmi = NULL;\r\nif (param_kernel->data_size <= KMALLOC_MAX_SIZE) {\r\ndmi = kmalloc(param_kernel->data_size, GFP_NOIO | __GFP_NORETRY | __GFP_NOMEMALLOC | __GFP_NOWARN);\r\nif (dmi)\r\n*param_flags |= DM_PARAMS_KMALLOC;\r\n}\r\nif (!dmi) {\r\nunsigned noio_flag;\r\nnoio_flag = memalloc_noio_save();\r\ndmi = __vmalloc(param_kernel->data_size, GFP_NOIO | __GFP_REPEAT | __GFP_HIGH | __GFP_HIGHMEM, PAGE_KERNEL);\r\nmemalloc_noio_restore(noio_flag);\r\nif (dmi)\r\n*param_flags |= DM_PARAMS_VMALLOC;\r\n}\r\nif (!dmi) {\r\nif (secure_data && clear_user(user, param_kernel->data_size))\r\nreturn -EFAULT;\r\nreturn -ENOMEM;\r\n}\r\nif (copy_from_user(dmi, user, param_kernel->data_size))\r\ngoto bad;\r\ndata_copied:\r\nif (dmi->data_size != param_kernel->data_size) {\r\nDMERR("rejecting ioctl: data size modified while processing parameters");\r\ngoto bad;\r\n}\r\nif (secure_data && clear_user(user, param_kernel->data_size))\r\ngoto bad;\r\n*param = dmi;\r\nreturn 0;\r\nbad:\r\nfree_params(dmi, param_kernel->data_size, *param_flags);\r\nreturn -EFAULT;\r\n}\r\nstatic int validate_params(uint cmd, struct dm_ioctl *param)\r\n{\r\nparam->flags &= ~DM_BUFFER_FULL_FLAG;\r\nparam->flags &= ~DM_UEVENT_GENERATED_FLAG;\r\nparam->flags &= ~DM_SECURE_DATA_FLAG;\r\nparam->flags &= ~DM_DATA_OUT_FLAG;\r\nif (cmd == DM_REMOVE_ALL_CMD ||\r\ncmd == DM_LIST_DEVICES_CMD ||\r\ncmd == DM_LIST_VERSIONS_CMD)\r\nreturn 0;\r\nif ((cmd == DM_DEV_CREATE_CMD)) {\r\nif (!*param->name) {\r\nDMWARN("name not supplied when creating device");\r\nreturn -EINVAL;\r\n}\r\n} else if ((*param->uuid && *param->name)) {\r\nDMWARN("only supply one of name or uuid, cmd(%u)", cmd);\r\nreturn -EINVAL;\r\n}\r\nparam->name[DM_NAME_LEN - 1] = '\0';\r\nparam->uuid[DM_UUID_LEN - 1] = '\0';\r\nreturn 0;\r\n}\r\nstatic int ctl_ioctl(uint command, struct dm_ioctl __user *user)\r\n{\r\nint r = 0;\r\nint ioctl_flags;\r\nint param_flags;\r\nunsigned int cmd;\r\nstruct dm_ioctl *uninitialized_var(param);\r\nioctl_fn fn = NULL;\r\nsize_t input_param_size;\r\nstruct dm_ioctl param_kernel;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EACCES;\r\nif (_IOC_TYPE(command) != DM_IOCTL)\r\nreturn -ENOTTY;\r\ncmd = _IOC_NR(command);\r\nr = check_version(cmd, user);\r\nif (r)\r\nreturn r;\r\nif (cmd == DM_VERSION_CMD)\r\nreturn 0;\r\nfn = lookup_ioctl(cmd, &ioctl_flags);\r\nif (!fn) {\r\nDMWARN("dm_ctl_ioctl: unknown command 0x%x", command);\r\nreturn -ENOTTY;\r\n}\r\nr = copy_params(user, &param_kernel, ioctl_flags, &param, &param_flags);\r\nif (r)\r\nreturn r;\r\ninput_param_size = param->data_size;\r\nr = validate_params(cmd, param);\r\nif (r)\r\ngoto out;\r\nparam->data_size = sizeof(*param);\r\nr = fn(param, input_param_size);\r\nif (unlikely(param->flags & DM_BUFFER_FULL_FLAG) &&\r\nunlikely(ioctl_flags & IOCTL_FLAGS_NO_PARAMS))\r\nDMERR("ioctl %d tried to output some data but has IOCTL_FLAGS_NO_PARAMS set", cmd);\r\nif (!r && copy_to_user(user, param, param->data_size))\r\nr = -EFAULT;\r\nout:\r\nfree_params(param, input_param_size, param_flags);\r\nreturn r;\r\n}\r\nstatic long dm_ctl_ioctl(struct file *file, uint command, ulong u)\r\n{\r\nreturn (long)ctl_ioctl(command, (struct dm_ioctl __user *)u);\r\n}\r\nstatic long dm_compat_ctl_ioctl(struct file *file, uint command, ulong u)\r\n{\r\nreturn (long)dm_ctl_ioctl(file, command, (ulong) compat_ptr(u));\r\n}\r\nint __init dm_interface_init(void)\r\n{\r\nint r;\r\nr = dm_hash_init();\r\nif (r)\r\nreturn r;\r\nr = misc_register(&_dm_misc);\r\nif (r) {\r\nDMERR("misc_register failed for control device");\r\ndm_hash_exit();\r\nreturn r;\r\n}\r\nDMINFO("%d.%d.%d%s initialised: %s", DM_VERSION_MAJOR,\r\nDM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA,\r\nDM_DRIVER_EMAIL);\r\nreturn 0;\r\n}\r\nvoid dm_interface_exit(void)\r\n{\r\nif (misc_deregister(&_dm_misc) < 0)\r\nDMERR("misc_deregister failed for control device");\r\ndm_hash_exit();\r\n}\r\nint dm_copy_name_and_uuid(struct mapped_device *md, char *name, char *uuid)\r\n{\r\nint r = 0;\r\nstruct hash_cell *hc;\r\nif (!md)\r\nreturn -ENXIO;\r\nmutex_lock(&dm_hash_cells_mutex);\r\nhc = dm_get_mdptr(md);\r\nif (!hc || hc->md != md) {\r\nr = -ENXIO;\r\ngoto out;\r\n}\r\nif (name)\r\nstrcpy(name, hc->name);\r\nif (uuid)\r\nstrcpy(uuid, hc->uuid ? : "");\r\nout:\r\nmutex_unlock(&dm_hash_cells_mutex);\r\nreturn r;\r\n}
