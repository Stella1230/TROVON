static void free_sm_ah(struct kref *kref)\r\n{\r\nstruct ib_sa_sm_ah *sm_ah = container_of(kref, struct ib_sa_sm_ah, ref);\r\nib_destroy_ah(sm_ah->ah);\r\nkfree(sm_ah);\r\n}\r\nstatic void update_sm_ah(struct work_struct *work)\r\n{\r\nstruct ib_sa_port *port =\r\ncontainer_of(work, struct ib_sa_port, update_task);\r\nstruct ib_sa_sm_ah *new_ah;\r\nstruct ib_port_attr port_attr;\r\nstruct ib_ah_attr ah_attr;\r\nif (ib_query_port(port->agent->device, port->port_num, &port_attr)) {\r\nprintk(KERN_WARNING "Couldn't query port\n");\r\nreturn;\r\n}\r\nnew_ah = kmalloc(sizeof *new_ah, GFP_KERNEL);\r\nif (!new_ah) {\r\nprintk(KERN_WARNING "Couldn't allocate new SM AH\n");\r\nreturn;\r\n}\r\nkref_init(&new_ah->ref);\r\nnew_ah->src_path_mask = (1 << port_attr.lmc) - 1;\r\nnew_ah->pkey_index = 0;\r\nif (ib_find_pkey(port->agent->device, port->port_num,\r\nIB_DEFAULT_PKEY_FULL, &new_ah->pkey_index))\r\nprintk(KERN_ERR "Couldn't find index for default PKey\n");\r\nmemset(&ah_attr, 0, sizeof ah_attr);\r\nah_attr.dlid = port_attr.sm_lid;\r\nah_attr.sl = port_attr.sm_sl;\r\nah_attr.port_num = port->port_num;\r\nnew_ah->ah = ib_create_ah(port->agent->qp->pd, &ah_attr);\r\nif (IS_ERR(new_ah->ah)) {\r\nprintk(KERN_WARNING "Couldn't create new SM AH\n");\r\nkfree(new_ah);\r\nreturn;\r\n}\r\nspin_lock_irq(&port->ah_lock);\r\nif (port->sm_ah)\r\nkref_put(&port->sm_ah->ref, free_sm_ah);\r\nport->sm_ah = new_ah;\r\nspin_unlock_irq(&port->ah_lock);\r\n}\r\nstatic void ib_sa_event(struct ib_event_handler *handler, struct ib_event *event)\r\n{\r\nif (event->event == IB_EVENT_PORT_ERR ||\r\nevent->event == IB_EVENT_PORT_ACTIVE ||\r\nevent->event == IB_EVENT_LID_CHANGE ||\r\nevent->event == IB_EVENT_PKEY_CHANGE ||\r\nevent->event == IB_EVENT_SM_CHANGE ||\r\nevent->event == IB_EVENT_CLIENT_REREGISTER) {\r\nunsigned long flags;\r\nstruct ib_sa_device *sa_dev =\r\ncontainer_of(handler, typeof(*sa_dev), event_handler);\r\nstruct ib_sa_port *port =\r\n&sa_dev->port[event->element.port_num - sa_dev->start_port];\r\nif (rdma_port_get_link_layer(handler->device, port->port_num) != IB_LINK_LAYER_INFINIBAND)\r\nreturn;\r\nspin_lock_irqsave(&port->ah_lock, flags);\r\nif (port->sm_ah)\r\nkref_put(&port->sm_ah->ref, free_sm_ah);\r\nport->sm_ah = NULL;\r\nspin_unlock_irqrestore(&port->ah_lock, flags);\r\nqueue_work(ib_wq, &sa_dev->port[event->element.port_num -\r\nsa_dev->start_port].update_task);\r\n}\r\n}\r\nvoid ib_sa_register_client(struct ib_sa_client *client)\r\n{\r\natomic_set(&client->users, 1);\r\ninit_completion(&client->comp);\r\n}\r\nvoid ib_sa_unregister_client(struct ib_sa_client *client)\r\n{\r\nib_sa_client_put(client);\r\nwait_for_completion(&client->comp);\r\n}\r\nvoid ib_sa_cancel_query(int id, struct ib_sa_query *query)\r\n{\r\nunsigned long flags;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_mad_send_buf *mad_buf;\r\nspin_lock_irqsave(&idr_lock, flags);\r\nif (idr_find(&query_idr, id) != query) {\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nreturn;\r\n}\r\nagent = query->port->agent;\r\nmad_buf = query->mad_buf;\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nib_cancel_mad(agent, mad_buf);\r\n}\r\nstatic u8 get_src_path_mask(struct ib_device *device, u8 port_num)\r\n{\r\nstruct ib_sa_device *sa_dev;\r\nstruct ib_sa_port *port;\r\nunsigned long flags;\r\nu8 src_path_mask;\r\nsa_dev = ib_get_client_data(device, &sa_client);\r\nif (!sa_dev)\r\nreturn 0x7f;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nspin_lock_irqsave(&port->ah_lock, flags);\r\nsrc_path_mask = port->sm_ah ? port->sm_ah->src_path_mask : 0x7f;\r\nspin_unlock_irqrestore(&port->ah_lock, flags);\r\nreturn src_path_mask;\r\n}\r\nint ib_init_ah_from_path(struct ib_device *device, u8 port_num,\r\nstruct ib_sa_path_rec *rec, struct ib_ah_attr *ah_attr)\r\n{\r\nint ret;\r\nu16 gid_index;\r\nint force_grh;\r\nmemset(ah_attr, 0, sizeof *ah_attr);\r\nah_attr->dlid = be16_to_cpu(rec->dlid);\r\nah_attr->sl = rec->sl;\r\nah_attr->src_path_bits = be16_to_cpu(rec->slid) &\r\nget_src_path_mask(device, port_num);\r\nah_attr->port_num = port_num;\r\nah_attr->static_rate = rec->rate;\r\nforce_grh = rdma_port_get_link_layer(device, port_num) == IB_LINK_LAYER_ETHERNET;\r\nif (rec->hop_limit > 1 || force_grh) {\r\nah_attr->ah_flags = IB_AH_GRH;\r\nah_attr->grh.dgid = rec->dgid;\r\nret = ib_find_cached_gid(device, &rec->sgid, &port_num,\r\n&gid_index);\r\nif (ret)\r\nreturn ret;\r\nah_attr->grh.sgid_index = gid_index;\r\nah_attr->grh.flow_label = be32_to_cpu(rec->flow_label);\r\nah_attr->grh.hop_limit = rec->hop_limit;\r\nah_attr->grh.traffic_class = rec->traffic_class;\r\n}\r\nif (force_grh) {\r\nmemcpy(ah_attr->dmac, rec->dmac, ETH_ALEN);\r\nah_attr->vlan_id = rec->vlan_id;\r\n} else {\r\nah_attr->vlan_id = 0xffff;\r\n}\r\nreturn 0;\r\n}\r\nstatic int alloc_mad(struct ib_sa_query *query, gfp_t gfp_mask)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&query->port->ah_lock, flags);\r\nif (!query->port->sm_ah) {\r\nspin_unlock_irqrestore(&query->port->ah_lock, flags);\r\nreturn -EAGAIN;\r\n}\r\nkref_get(&query->port->sm_ah->ref);\r\nquery->sm_ah = query->port->sm_ah;\r\nspin_unlock_irqrestore(&query->port->ah_lock, flags);\r\nquery->mad_buf = ib_create_send_mad(query->port->agent, 1,\r\nquery->sm_ah->pkey_index,\r\n0, IB_MGMT_SA_HDR, IB_MGMT_SA_DATA,\r\ngfp_mask);\r\nif (IS_ERR(query->mad_buf)) {\r\nkref_put(&query->sm_ah->ref, free_sm_ah);\r\nreturn -ENOMEM;\r\n}\r\nquery->mad_buf->ah = query->sm_ah->ah;\r\nreturn 0;\r\n}\r\nstatic void free_mad(struct ib_sa_query *query)\r\n{\r\nib_free_send_mad(query->mad_buf);\r\nkref_put(&query->sm_ah->ref, free_sm_ah);\r\n}\r\nstatic void init_mad(struct ib_sa_mad *mad, struct ib_mad_agent *agent)\r\n{\r\nunsigned long flags;\r\nmemset(mad, 0, sizeof *mad);\r\nmad->mad_hdr.base_version = IB_MGMT_BASE_VERSION;\r\nmad->mad_hdr.mgmt_class = IB_MGMT_CLASS_SUBN_ADM;\r\nmad->mad_hdr.class_version = IB_SA_CLASS_VERSION;\r\nspin_lock_irqsave(&tid_lock, flags);\r\nmad->mad_hdr.tid =\r\ncpu_to_be64(((u64) agent->hi_tid) << 32 | tid++);\r\nspin_unlock_irqrestore(&tid_lock, flags);\r\n}\r\nstatic int send_mad(struct ib_sa_query *query, int timeout_ms, gfp_t gfp_mask)\r\n{\r\nbool preload = gfp_mask & __GFP_WAIT;\r\nunsigned long flags;\r\nint ret, id;\r\nif (preload)\r\nidr_preload(gfp_mask);\r\nspin_lock_irqsave(&idr_lock, flags);\r\nid = idr_alloc(&query_idr, query, 0, 0, GFP_NOWAIT);\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nif (preload)\r\nidr_preload_end();\r\nif (id < 0)\r\nreturn id;\r\nquery->mad_buf->timeout_ms = timeout_ms;\r\nquery->mad_buf->context[0] = query;\r\nquery->id = id;\r\nret = ib_post_send_mad(query->mad_buf, NULL);\r\nif (ret) {\r\nspin_lock_irqsave(&idr_lock, flags);\r\nidr_remove(&query_idr, id);\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\n}\r\nreturn ret ? ret : id;\r\n}\r\nvoid ib_sa_unpack_path(void *attribute, struct ib_sa_path_rec *rec)\r\n{\r\nib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table), attribute, rec);\r\n}\r\nvoid ib_sa_pack_path(struct ib_sa_path_rec *rec, void *attribute)\r\n{\r\nib_pack(path_rec_table, ARRAY_SIZE(path_rec_table), rec, attribute);\r\n}\r\nstatic void ib_sa_path_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_path_query *query =\r\ncontainer_of(sa_query, struct ib_sa_path_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_path_rec rec;\r\nib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table),\r\nmad->data, &rec);\r\nrec.vlan_id = 0xffff;\r\nmemset(rec.dmac, 0, ETH_ALEN);\r\nmemset(rec.smac, 0, ETH_ALEN);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_path_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_path_query, sa_query));\r\n}\r\nint ib_sa_path_rec_get(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num,\r\nstruct ib_sa_path_rec *rec,\r\nib_sa_comp_mask comp_mask,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_path_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_path_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nquery = kmalloc(sizeof *query, gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_path_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_path_rec_release;\r\nmad->mad_hdr.method = IB_MGMT_METHOD_GET;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_PATH_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(path_rec_table, ARRAY_SIZE(path_rec_table), rec, mad->data);\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void ib_sa_service_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_service_query *query =\r\ncontainer_of(sa_query, struct ib_sa_service_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_service_rec rec;\r\nib_unpack(service_rec_table, ARRAY_SIZE(service_rec_table),\r\nmad->data, &rec);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_service_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_service_query, sa_query));\r\n}\r\nint ib_sa_service_rec_query(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num, u8 method,\r\nstruct ib_sa_service_rec *rec,\r\nib_sa_comp_mask comp_mask,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_service_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_service_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nif (method != IB_MGMT_METHOD_GET &&\r\nmethod != IB_MGMT_METHOD_SET &&\r\nmethod != IB_SA_METHOD_DELETE)\r\nreturn -EINVAL;\r\nquery = kmalloc(sizeof *query, gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_service_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_service_rec_release;\r\nmad->mad_hdr.method = method;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_SERVICE_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(service_rec_table, ARRAY_SIZE(service_rec_table),\r\nrec, mad->data);\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void ib_sa_mcmember_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_mcmember_query *query =\r\ncontainer_of(sa_query, struct ib_sa_mcmember_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_mcmember_rec rec;\r\nib_unpack(mcmember_rec_table, ARRAY_SIZE(mcmember_rec_table),\r\nmad->data, &rec);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_mcmember_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_mcmember_query, sa_query));\r\n}\r\nint ib_sa_mcmember_rec_query(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num,\r\nu8 method,\r\nstruct ib_sa_mcmember_rec *rec,\r\nib_sa_comp_mask comp_mask,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_mcmember_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_mcmember_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nquery = kmalloc(sizeof *query, gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_mcmember_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_mcmember_rec_release;\r\nmad->mad_hdr.method = method;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_MC_MEMBER_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(mcmember_rec_table, ARRAY_SIZE(mcmember_rec_table),\r\nrec, mad->data);\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void ib_sa_guidinfo_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_guidinfo_query *query =\r\ncontainer_of(sa_query, struct ib_sa_guidinfo_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_guidinfo_rec rec;\r\nib_unpack(guidinfo_rec_table, ARRAY_SIZE(guidinfo_rec_table),\r\nmad->data, &rec);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_guidinfo_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_guidinfo_query, sa_query));\r\n}\r\nint ib_sa_guid_info_rec_query(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num,\r\nstruct ib_sa_guidinfo_rec *rec,\r\nib_sa_comp_mask comp_mask, u8 method,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_guidinfo_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_guidinfo_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nif (method != IB_MGMT_METHOD_GET &&\r\nmethod != IB_MGMT_METHOD_SET &&\r\nmethod != IB_SA_METHOD_DELETE) {\r\nreturn -EINVAL;\r\n}\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nquery = kmalloc(sizeof *query, gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_guidinfo_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_guidinfo_rec_release;\r\nmad->mad_hdr.method = method;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_GUID_INFO_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(guidinfo_rec_table, ARRAY_SIZE(guidinfo_rec_table), rec,\r\nmad->data);\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void send_handler(struct ib_mad_agent *agent,\r\nstruct ib_mad_send_wc *mad_send_wc)\r\n{\r\nstruct ib_sa_query *query = mad_send_wc->send_buf->context[0];\r\nunsigned long flags;\r\nif (query->callback)\r\nswitch (mad_send_wc->status) {\r\ncase IB_WC_SUCCESS:\r\nbreak;\r\ncase IB_WC_RESP_TIMEOUT_ERR:\r\nquery->callback(query, -ETIMEDOUT, NULL);\r\nbreak;\r\ncase IB_WC_WR_FLUSH_ERR:\r\nquery->callback(query, -EINTR, NULL);\r\nbreak;\r\ndefault:\r\nquery->callback(query, -EIO, NULL);\r\nbreak;\r\n}\r\nspin_lock_irqsave(&idr_lock, flags);\r\nidr_remove(&query_idr, query->id);\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nfree_mad(query);\r\nib_sa_client_put(query->client);\r\nquery->release(query);\r\n}\r\nstatic void recv_handler(struct ib_mad_agent *mad_agent,\r\nstruct ib_mad_recv_wc *mad_recv_wc)\r\n{\r\nstruct ib_sa_query *query;\r\nstruct ib_mad_send_buf *mad_buf;\r\nmad_buf = (void *) (unsigned long) mad_recv_wc->wc->wr_id;\r\nquery = mad_buf->context[0];\r\nif (query->callback) {\r\nif (mad_recv_wc->wc->status == IB_WC_SUCCESS)\r\nquery->callback(query,\r\nmad_recv_wc->recv_buf.mad->mad_hdr.status ?\r\n-EINVAL : 0,\r\n(struct ib_sa_mad *) mad_recv_wc->recv_buf.mad);\r\nelse\r\nquery->callback(query, -EIO, NULL);\r\n}\r\nib_free_recv_mad(mad_recv_wc);\r\n}\r\nstatic void ib_sa_add_one(struct ib_device *device)\r\n{\r\nstruct ib_sa_device *sa_dev;\r\nint s, e, i;\r\nif (rdma_node_get_transport(device->node_type) != RDMA_TRANSPORT_IB)\r\nreturn;\r\nif (device->node_type == RDMA_NODE_IB_SWITCH)\r\ns = e = 0;\r\nelse {\r\ns = 1;\r\ne = device->phys_port_cnt;\r\n}\r\nsa_dev = kzalloc(sizeof *sa_dev +\r\n(e - s + 1) * sizeof (struct ib_sa_port),\r\nGFP_KERNEL);\r\nif (!sa_dev)\r\nreturn;\r\nsa_dev->start_port = s;\r\nsa_dev->end_port = e;\r\nfor (i = 0; i <= e - s; ++i) {\r\nspin_lock_init(&sa_dev->port[i].ah_lock);\r\nif (rdma_port_get_link_layer(device, i + 1) != IB_LINK_LAYER_INFINIBAND)\r\ncontinue;\r\nsa_dev->port[i].sm_ah = NULL;\r\nsa_dev->port[i].port_num = i + s;\r\nsa_dev->port[i].agent =\r\nib_register_mad_agent(device, i + s, IB_QPT_GSI,\r\nNULL, 0, send_handler,\r\nrecv_handler, sa_dev);\r\nif (IS_ERR(sa_dev->port[i].agent))\r\ngoto err;\r\nINIT_WORK(&sa_dev->port[i].update_task, update_sm_ah);\r\n}\r\nib_set_client_data(device, &sa_client, sa_dev);\r\nINIT_IB_EVENT_HANDLER(&sa_dev->event_handler, device, ib_sa_event);\r\nif (ib_register_event_handler(&sa_dev->event_handler))\r\ngoto err;\r\nfor (i = 0; i <= e - s; ++i)\r\nif (rdma_port_get_link_layer(device, i + 1) == IB_LINK_LAYER_INFINIBAND)\r\nupdate_sm_ah(&sa_dev->port[i].update_task);\r\nreturn;\r\nerr:\r\nwhile (--i >= 0)\r\nif (rdma_port_get_link_layer(device, i + 1) == IB_LINK_LAYER_INFINIBAND)\r\nib_unregister_mad_agent(sa_dev->port[i].agent);\r\nkfree(sa_dev);\r\nreturn;\r\n}\r\nstatic void ib_sa_remove_one(struct ib_device *device)\r\n{\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nint i;\r\nif (!sa_dev)\r\nreturn;\r\nib_unregister_event_handler(&sa_dev->event_handler);\r\nflush_workqueue(ib_wq);\r\nfor (i = 0; i <= sa_dev->end_port - sa_dev->start_port; ++i) {\r\nif (rdma_port_get_link_layer(device, i + 1) == IB_LINK_LAYER_INFINIBAND) {\r\nib_unregister_mad_agent(sa_dev->port[i].agent);\r\nif (sa_dev->port[i].sm_ah)\r\nkref_put(&sa_dev->port[i].sm_ah->ref, free_sm_ah);\r\n}\r\n}\r\nkfree(sa_dev);\r\n}\r\nstatic int __init ib_sa_init(void)\r\n{\r\nint ret;\r\nget_random_bytes(&tid, sizeof tid);\r\nret = ib_register_client(&sa_client);\r\nif (ret) {\r\nprintk(KERN_ERR "Couldn't register ib_sa client\n");\r\ngoto err1;\r\n}\r\nret = mcast_init();\r\nif (ret) {\r\nprintk(KERN_ERR "Couldn't initialize multicast handling\n");\r\ngoto err2;\r\n}\r\nreturn 0;\r\nerr2:\r\nib_unregister_client(&sa_client);\r\nerr1:\r\nreturn ret;\r\n}\r\nstatic void __exit ib_sa_cleanup(void)\r\n{\r\nmcast_cleanup();\r\nib_unregister_client(&sa_client);\r\nidr_destroy(&query_idr);\r\n}
