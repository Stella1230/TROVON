static int cpia2_open(struct file *file)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint retval;\r\nif (mutex_lock_interruptible(&cam->v4l2_lock))\r\nreturn -ERESTARTSYS;\r\nretval = v4l2_fh_open(file);\r\nif (retval)\r\ngoto open_unlock;\r\nif (v4l2_fh_is_singular_file(file)) {\r\nif (cpia2_allocate_buffers(cam)) {\r\nv4l2_fh_release(file);\r\nretval = -ENOMEM;\r\ngoto open_unlock;\r\n}\r\nif (cpia2_reset_camera(cam) < 0) {\r\nv4l2_fh_release(file);\r\nretval = -EIO;\r\ngoto open_unlock;\r\n}\r\ncam->APP_len = 0;\r\ncam->COM_len = 0;\r\n}\r\ncpia2_dbg_dump_registers(cam);\r\nopen_unlock:\r\nmutex_unlock(&cam->v4l2_lock);\r\nreturn retval;\r\n}\r\nstatic int cpia2_close(struct file *file)\r\n{\r\nstruct video_device *dev = video_devdata(file);\r\nstruct camera_data *cam = video_get_drvdata(dev);\r\nmutex_lock(&cam->v4l2_lock);\r\nif (video_is_registered(&cam->vdev) && v4l2_fh_is_singular_file(file)) {\r\ncpia2_usb_stream_stop(cam);\r\ncpia2_save_camera_state(cam);\r\ncpia2_set_low_power(cam);\r\ncpia2_free_buffers(cam);\r\n}\r\nif (cam->stream_fh == file->private_data) {\r\ncam->stream_fh = NULL;\r\ncam->mmapped = 0;\r\n}\r\nmutex_unlock(&cam->v4l2_lock);\r\nreturn v4l2_fh_release(file);\r\n}\r\nstatic ssize_t cpia2_v4l_read(struct file *file, char __user *buf, size_t count,\r\nloff_t *off)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint noblock = file->f_flags&O_NONBLOCK;\r\nssize_t ret;\r\nif(!cam)\r\nreturn -EINVAL;\r\nif (mutex_lock_interruptible(&cam->v4l2_lock))\r\nreturn -ERESTARTSYS;\r\nret = cpia2_read(cam, buf, count, noblock);\r\nmutex_unlock(&cam->v4l2_lock);\r\nreturn ret;\r\n}\r\nstatic unsigned int cpia2_v4l_poll(struct file *filp, struct poll_table_struct *wait)\r\n{\r\nstruct camera_data *cam = video_drvdata(filp);\r\nunsigned int res;\r\nmutex_lock(&cam->v4l2_lock);\r\nres = cpia2_poll(cam, filp, wait);\r\nmutex_unlock(&cam->v4l2_lock);\r\nreturn res;\r\n}\r\nstatic int sync(struct camera_data *cam, int frame_nr)\r\n{\r\nstruct framebuf *frame = &cam->buffers[frame_nr];\r\nwhile (1) {\r\nif (frame->status == FRAME_READY)\r\nreturn 0;\r\nif (!cam->streaming) {\r\nframe->status = FRAME_READY;\r\nframe->length = 0;\r\nreturn 0;\r\n}\r\nmutex_unlock(&cam->v4l2_lock);\r\nwait_event_interruptible(cam->wq_stream,\r\n!cam->streaming ||\r\nframe->status == FRAME_READY);\r\nmutex_lock(&cam->v4l2_lock);\r\nif (signal_pending(current))\r\nreturn -ERESTARTSYS;\r\nif (!video_is_registered(&cam->vdev))\r\nreturn -ENOTTY;\r\n}\r\n}\r\nstatic int cpia2_querycap(struct file *file, void *fh, struct v4l2_capability *vc)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nstrcpy(vc->driver, "cpia2");\r\nif (cam->params.pnp_id.product == 0x151)\r\nstrcpy(vc->card, "QX5 Microscope");\r\nelse\r\nstrcpy(vc->card, "CPiA2 Camera");\r\nswitch (cam->params.pnp_id.device_type) {\r\ncase DEVICE_STV_672:\r\nstrcat(vc->card, " (672/");\r\nbreak;\r\ncase DEVICE_STV_676:\r\nstrcat(vc->card, " (676/");\r\nbreak;\r\ndefault:\r\nstrcat(vc->card, " (XXX/");\r\nbreak;\r\n}\r\nswitch (cam->params.version.sensor_flags) {\r\ncase CPIA2_VP_SENSOR_FLAGS_404:\r\nstrcat(vc->card, "404)");\r\nbreak;\r\ncase CPIA2_VP_SENSOR_FLAGS_407:\r\nstrcat(vc->card, "407)");\r\nbreak;\r\ncase CPIA2_VP_SENSOR_FLAGS_409:\r\nstrcat(vc->card, "409)");\r\nbreak;\r\ncase CPIA2_VP_SENSOR_FLAGS_410:\r\nstrcat(vc->card, "410)");\r\nbreak;\r\ncase CPIA2_VP_SENSOR_FLAGS_500:\r\nstrcat(vc->card, "500)");\r\nbreak;\r\ndefault:\r\nstrcat(vc->card, "XXX)");\r\nbreak;\r\n}\r\nif (usb_make_path(cam->dev, vc->bus_info, sizeof(vc->bus_info)) <0)\r\nmemset(vc->bus_info,0, sizeof(vc->bus_info));\r\nvc->device_caps = V4L2_CAP_VIDEO_CAPTURE |\r\nV4L2_CAP_READWRITE |\r\nV4L2_CAP_STREAMING;\r\nvc->capabilities = vc->device_caps |\r\nV4L2_CAP_DEVICE_CAPS;\r\nreturn 0;\r\n}\r\nstatic int cpia2_enum_input(struct file *file, void *fh, struct v4l2_input *i)\r\n{\r\nif (i->index)\r\nreturn -EINVAL;\r\nstrcpy(i->name, "Camera");\r\ni->type = V4L2_INPUT_TYPE_CAMERA;\r\nreturn 0;\r\n}\r\nstatic int cpia2_g_input(struct file *file, void *fh, unsigned int *i)\r\n{\r\n*i = 0;\r\nreturn 0;\r\n}\r\nstatic int cpia2_s_input(struct file *file, void *fh, unsigned int i)\r\n{\r\nreturn i ? -EINVAL : 0;\r\n}\r\nstatic int cpia2_enum_fmt_vid_cap(struct file *file, void *fh,\r\nstruct v4l2_fmtdesc *f)\r\n{\r\nint index = f->index;\r\nif (index < 0 || index > 1)\r\nreturn -EINVAL;\r\nmemset(f, 0, sizeof(*f));\r\nf->index = index;\r\nf->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;\r\nf->flags = V4L2_FMT_FLAG_COMPRESSED;\r\nswitch(index) {\r\ncase 0:\r\nstrcpy(f->description, "MJPEG");\r\nf->pixelformat = V4L2_PIX_FMT_MJPEG;\r\nbreak;\r\ncase 1:\r\nstrcpy(f->description, "JPEG");\r\nf->pixelformat = V4L2_PIX_FMT_JPEG;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cpia2_try_fmt_vid_cap(struct file *file, void *fh,\r\nstruct v4l2_format *f)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nif (f->fmt.pix.pixelformat != V4L2_PIX_FMT_MJPEG &&\r\nf->fmt.pix.pixelformat != V4L2_PIX_FMT_JPEG)\r\nreturn -EINVAL;\r\nf->fmt.pix.field = V4L2_FIELD_NONE;\r\nf->fmt.pix.bytesperline = 0;\r\nf->fmt.pix.sizeimage = cam->frame_size;\r\nf->fmt.pix.colorspace = V4L2_COLORSPACE_JPEG;\r\nf->fmt.pix.priv = 0;\r\nswitch (cpia2_match_video_size(f->fmt.pix.width, f->fmt.pix.height)) {\r\ncase VIDEOSIZE_VGA:\r\nf->fmt.pix.width = 640;\r\nf->fmt.pix.height = 480;\r\nbreak;\r\ncase VIDEOSIZE_CIF:\r\nf->fmt.pix.width = 352;\r\nf->fmt.pix.height = 288;\r\nbreak;\r\ncase VIDEOSIZE_QVGA:\r\nf->fmt.pix.width = 320;\r\nf->fmt.pix.height = 240;\r\nbreak;\r\ncase VIDEOSIZE_288_216:\r\nf->fmt.pix.width = 288;\r\nf->fmt.pix.height = 216;\r\nbreak;\r\ncase VIDEOSIZE_256_192:\r\nf->fmt.pix.width = 256;\r\nf->fmt.pix.height = 192;\r\nbreak;\r\ncase VIDEOSIZE_224_168:\r\nf->fmt.pix.width = 224;\r\nf->fmt.pix.height = 168;\r\nbreak;\r\ncase VIDEOSIZE_192_144:\r\nf->fmt.pix.width = 192;\r\nf->fmt.pix.height = 144;\r\nbreak;\r\ncase VIDEOSIZE_QCIF:\r\ndefault:\r\nf->fmt.pix.width = 176;\r\nf->fmt.pix.height = 144;\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cpia2_s_fmt_vid_cap(struct file *file, void *_fh,\r\nstruct v4l2_format *f)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint err, frame;\r\nerr = cpia2_try_fmt_vid_cap(file, _fh, f);\r\nif(err != 0)\r\nreturn err;\r\ncam->pixelformat = f->fmt.pix.pixelformat;\r\ncam->params.compression.inhibit_htables = 0;\r\nDBG("Requested width = %d, height = %d\n",\r\nf->fmt.pix.width, f->fmt.pix.height);\r\nif (f->fmt.pix.width != cam->width ||\r\nf->fmt.pix.height != cam->height) {\r\ncam->width = f->fmt.pix.width;\r\ncam->height = f->fmt.pix.height;\r\ncam->params.roi.width = f->fmt.pix.width;\r\ncam->params.roi.height = f->fmt.pix.height;\r\ncpia2_set_format(cam);\r\n}\r\nfor (frame = 0; frame < cam->num_frames; ++frame) {\r\nif (cam->buffers[frame].status == FRAME_READING)\r\nif ((err = sync(cam, frame)) < 0)\r\nreturn err;\r\ncam->buffers[frame].status = FRAME_EMPTY;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cpia2_g_fmt_vid_cap(struct file *file, void *fh,\r\nstruct v4l2_format *f)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nf->fmt.pix.width = cam->width;\r\nf->fmt.pix.height = cam->height;\r\nf->fmt.pix.pixelformat = cam->pixelformat;\r\nf->fmt.pix.field = V4L2_FIELD_NONE;\r\nf->fmt.pix.bytesperline = 0;\r\nf->fmt.pix.sizeimage = cam->frame_size;\r\nf->fmt.pix.colorspace = V4L2_COLORSPACE_JPEG;\r\nf->fmt.pix.priv = 0;\r\nreturn 0;\r\n}\r\nstatic int cpia2_cropcap(struct file *file, void *fh, struct v4l2_cropcap *c)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nif (c->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nreturn -EINVAL;\r\nc->bounds.left = 0;\r\nc->bounds.top = 0;\r\nc->bounds.width = cam->width;\r\nc->bounds.height = cam->height;\r\nc->defrect.left = 0;\r\nc->defrect.top = 0;\r\nc->defrect.width = cam->width;\r\nc->defrect.height = cam->height;\r\nc->pixelaspect.numerator = 1;\r\nc->pixelaspect.denominator = 1;\r\nreturn 0;\r\n}\r\nstatic int cpia2_g_parm(struct file *file, void *fh, struct v4l2_streamparm *p)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nstruct v4l2_captureparm *cap = &p->parm.capture;\r\nint i;\r\nif (p->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nreturn -EINVAL;\r\ncap->capability = V4L2_CAP_TIMEPERFRAME;\r\ncap->readbuffers = cam->num_frames;\r\nfor (i = 0; i < ARRAY_SIZE(framerate_controls); i++)\r\nif (cam->params.vp_params.frame_rate == framerate_controls[i].value) {\r\ncap->timeperframe = framerate_controls[i].period;\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cpia2_s_parm(struct file *file, void *fh, struct v4l2_streamparm *p)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nstruct v4l2_captureparm *cap = &p->parm.capture;\r\nstruct v4l2_fract tpf = cap->timeperframe;\r\nint max = ARRAY_SIZE(framerate_controls) - 1;\r\nint ret;\r\nint i;\r\nret = cpia2_g_parm(file, fh, p);\r\nif (ret || !tpf.denominator || !tpf.numerator)\r\nreturn ret;\r\nif (cam->params.pnp_id.device_type == DEVICE_STV_672 &&\r\ncam->params.version.sensor_flags == CPIA2_VP_SENSOR_FLAGS_500)\r\nmax -= 2;\r\nfor (i = 0; i <= max; i++) {\r\nstruct v4l2_fract f1 = tpf;\r\nstruct v4l2_fract f2 = framerate_controls[i].period;\r\nf1.numerator *= f2.denominator;\r\nf2.numerator *= f1.denominator;\r\nif (f1.numerator >= f2.numerator)\r\nbreak;\r\n}\r\nif (i > max)\r\ni = max;\r\ncap->timeperframe = framerate_controls[i].period;\r\nreturn cpia2_set_fps(cam, framerate_controls[i].value);\r\n}\r\nstatic int cpia2_enum_framesizes(struct file *file, void *fh,\r\nstruct v4l2_frmsizeenum *fsize)\r\n{\r\nif (fsize->pixel_format != V4L2_PIX_FMT_MJPEG &&\r\nfsize->pixel_format != V4L2_PIX_FMT_JPEG)\r\nreturn -EINVAL;\r\nif (fsize->index >= ARRAY_SIZE(cpia2_framesizes))\r\nreturn -EINVAL;\r\nfsize->type = V4L2_FRMSIZE_TYPE_DISCRETE;\r\nfsize->discrete.width = cpia2_framesizes[fsize->index].width;\r\nfsize->discrete.height = cpia2_framesizes[fsize->index].height;\r\nreturn 0;\r\n}\r\nstatic int cpia2_enum_frameintervals(struct file *file, void *fh,\r\nstruct v4l2_frmivalenum *fival)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint max = ARRAY_SIZE(framerate_controls) - 1;\r\nint i;\r\nif (fival->pixel_format != V4L2_PIX_FMT_MJPEG &&\r\nfival->pixel_format != V4L2_PIX_FMT_JPEG)\r\nreturn -EINVAL;\r\nif (cam->params.pnp_id.device_type == DEVICE_STV_672 &&\r\ncam->params.version.sensor_flags == CPIA2_VP_SENSOR_FLAGS_500)\r\nmax -= 2;\r\nif (fival->index > max)\r\nreturn -EINVAL;\r\nfor (i = 0; i < ARRAY_SIZE(cpia2_framesizes); i++)\r\nif (fival->width == cpia2_framesizes[i].width &&\r\nfival->height == cpia2_framesizes[i].height)\r\nbreak;\r\nif (i == ARRAY_SIZE(cpia2_framesizes))\r\nreturn -EINVAL;\r\nfival->type = V4L2_FRMIVAL_TYPE_DISCRETE;\r\nfival->discrete = framerate_controls[fival->index].period;\r\nreturn 0;\r\n}\r\nstatic int cpia2_s_ctrl(struct v4l2_ctrl *ctrl)\r\n{\r\nstruct camera_data *cam =\r\ncontainer_of(ctrl->handler, struct camera_data, hdl);\r\nstatic const int flicker_table[] = {\r\nNEVER_FLICKER,\r\nFLICKER_50,\r\nFLICKER_60,\r\n};\r\nDBG("Set control id:%d, value:%d\n", ctrl->id, ctrl->val);\r\nswitch (ctrl->id) {\r\ncase V4L2_CID_BRIGHTNESS:\r\ncpia2_set_brightness(cam, ctrl->val);\r\nbreak;\r\ncase V4L2_CID_CONTRAST:\r\ncpia2_set_contrast(cam, ctrl->val);\r\nbreak;\r\ncase V4L2_CID_SATURATION:\r\ncpia2_set_saturation(cam, ctrl->val);\r\nbreak;\r\ncase V4L2_CID_HFLIP:\r\ncpia2_set_property_mirror(cam, ctrl->val);\r\nbreak;\r\ncase V4L2_CID_VFLIP:\r\ncpia2_set_property_flip(cam, ctrl->val);\r\nbreak;\r\ncase V4L2_CID_POWER_LINE_FREQUENCY:\r\nreturn cpia2_set_flicker_mode(cam, flicker_table[ctrl->val]);\r\ncase V4L2_CID_ILLUMINATORS_1:\r\nreturn cpia2_set_gpio(cam, (cam->top_light->val << 6) |\r\n(cam->bottom_light->val << 7));\r\ncase V4L2_CID_JPEG_ACTIVE_MARKER:\r\ncam->params.compression.inhibit_htables =\r\n!(ctrl->val & V4L2_JPEG_ACTIVE_MARKER_DHT);\r\nbreak;\r\ncase V4L2_CID_JPEG_COMPRESSION_QUALITY:\r\ncam->params.vc_params.quality = ctrl->val;\r\nbreak;\r\ncase CPIA2_CID_USB_ALT:\r\ncam->params.camera_state.stream_mode = ctrl->val;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cpia2_g_jpegcomp(struct file *file, void *fh, struct v4l2_jpegcompression *parms)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nmemset(parms, 0, sizeof(*parms));\r\nparms->quality = 80;\r\nparms->jpeg_markers = V4L2_JPEG_MARKER_DQT | V4L2_JPEG_MARKER_DRI;\r\nif(!cam->params.compression.inhibit_htables) {\r\nparms->jpeg_markers |= V4L2_JPEG_MARKER_DHT;\r\n}\r\nparms->APPn = cam->APPn;\r\nparms->APP_len = cam->APP_len;\r\nif(cam->APP_len > 0) {\r\nmemcpy(parms->APP_data, cam->APP_data, cam->APP_len);\r\nparms->jpeg_markers |= V4L2_JPEG_MARKER_APP;\r\n}\r\nparms->COM_len = cam->COM_len;\r\nif(cam->COM_len > 0) {\r\nmemcpy(parms->COM_data, cam->COM_data, cam->COM_len);\r\nparms->jpeg_markers |= JPEG_MARKER_COM;\r\n}\r\nDBG("G_JPEGCOMP APP_len:%d COM_len:%d\n",\r\nparms->APP_len, parms->COM_len);\r\nreturn 0;\r\n}\r\nstatic int cpia2_s_jpegcomp(struct file *file, void *fh,\r\nconst struct v4l2_jpegcompression *parms)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nDBG("S_JPEGCOMP APP_len:%d COM_len:%d\n",\r\nparms->APP_len, parms->COM_len);\r\ncam->params.compression.inhibit_htables =\r\n!(parms->jpeg_markers & V4L2_JPEG_MARKER_DHT);\r\nif(parms->APP_len != 0) {\r\nif(parms->APP_len > 0 &&\r\nparms->APP_len <= sizeof(cam->APP_data) &&\r\nparms->APPn >= 0 && parms->APPn <= 15) {\r\ncam->APPn = parms->APPn;\r\ncam->APP_len = parms->APP_len;\r\nmemcpy(cam->APP_data, parms->APP_data, parms->APP_len);\r\n} else {\r\nLOG("Bad APPn Params n=%d len=%d\n",\r\nparms->APPn, parms->APP_len);\r\nreturn -EINVAL;\r\n}\r\n} else {\r\ncam->APP_len = 0;\r\n}\r\nif(parms->COM_len != 0) {\r\nif(parms->COM_len > 0 &&\r\nparms->COM_len <= sizeof(cam->COM_data)) {\r\ncam->COM_len = parms->COM_len;\r\nmemcpy(cam->COM_data, parms->COM_data, parms->COM_len);\r\n} else {\r\nLOG("Bad COM_len=%d\n", parms->COM_len);\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int cpia2_reqbufs(struct file *file, void *fh, struct v4l2_requestbuffers *req)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nif(req->type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||\r\nreq->memory != V4L2_MEMORY_MMAP)\r\nreturn -EINVAL;\r\nDBG("REQBUFS requested:%d returning:%d\n", req->count, cam->num_frames);\r\nreq->count = cam->num_frames;\r\nmemset(&req->reserved, 0, sizeof(req->reserved));\r\nreturn 0;\r\n}\r\nstatic int cpia2_querybuf(struct file *file, void *fh, struct v4l2_buffer *buf)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nif(buf->type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||\r\nbuf->index > cam->num_frames)\r\nreturn -EINVAL;\r\nbuf->m.offset = cam->buffers[buf->index].data - cam->frame_buffer;\r\nbuf->length = cam->frame_size;\r\nbuf->memory = V4L2_MEMORY_MMAP;\r\nif(cam->mmapped)\r\nbuf->flags = V4L2_BUF_FLAG_MAPPED;\r\nelse\r\nbuf->flags = 0;\r\nbuf->flags |= V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;\r\nswitch (cam->buffers[buf->index].status) {\r\ncase FRAME_EMPTY:\r\ncase FRAME_ERROR:\r\ncase FRAME_READING:\r\nbuf->bytesused = 0;\r\nbuf->flags = V4L2_BUF_FLAG_QUEUED;\r\nbreak;\r\ncase FRAME_READY:\r\nbuf->bytesused = cam->buffers[buf->index].length;\r\nbuf->timestamp = cam->buffers[buf->index].timestamp;\r\nbuf->sequence = cam->buffers[buf->index].seq;\r\nbuf->flags = V4L2_BUF_FLAG_DONE;\r\nbreak;\r\n}\r\nDBG("QUERYBUF index:%d offset:%d flags:%d seq:%d bytesused:%d\n",\r\nbuf->index, buf->m.offset, buf->flags, buf->sequence,\r\nbuf->bytesused);\r\nreturn 0;\r\n}\r\nstatic int cpia2_qbuf(struct file *file, void *fh, struct v4l2_buffer *buf)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nif(buf->type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||\r\nbuf->memory != V4L2_MEMORY_MMAP ||\r\nbuf->index > cam->num_frames)\r\nreturn -EINVAL;\r\nDBG("QBUF #%d\n", buf->index);\r\nif(cam->buffers[buf->index].status == FRAME_READY)\r\ncam->buffers[buf->index].status = FRAME_EMPTY;\r\nreturn 0;\r\n}\r\nstatic int find_earliest_filled_buffer(struct camera_data *cam)\r\n{\r\nint i;\r\nint found = -1;\r\nfor (i=0; i<cam->num_frames; i++) {\r\nif(cam->buffers[i].status == FRAME_READY) {\r\nif(found < 0) {\r\nfound = i;\r\n} else {\r\nstruct timeval *tv1, *tv2;\r\ntv1 = &cam->buffers[i].timestamp;\r\ntv2 = &cam->buffers[found].timestamp;\r\nif(tv1->tv_sec < tv2->tv_sec ||\r\n(tv1->tv_sec == tv2->tv_sec &&\r\ntv1->tv_usec < tv2->tv_usec))\r\nfound = i;\r\n}\r\n}\r\n}\r\nreturn found;\r\n}\r\nstatic int cpia2_dqbuf(struct file *file, void *fh, struct v4l2_buffer *buf)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint frame;\r\nif(buf->type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||\r\nbuf->memory != V4L2_MEMORY_MMAP)\r\nreturn -EINVAL;\r\nframe = find_earliest_filled_buffer(cam);\r\nif(frame < 0 && file->f_flags&O_NONBLOCK)\r\nreturn -EAGAIN;\r\nif(frame < 0) {\r\nstruct framebuf *cb=cam->curbuff;\r\nmutex_unlock(&cam->v4l2_lock);\r\nwait_event_interruptible(cam->wq_stream,\r\n!video_is_registered(&cam->vdev) ||\r\n(cb=cam->curbuff)->status == FRAME_READY);\r\nmutex_lock(&cam->v4l2_lock);\r\nif (signal_pending(current))\r\nreturn -ERESTARTSYS;\r\nif (!video_is_registered(&cam->vdev))\r\nreturn -ENOTTY;\r\nframe = cb->num;\r\n}\r\nbuf->index = frame;\r\nbuf->bytesused = cam->buffers[buf->index].length;\r\nbuf->flags = V4L2_BUF_FLAG_MAPPED | V4L2_BUF_FLAG_DONE\r\n| V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;\r\nbuf->field = V4L2_FIELD_NONE;\r\nbuf->timestamp = cam->buffers[buf->index].timestamp;\r\nbuf->sequence = cam->buffers[buf->index].seq;\r\nbuf->m.offset = cam->buffers[buf->index].data - cam->frame_buffer;\r\nbuf->length = cam->frame_size;\r\nbuf->reserved2 = 0;\r\nbuf->reserved = 0;\r\nmemset(&buf->timecode, 0, sizeof(buf->timecode));\r\nDBG("DQBUF #%d status:%d seq:%d length:%d\n", buf->index,\r\ncam->buffers[buf->index].status, buf->sequence, buf->bytesused);\r\nreturn 0;\r\n}\r\nstatic int cpia2_streamon(struct file *file, void *fh, enum v4l2_buf_type type)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint ret = -EINVAL;\r\nDBG("VIDIOC_STREAMON, streaming=%d\n", cam->streaming);\r\nif (!cam->mmapped || type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nreturn -EINVAL;\r\nif (!cam->streaming) {\r\nret = cpia2_usb_stream_start(cam,\r\ncam->params.camera_state.stream_mode);\r\nif (!ret)\r\nv4l2_ctrl_grab(cam->usb_alt, true);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cpia2_streamoff(struct file *file, void *fh, enum v4l2_buf_type type)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint ret = -EINVAL;\r\nDBG("VIDIOC_STREAMOFF, streaming=%d\n", cam->streaming);\r\nif (!cam->mmapped || type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\r\nreturn -EINVAL;\r\nif (cam->streaming) {\r\nret = cpia2_usb_stream_stop(cam);\r\nif (!ret)\r\nv4l2_ctrl_grab(cam->usb_alt, false);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cpia2_mmap(struct file *file, struct vm_area_struct *area)\r\n{\r\nstruct camera_data *cam = video_drvdata(file);\r\nint retval;\r\nif (mutex_lock_interruptible(&cam->v4l2_lock))\r\nreturn -ERESTARTSYS;\r\nretval = cpia2_remap_buffer(cam, area);\r\nif(!retval)\r\ncam->stream_fh = file->private_data;\r\nmutex_unlock(&cam->v4l2_lock);\r\nreturn retval;\r\n}\r\nstatic void reset_camera_struct_v4l(struct camera_data *cam)\r\n{\r\ncam->width = cam->params.roi.width;\r\ncam->height = cam->params.roi.height;\r\ncam->frame_size = buffer_size;\r\ncam->num_frames = num_buffers;\r\ncam->params.flicker_control.flicker_mode_req = flicker_mode;\r\ncam->params.camera_state.stream_mode = alternate;\r\ncam->pixelformat = V4L2_PIX_FMT_JPEG;\r\n}\r\nvoid cpia2_camera_release(struct v4l2_device *v4l2_dev)\r\n{\r\nstruct camera_data *cam =\r\ncontainer_of(v4l2_dev, struct camera_data, v4l2_dev);\r\nv4l2_ctrl_handler_free(&cam->hdl);\r\nv4l2_device_unregister(&cam->v4l2_dev);\r\nkfree(cam);\r\n}\r\nint cpia2_register_camera(struct camera_data *cam)\r\n{\r\nstruct v4l2_ctrl_handler *hdl = &cam->hdl;\r\nstruct v4l2_ctrl_config cpia2_usb_alt = {\r\n.ops = &cpia2_ctrl_ops,\r\n.id = CPIA2_CID_USB_ALT,\r\n.name = "USB Alternate",\r\n.type = V4L2_CTRL_TYPE_INTEGER,\r\n.min = USBIF_ISO_1,\r\n.max = USBIF_ISO_6,\r\n.step = 1,\r\n};\r\nint ret;\r\nv4l2_ctrl_handler_init(hdl, 12);\r\nv4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_BRIGHTNESS,\r\ncam->params.pnp_id.device_type == DEVICE_STV_672 ? 1 : 0,\r\n255, 1, DEFAULT_BRIGHTNESS);\r\nv4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_CONTRAST, 0, 255, 1, DEFAULT_CONTRAST);\r\nv4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_SATURATION, 0, 255, 1, DEFAULT_SATURATION);\r\nv4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_HFLIP, 0, 1, 1, 0);\r\nv4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_JPEG_ACTIVE_MARKER, 0,\r\nV4L2_JPEG_ACTIVE_MARKER_DHT, 0,\r\nV4L2_JPEG_ACTIVE_MARKER_DHT);\r\nv4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_JPEG_COMPRESSION_QUALITY, 1,\r\n100, 1, 100);\r\ncpia2_usb_alt.def = alternate;\r\ncam->usb_alt = v4l2_ctrl_new_custom(hdl, &cpia2_usb_alt, NULL);\r\nif (cam->params.pnp_id.device_type != DEVICE_STV_672)\r\nv4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_VFLIP, 0, 1, 1, 0);\r\nif (cam->params.pnp_id.device_type == DEVICE_STV_672)\r\nv4l2_ctrl_new_std_menu(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_POWER_LINE_FREQUENCY,\r\nV4L2_CID_POWER_LINE_FREQUENCY_60HZ, 0, 0);\r\nif (cam->params.pnp_id.product == 0x151) {\r\ncam->top_light = v4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_ILLUMINATORS_1, 0, 1, 1, 0);\r\ncam->bottom_light = v4l2_ctrl_new_std(hdl, &cpia2_ctrl_ops,\r\nV4L2_CID_ILLUMINATORS_2, 0, 1, 1, 0);\r\nv4l2_ctrl_cluster(2, &cam->top_light);\r\n}\r\nif (hdl->error) {\r\nret = hdl->error;\r\nv4l2_ctrl_handler_free(hdl);\r\nreturn ret;\r\n}\r\ncam->vdev = cpia2_template;\r\nvideo_set_drvdata(&cam->vdev, cam);\r\ncam->vdev.lock = &cam->v4l2_lock;\r\ncam->vdev.ctrl_handler = hdl;\r\ncam->vdev.v4l2_dev = &cam->v4l2_dev;\r\nset_bit(V4L2_FL_USE_FH_PRIO, &cam->vdev.flags);\r\nreset_camera_struct_v4l(cam);\r\nif (video_register_device(&cam->vdev, VFL_TYPE_GRABBER, video_nr) < 0) {\r\nERR("video_register_device failed\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nvoid cpia2_unregister_camera(struct camera_data *cam)\r\n{\r\nvideo_unregister_device(&cam->vdev);\r\n}\r\nstatic void __init check_parameters(void)\r\n{\r\nif(buffer_size < PAGE_SIZE) {\r\nbuffer_size = PAGE_SIZE;\r\nLOG("buffer_size too small, setting to %d\n", buffer_size);\r\n} else if(buffer_size > 1024*1024) {\r\nbuffer_size = 1024*1024;\r\nLOG("buffer_size ridiculously large, setting to %d\n",\r\nbuffer_size);\r\n} else {\r\nbuffer_size += PAGE_SIZE-1;\r\nbuffer_size &= ~(PAGE_SIZE-1);\r\n}\r\nif(num_buffers < 1) {\r\nnum_buffers = 1;\r\nLOG("num_buffers too small, setting to %d\n", num_buffers);\r\n} else if(num_buffers > VIDEO_MAX_FRAME) {\r\nnum_buffers = VIDEO_MAX_FRAME;\r\nLOG("num_buffers too large, setting to %d\n", num_buffers);\r\n}\r\nif(alternate < USBIF_ISO_1 || alternate > USBIF_ISO_6) {\r\nalternate = DEFAULT_ALT;\r\nLOG("alternate specified is invalid, using %d\n", alternate);\r\n}\r\nif (flicker_mode != 0 && flicker_mode != FLICKER_50 && flicker_mode != FLICKER_60) {\r\nflicker_mode = 0;\r\nLOG("Flicker mode specified is invalid, using %d\n",\r\nflicker_mode);\r\n}\r\nDBG("Using %d buffers, each %d bytes, alternate=%d\n",\r\nnum_buffers, buffer_size, alternate);\r\n}\r\nstatic int __init cpia2_init(void)\r\n{\r\nLOG("%s v%s\n",\r\nABOUT, CPIA_VERSION);\r\ncheck_parameters();\r\ncpia2_usb_init();\r\nreturn 0;\r\n}\r\nstatic void __exit cpia2_exit(void)\r\n{\r\ncpia2_usb_cleanup();\r\nschedule_timeout(2 * HZ);\r\n}
