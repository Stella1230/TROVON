static int __init setup_fail_io_timeout(char *str)\r\n{\r\nreturn setup_fault_attr(&fail_io_timeout, str);\r\n}\r\nint blk_should_fake_timeout(struct request_queue *q)\r\n{\r\nif (!test_bit(QUEUE_FLAG_FAIL_IO, &q->queue_flags))\r\nreturn 0;\r\nreturn should_fail(&fail_io_timeout, 1);\r\n}\r\nstatic int __init fail_io_timeout_debugfs(void)\r\n{\r\nstruct dentry *dir = fault_create_debugfs_attr("fail_io_timeout",\r\nNULL, &fail_io_timeout);\r\nreturn PTR_ERR_OR_ZERO(dir);\r\n}\r\nssize_t part_timeout_show(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nint set = test_bit(QUEUE_FLAG_FAIL_IO, &disk->queue->queue_flags);\r\nreturn sprintf(buf, "%d\n", set != 0);\r\n}\r\nssize_t part_timeout_store(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nint val;\r\nif (count) {\r\nstruct request_queue *q = disk->queue;\r\nchar *p = (char *) buf;\r\nval = simple_strtoul(p, &p, 10);\r\nspin_lock_irq(q->queue_lock);\r\nif (val)\r\nqueue_flag_set(QUEUE_FLAG_FAIL_IO, q);\r\nelse\r\nqueue_flag_clear(QUEUE_FLAG_FAIL_IO, q);\r\nspin_unlock_irq(q->queue_lock);\r\n}\r\nreturn count;\r\n}\r\nvoid blk_delete_timer(struct request *req)\r\n{\r\nlist_del_init(&req->timeout_list);\r\n}\r\nstatic void blk_rq_timed_out(struct request *req)\r\n{\r\nstruct request_queue *q = req->q;\r\nenum blk_eh_timer_return ret = BLK_EH_RESET_TIMER;\r\nif (q->rq_timed_out_fn)\r\nret = q->rq_timed_out_fn(req);\r\nswitch (ret) {\r\ncase BLK_EH_HANDLED:\r\nif (q->mq_ops)\r\n__blk_mq_complete_request(req);\r\nelse\r\n__blk_complete_request(req);\r\nbreak;\r\ncase BLK_EH_RESET_TIMER:\r\nif (q->mq_ops)\r\nblk_mq_add_timer(req);\r\nelse\r\nblk_add_timer(req);\r\nblk_clear_rq_complete(req);\r\nbreak;\r\ncase BLK_EH_NOT_HANDLED:\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "block: bad eh return: %d\n", ret);\r\nbreak;\r\n}\r\n}\r\nvoid blk_rq_check_expired(struct request *rq, unsigned long *next_timeout,\r\nunsigned int *next_set)\r\n{\r\nif (time_after_eq(jiffies, rq->deadline)) {\r\nlist_del_init(&rq->timeout_list);\r\nif (!blk_mark_rq_complete(rq))\r\nblk_rq_timed_out(rq);\r\n} else if (!*next_set || time_after(*next_timeout, rq->deadline)) {\r\n*next_timeout = rq->deadline;\r\n*next_set = 1;\r\n}\r\n}\r\nvoid blk_rq_timed_out_timer(unsigned long data)\r\n{\r\nstruct request_queue *q = (struct request_queue *) data;\r\nunsigned long flags, next = 0;\r\nstruct request *rq, *tmp;\r\nint next_set = 0;\r\nspin_lock_irqsave(q->queue_lock, flags);\r\nlist_for_each_entry_safe(rq, tmp, &q->timeout_list, timeout_list)\r\nblk_rq_check_expired(rq, &next, &next_set);\r\nif (next_set)\r\nmod_timer(&q->timeout, round_jiffies_up(next));\r\nspin_unlock_irqrestore(q->queue_lock, flags);\r\n}\r\nvoid blk_abort_request(struct request *req)\r\n{\r\nif (blk_mark_rq_complete(req))\r\nreturn;\r\nblk_delete_timer(req);\r\nblk_rq_timed_out(req);\r\n}\r\nvoid __blk_add_timer(struct request *req, struct list_head *timeout_list)\r\n{\r\nstruct request_queue *q = req->q;\r\nunsigned long expiry;\r\nif (!q->rq_timed_out_fn)\r\nreturn;\r\nBUG_ON(!list_empty(&req->timeout_list));\r\nif (!req->timeout)\r\nreq->timeout = q->rq_timeout;\r\nreq->deadline = jiffies + req->timeout;\r\nif (timeout_list)\r\nlist_add_tail(&req->timeout_list, timeout_list);\r\nexpiry = round_jiffies_up(req->deadline);\r\nif (!timer_pending(&q->timeout) ||\r\ntime_before(expiry, q->timeout.expires))\r\nmod_timer(&q->timeout, expiry);\r\n}\r\nvoid blk_add_timer(struct request *req)\r\n{\r\n__blk_add_timer(req, &req->q->timeout_list);\r\n}
