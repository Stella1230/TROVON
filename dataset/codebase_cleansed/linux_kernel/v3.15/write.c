struct nfs_commit_data *nfs_commitdata_alloc(void)\r\n{\r\nstruct nfs_commit_data *p = mempool_alloc(nfs_commit_mempool, GFP_NOIO);\r\nif (p) {\r\nmemset(p, 0, sizeof(*p));\r\nINIT_LIST_HEAD(&p->pages);\r\n}\r\nreturn p;\r\n}\r\nvoid nfs_commit_free(struct nfs_commit_data *p)\r\n{\r\nmempool_free(p, nfs_commit_mempool);\r\n}\r\nstruct nfs_write_header *nfs_writehdr_alloc(void)\r\n{\r\nstruct nfs_write_header *p = mempool_alloc(nfs_wdata_mempool, GFP_NOIO);\r\nif (p) {\r\nstruct nfs_pgio_header *hdr = &p->header;\r\nmemset(p, 0, sizeof(*p));\r\nINIT_LIST_HEAD(&hdr->pages);\r\nINIT_LIST_HEAD(&hdr->rpc_list);\r\nspin_lock_init(&hdr->lock);\r\natomic_set(&hdr->refcnt, 0);\r\nhdr->verf = &p->verf;\r\n}\r\nreturn p;\r\n}\r\nstatic struct nfs_write_data *nfs_writedata_alloc(struct nfs_pgio_header *hdr,\r\nunsigned int pagecount)\r\n{\r\nstruct nfs_write_data *data, *prealloc;\r\nprealloc = &container_of(hdr, struct nfs_write_header, header)->rpc_data;\r\nif (prealloc->header == NULL)\r\ndata = prealloc;\r\nelse\r\ndata = kzalloc(sizeof(*data), GFP_KERNEL);\r\nif (!data)\r\ngoto out;\r\nif (nfs_pgarray_set(&data->pages, pagecount)) {\r\ndata->header = hdr;\r\natomic_inc(&hdr->refcnt);\r\n} else {\r\nif (data != prealloc)\r\nkfree(data);\r\ndata = NULL;\r\n}\r\nout:\r\nreturn data;\r\n}\r\nvoid nfs_writehdr_free(struct nfs_pgio_header *hdr)\r\n{\r\nstruct nfs_write_header *whdr = container_of(hdr, struct nfs_write_header, header);\r\nmempool_free(whdr, nfs_wdata_mempool);\r\n}\r\nvoid nfs_writedata_release(struct nfs_write_data *wdata)\r\n{\r\nstruct nfs_pgio_header *hdr = wdata->header;\r\nstruct nfs_write_header *write_header = container_of(hdr, struct nfs_write_header, header);\r\nput_nfs_open_context(wdata->args.context);\r\nif (wdata->pages.pagevec != wdata->pages.page_array)\r\nkfree(wdata->pages.pagevec);\r\nif (wdata == &write_header->rpc_data) {\r\nwdata->header = NULL;\r\nwdata = NULL;\r\n}\r\nif (atomic_dec_and_test(&hdr->refcnt))\r\nhdr->completion_ops->completion(hdr);\r\nkfree(wdata);\r\n}\r\nstatic void nfs_context_set_write_error(struct nfs_open_context *ctx, int error)\r\n{\r\nctx->error = error;\r\nsmp_wmb();\r\nset_bit(NFS_CONTEXT_ERROR_WRITE, &ctx->flags);\r\n}\r\nstatic struct nfs_page *\r\nnfs_page_find_request_locked(struct nfs_inode *nfsi, struct page *page)\r\n{\r\nstruct nfs_page *req = NULL;\r\nif (PagePrivate(page))\r\nreq = (struct nfs_page *)page_private(page);\r\nelse if (unlikely(PageSwapCache(page))) {\r\nstruct nfs_page *freq, *t;\r\nlist_for_each_entry_safe(freq, t, &nfsi->commit_info.list, wb_list) {\r\nif (freq->wb_page == page) {\r\nreq = freq;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (req)\r\nkref_get(&req->wb_kref);\r\nreturn req;\r\n}\r\nstatic struct nfs_page *nfs_page_find_request(struct page *page)\r\n{\r\nstruct inode *inode = page_file_mapping(page)->host;\r\nstruct nfs_page *req = NULL;\r\nspin_lock(&inode->i_lock);\r\nreq = nfs_page_find_request_locked(NFS_I(inode), page);\r\nspin_unlock(&inode->i_lock);\r\nreturn req;\r\n}\r\nstatic void nfs_grow_file(struct page *page, unsigned int offset, unsigned int count)\r\n{\r\nstruct inode *inode = page_file_mapping(page)->host;\r\nloff_t end, i_size;\r\npgoff_t end_index;\r\nspin_lock(&inode->i_lock);\r\ni_size = i_size_read(inode);\r\nend_index = (i_size - 1) >> PAGE_CACHE_SHIFT;\r\nif (i_size > 0 && page_file_index(page) < end_index)\r\ngoto out;\r\nend = page_file_offset(page) + ((loff_t)offset+count);\r\nif (i_size >= end)\r\ngoto out;\r\ni_size_write(inode, end);\r\nnfs_inc_stats(inode, NFSIOS_EXTENDWRITE);\r\nout:\r\nspin_unlock(&inode->i_lock);\r\n}\r\nstatic void nfs_set_pageerror(struct page *page)\r\n{\r\nnfs_zap_mapping(page_file_mapping(page)->host, page_file_mapping(page));\r\n}\r\nstatic void nfs_mark_uptodate(struct page *page, unsigned int base, unsigned int count)\r\n{\r\nif (PageUptodate(page))\r\nreturn;\r\nif (base != 0)\r\nreturn;\r\nif (count != nfs_page_length(page))\r\nreturn;\r\nSetPageUptodate(page);\r\n}\r\nstatic int wb_priority(struct writeback_control *wbc)\r\n{\r\nif (wbc->for_reclaim)\r\nreturn FLUSH_HIGHPRI | FLUSH_STABLE;\r\nif (wbc->for_kupdate || wbc->for_background)\r\nreturn FLUSH_LOWPRI | FLUSH_COND_STABLE;\r\nreturn FLUSH_COND_STABLE;\r\n}\r\nstatic void nfs_set_page_writeback(struct page *page)\r\n{\r\nstruct nfs_server *nfss = NFS_SERVER(page_file_mapping(page)->host);\r\nint ret = test_set_page_writeback(page);\r\nWARN_ON_ONCE(ret != 0);\r\nif (atomic_long_inc_return(&nfss->writeback) >\r\nNFS_CONGESTION_ON_THRESH) {\r\nset_bdi_congested(&nfss->backing_dev_info,\r\nBLK_RW_ASYNC);\r\n}\r\n}\r\nstatic void nfs_end_page_writeback(struct page *page)\r\n{\r\nstruct inode *inode = page_file_mapping(page)->host;\r\nstruct nfs_server *nfss = NFS_SERVER(inode);\r\nend_page_writeback(page);\r\nif (atomic_long_dec_return(&nfss->writeback) < NFS_CONGESTION_OFF_THRESH)\r\nclear_bdi_congested(&nfss->backing_dev_info, BLK_RW_ASYNC);\r\n}\r\nstatic struct nfs_page *nfs_find_and_lock_request(struct page *page, bool nonblock)\r\n{\r\nstruct inode *inode = page_file_mapping(page)->host;\r\nstruct nfs_page *req;\r\nint ret;\r\nspin_lock(&inode->i_lock);\r\nfor (;;) {\r\nreq = nfs_page_find_request_locked(NFS_I(inode), page);\r\nif (req == NULL)\r\nbreak;\r\nif (nfs_lock_request(req))\r\nbreak;\r\nspin_unlock(&inode->i_lock);\r\nif (!nonblock)\r\nret = nfs_wait_on_request(req);\r\nelse\r\nret = -EAGAIN;\r\nnfs_release_request(req);\r\nif (ret != 0)\r\nreturn ERR_PTR(ret);\r\nspin_lock(&inode->i_lock);\r\n}\r\nspin_unlock(&inode->i_lock);\r\nreturn req;\r\n}\r\nstatic int nfs_page_async_flush(struct nfs_pageio_descriptor *pgio,\r\nstruct page *page, bool nonblock)\r\n{\r\nstruct nfs_page *req;\r\nint ret = 0;\r\nreq = nfs_find_and_lock_request(page, nonblock);\r\nif (!req)\r\ngoto out;\r\nret = PTR_ERR(req);\r\nif (IS_ERR(req))\r\ngoto out;\r\nnfs_set_page_writeback(page);\r\nWARN_ON_ONCE(test_bit(PG_CLEAN, &req->wb_flags));\r\nret = 0;\r\nif (!nfs_pageio_add_request(pgio, req)) {\r\nnfs_redirty_request(req);\r\nret = pgio->pg_error;\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic int nfs_do_writepage(struct page *page, struct writeback_control *wbc, struct nfs_pageio_descriptor *pgio)\r\n{\r\nstruct inode *inode = page_file_mapping(page)->host;\r\nint ret;\r\nnfs_inc_stats(inode, NFSIOS_VFSWRITEPAGE);\r\nnfs_add_stats(inode, NFSIOS_WRITEPAGES, 1);\r\nnfs_pageio_cond_complete(pgio, page_file_index(page));\r\nret = nfs_page_async_flush(pgio, page, wbc->sync_mode == WB_SYNC_NONE);\r\nif (ret == -EAGAIN) {\r\nredirty_page_for_writepage(wbc, page);\r\nret = 0;\r\n}\r\nreturn ret;\r\n}\r\nstatic int nfs_writepage_locked(struct page *page, struct writeback_control *wbc)\r\n{\r\nstruct nfs_pageio_descriptor pgio;\r\nint err;\r\nNFS_PROTO(page_file_mapping(page)->host)->write_pageio_init(&pgio,\r\npage->mapping->host,\r\nwb_priority(wbc),\r\n&nfs_async_write_completion_ops);\r\nerr = nfs_do_writepage(page, wbc, &pgio);\r\nnfs_pageio_complete(&pgio);\r\nif (err < 0)\r\nreturn err;\r\nif (pgio.pg_error < 0)\r\nreturn pgio.pg_error;\r\nreturn 0;\r\n}\r\nint nfs_writepage(struct page *page, struct writeback_control *wbc)\r\n{\r\nint ret;\r\nret = nfs_writepage_locked(page, wbc);\r\nunlock_page(page);\r\nreturn ret;\r\n}\r\nstatic int nfs_writepages_callback(struct page *page, struct writeback_control *wbc, void *data)\r\n{\r\nint ret;\r\nret = nfs_do_writepage(page, wbc, data);\r\nunlock_page(page);\r\nreturn ret;\r\n}\r\nint nfs_writepages(struct address_space *mapping, struct writeback_control *wbc)\r\n{\r\nstruct inode *inode = mapping->host;\r\nunsigned long *bitlock = &NFS_I(inode)->flags;\r\nstruct nfs_pageio_descriptor pgio;\r\nint err;\r\nerr = wait_on_bit_lock(bitlock, NFS_INO_FLUSHING,\r\nnfs_wait_bit_killable, TASK_KILLABLE);\r\nif (err)\r\ngoto out_err;\r\nnfs_inc_stats(inode, NFSIOS_VFSWRITEPAGES);\r\nNFS_PROTO(inode)->write_pageio_init(&pgio, inode, wb_priority(wbc), &nfs_async_write_completion_ops);\r\nerr = write_cache_pages(mapping, wbc, nfs_writepages_callback, &pgio);\r\nnfs_pageio_complete(&pgio);\r\nclear_bit_unlock(NFS_INO_FLUSHING, bitlock);\r\nsmp_mb__after_clear_bit();\r\nwake_up_bit(bitlock, NFS_INO_FLUSHING);\r\nif (err < 0)\r\ngoto out_err;\r\nerr = pgio.pg_error;\r\nif (err < 0)\r\ngoto out_err;\r\nreturn 0;\r\nout_err:\r\nreturn err;\r\n}\r\nstatic void nfs_inode_add_request(struct inode *inode, struct nfs_page *req)\r\n{\r\nstruct nfs_inode *nfsi = NFS_I(inode);\r\nnfs_lock_request(req);\r\nspin_lock(&inode->i_lock);\r\nif (!nfsi->npages && NFS_PROTO(inode)->have_delegation(inode, FMODE_WRITE))\r\ninode->i_version++;\r\nif (likely(!PageSwapCache(req->wb_page))) {\r\nset_bit(PG_MAPPED, &req->wb_flags);\r\nSetPagePrivate(req->wb_page);\r\nset_page_private(req->wb_page, (unsigned long)req);\r\n}\r\nnfsi->npages++;\r\nkref_get(&req->wb_kref);\r\nspin_unlock(&inode->i_lock);\r\n}\r\nstatic void nfs_inode_remove_request(struct nfs_page *req)\r\n{\r\nstruct inode *inode = req->wb_context->dentry->d_inode;\r\nstruct nfs_inode *nfsi = NFS_I(inode);\r\nspin_lock(&inode->i_lock);\r\nif (likely(!PageSwapCache(req->wb_page))) {\r\nset_page_private(req->wb_page, 0);\r\nClearPagePrivate(req->wb_page);\r\nclear_bit(PG_MAPPED, &req->wb_flags);\r\n}\r\nnfsi->npages--;\r\nspin_unlock(&inode->i_lock);\r\nnfs_release_request(req);\r\n}\r\nstatic void\r\nnfs_mark_request_dirty(struct nfs_page *req)\r\n{\r\n__set_page_dirty_nobuffers(req->wb_page);\r\n}\r\nvoid\r\nnfs_request_add_commit_list(struct nfs_page *req, struct list_head *dst,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nset_bit(PG_CLEAN, &(req)->wb_flags);\r\nspin_lock(cinfo->lock);\r\nnfs_list_add_request(req, dst);\r\ncinfo->mds->ncommit++;\r\nspin_unlock(cinfo->lock);\r\nif (!cinfo->dreq) {\r\ninc_zone_page_state(req->wb_page, NR_UNSTABLE_NFS);\r\ninc_bdi_stat(page_file_mapping(req->wb_page)->backing_dev_info,\r\nBDI_RECLAIMABLE);\r\n__mark_inode_dirty(req->wb_context->dentry->d_inode,\r\nI_DIRTY_DATASYNC);\r\n}\r\n}\r\nvoid\r\nnfs_request_remove_commit_list(struct nfs_page *req,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nif (!test_and_clear_bit(PG_CLEAN, &(req)->wb_flags))\r\nreturn;\r\nnfs_list_remove_request(req);\r\ncinfo->mds->ncommit--;\r\n}\r\nstatic void nfs_init_cinfo_from_inode(struct nfs_commit_info *cinfo,\r\nstruct inode *inode)\r\n{\r\ncinfo->lock = &inode->i_lock;\r\ncinfo->mds = &NFS_I(inode)->commit_info;\r\ncinfo->ds = pnfs_get_ds_info(inode);\r\ncinfo->dreq = NULL;\r\ncinfo->completion_ops = &nfs_commit_completion_ops;\r\n}\r\nvoid nfs_init_cinfo(struct nfs_commit_info *cinfo,\r\nstruct inode *inode,\r\nstruct nfs_direct_req *dreq)\r\n{\r\nif (dreq)\r\nnfs_init_cinfo_from_dreq(cinfo, dreq);\r\nelse\r\nnfs_init_cinfo_from_inode(cinfo, inode);\r\n}\r\nvoid\r\nnfs_mark_request_commit(struct nfs_page *req, struct pnfs_layout_segment *lseg,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nif (pnfs_mark_request_commit(req, lseg, cinfo))\r\nreturn;\r\nnfs_request_add_commit_list(req, &cinfo->mds->list, cinfo);\r\n}\r\nstatic void\r\nnfs_clear_page_commit(struct page *page)\r\n{\r\ndec_zone_page_state(page, NR_UNSTABLE_NFS);\r\ndec_bdi_stat(page_file_mapping(page)->backing_dev_info, BDI_RECLAIMABLE);\r\n}\r\nstatic void\r\nnfs_clear_request_commit(struct nfs_page *req)\r\n{\r\nif (test_bit(PG_CLEAN, &req->wb_flags)) {\r\nstruct inode *inode = req->wb_context->dentry->d_inode;\r\nstruct nfs_commit_info cinfo;\r\nnfs_init_cinfo_from_inode(&cinfo, inode);\r\nif (!pnfs_clear_request_commit(req, &cinfo)) {\r\nspin_lock(cinfo.lock);\r\nnfs_request_remove_commit_list(req, &cinfo);\r\nspin_unlock(cinfo.lock);\r\n}\r\nnfs_clear_page_commit(req->wb_page);\r\n}\r\n}\r\nstatic inline\r\nint nfs_write_need_commit(struct nfs_write_data *data)\r\n{\r\nif (data->verf.committed == NFS_DATA_SYNC)\r\nreturn data->header->lseg == NULL;\r\nreturn data->verf.committed != NFS_FILE_SYNC;\r\n}\r\nstatic void nfs_init_cinfo_from_inode(struct nfs_commit_info *cinfo,\r\nstruct inode *inode)\r\n{\r\n}\r\nvoid nfs_init_cinfo(struct nfs_commit_info *cinfo,\r\nstruct inode *inode,\r\nstruct nfs_direct_req *dreq)\r\n{\r\n}\r\nvoid\r\nnfs_mark_request_commit(struct nfs_page *req, struct pnfs_layout_segment *lseg,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\n}\r\nstatic void\r\nnfs_clear_request_commit(struct nfs_page *req)\r\n{\r\n}\r\nstatic inline\r\nint nfs_write_need_commit(struct nfs_write_data *data)\r\n{\r\nreturn 0;\r\n}\r\nstatic void nfs_write_completion(struct nfs_pgio_header *hdr)\r\n{\r\nstruct nfs_commit_info cinfo;\r\nunsigned long bytes = 0;\r\nif (test_bit(NFS_IOHDR_REDO, &hdr->flags))\r\ngoto out;\r\nnfs_init_cinfo_from_inode(&cinfo, hdr->inode);\r\nwhile (!list_empty(&hdr->pages)) {\r\nstruct nfs_page *req = nfs_list_entry(hdr->pages.next);\r\nbytes += req->wb_bytes;\r\nnfs_list_remove_request(req);\r\nif (test_bit(NFS_IOHDR_ERROR, &hdr->flags) &&\r\n(hdr->good_bytes < bytes)) {\r\nnfs_set_pageerror(req->wb_page);\r\nnfs_context_set_write_error(req->wb_context, hdr->error);\r\ngoto remove_req;\r\n}\r\nif (test_bit(NFS_IOHDR_NEED_RESCHED, &hdr->flags)) {\r\nnfs_mark_request_dirty(req);\r\ngoto next;\r\n}\r\nif (test_bit(NFS_IOHDR_NEED_COMMIT, &hdr->flags)) {\r\nmemcpy(&req->wb_verf, &hdr->verf->verifier, sizeof(req->wb_verf));\r\nnfs_mark_request_commit(req, hdr->lseg, &cinfo);\r\ngoto next;\r\n}\r\nremove_req:\r\nnfs_inode_remove_request(req);\r\nnext:\r\nnfs_unlock_request(req);\r\nnfs_end_page_writeback(req->wb_page);\r\nnfs_release_request(req);\r\n}\r\nout:\r\nhdr->release(hdr);\r\n}\r\nstatic unsigned long\r\nnfs_reqs_to_commit(struct nfs_commit_info *cinfo)\r\n{\r\nreturn cinfo->mds->ncommit;\r\n}\r\nint\r\nnfs_scan_commit_list(struct list_head *src, struct list_head *dst,\r\nstruct nfs_commit_info *cinfo, int max)\r\n{\r\nstruct nfs_page *req, *tmp;\r\nint ret = 0;\r\nlist_for_each_entry_safe(req, tmp, src, wb_list) {\r\nif (!nfs_lock_request(req))\r\ncontinue;\r\nkref_get(&req->wb_kref);\r\nif (cond_resched_lock(cinfo->lock))\r\nlist_safe_reset_next(req, tmp, wb_list);\r\nnfs_request_remove_commit_list(req, cinfo);\r\nnfs_list_add_request(req, dst);\r\nret++;\r\nif ((ret == max) && !cinfo->dreq)\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nint\r\nnfs_scan_commit(struct inode *inode, struct list_head *dst,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nint ret = 0;\r\nspin_lock(cinfo->lock);\r\nif (cinfo->mds->ncommit > 0) {\r\nconst int max = INT_MAX;\r\nret = nfs_scan_commit_list(&cinfo->mds->list, dst,\r\ncinfo, max);\r\nret += pnfs_scan_commit_lists(inode, cinfo, max - ret);\r\n}\r\nspin_unlock(cinfo->lock);\r\nreturn ret;\r\n}\r\nstatic unsigned long nfs_reqs_to_commit(struct nfs_commit_info *cinfo)\r\n{\r\nreturn 0;\r\n}\r\nint nfs_scan_commit(struct inode *inode, struct list_head *dst,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nreturn 0;\r\n}\r\nstatic struct nfs_page *nfs_try_to_update_request(struct inode *inode,\r\nstruct page *page,\r\nunsigned int offset,\r\nunsigned int bytes)\r\n{\r\nstruct nfs_page *req;\r\nunsigned int rqend;\r\nunsigned int end;\r\nint error;\r\nif (!PagePrivate(page))\r\nreturn NULL;\r\nend = offset + bytes;\r\nspin_lock(&inode->i_lock);\r\nfor (;;) {\r\nreq = nfs_page_find_request_locked(NFS_I(inode), page);\r\nif (req == NULL)\r\ngoto out_unlock;\r\nrqend = req->wb_offset + req->wb_bytes;\r\nif (offset > rqend\r\n|| end < req->wb_offset)\r\ngoto out_flushme;\r\nif (nfs_lock_request(req))\r\nbreak;\r\nspin_unlock(&inode->i_lock);\r\nerror = nfs_wait_on_request(req);\r\nnfs_release_request(req);\r\nif (error != 0)\r\ngoto out_err;\r\nspin_lock(&inode->i_lock);\r\n}\r\nif (offset < req->wb_offset) {\r\nreq->wb_offset = offset;\r\nreq->wb_pgbase = offset;\r\n}\r\nif (end > rqend)\r\nreq->wb_bytes = end - req->wb_offset;\r\nelse\r\nreq->wb_bytes = rqend - req->wb_offset;\r\nout_unlock:\r\nspin_unlock(&inode->i_lock);\r\nif (req)\r\nnfs_clear_request_commit(req);\r\nreturn req;\r\nout_flushme:\r\nspin_unlock(&inode->i_lock);\r\nnfs_release_request(req);\r\nerror = nfs_wb_page(inode, page);\r\nout_err:\r\nreturn ERR_PTR(error);\r\n}\r\nstatic struct nfs_page * nfs_setup_write_request(struct nfs_open_context* ctx,\r\nstruct page *page, unsigned int offset, unsigned int bytes)\r\n{\r\nstruct inode *inode = page_file_mapping(page)->host;\r\nstruct nfs_page *req;\r\nreq = nfs_try_to_update_request(inode, page, offset, bytes);\r\nif (req != NULL)\r\ngoto out;\r\nreq = nfs_create_request(ctx, inode, page, offset, bytes);\r\nif (IS_ERR(req))\r\ngoto out;\r\nnfs_inode_add_request(inode, req);\r\nout:\r\nreturn req;\r\n}\r\nstatic int nfs_writepage_setup(struct nfs_open_context *ctx, struct page *page,\r\nunsigned int offset, unsigned int count)\r\n{\r\nstruct nfs_page *req;\r\nreq = nfs_setup_write_request(ctx, page, offset, count);\r\nif (IS_ERR(req))\r\nreturn PTR_ERR(req);\r\nnfs_grow_file(page, offset, count);\r\nnfs_mark_uptodate(page, req->wb_pgbase, req->wb_bytes);\r\nnfs_mark_request_dirty(req);\r\nnfs_unlock_and_release_request(req);\r\nreturn 0;\r\n}\r\nint nfs_flush_incompatible(struct file *file, struct page *page)\r\n{\r\nstruct nfs_open_context *ctx = nfs_file_open_context(file);\r\nstruct nfs_lock_context *l_ctx;\r\nstruct nfs_page *req;\r\nint do_flush, status;\r\ndo {\r\nreq = nfs_page_find_request(page);\r\nif (req == NULL)\r\nreturn 0;\r\nl_ctx = req->wb_lock_context;\r\ndo_flush = req->wb_page != page || req->wb_context != ctx;\r\nif (l_ctx && ctx->dentry->d_inode->i_flock != NULL) {\r\ndo_flush |= l_ctx->lockowner.l_owner != current->files\r\n|| l_ctx->lockowner.l_pid != current->tgid;\r\n}\r\nnfs_release_request(req);\r\nif (!do_flush)\r\nreturn 0;\r\nstatus = nfs_wb_page(page_file_mapping(page)->host, page);\r\n} while (status == 0);\r\nreturn status;\r\n}\r\nint\r\nnfs_key_timeout_notify(struct file *filp, struct inode *inode)\r\n{\r\nstruct nfs_open_context *ctx = nfs_file_open_context(filp);\r\nstruct rpc_auth *auth = NFS_SERVER(inode)->client->cl_auth;\r\nreturn rpcauth_key_timeout_notify(auth, ctx->cred);\r\n}\r\nbool nfs_ctx_key_to_expire(struct nfs_open_context *ctx)\r\n{\r\nreturn rpcauth_cred_key_to_expire(ctx->cred);\r\n}\r\nstatic bool nfs_write_pageuptodate(struct page *page, struct inode *inode)\r\n{\r\nstruct nfs_inode *nfsi = NFS_I(inode);\r\nif (nfs_have_delegated_attributes(inode))\r\ngoto out;\r\nif (nfsi->cache_validity & (NFS_INO_INVALID_DATA|NFS_INO_REVAL_PAGECACHE))\r\nreturn false;\r\nsmp_rmb();\r\nif (test_bit(NFS_INO_INVALIDATING, &nfsi->flags))\r\nreturn false;\r\nout:\r\nreturn PageUptodate(page) != 0;\r\n}\r\nstatic int nfs_can_extend_write(struct file *file, struct page *page, struct inode *inode)\r\n{\r\nif (file->f_flags & O_DSYNC)\r\nreturn 0;\r\nif (!nfs_write_pageuptodate(page, inode))\r\nreturn 0;\r\nif (NFS_PROTO(inode)->have_delegation(inode, FMODE_WRITE))\r\nreturn 1;\r\nif (inode->i_flock == NULL || (inode->i_flock->fl_start == 0 &&\r\ninode->i_flock->fl_end == OFFSET_MAX &&\r\ninode->i_flock->fl_type != F_RDLCK))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nint nfs_updatepage(struct file *file, struct page *page,\r\nunsigned int offset, unsigned int count)\r\n{\r\nstruct nfs_open_context *ctx = nfs_file_open_context(file);\r\nstruct inode *inode = page_file_mapping(page)->host;\r\nint status = 0;\r\nnfs_inc_stats(inode, NFSIOS_VFSUPDATEPAGE);\r\ndprintk("NFS: nfs_updatepage(%pD2 %d@%lld)\n",\r\nfile, count, (long long)(page_file_offset(page) + offset));\r\nif (nfs_can_extend_write(file, page, inode)) {\r\ncount = max(count + offset, nfs_page_length(page));\r\noffset = 0;\r\n}\r\nstatus = nfs_writepage_setup(ctx, page, offset, count);\r\nif (status < 0)\r\nnfs_set_pageerror(page);\r\nelse\r\n__set_page_dirty_nobuffers(page);\r\ndprintk("NFS: nfs_updatepage returns %d (isize %lld)\n",\r\nstatus, (long long)i_size_read(inode));\r\nreturn status;\r\n}\r\nstatic int flush_task_priority(int how)\r\n{\r\nswitch (how & (FLUSH_HIGHPRI|FLUSH_LOWPRI)) {\r\ncase FLUSH_HIGHPRI:\r\nreturn RPC_PRIORITY_HIGH;\r\ncase FLUSH_LOWPRI:\r\nreturn RPC_PRIORITY_LOW;\r\n}\r\nreturn RPC_PRIORITY_NORMAL;\r\n}\r\nint nfs_initiate_write(struct rpc_clnt *clnt,\r\nstruct nfs_write_data *data,\r\nconst struct rpc_call_ops *call_ops,\r\nint how, int flags)\r\n{\r\nstruct inode *inode = data->header->inode;\r\nint priority = flush_task_priority(how);\r\nstruct rpc_task *task;\r\nstruct rpc_message msg = {\r\n.rpc_argp = &data->args,\r\n.rpc_resp = &data->res,\r\n.rpc_cred = data->header->cred,\r\n};\r\nstruct rpc_task_setup task_setup_data = {\r\n.rpc_client = clnt,\r\n.task = &data->task,\r\n.rpc_message = &msg,\r\n.callback_ops = call_ops,\r\n.callback_data = data,\r\n.workqueue = nfsiod_workqueue,\r\n.flags = RPC_TASK_ASYNC | flags,\r\n.priority = priority,\r\n};\r\nint ret = 0;\r\nNFS_PROTO(inode)->write_setup(data, &msg);\r\ndprintk("NFS: %5u initiated write call "\r\n"(req %s/%llu, %u bytes @ offset %llu)\n",\r\ndata->task.tk_pid,\r\ninode->i_sb->s_id,\r\n(unsigned long long)NFS_FILEID(inode),\r\ndata->args.count,\r\n(unsigned long long)data->args.offset);\r\nnfs4_state_protect_write(NFS_SERVER(inode)->nfs_client,\r\n&task_setup_data.rpc_client, &msg, data);\r\ntask = rpc_run_task(&task_setup_data);\r\nif (IS_ERR(task)) {\r\nret = PTR_ERR(task);\r\ngoto out;\r\n}\r\nif (how & FLUSH_SYNC) {\r\nret = rpc_wait_for_completion_task(task);\r\nif (ret == 0)\r\nret = task->tk_status;\r\n}\r\nrpc_put_task(task);\r\nout:\r\nreturn ret;\r\n}\r\nstatic void nfs_write_rpcsetup(struct nfs_write_data *data,\r\nunsigned int count, unsigned int offset,\r\nint how, struct nfs_commit_info *cinfo)\r\n{\r\nstruct nfs_page *req = data->header->req;\r\ndata->args.fh = NFS_FH(data->header->inode);\r\ndata->args.offset = req_offset(req) + offset;\r\ndata->mds_offset = data->args.offset;\r\ndata->args.pgbase = req->wb_pgbase + offset;\r\ndata->args.pages = data->pages.pagevec;\r\ndata->args.count = count;\r\ndata->args.context = get_nfs_open_context(req->wb_context);\r\ndata->args.lock_context = req->wb_lock_context;\r\ndata->args.stable = NFS_UNSTABLE;\r\nswitch (how & (FLUSH_STABLE | FLUSH_COND_STABLE)) {\r\ncase 0:\r\nbreak;\r\ncase FLUSH_COND_STABLE:\r\nif (nfs_reqs_to_commit(cinfo))\r\nbreak;\r\ndefault:\r\ndata->args.stable = NFS_FILE_SYNC;\r\n}\r\ndata->res.fattr = &data->fattr;\r\ndata->res.count = count;\r\ndata->res.verf = &data->verf;\r\nnfs_fattr_init(&data->fattr);\r\n}\r\nstatic int nfs_do_write(struct nfs_write_data *data,\r\nconst struct rpc_call_ops *call_ops,\r\nint how)\r\n{\r\nstruct inode *inode = data->header->inode;\r\nreturn nfs_initiate_write(NFS_CLIENT(inode), data, call_ops, how, 0);\r\n}\r\nstatic int nfs_do_multiple_writes(struct list_head *head,\r\nconst struct rpc_call_ops *call_ops,\r\nint how)\r\n{\r\nstruct nfs_write_data *data;\r\nint ret = 0;\r\nwhile (!list_empty(head)) {\r\nint ret2;\r\ndata = list_first_entry(head, struct nfs_write_data, list);\r\nlist_del_init(&data->list);\r\nret2 = nfs_do_write(data, call_ops, how);\r\nif (ret == 0)\r\nret = ret2;\r\n}\r\nreturn ret;\r\n}\r\nstatic void nfs_redirty_request(struct nfs_page *req)\r\n{\r\nnfs_mark_request_dirty(req);\r\nnfs_unlock_request(req);\r\nnfs_end_page_writeback(req->wb_page);\r\nnfs_release_request(req);\r\n}\r\nstatic void nfs_async_write_error(struct list_head *head)\r\n{\r\nstruct nfs_page *req;\r\nwhile (!list_empty(head)) {\r\nreq = nfs_list_entry(head->next);\r\nnfs_list_remove_request(req);\r\nnfs_redirty_request(req);\r\n}\r\n}\r\nstatic void nfs_flush_error(struct nfs_pageio_descriptor *desc,\r\nstruct nfs_pgio_header *hdr)\r\n{\r\nset_bit(NFS_IOHDR_REDO, &hdr->flags);\r\nwhile (!list_empty(&hdr->rpc_list)) {\r\nstruct nfs_write_data *data = list_first_entry(&hdr->rpc_list,\r\nstruct nfs_write_data, list);\r\nlist_del(&data->list);\r\nnfs_writedata_release(data);\r\n}\r\ndesc->pg_completion_ops->error_cleanup(&desc->pg_list);\r\n}\r\nstatic int nfs_flush_multi(struct nfs_pageio_descriptor *desc,\r\nstruct nfs_pgio_header *hdr)\r\n{\r\nstruct nfs_page *req = hdr->req;\r\nstruct page *page = req->wb_page;\r\nstruct nfs_write_data *data;\r\nsize_t wsize = desc->pg_bsize, nbytes;\r\nunsigned int offset;\r\nint requests = 0;\r\nstruct nfs_commit_info cinfo;\r\nnfs_init_cinfo(&cinfo, desc->pg_inode, desc->pg_dreq);\r\nif ((desc->pg_ioflags & FLUSH_COND_STABLE) &&\r\n(desc->pg_moreio || nfs_reqs_to_commit(&cinfo) ||\r\ndesc->pg_count > wsize))\r\ndesc->pg_ioflags &= ~FLUSH_COND_STABLE;\r\noffset = 0;\r\nnbytes = desc->pg_count;\r\ndo {\r\nsize_t len = min(nbytes, wsize);\r\ndata = nfs_writedata_alloc(hdr, 1);\r\nif (!data) {\r\nnfs_flush_error(desc, hdr);\r\nreturn -ENOMEM;\r\n}\r\ndata->pages.pagevec[0] = page;\r\nnfs_write_rpcsetup(data, len, offset, desc->pg_ioflags, &cinfo);\r\nlist_add(&data->list, &hdr->rpc_list);\r\nrequests++;\r\nnbytes -= len;\r\noffset += len;\r\n} while (nbytes != 0);\r\nnfs_list_remove_request(req);\r\nnfs_list_add_request(req, &hdr->pages);\r\ndesc->pg_rpc_callops = &nfs_write_common_ops;\r\nreturn 0;\r\n}\r\nstatic int nfs_flush_one(struct nfs_pageio_descriptor *desc,\r\nstruct nfs_pgio_header *hdr)\r\n{\r\nstruct nfs_page *req;\r\nstruct page **pages;\r\nstruct nfs_write_data *data;\r\nstruct list_head *head = &desc->pg_list;\r\nstruct nfs_commit_info cinfo;\r\ndata = nfs_writedata_alloc(hdr, nfs_page_array_len(desc->pg_base,\r\ndesc->pg_count));\r\nif (!data) {\r\nnfs_flush_error(desc, hdr);\r\nreturn -ENOMEM;\r\n}\r\nnfs_init_cinfo(&cinfo, desc->pg_inode, desc->pg_dreq);\r\npages = data->pages.pagevec;\r\nwhile (!list_empty(head)) {\r\nreq = nfs_list_entry(head->next);\r\nnfs_list_remove_request(req);\r\nnfs_list_add_request(req, &hdr->pages);\r\n*pages++ = req->wb_page;\r\n}\r\nif ((desc->pg_ioflags & FLUSH_COND_STABLE) &&\r\n(desc->pg_moreio || nfs_reqs_to_commit(&cinfo)))\r\ndesc->pg_ioflags &= ~FLUSH_COND_STABLE;\r\nnfs_write_rpcsetup(data, desc->pg_count, 0, desc->pg_ioflags, &cinfo);\r\nlist_add(&data->list, &hdr->rpc_list);\r\ndesc->pg_rpc_callops = &nfs_write_common_ops;\r\nreturn 0;\r\n}\r\nint nfs_generic_flush(struct nfs_pageio_descriptor *desc,\r\nstruct nfs_pgio_header *hdr)\r\n{\r\nif (desc->pg_bsize < PAGE_CACHE_SIZE)\r\nreturn nfs_flush_multi(desc, hdr);\r\nreturn nfs_flush_one(desc, hdr);\r\n}\r\nstatic int nfs_generic_pg_writepages(struct nfs_pageio_descriptor *desc)\r\n{\r\nstruct nfs_write_header *whdr;\r\nstruct nfs_pgio_header *hdr;\r\nint ret;\r\nwhdr = nfs_writehdr_alloc();\r\nif (!whdr) {\r\ndesc->pg_completion_ops->error_cleanup(&desc->pg_list);\r\nreturn -ENOMEM;\r\n}\r\nhdr = &whdr->header;\r\nnfs_pgheader_init(desc, hdr, nfs_writehdr_free);\r\natomic_inc(&hdr->refcnt);\r\nret = nfs_generic_flush(desc, hdr);\r\nif (ret == 0)\r\nret = nfs_do_multiple_writes(&hdr->rpc_list,\r\ndesc->pg_rpc_callops,\r\ndesc->pg_ioflags);\r\nif (atomic_dec_and_test(&hdr->refcnt))\r\nhdr->completion_ops->completion(hdr);\r\nreturn ret;\r\n}\r\nvoid nfs_pageio_init_write(struct nfs_pageio_descriptor *pgio,\r\nstruct inode *inode, int ioflags,\r\nconst struct nfs_pgio_completion_ops *compl_ops)\r\n{\r\nnfs_pageio_init(pgio, inode, &nfs_pageio_write_ops, compl_ops,\r\nNFS_SERVER(inode)->wsize, ioflags);\r\n}\r\nvoid nfs_pageio_reset_write_mds(struct nfs_pageio_descriptor *pgio)\r\n{\r\npgio->pg_ops = &nfs_pageio_write_ops;\r\npgio->pg_bsize = NFS_SERVER(pgio->pg_inode)->wsize;\r\n}\r\nvoid nfs_write_prepare(struct rpc_task *task, void *calldata)\r\n{\r\nstruct nfs_write_data *data = calldata;\r\nint err;\r\nerr = NFS_PROTO(data->header->inode)->write_rpc_prepare(task, data);\r\nif (err)\r\nrpc_exit(task, err);\r\n}\r\nvoid nfs_commit_prepare(struct rpc_task *task, void *calldata)\r\n{\r\nstruct nfs_commit_data *data = calldata;\r\nNFS_PROTO(data->inode)->commit_rpc_prepare(task, data);\r\n}\r\nstatic void nfs_writeback_done_common(struct rpc_task *task, void *calldata)\r\n{\r\nstruct nfs_write_data *data = calldata;\r\nnfs_writeback_done(task, data);\r\n}\r\nstatic void nfs_writeback_release_common(void *calldata)\r\n{\r\nstruct nfs_write_data *data = calldata;\r\nstruct nfs_pgio_header *hdr = data->header;\r\nint status = data->task.tk_status;\r\nif ((status >= 0) && nfs_write_need_commit(data)) {\r\nspin_lock(&hdr->lock);\r\nif (test_bit(NFS_IOHDR_NEED_RESCHED, &hdr->flags))\r\n;\r\nelse if (!test_and_set_bit(NFS_IOHDR_NEED_COMMIT, &hdr->flags))\r\nmemcpy(hdr->verf, &data->verf, sizeof(*hdr->verf));\r\nelse if (memcmp(hdr->verf, &data->verf, sizeof(*hdr->verf)))\r\nset_bit(NFS_IOHDR_NEED_RESCHED, &hdr->flags);\r\nspin_unlock(&hdr->lock);\r\n}\r\nnfs_writedata_release(data);\r\n}\r\nvoid nfs_writeback_done(struct rpc_task *task, struct nfs_write_data *data)\r\n{\r\nstruct nfs_writeargs *argp = &data->args;\r\nstruct nfs_writeres *resp = &data->res;\r\nstruct inode *inode = data->header->inode;\r\nint status;\r\ndprintk("NFS: %5u nfs_writeback_done (status %d)\n",\r\ntask->tk_pid, task->tk_status);\r\nstatus = NFS_PROTO(inode)->write_done(task, data);\r\nif (status != 0)\r\nreturn;\r\nnfs_add_stats(inode, NFSIOS_SERVERWRITTENBYTES, resp->count);\r\n#if IS_ENABLED(CONFIG_NFS_V3) || IS_ENABLED(CONFIG_NFS_V4)\r\nif (resp->verf->committed < argp->stable && task->tk_status >= 0) {\r\nstatic unsigned long complain;\r\nif (time_before(complain, jiffies)) {\r\ndprintk("NFS: faulty NFS server %s:"\r\n" (committed = %d) != (stable = %d)\n",\r\nNFS_SERVER(inode)->nfs_client->cl_hostname,\r\nresp->verf->committed, argp->stable);\r\ncomplain = jiffies + 300 * HZ;\r\n}\r\n}\r\n#endif\r\nif (task->tk_status < 0)\r\nnfs_set_pgio_error(data->header, task->tk_status, argp->offset);\r\nelse if (resp->count < argp->count) {\r\nstatic unsigned long complain;\r\nnfs_inc_stats(inode, NFSIOS_SHORTWRITE);\r\nif (resp->count == 0) {\r\nif (time_before(complain, jiffies)) {\r\nprintk(KERN_WARNING\r\n"NFS: Server wrote zero bytes, expected %u.\n",\r\nargp->count);\r\ncomplain = jiffies + 300 * HZ;\r\n}\r\nnfs_set_pgio_error(data->header, -EIO, argp->offset);\r\ntask->tk_status = -EIO;\r\nreturn;\r\n}\r\nif (resp->verf->committed != NFS_UNSTABLE) {\r\ndata->mds_offset += resp->count;\r\nargp->offset += resp->count;\r\nargp->pgbase += resp->count;\r\nargp->count -= resp->count;\r\n} else {\r\nargp->stable = NFS_FILE_SYNC;\r\n}\r\nrpc_restart_call_prepare(task);\r\n}\r\n}\r\nstatic int nfs_commit_set_lock(struct nfs_inode *nfsi, int may_wait)\r\n{\r\nint ret;\r\nif (!test_and_set_bit(NFS_INO_COMMIT, &nfsi->flags))\r\nreturn 1;\r\nif (!may_wait)\r\nreturn 0;\r\nret = out_of_line_wait_on_bit_lock(&nfsi->flags,\r\nNFS_INO_COMMIT,\r\nnfs_wait_bit_killable,\r\nTASK_KILLABLE);\r\nreturn (ret < 0) ? ret : 1;\r\n}\r\nstatic void nfs_commit_clear_lock(struct nfs_inode *nfsi)\r\n{\r\nclear_bit(NFS_INO_COMMIT, &nfsi->flags);\r\nsmp_mb__after_clear_bit();\r\nwake_up_bit(&nfsi->flags, NFS_INO_COMMIT);\r\n}\r\nvoid nfs_commitdata_release(struct nfs_commit_data *data)\r\n{\r\nput_nfs_open_context(data->context);\r\nnfs_commit_free(data);\r\n}\r\nint nfs_initiate_commit(struct rpc_clnt *clnt, struct nfs_commit_data *data,\r\nconst struct rpc_call_ops *call_ops,\r\nint how, int flags)\r\n{\r\nstruct rpc_task *task;\r\nint priority = flush_task_priority(how);\r\nstruct rpc_message msg = {\r\n.rpc_argp = &data->args,\r\n.rpc_resp = &data->res,\r\n.rpc_cred = data->cred,\r\n};\r\nstruct rpc_task_setup task_setup_data = {\r\n.task = &data->task,\r\n.rpc_client = clnt,\r\n.rpc_message = &msg,\r\n.callback_ops = call_ops,\r\n.callback_data = data,\r\n.workqueue = nfsiod_workqueue,\r\n.flags = RPC_TASK_ASYNC | flags,\r\n.priority = priority,\r\n};\r\nNFS_PROTO(data->inode)->commit_setup(data, &msg);\r\ndprintk("NFS: %5u initiated commit call\n", data->task.tk_pid);\r\nnfs4_state_protect(NFS_SERVER(data->inode)->nfs_client,\r\nNFS_SP4_MACH_CRED_COMMIT, &task_setup_data.rpc_client, &msg);\r\ntask = rpc_run_task(&task_setup_data);\r\nif (IS_ERR(task))\r\nreturn PTR_ERR(task);\r\nif (how & FLUSH_SYNC)\r\nrpc_wait_for_completion_task(task);\r\nrpc_put_task(task);\r\nreturn 0;\r\n}\r\nvoid nfs_init_commit(struct nfs_commit_data *data,\r\nstruct list_head *head,\r\nstruct pnfs_layout_segment *lseg,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nstruct nfs_page *first = nfs_list_entry(head->next);\r\nstruct inode *inode = first->wb_context->dentry->d_inode;\r\nlist_splice_init(head, &data->pages);\r\ndata->inode = inode;\r\ndata->cred = first->wb_context->cred;\r\ndata->lseg = lseg;\r\ndata->mds_ops = &nfs_commit_ops;\r\ndata->completion_ops = cinfo->completion_ops;\r\ndata->dreq = cinfo->dreq;\r\ndata->args.fh = NFS_FH(data->inode);\r\ndata->args.offset = 0;\r\ndata->args.count = 0;\r\ndata->context = get_nfs_open_context(first->wb_context);\r\ndata->res.fattr = &data->fattr;\r\ndata->res.verf = &data->verf;\r\nnfs_fattr_init(&data->fattr);\r\n}\r\nvoid nfs_retry_commit(struct list_head *page_list,\r\nstruct pnfs_layout_segment *lseg,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nstruct nfs_page *req;\r\nwhile (!list_empty(page_list)) {\r\nreq = nfs_list_entry(page_list->next);\r\nnfs_list_remove_request(req);\r\nnfs_mark_request_commit(req, lseg, cinfo);\r\nif (!cinfo->dreq) {\r\ndec_zone_page_state(req->wb_page, NR_UNSTABLE_NFS);\r\ndec_bdi_stat(page_file_mapping(req->wb_page)->backing_dev_info,\r\nBDI_RECLAIMABLE);\r\n}\r\nnfs_unlock_and_release_request(req);\r\n}\r\n}\r\nstatic int\r\nnfs_commit_list(struct inode *inode, struct list_head *head, int how,\r\nstruct nfs_commit_info *cinfo)\r\n{\r\nstruct nfs_commit_data *data;\r\ndata = nfs_commitdata_alloc();\r\nif (!data)\r\ngoto out_bad;\r\nnfs_init_commit(data, head, NULL, cinfo);\r\natomic_inc(&cinfo->mds->rpcs_out);\r\nreturn nfs_initiate_commit(NFS_CLIENT(inode), data, data->mds_ops,\r\nhow, 0);\r\nout_bad:\r\nnfs_retry_commit(head, NULL, cinfo);\r\ncinfo->completion_ops->error_cleanup(NFS_I(inode));\r\nreturn -ENOMEM;\r\n}\r\nstatic void nfs_commit_done(struct rpc_task *task, void *calldata)\r\n{\r\nstruct nfs_commit_data *data = calldata;\r\ndprintk("NFS: %5u nfs_commit_done (status %d)\n",\r\ntask->tk_pid, task->tk_status);\r\nNFS_PROTO(data->inode)->commit_done(task, data);\r\n}\r\nstatic void nfs_commit_release_pages(struct nfs_commit_data *data)\r\n{\r\nstruct nfs_page *req;\r\nint status = data->task.tk_status;\r\nstruct nfs_commit_info cinfo;\r\nwhile (!list_empty(&data->pages)) {\r\nreq = nfs_list_entry(data->pages.next);\r\nnfs_list_remove_request(req);\r\nnfs_clear_page_commit(req->wb_page);\r\ndprintk("NFS: commit (%s/%llu %d@%lld)",\r\nreq->wb_context->dentry->d_sb->s_id,\r\n(unsigned long long)NFS_FILEID(req->wb_context->dentry->d_inode),\r\nreq->wb_bytes,\r\n(long long)req_offset(req));\r\nif (status < 0) {\r\nnfs_context_set_write_error(req->wb_context, status);\r\nnfs_inode_remove_request(req);\r\ndprintk(", error = %d\n", status);\r\ngoto next;\r\n}\r\nif (!memcmp(&req->wb_verf, &data->verf.verifier, sizeof(req->wb_verf))) {\r\nnfs_inode_remove_request(req);\r\ndprintk(" OK\n");\r\ngoto next;\r\n}\r\ndprintk(" mismatch\n");\r\nnfs_mark_request_dirty(req);\r\nset_bit(NFS_CONTEXT_RESEND_WRITES, &req->wb_context->flags);\r\nnext:\r\nnfs_unlock_and_release_request(req);\r\n}\r\nnfs_init_cinfo(&cinfo, data->inode, data->dreq);\r\nif (atomic_dec_and_test(&cinfo.mds->rpcs_out))\r\nnfs_commit_clear_lock(NFS_I(data->inode));\r\n}\r\nstatic void nfs_commit_release(void *calldata)\r\n{\r\nstruct nfs_commit_data *data = calldata;\r\ndata->completion_ops->completion(data);\r\nnfs_commitdata_release(calldata);\r\n}\r\nint nfs_generic_commit_list(struct inode *inode, struct list_head *head,\r\nint how, struct nfs_commit_info *cinfo)\r\n{\r\nint status;\r\nstatus = pnfs_commit_list(inode, head, how, cinfo);\r\nif (status == PNFS_NOT_ATTEMPTED)\r\nstatus = nfs_commit_list(inode, head, how, cinfo);\r\nreturn status;\r\n}\r\nint nfs_commit_inode(struct inode *inode, int how)\r\n{\r\nLIST_HEAD(head);\r\nstruct nfs_commit_info cinfo;\r\nint may_wait = how & FLUSH_SYNC;\r\nint res;\r\nres = nfs_commit_set_lock(NFS_I(inode), may_wait);\r\nif (res <= 0)\r\ngoto out_mark_dirty;\r\nnfs_init_cinfo_from_inode(&cinfo, inode);\r\nres = nfs_scan_commit(inode, &head, &cinfo);\r\nif (res) {\r\nint error;\r\nerror = nfs_generic_commit_list(inode, &head, how, &cinfo);\r\nif (error < 0)\r\nreturn error;\r\nif (!may_wait)\r\ngoto out_mark_dirty;\r\nerror = wait_on_bit(&NFS_I(inode)->flags,\r\nNFS_INO_COMMIT,\r\nnfs_wait_bit_killable,\r\nTASK_KILLABLE);\r\nif (error < 0)\r\nreturn error;\r\n} else\r\nnfs_commit_clear_lock(NFS_I(inode));\r\nreturn res;\r\nout_mark_dirty:\r\n__mark_inode_dirty(inode, I_DIRTY_DATASYNC);\r\nreturn res;\r\n}\r\nstatic int nfs_commit_unstable_pages(struct inode *inode, struct writeback_control *wbc)\r\n{\r\nstruct nfs_inode *nfsi = NFS_I(inode);\r\nint flags = FLUSH_SYNC;\r\nint ret = 0;\r\nif (!nfsi->commit_info.ncommit)\r\nreturn ret;\r\nif (wbc->sync_mode == WB_SYNC_NONE) {\r\nif (nfsi->commit_info.ncommit <= (nfsi->npages >> 1))\r\ngoto out_mark_dirty;\r\nflags = 0;\r\n}\r\nret = nfs_commit_inode(inode, flags);\r\nif (ret >= 0) {\r\nif (wbc->sync_mode == WB_SYNC_NONE) {\r\nif (ret < wbc->nr_to_write)\r\nwbc->nr_to_write -= ret;\r\nelse\r\nwbc->nr_to_write = 0;\r\n}\r\nreturn 0;\r\n}\r\nout_mark_dirty:\r\n__mark_inode_dirty(inode, I_DIRTY_DATASYNC);\r\nreturn ret;\r\n}\r\nstatic int nfs_commit_unstable_pages(struct inode *inode, struct writeback_control *wbc)\r\n{\r\nreturn 0;\r\n}\r\nint nfs_write_inode(struct inode *inode, struct writeback_control *wbc)\r\n{\r\nreturn nfs_commit_unstable_pages(inode, wbc);\r\n}\r\nint nfs_wb_all(struct inode *inode)\r\n{\r\nstruct writeback_control wbc = {\r\n.sync_mode = WB_SYNC_ALL,\r\n.nr_to_write = LONG_MAX,\r\n.range_start = 0,\r\n.range_end = LLONG_MAX,\r\n};\r\nint ret;\r\ntrace_nfs_writeback_inode_enter(inode);\r\nret = sync_inode(inode, &wbc);\r\ntrace_nfs_writeback_inode_exit(inode, ret);\r\nreturn ret;\r\n}\r\nint nfs_wb_page_cancel(struct inode *inode, struct page *page)\r\n{\r\nstruct nfs_page *req;\r\nint ret = 0;\r\nfor (;;) {\r\nwait_on_page_writeback(page);\r\nreq = nfs_page_find_request(page);\r\nif (req == NULL)\r\nbreak;\r\nif (nfs_lock_request(req)) {\r\nnfs_clear_request_commit(req);\r\nnfs_inode_remove_request(req);\r\ncancel_dirty_page(page, PAGE_CACHE_SIZE);\r\nnfs_unlock_and_release_request(req);\r\nbreak;\r\n}\r\nret = nfs_wait_on_request(req);\r\nnfs_release_request(req);\r\nif (ret < 0)\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nint nfs_wb_page(struct inode *inode, struct page *page)\r\n{\r\nloff_t range_start = page_file_offset(page);\r\nloff_t range_end = range_start + (loff_t)(PAGE_CACHE_SIZE - 1);\r\nstruct writeback_control wbc = {\r\n.sync_mode = WB_SYNC_ALL,\r\n.nr_to_write = 0,\r\n.range_start = range_start,\r\n.range_end = range_end,\r\n};\r\nint ret;\r\ntrace_nfs_writeback_page_enter(inode);\r\nfor (;;) {\r\nwait_on_page_writeback(page);\r\nif (clear_page_dirty_for_io(page)) {\r\nret = nfs_writepage_locked(page, &wbc);\r\nif (ret < 0)\r\ngoto out_error;\r\ncontinue;\r\n}\r\nret = 0;\r\nif (!PagePrivate(page))\r\nbreak;\r\nret = nfs_commit_inode(inode, FLUSH_SYNC);\r\nif (ret < 0)\r\ngoto out_error;\r\n}\r\nout_error:\r\ntrace_nfs_writeback_page_exit(inode, ret);\r\nreturn ret;\r\n}\r\nint nfs_migrate_page(struct address_space *mapping, struct page *newpage,\r\nstruct page *page, enum migrate_mode mode)\r\n{\r\nif (PagePrivate(page))\r\nreturn -EBUSY;\r\nif (!nfs_fscache_release_page(page, GFP_KERNEL))\r\nreturn -EBUSY;\r\nreturn migrate_page(mapping, newpage, page, mode);\r\n}\r\nint __init nfs_init_writepagecache(void)\r\n{\r\nnfs_wdata_cachep = kmem_cache_create("nfs_write_data",\r\nsizeof(struct nfs_write_header),\r\n0, SLAB_HWCACHE_ALIGN,\r\nNULL);\r\nif (nfs_wdata_cachep == NULL)\r\nreturn -ENOMEM;\r\nnfs_wdata_mempool = mempool_create_slab_pool(MIN_POOL_WRITE,\r\nnfs_wdata_cachep);\r\nif (nfs_wdata_mempool == NULL)\r\ngoto out_destroy_write_cache;\r\nnfs_cdata_cachep = kmem_cache_create("nfs_commit_data",\r\nsizeof(struct nfs_commit_data),\r\n0, SLAB_HWCACHE_ALIGN,\r\nNULL);\r\nif (nfs_cdata_cachep == NULL)\r\ngoto out_destroy_write_mempool;\r\nnfs_commit_mempool = mempool_create_slab_pool(MIN_POOL_COMMIT,\r\nnfs_cdata_cachep);\r\nif (nfs_commit_mempool == NULL)\r\ngoto out_destroy_commit_cache;\r\nnfs_congestion_kb = (16*int_sqrt(totalram_pages)) << (PAGE_SHIFT-10);\r\nif (nfs_congestion_kb > 256*1024)\r\nnfs_congestion_kb = 256*1024;\r\nreturn 0;\r\nout_destroy_commit_cache:\r\nkmem_cache_destroy(nfs_cdata_cachep);\r\nout_destroy_write_mempool:\r\nmempool_destroy(nfs_wdata_mempool);\r\nout_destroy_write_cache:\r\nkmem_cache_destroy(nfs_wdata_cachep);\r\nreturn -ENOMEM;\r\n}\r\nvoid nfs_destroy_writepagecache(void)\r\n{\r\nmempool_destroy(nfs_commit_mempool);\r\nkmem_cache_destroy(nfs_cdata_cachep);\r\nmempool_destroy(nfs_wdata_mempool);\r\nkmem_cache_destroy(nfs_wdata_cachep);\r\n}
