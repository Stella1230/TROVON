static inline u32 pcie_bar_low_val(u32 addr, u32 flags)\r\n{\r\nreturn (addr & PCI_BASE_ADDRESS_MEM_MASK) | flags;\r\n}\r\nstatic void __iomem *xgene_pcie_get_cfg_base(struct pci_bus *bus)\r\n{\r\nstruct xgene_pcie_port *port = bus->sysdata;\r\nif (bus->number >= (bus->primary + 1))\r\nreturn port->cfg_base + AXI_EP_CFG_ACCESS;\r\nreturn port->cfg_base;\r\n}\r\nstatic void xgene_pcie_set_rtdid_reg(struct pci_bus *bus, uint devfn)\r\n{\r\nstruct xgene_pcie_port *port = bus->sysdata;\r\nunsigned int b, d, f;\r\nu32 rtdid_val = 0;\r\nb = bus->number;\r\nd = PCI_SLOT(devfn);\r\nf = PCI_FUNC(devfn);\r\nif (!pci_is_root_bus(bus))\r\nrtdid_val = (b << 8) | (d << 3) | f;\r\nwritel(rtdid_val, port->csr_base + RTDID);\r\nreadl(port->csr_base + RTDID);\r\n}\r\nstatic bool xgene_pcie_hide_rc_bars(struct pci_bus *bus, int offset)\r\n{\r\nif (pci_is_root_bus(bus) && ((offset == PCI_BASE_ADDRESS_0) ||\r\n(offset == PCI_BASE_ADDRESS_1)))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void __iomem *xgene_pcie_map_bus(struct pci_bus *bus, unsigned int devfn,\r\nint offset)\r\n{\r\nif ((pci_is_root_bus(bus) && devfn != 0) ||\r\nxgene_pcie_hide_rc_bars(bus, offset))\r\nreturn NULL;\r\nxgene_pcie_set_rtdid_reg(bus, devfn);\r\nreturn xgene_pcie_get_cfg_base(bus) + offset;\r\n}\r\nstatic int xgene_pcie_config_read32(struct pci_bus *bus, unsigned int devfn,\r\nint where, int size, u32 *val)\r\n{\r\nstruct xgene_pcie_port *port = bus->sysdata;\r\nif (pci_generic_config_read32(bus, devfn, where & ~0x3, 4, val) !=\r\nPCIBIOS_SUCCESSFUL)\r\nreturn PCIBIOS_DEVICE_NOT_FOUND;\r\nif (pci_is_root_bus(bus) && (port->version == XGENE_PCIE_IP_VER_1) &&\r\n((where & ~0x3) == ROOT_CAP_AND_CTRL))\r\n*val &= ~(PCI_EXP_RTCAP_CRSVIS << 16);\r\nif (size <= 2)\r\n*val = (*val >> (8 * (where & 3))) & ((1 << (size * 8)) - 1);\r\nreturn PCIBIOS_SUCCESSFUL;\r\n}\r\nstatic u64 xgene_pcie_set_ib_mask(void __iomem *csr_base, u32 addr,\r\nu32 flags, u64 size)\r\n{\r\nu64 mask = (~(size - 1) & PCI_BASE_ADDRESS_MEM_MASK) | flags;\r\nu32 val32 = 0;\r\nu32 val;\r\nval32 = readl(csr_base + addr);\r\nval = (val32 & 0x0000ffff) | (lower_32_bits(mask) << 16);\r\nwritel(val, csr_base + addr);\r\nval32 = readl(csr_base + addr + 0x04);\r\nval = (val32 & 0xffff0000) | (lower_32_bits(mask) >> 16);\r\nwritel(val, csr_base + addr + 0x04);\r\nval32 = readl(csr_base + addr + 0x04);\r\nval = (val32 & 0x0000ffff) | (upper_32_bits(mask) << 16);\r\nwritel(val, csr_base + addr + 0x04);\r\nval32 = readl(csr_base + addr + 0x08);\r\nval = (val32 & 0xffff0000) | (upper_32_bits(mask) >> 16);\r\nwritel(val, csr_base + addr + 0x08);\r\nreturn mask;\r\n}\r\nstatic void xgene_pcie_linkup(struct xgene_pcie_port *port,\r\nu32 *lanes, u32 *speed)\r\n{\r\nvoid __iomem *csr_base = port->csr_base;\r\nu32 val32;\r\nport->link_up = false;\r\nval32 = readl(csr_base + PCIECORE_CTLANDSTATUS);\r\nif (val32 & LINK_UP_MASK) {\r\nport->link_up = true;\r\n*speed = PIPE_PHY_RATE_RD(val32);\r\nval32 = readl(csr_base + BRIDGE_STATUS_0);\r\n*lanes = val32 >> 26;\r\n}\r\n}\r\nstatic int xgene_pcie_init_port(struct xgene_pcie_port *port)\r\n{\r\nint rc;\r\nport->clk = clk_get(port->dev, NULL);\r\nif (IS_ERR(port->clk)) {\r\ndev_err(port->dev, "clock not available\n");\r\nreturn -ENODEV;\r\n}\r\nrc = clk_prepare_enable(port->clk);\r\nif (rc) {\r\ndev_err(port->dev, "clock enable failed\n");\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic int xgene_pcie_map_reg(struct xgene_pcie_port *port,\r\nstruct platform_device *pdev)\r\n{\r\nstruct resource *res;\r\nres = platform_get_resource_byname(pdev, IORESOURCE_MEM, "csr");\r\nport->csr_base = devm_ioremap_resource(port->dev, res);\r\nif (IS_ERR(port->csr_base))\r\nreturn PTR_ERR(port->csr_base);\r\nres = platform_get_resource_byname(pdev, IORESOURCE_MEM, "cfg");\r\nport->cfg_base = devm_ioremap_resource(port->dev, res);\r\nif (IS_ERR(port->cfg_base))\r\nreturn PTR_ERR(port->cfg_base);\r\nport->cfg_addr = res->start;\r\nreturn 0;\r\n}\r\nstatic void xgene_pcie_setup_ob_reg(struct xgene_pcie_port *port,\r\nstruct resource *res, u32 offset,\r\nu64 cpu_addr, u64 pci_addr)\r\n{\r\nvoid __iomem *base = port->csr_base + offset;\r\nresource_size_t size = resource_size(res);\r\nu64 restype = resource_type(res);\r\nu64 mask = 0;\r\nu32 min_size;\r\nu32 flag = EN_REG;\r\nif (restype == IORESOURCE_MEM) {\r\nmin_size = SZ_128M;\r\n} else {\r\nmin_size = 128;\r\nflag |= OB_LO_IO;\r\n}\r\nif (size >= min_size)\r\nmask = ~(size - 1) | flag;\r\nelse\r\ndev_warn(port->dev, "res size 0x%llx less than minimum 0x%x\n",\r\n(u64)size, min_size);\r\nwritel(lower_32_bits(cpu_addr), base);\r\nwritel(upper_32_bits(cpu_addr), base + 0x04);\r\nwritel(lower_32_bits(mask), base + 0x08);\r\nwritel(upper_32_bits(mask), base + 0x0c);\r\nwritel(lower_32_bits(pci_addr), base + 0x10);\r\nwritel(upper_32_bits(pci_addr), base + 0x14);\r\n}\r\nstatic void xgene_pcie_setup_cfg_reg(void __iomem *csr_base, u64 addr)\r\n{\r\nwritel(lower_32_bits(addr), csr_base + CFGBARL);\r\nwritel(upper_32_bits(addr), csr_base + CFGBARH);\r\nwritel(EN_REG, csr_base + CFGCTL);\r\n}\r\nstatic int xgene_pcie_map_ranges(struct xgene_pcie_port *port,\r\nstruct list_head *res,\r\nresource_size_t io_base)\r\n{\r\nstruct resource_entry *window;\r\nstruct device *dev = port->dev;\r\nint ret;\r\nresource_list_for_each_entry(window, res) {\r\nstruct resource *res = window->res;\r\nu64 restype = resource_type(res);\r\ndev_dbg(port->dev, "%pR\n", res);\r\nswitch (restype) {\r\ncase IORESOURCE_IO:\r\nxgene_pcie_setup_ob_reg(port, res, OMR3BARL, io_base,\r\nres->start - window->offset);\r\nret = pci_remap_iospace(res, io_base);\r\nif (ret < 0)\r\nreturn ret;\r\nbreak;\r\ncase IORESOURCE_MEM:\r\nif (res->flags & IORESOURCE_PREFETCH)\r\nxgene_pcie_setup_ob_reg(port, res, OMR2BARL,\r\nres->start,\r\nres->start -\r\nwindow->offset);\r\nelse\r\nxgene_pcie_setup_ob_reg(port, res, OMR1BARL,\r\nres->start,\r\nres->start -\r\nwindow->offset);\r\nbreak;\r\ncase IORESOURCE_BUS:\r\nbreak;\r\ndefault:\r\ndev_err(dev, "invalid resource %pR\n", res);\r\nreturn -EINVAL;\r\n}\r\n}\r\nxgene_pcie_setup_cfg_reg(port->csr_base, port->cfg_addr);\r\nreturn 0;\r\n}\r\nstatic void xgene_pcie_setup_pims(void *addr, u64 pim, u64 size)\r\n{\r\nwritel(lower_32_bits(pim), addr);\r\nwritel(upper_32_bits(pim) | EN_COHERENCY, addr + 0x04);\r\nwritel(lower_32_bits(size), addr + 0x10);\r\nwritel(upper_32_bits(size), addr + 0x14);\r\n}\r\nstatic int xgene_pcie_select_ib_reg(u8 *ib_reg_mask, u64 size)\r\n{\r\nif ((size > 4) && (size < SZ_16M) && !(*ib_reg_mask & (1 << 1))) {\r\n*ib_reg_mask |= (1 << 1);\r\nreturn 1;\r\n}\r\nif ((size > SZ_1K) && (size < SZ_1T) && !(*ib_reg_mask & (1 << 0))) {\r\n*ib_reg_mask |= (1 << 0);\r\nreturn 0;\r\n}\r\nif ((size > SZ_1M) && (size < SZ_1T) && !(*ib_reg_mask & (1 << 2))) {\r\n*ib_reg_mask |= (1 << 2);\r\nreturn 2;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic void xgene_pcie_setup_ib_reg(struct xgene_pcie_port *port,\r\nstruct of_pci_range *range, u8 *ib_reg_mask)\r\n{\r\nvoid __iomem *csr_base = port->csr_base;\r\nvoid __iomem *cfg_base = port->cfg_base;\r\nvoid *bar_addr;\r\nvoid *pim_addr;\r\nu64 cpu_addr = range->cpu_addr;\r\nu64 pci_addr = range->pci_addr;\r\nu64 size = range->size;\r\nu64 mask = ~(size - 1) | EN_REG;\r\nu32 flags = PCI_BASE_ADDRESS_MEM_TYPE_64;\r\nu32 bar_low;\r\nint region;\r\nregion = xgene_pcie_select_ib_reg(ib_reg_mask, range->size);\r\nif (region < 0) {\r\ndev_warn(port->dev, "invalid pcie dma-range config\n");\r\nreturn;\r\n}\r\nif (range->flags & IORESOURCE_PREFETCH)\r\nflags |= PCI_BASE_ADDRESS_MEM_PREFETCH;\r\nbar_low = pcie_bar_low_val((u32)cpu_addr, flags);\r\nswitch (region) {\r\ncase 0:\r\nxgene_pcie_set_ib_mask(csr_base, BRIDGE_CFG_4, flags, size);\r\nbar_addr = cfg_base + PCI_BASE_ADDRESS_0;\r\nwritel(bar_low, bar_addr);\r\nwritel(upper_32_bits(cpu_addr), bar_addr + 0x4);\r\npim_addr = csr_base + PIM1_1L;\r\nbreak;\r\ncase 1:\r\nbar_addr = csr_base + IBAR2;\r\nwritel(bar_low, bar_addr);\r\nwritel(lower_32_bits(mask), csr_base + IR2MSK);\r\npim_addr = csr_base + PIM2_1L;\r\nbreak;\r\ncase 2:\r\nbar_addr = csr_base + IBAR3L;\r\nwritel(bar_low, bar_addr);\r\nwritel(upper_32_bits(cpu_addr), bar_addr + 0x4);\r\nwritel(lower_32_bits(mask), csr_base + IR3MSKL);\r\nwritel(upper_32_bits(mask), csr_base + IR3MSKL + 0x4);\r\npim_addr = csr_base + PIM3_1L;\r\nbreak;\r\n}\r\nxgene_pcie_setup_pims(pim_addr, pci_addr, ~(size - 1));\r\n}\r\nstatic int pci_dma_range_parser_init(struct of_pci_range_parser *parser,\r\nstruct device_node *node)\r\n{\r\nconst int na = 3, ns = 2;\r\nint rlen;\r\nparser->node = node;\r\nparser->pna = of_n_addr_cells(node);\r\nparser->np = parser->pna + na + ns;\r\nparser->range = of_get_property(node, "dma-ranges", &rlen);\r\nif (!parser->range)\r\nreturn -ENOENT;\r\nparser->end = parser->range + rlen / sizeof(__be32);\r\nreturn 0;\r\n}\r\nstatic int xgene_pcie_parse_map_dma_ranges(struct xgene_pcie_port *port)\r\n{\r\nstruct device_node *np = port->node;\r\nstruct of_pci_range range;\r\nstruct of_pci_range_parser parser;\r\nstruct device *dev = port->dev;\r\nu8 ib_reg_mask = 0;\r\nif (pci_dma_range_parser_init(&parser, np)) {\r\ndev_err(dev, "missing dma-ranges property\n");\r\nreturn -EINVAL;\r\n}\r\nfor_each_of_pci_range(&parser, &range) {\r\nu64 end = range.cpu_addr + range.size - 1;\r\ndev_dbg(port->dev, "0x%08x 0x%016llx..0x%016llx -> 0x%016llx\n",\r\nrange.flags, range.cpu_addr, end, range.pci_addr);\r\nxgene_pcie_setup_ib_reg(port, &range, &ib_reg_mask);\r\n}\r\nreturn 0;\r\n}\r\nstatic void xgene_pcie_clear_config(struct xgene_pcie_port *port)\r\n{\r\nint i;\r\nfor (i = PIM1_1L; i <= CFGCTL; i += 4)\r\nwritel(0x0, port->csr_base + i);\r\n}\r\nstatic int xgene_pcie_setup(struct xgene_pcie_port *port,\r\nstruct list_head *res,\r\nresource_size_t io_base)\r\n{\r\nu32 val, lanes = 0, speed = 0;\r\nint ret;\r\nxgene_pcie_clear_config(port);\r\nval = (XGENE_PCIE_DEVICEID << 16) | XGENE_PCIE_VENDORID;\r\nwritel(val, port->csr_base + BRIDGE_CFG_0);\r\nret = xgene_pcie_map_ranges(port, res, io_base);\r\nif (ret)\r\nreturn ret;\r\nret = xgene_pcie_parse_map_dma_ranges(port);\r\nif (ret)\r\nreturn ret;\r\nxgene_pcie_linkup(port, &lanes, &speed);\r\nif (!port->link_up)\r\ndev_info(port->dev, "(rc) link down\n");\r\nelse\r\ndev_info(port->dev, "(rc) x%d gen-%d link up\n",\r\nlanes, speed + 1);\r\nreturn 0;\r\n}\r\nstatic int xgene_pcie_probe_bridge(struct platform_device *pdev)\r\n{\r\nstruct device_node *dn = pdev->dev.of_node;\r\nstruct xgene_pcie_port *port;\r\nresource_size_t iobase = 0;\r\nstruct pci_bus *bus;\r\nint ret;\r\nLIST_HEAD(res);\r\nport = devm_kzalloc(&pdev->dev, sizeof(*port), GFP_KERNEL);\r\nif (!port)\r\nreturn -ENOMEM;\r\nport->node = of_node_get(pdev->dev.of_node);\r\nport->dev = &pdev->dev;\r\nport->version = XGENE_PCIE_IP_VER_UNKN;\r\nif (of_device_is_compatible(port->node, "apm,xgene-pcie"))\r\nport->version = XGENE_PCIE_IP_VER_1;\r\nret = xgene_pcie_map_reg(port, pdev);\r\nif (ret)\r\nreturn ret;\r\nret = xgene_pcie_init_port(port);\r\nif (ret)\r\nreturn ret;\r\nret = of_pci_get_host_bridge_resources(dn, 0, 0xff, &res, &iobase);\r\nif (ret)\r\nreturn ret;\r\nret = xgene_pcie_setup(port, &res, iobase);\r\nif (ret)\r\nreturn ret;\r\nbus = pci_create_root_bus(&pdev->dev, 0,\r\n&xgene_pcie_ops, port, &res);\r\nif (!bus)\r\nreturn -ENOMEM;\r\npci_scan_child_bus(bus);\r\npci_assign_unassigned_bus_resources(bus);\r\npci_bus_add_devices(bus);\r\nplatform_set_drvdata(pdev, port);\r\nreturn 0;\r\n}
