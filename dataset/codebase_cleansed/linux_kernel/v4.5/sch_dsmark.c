static inline int dsmark_valid_index(struct dsmark_qdisc_data *p, u16 index)\r\n{\r\nreturn index <= p->indices && index > 0;\r\n}\r\nstatic int dsmark_graft(struct Qdisc *sch, unsigned long arg,\r\nstruct Qdisc *new, struct Qdisc **old)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\npr_debug("%s(sch %p,[qdisc %p],new %p,old %p)\n",\r\n__func__, sch, p, new, old);\r\nif (new == NULL) {\r\nnew = qdisc_create_dflt(sch->dev_queue, &pfifo_qdisc_ops,\r\nsch->handle);\r\nif (new == NULL)\r\nnew = &noop_qdisc;\r\n}\r\nsch_tree_lock(sch);\r\n*old = p->q;\r\np->q = new;\r\nqdisc_tree_decrease_qlen(*old, (*old)->q.qlen);\r\nqdisc_reset(*old);\r\nsch_tree_unlock(sch);\r\nreturn 0;\r\n}\r\nstatic struct Qdisc *dsmark_leaf(struct Qdisc *sch, unsigned long arg)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nreturn p->q;\r\n}\r\nstatic unsigned long dsmark_get(struct Qdisc *sch, u32 classid)\r\n{\r\npr_debug("%s(sch %p,[qdisc %p],classid %x)\n",\r\n__func__, sch, qdisc_priv(sch), classid);\r\nreturn TC_H_MIN(classid) + 1;\r\n}\r\nstatic unsigned long dsmark_bind_filter(struct Qdisc *sch,\r\nunsigned long parent, u32 classid)\r\n{\r\nreturn dsmark_get(sch, classid);\r\n}\r\nstatic void dsmark_put(struct Qdisc *sch, unsigned long cl)\r\n{\r\n}\r\nstatic int dsmark_change(struct Qdisc *sch, u32 classid, u32 parent,\r\nstruct nlattr **tca, unsigned long *arg)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nstruct nlattr *opt = tca[TCA_OPTIONS];\r\nstruct nlattr *tb[TCA_DSMARK_MAX + 1];\r\nint err = -EINVAL;\r\npr_debug("%s(sch %p,[qdisc %p],classid %x,parent %x), arg 0x%lx\n",\r\n__func__, sch, p, classid, parent, *arg);\r\nif (!dsmark_valid_index(p, *arg)) {\r\nerr = -ENOENT;\r\ngoto errout;\r\n}\r\nif (!opt)\r\ngoto errout;\r\nerr = nla_parse_nested(tb, TCA_DSMARK_MAX, opt, dsmark_policy);\r\nif (err < 0)\r\ngoto errout;\r\nif (tb[TCA_DSMARK_VALUE])\r\np->mv[*arg - 1].value = nla_get_u8(tb[TCA_DSMARK_VALUE]);\r\nif (tb[TCA_DSMARK_MASK])\r\np->mv[*arg - 1].mask = nla_get_u8(tb[TCA_DSMARK_MASK]);\r\nerr = 0;\r\nerrout:\r\nreturn err;\r\n}\r\nstatic int dsmark_delete(struct Qdisc *sch, unsigned long arg)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nif (!dsmark_valid_index(p, arg))\r\nreturn -EINVAL;\r\np->mv[arg - 1].mask = 0xff;\r\np->mv[arg - 1].value = 0;\r\nreturn 0;\r\n}\r\nstatic void dsmark_walk(struct Qdisc *sch, struct qdisc_walker *walker)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nint i;\r\npr_debug("%s(sch %p,[qdisc %p],walker %p)\n",\r\n__func__, sch, p, walker);\r\nif (walker->stop)\r\nreturn;\r\nfor (i = 0; i < p->indices; i++) {\r\nif (p->mv[i].mask == 0xff && !p->mv[i].value)\r\ngoto ignore;\r\nif (walker->count >= walker->skip) {\r\nif (walker->fn(sch, i + 1, walker) < 0) {\r\nwalker->stop = 1;\r\nbreak;\r\n}\r\n}\r\nignore:\r\nwalker->count++;\r\n}\r\n}\r\nstatic inline struct tcf_proto __rcu **dsmark_find_tcf(struct Qdisc *sch,\r\nunsigned long cl)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nreturn &p->filter_list;\r\n}\r\nstatic int dsmark_enqueue(struct sk_buff *skb, struct Qdisc *sch)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nint err;\r\npr_debug("%s(skb %p,sch %p,[qdisc %p])\n", __func__, skb, sch, p);\r\nif (p->set_tc_index) {\r\nswitch (tc_skb_protocol(skb)) {\r\ncase htons(ETH_P_IP):\r\nif (skb_cow_head(skb, sizeof(struct iphdr)))\r\ngoto drop;\r\nskb->tc_index = ipv4_get_dsfield(ip_hdr(skb))\r\n& ~INET_ECN_MASK;\r\nbreak;\r\ncase htons(ETH_P_IPV6):\r\nif (skb_cow_head(skb, sizeof(struct ipv6hdr)))\r\ngoto drop;\r\nskb->tc_index = ipv6_get_dsfield(ipv6_hdr(skb))\r\n& ~INET_ECN_MASK;\r\nbreak;\r\ndefault:\r\nskb->tc_index = 0;\r\nbreak;\r\n}\r\n}\r\nif (TC_H_MAJ(skb->priority) == sch->handle)\r\nskb->tc_index = TC_H_MIN(skb->priority);\r\nelse {\r\nstruct tcf_result res;\r\nstruct tcf_proto *fl = rcu_dereference_bh(p->filter_list);\r\nint result = tc_classify(skb, fl, &res, false);\r\npr_debug("result %d class 0x%04x\n", result, res.classid);\r\nswitch (result) {\r\n#ifdef CONFIG_NET_CLS_ACT\r\ncase TC_ACT_QUEUED:\r\ncase TC_ACT_STOLEN:\r\nkfree_skb(skb);\r\nreturn NET_XMIT_SUCCESS | __NET_XMIT_STOLEN;\r\ncase TC_ACT_SHOT:\r\ngoto drop;\r\n#endif\r\ncase TC_ACT_OK:\r\nskb->tc_index = TC_H_MIN(res.classid);\r\nbreak;\r\ndefault:\r\nif (p->default_index != NO_DEFAULT_INDEX)\r\nskb->tc_index = p->default_index;\r\nbreak;\r\n}\r\n}\r\nerr = qdisc_enqueue(skb, p->q);\r\nif (err != NET_XMIT_SUCCESS) {\r\nif (net_xmit_drop_count(err))\r\nqdisc_qstats_drop(sch);\r\nreturn err;\r\n}\r\nsch->q.qlen++;\r\nreturn NET_XMIT_SUCCESS;\r\ndrop:\r\nqdisc_drop(skb, sch);\r\nreturn NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\r\n}\r\nstatic struct sk_buff *dsmark_dequeue(struct Qdisc *sch)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nstruct sk_buff *skb;\r\nu32 index;\r\npr_debug("%s(sch %p,[qdisc %p])\n", __func__, sch, p);\r\nskb = p->q->ops->dequeue(p->q);\r\nif (skb == NULL)\r\nreturn NULL;\r\nqdisc_bstats_update(sch, skb);\r\nsch->q.qlen--;\r\nindex = skb->tc_index & (p->indices - 1);\r\npr_debug("index %d->%d\n", skb->tc_index, index);\r\nswitch (tc_skb_protocol(skb)) {\r\ncase htons(ETH_P_IP):\r\nipv4_change_dsfield(ip_hdr(skb), p->mv[index].mask,\r\np->mv[index].value);\r\nbreak;\r\ncase htons(ETH_P_IPV6):\r\nipv6_change_dsfield(ipv6_hdr(skb), p->mv[index].mask,\r\np->mv[index].value);\r\nbreak;\r\ndefault:\r\nif (p->mv[index].mask != 0xff || p->mv[index].value)\r\npr_warn("%s: unsupported protocol %d\n",\r\n__func__, ntohs(tc_skb_protocol(skb)));\r\nbreak;\r\n}\r\nreturn skb;\r\n}\r\nstatic struct sk_buff *dsmark_peek(struct Qdisc *sch)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\npr_debug("%s(sch %p,[qdisc %p])\n", __func__, sch, p);\r\nreturn p->q->ops->peek(p->q);\r\n}\r\nstatic unsigned int dsmark_drop(struct Qdisc *sch)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nunsigned int len;\r\npr_debug("%s(sch %p,[qdisc %p])\n", __func__, sch, p);\r\nif (p->q->ops->drop == NULL)\r\nreturn 0;\r\nlen = p->q->ops->drop(p->q);\r\nif (len)\r\nsch->q.qlen--;\r\nreturn len;\r\n}\r\nstatic int dsmark_init(struct Qdisc *sch, struct nlattr *opt)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nstruct nlattr *tb[TCA_DSMARK_MAX + 1];\r\nint err = -EINVAL;\r\nu32 default_index = NO_DEFAULT_INDEX;\r\nu16 indices;\r\nint i;\r\npr_debug("%s(sch %p,[qdisc %p],opt %p)\n", __func__, sch, p, opt);\r\nif (!opt)\r\ngoto errout;\r\nerr = nla_parse_nested(tb, TCA_DSMARK_MAX, opt, dsmark_policy);\r\nif (err < 0)\r\ngoto errout;\r\nerr = -EINVAL;\r\nindices = nla_get_u16(tb[TCA_DSMARK_INDICES]);\r\nif (hweight32(indices) != 1)\r\ngoto errout;\r\nif (tb[TCA_DSMARK_DEFAULT_INDEX])\r\ndefault_index = nla_get_u16(tb[TCA_DSMARK_DEFAULT_INDEX]);\r\nif (indices <= DSMARK_EMBEDDED_SZ)\r\np->mv = p->embedded;\r\nelse\r\np->mv = kmalloc_array(indices, sizeof(*p->mv), GFP_KERNEL);\r\nif (!p->mv) {\r\nerr = -ENOMEM;\r\ngoto errout;\r\n}\r\nfor (i = 0; i < indices; i++) {\r\np->mv[i].mask = 0xff;\r\np->mv[i].value = 0;\r\n}\r\np->indices = indices;\r\np->default_index = default_index;\r\np->set_tc_index = nla_get_flag(tb[TCA_DSMARK_SET_TC_INDEX]);\r\np->q = qdisc_create_dflt(sch->dev_queue, &pfifo_qdisc_ops, sch->handle);\r\nif (p->q == NULL)\r\np->q = &noop_qdisc;\r\npr_debug("%s: qdisc %p\n", __func__, p->q);\r\nerr = 0;\r\nerrout:\r\nreturn err;\r\n}\r\nstatic void dsmark_reset(struct Qdisc *sch)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\npr_debug("%s(sch %p,[qdisc %p])\n", __func__, sch, p);\r\nqdisc_reset(p->q);\r\nsch->q.qlen = 0;\r\n}\r\nstatic void dsmark_destroy(struct Qdisc *sch)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\npr_debug("%s(sch %p,[qdisc %p])\n", __func__, sch, p);\r\ntcf_destroy_chain(&p->filter_list);\r\nqdisc_destroy(p->q);\r\nif (p->mv != p->embedded)\r\nkfree(p->mv);\r\n}\r\nstatic int dsmark_dump_class(struct Qdisc *sch, unsigned long cl,\r\nstruct sk_buff *skb, struct tcmsg *tcm)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nstruct nlattr *opts = NULL;\r\npr_debug("%s(sch %p,[qdisc %p],class %ld\n", __func__, sch, p, cl);\r\nif (!dsmark_valid_index(p, cl))\r\nreturn -EINVAL;\r\ntcm->tcm_handle = TC_H_MAKE(TC_H_MAJ(sch->handle), cl - 1);\r\ntcm->tcm_info = p->q->handle;\r\nopts = nla_nest_start(skb, TCA_OPTIONS);\r\nif (opts == NULL)\r\ngoto nla_put_failure;\r\nif (nla_put_u8(skb, TCA_DSMARK_MASK, p->mv[cl - 1].mask) ||\r\nnla_put_u8(skb, TCA_DSMARK_VALUE, p->mv[cl - 1].value))\r\ngoto nla_put_failure;\r\nreturn nla_nest_end(skb, opts);\r\nnla_put_failure:\r\nnla_nest_cancel(skb, opts);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int dsmark_dump(struct Qdisc *sch, struct sk_buff *skb)\r\n{\r\nstruct dsmark_qdisc_data *p = qdisc_priv(sch);\r\nstruct nlattr *opts = NULL;\r\nopts = nla_nest_start(skb, TCA_OPTIONS);\r\nif (opts == NULL)\r\ngoto nla_put_failure;\r\nif (nla_put_u16(skb, TCA_DSMARK_INDICES, p->indices))\r\ngoto nla_put_failure;\r\nif (p->default_index != NO_DEFAULT_INDEX &&\r\nnla_put_u16(skb, TCA_DSMARK_DEFAULT_INDEX, p->default_index))\r\ngoto nla_put_failure;\r\nif (p->set_tc_index &&\r\nnla_put_flag(skb, TCA_DSMARK_SET_TC_INDEX))\r\ngoto nla_put_failure;\r\nreturn nla_nest_end(skb, opts);\r\nnla_put_failure:\r\nnla_nest_cancel(skb, opts);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int __init dsmark_module_init(void)\r\n{\r\nreturn register_qdisc(&dsmark_qdisc_ops);\r\n}\r\nstatic void __exit dsmark_module_exit(void)\r\n{\r\nunregister_qdisc(&dsmark_qdisc_ops);\r\n}
