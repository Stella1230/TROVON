static inline u32 rdl(struct pxa168_eth_private *pep, int offset)\r\n{\r\nreturn readl(pep->base + offset);\r\n}\r\nstatic inline void wrl(struct pxa168_eth_private *pep, int offset, u32 data)\r\n{\r\nwritel(data, pep->base + offset);\r\n}\r\nstatic void abort_dma(struct pxa168_eth_private *pep)\r\n{\r\nint delay;\r\nint max_retries = 40;\r\ndo {\r\nwrl(pep, SDMA_CMD, SDMA_CMD_AR | SDMA_CMD_AT);\r\nudelay(100);\r\ndelay = 10;\r\nwhile ((rdl(pep, SDMA_CMD) & (SDMA_CMD_AR | SDMA_CMD_AT))\r\n&& delay-- > 0) {\r\nudelay(10);\r\n}\r\n} while (max_retries-- > 0 && delay <= 0);\r\nif (max_retries <= 0)\r\nnetdev_err(pep->dev, "%s : DMA Stuck\n", __func__);\r\n}\r\nstatic void rxq_refill(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct sk_buff *skb;\r\nstruct rx_desc *p_used_rx_desc;\r\nint used_rx_desc;\r\nwhile (pep->rx_desc_count < pep->rx_ring_size) {\r\nint size;\r\nskb = netdev_alloc_skb(dev, pep->skb_size);\r\nif (!skb)\r\nbreak;\r\nif (SKB_DMA_REALIGN)\r\nskb_reserve(skb, SKB_DMA_REALIGN);\r\npep->rx_desc_count++;\r\nused_rx_desc = pep->rx_used_desc_q;\r\np_used_rx_desc = &pep->p_rx_desc_area[used_rx_desc];\r\nsize = skb_end_pointer(skb) - skb->data;\r\np_used_rx_desc->buf_ptr = dma_map_single(NULL,\r\nskb->data,\r\nsize,\r\nDMA_FROM_DEVICE);\r\np_used_rx_desc->buf_size = size;\r\npep->rx_skb[used_rx_desc] = skb;\r\nwmb();\r\np_used_rx_desc->cmd_sts = BUF_OWNED_BY_DMA | RX_EN_INT;\r\nwmb();\r\npep->rx_used_desc_q = (used_rx_desc + 1) % pep->rx_ring_size;\r\npep->rx_resource_err = 0;\r\nskb_reserve(skb, ETH_HW_IP_ALIGN);\r\n}\r\nif (pep->rx_desc_count == 0) {\r\npep->timeout.expires = jiffies + (HZ / 10);\r\nadd_timer(&pep->timeout);\r\n}\r\n}\r\nstatic inline void rxq_refill_timer_wrapper(unsigned long data)\r\n{\r\nstruct pxa168_eth_private *pep = (void *)data;\r\nnapi_schedule(&pep->napi);\r\n}\r\nstatic inline u8 flip_8_bits(u8 x)\r\n{\r\nreturn (((x) & 0x01) << 3) | (((x) & 0x02) << 1)\r\n| (((x) & 0x04) >> 1) | (((x) & 0x08) >> 3)\r\n| (((x) & 0x10) << 3) | (((x) & 0x20) << 1)\r\n| (((x) & 0x40) >> 1) | (((x) & 0x80) >> 3);\r\n}\r\nstatic void nibble_swap_every_byte(unsigned char *mac_addr)\r\n{\r\nint i;\r\nfor (i = 0; i < ETH_ALEN; i++) {\r\nmac_addr[i] = ((mac_addr[i] & 0x0f) << 4) |\r\n((mac_addr[i] & 0xf0) >> 4);\r\n}\r\n}\r\nstatic void inverse_every_nibble(unsigned char *mac_addr)\r\n{\r\nint i;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\nmac_addr[i] = flip_8_bits(mac_addr[i]);\r\n}\r\nstatic u32 hash_function(unsigned char *mac_addr_orig)\r\n{\r\nu32 hash_result;\r\nu32 addr0;\r\nu32 addr1;\r\nu32 addr2;\r\nu32 addr3;\r\nunsigned char mac_addr[ETH_ALEN];\r\nmemcpy(mac_addr, mac_addr_orig, ETH_ALEN);\r\nnibble_swap_every_byte(mac_addr);\r\ninverse_every_nibble(mac_addr);\r\naddr0 = (mac_addr[5] >> 2) & 0x3f;\r\naddr1 = (mac_addr[5] & 0x03) | (((mac_addr[4] & 0x7f)) << 2);\r\naddr2 = ((mac_addr[4] & 0x80) >> 7) | mac_addr[3] << 1;\r\naddr3 = (mac_addr[2] & 0xff) | ((mac_addr[1] & 1) << 8);\r\nhash_result = (addr0 << 9) | (addr1 ^ addr2 ^ addr3);\r\nhash_result = hash_result & 0x07ff;\r\nreturn hash_result;\r\n}\r\nstatic int add_del_hash_entry(struct pxa168_eth_private *pep,\r\nunsigned char *mac_addr,\r\nu32 rd, u32 skip, int del)\r\n{\r\nstruct addr_table_entry *entry, *start;\r\nu32 new_high;\r\nu32 new_low;\r\nu32 i;\r\nnew_low = (((mac_addr[1] >> 4) & 0xf) << 15)\r\n| (((mac_addr[1] >> 0) & 0xf) << 11)\r\n| (((mac_addr[0] >> 4) & 0xf) << 7)\r\n| (((mac_addr[0] >> 0) & 0xf) << 3)\r\n| (((mac_addr[3] >> 4) & 0x1) << 31)\r\n| (((mac_addr[3] >> 0) & 0xf) << 27)\r\n| (((mac_addr[2] >> 4) & 0xf) << 23)\r\n| (((mac_addr[2] >> 0) & 0xf) << 19)\r\n| (skip << SKIP) | (rd << HASH_ENTRY_RECEIVE_DISCARD_BIT)\r\n| HASH_ENTRY_VALID;\r\nnew_high = (((mac_addr[5] >> 4) & 0xf) << 15)\r\n| (((mac_addr[5] >> 0) & 0xf) << 11)\r\n| (((mac_addr[4] >> 4) & 0xf) << 7)\r\n| (((mac_addr[4] >> 0) & 0xf) << 3)\r\n| (((mac_addr[3] >> 5) & 0x7) << 0);\r\nstart = pep->htpr;\r\nentry = start + hash_function(mac_addr);\r\nfor (i = 0; i < HOP_NUMBER; i++) {\r\nif (!(le32_to_cpu(entry->lo) & HASH_ENTRY_VALID)) {\r\nbreak;\r\n} else {\r\nif (((le32_to_cpu(entry->lo) & 0xfffffff8) ==\r\n(new_low & 0xfffffff8)) &&\r\n(le32_to_cpu(entry->hi) == new_high)) {\r\nbreak;\r\n}\r\n}\r\nif (entry == start + 0x7ff)\r\nentry = start;\r\nelse\r\nentry++;\r\n}\r\nif (((le32_to_cpu(entry->lo) & 0xfffffff8) != (new_low & 0xfffffff8)) &&\r\n(le32_to_cpu(entry->hi) != new_high) && del)\r\nreturn 0;\r\nif (i == HOP_NUMBER) {\r\nif (!del) {\r\nnetdev_info(pep->dev,\r\n"%s: table section is full, need to "\r\n"move to 16kB implementation?\n",\r\n__FILE__);\r\nreturn -ENOSPC;\r\n} else\r\nreturn 0;\r\n}\r\nif (del) {\r\nentry->hi = 0;\r\nentry->lo = 0;\r\n} else {\r\nentry->hi = cpu_to_le32(new_high);\r\nentry->lo = cpu_to_le32(new_low);\r\n}\r\nreturn 0;\r\n}\r\nstatic void update_hash_table_mac_address(struct pxa168_eth_private *pep,\r\nunsigned char *oaddr,\r\nunsigned char *addr)\r\n{\r\nif (oaddr)\r\nadd_del_hash_entry(pep, oaddr, 1, 0, HASH_DELETE);\r\nadd_del_hash_entry(pep, addr, 1, 0, HASH_ADD);\r\n}\r\nstatic int init_hash_table(struct pxa168_eth_private *pep)\r\n{\r\nif (pep->htpr == NULL) {\r\npep->htpr = dma_zalloc_coherent(pep->dev->dev.parent,\r\nHASH_ADDR_TABLE_SIZE,\r\n&pep->htpr_dma, GFP_KERNEL);\r\nif (pep->htpr == NULL)\r\nreturn -ENOMEM;\r\n} else {\r\nmemset(pep->htpr, 0, HASH_ADDR_TABLE_SIZE);\r\n}\r\nwrl(pep, HTPR, pep->htpr_dma);\r\nreturn 0;\r\n}\r\nstatic void pxa168_eth_set_rx_mode(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct netdev_hw_addr *ha;\r\nu32 val;\r\nval = rdl(pep, PORT_CONFIG);\r\nif (dev->flags & IFF_PROMISC)\r\nval |= PCR_PM;\r\nelse\r\nval &= ~PCR_PM;\r\nwrl(pep, PORT_CONFIG, val);\r\nmemset(pep->htpr, 0, HASH_ADDR_TABLE_SIZE);\r\nupdate_hash_table_mac_address(pep, NULL, dev->dev_addr);\r\nnetdev_for_each_mc_addr(ha, dev)\r\nupdate_hash_table_mac_address(pep, NULL, ha->addr);\r\n}\r\nstatic void pxa168_eth_get_mac_address(struct net_device *dev,\r\nunsigned char *addr)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nunsigned int mac_h = rdl(pep, MAC_ADDR_HIGH);\r\nunsigned int mac_l = rdl(pep, MAC_ADDR_LOW);\r\naddr[0] = (mac_h >> 24) & 0xff;\r\naddr[1] = (mac_h >> 16) & 0xff;\r\naddr[2] = (mac_h >> 8) & 0xff;\r\naddr[3] = mac_h & 0xff;\r\naddr[4] = (mac_l >> 8) & 0xff;\r\naddr[5] = mac_l & 0xff;\r\n}\r\nstatic int pxa168_eth_set_mac_address(struct net_device *dev, void *addr)\r\n{\r\nstruct sockaddr *sa = addr;\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nunsigned char oldMac[ETH_ALEN];\r\nu32 mac_h, mac_l;\r\nif (!is_valid_ether_addr(sa->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(oldMac, dev->dev_addr, ETH_ALEN);\r\nmemcpy(dev->dev_addr, sa->sa_data, ETH_ALEN);\r\nmac_h = dev->dev_addr[0] << 24;\r\nmac_h |= dev->dev_addr[1] << 16;\r\nmac_h |= dev->dev_addr[2] << 8;\r\nmac_h |= dev->dev_addr[3];\r\nmac_l = dev->dev_addr[4] << 8;\r\nmac_l |= dev->dev_addr[5];\r\nwrl(pep, MAC_ADDR_HIGH, mac_h);\r\nwrl(pep, MAC_ADDR_LOW, mac_l);\r\nnetif_addr_lock_bh(dev);\r\nupdate_hash_table_mac_address(pep, oldMac, dev->dev_addr);\r\nnetif_addr_unlock_bh(dev);\r\nreturn 0;\r\n}\r\nstatic void eth_port_start(struct net_device *dev)\r\n{\r\nunsigned int val = 0;\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nint tx_curr_desc, rx_curr_desc;\r\nphy_start(pep->phy);\r\ntx_curr_desc = pep->tx_curr_desc_q;\r\nwrl(pep, ETH_C_TX_DESC_1,\r\n(u32) (pep->tx_desc_dma + tx_curr_desc * sizeof(struct tx_desc)));\r\nrx_curr_desc = pep->rx_curr_desc_q;\r\nwrl(pep, ETH_C_RX_DESC_0,\r\n(u32) (pep->rx_desc_dma + rx_curr_desc * sizeof(struct rx_desc)));\r\nwrl(pep, ETH_F_RX_DESC_0,\r\n(u32) (pep->rx_desc_dma + rx_curr_desc * sizeof(struct rx_desc)));\r\nwrl(pep, INT_CAUSE, 0);\r\nwrl(pep, INT_MASK, ALL_INTS);\r\nval = rdl(pep, PORT_CONFIG);\r\nval |= PCR_EN;\r\nwrl(pep, PORT_CONFIG, val);\r\nval = rdl(pep, SDMA_CMD);\r\nval |= SDMA_CMD_ERD;\r\nwrl(pep, SDMA_CMD, val);\r\n}\r\nstatic void eth_port_reset(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nunsigned int val = 0;\r\nwrl(pep, INT_MASK, 0);\r\nwrl(pep, INT_CAUSE, 0);\r\nval = rdl(pep, SDMA_CMD);\r\nval &= ~SDMA_CMD_ERD;\r\nabort_dma(pep);\r\nval = rdl(pep, PORT_CONFIG);\r\nval &= ~PCR_EN;\r\nwrl(pep, PORT_CONFIG, val);\r\nphy_stop(pep->phy);\r\n}\r\nstatic int txq_reclaim(struct net_device *dev, int force)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct tx_desc *desc;\r\nu32 cmd_sts;\r\nstruct sk_buff *skb;\r\nint tx_index;\r\ndma_addr_t addr;\r\nint count;\r\nint released = 0;\r\nnetif_tx_lock(dev);\r\npep->work_todo &= ~WORK_TX_DONE;\r\nwhile (pep->tx_desc_count > 0) {\r\ntx_index = pep->tx_used_desc_q;\r\ndesc = &pep->p_tx_desc_area[tx_index];\r\ncmd_sts = desc->cmd_sts;\r\nif (!force && (cmd_sts & BUF_OWNED_BY_DMA)) {\r\nif (released > 0) {\r\ngoto txq_reclaim_end;\r\n} else {\r\nreleased = -1;\r\ngoto txq_reclaim_end;\r\n}\r\n}\r\npep->tx_used_desc_q = (tx_index + 1) % pep->tx_ring_size;\r\npep->tx_desc_count--;\r\naddr = desc->buf_ptr;\r\ncount = desc->byte_cnt;\r\nskb = pep->tx_skb[tx_index];\r\nif (skb)\r\npep->tx_skb[tx_index] = NULL;\r\nif (cmd_sts & TX_ERROR) {\r\nif (net_ratelimit())\r\nnetdev_err(dev, "Error in TX\n");\r\ndev->stats.tx_errors++;\r\n}\r\ndma_unmap_single(NULL, addr, count, DMA_TO_DEVICE);\r\nif (skb)\r\ndev_kfree_skb_irq(skb);\r\nreleased++;\r\n}\r\ntxq_reclaim_end:\r\nnetif_tx_unlock(dev);\r\nreturn released;\r\n}\r\nstatic void pxa168_eth_tx_timeout(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nnetdev_info(dev, "TX timeout desc_count %d\n", pep->tx_desc_count);\r\nschedule_work(&pep->tx_timeout_task);\r\n}\r\nstatic void pxa168_eth_tx_timeout_task(struct work_struct *work)\r\n{\r\nstruct pxa168_eth_private *pep = container_of(work,\r\nstruct pxa168_eth_private,\r\ntx_timeout_task);\r\nstruct net_device *dev = pep->dev;\r\npxa168_eth_stop(dev);\r\npxa168_eth_open(dev);\r\n}\r\nstatic int rxq_process(struct net_device *dev, int budget)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct net_device_stats *stats = &dev->stats;\r\nunsigned int received_packets = 0;\r\nstruct sk_buff *skb;\r\nwhile (budget-- > 0) {\r\nint rx_next_curr_desc, rx_curr_desc, rx_used_desc;\r\nstruct rx_desc *rx_desc;\r\nunsigned int cmd_sts;\r\nif (pep->rx_resource_err)\r\nbreak;\r\nrx_curr_desc = pep->rx_curr_desc_q;\r\nrx_used_desc = pep->rx_used_desc_q;\r\nrx_desc = &pep->p_rx_desc_area[rx_curr_desc];\r\ncmd_sts = rx_desc->cmd_sts;\r\nrmb();\r\nif (cmd_sts & (BUF_OWNED_BY_DMA))\r\nbreak;\r\nskb = pep->rx_skb[rx_curr_desc];\r\npep->rx_skb[rx_curr_desc] = NULL;\r\nrx_next_curr_desc = (rx_curr_desc + 1) % pep->rx_ring_size;\r\npep->rx_curr_desc_q = rx_next_curr_desc;\r\nif (rx_next_curr_desc == rx_used_desc)\r\npep->rx_resource_err = 1;\r\npep->rx_desc_count--;\r\ndma_unmap_single(NULL, rx_desc->buf_ptr,\r\nrx_desc->buf_size,\r\nDMA_FROM_DEVICE);\r\nreceived_packets++;\r\nstats->rx_packets++;\r\nstats->rx_bytes += rx_desc->byte_cnt;\r\nif (((cmd_sts & (RX_FIRST_DESC | RX_LAST_DESC)) !=\r\n(RX_FIRST_DESC | RX_LAST_DESC))\r\n|| (cmd_sts & RX_ERROR)) {\r\nstats->rx_dropped++;\r\nif ((cmd_sts & (RX_FIRST_DESC | RX_LAST_DESC)) !=\r\n(RX_FIRST_DESC | RX_LAST_DESC)) {\r\nif (net_ratelimit())\r\nnetdev_err(dev,\r\n"Rx pkt on multiple desc\n");\r\n}\r\nif (cmd_sts & RX_ERROR)\r\nstats->rx_errors++;\r\ndev_kfree_skb_irq(skb);\r\n} else {\r\nskb_put(skb, rx_desc->byte_cnt - 4);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_receive_skb(skb);\r\n}\r\n}\r\nrxq_refill(dev);\r\nreturn received_packets;\r\n}\r\nstatic int pxa168_eth_collect_events(struct pxa168_eth_private *pep,\r\nstruct net_device *dev)\r\n{\r\nu32 icr;\r\nint ret = 0;\r\nicr = rdl(pep, INT_CAUSE);\r\nif (icr == 0)\r\nreturn IRQ_NONE;\r\nwrl(pep, INT_CAUSE, ~icr);\r\nif (icr & (ICR_TXBUF_H | ICR_TXBUF_L)) {\r\npep->work_todo |= WORK_TX_DONE;\r\nret = 1;\r\n}\r\nif (icr & ICR_RXBUF)\r\nret = 1;\r\nreturn ret;\r\n}\r\nstatic irqreturn_t pxa168_eth_int_handler(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *)dev_id;\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nif (unlikely(!pxa168_eth_collect_events(pep, dev)))\r\nreturn IRQ_NONE;\r\nwrl(pep, INT_MASK, 0);\r\nnapi_schedule(&pep->napi);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void pxa168_eth_recalc_skb_size(struct pxa168_eth_private *pep)\r\n{\r\nint skb_size;\r\nskb_size = pep->dev->mtu + 36;\r\npep->skb_size = (skb_size + 7) & ~7;\r\npep->skb_size += SKB_DMA_REALIGN;\r\n}\r\nstatic int set_port_config_ext(struct pxa168_eth_private *pep)\r\n{\r\nint skb_size;\r\npxa168_eth_recalc_skb_size(pep);\r\nif (pep->skb_size <= 1518)\r\nskb_size = PCXR_MFL_1518;\r\nelse if (pep->skb_size <= 1536)\r\nskb_size = PCXR_MFL_1536;\r\nelse if (pep->skb_size <= 2048)\r\nskb_size = PCXR_MFL_2048;\r\nelse\r\nskb_size = PCXR_MFL_64K;\r\nwrl(pep, PORT_CONFIG_EXT,\r\nPCXR_AN_SPEED_DIS |\r\nPCXR_AN_DUPLEX_DIS |\r\nPCXR_AN_FLOWCTL_DIS |\r\nPCXR_2BSM |\r\nPCXR_DSCP_EN |\r\nskb_size | PCXR_FLP |\r\nPCXR_TX_HIGH_PRI);\r\nreturn 0;\r\n}\r\nstatic void pxa168_eth_adjust_link(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct phy_device *phy = pep->phy;\r\nu32 cfg, cfg_o = rdl(pep, PORT_CONFIG);\r\nu32 cfgext, cfgext_o = rdl(pep, PORT_CONFIG_EXT);\r\ncfg = cfg_o & ~PCR_DUPLEX_FULL;\r\ncfgext = cfgext_o & ~(PCXR_SPEED_100 | PCXR_FLOWCTL_DIS | PCXR_RMII_EN);\r\nif (phy->interface == PHY_INTERFACE_MODE_RMII)\r\ncfgext |= PCXR_RMII_EN;\r\nif (phy->speed == SPEED_100)\r\ncfgext |= PCXR_SPEED_100;\r\nif (phy->duplex)\r\ncfg |= PCR_DUPLEX_FULL;\r\nif (!phy->pause)\r\ncfgext |= PCXR_FLOWCTL_DIS;\r\nif (cfg == cfg_o && cfgext == cfgext_o)\r\nreturn;\r\nwrl(pep, PORT_CONFIG, cfg);\r\nwrl(pep, PORT_CONFIG_EXT, cfgext);\r\nphy_print_status(phy);\r\n}\r\nstatic int pxa168_init_phy(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct ethtool_cmd cmd;\r\nint err;\r\nif (pep->phy)\r\nreturn 0;\r\npep->phy = mdiobus_scan(pep->smi_bus, pep->phy_addr);\r\nif (!pep->phy)\r\nreturn -ENODEV;\r\nerr = phy_connect_direct(dev, pep->phy, pxa168_eth_adjust_link,\r\npep->phy_intf);\r\nif (err)\r\nreturn err;\r\nerr = pxa168_get_settings(dev, &cmd);\r\nif (err)\r\nreturn err;\r\ncmd.phy_address = pep->phy_addr;\r\ncmd.speed = pep->phy_speed;\r\ncmd.duplex = pep->phy_duplex;\r\ncmd.advertising = PHY_BASIC_FEATURES;\r\ncmd.autoneg = AUTONEG_ENABLE;\r\nif (cmd.speed != 0)\r\ncmd.autoneg = AUTONEG_DISABLE;\r\nreturn pxa168_set_settings(dev, &cmd);\r\n}\r\nstatic int pxa168_init_hw(struct pxa168_eth_private *pep)\r\n{\r\nint err = 0;\r\nwrl(pep, INT_MASK, 0);\r\nwrl(pep, INT_CAUSE, 0);\r\nwrl(pep, INT_W_CLEAR, 0);\r\nabort_dma(pep);\r\nerr = init_hash_table(pep);\r\nif (err)\r\nreturn err;\r\nwrl(pep, SDMA_CONFIG, SDCR_BSZ8 |\r\nSDCR_RIFB |\r\nSDCR_BLMT |\r\nSDCR_BLMR |\r\nSDCR_RC_MAX_RETRANS);\r\nwrl(pep, PORT_CONFIG, PCR_HS);\r\nset_port_config_ext(pep);\r\nreturn err;\r\n}\r\nstatic int rxq_init(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct rx_desc *p_rx_desc;\r\nint size = 0, i = 0;\r\nint rx_desc_num = pep->rx_ring_size;\r\npep->rx_skb = kzalloc(sizeof(*pep->rx_skb) * pep->rx_ring_size,\r\nGFP_KERNEL);\r\nif (!pep->rx_skb)\r\nreturn -ENOMEM;\r\npep->rx_desc_count = 0;\r\nsize = pep->rx_ring_size * sizeof(struct rx_desc);\r\npep->rx_desc_area_size = size;\r\npep->p_rx_desc_area = dma_zalloc_coherent(pep->dev->dev.parent, size,\r\n&pep->rx_desc_dma,\r\nGFP_KERNEL);\r\nif (!pep->p_rx_desc_area)\r\ngoto out;\r\np_rx_desc = pep->p_rx_desc_area;\r\nfor (i = 0; i < rx_desc_num; i++) {\r\np_rx_desc[i].next_desc_ptr = pep->rx_desc_dma +\r\n((i + 1) % rx_desc_num) * sizeof(struct rx_desc);\r\n}\r\npep->rx_curr_desc_q = 0;\r\npep->rx_used_desc_q = 0;\r\npep->rx_desc_area_size = rx_desc_num * sizeof(struct rx_desc);\r\nreturn 0;\r\nout:\r\nkfree(pep->rx_skb);\r\nreturn -ENOMEM;\r\n}\r\nstatic void rxq_deinit(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nint curr;\r\nfor (curr = 0; pep->rx_desc_count && curr < pep->rx_ring_size; curr++) {\r\nif (pep->rx_skb[curr]) {\r\ndev_kfree_skb(pep->rx_skb[curr]);\r\npep->rx_desc_count--;\r\n}\r\n}\r\nif (pep->rx_desc_count)\r\nnetdev_err(dev, "Error in freeing Rx Ring. %d skb's still\n",\r\npep->rx_desc_count);\r\nif (pep->p_rx_desc_area)\r\ndma_free_coherent(pep->dev->dev.parent, pep->rx_desc_area_size,\r\npep->p_rx_desc_area, pep->rx_desc_dma);\r\nkfree(pep->rx_skb);\r\n}\r\nstatic int txq_init(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct tx_desc *p_tx_desc;\r\nint size = 0, i = 0;\r\nint tx_desc_num = pep->tx_ring_size;\r\npep->tx_skb = kzalloc(sizeof(*pep->tx_skb) * pep->tx_ring_size,\r\nGFP_KERNEL);\r\nif (!pep->tx_skb)\r\nreturn -ENOMEM;\r\npep->tx_desc_count = 0;\r\nsize = pep->tx_ring_size * sizeof(struct tx_desc);\r\npep->tx_desc_area_size = size;\r\npep->p_tx_desc_area = dma_zalloc_coherent(pep->dev->dev.parent, size,\r\n&pep->tx_desc_dma,\r\nGFP_KERNEL);\r\nif (!pep->p_tx_desc_area)\r\ngoto out;\r\np_tx_desc = pep->p_tx_desc_area;\r\nfor (i = 0; i < tx_desc_num; i++) {\r\np_tx_desc[i].next_desc_ptr = pep->tx_desc_dma +\r\n((i + 1) % tx_desc_num) * sizeof(struct tx_desc);\r\n}\r\npep->tx_curr_desc_q = 0;\r\npep->tx_used_desc_q = 0;\r\npep->tx_desc_area_size = tx_desc_num * sizeof(struct tx_desc);\r\nreturn 0;\r\nout:\r\nkfree(pep->tx_skb);\r\nreturn -ENOMEM;\r\n}\r\nstatic void txq_deinit(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\ntxq_reclaim(dev, 1);\r\nBUG_ON(pep->tx_used_desc_q != pep->tx_curr_desc_q);\r\nif (pep->p_tx_desc_area)\r\ndma_free_coherent(pep->dev->dev.parent, pep->tx_desc_area_size,\r\npep->p_tx_desc_area, pep->tx_desc_dma);\r\nkfree(pep->tx_skb);\r\n}\r\nstatic int pxa168_eth_open(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nint err;\r\nerr = pxa168_init_phy(dev);\r\nif (err)\r\nreturn err;\r\nerr = request_irq(dev->irq, pxa168_eth_int_handler, 0, dev->name, dev);\r\nif (err) {\r\ndev_err(&dev->dev, "can't assign irq\n");\r\nreturn -EAGAIN;\r\n}\r\npep->rx_resource_err = 0;\r\nerr = rxq_init(dev);\r\nif (err != 0)\r\ngoto out_free_irq;\r\nerr = txq_init(dev);\r\nif (err != 0)\r\ngoto out_free_rx_skb;\r\npep->rx_used_desc_q = 0;\r\npep->rx_curr_desc_q = 0;\r\nrxq_refill(dev);\r\npep->rx_used_desc_q = 0;\r\npep->rx_curr_desc_q = 0;\r\nnetif_carrier_off(dev);\r\nnapi_enable(&pep->napi);\r\neth_port_start(dev);\r\nreturn 0;\r\nout_free_rx_skb:\r\nrxq_deinit(dev);\r\nout_free_irq:\r\nfree_irq(dev->irq, dev);\r\nreturn err;\r\n}\r\nstatic int pxa168_eth_stop(struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\neth_port_reset(dev);\r\nwrl(pep, INT_MASK, 0);\r\nwrl(pep, INT_CAUSE, 0);\r\nwrl(pep, INT_W_CLEAR, 0);\r\nnapi_disable(&pep->napi);\r\ndel_timer_sync(&pep->timeout);\r\nnetif_carrier_off(dev);\r\nfree_irq(dev->irq, dev);\r\nrxq_deinit(dev);\r\ntxq_deinit(dev);\r\nreturn 0;\r\n}\r\nstatic int pxa168_eth_change_mtu(struct net_device *dev, int mtu)\r\n{\r\nint retval;\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nif ((mtu > 9500) || (mtu < 68))\r\nreturn -EINVAL;\r\ndev->mtu = mtu;\r\nretval = set_port_config_ext(pep);\r\nif (!netif_running(dev))\r\nreturn 0;\r\npxa168_eth_stop(dev);\r\nif (pxa168_eth_open(dev)) {\r\ndev_err(&dev->dev,\r\n"fatal error on re-opening device after MTU change\n");\r\n}\r\nreturn 0;\r\n}\r\nstatic int eth_alloc_tx_desc_index(struct pxa168_eth_private *pep)\r\n{\r\nint tx_desc_curr;\r\ntx_desc_curr = pep->tx_curr_desc_q;\r\npep->tx_curr_desc_q = (tx_desc_curr + 1) % pep->tx_ring_size;\r\nBUG_ON(pep->tx_curr_desc_q == pep->tx_used_desc_q);\r\npep->tx_desc_count++;\r\nreturn tx_desc_curr;\r\n}\r\nstatic int pxa168_rx_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct pxa168_eth_private *pep =\r\ncontainer_of(napi, struct pxa168_eth_private, napi);\r\nstruct net_device *dev = pep->dev;\r\nint work_done = 0;\r\ntxq_reclaim(dev, 0);\r\nif (netif_queue_stopped(dev)\r\n&& pep->tx_ring_size - pep->tx_desc_count > 1) {\r\nnetif_wake_queue(dev);\r\n}\r\nwork_done = rxq_process(dev, budget);\r\nif (work_done < budget) {\r\nnapi_complete(napi);\r\nwrl(pep, INT_MASK, ALL_INTS);\r\n}\r\nreturn work_done;\r\n}\r\nstatic int pxa168_eth_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nstruct net_device_stats *stats = &dev->stats;\r\nstruct tx_desc *desc;\r\nint tx_index;\r\nint length;\r\ntx_index = eth_alloc_tx_desc_index(pep);\r\ndesc = &pep->p_tx_desc_area[tx_index];\r\nlength = skb->len;\r\npep->tx_skb[tx_index] = skb;\r\ndesc->byte_cnt = length;\r\ndesc->buf_ptr = dma_map_single(NULL, skb->data, length, DMA_TO_DEVICE);\r\nskb_tx_timestamp(skb);\r\nwmb();\r\ndesc->cmd_sts = BUF_OWNED_BY_DMA | TX_GEN_CRC | TX_FIRST_DESC |\r\nTX_ZERO_PADDING | TX_LAST_DESC | TX_EN_INT;\r\nwmb();\r\nwrl(pep, SDMA_CMD, SDMA_CMD_TXDH | SDMA_CMD_ERD);\r\nstats->tx_bytes += length;\r\nstats->tx_packets++;\r\ndev->trans_start = jiffies;\r\nif (pep->tx_ring_size - pep->tx_desc_count <= 1) {\r\nnetif_stop_queue(dev);\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int smi_wait_ready(struct pxa168_eth_private *pep)\r\n{\r\nint i = 0;\r\nfor (i = 0; rdl(pep, SMI) & SMI_BUSY; i++) {\r\nif (i == PHY_WAIT_ITERATIONS)\r\nreturn -ETIMEDOUT;\r\nmsleep(10);\r\n}\r\nreturn 0;\r\n}\r\nstatic int pxa168_smi_read(struct mii_bus *bus, int phy_addr, int regnum)\r\n{\r\nstruct pxa168_eth_private *pep = bus->priv;\r\nint i = 0;\r\nint val;\r\nif (smi_wait_ready(pep)) {\r\nnetdev_warn(pep->dev, "pxa168_eth: SMI bus busy timeout\n");\r\nreturn -ETIMEDOUT;\r\n}\r\nwrl(pep, SMI, (phy_addr << 16) | (regnum << 21) | SMI_OP_R);\r\nfor (i = 0; !((val = rdl(pep, SMI)) & SMI_R_VALID); i++) {\r\nif (i == PHY_WAIT_ITERATIONS) {\r\nnetdev_warn(pep->dev,\r\n"pxa168_eth: SMI bus read not valid\n");\r\nreturn -ENODEV;\r\n}\r\nmsleep(10);\r\n}\r\nreturn val & 0xffff;\r\n}\r\nstatic int pxa168_smi_write(struct mii_bus *bus, int phy_addr, int regnum,\r\nu16 value)\r\n{\r\nstruct pxa168_eth_private *pep = bus->priv;\r\nif (smi_wait_ready(pep)) {\r\nnetdev_warn(pep->dev, "pxa168_eth: SMI bus busy timeout\n");\r\nreturn -ETIMEDOUT;\r\n}\r\nwrl(pep, SMI, (phy_addr << 16) | (regnum << 21) |\r\nSMI_OP_W | (value & 0xffff));\r\nif (smi_wait_ready(pep)) {\r\nnetdev_err(pep->dev, "pxa168_eth: SMI bus busy timeout\n");\r\nreturn -ETIMEDOUT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int pxa168_eth_do_ioctl(struct net_device *dev, struct ifreq *ifr,\r\nint cmd)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nif (pep->phy != NULL)\r\nreturn phy_mii_ioctl(pep->phy, ifr, cmd);\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic int pxa168_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nint err;\r\nerr = phy_read_status(pep->phy);\r\nif (err == 0)\r\nerr = phy_ethtool_gset(pep->phy, cmd);\r\nreturn err;\r\n}\r\nstatic int pxa168_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nreturn phy_ethtool_sset(pep->phy, cmd);\r\n}\r\nstatic void pxa168_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstrlcpy(info->driver, DRIVER_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRIVER_VERSION, sizeof(info->version));\r\nstrlcpy(info->fw_version, "N/A", sizeof(info->fw_version));\r\nstrlcpy(info->bus_info, "N/A", sizeof(info->bus_info));\r\n}\r\nstatic int pxa168_eth_probe(struct platform_device *pdev)\r\n{\r\nstruct pxa168_eth_private *pep = NULL;\r\nstruct net_device *dev = NULL;\r\nstruct resource *res;\r\nstruct clk *clk;\r\nstruct device_node *np;\r\nconst unsigned char *mac_addr = NULL;\r\nint err;\r\nprintk(KERN_NOTICE "PXA168 10/100 Ethernet Driver\n");\r\nclk = devm_clk_get(&pdev->dev, NULL);\r\nif (IS_ERR(clk)) {\r\ndev_err(&pdev->dev, "Fast Ethernet failed to get clock\n");\r\nreturn -ENODEV;\r\n}\r\nclk_prepare_enable(clk);\r\ndev = alloc_etherdev(sizeof(struct pxa168_eth_private));\r\nif (!dev) {\r\nerr = -ENOMEM;\r\ngoto err_clk;\r\n}\r\nplatform_set_drvdata(pdev, dev);\r\npep = netdev_priv(dev);\r\npep->dev = dev;\r\npep->clk = clk;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\npep->base = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(pep->base)) {\r\nerr = -ENOMEM;\r\ngoto err_netdev;\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\r\nBUG_ON(!res);\r\ndev->irq = res->start;\r\ndev->netdev_ops = &pxa168_eth_netdev_ops;\r\ndev->watchdog_timeo = 2 * HZ;\r\ndev->base_addr = 0;\r\ndev->ethtool_ops = &pxa168_ethtool_ops;\r\nINIT_WORK(&pep->tx_timeout_task, pxa168_eth_tx_timeout_task);\r\nif (pdev->dev.of_node)\r\nmac_addr = of_get_mac_address(pdev->dev.of_node);\r\nif (mac_addr && is_valid_ether_addr(mac_addr)) {\r\nether_addr_copy(dev->dev_addr, mac_addr);\r\n} else {\r\npxa168_eth_get_mac_address(dev, dev->dev_addr);\r\nif (!is_valid_ether_addr(dev->dev_addr)) {\r\ndev_info(&pdev->dev, "Using random mac address\n");\r\neth_hw_addr_random(dev);\r\n}\r\n}\r\npep->rx_ring_size = NUM_RX_DESCS;\r\npep->tx_ring_size = NUM_TX_DESCS;\r\npep->pd = dev_get_platdata(&pdev->dev);\r\nif (pep->pd) {\r\nif (pep->pd->rx_queue_size)\r\npep->rx_ring_size = pep->pd->rx_queue_size;\r\nif (pep->pd->tx_queue_size)\r\npep->tx_ring_size = pep->pd->tx_queue_size;\r\npep->port_num = pep->pd->port_number;\r\npep->phy_addr = pep->pd->phy_addr;\r\npep->phy_speed = pep->pd->speed;\r\npep->phy_duplex = pep->pd->duplex;\r\npep->phy_intf = pep->pd->intf;\r\nif (pep->pd->init)\r\npep->pd->init();\r\n} else if (pdev->dev.of_node) {\r\nof_property_read_u32(pdev->dev.of_node, "port-id",\r\n&pep->port_num);\r\nnp = of_parse_phandle(pdev->dev.of_node, "phy-handle", 0);\r\nif (!np) {\r\ndev_err(&pdev->dev, "missing phy-handle\n");\r\nerr = -EINVAL;\r\ngoto err_netdev;\r\n}\r\nof_property_read_u32(np, "reg", &pep->phy_addr);\r\npep->phy_intf = of_get_phy_mode(pdev->dev.of_node);\r\n}\r\nBUG_ON(pep->port_num > 2);\r\nnetif_napi_add(dev, &pep->napi, pxa168_rx_poll, pep->rx_ring_size);\r\nmemset(&pep->timeout, 0, sizeof(struct timer_list));\r\ninit_timer(&pep->timeout);\r\npep->timeout.function = rxq_refill_timer_wrapper;\r\npep->timeout.data = (unsigned long)pep;\r\npep->smi_bus = mdiobus_alloc();\r\nif (pep->smi_bus == NULL) {\r\nerr = -ENOMEM;\r\ngoto err_netdev;\r\n}\r\npep->smi_bus->priv = pep;\r\npep->smi_bus->name = "pxa168_eth smi";\r\npep->smi_bus->read = pxa168_smi_read;\r\npep->smi_bus->write = pxa168_smi_write;\r\nsnprintf(pep->smi_bus->id, MII_BUS_ID_SIZE, "%s-%d",\r\npdev->name, pdev->id);\r\npep->smi_bus->parent = &pdev->dev;\r\npep->smi_bus->phy_mask = 0xffffffff;\r\nerr = mdiobus_register(pep->smi_bus);\r\nif (err)\r\ngoto err_free_mdio;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\npxa168_init_hw(pep);\r\nerr = register_netdev(dev);\r\nif (err)\r\ngoto err_mdiobus;\r\nreturn 0;\r\nerr_mdiobus:\r\nmdiobus_unregister(pep->smi_bus);\r\nerr_free_mdio:\r\nmdiobus_free(pep->smi_bus);\r\nerr_netdev:\r\nfree_netdev(dev);\r\nerr_clk:\r\nclk_disable_unprepare(clk);\r\nreturn err;\r\n}\r\nstatic int pxa168_eth_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *dev = platform_get_drvdata(pdev);\r\nstruct pxa168_eth_private *pep = netdev_priv(dev);\r\nif (pep->htpr) {\r\ndma_free_coherent(pep->dev->dev.parent, HASH_ADDR_TABLE_SIZE,\r\npep->htpr, pep->htpr_dma);\r\npep->htpr = NULL;\r\n}\r\nif (pep->phy)\r\nphy_disconnect(pep->phy);\r\nif (pep->clk) {\r\nclk_disable_unprepare(pep->clk);\r\n}\r\nmdiobus_unregister(pep->smi_bus);\r\nmdiobus_free(pep->smi_bus);\r\nunregister_netdev(dev);\r\ncancel_work_sync(&pep->tx_timeout_task);\r\nfree_netdev(dev);\r\nreturn 0;\r\n}\r\nstatic void pxa168_eth_shutdown(struct platform_device *pdev)\r\n{\r\nstruct net_device *dev = platform_get_drvdata(pdev);\r\neth_port_reset(dev);\r\n}\r\nstatic int pxa168_eth_resume(struct platform_device *pdev)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic int pxa168_eth_suspend(struct platform_device *pdev, pm_message_t state)\r\n{\r\nreturn -ENOSYS;\r\n}
