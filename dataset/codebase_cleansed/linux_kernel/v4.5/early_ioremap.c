static int __init early_ioremap_debug_setup(char *str)\r\n{\r\nearly_ioremap_debug = 1;\r\nreturn 0;\r\n}\r\nvoid __init __weak early_ioremap_shutdown(void)\r\n{\r\n}\r\nvoid __init early_ioremap_reset(void)\r\n{\r\nearly_ioremap_shutdown();\r\nafter_paging_init = 1;\r\n}\r\nstatic inline void __init __late_set_fixmap(enum fixed_addresses idx,\r\nphys_addr_t phys, pgprot_t prot)\r\n{\r\nBUG();\r\n}\r\nstatic inline void __init __late_clear_fixmap(enum fixed_addresses idx)\r\n{\r\nBUG();\r\n}\r\nvoid __init early_ioremap_setup(void)\r\n{\r\nint i;\r\nfor (i = 0; i < FIX_BTMAPS_SLOTS; i++)\r\nif (WARN_ON(prev_map[i]))\r\nbreak;\r\nfor (i = 0; i < FIX_BTMAPS_SLOTS; i++)\r\nslot_virt[i] = __fix_to_virt(FIX_BTMAP_BEGIN - NR_FIX_BTMAPS*i);\r\n}\r\nstatic int __init check_early_ioremap_leak(void)\r\n{\r\nint count = 0;\r\nint i;\r\nfor (i = 0; i < FIX_BTMAPS_SLOTS; i++)\r\nif (prev_map[i])\r\ncount++;\r\nif (WARN(count, KERN_WARNING\r\n"Debug warning: early ioremap leak of %d areas detected.\n"\r\n"please boot with early_ioremap_debug and report the dmesg.\n",\r\ncount))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void __init __iomem *\r\n__early_ioremap(resource_size_t phys_addr, unsigned long size, pgprot_t prot)\r\n{\r\nunsigned long offset;\r\nresource_size_t last_addr;\r\nunsigned int nrpages;\r\nenum fixed_addresses idx;\r\nint i, slot;\r\nWARN_ON(system_state != SYSTEM_BOOTING);\r\nslot = -1;\r\nfor (i = 0; i < FIX_BTMAPS_SLOTS; i++) {\r\nif (!prev_map[i]) {\r\nslot = i;\r\nbreak;\r\n}\r\n}\r\nif (WARN(slot < 0, "%s(%08llx, %08lx) not found slot\n",\r\n__func__, (u64)phys_addr, size))\r\nreturn NULL;\r\nlast_addr = phys_addr + size - 1;\r\nif (WARN_ON(!size || last_addr < phys_addr))\r\nreturn NULL;\r\nprev_size[slot] = size;\r\noffset = offset_in_page(phys_addr);\r\nphys_addr &= PAGE_MASK;\r\nsize = PAGE_ALIGN(last_addr + 1) - phys_addr;\r\nnrpages = size >> PAGE_SHIFT;\r\nif (WARN_ON(nrpages > NR_FIX_BTMAPS))\r\nreturn NULL;\r\nidx = FIX_BTMAP_BEGIN - NR_FIX_BTMAPS*slot;\r\nwhile (nrpages > 0) {\r\nif (after_paging_init)\r\n__late_set_fixmap(idx, phys_addr, prot);\r\nelse\r\n__early_set_fixmap(idx, phys_addr, prot);\r\nphys_addr += PAGE_SIZE;\r\n--idx;\r\n--nrpages;\r\n}\r\nWARN(early_ioremap_debug, "%s(%08llx, %08lx) [%d] => %08lx + %08lx\n",\r\n__func__, (u64)phys_addr, size, slot, offset, slot_virt[slot]);\r\nprev_map[slot] = (void __iomem *)(offset + slot_virt[slot]);\r\nreturn prev_map[slot];\r\n}\r\nvoid __init early_iounmap(void __iomem *addr, unsigned long size)\r\n{\r\nunsigned long virt_addr;\r\nunsigned long offset;\r\nunsigned int nrpages;\r\nenum fixed_addresses idx;\r\nint i, slot;\r\nslot = -1;\r\nfor (i = 0; i < FIX_BTMAPS_SLOTS; i++) {\r\nif (prev_map[i] == addr) {\r\nslot = i;\r\nbreak;\r\n}\r\n}\r\nif (WARN(slot < 0, "early_iounmap(%p, %08lx) not found slot\n",\r\naddr, size))\r\nreturn;\r\nif (WARN(prev_size[slot] != size,\r\n"early_iounmap(%p, %08lx) [%d] size not consistent %08lx\n",\r\naddr, size, slot, prev_size[slot]))\r\nreturn;\r\nWARN(early_ioremap_debug, "early_iounmap(%p, %08lx) [%d]\n",\r\naddr, size, slot);\r\nvirt_addr = (unsigned long)addr;\r\nif (WARN_ON(virt_addr < fix_to_virt(FIX_BTMAP_BEGIN)))\r\nreturn;\r\noffset = offset_in_page(virt_addr);\r\nnrpages = PAGE_ALIGN(offset + size) >> PAGE_SHIFT;\r\nidx = FIX_BTMAP_BEGIN - NR_FIX_BTMAPS*slot;\r\nwhile (nrpages > 0) {\r\nif (after_paging_init)\r\n__late_clear_fixmap(idx);\r\nelse\r\n__early_set_fixmap(idx, 0, FIXMAP_PAGE_CLEAR);\r\n--idx;\r\n--nrpages;\r\n}\r\nprev_map[slot] = NULL;\r\n}\r\nvoid __init __iomem *\r\nearly_ioremap(resource_size_t phys_addr, unsigned long size)\r\n{\r\nreturn __early_ioremap(phys_addr, size, FIXMAP_PAGE_IO);\r\n}\r\nvoid __init *\r\nearly_memremap(resource_size_t phys_addr, unsigned long size)\r\n{\r\nreturn (__force void *)__early_ioremap(phys_addr, size,\r\nFIXMAP_PAGE_NORMAL);\r\n}\r\nvoid __init *\r\nearly_memremap_ro(resource_size_t phys_addr, unsigned long size)\r\n{\r\nreturn (__force void *)__early_ioremap(phys_addr, size, FIXMAP_PAGE_RO);\r\n}\r\nvoid __init copy_from_early_mem(void *dest, phys_addr_t src, unsigned long size)\r\n{\r\nunsigned long slop, clen;\r\nchar *p;\r\nwhile (size) {\r\nslop = offset_in_page(src);\r\nclen = size;\r\nif (clen > MAX_MAP_CHUNK - slop)\r\nclen = MAX_MAP_CHUNK - slop;\r\np = early_memremap(src & PAGE_MASK, clen + slop);\r\nmemcpy(dest, p + slop, clen);\r\nearly_memunmap(p, clen + slop);\r\ndest += clen;\r\nsrc += clen;\r\nsize -= clen;\r\n}\r\n}\r\nvoid __init __iomem *\r\nearly_ioremap(resource_size_t phys_addr, unsigned long size)\r\n{\r\nreturn (__force void __iomem *)phys_addr;\r\n}\r\nvoid __init *\r\nearly_memremap(resource_size_t phys_addr, unsigned long size)\r\n{\r\nreturn (void *)phys_addr;\r\n}\r\nvoid __init *\r\nearly_memremap_ro(resource_size_t phys_addr, unsigned long size)\r\n{\r\nreturn (void *)phys_addr;\r\n}\r\nvoid __init early_iounmap(void __iomem *addr, unsigned long size)\r\n{\r\n}\r\nvoid __init early_memunmap(void *addr, unsigned long size)\r\n{\r\nearly_iounmap((__force void __iomem *)addr, size);\r\n}
