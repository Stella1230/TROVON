static struct si_power_info *si_get_pi(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *pi = rdev->pm.dpm.priv;\r\nreturn pi;\r\n}\r\nstatic void si_calculate_leakage_for_v_and_t_formula(const struct ni_leakage_coeffients *coeff,\r\nu16 v, s32 t, u32 ileakage, u32 *leakage)\r\n{\r\ns64 kt, kv, leakage_w, i_leakage, vddc;\r\ns64 temperature, t_slope, t_intercept, av, bv, t_ref;\r\ns64 tmp;\r\ni_leakage = div64_s64(drm_int2fixp(ileakage), 100);\r\nvddc = div64_s64(drm_int2fixp(v), 1000);\r\ntemperature = div64_s64(drm_int2fixp(t), 1000);\r\nt_slope = div64_s64(drm_int2fixp(coeff->t_slope), 100000000);\r\nt_intercept = div64_s64(drm_int2fixp(coeff->t_intercept), 100000000);\r\nav = div64_s64(drm_int2fixp(coeff->av), 100000000);\r\nbv = div64_s64(drm_int2fixp(coeff->bv), 100000000);\r\nt_ref = drm_int2fixp(coeff->t_ref);\r\ntmp = drm_fixp_mul(t_slope, vddc) + t_intercept;\r\nkt = drm_fixp_exp(drm_fixp_mul(tmp, temperature));\r\nkt = drm_fixp_div(kt, drm_fixp_exp(drm_fixp_mul(tmp, t_ref)));\r\nkv = drm_fixp_mul(av, drm_fixp_exp(drm_fixp_mul(bv, vddc)));\r\nleakage_w = drm_fixp_mul(drm_fixp_mul(drm_fixp_mul(i_leakage, kt), kv), vddc);\r\n*leakage = drm_fixp2int(leakage_w * 1000);\r\n}\r\nstatic void si_calculate_leakage_for_v_and_t(struct radeon_device *rdev,\r\nconst struct ni_leakage_coeffients *coeff,\r\nu16 v,\r\ns32 t,\r\nu32 i_leakage,\r\nu32 *leakage)\r\n{\r\nsi_calculate_leakage_for_v_and_t_formula(coeff, v, t, i_leakage, leakage);\r\n}\r\nstatic void si_calculate_leakage_for_v_formula(const struct ni_leakage_coeffients *coeff,\r\nconst u32 fixed_kt, u16 v,\r\nu32 ileakage, u32 *leakage)\r\n{\r\ns64 kt, kv, leakage_w, i_leakage, vddc;\r\ni_leakage = div64_s64(drm_int2fixp(ileakage), 100);\r\nvddc = div64_s64(drm_int2fixp(v), 1000);\r\nkt = div64_s64(drm_int2fixp(fixed_kt), 100000000);\r\nkv = drm_fixp_mul(div64_s64(drm_int2fixp(coeff->av), 100000000),\r\ndrm_fixp_exp(drm_fixp_mul(div64_s64(drm_int2fixp(coeff->bv), 100000000), vddc)));\r\nleakage_w = drm_fixp_mul(drm_fixp_mul(drm_fixp_mul(i_leakage, kt), kv), vddc);\r\n*leakage = drm_fixp2int(leakage_w * 1000);\r\n}\r\nstatic void si_calculate_leakage_for_v(struct radeon_device *rdev,\r\nconst struct ni_leakage_coeffients *coeff,\r\nconst u32 fixed_kt,\r\nu16 v,\r\nu32 i_leakage,\r\nu32 *leakage)\r\n{\r\nsi_calculate_leakage_for_v_formula(coeff, fixed_kt, v, i_leakage, leakage);\r\n}\r\nstatic void si_update_dte_from_pl2(struct radeon_device *rdev,\r\nstruct si_dte_data *dte_data)\r\n{\r\nu32 p_limit1 = rdev->pm.dpm.tdp_limit;\r\nu32 p_limit2 = rdev->pm.dpm.near_tdp_limit;\r\nu32 k = dte_data->k;\r\nu32 t_max = dte_data->max_t;\r\nu32 t_split[5] = { 10, 15, 20, 25, 30 };\r\nu32 t_0 = dte_data->t0;\r\nu32 i;\r\nif (p_limit2 != 0 && p_limit2 <= p_limit1) {\r\ndte_data->tdep_count = 3;\r\nfor (i = 0; i < k; i++) {\r\ndte_data->r[i] =\r\n(t_split[i] * (t_max - t_0/(u32)1000) * (1 << 14)) /\r\n(p_limit2 * (u32)100);\r\n}\r\ndte_data->tdep_r[1] = dte_data->r[4] * 2;\r\nfor (i = 2; i < SMC_SISLANDS_DTE_MAX_TEMPERATURE_DEPENDENT_ARRAY_SIZE; i++) {\r\ndte_data->tdep_r[i] = dte_data->r[4];\r\n}\r\n} else {\r\nDRM_ERROR("Invalid PL2! DTE will not be updated.\n");\r\n}\r\n}\r\nstatic void si_initialize_powertune_defaults(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nbool update_dte_from_pl2 = false;\r\nif (rdev->family == CHIP_TAHITI) {\r\nsi_pi->cac_weights = cac_weights_tahiti;\r\nsi_pi->lcac_config = lcac_tahiti;\r\nsi_pi->cac_override = cac_override_tahiti;\r\nsi_pi->powertune_data = &powertune_data_tahiti;\r\nsi_pi->dte_data = dte_data_tahiti;\r\nswitch (rdev->pdev->device) {\r\ncase 0x6798:\r\nsi_pi->dte_data.enable_dte_by_default = true;\r\nbreak;\r\ncase 0x6799:\r\nsi_pi->dte_data = dte_data_new_zealand;\r\nbreak;\r\ncase 0x6790:\r\ncase 0x6791:\r\ncase 0x6792:\r\ncase 0x679E:\r\nsi_pi->dte_data = dte_data_aruba_pro;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ncase 0x679B:\r\nsi_pi->dte_data = dte_data_malta;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ncase 0x679A:\r\nsi_pi->dte_data = dte_data_tahiti_pro;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ndefault:\r\nif (si_pi->dte_data.enable_dte_by_default == true)\r\nDRM_ERROR("DTE is not enabled!\n");\r\nbreak;\r\n}\r\n} else if (rdev->family == CHIP_PITCAIRN) {\r\nswitch (rdev->pdev->device) {\r\ncase 0x6810:\r\ncase 0x6818:\r\nsi_pi->cac_weights = cac_weights_pitcairn;\r\nsi_pi->lcac_config = lcac_pitcairn;\r\nsi_pi->cac_override = cac_override_pitcairn;\r\nsi_pi->powertune_data = &powertune_data_pitcairn;\r\nsi_pi->dte_data = dte_data_curacao_xt;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ncase 0x6819:\r\ncase 0x6811:\r\nsi_pi->cac_weights = cac_weights_pitcairn;\r\nsi_pi->lcac_config = lcac_pitcairn;\r\nsi_pi->cac_override = cac_override_pitcairn;\r\nsi_pi->powertune_data = &powertune_data_pitcairn;\r\nsi_pi->dte_data = dte_data_curacao_pro;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ncase 0x6800:\r\ncase 0x6806:\r\nsi_pi->cac_weights = cac_weights_pitcairn;\r\nsi_pi->lcac_config = lcac_pitcairn;\r\nsi_pi->cac_override = cac_override_pitcairn;\r\nsi_pi->powertune_data = &powertune_data_pitcairn;\r\nsi_pi->dte_data = dte_data_neptune_xt;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ndefault:\r\nsi_pi->cac_weights = cac_weights_pitcairn;\r\nsi_pi->lcac_config = lcac_pitcairn;\r\nsi_pi->cac_override = cac_override_pitcairn;\r\nsi_pi->powertune_data = &powertune_data_pitcairn;\r\nsi_pi->dte_data = dte_data_pitcairn;\r\nbreak;\r\n}\r\n} else if (rdev->family == CHIP_VERDE) {\r\nsi_pi->lcac_config = lcac_cape_verde;\r\nsi_pi->cac_override = cac_override_cape_verde;\r\nsi_pi->powertune_data = &powertune_data_cape_verde;\r\nswitch (rdev->pdev->device) {\r\ncase 0x683B:\r\ncase 0x683F:\r\ncase 0x6829:\r\ncase 0x6835:\r\nsi_pi->cac_weights = cac_weights_cape_verde_pro;\r\nsi_pi->dte_data = dte_data_cape_verde;\r\nbreak;\r\ncase 0x682C:\r\nsi_pi->cac_weights = cac_weights_cape_verde_pro;\r\nsi_pi->dte_data = dte_data_sun_xt;\r\nbreak;\r\ncase 0x6825:\r\ncase 0x6827:\r\nsi_pi->cac_weights = cac_weights_heathrow;\r\nsi_pi->dte_data = dte_data_cape_verde;\r\nbreak;\r\ncase 0x6824:\r\ncase 0x682D:\r\nsi_pi->cac_weights = cac_weights_chelsea_xt;\r\nsi_pi->dte_data = dte_data_cape_verde;\r\nbreak;\r\ncase 0x682F:\r\nsi_pi->cac_weights = cac_weights_chelsea_pro;\r\nsi_pi->dte_data = dte_data_cape_verde;\r\nbreak;\r\ncase 0x6820:\r\nsi_pi->cac_weights = cac_weights_heathrow;\r\nsi_pi->dte_data = dte_data_venus_xtx;\r\nbreak;\r\ncase 0x6821:\r\nsi_pi->cac_weights = cac_weights_heathrow;\r\nsi_pi->dte_data = dte_data_venus_xt;\r\nbreak;\r\ncase 0x6823:\r\ncase 0x682B:\r\ncase 0x6822:\r\ncase 0x682A:\r\nsi_pi->cac_weights = cac_weights_chelsea_pro;\r\nsi_pi->dte_data = dte_data_venus_pro;\r\nbreak;\r\ndefault:\r\nsi_pi->cac_weights = cac_weights_cape_verde;\r\nsi_pi->dte_data = dte_data_cape_verde;\r\nbreak;\r\n}\r\n} else if (rdev->family == CHIP_OLAND) {\r\nswitch (rdev->pdev->device) {\r\ncase 0x6601:\r\ncase 0x6621:\r\ncase 0x6603:\r\ncase 0x6605:\r\nsi_pi->cac_weights = cac_weights_mars_pro;\r\nsi_pi->lcac_config = lcac_mars_pro;\r\nsi_pi->cac_override = cac_override_oland;\r\nsi_pi->powertune_data = &powertune_data_mars_pro;\r\nsi_pi->dte_data = dte_data_mars_pro;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ncase 0x6600:\r\ncase 0x6606:\r\ncase 0x6620:\r\ncase 0x6604:\r\nsi_pi->cac_weights = cac_weights_mars_xt;\r\nsi_pi->lcac_config = lcac_mars_pro;\r\nsi_pi->cac_override = cac_override_oland;\r\nsi_pi->powertune_data = &powertune_data_mars_pro;\r\nsi_pi->dte_data = dte_data_mars_pro;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ncase 0x6611:\r\ncase 0x6613:\r\ncase 0x6608:\r\nsi_pi->cac_weights = cac_weights_oland_pro;\r\nsi_pi->lcac_config = lcac_mars_pro;\r\nsi_pi->cac_override = cac_override_oland;\r\nsi_pi->powertune_data = &powertune_data_mars_pro;\r\nsi_pi->dte_data = dte_data_mars_pro;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ncase 0x6610:\r\nsi_pi->cac_weights = cac_weights_oland_xt;\r\nsi_pi->lcac_config = lcac_mars_pro;\r\nsi_pi->cac_override = cac_override_oland;\r\nsi_pi->powertune_data = &powertune_data_mars_pro;\r\nsi_pi->dte_data = dte_data_mars_pro;\r\nupdate_dte_from_pl2 = true;\r\nbreak;\r\ndefault:\r\nsi_pi->cac_weights = cac_weights_oland;\r\nsi_pi->lcac_config = lcac_oland;\r\nsi_pi->cac_override = cac_override_oland;\r\nsi_pi->powertune_data = &powertune_data_oland;\r\nsi_pi->dte_data = dte_data_oland;\r\nbreak;\r\n}\r\n} else if (rdev->family == CHIP_HAINAN) {\r\nsi_pi->cac_weights = cac_weights_hainan;\r\nsi_pi->lcac_config = lcac_oland;\r\nsi_pi->cac_override = cac_override_oland;\r\nsi_pi->powertune_data = &powertune_data_hainan;\r\nsi_pi->dte_data = dte_data_sun_xt;\r\nupdate_dte_from_pl2 = true;\r\n} else {\r\nDRM_ERROR("Unknown SI asic revision, failed to initialize PowerTune!\n");\r\nreturn;\r\n}\r\nni_pi->enable_power_containment = false;\r\nni_pi->enable_cac = false;\r\nni_pi->enable_sq_ramping = false;\r\nsi_pi->enable_dte = false;\r\nif (si_pi->powertune_data->enable_powertune_by_default) {\r\nni_pi->enable_power_containment= true;\r\nni_pi->enable_cac = true;\r\nif (si_pi->dte_data.enable_dte_by_default) {\r\nsi_pi->enable_dte = true;\r\nif (update_dte_from_pl2)\r\nsi_update_dte_from_pl2(rdev, &si_pi->dte_data);\r\n}\r\nni_pi->enable_sq_ramping = true;\r\n}\r\nni_pi->driver_calculate_cac_leakage = true;\r\nni_pi->cac_configuration_required = true;\r\nif (ni_pi->cac_configuration_required) {\r\nni_pi->support_cac_long_term_average = true;\r\nsi_pi->dyn_powertune_data.l2_lta_window_size =\r\nsi_pi->powertune_data->l2_lta_window_size_default;\r\nsi_pi->dyn_powertune_data.lts_truncate =\r\nsi_pi->powertune_data->lts_truncate_default;\r\n} else {\r\nni_pi->support_cac_long_term_average = false;\r\nsi_pi->dyn_powertune_data.l2_lta_window_size = 0;\r\nsi_pi->dyn_powertune_data.lts_truncate = 0;\r\n}\r\nsi_pi->dyn_powertune_data.disable_uvd_powertune = false;\r\n}\r\nstatic u32 si_get_smc_power_scaling_factor(struct radeon_device *rdev)\r\n{\r\nreturn 1;\r\n}\r\nstatic u32 si_calculate_cac_wintime(struct radeon_device *rdev)\r\n{\r\nu32 xclk;\r\nu32 wintime;\r\nu32 cac_window;\r\nu32 cac_window_size;\r\nxclk = radeon_get_xclk(rdev);\r\nif (xclk == 0)\r\nreturn 0;\r\ncac_window = RREG32(CG_CAC_CTRL) & CAC_WINDOW_MASK;\r\ncac_window_size = ((cac_window & 0xFFFF0000) >> 16) * (cac_window & 0x0000FFFF);\r\nwintime = (cac_window_size * 100) / xclk;\r\nreturn wintime;\r\n}\r\nstatic u32 si_scale_power_for_smc(u32 power_in_watts, u32 scaling_factor)\r\n{\r\nreturn power_in_watts;\r\n}\r\nstatic int si_calculate_adjusted_tdp_limits(struct radeon_device *rdev,\r\nbool adjust_polarity,\r\nu32 tdp_adjustment,\r\nu32 *tdp_limit,\r\nu32 *near_tdp_limit)\r\n{\r\nu32 adjustment_delta, max_tdp_limit;\r\nif (tdp_adjustment > (u32)rdev->pm.dpm.tdp_od_limit)\r\nreturn -EINVAL;\r\nmax_tdp_limit = ((100 + 100) * rdev->pm.dpm.tdp_limit) / 100;\r\nif (adjust_polarity) {\r\n*tdp_limit = ((100 + tdp_adjustment) * rdev->pm.dpm.tdp_limit) / 100;\r\n*near_tdp_limit = rdev->pm.dpm.near_tdp_limit_adjusted + (*tdp_limit - rdev->pm.dpm.tdp_limit);\r\n} else {\r\n*tdp_limit = ((100 - tdp_adjustment) * rdev->pm.dpm.tdp_limit) / 100;\r\nadjustment_delta = rdev->pm.dpm.tdp_limit - *tdp_limit;\r\nif (adjustment_delta < rdev->pm.dpm.near_tdp_limit_adjusted)\r\n*near_tdp_limit = rdev->pm.dpm.near_tdp_limit_adjusted - adjustment_delta;\r\nelse\r\n*near_tdp_limit = 0;\r\n}\r\nif ((*tdp_limit <= 0) || (*tdp_limit > max_tdp_limit))\r\nreturn -EINVAL;\r\nif ((*near_tdp_limit <= 0) || (*near_tdp_limit > *tdp_limit))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int si_populate_smc_tdp_limits(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nif (ni_pi->enable_power_containment) {\r\nSISLANDS_SMC_STATETABLE *smc_table = &si_pi->smc_statetable;\r\nPP_SIslands_PAPMParameters *papm_parm;\r\nstruct radeon_ppm_table *ppm = rdev->pm.dpm.dyn_state.ppm_table;\r\nu32 scaling_factor = si_get_smc_power_scaling_factor(rdev);\r\nu32 tdp_limit;\r\nu32 near_tdp_limit;\r\nint ret;\r\nif (scaling_factor == 0)\r\nreturn -EINVAL;\r\nmemset(smc_table, 0, sizeof(SISLANDS_SMC_STATETABLE));\r\nret = si_calculate_adjusted_tdp_limits(rdev,\r\nfalse,\r\nrdev->pm.dpm.tdp_adjustment,\r\n&tdp_limit,\r\n&near_tdp_limit);\r\nif (ret)\r\nreturn ret;\r\nsmc_table->dpm2Params.TDPLimit =\r\ncpu_to_be32(si_scale_power_for_smc(tdp_limit, scaling_factor) * 1000);\r\nsmc_table->dpm2Params.NearTDPLimit =\r\ncpu_to_be32(si_scale_power_for_smc(near_tdp_limit, scaling_factor) * 1000);\r\nsmc_table->dpm2Params.SafePowerLimit =\r\ncpu_to_be32(si_scale_power_for_smc((near_tdp_limit * SISLANDS_DPM2_TDP_SAFE_LIMIT_PERCENT) / 100, scaling_factor) * 1000);\r\nret = si_copy_bytes_to_smc(rdev,\r\n(si_pi->state_table_start + offsetof(SISLANDS_SMC_STATETABLE, dpm2Params) +\r\noffsetof(PP_SIslands_DPM2Parameters, TDPLimit)),\r\n(u8 *)(&(smc_table->dpm2Params.TDPLimit)),\r\nsizeof(u32) * 3,\r\nsi_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nif (si_pi->enable_ppm) {\r\npapm_parm = &si_pi->papm_parm;\r\nmemset(papm_parm, 0, sizeof(PP_SIslands_PAPMParameters));\r\npapm_parm->NearTDPLimitTherm = cpu_to_be32(ppm->dgpu_tdp);\r\npapm_parm->dGPU_T_Limit = cpu_to_be32(ppm->tj_max);\r\npapm_parm->dGPU_T_Warning = cpu_to_be32(95);\r\npapm_parm->dGPU_T_Hysteresis = cpu_to_be32(5);\r\npapm_parm->PlatformPowerLimit = 0xffffffff;\r\npapm_parm->NearTDPLimitPAPM = 0xffffffff;\r\nret = si_copy_bytes_to_smc(rdev, si_pi->papm_cfg_table_start,\r\n(u8 *)papm_parm,\r\nsizeof(PP_SIslands_PAPMParameters),\r\nsi_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_populate_smc_tdp_limits_2(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nif (ni_pi->enable_power_containment) {\r\nSISLANDS_SMC_STATETABLE *smc_table = &si_pi->smc_statetable;\r\nu32 scaling_factor = si_get_smc_power_scaling_factor(rdev);\r\nint ret;\r\nmemset(smc_table, 0, sizeof(SISLANDS_SMC_STATETABLE));\r\nsmc_table->dpm2Params.NearTDPLimit =\r\ncpu_to_be32(si_scale_power_for_smc(rdev->pm.dpm.near_tdp_limit_adjusted, scaling_factor) * 1000);\r\nsmc_table->dpm2Params.SafePowerLimit =\r\ncpu_to_be32(si_scale_power_for_smc((rdev->pm.dpm.near_tdp_limit_adjusted * SISLANDS_DPM2_TDP_SAFE_LIMIT_PERCENT) / 100, scaling_factor) * 1000);\r\nret = si_copy_bytes_to_smc(rdev,\r\n(si_pi->state_table_start +\r\noffsetof(SISLANDS_SMC_STATETABLE, dpm2Params) +\r\noffsetof(PP_SIslands_DPM2Parameters, NearTDPLimit)),\r\n(u8 *)(&(smc_table->dpm2Params.NearTDPLimit)),\r\nsizeof(u32) * 2,\r\nsi_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic u16 si_calculate_power_efficiency_ratio(struct radeon_device *rdev,\r\nconst u16 prev_std_vddc,\r\nconst u16 curr_std_vddc)\r\n{\r\nu64 margin = (u64)SISLANDS_DPM2_PWREFFICIENCYRATIO_MARGIN;\r\nu64 prev_vddc = (u64)prev_std_vddc;\r\nu64 curr_vddc = (u64)curr_std_vddc;\r\nu64 pwr_efficiency_ratio, n, d;\r\nif ((prev_vddc == 0) || (curr_vddc == 0))\r\nreturn 0;\r\nn = div64_u64((u64)1024 * curr_vddc * curr_vddc * ((u64)1000 + margin), (u64)1000);\r\nd = prev_vddc * prev_vddc;\r\npwr_efficiency_ratio = div64_u64(n, d);\r\nif (pwr_efficiency_ratio > (u64)0xFFFF)\r\nreturn 0;\r\nreturn (u16)pwr_efficiency_ratio;\r\n}\r\nstatic bool si_should_disable_uvd_powertune(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nif (si_pi->dyn_powertune_data.disable_uvd_powertune &&\r\nradeon_state->vclk && radeon_state->dclk)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic int si_populate_power_containment_values(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nSISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nSISLANDS_SMC_VOLTAGE_VALUE vddc;\r\nu32 prev_sclk;\r\nu32 max_sclk;\r\nu32 min_sclk;\r\nu16 prev_std_vddc;\r\nu16 curr_std_vddc;\r\nint i;\r\nu16 pwr_efficiency_ratio;\r\nu8 max_ps_percent;\r\nbool disable_uvd_power_tune;\r\nint ret;\r\nif (ni_pi->enable_power_containment == false)\r\nreturn 0;\r\nif (state->performance_level_count == 0)\r\nreturn -EINVAL;\r\nif (smc_state->levelCount != state->performance_level_count)\r\nreturn -EINVAL;\r\ndisable_uvd_power_tune = si_should_disable_uvd_powertune(rdev, radeon_state);\r\nsmc_state->levels[0].dpm2.MaxPS = 0;\r\nsmc_state->levels[0].dpm2.NearTDPDec = 0;\r\nsmc_state->levels[0].dpm2.AboveSafeInc = 0;\r\nsmc_state->levels[0].dpm2.BelowSafeInc = 0;\r\nsmc_state->levels[0].dpm2.PwrEfficiencyRatio = 0;\r\nfor (i = 1; i < state->performance_level_count; i++) {\r\nprev_sclk = state->performance_levels[i-1].sclk;\r\nmax_sclk = state->performance_levels[i].sclk;\r\nif (i == 1)\r\nmax_ps_percent = SISLANDS_DPM2_MAXPS_PERCENT_M;\r\nelse\r\nmax_ps_percent = SISLANDS_DPM2_MAXPS_PERCENT_H;\r\nif (prev_sclk > max_sclk)\r\nreturn -EINVAL;\r\nif ((max_ps_percent == 0) ||\r\n(prev_sclk == max_sclk) ||\r\ndisable_uvd_power_tune) {\r\nmin_sclk = max_sclk;\r\n} else if (i == 1) {\r\nmin_sclk = prev_sclk;\r\n} else {\r\nmin_sclk = (prev_sclk * (u32)max_ps_percent) / 100;\r\n}\r\nif (min_sclk < state->performance_levels[0].sclk)\r\nmin_sclk = state->performance_levels[0].sclk;\r\nif (min_sclk == 0)\r\nreturn -EINVAL;\r\nret = si_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\nstate->performance_levels[i-1].vddc, &vddc);\r\nif (ret)\r\nreturn ret;\r\nret = si_get_std_voltage_value(rdev, &vddc, &prev_std_vddc);\r\nif (ret)\r\nreturn ret;\r\nret = si_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\nstate->performance_levels[i].vddc, &vddc);\r\nif (ret)\r\nreturn ret;\r\nret = si_get_std_voltage_value(rdev, &vddc, &curr_std_vddc);\r\nif (ret)\r\nreturn ret;\r\npwr_efficiency_ratio = si_calculate_power_efficiency_ratio(rdev,\r\nprev_std_vddc, curr_std_vddc);\r\nsmc_state->levels[i].dpm2.MaxPS = (u8)((SISLANDS_DPM2_MAX_PULSE_SKIP * (max_sclk - min_sclk)) / max_sclk);\r\nsmc_state->levels[i].dpm2.NearTDPDec = SISLANDS_DPM2_NEAR_TDP_DEC;\r\nsmc_state->levels[i].dpm2.AboveSafeInc = SISLANDS_DPM2_ABOVE_SAFE_INC;\r\nsmc_state->levels[i].dpm2.BelowSafeInc = SISLANDS_DPM2_BELOW_SAFE_INC;\r\nsmc_state->levels[i].dpm2.PwrEfficiencyRatio = cpu_to_be16(pwr_efficiency_ratio);\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_populate_sq_ramping_values(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nSISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nu32 sq_power_throttle, sq_power_throttle2;\r\nbool enable_sq_ramping = ni_pi->enable_sq_ramping;\r\nint i;\r\nif (state->performance_level_count == 0)\r\nreturn -EINVAL;\r\nif (smc_state->levelCount != state->performance_level_count)\r\nreturn -EINVAL;\r\nif (rdev->pm.dpm.sq_ramping_threshold == 0)\r\nreturn -EINVAL;\r\nif (SISLANDS_DPM2_SQ_RAMP_MAX_POWER > (MAX_POWER_MASK >> MAX_POWER_SHIFT))\r\nenable_sq_ramping = false;\r\nif (SISLANDS_DPM2_SQ_RAMP_MIN_POWER > (MIN_POWER_MASK >> MIN_POWER_SHIFT))\r\nenable_sq_ramping = false;\r\nif (SISLANDS_DPM2_SQ_RAMP_MAX_POWER_DELTA > (MAX_POWER_DELTA_MASK >> MAX_POWER_DELTA_SHIFT))\r\nenable_sq_ramping = false;\r\nif (SISLANDS_DPM2_SQ_RAMP_STI_SIZE > (STI_SIZE_MASK >> STI_SIZE_SHIFT))\r\nenable_sq_ramping = false;\r\nif (SISLANDS_DPM2_SQ_RAMP_LTI_RATIO > (LTI_RATIO_MASK >> LTI_RATIO_SHIFT))\r\nenable_sq_ramping = false;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nsq_power_throttle = 0;\r\nsq_power_throttle2 = 0;\r\nif ((state->performance_levels[i].sclk >= rdev->pm.dpm.sq_ramping_threshold) &&\r\nenable_sq_ramping) {\r\nsq_power_throttle |= MAX_POWER(SISLANDS_DPM2_SQ_RAMP_MAX_POWER);\r\nsq_power_throttle |= MIN_POWER(SISLANDS_DPM2_SQ_RAMP_MIN_POWER);\r\nsq_power_throttle2 |= MAX_POWER_DELTA(SISLANDS_DPM2_SQ_RAMP_MAX_POWER_DELTA);\r\nsq_power_throttle2 |= STI_SIZE(SISLANDS_DPM2_SQ_RAMP_STI_SIZE);\r\nsq_power_throttle2 |= LTI_RATIO(SISLANDS_DPM2_SQ_RAMP_LTI_RATIO);\r\n} else {\r\nsq_power_throttle |= MAX_POWER_MASK | MIN_POWER_MASK;\r\nsq_power_throttle2 |= MAX_POWER_DELTA_MASK | STI_SIZE_MASK | LTI_RATIO_MASK;\r\n}\r\nsmc_state->levels[i].SQPowerThrottle = cpu_to_be32(sq_power_throttle);\r\nsmc_state->levels[i].SQPowerThrottle_2 = cpu_to_be32(sq_power_throttle2);\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_enable_power_containment(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state,\r\nbool enable)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nPPSMC_Result smc_result;\r\nint ret = 0;\r\nif (ni_pi->enable_power_containment) {\r\nif (enable) {\r\nif (!si_should_disable_uvd_powertune(rdev, radeon_new_state)) {\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_TDPClampingActive);\r\nif (smc_result != PPSMC_Result_OK) {\r\nret = -EINVAL;\r\nni_pi->pc_enabled = false;\r\n} else {\r\nni_pi->pc_enabled = true;\r\n}\r\n}\r\n} else {\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_TDPClampingInactive);\r\nif (smc_result != PPSMC_Result_OK)\r\nret = -EINVAL;\r\nni_pi->pc_enabled = false;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int si_initialize_smc_dte_tables(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nint ret = 0;\r\nstruct si_dte_data *dte_data = &si_pi->dte_data;\r\nSmc_SIslands_DTE_Configuration *dte_tables = NULL;\r\nu32 table_size;\r\nu8 tdep_count;\r\nu32 i;\r\nif (dte_data == NULL)\r\nsi_pi->enable_dte = false;\r\nif (si_pi->enable_dte == false)\r\nreturn 0;\r\nif (dte_data->k <= 0)\r\nreturn -EINVAL;\r\ndte_tables = kzalloc(sizeof(Smc_SIslands_DTE_Configuration), GFP_KERNEL);\r\nif (dte_tables == NULL) {\r\nsi_pi->enable_dte = false;\r\nreturn -ENOMEM;\r\n}\r\ntable_size = dte_data->k;\r\nif (table_size > SMC_SISLANDS_DTE_MAX_FILTER_STAGES)\r\ntable_size = SMC_SISLANDS_DTE_MAX_FILTER_STAGES;\r\ntdep_count = dte_data->tdep_count;\r\nif (tdep_count > SMC_SISLANDS_DTE_MAX_TEMPERATURE_DEPENDENT_ARRAY_SIZE)\r\ntdep_count = SMC_SISLANDS_DTE_MAX_TEMPERATURE_DEPENDENT_ARRAY_SIZE;\r\ndte_tables->K = cpu_to_be32(table_size);\r\ndte_tables->T0 = cpu_to_be32(dte_data->t0);\r\ndte_tables->MaxT = cpu_to_be32(dte_data->max_t);\r\ndte_tables->WindowSize = dte_data->window_size;\r\ndte_tables->temp_select = dte_data->temp_select;\r\ndte_tables->DTE_mode = dte_data->dte_mode;\r\ndte_tables->Tthreshold = cpu_to_be32(dte_data->t_threshold);\r\nif (tdep_count > 0)\r\ntable_size--;\r\nfor (i = 0; i < table_size; i++) {\r\ndte_tables->tau[i] = cpu_to_be32(dte_data->tau[i]);\r\ndte_tables->R[i] = cpu_to_be32(dte_data->r[i]);\r\n}\r\ndte_tables->Tdep_count = tdep_count;\r\nfor (i = 0; i < (u32)tdep_count; i++) {\r\ndte_tables->T_limits[i] = dte_data->t_limits[i];\r\ndte_tables->Tdep_tau[i] = cpu_to_be32(dte_data->tdep_tau[i]);\r\ndte_tables->Tdep_R[i] = cpu_to_be32(dte_data->tdep_r[i]);\r\n}\r\nret = si_copy_bytes_to_smc(rdev, si_pi->dte_table_start, (u8 *)dte_tables,\r\nsizeof(Smc_SIslands_DTE_Configuration), si_pi->sram_end);\r\nkfree(dte_tables);\r\nreturn ret;\r\n}\r\nstatic int si_get_cac_std_voltage_max_min(struct radeon_device *rdev,\r\nu16 *max, u16 *min)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct radeon_cac_leakage_table *table =\r\n&rdev->pm.dpm.dyn_state.cac_leakage_table;\r\nu32 i;\r\nu32 v0_loadline;\r\nif (table == NULL)\r\nreturn -EINVAL;\r\n*max = 0;\r\n*min = 0xFFFF;\r\nfor (i = 0; i < table->count; i++) {\r\nif (table->entries[i].vddc > *max)\r\n*max = table->entries[i].vddc;\r\nif (table->entries[i].vddc < *min)\r\n*min = table->entries[i].vddc;\r\n}\r\nif (si_pi->powertune_data->lkge_lut_v0_percent > 100)\r\nreturn -EINVAL;\r\nv0_loadline = (*min) * (100 - si_pi->powertune_data->lkge_lut_v0_percent) / 100;\r\nif (v0_loadline > 0xFFFFUL)\r\nreturn -EINVAL;\r\n*min = (u16)v0_loadline;\r\nif ((*min > *max) || (*max == 0) || (*min == 0))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic u16 si_get_cac_std_voltage_step(u16 max, u16 min)\r\n{\r\nreturn ((max - min) + (SMC_SISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES - 1)) /\r\nSMC_SISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES;\r\n}\r\nstatic int si_init_dte_leakage_table(struct radeon_device *rdev,\r\nPP_SIslands_CacConfig *cac_tables,\r\nu16 vddc_max, u16 vddc_min, u16 vddc_step,\r\nu16 t0, u16 t_step)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 leakage;\r\nunsigned int i, j;\r\ns32 t;\r\nu32 smc_leakage;\r\nu32 scaling_factor;\r\nu16 voltage;\r\nscaling_factor = si_get_smc_power_scaling_factor(rdev);\r\nfor (i = 0; i < SMC_SISLANDS_LKGE_LUT_NUM_OF_TEMP_ENTRIES ; i++) {\r\nt = (1000 * (i * t_step + t0));\r\nfor (j = 0; j < SMC_SISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES; j++) {\r\nvoltage = vddc_max - (vddc_step * j);\r\nsi_calculate_leakage_for_v_and_t(rdev,\r\n&si_pi->powertune_data->leakage_coefficients,\r\nvoltage,\r\nt,\r\nsi_pi->dyn_powertune_data.cac_leakage,\r\n&leakage);\r\nsmc_leakage = si_scale_power_for_smc(leakage, scaling_factor) / 4;\r\nif (smc_leakage > 0xFFFF)\r\nsmc_leakage = 0xFFFF;\r\ncac_tables->cac_lkge_lut[i][SMC_SISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES-1-j] =\r\ncpu_to_be16((u16)smc_leakage);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_init_simplified_leakage_table(struct radeon_device *rdev,\r\nPP_SIslands_CacConfig *cac_tables,\r\nu16 vddc_max, u16 vddc_min, u16 vddc_step)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 leakage;\r\nunsigned int i, j;\r\nu32 smc_leakage;\r\nu32 scaling_factor;\r\nu16 voltage;\r\nscaling_factor = si_get_smc_power_scaling_factor(rdev);\r\nfor (j = 0; j < SMC_SISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES; j++) {\r\nvoltage = vddc_max - (vddc_step * j);\r\nsi_calculate_leakage_for_v(rdev,\r\n&si_pi->powertune_data->leakage_coefficients,\r\nsi_pi->powertune_data->fixed_kt,\r\nvoltage,\r\nsi_pi->dyn_powertune_data.cac_leakage,\r\n&leakage);\r\nsmc_leakage = si_scale_power_for_smc(leakage, scaling_factor) / 4;\r\nif (smc_leakage > 0xFFFF)\r\nsmc_leakage = 0xFFFF;\r\nfor (i = 0; i < SMC_SISLANDS_LKGE_LUT_NUM_OF_TEMP_ENTRIES ; i++)\r\ncac_tables->cac_lkge_lut[i][SMC_SISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES-1-j] =\r\ncpu_to_be16((u16)smc_leakage);\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_initialize_smc_cac_tables(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nPP_SIslands_CacConfig *cac_tables = NULL;\r\nu16 vddc_max, vddc_min, vddc_step;\r\nu16 t0, t_step;\r\nu32 load_line_slope, reg;\r\nint ret = 0;\r\nu32 ticks_per_us = radeon_get_xclk(rdev) / 100;\r\nif (ni_pi->enable_cac == false)\r\nreturn 0;\r\ncac_tables = kzalloc(sizeof(PP_SIslands_CacConfig), GFP_KERNEL);\r\nif (!cac_tables)\r\nreturn -ENOMEM;\r\nreg = RREG32(CG_CAC_CTRL) & ~CAC_WINDOW_MASK;\r\nreg |= CAC_WINDOW(si_pi->powertune_data->cac_window);\r\nWREG32(CG_CAC_CTRL, reg);\r\nsi_pi->dyn_powertune_data.cac_leakage = rdev->pm.dpm.cac_leakage;\r\nsi_pi->dyn_powertune_data.dc_pwr_value =\r\nsi_pi->powertune_data->dc_cac[NISLANDS_DCCAC_LEVEL_0];\r\nsi_pi->dyn_powertune_data.wintime = si_calculate_cac_wintime(rdev);\r\nsi_pi->dyn_powertune_data.shift_n = si_pi->powertune_data->shift_n_default;\r\nsi_pi->dyn_powertune_data.leakage_minimum_temperature = 80 * 1000;\r\nret = si_get_cac_std_voltage_max_min(rdev, &vddc_max, &vddc_min);\r\nif (ret)\r\ngoto done_free;\r\nvddc_step = si_get_cac_std_voltage_step(vddc_max, vddc_min);\r\nvddc_min = vddc_max - (vddc_step * (SMC_SISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES - 1));\r\nt_step = 4;\r\nt0 = 60;\r\nif (si_pi->enable_dte || ni_pi->driver_calculate_cac_leakage)\r\nret = si_init_dte_leakage_table(rdev, cac_tables,\r\nvddc_max, vddc_min, vddc_step,\r\nt0, t_step);\r\nelse\r\nret = si_init_simplified_leakage_table(rdev, cac_tables,\r\nvddc_max, vddc_min, vddc_step);\r\nif (ret)\r\ngoto done_free;\r\nload_line_slope = ((u32)rdev->pm.dpm.load_line_slope << SMC_SISLANDS_SCALE_R) / 100;\r\ncac_tables->l2numWin_TDP = cpu_to_be32(si_pi->dyn_powertune_data.l2_lta_window_size);\r\ncac_tables->lts_truncate_n = si_pi->dyn_powertune_data.lts_truncate;\r\ncac_tables->SHIFT_N = si_pi->dyn_powertune_data.shift_n;\r\ncac_tables->lkge_lut_V0 = cpu_to_be32((u32)vddc_min);\r\ncac_tables->lkge_lut_Vstep = cpu_to_be32((u32)vddc_step);\r\ncac_tables->R_LL = cpu_to_be32(load_line_slope);\r\ncac_tables->WinTime = cpu_to_be32(si_pi->dyn_powertune_data.wintime);\r\ncac_tables->calculation_repeats = cpu_to_be32(2);\r\ncac_tables->dc_cac = cpu_to_be32(0);\r\ncac_tables->log2_PG_LKG_SCALE = 12;\r\ncac_tables->cac_temp = si_pi->powertune_data->operating_temp;\r\ncac_tables->lkge_lut_T0 = cpu_to_be32((u32)t0);\r\ncac_tables->lkge_lut_Tstep = cpu_to_be32((u32)t_step);\r\nret = si_copy_bytes_to_smc(rdev, si_pi->cac_table_start, (u8 *)cac_tables,\r\nsizeof(PP_SIslands_CacConfig), si_pi->sram_end);\r\nif (ret)\r\ngoto done_free;\r\nret = si_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_ticks_per_us, ticks_per_us);\r\ndone_free:\r\nif (ret) {\r\nni_pi->enable_cac = false;\r\nni_pi->enable_power_containment = false;\r\n}\r\nkfree(cac_tables);\r\nreturn 0;\r\n}\r\nstatic int si_program_cac_config_registers(struct radeon_device *rdev,\r\nconst struct si_cac_config_reg *cac_config_regs)\r\n{\r\nconst struct si_cac_config_reg *config_regs = cac_config_regs;\r\nu32 data = 0, offset;\r\nif (!config_regs)\r\nreturn -EINVAL;\r\nwhile (config_regs->offset != 0xFFFFFFFF) {\r\nswitch (config_regs->type) {\r\ncase SISLANDS_CACCONFIG_CGIND:\r\noffset = SMC_CG_IND_START + config_regs->offset;\r\nif (offset < SMC_CG_IND_END)\r\ndata = RREG32_SMC(offset);\r\nbreak;\r\ndefault:\r\ndata = RREG32(config_regs->offset << 2);\r\nbreak;\r\n}\r\ndata &= ~config_regs->mask;\r\ndata |= ((config_regs->value << config_regs->shift) & config_regs->mask);\r\nswitch (config_regs->type) {\r\ncase SISLANDS_CACCONFIG_CGIND:\r\noffset = SMC_CG_IND_START + config_regs->offset;\r\nif (offset < SMC_CG_IND_END)\r\nWREG32_SMC(offset, data);\r\nbreak;\r\ndefault:\r\nWREG32(config_regs->offset << 2, data);\r\nbreak;\r\n}\r\nconfig_regs++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_initialize_hardware_cac_manager(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nint ret;\r\nif ((ni_pi->enable_cac == false) ||\r\n(ni_pi->cac_configuration_required == false))\r\nreturn 0;\r\nret = si_program_cac_config_registers(rdev, si_pi->lcac_config);\r\nif (ret)\r\nreturn ret;\r\nret = si_program_cac_config_registers(rdev, si_pi->cac_override);\r\nif (ret)\r\nreturn ret;\r\nret = si_program_cac_config_registers(rdev, si_pi->cac_weights);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nstatic int si_enable_smc_cac(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state,\r\nbool enable)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nPPSMC_Result smc_result;\r\nint ret = 0;\r\nif (ni_pi->enable_cac) {\r\nif (enable) {\r\nif (!si_should_disable_uvd_powertune(rdev, radeon_new_state)) {\r\nif (ni_pi->support_cac_long_term_average) {\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_CACLongTermAvgEnable);\r\nif (smc_result != PPSMC_Result_OK)\r\nni_pi->support_cac_long_term_average = false;\r\n}\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_MSG_EnableCac);\r\nif (smc_result != PPSMC_Result_OK) {\r\nret = -EINVAL;\r\nni_pi->cac_enabled = false;\r\n} else {\r\nni_pi->cac_enabled = true;\r\n}\r\nif (si_pi->enable_dte) {\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_MSG_EnableDTE);\r\nif (smc_result != PPSMC_Result_OK)\r\nret = -EINVAL;\r\n}\r\n}\r\n} else if (ni_pi->cac_enabled) {\r\nif (si_pi->enable_dte)\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_MSG_DisableDTE);\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_MSG_DisableCac);\r\nni_pi->cac_enabled = false;\r\nif (ni_pi->support_cac_long_term_average)\r\nsmc_result = si_send_msg_to_smc(rdev, PPSMC_CACLongTermAvgDisable);\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int si_init_smc_spll_table(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nSMC_SISLANDS_SPLL_DIV_TABLE *spll_table;\r\nSISLANDS_SMC_SCLK_VALUE sclk_params;\r\nu32 fb_div, p_div;\r\nu32 clk_s, clk_v;\r\nu32 sclk = 0;\r\nint ret = 0;\r\nu32 tmp;\r\nint i;\r\nif (si_pi->spll_table_start == 0)\r\nreturn -EINVAL;\r\nspll_table = kzalloc(sizeof(SMC_SISLANDS_SPLL_DIV_TABLE), GFP_KERNEL);\r\nif (spll_table == NULL)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < 256; i++) {\r\nret = si_calculate_sclk_params(rdev, sclk, &sclk_params);\r\nif (ret)\r\nbreak;\r\np_div = (sclk_params.vCG_SPLL_FUNC_CNTL & SPLL_PDIV_A_MASK) >> SPLL_PDIV_A_SHIFT;\r\nfb_div = (sclk_params.vCG_SPLL_FUNC_CNTL_3 & SPLL_FB_DIV_MASK) >> SPLL_FB_DIV_SHIFT;\r\nclk_s = (sclk_params.vCG_SPLL_SPREAD_SPECTRUM & CLK_S_MASK) >> CLK_S_SHIFT;\r\nclk_v = (sclk_params.vCG_SPLL_SPREAD_SPECTRUM_2 & CLK_V_MASK) >> CLK_V_SHIFT;\r\nfb_div &= ~0x00001FFF;\r\nfb_div >>= 1;\r\nclk_v >>= 6;\r\nif (p_div & ~(SMC_SISLANDS_SPLL_DIV_TABLE_PDIV_MASK >> SMC_SISLANDS_SPLL_DIV_TABLE_PDIV_SHIFT))\r\nret = -EINVAL;\r\nif (fb_div & ~(SMC_SISLANDS_SPLL_DIV_TABLE_FBDIV_MASK >> SMC_SISLANDS_SPLL_DIV_TABLE_FBDIV_SHIFT))\r\nret = -EINVAL;\r\nif (clk_s & ~(SMC_SISLANDS_SPLL_DIV_TABLE_CLKS_MASK >> SMC_SISLANDS_SPLL_DIV_TABLE_CLKS_SHIFT))\r\nret = -EINVAL;\r\nif (clk_v & ~(SMC_SISLANDS_SPLL_DIV_TABLE_CLKV_MASK >> SMC_SISLANDS_SPLL_DIV_TABLE_CLKV_SHIFT))\r\nret = -EINVAL;\r\nif (ret)\r\nbreak;\r\ntmp = ((fb_div << SMC_SISLANDS_SPLL_DIV_TABLE_FBDIV_SHIFT) & SMC_SISLANDS_SPLL_DIV_TABLE_FBDIV_MASK) |\r\n((p_div << SMC_SISLANDS_SPLL_DIV_TABLE_PDIV_SHIFT) & SMC_SISLANDS_SPLL_DIV_TABLE_PDIV_MASK);\r\nspll_table->freq[i] = cpu_to_be32(tmp);\r\ntmp = ((clk_v << SMC_SISLANDS_SPLL_DIV_TABLE_CLKV_SHIFT) & SMC_SISLANDS_SPLL_DIV_TABLE_CLKV_MASK) |\r\n((clk_s << SMC_SISLANDS_SPLL_DIV_TABLE_CLKS_SHIFT) & SMC_SISLANDS_SPLL_DIV_TABLE_CLKS_MASK);\r\nspll_table->ss[i] = cpu_to_be32(tmp);\r\nsclk += 512;\r\n}\r\nif (!ret)\r\nret = si_copy_bytes_to_smc(rdev, si_pi->spll_table_start,\r\n(u8 *)spll_table, sizeof(SMC_SISLANDS_SPLL_DIV_TABLE),\r\nsi_pi->sram_end);\r\nif (ret)\r\nni_pi->enable_power_containment = false;\r\nkfree(spll_table);\r\nreturn ret;\r\n}\r\nstatic u16 si_get_lower_of_leakage_and_vce_voltage(struct radeon_device *rdev,\r\nu16 vce_voltage)\r\n{\r\nu16 highest_leakage = 0;\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nint i;\r\nfor (i = 0; i < si_pi->leakage_voltage.count; i++){\r\nif (highest_leakage < si_pi->leakage_voltage.entries[i].voltage)\r\nhighest_leakage = si_pi->leakage_voltage.entries[i].voltage;\r\n}\r\nif (si_pi->leakage_voltage.count && (highest_leakage < vce_voltage))\r\nreturn highest_leakage;\r\nreturn vce_voltage;\r\n}\r\nstatic int si_get_vce_clock_voltage(struct radeon_device *rdev,\r\nu32 evclk, u32 ecclk, u16 *voltage)\r\n{\r\nu32 i;\r\nint ret = -EINVAL;\r\nstruct radeon_vce_clock_voltage_dependency_table *table =\r\n&rdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\r\nif (((evclk == 0) && (ecclk == 0)) ||\r\n(table && (table->count == 0))) {\r\n*voltage = 0;\r\nreturn 0;\r\n}\r\nfor (i = 0; i < table->count; i++) {\r\nif ((evclk <= table->entries[i].evclk) &&\r\n(ecclk <= table->entries[i].ecclk)) {\r\n*voltage = table->entries[i].v;\r\nret = 0;\r\nbreak;\r\n}\r\n}\r\nif (ret)\r\n*voltage = table->entries[table->count - 1].v;\r\n*voltage = si_get_lower_of_leakage_and_vce_voltage(rdev, *voltage);\r\nreturn ret;\r\n}\r\nstatic void si_apply_state_adjust_rules(struct radeon_device *rdev,\r\nstruct radeon_ps *rps)\r\n{\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct radeon_clock_and_voltage_limits *max_limits;\r\nbool disable_mclk_switching = false;\r\nbool disable_sclk_switching = false;\r\nu32 mclk, sclk;\r\nu16 vddc, vddci, min_vce_voltage = 0;\r\nu32 max_sclk_vddc, max_mclk_vddci, max_mclk_vddc;\r\nu32 max_sclk = 0, max_mclk = 0;\r\nint i;\r\nstruct si_dpm_quirk *p = si_dpm_quirk_list;\r\nwhile (p && p->chip_device != 0) {\r\nif (rdev->pdev->vendor == p->chip_vendor &&\r\nrdev->pdev->device == p->chip_device &&\r\nrdev->pdev->subsystem_vendor == p->subsys_vendor &&\r\nrdev->pdev->subsystem_device == p->subsys_device) {\r\nmax_sclk = p->max_sclk;\r\nmax_mclk = p->max_mclk;\r\nbreak;\r\n}\r\n++p;\r\n}\r\nif (rps->vce_active) {\r\nrps->evclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].evclk;\r\nrps->ecclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].ecclk;\r\nsi_get_vce_clock_voltage(rdev, rps->evclk, rps->ecclk,\r\n&min_vce_voltage);\r\n} else {\r\nrps->evclk = 0;\r\nrps->ecclk = 0;\r\n}\r\nif ((rdev->pm.dpm.new_active_crtc_count > 1) ||\r\nni_dpm_vblank_too_short(rdev))\r\ndisable_mclk_switching = true;\r\nif (rps->vclk || rps->dclk) {\r\ndisable_mclk_switching = true;\r\ndisable_sclk_switching = true;\r\n}\r\nif (rdev->pm.dpm.ac_power)\r\nmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\r\nelse\r\nmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc;\r\nfor (i = ps->performance_level_count - 2; i >= 0; i--) {\r\nif (ps->performance_levels[i].vddc > ps->performance_levels[i+1].vddc)\r\nps->performance_levels[i].vddc = ps->performance_levels[i+1].vddc;\r\n}\r\nif (rdev->pm.dpm.ac_power == false) {\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].mclk > max_limits->mclk)\r\nps->performance_levels[i].mclk = max_limits->mclk;\r\nif (ps->performance_levels[i].sclk > max_limits->sclk)\r\nps->performance_levels[i].sclk = max_limits->sclk;\r\nif (ps->performance_levels[i].vddc > max_limits->vddc)\r\nps->performance_levels[i].vddc = max_limits->vddc;\r\nif (ps->performance_levels[i].vddci > max_limits->vddci)\r\nps->performance_levels[i].vddci = max_limits->vddci;\r\n}\r\n}\r\nbtc_get_max_clock_from_voltage_dependency_table(&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk,\r\n&max_sclk_vddc);\r\nbtc_get_max_clock_from_voltage_dependency_table(&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk,\r\n&max_mclk_vddci);\r\nbtc_get_max_clock_from_voltage_dependency_table(&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk,\r\n&max_mclk_vddc);\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nif (max_sclk_vddc) {\r\nif (ps->performance_levels[i].sclk > max_sclk_vddc)\r\nps->performance_levels[i].sclk = max_sclk_vddc;\r\n}\r\nif (max_mclk_vddci) {\r\nif (ps->performance_levels[i].mclk > max_mclk_vddci)\r\nps->performance_levels[i].mclk = max_mclk_vddci;\r\n}\r\nif (max_mclk_vddc) {\r\nif (ps->performance_levels[i].mclk > max_mclk_vddc)\r\nps->performance_levels[i].mclk = max_mclk_vddc;\r\n}\r\nif (max_mclk) {\r\nif (ps->performance_levels[i].mclk > max_mclk)\r\nps->performance_levels[i].mclk = max_mclk;\r\n}\r\nif (max_sclk) {\r\nif (ps->performance_levels[i].sclk > max_sclk)\r\nps->performance_levels[i].sclk = max_sclk;\r\n}\r\n}\r\nif (disable_mclk_switching) {\r\nmclk = ps->performance_levels[ps->performance_level_count - 1].mclk;\r\nvddci = ps->performance_levels[ps->performance_level_count - 1].vddci;\r\n} else {\r\nmclk = ps->performance_levels[0].mclk;\r\nvddci = ps->performance_levels[0].vddci;\r\n}\r\nif (disable_sclk_switching) {\r\nsclk = ps->performance_levels[ps->performance_level_count - 1].sclk;\r\nvddc = ps->performance_levels[ps->performance_level_count - 1].vddc;\r\n} else {\r\nsclk = ps->performance_levels[0].sclk;\r\nvddc = ps->performance_levels[0].vddc;\r\n}\r\nif (rps->vce_active) {\r\nif (sclk < rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].sclk)\r\nsclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].sclk;\r\nif (mclk < rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].mclk)\r\nmclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].mclk;\r\n}\r\nps->performance_levels[0].sclk = sclk;\r\nps->performance_levels[0].mclk = mclk;\r\nps->performance_levels[0].vddc = vddc;\r\nps->performance_levels[0].vddci = vddci;\r\nif (disable_sclk_switching) {\r\nsclk = ps->performance_levels[0].sclk;\r\nfor (i = 1; i < ps->performance_level_count; i++) {\r\nif (sclk < ps->performance_levels[i].sclk)\r\nsclk = ps->performance_levels[i].sclk;\r\n}\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nps->performance_levels[i].sclk = sclk;\r\nps->performance_levels[i].vddc = vddc;\r\n}\r\n} else {\r\nfor (i = 1; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].sclk < ps->performance_levels[i - 1].sclk)\r\nps->performance_levels[i].sclk = ps->performance_levels[i - 1].sclk;\r\nif (ps->performance_levels[i].vddc < ps->performance_levels[i - 1].vddc)\r\nps->performance_levels[i].vddc = ps->performance_levels[i - 1].vddc;\r\n}\r\n}\r\nif (disable_mclk_switching) {\r\nmclk = ps->performance_levels[0].mclk;\r\nfor (i = 1; i < ps->performance_level_count; i++) {\r\nif (mclk < ps->performance_levels[i].mclk)\r\nmclk = ps->performance_levels[i].mclk;\r\n}\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nps->performance_levels[i].mclk = mclk;\r\nps->performance_levels[i].vddci = vddci;\r\n}\r\n} else {\r\nfor (i = 1; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].mclk < ps->performance_levels[i - 1].mclk)\r\nps->performance_levels[i].mclk = ps->performance_levels[i - 1].mclk;\r\nif (ps->performance_levels[i].vddci < ps->performance_levels[i - 1].vddci)\r\nps->performance_levels[i].vddci = ps->performance_levels[i - 1].vddci;\r\n}\r\n}\r\nfor (i = 0; i < ps->performance_level_count; i++)\r\nbtc_adjust_clock_combinations(rdev, max_limits,\r\n&ps->performance_levels[i]);\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].vddc < min_vce_voltage)\r\nps->performance_levels[i].vddc = min_vce_voltage;\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk,\r\nps->performance_levels[i].sclk,\r\nmax_limits->vddc, &ps->performance_levels[i].vddc);\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk,\r\nps->performance_levels[i].mclk,\r\nmax_limits->vddci, &ps->performance_levels[i].vddci);\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk,\r\nps->performance_levels[i].mclk,\r\nmax_limits->vddc, &ps->performance_levels[i].vddc);\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk,\r\nrdev->clock.current_dispclk,\r\nmax_limits->vddc, &ps->performance_levels[i].vddc);\r\n}\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nbtc_apply_voltage_delta_rules(rdev,\r\nmax_limits->vddc, max_limits->vddci,\r\n&ps->performance_levels[i].vddc,\r\n&ps->performance_levels[i].vddci);\r\n}\r\nps->dc_compatible = true;\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].vddc > rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.vddc)\r\nps->dc_compatible = false;\r\n}\r\n}\r\nstatic int si_write_smc_soft_register(struct radeon_device *rdev,\r\nu16 reg_offset, u32 value)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nreturn si_write_smc_sram_dword(rdev,\r\nsi_pi->soft_regs_start + reg_offset,\r\nvalue, si_pi->sram_end);\r\n}\r\nstatic bool si_is_special_1gb_platform(struct radeon_device *rdev)\r\n{\r\nbool ret = false;\r\nu32 tmp, width, row, column, bank, density;\r\nbool is_memory_gddr5, is_special;\r\ntmp = RREG32(MC_SEQ_MISC0);\r\nis_memory_gddr5 = (MC_SEQ_MISC0_GDDR5_VALUE == ((tmp & MC_SEQ_MISC0_GDDR5_MASK) >> MC_SEQ_MISC0_GDDR5_SHIFT));\r\nis_special = (MC_SEQ_MISC0_REV_ID_VALUE == ((tmp & MC_SEQ_MISC0_REV_ID_MASK) >> MC_SEQ_MISC0_REV_ID_SHIFT))\r\n& (MC_SEQ_MISC0_VEN_ID_VALUE == ((tmp & MC_SEQ_MISC0_VEN_ID_MASK) >> MC_SEQ_MISC0_VEN_ID_SHIFT));\r\nWREG32(MC_SEQ_IO_DEBUG_INDEX, 0xb);\r\nwidth = ((RREG32(MC_SEQ_IO_DEBUG_DATA) >> 1) & 1) ? 16 : 32;\r\ntmp = RREG32(MC_ARB_RAMCFG);\r\nrow = ((tmp & NOOFROWS_MASK) >> NOOFROWS_SHIFT) + 10;\r\ncolumn = ((tmp & NOOFCOLS_MASK) >> NOOFCOLS_SHIFT) + 8;\r\nbank = ((tmp & NOOFBANK_MASK) >> NOOFBANK_SHIFT) + 2;\r\ndensity = (1 << (row + column - 20 + bank)) * width;\r\nif ((rdev->pdev->device == 0x6819) &&\r\nis_memory_gddr5 && is_special && (density == 0x400))\r\nret = true;\r\nreturn ret;\r\n}\r\nstatic void si_get_leakage_vddc(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu16 vddc, count = 0;\r\nint i, ret;\r\nfor (i = 0; i < SISLANDS_MAX_LEAKAGE_COUNT; i++) {\r\nret = radeon_atom_get_leakage_vddc_based_on_leakage_idx(rdev, &vddc, SISLANDS_LEAKAGE_INDEX0 + i);\r\nif (!ret && (vddc > 0) && (vddc != (SISLANDS_LEAKAGE_INDEX0 + i))) {\r\nsi_pi->leakage_voltage.entries[count].voltage = vddc;\r\nsi_pi->leakage_voltage.entries[count].leakage_index =\r\nSISLANDS_LEAKAGE_INDEX0 + i;\r\ncount++;\r\n}\r\n}\r\nsi_pi->leakage_voltage.count = count;\r\n}\r\nstatic int si_get_leakage_voltage_from_leakage_index(struct radeon_device *rdev,\r\nu32 index, u16 *leakage_voltage)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nint i;\r\nif (leakage_voltage == NULL)\r\nreturn -EINVAL;\r\nif ((index & 0xff00) != 0xff00)\r\nreturn -EINVAL;\r\nif ((index & 0xff) > SISLANDS_MAX_LEAKAGE_COUNT + 1)\r\nreturn -EINVAL;\r\nif (index < SISLANDS_LEAKAGE_INDEX0)\r\nreturn -EINVAL;\r\nfor (i = 0; i < si_pi->leakage_voltage.count; i++) {\r\nif (si_pi->leakage_voltage.entries[i].leakage_index == index) {\r\n*leakage_voltage = si_pi->leakage_voltage.entries[i].voltage;\r\nreturn 0;\r\n}\r\n}\r\nreturn -EAGAIN;\r\n}\r\nstatic void si_set_dpm_event_sources(struct radeon_device *rdev, u32 sources)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nbool want_thermal_protection;\r\nenum radeon_dpm_event_src dpm_event_src;\r\nswitch (sources) {\r\ncase 0:\r\ndefault:\r\nwant_thermal_protection = false;\r\nbreak;\r\ncase (1 << RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL):\r\nwant_thermal_protection = true;\r\ndpm_event_src = RADEON_DPM_EVENT_SRC_DIGITAL;\r\nbreak;\r\ncase (1 << RADEON_DPM_AUTO_THROTTLE_SRC_EXTERNAL):\r\nwant_thermal_protection = true;\r\ndpm_event_src = RADEON_DPM_EVENT_SRC_EXTERNAL;\r\nbreak;\r\ncase ((1 << RADEON_DPM_AUTO_THROTTLE_SRC_EXTERNAL) |\r\n(1 << RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL)):\r\nwant_thermal_protection = true;\r\ndpm_event_src = RADEON_DPM_EVENT_SRC_DIGIAL_OR_EXTERNAL;\r\nbreak;\r\n}\r\nif (want_thermal_protection) {\r\nWREG32_P(CG_THERMAL_CTRL, DPM_EVENT_SRC(dpm_event_src), ~DPM_EVENT_SRC_MASK);\r\nif (pi->thermal_protection)\r\nWREG32_P(GENERAL_PWRMGT, 0, ~THERMAL_PROTECTION_DIS);\r\n} else {\r\nWREG32_P(GENERAL_PWRMGT, THERMAL_PROTECTION_DIS, ~THERMAL_PROTECTION_DIS);\r\n}\r\n}\r\nstatic void si_enable_auto_throttle_source(struct radeon_device *rdev,\r\nenum radeon_dpm_auto_throttle_src source,\r\nbool enable)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nif (enable) {\r\nif (!(pi->active_auto_throttle_sources & (1 << source))) {\r\npi->active_auto_throttle_sources |= 1 << source;\r\nsi_set_dpm_event_sources(rdev, pi->active_auto_throttle_sources);\r\n}\r\n} else {\r\nif (pi->active_auto_throttle_sources & (1 << source)) {\r\npi->active_auto_throttle_sources &= ~(1 << source);\r\nsi_set_dpm_event_sources(rdev, pi->active_auto_throttle_sources);\r\n}\r\n}\r\n}\r\nstatic void si_start_dpm(struct radeon_device *rdev)\r\n{\r\nWREG32_P(GENERAL_PWRMGT, GLOBAL_PWRMGT_EN, ~GLOBAL_PWRMGT_EN);\r\n}\r\nstatic void si_stop_dpm(struct radeon_device *rdev)\r\n{\r\nWREG32_P(GENERAL_PWRMGT, 0, ~GLOBAL_PWRMGT_EN);\r\n}\r\nstatic void si_enable_sclk_control(struct radeon_device *rdev, bool enable)\r\n{\r\nif (enable)\r\nWREG32_P(SCLK_PWRMGT_CNTL, 0, ~SCLK_PWRMGT_OFF);\r\nelse\r\nWREG32_P(SCLK_PWRMGT_CNTL, SCLK_PWRMGT_OFF, ~SCLK_PWRMGT_OFF);\r\n}\r\nstatic PPSMC_Result si_send_msg_to_smc_with_parameter(struct radeon_device *rdev,\r\nPPSMC_Msg msg, u32 parameter)\r\n{\r\nWREG32(SMC_SCRATCH0, parameter);\r\nreturn si_send_msg_to_smc(rdev, msg);\r\n}\r\nstatic int si_restrict_performance_levels_before_switch(struct radeon_device *rdev)\r\n{\r\nif (si_send_msg_to_smc(rdev, PPSMC_MSG_NoForcedLevel) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nreturn (si_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, 1) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nint si_dpm_force_performance_level(struct radeon_device *rdev,\r\nenum radeon_dpm_forced_level level)\r\n{\r\nstruct radeon_ps *rps = rdev->pm.dpm.current_ps;\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nu32 levels = ps->performance_level_count;\r\nif (level == RADEON_DPM_FORCED_LEVEL_HIGH) {\r\nif (si_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, levels) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nif (si_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetForcedLevels, 1) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\n} else if (level == RADEON_DPM_FORCED_LEVEL_LOW) {\r\nif (si_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetForcedLevels, 0) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nif (si_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, 1) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\n} else if (level == RADEON_DPM_FORCED_LEVEL_AUTO) {\r\nif (si_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetForcedLevels, 0) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nif (si_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, levels) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\n}\r\nrdev->pm.dpm.forced_level = level;\r\nreturn 0;\r\n}\r\nstatic int si_set_sw_state(struct radeon_device *rdev)\r\n{\r\nreturn (si_send_msg_to_smc(rdev, PPSMC_MSG_SwitchToSwState) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nstatic int si_halt_smc(struct radeon_device *rdev)\r\n{\r\nif (si_send_msg_to_smc(rdev, PPSMC_MSG_Halt) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nreturn (si_wait_for_smc_inactive(rdev) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nstatic int si_resume_smc(struct radeon_device *rdev)\r\n{\r\nif (si_send_msg_to_smc(rdev, PPSMC_FlushDataCache) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nreturn (si_send_msg_to_smc(rdev, PPSMC_MSG_Resume) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nstatic void si_dpm_start_smc(struct radeon_device *rdev)\r\n{\r\nsi_program_jump_on_start(rdev);\r\nsi_start_smc(rdev);\r\nsi_start_smc_clock(rdev);\r\n}\r\nstatic void si_dpm_stop_smc(struct radeon_device *rdev)\r\n{\r\nsi_reset_smc(rdev);\r\nsi_stop_smc_clock(rdev);\r\n}\r\nstatic int si_process_firmware_header(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 tmp;\r\nint ret;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_stateTable,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->state_table_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_softRegisters,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->soft_regs_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_mcRegisterTable,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->mc_reg_table_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_fanTable,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->fan_table_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_mcArbDramAutoRefreshTable,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->arb_table_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_CacConfigTable,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->cac_table_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_DteConfiguration,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->dte_table_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_spllTable,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->spll_table_start = tmp;\r\nret = si_read_smc_sram_dword(rdev,\r\nSISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nSISLANDS_SMC_FIRMWARE_HEADER_PAPMParameters,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nsi_pi->papm_cfg_table_start = tmp;\r\nreturn ret;\r\n}\r\nstatic void si_read_clock_registers(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nsi_pi->clock_registers.cg_spll_func_cntl = RREG32(CG_SPLL_FUNC_CNTL);\r\nsi_pi->clock_registers.cg_spll_func_cntl_2 = RREG32(CG_SPLL_FUNC_CNTL_2);\r\nsi_pi->clock_registers.cg_spll_func_cntl_3 = RREG32(CG_SPLL_FUNC_CNTL_3);\r\nsi_pi->clock_registers.cg_spll_func_cntl_4 = RREG32(CG_SPLL_FUNC_CNTL_4);\r\nsi_pi->clock_registers.cg_spll_spread_spectrum = RREG32(CG_SPLL_SPREAD_SPECTRUM);\r\nsi_pi->clock_registers.cg_spll_spread_spectrum_2 = RREG32(CG_SPLL_SPREAD_SPECTRUM_2);\r\nsi_pi->clock_registers.dll_cntl = RREG32(DLL_CNTL);\r\nsi_pi->clock_registers.mclk_pwrmgt_cntl = RREG32(MCLK_PWRMGT_CNTL);\r\nsi_pi->clock_registers.mpll_ad_func_cntl = RREG32(MPLL_AD_FUNC_CNTL);\r\nsi_pi->clock_registers.mpll_dq_func_cntl = RREG32(MPLL_DQ_FUNC_CNTL);\r\nsi_pi->clock_registers.mpll_func_cntl = RREG32(MPLL_FUNC_CNTL);\r\nsi_pi->clock_registers.mpll_func_cntl_1 = RREG32(MPLL_FUNC_CNTL_1);\r\nsi_pi->clock_registers.mpll_func_cntl_2 = RREG32(MPLL_FUNC_CNTL_2);\r\nsi_pi->clock_registers.mpll_ss1 = RREG32(MPLL_SS1);\r\nsi_pi->clock_registers.mpll_ss2 = RREG32(MPLL_SS2);\r\n}\r\nstatic void si_enable_thermal_protection(struct radeon_device *rdev,\r\nbool enable)\r\n{\r\nif (enable)\r\nWREG32_P(GENERAL_PWRMGT, 0, ~THERMAL_PROTECTION_DIS);\r\nelse\r\nWREG32_P(GENERAL_PWRMGT, THERMAL_PROTECTION_DIS, ~THERMAL_PROTECTION_DIS);\r\n}\r\nstatic void si_enable_acpi_power_management(struct radeon_device *rdev)\r\n{\r\nWREG32_P(GENERAL_PWRMGT, STATIC_PM_EN, ~STATIC_PM_EN);\r\n}\r\nstatic int si_notify_smc_display_change(struct radeon_device *rdev,\r\nbool has_display)\r\n{\r\nPPSMC_Msg msg = has_display ?\r\nPPSMC_MSG_HasDisplay : PPSMC_MSG_NoDisplay;\r\nreturn (si_send_msg_to_smc(rdev, msg) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nstatic void si_program_response_times(struct radeon_device *rdev)\r\n{\r\nu32 voltage_response_time, backbias_response_time, acpi_delay_time, vbi_time_out;\r\nu32 vddc_dly, acpi_dly, vbi_dly;\r\nu32 reference_clock;\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_mvdd_chg_time, 1);\r\nvoltage_response_time = (u32)rdev->pm.dpm.voltage_response_time;\r\nbackbias_response_time = (u32)rdev->pm.dpm.backbias_response_time;\r\nif (voltage_response_time == 0)\r\nvoltage_response_time = 1000;\r\nacpi_delay_time = 15000;\r\nvbi_time_out = 100000;\r\nreference_clock = radeon_get_xclk(rdev);\r\nvddc_dly = (voltage_response_time * reference_clock) / 100;\r\nacpi_dly = (acpi_delay_time * reference_clock) / 100;\r\nvbi_dly = (vbi_time_out * reference_clock) / 100;\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_delay_vreg, vddc_dly);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_delay_acpi, acpi_dly);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_mclk_chg_timeout, vbi_dly);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_mc_block_delay, 0xAA);\r\n}\r\nstatic void si_program_ds_registers(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nu32 tmp = 1;\r\nif (eg_pi->sclk_deep_sleep) {\r\nWREG32_P(MISC_CLK_CNTL, DEEP_SLEEP_CLK_SEL(tmp), ~DEEP_SLEEP_CLK_SEL_MASK);\r\nWREG32_P(CG_SPLL_AUTOSCALE_CNTL, AUTOSCALE_ON_SS_CLEAR,\r\n~AUTOSCALE_ON_SS_CLEAR);\r\n}\r\n}\r\nstatic void si_program_display_gap(struct radeon_device *rdev)\r\n{\r\nu32 tmp, pipe;\r\nint i;\r\ntmp = RREG32(CG_DISPLAY_GAP_CNTL) & ~(DISP1_GAP_MASK | DISP2_GAP_MASK);\r\nif (rdev->pm.dpm.new_active_crtc_count > 0)\r\ntmp |= DISP1_GAP(R600_PM_DISPLAY_GAP_VBLANK_OR_WM);\r\nelse\r\ntmp |= DISP1_GAP(R600_PM_DISPLAY_GAP_IGNORE);\r\nif (rdev->pm.dpm.new_active_crtc_count > 1)\r\ntmp |= DISP2_GAP(R600_PM_DISPLAY_GAP_VBLANK_OR_WM);\r\nelse\r\ntmp |= DISP2_GAP(R600_PM_DISPLAY_GAP_IGNORE);\r\nWREG32(CG_DISPLAY_GAP_CNTL, tmp);\r\ntmp = RREG32(DCCG_DISP_SLOW_SELECT_REG);\r\npipe = (tmp & DCCG_DISP1_SLOW_SELECT_MASK) >> DCCG_DISP1_SLOW_SELECT_SHIFT;\r\nif ((rdev->pm.dpm.new_active_crtc_count > 0) &&\r\n(!(rdev->pm.dpm.new_active_crtcs & (1 << pipe)))) {\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (rdev->pm.dpm.new_active_crtcs & (1 << i))\r\nbreak;\r\n}\r\nif (i == rdev->num_crtc)\r\npipe = 0;\r\nelse\r\npipe = i;\r\ntmp &= ~DCCG_DISP1_SLOW_SELECT_MASK;\r\ntmp |= DCCG_DISP1_SLOW_SELECT(pipe);\r\nWREG32(DCCG_DISP_SLOW_SELECT_REG, tmp);\r\n}\r\nsi_notify_smc_display_change(rdev, rdev->pm.dpm.new_active_crtc_count > 0);\r\n}\r\nstatic void si_enable_spread_spectrum(struct radeon_device *rdev, bool enable)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nif (enable) {\r\nif (pi->sclk_ss)\r\nWREG32_P(GENERAL_PWRMGT, DYN_SPREAD_SPECTRUM_EN, ~DYN_SPREAD_SPECTRUM_EN);\r\n} else {\r\nWREG32_P(CG_SPLL_SPREAD_SPECTRUM, 0, ~SSEN);\r\nWREG32_P(GENERAL_PWRMGT, 0, ~DYN_SPREAD_SPECTRUM_EN);\r\n}\r\n}\r\nstatic void si_setup_bsp(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu32 xclk = radeon_get_xclk(rdev);\r\nr600_calculate_u_and_p(pi->asi,\r\nxclk,\r\n16,\r\n&pi->bsp,\r\n&pi->bsu);\r\nr600_calculate_u_and_p(pi->pasi,\r\nxclk,\r\n16,\r\n&pi->pbsp,\r\n&pi->pbsu);\r\npi->dsp = BSP(pi->bsp) | BSU(pi->bsu);\r\npi->psp = BSP(pi->pbsp) | BSU(pi->pbsu);\r\nWREG32(CG_BSP, pi->dsp);\r\n}\r\nstatic void si_program_git(struct radeon_device *rdev)\r\n{\r\nWREG32_P(CG_GIT, CG_GICST(R600_GICST_DFLT), ~CG_GICST_MASK);\r\n}\r\nstatic void si_program_tp(struct radeon_device *rdev)\r\n{\r\nint i;\r\nenum r600_td td = R600_TD_DFLT;\r\nfor (i = 0; i < R600_PM_NUMBER_OF_TC; i++)\r\nWREG32(CG_FFCT_0 + (i * 4), (UTC_0(r600_utc[i]) | DTC_0(r600_dtc[i])));\r\nif (td == R600_TD_AUTO)\r\nWREG32_P(SCLK_PWRMGT_CNTL, 0, ~FIR_FORCE_TREND_SEL);\r\nelse\r\nWREG32_P(SCLK_PWRMGT_CNTL, FIR_FORCE_TREND_SEL, ~FIR_FORCE_TREND_SEL);\r\nif (td == R600_TD_UP)\r\nWREG32_P(SCLK_PWRMGT_CNTL, 0, ~FIR_TREND_MODE);\r\nif (td == R600_TD_DOWN)\r\nWREG32_P(SCLK_PWRMGT_CNTL, FIR_TREND_MODE, ~FIR_TREND_MODE);\r\n}\r\nstatic void si_program_tpp(struct radeon_device *rdev)\r\n{\r\nWREG32(CG_TPC, R600_TPC_DFLT);\r\n}\r\nstatic void si_program_sstp(struct radeon_device *rdev)\r\n{\r\nWREG32(CG_SSP, (SSTU(R600_SSTU_DFLT) | SST(R600_SST_DFLT)));\r\n}\r\nstatic void si_enable_display_gap(struct radeon_device *rdev)\r\n{\r\nu32 tmp = RREG32(CG_DISPLAY_GAP_CNTL);\r\ntmp &= ~(DISP1_GAP_MASK | DISP2_GAP_MASK);\r\ntmp |= (DISP1_GAP(R600_PM_DISPLAY_GAP_IGNORE) |\r\nDISP2_GAP(R600_PM_DISPLAY_GAP_IGNORE));\r\ntmp &= ~(DISP1_GAP_MCHG_MASK | DISP2_GAP_MCHG_MASK);\r\ntmp |= (DISP1_GAP_MCHG(R600_PM_DISPLAY_GAP_VBLANK) |\r\nDISP2_GAP_MCHG(R600_PM_DISPLAY_GAP_IGNORE));\r\nWREG32(CG_DISPLAY_GAP_CNTL, tmp);\r\n}\r\nstatic void si_program_vc(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nWREG32(CG_FTV, pi->vrc);\r\n}\r\nstatic void si_clear_vc(struct radeon_device *rdev)\r\n{\r\nWREG32(CG_FTV, 0);\r\n}\r\nu8 si_get_ddr3_mclk_frequency_ratio(u32 memory_clock)\r\n{\r\nu8 mc_para_index;\r\nif (memory_clock < 10000)\r\nmc_para_index = 0;\r\nelse if (memory_clock >= 80000)\r\nmc_para_index = 0x0f;\r\nelse\r\nmc_para_index = (u8)((memory_clock - 10000) / 5000 + 1);\r\nreturn mc_para_index;\r\n}\r\nu8 si_get_mclk_frequency_ratio(u32 memory_clock, bool strobe_mode)\r\n{\r\nu8 mc_para_index;\r\nif (strobe_mode) {\r\nif (memory_clock < 12500)\r\nmc_para_index = 0x00;\r\nelse if (memory_clock > 47500)\r\nmc_para_index = 0x0f;\r\nelse\r\nmc_para_index = (u8)((memory_clock - 10000) / 2500);\r\n} else {\r\nif (memory_clock < 65000)\r\nmc_para_index = 0x00;\r\nelse if (memory_clock > 135000)\r\nmc_para_index = 0x0f;\r\nelse\r\nmc_para_index = (u8)((memory_clock - 60000) / 5000);\r\n}\r\nreturn mc_para_index;\r\n}\r\nstatic u8 si_get_strobe_mode_settings(struct radeon_device *rdev, u32 mclk)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nbool strobe_mode = false;\r\nu8 result = 0;\r\nif (mclk <= pi->mclk_strobe_mode_threshold)\r\nstrobe_mode = true;\r\nif (pi->mem_gddr5)\r\nresult = si_get_mclk_frequency_ratio(mclk, strobe_mode);\r\nelse\r\nresult = si_get_ddr3_mclk_frequency_ratio(mclk);\r\nif (strobe_mode)\r\nresult |= SISLANDS_SMC_STROBE_ENABLE;\r\nreturn result;\r\n}\r\nstatic int si_upload_firmware(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nint ret;\r\nsi_reset_smc(rdev);\r\nsi_stop_smc_clock(rdev);\r\nret = si_load_smc_ucode(rdev, si_pi->sram_end);\r\nreturn ret;\r\n}\r\nstatic bool si_validate_phase_shedding_tables(struct radeon_device *rdev,\r\nconst struct atom_voltage_table *table,\r\nconst struct radeon_phase_shedding_limits_table *limits)\r\n{\r\nu32 data, num_bits, num_levels;\r\nif ((table == NULL) || (limits == NULL))\r\nreturn false;\r\ndata = table->mask_low;\r\nnum_bits = hweight32(data);\r\nif (num_bits == 0)\r\nreturn false;\r\nnum_levels = (1 << num_bits);\r\nif (table->count != num_levels)\r\nreturn false;\r\nif (limits->count != (num_levels - 1))\r\nreturn false;\r\nreturn true;\r\n}\r\nvoid si_trim_voltage_table_to_fit_state_table(struct radeon_device *rdev,\r\nu32 max_voltage_steps,\r\nstruct atom_voltage_table *voltage_table)\r\n{\r\nunsigned int i, diff;\r\nif (voltage_table->count <= max_voltage_steps)\r\nreturn;\r\ndiff = voltage_table->count - max_voltage_steps;\r\nfor (i= 0; i < max_voltage_steps; i++)\r\nvoltage_table->entries[i] = voltage_table->entries[i + diff];\r\nvoltage_table->count = max_voltage_steps;\r\n}\r\nstatic int si_get_svi2_voltage_table(struct radeon_device *rdev,\r\nstruct radeon_clock_voltage_dependency_table *voltage_dependency_table,\r\nstruct atom_voltage_table *voltage_table)\r\n{\r\nu32 i;\r\nif (voltage_dependency_table == NULL)\r\nreturn -EINVAL;\r\nvoltage_table->mask_low = 0;\r\nvoltage_table->phase_delay = 0;\r\nvoltage_table->count = voltage_dependency_table->count;\r\nfor (i = 0; i < voltage_table->count; i++) {\r\nvoltage_table->entries[i].value = voltage_dependency_table->entries[i].v;\r\nvoltage_table->entries[i].smio_low = 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_construct_voltage_tables(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nint ret;\r\nif (pi->voltage_control) {\r\nret = radeon_atom_get_voltage_table(rdev, VOLTAGE_TYPE_VDDC,\r\nVOLTAGE_OBJ_GPIO_LUT, &eg_pi->vddc_voltage_table);\r\nif (ret)\r\nreturn ret;\r\nif (eg_pi->vddc_voltage_table.count > SISLANDS_MAX_NO_VREG_STEPS)\r\nsi_trim_voltage_table_to_fit_state_table(rdev,\r\nSISLANDS_MAX_NO_VREG_STEPS,\r\n&eg_pi->vddc_voltage_table);\r\n} else if (si_pi->voltage_control_svi2) {\r\nret = si_get_svi2_voltage_table(rdev,\r\n&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk,\r\n&eg_pi->vddc_voltage_table);\r\nif (ret)\r\nreturn ret;\r\n} else {\r\nreturn -EINVAL;\r\n}\r\nif (eg_pi->vddci_control) {\r\nret = radeon_atom_get_voltage_table(rdev, VOLTAGE_TYPE_VDDCI,\r\nVOLTAGE_OBJ_GPIO_LUT, &eg_pi->vddci_voltage_table);\r\nif (ret)\r\nreturn ret;\r\nif (eg_pi->vddci_voltage_table.count > SISLANDS_MAX_NO_VREG_STEPS)\r\nsi_trim_voltage_table_to_fit_state_table(rdev,\r\nSISLANDS_MAX_NO_VREG_STEPS,\r\n&eg_pi->vddci_voltage_table);\r\n}\r\nif (si_pi->vddci_control_svi2) {\r\nret = si_get_svi2_voltage_table(rdev,\r\n&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk,\r\n&eg_pi->vddci_voltage_table);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (pi->mvdd_control) {\r\nret = radeon_atom_get_voltage_table(rdev, VOLTAGE_TYPE_MVDDC,\r\nVOLTAGE_OBJ_GPIO_LUT, &si_pi->mvdd_voltage_table);\r\nif (ret) {\r\npi->mvdd_control = false;\r\nreturn ret;\r\n}\r\nif (si_pi->mvdd_voltage_table.count == 0) {\r\npi->mvdd_control = false;\r\nreturn -EINVAL;\r\n}\r\nif (si_pi->mvdd_voltage_table.count > SISLANDS_MAX_NO_VREG_STEPS)\r\nsi_trim_voltage_table_to_fit_state_table(rdev,\r\nSISLANDS_MAX_NO_VREG_STEPS,\r\n&si_pi->mvdd_voltage_table);\r\n}\r\nif (si_pi->vddc_phase_shed_control) {\r\nret = radeon_atom_get_voltage_table(rdev, VOLTAGE_TYPE_VDDC,\r\nVOLTAGE_OBJ_PHASE_LUT, &si_pi->vddc_phase_shed_table);\r\nif (ret)\r\nsi_pi->vddc_phase_shed_control = false;\r\nif ((si_pi->vddc_phase_shed_table.count == 0) ||\r\n(si_pi->vddc_phase_shed_table.count > SISLANDS_MAX_NO_VREG_STEPS))\r\nsi_pi->vddc_phase_shed_control = false;\r\n}\r\nreturn 0;\r\n}\r\nstatic void si_populate_smc_voltage_table(struct radeon_device *rdev,\r\nconst struct atom_voltage_table *voltage_table,\r\nSISLANDS_SMC_STATETABLE *table)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < voltage_table->count; i++)\r\ntable->lowSMIO[i] |= cpu_to_be32(voltage_table->entries[i].smio_low);\r\n}\r\nstatic int si_populate_smc_voltage_tables(struct radeon_device *rdev,\r\nSISLANDS_SMC_STATETABLE *table)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu8 i;\r\nif (si_pi->voltage_control_svi2) {\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_svi_rework_gpio_id_svc,\r\nsi_pi->svc_gpio_id);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_svi_rework_gpio_id_svd,\r\nsi_pi->svd_gpio_id);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_svi_rework_plat_type,\r\n2);\r\n} else {\r\nif (eg_pi->vddc_voltage_table.count) {\r\nsi_populate_smc_voltage_table(rdev, &eg_pi->vddc_voltage_table, table);\r\ntable->voltageMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_VDDC] =\r\ncpu_to_be32(eg_pi->vddc_voltage_table.mask_low);\r\nfor (i = 0; i < eg_pi->vddc_voltage_table.count; i++) {\r\nif (pi->max_vddc_in_table <= eg_pi->vddc_voltage_table.entries[i].value) {\r\ntable->maxVDDCIndexInPPTable = i;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (eg_pi->vddci_voltage_table.count) {\r\nsi_populate_smc_voltage_table(rdev, &eg_pi->vddci_voltage_table, table);\r\ntable->voltageMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_VDDCI] =\r\ncpu_to_be32(eg_pi->vddci_voltage_table.mask_low);\r\n}\r\nif (si_pi->mvdd_voltage_table.count) {\r\nsi_populate_smc_voltage_table(rdev, &si_pi->mvdd_voltage_table, table);\r\ntable->voltageMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_MVDD] =\r\ncpu_to_be32(si_pi->mvdd_voltage_table.mask_low);\r\n}\r\nif (si_pi->vddc_phase_shed_control) {\r\nif (si_validate_phase_shedding_tables(rdev, &si_pi->vddc_phase_shed_table,\r\n&rdev->pm.dpm.dyn_state.phase_shedding_limits_table)) {\r\nsi_populate_smc_voltage_table(rdev, &si_pi->vddc_phase_shed_table, table);\r\ntable->phaseMaskTable.lowMask[SISLANDS_SMC_VOLTAGEMASK_VDDC] =\r\ncpu_to_be32(si_pi->vddc_phase_shed_table.mask_low);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_phase_shedding_delay,\r\n(u32)si_pi->vddc_phase_shed_table.phase_delay);\r\n} else {\r\nsi_pi->vddc_phase_shed_control = false;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_populate_voltage_value(struct radeon_device *rdev,\r\nconst struct atom_voltage_table *table,\r\nu16 value, SISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < table->count; i++) {\r\nif (value <= table->entries[i].value) {\r\nvoltage->index = (u8)i;\r\nvoltage->value = cpu_to_be16(table->entries[i].value);\r\nbreak;\r\n}\r\n}\r\nif (i >= table->count)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int si_populate_mvdd_value(struct radeon_device *rdev, u32 mclk,\r\nSISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nif (pi->mvdd_control) {\r\nif (mclk <= pi->mvdd_split_frequency)\r\nvoltage->index = 0;\r\nelse\r\nvoltage->index = (u8)(si_pi->mvdd_voltage_table.count) - 1;\r\nvoltage->value = cpu_to_be16(si_pi->mvdd_voltage_table.entries[voltage->index].value);\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_get_std_voltage_value(struct radeon_device *rdev,\r\nSISLANDS_SMC_VOLTAGE_VALUE *voltage,\r\nu16 *std_voltage)\r\n{\r\nu16 v_index;\r\nbool voltage_found = false;\r\n*std_voltage = be16_to_cpu(voltage->value);\r\nif (rdev->pm.dpm.dyn_state.cac_leakage_table.entries) {\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_NEW_CAC_VOLTAGE) {\r\nif (rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries == NULL)\r\nreturn -EINVAL;\r\nfor (v_index = 0; (u32)v_index < rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count; v_index++) {\r\nif (be16_to_cpu(voltage->value) ==\r\n(u16)rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[v_index].v) {\r\nvoltage_found = true;\r\nif ((u32)v_index < rdev->pm.dpm.dyn_state.cac_leakage_table.count)\r\n*std_voltage =\r\nrdev->pm.dpm.dyn_state.cac_leakage_table.entries[v_index].vddc;\r\nelse\r\n*std_voltage =\r\nrdev->pm.dpm.dyn_state.cac_leakage_table.entries[rdev->pm.dpm.dyn_state.cac_leakage_table.count-1].vddc;\r\nbreak;\r\n}\r\n}\r\nif (!voltage_found) {\r\nfor (v_index = 0; (u32)v_index < rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count; v_index++) {\r\nif (be16_to_cpu(voltage->value) <=\r\n(u16)rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[v_index].v) {\r\nvoltage_found = true;\r\nif ((u32)v_index < rdev->pm.dpm.dyn_state.cac_leakage_table.count)\r\n*std_voltage =\r\nrdev->pm.dpm.dyn_state.cac_leakage_table.entries[v_index].vddc;\r\nelse\r\n*std_voltage =\r\nrdev->pm.dpm.dyn_state.cac_leakage_table.entries[rdev->pm.dpm.dyn_state.cac_leakage_table.count-1].vddc;\r\nbreak;\r\n}\r\n}\r\n}\r\n} else {\r\nif ((u32)voltage->index < rdev->pm.dpm.dyn_state.cac_leakage_table.count)\r\n*std_voltage = rdev->pm.dpm.dyn_state.cac_leakage_table.entries[voltage->index].vddc;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_populate_std_voltage_value(struct radeon_device *rdev,\r\nu16 value, u8 index,\r\nSISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nvoltage->index = index;\r\nvoltage->value = cpu_to_be16(value);\r\nreturn 0;\r\n}\r\nstatic int si_populate_phase_shedding_value(struct radeon_device *rdev,\r\nconst struct radeon_phase_shedding_limits_table *limits,\r\nu16 voltage, u32 sclk, u32 mclk,\r\nSISLANDS_SMC_VOLTAGE_VALUE *smc_voltage)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < limits->count; i++) {\r\nif ((voltage <= limits->entries[i].voltage) &&\r\n(sclk <= limits->entries[i].sclk) &&\r\n(mclk <= limits->entries[i].mclk))\r\nbreak;\r\n}\r\nsmc_voltage->phase_settings = (u8)i;\r\nreturn 0;\r\n}\r\nstatic int si_init_arb_table_index(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 tmp;\r\nint ret;\r\nret = si_read_smc_sram_dword(rdev, si_pi->arb_table_start, &tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\ntmp &= 0x00FFFFFF;\r\ntmp |= MC_CG_ARB_FREQ_F1 << 24;\r\nreturn si_write_smc_sram_dword(rdev, si_pi->arb_table_start, tmp, si_pi->sram_end);\r\n}\r\nstatic int si_initial_switch_from_arb_f0_to_f1(struct radeon_device *rdev)\r\n{\r\nreturn ni_copy_and_switch_arb_sets(rdev, MC_CG_ARB_FREQ_F0, MC_CG_ARB_FREQ_F1);\r\n}\r\nstatic int si_reset_to_default(struct radeon_device *rdev)\r\n{\r\nreturn (si_send_msg_to_smc(rdev, PPSMC_MSG_ResetToDefaults) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nstatic int si_force_switch_to_arb_f0(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 tmp;\r\nint ret;\r\nret = si_read_smc_sram_dword(rdev, si_pi->arb_table_start,\r\n&tmp, si_pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\ntmp = (tmp >> 24) & 0xff;\r\nif (tmp == MC_CG_ARB_FREQ_F0)\r\nreturn 0;\r\nreturn ni_copy_and_switch_arb_sets(rdev, tmp, MC_CG_ARB_FREQ_F0);\r\n}\r\nstatic u32 si_calculate_memory_refresh_rate(struct radeon_device *rdev,\r\nu32 engine_clock)\r\n{\r\nu32 dram_rows;\r\nu32 dram_refresh_rate;\r\nu32 mc_arb_rfsh_rate;\r\nu32 tmp = (RREG32(MC_ARB_RAMCFG) & NOOFROWS_MASK) >> NOOFROWS_SHIFT;\r\nif (tmp >= 4)\r\ndram_rows = 16384;\r\nelse\r\ndram_rows = 1 << (tmp + 10);\r\ndram_refresh_rate = 1 << ((RREG32(MC_SEQ_MISC0) & 0x3) + 3);\r\nmc_arb_rfsh_rate = ((engine_clock * 10) * dram_refresh_rate / dram_rows - 32) / 64;\r\nreturn mc_arb_rfsh_rate;\r\n}\r\nstatic int si_populate_memory_timing_parameters(struct radeon_device *rdev,\r\nstruct rv7xx_pl *pl,\r\nSMC_SIslands_MCArbDramTimingRegisterSet *arb_regs)\r\n{\r\nu32 dram_timing;\r\nu32 dram_timing2;\r\nu32 burst_time;\r\narb_regs->mc_arb_rfsh_rate =\r\n(u8)si_calculate_memory_refresh_rate(rdev, pl->sclk);\r\nradeon_atom_set_engine_dram_timings(rdev,\r\npl->sclk,\r\npl->mclk);\r\ndram_timing = RREG32(MC_ARB_DRAM_TIMING);\r\ndram_timing2 = RREG32(MC_ARB_DRAM_TIMING2);\r\nburst_time = RREG32(MC_ARB_BURST_TIME) & STATE0_MASK;\r\narb_regs->mc_arb_dram_timing = cpu_to_be32(dram_timing);\r\narb_regs->mc_arb_dram_timing2 = cpu_to_be32(dram_timing2);\r\narb_regs->mc_arb_burst_time = (u8)burst_time;\r\nreturn 0;\r\n}\r\nstatic int si_do_program_memory_timing_parameters(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nunsigned int first_arb_set)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nSMC_SIslands_MCArbDramTimingRegisterSet arb_regs = { 0 };\r\nint i, ret = 0;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nret = si_populate_memory_timing_parameters(rdev, &state->performance_levels[i], &arb_regs);\r\nif (ret)\r\nbreak;\r\nret = si_copy_bytes_to_smc(rdev,\r\nsi_pi->arb_table_start +\r\noffsetof(SMC_SIslands_MCArbDramTimingRegisters, data) +\r\nsizeof(SMC_SIslands_MCArbDramTimingRegisterSet) * (first_arb_set + i),\r\n(u8 *)&arb_regs,\r\nsizeof(SMC_SIslands_MCArbDramTimingRegisterSet),\r\nsi_pi->sram_end);\r\nif (ret)\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int si_program_memory_timing_parameters(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state)\r\n{\r\nreturn si_do_program_memory_timing_parameters(rdev, radeon_new_state,\r\nSISLANDS_DRIVER_STATE_ARB_INDEX);\r\n}\r\nstatic int si_populate_initial_mvdd_value(struct radeon_device *rdev,\r\nstruct SISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nif (pi->mvdd_control)\r\nreturn si_populate_voltage_value(rdev, &si_pi->mvdd_voltage_table,\r\nsi_pi->mvdd_bootup_value, voltage);\r\nreturn 0;\r\n}\r\nstatic int si_populate_smc_initial_state(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_initial_state,\r\nSISLANDS_SMC_STATETABLE *table)\r\n{\r\nstruct ni_ps *initial_state = ni_get_ps(radeon_initial_state);\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 reg;\r\nint ret;\r\ntable->initialState.levels[0].mclk.vDLL_CNTL =\r\ncpu_to_be32(si_pi->clock_registers.dll_cntl);\r\ntable->initialState.levels[0].mclk.vMCLK_PWRMGT_CNTL =\r\ncpu_to_be32(si_pi->clock_registers.mclk_pwrmgt_cntl);\r\ntable->initialState.levels[0].mclk.vMPLL_AD_FUNC_CNTL =\r\ncpu_to_be32(si_pi->clock_registers.mpll_ad_func_cntl);\r\ntable->initialState.levels[0].mclk.vMPLL_DQ_FUNC_CNTL =\r\ncpu_to_be32(si_pi->clock_registers.mpll_dq_func_cntl);\r\ntable->initialState.levels[0].mclk.vMPLL_FUNC_CNTL =\r\ncpu_to_be32(si_pi->clock_registers.mpll_func_cntl);\r\ntable->initialState.levels[0].mclk.vMPLL_FUNC_CNTL_1 =\r\ncpu_to_be32(si_pi->clock_registers.mpll_func_cntl_1);\r\ntable->initialState.levels[0].mclk.vMPLL_FUNC_CNTL_2 =\r\ncpu_to_be32(si_pi->clock_registers.mpll_func_cntl_2);\r\ntable->initialState.levels[0].mclk.vMPLL_SS =\r\ncpu_to_be32(si_pi->clock_registers.mpll_ss1);\r\ntable->initialState.levels[0].mclk.vMPLL_SS2 =\r\ncpu_to_be32(si_pi->clock_registers.mpll_ss2);\r\ntable->initialState.levels[0].mclk.mclk_value =\r\ncpu_to_be32(initial_state->performance_levels[0].mclk);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL =\r\ncpu_to_be32(si_pi->clock_registers.cg_spll_func_cntl);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_2 =\r\ncpu_to_be32(si_pi->clock_registers.cg_spll_func_cntl_2);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_3 =\r\ncpu_to_be32(si_pi->clock_registers.cg_spll_func_cntl_3);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_4 =\r\ncpu_to_be32(si_pi->clock_registers.cg_spll_func_cntl_4);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_SPREAD_SPECTRUM =\r\ncpu_to_be32(si_pi->clock_registers.cg_spll_spread_spectrum);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_SPREAD_SPECTRUM_2 =\r\ncpu_to_be32(si_pi->clock_registers.cg_spll_spread_spectrum_2);\r\ntable->initialState.levels[0].sclk.sclk_value =\r\ncpu_to_be32(initial_state->performance_levels[0].sclk);\r\ntable->initialState.levels[0].arbRefreshState =\r\nSISLANDS_INITIAL_STATE_ARB_INDEX;\r\ntable->initialState.levels[0].ACIndex = 0;\r\nret = si_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\ninitial_state->performance_levels[0].vddc,\r\n&table->initialState.levels[0].vddc);\r\nif (!ret) {\r\nu16 std_vddc;\r\nret = si_get_std_voltage_value(rdev,\r\n&table->initialState.levels[0].vddc,\r\n&std_vddc);\r\nif (!ret)\r\nsi_populate_std_voltage_value(rdev, std_vddc,\r\ntable->initialState.levels[0].vddc.index,\r\n&table->initialState.levels[0].std_vddc);\r\n}\r\nif (eg_pi->vddci_control)\r\nsi_populate_voltage_value(rdev,\r\n&eg_pi->vddci_voltage_table,\r\ninitial_state->performance_levels[0].vddci,\r\n&table->initialState.levels[0].vddci);\r\nif (si_pi->vddc_phase_shed_control)\r\nsi_populate_phase_shedding_value(rdev,\r\n&rdev->pm.dpm.dyn_state.phase_shedding_limits_table,\r\ninitial_state->performance_levels[0].vddc,\r\ninitial_state->performance_levels[0].sclk,\r\ninitial_state->performance_levels[0].mclk,\r\n&table->initialState.levels[0].vddc);\r\nsi_populate_initial_mvdd_value(rdev, &table->initialState.levels[0].mvdd);\r\nreg = CG_R(0xffff) | CG_L(0);\r\ntable->initialState.levels[0].aT = cpu_to_be32(reg);\r\ntable->initialState.levels[0].bSP = cpu_to_be32(pi->dsp);\r\ntable->initialState.levels[0].gen2PCIE = (u8)si_pi->boot_pcie_gen;\r\nif (pi->mem_gddr5) {\r\ntable->initialState.levels[0].strobeMode =\r\nsi_get_strobe_mode_settings(rdev,\r\ninitial_state->performance_levels[0].mclk);\r\nif (initial_state->performance_levels[0].mclk > pi->mclk_edc_enable_threshold)\r\ntable->initialState.levels[0].mcFlags = SISLANDS_SMC_MC_EDC_RD_FLAG | SISLANDS_SMC_MC_EDC_WR_FLAG;\r\nelse\r\ntable->initialState.levels[0].mcFlags = 0;\r\n}\r\ntable->initialState.levelCount = 1;\r\ntable->initialState.flags |= PPSMC_SWSTATE_FLAG_DC;\r\ntable->initialState.levels[0].dpm2.MaxPS = 0;\r\ntable->initialState.levels[0].dpm2.NearTDPDec = 0;\r\ntable->initialState.levels[0].dpm2.AboveSafeInc = 0;\r\ntable->initialState.levels[0].dpm2.BelowSafeInc = 0;\r\ntable->initialState.levels[0].dpm2.PwrEfficiencyRatio = 0;\r\nreg = MIN_POWER_MASK | MAX_POWER_MASK;\r\ntable->initialState.levels[0].SQPowerThrottle = cpu_to_be32(reg);\r\nreg = MAX_POWER_DELTA_MASK | STI_SIZE_MASK | LTI_RATIO_MASK;\r\ntable->initialState.levels[0].SQPowerThrottle_2 = cpu_to_be32(reg);\r\nreturn 0;\r\n}\r\nstatic int si_populate_smc_acpi_state(struct radeon_device *rdev,\r\nSISLANDS_SMC_STATETABLE *table)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 spll_func_cntl = si_pi->clock_registers.cg_spll_func_cntl;\r\nu32 spll_func_cntl_2 = si_pi->clock_registers.cg_spll_func_cntl_2;\r\nu32 spll_func_cntl_3 = si_pi->clock_registers.cg_spll_func_cntl_3;\r\nu32 spll_func_cntl_4 = si_pi->clock_registers.cg_spll_func_cntl_4;\r\nu32 dll_cntl = si_pi->clock_registers.dll_cntl;\r\nu32 mclk_pwrmgt_cntl = si_pi->clock_registers.mclk_pwrmgt_cntl;\r\nu32 mpll_ad_func_cntl = si_pi->clock_registers.mpll_ad_func_cntl;\r\nu32 mpll_dq_func_cntl = si_pi->clock_registers.mpll_dq_func_cntl;\r\nu32 mpll_func_cntl = si_pi->clock_registers.mpll_func_cntl;\r\nu32 mpll_func_cntl_1 = si_pi->clock_registers.mpll_func_cntl_1;\r\nu32 mpll_func_cntl_2 = si_pi->clock_registers.mpll_func_cntl_2;\r\nu32 reg;\r\nint ret;\r\ntable->ACPIState = table->initialState;\r\ntable->ACPIState.flags &= ~PPSMC_SWSTATE_FLAG_DC;\r\nif (pi->acpi_vddc) {\r\nret = si_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\npi->acpi_vddc, &table->ACPIState.levels[0].vddc);\r\nif (!ret) {\r\nu16 std_vddc;\r\nret = si_get_std_voltage_value(rdev,\r\n&table->ACPIState.levels[0].vddc, &std_vddc);\r\nif (!ret)\r\nsi_populate_std_voltage_value(rdev, std_vddc,\r\ntable->ACPIState.levels[0].vddc.index,\r\n&table->ACPIState.levels[0].std_vddc);\r\n}\r\ntable->ACPIState.levels[0].gen2PCIE = si_pi->acpi_pcie_gen;\r\nif (si_pi->vddc_phase_shed_control) {\r\nsi_populate_phase_shedding_value(rdev,\r\n&rdev->pm.dpm.dyn_state.phase_shedding_limits_table,\r\npi->acpi_vddc,\r\n0,\r\n0,\r\n&table->ACPIState.levels[0].vddc);\r\n}\r\n} else {\r\nret = si_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\npi->min_vddc_in_table, &table->ACPIState.levels[0].vddc);\r\nif (!ret) {\r\nu16 std_vddc;\r\nret = si_get_std_voltage_value(rdev,\r\n&table->ACPIState.levels[0].vddc, &std_vddc);\r\nif (!ret)\r\nsi_populate_std_voltage_value(rdev, std_vddc,\r\ntable->ACPIState.levels[0].vddc.index,\r\n&table->ACPIState.levels[0].std_vddc);\r\n}\r\ntable->ACPIState.levels[0].gen2PCIE = (u8)r600_get_pcie_gen_support(rdev,\r\nsi_pi->sys_pcie_mask,\r\nsi_pi->boot_pcie_gen,\r\nRADEON_PCIE_GEN1);\r\nif (si_pi->vddc_phase_shed_control)\r\nsi_populate_phase_shedding_value(rdev,\r\n&rdev->pm.dpm.dyn_state.phase_shedding_limits_table,\r\npi->min_vddc_in_table,\r\n0,\r\n0,\r\n&table->ACPIState.levels[0].vddc);\r\n}\r\nif (pi->acpi_vddc) {\r\nif (eg_pi->acpi_vddci)\r\nsi_populate_voltage_value(rdev, &eg_pi->vddci_voltage_table,\r\neg_pi->acpi_vddci,\r\n&table->ACPIState.levels[0].vddci);\r\n}\r\nmclk_pwrmgt_cntl |= MRDCK0_RESET | MRDCK1_RESET;\r\nmclk_pwrmgt_cntl &= ~(MRDCK0_PDNB | MRDCK1_PDNB);\r\ndll_cntl &= ~(MRDCK0_BYPASS | MRDCK1_BYPASS);\r\nspll_func_cntl_2 &= ~SCLK_MUX_SEL_MASK;\r\nspll_func_cntl_2 |= SCLK_MUX_SEL(4);\r\ntable->ACPIState.levels[0].mclk.vDLL_CNTL =\r\ncpu_to_be32(dll_cntl);\r\ntable->ACPIState.levels[0].mclk.vMCLK_PWRMGT_CNTL =\r\ncpu_to_be32(mclk_pwrmgt_cntl);\r\ntable->ACPIState.levels[0].mclk.vMPLL_AD_FUNC_CNTL =\r\ncpu_to_be32(mpll_ad_func_cntl);\r\ntable->ACPIState.levels[0].mclk.vMPLL_DQ_FUNC_CNTL =\r\ncpu_to_be32(mpll_dq_func_cntl);\r\ntable->ACPIState.levels[0].mclk.vMPLL_FUNC_CNTL =\r\ncpu_to_be32(mpll_func_cntl);\r\ntable->ACPIState.levels[0].mclk.vMPLL_FUNC_CNTL_1 =\r\ncpu_to_be32(mpll_func_cntl_1);\r\ntable->ACPIState.levels[0].mclk.vMPLL_FUNC_CNTL_2 =\r\ncpu_to_be32(mpll_func_cntl_2);\r\ntable->ACPIState.levels[0].mclk.vMPLL_SS =\r\ncpu_to_be32(si_pi->clock_registers.mpll_ss1);\r\ntable->ACPIState.levels[0].mclk.vMPLL_SS2 =\r\ncpu_to_be32(si_pi->clock_registers.mpll_ss2);\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL =\r\ncpu_to_be32(spll_func_cntl);\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_2 =\r\ncpu_to_be32(spll_func_cntl_2);\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_3 =\r\ncpu_to_be32(spll_func_cntl_3);\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_4 =\r\ncpu_to_be32(spll_func_cntl_4);\r\ntable->ACPIState.levels[0].mclk.mclk_value = 0;\r\ntable->ACPIState.levels[0].sclk.sclk_value = 0;\r\nsi_populate_mvdd_value(rdev, 0, &table->ACPIState.levels[0].mvdd);\r\nif (eg_pi->dynamic_ac_timing)\r\ntable->ACPIState.levels[0].ACIndex = 0;\r\ntable->ACPIState.levels[0].dpm2.MaxPS = 0;\r\ntable->ACPIState.levels[0].dpm2.NearTDPDec = 0;\r\ntable->ACPIState.levels[0].dpm2.AboveSafeInc = 0;\r\ntable->ACPIState.levels[0].dpm2.BelowSafeInc = 0;\r\ntable->ACPIState.levels[0].dpm2.PwrEfficiencyRatio = 0;\r\nreg = MIN_POWER_MASK | MAX_POWER_MASK;\r\ntable->ACPIState.levels[0].SQPowerThrottle = cpu_to_be32(reg);\r\nreg = MAX_POWER_DELTA_MASK | STI_SIZE_MASK | LTI_RATIO_MASK;\r\ntable->ACPIState.levels[0].SQPowerThrottle_2 = cpu_to_be32(reg);\r\nreturn 0;\r\n}\r\nstatic int si_populate_ulv_state(struct radeon_device *rdev,\r\nSISLANDS_SMC_SWSTATE *state)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct si_ulv_param *ulv = &si_pi->ulv;\r\nu32 sclk_in_sr = 1350;\r\nint ret;\r\nret = si_convert_power_level_to_smc(rdev, &ulv->pl,\r\n&state->levels[0]);\r\nif (!ret) {\r\nif (eg_pi->sclk_deep_sleep) {\r\nif (sclk_in_sr <= SCLK_MIN_DEEPSLEEP_FREQ)\r\nstate->levels[0].stateFlags |= PPSMC_STATEFLAG_DEEPSLEEP_BYPASS;\r\nelse\r\nstate->levels[0].stateFlags |= PPSMC_STATEFLAG_DEEPSLEEP_THROTTLE;\r\n}\r\nif (ulv->one_pcie_lane_in_ulv)\r\nstate->flags |= PPSMC_SWSTATE_FLAG_PCIE_X1;\r\nstate->levels[0].arbRefreshState = (u8)(SISLANDS_ULV_STATE_ARB_INDEX);\r\nstate->levels[0].ACIndex = 1;\r\nstate->levels[0].std_vddc = state->levels[0].vddc;\r\nstate->levelCount = 1;\r\nstate->flags |= PPSMC_SWSTATE_FLAG_DC;\r\n}\r\nreturn ret;\r\n}\r\nstatic int si_program_ulv_memory_timing_parameters(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct si_ulv_param *ulv = &si_pi->ulv;\r\nSMC_SIslands_MCArbDramTimingRegisterSet arb_regs = { 0 };\r\nint ret;\r\nret = si_populate_memory_timing_parameters(rdev, &ulv->pl,\r\n&arb_regs);\r\nif (ret)\r\nreturn ret;\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_ulv_volt_change_delay,\r\nulv->volt_change_delay);\r\nret = si_copy_bytes_to_smc(rdev,\r\nsi_pi->arb_table_start +\r\noffsetof(SMC_SIslands_MCArbDramTimingRegisters, data) +\r\nsizeof(SMC_SIslands_MCArbDramTimingRegisterSet) * SISLANDS_ULV_STATE_ARB_INDEX,\r\n(u8 *)&arb_regs,\r\nsizeof(SMC_SIslands_MCArbDramTimingRegisterSet),\r\nsi_pi->sram_end);\r\nreturn ret;\r\n}\r\nstatic void si_get_mvdd_configuration(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\npi->mvdd_split_frequency = 30000;\r\n}\r\nstatic int si_init_smc_table(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct radeon_ps *radeon_boot_state = rdev->pm.dpm.boot_ps;\r\nconst struct si_ulv_param *ulv = &si_pi->ulv;\r\nSISLANDS_SMC_STATETABLE *table = &si_pi->smc_statetable;\r\nint ret;\r\nu32 lane_width;\r\nu32 vr_hot_gpio;\r\nsi_populate_smc_voltage_tables(rdev, table);\r\nswitch (rdev->pm.int_thermal_type) {\r\ncase THERMAL_TYPE_SI:\r\ncase THERMAL_TYPE_EMC2103_WITH_INTERNAL:\r\ntable->thermalProtectType = PPSMC_THERMAL_PROTECT_TYPE_INTERNAL;\r\nbreak;\r\ncase THERMAL_TYPE_NONE:\r\ntable->thermalProtectType = PPSMC_THERMAL_PROTECT_TYPE_NONE;\r\nbreak;\r\ndefault:\r\ntable->thermalProtectType = PPSMC_THERMAL_PROTECT_TYPE_EXTERNAL;\r\nbreak;\r\n}\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_HARDWAREDC)\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_GPIO_DC;\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_REGULATOR_HOT) {\r\nif ((rdev->pdev->device != 0x6818) && (rdev->pdev->device != 0x6819))\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_REGULATOR_HOT;\r\n}\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_STEPVDDC)\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_STEPVDDC;\r\nif (pi->mem_gddr5)\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_GDDR5;\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_REVERT_GPIO5_POLARITY)\r\ntable->extraFlags |= PPSMC_EXTRAFLAGS_AC2DC_GPIO5_POLARITY_HIGH;\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_VRHOT_GPIO_CONFIGURABLE) {\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_REGULATOR_HOT_PROG_GPIO;\r\nvr_hot_gpio = rdev->pm.dpm.backbias_response_time;\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_vr_hot_gpio,\r\nvr_hot_gpio);\r\n}\r\nret = si_populate_smc_initial_state(rdev, radeon_boot_state, table);\r\nif (ret)\r\nreturn ret;\r\nret = si_populate_smc_acpi_state(rdev, table);\r\nif (ret)\r\nreturn ret;\r\ntable->driverState = table->initialState;\r\nret = si_do_program_memory_timing_parameters(rdev, radeon_boot_state,\r\nSISLANDS_INITIAL_STATE_ARB_INDEX);\r\nif (ret)\r\nreturn ret;\r\nif (ulv->supported && ulv->pl.vddc) {\r\nret = si_populate_ulv_state(rdev, &table->ULVState);\r\nif (ret)\r\nreturn ret;\r\nret = si_program_ulv_memory_timing_parameters(rdev);\r\nif (ret)\r\nreturn ret;\r\nWREG32(CG_ULV_CONTROL, ulv->cg_ulv_control);\r\nWREG32(CG_ULV_PARAMETER, ulv->cg_ulv_parameter);\r\nlane_width = radeon_get_pcie_lanes(rdev);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_non_ulv_pcie_link_width, lane_width);\r\n} else {\r\ntable->ULVState = table->initialState;\r\n}\r\nreturn si_copy_bytes_to_smc(rdev, si_pi->state_table_start,\r\n(u8 *)table, sizeof(SISLANDS_SMC_STATETABLE),\r\nsi_pi->sram_end);\r\n}\r\nstatic int si_calculate_sclk_params(struct radeon_device *rdev,\r\nu32 engine_clock,\r\nSISLANDS_SMC_SCLK_VALUE *sclk)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct atom_clock_dividers dividers;\r\nu32 spll_func_cntl = si_pi->clock_registers.cg_spll_func_cntl;\r\nu32 spll_func_cntl_2 = si_pi->clock_registers.cg_spll_func_cntl_2;\r\nu32 spll_func_cntl_3 = si_pi->clock_registers.cg_spll_func_cntl_3;\r\nu32 spll_func_cntl_4 = si_pi->clock_registers.cg_spll_func_cntl_4;\r\nu32 cg_spll_spread_spectrum = si_pi->clock_registers.cg_spll_spread_spectrum;\r\nu32 cg_spll_spread_spectrum_2 = si_pi->clock_registers.cg_spll_spread_spectrum_2;\r\nu64 tmp;\r\nu32 reference_clock = rdev->clock.spll.reference_freq;\r\nu32 reference_divider;\r\nu32 fbdiv;\r\nint ret;\r\nret = radeon_atom_get_clock_dividers(rdev, COMPUTE_ENGINE_PLL_PARAM,\r\nengine_clock, false, &dividers);\r\nif (ret)\r\nreturn ret;\r\nreference_divider = 1 + dividers.ref_div;\r\ntmp = (u64) engine_clock * reference_divider * dividers.post_div * 16384;\r\ndo_div(tmp, reference_clock);\r\nfbdiv = (u32) tmp;\r\nspll_func_cntl &= ~(SPLL_PDIV_A_MASK | SPLL_REF_DIV_MASK);\r\nspll_func_cntl |= SPLL_REF_DIV(dividers.ref_div);\r\nspll_func_cntl |= SPLL_PDIV_A(dividers.post_div);\r\nspll_func_cntl_2 &= ~SCLK_MUX_SEL_MASK;\r\nspll_func_cntl_2 |= SCLK_MUX_SEL(2);\r\nspll_func_cntl_3 &= ~SPLL_FB_DIV_MASK;\r\nspll_func_cntl_3 |= SPLL_FB_DIV(fbdiv);\r\nspll_func_cntl_3 |= SPLL_DITHEN;\r\nif (pi->sclk_ss) {\r\nstruct radeon_atom_ss ss;\r\nu32 vco_freq = engine_clock * dividers.post_div;\r\nif (radeon_atombios_get_asic_ss_info(rdev, &ss,\r\nASIC_INTERNAL_ENGINE_SS, vco_freq)) {\r\nu32 clk_s = reference_clock * 5 / (reference_divider * ss.rate);\r\nu32 clk_v = 4 * ss.percentage * fbdiv / (clk_s * 10000);\r\ncg_spll_spread_spectrum &= ~CLK_S_MASK;\r\ncg_spll_spread_spectrum |= CLK_S(clk_s);\r\ncg_spll_spread_spectrum |= SSEN;\r\ncg_spll_spread_spectrum_2 &= ~CLK_V_MASK;\r\ncg_spll_spread_spectrum_2 |= CLK_V(clk_v);\r\n}\r\n}\r\nsclk->sclk_value = engine_clock;\r\nsclk->vCG_SPLL_FUNC_CNTL = spll_func_cntl;\r\nsclk->vCG_SPLL_FUNC_CNTL_2 = spll_func_cntl_2;\r\nsclk->vCG_SPLL_FUNC_CNTL_3 = spll_func_cntl_3;\r\nsclk->vCG_SPLL_FUNC_CNTL_4 = spll_func_cntl_4;\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM = cg_spll_spread_spectrum;\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM_2 = cg_spll_spread_spectrum_2;\r\nreturn 0;\r\n}\r\nstatic int si_populate_sclk_value(struct radeon_device *rdev,\r\nu32 engine_clock,\r\nSISLANDS_SMC_SCLK_VALUE *sclk)\r\n{\r\nSISLANDS_SMC_SCLK_VALUE sclk_tmp;\r\nint ret;\r\nret = si_calculate_sclk_params(rdev, engine_clock, &sclk_tmp);\r\nif (!ret) {\r\nsclk->sclk_value = cpu_to_be32(sclk_tmp.sclk_value);\r\nsclk->vCG_SPLL_FUNC_CNTL = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL);\r\nsclk->vCG_SPLL_FUNC_CNTL_2 = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL_2);\r\nsclk->vCG_SPLL_FUNC_CNTL_3 = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL_3);\r\nsclk->vCG_SPLL_FUNC_CNTL_4 = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL_4);\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM = cpu_to_be32(sclk_tmp.vCG_SPLL_SPREAD_SPECTRUM);\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM_2 = cpu_to_be32(sclk_tmp.vCG_SPLL_SPREAD_SPECTRUM_2);\r\n}\r\nreturn ret;\r\n}\r\nstatic int si_populate_mclk_value(struct radeon_device *rdev,\r\nu32 engine_clock,\r\nu32 memory_clock,\r\nSISLANDS_SMC_MCLK_VALUE *mclk,\r\nbool strobe_mode,\r\nbool dll_state_on)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 dll_cntl = si_pi->clock_registers.dll_cntl;\r\nu32 mclk_pwrmgt_cntl = si_pi->clock_registers.mclk_pwrmgt_cntl;\r\nu32 mpll_ad_func_cntl = si_pi->clock_registers.mpll_ad_func_cntl;\r\nu32 mpll_dq_func_cntl = si_pi->clock_registers.mpll_dq_func_cntl;\r\nu32 mpll_func_cntl = si_pi->clock_registers.mpll_func_cntl;\r\nu32 mpll_func_cntl_1 = si_pi->clock_registers.mpll_func_cntl_1;\r\nu32 mpll_func_cntl_2 = si_pi->clock_registers.mpll_func_cntl_2;\r\nu32 mpll_ss1 = si_pi->clock_registers.mpll_ss1;\r\nu32 mpll_ss2 = si_pi->clock_registers.mpll_ss2;\r\nstruct atom_mpll_param mpll_param;\r\nint ret;\r\nret = radeon_atom_get_memory_pll_dividers(rdev, memory_clock, strobe_mode, &mpll_param);\r\nif (ret)\r\nreturn ret;\r\nmpll_func_cntl &= ~BWCTRL_MASK;\r\nmpll_func_cntl |= BWCTRL(mpll_param.bwcntl);\r\nmpll_func_cntl_1 &= ~(CLKF_MASK | CLKFRAC_MASK | VCO_MODE_MASK);\r\nmpll_func_cntl_1 |= CLKF(mpll_param.clkf) |\r\nCLKFRAC(mpll_param.clkfrac) | VCO_MODE(mpll_param.vco_mode);\r\nmpll_ad_func_cntl &= ~YCLK_POST_DIV_MASK;\r\nmpll_ad_func_cntl |= YCLK_POST_DIV(mpll_param.post_div);\r\nif (pi->mem_gddr5) {\r\nmpll_dq_func_cntl &= ~(YCLK_SEL_MASK | YCLK_POST_DIV_MASK);\r\nmpll_dq_func_cntl |= YCLK_SEL(mpll_param.yclk_sel) |\r\nYCLK_POST_DIV(mpll_param.post_div);\r\n}\r\nif (pi->mclk_ss) {\r\nstruct radeon_atom_ss ss;\r\nu32 freq_nom;\r\nu32 tmp;\r\nu32 reference_clock = rdev->clock.mpll.reference_freq;\r\nif (pi->mem_gddr5)\r\nfreq_nom = memory_clock * 4;\r\nelse\r\nfreq_nom = memory_clock * 2;\r\ntmp = freq_nom / reference_clock;\r\ntmp = tmp * tmp;\r\nif (radeon_atombios_get_asic_ss_info(rdev, &ss,\r\nASIC_INTERNAL_MEMORY_SS, freq_nom)) {\r\nu32 clks = reference_clock * 5 / ss.rate;\r\nu32 clkv = (u32)((((131 * ss.percentage * ss.rate) / 100) * tmp) / freq_nom);\r\nmpll_ss1 &= ~CLKV_MASK;\r\nmpll_ss1 |= CLKV(clkv);\r\nmpll_ss2 &= ~CLKS_MASK;\r\nmpll_ss2 |= CLKS(clks);\r\n}\r\n}\r\nmclk_pwrmgt_cntl &= ~DLL_SPEED_MASK;\r\nmclk_pwrmgt_cntl |= DLL_SPEED(mpll_param.dll_speed);\r\nif (dll_state_on)\r\nmclk_pwrmgt_cntl |= MRDCK0_PDNB | MRDCK1_PDNB;\r\nelse\r\nmclk_pwrmgt_cntl &= ~(MRDCK0_PDNB | MRDCK1_PDNB);\r\nmclk->mclk_value = cpu_to_be32(memory_clock);\r\nmclk->vMPLL_FUNC_CNTL = cpu_to_be32(mpll_func_cntl);\r\nmclk->vMPLL_FUNC_CNTL_1 = cpu_to_be32(mpll_func_cntl_1);\r\nmclk->vMPLL_FUNC_CNTL_2 = cpu_to_be32(mpll_func_cntl_2);\r\nmclk->vMPLL_AD_FUNC_CNTL = cpu_to_be32(mpll_ad_func_cntl);\r\nmclk->vMPLL_DQ_FUNC_CNTL = cpu_to_be32(mpll_dq_func_cntl);\r\nmclk->vMCLK_PWRMGT_CNTL = cpu_to_be32(mclk_pwrmgt_cntl);\r\nmclk->vDLL_CNTL = cpu_to_be32(dll_cntl);\r\nmclk->vMPLL_SS = cpu_to_be32(mpll_ss1);\r\nmclk->vMPLL_SS2 = cpu_to_be32(mpll_ss2);\r\nreturn 0;\r\n}\r\nstatic void si_populate_smc_sp(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nSISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct ni_ps *ps = ni_get_ps(radeon_state);\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nint i;\r\nfor (i = 0; i < ps->performance_level_count - 1; i++)\r\nsmc_state->levels[i].bSP = cpu_to_be32(pi->dsp);\r\nsmc_state->levels[ps->performance_level_count - 1].bSP =\r\ncpu_to_be32(pi->psp);\r\n}\r\nstatic int si_convert_power_level_to_smc(struct radeon_device *rdev,\r\nstruct rv7xx_pl *pl,\r\nSISLANDS_SMC_HW_PERFORMANCE_LEVEL *level)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nint ret;\r\nbool dll_state_on;\r\nu16 std_vddc;\r\nbool gmc_pg = false;\r\nif (eg_pi->pcie_performance_request &&\r\n(si_pi->force_pcie_gen != RADEON_PCIE_GEN_INVALID))\r\nlevel->gen2PCIE = (u8)si_pi->force_pcie_gen;\r\nelse\r\nlevel->gen2PCIE = (u8)pl->pcie_gen;\r\nret = si_populate_sclk_value(rdev, pl->sclk, &level->sclk);\r\nif (ret)\r\nreturn ret;\r\nlevel->mcFlags = 0;\r\nif (pi->mclk_stutter_mode_threshold &&\r\n(pl->mclk <= pi->mclk_stutter_mode_threshold) &&\r\n!eg_pi->uvd_enabled &&\r\n(RREG32(DPG_PIPE_STUTTER_CONTROL) & STUTTER_ENABLE) &&\r\n(rdev->pm.dpm.new_active_crtc_count <= 2)) {\r\nlevel->mcFlags |= SISLANDS_SMC_MC_STUTTER_EN;\r\nif (gmc_pg)\r\nlevel->mcFlags |= SISLANDS_SMC_MC_PG_EN;\r\n}\r\nif (pi->mem_gddr5) {\r\nif (pl->mclk > pi->mclk_edc_enable_threshold)\r\nlevel->mcFlags |= SISLANDS_SMC_MC_EDC_RD_FLAG;\r\nif (pl->mclk > eg_pi->mclk_edc_wr_enable_threshold)\r\nlevel->mcFlags |= SISLANDS_SMC_MC_EDC_WR_FLAG;\r\nlevel->strobeMode = si_get_strobe_mode_settings(rdev, pl->mclk);\r\nif (level->strobeMode & SISLANDS_SMC_STROBE_ENABLE) {\r\nif (si_get_mclk_frequency_ratio(pl->mclk, true) >=\r\n((RREG32(MC_SEQ_MISC7) >> 16) & 0xf))\r\ndll_state_on = ((RREG32(MC_SEQ_MISC5) >> 1) & 0x1) ? true : false;\r\nelse\r\ndll_state_on = ((RREG32(MC_SEQ_MISC6) >> 1) & 0x1) ? true : false;\r\n} else {\r\ndll_state_on = false;\r\n}\r\n} else {\r\nlevel->strobeMode = si_get_strobe_mode_settings(rdev,\r\npl->mclk);\r\ndll_state_on = ((RREG32(MC_SEQ_MISC5) >> 1) & 0x1) ? true : false;\r\n}\r\nret = si_populate_mclk_value(rdev,\r\npl->sclk,\r\npl->mclk,\r\n&level->mclk,\r\n(level->strobeMode & SISLANDS_SMC_STROBE_ENABLE) != 0, dll_state_on);\r\nif (ret)\r\nreturn ret;\r\nret = si_populate_voltage_value(rdev,\r\n&eg_pi->vddc_voltage_table,\r\npl->vddc, &level->vddc);\r\nif (ret)\r\nreturn ret;\r\nret = si_get_std_voltage_value(rdev, &level->vddc, &std_vddc);\r\nif (ret)\r\nreturn ret;\r\nret = si_populate_std_voltage_value(rdev, std_vddc,\r\nlevel->vddc.index, &level->std_vddc);\r\nif (ret)\r\nreturn ret;\r\nif (eg_pi->vddci_control) {\r\nret = si_populate_voltage_value(rdev, &eg_pi->vddci_voltage_table,\r\npl->vddci, &level->vddci);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (si_pi->vddc_phase_shed_control) {\r\nret = si_populate_phase_shedding_value(rdev,\r\n&rdev->pm.dpm.dyn_state.phase_shedding_limits_table,\r\npl->vddc,\r\npl->sclk,\r\npl->mclk,\r\n&level->vddc);\r\nif (ret)\r\nreturn ret;\r\n}\r\nlevel->MaxPoweredUpCU = si_pi->max_cu;\r\nret = si_populate_mvdd_value(rdev, pl->mclk, &level->mvdd);\r\nreturn ret;\r\n}\r\nstatic int si_populate_smc_t(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nSISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nu32 a_t;\r\nu32 t_l, t_h;\r\nu32 high_bsp;\r\nint i, ret;\r\nif (state->performance_level_count >= 9)\r\nreturn -EINVAL;\r\nif (state->performance_level_count < 2) {\r\na_t = CG_R(0xffff) | CG_L(0);\r\nsmc_state->levels[0].aT = cpu_to_be32(a_t);\r\nreturn 0;\r\n}\r\nsmc_state->levels[0].aT = cpu_to_be32(0);\r\nfor (i = 0; i <= state->performance_level_count - 2; i++) {\r\nret = r600_calculate_at(\r\n(50 / SISLANDS_MAX_HARDWARE_POWERLEVELS) * 100 * (i + 1),\r\n100 * R600_AH_DFLT,\r\nstate->performance_levels[i + 1].sclk,\r\nstate->performance_levels[i].sclk,\r\n&t_l,\r\n&t_h);\r\nif (ret) {\r\nt_h = (i + 1) * 1000 - 50 * R600_AH_DFLT;\r\nt_l = (i + 1) * 1000 + 50 * R600_AH_DFLT;\r\n}\r\na_t = be32_to_cpu(smc_state->levels[i].aT) & ~CG_R_MASK;\r\na_t |= CG_R(t_l * pi->bsp / 20000);\r\nsmc_state->levels[i].aT = cpu_to_be32(a_t);\r\nhigh_bsp = (i == state->performance_level_count - 2) ?\r\npi->pbsp : pi->bsp;\r\na_t = CG_R(0xffff) | CG_L(t_h * high_bsp / 20000);\r\nsmc_state->levels[i + 1].aT = cpu_to_be32(a_t);\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_disable_ulv(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct si_ulv_param *ulv = &si_pi->ulv;\r\nif (ulv->supported)\r\nreturn (si_send_msg_to_smc(rdev, PPSMC_MSG_DisableULV) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\nreturn 0;\r\n}\r\nstatic bool si_is_state_ulv_compatible(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state)\r\n{\r\nconst struct si_power_info *si_pi = si_get_pi(rdev);\r\nconst struct si_ulv_param *ulv = &si_pi->ulv;\r\nconst struct ni_ps *state = ni_get_ps(radeon_state);\r\nint i;\r\nif (state->performance_levels[0].mclk != ulv->pl.mclk)\r\nreturn false;\r\nfor (i = 0; i < rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.count; i++) {\r\nif (rdev->clock.current_dispclk <=\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[i].clk) {\r\nif (ulv->pl.vddc <\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[i].v)\r\nreturn false;\r\n}\r\n}\r\nif ((radeon_state->vclk != 0) || (radeon_state->dclk != 0))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int si_set_power_state_conditionally_enable_ulv(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state)\r\n{\r\nconst struct si_power_info *si_pi = si_get_pi(rdev);\r\nconst struct si_ulv_param *ulv = &si_pi->ulv;\r\nif (ulv->supported) {\r\nif (si_is_state_ulv_compatible(rdev, radeon_new_state))\r\nreturn (si_send_msg_to_smc(rdev, PPSMC_MSG_EnableULV) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_convert_power_state_to_smc(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nSISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nint i, ret;\r\nu32 threshold;\r\nu32 sclk_in_sr = 1350;\r\nif (state->performance_level_count > SISLANDS_MAX_HARDWARE_POWERLEVELS)\r\nreturn -EINVAL;\r\nthreshold = state->performance_levels[state->performance_level_count-1].sclk * 100 / 100;\r\nif (radeon_state->vclk && radeon_state->dclk) {\r\neg_pi->uvd_enabled = true;\r\nif (eg_pi->smu_uvd_hs)\r\nsmc_state->flags |= PPSMC_SWSTATE_FLAG_UVD;\r\n} else {\r\neg_pi->uvd_enabled = false;\r\n}\r\nif (state->dc_compatible)\r\nsmc_state->flags |= PPSMC_SWSTATE_FLAG_DC;\r\nsmc_state->levelCount = 0;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nif (eg_pi->sclk_deep_sleep) {\r\nif ((i == 0) || si_pi->sclk_deep_sleep_above_low) {\r\nif (sclk_in_sr <= SCLK_MIN_DEEPSLEEP_FREQ)\r\nsmc_state->levels[i].stateFlags |= PPSMC_STATEFLAG_DEEPSLEEP_BYPASS;\r\nelse\r\nsmc_state->levels[i].stateFlags |= PPSMC_STATEFLAG_DEEPSLEEP_THROTTLE;\r\n}\r\n}\r\nret = si_convert_power_level_to_smc(rdev, &state->performance_levels[i],\r\n&smc_state->levels[i]);\r\nsmc_state->levels[i].arbRefreshState =\r\n(u8)(SISLANDS_DRIVER_STATE_ARB_INDEX + i);\r\nif (ret)\r\nreturn ret;\r\nif (ni_pi->enable_power_containment)\r\nsmc_state->levels[i].displayWatermark =\r\n(state->performance_levels[i].sclk < threshold) ?\r\nPPSMC_DISPLAY_WATERMARK_LOW : PPSMC_DISPLAY_WATERMARK_HIGH;\r\nelse\r\nsmc_state->levels[i].displayWatermark = (i < 2) ?\r\nPPSMC_DISPLAY_WATERMARK_LOW : PPSMC_DISPLAY_WATERMARK_HIGH;\r\nif (eg_pi->dynamic_ac_timing)\r\nsmc_state->levels[i].ACIndex = SISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT + i;\r\nelse\r\nsmc_state->levels[i].ACIndex = 0;\r\nsmc_state->levelCount++;\r\n}\r\nsi_write_smc_soft_register(rdev,\r\nSI_SMC_SOFT_REGISTER_watermark_threshold,\r\nthreshold / 512);\r\nsi_populate_smc_sp(rdev, radeon_state, smc_state);\r\nret = si_populate_power_containment_values(rdev, radeon_state, smc_state);\r\nif (ret)\r\nni_pi->enable_power_containment = false;\r\nret = si_populate_sq_ramping_values(rdev, radeon_state, smc_state);\r\nif (ret)\r\nni_pi->enable_sq_ramping = false;\r\nreturn si_populate_smc_t(rdev, radeon_state, smc_state);\r\n}\r\nstatic int si_upload_sw_state(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct ni_ps *new_state = ni_get_ps(radeon_new_state);\r\nint ret;\r\nu32 address = si_pi->state_table_start +\r\noffsetof(SISLANDS_SMC_STATETABLE, driverState);\r\nu32 state_size = sizeof(SISLANDS_SMC_SWSTATE) +\r\n((new_state->performance_level_count - 1) *\r\nsizeof(SISLANDS_SMC_HW_PERFORMANCE_LEVEL));\r\nSISLANDS_SMC_SWSTATE *smc_state = &si_pi->smc_statetable.driverState;\r\nmemset(smc_state, 0, state_size);\r\nret = si_convert_power_state_to_smc(rdev, radeon_new_state, smc_state);\r\nif (ret)\r\nreturn ret;\r\nret = si_copy_bytes_to_smc(rdev, address, (u8 *)smc_state,\r\nstate_size, si_pi->sram_end);\r\nreturn ret;\r\n}\r\nstatic int si_upload_ulv_state(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct si_ulv_param *ulv = &si_pi->ulv;\r\nint ret = 0;\r\nif (ulv->supported && ulv->pl.vddc) {\r\nu32 address = si_pi->state_table_start +\r\noffsetof(SISLANDS_SMC_STATETABLE, ULVState);\r\nSISLANDS_SMC_SWSTATE *smc_state = &si_pi->smc_statetable.ULVState;\r\nu32 state_size = sizeof(SISLANDS_SMC_SWSTATE);\r\nmemset(smc_state, 0, state_size);\r\nret = si_populate_ulv_state(rdev, smc_state);\r\nif (!ret)\r\nret = si_copy_bytes_to_smc(rdev, address, (u8 *)smc_state,\r\nstate_size, si_pi->sram_end);\r\n}\r\nreturn ret;\r\n}\r\nstatic int si_upload_smc_data(struct radeon_device *rdev)\r\n{\r\nstruct radeon_crtc *radeon_crtc = NULL;\r\nint i;\r\nif (rdev->pm.dpm.new_active_crtc_count == 0)\r\nreturn 0;\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (rdev->pm.dpm.new_active_crtcs & (1 << i)) {\r\nradeon_crtc = rdev->mode_info.crtcs[i];\r\nbreak;\r\n}\r\n}\r\nif (radeon_crtc == NULL)\r\nreturn 0;\r\nif (radeon_crtc->line_time <= 0)\r\nreturn 0;\r\nif (si_write_smc_soft_register(rdev,\r\nSI_SMC_SOFT_REGISTER_crtc_index,\r\nradeon_crtc->crtc_id) != PPSMC_Result_OK)\r\nreturn 0;\r\nif (si_write_smc_soft_register(rdev,\r\nSI_SMC_SOFT_REGISTER_mclk_change_block_cp_min,\r\nradeon_crtc->wm_high / radeon_crtc->line_time) != PPSMC_Result_OK)\r\nreturn 0;\r\nif (si_write_smc_soft_register(rdev,\r\nSI_SMC_SOFT_REGISTER_mclk_change_block_cp_max,\r\nradeon_crtc->wm_low / radeon_crtc->line_time) != PPSMC_Result_OK)\r\nreturn 0;\r\nreturn 0;\r\n}\r\nstatic int si_set_mc_special_registers(struct radeon_device *rdev,\r\nstruct si_mc_reg_table *table)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu8 i, j, k;\r\nu32 temp_reg;\r\nfor (i = 0, j = table->last; i < table->last; i++) {\r\nif (j >= SMC_SISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nswitch (table->mc_reg_address[i].s1 << 2) {\r\ncase MC_SEQ_MISC1:\r\ntemp_reg = RREG32(MC_PMG_CMD_EMRS);\r\ntable->mc_reg_address[j].s1 = MC_PMG_CMD_EMRS >> 2;\r\ntable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_EMRS_LP >> 2;\r\nfor (k = 0; k < table->num_entries; k++)\r\ntable->mc_reg_table_entry[k].mc_data[j] =\r\n((temp_reg & 0xffff0000)) |\r\n((table->mc_reg_table_entry[k].mc_data[i] & 0xffff0000) >> 16);\r\nj++;\r\nif (j >= SMC_SISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\ntemp_reg = RREG32(MC_PMG_CMD_MRS);\r\ntable->mc_reg_address[j].s1 = MC_PMG_CMD_MRS >> 2;\r\ntable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_MRS_LP >> 2;\r\nfor (k = 0; k < table->num_entries; k++) {\r\ntable->mc_reg_table_entry[k].mc_data[j] =\r\n(temp_reg & 0xffff0000) |\r\n(table->mc_reg_table_entry[k].mc_data[i] & 0x0000ffff);\r\nif (!pi->mem_gddr5)\r\ntable->mc_reg_table_entry[k].mc_data[j] |= 0x100;\r\n}\r\nj++;\r\nif (j >= SMC_SISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nif (!pi->mem_gddr5) {\r\ntable->mc_reg_address[j].s1 = MC_PMG_AUTO_CMD >> 2;\r\ntable->mc_reg_address[j].s0 = MC_PMG_AUTO_CMD >> 2;\r\nfor (k = 0; k < table->num_entries; k++)\r\ntable->mc_reg_table_entry[k].mc_data[j] =\r\n(table->mc_reg_table_entry[k].mc_data[i] & 0xffff0000) >> 16;\r\nj++;\r\nif (j >= SMC_SISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ncase MC_SEQ_RESERVE_M:\r\ntemp_reg = RREG32(MC_PMG_CMD_MRS1);\r\ntable->mc_reg_address[j].s1 = MC_PMG_CMD_MRS1 >> 2;\r\ntable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_MRS1_LP >> 2;\r\nfor(k = 0; k < table->num_entries; k++)\r\ntable->mc_reg_table_entry[k].mc_data[j] =\r\n(temp_reg & 0xffff0000) |\r\n(table->mc_reg_table_entry[k].mc_data[i] & 0x0000ffff);\r\nj++;\r\nif (j >= SMC_SISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\ntable->last = j;\r\nreturn 0;\r\n}\r\nstatic bool si_check_s0_mc_reg_index(u16 in_reg, u16 *out_reg)\r\n{\r\nbool result = true;\r\nswitch (in_reg) {\r\ncase MC_SEQ_RAS_TIMING >> 2:\r\n*out_reg = MC_SEQ_RAS_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_CAS_TIMING >> 2:\r\n*out_reg = MC_SEQ_CAS_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_MISC_TIMING >> 2:\r\n*out_reg = MC_SEQ_MISC_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_MISC_TIMING2 >> 2:\r\n*out_reg = MC_SEQ_MISC_TIMING2_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_RD_CTL_D0 >> 2:\r\n*out_reg = MC_SEQ_RD_CTL_D0_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_RD_CTL_D1 >> 2:\r\n*out_reg = MC_SEQ_RD_CTL_D1_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_WR_CTL_D0 >> 2:\r\n*out_reg = MC_SEQ_WR_CTL_D0_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_WR_CTL_D1 >> 2:\r\n*out_reg = MC_SEQ_WR_CTL_D1_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_EMRS >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_EMRS_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_MRS >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_MRS_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_MRS1 >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_MRS1_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_PMG_TIMING >> 2:\r\n*out_reg = MC_SEQ_PMG_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_MRS2 >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_MRS2_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_WR_CTL_2 >> 2:\r\n*out_reg = MC_SEQ_WR_CTL_2_LP >> 2;\r\nbreak;\r\ndefault:\r\nresult = false;\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic void si_set_valid_flag(struct si_mc_reg_table *table)\r\n{\r\nu8 i, j;\r\nfor (i = 0; i < table->last; i++) {\r\nfor (j = 1; j < table->num_entries; j++) {\r\nif (table->mc_reg_table_entry[j-1].mc_data[i] != table->mc_reg_table_entry[j].mc_data[i]) {\r\ntable->valid_flag |= 1 << i;\r\nbreak;\r\n}\r\n}\r\n}\r\n}\r\nstatic void si_set_s0_mc_reg_index(struct si_mc_reg_table *table)\r\n{\r\nu32 i;\r\nu16 address;\r\nfor (i = 0; i < table->last; i++)\r\ntable->mc_reg_address[i].s0 = si_check_s0_mc_reg_index(table->mc_reg_address[i].s1, &address) ?\r\naddress : table->mc_reg_address[i].s1;\r\n}\r\nstatic int si_copy_vbios_mc_reg_table(struct atom_mc_reg_table *table,\r\nstruct si_mc_reg_table *si_table)\r\n{\r\nu8 i, j;\r\nif (table->last > SMC_SISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nif (table->num_entries > MAX_AC_TIMING_ENTRIES)\r\nreturn -EINVAL;\r\nfor (i = 0; i < table->last; i++)\r\nsi_table->mc_reg_address[i].s1 = table->mc_reg_address[i].s1;\r\nsi_table->last = table->last;\r\nfor (i = 0; i < table->num_entries; i++) {\r\nsi_table->mc_reg_table_entry[i].mclk_max =\r\ntable->mc_reg_table_entry[i].mclk_max;\r\nfor (j = 0; j < table->last; j++) {\r\nsi_table->mc_reg_table_entry[i].mc_data[j] =\r\ntable->mc_reg_table_entry[i].mc_data[j];\r\n}\r\n}\r\nsi_table->num_entries = table->num_entries;\r\nreturn 0;\r\n}\r\nstatic int si_initialize_mc_reg_table(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct atom_mc_reg_table *table;\r\nstruct si_mc_reg_table *si_table = &si_pi->mc_reg_table;\r\nu8 module_index = rv770_get_memory_module_index(rdev);\r\nint ret;\r\ntable = kzalloc(sizeof(struct atom_mc_reg_table), GFP_KERNEL);\r\nif (!table)\r\nreturn -ENOMEM;\r\nWREG32(MC_SEQ_RAS_TIMING_LP, RREG32(MC_SEQ_RAS_TIMING));\r\nWREG32(MC_SEQ_CAS_TIMING_LP, RREG32(MC_SEQ_CAS_TIMING));\r\nWREG32(MC_SEQ_MISC_TIMING_LP, RREG32(MC_SEQ_MISC_TIMING));\r\nWREG32(MC_SEQ_MISC_TIMING2_LP, RREG32(MC_SEQ_MISC_TIMING2));\r\nWREG32(MC_SEQ_PMG_CMD_EMRS_LP, RREG32(MC_PMG_CMD_EMRS));\r\nWREG32(MC_SEQ_PMG_CMD_MRS_LP, RREG32(MC_PMG_CMD_MRS));\r\nWREG32(MC_SEQ_PMG_CMD_MRS1_LP, RREG32(MC_PMG_CMD_MRS1));\r\nWREG32(MC_SEQ_WR_CTL_D0_LP, RREG32(MC_SEQ_WR_CTL_D0));\r\nWREG32(MC_SEQ_WR_CTL_D1_LP, RREG32(MC_SEQ_WR_CTL_D1));\r\nWREG32(MC_SEQ_RD_CTL_D0_LP, RREG32(MC_SEQ_RD_CTL_D0));\r\nWREG32(MC_SEQ_RD_CTL_D1_LP, RREG32(MC_SEQ_RD_CTL_D1));\r\nWREG32(MC_SEQ_PMG_TIMING_LP, RREG32(MC_SEQ_PMG_TIMING));\r\nWREG32(MC_SEQ_PMG_CMD_MRS2_LP, RREG32(MC_PMG_CMD_MRS2));\r\nWREG32(MC_SEQ_WR_CTL_2_LP, RREG32(MC_SEQ_WR_CTL_2));\r\nret = radeon_atom_init_mc_reg_table(rdev, module_index, table);\r\nif (ret)\r\ngoto init_mc_done;\r\nret = si_copy_vbios_mc_reg_table(table, si_table);\r\nif (ret)\r\ngoto init_mc_done;\r\nsi_set_s0_mc_reg_index(si_table);\r\nret = si_set_mc_special_registers(rdev, si_table);\r\nif (ret)\r\ngoto init_mc_done;\r\nsi_set_valid_flag(si_table);\r\ninit_mc_done:\r\nkfree(table);\r\nreturn ret;\r\n}\r\nstatic void si_populate_mc_reg_addresses(struct radeon_device *rdev,\r\nSMC_SIslands_MCRegisters *mc_reg_table)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 i, j;\r\nfor (i = 0, j = 0; j < si_pi->mc_reg_table.last; j++) {\r\nif (si_pi->mc_reg_table.valid_flag & (1 << j)) {\r\nif (i >= SMC_SISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nbreak;\r\nmc_reg_table->address[i].s0 =\r\ncpu_to_be16(si_pi->mc_reg_table.mc_reg_address[j].s0);\r\nmc_reg_table->address[i].s1 =\r\ncpu_to_be16(si_pi->mc_reg_table.mc_reg_address[j].s1);\r\ni++;\r\n}\r\n}\r\nmc_reg_table->last = (u8)i;\r\n}\r\nstatic void si_convert_mc_registers(const struct si_mc_reg_entry *entry,\r\nSMC_SIslands_MCRegisterSet *data,\r\nu32 num_entries, u32 valid_flag)\r\n{\r\nu32 i, j;\r\nfor(i = 0, j = 0; j < num_entries; j++) {\r\nif (valid_flag & (1 << j)) {\r\ndata->value[i] = cpu_to_be32(entry->mc_data[j]);\r\ni++;\r\n}\r\n}\r\n}\r\nstatic void si_convert_mc_reg_table_entry_to_smc(struct radeon_device *rdev,\r\nstruct rv7xx_pl *pl,\r\nSMC_SIslands_MCRegisterSet *mc_reg_table_data)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 i = 0;\r\nfor (i = 0; i < si_pi->mc_reg_table.num_entries; i++) {\r\nif (pl->mclk <= si_pi->mc_reg_table.mc_reg_table_entry[i].mclk_max)\r\nbreak;\r\n}\r\nif ((i == si_pi->mc_reg_table.num_entries) && (i > 0))\r\n--i;\r\nsi_convert_mc_registers(&si_pi->mc_reg_table.mc_reg_table_entry[i],\r\nmc_reg_table_data, si_pi->mc_reg_table.last,\r\nsi_pi->mc_reg_table.valid_flag);\r\n}\r\nstatic void si_convert_mc_reg_table_to_smc(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nSMC_SIslands_MCRegisters *mc_reg_table)\r\n{\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nint i;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nsi_convert_mc_reg_table_entry_to_smc(rdev,\r\n&state->performance_levels[i],\r\n&mc_reg_table->data[SISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT + i]);\r\n}\r\n}\r\nstatic int si_populate_mc_reg_table(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_boot_state)\r\n{\r\nstruct ni_ps *boot_state = ni_get_ps(radeon_boot_state);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct si_ulv_param *ulv = &si_pi->ulv;\r\nSMC_SIslands_MCRegisters *smc_mc_reg_table = &si_pi->smc_mc_reg_table;\r\nmemset(smc_mc_reg_table, 0, sizeof(SMC_SIslands_MCRegisters));\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_seq_index, 1);\r\nsi_populate_mc_reg_addresses(rdev, smc_mc_reg_table);\r\nsi_convert_mc_reg_table_entry_to_smc(rdev, &boot_state->performance_levels[0],\r\n&smc_mc_reg_table->data[SISLANDS_MCREGISTERTABLE_INITIAL_SLOT]);\r\nsi_convert_mc_registers(&si_pi->mc_reg_table.mc_reg_table_entry[0],\r\n&smc_mc_reg_table->data[SISLANDS_MCREGISTERTABLE_ACPI_SLOT],\r\nsi_pi->mc_reg_table.last,\r\nsi_pi->mc_reg_table.valid_flag);\r\nif (ulv->supported && ulv->pl.vddc != 0)\r\nsi_convert_mc_reg_table_entry_to_smc(rdev, &ulv->pl,\r\n&smc_mc_reg_table->data[SISLANDS_MCREGISTERTABLE_ULV_SLOT]);\r\nelse\r\nsi_convert_mc_registers(&si_pi->mc_reg_table.mc_reg_table_entry[0],\r\n&smc_mc_reg_table->data[SISLANDS_MCREGISTERTABLE_ULV_SLOT],\r\nsi_pi->mc_reg_table.last,\r\nsi_pi->mc_reg_table.valid_flag);\r\nsi_convert_mc_reg_table_to_smc(rdev, radeon_boot_state, smc_mc_reg_table);\r\nreturn si_copy_bytes_to_smc(rdev, si_pi->mc_reg_table_start,\r\n(u8 *)smc_mc_reg_table,\r\nsizeof(SMC_SIslands_MCRegisters), si_pi->sram_end);\r\n}\r\nstatic int si_upload_mc_reg_table(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state)\r\n{\r\nstruct ni_ps *new_state = ni_get_ps(radeon_new_state);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 address = si_pi->mc_reg_table_start +\r\noffsetof(SMC_SIslands_MCRegisters,\r\ndata[SISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT]);\r\nSMC_SIslands_MCRegisters *smc_mc_reg_table = &si_pi->smc_mc_reg_table;\r\nmemset(smc_mc_reg_table, 0, sizeof(SMC_SIslands_MCRegisters));\r\nsi_convert_mc_reg_table_to_smc(rdev, radeon_new_state, smc_mc_reg_table);\r\nreturn si_copy_bytes_to_smc(rdev, address,\r\n(u8 *)&smc_mc_reg_table->data[SISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT],\r\nsizeof(SMC_SIslands_MCRegisterSet) * new_state->performance_level_count,\r\nsi_pi->sram_end);\r\n}\r\nstatic void si_enable_voltage_control(struct radeon_device *rdev, bool enable)\r\n{\r\nif (enable)\r\nWREG32_P(GENERAL_PWRMGT, VOLT_PWRMGT_EN, ~VOLT_PWRMGT_EN);\r\nelse\r\nWREG32_P(GENERAL_PWRMGT, 0, ~VOLT_PWRMGT_EN);\r\n}\r\nstatic enum radeon_pcie_gen si_get_maximum_link_speed(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state)\r\n{\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nint i;\r\nu16 pcie_speed, max_speed = 0;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\npcie_speed = state->performance_levels[i].pcie_gen;\r\nif (max_speed < pcie_speed)\r\nmax_speed = pcie_speed;\r\n}\r\nreturn max_speed;\r\n}\r\nstatic u16 si_get_current_pcie_speed(struct radeon_device *rdev)\r\n{\r\nu32 speed_cntl;\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL) & LC_CURRENT_DATA_RATE_MASK;\r\nspeed_cntl >>= LC_CURRENT_DATA_RATE_SHIFT;\r\nreturn (u16)speed_cntl;\r\n}\r\nstatic void si_request_link_speed_change_before_state_change(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state,\r\nstruct radeon_ps *radeon_current_state)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nenum radeon_pcie_gen target_link_speed = si_get_maximum_link_speed(rdev, radeon_new_state);\r\nenum radeon_pcie_gen current_link_speed;\r\nif (si_pi->force_pcie_gen == RADEON_PCIE_GEN_INVALID)\r\ncurrent_link_speed = si_get_maximum_link_speed(rdev, radeon_current_state);\r\nelse\r\ncurrent_link_speed = si_pi->force_pcie_gen;\r\nsi_pi->force_pcie_gen = RADEON_PCIE_GEN_INVALID;\r\nsi_pi->pspp_notify_required = false;\r\nif (target_link_speed > current_link_speed) {\r\nswitch (target_link_speed) {\r\n#if defined(CONFIG_ACPI)\r\ncase RADEON_PCIE_GEN3:\r\nif (radeon_acpi_pcie_performance_request(rdev, PCIE_PERF_REQ_PECI_GEN3, false) == 0)\r\nbreak;\r\nsi_pi->force_pcie_gen = RADEON_PCIE_GEN2;\r\nif (current_link_speed == RADEON_PCIE_GEN2)\r\nbreak;\r\ncase RADEON_PCIE_GEN2:\r\nif (radeon_acpi_pcie_performance_request(rdev, PCIE_PERF_REQ_PECI_GEN2, false) == 0)\r\nbreak;\r\n#endif\r\ndefault:\r\nsi_pi->force_pcie_gen = si_get_current_pcie_speed(rdev);\r\nbreak;\r\n}\r\n} else {\r\nif (target_link_speed < current_link_speed)\r\nsi_pi->pspp_notify_required = true;\r\n}\r\n}\r\nstatic void si_notify_link_speed_change_after_state_change(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state,\r\nstruct radeon_ps *radeon_current_state)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nenum radeon_pcie_gen target_link_speed = si_get_maximum_link_speed(rdev, radeon_new_state);\r\nu8 request;\r\nif (si_pi->pspp_notify_required) {\r\nif (target_link_speed == RADEON_PCIE_GEN3)\r\nrequest = PCIE_PERF_REQ_PECI_GEN3;\r\nelse if (target_link_speed == RADEON_PCIE_GEN2)\r\nrequest = PCIE_PERF_REQ_PECI_GEN2;\r\nelse\r\nrequest = PCIE_PERF_REQ_PECI_GEN1;\r\nif ((request == PCIE_PERF_REQ_PECI_GEN1) &&\r\n(si_get_current_pcie_speed(rdev) > 0))\r\nreturn;\r\n#if defined(CONFIG_ACPI)\r\nradeon_acpi_pcie_performance_request(rdev, request, false);\r\n#endif\r\n}\r\n}\r\nstatic void si_set_max_cu_value(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nif (rdev->family == CHIP_VERDE) {\r\nswitch (rdev->pdev->device) {\r\ncase 0x6820:\r\ncase 0x6825:\r\ncase 0x6821:\r\ncase 0x6823:\r\ncase 0x6827:\r\nsi_pi->max_cu = 10;\r\nbreak;\r\ncase 0x682D:\r\ncase 0x6824:\r\ncase 0x682F:\r\ncase 0x6826:\r\nsi_pi->max_cu = 8;\r\nbreak;\r\ncase 0x6828:\r\ncase 0x6830:\r\ncase 0x6831:\r\ncase 0x6838:\r\ncase 0x6839:\r\ncase 0x683D:\r\nsi_pi->max_cu = 10;\r\nbreak;\r\ncase 0x683B:\r\ncase 0x683F:\r\ncase 0x6829:\r\nsi_pi->max_cu = 8;\r\nbreak;\r\ndefault:\r\nsi_pi->max_cu = 0;\r\nbreak;\r\n}\r\n} else {\r\nsi_pi->max_cu = 0;\r\n}\r\n}\r\nstatic int si_patch_single_dependency_table_based_on_leakage(struct radeon_device *rdev,\r\nstruct radeon_clock_voltage_dependency_table *table)\r\n{\r\nu32 i;\r\nint j;\r\nu16 leakage_voltage;\r\nif (table) {\r\nfor (i = 0; i < table->count; i++) {\r\nswitch (si_get_leakage_voltage_from_leakage_index(rdev,\r\ntable->entries[i].v,\r\n&leakage_voltage)) {\r\ncase 0:\r\ntable->entries[i].v = leakage_voltage;\r\nbreak;\r\ncase -EAGAIN:\r\nreturn -EINVAL;\r\ncase -EINVAL:\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nfor (j = (table->count - 2); j >= 0; j--) {\r\ntable->entries[j].v = (table->entries[j].v <= table->entries[j + 1].v) ?\r\ntable->entries[j].v : table->entries[j + 1].v;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_patch_dependency_tables_based_on_leakage(struct radeon_device *rdev)\r\n{\r\nint ret = 0;\r\nret = si_patch_single_dependency_table_based_on_leakage(rdev,\r\n&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk);\r\nret = si_patch_single_dependency_table_based_on_leakage(rdev,\r\n&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk);\r\nret = si_patch_single_dependency_table_based_on_leakage(rdev,\r\n&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk);\r\nreturn ret;\r\n}\r\nstatic void si_set_pcie_lane_width_in_smc(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state,\r\nstruct radeon_ps *radeon_current_state)\r\n{\r\nu32 lane_width;\r\nu32 new_lane_width =\r\n(radeon_new_state->caps & ATOM_PPLIB_PCIE_LINK_WIDTH_MASK) >> ATOM_PPLIB_PCIE_LINK_WIDTH_SHIFT;\r\nu32 current_lane_width =\r\n(radeon_current_state->caps & ATOM_PPLIB_PCIE_LINK_WIDTH_MASK) >> ATOM_PPLIB_PCIE_LINK_WIDTH_SHIFT;\r\nif (new_lane_width != current_lane_width) {\r\nradeon_set_pcie_lanes(rdev, new_lane_width);\r\nlane_width = radeon_get_pcie_lanes(rdev);\r\nsi_write_smc_soft_register(rdev, SI_SMC_SOFT_REGISTER_non_ulv_pcie_link_width, lane_width);\r\n}\r\n}\r\nstatic void si_set_vce_clock(struct radeon_device *rdev,\r\nstruct radeon_ps *new_rps,\r\nstruct radeon_ps *old_rps)\r\n{\r\nif ((old_rps->evclk != new_rps->evclk) ||\r\n(old_rps->ecclk != new_rps->ecclk)) {\r\nif (new_rps->evclk || new_rps->ecclk)\r\nvce_v1_0_enable_mgcg(rdev, false);\r\nelse\r\nvce_v1_0_enable_mgcg(rdev, true);\r\nradeon_set_vce_clocks(rdev, new_rps->evclk, new_rps->ecclk);\r\n}\r\n}\r\nvoid si_dpm_setup_asic(struct radeon_device *rdev)\r\n{\r\nint r;\r\nr = si_mc_load_microcode(rdev);\r\nif (r)\r\nDRM_ERROR("Failed to load MC firmware!\n");\r\nrv770_get_memory_type(rdev);\r\nsi_read_clock_registers(rdev);\r\nsi_enable_acpi_power_management(rdev);\r\n}\r\nstatic int si_thermal_enable_alert(struct radeon_device *rdev,\r\nbool enable)\r\n{\r\nu32 thermal_int = RREG32(CG_THERMAL_INT);\r\nif (enable) {\r\nPPSMC_Result result;\r\nthermal_int &= ~(THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW);\r\nWREG32(CG_THERMAL_INT, thermal_int);\r\nrdev->irq.dpm_thermal = false;\r\nresult = si_send_msg_to_smc(rdev, PPSMC_MSG_EnableThermalInterrupt);\r\nif (result != PPSMC_Result_OK) {\r\nDRM_DEBUG_KMS("Could not enable thermal interrupts.\n");\r\nreturn -EINVAL;\r\n}\r\n} else {\r\nthermal_int |= THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW;\r\nWREG32(CG_THERMAL_INT, thermal_int);\r\nrdev->irq.dpm_thermal = true;\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_thermal_set_temperature_range(struct radeon_device *rdev,\r\nint min_temp, int max_temp)\r\n{\r\nint low_temp = 0 * 1000;\r\nint high_temp = 255 * 1000;\r\nif (low_temp < min_temp)\r\nlow_temp = min_temp;\r\nif (high_temp > max_temp)\r\nhigh_temp = max_temp;\r\nif (high_temp < low_temp) {\r\nDRM_ERROR("invalid thermal range: %d - %d\n", low_temp, high_temp);\r\nreturn -EINVAL;\r\n}\r\nWREG32_P(CG_THERMAL_INT, DIG_THERM_INTH(high_temp / 1000), ~DIG_THERM_INTH_MASK);\r\nWREG32_P(CG_THERMAL_INT, DIG_THERM_INTL(low_temp / 1000), ~DIG_THERM_INTL_MASK);\r\nWREG32_P(CG_THERMAL_CTRL, DIG_THERM_DPM(high_temp / 1000), ~DIG_THERM_DPM_MASK);\r\nrdev->pm.dpm.thermal.min_temp = low_temp;\r\nrdev->pm.dpm.thermal.max_temp = high_temp;\r\nreturn 0;\r\n}\r\nstatic void si_fan_ctrl_set_static_mode(struct radeon_device *rdev, u32 mode)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 tmp;\r\nif (si_pi->fan_ctrl_is_in_default_mode) {\r\ntmp = (RREG32(CG_FDO_CTRL2) & FDO_PWM_MODE_MASK) >> FDO_PWM_MODE_SHIFT;\r\nsi_pi->fan_ctrl_default_mode = tmp;\r\ntmp = (RREG32(CG_FDO_CTRL2) & TMIN_MASK) >> TMIN_SHIFT;\r\nsi_pi->t_min = tmp;\r\nsi_pi->fan_ctrl_is_in_default_mode = false;\r\n}\r\ntmp = RREG32(CG_FDO_CTRL2) & ~TMIN_MASK;\r\ntmp |= TMIN(0);\r\nWREG32(CG_FDO_CTRL2, tmp);\r\ntmp = RREG32(CG_FDO_CTRL2) & ~FDO_PWM_MODE_MASK;\r\ntmp |= FDO_PWM_MODE(mode);\r\nWREG32(CG_FDO_CTRL2, tmp);\r\n}\r\nstatic int si_thermal_setup_fan_table(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nPP_SIslands_FanTable fan_table = { FDO_MODE_HARDWARE };\r\nu32 duty100;\r\nu32 t_diff1, t_diff2, pwm_diff1, pwm_diff2;\r\nu16 fdo_min, slope1, slope2;\r\nu32 reference_clock, tmp;\r\nint ret;\r\nu64 tmp64;\r\nif (!si_pi->fan_table_start) {\r\nrdev->pm.dpm.fan.ucode_fan_control = false;\r\nreturn 0;\r\n}\r\nduty100 = (RREG32(CG_FDO_CTRL1) & FMAX_DUTY100_MASK) >> FMAX_DUTY100_SHIFT;\r\nif (duty100 == 0) {\r\nrdev->pm.dpm.fan.ucode_fan_control = false;\r\nreturn 0;\r\n}\r\ntmp64 = (u64)rdev->pm.dpm.fan.pwm_min * duty100;\r\ndo_div(tmp64, 10000);\r\nfdo_min = (u16)tmp64;\r\nt_diff1 = rdev->pm.dpm.fan.t_med - rdev->pm.dpm.fan.t_min;\r\nt_diff2 = rdev->pm.dpm.fan.t_high - rdev->pm.dpm.fan.t_med;\r\npwm_diff1 = rdev->pm.dpm.fan.pwm_med - rdev->pm.dpm.fan.pwm_min;\r\npwm_diff2 = rdev->pm.dpm.fan.pwm_high - rdev->pm.dpm.fan.pwm_med;\r\nslope1 = (u16)((50 + ((16 * duty100 * pwm_diff1) / t_diff1)) / 100);\r\nslope2 = (u16)((50 + ((16 * duty100 * pwm_diff2) / t_diff2)) / 100);\r\nfan_table.temp_min = cpu_to_be16((50 + rdev->pm.dpm.fan.t_min) / 100);\r\nfan_table.temp_med = cpu_to_be16((50 + rdev->pm.dpm.fan.t_med) / 100);\r\nfan_table.temp_max = cpu_to_be16((50 + rdev->pm.dpm.fan.t_max) / 100);\r\nfan_table.slope1 = cpu_to_be16(slope1);\r\nfan_table.slope2 = cpu_to_be16(slope2);\r\nfan_table.fdo_min = cpu_to_be16(fdo_min);\r\nfan_table.hys_down = cpu_to_be16(rdev->pm.dpm.fan.t_hyst);\r\nfan_table.hys_up = cpu_to_be16(1);\r\nfan_table.hys_slope = cpu_to_be16(1);\r\nfan_table.temp_resp_lim = cpu_to_be16(5);\r\nreference_clock = radeon_get_xclk(rdev);\r\nfan_table.refresh_period = cpu_to_be32((rdev->pm.dpm.fan.cycle_delay *\r\nreference_clock) / 1600);\r\nfan_table.fdo_max = cpu_to_be16((u16)duty100);\r\ntmp = (RREG32(CG_MULT_THERMAL_CTRL) & TEMP_SEL_MASK) >> TEMP_SEL_SHIFT;\r\nfan_table.temp_src = (uint8_t)tmp;\r\nret = si_copy_bytes_to_smc(rdev,\r\nsi_pi->fan_table_start,\r\n(u8 *)(&fan_table),\r\nsizeof(fan_table),\r\nsi_pi->sram_end);\r\nif (ret) {\r\nDRM_ERROR("Failed to load fan table to the SMC.");\r\nrdev->pm.dpm.fan.ucode_fan_control = false;\r\n}\r\nreturn 0;\r\n}\r\nstatic int si_fan_ctrl_start_smc_fan_control(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nPPSMC_Result ret;\r\nret = si_send_msg_to_smc(rdev, PPSMC_StartFanControl);\r\nif (ret == PPSMC_Result_OK) {\r\nsi_pi->fan_is_controlled_by_smc = true;\r\nreturn 0;\r\n} else {\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int si_fan_ctrl_stop_smc_fan_control(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nPPSMC_Result ret;\r\nret = si_send_msg_to_smc(rdev, PPSMC_StopFanControl);\r\nif (ret == PPSMC_Result_OK) {\r\nsi_pi->fan_is_controlled_by_smc = false;\r\nreturn 0;\r\n} else {\r\nreturn -EINVAL;\r\n}\r\n}\r\nint si_fan_ctrl_get_fan_speed_percent(struct radeon_device *rdev,\r\nu32 *speed)\r\n{\r\nu32 duty, duty100;\r\nu64 tmp64;\r\nif (rdev->pm.no_fan)\r\nreturn -ENOENT;\r\nduty100 = (RREG32(CG_FDO_CTRL1) & FMAX_DUTY100_MASK) >> FMAX_DUTY100_SHIFT;\r\nduty = (RREG32(CG_THERMAL_STATUS) & FDO_PWM_DUTY_MASK) >> FDO_PWM_DUTY_SHIFT;\r\nif (duty100 == 0)\r\nreturn -EINVAL;\r\ntmp64 = (u64)duty * 100;\r\ndo_div(tmp64, duty100);\r\n*speed = (u32)tmp64;\r\nif (*speed > 100)\r\n*speed = 100;\r\nreturn 0;\r\n}\r\nint si_fan_ctrl_set_fan_speed_percent(struct radeon_device *rdev,\r\nu32 speed)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 tmp;\r\nu32 duty, duty100;\r\nu64 tmp64;\r\nif (rdev->pm.no_fan)\r\nreturn -ENOENT;\r\nif (si_pi->fan_is_controlled_by_smc)\r\nreturn -EINVAL;\r\nif (speed > 100)\r\nreturn -EINVAL;\r\nduty100 = (RREG32(CG_FDO_CTRL1) & FMAX_DUTY100_MASK) >> FMAX_DUTY100_SHIFT;\r\nif (duty100 == 0)\r\nreturn -EINVAL;\r\ntmp64 = (u64)speed * duty100;\r\ndo_div(tmp64, 100);\r\nduty = (u32)tmp64;\r\ntmp = RREG32(CG_FDO_CTRL0) & ~FDO_STATIC_DUTY_MASK;\r\ntmp |= FDO_STATIC_DUTY(duty);\r\nWREG32(CG_FDO_CTRL0, tmp);\r\nreturn 0;\r\n}\r\nvoid si_fan_ctrl_set_mode(struct radeon_device *rdev, u32 mode)\r\n{\r\nif (mode) {\r\nif (rdev->pm.dpm.fan.ucode_fan_control)\r\nsi_fan_ctrl_stop_smc_fan_control(rdev);\r\nsi_fan_ctrl_set_static_mode(rdev, mode);\r\n} else {\r\nif (rdev->pm.dpm.fan.ucode_fan_control)\r\nsi_thermal_start_smc_fan_control(rdev);\r\nelse\r\nsi_fan_ctrl_set_default_mode(rdev);\r\n}\r\n}\r\nu32 si_fan_ctrl_get_mode(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 tmp;\r\nif (si_pi->fan_is_controlled_by_smc)\r\nreturn 0;\r\ntmp = RREG32(CG_FDO_CTRL2) & FDO_PWM_MODE_MASK;\r\nreturn (tmp >> FDO_PWM_MODE_SHIFT);\r\n}\r\nstatic void si_fan_ctrl_set_default_mode(struct radeon_device *rdev)\r\n{\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nu32 tmp;\r\nif (!si_pi->fan_ctrl_is_in_default_mode) {\r\ntmp = RREG32(CG_FDO_CTRL2) & ~FDO_PWM_MODE_MASK;\r\ntmp |= FDO_PWM_MODE(si_pi->fan_ctrl_default_mode);\r\nWREG32(CG_FDO_CTRL2, tmp);\r\ntmp = RREG32(CG_FDO_CTRL2) & ~TMIN_MASK;\r\ntmp |= TMIN(si_pi->t_min);\r\nWREG32(CG_FDO_CTRL2, tmp);\r\nsi_pi->fan_ctrl_is_in_default_mode = true;\r\n}\r\n}\r\nstatic void si_thermal_start_smc_fan_control(struct radeon_device *rdev)\r\n{\r\nif (rdev->pm.dpm.fan.ucode_fan_control) {\r\nsi_fan_ctrl_start_smc_fan_control(rdev);\r\nsi_fan_ctrl_set_static_mode(rdev, FDO_PWM_MODE_STATIC);\r\n}\r\n}\r\nstatic void si_thermal_initialize(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nif (rdev->pm.fan_pulses_per_revolution) {\r\ntmp = RREG32(CG_TACH_CTRL) & ~EDGE_PER_REV_MASK;\r\ntmp |= EDGE_PER_REV(rdev->pm.fan_pulses_per_revolution -1);\r\nWREG32(CG_TACH_CTRL, tmp);\r\n}\r\ntmp = RREG32(CG_FDO_CTRL2) & ~TACH_PWM_RESP_RATE_MASK;\r\ntmp |= TACH_PWM_RESP_RATE(0x28);\r\nWREG32(CG_FDO_CTRL2, tmp);\r\n}\r\nstatic int si_thermal_start_thermal_controller(struct radeon_device *rdev)\r\n{\r\nint ret;\r\nsi_thermal_initialize(rdev);\r\nret = si_thermal_set_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);\r\nif (ret)\r\nreturn ret;\r\nret = si_thermal_enable_alert(rdev, true);\r\nif (ret)\r\nreturn ret;\r\nif (rdev->pm.dpm.fan.ucode_fan_control) {\r\nret = si_halt_smc(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = si_thermal_setup_fan_table(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = si_resume_smc(rdev);\r\nif (ret)\r\nreturn ret;\r\nsi_thermal_start_smc_fan_control(rdev);\r\n}\r\nreturn 0;\r\n}\r\nstatic void si_thermal_stop_thermal_controller(struct radeon_device *rdev)\r\n{\r\nif (!rdev->pm.no_fan) {\r\nsi_fan_ctrl_set_default_mode(rdev);\r\nsi_fan_ctrl_stop_smc_fan_control(rdev);\r\n}\r\n}\r\nint si_dpm_enable(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;\r\nint ret;\r\nif (si_is_smc_running(rdev))\r\nreturn -EINVAL;\r\nif (pi->voltage_control || si_pi->voltage_control_svi2)\r\nsi_enable_voltage_control(rdev, true);\r\nif (pi->mvdd_control)\r\nsi_get_mvdd_configuration(rdev);\r\nif (pi->voltage_control || si_pi->voltage_control_svi2) {\r\nret = si_construct_voltage_tables(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_construct_voltage_tables failed\n");\r\nreturn ret;\r\n}\r\n}\r\nif (eg_pi->dynamic_ac_timing) {\r\nret = si_initialize_mc_reg_table(rdev);\r\nif (ret)\r\neg_pi->dynamic_ac_timing = false;\r\n}\r\nif (pi->dynamic_ss)\r\nsi_enable_spread_spectrum(rdev, true);\r\nif (pi->thermal_protection)\r\nsi_enable_thermal_protection(rdev, true);\r\nsi_setup_bsp(rdev);\r\nsi_program_git(rdev);\r\nsi_program_tp(rdev);\r\nsi_program_tpp(rdev);\r\nsi_program_sstp(rdev);\r\nsi_enable_display_gap(rdev);\r\nsi_program_vc(rdev);\r\nret = si_upload_firmware(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_upload_firmware failed\n");\r\nreturn ret;\r\n}\r\nret = si_process_firmware_header(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_process_firmware_header failed\n");\r\nreturn ret;\r\n}\r\nret = si_initial_switch_from_arb_f0_to_f1(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_initial_switch_from_arb_f0_to_f1 failed\n");\r\nreturn ret;\r\n}\r\nret = si_init_smc_table(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_init_smc_table failed\n");\r\nreturn ret;\r\n}\r\nret = si_init_smc_spll_table(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_init_smc_spll_table failed\n");\r\nreturn ret;\r\n}\r\nret = si_init_arb_table_index(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_init_arb_table_index failed\n");\r\nreturn ret;\r\n}\r\nif (eg_pi->dynamic_ac_timing) {\r\nret = si_populate_mc_reg_table(rdev, boot_ps);\r\nif (ret) {\r\nDRM_ERROR("si_populate_mc_reg_table failed\n");\r\nreturn ret;\r\n}\r\n}\r\nret = si_initialize_smc_cac_tables(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_initialize_smc_cac_tables failed\n");\r\nreturn ret;\r\n}\r\nret = si_initialize_hardware_cac_manager(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_initialize_hardware_cac_manager failed\n");\r\nreturn ret;\r\n}\r\nret = si_initialize_smc_dte_tables(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_initialize_smc_dte_tables failed\n");\r\nreturn ret;\r\n}\r\nret = si_populate_smc_tdp_limits(rdev, boot_ps);\r\nif (ret) {\r\nDRM_ERROR("si_populate_smc_tdp_limits failed\n");\r\nreturn ret;\r\n}\r\nret = si_populate_smc_tdp_limits_2(rdev, boot_ps);\r\nif (ret) {\r\nDRM_ERROR("si_populate_smc_tdp_limits_2 failed\n");\r\nreturn ret;\r\n}\r\nsi_program_response_times(rdev);\r\nsi_program_ds_registers(rdev);\r\nsi_dpm_start_smc(rdev);\r\nret = si_notify_smc_display_change(rdev, false);\r\nif (ret) {\r\nDRM_ERROR("si_notify_smc_display_change failed\n");\r\nreturn ret;\r\n}\r\nsi_enable_sclk_control(rdev, true);\r\nsi_start_dpm(rdev);\r\nsi_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);\r\nsi_thermal_start_thermal_controller(rdev);\r\nni_update_current_ps(rdev, boot_ps);\r\nreturn 0;\r\n}\r\nstatic int si_set_temperature_range(struct radeon_device *rdev)\r\n{\r\nint ret;\r\nret = si_thermal_enable_alert(rdev, false);\r\nif (ret)\r\nreturn ret;\r\nret = si_thermal_set_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);\r\nif (ret)\r\nreturn ret;\r\nret = si_thermal_enable_alert(rdev, true);\r\nif (ret)\r\nreturn ret;\r\nreturn ret;\r\n}\r\nint si_dpm_late_enable(struct radeon_device *rdev)\r\n{\r\nint ret;\r\nret = si_set_temperature_range(rdev);\r\nif (ret)\r\nreturn ret;\r\nreturn ret;\r\n}\r\nvoid si_dpm_disable(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;\r\nif (!si_is_smc_running(rdev))\r\nreturn;\r\nsi_thermal_stop_thermal_controller(rdev);\r\nsi_disable_ulv(rdev);\r\nsi_clear_vc(rdev);\r\nif (pi->thermal_protection)\r\nsi_enable_thermal_protection(rdev, false);\r\nsi_enable_power_containment(rdev, boot_ps, false);\r\nsi_enable_smc_cac(rdev, boot_ps, false);\r\nsi_enable_spread_spectrum(rdev, false);\r\nsi_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, false);\r\nsi_stop_dpm(rdev);\r\nsi_reset_to_default(rdev);\r\nsi_dpm_stop_smc(rdev);\r\nsi_force_switch_to_arb_f0(rdev);\r\nni_update_current_ps(rdev, boot_ps);\r\n}\r\nint si_dpm_pre_set_power_state(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps requested_ps = *rdev->pm.dpm.requested_ps;\r\nstruct radeon_ps *new_ps = &requested_ps;\r\nni_update_requested_ps(rdev, new_ps);\r\nsi_apply_state_adjust_rules(rdev, &eg_pi->requested_rps);\r\nreturn 0;\r\n}\r\nstatic int si_power_control_set_level(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ps *new_ps = rdev->pm.dpm.requested_ps;\r\nint ret;\r\nret = si_restrict_performance_levels_before_switch(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = si_halt_smc(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = si_populate_smc_tdp_limits(rdev, new_ps);\r\nif (ret)\r\nreturn ret;\r\nret = si_populate_smc_tdp_limits_2(rdev, new_ps);\r\nif (ret)\r\nreturn ret;\r\nret = si_resume_smc(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = si_set_sw_state(rdev);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nint si_dpm_set_power_state(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *new_ps = &eg_pi->requested_rps;\r\nstruct radeon_ps *old_ps = &eg_pi->current_rps;\r\nint ret;\r\nret = si_disable_ulv(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_disable_ulv failed\n");\r\nreturn ret;\r\n}\r\nret = si_restrict_performance_levels_before_switch(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_restrict_performance_levels_before_switch failed\n");\r\nreturn ret;\r\n}\r\nif (eg_pi->pcie_performance_request)\r\nsi_request_link_speed_change_before_state_change(rdev, new_ps, old_ps);\r\nni_set_uvd_clock_before_set_eng_clock(rdev, new_ps, old_ps);\r\nret = si_enable_power_containment(rdev, new_ps, false);\r\nif (ret) {\r\nDRM_ERROR("si_enable_power_containment failed\n");\r\nreturn ret;\r\n}\r\nret = si_enable_smc_cac(rdev, new_ps, false);\r\nif (ret) {\r\nDRM_ERROR("si_enable_smc_cac failed\n");\r\nreturn ret;\r\n}\r\nret = si_halt_smc(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_halt_smc failed\n");\r\nreturn ret;\r\n}\r\nret = si_upload_sw_state(rdev, new_ps);\r\nif (ret) {\r\nDRM_ERROR("si_upload_sw_state failed\n");\r\nreturn ret;\r\n}\r\nret = si_upload_smc_data(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_upload_smc_data failed\n");\r\nreturn ret;\r\n}\r\nret = si_upload_ulv_state(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_upload_ulv_state failed\n");\r\nreturn ret;\r\n}\r\nif (eg_pi->dynamic_ac_timing) {\r\nret = si_upload_mc_reg_table(rdev, new_ps);\r\nif (ret) {\r\nDRM_ERROR("si_upload_mc_reg_table failed\n");\r\nreturn ret;\r\n}\r\n}\r\nret = si_program_memory_timing_parameters(rdev, new_ps);\r\nif (ret) {\r\nDRM_ERROR("si_program_memory_timing_parameters failed\n");\r\nreturn ret;\r\n}\r\nsi_set_pcie_lane_width_in_smc(rdev, new_ps, old_ps);\r\nret = si_resume_smc(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_resume_smc failed\n");\r\nreturn ret;\r\n}\r\nret = si_set_sw_state(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_set_sw_state failed\n");\r\nreturn ret;\r\n}\r\nni_set_uvd_clock_after_set_eng_clock(rdev, new_ps, old_ps);\r\nsi_set_vce_clock(rdev, new_ps, old_ps);\r\nif (eg_pi->pcie_performance_request)\r\nsi_notify_link_speed_change_after_state_change(rdev, new_ps, old_ps);\r\nret = si_set_power_state_conditionally_enable_ulv(rdev, new_ps);\r\nif (ret) {\r\nDRM_ERROR("si_set_power_state_conditionally_enable_ulv failed\n");\r\nreturn ret;\r\n}\r\nret = si_enable_smc_cac(rdev, new_ps, true);\r\nif (ret) {\r\nDRM_ERROR("si_enable_smc_cac failed\n");\r\nreturn ret;\r\n}\r\nret = si_enable_power_containment(rdev, new_ps, true);\r\nif (ret) {\r\nDRM_ERROR("si_enable_power_containment failed\n");\r\nreturn ret;\r\n}\r\nret = si_power_control_set_level(rdev);\r\nif (ret) {\r\nDRM_ERROR("si_power_control_set_level failed\n");\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nvoid si_dpm_post_set_power_state(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *new_ps = &eg_pi->requested_rps;\r\nni_update_current_ps(rdev, new_ps);\r\n}\r\nvoid si_dpm_display_configuration_changed(struct radeon_device *rdev)\r\n{\r\nsi_program_display_gap(rdev);\r\n}\r\nstatic void si_parse_pplib_non_clock_info(struct radeon_device *rdev,\r\nstruct radeon_ps *rps,\r\nstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info,\r\nu8 table_rev)\r\n{\r\nrps->caps = le32_to_cpu(non_clock_info->ulCapsAndSettings);\r\nrps->class = le16_to_cpu(non_clock_info->usClassification);\r\nrps->class2 = le16_to_cpu(non_clock_info->usClassification2);\r\nif (ATOM_PPLIB_NONCLOCKINFO_VER1 < table_rev) {\r\nrps->vclk = le32_to_cpu(non_clock_info->ulVCLK);\r\nrps->dclk = le32_to_cpu(non_clock_info->ulDCLK);\r\n} else if (r600_is_uvd_state(rps->class, rps->class2)) {\r\nrps->vclk = RV770_DEFAULT_VCLK_FREQ;\r\nrps->dclk = RV770_DEFAULT_DCLK_FREQ;\r\n} else {\r\nrps->vclk = 0;\r\nrps->dclk = 0;\r\n}\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT)\r\nrdev->pm.dpm.boot_ps = rps;\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_UVDSTATE)\r\nrdev->pm.dpm.uvd_ps = rps;\r\n}\r\nstatic void si_parse_pplib_clock_info(struct radeon_device *rdev,\r\nstruct radeon_ps *rps, int index,\r\nunion pplib_clock_info *clock_info)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct si_power_info *si_pi = si_get_pi(rdev);\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nu16 leakage_voltage;\r\nstruct rv7xx_pl *pl = &ps->performance_levels[index];\r\nint ret;\r\nps->performance_level_count = index + 1;\r\npl->sclk = le16_to_cpu(clock_info->si.usEngineClockLow);\r\npl->sclk |= clock_info->si.ucEngineClockHigh << 16;\r\npl->mclk = le16_to_cpu(clock_info->si.usMemoryClockLow);\r\npl->mclk |= clock_info->si.ucMemoryClockHigh << 16;\r\npl->vddc = le16_to_cpu(clock_info->si.usVDDC);\r\npl->vddci = le16_to_cpu(clock_info->si.usVDDCI);\r\npl->flags = le32_to_cpu(clock_info->si.ulFlags);\r\npl->pcie_gen = r600_get_pcie_gen_support(rdev,\r\nsi_pi->sys_pcie_mask,\r\nsi_pi->boot_pcie_gen,\r\nclock_info->si.ucPCIEGen);\r\nret = si_get_leakage_voltage_from_leakage_index(rdev, pl->vddc,\r\n&leakage_voltage);\r\nif (ret == 0)\r\npl->vddc = leakage_voltage;\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_ACPI) {\r\npi->acpi_vddc = pl->vddc;\r\neg_pi->acpi_vddci = pl->vddci;\r\nsi_pi->acpi_pcie_gen = pl->pcie_gen;\r\n}\r\nif ((rps->class2 & ATOM_PPLIB_CLASSIFICATION2_ULV) &&\r\nindex == 0) {\r\nsi_pi->ulv.supported = false;\r\nsi_pi->ulv.pl = *pl;\r\nsi_pi->ulv.one_pcie_lane_in_ulv = false;\r\nsi_pi->ulv.volt_change_delay = SISLANDS_ULVVOLTAGECHANGEDELAY_DFLT;\r\nsi_pi->ulv.cg_ulv_parameter = SISLANDS_CGULVPARAMETER_DFLT;\r\nsi_pi->ulv.cg_ulv_control = SISLANDS_CGULVCONTROL_DFLT;\r\n}\r\nif (pi->min_vddc_in_table > pl->vddc)\r\npi->min_vddc_in_table = pl->vddc;\r\nif (pi->max_vddc_in_table < pl->vddc)\r\npi->max_vddc_in_table = pl->vddc;\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT) {\r\nu16 vddc, vddci, mvdd;\r\nradeon_atombios_get_default_voltages(rdev, &vddc, &vddci, &mvdd);\r\npl->mclk = rdev->clock.default_mclk;\r\npl->sclk = rdev->clock.default_sclk;\r\npl->vddc = vddc;\r\npl->vddci = vddci;\r\nsi_pi->mvdd_bootup_value = mvdd;\r\n}\r\nif ((rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) ==\r\nATOM_PPLIB_CLASSIFICATION_UI_PERFORMANCE) {\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk = pl->sclk;\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.mclk = pl->mclk;\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddc = pl->vddc;\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddci = pl->vddci;\r\n}\r\n}\r\nstatic int si_parse_power_table(struct radeon_device *rdev)\r\n{\r\nstruct radeon_mode_info *mode_info = &rdev->mode_info;\r\nstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info;\r\nunion pplib_power_state *power_state;\r\nint i, j, k, non_clock_array_index, clock_array_index;\r\nunion pplib_clock_info *clock_info;\r\nstruct _StateArray *state_array;\r\nstruct _ClockInfoArray *clock_info_array;\r\nstruct _NonClockInfoArray *non_clock_info_array;\r\nunion power_info *power_info;\r\nint index = GetIndexIntoMasterTable(DATA, PowerPlayInfo);\r\nu16 data_offset;\r\nu8 frev, crev;\r\nu8 *power_state_offset;\r\nstruct ni_ps *ps;\r\nif (!atom_parse_data_header(mode_info->atom_context, index, NULL,\r\n&frev, &crev, &data_offset))\r\nreturn -EINVAL;\r\npower_info = (union power_info *)(mode_info->atom_context->bios + data_offset);\r\nstate_array = (struct _StateArray *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usStateArrayOffset));\r\nclock_info_array = (struct _ClockInfoArray *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usClockInfoArrayOffset));\r\nnon_clock_info_array = (struct _NonClockInfoArray *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usNonClockInfoArrayOffset));\r\nrdev->pm.dpm.ps = kzalloc(sizeof(struct radeon_ps) *\r\nstate_array->ucNumEntries, GFP_KERNEL);\r\nif (!rdev->pm.dpm.ps)\r\nreturn -ENOMEM;\r\npower_state_offset = (u8 *)state_array->states;\r\nfor (i = 0; i < state_array->ucNumEntries; i++) {\r\nu8 *idx;\r\npower_state = (union pplib_power_state *)power_state_offset;\r\nnon_clock_array_index = power_state->v2.nonClockInfoIndex;\r\nnon_clock_info = (struct _ATOM_PPLIB_NONCLOCK_INFO *)\r\n&non_clock_info_array->nonClockInfo[non_clock_array_index];\r\nif (!rdev->pm.power_state[i].clock_info)\r\nreturn -EINVAL;\r\nps = kzalloc(sizeof(struct ni_ps), GFP_KERNEL);\r\nif (ps == NULL) {\r\nkfree(rdev->pm.dpm.ps);\r\nreturn -ENOMEM;\r\n}\r\nrdev->pm.dpm.ps[i].ps_priv = ps;\r\nsi_parse_pplib_non_clock_info(rdev, &rdev->pm.dpm.ps[i],\r\nnon_clock_info,\r\nnon_clock_info_array->ucEntrySize);\r\nk = 0;\r\nidx = (u8 *)&power_state->v2.clockInfoIndex[0];\r\nfor (j = 0; j < power_state->v2.ucNumDPMLevels; j++) {\r\nclock_array_index = idx[j];\r\nif (clock_array_index >= clock_info_array->ucNumEntries)\r\ncontinue;\r\nif (k >= SISLANDS_MAX_HARDWARE_POWERLEVELS)\r\nbreak;\r\nclock_info = (union pplib_clock_info *)\r\n((u8 *)&clock_info_array->clockInfo[0] +\r\n(clock_array_index * clock_info_array->ucEntrySize));\r\nsi_parse_pplib_clock_info(rdev,\r\n&rdev->pm.dpm.ps[i], k,\r\nclock_info);\r\nk++;\r\n}\r\npower_state_offset += 2 + power_state->v2.ucNumDPMLevels;\r\n}\r\nrdev->pm.dpm.num_ps = state_array->ucNumEntries;\r\nfor (i = 0; i < RADEON_MAX_VCE_LEVELS; i++) {\r\nu32 sclk, mclk;\r\nclock_array_index = rdev->pm.dpm.vce_states[i].clk_idx;\r\nclock_info = (union pplib_clock_info *)\r\n&clock_info_array->clockInfo[clock_array_index * clock_info_array->ucEntrySize];\r\nsclk = le16_to_cpu(clock_info->si.usEngineClockLow);\r\nsclk |= clock_info->si.ucEngineClockHigh << 16;\r\nmclk = le16_to_cpu(clock_info->si.usMemoryClockLow);\r\nmclk |= clock_info->si.ucMemoryClockHigh << 16;\r\nrdev->pm.dpm.vce_states[i].sclk = sclk;\r\nrdev->pm.dpm.vce_states[i].mclk = mclk;\r\n}\r\nreturn 0;\r\n}\r\nint si_dpm_init(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi;\r\nstruct evergreen_power_info *eg_pi;\r\nstruct ni_power_info *ni_pi;\r\nstruct si_power_info *si_pi;\r\nstruct atom_clock_dividers dividers;\r\nint ret;\r\nu32 mask;\r\nsi_pi = kzalloc(sizeof(struct si_power_info), GFP_KERNEL);\r\nif (si_pi == NULL)\r\nreturn -ENOMEM;\r\nrdev->pm.dpm.priv = si_pi;\r\nni_pi = &si_pi->ni;\r\neg_pi = &ni_pi->eg;\r\npi = &eg_pi->rv7xx;\r\nret = drm_pcie_get_speed_cap_mask(rdev->ddev, &mask);\r\nif (ret)\r\nsi_pi->sys_pcie_mask = 0;\r\nelse\r\nsi_pi->sys_pcie_mask = mask;\r\nsi_pi->force_pcie_gen = RADEON_PCIE_GEN_INVALID;\r\nsi_pi->boot_pcie_gen = si_get_current_pcie_speed(rdev);\r\nsi_set_max_cu_value(rdev);\r\nrv770_get_max_vddc(rdev);\r\nsi_get_leakage_vddc(rdev);\r\nsi_patch_dependency_tables_based_on_leakage(rdev);\r\npi->acpi_vddc = 0;\r\neg_pi->acpi_vddci = 0;\r\npi->min_vddc_in_table = 0;\r\npi->max_vddc_in_table = 0;\r\nret = r600_get_platform_caps(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = r600_parse_extended_power_table(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = si_parse_power_table(rdev);\r\nif (ret)\r\nreturn ret;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries =\r\nkzalloc(4 * sizeof(struct radeon_clock_voltage_dependency_entry), GFP_KERNEL);\r\nif (!rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries) {\r\nr600_free_extended_power_table(rdev);\r\nreturn -ENOMEM;\r\n}\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.count = 4;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[0].clk = 0;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[0].v = 0;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[1].clk = 36000;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[1].v = 720;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[2].clk = 54000;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[2].v = 810;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[3].clk = 72000;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[3].v = 900;\r\nif (rdev->pm.dpm.voltage_response_time == 0)\r\nrdev->pm.dpm.voltage_response_time = R600_VOLTAGERESPONSETIME_DFLT;\r\nif (rdev->pm.dpm.backbias_response_time == 0)\r\nrdev->pm.dpm.backbias_response_time = R600_BACKBIASRESPONSETIME_DFLT;\r\nret = radeon_atom_get_clock_dividers(rdev, COMPUTE_ENGINE_PLL_PARAM,\r\n0, false, &dividers);\r\nif (ret)\r\npi->ref_div = dividers.ref_div + 1;\r\nelse\r\npi->ref_div = R600_REFERENCEDIVIDER_DFLT;\r\neg_pi->smu_uvd_hs = false;\r\npi->mclk_strobe_mode_threshold = 40000;\r\nif (si_is_special_1gb_platform(rdev))\r\npi->mclk_stutter_mode_threshold = 0;\r\nelse\r\npi->mclk_stutter_mode_threshold = pi->mclk_strobe_mode_threshold;\r\npi->mclk_edc_enable_threshold = 40000;\r\neg_pi->mclk_edc_wr_enable_threshold = 40000;\r\nni_pi->mclk_rtt_mode_threshold = eg_pi->mclk_edc_wr_enable_threshold;\r\npi->voltage_control =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_VDDC,\r\nVOLTAGE_OBJ_GPIO_LUT);\r\nif (!pi->voltage_control) {\r\nsi_pi->voltage_control_svi2 =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_VDDC,\r\nVOLTAGE_OBJ_SVID2);\r\nif (si_pi->voltage_control_svi2)\r\nradeon_atom_get_svi2_info(rdev, SET_VOLTAGE_TYPE_ASIC_VDDC,\r\n&si_pi->svd_gpio_id, &si_pi->svc_gpio_id);\r\n}\r\npi->mvdd_control =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_MVDDC,\r\nVOLTAGE_OBJ_GPIO_LUT);\r\neg_pi->vddci_control =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_VDDCI,\r\nVOLTAGE_OBJ_GPIO_LUT);\r\nif (!eg_pi->vddci_control)\r\nsi_pi->vddci_control_svi2 =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_VDDCI,\r\nVOLTAGE_OBJ_SVID2);\r\nsi_pi->vddc_phase_shed_control =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_VDDC,\r\nVOLTAGE_OBJ_PHASE_LUT);\r\nrv770_get_engine_memory_ss(rdev);\r\npi->asi = RV770_ASI_DFLT;\r\npi->pasi = CYPRESS_HASI_DFLT;\r\npi->vrc = SISLANDS_VRC_DFLT;\r\npi->gfx_clock_gating = true;\r\neg_pi->sclk_deep_sleep = true;\r\nsi_pi->sclk_deep_sleep_above_low = false;\r\nif (rdev->pm.int_thermal_type != THERMAL_TYPE_NONE)\r\npi->thermal_protection = true;\r\nelse\r\npi->thermal_protection = false;\r\neg_pi->dynamic_ac_timing = true;\r\neg_pi->light_sleep = true;\r\n#if defined(CONFIG_ACPI)\r\neg_pi->pcie_performance_request =\r\nradeon_acpi_is_pcie_performance_request_supported(rdev);\r\n#else\r\neg_pi->pcie_performance_request = false;\r\n#endif\r\nsi_pi->sram_end = SMC_RAM_END;\r\nrdev->pm.dpm.dyn_state.mclk_sclk_ratio = 4;\r\nrdev->pm.dpm.dyn_state.sclk_mclk_delta = 15000;\r\nrdev->pm.dpm.dyn_state.vddc_vddci_delta = 200;\r\nrdev->pm.dpm.dyn_state.valid_sclk_values.count = 0;\r\nrdev->pm.dpm.dyn_state.valid_sclk_values.values = NULL;\r\nrdev->pm.dpm.dyn_state.valid_mclk_values.count = 0;\r\nrdev->pm.dpm.dyn_state.valid_mclk_values.values = NULL;\r\nsi_initialize_powertune_defaults(rdev);\r\nif ((rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.sclk == 0) ||\r\n(rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.mclk == 0))\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_dc =\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\r\nsi_pi->fan_ctrl_is_in_default_mode = true;\r\nreturn 0;\r\n}\r\nvoid si_dpm_fini(struct radeon_device *rdev)\r\n{\r\nint i;\r\nfor (i = 0; i < rdev->pm.dpm.num_ps; i++) {\r\nkfree(rdev->pm.dpm.ps[i].ps_priv);\r\n}\r\nkfree(rdev->pm.dpm.ps);\r\nkfree(rdev->pm.dpm.priv);\r\nkfree(rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries);\r\nr600_free_extended_power_table(rdev);\r\n}\r\nvoid si_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,\r\nstruct seq_file *m)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *rps = &eg_pi->current_rps;\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl;\r\nu32 current_index =\r\n(RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_STATE_INDEX_MASK) >>\r\nCURRENT_STATE_INDEX_SHIFT;\r\nif (current_index >= ps->performance_level_count) {\r\nseq_printf(m, "invalid dpm profile %d\n", current_index);\r\n} else {\r\npl = &ps->performance_levels[current_index];\r\nseq_printf(m, "uvd vclk: %d dclk: %d\n", rps->vclk, rps->dclk);\r\nseq_printf(m, "power level %d sclk: %u mclk: %u vddc: %u vddci: %u pcie gen: %u\n",\r\ncurrent_index, pl->sclk, pl->mclk, pl->vddc, pl->vddci, pl->pcie_gen + 1);\r\n}\r\n}\r\nu32 si_dpm_get_current_sclk(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *rps = &eg_pi->current_rps;\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl;\r\nu32 current_index =\r\n(RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_STATE_INDEX_MASK) >>\r\nCURRENT_STATE_INDEX_SHIFT;\r\nif (current_index >= ps->performance_level_count) {\r\nreturn 0;\r\n} else {\r\npl = &ps->performance_levels[current_index];\r\nreturn pl->sclk;\r\n}\r\n}\r\nu32 si_dpm_get_current_mclk(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *rps = &eg_pi->current_rps;\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl;\r\nu32 current_index =\r\n(RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_STATE_INDEX_MASK) >>\r\nCURRENT_STATE_INDEX_SHIFT;\r\nif (current_index >= ps->performance_level_count) {\r\nreturn 0;\r\n} else {\r\npl = &ps->performance_levels[current_index];\r\nreturn pl->mclk;\r\n}\r\n}
