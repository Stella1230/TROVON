static int\r\nnv50_ram_timing_calc(struct nv50_ram *ram, u32 *timing)\r\n{\r\nstruct nvbios_ramcfg *cfg = &ram->base.target.bios;\r\nstruct nvkm_subdev *subdev = &ram->base.fb->subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nu32 cur2, cur4, cur7, cur8;\r\nu8 unkt3b;\r\ncur2 = nvkm_rd32(device, 0x100228);\r\ncur4 = nvkm_rd32(device, 0x100230);\r\ncur7 = nvkm_rd32(device, 0x10023c);\r\ncur8 = nvkm_rd32(device, 0x100240);\r\nswitch ((!T(CWL)) * ram->base.type) {\r\ncase NVKM_RAM_TYPE_DDR2:\r\nT(CWL) = T(CL) - 1;\r\nbreak;\r\ncase NVKM_RAM_TYPE_GDDR3:\r\nT(CWL) = ((cur2 & 0xff000000) >> 24) + 1;\r\nbreak;\r\n}\r\nif (device->chipset == 0xa0) {\r\nunkt3b = 0x19 + ram->base.next->bios.rammap_00_16_40;\r\ntiming[6] = (0x2d + T(CL) - T(CWL) +\r\nram->base.next->bios.rammap_00_16_40) << 16 |\r\nT(CWL) << 8 |\r\n(0x2f + T(CL) - T(CWL));\r\n} else {\r\nunkt3b = 0x16;\r\ntiming[6] = (0x2b + T(CL) - T(CWL)) << 16 |\r\nmax_t(s8, T(CWL) - 2, 1) << 8 |\r\n(0x2e + T(CL) - T(CWL));\r\n}\r\ntiming[0] = (T(RP) << 24 | T(RAS) << 16 | T(RFC) << 8 | T(RC));\r\ntiming[1] = (T(WR) + 1 + T(CWL)) << 24 |\r\nmax_t(u8, T(18), 1) << 16 |\r\n(T(WTR) + 1 + T(CWL)) << 8 |\r\n(3 + T(CL) - T(CWL));\r\ntiming[2] = (T(CWL) - 1) << 24 |\r\n(T(RRD) << 16) |\r\n(T(RCDWR) << 8) |\r\nT(RCDRD);\r\ntiming[3] = (unkt3b - 2 + T(CL)) << 24 |\r\nunkt3b << 16 |\r\n(T(CL) - 1) << 8 |\r\n(T(CL) - 1);\r\ntiming[4] = (cur4 & 0xffff0000) |\r\nT(13) << 8 |\r\nT(13);\r\ntiming[5] = T(RFC) << 24 |\r\nmax_t(u8, T(RCDRD), T(RCDWR)) << 16 |\r\nT(RP);\r\ntiming[7] = (cur7 & 0xff00ffff) | (T(CL) - 1) << 16;\r\ntiming[8] = (cur8 & 0xffffff00);\r\nif (ram->base.type == NVKM_RAM_TYPE_DDR2) {\r\ntiming[5] |= (T(CL) + 3) << 8;\r\ntiming[8] |= (T(CL) - 4);\r\n} else\r\nif (ram->base.type == NVKM_RAM_TYPE_GDDR3) {\r\ntiming[5] |= (T(CL) + 2) << 8;\r\ntiming[8] |= (T(CL) - 2);\r\n}\r\nnvkm_debug(subdev, " 220: %08x %08x %08x %08x\n",\r\ntiming[0], timing[1], timing[2], timing[3]);\r\nnvkm_debug(subdev, " 230: %08x %08x %08x %08x\n",\r\ntiming[4], timing[5], timing[6], timing[7]);\r\nnvkm_debug(subdev, " 240: %08x\n", timing[8]);\r\nreturn 0;\r\n}\r\nstatic int\r\nnv50_ram_timing_read(struct nv50_ram *ram, u32 *timing)\r\n{\r\nunsigned int i;\r\nstruct nvbios_ramcfg *cfg = &ram->base.target.bios;\r\nstruct nvkm_subdev *subdev = &ram->base.fb->subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nfor (i = 0; i <= 8; i++)\r\ntiming[i] = nvkm_rd32(device, 0x100220 + (i * 4));\r\ncfg->timing_ver = 0x10;\r\nT(CL) = (timing[3] & 0xff) + 1;\r\nswitch (ram->base.type) {\r\ncase NVKM_RAM_TYPE_DDR2:\r\nT(CWL) = T(CL) - 1;\r\nbreak;\r\ncase NVKM_RAM_TYPE_GDDR3:\r\nT(CWL) = ((timing[2] & 0xff000000) >> 24) + 1;\r\nbreak;\r\ndefault:\r\nreturn -ENOSYS;\r\nbreak;\r\n}\r\nT(WR) = ((timing[1] >> 24) & 0xff) - 1 - T(CWL);\r\nreturn 0;\r\n}\r\nstatic void\r\nnvkm_sddr2_dll_reset(struct nv50_ramseq *hwsq)\r\n{\r\nram_mask(hwsq, mr[0], 0x100, 0x100);\r\nram_mask(hwsq, mr[0], 0x100, 0x000);\r\nram_nsec(hwsq, 24000);\r\n}\r\nstatic void\r\nnv50_ram_gpio(struct nv50_ramseq *hwsq, u8 tag, u32 val)\r\n{\r\nstruct nvkm_gpio *gpio = hwsq->base.subdev->device->gpio;\r\nstruct dcb_gpio_func func;\r\nu32 reg, sh, gpio_val;\r\nint ret;\r\nif (nvkm_gpio_get(gpio, 0, tag, DCB_GPIO_UNUSED) != val) {\r\nret = nvkm_gpio_find(gpio, 0, tag, DCB_GPIO_UNUSED, &func);\r\nif (ret)\r\nreturn;\r\nreg = func.line >> 3;\r\nsh = (func.line & 0x7) << 2;\r\ngpio_val = ram_rd32(hwsq, gpio[reg]);\r\nif (gpio_val & (8 << sh))\r\nval = !val;\r\nif (!(func.log[1] & 1))\r\nval = !val;\r\nram_mask(hwsq, gpio[reg], (0x3 << sh), ((val | 0x2) << sh));\r\nram_nsec(hwsq, 20000);\r\n}\r\n}\r\nstatic int\r\nnv50_ram_calc(struct nvkm_ram *base, u32 freq)\r\n{\r\nstruct nv50_ram *ram = nv50_ram(base);\r\nstruct nv50_ramseq *hwsq = &ram->hwsq;\r\nstruct nvkm_subdev *subdev = &ram->base.fb->subdev;\r\nstruct nvkm_bios *bios = subdev->device->bios;\r\nstruct nvbios_perfE perfE;\r\nstruct nvbios_pll mpll;\r\nstruct nvkm_ram_data *next;\r\nu8 ver, hdr, cnt, len, strap, size;\r\nu32 data;\r\nu32 r100da0, r004008, unk710, unk714, unk718, unk71c;\r\nint N1, M1, N2, M2, P;\r\nint ret, i;\r\nu32 timing[9];\r\nnext = &ram->base.target;\r\nnext->freq = freq;\r\nram->base.next = next;\r\ni = 0;\r\ndo {\r\ndata = nvbios_perfEp(bios, i++, &ver, &hdr, &cnt,\r\n&size, &perfE);\r\nif (!data || (ver < 0x25 || ver >= 0x40) ||\r\n(size < 2)) {\r\nnvkm_error(subdev, "invalid/missing perftab entry\n");\r\nreturn -EINVAL;\r\n}\r\n} while (perfE.memory < freq);\r\nnvbios_rammapEp_from_perf(bios, data, hdr, &next->bios);\r\nstrap = nvbios_ramcfg_index(subdev);\r\nif (strap >= cnt) {\r\nnvkm_error(subdev, "invalid ramcfg strap\n");\r\nreturn -EINVAL;\r\n}\r\ndata = nvbios_rammapSp_from_perf(bios, data + hdr, size, strap,\r\n&next->bios);\r\nif (!data) {\r\nnvkm_error(subdev, "invalid/missing rammap entry ");\r\nreturn -EINVAL;\r\n}\r\nif (next->bios.ramcfg_timing != 0xff) {\r\ndata = nvbios_timingEp(bios, next->bios.ramcfg_timing,\r\n&ver, &hdr, &cnt, &len, &next->bios);\r\nif (!data || ver != 0x10 || hdr < 0x12) {\r\nnvkm_error(subdev, "invalid/missing timing entry "\r\n"%02x %04x %02x %02x\n",\r\nstrap, data, ver, hdr);\r\nreturn -EINVAL;\r\n}\r\nnv50_ram_timing_calc(ram, timing);\r\n} else {\r\nnv50_ram_timing_read(ram, timing);\r\n}\r\nret = ram_init(hwsq, subdev);\r\nif (ret)\r\nreturn ret;\r\nram->base.mr[0] = ram_rd32(hwsq, mr[0]);\r\nram->base.mr[1] = ram_rd32(hwsq, mr[1]);\r\nram->base.mr[2] = ram_rd32(hwsq, mr[2]);\r\nswitch (ram->base.type) {\r\ncase NVKM_RAM_TYPE_GDDR3:\r\nret = nvkm_gddr3_calc(&ram->base);\r\nbreak;\r\ndefault:\r\nret = -ENOSYS;\r\nbreak;\r\n}\r\nif (ret) {\r\nnvkm_error(subdev, "Could not calculate MR\n");\r\nreturn ret;\r\n}\r\nif (subdev->device->chipset <= 0x96 && !next->bios.ramcfg_00_03_02)\r\nram_mask(hwsq, 0x100710, 0x00000200, 0x00000000);\r\nram_mask(hwsq, 0x100200, 0x00000800, 0x00000000);\r\nram_wait_vblank(hwsq);\r\nram_wr32(hwsq, 0x611200, 0x00003300);\r\nram_wr32(hwsq, 0x002504, 0x00000001);\r\nram_nsec(hwsq, 8000);\r\nram_setf(hwsq, 0x10, 0x00);\r\nram_wait(hwsq, 0x00, 0x01);\r\nram_nsec(hwsq, 2000);\r\nif (next->bios.timing_10_ODT)\r\nnv50_ram_gpio(hwsq, 0x2e, 1);\r\nram_wr32(hwsq, 0x1002d4, 0x00000001);\r\nram_wr32(hwsq, 0x1002d0, 0x00000001);\r\nram_wr32(hwsq, 0x1002d0, 0x00000001);\r\nram_wr32(hwsq, 0x100210, 0x00000000);\r\nram_wr32(hwsq, 0x1002dc, 0x00000001);\r\nret = nvbios_pll_parse(bios, 0x004008, &mpll);\r\nmpll.vco2.max_freq = 0;\r\nif (ret >= 0) {\r\nret = nv04_pll_calc(subdev, &mpll, freq,\r\n&N1, &M1, &N2, &M2, &P);\r\nif (ret <= 0)\r\nret = -EINVAL;\r\n}\r\nif (ret < 0)\r\nreturn ret;\r\nif (freq <= 750000) {\r\nr100da0 = 0x00000010;\r\nr004008 = 0x90000000;\r\n} else {\r\nr100da0 = 0x00000000;\r\nr004008 = 0x80000000;\r\n}\r\nr004008 |= (mpll.bias_p << 19) | (P << 22) | (P << 16);\r\nram_mask(hwsq, 0x00c040, 0xc000c000, 0x0000c000);\r\nram_mask(hwsq, 0x004008, 0x00004200, 0x00000200 |\r\nnext->bios.rammap_00_16_40 << 14);\r\nram_mask(hwsq, 0x00400c, 0x0000ffff, (N1 << 8) | M1);\r\nram_mask(hwsq, 0x004008, 0x91ff0000, r004008);\r\nif (subdev->device->chipset >= 0x92)\r\nram_wr32(hwsq, 0x100da0, r100da0);\r\nnv50_ram_gpio(hwsq, 0x18, !next->bios.ramcfg_FBVDDQ);\r\nram_nsec(hwsq, 64000);\r\nram_nsec(hwsq, 32000);\r\nram_mask(hwsq, 0x004008, 0x00002200, 0x00002000);\r\nram_wr32(hwsq, 0x1002dc, 0x00000000);\r\nram_wr32(hwsq, 0x1002d4, 0x00000001);\r\nram_wr32(hwsq, 0x100210, 0x80000000);\r\nram_nsec(hwsq, 12000);\r\nswitch (ram->base.type) {\r\ncase NVKM_RAM_TYPE_DDR2:\r\nram_nuke(hwsq, mr[0]);\r\nram_mask(hwsq, mr[0], 0x000, 0x000);\r\nbreak;\r\ncase NVKM_RAM_TYPE_GDDR3:\r\nram_nuke(hwsq, mr[1]);\r\nram_wr32(hwsq, mr[1], ram->base.mr[1]);\r\nram_nuke(hwsq, mr[0]);\r\nram_wr32(hwsq, mr[0], ram->base.mr[0]);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nram_mask(hwsq, timing[3], 0xffffffff, timing[3]);\r\nram_mask(hwsq, timing[1], 0xffffffff, timing[1]);\r\nram_mask(hwsq, timing[6], 0xffffffff, timing[6]);\r\nram_mask(hwsq, timing[7], 0xffffffff, timing[7]);\r\nram_mask(hwsq, timing[8], 0xffffffff, timing[8]);\r\nram_mask(hwsq, timing[0], 0xffffffff, timing[0]);\r\nram_mask(hwsq, timing[2], 0xffffffff, timing[2]);\r\nram_mask(hwsq, timing[4], 0xffffffff, timing[4]);\r\nram_mask(hwsq, timing[5], 0xffffffff, timing[5]);\r\nif (!next->bios.ramcfg_00_03_02)\r\nram_mask(hwsq, 0x10021c, 0x00010000, 0x00000000);\r\nram_mask(hwsq, 0x100200, 0x00001000, !next->bios.ramcfg_00_04_02 << 12);\r\nunk710 = ram_rd32(hwsq, 0x100710) & ~0x00000100;\r\nunk714 = ram_rd32(hwsq, 0x100714) & ~0xf0000020;\r\nunk718 = ram_rd32(hwsq, 0x100718) & ~0x00000100;\r\nunk71c = ram_rd32(hwsq, 0x10071c) & ~0x00000100;\r\nif (subdev->device->chipset <= 0x96) {\r\nunk710 &= ~0x0000006e;\r\nunk714 &= ~0x00000100;\r\nif (!next->bios.ramcfg_00_03_08)\r\nunk710 |= 0x00000060;\r\nif (!next->bios.ramcfg_FBVDDQ)\r\nunk714 |= 0x00000100;\r\nif ( next->bios.ramcfg_00_04_04)\r\nunk710 |= 0x0000000e;\r\n} else {\r\nunk710 &= ~0x00000001;\r\nif (!next->bios.ramcfg_00_03_08)\r\nunk710 |= 0x00000001;\r\n}\r\nif ( next->bios.ramcfg_00_03_01)\r\nunk71c |= 0x00000100;\r\nif ( next->bios.ramcfg_00_03_02)\r\nunk710 |= 0x00000100;\r\nif (!next->bios.ramcfg_00_03_08)\r\nunk714 |= 0x00000020;\r\nif ( next->bios.ramcfg_00_04_04)\r\nunk714 |= 0x70000000;\r\nif ( next->bios.ramcfg_00_04_20)\r\nunk718 |= 0x00000100;\r\nram_mask(hwsq, 0x100714, 0xffffffff, unk714);\r\nram_mask(hwsq, 0x10071c, 0xffffffff, unk71c);\r\nram_mask(hwsq, 0x100718, 0xffffffff, unk718);\r\nram_mask(hwsq, 0x100710, 0xffffffff, unk710);\r\nif (next->bios.rammap_00_16_20) {\r\nram_wr32(hwsq, 0x1005a0, next->bios.ramcfg_00_07 << 16 |\r\nnext->bios.ramcfg_00_06 << 8 |\r\nnext->bios.ramcfg_00_05);\r\nram_wr32(hwsq, 0x1005a4, next->bios.ramcfg_00_09 << 8 |\r\nnext->bios.ramcfg_00_08);\r\nram_mask(hwsq, 0x10053c, 0x00001000, 0x00000000);\r\n} else {\r\nram_mask(hwsq, 0x10053c, 0x00001000, 0x00001000);\r\n}\r\nram_mask(hwsq, mr[1], 0xffffffff, ram->base.mr[1]);\r\nif (!next->bios.timing_10_ODT)\r\nnv50_ram_gpio(hwsq, 0x2e, 0);\r\nif (!next->bios.ramcfg_DLLoff)\r\nnvkm_sddr2_dll_reset(hwsq);\r\nram_setf(hwsq, 0x10, 0x01);\r\nram_wait(hwsq, 0x00, 0x00);\r\nram_wr32(hwsq, 0x611200, 0x00003330);\r\nram_wr32(hwsq, 0x002504, 0x00000000);\r\nif (next->bios.rammap_00_17_02)\r\nram_mask(hwsq, 0x100200, 0x00000800, 0x00000800);\r\nif (!next->bios.rammap_00_16_40)\r\nram_mask(hwsq, 0x004008, 0x00004000, 0x00000000);\r\nif (next->bios.ramcfg_00_03_02)\r\nram_mask(hwsq, 0x10021c, 0x00010000, 0x00010000);\r\nif (subdev->device->chipset <= 0x96 && next->bios.ramcfg_00_03_02)\r\nram_mask(hwsq, 0x100710, 0x00000200, 0x00000200);\r\nreturn 0;\r\n}\r\nstatic int\r\nnv50_ram_prog(struct nvkm_ram *base)\r\n{\r\nstruct nv50_ram *ram = nv50_ram(base);\r\nstruct nvkm_device *device = ram->base.fb->subdev.device;\r\nram_exec(&ram->hwsq, nvkm_boolopt(device->cfgopt, "NvMemExec", true));\r\nreturn 0;\r\n}\r\nstatic void\r\nnv50_ram_tidy(struct nvkm_ram *base)\r\n{\r\nstruct nv50_ram *ram = nv50_ram(base);\r\nram_exec(&ram->hwsq, false);\r\n}\r\nvoid\r\n__nv50_ram_put(struct nvkm_ram *ram, struct nvkm_mem *mem)\r\n{\r\nstruct nvkm_mm_node *this;\r\nwhile (!list_empty(&mem->regions)) {\r\nthis = list_first_entry(&mem->regions, typeof(*this), rl_entry);\r\nlist_del(&this->rl_entry);\r\nnvkm_mm_free(&ram->vram, &this);\r\n}\r\nnvkm_mm_free(&ram->tags, &mem->tag);\r\n}\r\nvoid\r\nnv50_ram_put(struct nvkm_ram *ram, struct nvkm_mem **pmem)\r\n{\r\nstruct nvkm_mem *mem = *pmem;\r\n*pmem = NULL;\r\nif (unlikely(mem == NULL))\r\nreturn;\r\nmutex_lock(&ram->fb->subdev.mutex);\r\n__nv50_ram_put(ram, mem);\r\nmutex_unlock(&ram->fb->subdev.mutex);\r\nkfree(mem);\r\n}\r\nint\r\nnv50_ram_get(struct nvkm_ram *ram, u64 size, u32 align, u32 ncmin,\r\nu32 memtype, struct nvkm_mem **pmem)\r\n{\r\nstruct nvkm_mm *heap = &ram->vram;\r\nstruct nvkm_mm *tags = &ram->tags;\r\nstruct nvkm_mm_node *r;\r\nstruct nvkm_mem *mem;\r\nint comp = (memtype & 0x300) >> 8;\r\nint type = (memtype & 0x07f);\r\nint back = (memtype & 0x800);\r\nint min, max, ret;\r\nmax = (size >> NVKM_RAM_MM_SHIFT);\r\nmin = ncmin ? (ncmin >> NVKM_RAM_MM_SHIFT) : max;\r\nalign >>= NVKM_RAM_MM_SHIFT;\r\nmem = kzalloc(sizeof(*mem), GFP_KERNEL);\r\nif (!mem)\r\nreturn -ENOMEM;\r\nmutex_lock(&ram->fb->subdev.mutex);\r\nif (comp) {\r\nif (align == (1 << (16 - NVKM_RAM_MM_SHIFT))) {\r\nint n = (max >> 4) * comp;\r\nret = nvkm_mm_head(tags, 0, 1, n, n, 1, &mem->tag);\r\nif (ret)\r\nmem->tag = NULL;\r\n}\r\nif (unlikely(!mem->tag))\r\ncomp = 0;\r\n}\r\nINIT_LIST_HEAD(&mem->regions);\r\nmem->memtype = (comp << 7) | type;\r\nmem->size = max;\r\ntype = nv50_fb_memtype[type];\r\ndo {\r\nif (back)\r\nret = nvkm_mm_tail(heap, 0, type, max, min, align, &r);\r\nelse\r\nret = nvkm_mm_head(heap, 0, type, max, min, align, &r);\r\nif (ret) {\r\nmutex_unlock(&ram->fb->subdev.mutex);\r\nram->func->put(ram, &mem);\r\nreturn ret;\r\n}\r\nlist_add_tail(&r->rl_entry, &mem->regions);\r\nmax -= r->length;\r\n} while (max);\r\nmutex_unlock(&ram->fb->subdev.mutex);\r\nr = list_first_entry(&mem->regions, struct nvkm_mm_node, rl_entry);\r\nmem->offset = (u64)r->offset << NVKM_RAM_MM_SHIFT;\r\n*pmem = mem;\r\nreturn 0;\r\n}\r\nstatic u32\r\nnv50_fb_vram_rblock(struct nvkm_ram *ram)\r\n{\r\nstruct nvkm_subdev *subdev = &ram->fb->subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nint colbits, rowbitsa, rowbitsb, banks;\r\nu64 rowsize, predicted;\r\nu32 r0, r4, rt, rblock_size;\r\nr0 = nvkm_rd32(device, 0x100200);\r\nr4 = nvkm_rd32(device, 0x100204);\r\nrt = nvkm_rd32(device, 0x100250);\r\nnvkm_debug(subdev, "memcfg %08x %08x %08x %08x\n",\r\nr0, r4, rt, nvkm_rd32(device, 0x001540));\r\ncolbits = (r4 & 0x0000f000) >> 12;\r\nrowbitsa = ((r4 & 0x000f0000) >> 16) + 8;\r\nrowbitsb = ((r4 & 0x00f00000) >> 20) + 8;\r\nbanks = 1 << (((r4 & 0x03000000) >> 24) + 2);\r\nrowsize = ram->parts * banks * (1 << colbits) * 8;\r\npredicted = rowsize << rowbitsa;\r\nif (r0 & 0x00000004)\r\npredicted += rowsize << rowbitsb;\r\nif (predicted != ram->size) {\r\nnvkm_warn(subdev, "memory controller reports %d MiB VRAM\n",\r\n(u32)(ram->size >> 20));\r\n}\r\nrblock_size = rowsize;\r\nif (rt & 1)\r\nrblock_size *= 3;\r\nnvkm_debug(subdev, "rblock %d bytes\n", rblock_size);\r\nreturn rblock_size;\r\n}\r\nint\r\nnv50_ram_ctor(const struct nvkm_ram_func *func,\r\nstruct nvkm_fb *fb, struct nvkm_ram *ram)\r\n{\r\nstruct nvkm_device *device = fb->subdev.device;\r\nstruct nvkm_bios *bios = device->bios;\r\nconst u32 rsvd_head = ( 256 * 1024);\r\nconst u32 rsvd_tail = (1024 * 1024);\r\nu64 size = nvkm_rd32(device, 0x10020c);\r\nu32 tags = nvkm_rd32(device, 0x100320);\r\nenum nvkm_ram_type type = NVKM_RAM_TYPE_UNKNOWN;\r\nint ret;\r\nswitch (nvkm_rd32(device, 0x100714) & 0x00000007) {\r\ncase 0: type = NVKM_RAM_TYPE_DDR1; break;\r\ncase 1:\r\nif (nvkm_fb_bios_memtype(bios) == NVKM_RAM_TYPE_DDR3)\r\ntype = NVKM_RAM_TYPE_DDR3;\r\nelse\r\ntype = NVKM_RAM_TYPE_DDR2;\r\nbreak;\r\ncase 2: type = NVKM_RAM_TYPE_GDDR3; break;\r\ncase 3: type = NVKM_RAM_TYPE_GDDR4; break;\r\ncase 4: type = NVKM_RAM_TYPE_GDDR5; break;\r\ndefault:\r\nbreak;\r\n}\r\nsize = (size & 0x000000ff) << 32 | (size & 0xffffff00);\r\nret = nvkm_ram_ctor(func, fb, type, size, tags, ram);\r\nif (ret)\r\nreturn ret;\r\nram->part_mask = (nvkm_rd32(device, 0x001540) & 0x00ff0000) >> 16;\r\nram->parts = hweight8(ram->part_mask);\r\nram->ranks = (nvkm_rd32(device, 0x100200) & 0x4) ? 2 : 1;\r\nnvkm_mm_fini(&ram->vram);\r\nreturn nvkm_mm_init(&ram->vram, rsvd_head >> NVKM_RAM_MM_SHIFT,\r\n(size - rsvd_head - rsvd_tail) >> NVKM_RAM_MM_SHIFT,\r\nnv50_fb_vram_rblock(ram) >> NVKM_RAM_MM_SHIFT);\r\n}\r\nint\r\nnv50_ram_new(struct nvkm_fb *fb, struct nvkm_ram **pram)\r\n{\r\nstruct nv50_ram *ram;\r\nint ret, i;\r\nif (!(ram = kzalloc(sizeof(*ram), GFP_KERNEL)))\r\nreturn -ENOMEM;\r\n*pram = &ram->base;\r\nret = nv50_ram_ctor(&nv50_ram_func, fb, &ram->base);\r\nif (ret)\r\nreturn ret;\r\nram->hwsq.r_0x002504 = hwsq_reg(0x002504);\r\nram->hwsq.r_0x00c040 = hwsq_reg(0x00c040);\r\nram->hwsq.r_0x004008 = hwsq_reg(0x004008);\r\nram->hwsq.r_0x00400c = hwsq_reg(0x00400c);\r\nram->hwsq.r_0x100200 = hwsq_reg(0x100200);\r\nram->hwsq.r_0x100210 = hwsq_reg(0x100210);\r\nram->hwsq.r_0x10021c = hwsq_reg(0x10021c);\r\nram->hwsq.r_0x1002d0 = hwsq_reg(0x1002d0);\r\nram->hwsq.r_0x1002d4 = hwsq_reg(0x1002d4);\r\nram->hwsq.r_0x1002dc = hwsq_reg(0x1002dc);\r\nram->hwsq.r_0x10053c = hwsq_reg(0x10053c);\r\nram->hwsq.r_0x1005a0 = hwsq_reg(0x1005a0);\r\nram->hwsq.r_0x1005a4 = hwsq_reg(0x1005a4);\r\nram->hwsq.r_0x100710 = hwsq_reg(0x100710);\r\nram->hwsq.r_0x100714 = hwsq_reg(0x100714);\r\nram->hwsq.r_0x100718 = hwsq_reg(0x100718);\r\nram->hwsq.r_0x10071c = hwsq_reg(0x10071c);\r\nram->hwsq.r_0x100da0 = hwsq_stride(0x100da0, 4, ram->base.part_mask);\r\nram->hwsq.r_0x100e20 = hwsq_reg(0x100e20);\r\nram->hwsq.r_0x100e24 = hwsq_reg(0x100e24);\r\nram->hwsq.r_0x611200 = hwsq_reg(0x611200);\r\nfor (i = 0; i < 9; i++)\r\nram->hwsq.r_timing[i] = hwsq_reg(0x100220 + (i * 0x04));\r\nif (ram->base.ranks > 1) {\r\nram->hwsq.r_mr[0] = hwsq_reg2(0x1002c0, 0x1002c8);\r\nram->hwsq.r_mr[1] = hwsq_reg2(0x1002c4, 0x1002cc);\r\nram->hwsq.r_mr[2] = hwsq_reg2(0x1002e0, 0x1002e8);\r\nram->hwsq.r_mr[3] = hwsq_reg2(0x1002e4, 0x1002ec);\r\n} else {\r\nram->hwsq.r_mr[0] = hwsq_reg(0x1002c0);\r\nram->hwsq.r_mr[1] = hwsq_reg(0x1002c4);\r\nram->hwsq.r_mr[2] = hwsq_reg(0x1002e0);\r\nram->hwsq.r_mr[3] = hwsq_reg(0x1002e4);\r\n}\r\nram->hwsq.r_gpio[0] = hwsq_reg(0x00e104);\r\nram->hwsq.r_gpio[1] = hwsq_reg(0x00e108);\r\nram->hwsq.r_gpio[2] = hwsq_reg(0x00e120);\r\nram->hwsq.r_gpio[3] = hwsq_reg(0x00e124);\r\nreturn 0;\r\n}
