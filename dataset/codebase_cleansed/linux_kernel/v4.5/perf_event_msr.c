static bool test_aperfmperf(int idx)\r\n{\r\nreturn boot_cpu_has(X86_FEATURE_APERFMPERF);\r\n}\r\nstatic bool test_intel(int idx)\r\n{\r\nif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL ||\r\nboot_cpu_data.x86 != 6)\r\nreturn false;\r\nswitch (boot_cpu_data.x86_model) {\r\ncase 30:\r\ncase 26:\r\ncase 46:\r\ncase 37:\r\ncase 44:\r\ncase 47:\r\ncase 42:\r\ncase 45:\r\ncase 58:\r\ncase 62:\r\ncase 60:\r\ncase 63:\r\ncase 69:\r\ncase 70:\r\ncase 61:\r\ncase 86:\r\ncase 71:\r\ncase 79:\r\ncase 55:\r\ncase 77:\r\ncase 76:\r\nif (idx == PERF_MSR_SMI)\r\nreturn true;\r\nbreak;\r\ncase 78:\r\ncase 94:\r\nif (idx == PERF_MSR_SMI || idx == PERF_MSR_PPERF)\r\nreturn true;\r\nbreak;\r\n}\r\nreturn false;\r\n}\r\nstatic int msr_event_init(struct perf_event *event)\r\n{\r\nu64 cfg = event->attr.config;\r\nif (event->attr.type != event->pmu->type)\r\nreturn -ENOENT;\r\nif (cfg >= PERF_MSR_EVENT_MAX)\r\nreturn -EINVAL;\r\nif (event->attr.exclude_user ||\r\nevent->attr.exclude_kernel ||\r\nevent->attr.exclude_hv ||\r\nevent->attr.exclude_idle ||\r\nevent->attr.exclude_host ||\r\nevent->attr.exclude_guest ||\r\nevent->attr.sample_period)\r\nreturn -EINVAL;\r\nif (!msr[cfg].attr)\r\nreturn -EINVAL;\r\nevent->hw.idx = -1;\r\nevent->hw.event_base = msr[cfg].msr;\r\nevent->hw.config = cfg;\r\nreturn 0;\r\n}\r\nstatic inline u64 msr_read_counter(struct perf_event *event)\r\n{\r\nu64 now;\r\nif (event->hw.event_base)\r\nrdmsrl(event->hw.event_base, now);\r\nelse\r\nrdtscll(now);\r\nreturn now;\r\n}\r\nstatic void msr_event_update(struct perf_event *event)\r\n{\r\nu64 prev, now;\r\ns64 delta;\r\nagain:\r\nprev = local64_read(&event->hw.prev_count);\r\nnow = msr_read_counter(event);\r\nif (local64_cmpxchg(&event->hw.prev_count, prev, now) != prev)\r\ngoto again;\r\ndelta = now - prev;\r\nif (unlikely(event->hw.event_base == MSR_SMI_COUNT))\r\ndelta = sign_extend64(delta, 31);\r\nlocal64_add(now - prev, &event->count);\r\n}\r\nstatic void msr_event_start(struct perf_event *event, int flags)\r\n{\r\nu64 now;\r\nnow = msr_read_counter(event);\r\nlocal64_set(&event->hw.prev_count, now);\r\n}\r\nstatic void msr_event_stop(struct perf_event *event, int flags)\r\n{\r\nmsr_event_update(event);\r\n}\r\nstatic void msr_event_del(struct perf_event *event, int flags)\r\n{\r\nmsr_event_stop(event, PERF_EF_UPDATE);\r\n}\r\nstatic int msr_event_add(struct perf_event *event, int flags)\r\n{\r\nif (flags & PERF_EF_START)\r\nmsr_event_start(event, flags);\r\nreturn 0;\r\n}\r\nstatic int __init msr_init(void)\r\n{\r\nint i, j = 0;\r\nif (!boot_cpu_has(X86_FEATURE_TSC)) {\r\npr_cont("no MSR PMU driver.\n");\r\nreturn 0;\r\n}\r\nfor (i = PERF_MSR_TSC + 1; i < PERF_MSR_EVENT_MAX; i++) {\r\nu64 val;\r\nif (!msr[i].test(i) || rdmsrl_safe(msr[i].msr, &val))\r\nmsr[i].attr = NULL;\r\n}\r\nfor (i = 0; i < PERF_MSR_EVENT_MAX; i++) {\r\nif (msr[i].attr)\r\nevents_attrs[j++] = &msr[i].attr->attr.attr;\r\n}\r\nevents_attrs[j] = NULL;\r\nperf_pmu_register(&pmu_msr, "msr", -1);\r\nreturn 0;\r\n}
