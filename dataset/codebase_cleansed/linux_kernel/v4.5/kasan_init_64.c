static int __init map_range(struct range *range)\r\n{\r\nunsigned long start;\r\nunsigned long end;\r\nstart = (unsigned long)kasan_mem_to_shadow(pfn_to_kaddr(range->start));\r\nend = (unsigned long)kasan_mem_to_shadow(pfn_to_kaddr(range->end));\r\nreturn vmemmap_populate(start, end + 1, NUMA_NO_NODE);\r\n}\r\nstatic void __init clear_pgds(unsigned long start,\r\nunsigned long end)\r\n{\r\nfor (; start < end; start += PGDIR_SIZE)\r\npgd_clear(pgd_offset_k(start));\r\n}\r\nstatic void __init kasan_map_early_shadow(pgd_t *pgd)\r\n{\r\nint i;\r\nunsigned long start = KASAN_SHADOW_START;\r\nunsigned long end = KASAN_SHADOW_END;\r\nfor (i = pgd_index(start); start < end; i++) {\r\npgd[i] = __pgd(__pa_nodebug(kasan_zero_pud)\r\n| _KERNPG_TABLE);\r\nstart += PGDIR_SIZE;\r\n}\r\n}\r\nstatic int kasan_die_handler(struct notifier_block *self,\r\nunsigned long val,\r\nvoid *data)\r\n{\r\nif (val == DIE_GPF) {\r\npr_emerg("CONFIG_KASAN_INLINE enabled");\r\npr_emerg("GPF could be caused by NULL-ptr deref or user memory access");\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nvoid __init kasan_early_init(void)\r\n{\r\nint i;\r\npteval_t pte_val = __pa_nodebug(kasan_zero_page) | __PAGE_KERNEL;\r\npmdval_t pmd_val = __pa_nodebug(kasan_zero_pte) | _KERNPG_TABLE;\r\npudval_t pud_val = __pa_nodebug(kasan_zero_pmd) | _KERNPG_TABLE;\r\nfor (i = 0; i < PTRS_PER_PTE; i++)\r\nkasan_zero_pte[i] = __pte(pte_val);\r\nfor (i = 0; i < PTRS_PER_PMD; i++)\r\nkasan_zero_pmd[i] = __pmd(pmd_val);\r\nfor (i = 0; i < PTRS_PER_PUD; i++)\r\nkasan_zero_pud[i] = __pud(pud_val);\r\nkasan_map_early_shadow(early_level4_pgt);\r\nkasan_map_early_shadow(init_level4_pgt);\r\n}\r\nvoid __init kasan_init(void)\r\n{\r\nint i;\r\n#ifdef CONFIG_KASAN_INLINE\r\nregister_die_notifier(&kasan_die_notifier);\r\n#endif\r\nmemcpy(early_level4_pgt, init_level4_pgt, sizeof(early_level4_pgt));\r\nload_cr3(early_level4_pgt);\r\n__flush_tlb_all();\r\nclear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);\r\nkasan_populate_zero_shadow((void *)KASAN_SHADOW_START,\r\nkasan_mem_to_shadow((void *)PAGE_OFFSET));\r\nfor (i = 0; i < E820_X_MAX; i++) {\r\nif (pfn_mapped[i].end == 0)\r\nbreak;\r\nif (map_range(&pfn_mapped[i]))\r\npanic("kasan: unable to allocate shadow!");\r\n}\r\nkasan_populate_zero_shadow(\r\nkasan_mem_to_shadow((void *)PAGE_OFFSET + MAXMEM),\r\nkasan_mem_to_shadow((void *)__START_KERNEL_map));\r\nvmemmap_populate((unsigned long)kasan_mem_to_shadow(_stext),\r\n(unsigned long)kasan_mem_to_shadow(_end),\r\nNUMA_NO_NODE);\r\nkasan_populate_zero_shadow(kasan_mem_to_shadow((void *)MODULES_END),\r\n(void *)KASAN_SHADOW_END);\r\nmemset(kasan_zero_page, 0, PAGE_SIZE);\r\nload_cr3(init_level4_pgt);\r\n__flush_tlb_all();\r\ninit_task.kasan_depth = 0;\r\npr_info("KernelAddressSanitizer initialized\n");\r\n}
