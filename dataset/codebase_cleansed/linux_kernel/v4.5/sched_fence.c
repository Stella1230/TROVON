struct amd_sched_fence *amd_sched_fence_create(struct amd_sched_entity *s_entity, void *owner)\r\n{\r\nstruct amd_sched_fence *fence = NULL;\r\nunsigned seq;\r\nfence = kmem_cache_zalloc(sched_fence_slab, GFP_KERNEL);\r\nif (fence == NULL)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&fence->scheduled_cb);\r\nfence->owner = owner;\r\nfence->sched = s_entity->sched;\r\nspin_lock_init(&fence->lock);\r\nseq = atomic_inc_return(&s_entity->fence_seq);\r\nfence_init(&fence->base, &amd_sched_fence_ops, &fence->lock,\r\ns_entity->fence_context, seq);\r\nreturn fence;\r\n}\r\nvoid amd_sched_fence_signal(struct amd_sched_fence *fence)\r\n{\r\nint ret = fence_signal(&fence->base);\r\nif (!ret)\r\nFENCE_TRACE(&fence->base, "signaled from irq context\n");\r\nelse\r\nFENCE_TRACE(&fence->base, "was already signaled\n");\r\n}\r\nvoid amd_sched_fence_scheduled(struct amd_sched_fence *s_fence)\r\n{\r\nstruct fence_cb *cur, *tmp;\r\nset_bit(AMD_SCHED_FENCE_SCHEDULED_BIT, &s_fence->base.flags);\r\nlist_for_each_entry_safe(cur, tmp, &s_fence->scheduled_cb, node) {\r\nlist_del_init(&cur->node);\r\ncur->func(&s_fence->base, cur);\r\n}\r\n}\r\nstatic const char *amd_sched_fence_get_driver_name(struct fence *fence)\r\n{\r\nreturn "amd_sched";\r\n}\r\nstatic const char *amd_sched_fence_get_timeline_name(struct fence *f)\r\n{\r\nstruct amd_sched_fence *fence = to_amd_sched_fence(f);\r\nreturn (const char *)fence->sched->name;\r\n}\r\nstatic bool amd_sched_fence_enable_signaling(struct fence *f)\r\n{\r\nreturn true;\r\n}\r\nstatic void amd_sched_fence_release(struct fence *f)\r\n{\r\nstruct amd_sched_fence *fence = to_amd_sched_fence(f);\r\nkmem_cache_free(sched_fence_slab, fence);\r\n}
