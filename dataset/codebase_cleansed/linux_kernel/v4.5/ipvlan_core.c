void ipvlan_init_secret(void)\r\n{\r\nnet_get_random_once(&ipvlan_jhash_secret, sizeof(ipvlan_jhash_secret));\r\n}\r\nstatic void ipvlan_count_rx(const struct ipvl_dev *ipvlan,\r\nunsigned int len, bool success, bool mcast)\r\n{\r\nif (!ipvlan)\r\nreturn;\r\nif (likely(success)) {\r\nstruct ipvl_pcpu_stats *pcptr;\r\npcptr = this_cpu_ptr(ipvlan->pcpu_stats);\r\nu64_stats_update_begin(&pcptr->syncp);\r\npcptr->rx_pkts++;\r\npcptr->rx_bytes += len;\r\nif (mcast)\r\npcptr->rx_mcast++;\r\nu64_stats_update_end(&pcptr->syncp);\r\n} else {\r\nthis_cpu_inc(ipvlan->pcpu_stats->rx_errs);\r\n}\r\n}\r\nstatic u8 ipvlan_get_v6_hash(const void *iaddr)\r\n{\r\nconst struct in6_addr *ip6_addr = iaddr;\r\nreturn __ipv6_addr_jhash(ip6_addr, ipvlan_jhash_secret) &\r\nIPVLAN_HASH_MASK;\r\n}\r\nstatic u8 ipvlan_get_v4_hash(const void *iaddr)\r\n{\r\nconst struct in_addr *ip4_addr = iaddr;\r\nreturn jhash_1word(ip4_addr->s_addr, ipvlan_jhash_secret) &\r\nIPVLAN_HASH_MASK;\r\n}\r\nstruct ipvl_addr *ipvlan_ht_addr_lookup(const struct ipvl_port *port,\r\nconst void *iaddr, bool is_v6)\r\n{\r\nstruct ipvl_addr *addr;\r\nu8 hash;\r\nhash = is_v6 ? ipvlan_get_v6_hash(iaddr) :\r\nipvlan_get_v4_hash(iaddr);\r\nhlist_for_each_entry_rcu(addr, &port->hlhead[hash], hlnode) {\r\nif (is_v6 && addr->atype == IPVL_IPV6 &&\r\nipv6_addr_equal(&addr->ip6addr, iaddr))\r\nreturn addr;\r\nelse if (!is_v6 && addr->atype == IPVL_IPV4 &&\r\naddr->ip4addr.s_addr ==\r\n((struct in_addr *)iaddr)->s_addr)\r\nreturn addr;\r\n}\r\nreturn NULL;\r\n}\r\nvoid ipvlan_ht_addr_add(struct ipvl_dev *ipvlan, struct ipvl_addr *addr)\r\n{\r\nstruct ipvl_port *port = ipvlan->port;\r\nu8 hash;\r\nhash = (addr->atype == IPVL_IPV6) ?\r\nipvlan_get_v6_hash(&addr->ip6addr) :\r\nipvlan_get_v4_hash(&addr->ip4addr);\r\nif (hlist_unhashed(&addr->hlnode))\r\nhlist_add_head_rcu(&addr->hlnode, &port->hlhead[hash]);\r\n}\r\nvoid ipvlan_ht_addr_del(struct ipvl_addr *addr)\r\n{\r\nhlist_del_init_rcu(&addr->hlnode);\r\n}\r\nstruct ipvl_addr *ipvlan_find_addr(const struct ipvl_dev *ipvlan,\r\nconst void *iaddr, bool is_v6)\r\n{\r\nstruct ipvl_addr *addr;\r\nlist_for_each_entry(addr, &ipvlan->addrs, anode) {\r\nif ((is_v6 && addr->atype == IPVL_IPV6 &&\r\nipv6_addr_equal(&addr->ip6addr, iaddr)) ||\r\n(!is_v6 && addr->atype == IPVL_IPV4 &&\r\naddr->ip4addr.s_addr == ((struct in_addr *)iaddr)->s_addr))\r\nreturn addr;\r\n}\r\nreturn NULL;\r\n}\r\nbool ipvlan_addr_busy(struct ipvl_port *port, void *iaddr, bool is_v6)\r\n{\r\nstruct ipvl_dev *ipvlan;\r\nASSERT_RTNL();\r\nlist_for_each_entry(ipvlan, &port->ipvlans, pnode) {\r\nif (ipvlan_find_addr(ipvlan, iaddr, is_v6))\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic void *ipvlan_get_L3_hdr(struct sk_buff *skb, int *type)\r\n{\r\nvoid *lyr3h = NULL;\r\nswitch (skb->protocol) {\r\ncase htons(ETH_P_ARP): {\r\nstruct arphdr *arph;\r\nif (unlikely(!pskb_may_pull(skb, sizeof(*arph))))\r\nreturn NULL;\r\narph = arp_hdr(skb);\r\n*type = IPVL_ARP;\r\nlyr3h = arph;\r\nbreak;\r\n}\r\ncase htons(ETH_P_IP): {\r\nu32 pktlen;\r\nstruct iphdr *ip4h;\r\nif (unlikely(!pskb_may_pull(skb, sizeof(*ip4h))))\r\nreturn NULL;\r\nip4h = ip_hdr(skb);\r\npktlen = ntohs(ip4h->tot_len);\r\nif (ip4h->ihl < 5 || ip4h->version != 4)\r\nreturn NULL;\r\nif (skb->len < pktlen || pktlen < (ip4h->ihl * 4))\r\nreturn NULL;\r\n*type = IPVL_IPV4;\r\nlyr3h = ip4h;\r\nbreak;\r\n}\r\ncase htons(ETH_P_IPV6): {\r\nstruct ipv6hdr *ip6h;\r\nif (unlikely(!pskb_may_pull(skb, sizeof(*ip6h))))\r\nreturn NULL;\r\nip6h = ipv6_hdr(skb);\r\nif (ip6h->version != 6)\r\nreturn NULL;\r\n*type = IPVL_IPV6;\r\nlyr3h = ip6h;\r\nif (ipv6_addr_any(&ip6h->saddr) &&\r\nip6h->nexthdr == NEXTHDR_ICMP) {\r\n*type = IPVL_ICMPV6;\r\nlyr3h = ip6h + 1;\r\n}\r\nbreak;\r\n}\r\ndefault:\r\nreturn NULL;\r\n}\r\nreturn lyr3h;\r\n}\r\nunsigned int ipvlan_mac_hash(const unsigned char *addr)\r\n{\r\nu32 hash = jhash_1word(__get_unaligned_cpu32(addr+2),\r\nipvlan_jhash_secret);\r\nreturn hash & IPVLAN_MAC_FILTER_MASK;\r\n}\r\nvoid ipvlan_process_multicast(struct work_struct *work)\r\n{\r\nstruct ipvl_port *port = container_of(work, struct ipvl_port, wq);\r\nstruct ethhdr *ethh;\r\nstruct ipvl_dev *ipvlan;\r\nstruct sk_buff *skb, *nskb;\r\nstruct sk_buff_head list;\r\nunsigned int len;\r\nunsigned int mac_hash;\r\nint ret;\r\nu8 pkt_type;\r\nbool hlocal, dlocal;\r\n__skb_queue_head_init(&list);\r\nspin_lock_bh(&port->backlog.lock);\r\nskb_queue_splice_tail_init(&port->backlog, &list);\r\nspin_unlock_bh(&port->backlog.lock);\r\nwhile ((skb = __skb_dequeue(&list)) != NULL) {\r\nethh = eth_hdr(skb);\r\nhlocal = ether_addr_equal(ethh->h_source, port->dev->dev_addr);\r\nmac_hash = ipvlan_mac_hash(ethh->h_dest);\r\nif (ether_addr_equal(ethh->h_dest, port->dev->broadcast))\r\npkt_type = PACKET_BROADCAST;\r\nelse\r\npkt_type = PACKET_MULTICAST;\r\ndlocal = false;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(ipvlan, &port->ipvlans, pnode) {\r\nif (hlocal && (ipvlan->dev == skb->dev)) {\r\ndlocal = true;\r\ncontinue;\r\n}\r\nif (!test_bit(mac_hash, ipvlan->mac_filters))\r\ncontinue;\r\nret = NET_RX_DROP;\r\nlen = skb->len + ETH_HLEN;\r\nnskb = skb_clone(skb, GFP_ATOMIC);\r\nif (!nskb)\r\ngoto acct;\r\nnskb->pkt_type = pkt_type;\r\nnskb->dev = ipvlan->dev;\r\nif (hlocal)\r\nret = dev_forward_skb(ipvlan->dev, nskb);\r\nelse\r\nret = netif_rx(nskb);\r\nacct:\r\nipvlan_count_rx(ipvlan, len, ret == NET_RX_SUCCESS, true);\r\n}\r\nrcu_read_unlock();\r\nif (dlocal) {\r\nskb->dev = port->dev;\r\nskb->pkt_type = pkt_type;\r\ndev_queue_xmit(skb);\r\n} else {\r\nkfree_skb(skb);\r\n}\r\n}\r\n}\r\nstatic int ipvlan_rcv_frame(struct ipvl_addr *addr, struct sk_buff **pskb,\r\nbool local)\r\n{\r\nstruct ipvl_dev *ipvlan = addr->master;\r\nstruct net_device *dev = ipvlan->dev;\r\nunsigned int len;\r\nrx_handler_result_t ret = RX_HANDLER_CONSUMED;\r\nbool success = false;\r\nstruct sk_buff *skb = *pskb;\r\nlen = skb->len + ETH_HLEN;\r\nif (unlikely(!(dev->flags & IFF_UP))) {\r\nkfree_skb(skb);\r\ngoto out;\r\n}\r\nskb = skb_share_check(skb, GFP_ATOMIC);\r\nif (!skb)\r\ngoto out;\r\n*pskb = skb;\r\nskb->dev = dev;\r\nskb->pkt_type = PACKET_HOST;\r\nif (local) {\r\nif (dev_forward_skb(ipvlan->dev, skb) == NET_RX_SUCCESS)\r\nsuccess = true;\r\n} else {\r\nret = RX_HANDLER_ANOTHER;\r\nsuccess = true;\r\n}\r\nout:\r\nipvlan_count_rx(ipvlan, len, success, false);\r\nreturn ret;\r\n}\r\nstatic struct ipvl_addr *ipvlan_addr_lookup(struct ipvl_port *port,\r\nvoid *lyr3h, int addr_type,\r\nbool use_dest)\r\n{\r\nstruct ipvl_addr *addr = NULL;\r\nif (addr_type == IPVL_IPV6) {\r\nstruct ipv6hdr *ip6h;\r\nstruct in6_addr *i6addr;\r\nip6h = (struct ipv6hdr *)lyr3h;\r\ni6addr = use_dest ? &ip6h->daddr : &ip6h->saddr;\r\naddr = ipvlan_ht_addr_lookup(port, i6addr, true);\r\n} else if (addr_type == IPVL_ICMPV6) {\r\nstruct nd_msg *ndmh;\r\nstruct in6_addr *i6addr;\r\nndmh = (struct nd_msg *)lyr3h;\r\nif (ndmh->icmph.icmp6_type == NDISC_NEIGHBOUR_SOLICITATION) {\r\ni6addr = &ndmh->target;\r\naddr = ipvlan_ht_addr_lookup(port, i6addr, true);\r\n}\r\n} else if (addr_type == IPVL_IPV4) {\r\nstruct iphdr *ip4h;\r\n__be32 *i4addr;\r\nip4h = (struct iphdr *)lyr3h;\r\ni4addr = use_dest ? &ip4h->daddr : &ip4h->saddr;\r\naddr = ipvlan_ht_addr_lookup(port, i4addr, false);\r\n} else if (addr_type == IPVL_ARP) {\r\nstruct arphdr *arph;\r\nunsigned char *arp_ptr;\r\n__be32 dip;\r\narph = (struct arphdr *)lyr3h;\r\narp_ptr = (unsigned char *)(arph + 1);\r\nif (use_dest)\r\narp_ptr += (2 * port->dev->addr_len) + 4;\r\nelse\r\narp_ptr += port->dev->addr_len;\r\nmemcpy(&dip, arp_ptr, 4);\r\naddr = ipvlan_ht_addr_lookup(port, &dip, false);\r\n}\r\nreturn addr;\r\n}\r\nstatic int ipvlan_process_v4_outbound(struct sk_buff *skb)\r\n{\r\nconst struct iphdr *ip4h = ip_hdr(skb);\r\nstruct net_device *dev = skb->dev;\r\nstruct net *net = dev_net(dev);\r\nstruct rtable *rt;\r\nint err, ret = NET_XMIT_DROP;\r\nstruct flowi4 fl4 = {\r\n.flowi4_oif = dev->ifindex,\r\n.flowi4_tos = RT_TOS(ip4h->tos),\r\n.flowi4_flags = FLOWI_FLAG_ANYSRC,\r\n.daddr = ip4h->daddr,\r\n.saddr = ip4h->saddr,\r\n};\r\nrt = ip_route_output_flow(net, &fl4, NULL);\r\nif (IS_ERR(rt))\r\ngoto err;\r\nif (rt->rt_type != RTN_UNICAST && rt->rt_type != RTN_LOCAL) {\r\nip_rt_put(rt);\r\ngoto err;\r\n}\r\nskb_dst_drop(skb);\r\nskb_dst_set(skb, &rt->dst);\r\nerr = ip_local_out(net, skb->sk, skb);\r\nif (unlikely(net_xmit_eval(err)))\r\ndev->stats.tx_errors++;\r\nelse\r\nret = NET_XMIT_SUCCESS;\r\ngoto out;\r\nerr:\r\ndev->stats.tx_errors++;\r\nkfree_skb(skb);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int ipvlan_process_v6_outbound(struct sk_buff *skb)\r\n{\r\nconst struct ipv6hdr *ip6h = ipv6_hdr(skb);\r\nstruct net_device *dev = skb->dev;\r\nstruct net *net = dev_net(dev);\r\nstruct dst_entry *dst;\r\nint err, ret = NET_XMIT_DROP;\r\nstruct flowi6 fl6 = {\r\n.flowi6_iif = dev->ifindex,\r\n.daddr = ip6h->daddr,\r\n.saddr = ip6h->saddr,\r\n.flowi6_flags = FLOWI_FLAG_ANYSRC,\r\n.flowlabel = ip6_flowinfo(ip6h),\r\n.flowi6_mark = skb->mark,\r\n.flowi6_proto = ip6h->nexthdr,\r\n};\r\ndst = ip6_route_output(net, NULL, &fl6);\r\nif (dst->error) {\r\nret = dst->error;\r\ndst_release(dst);\r\ngoto err;\r\n}\r\nskb_dst_drop(skb);\r\nskb_dst_set(skb, dst);\r\nerr = ip6_local_out(net, skb->sk, skb);\r\nif (unlikely(net_xmit_eval(err)))\r\ndev->stats.tx_errors++;\r\nelse\r\nret = NET_XMIT_SUCCESS;\r\ngoto out;\r\nerr:\r\ndev->stats.tx_errors++;\r\nkfree_skb(skb);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int ipvlan_process_outbound(struct sk_buff *skb,\r\nconst struct ipvl_dev *ipvlan)\r\n{\r\nstruct ethhdr *ethh = eth_hdr(skb);\r\nint ret = NET_XMIT_DROP;\r\nif (is_multicast_ether_addr(ethh->h_dest)) {\r\npr_warn_ratelimited("Dropped {multi|broad}cast of type= [%x]\n",\r\nntohs(skb->protocol));\r\nkfree_skb(skb);\r\ngoto out;\r\n}\r\nif (skb_mac_header_was_set(skb)) {\r\nskb_pull(skb, sizeof(*ethh));\r\nskb->mac_header = (typeof(skb->mac_header))~0U;\r\nskb_reset_network_header(skb);\r\n}\r\nif (skb->protocol == htons(ETH_P_IPV6))\r\nret = ipvlan_process_v6_outbound(skb);\r\nelse if (skb->protocol == htons(ETH_P_IP))\r\nret = ipvlan_process_v4_outbound(skb);\r\nelse {\r\npr_warn_ratelimited("Dropped outbound packet type=%x\n",\r\nntohs(skb->protocol));\r\nkfree_skb(skb);\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic void ipvlan_multicast_enqueue(struct ipvl_port *port,\r\nstruct sk_buff *skb)\r\n{\r\nif (skb->protocol == htons(ETH_P_PAUSE)) {\r\nkfree_skb(skb);\r\nreturn;\r\n}\r\nspin_lock(&port->backlog.lock);\r\nif (skb_queue_len(&port->backlog) < IPVLAN_QBACKLOG_LIMIT) {\r\n__skb_queue_tail(&port->backlog, skb);\r\nspin_unlock(&port->backlog.lock);\r\nschedule_work(&port->wq);\r\n} else {\r\nspin_unlock(&port->backlog.lock);\r\natomic_long_inc(&skb->dev->rx_dropped);\r\nkfree_skb(skb);\r\n}\r\n}\r\nstatic int ipvlan_xmit_mode_l3(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nconst struct ipvl_dev *ipvlan = netdev_priv(dev);\r\nvoid *lyr3h;\r\nstruct ipvl_addr *addr;\r\nint addr_type;\r\nlyr3h = ipvlan_get_L3_hdr(skb, &addr_type);\r\nif (!lyr3h)\r\ngoto out;\r\naddr = ipvlan_addr_lookup(ipvlan->port, lyr3h, addr_type, true);\r\nif (addr)\r\nreturn ipvlan_rcv_frame(addr, &skb, true);\r\nout:\r\nskb->dev = ipvlan->phy_dev;\r\nreturn ipvlan_process_outbound(skb, ipvlan);\r\n}\r\nstatic int ipvlan_xmit_mode_l2(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nconst struct ipvl_dev *ipvlan = netdev_priv(dev);\r\nstruct ethhdr *eth = eth_hdr(skb);\r\nstruct ipvl_addr *addr;\r\nvoid *lyr3h;\r\nint addr_type;\r\nif (ether_addr_equal(eth->h_dest, eth->h_source)) {\r\nlyr3h = ipvlan_get_L3_hdr(skb, &addr_type);\r\nif (lyr3h) {\r\naddr = ipvlan_addr_lookup(ipvlan->port, lyr3h, addr_type, true);\r\nif (addr)\r\nreturn ipvlan_rcv_frame(addr, &skb, true);\r\n}\r\nskb = skb_share_check(skb, GFP_ATOMIC);\r\nif (!skb)\r\nreturn NET_XMIT_DROP;\r\nreturn dev_forward_skb(ipvlan->phy_dev, skb);\r\n} else if (is_multicast_ether_addr(eth->h_dest)) {\r\nipvlan_multicast_enqueue(ipvlan->port, skb);\r\nreturn NET_XMIT_SUCCESS;\r\n}\r\nskb->dev = ipvlan->phy_dev;\r\nreturn dev_queue_xmit(skb);\r\n}\r\nint ipvlan_queue_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct ipvl_dev *ipvlan = netdev_priv(dev);\r\nstruct ipvl_port *port = ipvlan_port_get_rcu_bh(ipvlan->phy_dev);\r\nif (!port)\r\ngoto out;\r\nif (unlikely(!pskb_may_pull(skb, sizeof(struct ethhdr))))\r\ngoto out;\r\nswitch(port->mode) {\r\ncase IPVLAN_MODE_L2:\r\nreturn ipvlan_xmit_mode_l2(skb, dev);\r\ncase IPVLAN_MODE_L3:\r\nreturn ipvlan_xmit_mode_l3(skb, dev);\r\n}\r\nWARN_ONCE(true, "ipvlan_queue_xmit() called for mode = [%hx]\n",\r\nport->mode);\r\nout:\r\nkfree_skb(skb);\r\nreturn NET_XMIT_DROP;\r\n}\r\nstatic bool ipvlan_external_frame(struct sk_buff *skb, struct ipvl_port *port)\r\n{\r\nstruct ethhdr *eth = eth_hdr(skb);\r\nstruct ipvl_addr *addr;\r\nvoid *lyr3h;\r\nint addr_type;\r\nif (ether_addr_equal(eth->h_source, skb->dev->dev_addr)) {\r\nlyr3h = ipvlan_get_L3_hdr(skb, &addr_type);\r\nif (!lyr3h)\r\nreturn true;\r\naddr = ipvlan_addr_lookup(port, lyr3h, addr_type, false);\r\nif (addr)\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic rx_handler_result_t ipvlan_handle_mode_l3(struct sk_buff **pskb,\r\nstruct ipvl_port *port)\r\n{\r\nvoid *lyr3h;\r\nint addr_type;\r\nstruct ipvl_addr *addr;\r\nstruct sk_buff *skb = *pskb;\r\nrx_handler_result_t ret = RX_HANDLER_PASS;\r\nlyr3h = ipvlan_get_L3_hdr(skb, &addr_type);\r\nif (!lyr3h)\r\ngoto out;\r\naddr = ipvlan_addr_lookup(port, lyr3h, addr_type, true);\r\nif (addr)\r\nret = ipvlan_rcv_frame(addr, pskb, false);\r\nout:\r\nreturn ret;\r\n}\r\nstatic rx_handler_result_t ipvlan_handle_mode_l2(struct sk_buff **pskb,\r\nstruct ipvl_port *port)\r\n{\r\nstruct sk_buff *skb = *pskb;\r\nstruct ethhdr *eth = eth_hdr(skb);\r\nrx_handler_result_t ret = RX_HANDLER_PASS;\r\nvoid *lyr3h;\r\nint addr_type;\r\nif (is_multicast_ether_addr(eth->h_dest)) {\r\nif (ipvlan_external_frame(skb, port)) {\r\nstruct sk_buff *nskb = skb_clone(skb, GFP_ATOMIC);\r\nif (nskb)\r\nipvlan_multicast_enqueue(port, nskb);\r\n}\r\n} else {\r\nstruct ipvl_addr *addr;\r\nlyr3h = ipvlan_get_L3_hdr(skb, &addr_type);\r\nif (!lyr3h)\r\nreturn ret;\r\naddr = ipvlan_addr_lookup(port, lyr3h, addr_type, true);\r\nif (addr)\r\nret = ipvlan_rcv_frame(addr, pskb, false);\r\n}\r\nreturn ret;\r\n}\r\nrx_handler_result_t ipvlan_handle_frame(struct sk_buff **pskb)\r\n{\r\nstruct sk_buff *skb = *pskb;\r\nstruct ipvl_port *port = ipvlan_port_get_rcu(skb->dev);\r\nif (!port)\r\nreturn RX_HANDLER_PASS;\r\nswitch (port->mode) {\r\ncase IPVLAN_MODE_L2:\r\nreturn ipvlan_handle_mode_l2(pskb, port);\r\ncase IPVLAN_MODE_L3:\r\nreturn ipvlan_handle_mode_l3(pskb, port);\r\n}\r\nWARN_ONCE(true, "ipvlan_handle_frame() called for mode = [%hx]\n",\r\nport->mode);\r\nkfree_skb(skb);\r\nreturn RX_HANDLER_CONSUMED;\r\n}
