bool mv_cesa_req_dma_iter_next_transfer(struct mv_cesa_dma_iter *iter,\r\nstruct mv_cesa_sg_dma_iter *sgiter,\r\nunsigned int len)\r\n{\r\nif (!sgiter->sg)\r\nreturn false;\r\nsgiter->op_offset += len;\r\nsgiter->offset += len;\r\nif (sgiter->offset == sg_dma_len(sgiter->sg)) {\r\nif (sg_is_last(sgiter->sg))\r\nreturn false;\r\nsgiter->offset = 0;\r\nsgiter->sg = sg_next(sgiter->sg);\r\n}\r\nif (sgiter->op_offset == iter->op_len)\r\nreturn false;\r\nreturn true;\r\n}\r\nvoid mv_cesa_dma_step(struct mv_cesa_tdma_req *dreq)\r\n{\r\nstruct mv_cesa_engine *engine = dreq->base.engine;\r\nwritel_relaxed(0, engine->regs + CESA_SA_CFG);\r\nmv_cesa_set_int_mask(engine, CESA_SA_INT_ACC0_IDMA_DONE);\r\nwritel_relaxed(CESA_TDMA_DST_BURST_128B | CESA_TDMA_SRC_BURST_128B |\r\nCESA_TDMA_NO_BYTE_SWAP | CESA_TDMA_EN,\r\nengine->regs + CESA_TDMA_CONTROL);\r\nwritel_relaxed(CESA_SA_CFG_ACT_CH0_IDMA | CESA_SA_CFG_MULTI_PKT |\r\nCESA_SA_CFG_CH0_W_IDMA | CESA_SA_CFG_PARA_DIS,\r\nengine->regs + CESA_SA_CFG);\r\nwritel_relaxed(dreq->chain.first->cur_dma,\r\nengine->regs + CESA_TDMA_NEXT_ADDR);\r\nwritel(CESA_SA_CMD_EN_CESA_SA_ACCL0, engine->regs + CESA_SA_CMD);\r\n}\r\nvoid mv_cesa_dma_cleanup(struct mv_cesa_tdma_req *dreq)\r\n{\r\nstruct mv_cesa_tdma_desc *tdma;\r\nfor (tdma = dreq->chain.first; tdma;) {\r\nstruct mv_cesa_tdma_desc *old_tdma = tdma;\r\nif (tdma->flags & CESA_TDMA_OP)\r\ndma_pool_free(cesa_dev->dma->op_pool, tdma->op,\r\nle32_to_cpu(tdma->src));\r\ntdma = tdma->next;\r\ndma_pool_free(cesa_dev->dma->tdma_desc_pool, old_tdma,\r\nold_tdma->cur_dma);\r\n}\r\ndreq->chain.first = NULL;\r\ndreq->chain.last = NULL;\r\n}\r\nvoid mv_cesa_dma_prepare(struct mv_cesa_tdma_req *dreq,\r\nstruct mv_cesa_engine *engine)\r\n{\r\nstruct mv_cesa_tdma_desc *tdma;\r\nfor (tdma = dreq->chain.first; tdma; tdma = tdma->next) {\r\nif (tdma->flags & CESA_TDMA_DST_IN_SRAM)\r\ntdma->dst = cpu_to_le32(tdma->dst + engine->sram_dma);\r\nif (tdma->flags & CESA_TDMA_SRC_IN_SRAM)\r\ntdma->src = cpu_to_le32(tdma->src + engine->sram_dma);\r\nif (tdma->flags & CESA_TDMA_OP)\r\nmv_cesa_adjust_op(engine, tdma->op);\r\n}\r\n}\r\nstatic struct mv_cesa_tdma_desc *\r\nmv_cesa_dma_add_desc(struct mv_cesa_tdma_chain *chain, gfp_t flags)\r\n{\r\nstruct mv_cesa_tdma_desc *new_tdma = NULL;\r\ndma_addr_t dma_handle;\r\nnew_tdma = dma_pool_alloc(cesa_dev->dma->tdma_desc_pool, flags,\r\n&dma_handle);\r\nif (!new_tdma)\r\nreturn ERR_PTR(-ENOMEM);\r\nmemset(new_tdma, 0, sizeof(*new_tdma));\r\nnew_tdma->cur_dma = dma_handle;\r\nif (chain->last) {\r\nchain->last->next_dma = cpu_to_le32(dma_handle);\r\nchain->last->next = new_tdma;\r\n} else {\r\nchain->first = new_tdma;\r\n}\r\nchain->last = new_tdma;\r\nreturn new_tdma;\r\n}\r\nstruct mv_cesa_op_ctx *mv_cesa_dma_add_op(struct mv_cesa_tdma_chain *chain,\r\nconst struct mv_cesa_op_ctx *op_templ,\r\nbool skip_ctx,\r\ngfp_t flags)\r\n{\r\nstruct mv_cesa_tdma_desc *tdma;\r\nstruct mv_cesa_op_ctx *op;\r\ndma_addr_t dma_handle;\r\nunsigned int size;\r\ntdma = mv_cesa_dma_add_desc(chain, flags);\r\nif (IS_ERR(tdma))\r\nreturn ERR_CAST(tdma);\r\nop = dma_pool_alloc(cesa_dev->dma->op_pool, flags, &dma_handle);\r\nif (!op)\r\nreturn ERR_PTR(-ENOMEM);\r\n*op = *op_templ;\r\nsize = skip_ctx ? sizeof(op->desc) : sizeof(*op);\r\ntdma = chain->last;\r\ntdma->op = op;\r\ntdma->byte_cnt = cpu_to_le32(size | BIT(31));\r\ntdma->src = cpu_to_le32(dma_handle);\r\ntdma->flags = CESA_TDMA_DST_IN_SRAM | CESA_TDMA_OP;\r\nreturn op;\r\n}\r\nint mv_cesa_dma_add_data_transfer(struct mv_cesa_tdma_chain *chain,\r\ndma_addr_t dst, dma_addr_t src, u32 size,\r\nu32 flags, gfp_t gfp_flags)\r\n{\r\nstruct mv_cesa_tdma_desc *tdma;\r\ntdma = mv_cesa_dma_add_desc(chain, gfp_flags);\r\nif (IS_ERR(tdma))\r\nreturn PTR_ERR(tdma);\r\ntdma->byte_cnt = cpu_to_le32(size | BIT(31));\r\ntdma->src = src;\r\ntdma->dst = dst;\r\nflags &= (CESA_TDMA_DST_IN_SRAM | CESA_TDMA_SRC_IN_SRAM);\r\ntdma->flags = flags | CESA_TDMA_DATA;\r\nreturn 0;\r\n}\r\nint mv_cesa_dma_add_dummy_launch(struct mv_cesa_tdma_chain *chain, gfp_t flags)\r\n{\r\nstruct mv_cesa_tdma_desc *tdma;\r\ntdma = mv_cesa_dma_add_desc(chain, flags);\r\nif (IS_ERR(tdma))\r\nreturn PTR_ERR(tdma);\r\nreturn 0;\r\n}\r\nint mv_cesa_dma_add_dummy_end(struct mv_cesa_tdma_chain *chain, gfp_t flags)\r\n{\r\nstruct mv_cesa_tdma_desc *tdma;\r\ntdma = mv_cesa_dma_add_desc(chain, flags);\r\nif (IS_ERR(tdma))\r\nreturn PTR_ERR(tdma);\r\ntdma->byte_cnt = cpu_to_le32(BIT(31));\r\nreturn 0;\r\n}\r\nint mv_cesa_dma_add_op_transfers(struct mv_cesa_tdma_chain *chain,\r\nstruct mv_cesa_dma_iter *dma_iter,\r\nstruct mv_cesa_sg_dma_iter *sgiter,\r\ngfp_t gfp_flags)\r\n{\r\nu32 flags = sgiter->dir == DMA_TO_DEVICE ?\r\nCESA_TDMA_DST_IN_SRAM : CESA_TDMA_SRC_IN_SRAM;\r\nunsigned int len;\r\ndo {\r\ndma_addr_t dst, src;\r\nint ret;\r\nlen = mv_cesa_req_dma_iter_transfer_len(dma_iter, sgiter);\r\nif (sgiter->dir == DMA_TO_DEVICE) {\r\ndst = CESA_SA_DATA_SRAM_OFFSET + sgiter->op_offset;\r\nsrc = sg_dma_address(sgiter->sg) + sgiter->offset;\r\n} else {\r\ndst = sg_dma_address(sgiter->sg) + sgiter->offset;\r\nsrc = CESA_SA_DATA_SRAM_OFFSET + sgiter->op_offset;\r\n}\r\nret = mv_cesa_dma_add_data_transfer(chain, dst, src, len,\r\nflags, gfp_flags);\r\nif (ret)\r\nreturn ret;\r\n} while (mv_cesa_req_dma_iter_next_transfer(dma_iter, sgiter, len));\r\nreturn 0;\r\n}
