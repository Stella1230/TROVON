static void vfp_double_dump(const char *str, struct vfp_double *d)\r\n{\r\npr_debug("VFP: %s: sign=%d exponent=%d significand=%016llx\n",\r\nstr, d->sign != 0, d->exponent, d->significand);\r\n}\r\nstatic void vfp_double_normalise_denormal(struct vfp_double *vd)\r\n{\r\nint bits = 31 - fls(vd->significand >> 32);\r\nif (bits == 31)\r\nbits = 63 - fls(vd->significand);\r\nvfp_double_dump("normalise_denormal: in", vd);\r\nif (bits) {\r\nvd->exponent -= bits - 1;\r\nvd->significand <<= bits;\r\n}\r\nvfp_double_dump("normalise_denormal: out", vd);\r\n}\r\nu32 vfp_double_normaliseround(int dd, struct vfp_double *vd, u32 fpscr, u32 exceptions, const char *func)\r\n{\r\nu64 significand, incr;\r\nint exponent, shift, underflow;\r\nu32 rmode;\r\nvfp_double_dump("pack: in", vd);\r\nif (vd->exponent == 2047 && (vd->significand == 0 || exceptions))\r\ngoto pack;\r\nif (vd->significand == 0) {\r\nvd->exponent = 0;\r\ngoto pack;\r\n}\r\nexponent = vd->exponent;\r\nsignificand = vd->significand;\r\nshift = 32 - fls(significand >> 32);\r\nif (shift == 32)\r\nshift = 64 - fls(significand);\r\nif (shift) {\r\nexponent -= shift;\r\nsignificand <<= shift;\r\n}\r\n#ifdef DEBUG\r\nvd->exponent = exponent;\r\nvd->significand = significand;\r\nvfp_double_dump("pack: normalised", vd);\r\n#endif\r\nunderflow = exponent < 0;\r\nif (underflow) {\r\nsignificand = vfp_shiftright64jamming(significand, -exponent);\r\nexponent = 0;\r\n#ifdef DEBUG\r\nvd->exponent = exponent;\r\nvd->significand = significand;\r\nvfp_double_dump("pack: tiny number", vd);\r\n#endif\r\nif (!(significand & ((1ULL << (VFP_DOUBLE_LOW_BITS + 1)) - 1)))\r\nunderflow = 0;\r\n}\r\nincr = 0;\r\nrmode = fpscr & FPSCR_RMODE_MASK;\r\nif (rmode == FPSCR_ROUND_NEAREST) {\r\nincr = 1ULL << VFP_DOUBLE_LOW_BITS;\r\nif ((significand & (1ULL << (VFP_DOUBLE_LOW_BITS + 1))) == 0)\r\nincr -= 1;\r\n} else if (rmode == FPSCR_ROUND_TOZERO) {\r\nincr = 0;\r\n} else if ((rmode == FPSCR_ROUND_PLUSINF) ^ (vd->sign != 0))\r\nincr = (1ULL << (VFP_DOUBLE_LOW_BITS + 1)) - 1;\r\npr_debug("VFP: rounding increment = 0x%08llx\n", incr);\r\nif ((significand + incr) < significand) {\r\nexponent += 1;\r\nsignificand = (significand >> 1) | (significand & 1);\r\nincr >>= 1;\r\n#ifdef DEBUG\r\nvd->exponent = exponent;\r\nvd->significand = significand;\r\nvfp_double_dump("pack: overflow", vd);\r\n#endif\r\n}\r\nif (significand & ((1 << (VFP_DOUBLE_LOW_BITS + 1)) - 1))\r\nexceptions |= FPSCR_IXC;\r\nsignificand += incr;\r\nif (exponent >= 2046) {\r\nexceptions |= FPSCR_OFC | FPSCR_IXC;\r\nif (incr == 0) {\r\nvd->exponent = 2045;\r\nvd->significand = 0x7fffffffffffffffULL;\r\n} else {\r\nvd->exponent = 2047;\r\nvd->significand = 0;\r\n}\r\n} else {\r\nif (significand >> (VFP_DOUBLE_LOW_BITS + 1) == 0)\r\nexponent = 0;\r\nif (exponent || significand > 0x8000000000000000ULL)\r\nunderflow = 0;\r\nif (underflow)\r\nexceptions |= FPSCR_UFC;\r\nvd->exponent = exponent;\r\nvd->significand = significand >> 1;\r\n}\r\npack:\r\nvfp_double_dump("pack: final", vd);\r\n{\r\ns64 d = vfp_double_pack(vd);\r\npr_debug("VFP: %s: d(d%d)=%016llx exceptions=%08x\n", func,\r\ndd, d, exceptions);\r\nvfp_put_double(d, dd);\r\n}\r\nreturn exceptions;\r\n}\r\nstatic u32\r\nvfp_propagate_nan(struct vfp_double *vdd, struct vfp_double *vdn,\r\nstruct vfp_double *vdm, u32 fpscr)\r\n{\r\nstruct vfp_double *nan;\r\nint tn, tm = 0;\r\ntn = vfp_double_type(vdn);\r\nif (vdm)\r\ntm = vfp_double_type(vdm);\r\nif (fpscr & FPSCR_DEFAULT_NAN)\r\nnan = &vfp_double_default_qnan;\r\nelse {\r\nif (tn == VFP_SNAN || (tm != VFP_SNAN && tn == VFP_QNAN))\r\nnan = vdn;\r\nelse\r\nnan = vdm;\r\nnan->significand |= VFP_DOUBLE_SIGNIFICAND_QNAN;\r\n}\r\n*vdd = *nan;\r\nreturn tn == VFP_SNAN || tm == VFP_SNAN ? FPSCR_IOC : VFP_NAN_FLAG;\r\n}\r\nstatic u32 vfp_double_fabs(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nvfp_put_double(vfp_double_packed_abs(vfp_get_double(dm)), dd);\r\nreturn 0;\r\n}\r\nstatic u32 vfp_double_fcpy(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nvfp_put_double(vfp_get_double(dm), dd);\r\nreturn 0;\r\n}\r\nstatic u32 vfp_double_fneg(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nvfp_put_double(vfp_double_packed_negate(vfp_get_double(dm)), dd);\r\nreturn 0;\r\n}\r\nstatic u32 vfp_double_fsqrt(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdm, vdd;\r\nint ret, tm;\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\ntm = vfp_double_type(&vdm);\r\nif (tm & (VFP_NAN|VFP_INFINITY)) {\r\nstruct vfp_double *vdp = &vdd;\r\nif (tm & VFP_NAN)\r\nret = vfp_propagate_nan(vdp, &vdm, NULL, fpscr);\r\nelse if (vdm.sign == 0) {\r\nsqrt_copy:\r\nvdp = &vdm;\r\nret = 0;\r\n} else {\r\nsqrt_invalid:\r\nvdp = &vfp_double_default_qnan;\r\nret = FPSCR_IOC;\r\n}\r\nvfp_put_double(vfp_double_pack(vdp), dd);\r\nreturn ret;\r\n}\r\nif (tm & VFP_ZERO)\r\ngoto sqrt_copy;\r\nif (tm & VFP_DENORMAL)\r\nvfp_double_normalise_denormal(&vdm);\r\nif (vdm.sign)\r\ngoto sqrt_invalid;\r\nvfp_double_dump("sqrt", &vdm);\r\nvdd.sign = 0;\r\nvdd.exponent = ((vdm.exponent - 1023) >> 1) + 1023;\r\nvdd.significand = (u64)vfp_estimate_sqrt_significand(vdm.exponent, vdm.significand >> 32) << 31;\r\nvfp_double_dump("sqrt estimate1", &vdd);\r\nvdm.significand >>= 1 + (vdm.exponent & 1);\r\nvdd.significand += 2 + vfp_estimate_div128to64(vdm.significand, 0, vdd.significand);\r\nvfp_double_dump("sqrt estimate2", &vdd);\r\nif ((vdd.significand & VFP_DOUBLE_LOW_BITS_MASK) <= 5) {\r\nif (vdd.significand < 2) {\r\nvdd.significand = ~0ULL;\r\n} else {\r\nu64 termh, terml, remh, reml;\r\nvdm.significand <<= 2;\r\nmul64to128(&termh, &terml, vdd.significand, vdd.significand);\r\nsub128(&remh, &reml, vdm.significand, 0, termh, terml);\r\nwhile ((s64)remh < 0) {\r\nvdd.significand -= 1;\r\nshift64left(&termh, &terml, vdd.significand);\r\nterml |= 1;\r\nadd128(&remh, &reml, remh, reml, termh, terml);\r\n}\r\nvdd.significand |= (remh | reml) != 0;\r\n}\r\n}\r\nvdd.significand = vfp_shiftright64jamming(vdd.significand, 1);\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, 0, "fsqrt");\r\n}\r\nstatic u32 vfp_compare(int dd, int signal_on_qnan, int dm, u32 fpscr)\r\n{\r\ns64 d, m;\r\nu32 ret = 0;\r\nm = vfp_get_double(dm);\r\nif (vfp_double_packed_exponent(m) == 2047 && vfp_double_packed_mantissa(m)) {\r\nret |= FPSCR_C | FPSCR_V;\r\nif (signal_on_qnan || !(vfp_double_packed_mantissa(m) & (1ULL << (VFP_DOUBLE_MANTISSA_BITS - 1))))\r\nret |= FPSCR_IOC;\r\n}\r\nd = vfp_get_double(dd);\r\nif (vfp_double_packed_exponent(d) == 2047 && vfp_double_packed_mantissa(d)) {\r\nret |= FPSCR_C | FPSCR_V;\r\nif (signal_on_qnan || !(vfp_double_packed_mantissa(d) & (1ULL << (VFP_DOUBLE_MANTISSA_BITS - 1))))\r\nret |= FPSCR_IOC;\r\n}\r\nif (ret == 0) {\r\nif (d == m || vfp_double_packed_abs(d | m) == 0) {\r\nret |= FPSCR_Z | FPSCR_C;\r\n} else if (vfp_double_packed_sign(d ^ m)) {\r\nif (vfp_double_packed_sign(d))\r\nret |= FPSCR_N;\r\nelse\r\nret |= FPSCR_C;\r\n} else if ((vfp_double_packed_sign(d) != 0) ^ (d < m)) {\r\nret |= FPSCR_N;\r\n} else if ((vfp_double_packed_sign(d) != 0) ^ (d > m)) {\r\nret |= FPSCR_C;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic u32 vfp_double_fcmp(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nreturn vfp_compare(dd, 0, dm, fpscr);\r\n}\r\nstatic u32 vfp_double_fcmpe(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nreturn vfp_compare(dd, 1, dm, fpscr);\r\n}\r\nstatic u32 vfp_double_fcmpz(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nreturn vfp_compare(dd, 0, VFP_REG_ZERO, fpscr);\r\n}\r\nstatic u32 vfp_double_fcmpez(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nreturn vfp_compare(dd, 1, VFP_REG_ZERO, fpscr);\r\n}\r\nstatic u32 vfp_double_fcvts(int sd, int unused, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdm;\r\nstruct vfp_single vsd;\r\nint tm;\r\nu32 exceptions = 0;\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\ntm = vfp_double_type(&vdm);\r\nif (tm == VFP_SNAN)\r\nexceptions = FPSCR_IOC;\r\nif (tm & VFP_DENORMAL)\r\nvfp_double_normalise_denormal(&vdm);\r\nvsd.sign = vdm.sign;\r\nvsd.significand = vfp_hi64to32jamming(vdm.significand);\r\nif (tm & (VFP_INFINITY|VFP_NAN)) {\r\nvsd.exponent = 255;\r\nif (tm == VFP_QNAN)\r\nvsd.significand |= VFP_SINGLE_SIGNIFICAND_QNAN;\r\ngoto pack_nan;\r\n} else if (tm & VFP_ZERO)\r\nvsd.exponent = 0;\r\nelse\r\nvsd.exponent = vdm.exponent - (1023 - 127);\r\nreturn vfp_single_normaliseround(sd, &vsd, fpscr, exceptions, "fcvts");\r\npack_nan:\r\nvfp_put_float(vfp_single_pack(&vsd), sd);\r\nreturn exceptions;\r\n}\r\nstatic u32 vfp_double_fuito(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdm;\r\nu32 m = vfp_get_float(dm);\r\nvdm.sign = 0;\r\nvdm.exponent = 1023 + 63 - 1;\r\nvdm.significand = (u64)m;\r\nreturn vfp_double_normaliseround(dd, &vdm, fpscr, 0, "fuito");\r\n}\r\nstatic u32 vfp_double_fsito(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdm;\r\nu32 m = vfp_get_float(dm);\r\nvdm.sign = (m & 0x80000000) >> 16;\r\nvdm.exponent = 1023 + 63 - 1;\r\nvdm.significand = vdm.sign ? -m : m;\r\nreturn vfp_double_normaliseround(dd, &vdm, fpscr, 0, "fsito");\r\n}\r\nstatic u32 vfp_double_ftoui(int sd, int unused, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdm;\r\nu32 d, exceptions = 0;\r\nint rmode = fpscr & FPSCR_RMODE_MASK;\r\nint tm;\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\ntm = vfp_double_type(&vdm);\r\nif (tm & VFP_DENORMAL)\r\nexceptions |= FPSCR_IDC;\r\nif (tm & VFP_NAN)\r\nvdm.sign = 0;\r\nif (vdm.exponent >= 1023 + 32) {\r\nd = vdm.sign ? 0 : 0xffffffff;\r\nexceptions = FPSCR_IOC;\r\n} else if (vdm.exponent >= 1023 - 1) {\r\nint shift = 1023 + 63 - vdm.exponent;\r\nu64 rem, incr = 0;\r\nd = (vdm.significand << 1) >> shift;\r\nrem = vdm.significand << (65 - shift);\r\nif (rmode == FPSCR_ROUND_NEAREST) {\r\nincr = 0x8000000000000000ULL;\r\nif ((d & 1) == 0)\r\nincr -= 1;\r\n} else if (rmode == FPSCR_ROUND_TOZERO) {\r\nincr = 0;\r\n} else if ((rmode == FPSCR_ROUND_PLUSINF) ^ (vdm.sign != 0)) {\r\nincr = ~0ULL;\r\n}\r\nif ((rem + incr) < rem) {\r\nif (d < 0xffffffff)\r\nd += 1;\r\nelse\r\nexceptions |= FPSCR_IOC;\r\n}\r\nif (d && vdm.sign) {\r\nd = 0;\r\nexceptions |= FPSCR_IOC;\r\n} else if (rem)\r\nexceptions |= FPSCR_IXC;\r\n} else {\r\nd = 0;\r\nif (vdm.exponent | vdm.significand) {\r\nexceptions |= FPSCR_IXC;\r\nif (rmode == FPSCR_ROUND_PLUSINF && vdm.sign == 0)\r\nd = 1;\r\nelse if (rmode == FPSCR_ROUND_MINUSINF && vdm.sign) {\r\nd = 0;\r\nexceptions |= FPSCR_IOC;\r\n}\r\n}\r\n}\r\npr_debug("VFP: ftoui: d(s%d)=%08x exceptions=%08x\n", sd, d, exceptions);\r\nvfp_put_float(d, sd);\r\nreturn exceptions;\r\n}\r\nstatic u32 vfp_double_ftouiz(int sd, int unused, int dm, u32 fpscr)\r\n{\r\nreturn vfp_double_ftoui(sd, unused, dm, FPSCR_ROUND_TOZERO);\r\n}\r\nstatic u32 vfp_double_ftosi(int sd, int unused, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdm;\r\nu32 d, exceptions = 0;\r\nint rmode = fpscr & FPSCR_RMODE_MASK;\r\nint tm;\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\nvfp_double_dump("VDM", &vdm);\r\ntm = vfp_double_type(&vdm);\r\nif (tm & VFP_DENORMAL)\r\nexceptions |= FPSCR_IDC;\r\nif (tm & VFP_NAN) {\r\nd = 0;\r\nexceptions |= FPSCR_IOC;\r\n} else if (vdm.exponent >= 1023 + 32) {\r\nd = 0x7fffffff;\r\nif (vdm.sign)\r\nd = ~d;\r\nexceptions |= FPSCR_IOC;\r\n} else if (vdm.exponent >= 1023 - 1) {\r\nint shift = 1023 + 63 - vdm.exponent;\r\nu64 rem, incr = 0;\r\nd = (vdm.significand << 1) >> shift;\r\nrem = vdm.significand << (65 - shift);\r\nif (rmode == FPSCR_ROUND_NEAREST) {\r\nincr = 0x8000000000000000ULL;\r\nif ((d & 1) == 0)\r\nincr -= 1;\r\n} else if (rmode == FPSCR_ROUND_TOZERO) {\r\nincr = 0;\r\n} else if ((rmode == FPSCR_ROUND_PLUSINF) ^ (vdm.sign != 0)) {\r\nincr = ~0ULL;\r\n}\r\nif ((rem + incr) < rem && d < 0xffffffff)\r\nd += 1;\r\nif (d > 0x7fffffff + (vdm.sign != 0)) {\r\nd = 0x7fffffff + (vdm.sign != 0);\r\nexceptions |= FPSCR_IOC;\r\n} else if (rem)\r\nexceptions |= FPSCR_IXC;\r\nif (vdm.sign)\r\nd = -d;\r\n} else {\r\nd = 0;\r\nif (vdm.exponent | vdm.significand) {\r\nexceptions |= FPSCR_IXC;\r\nif (rmode == FPSCR_ROUND_PLUSINF && vdm.sign == 0)\r\nd = 1;\r\nelse if (rmode == FPSCR_ROUND_MINUSINF && vdm.sign)\r\nd = -1;\r\n}\r\n}\r\npr_debug("VFP: ftosi: d(s%d)=%08x exceptions=%08x\n", sd, d, exceptions);\r\nvfp_put_float((s32)d, sd);\r\nreturn exceptions;\r\n}\r\nstatic u32 vfp_double_ftosiz(int dd, int unused, int dm, u32 fpscr)\r\n{\r\nreturn vfp_double_ftosi(dd, unused, dm, FPSCR_ROUND_TOZERO);\r\n}\r\nstatic u32\r\nvfp_double_fadd_nonnumber(struct vfp_double *vdd, struct vfp_double *vdn,\r\nstruct vfp_double *vdm, u32 fpscr)\r\n{\r\nstruct vfp_double *vdp;\r\nu32 exceptions = 0;\r\nint tn, tm;\r\ntn = vfp_double_type(vdn);\r\ntm = vfp_double_type(vdm);\r\nif (tn & tm & VFP_INFINITY) {\r\nif (vdn->sign ^ vdm->sign) {\r\nexceptions = FPSCR_IOC;\r\nvdp = &vfp_double_default_qnan;\r\n} else {\r\nvdp = vdn;\r\n}\r\n} else if (tn & VFP_INFINITY && tm & VFP_NUMBER) {\r\nvdp = vdn;\r\n} else {\r\nreturn vfp_propagate_nan(vdd, vdn, vdm, fpscr);\r\n}\r\n*vdd = *vdp;\r\nreturn exceptions;\r\n}\r\nstatic u32\r\nvfp_double_add(struct vfp_double *vdd, struct vfp_double *vdn,\r\nstruct vfp_double *vdm, u32 fpscr)\r\n{\r\nu32 exp_diff;\r\nu64 m_sig;\r\nif (vdn->significand & (1ULL << 63) ||\r\nvdm->significand & (1ULL << 63)) {\r\npr_info("VFP: bad FP values in %s\n", __func__);\r\nvfp_double_dump("VDN", vdn);\r\nvfp_double_dump("VDM", vdm);\r\n}\r\nif (vdn->exponent < vdm->exponent) {\r\nstruct vfp_double *t = vdn;\r\nvdn = vdm;\r\nvdm = t;\r\n}\r\nif (vdn->exponent == 2047)\r\nreturn vfp_double_fadd_nonnumber(vdd, vdn, vdm, fpscr);\r\n*vdd = *vdn;\r\nexp_diff = vdn->exponent - vdm->exponent;\r\nm_sig = vfp_shiftright64jamming(vdm->significand, exp_diff);\r\nif (vdn->sign ^ vdm->sign) {\r\nm_sig = vdn->significand - m_sig;\r\nif ((s64)m_sig < 0) {\r\nvdd->sign = vfp_sign_negate(vdd->sign);\r\nm_sig = -m_sig;\r\n} else if (m_sig == 0) {\r\nvdd->sign = (fpscr & FPSCR_RMODE_MASK) ==\r\nFPSCR_ROUND_MINUSINF ? 0x8000 : 0;\r\n}\r\n} else {\r\nm_sig += vdn->significand;\r\n}\r\nvdd->significand = m_sig;\r\nreturn 0;\r\n}\r\nstatic u32\r\nvfp_double_multiply(struct vfp_double *vdd, struct vfp_double *vdn,\r\nstruct vfp_double *vdm, u32 fpscr)\r\n{\r\nvfp_double_dump("VDN", vdn);\r\nvfp_double_dump("VDM", vdm);\r\nif (vdn->exponent < vdm->exponent) {\r\nstruct vfp_double *t = vdn;\r\nvdn = vdm;\r\nvdm = t;\r\npr_debug("VFP: swapping M <-> N\n");\r\n}\r\nvdd->sign = vdn->sign ^ vdm->sign;\r\nif (vdn->exponent == 2047) {\r\nif (vdn->significand || (vdm->exponent == 2047 && vdm->significand))\r\nreturn vfp_propagate_nan(vdd, vdn, vdm, fpscr);\r\nif ((vdm->exponent | vdm->significand) == 0) {\r\n*vdd = vfp_double_default_qnan;\r\nreturn FPSCR_IOC;\r\n}\r\nvdd->exponent = vdn->exponent;\r\nvdd->significand = 0;\r\nreturn 0;\r\n}\r\nif ((vdm->exponent | vdm->significand) == 0) {\r\nvdd->exponent = 0;\r\nvdd->significand = 0;\r\nreturn 0;\r\n}\r\nvdd->exponent = vdn->exponent + vdm->exponent - 1023 + 2;\r\nvdd->significand = vfp_hi64multiply64(vdn->significand, vdm->significand);\r\nvfp_double_dump("VDD", vdd);\r\nreturn 0;\r\n}\r\nstatic u32\r\nvfp_double_multiply_accumulate(int dd, int dn, int dm, u32 fpscr, u32 negate, char *func)\r\n{\r\nstruct vfp_double vdd, vdp, vdn, vdm;\r\nu32 exceptions;\r\nvfp_double_unpack(&vdn, vfp_get_double(dn));\r\nif (vdn.exponent == 0 && vdn.significand)\r\nvfp_double_normalise_denormal(&vdn);\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\nif (vdm.exponent == 0 && vdm.significand)\r\nvfp_double_normalise_denormal(&vdm);\r\nexceptions = vfp_double_multiply(&vdp, &vdn, &vdm, fpscr);\r\nif (negate & NEG_MULTIPLY)\r\nvdp.sign = vfp_sign_negate(vdp.sign);\r\nvfp_double_unpack(&vdn, vfp_get_double(dd));\r\nif (vdn.exponent == 0 && vdn.significand)\r\nvfp_double_normalise_denormal(&vdn);\r\nif (negate & NEG_SUBTRACT)\r\nvdn.sign = vfp_sign_negate(vdn.sign);\r\nexceptions |= vfp_double_add(&vdd, &vdn, &vdp, fpscr);\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, exceptions, func);\r\n}\r\nstatic u32 vfp_double_fmac(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nreturn vfp_double_multiply_accumulate(dd, dn, dm, fpscr, 0, "fmac");\r\n}\r\nstatic u32 vfp_double_fnmac(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nreturn vfp_double_multiply_accumulate(dd, dn, dm, fpscr, NEG_MULTIPLY, "fnmac");\r\n}\r\nstatic u32 vfp_double_fmsc(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nreturn vfp_double_multiply_accumulate(dd, dn, dm, fpscr, NEG_SUBTRACT, "fmsc");\r\n}\r\nstatic u32 vfp_double_fnmsc(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nreturn vfp_double_multiply_accumulate(dd, dn, dm, fpscr, NEG_SUBTRACT | NEG_MULTIPLY, "fnmsc");\r\n}\r\nstatic u32 vfp_double_fmul(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdd, vdn, vdm;\r\nu32 exceptions;\r\nvfp_double_unpack(&vdn, vfp_get_double(dn));\r\nif (vdn.exponent == 0 && vdn.significand)\r\nvfp_double_normalise_denormal(&vdn);\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\nif (vdm.exponent == 0 && vdm.significand)\r\nvfp_double_normalise_denormal(&vdm);\r\nexceptions = vfp_double_multiply(&vdd, &vdn, &vdm, fpscr);\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, exceptions, "fmul");\r\n}\r\nstatic u32 vfp_double_fnmul(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdd, vdn, vdm;\r\nu32 exceptions;\r\nvfp_double_unpack(&vdn, vfp_get_double(dn));\r\nif (vdn.exponent == 0 && vdn.significand)\r\nvfp_double_normalise_denormal(&vdn);\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\nif (vdm.exponent == 0 && vdm.significand)\r\nvfp_double_normalise_denormal(&vdm);\r\nexceptions = vfp_double_multiply(&vdd, &vdn, &vdm, fpscr);\r\nvdd.sign = vfp_sign_negate(vdd.sign);\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, exceptions, "fnmul");\r\n}\r\nstatic u32 vfp_double_fadd(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdd, vdn, vdm;\r\nu32 exceptions;\r\nvfp_double_unpack(&vdn, vfp_get_double(dn));\r\nif (vdn.exponent == 0 && vdn.significand)\r\nvfp_double_normalise_denormal(&vdn);\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\nif (vdm.exponent == 0 && vdm.significand)\r\nvfp_double_normalise_denormal(&vdm);\r\nexceptions = vfp_double_add(&vdd, &vdn, &vdm, fpscr);\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, exceptions, "fadd");\r\n}\r\nstatic u32 vfp_double_fsub(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdd, vdn, vdm;\r\nu32 exceptions;\r\nvfp_double_unpack(&vdn, vfp_get_double(dn));\r\nif (vdn.exponent == 0 && vdn.significand)\r\nvfp_double_normalise_denormal(&vdn);\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\nif (vdm.exponent == 0 && vdm.significand)\r\nvfp_double_normalise_denormal(&vdm);\r\nvdm.sign = vfp_sign_negate(vdm.sign);\r\nexceptions = vfp_double_add(&vdd, &vdn, &vdm, fpscr);\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, exceptions, "fsub");\r\n}\r\nstatic u32 vfp_double_fdiv(int dd, int dn, int dm, u32 fpscr)\r\n{\r\nstruct vfp_double vdd, vdn, vdm;\r\nu32 exceptions = 0;\r\nint tm, tn;\r\nvfp_double_unpack(&vdn, vfp_get_double(dn));\r\nvfp_double_unpack(&vdm, vfp_get_double(dm));\r\nvdd.sign = vdn.sign ^ vdm.sign;\r\ntn = vfp_double_type(&vdn);\r\ntm = vfp_double_type(&vdm);\r\nif (tn & VFP_NAN)\r\ngoto vdn_nan;\r\nif (tm & VFP_NAN)\r\ngoto vdm_nan;\r\nif (tm & tn & (VFP_INFINITY|VFP_ZERO))\r\ngoto invalid;\r\nif (tn & VFP_INFINITY)\r\ngoto infinity;\r\nif (tm & VFP_ZERO)\r\ngoto divzero;\r\nif (tm & VFP_INFINITY || tn & VFP_ZERO)\r\ngoto zero;\r\nif (tn & VFP_DENORMAL)\r\nvfp_double_normalise_denormal(&vdn);\r\nif (tm & VFP_DENORMAL)\r\nvfp_double_normalise_denormal(&vdm);\r\nvdd.exponent = vdn.exponent - vdm.exponent + 1023 - 1;\r\nvdm.significand <<= 1;\r\nif (vdm.significand <= (2 * vdn.significand)) {\r\nvdn.significand >>= 1;\r\nvdd.exponent++;\r\n}\r\nvdd.significand = vfp_estimate_div128to64(vdn.significand, 0, vdm.significand);\r\nif ((vdd.significand & 0x1ff) <= 2) {\r\nu64 termh, terml, remh, reml;\r\nmul64to128(&termh, &terml, vdm.significand, vdd.significand);\r\nsub128(&remh, &reml, vdn.significand, 0, termh, terml);\r\nwhile ((s64)remh < 0) {\r\nvdd.significand -= 1;\r\nadd128(&remh, &reml, remh, reml, 0, vdm.significand);\r\n}\r\nvdd.significand |= (reml != 0);\r\n}\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, 0, "fdiv");\r\nvdn_nan:\r\nexceptions = vfp_propagate_nan(&vdd, &vdn, &vdm, fpscr);\r\npack:\r\nvfp_put_double(vfp_double_pack(&vdd), dd);\r\nreturn exceptions;\r\nvdm_nan:\r\nexceptions = vfp_propagate_nan(&vdd, &vdm, &vdn, fpscr);\r\ngoto pack;\r\nzero:\r\nvdd.exponent = 0;\r\nvdd.significand = 0;\r\ngoto pack;\r\ndivzero:\r\nexceptions = FPSCR_DZC;\r\ninfinity:\r\nvdd.exponent = 2047;\r\nvdd.significand = 0;\r\ngoto pack;\r\ninvalid:\r\nvfp_put_double(vfp_double_pack(&vfp_double_default_qnan), dd);\r\nreturn FPSCR_IOC;\r\n}\r\nu32 vfp_double_cpdo(u32 inst, u32 fpscr)\r\n{\r\nu32 op = inst & FOP_MASK;\r\nu32 exceptions = 0;\r\nunsigned int dest;\r\nunsigned int dn = vfp_get_dn(inst);\r\nunsigned int dm;\r\nunsigned int vecitr, veclen, vecstride;\r\nstruct op *fop;\r\nvecstride = (1 + ((fpscr & FPSCR_STRIDE_MASK) == FPSCR_STRIDE_MASK));\r\nfop = (op == FOP_EXT) ? &fops_ext[FEXT_TO_IDX(inst)] : &fops[FOP_TO_IDX(op)];\r\nif (fop->flags & OP_SD)\r\ndest = vfp_get_sd(inst);\r\nelse\r\ndest = vfp_get_dd(inst);\r\nif (fop->flags & OP_SM)\r\ndm = vfp_get_sm(inst);\r\nelse\r\ndm = vfp_get_dm(inst);\r\nif ((fop->flags & OP_SCALAR) || (FREG_BANK(dest) == 0))\r\nveclen = 0;\r\nelse\r\nveclen = fpscr & FPSCR_LENGTH_MASK;\r\npr_debug("VFP: vecstride=%u veclen=%u\n", vecstride,\r\n(veclen >> FPSCR_LENGTH_BIT) + 1);\r\nif (!fop->fn)\r\ngoto invalid;\r\nfor (vecitr = 0; vecitr <= veclen; vecitr += 1 << FPSCR_LENGTH_BIT) {\r\nu32 except;\r\nchar type;\r\ntype = fop->flags & OP_SD ? 's' : 'd';\r\nif (op == FOP_EXT)\r\npr_debug("VFP: itr%d (%c%u) = op[%u] (d%u)\n",\r\nvecitr >> FPSCR_LENGTH_BIT,\r\ntype, dest, dn, dm);\r\nelse\r\npr_debug("VFP: itr%d (%c%u) = (d%u) op[%u] (d%u)\n",\r\nvecitr >> FPSCR_LENGTH_BIT,\r\ntype, dest, dn, FOP_TO_IDX(op), dm);\r\nexcept = fop->fn(dest, dn, dm, fpscr);\r\npr_debug("VFP: itr%d: exceptions=%08x\n",\r\nvecitr >> FPSCR_LENGTH_BIT, except);\r\nexceptions |= except;\r\ndest = FREG_BANK(dest) + ((FREG_IDX(dest) + vecstride) & 3);\r\ndn = FREG_BANK(dn) + ((FREG_IDX(dn) + vecstride) & 3);\r\nif (FREG_BANK(dm) != 0)\r\ndm = FREG_BANK(dm) + ((FREG_IDX(dm) + vecstride) & 3);\r\n}\r\nreturn exceptions;\r\ninvalid:\r\nreturn ~0;\r\n}
