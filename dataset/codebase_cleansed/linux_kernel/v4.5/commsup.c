static int fib_map_alloc(struct aac_dev *dev)\r\n{\r\ndprintk((KERN_INFO\r\n"allocate hardware fibs pci_alloc_consistent(%p, %d * (%d + %d), %p)\n",\r\ndev->pdev, dev->max_fib_size, dev->scsi_host_ptr->can_queue,\r\nAAC_NUM_MGT_FIB, &dev->hw_fib_pa));\r\ndev->hw_fib_va = pci_alloc_consistent(dev->pdev,\r\n(dev->max_fib_size + sizeof(struct aac_fib_xporthdr))\r\n* (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) + (ALIGN32 - 1),\r\n&dev->hw_fib_pa);\r\nif (dev->hw_fib_va == NULL)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid aac_fib_map_free(struct aac_dev *dev)\r\n{\r\npci_free_consistent(dev->pdev,\r\ndev->max_fib_size * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB),\r\ndev->hw_fib_va, dev->hw_fib_pa);\r\ndev->hw_fib_va = NULL;\r\ndev->hw_fib_pa = 0;\r\n}\r\nint aac_fib_setup(struct aac_dev * dev)\r\n{\r\nstruct fib *fibptr;\r\nstruct hw_fib *hw_fib;\r\ndma_addr_t hw_fib_pa;\r\nint i;\r\nwhile (((i = fib_map_alloc(dev)) == -ENOMEM)\r\n&& (dev->scsi_host_ptr->can_queue > (64 - AAC_NUM_MGT_FIB))) {\r\ndev->init->MaxIoCommands = cpu_to_le32((dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) >> 1);\r\ndev->scsi_host_ptr->can_queue = le32_to_cpu(dev->init->MaxIoCommands) - AAC_NUM_MGT_FIB;\r\n}\r\nif (i<0)\r\nreturn -ENOMEM;\r\nhw_fib_pa = (dev->hw_fib_pa + (ALIGN32 - 1)) & ~(ALIGN32 - 1);\r\ndev->hw_fib_va = (struct hw_fib *)((unsigned char *)dev->hw_fib_va +\r\n(hw_fib_pa - dev->hw_fib_pa));\r\ndev->hw_fib_pa = hw_fib_pa;\r\nmemset(dev->hw_fib_va, 0,\r\n(dev->max_fib_size + sizeof(struct aac_fib_xporthdr)) *\r\n(dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB));\r\ndev->hw_fib_va = (struct hw_fib *)((unsigned char *)dev->hw_fib_va +\r\nsizeof(struct aac_fib_xporthdr));\r\ndev->hw_fib_pa += sizeof(struct aac_fib_xporthdr);\r\nhw_fib = dev->hw_fib_va;\r\nhw_fib_pa = dev->hw_fib_pa;\r\nfor (i = 0, fibptr = &dev->fibs[i];\r\ni < (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB);\r\ni++, fibptr++)\r\n{\r\nfibptr->flags = 0;\r\nfibptr->dev = dev;\r\nfibptr->hw_fib_va = hw_fib;\r\nfibptr->data = (void *) fibptr->hw_fib_va->data;\r\nfibptr->next = fibptr+1;\r\nsema_init(&fibptr->event_wait, 0);\r\nspin_lock_init(&fibptr->event_lock);\r\nhw_fib->header.XferState = cpu_to_le32(0xffffffff);\r\nhw_fib->header.SenderSize = cpu_to_le16(dev->max_fib_size);\r\nfibptr->hw_fib_pa = hw_fib_pa;\r\nhw_fib = (struct hw_fib *)((unsigned char *)hw_fib +\r\ndev->max_fib_size + sizeof(struct aac_fib_xporthdr));\r\nhw_fib_pa = hw_fib_pa +\r\ndev->max_fib_size + sizeof(struct aac_fib_xporthdr);\r\n}\r\ndev->fibs[dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB - 1].next = NULL;\r\ndev->free_fib = &dev->fibs[0];\r\nreturn 0;\r\n}\r\nstruct fib *aac_fib_alloc(struct aac_dev *dev)\r\n{\r\nstruct fib * fibptr;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dev->fib_lock, flags);\r\nfibptr = dev->free_fib;\r\nif(!fibptr){\r\nspin_unlock_irqrestore(&dev->fib_lock, flags);\r\nreturn fibptr;\r\n}\r\ndev->free_fib = fibptr->next;\r\nspin_unlock_irqrestore(&dev->fib_lock, flags);\r\nfibptr->type = FSAFS_NTC_FIB_CONTEXT;\r\nfibptr->size = sizeof(struct fib);\r\nfibptr->hw_fib_va->header.XferState = 0;\r\nfibptr->flags = 0;\r\nfibptr->callback = NULL;\r\nfibptr->callback_data = NULL;\r\nreturn fibptr;\r\n}\r\nvoid aac_fib_free(struct fib *fibptr)\r\n{\r\nunsigned long flags;\r\nif (fibptr->done == 2)\r\nreturn;\r\nspin_lock_irqsave(&fibptr->dev->fib_lock, flags);\r\nif (unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))\r\naac_config.fib_timeouts++;\r\nif (fibptr->hw_fib_va->header.XferState != 0) {\r\nprintk(KERN_WARNING "aac_fib_free, XferState != 0, fibptr = 0x%p, XferState = 0x%x\n",\r\n(void*)fibptr,\r\nle32_to_cpu(fibptr->hw_fib_va->header.XferState));\r\n}\r\nfibptr->next = fibptr->dev->free_fib;\r\nfibptr->dev->free_fib = fibptr;\r\nspin_unlock_irqrestore(&fibptr->dev->fib_lock, flags);\r\n}\r\nvoid aac_fib_init(struct fib *fibptr)\r\n{\r\nstruct hw_fib *hw_fib = fibptr->hw_fib_va;\r\nmemset(&hw_fib->header, 0, sizeof(struct aac_fibhdr));\r\nhw_fib->header.StructType = FIB_MAGIC;\r\nhw_fib->header.Size = cpu_to_le16(fibptr->dev->max_fib_size);\r\nhw_fib->header.XferState = cpu_to_le32(HostOwned | FibInitialized | FibEmpty | FastResponseCapable);\r\nhw_fib->header.u.ReceiverFibAddress = cpu_to_le32(fibptr->hw_fib_pa);\r\nhw_fib->header.SenderSize = cpu_to_le16(fibptr->dev->max_fib_size);\r\n}\r\nstatic void fib_dealloc(struct fib * fibptr)\r\n{\r\nstruct hw_fib *hw_fib = fibptr->hw_fib_va;\r\nhw_fib->header.XferState = 0;\r\n}\r\nstatic int aac_get_entry (struct aac_dev * dev, u32 qid, struct aac_entry **entry, u32 * index, unsigned long *nonotify)\r\n{\r\nstruct aac_queue * q;\r\nunsigned long idx;\r\nq = &dev->queues->queue[qid];\r\nidx = *index = le32_to_cpu(*(q->headers.producer));\r\nif (idx != le32_to_cpu(*(q->headers.consumer))) {\r\nif (--idx == 0) {\r\nif (qid == AdapNormCmdQueue)\r\nidx = ADAP_NORM_CMD_ENTRIES;\r\nelse\r\nidx = ADAP_NORM_RESP_ENTRIES;\r\n}\r\nif (idx != le32_to_cpu(*(q->headers.consumer)))\r\n*nonotify = 1;\r\n}\r\nif (qid == AdapNormCmdQueue) {\r\nif (*index >= ADAP_NORM_CMD_ENTRIES)\r\n*index = 0;\r\n} else {\r\nif (*index >= ADAP_NORM_RESP_ENTRIES)\r\n*index = 0;\r\n}\r\nif ((*index + 1) == le32_to_cpu(*(q->headers.consumer))) {\r\nprintk(KERN_WARNING "Queue %d full, %u outstanding.\n",\r\nqid, atomic_read(&q->numpending));\r\nreturn 0;\r\n} else {\r\n*entry = q->base + *index;\r\nreturn 1;\r\n}\r\n}\r\nint aac_queue_get(struct aac_dev * dev, u32 * index, u32 qid, struct hw_fib * hw_fib, int wait, struct fib * fibptr, unsigned long *nonotify)\r\n{\r\nstruct aac_entry * entry = NULL;\r\nint map = 0;\r\nif (qid == AdapNormCmdQueue) {\r\nwhile (!aac_get_entry(dev, qid, &entry, index, nonotify)) {\r\nprintk(KERN_ERR "GetEntries failed\n");\r\n}\r\nentry->size = cpu_to_le32(le16_to_cpu(hw_fib->header.Size));\r\nmap = 1;\r\n} else {\r\nwhile (!aac_get_entry(dev, qid, &entry, index, nonotify)) {\r\n}\r\nentry->size = cpu_to_le32(le16_to_cpu(hw_fib->header.Size));\r\nentry->addr = hw_fib->header.SenderFibAddress;\r\nhw_fib->header.u.ReceiverFibAddress = hw_fib->header.SenderFibAddress;\r\nmap = 0;\r\n}\r\nif (map)\r\nentry->addr = cpu_to_le32(fibptr->hw_fib_pa);\r\nreturn 0;\r\n}\r\nint aac_fib_send(u16 command, struct fib *fibptr, unsigned long size,\r\nint priority, int wait, int reply, fib_callback callback,\r\nvoid *callback_data)\r\n{\r\nstruct aac_dev * dev = fibptr->dev;\r\nstruct hw_fib * hw_fib = fibptr->hw_fib_va;\r\nunsigned long flags = 0;\r\nunsigned long mflags = 0;\r\nunsigned long sflags = 0;\r\nif (!(hw_fib->header.XferState & cpu_to_le32(HostOwned)))\r\nreturn -EBUSY;\r\nfibptr->flags = 0;\r\nif (wait && !reply) {\r\nreturn -EINVAL;\r\n} else if (!wait && reply) {\r\nhw_fib->header.XferState |= cpu_to_le32(Async | ResponseExpected);\r\nFIB_COUNTER_INCREMENT(aac_config.AsyncSent);\r\n} else if (!wait && !reply) {\r\nhw_fib->header.XferState |= cpu_to_le32(NoResponseExpected);\r\nFIB_COUNTER_INCREMENT(aac_config.NoResponseSent);\r\n} else if (wait && reply) {\r\nhw_fib->header.XferState |= cpu_to_le32(ResponseExpected);\r\nFIB_COUNTER_INCREMENT(aac_config.NormalSent);\r\n}\r\nhw_fib->header.SenderFibAddress = cpu_to_le32(((u32)(fibptr - dev->fibs)) << 2);\r\nhw_fib->header.Handle = (u32)(fibptr - dev->fibs) + 1;\r\nhw_fib->header.Command = cpu_to_le16(command);\r\nhw_fib->header.XferState |= cpu_to_le32(SentFromHost);\r\nhw_fib->header.Size = cpu_to_le16(sizeof(struct aac_fibhdr) + size);\r\nif (le16_to_cpu(hw_fib->header.Size) > le16_to_cpu(hw_fib->header.SenderSize)) {\r\nreturn -EMSGSIZE;\r\n}\r\nhw_fib->header.XferState |= cpu_to_le32(NormalPriority);\r\nif (!wait) {\r\nfibptr->callback = callback;\r\nfibptr->callback_data = callback_data;\r\nfibptr->flags = FIB_CONTEXT_FLAG;\r\n}\r\nfibptr->done = 0;\r\nFIB_COUNTER_INCREMENT(aac_config.FibsSent);\r\ndprintk((KERN_DEBUG "Fib contents:.\n"));\r\ndprintk((KERN_DEBUG " Command = %d.\n", le32_to_cpu(hw_fib->header.Command)));\r\ndprintk((KERN_DEBUG " SubCommand = %d.\n", le32_to_cpu(((struct aac_query_mount *)fib_data(fibptr))->command)));\r\ndprintk((KERN_DEBUG " XferState = %x.\n", le32_to_cpu(hw_fib->header.XferState)));\r\ndprintk((KERN_DEBUG " hw_fib va being sent=%p\n",fibptr->hw_fib_va));\r\ndprintk((KERN_DEBUG " hw_fib pa being sent=%lx\n",(ulong)fibptr->hw_fib_pa));\r\ndprintk((KERN_DEBUG " fib being sent=%p\n",fibptr));\r\nif (!dev->queues)\r\nreturn -EBUSY;\r\nif (wait) {\r\nspin_lock_irqsave(&dev->manage_lock, mflags);\r\nif (dev->management_fib_count >= AAC_NUM_MGT_FIB) {\r\nprintk(KERN_INFO "No management Fibs Available:%d\n",\r\ndev->management_fib_count);\r\nspin_unlock_irqrestore(&dev->manage_lock, mflags);\r\nreturn -EBUSY;\r\n}\r\ndev->management_fib_count++;\r\nspin_unlock_irqrestore(&dev->manage_lock, mflags);\r\nspin_lock_irqsave(&fibptr->event_lock, flags);\r\n}\r\nif (dev->sync_mode) {\r\nif (wait)\r\nspin_unlock_irqrestore(&fibptr->event_lock, flags);\r\nspin_lock_irqsave(&dev->sync_lock, sflags);\r\nif (dev->sync_fib) {\r\nlist_add_tail(&fibptr->fiblink, &dev->sync_fib_list);\r\nspin_unlock_irqrestore(&dev->sync_lock, sflags);\r\n} else {\r\ndev->sync_fib = fibptr;\r\nspin_unlock_irqrestore(&dev->sync_lock, sflags);\r\naac_adapter_sync_cmd(dev, SEND_SYNCHRONOUS_FIB,\r\n(u32)fibptr->hw_fib_pa, 0, 0, 0, 0, 0,\r\nNULL, NULL, NULL, NULL, NULL);\r\n}\r\nif (wait) {\r\nfibptr->flags |= FIB_CONTEXT_FLAG_WAIT;\r\nif (down_interruptible(&fibptr->event_wait)) {\r\nfibptr->flags &= ~FIB_CONTEXT_FLAG_WAIT;\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nreturn -EINPROGRESS;\r\n}\r\nif (aac_adapter_deliver(fibptr) != 0) {\r\nprintk(KERN_ERR "aac_fib_send: returned -EBUSY\n");\r\nif (wait) {\r\nspin_unlock_irqrestore(&fibptr->event_lock, flags);\r\nspin_lock_irqsave(&dev->manage_lock, mflags);\r\ndev->management_fib_count--;\r\nspin_unlock_irqrestore(&dev->manage_lock, mflags);\r\n}\r\nreturn -EBUSY;\r\n}\r\nif (wait) {\r\nspin_unlock_irqrestore(&fibptr->event_lock, flags);\r\nif (wait < 0) {\r\nunsigned long timeout = jiffies + (180 * HZ);\r\nwhile (down_trylock(&fibptr->event_wait)) {\r\nint blink;\r\nif (time_is_before_eq_jiffies(timeout)) {\r\nstruct aac_queue * q = &dev->queues->queue[AdapNormCmdQueue];\r\natomic_dec(&q->numpending);\r\nif (wait == -1) {\r\nprintk(KERN_ERR "aacraid: aac_fib_send: first asynchronous command timed out.\n"\r\n"Usually a result of a PCI interrupt routing problem;\n"\r\n"update mother board BIOS or consider utilizing one of\n"\r\n"the SAFE mode kernel options (acpi, apic etc)\n");\r\n}\r\nreturn -ETIMEDOUT;\r\n}\r\nif ((blink = aac_adapter_check_health(dev)) > 0) {\r\nif (wait == -1) {\r\nprintk(KERN_ERR "aacraid: aac_fib_send: adapter blinkLED 0x%x.\n"\r\n"Usually a result of a serious unrecoverable hardware problem\n",\r\nblink);\r\n}\r\nreturn -EFAULT;\r\n}\r\ncpu_relax();\r\n}\r\n} else if (down_interruptible(&fibptr->event_wait)) {\r\n}\r\nspin_lock_irqsave(&fibptr->event_lock, flags);\r\nif (fibptr->done == 0) {\r\nfibptr->done = 2;\r\nspin_unlock_irqrestore(&fibptr->event_lock, flags);\r\nreturn -ERESTARTSYS;\r\n}\r\nspin_unlock_irqrestore(&fibptr->event_lock, flags);\r\nBUG_ON(fibptr->done == 0);\r\nif(unlikely(fibptr->flags & FIB_CONTEXT_FLAG_TIMED_OUT))\r\nreturn -ETIMEDOUT;\r\nreturn 0;\r\n}\r\nif (reply)\r\nreturn -EINPROGRESS;\r\nelse\r\nreturn 0;\r\n}\r\nint aac_consumer_get(struct aac_dev * dev, struct aac_queue * q, struct aac_entry **entry)\r\n{\r\nu32 index;\r\nint status;\r\nif (le32_to_cpu(*q->headers.producer) == le32_to_cpu(*q->headers.consumer)) {\r\nstatus = 0;\r\n} else {\r\nif (le32_to_cpu(*q->headers.consumer) >= q->entries)\r\nindex = 0;\r\nelse\r\nindex = le32_to_cpu(*q->headers.consumer);\r\n*entry = q->base + index;\r\nstatus = 1;\r\n}\r\nreturn(status);\r\n}\r\nvoid aac_consumer_free(struct aac_dev * dev, struct aac_queue *q, u32 qid)\r\n{\r\nint wasfull = 0;\r\nu32 notify;\r\nif ((le32_to_cpu(*q->headers.producer)+1) == le32_to_cpu(*q->headers.consumer))\r\nwasfull = 1;\r\nif (le32_to_cpu(*q->headers.consumer) >= q->entries)\r\n*q->headers.consumer = cpu_to_le32(1);\r\nelse\r\nle32_add_cpu(q->headers.consumer, 1);\r\nif (wasfull) {\r\nswitch (qid) {\r\ncase HostNormCmdQueue:\r\nnotify = HostNormCmdNotFull;\r\nbreak;\r\ncase HostNormRespQueue:\r\nnotify = HostNormRespNotFull;\r\nbreak;\r\ndefault:\r\nBUG();\r\nreturn;\r\n}\r\naac_adapter_notify(dev, notify);\r\n}\r\n}\r\nint aac_fib_adapter_complete(struct fib *fibptr, unsigned short size)\r\n{\r\nstruct hw_fib * hw_fib = fibptr->hw_fib_va;\r\nstruct aac_dev * dev = fibptr->dev;\r\nstruct aac_queue * q;\r\nunsigned long nointr = 0;\r\nunsigned long qflags;\r\nif (dev->comm_interface == AAC_COMM_MESSAGE_TYPE1 ||\r\ndev->comm_interface == AAC_COMM_MESSAGE_TYPE2) {\r\nkfree(hw_fib);\r\nreturn 0;\r\n}\r\nif (hw_fib->header.XferState == 0) {\r\nif (dev->comm_interface == AAC_COMM_MESSAGE)\r\nkfree(hw_fib);\r\nreturn 0;\r\n}\r\nif (hw_fib->header.StructType != FIB_MAGIC &&\r\nhw_fib->header.StructType != FIB_MAGIC2 &&\r\nhw_fib->header.StructType != FIB_MAGIC2_64) {\r\nif (dev->comm_interface == AAC_COMM_MESSAGE)\r\nkfree(hw_fib);\r\nreturn -EINVAL;\r\n}\r\nif (hw_fib->header.XferState & cpu_to_le32(SentFromAdapter)) {\r\nif (dev->comm_interface == AAC_COMM_MESSAGE) {\r\nkfree (hw_fib);\r\n} else {\r\nu32 index;\r\nhw_fib->header.XferState |= cpu_to_le32(HostProcessed);\r\nif (size) {\r\nsize += sizeof(struct aac_fibhdr);\r\nif (size > le16_to_cpu(hw_fib->header.SenderSize))\r\nreturn -EMSGSIZE;\r\nhw_fib->header.Size = cpu_to_le16(size);\r\n}\r\nq = &dev->queues->queue[AdapNormRespQueue];\r\nspin_lock_irqsave(q->lock, qflags);\r\naac_queue_get(dev, &index, AdapNormRespQueue, hw_fib, 1, NULL, &nointr);\r\n*(q->headers.producer) = cpu_to_le32(index + 1);\r\nspin_unlock_irqrestore(q->lock, qflags);\r\nif (!(nointr & (int)aac_config.irq_mod))\r\naac_adapter_notify(dev, AdapNormRespQueue);\r\n}\r\n} else {\r\nprintk(KERN_WARNING "aac_fib_adapter_complete: "\r\n"Unknown xferstate detected.\n");\r\nBUG();\r\n}\r\nreturn 0;\r\n}\r\nint aac_fib_complete(struct fib *fibptr)\r\n{\r\nstruct hw_fib * hw_fib = fibptr->hw_fib_va;\r\nif (hw_fib->header.XferState == 0)\r\nreturn 0;\r\nif (hw_fib->header.StructType != FIB_MAGIC &&\r\nhw_fib->header.StructType != FIB_MAGIC2 &&\r\nhw_fib->header.StructType != FIB_MAGIC2_64)\r\nreturn -EINVAL;\r\nif((hw_fib->header.XferState & cpu_to_le32(SentFromHost)) &&\r\n(hw_fib->header.XferState & cpu_to_le32(AdapterProcessed)))\r\n{\r\nfib_dealloc(fibptr);\r\n}\r\nelse if(hw_fib->header.XferState & cpu_to_le32(SentFromHost))\r\n{\r\nfib_dealloc(fibptr);\r\n} else if(hw_fib->header.XferState & cpu_to_le32(HostOwned)) {\r\nfib_dealloc(fibptr);\r\n} else {\r\nBUG();\r\n}\r\nreturn 0;\r\n}\r\nvoid aac_printf(struct aac_dev *dev, u32 val)\r\n{\r\nchar *cp = dev->printfbuf;\r\nif (dev->printf_enabled)\r\n{\r\nint length = val & 0xffff;\r\nint level = (val >> 16) & 0xffff;\r\nif (length > 255)\r\nlength = 255;\r\nif (cp[length] != 0)\r\ncp[length] = 0;\r\nif (level == LOG_AAC_HIGH_ERROR)\r\nprintk(KERN_WARNING "%s:%s", dev->name, cp);\r\nelse\r\nprintk(KERN_INFO "%s:%s", dev->name, cp);\r\n}\r\nmemset(cp, 0, 256);\r\n}\r\nstatic void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)\r\n{\r\nstruct hw_fib * hw_fib = fibptr->hw_fib_va;\r\nstruct aac_aifcmd * aifcmd = (struct aac_aifcmd *)hw_fib->data;\r\nu32 channel, id, lun, container;\r\nstruct scsi_device *device;\r\nenum {\r\nNOTHING,\r\nDELETE,\r\nADD,\r\nCHANGE\r\n} device_config_needed = NOTHING;\r\nif (!dev || !dev->fsa_dev)\r\nreturn;\r\ncontainer = channel = id = lun = (u32)-1;\r\nswitch (le32_to_cpu(aifcmd->command)) {\r\ncase AifCmdDriverNotify:\r\nswitch (le32_to_cpu(((__le32 *)aifcmd->data)[0])) {\r\ncase AifRawDeviceRemove:\r\ncontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\r\nif ((container >> 28)) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nchannel = (container >> 24) & 0xF;\r\nif (channel >= dev->maximum_num_channels) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nid = container & 0xFFFF;\r\nif (id >= dev->maximum_num_physicals) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nlun = (container >> 16) & 0xFF;\r\ncontainer = (u32)-1;\r\nchannel = aac_phys_to_logical(channel);\r\ndevice_config_needed =\r\n(((__le32 *)aifcmd->data)[0] ==\r\ncpu_to_le32(AifRawDeviceRemove)) ? DELETE : ADD;\r\nif (device_config_needed == ADD) {\r\ndevice = scsi_device_lookup(\r\ndev->scsi_host_ptr,\r\nchannel, id, lun);\r\nif (device) {\r\nscsi_remove_device(device);\r\nscsi_device_put(device);\r\n}\r\n}\r\nbreak;\r\ncase AifDenMorphComplete:\r\ncase AifDenVolumeExtendComplete:\r\ncontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\r\nif (container >= dev->maximum_num_containers)\r\nbreak;\r\nif ((dev != NULL) && (dev->scsi_host_ptr != NULL)) {\r\ndevice = scsi_device_lookup(dev->scsi_host_ptr,\r\nCONTAINER_TO_CHANNEL(container),\r\nCONTAINER_TO_ID(container),\r\nCONTAINER_TO_LUN(container));\r\nif (device) {\r\ndev->fsa_dev[container].config_needed = CHANGE;\r\ndev->fsa_dev[container].config_waiting_on = AifEnConfigChange;\r\ndev->fsa_dev[container].config_waiting_stamp = jiffies;\r\nscsi_device_put(device);\r\n}\r\n}\r\n}\r\nif (container != (u32)-1) {\r\nif (container >= dev->maximum_num_containers)\r\nbreak;\r\nif ((dev->fsa_dev[container].config_waiting_on ==\r\nle32_to_cpu(*(__le32 *)aifcmd->data)) &&\r\ntime_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\r\ndev->fsa_dev[container].config_waiting_on = 0;\r\n} else for (container = 0;\r\ncontainer < dev->maximum_num_containers; ++container) {\r\nif ((dev->fsa_dev[container].config_waiting_on ==\r\nle32_to_cpu(*(__le32 *)aifcmd->data)) &&\r\ntime_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\r\ndev->fsa_dev[container].config_waiting_on = 0;\r\n}\r\nbreak;\r\ncase AifCmdEventNotify:\r\nswitch (le32_to_cpu(((__le32 *)aifcmd->data)[0])) {\r\ncase AifEnBatteryEvent:\r\ndev->cache_protected =\r\n(((__le32 *)aifcmd->data)[1] == cpu_to_le32(3));\r\nbreak;\r\ncase AifEnAddContainer:\r\ncontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\r\nif (container >= dev->maximum_num_containers)\r\nbreak;\r\ndev->fsa_dev[container].config_needed = ADD;\r\ndev->fsa_dev[container].config_waiting_on =\r\nAifEnConfigChange;\r\ndev->fsa_dev[container].config_waiting_stamp = jiffies;\r\nbreak;\r\ncase AifEnDeleteContainer:\r\ncontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\r\nif (container >= dev->maximum_num_containers)\r\nbreak;\r\ndev->fsa_dev[container].config_needed = DELETE;\r\ndev->fsa_dev[container].config_waiting_on =\r\nAifEnConfigChange;\r\ndev->fsa_dev[container].config_waiting_stamp = jiffies;\r\nbreak;\r\ncase AifEnContainerChange:\r\ncontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\r\nif (container >= dev->maximum_num_containers)\r\nbreak;\r\nif (dev->fsa_dev[container].config_waiting_on &&\r\ntime_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\r\nbreak;\r\ndev->fsa_dev[container].config_needed = CHANGE;\r\ndev->fsa_dev[container].config_waiting_on =\r\nAifEnConfigChange;\r\ndev->fsa_dev[container].config_waiting_stamp = jiffies;\r\nbreak;\r\ncase AifEnConfigChange:\r\nbreak;\r\ncase AifEnAddJBOD:\r\ncase AifEnDeleteJBOD:\r\ncontainer = le32_to_cpu(((__le32 *)aifcmd->data)[1]);\r\nif ((container >> 28)) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nchannel = (container >> 24) & 0xF;\r\nif (channel >= dev->maximum_num_channels) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nid = container & 0xFFFF;\r\nif (id >= dev->maximum_num_physicals) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nlun = (container >> 16) & 0xFF;\r\ncontainer = (u32)-1;\r\nchannel = aac_phys_to_logical(channel);\r\ndevice_config_needed =\r\n(((__le32 *)aifcmd->data)[0] ==\r\ncpu_to_le32(AifEnAddJBOD)) ? ADD : DELETE;\r\nif (device_config_needed == ADD) {\r\ndevice = scsi_device_lookup(dev->scsi_host_ptr,\r\nchannel,\r\nid,\r\nlun);\r\nif (device) {\r\nscsi_remove_device(device);\r\nscsi_device_put(device);\r\n}\r\n}\r\nbreak;\r\ncase AifEnEnclosureManagement:\r\nif (dev->jbod)\r\nbreak;\r\nswitch (le32_to_cpu(((__le32 *)aifcmd->data)[3])) {\r\ncase EM_DRIVE_INSERTION:\r\ncase EM_DRIVE_REMOVAL:\r\ncase EM_SES_DRIVE_INSERTION:\r\ncase EM_SES_DRIVE_REMOVAL:\r\ncontainer = le32_to_cpu(\r\n((__le32 *)aifcmd->data)[2]);\r\nif ((container >> 28)) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nchannel = (container >> 24) & 0xF;\r\nif (channel >= dev->maximum_num_channels) {\r\ncontainer = (u32)-1;\r\nbreak;\r\n}\r\nid = container & 0xFFFF;\r\nlun = (container >> 16) & 0xFF;\r\ncontainer = (u32)-1;\r\nif (id >= dev->maximum_num_physicals) {\r\nif ((0x2000 <= id) || lun || channel ||\r\n((channel = (id >> 7) & 0x3F) >=\r\ndev->maximum_num_channels))\r\nbreak;\r\nlun = (id >> 4) & 7;\r\nid &= 0xF;\r\n}\r\nchannel = aac_phys_to_logical(channel);\r\ndevice_config_needed =\r\n((((__le32 *)aifcmd->data)[3]\r\n== cpu_to_le32(EM_DRIVE_INSERTION)) ||\r\n(((__le32 *)aifcmd->data)[3]\r\n== cpu_to_le32(EM_SES_DRIVE_INSERTION))) ?\r\nADD : DELETE;\r\nbreak;\r\n}\r\nbreak;\r\n}\r\nif (container != (u32)-1) {\r\nif (container >= dev->maximum_num_containers)\r\nbreak;\r\nif ((dev->fsa_dev[container].config_waiting_on ==\r\nle32_to_cpu(*(__le32 *)aifcmd->data)) &&\r\ntime_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\r\ndev->fsa_dev[container].config_waiting_on = 0;\r\n} else for (container = 0;\r\ncontainer < dev->maximum_num_containers; ++container) {\r\nif ((dev->fsa_dev[container].config_waiting_on ==\r\nle32_to_cpu(*(__le32 *)aifcmd->data)) &&\r\ntime_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT))\r\ndev->fsa_dev[container].config_waiting_on = 0;\r\n}\r\nbreak;\r\ncase AifCmdJobProgress:\r\nif (((__le32 *)aifcmd->data)[1] == cpu_to_le32(AifJobCtrZero) &&\r\n(((__le32 *)aifcmd->data)[6] == ((__le32 *)aifcmd->data)[5] ||\r\n((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsSuccess))) {\r\nfor (container = 0;\r\ncontainer < dev->maximum_num_containers;\r\n++container) {\r\ndev->fsa_dev[container].config_waiting_on =\r\nAifEnContainerChange;\r\ndev->fsa_dev[container].config_needed = ADD;\r\ndev->fsa_dev[container].config_waiting_stamp =\r\njiffies;\r\n}\r\n}\r\nif (((__le32 *)aifcmd->data)[1] == cpu_to_le32(AifJobCtrZero) &&\r\n((__le32 *)aifcmd->data)[6] == 0 &&\r\n((__le32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsRunning)) {\r\nfor (container = 0;\r\ncontainer < dev->maximum_num_containers;\r\n++container) {\r\ndev->fsa_dev[container].config_waiting_on =\r\nAifEnContainerChange;\r\ndev->fsa_dev[container].config_needed = DELETE;\r\ndev->fsa_dev[container].config_waiting_stamp =\r\njiffies;\r\n}\r\n}\r\nbreak;\r\n}\r\ncontainer = 0;\r\nretry_next:\r\nif (device_config_needed == NOTHING)\r\nfor (; container < dev->maximum_num_containers; ++container) {\r\nif ((dev->fsa_dev[container].config_waiting_on == 0) &&\r\n(dev->fsa_dev[container].config_needed != NOTHING) &&\r\ntime_before(jiffies, dev->fsa_dev[container].config_waiting_stamp + AIF_SNIFF_TIMEOUT)) {\r\ndevice_config_needed =\r\ndev->fsa_dev[container].config_needed;\r\ndev->fsa_dev[container].config_needed = NOTHING;\r\nchannel = CONTAINER_TO_CHANNEL(container);\r\nid = CONTAINER_TO_ID(container);\r\nlun = CONTAINER_TO_LUN(container);\r\nbreak;\r\n}\r\n}\r\nif (device_config_needed == NOTHING)\r\nreturn;\r\nif (!dev || !dev->scsi_host_ptr)\r\nreturn;\r\nif ((channel == CONTAINER_CHANNEL) &&\r\n(device_config_needed != NOTHING)) {\r\nif (dev->fsa_dev[container].valid == 1)\r\ndev->fsa_dev[container].valid = 2;\r\naac_probe_container(dev, container);\r\n}\r\ndevice = scsi_device_lookup(dev->scsi_host_ptr, channel, id, lun);\r\nif (device) {\r\nswitch (device_config_needed) {\r\ncase DELETE:\r\n#if (defined(AAC_DEBUG_INSTRUMENT_AIF_DELETE))\r\nscsi_remove_device(device);\r\n#else\r\nif (scsi_device_online(device)) {\r\nscsi_device_set_state(device, SDEV_OFFLINE);\r\nsdev_printk(KERN_INFO, device,\r\n"Device offlined - %s\n",\r\n(channel == CONTAINER_CHANNEL) ?\r\n"array deleted" :\r\n"enclosure services event");\r\n}\r\n#endif\r\nbreak;\r\ncase ADD:\r\nif (!scsi_device_online(device)) {\r\nsdev_printk(KERN_INFO, device,\r\n"Device online - %s\n",\r\n(channel == CONTAINER_CHANNEL) ?\r\n"array created" :\r\n"enclosure services event");\r\nscsi_device_set_state(device, SDEV_RUNNING);\r\n}\r\ncase CHANGE:\r\nif ((channel == CONTAINER_CHANNEL)\r\n&& (!dev->fsa_dev[container].valid)) {\r\n#if (defined(AAC_DEBUG_INSTRUMENT_AIF_DELETE))\r\nscsi_remove_device(device);\r\n#else\r\nif (!scsi_device_online(device))\r\nbreak;\r\nscsi_device_set_state(device, SDEV_OFFLINE);\r\nsdev_printk(KERN_INFO, device,\r\n"Device offlined - %s\n",\r\n"array failed");\r\n#endif\r\nbreak;\r\n}\r\nscsi_rescan_device(&device->sdev_gendev);\r\ndefault:\r\nbreak;\r\n}\r\nscsi_device_put(device);\r\ndevice_config_needed = NOTHING;\r\n}\r\nif (device_config_needed == ADD)\r\nscsi_add_device(dev->scsi_host_ptr, channel, id, lun);\r\nif (channel == CONTAINER_CHANNEL) {\r\ncontainer++;\r\ndevice_config_needed = NOTHING;\r\ngoto retry_next;\r\n}\r\n}\r\nstatic int _aac_reset_adapter(struct aac_dev *aac, int forced)\r\n{\r\nint index, quirks;\r\nint retval;\r\nstruct Scsi_Host *host;\r\nstruct scsi_device *dev;\r\nstruct scsi_cmnd *command;\r\nstruct scsi_cmnd *command_list;\r\nint jafo = 0;\r\nhost = aac->scsi_host_ptr;\r\nscsi_block_requests(host);\r\naac_adapter_disable_int(aac);\r\nif (aac->thread->pid != current->pid) {\r\nspin_unlock_irq(host->host_lock);\r\nkthread_stop(aac->thread);\r\njafo = 1;\r\n}\r\nretval = aac_adapter_restart(aac, forced ? 0 : aac_adapter_check_health(aac));\r\nif (retval)\r\ngoto out;\r\nfor (retval = 1, index = 0; index < (aac->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB); index++) {\r\nstruct fib *fib = &aac->fibs[index];\r\nif (!(fib->hw_fib_va->header.XferState & cpu_to_le32(NoResponseExpected | Async)) &&\r\n(fib->hw_fib_va->header.XferState & cpu_to_le32(ResponseExpected))) {\r\nunsigned long flagv;\r\nspin_lock_irqsave(&fib->event_lock, flagv);\r\nup(&fib->event_wait);\r\nspin_unlock_irqrestore(&fib->event_lock, flagv);\r\nschedule();\r\nretval = 0;\r\n}\r\n}\r\nif (retval == 0)\r\nssleep(2);\r\nindex = aac->cardtype;\r\naac_fib_map_free(aac);\r\npci_free_consistent(aac->pdev, aac->comm_size, aac->comm_addr, aac->comm_phys);\r\naac->comm_addr = NULL;\r\naac->comm_phys = 0;\r\nkfree(aac->queues);\r\naac->queues = NULL;\r\naac_free_irq(aac);\r\nkfree(aac->fsa_dev);\r\naac->fsa_dev = NULL;\r\nquirks = aac_get_driver_ident(index)->quirks;\r\nif (quirks & AAC_QUIRK_31BIT) {\r\nif (((retval = pci_set_dma_mask(aac->pdev, DMA_BIT_MASK(31)))) ||\r\n((retval = pci_set_consistent_dma_mask(aac->pdev, DMA_BIT_MASK(31)))))\r\ngoto out;\r\n} else {\r\nif (((retval = pci_set_dma_mask(aac->pdev, DMA_BIT_MASK(32)))) ||\r\n((retval = pci_set_consistent_dma_mask(aac->pdev, DMA_BIT_MASK(32)))))\r\ngoto out;\r\n}\r\nif ((retval = (*(aac_get_driver_ident(index)->init))(aac)))\r\ngoto out;\r\nif (quirks & AAC_QUIRK_31BIT)\r\nif ((retval = pci_set_dma_mask(aac->pdev, DMA_BIT_MASK(32))))\r\ngoto out;\r\nif (jafo) {\r\naac->thread = kthread_run(aac_command_thread, aac, "%s",\r\naac->name);\r\nif (IS_ERR(aac->thread)) {\r\nretval = PTR_ERR(aac->thread);\r\ngoto out;\r\n}\r\n}\r\n(void)aac_get_adapter_info(aac);\r\nif ((quirks & AAC_QUIRK_34SG) && (host->sg_tablesize > 34)) {\r\nhost->sg_tablesize = 34;\r\nhost->max_sectors = (host->sg_tablesize * 8) + 112;\r\n}\r\nif ((quirks & AAC_QUIRK_17SG) && (host->sg_tablesize > 17)) {\r\nhost->sg_tablesize = 17;\r\nhost->max_sectors = (host->sg_tablesize * 8) + 112;\r\n}\r\naac_get_config_status(aac, 1);\r\naac_get_containers(aac);\r\ncommand_list = NULL;\r\n__shost_for_each_device(dev, host) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&dev->list_lock, flags);\r\nlist_for_each_entry(command, &dev->cmd_list, list)\r\nif (command->SCp.phase == AAC_OWNER_FIRMWARE) {\r\ncommand->SCp.buffer = (struct scatterlist *)command_list;\r\ncommand_list = command;\r\n}\r\nspin_unlock_irqrestore(&dev->list_lock, flags);\r\n}\r\nwhile ((command = command_list)) {\r\ncommand_list = (struct scsi_cmnd *)command->SCp.buffer;\r\ncommand->SCp.buffer = NULL;\r\ncommand->result = DID_OK << 16\r\n| COMMAND_COMPLETE << 8\r\n| SAM_STAT_TASK_SET_FULL;\r\ncommand->SCp.phase = AAC_OWNER_ERROR_HANDLER;\r\ncommand->scsi_done(command);\r\n}\r\nretval = 0;\r\nout:\r\naac->in_reset = 0;\r\nscsi_unblock_requests(host);\r\nif (jafo) {\r\nspin_lock_irq(host->host_lock);\r\n}\r\nreturn retval;\r\n}\r\nint aac_reset_adapter(struct aac_dev * aac, int forced)\r\n{\r\nunsigned long flagv = 0;\r\nint retval;\r\nstruct Scsi_Host * host;\r\nif (spin_trylock_irqsave(&aac->fib_lock, flagv) == 0)\r\nreturn -EBUSY;\r\nif (aac->in_reset) {\r\nspin_unlock_irqrestore(&aac->fib_lock, flagv);\r\nreturn -EBUSY;\r\n}\r\naac->in_reset = 1;\r\nspin_unlock_irqrestore(&aac->fib_lock, flagv);\r\nhost = aac->scsi_host_ptr;\r\nscsi_block_requests(host);\r\nif (forced < 2) for (retval = 60; retval; --retval) {\r\nstruct scsi_device * dev;\r\nstruct scsi_cmnd * command;\r\nint active = 0;\r\n__shost_for_each_device(dev, host) {\r\nspin_lock_irqsave(&dev->list_lock, flagv);\r\nlist_for_each_entry(command, &dev->cmd_list, list) {\r\nif (command->SCp.phase == AAC_OWNER_FIRMWARE) {\r\nactive++;\r\nbreak;\r\n}\r\n}\r\nspin_unlock_irqrestore(&dev->list_lock, flagv);\r\nif (active)\r\nbreak;\r\n}\r\nif (active == 0)\r\nbreak;\r\nssleep(1);\r\n}\r\nif (forced < 2)\r\naac_send_shutdown(aac);\r\nspin_lock_irqsave(host->host_lock, flagv);\r\nretval = _aac_reset_adapter(aac, forced ? forced : ((aac_check_reset != 0) && (aac_check_reset != 1)));\r\nspin_unlock_irqrestore(host->host_lock, flagv);\r\nif ((forced < 2) && (retval == -ENODEV)) {\r\nstruct fib * fibctx = aac_fib_alloc(aac);\r\nif (fibctx) {\r\nstruct aac_pause *cmd;\r\nint status;\r\naac_fib_init(fibctx);\r\ncmd = (struct aac_pause *) fib_data(fibctx);\r\ncmd->command = cpu_to_le32(VM_ContainerConfig);\r\ncmd->type = cpu_to_le32(CT_PAUSE_IO);\r\ncmd->timeout = cpu_to_le32(1);\r\ncmd->min = cpu_to_le32(1);\r\ncmd->noRescan = cpu_to_le32(1);\r\ncmd->count = cpu_to_le32(0);\r\nstatus = aac_fib_send(ContainerCommand,\r\nfibctx,\r\nsizeof(struct aac_pause),\r\nFsaNormal,\r\n-2 , 1,\r\nNULL, NULL);\r\nif (status >= 0)\r\naac_fib_complete(fibctx);\r\nif (status != -ERESTARTSYS)\r\naac_fib_free(fibctx);\r\n}\r\n}\r\nreturn retval;\r\n}\r\nint aac_check_health(struct aac_dev * aac)\r\n{\r\nint BlinkLED;\r\nunsigned long time_now, flagv = 0;\r\nstruct list_head * entry;\r\nstruct Scsi_Host * host;\r\nif (spin_trylock_irqsave(&aac->fib_lock, flagv) == 0)\r\nreturn 0;\r\nif (aac->in_reset || !(BlinkLED = aac_adapter_check_health(aac))) {\r\nspin_unlock_irqrestore(&aac->fib_lock, flagv);\r\nreturn 0;\r\n}\r\naac->in_reset = 1;\r\ntime_now = jiffies/HZ;\r\nentry = aac->fib_list.next;\r\nwhile (entry != &aac->fib_list) {\r\nstruct aac_fib_context *fibctx = list_entry(entry, struct aac_fib_context, next);\r\nstruct hw_fib * hw_fib;\r\nstruct fib * fib;\r\nif (fibctx->count > 20) {\r\nu32 time_last = fibctx->jiffies;\r\nif ((time_now - time_last) > aif_timeout) {\r\nentry = entry->next;\r\naac_close_fib_context(aac, fibctx);\r\ncontinue;\r\n}\r\n}\r\nhw_fib = kzalloc(sizeof(struct hw_fib), GFP_ATOMIC);\r\nfib = kzalloc(sizeof(struct fib), GFP_ATOMIC);\r\nif (fib && hw_fib) {\r\nstruct aac_aifcmd * aif;\r\nfib->hw_fib_va = hw_fib;\r\nfib->dev = aac;\r\naac_fib_init(fib);\r\nfib->type = FSAFS_NTC_FIB_CONTEXT;\r\nfib->size = sizeof (struct fib);\r\nfib->data = hw_fib->data;\r\naif = (struct aac_aifcmd *)hw_fib->data;\r\naif->command = cpu_to_le32(AifCmdEventNotify);\r\naif->seqnum = cpu_to_le32(0xFFFFFFFF);\r\n((__le32 *)aif->data)[0] = cpu_to_le32(AifEnExpEvent);\r\n((__le32 *)aif->data)[1] = cpu_to_le32(AifExeFirmwarePanic);\r\n((__le32 *)aif->data)[2] = cpu_to_le32(AifHighPriority);\r\n((__le32 *)aif->data)[3] = cpu_to_le32(BlinkLED);\r\nlist_add_tail(&fib->fiblink, &fibctx->fib_list);\r\nfibctx->count++;\r\nup(&fibctx->wait_sem);\r\n} else {\r\nprintk(KERN_WARNING "aifd: didn't allocate NewFib.\n");\r\nkfree(fib);\r\nkfree(hw_fib);\r\n}\r\nentry = entry->next;\r\n}\r\nspin_unlock_irqrestore(&aac->fib_lock, flagv);\r\nif (BlinkLED < 0) {\r\nprintk(KERN_ERR "%s: Host adapter dead %d\n", aac->name, BlinkLED);\r\ngoto out;\r\n}\r\nprintk(KERN_ERR "%s: Host adapter BLINK LED 0x%x\n", aac->name, BlinkLED);\r\nif (!aac_check_reset || ((aac_check_reset == 1) &&\r\n(aac->supplement_adapter_info.SupportedOptions2 &\r\nAAC_OPTION_IGNORE_RESET)))\r\ngoto out;\r\nhost = aac->scsi_host_ptr;\r\nif (aac->thread->pid != current->pid)\r\nspin_lock_irqsave(host->host_lock, flagv);\r\nBlinkLED = _aac_reset_adapter(aac, aac_check_reset != 1);\r\nif (aac->thread->pid != current->pid)\r\nspin_unlock_irqrestore(host->host_lock, flagv);\r\nreturn BlinkLED;\r\nout:\r\naac->in_reset = 0;\r\nreturn BlinkLED;\r\n}\r\nint aac_command_thread(void *data)\r\n{\r\nstruct aac_dev *dev = data;\r\nstruct hw_fib *hw_fib, *hw_newfib;\r\nstruct fib *fib, *newfib;\r\nstruct aac_fib_context *fibctx;\r\nunsigned long flags;\r\nDECLARE_WAITQUEUE(wait, current);\r\nunsigned long next_jiffies = jiffies + HZ;\r\nunsigned long next_check_jiffies = next_jiffies;\r\nlong difference = HZ;\r\nif (dev->aif_thread)\r\nreturn -EINVAL;\r\ndev->aif_thread = 1;\r\nadd_wait_queue(&dev->queues->queue[HostNormCmdQueue].cmdready, &wait);\r\nset_current_state(TASK_INTERRUPTIBLE);\r\ndprintk ((KERN_INFO "aac_command_thread start\n"));\r\nwhile (1) {\r\nspin_lock_irqsave(dev->queues->queue[HostNormCmdQueue].lock, flags);\r\nwhile(!list_empty(&(dev->queues->queue[HostNormCmdQueue].cmdq))) {\r\nstruct list_head *entry;\r\nstruct aac_aifcmd * aifcmd;\r\nset_current_state(TASK_RUNNING);\r\nentry = dev->queues->queue[HostNormCmdQueue].cmdq.next;\r\nlist_del(entry);\r\nspin_unlock_irqrestore(dev->queues->queue[HostNormCmdQueue].lock, flags);\r\nfib = list_entry(entry, struct fib, fiblink);\r\nhw_fib = fib->hw_fib_va;\r\nmemset(fib, 0, sizeof(struct fib));\r\nfib->type = FSAFS_NTC_FIB_CONTEXT;\r\nfib->size = sizeof(struct fib);\r\nfib->hw_fib_va = hw_fib;\r\nfib->data = hw_fib->data;\r\nfib->dev = dev;\r\naifcmd = (struct aac_aifcmd *) hw_fib->data;\r\nif (aifcmd->command == cpu_to_le32(AifCmdDriverNotify)) {\r\naac_handle_aif(dev, fib);\r\n*(__le32 *)hw_fib->data = cpu_to_le32(ST_OK);\r\naac_fib_adapter_complete(fib, (u16)sizeof(u32));\r\n} else {\r\nu32 time_now, time_last;\r\nunsigned long flagv;\r\nunsigned num;\r\nstruct hw_fib ** hw_fib_pool, ** hw_fib_p;\r\nstruct fib ** fib_pool, ** fib_p;\r\nif ((aifcmd->command ==\r\ncpu_to_le32(AifCmdEventNotify)) ||\r\n(aifcmd->command ==\r\ncpu_to_le32(AifCmdJobProgress))) {\r\naac_handle_aif(dev, fib);\r\n}\r\ntime_now = jiffies/HZ;\r\nnum = le32_to_cpu(dev->init->AdapterFibsSize)\r\n/ sizeof(struct hw_fib);\r\nspin_lock_irqsave(&dev->fib_lock, flagv);\r\nentry = dev->fib_list.next;\r\nwhile (entry != &dev->fib_list) {\r\nentry = entry->next;\r\n++num;\r\n}\r\nspin_unlock_irqrestore(&dev->fib_lock, flagv);\r\nhw_fib_pool = NULL;\r\nfib_pool = NULL;\r\nif (num\r\n&& ((hw_fib_pool = kmalloc(sizeof(struct hw_fib *) * num, GFP_KERNEL)))\r\n&& ((fib_pool = kmalloc(sizeof(struct fib *) * num, GFP_KERNEL)))) {\r\nhw_fib_p = hw_fib_pool;\r\nfib_p = fib_pool;\r\nwhile (hw_fib_p < &hw_fib_pool[num]) {\r\nif (!(*(hw_fib_p++) = kmalloc(sizeof(struct hw_fib), GFP_KERNEL))) {\r\n--hw_fib_p;\r\nbreak;\r\n}\r\nif (!(*(fib_p++) = kmalloc(sizeof(struct fib), GFP_KERNEL))) {\r\nkfree(*(--hw_fib_p));\r\nbreak;\r\n}\r\n}\r\nif ((num = hw_fib_p - hw_fib_pool) == 0) {\r\nkfree(fib_pool);\r\nfib_pool = NULL;\r\nkfree(hw_fib_pool);\r\nhw_fib_pool = NULL;\r\n}\r\n} else {\r\nkfree(hw_fib_pool);\r\nhw_fib_pool = NULL;\r\n}\r\nspin_lock_irqsave(&dev->fib_lock, flagv);\r\nentry = dev->fib_list.next;\r\nhw_fib_p = hw_fib_pool;\r\nfib_p = fib_pool;\r\nwhile (entry != &dev->fib_list) {\r\nfibctx = list_entry(entry, struct aac_fib_context, next);\r\nif (fibctx->count > 20)\r\n{\r\ntime_last = fibctx->jiffies;\r\nif ((time_now - time_last) > aif_timeout) {\r\nentry = entry->next;\r\naac_close_fib_context(dev, fibctx);\r\ncontinue;\r\n}\r\n}\r\nif (hw_fib_p < &hw_fib_pool[num]) {\r\nhw_newfib = *hw_fib_p;\r\n*(hw_fib_p++) = NULL;\r\nnewfib = *fib_p;\r\n*(fib_p++) = NULL;\r\nmemcpy(hw_newfib, hw_fib, sizeof(struct hw_fib));\r\nmemcpy(newfib, fib, sizeof(struct fib));\r\nnewfib->hw_fib_va = hw_newfib;\r\nlist_add_tail(&newfib->fiblink, &fibctx->fib_list);\r\nfibctx->count++;\r\nup(&fibctx->wait_sem);\r\n} else {\r\nprintk(KERN_WARNING "aifd: didn't allocate NewFib.\n");\r\n}\r\nentry = entry->next;\r\n}\r\n*(__le32 *)hw_fib->data = cpu_to_le32(ST_OK);\r\naac_fib_adapter_complete(fib, sizeof(u32));\r\nspin_unlock_irqrestore(&dev->fib_lock, flagv);\r\nhw_fib_p = hw_fib_pool;\r\nfib_p = fib_pool;\r\nwhile (hw_fib_p < &hw_fib_pool[num]) {\r\nkfree(*hw_fib_p);\r\nkfree(*fib_p);\r\n++fib_p;\r\n++hw_fib_p;\r\n}\r\nkfree(hw_fib_pool);\r\nkfree(fib_pool);\r\n}\r\nkfree(fib);\r\nspin_lock_irqsave(dev->queues->queue[HostNormCmdQueue].lock, flags);\r\n}\r\nspin_unlock_irqrestore(dev->queues->queue[HostNormCmdQueue].lock, flags);\r\nif ((time_before(next_check_jiffies,next_jiffies))\r\n&& ((difference = next_check_jiffies - jiffies) <= 0)) {\r\nnext_check_jiffies = next_jiffies;\r\nif (aac_check_health(dev) == 0) {\r\ndifference = ((long)(unsigned)check_interval)\r\n* HZ;\r\nnext_check_jiffies = jiffies + difference;\r\n} else if (!dev->queues)\r\nbreak;\r\n}\r\nif (!time_before(next_check_jiffies,next_jiffies)\r\n&& ((difference = next_jiffies - jiffies) <= 0)) {\r\nstruct timeval now;\r\nint ret;\r\nret = aac_check_health(dev);\r\nif (!ret && !dev->queues)\r\nbreak;\r\nnext_check_jiffies = jiffies\r\n+ ((long)(unsigned)check_interval)\r\n* HZ;\r\ndo_gettimeofday(&now);\r\nif (((1000000 - (1000000 / HZ)) > now.tv_usec)\r\n&& (now.tv_usec > (1000000 / HZ)))\r\ndifference = (((1000000 - now.tv_usec) * HZ)\r\n+ 500000) / 1000000;\r\nelse if (ret == 0) {\r\nstruct fib *fibptr;\r\nif ((fibptr = aac_fib_alloc(dev))) {\r\nint status;\r\n__le32 *info;\r\naac_fib_init(fibptr);\r\ninfo = (__le32 *) fib_data(fibptr);\r\nif (now.tv_usec > 500000)\r\n++now.tv_sec;\r\n*info = cpu_to_le32(now.tv_sec);\r\nstatus = aac_fib_send(SendHostTime,\r\nfibptr,\r\nsizeof(*info),\r\nFsaNormal,\r\n1, 1,\r\nNULL,\r\nNULL);\r\nif (status >= 0)\r\naac_fib_complete(fibptr);\r\nif (status != -ERESTARTSYS)\r\naac_fib_free(fibptr);\r\n}\r\ndifference = (long)(unsigned)update_interval*HZ;\r\n} else {\r\ndifference = 10 * HZ;\r\n}\r\nnext_jiffies = jiffies + difference;\r\nif (time_before(next_check_jiffies,next_jiffies))\r\ndifference = next_check_jiffies - jiffies;\r\n}\r\nif (difference <= 0)\r\ndifference = 1;\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nschedule_timeout(difference);\r\nif (kthread_should_stop())\r\nbreak;\r\n}\r\nif (dev->queues)\r\nremove_wait_queue(&dev->queues->queue[HostNormCmdQueue].cmdready, &wait);\r\ndev->aif_thread = 0;\r\nreturn 0;\r\n}\r\nint aac_acquire_irq(struct aac_dev *dev)\r\n{\r\nint i;\r\nint j;\r\nint ret = 0;\r\nint cpu;\r\ncpu = cpumask_first(cpu_online_mask);\r\nif (!dev->sync_mode && dev->msi_enabled && dev->max_msix > 1) {\r\nfor (i = 0; i < dev->max_msix; i++) {\r\ndev->aac_msix[i].vector_no = i;\r\ndev->aac_msix[i].dev = dev;\r\nif (request_irq(dev->msixentry[i].vector,\r\ndev->a_ops.adapter_intr,\r\n0, "aacraid", &(dev->aac_msix[i]))) {\r\nprintk(KERN_ERR "%s%d: Failed to register IRQ for vector %d.\n",\r\ndev->name, dev->id, i);\r\nfor (j = 0 ; j < i ; j++)\r\nfree_irq(dev->msixentry[j].vector,\r\n&(dev->aac_msix[j]));\r\npci_disable_msix(dev->pdev);\r\nret = -1;\r\n}\r\nif (irq_set_affinity_hint(dev->msixentry[i].vector,\r\nget_cpu_mask(cpu))) {\r\nprintk(KERN_ERR "%s%d: Failed to set IRQ affinity for cpu %d\n",\r\ndev->name, dev->id, cpu);\r\n}\r\ncpu = cpumask_next(cpu, cpu_online_mask);\r\n}\r\n} else {\r\ndev->aac_msix[0].vector_no = 0;\r\ndev->aac_msix[0].dev = dev;\r\nif (request_irq(dev->pdev->irq, dev->a_ops.adapter_intr,\r\nIRQF_SHARED, "aacraid",\r\n&(dev->aac_msix[0])) < 0) {\r\nif (dev->msi)\r\npci_disable_msi(dev->pdev);\r\nprintk(KERN_ERR "%s%d: Interrupt unavailable.\n",\r\ndev->name, dev->id);\r\nret = -1;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid aac_free_irq(struct aac_dev *dev)\r\n{\r\nint i;\r\nint cpu;\r\ncpu = cpumask_first(cpu_online_mask);\r\nif (dev->pdev->device == PMC_DEVICE_S6 ||\r\ndev->pdev->device == PMC_DEVICE_S7 ||\r\ndev->pdev->device == PMC_DEVICE_S8 ||\r\ndev->pdev->device == PMC_DEVICE_S9) {\r\nif (dev->max_msix > 1) {\r\nfor (i = 0; i < dev->max_msix; i++) {\r\nif (irq_set_affinity_hint(\r\ndev->msixentry[i].vector, NULL)) {\r\nprintk(KERN_ERR "%s%d: Failed to reset IRQ affinity for cpu %d\n",\r\ndev->name, dev->id, cpu);\r\n}\r\ncpu = cpumask_next(cpu, cpu_online_mask);\r\nfree_irq(dev->msixentry[i].vector,\r\n&(dev->aac_msix[i]));\r\n}\r\n} else {\r\nfree_irq(dev->pdev->irq, &(dev->aac_msix[0]));\r\n}\r\n} else {\r\nfree_irq(dev->pdev->irq, dev);\r\n}\r\nif (dev->msi)\r\npci_disable_msi(dev->pdev);\r\nelse if (dev->max_msix > 1)\r\npci_disable_msix(dev->pdev);\r\n}
