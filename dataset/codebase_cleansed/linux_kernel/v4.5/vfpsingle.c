static void vfp_single_dump(const char *str, struct vfp_single *s)\r\n{\r\npr_debug("VFP: %s: sign=%d exponent=%d significand=%08x\n",\r\nstr, s->sign != 0, s->exponent, s->significand);\r\n}\r\nstatic void vfp_single_normalise_denormal(struct vfp_single *vs)\r\n{\r\nint bits = 31 - fls(vs->significand);\r\nvfp_single_dump("normalise_denormal: in", vs);\r\nif (bits) {\r\nvs->exponent -= bits - 1;\r\nvs->significand <<= bits;\r\n}\r\nvfp_single_dump("normalise_denormal: out", vs);\r\n}\r\nstatic u32\r\nvfp_propagate_nan(struct vfp_single *vsd, struct vfp_single *vsn,\r\nstruct vfp_single *vsm, u32 fpscr)\r\n{\r\nstruct vfp_single *nan;\r\nint tn, tm = 0;\r\ntn = vfp_single_type(vsn);\r\nif (vsm)\r\ntm = vfp_single_type(vsm);\r\nif (fpscr & FPSCR_DEFAULT_NAN)\r\nnan = &vfp_single_default_qnan;\r\nelse {\r\nif (tn == VFP_SNAN || (tm != VFP_SNAN && tn == VFP_QNAN))\r\nnan = vsn;\r\nelse\r\nnan = vsm;\r\nnan->significand |= VFP_SINGLE_SIGNIFICAND_QNAN;\r\n}\r\n*vsd = *nan;\r\nreturn tn == VFP_SNAN || tm == VFP_SNAN ? FPSCR_IOC : VFP_NAN_FLAG;\r\n}\r\nstatic u32 vfp_single_fabs(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nvfp_put_float(vfp_single_packed_abs(m), sd);\r\nreturn 0;\r\n}\r\nstatic u32 vfp_single_fcpy(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nvfp_put_float(m, sd);\r\nreturn 0;\r\n}\r\nstatic u32 vfp_single_fneg(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nvfp_put_float(vfp_single_packed_negate(m), sd);\r\nreturn 0;\r\n}\r\nu32 vfp_estimate_sqrt_significand(u32 exponent, u32 significand)\r\n{\r\nint index;\r\nu32 z, a;\r\nif ((significand & 0xc0000000) != 0x40000000) {\r\npr_warn("VFP: estimate_sqrt: invalid significand\n");\r\n}\r\na = significand << 1;\r\nindex = (a >> 27) & 15;\r\nif (exponent & 1) {\r\nz = 0x4000 + (a >> 17) - sqrt_oddadjust[index];\r\nz = ((a / z) << 14) + (z << 15);\r\na >>= 1;\r\n} else {\r\nz = 0x8000 + (a >> 17) - sqrt_evenadjust[index];\r\nz = a / z + z;\r\nz = (z >= 0x20000) ? 0xffff8000 : (z << 15);\r\nif (z <= a)\r\nreturn (s32)a >> 1;\r\n}\r\n{\r\nu64 v = (u64)a << 31;\r\ndo_div(v, z);\r\nreturn v + (z >> 1);\r\n}\r\n}\r\nstatic u32 vfp_single_fsqrt(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsm, vsd;\r\nint ret, tm;\r\nvfp_single_unpack(&vsm, m);\r\ntm = vfp_single_type(&vsm);\r\nif (tm & (VFP_NAN|VFP_INFINITY)) {\r\nstruct vfp_single *vsp = &vsd;\r\nif (tm & VFP_NAN)\r\nret = vfp_propagate_nan(vsp, &vsm, NULL, fpscr);\r\nelse if (vsm.sign == 0) {\r\nsqrt_copy:\r\nvsp = &vsm;\r\nret = 0;\r\n} else {\r\nsqrt_invalid:\r\nvsp = &vfp_single_default_qnan;\r\nret = FPSCR_IOC;\r\n}\r\nvfp_put_float(vfp_single_pack(vsp), sd);\r\nreturn ret;\r\n}\r\nif (tm & VFP_ZERO)\r\ngoto sqrt_copy;\r\nif (tm & VFP_DENORMAL)\r\nvfp_single_normalise_denormal(&vsm);\r\nif (vsm.sign)\r\ngoto sqrt_invalid;\r\nvfp_single_dump("sqrt", &vsm);\r\nvsd.sign = 0;\r\nvsd.exponent = ((vsm.exponent - 127) >> 1) + 127;\r\nvsd.significand = vfp_estimate_sqrt_significand(vsm.exponent, vsm.significand) + 2;\r\nvfp_single_dump("sqrt estimate", &vsd);\r\nif ((vsd.significand & VFP_SINGLE_LOW_BITS_MASK) <= 5) {\r\nif (vsd.significand < 2) {\r\nvsd.significand = 0xffffffff;\r\n} else {\r\nu64 term;\r\ns64 rem;\r\nvsm.significand <<= !(vsm.exponent & 1);\r\nterm = (u64)vsd.significand * vsd.significand;\r\nrem = ((u64)vsm.significand << 32) - term;\r\npr_debug("VFP: term=%016llx rem=%016llx\n", term, rem);\r\nwhile (rem < 0) {\r\nvsd.significand -= 1;\r\nrem += ((u64)vsd.significand << 1) | 1;\r\n}\r\nvsd.significand |= rem != 0;\r\n}\r\n}\r\nvsd.significand = vfp_shiftright32jamming(vsd.significand, 1);\r\nreturn vfp_single_normaliseround(sd, &vsd, fpscr, 0, "fsqrt");\r\n}\r\nstatic u32 vfp_compare(int sd, int signal_on_qnan, s32 m, u32 fpscr)\r\n{\r\ns32 d;\r\nu32 ret = 0;\r\nd = vfp_get_float(sd);\r\nif (vfp_single_packed_exponent(m) == 255 && vfp_single_packed_mantissa(m)) {\r\nret |= FPSCR_C | FPSCR_V;\r\nif (signal_on_qnan || !(vfp_single_packed_mantissa(m) & (1 << (VFP_SINGLE_MANTISSA_BITS - 1))))\r\nret |= FPSCR_IOC;\r\n}\r\nif (vfp_single_packed_exponent(d) == 255 && vfp_single_packed_mantissa(d)) {\r\nret |= FPSCR_C | FPSCR_V;\r\nif (signal_on_qnan || !(vfp_single_packed_mantissa(d) & (1 << (VFP_SINGLE_MANTISSA_BITS - 1))))\r\nret |= FPSCR_IOC;\r\n}\r\nif (ret == 0) {\r\nif (d == m || vfp_single_packed_abs(d | m) == 0) {\r\nret |= FPSCR_Z | FPSCR_C;\r\n} else if (vfp_single_packed_sign(d ^ m)) {\r\nif (vfp_single_packed_sign(d))\r\nret |= FPSCR_N;\r\nelse\r\nret |= FPSCR_C;\r\n} else if ((vfp_single_packed_sign(d) != 0) ^ (d < m)) {\r\nret |= FPSCR_N;\r\n} else if ((vfp_single_packed_sign(d) != 0) ^ (d > m)) {\r\nret |= FPSCR_C;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic u32 vfp_single_fcmp(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_compare(sd, 0, m, fpscr);\r\n}\r\nstatic u32 vfp_single_fcmpe(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_compare(sd, 1, m, fpscr);\r\n}\r\nstatic u32 vfp_single_fcmpz(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_compare(sd, 0, 0, fpscr);\r\n}\r\nstatic u32 vfp_single_fcmpez(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_compare(sd, 1, 0, fpscr);\r\n}\r\nstatic u32 vfp_single_fcvtd(int dd, int unused, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsm;\r\nstruct vfp_double vdd;\r\nint tm;\r\nu32 exceptions = 0;\r\nvfp_single_unpack(&vsm, m);\r\ntm = vfp_single_type(&vsm);\r\nif (tm == VFP_SNAN)\r\nexceptions = FPSCR_IOC;\r\nif (tm & VFP_DENORMAL)\r\nvfp_single_normalise_denormal(&vsm);\r\nvdd.sign = vsm.sign;\r\nvdd.significand = (u64)vsm.significand << 32;\r\nif (tm & (VFP_INFINITY|VFP_NAN)) {\r\nvdd.exponent = 2047;\r\nif (tm == VFP_QNAN)\r\nvdd.significand |= VFP_DOUBLE_SIGNIFICAND_QNAN;\r\ngoto pack_nan;\r\n} else if (tm & VFP_ZERO)\r\nvdd.exponent = 0;\r\nelse\r\nvdd.exponent = vsm.exponent + (1023 - 127);\r\nreturn vfp_double_normaliseround(dd, &vdd, fpscr, exceptions, "fcvtd");\r\npack_nan:\r\nvfp_put_double(vfp_double_pack(&vdd), dd);\r\nreturn exceptions;\r\n}\r\nstatic u32 vfp_single_fuito(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vs;\r\nvs.sign = 0;\r\nvs.exponent = 127 + 31 - 1;\r\nvs.significand = (u32)m;\r\nreturn vfp_single_normaliseround(sd, &vs, fpscr, 0, "fuito");\r\n}\r\nstatic u32 vfp_single_fsito(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vs;\r\nvs.sign = (m & 0x80000000) >> 16;\r\nvs.exponent = 127 + 31 - 1;\r\nvs.significand = vs.sign ? -m : m;\r\nreturn vfp_single_normaliseround(sd, &vs, fpscr, 0, "fsito");\r\n}\r\nstatic u32 vfp_single_ftoui(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsm;\r\nu32 d, exceptions = 0;\r\nint rmode = fpscr & FPSCR_RMODE_MASK;\r\nint tm;\r\nvfp_single_unpack(&vsm, m);\r\nvfp_single_dump("VSM", &vsm);\r\ntm = vfp_single_type(&vsm);\r\nif (tm & VFP_DENORMAL)\r\nexceptions |= FPSCR_IDC;\r\nif (tm & VFP_NAN)\r\nvsm.sign = 0;\r\nif (vsm.exponent >= 127 + 32) {\r\nd = vsm.sign ? 0 : 0xffffffff;\r\nexceptions = FPSCR_IOC;\r\n} else if (vsm.exponent >= 127 - 1) {\r\nint shift = 127 + 31 - vsm.exponent;\r\nu32 rem, incr = 0;\r\nd = (vsm.significand << 1) >> shift;\r\nrem = vsm.significand << (33 - shift);\r\nif (rmode == FPSCR_ROUND_NEAREST) {\r\nincr = 0x80000000;\r\nif ((d & 1) == 0)\r\nincr -= 1;\r\n} else if (rmode == FPSCR_ROUND_TOZERO) {\r\nincr = 0;\r\n} else if ((rmode == FPSCR_ROUND_PLUSINF) ^ (vsm.sign != 0)) {\r\nincr = ~0;\r\n}\r\nif ((rem + incr) < rem) {\r\nif (d < 0xffffffff)\r\nd += 1;\r\nelse\r\nexceptions |= FPSCR_IOC;\r\n}\r\nif (d && vsm.sign) {\r\nd = 0;\r\nexceptions |= FPSCR_IOC;\r\n} else if (rem)\r\nexceptions |= FPSCR_IXC;\r\n} else {\r\nd = 0;\r\nif (vsm.exponent | vsm.significand) {\r\nexceptions |= FPSCR_IXC;\r\nif (rmode == FPSCR_ROUND_PLUSINF && vsm.sign == 0)\r\nd = 1;\r\nelse if (rmode == FPSCR_ROUND_MINUSINF && vsm.sign) {\r\nd = 0;\r\nexceptions |= FPSCR_IOC;\r\n}\r\n}\r\n}\r\npr_debug("VFP: ftoui: d(s%d)=%08x exceptions=%08x\n", sd, d, exceptions);\r\nvfp_put_float(d, sd);\r\nreturn exceptions;\r\n}\r\nstatic u32 vfp_single_ftouiz(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_single_ftoui(sd, unused, m, FPSCR_ROUND_TOZERO);\r\n}\r\nstatic u32 vfp_single_ftosi(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsm;\r\nu32 d, exceptions = 0;\r\nint rmode = fpscr & FPSCR_RMODE_MASK;\r\nint tm;\r\nvfp_single_unpack(&vsm, m);\r\nvfp_single_dump("VSM", &vsm);\r\ntm = vfp_single_type(&vsm);\r\nif (vfp_single_type(&vsm) & VFP_DENORMAL)\r\nexceptions |= FPSCR_IDC;\r\nif (tm & VFP_NAN) {\r\nd = 0;\r\nexceptions |= FPSCR_IOC;\r\n} else if (vsm.exponent >= 127 + 32) {\r\nd = 0x7fffffff;\r\nif (vsm.sign)\r\nd = ~d;\r\nexceptions |= FPSCR_IOC;\r\n} else if (vsm.exponent >= 127 - 1) {\r\nint shift = 127 + 31 - vsm.exponent;\r\nu32 rem, incr = 0;\r\nd = (vsm.significand << 1) >> shift;\r\nrem = vsm.significand << (33 - shift);\r\nif (rmode == FPSCR_ROUND_NEAREST) {\r\nincr = 0x80000000;\r\nif ((d & 1) == 0)\r\nincr -= 1;\r\n} else if (rmode == FPSCR_ROUND_TOZERO) {\r\nincr = 0;\r\n} else if ((rmode == FPSCR_ROUND_PLUSINF) ^ (vsm.sign != 0)) {\r\nincr = ~0;\r\n}\r\nif ((rem + incr) < rem && d < 0xffffffff)\r\nd += 1;\r\nif (d > 0x7fffffff + (vsm.sign != 0)) {\r\nd = 0x7fffffff + (vsm.sign != 0);\r\nexceptions |= FPSCR_IOC;\r\n} else if (rem)\r\nexceptions |= FPSCR_IXC;\r\nif (vsm.sign)\r\nd = -d;\r\n} else {\r\nd = 0;\r\nif (vsm.exponent | vsm.significand) {\r\nexceptions |= FPSCR_IXC;\r\nif (rmode == FPSCR_ROUND_PLUSINF && vsm.sign == 0)\r\nd = 1;\r\nelse if (rmode == FPSCR_ROUND_MINUSINF && vsm.sign)\r\nd = -1;\r\n}\r\n}\r\npr_debug("VFP: ftosi: d(s%d)=%08x exceptions=%08x\n", sd, d, exceptions);\r\nvfp_put_float((s32)d, sd);\r\nreturn exceptions;\r\n}\r\nstatic u32 vfp_single_ftosiz(int sd, int unused, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_single_ftosi(sd, unused, m, FPSCR_ROUND_TOZERO);\r\n}\r\nstatic u32\r\nvfp_single_fadd_nonnumber(struct vfp_single *vsd, struct vfp_single *vsn,\r\nstruct vfp_single *vsm, u32 fpscr)\r\n{\r\nstruct vfp_single *vsp;\r\nu32 exceptions = 0;\r\nint tn, tm;\r\ntn = vfp_single_type(vsn);\r\ntm = vfp_single_type(vsm);\r\nif (tn & tm & VFP_INFINITY) {\r\nif (vsn->sign ^ vsm->sign) {\r\nexceptions = FPSCR_IOC;\r\nvsp = &vfp_single_default_qnan;\r\n} else {\r\nvsp = vsn;\r\n}\r\n} else if (tn & VFP_INFINITY && tm & VFP_NUMBER) {\r\nvsp = vsn;\r\n} else {\r\nreturn vfp_propagate_nan(vsd, vsn, vsm, fpscr);\r\n}\r\n*vsd = *vsp;\r\nreturn exceptions;\r\n}\r\nstatic u32\r\nvfp_single_add(struct vfp_single *vsd, struct vfp_single *vsn,\r\nstruct vfp_single *vsm, u32 fpscr)\r\n{\r\nu32 exp_diff, m_sig;\r\nif (vsn->significand & 0x80000000 ||\r\nvsm->significand & 0x80000000) {\r\npr_info("VFP: bad FP values in %s\n", __func__);\r\nvfp_single_dump("VSN", vsn);\r\nvfp_single_dump("VSM", vsm);\r\n}\r\nif (vsn->exponent < vsm->exponent) {\r\nstruct vfp_single *t = vsn;\r\nvsn = vsm;\r\nvsm = t;\r\n}\r\nif (vsn->exponent == 255)\r\nreturn vfp_single_fadd_nonnumber(vsd, vsn, vsm, fpscr);\r\n*vsd = *vsn;\r\nexp_diff = vsn->exponent - vsm->exponent;\r\nm_sig = vfp_shiftright32jamming(vsm->significand, exp_diff);\r\nif (vsn->sign ^ vsm->sign) {\r\nm_sig = vsn->significand - m_sig;\r\nif ((s32)m_sig < 0) {\r\nvsd->sign = vfp_sign_negate(vsd->sign);\r\nm_sig = -m_sig;\r\n} else if (m_sig == 0) {\r\nvsd->sign = (fpscr & FPSCR_RMODE_MASK) ==\r\nFPSCR_ROUND_MINUSINF ? 0x8000 : 0;\r\n}\r\n} else {\r\nm_sig = vsn->significand + m_sig;\r\n}\r\nvsd->significand = m_sig;\r\nreturn 0;\r\n}\r\nstatic u32\r\nvfp_single_multiply(struct vfp_single *vsd, struct vfp_single *vsn, struct vfp_single *vsm, u32 fpscr)\r\n{\r\nvfp_single_dump("VSN", vsn);\r\nvfp_single_dump("VSM", vsm);\r\nif (vsn->exponent < vsm->exponent) {\r\nstruct vfp_single *t = vsn;\r\nvsn = vsm;\r\nvsm = t;\r\npr_debug("VFP: swapping M <-> N\n");\r\n}\r\nvsd->sign = vsn->sign ^ vsm->sign;\r\nif (vsn->exponent == 255) {\r\nif (vsn->significand || (vsm->exponent == 255 && vsm->significand))\r\nreturn vfp_propagate_nan(vsd, vsn, vsm, fpscr);\r\nif ((vsm->exponent | vsm->significand) == 0) {\r\n*vsd = vfp_single_default_qnan;\r\nreturn FPSCR_IOC;\r\n}\r\nvsd->exponent = vsn->exponent;\r\nvsd->significand = 0;\r\nreturn 0;\r\n}\r\nif ((vsm->exponent | vsm->significand) == 0) {\r\nvsd->exponent = 0;\r\nvsd->significand = 0;\r\nreturn 0;\r\n}\r\nvsd->exponent = vsn->exponent + vsm->exponent - 127 + 2;\r\nvsd->significand = vfp_hi64to32jamming((u64)vsn->significand * vsm->significand);\r\nvfp_single_dump("VSD", vsd);\r\nreturn 0;\r\n}\r\nstatic u32\r\nvfp_single_multiply_accumulate(int sd, int sn, s32 m, u32 fpscr, u32 negate, char *func)\r\n{\r\nstruct vfp_single vsd, vsp, vsn, vsm;\r\nu32 exceptions;\r\ns32 v;\r\nv = vfp_get_float(sn);\r\npr_debug("VFP: s%u = %08x\n", sn, v);\r\nvfp_single_unpack(&vsn, v);\r\nif (vsn.exponent == 0 && vsn.significand)\r\nvfp_single_normalise_denormal(&vsn);\r\nvfp_single_unpack(&vsm, m);\r\nif (vsm.exponent == 0 && vsm.significand)\r\nvfp_single_normalise_denormal(&vsm);\r\nexceptions = vfp_single_multiply(&vsp, &vsn, &vsm, fpscr);\r\nif (negate & NEG_MULTIPLY)\r\nvsp.sign = vfp_sign_negate(vsp.sign);\r\nv = vfp_get_float(sd);\r\npr_debug("VFP: s%u = %08x\n", sd, v);\r\nvfp_single_unpack(&vsn, v);\r\nif (vsn.exponent == 0 && vsn.significand)\r\nvfp_single_normalise_denormal(&vsn);\r\nif (negate & NEG_SUBTRACT)\r\nvsn.sign = vfp_sign_negate(vsn.sign);\r\nexceptions |= vfp_single_add(&vsd, &vsn, &vsp, fpscr);\r\nreturn vfp_single_normaliseround(sd, &vsd, fpscr, exceptions, func);\r\n}\r\nstatic u32 vfp_single_fmac(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_single_multiply_accumulate(sd, sn, m, fpscr, 0, "fmac");\r\n}\r\nstatic u32 vfp_single_fnmac(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_single_multiply_accumulate(sd, sn, m, fpscr, NEG_MULTIPLY, "fnmac");\r\n}\r\nstatic u32 vfp_single_fmsc(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_single_multiply_accumulate(sd, sn, m, fpscr, NEG_SUBTRACT, "fmsc");\r\n}\r\nstatic u32 vfp_single_fnmsc(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_single_multiply_accumulate(sd, sn, m, fpscr, NEG_SUBTRACT | NEG_MULTIPLY, "fnmsc");\r\n}\r\nstatic u32 vfp_single_fmul(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsd, vsn, vsm;\r\nu32 exceptions;\r\ns32 n = vfp_get_float(sn);\r\npr_debug("VFP: s%u = %08x\n", sn, n);\r\nvfp_single_unpack(&vsn, n);\r\nif (vsn.exponent == 0 && vsn.significand)\r\nvfp_single_normalise_denormal(&vsn);\r\nvfp_single_unpack(&vsm, m);\r\nif (vsm.exponent == 0 && vsm.significand)\r\nvfp_single_normalise_denormal(&vsm);\r\nexceptions = vfp_single_multiply(&vsd, &vsn, &vsm, fpscr);\r\nreturn vfp_single_normaliseround(sd, &vsd, fpscr, exceptions, "fmul");\r\n}\r\nstatic u32 vfp_single_fnmul(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsd, vsn, vsm;\r\nu32 exceptions;\r\ns32 n = vfp_get_float(sn);\r\npr_debug("VFP: s%u = %08x\n", sn, n);\r\nvfp_single_unpack(&vsn, n);\r\nif (vsn.exponent == 0 && vsn.significand)\r\nvfp_single_normalise_denormal(&vsn);\r\nvfp_single_unpack(&vsm, m);\r\nif (vsm.exponent == 0 && vsm.significand)\r\nvfp_single_normalise_denormal(&vsm);\r\nexceptions = vfp_single_multiply(&vsd, &vsn, &vsm, fpscr);\r\nvsd.sign = vfp_sign_negate(vsd.sign);\r\nreturn vfp_single_normaliseround(sd, &vsd, fpscr, exceptions, "fnmul");\r\n}\r\nstatic u32 vfp_single_fadd(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsd, vsn, vsm;\r\nu32 exceptions;\r\ns32 n = vfp_get_float(sn);\r\npr_debug("VFP: s%u = %08x\n", sn, n);\r\nvfp_single_unpack(&vsn, n);\r\nif (vsn.exponent == 0 && vsn.significand)\r\nvfp_single_normalise_denormal(&vsn);\r\nvfp_single_unpack(&vsm, m);\r\nif (vsm.exponent == 0 && vsm.significand)\r\nvfp_single_normalise_denormal(&vsm);\r\nexceptions = vfp_single_add(&vsd, &vsn, &vsm, fpscr);\r\nreturn vfp_single_normaliseround(sd, &vsd, fpscr, exceptions, "fadd");\r\n}\r\nstatic u32 vfp_single_fsub(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nreturn vfp_single_fadd(sd, sn, vfp_single_packed_negate(m), fpscr);\r\n}\r\nstatic u32 vfp_single_fdiv(int sd, int sn, s32 m, u32 fpscr)\r\n{\r\nstruct vfp_single vsd, vsn, vsm;\r\nu32 exceptions = 0;\r\ns32 n = vfp_get_float(sn);\r\nint tm, tn;\r\npr_debug("VFP: s%u = %08x\n", sn, n);\r\nvfp_single_unpack(&vsn, n);\r\nvfp_single_unpack(&vsm, m);\r\nvsd.sign = vsn.sign ^ vsm.sign;\r\ntn = vfp_single_type(&vsn);\r\ntm = vfp_single_type(&vsm);\r\nif (tn & VFP_NAN)\r\ngoto vsn_nan;\r\nif (tm & VFP_NAN)\r\ngoto vsm_nan;\r\nif (tm & tn & (VFP_INFINITY|VFP_ZERO))\r\ngoto invalid;\r\nif (tn & VFP_INFINITY)\r\ngoto infinity;\r\nif (tm & VFP_ZERO)\r\ngoto divzero;\r\nif (tm & VFP_INFINITY || tn & VFP_ZERO)\r\ngoto zero;\r\nif (tn & VFP_DENORMAL)\r\nvfp_single_normalise_denormal(&vsn);\r\nif (tm & VFP_DENORMAL)\r\nvfp_single_normalise_denormal(&vsm);\r\nvsd.exponent = vsn.exponent - vsm.exponent + 127 - 1;\r\nvsm.significand <<= 1;\r\nif (vsm.significand <= (2 * vsn.significand)) {\r\nvsn.significand >>= 1;\r\nvsd.exponent++;\r\n}\r\n{\r\nu64 significand = (u64)vsn.significand << 32;\r\ndo_div(significand, vsm.significand);\r\nvsd.significand = significand;\r\n}\r\nif ((vsd.significand & 0x3f) == 0)\r\nvsd.significand |= ((u64)vsm.significand * vsd.significand != (u64)vsn.significand << 32);\r\nreturn vfp_single_normaliseround(sd, &vsd, fpscr, 0, "fdiv");\r\nvsn_nan:\r\nexceptions = vfp_propagate_nan(&vsd, &vsn, &vsm, fpscr);\r\npack:\r\nvfp_put_float(vfp_single_pack(&vsd), sd);\r\nreturn exceptions;\r\nvsm_nan:\r\nexceptions = vfp_propagate_nan(&vsd, &vsm, &vsn, fpscr);\r\ngoto pack;\r\nzero:\r\nvsd.exponent = 0;\r\nvsd.significand = 0;\r\ngoto pack;\r\ndivzero:\r\nexceptions = FPSCR_DZC;\r\ninfinity:\r\nvsd.exponent = 255;\r\nvsd.significand = 0;\r\ngoto pack;\r\ninvalid:\r\nvfp_put_float(vfp_single_pack(&vfp_single_default_qnan), sd);\r\nreturn FPSCR_IOC;\r\n}\r\nu32 vfp_single_cpdo(u32 inst, u32 fpscr)\r\n{\r\nu32 op = inst & FOP_MASK;\r\nu32 exceptions = 0;\r\nunsigned int dest;\r\nunsigned int sn = vfp_get_sn(inst);\r\nunsigned int sm = vfp_get_sm(inst);\r\nunsigned int vecitr, veclen, vecstride;\r\nstruct op *fop;\r\nvecstride = 1 + ((fpscr & FPSCR_STRIDE_MASK) == FPSCR_STRIDE_MASK);\r\nfop = (op == FOP_EXT) ? &fops_ext[FEXT_TO_IDX(inst)] : &fops[FOP_TO_IDX(op)];\r\nif (fop->flags & OP_DD)\r\ndest = vfp_get_dd(inst);\r\nelse\r\ndest = vfp_get_sd(inst);\r\nif ((fop->flags & OP_SCALAR) || FREG_BANK(dest) == 0)\r\nveclen = 0;\r\nelse\r\nveclen = fpscr & FPSCR_LENGTH_MASK;\r\npr_debug("VFP: vecstride=%u veclen=%u\n", vecstride,\r\n(veclen >> FPSCR_LENGTH_BIT) + 1);\r\nif (!fop->fn)\r\ngoto invalid;\r\nfor (vecitr = 0; vecitr <= veclen; vecitr += 1 << FPSCR_LENGTH_BIT) {\r\ns32 m = vfp_get_float(sm);\r\nu32 except;\r\nchar type;\r\ntype = fop->flags & OP_DD ? 'd' : 's';\r\nif (op == FOP_EXT)\r\npr_debug("VFP: itr%d (%c%u) = op[%u] (s%u=%08x)\n",\r\nvecitr >> FPSCR_LENGTH_BIT, type, dest, sn,\r\nsm, m);\r\nelse\r\npr_debug("VFP: itr%d (%c%u) = (s%u) op[%u] (s%u=%08x)\n",\r\nvecitr >> FPSCR_LENGTH_BIT, type, dest, sn,\r\nFOP_TO_IDX(op), sm, m);\r\nexcept = fop->fn(dest, sn, m, fpscr);\r\npr_debug("VFP: itr%d: exceptions=%08x\n",\r\nvecitr >> FPSCR_LENGTH_BIT, except);\r\nexceptions |= except;\r\ndest = FREG_BANK(dest) + ((FREG_IDX(dest) + vecstride) & 7);\r\nsn = FREG_BANK(sn) + ((FREG_IDX(sn) + vecstride) & 7);\r\nif (FREG_BANK(sm) != 0)\r\nsm = FREG_BANK(sm) + ((FREG_IDX(sm) + vecstride) & 7);\r\n}\r\nreturn exceptions;\r\ninvalid:\r\nreturn (u32)-1;\r\n}
