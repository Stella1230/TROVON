void __serpent_crypt_ctr(void *ctx, u128 *dst, const u128 *src, le128 *iv)\r\n{\r\nbe128 ctrblk;\r\nle128_to_be128(&ctrblk, iv);\r\nle128_inc(iv);\r\n__serpent_encrypt(ctx, (u8 *)&ctrblk, (u8 *)&ctrblk);\r\nu128_xor(dst, src, (u128 *)&ctrblk);\r\n}\r\nvoid serpent_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)\r\n{\r\nglue_xts_crypt_128bit_one(ctx, dst, src, iv,\r\nGLUE_FUNC_CAST(__serpent_encrypt));\r\n}\r\nvoid serpent_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)\r\n{\r\nglue_xts_crypt_128bit_one(ctx, dst, src, iv,\r\nGLUE_FUNC_CAST(__serpent_decrypt));\r\n}\r\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nreturn glue_ecb_crypt_128bit(&serpent_enc, desc, dst, src, nbytes);\r\n}\r\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nreturn glue_ecb_crypt_128bit(&serpent_dec, desc, dst, src, nbytes);\r\n}\r\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nreturn glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__serpent_encrypt), desc,\r\ndst, src, nbytes);\r\n}\r\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nreturn glue_cbc_decrypt_128bit(&serpent_dec_cbc, desc, dst, src,\r\nnbytes);\r\n}\r\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nreturn glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);\r\n}\r\nstatic inline bool serpent_fpu_begin(bool fpu_enabled, unsigned int nbytes)\r\n{\r\nreturn glue_fpu_begin(SERPENT_BLOCK_SIZE, SERPENT_PARALLEL_BLOCKS,\r\nNULL, fpu_enabled, nbytes);\r\n}\r\nstatic inline void serpent_fpu_end(bool fpu_enabled)\r\n{\r\nglue_fpu_end(fpu_enabled);\r\n}\r\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\r\n{\r\nconst unsigned int bsize = SERPENT_BLOCK_SIZE;\r\nstruct crypt_priv *ctx = priv;\r\nint i;\r\nctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\r\nif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\r\nserpent_ecb_enc_8way_avx(ctx->ctx, srcdst, srcdst);\r\nreturn;\r\n}\r\nfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\r\n__serpent_encrypt(ctx->ctx, srcdst, srcdst);\r\n}\r\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\r\n{\r\nconst unsigned int bsize = SERPENT_BLOCK_SIZE;\r\nstruct crypt_priv *ctx = priv;\r\nint i;\r\nctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);\r\nif (nbytes == bsize * SERPENT_PARALLEL_BLOCKS) {\r\nserpent_ecb_dec_8way_avx(ctx->ctx, srcdst, srcdst);\r\nreturn;\r\n}\r\nfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\r\n__serpent_decrypt(ctx->ctx, srcdst, srcdst);\r\n}\r\nint lrw_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\r\nint err;\r\nerr = __serpent_setkey(&ctx->serpent_ctx, key, keylen -\r\nSERPENT_BLOCK_SIZE);\r\nif (err)\r\nreturn err;\r\nreturn lrw_init_table(&ctx->lrw_table, key + keylen -\r\nSERPENT_BLOCK_SIZE);\r\n}\r\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nbe128 buf[SERPENT_PARALLEL_BLOCKS];\r\nstruct crypt_priv crypt_ctx = {\r\n.ctx = &ctx->serpent_ctx,\r\n.fpu_enabled = false,\r\n};\r\nstruct lrw_crypt_req req = {\r\n.tbuf = buf,\r\n.tbuflen = sizeof(buf),\r\n.table_ctx = &ctx->lrw_table,\r\n.crypt_ctx = &crypt_ctx,\r\n.crypt_fn = encrypt_callback,\r\n};\r\nint ret;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nret = lrw_crypt(desc, dst, src, nbytes, &req);\r\nserpent_fpu_end(crypt_ctx.fpu_enabled);\r\nreturn ret;\r\n}\r\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct serpent_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nbe128 buf[SERPENT_PARALLEL_BLOCKS];\r\nstruct crypt_priv crypt_ctx = {\r\n.ctx = &ctx->serpent_ctx,\r\n.fpu_enabled = false,\r\n};\r\nstruct lrw_crypt_req req = {\r\n.tbuf = buf,\r\n.tbuflen = sizeof(buf),\r\n.table_ctx = &ctx->lrw_table,\r\n.crypt_ctx = &crypt_ctx,\r\n.crypt_fn = decrypt_callback,\r\n};\r\nint ret;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nret = lrw_crypt(desc, dst, src, nbytes, &req);\r\nserpent_fpu_end(crypt_ctx.fpu_enabled);\r\nreturn ret;\r\n}\r\nvoid lrw_serpent_exit_tfm(struct crypto_tfm *tfm)\r\n{\r\nstruct serpent_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\r\nlrw_free_table(&ctx->lrw_table);\r\n}\r\nint xts_serpent_setkey(struct crypto_tfm *tfm, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nstruct serpent_xts_ctx *ctx = crypto_tfm_ctx(tfm);\r\nu32 *flags = &tfm->crt_flags;\r\nint err;\r\nif (keylen % 2) {\r\n*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nerr = __serpent_setkey(&ctx->crypt_ctx, key, keylen / 2);\r\nif (err)\r\nreturn err;\r\nreturn __serpent_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2);\r\n}\r\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nreturn glue_xts_crypt_128bit(&serpent_enc_xts, desc, dst, src, nbytes,\r\nXTS_TWEAK_CAST(__serpent_encrypt),\r\n&ctx->tweak_ctx, &ctx->crypt_ctx);\r\n}\r\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct serpent_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nreturn glue_xts_crypt_128bit(&serpent_dec_xts, desc, dst, src, nbytes,\r\nXTS_TWEAK_CAST(__serpent_encrypt),\r\n&ctx->tweak_ctx, &ctx->crypt_ctx);\r\n}\r\nstatic int __init serpent_init(void)\r\n{\r\nconst char *feature_name;\r\nif (!cpu_has_xfeatures(XFEATURE_MASK_SSE | XFEATURE_MASK_YMM,\r\n&feature_name)) {\r\npr_info("CPU feature '%s' is not supported.\n", feature_name);\r\nreturn -ENODEV;\r\n}\r\nreturn crypto_register_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\r\n}\r\nstatic void __exit serpent_exit(void)\r\n{\r\ncrypto_unregister_algs(serpent_algs, ARRAY_SIZE(serpent_algs));\r\n}
