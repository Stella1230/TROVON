static int queue_empty(struct ddcb_queue *queue)\r\n{\r\nreturn queue->ddcb_next == queue->ddcb_act;\r\n}\r\nstatic int queue_enqueued_ddcbs(struct ddcb_queue *queue)\r\n{\r\nif (queue->ddcb_next >= queue->ddcb_act)\r\nreturn queue->ddcb_next - queue->ddcb_act;\r\nreturn queue->ddcb_max - (queue->ddcb_act - queue->ddcb_next);\r\n}\r\nstatic int queue_free_ddcbs(struct ddcb_queue *queue)\r\n{\r\nint free_ddcbs = queue->ddcb_max - queue_enqueued_ddcbs(queue) - 1;\r\nif (WARN_ON_ONCE(free_ddcbs < 0)) {\r\nreturn 0;\r\n}\r\nreturn free_ddcbs;\r\n}\r\nstatic inline void ddcb_mark_tapped(struct ddcb *pddcb)\r\n{\r\npddcb->priv[7] = 0xbb;\r\n}\r\nstatic inline void ddcb_mark_appended(struct ddcb *pddcb)\r\n{\r\npddcb->priv[7] = 0xaa;\r\n}\r\nstatic inline void ddcb_mark_cleared(struct ddcb *pddcb)\r\n{\r\npddcb->priv[6] = 0xcc;\r\n}\r\nstatic inline void ddcb_mark_finished(struct ddcb *pddcb)\r\n{\r\npddcb->priv[6] = 0xff;\r\n}\r\nstatic inline void ddcb_mark_unused(struct ddcb *pddcb)\r\n{\r\npddcb->priv_64 = cpu_to_be64(0);\r\n}\r\nstatic inline u16 genwqe_crc16(const u8 *buff, size_t len, u16 init)\r\n{\r\nreturn crc_itu_t(init, buff, len);\r\n}\r\nstatic void print_ddcb_info(struct genwqe_dev *cd, struct ddcb_queue *queue)\r\n{\r\nint i;\r\nstruct ddcb *pddcb;\r\nunsigned long flags;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nspin_lock_irqsave(&cd->print_lock, flags);\r\ndev_info(&pci_dev->dev,\r\n"DDCB list for card #%d (ddcb_act=%d / ddcb_next=%d):\n",\r\ncd->card_idx, queue->ddcb_act, queue->ddcb_next);\r\npddcb = queue->ddcb_vaddr;\r\nfor (i = 0; i < queue->ddcb_max; i++) {\r\ndev_err(&pci_dev->dev,\r\n" %c %-3d: RETC=%03x SEQ=%04x HSI=%02X SHI=%02x PRIV=%06llx CMD=%03x\n",\r\ni == queue->ddcb_act ? '>' : ' ',\r\ni,\r\nbe16_to_cpu(pddcb->retc_16),\r\nbe16_to_cpu(pddcb->seqnum_16),\r\npddcb->hsi,\r\npddcb->shi,\r\nbe64_to_cpu(pddcb->priv_64),\r\npddcb->cmd);\r\npddcb++;\r\n}\r\nspin_unlock_irqrestore(&cd->print_lock, flags);\r\n}\r\nstruct genwqe_ddcb_cmd *ddcb_requ_alloc(void)\r\n{\r\nstruct ddcb_requ *req;\r\nreq = kzalloc(sizeof(*req), GFP_KERNEL);\r\nif (!req)\r\nreturn NULL;\r\nreturn &req->cmd;\r\n}\r\nvoid ddcb_requ_free(struct genwqe_ddcb_cmd *cmd)\r\n{\r\nstruct ddcb_requ *req = container_of(cmd, struct ddcb_requ, cmd);\r\nkfree(req);\r\n}\r\nstatic inline enum genwqe_requ_state ddcb_requ_get_state(struct ddcb_requ *req)\r\n{\r\nreturn req->req_state;\r\n}\r\nstatic inline void ddcb_requ_set_state(struct ddcb_requ *req,\r\nenum genwqe_requ_state new_state)\r\n{\r\nreq->req_state = new_state;\r\n}\r\nstatic inline int ddcb_requ_collect_debug_data(struct ddcb_requ *req)\r\n{\r\nreturn req->cmd.ddata_addr != 0x0;\r\n}\r\nstatic int ddcb_requ_finished(struct genwqe_dev *cd, struct ddcb_requ *req)\r\n{\r\nreturn (ddcb_requ_get_state(req) == GENWQE_REQU_FINISHED) ||\r\n(cd->card_state != GENWQE_CARD_USED);\r\n}\r\nstatic int enqueue_ddcb(struct genwqe_dev *cd, struct ddcb_queue *queue,\r\nstruct ddcb *pddcb, int ddcb_no)\r\n{\r\nunsigned int try;\r\nint prev_no;\r\nstruct ddcb *prev_ddcb;\r\n__be32 old, new, icrc_hsi_shi;\r\nu64 num;\r\nddcb_mark_unused(pddcb);\r\nprev_no = (ddcb_no == 0) ? queue->ddcb_max - 1 : ddcb_no - 1;\r\nprev_ddcb = &queue->ddcb_vaddr[prev_no];\r\nddcb_mark_appended(pddcb);\r\nfor (try = 0; try < 2; try++) {\r\nold = prev_ddcb->icrc_hsi_shi_32;\r\nif ((old & DDCB_COMPLETED_BE32) != 0x00000000)\r\nbreak;\r\nnew = (old | DDCB_NEXT_BE32);\r\nwmb();\r\nicrc_hsi_shi = cmpxchg(&prev_ddcb->icrc_hsi_shi_32, old, new);\r\nif (icrc_hsi_shi == old)\r\nreturn RET_DDCB_APPENDED;\r\n}\r\nddcb_mark_tapped(pddcb);\r\nnum = (u64)ddcb_no << 8;\r\nwmb();\r\n__genwqe_writeq(cd, queue->IO_QUEUE_OFFSET, num);\r\nreturn RET_DDCB_TAPPED;\r\n}\r\nstatic void copy_ddcb_results(struct ddcb_requ *req, int ddcb_no)\r\n{\r\nstruct ddcb_queue *queue = req->queue;\r\nstruct ddcb *pddcb = &queue->ddcb_vaddr[req->num];\r\nmemcpy(&req->cmd.asv[0], &pddcb->asv[0], DDCB_ASV_LENGTH);\r\nreq->cmd.vcrc = be16_to_cpu(pddcb->vcrc_16);\r\nreq->cmd.deque_ts = be64_to_cpu(pddcb->deque_ts_64);\r\nreq->cmd.cmplt_ts = be64_to_cpu(pddcb->cmplt_ts_64);\r\nreq->cmd.attn = be16_to_cpu(pddcb->attn_16);\r\nreq->cmd.progress = be32_to_cpu(pddcb->progress_32);\r\nreq->cmd.retc = be16_to_cpu(pddcb->retc_16);\r\nif (ddcb_requ_collect_debug_data(req)) {\r\nint prev_no = (ddcb_no == 0) ?\r\nqueue->ddcb_max - 1 : ddcb_no - 1;\r\nstruct ddcb *prev_pddcb = &queue->ddcb_vaddr[prev_no];\r\nmemcpy(&req->debug_data.ddcb_finished, pddcb,\r\nsizeof(req->debug_data.ddcb_finished));\r\nmemcpy(&req->debug_data.ddcb_prev, prev_pddcb,\r\nsizeof(req->debug_data.ddcb_prev));\r\n}\r\n}\r\nstatic int genwqe_check_ddcb_queue(struct genwqe_dev *cd,\r\nstruct ddcb_queue *queue)\r\n{\r\nunsigned long flags;\r\nint ddcbs_finished = 0;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nspin_lock_irqsave(&queue->ddcb_lock, flags);\r\nwhile (!queue_empty(queue) && (ddcbs_finished < queue->ddcb_max)) {\r\nstruct ddcb *pddcb;\r\nstruct ddcb_requ *req;\r\nu16 vcrc, vcrc_16, retc_16;\r\npddcb = &queue->ddcb_vaddr[queue->ddcb_act];\r\nif ((pddcb->icrc_hsi_shi_32 & DDCB_COMPLETED_BE32) ==\r\n0x00000000)\r\ngoto go_home;\r\nwmb();\r\nreq = queue->ddcb_req[queue->ddcb_act];\r\nif (req == NULL) {\r\ngoto pick_next_one;\r\n}\r\nretc_16 = be16_to_cpu(pddcb->retc_16);\r\nif ((pddcb->hsi == 0x44) && (retc_16 <= 0x101)) {\r\nu64 errcnts, status;\r\nu64 ddcb_offs = (u64)pddcb - (u64)queue->ddcb_vaddr;\r\nerrcnts = __genwqe_readq(cd, queue->IO_QUEUE_ERRCNTS);\r\nstatus = __genwqe_readq(cd, queue->IO_QUEUE_STATUS);\r\ndev_err(&pci_dev->dev,\r\n"[%s] SEQN=%04x HSI=%02x RETC=%03x Q_ERRCNTS=%016llx Q_STATUS=%016llx DDCB_DMA_ADDR=%016llx\n",\r\n__func__, be16_to_cpu(pddcb->seqnum_16),\r\npddcb->hsi, retc_16, errcnts, status,\r\nqueue->ddcb_daddr + ddcb_offs);\r\n}\r\ncopy_ddcb_results(req, queue->ddcb_act);\r\nqueue->ddcb_req[queue->ddcb_act] = NULL;\r\ndev_dbg(&pci_dev->dev, "FINISHED DDCB#%d\n", req->num);\r\ngenwqe_hexdump(pci_dev, pddcb, sizeof(*pddcb));\r\nddcb_mark_finished(pddcb);\r\nvcrc = genwqe_crc16(pddcb->asv,\r\nVCRC_LENGTH(req->cmd.asv_length),\r\n0xffff);\r\nvcrc_16 = be16_to_cpu(pddcb->vcrc_16);\r\nif (vcrc != vcrc_16) {\r\nprintk_ratelimited(KERN_ERR\r\n"%s %s: err: wrong VCRC pre=%02x vcrc_len=%d bytes vcrc_data=%04x is not vcrc_card=%04x\n",\r\nGENWQE_DEVNAME, dev_name(&pci_dev->dev),\r\npddcb->pre, VCRC_LENGTH(req->cmd.asv_length),\r\nvcrc, vcrc_16);\r\n}\r\nddcb_requ_set_state(req, GENWQE_REQU_FINISHED);\r\nqueue->ddcbs_completed++;\r\nqueue->ddcbs_in_flight--;\r\nwake_up_interruptible(&queue->ddcb_waitqs[queue->ddcb_act]);\r\nwake_up_interruptible(&queue->busy_waitq);\r\npick_next_one:\r\nqueue->ddcb_act = (queue->ddcb_act + 1) % queue->ddcb_max;\r\nddcbs_finished++;\r\n}\r\ngo_home:\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nreturn ddcbs_finished;\r\n}\r\nint __genwqe_wait_ddcb(struct genwqe_dev *cd, struct ddcb_requ *req)\r\n{\r\nint rc;\r\nunsigned int ddcb_no;\r\nstruct ddcb_queue *queue;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif (req == NULL)\r\nreturn -EINVAL;\r\nqueue = req->queue;\r\nif (queue == NULL)\r\nreturn -EINVAL;\r\nddcb_no = req->num;\r\nif (ddcb_no >= queue->ddcb_max)\r\nreturn -EINVAL;\r\nrc = wait_event_interruptible_timeout(queue->ddcb_waitqs[ddcb_no],\r\nddcb_requ_finished(cd, req),\r\ngenwqe_ddcb_software_timeout * HZ);\r\nif (rc == 0) {\r\nstruct ddcb_queue *queue = req->queue;\r\nstruct ddcb *pddcb;\r\ngenwqe_check_ddcb_queue(cd, req->queue);\r\nif (ddcb_requ_finished(cd, req))\r\nreturn rc;\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: DDCB#%d timeout rc=%d state=%d req @ %p\n",\r\n__func__, req->num, rc, ddcb_requ_get_state(req),\r\nreq);\r\ndev_err(&pci_dev->dev,\r\n"[%s] IO_QUEUE_STATUS=0x%016llx\n", __func__,\r\n__genwqe_readq(cd, queue->IO_QUEUE_STATUS));\r\npddcb = &queue->ddcb_vaddr[req->num];\r\ngenwqe_hexdump(pci_dev, pddcb, sizeof(*pddcb));\r\nprint_ddcb_info(cd, req->queue);\r\nreturn -ETIMEDOUT;\r\n} else if (rc == -ERESTARTSYS) {\r\nreturn rc;\r\n} else if (rc < 0) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: DDCB#%d unknown result (rc=%d) %d!\n",\r\n__func__, req->num, rc, ddcb_requ_get_state(req));\r\nreturn -EINVAL;\r\n}\r\nif (cd->card_state != GENWQE_CARD_USED) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: DDCB#%d forced to stop (rc=%d)\n",\r\n__func__, req->num, rc);\r\nreturn -EIO;\r\n}\r\nreturn rc;\r\n}\r\nstatic struct ddcb *get_next_ddcb(struct genwqe_dev *cd,\r\nstruct ddcb_queue *queue,\r\nint *num)\r\n{\r\nu64 *pu64;\r\nstruct ddcb *pddcb;\r\nif (queue_free_ddcbs(queue) == 0)\r\nreturn NULL;\r\npddcb = &queue->ddcb_vaddr[queue->ddcb_next];\r\nif ((pddcb->icrc_hsi_shi_32 & DDCB_COMPLETED_BE32) == 0x00000000)\r\nreturn NULL;\r\n*num = queue->ddcb_next;\r\nqueue->ddcb_next = (queue->ddcb_next + 1) % queue->ddcb_max;\r\npu64 = (u64 *)pddcb;\r\npu64[0] = 0ULL;\r\npu64[1] = 0ULL;\r\npu64[0x80/8] = 0ULL;\r\npu64[0x88/8] = 0ULL;\r\npu64[0x90/8] = 0ULL;\r\npu64[0x98/8] = 0ULL;\r\npu64[0xd0/8] = 0ULL;\r\npddcb->pre = DDCB_PRESET_PRE;\r\npddcb->seqnum_16 = cpu_to_be16(queue->ddcb_seq++);\r\nreturn pddcb;\r\n}\r\nint __genwqe_purge_ddcb(struct genwqe_dev *cd, struct ddcb_requ *req)\r\n{\r\nstruct ddcb *pddcb = NULL;\r\nunsigned int t;\r\nunsigned long flags;\r\nstruct ddcb_queue *queue = req->queue;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nu64 queue_status;\r\n__be32 icrc_hsi_shi = 0x0000;\r\n__be32 old, new;\r\nif (genwqe_ddcb_software_timeout <= 0) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: software timeout is not set!\n", __func__);\r\nreturn -EFAULT;\r\n}\r\npddcb = &queue->ddcb_vaddr[req->num];\r\nfor (t = 0; t < genwqe_ddcb_software_timeout * 10; t++) {\r\nspin_lock_irqsave(&queue->ddcb_lock, flags);\r\nif (ddcb_requ_get_state(req) == GENWQE_REQU_FINISHED)\r\ngoto go_home;\r\nold = pddcb->icrc_hsi_shi_32;\r\nif ((old & DDCB_FETCHED_BE32) == 0x00000000) {\r\nnew = (old | DDCB_PURGE_BE32);\r\nicrc_hsi_shi = cmpxchg(&pddcb->icrc_hsi_shi_32,\r\nold, new);\r\nif (icrc_hsi_shi == old)\r\ngoto finish_ddcb;\r\n}\r\nbarrier();\r\nicrc_hsi_shi = pddcb->icrc_hsi_shi_32;\r\nif (icrc_hsi_shi & DDCB_COMPLETED_BE32)\r\ngoto finish_ddcb;\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\ncopy_ddcb_results(req, req->num);\r\nmsleep(100);\r\ncontinue;\r\nfinish_ddcb:\r\ncopy_ddcb_results(req, req->num);\r\nddcb_requ_set_state(req, GENWQE_REQU_FINISHED);\r\nqueue->ddcbs_in_flight--;\r\nqueue->ddcb_req[req->num] = NULL;\r\nddcb_mark_cleared(pddcb);\r\nicrc_hsi_shi = pddcb->icrc_hsi_shi_32;\r\nif ((icrc_hsi_shi & DDCB_COMPLETED_BE32) &&\r\n(queue->ddcb_act == req->num)) {\r\nqueue->ddcb_act = ((queue->ddcb_act + 1) %\r\nqueue->ddcb_max);\r\n}\r\ngo_home:\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nreturn 0;\r\n}\r\nqueue_status = __genwqe_readq(cd, queue->IO_QUEUE_STATUS);\r\ndev_dbg(&pci_dev->dev, "UN/FINISHED DDCB#%d\n", req->num);\r\ngenwqe_hexdump(pci_dev, pddcb, sizeof(*pddcb));\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: DDCB#%d not purged and not completed after %d seconds QSTAT=%016llx!!\n",\r\n__func__, req->num, genwqe_ddcb_software_timeout,\r\nqueue_status);\r\nprint_ddcb_info(cd, req->queue);\r\nreturn -EFAULT;\r\n}\r\nint genwqe_init_debug_data(struct genwqe_dev *cd, struct genwqe_debug_data *d)\r\n{\r\nint len;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif (d == NULL) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: invalid memory for debug data!\n",\r\n__func__);\r\nreturn -EFAULT;\r\n}\r\nlen = sizeof(d->driver_version);\r\nsnprintf(d->driver_version, len, "%s", DRV_VERSION);\r\nd->slu_unitcfg = cd->slu_unitcfg;\r\nd->app_unitcfg = cd->app_unitcfg;\r\nreturn 0;\r\n}\r\nint __genwqe_enqueue_ddcb(struct genwqe_dev *cd, struct ddcb_requ *req,\r\nunsigned int f_flags)\r\n{\r\nstruct ddcb *pddcb;\r\nunsigned long flags;\r\nstruct ddcb_queue *queue;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nu16 icrc;\r\nretry:\r\nif (cd->card_state != GENWQE_CARD_USED) {\r\nprintk_ratelimited(KERN_ERR\r\n"%s %s: [%s] Card is unusable/PCIe problem Req#%d\n",\r\nGENWQE_DEVNAME, dev_name(&pci_dev->dev),\r\n__func__, req->num);\r\nreturn -EIO;\r\n}\r\nqueue = req->queue = &cd->queue;\r\nif (genwqe_polling_enabled)\r\ngenwqe_check_ddcb_queue(cd, queue);\r\nspin_lock_irqsave(&queue->ddcb_lock, flags);\r\npddcb = get_next_ddcb(cd, queue, &req->num);\r\nif (pddcb == NULL) {\r\nint rc;\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nif (f_flags & O_NONBLOCK) {\r\nqueue->return_on_busy++;\r\nreturn -EBUSY;\r\n}\r\nqueue->wait_on_busy++;\r\nrc = wait_event_interruptible(queue->busy_waitq,\r\nqueue_free_ddcbs(queue) != 0);\r\ndev_dbg(&pci_dev->dev, "[%s] waiting for free DDCB: rc=%d\n",\r\n__func__, rc);\r\nif (rc == -ERESTARTSYS)\r\nreturn rc;\r\ngoto retry;\r\n}\r\nif (queue->ddcb_req[req->num] != NULL) {\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\ndev_err(&pci_dev->dev,\r\n"[%s] picked DDCB %d with req=%p still in use!!\n",\r\n__func__, req->num, req);\r\nreturn -EFAULT;\r\n}\r\nddcb_requ_set_state(req, GENWQE_REQU_ENQUEUED);\r\nqueue->ddcb_req[req->num] = req;\r\npddcb->cmdopts_16 = cpu_to_be16(req->cmd.cmdopts);\r\npddcb->cmd = req->cmd.cmd;\r\npddcb->acfunc = req->cmd.acfunc;\r\nif ((cd->slu_unitcfg & 0xFFFF0ull) > 0x34199ull)\r\npddcb->xdir = 0x1;\r\nelse\r\npddcb->xdir = 0x0;\r\npddcb->psp = (((req->cmd.asiv_length / 8) << 4) |\r\n((req->cmd.asv_length / 8)));\r\npddcb->disp_ts_64 = cpu_to_be64(req->cmd.disp_ts);\r\nif (genwqe_get_slu_id(cd) <= 0x2) {\r\nmemcpy(&pddcb->__asiv[0],\r\n&req->cmd.__asiv[0],\r\nDDCB_ASIV_LENGTH);\r\n} else {\r\npddcb->n.ats_64 = cpu_to_be64(req->cmd.ats);\r\nmemcpy(&pddcb->n.asiv[0],\r\n&req->cmd.asiv[0],\r\nDDCB_ASIV_LENGTH_ATS);\r\n}\r\npddcb->icrc_hsi_shi_32 = cpu_to_be32(0x00000000);\r\nicrc = genwqe_crc16((const u8 *)pddcb,\r\nICRC_LENGTH(req->cmd.asiv_length), 0xffff);\r\npddcb->icrc_hsi_shi_32 = cpu_to_be32((u32)icrc << 16);\r\nif (!genwqe_polling_enabled)\r\npddcb->icrc_hsi_shi_32 |= DDCB_INTR_BE32;\r\ndev_dbg(&pci_dev->dev, "INPUT DDCB#%d\n", req->num);\r\ngenwqe_hexdump(pci_dev, pddcb, sizeof(*pddcb));\r\nif (ddcb_requ_collect_debug_data(req)) {\r\ngenwqe_init_debug_data(cd, &req->debug_data);\r\nmemcpy(&req->debug_data.ddcb_before, pddcb,\r\nsizeof(req->debug_data.ddcb_before));\r\n}\r\nenqueue_ddcb(cd, queue, pddcb, req->num);\r\nqueue->ddcbs_in_flight++;\r\nif (queue->ddcbs_in_flight > queue->ddcbs_max_in_flight)\r\nqueue->ddcbs_max_in_flight = queue->ddcbs_in_flight;\r\nddcb_requ_set_state(req, GENWQE_REQU_TAPPED);\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nwake_up_interruptible(&cd->queue_waitq);\r\nreturn 0;\r\n}\r\nint __genwqe_execute_raw_ddcb(struct genwqe_dev *cd,\r\nstruct genwqe_ddcb_cmd *cmd,\r\nunsigned int f_flags)\r\n{\r\nint rc = 0;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nstruct ddcb_requ *req = container_of(cmd, struct ddcb_requ, cmd);\r\nif (cmd->asiv_length > DDCB_ASIV_LENGTH) {\r\ndev_err(&pci_dev->dev, "[%s] err: wrong asiv_length of %d\n",\r\n__func__, cmd->asiv_length);\r\nreturn -EINVAL;\r\n}\r\nif (cmd->asv_length > DDCB_ASV_LENGTH) {\r\ndev_err(&pci_dev->dev, "[%s] err: wrong asv_length of %d\n",\r\n__func__, cmd->asiv_length);\r\nreturn -EINVAL;\r\n}\r\nrc = __genwqe_enqueue_ddcb(cd, req, f_flags);\r\nif (rc != 0)\r\nreturn rc;\r\nrc = __genwqe_wait_ddcb(cd, req);\r\nif (rc < 0)\r\ngoto err_exit;\r\nif (ddcb_requ_collect_debug_data(req)) {\r\nif (copy_to_user((struct genwqe_debug_data __user *)\r\n(unsigned long)cmd->ddata_addr,\r\n&req->debug_data,\r\nsizeof(struct genwqe_debug_data)))\r\nreturn -EFAULT;\r\n}\r\nif (cmd->retc != DDCB_RETC_COMPLETE) {\r\nrc = -EBADMSG;\r\n}\r\nreturn rc;\r\nerr_exit:\r\n__genwqe_purge_ddcb(cd, req);\r\nif (ddcb_requ_collect_debug_data(req)) {\r\nif (copy_to_user((struct genwqe_debug_data __user *)\r\n(unsigned long)cmd->ddata_addr,\r\n&req->debug_data,\r\nsizeof(struct genwqe_debug_data)))\r\nreturn -EFAULT;\r\n}\r\nreturn rc;\r\n}\r\nstatic int genwqe_next_ddcb_ready(struct genwqe_dev *cd)\r\n{\r\nunsigned long flags;\r\nstruct ddcb *pddcb;\r\nstruct ddcb_queue *queue = &cd->queue;\r\nspin_lock_irqsave(&queue->ddcb_lock, flags);\r\nif (queue_empty(queue)) {\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nreturn 0;\r\n}\r\npddcb = &queue->ddcb_vaddr[queue->ddcb_act];\r\nif (pddcb->icrc_hsi_shi_32 & DDCB_COMPLETED_BE32) {\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nreturn 1;\r\n}\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nreturn 0;\r\n}\r\nint genwqe_ddcbs_in_flight(struct genwqe_dev *cd)\r\n{\r\nunsigned long flags;\r\nint ddcbs_in_flight = 0;\r\nstruct ddcb_queue *queue = &cd->queue;\r\nspin_lock_irqsave(&queue->ddcb_lock, flags);\r\nddcbs_in_flight += queue->ddcbs_in_flight;\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nreturn ddcbs_in_flight;\r\n}\r\nstatic int setup_ddcb_queue(struct genwqe_dev *cd, struct ddcb_queue *queue)\r\n{\r\nint rc, i;\r\nstruct ddcb *pddcb;\r\nu64 val64;\r\nunsigned int queue_size;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif (genwqe_ddcb_max < 2)\r\nreturn -EINVAL;\r\nqueue_size = roundup(genwqe_ddcb_max * sizeof(struct ddcb), PAGE_SIZE);\r\nqueue->ddcbs_in_flight = 0;\r\nqueue->ddcbs_max_in_flight = 0;\r\nqueue->ddcbs_completed = 0;\r\nqueue->return_on_busy = 0;\r\nqueue->wait_on_busy = 0;\r\nqueue->ddcb_seq = 0x100;\r\nqueue->ddcb_max = genwqe_ddcb_max;\r\nqueue->ddcb_vaddr = __genwqe_alloc_consistent(cd, queue_size,\r\n&queue->ddcb_daddr);\r\nif (queue->ddcb_vaddr == NULL) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] **err: could not allocate DDCB **\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nmemset(queue->ddcb_vaddr, 0, queue_size);\r\nqueue->ddcb_req = kzalloc(sizeof(struct ddcb_requ *) *\r\nqueue->ddcb_max, GFP_KERNEL);\r\nif (!queue->ddcb_req) {\r\nrc = -ENOMEM;\r\ngoto free_ddcbs;\r\n}\r\nqueue->ddcb_waitqs = kzalloc(sizeof(wait_queue_head_t) *\r\nqueue->ddcb_max, GFP_KERNEL);\r\nif (!queue->ddcb_waitqs) {\r\nrc = -ENOMEM;\r\ngoto free_requs;\r\n}\r\nfor (i = 0; i < queue->ddcb_max; i++) {\r\npddcb = &queue->ddcb_vaddr[i];\r\npddcb->icrc_hsi_shi_32 = DDCB_COMPLETED_BE32;\r\npddcb->retc_16 = cpu_to_be16(0xfff);\r\nqueue->ddcb_req[i] = NULL;\r\ninit_waitqueue_head(&queue->ddcb_waitqs[i]);\r\n}\r\nqueue->ddcb_act = 0;\r\nqueue->ddcb_next = 0;\r\nspin_lock_init(&queue->ddcb_lock);\r\ninit_waitqueue_head(&queue->busy_waitq);\r\nval64 = ((u64)(queue->ddcb_max - 1) << 8);\r\n__genwqe_writeq(cd, queue->IO_QUEUE_CONFIG, 0x07);\r\n__genwqe_writeq(cd, queue->IO_QUEUE_SEGMENT, queue->ddcb_daddr);\r\n__genwqe_writeq(cd, queue->IO_QUEUE_INITSQN, queue->ddcb_seq);\r\n__genwqe_writeq(cd, queue->IO_QUEUE_WRAP, val64);\r\nreturn 0;\r\nfree_requs:\r\nkfree(queue->ddcb_req);\r\nqueue->ddcb_req = NULL;\r\nfree_ddcbs:\r\n__genwqe_free_consistent(cd, queue_size, queue->ddcb_vaddr,\r\nqueue->ddcb_daddr);\r\nqueue->ddcb_vaddr = NULL;\r\nqueue->ddcb_daddr = 0ull;\r\nreturn -ENODEV;\r\n}\r\nstatic int ddcb_queue_initialized(struct ddcb_queue *queue)\r\n{\r\nreturn queue->ddcb_vaddr != NULL;\r\n}\r\nstatic void free_ddcb_queue(struct genwqe_dev *cd, struct ddcb_queue *queue)\r\n{\r\nunsigned int queue_size;\r\nqueue_size = roundup(queue->ddcb_max * sizeof(struct ddcb), PAGE_SIZE);\r\nkfree(queue->ddcb_req);\r\nqueue->ddcb_req = NULL;\r\nif (queue->ddcb_vaddr) {\r\n__genwqe_free_consistent(cd, queue_size, queue->ddcb_vaddr,\r\nqueue->ddcb_daddr);\r\nqueue->ddcb_vaddr = NULL;\r\nqueue->ddcb_daddr = 0ull;\r\n}\r\n}\r\nstatic irqreturn_t genwqe_pf_isr(int irq, void *dev_id)\r\n{\r\nu64 gfir;\r\nstruct genwqe_dev *cd = (struct genwqe_dev *)dev_id;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\ncd->irqs_processed++;\r\nwake_up_interruptible(&cd->queue_waitq);\r\ngfir = __genwqe_readq(cd, IO_SLC_CFGREG_GFIR);\r\nif (((gfir & GFIR_ERR_TRIGGER) != 0x0) &&\r\n!pci_channel_offline(pci_dev)) {\r\nif (cd->use_platform_recovery) {\r\nreadq(cd->mmio + IO_SLC_CFGREG_GFIR);\r\nif (pci_channel_offline(pci_dev))\r\ngoto exit;\r\n}\r\nwake_up_interruptible(&cd->health_waitq);\r\ndev_err_ratelimited(&pci_dev->dev,\r\n"[%s] GFIR=%016llx\n",\r\n__func__, gfir);\r\n}\r\nexit:\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t genwqe_vf_isr(int irq, void *dev_id)\r\n{\r\nstruct genwqe_dev *cd = (struct genwqe_dev *)dev_id;\r\ncd->irqs_processed++;\r\nwake_up_interruptible(&cd->queue_waitq);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int genwqe_card_thread(void *data)\r\n{\r\nint should_stop = 0, rc = 0;\r\nstruct genwqe_dev *cd = (struct genwqe_dev *)data;\r\nwhile (!kthread_should_stop()) {\r\ngenwqe_check_ddcb_queue(cd, &cd->queue);\r\nif (genwqe_polling_enabled) {\r\nrc = wait_event_interruptible_timeout(\r\ncd->queue_waitq,\r\ngenwqe_ddcbs_in_flight(cd) ||\r\n(should_stop = kthread_should_stop()), 1);\r\n} else {\r\nrc = wait_event_interruptible_timeout(\r\ncd->queue_waitq,\r\ngenwqe_next_ddcb_ready(cd) ||\r\n(should_stop = kthread_should_stop()), HZ);\r\n}\r\nif (should_stop)\r\nbreak;\r\ncond_resched();\r\n}\r\nreturn 0;\r\n}\r\nint genwqe_setup_service_layer(struct genwqe_dev *cd)\r\n{\r\nint rc;\r\nstruct ddcb_queue *queue;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif (genwqe_is_privileged(cd)) {\r\nrc = genwqe_card_reset(cd);\r\nif (rc < 0) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: reset failed.\n", __func__);\r\nreturn rc;\r\n}\r\ngenwqe_read_softreset(cd);\r\n}\r\nqueue = &cd->queue;\r\nqueue->IO_QUEUE_CONFIG = IO_SLC_QUEUE_CONFIG;\r\nqueue->IO_QUEUE_STATUS = IO_SLC_QUEUE_STATUS;\r\nqueue->IO_QUEUE_SEGMENT = IO_SLC_QUEUE_SEGMENT;\r\nqueue->IO_QUEUE_INITSQN = IO_SLC_QUEUE_INITSQN;\r\nqueue->IO_QUEUE_OFFSET = IO_SLC_QUEUE_OFFSET;\r\nqueue->IO_QUEUE_WRAP = IO_SLC_QUEUE_WRAP;\r\nqueue->IO_QUEUE_WTIME = IO_SLC_QUEUE_WTIME;\r\nqueue->IO_QUEUE_ERRCNTS = IO_SLC_QUEUE_ERRCNTS;\r\nqueue->IO_QUEUE_LRW = IO_SLC_QUEUE_LRW;\r\nrc = setup_ddcb_queue(cd, queue);\r\nif (rc != 0) {\r\nrc = -ENODEV;\r\ngoto err_out;\r\n}\r\ninit_waitqueue_head(&cd->queue_waitq);\r\ncd->card_thread = kthread_run(genwqe_card_thread, cd,\r\nGENWQE_DEVNAME "%d_thread",\r\ncd->card_idx);\r\nif (IS_ERR(cd->card_thread)) {\r\nrc = PTR_ERR(cd->card_thread);\r\ncd->card_thread = NULL;\r\ngoto stop_free_queue;\r\n}\r\nrc = genwqe_set_interrupt_capability(cd, GENWQE_MSI_IRQS);\r\nif (rc)\r\ngoto stop_kthread;\r\ninit_waitqueue_head(&cd->health_waitq);\r\nif (genwqe_is_privileged(cd)) {\r\nrc = request_irq(pci_dev->irq, genwqe_pf_isr, IRQF_SHARED,\r\nGENWQE_DEVNAME, cd);\r\n} else {\r\nrc = request_irq(pci_dev->irq, genwqe_vf_isr, IRQF_SHARED,\r\nGENWQE_DEVNAME, cd);\r\n}\r\nif (rc < 0) {\r\ndev_err(&pci_dev->dev, "irq %d not free.\n", pci_dev->irq);\r\ngoto stop_irq_cap;\r\n}\r\ncd->card_state = GENWQE_CARD_USED;\r\nreturn 0;\r\nstop_irq_cap:\r\ngenwqe_reset_interrupt_capability(cd);\r\nstop_kthread:\r\nkthread_stop(cd->card_thread);\r\ncd->card_thread = NULL;\r\nstop_free_queue:\r\nfree_ddcb_queue(cd, queue);\r\nerr_out:\r\nreturn rc;\r\n}\r\nstatic int queue_wake_up_all(struct genwqe_dev *cd)\r\n{\r\nunsigned int i;\r\nunsigned long flags;\r\nstruct ddcb_queue *queue = &cd->queue;\r\nspin_lock_irqsave(&queue->ddcb_lock, flags);\r\nfor (i = 0; i < queue->ddcb_max; i++)\r\nwake_up_interruptible(&queue->ddcb_waitqs[queue->ddcb_act]);\r\nwake_up_interruptible(&queue->busy_waitq);\r\nspin_unlock_irqrestore(&queue->ddcb_lock, flags);\r\nreturn 0;\r\n}\r\nint genwqe_finish_queue(struct genwqe_dev *cd)\r\n{\r\nint i, rc = 0, in_flight;\r\nint waitmax = genwqe_ddcb_software_timeout;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nstruct ddcb_queue *queue = &cd->queue;\r\nif (!ddcb_queue_initialized(queue))\r\nreturn 0;\r\nif (cd->card_state == GENWQE_CARD_USED)\r\ncd->card_state = GENWQE_CARD_UNUSED;\r\nqueue_wake_up_all(cd);\r\nfor (i = 0; i < waitmax; i++) {\r\nin_flight = genwqe_ddcbs_in_flight(cd);\r\nif (in_flight == 0)\r\nbreak;\r\ndev_dbg(&pci_dev->dev,\r\n" DEBUG [%d/%d] waiting for queue to get empty: %d requests!\n",\r\ni, waitmax, in_flight);\r\nmsleep(1000);\r\n}\r\nif (i == waitmax) {\r\ndev_err(&pci_dev->dev, " [%s] err: queue is not empty!!\n",\r\n__func__);\r\nrc = -EIO;\r\n}\r\nreturn rc;\r\n}\r\nint genwqe_release_service_layer(struct genwqe_dev *cd)\r\n{\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif (!ddcb_queue_initialized(&cd->queue))\r\nreturn 1;\r\nfree_irq(pci_dev->irq, cd);\r\ngenwqe_reset_interrupt_capability(cd);\r\nif (cd->card_thread != NULL) {\r\nkthread_stop(cd->card_thread);\r\ncd->card_thread = NULL;\r\n}\r\nfree_ddcb_queue(cd, &cd->queue);\r\nreturn 0;\r\n}
