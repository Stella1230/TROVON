static struct fence *amdgpu_sched_dependency(struct amd_sched_job *sched_job)\r\n{\r\nstruct amdgpu_job *job = to_amdgpu_job(sched_job);\r\nreturn amdgpu_sync_get_fence(&job->ibs->sync);\r\n}\r\nstatic struct fence *amdgpu_sched_run_job(struct amd_sched_job *sched_job)\r\n{\r\nstruct amdgpu_fence *fence = NULL;\r\nstruct amdgpu_job *job;\r\nint r;\r\nif (!sched_job) {\r\nDRM_ERROR("job is null\n");\r\nreturn NULL;\r\n}\r\njob = to_amdgpu_job(sched_job);\r\ntrace_amdgpu_sched_run_job(job);\r\nr = amdgpu_ib_schedule(job->adev, job->num_ibs, job->ibs, job->owner);\r\nif (r) {\r\nDRM_ERROR("Error scheduling IBs (%d)\n", r);\r\ngoto err;\r\n}\r\nfence = job->ibs[job->num_ibs - 1].fence;\r\nfence_get(&fence->base);\r\nerr:\r\nif (job->free_job)\r\njob->free_job(job);\r\nkfree(job);\r\nreturn fence ? &fence->base : NULL;\r\n}\r\nint amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,\r\nstruct amdgpu_ring *ring,\r\nstruct amdgpu_ib *ibs,\r\nunsigned num_ibs,\r\nint (*free_job)(struct amdgpu_job *),\r\nvoid *owner,\r\nstruct fence **f)\r\n{\r\nint r = 0;\r\nif (amdgpu_enable_scheduler) {\r\nstruct amdgpu_job *job =\r\nkzalloc(sizeof(struct amdgpu_job), GFP_KERNEL);\r\nif (!job)\r\nreturn -ENOMEM;\r\njob->base.sched = &ring->sched;\r\njob->base.s_entity = &adev->kernel_ctx.rings[ring->idx].entity;\r\njob->base.s_fence = amd_sched_fence_create(job->base.s_entity, owner);\r\nif (!job->base.s_fence) {\r\nkfree(job);\r\nreturn -ENOMEM;\r\n}\r\n*f = fence_get(&job->base.s_fence->base);\r\njob->adev = adev;\r\njob->ibs = ibs;\r\njob->num_ibs = num_ibs;\r\njob->owner = owner;\r\njob->free_job = free_job;\r\namd_sched_entity_push_job(&job->base);\r\n} else {\r\nr = amdgpu_ib_schedule(adev, num_ibs, ibs, owner);\r\nif (r)\r\nreturn r;\r\n*f = fence_get(&ibs[num_ibs - 1].fence->base);\r\n}\r\nreturn 0;\r\n}
