struct kfd_dev *kfd_device_by_id(uint32_t gpu_id)\r\n{\r\nstruct kfd_topology_device *top_dev;\r\nstruct kfd_dev *device = NULL;\r\ndown_read(&topology_lock);\r\nlist_for_each_entry(top_dev, &topology_device_list, list)\r\nif (top_dev->gpu_id == gpu_id) {\r\ndevice = top_dev->gpu;\r\nbreak;\r\n}\r\nup_read(&topology_lock);\r\nreturn device;\r\n}\r\nstruct kfd_dev *kfd_device_by_pci_dev(const struct pci_dev *pdev)\r\n{\r\nstruct kfd_topology_device *top_dev;\r\nstruct kfd_dev *device = NULL;\r\ndown_read(&topology_lock);\r\nlist_for_each_entry(top_dev, &topology_device_list, list)\r\nif (top_dev->gpu->pdev == pdev) {\r\ndevice = top_dev->gpu;\r\nbreak;\r\n}\r\nup_read(&topology_lock);\r\nreturn device;\r\n}\r\nstatic int kfd_topology_get_crat_acpi(void *crat_image, size_t *size)\r\n{\r\nstruct acpi_table_header *crat_table;\r\nacpi_status status;\r\nif (!size)\r\nreturn -EINVAL;\r\nstatus = acpi_get_table(CRAT_SIGNATURE, 0, &crat_table);\r\nif (status == AE_NOT_FOUND) {\r\npr_warn("CRAT table not found\n");\r\nreturn -ENODATA;\r\n} else if (ACPI_FAILURE(status)) {\r\nconst char *err = acpi_format_exception(status);\r\npr_err("CRAT table error: %s\n", err);\r\nreturn -EINVAL;\r\n}\r\nif (*size >= crat_table->length && crat_image != NULL)\r\nmemcpy(crat_image, crat_table, crat_table->length);\r\n*size = crat_table->length;\r\nreturn 0;\r\n}\r\nstatic void kfd_populated_cu_info_cpu(struct kfd_topology_device *dev,\r\nstruct crat_subtype_computeunit *cu)\r\n{\r\nBUG_ON(!dev);\r\nBUG_ON(!cu);\r\ndev->node_props.cpu_cores_count = cu->num_cpu_cores;\r\ndev->node_props.cpu_core_id_base = cu->processor_id_low;\r\nif (cu->hsa_capability & CRAT_CU_FLAGS_IOMMU_PRESENT)\r\ndev->node_props.capability |= HSA_CAP_ATS_PRESENT;\r\npr_info("CU CPU: cores=%d id_base=%d\n", cu->num_cpu_cores,\r\ncu->processor_id_low);\r\n}\r\nstatic void kfd_populated_cu_info_gpu(struct kfd_topology_device *dev,\r\nstruct crat_subtype_computeunit *cu)\r\n{\r\nBUG_ON(!dev);\r\nBUG_ON(!cu);\r\ndev->node_props.simd_id_base = cu->processor_id_low;\r\ndev->node_props.simd_count = cu->num_simd_cores;\r\ndev->node_props.lds_size_in_kb = cu->lds_size_in_kb;\r\ndev->node_props.max_waves_per_simd = cu->max_waves_simd;\r\ndev->node_props.wave_front_size = cu->wave_front_size;\r\ndev->node_props.mem_banks_count = cu->num_banks;\r\ndev->node_props.array_count = cu->num_arrays;\r\ndev->node_props.cu_per_simd_array = cu->num_cu_per_array;\r\ndev->node_props.simd_per_cu = cu->num_simd_per_cu;\r\ndev->node_props.max_slots_scratch_cu = cu->max_slots_scatch_cu;\r\nif (cu->hsa_capability & CRAT_CU_FLAGS_HOT_PLUGGABLE)\r\ndev->node_props.capability |= HSA_CAP_HOT_PLUGGABLE;\r\npr_info("CU GPU: simds=%d id_base=%d\n", cu->num_simd_cores,\r\ncu->processor_id_low);\r\n}\r\nstatic int kfd_parse_subtype_cu(struct crat_subtype_computeunit *cu)\r\n{\r\nstruct kfd_topology_device *dev;\r\nint i = 0;\r\nBUG_ON(!cu);\r\npr_info("Found CU entry in CRAT table with proximity_domain=%d caps=%x\n",\r\ncu->proximity_domain, cu->hsa_capability);\r\nlist_for_each_entry(dev, &topology_device_list, list) {\r\nif (cu->proximity_domain == i) {\r\nif (cu->flags & CRAT_CU_FLAGS_CPU_PRESENT)\r\nkfd_populated_cu_info_cpu(dev, cu);\r\nif (cu->flags & CRAT_CU_FLAGS_GPU_PRESENT)\r\nkfd_populated_cu_info_gpu(dev, cu);\r\nbreak;\r\n}\r\ni++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int kfd_parse_subtype_mem(struct crat_subtype_memory *mem)\r\n{\r\nstruct kfd_mem_properties *props;\r\nstruct kfd_topology_device *dev;\r\nint i = 0;\r\nBUG_ON(!mem);\r\npr_info("Found memory entry in CRAT table with proximity_domain=%d\n",\r\nmem->promixity_domain);\r\nlist_for_each_entry(dev, &topology_device_list, list) {\r\nif (mem->promixity_domain == i) {\r\nprops = kfd_alloc_struct(props);\r\nif (props == NULL)\r\nreturn -ENOMEM;\r\nif (dev->node_props.cpu_cores_count == 0)\r\nprops->heap_type = HSA_MEM_HEAP_TYPE_FB_PRIVATE;\r\nelse\r\nprops->heap_type = HSA_MEM_HEAP_TYPE_SYSTEM;\r\nif (mem->flags & CRAT_MEM_FLAGS_HOT_PLUGGABLE)\r\nprops->flags |= HSA_MEM_FLAGS_HOT_PLUGGABLE;\r\nif (mem->flags & CRAT_MEM_FLAGS_NON_VOLATILE)\r\nprops->flags |= HSA_MEM_FLAGS_NON_VOLATILE;\r\nprops->size_in_bytes =\r\n((uint64_t)mem->length_high << 32) +\r\nmem->length_low;\r\nprops->width = mem->width;\r\ndev->mem_bank_count++;\r\nlist_add_tail(&props->list, &dev->mem_props);\r\nbreak;\r\n}\r\ni++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int kfd_parse_subtype_cache(struct crat_subtype_cache *cache)\r\n{\r\nstruct kfd_cache_properties *props;\r\nstruct kfd_topology_device *dev;\r\nuint32_t id;\r\nBUG_ON(!cache);\r\nid = cache->processor_id_low;\r\npr_info("Found cache entry in CRAT table with processor_id=%d\n", id);\r\nlist_for_each_entry(dev, &topology_device_list, list)\r\nif (id == dev->node_props.cpu_core_id_base ||\r\nid == dev->node_props.simd_id_base) {\r\nprops = kfd_alloc_struct(props);\r\nif (props == NULL)\r\nreturn -ENOMEM;\r\nprops->processor_id_low = id;\r\nprops->cache_level = cache->cache_level;\r\nprops->cache_size = cache->cache_size;\r\nprops->cacheline_size = cache->cache_line_size;\r\nprops->cachelines_per_tag = cache->lines_per_tag;\r\nprops->cache_assoc = cache->associativity;\r\nprops->cache_latency = cache->cache_latency;\r\nif (cache->flags & CRAT_CACHE_FLAGS_DATA_CACHE)\r\nprops->cache_type |= HSA_CACHE_TYPE_DATA;\r\nif (cache->flags & CRAT_CACHE_FLAGS_INST_CACHE)\r\nprops->cache_type |= HSA_CACHE_TYPE_INSTRUCTION;\r\nif (cache->flags & CRAT_CACHE_FLAGS_CPU_CACHE)\r\nprops->cache_type |= HSA_CACHE_TYPE_CPU;\r\nif (cache->flags & CRAT_CACHE_FLAGS_SIMD_CACHE)\r\nprops->cache_type |= HSA_CACHE_TYPE_HSACU;\r\ndev->cache_count++;\r\ndev->node_props.caches_count++;\r\nlist_add_tail(&props->list, &dev->cache_props);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int kfd_parse_subtype_iolink(struct crat_subtype_iolink *iolink)\r\n{\r\nstruct kfd_iolink_properties *props;\r\nstruct kfd_topology_device *dev;\r\nuint32_t i = 0;\r\nuint32_t id_from;\r\nuint32_t id_to;\r\nBUG_ON(!iolink);\r\nid_from = iolink->proximity_domain_from;\r\nid_to = iolink->proximity_domain_to;\r\npr_info("Found IO link entry in CRAT table with id_from=%d\n", id_from);\r\nlist_for_each_entry(dev, &topology_device_list, list) {\r\nif (id_from == i) {\r\nprops = kfd_alloc_struct(props);\r\nif (props == NULL)\r\nreturn -ENOMEM;\r\nprops->node_from = id_from;\r\nprops->node_to = id_to;\r\nprops->ver_maj = iolink->version_major;\r\nprops->ver_min = iolink->version_minor;\r\nprops->weight = 1;\r\nprops->min_latency = iolink->minimum_latency;\r\nprops->max_latency = iolink->maximum_latency;\r\nprops->min_bandwidth = iolink->minimum_bandwidth_mbs;\r\nprops->max_bandwidth = iolink->maximum_bandwidth_mbs;\r\nprops->rec_transfer_size =\r\niolink->recommended_transfer_size;\r\ndev->io_link_count++;\r\ndev->node_props.io_links_count++;\r\nlist_add_tail(&props->list, &dev->io_link_props);\r\nbreak;\r\n}\r\ni++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int kfd_parse_subtype(struct crat_subtype_generic *sub_type_hdr)\r\n{\r\nstruct crat_subtype_computeunit *cu;\r\nstruct crat_subtype_memory *mem;\r\nstruct crat_subtype_cache *cache;\r\nstruct crat_subtype_iolink *iolink;\r\nint ret = 0;\r\nBUG_ON(!sub_type_hdr);\r\nswitch (sub_type_hdr->type) {\r\ncase CRAT_SUBTYPE_COMPUTEUNIT_AFFINITY:\r\ncu = (struct crat_subtype_computeunit *)sub_type_hdr;\r\nret = kfd_parse_subtype_cu(cu);\r\nbreak;\r\ncase CRAT_SUBTYPE_MEMORY_AFFINITY:\r\nmem = (struct crat_subtype_memory *)sub_type_hdr;\r\nret = kfd_parse_subtype_mem(mem);\r\nbreak;\r\ncase CRAT_SUBTYPE_CACHE_AFFINITY:\r\ncache = (struct crat_subtype_cache *)sub_type_hdr;\r\nret = kfd_parse_subtype_cache(cache);\r\nbreak;\r\ncase CRAT_SUBTYPE_TLB_AFFINITY:\r\npr_info("Found TLB entry in CRAT table (not processing)\n");\r\nbreak;\r\ncase CRAT_SUBTYPE_CCOMPUTE_AFFINITY:\r\npr_info("Found CCOMPUTE entry in CRAT table (not processing)\n");\r\nbreak;\r\ncase CRAT_SUBTYPE_IOLINK_AFFINITY:\r\niolink = (struct crat_subtype_iolink *)sub_type_hdr;\r\nret = kfd_parse_subtype_iolink(iolink);\r\nbreak;\r\ndefault:\r\npr_warn("Unknown subtype (%d) in CRAT\n",\r\nsub_type_hdr->type);\r\n}\r\nreturn ret;\r\n}\r\nstatic void kfd_release_topology_device(struct kfd_topology_device *dev)\r\n{\r\nstruct kfd_mem_properties *mem;\r\nstruct kfd_cache_properties *cache;\r\nstruct kfd_iolink_properties *iolink;\r\nBUG_ON(!dev);\r\nlist_del(&dev->list);\r\nwhile (dev->mem_props.next != &dev->mem_props) {\r\nmem = container_of(dev->mem_props.next,\r\nstruct kfd_mem_properties, list);\r\nlist_del(&mem->list);\r\nkfree(mem);\r\n}\r\nwhile (dev->cache_props.next != &dev->cache_props) {\r\ncache = container_of(dev->cache_props.next,\r\nstruct kfd_cache_properties, list);\r\nlist_del(&cache->list);\r\nkfree(cache);\r\n}\r\nwhile (dev->io_link_props.next != &dev->io_link_props) {\r\niolink = container_of(dev->io_link_props.next,\r\nstruct kfd_iolink_properties, list);\r\nlist_del(&iolink->list);\r\nkfree(iolink);\r\n}\r\nkfree(dev);\r\nsys_props.num_devices--;\r\n}\r\nstatic void kfd_release_live_view(void)\r\n{\r\nstruct kfd_topology_device *dev;\r\nwhile (topology_device_list.next != &topology_device_list) {\r\ndev = container_of(topology_device_list.next,\r\nstruct kfd_topology_device, list);\r\nkfd_release_topology_device(dev);\r\n}\r\nmemset(&sys_props, 0, sizeof(sys_props));\r\n}\r\nstatic struct kfd_topology_device *kfd_create_topology_device(void)\r\n{\r\nstruct kfd_topology_device *dev;\r\ndev = kfd_alloc_struct(dev);\r\nif (dev == NULL) {\r\npr_err("No memory to allocate a topology device");\r\nreturn NULL;\r\n}\r\nINIT_LIST_HEAD(&dev->mem_props);\r\nINIT_LIST_HEAD(&dev->cache_props);\r\nINIT_LIST_HEAD(&dev->io_link_props);\r\nlist_add_tail(&dev->list, &topology_device_list);\r\nsys_props.num_devices++;\r\nreturn dev;\r\n}\r\nstatic int kfd_parse_crat_table(void *crat_image)\r\n{\r\nstruct kfd_topology_device *top_dev;\r\nstruct crat_subtype_generic *sub_type_hdr;\r\nuint16_t node_id;\r\nint ret;\r\nstruct crat_header *crat_table = (struct crat_header *)crat_image;\r\nuint16_t num_nodes;\r\nuint32_t image_len;\r\nif (!crat_image)\r\nreturn -EINVAL;\r\nnum_nodes = crat_table->num_domains;\r\nimage_len = crat_table->length;\r\npr_info("Parsing CRAT table with %d nodes\n", num_nodes);\r\nfor (node_id = 0; node_id < num_nodes; node_id++) {\r\ntop_dev = kfd_create_topology_device();\r\nif (!top_dev) {\r\nkfd_release_live_view();\r\nreturn -ENOMEM;\r\n}\r\n}\r\nsys_props.platform_id =\r\n(*((uint64_t *)crat_table->oem_id)) & CRAT_OEMID_64BIT_MASK;\r\nsys_props.platform_oem = *((uint64_t *)crat_table->oem_table_id);\r\nsys_props.platform_rev = crat_table->revision;\r\nsub_type_hdr = (struct crat_subtype_generic *)(crat_table+1);\r\nwhile ((char *)sub_type_hdr + sizeof(struct crat_subtype_generic) <\r\n((char *)crat_image) + image_len) {\r\nif (sub_type_hdr->flags & CRAT_SUBTYPE_FLAGS_ENABLED) {\r\nret = kfd_parse_subtype(sub_type_hdr);\r\nif (ret != 0) {\r\nkfd_release_live_view();\r\nreturn ret;\r\n}\r\n}\r\nsub_type_hdr = (typeof(sub_type_hdr))((char *)sub_type_hdr +\r\nsub_type_hdr->length);\r\n}\r\nsys_props.generation_count++;\r\ntopology_crat_parsed = 1;\r\nreturn 0;\r\n}\r\nstatic ssize_t sysprops_show(struct kobject *kobj, struct attribute *attr,\r\nchar *buffer)\r\n{\r\nssize_t ret;\r\nbuffer[0] = 0;\r\nif (attr == &sys_props.attr_genid) {\r\nret = sysfs_show_32bit_val(buffer, sys_props.generation_count);\r\n} else if (attr == &sys_props.attr_props) {\r\nsysfs_show_64bit_prop(buffer, "platform_oem",\r\nsys_props.platform_oem);\r\nsysfs_show_64bit_prop(buffer, "platform_id",\r\nsys_props.platform_id);\r\nret = sysfs_show_64bit_prop(buffer, "platform_rev",\r\nsys_props.platform_rev);\r\n} else {\r\nret = -EINVAL;\r\n}\r\nreturn ret;\r\n}\r\nstatic ssize_t iolink_show(struct kobject *kobj, struct attribute *attr,\r\nchar *buffer)\r\n{\r\nssize_t ret;\r\nstruct kfd_iolink_properties *iolink;\r\nbuffer[0] = 0;\r\niolink = container_of(attr, struct kfd_iolink_properties, attr);\r\nsysfs_show_32bit_prop(buffer, "type", iolink->iolink_type);\r\nsysfs_show_32bit_prop(buffer, "version_major", iolink->ver_maj);\r\nsysfs_show_32bit_prop(buffer, "version_minor", iolink->ver_min);\r\nsysfs_show_32bit_prop(buffer, "node_from", iolink->node_from);\r\nsysfs_show_32bit_prop(buffer, "node_to", iolink->node_to);\r\nsysfs_show_32bit_prop(buffer, "weight", iolink->weight);\r\nsysfs_show_32bit_prop(buffer, "min_latency", iolink->min_latency);\r\nsysfs_show_32bit_prop(buffer, "max_latency", iolink->max_latency);\r\nsysfs_show_32bit_prop(buffer, "min_bandwidth", iolink->min_bandwidth);\r\nsysfs_show_32bit_prop(buffer, "max_bandwidth", iolink->max_bandwidth);\r\nsysfs_show_32bit_prop(buffer, "recommended_transfer_size",\r\niolink->rec_transfer_size);\r\nret = sysfs_show_32bit_prop(buffer, "flags", iolink->flags);\r\nreturn ret;\r\n}\r\nstatic ssize_t mem_show(struct kobject *kobj, struct attribute *attr,\r\nchar *buffer)\r\n{\r\nssize_t ret;\r\nstruct kfd_mem_properties *mem;\r\nbuffer[0] = 0;\r\nmem = container_of(attr, struct kfd_mem_properties, attr);\r\nsysfs_show_32bit_prop(buffer, "heap_type", mem->heap_type);\r\nsysfs_show_64bit_prop(buffer, "size_in_bytes", mem->size_in_bytes);\r\nsysfs_show_32bit_prop(buffer, "flags", mem->flags);\r\nsysfs_show_32bit_prop(buffer, "width", mem->width);\r\nret = sysfs_show_32bit_prop(buffer, "mem_clk_max", mem->mem_clk_max);\r\nreturn ret;\r\n}\r\nstatic ssize_t kfd_cache_show(struct kobject *kobj, struct attribute *attr,\r\nchar *buffer)\r\n{\r\nssize_t ret;\r\nuint32_t i;\r\nstruct kfd_cache_properties *cache;\r\nbuffer[0] = 0;\r\ncache = container_of(attr, struct kfd_cache_properties, attr);\r\nsysfs_show_32bit_prop(buffer, "processor_id_low",\r\ncache->processor_id_low);\r\nsysfs_show_32bit_prop(buffer, "level", cache->cache_level);\r\nsysfs_show_32bit_prop(buffer, "size", cache->cache_size);\r\nsysfs_show_32bit_prop(buffer, "cache_line_size", cache->cacheline_size);\r\nsysfs_show_32bit_prop(buffer, "cache_lines_per_tag",\r\ncache->cachelines_per_tag);\r\nsysfs_show_32bit_prop(buffer, "association", cache->cache_assoc);\r\nsysfs_show_32bit_prop(buffer, "latency", cache->cache_latency);\r\nsysfs_show_32bit_prop(buffer, "type", cache->cache_type);\r\nsnprintf(buffer, PAGE_SIZE, "%ssibling_map ", buffer);\r\nfor (i = 0; i < KFD_TOPOLOGY_CPU_SIBLINGS; i++)\r\nret = snprintf(buffer, PAGE_SIZE, "%s%d%s",\r\nbuffer, cache->sibling_map[i],\r\n(i == KFD_TOPOLOGY_CPU_SIBLINGS-1) ?\r\n"\n" : ",");\r\nreturn ret;\r\n}\r\nstatic ssize_t node_show(struct kobject *kobj, struct attribute *attr,\r\nchar *buffer)\r\n{\r\nstruct kfd_topology_device *dev;\r\nchar public_name[KFD_TOPOLOGY_PUBLIC_NAME_SIZE];\r\nuint32_t i;\r\nuint32_t log_max_watch_addr;\r\nbuffer[0] = 0;\r\nif (strcmp(attr->name, "gpu_id") == 0) {\r\ndev = container_of(attr, struct kfd_topology_device,\r\nattr_gpuid);\r\nreturn sysfs_show_32bit_val(buffer, dev->gpu_id);\r\n}\r\nif (strcmp(attr->name, "name") == 0) {\r\ndev = container_of(attr, struct kfd_topology_device,\r\nattr_name);\r\nfor (i = 0; i < KFD_TOPOLOGY_PUBLIC_NAME_SIZE; i++) {\r\npublic_name[i] =\r\n(char)dev->node_props.marketing_name[i];\r\nif (dev->node_props.marketing_name[i] == 0)\r\nbreak;\r\n}\r\npublic_name[KFD_TOPOLOGY_PUBLIC_NAME_SIZE-1] = 0x0;\r\nreturn sysfs_show_str_val(buffer, public_name);\r\n}\r\ndev = container_of(attr, struct kfd_topology_device,\r\nattr_props);\r\nsysfs_show_32bit_prop(buffer, "cpu_cores_count",\r\ndev->node_props.cpu_cores_count);\r\nsysfs_show_32bit_prop(buffer, "simd_count",\r\ndev->node_props.simd_count);\r\nif (dev->mem_bank_count < dev->node_props.mem_banks_count) {\r\npr_warn("kfd: mem_banks_count truncated from %d to %d\n",\r\ndev->node_props.mem_banks_count,\r\ndev->mem_bank_count);\r\nsysfs_show_32bit_prop(buffer, "mem_banks_count",\r\ndev->mem_bank_count);\r\n} else {\r\nsysfs_show_32bit_prop(buffer, "mem_banks_count",\r\ndev->node_props.mem_banks_count);\r\n}\r\nsysfs_show_32bit_prop(buffer, "caches_count",\r\ndev->node_props.caches_count);\r\nsysfs_show_32bit_prop(buffer, "io_links_count",\r\ndev->node_props.io_links_count);\r\nsysfs_show_32bit_prop(buffer, "cpu_core_id_base",\r\ndev->node_props.cpu_core_id_base);\r\nsysfs_show_32bit_prop(buffer, "simd_id_base",\r\ndev->node_props.simd_id_base);\r\nsysfs_show_32bit_prop(buffer, "max_waves_per_simd",\r\ndev->node_props.max_waves_per_simd);\r\nsysfs_show_32bit_prop(buffer, "lds_size_in_kb",\r\ndev->node_props.lds_size_in_kb);\r\nsysfs_show_32bit_prop(buffer, "gds_size_in_kb",\r\ndev->node_props.gds_size_in_kb);\r\nsysfs_show_32bit_prop(buffer, "wave_front_size",\r\ndev->node_props.wave_front_size);\r\nsysfs_show_32bit_prop(buffer, "array_count",\r\ndev->node_props.array_count);\r\nsysfs_show_32bit_prop(buffer, "simd_arrays_per_engine",\r\ndev->node_props.simd_arrays_per_engine);\r\nsysfs_show_32bit_prop(buffer, "cu_per_simd_array",\r\ndev->node_props.cu_per_simd_array);\r\nsysfs_show_32bit_prop(buffer, "simd_per_cu",\r\ndev->node_props.simd_per_cu);\r\nsysfs_show_32bit_prop(buffer, "max_slots_scratch_cu",\r\ndev->node_props.max_slots_scratch_cu);\r\nsysfs_show_32bit_prop(buffer, "vendor_id",\r\ndev->node_props.vendor_id);\r\nsysfs_show_32bit_prop(buffer, "device_id",\r\ndev->node_props.device_id);\r\nsysfs_show_32bit_prop(buffer, "location_id",\r\ndev->node_props.location_id);\r\nif (dev->gpu) {\r\nlog_max_watch_addr =\r\n__ilog2_u32(dev->gpu->device_info->num_of_watch_points);\r\nif (log_max_watch_addr) {\r\ndev->node_props.capability |=\r\nHSA_CAP_WATCH_POINTS_SUPPORTED;\r\ndev->node_props.capability |=\r\n((log_max_watch_addr <<\r\nHSA_CAP_WATCH_POINTS_TOTALBITS_SHIFT) &\r\nHSA_CAP_WATCH_POINTS_TOTALBITS_MASK);\r\n}\r\nsysfs_show_32bit_prop(buffer, "max_engine_clk_fcompute",\r\ndev->gpu->kfd2kgd->get_max_engine_clock_in_mhz(\r\ndev->gpu->kgd));\r\nsysfs_show_64bit_prop(buffer, "local_mem_size",\r\n(unsigned long long int) 0);\r\nsysfs_show_32bit_prop(buffer, "fw_version",\r\ndev->gpu->kfd2kgd->get_fw_version(\r\ndev->gpu->kgd,\r\nKGD_ENGINE_MEC1));\r\nsysfs_show_32bit_prop(buffer, "capability",\r\ndev->node_props.capability);\r\n}\r\nreturn sysfs_show_32bit_prop(buffer, "max_engine_clk_ccompute",\r\ncpufreq_quick_get_max(0)/1000);\r\n}\r\nstatic void kfd_remove_sysfs_file(struct kobject *kobj, struct attribute *attr)\r\n{\r\nsysfs_remove_file(kobj, attr);\r\nkobject_del(kobj);\r\nkobject_put(kobj);\r\n}\r\nstatic void kfd_remove_sysfs_node_entry(struct kfd_topology_device *dev)\r\n{\r\nstruct kfd_iolink_properties *iolink;\r\nstruct kfd_cache_properties *cache;\r\nstruct kfd_mem_properties *mem;\r\nBUG_ON(!dev);\r\nif (dev->kobj_iolink) {\r\nlist_for_each_entry(iolink, &dev->io_link_props, list)\r\nif (iolink->kobj) {\r\nkfd_remove_sysfs_file(iolink->kobj,\r\n&iolink->attr);\r\niolink->kobj = NULL;\r\n}\r\nkobject_del(dev->kobj_iolink);\r\nkobject_put(dev->kobj_iolink);\r\ndev->kobj_iolink = NULL;\r\n}\r\nif (dev->kobj_cache) {\r\nlist_for_each_entry(cache, &dev->cache_props, list)\r\nif (cache->kobj) {\r\nkfd_remove_sysfs_file(cache->kobj,\r\n&cache->attr);\r\ncache->kobj = NULL;\r\n}\r\nkobject_del(dev->kobj_cache);\r\nkobject_put(dev->kobj_cache);\r\ndev->kobj_cache = NULL;\r\n}\r\nif (dev->kobj_mem) {\r\nlist_for_each_entry(mem, &dev->mem_props, list)\r\nif (mem->kobj) {\r\nkfd_remove_sysfs_file(mem->kobj, &mem->attr);\r\nmem->kobj = NULL;\r\n}\r\nkobject_del(dev->kobj_mem);\r\nkobject_put(dev->kobj_mem);\r\ndev->kobj_mem = NULL;\r\n}\r\nif (dev->kobj_node) {\r\nsysfs_remove_file(dev->kobj_node, &dev->attr_gpuid);\r\nsysfs_remove_file(dev->kobj_node, &dev->attr_name);\r\nsysfs_remove_file(dev->kobj_node, &dev->attr_props);\r\nkobject_del(dev->kobj_node);\r\nkobject_put(dev->kobj_node);\r\ndev->kobj_node = NULL;\r\n}\r\n}\r\nstatic int kfd_build_sysfs_node_entry(struct kfd_topology_device *dev,\r\nuint32_t id)\r\n{\r\nstruct kfd_iolink_properties *iolink;\r\nstruct kfd_cache_properties *cache;\r\nstruct kfd_mem_properties *mem;\r\nint ret;\r\nuint32_t i;\r\nBUG_ON(!dev);\r\nBUG_ON(dev->kobj_node);\r\ndev->kobj_node = kfd_alloc_struct(dev->kobj_node);\r\nif (!dev->kobj_node)\r\nreturn -ENOMEM;\r\nret = kobject_init_and_add(dev->kobj_node, &node_type,\r\nsys_props.kobj_nodes, "%d", id);\r\nif (ret < 0)\r\nreturn ret;\r\ndev->kobj_mem = kobject_create_and_add("mem_banks", dev->kobj_node);\r\nif (!dev->kobj_mem)\r\nreturn -ENOMEM;\r\ndev->kobj_cache = kobject_create_and_add("caches", dev->kobj_node);\r\nif (!dev->kobj_cache)\r\nreturn -ENOMEM;\r\ndev->kobj_iolink = kobject_create_and_add("io_links", dev->kobj_node);\r\nif (!dev->kobj_iolink)\r\nreturn -ENOMEM;\r\ndev->attr_gpuid.name = "gpu_id";\r\ndev->attr_gpuid.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&dev->attr_gpuid);\r\ndev->attr_name.name = "name";\r\ndev->attr_name.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&dev->attr_name);\r\ndev->attr_props.name = "properties";\r\ndev->attr_props.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&dev->attr_props);\r\nret = sysfs_create_file(dev->kobj_node, &dev->attr_gpuid);\r\nif (ret < 0)\r\nreturn ret;\r\nret = sysfs_create_file(dev->kobj_node, &dev->attr_name);\r\nif (ret < 0)\r\nreturn ret;\r\nret = sysfs_create_file(dev->kobj_node, &dev->attr_props);\r\nif (ret < 0)\r\nreturn ret;\r\ni = 0;\r\nlist_for_each_entry(mem, &dev->mem_props, list) {\r\nmem->kobj = kzalloc(sizeof(struct kobject), GFP_KERNEL);\r\nif (!mem->kobj)\r\nreturn -ENOMEM;\r\nret = kobject_init_and_add(mem->kobj, &mem_type,\r\ndev->kobj_mem, "%d", i);\r\nif (ret < 0)\r\nreturn ret;\r\nmem->attr.name = "properties";\r\nmem->attr.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&mem->attr);\r\nret = sysfs_create_file(mem->kobj, &mem->attr);\r\nif (ret < 0)\r\nreturn ret;\r\ni++;\r\n}\r\ni = 0;\r\nlist_for_each_entry(cache, &dev->cache_props, list) {\r\ncache->kobj = kzalloc(sizeof(struct kobject), GFP_KERNEL);\r\nif (!cache->kobj)\r\nreturn -ENOMEM;\r\nret = kobject_init_and_add(cache->kobj, &cache_type,\r\ndev->kobj_cache, "%d", i);\r\nif (ret < 0)\r\nreturn ret;\r\ncache->attr.name = "properties";\r\ncache->attr.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&cache->attr);\r\nret = sysfs_create_file(cache->kobj, &cache->attr);\r\nif (ret < 0)\r\nreturn ret;\r\ni++;\r\n}\r\ni = 0;\r\nlist_for_each_entry(iolink, &dev->io_link_props, list) {\r\niolink->kobj = kzalloc(sizeof(struct kobject), GFP_KERNEL);\r\nif (!iolink->kobj)\r\nreturn -ENOMEM;\r\nret = kobject_init_and_add(iolink->kobj, &iolink_type,\r\ndev->kobj_iolink, "%d", i);\r\nif (ret < 0)\r\nreturn ret;\r\niolink->attr.name = "properties";\r\niolink->attr.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&iolink->attr);\r\nret = sysfs_create_file(iolink->kobj, &iolink->attr);\r\nif (ret < 0)\r\nreturn ret;\r\ni++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int kfd_build_sysfs_node_tree(void)\r\n{\r\nstruct kfd_topology_device *dev;\r\nint ret;\r\nuint32_t i = 0;\r\nlist_for_each_entry(dev, &topology_device_list, list) {\r\nret = kfd_build_sysfs_node_entry(dev, i);\r\nif (ret < 0)\r\nreturn ret;\r\ni++;\r\n}\r\nreturn 0;\r\n}\r\nstatic void kfd_remove_sysfs_node_tree(void)\r\n{\r\nstruct kfd_topology_device *dev;\r\nlist_for_each_entry(dev, &topology_device_list, list)\r\nkfd_remove_sysfs_node_entry(dev);\r\n}\r\nstatic int kfd_topology_update_sysfs(void)\r\n{\r\nint ret;\r\npr_info("Creating topology SYSFS entries\n");\r\nif (sys_props.kobj_topology == NULL) {\r\nsys_props.kobj_topology =\r\nkfd_alloc_struct(sys_props.kobj_topology);\r\nif (!sys_props.kobj_topology)\r\nreturn -ENOMEM;\r\nret = kobject_init_and_add(sys_props.kobj_topology,\r\n&sysprops_type, &kfd_device->kobj,\r\n"topology");\r\nif (ret < 0)\r\nreturn ret;\r\nsys_props.kobj_nodes = kobject_create_and_add("nodes",\r\nsys_props.kobj_topology);\r\nif (!sys_props.kobj_nodes)\r\nreturn -ENOMEM;\r\nsys_props.attr_genid.name = "generation_id";\r\nsys_props.attr_genid.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&sys_props.attr_genid);\r\nret = sysfs_create_file(sys_props.kobj_topology,\r\n&sys_props.attr_genid);\r\nif (ret < 0)\r\nreturn ret;\r\nsys_props.attr_props.name = "system_properties";\r\nsys_props.attr_props.mode = KFD_SYSFS_FILE_MODE;\r\nsysfs_attr_init(&sys_props.attr_props);\r\nret = sysfs_create_file(sys_props.kobj_topology,\r\n&sys_props.attr_props);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\nkfd_remove_sysfs_node_tree();\r\nreturn kfd_build_sysfs_node_tree();\r\n}\r\nstatic void kfd_topology_release_sysfs(void)\r\n{\r\nkfd_remove_sysfs_node_tree();\r\nif (sys_props.kobj_topology) {\r\nsysfs_remove_file(sys_props.kobj_topology,\r\n&sys_props.attr_genid);\r\nsysfs_remove_file(sys_props.kobj_topology,\r\n&sys_props.attr_props);\r\nif (sys_props.kobj_nodes) {\r\nkobject_del(sys_props.kobj_nodes);\r\nkobject_put(sys_props.kobj_nodes);\r\nsys_props.kobj_nodes = NULL;\r\n}\r\nkobject_del(sys_props.kobj_topology);\r\nkobject_put(sys_props.kobj_topology);\r\nsys_props.kobj_topology = NULL;\r\n}\r\n}\r\nint kfd_topology_init(void)\r\n{\r\nvoid *crat_image = NULL;\r\nsize_t image_size = 0;\r\nint ret;\r\nINIT_LIST_HEAD(&topology_device_list);\r\ninit_rwsem(&topology_lock);\r\ntopology_crat_parsed = 0;\r\nmemset(&sys_props, 0, sizeof(sys_props));\r\nret = kfd_topology_get_crat_acpi(crat_image, &image_size);\r\nif (ret == 0 && image_size > 0) {\r\npr_info("Found CRAT image with size=%zd\n", image_size);\r\ncrat_image = kmalloc(image_size, GFP_KERNEL);\r\nif (!crat_image) {\r\nret = -ENOMEM;\r\npr_err("No memory for allocating CRAT image\n");\r\ngoto err;\r\n}\r\nret = kfd_topology_get_crat_acpi(crat_image, &image_size);\r\nif (ret == 0) {\r\ndown_write(&topology_lock);\r\nret = kfd_parse_crat_table(crat_image);\r\nif (ret == 0)\r\nret = kfd_topology_update_sysfs();\r\nup_write(&topology_lock);\r\n} else {\r\npr_err("Couldn't get CRAT table size from ACPI\n");\r\n}\r\nkfree(crat_image);\r\n} else if (ret == -ENODATA) {\r\nret = 0;\r\n} else {\r\npr_err("Couldn't get CRAT table size from ACPI\n");\r\n}\r\nerr:\r\npr_info("Finished initializing topology ret=%d\n", ret);\r\nreturn ret;\r\n}\r\nvoid kfd_topology_shutdown(void)\r\n{\r\nkfd_topology_release_sysfs();\r\nkfd_release_live_view();\r\n}\r\nstatic void kfd_debug_print_topology(void)\r\n{\r\nstruct kfd_topology_device *dev;\r\nuint32_t i = 0;\r\npr_info("DEBUG PRINT OF TOPOLOGY:");\r\nlist_for_each_entry(dev, &topology_device_list, list) {\r\npr_info("Node: %d\n", i);\r\npr_info("\tGPU assigned: %s\n", (dev->gpu ? "yes" : "no"));\r\npr_info("\tCPU count: %d\n", dev->node_props.cpu_cores_count);\r\npr_info("\tSIMD count: %d", dev->node_props.simd_count);\r\ni++;\r\n}\r\n}\r\nstatic uint32_t kfd_generate_gpu_id(struct kfd_dev *gpu)\r\n{\r\nuint32_t hashout;\r\nuint32_t buf[7];\r\nint i;\r\nif (!gpu)\r\nreturn 0;\r\nbuf[0] = gpu->pdev->devfn;\r\nbuf[1] = gpu->pdev->subsystem_vendor;\r\nbuf[2] = gpu->pdev->subsystem_device;\r\nbuf[3] = gpu->pdev->device;\r\nbuf[4] = gpu->pdev->bus->number;\r\nbuf[5] = (uint32_t)(gpu->kfd2kgd->get_vmem_size(gpu->kgd)\r\n& 0xffffffff);\r\nbuf[6] = (uint32_t)(gpu->kfd2kgd->get_vmem_size(gpu->kgd) >> 32);\r\nfor (i = 0, hashout = 0; i < 7; i++)\r\nhashout ^= hash_32(buf[i], KFD_GPU_ID_HASH_WIDTH);\r\nreturn hashout;\r\n}\r\nstatic struct kfd_topology_device *kfd_assign_gpu(struct kfd_dev *gpu)\r\n{\r\nstruct kfd_topology_device *dev;\r\nstruct kfd_topology_device *out_dev = NULL;\r\nBUG_ON(!gpu);\r\nlist_for_each_entry(dev, &topology_device_list, list)\r\nif (dev->gpu == NULL && dev->node_props.simd_count > 0) {\r\ndev->gpu = gpu;\r\nout_dev = dev;\r\nbreak;\r\n}\r\nreturn out_dev;\r\n}\r\nstatic void kfd_notify_gpu_change(uint32_t gpu_id, int arrival)\r\n{\r\n}\r\nint kfd_topology_add_device(struct kfd_dev *gpu)\r\n{\r\nuint32_t gpu_id;\r\nstruct kfd_topology_device *dev;\r\nint res;\r\nBUG_ON(!gpu);\r\ngpu_id = kfd_generate_gpu_id(gpu);\r\npr_debug("kfd: Adding new GPU (ID: 0x%x) to topology\n", gpu_id);\r\ndown_write(&topology_lock);\r\ndev = kfd_assign_gpu(gpu);\r\nif (!dev) {\r\npr_info("GPU was not found in the current topology. Extending.\n");\r\nkfd_debug_print_topology();\r\ndev = kfd_create_topology_device();\r\nif (!dev) {\r\nres = -ENOMEM;\r\ngoto err;\r\n}\r\ndev->gpu = gpu;\r\nif (kfd_topology_update_sysfs() < 0)\r\nkfd_topology_release_sysfs();\r\n}\r\ndev->gpu_id = gpu_id;\r\ngpu->id = gpu_id;\r\ndev->node_props.vendor_id = gpu->pdev->vendor;\r\ndev->node_props.device_id = gpu->pdev->device;\r\ndev->node_props.location_id = (gpu->pdev->bus->number << 24) +\r\n(gpu->pdev->devfn & 0xffffff);\r\nif (dev->gpu->device_info->asic_family == CHIP_CARRIZO) {\r\ndev->node_props.capability |= HSA_CAP_DOORBELL_PACKET_TYPE;\r\npr_info("amdkfd: adding doorbell packet type capability\n");\r\n}\r\nres = 0;\r\nerr:\r\nup_write(&topology_lock);\r\nif (res == 0)\r\nkfd_notify_gpu_change(gpu_id, 1);\r\nreturn res;\r\n}\r\nint kfd_topology_remove_device(struct kfd_dev *gpu)\r\n{\r\nstruct kfd_topology_device *dev;\r\nuint32_t gpu_id;\r\nint res = -ENODEV;\r\nBUG_ON(!gpu);\r\ndown_write(&topology_lock);\r\nlist_for_each_entry(dev, &topology_device_list, list)\r\nif (dev->gpu == gpu) {\r\ngpu_id = dev->gpu_id;\r\nkfd_remove_sysfs_node_entry(dev);\r\nkfd_release_topology_device(dev);\r\nres = 0;\r\nif (kfd_topology_update_sysfs() < 0)\r\nkfd_topology_release_sysfs();\r\nbreak;\r\n}\r\nup_write(&topology_lock);\r\nif (res == 0)\r\nkfd_notify_gpu_change(gpu_id, 0);\r\nreturn res;\r\n}\r\nstruct kfd_dev *kfd_topology_enum_kfd_devices(uint8_t idx)\r\n{\r\nstruct kfd_topology_device *top_dev;\r\nstruct kfd_dev *device = NULL;\r\nuint8_t device_idx = 0;\r\ndown_read(&topology_lock);\r\nlist_for_each_entry(top_dev, &topology_device_list, list) {\r\nif (device_idx == idx) {\r\ndevice = top_dev->gpu;\r\nbreak;\r\n}\r\ndevice_idx++;\r\n}\r\nup_read(&topology_lock);\r\nreturn device;\r\n}
