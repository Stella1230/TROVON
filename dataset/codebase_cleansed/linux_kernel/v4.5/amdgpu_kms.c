static inline bool amdgpu_has_atpx(void) { return false; }\r\nint amdgpu_driver_unload_kms(struct drm_device *dev)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nif (adev == NULL)\r\nreturn 0;\r\nif (adev->rmmio == NULL)\r\ngoto done_free;\r\npm_runtime_get_sync(dev->dev);\r\namdgpu_amdkfd_device_fini(adev);\r\namdgpu_acpi_fini(adev);\r\namdgpu_device_fini(adev);\r\ndone_free:\r\nkfree(adev);\r\ndev->dev_private = NULL;\r\nreturn 0;\r\n}\r\nint amdgpu_driver_load_kms(struct drm_device *dev, unsigned long flags)\r\n{\r\nstruct amdgpu_device *adev;\r\nint r, acpi_status;\r\nadev = kzalloc(sizeof(struct amdgpu_device), GFP_KERNEL);\r\nif (adev == NULL) {\r\nreturn -ENOMEM;\r\n}\r\ndev->dev_private = (void *)adev;\r\nif ((amdgpu_runtime_pm != 0) &&\r\namdgpu_has_atpx() &&\r\n((flags & AMD_IS_APU) == 0))\r\nflags |= AMD_IS_PX;\r\nr = amdgpu_device_init(adev, dev, dev->pdev, flags);\r\nif (r) {\r\ndev_err(&dev->pdev->dev, "Fatal error during GPU init\n");\r\ngoto out;\r\n}\r\nif (!r) {\r\nacpi_status = amdgpu_acpi_init(adev);\r\nif (acpi_status)\r\ndev_dbg(&dev->pdev->dev,\r\n"Error during ACPI methods call\n");\r\n}\r\namdgpu_amdkfd_load_interface(adev);\r\namdgpu_amdkfd_device_probe(adev);\r\namdgpu_amdkfd_device_init(adev);\r\nif (amdgpu_device_is_px(dev)) {\r\npm_runtime_use_autosuspend(dev->dev);\r\npm_runtime_set_autosuspend_delay(dev->dev, 5000);\r\npm_runtime_set_active(dev->dev);\r\npm_runtime_allow(dev->dev);\r\npm_runtime_mark_last_busy(dev->dev);\r\npm_runtime_put_autosuspend(dev->dev);\r\n}\r\nout:\r\nif (r)\r\namdgpu_driver_unload_kms(dev);\r\nreturn r;\r\n}\r\nstatic int amdgpu_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nstruct drm_amdgpu_info *info = data;\r\nstruct amdgpu_mode_info *minfo = &adev->mode_info;\r\nvoid __user *out = (void __user *)(long)info->return_pointer;\r\nuint32_t size = info->return_size;\r\nstruct drm_crtc *crtc;\r\nuint32_t ui32 = 0;\r\nuint64_t ui64 = 0;\r\nint i, found;\r\nif (!info->return_size || !info->return_pointer)\r\nreturn -EINVAL;\r\nswitch (info->query) {\r\ncase AMDGPU_INFO_ACCEL_WORKING:\r\nui32 = adev->accel_working;\r\nreturn copy_to_user(out, &ui32, min(size, 4u)) ? -EFAULT : 0;\r\ncase AMDGPU_INFO_CRTC_FROM_ID:\r\nfor (i = 0, found = 0; i < adev->mode_info.num_crtc; i++) {\r\ncrtc = (struct drm_crtc *)minfo->crtcs[i];\r\nif (crtc && crtc->base.id == info->mode_crtc.id) {\r\nstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\r\nui32 = amdgpu_crtc->crtc_id;\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nDRM_DEBUG_KMS("unknown crtc id %d\n", info->mode_crtc.id);\r\nreturn -EINVAL;\r\n}\r\nreturn copy_to_user(out, &ui32, min(size, 4u)) ? -EFAULT : 0;\r\ncase AMDGPU_INFO_HW_IP_INFO: {\r\nstruct drm_amdgpu_info_hw_ip ip = {};\r\nenum amd_ip_block_type type;\r\nuint32_t ring_mask = 0;\r\nuint32_t ib_start_alignment = 0;\r\nuint32_t ib_size_alignment = 0;\r\nif (info->query_hw_ip.ip_instance >= AMDGPU_HW_IP_INSTANCE_MAX_COUNT)\r\nreturn -EINVAL;\r\nswitch (info->query_hw_ip.type) {\r\ncase AMDGPU_HW_IP_GFX:\r\ntype = AMD_IP_BLOCK_TYPE_GFX;\r\nfor (i = 0; i < adev->gfx.num_gfx_rings; i++)\r\nring_mask |= ((adev->gfx.gfx_ring[i].ready ? 1 : 0) << i);\r\nib_start_alignment = AMDGPU_GPU_PAGE_SIZE;\r\nib_size_alignment = 8;\r\nbreak;\r\ncase AMDGPU_HW_IP_COMPUTE:\r\ntype = AMD_IP_BLOCK_TYPE_GFX;\r\nfor (i = 0; i < adev->gfx.num_compute_rings; i++)\r\nring_mask |= ((adev->gfx.compute_ring[i].ready ? 1 : 0) << i);\r\nib_start_alignment = AMDGPU_GPU_PAGE_SIZE;\r\nib_size_alignment = 8;\r\nbreak;\r\ncase AMDGPU_HW_IP_DMA:\r\ntype = AMD_IP_BLOCK_TYPE_SDMA;\r\nfor (i = 0; i < adev->sdma.num_instances; i++)\r\nring_mask |= ((adev->sdma.instance[i].ring.ready ? 1 : 0) << i);\r\nib_start_alignment = AMDGPU_GPU_PAGE_SIZE;\r\nib_size_alignment = 1;\r\nbreak;\r\ncase AMDGPU_HW_IP_UVD:\r\ntype = AMD_IP_BLOCK_TYPE_UVD;\r\nring_mask = adev->uvd.ring.ready ? 1 : 0;\r\nib_start_alignment = AMDGPU_GPU_PAGE_SIZE;\r\nib_size_alignment = 8;\r\nbreak;\r\ncase AMDGPU_HW_IP_VCE:\r\ntype = AMD_IP_BLOCK_TYPE_VCE;\r\nfor (i = 0; i < AMDGPU_MAX_VCE_RINGS; i++)\r\nring_mask |= ((adev->vce.ring[i].ready ? 1 : 0) << i);\r\nib_start_alignment = AMDGPU_GPU_PAGE_SIZE;\r\nib_size_alignment = 8;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < adev->num_ip_blocks; i++) {\r\nif (adev->ip_blocks[i].type == type &&\r\nadev->ip_block_status[i].valid) {\r\nip.hw_ip_version_major = adev->ip_blocks[i].major;\r\nip.hw_ip_version_minor = adev->ip_blocks[i].minor;\r\nip.capabilities_flags = 0;\r\nip.available_rings = ring_mask;\r\nip.ib_start_alignment = ib_start_alignment;\r\nip.ib_size_alignment = ib_size_alignment;\r\nbreak;\r\n}\r\n}\r\nreturn copy_to_user(out, &ip,\r\nmin((size_t)size, sizeof(ip))) ? -EFAULT : 0;\r\n}\r\ncase AMDGPU_INFO_HW_IP_COUNT: {\r\nenum amd_ip_block_type type;\r\nuint32_t count = 0;\r\nswitch (info->query_hw_ip.type) {\r\ncase AMDGPU_HW_IP_GFX:\r\ntype = AMD_IP_BLOCK_TYPE_GFX;\r\nbreak;\r\ncase AMDGPU_HW_IP_COMPUTE:\r\ntype = AMD_IP_BLOCK_TYPE_GFX;\r\nbreak;\r\ncase AMDGPU_HW_IP_DMA:\r\ntype = AMD_IP_BLOCK_TYPE_SDMA;\r\nbreak;\r\ncase AMDGPU_HW_IP_UVD:\r\ntype = AMD_IP_BLOCK_TYPE_UVD;\r\nbreak;\r\ncase AMDGPU_HW_IP_VCE:\r\ntype = AMD_IP_BLOCK_TYPE_VCE;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < adev->num_ip_blocks; i++)\r\nif (adev->ip_blocks[i].type == type &&\r\nadev->ip_block_status[i].valid &&\r\ncount < AMDGPU_HW_IP_INSTANCE_MAX_COUNT)\r\ncount++;\r\nreturn copy_to_user(out, &count, min(size, 4u)) ? -EFAULT : 0;\r\n}\r\ncase AMDGPU_INFO_TIMESTAMP:\r\nui64 = amdgpu_asic_get_gpu_clock_counter(adev);\r\nreturn copy_to_user(out, &ui64, min(size, 8u)) ? -EFAULT : 0;\r\ncase AMDGPU_INFO_FW_VERSION: {\r\nstruct drm_amdgpu_info_firmware fw_info;\r\nif (info->query_fw.ip_instance != 0)\r\nreturn -EINVAL;\r\nswitch (info->query_fw.fw_type) {\r\ncase AMDGPU_INFO_FW_VCE:\r\nfw_info.ver = adev->vce.fw_version;\r\nfw_info.feature = adev->vce.fb_version;\r\nbreak;\r\ncase AMDGPU_INFO_FW_UVD:\r\nfw_info.ver = 0;\r\nfw_info.feature = 0;\r\nbreak;\r\ncase AMDGPU_INFO_FW_GMC:\r\nfw_info.ver = adev->mc.fw_version;\r\nfw_info.feature = 0;\r\nbreak;\r\ncase AMDGPU_INFO_FW_GFX_ME:\r\nfw_info.ver = adev->gfx.me_fw_version;\r\nfw_info.feature = adev->gfx.me_feature_version;\r\nbreak;\r\ncase AMDGPU_INFO_FW_GFX_PFP:\r\nfw_info.ver = adev->gfx.pfp_fw_version;\r\nfw_info.feature = adev->gfx.pfp_feature_version;\r\nbreak;\r\ncase AMDGPU_INFO_FW_GFX_CE:\r\nfw_info.ver = adev->gfx.ce_fw_version;\r\nfw_info.feature = adev->gfx.ce_feature_version;\r\nbreak;\r\ncase AMDGPU_INFO_FW_GFX_RLC:\r\nfw_info.ver = adev->gfx.rlc_fw_version;\r\nfw_info.feature = adev->gfx.rlc_feature_version;\r\nbreak;\r\ncase AMDGPU_INFO_FW_GFX_MEC:\r\nif (info->query_fw.index == 0) {\r\nfw_info.ver = adev->gfx.mec_fw_version;\r\nfw_info.feature = adev->gfx.mec_feature_version;\r\n} else if (info->query_fw.index == 1) {\r\nfw_info.ver = adev->gfx.mec2_fw_version;\r\nfw_info.feature = adev->gfx.mec2_feature_version;\r\n} else\r\nreturn -EINVAL;\r\nbreak;\r\ncase AMDGPU_INFO_FW_SMC:\r\nfw_info.ver = adev->pm.fw_version;\r\nfw_info.feature = 0;\r\nbreak;\r\ncase AMDGPU_INFO_FW_SDMA:\r\nif (info->query_fw.index >= adev->sdma.num_instances)\r\nreturn -EINVAL;\r\nfw_info.ver = adev->sdma.instance[info->query_fw.index].fw_version;\r\nfw_info.feature = adev->sdma.instance[info->query_fw.index].feature_version;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn copy_to_user(out, &fw_info,\r\nmin((size_t)size, sizeof(fw_info))) ? -EFAULT : 0;\r\n}\r\ncase AMDGPU_INFO_NUM_BYTES_MOVED:\r\nui64 = atomic64_read(&adev->num_bytes_moved);\r\nreturn copy_to_user(out, &ui64, min(size, 8u)) ? -EFAULT : 0;\r\ncase AMDGPU_INFO_VRAM_USAGE:\r\nui64 = atomic64_read(&adev->vram_usage);\r\nreturn copy_to_user(out, &ui64, min(size, 8u)) ? -EFAULT : 0;\r\ncase AMDGPU_INFO_VIS_VRAM_USAGE:\r\nui64 = atomic64_read(&adev->vram_vis_usage);\r\nreturn copy_to_user(out, &ui64, min(size, 8u)) ? -EFAULT : 0;\r\ncase AMDGPU_INFO_GTT_USAGE:\r\nui64 = atomic64_read(&adev->gtt_usage);\r\nreturn copy_to_user(out, &ui64, min(size, 8u)) ? -EFAULT : 0;\r\ncase AMDGPU_INFO_GDS_CONFIG: {\r\nstruct drm_amdgpu_info_gds gds_info;\r\nmemset(&gds_info, 0, sizeof(gds_info));\r\ngds_info.gds_gfx_partition_size = adev->gds.mem.gfx_partition_size >> AMDGPU_GDS_SHIFT;\r\ngds_info.compute_partition_size = adev->gds.mem.cs_partition_size >> AMDGPU_GDS_SHIFT;\r\ngds_info.gds_total_size = adev->gds.mem.total_size >> AMDGPU_GDS_SHIFT;\r\ngds_info.gws_per_gfx_partition = adev->gds.gws.gfx_partition_size >> AMDGPU_GWS_SHIFT;\r\ngds_info.gws_per_compute_partition = adev->gds.gws.cs_partition_size >> AMDGPU_GWS_SHIFT;\r\ngds_info.oa_per_gfx_partition = adev->gds.oa.gfx_partition_size >> AMDGPU_OA_SHIFT;\r\ngds_info.oa_per_compute_partition = adev->gds.oa.cs_partition_size >> AMDGPU_OA_SHIFT;\r\nreturn copy_to_user(out, &gds_info,\r\nmin((size_t)size, sizeof(gds_info))) ? -EFAULT : 0;\r\n}\r\ncase AMDGPU_INFO_VRAM_GTT: {\r\nstruct drm_amdgpu_info_vram_gtt vram_gtt;\r\nvram_gtt.vram_size = adev->mc.real_vram_size;\r\nvram_gtt.vram_cpu_accessible_size = adev->mc.visible_vram_size;\r\nvram_gtt.vram_cpu_accessible_size -= adev->vram_pin_size;\r\nvram_gtt.gtt_size = adev->mc.gtt_size;\r\nvram_gtt.gtt_size -= adev->gart_pin_size;\r\nreturn copy_to_user(out, &vram_gtt,\r\nmin((size_t)size, sizeof(vram_gtt))) ? -EFAULT : 0;\r\n}\r\ncase AMDGPU_INFO_READ_MMR_REG: {\r\nunsigned n, alloc_size;\r\nuint32_t *regs;\r\nunsigned se_num = (info->read_mmr_reg.instance >>\r\nAMDGPU_INFO_MMR_SE_INDEX_SHIFT) &\r\nAMDGPU_INFO_MMR_SE_INDEX_MASK;\r\nunsigned sh_num = (info->read_mmr_reg.instance >>\r\nAMDGPU_INFO_MMR_SH_INDEX_SHIFT) &\r\nAMDGPU_INFO_MMR_SH_INDEX_MASK;\r\nif (se_num == AMDGPU_INFO_MMR_SE_INDEX_MASK)\r\nse_num = 0xffffffff;\r\nif (sh_num == AMDGPU_INFO_MMR_SH_INDEX_MASK)\r\nsh_num = 0xffffffff;\r\nregs = kmalloc_array(info->read_mmr_reg.count, sizeof(*regs), GFP_KERNEL);\r\nif (!regs)\r\nreturn -ENOMEM;\r\nalloc_size = info->read_mmr_reg.count * sizeof(*regs);\r\nfor (i = 0; i < info->read_mmr_reg.count; i++)\r\nif (amdgpu_asic_read_register(adev, se_num, sh_num,\r\ninfo->read_mmr_reg.dword_offset + i,\r\n&regs[i])) {\r\nDRM_DEBUG_KMS("unallowed offset %#x\n",\r\ninfo->read_mmr_reg.dword_offset + i);\r\nkfree(regs);\r\nreturn -EFAULT;\r\n}\r\nn = copy_to_user(out, regs, min(size, alloc_size));\r\nkfree(regs);\r\nreturn n ? -EFAULT : 0;\r\n}\r\ncase AMDGPU_INFO_DEV_INFO: {\r\nstruct drm_amdgpu_info_device dev_info = {};\r\nstruct amdgpu_cu_info cu_info;\r\ndev_info.device_id = dev->pdev->device;\r\ndev_info.chip_rev = adev->rev_id;\r\ndev_info.external_rev = adev->external_rev_id;\r\ndev_info.pci_rev = dev->pdev->revision;\r\ndev_info.family = adev->family;\r\ndev_info.num_shader_engines = adev->gfx.config.max_shader_engines;\r\ndev_info.num_shader_arrays_per_engine = adev->gfx.config.max_sh_per_se;\r\ndev_info.gpu_counter_freq = amdgpu_asic_get_xclk(adev) * 10;\r\nif (adev->pm.dpm_enabled) {\r\ndev_info.max_engine_clock =\r\nadev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk * 10;\r\ndev_info.max_memory_clock =\r\nadev->pm.dpm.dyn_state.max_clock_voltage_on_ac.mclk * 10;\r\n} else {\r\ndev_info.max_engine_clock = adev->pm.default_sclk * 10;\r\ndev_info.max_memory_clock = adev->pm.default_mclk * 10;\r\n}\r\ndev_info.enabled_rb_pipes_mask = adev->gfx.config.backend_enable_mask;\r\ndev_info.num_rb_pipes = adev->gfx.config.max_backends_per_se *\r\nadev->gfx.config.max_shader_engines;\r\ndev_info.num_hw_gfx_contexts = adev->gfx.config.max_hw_contexts;\r\ndev_info._pad = 0;\r\ndev_info.ids_flags = 0;\r\nif (adev->flags & AMD_IS_APU)\r\ndev_info.ids_flags |= AMDGPU_IDS_FLAGS_FUSION;\r\ndev_info.virtual_address_offset = AMDGPU_VA_RESERVED_SIZE;\r\ndev_info.virtual_address_max = (uint64_t)adev->vm_manager.max_pfn * AMDGPU_GPU_PAGE_SIZE;\r\ndev_info.virtual_address_alignment = max((int)PAGE_SIZE, AMDGPU_GPU_PAGE_SIZE);\r\ndev_info.pte_fragment_size = (1 << AMDGPU_LOG2_PAGES_PER_FRAG) *\r\nAMDGPU_GPU_PAGE_SIZE;\r\ndev_info.gart_page_size = AMDGPU_GPU_PAGE_SIZE;\r\namdgpu_asic_get_cu_info(adev, &cu_info);\r\ndev_info.cu_active_number = cu_info.number;\r\ndev_info.cu_ao_mask = cu_info.ao_cu_mask;\r\ndev_info.ce_ram_size = adev->gfx.ce_ram_size;\r\nmemcpy(&dev_info.cu_bitmap[0], &cu_info.bitmap[0], sizeof(cu_info.bitmap));\r\ndev_info.vram_type = adev->mc.vram_type;\r\ndev_info.vram_bit_width = adev->mc.vram_width;\r\ndev_info.vce_harvest_config = adev->vce.harvest_config;\r\nreturn copy_to_user(out, &dev_info,\r\nmin((size_t)size, sizeof(dev_info))) ? -EFAULT : 0;\r\n}\r\ndefault:\r\nDRM_DEBUG_KMS("Invalid request %d\n", info->query);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nvoid amdgpu_driver_lastclose_kms(struct drm_device *dev)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\namdgpu_fbdev_restore_mode(adev);\r\nvga_switcheroo_process_delayed_switch();\r\n}\r\nint amdgpu_driver_open_kms(struct drm_device *dev, struct drm_file *file_priv)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nstruct amdgpu_fpriv *fpriv;\r\nint r;\r\nfile_priv->driver_priv = NULL;\r\nr = pm_runtime_get_sync(dev->dev);\r\nif (r < 0)\r\nreturn r;\r\nfpriv = kzalloc(sizeof(*fpriv), GFP_KERNEL);\r\nif (unlikely(!fpriv))\r\nreturn -ENOMEM;\r\nr = amdgpu_vm_init(adev, &fpriv->vm);\r\nif (r)\r\ngoto error_free;\r\nmutex_init(&fpriv->bo_list_lock);\r\nidr_init(&fpriv->bo_list_handles);\r\namdgpu_ctx_mgr_init(&fpriv->ctx_mgr);\r\nfile_priv->driver_priv = fpriv;\r\npm_runtime_mark_last_busy(dev->dev);\r\npm_runtime_put_autosuspend(dev->dev);\r\nreturn 0;\r\nerror_free:\r\nkfree(fpriv);\r\nreturn r;\r\n}\r\nvoid amdgpu_driver_postclose_kms(struct drm_device *dev,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nstruct amdgpu_fpriv *fpriv = file_priv->driver_priv;\r\nstruct amdgpu_bo_list *list;\r\nint handle;\r\nif (!fpriv)\r\nreturn;\r\namdgpu_ctx_mgr_fini(&fpriv->ctx_mgr);\r\namdgpu_vm_fini(adev, &fpriv->vm);\r\nidr_for_each_entry(&fpriv->bo_list_handles, list, handle)\r\namdgpu_bo_list_free(list);\r\nidr_destroy(&fpriv->bo_list_handles);\r\nmutex_destroy(&fpriv->bo_list_lock);\r\nkfree(fpriv);\r\nfile_priv->driver_priv = NULL;\r\n}\r\nvoid amdgpu_driver_preclose_kms(struct drm_device *dev,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\namdgpu_uvd_free_handles(adev, file_priv);\r\namdgpu_vce_free_handles(adev, file_priv);\r\n}\r\nu32 amdgpu_get_vblank_counter_kms(struct drm_device *dev, unsigned int pipe)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nint vpos, hpos, stat;\r\nu32 count;\r\nif (pipe >= adev->mode_info.num_crtc) {\r\nDRM_ERROR("Invalid crtc %u\n", pipe);\r\nreturn -EINVAL;\r\n}\r\nif (adev->mode_info.crtcs[pipe]) {\r\ndo {\r\ncount = amdgpu_display_vblank_get_counter(adev, pipe);\r\nstat = amdgpu_get_crtc_scanoutpos(\r\ndev, pipe, GET_DISTANCE_TO_VBLANKSTART,\r\n&vpos, &hpos, NULL, NULL,\r\n&adev->mode_info.crtcs[pipe]->base.hwmode);\r\n} while (count != amdgpu_display_vblank_get_counter(adev, pipe));\r\nif (((stat & (DRM_SCANOUTPOS_VALID | DRM_SCANOUTPOS_ACCURATE)) !=\r\n(DRM_SCANOUTPOS_VALID | DRM_SCANOUTPOS_ACCURATE))) {\r\nDRM_DEBUG_VBL("Query failed! stat %d\n", stat);\r\n} else {\r\nDRM_DEBUG_VBL("crtc %d: dist from vblank start %d\n",\r\npipe, vpos);\r\nif (vpos >= 0)\r\ncount++;\r\n}\r\n} else {\r\ncount = amdgpu_display_vblank_get_counter(adev, pipe);\r\nDRM_DEBUG_VBL("NULL mode info! Returned count may be wrong.\n");\r\n}\r\nreturn count;\r\n}\r\nint amdgpu_enable_vblank_kms(struct drm_device *dev, unsigned int pipe)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nint idx = amdgpu_crtc_idx_to_irq_type(adev, pipe);\r\nreturn amdgpu_irq_get(adev, &adev->crtc_irq, idx);\r\n}\r\nvoid amdgpu_disable_vblank_kms(struct drm_device *dev, unsigned int pipe)\r\n{\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nint idx = amdgpu_crtc_idx_to_irq_type(adev, pipe);\r\namdgpu_irq_put(adev, &adev->crtc_irq, idx);\r\n}\r\nint amdgpu_get_vblank_timestamp_kms(struct drm_device *dev, unsigned int pipe,\r\nint *max_error,\r\nstruct timeval *vblank_time,\r\nunsigned flags)\r\n{\r\nstruct drm_crtc *crtc;\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nif (pipe >= dev->num_crtcs) {\r\nDRM_ERROR("Invalid crtc %u\n", pipe);\r\nreturn -EINVAL;\r\n}\r\ncrtc = &adev->mode_info.crtcs[pipe]->base;\r\nreturn drm_calc_vbltimestamp_from_scanoutpos(dev, pipe, max_error,\r\nvblank_time, flags,\r\n&crtc->hwmode);\r\n}
