void scif_rma_ep_init(struct scif_endpt *ep)\r\n{\r\nstruct scif_endpt_rma_info *rma = &ep->rma_info;\r\nmutex_init(&rma->rma_lock);\r\ninit_iova_domain(&rma->iovad, PAGE_SIZE, SCIF_IOVA_START_PFN,\r\nSCIF_DMA_64BIT_PFN);\r\nspin_lock_init(&rma->tc_lock);\r\nmutex_init(&rma->mmn_lock);\r\nINIT_LIST_HEAD(&rma->reg_list);\r\nINIT_LIST_HEAD(&rma->remote_reg_list);\r\natomic_set(&rma->tw_refcount, 0);\r\natomic_set(&rma->tcw_refcount, 0);\r\natomic_set(&rma->tcw_total_pages, 0);\r\natomic_set(&rma->fence_refcount, 0);\r\nrma->async_list_del = 0;\r\nrma->dma_chan = NULL;\r\nINIT_LIST_HEAD(&rma->mmn_list);\r\nINIT_LIST_HEAD(&rma->vma_list);\r\ninit_waitqueue_head(&rma->markwq);\r\n}\r\nint scif_rma_ep_can_uninit(struct scif_endpt *ep)\r\n{\r\nint ret = 0;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nif (list_empty(&ep->rma_info.reg_list) &&\r\nlist_empty(&ep->rma_info.remote_reg_list) &&\r\nlist_empty(&ep->rma_info.mmn_list) &&\r\n!atomic_read(&ep->rma_info.tw_refcount) &&\r\n!atomic_read(&ep->rma_info.tcw_refcount) &&\r\n!atomic_read(&ep->rma_info.fence_refcount))\r\nret = 1;\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nreturn ret;\r\n}\r\nstatic struct scif_pinned_pages *\r\nscif_create_pinned_pages(int nr_pages, int prot)\r\n{\r\nstruct scif_pinned_pages *pin;\r\nmight_sleep();\r\npin = scif_zalloc(sizeof(*pin));\r\nif (!pin)\r\ngoto error;\r\npin->pages = scif_zalloc(nr_pages * sizeof(*pin->pages));\r\nif (!pin->pages)\r\ngoto error_free_pinned_pages;\r\npin->prot = prot;\r\npin->magic = SCIFEP_MAGIC;\r\nreturn pin;\r\nerror_free_pinned_pages:\r\nscif_free(pin, sizeof(*pin));\r\nerror:\r\nreturn NULL;\r\n}\r\nstatic int scif_destroy_pinned_pages(struct scif_pinned_pages *pin)\r\n{\r\nint j;\r\nint writeable = pin->prot & SCIF_PROT_WRITE;\r\nint kernel = SCIF_MAP_KERNEL & pin->map_flags;\r\nfor (j = 0; j < pin->nr_pages; j++) {\r\nif (pin->pages[j] && !kernel) {\r\nif (writeable)\r\nSetPageDirty(pin->pages[j]);\r\nput_page(pin->pages[j]);\r\n}\r\n}\r\nscif_free(pin->pages,\r\npin->nr_pages * sizeof(*pin->pages));\r\nscif_free(pin, sizeof(*pin));\r\nreturn 0;\r\n}\r\nstruct scif_window *scif_create_window(struct scif_endpt *ep, int nr_pages,\r\ns64 offset, bool temp)\r\n{\r\nstruct scif_window *window;\r\nmight_sleep();\r\nwindow = scif_zalloc(sizeof(*window));\r\nif (!window)\r\ngoto error;\r\nwindow->dma_addr = scif_zalloc(nr_pages * sizeof(*window->dma_addr));\r\nif (!window->dma_addr)\r\ngoto error_free_window;\r\nwindow->num_pages = scif_zalloc(nr_pages * sizeof(*window->num_pages));\r\nif (!window->num_pages)\r\ngoto error_free_window;\r\nwindow->offset = offset;\r\nwindow->ep = (u64)ep;\r\nwindow->magic = SCIFEP_MAGIC;\r\nwindow->reg_state = OP_IDLE;\r\ninit_waitqueue_head(&window->regwq);\r\nwindow->unreg_state = OP_IDLE;\r\ninit_waitqueue_head(&window->unregwq);\r\nINIT_LIST_HEAD(&window->list);\r\nwindow->type = SCIF_WINDOW_SELF;\r\nwindow->temp = temp;\r\nreturn window;\r\nerror_free_window:\r\nscif_free(window->dma_addr,\r\nnr_pages * sizeof(*window->dma_addr));\r\nscif_free(window, sizeof(*window));\r\nerror:\r\nreturn NULL;\r\n}\r\nstatic void scif_destroy_incomplete_window(struct scif_endpt *ep,\r\nstruct scif_window *window)\r\n{\r\nint err;\r\nint nr_pages = window->nr_pages;\r\nstruct scif_allocmsg *alloc = &window->alloc_handle;\r\nstruct scifmsg msg;\r\nretry:\r\nerr = wait_event_timeout(alloc->allocwq,\r\nalloc->state != OP_IN_PROGRESS,\r\nSCIF_NODE_ALIVE_TIMEOUT);\r\nif (!err && scifdev_alive(ep))\r\ngoto retry;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nif (alloc->state == OP_COMPLETED) {\r\nmsg.uop = SCIF_FREE_VIRT;\r\nmsg.src = ep->port;\r\nmsg.payload[0] = ep->remote_ep;\r\nmsg.payload[1] = window->alloc_handle.vaddr;\r\nmsg.payload[2] = (u64)window;\r\nmsg.payload[3] = SCIF_REGISTER;\r\n_scif_nodeqp_send(ep->remote_dev, &msg);\r\n}\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nscif_free_window_offset(ep, window, window->offset);\r\nscif_free(window->dma_addr, nr_pages * sizeof(*window->dma_addr));\r\nscif_free(window->num_pages, nr_pages * sizeof(*window->num_pages));\r\nscif_free(window, sizeof(*window));\r\n}\r\nvoid scif_unmap_window(struct scif_dev *remote_dev, struct scif_window *window)\r\n{\r\nint j;\r\nif (scif_is_iommu_enabled() && !scifdev_self(remote_dev)) {\r\nif (window->st) {\r\ndma_unmap_sg(&remote_dev->sdev->dev,\r\nwindow->st->sgl, window->st->nents,\r\nDMA_BIDIRECTIONAL);\r\nsg_free_table(window->st);\r\nkfree(window->st);\r\nwindow->st = NULL;\r\n}\r\n} else {\r\nfor (j = 0; j < window->nr_contig_chunks; j++) {\r\nif (window->dma_addr[j]) {\r\nscif_unmap_single(window->dma_addr[j],\r\nremote_dev,\r\nwindow->num_pages[j] <<\r\nPAGE_SHIFT);\r\nwindow->dma_addr[j] = 0x0;\r\n}\r\n}\r\n}\r\n}\r\nstatic inline struct mm_struct *__scif_acquire_mm(void)\r\n{\r\nif (scif_ulimit_check)\r\nreturn get_task_mm(current);\r\nreturn NULL;\r\n}\r\nstatic inline void __scif_release_mm(struct mm_struct *mm)\r\n{\r\nif (mm)\r\nmmput(mm);\r\n}\r\nstatic inline int\r\n__scif_dec_pinned_vm_lock(struct mm_struct *mm,\r\nint nr_pages, bool try_lock)\r\n{\r\nif (!mm || !nr_pages || !scif_ulimit_check)\r\nreturn 0;\r\nif (try_lock) {\r\nif (!down_write_trylock(&mm->mmap_sem)) {\r\ndev_err(scif_info.mdev.this_device,\r\n"%s %d err\n", __func__, __LINE__);\r\nreturn -1;\r\n}\r\n} else {\r\ndown_write(&mm->mmap_sem);\r\n}\r\nmm->pinned_vm -= nr_pages;\r\nup_write(&mm->mmap_sem);\r\nreturn 0;\r\n}\r\nstatic inline int __scif_check_inc_pinned_vm(struct mm_struct *mm,\r\nint nr_pages)\r\n{\r\nunsigned long locked, lock_limit;\r\nif (!mm || !nr_pages || !scif_ulimit_check)\r\nreturn 0;\r\nlocked = nr_pages;\r\nlocked += mm->pinned_vm;\r\nlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\r\nif ((locked > lock_limit) && !capable(CAP_IPC_LOCK)) {\r\ndev_err(scif_info.mdev.this_device,\r\n"locked(%lu) > lock_limit(%lu)\n",\r\nlocked, lock_limit);\r\nreturn -ENOMEM;\r\n}\r\nmm->pinned_vm = locked;\r\nreturn 0;\r\n}\r\nint scif_destroy_window(struct scif_endpt *ep, struct scif_window *window)\r\n{\r\nint j;\r\nstruct scif_pinned_pages *pinned_pages = window->pinned_pages;\r\nint nr_pages = window->nr_pages;\r\nmight_sleep();\r\nif (!window->temp && window->mm) {\r\n__scif_dec_pinned_vm_lock(window->mm, window->nr_pages, 0);\r\n__scif_release_mm(window->mm);\r\nwindow->mm = NULL;\r\n}\r\nscif_free_window_offset(ep, window, window->offset);\r\nscif_unmap_window(ep->remote_dev, window);\r\nj = atomic_sub_return(1, &pinned_pages->ref_count);\r\nif (j < 0)\r\ndev_err(scif_info.mdev.this_device,\r\n"%s %d incorrect ref count %d\n",\r\n__func__, __LINE__, j);\r\nif (!j)\r\nscif_destroy_pinned_pages(window->pinned_pages);\r\nscif_free(window->dma_addr, nr_pages * sizeof(*window->dma_addr));\r\nscif_free(window->num_pages, nr_pages * sizeof(*window->num_pages));\r\nwindow->magic = 0;\r\nscif_free(window, sizeof(*window));\r\nreturn 0;\r\n}\r\nstatic int scif_create_remote_lookup(struct scif_dev *remote_dev,\r\nstruct scif_window *window)\r\n{\r\nint i, j, err = 0;\r\nint nr_pages = window->nr_pages;\r\nbool vmalloc_dma_phys, vmalloc_num_pages;\r\nmight_sleep();\r\nerr = scif_map_single(&window->mapped_offset,\r\nwindow, remote_dev, sizeof(*window));\r\nif (err)\r\ngoto error_window;\r\nwindow->nr_lookup = ALIGN(nr_pages * PAGE_SIZE,\r\n((2) * 1024 * 1024)) >> 21;\r\nwindow->dma_addr_lookup.lookup =\r\nscif_alloc_coherent(&window->dma_addr_lookup.offset,\r\nremote_dev, window->nr_lookup *\r\nsizeof(*window->dma_addr_lookup.lookup),\r\nGFP_KERNEL | __GFP_ZERO);\r\nif (!window->dma_addr_lookup.lookup) {\r\nerr = -ENOMEM;\r\ngoto error_window;\r\n}\r\nwindow->num_pages_lookup.lookup =\r\nscif_alloc_coherent(&window->num_pages_lookup.offset,\r\nremote_dev, window->nr_lookup *\r\nsizeof(*window->num_pages_lookup.lookup),\r\nGFP_KERNEL | __GFP_ZERO);\r\nif (!window->num_pages_lookup.lookup) {\r\nerr = -ENOMEM;\r\ngoto error_window;\r\n}\r\nvmalloc_dma_phys = is_vmalloc_addr(&window->dma_addr[0]);\r\nvmalloc_num_pages = is_vmalloc_addr(&window->num_pages[0]);\r\nfor (i = 0, j = 0; i < nr_pages; i += SCIF_NR_ADDR_IN_PAGE, j++) {\r\nerr = scif_map_page(&window->dma_addr_lookup.lookup[j],\r\nvmalloc_dma_phys ?\r\nvmalloc_to_page(&window->dma_addr[i]) :\r\nvirt_to_page(&window->dma_addr[i]),\r\nremote_dev);\r\nif (err)\r\ngoto error_window;\r\nerr = scif_map_page(&window->num_pages_lookup.lookup[j],\r\nvmalloc_dma_phys ?\r\nvmalloc_to_page(&window->num_pages[i]) :\r\nvirt_to_page(&window->num_pages[i]),\r\nremote_dev);\r\nif (err)\r\ngoto error_window;\r\n}\r\nreturn 0;\r\nerror_window:\r\nreturn err;\r\n}\r\nstatic void scif_destroy_remote_lookup(struct scif_dev *remote_dev,\r\nstruct scif_window *window)\r\n{\r\nint i, j;\r\nif (window->nr_lookup) {\r\nstruct scif_rma_lookup *lup = &window->dma_addr_lookup;\r\nstruct scif_rma_lookup *npup = &window->num_pages_lookup;\r\nfor (i = 0, j = 0; i < window->nr_pages;\r\ni += SCIF_NR_ADDR_IN_PAGE, j++) {\r\nif (lup->lookup && lup->lookup[j])\r\nscif_unmap_single(lup->lookup[j],\r\nremote_dev,\r\nPAGE_SIZE);\r\nif (npup->lookup && npup->lookup[j])\r\nscif_unmap_single(npup->lookup[j],\r\nremote_dev,\r\nPAGE_SIZE);\r\n}\r\nif (lup->lookup)\r\nscif_free_coherent(lup->lookup, lup->offset,\r\nremote_dev, window->nr_lookup *\r\nsizeof(*lup->lookup));\r\nif (npup->lookup)\r\nscif_free_coherent(npup->lookup, npup->offset,\r\nremote_dev, window->nr_lookup *\r\nsizeof(*npup->lookup));\r\nif (window->mapped_offset)\r\nscif_unmap_single(window->mapped_offset,\r\nremote_dev, sizeof(*window));\r\nwindow->nr_lookup = 0;\r\n}\r\n}\r\nstatic struct scif_window *\r\nscif_create_remote_window(struct scif_dev *scifdev, int nr_pages)\r\n{\r\nstruct scif_window *window;\r\nmight_sleep();\r\nwindow = scif_zalloc(sizeof(*window));\r\nif (!window)\r\ngoto error_ret;\r\nwindow->magic = SCIFEP_MAGIC;\r\nwindow->nr_pages = nr_pages;\r\nwindow->dma_addr = scif_zalloc(nr_pages * sizeof(*window->dma_addr));\r\nif (!window->dma_addr)\r\ngoto error_window;\r\nwindow->num_pages = scif_zalloc(nr_pages *\r\nsizeof(*window->num_pages));\r\nif (!window->num_pages)\r\ngoto error_window;\r\nif (scif_create_remote_lookup(scifdev, window))\r\ngoto error_window;\r\nwindow->type = SCIF_WINDOW_PEER;\r\nwindow->unreg_state = OP_IDLE;\r\nINIT_LIST_HEAD(&window->list);\r\nreturn window;\r\nerror_window:\r\nscif_destroy_remote_window(window);\r\nerror_ret:\r\nreturn NULL;\r\n}\r\nvoid\r\nscif_destroy_remote_window(struct scif_window *window)\r\n{\r\nscif_free(window->dma_addr, window->nr_pages *\r\nsizeof(*window->dma_addr));\r\nscif_free(window->num_pages, window->nr_pages *\r\nsizeof(*window->num_pages));\r\nwindow->magic = 0;\r\nscif_free(window, sizeof(*window));\r\n}\r\nstatic int scif_iommu_map(struct scif_dev *remote_dev,\r\nstruct scif_window *window)\r\n{\r\nstruct scatterlist *sg;\r\nint i, err;\r\nscif_pinned_pages_t pin = window->pinned_pages;\r\nwindow->st = kzalloc(sizeof(*window->st), GFP_KERNEL);\r\nif (!window->st)\r\nreturn -ENOMEM;\r\nerr = sg_alloc_table(window->st, window->nr_pages, GFP_KERNEL);\r\nif (err)\r\nreturn err;\r\nfor_each_sg(window->st->sgl, sg, window->st->nents, i)\r\nsg_set_page(sg, pin->pages[i], PAGE_SIZE, 0x0);\r\nerr = dma_map_sg(&remote_dev->sdev->dev, window->st->sgl,\r\nwindow->st->nents, DMA_BIDIRECTIONAL);\r\nif (!err)\r\nreturn -ENOMEM;\r\nsg = window->st->sgl;\r\nfor (i = 0; sg; i++) {\r\ndma_addr_t last_da;\r\nwindow->dma_addr[i] = sg_dma_address(sg);\r\nwindow->num_pages[i] = sg_dma_len(sg) >> PAGE_SHIFT;\r\nlast_da = sg_dma_address(sg) + sg_dma_len(sg);\r\nwhile ((sg = sg_next(sg)) && sg_dma_address(sg) == last_da) {\r\nwindow->num_pages[i] +=\r\n(sg_dma_len(sg) >> PAGE_SHIFT);\r\nlast_da = window->dma_addr[i] +\r\nsg_dma_len(sg);\r\n}\r\nwindow->nr_contig_chunks++;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nscif_map_window(struct scif_dev *remote_dev, struct scif_window *window)\r\n{\r\nint i, j, k, err = 0, nr_contig_pages;\r\nscif_pinned_pages_t pin;\r\nphys_addr_t phys_prev, phys_curr;\r\nmight_sleep();\r\npin = window->pinned_pages;\r\nif (intel_iommu_enabled && !scifdev_self(remote_dev))\r\nreturn scif_iommu_map(remote_dev, window);\r\nfor (i = 0, j = 0; i < window->nr_pages; i += nr_contig_pages, j++) {\r\nphys_prev = page_to_phys(pin->pages[i]);\r\nnr_contig_pages = 1;\r\nfor (k = i + 1; k < window->nr_pages; k++) {\r\nphys_curr = page_to_phys(pin->pages[k]);\r\nif (phys_curr != (phys_prev + PAGE_SIZE))\r\nbreak;\r\nphys_prev = phys_curr;\r\nnr_contig_pages++;\r\n}\r\nwindow->num_pages[j] = nr_contig_pages;\r\nwindow->nr_contig_chunks++;\r\nif (scif_is_mgmt_node()) {\r\nerr = scif_map_single(&window->dma_addr[j],\r\nphys_to_virt(page_to_phys(\r\npin->pages[i])),\r\nremote_dev,\r\nnr_contig_pages << PAGE_SHIFT);\r\nif (err)\r\nreturn err;\r\n} else {\r\nwindow->dma_addr[j] = page_to_phys(pin->pages[i]);\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic int scif_send_scif_unregister(struct scif_endpt *ep,\r\nstruct scif_window *window)\r\n{\r\nstruct scifmsg msg;\r\nmsg.uop = SCIF_UNREGISTER;\r\nmsg.src = ep->port;\r\nmsg.payload[0] = window->alloc_handle.vaddr;\r\nmsg.payload[1] = (u64)window;\r\nreturn scif_nodeqp_send(ep->remote_dev, &msg);\r\n}\r\nint scif_unregister_window(struct scif_window *window)\r\n{\r\nint err = 0;\r\nstruct scif_endpt *ep = (struct scif_endpt *)window->ep;\r\nbool send_msg = false;\r\nmight_sleep();\r\nswitch (window->unreg_state) {\r\ncase OP_IDLE:\r\n{\r\nwindow->unreg_state = OP_IN_PROGRESS;\r\nsend_msg = true;\r\n}\r\ncase OP_IN_PROGRESS:\r\n{\r\nscif_get_window(window, 1);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nif (send_msg) {\r\nerr = scif_send_scif_unregister(ep, window);\r\nif (err) {\r\nwindow->unreg_state = OP_COMPLETED;\r\ngoto done;\r\n}\r\n} else {\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nreturn -ENXIO;\r\n}\r\nretry:\r\nerr = wait_event_timeout(window->unregwq,\r\nwindow->unreg_state != OP_IN_PROGRESS,\r\nSCIF_NODE_ALIVE_TIMEOUT);\r\nif (!err && scifdev_alive(ep))\r\ngoto retry;\r\nif (!err) {\r\nerr = -ENODEV;\r\nwindow->unreg_state = OP_COMPLETED;\r\ndev_err(scif_info.mdev.this_device,\r\n"%s %d err %d\n", __func__, __LINE__, err);\r\n}\r\nif (err > 0)\r\nerr = 0;\r\ndone:\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nscif_put_window(window, 1);\r\nbreak;\r\n}\r\ncase OP_FAILED:\r\n{\r\nif (!scifdev_alive(ep)) {\r\nerr = -ENODEV;\r\nwindow->unreg_state = OP_COMPLETED;\r\n}\r\nbreak;\r\n}\r\ncase OP_COMPLETED:\r\nbreak;\r\ndefault:\r\nerr = -ENODEV;\r\n}\r\nif (window->unreg_state == OP_COMPLETED && window->ref_count)\r\nscif_put_window(window, window->nr_pages);\r\nif (!window->ref_count) {\r\natomic_inc(&ep->rma_info.tw_refcount);\r\nlist_del_init(&window->list);\r\nscif_free_window_offset(ep, window, window->offset);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nif ((!!(window->pinned_pages->map_flags & SCIF_MAP_KERNEL)) &&\r\nscifdev_alive(ep)) {\r\nscif_drain_dma_intr(ep->remote_dev->sdev,\r\nep->rma_info.dma_chan);\r\n} else {\r\nif (!__scif_dec_pinned_vm_lock(window->mm,\r\nwindow->nr_pages, 1)) {\r\n__scif_release_mm(window->mm);\r\nwindow->mm = NULL;\r\n}\r\n}\r\nscif_queue_for_cleanup(window, &scif_info.rma);\r\nmutex_lock(&ep->rma_info.rma_lock);\r\n}\r\nreturn err;\r\n}\r\nstatic int scif_send_alloc_request(struct scif_endpt *ep,\r\nstruct scif_window *window)\r\n{\r\nstruct scifmsg msg;\r\nstruct scif_allocmsg *alloc = &window->alloc_handle;\r\nalloc->state = OP_IN_PROGRESS;\r\ninit_waitqueue_head(&alloc->allocwq);\r\nmsg.uop = SCIF_ALLOC_REQ;\r\nmsg.payload[1] = window->nr_pages;\r\nmsg.payload[2] = (u64)&window->alloc_handle;\r\nreturn _scif_nodeqp_send(ep->remote_dev, &msg);\r\n}\r\nstatic int scif_prep_remote_window(struct scif_endpt *ep,\r\nstruct scif_window *window)\r\n{\r\nstruct scifmsg msg;\r\nstruct scif_window *remote_window;\r\nstruct scif_allocmsg *alloc = &window->alloc_handle;\r\ndma_addr_t *dma_phys_lookup, *tmp, *num_pages_lookup, *tmp1;\r\nint i = 0, j = 0;\r\nint nr_contig_chunks, loop_nr_contig_chunks;\r\nint remaining_nr_contig_chunks, nr_lookup;\r\nint err, map_err;\r\nmap_err = scif_map_window(ep->remote_dev, window);\r\nif (map_err)\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d map_err %d\n", __func__, __LINE__, map_err);\r\nremaining_nr_contig_chunks = window->nr_contig_chunks;\r\nnr_contig_chunks = window->nr_contig_chunks;\r\nretry:\r\nerr = wait_event_timeout(alloc->allocwq,\r\nalloc->state != OP_IN_PROGRESS,\r\nSCIF_NODE_ALIVE_TIMEOUT);\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nif (!err && scifdev_alive(ep))\r\ngoto retry;\r\nif (!err)\r\nerr = -ENODEV;\r\nif (err > 0)\r\nerr = 0;\r\nelse\r\nreturn err;\r\nif (alloc->state == OP_FAILED)\r\nreturn -ENOMEM;\r\nif (map_err) {\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %d\n", __func__, __LINE__, map_err);\r\nmsg.uop = SCIF_FREE_VIRT;\r\nmsg.src = ep->port;\r\nmsg.payload[0] = ep->remote_ep;\r\nmsg.payload[1] = window->alloc_handle.vaddr;\r\nmsg.payload[2] = (u64)window;\r\nmsg.payload[3] = SCIF_REGISTER;\r\nspin_lock(&ep->lock);\r\nif (ep->state == SCIFEP_CONNECTED)\r\nerr = _scif_nodeqp_send(ep->remote_dev, &msg);\r\nelse\r\nerr = -ENOTCONN;\r\nspin_unlock(&ep->lock);\r\nreturn err;\r\n}\r\nremote_window = scif_ioremap(alloc->phys_addr, sizeof(*window),\r\nep->remote_dev);\r\nnr_lookup = ALIGN(nr_contig_chunks, SCIF_NR_ADDR_IN_PAGE)\r\n>> ilog2(SCIF_NR_ADDR_IN_PAGE);\r\ndma_phys_lookup =\r\nscif_ioremap(remote_window->dma_addr_lookup.offset,\r\nnr_lookup *\r\nsizeof(*remote_window->dma_addr_lookup.lookup),\r\nep->remote_dev);\r\nnum_pages_lookup =\r\nscif_ioremap(remote_window->num_pages_lookup.offset,\r\nnr_lookup *\r\nsizeof(*remote_window->num_pages_lookup.lookup),\r\nep->remote_dev);\r\nwhile (remaining_nr_contig_chunks) {\r\nloop_nr_contig_chunks = min_t(int, remaining_nr_contig_chunks,\r\n(int)SCIF_NR_ADDR_IN_PAGE);\r\ntmp = scif_ioremap(dma_phys_lookup[j],\r\nloop_nr_contig_chunks *\r\nsizeof(*window->dma_addr),\r\nep->remote_dev);\r\ntmp1 = scif_ioremap(num_pages_lookup[j],\r\nloop_nr_contig_chunks *\r\nsizeof(*window->num_pages),\r\nep->remote_dev);\r\nif (scif_is_mgmt_node()) {\r\nmemcpy_toio((void __force __iomem *)tmp,\r\n&window->dma_addr[i], loop_nr_contig_chunks\r\n* sizeof(*window->dma_addr));\r\nmemcpy_toio((void __force __iomem *)tmp1,\r\n&window->num_pages[i], loop_nr_contig_chunks\r\n* sizeof(*window->num_pages));\r\n} else {\r\nif (scifdev_is_p2p(ep->remote_dev)) {\r\nint m;\r\ndma_addr_t dma_addr;\r\nfor (m = 0; m < loop_nr_contig_chunks; m++) {\r\ndma_addr = window->dma_addr[i + m] +\r\nep->remote_dev->base_addr;\r\nwriteq(dma_addr,\r\n(void __force __iomem *)&tmp[m]);\r\n}\r\nmemcpy_toio((void __force __iomem *)tmp1,\r\n&window->num_pages[i],\r\nloop_nr_contig_chunks\r\n* sizeof(*window->num_pages));\r\n} else {\r\nmemcpy_toio((void __force __iomem *)tmp,\r\n&window->dma_addr[i],\r\nloop_nr_contig_chunks *\r\nsizeof(*window->dma_addr));\r\nmemcpy_toio((void __force __iomem *)tmp1,\r\n&window->num_pages[i],\r\nloop_nr_contig_chunks *\r\nsizeof(*window->num_pages));\r\n}\r\n}\r\nremaining_nr_contig_chunks -= loop_nr_contig_chunks;\r\ni += loop_nr_contig_chunks;\r\nj++;\r\nscif_iounmap(tmp, loop_nr_contig_chunks *\r\nsizeof(*window->dma_addr), ep->remote_dev);\r\nscif_iounmap(tmp1, loop_nr_contig_chunks *\r\nsizeof(*window->num_pages), ep->remote_dev);\r\n}\r\nremote_window->peer_window = (u64)window;\r\nremote_window->offset = window->offset;\r\nremote_window->prot = window->prot;\r\nremote_window->nr_contig_chunks = nr_contig_chunks;\r\nremote_window->ep = ep->remote_ep;\r\nscif_iounmap(num_pages_lookup,\r\nnr_lookup *\r\nsizeof(*remote_window->num_pages_lookup.lookup),\r\nep->remote_dev);\r\nscif_iounmap(dma_phys_lookup,\r\nnr_lookup *\r\nsizeof(*remote_window->dma_addr_lookup.lookup),\r\nep->remote_dev);\r\nscif_iounmap(remote_window, sizeof(*remote_window), ep->remote_dev);\r\nwindow->peer_window = alloc->vaddr;\r\nreturn err;\r\n}\r\nstatic int scif_send_scif_register(struct scif_endpt *ep,\r\nstruct scif_window *window)\r\n{\r\nint err = 0;\r\nstruct scifmsg msg;\r\nmsg.src = ep->port;\r\nmsg.payload[0] = ep->remote_ep;\r\nmsg.payload[1] = window->alloc_handle.vaddr;\r\nmsg.payload[2] = (u64)window;\r\nspin_lock(&ep->lock);\r\nif (ep->state == SCIFEP_CONNECTED) {\r\nmsg.uop = SCIF_REGISTER;\r\nwindow->reg_state = OP_IN_PROGRESS;\r\nerr = _scif_nodeqp_send(ep->remote_dev, &msg);\r\nspin_unlock(&ep->lock);\r\nif (!err) {\r\nretry:\r\nerr = wait_event_timeout(window->regwq,\r\nwindow->reg_state !=\r\nOP_IN_PROGRESS,\r\nSCIF_NODE_ALIVE_TIMEOUT);\r\nif (!err && scifdev_alive(ep))\r\ngoto retry;\r\nerr = !err ? -ENODEV : 0;\r\nif (window->reg_state == OP_FAILED)\r\nerr = -ENOTCONN;\r\n}\r\n} else {\r\nmsg.uop = SCIF_FREE_VIRT;\r\nmsg.payload[3] = SCIF_REGISTER;\r\nerr = _scif_nodeqp_send(ep->remote_dev, &msg);\r\nspin_unlock(&ep->lock);\r\nif (!err)\r\nerr = -ENOTCONN;\r\n}\r\nreturn err;\r\n}\r\nint scif_get_window_offset(struct scif_endpt *ep, int flags, s64 offset,\r\nint num_pages, s64 *out_offset)\r\n{\r\ns64 page_index;\r\nstruct iova *iova_ptr;\r\nint err = 0;\r\nif (flags & SCIF_MAP_FIXED) {\r\npage_index = SCIF_IOVA_PFN(offset);\r\niova_ptr = reserve_iova(&ep->rma_info.iovad, page_index,\r\npage_index + num_pages - 1);\r\nif (!iova_ptr)\r\nerr = -EADDRINUSE;\r\n} else {\r\niova_ptr = alloc_iova(&ep->rma_info.iovad, num_pages,\r\nSCIF_DMA_63BIT_PFN - 1, 0);\r\nif (!iova_ptr)\r\nerr = -ENOMEM;\r\n}\r\nif (!err)\r\n*out_offset = (iova_ptr->pfn_lo) << PAGE_SHIFT;\r\nreturn err;\r\n}\r\nvoid scif_free_window_offset(struct scif_endpt *ep,\r\nstruct scif_window *window, s64 offset)\r\n{\r\nif ((window && !window->offset_freed) || !window) {\r\nfree_iova(&ep->rma_info.iovad, offset >> PAGE_SHIFT);\r\nif (window)\r\nwindow->offset_freed = true;\r\n}\r\n}\r\nvoid scif_alloc_req(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nint err;\r\nstruct scif_window *window = NULL;\r\nint nr_pages = msg->payload[1];\r\nwindow = scif_create_remote_window(scifdev, nr_pages);\r\nif (!window) {\r\nerr = -ENOMEM;\r\ngoto error;\r\n}\r\nmsg->uop = SCIF_ALLOC_GNT;\r\nmsg->payload[0] = (u64)window;\r\nmsg->payload[1] = window->mapped_offset;\r\nerr = scif_nodeqp_send(scifdev, msg);\r\nif (err)\r\nscif_destroy_remote_window(window);\r\nreturn;\r\nerror:\r\ndev_err(&scifdev->sdev->dev,\r\n"%s %d error %d alloc_ptr %p nr_pages 0x%x\n",\r\n__func__, __LINE__, err, window, nr_pages);\r\nmsg->uop = SCIF_ALLOC_REJ;\r\nscif_nodeqp_send(scifdev, msg);\r\n}\r\nvoid scif_alloc_gnt_rej(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_allocmsg *handle = (struct scif_allocmsg *)msg->payload[2];\r\nstruct scif_window *window = container_of(handle, struct scif_window,\r\nalloc_handle);\r\nstruct scif_endpt *ep = (struct scif_endpt *)window->ep;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nhandle->vaddr = msg->payload[0];\r\nhandle->phys_addr = msg->payload[1];\r\nif (msg->uop == SCIF_ALLOC_GNT)\r\nhandle->state = OP_COMPLETED;\r\nelse\r\nhandle->state = OP_FAILED;\r\nwake_up(&handle->allocwq);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\n}\r\nvoid scif_free_virt(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_window *window = (struct scif_window *)msg->payload[1];\r\nscif_destroy_remote_window(window);\r\n}\r\nstatic void\r\nscif_fixup_aper_base(struct scif_dev *dev, struct scif_window *window)\r\n{\r\nint j;\r\nstruct scif_hw_dev *sdev = dev->sdev;\r\nphys_addr_t apt_base = 0;\r\nif (!scifdev_self(dev) && window->type == SCIF_WINDOW_PEER &&\r\nsdev->aper && !sdev->card_rel_da)\r\napt_base = sdev->aper->pa;\r\nelse\r\nreturn;\r\nfor (j = 0; j < window->nr_contig_chunks; j++) {\r\nif (window->num_pages[j])\r\nwindow->dma_addr[j] += apt_base;\r\nelse\r\nbreak;\r\n}\r\n}\r\nvoid scif_recv_reg(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_endpt *ep = (struct scif_endpt *)msg->payload[0];\r\nstruct scif_window *window =\r\n(struct scif_window *)msg->payload[1];\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nspin_lock(&ep->lock);\r\nif (ep->state == SCIFEP_CONNECTED) {\r\nmsg->uop = SCIF_REGISTER_ACK;\r\nscif_nodeqp_send(ep->remote_dev, msg);\r\nscif_fixup_aper_base(ep->remote_dev, window);\r\nscif_insert_window(window, &ep->rma_info.remote_reg_list);\r\n} else {\r\nmsg->uop = SCIF_REGISTER_NACK;\r\nscif_nodeqp_send(ep->remote_dev, msg);\r\n}\r\nspin_unlock(&ep->lock);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nscif_destroy_remote_lookup(ep->remote_dev, window);\r\nif (msg->uop == SCIF_REGISTER_NACK)\r\nscif_destroy_remote_window(window);\r\n}\r\nvoid scif_recv_unreg(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_rma_req req;\r\nstruct scif_window *window = NULL;\r\nstruct scif_window *recv_window =\r\n(struct scif_window *)msg->payload[0];\r\nstruct scif_endpt *ep;\r\nint del_window = 0;\r\nep = (struct scif_endpt *)recv_window->ep;\r\nreq.out_window = &window;\r\nreq.offset = recv_window->offset;\r\nreq.prot = 0;\r\nreq.nr_bytes = recv_window->nr_pages << PAGE_SHIFT;\r\nreq.type = SCIF_WINDOW_FULL;\r\nreq.head = &ep->rma_info.remote_reg_list;\r\nmsg->payload[0] = ep->remote_ep;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nif (scif_query_window(&req)) {\r\ndev_err(&scifdev->sdev->dev,\r\n"%s %d -ENXIO\n", __func__, __LINE__);\r\nmsg->uop = SCIF_UNREGISTER_ACK;\r\ngoto error;\r\n}\r\nif (window) {\r\nif (window->ref_count)\r\nscif_put_window(window, window->nr_pages);\r\nelse\r\ndev_err(&scifdev->sdev->dev,\r\n"%s %d ref count should be +ve\n",\r\n__func__, __LINE__);\r\nwindow->unreg_state = OP_COMPLETED;\r\nif (!window->ref_count) {\r\nmsg->uop = SCIF_UNREGISTER_ACK;\r\natomic_inc(&ep->rma_info.tw_refcount);\r\nep->rma_info.async_list_del = 1;\r\nlist_del_init(&window->list);\r\ndel_window = 1;\r\n} else {\r\nmsg->uop = SCIF_UNREGISTER_NACK;\r\n}\r\n} else {\r\nmsg->uop = SCIF_UNREGISTER_ACK;\r\nscif_destroy_remote_window(recv_window);\r\n}\r\nerror:\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nif (del_window)\r\nscif_drain_dma_intr(ep->remote_dev->sdev,\r\nep->rma_info.dma_chan);\r\nscif_nodeqp_send(ep->remote_dev, msg);\r\nif (del_window)\r\nscif_queue_for_cleanup(window, &scif_info.rma);\r\n}\r\nvoid scif_recv_reg_ack(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_window *window =\r\n(struct scif_window *)msg->payload[2];\r\nstruct scif_endpt *ep = (struct scif_endpt *)window->ep;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nwindow->reg_state = OP_COMPLETED;\r\nwake_up(&window->regwq);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\n}\r\nvoid scif_recv_reg_nack(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_window *window =\r\n(struct scif_window *)msg->payload[2];\r\nstruct scif_endpt *ep = (struct scif_endpt *)window->ep;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nwindow->reg_state = OP_FAILED;\r\nwake_up(&window->regwq);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\n}\r\nvoid scif_recv_unreg_ack(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_window *window =\r\n(struct scif_window *)msg->payload[1];\r\nstruct scif_endpt *ep = (struct scif_endpt *)window->ep;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nwindow->unreg_state = OP_COMPLETED;\r\nwake_up(&window->unregwq);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\n}\r\nvoid scif_recv_unreg_nack(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_window *window =\r\n(struct scif_window *)msg->payload[1];\r\nstruct scif_endpt *ep = (struct scif_endpt *)window->ep;\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nwindow->unreg_state = OP_FAILED;\r\nwake_up(&window->unregwq);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\n}\r\nint __scif_pin_pages(void *addr, size_t len, int *out_prot,\r\nint map_flags, scif_pinned_pages_t *pages)\r\n{\r\nstruct scif_pinned_pages *pinned_pages;\r\nint nr_pages, err = 0, i;\r\nbool vmalloc_addr = false;\r\nbool try_upgrade = false;\r\nint prot = *out_prot;\r\nint ulimit = 0;\r\nstruct mm_struct *mm = NULL;\r\nif (map_flags & ~(SCIF_MAP_KERNEL | SCIF_MAP_ULIMIT))\r\nreturn -EINVAL;\r\nulimit = !!(map_flags & SCIF_MAP_ULIMIT);\r\nif (prot & ~(SCIF_PROT_READ | SCIF_PROT_WRITE))\r\nreturn -EINVAL;\r\nif (!len ||\r\n(ALIGN((u64)addr, PAGE_SIZE) != (u64)addr) ||\r\n(ALIGN((u64)len, PAGE_SIZE) != (u64)len))\r\nreturn -EINVAL;\r\nmight_sleep();\r\nnr_pages = len >> PAGE_SHIFT;\r\npinned_pages = scif_create_pinned_pages(nr_pages, prot);\r\nif (!pinned_pages)\r\nreturn -ENOMEM;\r\nif (map_flags & SCIF_MAP_KERNEL) {\r\nif (is_vmalloc_addr(addr))\r\nvmalloc_addr = true;\r\nfor (i = 0; i < nr_pages; i++) {\r\nif (vmalloc_addr)\r\npinned_pages->pages[i] =\r\nvmalloc_to_page(addr + (i * PAGE_SIZE));\r\nelse\r\npinned_pages->pages[i] =\r\nvirt_to_page(addr + (i * PAGE_SIZE));\r\n}\r\npinned_pages->nr_pages = nr_pages;\r\npinned_pages->map_flags = SCIF_MAP_KERNEL;\r\n} else {\r\nif (prot == SCIF_PROT_READ)\r\ntry_upgrade = true;\r\nprot |= SCIF_PROT_WRITE;\r\nretry:\r\nmm = current->mm;\r\ndown_write(&mm->mmap_sem);\r\nif (ulimit) {\r\nerr = __scif_check_inc_pinned_vm(mm, nr_pages);\r\nif (err) {\r\nup_write(&mm->mmap_sem);\r\npinned_pages->nr_pages = 0;\r\ngoto error_unmap;\r\n}\r\n}\r\npinned_pages->nr_pages = get_user_pages(\r\ncurrent,\r\nmm,\r\n(u64)addr,\r\nnr_pages,\r\n!!(prot & SCIF_PROT_WRITE),\r\n0,\r\npinned_pages->pages,\r\nNULL);\r\nup_write(&mm->mmap_sem);\r\nif (nr_pages != pinned_pages->nr_pages) {\r\nif (try_upgrade) {\r\nif (ulimit)\r\n__scif_dec_pinned_vm_lock(mm,\r\nnr_pages, 0);\r\nfor (i = 0; i < pinned_pages->nr_pages; i++) {\r\nif (pinned_pages->pages[i])\r\nput_page(\r\npinned_pages->pages[i]);\r\n}\r\nprot &= ~SCIF_PROT_WRITE;\r\ntry_upgrade = false;\r\ngoto retry;\r\n}\r\n}\r\npinned_pages->map_flags = 0;\r\n}\r\nif (pinned_pages->nr_pages < nr_pages) {\r\nerr = -EFAULT;\r\npinned_pages->nr_pages = nr_pages;\r\ngoto dec_pinned;\r\n}\r\n*out_prot = prot;\r\natomic_set(&pinned_pages->ref_count, 1);\r\n*pages = pinned_pages;\r\nreturn err;\r\ndec_pinned:\r\nif (ulimit)\r\n__scif_dec_pinned_vm_lock(mm, nr_pages, 0);\r\nerror_unmap:\r\npinned_pages->nr_pages = nr_pages;\r\nscif_destroy_pinned_pages(pinned_pages);\r\n*pages = NULL;\r\ndev_dbg(scif_info.mdev.this_device,\r\n"%s %d err %d len 0x%lx\n", __func__, __LINE__, err, len);\r\nreturn err;\r\n}\r\nint scif_pin_pages(void *addr, size_t len, int prot,\r\nint map_flags, scif_pinned_pages_t *pages)\r\n{\r\nreturn __scif_pin_pages(addr, len, &prot, map_flags, pages);\r\n}\r\nint scif_unpin_pages(scif_pinned_pages_t pinned_pages)\r\n{\r\nint err = 0, ret;\r\nif (!pinned_pages || SCIFEP_MAGIC != pinned_pages->magic)\r\nreturn -EINVAL;\r\nret = atomic_sub_return(1, &pinned_pages->ref_count);\r\nif (ret < 0) {\r\ndev_err(scif_info.mdev.this_device,\r\n"%s %d scif_unpin_pages called without pinning? rc %d\n",\r\n__func__, __LINE__, ret);\r\nreturn -EINVAL;\r\n}\r\nif (!ret)\r\nerr = scif_destroy_pinned_pages(pinned_pages);\r\nreturn err;\r\n}\r\nstatic inline void\r\nscif_insert_local_window(struct scif_window *window, struct scif_endpt *ep)\r\n{\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nscif_insert_window(window, &ep->rma_info.reg_list);\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\n}\r\noff_t scif_register_pinned_pages(scif_epd_t epd,\r\nscif_pinned_pages_t pinned_pages,\r\noff_t offset, int map_flags)\r\n{\r\nstruct scif_endpt *ep = (struct scif_endpt *)epd;\r\ns64 computed_offset;\r\nstruct scif_window *window;\r\nint err;\r\nsize_t len;\r\nstruct device *spdev;\r\nif (map_flags & ~SCIF_MAP_FIXED)\r\nreturn -EINVAL;\r\nlen = pinned_pages->nr_pages << PAGE_SHIFT;\r\nif ((map_flags & SCIF_MAP_FIXED) &&\r\n((ALIGN(offset, PAGE_SIZE) != offset) ||\r\n(offset < 0) ||\r\n(offset + (off_t)len < offset)))\r\nreturn -EINVAL;\r\nmight_sleep();\r\nerr = scif_verify_epd(ep);\r\nif (err)\r\nreturn err;\r\nif (!atomic_add_unless(&pinned_pages->ref_count, 1, 0))\r\nreturn -EINVAL;\r\nerr = scif_get_window_offset(ep, map_flags, offset,\r\nlen, &computed_offset);\r\nif (err) {\r\natomic_sub(1, &pinned_pages->ref_count);\r\nreturn err;\r\n}\r\nwindow = scif_create_window(ep, pinned_pages->nr_pages,\r\ncomputed_offset, false);\r\nif (!window) {\r\natomic_sub(1, &pinned_pages->ref_count);\r\nscif_free_window_offset(ep, NULL, computed_offset);\r\nreturn -ENOMEM;\r\n}\r\nwindow->pinned_pages = pinned_pages;\r\nwindow->nr_pages = pinned_pages->nr_pages;\r\nwindow->prot = pinned_pages->prot;\r\nspdev = scif_get_peer_dev(ep->remote_dev);\r\nif (IS_ERR(spdev)) {\r\nerr = PTR_ERR(spdev);\r\nscif_destroy_window(ep, window);\r\nreturn err;\r\n}\r\nerr = scif_send_alloc_request(ep, window);\r\nif (err) {\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %d\n", __func__, __LINE__, err);\r\ngoto error_unmap;\r\n}\r\nerr = scif_prep_remote_window(ep, window);\r\nif (err) {\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %d\n", __func__, __LINE__, err);\r\ngoto error_unmap;\r\n}\r\nerr = scif_send_scif_register(ep, window);\r\nif (err) {\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %d\n", __func__, __LINE__, err);\r\ngoto error_unmap;\r\n}\r\nscif_put_peer_dev(spdev);\r\nscif_insert_local_window(window, ep);\r\nreturn computed_offset;\r\nerror_unmap:\r\nscif_destroy_window(ep, window);\r\nscif_put_peer_dev(spdev);\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %d\n", __func__, __LINE__, err);\r\nreturn err;\r\n}\r\noff_t scif_register(scif_epd_t epd, void *addr, size_t len, off_t offset,\r\nint prot, int map_flags)\r\n{\r\nscif_pinned_pages_t pinned_pages;\r\noff_t err;\r\nstruct scif_endpt *ep = (struct scif_endpt *)epd;\r\ns64 computed_offset;\r\nstruct scif_window *window;\r\nstruct mm_struct *mm = NULL;\r\nstruct device *spdev;\r\ndev_dbg(scif_info.mdev.this_device,\r\n"SCIFAPI register: ep %p addr %p len 0x%lx offset 0x%lx prot 0x%x map_flags 0x%x\n",\r\nepd, addr, len, offset, prot, map_flags);\r\nif (map_flags & ~(SCIF_MAP_FIXED | SCIF_MAP_KERNEL))\r\nreturn -EINVAL;\r\nif ((map_flags & SCIF_MAP_FIXED) &&\r\n((ALIGN(offset, PAGE_SIZE) != offset) ||\r\n(offset < 0) ||\r\n(offset + (off_t)len < offset)))\r\nreturn -EINVAL;\r\nif (prot & ~(SCIF_PROT_READ | SCIF_PROT_WRITE))\r\nreturn -EINVAL;\r\nif (!len || (ALIGN((u64)addr, PAGE_SIZE) != (u64)addr) ||\r\n(ALIGN(len, PAGE_SIZE) != len))\r\nreturn -EINVAL;\r\nmight_sleep();\r\nerr = scif_verify_epd(ep);\r\nif (err)\r\nreturn err;\r\nerr = scif_get_window_offset(ep, map_flags, offset,\r\nlen >> PAGE_SHIFT, &computed_offset);\r\nif (err)\r\nreturn err;\r\nspdev = scif_get_peer_dev(ep->remote_dev);\r\nif (IS_ERR(spdev)) {\r\nerr = PTR_ERR(spdev);\r\nscif_free_window_offset(ep, NULL, computed_offset);\r\nreturn err;\r\n}\r\nwindow = scif_create_window(ep, len >> PAGE_SHIFT,\r\ncomputed_offset, false);\r\nif (!window) {\r\nscif_free_window_offset(ep, NULL, computed_offset);\r\nscif_put_peer_dev(spdev);\r\nreturn -ENOMEM;\r\n}\r\nwindow->nr_pages = len >> PAGE_SHIFT;\r\nerr = scif_send_alloc_request(ep, window);\r\nif (err) {\r\nscif_destroy_incomplete_window(ep, window);\r\nscif_put_peer_dev(spdev);\r\nreturn err;\r\n}\r\nif (!(map_flags & SCIF_MAP_KERNEL)) {\r\nmm = __scif_acquire_mm();\r\nmap_flags |= SCIF_MAP_ULIMIT;\r\n}\r\nerr = __scif_pin_pages(addr, len, &prot,\r\nmap_flags & (SCIF_MAP_KERNEL | SCIF_MAP_ULIMIT),\r\n&pinned_pages);\r\nif (err) {\r\nscif_destroy_incomplete_window(ep, window);\r\n__scif_release_mm(mm);\r\ngoto error;\r\n}\r\nwindow->pinned_pages = pinned_pages;\r\nwindow->prot = pinned_pages->prot;\r\nwindow->mm = mm;\r\nerr = scif_prep_remote_window(ep, window);\r\nif (err) {\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %ld\n", __func__, __LINE__, err);\r\ngoto error_unmap;\r\n}\r\nerr = scif_send_scif_register(ep, window);\r\nif (err) {\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %ld\n", __func__, __LINE__, err);\r\ngoto error_unmap;\r\n}\r\nscif_put_peer_dev(spdev);\r\nscif_insert_local_window(window, ep);\r\ndev_dbg(&ep->remote_dev->sdev->dev,\r\n"SCIFAPI register: ep %p addr %p len 0x%lx computed_offset 0x%llx\n",\r\nepd, addr, len, computed_offset);\r\nreturn computed_offset;\r\nerror_unmap:\r\nscif_destroy_window(ep, window);\r\nerror:\r\nscif_put_peer_dev(spdev);\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %ld\n", __func__, __LINE__, err);\r\nreturn err;\r\n}\r\nint\r\nscif_unregister(scif_epd_t epd, off_t offset, size_t len)\r\n{\r\nstruct scif_endpt *ep = (struct scif_endpt *)epd;\r\nstruct scif_window *window = NULL;\r\nstruct scif_rma_req req;\r\nint nr_pages, err;\r\nstruct device *spdev;\r\ndev_dbg(scif_info.mdev.this_device,\r\n"SCIFAPI unregister: ep %p offset 0x%lx len 0x%lx\n",\r\nep, offset, len);\r\nif (!len ||\r\n(ALIGN((u64)len, PAGE_SIZE) != (u64)len))\r\nreturn -EINVAL;\r\nif ((ALIGN(offset, PAGE_SIZE) != offset) ||\r\n(offset + (off_t)len < offset))\r\nreturn -EINVAL;\r\nerr = scif_verify_epd(ep);\r\nif (err)\r\nreturn err;\r\nmight_sleep();\r\nnr_pages = len >> PAGE_SHIFT;\r\nreq.out_window = &window;\r\nreq.offset = offset;\r\nreq.prot = 0;\r\nreq.nr_bytes = len;\r\nreq.type = SCIF_WINDOW_FULL;\r\nreq.head = &ep->rma_info.reg_list;\r\nspdev = scif_get_peer_dev(ep->remote_dev);\r\nif (IS_ERR(spdev)) {\r\nerr = PTR_ERR(spdev);\r\nreturn err;\r\n}\r\nmutex_lock(&ep->rma_info.rma_lock);\r\nerr = scif_query_window(&req);\r\nif (err) {\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %d\n", __func__, __LINE__, err);\r\ngoto error;\r\n}\r\nerr = scif_rma_list_unregister(window, offset, nr_pages);\r\nif (err)\r\ndev_err(&ep->remote_dev->sdev->dev,\r\n"%s %d err %d\n", __func__, __LINE__, err);\r\nerror:\r\nmutex_unlock(&ep->rma_info.rma_lock);\r\nscif_put_peer_dev(spdev);\r\nreturn err;\r\n}
