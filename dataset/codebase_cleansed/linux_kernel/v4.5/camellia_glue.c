static int camellia_set_key(struct crypto_tfm *tfm, const u8 *_in_key,\r\nunsigned int key_len)\r\n{\r\nstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\r\nconst u32 *in_key = (const u32 *) _in_key;\r\nu32 *flags = &tfm->crt_flags;\r\nif (key_len != 16 && key_len != 24 && key_len != 32) {\r\n*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nctx->key_len = key_len;\r\ncamellia_sparc64_key_expand(in_key, &ctx->encrypt_key[0],\r\nkey_len, &ctx->decrypt_key[0]);\r\nreturn 0;\r\n}\r\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\r\n{\r\nstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\r\ncamellia_sparc64_crypt(&ctx->encrypt_key[0],\r\n(const u32 *) src,\r\n(u32 *) dst, ctx->key_len);\r\n}\r\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\r\n{\r\nstruct camellia_sparc64_ctx *ctx = crypto_tfm_ctx(tfm);\r\ncamellia_sparc64_crypt(&ctx->decrypt_key[0],\r\n(const u32 *) src,\r\n(u32 *) dst, ctx->key_len);\r\n}\r\nstatic int __ecb_crypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst, struct scatterlist *src,\r\nunsigned int nbytes, bool encrypt)\r\n{\r\nstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\necb_crypt_op *op;\r\nconst u64 *key;\r\nint err;\r\nop = camellia_sparc64_ecb_crypt_3_grand_rounds;\r\nif (ctx->key_len != 16)\r\nop = camellia_sparc64_ecb_crypt_4_grand_rounds;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nif (encrypt)\r\nkey = &ctx->encrypt_key[0];\r\nelse\r\nkey = &ctx->decrypt_key[0];\r\ncamellia_sparc64_load_keys(key, ctx->key_len);\r\nwhile ((nbytes = walk.nbytes)) {\r\nunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\r\nif (likely(block_len)) {\r\nconst u64 *src64;\r\nu64 *dst64;\r\nsrc64 = (const u64 *)walk.src.virt.addr;\r\ndst64 = (u64 *) walk.dst.virt.addr;\r\nop(src64, dst64, block_len, key);\r\n}\r\nnbytes &= CAMELLIA_BLOCK_SIZE - 1;\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nfprs_write(0);\r\nreturn err;\r\n}\r\nstatic int ecb_encrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst, struct scatterlist *src,\r\nunsigned int nbytes)\r\n{\r\nreturn __ecb_crypt(desc, dst, src, nbytes, true);\r\n}\r\nstatic int ecb_decrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst, struct scatterlist *src,\r\nunsigned int nbytes)\r\n{\r\nreturn __ecb_crypt(desc, dst, src, nbytes, false);\r\n}\r\nstatic int cbc_encrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst, struct scatterlist *src,\r\nunsigned int nbytes)\r\n{\r\nstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\ncbc_crypt_op *op;\r\nconst u64 *key;\r\nint err;\r\nop = camellia_sparc64_cbc_encrypt_3_grand_rounds;\r\nif (ctx->key_len != 16)\r\nop = camellia_sparc64_cbc_encrypt_4_grand_rounds;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nkey = &ctx->encrypt_key[0];\r\ncamellia_sparc64_load_keys(key, ctx->key_len);\r\nwhile ((nbytes = walk.nbytes)) {\r\nunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\r\nif (likely(block_len)) {\r\nconst u64 *src64;\r\nu64 *dst64;\r\nsrc64 = (const u64 *)walk.src.virt.addr;\r\ndst64 = (u64 *) walk.dst.virt.addr;\r\nop(src64, dst64, block_len, key,\r\n(u64 *) walk.iv);\r\n}\r\nnbytes &= CAMELLIA_BLOCK_SIZE - 1;\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nfprs_write(0);\r\nreturn err;\r\n}\r\nstatic int cbc_decrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst, struct scatterlist *src,\r\nunsigned int nbytes)\r\n{\r\nstruct camellia_sparc64_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\ncbc_crypt_op *op;\r\nconst u64 *key;\r\nint err;\r\nop = camellia_sparc64_cbc_decrypt_3_grand_rounds;\r\nif (ctx->key_len != 16)\r\nop = camellia_sparc64_cbc_decrypt_4_grand_rounds;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nkey = &ctx->decrypt_key[0];\r\ncamellia_sparc64_load_keys(key, ctx->key_len);\r\nwhile ((nbytes = walk.nbytes)) {\r\nunsigned int block_len = nbytes & CAMELLIA_BLOCK_MASK;\r\nif (likely(block_len)) {\r\nconst u64 *src64;\r\nu64 *dst64;\r\nsrc64 = (const u64 *)walk.src.virt.addr;\r\ndst64 = (u64 *) walk.dst.virt.addr;\r\nop(src64, dst64, block_len, key,\r\n(u64 *) walk.iv);\r\n}\r\nnbytes &= CAMELLIA_BLOCK_SIZE - 1;\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nfprs_write(0);\r\nreturn err;\r\n}\r\nstatic bool __init sparc64_has_camellia_opcode(void)\r\n{\r\nunsigned long cfr;\r\nif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\r\nreturn false;\r\n__asm__ __volatile__("rd %%asr26, %0" : "=r" (cfr));\r\nif (!(cfr & CFR_CAMELLIA))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int __init camellia_sparc64_mod_init(void)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(algs); i++)\r\nINIT_LIST_HEAD(&algs[i].cra_list);\r\nif (sparc64_has_camellia_opcode()) {\r\npr_info("Using sparc64 camellia opcodes optimized CAMELLIA implementation\n");\r\nreturn crypto_register_algs(algs, ARRAY_SIZE(algs));\r\n}\r\npr_info("sparc64 camellia opcodes not available.\n");\r\nreturn -ENODEV;\r\n}\r\nstatic void __exit camellia_sparc64_mod_fini(void)\r\n{\r\ncrypto_unregister_algs(algs, ARRAY_SIZE(algs));\r\n}
