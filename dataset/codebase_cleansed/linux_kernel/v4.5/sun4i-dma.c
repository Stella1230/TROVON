static struct sun4i_dma_dev *to_sun4i_dma_dev(struct dma_device *dev)\r\n{\r\nreturn container_of(dev, struct sun4i_dma_dev, slave);\r\n}\r\nstatic struct sun4i_dma_vchan *to_sun4i_dma_vchan(struct dma_chan *chan)\r\n{\r\nreturn container_of(chan, struct sun4i_dma_vchan, vc.chan);\r\n}\r\nstatic struct sun4i_dma_contract *to_sun4i_dma_contract(struct virt_dma_desc *vd)\r\n{\r\nreturn container_of(vd, struct sun4i_dma_contract, vd);\r\n}\r\nstatic struct device *chan2dev(struct dma_chan *chan)\r\n{\r\nreturn &chan->dev->device;\r\n}\r\nstatic int convert_burst(u32 maxburst)\r\n{\r\nif (maxburst > 8)\r\nreturn -EINVAL;\r\nreturn (maxburst >> 2);\r\n}\r\nstatic int convert_buswidth(enum dma_slave_buswidth addr_width)\r\n{\r\nif (addr_width > DMA_SLAVE_BUSWIDTH_4_BYTES)\r\nreturn -EINVAL;\r\nreturn (addr_width >> 1);\r\n}\r\nstatic void sun4i_dma_free_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nvchan_free_chan_resources(&vchan->vc);\r\n}\r\nstatic struct sun4i_dma_pchan *find_and_use_pchan(struct sun4i_dma_dev *priv,\r\nstruct sun4i_dma_vchan *vchan)\r\n{\r\nstruct sun4i_dma_pchan *pchan = NULL, *pchans = priv->pchans;\r\nunsigned long flags;\r\nint i, max;\r\nif (vchan->is_dedicated) {\r\ni = SUN4I_NDMA_NR_MAX_CHANNELS;\r\nmax = SUN4I_DMA_NR_MAX_CHANNELS;\r\n} else {\r\ni = 0;\r\nmax = SUN4I_NDMA_NR_MAX_CHANNELS;\r\n}\r\nspin_lock_irqsave(&priv->lock, flags);\r\nfor_each_clear_bit_from(i, &priv->pchans_used, max) {\r\npchan = &pchans[i];\r\npchan->vchan = vchan;\r\nset_bit(i, priv->pchans_used);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nreturn pchan;\r\n}\r\nstatic void release_pchan(struct sun4i_dma_dev *priv,\r\nstruct sun4i_dma_pchan *pchan)\r\n{\r\nunsigned long flags;\r\nint nr = pchan - priv->pchans;\r\nspin_lock_irqsave(&priv->lock, flags);\r\npchan->vchan = NULL;\r\nclear_bit(nr, priv->pchans_used);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic void configure_pchan(struct sun4i_dma_pchan *pchan,\r\nstruct sun4i_dma_promise *d)\r\n{\r\nif (pchan->is_dedicated) {\r\nwritel_relaxed(d->src, pchan->base + SUN4I_DDMA_SRC_ADDR_REG);\r\nwritel_relaxed(d->dst, pchan->base + SUN4I_DDMA_DST_ADDR_REG);\r\nwritel_relaxed(d->len, pchan->base + SUN4I_DDMA_BYTE_COUNT_REG);\r\nwritel_relaxed(d->para, pchan->base + SUN4I_DDMA_PARA_REG);\r\nwritel_relaxed(d->cfg, pchan->base + SUN4I_DDMA_CFG_REG);\r\n} else {\r\nwritel_relaxed(d->src, pchan->base + SUN4I_NDMA_SRC_ADDR_REG);\r\nwritel_relaxed(d->dst, pchan->base + SUN4I_NDMA_DST_ADDR_REG);\r\nwritel_relaxed(d->len, pchan->base + SUN4I_NDMA_BYTE_COUNT_REG);\r\nwritel_relaxed(d->cfg, pchan->base + SUN4I_NDMA_CFG_REG);\r\n}\r\n}\r\nstatic void set_pchan_interrupt(struct sun4i_dma_dev *priv,\r\nstruct sun4i_dma_pchan *pchan,\r\nint half, int end)\r\n{\r\nu32 reg;\r\nint pchan_number = pchan - priv->pchans;\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nreg = readl_relaxed(priv->base + SUN4I_DMA_IRQ_ENABLE_REG);\r\nif (half)\r\nreg |= BIT(pchan_number * 2);\r\nelse\r\nreg &= ~BIT(pchan_number * 2);\r\nif (end)\r\nreg |= BIT(pchan_number * 2 + 1);\r\nelse\r\nreg &= ~BIT(pchan_number * 2 + 1);\r\nwritel_relaxed(reg, priv->base + SUN4I_DMA_IRQ_ENABLE_REG);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic int __execute_vchan_pending(struct sun4i_dma_dev *priv,\r\nstruct sun4i_dma_vchan *vchan)\r\n{\r\nstruct sun4i_dma_promise *promise = NULL;\r\nstruct sun4i_dma_contract *contract = NULL;\r\nstruct sun4i_dma_pchan *pchan;\r\nstruct virt_dma_desc *vd;\r\nint ret;\r\nlockdep_assert_held(&vchan->vc.lock);\r\npchan = find_and_use_pchan(priv, vchan);\r\nif (!pchan)\r\nreturn -EBUSY;\r\nif (vchan->processing) {\r\ndev_dbg(chan2dev(&vchan->vc.chan),\r\n"processing something to this endpoint already\n");\r\nret = -EBUSY;\r\ngoto release_pchan;\r\n}\r\ndo {\r\nvd = vchan_next_desc(&vchan->vc);\r\nif (!vd) {\r\ndev_dbg(chan2dev(&vchan->vc.chan),\r\n"No pending contract found");\r\nret = 0;\r\ngoto release_pchan;\r\n}\r\ncontract = to_sun4i_dma_contract(vd);\r\nif (list_empty(&contract->demands)) {\r\nlist_del(&contract->vd.node);\r\nvchan_cookie_complete(&contract->vd);\r\ndev_dbg(chan2dev(&vchan->vc.chan),\r\n"Empty contract found and marked complete");\r\n}\r\n} while (list_empty(&contract->demands));\r\npromise = list_first_entry(&contract->demands,\r\nstruct sun4i_dma_promise, list);\r\nvchan->processing = promise;\r\nif (promise) {\r\nvchan->contract = contract;\r\nvchan->pchan = pchan;\r\nset_pchan_interrupt(priv, pchan, contract->is_cyclic, 1);\r\nconfigure_pchan(pchan, promise);\r\n}\r\nreturn 0;\r\nrelease_pchan:\r\nrelease_pchan(priv, pchan);\r\nreturn ret;\r\n}\r\nstatic int sanitize_config(struct dma_slave_config *sconfig,\r\nenum dma_transfer_direction direction)\r\n{\r\nswitch (direction) {\r\ncase DMA_MEM_TO_DEV:\r\nif ((sconfig->dst_addr_width == DMA_SLAVE_BUSWIDTH_UNDEFINED) ||\r\n!sconfig->dst_maxburst)\r\nreturn -EINVAL;\r\nif (sconfig->src_addr_width == DMA_SLAVE_BUSWIDTH_UNDEFINED)\r\nsconfig->src_addr_width = sconfig->dst_addr_width;\r\nif (!sconfig->src_maxburst)\r\nsconfig->src_maxburst = sconfig->dst_maxburst;\r\nbreak;\r\ncase DMA_DEV_TO_MEM:\r\nif ((sconfig->src_addr_width == DMA_SLAVE_BUSWIDTH_UNDEFINED) ||\r\n!sconfig->src_maxburst)\r\nreturn -EINVAL;\r\nif (sconfig->dst_addr_width == DMA_SLAVE_BUSWIDTH_UNDEFINED)\r\nsconfig->dst_addr_width = sconfig->src_addr_width;\r\nif (!sconfig->dst_maxburst)\r\nsconfig->dst_maxburst = sconfig->src_maxburst;\r\nbreak;\r\ndefault:\r\nreturn 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct sun4i_dma_promise *\r\ngenerate_ndma_promise(struct dma_chan *chan, dma_addr_t src, dma_addr_t dest,\r\nsize_t len, struct dma_slave_config *sconfig,\r\nenum dma_transfer_direction direction)\r\n{\r\nstruct sun4i_dma_promise *promise;\r\nint ret;\r\nret = sanitize_config(sconfig, direction);\r\nif (ret)\r\nreturn NULL;\r\npromise = kzalloc(sizeof(*promise), GFP_NOWAIT);\r\nif (!promise)\r\nreturn NULL;\r\npromise->src = src;\r\npromise->dst = dest;\r\npromise->len = len;\r\npromise->cfg = SUN4I_DMA_CFG_LOADING |\r\nSUN4I_NDMA_CFG_BYTE_COUNT_MODE_REMAIN;\r\ndev_dbg(chan2dev(chan),\r\n"src burst %d, dst burst %d, src buswidth %d, dst buswidth %d",\r\nsconfig->src_maxburst, sconfig->dst_maxburst,\r\nsconfig->src_addr_width, sconfig->dst_addr_width);\r\nret = convert_burst(sconfig->src_maxburst);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_SRC_BURST_LENGTH(ret);\r\nret = convert_burst(sconfig->dst_maxburst);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_DST_BURST_LENGTH(ret);\r\nret = convert_buswidth(sconfig->src_addr_width);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_SRC_DATA_WIDTH(ret);\r\nret = convert_buswidth(sconfig->dst_addr_width);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_DST_DATA_WIDTH(ret);\r\nreturn promise;\r\nfail:\r\nkfree(promise);\r\nreturn NULL;\r\n}\r\nstatic struct sun4i_dma_promise *\r\ngenerate_ddma_promise(struct dma_chan *chan, dma_addr_t src, dma_addr_t dest,\r\nsize_t len, struct dma_slave_config *sconfig)\r\n{\r\nstruct sun4i_dma_promise *promise;\r\nint ret;\r\npromise = kzalloc(sizeof(*promise), GFP_NOWAIT);\r\nif (!promise)\r\nreturn NULL;\r\npromise->src = src;\r\npromise->dst = dest;\r\npromise->len = len;\r\npromise->cfg = SUN4I_DMA_CFG_LOADING |\r\nSUN4I_DDMA_CFG_BYTE_COUNT_MODE_REMAIN;\r\nret = convert_burst(sconfig->src_maxburst);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_SRC_BURST_LENGTH(ret);\r\nret = convert_burst(sconfig->dst_maxburst);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_DST_BURST_LENGTH(ret);\r\nret = convert_buswidth(sconfig->src_addr_width);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_SRC_DATA_WIDTH(ret);\r\nret = convert_buswidth(sconfig->dst_addr_width);\r\nif (IS_ERR_VALUE(ret))\r\ngoto fail;\r\npromise->cfg |= SUN4I_DMA_CFG_DST_DATA_WIDTH(ret);\r\nreturn promise;\r\nfail:\r\nkfree(promise);\r\nreturn NULL;\r\n}\r\nstatic struct sun4i_dma_contract *generate_dma_contract(void)\r\n{\r\nstruct sun4i_dma_contract *contract;\r\ncontract = kzalloc(sizeof(*contract), GFP_NOWAIT);\r\nif (!contract)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&contract->demands);\r\nINIT_LIST_HEAD(&contract->completed_demands);\r\nreturn contract;\r\n}\r\nstatic struct sun4i_dma_promise *\r\nget_next_cyclic_promise(struct sun4i_dma_contract *contract)\r\n{\r\nstruct sun4i_dma_promise *promise;\r\npromise = list_first_entry_or_null(&contract->demands,\r\nstruct sun4i_dma_promise, list);\r\nif (!promise) {\r\nlist_splice_init(&contract->completed_demands,\r\n&contract->demands);\r\npromise = list_first_entry(&contract->demands,\r\nstruct sun4i_dma_promise, list);\r\n}\r\nreturn promise;\r\n}\r\nstatic void sun4i_dma_free_contract(struct virt_dma_desc *vd)\r\n{\r\nstruct sun4i_dma_contract *contract = to_sun4i_dma_contract(vd);\r\nstruct sun4i_dma_promise *promise, *tmp;\r\nlist_for_each_entry_safe(promise, tmp, &contract->demands, list)\r\nkfree(promise);\r\nlist_for_each_entry_safe(promise, tmp, &contract->completed_demands, list)\r\nkfree(promise);\r\nkfree(contract);\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\nsun4i_dma_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest,\r\ndma_addr_t src, size_t len, unsigned long flags)\r\n{\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nstruct dma_slave_config *sconfig = &vchan->cfg;\r\nstruct sun4i_dma_promise *promise;\r\nstruct sun4i_dma_contract *contract;\r\ncontract = generate_dma_contract();\r\nif (!contract)\r\nreturn NULL;\r\nsconfig->src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\r\nsconfig->dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\r\nsconfig->src_maxburst = 8;\r\nsconfig->dst_maxburst = 8;\r\nif (vchan->is_dedicated)\r\npromise = generate_ddma_promise(chan, src, dest, len, sconfig);\r\nelse\r\npromise = generate_ndma_promise(chan, src, dest, len, sconfig,\r\nDMA_MEM_TO_MEM);\r\nif (!promise) {\r\nkfree(contract);\r\nreturn NULL;\r\n}\r\nif (vchan->is_dedicated) {\r\npromise->cfg |= SUN4I_DMA_CFG_SRC_DRQ_TYPE(SUN4I_DDMA_DRQ_TYPE_SDRAM) |\r\nSUN4I_DMA_CFG_DST_DRQ_TYPE(SUN4I_DDMA_DRQ_TYPE_SDRAM);\r\n} else {\r\npromise->cfg |= SUN4I_DMA_CFG_SRC_DRQ_TYPE(SUN4I_NDMA_DRQ_TYPE_SDRAM) |\r\nSUN4I_DMA_CFG_DST_DRQ_TYPE(SUN4I_NDMA_DRQ_TYPE_SDRAM);\r\n}\r\nlist_add_tail(&promise->list, &contract->demands);\r\nreturn vchan_tx_prep(&vchan->vc, &contract->vd, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\nsun4i_dma_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t buf, size_t len,\r\nsize_t period_len, enum dma_transfer_direction dir,\r\nunsigned long flags)\r\n{\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nstruct dma_slave_config *sconfig = &vchan->cfg;\r\nstruct sun4i_dma_promise *promise;\r\nstruct sun4i_dma_contract *contract;\r\ndma_addr_t src, dest;\r\nu32 endpoints;\r\nint nr_periods, offset, plength, i;\r\nif (!is_slave_direction(dir)) {\r\ndev_err(chan2dev(chan), "Invalid DMA direction\n");\r\nreturn NULL;\r\n}\r\nif (vchan->is_dedicated) {\r\ndev_err(chan2dev(chan),\r\n"Cyclic transfers are only supported on Normal DMA\n");\r\nreturn NULL;\r\n}\r\ncontract = generate_dma_contract();\r\nif (!contract)\r\nreturn NULL;\r\ncontract->is_cyclic = 1;\r\nif (dir == DMA_MEM_TO_DEV) {\r\nsrc = buf;\r\ndest = sconfig->dst_addr;\r\nendpoints = SUN4I_DMA_CFG_SRC_DRQ_TYPE(SUN4I_NDMA_DRQ_TYPE_SDRAM) |\r\nSUN4I_DMA_CFG_DST_DRQ_TYPE(vchan->endpoint) |\r\nSUN4I_DMA_CFG_DST_ADDR_MODE(SUN4I_NDMA_ADDR_MODE_IO);\r\n} else {\r\nsrc = sconfig->src_addr;\r\ndest = buf;\r\nendpoints = SUN4I_DMA_CFG_SRC_DRQ_TYPE(vchan->endpoint) |\r\nSUN4I_DMA_CFG_SRC_ADDR_MODE(SUN4I_NDMA_ADDR_MODE_IO) |\r\nSUN4I_DMA_CFG_DST_DRQ_TYPE(SUN4I_NDMA_DRQ_TYPE_SDRAM);\r\n}\r\nnr_periods = DIV_ROUND_UP(len / period_len, 2);\r\nfor (i = 0; i < nr_periods; i++) {\r\noffset = i * period_len * 2;\r\nplength = min((len - offset), (period_len * 2));\r\nif (dir == DMA_MEM_TO_DEV)\r\nsrc = buf + offset;\r\nelse\r\ndest = buf + offset;\r\npromise = generate_ndma_promise(chan, src, dest,\r\nplength, sconfig, dir);\r\nif (!promise) {\r\nreturn NULL;\r\n}\r\npromise->cfg |= endpoints;\r\nlist_add_tail(&promise->list, &contract->demands);\r\n}\r\nreturn vchan_tx_prep(&vchan->vc, &contract->vd, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\nsun4i_dma_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction dir,\r\nunsigned long flags, void *context)\r\n{\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nstruct dma_slave_config *sconfig = &vchan->cfg;\r\nstruct sun4i_dma_promise *promise;\r\nstruct sun4i_dma_contract *contract;\r\nu8 ram_type, io_mode, linear_mode;\r\nstruct scatterlist *sg;\r\ndma_addr_t srcaddr, dstaddr;\r\nu32 endpoints, para;\r\nint i;\r\nif (!sgl)\r\nreturn NULL;\r\nif (!is_slave_direction(dir)) {\r\ndev_err(chan2dev(chan), "Invalid DMA direction\n");\r\nreturn NULL;\r\n}\r\ncontract = generate_dma_contract();\r\nif (!contract)\r\nreturn NULL;\r\nif (vchan->is_dedicated) {\r\nio_mode = SUN4I_DDMA_ADDR_MODE_IO;\r\nlinear_mode = SUN4I_DDMA_ADDR_MODE_LINEAR;\r\nram_type = SUN4I_DDMA_DRQ_TYPE_SDRAM;\r\n} else {\r\nio_mode = SUN4I_NDMA_ADDR_MODE_IO;\r\nlinear_mode = SUN4I_NDMA_ADDR_MODE_LINEAR;\r\nram_type = SUN4I_NDMA_DRQ_TYPE_SDRAM;\r\n}\r\nif (dir == DMA_MEM_TO_DEV)\r\nendpoints = SUN4I_DMA_CFG_DST_DRQ_TYPE(vchan->endpoint) |\r\nSUN4I_DMA_CFG_DST_ADDR_MODE(io_mode) |\r\nSUN4I_DMA_CFG_SRC_DRQ_TYPE(ram_type) |\r\nSUN4I_DMA_CFG_SRC_ADDR_MODE(linear_mode);\r\nelse\r\nendpoints = SUN4I_DMA_CFG_DST_DRQ_TYPE(ram_type) |\r\nSUN4I_DMA_CFG_DST_ADDR_MODE(linear_mode) |\r\nSUN4I_DMA_CFG_SRC_DRQ_TYPE(vchan->endpoint) |\r\nSUN4I_DMA_CFG_SRC_ADDR_MODE(io_mode);\r\nfor_each_sg(sgl, sg, sg_len, i) {\r\nif (dir == DMA_MEM_TO_DEV) {\r\nsrcaddr = sg_dma_address(sg);\r\ndstaddr = sconfig->dst_addr;\r\n} else {\r\nsrcaddr = sconfig->src_addr;\r\ndstaddr = sg_dma_address(sg);\r\n}\r\npara = SUN4I_DDMA_MAGIC_SPI_PARAMETERS;\r\nif (vchan->is_dedicated)\r\npromise = generate_ddma_promise(chan, srcaddr, dstaddr,\r\nsg_dma_len(sg),\r\nsconfig);\r\nelse\r\npromise = generate_ndma_promise(chan, srcaddr, dstaddr,\r\nsg_dma_len(sg),\r\nsconfig, dir);\r\nif (!promise)\r\nreturn NULL;\r\npromise->cfg |= endpoints;\r\npromise->para = para;\r\nlist_add_tail(&promise->list, &contract->demands);\r\n}\r\nreturn vchan_tx_prep(&vchan->vc, &contract->vd, flags);\r\n}\r\nstatic int sun4i_dma_terminate_all(struct dma_chan *chan)\r\n{\r\nstruct sun4i_dma_dev *priv = to_sun4i_dma_dev(chan->device);\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nstruct sun4i_dma_pchan *pchan = vchan->pchan;\r\nLIST_HEAD(head);\r\nunsigned long flags;\r\nspin_lock_irqsave(&vchan->vc.lock, flags);\r\nvchan_get_all_descriptors(&vchan->vc, &head);\r\nspin_unlock_irqrestore(&vchan->vc.lock, flags);\r\nif (pchan) {\r\nif (pchan->is_dedicated)\r\nwritel(0, pchan->base + SUN4I_DDMA_CFG_REG);\r\nelse\r\nwritel(0, pchan->base + SUN4I_NDMA_CFG_REG);\r\nset_pchan_interrupt(priv, pchan, 0, 0);\r\nrelease_pchan(priv, pchan);\r\n}\r\nspin_lock_irqsave(&vchan->vc.lock, flags);\r\nvchan_dma_desc_free_list(&vchan->vc, &head);\r\nvchan->processing = NULL;\r\nvchan->pchan = NULL;\r\nspin_unlock_irqrestore(&vchan->vc.lock, flags);\r\nreturn 0;\r\n}\r\nstatic int sun4i_dma_config(struct dma_chan *chan,\r\nstruct dma_slave_config *config)\r\n{\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nmemcpy(&vchan->cfg, config, sizeof(*config));\r\nreturn 0;\r\n}\r\nstatic struct dma_chan *sun4i_dma_of_xlate(struct of_phandle_args *dma_spec,\r\nstruct of_dma *ofdma)\r\n{\r\nstruct sun4i_dma_dev *priv = ofdma->of_dma_data;\r\nstruct sun4i_dma_vchan *vchan;\r\nstruct dma_chan *chan;\r\nu8 is_dedicated = dma_spec->args[0];\r\nu8 endpoint = dma_spec->args[1];\r\nif (is_dedicated != 0 && is_dedicated != 1)\r\nreturn NULL;\r\nif ((is_dedicated && endpoint >= SUN4I_DDMA_DRQ_TYPE_LIMIT) ||\r\n(!is_dedicated && endpoint >= SUN4I_NDMA_DRQ_TYPE_LIMIT))\r\nreturn NULL;\r\nchan = dma_get_any_slave_channel(&priv->slave);\r\nif (!chan)\r\nreturn NULL;\r\nvchan = to_sun4i_dma_vchan(chan);\r\nvchan->is_dedicated = is_dedicated;\r\nvchan->endpoint = endpoint;\r\nreturn chan;\r\n}\r\nstatic enum dma_status sun4i_dma_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie,\r\nstruct dma_tx_state *state)\r\n{\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nstruct sun4i_dma_pchan *pchan = vchan->pchan;\r\nstruct sun4i_dma_contract *contract;\r\nstruct sun4i_dma_promise *promise;\r\nstruct virt_dma_desc *vd;\r\nunsigned long flags;\r\nenum dma_status ret;\r\nsize_t bytes = 0;\r\nret = dma_cookie_status(chan, cookie, state);\r\nif (!state || (ret == DMA_COMPLETE))\r\nreturn ret;\r\nspin_lock_irqsave(&vchan->vc.lock, flags);\r\nvd = vchan_find_desc(&vchan->vc, cookie);\r\nif (!vd)\r\ngoto exit;\r\ncontract = to_sun4i_dma_contract(vd);\r\nlist_for_each_entry(promise, &contract->demands, list)\r\nbytes += promise->len;\r\npromise = list_first_entry_or_null(&contract->demands,\r\nstruct sun4i_dma_promise, list);\r\nif (promise && pchan) {\r\nbytes -= promise->len;\r\nif (pchan->is_dedicated)\r\nbytes += readl(pchan->base + SUN4I_DDMA_BYTE_COUNT_REG);\r\nelse\r\nbytes += readl(pchan->base + SUN4I_NDMA_BYTE_COUNT_REG);\r\n}\r\nexit:\r\ndma_set_residue(state, bytes);\r\nspin_unlock_irqrestore(&vchan->vc.lock, flags);\r\nreturn ret;\r\n}\r\nstatic void sun4i_dma_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct sun4i_dma_dev *priv = to_sun4i_dma_dev(chan->device);\r\nstruct sun4i_dma_vchan *vchan = to_sun4i_dma_vchan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&vchan->vc.lock, flags);\r\nif (vchan_issue_pending(&vchan->vc))\r\n__execute_vchan_pending(priv, vchan);\r\nspin_unlock_irqrestore(&vchan->vc.lock, flags);\r\n}\r\nstatic irqreturn_t sun4i_dma_interrupt(int irq, void *dev_id)\r\n{\r\nstruct sun4i_dma_dev *priv = dev_id;\r\nstruct sun4i_dma_pchan *pchans = priv->pchans, *pchan;\r\nstruct sun4i_dma_vchan *vchan;\r\nstruct sun4i_dma_contract *contract;\r\nstruct sun4i_dma_promise *promise;\r\nunsigned long pendirq, irqs, disableirqs;\r\nint bit, i, free_room, allow_mitigation = 1;\r\npendirq = readl_relaxed(priv->base + SUN4I_DMA_IRQ_PENDING_STATUS_REG);\r\nhandle_pending:\r\ndisableirqs = 0;\r\nfree_room = 0;\r\nfor_each_set_bit(bit, &pendirq, 32) {\r\npchan = &pchans[bit >> 1];\r\nvchan = pchan->vchan;\r\nif (!vchan)\r\ncontinue;\r\ncontract = vchan->contract;\r\nif (bit & 1) {\r\nspin_lock(&vchan->vc.lock);\r\nlist_del(&vchan->processing->list);\r\nlist_add_tail(&vchan->processing->list,\r\n&contract->completed_demands);\r\nif (contract->is_cyclic) {\r\npromise = get_next_cyclic_promise(contract);\r\nvchan->processing = promise;\r\nconfigure_pchan(pchan, promise);\r\nvchan_cyclic_callback(&contract->vd);\r\n} else {\r\nvchan->processing = NULL;\r\nvchan->pchan = NULL;\r\nfree_room = 1;\r\ndisableirqs |= BIT(bit);\r\nrelease_pchan(priv, pchan);\r\n}\r\nspin_unlock(&vchan->vc.lock);\r\n} else {\r\nif (contract->is_cyclic)\r\nvchan_cyclic_callback(&contract->vd);\r\nelse\r\ndisableirqs |= BIT(bit);\r\n}\r\n}\r\nspin_lock(&priv->lock);\r\nirqs = readl_relaxed(priv->base + SUN4I_DMA_IRQ_ENABLE_REG);\r\nwritel_relaxed(irqs & ~disableirqs,\r\npriv->base + SUN4I_DMA_IRQ_ENABLE_REG);\r\nspin_unlock(&priv->lock);\r\nwritel_relaxed(pendirq, priv->base + SUN4I_DMA_IRQ_PENDING_STATUS_REG);\r\nif (free_room) {\r\nfor (i = 0; i < SUN4I_DMA_NR_MAX_VCHANS; i++) {\r\nvchan = &priv->vchans[i];\r\nspin_lock(&vchan->vc.lock);\r\n__execute_vchan_pending(priv, vchan);\r\nspin_unlock(&vchan->vc.lock);\r\n}\r\n}\r\nif (allow_mitigation) {\r\npendirq = readl_relaxed(priv->base +\r\nSUN4I_DMA_IRQ_PENDING_STATUS_REG);\r\nif (pendirq) {\r\nallow_mitigation = 0;\r\ngoto handle_pending;\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int sun4i_dma_probe(struct platform_device *pdev)\r\n{\r\nstruct sun4i_dma_dev *priv;\r\nstruct resource *res;\r\nint i, j, ret;\r\npriv = devm_kzalloc(&pdev->dev, sizeof(*priv), GFP_KERNEL);\r\nif (!priv)\r\nreturn -ENOMEM;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\npriv->base = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(priv->base))\r\nreturn PTR_ERR(priv->base);\r\npriv->irq = platform_get_irq(pdev, 0);\r\nif (priv->irq < 0) {\r\ndev_err(&pdev->dev, "Cannot claim IRQ\n");\r\nreturn priv->irq;\r\n}\r\npriv->clk = devm_clk_get(&pdev->dev, NULL);\r\nif (IS_ERR(priv->clk)) {\r\ndev_err(&pdev->dev, "No clock specified\n");\r\nreturn PTR_ERR(priv->clk);\r\n}\r\nplatform_set_drvdata(pdev, priv);\r\nspin_lock_init(&priv->lock);\r\ndma_cap_zero(priv->slave.cap_mask);\r\ndma_cap_set(DMA_PRIVATE, priv->slave.cap_mask);\r\ndma_cap_set(DMA_MEMCPY, priv->slave.cap_mask);\r\ndma_cap_set(DMA_CYCLIC, priv->slave.cap_mask);\r\ndma_cap_set(DMA_SLAVE, priv->slave.cap_mask);\r\nINIT_LIST_HEAD(&priv->slave.channels);\r\npriv->slave.device_free_chan_resources = sun4i_dma_free_chan_resources;\r\npriv->slave.device_tx_status = sun4i_dma_tx_status;\r\npriv->slave.device_issue_pending = sun4i_dma_issue_pending;\r\npriv->slave.device_prep_slave_sg = sun4i_dma_prep_slave_sg;\r\npriv->slave.device_prep_dma_memcpy = sun4i_dma_prep_dma_memcpy;\r\npriv->slave.device_prep_dma_cyclic = sun4i_dma_prep_dma_cyclic;\r\npriv->slave.device_config = sun4i_dma_config;\r\npriv->slave.device_terminate_all = sun4i_dma_terminate_all;\r\npriv->slave.copy_align = 2;\r\npriv->slave.src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\r\nBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\r\nBIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\npriv->slave.dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |\r\nBIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |\r\nBIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\npriv->slave.directions = BIT(DMA_DEV_TO_MEM) |\r\nBIT(DMA_MEM_TO_DEV);\r\npriv->slave.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\r\npriv->slave.dev = &pdev->dev;\r\npriv->pchans = devm_kcalloc(&pdev->dev, SUN4I_DMA_NR_MAX_CHANNELS,\r\nsizeof(struct sun4i_dma_pchan), GFP_KERNEL);\r\npriv->vchans = devm_kcalloc(&pdev->dev, SUN4I_DMA_NR_MAX_VCHANS,\r\nsizeof(struct sun4i_dma_vchan), GFP_KERNEL);\r\nif (!priv->vchans || !priv->pchans)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < SUN4I_NDMA_NR_MAX_CHANNELS; i++)\r\npriv->pchans[i].base = priv->base +\r\nSUN4I_NDMA_CHANNEL_REG_BASE(i);\r\nfor (j = 0; i < SUN4I_DMA_NR_MAX_CHANNELS; i++, j++) {\r\npriv->pchans[i].base = priv->base +\r\nSUN4I_DDMA_CHANNEL_REG_BASE(j);\r\npriv->pchans[i].is_dedicated = 1;\r\n}\r\nfor (i = 0; i < SUN4I_DMA_NR_MAX_VCHANS; i++) {\r\nstruct sun4i_dma_vchan *vchan = &priv->vchans[i];\r\nspin_lock_init(&vchan->vc.lock);\r\nvchan->vc.desc_free = sun4i_dma_free_contract;\r\nvchan_init(&vchan->vc, &priv->slave);\r\n}\r\nret = clk_prepare_enable(priv->clk);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Couldn't enable the clock\n");\r\nreturn ret;\r\n}\r\nwritel(0, priv->base + SUN4I_DMA_IRQ_ENABLE_REG);\r\nwritel(0xFFFFFFFF, priv->base + SUN4I_DMA_IRQ_PENDING_STATUS_REG);\r\nret = devm_request_irq(&pdev->dev, priv->irq, sun4i_dma_interrupt,\r\n0, dev_name(&pdev->dev), priv);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Cannot request IRQ\n");\r\ngoto err_clk_disable;\r\n}\r\nret = dma_async_device_register(&priv->slave);\r\nif (ret) {\r\ndev_warn(&pdev->dev, "Failed to register DMA engine device\n");\r\ngoto err_clk_disable;\r\n}\r\nret = of_dma_controller_register(pdev->dev.of_node, sun4i_dma_of_xlate,\r\npriv);\r\nif (ret) {\r\ndev_err(&pdev->dev, "of_dma_controller_register failed\n");\r\ngoto err_dma_unregister;\r\n}\r\ndev_dbg(&pdev->dev, "Successfully probed SUN4I_DMA\n");\r\nreturn 0;\r\nerr_dma_unregister:\r\ndma_async_device_unregister(&priv->slave);\r\nerr_clk_disable:\r\nclk_disable_unprepare(priv->clk);\r\nreturn ret;\r\n}\r\nstatic int sun4i_dma_remove(struct platform_device *pdev)\r\n{\r\nstruct sun4i_dma_dev *priv = platform_get_drvdata(pdev);\r\ndisable_irq(priv->irq);\r\nof_dma_controller_free(pdev->dev.of_node);\r\ndma_async_device_unregister(&priv->slave);\r\nclk_disable_unprepare(priv->clk);\r\nreturn 0;\r\n}
