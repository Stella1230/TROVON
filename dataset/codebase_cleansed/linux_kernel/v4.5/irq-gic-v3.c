static inline unsigned int gic_irq(struct irq_data *d)\r\n{\r\nreturn d->hwirq;\r\n}\r\nstatic inline int gic_irq_in_rdist(struct irq_data *d)\r\n{\r\nreturn gic_irq(d) < 32;\r\n}\r\nstatic inline void __iomem *gic_dist_base(struct irq_data *d)\r\n{\r\nif (gic_irq_in_rdist(d))\r\nreturn gic_data_rdist_sgi_base();\r\nif (d->hwirq <= 1023)\r\nreturn gic_data.dist_base;\r\nreturn NULL;\r\n}\r\nstatic void gic_do_wait_for_rwp(void __iomem *base)\r\n{\r\nu32 count = 1000000;\r\nwhile (readl_relaxed(base + GICD_CTLR) & GICD_CTLR_RWP) {\r\ncount--;\r\nif (!count) {\r\npr_err_ratelimited("RWP timeout, gone fishing\n");\r\nreturn;\r\n}\r\ncpu_relax();\r\nudelay(1);\r\n};\r\n}\r\nstatic void gic_dist_wait_for_rwp(void)\r\n{\r\ngic_do_wait_for_rwp(gic_data.dist_base);\r\n}\r\nstatic void gic_redist_wait_for_rwp(void)\r\n{\r\ngic_do_wait_for_rwp(gic_data_rdist_rd_base());\r\n}\r\nstatic u64 __maybe_unused gic_read_iar(void)\r\n{\r\nif (static_branch_unlikely(&is_cavium_thunderx))\r\nreturn gic_read_iar_cavium_thunderx();\r\nelse\r\nreturn gic_read_iar_common();\r\n}\r\nstatic void gic_enable_redist(bool enable)\r\n{\r\nvoid __iomem *rbase;\r\nu32 count = 1000000;\r\nu32 val;\r\nrbase = gic_data_rdist_rd_base();\r\nval = readl_relaxed(rbase + GICR_WAKER);\r\nif (enable)\r\nval &= ~GICR_WAKER_ProcessorSleep;\r\nelse\r\nval |= GICR_WAKER_ProcessorSleep;\r\nwritel_relaxed(val, rbase + GICR_WAKER);\r\nif (!enable) {\r\nval = readl_relaxed(rbase + GICR_WAKER);\r\nif (!(val & GICR_WAKER_ProcessorSleep))\r\nreturn;\r\n}\r\nwhile (count--) {\r\nval = readl_relaxed(rbase + GICR_WAKER);\r\nif (enable ^ (val & GICR_WAKER_ChildrenAsleep))\r\nbreak;\r\ncpu_relax();\r\nudelay(1);\r\n};\r\nif (!count)\r\npr_err_ratelimited("redistributor failed to %s...\n",\r\nenable ? "wakeup" : "sleep");\r\n}\r\nstatic int gic_peek_irq(struct irq_data *d, u32 offset)\r\n{\r\nu32 mask = 1 << (gic_irq(d) % 32);\r\nvoid __iomem *base;\r\nif (gic_irq_in_rdist(d))\r\nbase = gic_data_rdist_sgi_base();\r\nelse\r\nbase = gic_data.dist_base;\r\nreturn !!(readl_relaxed(base + offset + (gic_irq(d) / 32) * 4) & mask);\r\n}\r\nstatic void gic_poke_irq(struct irq_data *d, u32 offset)\r\n{\r\nu32 mask = 1 << (gic_irq(d) % 32);\r\nvoid (*rwp_wait)(void);\r\nvoid __iomem *base;\r\nif (gic_irq_in_rdist(d)) {\r\nbase = gic_data_rdist_sgi_base();\r\nrwp_wait = gic_redist_wait_for_rwp;\r\n} else {\r\nbase = gic_data.dist_base;\r\nrwp_wait = gic_dist_wait_for_rwp;\r\n}\r\nwritel_relaxed(mask, base + offset + (gic_irq(d) / 32) * 4);\r\nrwp_wait();\r\n}\r\nstatic void gic_mask_irq(struct irq_data *d)\r\n{\r\ngic_poke_irq(d, GICD_ICENABLER);\r\n}\r\nstatic void gic_eoimode1_mask_irq(struct irq_data *d)\r\n{\r\ngic_mask_irq(d);\r\nif (irqd_is_forwarded_to_vcpu(d))\r\ngic_poke_irq(d, GICD_ICACTIVER);\r\n}\r\nstatic void gic_unmask_irq(struct irq_data *d)\r\n{\r\ngic_poke_irq(d, GICD_ISENABLER);\r\n}\r\nstatic int gic_irq_set_irqchip_state(struct irq_data *d,\r\nenum irqchip_irq_state which, bool val)\r\n{\r\nu32 reg;\r\nif (d->hwirq >= gic_data.irq_nr)\r\nreturn -EINVAL;\r\nswitch (which) {\r\ncase IRQCHIP_STATE_PENDING:\r\nreg = val ? GICD_ISPENDR : GICD_ICPENDR;\r\nbreak;\r\ncase IRQCHIP_STATE_ACTIVE:\r\nreg = val ? GICD_ISACTIVER : GICD_ICACTIVER;\r\nbreak;\r\ncase IRQCHIP_STATE_MASKED:\r\nreg = val ? GICD_ICENABLER : GICD_ISENABLER;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ngic_poke_irq(d, reg);\r\nreturn 0;\r\n}\r\nstatic int gic_irq_get_irqchip_state(struct irq_data *d,\r\nenum irqchip_irq_state which, bool *val)\r\n{\r\nif (d->hwirq >= gic_data.irq_nr)\r\nreturn -EINVAL;\r\nswitch (which) {\r\ncase IRQCHIP_STATE_PENDING:\r\n*val = gic_peek_irq(d, GICD_ISPENDR);\r\nbreak;\r\ncase IRQCHIP_STATE_ACTIVE:\r\n*val = gic_peek_irq(d, GICD_ISACTIVER);\r\nbreak;\r\ncase IRQCHIP_STATE_MASKED:\r\n*val = !gic_peek_irq(d, GICD_ISENABLER);\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void gic_eoi_irq(struct irq_data *d)\r\n{\r\ngic_write_eoir(gic_irq(d));\r\n}\r\nstatic void gic_eoimode1_eoi_irq(struct irq_data *d)\r\n{\r\nif (gic_irq(d) >= 8192 || irqd_is_forwarded_to_vcpu(d))\r\nreturn;\r\ngic_write_dir(gic_irq(d));\r\n}\r\nstatic int gic_set_type(struct irq_data *d, unsigned int type)\r\n{\r\nunsigned int irq = gic_irq(d);\r\nvoid (*rwp_wait)(void);\r\nvoid __iomem *base;\r\nif (irq < 16)\r\nreturn -EINVAL;\r\nif (irq >= 32 && type != IRQ_TYPE_LEVEL_HIGH &&\r\ntype != IRQ_TYPE_EDGE_RISING)\r\nreturn -EINVAL;\r\nif (gic_irq_in_rdist(d)) {\r\nbase = gic_data_rdist_sgi_base();\r\nrwp_wait = gic_redist_wait_for_rwp;\r\n} else {\r\nbase = gic_data.dist_base;\r\nrwp_wait = gic_dist_wait_for_rwp;\r\n}\r\nreturn gic_configure_irq(irq, type, base, rwp_wait);\r\n}\r\nstatic int gic_irq_set_vcpu_affinity(struct irq_data *d, void *vcpu)\r\n{\r\nif (vcpu)\r\nirqd_set_forwarded_to_vcpu(d);\r\nelse\r\nirqd_clr_forwarded_to_vcpu(d);\r\nreturn 0;\r\n}\r\nstatic u64 gic_mpidr_to_affinity(unsigned long mpidr)\r\n{\r\nu64 aff;\r\naff = ((u64)MPIDR_AFFINITY_LEVEL(mpidr, 3) << 32 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 2) << 16 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 1) << 8 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 0));\r\nreturn aff;\r\n}\r\nstatic asmlinkage void __exception_irq_entry gic_handle_irq(struct pt_regs *regs)\r\n{\r\nu32 irqnr;\r\ndo {\r\nirqnr = gic_read_iar();\r\nif (likely(irqnr > 15 && irqnr < 1020) || irqnr >= 8192) {\r\nint err;\r\nif (static_key_true(&supports_deactivate))\r\ngic_write_eoir(irqnr);\r\nerr = handle_domain_irq(gic_data.domain, irqnr, regs);\r\nif (err) {\r\nWARN_ONCE(true, "Unexpected interrupt received!\n");\r\nif (static_key_true(&supports_deactivate)) {\r\nif (irqnr < 8192)\r\ngic_write_dir(irqnr);\r\n} else {\r\ngic_write_eoir(irqnr);\r\n}\r\n}\r\ncontinue;\r\n}\r\nif (irqnr < 16) {\r\ngic_write_eoir(irqnr);\r\nif (static_key_true(&supports_deactivate))\r\ngic_write_dir(irqnr);\r\n#ifdef CONFIG_SMP\r\nhandle_IPI(irqnr, regs);\r\n#else\r\nWARN_ONCE(true, "Unexpected SGI received!\n");\r\n#endif\r\ncontinue;\r\n}\r\n} while (irqnr != ICC_IAR1_EL1_SPURIOUS);\r\n}\r\nstatic void __init gic_dist_init(void)\r\n{\r\nunsigned int i;\r\nu64 affinity;\r\nvoid __iomem *base = gic_data.dist_base;\r\nwritel_relaxed(0, base + GICD_CTLR);\r\ngic_dist_wait_for_rwp();\r\ngic_dist_config(base, gic_data.irq_nr, gic_dist_wait_for_rwp);\r\nwritel_relaxed(GICD_CTLR_ARE_NS | GICD_CTLR_ENABLE_G1A | GICD_CTLR_ENABLE_G1,\r\nbase + GICD_CTLR);\r\naffinity = gic_mpidr_to_affinity(cpu_logical_map(smp_processor_id()));\r\nfor (i = 32; i < gic_data.irq_nr; i++)\r\ngic_write_irouter(affinity, base + GICD_IROUTER + i * 8);\r\n}\r\nstatic int gic_populate_rdist(void)\r\n{\r\nunsigned long mpidr = cpu_logical_map(smp_processor_id());\r\nu64 typer;\r\nu32 aff;\r\nint i;\r\naff = (MPIDR_AFFINITY_LEVEL(mpidr, 3) << 24 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 2) << 16 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 1) << 8 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 0));\r\nfor (i = 0; i < gic_data.nr_redist_regions; i++) {\r\nvoid __iomem *ptr = gic_data.redist_regions[i].redist_base;\r\nu32 reg;\r\nreg = readl_relaxed(ptr + GICR_PIDR2) & GIC_PIDR2_ARCH_MASK;\r\nif (reg != GIC_PIDR2_ARCH_GICv3 &&\r\nreg != GIC_PIDR2_ARCH_GICv4) {\r\npr_warn("No redistributor present @%p\n", ptr);\r\nbreak;\r\n}\r\ndo {\r\ntyper = gic_read_typer(ptr + GICR_TYPER);\r\nif ((typer >> 32) == aff) {\r\nu64 offset = ptr - gic_data.redist_regions[i].redist_base;\r\ngic_data_rdist_rd_base() = ptr;\r\ngic_data_rdist()->phys_base = gic_data.redist_regions[i].phys_base + offset;\r\npr_info("CPU%d: found redistributor %lx region %d:%pa\n",\r\nsmp_processor_id(), mpidr, i,\r\n&gic_data_rdist()->phys_base);\r\nreturn 0;\r\n}\r\nif (gic_data.redist_stride) {\r\nptr += gic_data.redist_stride;\r\n} else {\r\nptr += SZ_64K * 2;\r\nif (typer & GICR_TYPER_VLPIS)\r\nptr += SZ_64K * 2;\r\n}\r\n} while (!(typer & GICR_TYPER_LAST));\r\n}\r\nWARN(true, "CPU%d: mpidr %lx has no re-distributor!\n",\r\nsmp_processor_id(), mpidr);\r\nreturn -ENODEV;\r\n}\r\nstatic void gic_cpu_sys_reg_init(void)\r\n{\r\nif (!gic_enable_sre())\r\npr_err("GIC: unable to set SRE (disabled at EL2), panic ahead\n");\r\ngic_write_pmr(DEFAULT_PMR_VALUE);\r\nif (static_key_true(&supports_deactivate)) {\r\ngic_write_ctlr(ICC_CTLR_EL1_EOImode_drop);\r\n} else {\r\ngic_write_ctlr(ICC_CTLR_EL1_EOImode_drop_dir);\r\n}\r\ngic_write_grpen1(1);\r\n}\r\nstatic int gic_dist_supports_lpis(void)\r\n{\r\nreturn !!(readl_relaxed(gic_data.dist_base + GICD_TYPER) & GICD_TYPER_LPIS);\r\n}\r\nstatic void gic_cpu_init(void)\r\n{\r\nvoid __iomem *rbase;\r\nif (gic_populate_rdist())\r\nreturn;\r\ngic_enable_redist(true);\r\nrbase = gic_data_rdist_sgi_base();\r\ngic_cpu_config(rbase, gic_redist_wait_for_rwp);\r\nif (IS_ENABLED(CONFIG_ARM_GIC_V3_ITS) && gic_dist_supports_lpis())\r\nits_cpu_init();\r\ngic_cpu_sys_reg_init();\r\n}\r\nstatic int gic_secondary_init(struct notifier_block *nfb,\r\nunsigned long action, void *hcpu)\r\n{\r\nif (action == CPU_STARTING || action == CPU_STARTING_FROZEN)\r\ngic_cpu_init();\r\nreturn NOTIFY_OK;\r\n}\r\nstatic u16 gic_compute_target_list(int *base_cpu, const struct cpumask *mask,\r\nunsigned long cluster_id)\r\n{\r\nint cpu = *base_cpu;\r\nunsigned long mpidr = cpu_logical_map(cpu);\r\nu16 tlist = 0;\r\nwhile (cpu < nr_cpu_ids) {\r\nif (WARN_ON((mpidr & 0xff) >= 16))\r\ngoto out;\r\ntlist |= 1 << (mpidr & 0xf);\r\ncpu = cpumask_next(cpu, mask);\r\nif (cpu >= nr_cpu_ids)\r\ngoto out;\r\nmpidr = cpu_logical_map(cpu);\r\nif (cluster_id != (mpidr & ~0xffUL)) {\r\ncpu--;\r\ngoto out;\r\n}\r\n}\r\nout:\r\n*base_cpu = cpu;\r\nreturn tlist;\r\n}\r\nstatic void gic_send_sgi(u64 cluster_id, u16 tlist, unsigned int irq)\r\n{\r\nu64 val;\r\nval = (MPIDR_TO_SGI_AFFINITY(cluster_id, 3) |\r\nMPIDR_TO_SGI_AFFINITY(cluster_id, 2) |\r\nirq << ICC_SGI1R_SGI_ID_SHIFT |\r\nMPIDR_TO_SGI_AFFINITY(cluster_id, 1) |\r\ntlist << ICC_SGI1R_TARGET_LIST_SHIFT);\r\npr_debug("CPU%d: ICC_SGI1R_EL1 %llx\n", smp_processor_id(), val);\r\ngic_write_sgi1r(val);\r\n}\r\nstatic void gic_raise_softirq(const struct cpumask *mask, unsigned int irq)\r\n{\r\nint cpu;\r\nif (WARN_ON(irq >= 16))\r\nreturn;\r\nsmp_wmb();\r\nfor_each_cpu(cpu, mask) {\r\nunsigned long cluster_id = cpu_logical_map(cpu) & ~0xffUL;\r\nu16 tlist;\r\ntlist = gic_compute_target_list(&cpu, mask, cluster_id);\r\ngic_send_sgi(cluster_id, tlist, irq);\r\n}\r\nisb();\r\n}\r\nstatic void gic_smp_init(void)\r\n{\r\nset_smp_cross_call(gic_raise_softirq);\r\nregister_cpu_notifier(&gic_cpu_notifier);\r\n}\r\nstatic int gic_set_affinity(struct irq_data *d, const struct cpumask *mask_val,\r\nbool force)\r\n{\r\nunsigned int cpu = cpumask_any_and(mask_val, cpu_online_mask);\r\nvoid __iomem *reg;\r\nint enabled;\r\nu64 val;\r\nif (gic_irq_in_rdist(d))\r\nreturn -EINVAL;\r\nenabled = gic_peek_irq(d, GICD_ISENABLER);\r\nif (enabled)\r\ngic_mask_irq(d);\r\nreg = gic_dist_base(d) + GICD_IROUTER + (gic_irq(d) * 8);\r\nval = gic_mpidr_to_affinity(cpu_logical_map(cpu));\r\ngic_write_irouter(val, reg);\r\nif (enabled)\r\ngic_unmask_irq(d);\r\nelse\r\ngic_dist_wait_for_rwp();\r\nreturn IRQ_SET_MASK_OK;\r\n}\r\nstatic int gic_cpu_pm_notifier(struct notifier_block *self,\r\nunsigned long cmd, void *v)\r\n{\r\nif (cmd == CPU_PM_EXIT) {\r\ngic_enable_redist(true);\r\ngic_cpu_sys_reg_init();\r\n} else if (cmd == CPU_PM_ENTER) {\r\ngic_write_grpen1(0);\r\ngic_enable_redist(false);\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic void gic_cpu_pm_init(void)\r\n{\r\ncpu_pm_register_notifier(&gic_cpu_pm_notifier_block);\r\n}\r\nstatic inline void gic_cpu_pm_init(void) { }\r\nstatic int gic_irq_domain_map(struct irq_domain *d, unsigned int irq,\r\nirq_hw_number_t hw)\r\n{\r\nstruct irq_chip *chip = &gic_chip;\r\nif (static_key_true(&supports_deactivate))\r\nchip = &gic_eoimode1_chip;\r\nif (hw < 16)\r\nreturn -EPERM;\r\nif (hw >= gic_data.irq_nr && hw < 8192)\r\nreturn -EPERM;\r\nif (hw >= GIC_ID_NR)\r\nreturn -EPERM;\r\nif (hw < 32) {\r\nirq_set_percpu_devid(irq);\r\nirq_domain_set_info(d, irq, hw, chip, d->host_data,\r\nhandle_percpu_devid_irq, NULL, NULL);\r\nirq_set_status_flags(irq, IRQ_NOAUTOEN);\r\n}\r\nif (hw >= 32 && hw < gic_data.irq_nr) {\r\nirq_domain_set_info(d, irq, hw, chip, d->host_data,\r\nhandle_fasteoi_irq, NULL, NULL);\r\nirq_set_probe(irq);\r\n}\r\nif (hw >= 8192 && hw < GIC_ID_NR) {\r\nif (!gic_dist_supports_lpis())\r\nreturn -EPERM;\r\nirq_domain_set_info(d, irq, hw, chip, d->host_data,\r\nhandle_fasteoi_irq, NULL, NULL);\r\n}\r\nreturn 0;\r\n}\r\nstatic int gic_irq_domain_translate(struct irq_domain *d,\r\nstruct irq_fwspec *fwspec,\r\nunsigned long *hwirq,\r\nunsigned int *type)\r\n{\r\nif (is_of_node(fwspec->fwnode)) {\r\nif (fwspec->param_count < 3)\r\nreturn -EINVAL;\r\nswitch (fwspec->param[0]) {\r\ncase 0:\r\n*hwirq = fwspec->param[1] + 32;\r\nbreak;\r\ncase 1:\r\n*hwirq = fwspec->param[1] + 16;\r\nbreak;\r\ncase GIC_IRQ_TYPE_LPI:\r\n*hwirq = fwspec->param[1];\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n*type = fwspec->param[2] & IRQ_TYPE_SENSE_MASK;\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int gic_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,\r\nunsigned int nr_irqs, void *arg)\r\n{\r\nint i, ret;\r\nirq_hw_number_t hwirq;\r\nunsigned int type = IRQ_TYPE_NONE;\r\nstruct irq_fwspec *fwspec = arg;\r\nret = gic_irq_domain_translate(domain, fwspec, &hwirq, &type);\r\nif (ret)\r\nreturn ret;\r\nfor (i = 0; i < nr_irqs; i++)\r\ngic_irq_domain_map(domain, virq + i, hwirq + i);\r\nreturn 0;\r\n}\r\nstatic void gic_irq_domain_free(struct irq_domain *domain, unsigned int virq,\r\nunsigned int nr_irqs)\r\n{\r\nint i;\r\nfor (i = 0; i < nr_irqs; i++) {\r\nstruct irq_data *d = irq_domain_get_irq_data(domain, virq + i);\r\nirq_set_handler(virq + i, NULL);\r\nirq_domain_reset_irq_data(d);\r\n}\r\n}\r\nstatic void gicv3_enable_quirks(void)\r\n{\r\n#ifdef CONFIG_ARM64\r\nif (cpus_have_cap(ARM64_WORKAROUND_CAVIUM_23154))\r\nstatic_branch_enable(&is_cavium_thunderx);\r\n#endif\r\n}\r\nstatic int __init gic_of_init(struct device_node *node, struct device_node *parent)\r\n{\r\nvoid __iomem *dist_base;\r\nstruct redist_region *rdist_regs;\r\nu64 redist_stride;\r\nu32 nr_redist_regions;\r\nu32 typer;\r\nu32 reg;\r\nint gic_irqs;\r\nint err;\r\nint i;\r\ndist_base = of_iomap(node, 0);\r\nif (!dist_base) {\r\npr_err("%s: unable to map gic dist registers\n",\r\nnode->full_name);\r\nreturn -ENXIO;\r\n}\r\nreg = readl_relaxed(dist_base + GICD_PIDR2) & GIC_PIDR2_ARCH_MASK;\r\nif (reg != GIC_PIDR2_ARCH_GICv3 && reg != GIC_PIDR2_ARCH_GICv4) {\r\npr_err("%s: no distributor detected, giving up\n",\r\nnode->full_name);\r\nerr = -ENODEV;\r\ngoto out_unmap_dist;\r\n}\r\nif (of_property_read_u32(node, "#redistributor-regions", &nr_redist_regions))\r\nnr_redist_regions = 1;\r\nrdist_regs = kzalloc(sizeof(*rdist_regs) * nr_redist_regions, GFP_KERNEL);\r\nif (!rdist_regs) {\r\nerr = -ENOMEM;\r\ngoto out_unmap_dist;\r\n}\r\nfor (i = 0; i < nr_redist_regions; i++) {\r\nstruct resource res;\r\nint ret;\r\nret = of_address_to_resource(node, 1 + i, &res);\r\nrdist_regs[i].redist_base = of_iomap(node, 1 + i);\r\nif (ret || !rdist_regs[i].redist_base) {\r\npr_err("%s: couldn't map region %d\n",\r\nnode->full_name, i);\r\nerr = -ENODEV;\r\ngoto out_unmap_rdist;\r\n}\r\nrdist_regs[i].phys_base = res.start;\r\n}\r\nif (of_property_read_u64(node, "redistributor-stride", &redist_stride))\r\nredist_stride = 0;\r\nif (!is_hyp_mode_available())\r\nstatic_key_slow_dec(&supports_deactivate);\r\nif (static_key_true(&supports_deactivate))\r\npr_info("GIC: Using split EOI/Deactivate mode\n");\r\ngic_data.dist_base = dist_base;\r\ngic_data.redist_regions = rdist_regs;\r\ngic_data.nr_redist_regions = nr_redist_regions;\r\ngic_data.redist_stride = redist_stride;\r\ngicv3_enable_quirks();\r\ntyper = readl_relaxed(gic_data.dist_base + GICD_TYPER);\r\ngic_data.rdists.id_bits = GICD_TYPER_ID_BITS(typer);\r\ngic_irqs = GICD_TYPER_IRQS(typer);\r\nif (gic_irqs > 1020)\r\ngic_irqs = 1020;\r\ngic_data.irq_nr = gic_irqs;\r\ngic_data.domain = irq_domain_add_tree(node, &gic_irq_domain_ops,\r\n&gic_data);\r\ngic_data.rdists.rdist = alloc_percpu(typeof(*gic_data.rdists.rdist));\r\nif (WARN_ON(!gic_data.domain) || WARN_ON(!gic_data.rdists.rdist)) {\r\nerr = -ENOMEM;\r\ngoto out_free;\r\n}\r\nset_handle_irq(gic_handle_irq);\r\nif (IS_ENABLED(CONFIG_ARM_GIC_V3_ITS) && gic_dist_supports_lpis())\r\nits_init(node, &gic_data.rdists, gic_data.domain);\r\ngic_smp_init();\r\ngic_dist_init();\r\ngic_cpu_init();\r\ngic_cpu_pm_init();\r\nreturn 0;\r\nout_free:\r\nif (gic_data.domain)\r\nirq_domain_remove(gic_data.domain);\r\nfree_percpu(gic_data.rdists.rdist);\r\nout_unmap_rdist:\r\nfor (i = 0; i < nr_redist_regions; i++)\r\nif (rdist_regs[i].redist_base)\r\niounmap(rdist_regs[i].redist_base);\r\nkfree(rdist_regs);\r\nout_unmap_dist:\r\niounmap(dist_base);\r\nreturn err;\r\n}
