static void convert_to_hw_box(struct virtio_gpu_box *dst,\r\nconst struct drm_virtgpu_3d_box *src)\r\n{\r\ndst->x = cpu_to_le32(src->x);\r\ndst->y = cpu_to_le32(src->y);\r\ndst->z = cpu_to_le32(src->z);\r\ndst->w = cpu_to_le32(src->w);\r\ndst->h = cpu_to_le32(src->h);\r\ndst->d = cpu_to_le32(src->d);\r\n}\r\nstatic int virtio_gpu_map_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct virtio_gpu_device *vgdev = dev->dev_private;\r\nstruct drm_virtgpu_map *virtio_gpu_map = data;\r\nreturn virtio_gpu_mode_dumb_mmap(file_priv, vgdev->ddev,\r\nvirtio_gpu_map->handle,\r\n&virtio_gpu_map->offset);\r\n}\r\nstatic int virtio_gpu_object_list_validate(struct ww_acquire_ctx *ticket,\r\nstruct list_head *head)\r\n{\r\nstruct ttm_validate_buffer *buf;\r\nstruct ttm_buffer_object *bo;\r\nstruct virtio_gpu_object *qobj;\r\nint ret;\r\nret = ttm_eu_reserve_buffers(ticket, head, true, NULL);\r\nif (ret != 0)\r\nreturn ret;\r\nlist_for_each_entry(buf, head, head) {\r\nbo = buf->bo;\r\nqobj = container_of(bo, struct virtio_gpu_object, tbo);\r\nret = ttm_bo_validate(bo, &qobj->placement, false, false);\r\nif (ret) {\r\nttm_eu_backoff_reservation(ticket, head);\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void virtio_gpu_unref_list(struct list_head *head)\r\n{\r\nstruct ttm_validate_buffer *buf;\r\nstruct ttm_buffer_object *bo;\r\nstruct virtio_gpu_object *qobj;\r\nlist_for_each_entry(buf, head, head) {\r\nbo = buf->bo;\r\nqobj = container_of(bo, struct virtio_gpu_object, tbo);\r\ndrm_gem_object_unreference_unlocked(&qobj->gem_base);\r\n}\r\n}\r\nstatic int virtio_gpu_execbuffer(struct drm_device *dev,\r\nstruct drm_virtgpu_execbuffer *exbuf,\r\nstruct drm_file *drm_file)\r\n{\r\nstruct virtio_gpu_device *vgdev = dev->dev_private;\r\nstruct virtio_gpu_fpriv *vfpriv = drm_file->driver_priv;\r\nstruct drm_gem_object *gobj;\r\nstruct virtio_gpu_fence *fence;\r\nstruct virtio_gpu_object *qobj;\r\nint ret;\r\nuint32_t *bo_handles = NULL;\r\nvoid __user *user_bo_handles = NULL;\r\nstruct list_head validate_list;\r\nstruct ttm_validate_buffer *buflist = NULL;\r\nint i;\r\nstruct ww_acquire_ctx ticket;\r\nvoid *buf;\r\nif (vgdev->has_virgl_3d == false)\r\nreturn -ENOSYS;\r\nINIT_LIST_HEAD(&validate_list);\r\nif (exbuf->num_bo_handles) {\r\nbo_handles = drm_malloc_ab(exbuf->num_bo_handles,\r\nsizeof(uint32_t));\r\nbuflist = drm_calloc_large(exbuf->num_bo_handles,\r\nsizeof(struct ttm_validate_buffer));\r\nif (!bo_handles || !buflist) {\r\ndrm_free_large(bo_handles);\r\ndrm_free_large(buflist);\r\nreturn -ENOMEM;\r\n}\r\nuser_bo_handles = (void __user *)(uintptr_t)exbuf->bo_handles;\r\nif (copy_from_user(bo_handles, user_bo_handles,\r\nexbuf->num_bo_handles * sizeof(uint32_t))) {\r\nret = -EFAULT;\r\ndrm_free_large(bo_handles);\r\ndrm_free_large(buflist);\r\nreturn ret;\r\n}\r\nfor (i = 0; i < exbuf->num_bo_handles; i++) {\r\ngobj = drm_gem_object_lookup(dev,\r\ndrm_file, bo_handles[i]);\r\nif (!gobj) {\r\ndrm_free_large(bo_handles);\r\ndrm_free_large(buflist);\r\nreturn -ENOENT;\r\n}\r\nqobj = gem_to_virtio_gpu_obj(gobj);\r\nbuflist[i].bo = &qobj->tbo;\r\nlist_add(&buflist[i].head, &validate_list);\r\n}\r\ndrm_free_large(bo_handles);\r\n}\r\nret = virtio_gpu_object_list_validate(&ticket, &validate_list);\r\nif (ret)\r\ngoto out_free;\r\nbuf = kmalloc(exbuf->size, GFP_KERNEL);\r\nif (!buf) {\r\nret = -ENOMEM;\r\ngoto out_unresv;\r\n}\r\nif (copy_from_user(buf, (void __user *)(uintptr_t)exbuf->command,\r\nexbuf->size)) {\r\nkfree(buf);\r\nret = -EFAULT;\r\ngoto out_unresv;\r\n}\r\nvirtio_gpu_cmd_submit(vgdev, buf, exbuf->size,\r\nvfpriv->ctx_id, &fence);\r\nttm_eu_fence_buffer_objects(&ticket, &validate_list, &fence->f);\r\nvirtio_gpu_unref_list(&validate_list);\r\ndrm_free_large(buflist);\r\nfence_put(&fence->f);\r\nreturn 0;\r\nout_unresv:\r\nttm_eu_backoff_reservation(&ticket, &validate_list);\r\nout_free:\r\nvirtio_gpu_unref_list(&validate_list);\r\ndrm_free_large(buflist);\r\nreturn ret;\r\n}\r\nstatic int virtio_gpu_execbuffer_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_virtgpu_execbuffer *execbuffer = data;\r\nreturn virtio_gpu_execbuffer(dev, execbuffer, file_priv);\r\n}\r\nstatic int virtio_gpu_getparam_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct virtio_gpu_device *vgdev = dev->dev_private;\r\nstruct drm_virtgpu_getparam *param = data;\r\nint value;\r\nswitch (param->param) {\r\ncase VIRTGPU_PARAM_3D_FEATURES:\r\nvalue = vgdev->has_virgl_3d == true ? 1 : 0;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (copy_to_user((void __user *)(unsigned long)param->value,\r\n&value, sizeof(int))) {\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int virtio_gpu_resource_create_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct virtio_gpu_device *vgdev = dev->dev_private;\r\nstruct drm_virtgpu_resource_create *rc = data;\r\nint ret;\r\nuint32_t res_id;\r\nstruct virtio_gpu_object *qobj;\r\nstruct drm_gem_object *obj;\r\nuint32_t handle = 0;\r\nuint32_t size;\r\nstruct list_head validate_list;\r\nstruct ttm_validate_buffer mainbuf;\r\nstruct virtio_gpu_fence *fence = NULL;\r\nstruct ww_acquire_ctx ticket;\r\nstruct virtio_gpu_resource_create_3d rc_3d;\r\nif (vgdev->has_virgl_3d == false) {\r\nif (rc->depth > 1)\r\nreturn -EINVAL;\r\nif (rc->nr_samples > 1)\r\nreturn -EINVAL;\r\nif (rc->last_level > 1)\r\nreturn -EINVAL;\r\nif (rc->target != 2)\r\nreturn -EINVAL;\r\nif (rc->array_size > 1)\r\nreturn -EINVAL;\r\n}\r\nINIT_LIST_HEAD(&validate_list);\r\nmemset(&mainbuf, 0, sizeof(struct ttm_validate_buffer));\r\nvirtio_gpu_resource_id_get(vgdev, &res_id);\r\nsize = rc->size;\r\nif (size == 0)\r\nsize = PAGE_SIZE;\r\nqobj = virtio_gpu_alloc_object(dev, size, false, false);\r\nif (IS_ERR(qobj)) {\r\nret = PTR_ERR(qobj);\r\ngoto fail_id;\r\n}\r\nobj = &qobj->gem_base;\r\nif (!vgdev->has_virgl_3d) {\r\nvirtio_gpu_cmd_create_resource(vgdev, res_id, rc->format,\r\nrc->width, rc->height);\r\nret = virtio_gpu_object_attach(vgdev, qobj, res_id, NULL);\r\n} else {\r\ndrm_gem_object_reference(&qobj->gem_base);\r\nmainbuf.bo = &qobj->tbo;\r\nlist_add(&mainbuf.head, &validate_list);\r\nret = virtio_gpu_object_list_validate(&ticket, &validate_list);\r\nif (ret) {\r\nDRM_DEBUG("failed to validate\n");\r\ngoto fail_unref;\r\n}\r\nrc_3d.resource_id = cpu_to_le32(res_id);\r\nrc_3d.target = cpu_to_le32(rc->target);\r\nrc_3d.format = cpu_to_le32(rc->format);\r\nrc_3d.bind = cpu_to_le32(rc->bind);\r\nrc_3d.width = cpu_to_le32(rc->width);\r\nrc_3d.height = cpu_to_le32(rc->height);\r\nrc_3d.depth = cpu_to_le32(rc->depth);\r\nrc_3d.array_size = cpu_to_le32(rc->array_size);\r\nrc_3d.last_level = cpu_to_le32(rc->last_level);\r\nrc_3d.nr_samples = cpu_to_le32(rc->nr_samples);\r\nrc_3d.flags = cpu_to_le32(rc->flags);\r\nvirtio_gpu_cmd_resource_create_3d(vgdev, &rc_3d, NULL);\r\nret = virtio_gpu_object_attach(vgdev, qobj, res_id, &fence);\r\nif (ret) {\r\nttm_eu_backoff_reservation(&ticket, &validate_list);\r\ngoto fail_unref;\r\n}\r\nttm_eu_fence_buffer_objects(&ticket, &validate_list, &fence->f);\r\n}\r\nqobj->hw_res_handle = res_id;\r\nret = drm_gem_handle_create(file_priv, obj, &handle);\r\nif (ret) {\r\ndrm_gem_object_release(obj);\r\nif (vgdev->has_virgl_3d) {\r\nvirtio_gpu_unref_list(&validate_list);\r\nfence_put(&fence->f);\r\n}\r\nreturn ret;\r\n}\r\ndrm_gem_object_unreference_unlocked(obj);\r\nrc->res_handle = res_id;\r\nrc->bo_handle = handle;\r\nif (vgdev->has_virgl_3d) {\r\nvirtio_gpu_unref_list(&validate_list);\r\nfence_put(&fence->f);\r\n}\r\nreturn 0;\r\nfail_unref:\r\nif (vgdev->has_virgl_3d) {\r\nvirtio_gpu_unref_list(&validate_list);\r\nfence_put(&fence->f);\r\n}\r\nfail_id:\r\nvirtio_gpu_resource_id_put(vgdev, res_id);\r\nreturn ret;\r\n}\r\nstatic int virtio_gpu_resource_info_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_virtgpu_resource_info *ri = data;\r\nstruct drm_gem_object *gobj = NULL;\r\nstruct virtio_gpu_object *qobj = NULL;\r\ngobj = drm_gem_object_lookup(dev, file_priv, ri->bo_handle);\r\nif (gobj == NULL)\r\nreturn -ENOENT;\r\nqobj = gem_to_virtio_gpu_obj(gobj);\r\nri->size = qobj->gem_base.size;\r\nri->res_handle = qobj->hw_res_handle;\r\ndrm_gem_object_unreference_unlocked(gobj);\r\nreturn 0;\r\n}\r\nstatic int virtio_gpu_transfer_from_host_ioctl(struct drm_device *dev,\r\nvoid *data,\r\nstruct drm_file *file)\r\n{\r\nstruct virtio_gpu_device *vgdev = dev->dev_private;\r\nstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\r\nstruct drm_virtgpu_3d_transfer_from_host *args = data;\r\nstruct drm_gem_object *gobj = NULL;\r\nstruct virtio_gpu_object *qobj = NULL;\r\nstruct virtio_gpu_fence *fence;\r\nint ret;\r\nu32 offset = args->offset;\r\nstruct virtio_gpu_box box;\r\nif (vgdev->has_virgl_3d == false)\r\nreturn -ENOSYS;\r\ngobj = drm_gem_object_lookup(dev, file, args->bo_handle);\r\nif (gobj == NULL)\r\nreturn -ENOENT;\r\nqobj = gem_to_virtio_gpu_obj(gobj);\r\nret = virtio_gpu_object_reserve(qobj, false);\r\nif (ret)\r\ngoto out;\r\nret = ttm_bo_validate(&qobj->tbo, &qobj->placement,\r\ntrue, false);\r\nif (unlikely(ret))\r\ngoto out_unres;\r\nconvert_to_hw_box(&box, &args->box);\r\nvirtio_gpu_cmd_transfer_from_host_3d\r\n(vgdev, qobj->hw_res_handle,\r\nvfpriv->ctx_id, offset, args->level,\r\n&box, &fence);\r\nreservation_object_add_excl_fence(qobj->tbo.resv,\r\n&fence->f);\r\nfence_put(&fence->f);\r\nout_unres:\r\nvirtio_gpu_object_unreserve(qobj);\r\nout:\r\ndrm_gem_object_unreference_unlocked(gobj);\r\nreturn ret;\r\n}\r\nstatic int virtio_gpu_transfer_to_host_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct virtio_gpu_device *vgdev = dev->dev_private;\r\nstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\r\nstruct drm_virtgpu_3d_transfer_to_host *args = data;\r\nstruct drm_gem_object *gobj = NULL;\r\nstruct virtio_gpu_object *qobj = NULL;\r\nstruct virtio_gpu_fence *fence;\r\nstruct virtio_gpu_box box;\r\nint ret;\r\nu32 offset = args->offset;\r\ngobj = drm_gem_object_lookup(dev, file, args->bo_handle);\r\nif (gobj == NULL)\r\nreturn -ENOENT;\r\nqobj = gem_to_virtio_gpu_obj(gobj);\r\nret = virtio_gpu_object_reserve(qobj, false);\r\nif (ret)\r\ngoto out;\r\nret = ttm_bo_validate(&qobj->tbo, &qobj->placement,\r\ntrue, false);\r\nif (unlikely(ret))\r\ngoto out_unres;\r\nconvert_to_hw_box(&box, &args->box);\r\nif (!vgdev->has_virgl_3d) {\r\nvirtio_gpu_cmd_transfer_to_host_2d\r\n(vgdev, qobj->hw_res_handle, offset,\r\nbox.w, box.h, box.x, box.y, NULL);\r\n} else {\r\nvirtio_gpu_cmd_transfer_to_host_3d\r\n(vgdev, qobj->hw_res_handle,\r\nvfpriv ? vfpriv->ctx_id : 0, offset,\r\nargs->level, &box, &fence);\r\nreservation_object_add_excl_fence(qobj->tbo.resv,\r\n&fence->f);\r\nfence_put(&fence->f);\r\n}\r\nout_unres:\r\nvirtio_gpu_object_unreserve(qobj);\r\nout:\r\ndrm_gem_object_unreference_unlocked(gobj);\r\nreturn ret;\r\n}\r\nstatic int virtio_gpu_wait_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_virtgpu_3d_wait *args = data;\r\nstruct drm_gem_object *gobj = NULL;\r\nstruct virtio_gpu_object *qobj = NULL;\r\nint ret;\r\nbool nowait = false;\r\ngobj = drm_gem_object_lookup(dev, file, args->handle);\r\nif (gobj == NULL)\r\nreturn -ENOENT;\r\nqobj = gem_to_virtio_gpu_obj(gobj);\r\nif (args->flags & VIRTGPU_WAIT_NOWAIT)\r\nnowait = true;\r\nret = virtio_gpu_object_wait(qobj, nowait);\r\ndrm_gem_object_unreference_unlocked(gobj);\r\nreturn ret;\r\n}\r\nstatic int virtio_gpu_get_caps_ioctl(struct drm_device *dev,\r\nvoid *data, struct drm_file *file)\r\n{\r\nstruct virtio_gpu_device *vgdev = dev->dev_private;\r\nstruct drm_virtgpu_get_caps *args = data;\r\nint size;\r\nint i;\r\nint found_valid = -1;\r\nint ret;\r\nstruct virtio_gpu_drv_cap_cache *cache_ent;\r\nvoid *ptr;\r\nif (vgdev->num_capsets == 0)\r\nreturn -ENOSYS;\r\nspin_lock(&vgdev->display_info_lock);\r\nfor (i = 0; i < vgdev->num_capsets; i++) {\r\nif (vgdev->capsets[i].id == args->cap_set_id) {\r\nif (vgdev->capsets[i].max_version >= args->cap_set_ver) {\r\nfound_valid = i;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (found_valid == -1) {\r\nspin_unlock(&vgdev->display_info_lock);\r\nreturn -EINVAL;\r\n}\r\nsize = vgdev->capsets[found_valid].max_size;\r\nif (args->size > size) {\r\nspin_unlock(&vgdev->display_info_lock);\r\nreturn -EINVAL;\r\n}\r\nlist_for_each_entry(cache_ent, &vgdev->cap_cache, head) {\r\nif (cache_ent->id == args->cap_set_id &&\r\ncache_ent->version == args->cap_set_ver) {\r\nptr = cache_ent->caps_cache;\r\nspin_unlock(&vgdev->display_info_lock);\r\ngoto copy_exit;\r\n}\r\n}\r\nspin_unlock(&vgdev->display_info_lock);\r\nvirtio_gpu_cmd_get_capset(vgdev, found_valid, args->cap_set_ver,\r\n&cache_ent);\r\nret = wait_event_timeout(vgdev->resp_wq,\r\natomic_read(&cache_ent->is_valid), 5 * HZ);\r\nptr = cache_ent->caps_cache;\r\ncopy_exit:\r\nif (copy_to_user((void __user *)(unsigned long)args->addr, ptr, size))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}
