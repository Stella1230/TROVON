static void __init allocate_lppacas(int nr_cpus, unsigned long limit)\r\n{\r\nif (nr_cpus <= NR_LPPACAS)\r\nreturn;\r\nlppaca_size = PAGE_ALIGN(sizeof(struct lppaca) *\r\n(nr_cpus - NR_LPPACAS));\r\nextra_lppacas = __va(memblock_alloc_base(lppaca_size,\r\nPAGE_SIZE, limit));\r\n}\r\nstatic struct lppaca * __init new_lppaca(int cpu)\r\n{\r\nstruct lppaca *lp;\r\nif (cpu < NR_LPPACAS)\r\nreturn &lppaca[cpu];\r\nlp = extra_lppacas + (cpu - NR_LPPACAS);\r\n*lp = lppaca[0];\r\nreturn lp;\r\n}\r\nstatic void __init free_lppacas(void)\r\n{\r\nlong new_size = 0, nr;\r\nif (!lppaca_size)\r\nreturn;\r\nnr = num_possible_cpus() - NR_LPPACAS;\r\nif (nr > 0)\r\nnew_size = PAGE_ALIGN(nr * sizeof(struct lppaca));\r\nif (new_size >= lppaca_size)\r\nreturn;\r\nmemblock_free(__pa(extra_lppacas) + new_size, lppaca_size - new_size);\r\nlppaca_size = new_size;\r\n}\r\nstatic inline void allocate_lppacas(int nr_cpus, unsigned long limit) { }\r\nstatic inline void free_lppacas(void) { }\r\nstatic void __init allocate_slb_shadows(int nr_cpus, int limit)\r\n{\r\nint size = PAGE_ALIGN(sizeof(struct slb_shadow) * nr_cpus);\r\nslb_shadow = __va(memblock_alloc_base(size, PAGE_SIZE, limit));\r\nmemset(slb_shadow, 0, size);\r\n}\r\nstatic struct slb_shadow * __init init_slb_shadow(int cpu)\r\n{\r\nstruct slb_shadow *s = &slb_shadow[cpu];\r\nif (!slb_shadow)\r\nreturn NULL;\r\ns->persistent = cpu_to_be32(SLB_NUM_BOLTED);\r\ns->buffer_length = cpu_to_be32(sizeof(*s));\r\nreturn s;\r\n}\r\nstatic void __init allocate_slb_shadows(int nr_cpus, int limit) { }\r\nvoid __init initialise_paca(struct paca_struct *new_paca, int cpu)\r\n{\r\nunsigned long kernel_toc = (unsigned long)(&__toc_start) + 0x8000UL;\r\n#ifdef CONFIG_PPC_BOOK3S\r\nnew_paca->lppaca_ptr = new_lppaca(cpu);\r\n#else\r\nnew_paca->kernel_pgd = swapper_pg_dir;\r\n#endif\r\nnew_paca->lock_token = 0x8000;\r\nnew_paca->paca_index = cpu;\r\nnew_paca->kernel_toc = kernel_toc;\r\nnew_paca->kernelbase = (unsigned long) _stext;\r\nnew_paca->kernel_msr = MSR_KERNEL & ~(MSR_IR | MSR_DR);\r\nnew_paca->hw_cpu_id = 0xffff;\r\nnew_paca->kexec_state = KEXEC_STATE_NONE;\r\nnew_paca->__current = &init_task;\r\nnew_paca->data_offset = 0xfeeeeeeeeeeeeeeeULL;\r\n#ifdef CONFIG_PPC_STD_MMU_64\r\nnew_paca->slb_shadow_ptr = init_slb_shadow(cpu);\r\n#endif\r\n#ifdef CONFIG_PPC_BOOK3E\r\nnew_paca->tcd_ptr = &new_paca->tcd;\r\n#endif\r\n}\r\nvoid setup_paca(struct paca_struct *new_paca)\r\n{\r\nlocal_paca = new_paca;\r\n#ifdef CONFIG_PPC_BOOK3E\r\nmtspr(SPRN_SPRG_TLB_EXFRAME, local_paca->extlb);\r\n#else\r\nif (cpu_has_feature(CPU_FTR_HVMODE))\r\nmtspr(SPRN_SPRG_HPACA, local_paca);\r\n#endif\r\nmtspr(SPRN_SPRG_PACA, local_paca);\r\n}\r\nvoid __init allocate_pacas(void)\r\n{\r\nu64 limit;\r\nint cpu;\r\nlimit = ppc64_rma_size;\r\n#ifdef CONFIG_PPC_BOOK3S_64\r\nlimit = min(0x10000000ULL, limit);\r\n#endif\r\npaca_size = PAGE_ALIGN(sizeof(struct paca_struct) * nr_cpu_ids);\r\npaca = __va(memblock_alloc_base(paca_size, PAGE_SIZE, limit));\r\nmemset(paca, 0, paca_size);\r\nprintk(KERN_DEBUG "Allocated %u bytes for %d pacas at %p\n",\r\npaca_size, nr_cpu_ids, paca);\r\nallocate_lppacas(nr_cpu_ids, limit);\r\nallocate_slb_shadows(nr_cpu_ids, limit);\r\nfor (cpu = 0; cpu < nr_cpu_ids; cpu++)\r\ninitialise_paca(&paca[cpu], cpu);\r\n}\r\nvoid __init free_unused_pacas(void)\r\n{\r\nint new_size;\r\nnew_size = PAGE_ALIGN(sizeof(struct paca_struct) * nr_cpu_ids);\r\nif (new_size >= paca_size)\r\nreturn;\r\nmemblock_free(__pa(paca) + new_size, paca_size - new_size);\r\nprintk(KERN_DEBUG "Freed %u bytes for unused pacas\n",\r\npaca_size - new_size);\r\npaca_size = new_size;\r\nfree_lppacas();\r\n}
