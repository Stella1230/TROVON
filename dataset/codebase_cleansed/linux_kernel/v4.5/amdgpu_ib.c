int amdgpu_ib_get(struct amdgpu_ring *ring, struct amdgpu_vm *vm,\r\nunsigned size, struct amdgpu_ib *ib)\r\n{\r\nstruct amdgpu_device *adev = ring->adev;\r\nint r;\r\nif (size) {\r\nr = amdgpu_sa_bo_new(&adev->ring_tmp_bo,\r\n&ib->sa_bo, size, 256);\r\nif (r) {\r\ndev_err(adev->dev, "failed to get a new IB (%d)\n", r);\r\nreturn r;\r\n}\r\nib->ptr = amdgpu_sa_bo_cpu_addr(ib->sa_bo);\r\nif (!vm)\r\nib->gpu_addr = amdgpu_sa_bo_gpu_addr(ib->sa_bo);\r\n}\r\namdgpu_sync_create(&ib->sync);\r\nib->ring = ring;\r\nib->vm = vm;\r\nreturn 0;\r\n}\r\nvoid amdgpu_ib_free(struct amdgpu_device *adev, struct amdgpu_ib *ib)\r\n{\r\namdgpu_sync_free(adev, &ib->sync, &ib->fence->base);\r\namdgpu_sa_bo_free(adev, &ib->sa_bo, &ib->fence->base);\r\nif (ib->fence)\r\nfence_put(&ib->fence->base);\r\n}\r\nint amdgpu_ib_schedule(struct amdgpu_device *adev, unsigned num_ibs,\r\nstruct amdgpu_ib *ibs, void *owner)\r\n{\r\nstruct amdgpu_ib *ib = &ibs[0];\r\nstruct amdgpu_ring *ring;\r\nstruct amdgpu_ctx *ctx, *old_ctx;\r\nstruct amdgpu_vm *vm;\r\nunsigned i;\r\nint r = 0;\r\nif (num_ibs == 0)\r\nreturn -EINVAL;\r\nring = ibs->ring;\r\nctx = ibs->ctx;\r\nvm = ibs->vm;\r\nif (!ring->ready) {\r\ndev_err(adev->dev, "couldn't schedule ib\n");\r\nreturn -EINVAL;\r\n}\r\nr = amdgpu_sync_wait(&ibs->sync);\r\nif (r) {\r\ndev_err(adev->dev, "IB sync failed (%d).\n", r);\r\nreturn r;\r\n}\r\nr = amdgpu_ring_lock(ring, (256 + AMDGPU_NUM_SYNCS * 8) * num_ibs);\r\nif (r) {\r\ndev_err(adev->dev, "scheduling IB failed (%d).\n", r);\r\nreturn r;\r\n}\r\nif (vm) {\r\nr = amdgpu_vm_grab_id(ibs->vm, ibs->ring, &ibs->sync);\r\nif (r) {\r\namdgpu_ring_unlock_undo(ring);\r\nreturn r;\r\n}\r\n}\r\nr = amdgpu_sync_rings(&ibs->sync, ring);\r\nif (r) {\r\namdgpu_ring_unlock_undo(ring);\r\ndev_err(adev->dev, "failed to sync rings (%d)\n", r);\r\nreturn r;\r\n}\r\nif (vm) {\r\namdgpu_vm_flush(ring, vm, ib->sync.last_vm_update);\r\nif (ring->funcs->emit_gds_switch)\r\namdgpu_ring_emit_gds_switch(ring, ib->vm->ids[ring->idx].id,\r\nib->gds_base, ib->gds_size,\r\nib->gws_base, ib->gws_size,\r\nib->oa_base, ib->oa_size);\r\nif (ring->funcs->emit_hdp_flush)\r\namdgpu_ring_emit_hdp_flush(ring);\r\n}\r\nold_ctx = ring->current_ctx;\r\nfor (i = 0; i < num_ibs; ++i) {\r\nib = &ibs[i];\r\nif (ib->ring != ring || ib->ctx != ctx || ib->vm != vm) {\r\nring->current_ctx = old_ctx;\r\namdgpu_ring_unlock_undo(ring);\r\nreturn -EINVAL;\r\n}\r\namdgpu_ring_emit_ib(ring, ib);\r\nring->current_ctx = ctx;\r\n}\r\nr = amdgpu_fence_emit(ring, owner, &ib->fence);\r\nif (r) {\r\ndev_err(adev->dev, "failed to emit fence (%d)\n", r);\r\nring->current_ctx = old_ctx;\r\namdgpu_ring_unlock_undo(ring);\r\nreturn r;\r\n}\r\nif (!amdgpu_enable_scheduler && ib->ctx)\r\nib->sequence = amdgpu_ctx_add_fence(ib->ctx, ring,\r\n&ib->fence->base);\r\nif (ib->user) {\r\nuint64_t addr = amdgpu_bo_gpu_offset(ib->user->bo);\r\naddr += ib->user->offset;\r\namdgpu_ring_emit_fence(ring, addr, ib->sequence,\r\nAMDGPU_FENCE_FLAG_64BIT);\r\n}\r\nif (ib->vm)\r\namdgpu_vm_fence(adev, ib->vm, &ib->fence->base);\r\namdgpu_ring_unlock_commit(ring);\r\nreturn 0;\r\n}\r\nint amdgpu_ib_pool_init(struct amdgpu_device *adev)\r\n{\r\nint r;\r\nif (adev->ib_pool_ready) {\r\nreturn 0;\r\n}\r\nr = amdgpu_sa_bo_manager_init(adev, &adev->ring_tmp_bo,\r\nAMDGPU_IB_POOL_SIZE*64*1024,\r\nAMDGPU_GPU_PAGE_SIZE,\r\nAMDGPU_GEM_DOMAIN_GTT);\r\nif (r) {\r\nreturn r;\r\n}\r\nr = amdgpu_sa_bo_manager_start(adev, &adev->ring_tmp_bo);\r\nif (r) {\r\nreturn r;\r\n}\r\nadev->ib_pool_ready = true;\r\nif (amdgpu_debugfs_sa_init(adev)) {\r\ndev_err(adev->dev, "failed to register debugfs file for SA\n");\r\n}\r\nreturn 0;\r\n}\r\nvoid amdgpu_ib_pool_fini(struct amdgpu_device *adev)\r\n{\r\nif (adev->ib_pool_ready) {\r\namdgpu_sa_bo_manager_suspend(adev, &adev->ring_tmp_bo);\r\namdgpu_sa_bo_manager_fini(adev, &adev->ring_tmp_bo);\r\nadev->ib_pool_ready = false;\r\n}\r\n}\r\nint amdgpu_ib_ring_tests(struct amdgpu_device *adev)\r\n{\r\nunsigned i;\r\nint r;\r\nfor (i = 0; i < AMDGPU_MAX_RINGS; ++i) {\r\nstruct amdgpu_ring *ring = adev->rings[i];\r\nif (!ring || !ring->ready)\r\ncontinue;\r\nr = amdgpu_ring_test_ib(ring);\r\nif (r) {\r\nring->ready = false;\r\nif (ring == &adev->gfx.gfx_ring[0]) {\r\nDRM_ERROR("amdgpu: failed testing IB on GFX ring (%d).\n", r);\r\nadev->accel_working = false;\r\nreturn r;\r\n} else {\r\nDRM_ERROR("amdgpu: failed testing IB on ring %d (%d).\n", i, r);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int amdgpu_debugfs_sa_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct amdgpu_device *adev = dev->dev_private;\r\namdgpu_sa_bo_dump_debug_info(&adev->ring_tmp_bo, m);\r\nreturn 0;\r\n}\r\nstatic int amdgpu_debugfs_sa_init(struct amdgpu_device *adev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nreturn amdgpu_debugfs_add_files(adev, amdgpu_debugfs_sa_list, 1);\r\n#else\r\nreturn 0;\r\n#endif\r\n}
