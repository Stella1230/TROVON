static void cvm_oct_rx_refill_worker(struct work_struct *work)\r\n{\r\ncvm_oct_rx_refill_pool(num_packet_buffers / 2);\r\nif (!atomic_read(&cvm_oct_poll_queue_stopping))\r\nqueue_delayed_work(cvm_oct_poll_queue,\r\n&cvm_oct_rx_refill_work, HZ);\r\n}\r\nstatic void cvm_oct_periodic_worker(struct work_struct *work)\r\n{\r\nstruct octeon_ethernet *priv = container_of(work,\r\nstruct octeon_ethernet,\r\nport_periodic_work.work);\r\nif (priv->poll)\r\npriv->poll(cvm_oct_device[priv->port]);\r\ncvm_oct_device[priv->port]->netdev_ops->ndo_get_stats(\r\ncvm_oct_device[priv->port]);\r\nif (!atomic_read(&cvm_oct_poll_queue_stopping))\r\nqueue_delayed_work(cvm_oct_poll_queue,\r\n&priv->port_periodic_work, HZ);\r\n}\r\nstatic void cvm_oct_configure_common_hw(void)\r\n{\r\ncvmx_fpa_enable();\r\ncvm_oct_mem_fill_fpa(CVMX_FPA_PACKET_POOL, CVMX_FPA_PACKET_POOL_SIZE,\r\nnum_packet_buffers);\r\ncvm_oct_mem_fill_fpa(CVMX_FPA_WQE_POOL, CVMX_FPA_WQE_POOL_SIZE,\r\nnum_packet_buffers);\r\nif (CVMX_FPA_OUTPUT_BUFFER_POOL != CVMX_FPA_PACKET_POOL)\r\ncvm_oct_mem_fill_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL,\r\nCVMX_FPA_OUTPUT_BUFFER_POOL_SIZE, 1024);\r\n#ifdef __LITTLE_ENDIAN\r\n{\r\nunion cvmx_ipd_ctl_status ipd_ctl_status;\r\nipd_ctl_status.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);\r\nipd_ctl_status.s.pkt_lend = 1;\r\nipd_ctl_status.s.wqe_lend = 1;\r\ncvmx_write_csr(CVMX_IPD_CTL_STATUS, ipd_ctl_status.u64);\r\n}\r\n#endif\r\ncvmx_helper_setup_red(num_packet_buffers / 4, num_packet_buffers / 8);\r\n}\r\nint cvm_oct_free_work(void *work_queue_entry)\r\n{\r\ncvmx_wqe_t *work = work_queue_entry;\r\nint segments = work->word2.s.bufs;\r\nunion cvmx_buf_ptr segment_ptr = work->packet_ptr;\r\nwhile (segments--) {\r\nunion cvmx_buf_ptr next_ptr = *(union cvmx_buf_ptr *)\r\ncvmx_phys_to_ptr(segment_ptr.s.addr - 8);\r\nif (unlikely(!segment_ptr.s.i))\r\ncvmx_fpa_free(cvm_oct_get_buffer_ptr(segment_ptr),\r\nsegment_ptr.s.pool,\r\nCVMX_FPA_PACKET_POOL_SIZE / 128);\r\nsegment_ptr = next_ptr;\r\n}\r\ncvmx_fpa_free(work, CVMX_FPA_WQE_POOL, 1);\r\nreturn 0;\r\n}\r\nstatic struct net_device_stats *cvm_oct_common_get_stats(struct net_device *dev)\r\n{\r\ncvmx_pip_port_status_t rx_status;\r\ncvmx_pko_port_status_t tx_status;\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\nif (priv->port < CVMX_PIP_NUM_INPUT_PORTS) {\r\nif (octeon_is_simulation()) {\r\nmemset(&rx_status, 0, sizeof(rx_status));\r\nmemset(&tx_status, 0, sizeof(tx_status));\r\n} else {\r\ncvmx_pip_get_port_status(priv->port, 1, &rx_status);\r\ncvmx_pko_get_port_status(priv->port, 1, &tx_status);\r\n}\r\npriv->stats.rx_packets += rx_status.inb_packets;\r\npriv->stats.tx_packets += tx_status.packets;\r\npriv->stats.rx_bytes += rx_status.inb_octets;\r\npriv->stats.tx_bytes += tx_status.octets;\r\npriv->stats.multicast += rx_status.multicast_packets;\r\npriv->stats.rx_crc_errors += rx_status.inb_errors;\r\npriv->stats.rx_frame_errors += rx_status.fcs_align_err_packets;\r\n#ifdef CONFIG_64BIT\r\natomic64_add(rx_status.dropped_packets,\r\n(atomic64_t *)&priv->stats.rx_dropped);\r\n#else\r\natomic_add(rx_status.dropped_packets,\r\n(atomic_t *)&priv->stats.rx_dropped);\r\n#endif\r\n}\r\nreturn &priv->stats;\r\n}\r\nstatic int cvm_oct_common_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\nint interface = INTERFACE(priv->port);\r\nint index = INDEX(priv->port);\r\n#if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)\r\nint vlan_bytes = 4;\r\n#else\r\nint vlan_bytes = 0;\r\n#endif\r\nif ((new_mtu + 14 + 4 + vlan_bytes < 64)\r\n|| (new_mtu + 14 + 4 + vlan_bytes > 65392)) {\r\npr_err("MTU must be between %d and %d.\n",\r\n64 - 14 - 4 - vlan_bytes, 65392 - 14 - 4 - vlan_bytes);\r\nreturn -EINVAL;\r\n}\r\ndev->mtu = new_mtu;\r\nif ((interface < 2)\r\n&& (cvmx_helper_interface_get_mode(interface) !=\r\nCVMX_HELPER_INTERFACE_MODE_SPI)) {\r\nint max_packet = new_mtu + 14 + 4 + vlan_bytes;\r\nif (OCTEON_IS_MODEL(OCTEON_CN3XXX)\r\n|| OCTEON_IS_MODEL(OCTEON_CN58XX)) {\r\ncvmx_write_csr(CVMX_GMXX_RXX_FRM_MAX(index, interface),\r\nmax_packet);\r\n} else {\r\nunion cvmx_pip_frm_len_chkx frm_len_chk;\r\nfrm_len_chk.u64 = 0;\r\nfrm_len_chk.s.minlen = 64;\r\nfrm_len_chk.s.maxlen = max_packet;\r\ncvmx_write_csr(CVMX_PIP_FRM_LEN_CHKX(interface),\r\nfrm_len_chk.u64);\r\n}\r\ncvmx_write_csr(CVMX_GMXX_RXX_JABBER(index, interface),\r\n(max_packet + 7) & ~7u);\r\n}\r\nreturn 0;\r\n}\r\nstatic void cvm_oct_common_set_multicast_list(struct net_device *dev)\r\n{\r\nunion cvmx_gmxx_prtx_cfg gmx_cfg;\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\nint interface = INTERFACE(priv->port);\r\nint index = INDEX(priv->port);\r\nif ((interface < 2)\r\n&& (cvmx_helper_interface_get_mode(interface) !=\r\nCVMX_HELPER_INTERFACE_MODE_SPI)) {\r\nunion cvmx_gmxx_rxx_adr_ctl control;\r\ncontrol.u64 = 0;\r\ncontrol.s.bcst = 1;\r\nif (!netdev_mc_empty(dev) || (dev->flags & IFF_ALLMULTI) ||\r\n(dev->flags & IFF_PROMISC))\r\ncontrol.s.mcst = 2;\r\nelse\r\ncontrol.s.mcst = 1;\r\nif (dev->flags & IFF_PROMISC)\r\ncontrol.s.cam_mode = 0;\r\nelse\r\ncontrol.s.cam_mode = 1;\r\ngmx_cfg.u64 =\r\ncvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));\r\ncvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface),\r\ngmx_cfg.u64 & ~1ull);\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CTL(index, interface),\r\ncontrol.u64);\r\nif (dev->flags & IFF_PROMISC)\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM_EN\r\n(index, interface), 0);\r\nelse\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM_EN\r\n(index, interface), 1);\r\ncvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface),\r\ngmx_cfg.u64);\r\n}\r\n}\r\nstatic int cvm_oct_set_mac_filter(struct net_device *dev)\r\n{\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\nunion cvmx_gmxx_prtx_cfg gmx_cfg;\r\nint interface = INTERFACE(priv->port);\r\nint index = INDEX(priv->port);\r\nif ((interface < 2)\r\n&& (cvmx_helper_interface_get_mode(interface) !=\r\nCVMX_HELPER_INTERFACE_MODE_SPI)) {\r\nint i;\r\nu8 *ptr = dev->dev_addr;\r\nu64 mac = 0;\r\nfor (i = 0; i < 6; i++)\r\nmac = (mac << 8) | (u64)ptr[i];\r\ngmx_cfg.u64 =\r\ncvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));\r\ncvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface),\r\ngmx_cfg.u64 & ~1ull);\r\ncvmx_write_csr(CVMX_GMXX_SMACX(index, interface), mac);\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM0(index, interface),\r\nptr[0]);\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM1(index, interface),\r\nptr[1]);\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM2(index, interface),\r\nptr[2]);\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM3(index, interface),\r\nptr[3]);\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM4(index, interface),\r\nptr[4]);\r\ncvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM5(index, interface),\r\nptr[5]);\r\ncvm_oct_common_set_multicast_list(dev);\r\ncvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface),\r\ngmx_cfg.u64);\r\n}\r\nreturn 0;\r\n}\r\nstatic int cvm_oct_common_set_mac_address(struct net_device *dev, void *addr)\r\n{\r\nint r = eth_mac_addr(dev, addr);\r\nif (r)\r\nreturn r;\r\nreturn cvm_oct_set_mac_filter(dev);\r\n}\r\nint cvm_oct_common_init(struct net_device *dev)\r\n{\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\nconst u8 *mac = NULL;\r\nif (priv->of_node)\r\nmac = of_get_mac_address(priv->of_node);\r\nif (mac)\r\nether_addr_copy(dev->dev_addr, mac);\r\nelse\r\neth_hw_addr_random(dev);\r\nif ((pow_send_group != -1)\r\n&& (always_use_pow || strstr(pow_send_list, dev->name)))\r\npriv->queue = -1;\r\nif (priv->queue != -1)\r\ndev->features |= NETIF_F_SG | NETIF_F_IP_CSUM;\r\ndev->features |= NETIF_F_LLTX;\r\ndev->ethtool_ops = &cvm_oct_ethtool_ops;\r\ncvm_oct_set_mac_filter(dev);\r\ndev->netdev_ops->ndo_change_mtu(dev, dev->mtu);\r\nmemset(dev->netdev_ops->ndo_get_stats(dev), 0,\r\nsizeof(struct net_device_stats));\r\nif (dev->netdev_ops->ndo_stop)\r\ndev->netdev_ops->ndo_stop(dev);\r\nreturn 0;\r\n}\r\nvoid cvm_oct_common_uninit(struct net_device *dev)\r\n{\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\nif (priv->phydev)\r\nphy_disconnect(priv->phydev);\r\n}\r\nint cvm_oct_common_open(struct net_device *dev,\r\nvoid (*link_poll)(struct net_device *))\r\n{\r\nunion cvmx_gmxx_prtx_cfg gmx_cfg;\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\nint interface = INTERFACE(priv->port);\r\nint index = INDEX(priv->port);\r\ncvmx_helper_link_info_t link_info;\r\nint rv;\r\nrv = cvm_oct_phy_setup_device(dev);\r\nif (rv)\r\nreturn rv;\r\ngmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));\r\ngmx_cfg.s.en = 1;\r\ncvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);\r\nif (octeon_is_simulation())\r\nreturn 0;\r\nif (priv->phydev) {\r\nint r = phy_read_status(priv->phydev);\r\nif (r == 0 && priv->phydev->link == 0)\r\nnetif_carrier_off(dev);\r\ncvm_oct_adjust_link(dev);\r\n} else {\r\nlink_info = cvmx_helper_link_get(priv->port);\r\nif (!link_info.s.link_up)\r\nnetif_carrier_off(dev);\r\npriv->poll = link_poll;\r\nlink_poll(dev);\r\n}\r\nreturn 0;\r\n}\r\nvoid cvm_oct_link_poll(struct net_device *dev)\r\n{\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\ncvmx_helper_link_info_t link_info;\r\nlink_info = cvmx_helper_link_get(priv->port);\r\nif (link_info.u64 == priv->link_info)\r\nreturn;\r\nlink_info = cvmx_helper_link_autoconf(priv->port);\r\npriv->link_info = link_info.u64;\r\nif (link_info.s.link_up) {\r\nif (!netif_carrier_ok(dev))\r\nnetif_carrier_on(dev);\r\n} else if (netif_carrier_ok(dev)) {\r\nnetif_carrier_off(dev);\r\n}\r\ncvm_oct_note_carrier(priv, link_info);\r\n}\r\nstatic int cvm_oct_xaui_open(struct net_device *dev)\r\n{\r\nreturn cvm_oct_common_open(dev, cvm_oct_link_poll);\r\n}\r\nstatic struct device_node *cvm_oct_of_get_child(\r\nconst struct device_node *parent, int reg_val)\r\n{\r\nstruct device_node *node = NULL;\r\nint size;\r\nconst __be32 *addr;\r\nfor (;;) {\r\nnode = of_get_next_child(parent, node);\r\nif (!node)\r\nbreak;\r\naddr = of_get_property(node, "reg", &size);\r\nif (addr && (be32_to_cpu(*addr) == reg_val))\r\nbreak;\r\n}\r\nreturn node;\r\n}\r\nstatic struct device_node *cvm_oct_node_for_port(struct device_node *pip,\r\nint interface, int port)\r\n{\r\nstruct device_node *ni, *np;\r\nni = cvm_oct_of_get_child(pip, interface);\r\nif (!ni)\r\nreturn NULL;\r\nnp = cvm_oct_of_get_child(ni, port);\r\nof_node_put(ni);\r\nreturn np;\r\n}\r\nstatic int cvm_oct_probe(struct platform_device *pdev)\r\n{\r\nint num_interfaces;\r\nint interface;\r\nint fau = FAU_NUM_PACKET_BUFFERS_TO_FREE;\r\nint qos;\r\nstruct device_node *pip;\r\nocteon_mdiobus_force_mod_depencency();\r\npip = pdev->dev.of_node;\r\nif (!pip) {\r\npr_err("Error: No 'pip' in /aliases\n");\r\nreturn -EINVAL;\r\n}\r\ncvm_oct_poll_queue = create_singlethread_workqueue("octeon-ethernet");\r\nif (!cvm_oct_poll_queue) {\r\npr_err("octeon-ethernet: Cannot create workqueue");\r\nreturn -ENOMEM;\r\n}\r\ncvm_oct_configure_common_hw();\r\ncvmx_helper_initialize_packet_io_global();\r\nnum_interfaces = cvmx_helper_get_number_of_interfaces();\r\nfor (interface = 0; interface < num_interfaces; interface++) {\r\nint num_ports = cvmx_helper_ports_on_interface(interface);\r\nint port;\r\nfor (port = cvmx_helper_get_ipd_port(interface, 0);\r\nport < cvmx_helper_get_ipd_port(interface, num_ports);\r\nport++) {\r\nunion cvmx_pip_prt_tagx pip_prt_tagx;\r\npip_prt_tagx.u64 =\r\ncvmx_read_csr(CVMX_PIP_PRT_TAGX(port));\r\npip_prt_tagx.s.grp = pow_receive_group;\r\ncvmx_write_csr(CVMX_PIP_PRT_TAGX(port),\r\npip_prt_tagx.u64);\r\n}\r\n}\r\ncvmx_helper_ipd_and_packet_input_enable();\r\nmemset(cvm_oct_device, 0, sizeof(cvm_oct_device));\r\ncvmx_fau_atomic_write32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);\r\ncvmx_fau_atomic_write32(FAU_TOTAL_TX_TO_CLEAN, 0);\r\nif ((pow_send_group != -1)) {\r\nstruct net_device *dev;\r\npr_info("\tConfiguring device for POW only access\n");\r\ndev = alloc_etherdev(sizeof(struct octeon_ethernet));\r\nif (dev) {\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\ndev->netdev_ops = &cvm_oct_pow_netdev_ops;\r\npriv->imode = CVMX_HELPER_INTERFACE_MODE_DISABLED;\r\npriv->port = CVMX_PIP_NUM_INPUT_PORTS;\r\npriv->queue = -1;\r\nstrcpy(dev->name, "pow%d");\r\nfor (qos = 0; qos < 16; qos++)\r\nskb_queue_head_init(&priv->tx_free_list[qos]);\r\nif (register_netdev(dev) < 0) {\r\npr_err("Failed to register ethernet device for POW\n");\r\nfree_netdev(dev);\r\n} else {\r\ncvm_oct_device[CVMX_PIP_NUM_INPUT_PORTS] = dev;\r\npr_info("%s: POW send group %d, receive group %d\n",\r\ndev->name, pow_send_group,\r\npow_receive_group);\r\n}\r\n} else {\r\npr_err("Failed to allocate ethernet device for POW\n");\r\n}\r\n}\r\nnum_interfaces = cvmx_helper_get_number_of_interfaces();\r\nfor (interface = 0; interface < num_interfaces; interface++) {\r\ncvmx_helper_interface_mode_t imode =\r\ncvmx_helper_interface_get_mode(interface);\r\nint num_ports = cvmx_helper_ports_on_interface(interface);\r\nint port;\r\nint port_index;\r\nfor (port_index = 0,\r\nport = cvmx_helper_get_ipd_port(interface, 0);\r\nport < cvmx_helper_get_ipd_port(interface, num_ports);\r\nport_index++, port++) {\r\nstruct octeon_ethernet *priv;\r\nstruct net_device *dev =\r\nalloc_etherdev(sizeof(struct octeon_ethernet));\r\nif (!dev) {\r\npr_err("Failed to allocate ethernet device for port %d\n",\r\nport);\r\ncontinue;\r\n}\r\npriv = netdev_priv(dev);\r\npriv->netdev = dev;\r\npriv->of_node = cvm_oct_node_for_port(pip, interface,\r\nport_index);\r\nINIT_DELAYED_WORK(&priv->port_periodic_work,\r\ncvm_oct_periodic_worker);\r\npriv->imode = imode;\r\npriv->port = port;\r\npriv->queue = cvmx_pko_get_base_queue(priv->port);\r\npriv->fau = fau - cvmx_pko_get_num_queues(port) * 4;\r\nfor (qos = 0; qos < 16; qos++)\r\nskb_queue_head_init(&priv->tx_free_list[qos]);\r\nfor (qos = 0; qos < cvmx_pko_get_num_queues(port);\r\nqos++)\r\ncvmx_fau_atomic_write32(priv->fau + qos * 4, 0);\r\nswitch (priv->imode) {\r\ncase CVMX_HELPER_INTERFACE_MODE_DISABLED:\r\ncase CVMX_HELPER_INTERFACE_MODE_PCIE:\r\ncase CVMX_HELPER_INTERFACE_MODE_PICMG:\r\nbreak;\r\ncase CVMX_HELPER_INTERFACE_MODE_NPI:\r\ndev->netdev_ops = &cvm_oct_npi_netdev_ops;\r\nstrcpy(dev->name, "npi%d");\r\nbreak;\r\ncase CVMX_HELPER_INTERFACE_MODE_XAUI:\r\ndev->netdev_ops = &cvm_oct_xaui_netdev_ops;\r\nstrcpy(dev->name, "xaui%d");\r\nbreak;\r\ncase CVMX_HELPER_INTERFACE_MODE_LOOP:\r\ndev->netdev_ops = &cvm_oct_npi_netdev_ops;\r\nstrcpy(dev->name, "loop%d");\r\nbreak;\r\ncase CVMX_HELPER_INTERFACE_MODE_SGMII:\r\ndev->netdev_ops = &cvm_oct_sgmii_netdev_ops;\r\nstrcpy(dev->name, "eth%d");\r\nbreak;\r\ncase CVMX_HELPER_INTERFACE_MODE_SPI:\r\ndev->netdev_ops = &cvm_oct_spi_netdev_ops;\r\nstrcpy(dev->name, "spi%d");\r\nbreak;\r\ncase CVMX_HELPER_INTERFACE_MODE_RGMII:\r\ncase CVMX_HELPER_INTERFACE_MODE_GMII:\r\ndev->netdev_ops = &cvm_oct_rgmii_netdev_ops;\r\nstrcpy(dev->name, "eth%d");\r\nbreak;\r\n}\r\nif (!dev->netdev_ops) {\r\nfree_netdev(dev);\r\n} else if (register_netdev(dev) < 0) {\r\npr_err("Failed to register ethernet device for interface %d, port %d\n",\r\ninterface, priv->port);\r\nfree_netdev(dev);\r\n} else {\r\ncvm_oct_device[priv->port] = dev;\r\nfau -=\r\ncvmx_pko_get_num_queues(priv->port) *\r\nsizeof(u32);\r\nqueue_delayed_work(cvm_oct_poll_queue,\r\n&priv->port_periodic_work, HZ);\r\n}\r\n}\r\n}\r\ncvm_oct_tx_initialize();\r\ncvm_oct_rx_initialize();\r\ncvm_oct_tx_poll_interval = 150 * (octeon_get_clock_rate() / 1000000);\r\nqueue_delayed_work(cvm_oct_poll_queue, &cvm_oct_rx_refill_work, HZ);\r\nreturn 0;\r\n}\r\nstatic int cvm_oct_remove(struct platform_device *pdev)\r\n{\r\nint port;\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX))\r\ncvmx_write_csr(CVMX_SSO_WQ_INT_THRX(pow_receive_group), 0);\r\nelse\r\ncvmx_write_csr(CVMX_POW_WQ_INT_THRX(pow_receive_group), 0);\r\ncvmx_ipd_disable();\r\nfree_irq(OCTEON_IRQ_WORKQ0 + pow_receive_group, cvm_oct_device);\r\natomic_inc_return(&cvm_oct_poll_queue_stopping);\r\ncancel_delayed_work_sync(&cvm_oct_rx_refill_work);\r\ncvm_oct_rx_shutdown();\r\ncvm_oct_tx_shutdown();\r\ncvmx_pko_disable();\r\nfor (port = 0; port < TOTAL_NUMBER_OF_PORTS; port++) {\r\nif (cvm_oct_device[port]) {\r\nstruct net_device *dev = cvm_oct_device[port];\r\nstruct octeon_ethernet *priv = netdev_priv(dev);\r\ncancel_delayed_work_sync(&priv->port_periodic_work);\r\ncvm_oct_tx_shutdown_dev(dev);\r\nunregister_netdev(dev);\r\nfree_netdev(dev);\r\ncvm_oct_device[port] = NULL;\r\n}\r\n}\r\ndestroy_workqueue(cvm_oct_poll_queue);\r\ncvmx_pko_shutdown();\r\ncvmx_ipd_free_ptr();\r\ncvm_oct_mem_empty_fpa(CVMX_FPA_PACKET_POOL, CVMX_FPA_PACKET_POOL_SIZE,\r\nnum_packet_buffers);\r\ncvm_oct_mem_empty_fpa(CVMX_FPA_WQE_POOL, CVMX_FPA_WQE_POOL_SIZE,\r\nnum_packet_buffers);\r\nif (CVMX_FPA_OUTPUT_BUFFER_POOL != CVMX_FPA_PACKET_POOL)\r\ncvm_oct_mem_empty_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL,\r\nCVMX_FPA_OUTPUT_BUFFER_POOL_SIZE, 128);\r\nreturn 0;\r\n}
