static void btrfs_qgroup_update_old_refcnt(struct btrfs_qgroup *qg, u64 seq,\r\nint mod)\r\n{\r\nif (qg->old_refcnt < seq)\r\nqg->old_refcnt = seq;\r\nqg->old_refcnt += mod;\r\n}\r\nstatic void btrfs_qgroup_update_new_refcnt(struct btrfs_qgroup *qg, u64 seq,\r\nint mod)\r\n{\r\nif (qg->new_refcnt < seq)\r\nqg->new_refcnt = seq;\r\nqg->new_refcnt += mod;\r\n}\r\nstatic inline u64 btrfs_qgroup_get_old_refcnt(struct btrfs_qgroup *qg, u64 seq)\r\n{\r\nif (qg->old_refcnt < seq)\r\nreturn 0;\r\nreturn qg->old_refcnt - seq;\r\n}\r\nstatic inline u64 btrfs_qgroup_get_new_refcnt(struct btrfs_qgroup *qg, u64 seq)\r\n{\r\nif (qg->new_refcnt < seq)\r\nreturn 0;\r\nreturn qg->new_refcnt - seq;\r\n}\r\nstatic struct btrfs_qgroup *find_qgroup_rb(struct btrfs_fs_info *fs_info,\r\nu64 qgroupid)\r\n{\r\nstruct rb_node *n = fs_info->qgroup_tree.rb_node;\r\nstruct btrfs_qgroup *qgroup;\r\nwhile (n) {\r\nqgroup = rb_entry(n, struct btrfs_qgroup, node);\r\nif (qgroup->qgroupid < qgroupid)\r\nn = n->rb_left;\r\nelse if (qgroup->qgroupid > qgroupid)\r\nn = n->rb_right;\r\nelse\r\nreturn qgroup;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct btrfs_qgroup *add_qgroup_rb(struct btrfs_fs_info *fs_info,\r\nu64 qgroupid)\r\n{\r\nstruct rb_node **p = &fs_info->qgroup_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct btrfs_qgroup *qgroup;\r\nwhile (*p) {\r\nparent = *p;\r\nqgroup = rb_entry(parent, struct btrfs_qgroup, node);\r\nif (qgroup->qgroupid < qgroupid)\r\np = &(*p)->rb_left;\r\nelse if (qgroup->qgroupid > qgroupid)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn qgroup;\r\n}\r\nqgroup = kzalloc(sizeof(*qgroup), GFP_ATOMIC);\r\nif (!qgroup)\r\nreturn ERR_PTR(-ENOMEM);\r\nqgroup->qgroupid = qgroupid;\r\nINIT_LIST_HEAD(&qgroup->groups);\r\nINIT_LIST_HEAD(&qgroup->members);\r\nINIT_LIST_HEAD(&qgroup->dirty);\r\nrb_link_node(&qgroup->node, parent, p);\r\nrb_insert_color(&qgroup->node, &fs_info->qgroup_tree);\r\nreturn qgroup;\r\n}\r\nstatic void __del_qgroup_rb(struct btrfs_qgroup *qgroup)\r\n{\r\nstruct btrfs_qgroup_list *list;\r\nlist_del(&qgroup->dirty);\r\nwhile (!list_empty(&qgroup->groups)) {\r\nlist = list_first_entry(&qgroup->groups,\r\nstruct btrfs_qgroup_list, next_group);\r\nlist_del(&list->next_group);\r\nlist_del(&list->next_member);\r\nkfree(list);\r\n}\r\nwhile (!list_empty(&qgroup->members)) {\r\nlist = list_first_entry(&qgroup->members,\r\nstruct btrfs_qgroup_list, next_member);\r\nlist_del(&list->next_group);\r\nlist_del(&list->next_member);\r\nkfree(list);\r\n}\r\nkfree(qgroup);\r\n}\r\nstatic int del_qgroup_rb(struct btrfs_fs_info *fs_info, u64 qgroupid)\r\n{\r\nstruct btrfs_qgroup *qgroup = find_qgroup_rb(fs_info, qgroupid);\r\nif (!qgroup)\r\nreturn -ENOENT;\r\nrb_erase(&qgroup->node, &fs_info->qgroup_tree);\r\n__del_qgroup_rb(qgroup);\r\nreturn 0;\r\n}\r\nstatic int add_relation_rb(struct btrfs_fs_info *fs_info,\r\nu64 memberid, u64 parentid)\r\n{\r\nstruct btrfs_qgroup *member;\r\nstruct btrfs_qgroup *parent;\r\nstruct btrfs_qgroup_list *list;\r\nmember = find_qgroup_rb(fs_info, memberid);\r\nparent = find_qgroup_rb(fs_info, parentid);\r\nif (!member || !parent)\r\nreturn -ENOENT;\r\nlist = kzalloc(sizeof(*list), GFP_ATOMIC);\r\nif (!list)\r\nreturn -ENOMEM;\r\nlist->group = parent;\r\nlist->member = member;\r\nlist_add_tail(&list->next_group, &member->groups);\r\nlist_add_tail(&list->next_member, &parent->members);\r\nreturn 0;\r\n}\r\nstatic int del_relation_rb(struct btrfs_fs_info *fs_info,\r\nu64 memberid, u64 parentid)\r\n{\r\nstruct btrfs_qgroup *member;\r\nstruct btrfs_qgroup *parent;\r\nstruct btrfs_qgroup_list *list;\r\nmember = find_qgroup_rb(fs_info, memberid);\r\nparent = find_qgroup_rb(fs_info, parentid);\r\nif (!member || !parent)\r\nreturn -ENOENT;\r\nlist_for_each_entry(list, &member->groups, next_group) {\r\nif (list->group == parent) {\r\nlist_del(&list->next_group);\r\nlist_del(&list->next_member);\r\nkfree(list);\r\nreturn 0;\r\n}\r\n}\r\nreturn -ENOENT;\r\n}\r\nint btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,\r\nu64 rfer, u64 excl)\r\n{\r\nstruct btrfs_qgroup *qgroup;\r\nqgroup = find_qgroup_rb(fs_info, qgroupid);\r\nif (!qgroup)\r\nreturn -EINVAL;\r\nif (qgroup->rfer != rfer || qgroup->excl != excl)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nint btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_key key;\r\nstruct btrfs_key found_key;\r\nstruct btrfs_root *quota_root = fs_info->quota_root;\r\nstruct btrfs_path *path = NULL;\r\nstruct extent_buffer *l;\r\nint slot;\r\nint ret = 0;\r\nu64 flags = 0;\r\nu64 rescan_progress = 0;\r\nif (!fs_info->quota_enabled)\r\nreturn 0;\r\nfs_info->qgroup_ulist = ulist_alloc(GFP_NOFS);\r\nif (!fs_info->qgroup_ulist) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\npath = btrfs_alloc_path();\r\nif (!path) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nfs_info->qgroup_flags = 0;\r\nkey.objectid = 0;\r\nkey.type = 0;\r\nkey.offset = 0;\r\nret = btrfs_search_slot_for_read(quota_root, &key, path, 1, 1);\r\nif (ret)\r\ngoto out;\r\nwhile (1) {\r\nstruct btrfs_qgroup *qgroup;\r\nslot = path->slots[0];\r\nl = path->nodes[0];\r\nbtrfs_item_key_to_cpu(l, &found_key, slot);\r\nif (found_key.type == BTRFS_QGROUP_STATUS_KEY) {\r\nstruct btrfs_qgroup_status_item *ptr;\r\nptr = btrfs_item_ptr(l, slot,\r\nstruct btrfs_qgroup_status_item);\r\nif (btrfs_qgroup_status_version(l, ptr) !=\r\nBTRFS_QGROUP_STATUS_VERSION) {\r\nbtrfs_err(fs_info,\r\n"old qgroup version, quota disabled");\r\ngoto out;\r\n}\r\nif (btrfs_qgroup_status_generation(l, ptr) !=\r\nfs_info->generation) {\r\nflags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nbtrfs_err(fs_info,\r\n"qgroup generation mismatch, "\r\n"marked as inconsistent");\r\n}\r\nfs_info->qgroup_flags = btrfs_qgroup_status_flags(l,\r\nptr);\r\nrescan_progress = btrfs_qgroup_status_rescan(l, ptr);\r\ngoto next1;\r\n}\r\nif (found_key.type != BTRFS_QGROUP_INFO_KEY &&\r\nfound_key.type != BTRFS_QGROUP_LIMIT_KEY)\r\ngoto next1;\r\nqgroup = find_qgroup_rb(fs_info, found_key.offset);\r\nif ((qgroup && found_key.type == BTRFS_QGROUP_INFO_KEY) ||\r\n(!qgroup && found_key.type == BTRFS_QGROUP_LIMIT_KEY)) {\r\nbtrfs_err(fs_info, "inconsistent qgroup config");\r\nflags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\n}\r\nif (!qgroup) {\r\nqgroup = add_qgroup_rb(fs_info, found_key.offset);\r\nif (IS_ERR(qgroup)) {\r\nret = PTR_ERR(qgroup);\r\ngoto out;\r\n}\r\n}\r\nswitch (found_key.type) {\r\ncase BTRFS_QGROUP_INFO_KEY: {\r\nstruct btrfs_qgroup_info_item *ptr;\r\nptr = btrfs_item_ptr(l, slot,\r\nstruct btrfs_qgroup_info_item);\r\nqgroup->rfer = btrfs_qgroup_info_rfer(l, ptr);\r\nqgroup->rfer_cmpr = btrfs_qgroup_info_rfer_cmpr(l, ptr);\r\nqgroup->excl = btrfs_qgroup_info_excl(l, ptr);\r\nqgroup->excl_cmpr = btrfs_qgroup_info_excl_cmpr(l, ptr);\r\nbreak;\r\n}\r\ncase BTRFS_QGROUP_LIMIT_KEY: {\r\nstruct btrfs_qgroup_limit_item *ptr;\r\nptr = btrfs_item_ptr(l, slot,\r\nstruct btrfs_qgroup_limit_item);\r\nqgroup->lim_flags = btrfs_qgroup_limit_flags(l, ptr);\r\nqgroup->max_rfer = btrfs_qgroup_limit_max_rfer(l, ptr);\r\nqgroup->max_excl = btrfs_qgroup_limit_max_excl(l, ptr);\r\nqgroup->rsv_rfer = btrfs_qgroup_limit_rsv_rfer(l, ptr);\r\nqgroup->rsv_excl = btrfs_qgroup_limit_rsv_excl(l, ptr);\r\nbreak;\r\n}\r\n}\r\nnext1:\r\nret = btrfs_next_item(quota_root, path);\r\nif (ret < 0)\r\ngoto out;\r\nif (ret)\r\nbreak;\r\n}\r\nbtrfs_release_path(path);\r\nkey.objectid = 0;\r\nkey.type = BTRFS_QGROUP_RELATION_KEY;\r\nkey.offset = 0;\r\nret = btrfs_search_slot_for_read(quota_root, &key, path, 1, 0);\r\nif (ret)\r\ngoto out;\r\nwhile (1) {\r\nslot = path->slots[0];\r\nl = path->nodes[0];\r\nbtrfs_item_key_to_cpu(l, &found_key, slot);\r\nif (found_key.type != BTRFS_QGROUP_RELATION_KEY)\r\ngoto next2;\r\nif (found_key.objectid > found_key.offset) {\r\ngoto next2;\r\n}\r\nret = add_relation_rb(fs_info, found_key.objectid,\r\nfound_key.offset);\r\nif (ret == -ENOENT) {\r\nbtrfs_warn(fs_info,\r\n"orphan qgroup relation 0x%llx->0x%llx",\r\nfound_key.objectid, found_key.offset);\r\nret = 0;\r\n}\r\nif (ret)\r\ngoto out;\r\nnext2:\r\nret = btrfs_next_item(quota_root, path);\r\nif (ret < 0)\r\ngoto out;\r\nif (ret)\r\nbreak;\r\n}\r\nout:\r\nfs_info->qgroup_flags |= flags;\r\nif (!(fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_ON)) {\r\nfs_info->quota_enabled = 0;\r\nfs_info->pending_quota_state = 0;\r\n} else if (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN &&\r\nret >= 0) {\r\nret = qgroup_rescan_init(fs_info, rescan_progress, 0);\r\n}\r\nbtrfs_free_path(path);\r\nif (ret < 0) {\r\nulist_free(fs_info->qgroup_ulist);\r\nfs_info->qgroup_ulist = NULL;\r\nfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\r\n}\r\nreturn ret < 0 ? ret : 0;\r\n}\r\nvoid btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct rb_node *n;\r\nstruct btrfs_qgroup *qgroup;\r\nwhile ((n = rb_first(&fs_info->qgroup_tree))) {\r\nqgroup = rb_entry(n, struct btrfs_qgroup, node);\r\nrb_erase(n, &fs_info->qgroup_tree);\r\n__del_qgroup_rb(qgroup);\r\n}\r\nulist_free(fs_info->qgroup_ulist);\r\nfs_info->qgroup_ulist = NULL;\r\n}\r\nstatic int add_qgroup_relation_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *quota_root,\r\nu64 src, u64 dst)\r\n{\r\nint ret;\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nkey.objectid = src;\r\nkey.type = BTRFS_QGROUP_RELATION_KEY;\r\nkey.offset = dst;\r\nret = btrfs_insert_empty_item(trans, quota_root, path, &key, 0);\r\nbtrfs_mark_buffer_dirty(path->nodes[0]);\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int del_qgroup_relation_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *quota_root,\r\nu64 src, u64 dst)\r\n{\r\nint ret;\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nkey.objectid = src;\r\nkey.type = BTRFS_QGROUP_RELATION_KEY;\r\nkey.offset = dst;\r\nret = btrfs_search_slot(trans, quota_root, &key, path, -1, 1);\r\nif (ret < 0)\r\ngoto out;\r\nif (ret > 0) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nret = btrfs_del_item(trans, quota_root, path);\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int add_qgroup_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *quota_root, u64 qgroupid)\r\n{\r\nint ret;\r\nstruct btrfs_path *path;\r\nstruct btrfs_qgroup_info_item *qgroup_info;\r\nstruct btrfs_qgroup_limit_item *qgroup_limit;\r\nstruct extent_buffer *leaf;\r\nstruct btrfs_key key;\r\nif (btrfs_test_is_dummy_root(quota_root))\r\nreturn 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nkey.objectid = 0;\r\nkey.type = BTRFS_QGROUP_INFO_KEY;\r\nkey.offset = qgroupid;\r\nret = btrfs_insert_empty_item(trans, quota_root, path, &key,\r\nsizeof(*qgroup_info));\r\nif (ret && ret != -EEXIST)\r\ngoto out;\r\nleaf = path->nodes[0];\r\nqgroup_info = btrfs_item_ptr(leaf, path->slots[0],\r\nstruct btrfs_qgroup_info_item);\r\nbtrfs_set_qgroup_info_generation(leaf, qgroup_info, trans->transid);\r\nbtrfs_set_qgroup_info_rfer(leaf, qgroup_info, 0);\r\nbtrfs_set_qgroup_info_rfer_cmpr(leaf, qgroup_info, 0);\r\nbtrfs_set_qgroup_info_excl(leaf, qgroup_info, 0);\r\nbtrfs_set_qgroup_info_excl_cmpr(leaf, qgroup_info, 0);\r\nbtrfs_mark_buffer_dirty(leaf);\r\nbtrfs_release_path(path);\r\nkey.type = BTRFS_QGROUP_LIMIT_KEY;\r\nret = btrfs_insert_empty_item(trans, quota_root, path, &key,\r\nsizeof(*qgroup_limit));\r\nif (ret && ret != -EEXIST)\r\ngoto out;\r\nleaf = path->nodes[0];\r\nqgroup_limit = btrfs_item_ptr(leaf, path->slots[0],\r\nstruct btrfs_qgroup_limit_item);\r\nbtrfs_set_qgroup_limit_flags(leaf, qgroup_limit, 0);\r\nbtrfs_set_qgroup_limit_max_rfer(leaf, qgroup_limit, 0);\r\nbtrfs_set_qgroup_limit_max_excl(leaf, qgroup_limit, 0);\r\nbtrfs_set_qgroup_limit_rsv_rfer(leaf, qgroup_limit, 0);\r\nbtrfs_set_qgroup_limit_rsv_excl(leaf, qgroup_limit, 0);\r\nbtrfs_mark_buffer_dirty(leaf);\r\nret = 0;\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int del_qgroup_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *quota_root, u64 qgroupid)\r\n{\r\nint ret;\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nkey.objectid = 0;\r\nkey.type = BTRFS_QGROUP_INFO_KEY;\r\nkey.offset = qgroupid;\r\nret = btrfs_search_slot(trans, quota_root, &key, path, -1, 1);\r\nif (ret < 0)\r\ngoto out;\r\nif (ret > 0) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nret = btrfs_del_item(trans, quota_root, path);\r\nif (ret)\r\ngoto out;\r\nbtrfs_release_path(path);\r\nkey.type = BTRFS_QGROUP_LIMIT_KEY;\r\nret = btrfs_search_slot(trans, quota_root, &key, path, -1, 1);\r\nif (ret < 0)\r\ngoto out;\r\nif (ret > 0) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nret = btrfs_del_item(trans, quota_root, path);\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int update_qgroup_limit_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct btrfs_qgroup *qgroup)\r\n{\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\nstruct extent_buffer *l;\r\nstruct btrfs_qgroup_limit_item *qgroup_limit;\r\nint ret;\r\nint slot;\r\nkey.objectid = 0;\r\nkey.type = BTRFS_QGROUP_LIMIT_KEY;\r\nkey.offset = qgroup->qgroupid;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nret = btrfs_search_slot(trans, root, &key, path, 0, 1);\r\nif (ret > 0)\r\nret = -ENOENT;\r\nif (ret)\r\ngoto out;\r\nl = path->nodes[0];\r\nslot = path->slots[0];\r\nqgroup_limit = btrfs_item_ptr(l, slot, struct btrfs_qgroup_limit_item);\r\nbtrfs_set_qgroup_limit_flags(l, qgroup_limit, qgroup->lim_flags);\r\nbtrfs_set_qgroup_limit_max_rfer(l, qgroup_limit, qgroup->max_rfer);\r\nbtrfs_set_qgroup_limit_max_excl(l, qgroup_limit, qgroup->max_excl);\r\nbtrfs_set_qgroup_limit_rsv_rfer(l, qgroup_limit, qgroup->rsv_rfer);\r\nbtrfs_set_qgroup_limit_rsv_excl(l, qgroup_limit, qgroup->rsv_excl);\r\nbtrfs_mark_buffer_dirty(l);\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int update_qgroup_info_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root,\r\nstruct btrfs_qgroup *qgroup)\r\n{\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\nstruct extent_buffer *l;\r\nstruct btrfs_qgroup_info_item *qgroup_info;\r\nint ret;\r\nint slot;\r\nif (btrfs_test_is_dummy_root(root))\r\nreturn 0;\r\nkey.objectid = 0;\r\nkey.type = BTRFS_QGROUP_INFO_KEY;\r\nkey.offset = qgroup->qgroupid;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nret = btrfs_search_slot(trans, root, &key, path, 0, 1);\r\nif (ret > 0)\r\nret = -ENOENT;\r\nif (ret)\r\ngoto out;\r\nl = path->nodes[0];\r\nslot = path->slots[0];\r\nqgroup_info = btrfs_item_ptr(l, slot, struct btrfs_qgroup_info_item);\r\nbtrfs_set_qgroup_info_generation(l, qgroup_info, trans->transid);\r\nbtrfs_set_qgroup_info_rfer(l, qgroup_info, qgroup->rfer);\r\nbtrfs_set_qgroup_info_rfer_cmpr(l, qgroup_info, qgroup->rfer_cmpr);\r\nbtrfs_set_qgroup_info_excl(l, qgroup_info, qgroup->excl);\r\nbtrfs_set_qgroup_info_excl_cmpr(l, qgroup_info, qgroup->excl_cmpr);\r\nbtrfs_mark_buffer_dirty(l);\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int update_qgroup_status_item(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info,\r\nstruct btrfs_root *root)\r\n{\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\nstruct extent_buffer *l;\r\nstruct btrfs_qgroup_status_item *ptr;\r\nint ret;\r\nint slot;\r\nkey.objectid = 0;\r\nkey.type = BTRFS_QGROUP_STATUS_KEY;\r\nkey.offset = 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nret = btrfs_search_slot(trans, root, &key, path, 0, 1);\r\nif (ret > 0)\r\nret = -ENOENT;\r\nif (ret)\r\ngoto out;\r\nl = path->nodes[0];\r\nslot = path->slots[0];\r\nptr = btrfs_item_ptr(l, slot, struct btrfs_qgroup_status_item);\r\nbtrfs_set_qgroup_status_flags(l, ptr, fs_info->qgroup_flags);\r\nbtrfs_set_qgroup_status_generation(l, ptr, trans->transid);\r\nbtrfs_set_qgroup_status_rescan(l, ptr,\r\nfs_info->qgroup_rescan_progress.objectid);\r\nbtrfs_mark_buffer_dirty(l);\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int btrfs_clean_quota_tree(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root)\r\n{\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\nstruct extent_buffer *leaf = NULL;\r\nint ret;\r\nint nr = 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\npath->leave_spinning = 1;\r\nkey.objectid = 0;\r\nkey.offset = 0;\r\nkey.type = 0;\r\nwhile (1) {\r\nret = btrfs_search_slot(trans, root, &key, path, -1, 1);\r\nif (ret < 0)\r\ngoto out;\r\nleaf = path->nodes[0];\r\nnr = btrfs_header_nritems(leaf);\r\nif (!nr)\r\nbreak;\r\npath->slots[0] = 0;\r\nret = btrfs_del_items(trans, root, path, 0, nr);\r\nif (ret)\r\ngoto out;\r\nbtrfs_release_path(path);\r\n}\r\nret = 0;\r\nout:\r\nroot->fs_info->pending_quota_state = 0;\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nint btrfs_quota_enable(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_root *tree_root = fs_info->tree_root;\r\nstruct btrfs_path *path = NULL;\r\nstruct btrfs_qgroup_status_item *ptr;\r\nstruct extent_buffer *leaf;\r\nstruct btrfs_key key;\r\nstruct btrfs_key found_key;\r\nstruct btrfs_qgroup *qgroup = NULL;\r\nint ret = 0;\r\nint slot;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nif (fs_info->quota_root) {\r\nfs_info->pending_quota_state = 1;\r\ngoto out;\r\n}\r\nfs_info->qgroup_ulist = ulist_alloc(GFP_NOFS);\r\nif (!fs_info->qgroup_ulist) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nquota_root = btrfs_create_tree(trans, fs_info,\r\nBTRFS_QUOTA_TREE_OBJECTID);\r\nif (IS_ERR(quota_root)) {\r\nret = PTR_ERR(quota_root);\r\ngoto out;\r\n}\r\npath = btrfs_alloc_path();\r\nif (!path) {\r\nret = -ENOMEM;\r\ngoto out_free_root;\r\n}\r\nkey.objectid = 0;\r\nkey.type = BTRFS_QGROUP_STATUS_KEY;\r\nkey.offset = 0;\r\nret = btrfs_insert_empty_item(trans, quota_root, path, &key,\r\nsizeof(*ptr));\r\nif (ret)\r\ngoto out_free_path;\r\nleaf = path->nodes[0];\r\nptr = btrfs_item_ptr(leaf, path->slots[0],\r\nstruct btrfs_qgroup_status_item);\r\nbtrfs_set_qgroup_status_generation(leaf, ptr, trans->transid);\r\nbtrfs_set_qgroup_status_version(leaf, ptr, BTRFS_QGROUP_STATUS_VERSION);\r\nfs_info->qgroup_flags = BTRFS_QGROUP_STATUS_FLAG_ON |\r\nBTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nbtrfs_set_qgroup_status_flags(leaf, ptr, fs_info->qgroup_flags);\r\nbtrfs_set_qgroup_status_rescan(leaf, ptr, 0);\r\nbtrfs_mark_buffer_dirty(leaf);\r\nkey.objectid = 0;\r\nkey.type = BTRFS_ROOT_REF_KEY;\r\nkey.offset = 0;\r\nbtrfs_release_path(path);\r\nret = btrfs_search_slot_for_read(tree_root, &key, path, 1, 0);\r\nif (ret > 0)\r\ngoto out_add_root;\r\nif (ret < 0)\r\ngoto out_free_path;\r\nwhile (1) {\r\nslot = path->slots[0];\r\nleaf = path->nodes[0];\r\nbtrfs_item_key_to_cpu(leaf, &found_key, slot);\r\nif (found_key.type == BTRFS_ROOT_REF_KEY) {\r\nret = add_qgroup_item(trans, quota_root,\r\nfound_key.offset);\r\nif (ret)\r\ngoto out_free_path;\r\nqgroup = add_qgroup_rb(fs_info, found_key.offset);\r\nif (IS_ERR(qgroup)) {\r\nret = PTR_ERR(qgroup);\r\ngoto out_free_path;\r\n}\r\n}\r\nret = btrfs_next_item(tree_root, path);\r\nif (ret < 0)\r\ngoto out_free_path;\r\nif (ret)\r\nbreak;\r\n}\r\nout_add_root:\r\nbtrfs_release_path(path);\r\nret = add_qgroup_item(trans, quota_root, BTRFS_FS_TREE_OBJECTID);\r\nif (ret)\r\ngoto out_free_path;\r\nqgroup = add_qgroup_rb(fs_info, BTRFS_FS_TREE_OBJECTID);\r\nif (IS_ERR(qgroup)) {\r\nret = PTR_ERR(qgroup);\r\ngoto out_free_path;\r\n}\r\nspin_lock(&fs_info->qgroup_lock);\r\nfs_info->quota_root = quota_root;\r\nfs_info->pending_quota_state = 1;\r\nspin_unlock(&fs_info->qgroup_lock);\r\nout_free_path:\r\nbtrfs_free_path(path);\r\nout_free_root:\r\nif (ret) {\r\nfree_extent_buffer(quota_root->node);\r\nfree_extent_buffer(quota_root->commit_root);\r\nkfree(quota_root);\r\n}\r\nout:\r\nif (ret) {\r\nulist_free(fs_info->qgroup_ulist);\r\nfs_info->qgroup_ulist = NULL;\r\n}\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nreturn ret;\r\n}\r\nint btrfs_quota_disable(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_root *tree_root = fs_info->tree_root;\r\nstruct btrfs_root *quota_root;\r\nint ret = 0;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nif (!fs_info->quota_root)\r\ngoto out;\r\nfs_info->quota_enabled = 0;\r\nfs_info->pending_quota_state = 0;\r\nbtrfs_qgroup_wait_for_completion(fs_info);\r\nspin_lock(&fs_info->qgroup_lock);\r\nquota_root = fs_info->quota_root;\r\nfs_info->quota_root = NULL;\r\nfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_ON;\r\nspin_unlock(&fs_info->qgroup_lock);\r\nbtrfs_free_qgroup_config(fs_info);\r\nret = btrfs_clean_quota_tree(trans, quota_root);\r\nif (ret)\r\ngoto out;\r\nret = btrfs_del_root(trans, tree_root, &quota_root->root_key);\r\nif (ret)\r\ngoto out;\r\nlist_del(&quota_root->dirty_list);\r\nbtrfs_tree_lock(quota_root->node);\r\nclean_tree_block(trans, tree_root->fs_info, quota_root->node);\r\nbtrfs_tree_unlock(quota_root->node);\r\nbtrfs_free_tree_block(trans, quota_root, quota_root->node, 0, 1);\r\nfree_extent_buffer(quota_root->node);\r\nfree_extent_buffer(quota_root->commit_root);\r\nkfree(quota_root);\r\nout:\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nreturn ret;\r\n}\r\nstatic void qgroup_dirty(struct btrfs_fs_info *fs_info,\r\nstruct btrfs_qgroup *qgroup)\r\n{\r\nif (list_empty(&qgroup->dirty))\r\nlist_add(&qgroup->dirty, &fs_info->dirty_qgroups);\r\n}\r\nstatic int __qgroup_excl_accounting(struct btrfs_fs_info *fs_info,\r\nstruct ulist *tmp, u64 ref_root,\r\nu64 num_bytes, int sign)\r\n{\r\nstruct btrfs_qgroup *qgroup;\r\nstruct btrfs_qgroup_list *glist;\r\nstruct ulist_node *unode;\r\nstruct ulist_iterator uiter;\r\nint ret = 0;\r\nqgroup = find_qgroup_rb(fs_info, ref_root);\r\nif (!qgroup)\r\ngoto out;\r\nqgroup->rfer += sign * num_bytes;\r\nqgroup->rfer_cmpr += sign * num_bytes;\r\nWARN_ON(sign < 0 && qgroup->excl < num_bytes);\r\nqgroup->excl += sign * num_bytes;\r\nqgroup->excl_cmpr += sign * num_bytes;\r\nif (sign > 0)\r\nqgroup->reserved -= num_bytes;\r\nqgroup_dirty(fs_info, qgroup);\r\nlist_for_each_entry(glist, &qgroup->groups, next_group) {\r\nret = ulist_add(tmp, glist->group->qgroupid,\r\nptr_to_u64(glist->group), GFP_ATOMIC);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\nULIST_ITER_INIT(&uiter);\r\nwhile ((unode = ulist_next(tmp, &uiter))) {\r\nqgroup = u64_to_ptr(unode->aux);\r\nqgroup->rfer += sign * num_bytes;\r\nqgroup->rfer_cmpr += sign * num_bytes;\r\nWARN_ON(sign < 0 && qgroup->excl < num_bytes);\r\nqgroup->excl += sign * num_bytes;\r\nif (sign > 0)\r\nqgroup->reserved -= num_bytes;\r\nqgroup->excl_cmpr += sign * num_bytes;\r\nqgroup_dirty(fs_info, qgroup);\r\nlist_for_each_entry(glist, &qgroup->groups, next_group) {\r\nret = ulist_add(tmp, glist->group->qgroupid,\r\nptr_to_u64(glist->group), GFP_ATOMIC);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\n}\r\nret = 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic int quick_update_accounting(struct btrfs_fs_info *fs_info,\r\nstruct ulist *tmp, u64 src, u64 dst,\r\nint sign)\r\n{\r\nstruct btrfs_qgroup *qgroup;\r\nint ret = 1;\r\nint err = 0;\r\nqgroup = find_qgroup_rb(fs_info, src);\r\nif (!qgroup)\r\ngoto out;\r\nif (qgroup->excl == qgroup->rfer) {\r\nret = 0;\r\nerr = __qgroup_excl_accounting(fs_info, tmp, dst,\r\nqgroup->excl, sign);\r\nif (err < 0) {\r\nret = err;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nif (ret)\r\nfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nreturn ret;\r\n}\r\nint btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info, u64 src, u64 dst)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_qgroup *parent;\r\nstruct btrfs_qgroup *member;\r\nstruct btrfs_qgroup_list *list;\r\nstruct ulist *tmp;\r\nint ret = 0;\r\nif (btrfs_qgroup_level(src) >= btrfs_qgroup_level(dst))\r\nreturn -EINVAL;\r\ntmp = ulist_alloc(GFP_NOFS);\r\nif (!tmp)\r\nreturn -ENOMEM;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nquota_root = fs_info->quota_root;\r\nif (!quota_root) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nmember = find_qgroup_rb(fs_info, src);\r\nparent = find_qgroup_rb(fs_info, dst);\r\nif (!member || !parent) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nlist_for_each_entry(list, &member->groups, next_group) {\r\nif (list->group == parent) {\r\nret = -EEXIST;\r\ngoto out;\r\n}\r\n}\r\nret = add_qgroup_relation_item(trans, quota_root, src, dst);\r\nif (ret)\r\ngoto out;\r\nret = add_qgroup_relation_item(trans, quota_root, dst, src);\r\nif (ret) {\r\ndel_qgroup_relation_item(trans, quota_root, src, dst);\r\ngoto out;\r\n}\r\nspin_lock(&fs_info->qgroup_lock);\r\nret = add_relation_rb(quota_root->fs_info, src, dst);\r\nif (ret < 0) {\r\nspin_unlock(&fs_info->qgroup_lock);\r\ngoto out;\r\n}\r\nret = quick_update_accounting(fs_info, tmp, src, dst, 1);\r\nspin_unlock(&fs_info->qgroup_lock);\r\nout:\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nulist_free(tmp);\r\nreturn ret;\r\n}\r\nint __del_qgroup_relation(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info, u64 src, u64 dst)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_qgroup *parent;\r\nstruct btrfs_qgroup *member;\r\nstruct btrfs_qgroup_list *list;\r\nstruct ulist *tmp;\r\nint ret = 0;\r\nint err;\r\ntmp = ulist_alloc(GFP_NOFS);\r\nif (!tmp)\r\nreturn -ENOMEM;\r\nquota_root = fs_info->quota_root;\r\nif (!quota_root) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nmember = find_qgroup_rb(fs_info, src);\r\nparent = find_qgroup_rb(fs_info, dst);\r\nif (!member || !parent) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nlist_for_each_entry(list, &member->groups, next_group) {\r\nif (list->group == parent)\r\ngoto exist;\r\n}\r\nret = -ENOENT;\r\ngoto out;\r\nexist:\r\nret = del_qgroup_relation_item(trans, quota_root, src, dst);\r\nerr = del_qgroup_relation_item(trans, quota_root, dst, src);\r\nif (err && !ret)\r\nret = err;\r\nspin_lock(&fs_info->qgroup_lock);\r\ndel_relation_rb(fs_info, src, dst);\r\nret = quick_update_accounting(fs_info, tmp, src, dst, -1);\r\nspin_unlock(&fs_info->qgroup_lock);\r\nout:\r\nulist_free(tmp);\r\nreturn ret;\r\n}\r\nint btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info, u64 src, u64 dst)\r\n{\r\nint ret = 0;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nret = __del_qgroup_relation(trans, fs_info, src, dst);\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nreturn ret;\r\n}\r\nint btrfs_create_qgroup(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info, u64 qgroupid)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_qgroup *qgroup;\r\nint ret = 0;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nquota_root = fs_info->quota_root;\r\nif (!quota_root) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nqgroup = find_qgroup_rb(fs_info, qgroupid);\r\nif (qgroup) {\r\nret = -EEXIST;\r\ngoto out;\r\n}\r\nret = add_qgroup_item(trans, quota_root, qgroupid);\r\nif (ret)\r\ngoto out;\r\nspin_lock(&fs_info->qgroup_lock);\r\nqgroup = add_qgroup_rb(fs_info, qgroupid);\r\nspin_unlock(&fs_info->qgroup_lock);\r\nif (IS_ERR(qgroup))\r\nret = PTR_ERR(qgroup);\r\nout:\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nreturn ret;\r\n}\r\nint btrfs_remove_qgroup(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info, u64 qgroupid)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_qgroup *qgroup;\r\nstruct btrfs_qgroup_list *list;\r\nint ret = 0;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nquota_root = fs_info->quota_root;\r\nif (!quota_root) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nqgroup = find_qgroup_rb(fs_info, qgroupid);\r\nif (!qgroup) {\r\nret = -ENOENT;\r\ngoto out;\r\n} else {\r\nif (!list_empty(&qgroup->members)) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\n}\r\nret = del_qgroup_item(trans, quota_root, qgroupid);\r\nwhile (!list_empty(&qgroup->groups)) {\r\nlist = list_first_entry(&qgroup->groups,\r\nstruct btrfs_qgroup_list, next_group);\r\nret = __del_qgroup_relation(trans, fs_info,\r\nqgroupid,\r\nlist->group->qgroupid);\r\nif (ret)\r\ngoto out;\r\n}\r\nspin_lock(&fs_info->qgroup_lock);\r\ndel_qgroup_rb(quota_root->fs_info, qgroupid);\r\nspin_unlock(&fs_info->qgroup_lock);\r\nout:\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nreturn ret;\r\n}\r\nint btrfs_limit_qgroup(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info, u64 qgroupid,\r\nstruct btrfs_qgroup_limit *limit)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_qgroup *qgroup;\r\nint ret = 0;\r\nconst u64 CLEAR_VALUE = -1;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nquota_root = fs_info->quota_root;\r\nif (!quota_root) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nqgroup = find_qgroup_rb(fs_info, qgroupid);\r\nif (!qgroup) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nspin_lock(&fs_info->qgroup_lock);\r\nif (limit->flags & BTRFS_QGROUP_LIMIT_MAX_RFER) {\r\nif (limit->max_rfer == CLEAR_VALUE) {\r\nqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_MAX_RFER;\r\nlimit->flags &= ~BTRFS_QGROUP_LIMIT_MAX_RFER;\r\nqgroup->max_rfer = 0;\r\n} else {\r\nqgroup->max_rfer = limit->max_rfer;\r\n}\r\n}\r\nif (limit->flags & BTRFS_QGROUP_LIMIT_MAX_EXCL) {\r\nif (limit->max_excl == CLEAR_VALUE) {\r\nqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_MAX_EXCL;\r\nlimit->flags &= ~BTRFS_QGROUP_LIMIT_MAX_EXCL;\r\nqgroup->max_excl = 0;\r\n} else {\r\nqgroup->max_excl = limit->max_excl;\r\n}\r\n}\r\nif (limit->flags & BTRFS_QGROUP_LIMIT_RSV_RFER) {\r\nif (limit->rsv_rfer == CLEAR_VALUE) {\r\nqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_RSV_RFER;\r\nlimit->flags &= ~BTRFS_QGROUP_LIMIT_RSV_RFER;\r\nqgroup->rsv_rfer = 0;\r\n} else {\r\nqgroup->rsv_rfer = limit->rsv_rfer;\r\n}\r\n}\r\nif (limit->flags & BTRFS_QGROUP_LIMIT_RSV_EXCL) {\r\nif (limit->rsv_excl == CLEAR_VALUE) {\r\nqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_RSV_EXCL;\r\nlimit->flags &= ~BTRFS_QGROUP_LIMIT_RSV_EXCL;\r\nqgroup->rsv_excl = 0;\r\n} else {\r\nqgroup->rsv_excl = limit->rsv_excl;\r\n}\r\n}\r\nqgroup->lim_flags |= limit->flags;\r\nspin_unlock(&fs_info->qgroup_lock);\r\nret = update_qgroup_limit_item(trans, quota_root, qgroup);\r\nif (ret) {\r\nfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nbtrfs_info(fs_info, "unable to update quota limit for %llu",\r\nqgroupid);\r\n}\r\nout:\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nreturn ret;\r\n}\r\nint btrfs_qgroup_prepare_account_extents(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_qgroup_extent_record *record;\r\nstruct btrfs_delayed_ref_root *delayed_refs;\r\nstruct rb_node *node;\r\nu64 qgroup_to_skip;\r\nint ret = 0;\r\ndelayed_refs = &trans->transaction->delayed_refs;\r\nqgroup_to_skip = delayed_refs->qgroup_to_skip;\r\nnode = rb_first(&delayed_refs->dirty_extent_root);\r\nwhile (node) {\r\nrecord = rb_entry(node, struct btrfs_qgroup_extent_record,\r\nnode);\r\nret = btrfs_find_all_roots(NULL, fs_info, record->bytenr, 0,\r\n&record->old_roots);\r\nif (ret < 0)\r\nbreak;\r\nif (qgroup_to_skip)\r\nulist_del(record->old_roots, qgroup_to_skip, 0);\r\nnode = rb_next(node);\r\n}\r\nreturn ret;\r\n}\r\nstruct btrfs_qgroup_extent_record\r\n*btrfs_qgroup_insert_dirty_extent(struct btrfs_delayed_ref_root *delayed_refs,\r\nstruct btrfs_qgroup_extent_record *record)\r\n{\r\nstruct rb_node **p = &delayed_refs->dirty_extent_root.rb_node;\r\nstruct rb_node *parent_node = NULL;\r\nstruct btrfs_qgroup_extent_record *entry;\r\nu64 bytenr = record->bytenr;\r\nassert_spin_locked(&delayed_refs->lock);\r\nwhile (*p) {\r\nparent_node = *p;\r\nentry = rb_entry(parent_node, struct btrfs_qgroup_extent_record,\r\nnode);\r\nif (bytenr < entry->bytenr)\r\np = &(*p)->rb_left;\r\nelse if (bytenr > entry->bytenr)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn entry;\r\n}\r\nrb_link_node(&record->node, parent_node, p);\r\nrb_insert_color(&record->node, &delayed_refs->dirty_extent_root);\r\nreturn NULL;\r\n}\r\nstatic int qgroup_update_refcnt(struct btrfs_fs_info *fs_info,\r\nstruct ulist *roots, struct ulist *tmp,\r\nstruct ulist *qgroups, u64 seq, int update_old)\r\n{\r\nstruct ulist_node *unode;\r\nstruct ulist_iterator uiter;\r\nstruct ulist_node *tmp_unode;\r\nstruct ulist_iterator tmp_uiter;\r\nstruct btrfs_qgroup *qg;\r\nint ret = 0;\r\nif (!roots)\r\nreturn 0;\r\nULIST_ITER_INIT(&uiter);\r\nwhile ((unode = ulist_next(roots, &uiter))) {\r\nqg = find_qgroup_rb(fs_info, unode->val);\r\nif (!qg)\r\ncontinue;\r\nulist_reinit(tmp);\r\nret = ulist_add(qgroups, qg->qgroupid, ptr_to_u64(qg),\r\nGFP_ATOMIC);\r\nif (ret < 0)\r\nreturn ret;\r\nret = ulist_add(tmp, qg->qgroupid, ptr_to_u64(qg), GFP_ATOMIC);\r\nif (ret < 0)\r\nreturn ret;\r\nULIST_ITER_INIT(&tmp_uiter);\r\nwhile ((tmp_unode = ulist_next(tmp, &tmp_uiter))) {\r\nstruct btrfs_qgroup_list *glist;\r\nqg = u64_to_ptr(tmp_unode->aux);\r\nif (update_old)\r\nbtrfs_qgroup_update_old_refcnt(qg, seq, 1);\r\nelse\r\nbtrfs_qgroup_update_new_refcnt(qg, seq, 1);\r\nlist_for_each_entry(glist, &qg->groups, next_group) {\r\nret = ulist_add(qgroups, glist->group->qgroupid,\r\nptr_to_u64(glist->group),\r\nGFP_ATOMIC);\r\nif (ret < 0)\r\nreturn ret;\r\nret = ulist_add(tmp, glist->group->qgroupid,\r\nptr_to_u64(glist->group),\r\nGFP_ATOMIC);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int qgroup_update_counters(struct btrfs_fs_info *fs_info,\r\nstruct ulist *qgroups,\r\nu64 nr_old_roots,\r\nu64 nr_new_roots,\r\nu64 num_bytes, u64 seq)\r\n{\r\nstruct ulist_node *unode;\r\nstruct ulist_iterator uiter;\r\nstruct btrfs_qgroup *qg;\r\nu64 cur_new_count, cur_old_count;\r\nULIST_ITER_INIT(&uiter);\r\nwhile ((unode = ulist_next(qgroups, &uiter))) {\r\nbool dirty = false;\r\nqg = u64_to_ptr(unode->aux);\r\ncur_old_count = btrfs_qgroup_get_old_refcnt(qg, seq);\r\ncur_new_count = btrfs_qgroup_get_new_refcnt(qg, seq);\r\nif (cur_old_count == 0 && cur_new_count > 0) {\r\nqg->rfer += num_bytes;\r\nqg->rfer_cmpr += num_bytes;\r\ndirty = true;\r\n}\r\nif (cur_old_count > 0 && cur_new_count == 0) {\r\nqg->rfer -= num_bytes;\r\nqg->rfer_cmpr -= num_bytes;\r\ndirty = true;\r\n}\r\nif (cur_old_count == nr_old_roots &&\r\ncur_new_count < nr_new_roots) {\r\nif (cur_old_count != 0) {\r\nqg->excl -= num_bytes;\r\nqg->excl_cmpr -= num_bytes;\r\ndirty = true;\r\n}\r\n}\r\nif (cur_old_count < nr_old_roots &&\r\ncur_new_count == nr_new_roots) {\r\nif (cur_new_count != 0) {\r\nqg->excl += num_bytes;\r\nqg->excl_cmpr += num_bytes;\r\ndirty = true;\r\n}\r\n}\r\nif (cur_old_count == nr_old_roots &&\r\ncur_new_count == nr_new_roots) {\r\nif (cur_old_count == 0) {\r\nif (cur_new_count != 0) {\r\nqg->excl += num_bytes;\r\nqg->excl_cmpr += num_bytes;\r\ndirty = true;\r\n}\r\n} else {\r\nif (cur_new_count == 0) {\r\nqg->excl -= num_bytes;\r\nqg->excl_cmpr -= num_bytes;\r\ndirty = true;\r\n}\r\n}\r\n}\r\nif (dirty)\r\nqgroup_dirty(fs_info, qg);\r\n}\r\nreturn 0;\r\n}\r\nint\r\nbtrfs_qgroup_account_extent(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info,\r\nu64 bytenr, u64 num_bytes,\r\nstruct ulist *old_roots, struct ulist *new_roots)\r\n{\r\nstruct ulist *qgroups = NULL;\r\nstruct ulist *tmp = NULL;\r\nu64 seq;\r\nu64 nr_new_roots = 0;\r\nu64 nr_old_roots = 0;\r\nint ret = 0;\r\nif (new_roots)\r\nnr_new_roots = new_roots->nnodes;\r\nif (old_roots)\r\nnr_old_roots = old_roots->nnodes;\r\nif (!fs_info->quota_enabled)\r\ngoto out_free;\r\nBUG_ON(!fs_info->quota_root);\r\nqgroups = ulist_alloc(GFP_NOFS);\r\nif (!qgroups) {\r\nret = -ENOMEM;\r\ngoto out_free;\r\n}\r\ntmp = ulist_alloc(GFP_NOFS);\r\nif (!tmp) {\r\nret = -ENOMEM;\r\ngoto out_free;\r\n}\r\nmutex_lock(&fs_info->qgroup_rescan_lock);\r\nif (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN) {\r\nif (fs_info->qgroup_rescan_progress.objectid <= bytenr) {\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\nret = 0;\r\ngoto out_free;\r\n}\r\n}\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\nspin_lock(&fs_info->qgroup_lock);\r\nseq = fs_info->qgroup_seq;\r\nret = qgroup_update_refcnt(fs_info, old_roots, tmp, qgroups, seq,\r\nUPDATE_OLD);\r\nif (ret < 0)\r\ngoto out;\r\nret = qgroup_update_refcnt(fs_info, new_roots, tmp, qgroups, seq,\r\nUPDATE_NEW);\r\nif (ret < 0)\r\ngoto out;\r\nqgroup_update_counters(fs_info, qgroups, nr_old_roots, nr_new_roots,\r\nnum_bytes, seq);\r\nfs_info->qgroup_seq += max(nr_old_roots, nr_new_roots) + 1;\r\nout:\r\nspin_unlock(&fs_info->qgroup_lock);\r\nout_free:\r\nulist_free(tmp);\r\nulist_free(qgroups);\r\nulist_free(old_roots);\r\nulist_free(new_roots);\r\nreturn ret;\r\n}\r\nint btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_qgroup_extent_record *record;\r\nstruct btrfs_delayed_ref_root *delayed_refs;\r\nstruct ulist *new_roots = NULL;\r\nstruct rb_node *node;\r\nu64 qgroup_to_skip;\r\nint ret = 0;\r\ndelayed_refs = &trans->transaction->delayed_refs;\r\nqgroup_to_skip = delayed_refs->qgroup_to_skip;\r\nwhile ((node = rb_first(&delayed_refs->dirty_extent_root))) {\r\nrecord = rb_entry(node, struct btrfs_qgroup_extent_record,\r\nnode);\r\nif (!ret) {\r\nret = btrfs_find_all_roots(trans, fs_info,\r\nrecord->bytenr, (u64)-1, &new_roots);\r\nif (ret < 0)\r\ngoto cleanup;\r\nif (qgroup_to_skip)\r\nulist_del(new_roots, qgroup_to_skip, 0);\r\nret = btrfs_qgroup_account_extent(trans, fs_info,\r\nrecord->bytenr, record->num_bytes,\r\nrecord->old_roots, new_roots);\r\nrecord->old_roots = NULL;\r\nnew_roots = NULL;\r\n}\r\ncleanup:\r\nulist_free(record->old_roots);\r\nulist_free(new_roots);\r\nnew_roots = NULL;\r\nrb_erase(node, &delayed_refs->dirty_extent_root);\r\nkfree(record);\r\n}\r\nreturn ret;\r\n}\r\nint btrfs_run_qgroups(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_root *quota_root = fs_info->quota_root;\r\nint ret = 0;\r\nint start_rescan_worker = 0;\r\nif (!quota_root)\r\ngoto out;\r\nif (!fs_info->quota_enabled && fs_info->pending_quota_state)\r\nstart_rescan_worker = 1;\r\nfs_info->quota_enabled = fs_info->pending_quota_state;\r\nspin_lock(&fs_info->qgroup_lock);\r\nwhile (!list_empty(&fs_info->dirty_qgroups)) {\r\nstruct btrfs_qgroup *qgroup;\r\nqgroup = list_first_entry(&fs_info->dirty_qgroups,\r\nstruct btrfs_qgroup, dirty);\r\nlist_del_init(&qgroup->dirty);\r\nspin_unlock(&fs_info->qgroup_lock);\r\nret = update_qgroup_info_item(trans, quota_root, qgroup);\r\nif (ret)\r\nfs_info->qgroup_flags |=\r\nBTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nret = update_qgroup_limit_item(trans, quota_root, qgroup);\r\nif (ret)\r\nfs_info->qgroup_flags |=\r\nBTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nspin_lock(&fs_info->qgroup_lock);\r\n}\r\nif (fs_info->quota_enabled)\r\nfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_ON;\r\nelse\r\nfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_ON;\r\nspin_unlock(&fs_info->qgroup_lock);\r\nret = update_qgroup_status_item(trans, fs_info, quota_root);\r\nif (ret)\r\nfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nif (!ret && start_rescan_worker) {\r\nret = qgroup_rescan_init(fs_info, 0, 1);\r\nif (!ret) {\r\nqgroup_rescan_zero_tracking(fs_info);\r\nbtrfs_queue_work(fs_info->qgroup_rescan_workers,\r\n&fs_info->qgroup_rescan_work);\r\n}\r\nret = 0;\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nint btrfs_qgroup_inherit(struct btrfs_trans_handle *trans,\r\nstruct btrfs_fs_info *fs_info, u64 srcid, u64 objectid,\r\nstruct btrfs_qgroup_inherit *inherit)\r\n{\r\nint ret = 0;\r\nint i;\r\nu64 *i_qgroups;\r\nstruct btrfs_root *quota_root = fs_info->quota_root;\r\nstruct btrfs_qgroup *srcgroup;\r\nstruct btrfs_qgroup *dstgroup;\r\nu32 level_size = 0;\r\nu64 nums;\r\nmutex_lock(&fs_info->qgroup_ioctl_lock);\r\nif (!fs_info->quota_enabled)\r\ngoto out;\r\nif (!quota_root) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nif (inherit) {\r\ni_qgroups = (u64 *)(inherit + 1);\r\nnums = inherit->num_qgroups + 2 * inherit->num_ref_copies +\r\n2 * inherit->num_excl_copies;\r\nfor (i = 0; i < nums; ++i) {\r\nsrcgroup = find_qgroup_rb(fs_info, *i_qgroups);\r\nif (!srcgroup) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nif ((srcgroup->qgroupid >> 48) <= (objectid >> 48)) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\n++i_qgroups;\r\n}\r\n}\r\nret = add_qgroup_item(trans, quota_root, objectid);\r\nif (ret)\r\ngoto out;\r\nif (srcid) {\r\nstruct btrfs_root *srcroot;\r\nstruct btrfs_key srckey;\r\nsrckey.objectid = srcid;\r\nsrckey.type = BTRFS_ROOT_ITEM_KEY;\r\nsrckey.offset = (u64)-1;\r\nsrcroot = btrfs_read_fs_root_no_name(fs_info, &srckey);\r\nif (IS_ERR(srcroot)) {\r\nret = PTR_ERR(srcroot);\r\ngoto out;\r\n}\r\nrcu_read_lock();\r\nlevel_size = srcroot->nodesize;\r\nrcu_read_unlock();\r\n}\r\nif (inherit) {\r\ni_qgroups = (u64 *)(inherit + 1);\r\nfor (i = 0; i < inherit->num_qgroups; ++i) {\r\nret = add_qgroup_relation_item(trans, quota_root,\r\nobjectid, *i_qgroups);\r\nif (ret)\r\ngoto out;\r\nret = add_qgroup_relation_item(trans, quota_root,\r\n*i_qgroups, objectid);\r\nif (ret)\r\ngoto out;\r\n++i_qgroups;\r\n}\r\n}\r\nspin_lock(&fs_info->qgroup_lock);\r\ndstgroup = add_qgroup_rb(fs_info, objectid);\r\nif (IS_ERR(dstgroup)) {\r\nret = PTR_ERR(dstgroup);\r\ngoto unlock;\r\n}\r\nif (inherit && inherit->flags & BTRFS_QGROUP_INHERIT_SET_LIMITS) {\r\ndstgroup->lim_flags = inherit->lim.flags;\r\ndstgroup->max_rfer = inherit->lim.max_rfer;\r\ndstgroup->max_excl = inherit->lim.max_excl;\r\ndstgroup->rsv_rfer = inherit->lim.rsv_rfer;\r\ndstgroup->rsv_excl = inherit->lim.rsv_excl;\r\nret = update_qgroup_limit_item(trans, quota_root, dstgroup);\r\nif (ret) {\r\nfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\nbtrfs_info(fs_info, "unable to update quota limit for %llu",\r\ndstgroup->qgroupid);\r\ngoto unlock;\r\n}\r\n}\r\nif (srcid) {\r\nsrcgroup = find_qgroup_rb(fs_info, srcid);\r\nif (!srcgroup)\r\ngoto unlock;\r\ndstgroup->rfer = srcgroup->rfer;\r\ndstgroup->rfer_cmpr = srcgroup->rfer_cmpr;\r\ndstgroup->excl = level_size;\r\ndstgroup->excl_cmpr = level_size;\r\nsrcgroup->excl = level_size;\r\nsrcgroup->excl_cmpr = level_size;\r\ndstgroup->lim_flags = srcgroup->lim_flags;\r\ndstgroup->max_rfer = srcgroup->max_rfer;\r\ndstgroup->max_excl = srcgroup->max_excl;\r\ndstgroup->rsv_rfer = srcgroup->rsv_rfer;\r\ndstgroup->rsv_excl = srcgroup->rsv_excl;\r\nqgroup_dirty(fs_info, dstgroup);\r\nqgroup_dirty(fs_info, srcgroup);\r\n}\r\nif (!inherit)\r\ngoto unlock;\r\ni_qgroups = (u64 *)(inherit + 1);\r\nfor (i = 0; i < inherit->num_qgroups; ++i) {\r\nret = add_relation_rb(quota_root->fs_info, objectid,\r\n*i_qgroups);\r\nif (ret)\r\ngoto unlock;\r\n++i_qgroups;\r\n}\r\nfor (i = 0; i < inherit->num_ref_copies; ++i) {\r\nstruct btrfs_qgroup *src;\r\nstruct btrfs_qgroup *dst;\r\nsrc = find_qgroup_rb(fs_info, i_qgroups[0]);\r\ndst = find_qgroup_rb(fs_info, i_qgroups[1]);\r\nif (!src || !dst) {\r\nret = -EINVAL;\r\ngoto unlock;\r\n}\r\ndst->rfer = src->rfer - level_size;\r\ndst->rfer_cmpr = src->rfer_cmpr - level_size;\r\ni_qgroups += 2;\r\n}\r\nfor (i = 0; i < inherit->num_excl_copies; ++i) {\r\nstruct btrfs_qgroup *src;\r\nstruct btrfs_qgroup *dst;\r\nsrc = find_qgroup_rb(fs_info, i_qgroups[0]);\r\ndst = find_qgroup_rb(fs_info, i_qgroups[1]);\r\nif (!src || !dst) {\r\nret = -EINVAL;\r\ngoto unlock;\r\n}\r\ndst->excl = src->excl + level_size;\r\ndst->excl_cmpr = src->excl_cmpr + level_size;\r\ni_qgroups += 2;\r\n}\r\nunlock:\r\nspin_unlock(&fs_info->qgroup_lock);\r\nout:\r\nmutex_unlock(&fs_info->qgroup_ioctl_lock);\r\nreturn ret;\r\n}\r\nstatic int qgroup_reserve(struct btrfs_root *root, u64 num_bytes)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_qgroup *qgroup;\r\nstruct btrfs_fs_info *fs_info = root->fs_info;\r\nu64 ref_root = root->root_key.objectid;\r\nint ret = 0;\r\nstruct ulist_node *unode;\r\nstruct ulist_iterator uiter;\r\nif (!is_fstree(ref_root))\r\nreturn 0;\r\nif (num_bytes == 0)\r\nreturn 0;\r\nspin_lock(&fs_info->qgroup_lock);\r\nquota_root = fs_info->quota_root;\r\nif (!quota_root)\r\ngoto out;\r\nqgroup = find_qgroup_rb(fs_info, ref_root);\r\nif (!qgroup)\r\ngoto out;\r\nulist_reinit(fs_info->qgroup_ulist);\r\nret = ulist_add(fs_info->qgroup_ulist, qgroup->qgroupid,\r\n(uintptr_t)qgroup, GFP_ATOMIC);\r\nif (ret < 0)\r\ngoto out;\r\nULIST_ITER_INIT(&uiter);\r\nwhile ((unode = ulist_next(fs_info->qgroup_ulist, &uiter))) {\r\nstruct btrfs_qgroup *qg;\r\nstruct btrfs_qgroup_list *glist;\r\nqg = u64_to_ptr(unode->aux);\r\nif ((qg->lim_flags & BTRFS_QGROUP_LIMIT_MAX_RFER) &&\r\nqg->reserved + (s64)qg->rfer + num_bytes >\r\nqg->max_rfer) {\r\nret = -EDQUOT;\r\ngoto out;\r\n}\r\nif ((qg->lim_flags & BTRFS_QGROUP_LIMIT_MAX_EXCL) &&\r\nqg->reserved + (s64)qg->excl + num_bytes >\r\nqg->max_excl) {\r\nret = -EDQUOT;\r\ngoto out;\r\n}\r\nlist_for_each_entry(glist, &qg->groups, next_group) {\r\nret = ulist_add(fs_info->qgroup_ulist,\r\nglist->group->qgroupid,\r\n(uintptr_t)glist->group, GFP_ATOMIC);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\n}\r\nret = 0;\r\nULIST_ITER_INIT(&uiter);\r\nwhile ((unode = ulist_next(fs_info->qgroup_ulist, &uiter))) {\r\nstruct btrfs_qgroup *qg;\r\nqg = u64_to_ptr(unode->aux);\r\nqg->reserved += num_bytes;\r\n}\r\nout:\r\nspin_unlock(&fs_info->qgroup_lock);\r\nreturn ret;\r\n}\r\nvoid btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,\r\nu64 ref_root, u64 num_bytes)\r\n{\r\nstruct btrfs_root *quota_root;\r\nstruct btrfs_qgroup *qgroup;\r\nstruct ulist_node *unode;\r\nstruct ulist_iterator uiter;\r\nint ret = 0;\r\nif (!is_fstree(ref_root))\r\nreturn;\r\nif (num_bytes == 0)\r\nreturn;\r\nspin_lock(&fs_info->qgroup_lock);\r\nquota_root = fs_info->quota_root;\r\nif (!quota_root)\r\ngoto out;\r\nqgroup = find_qgroup_rb(fs_info, ref_root);\r\nif (!qgroup)\r\ngoto out;\r\nulist_reinit(fs_info->qgroup_ulist);\r\nret = ulist_add(fs_info->qgroup_ulist, qgroup->qgroupid,\r\n(uintptr_t)qgroup, GFP_ATOMIC);\r\nif (ret < 0)\r\ngoto out;\r\nULIST_ITER_INIT(&uiter);\r\nwhile ((unode = ulist_next(fs_info->qgroup_ulist, &uiter))) {\r\nstruct btrfs_qgroup *qg;\r\nstruct btrfs_qgroup_list *glist;\r\nqg = u64_to_ptr(unode->aux);\r\nqg->reserved -= num_bytes;\r\nlist_for_each_entry(glist, &qg->groups, next_group) {\r\nret = ulist_add(fs_info->qgroup_ulist,\r\nglist->group->qgroupid,\r\n(uintptr_t)glist->group, GFP_ATOMIC);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\n}\r\nout:\r\nspin_unlock(&fs_info->qgroup_lock);\r\n}\r\nstatic inline void qgroup_free(struct btrfs_root *root, u64 num_bytes)\r\n{\r\nreturn btrfs_qgroup_free_refroot(root->fs_info, root->objectid,\r\nnum_bytes);\r\n}\r\nvoid assert_qgroups_uptodate(struct btrfs_trans_handle *trans)\r\n{\r\nif (list_empty(&trans->qgroup_ref_list) && !trans->delayed_ref_elem.seq)\r\nreturn;\r\nbtrfs_err(trans->root->fs_info,\r\n"qgroups not uptodate in trans handle %p: list is%s empty, "\r\n"seq is %#x.%x",\r\ntrans, list_empty(&trans->qgroup_ref_list) ? "" : " not",\r\n(u32)(trans->delayed_ref_elem.seq >> 32),\r\n(u32)trans->delayed_ref_elem.seq);\r\nBUG();\r\n}\r\nstatic int\r\nqgroup_rescan_leaf(struct btrfs_fs_info *fs_info, struct btrfs_path *path,\r\nstruct btrfs_trans_handle *trans)\r\n{\r\nstruct btrfs_key found;\r\nstruct extent_buffer *scratch_leaf = NULL;\r\nstruct ulist *roots = NULL;\r\nstruct seq_list tree_mod_seq_elem = SEQ_LIST_INIT(tree_mod_seq_elem);\r\nu64 num_bytes;\r\nint slot;\r\nint ret;\r\nmutex_lock(&fs_info->qgroup_rescan_lock);\r\nret = btrfs_search_slot_for_read(fs_info->extent_root,\r\n&fs_info->qgroup_rescan_progress,\r\npath, 1, 0);\r\npr_debug("current progress key (%llu %u %llu), search_slot ret %d\n",\r\nfs_info->qgroup_rescan_progress.objectid,\r\nfs_info->qgroup_rescan_progress.type,\r\nfs_info->qgroup_rescan_progress.offset, ret);\r\nif (ret) {\r\nfs_info->qgroup_rescan_progress.objectid = (u64)-1;\r\nbtrfs_release_path(path);\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\nreturn ret;\r\n}\r\nbtrfs_item_key_to_cpu(path->nodes[0], &found,\r\nbtrfs_header_nritems(path->nodes[0]) - 1);\r\nfs_info->qgroup_rescan_progress.objectid = found.objectid + 1;\r\nbtrfs_get_tree_mod_seq(fs_info, &tree_mod_seq_elem);\r\nscratch_leaf = btrfs_clone_extent_buffer(path->nodes[0]);\r\nif (!scratch_leaf) {\r\nret = -ENOMEM;\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\ngoto out;\r\n}\r\nextent_buffer_get(scratch_leaf);\r\nbtrfs_tree_read_lock(scratch_leaf);\r\nbtrfs_set_lock_blocking_rw(scratch_leaf, BTRFS_READ_LOCK);\r\nslot = path->slots[0];\r\nbtrfs_release_path(path);\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\nfor (; slot < btrfs_header_nritems(scratch_leaf); ++slot) {\r\nbtrfs_item_key_to_cpu(scratch_leaf, &found, slot);\r\nif (found.type != BTRFS_EXTENT_ITEM_KEY &&\r\nfound.type != BTRFS_METADATA_ITEM_KEY)\r\ncontinue;\r\nif (found.type == BTRFS_METADATA_ITEM_KEY)\r\nnum_bytes = fs_info->extent_root->nodesize;\r\nelse\r\nnum_bytes = found.offset;\r\nret = btrfs_find_all_roots(NULL, fs_info, found.objectid, 0,\r\n&roots);\r\nif (ret < 0)\r\ngoto out;\r\nret = btrfs_qgroup_account_extent(trans, fs_info,\r\nfound.objectid, num_bytes, NULL, roots);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\nout:\r\nif (scratch_leaf) {\r\nbtrfs_tree_read_unlock_blocking(scratch_leaf);\r\nfree_extent_buffer(scratch_leaf);\r\n}\r\nbtrfs_put_tree_mod_seq(fs_info, &tree_mod_seq_elem);\r\nreturn ret;\r\n}\r\nstatic void btrfs_qgroup_rescan_worker(struct btrfs_work *work)\r\n{\r\nstruct btrfs_fs_info *fs_info = container_of(work, struct btrfs_fs_info,\r\nqgroup_rescan_work);\r\nstruct btrfs_path *path;\r\nstruct btrfs_trans_handle *trans = NULL;\r\nint err = -ENOMEM;\r\nint ret = 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\ngoto out;\r\nerr = 0;\r\nwhile (!err && !btrfs_fs_closing(fs_info)) {\r\ntrans = btrfs_start_transaction(fs_info->fs_root, 0);\r\nif (IS_ERR(trans)) {\r\nerr = PTR_ERR(trans);\r\nbreak;\r\n}\r\nif (!fs_info->quota_enabled) {\r\nerr = -EINTR;\r\n} else {\r\nerr = qgroup_rescan_leaf(fs_info, path, trans);\r\n}\r\nif (err > 0)\r\nbtrfs_commit_transaction(trans, fs_info->fs_root);\r\nelse\r\nbtrfs_end_transaction(trans, fs_info->fs_root);\r\n}\r\nout:\r\nbtrfs_free_path(path);\r\nmutex_lock(&fs_info->qgroup_rescan_lock);\r\nif (!btrfs_fs_closing(fs_info))\r\nfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\r\nif (err > 0 &&\r\nfs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT) {\r\nfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\n} else if (err < 0) {\r\nfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\r\n}\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\ntrans = btrfs_start_transaction(fs_info->quota_root, 1);\r\nif (IS_ERR(trans)) {\r\nerr = PTR_ERR(trans);\r\nbtrfs_err(fs_info,\r\n"fail to start transaction for status update: %d\n",\r\nerr);\r\ngoto done;\r\n}\r\nret = update_qgroup_status_item(trans, fs_info, fs_info->quota_root);\r\nif (ret < 0) {\r\nerr = ret;\r\nbtrfs_err(fs_info, "fail to update qgroup status: %d\n", err);\r\n}\r\nbtrfs_end_transaction(trans, fs_info->quota_root);\r\nif (btrfs_fs_closing(fs_info)) {\r\nbtrfs_info(fs_info, "qgroup scan paused");\r\n} else if (err >= 0) {\r\nbtrfs_info(fs_info, "qgroup scan completed%s",\r\nerr > 0 ? " (inconsistency flag cleared)" : "");\r\n} else {\r\nbtrfs_err(fs_info, "qgroup scan failed with %d", err);\r\n}\r\ndone:\r\ncomplete_all(&fs_info->qgroup_rescan_completion);\r\n}\r\nstatic int\r\nqgroup_rescan_init(struct btrfs_fs_info *fs_info, u64 progress_objectid,\r\nint init_flags)\r\n{\r\nint ret = 0;\r\nif (!init_flags &&\r\n(!(fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN) ||\r\n!(fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_ON))) {\r\nret = -EINVAL;\r\ngoto err;\r\n}\r\nmutex_lock(&fs_info->qgroup_rescan_lock);\r\nspin_lock(&fs_info->qgroup_lock);\r\nif (init_flags) {\r\nif (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN)\r\nret = -EINPROGRESS;\r\nelse if (!(fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_ON))\r\nret = -EINVAL;\r\nif (ret) {\r\nspin_unlock(&fs_info->qgroup_lock);\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\ngoto err;\r\n}\r\nfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_RESCAN;\r\n}\r\nmemset(&fs_info->qgroup_rescan_progress, 0,\r\nsizeof(fs_info->qgroup_rescan_progress));\r\nfs_info->qgroup_rescan_progress.objectid = progress_objectid;\r\ninit_completion(&fs_info->qgroup_rescan_completion);\r\nspin_unlock(&fs_info->qgroup_lock);\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\nmemset(&fs_info->qgroup_rescan_work, 0,\r\nsizeof(fs_info->qgroup_rescan_work));\r\nbtrfs_init_work(&fs_info->qgroup_rescan_work,\r\nbtrfs_qgroup_rescan_helper,\r\nbtrfs_qgroup_rescan_worker, NULL, NULL);\r\nif (ret) {\r\nerr:\r\nbtrfs_info(fs_info, "qgroup_rescan_init failed with %d", ret);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nqgroup_rescan_zero_tracking(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct rb_node *n;\r\nstruct btrfs_qgroup *qgroup;\r\nspin_lock(&fs_info->qgroup_lock);\r\nfor (n = rb_first(&fs_info->qgroup_tree); n; n = rb_next(n)) {\r\nqgroup = rb_entry(n, struct btrfs_qgroup, node);\r\nqgroup->rfer = 0;\r\nqgroup->rfer_cmpr = 0;\r\nqgroup->excl = 0;\r\nqgroup->excl_cmpr = 0;\r\n}\r\nspin_unlock(&fs_info->qgroup_lock);\r\n}\r\nint\r\nbtrfs_qgroup_rescan(struct btrfs_fs_info *fs_info)\r\n{\r\nint ret = 0;\r\nstruct btrfs_trans_handle *trans;\r\nret = qgroup_rescan_init(fs_info, 0, 1);\r\nif (ret)\r\nreturn ret;\r\ntrans = btrfs_join_transaction(fs_info->fs_root);\r\nif (IS_ERR(trans)) {\r\nfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\r\nreturn PTR_ERR(trans);\r\n}\r\nret = btrfs_commit_transaction(trans, fs_info->fs_root);\r\nif (ret) {\r\nfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\r\nreturn ret;\r\n}\r\nqgroup_rescan_zero_tracking(fs_info);\r\nbtrfs_queue_work(fs_info->qgroup_rescan_workers,\r\n&fs_info->qgroup_rescan_work);\r\nreturn 0;\r\n}\r\nint btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info)\r\n{\r\nint running;\r\nint ret = 0;\r\nmutex_lock(&fs_info->qgroup_rescan_lock);\r\nspin_lock(&fs_info->qgroup_lock);\r\nrunning = fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN;\r\nspin_unlock(&fs_info->qgroup_lock);\r\nmutex_unlock(&fs_info->qgroup_rescan_lock);\r\nif (running)\r\nret = wait_for_completion_interruptible(\r\n&fs_info->qgroup_rescan_completion);\r\nreturn ret;\r\n}\r\nvoid\r\nbtrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info)\r\n{\r\nif (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN)\r\nbtrfs_queue_work(fs_info->qgroup_rescan_workers,\r\n&fs_info->qgroup_rescan_work);\r\n}\r\nint btrfs_qgroup_reserve_data(struct inode *inode, u64 start, u64 len)\r\n{\r\nstruct btrfs_root *root = BTRFS_I(inode)->root;\r\nstruct extent_changeset changeset;\r\nstruct ulist_node *unode;\r\nstruct ulist_iterator uiter;\r\nint ret;\r\nif (!root->fs_info->quota_enabled || !is_fstree(root->objectid) ||\r\nlen == 0)\r\nreturn 0;\r\nchangeset.bytes_changed = 0;\r\nchangeset.range_changed = ulist_alloc(GFP_NOFS);\r\nret = set_record_extent_bits(&BTRFS_I(inode)->io_tree, start,\r\nstart + len -1, EXTENT_QGROUP_RESERVED, GFP_NOFS,\r\n&changeset);\r\ntrace_btrfs_qgroup_reserve_data(inode, start, len,\r\nchangeset.bytes_changed,\r\nQGROUP_RESERVE);\r\nif (ret < 0)\r\ngoto cleanup;\r\nret = qgroup_reserve(root, changeset.bytes_changed);\r\nif (ret < 0)\r\ngoto cleanup;\r\nulist_free(changeset.range_changed);\r\nreturn ret;\r\ncleanup:\r\nULIST_ITER_INIT(&uiter);\r\nwhile ((unode = ulist_next(changeset.range_changed, &uiter)))\r\nclear_extent_bit(&BTRFS_I(inode)->io_tree, unode->val,\r\nunode->aux, EXTENT_QGROUP_RESERVED, 0, 0, NULL,\r\nGFP_NOFS);\r\nulist_free(changeset.range_changed);\r\nreturn ret;\r\n}\r\nstatic int __btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len,\r\nint free)\r\n{\r\nstruct extent_changeset changeset;\r\nint trace_op = QGROUP_RELEASE;\r\nint ret;\r\nchangeset.bytes_changed = 0;\r\nchangeset.range_changed = ulist_alloc(GFP_NOFS);\r\nif (!changeset.range_changed)\r\nreturn -ENOMEM;\r\nret = clear_record_extent_bits(&BTRFS_I(inode)->io_tree, start,\r\nstart + len -1, EXTENT_QGROUP_RESERVED, GFP_NOFS,\r\n&changeset);\r\nif (ret < 0)\r\ngoto out;\r\nif (free) {\r\nqgroup_free(BTRFS_I(inode)->root, changeset.bytes_changed);\r\ntrace_op = QGROUP_FREE;\r\n}\r\ntrace_btrfs_qgroup_release_data(inode, start, len,\r\nchangeset.bytes_changed, trace_op);\r\nout:\r\nulist_free(changeset.range_changed);\r\nreturn ret;\r\n}\r\nint btrfs_qgroup_free_data(struct inode *inode, u64 start, u64 len)\r\n{\r\nreturn __btrfs_qgroup_release_data(inode, start, len, 1);\r\n}\r\nint btrfs_qgroup_release_data(struct inode *inode, u64 start, u64 len)\r\n{\r\nreturn __btrfs_qgroup_release_data(inode, start, len, 0);\r\n}\r\nint btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes)\r\n{\r\nint ret;\r\nif (!root->fs_info->quota_enabled || !is_fstree(root->objectid) ||\r\nnum_bytes == 0)\r\nreturn 0;\r\nBUG_ON(num_bytes != round_down(num_bytes, root->nodesize));\r\nret = qgroup_reserve(root, num_bytes);\r\nif (ret < 0)\r\nreturn ret;\r\natomic_add(num_bytes, &root->qgroup_meta_rsv);\r\nreturn ret;\r\n}\r\nvoid btrfs_qgroup_free_meta_all(struct btrfs_root *root)\r\n{\r\nint reserved;\r\nif (!root->fs_info->quota_enabled || !is_fstree(root->objectid))\r\nreturn;\r\nreserved = atomic_xchg(&root->qgroup_meta_rsv, 0);\r\nif (reserved == 0)\r\nreturn;\r\nqgroup_free(root, reserved);\r\n}\r\nvoid btrfs_qgroup_free_meta(struct btrfs_root *root, int num_bytes)\r\n{\r\nif (!root->fs_info->quota_enabled || !is_fstree(root->objectid))\r\nreturn;\r\nBUG_ON(num_bytes != round_down(num_bytes, root->nodesize));\r\nWARN_ON(atomic_read(&root->qgroup_meta_rsv) < num_bytes);\r\natomic_sub(num_bytes, &root->qgroup_meta_rsv);\r\nqgroup_free(root, num_bytes);\r\n}\r\nvoid btrfs_qgroup_check_reserved_leak(struct inode *inode)\r\n{\r\nstruct extent_changeset changeset;\r\nstruct ulist_node *unode;\r\nstruct ulist_iterator iter;\r\nint ret;\r\nchangeset.bytes_changed = 0;\r\nchangeset.range_changed = ulist_alloc(GFP_NOFS);\r\nif (WARN_ON(!changeset.range_changed))\r\nreturn;\r\nret = clear_record_extent_bits(&BTRFS_I(inode)->io_tree, 0, (u64)-1,\r\nEXTENT_QGROUP_RESERVED, GFP_NOFS, &changeset);\r\nWARN_ON(ret < 0);\r\nif (WARN_ON(changeset.bytes_changed)) {\r\nULIST_ITER_INIT(&iter);\r\nwhile ((unode = ulist_next(changeset.range_changed, &iter))) {\r\nbtrfs_warn(BTRFS_I(inode)->root->fs_info,\r\n"leaking qgroup reserved space, ino: %lu, start: %llu, end: %llu",\r\ninode->i_ino, unode->val, unode->aux);\r\n}\r\nqgroup_free(BTRFS_I(inode)->root, changeset.bytes_changed);\r\n}\r\nulist_free(changeset.range_changed);\r\n}
