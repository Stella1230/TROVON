int virtcrypto_devmgr_add_dev(struct virtio_crypto *vcrypto_dev)\r\n{\r\nstruct list_head *itr;\r\nmutex_lock(&table_lock);\r\nif (num_devices == VIRTIO_CRYPTO_MAX_DEVICES) {\r\npr_info("virtio_crypto: only support up to %d devices\n",\r\nVIRTIO_CRYPTO_MAX_DEVICES);\r\nmutex_unlock(&table_lock);\r\nreturn -EFAULT;\r\n}\r\nlist_for_each(itr, &virtio_crypto_table) {\r\nstruct virtio_crypto *ptr =\r\nlist_entry(itr, struct virtio_crypto, list);\r\nif (ptr == vcrypto_dev) {\r\nmutex_unlock(&table_lock);\r\nreturn -EEXIST;\r\n}\r\n}\r\natomic_set(&vcrypto_dev->ref_count, 0);\r\nlist_add_tail(&vcrypto_dev->list, &virtio_crypto_table);\r\nvcrypto_dev->dev_id = num_devices++;\r\nmutex_unlock(&table_lock);\r\nreturn 0;\r\n}\r\nstruct list_head *virtcrypto_devmgr_get_head(void)\r\n{\r\nreturn &virtio_crypto_table;\r\n}\r\nvoid virtcrypto_devmgr_rm_dev(struct virtio_crypto *vcrypto_dev)\r\n{\r\nmutex_lock(&table_lock);\r\nlist_del(&vcrypto_dev->list);\r\nnum_devices--;\r\nmutex_unlock(&table_lock);\r\n}\r\nstruct virtio_crypto *virtcrypto_devmgr_get_first(void)\r\n{\r\nstruct virtio_crypto *dev = NULL;\r\nmutex_lock(&table_lock);\r\nif (!list_empty(&virtio_crypto_table))\r\ndev = list_first_entry(&virtio_crypto_table,\r\nstruct virtio_crypto,\r\nlist);\r\nmutex_unlock(&table_lock);\r\nreturn dev;\r\n}\r\nint virtcrypto_dev_in_use(struct virtio_crypto *vcrypto_dev)\r\n{\r\nreturn atomic_read(&vcrypto_dev->ref_count) != 0;\r\n}\r\nint virtcrypto_dev_get(struct virtio_crypto *vcrypto_dev)\r\n{\r\nif (atomic_add_return(1, &vcrypto_dev->ref_count) == 1)\r\nif (!try_module_get(vcrypto_dev->owner))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nvoid virtcrypto_dev_put(struct virtio_crypto *vcrypto_dev)\r\n{\r\nif (atomic_sub_return(1, &vcrypto_dev->ref_count) == 0)\r\nmodule_put(vcrypto_dev->owner);\r\n}\r\nint virtcrypto_dev_started(struct virtio_crypto *vcrypto_dev)\r\n{\r\nreturn (vcrypto_dev->status & VIRTIO_CRYPTO_S_HW_READY);\r\n}\r\nstruct virtio_crypto *virtcrypto_get_dev_node(int node)\r\n{\r\nstruct virtio_crypto *vcrypto_dev = NULL, *tmp_dev;\r\nunsigned long best = ~0;\r\nunsigned long ctr;\r\nmutex_lock(&table_lock);\r\nlist_for_each_entry(tmp_dev, virtcrypto_devmgr_get_head(), list) {\r\nif ((node == dev_to_node(&tmp_dev->vdev->dev) ||\r\ndev_to_node(&tmp_dev->vdev->dev) < 0) &&\r\nvirtcrypto_dev_started(tmp_dev)) {\r\nctr = atomic_read(&tmp_dev->ref_count);\r\nif (best > ctr) {\r\nvcrypto_dev = tmp_dev;\r\nbest = ctr;\r\n}\r\n}\r\n}\r\nif (!vcrypto_dev) {\r\npr_info("virtio_crypto: Could not find a device on node %d\n",\r\nnode);\r\nlist_for_each_entry(tmp_dev,\r\nvirtcrypto_devmgr_get_head(), list) {\r\nif (virtcrypto_dev_started(tmp_dev)) {\r\nvcrypto_dev = tmp_dev;\r\nbreak;\r\n}\r\n}\r\n}\r\nmutex_unlock(&table_lock);\r\nif (!vcrypto_dev)\r\nreturn NULL;\r\nvirtcrypto_dev_get(vcrypto_dev);\r\nreturn vcrypto_dev;\r\n}\r\nint virtcrypto_dev_start(struct virtio_crypto *vcrypto)\r\n{\r\nif (virtio_crypto_algs_register()) {\r\npr_err("virtio_crypto: Failed to register crypto algs\n");\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nvoid virtcrypto_dev_stop(struct virtio_crypto *vcrypto)\r\n{\r\nvirtio_crypto_algs_unregister();\r\n}
