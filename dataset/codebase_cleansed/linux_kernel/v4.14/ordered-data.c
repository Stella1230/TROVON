static u64 entry_end(struct btrfs_ordered_extent *entry)\r\n{\r\nif (entry->file_offset + entry->len < entry->file_offset)\r\nreturn (u64)-1;\r\nreturn entry->file_offset + entry->len;\r\n}\r\nstatic struct rb_node *tree_insert(struct rb_root *root, u64 file_offset,\r\nstruct rb_node *node)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct btrfs_ordered_extent *entry;\r\nwhile (*p) {\r\nparent = *p;\r\nentry = rb_entry(parent, struct btrfs_ordered_extent, rb_node);\r\nif (file_offset < entry->file_offset)\r\np = &(*p)->rb_left;\r\nelse if (file_offset >= entry_end(entry))\r\np = &(*p)->rb_right;\r\nelse\r\nreturn parent;\r\n}\r\nrb_link_node(node, parent, p);\r\nrb_insert_color(node, root);\r\nreturn NULL;\r\n}\r\nstatic void ordered_data_tree_panic(struct inode *inode, int errno,\r\nu64 offset)\r\n{\r\nstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\r\nbtrfs_panic(fs_info, errno,\r\n"Inconsistency in ordered tree at offset %llu", offset);\r\n}\r\nstatic struct rb_node *__tree_search(struct rb_root *root, u64 file_offset,\r\nstruct rb_node **prev_ret)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct rb_node *prev = NULL;\r\nstruct rb_node *test;\r\nstruct btrfs_ordered_extent *entry;\r\nstruct btrfs_ordered_extent *prev_entry = NULL;\r\nwhile (n) {\r\nentry = rb_entry(n, struct btrfs_ordered_extent, rb_node);\r\nprev = n;\r\nprev_entry = entry;\r\nif (file_offset < entry->file_offset)\r\nn = n->rb_left;\r\nelse if (file_offset >= entry_end(entry))\r\nn = n->rb_right;\r\nelse\r\nreturn n;\r\n}\r\nif (!prev_ret)\r\nreturn NULL;\r\nwhile (prev && file_offset >= entry_end(prev_entry)) {\r\ntest = rb_next(prev);\r\nif (!test)\r\nbreak;\r\nprev_entry = rb_entry(test, struct btrfs_ordered_extent,\r\nrb_node);\r\nif (file_offset < entry_end(prev_entry))\r\nbreak;\r\nprev = test;\r\n}\r\nif (prev)\r\nprev_entry = rb_entry(prev, struct btrfs_ordered_extent,\r\nrb_node);\r\nwhile (prev && file_offset < entry_end(prev_entry)) {\r\ntest = rb_prev(prev);\r\nif (!test)\r\nbreak;\r\nprev_entry = rb_entry(test, struct btrfs_ordered_extent,\r\nrb_node);\r\nprev = test;\r\n}\r\n*prev_ret = prev;\r\nreturn NULL;\r\n}\r\nstatic int offset_in_entry(struct btrfs_ordered_extent *entry, u64 file_offset)\r\n{\r\nif (file_offset < entry->file_offset ||\r\nentry->file_offset + entry->len <= file_offset)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic int range_overlaps(struct btrfs_ordered_extent *entry, u64 file_offset,\r\nu64 len)\r\n{\r\nif (file_offset + len <= entry->file_offset ||\r\nentry->file_offset + entry->len <= file_offset)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic inline struct rb_node *tree_search(struct btrfs_ordered_inode_tree *tree,\r\nu64 file_offset)\r\n{\r\nstruct rb_root *root = &tree->tree;\r\nstruct rb_node *prev = NULL;\r\nstruct rb_node *ret;\r\nstruct btrfs_ordered_extent *entry;\r\nif (tree->last) {\r\nentry = rb_entry(tree->last, struct btrfs_ordered_extent,\r\nrb_node);\r\nif (offset_in_entry(entry, file_offset))\r\nreturn tree->last;\r\n}\r\nret = __tree_search(root, file_offset, &prev);\r\nif (!ret)\r\nret = prev;\r\nif (ret)\r\ntree->last = ret;\r\nreturn ret;\r\n}\r\nstatic int __btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len,\r\nint type, int dio, int compress_type)\r\n{\r\nstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\r\nstruct btrfs_root *root = BTRFS_I(inode)->root;\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nentry = kmem_cache_zalloc(btrfs_ordered_extent_cache, GFP_NOFS);\r\nif (!entry)\r\nreturn -ENOMEM;\r\nentry->file_offset = file_offset;\r\nentry->start = start;\r\nentry->len = len;\r\nentry->disk_len = disk_len;\r\nentry->bytes_left = len;\r\nentry->inode = igrab(inode);\r\nentry->compress_type = compress_type;\r\nentry->truncated_len = (u64)-1;\r\nif (type != BTRFS_ORDERED_IO_DONE && type != BTRFS_ORDERED_COMPLETE)\r\nset_bit(type, &entry->flags);\r\nif (dio)\r\nset_bit(BTRFS_ORDERED_DIRECT, &entry->flags);\r\nrefcount_set(&entry->refs, 1);\r\ninit_waitqueue_head(&entry->wait);\r\nINIT_LIST_HEAD(&entry->list);\r\nINIT_LIST_HEAD(&entry->root_extent_list);\r\nINIT_LIST_HEAD(&entry->work_list);\r\ninit_completion(&entry->completion);\r\nINIT_LIST_HEAD(&entry->log_list);\r\nINIT_LIST_HEAD(&entry->trans_list);\r\ntrace_btrfs_ordered_extent_add(inode, entry);\r\nspin_lock_irq(&tree->lock);\r\nnode = tree_insert(&tree->tree, file_offset,\r\n&entry->rb_node);\r\nif (node)\r\nordered_data_tree_panic(inode, -EEXIST, file_offset);\r\nspin_unlock_irq(&tree->lock);\r\nspin_lock(&root->ordered_extent_lock);\r\nlist_add_tail(&entry->root_extent_list,\r\n&root->ordered_extents);\r\nroot->nr_ordered_extents++;\r\nif (root->nr_ordered_extents == 1) {\r\nspin_lock(&fs_info->ordered_root_lock);\r\nBUG_ON(!list_empty(&root->ordered_root));\r\nlist_add_tail(&root->ordered_root, &fs_info->ordered_roots);\r\nspin_unlock(&fs_info->ordered_root_lock);\r\n}\r\nspin_unlock(&root->ordered_extent_lock);\r\nreturn 0;\r\n}\r\nint btrfs_add_ordered_extent(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len, int type)\r\n{\r\nreturn __btrfs_add_ordered_extent(inode, file_offset, start, len,\r\ndisk_len, type, 0,\r\nBTRFS_COMPRESS_NONE);\r\n}\r\nint btrfs_add_ordered_extent_dio(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len, int type)\r\n{\r\nreturn __btrfs_add_ordered_extent(inode, file_offset, start, len,\r\ndisk_len, type, 1,\r\nBTRFS_COMPRESS_NONE);\r\n}\r\nint btrfs_add_ordered_extent_compress(struct inode *inode, u64 file_offset,\r\nu64 start, u64 len, u64 disk_len,\r\nint type, int compress_type)\r\n{\r\nreturn __btrfs_add_ordered_extent(inode, file_offset, start, len,\r\ndisk_len, type, 0,\r\ncompress_type);\r\n}\r\nvoid btrfs_add_ordered_sum(struct inode *inode,\r\nstruct btrfs_ordered_extent *entry,\r\nstruct btrfs_ordered_sum *sum)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock_irq(&tree->lock);\r\nlist_add_tail(&sum->list, &entry->list);\r\nspin_unlock_irq(&tree->lock);\r\n}\r\nint btrfs_dec_test_first_ordered_pending(struct inode *inode,\r\nstruct btrfs_ordered_extent **cached,\r\nu64 *file_offset, u64 io_size, int uptodate)\r\n{\r\nstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\nint ret;\r\nunsigned long flags;\r\nu64 dec_end;\r\nu64 dec_start;\r\nu64 to_dec;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock_irqsave(&tree->lock, flags);\r\nnode = tree_search(tree, *file_offset);\r\nif (!node) {\r\nret = 1;\r\ngoto out;\r\n}\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (!offset_in_entry(entry, *file_offset)) {\r\nret = 1;\r\ngoto out;\r\n}\r\ndec_start = max(*file_offset, entry->file_offset);\r\ndec_end = min(*file_offset + io_size, entry->file_offset +\r\nentry->len);\r\n*file_offset = dec_end;\r\nif (dec_start > dec_end) {\r\nbtrfs_crit(fs_info, "bad ordering dec_start %llu end %llu",\r\ndec_start, dec_end);\r\n}\r\nto_dec = dec_end - dec_start;\r\nif (to_dec > entry->bytes_left) {\r\nbtrfs_crit(fs_info,\r\n"bad ordered accounting left %llu size %llu",\r\nentry->bytes_left, to_dec);\r\n}\r\nentry->bytes_left -= to_dec;\r\nif (!uptodate)\r\nset_bit(BTRFS_ORDERED_IOERR, &entry->flags);\r\nif (entry->bytes_left == 0) {\r\nret = test_and_set_bit(BTRFS_ORDERED_IO_DONE, &entry->flags);\r\nif (waitqueue_active(&entry->wait))\r\nwake_up(&entry->wait);\r\n} else {\r\nret = 1;\r\n}\r\nout:\r\nif (!ret && cached && entry) {\r\n*cached = entry;\r\nrefcount_inc(&entry->refs);\r\n}\r\nspin_unlock_irqrestore(&tree->lock, flags);\r\nreturn ret == 0;\r\n}\r\nint btrfs_dec_test_ordered_pending(struct inode *inode,\r\nstruct btrfs_ordered_extent **cached,\r\nu64 file_offset, u64 io_size, int uptodate)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\nunsigned long flags;\r\nint ret;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock_irqsave(&tree->lock, flags);\r\nif (cached && *cached) {\r\nentry = *cached;\r\ngoto have_entry;\r\n}\r\nnode = tree_search(tree, file_offset);\r\nif (!node) {\r\nret = 1;\r\ngoto out;\r\n}\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nhave_entry:\r\nif (!offset_in_entry(entry, file_offset)) {\r\nret = 1;\r\ngoto out;\r\n}\r\nif (io_size > entry->bytes_left) {\r\nbtrfs_crit(BTRFS_I(inode)->root->fs_info,\r\n"bad ordered accounting left %llu size %llu",\r\nentry->bytes_left, io_size);\r\n}\r\nentry->bytes_left -= io_size;\r\nif (!uptodate)\r\nset_bit(BTRFS_ORDERED_IOERR, &entry->flags);\r\nif (entry->bytes_left == 0) {\r\nret = test_and_set_bit(BTRFS_ORDERED_IO_DONE, &entry->flags);\r\nif (waitqueue_active(&entry->wait))\r\nwake_up(&entry->wait);\r\n} else {\r\nret = 1;\r\n}\r\nout:\r\nif (!ret && cached && entry) {\r\n*cached = entry;\r\nrefcount_inc(&entry->refs);\r\n}\r\nspin_unlock_irqrestore(&tree->lock, flags);\r\nreturn ret == 0;\r\n}\r\nvoid btrfs_get_logged_extents(struct btrfs_inode *inode,\r\nstruct list_head *logged_list,\r\nconst loff_t start,\r\nconst loff_t end)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct btrfs_ordered_extent *ordered;\r\nstruct rb_node *n;\r\nstruct rb_node *prev;\r\ntree = &inode->ordered_tree;\r\nspin_lock_irq(&tree->lock);\r\nn = __tree_search(&tree->tree, end, &prev);\r\nif (!n)\r\nn = prev;\r\nfor (; n; n = rb_prev(n)) {\r\nordered = rb_entry(n, struct btrfs_ordered_extent, rb_node);\r\nif (ordered->file_offset > end)\r\ncontinue;\r\nif (entry_end(ordered) <= start)\r\nbreak;\r\nif (test_and_set_bit(BTRFS_ORDERED_LOGGED, &ordered->flags))\r\ncontinue;\r\nlist_add(&ordered->log_list, logged_list);\r\nrefcount_inc(&ordered->refs);\r\n}\r\nspin_unlock_irq(&tree->lock);\r\n}\r\nvoid btrfs_put_logged_extents(struct list_head *logged_list)\r\n{\r\nstruct btrfs_ordered_extent *ordered;\r\nwhile (!list_empty(logged_list)) {\r\nordered = list_first_entry(logged_list,\r\nstruct btrfs_ordered_extent,\r\nlog_list);\r\nlist_del_init(&ordered->log_list);\r\nbtrfs_put_ordered_extent(ordered);\r\n}\r\n}\r\nvoid btrfs_submit_logged_extents(struct list_head *logged_list,\r\nstruct btrfs_root *log)\r\n{\r\nint index = log->log_transid % 2;\r\nspin_lock_irq(&log->log_extents_lock[index]);\r\nlist_splice_tail(logged_list, &log->logged_list[index]);\r\nspin_unlock_irq(&log->log_extents_lock[index]);\r\n}\r\nvoid btrfs_wait_logged_extents(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *log, u64 transid)\r\n{\r\nstruct btrfs_ordered_extent *ordered;\r\nint index = transid % 2;\r\nspin_lock_irq(&log->log_extents_lock[index]);\r\nwhile (!list_empty(&log->logged_list[index])) {\r\nstruct inode *inode;\r\nordered = list_first_entry(&log->logged_list[index],\r\nstruct btrfs_ordered_extent,\r\nlog_list);\r\nlist_del_init(&ordered->log_list);\r\ninode = ordered->inode;\r\nspin_unlock_irq(&log->log_extents_lock[index]);\r\nif (!test_bit(BTRFS_ORDERED_IO_DONE, &ordered->flags) &&\r\n!test_bit(BTRFS_ORDERED_DIRECT, &ordered->flags)) {\r\nu64 start = ordered->file_offset;\r\nu64 end = ordered->file_offset + ordered->len - 1;\r\nWARN_ON(!inode);\r\nfilemap_fdatawrite_range(inode->i_mapping, start, end);\r\n}\r\nwait_event(ordered->wait, test_bit(BTRFS_ORDERED_IO_DONE,\r\n&ordered->flags));\r\nif (!test_bit(BTRFS_ORDERED_COMPLETE, &ordered->flags)) {\r\nstruct btrfs_ordered_inode_tree *tree;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock_irq(&tree->lock);\r\nif (!test_bit(BTRFS_ORDERED_COMPLETE, &ordered->flags)) {\r\nset_bit(BTRFS_ORDERED_PENDING, &ordered->flags);\r\natomic_inc(&trans->transaction->pending_ordered);\r\n}\r\nspin_unlock_irq(&tree->lock);\r\n}\r\nbtrfs_put_ordered_extent(ordered);\r\nspin_lock_irq(&log->log_extents_lock[index]);\r\n}\r\nspin_unlock_irq(&log->log_extents_lock[index]);\r\n}\r\nvoid btrfs_free_logged_extents(struct btrfs_root *log, u64 transid)\r\n{\r\nstruct btrfs_ordered_extent *ordered;\r\nint index = transid % 2;\r\nspin_lock_irq(&log->log_extents_lock[index]);\r\nwhile (!list_empty(&log->logged_list[index])) {\r\nordered = list_first_entry(&log->logged_list[index],\r\nstruct btrfs_ordered_extent,\r\nlog_list);\r\nlist_del_init(&ordered->log_list);\r\nspin_unlock_irq(&log->log_extents_lock[index]);\r\nbtrfs_put_ordered_extent(ordered);\r\nspin_lock_irq(&log->log_extents_lock[index]);\r\n}\r\nspin_unlock_irq(&log->log_extents_lock[index]);\r\n}\r\nvoid btrfs_put_ordered_extent(struct btrfs_ordered_extent *entry)\r\n{\r\nstruct list_head *cur;\r\nstruct btrfs_ordered_sum *sum;\r\ntrace_btrfs_ordered_extent_put(entry->inode, entry);\r\nif (refcount_dec_and_test(&entry->refs)) {\r\nASSERT(list_empty(&entry->log_list));\r\nASSERT(list_empty(&entry->trans_list));\r\nASSERT(list_empty(&entry->root_extent_list));\r\nASSERT(RB_EMPTY_NODE(&entry->rb_node));\r\nif (entry->inode)\r\nbtrfs_add_delayed_iput(entry->inode);\r\nwhile (!list_empty(&entry->list)) {\r\ncur = entry->list.next;\r\nsum = list_entry(cur, struct btrfs_ordered_sum, list);\r\nlist_del(&sum->list);\r\nkfree(sum);\r\n}\r\nkmem_cache_free(btrfs_ordered_extent_cache, entry);\r\n}\r\n}\r\nvoid btrfs_remove_ordered_extent(struct inode *inode,\r\nstruct btrfs_ordered_extent *entry)\r\n{\r\nstruct btrfs_fs_info *fs_info = btrfs_sb(inode->i_sb);\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct btrfs_root *root = BTRFS_I(inode)->root;\r\nstruct rb_node *node;\r\nbool dec_pending_ordered = false;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock_irq(&tree->lock);\r\nnode = &entry->rb_node;\r\nrb_erase(node, &tree->tree);\r\nRB_CLEAR_NODE(node);\r\nif (tree->last == node)\r\ntree->last = NULL;\r\nset_bit(BTRFS_ORDERED_COMPLETE, &entry->flags);\r\nif (test_and_clear_bit(BTRFS_ORDERED_PENDING, &entry->flags))\r\ndec_pending_ordered = true;\r\nspin_unlock_irq(&tree->lock);\r\nif (dec_pending_ordered) {\r\nstruct btrfs_transaction *trans;\r\nspin_lock(&fs_info->trans_lock);\r\ntrans = fs_info->running_transaction;\r\nif (trans)\r\nrefcount_inc(&trans->use_count);\r\nspin_unlock(&fs_info->trans_lock);\r\nASSERT(trans);\r\nif (trans) {\r\nif (atomic_dec_and_test(&trans->pending_ordered))\r\nwake_up(&trans->pending_wait);\r\nbtrfs_put_transaction(trans);\r\n}\r\n}\r\nspin_lock(&root->ordered_extent_lock);\r\nlist_del_init(&entry->root_extent_list);\r\nroot->nr_ordered_extents--;\r\ntrace_btrfs_ordered_extent_remove(inode, entry);\r\nif (!root->nr_ordered_extents) {\r\nspin_lock(&fs_info->ordered_root_lock);\r\nBUG_ON(list_empty(&root->ordered_root));\r\nlist_del_init(&root->ordered_root);\r\nspin_unlock(&fs_info->ordered_root_lock);\r\n}\r\nspin_unlock(&root->ordered_extent_lock);\r\nwake_up(&entry->wait);\r\n}\r\nstatic void btrfs_run_ordered_extent_work(struct btrfs_work *work)\r\n{\r\nstruct btrfs_ordered_extent *ordered;\r\nordered = container_of(work, struct btrfs_ordered_extent, flush_work);\r\nbtrfs_start_ordered_extent(ordered->inode, ordered, 1);\r\ncomplete(&ordered->completion);\r\n}\r\nu64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,\r\nconst u64 range_start, const u64 range_len)\r\n{\r\nstruct btrfs_fs_info *fs_info = root->fs_info;\r\nLIST_HEAD(splice);\r\nLIST_HEAD(skipped);\r\nLIST_HEAD(works);\r\nstruct btrfs_ordered_extent *ordered, *next;\r\nu64 count = 0;\r\nconst u64 range_end = range_start + range_len;\r\nmutex_lock(&root->ordered_extent_mutex);\r\nspin_lock(&root->ordered_extent_lock);\r\nlist_splice_init(&root->ordered_extents, &splice);\r\nwhile (!list_empty(&splice) && nr) {\r\nordered = list_first_entry(&splice, struct btrfs_ordered_extent,\r\nroot_extent_list);\r\nif (range_end <= ordered->start ||\r\nordered->start + ordered->disk_len <= range_start) {\r\nlist_move_tail(&ordered->root_extent_list, &skipped);\r\ncond_resched_lock(&root->ordered_extent_lock);\r\ncontinue;\r\n}\r\nlist_move_tail(&ordered->root_extent_list,\r\n&root->ordered_extents);\r\nrefcount_inc(&ordered->refs);\r\nspin_unlock(&root->ordered_extent_lock);\r\nbtrfs_init_work(&ordered->flush_work,\r\nbtrfs_flush_delalloc_helper,\r\nbtrfs_run_ordered_extent_work, NULL, NULL);\r\nlist_add_tail(&ordered->work_list, &works);\r\nbtrfs_queue_work(fs_info->flush_workers, &ordered->flush_work);\r\ncond_resched();\r\nspin_lock(&root->ordered_extent_lock);\r\nif (nr != U64_MAX)\r\nnr--;\r\ncount++;\r\n}\r\nlist_splice_tail(&skipped, &root->ordered_extents);\r\nlist_splice_tail(&splice, &root->ordered_extents);\r\nspin_unlock(&root->ordered_extent_lock);\r\nlist_for_each_entry_safe(ordered, next, &works, work_list) {\r\nlist_del_init(&ordered->work_list);\r\nwait_for_completion(&ordered->completion);\r\nbtrfs_put_ordered_extent(ordered);\r\ncond_resched();\r\n}\r\nmutex_unlock(&root->ordered_extent_mutex);\r\nreturn count;\r\n}\r\nu64 btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,\r\nconst u64 range_start, const u64 range_len)\r\n{\r\nstruct btrfs_root *root;\r\nstruct list_head splice;\r\nu64 total_done = 0;\r\nu64 done;\r\nINIT_LIST_HEAD(&splice);\r\nmutex_lock(&fs_info->ordered_operations_mutex);\r\nspin_lock(&fs_info->ordered_root_lock);\r\nlist_splice_init(&fs_info->ordered_roots, &splice);\r\nwhile (!list_empty(&splice) && nr) {\r\nroot = list_first_entry(&splice, struct btrfs_root,\r\nordered_root);\r\nroot = btrfs_grab_fs_root(root);\r\nBUG_ON(!root);\r\nlist_move_tail(&root->ordered_root,\r\n&fs_info->ordered_roots);\r\nspin_unlock(&fs_info->ordered_root_lock);\r\ndone = btrfs_wait_ordered_extents(root, nr,\r\nrange_start, range_len);\r\nbtrfs_put_fs_root(root);\r\ntotal_done += done;\r\nspin_lock(&fs_info->ordered_root_lock);\r\nif (nr != U64_MAX) {\r\nnr -= done;\r\n}\r\n}\r\nlist_splice_tail(&splice, &fs_info->ordered_roots);\r\nspin_unlock(&fs_info->ordered_root_lock);\r\nmutex_unlock(&fs_info->ordered_operations_mutex);\r\nreturn total_done;\r\n}\r\nvoid btrfs_start_ordered_extent(struct inode *inode,\r\nstruct btrfs_ordered_extent *entry,\r\nint wait)\r\n{\r\nu64 start = entry->file_offset;\r\nu64 end = start + entry->len - 1;\r\ntrace_btrfs_ordered_extent_start(inode, entry);\r\nif (!test_bit(BTRFS_ORDERED_DIRECT, &entry->flags))\r\nfilemap_fdatawrite_range(inode->i_mapping, start, end);\r\nif (wait) {\r\nwait_event(entry->wait, test_bit(BTRFS_ORDERED_COMPLETE,\r\n&entry->flags));\r\n}\r\n}\r\nint btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len)\r\n{\r\nint ret = 0;\r\nint ret_wb = 0;\r\nu64 end;\r\nu64 orig_end;\r\nstruct btrfs_ordered_extent *ordered;\r\nif (start + len < start) {\r\norig_end = INT_LIMIT(loff_t);\r\n} else {\r\norig_end = start + len - 1;\r\nif (orig_end > INT_LIMIT(loff_t))\r\norig_end = INT_LIMIT(loff_t);\r\n}\r\nret = btrfs_fdatawrite_range(inode, start, orig_end);\r\nif (ret)\r\nreturn ret;\r\nret_wb = filemap_fdatawait_range(inode->i_mapping, start, orig_end);\r\nend = orig_end;\r\nwhile (1) {\r\nordered = btrfs_lookup_first_ordered_extent(inode, end);\r\nif (!ordered)\r\nbreak;\r\nif (ordered->file_offset > orig_end) {\r\nbtrfs_put_ordered_extent(ordered);\r\nbreak;\r\n}\r\nif (ordered->file_offset + ordered->len <= start) {\r\nbtrfs_put_ordered_extent(ordered);\r\nbreak;\r\n}\r\nbtrfs_start_ordered_extent(inode, ordered, 1);\r\nend = ordered->file_offset;\r\nif (test_bit(BTRFS_ORDERED_IOERR, &ordered->flags))\r\nret = -EIO;\r\nbtrfs_put_ordered_extent(ordered);\r\nif (ret || end == 0 || end == start)\r\nbreak;\r\nend--;\r\n}\r\nreturn ret_wb ? ret_wb : ret;\r\n}\r\nstruct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct inode *inode,\r\nu64 file_offset)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock_irq(&tree->lock);\r\nnode = tree_search(tree, file_offset);\r\nif (!node)\r\ngoto out;\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (!offset_in_entry(entry, file_offset))\r\nentry = NULL;\r\nif (entry)\r\nrefcount_inc(&entry->refs);\r\nout:\r\nspin_unlock_irq(&tree->lock);\r\nreturn entry;\r\n}\r\nstruct btrfs_ordered_extent *btrfs_lookup_ordered_range(\r\nstruct btrfs_inode *inode, u64 file_offset, u64 len)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\ntree = &inode->ordered_tree;\r\nspin_lock_irq(&tree->lock);\r\nnode = tree_search(tree, file_offset);\r\nif (!node) {\r\nnode = tree_search(tree, file_offset + len);\r\nif (!node)\r\ngoto out;\r\n}\r\nwhile (1) {\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (range_overlaps(entry, file_offset, len))\r\nbreak;\r\nif (entry->file_offset >= file_offset + len) {\r\nentry = NULL;\r\nbreak;\r\n}\r\nentry = NULL;\r\nnode = rb_next(node);\r\nif (!node)\r\nbreak;\r\n}\r\nout:\r\nif (entry)\r\nrefcount_inc(&entry->refs);\r\nspin_unlock_irq(&tree->lock);\r\nreturn entry;\r\n}\r\nbool btrfs_have_ordered_extents_in_range(struct inode *inode,\r\nu64 file_offset,\r\nu64 len)\r\n{\r\nstruct btrfs_ordered_extent *oe;\r\noe = btrfs_lookup_ordered_range(BTRFS_I(inode), file_offset, len);\r\nif (oe) {\r\nbtrfs_put_ordered_extent(oe);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstruct btrfs_ordered_extent *\r\nbtrfs_lookup_first_ordered_extent(struct inode *inode, u64 file_offset)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree;\r\nstruct rb_node *node;\r\nstruct btrfs_ordered_extent *entry = NULL;\r\ntree = &BTRFS_I(inode)->ordered_tree;\r\nspin_lock_irq(&tree->lock);\r\nnode = tree_search(tree, file_offset);\r\nif (!node)\r\ngoto out;\r\nentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nrefcount_inc(&entry->refs);\r\nout:\r\nspin_unlock_irq(&tree->lock);\r\nreturn entry;\r\n}\r\nint btrfs_ordered_update_i_size(struct inode *inode, u64 offset,\r\nstruct btrfs_ordered_extent *ordered)\r\n{\r\nstruct btrfs_ordered_inode_tree *tree = &BTRFS_I(inode)->ordered_tree;\r\nu64 disk_i_size;\r\nu64 new_i_size;\r\nu64 i_size = i_size_read(inode);\r\nstruct rb_node *node;\r\nstruct rb_node *prev = NULL;\r\nstruct btrfs_ordered_extent *test;\r\nint ret = 1;\r\nu64 orig_offset = offset;\r\nspin_lock_irq(&tree->lock);\r\nif (ordered) {\r\noffset = entry_end(ordered);\r\nif (test_bit(BTRFS_ORDERED_TRUNCATED, &ordered->flags))\r\noffset = min(offset,\r\nordered->file_offset +\r\nordered->truncated_len);\r\n} else {\r\noffset = ALIGN(offset, btrfs_inode_sectorsize(inode));\r\n}\r\ndisk_i_size = BTRFS_I(inode)->disk_i_size;\r\nif (!ordered && disk_i_size > i_size) {\r\nBTRFS_I(inode)->disk_i_size = orig_offset;\r\nret = 0;\r\ngoto out;\r\n}\r\nif (disk_i_size == i_size)\r\ngoto out;\r\nif (offset <= disk_i_size &&\r\n(!ordered || ordered->outstanding_isize <= disk_i_size))\r\ngoto out;\r\nif (ordered) {\r\nnode = rb_prev(&ordered->rb_node);\r\n} else {\r\nprev = tree_search(tree, offset);\r\nif (prev) {\r\ntest = rb_entry(prev, struct btrfs_ordered_extent,\r\nrb_node);\r\nBUG_ON(offset_in_entry(test, offset));\r\n}\r\nnode = prev;\r\n}\r\nfor (; node; node = rb_prev(node)) {\r\ntest = rb_entry(node, struct btrfs_ordered_extent, rb_node);\r\nif (test_bit(BTRFS_ORDERED_UPDATED_ISIZE, &test->flags))\r\ncontinue;\r\nif (entry_end(test) <= disk_i_size)\r\nbreak;\r\nif (test->file_offset >= i_size)\r\nbreak;\r\nif (test->outstanding_isize < offset)\r\ntest->outstanding_isize = offset;\r\nif (ordered &&\r\nordered->outstanding_isize > test->outstanding_isize)\r\ntest->outstanding_isize = ordered->outstanding_isize;\r\ngoto out;\r\n}\r\nnew_i_size = min_t(u64, offset, i_size);\r\nif (ordered && ordered->outstanding_isize > new_i_size)\r\nnew_i_size = min_t(u64, ordered->outstanding_isize, i_size);\r\nBTRFS_I(inode)->disk_i_size = new_i_size;\r\nret = 0;\r\nout:\r\nif (ordered)\r\nset_bit(BTRFS_ORDERED_UPDATED_ISIZE, &ordered->flags);\r\nspin_unlock_irq(&tree->lock);\r\nreturn ret;\r\n}\r\nint btrfs_find_ordered_sum(struct inode *inode, u64 offset, u64 disk_bytenr,\r\nu32 *sum, int len)\r\n{\r\nstruct btrfs_ordered_sum *ordered_sum;\r\nstruct btrfs_ordered_extent *ordered;\r\nstruct btrfs_ordered_inode_tree *tree = &BTRFS_I(inode)->ordered_tree;\r\nunsigned long num_sectors;\r\nunsigned long i;\r\nu32 sectorsize = btrfs_inode_sectorsize(inode);\r\nint index = 0;\r\nordered = btrfs_lookup_ordered_extent(inode, offset);\r\nif (!ordered)\r\nreturn 0;\r\nspin_lock_irq(&tree->lock);\r\nlist_for_each_entry_reverse(ordered_sum, &ordered->list, list) {\r\nif (disk_bytenr >= ordered_sum->bytenr &&\r\ndisk_bytenr < ordered_sum->bytenr + ordered_sum->len) {\r\ni = (disk_bytenr - ordered_sum->bytenr) >>\r\ninode->i_sb->s_blocksize_bits;\r\nnum_sectors = ordered_sum->len >>\r\ninode->i_sb->s_blocksize_bits;\r\nnum_sectors = min_t(int, len - index, num_sectors - i);\r\nmemcpy(sum + index, ordered_sum->sums + i,\r\nnum_sectors);\r\nindex += (int)num_sectors;\r\nif (index == len)\r\ngoto out;\r\ndisk_bytenr += num_sectors * sectorsize;\r\n}\r\n}\r\nout:\r\nspin_unlock_irq(&tree->lock);\r\nbtrfs_put_ordered_extent(ordered);\r\nreturn index;\r\n}\r\nint __init ordered_data_init(void)\r\n{\r\nbtrfs_ordered_extent_cache = kmem_cache_create("btrfs_ordered_extent",\r\nsizeof(struct btrfs_ordered_extent), 0,\r\nSLAB_MEM_SPREAD,\r\nNULL);\r\nif (!btrfs_ordered_extent_cache)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid ordered_data_exit(void)\r\n{\r\nkmem_cache_destroy(btrfs_ordered_extent_cache);\r\n}
