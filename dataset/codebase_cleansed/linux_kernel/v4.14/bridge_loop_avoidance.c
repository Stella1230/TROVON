static inline u32 batadv_choose_claim(const void *data, u32 size)\r\n{\r\nstruct batadv_bla_claim *claim = (struct batadv_bla_claim *)data;\r\nu32 hash = 0;\r\nhash = jhash(&claim->addr, sizeof(claim->addr), hash);\r\nhash = jhash(&claim->vid, sizeof(claim->vid), hash);\r\nreturn hash % size;\r\n}\r\nstatic inline u32 batadv_choose_backbone_gw(const void *data, u32 size)\r\n{\r\nconst struct batadv_bla_claim *claim = (struct batadv_bla_claim *)data;\r\nu32 hash = 0;\r\nhash = jhash(&claim->addr, sizeof(claim->addr), hash);\r\nhash = jhash(&claim->vid, sizeof(claim->vid), hash);\r\nreturn hash % size;\r\n}\r\nstatic bool batadv_compare_backbone_gw(const struct hlist_node *node,\r\nconst void *data2)\r\n{\r\nconst void *data1 = container_of(node, struct batadv_bla_backbone_gw,\r\nhash_entry);\r\nconst struct batadv_bla_backbone_gw *gw1 = data1;\r\nconst struct batadv_bla_backbone_gw *gw2 = data2;\r\nif (!batadv_compare_eth(gw1->orig, gw2->orig))\r\nreturn false;\r\nif (gw1->vid != gw2->vid)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic bool batadv_compare_claim(const struct hlist_node *node,\r\nconst void *data2)\r\n{\r\nconst void *data1 = container_of(node, struct batadv_bla_claim,\r\nhash_entry);\r\nconst struct batadv_bla_claim *cl1 = data1;\r\nconst struct batadv_bla_claim *cl2 = data2;\r\nif (!batadv_compare_eth(cl1->addr, cl2->addr))\r\nreturn false;\r\nif (cl1->vid != cl2->vid)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void batadv_backbone_gw_release(struct kref *ref)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nbackbone_gw = container_of(ref, struct batadv_bla_backbone_gw,\r\nrefcount);\r\nkfree_rcu(backbone_gw, rcu);\r\n}\r\nstatic void batadv_backbone_gw_put(struct batadv_bla_backbone_gw *backbone_gw)\r\n{\r\nkref_put(&backbone_gw->refcount, batadv_backbone_gw_release);\r\n}\r\nstatic void batadv_claim_release(struct kref *ref)\r\n{\r\nstruct batadv_bla_claim *claim;\r\nstruct batadv_bla_backbone_gw *old_backbone_gw;\r\nclaim = container_of(ref, struct batadv_bla_claim, refcount);\r\nspin_lock_bh(&claim->backbone_lock);\r\nold_backbone_gw = claim->backbone_gw;\r\nclaim->backbone_gw = NULL;\r\nspin_unlock_bh(&claim->backbone_lock);\r\nspin_lock_bh(&old_backbone_gw->crc_lock);\r\nold_backbone_gw->crc ^= crc16(0, claim->addr, ETH_ALEN);\r\nspin_unlock_bh(&old_backbone_gw->crc_lock);\r\nbatadv_backbone_gw_put(old_backbone_gw);\r\nkfree_rcu(claim, rcu);\r\n}\r\nstatic void batadv_claim_put(struct batadv_bla_claim *claim)\r\n{\r\nkref_put(&claim->refcount, batadv_claim_release);\r\n}\r\nstatic struct batadv_bla_claim *\r\nbatadv_claim_hash_find(struct batadv_priv *bat_priv,\r\nstruct batadv_bla_claim *data)\r\n{\r\nstruct batadv_hashtable *hash = bat_priv->bla.claim_hash;\r\nstruct hlist_head *head;\r\nstruct batadv_bla_claim *claim;\r\nstruct batadv_bla_claim *claim_tmp = NULL;\r\nint index;\r\nif (!hash)\r\nreturn NULL;\r\nindex = batadv_choose_claim(data, hash->size);\r\nhead = &hash->table[index];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(claim, head, hash_entry) {\r\nif (!batadv_compare_claim(&claim->hash_entry, data))\r\ncontinue;\r\nif (!kref_get_unless_zero(&claim->refcount))\r\ncontinue;\r\nclaim_tmp = claim;\r\nbreak;\r\n}\r\nrcu_read_unlock();\r\nreturn claim_tmp;\r\n}\r\nstatic struct batadv_bla_backbone_gw *\r\nbatadv_backbone_hash_find(struct batadv_priv *bat_priv, u8 *addr,\r\nunsigned short vid)\r\n{\r\nstruct batadv_hashtable *hash = bat_priv->bla.backbone_hash;\r\nstruct hlist_head *head;\r\nstruct batadv_bla_backbone_gw search_entry, *backbone_gw;\r\nstruct batadv_bla_backbone_gw *backbone_gw_tmp = NULL;\r\nint index;\r\nif (!hash)\r\nreturn NULL;\r\nether_addr_copy(search_entry.orig, addr);\r\nsearch_entry.vid = vid;\r\nindex = batadv_choose_backbone_gw(&search_entry, hash->size);\r\nhead = &hash->table[index];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(backbone_gw, head, hash_entry) {\r\nif (!batadv_compare_backbone_gw(&backbone_gw->hash_entry,\r\n&search_entry))\r\ncontinue;\r\nif (!kref_get_unless_zero(&backbone_gw->refcount))\r\ncontinue;\r\nbackbone_gw_tmp = backbone_gw;\r\nbreak;\r\n}\r\nrcu_read_unlock();\r\nreturn backbone_gw_tmp;\r\n}\r\nstatic void\r\nbatadv_bla_del_backbone_claims(struct batadv_bla_backbone_gw *backbone_gw)\r\n{\r\nstruct batadv_hashtable *hash;\r\nstruct hlist_node *node_tmp;\r\nstruct hlist_head *head;\r\nstruct batadv_bla_claim *claim;\r\nint i;\r\nspinlock_t *list_lock;\r\nhash = backbone_gw->bat_priv->bla.claim_hash;\r\nif (!hash)\r\nreturn;\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nlist_lock = &hash->list_locks[i];\r\nspin_lock_bh(list_lock);\r\nhlist_for_each_entry_safe(claim, node_tmp,\r\nhead, hash_entry) {\r\nif (claim->backbone_gw != backbone_gw)\r\ncontinue;\r\nbatadv_claim_put(claim);\r\nhlist_del_rcu(&claim->hash_entry);\r\n}\r\nspin_unlock_bh(list_lock);\r\n}\r\nspin_lock_bh(&backbone_gw->crc_lock);\r\nbackbone_gw->crc = BATADV_BLA_CRC_INIT;\r\nspin_unlock_bh(&backbone_gw->crc_lock);\r\n}\r\nstatic void batadv_bla_send_claim(struct batadv_priv *bat_priv, u8 *mac,\r\nunsigned short vid, int claimtype)\r\n{\r\nstruct sk_buff *skb;\r\nstruct ethhdr *ethhdr;\r\nstruct batadv_hard_iface *primary_if;\r\nstruct net_device *soft_iface;\r\nu8 *hw_src;\r\nstruct batadv_bla_claim_dst local_claim_dest;\r\n__be32 zeroip = 0;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if)\r\nreturn;\r\nmemcpy(&local_claim_dest, &bat_priv->bla.claim_dest,\r\nsizeof(local_claim_dest));\r\nlocal_claim_dest.type = claimtype;\r\nsoft_iface = primary_if->soft_iface;\r\nskb = arp_create(ARPOP_REPLY, ETH_P_ARP,\r\nzeroip,\r\nprimary_if->soft_iface,\r\nzeroip,\r\nNULL,\r\nprimary_if->net_dev->dev_addr,\r\n(u8 *)&local_claim_dest);\r\nif (!skb)\r\ngoto out;\r\nethhdr = (struct ethhdr *)skb->data;\r\nhw_src = (u8 *)ethhdr + ETH_HLEN + sizeof(struct arphdr);\r\nswitch (claimtype) {\r\ncase BATADV_CLAIM_TYPE_CLAIM:\r\nether_addr_copy(ethhdr->h_source, mac);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): CLAIM %pM on vid %d\n", __func__, mac,\r\nbatadv_print_vid(vid));\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_UNCLAIM:\r\nether_addr_copy(hw_src, mac);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): UNCLAIM %pM on vid %d\n", __func__, mac,\r\nbatadv_print_vid(vid));\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_ANNOUNCE:\r\nether_addr_copy(hw_src, mac);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): ANNOUNCE of %pM on vid %d\n", __func__,\r\nethhdr->h_source, batadv_print_vid(vid));\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_REQUEST:\r\nether_addr_copy(hw_src, mac);\r\nether_addr_copy(ethhdr->h_dest, mac);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): REQUEST of %pM to %pM on vid %d\n", __func__,\r\nethhdr->h_source, ethhdr->h_dest,\r\nbatadv_print_vid(vid));\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_LOOPDETECT:\r\nether_addr_copy(ethhdr->h_source, mac);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): LOOPDETECT of %pM to %pM on vid %d\n",\r\n__func__, ethhdr->h_source, ethhdr->h_dest,\r\nbatadv_print_vid(vid));\r\nbreak;\r\n}\r\nif (vid & BATADV_VLAN_HAS_TAG) {\r\nskb = vlan_insert_tag(skb, htons(ETH_P_8021Q),\r\nvid & VLAN_VID_MASK);\r\nif (!skb)\r\ngoto out;\r\n}\r\nskb_reset_mac_header(skb);\r\nskb->protocol = eth_type_trans(skb, soft_iface);\r\nbatadv_inc_counter(bat_priv, BATADV_CNT_RX);\r\nbatadv_add_counter(bat_priv, BATADV_CNT_RX_BYTES,\r\nskb->len + ETH_HLEN);\r\nnetif_rx(skb);\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\n}\r\nstatic void batadv_bla_loopdetect_report(struct work_struct *work)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct batadv_priv *bat_priv;\r\nchar vid_str[6] = { '\0' };\r\nbackbone_gw = container_of(work, struct batadv_bla_backbone_gw,\r\nreport_work);\r\nbat_priv = backbone_gw->bat_priv;\r\nbatadv_info(bat_priv->soft_iface,\r\n"Possible loop on VLAN %d detected which can't be handled by BLA - please check your network setup!\n",\r\nbatadv_print_vid(backbone_gw->vid));\r\nsnprintf(vid_str, sizeof(vid_str), "%d",\r\nbatadv_print_vid(backbone_gw->vid));\r\nvid_str[sizeof(vid_str) - 1] = 0;\r\nbatadv_throw_uevent(bat_priv, BATADV_UEV_BLA, BATADV_UEV_LOOPDETECT,\r\nvid_str);\r\nbatadv_backbone_gw_put(backbone_gw);\r\n}\r\nstatic struct batadv_bla_backbone_gw *\r\nbatadv_bla_get_backbone_gw(struct batadv_priv *bat_priv, u8 *orig,\r\nunsigned short vid, bool own_backbone)\r\n{\r\nstruct batadv_bla_backbone_gw *entry;\r\nstruct batadv_orig_node *orig_node;\r\nint hash_added;\r\nentry = batadv_backbone_hash_find(bat_priv, orig, vid);\r\nif (entry)\r\nreturn entry;\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): not found (%pM, %d), creating new entry\n", __func__,\r\norig, batadv_print_vid(vid));\r\nentry = kzalloc(sizeof(*entry), GFP_ATOMIC);\r\nif (!entry)\r\nreturn NULL;\r\nentry->vid = vid;\r\nentry->lasttime = jiffies;\r\nentry->crc = BATADV_BLA_CRC_INIT;\r\nentry->bat_priv = bat_priv;\r\nspin_lock_init(&entry->crc_lock);\r\natomic_set(&entry->request_sent, 0);\r\natomic_set(&entry->wait_periods, 0);\r\nether_addr_copy(entry->orig, orig);\r\nINIT_WORK(&entry->report_work, batadv_bla_loopdetect_report);\r\nkref_init(&entry->refcount);\r\nkref_get(&entry->refcount);\r\nhash_added = batadv_hash_add(bat_priv->bla.backbone_hash,\r\nbatadv_compare_backbone_gw,\r\nbatadv_choose_backbone_gw, entry,\r\n&entry->hash_entry);\r\nif (unlikely(hash_added != 0)) {\r\nkfree(entry);\r\nreturn NULL;\r\n}\r\norig_node = batadv_orig_hash_find(bat_priv, orig);\r\nif (orig_node) {\r\nbatadv_tt_global_del_orig(bat_priv, orig_node, vid,\r\n"became a backbone gateway");\r\nbatadv_orig_node_put(orig_node);\r\n}\r\nif (own_backbone) {\r\nbatadv_bla_send_announce(bat_priv, entry);\r\natomic_inc(&entry->request_sent);\r\natomic_set(&entry->wait_periods, BATADV_BLA_WAIT_PERIODS);\r\natomic_inc(&bat_priv->bla.num_requests);\r\n}\r\nreturn entry;\r\n}\r\nstatic void\r\nbatadv_bla_update_own_backbone_gw(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nunsigned short vid)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nbackbone_gw = batadv_bla_get_backbone_gw(bat_priv,\r\nprimary_if->net_dev->dev_addr,\r\nvid, true);\r\nif (unlikely(!backbone_gw))\r\nreturn;\r\nbackbone_gw->lasttime = jiffies;\r\nbatadv_backbone_gw_put(backbone_gw);\r\n}\r\nstatic void batadv_bla_answer_request(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nunsigned short vid)\r\n{\r\nstruct hlist_head *head;\r\nstruct batadv_hashtable *hash;\r\nstruct batadv_bla_claim *claim;\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nint i;\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): received a claim request, send all of our own claims again\n",\r\n__func__);\r\nbackbone_gw = batadv_backbone_hash_find(bat_priv,\r\nprimary_if->net_dev->dev_addr,\r\nvid);\r\nif (!backbone_gw)\r\nreturn;\r\nhash = bat_priv->bla.claim_hash;\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(claim, head, hash_entry) {\r\nif (claim->backbone_gw != backbone_gw)\r\ncontinue;\r\nbatadv_bla_send_claim(bat_priv, claim->addr, claim->vid,\r\nBATADV_CLAIM_TYPE_CLAIM);\r\n}\r\nrcu_read_unlock();\r\n}\r\nbatadv_bla_send_announce(bat_priv, backbone_gw);\r\nbatadv_backbone_gw_put(backbone_gw);\r\n}\r\nstatic void batadv_bla_send_request(struct batadv_bla_backbone_gw *backbone_gw)\r\n{\r\nbatadv_bla_del_backbone_claims(backbone_gw);\r\nbatadv_dbg(BATADV_DBG_BLA, backbone_gw->bat_priv,\r\n"Sending REQUEST to %pM\n", backbone_gw->orig);\r\nbatadv_bla_send_claim(backbone_gw->bat_priv, backbone_gw->orig,\r\nbackbone_gw->vid, BATADV_CLAIM_TYPE_REQUEST);\r\nif (!atomic_read(&backbone_gw->request_sent)) {\r\natomic_inc(&backbone_gw->bat_priv->bla.num_requests);\r\natomic_set(&backbone_gw->request_sent, 1);\r\n}\r\n}\r\nstatic void batadv_bla_send_announce(struct batadv_priv *bat_priv,\r\nstruct batadv_bla_backbone_gw *backbone_gw)\r\n{\r\nu8 mac[ETH_ALEN];\r\n__be16 crc;\r\nmemcpy(mac, batadv_announce_mac, 4);\r\nspin_lock_bh(&backbone_gw->crc_lock);\r\ncrc = htons(backbone_gw->crc);\r\nspin_unlock_bh(&backbone_gw->crc_lock);\r\nmemcpy(&mac[4], &crc, 2);\r\nbatadv_bla_send_claim(bat_priv, mac, backbone_gw->vid,\r\nBATADV_CLAIM_TYPE_ANNOUNCE);\r\n}\r\nstatic void batadv_bla_add_claim(struct batadv_priv *bat_priv,\r\nconst u8 *mac, const unsigned short vid,\r\nstruct batadv_bla_backbone_gw *backbone_gw)\r\n{\r\nstruct batadv_bla_backbone_gw *old_backbone_gw;\r\nstruct batadv_bla_claim *claim;\r\nstruct batadv_bla_claim search_claim;\r\nbool remove_crc = false;\r\nint hash_added;\r\nether_addr_copy(search_claim.addr, mac);\r\nsearch_claim.vid = vid;\r\nclaim = batadv_claim_hash_find(bat_priv, &search_claim);\r\nif (!claim) {\r\nclaim = kzalloc(sizeof(*claim), GFP_ATOMIC);\r\nif (!claim)\r\nreturn;\r\nether_addr_copy(claim->addr, mac);\r\nspin_lock_init(&claim->backbone_lock);\r\nclaim->vid = vid;\r\nclaim->lasttime = jiffies;\r\nkref_get(&backbone_gw->refcount);\r\nclaim->backbone_gw = backbone_gw;\r\nkref_init(&claim->refcount);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): adding new entry %pM, vid %d to hash ...\n",\r\n__func__, mac, batadv_print_vid(vid));\r\nkref_get(&claim->refcount);\r\nhash_added = batadv_hash_add(bat_priv->bla.claim_hash,\r\nbatadv_compare_claim,\r\nbatadv_choose_claim, claim,\r\n&claim->hash_entry);\r\nif (unlikely(hash_added != 0)) {\r\nkfree(claim);\r\nreturn;\r\n}\r\n} else {\r\nclaim->lasttime = jiffies;\r\nif (claim->backbone_gw == backbone_gw)\r\ngoto claim_free_ref;\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): changing ownership for %pM, vid %d to gw %pM\n",\r\n__func__, mac, batadv_print_vid(vid),\r\nbackbone_gw->orig);\r\nremove_crc = true;\r\n}\r\nspin_lock_bh(&claim->backbone_lock);\r\nold_backbone_gw = claim->backbone_gw;\r\nkref_get(&backbone_gw->refcount);\r\nclaim->backbone_gw = backbone_gw;\r\nspin_unlock_bh(&claim->backbone_lock);\r\nif (remove_crc) {\r\nspin_lock_bh(&old_backbone_gw->crc_lock);\r\nold_backbone_gw->crc ^= crc16(0, claim->addr, ETH_ALEN);\r\nspin_unlock_bh(&old_backbone_gw->crc_lock);\r\n}\r\nbatadv_backbone_gw_put(old_backbone_gw);\r\nspin_lock_bh(&backbone_gw->crc_lock);\r\nbackbone_gw->crc ^= crc16(0, claim->addr, ETH_ALEN);\r\nspin_unlock_bh(&backbone_gw->crc_lock);\r\nbackbone_gw->lasttime = jiffies;\r\nclaim_free_ref:\r\nbatadv_claim_put(claim);\r\n}\r\nstatic struct batadv_bla_backbone_gw *\r\nbatadv_bla_claim_get_backbone_gw(struct batadv_bla_claim *claim)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nspin_lock_bh(&claim->backbone_lock);\r\nbackbone_gw = claim->backbone_gw;\r\nkref_get(&backbone_gw->refcount);\r\nspin_unlock_bh(&claim->backbone_lock);\r\nreturn backbone_gw;\r\n}\r\nstatic void batadv_bla_del_claim(struct batadv_priv *bat_priv,\r\nconst u8 *mac, const unsigned short vid)\r\n{\r\nstruct batadv_bla_claim search_claim, *claim;\r\nether_addr_copy(search_claim.addr, mac);\r\nsearch_claim.vid = vid;\r\nclaim = batadv_claim_hash_find(bat_priv, &search_claim);\r\nif (!claim)\r\nreturn;\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv, "%s(): %pM, vid %d\n", __func__,\r\nmac, batadv_print_vid(vid));\r\nbatadv_hash_remove(bat_priv->bla.claim_hash, batadv_compare_claim,\r\nbatadv_choose_claim, claim);\r\nbatadv_claim_put(claim);\r\nbatadv_claim_put(claim);\r\n}\r\nstatic bool batadv_handle_announce(struct batadv_priv *bat_priv, u8 *an_addr,\r\nu8 *backbone_addr, unsigned short vid)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nu16 backbone_crc, crc;\r\nif (memcmp(an_addr, batadv_announce_mac, 4) != 0)\r\nreturn false;\r\nbackbone_gw = batadv_bla_get_backbone_gw(bat_priv, backbone_addr, vid,\r\nfalse);\r\nif (unlikely(!backbone_gw))\r\nreturn true;\r\nbackbone_gw->lasttime = jiffies;\r\ncrc = ntohs(*((__be16 *)(&an_addr[4])));\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): ANNOUNCE vid %d (sent by %pM)... CRC = %#.4x\n",\r\n__func__, batadv_print_vid(vid), backbone_gw->orig, crc);\r\nspin_lock_bh(&backbone_gw->crc_lock);\r\nbackbone_crc = backbone_gw->crc;\r\nspin_unlock_bh(&backbone_gw->crc_lock);\r\nif (backbone_crc != crc) {\r\nbatadv_dbg(BATADV_DBG_BLA, backbone_gw->bat_priv,\r\n"%s(): CRC FAILED for %pM/%d (my = %#.4x, sent = %#.4x)\n",\r\n__func__, backbone_gw->orig,\r\nbatadv_print_vid(backbone_gw->vid),\r\nbackbone_crc, crc);\r\nbatadv_bla_send_request(backbone_gw);\r\n} else {\r\nif (atomic_read(&backbone_gw->request_sent)) {\r\natomic_dec(&backbone_gw->bat_priv->bla.num_requests);\r\natomic_set(&backbone_gw->request_sent, 0);\r\n}\r\n}\r\nbatadv_backbone_gw_put(backbone_gw);\r\nreturn true;\r\n}\r\nstatic bool batadv_handle_request(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nu8 *backbone_addr, struct ethhdr *ethhdr,\r\nunsigned short vid)\r\n{\r\nif (!batadv_compare_eth(backbone_addr, ethhdr->h_dest))\r\nreturn false;\r\nif (!batadv_compare_eth(ethhdr->h_dest, primary_if->net_dev->dev_addr))\r\nreturn true;\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): REQUEST vid %d (sent by %pM)...\n",\r\n__func__, batadv_print_vid(vid), ethhdr->h_source);\r\nbatadv_bla_answer_request(bat_priv, primary_if, vid);\r\nreturn true;\r\n}\r\nstatic bool batadv_handle_unclaim(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nu8 *backbone_addr, u8 *claim_addr,\r\nunsigned short vid)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nif (primary_if && batadv_compare_eth(backbone_addr,\r\nprimary_if->net_dev->dev_addr))\r\nbatadv_bla_send_claim(bat_priv, claim_addr, vid,\r\nBATADV_CLAIM_TYPE_UNCLAIM);\r\nbackbone_gw = batadv_backbone_hash_find(bat_priv, backbone_addr, vid);\r\nif (!backbone_gw)\r\nreturn true;\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): UNCLAIM %pM on vid %d (sent by %pM)...\n", __func__,\r\nclaim_addr, batadv_print_vid(vid), backbone_gw->orig);\r\nbatadv_bla_del_claim(bat_priv, claim_addr, vid);\r\nbatadv_backbone_gw_put(backbone_gw);\r\nreturn true;\r\n}\r\nstatic bool batadv_handle_claim(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nu8 *backbone_addr, u8 *claim_addr,\r\nunsigned short vid)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nbackbone_gw = batadv_bla_get_backbone_gw(bat_priv, backbone_addr, vid,\r\nfalse);\r\nif (unlikely(!backbone_gw))\r\nreturn true;\r\nbatadv_bla_add_claim(bat_priv, claim_addr, vid, backbone_gw);\r\nif (batadv_compare_eth(backbone_addr, primary_if->net_dev->dev_addr))\r\nbatadv_bla_send_claim(bat_priv, claim_addr, vid,\r\nBATADV_CLAIM_TYPE_CLAIM);\r\nbatadv_backbone_gw_put(backbone_gw);\r\nreturn true;\r\n}\r\nstatic int batadv_check_claim_group(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nu8 *hw_src, u8 *hw_dst,\r\nstruct ethhdr *ethhdr)\r\n{\r\nu8 *backbone_addr;\r\nstruct batadv_orig_node *orig_node;\r\nstruct batadv_bla_claim_dst *bla_dst, *bla_dst_own;\r\nbla_dst = (struct batadv_bla_claim_dst *)hw_dst;\r\nbla_dst_own = &bat_priv->bla.claim_dest;\r\nswitch (bla_dst->type) {\r\ncase BATADV_CLAIM_TYPE_CLAIM:\r\nbackbone_addr = hw_src;\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_REQUEST:\r\ncase BATADV_CLAIM_TYPE_ANNOUNCE:\r\ncase BATADV_CLAIM_TYPE_UNCLAIM:\r\nbackbone_addr = ethhdr->h_source;\r\nbreak;\r\ndefault:\r\nreturn 0;\r\n}\r\nif (batadv_compare_eth(backbone_addr, primary_if->net_dev->dev_addr))\r\nreturn 0;\r\nif (bla_dst->group == bla_dst_own->group)\r\nreturn 2;\r\norig_node = batadv_orig_hash_find(bat_priv, backbone_addr);\r\nif (!orig_node)\r\nreturn 1;\r\nif (ntohs(bla_dst->group) > ntohs(bla_dst_own->group)) {\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"taking other backbones claim group: %#.4x\n",\r\nntohs(bla_dst->group));\r\nbla_dst_own->group = bla_dst->group;\r\n}\r\nbatadv_orig_node_put(orig_node);\r\nreturn 2;\r\n}\r\nstatic bool batadv_bla_process_claim(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nstruct sk_buff *skb)\r\n{\r\nstruct batadv_bla_claim_dst *bla_dst, *bla_dst_own;\r\nu8 *hw_src, *hw_dst;\r\nstruct vlan_hdr *vhdr, vhdr_buf;\r\nstruct ethhdr *ethhdr;\r\nstruct arphdr *arphdr;\r\nunsigned short vid;\r\nint vlan_depth = 0;\r\n__be16 proto;\r\nint headlen;\r\nint ret;\r\nvid = batadv_get_vid(skb, 0);\r\nethhdr = eth_hdr(skb);\r\nproto = ethhdr->h_proto;\r\nheadlen = ETH_HLEN;\r\nif (vid & BATADV_VLAN_HAS_TAG) {\r\ndo {\r\nvhdr = skb_header_pointer(skb, headlen, VLAN_HLEN,\r\n&vhdr_buf);\r\nif (!vhdr)\r\nreturn false;\r\nproto = vhdr->h_vlan_encapsulated_proto;\r\nheadlen += VLAN_HLEN;\r\nvlan_depth++;\r\n} while (proto == htons(ETH_P_8021Q));\r\n}\r\nif (proto != htons(ETH_P_ARP))\r\nreturn false;\r\nif (unlikely(!pskb_may_pull(skb, headlen + arp_hdr_len(skb->dev))))\r\nreturn false;\r\nethhdr = eth_hdr(skb);\r\narphdr = (struct arphdr *)((u8 *)ethhdr + headlen);\r\nif (arphdr->ar_hrd != htons(ARPHRD_ETHER))\r\nreturn false;\r\nif (arphdr->ar_pro != htons(ETH_P_IP))\r\nreturn false;\r\nif (arphdr->ar_hln != ETH_ALEN)\r\nreturn false;\r\nif (arphdr->ar_pln != 4)\r\nreturn false;\r\nhw_src = (u8 *)arphdr + sizeof(struct arphdr);\r\nhw_dst = hw_src + ETH_ALEN + 4;\r\nbla_dst = (struct batadv_bla_claim_dst *)hw_dst;\r\nbla_dst_own = &bat_priv->bla.claim_dest;\r\nif (memcmp(bla_dst->magic, bla_dst_own->magic,\r\nsizeof(bla_dst->magic)) != 0)\r\nreturn false;\r\nif (vlan_depth > 1)\r\nreturn true;\r\nif (bla_dst->type == BATADV_CLAIM_TYPE_LOOPDETECT)\r\nreturn false;\r\nret = batadv_check_claim_group(bat_priv, primary_if, hw_src, hw_dst,\r\nethhdr);\r\nif (ret == 1)\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): received a claim frame from another group. From: %pM on vid %d ...(hw_src %pM, hw_dst %pM)\n",\r\n__func__, ethhdr->h_source, batadv_print_vid(vid),\r\nhw_src, hw_dst);\r\nif (ret < 2)\r\nreturn !!ret;\r\nbatadv_bla_update_own_backbone_gw(bat_priv, primary_if, vid);\r\nswitch (bla_dst->type) {\r\ncase BATADV_CLAIM_TYPE_CLAIM:\r\nif (batadv_handle_claim(bat_priv, primary_if, hw_src,\r\nethhdr->h_source, vid))\r\nreturn true;\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_UNCLAIM:\r\nif (batadv_handle_unclaim(bat_priv, primary_if,\r\nethhdr->h_source, hw_src, vid))\r\nreturn true;\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_ANNOUNCE:\r\nif (batadv_handle_announce(bat_priv, hw_src, ethhdr->h_source,\r\nvid))\r\nreturn true;\r\nbreak;\r\ncase BATADV_CLAIM_TYPE_REQUEST:\r\nif (batadv_handle_request(bat_priv, primary_if, hw_src, ethhdr,\r\nvid))\r\nreturn true;\r\nbreak;\r\n}\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): ERROR - this looks like a claim frame, but is useless. eth src %pM on vid %d ...(hw_src %pM, hw_dst %pM)\n",\r\n__func__, ethhdr->h_source, batadv_print_vid(vid), hw_src,\r\nhw_dst);\r\nreturn true;\r\n}\r\nstatic void batadv_bla_purge_backbone_gw(struct batadv_priv *bat_priv, int now)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct hlist_node *node_tmp;\r\nstruct hlist_head *head;\r\nstruct batadv_hashtable *hash;\r\nspinlock_t *list_lock;\r\nint i;\r\nhash = bat_priv->bla.backbone_hash;\r\nif (!hash)\r\nreturn;\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nlist_lock = &hash->list_locks[i];\r\nspin_lock_bh(list_lock);\r\nhlist_for_each_entry_safe(backbone_gw, node_tmp,\r\nhead, hash_entry) {\r\nif (now)\r\ngoto purge_now;\r\nif (!batadv_has_timed_out(backbone_gw->lasttime,\r\nBATADV_BLA_BACKBONE_TIMEOUT))\r\ncontinue;\r\nbatadv_dbg(BATADV_DBG_BLA, backbone_gw->bat_priv,\r\n"%s(): backbone gw %pM timed out\n",\r\n__func__, backbone_gw->orig);\r\npurge_now:\r\nif (atomic_read(&backbone_gw->request_sent))\r\natomic_dec(&bat_priv->bla.num_requests);\r\nbatadv_bla_del_backbone_claims(backbone_gw);\r\nhlist_del_rcu(&backbone_gw->hash_entry);\r\nbatadv_backbone_gw_put(backbone_gw);\r\n}\r\nspin_unlock_bh(list_lock);\r\n}\r\n}\r\nstatic void batadv_bla_purge_claims(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nint now)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct batadv_bla_claim *claim;\r\nstruct hlist_head *head;\r\nstruct batadv_hashtable *hash;\r\nint i;\r\nhash = bat_priv->bla.claim_hash;\r\nif (!hash)\r\nreturn;\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(claim, head, hash_entry) {\r\nbackbone_gw = batadv_bla_claim_get_backbone_gw(claim);\r\nif (now)\r\ngoto purge_now;\r\nif (!batadv_compare_eth(backbone_gw->orig,\r\nprimary_if->net_dev->dev_addr))\r\ngoto skip;\r\nif (!batadv_has_timed_out(claim->lasttime,\r\nBATADV_BLA_CLAIM_TIMEOUT))\r\ngoto skip;\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): timed out.\n", __func__);\r\npurge_now:\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): %pM, vid %d\n", __func__,\r\nclaim->addr, claim->vid);\r\nbatadv_handle_unclaim(bat_priv, primary_if,\r\nbackbone_gw->orig,\r\nclaim->addr, claim->vid);\r\nskip:\r\nbatadv_backbone_gw_put(backbone_gw);\r\n}\r\nrcu_read_unlock();\r\n}\r\n}\r\nvoid batadv_bla_update_orig_address(struct batadv_priv *bat_priv,\r\nstruct batadv_hard_iface *primary_if,\r\nstruct batadv_hard_iface *oldif)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct hlist_head *head;\r\nstruct batadv_hashtable *hash;\r\n__be16 group;\r\nint i;\r\ngroup = htons(crc16(0, primary_if->net_dev->dev_addr, ETH_ALEN));\r\nbat_priv->bla.claim_dest.group = group;\r\nif (!atomic_read(&bat_priv->bridge_loop_avoidance))\r\noldif = NULL;\r\nif (!oldif) {\r\nbatadv_bla_purge_claims(bat_priv, NULL, 1);\r\nbatadv_bla_purge_backbone_gw(bat_priv, 1);\r\nreturn;\r\n}\r\nhash = bat_priv->bla.backbone_hash;\r\nif (!hash)\r\nreturn;\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(backbone_gw, head, hash_entry) {\r\nif (!batadv_compare_eth(backbone_gw->orig,\r\noldif->net_dev->dev_addr))\r\ncontinue;\r\nether_addr_copy(backbone_gw->orig,\r\nprimary_if->net_dev->dev_addr);\r\nbatadv_bla_send_announce(bat_priv, backbone_gw);\r\n}\r\nrcu_read_unlock();\r\n}\r\n}\r\nstatic void\r\nbatadv_bla_send_loopdetect(struct batadv_priv *bat_priv,\r\nstruct batadv_bla_backbone_gw *backbone_gw)\r\n{\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv, "Send loopdetect frame for vid %d\n",\r\nbackbone_gw->vid);\r\nbatadv_bla_send_claim(bat_priv, bat_priv->bla.loopdetect_addr,\r\nbackbone_gw->vid, BATADV_CLAIM_TYPE_LOOPDETECT);\r\n}\r\nvoid batadv_bla_status_update(struct net_device *net_dev)\r\n{\r\nstruct batadv_priv *bat_priv = netdev_priv(net_dev);\r\nstruct batadv_hard_iface *primary_if;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if)\r\nreturn;\r\nbatadv_bla_update_orig_address(bat_priv, primary_if, primary_if);\r\nbatadv_hardif_put(primary_if);\r\n}\r\nstatic void batadv_bla_periodic_work(struct work_struct *work)\r\n{\r\nstruct delayed_work *delayed_work;\r\nstruct batadv_priv *bat_priv;\r\nstruct batadv_priv_bla *priv_bla;\r\nstruct hlist_head *head;\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct batadv_hashtable *hash;\r\nstruct batadv_hard_iface *primary_if;\r\nbool send_loopdetect = false;\r\nint i;\r\ndelayed_work = to_delayed_work(work);\r\npriv_bla = container_of(delayed_work, struct batadv_priv_bla, work);\r\nbat_priv = container_of(priv_bla, struct batadv_priv, bla);\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if)\r\ngoto out;\r\nbatadv_bla_purge_claims(bat_priv, primary_if, 0);\r\nbatadv_bla_purge_backbone_gw(bat_priv, 0);\r\nif (!atomic_read(&bat_priv->bridge_loop_avoidance))\r\ngoto out;\r\nif (atomic_dec_and_test(&bat_priv->bla.loopdetect_next)) {\r\nrandom_ether_addr(bat_priv->bla.loopdetect_addr);\r\nbat_priv->bla.loopdetect_addr[0] = 0xba;\r\nbat_priv->bla.loopdetect_addr[1] = 0xbe;\r\nbat_priv->bla.loopdetect_lasttime = jiffies;\r\natomic_set(&bat_priv->bla.loopdetect_next,\r\nBATADV_BLA_LOOPDETECT_PERIODS);\r\nsend_loopdetect = true;\r\n}\r\nhash = bat_priv->bla.backbone_hash;\r\nif (!hash)\r\ngoto out;\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(backbone_gw, head, hash_entry) {\r\nif (!batadv_compare_eth(backbone_gw->orig,\r\nprimary_if->net_dev->dev_addr))\r\ncontinue;\r\nbackbone_gw->lasttime = jiffies;\r\nbatadv_bla_send_announce(bat_priv, backbone_gw);\r\nif (send_loopdetect)\r\nbatadv_bla_send_loopdetect(bat_priv,\r\nbackbone_gw);\r\nif (atomic_read(&backbone_gw->request_sent) == 0)\r\ncontinue;\r\nif (!atomic_dec_and_test(&backbone_gw->wait_periods))\r\ncontinue;\r\natomic_dec(&backbone_gw->bat_priv->bla.num_requests);\r\natomic_set(&backbone_gw->request_sent, 0);\r\n}\r\nrcu_read_unlock();\r\n}\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\nqueue_delayed_work(batadv_event_workqueue, &bat_priv->bla.work,\r\nmsecs_to_jiffies(BATADV_BLA_PERIOD_LENGTH));\r\n}\r\nint batadv_bla_init(struct batadv_priv *bat_priv)\r\n{\r\nint i;\r\nu8 claim_dest[ETH_ALEN] = {0xff, 0x43, 0x05, 0x00, 0x00, 0x00};\r\nstruct batadv_hard_iface *primary_if;\r\nu16 crc;\r\nunsigned long entrytime;\r\nspin_lock_init(&bat_priv->bla.bcast_duplist_lock);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv, "bla hash registering\n");\r\nmemcpy(&bat_priv->bla.claim_dest.magic, claim_dest, 3);\r\nbat_priv->bla.claim_dest.type = 0;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (primary_if) {\r\ncrc = crc16(0, primary_if->net_dev->dev_addr, ETH_ALEN);\r\nbat_priv->bla.claim_dest.group = htons(crc);\r\nbatadv_hardif_put(primary_if);\r\n} else {\r\nbat_priv->bla.claim_dest.group = 0;\r\n}\r\nentrytime = jiffies - msecs_to_jiffies(BATADV_DUPLIST_TIMEOUT);\r\nfor (i = 0; i < BATADV_DUPLIST_SIZE; i++)\r\nbat_priv->bla.bcast_duplist[i].entrytime = entrytime;\r\nbat_priv->bla.bcast_duplist_curr = 0;\r\natomic_set(&bat_priv->bla.loopdetect_next,\r\nBATADV_BLA_LOOPDETECT_PERIODS);\r\nif (bat_priv->bla.claim_hash)\r\nreturn 0;\r\nbat_priv->bla.claim_hash = batadv_hash_new(128);\r\nbat_priv->bla.backbone_hash = batadv_hash_new(32);\r\nif (!bat_priv->bla.claim_hash || !bat_priv->bla.backbone_hash)\r\nreturn -ENOMEM;\r\nbatadv_hash_set_lock_class(bat_priv->bla.claim_hash,\r\n&batadv_claim_hash_lock_class_key);\r\nbatadv_hash_set_lock_class(bat_priv->bla.backbone_hash,\r\n&batadv_backbone_hash_lock_class_key);\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv, "bla hashes initialized\n");\r\nINIT_DELAYED_WORK(&bat_priv->bla.work, batadv_bla_periodic_work);\r\nqueue_delayed_work(batadv_event_workqueue, &bat_priv->bla.work,\r\nmsecs_to_jiffies(BATADV_BLA_PERIOD_LENGTH));\r\nreturn 0;\r\n}\r\nbool batadv_bla_check_bcast_duplist(struct batadv_priv *bat_priv,\r\nstruct sk_buff *skb)\r\n{\r\nint i, curr;\r\n__be32 crc;\r\nstruct batadv_bcast_packet *bcast_packet;\r\nstruct batadv_bcast_duplist_entry *entry;\r\nbool ret = false;\r\nbcast_packet = (struct batadv_bcast_packet *)skb->data;\r\ncrc = batadv_skb_crc32(skb, (u8 *)(bcast_packet + 1));\r\nspin_lock_bh(&bat_priv->bla.bcast_duplist_lock);\r\nfor (i = 0; i < BATADV_DUPLIST_SIZE; i++) {\r\ncurr = (bat_priv->bla.bcast_duplist_curr + i);\r\ncurr %= BATADV_DUPLIST_SIZE;\r\nentry = &bat_priv->bla.bcast_duplist[curr];\r\nif (batadv_has_timed_out(entry->entrytime,\r\nBATADV_DUPLIST_TIMEOUT))\r\nbreak;\r\nif (entry->crc != crc)\r\ncontinue;\r\nif (batadv_compare_eth(entry->orig, bcast_packet->orig))\r\ncontinue;\r\nret = true;\r\ngoto out;\r\n}\r\ncurr = (bat_priv->bla.bcast_duplist_curr + BATADV_DUPLIST_SIZE - 1);\r\ncurr %= BATADV_DUPLIST_SIZE;\r\nentry = &bat_priv->bla.bcast_duplist[curr];\r\nentry->crc = crc;\r\nentry->entrytime = jiffies;\r\nether_addr_copy(entry->orig, bcast_packet->orig);\r\nbat_priv->bla.bcast_duplist_curr = curr;\r\nout:\r\nspin_unlock_bh(&bat_priv->bla.bcast_duplist_lock);\r\nreturn ret;\r\n}\r\nbool batadv_bla_is_backbone_gw_orig(struct batadv_priv *bat_priv, u8 *orig,\r\nunsigned short vid)\r\n{\r\nstruct batadv_hashtable *hash = bat_priv->bla.backbone_hash;\r\nstruct hlist_head *head;\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nint i;\r\nif (!atomic_read(&bat_priv->bridge_loop_avoidance))\r\nreturn false;\r\nif (!hash)\r\nreturn false;\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(backbone_gw, head, hash_entry) {\r\nif (batadv_compare_eth(backbone_gw->orig, orig) &&\r\nbackbone_gw->vid == vid) {\r\nrcu_read_unlock();\r\nreturn true;\r\n}\r\n}\r\nrcu_read_unlock();\r\n}\r\nreturn false;\r\n}\r\nbool batadv_bla_is_backbone_gw(struct sk_buff *skb,\r\nstruct batadv_orig_node *orig_node, int hdr_size)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nunsigned short vid;\r\nif (!atomic_read(&orig_node->bat_priv->bridge_loop_avoidance))\r\nreturn false;\r\nif (!pskb_may_pull(skb, hdr_size + ETH_HLEN))\r\nreturn false;\r\nvid = batadv_get_vid(skb, hdr_size);\r\nbackbone_gw = batadv_backbone_hash_find(orig_node->bat_priv,\r\norig_node->orig, vid);\r\nif (!backbone_gw)\r\nreturn false;\r\nbatadv_backbone_gw_put(backbone_gw);\r\nreturn true;\r\n}\r\nvoid batadv_bla_free(struct batadv_priv *bat_priv)\r\n{\r\nstruct batadv_hard_iface *primary_if;\r\ncancel_delayed_work_sync(&bat_priv->bla.work);\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (bat_priv->bla.claim_hash) {\r\nbatadv_bla_purge_claims(bat_priv, primary_if, 1);\r\nbatadv_hash_destroy(bat_priv->bla.claim_hash);\r\nbat_priv->bla.claim_hash = NULL;\r\n}\r\nif (bat_priv->bla.backbone_hash) {\r\nbatadv_bla_purge_backbone_gw(bat_priv, 1);\r\nbatadv_hash_destroy(bat_priv->bla.backbone_hash);\r\nbat_priv->bla.backbone_hash = NULL;\r\n}\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\n}\r\nstatic bool\r\nbatadv_bla_loopdetect_check(struct batadv_priv *bat_priv, struct sk_buff *skb,\r\nstruct batadv_hard_iface *primary_if,\r\nunsigned short vid)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct ethhdr *ethhdr;\r\nethhdr = eth_hdr(skb);\r\nif (!batadv_compare_eth(ethhdr->h_source,\r\nbat_priv->bla.loopdetect_addr))\r\nreturn false;\r\nif (batadv_has_timed_out(bat_priv->bla.loopdetect_lasttime,\r\nBATADV_BLA_LOOPDETECT_TIMEOUT))\r\nreturn true;\r\nbackbone_gw = batadv_bla_get_backbone_gw(bat_priv,\r\nprimary_if->net_dev->dev_addr,\r\nvid, true);\r\nif (unlikely(!backbone_gw))\r\nreturn true;\r\nqueue_work(batadv_event_workqueue, &backbone_gw->report_work);\r\nreturn true;\r\n}\r\nbool batadv_bla_rx(struct batadv_priv *bat_priv, struct sk_buff *skb,\r\nunsigned short vid, bool is_bcast)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct ethhdr *ethhdr;\r\nstruct batadv_bla_claim search_claim, *claim = NULL;\r\nstruct batadv_hard_iface *primary_if;\r\nbool own_claim;\r\nbool ret;\r\nethhdr = eth_hdr(skb);\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if)\r\ngoto handled;\r\nif (!atomic_read(&bat_priv->bridge_loop_avoidance))\r\ngoto allow;\r\nif (batadv_bla_loopdetect_check(bat_priv, skb, primary_if, vid))\r\ngoto handled;\r\nif (unlikely(atomic_read(&bat_priv->bla.num_requests)))\r\nif (is_multicast_ether_addr(ethhdr->h_dest) && is_bcast)\r\ngoto handled;\r\nether_addr_copy(search_claim.addr, ethhdr->h_source);\r\nsearch_claim.vid = vid;\r\nclaim = batadv_claim_hash_find(bat_priv, &search_claim);\r\nif (!claim) {\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv,\r\n"%s(): Unclaimed MAC %pM found. Claim it. Local: %s\n",\r\n__func__, ethhdr->h_source,\r\nbatadv_is_my_client(bat_priv,\r\nethhdr->h_source, vid) ?\r\n"yes" : "no");\r\nbatadv_handle_claim(bat_priv, primary_if,\r\nprimary_if->net_dev->dev_addr,\r\nethhdr->h_source, vid);\r\ngoto allow;\r\n}\r\nbackbone_gw = batadv_bla_claim_get_backbone_gw(claim);\r\nown_claim = batadv_compare_eth(backbone_gw->orig,\r\nprimary_if->net_dev->dev_addr);\r\nbatadv_backbone_gw_put(backbone_gw);\r\nif (own_claim) {\r\nclaim->lasttime = jiffies;\r\ngoto allow;\r\n}\r\nif (is_multicast_ether_addr(ethhdr->h_dest) && is_bcast) {\r\ngoto handled;\r\n} else {\r\nbatadv_handle_claim(bat_priv, primary_if,\r\nprimary_if->net_dev->dev_addr,\r\nethhdr->h_source, vid);\r\ngoto allow;\r\n}\r\nallow:\r\nbatadv_bla_update_own_backbone_gw(bat_priv, primary_if, vid);\r\nret = false;\r\ngoto out;\r\nhandled:\r\nkfree_skb(skb);\r\nret = true;\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\nif (claim)\r\nbatadv_claim_put(claim);\r\nreturn ret;\r\n}\r\nbool batadv_bla_tx(struct batadv_priv *bat_priv, struct sk_buff *skb,\r\nunsigned short vid)\r\n{\r\nstruct ethhdr *ethhdr;\r\nstruct batadv_bla_claim search_claim, *claim = NULL;\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct batadv_hard_iface *primary_if;\r\nbool client_roamed;\r\nbool ret = false;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if)\r\ngoto out;\r\nif (!atomic_read(&bat_priv->bridge_loop_avoidance))\r\ngoto allow;\r\nif (batadv_bla_process_claim(bat_priv, primary_if, skb))\r\ngoto handled;\r\nethhdr = eth_hdr(skb);\r\nif (unlikely(atomic_read(&bat_priv->bla.num_requests)))\r\nif (is_multicast_ether_addr(ethhdr->h_dest))\r\ngoto handled;\r\nether_addr_copy(search_claim.addr, ethhdr->h_source);\r\nsearch_claim.vid = vid;\r\nclaim = batadv_claim_hash_find(bat_priv, &search_claim);\r\nif (!claim)\r\ngoto allow;\r\nbackbone_gw = batadv_bla_claim_get_backbone_gw(claim);\r\nclient_roamed = batadv_compare_eth(backbone_gw->orig,\r\nprimary_if->net_dev->dev_addr);\r\nbatadv_backbone_gw_put(backbone_gw);\r\nif (client_roamed) {\r\nif (batadv_has_timed_out(claim->lasttime, 100)) {\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv, "%s(): Roaming client %pM detected. Unclaim it.\n",\r\n__func__, ethhdr->h_source);\r\nbatadv_handle_unclaim(bat_priv, primary_if,\r\nprimary_if->net_dev->dev_addr,\r\nethhdr->h_source, vid);\r\ngoto allow;\r\n} else {\r\nbatadv_dbg(BATADV_DBG_BLA, bat_priv, "%s(): Race for claim %pM detected. Drop packet.\n",\r\n__func__, ethhdr->h_source);\r\ngoto handled;\r\n}\r\n}\r\nif (is_multicast_ether_addr(ethhdr->h_dest)) {\r\ngoto handled;\r\n} else {\r\ngoto allow;\r\n}\r\nallow:\r\nbatadv_bla_update_own_backbone_gw(bat_priv, primary_if, vid);\r\nret = false;\r\ngoto out;\r\nhandled:\r\nret = true;\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\nif (claim)\r\nbatadv_claim_put(claim);\r\nreturn ret;\r\n}\r\nint batadv_bla_claim_table_seq_print_text(struct seq_file *seq, void *offset)\r\n{\r\nstruct net_device *net_dev = (struct net_device *)seq->private;\r\nstruct batadv_priv *bat_priv = netdev_priv(net_dev);\r\nstruct batadv_hashtable *hash = bat_priv->bla.claim_hash;\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct batadv_bla_claim *claim;\r\nstruct batadv_hard_iface *primary_if;\r\nstruct hlist_head *head;\r\nu16 backbone_crc;\r\nu32 i;\r\nbool is_own;\r\nu8 *primary_addr;\r\nprimary_if = batadv_seq_print_text_primary_if_get(seq);\r\nif (!primary_if)\r\ngoto out;\r\nprimary_addr = primary_if->net_dev->dev_addr;\r\nseq_printf(seq,\r\n"Claims announced for the mesh %s (orig %pM, group id %#.4x)\n",\r\nnet_dev->name, primary_addr,\r\nntohs(bat_priv->bla.claim_dest.group));\r\nseq_puts(seq,\r\n" Client VID Originator [o] (CRC )\n");\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(claim, head, hash_entry) {\r\nbackbone_gw = batadv_bla_claim_get_backbone_gw(claim);\r\nis_own = batadv_compare_eth(backbone_gw->orig,\r\nprimary_addr);\r\nspin_lock_bh(&backbone_gw->crc_lock);\r\nbackbone_crc = backbone_gw->crc;\r\nspin_unlock_bh(&backbone_gw->crc_lock);\r\nseq_printf(seq, " * %pM on %5d by %pM [%c] (%#.4x)\n",\r\nclaim->addr, batadv_print_vid(claim->vid),\r\nbackbone_gw->orig,\r\n(is_own ? 'x' : ' '),\r\nbackbone_crc);\r\nbatadv_backbone_gw_put(backbone_gw);\r\n}\r\nrcu_read_unlock();\r\n}\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\nreturn 0;\r\n}\r\nstatic int\r\nbatadv_bla_claim_dump_entry(struct sk_buff *msg, u32 portid, u32 seq,\r\nstruct batadv_hard_iface *primary_if,\r\nstruct batadv_bla_claim *claim)\r\n{\r\nu8 *primary_addr = primary_if->net_dev->dev_addr;\r\nu16 backbone_crc;\r\nbool is_own;\r\nvoid *hdr;\r\nint ret = -EINVAL;\r\nhdr = genlmsg_put(msg, portid, seq, &batadv_netlink_family,\r\nNLM_F_MULTI, BATADV_CMD_GET_BLA_CLAIM);\r\nif (!hdr) {\r\nret = -ENOBUFS;\r\ngoto out;\r\n}\r\nis_own = batadv_compare_eth(claim->backbone_gw->orig,\r\nprimary_addr);\r\nspin_lock_bh(&claim->backbone_gw->crc_lock);\r\nbackbone_crc = claim->backbone_gw->crc;\r\nspin_unlock_bh(&claim->backbone_gw->crc_lock);\r\nif (is_own)\r\nif (nla_put_flag(msg, BATADV_ATTR_BLA_OWN)) {\r\ngenlmsg_cancel(msg, hdr);\r\ngoto out;\r\n}\r\nif (nla_put(msg, BATADV_ATTR_BLA_ADDRESS, ETH_ALEN, claim->addr) ||\r\nnla_put_u16(msg, BATADV_ATTR_BLA_VID, claim->vid) ||\r\nnla_put(msg, BATADV_ATTR_BLA_BACKBONE, ETH_ALEN,\r\nclaim->backbone_gw->orig) ||\r\nnla_put_u16(msg, BATADV_ATTR_BLA_CRC,\r\nbackbone_crc)) {\r\ngenlmsg_cancel(msg, hdr);\r\ngoto out;\r\n}\r\ngenlmsg_end(msg, hdr);\r\nret = 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic int\r\nbatadv_bla_claim_dump_bucket(struct sk_buff *msg, u32 portid, u32 seq,\r\nstruct batadv_hard_iface *primary_if,\r\nstruct hlist_head *head, int *idx_skip)\r\n{\r\nstruct batadv_bla_claim *claim;\r\nint idx = 0;\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(claim, head, hash_entry) {\r\nif (idx++ < *idx_skip)\r\ncontinue;\r\nif (batadv_bla_claim_dump_entry(msg, portid, seq,\r\nprimary_if, claim)) {\r\n*idx_skip = idx - 1;\r\ngoto unlock;\r\n}\r\n}\r\n*idx_skip = idx;\r\nunlock:\r\nrcu_read_unlock();\r\nreturn 0;\r\n}\r\nint batadv_bla_claim_dump(struct sk_buff *msg, struct netlink_callback *cb)\r\n{\r\nstruct batadv_hard_iface *primary_if = NULL;\r\nint portid = NETLINK_CB(cb->skb).portid;\r\nstruct net *net = sock_net(cb->skb->sk);\r\nstruct net_device *soft_iface;\r\nstruct batadv_hashtable *hash;\r\nstruct batadv_priv *bat_priv;\r\nint bucket = cb->args[0];\r\nstruct hlist_head *head;\r\nint idx = cb->args[1];\r\nint ifindex;\r\nint ret = 0;\r\nifindex = batadv_netlink_get_ifindex(cb->nlh,\r\nBATADV_ATTR_MESH_IFINDEX);\r\nif (!ifindex)\r\nreturn -EINVAL;\r\nsoft_iface = dev_get_by_index(net, ifindex);\r\nif (!soft_iface || !batadv_softif_is_valid(soft_iface)) {\r\nret = -ENODEV;\r\ngoto out;\r\n}\r\nbat_priv = netdev_priv(soft_iface);\r\nhash = bat_priv->bla.claim_hash;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if || primary_if->if_status != BATADV_IF_ACTIVE) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nwhile (bucket < hash->size) {\r\nhead = &hash->table[bucket];\r\nif (batadv_bla_claim_dump_bucket(msg, portid,\r\ncb->nlh->nlmsg_seq,\r\nprimary_if, head, &idx))\r\nbreak;\r\nbucket++;\r\n}\r\ncb->args[0] = bucket;\r\ncb->args[1] = idx;\r\nret = msg->len;\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\nif (soft_iface)\r\ndev_put(soft_iface);\r\nreturn ret;\r\n}\r\nint batadv_bla_backbone_table_seq_print_text(struct seq_file *seq, void *offset)\r\n{\r\nstruct net_device *net_dev = (struct net_device *)seq->private;\r\nstruct batadv_priv *bat_priv = netdev_priv(net_dev);\r\nstruct batadv_hashtable *hash = bat_priv->bla.backbone_hash;\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nstruct batadv_hard_iface *primary_if;\r\nstruct hlist_head *head;\r\nint secs, msecs;\r\nu16 backbone_crc;\r\nu32 i;\r\nbool is_own;\r\nu8 *primary_addr;\r\nprimary_if = batadv_seq_print_text_primary_if_get(seq);\r\nif (!primary_if)\r\ngoto out;\r\nprimary_addr = primary_if->net_dev->dev_addr;\r\nseq_printf(seq,\r\n"Backbones announced for the mesh %s (orig %pM, group id %#.4x)\n",\r\nnet_dev->name, primary_addr,\r\nntohs(bat_priv->bla.claim_dest.group));\r\nseq_puts(seq, " Originator VID last seen (CRC )\n");\r\nfor (i = 0; i < hash->size; i++) {\r\nhead = &hash->table[i];\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(backbone_gw, head, hash_entry) {\r\nmsecs = jiffies_to_msecs(jiffies -\r\nbackbone_gw->lasttime);\r\nsecs = msecs / 1000;\r\nmsecs = msecs % 1000;\r\nis_own = batadv_compare_eth(backbone_gw->orig,\r\nprimary_addr);\r\nif (is_own)\r\ncontinue;\r\nspin_lock_bh(&backbone_gw->crc_lock);\r\nbackbone_crc = backbone_gw->crc;\r\nspin_unlock_bh(&backbone_gw->crc_lock);\r\nseq_printf(seq, " * %pM on %5d %4i.%03is (%#.4x)\n",\r\nbackbone_gw->orig,\r\nbatadv_print_vid(backbone_gw->vid), secs,\r\nmsecs, backbone_crc);\r\n}\r\nrcu_read_unlock();\r\n}\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\nreturn 0;\r\n}\r\nstatic int\r\nbatadv_bla_backbone_dump_entry(struct sk_buff *msg, u32 portid, u32 seq,\r\nstruct batadv_hard_iface *primary_if,\r\nstruct batadv_bla_backbone_gw *backbone_gw)\r\n{\r\nu8 *primary_addr = primary_if->net_dev->dev_addr;\r\nu16 backbone_crc;\r\nbool is_own;\r\nint msecs;\r\nvoid *hdr;\r\nint ret = -EINVAL;\r\nhdr = genlmsg_put(msg, portid, seq, &batadv_netlink_family,\r\nNLM_F_MULTI, BATADV_CMD_GET_BLA_BACKBONE);\r\nif (!hdr) {\r\nret = -ENOBUFS;\r\ngoto out;\r\n}\r\nis_own = batadv_compare_eth(backbone_gw->orig, primary_addr);\r\nspin_lock_bh(&backbone_gw->crc_lock);\r\nbackbone_crc = backbone_gw->crc;\r\nspin_unlock_bh(&backbone_gw->crc_lock);\r\nmsecs = jiffies_to_msecs(jiffies - backbone_gw->lasttime);\r\nif (is_own)\r\nif (nla_put_flag(msg, BATADV_ATTR_BLA_OWN)) {\r\ngenlmsg_cancel(msg, hdr);\r\ngoto out;\r\n}\r\nif (nla_put(msg, BATADV_ATTR_BLA_BACKBONE, ETH_ALEN,\r\nbackbone_gw->orig) ||\r\nnla_put_u16(msg, BATADV_ATTR_BLA_VID, backbone_gw->vid) ||\r\nnla_put_u16(msg, BATADV_ATTR_BLA_CRC,\r\nbackbone_crc) ||\r\nnla_put_u32(msg, BATADV_ATTR_LAST_SEEN_MSECS, msecs)) {\r\ngenlmsg_cancel(msg, hdr);\r\ngoto out;\r\n}\r\ngenlmsg_end(msg, hdr);\r\nret = 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic int\r\nbatadv_bla_backbone_dump_bucket(struct sk_buff *msg, u32 portid, u32 seq,\r\nstruct batadv_hard_iface *primary_if,\r\nstruct hlist_head *head, int *idx_skip)\r\n{\r\nstruct batadv_bla_backbone_gw *backbone_gw;\r\nint idx = 0;\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(backbone_gw, head, hash_entry) {\r\nif (idx++ < *idx_skip)\r\ncontinue;\r\nif (batadv_bla_backbone_dump_entry(msg, portid, seq,\r\nprimary_if, backbone_gw)) {\r\n*idx_skip = idx - 1;\r\ngoto unlock;\r\n}\r\n}\r\n*idx_skip = idx;\r\nunlock:\r\nrcu_read_unlock();\r\nreturn 0;\r\n}\r\nint batadv_bla_backbone_dump(struct sk_buff *msg, struct netlink_callback *cb)\r\n{\r\nstruct batadv_hard_iface *primary_if = NULL;\r\nint portid = NETLINK_CB(cb->skb).portid;\r\nstruct net *net = sock_net(cb->skb->sk);\r\nstruct net_device *soft_iface;\r\nstruct batadv_hashtable *hash;\r\nstruct batadv_priv *bat_priv;\r\nint bucket = cb->args[0];\r\nstruct hlist_head *head;\r\nint idx = cb->args[1];\r\nint ifindex;\r\nint ret = 0;\r\nifindex = batadv_netlink_get_ifindex(cb->nlh,\r\nBATADV_ATTR_MESH_IFINDEX);\r\nif (!ifindex)\r\nreturn -EINVAL;\r\nsoft_iface = dev_get_by_index(net, ifindex);\r\nif (!soft_iface || !batadv_softif_is_valid(soft_iface)) {\r\nret = -ENODEV;\r\ngoto out;\r\n}\r\nbat_priv = netdev_priv(soft_iface);\r\nhash = bat_priv->bla.backbone_hash;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if || primary_if->if_status != BATADV_IF_ACTIVE) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nwhile (bucket < hash->size) {\r\nhead = &hash->table[bucket];\r\nif (batadv_bla_backbone_dump_bucket(msg, portid,\r\ncb->nlh->nlmsg_seq,\r\nprimary_if, head, &idx))\r\nbreak;\r\nbucket++;\r\n}\r\ncb->args[0] = bucket;\r\ncb->args[1] = idx;\r\nret = msg->len;\r\nout:\r\nif (primary_if)\r\nbatadv_hardif_put(primary_if);\r\nif (soft_iface)\r\ndev_put(soft_iface);\r\nreturn ret;\r\n}\r\nbool batadv_bla_check_claim(struct batadv_priv *bat_priv,\r\nu8 *addr, unsigned short vid)\r\n{\r\nstruct batadv_bla_claim search_claim;\r\nstruct batadv_bla_claim *claim = NULL;\r\nstruct batadv_hard_iface *primary_if = NULL;\r\nbool ret = true;\r\nif (!atomic_read(&bat_priv->bridge_loop_avoidance))\r\nreturn ret;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if)\r\nreturn ret;\r\nether_addr_copy(search_claim.addr, addr);\r\nsearch_claim.vid = vid;\r\nclaim = batadv_claim_hash_find(bat_priv, &search_claim);\r\nif (claim) {\r\nif (!batadv_compare_eth(claim->backbone_gw->orig,\r\nprimary_if->net_dev->dev_addr))\r\nret = false;\r\nbatadv_claim_put(claim);\r\n}\r\nbatadv_hardif_put(primary_if);\r\nreturn ret;\r\n}
