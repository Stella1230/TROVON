static int process_vm_rw_pages(struct page **pages,\r\nunsigned offset,\r\nsize_t len,\r\nstruct iov_iter *iter,\r\nint vm_write)\r\n{\r\nwhile (len && iov_iter_count(iter)) {\r\nstruct page *page = *pages++;\r\nsize_t copy = PAGE_SIZE - offset;\r\nsize_t copied;\r\nif (copy > len)\r\ncopy = len;\r\nif (vm_write) {\r\ncopied = copy_page_from_iter(page, offset, copy, iter);\r\nset_page_dirty_lock(page);\r\n} else {\r\ncopied = copy_page_to_iter(page, offset, copy, iter);\r\n}\r\nlen -= copied;\r\nif (copied < copy && iov_iter_count(iter))\r\nreturn -EFAULT;\r\noffset = 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic int process_vm_rw_single_vec(unsigned long addr,\r\nunsigned long len,\r\nstruct iov_iter *iter,\r\nstruct page **process_pages,\r\nstruct mm_struct *mm,\r\nstruct task_struct *task,\r\nint vm_write)\r\n{\r\nunsigned long pa = addr & PAGE_MASK;\r\nunsigned long start_offset = addr - pa;\r\nunsigned long nr_pages;\r\nssize_t rc = 0;\r\nunsigned long max_pages_per_loop = PVM_MAX_KMALLOC_PAGES\r\n/ sizeof(struct pages *);\r\nunsigned int flags = 0;\r\nif (len == 0)\r\nreturn 0;\r\nnr_pages = (addr + len - 1) / PAGE_SIZE - addr / PAGE_SIZE + 1;\r\nif (vm_write)\r\nflags |= FOLL_WRITE;\r\nwhile (!rc && nr_pages && iov_iter_count(iter)) {\r\nint pages = min(nr_pages, max_pages_per_loop);\r\nint locked = 1;\r\nsize_t bytes;\r\ndown_read(&mm->mmap_sem);\r\npages = get_user_pages_remote(task, mm, pa, pages, flags,\r\nprocess_pages, NULL, &locked);\r\nif (locked)\r\nup_read(&mm->mmap_sem);\r\nif (pages <= 0)\r\nreturn -EFAULT;\r\nbytes = pages * PAGE_SIZE - start_offset;\r\nif (bytes > len)\r\nbytes = len;\r\nrc = process_vm_rw_pages(process_pages,\r\nstart_offset, bytes, iter,\r\nvm_write);\r\nlen -= bytes;\r\nstart_offset = 0;\r\nnr_pages -= pages;\r\npa += pages * PAGE_SIZE;\r\nwhile (pages)\r\nput_page(process_pages[--pages]);\r\n}\r\nreturn rc;\r\n}\r\nstatic ssize_t process_vm_rw_core(pid_t pid, struct iov_iter *iter,\r\nconst struct iovec *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags, int vm_write)\r\n{\r\nstruct task_struct *task;\r\nstruct page *pp_stack[PVM_MAX_PP_ARRAY_COUNT];\r\nstruct page **process_pages = pp_stack;\r\nstruct mm_struct *mm;\r\nunsigned long i;\r\nssize_t rc = 0;\r\nunsigned long nr_pages = 0;\r\nunsigned long nr_pages_iov;\r\nssize_t iov_len;\r\nsize_t total_len = iov_iter_count(iter);\r\nfor (i = 0; i < riovcnt; i++) {\r\niov_len = rvec[i].iov_len;\r\nif (iov_len > 0) {\r\nnr_pages_iov = ((unsigned long)rvec[i].iov_base\r\n+ iov_len)\r\n/ PAGE_SIZE - (unsigned long)rvec[i].iov_base\r\n/ PAGE_SIZE + 1;\r\nnr_pages = max(nr_pages, nr_pages_iov);\r\n}\r\n}\r\nif (nr_pages == 0)\r\nreturn 0;\r\nif (nr_pages > PVM_MAX_PP_ARRAY_COUNT) {\r\nprocess_pages = kmalloc(min_t(size_t, PVM_MAX_KMALLOC_PAGES,\r\nsizeof(struct pages *)*nr_pages),\r\nGFP_KERNEL);\r\nif (!process_pages)\r\nreturn -ENOMEM;\r\n}\r\nrcu_read_lock();\r\ntask = find_task_by_vpid(pid);\r\nif (task)\r\nget_task_struct(task);\r\nrcu_read_unlock();\r\nif (!task) {\r\nrc = -ESRCH;\r\ngoto free_proc_pages;\r\n}\r\nmm = mm_access(task, PTRACE_MODE_ATTACH_REALCREDS);\r\nif (!mm || IS_ERR(mm)) {\r\nrc = IS_ERR(mm) ? PTR_ERR(mm) : -ESRCH;\r\nif (rc == -EACCES)\r\nrc = -EPERM;\r\ngoto put_task_struct;\r\n}\r\nfor (i = 0; i < riovcnt && iov_iter_count(iter) && !rc; i++)\r\nrc = process_vm_rw_single_vec(\r\n(unsigned long)rvec[i].iov_base, rvec[i].iov_len,\r\niter, process_pages, mm, task, vm_write);\r\ntotal_len -= iov_iter_count(iter);\r\nif (total_len)\r\nrc = total_len;\r\nmmput(mm);\r\nput_task_struct:\r\nput_task_struct(task);\r\nfree_proc_pages:\r\nif (process_pages != pp_stack)\r\nkfree(process_pages);\r\nreturn rc;\r\n}\r\nstatic ssize_t process_vm_rw(pid_t pid,\r\nconst struct iovec __user *lvec,\r\nunsigned long liovcnt,\r\nconst struct iovec __user *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags, int vm_write)\r\n{\r\nstruct iovec iovstack_l[UIO_FASTIOV];\r\nstruct iovec iovstack_r[UIO_FASTIOV];\r\nstruct iovec *iov_l = iovstack_l;\r\nstruct iovec *iov_r = iovstack_r;\r\nstruct iov_iter iter;\r\nssize_t rc;\r\nint dir = vm_write ? WRITE : READ;\r\nif (flags != 0)\r\nreturn -EINVAL;\r\nrc = import_iovec(dir, lvec, liovcnt, UIO_FASTIOV, &iov_l, &iter);\r\nif (rc < 0)\r\nreturn rc;\r\nif (!iov_iter_count(&iter))\r\ngoto free_iovecs;\r\nrc = rw_copy_check_uvector(CHECK_IOVEC_ONLY, rvec, riovcnt, UIO_FASTIOV,\r\niovstack_r, &iov_r);\r\nif (rc <= 0)\r\ngoto free_iovecs;\r\nrc = process_vm_rw_core(pid, &iter, iov_r, riovcnt, flags, vm_write);\r\nfree_iovecs:\r\nif (iov_r != iovstack_r)\r\nkfree(iov_r);\r\nkfree(iov_l);\r\nreturn rc;\r\n}\r\nstatic ssize_t\r\ncompat_process_vm_rw(compat_pid_t pid,\r\nconst struct compat_iovec __user *lvec,\r\nunsigned long liovcnt,\r\nconst struct compat_iovec __user *rvec,\r\nunsigned long riovcnt,\r\nunsigned long flags, int vm_write)\r\n{\r\nstruct iovec iovstack_l[UIO_FASTIOV];\r\nstruct iovec iovstack_r[UIO_FASTIOV];\r\nstruct iovec *iov_l = iovstack_l;\r\nstruct iovec *iov_r = iovstack_r;\r\nstruct iov_iter iter;\r\nssize_t rc = -EFAULT;\r\nint dir = vm_write ? WRITE : READ;\r\nif (flags != 0)\r\nreturn -EINVAL;\r\nrc = compat_import_iovec(dir, lvec, liovcnt, UIO_FASTIOV, &iov_l, &iter);\r\nif (rc < 0)\r\nreturn rc;\r\nif (!iov_iter_count(&iter))\r\ngoto free_iovecs;\r\nrc = compat_rw_copy_check_uvector(CHECK_IOVEC_ONLY, rvec, riovcnt,\r\nUIO_FASTIOV, iovstack_r,\r\n&iov_r);\r\nif (rc <= 0)\r\ngoto free_iovecs;\r\nrc = process_vm_rw_core(pid, &iter, iov_r, riovcnt, flags, vm_write);\r\nfree_iovecs:\r\nif (iov_r != iovstack_r)\r\nkfree(iov_r);\r\nkfree(iov_l);\r\nreturn rc;\r\n}
