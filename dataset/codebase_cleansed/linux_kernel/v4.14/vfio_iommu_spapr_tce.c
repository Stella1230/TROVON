static long try_increment_locked_vm(struct mm_struct *mm, long npages)\r\n{\r\nlong ret = 0, locked, lock_limit;\r\nif (WARN_ON_ONCE(!mm))\r\nreturn -EPERM;\r\nif (!npages)\r\nreturn 0;\r\ndown_write(&mm->mmap_sem);\r\nlocked = mm->locked_vm + npages;\r\nlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\r\nif (locked > lock_limit && !capable(CAP_IPC_LOCK))\r\nret = -ENOMEM;\r\nelse\r\nmm->locked_vm += npages;\r\npr_debug("[%d] RLIMIT_MEMLOCK +%ld %ld/%ld%s\n", current->pid,\r\nnpages << PAGE_SHIFT,\r\nmm->locked_vm << PAGE_SHIFT,\r\nrlimit(RLIMIT_MEMLOCK),\r\nret ? " - exceeded" : "");\r\nup_write(&mm->mmap_sem);\r\nreturn ret;\r\n}\r\nstatic void decrement_locked_vm(struct mm_struct *mm, long npages)\r\n{\r\nif (!mm || !npages)\r\nreturn;\r\ndown_write(&mm->mmap_sem);\r\nif (WARN_ON_ONCE(npages > mm->locked_vm))\r\nnpages = mm->locked_vm;\r\nmm->locked_vm -= npages;\r\npr_debug("[%d] RLIMIT_MEMLOCK -%ld %ld/%ld\n", current->pid,\r\nnpages << PAGE_SHIFT,\r\nmm->locked_vm << PAGE_SHIFT,\r\nrlimit(RLIMIT_MEMLOCK));\r\nup_write(&mm->mmap_sem);\r\n}\r\nstatic long tce_iommu_mm_set(struct tce_container *container)\r\n{\r\nif (container->mm) {\r\nif (container->mm == current->mm)\r\nreturn 0;\r\nreturn -EPERM;\r\n}\r\nBUG_ON(!current->mm);\r\ncontainer->mm = current->mm;\r\natomic_inc(&container->mm->mm_count);\r\nreturn 0;\r\n}\r\nstatic long tce_iommu_prereg_free(struct tce_container *container,\r\nstruct tce_iommu_prereg *tcemem)\r\n{\r\nlong ret;\r\nret = mm_iommu_put(container->mm, tcemem->mem);\r\nif (ret)\r\nreturn ret;\r\nlist_del(&tcemem->next);\r\nkfree(tcemem);\r\nreturn 0;\r\n}\r\nstatic long tce_iommu_unregister_pages(struct tce_container *container,\r\n__u64 vaddr, __u64 size)\r\n{\r\nstruct mm_iommu_table_group_mem_t *mem;\r\nstruct tce_iommu_prereg *tcemem;\r\nbool found = false;\r\nif ((vaddr & ~PAGE_MASK) || (size & ~PAGE_MASK))\r\nreturn -EINVAL;\r\nmem = mm_iommu_find(container->mm, vaddr, size >> PAGE_SHIFT);\r\nif (!mem)\r\nreturn -ENOENT;\r\nlist_for_each_entry(tcemem, &container->prereg_list, next) {\r\nif (tcemem->mem == mem) {\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (!found)\r\nreturn -ENOENT;\r\nreturn tce_iommu_prereg_free(container, tcemem);\r\n}\r\nstatic long tce_iommu_register_pages(struct tce_container *container,\r\n__u64 vaddr, __u64 size)\r\n{\r\nlong ret = 0;\r\nstruct mm_iommu_table_group_mem_t *mem = NULL;\r\nstruct tce_iommu_prereg *tcemem;\r\nunsigned long entries = size >> PAGE_SHIFT;\r\nif ((vaddr & ~PAGE_MASK) || (size & ~PAGE_MASK) ||\r\n((vaddr + size) < vaddr))\r\nreturn -EINVAL;\r\nmem = mm_iommu_find(container->mm, vaddr, entries);\r\nif (mem) {\r\nlist_for_each_entry(tcemem, &container->prereg_list, next) {\r\nif (tcemem->mem == mem)\r\nreturn -EBUSY;\r\n}\r\n}\r\nret = mm_iommu_get(container->mm, vaddr, entries, &mem);\r\nif (ret)\r\nreturn ret;\r\ntcemem = kzalloc(sizeof(*tcemem), GFP_KERNEL);\r\nif (!tcemem) {\r\nmm_iommu_put(container->mm, mem);\r\nreturn -ENOMEM;\r\n}\r\ntcemem->mem = mem;\r\nlist_add(&tcemem->next, &container->prereg_list);\r\ncontainer->enabled = true;\r\nreturn 0;\r\n}\r\nstatic long tce_iommu_userspace_view_alloc(struct iommu_table *tbl,\r\nstruct mm_struct *mm)\r\n{\r\nunsigned long cb = _ALIGN_UP(sizeof(tbl->it_userspace[0]) *\r\ntbl->it_size, PAGE_SIZE);\r\nunsigned long *uas;\r\nlong ret;\r\nBUG_ON(tbl->it_userspace);\r\nret = try_increment_locked_vm(mm, cb >> PAGE_SHIFT);\r\nif (ret)\r\nreturn ret;\r\nuas = vzalloc(cb);\r\nif (!uas) {\r\ndecrement_locked_vm(mm, cb >> PAGE_SHIFT);\r\nreturn -ENOMEM;\r\n}\r\ntbl->it_userspace = uas;\r\nreturn 0;\r\n}\r\nstatic void tce_iommu_userspace_view_free(struct iommu_table *tbl,\r\nstruct mm_struct *mm)\r\n{\r\nunsigned long cb = _ALIGN_UP(sizeof(tbl->it_userspace[0]) *\r\ntbl->it_size, PAGE_SIZE);\r\nif (!tbl->it_userspace)\r\nreturn;\r\nvfree(tbl->it_userspace);\r\ntbl->it_userspace = NULL;\r\ndecrement_locked_vm(mm, cb >> PAGE_SHIFT);\r\n}\r\nstatic bool tce_page_is_contained(struct page *page, unsigned page_shift)\r\n{\r\nreturn (PAGE_SHIFT + compound_order(compound_head(page))) >= page_shift;\r\n}\r\nstatic inline bool tce_groups_attached(struct tce_container *container)\r\n{\r\nreturn !list_empty(&container->group_list);\r\n}\r\nstatic long tce_iommu_find_table(struct tce_container *container,\r\nphys_addr_t ioba, struct iommu_table **ptbl)\r\n{\r\nlong i;\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\r\nstruct iommu_table *tbl = container->tables[i];\r\nif (tbl) {\r\nunsigned long entry = ioba >> tbl->it_page_shift;\r\nunsigned long start = tbl->it_offset;\r\nunsigned long end = start + tbl->it_size;\r\nif ((start <= entry) && (entry < end)) {\r\n*ptbl = tbl;\r\nreturn i;\r\n}\r\n}\r\n}\r\nreturn -1;\r\n}\r\nstatic int tce_iommu_find_free_table(struct tce_container *container)\r\n{\r\nint i;\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\r\nif (!container->tables[i])\r\nreturn i;\r\n}\r\nreturn -ENOSPC;\r\n}\r\nstatic int tce_iommu_enable(struct tce_container *container)\r\n{\r\nint ret = 0;\r\nunsigned long locked;\r\nstruct iommu_table_group *table_group;\r\nstruct tce_iommu_group *tcegrp;\r\nif (container->enabled)\r\nreturn -EBUSY;\r\nif (!tce_groups_attached(container))\r\nreturn -ENODEV;\r\ntcegrp = list_first_entry(&container->group_list,\r\nstruct tce_iommu_group, next);\r\ntable_group = iommu_group_get_iommudata(tcegrp->grp);\r\nif (!table_group)\r\nreturn -ENODEV;\r\nif (!table_group->tce32_size)\r\nreturn -EPERM;\r\nret = tce_iommu_mm_set(container);\r\nif (ret)\r\nreturn ret;\r\nlocked = table_group->tce32_size >> PAGE_SHIFT;\r\nret = try_increment_locked_vm(container->mm, locked);\r\nif (ret)\r\nreturn ret;\r\ncontainer->locked_pages = locked;\r\ncontainer->enabled = true;\r\nreturn ret;\r\n}\r\nstatic void tce_iommu_disable(struct tce_container *container)\r\n{\r\nif (!container->enabled)\r\nreturn;\r\ncontainer->enabled = false;\r\nBUG_ON(!container->mm);\r\ndecrement_locked_vm(container->mm, container->locked_pages);\r\n}\r\nstatic void *tce_iommu_open(unsigned long arg)\r\n{\r\nstruct tce_container *container;\r\nif ((arg != VFIO_SPAPR_TCE_IOMMU) && (arg != VFIO_SPAPR_TCE_v2_IOMMU)) {\r\npr_err("tce_vfio: Wrong IOMMU type\n");\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\ncontainer = kzalloc(sizeof(*container), GFP_KERNEL);\r\nif (!container)\r\nreturn ERR_PTR(-ENOMEM);\r\nmutex_init(&container->lock);\r\nINIT_LIST_HEAD_RCU(&container->group_list);\r\nINIT_LIST_HEAD_RCU(&container->prereg_list);\r\ncontainer->v2 = arg == VFIO_SPAPR_TCE_v2_IOMMU;\r\nreturn container;\r\n}\r\nstatic void tce_iommu_release(void *iommu_data)\r\n{\r\nstruct tce_container *container = iommu_data;\r\nstruct tce_iommu_group *tcegrp;\r\nlong i;\r\nwhile (tce_groups_attached(container)) {\r\ntcegrp = list_first_entry(&container->group_list,\r\nstruct tce_iommu_group, next);\r\ntce_iommu_detach_group(iommu_data, tcegrp->grp);\r\n}\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\r\nstruct iommu_table *tbl = container->tables[i];\r\nif (!tbl)\r\ncontinue;\r\ntce_iommu_clear(container, tbl, tbl->it_offset, tbl->it_size);\r\ntce_iommu_free_table(container, tbl);\r\n}\r\nwhile (!list_empty(&container->prereg_list)) {\r\nstruct tce_iommu_prereg *tcemem;\r\ntcemem = list_first_entry(&container->prereg_list,\r\nstruct tce_iommu_prereg, next);\r\nWARN_ON_ONCE(tce_iommu_prereg_free(container, tcemem));\r\n}\r\ntce_iommu_disable(container);\r\nif (container->mm)\r\nmmdrop(container->mm);\r\nmutex_destroy(&container->lock);\r\nkfree(container);\r\n}\r\nstatic void tce_iommu_unuse_page(struct tce_container *container,\r\nunsigned long hpa)\r\n{\r\nstruct page *page;\r\npage = pfn_to_page(hpa >> PAGE_SHIFT);\r\nput_page(page);\r\n}\r\nstatic int tce_iommu_prereg_ua_to_hpa(struct tce_container *container,\r\nunsigned long tce, unsigned long size,\r\nunsigned long *phpa, struct mm_iommu_table_group_mem_t **pmem)\r\n{\r\nlong ret = 0;\r\nstruct mm_iommu_table_group_mem_t *mem;\r\nmem = mm_iommu_lookup(container->mm, tce, size);\r\nif (!mem)\r\nreturn -EINVAL;\r\nret = mm_iommu_ua_to_hpa(mem, tce, phpa);\r\nif (ret)\r\nreturn -EINVAL;\r\n*pmem = mem;\r\nreturn 0;\r\n}\r\nstatic void tce_iommu_unuse_page_v2(struct tce_container *container,\r\nstruct iommu_table *tbl, unsigned long entry)\r\n{\r\nstruct mm_iommu_table_group_mem_t *mem = NULL;\r\nint ret;\r\nunsigned long hpa = 0;\r\nunsigned long *pua = IOMMU_TABLE_USERSPACE_ENTRY(tbl, entry);\r\nif (!pua)\r\nreturn;\r\nret = tce_iommu_prereg_ua_to_hpa(container, *pua, IOMMU_PAGE_SIZE(tbl),\r\n&hpa, &mem);\r\nif (ret)\r\npr_debug("%s: tce %lx at #%lx was not cached, ret=%d\n",\r\n__func__, *pua, entry, ret);\r\nif (mem)\r\nmm_iommu_mapped_dec(mem);\r\n*pua = 0;\r\n}\r\nstatic int tce_iommu_clear(struct tce_container *container,\r\nstruct iommu_table *tbl,\r\nunsigned long entry, unsigned long pages)\r\n{\r\nunsigned long oldhpa;\r\nlong ret;\r\nenum dma_data_direction direction;\r\nfor ( ; pages; --pages, ++entry) {\r\ndirection = DMA_NONE;\r\noldhpa = 0;\r\nret = iommu_tce_xchg(tbl, entry, &oldhpa, &direction);\r\nif (ret)\r\ncontinue;\r\nif (direction == DMA_NONE)\r\ncontinue;\r\nif (container->v2) {\r\ntce_iommu_unuse_page_v2(container, tbl, entry);\r\ncontinue;\r\n}\r\ntce_iommu_unuse_page(container, oldhpa);\r\n}\r\nreturn 0;\r\n}\r\nstatic int tce_iommu_use_page(unsigned long tce, unsigned long *hpa)\r\n{\r\nstruct page *page = NULL;\r\nenum dma_data_direction direction = iommu_tce_direction(tce);\r\nif (get_user_pages_fast(tce & PAGE_MASK, 1,\r\ndirection != DMA_TO_DEVICE, &page) != 1)\r\nreturn -EFAULT;\r\n*hpa = __pa((unsigned long) page_address(page));\r\nreturn 0;\r\n}\r\nstatic long tce_iommu_build(struct tce_container *container,\r\nstruct iommu_table *tbl,\r\nunsigned long entry, unsigned long tce, unsigned long pages,\r\nenum dma_data_direction direction)\r\n{\r\nlong i, ret = 0;\r\nstruct page *page;\r\nunsigned long hpa;\r\nenum dma_data_direction dirtmp;\r\nfor (i = 0; i < pages; ++i) {\r\nunsigned long offset = tce & IOMMU_PAGE_MASK(tbl) & ~PAGE_MASK;\r\nret = tce_iommu_use_page(tce, &hpa);\r\nif (ret)\r\nbreak;\r\npage = pfn_to_page(hpa >> PAGE_SHIFT);\r\nif (!tce_page_is_contained(page, tbl->it_page_shift)) {\r\nret = -EPERM;\r\nbreak;\r\n}\r\nhpa |= offset;\r\ndirtmp = direction;\r\nret = iommu_tce_xchg(tbl, entry + i, &hpa, &dirtmp);\r\nif (ret) {\r\ntce_iommu_unuse_page(container, hpa);\r\npr_err("iommu_tce: %s failed ioba=%lx, tce=%lx, ret=%ld\n",\r\n__func__, entry << tbl->it_page_shift,\r\ntce, ret);\r\nbreak;\r\n}\r\nif (dirtmp != DMA_NONE)\r\ntce_iommu_unuse_page(container, hpa);\r\ntce += IOMMU_PAGE_SIZE(tbl);\r\n}\r\nif (ret)\r\ntce_iommu_clear(container, tbl, entry, i);\r\nreturn ret;\r\n}\r\nstatic long tce_iommu_build_v2(struct tce_container *container,\r\nstruct iommu_table *tbl,\r\nunsigned long entry, unsigned long tce, unsigned long pages,\r\nenum dma_data_direction direction)\r\n{\r\nlong i, ret = 0;\r\nstruct page *page;\r\nunsigned long hpa;\r\nenum dma_data_direction dirtmp;\r\nif (!tbl->it_userspace) {\r\nret = tce_iommu_userspace_view_alloc(tbl, container->mm);\r\nif (ret)\r\nreturn ret;\r\n}\r\nfor (i = 0; i < pages; ++i) {\r\nstruct mm_iommu_table_group_mem_t *mem = NULL;\r\nunsigned long *pua = IOMMU_TABLE_USERSPACE_ENTRY(tbl,\r\nentry + i);\r\nret = tce_iommu_prereg_ua_to_hpa(container,\r\ntce, IOMMU_PAGE_SIZE(tbl), &hpa, &mem);\r\nif (ret)\r\nbreak;\r\npage = pfn_to_page(hpa >> PAGE_SHIFT);\r\nif (!tce_page_is_contained(page, tbl->it_page_shift)) {\r\nret = -EPERM;\r\nbreak;\r\n}\r\nhpa |= tce & IOMMU_PAGE_MASK(tbl) & ~PAGE_MASK;\r\ndirtmp = direction;\r\nif (mm_iommu_mapped_inc(mem))\r\nbreak;\r\nret = iommu_tce_xchg(tbl, entry + i, &hpa, &dirtmp);\r\nif (ret) {\r\ntce_iommu_unuse_page_v2(container, tbl, entry + i);\r\npr_err("iommu_tce: %s failed ioba=%lx, tce=%lx, ret=%ld\n",\r\n__func__, entry << tbl->it_page_shift,\r\ntce, ret);\r\nbreak;\r\n}\r\nif (dirtmp != DMA_NONE)\r\ntce_iommu_unuse_page_v2(container, tbl, entry + i);\r\n*pua = tce;\r\ntce += IOMMU_PAGE_SIZE(tbl);\r\n}\r\nif (ret)\r\ntce_iommu_clear(container, tbl, entry, i);\r\nreturn ret;\r\n}\r\nstatic long tce_iommu_create_table(struct tce_container *container,\r\nstruct iommu_table_group *table_group,\r\nint num,\r\n__u32 page_shift,\r\n__u64 window_size,\r\n__u32 levels,\r\nstruct iommu_table **ptbl)\r\n{\r\nlong ret, table_size;\r\ntable_size = table_group->ops->get_table_size(page_shift, window_size,\r\nlevels);\r\nif (!table_size)\r\nreturn -EINVAL;\r\nret = try_increment_locked_vm(container->mm, table_size >> PAGE_SHIFT);\r\nif (ret)\r\nreturn ret;\r\nret = table_group->ops->create_table(table_group, num,\r\npage_shift, window_size, levels, ptbl);\r\nWARN_ON(!ret && !(*ptbl)->it_ops->free);\r\nWARN_ON(!ret && ((*ptbl)->it_allocated_size != table_size));\r\nreturn ret;\r\n}\r\nstatic void tce_iommu_free_table(struct tce_container *container,\r\nstruct iommu_table *tbl)\r\n{\r\nunsigned long pages = tbl->it_allocated_size >> PAGE_SHIFT;\r\ntce_iommu_userspace_view_free(tbl, container->mm);\r\niommu_tce_table_put(tbl);\r\ndecrement_locked_vm(container->mm, pages);\r\n}\r\nstatic long tce_iommu_create_window(struct tce_container *container,\r\n__u32 page_shift, __u64 window_size, __u32 levels,\r\n__u64 *start_addr)\r\n{\r\nstruct tce_iommu_group *tcegrp;\r\nstruct iommu_table_group *table_group;\r\nstruct iommu_table *tbl = NULL;\r\nlong ret, num;\r\nnum = tce_iommu_find_free_table(container);\r\nif (num < 0)\r\nreturn num;\r\ntcegrp = list_first_entry(&container->group_list,\r\nstruct tce_iommu_group, next);\r\ntable_group = iommu_group_get_iommudata(tcegrp->grp);\r\nif (!table_group)\r\nreturn -EFAULT;\r\nif (!(table_group->pgsizes & (1ULL << page_shift)))\r\nreturn -EINVAL;\r\nif (!table_group->ops->set_window || !table_group->ops->unset_window ||\r\n!table_group->ops->get_table_size ||\r\n!table_group->ops->create_table)\r\nreturn -EPERM;\r\nret = tce_iommu_create_table(container, table_group, num,\r\npage_shift, window_size, levels, &tbl);\r\nif (ret)\r\nreturn ret;\r\nBUG_ON(!tbl->it_ops->free);\r\nlist_for_each_entry(tcegrp, &container->group_list, next) {\r\ntable_group = iommu_group_get_iommudata(tcegrp->grp);\r\nret = table_group->ops->set_window(table_group, num, tbl);\r\nif (ret)\r\ngoto unset_exit;\r\n}\r\ncontainer->tables[num] = tbl;\r\n*start_addr = tbl->it_offset << tbl->it_page_shift;\r\nreturn 0;\r\nunset_exit:\r\nlist_for_each_entry(tcegrp, &container->group_list, next) {\r\ntable_group = iommu_group_get_iommudata(tcegrp->grp);\r\ntable_group->ops->unset_window(table_group, num);\r\n}\r\ntce_iommu_free_table(container, tbl);\r\nreturn ret;\r\n}\r\nstatic long tce_iommu_remove_window(struct tce_container *container,\r\n__u64 start_addr)\r\n{\r\nstruct iommu_table_group *table_group = NULL;\r\nstruct iommu_table *tbl;\r\nstruct tce_iommu_group *tcegrp;\r\nint num;\r\nnum = tce_iommu_find_table(container, start_addr, &tbl);\r\nif (num < 0)\r\nreturn -EINVAL;\r\nBUG_ON(!tbl->it_size);\r\nlist_for_each_entry(tcegrp, &container->group_list, next) {\r\ntable_group = iommu_group_get_iommudata(tcegrp->grp);\r\nif (!table_group->ops || !table_group->ops->unset_window)\r\nreturn -EPERM;\r\ntable_group->ops->unset_window(table_group, num);\r\n}\r\ntce_iommu_clear(container, tbl, tbl->it_offset, tbl->it_size);\r\ntce_iommu_free_table(container, tbl);\r\ncontainer->tables[num] = NULL;\r\nreturn 0;\r\n}\r\nstatic long tce_iommu_create_default_window(struct tce_container *container)\r\n{\r\nlong ret;\r\n__u64 start_addr = 0;\r\nstruct tce_iommu_group *tcegrp;\r\nstruct iommu_table_group *table_group;\r\nif (!container->def_window_pending)\r\nreturn 0;\r\nif (!tce_groups_attached(container))\r\nreturn -ENODEV;\r\ntcegrp = list_first_entry(&container->group_list,\r\nstruct tce_iommu_group, next);\r\ntable_group = iommu_group_get_iommudata(tcegrp->grp);\r\nif (!table_group)\r\nreturn -ENODEV;\r\nret = tce_iommu_create_window(container, IOMMU_PAGE_SHIFT_4K,\r\ntable_group->tce32_size, 1, &start_addr);\r\nWARN_ON_ONCE(!ret && start_addr);\r\nif (!ret)\r\ncontainer->def_window_pending = false;\r\nreturn ret;\r\n}\r\nstatic long tce_iommu_ioctl(void *iommu_data,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nstruct tce_container *container = iommu_data;\r\nunsigned long minsz, ddwsz;\r\nlong ret;\r\nswitch (cmd) {\r\ncase VFIO_CHECK_EXTENSION:\r\nswitch (arg) {\r\ncase VFIO_SPAPR_TCE_IOMMU:\r\ncase VFIO_SPAPR_TCE_v2_IOMMU:\r\nret = 1;\r\nbreak;\r\ndefault:\r\nret = vfio_spapr_iommu_eeh_ioctl(NULL, cmd, arg);\r\nbreak;\r\n}\r\nreturn (ret < 0) ? 0 : ret;\r\n}\r\nBUG_ON(!container);\r\nif (container->mm && container->mm != current->mm)\r\nreturn -EPERM;\r\nswitch (cmd) {\r\ncase VFIO_IOMMU_SPAPR_TCE_GET_INFO: {\r\nstruct vfio_iommu_spapr_tce_info info;\r\nstruct tce_iommu_group *tcegrp;\r\nstruct iommu_table_group *table_group;\r\nif (!tce_groups_attached(container))\r\nreturn -ENXIO;\r\ntcegrp = list_first_entry(&container->group_list,\r\nstruct tce_iommu_group, next);\r\ntable_group = iommu_group_get_iommudata(tcegrp->grp);\r\nif (!table_group)\r\nreturn -ENXIO;\r\nminsz = offsetofend(struct vfio_iommu_spapr_tce_info,\r\ndma32_window_size);\r\nif (copy_from_user(&info, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (info.argsz < minsz)\r\nreturn -EINVAL;\r\ninfo.dma32_window_start = table_group->tce32_start;\r\ninfo.dma32_window_size = table_group->tce32_size;\r\ninfo.flags = 0;\r\nmemset(&info.ddw, 0, sizeof(info.ddw));\r\nif (table_group->max_dynamic_windows_supported &&\r\ncontainer->v2) {\r\ninfo.flags |= VFIO_IOMMU_SPAPR_INFO_DDW;\r\ninfo.ddw.pgsizes = table_group->pgsizes;\r\ninfo.ddw.max_dynamic_windows_supported =\r\ntable_group->max_dynamic_windows_supported;\r\ninfo.ddw.levels = table_group->max_levels;\r\n}\r\nddwsz = offsetofend(struct vfio_iommu_spapr_tce_info, ddw);\r\nif (info.argsz >= ddwsz)\r\nminsz = ddwsz;\r\nif (copy_to_user((void __user *)arg, &info, minsz))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\ncase VFIO_IOMMU_MAP_DMA: {\r\nstruct vfio_iommu_type1_dma_map param;\r\nstruct iommu_table *tbl = NULL;\r\nlong num;\r\nenum dma_data_direction direction;\r\nif (!container->enabled)\r\nreturn -EPERM;\r\nminsz = offsetofend(struct vfio_iommu_type1_dma_map, size);\r\nif (copy_from_user(&param, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (param.argsz < minsz)\r\nreturn -EINVAL;\r\nif (param.flags & ~(VFIO_DMA_MAP_FLAG_READ |\r\nVFIO_DMA_MAP_FLAG_WRITE))\r\nreturn -EINVAL;\r\nret = tce_iommu_create_default_window(container);\r\nif (ret)\r\nreturn ret;\r\nnum = tce_iommu_find_table(container, param.iova, &tbl);\r\nif (num < 0)\r\nreturn -ENXIO;\r\nif ((param.size & ~IOMMU_PAGE_MASK(tbl)) ||\r\n(param.vaddr & ~IOMMU_PAGE_MASK(tbl)))\r\nreturn -EINVAL;\r\nif (param.flags & VFIO_DMA_MAP_FLAG_READ) {\r\nif (param.flags & VFIO_DMA_MAP_FLAG_WRITE)\r\ndirection = DMA_BIDIRECTIONAL;\r\nelse\r\ndirection = DMA_TO_DEVICE;\r\n} else {\r\nif (param.flags & VFIO_DMA_MAP_FLAG_WRITE)\r\ndirection = DMA_FROM_DEVICE;\r\nelse\r\nreturn -EINVAL;\r\n}\r\nret = iommu_tce_put_param_check(tbl, param.iova, param.vaddr);\r\nif (ret)\r\nreturn ret;\r\nif (container->v2)\r\nret = tce_iommu_build_v2(container, tbl,\r\nparam.iova >> tbl->it_page_shift,\r\nparam.vaddr,\r\nparam.size >> tbl->it_page_shift,\r\ndirection);\r\nelse\r\nret = tce_iommu_build(container, tbl,\r\nparam.iova >> tbl->it_page_shift,\r\nparam.vaddr,\r\nparam.size >> tbl->it_page_shift,\r\ndirection);\r\niommu_flush_tce(tbl);\r\nreturn ret;\r\n}\r\ncase VFIO_IOMMU_UNMAP_DMA: {\r\nstruct vfio_iommu_type1_dma_unmap param;\r\nstruct iommu_table *tbl = NULL;\r\nlong num;\r\nif (!container->enabled)\r\nreturn -EPERM;\r\nminsz = offsetofend(struct vfio_iommu_type1_dma_unmap,\r\nsize);\r\nif (copy_from_user(&param, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (param.argsz < minsz)\r\nreturn -EINVAL;\r\nif (param.flags)\r\nreturn -EINVAL;\r\nret = tce_iommu_create_default_window(container);\r\nif (ret)\r\nreturn ret;\r\nnum = tce_iommu_find_table(container, param.iova, &tbl);\r\nif (num < 0)\r\nreturn -ENXIO;\r\nif (param.size & ~IOMMU_PAGE_MASK(tbl))\r\nreturn -EINVAL;\r\nret = iommu_tce_clear_param_check(tbl, param.iova, 0,\r\nparam.size >> tbl->it_page_shift);\r\nif (ret)\r\nreturn ret;\r\nret = tce_iommu_clear(container, tbl,\r\nparam.iova >> tbl->it_page_shift,\r\nparam.size >> tbl->it_page_shift);\r\niommu_flush_tce(tbl);\r\nreturn ret;\r\n}\r\ncase VFIO_IOMMU_SPAPR_REGISTER_MEMORY: {\r\nstruct vfio_iommu_spapr_register_memory param;\r\nif (!container->v2)\r\nbreak;\r\nminsz = offsetofend(struct vfio_iommu_spapr_register_memory,\r\nsize);\r\nret = tce_iommu_mm_set(container);\r\nif (ret)\r\nreturn ret;\r\nif (copy_from_user(&param, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (param.argsz < minsz)\r\nreturn -EINVAL;\r\nif (param.flags)\r\nreturn -EINVAL;\r\nmutex_lock(&container->lock);\r\nret = tce_iommu_register_pages(container, param.vaddr,\r\nparam.size);\r\nmutex_unlock(&container->lock);\r\nreturn ret;\r\n}\r\ncase VFIO_IOMMU_SPAPR_UNREGISTER_MEMORY: {\r\nstruct vfio_iommu_spapr_register_memory param;\r\nif (!container->v2)\r\nbreak;\r\nif (!container->mm)\r\nreturn -EPERM;\r\nminsz = offsetofend(struct vfio_iommu_spapr_register_memory,\r\nsize);\r\nif (copy_from_user(&param, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (param.argsz < minsz)\r\nreturn -EINVAL;\r\nif (param.flags)\r\nreturn -EINVAL;\r\nmutex_lock(&container->lock);\r\nret = tce_iommu_unregister_pages(container, param.vaddr,\r\nparam.size);\r\nmutex_unlock(&container->lock);\r\nreturn ret;\r\n}\r\ncase VFIO_IOMMU_ENABLE:\r\nif (container->v2)\r\nbreak;\r\nmutex_lock(&container->lock);\r\nret = tce_iommu_enable(container);\r\nmutex_unlock(&container->lock);\r\nreturn ret;\r\ncase VFIO_IOMMU_DISABLE:\r\nif (container->v2)\r\nbreak;\r\nmutex_lock(&container->lock);\r\ntce_iommu_disable(container);\r\nmutex_unlock(&container->lock);\r\nreturn 0;\r\ncase VFIO_EEH_PE_OP: {\r\nstruct tce_iommu_group *tcegrp;\r\nret = 0;\r\nlist_for_each_entry(tcegrp, &container->group_list, next) {\r\nret = vfio_spapr_iommu_eeh_ioctl(tcegrp->grp,\r\ncmd, arg);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\ncase VFIO_IOMMU_SPAPR_TCE_CREATE: {\r\nstruct vfio_iommu_spapr_tce_create create;\r\nif (!container->v2)\r\nbreak;\r\nret = tce_iommu_mm_set(container);\r\nif (ret)\r\nreturn ret;\r\nif (!tce_groups_attached(container))\r\nreturn -ENXIO;\r\nminsz = offsetofend(struct vfio_iommu_spapr_tce_create,\r\nstart_addr);\r\nif (copy_from_user(&create, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (create.argsz < minsz)\r\nreturn -EINVAL;\r\nif (create.flags)\r\nreturn -EINVAL;\r\nmutex_lock(&container->lock);\r\nret = tce_iommu_create_default_window(container);\r\nif (!ret)\r\nret = tce_iommu_create_window(container,\r\ncreate.page_shift,\r\ncreate.window_size, create.levels,\r\n&create.start_addr);\r\nmutex_unlock(&container->lock);\r\nif (!ret && copy_to_user((void __user *)arg, &create, minsz))\r\nret = -EFAULT;\r\nreturn ret;\r\n}\r\ncase VFIO_IOMMU_SPAPR_TCE_REMOVE: {\r\nstruct vfio_iommu_spapr_tce_remove remove;\r\nif (!container->v2)\r\nbreak;\r\nret = tce_iommu_mm_set(container);\r\nif (ret)\r\nreturn ret;\r\nif (!tce_groups_attached(container))\r\nreturn -ENXIO;\r\nminsz = offsetofend(struct vfio_iommu_spapr_tce_remove,\r\nstart_addr);\r\nif (copy_from_user(&remove, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (remove.argsz < minsz)\r\nreturn -EINVAL;\r\nif (remove.flags)\r\nreturn -EINVAL;\r\nif (container->def_window_pending && !remove.start_addr) {\r\ncontainer->def_window_pending = false;\r\nreturn 0;\r\n}\r\nmutex_lock(&container->lock);\r\nret = tce_iommu_remove_window(container, remove.start_addr);\r\nmutex_unlock(&container->lock);\r\nreturn ret;\r\n}\r\n}\r\nreturn -ENOTTY;\r\n}\r\nstatic void tce_iommu_release_ownership(struct tce_container *container,\r\nstruct iommu_table_group *table_group)\r\n{\r\nint i;\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\r\nstruct iommu_table *tbl = container->tables[i];\r\nif (!tbl)\r\ncontinue;\r\ntce_iommu_clear(container, tbl, tbl->it_offset, tbl->it_size);\r\ntce_iommu_userspace_view_free(tbl, container->mm);\r\nif (tbl->it_map)\r\niommu_release_ownership(tbl);\r\ncontainer->tables[i] = NULL;\r\n}\r\n}\r\nstatic int tce_iommu_take_ownership(struct tce_container *container,\r\nstruct iommu_table_group *table_group)\r\n{\r\nint i, j, rc = 0;\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\r\nstruct iommu_table *tbl = table_group->tables[i];\r\nif (!tbl || !tbl->it_map)\r\ncontinue;\r\nrc = iommu_take_ownership(tbl);\r\nif (rc) {\r\nfor (j = 0; j < i; ++j)\r\niommu_release_ownership(\r\ntable_group->tables[j]);\r\nreturn rc;\r\n}\r\n}\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i)\r\ncontainer->tables[i] = table_group->tables[i];\r\nreturn 0;\r\n}\r\nstatic void tce_iommu_release_ownership_ddw(struct tce_container *container,\r\nstruct iommu_table_group *table_group)\r\n{\r\nlong i;\r\nif (!table_group->ops->unset_window) {\r\nWARN_ON_ONCE(1);\r\nreturn;\r\n}\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i)\r\ntable_group->ops->unset_window(table_group, i);\r\ntable_group->ops->release_ownership(table_group);\r\n}\r\nstatic long tce_iommu_take_ownership_ddw(struct tce_container *container,\r\nstruct iommu_table_group *table_group)\r\n{\r\nlong i, ret = 0;\r\nif (!table_group->ops->create_table || !table_group->ops->set_window ||\r\n!table_group->ops->release_ownership) {\r\nWARN_ON_ONCE(1);\r\nreturn -EFAULT;\r\n}\r\ntable_group->ops->take_ownership(table_group);\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i) {\r\nstruct iommu_table *tbl = container->tables[i];\r\nif (!tbl)\r\ncontinue;\r\nret = table_group->ops->set_window(table_group, i, tbl);\r\nif (ret)\r\ngoto release_exit;\r\n}\r\nreturn 0;\r\nrelease_exit:\r\nfor (i = 0; i < IOMMU_TABLE_GROUP_MAX_TABLES; ++i)\r\ntable_group->ops->unset_window(table_group, i);\r\ntable_group->ops->release_ownership(table_group);\r\nreturn ret;\r\n}\r\nstatic int tce_iommu_attach_group(void *iommu_data,\r\nstruct iommu_group *iommu_group)\r\n{\r\nint ret;\r\nstruct tce_container *container = iommu_data;\r\nstruct iommu_table_group *table_group;\r\nstruct tce_iommu_group *tcegrp = NULL;\r\nmutex_lock(&container->lock);\r\ntable_group = iommu_group_get_iommudata(iommu_group);\r\nif (!table_group) {\r\nret = -ENODEV;\r\ngoto unlock_exit;\r\n}\r\nif (tce_groups_attached(container) && (!table_group->ops ||\r\n!table_group->ops->take_ownership ||\r\n!table_group->ops->release_ownership)) {\r\nret = -EBUSY;\r\ngoto unlock_exit;\r\n}\r\nlist_for_each_entry(tcegrp, &container->group_list, next) {\r\nstruct iommu_table_group *table_group_tmp;\r\nif (tcegrp->grp == iommu_group) {\r\npr_warn("tce_vfio: Group %d is already attached\n",\r\niommu_group_id(iommu_group));\r\nret = -EBUSY;\r\ngoto unlock_exit;\r\n}\r\ntable_group_tmp = iommu_group_get_iommudata(tcegrp->grp);\r\nif (table_group_tmp->ops->create_table !=\r\ntable_group->ops->create_table) {\r\npr_warn("tce_vfio: Group %d is incompatible with group %d\n",\r\niommu_group_id(iommu_group),\r\niommu_group_id(tcegrp->grp));\r\nret = -EPERM;\r\ngoto unlock_exit;\r\n}\r\n}\r\ntcegrp = kzalloc(sizeof(*tcegrp), GFP_KERNEL);\r\nif (!tcegrp) {\r\nret = -ENOMEM;\r\ngoto unlock_exit;\r\n}\r\nif (!table_group->ops || !table_group->ops->take_ownership ||\r\n!table_group->ops->release_ownership) {\r\nif (container->v2) {\r\nret = -EPERM;\r\ngoto unlock_exit;\r\n}\r\nret = tce_iommu_take_ownership(container, table_group);\r\n} else {\r\nif (!container->v2) {\r\nret = -EPERM;\r\ngoto unlock_exit;\r\n}\r\nret = tce_iommu_take_ownership_ddw(container, table_group);\r\nif (!tce_groups_attached(container) && !container->tables[0])\r\ncontainer->def_window_pending = true;\r\n}\r\nif (!ret) {\r\ntcegrp->grp = iommu_group;\r\nlist_add(&tcegrp->next, &container->group_list);\r\n}\r\nunlock_exit:\r\nif (ret && tcegrp)\r\nkfree(tcegrp);\r\nmutex_unlock(&container->lock);\r\nreturn ret;\r\n}\r\nstatic void tce_iommu_detach_group(void *iommu_data,\r\nstruct iommu_group *iommu_group)\r\n{\r\nstruct tce_container *container = iommu_data;\r\nstruct iommu_table_group *table_group;\r\nbool found = false;\r\nstruct tce_iommu_group *tcegrp;\r\nmutex_lock(&container->lock);\r\nlist_for_each_entry(tcegrp, &container->group_list, next) {\r\nif (tcegrp->grp == iommu_group) {\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\npr_warn("tce_vfio: detaching unattached group #%u\n",\r\niommu_group_id(iommu_group));\r\ngoto unlock_exit;\r\n}\r\nlist_del(&tcegrp->next);\r\nkfree(tcegrp);\r\ntable_group = iommu_group_get_iommudata(iommu_group);\r\nBUG_ON(!table_group);\r\nif (!table_group->ops || !table_group->ops->release_ownership)\r\ntce_iommu_release_ownership(container, table_group);\r\nelse\r\ntce_iommu_release_ownership_ddw(container, table_group);\r\nunlock_exit:\r\nmutex_unlock(&container->lock);\r\n}\r\nstatic int __init tce_iommu_init(void)\r\n{\r\nreturn vfio_register_iommu_driver(&tce_iommu_driver_ops);\r\n}\r\nstatic void __exit tce_iommu_cleanup(void)\r\n{\r\nvfio_unregister_iommu_driver(&tce_iommu_driver_ops);\r\n}
