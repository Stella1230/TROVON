static u32 xdr_padsize(u32 len)\r\n{\r\nreturn (len & 3) ? (4 - (len & 3)) : 0;\r\n}\r\nstatic unsigned int svc_rdma_reply_hdr_len(__be32 *rdma_resp)\r\n{\r\nunsigned int nsegs;\r\n__be32 *p;\r\np = rdma_resp;\r\np += rpcrdma_fixed_maxsz + 1;\r\nwhile (*p++ != xdr_zero) {\r\nnsegs = be32_to_cpup(p++);\r\np += nsegs * rpcrdma_segment_maxsz;\r\n}\r\nif (*p++ != xdr_zero) {\r\nnsegs = be32_to_cpup(p++);\r\np += nsegs * rpcrdma_segment_maxsz;\r\n}\r\nreturn (unsigned long)p - (unsigned long)rdma_resp;\r\n}\r\nstatic unsigned int xdr_encode_write_chunk(__be32 *dst, __be32 *src,\r\nunsigned int remaining)\r\n{\r\nunsigned int i, nsegs;\r\nu32 seg_len;\r\n*dst++ = *src++;\r\nnsegs = be32_to_cpup(src);\r\n*dst++ = *src++;\r\nfor (i = nsegs; i; i--) {\r\n*dst++ = *src++;\r\nseg_len = be32_to_cpu(*src);\r\nif (remaining >= seg_len) {\r\n*dst = *src;\r\nremaining -= seg_len;\r\n} else {\r\n*dst = cpu_to_be32(remaining);\r\nremaining = 0;\r\n}\r\ndst++; src++;\r\n*dst++ = *src++;\r\n*dst++ = *src++;\r\n}\r\nreturn nsegs;\r\n}\r\nstatic void svc_rdma_xdr_encode_write_list(__be32 *rdma_resp, __be32 *wr_ch,\r\nunsigned int consumed)\r\n{\r\nunsigned int nsegs;\r\n__be32 *p, *q;\r\np = rdma_resp + rpcrdma_fixed_maxsz + 1;\r\nq = wr_ch;\r\nwhile (*q != xdr_zero) {\r\nnsegs = xdr_encode_write_chunk(p, q, consumed);\r\nq += 2 + nsegs * rpcrdma_segment_maxsz;\r\np += 2 + nsegs * rpcrdma_segment_maxsz;\r\nconsumed = 0;\r\n}\r\n*p++ = xdr_zero;\r\n*p = xdr_zero;\r\n}\r\nstatic void svc_rdma_xdr_encode_reply_chunk(__be32 *rdma_resp, __be32 *rp_ch,\r\nunsigned int consumed)\r\n{\r\n__be32 *p;\r\np = rdma_resp + rpcrdma_fixed_maxsz + 1;\r\nwhile (*p++ != xdr_zero)\r\np += 1 + be32_to_cpup(p) * rpcrdma_segment_maxsz;\r\nxdr_encode_write_chunk(p, rp_ch, consumed);\r\n}\r\nstatic void svc_rdma_get_write_arrays(__be32 *rdma_argp,\r\n__be32 **write, __be32 **reply)\r\n{\r\n__be32 *p;\r\np = rdma_argp + rpcrdma_fixed_maxsz;\r\nwhile (*p++ != xdr_zero)\r\np += 5;\r\nif (*p != xdr_zero) {\r\n*write = p;\r\nwhile (*p++ != xdr_zero)\r\np += 1 + be32_to_cpu(*p) * 4;\r\n} else {\r\n*write = NULL;\r\np++;\r\n}\r\nif (*p != xdr_zero)\r\n*reply = p;\r\nelse\r\n*reply = NULL;\r\n}\r\nstatic u32 svc_rdma_get_inv_rkey(__be32 *rdma_argp,\r\n__be32 *wr_lst, __be32 *rp_ch)\r\n{\r\n__be32 *p;\r\np = rdma_argp + rpcrdma_fixed_maxsz;\r\nif (*p != xdr_zero)\r\np += 2;\r\nelse if (wr_lst && be32_to_cpup(wr_lst + 1))\r\np = wr_lst + 2;\r\nelse if (rp_ch && be32_to_cpup(rp_ch + 1))\r\np = rp_ch + 2;\r\nelse\r\nreturn 0;\r\nreturn be32_to_cpup(p);\r\n}\r\nstatic int svc_rdma_dma_map_buf(struct svcxprt_rdma *rdma,\r\nstruct svc_rdma_op_ctxt *ctxt,\r\nunsigned int sge_no,\r\nunsigned char *base,\r\nunsigned int len)\r\n{\r\nunsigned long offset = (unsigned long)base & ~PAGE_MASK;\r\nstruct ib_device *dev = rdma->sc_cm_id->device;\r\ndma_addr_t dma_addr;\r\ndma_addr = ib_dma_map_page(dev, virt_to_page(base),\r\noffset, len, DMA_TO_DEVICE);\r\nif (ib_dma_mapping_error(dev, dma_addr))\r\ngoto out_maperr;\r\nctxt->sge[sge_no].addr = dma_addr;\r\nctxt->sge[sge_no].length = len;\r\nctxt->sge[sge_no].lkey = rdma->sc_pd->local_dma_lkey;\r\nsvc_rdma_count_mappings(rdma, ctxt);\r\nreturn 0;\r\nout_maperr:\r\npr_err("svcrdma: failed to map buffer\n");\r\nreturn -EIO;\r\n}\r\nstatic int svc_rdma_dma_map_page(struct svcxprt_rdma *rdma,\r\nstruct svc_rdma_op_ctxt *ctxt,\r\nunsigned int sge_no,\r\nstruct page *page,\r\nunsigned int offset,\r\nunsigned int len)\r\n{\r\nstruct ib_device *dev = rdma->sc_cm_id->device;\r\ndma_addr_t dma_addr;\r\ndma_addr = ib_dma_map_page(dev, page, offset, len, DMA_TO_DEVICE);\r\nif (ib_dma_mapping_error(dev, dma_addr))\r\ngoto out_maperr;\r\nctxt->sge[sge_no].addr = dma_addr;\r\nctxt->sge[sge_no].length = len;\r\nctxt->sge[sge_no].lkey = rdma->sc_pd->local_dma_lkey;\r\nsvc_rdma_count_mappings(rdma, ctxt);\r\nreturn 0;\r\nout_maperr:\r\npr_err("svcrdma: failed to map page\n");\r\nreturn -EIO;\r\n}\r\nint svc_rdma_map_reply_hdr(struct svcxprt_rdma *rdma,\r\nstruct svc_rdma_op_ctxt *ctxt,\r\n__be32 *rdma_resp,\r\nunsigned int len)\r\n{\r\nctxt->direction = DMA_TO_DEVICE;\r\nctxt->pages[0] = virt_to_page(rdma_resp);\r\nctxt->count = 1;\r\nreturn svc_rdma_dma_map_page(rdma, ctxt, 0, ctxt->pages[0], 0, len);\r\n}\r\nstatic int svc_rdma_map_reply_msg(struct svcxprt_rdma *rdma,\r\nstruct svc_rdma_op_ctxt *ctxt,\r\nstruct xdr_buf *xdr, __be32 *wr_lst)\r\n{\r\nunsigned int len, sge_no, remaining, page_off;\r\nstruct page **ppages;\r\nunsigned char *base;\r\nu32 xdr_pad;\r\nint ret;\r\nsge_no = 1;\r\nret = svc_rdma_dma_map_buf(rdma, ctxt, sge_no++,\r\nxdr->head[0].iov_base,\r\nxdr->head[0].iov_len);\r\nif (ret < 0)\r\nreturn ret;\r\nif (wr_lst) {\r\nbase = xdr->tail[0].iov_base;\r\nlen = xdr->tail[0].iov_len;\r\nxdr_pad = xdr_padsize(xdr->page_len);\r\nif (len && xdr_pad) {\r\nbase += xdr_pad;\r\nlen -= xdr_pad;\r\n}\r\ngoto tail;\r\n}\r\nppages = xdr->pages + (xdr->page_base >> PAGE_SHIFT);\r\npage_off = xdr->page_base & ~PAGE_MASK;\r\nremaining = xdr->page_len;\r\nwhile (remaining) {\r\nlen = min_t(u32, PAGE_SIZE - page_off, remaining);\r\nret = svc_rdma_dma_map_page(rdma, ctxt, sge_no++,\r\n*ppages++, page_off, len);\r\nif (ret < 0)\r\nreturn ret;\r\nremaining -= len;\r\npage_off = 0;\r\n}\r\nbase = xdr->tail[0].iov_base;\r\nlen = xdr->tail[0].iov_len;\r\ntail:\r\nif (len) {\r\nret = svc_rdma_dma_map_buf(rdma, ctxt, sge_no++, base, len);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\nreturn sge_no - 1;\r\n}\r\nstatic void svc_rdma_save_io_pages(struct svc_rqst *rqstp,\r\nstruct svc_rdma_op_ctxt *ctxt)\r\n{\r\nint i, pages = rqstp->rq_next_page - rqstp->rq_respages;\r\nctxt->count += pages;\r\nfor (i = 0; i < pages; i++) {\r\nctxt->pages[i + 1] = rqstp->rq_respages[i];\r\nrqstp->rq_respages[i] = NULL;\r\n}\r\nrqstp->rq_next_page = rqstp->rq_respages + 1;\r\n}\r\nint svc_rdma_post_send_wr(struct svcxprt_rdma *rdma,\r\nstruct svc_rdma_op_ctxt *ctxt, int num_sge,\r\nu32 inv_rkey)\r\n{\r\nstruct ib_send_wr *send_wr = &ctxt->send_wr;\r\ndprintk("svcrdma: posting Send WR with %u sge(s)\n", num_sge);\r\nsend_wr->next = NULL;\r\nctxt->cqe.done = svc_rdma_wc_send;\r\nsend_wr->wr_cqe = &ctxt->cqe;\r\nsend_wr->sg_list = ctxt->sge;\r\nsend_wr->num_sge = num_sge;\r\nsend_wr->send_flags = IB_SEND_SIGNALED;\r\nif (inv_rkey) {\r\nsend_wr->opcode = IB_WR_SEND_WITH_INV;\r\nsend_wr->ex.invalidate_rkey = inv_rkey;\r\n} else {\r\nsend_wr->opcode = IB_WR_SEND;\r\n}\r\nreturn svc_rdma_send(rdma, send_wr);\r\n}\r\nstatic int svc_rdma_send_reply_msg(struct svcxprt_rdma *rdma,\r\n__be32 *rdma_argp, __be32 *rdma_resp,\r\nstruct svc_rqst *rqstp,\r\n__be32 *wr_lst, __be32 *rp_ch)\r\n{\r\nstruct svc_rdma_op_ctxt *ctxt;\r\nu32 inv_rkey;\r\nint ret;\r\ndprintk("svcrdma: sending %s reply: head=%zu, pagelen=%u, tail=%zu\n",\r\n(rp_ch ? "RDMA_NOMSG" : "RDMA_MSG"),\r\nrqstp->rq_res.head[0].iov_len,\r\nrqstp->rq_res.page_len,\r\nrqstp->rq_res.tail[0].iov_len);\r\nctxt = svc_rdma_get_context(rdma);\r\nret = svc_rdma_map_reply_hdr(rdma, ctxt, rdma_resp,\r\nsvc_rdma_reply_hdr_len(rdma_resp));\r\nif (ret < 0)\r\ngoto err;\r\nif (!rp_ch) {\r\nret = svc_rdma_map_reply_msg(rdma, ctxt,\r\n&rqstp->rq_res, wr_lst);\r\nif (ret < 0)\r\ngoto err;\r\n}\r\nsvc_rdma_save_io_pages(rqstp, ctxt);\r\ninv_rkey = 0;\r\nif (rdma->sc_snd_w_inv)\r\ninv_rkey = svc_rdma_get_inv_rkey(rdma_argp, wr_lst, rp_ch);\r\nret = svc_rdma_post_send_wr(rdma, ctxt, 1 + ret, inv_rkey);\r\nif (ret)\r\ngoto err;\r\nreturn 0;\r\nerr:\r\nsvc_rdma_unmap_dma(ctxt);\r\nsvc_rdma_put_context(ctxt, 1);\r\nreturn ret;\r\n}\r\nstatic int svc_rdma_send_error_msg(struct svcxprt_rdma *rdma,\r\n__be32 *rdma_resp, struct svc_rqst *rqstp)\r\n{\r\nstruct svc_rdma_op_ctxt *ctxt;\r\n__be32 *p;\r\nint ret;\r\nctxt = svc_rdma_get_context(rdma);\r\np = rdma_resp + 3;\r\n*p++ = rdma_error;\r\n*p = err_chunk;\r\nret = svc_rdma_map_reply_hdr(rdma, ctxt, rdma_resp, 20);\r\nif (ret < 0)\r\ngoto err;\r\nsvc_rdma_save_io_pages(rqstp, ctxt);\r\nret = svc_rdma_post_send_wr(rdma, ctxt, 1 + ret, 0);\r\nif (ret)\r\ngoto err;\r\nreturn 0;\r\nerr:\r\npr_err("svcrdma: failed to post Send WR (%d)\n", ret);\r\nsvc_rdma_unmap_dma(ctxt);\r\nsvc_rdma_put_context(ctxt, 1);\r\nreturn ret;\r\n}\r\nvoid svc_rdma_prep_reply_hdr(struct svc_rqst *rqstp)\r\n{\r\n}\r\nint svc_rdma_sendto(struct svc_rqst *rqstp)\r\n{\r\nstruct svc_xprt *xprt = rqstp->rq_xprt;\r\nstruct svcxprt_rdma *rdma =\r\ncontainer_of(xprt, struct svcxprt_rdma, sc_xprt);\r\n__be32 *p, *rdma_argp, *rdma_resp, *wr_lst, *rp_ch;\r\nstruct xdr_buf *xdr = &rqstp->rq_res;\r\nstruct page *res_page;\r\nint ret;\r\nrdma_argp = page_address(rqstp->rq_pages[0]);\r\nsvc_rdma_get_write_arrays(rdma_argp, &wr_lst, &rp_ch);\r\ndprintk("svcrdma: preparing response for XID 0x%08x\n",\r\nbe32_to_cpup(rdma_argp));\r\nret = -ENOMEM;\r\nres_page = alloc_page(GFP_KERNEL);\r\nif (!res_page)\r\ngoto err0;\r\nrdma_resp = page_address(res_page);\r\np = rdma_resp;\r\n*p++ = *rdma_argp;\r\n*p++ = *(rdma_argp + 1);\r\n*p++ = rdma->sc_fc_credits;\r\n*p++ = rp_ch ? rdma_nomsg : rdma_msg;\r\n*p++ = xdr_zero;\r\n*p++ = xdr_zero;\r\n*p = xdr_zero;\r\nif (wr_lst) {\r\nret = svc_rdma_send_write_chunk(rdma, wr_lst, xdr);\r\nif (ret < 0)\r\ngoto err2;\r\nsvc_rdma_xdr_encode_write_list(rdma_resp, wr_lst, ret);\r\n}\r\nif (rp_ch) {\r\nret = svc_rdma_send_reply_chunk(rdma, rp_ch, wr_lst, xdr);\r\nif (ret < 0)\r\ngoto err2;\r\nsvc_rdma_xdr_encode_reply_chunk(rdma_resp, rp_ch, ret);\r\n}\r\nret = svc_rdma_post_recv(rdma, GFP_KERNEL);\r\nif (ret)\r\ngoto err1;\r\nret = svc_rdma_send_reply_msg(rdma, rdma_argp, rdma_resp, rqstp,\r\nwr_lst, rp_ch);\r\nif (ret < 0)\r\ngoto err0;\r\nreturn 0;\r\nerr2:\r\nif (ret != -E2BIG && ret != -EINVAL)\r\ngoto err1;\r\nret = svc_rdma_post_recv(rdma, GFP_KERNEL);\r\nif (ret)\r\ngoto err1;\r\nret = svc_rdma_send_error_msg(rdma, rdma_resp, rqstp);\r\nif (ret < 0)\r\ngoto err0;\r\nreturn 0;\r\nerr1:\r\nput_page(res_page);\r\nerr0:\r\npr_err("svcrdma: Could not send reply, err=%d. Closing transport.\n",\r\nret);\r\nset_bit(XPT_CLOSE, &xprt->xpt_flags);\r\nreturn -ENOTCONN;\r\n}
