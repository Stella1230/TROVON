static inline u32 gtp0_hashfn(u64 tid)\r\n{\r\nu32 *tid32 = (u32 *) &tid;\r\nreturn jhash_2words(tid32[0], tid32[1], gtp_h_initval);\r\n}\r\nstatic inline u32 gtp1u_hashfn(u32 tid)\r\n{\r\nreturn jhash_1word(tid, gtp_h_initval);\r\n}\r\nstatic inline u32 ipv4_hashfn(__be32 ip)\r\n{\r\nreturn jhash_1word((__force u32)ip, gtp_h_initval);\r\n}\r\nstatic struct pdp_ctx *gtp0_pdp_find(struct gtp_dev *gtp, u64 tid)\r\n{\r\nstruct hlist_head *head;\r\nstruct pdp_ctx *pdp;\r\nhead = &gtp->tid_hash[gtp0_hashfn(tid) % gtp->hash_size];\r\nhlist_for_each_entry_rcu(pdp, head, hlist_tid) {\r\nif (pdp->gtp_version == GTP_V0 &&\r\npdp->u.v0.tid == tid)\r\nreturn pdp;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct pdp_ctx *gtp1_pdp_find(struct gtp_dev *gtp, u32 tid)\r\n{\r\nstruct hlist_head *head;\r\nstruct pdp_ctx *pdp;\r\nhead = &gtp->tid_hash[gtp1u_hashfn(tid) % gtp->hash_size];\r\nhlist_for_each_entry_rcu(pdp, head, hlist_tid) {\r\nif (pdp->gtp_version == GTP_V1 &&\r\npdp->u.v1.i_tei == tid)\r\nreturn pdp;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct pdp_ctx *ipv4_pdp_find(struct gtp_dev *gtp, __be32 ms_addr)\r\n{\r\nstruct hlist_head *head;\r\nstruct pdp_ctx *pdp;\r\nhead = &gtp->addr_hash[ipv4_hashfn(ms_addr) % gtp->hash_size];\r\nhlist_for_each_entry_rcu(pdp, head, hlist_addr) {\r\nif (pdp->af == AF_INET &&\r\npdp->ms_addr_ip4.s_addr == ms_addr)\r\nreturn pdp;\r\n}\r\nreturn NULL;\r\n}\r\nstatic bool gtp_check_ms_ipv4(struct sk_buff *skb, struct pdp_ctx *pctx,\r\nunsigned int hdrlen, unsigned int role)\r\n{\r\nstruct iphdr *iph;\r\nif (!pskb_may_pull(skb, hdrlen + sizeof(struct iphdr)))\r\nreturn false;\r\niph = (struct iphdr *)(skb->data + hdrlen);\r\nif (role == GTP_ROLE_SGSN)\r\nreturn iph->daddr == pctx->ms_addr_ip4.s_addr;\r\nelse\r\nreturn iph->saddr == pctx->ms_addr_ip4.s_addr;\r\n}\r\nstatic bool gtp_check_ms(struct sk_buff *skb, struct pdp_ctx *pctx,\r\nunsigned int hdrlen, unsigned int role)\r\n{\r\nswitch (ntohs(skb->protocol)) {\r\ncase ETH_P_IP:\r\nreturn gtp_check_ms_ipv4(skb, pctx, hdrlen, role);\r\n}\r\nreturn false;\r\n}\r\nstatic int gtp_rx(struct pdp_ctx *pctx, struct sk_buff *skb,\r\nunsigned int hdrlen, unsigned int role)\r\n{\r\nstruct pcpu_sw_netstats *stats;\r\nif (!gtp_check_ms(skb, pctx, hdrlen, role)) {\r\nnetdev_dbg(pctx->dev, "No PDP ctx for this MS\n");\r\nreturn 1;\r\n}\r\nif (iptunnel_pull_header(skb, hdrlen, skb->protocol,\r\n!net_eq(sock_net(pctx->sk), dev_net(pctx->dev))))\r\nreturn -1;\r\nnetdev_dbg(pctx->dev, "forwarding packet from GGSN to uplink\n");\r\nskb_reset_network_header(skb);\r\nskb->dev = pctx->dev;\r\nstats = this_cpu_ptr(pctx->dev->tstats);\r\nu64_stats_update_begin(&stats->syncp);\r\nstats->rx_packets++;\r\nstats->rx_bytes += skb->len;\r\nu64_stats_update_end(&stats->syncp);\r\nnetif_rx(skb);\r\nreturn 0;\r\n}\r\nstatic int gtp0_udp_encap_recv(struct gtp_dev *gtp, struct sk_buff *skb)\r\n{\r\nunsigned int hdrlen = sizeof(struct udphdr) +\r\nsizeof(struct gtp0_header);\r\nstruct gtp0_header *gtp0;\r\nstruct pdp_ctx *pctx;\r\nif (!pskb_may_pull(skb, hdrlen))\r\nreturn -1;\r\ngtp0 = (struct gtp0_header *)(skb->data + sizeof(struct udphdr));\r\nif ((gtp0->flags >> 5) != GTP_V0)\r\nreturn 1;\r\nif (gtp0->type != GTP_TPDU)\r\nreturn 1;\r\npctx = gtp0_pdp_find(gtp, be64_to_cpu(gtp0->tid));\r\nif (!pctx) {\r\nnetdev_dbg(gtp->dev, "No PDP ctx to decap skb=%p\n", skb);\r\nreturn 1;\r\n}\r\nreturn gtp_rx(pctx, skb, hdrlen, gtp->role);\r\n}\r\nstatic int gtp1u_udp_encap_recv(struct gtp_dev *gtp, struct sk_buff *skb)\r\n{\r\nunsigned int hdrlen = sizeof(struct udphdr) +\r\nsizeof(struct gtp1_header);\r\nstruct gtp1_header *gtp1;\r\nstruct pdp_ctx *pctx;\r\nif (!pskb_may_pull(skb, hdrlen))\r\nreturn -1;\r\ngtp1 = (struct gtp1_header *)(skb->data + sizeof(struct udphdr));\r\nif ((gtp1->flags >> 5) != GTP_V1)\r\nreturn 1;\r\nif (gtp1->type != GTP_TPDU)\r\nreturn 1;\r\nif (gtp1->flags & GTP1_F_MASK)\r\nhdrlen += 4;\r\nif (!pskb_may_pull(skb, hdrlen))\r\nreturn -1;\r\ngtp1 = (struct gtp1_header *)(skb->data + sizeof(struct udphdr));\r\npctx = gtp1_pdp_find(gtp, ntohl(gtp1->tid));\r\nif (!pctx) {\r\nnetdev_dbg(gtp->dev, "No PDP ctx to decap skb=%p\n", skb);\r\nreturn 1;\r\n}\r\nreturn gtp_rx(pctx, skb, hdrlen, gtp->role);\r\n}\r\nstatic void gtp_encap_destroy(struct sock *sk)\r\n{\r\nstruct gtp_dev *gtp;\r\ngtp = rcu_dereference_sk_user_data(sk);\r\nif (gtp) {\r\nudp_sk(sk)->encap_type = 0;\r\nrcu_assign_sk_user_data(sk, NULL);\r\nsock_put(sk);\r\n}\r\n}\r\nstatic void gtp_encap_disable_sock(struct sock *sk)\r\n{\r\nif (!sk)\r\nreturn;\r\ngtp_encap_destroy(sk);\r\n}\r\nstatic void gtp_encap_disable(struct gtp_dev *gtp)\r\n{\r\ngtp_encap_disable_sock(gtp->sk0);\r\ngtp_encap_disable_sock(gtp->sk1u);\r\n}\r\nstatic int gtp_encap_recv(struct sock *sk, struct sk_buff *skb)\r\n{\r\nstruct gtp_dev *gtp;\r\nint ret = 0;\r\ngtp = rcu_dereference_sk_user_data(sk);\r\nif (!gtp)\r\nreturn 1;\r\nnetdev_dbg(gtp->dev, "encap_recv sk=%p\n", sk);\r\nswitch (udp_sk(sk)->encap_type) {\r\ncase UDP_ENCAP_GTP0:\r\nnetdev_dbg(gtp->dev, "received GTP0 packet\n");\r\nret = gtp0_udp_encap_recv(gtp, skb);\r\nbreak;\r\ncase UDP_ENCAP_GTP1U:\r\nnetdev_dbg(gtp->dev, "received GTP1U packet\n");\r\nret = gtp1u_udp_encap_recv(gtp, skb);\r\nbreak;\r\ndefault:\r\nret = -1;\r\n}\r\nswitch (ret) {\r\ncase 1:\r\nnetdev_dbg(gtp->dev, "pass up to the process\n");\r\nbreak;\r\ncase 0:\r\nbreak;\r\ncase -1:\r\nnetdev_dbg(gtp->dev, "GTP packet has been dropped\n");\r\nkfree_skb(skb);\r\nret = 0;\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int gtp_dev_init(struct net_device *dev)\r\n{\r\nstruct gtp_dev *gtp = netdev_priv(dev);\r\ngtp->dev = dev;\r\ndev->tstats = netdev_alloc_pcpu_stats(struct pcpu_sw_netstats);\r\nif (!dev->tstats)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic void gtp_dev_uninit(struct net_device *dev)\r\n{\r\nstruct gtp_dev *gtp = netdev_priv(dev);\r\ngtp_encap_disable(gtp);\r\nfree_percpu(dev->tstats);\r\n}\r\nstatic struct rtable *ip4_route_output_gtp(struct flowi4 *fl4,\r\nconst struct sock *sk,\r\n__be32 daddr)\r\n{\r\nmemset(fl4, 0, sizeof(*fl4));\r\nfl4->flowi4_oif = sk->sk_bound_dev_if;\r\nfl4->daddr = daddr;\r\nfl4->saddr = inet_sk(sk)->inet_saddr;\r\nfl4->flowi4_tos = RT_CONN_FLAGS(sk);\r\nfl4->flowi4_proto = sk->sk_protocol;\r\nreturn ip_route_output_key(sock_net(sk), fl4);\r\n}\r\nstatic inline void gtp0_push_header(struct sk_buff *skb, struct pdp_ctx *pctx)\r\n{\r\nint payload_len = skb->len;\r\nstruct gtp0_header *gtp0;\r\ngtp0 = skb_push(skb, sizeof(*gtp0));\r\ngtp0->flags = 0x1e;\r\ngtp0->type = GTP_TPDU;\r\ngtp0->length = htons(payload_len);\r\ngtp0->seq = htons((atomic_inc_return(&pctx->tx_seq) - 1) % 0xffff);\r\ngtp0->flow = htons(pctx->u.v0.flow);\r\ngtp0->number = 0xff;\r\ngtp0->spare[0] = gtp0->spare[1] = gtp0->spare[2] = 0xff;\r\ngtp0->tid = cpu_to_be64(pctx->u.v0.tid);\r\n}\r\nstatic inline void gtp1_push_header(struct sk_buff *skb, struct pdp_ctx *pctx)\r\n{\r\nint payload_len = skb->len;\r\nstruct gtp1_header *gtp1;\r\ngtp1 = skb_push(skb, sizeof(*gtp1));\r\ngtp1->flags = 0x30;\r\ngtp1->type = GTP_TPDU;\r\ngtp1->length = htons(payload_len);\r\ngtp1->tid = htonl(pctx->u.v1.o_tei);\r\n}\r\nstatic void gtp_push_header(struct sk_buff *skb, struct gtp_pktinfo *pktinfo)\r\n{\r\nswitch (pktinfo->pctx->gtp_version) {\r\ncase GTP_V0:\r\npktinfo->gtph_port = htons(GTP0_PORT);\r\ngtp0_push_header(skb, pktinfo->pctx);\r\nbreak;\r\ncase GTP_V1:\r\npktinfo->gtph_port = htons(GTP1U_PORT);\r\ngtp1_push_header(skb, pktinfo->pctx);\r\nbreak;\r\n}\r\n}\r\nstatic inline void gtp_set_pktinfo_ipv4(struct gtp_pktinfo *pktinfo,\r\nstruct sock *sk, struct iphdr *iph,\r\nstruct pdp_ctx *pctx, struct rtable *rt,\r\nstruct flowi4 *fl4,\r\nstruct net_device *dev)\r\n{\r\npktinfo->sk = sk;\r\npktinfo->iph = iph;\r\npktinfo->pctx = pctx;\r\npktinfo->rt = rt;\r\npktinfo->fl4 = *fl4;\r\npktinfo->dev = dev;\r\n}\r\nstatic int gtp_build_skb_ip4(struct sk_buff *skb, struct net_device *dev,\r\nstruct gtp_pktinfo *pktinfo)\r\n{\r\nstruct gtp_dev *gtp = netdev_priv(dev);\r\nstruct pdp_ctx *pctx;\r\nstruct rtable *rt;\r\nstruct flowi4 fl4;\r\nstruct iphdr *iph;\r\n__be16 df;\r\nint mtu;\r\niph = ip_hdr(skb);\r\nif (gtp->role == GTP_ROLE_SGSN)\r\npctx = ipv4_pdp_find(gtp, iph->saddr);\r\nelse\r\npctx = ipv4_pdp_find(gtp, iph->daddr);\r\nif (!pctx) {\r\nnetdev_dbg(dev, "no PDP ctx found for %pI4, skip\n",\r\n&iph->daddr);\r\nreturn -ENOENT;\r\n}\r\nnetdev_dbg(dev, "found PDP context %p\n", pctx);\r\nrt = ip4_route_output_gtp(&fl4, pctx->sk, pctx->peer_addr_ip4.s_addr);\r\nif (IS_ERR(rt)) {\r\nnetdev_dbg(dev, "no route to SSGN %pI4\n",\r\n&pctx->peer_addr_ip4.s_addr);\r\ndev->stats.tx_carrier_errors++;\r\ngoto err;\r\n}\r\nif (rt->dst.dev == dev) {\r\nnetdev_dbg(dev, "circular route to SSGN %pI4\n",\r\n&pctx->peer_addr_ip4.s_addr);\r\ndev->stats.collisions++;\r\ngoto err_rt;\r\n}\r\nskb_dst_drop(skb);\r\ndf = iph->frag_off;\r\nif (df) {\r\nmtu = dst_mtu(&rt->dst) - dev->hard_header_len -\r\nsizeof(struct iphdr) - sizeof(struct udphdr);\r\nswitch (pctx->gtp_version) {\r\ncase GTP_V0:\r\nmtu -= sizeof(struct gtp0_header);\r\nbreak;\r\ncase GTP_V1:\r\nmtu -= sizeof(struct gtp1_header);\r\nbreak;\r\n}\r\n} else {\r\nmtu = dst_mtu(&rt->dst);\r\n}\r\nrt->dst.ops->update_pmtu(&rt->dst, NULL, skb, mtu);\r\nif (!skb_is_gso(skb) && (iph->frag_off & htons(IP_DF)) &&\r\nmtu < ntohs(iph->tot_len)) {\r\nnetdev_dbg(dev, "packet too big, fragmentation needed\n");\r\nmemset(IPCB(skb), 0, sizeof(*IPCB(skb)));\r\nicmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,\r\nhtonl(mtu));\r\ngoto err_rt;\r\n}\r\ngtp_set_pktinfo_ipv4(pktinfo, pctx->sk, iph, pctx, rt, &fl4, dev);\r\ngtp_push_header(skb, pktinfo);\r\nreturn 0;\r\nerr_rt:\r\nip_rt_put(rt);\r\nerr:\r\nreturn -EBADMSG;\r\n}\r\nstatic netdev_tx_t gtp_dev_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nunsigned int proto = ntohs(skb->protocol);\r\nstruct gtp_pktinfo pktinfo;\r\nint err;\r\nif (skb_cow_head(skb, dev->needed_headroom))\r\ngoto tx_err;\r\nskb_reset_inner_headers(skb);\r\nrcu_read_lock();\r\nswitch (proto) {\r\ncase ETH_P_IP:\r\nerr = gtp_build_skb_ip4(skb, dev, &pktinfo);\r\nbreak;\r\ndefault:\r\nerr = -EOPNOTSUPP;\r\nbreak;\r\n}\r\nrcu_read_unlock();\r\nif (err < 0)\r\ngoto tx_err;\r\nswitch (proto) {\r\ncase ETH_P_IP:\r\nnetdev_dbg(pktinfo.dev, "gtp -> IP src: %pI4 dst: %pI4\n",\r\n&pktinfo.iph->saddr, &pktinfo.iph->daddr);\r\nudp_tunnel_xmit_skb(pktinfo.rt, pktinfo.sk, skb,\r\npktinfo.fl4.saddr, pktinfo.fl4.daddr,\r\npktinfo.iph->tos,\r\nip4_dst_hoplimit(&pktinfo.rt->dst),\r\n0,\r\npktinfo.gtph_port, pktinfo.gtph_port,\r\ntrue, false);\r\nbreak;\r\n}\r\nreturn NETDEV_TX_OK;\r\ntx_err:\r\ndev->stats.tx_errors++;\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void gtp_link_setup(struct net_device *dev)\r\n{\r\ndev->netdev_ops = &gtp_netdev_ops;\r\ndev->needs_free_netdev = true;\r\ndev->hard_header_len = 0;\r\ndev->addr_len = 0;\r\ndev->type = ARPHRD_NONE;\r\ndev->flags = IFF_POINTOPOINT | IFF_NOARP | IFF_MULTICAST;\r\ndev->priv_flags |= IFF_NO_QUEUE;\r\ndev->features |= NETIF_F_LLTX;\r\nnetif_keep_dst(dev);\r\ndev->needed_headroom = LL_MAX_HEADER +\r\nsizeof(struct iphdr) +\r\nsizeof(struct udphdr) +\r\nsizeof(struct gtp0_header);\r\n}\r\nstatic int gtp_newlink(struct net *src_net, struct net_device *dev,\r\nstruct nlattr *tb[], struct nlattr *data[],\r\nstruct netlink_ext_ack *extack)\r\n{\r\nstruct gtp_dev *gtp;\r\nstruct gtp_net *gn;\r\nint hashsize, err;\r\nif (!data[IFLA_GTP_FD0] && !data[IFLA_GTP_FD1])\r\nreturn -EINVAL;\r\ngtp = netdev_priv(dev);\r\nerr = gtp_encap_enable(gtp, data);\r\nif (err < 0)\r\nreturn err;\r\nif (!data[IFLA_GTP_PDP_HASHSIZE])\r\nhashsize = 1024;\r\nelse\r\nhashsize = nla_get_u32(data[IFLA_GTP_PDP_HASHSIZE]);\r\nerr = gtp_hashtable_new(gtp, hashsize);\r\nif (err < 0)\r\ngoto out_encap;\r\nerr = register_netdevice(dev);\r\nif (err < 0) {\r\nnetdev_dbg(dev, "failed to register new netdev %d\n", err);\r\ngoto out_hashtable;\r\n}\r\ngn = net_generic(dev_net(dev), gtp_net_id);\r\nlist_add_rcu(&gtp->list, &gn->gtp_dev_list);\r\nnetdev_dbg(dev, "registered new GTP interface\n");\r\nreturn 0;\r\nout_hashtable:\r\ngtp_hashtable_free(gtp);\r\nout_encap:\r\ngtp_encap_disable(gtp);\r\nreturn err;\r\n}\r\nstatic void gtp_dellink(struct net_device *dev, struct list_head *head)\r\n{\r\nstruct gtp_dev *gtp = netdev_priv(dev);\r\ngtp_encap_disable(gtp);\r\ngtp_hashtable_free(gtp);\r\nlist_del_rcu(&gtp->list);\r\nunregister_netdevice_queue(dev, head);\r\n}\r\nstatic int gtp_validate(struct nlattr *tb[], struct nlattr *data[],\r\nstruct netlink_ext_ack *extack)\r\n{\r\nif (!data)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic size_t gtp_get_size(const struct net_device *dev)\r\n{\r\nreturn nla_total_size(sizeof(__u32));\r\n}\r\nstatic int gtp_fill_info(struct sk_buff *skb, const struct net_device *dev)\r\n{\r\nstruct gtp_dev *gtp = netdev_priv(dev);\r\nif (nla_put_u32(skb, IFLA_GTP_PDP_HASHSIZE, gtp->hash_size))\r\ngoto nla_put_failure;\r\nreturn 0;\r\nnla_put_failure:\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int gtp_hashtable_new(struct gtp_dev *gtp, int hsize)\r\n{\r\nint i;\r\ngtp->addr_hash = kmalloc(sizeof(struct hlist_head) * hsize, GFP_KERNEL);\r\nif (gtp->addr_hash == NULL)\r\nreturn -ENOMEM;\r\ngtp->tid_hash = kmalloc(sizeof(struct hlist_head) * hsize, GFP_KERNEL);\r\nif (gtp->tid_hash == NULL)\r\ngoto err1;\r\ngtp->hash_size = hsize;\r\nfor (i = 0; i < hsize; i++) {\r\nINIT_HLIST_HEAD(&gtp->addr_hash[i]);\r\nINIT_HLIST_HEAD(&gtp->tid_hash[i]);\r\n}\r\nreturn 0;\r\nerr1:\r\nkfree(gtp->addr_hash);\r\nreturn -ENOMEM;\r\n}\r\nstatic void gtp_hashtable_free(struct gtp_dev *gtp)\r\n{\r\nstruct pdp_ctx *pctx;\r\nint i;\r\nfor (i = 0; i < gtp->hash_size; i++)\r\nhlist_for_each_entry_rcu(pctx, &gtp->tid_hash[i], hlist_tid)\r\npdp_context_delete(pctx);\r\nsynchronize_rcu();\r\nkfree(gtp->addr_hash);\r\nkfree(gtp->tid_hash);\r\n}\r\nstatic struct sock *gtp_encap_enable_socket(int fd, int type,\r\nstruct gtp_dev *gtp)\r\n{\r\nstruct udp_tunnel_sock_cfg tuncfg = {NULL};\r\nstruct socket *sock;\r\nstruct sock *sk;\r\nint err;\r\npr_debug("enable gtp on %d, %d\n", fd, type);\r\nsock = sockfd_lookup(fd, &err);\r\nif (!sock) {\r\npr_debug("gtp socket fd=%d not found\n", fd);\r\nreturn NULL;\r\n}\r\nif (sock->sk->sk_protocol != IPPROTO_UDP) {\r\npr_debug("socket fd=%d not UDP\n", fd);\r\nsk = ERR_PTR(-EINVAL);\r\ngoto out_sock;\r\n}\r\nif (rcu_dereference_sk_user_data(sock->sk)) {\r\nsk = ERR_PTR(-EBUSY);\r\ngoto out_sock;\r\n}\r\nsk = sock->sk;\r\nsock_hold(sk);\r\ntuncfg.sk_user_data = gtp;\r\ntuncfg.encap_type = type;\r\ntuncfg.encap_rcv = gtp_encap_recv;\r\ntuncfg.encap_destroy = gtp_encap_destroy;\r\nsetup_udp_tunnel_sock(sock_net(sock->sk), sock, &tuncfg);\r\nout_sock:\r\nsockfd_put(sock);\r\nreturn sk;\r\n}\r\nstatic int gtp_encap_enable(struct gtp_dev *gtp, struct nlattr *data[])\r\n{\r\nstruct sock *sk1u = NULL;\r\nstruct sock *sk0 = NULL;\r\nunsigned int role = GTP_ROLE_GGSN;\r\nif (data[IFLA_GTP_FD0]) {\r\nu32 fd0 = nla_get_u32(data[IFLA_GTP_FD0]);\r\nsk0 = gtp_encap_enable_socket(fd0, UDP_ENCAP_GTP0, gtp);\r\nif (IS_ERR(sk0))\r\nreturn PTR_ERR(sk0);\r\n}\r\nif (data[IFLA_GTP_FD1]) {\r\nu32 fd1 = nla_get_u32(data[IFLA_GTP_FD1]);\r\nsk1u = gtp_encap_enable_socket(fd1, UDP_ENCAP_GTP1U, gtp);\r\nif (IS_ERR(sk1u)) {\r\nif (sk0)\r\ngtp_encap_disable_sock(sk0);\r\nreturn PTR_ERR(sk1u);\r\n}\r\n}\r\nif (data[IFLA_GTP_ROLE]) {\r\nrole = nla_get_u32(data[IFLA_GTP_ROLE]);\r\nif (role > GTP_ROLE_SGSN)\r\nreturn -EINVAL;\r\n}\r\ngtp->sk0 = sk0;\r\ngtp->sk1u = sk1u;\r\ngtp->role = role;\r\nreturn 0;\r\n}\r\nstatic struct gtp_dev *gtp_find_dev(struct net *src_net, struct nlattr *nla[])\r\n{\r\nstruct gtp_dev *gtp = NULL;\r\nstruct net_device *dev;\r\nstruct net *net;\r\nif (nla[GTPA_NET_NS_FD])\r\nnet = get_net_ns_by_fd(nla_get_u32(nla[GTPA_NET_NS_FD]));\r\nelse\r\nnet = get_net(src_net);\r\nif (IS_ERR(net))\r\nreturn NULL;\r\ndev = dev_get_by_index_rcu(net, nla_get_u32(nla[GTPA_LINK]));\r\nif (dev && dev->netdev_ops == &gtp_netdev_ops)\r\ngtp = netdev_priv(dev);\r\nput_net(net);\r\nreturn gtp;\r\n}\r\nstatic void ipv4_pdp_fill(struct pdp_ctx *pctx, struct genl_info *info)\r\n{\r\npctx->gtp_version = nla_get_u32(info->attrs[GTPA_VERSION]);\r\npctx->af = AF_INET;\r\npctx->peer_addr_ip4.s_addr =\r\nnla_get_be32(info->attrs[GTPA_PEER_ADDRESS]);\r\npctx->ms_addr_ip4.s_addr =\r\nnla_get_be32(info->attrs[GTPA_MS_ADDRESS]);\r\nswitch (pctx->gtp_version) {\r\ncase GTP_V0:\r\npctx->u.v0.tid = nla_get_u64(info->attrs[GTPA_TID]);\r\npctx->u.v0.flow = nla_get_u16(info->attrs[GTPA_FLOW]);\r\nbreak;\r\ncase GTP_V1:\r\npctx->u.v1.i_tei = nla_get_u32(info->attrs[GTPA_I_TEI]);\r\npctx->u.v1.o_tei = nla_get_u32(info->attrs[GTPA_O_TEI]);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic int ipv4_pdp_add(struct gtp_dev *gtp, struct sock *sk,\r\nstruct genl_info *info)\r\n{\r\nstruct net_device *dev = gtp->dev;\r\nu32 hash_ms, hash_tid = 0;\r\nstruct pdp_ctx *pctx;\r\nbool found = false;\r\n__be32 ms_addr;\r\nms_addr = nla_get_be32(info->attrs[GTPA_MS_ADDRESS]);\r\nhash_ms = ipv4_hashfn(ms_addr) % gtp->hash_size;\r\nhlist_for_each_entry_rcu(pctx, &gtp->addr_hash[hash_ms], hlist_addr) {\r\nif (pctx->ms_addr_ip4.s_addr == ms_addr) {\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (found) {\r\nif (info->nlhdr->nlmsg_flags & NLM_F_EXCL)\r\nreturn -EEXIST;\r\nif (info->nlhdr->nlmsg_flags & NLM_F_REPLACE)\r\nreturn -EOPNOTSUPP;\r\nipv4_pdp_fill(pctx, info);\r\nif (pctx->gtp_version == GTP_V0)\r\nnetdev_dbg(dev, "GTPv0-U: update tunnel id = %llx (pdp %p)\n",\r\npctx->u.v0.tid, pctx);\r\nelse if (pctx->gtp_version == GTP_V1)\r\nnetdev_dbg(dev, "GTPv1-U: update tunnel id = %x/%x (pdp %p)\n",\r\npctx->u.v1.i_tei, pctx->u.v1.o_tei, pctx);\r\nreturn 0;\r\n}\r\npctx = kmalloc(sizeof(struct pdp_ctx), GFP_KERNEL);\r\nif (pctx == NULL)\r\nreturn -ENOMEM;\r\nsock_hold(sk);\r\npctx->sk = sk;\r\npctx->dev = gtp->dev;\r\nipv4_pdp_fill(pctx, info);\r\natomic_set(&pctx->tx_seq, 0);\r\nswitch (pctx->gtp_version) {\r\ncase GTP_V0:\r\nhash_tid = gtp0_hashfn(pctx->u.v0.tid) % gtp->hash_size;\r\nbreak;\r\ncase GTP_V1:\r\nhash_tid = gtp1u_hashfn(pctx->u.v1.i_tei) % gtp->hash_size;\r\nbreak;\r\n}\r\nhlist_add_head_rcu(&pctx->hlist_addr, &gtp->addr_hash[hash_ms]);\r\nhlist_add_head_rcu(&pctx->hlist_tid, &gtp->tid_hash[hash_tid]);\r\nswitch (pctx->gtp_version) {\r\ncase GTP_V0:\r\nnetdev_dbg(dev, "GTPv0-U: new PDP ctx id=%llx ssgn=%pI4 ms=%pI4 (pdp=%p)\n",\r\npctx->u.v0.tid, &pctx->peer_addr_ip4,\r\n&pctx->ms_addr_ip4, pctx);\r\nbreak;\r\ncase GTP_V1:\r\nnetdev_dbg(dev, "GTPv1-U: new PDP ctx id=%x/%x ssgn=%pI4 ms=%pI4 (pdp=%p)\n",\r\npctx->u.v1.i_tei, pctx->u.v1.o_tei,\r\n&pctx->peer_addr_ip4, &pctx->ms_addr_ip4, pctx);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic void pdp_context_free(struct rcu_head *head)\r\n{\r\nstruct pdp_ctx *pctx = container_of(head, struct pdp_ctx, rcu_head);\r\nsock_put(pctx->sk);\r\nkfree(pctx);\r\n}\r\nstatic void pdp_context_delete(struct pdp_ctx *pctx)\r\n{\r\nhlist_del_rcu(&pctx->hlist_tid);\r\nhlist_del_rcu(&pctx->hlist_addr);\r\ncall_rcu(&pctx->rcu_head, pdp_context_free);\r\n}\r\nstatic int gtp_genl_new_pdp(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nunsigned int version;\r\nstruct gtp_dev *gtp;\r\nstruct sock *sk;\r\nint err;\r\nif (!info->attrs[GTPA_VERSION] ||\r\n!info->attrs[GTPA_LINK] ||\r\n!info->attrs[GTPA_PEER_ADDRESS] ||\r\n!info->attrs[GTPA_MS_ADDRESS])\r\nreturn -EINVAL;\r\nversion = nla_get_u32(info->attrs[GTPA_VERSION]);\r\nswitch (version) {\r\ncase GTP_V0:\r\nif (!info->attrs[GTPA_TID] ||\r\n!info->attrs[GTPA_FLOW])\r\nreturn -EINVAL;\r\nbreak;\r\ncase GTP_V1:\r\nif (!info->attrs[GTPA_I_TEI] ||\r\n!info->attrs[GTPA_O_TEI])\r\nreturn -EINVAL;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nrcu_read_lock();\r\ngtp = gtp_find_dev(sock_net(skb->sk), info->attrs);\r\nif (!gtp) {\r\nerr = -ENODEV;\r\ngoto out_unlock;\r\n}\r\nif (version == GTP_V0)\r\nsk = gtp->sk0;\r\nelse if (version == GTP_V1)\r\nsk = gtp->sk1u;\r\nelse\r\nsk = NULL;\r\nif (!sk) {\r\nerr = -ENODEV;\r\ngoto out_unlock;\r\n}\r\nerr = ipv4_pdp_add(gtp, sk, info);\r\nout_unlock:\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nstatic struct pdp_ctx *gtp_find_pdp_by_link(struct net *net,\r\nstruct nlattr *nla[])\r\n{\r\nstruct gtp_dev *gtp;\r\ngtp = gtp_find_dev(net, nla);\r\nif (!gtp)\r\nreturn ERR_PTR(-ENODEV);\r\nif (nla[GTPA_MS_ADDRESS]) {\r\n__be32 ip = nla_get_be32(nla[GTPA_MS_ADDRESS]);\r\nreturn ipv4_pdp_find(gtp, ip);\r\n} else if (nla[GTPA_VERSION]) {\r\nu32 gtp_version = nla_get_u32(nla[GTPA_VERSION]);\r\nif (gtp_version == GTP_V0 && nla[GTPA_TID])\r\nreturn gtp0_pdp_find(gtp, nla_get_u64(nla[GTPA_TID]));\r\nelse if (gtp_version == GTP_V1 && nla[GTPA_I_TEI])\r\nreturn gtp1_pdp_find(gtp, nla_get_u32(nla[GTPA_I_TEI]));\r\n}\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nstatic struct pdp_ctx *gtp_find_pdp(struct net *net, struct nlattr *nla[])\r\n{\r\nstruct pdp_ctx *pctx;\r\nif (nla[GTPA_LINK])\r\npctx = gtp_find_pdp_by_link(net, nla);\r\nelse\r\npctx = ERR_PTR(-EINVAL);\r\nif (!pctx)\r\npctx = ERR_PTR(-ENOENT);\r\nreturn pctx;\r\n}\r\nstatic int gtp_genl_del_pdp(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct pdp_ctx *pctx;\r\nint err = 0;\r\nif (!info->attrs[GTPA_VERSION])\r\nreturn -EINVAL;\r\nrcu_read_lock();\r\npctx = gtp_find_pdp(sock_net(skb->sk), info->attrs);\r\nif (IS_ERR(pctx)) {\r\nerr = PTR_ERR(pctx);\r\ngoto out_unlock;\r\n}\r\nif (pctx->gtp_version == GTP_V0)\r\nnetdev_dbg(pctx->dev, "GTPv0-U: deleting tunnel id = %llx (pdp %p)\n",\r\npctx->u.v0.tid, pctx);\r\nelse if (pctx->gtp_version == GTP_V1)\r\nnetdev_dbg(pctx->dev, "GTPv1-U: deleting tunnel id = %x/%x (pdp %p)\n",\r\npctx->u.v1.i_tei, pctx->u.v1.o_tei, pctx);\r\npdp_context_delete(pctx);\r\nout_unlock:\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nstatic int gtp_genl_fill_info(struct sk_buff *skb, u32 snd_portid, u32 snd_seq,\r\nu32 type, struct pdp_ctx *pctx)\r\n{\r\nvoid *genlh;\r\ngenlh = genlmsg_put(skb, snd_portid, snd_seq, &gtp_genl_family, 0,\r\ntype);\r\nif (genlh == NULL)\r\ngoto nlmsg_failure;\r\nif (nla_put_u32(skb, GTPA_VERSION, pctx->gtp_version) ||\r\nnla_put_be32(skb, GTPA_PEER_ADDRESS, pctx->peer_addr_ip4.s_addr) ||\r\nnla_put_be32(skb, GTPA_MS_ADDRESS, pctx->ms_addr_ip4.s_addr))\r\ngoto nla_put_failure;\r\nswitch (pctx->gtp_version) {\r\ncase GTP_V0:\r\nif (nla_put_u64_64bit(skb, GTPA_TID, pctx->u.v0.tid, GTPA_PAD) ||\r\nnla_put_u16(skb, GTPA_FLOW, pctx->u.v0.flow))\r\ngoto nla_put_failure;\r\nbreak;\r\ncase GTP_V1:\r\nif (nla_put_u32(skb, GTPA_I_TEI, pctx->u.v1.i_tei) ||\r\nnla_put_u32(skb, GTPA_O_TEI, pctx->u.v1.o_tei))\r\ngoto nla_put_failure;\r\nbreak;\r\n}\r\ngenlmsg_end(skb, genlh);\r\nreturn 0;\r\nnlmsg_failure:\r\nnla_put_failure:\r\ngenlmsg_cancel(skb, genlh);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int gtp_genl_get_pdp(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct pdp_ctx *pctx = NULL;\r\nstruct sk_buff *skb2;\r\nint err;\r\nif (!info->attrs[GTPA_VERSION])\r\nreturn -EINVAL;\r\nrcu_read_lock();\r\npctx = gtp_find_pdp(sock_net(skb->sk), info->attrs);\r\nif (IS_ERR(pctx)) {\r\nerr = PTR_ERR(pctx);\r\ngoto err_unlock;\r\n}\r\nskb2 = genlmsg_new(NLMSG_GOODSIZE, GFP_ATOMIC);\r\nif (skb2 == NULL) {\r\nerr = -ENOMEM;\r\ngoto err_unlock;\r\n}\r\nerr = gtp_genl_fill_info(skb2, NETLINK_CB(skb).portid,\r\ninfo->snd_seq, info->nlhdr->nlmsg_type, pctx);\r\nif (err < 0)\r\ngoto err_unlock_free;\r\nrcu_read_unlock();\r\nreturn genlmsg_unicast(genl_info_net(info), skb2, info->snd_portid);\r\nerr_unlock_free:\r\nkfree_skb(skb2);\r\nerr_unlock:\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nstatic int gtp_genl_dump_pdp(struct sk_buff *skb,\r\nstruct netlink_callback *cb)\r\n{\r\nstruct gtp_dev *last_gtp = (struct gtp_dev *)cb->args[2], *gtp;\r\nstruct net *net = sock_net(skb->sk);\r\nstruct gtp_net *gn = net_generic(net, gtp_net_id);\r\nunsigned long tid = cb->args[1];\r\nint i, k = cb->args[0], ret;\r\nstruct pdp_ctx *pctx;\r\nif (cb->args[4])\r\nreturn 0;\r\nlist_for_each_entry_rcu(gtp, &gn->gtp_dev_list, list) {\r\nif (last_gtp && last_gtp != gtp)\r\ncontinue;\r\nelse\r\nlast_gtp = NULL;\r\nfor (i = k; i < gtp->hash_size; i++) {\r\nhlist_for_each_entry_rcu(pctx, &gtp->tid_hash[i], hlist_tid) {\r\nif (tid && tid != pctx->u.tid)\r\ncontinue;\r\nelse\r\ntid = 0;\r\nret = gtp_genl_fill_info(skb,\r\nNETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq,\r\ncb->nlh->nlmsg_type, pctx);\r\nif (ret < 0) {\r\ncb->args[0] = i;\r\ncb->args[1] = pctx->u.tid;\r\ncb->args[2] = (unsigned long)gtp;\r\ngoto out;\r\n}\r\n}\r\n}\r\n}\r\ncb->args[4] = 1;\r\nout:\r\nreturn skb->len;\r\n}\r\nstatic int __net_init gtp_net_init(struct net *net)\r\n{\r\nstruct gtp_net *gn = net_generic(net, gtp_net_id);\r\nINIT_LIST_HEAD(&gn->gtp_dev_list);\r\nreturn 0;\r\n}\r\nstatic void __net_exit gtp_net_exit(struct net *net)\r\n{\r\nstruct gtp_net *gn = net_generic(net, gtp_net_id);\r\nstruct gtp_dev *gtp;\r\nLIST_HEAD(list);\r\nrtnl_lock();\r\nlist_for_each_entry(gtp, &gn->gtp_dev_list, list)\r\ngtp_dellink(gtp->dev, &list);\r\nunregister_netdevice_many(&list);\r\nrtnl_unlock();\r\n}\r\nstatic int __init gtp_init(void)\r\n{\r\nint err;\r\nget_random_bytes(&gtp_h_initval, sizeof(gtp_h_initval));\r\nerr = rtnl_link_register(&gtp_link_ops);\r\nif (err < 0)\r\ngoto error_out;\r\nerr = genl_register_family(&gtp_genl_family);\r\nif (err < 0)\r\ngoto unreg_rtnl_link;\r\nerr = register_pernet_subsys(&gtp_net_ops);\r\nif (err < 0)\r\ngoto unreg_genl_family;\r\npr_info("GTP module loaded (pdp ctx size %zd bytes)\n",\r\nsizeof(struct pdp_ctx));\r\nreturn 0;\r\nunreg_genl_family:\r\ngenl_unregister_family(&gtp_genl_family);\r\nunreg_rtnl_link:\r\nrtnl_link_unregister(&gtp_link_ops);\r\nerror_out:\r\npr_err("error loading GTP module loaded\n");\r\nreturn err;\r\n}\r\nstatic void __exit gtp_fini(void)\r\n{\r\nunregister_pernet_subsys(&gtp_net_ops);\r\ngenl_unregister_family(&gtp_genl_family);\r\nrtnl_link_unregister(&gtp_link_ops);\r\npr_info("GTP module unloaded\n");\r\n}
