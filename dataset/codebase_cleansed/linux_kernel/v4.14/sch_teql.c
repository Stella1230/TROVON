static int\r\nteql_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free)\r\n{\r\nstruct net_device *dev = qdisc_dev(sch);\r\nstruct teql_sched_data *q = qdisc_priv(sch);\r\nif (q->q.qlen < dev->tx_queue_len) {\r\n__skb_queue_tail(&q->q, skb);\r\nreturn NET_XMIT_SUCCESS;\r\n}\r\nreturn qdisc_drop(skb, sch, to_free);\r\n}\r\nstatic struct sk_buff *\r\nteql_dequeue(struct Qdisc *sch)\r\n{\r\nstruct teql_sched_data *dat = qdisc_priv(sch);\r\nstruct netdev_queue *dat_queue;\r\nstruct sk_buff *skb;\r\nstruct Qdisc *q;\r\nskb = __skb_dequeue(&dat->q);\r\ndat_queue = netdev_get_tx_queue(dat->m->dev, 0);\r\nq = rcu_dereference_bh(dat_queue->qdisc);\r\nif (skb == NULL) {\r\nstruct net_device *m = qdisc_dev(q);\r\nif (m) {\r\ndat->m->slaves = sch;\r\nnetif_wake_queue(m);\r\n}\r\n} else {\r\nqdisc_bstats_update(sch, skb);\r\n}\r\nsch->q.qlen = dat->q.qlen + q->q.qlen;\r\nreturn skb;\r\n}\r\nstatic struct sk_buff *\r\nteql_peek(struct Qdisc *sch)\r\n{\r\nreturn NULL;\r\n}\r\nstatic void\r\nteql_reset(struct Qdisc *sch)\r\n{\r\nstruct teql_sched_data *dat = qdisc_priv(sch);\r\nskb_queue_purge(&dat->q);\r\nsch->q.qlen = 0;\r\n}\r\nstatic void\r\nteql_destroy(struct Qdisc *sch)\r\n{\r\nstruct Qdisc *q, *prev;\r\nstruct teql_sched_data *dat = qdisc_priv(sch);\r\nstruct teql_master *master = dat->m;\r\nprev = master->slaves;\r\nif (prev) {\r\ndo {\r\nq = NEXT_SLAVE(prev);\r\nif (q == sch) {\r\nNEXT_SLAVE(prev) = NEXT_SLAVE(q);\r\nif (q == master->slaves) {\r\nmaster->slaves = NEXT_SLAVE(q);\r\nif (q == master->slaves) {\r\nstruct netdev_queue *txq;\r\nspinlock_t *root_lock;\r\ntxq = netdev_get_tx_queue(master->dev, 0);\r\nmaster->slaves = NULL;\r\nroot_lock = qdisc_root_sleeping_lock(rtnl_dereference(txq->qdisc));\r\nspin_lock_bh(root_lock);\r\nqdisc_reset(rtnl_dereference(txq->qdisc));\r\nspin_unlock_bh(root_lock);\r\n}\r\n}\r\nskb_queue_purge(&dat->q);\r\nbreak;\r\n}\r\n} while ((prev = q) != master->slaves);\r\n}\r\n}\r\nstatic int teql_qdisc_init(struct Qdisc *sch, struct nlattr *opt)\r\n{\r\nstruct net_device *dev = qdisc_dev(sch);\r\nstruct teql_master *m = (struct teql_master *)sch->ops;\r\nstruct teql_sched_data *q = qdisc_priv(sch);\r\nif (dev->hard_header_len > m->dev->hard_header_len)\r\nreturn -EINVAL;\r\nif (m->dev == dev)\r\nreturn -ELOOP;\r\nq->m = m;\r\nskb_queue_head_init(&q->q);\r\nif (m->slaves) {\r\nif (m->dev->flags & IFF_UP) {\r\nif ((m->dev->flags & IFF_POINTOPOINT &&\r\n!(dev->flags & IFF_POINTOPOINT)) ||\r\n(m->dev->flags & IFF_BROADCAST &&\r\n!(dev->flags & IFF_BROADCAST)) ||\r\n(m->dev->flags & IFF_MULTICAST &&\r\n!(dev->flags & IFF_MULTICAST)) ||\r\ndev->mtu < m->dev->mtu)\r\nreturn -EINVAL;\r\n} else {\r\nif (!(dev->flags&IFF_POINTOPOINT))\r\nm->dev->flags &= ~IFF_POINTOPOINT;\r\nif (!(dev->flags&IFF_BROADCAST))\r\nm->dev->flags &= ~IFF_BROADCAST;\r\nif (!(dev->flags&IFF_MULTICAST))\r\nm->dev->flags &= ~IFF_MULTICAST;\r\nif (dev->mtu < m->dev->mtu)\r\nm->dev->mtu = dev->mtu;\r\n}\r\nq->next = NEXT_SLAVE(m->slaves);\r\nNEXT_SLAVE(m->slaves) = sch;\r\n} else {\r\nq->next = sch;\r\nm->slaves = sch;\r\nm->dev->mtu = dev->mtu;\r\nm->dev->flags = (m->dev->flags&~FMASK)|(dev->flags&FMASK);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\n__teql_resolve(struct sk_buff *skb, struct sk_buff *skb_res,\r\nstruct net_device *dev, struct netdev_queue *txq,\r\nstruct dst_entry *dst)\r\n{\r\nstruct neighbour *n;\r\nint err = 0;\r\nn = dst_neigh_lookup_skb(dst, skb);\r\nif (!n)\r\nreturn -ENOENT;\r\nif (dst->dev != dev) {\r\nstruct neighbour *mn;\r\nmn = __neigh_lookup_errno(n->tbl, n->primary_key, dev);\r\nneigh_release(n);\r\nif (IS_ERR(mn))\r\nreturn PTR_ERR(mn);\r\nn = mn;\r\n}\r\nif (neigh_event_send(n, skb_res) == 0) {\r\nint err;\r\nchar haddr[MAX_ADDR_LEN];\r\nneigh_ha_snapshot(haddr, n, dev);\r\nerr = dev_hard_header(skb, dev, ntohs(tc_skb_protocol(skb)),\r\nhaddr, NULL, skb->len);\r\nif (err < 0)\r\nerr = -EINVAL;\r\n} else {\r\nerr = (skb_res == NULL) ? -EAGAIN : 1;\r\n}\r\nneigh_release(n);\r\nreturn err;\r\n}\r\nstatic inline int teql_resolve(struct sk_buff *skb,\r\nstruct sk_buff *skb_res,\r\nstruct net_device *dev,\r\nstruct netdev_queue *txq)\r\n{\r\nstruct dst_entry *dst = skb_dst(skb);\r\nint res;\r\nif (rcu_access_pointer(txq->qdisc) == &noop_qdisc)\r\nreturn -ENODEV;\r\nif (!dev->header_ops || !dst)\r\nreturn 0;\r\nrcu_read_lock();\r\nres = __teql_resolve(skb, skb_res, dev, txq, dst);\r\nrcu_read_unlock();\r\nreturn res;\r\n}\r\nstatic netdev_tx_t teql_master_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct teql_master *master = netdev_priv(dev);\r\nstruct Qdisc *start, *q;\r\nint busy;\r\nint nores;\r\nint subq = skb_get_queue_mapping(skb);\r\nstruct sk_buff *skb_res = NULL;\r\nstart = master->slaves;\r\nrestart:\r\nnores = 0;\r\nbusy = 0;\r\nq = start;\r\nif (!q)\r\ngoto drop;\r\ndo {\r\nstruct net_device *slave = qdisc_dev(q);\r\nstruct netdev_queue *slave_txq = netdev_get_tx_queue(slave, 0);\r\nif (slave_txq->qdisc_sleeping != q)\r\ncontinue;\r\nif (netif_xmit_stopped(netdev_get_tx_queue(slave, subq)) ||\r\n!netif_running(slave)) {\r\nbusy = 1;\r\ncontinue;\r\n}\r\nswitch (teql_resolve(skb, skb_res, slave, slave_txq)) {\r\ncase 0:\r\nif (__netif_tx_trylock(slave_txq)) {\r\nunsigned int length = qdisc_pkt_len(skb);\r\nif (!netif_xmit_frozen_or_stopped(slave_txq) &&\r\nnetdev_start_xmit(skb, slave, slave_txq, false) ==\r\nNETDEV_TX_OK) {\r\n__netif_tx_unlock(slave_txq);\r\nmaster->slaves = NEXT_SLAVE(q);\r\nnetif_wake_queue(dev);\r\nmaster->tx_packets++;\r\nmaster->tx_bytes += length;\r\nreturn NETDEV_TX_OK;\r\n}\r\n__netif_tx_unlock(slave_txq);\r\n}\r\nif (netif_xmit_stopped(netdev_get_tx_queue(dev, 0)))\r\nbusy = 1;\r\nbreak;\r\ncase 1:\r\nmaster->slaves = NEXT_SLAVE(q);\r\nreturn NETDEV_TX_OK;\r\ndefault:\r\nnores = 1;\r\nbreak;\r\n}\r\n__skb_pull(skb, skb_network_offset(skb));\r\n} while ((q = NEXT_SLAVE(q)) != start);\r\nif (nores && skb_res == NULL) {\r\nskb_res = skb;\r\ngoto restart;\r\n}\r\nif (busy) {\r\nnetif_stop_queue(dev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nmaster->tx_errors++;\r\ndrop:\r\nmaster->tx_dropped++;\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int teql_master_open(struct net_device *dev)\r\n{\r\nstruct Qdisc *q;\r\nstruct teql_master *m = netdev_priv(dev);\r\nint mtu = 0xFFFE;\r\nunsigned int flags = IFF_NOARP | IFF_MULTICAST;\r\nif (m->slaves == NULL)\r\nreturn -EUNATCH;\r\nflags = FMASK;\r\nq = m->slaves;\r\ndo {\r\nstruct net_device *slave = qdisc_dev(q);\r\nif (slave == NULL)\r\nreturn -EUNATCH;\r\nif (slave->mtu < mtu)\r\nmtu = slave->mtu;\r\nif (slave->hard_header_len > LL_MAX_HEADER)\r\nreturn -EINVAL;\r\nif (!(slave->flags&IFF_POINTOPOINT))\r\nflags &= ~IFF_POINTOPOINT;\r\nif (!(slave->flags&IFF_BROADCAST))\r\nflags &= ~IFF_BROADCAST;\r\nif (!(slave->flags&IFF_MULTICAST))\r\nflags &= ~IFF_MULTICAST;\r\n} while ((q = NEXT_SLAVE(q)) != m->slaves);\r\nm->dev->mtu = mtu;\r\nm->dev->flags = (m->dev->flags&~FMASK) | flags;\r\nnetif_start_queue(m->dev);\r\nreturn 0;\r\n}\r\nstatic int teql_master_close(struct net_device *dev)\r\n{\r\nnetif_stop_queue(dev);\r\nreturn 0;\r\n}\r\nstatic void teql_master_stats64(struct net_device *dev,\r\nstruct rtnl_link_stats64 *stats)\r\n{\r\nstruct teql_master *m = netdev_priv(dev);\r\nstats->tx_packets = m->tx_packets;\r\nstats->tx_bytes = m->tx_bytes;\r\nstats->tx_errors = m->tx_errors;\r\nstats->tx_dropped = m->tx_dropped;\r\n}\r\nstatic int teql_master_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct teql_master *m = netdev_priv(dev);\r\nstruct Qdisc *q;\r\nq = m->slaves;\r\nif (q) {\r\ndo {\r\nif (new_mtu > qdisc_dev(q)->mtu)\r\nreturn -EINVAL;\r\n} while ((q = NEXT_SLAVE(q)) != m->slaves);\r\n}\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nstatic __init void teql_master_setup(struct net_device *dev)\r\n{\r\nstruct teql_master *master = netdev_priv(dev);\r\nstruct Qdisc_ops *ops = &master->qops;\r\nmaster->dev = dev;\r\nops->priv_size = sizeof(struct teql_sched_data);\r\nops->enqueue = teql_enqueue;\r\nops->dequeue = teql_dequeue;\r\nops->peek = teql_peek;\r\nops->init = teql_qdisc_init;\r\nops->reset = teql_reset;\r\nops->destroy = teql_destroy;\r\nops->owner = THIS_MODULE;\r\ndev->netdev_ops = &teql_netdev_ops;\r\ndev->type = ARPHRD_VOID;\r\ndev->mtu = 1500;\r\ndev->min_mtu = 68;\r\ndev->max_mtu = 65535;\r\ndev->tx_queue_len = 100;\r\ndev->flags = IFF_NOARP;\r\ndev->hard_header_len = LL_MAX_HEADER;\r\nnetif_keep_dst(dev);\r\n}\r\nstatic int __init teql_init(void)\r\n{\r\nint i;\r\nint err = -ENODEV;\r\nfor (i = 0; i < max_equalizers; i++) {\r\nstruct net_device *dev;\r\nstruct teql_master *master;\r\ndev = alloc_netdev(sizeof(struct teql_master), "teql%d",\r\nNET_NAME_UNKNOWN, teql_master_setup);\r\nif (!dev) {\r\nerr = -ENOMEM;\r\nbreak;\r\n}\r\nif ((err = register_netdev(dev))) {\r\nfree_netdev(dev);\r\nbreak;\r\n}\r\nmaster = netdev_priv(dev);\r\nstrlcpy(master->qops.id, dev->name, IFNAMSIZ);\r\nerr = register_qdisc(&master->qops);\r\nif (err) {\r\nunregister_netdev(dev);\r\nfree_netdev(dev);\r\nbreak;\r\n}\r\nlist_add_tail(&master->master_list, &master_dev_list);\r\n}\r\nreturn i ? 0 : err;\r\n}\r\nstatic void __exit teql_exit(void)\r\n{\r\nstruct teql_master *master, *nxt;\r\nlist_for_each_entry_safe(master, nxt, &master_dev_list, master_list) {\r\nlist_del(&master->master_list);\r\nunregister_qdisc(&master->qops);\r\nunregister_netdev(master->dev);\r\nfree_netdev(master->dev);\r\n}\r\n}
