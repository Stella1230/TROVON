static inline unsigned long sh_mtu2_read(struct sh_mtu2_channel *ch, int reg_nr)\r\n{\r\nunsigned long offs;\r\nif (reg_nr == TSTR)\r\nreturn ioread8(ch->mtu->mapbase + 0x280);\r\noffs = mtu2_reg_offs[reg_nr];\r\nif ((reg_nr == TCNT) || (reg_nr == TGR))\r\nreturn ioread16(ch->base + offs);\r\nelse\r\nreturn ioread8(ch->base + offs);\r\n}\r\nstatic inline void sh_mtu2_write(struct sh_mtu2_channel *ch, int reg_nr,\r\nunsigned long value)\r\n{\r\nunsigned long offs;\r\nif (reg_nr == TSTR)\r\nreturn iowrite8(value, ch->mtu->mapbase + 0x280);\r\noffs = mtu2_reg_offs[reg_nr];\r\nif ((reg_nr == TCNT) || (reg_nr == TGR))\r\niowrite16(value, ch->base + offs);\r\nelse\r\niowrite8(value, ch->base + offs);\r\n}\r\nstatic void sh_mtu2_start_stop_ch(struct sh_mtu2_channel *ch, int start)\r\n{\r\nunsigned long flags, value;\r\nraw_spin_lock_irqsave(&ch->mtu->lock, flags);\r\nvalue = sh_mtu2_read(ch, TSTR);\r\nif (start)\r\nvalue |= 1 << ch->index;\r\nelse\r\nvalue &= ~(1 << ch->index);\r\nsh_mtu2_write(ch, TSTR, value);\r\nraw_spin_unlock_irqrestore(&ch->mtu->lock, flags);\r\n}\r\nstatic int sh_mtu2_enable(struct sh_mtu2_channel *ch)\r\n{\r\nunsigned long periodic;\r\nunsigned long rate;\r\nint ret;\r\npm_runtime_get_sync(&ch->mtu->pdev->dev);\r\ndev_pm_syscore_device(&ch->mtu->pdev->dev, true);\r\nret = clk_enable(ch->mtu->clk);\r\nif (ret) {\r\ndev_err(&ch->mtu->pdev->dev, "ch%u: cannot enable clock\n",\r\nch->index);\r\nreturn ret;\r\n}\r\nsh_mtu2_start_stop_ch(ch, 0);\r\nrate = clk_get_rate(ch->mtu->clk) / 64;\r\nperiodic = (rate + HZ/2) / HZ;\r\nsh_mtu2_write(ch, TCR, TCR_CCLR_TGRA | TCR_TPSC_P64);\r\nsh_mtu2_write(ch, TIOR, TIOC_IOCH(TIOR_OC_0_CLEAR) |\r\nTIOC_IOCL(TIOR_OC_0_CLEAR));\r\nsh_mtu2_write(ch, TGR, periodic);\r\nsh_mtu2_write(ch, TCNT, 0);\r\nsh_mtu2_write(ch, TMDR, TMDR_MD_NORMAL);\r\nsh_mtu2_write(ch, TIER, TIER_TGIEA);\r\nsh_mtu2_start_stop_ch(ch, 1);\r\nreturn 0;\r\n}\r\nstatic void sh_mtu2_disable(struct sh_mtu2_channel *ch)\r\n{\r\nsh_mtu2_start_stop_ch(ch, 0);\r\nclk_disable(ch->mtu->clk);\r\ndev_pm_syscore_device(&ch->mtu->pdev->dev, false);\r\npm_runtime_put(&ch->mtu->pdev->dev);\r\n}\r\nstatic irqreturn_t sh_mtu2_interrupt(int irq, void *dev_id)\r\n{\r\nstruct sh_mtu2_channel *ch = dev_id;\r\nsh_mtu2_read(ch, TSR);\r\nsh_mtu2_write(ch, TSR, ~TSR_TGFA);\r\nch->ced.event_handler(&ch->ced);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic struct sh_mtu2_channel *ced_to_sh_mtu2(struct clock_event_device *ced)\r\n{\r\nreturn container_of(ced, struct sh_mtu2_channel, ced);\r\n}\r\nstatic int sh_mtu2_clock_event_shutdown(struct clock_event_device *ced)\r\n{\r\nstruct sh_mtu2_channel *ch = ced_to_sh_mtu2(ced);\r\nif (clockevent_state_periodic(ced))\r\nsh_mtu2_disable(ch);\r\nreturn 0;\r\n}\r\nstatic int sh_mtu2_clock_event_set_periodic(struct clock_event_device *ced)\r\n{\r\nstruct sh_mtu2_channel *ch = ced_to_sh_mtu2(ced);\r\nif (clockevent_state_periodic(ced))\r\nsh_mtu2_disable(ch);\r\ndev_info(&ch->mtu->pdev->dev, "ch%u: used for periodic clock events\n",\r\nch->index);\r\nsh_mtu2_enable(ch);\r\nreturn 0;\r\n}\r\nstatic void sh_mtu2_clock_event_suspend(struct clock_event_device *ced)\r\n{\r\npm_genpd_syscore_poweroff(&ced_to_sh_mtu2(ced)->mtu->pdev->dev);\r\n}\r\nstatic void sh_mtu2_clock_event_resume(struct clock_event_device *ced)\r\n{\r\npm_genpd_syscore_poweron(&ced_to_sh_mtu2(ced)->mtu->pdev->dev);\r\n}\r\nstatic void sh_mtu2_register_clockevent(struct sh_mtu2_channel *ch,\r\nconst char *name)\r\n{\r\nstruct clock_event_device *ced = &ch->ced;\r\nced->name = name;\r\nced->features = CLOCK_EVT_FEAT_PERIODIC;\r\nced->rating = 200;\r\nced->cpumask = cpu_possible_mask;\r\nced->set_state_shutdown = sh_mtu2_clock_event_shutdown;\r\nced->set_state_periodic = sh_mtu2_clock_event_set_periodic;\r\nced->suspend = sh_mtu2_clock_event_suspend;\r\nced->resume = sh_mtu2_clock_event_resume;\r\ndev_info(&ch->mtu->pdev->dev, "ch%u: used for clock events\n",\r\nch->index);\r\nclockevents_register_device(ced);\r\n}\r\nstatic int sh_mtu2_register(struct sh_mtu2_channel *ch, const char *name)\r\n{\r\nch->mtu->has_clockevent = true;\r\nsh_mtu2_register_clockevent(ch, name);\r\nreturn 0;\r\n}\r\nstatic int sh_mtu2_setup_channel(struct sh_mtu2_channel *ch, unsigned int index,\r\nstruct sh_mtu2_device *mtu)\r\n{\r\nstatic const unsigned int channel_offsets[] = {\r\n0x300, 0x380, 0x000,\r\n};\r\nchar name[6];\r\nint irq;\r\nint ret;\r\nch->mtu = mtu;\r\nsprintf(name, "tgi%ua", index);\r\nirq = platform_get_irq_byname(mtu->pdev, name);\r\nif (irq < 0) {\r\nreturn 0;\r\n}\r\nret = request_irq(irq, sh_mtu2_interrupt,\r\nIRQF_TIMER | IRQF_IRQPOLL | IRQF_NOBALANCING,\r\ndev_name(&ch->mtu->pdev->dev), ch);\r\nif (ret) {\r\ndev_err(&ch->mtu->pdev->dev, "ch%u: failed to request irq %d\n",\r\nindex, irq);\r\nreturn ret;\r\n}\r\nch->base = mtu->mapbase + channel_offsets[index];\r\nch->index = index;\r\nreturn sh_mtu2_register(ch, dev_name(&mtu->pdev->dev));\r\n}\r\nstatic int sh_mtu2_map_memory(struct sh_mtu2_device *mtu)\r\n{\r\nstruct resource *res;\r\nres = platform_get_resource(mtu->pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(&mtu->pdev->dev, "failed to get I/O memory\n");\r\nreturn -ENXIO;\r\n}\r\nmtu->mapbase = ioremap_nocache(res->start, resource_size(res));\r\nif (mtu->mapbase == NULL)\r\nreturn -ENXIO;\r\nreturn 0;\r\n}\r\nstatic int sh_mtu2_setup(struct sh_mtu2_device *mtu,\r\nstruct platform_device *pdev)\r\n{\r\nunsigned int i;\r\nint ret;\r\nmtu->pdev = pdev;\r\nraw_spin_lock_init(&mtu->lock);\r\nmtu->clk = clk_get(&mtu->pdev->dev, "fck");\r\nif (IS_ERR(mtu->clk)) {\r\ndev_err(&mtu->pdev->dev, "cannot get clock\n");\r\nreturn PTR_ERR(mtu->clk);\r\n}\r\nret = clk_prepare(mtu->clk);\r\nif (ret < 0)\r\ngoto err_clk_put;\r\nret = sh_mtu2_map_memory(mtu);\r\nif (ret < 0) {\r\ndev_err(&mtu->pdev->dev, "failed to remap I/O memory\n");\r\ngoto err_clk_unprepare;\r\n}\r\nmtu->num_channels = 3;\r\nmtu->channels = kzalloc(sizeof(*mtu->channels) * mtu->num_channels,\r\nGFP_KERNEL);\r\nif (mtu->channels == NULL) {\r\nret = -ENOMEM;\r\ngoto err_unmap;\r\n}\r\nfor (i = 0; i < mtu->num_channels; ++i) {\r\nret = sh_mtu2_setup_channel(&mtu->channels[i], i, mtu);\r\nif (ret < 0)\r\ngoto err_unmap;\r\n}\r\nplatform_set_drvdata(pdev, mtu);\r\nreturn 0;\r\nerr_unmap:\r\nkfree(mtu->channels);\r\niounmap(mtu->mapbase);\r\nerr_clk_unprepare:\r\nclk_unprepare(mtu->clk);\r\nerr_clk_put:\r\nclk_put(mtu->clk);\r\nreturn ret;\r\n}\r\nstatic int sh_mtu2_probe(struct platform_device *pdev)\r\n{\r\nstruct sh_mtu2_device *mtu = platform_get_drvdata(pdev);\r\nint ret;\r\nif (!is_early_platform_device(pdev)) {\r\npm_runtime_set_active(&pdev->dev);\r\npm_runtime_enable(&pdev->dev);\r\n}\r\nif (mtu) {\r\ndev_info(&pdev->dev, "kept as earlytimer\n");\r\ngoto out;\r\n}\r\nmtu = kzalloc(sizeof(*mtu), GFP_KERNEL);\r\nif (mtu == NULL)\r\nreturn -ENOMEM;\r\nret = sh_mtu2_setup(mtu, pdev);\r\nif (ret) {\r\nkfree(mtu);\r\npm_runtime_idle(&pdev->dev);\r\nreturn ret;\r\n}\r\nif (is_early_platform_device(pdev))\r\nreturn 0;\r\nout:\r\nif (mtu->has_clockevent)\r\npm_runtime_irq_safe(&pdev->dev);\r\nelse\r\npm_runtime_idle(&pdev->dev);\r\nreturn 0;\r\n}\r\nstatic int sh_mtu2_remove(struct platform_device *pdev)\r\n{\r\nreturn -EBUSY;\r\n}\r\nstatic int __init sh_mtu2_init(void)\r\n{\r\nreturn platform_driver_register(&sh_mtu2_device_driver);\r\n}\r\nstatic void __exit sh_mtu2_exit(void)\r\n{\r\nplatform_driver_unregister(&sh_mtu2_device_driver);\r\n}
