static inline struct bpf_lwt *bpf_lwt_lwtunnel(struct lwtunnel_state *lwt)\r\n{\r\nreturn (struct bpf_lwt *)lwt->data;\r\n}\r\nstatic int run_lwt_bpf(struct sk_buff *skb, struct bpf_lwt_prog *lwt,\r\nstruct dst_entry *dst, bool can_redirect)\r\n{\r\nint ret;\r\npreempt_disable();\r\nrcu_read_lock();\r\nbpf_compute_data_end(skb);\r\nret = bpf_prog_run_save_cb(lwt->prog, skb);\r\nrcu_read_unlock();\r\nswitch (ret) {\r\ncase BPF_OK:\r\nbreak;\r\ncase BPF_REDIRECT:\r\nif (unlikely(!can_redirect)) {\r\npr_warn_once("Illegal redirect return code in prog %s\n",\r\nlwt->name ? : "<unknown>");\r\nret = BPF_OK;\r\n} else {\r\nret = skb_do_redirect(skb);\r\nif (ret == 0)\r\nret = BPF_REDIRECT;\r\n}\r\nbreak;\r\ncase BPF_DROP:\r\nkfree_skb(skb);\r\nret = -EPERM;\r\nbreak;\r\ndefault:\r\npr_warn_once("bpf-lwt: Illegal return value %u, expect packet loss\n", ret);\r\nkfree_skb(skb);\r\nret = -EINVAL;\r\nbreak;\r\n}\r\npreempt_enable();\r\nreturn ret;\r\n}\r\nstatic int bpf_input(struct sk_buff *skb)\r\n{\r\nstruct dst_entry *dst = skb_dst(skb);\r\nstruct bpf_lwt *bpf;\r\nint ret;\r\nbpf = bpf_lwt_lwtunnel(dst->lwtstate);\r\nif (bpf->in.prog) {\r\nret = run_lwt_bpf(skb, &bpf->in, dst, NO_REDIRECT);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\nif (unlikely(!dst->lwtstate->orig_input)) {\r\npr_warn_once("orig_input not set on dst for prog %s\n",\r\nbpf->out.name);\r\nkfree_skb(skb);\r\nreturn -EINVAL;\r\n}\r\nreturn dst->lwtstate->orig_input(skb);\r\n}\r\nstatic int bpf_output(struct net *net, struct sock *sk, struct sk_buff *skb)\r\n{\r\nstruct dst_entry *dst = skb_dst(skb);\r\nstruct bpf_lwt *bpf;\r\nint ret;\r\nbpf = bpf_lwt_lwtunnel(dst->lwtstate);\r\nif (bpf->out.prog) {\r\nret = run_lwt_bpf(skb, &bpf->out, dst, NO_REDIRECT);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\nif (unlikely(!dst->lwtstate->orig_output)) {\r\npr_warn_once("orig_output not set on dst for prog %s\n",\r\nbpf->out.name);\r\nkfree_skb(skb);\r\nreturn -EINVAL;\r\n}\r\nreturn dst->lwtstate->orig_output(net, sk, skb);\r\n}\r\nstatic int xmit_check_hhlen(struct sk_buff *skb)\r\n{\r\nint hh_len = skb_dst(skb)->dev->hard_header_len;\r\nif (skb_headroom(skb) < hh_len) {\r\nint nhead = HH_DATA_ALIGN(hh_len - skb_headroom(skb));\r\nif (pskb_expand_head(skb, nhead, 0, GFP_ATOMIC))\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic int bpf_xmit(struct sk_buff *skb)\r\n{\r\nstruct dst_entry *dst = skb_dst(skb);\r\nstruct bpf_lwt *bpf;\r\nbpf = bpf_lwt_lwtunnel(dst->lwtstate);\r\nif (bpf->xmit.prog) {\r\nint ret;\r\nret = run_lwt_bpf(skb, &bpf->xmit, dst, CAN_REDIRECT);\r\nswitch (ret) {\r\ncase BPF_OK:\r\nret = xmit_check_hhlen(skb);\r\nif (unlikely(ret))\r\nreturn ret;\r\nreturn LWTUNNEL_XMIT_CONTINUE;\r\ncase BPF_REDIRECT:\r\nreturn LWTUNNEL_XMIT_DONE;\r\ndefault:\r\nreturn ret;\r\n}\r\n}\r\nreturn LWTUNNEL_XMIT_CONTINUE;\r\n}\r\nstatic void bpf_lwt_prog_destroy(struct bpf_lwt_prog *prog)\r\n{\r\nif (prog->prog)\r\nbpf_prog_put(prog->prog);\r\nkfree(prog->name);\r\n}\r\nstatic void bpf_destroy_state(struct lwtunnel_state *lwt)\r\n{\r\nstruct bpf_lwt *bpf = bpf_lwt_lwtunnel(lwt);\r\nbpf_lwt_prog_destroy(&bpf->in);\r\nbpf_lwt_prog_destroy(&bpf->out);\r\nbpf_lwt_prog_destroy(&bpf->xmit);\r\n}\r\nstatic int bpf_parse_prog(struct nlattr *attr, struct bpf_lwt_prog *prog,\r\nenum bpf_prog_type type)\r\n{\r\nstruct nlattr *tb[LWT_BPF_PROG_MAX + 1];\r\nstruct bpf_prog *p;\r\nint ret;\r\nu32 fd;\r\nret = nla_parse_nested(tb, LWT_BPF_PROG_MAX, attr, bpf_prog_policy,\r\nNULL);\r\nif (ret < 0)\r\nreturn ret;\r\nif (!tb[LWT_BPF_PROG_FD] || !tb[LWT_BPF_PROG_NAME])\r\nreturn -EINVAL;\r\nprog->name = nla_memdup(tb[LWT_BPF_PROG_NAME], GFP_KERNEL);\r\nif (!prog->name)\r\nreturn -ENOMEM;\r\nfd = nla_get_u32(tb[LWT_BPF_PROG_FD]);\r\np = bpf_prog_get_type(fd, type);\r\nif (IS_ERR(p))\r\nreturn PTR_ERR(p);\r\nprog->prog = p;\r\nreturn 0;\r\n}\r\nstatic int bpf_build_state(struct nlattr *nla,\r\nunsigned int family, const void *cfg,\r\nstruct lwtunnel_state **ts,\r\nstruct netlink_ext_ack *extack)\r\n{\r\nstruct nlattr *tb[LWT_BPF_MAX + 1];\r\nstruct lwtunnel_state *newts;\r\nstruct bpf_lwt *bpf;\r\nint ret;\r\nif (family != AF_INET && family != AF_INET6)\r\nreturn -EAFNOSUPPORT;\r\nret = nla_parse_nested(tb, LWT_BPF_MAX, nla, bpf_nl_policy, extack);\r\nif (ret < 0)\r\nreturn ret;\r\nif (!tb[LWT_BPF_IN] && !tb[LWT_BPF_OUT] && !tb[LWT_BPF_XMIT])\r\nreturn -EINVAL;\r\nnewts = lwtunnel_state_alloc(sizeof(*bpf));\r\nif (!newts)\r\nreturn -ENOMEM;\r\nnewts->type = LWTUNNEL_ENCAP_BPF;\r\nbpf = bpf_lwt_lwtunnel(newts);\r\nif (tb[LWT_BPF_IN]) {\r\nnewts->flags |= LWTUNNEL_STATE_INPUT_REDIRECT;\r\nret = bpf_parse_prog(tb[LWT_BPF_IN], &bpf->in,\r\nBPF_PROG_TYPE_LWT_IN);\r\nif (ret < 0)\r\ngoto errout;\r\n}\r\nif (tb[LWT_BPF_OUT]) {\r\nnewts->flags |= LWTUNNEL_STATE_OUTPUT_REDIRECT;\r\nret = bpf_parse_prog(tb[LWT_BPF_OUT], &bpf->out,\r\nBPF_PROG_TYPE_LWT_OUT);\r\nif (ret < 0)\r\ngoto errout;\r\n}\r\nif (tb[LWT_BPF_XMIT]) {\r\nnewts->flags |= LWTUNNEL_STATE_XMIT_REDIRECT;\r\nret = bpf_parse_prog(tb[LWT_BPF_XMIT], &bpf->xmit,\r\nBPF_PROG_TYPE_LWT_XMIT);\r\nif (ret < 0)\r\ngoto errout;\r\n}\r\nif (tb[LWT_BPF_XMIT_HEADROOM]) {\r\nu32 headroom = nla_get_u32(tb[LWT_BPF_XMIT_HEADROOM]);\r\nif (headroom > LWT_BPF_MAX_HEADROOM) {\r\nret = -ERANGE;\r\ngoto errout;\r\n}\r\nnewts->headroom = headroom;\r\n}\r\nbpf->family = family;\r\n*ts = newts;\r\nreturn 0;\r\nerrout:\r\nbpf_destroy_state(newts);\r\nkfree(newts);\r\nreturn ret;\r\n}\r\nstatic int bpf_fill_lwt_prog(struct sk_buff *skb, int attr,\r\nstruct bpf_lwt_prog *prog)\r\n{\r\nstruct nlattr *nest;\r\nif (!prog->prog)\r\nreturn 0;\r\nnest = nla_nest_start(skb, attr);\r\nif (!nest)\r\nreturn -EMSGSIZE;\r\nif (prog->name &&\r\nnla_put_string(skb, LWT_BPF_PROG_NAME, prog->name))\r\nreturn -EMSGSIZE;\r\nreturn nla_nest_end(skb, nest);\r\n}\r\nstatic int bpf_fill_encap_info(struct sk_buff *skb, struct lwtunnel_state *lwt)\r\n{\r\nstruct bpf_lwt *bpf = bpf_lwt_lwtunnel(lwt);\r\nif (bpf_fill_lwt_prog(skb, LWT_BPF_IN, &bpf->in) < 0 ||\r\nbpf_fill_lwt_prog(skb, LWT_BPF_OUT, &bpf->out) < 0 ||\r\nbpf_fill_lwt_prog(skb, LWT_BPF_XMIT, &bpf->xmit) < 0)\r\nreturn -EMSGSIZE;\r\nreturn 0;\r\n}\r\nstatic int bpf_encap_nlsize(struct lwtunnel_state *lwtstate)\r\n{\r\nint nest_len = nla_total_size(sizeof(struct nlattr)) +\r\nnla_total_size(MAX_PROG_NAME) +\r\n0;\r\nreturn nest_len +\r\nnest_len +\r\nnest_len +\r\n0;\r\n}\r\nstatic int bpf_lwt_prog_cmp(struct bpf_lwt_prog *a, struct bpf_lwt_prog *b)\r\n{\r\nif (!a->name && !b->name)\r\nreturn 0;\r\nif (!a->name || !b->name)\r\nreturn 1;\r\nreturn strcmp(a->name, b->name);\r\n}\r\nstatic int bpf_encap_cmp(struct lwtunnel_state *a, struct lwtunnel_state *b)\r\n{\r\nstruct bpf_lwt *a_bpf = bpf_lwt_lwtunnel(a);\r\nstruct bpf_lwt *b_bpf = bpf_lwt_lwtunnel(b);\r\nreturn bpf_lwt_prog_cmp(&a_bpf->in, &b_bpf->in) ||\r\nbpf_lwt_prog_cmp(&a_bpf->out, &b_bpf->out) ||\r\nbpf_lwt_prog_cmp(&a_bpf->xmit, &b_bpf->xmit);\r\n}\r\nstatic int __init bpf_lwt_init(void)\r\n{\r\nreturn lwtunnel_encap_add_ops(&bpf_encap_ops, LWTUNNEL_ENCAP_BPF);\r\n}
