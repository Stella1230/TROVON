static int stmmac_jumbo_frm(void *p, struct sk_buff *skb, int csum)\r\n{\r\nstruct stmmac_tx_queue *tx_q = (struct stmmac_tx_queue *)p;\r\nunsigned int nopaged_len = skb_headlen(skb);\r\nstruct stmmac_priv *priv = tx_q->priv_data;\r\nunsigned int entry = tx_q->cur_tx;\r\nunsigned int bmax, des2;\r\nunsigned int i = 1, len;\r\nstruct dma_desc *desc;\r\ndesc = tx_q->dma_tx + entry;\r\nif (priv->plat->enh_desc)\r\nbmax = BUF_SIZE_8KiB;\r\nelse\r\nbmax = BUF_SIZE_2KiB;\r\nlen = nopaged_len - bmax;\r\ndes2 = dma_map_single(priv->device, skb->data,\r\nbmax, DMA_TO_DEVICE);\r\ndesc->des2 = cpu_to_le32(des2);\r\nif (dma_mapping_error(priv->device, des2))\r\nreturn -1;\r\ntx_q->tx_skbuff_dma[entry].buf = des2;\r\ntx_q->tx_skbuff_dma[entry].len = bmax;\r\npriv->hw->desc->prepare_tx_desc(desc, 1, bmax, csum, STMMAC_CHAIN_MODE,\r\n0, false, skb->len);\r\nwhile (len != 0) {\r\ntx_q->tx_skbuff[entry] = NULL;\r\nentry = STMMAC_GET_ENTRY(entry, DMA_TX_SIZE);\r\ndesc = tx_q->dma_tx + entry;\r\nif (len > bmax) {\r\ndes2 = dma_map_single(priv->device,\r\n(skb->data + bmax * i),\r\nbmax, DMA_TO_DEVICE);\r\ndesc->des2 = cpu_to_le32(des2);\r\nif (dma_mapping_error(priv->device, des2))\r\nreturn -1;\r\ntx_q->tx_skbuff_dma[entry].buf = des2;\r\ntx_q->tx_skbuff_dma[entry].len = bmax;\r\npriv->hw->desc->prepare_tx_desc(desc, 0, bmax, csum,\r\nSTMMAC_CHAIN_MODE, 1,\r\nfalse, skb->len);\r\nlen -= bmax;\r\ni++;\r\n} else {\r\ndes2 = dma_map_single(priv->device,\r\n(skb->data + bmax * i), len,\r\nDMA_TO_DEVICE);\r\ndesc->des2 = cpu_to_le32(des2);\r\nif (dma_mapping_error(priv->device, des2))\r\nreturn -1;\r\ntx_q->tx_skbuff_dma[entry].buf = des2;\r\ntx_q->tx_skbuff_dma[entry].len = len;\r\npriv->hw->desc->prepare_tx_desc(desc, 0, len, csum,\r\nSTMMAC_CHAIN_MODE, 1,\r\ntrue, skb->len);\r\nlen = 0;\r\n}\r\n}\r\ntx_q->cur_tx = entry;\r\nreturn entry;\r\n}\r\nstatic unsigned int stmmac_is_jumbo_frm(int len, int enh_desc)\r\n{\r\nunsigned int ret = 0;\r\nif ((enh_desc && (len > BUF_SIZE_8KiB)) ||\r\n(!enh_desc && (len > BUF_SIZE_2KiB))) {\r\nret = 1;\r\n}\r\nreturn ret;\r\n}\r\nstatic void stmmac_init_dma_chain(void *des, dma_addr_t phy_addr,\r\nunsigned int size, unsigned int extend_desc)\r\n{\r\nint i;\r\ndma_addr_t dma_phy = phy_addr;\r\nif (extend_desc) {\r\nstruct dma_extended_desc *p = (struct dma_extended_desc *)des;\r\nfor (i = 0; i < (size - 1); i++) {\r\ndma_phy += sizeof(struct dma_extended_desc);\r\np->basic.des3 = cpu_to_le32((unsigned int)dma_phy);\r\np++;\r\n}\r\np->basic.des3 = cpu_to_le32((unsigned int)phy_addr);\r\n} else {\r\nstruct dma_desc *p = (struct dma_desc *)des;\r\nfor (i = 0; i < (size - 1); i++) {\r\ndma_phy += sizeof(struct dma_desc);\r\np->des3 = cpu_to_le32((unsigned int)dma_phy);\r\np++;\r\n}\r\np->des3 = cpu_to_le32((unsigned int)phy_addr);\r\n}\r\n}\r\nstatic void stmmac_refill_desc3(void *priv_ptr, struct dma_desc *p)\r\n{\r\nstruct stmmac_rx_queue *rx_q = (struct stmmac_rx_queue *)priv_ptr;\r\nstruct stmmac_priv *priv = rx_q->priv_data;\r\nif (priv->hwts_rx_en && !priv->extend_desc)\r\np->des3 = cpu_to_le32((unsigned int)(rx_q->dma_rx_phy +\r\n(((rx_q->dirty_rx) + 1) %\r\nDMA_RX_SIZE) *\r\nsizeof(struct dma_desc)));\r\n}\r\nstatic void stmmac_clean_desc3(void *priv_ptr, struct dma_desc *p)\r\n{\r\nstruct stmmac_tx_queue *tx_q = (struct stmmac_tx_queue *)priv_ptr;\r\nstruct stmmac_priv *priv = tx_q->priv_data;\r\nunsigned int entry = tx_q->dirty_tx;\r\nif (tx_q->tx_skbuff_dma[entry].last_segment && !priv->extend_desc &&\r\npriv->hwts_tx_en)\r\np->des3 = cpu_to_le32((unsigned int)((tx_q->dma_tx_phy +\r\n((tx_q->dirty_tx + 1) % DMA_TX_SIZE))\r\n* sizeof(struct dma_desc)));\r\n}
