u32 cn23xx_vf_get_oq_ticks(struct octeon_device *oct, u32 time_intr_in_us)\r\n{\r\nu32 oqticks_per_us = (u32)oct->pfvf_hsword.coproc_tics_per_us;\r\noqticks_per_us *= 1000;\r\noqticks_per_us /= 1024;\r\noqticks_per_us *= time_intr_in_us;\r\noqticks_per_us /= 1000;\r\nreturn oqticks_per_us;\r\n}\r\nstatic int cn23xx_vf_reset_io_queues(struct octeon_device *oct, u32 num_queues)\r\n{\r\nu32 loop = BUSY_READING_REG_VF_LOOP_COUNT;\r\nint ret_val = 0;\r\nu32 q_no;\r\nu64 d64;\r\nfor (q_no = 0; q_no < num_queues; q_no++) {\r\nd64 = octeon_read_csr64(oct,\r\nCN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no));\r\nd64 |= CN23XX_PKT_INPUT_CTL_RST;\r\nocteon_write_csr64(oct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no),\r\nd64);\r\n}\r\nfor (q_no = 0; q_no < num_queues; q_no++) {\r\nu64 reg_val = octeon_read_csr64(oct,\r\nCN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no));\r\nwhile ((READ_ONCE(reg_val) & CN23XX_PKT_INPUT_CTL_RST) &&\r\n!(READ_ONCE(reg_val) & CN23XX_PKT_INPUT_CTL_QUIET) &&\r\nloop) {\r\nWRITE_ONCE(reg_val, octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no)));\r\nloop--;\r\n}\r\nif (!loop) {\r\ndev_err(&oct->pci_dev->dev,\r\n"clearing the reset reg failed or setting the quiet reg failed for qno: %u\n",\r\nq_no);\r\nreturn -1;\r\n}\r\nWRITE_ONCE(reg_val, READ_ONCE(reg_val) &\r\n~CN23XX_PKT_INPUT_CTL_RST);\r\nocteon_write_csr64(oct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no),\r\nREAD_ONCE(reg_val));\r\nWRITE_ONCE(reg_val, octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no)));\r\nif (READ_ONCE(reg_val) & CN23XX_PKT_INPUT_CTL_RST) {\r\ndev_err(&oct->pci_dev->dev,\r\n"clearing the reset failed for qno: %u\n",\r\nq_no);\r\nret_val = -1;\r\n}\r\n}\r\nreturn ret_val;\r\n}\r\nstatic int cn23xx_vf_setup_global_input_regs(struct octeon_device *oct)\r\n{\r\nstruct octeon_cn23xx_vf *cn23xx = (struct octeon_cn23xx_vf *)oct->chip;\r\nstruct octeon_instr_queue *iq;\r\nu64 q_no, intr_threshold;\r\nu64 d64;\r\nif (cn23xx_vf_reset_io_queues(oct, oct->sriov_info.rings_per_vf))\r\nreturn -1;\r\nfor (q_no = 0; q_no < (oct->sriov_info.rings_per_vf); q_no++) {\r\nvoid __iomem *inst_cnt_reg;\r\nocteon_write_csr64(oct, CN23XX_VF_SLI_IQ_DOORBELL(q_no),\r\n0xFFFFFFFF);\r\niq = oct->instr_queue[q_no];\r\nif (iq)\r\ninst_cnt_reg = iq->inst_cnt_reg;\r\nelse\r\ninst_cnt_reg = (u8 *)oct->mmio[0].hw_addr +\r\nCN23XX_VF_SLI_IQ_INSTR_COUNT64(q_no);\r\nd64 = octeon_read_csr64(oct,\r\nCN23XX_VF_SLI_IQ_INSTR_COUNT64(q_no));\r\nd64 &= 0xEFFFFFFFFFFFFFFFL;\r\nocteon_write_csr64(oct, CN23XX_VF_SLI_IQ_INSTR_COUNT64(q_no),\r\nd64);\r\nocteon_write_csr64(oct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no),\r\nCN23XX_PKT_INPUT_CTL_MASK);\r\nintr_threshold = CFG_GET_IQ_INTR_PKT(cn23xx->conf) &\r\nCN23XX_PKT_IN_DONE_WMARK_MASK;\r\nwriteq((readq(inst_cnt_reg) &\r\n~(CN23XX_PKT_IN_DONE_WMARK_MASK <<\r\nCN23XX_PKT_IN_DONE_WMARK_BIT_POS)) |\r\n(intr_threshold << CN23XX_PKT_IN_DONE_WMARK_BIT_POS),\r\ninst_cnt_reg);\r\n}\r\nreturn 0;\r\n}\r\nstatic void cn23xx_vf_setup_global_output_regs(struct octeon_device *oct)\r\n{\r\nu32 reg_val;\r\nu32 q_no;\r\nfor (q_no = 0; q_no < (oct->sriov_info.rings_per_vf); q_no++) {\r\nocteon_write_csr(oct, CN23XX_VF_SLI_OQ_PKTS_CREDIT(q_no),\r\n0xFFFFFFFF);\r\nreg_val =\r\nocteon_read_csr(oct, CN23XX_VF_SLI_OQ_PKTS_SENT(q_no));\r\nreg_val &= 0xEFFFFFFFFFFFFFFFL;\r\nreg_val =\r\nocteon_read_csr(oct, CN23XX_VF_SLI_OQ_PKT_CONTROL(q_no));\r\nreg_val |= CN23XX_PKT_OUTPUT_CTL_DPTR;\r\nreg_val &= ~(CN23XX_PKT_OUTPUT_CTL_BMODE);\r\nreg_val &= ~(CN23XX_PKT_OUTPUT_CTL_ROR_P);\r\nreg_val &= ~(CN23XX_PKT_OUTPUT_CTL_NSR_P);\r\n#ifdef __LITTLE_ENDIAN_BITFIELD\r\nreg_val &= ~(CN23XX_PKT_OUTPUT_CTL_ES_P);\r\n#else\r\nreg_val |= (CN23XX_PKT_OUTPUT_CTL_ES_P);\r\n#endif\r\nreg_val &= ~(CN23XX_PKT_OUTPUT_CTL_ROR);\r\nreg_val &= ~(CN23XX_PKT_OUTPUT_CTL_NSR);\r\nreg_val |= (CN23XX_PKT_OUTPUT_CTL_ES);\r\nocteon_write_csr(oct, CN23XX_VF_SLI_OQ_PKT_CONTROL(q_no),\r\nreg_val);\r\n}\r\n}\r\nstatic int cn23xx_setup_vf_device_regs(struct octeon_device *oct)\r\n{\r\nif (cn23xx_vf_setup_global_input_regs(oct))\r\nreturn -1;\r\ncn23xx_vf_setup_global_output_regs(oct);\r\nreturn 0;\r\n}\r\nstatic void cn23xx_setup_vf_iq_regs(struct octeon_device *oct, u32 iq_no)\r\n{\r\nstruct octeon_instr_queue *iq = oct->instr_queue[iq_no];\r\nu64 pkt_in_done;\r\nocteon_write_csr64(oct, CN23XX_VF_SLI_IQ_BASE_ADDR64(iq_no),\r\niq->base_addr_dma);\r\nocteon_write_csr(oct, CN23XX_VF_SLI_IQ_SIZE(iq_no), iq->max_count);\r\niq->doorbell_reg =\r\n(u8 *)oct->mmio[0].hw_addr + CN23XX_VF_SLI_IQ_DOORBELL(iq_no);\r\niq->inst_cnt_reg =\r\n(u8 *)oct->mmio[0].hw_addr + CN23XX_VF_SLI_IQ_INSTR_COUNT64(iq_no);\r\ndev_dbg(&oct->pci_dev->dev, "InstQ[%d]:dbell reg @ 0x%p instcnt_reg @ 0x%p\n",\r\niq_no, iq->doorbell_reg, iq->inst_cnt_reg);\r\npkt_in_done = readq(iq->inst_cnt_reg);\r\nif (oct->msix_on) {\r\nwriteq((pkt_in_done | CN23XX_INTR_CINT_ENB),\r\niq->inst_cnt_reg);\r\n}\r\niq->reset_instr_cnt = 0;\r\n}\r\nstatic void cn23xx_setup_vf_oq_regs(struct octeon_device *oct, u32 oq_no)\r\n{\r\nstruct octeon_droq *droq = oct->droq[oq_no];\r\nocteon_write_csr64(oct, CN23XX_VF_SLI_OQ_BASE_ADDR64(oq_no),\r\ndroq->desc_ring_dma);\r\nocteon_write_csr(oct, CN23XX_VF_SLI_OQ_SIZE(oq_no), droq->max_count);\r\nocteon_write_csr(oct, CN23XX_VF_SLI_OQ_BUFF_INFO_SIZE(oq_no),\r\ndroq->buffer_size);\r\ndroq->pkts_sent_reg =\r\n(u8 *)oct->mmio[0].hw_addr + CN23XX_VF_SLI_OQ_PKTS_SENT(oq_no);\r\ndroq->pkts_credit_reg =\r\n(u8 *)oct->mmio[0].hw_addr + CN23XX_VF_SLI_OQ_PKTS_CREDIT(oq_no);\r\n}\r\nstatic void cn23xx_vf_mbox_thread(struct work_struct *work)\r\n{\r\nstruct cavium_wk *wk = (struct cavium_wk *)work;\r\nstruct octeon_mbox *mbox = (struct octeon_mbox *)wk->ctxptr;\r\nocteon_mbox_process_message(mbox);\r\n}\r\nstatic int cn23xx_free_vf_mbox(struct octeon_device *oct)\r\n{\r\ncancel_delayed_work_sync(&oct->mbox[0]->mbox_poll_wk.work);\r\nvfree(oct->mbox[0]);\r\nreturn 0;\r\n}\r\nstatic int cn23xx_setup_vf_mbox(struct octeon_device *oct)\r\n{\r\nstruct octeon_mbox *mbox = NULL;\r\nmbox = vmalloc(sizeof(*mbox));\r\nif (!mbox)\r\nreturn 1;\r\nmemset(mbox, 0, sizeof(struct octeon_mbox));\r\nspin_lock_init(&mbox->lock);\r\nmbox->oct_dev = oct;\r\nmbox->q_no = 0;\r\nmbox->state = OCTEON_MBOX_STATE_IDLE;\r\nmbox->mbox_int_reg =\r\n(u8 *)oct->mmio[0].hw_addr + CN23XX_VF_SLI_PKT_MBOX_INT(0);\r\nmbox->mbox_read_reg =\r\n(u8 *)oct->mmio[0].hw_addr + CN23XX_SLI_PKT_PF_VF_MBOX_SIG(0, 0);\r\nmbox->mbox_write_reg =\r\n(u8 *)oct->mmio[0].hw_addr + CN23XX_SLI_PKT_PF_VF_MBOX_SIG(0, 1);\r\nINIT_DELAYED_WORK(&mbox->mbox_poll_wk.work,\r\ncn23xx_vf_mbox_thread);\r\nmbox->mbox_poll_wk.ctxptr = mbox;\r\noct->mbox[0] = mbox;\r\nwriteq(OCTEON_PFVFSIG, mbox->mbox_read_reg);\r\nreturn 0;\r\n}\r\nstatic int cn23xx_enable_vf_io_queues(struct octeon_device *oct)\r\n{\r\nu32 q_no;\r\nfor (q_no = 0; q_no < oct->num_iqs; q_no++) {\r\nu64 reg_val;\r\nif (oct->io_qmask.iq64B & BIT_ULL(q_no)) {\r\nreg_val = octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no));\r\nreg_val |= CN23XX_PKT_INPUT_CTL_IS_64B;\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no), reg_val);\r\n}\r\nif (oct->io_qmask.iq & BIT_ULL(q_no)) {\r\nreg_val = octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no));\r\nreg_val |= CN23XX_PKT_INPUT_CTL_RING_ENB;\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no), reg_val);\r\n}\r\n}\r\nfor (q_no = 0; q_no < oct->num_oqs; q_no++) {\r\nu32 reg_val;\r\nif (oct->io_qmask.oq & BIT_ULL(q_no)) {\r\nreg_val = octeon_read_csr(\r\noct, CN23XX_VF_SLI_OQ_PKT_CONTROL(q_no));\r\nreg_val |= CN23XX_PKT_OUTPUT_CTL_RING_ENB;\r\nocteon_write_csr(\r\noct, CN23XX_VF_SLI_OQ_PKT_CONTROL(q_no), reg_val);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void cn23xx_disable_vf_io_queues(struct octeon_device *oct)\r\n{\r\nu32 num_queues = oct->num_iqs;\r\nif (num_queues < oct->num_oqs)\r\nnum_queues = oct->num_oqs;\r\ncn23xx_vf_reset_io_queues(oct, num_queues);\r\n}\r\nvoid cn23xx_vf_ask_pf_to_do_flr(struct octeon_device *oct)\r\n{\r\nstruct octeon_mbox_cmd mbox_cmd;\r\nmbox_cmd.msg.u64 = 0;\r\nmbox_cmd.msg.s.type = OCTEON_MBOX_REQUEST;\r\nmbox_cmd.msg.s.resp_needed = 0;\r\nmbox_cmd.msg.s.cmd = OCTEON_VF_FLR_REQUEST;\r\nmbox_cmd.msg.s.len = 1;\r\nmbox_cmd.q_no = 0;\r\nmbox_cmd.recv_len = 0;\r\nmbox_cmd.recv_status = 0;\r\nmbox_cmd.fn = NULL;\r\nmbox_cmd.fn_arg = 0;\r\nocteon_mbox_write(oct, &mbox_cmd);\r\n}\r\nstatic void octeon_pfvf_hs_callback(struct octeon_device *oct,\r\nstruct octeon_mbox_cmd *cmd,\r\nvoid *arg)\r\n{\r\nu32 major = 0;\r\nmemcpy((uint8_t *)&oct->pfvf_hsword, cmd->msg.s.params,\r\nCN23XX_MAILBOX_MSGPARAM_SIZE);\r\nif (cmd->recv_len > 1) {\r\nmajor = ((struct lio_version *)(cmd->data))->major;\r\nmajor = major << 16;\r\n}\r\natomic_set((atomic_t *)arg, major | 1);\r\n}\r\nint cn23xx_octeon_pfvf_handshake(struct octeon_device *oct)\r\n{\r\nstruct octeon_mbox_cmd mbox_cmd;\r\nu32 q_no, count = 0;\r\natomic_t status;\r\nu32 pfmajor;\r\nu32 vfmajor;\r\nu32 ret;\r\ndev_dbg(&oct->pci_dev->dev, "requesting info from pf\n");\r\nmbox_cmd.msg.u64 = 0;\r\nmbox_cmd.msg.s.type = OCTEON_MBOX_REQUEST;\r\nmbox_cmd.msg.s.resp_needed = 1;\r\nmbox_cmd.msg.s.cmd = OCTEON_VF_ACTIVE;\r\nmbox_cmd.msg.s.len = 2;\r\nmbox_cmd.data[0] = 0;\r\n((struct lio_version *)&mbox_cmd.data[0])->major =\r\nLIQUIDIO_BASE_MAJOR_VERSION;\r\n((struct lio_version *)&mbox_cmd.data[0])->minor =\r\nLIQUIDIO_BASE_MINOR_VERSION;\r\n((struct lio_version *)&mbox_cmd.data[0])->micro =\r\nLIQUIDIO_BASE_MICRO_VERSION;\r\nmbox_cmd.q_no = 0;\r\nmbox_cmd.recv_len = 0;\r\nmbox_cmd.recv_status = 0;\r\nmbox_cmd.fn = (octeon_mbox_callback_t)octeon_pfvf_hs_callback;\r\nmbox_cmd.fn_arg = &status;\r\nocteon_mbox_write(oct, &mbox_cmd);\r\natomic_set(&status, 0);\r\ndo {\r\nschedule_timeout_uninterruptible(1);\r\n} while ((!atomic_read(&status)) && (count++ < 100000));\r\nret = atomic_read(&status);\r\nif (!ret) {\r\ndev_err(&oct->pci_dev->dev, "octeon_pfvf_handshake timeout\n");\r\nreturn 1;\r\n}\r\nfor (q_no = 0 ; q_no < oct->num_iqs ; q_no++)\r\noct->instr_queue[q_no]->txpciq.s.pkind = oct->pfvf_hsword.pkind;\r\nvfmajor = LIQUIDIO_BASE_MAJOR_VERSION;\r\npfmajor = ret >> 16;\r\nif (pfmajor != vfmajor) {\r\ndev_err(&oct->pci_dev->dev,\r\n"VF Liquidio driver (major version %d) is not compatible with Liquidio PF driver (major version %d)\n",\r\nvfmajor, pfmajor);\r\nreturn 1;\r\n}\r\ndev_dbg(&oct->pci_dev->dev,\r\n"VF Liquidio driver (major version %d), Liquidio PF driver (major version %d)\n",\r\nvfmajor, pfmajor);\r\ndev_dbg(&oct->pci_dev->dev, "got data from pf pkind is %d\n",\r\noct->pfvf_hsword.pkind);\r\nreturn 0;\r\n}\r\nstatic void cn23xx_handle_vf_mbox_intr(struct octeon_ioq_vector *ioq_vector)\r\n{\r\nstruct octeon_device *oct = ioq_vector->oct_dev;\r\nu64 mbox_int_val;\r\nif (!ioq_vector->droq_index) {\r\nmbox_int_val = readq(oct->mbox[0]->mbox_int_reg);\r\nwriteq(mbox_int_val, oct->mbox[0]->mbox_int_reg);\r\nif (octeon_mbox_read(oct->mbox[0]))\r\nschedule_delayed_work(&oct->mbox[0]->mbox_poll_wk.work,\r\nmsecs_to_jiffies(0));\r\n}\r\n}\r\nstatic u64 cn23xx_vf_msix_interrupt_handler(void *dev)\r\n{\r\nstruct octeon_ioq_vector *ioq_vector = (struct octeon_ioq_vector *)dev;\r\nstruct octeon_device *oct = ioq_vector->oct_dev;\r\nstruct octeon_droq *droq = oct->droq[ioq_vector->droq_index];\r\nu64 pkts_sent;\r\nu64 ret = 0;\r\ndev_dbg(&oct->pci_dev->dev, "In %s octeon_dev @ %p\n", __func__, oct);\r\npkts_sent = readq(droq->pkts_sent_reg);\r\nif (!pkts_sent || (pkts_sent == 0xFFFFFFFFFFFFFFFFULL))\r\nreturn ret;\r\nif ((pkts_sent & CN23XX_INTR_PO_INT) ||\r\n(pkts_sent & CN23XX_INTR_PI_INT)) {\r\nif (pkts_sent & CN23XX_INTR_PO_INT)\r\nret |= MSIX_PO_INT;\r\n}\r\nif (pkts_sent & CN23XX_INTR_PI_INT)\r\nret |= MSIX_PI_INT;\r\nif (pkts_sent & CN23XX_INTR_MBOX_INT) {\r\ncn23xx_handle_vf_mbox_intr(ioq_vector);\r\nret |= MSIX_MBOX_INT;\r\n}\r\nreturn ret;\r\n}\r\nstatic u32 cn23xx_update_read_index(struct octeon_instr_queue *iq)\r\n{\r\nu32 pkt_in_done = readl(iq->inst_cnt_reg);\r\nu32 last_done;\r\nu32 new_idx;\r\nlast_done = pkt_in_done - iq->pkt_in_done;\r\niq->pkt_in_done = pkt_in_done;\r\nnew_idx = (iq->octeon_read_index +\r\n(u32)(last_done & CN23XX_PKT_IN_DONE_CNT_MASK)) %\r\niq->max_count;\r\nreturn new_idx;\r\n}\r\nstatic void cn23xx_enable_vf_interrupt(struct octeon_device *oct, u8 intr_flag)\r\n{\r\nstruct octeon_cn23xx_vf *cn23xx = (struct octeon_cn23xx_vf *)oct->chip;\r\nu32 q_no, time_threshold;\r\nif (intr_flag & OCTEON_OUTPUT_INTR) {\r\nfor (q_no = 0; q_no < oct->num_oqs; q_no++) {\r\ntime_threshold = cn23xx_vf_get_oq_ticks(\r\noct, (u32)CFG_GET_OQ_INTR_TIME(cn23xx->conf));\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_OQ_PKT_INT_LEVELS(q_no),\r\n(CFG_GET_OQ_INTR_PKT(cn23xx->conf) |\r\n((u64)time_threshold << 32)));\r\n}\r\n}\r\nif (intr_flag & OCTEON_INPUT_INTR) {\r\nfor (q_no = 0; q_no < oct->num_oqs; q_no++) {\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_IQ_INSTR_COUNT64(q_no),\r\n((octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_INSTR_COUNT64(q_no)) &\r\n~CN23XX_PKT_IN_DONE_CNT_MASK) |\r\nCN23XX_INTR_CINT_ENB));\r\n}\r\n}\r\nif (intr_flag & OCTEON_MBOX_INTR) {\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_PKT_MBOX_INT(0),\r\n(octeon_read_csr64(oct, CN23XX_VF_SLI_PKT_MBOX_INT(0)) |\r\nCN23XX_INTR_MBOX_ENB));\r\n}\r\n}\r\nstatic void cn23xx_disable_vf_interrupt(struct octeon_device *oct, u8 intr_flag)\r\n{\r\nu32 q_no;\r\nif (intr_flag & OCTEON_OUTPUT_INTR) {\r\nfor (q_no = 0; q_no < oct->num_oqs; q_no++) {\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_OQ_PKT_INT_LEVELS(q_no),\r\n0x3fffffffffffff);\r\n}\r\n}\r\nif (intr_flag & OCTEON_INPUT_INTR) {\r\nfor (q_no = 0; q_no < oct->num_oqs; q_no++) {\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_IQ_INSTR_COUNT64(q_no),\r\n(octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_INSTR_COUNT64(q_no)) &\r\n~(CN23XX_INTR_CINT_ENB |\r\nCN23XX_PKT_IN_DONE_CNT_MASK)));\r\n}\r\n}\r\nif (intr_flag & OCTEON_MBOX_INTR) {\r\nocteon_write_csr64(\r\noct, CN23XX_VF_SLI_PKT_MBOX_INT(0),\r\n(octeon_read_csr64(oct, CN23XX_VF_SLI_PKT_MBOX_INT(0)) &\r\n~CN23XX_INTR_MBOX_ENB));\r\n}\r\n}\r\nint cn23xx_setup_octeon_vf_device(struct octeon_device *oct)\r\n{\r\nstruct octeon_cn23xx_vf *cn23xx = (struct octeon_cn23xx_vf *)oct->chip;\r\nu32 rings_per_vf, ring_flag;\r\nu64 reg_val;\r\nif (octeon_map_pci_barx(oct, 0, 0))\r\nreturn 1;\r\nreg_val = octeon_read_csr64(oct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(0));\r\noct->pf_num = (reg_val >> CN23XX_PKT_INPUT_CTL_PF_NUM_POS) &\r\nCN23XX_PKT_INPUT_CTL_PF_NUM_MASK;\r\noct->vf_num = (reg_val >> CN23XX_PKT_INPUT_CTL_VF_NUM_POS) &\r\nCN23XX_PKT_INPUT_CTL_VF_NUM_MASK;\r\nreg_val = reg_val >> CN23XX_PKT_INPUT_CTL_RPVF_POS;\r\nrings_per_vf = reg_val & CN23XX_PKT_INPUT_CTL_RPVF_MASK;\r\nring_flag = 0;\r\ncn23xx->conf = oct_get_config_info(oct, LIO_23XX);\r\nif (!cn23xx->conf) {\r\ndev_err(&oct->pci_dev->dev, "%s No Config found for CN23XX\n",\r\n__func__);\r\nocteon_unmap_pci_barx(oct, 0);\r\nreturn 1;\r\n}\r\nif (oct->sriov_info.rings_per_vf > rings_per_vf) {\r\ndev_warn(&oct->pci_dev->dev,\r\n"num_queues:%d greater than PF configured rings_per_vf:%d. Reducing to %d.\n",\r\noct->sriov_info.rings_per_vf, rings_per_vf,\r\nrings_per_vf);\r\noct->sriov_info.rings_per_vf = rings_per_vf;\r\n} else {\r\nif (rings_per_vf > num_present_cpus()) {\r\ndev_warn(&oct->pci_dev->dev,\r\n"PF configured rings_per_vf:%d greater than num_cpu:%d. Using rings_per_vf:%d equal to num cpus\n",\r\nrings_per_vf,\r\nnum_present_cpus(),\r\nnum_present_cpus());\r\noct->sriov_info.rings_per_vf =\r\nnum_present_cpus();\r\n} else {\r\noct->sriov_info.rings_per_vf = rings_per_vf;\r\n}\r\n}\r\noct->fn_list.setup_iq_regs = cn23xx_setup_vf_iq_regs;\r\noct->fn_list.setup_oq_regs = cn23xx_setup_vf_oq_regs;\r\noct->fn_list.setup_mbox = cn23xx_setup_vf_mbox;\r\noct->fn_list.free_mbox = cn23xx_free_vf_mbox;\r\noct->fn_list.msix_interrupt_handler = cn23xx_vf_msix_interrupt_handler;\r\noct->fn_list.setup_device_regs = cn23xx_setup_vf_device_regs;\r\noct->fn_list.update_iq_read_idx = cn23xx_update_read_index;\r\noct->fn_list.enable_interrupt = cn23xx_enable_vf_interrupt;\r\noct->fn_list.disable_interrupt = cn23xx_disable_vf_interrupt;\r\noct->fn_list.enable_io_queues = cn23xx_enable_vf_io_queues;\r\noct->fn_list.disable_io_queues = cn23xx_disable_vf_io_queues;\r\nreturn 0;\r\n}\r\nvoid cn23xx_dump_vf_iq_regs(struct octeon_device *oct)\r\n{\r\nu32 regval, q_no;\r\ndev_dbg(&oct->pci_dev->dev, "SLI_IQ_DOORBELL_0 [0x%x]: 0x%016llx\n",\r\nCN23XX_VF_SLI_IQ_DOORBELL(0),\r\nCVM_CAST64(octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_DOORBELL(0))));\r\ndev_dbg(&oct->pci_dev->dev, "SLI_IQ_BASEADDR_0 [0x%x]: 0x%016llx\n",\r\nCN23XX_VF_SLI_IQ_BASE_ADDR64(0),\r\nCVM_CAST64(octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_BASE_ADDR64(0))));\r\ndev_dbg(&oct->pci_dev->dev, "SLI_IQ_FIFO_RSIZE_0 [0x%x]: 0x%016llx\n",\r\nCN23XX_VF_SLI_IQ_SIZE(0),\r\nCVM_CAST64(octeon_read_csr64(oct, CN23XX_VF_SLI_IQ_SIZE(0))));\r\nfor (q_no = 0; q_no < oct->sriov_info.rings_per_vf; q_no++) {\r\ndev_dbg(&oct->pci_dev->dev, "SLI_PKT[%d]_INPUT_CTL [0x%x]: 0x%016llx\n",\r\nq_no, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no),\r\nCVM_CAST64(octeon_read_csr64(\r\noct, CN23XX_VF_SLI_IQ_PKT_CONTROL64(q_no))));\r\n}\r\npci_read_config_dword(oct->pci_dev, CN23XX_CONFIG_PCIE_DEVCTL, &regval);\r\ndev_dbg(&oct->pci_dev->dev, "Config DevCtl [0x%x]: 0x%08x\n",\r\nCN23XX_CONFIG_PCIE_DEVCTL, regval);\r\n}
