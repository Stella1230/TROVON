static int kvm_set_pic_irq(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level,\r\nbool line_status)\r\n{\r\nstruct kvm_pic *pic = kvm->arch.vpic;\r\nreturn kvm_pic_set_irq(pic, e->irqchip.pin, irq_source_id, level);\r\n}\r\nstatic int kvm_set_ioapic_irq(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level,\r\nbool line_status)\r\n{\r\nstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\r\nreturn kvm_ioapic_set_irq(ioapic, e->irqchip.pin, irq_source_id, level,\r\nline_status);\r\n}\r\nint kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,\r\nstruct kvm_lapic_irq *irq, struct dest_map *dest_map)\r\n{\r\nint i, r = -1;\r\nstruct kvm_vcpu *vcpu, *lowest = NULL;\r\nunsigned long dest_vcpu_bitmap[BITS_TO_LONGS(KVM_MAX_VCPUS)];\r\nunsigned int dest_vcpus = 0;\r\nif (irq->dest_mode == 0 && irq->dest_id == 0xff &&\r\nkvm_lowest_prio_delivery(irq)) {\r\nprintk(KERN_INFO "kvm: apic: phys broadcast and lowest prio\n");\r\nirq->delivery_mode = APIC_DM_FIXED;\r\n}\r\nif (kvm_irq_delivery_to_apic_fast(kvm, src, irq, &r, dest_map))\r\nreturn r;\r\nmemset(dest_vcpu_bitmap, 0, sizeof(dest_vcpu_bitmap));\r\nkvm_for_each_vcpu(i, vcpu, kvm) {\r\nif (!kvm_apic_present(vcpu))\r\ncontinue;\r\nif (!kvm_apic_match_dest(vcpu, src, irq->shorthand,\r\nirq->dest_id, irq->dest_mode))\r\ncontinue;\r\nif (!kvm_lowest_prio_delivery(irq)) {\r\nif (r < 0)\r\nr = 0;\r\nr += kvm_apic_set_irq(vcpu, irq, dest_map);\r\n} else if (kvm_lapic_enabled(vcpu)) {\r\nif (!kvm_vector_hashing_enabled()) {\r\nif (!lowest)\r\nlowest = vcpu;\r\nelse if (kvm_apic_compare_prio(vcpu, lowest) < 0)\r\nlowest = vcpu;\r\n} else {\r\n__set_bit(i, dest_vcpu_bitmap);\r\ndest_vcpus++;\r\n}\r\n}\r\n}\r\nif (dest_vcpus != 0) {\r\nint idx = kvm_vector_to_index(irq->vector, dest_vcpus,\r\ndest_vcpu_bitmap, KVM_MAX_VCPUS);\r\nlowest = kvm_get_vcpu(kvm, idx);\r\n}\r\nif (lowest)\r\nr = kvm_apic_set_irq(lowest, irq, dest_map);\r\nreturn r;\r\n}\r\nvoid kvm_set_msi_irq(struct kvm *kvm, struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm_lapic_irq *irq)\r\n{\r\ntrace_kvm_msi_set_irq(e->msi.address_lo | (kvm->arch.x2apic_format ?\r\n(u64)e->msi.address_hi << 32 : 0),\r\ne->msi.data);\r\nirq->dest_id = (e->msi.address_lo &\r\nMSI_ADDR_DEST_ID_MASK) >> MSI_ADDR_DEST_ID_SHIFT;\r\nif (kvm->arch.x2apic_format)\r\nirq->dest_id |= MSI_ADDR_EXT_DEST_ID(e->msi.address_hi);\r\nirq->vector = (e->msi.data &\r\nMSI_DATA_VECTOR_MASK) >> MSI_DATA_VECTOR_SHIFT;\r\nirq->dest_mode = (1 << MSI_ADDR_DEST_MODE_SHIFT) & e->msi.address_lo;\r\nirq->trig_mode = (1 << MSI_DATA_TRIGGER_SHIFT) & e->msi.data;\r\nirq->delivery_mode = e->msi.data & 0x700;\r\nirq->msi_redir_hint = ((e->msi.address_lo\r\n& MSI_ADDR_REDIRECTION_LOWPRI) > 0);\r\nirq->level = 1;\r\nirq->shorthand = 0;\r\n}\r\nstatic inline bool kvm_msi_route_invalid(struct kvm *kvm,\r\nstruct kvm_kernel_irq_routing_entry *e)\r\n{\r\nreturn kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);\r\n}\r\nint kvm_set_msi(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level, bool line_status)\r\n{\r\nstruct kvm_lapic_irq irq;\r\nif (kvm_msi_route_invalid(kvm, e))\r\nreturn -EINVAL;\r\nif (!level)\r\nreturn -1;\r\nkvm_set_msi_irq(kvm, e, &irq);\r\nreturn kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);\r\n}\r\nstatic int kvm_hv_set_sint(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level,\r\nbool line_status)\r\n{\r\nif (!level)\r\nreturn -1;\r\nreturn kvm_hv_synic_set_irq(kvm, e->hv_sint.vcpu, e->hv_sint.sint);\r\n}\r\nint kvm_arch_set_irq_inatomic(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level,\r\nbool line_status)\r\n{\r\nstruct kvm_lapic_irq irq;\r\nint r;\r\nswitch (e->type) {\r\ncase KVM_IRQ_ROUTING_HV_SINT:\r\nreturn kvm_hv_set_sint(e, kvm, irq_source_id, level,\r\nline_status);\r\ncase KVM_IRQ_ROUTING_MSI:\r\nif (kvm_msi_route_invalid(kvm, e))\r\nreturn -EINVAL;\r\nkvm_set_msi_irq(kvm, e, &irq);\r\nif (kvm_irq_delivery_to_apic_fast(kvm, NULL, &irq, &r, NULL))\r\nreturn r;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn -EWOULDBLOCK;\r\n}\r\nint kvm_request_irq_source_id(struct kvm *kvm)\r\n{\r\nunsigned long *bitmap = &kvm->arch.irq_sources_bitmap;\r\nint irq_source_id;\r\nmutex_lock(&kvm->irq_lock);\r\nirq_source_id = find_first_zero_bit(bitmap, BITS_PER_LONG);\r\nif (irq_source_id >= BITS_PER_LONG) {\r\nprintk(KERN_WARNING "kvm: exhaust allocatable IRQ sources!\n");\r\nirq_source_id = -EFAULT;\r\ngoto unlock;\r\n}\r\nASSERT(irq_source_id != KVM_USERSPACE_IRQ_SOURCE_ID);\r\nASSERT(irq_source_id != KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID);\r\nset_bit(irq_source_id, bitmap);\r\nunlock:\r\nmutex_unlock(&kvm->irq_lock);\r\nreturn irq_source_id;\r\n}\r\nvoid kvm_free_irq_source_id(struct kvm *kvm, int irq_source_id)\r\n{\r\nASSERT(irq_source_id != KVM_USERSPACE_IRQ_SOURCE_ID);\r\nASSERT(irq_source_id != KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID);\r\nmutex_lock(&kvm->irq_lock);\r\nif (irq_source_id < 0 ||\r\nirq_source_id >= BITS_PER_LONG) {\r\nprintk(KERN_ERR "kvm: IRQ source ID out of range!\n");\r\ngoto unlock;\r\n}\r\nclear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);\r\nif (!irqchip_kernel(kvm))\r\ngoto unlock;\r\nkvm_ioapic_clear_all(kvm->arch.vioapic, irq_source_id);\r\nkvm_pic_clear_all(kvm->arch.vpic, irq_source_id);\r\nunlock:\r\nmutex_unlock(&kvm->irq_lock);\r\n}\r\nvoid kvm_register_irq_mask_notifier(struct kvm *kvm, int irq,\r\nstruct kvm_irq_mask_notifier *kimn)\r\n{\r\nmutex_lock(&kvm->irq_lock);\r\nkimn->irq = irq;\r\nhlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);\r\nmutex_unlock(&kvm->irq_lock);\r\n}\r\nvoid kvm_unregister_irq_mask_notifier(struct kvm *kvm, int irq,\r\nstruct kvm_irq_mask_notifier *kimn)\r\n{\r\nmutex_lock(&kvm->irq_lock);\r\nhlist_del_rcu(&kimn->link);\r\nmutex_unlock(&kvm->irq_lock);\r\nsynchronize_srcu(&kvm->irq_srcu);\r\n}\r\nvoid kvm_fire_mask_notifiers(struct kvm *kvm, unsigned irqchip, unsigned pin,\r\nbool mask)\r\n{\r\nstruct kvm_irq_mask_notifier *kimn;\r\nint idx, gsi;\r\nidx = srcu_read_lock(&kvm->irq_srcu);\r\ngsi = kvm_irq_map_chip_pin(kvm, irqchip, pin);\r\nif (gsi != -1)\r\nhlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)\r\nif (kimn->irq == gsi)\r\nkimn->func(kimn, mask);\r\nsrcu_read_unlock(&kvm->irq_srcu, idx);\r\n}\r\nbool kvm_arch_can_set_irq_routing(struct kvm *kvm)\r\n{\r\nreturn irqchip_in_kernel(kvm);\r\n}\r\nint kvm_set_routing_entry(struct kvm *kvm,\r\nstruct kvm_kernel_irq_routing_entry *e,\r\nconst struct kvm_irq_routing_entry *ue)\r\n{\r\nswitch (ue->type) {\r\ncase KVM_IRQ_ROUTING_IRQCHIP:\r\nif (irqchip_split(kvm))\r\nreturn -EINVAL;\r\ne->irqchip.pin = ue->u.irqchip.pin;\r\nswitch (ue->u.irqchip.irqchip) {\r\ncase KVM_IRQCHIP_PIC_SLAVE:\r\ne->irqchip.pin += PIC_NUM_PINS / 2;\r\ncase KVM_IRQCHIP_PIC_MASTER:\r\nif (ue->u.irqchip.pin >= PIC_NUM_PINS / 2)\r\nreturn -EINVAL;\r\ne->set = kvm_set_pic_irq;\r\nbreak;\r\ncase KVM_IRQCHIP_IOAPIC:\r\nif (ue->u.irqchip.pin >= KVM_IOAPIC_NUM_PINS)\r\nreturn -EINVAL;\r\ne->set = kvm_set_ioapic_irq;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ne->irqchip.irqchip = ue->u.irqchip.irqchip;\r\nbreak;\r\ncase KVM_IRQ_ROUTING_MSI:\r\ne->set = kvm_set_msi;\r\ne->msi.address_lo = ue->u.msi.address_lo;\r\ne->msi.address_hi = ue->u.msi.address_hi;\r\ne->msi.data = ue->u.msi.data;\r\nif (kvm_msi_route_invalid(kvm, e))\r\nreturn -EINVAL;\r\nbreak;\r\ncase KVM_IRQ_ROUTING_HV_SINT:\r\ne->set = kvm_hv_set_sint;\r\ne->hv_sint.vcpu = ue->u.hv_sint.vcpu;\r\ne->hv_sint.sint = ue->u.hv_sint.sint;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nbool kvm_intr_is_single_vcpu(struct kvm *kvm, struct kvm_lapic_irq *irq,\r\nstruct kvm_vcpu **dest_vcpu)\r\n{\r\nint i, r = 0;\r\nstruct kvm_vcpu *vcpu;\r\nif (kvm_intr_is_single_vcpu_fast(kvm, irq, dest_vcpu))\r\nreturn true;\r\nkvm_for_each_vcpu(i, vcpu, kvm) {\r\nif (!kvm_apic_present(vcpu))\r\ncontinue;\r\nif (!kvm_apic_match_dest(vcpu, NULL, irq->shorthand,\r\nirq->dest_id, irq->dest_mode))\r\ncontinue;\r\nif (++r == 2)\r\nreturn false;\r\n*dest_vcpu = vcpu;\r\n}\r\nreturn r == 1;\r\n}\r\nint kvm_setup_default_irq_routing(struct kvm *kvm)\r\n{\r\nreturn kvm_set_irq_routing(kvm, default_routing,\r\nARRAY_SIZE(default_routing), 0);\r\n}\r\nint kvm_setup_empty_irq_routing(struct kvm *kvm)\r\n{\r\nreturn kvm_set_irq_routing(kvm, empty_routing, 0, 0);\r\n}\r\nvoid kvm_arch_post_irq_routing_update(struct kvm *kvm)\r\n{\r\nif (!irqchip_split(kvm))\r\nreturn;\r\nkvm_make_scan_ioapic_request(kvm);\r\n}\r\nvoid kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,\r\nulong *ioapic_handled_vectors)\r\n{\r\nstruct kvm *kvm = vcpu->kvm;\r\nstruct kvm_kernel_irq_routing_entry *entry;\r\nstruct kvm_irq_routing_table *table;\r\nu32 i, nr_ioapic_pins;\r\nint idx;\r\nidx = srcu_read_lock(&kvm->irq_srcu);\r\ntable = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);\r\nnr_ioapic_pins = min_t(u32, table->nr_rt_entries,\r\nkvm->arch.nr_reserved_ioapic_pins);\r\nfor (i = 0; i < nr_ioapic_pins; ++i) {\r\nhlist_for_each_entry(entry, &table->map[i], link) {\r\nstruct kvm_lapic_irq irq;\r\nif (entry->type != KVM_IRQ_ROUTING_MSI)\r\ncontinue;\r\nkvm_set_msi_irq(vcpu->kvm, entry, &irq);\r\nif (irq.level && kvm_apic_match_dest(vcpu, NULL, 0,\r\nirq.dest_id, irq.dest_mode))\r\n__set_bit(irq.vector, ioapic_handled_vectors);\r\n}\r\n}\r\nsrcu_read_unlock(&kvm->irq_srcu, idx);\r\n}\r\nvoid kvm_arch_irq_routing_update(struct kvm *kvm)\r\n{\r\nkvm_hv_irq_routing_update(kvm);\r\n}
