static int iser_prepare_read_cmd(struct iscsi_task *task)\r\n{\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_mem_reg *mem_reg;\r\nint err;\r\nstruct iser_ctrl *hdr = &iser_task->desc.iser_header;\r\nstruct iser_data_buf *buf_in = &iser_task->data[ISER_DIR_IN];\r\nerr = iser_dma_map_task_data(iser_task,\r\nbuf_in,\r\nISER_DIR_IN,\r\nDMA_FROM_DEVICE);\r\nif (err)\r\nreturn err;\r\nif (scsi_prot_sg_count(iser_task->sc)) {\r\nstruct iser_data_buf *pbuf_in = &iser_task->prot[ISER_DIR_IN];\r\nerr = iser_dma_map_task_data(iser_task,\r\npbuf_in,\r\nISER_DIR_IN,\r\nDMA_FROM_DEVICE);\r\nif (err)\r\nreturn err;\r\n}\r\nerr = iser_reg_rdma_mem(iser_task, ISER_DIR_IN, false);\r\nif (err) {\r\niser_err("Failed to set up Data-IN RDMA\n");\r\nreturn err;\r\n}\r\nmem_reg = &iser_task->rdma_reg[ISER_DIR_IN];\r\nhdr->flags |= ISER_RSV;\r\nhdr->read_stag = cpu_to_be32(mem_reg->rkey);\r\nhdr->read_va = cpu_to_be64(mem_reg->sge.addr);\r\niser_dbg("Cmd itt:%d READ tags RKEY:%#.4X VA:%#llX\n",\r\ntask->itt, mem_reg->rkey,\r\n(unsigned long long)mem_reg->sge.addr);\r\nreturn 0;\r\n}\r\nstatic int\r\niser_prepare_write_cmd(struct iscsi_task *task,\r\nunsigned int imm_sz,\r\nunsigned int unsol_sz,\r\nunsigned int edtl)\r\n{\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_mem_reg *mem_reg;\r\nint err;\r\nstruct iser_ctrl *hdr = &iser_task->desc.iser_header;\r\nstruct iser_data_buf *buf_out = &iser_task->data[ISER_DIR_OUT];\r\nstruct ib_sge *tx_dsg = &iser_task->desc.tx_sg[1];\r\nerr = iser_dma_map_task_data(iser_task,\r\nbuf_out,\r\nISER_DIR_OUT,\r\nDMA_TO_DEVICE);\r\nif (err)\r\nreturn err;\r\nif (scsi_prot_sg_count(iser_task->sc)) {\r\nstruct iser_data_buf *pbuf_out = &iser_task->prot[ISER_DIR_OUT];\r\nerr = iser_dma_map_task_data(iser_task,\r\npbuf_out,\r\nISER_DIR_OUT,\r\nDMA_TO_DEVICE);\r\nif (err)\r\nreturn err;\r\n}\r\nerr = iser_reg_rdma_mem(iser_task, ISER_DIR_OUT,\r\nbuf_out->data_len == imm_sz);\r\nif (err != 0) {\r\niser_err("Failed to register write cmd RDMA mem\n");\r\nreturn err;\r\n}\r\nmem_reg = &iser_task->rdma_reg[ISER_DIR_OUT];\r\nif (unsol_sz < edtl) {\r\nhdr->flags |= ISER_WSV;\r\nif (buf_out->data_len > imm_sz) {\r\nhdr->write_stag = cpu_to_be32(mem_reg->rkey);\r\nhdr->write_va = cpu_to_be64(mem_reg->sge.addr + unsol_sz);\r\n}\r\niser_dbg("Cmd itt:%d, WRITE tags, RKEY:%#.4X "\r\n"VA:%#llX + unsol:%d\n",\r\ntask->itt, mem_reg->rkey,\r\n(unsigned long long)mem_reg->sge.addr, unsol_sz);\r\n}\r\nif (imm_sz > 0) {\r\niser_dbg("Cmd itt:%d, WRITE, adding imm.data sz: %d\n",\r\ntask->itt, imm_sz);\r\ntx_dsg->addr = mem_reg->sge.addr;\r\ntx_dsg->length = imm_sz;\r\ntx_dsg->lkey = mem_reg->sge.lkey;\r\niser_task->desc.num_sge = 2;\r\n}\r\nreturn 0;\r\n}\r\nstatic void iser_create_send_desc(struct iser_conn *iser_conn,\r\nstruct iser_tx_desc *tx_desc)\r\n{\r\nstruct iser_device *device = iser_conn->ib_conn.device;\r\nib_dma_sync_single_for_cpu(device->ib_device,\r\ntx_desc->dma_addr, ISER_HEADERS_LEN, DMA_TO_DEVICE);\r\nmemset(&tx_desc->iser_header, 0, sizeof(struct iser_ctrl));\r\ntx_desc->iser_header.flags = ISER_VER;\r\ntx_desc->num_sge = 1;\r\n}\r\nstatic void iser_free_login_buf(struct iser_conn *iser_conn)\r\n{\r\nstruct iser_device *device = iser_conn->ib_conn.device;\r\nstruct iser_login_desc *desc = &iser_conn->login_desc;\r\nif (!desc->req)\r\nreturn;\r\nib_dma_unmap_single(device->ib_device, desc->req_dma,\r\nISCSI_DEF_MAX_RECV_SEG_LEN, DMA_TO_DEVICE);\r\nib_dma_unmap_single(device->ib_device, desc->rsp_dma,\r\nISER_RX_LOGIN_SIZE, DMA_FROM_DEVICE);\r\nkfree(desc->req);\r\nkfree(desc->rsp);\r\ndesc->req = NULL;\r\ndesc->rsp = NULL;\r\n}\r\nstatic int iser_alloc_login_buf(struct iser_conn *iser_conn)\r\n{\r\nstruct iser_device *device = iser_conn->ib_conn.device;\r\nstruct iser_login_desc *desc = &iser_conn->login_desc;\r\ndesc->req = kmalloc(ISCSI_DEF_MAX_RECV_SEG_LEN, GFP_KERNEL);\r\nif (!desc->req)\r\nreturn -ENOMEM;\r\ndesc->req_dma = ib_dma_map_single(device->ib_device, desc->req,\r\nISCSI_DEF_MAX_RECV_SEG_LEN,\r\nDMA_TO_DEVICE);\r\nif (ib_dma_mapping_error(device->ib_device,\r\ndesc->req_dma))\r\ngoto free_req;\r\ndesc->rsp = kmalloc(ISER_RX_LOGIN_SIZE, GFP_KERNEL);\r\nif (!desc->rsp)\r\ngoto unmap_req;\r\ndesc->rsp_dma = ib_dma_map_single(device->ib_device, desc->rsp,\r\nISER_RX_LOGIN_SIZE,\r\nDMA_FROM_DEVICE);\r\nif (ib_dma_mapping_error(device->ib_device,\r\ndesc->rsp_dma))\r\ngoto free_rsp;\r\nreturn 0;\r\nfree_rsp:\r\nkfree(desc->rsp);\r\nunmap_req:\r\nib_dma_unmap_single(device->ib_device, desc->req_dma,\r\nISCSI_DEF_MAX_RECV_SEG_LEN,\r\nDMA_TO_DEVICE);\r\nfree_req:\r\nkfree(desc->req);\r\nreturn -ENOMEM;\r\n}\r\nint iser_alloc_rx_descriptors(struct iser_conn *iser_conn,\r\nstruct iscsi_session *session)\r\n{\r\nint i, j;\r\nu64 dma_addr;\r\nstruct iser_rx_desc *rx_desc;\r\nstruct ib_sge *rx_sg;\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nstruct iser_device *device = ib_conn->device;\r\niser_conn->qp_max_recv_dtos = session->cmds_max;\r\niser_conn->qp_max_recv_dtos_mask = session->cmds_max - 1;\r\niser_conn->min_posted_rx = iser_conn->qp_max_recv_dtos >> 2;\r\nif (device->reg_ops->alloc_reg_res(ib_conn, session->scsi_cmds_max,\r\niser_conn->scsi_sg_tablesize))\r\ngoto create_rdma_reg_res_failed;\r\nif (iser_alloc_login_buf(iser_conn))\r\ngoto alloc_login_buf_fail;\r\niser_conn->num_rx_descs = session->cmds_max;\r\niser_conn->rx_descs = kmalloc(iser_conn->num_rx_descs *\r\nsizeof(struct iser_rx_desc), GFP_KERNEL);\r\nif (!iser_conn->rx_descs)\r\ngoto rx_desc_alloc_fail;\r\nrx_desc = iser_conn->rx_descs;\r\nfor (i = 0; i < iser_conn->qp_max_recv_dtos; i++, rx_desc++) {\r\ndma_addr = ib_dma_map_single(device->ib_device, (void *)rx_desc,\r\nISER_RX_PAYLOAD_SIZE, DMA_FROM_DEVICE);\r\nif (ib_dma_mapping_error(device->ib_device, dma_addr))\r\ngoto rx_desc_dma_map_failed;\r\nrx_desc->dma_addr = dma_addr;\r\nrx_desc->cqe.done = iser_task_rsp;\r\nrx_sg = &rx_desc->rx_sg;\r\nrx_sg->addr = rx_desc->dma_addr;\r\nrx_sg->length = ISER_RX_PAYLOAD_SIZE;\r\nrx_sg->lkey = device->pd->local_dma_lkey;\r\n}\r\niser_conn->rx_desc_head = 0;\r\nreturn 0;\r\nrx_desc_dma_map_failed:\r\nrx_desc = iser_conn->rx_descs;\r\nfor (j = 0; j < i; j++, rx_desc++)\r\nib_dma_unmap_single(device->ib_device, rx_desc->dma_addr,\r\nISER_RX_PAYLOAD_SIZE, DMA_FROM_DEVICE);\r\nkfree(iser_conn->rx_descs);\r\niser_conn->rx_descs = NULL;\r\nrx_desc_alloc_fail:\r\niser_free_login_buf(iser_conn);\r\nalloc_login_buf_fail:\r\ndevice->reg_ops->free_reg_res(ib_conn);\r\ncreate_rdma_reg_res_failed:\r\niser_err("failed allocating rx descriptors / data buffers\n");\r\nreturn -ENOMEM;\r\n}\r\nvoid iser_free_rx_descriptors(struct iser_conn *iser_conn)\r\n{\r\nint i;\r\nstruct iser_rx_desc *rx_desc;\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nstruct iser_device *device = ib_conn->device;\r\nif (device->reg_ops->free_reg_res)\r\ndevice->reg_ops->free_reg_res(ib_conn);\r\nrx_desc = iser_conn->rx_descs;\r\nfor (i = 0; i < iser_conn->qp_max_recv_dtos; i++, rx_desc++)\r\nib_dma_unmap_single(device->ib_device, rx_desc->dma_addr,\r\nISER_RX_PAYLOAD_SIZE, DMA_FROM_DEVICE);\r\nkfree(iser_conn->rx_descs);\r\niser_conn->rx_descs = NULL;\r\niser_free_login_buf(iser_conn);\r\n}\r\nstatic int iser_post_rx_bufs(struct iscsi_conn *conn, struct iscsi_hdr *req)\r\n{\r\nstruct iser_conn *iser_conn = conn->dd_data;\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nstruct iscsi_session *session = conn->session;\r\niser_dbg("req op %x flags %x\n", req->opcode, req->flags);\r\nif ((req->flags & ISCSI_FULL_FEATURE_PHASE) != ISCSI_FULL_FEATURE_PHASE)\r\nreturn 0;\r\nWARN_ON(ib_conn->post_recv_buf_count != 1);\r\nif (session->discovery_sess) {\r\niser_info("Discovery session, re-using login RX buffer\n");\r\nreturn 0;\r\n} else\r\niser_info("Normal session, posting batch of RX %d buffers\n",\r\niser_conn->min_posted_rx);\r\nif (iser_post_recvm(iser_conn, iser_conn->min_posted_rx))\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic inline bool iser_signal_comp(u8 sig_count)\r\n{\r\nreturn ((sig_count % ISER_SIGNAL_CMD_COUNT) == 0);\r\n}\r\nint iser_send_command(struct iscsi_conn *conn,\r\nstruct iscsi_task *task)\r\n{\r\nstruct iser_conn *iser_conn = conn->dd_data;\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nunsigned long edtl;\r\nint err;\r\nstruct iser_data_buf *data_buf, *prot_buf;\r\nstruct iscsi_scsi_req *hdr = (struct iscsi_scsi_req *)task->hdr;\r\nstruct scsi_cmnd *sc = task->sc;\r\nstruct iser_tx_desc *tx_desc = &iser_task->desc;\r\nu8 sig_count = ++iser_conn->ib_conn.sig_count;\r\nedtl = ntohl(hdr->data_length);\r\ntx_desc->type = ISCSI_TX_SCSI_COMMAND;\r\ntx_desc->cqe.done = iser_cmd_comp;\r\niser_create_send_desc(iser_conn, tx_desc);\r\nif (hdr->flags & ISCSI_FLAG_CMD_READ) {\r\ndata_buf = &iser_task->data[ISER_DIR_IN];\r\nprot_buf = &iser_task->prot[ISER_DIR_IN];\r\n} else {\r\ndata_buf = &iser_task->data[ISER_DIR_OUT];\r\nprot_buf = &iser_task->prot[ISER_DIR_OUT];\r\n}\r\nif (scsi_sg_count(sc)) {\r\ndata_buf->sg = scsi_sglist(sc);\r\ndata_buf->size = scsi_sg_count(sc);\r\n}\r\ndata_buf->data_len = scsi_bufflen(sc);\r\nif (scsi_prot_sg_count(sc)) {\r\nprot_buf->sg = scsi_prot_sglist(sc);\r\nprot_buf->size = scsi_prot_sg_count(sc);\r\nprot_buf->data_len = (data_buf->data_len >>\r\nilog2(sc->device->sector_size)) * 8;\r\n}\r\nif (hdr->flags & ISCSI_FLAG_CMD_READ) {\r\nerr = iser_prepare_read_cmd(task);\r\nif (err)\r\ngoto send_command_error;\r\n}\r\nif (hdr->flags & ISCSI_FLAG_CMD_WRITE) {\r\nerr = iser_prepare_write_cmd(task,\r\ntask->imm_count,\r\ntask->imm_count +\r\ntask->unsol_r2t.data_length,\r\nedtl);\r\nif (err)\r\ngoto send_command_error;\r\n}\r\niser_task->status = ISER_TASK_STATUS_STARTED;\r\nerr = iser_post_send(&iser_conn->ib_conn, tx_desc,\r\niser_signal_comp(sig_count));\r\nif (!err)\r\nreturn 0;\r\nsend_command_error:\r\niser_err("conn %p failed task->itt %d err %d\n",conn, task->itt, err);\r\nreturn err;\r\n}\r\nint iser_send_data_out(struct iscsi_conn *conn,\r\nstruct iscsi_task *task,\r\nstruct iscsi_data *hdr)\r\n{\r\nstruct iser_conn *iser_conn = conn->dd_data;\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_tx_desc *tx_desc = NULL;\r\nstruct iser_mem_reg *mem_reg;\r\nunsigned long buf_offset;\r\nunsigned long data_seg_len;\r\nuint32_t itt;\r\nint err;\r\nstruct ib_sge *tx_dsg;\r\nitt = (__force uint32_t)hdr->itt;\r\ndata_seg_len = ntoh24(hdr->dlength);\r\nbuf_offset = ntohl(hdr->offset);\r\niser_dbg("%s itt %d dseg_len %d offset %d\n",\r\n__func__,(int)itt,(int)data_seg_len,(int)buf_offset);\r\ntx_desc = kmem_cache_zalloc(ig.desc_cache, GFP_ATOMIC);\r\nif (tx_desc == NULL) {\r\niser_err("Failed to alloc desc for post dataout\n");\r\nreturn -ENOMEM;\r\n}\r\ntx_desc->type = ISCSI_TX_DATAOUT;\r\ntx_desc->cqe.done = iser_dataout_comp;\r\ntx_desc->iser_header.flags = ISER_VER;\r\nmemcpy(&tx_desc->iscsi_header, hdr, sizeof(struct iscsi_hdr));\r\nerr = iser_initialize_task_headers(task, tx_desc);\r\nif (err)\r\ngoto send_data_out_error;\r\nmem_reg = &iser_task->rdma_reg[ISER_DIR_OUT];\r\ntx_dsg = &tx_desc->tx_sg[1];\r\ntx_dsg->addr = mem_reg->sge.addr + buf_offset;\r\ntx_dsg->length = data_seg_len;\r\ntx_dsg->lkey = mem_reg->sge.lkey;\r\ntx_desc->num_sge = 2;\r\nif (buf_offset + data_seg_len > iser_task->data[ISER_DIR_OUT].data_len) {\r\niser_err("Offset:%ld & DSL:%ld in Data-Out "\r\n"inconsistent with total len:%ld, itt:%d\n",\r\nbuf_offset, data_seg_len,\r\niser_task->data[ISER_DIR_OUT].data_len, itt);\r\nerr = -EINVAL;\r\ngoto send_data_out_error;\r\n}\r\niser_dbg("data-out itt: %d, offset: %ld, sz: %ld\n",\r\nitt, buf_offset, data_seg_len);\r\nerr = iser_post_send(&iser_conn->ib_conn, tx_desc, true);\r\nif (!err)\r\nreturn 0;\r\nsend_data_out_error:\r\nkmem_cache_free(ig.desc_cache, tx_desc);\r\niser_err("conn %p failed err %d\n", conn, err);\r\nreturn err;\r\n}\r\nint iser_send_control(struct iscsi_conn *conn,\r\nstruct iscsi_task *task)\r\n{\r\nstruct iser_conn *iser_conn = conn->dd_data;\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_tx_desc *mdesc = &iser_task->desc;\r\nunsigned long data_seg_len;\r\nint err = 0;\r\nstruct iser_device *device;\r\nmdesc->type = ISCSI_TX_CONTROL;\r\nmdesc->cqe.done = iser_ctrl_comp;\r\niser_create_send_desc(iser_conn, mdesc);\r\ndevice = iser_conn->ib_conn.device;\r\ndata_seg_len = ntoh24(task->hdr->dlength);\r\nif (data_seg_len > 0) {\r\nstruct iser_login_desc *desc = &iser_conn->login_desc;\r\nstruct ib_sge *tx_dsg = &mdesc->tx_sg[1];\r\nif (task != conn->login_task) {\r\niser_err("data present on non login task!!!\n");\r\ngoto send_control_error;\r\n}\r\nib_dma_sync_single_for_cpu(device->ib_device, desc->req_dma,\r\ntask->data_count, DMA_TO_DEVICE);\r\nmemcpy(desc->req, task->data, task->data_count);\r\nib_dma_sync_single_for_device(device->ib_device, desc->req_dma,\r\ntask->data_count, DMA_TO_DEVICE);\r\ntx_dsg->addr = desc->req_dma;\r\ntx_dsg->length = task->data_count;\r\ntx_dsg->lkey = device->pd->local_dma_lkey;\r\nmdesc->num_sge = 2;\r\n}\r\nif (task == conn->login_task) {\r\niser_dbg("op %x dsl %lx, posting login rx buffer\n",\r\ntask->hdr->opcode, data_seg_len);\r\nerr = iser_post_recvl(iser_conn);\r\nif (err)\r\ngoto send_control_error;\r\nerr = iser_post_rx_bufs(conn, task->hdr);\r\nif (err)\r\ngoto send_control_error;\r\n}\r\nerr = iser_post_send(&iser_conn->ib_conn, mdesc, true);\r\nif (!err)\r\nreturn 0;\r\nsend_control_error:\r\niser_err("conn %p failed err %d\n",conn, err);\r\nreturn err;\r\n}\r\nvoid iser_login_rsp(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\nstruct ib_conn *ib_conn = wc->qp->qp_context;\r\nstruct iser_conn *iser_conn = to_iser_conn(ib_conn);\r\nstruct iser_login_desc *desc = iser_login(wc->wr_cqe);\r\nstruct iscsi_hdr *hdr;\r\nchar *data;\r\nint length;\r\nif (unlikely(wc->status != IB_WC_SUCCESS)) {\r\niser_err_comp(wc, "login_rsp");\r\nreturn;\r\n}\r\nib_dma_sync_single_for_cpu(ib_conn->device->ib_device,\r\ndesc->rsp_dma, ISER_RX_LOGIN_SIZE,\r\nDMA_FROM_DEVICE);\r\nhdr = desc->rsp + sizeof(struct iser_ctrl);\r\ndata = desc->rsp + ISER_HEADERS_LEN;\r\nlength = wc->byte_len - ISER_HEADERS_LEN;\r\niser_dbg("op 0x%x itt 0x%x dlen %d\n", hdr->opcode,\r\nhdr->itt, length);\r\niscsi_iser_recv(iser_conn->iscsi_conn, hdr, data, length);\r\nib_dma_sync_single_for_device(ib_conn->device->ib_device,\r\ndesc->rsp_dma, ISER_RX_LOGIN_SIZE,\r\nDMA_FROM_DEVICE);\r\nib_conn->post_recv_buf_count--;\r\n}\r\nstatic inline void\r\niser_inv_desc(struct iser_fr_desc *desc, u32 rkey)\r\n{\r\nif (likely(rkey == desc->rsc.mr->rkey))\r\ndesc->rsc.mr_valid = 0;\r\nelse if (likely(rkey == desc->pi_ctx->sig_mr->rkey))\r\ndesc->pi_ctx->sig_mr_valid = 0;\r\n}\r\nstatic int\r\niser_check_remote_inv(struct iser_conn *iser_conn,\r\nstruct ib_wc *wc,\r\nstruct iscsi_hdr *hdr)\r\n{\r\nif (wc->wc_flags & IB_WC_WITH_INVALIDATE) {\r\nstruct iscsi_task *task;\r\nu32 rkey = wc->ex.invalidate_rkey;\r\niser_dbg("conn %p: remote invalidation for rkey %#x\n",\r\niser_conn, rkey);\r\nif (unlikely(!iser_conn->snd_w_inv)) {\r\niser_err("conn %p: unexpected remote invalidation, "\r\n"terminating connection\n", iser_conn);\r\nreturn -EPROTO;\r\n}\r\ntask = iscsi_itt_to_ctask(iser_conn->iscsi_conn, hdr->itt);\r\nif (likely(task)) {\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_fr_desc *desc;\r\nif (iser_task->dir[ISER_DIR_IN]) {\r\ndesc = iser_task->rdma_reg[ISER_DIR_IN].mem_h;\r\niser_inv_desc(desc, rkey);\r\n}\r\nif (iser_task->dir[ISER_DIR_OUT]) {\r\ndesc = iser_task->rdma_reg[ISER_DIR_OUT].mem_h;\r\niser_inv_desc(desc, rkey);\r\n}\r\n} else {\r\niser_err("failed to get task for itt=%d\n", hdr->itt);\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid iser_task_rsp(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\nstruct ib_conn *ib_conn = wc->qp->qp_context;\r\nstruct iser_conn *iser_conn = to_iser_conn(ib_conn);\r\nstruct iser_rx_desc *desc = iser_rx(wc->wr_cqe);\r\nstruct iscsi_hdr *hdr;\r\nint length;\r\nint outstanding, count, err;\r\nif (unlikely(wc->status != IB_WC_SUCCESS)) {\r\niser_err_comp(wc, "task_rsp");\r\nreturn;\r\n}\r\nib_dma_sync_single_for_cpu(ib_conn->device->ib_device,\r\ndesc->dma_addr, ISER_RX_PAYLOAD_SIZE,\r\nDMA_FROM_DEVICE);\r\nhdr = &desc->iscsi_header;\r\nlength = wc->byte_len - ISER_HEADERS_LEN;\r\niser_dbg("op 0x%x itt 0x%x dlen %d\n", hdr->opcode,\r\nhdr->itt, length);\r\nif (iser_check_remote_inv(iser_conn, wc, hdr)) {\r\niscsi_conn_failure(iser_conn->iscsi_conn,\r\nISCSI_ERR_CONN_FAILED);\r\nreturn;\r\n}\r\niscsi_iser_recv(iser_conn->iscsi_conn, hdr, desc->data, length);\r\nib_dma_sync_single_for_device(ib_conn->device->ib_device,\r\ndesc->dma_addr, ISER_RX_PAYLOAD_SIZE,\r\nDMA_FROM_DEVICE);\r\nib_conn->post_recv_buf_count--;\r\noutstanding = ib_conn->post_recv_buf_count;\r\nif (outstanding + iser_conn->min_posted_rx <= iser_conn->qp_max_recv_dtos) {\r\ncount = min(iser_conn->qp_max_recv_dtos - outstanding,\r\niser_conn->min_posted_rx);\r\nerr = iser_post_recvm(iser_conn, count);\r\nif (err)\r\niser_err("posting %d rx bufs err %d\n", count, err);\r\n}\r\n}\r\nvoid iser_cmd_comp(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\nif (unlikely(wc->status != IB_WC_SUCCESS))\r\niser_err_comp(wc, "command");\r\n}\r\nvoid iser_ctrl_comp(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\nstruct iser_tx_desc *desc = iser_tx(wc->wr_cqe);\r\nstruct iscsi_task *task;\r\nif (unlikely(wc->status != IB_WC_SUCCESS)) {\r\niser_err_comp(wc, "control");\r\nreturn;\r\n}\r\ntask = (void *)desc - sizeof(struct iscsi_task);\r\nif (task->hdr->itt == RESERVED_ITT)\r\niscsi_put_task(task);\r\n}\r\nvoid iser_dataout_comp(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\nstruct iser_tx_desc *desc = iser_tx(wc->wr_cqe);\r\nstruct ib_conn *ib_conn = wc->qp->qp_context;\r\nstruct iser_device *device = ib_conn->device;\r\nif (unlikely(wc->status != IB_WC_SUCCESS))\r\niser_err_comp(wc, "dataout");\r\nib_dma_unmap_single(device->ib_device, desc->dma_addr,\r\nISER_HEADERS_LEN, DMA_TO_DEVICE);\r\nkmem_cache_free(ig.desc_cache, desc);\r\n}\r\nvoid iser_task_rdma_init(struct iscsi_iser_task *iser_task)\r\n{\r\niser_task->status = ISER_TASK_STATUS_INIT;\r\niser_task->dir[ISER_DIR_IN] = 0;\r\niser_task->dir[ISER_DIR_OUT] = 0;\r\niser_task->data[ISER_DIR_IN].data_len = 0;\r\niser_task->data[ISER_DIR_OUT].data_len = 0;\r\niser_task->prot[ISER_DIR_IN].data_len = 0;\r\niser_task->prot[ISER_DIR_OUT].data_len = 0;\r\nmemset(&iser_task->rdma_reg[ISER_DIR_IN], 0,\r\nsizeof(struct iser_mem_reg));\r\nmemset(&iser_task->rdma_reg[ISER_DIR_OUT], 0,\r\nsizeof(struct iser_mem_reg));\r\n}\r\nvoid iser_task_rdma_finalize(struct iscsi_iser_task *iser_task)\r\n{\r\nint prot_count = scsi_prot_sg_count(iser_task->sc);\r\nif (iser_task->dir[ISER_DIR_IN]) {\r\niser_unreg_rdma_mem(iser_task, ISER_DIR_IN);\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->data[ISER_DIR_IN],\r\nDMA_FROM_DEVICE);\r\nif (prot_count)\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->prot[ISER_DIR_IN],\r\nDMA_FROM_DEVICE);\r\n}\r\nif (iser_task->dir[ISER_DIR_OUT]) {\r\niser_unreg_rdma_mem(iser_task, ISER_DIR_OUT);\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->data[ISER_DIR_OUT],\r\nDMA_TO_DEVICE);\r\nif (prot_count)\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->prot[ISER_DIR_OUT],\r\nDMA_TO_DEVICE);\r\n}\r\n}
