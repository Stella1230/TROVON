void __init add_memory_region(phys_addr_t start, phys_addr_t size, long type)\r\n{\r\nint x = boot_mem_map.nr_map;\r\nint i;\r\nif (start + size - 1 == (phys_addr_t)ULLONG_MAX)\r\n--size;\r\nif (start + size < start) {\r\npr_warn("Trying to add an invalid memory region, skipped\n");\r\nreturn;\r\n}\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nstruct boot_mem_map_entry *entry = boot_mem_map.map + i;\r\nunsigned long top;\r\nif (entry->type != type)\r\ncontinue;\r\nif (start + size < entry->addr)\r\ncontinue;\r\nif (entry->addr + entry->size < start)\r\ncontinue;\r\ntop = max(entry->addr + entry->size, start + size);\r\nentry->addr = min(entry->addr, start);\r\nentry->size = top - entry->addr;\r\nreturn;\r\n}\r\nif (boot_mem_map.nr_map == BOOT_MEM_MAP_MAX) {\r\npr_err("Ooops! Too many entries in the memory map!\n");\r\nreturn;\r\n}\r\nboot_mem_map.map[x].addr = start;\r\nboot_mem_map.map[x].size = size;\r\nboot_mem_map.map[x].type = type;\r\nboot_mem_map.nr_map++;\r\n}\r\nvoid __init detect_memory_region(phys_addr_t start, phys_addr_t sz_min, phys_addr_t sz_max)\r\n{\r\nvoid *dm = &detect_magic;\r\nphys_addr_t size;\r\nfor (size = sz_min; size < sz_max; size <<= 1) {\r\nif (!memcmp(dm, dm + size, sizeof(detect_magic)))\r\nbreak;\r\n}\r\npr_debug("Memory: %lluMB of RAM detected at 0x%llx (min: %lluMB, max: %lluMB)\n",\r\n((unsigned long long) size) / SZ_1M,\r\n(unsigned long long) start,\r\n((unsigned long long) sz_min) / SZ_1M,\r\n((unsigned long long) sz_max) / SZ_1M);\r\nadd_memory_region(start, size, BOOT_MEM_RAM);\r\n}\r\nbool __init memory_region_available(phys_addr_t start, phys_addr_t size)\r\n{\r\nint i;\r\nbool in_ram = false, free = true;\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nphys_addr_t start_, end_;\r\nstart_ = boot_mem_map.map[i].addr;\r\nend_ = boot_mem_map.map[i].addr + boot_mem_map.map[i].size;\r\nswitch (boot_mem_map.map[i].type) {\r\ncase BOOT_MEM_RAM:\r\nif (start >= start_ && start + size <= end_)\r\nin_ram = true;\r\nbreak;\r\ncase BOOT_MEM_RESERVED:\r\nif ((start >= start_ && start < end_) ||\r\n(start < start_ && start + size >= start_))\r\nfree = false;\r\nbreak;\r\ndefault:\r\ncontinue;\r\n}\r\n}\r\nreturn in_ram && free;\r\n}\r\nstatic void __init print_memory_map(void)\r\n{\r\nint i;\r\nconst int field = 2 * sizeof(unsigned long);\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nprintk(KERN_INFO " memory: %0*Lx @ %0*Lx ",\r\nfield, (unsigned long long) boot_mem_map.map[i].size,\r\nfield, (unsigned long long) boot_mem_map.map[i].addr);\r\nswitch (boot_mem_map.map[i].type) {\r\ncase BOOT_MEM_RAM:\r\nprintk(KERN_CONT "(usable)\n");\r\nbreak;\r\ncase BOOT_MEM_INIT_RAM:\r\nprintk(KERN_CONT "(usable after init)\n");\r\nbreak;\r\ncase BOOT_MEM_ROM_DATA:\r\nprintk(KERN_CONT "(ROM data)\n");\r\nbreak;\r\ncase BOOT_MEM_RESERVED:\r\nprintk(KERN_CONT "(reserved)\n");\r\nbreak;\r\ndefault:\r\nprintk(KERN_CONT "type %lu\n", boot_mem_map.map[i].type);\r\nbreak;\r\n}\r\n}\r\n}\r\nstatic int __init rd_start_early(char *p)\r\n{\r\nunsigned long start = memparse(p, &p);\r\n#ifdef CONFIG_64BIT\r\nif (start < XKPHYS)\r\nstart = (int)start;\r\n#endif\r\ninitrd_start = start;\r\ninitrd_end += start;\r\nreturn 0;\r\n}\r\nstatic int __init rd_size_early(char *p)\r\n{\r\ninitrd_end += memparse(p, &p);\r\nreturn 0;\r\n}\r\nstatic unsigned long __init init_initrd(void)\r\n{\r\nunsigned long end;\r\nif (!initrd_start || initrd_end <= initrd_start)\r\ngoto disable;\r\nif (initrd_start & ~PAGE_MASK) {\r\npr_err("initrd start must be page aligned\n");\r\ngoto disable;\r\n}\r\nif (initrd_start < PAGE_OFFSET) {\r\npr_err("initrd start < PAGE_OFFSET\n");\r\ngoto disable;\r\n}\r\nend = __pa(initrd_end);\r\ninitrd_end = (unsigned long)__va(end);\r\ninitrd_start = (unsigned long)__va(__pa(initrd_start));\r\nROOT_DEV = Root_RAM0;\r\nreturn PFN_UP(end);\r\ndisable:\r\ninitrd_start = 0;\r\ninitrd_end = 0;\r\nreturn 0;\r\n}\r\nstatic void __init maybe_bswap_initrd(void)\r\n{\r\n#if defined(CONFIG_CPU_CAVIUM_OCTEON)\r\nu64 buf;\r\nif (!memcmp((void *)initrd_start, "070701", 6))\r\nreturn;\r\nif (decompress_method((unsigned char *)initrd_start, 8, NULL))\r\nreturn;\r\nbuf = swab64p((u64 *)initrd_start);\r\nif (!memcmp(&buf, "070701", 6) ||\r\ndecompress_method((unsigned char *)(&buf), 8, NULL)) {\r\nunsigned long i;\r\npr_info("Byteswapped initrd detected\n");\r\nfor (i = initrd_start; i < ALIGN(initrd_end, 8); i += 8)\r\nswab64s((u64 *)i);\r\n}\r\n#endif\r\n}\r\nstatic void __init finalize_initrd(void)\r\n{\r\nunsigned long size = initrd_end - initrd_start;\r\nif (size == 0) {\r\nprintk(KERN_INFO "Initrd not found or empty");\r\ngoto disable;\r\n}\r\nif (__pa(initrd_end) > PFN_PHYS(max_low_pfn)) {\r\nprintk(KERN_ERR "Initrd extends beyond end of memory");\r\ngoto disable;\r\n}\r\nmaybe_bswap_initrd();\r\nreserve_bootmem(__pa(initrd_start), size, BOOTMEM_DEFAULT);\r\ninitrd_below_start_ok = 1;\r\npr_info("Initial ramdisk at: 0x%lx (%lu bytes)\n",\r\ninitrd_start, size);\r\nreturn;\r\ndisable:\r\nprintk(KERN_CONT " - disabling initrd\n");\r\ninitrd_start = 0;\r\ninitrd_end = 0;\r\n}\r\nstatic unsigned long __init init_initrd(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic void __init bootmem_init(void)\r\n{\r\ninit_initrd();\r\nfinalize_initrd();\r\n}\r\nstatic unsigned long __init bootmap_bytes(unsigned long pages)\r\n{\r\nunsigned long bytes = DIV_ROUND_UP(pages, 8);\r\nreturn ALIGN(bytes, sizeof(long));\r\n}\r\nstatic void __init bootmem_init(void)\r\n{\r\nunsigned long reserved_end;\r\nunsigned long mapstart = ~0UL;\r\nunsigned long bootmap_size;\r\nbool bootmap_valid = false;\r\nint i;\r\ninit_initrd();\r\nreserved_end = (unsigned long) PFN_UP(__pa_symbol(&_end));\r\nmin_low_pfn = ~0UL;\r\nmax_low_pfn = 0;\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nunsigned long start, end;\r\nif (boot_mem_map.map[i].type != BOOT_MEM_RAM)\r\ncontinue;\r\nstart = PFN_UP(boot_mem_map.map[i].addr);\r\nend = PFN_DOWN(boot_mem_map.map[i].addr\r\n+ boot_mem_map.map[i].size);\r\n#ifndef CONFIG_HIGHMEM\r\nif (start >= PFN_DOWN(HIGHMEM_START))\r\ncontinue;\r\nif (end > PFN_DOWN(HIGHMEM_START))\r\nend = PFN_DOWN(HIGHMEM_START);\r\n#endif\r\nif (end > max_low_pfn)\r\nmax_low_pfn = end;\r\nif (start < min_low_pfn)\r\nmin_low_pfn = start;\r\nif (end <= reserved_end)\r\ncontinue;\r\n#ifdef CONFIG_BLK_DEV_INITRD\r\nif (initrd_end && end <= (unsigned long)PFN_UP(__pa(initrd_end)))\r\ncontinue;\r\n#endif\r\nif (start >= mapstart)\r\ncontinue;\r\nmapstart = max(reserved_end, start);\r\n}\r\nif (min_low_pfn >= max_low_pfn)\r\npanic("Incorrect memory mapping !!!");\r\nif (min_low_pfn > ARCH_PFN_OFFSET) {\r\npr_info("Wasting %lu bytes for tracking %lu unused pages\n",\r\n(min_low_pfn - ARCH_PFN_OFFSET) * sizeof(struct page),\r\nmin_low_pfn - ARCH_PFN_OFFSET);\r\n} else if (min_low_pfn < ARCH_PFN_OFFSET) {\r\npr_info("%lu free pages won't be used\n",\r\nARCH_PFN_OFFSET - min_low_pfn);\r\n}\r\nmin_low_pfn = ARCH_PFN_OFFSET;\r\nmax_pfn = max_low_pfn;\r\nif (max_low_pfn > PFN_DOWN(HIGHMEM_START)) {\r\n#ifdef CONFIG_HIGHMEM\r\nhighstart_pfn = PFN_DOWN(HIGHMEM_START);\r\nhighend_pfn = max_low_pfn;\r\n#endif\r\nmax_low_pfn = PFN_DOWN(HIGHMEM_START);\r\n}\r\n#ifdef CONFIG_BLK_DEV_INITRD\r\nif (initrd_end)\r\nmapstart = max(mapstart, (unsigned long)PFN_UP(__pa(initrd_end)));\r\n#endif\r\nbootmap_size = bootmap_bytes(max_low_pfn - min_low_pfn);\r\nbootmap_valid = memory_region_available(PFN_PHYS(mapstart),\r\nbootmap_size);\r\nfor (i = 0; i < boot_mem_map.nr_map && !bootmap_valid; i++) {\r\nunsigned long mapstart_addr;\r\nswitch (boot_mem_map.map[i].type) {\r\ncase BOOT_MEM_RESERVED:\r\nmapstart_addr = PFN_ALIGN(boot_mem_map.map[i].addr +\r\nboot_mem_map.map[i].size);\r\nif (PHYS_PFN(mapstart_addr) < mapstart)\r\nbreak;\r\nbootmap_valid = memory_region_available(mapstart_addr,\r\nbootmap_size);\r\nif (bootmap_valid)\r\nmapstart = PHYS_PFN(mapstart_addr);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nif (!bootmap_valid)\r\npanic("No memory area to place a bootmap bitmap");\r\nif (bootmap_size != init_bootmem_node(NODE_DATA(0), mapstart,\r\nmin_low_pfn, max_low_pfn))\r\npanic("Unexpected memory size required for bootmap");\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nunsigned long start, end;\r\nstart = PFN_UP(boot_mem_map.map[i].addr);\r\nend = PFN_DOWN(boot_mem_map.map[i].addr\r\n+ boot_mem_map.map[i].size);\r\nif (start <= min_low_pfn)\r\nstart = min_low_pfn;\r\nif (start >= end)\r\ncontinue;\r\n#ifndef CONFIG_HIGHMEM\r\nif (end > max_low_pfn)\r\nend = max_low_pfn;\r\nif (end <= start)\r\ncontinue;\r\n#endif\r\nmemblock_add_node(PFN_PHYS(start), PFN_PHYS(end - start), 0);\r\n}\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nunsigned long start, end, size;\r\nstart = PFN_UP(boot_mem_map.map[i].addr);\r\nend = PFN_DOWN(boot_mem_map.map[i].addr\r\n+ boot_mem_map.map[i].size);\r\nswitch (boot_mem_map.map[i].type) {\r\ncase BOOT_MEM_RAM:\r\nbreak;\r\ncase BOOT_MEM_INIT_RAM:\r\nmemory_present(0, start, end);\r\ncontinue;\r\ndefault:\r\nif (start > min_low_pfn && end < max_low_pfn)\r\nreserve_bootmem(boot_mem_map.map[i].addr,\r\nboot_mem_map.map[i].size,\r\nBOOTMEM_DEFAULT);\r\ncontinue;\r\n}\r\nif (start >= max_low_pfn)\r\ncontinue;\r\nif (start < reserved_end)\r\nstart = reserved_end;\r\nif (end > max_low_pfn)\r\nend = max_low_pfn;\r\nif (end <= start)\r\ncontinue;\r\nsize = end - start;\r\nfree_bootmem(PFN_PHYS(start), size << PAGE_SHIFT);\r\nmemory_present(0, start, end);\r\n}\r\nreserve_bootmem(PFN_PHYS(mapstart), bootmap_size, BOOTMEM_DEFAULT);\r\n#ifdef CONFIG_RELOCATABLE\r\nif (__pa_symbol(_text) > __pa_symbol(VMLINUX_LOAD_ADDRESS)) {\r\nunsigned long offset;\r\nextern void show_kernel_relocation(const char *level);\r\noffset = __pa_symbol(_text) - __pa_symbol(VMLINUX_LOAD_ADDRESS);\r\nfree_bootmem(__pa_symbol(VMLINUX_LOAD_ADDRESS), offset);\r\n#if defined(CONFIG_DEBUG_KERNEL) && defined(CONFIG_DEBUG_INFO)\r\nshow_kernel_relocation(KERN_INFO);\r\n#endif\r\n}\r\n#endif\r\nfinalize_initrd();\r\n}\r\nstatic int __init early_parse_mem(char *p)\r\n{\r\nphys_addr_t start, size;\r\nif (usermem == 0) {\r\nboot_mem_map.nr_map = 0;\r\nusermem = 1;\r\n}\r\nstart = 0;\r\nsize = memparse(p, &p);\r\nif (*p == '@')\r\nstart = memparse(p + 1, &p);\r\nadd_memory_region(start, size, BOOT_MEM_RAM);\r\nif (start && start > PHYS_OFFSET)\r\nadd_memory_region(PHYS_OFFSET, start - PHYS_OFFSET,\r\nBOOT_MEM_RESERVED);\r\nreturn 0;\r\n}\r\nstatic int __init early_parse_memmap(char *p)\r\n{\r\nchar *oldp;\r\nu64 start_at, mem_size;\r\nif (!p)\r\nreturn -EINVAL;\r\nif (!strncmp(p, "exactmap", 8)) {\r\npr_err("\"memmap=exactmap\" invalid on MIPS\n");\r\nreturn 0;\r\n}\r\noldp = p;\r\nmem_size = memparse(p, &p);\r\nif (p == oldp)\r\nreturn -EINVAL;\r\nif (*p == '@') {\r\nstart_at = memparse(p+1, &p);\r\nadd_memory_region(start_at, mem_size, BOOT_MEM_RAM);\r\n} else if (*p == '#') {\r\npr_err("\"memmap=nn#ss\" (force ACPI data) invalid on MIPS\n");\r\nreturn -EINVAL;\r\n} else if (*p == '$') {\r\nstart_at = memparse(p+1, &p);\r\nadd_memory_region(start_at, mem_size, BOOT_MEM_RESERVED);\r\n} else {\r\npr_err("\"memmap\" invalid format!\n");\r\nreturn -EINVAL;\r\n}\r\nif (*p == '\0') {\r\nusermem = 1;\r\nreturn 0;\r\n} else\r\nreturn -EINVAL;\r\n}\r\nstatic int __init early_parse_elfcorehdr(char *p)\r\n{\r\nint i;\r\nsetup_elfcorehdr = memparse(p, &p);\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nunsigned long start = boot_mem_map.map[i].addr;\r\nunsigned long end = (boot_mem_map.map[i].addr +\r\nboot_mem_map.map[i].size);\r\nif (setup_elfcorehdr >= start && setup_elfcorehdr < end) {\r\nsetup_elfcorehdr_size = end - setup_elfcorehdr;\r\nbreak;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void __init arch_mem_addpart(phys_addr_t mem, phys_addr_t end, int type)\r\n{\r\nphys_addr_t size;\r\nint i;\r\nsize = end - mem;\r\nif (!size)\r\nreturn;\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nif (mem >= boot_mem_map.map[i].addr &&\r\nmem < (boot_mem_map.map[i].addr +\r\nboot_mem_map.map[i].size))\r\nreturn;\r\n}\r\nadd_memory_region(mem, size, type);\r\n}\r\nstatic inline unsigned long long get_total_mem(void)\r\n{\r\nunsigned long long total;\r\ntotal = max_pfn - min_low_pfn;\r\nreturn total << PAGE_SHIFT;\r\n}\r\nstatic void __init mips_parse_crashkernel(void)\r\n{\r\nunsigned long long total_mem;\r\nunsigned long long crash_size, crash_base;\r\nint ret;\r\ntotal_mem = get_total_mem();\r\nret = parse_crashkernel(boot_command_line, total_mem,\r\n&crash_size, &crash_base);\r\nif (ret != 0 || crash_size <= 0)\r\nreturn;\r\nif (!memory_region_available(crash_base, crash_size)) {\r\npr_warn("Invalid memory region reserved for crash kernel\n");\r\nreturn;\r\n}\r\ncrashk_res.start = crash_base;\r\ncrashk_res.end = crash_base + crash_size - 1;\r\n}\r\nstatic void __init request_crashkernel(struct resource *res)\r\n{\r\nint ret;\r\nif (crashk_res.start == crashk_res.end)\r\nreturn;\r\nret = request_resource(res, &crashk_res);\r\nif (!ret)\r\npr_info("Reserving %ldMB of memory at %ldMB for crashkernel\n",\r\n(unsigned long)((crashk_res.end -\r\ncrashk_res.start + 1) >> 20),\r\n(unsigned long)(crashk_res.start >> 20));\r\n}\r\nstatic void __init mips_parse_crashkernel(void)\r\n{\r\n}\r\nstatic void __init request_crashkernel(struct resource *res)\r\n{\r\n}\r\nstatic void __init arch_mem_init(char **cmdline_p)\r\n{\r\nstruct memblock_region *reg;\r\nextern void plat_mem_setup(void);\r\nplat_mem_setup();\r\narch_mem_addpart(PFN_DOWN(__pa_symbol(&_text)) << PAGE_SHIFT,\r\nPFN_UP(__pa_symbol(&_edata)) << PAGE_SHIFT,\r\nBOOT_MEM_RAM);\r\narch_mem_addpart(PFN_UP(__pa_symbol(&__init_begin)) << PAGE_SHIFT,\r\nPFN_DOWN(__pa_symbol(&__init_end)) << PAGE_SHIFT,\r\nBOOT_MEM_INIT_RAM);\r\npr_info("Determined physical RAM map:\n");\r\nprint_memory_map();\r\n#if defined(CONFIG_CMDLINE_BOOL) && defined(CONFIG_CMDLINE_OVERRIDE)\r\nstrlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);\r\n#else\r\nif ((USE_PROM_CMDLINE && arcs_cmdline[0]) ||\r\n(USE_DTB_CMDLINE && !boot_command_line[0]))\r\nstrlcpy(boot_command_line, arcs_cmdline, COMMAND_LINE_SIZE);\r\nif (EXTEND_WITH_PROM && arcs_cmdline[0]) {\r\nif (boot_command_line[0])\r\nstrlcat(boot_command_line, " ", COMMAND_LINE_SIZE);\r\nstrlcat(boot_command_line, arcs_cmdline, COMMAND_LINE_SIZE);\r\n}\r\n#if defined(CONFIG_CMDLINE_BOOL)\r\nif (builtin_cmdline[0]) {\r\nif (boot_command_line[0])\r\nstrlcat(boot_command_line, " ", COMMAND_LINE_SIZE);\r\nstrlcat(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);\r\n}\r\nif (BUILTIN_EXTEND_WITH_PROM && arcs_cmdline[0]) {\r\nif (boot_command_line[0])\r\nstrlcat(boot_command_line, " ", COMMAND_LINE_SIZE);\r\nstrlcat(boot_command_line, arcs_cmdline, COMMAND_LINE_SIZE);\r\n}\r\n#endif\r\n#endif\r\nstrlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);\r\n*cmdline_p = command_line;\r\nparse_early_param();\r\nif (usermem) {\r\npr_info("User-defined physical RAM map:\n");\r\nprint_memory_map();\r\n}\r\nearly_init_fdt_reserve_self();\r\nearly_init_fdt_scan_reserved_mem();\r\nbootmem_init();\r\n#ifdef CONFIG_PROC_VMCORE\r\nif (setup_elfcorehdr && setup_elfcorehdr_size) {\r\nprintk(KERN_INFO "kdump reserved memory at %lx-%lx\n",\r\nsetup_elfcorehdr, setup_elfcorehdr_size);\r\nreserve_bootmem(setup_elfcorehdr, setup_elfcorehdr_size,\r\nBOOTMEM_DEFAULT);\r\n}\r\n#endif\r\nmips_parse_crashkernel();\r\n#ifdef CONFIG_KEXEC\r\nif (crashk_res.start != crashk_res.end)\r\nreserve_bootmem(crashk_res.start,\r\ncrashk_res.end - crashk_res.start + 1,\r\nBOOTMEM_DEFAULT);\r\n#endif\r\ndevice_tree_init();\r\nsparse_init();\r\nplat_swiotlb_setup();\r\ndma_contiguous_reserve(PFN_PHYS(max_low_pfn));\r\nfor_each_memblock(reserved, reg)\r\nif (reg->size != 0)\r\nreserve_bootmem(reg->base, reg->size, BOOTMEM_DEFAULT);\r\nreserve_bootmem_region(__pa_symbol(&__nosave_begin),\r\n__pa_symbol(&__nosave_end));\r\n}\r\nstatic void __init resource_init(void)\r\n{\r\nint i;\r\nif (UNCAC_BASE != IO_BASE)\r\nreturn;\r\ncode_resource.start = __pa_symbol(&_text);\r\ncode_resource.end = __pa_symbol(&_etext) - 1;\r\ndata_resource.start = __pa_symbol(&_etext);\r\ndata_resource.end = __pa_symbol(&_edata) - 1;\r\nfor (i = 0; i < boot_mem_map.nr_map; i++) {\r\nstruct resource *res;\r\nunsigned long start, end;\r\nstart = boot_mem_map.map[i].addr;\r\nend = boot_mem_map.map[i].addr + boot_mem_map.map[i].size - 1;\r\nif (start >= HIGHMEM_START)\r\ncontinue;\r\nif (end >= HIGHMEM_START)\r\nend = HIGHMEM_START - 1;\r\nres = alloc_bootmem(sizeof(struct resource));\r\nres->start = start;\r\nres->end = end;\r\nres->flags = IORESOURCE_MEM | IORESOURCE_BUSY;\r\nswitch (boot_mem_map.map[i].type) {\r\ncase BOOT_MEM_RAM:\r\ncase BOOT_MEM_INIT_RAM:\r\ncase BOOT_MEM_ROM_DATA:\r\nres->name = "System RAM";\r\nres->flags |= IORESOURCE_SYSRAM;\r\nbreak;\r\ncase BOOT_MEM_RESERVED:\r\ndefault:\r\nres->name = "reserved";\r\n}\r\nrequest_resource(&iomem_resource, res);\r\nrequest_resource(res, &code_resource);\r\nrequest_resource(res, &data_resource);\r\nrequest_crashkernel(res);\r\n}\r\n}\r\nstatic void __init prefill_possible_map(void)\r\n{\r\nint i, possible = num_possible_cpus();\r\nif (possible > nr_cpu_ids)\r\npossible = nr_cpu_ids;\r\nfor (i = 0; i < possible; i++)\r\nset_cpu_possible(i, true);\r\nfor (; i < NR_CPUS; i++)\r\nset_cpu_possible(i, false);\r\nnr_cpu_ids = possible;\r\n}\r\nstatic inline void prefill_possible_map(void) {}\r\nvoid __init setup_arch(char **cmdline_p)\r\n{\r\ncpu_probe();\r\nmips_cm_probe();\r\nprom_init();\r\nsetup_early_fdc_console();\r\n#ifdef CONFIG_EARLY_PRINTK\r\nsetup_early_printk();\r\n#endif\r\ncpu_report();\r\ncheck_bugs_early();\r\n#if defined(CONFIG_VT)\r\n#if defined(CONFIG_VGA_CONSOLE)\r\nconswitchp = &vga_con;\r\n#elif defined(CONFIG_DUMMY_CONSOLE)\r\nconswitchp = &dummy_con;\r\n#endif\r\n#endif\r\narch_mem_init(cmdline_p);\r\nresource_init();\r\nplat_smp_setup();\r\nprefill_possible_map();\r\ncpu_cache_init();\r\npaging_init();\r\n}\r\nstatic int __init debugfs_mips(void)\r\n{\r\nstruct dentry *d;\r\nd = debugfs_create_dir("mips", NULL);\r\nif (!d)\r\nreturn -ENOMEM;\r\nmips_debugfs_dir = d;\r\nreturn 0;\r\n}
