void fsnotify_get_mark(struct fsnotify_mark *mark)\r\n{\r\nWARN_ON_ONCE(!atomic_read(&mark->refcnt));\r\natomic_inc(&mark->refcnt);\r\n}\r\nstatic bool fsnotify_get_mark_safe(struct fsnotify_mark *mark)\r\n{\r\nreturn atomic_inc_not_zero(&mark->refcnt);\r\n}\r\nstatic void __fsnotify_recalc_mask(struct fsnotify_mark_connector *conn)\r\n{\r\nu32 new_mask = 0;\r\nstruct fsnotify_mark *mark;\r\nassert_spin_locked(&conn->lock);\r\nhlist_for_each_entry(mark, &conn->list, obj_list) {\r\nif (mark->flags & FSNOTIFY_MARK_FLAG_ATTACHED)\r\nnew_mask |= mark->mask;\r\n}\r\nif (conn->flags & FSNOTIFY_OBJ_TYPE_INODE)\r\nconn->inode->i_fsnotify_mask = new_mask;\r\nelse if (conn->flags & FSNOTIFY_OBJ_TYPE_VFSMOUNT)\r\nreal_mount(conn->mnt)->mnt_fsnotify_mask = new_mask;\r\n}\r\nvoid fsnotify_recalc_mask(struct fsnotify_mark_connector *conn)\r\n{\r\nif (!conn)\r\nreturn;\r\nspin_lock(&conn->lock);\r\n__fsnotify_recalc_mask(conn);\r\nspin_unlock(&conn->lock);\r\nif (conn->flags & FSNOTIFY_OBJ_TYPE_INODE)\r\n__fsnotify_update_child_dentry_flags(conn->inode);\r\n}\r\nstatic void fsnotify_connector_destroy_workfn(struct work_struct *work)\r\n{\r\nstruct fsnotify_mark_connector *conn, *free;\r\nspin_lock(&destroy_lock);\r\nconn = connector_destroy_list;\r\nconnector_destroy_list = NULL;\r\nspin_unlock(&destroy_lock);\r\nsynchronize_srcu(&fsnotify_mark_srcu);\r\nwhile (conn) {\r\nfree = conn;\r\nconn = conn->destroy_next;\r\nkmem_cache_free(fsnotify_mark_connector_cachep, free);\r\n}\r\n}\r\nstatic struct inode *fsnotify_detach_connector_from_object(\r\nstruct fsnotify_mark_connector *conn)\r\n{\r\nstruct inode *inode = NULL;\r\nif (conn->flags & FSNOTIFY_OBJ_TYPE_INODE) {\r\ninode = conn->inode;\r\nrcu_assign_pointer(inode->i_fsnotify_marks, NULL);\r\ninode->i_fsnotify_mask = 0;\r\nconn->inode = NULL;\r\nconn->flags &= ~FSNOTIFY_OBJ_TYPE_INODE;\r\n} else if (conn->flags & FSNOTIFY_OBJ_TYPE_VFSMOUNT) {\r\nrcu_assign_pointer(real_mount(conn->mnt)->mnt_fsnotify_marks,\r\nNULL);\r\nreal_mount(conn->mnt)->mnt_fsnotify_mask = 0;\r\nconn->mnt = NULL;\r\nconn->flags &= ~FSNOTIFY_OBJ_TYPE_VFSMOUNT;\r\n}\r\nreturn inode;\r\n}\r\nstatic void fsnotify_final_mark_destroy(struct fsnotify_mark *mark)\r\n{\r\nstruct fsnotify_group *group = mark->group;\r\nif (WARN_ON_ONCE(!group))\r\nreturn;\r\ngroup->ops->free_mark(mark);\r\nfsnotify_put_group(group);\r\n}\r\nvoid fsnotify_put_mark(struct fsnotify_mark *mark)\r\n{\r\nstruct fsnotify_mark_connector *conn;\r\nstruct inode *inode = NULL;\r\nbool free_conn = false;\r\nif (!mark->connector) {\r\nif (atomic_dec_and_test(&mark->refcnt))\r\nfsnotify_final_mark_destroy(mark);\r\nreturn;\r\n}\r\nif (!atomic_dec_and_lock(&mark->refcnt, &mark->connector->lock))\r\nreturn;\r\nconn = mark->connector;\r\nhlist_del_init_rcu(&mark->obj_list);\r\nif (hlist_empty(&conn->list)) {\r\ninode = fsnotify_detach_connector_from_object(conn);\r\nfree_conn = true;\r\n} else {\r\n__fsnotify_recalc_mask(conn);\r\n}\r\nmark->connector = NULL;\r\nspin_unlock(&conn->lock);\r\niput(inode);\r\nif (free_conn) {\r\nspin_lock(&destroy_lock);\r\nconn->destroy_next = connector_destroy_list;\r\nconnector_destroy_list = conn;\r\nspin_unlock(&destroy_lock);\r\nqueue_work(system_unbound_wq, &connector_reaper_work);\r\n}\r\nspin_lock(&destroy_lock);\r\nlist_add(&mark->g_list, &destroy_list);\r\nspin_unlock(&destroy_lock);\r\nqueue_delayed_work(system_unbound_wq, &reaper_work,\r\nFSNOTIFY_REAPER_DELAY);\r\n}\r\nbool fsnotify_prepare_user_wait(struct fsnotify_iter_info *iter_info)\r\n{\r\nstruct fsnotify_group *group;\r\nif (WARN_ON_ONCE(!iter_info->inode_mark && !iter_info->vfsmount_mark))\r\nreturn false;\r\nif (iter_info->inode_mark)\r\ngroup = iter_info->inode_mark->group;\r\nelse\r\ngroup = iter_info->vfsmount_mark->group;\r\natomic_inc(&group->user_waits);\r\nif (iter_info->inode_mark) {\r\nif (!fsnotify_get_mark_safe(iter_info->inode_mark))\r\ngoto out_wait;\r\n}\r\nif (iter_info->vfsmount_mark) {\r\nif (!fsnotify_get_mark_safe(iter_info->vfsmount_mark))\r\ngoto out_inode;\r\n}\r\nsrcu_read_unlock(&fsnotify_mark_srcu, iter_info->srcu_idx);\r\nreturn true;\r\nout_inode:\r\nif (iter_info->inode_mark)\r\nfsnotify_put_mark(iter_info->inode_mark);\r\nout_wait:\r\nif (atomic_dec_and_test(&group->user_waits) && group->shutdown)\r\nwake_up(&group->notification_waitq);\r\nreturn false;\r\n}\r\nvoid fsnotify_finish_user_wait(struct fsnotify_iter_info *iter_info)\r\n{\r\nstruct fsnotify_group *group = NULL;\r\niter_info->srcu_idx = srcu_read_lock(&fsnotify_mark_srcu);\r\nif (iter_info->inode_mark) {\r\ngroup = iter_info->inode_mark->group;\r\nfsnotify_put_mark(iter_info->inode_mark);\r\n}\r\nif (iter_info->vfsmount_mark) {\r\ngroup = iter_info->vfsmount_mark->group;\r\nfsnotify_put_mark(iter_info->vfsmount_mark);\r\n}\r\nif (atomic_dec_and_test(&group->user_waits) && group->shutdown)\r\nwake_up(&group->notification_waitq);\r\n}\r\nvoid fsnotify_detach_mark(struct fsnotify_mark *mark)\r\n{\r\nstruct fsnotify_group *group = mark->group;\r\nWARN_ON_ONCE(!mutex_is_locked(&group->mark_mutex));\r\nWARN_ON_ONCE(!srcu_read_lock_held(&fsnotify_mark_srcu) &&\r\natomic_read(&mark->refcnt) < 1 +\r\n!!(mark->flags & FSNOTIFY_MARK_FLAG_ATTACHED));\r\nspin_lock(&mark->lock);\r\nif (!(mark->flags & FSNOTIFY_MARK_FLAG_ATTACHED)) {\r\nspin_unlock(&mark->lock);\r\nreturn;\r\n}\r\nmark->flags &= ~FSNOTIFY_MARK_FLAG_ATTACHED;\r\nlist_del_init(&mark->g_list);\r\nspin_unlock(&mark->lock);\r\natomic_dec(&group->num_marks);\r\nfsnotify_put_mark(mark);\r\n}\r\nvoid fsnotify_free_mark(struct fsnotify_mark *mark)\r\n{\r\nstruct fsnotify_group *group = mark->group;\r\nspin_lock(&mark->lock);\r\nif (!(mark->flags & FSNOTIFY_MARK_FLAG_ALIVE)) {\r\nspin_unlock(&mark->lock);\r\nreturn;\r\n}\r\nmark->flags &= ~FSNOTIFY_MARK_FLAG_ALIVE;\r\nspin_unlock(&mark->lock);\r\nif (group->ops->freeing_mark)\r\ngroup->ops->freeing_mark(mark, group);\r\n}\r\nvoid fsnotify_destroy_mark(struct fsnotify_mark *mark,\r\nstruct fsnotify_group *group)\r\n{\r\nmutex_lock_nested(&group->mark_mutex, SINGLE_DEPTH_NESTING);\r\nfsnotify_detach_mark(mark);\r\nmutex_unlock(&group->mark_mutex);\r\nfsnotify_free_mark(mark);\r\n}\r\nint fsnotify_compare_groups(struct fsnotify_group *a, struct fsnotify_group *b)\r\n{\r\nif (a == b)\r\nreturn 0;\r\nif (!a)\r\nreturn 1;\r\nif (!b)\r\nreturn -1;\r\nif (a->priority < b->priority)\r\nreturn 1;\r\nif (a->priority > b->priority)\r\nreturn -1;\r\nif (a < b)\r\nreturn 1;\r\nreturn -1;\r\n}\r\nstatic int fsnotify_attach_connector_to_object(\r\nstruct fsnotify_mark_connector __rcu **connp,\r\nstruct inode *inode,\r\nstruct vfsmount *mnt)\r\n{\r\nstruct fsnotify_mark_connector *conn;\r\nconn = kmem_cache_alloc(fsnotify_mark_connector_cachep, GFP_KERNEL);\r\nif (!conn)\r\nreturn -ENOMEM;\r\nspin_lock_init(&conn->lock);\r\nINIT_HLIST_HEAD(&conn->list);\r\nif (inode) {\r\nconn->flags = FSNOTIFY_OBJ_TYPE_INODE;\r\nconn->inode = igrab(inode);\r\n} else {\r\nconn->flags = FSNOTIFY_OBJ_TYPE_VFSMOUNT;\r\nconn->mnt = mnt;\r\n}\r\nif (cmpxchg(connp, NULL, conn)) {\r\nif (inode)\r\niput(inode);\r\nkmem_cache_free(fsnotify_mark_connector_cachep, conn);\r\n}\r\nreturn 0;\r\n}\r\nstatic struct fsnotify_mark_connector *fsnotify_grab_connector(\r\nstruct fsnotify_mark_connector __rcu **connp)\r\n{\r\nstruct fsnotify_mark_connector *conn;\r\nint idx;\r\nidx = srcu_read_lock(&fsnotify_mark_srcu);\r\nconn = srcu_dereference(*connp, &fsnotify_mark_srcu);\r\nif (!conn)\r\ngoto out;\r\nspin_lock(&conn->lock);\r\nif (!(conn->flags & (FSNOTIFY_OBJ_TYPE_INODE |\r\nFSNOTIFY_OBJ_TYPE_VFSMOUNT))) {\r\nspin_unlock(&conn->lock);\r\nsrcu_read_unlock(&fsnotify_mark_srcu, idx);\r\nreturn NULL;\r\n}\r\nout:\r\nsrcu_read_unlock(&fsnotify_mark_srcu, idx);\r\nreturn conn;\r\n}\r\nstatic int fsnotify_add_mark_list(struct fsnotify_mark *mark,\r\nstruct inode *inode, struct vfsmount *mnt,\r\nint allow_dups)\r\n{\r\nstruct fsnotify_mark *lmark, *last = NULL;\r\nstruct fsnotify_mark_connector *conn;\r\nstruct fsnotify_mark_connector __rcu **connp;\r\nint cmp;\r\nint err = 0;\r\nif (WARN_ON(!inode && !mnt))\r\nreturn -EINVAL;\r\nif (inode)\r\nconnp = &inode->i_fsnotify_marks;\r\nelse\r\nconnp = &real_mount(mnt)->mnt_fsnotify_marks;\r\nrestart:\r\nspin_lock(&mark->lock);\r\nconn = fsnotify_grab_connector(connp);\r\nif (!conn) {\r\nspin_unlock(&mark->lock);\r\nerr = fsnotify_attach_connector_to_object(connp, inode, mnt);\r\nif (err)\r\nreturn err;\r\ngoto restart;\r\n}\r\nif (hlist_empty(&conn->list)) {\r\nhlist_add_head_rcu(&mark->obj_list, &conn->list);\r\ngoto added;\r\n}\r\nhlist_for_each_entry(lmark, &conn->list, obj_list) {\r\nlast = lmark;\r\nif ((lmark->group == mark->group) &&\r\n(lmark->flags & FSNOTIFY_MARK_FLAG_ATTACHED) &&\r\n!allow_dups) {\r\nerr = -EEXIST;\r\ngoto out_err;\r\n}\r\ncmp = fsnotify_compare_groups(lmark->group, mark->group);\r\nif (cmp >= 0) {\r\nhlist_add_before_rcu(&mark->obj_list, &lmark->obj_list);\r\ngoto added;\r\n}\r\n}\r\nBUG_ON(last == NULL);\r\nhlist_add_behind_rcu(&mark->obj_list, &last->obj_list);\r\nadded:\r\nmark->connector = conn;\r\nout_err:\r\nspin_unlock(&conn->lock);\r\nspin_unlock(&mark->lock);\r\nreturn err;\r\n}\r\nint fsnotify_add_mark_locked(struct fsnotify_mark *mark, struct inode *inode,\r\nstruct vfsmount *mnt, int allow_dups)\r\n{\r\nstruct fsnotify_group *group = mark->group;\r\nint ret = 0;\r\nBUG_ON(inode && mnt);\r\nBUG_ON(!inode && !mnt);\r\nBUG_ON(!mutex_is_locked(&group->mark_mutex));\r\nspin_lock(&mark->lock);\r\nmark->flags |= FSNOTIFY_MARK_FLAG_ALIVE | FSNOTIFY_MARK_FLAG_ATTACHED;\r\nlist_add(&mark->g_list, &group->marks_list);\r\natomic_inc(&group->num_marks);\r\nfsnotify_get_mark(mark);\r\nspin_unlock(&mark->lock);\r\nret = fsnotify_add_mark_list(mark, inode, mnt, allow_dups);\r\nif (ret)\r\ngoto err;\r\nif (mark->mask)\r\nfsnotify_recalc_mask(mark->connector);\r\nreturn ret;\r\nerr:\r\nmark->flags &= ~(FSNOTIFY_MARK_FLAG_ALIVE |\r\nFSNOTIFY_MARK_FLAG_ATTACHED);\r\nlist_del_init(&mark->g_list);\r\natomic_dec(&group->num_marks);\r\nfsnotify_put_mark(mark);\r\nreturn ret;\r\n}\r\nint fsnotify_add_mark(struct fsnotify_mark *mark, struct inode *inode,\r\nstruct vfsmount *mnt, int allow_dups)\r\n{\r\nint ret;\r\nstruct fsnotify_group *group = mark->group;\r\nmutex_lock(&group->mark_mutex);\r\nret = fsnotify_add_mark_locked(mark, inode, mnt, allow_dups);\r\nmutex_unlock(&group->mark_mutex);\r\nreturn ret;\r\n}\r\nstruct fsnotify_mark *fsnotify_find_mark(\r\nstruct fsnotify_mark_connector __rcu **connp,\r\nstruct fsnotify_group *group)\r\n{\r\nstruct fsnotify_mark_connector *conn;\r\nstruct fsnotify_mark *mark;\r\nconn = fsnotify_grab_connector(connp);\r\nif (!conn)\r\nreturn NULL;\r\nhlist_for_each_entry(mark, &conn->list, obj_list) {\r\nif (mark->group == group &&\r\n(mark->flags & FSNOTIFY_MARK_FLAG_ATTACHED)) {\r\nfsnotify_get_mark(mark);\r\nspin_unlock(&conn->lock);\r\nreturn mark;\r\n}\r\n}\r\nspin_unlock(&conn->lock);\r\nreturn NULL;\r\n}\r\nvoid fsnotify_clear_marks_by_group(struct fsnotify_group *group,\r\nunsigned int type)\r\n{\r\nstruct fsnotify_mark *lmark, *mark;\r\nLIST_HEAD(to_free);\r\nstruct list_head *head = &to_free;\r\nif (type == FSNOTIFY_OBJ_ALL_TYPES) {\r\nhead = &group->marks_list;\r\ngoto clear;\r\n}\r\nmutex_lock_nested(&group->mark_mutex, SINGLE_DEPTH_NESTING);\r\nlist_for_each_entry_safe(mark, lmark, &group->marks_list, g_list) {\r\nif (mark->connector->flags & type)\r\nlist_move(&mark->g_list, &to_free);\r\n}\r\nmutex_unlock(&group->mark_mutex);\r\nclear:\r\nwhile (1) {\r\nmutex_lock_nested(&group->mark_mutex, SINGLE_DEPTH_NESTING);\r\nif (list_empty(head)) {\r\nmutex_unlock(&group->mark_mutex);\r\nbreak;\r\n}\r\nmark = list_first_entry(head, struct fsnotify_mark, g_list);\r\nfsnotify_get_mark(mark);\r\nfsnotify_detach_mark(mark);\r\nmutex_unlock(&group->mark_mutex);\r\nfsnotify_free_mark(mark);\r\nfsnotify_put_mark(mark);\r\n}\r\n}\r\nvoid fsnotify_destroy_marks(struct fsnotify_mark_connector __rcu **connp)\r\n{\r\nstruct fsnotify_mark_connector *conn;\r\nstruct fsnotify_mark *mark, *old_mark = NULL;\r\nstruct inode *inode;\r\nconn = fsnotify_grab_connector(connp);\r\nif (!conn)\r\nreturn;\r\nhlist_for_each_entry(mark, &conn->list, obj_list) {\r\nfsnotify_get_mark(mark);\r\nspin_unlock(&conn->lock);\r\nif (old_mark)\r\nfsnotify_put_mark(old_mark);\r\nold_mark = mark;\r\nfsnotify_destroy_mark(mark, mark->group);\r\nspin_lock(&conn->lock);\r\n}\r\ninode = fsnotify_detach_connector_from_object(conn);\r\nspin_unlock(&conn->lock);\r\nif (old_mark)\r\nfsnotify_put_mark(old_mark);\r\niput(inode);\r\n}\r\nvoid fsnotify_init_mark(struct fsnotify_mark *mark,\r\nstruct fsnotify_group *group)\r\n{\r\nmemset(mark, 0, sizeof(*mark));\r\nspin_lock_init(&mark->lock);\r\natomic_set(&mark->refcnt, 1);\r\nfsnotify_get_group(group);\r\nmark->group = group;\r\n}\r\nstatic void fsnotify_mark_destroy_workfn(struct work_struct *work)\r\n{\r\nstruct fsnotify_mark *mark, *next;\r\nstruct list_head private_destroy_list;\r\nspin_lock(&destroy_lock);\r\nlist_replace_init(&destroy_list, &private_destroy_list);\r\nspin_unlock(&destroy_lock);\r\nsynchronize_srcu(&fsnotify_mark_srcu);\r\nlist_for_each_entry_safe(mark, next, &private_destroy_list, g_list) {\r\nlist_del_init(&mark->g_list);\r\nfsnotify_final_mark_destroy(mark);\r\n}\r\n}\r\nvoid fsnotify_wait_marks_destroyed(void)\r\n{\r\nflush_delayed_work(&reaper_work);\r\n}
