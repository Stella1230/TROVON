int\r\ngm200_secboot_run_blob(struct nvkm_secboot *sb, struct nvkm_gpuobj *blob,\r\nstruct nvkm_falcon *falcon)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nstruct nvkm_subdev *subdev = &gsb->base.subdev;\r\nstruct nvkm_vma vma;\r\nu32 start_address;\r\nint ret;\r\nret = nvkm_falcon_get(falcon, subdev);\r\nif (ret)\r\nreturn ret;\r\nret = nvkm_gpuobj_map(blob, gsb->vm, NV_MEM_ACCESS_RW, &vma);\r\nif (ret) {\r\nnvkm_falcon_put(falcon, subdev);\r\nreturn ret;\r\n}\r\nret = nvkm_falcon_reset(falcon);\r\nif (ret)\r\ngoto end;\r\nnvkm_falcon_bind_context(falcon, gsb->inst);\r\nret = sb->acr->func->load(sb->acr, falcon, blob, vma.offset);\r\nif (ret < 0)\r\ngoto end;\r\nstart_address = ret;\r\nnvkm_mc_intr_mask(sb->subdev.device, falcon->owner->index, false);\r\nnvkm_falcon_wr32(falcon, 0x040, 0xdeada5a5);\r\nnvkm_falcon_set_start_addr(falcon, start_address);\r\nnvkm_falcon_start(falcon);\r\nret = nvkm_falcon_wait_for_halt(falcon, 100);\r\nif (ret)\r\ngoto end;\r\nret = nvkm_falcon_rd32(falcon, 0x040);\r\nend:\r\nnvkm_mc_intr_mask(sb->subdev.device, falcon->owner->index, true);\r\nnvkm_gpuobj_unmap(&vma);\r\nnvkm_falcon_put(falcon, subdev);\r\nreturn ret;\r\n}\r\nint\r\ngm200_secboot_oneinit(struct nvkm_secboot *sb)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nstruct nvkm_device *device = sb->subdev.device;\r\nstruct nvkm_vm *vm;\r\nconst u64 vm_area_len = 600 * 1024;\r\nint ret;\r\nret = nvkm_gpuobj_new(device, 0x1000, 0, true, NULL, &gsb->inst);\r\nif (ret)\r\nreturn ret;\r\nret = nvkm_gpuobj_new(device, 0x8000, 0, true, NULL, &gsb->pgd);\r\nif (ret)\r\nreturn ret;\r\nret = nvkm_vm_new(device, 0, vm_area_len, 0, NULL, &vm);\r\nif (ret)\r\nreturn ret;\r\natomic_inc(&vm->engref[NVKM_SUBDEV_PMU]);\r\nret = nvkm_vm_ref(vm, &gsb->vm, gsb->pgd);\r\nnvkm_vm_ref(NULL, &vm, NULL);\r\nif (ret)\r\nreturn ret;\r\nnvkm_kmap(gsb->inst);\r\nnvkm_wo32(gsb->inst, 0x200, lower_32_bits(gsb->pgd->addr));\r\nnvkm_wo32(gsb->inst, 0x204, upper_32_bits(gsb->pgd->addr));\r\nnvkm_wo32(gsb->inst, 0x208, lower_32_bits(vm_area_len - 1));\r\nnvkm_wo32(gsb->inst, 0x20c, upper_32_bits(vm_area_len - 1));\r\nnvkm_done(gsb->inst);\r\nif (sb->acr->func->oneinit) {\r\nret = sb->acr->func->oneinit(sb->acr, sb);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint\r\ngm200_secboot_fini(struct nvkm_secboot *sb, bool suspend)\r\n{\r\nint ret = 0;\r\nif (sb->acr->func->fini)\r\nret = sb->acr->func->fini(sb->acr, sb, suspend);\r\nreturn ret;\r\n}\r\nvoid *\r\ngm200_secboot_dtor(struct nvkm_secboot *sb)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nsb->acr->func->dtor(sb->acr);\r\nnvkm_vm_ref(NULL, &gsb->vm, gsb->pgd);\r\nnvkm_gpuobj_del(&gsb->pgd);\r\nnvkm_gpuobj_del(&gsb->inst);\r\nreturn gsb;\r\n}\r\nint\r\ngm200_secboot_new(struct nvkm_device *device, int index,\r\nstruct nvkm_secboot **psb)\r\n{\r\nint ret;\r\nstruct gm200_secboot *gsb;\r\nstruct nvkm_acr *acr;\r\nacr = acr_r361_new(BIT(NVKM_SECBOOT_FALCON_FECS) |\r\nBIT(NVKM_SECBOOT_FALCON_GPCCS));\r\nif (IS_ERR(acr))\r\nreturn PTR_ERR(acr);\r\ngsb = kzalloc(sizeof(*gsb), GFP_KERNEL);\r\nif (!gsb) {\r\npsb = NULL;\r\nreturn -ENOMEM;\r\n}\r\n*psb = &gsb->base;\r\nret = nvkm_secboot_ctor(&gm200_secboot, acr, device, index, &gsb->base);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}
