static void\r\nvia_unmap_blit_from_device(struct pci_dev *pdev, drm_via_sg_info_t *vsg)\r\n{\r\nint num_desc = vsg->num_desc;\r\nunsigned cur_descriptor_page = num_desc / vsg->descriptors_per_page;\r\nunsigned descriptor_this_page = num_desc % vsg->descriptors_per_page;\r\ndrm_via_descriptor_t *desc_ptr = vsg->desc_pages[cur_descriptor_page] +\r\ndescriptor_this_page;\r\ndma_addr_t next = vsg->chain_start;\r\nwhile (num_desc--) {\r\nif (descriptor_this_page-- == 0) {\r\ncur_descriptor_page--;\r\ndescriptor_this_page = vsg->descriptors_per_page - 1;\r\ndesc_ptr = vsg->desc_pages[cur_descriptor_page] +\r\ndescriptor_this_page;\r\n}\r\ndma_unmap_single(&pdev->dev, next, sizeof(*desc_ptr), DMA_TO_DEVICE);\r\ndma_unmap_page(&pdev->dev, desc_ptr->mem_addr, desc_ptr->size, vsg->direction);\r\nnext = (dma_addr_t) desc_ptr->next;\r\ndesc_ptr--;\r\n}\r\n}\r\nstatic void\r\nvia_map_blit_for_device(struct pci_dev *pdev,\r\nconst drm_via_dmablit_t *xfer,\r\ndrm_via_sg_info_t *vsg,\r\nint mode)\r\n{\r\nunsigned cur_descriptor_page = 0;\r\nunsigned num_descriptors_this_page = 0;\r\nunsigned char *mem_addr = xfer->mem_addr;\r\nunsigned char *cur_mem;\r\nunsigned char *first_addr = (unsigned char *)VIA_PGDN(mem_addr);\r\nuint32_t fb_addr = xfer->fb_addr;\r\nuint32_t cur_fb;\r\nunsigned long line_len;\r\nunsigned remaining_len;\r\nint num_desc = 0;\r\nint cur_line;\r\ndma_addr_t next = 0 | VIA_DMA_DPR_EC;\r\ndrm_via_descriptor_t *desc_ptr = NULL;\r\nif (mode == 1)\r\ndesc_ptr = vsg->desc_pages[cur_descriptor_page];\r\nfor (cur_line = 0; cur_line < xfer->num_lines; ++cur_line) {\r\nline_len = xfer->line_length;\r\ncur_fb = fb_addr;\r\ncur_mem = mem_addr;\r\nwhile (line_len > 0) {\r\nremaining_len = min(PAGE_SIZE-VIA_PGOFF(cur_mem), line_len);\r\nline_len -= remaining_len;\r\nif (mode == 1) {\r\ndesc_ptr->mem_addr =\r\ndma_map_page(&pdev->dev,\r\nvsg->pages[VIA_PFN(cur_mem) -\r\nVIA_PFN(first_addr)],\r\nVIA_PGOFF(cur_mem), remaining_len,\r\nvsg->direction);\r\ndesc_ptr->dev_addr = cur_fb;\r\ndesc_ptr->size = remaining_len;\r\ndesc_ptr->next = (uint32_t) next;\r\nnext = dma_map_single(&pdev->dev, desc_ptr, sizeof(*desc_ptr),\r\nDMA_TO_DEVICE);\r\ndesc_ptr++;\r\nif (++num_descriptors_this_page >= vsg->descriptors_per_page) {\r\nnum_descriptors_this_page = 0;\r\ndesc_ptr = vsg->desc_pages[++cur_descriptor_page];\r\n}\r\n}\r\nnum_desc++;\r\ncur_mem += remaining_len;\r\ncur_fb += remaining_len;\r\n}\r\nmem_addr += xfer->mem_stride;\r\nfb_addr += xfer->fb_stride;\r\n}\r\nif (mode == 1) {\r\nvsg->chain_start = next;\r\nvsg->state = dr_via_device_mapped;\r\n}\r\nvsg->num_desc = num_desc;\r\n}\r\nstatic void\r\nvia_free_sg_info(struct pci_dev *pdev, drm_via_sg_info_t *vsg)\r\n{\r\nstruct page *page;\r\nint i;\r\nswitch (vsg->state) {\r\ncase dr_via_device_mapped:\r\nvia_unmap_blit_from_device(pdev, vsg);\r\ncase dr_via_desc_pages_alloc:\r\nfor (i = 0; i < vsg->num_desc_pages; ++i) {\r\nif (vsg->desc_pages[i] != NULL)\r\nfree_page((unsigned long)vsg->desc_pages[i]);\r\n}\r\nkfree(vsg->desc_pages);\r\ncase dr_via_pages_locked:\r\nfor (i = 0; i < vsg->num_pages; ++i) {\r\nif (NULL != (page = vsg->pages[i])) {\r\nif (!PageReserved(page) && (DMA_FROM_DEVICE == vsg->direction))\r\nSetPageDirty(page);\r\nput_page(page);\r\n}\r\n}\r\ncase dr_via_pages_alloc:\r\nvfree(vsg->pages);\r\ndefault:\r\nvsg->state = dr_via_sg_init;\r\n}\r\nvfree(vsg->bounce_buffer);\r\nvsg->bounce_buffer = NULL;\r\nvsg->free_on_sequence = 0;\r\n}\r\nstatic void\r\nvia_fire_dmablit(struct drm_device *dev, drm_via_sg_info_t *vsg, int engine)\r\n{\r\ndrm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;\r\nVIA_WRITE(VIA_PCI_DMA_MAR0 + engine*0x10, 0);\r\nVIA_WRITE(VIA_PCI_DMA_DAR0 + engine*0x10, 0);\r\nVIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_DD | VIA_DMA_CSR_TD |\r\nVIA_DMA_CSR_DE);\r\nVIA_WRITE(VIA_PCI_DMA_MR0 + engine*0x04, VIA_DMA_MR_CM | VIA_DMA_MR_TDIE);\r\nVIA_WRITE(VIA_PCI_DMA_BCR0 + engine*0x10, 0);\r\nVIA_WRITE(VIA_PCI_DMA_DPR0 + engine*0x10, vsg->chain_start);\r\nwmb();\r\nVIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_DE | VIA_DMA_CSR_TS);\r\nVIA_READ(VIA_PCI_DMA_CSR0 + engine*0x04);\r\n}\r\nstatic int\r\nvia_lock_all_dma_pages(drm_via_sg_info_t *vsg, drm_via_dmablit_t *xfer)\r\n{\r\nint ret;\r\nunsigned long first_pfn = VIA_PFN(xfer->mem_addr);\r\nvsg->num_pages = VIA_PFN(xfer->mem_addr + (xfer->num_lines * xfer->mem_stride - 1)) -\r\nfirst_pfn + 1;\r\nvsg->pages = vzalloc(sizeof(struct page *) * vsg->num_pages);\r\nif (NULL == vsg->pages)\r\nreturn -ENOMEM;\r\nret = get_user_pages_unlocked((unsigned long)xfer->mem_addr,\r\nvsg->num_pages, vsg->pages,\r\n(vsg->direction == DMA_FROM_DEVICE) ? FOLL_WRITE : 0);\r\nif (ret != vsg->num_pages) {\r\nif (ret < 0)\r\nreturn ret;\r\nvsg->state = dr_via_pages_locked;\r\nreturn -EINVAL;\r\n}\r\nvsg->state = dr_via_pages_locked;\r\nDRM_DEBUG("DMA pages locked\n");\r\nreturn 0;\r\n}\r\nstatic int\r\nvia_alloc_desc_pages(drm_via_sg_info_t *vsg)\r\n{\r\nint i;\r\nvsg->descriptors_per_page = PAGE_SIZE / sizeof(drm_via_descriptor_t);\r\nvsg->num_desc_pages = (vsg->num_desc + vsg->descriptors_per_page - 1) /\r\nvsg->descriptors_per_page;\r\nif (NULL == (vsg->desc_pages = kcalloc(vsg->num_desc_pages, sizeof(void *), GFP_KERNEL)))\r\nreturn -ENOMEM;\r\nvsg->state = dr_via_desc_pages_alloc;\r\nfor (i = 0; i < vsg->num_desc_pages; ++i) {\r\nif (NULL == (vsg->desc_pages[i] =\r\n(drm_via_descriptor_t *) __get_free_page(GFP_KERNEL)))\r\nreturn -ENOMEM;\r\n}\r\nDRM_DEBUG("Allocated %d pages for %d descriptors.\n", vsg->num_desc_pages,\r\nvsg->num_desc);\r\nreturn 0;\r\n}\r\nstatic void\r\nvia_abort_dmablit(struct drm_device *dev, int engine)\r\n{\r\ndrm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;\r\nVIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_TA);\r\n}\r\nstatic void\r\nvia_dmablit_engine_off(struct drm_device *dev, int engine)\r\n{\r\ndrm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;\r\nVIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_TD | VIA_DMA_CSR_DD);\r\n}\r\nvoid\r\nvia_dmablit_handler(struct drm_device *dev, int engine, int from_irq)\r\n{\r\ndrm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;\r\ndrm_via_blitq_t *blitq = dev_priv->blit_queues + engine;\r\nint cur;\r\nint done_transfer;\r\nunsigned long irqsave = 0;\r\nuint32_t status = 0;\r\nDRM_DEBUG("DMA blit handler called. engine = %d, from_irq = %d, blitq = 0x%lx\n",\r\nengine, from_irq, (unsigned long) blitq);\r\nif (from_irq)\r\nspin_lock(&blitq->blit_lock);\r\nelse\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\ndone_transfer = blitq->is_active &&\r\n((status = VIA_READ(VIA_PCI_DMA_CSR0 + engine*0x04)) & VIA_DMA_CSR_TD);\r\ndone_transfer = done_transfer || (blitq->aborting && !(status & VIA_DMA_CSR_DE));\r\ncur = blitq->cur;\r\nif (done_transfer) {\r\nblitq->blits[cur]->aborted = blitq->aborting;\r\nblitq->done_blit_handle++;\r\nwake_up(blitq->blit_queue + cur);\r\ncur++;\r\nif (cur >= VIA_NUM_BLIT_SLOTS)\r\ncur = 0;\r\nblitq->cur = cur;\r\nVIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_TD);\r\nblitq->is_active = 0;\r\nblitq->aborting = 0;\r\nschedule_work(&blitq->wq);\r\n} else if (blitq->is_active && time_after_eq(jiffies, blitq->end)) {\r\nvia_abort_dmablit(dev, engine);\r\nblitq->aborting = 1;\r\nblitq->end = jiffies + HZ;\r\n}\r\nif (!blitq->is_active) {\r\nif (blitq->num_outstanding) {\r\nvia_fire_dmablit(dev, blitq->blits[cur], engine);\r\nblitq->is_active = 1;\r\nblitq->cur = cur;\r\nblitq->num_outstanding--;\r\nblitq->end = jiffies + HZ;\r\nif (!timer_pending(&blitq->poll_timer))\r\nmod_timer(&blitq->poll_timer, jiffies + 1);\r\n} else {\r\nif (timer_pending(&blitq->poll_timer))\r\ndel_timer(&blitq->poll_timer);\r\nvia_dmablit_engine_off(dev, engine);\r\n}\r\n}\r\nif (from_irq)\r\nspin_unlock(&blitq->blit_lock);\r\nelse\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\n}\r\nstatic int\r\nvia_dmablit_active(drm_via_blitq_t *blitq, int engine, uint32_t handle, wait_queue_head_t **queue)\r\n{\r\nunsigned long irqsave;\r\nuint32_t slot;\r\nint active;\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\nactive = ((blitq->done_blit_handle - handle) > (1 << 23)) &&\r\n((blitq->cur_blit_handle - handle) <= (1 << 23));\r\nif (queue && active) {\r\nslot = handle - blitq->done_blit_handle + blitq->cur - 1;\r\nif (slot >= VIA_NUM_BLIT_SLOTS)\r\nslot -= VIA_NUM_BLIT_SLOTS;\r\n*queue = blitq->blit_queue + slot;\r\n}\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\nreturn active;\r\n}\r\nstatic int\r\nvia_dmablit_sync(struct drm_device *dev, uint32_t handle, int engine)\r\n{\r\ndrm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;\r\ndrm_via_blitq_t *blitq = dev_priv->blit_queues + engine;\r\nwait_queue_head_t *queue;\r\nint ret = 0;\r\nif (via_dmablit_active(blitq, engine, handle, &queue)) {\r\nDRM_WAIT_ON(ret, *queue, 3 * HZ,\r\n!via_dmablit_active(blitq, engine, handle, NULL));\r\n}\r\nDRM_DEBUG("DMA blit sync handle 0x%x engine %d returned %d\n",\r\nhandle, engine, ret);\r\nreturn ret;\r\n}\r\nstatic void\r\nvia_dmablit_timer(unsigned long data)\r\n{\r\ndrm_via_blitq_t *blitq = (drm_via_blitq_t *) data;\r\nstruct drm_device *dev = blitq->dev;\r\nint engine = (int)\r\n(blitq - ((drm_via_private_t *)dev->dev_private)->blit_queues);\r\nDRM_DEBUG("Polling timer called for engine %d, jiffies %lu\n", engine,\r\n(unsigned long) jiffies);\r\nvia_dmablit_handler(dev, engine, 0);\r\nif (!timer_pending(&blitq->poll_timer)) {\r\nmod_timer(&blitq->poll_timer, jiffies + 1);\r\nvia_dmablit_handler(dev, engine, 0);\r\n}\r\n}\r\nstatic void\r\nvia_dmablit_workqueue(struct work_struct *work)\r\n{\r\ndrm_via_blitq_t *blitq = container_of(work, drm_via_blitq_t, wq);\r\nstruct drm_device *dev = blitq->dev;\r\nunsigned long irqsave;\r\ndrm_via_sg_info_t *cur_sg;\r\nint cur_released;\r\nDRM_DEBUG("Workqueue task called for blit engine %ld\n", (unsigned long)\r\n(blitq - ((drm_via_private_t *)dev->dev_private)->blit_queues));\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\nwhile (blitq->serviced != blitq->cur) {\r\ncur_released = blitq->serviced++;\r\nDRM_DEBUG("Releasing blit slot %d\n", cur_released);\r\nif (blitq->serviced >= VIA_NUM_BLIT_SLOTS)\r\nblitq->serviced = 0;\r\ncur_sg = blitq->blits[cur_released];\r\nblitq->num_free++;\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\nwake_up(&blitq->busy_queue);\r\nvia_free_sg_info(dev->pdev, cur_sg);\r\nkfree(cur_sg);\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\n}\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\n}\r\nvoid\r\nvia_init_dmablit(struct drm_device *dev)\r\n{\r\nint i, j;\r\ndrm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;\r\ndrm_via_blitq_t *blitq;\r\npci_set_master(dev->pdev);\r\nfor (i = 0; i < VIA_NUM_BLIT_ENGINES; ++i) {\r\nblitq = dev_priv->blit_queues + i;\r\nblitq->dev = dev;\r\nblitq->cur_blit_handle = 0;\r\nblitq->done_blit_handle = 0;\r\nblitq->head = 0;\r\nblitq->cur = 0;\r\nblitq->serviced = 0;\r\nblitq->num_free = VIA_NUM_BLIT_SLOTS - 1;\r\nblitq->num_outstanding = 0;\r\nblitq->is_active = 0;\r\nblitq->aborting = 0;\r\nspin_lock_init(&blitq->blit_lock);\r\nfor (j = 0; j < VIA_NUM_BLIT_SLOTS; ++j)\r\ninit_waitqueue_head(blitq->blit_queue + j);\r\ninit_waitqueue_head(&blitq->busy_queue);\r\nINIT_WORK(&blitq->wq, via_dmablit_workqueue);\r\nsetup_timer(&blitq->poll_timer, via_dmablit_timer,\r\n(unsigned long)blitq);\r\n}\r\n}\r\nstatic int\r\nvia_build_sg_info(struct drm_device *dev, drm_via_sg_info_t *vsg, drm_via_dmablit_t *xfer)\r\n{\r\nint draw = xfer->to_fb;\r\nint ret = 0;\r\nvsg->direction = (draw) ? DMA_TO_DEVICE : DMA_FROM_DEVICE;\r\nvsg->bounce_buffer = NULL;\r\nvsg->state = dr_via_sg_init;\r\nif (xfer->num_lines <= 0 || xfer->line_length <= 0) {\r\nDRM_ERROR("Zero size bitblt.\n");\r\nreturn -EINVAL;\r\n}\r\nif ((xfer->mem_stride - xfer->line_length) > 2*PAGE_SIZE) {\r\nDRM_ERROR("Too large system memory stride. Stride: %d, "\r\n"Length: %d\n", xfer->mem_stride, xfer->line_length);\r\nreturn -EINVAL;\r\n}\r\nif ((xfer->mem_stride == xfer->line_length) &&\r\n(xfer->fb_stride == xfer->line_length)) {\r\nxfer->mem_stride *= xfer->num_lines;\r\nxfer->line_length = xfer->mem_stride;\r\nxfer->fb_stride = xfer->mem_stride;\r\nxfer->num_lines = 1;\r\n}\r\nif (xfer->num_lines > 2048 || (xfer->num_lines*xfer->mem_stride > (2048*2048*4))) {\r\nDRM_ERROR("Too large PCI DMA bitblt.\n");\r\nreturn -EINVAL;\r\n}\r\nif (xfer->mem_stride < xfer->line_length ||\r\nabs(xfer->fb_stride) < xfer->line_length) {\r\nDRM_ERROR("Invalid frame-buffer / memory stride.\n");\r\nreturn -EINVAL;\r\n}\r\n#ifdef VIA_BUGFREE\r\nif ((((unsigned long)xfer->mem_addr & 3) != ((unsigned long)xfer->fb_addr & 3)) ||\r\n((xfer->num_lines > 1) && ((xfer->mem_stride & 3) != (xfer->fb_stride & 3)))) {\r\nDRM_ERROR("Invalid DRM bitblt alignment.\n");\r\nreturn -EINVAL;\r\n}\r\n#else\r\nif ((((unsigned long)xfer->mem_addr & 15) ||\r\n((unsigned long)xfer->fb_addr & 3)) ||\r\n((xfer->num_lines > 1) &&\r\n((xfer->mem_stride & 15) || (xfer->fb_stride & 3)))) {\r\nDRM_ERROR("Invalid DRM bitblt alignment.\n");\r\nreturn -EINVAL;\r\n}\r\n#endif\r\nif (0 != (ret = via_lock_all_dma_pages(vsg, xfer))) {\r\nDRM_ERROR("Could not lock DMA pages.\n");\r\nvia_free_sg_info(dev->pdev, vsg);\r\nreturn ret;\r\n}\r\nvia_map_blit_for_device(dev->pdev, xfer, vsg, 0);\r\nif (0 != (ret = via_alloc_desc_pages(vsg))) {\r\nDRM_ERROR("Could not allocate DMA descriptor pages.\n");\r\nvia_free_sg_info(dev->pdev, vsg);\r\nreturn ret;\r\n}\r\nvia_map_blit_for_device(dev->pdev, xfer, vsg, 1);\r\nreturn 0;\r\n}\r\nstatic int\r\nvia_dmablit_grab_slot(drm_via_blitq_t *blitq, int engine)\r\n{\r\nint ret = 0;\r\nunsigned long irqsave;\r\nDRM_DEBUG("Num free is %d\n", blitq->num_free);\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\nwhile (blitq->num_free == 0) {\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\nDRM_WAIT_ON(ret, blitq->busy_queue, HZ, blitq->num_free > 0);\r\nif (ret)\r\nreturn (-EINTR == ret) ? -EAGAIN : ret;\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\n}\r\nblitq->num_free--;\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\nreturn 0;\r\n}\r\nstatic void\r\nvia_dmablit_release_slot(drm_via_blitq_t *blitq)\r\n{\r\nunsigned long irqsave;\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\nblitq->num_free++;\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\nwake_up(&blitq->busy_queue);\r\n}\r\nstatic int\r\nvia_dmablit(struct drm_device *dev, drm_via_dmablit_t *xfer)\r\n{\r\ndrm_via_private_t *dev_priv = (drm_via_private_t *)dev->dev_private;\r\ndrm_via_sg_info_t *vsg;\r\ndrm_via_blitq_t *blitq;\r\nint ret;\r\nint engine;\r\nunsigned long irqsave;\r\nif (dev_priv == NULL) {\r\nDRM_ERROR("Called without initialization.\n");\r\nreturn -EINVAL;\r\n}\r\nengine = (xfer->to_fb) ? 0 : 1;\r\nblitq = dev_priv->blit_queues + engine;\r\nif (0 != (ret = via_dmablit_grab_slot(blitq, engine)))\r\nreturn ret;\r\nif (NULL == (vsg = kmalloc(sizeof(*vsg), GFP_KERNEL))) {\r\nvia_dmablit_release_slot(blitq);\r\nreturn -ENOMEM;\r\n}\r\nif (0 != (ret = via_build_sg_info(dev, vsg, xfer))) {\r\nvia_dmablit_release_slot(blitq);\r\nkfree(vsg);\r\nreturn ret;\r\n}\r\nspin_lock_irqsave(&blitq->blit_lock, irqsave);\r\nblitq->blits[blitq->head++] = vsg;\r\nif (blitq->head >= VIA_NUM_BLIT_SLOTS)\r\nblitq->head = 0;\r\nblitq->num_outstanding++;\r\nxfer->sync.sync_handle = ++blitq->cur_blit_handle;\r\nspin_unlock_irqrestore(&blitq->blit_lock, irqsave);\r\nxfer->sync.engine = engine;\r\nvia_dmablit_handler(dev, engine, 0);\r\nreturn 0;\r\n}\r\nint\r\nvia_dma_blit_sync(struct drm_device *dev, void *data, struct drm_file *file_priv)\r\n{\r\ndrm_via_blitsync_t *sync = data;\r\nint err;\r\nif (sync->engine >= VIA_NUM_BLIT_ENGINES)\r\nreturn -EINVAL;\r\nerr = via_dmablit_sync(dev, sync->sync_handle, sync->engine);\r\nif (-EINTR == err)\r\nerr = -EAGAIN;\r\nreturn err;\r\n}\r\nint\r\nvia_dma_blit(struct drm_device *dev, void *data, struct drm_file *file_priv)\r\n{\r\ndrm_via_dmablit_t *xfer = data;\r\nint err;\r\nerr = via_dmablit(dev, xfer);\r\nreturn err;\r\n}
