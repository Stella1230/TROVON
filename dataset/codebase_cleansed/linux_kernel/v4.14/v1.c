static void\r\nnvkm_falcon_v1_load_imem(struct nvkm_falcon *falcon, void *data, u32 start,\r\nu32 size, u16 tag, u8 port, bool secure)\r\n{\r\nu8 rem = size % 4;\r\nu32 reg;\r\nint i;\r\nsize -= rem;\r\nreg = start | BIT(24) | (secure ? BIT(28) : 0);\r\nnvkm_falcon_wr32(falcon, 0x180 + (port * 16), reg);\r\nfor (i = 0; i < size / 4; i++) {\r\nif ((i & 0x3f) == 0)\r\nnvkm_falcon_wr32(falcon, 0x188 + (port * 16), tag++);\r\nnvkm_falcon_wr32(falcon, 0x184 + (port * 16), ((u32 *)data)[i]);\r\n}\r\nif (rem) {\r\nu32 extra = ((u32 *)data)[i];\r\nif ((i & 0x3f) == 0)\r\nnvkm_falcon_wr32(falcon, 0x188 + (port * 16), tag++);\r\nnvkm_falcon_wr32(falcon, 0x184 + (port * 16),\r\nextra & (BIT(rem * 8) - 1));\r\n++i;\r\n}\r\nfor (; i & 0x3f; i++)\r\nnvkm_falcon_wr32(falcon, 0x184 + (port * 16), 0);\r\n}\r\nstatic void\r\nnvkm_falcon_v1_load_emem(struct nvkm_falcon *falcon, void *data, u32 start,\r\nu32 size, u8 port)\r\n{\r\nu8 rem = size % 4;\r\nint i;\r\nsize -= rem;\r\nnvkm_falcon_wr32(falcon, 0xac0 + (port * 8), start | (0x1 << 24));\r\nfor (i = 0; i < size / 4; i++)\r\nnvkm_falcon_wr32(falcon, 0xac4 + (port * 8), ((u32 *)data)[i]);\r\nif (rem) {\r\nu32 extra = ((u32 *)data)[i];\r\nnvkm_falcon_wr32(falcon, 0xac4 + (port * 8),\r\nextra & (BIT(rem * 8) - 1));\r\n}\r\n}\r\nstatic void\r\nnvkm_falcon_v1_load_dmem(struct nvkm_falcon *falcon, void *data, u32 start,\r\nu32 size, u8 port)\r\n{\r\nu8 rem = size % 4;\r\nint i;\r\nif (start >= EMEM_START_ADDR && falcon->has_emem)\r\nreturn nvkm_falcon_v1_load_emem(falcon, data,\r\nstart - EMEM_START_ADDR, size,\r\nport);\r\nsize -= rem;\r\nnvkm_falcon_wr32(falcon, 0x1c0 + (port * 8), start | (0x1 << 24));\r\nfor (i = 0; i < size / 4; i++)\r\nnvkm_falcon_wr32(falcon, 0x1c4 + (port * 8), ((u32 *)data)[i]);\r\nif (rem) {\r\nu32 extra = ((u32 *)data)[i];\r\nnvkm_falcon_wr32(falcon, 0x1c4 + (port * 8),\r\nextra & (BIT(rem * 8) - 1));\r\n}\r\n}\r\nstatic void\r\nnvkm_falcon_v1_read_emem(struct nvkm_falcon *falcon, u32 start, u32 size,\r\nu8 port, void *data)\r\n{\r\nu8 rem = size % 4;\r\nint i;\r\nsize -= rem;\r\nnvkm_falcon_wr32(falcon, 0xac0 + (port * 8), start | (0x1 << 25));\r\nfor (i = 0; i < size / 4; i++)\r\n((u32 *)data)[i] = nvkm_falcon_rd32(falcon, 0xac4 + (port * 8));\r\nif (rem) {\r\nu32 extra = nvkm_falcon_rd32(falcon, 0xac4 + (port * 8));\r\nfor (i = size; i < size + rem; i++) {\r\n((u8 *)data)[i] = (u8)(extra & 0xff);\r\nextra >>= 8;\r\n}\r\n}\r\n}\r\nstatic void\r\nnvkm_falcon_v1_read_dmem(struct nvkm_falcon *falcon, u32 start, u32 size,\r\nu8 port, void *data)\r\n{\r\nu8 rem = size % 4;\r\nint i;\r\nif (start >= EMEM_START_ADDR && falcon->has_emem)\r\nreturn nvkm_falcon_v1_read_emem(falcon, start - EMEM_START_ADDR,\r\nsize, port, data);\r\nsize -= rem;\r\nnvkm_falcon_wr32(falcon, 0x1c0 + (port * 8), start | (0x1 << 25));\r\nfor (i = 0; i < size / 4; i++)\r\n((u32 *)data)[i] = nvkm_falcon_rd32(falcon, 0x1c4 + (port * 8));\r\nif (rem) {\r\nu32 extra = nvkm_falcon_rd32(falcon, 0x1c4 + (port * 8));\r\nfor (i = size; i < size + rem; i++) {\r\n((u8 *)data)[i] = (u8)(extra & 0xff);\r\nextra >>= 8;\r\n}\r\n}\r\n}\r\nstatic void\r\nnvkm_falcon_v1_bind_context(struct nvkm_falcon *falcon, struct nvkm_gpuobj *ctx)\r\n{\r\nu32 inst_loc;\r\nu32 fbif;\r\nif (ctx == NULL) {\r\nnvkm_falcon_wr32(falcon, 0x10c, 0x0);\r\nreturn;\r\n}\r\nswitch (falcon->owner->index) {\r\ncase NVKM_ENGINE_NVENC0:\r\ncase NVKM_ENGINE_NVENC1:\r\ncase NVKM_ENGINE_NVENC2:\r\nfbif = 0x800;\r\nbreak;\r\ncase NVKM_SUBDEV_PMU:\r\nfbif = 0xe00;\r\nbreak;\r\ndefault:\r\nfbif = 0x600;\r\nbreak;\r\n}\r\nnvkm_falcon_wr32(falcon, 0x10c, 0x1);\r\nnvkm_falcon_wr32(falcon, fbif + 4 * FALCON_DMAIDX_UCODE, 0x4);\r\nnvkm_falcon_wr32(falcon, fbif + 4 * FALCON_DMAIDX_VIRT, 0x0);\r\nnvkm_falcon_wr32(falcon, fbif + 4 * FALCON_DMAIDX_PHYS_VID, 0x4);\r\nnvkm_falcon_wr32(falcon, fbif + 4 * FALCON_DMAIDX_PHYS_SYS_COH, 0x5);\r\nnvkm_falcon_wr32(falcon, fbif + 4 * FALCON_DMAIDX_PHYS_SYS_NCOH, 0x6);\r\nswitch (nvkm_memory_target(ctx->memory)) {\r\ncase NVKM_MEM_TARGET_VRAM: inst_loc = 0; break;\r\ncase NVKM_MEM_TARGET_HOST: inst_loc = 2; break;\r\ncase NVKM_MEM_TARGET_NCOH: inst_loc = 3; break;\r\ndefault:\r\nWARN_ON(1);\r\nreturn;\r\n}\r\nnvkm_falcon_mask(falcon, 0x048, 0x1, 0x1);\r\nnvkm_falcon_wr32(falcon, 0x054,\r\n((ctx->addr >> 12) & 0xfffffff) |\r\n(inst_loc << 28) | (1 << 30));\r\nnvkm_falcon_mask(falcon, 0x090, 0x10000, 0x10000);\r\nnvkm_falcon_mask(falcon, 0x0a4, 0x8, 0x8);\r\n}\r\nstatic void\r\nnvkm_falcon_v1_set_start_addr(struct nvkm_falcon *falcon, u32 start_addr)\r\n{\r\nnvkm_falcon_wr32(falcon, 0x104, start_addr);\r\n}\r\nstatic void\r\nnvkm_falcon_v1_start(struct nvkm_falcon *falcon)\r\n{\r\nu32 reg = nvkm_falcon_rd32(falcon, 0x100);\r\nif (reg & BIT(6))\r\nnvkm_falcon_wr32(falcon, 0x130, 0x2);\r\nelse\r\nnvkm_falcon_wr32(falcon, 0x100, 0x2);\r\n}\r\nstatic int\r\nnvkm_falcon_v1_wait_for_halt(struct nvkm_falcon *falcon, u32 ms)\r\n{\r\nstruct nvkm_device *device = falcon->owner->device;\r\nint ret;\r\nret = nvkm_wait_msec(device, ms, falcon->addr + 0x100, 0x10, 0x10);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nstatic int\r\nnvkm_falcon_v1_clear_interrupt(struct nvkm_falcon *falcon, u32 mask)\r\n{\r\nstruct nvkm_device *device = falcon->owner->device;\r\nint ret;\r\nnvkm_falcon_mask(falcon, 0x004, mask, mask);\r\nret = nvkm_wait_msec(device, 10, falcon->addr + 0x008, mask, 0x0);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nstatic int\r\nfalcon_v1_wait_idle(struct nvkm_falcon *falcon)\r\n{\r\nstruct nvkm_device *device = falcon->owner->device;\r\nint ret;\r\nret = nvkm_wait_msec(device, 10, falcon->addr + 0x04c, 0xffff, 0x0);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nstatic int\r\nnvkm_falcon_v1_enable(struct nvkm_falcon *falcon)\r\n{\r\nstruct nvkm_device *device = falcon->owner->device;\r\nint ret;\r\nret = nvkm_wait_msec(device, 10, falcon->addr + 0x10c, 0x6, 0x0);\r\nif (ret < 0) {\r\nnvkm_error(falcon->user, "Falcon mem scrubbing timeout\n");\r\nreturn ret;\r\n}\r\nret = falcon_v1_wait_idle(falcon);\r\nif (ret)\r\nreturn ret;\r\nnvkm_falcon_wr32(falcon, 0x010, 0xff);\r\nreturn 0;\r\n}\r\nstatic void\r\nnvkm_falcon_v1_disable(struct nvkm_falcon *falcon)\r\n{\r\nnvkm_falcon_wr32(falcon, 0x014, 0xff);\r\nfalcon_v1_wait_idle(falcon);\r\n}\r\nint\r\nnvkm_falcon_v1_new(struct nvkm_subdev *owner, const char *name, u32 addr,\r\nstruct nvkm_falcon **pfalcon)\r\n{\r\nstruct nvkm_falcon *falcon;\r\nif (!(falcon = *pfalcon = kzalloc(sizeof(*falcon), GFP_KERNEL)))\r\nreturn -ENOMEM;\r\nnvkm_falcon_ctor(&nvkm_falcon_v1, owner, name, addr, falcon);\r\nreturn 0;\r\n}
