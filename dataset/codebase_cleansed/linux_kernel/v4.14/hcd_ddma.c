static u16 dwc2_frame_list_idx(u16 frame)\r\n{\r\nreturn frame & (FRLISTEN_64_SIZE - 1);\r\n}\r\nstatic u16 dwc2_desclist_idx_inc(u16 idx, u16 inc, u8 speed)\r\n{\r\nreturn (idx + inc) &\r\n((speed == USB_SPEED_HIGH ? MAX_DMA_DESC_NUM_HS_ISOC :\r\nMAX_DMA_DESC_NUM_GENERIC) - 1);\r\n}\r\nstatic u16 dwc2_desclist_idx_dec(u16 idx, u16 inc, u8 speed)\r\n{\r\nreturn (idx - inc) &\r\n((speed == USB_SPEED_HIGH ? MAX_DMA_DESC_NUM_HS_ISOC :\r\nMAX_DMA_DESC_NUM_GENERIC) - 1);\r\n}\r\nstatic u16 dwc2_max_desc_num(struct dwc2_qh *qh)\r\n{\r\nreturn (qh->ep_type == USB_ENDPOINT_XFER_ISOC &&\r\nqh->dev_speed == USB_SPEED_HIGH) ?\r\nMAX_DMA_DESC_NUM_HS_ISOC : MAX_DMA_DESC_NUM_GENERIC;\r\n}\r\nstatic u16 dwc2_frame_incr_val(struct dwc2_qh *qh)\r\n{\r\nreturn qh->dev_speed == USB_SPEED_HIGH ?\r\n(qh->host_interval + 8 - 1) / 8 : qh->host_interval;\r\n}\r\nstatic int dwc2_desc_list_alloc(struct dwc2_hsotg *hsotg, struct dwc2_qh *qh,\r\ngfp_t flags)\r\n{\r\nstruct kmem_cache *desc_cache;\r\nif (qh->ep_type == USB_ENDPOINT_XFER_ISOC &&\r\nqh->dev_speed == USB_SPEED_HIGH)\r\ndesc_cache = hsotg->desc_hsisoc_cache;\r\nelse\r\ndesc_cache = hsotg->desc_gen_cache;\r\nqh->desc_list_sz = sizeof(struct dwc2_dma_desc) *\r\ndwc2_max_desc_num(qh);\r\nqh->desc_list = kmem_cache_zalloc(desc_cache, flags | GFP_DMA);\r\nif (!qh->desc_list)\r\nreturn -ENOMEM;\r\nqh->desc_list_dma = dma_map_single(hsotg->dev, qh->desc_list,\r\nqh->desc_list_sz,\r\nDMA_TO_DEVICE);\r\nqh->n_bytes = kcalloc(dwc2_max_desc_num(qh), sizeof(u32), flags);\r\nif (!qh->n_bytes) {\r\ndma_unmap_single(hsotg->dev, qh->desc_list_dma,\r\nqh->desc_list_sz,\r\nDMA_FROM_DEVICE);\r\nkmem_cache_free(desc_cache, qh->desc_list);\r\nqh->desc_list = NULL;\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void dwc2_desc_list_free(struct dwc2_hsotg *hsotg, struct dwc2_qh *qh)\r\n{\r\nstruct kmem_cache *desc_cache;\r\nif (qh->ep_type == USB_ENDPOINT_XFER_ISOC &&\r\nqh->dev_speed == USB_SPEED_HIGH)\r\ndesc_cache = hsotg->desc_hsisoc_cache;\r\nelse\r\ndesc_cache = hsotg->desc_gen_cache;\r\nif (qh->desc_list) {\r\ndma_unmap_single(hsotg->dev, qh->desc_list_dma,\r\nqh->desc_list_sz, DMA_FROM_DEVICE);\r\nkmem_cache_free(desc_cache, qh->desc_list);\r\nqh->desc_list = NULL;\r\n}\r\nkfree(qh->n_bytes);\r\nqh->n_bytes = NULL;\r\n}\r\nstatic int dwc2_frame_list_alloc(struct dwc2_hsotg *hsotg, gfp_t mem_flags)\r\n{\r\nif (hsotg->frame_list)\r\nreturn 0;\r\nhsotg->frame_list_sz = 4 * FRLISTEN_64_SIZE;\r\nhsotg->frame_list = kzalloc(hsotg->frame_list_sz, GFP_ATOMIC | GFP_DMA);\r\nif (!hsotg->frame_list)\r\nreturn -ENOMEM;\r\nhsotg->frame_list_dma = dma_map_single(hsotg->dev, hsotg->frame_list,\r\nhsotg->frame_list_sz,\r\nDMA_TO_DEVICE);\r\nreturn 0;\r\n}\r\nstatic void dwc2_frame_list_free(struct dwc2_hsotg *hsotg)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&hsotg->lock, flags);\r\nif (!hsotg->frame_list) {\r\nspin_unlock_irqrestore(&hsotg->lock, flags);\r\nreturn;\r\n}\r\ndma_unmap_single(hsotg->dev, hsotg->frame_list_dma,\r\nhsotg->frame_list_sz, DMA_FROM_DEVICE);\r\nkfree(hsotg->frame_list);\r\nhsotg->frame_list = NULL;\r\nspin_unlock_irqrestore(&hsotg->lock, flags);\r\n}\r\nstatic void dwc2_per_sched_enable(struct dwc2_hsotg *hsotg, u32 fr_list_en)\r\n{\r\nu32 hcfg;\r\nunsigned long flags;\r\nspin_lock_irqsave(&hsotg->lock, flags);\r\nhcfg = dwc2_readl(hsotg->regs + HCFG);\r\nif (hcfg & HCFG_PERSCHEDENA) {\r\nspin_unlock_irqrestore(&hsotg->lock, flags);\r\nreturn;\r\n}\r\ndwc2_writel(hsotg->frame_list_dma, hsotg->regs + HFLBADDR);\r\nhcfg &= ~HCFG_FRLISTEN_MASK;\r\nhcfg |= fr_list_en | HCFG_PERSCHEDENA;\r\ndev_vdbg(hsotg->dev, "Enabling Periodic schedule\n");\r\ndwc2_writel(hcfg, hsotg->regs + HCFG);\r\nspin_unlock_irqrestore(&hsotg->lock, flags);\r\n}\r\nstatic void dwc2_per_sched_disable(struct dwc2_hsotg *hsotg)\r\n{\r\nu32 hcfg;\r\nunsigned long flags;\r\nspin_lock_irqsave(&hsotg->lock, flags);\r\nhcfg = dwc2_readl(hsotg->regs + HCFG);\r\nif (!(hcfg & HCFG_PERSCHEDENA)) {\r\nspin_unlock_irqrestore(&hsotg->lock, flags);\r\nreturn;\r\n}\r\nhcfg &= ~HCFG_PERSCHEDENA;\r\ndev_vdbg(hsotg->dev, "Disabling Periodic schedule\n");\r\ndwc2_writel(hcfg, hsotg->regs + HCFG);\r\nspin_unlock_irqrestore(&hsotg->lock, flags);\r\n}\r\nstatic void dwc2_update_frame_list(struct dwc2_hsotg *hsotg, struct dwc2_qh *qh,\r\nint enable)\r\n{\r\nstruct dwc2_host_chan *chan;\r\nu16 i, j, inc;\r\nif (!hsotg) {\r\npr_err("hsotg = %p\n", hsotg);\r\nreturn;\r\n}\r\nif (!qh->channel) {\r\ndev_err(hsotg->dev, "qh->channel = %p\n", qh->channel);\r\nreturn;\r\n}\r\nif (!hsotg->frame_list) {\r\ndev_err(hsotg->dev, "hsotg->frame_list = %p\n",\r\nhsotg->frame_list);\r\nreturn;\r\n}\r\nchan = qh->channel;\r\ninc = dwc2_frame_incr_val(qh);\r\nif (qh->ep_type == USB_ENDPOINT_XFER_ISOC)\r\ni = dwc2_frame_list_idx(qh->next_active_frame);\r\nelse\r\ni = 0;\r\nj = i;\r\ndo {\r\nif (enable)\r\nhsotg->frame_list[j] |= 1 << chan->hc_num;\r\nelse\r\nhsotg->frame_list[j] &= ~(1 << chan->hc_num);\r\nj = (j + inc) & (FRLISTEN_64_SIZE - 1);\r\n} while (j != i);\r\ndma_sync_single_for_device(hsotg->dev,\r\nhsotg->frame_list_dma,\r\nhsotg->frame_list_sz,\r\nDMA_TO_DEVICE);\r\nif (!enable)\r\nreturn;\r\nchan->schinfo = 0;\r\nif (chan->speed == USB_SPEED_HIGH && qh->host_interval) {\r\nj = 1;\r\ninc = (8 + qh->host_interval - 1) / qh->host_interval;\r\nfor (i = 0; i < inc; i++) {\r\nchan->schinfo |= j;\r\nj = j << qh->host_interval;\r\n}\r\n} else {\r\nchan->schinfo = 0xff;\r\n}\r\n}\r\nstatic void dwc2_release_channel_ddma(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_qh *qh)\r\n{\r\nstruct dwc2_host_chan *chan = qh->channel;\r\nif (dwc2_qh_is_non_per(qh)) {\r\nif (hsotg->params.uframe_sched)\r\nhsotg->available_host_channels++;\r\nelse\r\nhsotg->non_periodic_channels--;\r\n} else {\r\ndwc2_update_frame_list(hsotg, qh, 0);\r\nhsotg->available_host_channels++;\r\n}\r\nif (chan->qh) {\r\nif (!list_empty(&chan->hc_list_entry))\r\nlist_del(&chan->hc_list_entry);\r\ndwc2_hc_cleanup(hsotg, chan);\r\nlist_add_tail(&chan->hc_list_entry, &hsotg->free_hc_list);\r\nchan->qh = NULL;\r\n}\r\nqh->channel = NULL;\r\nqh->ntd = 0;\r\nif (qh->desc_list)\r\nmemset(qh->desc_list, 0, sizeof(struct dwc2_dma_desc) *\r\ndwc2_max_desc_num(qh));\r\n}\r\nint dwc2_hcd_qh_init_ddma(struct dwc2_hsotg *hsotg, struct dwc2_qh *qh,\r\ngfp_t mem_flags)\r\n{\r\nint retval;\r\nif (qh->do_split) {\r\ndev_err(hsotg->dev,\r\n"SPLIT Transfers are not supported in Descriptor DMA mode.\n");\r\nretval = -EINVAL;\r\ngoto err0;\r\n}\r\nretval = dwc2_desc_list_alloc(hsotg, qh, mem_flags);\r\nif (retval)\r\ngoto err0;\r\nif (qh->ep_type == USB_ENDPOINT_XFER_ISOC ||\r\nqh->ep_type == USB_ENDPOINT_XFER_INT) {\r\nif (!hsotg->frame_list) {\r\nretval = dwc2_frame_list_alloc(hsotg, mem_flags);\r\nif (retval)\r\ngoto err1;\r\ndwc2_per_sched_enable(hsotg, HCFG_FRLISTEN_64);\r\n}\r\n}\r\nqh->ntd = 0;\r\nreturn 0;\r\nerr1:\r\ndwc2_desc_list_free(hsotg, qh);\r\nerr0:\r\nreturn retval;\r\n}\r\nvoid dwc2_hcd_qh_free_ddma(struct dwc2_hsotg *hsotg, struct dwc2_qh *qh)\r\n{\r\nunsigned long flags;\r\ndwc2_desc_list_free(hsotg, qh);\r\nspin_lock_irqsave(&hsotg->lock, flags);\r\nif (qh->channel)\r\ndwc2_release_channel_ddma(hsotg, qh);\r\nspin_unlock_irqrestore(&hsotg->lock, flags);\r\nif ((qh->ep_type == USB_ENDPOINT_XFER_ISOC ||\r\nqh->ep_type == USB_ENDPOINT_XFER_INT) &&\r\n(hsotg->params.uframe_sched ||\r\n!hsotg->periodic_channels) && hsotg->frame_list) {\r\ndwc2_per_sched_disable(hsotg);\r\ndwc2_frame_list_free(hsotg);\r\n}\r\n}\r\nstatic u8 dwc2_frame_to_desc_idx(struct dwc2_qh *qh, u16 frame_idx)\r\n{\r\nif (qh->dev_speed == USB_SPEED_HIGH)\r\nreturn (frame_idx & ((MAX_DMA_DESC_NUM_HS_ISOC / 8) - 1)) * 8;\r\nelse\r\nreturn frame_idx & (MAX_DMA_DESC_NUM_GENERIC - 1);\r\n}\r\nstatic u16 dwc2_calc_starting_frame(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_qh *qh, u16 *skip_frames)\r\n{\r\nu16 frame;\r\nhsotg->frame_number = dwc2_hcd_get_frame_number(hsotg);\r\nif (qh->dev_speed == USB_SPEED_HIGH) {\r\nif (dwc2_micro_frame_num(hsotg->frame_number) >= 5) {\r\n*skip_frames = 2 * 8;\r\nframe = dwc2_frame_num_inc(hsotg->frame_number,\r\n*skip_frames);\r\n} else {\r\n*skip_frames = 1 * 8;\r\nframe = dwc2_frame_num_inc(hsotg->frame_number,\r\n*skip_frames);\r\n}\r\nframe = dwc2_full_frame_num(frame);\r\n} else {\r\n*skip_frames = 1;\r\nframe = dwc2_frame_num_inc(hsotg->frame_number, 2);\r\n}\r\nreturn frame;\r\n}\r\nstatic u16 dwc2_recalc_initial_desc_idx(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_qh *qh)\r\n{\r\nu16 frame, fr_idx, fr_idx_tmp, skip_frames;\r\nif (qh->channel) {\r\nframe = dwc2_calc_starting_frame(hsotg, qh, &skip_frames);\r\nfr_idx_tmp = dwc2_frame_list_idx(frame);\r\nfr_idx = (FRLISTEN_64_SIZE +\r\ndwc2_frame_list_idx(qh->next_active_frame) -\r\nfr_idx_tmp) % dwc2_frame_incr_val(qh);\r\nfr_idx = (fr_idx + fr_idx_tmp) % FRLISTEN_64_SIZE;\r\n} else {\r\nqh->next_active_frame = dwc2_calc_starting_frame(hsotg, qh,\r\n&skip_frames);\r\nfr_idx = dwc2_frame_list_idx(qh->next_active_frame);\r\n}\r\nqh->td_first = qh->td_last = dwc2_frame_to_desc_idx(qh, fr_idx);\r\nreturn skip_frames;\r\n}\r\nstatic void dwc2_fill_host_isoc_dma_desc(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_qtd *qtd,\r\nstruct dwc2_qh *qh, u32 max_xfer_size,\r\nu16 idx)\r\n{\r\nstruct dwc2_dma_desc *dma_desc = &qh->desc_list[idx];\r\nstruct dwc2_hcd_iso_packet_desc *frame_desc;\r\nmemset(dma_desc, 0, sizeof(*dma_desc));\r\nframe_desc = &qtd->urb->iso_descs[qtd->isoc_frame_index_last];\r\nif (frame_desc->length > max_xfer_size)\r\nqh->n_bytes[idx] = max_xfer_size;\r\nelse\r\nqh->n_bytes[idx] = frame_desc->length;\r\ndma_desc->buf = (u32)(qtd->urb->dma + frame_desc->offset);\r\ndma_desc->status = qh->n_bytes[idx] << HOST_DMA_ISOC_NBYTES_SHIFT &\r\nHOST_DMA_ISOC_NBYTES_MASK;\r\ndma_desc->status |= HOST_DMA_A;\r\nqh->ntd++;\r\nqtd->isoc_frame_index_last++;\r\n#ifdef ISOC_URB_GIVEBACK_ASAP\r\nif (qtd->isoc_frame_index_last == qtd->urb->packet_count)\r\ndma_desc->status |= HOST_DMA_IOC;\r\n#endif\r\ndma_sync_single_for_device(hsotg->dev,\r\nqh->desc_list_dma +\r\n(idx * sizeof(struct dwc2_dma_desc)),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_TO_DEVICE);\r\n}\r\nstatic void dwc2_init_isoc_dma_desc(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_qh *qh, u16 skip_frames)\r\n{\r\nstruct dwc2_qtd *qtd;\r\nu32 max_xfer_size;\r\nu16 idx, inc, n_desc = 0, ntd_max = 0;\r\nu16 cur_idx;\r\nu16 next_idx;\r\nidx = qh->td_last;\r\ninc = qh->host_interval;\r\nhsotg->frame_number = dwc2_hcd_get_frame_number(hsotg);\r\ncur_idx = dwc2_frame_list_idx(hsotg->frame_number);\r\nnext_idx = dwc2_desclist_idx_inc(qh->td_last, inc, qh->dev_speed);\r\nif (dwc2_frame_idx_num_gt(cur_idx, next_idx) || (cur_idx == next_idx)) {\r\nif (inc < 32) {\r\ndev_vdbg(hsotg->dev,\r\n"current frame number overstep last descriptor\n");\r\nqh->td_last = dwc2_desclist_idx_inc(cur_idx, inc,\r\nqh->dev_speed);\r\nidx = qh->td_last;\r\n}\r\n}\r\nif (qh->host_interval) {\r\nntd_max = (dwc2_max_desc_num(qh) + qh->host_interval - 1) /\r\nqh->host_interval;\r\nif (skip_frames && !qh->channel)\r\nntd_max -= skip_frames / qh->host_interval;\r\n}\r\nmax_xfer_size = qh->dev_speed == USB_SPEED_HIGH ?\r\nMAX_ISOC_XFER_SIZE_HS : MAX_ISOC_XFER_SIZE_FS;\r\nlist_for_each_entry(qtd, &qh->qtd_list, qtd_list_entry) {\r\nif (qtd->in_process &&\r\nqtd->isoc_frame_index_last ==\r\nqtd->urb->packet_count)\r\ncontinue;\r\nqtd->isoc_td_first = idx;\r\nwhile (qh->ntd < ntd_max && qtd->isoc_frame_index_last <\r\nqtd->urb->packet_count) {\r\ndwc2_fill_host_isoc_dma_desc(hsotg, qtd, qh,\r\nmax_xfer_size, idx);\r\nidx = dwc2_desclist_idx_inc(idx, inc, qh->dev_speed);\r\nn_desc++;\r\n}\r\nqtd->isoc_td_last = idx;\r\nqtd->in_process = 1;\r\n}\r\nqh->td_last = idx;\r\n#ifdef ISOC_URB_GIVEBACK_ASAP\r\nif (qh->ntd == ntd_max) {\r\nidx = dwc2_desclist_idx_dec(qh->td_last, inc, qh->dev_speed);\r\nqh->desc_list[idx].status |= HOST_DMA_IOC;\r\ndma_sync_single_for_device(hsotg->dev,\r\nqh->desc_list_dma + (idx *\r\nsizeof(struct dwc2_dma_desc)),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_TO_DEVICE);\r\n}\r\n#else\r\nif (n_desc > DESCNUM_THRESHOLD)\r\nidx = dwc2_desclist_idx_dec(idx, inc * ((qh->ntd + 1) / 2),\r\nqh->dev_speed);\r\nelse\r\nidx = dwc2_desclist_idx_dec(qh->td_last, inc, qh->dev_speed);\r\nqh->desc_list[idx].status |= HOST_DMA_IOC;\r\ndma_sync_single_for_device(hsotg->dev,\r\nqh->desc_list_dma +\r\n(idx * sizeof(struct dwc2_dma_desc)),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_TO_DEVICE);\r\n#endif\r\n}\r\nstatic void dwc2_fill_host_dma_desc(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_host_chan *chan,\r\nstruct dwc2_qtd *qtd, struct dwc2_qh *qh,\r\nint n_desc)\r\n{\r\nstruct dwc2_dma_desc *dma_desc = &qh->desc_list[n_desc];\r\nint len = chan->xfer_len;\r\nif (len > HOST_DMA_NBYTES_LIMIT - (chan->max_packet - 1))\r\nlen = HOST_DMA_NBYTES_LIMIT - (chan->max_packet - 1);\r\nif (chan->ep_is_in) {\r\nint num_packets;\r\nif (len > 0 && chan->max_packet)\r\nnum_packets = (len + chan->max_packet - 1)\r\n/ chan->max_packet;\r\nelse\r\nnum_packets = 1;\r\nlen = num_packets * chan->max_packet;\r\n}\r\ndma_desc->status = len << HOST_DMA_NBYTES_SHIFT & HOST_DMA_NBYTES_MASK;\r\nqh->n_bytes[n_desc] = len;\r\nif (qh->ep_type == USB_ENDPOINT_XFER_CONTROL &&\r\nqtd->control_phase == DWC2_CONTROL_SETUP)\r\ndma_desc->status |= HOST_DMA_SUP;\r\ndma_desc->buf = (u32)chan->xfer_dma;\r\ndma_sync_single_for_device(hsotg->dev,\r\nqh->desc_list_dma +\r\n(n_desc * sizeof(struct dwc2_dma_desc)),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_TO_DEVICE);\r\nif (len > chan->xfer_len) {\r\nchan->xfer_len = 0;\r\n} else {\r\nchan->xfer_dma += len;\r\nchan->xfer_len -= len;\r\n}\r\n}\r\nstatic void dwc2_init_non_isoc_dma_desc(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_qh *qh)\r\n{\r\nstruct dwc2_qtd *qtd;\r\nstruct dwc2_host_chan *chan = qh->channel;\r\nint n_desc = 0;\r\ndev_vdbg(hsotg->dev, "%s(): qh=%p dma=%08lx len=%d\n", __func__, qh,\r\n(unsigned long)chan->xfer_dma, chan->xfer_len);\r\nlist_for_each_entry(qtd, &qh->qtd_list, qtd_list_entry) {\r\ndev_vdbg(hsotg->dev, "qtd=%p\n", qtd);\r\nif (n_desc) {\r\nchan->xfer_dma = qtd->urb->dma +\r\nqtd->urb->actual_length;\r\nchan->xfer_len = qtd->urb->length -\r\nqtd->urb->actual_length;\r\ndev_vdbg(hsotg->dev, "buf=%08lx len=%d\n",\r\n(unsigned long)chan->xfer_dma, chan->xfer_len);\r\n}\r\nqtd->n_desc = 0;\r\ndo {\r\nif (n_desc > 1) {\r\nqh->desc_list[n_desc - 1].status |= HOST_DMA_A;\r\ndev_vdbg(hsotg->dev,\r\n"set A bit in desc %d (%p)\n",\r\nn_desc - 1,\r\n&qh->desc_list[n_desc - 1]);\r\ndma_sync_single_for_device(hsotg->dev,\r\nqh->desc_list_dma +\r\n((n_desc - 1) *\r\nsizeof(struct dwc2_dma_desc)),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_TO_DEVICE);\r\n}\r\ndwc2_fill_host_dma_desc(hsotg, chan, qtd, qh, n_desc);\r\ndev_vdbg(hsotg->dev,\r\n"desc %d (%p) buf=%08x status=%08x\n",\r\nn_desc, &qh->desc_list[n_desc],\r\nqh->desc_list[n_desc].buf,\r\nqh->desc_list[n_desc].status);\r\nqtd->n_desc++;\r\nn_desc++;\r\n} while (chan->xfer_len > 0 &&\r\nn_desc != MAX_DMA_DESC_NUM_GENERIC);\r\ndev_vdbg(hsotg->dev, "n_desc=%d\n", n_desc);\r\nqtd->in_process = 1;\r\nif (qh->ep_type == USB_ENDPOINT_XFER_CONTROL)\r\nbreak;\r\nif (n_desc == MAX_DMA_DESC_NUM_GENERIC)\r\nbreak;\r\n}\r\nif (n_desc) {\r\nqh->desc_list[n_desc - 1].status |=\r\nHOST_DMA_IOC | HOST_DMA_EOL | HOST_DMA_A;\r\ndev_vdbg(hsotg->dev, "set IOC/EOL/A bits in desc %d (%p)\n",\r\nn_desc - 1, &qh->desc_list[n_desc - 1]);\r\ndma_sync_single_for_device(hsotg->dev,\r\nqh->desc_list_dma + (n_desc - 1) *\r\nsizeof(struct dwc2_dma_desc),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_TO_DEVICE);\r\nif (n_desc > 1) {\r\nqh->desc_list[0].status |= HOST_DMA_A;\r\ndev_vdbg(hsotg->dev, "set A bit in desc 0 (%p)\n",\r\n&qh->desc_list[0]);\r\ndma_sync_single_for_device(hsotg->dev,\r\nqh->desc_list_dma,\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_TO_DEVICE);\r\n}\r\nchan->ntd = n_desc;\r\n}\r\n}\r\nvoid dwc2_hcd_start_xfer_ddma(struct dwc2_hsotg *hsotg, struct dwc2_qh *qh)\r\n{\r\nstruct dwc2_host_chan *chan = qh->channel;\r\nu16 skip_frames = 0;\r\nswitch (chan->ep_type) {\r\ncase USB_ENDPOINT_XFER_CONTROL:\r\ncase USB_ENDPOINT_XFER_BULK:\r\ndwc2_init_non_isoc_dma_desc(hsotg, qh);\r\ndwc2_hc_start_transfer_ddma(hsotg, chan);\r\nbreak;\r\ncase USB_ENDPOINT_XFER_INT:\r\ndwc2_init_non_isoc_dma_desc(hsotg, qh);\r\ndwc2_update_frame_list(hsotg, qh, 1);\r\ndwc2_hc_start_transfer_ddma(hsotg, chan);\r\nbreak;\r\ncase USB_ENDPOINT_XFER_ISOC:\r\nif (!qh->ntd)\r\nskip_frames = dwc2_recalc_initial_desc_idx(hsotg, qh);\r\ndwc2_init_isoc_dma_desc(hsotg, qh, skip_frames);\r\nif (!chan->xfer_started) {\r\ndwc2_update_frame_list(hsotg, qh, 1);\r\nchan->ntd = dwc2_max_desc_num(qh);\r\ndwc2_hc_start_transfer_ddma(hsotg, chan);\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic int dwc2_cmpl_host_isoc_dma_desc(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_host_chan *chan,\r\nstruct dwc2_qtd *qtd,\r\nstruct dwc2_qh *qh, u16 idx)\r\n{\r\nstruct dwc2_dma_desc *dma_desc;\r\nstruct dwc2_hcd_iso_packet_desc *frame_desc;\r\nu16 remain = 0;\r\nint rc = 0;\r\nif (!qtd->urb)\r\nreturn -EINVAL;\r\ndma_sync_single_for_cpu(hsotg->dev, qh->desc_list_dma + (idx *\r\nsizeof(struct dwc2_dma_desc)),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_FROM_DEVICE);\r\ndma_desc = &qh->desc_list[idx];\r\nframe_desc = &qtd->urb->iso_descs[qtd->isoc_frame_index_last];\r\ndma_desc->buf = (u32)(qtd->urb->dma + frame_desc->offset);\r\nif (chan->ep_is_in)\r\nremain = (dma_desc->status & HOST_DMA_ISOC_NBYTES_MASK) >>\r\nHOST_DMA_ISOC_NBYTES_SHIFT;\r\nif ((dma_desc->status & HOST_DMA_STS_MASK) == HOST_DMA_STS_PKTERR) {\r\nqtd->urb->error_count++;\r\nframe_desc->actual_length = qh->n_bytes[idx] - remain;\r\nframe_desc->status = -EPROTO;\r\n} else {\r\nframe_desc->actual_length = qh->n_bytes[idx] - remain;\r\nframe_desc->status = 0;\r\n}\r\nif (++qtd->isoc_frame_index == qtd->urb->packet_count) {\r\ndwc2_host_complete(hsotg, qtd, 0);\r\ndwc2_hcd_qtd_unlink_and_free(hsotg, qtd, qh);\r\nif (chan->halt_status == DWC2_HC_XFER_URB_DEQUEUE)\r\nreturn -1;\r\nrc = DWC2_CMPL_DONE;\r\n}\r\nqh->ntd--;\r\nif (dma_desc->status & HOST_DMA_IOC)\r\nrc = DWC2_CMPL_STOP;\r\nreturn rc;\r\n}\r\nstatic void dwc2_complete_isoc_xfer_ddma(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_host_chan *chan,\r\nenum dwc2_halt_status halt_status)\r\n{\r\nstruct dwc2_hcd_iso_packet_desc *frame_desc;\r\nstruct dwc2_qtd *qtd, *qtd_tmp;\r\nstruct dwc2_qh *qh;\r\nu16 idx;\r\nint rc;\r\nqh = chan->qh;\r\nidx = qh->td_first;\r\nif (chan->halt_status == DWC2_HC_XFER_URB_DEQUEUE) {\r\nlist_for_each_entry(qtd, &qh->qtd_list, qtd_list_entry)\r\nqtd->in_process = 0;\r\nreturn;\r\n}\r\nif (halt_status == DWC2_HC_XFER_AHB_ERR ||\r\nhalt_status == DWC2_HC_XFER_BABBLE_ERR) {\r\nint err = halt_status == DWC2_HC_XFER_AHB_ERR ?\r\n-EIO : -EOVERFLOW;\r\nlist_for_each_entry_safe(qtd, qtd_tmp, &qh->qtd_list,\r\nqtd_list_entry) {\r\nif (qtd->urb) {\r\nfor (idx = 0; idx < qtd->urb->packet_count;\r\nidx++) {\r\nframe_desc = &qtd->urb->iso_descs[idx];\r\nframe_desc->status = err;\r\n}\r\ndwc2_host_complete(hsotg, qtd, err);\r\n}\r\ndwc2_hcd_qtd_unlink_and_free(hsotg, qtd, qh);\r\n}\r\nreturn;\r\n}\r\nlist_for_each_entry_safe(qtd, qtd_tmp, &qh->qtd_list, qtd_list_entry) {\r\nif (!qtd->in_process)\r\nbreak;\r\nif (idx != qtd->isoc_td_first) {\r\ndev_vdbg(hsotg->dev,\r\n"try to complete %d instead of %d\n",\r\nidx, qtd->isoc_td_first);\r\nidx = qtd->isoc_td_first;\r\n}\r\ndo {\r\nstruct dwc2_qtd *qtd_next;\r\nu16 cur_idx;\r\nrc = dwc2_cmpl_host_isoc_dma_desc(hsotg, chan, qtd, qh,\r\nidx);\r\nif (rc < 0)\r\nreturn;\r\nidx = dwc2_desclist_idx_inc(idx, qh->host_interval,\r\nchan->speed);\r\nif (!rc)\r\ncontinue;\r\nif (rc == DWC2_CMPL_DONE)\r\nbreak;\r\nif (qh->host_interval >= 32)\r\ngoto stop_scan;\r\nqh->td_first = idx;\r\ncur_idx = dwc2_frame_list_idx(hsotg->frame_number);\r\nqtd_next = list_first_entry(&qh->qtd_list,\r\nstruct dwc2_qtd,\r\nqtd_list_entry);\r\nif (dwc2_frame_idx_num_gt(cur_idx,\r\nqtd_next->isoc_td_last))\r\nbreak;\r\ngoto stop_scan;\r\n} while (idx != qh->td_first);\r\n}\r\nstop_scan:\r\nqh->td_first = idx;\r\n}\r\nstatic int dwc2_update_non_isoc_urb_state_ddma(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_host_chan *chan,\r\nstruct dwc2_qtd *qtd,\r\nstruct dwc2_dma_desc *dma_desc,\r\nenum dwc2_halt_status halt_status,\r\nu32 n_bytes, int *xfer_done)\r\n{\r\nstruct dwc2_hcd_urb *urb = qtd->urb;\r\nu16 remain = 0;\r\nif (chan->ep_is_in)\r\nremain = (dma_desc->status & HOST_DMA_NBYTES_MASK) >>\r\nHOST_DMA_NBYTES_SHIFT;\r\ndev_vdbg(hsotg->dev, "remain=%d dwc2_urb=%p\n", remain, urb);\r\nif (halt_status == DWC2_HC_XFER_AHB_ERR) {\r\ndev_err(hsotg->dev, "EIO\n");\r\nurb->status = -EIO;\r\nreturn 1;\r\n}\r\nif ((dma_desc->status & HOST_DMA_STS_MASK) == HOST_DMA_STS_PKTERR) {\r\nswitch (halt_status) {\r\ncase DWC2_HC_XFER_STALL:\r\ndev_vdbg(hsotg->dev, "Stall\n");\r\nurb->status = -EPIPE;\r\nbreak;\r\ncase DWC2_HC_XFER_BABBLE_ERR:\r\ndev_err(hsotg->dev, "Babble\n");\r\nurb->status = -EOVERFLOW;\r\nbreak;\r\ncase DWC2_HC_XFER_XACT_ERR:\r\ndev_err(hsotg->dev, "XactErr\n");\r\nurb->status = -EPROTO;\r\nbreak;\r\ndefault:\r\ndev_err(hsotg->dev,\r\n"%s: Unhandled descriptor error status (%d)\n",\r\n__func__, halt_status);\r\nbreak;\r\n}\r\nreturn 1;\r\n}\r\nif (dma_desc->status & HOST_DMA_A) {\r\ndev_vdbg(hsotg->dev,\r\n"Active descriptor encountered on channel %d\n",\r\nchan->hc_num);\r\nreturn 0;\r\n}\r\nif (chan->ep_type == USB_ENDPOINT_XFER_CONTROL) {\r\nif (qtd->control_phase == DWC2_CONTROL_DATA) {\r\nurb->actual_length += n_bytes - remain;\r\nif (remain || urb->actual_length >= urb->length) {\r\n*xfer_done = 1;\r\n}\r\n} else if (qtd->control_phase == DWC2_CONTROL_STATUS) {\r\nurb->status = 0;\r\n*xfer_done = 1;\r\n}\r\n} else {\r\nurb->actual_length += n_bytes - remain;\r\ndev_vdbg(hsotg->dev, "length=%d actual=%d\n", urb->length,\r\nurb->actual_length);\r\nif (remain || urb->actual_length >= urb->length) {\r\nurb->status = 0;\r\n*xfer_done = 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int dwc2_process_non_isoc_desc(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_host_chan *chan,\r\nint chnum, struct dwc2_qtd *qtd,\r\nint desc_num,\r\nenum dwc2_halt_status halt_status,\r\nint *xfer_done)\r\n{\r\nstruct dwc2_qh *qh = chan->qh;\r\nstruct dwc2_hcd_urb *urb = qtd->urb;\r\nstruct dwc2_dma_desc *dma_desc;\r\nu32 n_bytes;\r\nint failed;\r\ndev_vdbg(hsotg->dev, "%s()\n", __func__);\r\nif (!urb)\r\nreturn -EINVAL;\r\ndma_sync_single_for_cpu(hsotg->dev,\r\nqh->desc_list_dma + (desc_num *\r\nsizeof(struct dwc2_dma_desc)),\r\nsizeof(struct dwc2_dma_desc),\r\nDMA_FROM_DEVICE);\r\ndma_desc = &qh->desc_list[desc_num];\r\nn_bytes = qh->n_bytes[desc_num];\r\ndev_vdbg(hsotg->dev,\r\n"qtd=%p dwc2_urb=%p desc_num=%d desc=%p n_bytes=%d\n",\r\nqtd, urb, desc_num, dma_desc, n_bytes);\r\nfailed = dwc2_update_non_isoc_urb_state_ddma(hsotg, chan, qtd, dma_desc,\r\nhalt_status, n_bytes,\r\nxfer_done);\r\nif (failed || (*xfer_done && urb->status != -EINPROGRESS)) {\r\ndwc2_host_complete(hsotg, qtd, urb->status);\r\ndwc2_hcd_qtd_unlink_and_free(hsotg, qtd, qh);\r\ndev_vdbg(hsotg->dev, "failed=%1x xfer_done=%1x\n",\r\nfailed, *xfer_done);\r\nreturn failed;\r\n}\r\nif (qh->ep_type == USB_ENDPOINT_XFER_CONTROL) {\r\nswitch (qtd->control_phase) {\r\ncase DWC2_CONTROL_SETUP:\r\nif (urb->length > 0)\r\nqtd->control_phase = DWC2_CONTROL_DATA;\r\nelse\r\nqtd->control_phase = DWC2_CONTROL_STATUS;\r\ndev_vdbg(hsotg->dev,\r\n" Control setup transaction done\n");\r\nbreak;\r\ncase DWC2_CONTROL_DATA:\r\nif (*xfer_done) {\r\nqtd->control_phase = DWC2_CONTROL_STATUS;\r\ndev_vdbg(hsotg->dev,\r\n" Control data transfer done\n");\r\n} else if (desc_num + 1 == qtd->n_desc) {\r\ndwc2_hcd_save_data_toggle(hsotg, chan, chnum,\r\nqtd);\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void dwc2_complete_non_isoc_xfer_ddma(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_host_chan *chan,\r\nint chnum,\r\nenum dwc2_halt_status halt_status)\r\n{\r\nstruct list_head *qtd_item, *qtd_tmp;\r\nstruct dwc2_qh *qh = chan->qh;\r\nstruct dwc2_qtd *qtd = NULL;\r\nint xfer_done;\r\nint desc_num = 0;\r\nif (chan->halt_status == DWC2_HC_XFER_URB_DEQUEUE) {\r\nlist_for_each_entry(qtd, &qh->qtd_list, qtd_list_entry)\r\nqtd->in_process = 0;\r\nreturn;\r\n}\r\nlist_for_each_safe(qtd_item, qtd_tmp, &qh->qtd_list) {\r\nint i;\r\nint qtd_desc_count;\r\nqtd = list_entry(qtd_item, struct dwc2_qtd, qtd_list_entry);\r\nxfer_done = 0;\r\nqtd_desc_count = qtd->n_desc;\r\nfor (i = 0; i < qtd_desc_count; i++) {\r\nif (dwc2_process_non_isoc_desc(hsotg, chan, chnum, qtd,\r\ndesc_num, halt_status,\r\n&xfer_done)) {\r\nqtd = NULL;\r\ngoto stop_scan;\r\n}\r\ndesc_num++;\r\n}\r\n}\r\nstop_scan:\r\nif (qh->ep_type != USB_ENDPOINT_XFER_CONTROL) {\r\nif (halt_status == DWC2_HC_XFER_STALL)\r\nqh->data_toggle = DWC2_HC_PID_DATA0;\r\nelse\r\ndwc2_hcd_save_data_toggle(hsotg, chan, chnum, NULL);\r\n}\r\nif (halt_status == DWC2_HC_XFER_COMPLETE) {\r\nif (chan->hcint & HCINTMSK_NYET) {\r\nqh->ping_state = 1;\r\n}\r\n}\r\n}\r\nvoid dwc2_hcd_complete_xfer_ddma(struct dwc2_hsotg *hsotg,\r\nstruct dwc2_host_chan *chan, int chnum,\r\nenum dwc2_halt_status halt_status)\r\n{\r\nstruct dwc2_qh *qh = chan->qh;\r\nint continue_isoc_xfer = 0;\r\nenum dwc2_transaction_type tr_type;\r\nif (chan->ep_type == USB_ENDPOINT_XFER_ISOC) {\r\ndwc2_complete_isoc_xfer_ddma(hsotg, chan, halt_status);\r\nif (halt_status != DWC2_HC_XFER_COMPLETE ||\r\nlist_empty(&qh->qtd_list)) {\r\nstruct dwc2_qtd *qtd, *qtd_tmp;\r\nlist_for_each_entry_safe(qtd, qtd_tmp,\r\n&qh->qtd_list,\r\nqtd_list_entry) {\r\ndwc2_host_complete(hsotg, qtd,\r\n-ECONNRESET);\r\ndwc2_hcd_qtd_unlink_and_free(hsotg,\r\nqtd, qh);\r\n}\r\nif (halt_status == DWC2_HC_XFER_COMPLETE)\r\ndwc2_hc_halt(hsotg, chan, halt_status);\r\ndwc2_release_channel_ddma(hsotg, qh);\r\ndwc2_hcd_qh_unlink(hsotg, qh);\r\n} else {\r\nlist_move_tail(&qh->qh_list_entry,\r\n&hsotg->periodic_sched_assigned);\r\nif (!chan->halt_status)\r\ncontinue_isoc_xfer = 1;\r\n}\r\n} else {\r\ndwc2_complete_non_isoc_xfer_ddma(hsotg, chan, chnum,\r\nhalt_status);\r\ndwc2_release_channel_ddma(hsotg, qh);\r\ndwc2_hcd_qh_unlink(hsotg, qh);\r\nif (!list_empty(&qh->qtd_list)) {\r\ndwc2_hcd_qh_add(hsotg, qh);\r\n}\r\n}\r\ntr_type = dwc2_hcd_select_transactions(hsotg);\r\nif (tr_type != DWC2_TRANSACTION_NONE || continue_isoc_xfer) {\r\nif (continue_isoc_xfer) {\r\nif (tr_type == DWC2_TRANSACTION_NONE)\r\ntr_type = DWC2_TRANSACTION_PERIODIC;\r\nelse if (tr_type == DWC2_TRANSACTION_NON_PERIODIC)\r\ntr_type = DWC2_TRANSACTION_ALL;\r\n}\r\ndwc2_hcd_queue_transactions(hsotg, tr_type);\r\n}\r\n}
