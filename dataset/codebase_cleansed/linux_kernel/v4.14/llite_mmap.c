void policy_from_vma(union ldlm_policy_data *policy,\r\nstruct vm_area_struct *vma, unsigned long addr,\r\nsize_t count)\r\n{\r\npolicy->l_extent.start = ((addr - vma->vm_start) & PAGE_MASK) +\r\n(vma->vm_pgoff << PAGE_SHIFT);\r\npolicy->l_extent.end = (policy->l_extent.start + count - 1) |\r\n~PAGE_MASK;\r\n}\r\nstruct vm_area_struct *our_vma(struct mm_struct *mm, unsigned long addr,\r\nsize_t count)\r\n{\r\nstruct vm_area_struct *vma, *ret = NULL;\r\nLASSERT(!down_write_trylock(&mm->mmap_sem));\r\nfor (vma = find_vma(mm, addr);\r\nvma && vma->vm_start < (addr + count); vma = vma->vm_next) {\r\nif (vma->vm_ops && vma->vm_ops == &ll_file_vm_ops &&\r\nvma->vm_flags & VM_SHARED) {\r\nret = vma;\r\nbreak;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic struct cl_io *\r\nll_fault_io_init(struct lu_env *env, struct vm_area_struct *vma,\r\npgoff_t index, unsigned long *ra_flags)\r\n{\r\nstruct file *file = vma->vm_file;\r\nstruct inode *inode = file_inode(file);\r\nstruct cl_io *io;\r\nstruct cl_fault_io *fio;\r\nint rc;\r\nif (ll_file_nolock(file))\r\nreturn ERR_PTR(-EOPNOTSUPP);\r\nrestart:\r\nio = vvp_env_thread_io(env);\r\nio->ci_obj = ll_i2info(inode)->lli_clob;\r\nLASSERT(io->ci_obj);\r\nfio = &io->u.ci_fault;\r\nfio->ft_index = index;\r\nfio->ft_executable = vma->vm_flags & VM_EXEC;\r\nif (ra_flags)\r\n*ra_flags = vma->vm_flags & (VM_RAND_READ | VM_SEQ_READ);\r\nvma->vm_flags &= ~VM_SEQ_READ;\r\nvma->vm_flags |= VM_RAND_READ;\r\nCDEBUG(D_MMAP, "vm_flags: %lx (%lu %d)\n", vma->vm_flags,\r\nfio->ft_index, fio->ft_executable);\r\nrc = cl_io_init(env, io, CIT_FAULT, io->ci_obj);\r\nif (rc == 0) {\r\nstruct vvp_io *vio = vvp_env_io(env);\r\nstruct ll_file_data *fd = LUSTRE_FPRIVATE(file);\r\nLASSERT(vio->vui_cl.cis_io == io);\r\nio->ci_lockreq = CILR_MANDATORY;\r\nvio->vui_fd = fd;\r\n} else {\r\nLASSERT(rc < 0);\r\ncl_io_fini(env, io);\r\nif (io->ci_need_restart)\r\ngoto restart;\r\nio = ERR_PTR(rc);\r\n}\r\nreturn io;\r\n}\r\nstatic int ll_page_mkwrite0(struct vm_area_struct *vma, struct page *vmpage,\r\nbool *retry)\r\n{\r\nstruct lu_env *env;\r\nstruct cl_io *io;\r\nstruct vvp_io *vio;\r\nint result;\r\nu16 refcheck;\r\nsigset_t set;\r\nstruct inode *inode;\r\nstruct ll_inode_info *lli;\r\nenv = cl_env_get(&refcheck);\r\nif (IS_ERR(env))\r\nreturn PTR_ERR(env);\r\nio = ll_fault_io_init(env, vma, vmpage->index, NULL);\r\nif (IS_ERR(io)) {\r\nresult = PTR_ERR(io);\r\ngoto out;\r\n}\r\nresult = io->ci_result;\r\nif (result < 0)\r\ngoto out_io;\r\nio->u.ci_fault.ft_mkwrite = 1;\r\nio->u.ci_fault.ft_writable = 1;\r\nvio = vvp_env_io(env);\r\nvio->u.fault.ft_vma = vma;\r\nvio->u.fault.ft_vmpage = vmpage;\r\nset = cfs_block_sigsinv(sigmask(SIGKILL) | sigmask(SIGTERM));\r\ninode = vvp_object_inode(io->ci_obj);\r\nlli = ll_i2info(inode);\r\nresult = cl_io_loop(env, io);\r\ncfs_restore_sigs(set);\r\nif (result == 0) {\r\nstruct inode *inode = file_inode(vma->vm_file);\r\nstruct ll_inode_info *lli = ll_i2info(inode);\r\nlock_page(vmpage);\r\nif (!vmpage->mapping) {\r\nunlock_page(vmpage);\r\nif (result == 0)\r\nresult = -ENODATA;\r\n} else if (!PageDirty(vmpage)) {\r\nunlock_page(vmpage);\r\nCDEBUG(D_MMAP, "Race on page_mkwrite %p/%lu, page has been written out, retry.\n",\r\nvmpage, vmpage->index);\r\n*retry = true;\r\nresult = -EAGAIN;\r\n}\r\nif (!result)\r\nset_bit(LLIF_DATA_MODIFIED, &lli->lli_flags);\r\n}\r\nout_io:\r\ncl_io_fini(env, io);\r\nout:\r\ncl_env_put(env, &refcheck);\r\nCDEBUG(D_MMAP, "%s mkwrite with %d\n", current->comm, result);\r\nLASSERT(ergo(result == 0, PageLocked(vmpage)));\r\nreturn result;\r\n}\r\nstatic inline int to_fault_error(int result)\r\n{\r\nswitch (result) {\r\ncase 0:\r\nresult = VM_FAULT_LOCKED;\r\nbreak;\r\ncase -EFAULT:\r\nresult = VM_FAULT_NOPAGE;\r\nbreak;\r\ncase -ENOMEM:\r\nresult = VM_FAULT_OOM;\r\nbreak;\r\ndefault:\r\nresult = VM_FAULT_SIGBUS;\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic int ll_fault0(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct lu_env *env;\r\nstruct cl_io *io;\r\nstruct vvp_io *vio = NULL;\r\nstruct page *vmpage;\r\nunsigned long ra_flags;\r\nint result = 0;\r\nint fault_ret = 0;\r\nu16 refcheck;\r\nenv = cl_env_get(&refcheck);\r\nif (IS_ERR(env))\r\nreturn PTR_ERR(env);\r\nio = ll_fault_io_init(env, vma, vmf->pgoff, &ra_flags);\r\nif (IS_ERR(io)) {\r\nresult = to_fault_error(PTR_ERR(io));\r\ngoto out;\r\n}\r\nresult = io->ci_result;\r\nif (result == 0) {\r\nvio = vvp_env_io(env);\r\nvio->u.fault.ft_vma = vma;\r\nvio->u.fault.ft_vmpage = NULL;\r\nvio->u.fault.ft_vmf = vmf;\r\nvio->u.fault.ft_flags = 0;\r\nvio->u.fault.ft_flags_valid = false;\r\nll_cl_add(vma->vm_file, env, io);\r\nresult = cl_io_loop(env, io);\r\nll_cl_remove(vma->vm_file, env);\r\nif (vio->u.fault.ft_flags_valid)\r\nfault_ret = vio->u.fault.ft_flags;\r\nvmpage = vio->u.fault.ft_vmpage;\r\nif (result != 0 && vmpage) {\r\nput_page(vmpage);\r\nvmf->page = NULL;\r\n}\r\n}\r\ncl_io_fini(env, io);\r\nvma->vm_flags |= ra_flags;\r\nout:\r\ncl_env_put(env, &refcheck);\r\nif (result != 0 && !(fault_ret & VM_FAULT_RETRY))\r\nfault_ret |= to_fault_error(result);\r\nCDEBUG(D_MMAP, "%s fault %d/%d\n", current->comm, fault_ret, result);\r\nreturn fault_ret;\r\n}\r\nstatic int ll_fault(struct vm_fault *vmf)\r\n{\r\nint count = 0;\r\nbool printed = false;\r\nint result;\r\nsigset_t set;\r\nset = cfs_block_sigsinv(sigmask(SIGKILL) | sigmask(SIGTERM));\r\nrestart:\r\nresult = ll_fault0(vmf->vma, vmf);\r\nLASSERT(!(result & VM_FAULT_LOCKED));\r\nif (result == 0) {\r\nstruct page *vmpage = vmf->page;\r\nlock_page(vmpage);\r\nif (unlikely(!vmpage->mapping)) {\r\nunlock_page(vmpage);\r\nput_page(vmpage);\r\nvmf->page = NULL;\r\nif (!printed && ++count > 16) {\r\nCWARN("the page is under heavy contention, maybe your app(%s) needs revising :-)\n",\r\ncurrent->comm);\r\nprinted = true;\r\n}\r\ngoto restart;\r\n}\r\nresult = VM_FAULT_LOCKED;\r\n}\r\ncfs_restore_sigs(set);\r\nreturn result;\r\n}\r\nstatic int ll_page_mkwrite(struct vm_fault *vmf)\r\n{\r\nstruct vm_area_struct *vma = vmf->vma;\r\nint count = 0;\r\nbool printed = false;\r\nbool retry;\r\nint result;\r\nfile_update_time(vma->vm_file);\r\ndo {\r\nretry = false;\r\nresult = ll_page_mkwrite0(vma, vmf->page, &retry);\r\nif (!printed && ++count > 16) {\r\nconst struct dentry *de = vma->vm_file->f_path.dentry;\r\nCWARN("app(%s): the page %lu of file " DFID " is under heavy contention\n",\r\ncurrent->comm, vmf->pgoff,\r\nPFID(ll_inode2fid(de->d_inode)));\r\nprinted = true;\r\n}\r\n} while (retry);\r\nswitch (result) {\r\ncase 0:\r\nLASSERT(PageLocked(vmf->page));\r\nresult = VM_FAULT_LOCKED;\r\nbreak;\r\ncase -ENODATA:\r\ncase -EAGAIN:\r\ncase -EFAULT:\r\nresult = VM_FAULT_NOPAGE;\r\nbreak;\r\ncase -ENOMEM:\r\nresult = VM_FAULT_OOM;\r\nbreak;\r\ndefault:\r\nresult = VM_FAULT_SIGBUS;\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic void ll_vm_open(struct vm_area_struct *vma)\r\n{\r\nstruct inode *inode = file_inode(vma->vm_file);\r\nstruct vvp_object *vob = cl_inode2vvp(inode);\r\nLASSERT(atomic_read(&vob->vob_mmap_cnt) >= 0);\r\natomic_inc(&vob->vob_mmap_cnt);\r\n}\r\nstatic void ll_vm_close(struct vm_area_struct *vma)\r\n{\r\nstruct inode *inode = file_inode(vma->vm_file);\r\nstruct vvp_object *vob = cl_inode2vvp(inode);\r\natomic_dec(&vob->vob_mmap_cnt);\r\nLASSERT(atomic_read(&vob->vob_mmap_cnt) >= 0);\r\n}\r\nint ll_teardown_mmaps(struct address_space *mapping, __u64 first, __u64 last)\r\n{\r\nint rc = -ENOENT;\r\nLASSERTF(last > first, "last %llu first %llu\n", last, first);\r\nif (mapping_mapped(mapping)) {\r\nrc = 0;\r\nunmap_mapping_range(mapping, first + PAGE_SIZE - 1,\r\nlast - first + 1, 0);\r\n}\r\nreturn rc;\r\n}\r\nint ll_file_mmap(struct file *file, struct vm_area_struct *vma)\r\n{\r\nstruct inode *inode = file_inode(file);\r\nint rc;\r\nif (ll_file_nolock(file))\r\nreturn -EOPNOTSUPP;\r\nll_stats_ops_tally(ll_i2sbi(inode), LPROC_LL_MAP, 1);\r\nrc = generic_file_mmap(file, vma);\r\nif (rc == 0) {\r\nvma->vm_ops = &ll_file_vm_ops;\r\nvma->vm_ops->open(vma);\r\nrc = ll_glimpse_size(inode);\r\n}\r\nreturn rc;\r\n}
