static inline u8 byte(const u32 x, const unsigned n)\r\n{\r\nreturn x >> (n << 3);\r\n}\r\nint crypto_aes_expand_key(struct crypto_aes_ctx *ctx, const u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nu32 i, t, u, v, w, j;\r\nif (key_len != AES_KEYSIZE_128 && key_len != AES_KEYSIZE_192 &&\r\nkey_len != AES_KEYSIZE_256)\r\nreturn -EINVAL;\r\nctx->key_length = key_len;\r\nctx->key_enc[0] = get_unaligned_le32(in_key);\r\nctx->key_enc[1] = get_unaligned_le32(in_key + 4);\r\nctx->key_enc[2] = get_unaligned_le32(in_key + 8);\r\nctx->key_enc[3] = get_unaligned_le32(in_key + 12);\r\nctx->key_dec[key_len + 24] = ctx->key_enc[0];\r\nctx->key_dec[key_len + 25] = ctx->key_enc[1];\r\nctx->key_dec[key_len + 26] = ctx->key_enc[2];\r\nctx->key_dec[key_len + 27] = ctx->key_enc[3];\r\nswitch (key_len) {\r\ncase AES_KEYSIZE_128:\r\nt = ctx->key_enc[3];\r\nfor (i = 0; i < 10; ++i)\r\nloop4(i);\r\nbreak;\r\ncase AES_KEYSIZE_192:\r\nctx->key_enc[4] = get_unaligned_le32(in_key + 16);\r\nt = ctx->key_enc[5] = get_unaligned_le32(in_key + 20);\r\nfor (i = 0; i < 8; ++i)\r\nloop6(i);\r\nbreak;\r\ncase AES_KEYSIZE_256:\r\nctx->key_enc[4] = get_unaligned_le32(in_key + 16);\r\nctx->key_enc[5] = get_unaligned_le32(in_key + 20);\r\nctx->key_enc[6] = get_unaligned_le32(in_key + 24);\r\nt = ctx->key_enc[7] = get_unaligned_le32(in_key + 28);\r\nfor (i = 0; i < 6; ++i)\r\nloop8(i);\r\nloop8tophalf(i);\r\nbreak;\r\n}\r\nctx->key_dec[0] = ctx->key_enc[key_len + 24];\r\nctx->key_dec[1] = ctx->key_enc[key_len + 25];\r\nctx->key_dec[2] = ctx->key_enc[key_len + 26];\r\nctx->key_dec[3] = ctx->key_enc[key_len + 27];\r\nfor (i = 4; i < key_len + 24; ++i) {\r\nj = key_len + 24 - (i & ~3) + (i & 3);\r\nimix_col(ctx->key_dec[j], ctx->key_enc[i]);\r\n}\r\nreturn 0;\r\n}\r\nint crypto_aes_set_key(struct crypto_tfm *tfm, const u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nstruct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\r\nu32 *flags = &tfm->crt_flags;\r\nint ret;\r\nret = crypto_aes_expand_key(ctx, in_key, key_len);\r\nif (!ret)\r\nreturn 0;\r\n*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nstatic void aes_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\r\n{\r\nconst struct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\r\nu32 b0[4], b1[4];\r\nconst u32 *kp = ctx->key_enc + 4;\r\nconst int key_len = ctx->key_length;\r\nb0[0] = ctx->key_enc[0] ^ get_unaligned_le32(in);\r\nb0[1] = ctx->key_enc[1] ^ get_unaligned_le32(in + 4);\r\nb0[2] = ctx->key_enc[2] ^ get_unaligned_le32(in + 8);\r\nb0[3] = ctx->key_enc[3] ^ get_unaligned_le32(in + 12);\r\nif (key_len > 24) {\r\nf_nround(b1, b0, kp);\r\nf_nround(b0, b1, kp);\r\n}\r\nif (key_len > 16) {\r\nf_nround(b1, b0, kp);\r\nf_nround(b0, b1, kp);\r\n}\r\nf_nround(b1, b0, kp);\r\nf_nround(b0, b1, kp);\r\nf_nround(b1, b0, kp);\r\nf_nround(b0, b1, kp);\r\nf_nround(b1, b0, kp);\r\nf_nround(b0, b1, kp);\r\nf_nround(b1, b0, kp);\r\nf_nround(b0, b1, kp);\r\nf_nround(b1, b0, kp);\r\nf_lround(b0, b1, kp);\r\nput_unaligned_le32(b0[0], out);\r\nput_unaligned_le32(b0[1], out + 4);\r\nput_unaligned_le32(b0[2], out + 8);\r\nput_unaligned_le32(b0[3], out + 12);\r\n}\r\nstatic void aes_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\r\n{\r\nconst struct crypto_aes_ctx *ctx = crypto_tfm_ctx(tfm);\r\nu32 b0[4], b1[4];\r\nconst int key_len = ctx->key_length;\r\nconst u32 *kp = ctx->key_dec + 4;\r\nb0[0] = ctx->key_dec[0] ^ get_unaligned_le32(in);\r\nb0[1] = ctx->key_dec[1] ^ get_unaligned_le32(in + 4);\r\nb0[2] = ctx->key_dec[2] ^ get_unaligned_le32(in + 8);\r\nb0[3] = ctx->key_dec[3] ^ get_unaligned_le32(in + 12);\r\nif (key_len > 24) {\r\ni_nround(b1, b0, kp);\r\ni_nround(b0, b1, kp);\r\n}\r\nif (key_len > 16) {\r\ni_nround(b1, b0, kp);\r\ni_nround(b0, b1, kp);\r\n}\r\ni_nround(b1, b0, kp);\r\ni_nround(b0, b1, kp);\r\ni_nround(b1, b0, kp);\r\ni_nround(b0, b1, kp);\r\ni_nround(b1, b0, kp);\r\ni_nround(b0, b1, kp);\r\ni_nround(b1, b0, kp);\r\ni_nround(b0, b1, kp);\r\ni_nround(b1, b0, kp);\r\ni_lround(b0, b1, kp);\r\nput_unaligned_le32(b0[0], out);\r\nput_unaligned_le32(b0[1], out + 4);\r\nput_unaligned_le32(b0[2], out + 8);\r\nput_unaligned_le32(b0[3], out + 12);\r\n}\r\nstatic int __init aes_init(void)\r\n{\r\nreturn crypto_register_alg(&aes_alg);\r\n}\r\nstatic void __exit aes_fini(void)\r\n{\r\ncrypto_unregister_alg(&aes_alg);\r\n}
