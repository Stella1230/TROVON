static u32 efx_ef10_filter_get_unsafe_id(u32 filter_id)\r\n{\r\nWARN_ON_ONCE(filter_id == EFX_EF10_FILTER_ID_INVALID);\r\nreturn filter_id & (HUNT_FILTER_TBL_ROWS - 1);\r\n}\r\nstatic unsigned int efx_ef10_filter_get_unsafe_pri(u32 filter_id)\r\n{\r\nreturn filter_id / (HUNT_FILTER_TBL_ROWS * 2);\r\n}\r\nstatic u32 efx_ef10_make_filter_id(unsigned int pri, u16 idx)\r\n{\r\nreturn pri * HUNT_FILTER_TBL_ROWS * 2 + idx;\r\n}\r\nstatic int efx_ef10_get_warm_boot_count(struct efx_nic *efx)\r\n{\r\nefx_dword_t reg;\r\nefx_readd(efx, &reg, ER_DZ_BIU_MC_SFT_STATUS);\r\nreturn EFX_DWORD_FIELD(reg, EFX_WORD_1) == 0xb007 ?\r\nEFX_DWORD_FIELD(reg, EFX_WORD_0) : -EIO;\r\n}\r\nstatic unsigned int efx_ef10_mem_map_size(struct efx_nic *efx)\r\n{\r\nint bar;\r\nbar = efx->type->mem_bar;\r\nreturn resource_size(&efx->pci_dev->resource[bar]);\r\n}\r\nstatic bool efx_ef10_is_vf(struct efx_nic *efx)\r\n{\r\nreturn efx->type->is_vf;\r\n}\r\nstatic int efx_ef10_get_pf_index(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_FUNCTION_INFO_OUT_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t outlen;\r\nint rc;\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_FUNCTION_INFO, NULL, 0, outbuf,\r\nsizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < sizeof(outbuf))\r\nreturn -EIO;\r\nnic_data->pf_index = MCDI_DWORD(outbuf, GET_FUNCTION_INFO_OUT_PF);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_get_vf_index(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_FUNCTION_INFO_OUT_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t outlen;\r\nint rc;\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_FUNCTION_INFO, NULL, 0, outbuf,\r\nsizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < sizeof(outbuf))\r\nreturn -EIO;\r\nnic_data->vf_index = MCDI_DWORD(outbuf, GET_FUNCTION_INFO_OUT_VF);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_init_datapath_caps(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_CAPABILITIES_V2_OUT_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t outlen;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_GET_CAPABILITIES_IN_LEN != 0);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_CAPABILITIES, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_GET_CAPABILITIES_OUT_LEN) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"unable to read datapath firmware capabilities\n");\r\nreturn -EIO;\r\n}\r\nnic_data->datapath_caps =\r\nMCDI_DWORD(outbuf, GET_CAPABILITIES_OUT_FLAGS1);\r\nif (outlen >= MC_CMD_GET_CAPABILITIES_V2_OUT_LEN) {\r\nnic_data->datapath_caps2 = MCDI_DWORD(outbuf,\r\nGET_CAPABILITIES_V2_OUT_FLAGS2);\r\nnic_data->piobuf_size = MCDI_WORD(outbuf,\r\nGET_CAPABILITIES_V2_OUT_SIZE_PIO_BUFF);\r\n} else {\r\nnic_data->datapath_caps2 = 0;\r\nnic_data->piobuf_size = ER_DZ_TX_PIOBUF_SIZE;\r\n}\r\nnic_data->rx_dpcpu_fw_id =\r\nMCDI_WORD(outbuf, GET_CAPABILITIES_OUT_RX_DPCPU_FW_ID);\r\nnic_data->tx_dpcpu_fw_id =\r\nMCDI_WORD(outbuf, GET_CAPABILITIES_OUT_TX_DPCPU_FW_ID);\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_RX_PREFIX_LEN_14_LBN))) {\r\nnetif_err(efx, probe, efx->net_dev,\r\n"current firmware does not support an RX prefix\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_get_sysclk_freq(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_CLOCK_OUT_LEN);\r\nint rc;\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_CLOCK, NULL, 0,\r\noutbuf, sizeof(outbuf), NULL);\r\nif (rc)\r\nreturn rc;\r\nrc = MCDI_DWORD(outbuf, GET_CLOCK_OUT_SYS_FREQ);\r\nreturn rc > 0 ? rc : -ERANGE;\r\n}\r\nstatic int efx_ef10_get_timer_workarounds(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nunsigned int implemented;\r\nunsigned int enabled;\r\nint rc;\r\nnic_data->workaround_35388 = false;\r\nnic_data->workaround_61265 = false;\r\nrc = efx_mcdi_get_workarounds(efx, &implemented, &enabled);\r\nif (rc == -ENOSYS) {\r\nrc = 0;\r\n} else if (rc == 0) {\r\nif (enabled & MC_CMD_GET_WORKAROUNDS_OUT_BUG61265)\r\nnic_data->workaround_61265 = true;\r\nif (enabled & MC_CMD_GET_WORKAROUNDS_OUT_BUG35388) {\r\nnic_data->workaround_35388 = true;\r\n} else if (implemented & MC_CMD_GET_WORKAROUNDS_OUT_BUG35388) {\r\nrc = efx_mcdi_set_workaround(efx,\r\nMC_CMD_WORKAROUND_BUG35388,\r\ntrue, NULL);\r\nif (rc == 0)\r\nnic_data->workaround_35388 = true;\r\nrc = 0;\r\n}\r\n}\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"workaround for bug 35388 is %sabled\n",\r\nnic_data->workaround_35388 ? "en" : "dis");\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"workaround for bug 61265 is %sabled\n",\r\nnic_data->workaround_61265 ? "en" : "dis");\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_process_timer_config(struct efx_nic *efx,\r\nconst efx_dword_t *data)\r\n{\r\nunsigned int max_count;\r\nif (EFX_EF10_WORKAROUND_61265(efx)) {\r\nefx->timer_quantum_ns = MCDI_DWORD(data,\r\nGET_EVQ_TMR_PROPERTIES_OUT_MCDI_TMR_STEP_NS);\r\nefx->timer_max_ns = MCDI_DWORD(data,\r\nGET_EVQ_TMR_PROPERTIES_OUT_MCDI_TMR_MAX_NS);\r\n} else if (EFX_EF10_WORKAROUND_35388(efx)) {\r\nefx->timer_quantum_ns = MCDI_DWORD(data,\r\nGET_EVQ_TMR_PROPERTIES_OUT_BUG35388_TMR_NS_PER_COUNT);\r\nmax_count = MCDI_DWORD(data,\r\nGET_EVQ_TMR_PROPERTIES_OUT_BUG35388_TMR_MAX_COUNT);\r\nefx->timer_max_ns = max_count * efx->timer_quantum_ns;\r\n} else {\r\nefx->timer_quantum_ns = MCDI_DWORD(data,\r\nGET_EVQ_TMR_PROPERTIES_OUT_TMR_REG_NS_PER_COUNT);\r\nmax_count = MCDI_DWORD(data,\r\nGET_EVQ_TMR_PROPERTIES_OUT_TMR_REG_MAX_COUNT);\r\nefx->timer_max_ns = max_count * efx->timer_quantum_ns;\r\n}\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"got timer properties from MC: quantum %u ns; max %u ns\n",\r\nefx->timer_quantum_ns, efx->timer_max_ns);\r\n}\r\nstatic int efx_ef10_get_timer_config(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_EVQ_TMR_PROPERTIES_OUT_LEN);\r\nint rc;\r\nrc = efx_ef10_get_timer_workarounds(efx);\r\nif (rc)\r\nreturn rc;\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_GET_EVQ_TMR_PROPERTIES, NULL, 0,\r\noutbuf, sizeof(outbuf), NULL);\r\nif (rc == 0) {\r\nefx_ef10_process_timer_config(efx, outbuf);\r\n} else if (rc == -ENOSYS || rc == -EPERM) {\r\nunsigned int quantum;\r\nrc = efx_ef10_get_sysclk_freq(efx);\r\nif (rc < 0)\r\nreturn rc;\r\nquantum = 1536000 / rc;\r\nefx->timer_quantum_ns = quantum;\r\nefx->timer_max_ns = efx->type->timer_period_max * quantum;\r\nrc = 0;\r\n} else {\r\nefx_mcdi_display_error(efx, MC_CMD_GET_EVQ_TMR_PROPERTIES,\r\nMC_CMD_GET_EVQ_TMR_PROPERTIES_OUT_LEN,\r\nNULL, 0, rc);\r\n}\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_get_mac_address_pf(struct efx_nic *efx, u8 *mac_address)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_MAC_ADDRESSES_OUT_LEN);\r\nsize_t outlen;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_GET_MAC_ADDRESSES_IN_LEN != 0);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_MAC_ADDRESSES, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_GET_MAC_ADDRESSES_OUT_LEN)\r\nreturn -EIO;\r\nether_addr_copy(mac_address,\r\nMCDI_PTR(outbuf, GET_MAC_ADDRESSES_OUT_MAC_ADDR_BASE));\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_get_mac_address_vf(struct efx_nic *efx, u8 *mac_address)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_VPORT_GET_MAC_ADDRESSES_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_VPORT_GET_MAC_ADDRESSES_OUT_LENMAX);\r\nsize_t outlen;\r\nint num_addrs, rc;\r\nMCDI_SET_DWORD(inbuf, VPORT_GET_MAC_ADDRESSES_IN_VPORT_ID,\r\nEVB_PORT_ID_ASSIGNED);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_VPORT_GET_MAC_ADDRESSES, inbuf,\r\nsizeof(inbuf), outbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_VPORT_GET_MAC_ADDRESSES_OUT_LENMIN)\r\nreturn -EIO;\r\nnum_addrs = MCDI_DWORD(outbuf,\r\nVPORT_GET_MAC_ADDRESSES_OUT_MACADDR_COUNT);\r\nWARN_ON(num_addrs != 1);\r\nether_addr_copy(mac_address,\r\nMCDI_PTR(outbuf, VPORT_GET_MAC_ADDRESSES_OUT_MACADDR));\r\nreturn 0;\r\n}\r\nstatic ssize_t efx_ef10_show_link_control_flag(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct efx_nic *efx = pci_get_drvdata(to_pci_dev(dev));\r\nreturn sprintf(buf, "%d\n",\r\n((efx->mcdi->fn_flags) &\r\n(1 << MC_CMD_DRV_ATTACH_EXT_OUT_FLAG_LINKCTRL))\r\n? 1 : 0);\r\n}\r\nstatic ssize_t efx_ef10_show_primary_flag(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct efx_nic *efx = pci_get_drvdata(to_pci_dev(dev));\r\nreturn sprintf(buf, "%d\n",\r\n((efx->mcdi->fn_flags) &\r\n(1 << MC_CMD_DRV_ATTACH_EXT_OUT_FLAG_PRIMARY))\r\n? 1 : 0);\r\n}\r\nstatic struct efx_ef10_vlan *efx_ef10_find_vlan(struct efx_nic *efx, u16 vid)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_ef10_vlan *vlan;\r\nWARN_ON(!mutex_is_locked(&nic_data->vlan_lock));\r\nlist_for_each_entry(vlan, &nic_data->vlan_list, list) {\r\nif (vlan->vid == vid)\r\nreturn vlan;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int efx_ef10_add_vlan(struct efx_nic *efx, u16 vid)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_ef10_vlan *vlan;\r\nint rc;\r\nmutex_lock(&nic_data->vlan_lock);\r\nvlan = efx_ef10_find_vlan(efx, vid);\r\nif (vlan) {\r\nif (vid == 0)\r\ngoto done_unlock;\r\nnetif_warn(efx, drv, efx->net_dev,\r\n"VLAN %u already added\n", vid);\r\nrc = -EALREADY;\r\ngoto fail_exist;\r\n}\r\nrc = -ENOMEM;\r\nvlan = kzalloc(sizeof(*vlan), GFP_KERNEL);\r\nif (!vlan)\r\ngoto fail_alloc;\r\nvlan->vid = vid;\r\nlist_add_tail(&vlan->list, &nic_data->vlan_list);\r\nif (efx->filter_state) {\r\nmutex_lock(&efx->mac_lock);\r\ndown_write(&efx->filter_sem);\r\nrc = efx_ef10_filter_add_vlan(efx, vlan->vid);\r\nup_write(&efx->filter_sem);\r\nmutex_unlock(&efx->mac_lock);\r\nif (rc)\r\ngoto fail_filter_add_vlan;\r\n}\r\ndone_unlock:\r\nmutex_unlock(&nic_data->vlan_lock);\r\nreturn 0;\r\nfail_filter_add_vlan:\r\nlist_del(&vlan->list);\r\nkfree(vlan);\r\nfail_alloc:\r\nfail_exist:\r\nmutex_unlock(&nic_data->vlan_lock);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_del_vlan_internal(struct efx_nic *efx,\r\nstruct efx_ef10_vlan *vlan)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nWARN_ON(!mutex_is_locked(&nic_data->vlan_lock));\r\nif (efx->filter_state) {\r\ndown_write(&efx->filter_sem);\r\nefx_ef10_filter_del_vlan(efx, vlan->vid);\r\nup_write(&efx->filter_sem);\r\n}\r\nlist_del(&vlan->list);\r\nkfree(vlan);\r\n}\r\nstatic int efx_ef10_del_vlan(struct efx_nic *efx, u16 vid)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_ef10_vlan *vlan;\r\nint rc = 0;\r\nif (vid == 0)\r\nreturn 0;\r\nmutex_lock(&nic_data->vlan_lock);\r\nvlan = efx_ef10_find_vlan(efx, vid);\r\nif (!vlan) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"VLAN %u to be deleted not found\n", vid);\r\nrc = -ENOENT;\r\n} else {\r\nefx_ef10_del_vlan_internal(efx, vlan);\r\n}\r\nmutex_unlock(&nic_data->vlan_lock);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_cleanup_vlans(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_ef10_vlan *vlan, *next_vlan;\r\nmutex_lock(&nic_data->vlan_lock);\r\nlist_for_each_entry_safe(vlan, next_vlan, &nic_data->vlan_list, list)\r\nefx_ef10_del_vlan_internal(efx, vlan);\r\nmutex_unlock(&nic_data->vlan_lock);\r\n}\r\nstatic int efx_ef10_probe(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data;\r\nint i, rc;\r\nefx->max_channels = min_t(unsigned int,\r\nEFX_MAX_CHANNELS,\r\nefx_ef10_mem_map_size(efx) /\r\n(EFX_VI_PAGE_SIZE * EFX_TXQ_TYPES));\r\nefx->max_tx_channels = efx->max_channels;\r\nif (WARN_ON(efx->max_channels == 0))\r\nreturn -EIO;\r\nnic_data = kzalloc(sizeof(*nic_data), GFP_KERNEL);\r\nif (!nic_data)\r\nreturn -ENOMEM;\r\nefx->nic_data = nic_data;\r\nBUILD_BUG_ON(MCDI_CTL_SDU_LEN_MAX_V2 % 4);\r\nrc = efx_nic_alloc_buffer(efx, &nic_data->mcdi_buf,\r\n8 + MCDI_CTL_SDU_LEN_MAX_V2, GFP_KERNEL);\r\nif (rc)\r\ngoto fail1;\r\ni = 0;\r\nfor (;;) {\r\nrc = efx_ef10_get_warm_boot_count(efx);\r\nif (rc >= 0)\r\nbreak;\r\nif (++i == 5)\r\ngoto fail2;\r\nssleep(1);\r\n}\r\nnic_data->warm_boot_count = rc;\r\nnic_data->rx_rss_context = EFX_EF10_RSS_CONTEXT_INVALID;\r\nnic_data->vport_id = EVB_PORT_ID_ASSIGNED;\r\n_efx_writed(efx, cpu_to_le32(1), ER_DZ_MC_DB_HWRD);\r\nrc = efx_mcdi_init(efx);\r\nif (rc)\r\ngoto fail2;\r\nmutex_init(&nic_data->udp_tunnels_lock);\r\nrc = efx_mcdi_reset(efx, RESET_TYPE_ALL);\r\nif (rc)\r\ngoto fail3;\r\nrc = efx_mcdi_log_ctrl(efx, true, false, 0);\r\nif (rc)\r\ngoto fail3;\r\nrc = device_create_file(&efx->pci_dev->dev,\r\n&dev_attr_link_control_flag);\r\nif (rc)\r\ngoto fail3;\r\nrc = device_create_file(&efx->pci_dev->dev, &dev_attr_primary_flag);\r\nif (rc)\r\ngoto fail4;\r\nrc = efx_ef10_get_pf_index(efx);\r\nif (rc)\r\ngoto fail5;\r\nrc = efx_ef10_init_datapath_caps(efx);\r\nif (rc < 0)\r\ngoto fail5;\r\nefx->rx_packet_len_offset =\r\nES_DZ_RX_PREFIX_PKTLEN_OFST - ES_DZ_RX_PREFIX_SIZE;\r\nrc = efx_mcdi_port_get_number(efx);\r\nif (rc < 0)\r\ngoto fail5;\r\nefx->port_num = rc;\r\nrc = efx->type->get_mac_address(efx, efx->net_dev->perm_addr);\r\nif (rc)\r\ngoto fail5;\r\nrc = efx_ef10_get_timer_config(efx);\r\nif (rc < 0)\r\ngoto fail5;\r\nrc = efx_mcdi_mon_probe(efx);\r\nif (rc && rc != -EPERM)\r\ngoto fail5;\r\nefx_ptp_probe(efx, NULL);\r\n#ifdef CONFIG_SFC_SRIOV\r\nif ((efx->pci_dev->physfn) && (!efx->pci_dev->is_physfn)) {\r\nstruct pci_dev *pci_dev_pf = efx->pci_dev->physfn;\r\nstruct efx_nic *efx_pf = pci_get_drvdata(pci_dev_pf);\r\nefx_pf->type->get_mac_address(efx_pf, nic_data->port_id);\r\n} else\r\n#endif\r\nether_addr_copy(nic_data->port_id, efx->net_dev->perm_addr);\r\nINIT_LIST_HEAD(&nic_data->vlan_list);\r\nmutex_init(&nic_data->vlan_lock);\r\nrc = efx_ef10_add_vlan(efx, EFX_FILTER_VID_UNSPEC);\r\nif (rc)\r\ngoto fail_add_vid_unspec;\r\nrc = efx_ef10_add_vlan(efx, 0);\r\nif (rc)\r\ngoto fail_add_vid_0;\r\nreturn 0;\r\nfail_add_vid_0:\r\nefx_ef10_cleanup_vlans(efx);\r\nfail_add_vid_unspec:\r\nmutex_destroy(&nic_data->vlan_lock);\r\nefx_ptp_remove(efx);\r\nefx_mcdi_mon_remove(efx);\r\nfail5:\r\ndevice_remove_file(&efx->pci_dev->dev, &dev_attr_primary_flag);\r\nfail4:\r\ndevice_remove_file(&efx->pci_dev->dev, &dev_attr_link_control_flag);\r\nfail3:\r\nefx_mcdi_detach(efx);\r\nmutex_lock(&nic_data->udp_tunnels_lock);\r\nmemset(nic_data->udp_tunnels, 0, sizeof(nic_data->udp_tunnels));\r\n(void)efx_ef10_set_udp_tnl_ports(efx, true);\r\nmutex_unlock(&nic_data->udp_tunnels_lock);\r\nmutex_destroy(&nic_data->udp_tunnels_lock);\r\nefx_mcdi_fini(efx);\r\nfail2:\r\nefx_nic_free_buffer(efx, &nic_data->mcdi_buf);\r\nfail1:\r\nkfree(nic_data);\r\nefx->nic_data = NULL;\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_free_vis(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF_ERR(outbuf);\r\nsize_t outlen;\r\nint rc = efx_mcdi_rpc_quiet(efx, MC_CMD_FREE_VIS, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc == -EALREADY)\r\nrc = 0;\r\nif (rc)\r\nefx_mcdi_display_error(efx, MC_CMD_FREE_VIS, 0, outbuf, outlen,\r\nrc);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_free_piobufs(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FREE_PIOBUF_IN_LEN);\r\nunsigned int i;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_FREE_PIOBUF_OUT_LEN != 0);\r\nfor (i = 0; i < nic_data->n_piobufs; i++) {\r\nMCDI_SET_DWORD(inbuf, FREE_PIOBUF_IN_PIOBUF_HANDLE,\r\nnic_data->piobuf_handle[i]);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FREE_PIOBUF, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nWARN_ON(rc);\r\n}\r\nnic_data->n_piobufs = 0;\r\n}\r\nstatic int efx_ef10_alloc_piobufs(struct efx_nic *efx, unsigned int n)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_ALLOC_PIOBUF_OUT_LEN);\r\nunsigned int i;\r\nsize_t outlen;\r\nint rc = 0;\r\nBUILD_BUG_ON(MC_CMD_ALLOC_PIOBUF_IN_LEN != 0);\r\nfor (i = 0; i < n; i++) {\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_ALLOC_PIOBUF, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc) {\r\nif (!(efx_ef10_is_vf(efx) && rc == -ENOSPC))\r\nefx_mcdi_display_error(efx, MC_CMD_ALLOC_PIOBUF,\r\n0, outbuf, outlen, rc);\r\nbreak;\r\n}\r\nif (outlen < MC_CMD_ALLOC_PIOBUF_OUT_LEN) {\r\nrc = -EIO;\r\nbreak;\r\n}\r\nnic_data->piobuf_handle[i] =\r\nMCDI_DWORD(outbuf, ALLOC_PIOBUF_OUT_PIOBUF_HANDLE);\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"allocated PIO buffer %u handle %x\n", i,\r\nnic_data->piobuf_handle[i]);\r\n}\r\nnic_data->n_piobufs = i;\r\nif (rc)\r\nefx_ef10_free_piobufs(efx);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_link_piobufs(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_LINK_PIOBUF_IN_LEN);\r\nstruct efx_channel *channel;\r\nstruct efx_tx_queue *tx_queue;\r\nunsigned int offset, index;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_LINK_PIOBUF_OUT_LEN != 0);\r\nBUILD_BUG_ON(MC_CMD_UNLINK_PIOBUF_OUT_LEN != 0);\r\nfor (index = 0; index < nic_data->n_piobufs; ++index) {\r\nMCDI_SET_DWORD(inbuf, LINK_PIOBUF_IN_PIOBUF_HANDLE,\r\nnic_data->piobuf_handle[index]);\r\nMCDI_SET_DWORD(inbuf, LINK_PIOBUF_IN_TXQ_INSTANCE,\r\nnic_data->pio_write_vi_base + index);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_LINK_PIOBUF,\r\ninbuf, MC_CMD_LINK_PIOBUF_IN_LEN,\r\nNULL, 0, NULL);\r\nif (rc) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"failed to link VI %u to PIO buffer %u (%d)\n",\r\nnic_data->pio_write_vi_base + index, index,\r\nrc);\r\ngoto fail;\r\n}\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"linked VI %u to PIO buffer %u\n",\r\nnic_data->pio_write_vi_base + index, index);\r\n}\r\nefx_for_each_channel(channel, efx) {\r\nefx_for_each_channel_tx_queue(tx_queue, channel) {\r\noffset = ((efx->tx_channel_offset + efx->n_tx_channels -\r\ntx_queue->channel->channel - 1) *\r\nefx_piobuf_size);\r\nindex = offset / nic_data->piobuf_size;\r\noffset = offset % nic_data->piobuf_size;\r\nif (tx_queue->queue == nic_data->pio_write_vi_base) {\r\nBUG_ON(index != 0);\r\nrc = 0;\r\n} else {\r\nMCDI_SET_DWORD(inbuf,\r\nLINK_PIOBUF_IN_PIOBUF_HANDLE,\r\nnic_data->piobuf_handle[index]);\r\nMCDI_SET_DWORD(inbuf,\r\nLINK_PIOBUF_IN_TXQ_INSTANCE,\r\ntx_queue->queue);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_LINK_PIOBUF,\r\ninbuf, MC_CMD_LINK_PIOBUF_IN_LEN,\r\nNULL, 0, NULL);\r\n}\r\nif (rc) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"failed to link VI %u to PIO buffer %u (%d)\n",\r\ntx_queue->queue, index, rc);\r\ntx_queue->piobuf = NULL;\r\n} else {\r\ntx_queue->piobuf =\r\nnic_data->pio_write_base +\r\nindex * EFX_VI_PAGE_SIZE + offset;\r\ntx_queue->piobuf_offset = offset;\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"linked VI %u to PIO buffer %u offset %x addr %p\n",\r\ntx_queue->queue, index,\r\ntx_queue->piobuf_offset,\r\ntx_queue->piobuf);\r\n}\r\n}\r\n}\r\nreturn 0;\r\nfail:\r\nBUILD_BUG_ON(MC_CMD_LINK_PIOBUF_IN_LEN < MC_CMD_UNLINK_PIOBUF_IN_LEN);\r\nwhile (index--) {\r\nMCDI_SET_DWORD(inbuf, UNLINK_PIOBUF_IN_TXQ_INSTANCE,\r\nnic_data->pio_write_vi_base + index);\r\nefx_mcdi_rpc(efx, MC_CMD_UNLINK_PIOBUF,\r\ninbuf, MC_CMD_UNLINK_PIOBUF_IN_LEN,\r\nNULL, 0, NULL);\r\n}\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_forget_old_piobufs(struct efx_nic *efx)\r\n{\r\nstruct efx_channel *channel;\r\nstruct efx_tx_queue *tx_queue;\r\nefx_for_each_channel(channel, efx)\r\nefx_for_each_channel_tx_queue(tx_queue, channel)\r\ntx_queue->piobuf = NULL;\r\n}\r\nstatic int efx_ef10_alloc_piobufs(struct efx_nic *efx, unsigned int n)\r\n{\r\nreturn n == 0 ? 0 : -ENOBUFS;\r\n}\r\nstatic int efx_ef10_link_piobufs(struct efx_nic *efx)\r\n{\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_free_piobufs(struct efx_nic *efx)\r\n{\r\n}\r\nstatic void efx_ef10_forget_old_piobufs(struct efx_nic *efx)\r\n{\r\n}\r\nstatic void efx_ef10_remove(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\n#ifdef CONFIG_SFC_SRIOV\r\nstruct efx_ef10_nic_data *nic_data_pf;\r\nstruct pci_dev *pci_dev_pf;\r\nstruct efx_nic *efx_pf;\r\nstruct ef10_vf *vf;\r\nif (efx->pci_dev->is_virtfn) {\r\npci_dev_pf = efx->pci_dev->physfn;\r\nif (pci_dev_pf) {\r\nefx_pf = pci_get_drvdata(pci_dev_pf);\r\nnic_data_pf = efx_pf->nic_data;\r\nvf = nic_data_pf->vf + nic_data->vf_index;\r\nvf->efx = NULL;\r\n} else\r\nnetif_info(efx, drv, efx->net_dev,\r\n"Could not get the PF id from VF\n");\r\n}\r\n#endif\r\nefx_ef10_cleanup_vlans(efx);\r\nmutex_destroy(&nic_data->vlan_lock);\r\nefx_ptp_remove(efx);\r\nefx_mcdi_mon_remove(efx);\r\nefx_ef10_rx_free_indir_table(efx);\r\nif (nic_data->wc_membase)\r\niounmap(nic_data->wc_membase);\r\nrc = efx_ef10_free_vis(efx);\r\nWARN_ON(rc != 0);\r\nif (!nic_data->must_restore_piobufs)\r\nefx_ef10_free_piobufs(efx);\r\ndevice_remove_file(&efx->pci_dev->dev, &dev_attr_primary_flag);\r\ndevice_remove_file(&efx->pci_dev->dev, &dev_attr_link_control_flag);\r\nefx_mcdi_detach(efx);\r\nmemset(nic_data->udp_tunnels, 0, sizeof(nic_data->udp_tunnels));\r\nmutex_lock(&nic_data->udp_tunnels_lock);\r\n(void)efx_ef10_set_udp_tnl_ports(efx, true);\r\nmutex_unlock(&nic_data->udp_tunnels_lock);\r\nmutex_destroy(&nic_data->udp_tunnels_lock);\r\nefx_mcdi_fini(efx);\r\nefx_nic_free_buffer(efx, &nic_data->mcdi_buf);\r\nkfree(nic_data);\r\n}\r\nstatic int efx_ef10_probe_pf(struct efx_nic *efx)\r\n{\r\nreturn efx_ef10_probe(efx);\r\n}\r\nint efx_ef10_vadaptor_query(struct efx_nic *efx, unsigned int port_id,\r\nu32 *port_flags, u32 *vadaptor_flags,\r\nunsigned int *vlan_tags)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_VADAPTOR_QUERY_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_VADAPTOR_QUERY_OUT_LEN);\r\nsize_t outlen;\r\nint rc;\r\nif (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VADAPTOR_QUERY_LBN)) {\r\nMCDI_SET_DWORD(inbuf, VADAPTOR_QUERY_IN_UPSTREAM_PORT_ID,\r\nport_id);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_VADAPTOR_QUERY, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < sizeof(outbuf)) {\r\nrc = -EIO;\r\nreturn rc;\r\n}\r\n}\r\nif (port_flags)\r\n*port_flags = MCDI_DWORD(outbuf, VADAPTOR_QUERY_OUT_PORT_FLAGS);\r\nif (vadaptor_flags)\r\n*vadaptor_flags =\r\nMCDI_DWORD(outbuf, VADAPTOR_QUERY_OUT_VADAPTOR_FLAGS);\r\nif (vlan_tags)\r\n*vlan_tags =\r\nMCDI_DWORD(outbuf,\r\nVADAPTOR_QUERY_OUT_NUM_AVAILABLE_VLAN_TAGS);\r\nreturn 0;\r\n}\r\nint efx_ef10_vadaptor_alloc(struct efx_nic *efx, unsigned int port_id)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_VADAPTOR_ALLOC_IN_LEN);\r\nMCDI_SET_DWORD(inbuf, VADAPTOR_ALLOC_IN_UPSTREAM_PORT_ID, port_id);\r\nreturn efx_mcdi_rpc(efx, MC_CMD_VADAPTOR_ALLOC, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\n}\r\nint efx_ef10_vadaptor_free(struct efx_nic *efx, unsigned int port_id)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_VADAPTOR_FREE_IN_LEN);\r\nMCDI_SET_DWORD(inbuf, VADAPTOR_FREE_IN_UPSTREAM_PORT_ID, port_id);\r\nreturn efx_mcdi_rpc(efx, MC_CMD_VADAPTOR_FREE, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\n}\r\nint efx_ef10_vport_add_mac(struct efx_nic *efx,\r\nunsigned int port_id, u8 *mac)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_VPORT_ADD_MAC_ADDRESS_IN_LEN);\r\nMCDI_SET_DWORD(inbuf, VPORT_ADD_MAC_ADDRESS_IN_VPORT_ID, port_id);\r\nether_addr_copy(MCDI_PTR(inbuf, VPORT_ADD_MAC_ADDRESS_IN_MACADDR), mac);\r\nreturn efx_mcdi_rpc(efx, MC_CMD_VPORT_ADD_MAC_ADDRESS, inbuf,\r\nsizeof(inbuf), NULL, 0, NULL);\r\n}\r\nint efx_ef10_vport_del_mac(struct efx_nic *efx,\r\nunsigned int port_id, u8 *mac)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_VPORT_DEL_MAC_ADDRESS_IN_LEN);\r\nMCDI_SET_DWORD(inbuf, VPORT_DEL_MAC_ADDRESS_IN_VPORT_ID, port_id);\r\nether_addr_copy(MCDI_PTR(inbuf, VPORT_DEL_MAC_ADDRESS_IN_MACADDR), mac);\r\nreturn efx_mcdi_rpc(efx, MC_CMD_VPORT_DEL_MAC_ADDRESS, inbuf,\r\nsizeof(inbuf), NULL, 0, NULL);\r\n}\r\nstatic int efx_ef10_probe_vf(struct efx_nic *efx)\r\n{\r\nint rc;\r\nstruct pci_dev *pci_dev_pf;\r\npci_dev_pf = efx->pci_dev->physfn;\r\nif (pci_dev_pf) {\r\nstruct efx_nic *efx_pf = pci_get_drvdata(pci_dev_pf);\r\nstruct efx_ef10_nic_data *nic_data_pf = efx_pf->nic_data;\r\nif (!nic_data_pf->vf) {\r\nnetif_info(efx, drv, efx->net_dev,\r\n"The VF cannot link to its parent PF; "\r\n"please destroy and re-create the VF\n");\r\nreturn -EBUSY;\r\n}\r\n}\r\nrc = efx_ef10_probe(efx);\r\nif (rc)\r\nreturn rc;\r\nrc = efx_ef10_get_vf_index(efx);\r\nif (rc)\r\ngoto fail;\r\nif (efx->pci_dev->is_virtfn) {\r\nif (efx->pci_dev->physfn) {\r\nstruct efx_nic *efx_pf =\r\npci_get_drvdata(efx->pci_dev->physfn);\r\nstruct efx_ef10_nic_data *nic_data_p = efx_pf->nic_data;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nnic_data_p->vf[nic_data->vf_index].efx = efx;\r\nnic_data_p->vf[nic_data->vf_index].pci_dev =\r\nefx->pci_dev;\r\n} else\r\nnetif_info(efx, drv, efx->net_dev,\r\n"Could not get the PF id from VF\n");\r\n}\r\nreturn 0;\r\nfail:\r\nefx_ef10_remove(efx);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_alloc_vis(struct efx_nic *efx,\r\nunsigned int min_vis, unsigned int max_vis)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_ALLOC_VIS_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_ALLOC_VIS_OUT_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, ALLOC_VIS_IN_MIN_VI_COUNT, min_vis);\r\nMCDI_SET_DWORD(inbuf, ALLOC_VIS_IN_MAX_VI_COUNT, max_vis);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_ALLOC_VIS, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (outlen < MC_CMD_ALLOC_VIS_OUT_LEN)\r\nreturn -EIO;\r\nnetif_dbg(efx, drv, efx->net_dev, "base VI is A0x%03x\n",\r\nMCDI_DWORD(outbuf, ALLOC_VIS_OUT_VI_BASE));\r\nnic_data->vi_base = MCDI_DWORD(outbuf, ALLOC_VIS_OUT_VI_BASE);\r\nnic_data->n_allocated_vis = MCDI_DWORD(outbuf, ALLOC_VIS_OUT_VI_COUNT);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_dimension_resources(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nunsigned int uc_mem_map_size, wc_mem_map_size;\r\nunsigned int min_vis = max(EFX_TXQ_TYPES,\r\nefx_separate_tx_channels ? 2 : 1);\r\nunsigned int channel_vis, pio_write_vi_base, max_vis;\r\nvoid __iomem *membase;\r\nint rc;\r\nchannel_vis = max(efx->n_channels, efx->n_tx_channels * EFX_TXQ_TYPES);\r\n#ifdef EFX_USE_PIO\r\nif (efx_piobuf_size != 0 &&\r\nnic_data->piobuf_size / efx_piobuf_size * EF10_TX_PIOBUF_COUNT >=\r\nefx->n_tx_channels) {\r\nunsigned int n_piobufs =\r\nDIV_ROUND_UP(efx->n_tx_channels,\r\nnic_data->piobuf_size / efx_piobuf_size);\r\nrc = efx_ef10_alloc_piobufs(efx, n_piobufs);\r\nif (rc == -ENOSPC)\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"out of PIO buffers; cannot allocate more\n");\r\nelse if (rc == -EPERM)\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"not permitted to allocate PIO buffers\n");\r\nelse if (rc)\r\nnetif_err(efx, probe, efx->net_dev,\r\n"failed to allocate PIO buffers (%d)\n", rc);\r\nelse\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"allocated %u PIO buffers\n", n_piobufs);\r\n}\r\n#else\r\nnic_data->n_piobufs = 0;\r\n#endif\r\nuc_mem_map_size = PAGE_ALIGN((channel_vis - 1) * EFX_VI_PAGE_SIZE +\r\nER_DZ_TX_PIOBUF);\r\nif (nic_data->n_piobufs) {\r\npio_write_vi_base = uc_mem_map_size / EFX_VI_PAGE_SIZE;\r\nwc_mem_map_size = (PAGE_ALIGN((pio_write_vi_base +\r\nnic_data->n_piobufs) *\r\nEFX_VI_PAGE_SIZE) -\r\nuc_mem_map_size);\r\nmax_vis = pio_write_vi_base + nic_data->n_piobufs;\r\n} else {\r\npio_write_vi_base = 0;\r\nwc_mem_map_size = 0;\r\nmax_vis = channel_vis;\r\n}\r\nrc = efx_ef10_free_vis(efx);\r\nif (rc != 0)\r\nreturn rc;\r\nrc = efx_ef10_alloc_vis(efx, min_vis, max_vis);\r\nif (rc != 0)\r\nreturn rc;\r\nif (nic_data->n_allocated_vis < channel_vis) {\r\nnetif_info(efx, drv, efx->net_dev,\r\n"Could not allocate enough VIs to satisfy RSS"\r\n" requirements. Performance may not be optimal.\n");\r\nefx->max_channels = nic_data->n_allocated_vis;\r\nefx->max_tx_channels =\r\nnic_data->n_allocated_vis / EFX_TXQ_TYPES;\r\nefx_ef10_free_vis(efx);\r\nreturn -EAGAIN;\r\n}\r\nif (nic_data->n_piobufs &&\r\nnic_data->n_allocated_vis <\r\npio_write_vi_base + nic_data->n_piobufs) {\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"%u VIs are not sufficient to map %u PIO buffers\n",\r\nnic_data->n_allocated_vis, nic_data->n_piobufs);\r\nefx_ef10_free_piobufs(efx);\r\n}\r\nmembase = ioremap_nocache(efx->membase_phys, uc_mem_map_size);\r\nif (!membase) {\r\nnetif_err(efx, probe, efx->net_dev,\r\n"could not shrink memory BAR to %x\n",\r\nuc_mem_map_size);\r\nreturn -ENOMEM;\r\n}\r\niounmap(efx->membase);\r\nefx->membase = membase;\r\nif (wc_mem_map_size) {\r\nnic_data->wc_membase = ioremap_wc(efx->membase_phys +\r\nuc_mem_map_size,\r\nwc_mem_map_size);\r\nif (!nic_data->wc_membase) {\r\nnetif_err(efx, probe, efx->net_dev,\r\n"could not allocate WC mapping of size %x\n",\r\nwc_mem_map_size);\r\nreturn -ENOMEM;\r\n}\r\nnic_data->pio_write_vi_base = pio_write_vi_base;\r\nnic_data->pio_write_base =\r\nnic_data->wc_membase +\r\n(pio_write_vi_base * EFX_VI_PAGE_SIZE + ER_DZ_TX_PIOBUF -\r\nuc_mem_map_size);\r\nrc = efx_ef10_link_piobufs(efx);\r\nif (rc)\r\nefx_ef10_free_piobufs(efx);\r\n}\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"memory BAR at %pa (virtual %p+%x UC, %p+%x WC)\n",\r\n&efx->membase_phys, efx->membase, uc_mem_map_size,\r\nnic_data->wc_membase, wc_mem_map_size);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_init_nic(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\nif (nic_data->must_check_datapath_caps) {\r\nrc = efx_ef10_init_datapath_caps(efx);\r\nif (rc)\r\nreturn rc;\r\nnic_data->must_check_datapath_caps = false;\r\n}\r\nif (nic_data->must_realloc_vis) {\r\nrc = efx_ef10_alloc_vis(efx, nic_data->n_allocated_vis,\r\nnic_data->n_allocated_vis);\r\nif (rc)\r\nreturn rc;\r\nnic_data->must_realloc_vis = false;\r\n}\r\nif (nic_data->must_restore_piobufs && nic_data->n_piobufs) {\r\nrc = efx_ef10_alloc_piobufs(efx, nic_data->n_piobufs);\r\nif (rc == 0) {\r\nrc = efx_ef10_link_piobufs(efx);\r\nif (rc)\r\nefx_ef10_free_piobufs(efx);\r\n}\r\nif (rc == -EPERM)\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"not permitted to restore PIO buffers\n");\r\nelse if (rc)\r\nnetif_err(efx, drv, efx->net_dev,\r\n"failed to restore PIO buffers (%d)\n", rc);\r\nnic_data->must_restore_piobufs = false;\r\n}\r\nrc = efx->type->rx_push_rss_config(efx, false, efx->rx_indir_table, NULL);\r\nefx->rss_active = (rc == 0);\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_reset_mc_allocations(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\n#ifdef CONFIG_SFC_SRIOV\r\nunsigned int i;\r\n#endif\r\nnic_data->must_realloc_vis = true;\r\nnic_data->must_restore_filters = true;\r\nnic_data->must_restore_piobufs = true;\r\nefx_ef10_forget_old_piobufs(efx);\r\nnic_data->rx_rss_context = EFX_EF10_RSS_CONTEXT_INVALID;\r\nnic_data->must_probe_vswitching = true;\r\nnic_data->vport_id = EVB_PORT_ID_ASSIGNED;\r\n#ifdef CONFIG_SFC_SRIOV\r\nif (nic_data->vf)\r\nfor (i = 0; i < efx->vf_count; i++)\r\nnic_data->vf[i].vport_id = 0;\r\n#endif\r\n}\r\nstatic enum reset_type efx_ef10_map_reset_reason(enum reset_type reason)\r\n{\r\nif (reason == RESET_TYPE_MC_FAILURE)\r\nreturn RESET_TYPE_DATAPATH;\r\nreturn efx_mcdi_map_reset_reason(reason);\r\n}\r\nstatic int efx_ef10_map_reset_flags(u32 *flags)\r\n{\r\nenum {\r\nEF10_RESET_PORT = ((ETH_RESET_MAC | ETH_RESET_PHY) <<\r\nETH_RESET_SHARED_SHIFT),\r\nEF10_RESET_MC = ((ETH_RESET_DMA | ETH_RESET_FILTER |\r\nETH_RESET_OFFLOAD | ETH_RESET_MAC |\r\nETH_RESET_PHY | ETH_RESET_MGMT) <<\r\nETH_RESET_SHARED_SHIFT)\r\n};\r\nif ((*flags & EF10_RESET_MC) == EF10_RESET_MC) {\r\n*flags &= ~EF10_RESET_MC;\r\nreturn RESET_TYPE_WORLD;\r\n}\r\nif ((*flags & EF10_RESET_PORT) == EF10_RESET_PORT) {\r\n*flags &= ~EF10_RESET_PORT;\r\nreturn RESET_TYPE_ALL;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int efx_ef10_reset(struct efx_nic *efx, enum reset_type reset_type)\r\n{\r\nint rc = efx_mcdi_reset(efx, reset_type);\r\nif (reset_type == RESET_TYPE_WORLD && rc == -EPERM)\r\nrc = 0;\r\nif ((reset_type == RESET_TYPE_ALL ||\r\nreset_type == RESET_TYPE_MCDI_TIMEOUT) && !rc)\r\nefx_ef10_reset_mc_allocations(efx);\r\nreturn rc;\r\n}\r\nstatic u64 efx_ef10_raw_stat_mask(struct efx_nic *efx)\r\n{\r\nu64 raw_mask = HUNT_COMMON_STAT_MASK;\r\nu32 port_caps = efx_mcdi_phy_get_caps(efx);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (!(efx->mcdi->fn_flags &\r\n1 << MC_CMD_DRV_ATTACH_EXT_OUT_FLAG_LINKCTRL))\r\nreturn 0;\r\nif (port_caps & (1 << MC_CMD_PHY_CAP_40000FDX_LBN)) {\r\nraw_mask |= HUNT_40G_EXTRA_STAT_MASK;\r\nif (nic_data->datapath_caps2 &\r\n(1 << MC_CMD_GET_CAPABILITIES_V2_OUT_MAC_STATS_40G_TX_SIZE_BINS_LBN))\r\nraw_mask |= HUNT_10G_ONLY_STAT_MASK;\r\n} else {\r\nraw_mask |= HUNT_10G_ONLY_STAT_MASK;\r\n}\r\nif (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_PM_AND_RXDP_COUNTERS_LBN))\r\nraw_mask |= HUNT_PM_AND_RXDP_STAT_MASK;\r\nreturn raw_mask;\r\n}\r\nstatic void efx_ef10_get_stat_mask(struct efx_nic *efx, unsigned long *mask)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu64 raw_mask[2];\r\nraw_mask[0] = efx_ef10_raw_stat_mask(efx);\r\nif (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_EVB_LBN)) {\r\nraw_mask[0] |= ~((1ULL << EF10_STAT_rx_unicast) - 1);\r\nraw_mask[1] = (1ULL << (EF10_STAT_COUNT - 63)) - 1;\r\n} else {\r\nraw_mask[1] = 0;\r\n}\r\n#if BITS_PER_LONG == 64\r\nBUILD_BUG_ON(BITS_TO_LONGS(EF10_STAT_COUNT) != 2);\r\nmask[0] = raw_mask[0];\r\nmask[1] = raw_mask[1];\r\n#else\r\nBUILD_BUG_ON(BITS_TO_LONGS(EF10_STAT_COUNT) != 3);\r\nmask[0] = raw_mask[0] & 0xffffffff;\r\nmask[1] = raw_mask[0] >> 32;\r\nmask[2] = raw_mask[1] & 0xffffffff;\r\n#endif\r\n}\r\nstatic size_t efx_ef10_describe_stats(struct efx_nic *efx, u8 *names)\r\n{\r\nDECLARE_BITMAP(mask, EF10_STAT_COUNT);\r\nefx_ef10_get_stat_mask(efx, mask);\r\nreturn efx_nic_describe_stats(efx_ef10_stat_desc, EF10_STAT_COUNT,\r\nmask, names);\r\n}\r\nstatic size_t efx_ef10_update_stats_common(struct efx_nic *efx, u64 *full_stats,\r\nstruct rtnl_link_stats64 *core_stats)\r\n{\r\nDECLARE_BITMAP(mask, EF10_STAT_COUNT);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu64 *stats = nic_data->stats;\r\nsize_t stats_count = 0, index;\r\nefx_ef10_get_stat_mask(efx, mask);\r\nif (full_stats) {\r\nfor_each_set_bit(index, mask, EF10_STAT_COUNT) {\r\nif (efx_ef10_stat_desc[index].name) {\r\n*full_stats++ = stats[index];\r\n++stats_count;\r\n}\r\n}\r\n}\r\nif (!core_stats)\r\nreturn stats_count;\r\nif (nic_data->datapath_caps &\r\n1 << MC_CMD_GET_CAPABILITIES_OUT_EVB_LBN) {\r\ncore_stats->rx_packets = stats[EF10_STAT_rx_unicast] +\r\nstats[EF10_STAT_rx_multicast] +\r\nstats[EF10_STAT_rx_broadcast];\r\ncore_stats->tx_packets = stats[EF10_STAT_tx_unicast] +\r\nstats[EF10_STAT_tx_multicast] +\r\nstats[EF10_STAT_tx_broadcast];\r\ncore_stats->rx_bytes = stats[EF10_STAT_rx_unicast_bytes] +\r\nstats[EF10_STAT_rx_multicast_bytes] +\r\nstats[EF10_STAT_rx_broadcast_bytes];\r\ncore_stats->tx_bytes = stats[EF10_STAT_tx_unicast_bytes] +\r\nstats[EF10_STAT_tx_multicast_bytes] +\r\nstats[EF10_STAT_tx_broadcast_bytes];\r\ncore_stats->rx_dropped = stats[GENERIC_STAT_rx_nodesc_trunc] +\r\nstats[GENERIC_STAT_rx_noskb_drops];\r\ncore_stats->multicast = stats[EF10_STAT_rx_multicast];\r\ncore_stats->rx_crc_errors = stats[EF10_STAT_rx_bad];\r\ncore_stats->rx_fifo_errors = stats[EF10_STAT_rx_overflow];\r\ncore_stats->rx_errors = core_stats->rx_crc_errors;\r\ncore_stats->tx_errors = stats[EF10_STAT_tx_bad];\r\n} else {\r\ncore_stats->rx_packets = stats[EF10_STAT_port_rx_packets];\r\ncore_stats->tx_packets = stats[EF10_STAT_port_tx_packets];\r\ncore_stats->rx_bytes = stats[EF10_STAT_port_rx_bytes];\r\ncore_stats->tx_bytes = stats[EF10_STAT_port_tx_bytes];\r\ncore_stats->rx_dropped = stats[EF10_STAT_port_rx_nodesc_drops] +\r\nstats[GENERIC_STAT_rx_nodesc_trunc] +\r\nstats[GENERIC_STAT_rx_noskb_drops];\r\ncore_stats->multicast = stats[EF10_STAT_port_rx_multicast];\r\ncore_stats->rx_length_errors =\r\nstats[EF10_STAT_port_rx_gtjumbo] +\r\nstats[EF10_STAT_port_rx_length_error];\r\ncore_stats->rx_crc_errors = stats[EF10_STAT_port_rx_bad];\r\ncore_stats->rx_frame_errors =\r\nstats[EF10_STAT_port_rx_align_error];\r\ncore_stats->rx_fifo_errors = stats[EF10_STAT_port_rx_overflow];\r\ncore_stats->rx_errors = (core_stats->rx_length_errors +\r\ncore_stats->rx_crc_errors +\r\ncore_stats->rx_frame_errors);\r\n}\r\nreturn stats_count;\r\n}\r\nstatic int efx_ef10_try_update_nic_stats_pf(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nDECLARE_BITMAP(mask, EF10_STAT_COUNT);\r\n__le64 generation_start, generation_end;\r\nu64 *stats = nic_data->stats;\r\n__le64 *dma_stats;\r\nefx_ef10_get_stat_mask(efx, mask);\r\ndma_stats = efx->stats_buffer.addr;\r\ngeneration_end = dma_stats[MC_CMD_MAC_GENERATION_END];\r\nif (generation_end == EFX_MC_STATS_GENERATION_INVALID)\r\nreturn 0;\r\nrmb();\r\nefx_nic_update_stats(efx_ef10_stat_desc, EF10_STAT_COUNT, mask,\r\nstats, efx->stats_buffer.addr, false);\r\nrmb();\r\ngeneration_start = dma_stats[MC_CMD_MAC_GENERATION_START];\r\nif (generation_end != generation_start)\r\nreturn -EAGAIN;\r\nefx_nic_fix_nodesc_drop_stat(efx,\r\n&stats[EF10_STAT_port_rx_nodesc_drops]);\r\nstats[EF10_STAT_port_rx_good_bytes] =\r\nstats[EF10_STAT_port_rx_bytes] -\r\nstats[EF10_STAT_port_rx_bytes_minus_good_bytes];\r\nefx_update_diff_stat(&stats[EF10_STAT_port_rx_bad_bytes],\r\nstats[EF10_STAT_port_rx_bytes_minus_good_bytes]);\r\nefx_update_sw_stats(efx, stats);\r\nreturn 0;\r\n}\r\nstatic size_t efx_ef10_update_stats_pf(struct efx_nic *efx, u64 *full_stats,\r\nstruct rtnl_link_stats64 *core_stats)\r\n{\r\nint retry;\r\nfor (retry = 0; retry < 100; ++retry) {\r\nif (efx_ef10_try_update_nic_stats_pf(efx) == 0)\r\nbreak;\r\nudelay(100);\r\n}\r\nreturn efx_ef10_update_stats_common(efx, full_stats, core_stats);\r\n}\r\nstatic int efx_ef10_try_update_nic_stats_vf(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_MAC_STATS_IN_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nDECLARE_BITMAP(mask, EF10_STAT_COUNT);\r\n__le64 generation_start, generation_end;\r\nu64 *stats = nic_data->stats;\r\nu32 dma_len = MC_CMD_MAC_NSTATS * sizeof(u64);\r\nstruct efx_buffer stats_buf;\r\n__le64 *dma_stats;\r\nint rc;\r\nspin_unlock_bh(&efx->stats_lock);\r\nif (in_interrupt()) {\r\nspin_lock_bh(&efx->stats_lock);\r\nefx_update_sw_stats(efx, stats);\r\nreturn 0;\r\n}\r\nefx_ef10_get_stat_mask(efx, mask);\r\nrc = efx_nic_alloc_buffer(efx, &stats_buf, dma_len, GFP_ATOMIC);\r\nif (rc) {\r\nspin_lock_bh(&efx->stats_lock);\r\nreturn rc;\r\n}\r\ndma_stats = stats_buf.addr;\r\ndma_stats[MC_CMD_MAC_GENERATION_END] = EFX_MC_STATS_GENERATION_INVALID;\r\nMCDI_SET_QWORD(inbuf, MAC_STATS_IN_DMA_ADDR, stats_buf.dma_addr);\r\nMCDI_POPULATE_DWORD_1(inbuf, MAC_STATS_IN_CMD,\r\nMAC_STATS_IN_DMA, 1);\r\nMCDI_SET_DWORD(inbuf, MAC_STATS_IN_DMA_LEN, dma_len);\r\nMCDI_SET_DWORD(inbuf, MAC_STATS_IN_PORT_ID, EVB_PORT_ID_ASSIGNED);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_MAC_STATS, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nspin_lock_bh(&efx->stats_lock);\r\nif (rc) {\r\nif (rc != -ENOENT || atomic_read(&efx->active_queues))\r\nefx_mcdi_display_error(efx, MC_CMD_MAC_STATS,\r\nsizeof(inbuf), NULL, 0, rc);\r\ngoto out;\r\n}\r\ngeneration_end = dma_stats[MC_CMD_MAC_GENERATION_END];\r\nif (generation_end == EFX_MC_STATS_GENERATION_INVALID) {\r\nWARN_ON_ONCE(1);\r\ngoto out;\r\n}\r\nrmb();\r\nefx_nic_update_stats(efx_ef10_stat_desc, EF10_STAT_COUNT, mask,\r\nstats, stats_buf.addr, false);\r\nrmb();\r\ngeneration_start = dma_stats[MC_CMD_MAC_GENERATION_START];\r\nif (generation_end != generation_start) {\r\nrc = -EAGAIN;\r\ngoto out;\r\n}\r\nefx_update_sw_stats(efx, stats);\r\nout:\r\nefx_nic_free_buffer(efx, &stats_buf);\r\nreturn rc;\r\n}\r\nstatic size_t efx_ef10_update_stats_vf(struct efx_nic *efx, u64 *full_stats,\r\nstruct rtnl_link_stats64 *core_stats)\r\n{\r\nif (efx_ef10_try_update_nic_stats_vf(efx))\r\nreturn 0;\r\nreturn efx_ef10_update_stats_common(efx, full_stats, core_stats);\r\n}\r\nstatic void efx_ef10_push_irq_moderation(struct efx_channel *channel)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nunsigned int mode, usecs;\r\nefx_dword_t timer_cmd;\r\nif (channel->irq_moderation_us) {\r\nmode = 3;\r\nusecs = channel->irq_moderation_us;\r\n} else {\r\nmode = 0;\r\nusecs = 0;\r\n}\r\nif (EFX_EF10_WORKAROUND_61265(efx)) {\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_SET_EVQ_TMR_IN_LEN);\r\nunsigned int ns = usecs * 1000;\r\nMCDI_SET_DWORD(inbuf, SET_EVQ_TMR_IN_INSTANCE,\r\nchannel->channel);\r\nMCDI_SET_DWORD(inbuf, SET_EVQ_TMR_IN_TMR_LOAD_REQ_NS, ns);\r\nMCDI_SET_DWORD(inbuf, SET_EVQ_TMR_IN_TMR_RELOAD_REQ_NS, ns);\r\nMCDI_SET_DWORD(inbuf, SET_EVQ_TMR_IN_TMR_MODE, mode);\r\nefx_mcdi_rpc_async(efx, MC_CMD_SET_EVQ_TMR,\r\ninbuf, sizeof(inbuf), 0, NULL, 0);\r\n} else if (EFX_EF10_WORKAROUND_35388(efx)) {\r\nunsigned int ticks = efx_usecs_to_ticks(efx, usecs);\r\nEFX_POPULATE_DWORD_3(timer_cmd, ERF_DD_EVQ_IND_TIMER_FLAGS,\r\nEFE_DD_EVQ_IND_TIMER_FLAGS,\r\nERF_DD_EVQ_IND_TIMER_MODE, mode,\r\nERF_DD_EVQ_IND_TIMER_VAL, ticks);\r\nefx_writed_page(efx, &timer_cmd, ER_DD_EVQ_INDIRECT,\r\nchannel->channel);\r\n} else {\r\nunsigned int ticks = efx_usecs_to_ticks(efx, usecs);\r\nEFX_POPULATE_DWORD_2(timer_cmd, ERF_DZ_TC_TIMER_MODE, mode,\r\nERF_DZ_TC_TIMER_VAL, ticks);\r\nefx_writed_page(efx, &timer_cmd, ER_DZ_EVQ_TMR,\r\nchannel->channel);\r\n}\r\n}\r\nstatic void efx_ef10_get_wol_vf(struct efx_nic *efx,\r\nstruct ethtool_wolinfo *wol) {}\r\nstatic int efx_ef10_set_wol_vf(struct efx_nic *efx, u32 type)\r\n{\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic void efx_ef10_get_wol(struct efx_nic *efx, struct ethtool_wolinfo *wol)\r\n{\r\nwol->supported = 0;\r\nwol->wolopts = 0;\r\nmemset(&wol->sopass, 0, sizeof(wol->sopass));\r\n}\r\nstatic int efx_ef10_set_wol(struct efx_nic *efx, u32 type)\r\n{\r\nif (type != 0)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_mcdi_request(struct efx_nic *efx,\r\nconst efx_dword_t *hdr, size_t hdr_len,\r\nconst efx_dword_t *sdu, size_t sdu_len)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu8 *pdu = nic_data->mcdi_buf.addr;\r\nmemcpy(pdu, hdr, hdr_len);\r\nmemcpy(pdu + hdr_len, sdu, sdu_len);\r\nwmb();\r\n_efx_writed(efx, cpu_to_le32((u64)nic_data->mcdi_buf.dma_addr >> 32),\r\nER_DZ_MC_DB_LWRD);\r\n_efx_writed(efx, cpu_to_le32((u32)nic_data->mcdi_buf.dma_addr),\r\nER_DZ_MC_DB_HWRD);\r\n}\r\nstatic bool efx_ef10_mcdi_poll_response(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nconst efx_dword_t hdr = *(const efx_dword_t *)nic_data->mcdi_buf.addr;\r\nrmb();\r\nreturn EFX_DWORD_FIELD(hdr, MCDI_HEADER_RESPONSE);\r\n}\r\nstatic void\r\nefx_ef10_mcdi_read_response(struct efx_nic *efx, efx_dword_t *outbuf,\r\nsize_t offset, size_t outlen)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nconst u8 *pdu = nic_data->mcdi_buf.addr;\r\nmemcpy(outbuf, pdu + offset, outlen);\r\n}\r\nstatic void efx_ef10_mcdi_reboot_detected(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nefx_ef10_reset_mc_allocations(efx);\r\nnic_data->must_check_datapath_caps = true;\r\nnic_data->stats[EF10_STAT_port_rx_bad_bytes] = 0;\r\n}\r\nstatic int efx_ef10_mcdi_poll_reboot(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\nrc = efx_ef10_get_warm_boot_count(efx);\r\nif (rc < 0) {\r\nreturn 0;\r\n}\r\nif (rc == nic_data->warm_boot_count)\r\nreturn 0;\r\nnic_data->warm_boot_count = rc;\r\nefx_ef10_mcdi_reboot_detected(efx);\r\nreturn -EIO;\r\n}\r\nstatic irqreturn_t efx_ef10_msi_interrupt(int irq, void *dev_id)\r\n{\r\nstruct efx_msi_context *context = dev_id;\r\nstruct efx_nic *efx = context->efx;\r\nnetif_vdbg(efx, intr, efx->net_dev,\r\n"IRQ %d on CPU %d\n", irq, raw_smp_processor_id());\r\nif (likely(ACCESS_ONCE(efx->irq_soft_enabled))) {\r\nif (context->index == efx->irq_level)\r\nefx->last_irq_cpu = raw_smp_processor_id();\r\nefx_schedule_channel_irq(efx->channel[context->index]);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t efx_ef10_legacy_interrupt(int irq, void *dev_id)\r\n{\r\nstruct efx_nic *efx = dev_id;\r\nbool soft_enabled = ACCESS_ONCE(efx->irq_soft_enabled);\r\nstruct efx_channel *channel;\r\nefx_dword_t reg;\r\nu32 queues;\r\nefx_readd(efx, &reg, ER_DZ_BIU_INT_ISR);\r\nqueues = EFX_DWORD_FIELD(reg, ERF_DZ_ISR_REG);\r\nif (queues == 0)\r\nreturn IRQ_NONE;\r\nif (likely(soft_enabled)) {\r\nif (queues & (1U << efx->irq_level))\r\nefx->last_irq_cpu = raw_smp_processor_id();\r\nefx_for_each_channel(channel, efx) {\r\nif (queues & 1)\r\nefx_schedule_channel_irq(channel);\r\nqueues >>= 1;\r\n}\r\n}\r\nnetif_vdbg(efx, intr, efx->net_dev,\r\n"IRQ %d on CPU %d status " EFX_DWORD_FMT "\n",\r\nirq, raw_smp_processor_id(), EFX_DWORD_VAL(reg));\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int efx_ef10_irq_test_generate(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_TRIGGER_INTERRUPT_IN_LEN);\r\nif (efx_mcdi_set_workaround(efx, MC_CMD_WORKAROUND_BUG41750, true,\r\nNULL) == 0)\r\nreturn -ENOTSUPP;\r\nBUILD_BUG_ON(MC_CMD_TRIGGER_INTERRUPT_OUT_LEN != 0);\r\nMCDI_SET_DWORD(inbuf, TRIGGER_INTERRUPT_IN_INTR_LEVEL, efx->irq_level);\r\nreturn efx_mcdi_rpc(efx, MC_CMD_TRIGGER_INTERRUPT,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\n}\r\nstatic int efx_ef10_tx_probe(struct efx_tx_queue *tx_queue)\r\n{\r\nreturn efx_nic_alloc_buffer(tx_queue->efx, &tx_queue->txd.buf,\r\n(tx_queue->ptr_mask + 1) *\r\nsizeof(efx_qword_t),\r\nGFP_KERNEL);\r\n}\r\nstatic inline void efx_ef10_push_tx_desc(struct efx_tx_queue *tx_queue,\r\nconst efx_qword_t *txd)\r\n{\r\nunsigned int write_ptr;\r\nefx_oword_t reg;\r\nwrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\r\nEFX_POPULATE_OWORD_1(reg, ERF_DZ_TX_DESC_WPTR, write_ptr);\r\nreg.qword[0] = *txd;\r\nefx_writeo_page(tx_queue->efx, &reg,\r\nER_DZ_TX_DESC_UPD, tx_queue->queue);\r\n}\r\nstatic int efx_ef10_tx_tso_desc(struct efx_tx_queue *tx_queue,\r\nstruct sk_buff *skb,\r\nbool *data_mapped)\r\n{\r\nstruct efx_tx_buffer *buffer;\r\nstruct tcphdr *tcp;\r\nstruct iphdr *ip;\r\nu16 ipv4_id;\r\nu32 seqnum;\r\nu32 mss;\r\nEFX_WARN_ON_ONCE_PARANOID(tx_queue->tso_version != 2);\r\nmss = skb_shinfo(skb)->gso_size;\r\nif (unlikely(mss < 4)) {\r\nWARN_ONCE(1, "MSS of %u is too small for TSO v2\n", mss);\r\nreturn -EINVAL;\r\n}\r\nip = ip_hdr(skb);\r\nif (ip->version == 4) {\r\nip->tot_len = 0;\r\nip->check = 0;\r\nipv4_id = ntohs(ip->id);\r\n} else {\r\nstruct ipv6hdr *ipv6 = ipv6_hdr(skb);\r\nipv6->payload_len = 0;\r\nipv4_id = 0;\r\n}\r\ntcp = tcp_hdr(skb);\r\nseqnum = ntohl(tcp->seq);\r\nbuffer = efx_tx_queue_get_insert_buffer(tx_queue);\r\nbuffer->flags = EFX_TX_BUF_OPTION;\r\nbuffer->len = 0;\r\nbuffer->unmap_len = 0;\r\nEFX_POPULATE_QWORD_5(buffer->option,\r\nESF_DZ_TX_DESC_IS_OPT, 1,\r\nESF_DZ_TX_OPTION_TYPE, ESE_DZ_TX_OPTION_DESC_TSO,\r\nESF_DZ_TX_TSO_OPTION_TYPE,\r\nESE_DZ_TX_TSO_OPTION_DESC_FATSO2A,\r\nESF_DZ_TX_TSO_IP_ID, ipv4_id,\r\nESF_DZ_TX_TSO_TCP_SEQNO, seqnum\r\n);\r\n++tx_queue->insert_count;\r\nbuffer = efx_tx_queue_get_insert_buffer(tx_queue);\r\nbuffer->flags = EFX_TX_BUF_OPTION;\r\nbuffer->len = 0;\r\nbuffer->unmap_len = 0;\r\nEFX_POPULATE_QWORD_4(buffer->option,\r\nESF_DZ_TX_DESC_IS_OPT, 1,\r\nESF_DZ_TX_OPTION_TYPE, ESE_DZ_TX_OPTION_DESC_TSO,\r\nESF_DZ_TX_TSO_OPTION_TYPE,\r\nESE_DZ_TX_TSO_OPTION_DESC_FATSO2B,\r\nESF_DZ_TX_TSO_TCP_MSS, mss\r\n);\r\n++tx_queue->insert_count;\r\nreturn 0;\r\n}\r\nstatic u32 efx_ef10_tso_versions(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu32 tso_versions = 0;\r\nif (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_TX_TSO_LBN))\r\ntso_versions |= BIT(1);\r\nif (nic_data->datapath_caps2 &\r\n(1 << MC_CMD_GET_CAPABILITIES_V2_OUT_TX_TSO_V2_LBN))\r\ntso_versions |= BIT(2);\r\nreturn tso_versions;\r\n}\r\nstatic void efx_ef10_tx_init(struct efx_tx_queue *tx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_INIT_TXQ_IN_LEN(EFX_MAX_DMAQ_SIZE * 8 /\r\nEFX_BUF_SIZE));\r\nbool csum_offload = tx_queue->queue & EFX_TXQ_TYPE_OFFLOAD;\r\nsize_t entries = tx_queue->txd.buf.len / EFX_BUF_SIZE;\r\nstruct efx_channel *channel = tx_queue->channel;\r\nstruct efx_nic *efx = tx_queue->efx;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nbool tso_v2 = false;\r\nsize_t inlen;\r\ndma_addr_t dma_addr;\r\nefx_qword_t *txd;\r\nint rc;\r\nint i;\r\nBUILD_BUG_ON(MC_CMD_INIT_TXQ_OUT_LEN != 0);\r\nif (csum_offload && (nic_data->datapath_caps2 &\r\n(1 << MC_CMD_GET_CAPABILITIES_V2_OUT_TX_TSO_V2_LBN))) {\r\ntso_v2 = true;\r\nnetif_dbg(efx, hw, efx->net_dev, "Using TSOv2 for channel %u\n",\r\nchannel->channel);\r\n}\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_SIZE, tx_queue->ptr_mask + 1);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_TARGET_EVQ, channel->channel);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_LABEL, tx_queue->queue);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_INSTANCE, tx_queue->queue);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_OWNER_ID, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_TXQ_IN_PORT_ID, nic_data->vport_id);\r\ndma_addr = tx_queue->txd.buf.dma_addr;\r\nnetif_dbg(efx, hw, efx->net_dev, "pushing TXQ %d. %zu entries (%llx)\n",\r\ntx_queue->queue, entries, (u64)dma_addr);\r\nfor (i = 0; i < entries; ++i) {\r\nMCDI_SET_ARRAY_QWORD(inbuf, INIT_TXQ_IN_DMA_ADDR, i, dma_addr);\r\ndma_addr += EFX_BUF_SIZE;\r\n}\r\ninlen = MC_CMD_INIT_TXQ_IN_LEN(entries);\r\ndo {\r\nMCDI_POPULATE_DWORD_3(inbuf, INIT_TXQ_IN_FLAGS,\r\nINIT_TXQ_EXT_IN_FLAG_TSOV2_EN, tso_v2,\r\nINIT_TXQ_IN_FLAG_IP_CSUM_DIS, !csum_offload,\r\nINIT_TXQ_IN_FLAG_TCP_CSUM_DIS, !csum_offload);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_INIT_TXQ, inbuf, inlen,\r\nNULL, 0, NULL);\r\nif (rc == -ENOSPC && tso_v2) {\r\ntso_v2 = false;\r\nnetif_warn(efx, probe, efx->net_dev,\r\n"TSOv2 context not available to segment in hardware. TCP performance may be reduced.\n");\r\n} else if (rc) {\r\nefx_mcdi_display_error(efx, MC_CMD_INIT_TXQ,\r\nMC_CMD_INIT_TXQ_EXT_IN_LEN,\r\nNULL, 0, rc);\r\ngoto fail;\r\n}\r\n} while (rc);\r\ntx_queue->buffer[0].flags = EFX_TX_BUF_OPTION;\r\ntx_queue->insert_count = 1;\r\ntxd = efx_tx_desc(tx_queue, 0);\r\nEFX_POPULATE_QWORD_4(*txd,\r\nESF_DZ_TX_DESC_IS_OPT, true,\r\nESF_DZ_TX_OPTION_TYPE,\r\nESE_DZ_TX_OPTION_DESC_CRC_CSUM,\r\nESF_DZ_TX_OPTION_UDP_TCP_CSUM, csum_offload,\r\nESF_DZ_TX_OPTION_IP_CSUM, csum_offload);\r\ntx_queue->write_count = 1;\r\nif (tso_v2) {\r\ntx_queue->handle_tso = efx_ef10_tx_tso_desc;\r\ntx_queue->tso_version = 2;\r\n} else if (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_TX_TSO_LBN)) {\r\ntx_queue->tso_version = 1;\r\n}\r\nwmb();\r\nefx_ef10_push_tx_desc(tx_queue, txd);\r\nreturn;\r\nfail:\r\nnetdev_WARN(efx->net_dev, "failed to initialise TXQ %d\n",\r\ntx_queue->queue);\r\n}\r\nstatic void efx_ef10_tx_fini(struct efx_tx_queue *tx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FINI_TXQ_IN_LEN);\r\nMCDI_DECLARE_BUF_ERR(outbuf);\r\nstruct efx_nic *efx = tx_queue->efx;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, FINI_TXQ_IN_INSTANCE,\r\ntx_queue->queue);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FINI_TXQ, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc && rc != -EALREADY)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nefx_mcdi_display_error(efx, MC_CMD_FINI_TXQ, MC_CMD_FINI_TXQ_IN_LEN,\r\noutbuf, outlen, rc);\r\n}\r\nstatic void efx_ef10_tx_remove(struct efx_tx_queue *tx_queue)\r\n{\r\nefx_nic_free_buffer(tx_queue->efx, &tx_queue->txd.buf);\r\n}\r\nstatic inline void efx_ef10_notify_tx_desc(struct efx_tx_queue *tx_queue)\r\n{\r\nunsigned int write_ptr;\r\nefx_dword_t reg;\r\nwrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\r\nEFX_POPULATE_DWORD_1(reg, ERF_DZ_TX_DESC_WPTR_DWORD, write_ptr);\r\nefx_writed_page(tx_queue->efx, &reg,\r\nER_DZ_TX_DESC_UPD_DWORD, tx_queue->queue);\r\n}\r\nstatic unsigned int efx_ef10_tx_limit_len(struct efx_tx_queue *tx_queue,\r\ndma_addr_t dma_addr, unsigned int len)\r\n{\r\nif (len > EFX_EF10_MAX_TX_DESCRIPTOR_LEN) {\r\ndma_addr_t end = dma_addr + EFX_EF10_MAX_TX_DESCRIPTOR_LEN;\r\nBUILD_BUG_ON(EFX_EF10_MAX_TX_DESCRIPTOR_LEN < EFX_PAGE_SIZE);\r\nlen = (end & (~(EFX_PAGE_SIZE - 1))) - dma_addr;\r\n}\r\nreturn len;\r\n}\r\nstatic void efx_ef10_tx_write(struct efx_tx_queue *tx_queue)\r\n{\r\nunsigned int old_write_count = tx_queue->write_count;\r\nstruct efx_tx_buffer *buffer;\r\nunsigned int write_ptr;\r\nefx_qword_t *txd;\r\ntx_queue->xmit_more_available = false;\r\nif (unlikely(tx_queue->write_count == tx_queue->insert_count))\r\nreturn;\r\ndo {\r\nwrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\r\nbuffer = &tx_queue->buffer[write_ptr];\r\ntxd = efx_tx_desc(tx_queue, write_ptr);\r\n++tx_queue->write_count;\r\nif (buffer->flags & EFX_TX_BUF_OPTION) {\r\n*txd = buffer->option;\r\nif (EFX_QWORD_FIELD(*txd, ESF_DZ_TX_OPTION_TYPE) == 1)\r\ntx_queue->packet_write_count = tx_queue->write_count;\r\n} else {\r\ntx_queue->packet_write_count = tx_queue->write_count;\r\nBUILD_BUG_ON(EFX_TX_BUF_CONT != 1);\r\nEFX_POPULATE_QWORD_3(\r\n*txd,\r\nESF_DZ_TX_KER_CONT,\r\nbuffer->flags & EFX_TX_BUF_CONT,\r\nESF_DZ_TX_KER_BYTE_CNT, buffer->len,\r\nESF_DZ_TX_KER_BUF_ADDR, buffer->dma_addr);\r\n}\r\n} while (tx_queue->write_count != tx_queue->insert_count);\r\nwmb();\r\nif (efx_nic_may_push_tx_desc(tx_queue, old_write_count)) {\r\ntxd = efx_tx_desc(tx_queue,\r\nold_write_count & tx_queue->ptr_mask);\r\nefx_ef10_push_tx_desc(tx_queue, txd);\r\n++tx_queue->pushes;\r\n} else {\r\nefx_ef10_notify_tx_desc(tx_queue);\r\n}\r\n}\r\nstatic int efx_ef10_get_rss_flags(struct efx_nic *efx, u32 context, u32 *flags)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_RSS_CONTEXT_GET_FLAGS_OUT_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_RSS_CONTEXT_GET_FLAGS_OUT_LEN);\r\nsize_t outlen;\r\nint rc;\r\nBUILD_BUG_ON(MC_CMD_RSS_CONTEXT_GET_FLAGS_IN_LEN != MC_CMD_RSS_CONTEXT_GET_FLAGS_OUT_FLAGS_OFST);\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_GET_FLAGS_IN_RSS_CONTEXT_ID, context);\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_GET_FLAGS_OUT_FLAGS,\r\nRSS_CONTEXT_FLAGS_DEFAULT);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_GET_FLAGS, inbuf,\r\nsizeof(inbuf), outbuf, sizeof(outbuf), &outlen);\r\nif (rc == 0) {\r\nif (outlen < MC_CMD_RSS_CONTEXT_GET_FLAGS_OUT_LEN)\r\nrc = -EIO;\r\nelse\r\n*flags = MCDI_DWORD(outbuf, RSS_CONTEXT_GET_FLAGS_OUT_FLAGS);\r\n}\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_set_rss_flags(struct efx_nic *efx, u32 context)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_RSS_CONTEXT_SET_FLAGS_IN_LEN);\r\nu32 flags;\r\nBUILD_BUG_ON(MC_CMD_RSS_CONTEXT_SET_FLAGS_OUT_LEN != 0);\r\nif (efx_ef10_get_rss_flags(efx, context, &flags) != 0)\r\nreturn;\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_SET_FLAGS_IN_RSS_CONTEXT_ID, context);\r\nflags |= RSS_MODE_HASH_PORTS << MC_CMD_RSS_CONTEXT_GET_FLAGS_OUT_UDP_IPV4_RSS_MODE_LBN;\r\nflags |= RSS_MODE_HASH_PORTS << MC_CMD_RSS_CONTEXT_GET_FLAGS_OUT_UDP_IPV6_RSS_MODE_LBN;\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_SET_FLAGS_IN_FLAGS, flags);\r\nif (!efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_SET_FLAGS, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL))\r\nefx->rx_hash_udp_4tuple = true;\r\n}\r\nstatic int efx_ef10_alloc_rss_context(struct efx_nic *efx, u32 *context,\r\nbool exclusive, unsigned *context_size)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_RSS_CONTEXT_ALLOC_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_RSS_CONTEXT_ALLOC_OUT_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t outlen;\r\nint rc;\r\nu32 alloc_type = exclusive ?\r\nMC_CMD_RSS_CONTEXT_ALLOC_IN_TYPE_EXCLUSIVE :\r\nMC_CMD_RSS_CONTEXT_ALLOC_IN_TYPE_SHARED;\r\nunsigned rss_spread = exclusive ?\r\nefx->rss_spread :\r\nmin(rounddown_pow_of_two(efx->rss_spread),\r\nEFX_EF10_MAX_SHARED_RSS_CONTEXT_SIZE);\r\nif (!exclusive && rss_spread == 1) {\r\n*context = EFX_EF10_RSS_CONTEXT_INVALID;\r\nif (context_size)\r\n*context_size = 1;\r\nreturn 0;\r\n}\r\nif (nic_data->datapath_caps &\r\n1 << MC_CMD_GET_CAPABILITIES_OUT_RX_RSS_LIMITED_LBN)\r\nreturn -EOPNOTSUPP;\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_ALLOC_IN_UPSTREAM_PORT_ID,\r\nnic_data->vport_id);\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_ALLOC_IN_TYPE, alloc_type);\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_ALLOC_IN_NUM_QUEUES, rss_spread);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_ALLOC, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (outlen < MC_CMD_RSS_CONTEXT_ALLOC_OUT_LEN)\r\nreturn -EIO;\r\n*context = MCDI_DWORD(outbuf, RSS_CONTEXT_ALLOC_OUT_RSS_CONTEXT_ID);\r\nif (context_size)\r\n*context_size = rss_spread;\r\nif (nic_data->datapath_caps &\r\n1 << MC_CMD_GET_CAPABILITIES_OUT_ADDITIONAL_RSS_MODES_LBN)\r\nefx_ef10_set_rss_flags(efx, *context);\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_free_rss_context(struct efx_nic *efx, u32 context)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_RSS_CONTEXT_FREE_IN_LEN);\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_FREE_IN_RSS_CONTEXT_ID,\r\ncontext);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_FREE, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nWARN_ON(rc != 0);\r\n}\r\nstatic int efx_ef10_populate_rss_table(struct efx_nic *efx, u32 context,\r\nconst u32 *rx_indir_table, const u8 *key)\r\n{\r\nMCDI_DECLARE_BUF(tablebuf, MC_CMD_RSS_CONTEXT_SET_TABLE_IN_LEN);\r\nMCDI_DECLARE_BUF(keybuf, MC_CMD_RSS_CONTEXT_SET_KEY_IN_LEN);\r\nint i, rc;\r\nMCDI_SET_DWORD(tablebuf, RSS_CONTEXT_SET_TABLE_IN_RSS_CONTEXT_ID,\r\ncontext);\r\nBUILD_BUG_ON(ARRAY_SIZE(efx->rx_indir_table) !=\r\nMC_CMD_RSS_CONTEXT_SET_TABLE_IN_INDIRECTION_TABLE_LEN);\r\nfor (i = 0; i < ARRAY_SIZE(efx->rx_indir_table); ++i)\r\nMCDI_PTR(tablebuf,\r\nRSS_CONTEXT_SET_TABLE_IN_INDIRECTION_TABLE)[i] =\r\n(u8) rx_indir_table[i];\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_SET_TABLE, tablebuf,\r\nsizeof(tablebuf), NULL, 0, NULL);\r\nif (rc != 0)\r\nreturn rc;\r\nMCDI_SET_DWORD(keybuf, RSS_CONTEXT_SET_KEY_IN_RSS_CONTEXT_ID,\r\ncontext);\r\nBUILD_BUG_ON(ARRAY_SIZE(efx->rx_hash_key) !=\r\nMC_CMD_RSS_CONTEXT_SET_KEY_IN_TOEPLITZ_KEY_LEN);\r\nfor (i = 0; i < ARRAY_SIZE(efx->rx_hash_key); ++i)\r\nMCDI_PTR(keybuf, RSS_CONTEXT_SET_KEY_IN_TOEPLITZ_KEY)[i] = key[i];\r\nreturn efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_SET_KEY, keybuf,\r\nsizeof(keybuf), NULL, 0, NULL);\r\n}\r\nstatic void efx_ef10_rx_free_indir_table(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (nic_data->rx_rss_context != EFX_EF10_RSS_CONTEXT_INVALID)\r\nefx_ef10_free_rss_context(efx, nic_data->rx_rss_context);\r\nnic_data->rx_rss_context = EFX_EF10_RSS_CONTEXT_INVALID;\r\n}\r\nstatic int efx_ef10_rx_push_shared_rss_config(struct efx_nic *efx,\r\nunsigned *context_size)\r\n{\r\nu32 new_rx_rss_context;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc = efx_ef10_alloc_rss_context(efx, &new_rx_rss_context,\r\nfalse, context_size);\r\nif (rc != 0)\r\nreturn rc;\r\nnic_data->rx_rss_context = new_rx_rss_context;\r\nnic_data->rx_rss_context_exclusive = false;\r\nefx_set_default_rx_indir_table(efx);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_rx_push_exclusive_rss_config(struct efx_nic *efx,\r\nconst u32 *rx_indir_table,\r\nconst u8 *key)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc;\r\nu32 new_rx_rss_context;\r\nif (nic_data->rx_rss_context == EFX_EF10_RSS_CONTEXT_INVALID ||\r\n!nic_data->rx_rss_context_exclusive) {\r\nrc = efx_ef10_alloc_rss_context(efx, &new_rx_rss_context,\r\ntrue, NULL);\r\nif (rc == -EOPNOTSUPP)\r\nreturn rc;\r\nelse if (rc != 0)\r\ngoto fail1;\r\n} else {\r\nnew_rx_rss_context = nic_data->rx_rss_context;\r\n}\r\nrc = efx_ef10_populate_rss_table(efx, new_rx_rss_context,\r\nrx_indir_table, key);\r\nif (rc != 0)\r\ngoto fail2;\r\nif (nic_data->rx_rss_context != new_rx_rss_context)\r\nefx_ef10_rx_free_indir_table(efx);\r\nnic_data->rx_rss_context = new_rx_rss_context;\r\nnic_data->rx_rss_context_exclusive = true;\r\nif (rx_indir_table != efx->rx_indir_table)\r\nmemcpy(efx->rx_indir_table, rx_indir_table,\r\nsizeof(efx->rx_indir_table));\r\nif (key != efx->rx_hash_key)\r\nmemcpy(efx->rx_hash_key, key, efx->type->rx_hash_key_size);\r\nreturn 0;\r\nfail2:\r\nif (new_rx_rss_context != nic_data->rx_rss_context)\r\nefx_ef10_free_rss_context(efx, new_rx_rss_context);\r\nfail1:\r\nnetif_err(efx, hw, efx->net_dev, "%s: failed rc=%d\n", __func__, rc);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_rx_pull_rss_config(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_RSS_CONTEXT_GET_TABLE_IN_LEN);\r\nMCDI_DECLARE_BUF(tablebuf, MC_CMD_RSS_CONTEXT_GET_TABLE_OUT_LEN);\r\nMCDI_DECLARE_BUF(keybuf, MC_CMD_RSS_CONTEXT_GET_KEY_OUT_LEN);\r\nsize_t outlen;\r\nint rc, i;\r\nBUILD_BUG_ON(MC_CMD_RSS_CONTEXT_GET_TABLE_IN_LEN !=\r\nMC_CMD_RSS_CONTEXT_GET_KEY_IN_LEN);\r\nif (nic_data->rx_rss_context == EFX_EF10_RSS_CONTEXT_INVALID)\r\nreturn -ENOENT;\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_GET_TABLE_IN_RSS_CONTEXT_ID,\r\nnic_data->rx_rss_context);\r\nBUILD_BUG_ON(ARRAY_SIZE(efx->rx_indir_table) !=\r\nMC_CMD_RSS_CONTEXT_GET_TABLE_OUT_INDIRECTION_TABLE_LEN);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_GET_TABLE, inbuf, sizeof(inbuf),\r\ntablebuf, sizeof(tablebuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (WARN_ON(outlen != MC_CMD_RSS_CONTEXT_GET_TABLE_OUT_LEN))\r\nreturn -EIO;\r\nfor (i = 0; i < ARRAY_SIZE(efx->rx_indir_table); i++)\r\nefx->rx_indir_table[i] = MCDI_PTR(tablebuf,\r\nRSS_CONTEXT_GET_TABLE_OUT_INDIRECTION_TABLE)[i];\r\nMCDI_SET_DWORD(inbuf, RSS_CONTEXT_GET_KEY_IN_RSS_CONTEXT_ID,\r\nnic_data->rx_rss_context);\r\nBUILD_BUG_ON(ARRAY_SIZE(efx->rx_hash_key) !=\r\nMC_CMD_RSS_CONTEXT_SET_KEY_IN_TOEPLITZ_KEY_LEN);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_RSS_CONTEXT_GET_KEY, inbuf, sizeof(inbuf),\r\nkeybuf, sizeof(keybuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (WARN_ON(outlen != MC_CMD_RSS_CONTEXT_GET_KEY_OUT_LEN))\r\nreturn -EIO;\r\nfor (i = 0; i < ARRAY_SIZE(efx->rx_hash_key); ++i)\r\nefx->rx_hash_key[i] = MCDI_PTR(\r\nkeybuf, RSS_CONTEXT_GET_KEY_OUT_TOEPLITZ_KEY)[i];\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_pf_rx_push_rss_config(struct efx_nic *efx, bool user,\r\nconst u32 *rx_indir_table,\r\nconst u8 *key)\r\n{\r\nint rc;\r\nif (efx->rss_spread == 1)\r\nreturn 0;\r\nif (!key)\r\nkey = efx->rx_hash_key;\r\nrc = efx_ef10_rx_push_exclusive_rss_config(efx, rx_indir_table, key);\r\nif (rc == -ENOBUFS && !user) {\r\nunsigned context_size;\r\nbool mismatch = false;\r\nsize_t i;\r\nfor (i = 0; i < ARRAY_SIZE(efx->rx_indir_table) && !mismatch;\r\ni++)\r\nmismatch = rx_indir_table[i] !=\r\nethtool_rxfh_indir_default(i, efx->rss_spread);\r\nrc = efx_ef10_rx_push_shared_rss_config(efx, &context_size);\r\nif (rc == 0) {\r\nif (context_size != efx->rss_spread)\r\nnetif_warn(efx, probe, efx->net_dev,\r\n"Could not allocate an exclusive RSS"\r\n" context; allocated a shared one of"\r\n" different size."\r\n" Wanted %u, got %u.\n",\r\nefx->rss_spread, context_size);\r\nelse if (mismatch)\r\nnetif_warn(efx, probe, efx->net_dev,\r\n"Could not allocate an exclusive RSS"\r\n" context; allocated a shared one but"\r\n" could not apply custom"\r\n" indirection.\n");\r\nelse\r\nnetif_info(efx, probe, efx->net_dev,\r\n"Could not allocate an exclusive RSS"\r\n" context; allocated a shared one.\n");\r\n}\r\n}\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_rx_probe(struct efx_rx_queue *rx_queue)\r\n{\r\nreturn efx_nic_alloc_buffer(rx_queue->efx, &rx_queue->rxd.buf,\r\n(rx_queue->ptr_mask + 1) *\r\nsizeof(efx_qword_t),\r\nGFP_KERNEL);\r\n}\r\nstatic void efx_ef10_rx_init(struct efx_rx_queue *rx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_INIT_RXQ_IN_LEN(EFX_MAX_DMAQ_SIZE * 8 /\r\nEFX_BUF_SIZE));\r\nstruct efx_channel *channel = efx_rx_queue_channel(rx_queue);\r\nsize_t entries = rx_queue->rxd.buf.len / EFX_BUF_SIZE;\r\nstruct efx_nic *efx = rx_queue->efx;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t inlen;\r\ndma_addr_t dma_addr;\r\nint rc;\r\nint i;\r\nBUILD_BUG_ON(MC_CMD_INIT_RXQ_OUT_LEN != 0);\r\nrx_queue->scatter_n = 0;\r\nrx_queue->scatter_len = 0;\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_SIZE, rx_queue->ptr_mask + 1);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_TARGET_EVQ, channel->channel);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_LABEL, efx_rx_queue_index(rx_queue));\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_INSTANCE,\r\nefx_rx_queue_index(rx_queue));\r\nMCDI_POPULATE_DWORD_2(inbuf, INIT_RXQ_IN_FLAGS,\r\nINIT_RXQ_IN_FLAG_PREFIX, 1,\r\nINIT_RXQ_IN_FLAG_TIMESTAMP, 1);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_OWNER_ID, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_RXQ_IN_PORT_ID, nic_data->vport_id);\r\ndma_addr = rx_queue->rxd.buf.dma_addr;\r\nnetif_dbg(efx, hw, efx->net_dev, "pushing RXQ %d. %zu entries (%llx)\n",\r\nefx_rx_queue_index(rx_queue), entries, (u64)dma_addr);\r\nfor (i = 0; i < entries; ++i) {\r\nMCDI_SET_ARRAY_QWORD(inbuf, INIT_RXQ_IN_DMA_ADDR, i, dma_addr);\r\ndma_addr += EFX_BUF_SIZE;\r\n}\r\ninlen = MC_CMD_INIT_RXQ_IN_LEN(entries);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_INIT_RXQ, inbuf, inlen,\r\nNULL, 0, NULL);\r\nif (rc)\r\nnetdev_WARN(efx->net_dev, "failed to initialise RXQ %d\n",\r\nefx_rx_queue_index(rx_queue));\r\n}\r\nstatic void efx_ef10_rx_fini(struct efx_rx_queue *rx_queue)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FINI_RXQ_IN_LEN);\r\nMCDI_DECLARE_BUF_ERR(outbuf);\r\nstruct efx_nic *efx = rx_queue->efx;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, FINI_RXQ_IN_INSTANCE,\r\nefx_rx_queue_index(rx_queue));\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FINI_RXQ, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc && rc != -EALREADY)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nefx_mcdi_display_error(efx, MC_CMD_FINI_RXQ, MC_CMD_FINI_RXQ_IN_LEN,\r\noutbuf, outlen, rc);\r\n}\r\nstatic void efx_ef10_rx_remove(struct efx_rx_queue *rx_queue)\r\n{\r\nefx_nic_free_buffer(rx_queue->efx, &rx_queue->rxd.buf);\r\n}\r\nstatic inline void\r\nefx_ef10_build_rx_desc(struct efx_rx_queue *rx_queue, unsigned int index)\r\n{\r\nstruct efx_rx_buffer *rx_buf;\r\nefx_qword_t *rxd;\r\nrxd = efx_rx_desc(rx_queue, index);\r\nrx_buf = efx_rx_buffer(rx_queue, index);\r\nEFX_POPULATE_QWORD_2(*rxd,\r\nESF_DZ_RX_KER_BYTE_CNT, rx_buf->len,\r\nESF_DZ_RX_KER_BUF_ADDR, rx_buf->dma_addr);\r\n}\r\nstatic void efx_ef10_rx_write(struct efx_rx_queue *rx_queue)\r\n{\r\nstruct efx_nic *efx = rx_queue->efx;\r\nunsigned int write_count;\r\nefx_dword_t reg;\r\nwrite_count = rx_queue->added_count & ~7;\r\nif (rx_queue->notified_count == write_count)\r\nreturn;\r\ndo\r\nefx_ef10_build_rx_desc(\r\nrx_queue,\r\nrx_queue->notified_count & rx_queue->ptr_mask);\r\nwhile (++rx_queue->notified_count != write_count);\r\nwmb();\r\nEFX_POPULATE_DWORD_1(reg, ERF_DZ_RX_DESC_WPTR,\r\nwrite_count & rx_queue->ptr_mask);\r\nefx_writed_page(efx, &reg, ER_DZ_RX_DESC_UPD,\r\nefx_rx_queue_index(rx_queue));\r\n}\r\nstatic void efx_ef10_rx_defer_refill(struct efx_rx_queue *rx_queue)\r\n{\r\nstruct efx_channel *channel = efx_rx_queue_channel(rx_queue);\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_DRIVER_EVENT_IN_LEN);\r\nefx_qword_t event;\r\nEFX_POPULATE_QWORD_2(event,\r\nESF_DZ_EV_CODE, EFX_EF10_DRVGEN_EV,\r\nESF_DZ_EV_DATA, EFX_EF10_REFILL);\r\nMCDI_SET_DWORD(inbuf, DRIVER_EVENT_IN_EVQ, channel->channel);\r\nmemcpy(MCDI_PTR(inbuf, DRIVER_EVENT_IN_DATA), &event.u64[0],\r\nsizeof(efx_qword_t));\r\nefx_mcdi_rpc_async(channel->efx, MC_CMD_DRIVER_EVENT,\r\ninbuf, sizeof(inbuf), 0,\r\nefx_ef10_rx_defer_refill_complete, 0);\r\n}\r\nstatic void\r\nefx_ef10_rx_defer_refill_complete(struct efx_nic *efx, unsigned long cookie,\r\nint rc, efx_dword_t *outbuf,\r\nsize_t outlen_actual)\r\n{\r\n}\r\nstatic int efx_ef10_ev_probe(struct efx_channel *channel)\r\n{\r\nreturn efx_nic_alloc_buffer(channel->efx, &channel->eventq.buf,\r\n(channel->eventq_mask + 1) *\r\nsizeof(efx_qword_t),\r\nGFP_KERNEL);\r\n}\r\nstatic void efx_ef10_ev_fini(struct efx_channel *channel)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FINI_EVQ_IN_LEN);\r\nMCDI_DECLARE_BUF_ERR(outbuf);\r\nstruct efx_nic *efx = channel->efx;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, FINI_EVQ_IN_INSTANCE, channel->channel);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FINI_EVQ, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc && rc != -EALREADY)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nefx_mcdi_display_error(efx, MC_CMD_FINI_EVQ, MC_CMD_FINI_EVQ_IN_LEN,\r\noutbuf, outlen, rc);\r\n}\r\nstatic int efx_ef10_ev_init(struct efx_channel *channel)\r\n{\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_INIT_EVQ_V2_IN_LEN(EFX_MAX_EVQ_SIZE * 8 /\r\nEFX_BUF_SIZE));\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_INIT_EVQ_V2_OUT_LEN);\r\nsize_t entries = channel->eventq.buf.len / EFX_BUF_SIZE;\r\nstruct efx_nic *efx = channel->efx;\r\nstruct efx_ef10_nic_data *nic_data;\r\nsize_t inlen, outlen;\r\nunsigned int enabled, implemented;\r\ndma_addr_t dma_addr;\r\nint rc;\r\nint i;\r\nnic_data = efx->nic_data;\r\nmemset(channel->eventq.buf.addr, 0xff, channel->eventq.buf.len);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_SIZE, channel->eventq_mask + 1);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_INSTANCE, channel->channel);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_IRQ_NUM, channel->channel);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_TMR_MODE,\r\nMC_CMD_INIT_EVQ_IN_TMR_MODE_DIS);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_TMR_LOAD, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_TMR_RELOAD, 0);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_COUNT_MODE,\r\nMC_CMD_INIT_EVQ_IN_COUNT_MODE_DIS);\r\nMCDI_SET_DWORD(inbuf, INIT_EVQ_IN_COUNT_THRSHLD, 0);\r\nif (nic_data->datapath_caps2 &\r\n1 << MC_CMD_GET_CAPABILITIES_V2_OUT_INIT_EVQ_V2_LBN) {\r\nMCDI_POPULATE_DWORD_2(inbuf, INIT_EVQ_V2_IN_FLAGS,\r\nINIT_EVQ_V2_IN_FLAG_INTERRUPTING, 1,\r\nINIT_EVQ_V2_IN_FLAG_TYPE,\r\nMC_CMD_INIT_EVQ_V2_IN_FLAG_TYPE_AUTO);\r\n} else {\r\nbool cut_thru = !(nic_data->datapath_caps &\r\n1 << MC_CMD_GET_CAPABILITIES_OUT_RX_BATCHING_LBN);\r\nMCDI_POPULATE_DWORD_4(inbuf, INIT_EVQ_IN_FLAGS,\r\nINIT_EVQ_IN_FLAG_INTERRUPTING, 1,\r\nINIT_EVQ_IN_FLAG_RX_MERGE, 1,\r\nINIT_EVQ_IN_FLAG_TX_MERGE, 1,\r\nINIT_EVQ_IN_FLAG_CUT_THRU, cut_thru);\r\n}\r\ndma_addr = channel->eventq.buf.dma_addr;\r\nfor (i = 0; i < entries; ++i) {\r\nMCDI_SET_ARRAY_QWORD(inbuf, INIT_EVQ_IN_DMA_ADDR, i, dma_addr);\r\ndma_addr += EFX_BUF_SIZE;\r\n}\r\ninlen = MC_CMD_INIT_EVQ_IN_LEN(entries);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_INIT_EVQ, inbuf, inlen,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (outlen >= MC_CMD_INIT_EVQ_V2_OUT_LEN)\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"Channel %d using event queue flags %08x\n",\r\nchannel->channel,\r\nMCDI_DWORD(outbuf, INIT_EVQ_V2_OUT_FLAGS));\r\nif (channel->channel || rc)\r\nreturn rc;\r\nrc = efx_mcdi_get_workarounds(efx, &implemented, &enabled);\r\nif (rc == -ENOSYS) {\r\nnic_data->workaround_26807 = false;\r\nrc = 0;\r\n} else if (rc) {\r\ngoto fail;\r\n} else {\r\nnic_data->workaround_26807 =\r\n!!(enabled & MC_CMD_GET_WORKAROUNDS_OUT_BUG26807);\r\nif (implemented & MC_CMD_GET_WORKAROUNDS_OUT_BUG26807 &&\r\n!nic_data->workaround_26807) {\r\nunsigned int flags;\r\nrc = efx_mcdi_set_workaround(efx,\r\nMC_CMD_WORKAROUND_BUG26807,\r\ntrue, &flags);\r\nif (!rc) {\r\nif (flags &\r\n1 << MC_CMD_WORKAROUND_EXT_OUT_FLR_DONE_LBN) {\r\nnetif_info(efx, drv, efx->net_dev,\r\n"other functions on NIC have been reset\n");\r\nrc = efx_ef10_get_warm_boot_count(efx);\r\nif (rc >= 0) {\r\nnic_data->warm_boot_count = rc;\r\nrc = 0;\r\n}\r\n}\r\nnic_data->workaround_26807 = true;\r\n} else if (rc == -EPERM) {\r\nrc = 0;\r\n}\r\n}\r\n}\r\nif (!rc)\r\nreturn 0;\r\nfail:\r\nefx_ef10_ev_fini(channel);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_ev_remove(struct efx_channel *channel)\r\n{\r\nefx_nic_free_buffer(channel->efx, &channel->eventq.buf);\r\n}\r\nstatic void efx_ef10_handle_rx_wrong_queue(struct efx_rx_queue *rx_queue,\r\nunsigned int rx_queue_label)\r\n{\r\nstruct efx_nic *efx = rx_queue->efx;\r\nnetif_info(efx, hw, efx->net_dev,\r\n"rx event arrived on queue %d labeled as queue %u\n",\r\nefx_rx_queue_index(rx_queue), rx_queue_label);\r\nefx_schedule_reset(efx, RESET_TYPE_DISABLE);\r\n}\r\nstatic void\r\nefx_ef10_handle_rx_bad_lbits(struct efx_rx_queue *rx_queue,\r\nunsigned int actual, unsigned int expected)\r\n{\r\nunsigned int dropped = (actual - expected) & rx_queue->ptr_mask;\r\nstruct efx_nic *efx = rx_queue->efx;\r\nnetif_info(efx, hw, efx->net_dev,\r\n"dropped %d events (index=%d expected=%d)\n",\r\ndropped, actual, expected);\r\nefx_schedule_reset(efx, RESET_TYPE_DISABLE);\r\n}\r\nstatic void efx_ef10_handle_rx_abort(struct efx_rx_queue *rx_queue)\r\n{\r\nunsigned int rx_desc_ptr;\r\nnetif_dbg(rx_queue->efx, hw, rx_queue->efx->net_dev,\r\n"scattered RX aborted (dropping %u buffers)\n",\r\nrx_queue->scatter_n);\r\nrx_desc_ptr = rx_queue->removed_count & rx_queue->ptr_mask;\r\nefx_rx_packet(rx_queue, rx_desc_ptr, rx_queue->scatter_n,\r\n0, EFX_RX_PKT_DISCARD);\r\nrx_queue->removed_count += rx_queue->scatter_n;\r\nrx_queue->scatter_n = 0;\r\nrx_queue->scatter_len = 0;\r\n++efx_rx_queue_channel(rx_queue)->n_rx_nodesc_trunc;\r\n}\r\nstatic u16 efx_ef10_handle_rx_event_errors(struct efx_channel *channel,\r\nunsigned int n_packets,\r\nunsigned int rx_encap_hdr,\r\nunsigned int rx_l3_class,\r\nunsigned int rx_l4_class,\r\nconst efx_qword_t *event)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nif (EFX_QWORD_FIELD(*event, ESF_DZ_RX_ECRC_ERR)) {\r\nif (!efx->loopback_selftest)\r\nchannel->n_rx_eth_crc_err += n_packets;\r\nreturn EFX_RX_PKT_DISCARD;\r\n}\r\nif (EFX_QWORD_FIELD(*event, ESF_DZ_RX_IPCKSUM_ERR)) {\r\nif (unlikely(rx_encap_hdr != ESE_EZ_ENCAP_HDR_VXLAN &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP4 &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP4_FRAG &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP6 &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP6_FRAG))\r\nnetdev_WARN(efx->net_dev,\r\n"invalid class for RX_IPCKSUM_ERR: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nif (!efx->loopback_selftest)\r\n*(rx_encap_hdr ?\r\n&channel->n_rx_outer_ip_hdr_chksum_err :\r\n&channel->n_rx_ip_hdr_chksum_err) += n_packets;\r\nreturn 0;\r\n}\r\nif (EFX_QWORD_FIELD(*event, ESF_DZ_RX_TCPUDP_CKSUM_ERR)) {\r\nif (unlikely(rx_encap_hdr != ESE_EZ_ENCAP_HDR_VXLAN &&\r\n((rx_l3_class != ESE_DZ_L3_CLASS_IP4 &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP6) ||\r\n(rx_l4_class != ESE_DZ_L4_CLASS_TCP &&\r\nrx_l4_class != ESE_DZ_L4_CLASS_UDP))))\r\nnetdev_WARN(efx->net_dev,\r\n"invalid class for RX_TCPUDP_CKSUM_ERR: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nif (!efx->loopback_selftest)\r\n*(rx_encap_hdr ?\r\n&channel->n_rx_outer_tcp_udp_chksum_err :\r\n&channel->n_rx_tcp_udp_chksum_err) += n_packets;\r\nreturn 0;\r\n}\r\nif (EFX_QWORD_FIELD(*event, ESF_EZ_RX_IP_INNER_CHKSUM_ERR)) {\r\nif (unlikely(!rx_encap_hdr))\r\nnetdev_WARN(efx->net_dev,\r\n"invalid encapsulation type for RX_IP_INNER_CHKSUM_ERR: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nelse if (unlikely(rx_l3_class != ESE_DZ_L3_CLASS_IP4 &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP4_FRAG &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP6 &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP6_FRAG))\r\nnetdev_WARN(efx->net_dev,\r\n"invalid class for RX_IP_INNER_CHKSUM_ERR: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nif (!efx->loopback_selftest)\r\nchannel->n_rx_inner_ip_hdr_chksum_err += n_packets;\r\nreturn 0;\r\n}\r\nif (EFX_QWORD_FIELD(*event, ESF_EZ_RX_TCP_UDP_INNER_CHKSUM_ERR)) {\r\nif (unlikely(!rx_encap_hdr))\r\nnetdev_WARN(efx->net_dev,\r\n"invalid encapsulation type for RX_TCP_UDP_INNER_CHKSUM_ERR: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nelse if (unlikely((rx_l3_class != ESE_DZ_L3_CLASS_IP4 &&\r\nrx_l3_class != ESE_DZ_L3_CLASS_IP6) ||\r\n(rx_l4_class != ESE_DZ_L4_CLASS_TCP &&\r\nrx_l4_class != ESE_DZ_L4_CLASS_UDP)))\r\nnetdev_WARN(efx->net_dev,\r\n"invalid class for RX_TCP_UDP_INNER_CHKSUM_ERR: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nif (!efx->loopback_selftest)\r\nchannel->n_rx_inner_tcp_udp_chksum_err += n_packets;\r\nreturn 0;\r\n}\r\nWARN_ON(1);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_handle_rx_event(struct efx_channel *channel,\r\nconst efx_qword_t *event)\r\n{\r\nunsigned int rx_bytes, next_ptr_lbits, rx_queue_label;\r\nunsigned int rx_l3_class, rx_l4_class, rx_encap_hdr;\r\nunsigned int n_descs, n_packets, i;\r\nstruct efx_nic *efx = channel->efx;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_rx_queue *rx_queue;\r\nefx_qword_t errors;\r\nbool rx_cont;\r\nu16 flags = 0;\r\nif (unlikely(ACCESS_ONCE(efx->reset_pending)))\r\nreturn 0;\r\nrx_bytes = EFX_QWORD_FIELD(*event, ESF_DZ_RX_BYTES);\r\nnext_ptr_lbits = EFX_QWORD_FIELD(*event, ESF_DZ_RX_DSC_PTR_LBITS);\r\nrx_queue_label = EFX_QWORD_FIELD(*event, ESF_DZ_RX_QLABEL);\r\nrx_l3_class = EFX_QWORD_FIELD(*event, ESF_DZ_RX_L3_CLASS);\r\nrx_l4_class = EFX_QWORD_FIELD(*event, ESF_DZ_RX_L4_CLASS);\r\nrx_cont = EFX_QWORD_FIELD(*event, ESF_DZ_RX_CONT);\r\nrx_encap_hdr =\r\nnic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VXLAN_NVGRE_LBN) ?\r\nEFX_QWORD_FIELD(*event, ESF_EZ_RX_ENCAP_HDR) :\r\nESE_EZ_ENCAP_HDR_NONE;\r\nif (EFX_QWORD_FIELD(*event, ESF_DZ_RX_DROP_EVENT))\r\nnetdev_WARN(efx->net_dev, "saw RX_DROP_EVENT: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\nrx_queue = efx_channel_get_rx_queue(channel);\r\nif (unlikely(rx_queue_label != efx_rx_queue_index(rx_queue)))\r\nefx_ef10_handle_rx_wrong_queue(rx_queue, rx_queue_label);\r\nn_descs = ((next_ptr_lbits - rx_queue->removed_count) &\r\n((1 << ESF_DZ_RX_DSC_PTR_LBITS_WIDTH) - 1));\r\nif (n_descs != rx_queue->scatter_n + 1) {\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (unlikely(n_descs == rx_queue->scatter_n)) {\r\nif (rx_queue->scatter_n == 0 || rx_bytes != 0)\r\nnetdev_WARN(efx->net_dev,\r\n"invalid RX abort: scatter_n=%u event="\r\nEFX_QWORD_FMT "\n",\r\nrx_queue->scatter_n,\r\nEFX_QWORD_VAL(*event));\r\nefx_ef10_handle_rx_abort(rx_queue);\r\nreturn 0;\r\n}\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_RX_BATCHING_LBN)) ||\r\nrx_queue->scatter_n != 0 || rx_cont) {\r\nefx_ef10_handle_rx_bad_lbits(\r\nrx_queue, next_ptr_lbits,\r\n(rx_queue->removed_count +\r\nrx_queue->scatter_n + 1) &\r\n((1 << ESF_DZ_RX_DSC_PTR_LBITS_WIDTH) - 1));\r\nreturn 0;\r\n}\r\nrx_queue->scatter_n = 1;\r\nrx_queue->scatter_len = 0;\r\nn_packets = n_descs;\r\n++channel->n_rx_merge_events;\r\nchannel->n_rx_merge_packets += n_packets;\r\nflags |= EFX_RX_PKT_PREFIX_LEN;\r\n} else {\r\n++rx_queue->scatter_n;\r\nrx_queue->scatter_len += rx_bytes;\r\nif (rx_cont)\r\nreturn 0;\r\nn_packets = 1;\r\n}\r\nEFX_POPULATE_QWORD_5(errors, ESF_DZ_RX_ECRC_ERR, 1,\r\nESF_DZ_RX_IPCKSUM_ERR, 1,\r\nESF_DZ_RX_TCPUDP_CKSUM_ERR, 1,\r\nESF_EZ_RX_IP_INNER_CHKSUM_ERR, 1,\r\nESF_EZ_RX_TCP_UDP_INNER_CHKSUM_ERR, 1);\r\nEFX_AND_QWORD(errors, *event, errors);\r\nif (unlikely(!EFX_QWORD_IS_ZERO(errors))) {\r\nflags |= efx_ef10_handle_rx_event_errors(channel, n_packets,\r\nrx_encap_hdr,\r\nrx_l3_class, rx_l4_class,\r\nevent);\r\n} else {\r\nbool tcpudp = rx_l4_class == ESE_DZ_L4_CLASS_TCP ||\r\nrx_l4_class == ESE_DZ_L4_CLASS_UDP;\r\nswitch (rx_encap_hdr) {\r\ncase ESE_EZ_ENCAP_HDR_VXLAN:\r\nflags |= EFX_RX_PKT_CSUMMED;\r\nif (tcpudp)\r\nflags |= EFX_RX_PKT_CSUM_LEVEL;\r\nbreak;\r\ncase ESE_EZ_ENCAP_HDR_GRE:\r\ncase ESE_EZ_ENCAP_HDR_NONE:\r\nif (tcpudp)\r\nflags |= EFX_RX_PKT_CSUMMED;\r\nbreak;\r\ndefault:\r\nnetdev_WARN(efx->net_dev,\r\n"unknown encapsulation type: event="\r\nEFX_QWORD_FMT "\n",\r\nEFX_QWORD_VAL(*event));\r\n}\r\n}\r\nif (rx_l4_class == ESE_DZ_L4_CLASS_TCP)\r\nflags |= EFX_RX_PKT_TCP;\r\nchannel->irq_mod_score += 2 * n_packets;\r\nfor (i = 0; i < n_packets; i++) {\r\nefx_rx_packet(rx_queue,\r\nrx_queue->removed_count & rx_queue->ptr_mask,\r\nrx_queue->scatter_n, rx_queue->scatter_len,\r\nflags);\r\nrx_queue->removed_count += rx_queue->scatter_n;\r\n}\r\nrx_queue->scatter_n = 0;\r\nrx_queue->scatter_len = 0;\r\nreturn n_packets;\r\n}\r\nstatic int\r\nefx_ef10_handle_tx_event(struct efx_channel *channel, efx_qword_t *event)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nstruct efx_tx_queue *tx_queue;\r\nunsigned int tx_ev_desc_ptr;\r\nunsigned int tx_ev_q_label;\r\nint tx_descs = 0;\r\nif (unlikely(ACCESS_ONCE(efx->reset_pending)))\r\nreturn 0;\r\nif (unlikely(EFX_QWORD_FIELD(*event, ESF_DZ_TX_DROP_EVENT)))\r\nreturn 0;\r\ntx_ev_desc_ptr = EFX_QWORD_FIELD(*event, ESF_DZ_TX_DESCR_INDX);\r\ntx_ev_q_label = EFX_QWORD_FIELD(*event, ESF_DZ_TX_QLABEL);\r\ntx_queue = efx_channel_get_tx_queue(channel,\r\ntx_ev_q_label % EFX_TXQ_TYPES);\r\ntx_descs = ((tx_ev_desc_ptr + 1 - tx_queue->read_count) &\r\ntx_queue->ptr_mask);\r\nefx_xmit_done(tx_queue, tx_ev_desc_ptr & tx_queue->ptr_mask);\r\nreturn tx_descs;\r\n}\r\nstatic void\r\nefx_ef10_handle_driver_event(struct efx_channel *channel, efx_qword_t *event)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nint subcode;\r\nsubcode = EFX_QWORD_FIELD(*event, ESF_DZ_DRV_SUB_CODE);\r\nswitch (subcode) {\r\ncase ESE_DZ_DRV_TIMER_EV:\r\ncase ESE_DZ_DRV_WAKE_UP_EV:\r\nbreak;\r\ncase ESE_DZ_DRV_START_UP_EV:\r\nbreak;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"channel %d unknown driver event type %d"\r\n" (data " EFX_QWORD_FMT ")\n",\r\nchannel->channel, subcode,\r\nEFX_QWORD_VAL(*event));\r\n}\r\n}\r\nstatic void efx_ef10_handle_driver_generated_event(struct efx_channel *channel,\r\nefx_qword_t *event)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nu32 subcode;\r\nsubcode = EFX_QWORD_FIELD(*event, EFX_DWORD_0);\r\nswitch (subcode) {\r\ncase EFX_EF10_TEST:\r\nchannel->event_test_cpu = raw_smp_processor_id();\r\nbreak;\r\ncase EFX_EF10_REFILL:\r\nefx_fast_push_rx_descriptors(&channel->rx_queue, true);\r\nbreak;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"channel %d unknown driver event type %u"\r\n" (data " EFX_QWORD_FMT ")\n",\r\nchannel->channel, (unsigned) subcode,\r\nEFX_QWORD_VAL(*event));\r\n}\r\n}\r\nstatic int efx_ef10_ev_process(struct efx_channel *channel, int quota)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nefx_qword_t event, *p_event;\r\nunsigned int read_ptr;\r\nint ev_code;\r\nint tx_descs = 0;\r\nint spent = 0;\r\nif (quota <= 0)\r\nreturn spent;\r\nread_ptr = channel->eventq_read_ptr;\r\nfor (;;) {\r\np_event = efx_event(channel, read_ptr);\r\nevent = *p_event;\r\nif (!efx_event_present(&event))\r\nbreak;\r\nEFX_SET_QWORD(*p_event);\r\n++read_ptr;\r\nev_code = EFX_QWORD_FIELD(event, ESF_DZ_EV_CODE);\r\nnetif_vdbg(efx, drv, efx->net_dev,\r\n"processing event on %d " EFX_QWORD_FMT "\n",\r\nchannel->channel, EFX_QWORD_VAL(event));\r\nswitch (ev_code) {\r\ncase ESE_DZ_EV_CODE_MCDI_EV:\r\nefx_mcdi_process_event(channel, &event);\r\nbreak;\r\ncase ESE_DZ_EV_CODE_RX_EV:\r\nspent += efx_ef10_handle_rx_event(channel, &event);\r\nif (spent >= quota) {\r\nspent = quota;\r\ngoto out;\r\n}\r\nbreak;\r\ncase ESE_DZ_EV_CODE_TX_EV:\r\ntx_descs += efx_ef10_handle_tx_event(channel, &event);\r\nif (tx_descs > efx->txq_entries) {\r\nspent = quota;\r\ngoto out;\r\n} else if (++spent == quota) {\r\ngoto out;\r\n}\r\nbreak;\r\ncase ESE_DZ_EV_CODE_DRIVER_EV:\r\nefx_ef10_handle_driver_event(channel, &event);\r\nif (++spent == quota)\r\ngoto out;\r\nbreak;\r\ncase EFX_EF10_DRVGEN_EV:\r\nefx_ef10_handle_driver_generated_event(channel, &event);\r\nbreak;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"channel %d unknown event type %d"\r\n" (data " EFX_QWORD_FMT ")\n",\r\nchannel->channel, ev_code,\r\nEFX_QWORD_VAL(event));\r\n}\r\n}\r\nout:\r\nchannel->eventq_read_ptr = read_ptr;\r\nreturn spent;\r\n}\r\nstatic void efx_ef10_ev_read_ack(struct efx_channel *channel)\r\n{\r\nstruct efx_nic *efx = channel->efx;\r\nefx_dword_t rptr;\r\nif (EFX_EF10_WORKAROUND_35388(efx)) {\r\nBUILD_BUG_ON(EFX_MIN_EVQ_SIZE <\r\n(1 << ERF_DD_EVQ_IND_RPTR_WIDTH));\r\nBUILD_BUG_ON(EFX_MAX_EVQ_SIZE >\r\n(1 << 2 * ERF_DD_EVQ_IND_RPTR_WIDTH));\r\nEFX_POPULATE_DWORD_2(rptr, ERF_DD_EVQ_IND_RPTR_FLAGS,\r\nEFE_DD_EVQ_IND_RPTR_FLAGS_HIGH,\r\nERF_DD_EVQ_IND_RPTR,\r\n(channel->eventq_read_ptr &\r\nchannel->eventq_mask) >>\r\nERF_DD_EVQ_IND_RPTR_WIDTH);\r\nefx_writed_page(efx, &rptr, ER_DD_EVQ_INDIRECT,\r\nchannel->channel);\r\nEFX_POPULATE_DWORD_2(rptr, ERF_DD_EVQ_IND_RPTR_FLAGS,\r\nEFE_DD_EVQ_IND_RPTR_FLAGS_LOW,\r\nERF_DD_EVQ_IND_RPTR,\r\nchannel->eventq_read_ptr &\r\n((1 << ERF_DD_EVQ_IND_RPTR_WIDTH) - 1));\r\nefx_writed_page(efx, &rptr, ER_DD_EVQ_INDIRECT,\r\nchannel->channel);\r\n} else {\r\nEFX_POPULATE_DWORD_1(rptr, ERF_DZ_EVQ_RPTR,\r\nchannel->eventq_read_ptr &\r\nchannel->eventq_mask);\r\nefx_writed_page(efx, &rptr, ER_DZ_EVQ_RPTR, channel->channel);\r\n}\r\n}\r\nstatic void efx_ef10_ev_test_generate(struct efx_channel *channel)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_DRIVER_EVENT_IN_LEN);\r\nstruct efx_nic *efx = channel->efx;\r\nefx_qword_t event;\r\nint rc;\r\nEFX_POPULATE_QWORD_2(event,\r\nESF_DZ_EV_CODE, EFX_EF10_DRVGEN_EV,\r\nESF_DZ_EV_DATA, EFX_EF10_TEST);\r\nMCDI_SET_DWORD(inbuf, DRIVER_EVENT_IN_EVQ, channel->channel);\r\nmemcpy(MCDI_PTR(inbuf, DRIVER_EVENT_IN_DATA), &event.u64[0],\r\nsizeof(efx_qword_t));\r\nrc = efx_mcdi_rpc(efx, MC_CMD_DRIVER_EVENT, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nif (rc != 0)\r\ngoto fail;\r\nreturn;\r\nfail:\r\nWARN_ON(true);\r\nnetif_err(efx, hw, efx->net_dev, "%s: failed rc=%d\n", __func__, rc);\r\n}\r\nvoid efx_ef10_handle_drain_event(struct efx_nic *efx)\r\n{\r\nif (atomic_dec_and_test(&efx->active_queues))\r\nwake_up(&efx->flush_wq);\r\nWARN_ON(atomic_read(&efx->active_queues) < 0);\r\n}\r\nstatic int efx_ef10_fini_dmaq(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_channel *channel;\r\nstruct efx_tx_queue *tx_queue;\r\nstruct efx_rx_queue *rx_queue;\r\nint pending;\r\nif (nic_data->must_realloc_vis) {\r\natomic_set(&efx->active_queues, 0);\r\nreturn 0;\r\n}\r\nif (efx->state != STATE_RECOVERY) {\r\nefx_for_each_channel(channel, efx) {\r\nefx_for_each_channel_rx_queue(rx_queue, channel)\r\nefx_ef10_rx_fini(rx_queue);\r\nefx_for_each_channel_tx_queue(tx_queue, channel)\r\nefx_ef10_tx_fini(tx_queue);\r\n}\r\nwait_event_timeout(efx->flush_wq,\r\natomic_read(&efx->active_queues) == 0,\r\nmsecs_to_jiffies(EFX_MAX_FLUSH_TIME));\r\npending = atomic_read(&efx->active_queues);\r\nif (pending) {\r\nnetif_err(efx, hw, efx->net_dev, "failed to flush %d queues\n",\r\npending);\r\nreturn -ETIMEDOUT;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_prepare_flr(struct efx_nic *efx)\r\n{\r\natomic_set(&efx->active_queues, 0);\r\n}\r\nstatic bool efx_ef10_filter_equal(const struct efx_filter_spec *left,\r\nconst struct efx_filter_spec *right)\r\n{\r\nif ((left->match_flags ^ right->match_flags) |\r\n((left->flags ^ right->flags) &\r\n(EFX_FILTER_FLAG_RX | EFX_FILTER_FLAG_TX)))\r\nreturn false;\r\nreturn memcmp(&left->outer_vid, &right->outer_vid,\r\nsizeof(struct efx_filter_spec) -\r\noffsetof(struct efx_filter_spec, outer_vid)) == 0;\r\n}\r\nstatic unsigned int efx_ef10_filter_hash(const struct efx_filter_spec *spec)\r\n{\r\nBUILD_BUG_ON(offsetof(struct efx_filter_spec, outer_vid) & 3);\r\nreturn jhash2((const u32 *)&spec->outer_vid,\r\n(sizeof(struct efx_filter_spec) -\r\noffsetof(struct efx_filter_spec, outer_vid)) / 4,\r\n0);\r\n}\r\nstatic bool efx_ef10_filter_is_exclusive(const struct efx_filter_spec *spec)\r\n{\r\nif (spec->match_flags & EFX_FILTER_MATCH_LOC_MAC &&\r\n!is_multicast_ether_addr(spec->loc_mac))\r\nreturn true;\r\nif ((spec->match_flags &\r\n(EFX_FILTER_MATCH_ETHER_TYPE | EFX_FILTER_MATCH_LOC_HOST)) ==\r\n(EFX_FILTER_MATCH_ETHER_TYPE | EFX_FILTER_MATCH_LOC_HOST)) {\r\nif (spec->ether_type == htons(ETH_P_IP) &&\r\n!ipv4_is_multicast(spec->loc_host[0]))\r\nreturn true;\r\nif (spec->ether_type == htons(ETH_P_IPV6) &&\r\n((const u8 *)spec->loc_host)[0] != 0xff)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic struct efx_filter_spec *\r\nefx_ef10_filter_entry_spec(const struct efx_ef10_filter_table *table,\r\nunsigned int filter_idx)\r\n{\r\nreturn (struct efx_filter_spec *)(table->entry[filter_idx].spec &\r\n~EFX_EF10_FILTER_FLAGS);\r\n}\r\nstatic unsigned int\r\nefx_ef10_filter_entry_flags(const struct efx_ef10_filter_table *table,\r\nunsigned int filter_idx)\r\n{\r\nreturn table->entry[filter_idx].spec & EFX_EF10_FILTER_FLAGS;\r\n}\r\nstatic void\r\nefx_ef10_filter_set_entry(struct efx_ef10_filter_table *table,\r\nunsigned int filter_idx,\r\nconst struct efx_filter_spec *spec,\r\nunsigned int flags)\r\n{\r\ntable->entry[filter_idx].spec = (unsigned long)spec | flags;\r\n}\r\nstatic void\r\nefx_ef10_filter_push_prep_set_match_fields(struct efx_nic *efx,\r\nconst struct efx_filter_spec *spec,\r\nefx_dword_t *inbuf)\r\n{\r\nenum efx_encap_type encap_type = efx_filter_get_encap_type(spec);\r\nu32 match_fields = 0, uc_match, mc_match;\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nefx_ef10_filter_is_exclusive(spec) ?\r\nMC_CMD_FILTER_OP_IN_OP_INSERT :\r\nMC_CMD_FILTER_OP_IN_OP_SUBSCRIBE);\r\n#define COPY_VALUE(value, mcdi_field) \\r\ndo { \\r\nmatch_fields |= \\r\n1 << MC_CMD_FILTER_OP_IN_MATCH_ ## \\r\nmcdi_field ## _LBN; \\r\nBUILD_BUG_ON( \\r\nMC_CMD_FILTER_OP_IN_ ## mcdi_field ## _LEN < \\r\nsizeof(value)); \\r\nmemcpy(MCDI_PTR(inbuf, FILTER_OP_IN_ ## mcdi_field), \\r\n&value, sizeof(value)); \\r\n} while (0)\r\n#define COPY_FIELD(gen_flag, gen_field, mcdi_field) \\r\nif (spec->match_flags & EFX_FILTER_MATCH_ ## gen_flag) { \\r\nCOPY_VALUE(spec->gen_field, mcdi_field); \\r\n}\r\nif (encap_type) {\r\n__be16 ether_type =\r\nhtons(encap_type & EFX_ENCAP_FLAG_IPV6 ?\r\nETH_P_IPV6 : ETH_P_IP);\r\nu8 vni_type = MC_CMD_FILTER_OP_EXT_IN_VNI_TYPE_GENEVE;\r\nu8 outer_ip_proto;\r\nswitch (encap_type & EFX_ENCAP_TYPES_MASK) {\r\ncase EFX_ENCAP_TYPE_VXLAN:\r\nvni_type = MC_CMD_FILTER_OP_EXT_IN_VNI_TYPE_VXLAN;\r\ncase EFX_ENCAP_TYPE_GENEVE:\r\nCOPY_VALUE(ether_type, ETHER_TYPE);\r\nouter_ip_proto = IPPROTO_UDP;\r\nCOPY_VALUE(outer_ip_proto, IP_PROTO);\r\nMCDI_POPULATE_DWORD_1(inbuf,\r\nFILTER_OP_EXT_IN_VNI_OR_VSID,\r\nFILTER_OP_EXT_IN_VNI_TYPE,\r\nvni_type);\r\nbreak;\r\ncase EFX_ENCAP_TYPE_NVGRE:\r\nCOPY_VALUE(ether_type, ETHER_TYPE);\r\nouter_ip_proto = IPPROTO_GRE;\r\nCOPY_VALUE(outer_ip_proto, IP_PROTO);\r\nbreak;\r\ndefault:\r\nWARN_ON(1);\r\n}\r\nuc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_IFRM_UNKNOWN_UCAST_DST_LBN;\r\nmc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_IFRM_UNKNOWN_MCAST_DST_LBN;\r\n} else {\r\nuc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_UNKNOWN_UCAST_DST_LBN;\r\nmc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_UNKNOWN_MCAST_DST_LBN;\r\n}\r\nif (spec->match_flags & EFX_FILTER_MATCH_LOC_MAC_IG)\r\nmatch_fields |=\r\nis_multicast_ether_addr(spec->loc_mac) ?\r\n1 << mc_match :\r\n1 << uc_match;\r\nCOPY_FIELD(REM_HOST, rem_host, SRC_IP);\r\nCOPY_FIELD(LOC_HOST, loc_host, DST_IP);\r\nCOPY_FIELD(REM_MAC, rem_mac, SRC_MAC);\r\nCOPY_FIELD(REM_PORT, rem_port, SRC_PORT);\r\nCOPY_FIELD(LOC_MAC, loc_mac, DST_MAC);\r\nCOPY_FIELD(LOC_PORT, loc_port, DST_PORT);\r\nCOPY_FIELD(ETHER_TYPE, ether_type, ETHER_TYPE);\r\nCOPY_FIELD(INNER_VID, inner_vid, INNER_VLAN);\r\nCOPY_FIELD(OUTER_VID, outer_vid, OUTER_VLAN);\r\nCOPY_FIELD(IP_PROTO, ip_proto, IP_PROTO);\r\n#undef COPY_FIELD\r\n#undef COPY_VALUE\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_MATCH_FIELDS,\r\nmatch_fields);\r\n}\r\nstatic void efx_ef10_filter_push_prep(struct efx_nic *efx,\r\nconst struct efx_filter_spec *spec,\r\nefx_dword_t *inbuf, u64 handle,\r\nbool replacing)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu32 flags = spec->flags;\r\nmemset(inbuf, 0, MC_CMD_FILTER_OP_EXT_IN_LEN);\r\nif (flags & EFX_FILTER_FLAG_RX_RSS &&\r\nspec->rss_context == EFX_FILTER_RSS_CONTEXT_DEFAULT &&\r\nnic_data->rx_rss_context == EFX_EF10_RSS_CONTEXT_INVALID)\r\nflags &= ~EFX_FILTER_FLAG_RX_RSS;\r\nif (replacing) {\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nMC_CMD_FILTER_OP_IN_OP_REPLACE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE, handle);\r\n} else {\r\nefx_ef10_filter_push_prep_set_match_fields(efx, spec, inbuf);\r\n}\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_PORT_ID, nic_data->vport_id);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_DEST,\r\nspec->dmaq_id == EFX_FILTER_RX_DMAQ_ID_DROP ?\r\nMC_CMD_FILTER_OP_IN_RX_DEST_DROP :\r\nMC_CMD_FILTER_OP_IN_RX_DEST_HOST);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_TX_DOMAIN, 0);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_TX_DEST,\r\nMC_CMD_FILTER_OP_IN_TX_DEST_DEFAULT);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_QUEUE,\r\nspec->dmaq_id == EFX_FILTER_RX_DMAQ_ID_DROP ?\r\n0 : spec->dmaq_id);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_MODE,\r\n(flags & EFX_FILTER_FLAG_RX_RSS) ?\r\nMC_CMD_FILTER_OP_IN_RX_MODE_RSS :\r\nMC_CMD_FILTER_OP_IN_RX_MODE_SIMPLE);\r\nif (flags & EFX_FILTER_FLAG_RX_RSS)\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_RX_CONTEXT,\r\nspec->rss_context !=\r\nEFX_FILTER_RSS_CONTEXT_DEFAULT ?\r\nspec->rss_context : nic_data->rx_rss_context);\r\n}\r\nstatic int efx_ef10_filter_push(struct efx_nic *efx,\r\nconst struct efx_filter_spec *spec,\r\nu64 *handle, bool replacing)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_EXT_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_FILTER_OP_EXT_OUT_LEN);\r\nint rc;\r\nefx_ef10_filter_push_prep(efx, spec, inbuf, *handle, replacing);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), NULL);\r\nif (rc == 0)\r\n*handle = MCDI_QWORD(outbuf, FILTER_OP_OUT_HANDLE);\r\nif (rc == -ENOSPC)\r\nrc = -EBUSY;\r\nreturn rc;\r\n}\r\nstatic u32 efx_ef10_filter_mcdi_flags_from_spec(const struct efx_filter_spec *spec)\r\n{\r\nenum efx_encap_type encap_type = efx_filter_get_encap_type(spec);\r\nunsigned int match_flags = spec->match_flags;\r\nunsigned int uc_match, mc_match;\r\nu32 mcdi_flags = 0;\r\n#define MAP_FILTER_TO_MCDI_FLAG(gen_flag, mcdi_field, encap) { \\r\nunsigned int old_match_flags = match_flags; \\r\nmatch_flags &= ~EFX_FILTER_MATCH_ ## gen_flag; \\r\nif (match_flags != old_match_flags) \\r\nmcdi_flags |= \\r\n(1 << ((encap) ? \\r\nMC_CMD_FILTER_OP_EXT_IN_MATCH_IFRM_ ## \\r\nmcdi_field ## _LBN : \\r\nMC_CMD_FILTER_OP_EXT_IN_MATCH_ ##\\r\nmcdi_field ## _LBN)); \\r\n}\r\nMAP_FILTER_TO_MCDI_FLAG(REM_HOST, SRC_IP, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(LOC_HOST, DST_IP, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(REM_MAC, SRC_MAC, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(REM_PORT, SRC_PORT, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(LOC_MAC, DST_MAC, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(LOC_PORT, DST_PORT, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(ETHER_TYPE, ETHER_TYPE, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(IP_PROTO, IP_PROTO, encap_type);\r\nMAP_FILTER_TO_MCDI_FLAG(INNER_VID, INNER_VLAN, false);\r\nMAP_FILTER_TO_MCDI_FLAG(OUTER_VID, OUTER_VLAN, false);\r\n#undef MAP_FILTER_TO_MCDI_FLAG\r\nif (encap_type) {\r\nmatch_flags &= ~EFX_FILTER_MATCH_ENCAP_TYPE;\r\nmcdi_flags |=\r\n(1 << MC_CMD_FILTER_OP_EXT_IN_MATCH_ETHER_TYPE_LBN);\r\nmcdi_flags |= (1 << MC_CMD_FILTER_OP_EXT_IN_MATCH_IP_PROTO_LBN);\r\nuc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_IFRM_UNKNOWN_UCAST_DST_LBN;\r\nmc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_IFRM_UNKNOWN_MCAST_DST_LBN;\r\n} else {\r\nuc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_UNKNOWN_UCAST_DST_LBN;\r\nmc_match = MC_CMD_FILTER_OP_EXT_IN_MATCH_UNKNOWN_MCAST_DST_LBN;\r\n}\r\nif (match_flags & EFX_FILTER_MATCH_LOC_MAC_IG) {\r\nmatch_flags &= ~EFX_FILTER_MATCH_LOC_MAC_IG;\r\nmcdi_flags |=\r\nis_multicast_ether_addr(spec->loc_mac) ?\r\n1 << mc_match :\r\n1 << uc_match;\r\n}\r\nWARN_ON_ONCE(match_flags);\r\nreturn mcdi_flags;\r\n}\r\nstatic int efx_ef10_filter_pri(struct efx_ef10_filter_table *table,\r\nconst struct efx_filter_spec *spec)\r\n{\r\nu32 mcdi_flags = efx_ef10_filter_mcdi_flags_from_spec(spec);\r\nunsigned int match_pri;\r\nfor (match_pri = 0;\r\nmatch_pri < table->rx_match_count;\r\nmatch_pri++)\r\nif (table->rx_match_mcdi_flags[match_pri] == mcdi_flags)\r\nreturn match_pri;\r\nreturn -EPROTONOSUPPORT;\r\n}\r\nstatic s32 efx_ef10_filter_insert(struct efx_nic *efx,\r\nstruct efx_filter_spec *spec,\r\nbool replace_equal)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nDECLARE_BITMAP(mc_rem_map, EFX_EF10_FILTER_SEARCH_LIMIT);\r\nstruct efx_filter_spec *saved_spec;\r\nunsigned int match_pri, hash;\r\nunsigned int priv_flags;\r\nbool replacing = false;\r\nint ins_index = -1;\r\nDEFINE_WAIT(wait);\r\nbool is_mc_recip;\r\ns32 rc;\r\nif ((spec->flags & (EFX_FILTER_FLAG_RX | EFX_FILTER_FLAG_TX)) !=\r\nEFX_FILTER_FLAG_RX)\r\nreturn -EINVAL;\r\nrc = efx_ef10_filter_pri(table, spec);\r\nif (rc < 0)\r\nreturn rc;\r\nmatch_pri = rc;\r\nhash = efx_ef10_filter_hash(spec);\r\nis_mc_recip = efx_filter_is_mc_recipient(spec);\r\nif (is_mc_recip)\r\nbitmap_zero(mc_rem_map, EFX_EF10_FILTER_SEARCH_LIMIT);\r\nfor (;;) {\r\nunsigned int depth = 1;\r\nunsigned int i;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (;;) {\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, i);\r\nif (!saved_spec) {\r\nif (ins_index < 0)\r\nins_index = i;\r\n} else if (efx_ef10_filter_equal(spec, saved_spec)) {\r\nif (table->entry[i].spec &\r\nEFX_EF10_FILTER_FLAG_BUSY)\r\nbreak;\r\nif (spec->priority < saved_spec->priority &&\r\nspec->priority != EFX_FILTER_PRI_AUTO) {\r\nrc = -EPERM;\r\ngoto out_unlock;\r\n}\r\nif (!is_mc_recip) {\r\nif (spec->priority ==\r\nsaved_spec->priority &&\r\n!replace_equal) {\r\nrc = -EEXIST;\r\ngoto out_unlock;\r\n}\r\nins_index = i;\r\ngoto found;\r\n} else if (spec->priority >\r\nsaved_spec->priority ||\r\n(spec->priority ==\r\nsaved_spec->priority &&\r\nreplace_equal)) {\r\nif (ins_index < 0)\r\nins_index = i;\r\nelse\r\n__set_bit(depth, mc_rem_map);\r\n}\r\n}\r\nif (depth == EFX_EF10_FILTER_SEARCH_LIMIT) {\r\nif (ins_index < 0) {\r\nrc = -EBUSY;\r\ngoto out_unlock;\r\n}\r\ngoto found;\r\n}\r\n++depth;\r\n}\r\nprepare_to_wait(&table->waitq, &wait, TASK_UNINTERRUPTIBLE);\r\nspin_unlock_bh(&efx->filter_lock);\r\nschedule();\r\n}\r\nfound:\r\nsaved_spec = efx_ef10_filter_entry_spec(table, ins_index);\r\nif (saved_spec) {\r\nif (spec->priority == EFX_FILTER_PRI_AUTO &&\r\nsaved_spec->priority >= EFX_FILTER_PRI_AUTO) {\r\nif (saved_spec->priority > EFX_FILTER_PRI_AUTO)\r\nsaved_spec->flags |= EFX_FILTER_FLAG_RX_OVER_AUTO;\r\ntable->entry[ins_index].spec &=\r\n~EFX_EF10_FILTER_FLAG_AUTO_OLD;\r\nrc = ins_index;\r\ngoto out_unlock;\r\n}\r\nreplacing = true;\r\npriv_flags = efx_ef10_filter_entry_flags(table, ins_index);\r\n} else {\r\nsaved_spec = kmalloc(sizeof(*spec), GFP_ATOMIC);\r\nif (!saved_spec) {\r\nrc = -ENOMEM;\r\ngoto out_unlock;\r\n}\r\n*saved_spec = *spec;\r\npriv_flags = 0;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, saved_spec,\r\npriv_flags | EFX_EF10_FILTER_FLAG_BUSY);\r\nif (is_mc_recip) {\r\nunsigned int depth, i;\r\nfor (depth = 0; depth < EFX_EF10_FILTER_SEARCH_LIMIT; depth++) {\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nif (test_bit(depth, mc_rem_map))\r\ntable->entry[i].spec |=\r\nEFX_EF10_FILTER_FLAG_BUSY;\r\n}\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nrc = efx_ef10_filter_push(efx, spec, &table->entry[ins_index].handle,\r\nreplacing);\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc == 0) {\r\nif (replacing) {\r\nif (saved_spec->priority == EFX_FILTER_PRI_AUTO)\r\nsaved_spec->flags |=\r\nEFX_FILTER_FLAG_RX_OVER_AUTO;\r\nsaved_spec->priority = spec->priority;\r\nsaved_spec->flags &= EFX_FILTER_FLAG_RX_OVER_AUTO;\r\nsaved_spec->flags |= spec->flags;\r\nsaved_spec->rss_context = spec->rss_context;\r\nsaved_spec->dmaq_id = spec->dmaq_id;\r\n}\r\n} else if (!replacing) {\r\nkfree(saved_spec);\r\nsaved_spec = NULL;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, saved_spec, priv_flags);\r\nif (is_mc_recip) {\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_EXT_IN_LEN);\r\nunsigned int depth, i;\r\nmemset(inbuf, 0, sizeof(inbuf));\r\nfor (depth = 0; depth < EFX_EF10_FILTER_SEARCH_LIMIT; depth++) {\r\nif (!test_bit(depth, mc_rem_map))\r\ncontinue;\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, i);\r\npriv_flags = efx_ef10_filter_entry_flags(table, i);\r\nif (rc == 0) {\r\nspin_unlock_bh(&efx->filter_lock);\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nMC_CMD_FILTER_OP_IN_OP_UNSUBSCRIBE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[i].handle);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_FILTER_OP,\r\ninbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\nspin_lock_bh(&efx->filter_lock);\r\n}\r\nif (rc == 0) {\r\nkfree(saved_spec);\r\nsaved_spec = NULL;\r\npriv_flags = 0;\r\n} else {\r\npriv_flags &= ~EFX_EF10_FILTER_FLAG_BUSY;\r\n}\r\nefx_ef10_filter_set_entry(table, i, saved_spec,\r\npriv_flags);\r\n}\r\n}\r\nif (rc == 0)\r\nrc = efx_ef10_make_filter_id(match_pri, ins_index);\r\nwake_up_all(&table->waitq);\r\nout_unlock:\r\nspin_unlock_bh(&efx->filter_lock);\r\nfinish_wait(&table->waitq, &wait);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_filter_update_rx_scatter(struct efx_nic *efx)\r\n{\r\n}\r\nstatic int efx_ef10_filter_remove_internal(struct efx_nic *efx,\r\nunsigned int priority_mask,\r\nu32 filter_id, bool by_index)\r\n{\r\nunsigned int filter_idx = efx_ef10_filter_get_unsafe_id(filter_id);\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_FILTER_OP_IN_HANDLE_OFST +\r\nMC_CMD_FILTER_OP_IN_HANDLE_LEN);\r\nstruct efx_filter_spec *spec;\r\nDEFINE_WAIT(wait);\r\nint rc;\r\nfor (;;) {\r\nspin_lock_bh(&efx->filter_lock);\r\nif (!(table->entry[filter_idx].spec &\r\nEFX_EF10_FILTER_FLAG_BUSY))\r\nbreak;\r\nprepare_to_wait(&table->waitq, &wait, TASK_UNINTERRUPTIBLE);\r\nspin_unlock_bh(&efx->filter_lock);\r\nschedule();\r\n}\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (!spec ||\r\n(!by_index &&\r\nefx_ef10_filter_pri(table, spec) !=\r\nefx_ef10_filter_get_unsafe_pri(filter_id))) {\r\nrc = -ENOENT;\r\ngoto out_unlock;\r\n}\r\nif (spec->flags & EFX_FILTER_FLAG_RX_OVER_AUTO &&\r\npriority_mask == (1U << EFX_FILTER_PRI_AUTO)) {\r\nspec->flags &= ~EFX_FILTER_FLAG_RX_OVER_AUTO;\r\ntable->entry[filter_idx].spec &= ~EFX_EF10_FILTER_FLAG_AUTO_OLD;\r\nrc = 0;\r\ngoto out_unlock;\r\n}\r\nif (!(priority_mask & (1U << spec->priority))) {\r\nrc = -ENOENT;\r\ngoto out_unlock;\r\n}\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_BUSY;\r\nspin_unlock_bh(&efx->filter_lock);\r\nif (spec->flags & EFX_FILTER_FLAG_RX_OVER_AUTO) {\r\nstruct efx_filter_spec new_spec = *spec;\r\nnew_spec.priority = EFX_FILTER_PRI_AUTO;\r\nnew_spec.flags = (EFX_FILTER_FLAG_RX |\r\n(efx_rss_enabled(efx) ?\r\nEFX_FILTER_FLAG_RX_RSS : 0));\r\nnew_spec.dmaq_id = 0;\r\nnew_spec.rss_context = EFX_FILTER_RSS_CONTEXT_DEFAULT;\r\nrc = efx_ef10_filter_push(efx, &new_spec,\r\n&table->entry[filter_idx].handle,\r\ntrue);\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc == 0)\r\n*spec = new_spec;\r\n} else {\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nefx_ef10_filter_is_exclusive(spec) ?\r\nMC_CMD_FILTER_OP_IN_OP_REMOVE :\r\nMC_CMD_FILTER_OP_IN_OP_UNSUBSCRIBE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[filter_idx].handle);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FILTER_OP,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\nspin_lock_bh(&efx->filter_lock);\r\nif ((rc == 0) || (rc == -ENOENT)) {\r\nkfree(spec);\r\nefx_ef10_filter_set_entry(table, filter_idx, NULL, 0);\r\n} else {\r\nefx_mcdi_display_error(efx, MC_CMD_FILTER_OP,\r\nMC_CMD_FILTER_OP_EXT_IN_LEN,\r\nNULL, 0, rc);\r\n}\r\n}\r\ntable->entry[filter_idx].spec &= ~EFX_EF10_FILTER_FLAG_BUSY;\r\nwake_up_all(&table->waitq);\r\nout_unlock:\r\nspin_unlock_bh(&efx->filter_lock);\r\nfinish_wait(&table->waitq, &wait);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_filter_remove_safe(struct efx_nic *efx,\r\nenum efx_filter_priority priority,\r\nu32 filter_id)\r\n{\r\nreturn efx_ef10_filter_remove_internal(efx, 1U << priority,\r\nfilter_id, false);\r\n}\r\nstatic void efx_ef10_filter_remove_unsafe(struct efx_nic *efx,\r\nenum efx_filter_priority priority,\r\nu32 filter_id)\r\n{\r\nif (filter_id == EFX_EF10_FILTER_ID_INVALID)\r\nreturn;\r\nefx_ef10_filter_remove_internal(efx, 1U << priority, filter_id, true);\r\n}\r\nstatic int efx_ef10_filter_get_safe(struct efx_nic *efx,\r\nenum efx_filter_priority priority,\r\nu32 filter_id, struct efx_filter_spec *spec)\r\n{\r\nunsigned int filter_idx = efx_ef10_filter_get_unsafe_id(filter_id);\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nconst struct efx_filter_spec *saved_spec;\r\nint rc;\r\nspin_lock_bh(&efx->filter_lock);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (saved_spec && saved_spec->priority == priority &&\r\nefx_ef10_filter_pri(table, saved_spec) ==\r\nefx_ef10_filter_get_unsafe_pri(filter_id)) {\r\n*spec = *saved_spec;\r\nrc = 0;\r\n} else {\r\nrc = -ENOENT;\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_filter_clear_rx(struct efx_nic *efx,\r\nenum efx_filter_priority priority)\r\n{\r\nunsigned int priority_mask;\r\nunsigned int i;\r\nint rc;\r\npriority_mask = (((1U << (priority + 1)) - 1) &\r\n~(1U << EFX_FILTER_PRI_AUTO));\r\nfor (i = 0; i < HUNT_FILTER_TBL_ROWS; i++) {\r\nrc = efx_ef10_filter_remove_internal(efx, priority_mask,\r\ni, true);\r\nif (rc && rc != -ENOENT)\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic u32 efx_ef10_filter_count_rx_used(struct efx_nic *efx,\r\nenum efx_filter_priority priority)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nunsigned int filter_idx;\r\ns32 count = 0;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nif (table->entry[filter_idx].spec &&\r\nefx_ef10_filter_entry_spec(table, filter_idx)->priority ==\r\npriority)\r\n++count;\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn count;\r\n}\r\nstatic u32 efx_ef10_filter_get_rx_id_limit(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nreturn table->rx_match_count * HUNT_FILTER_TBL_ROWS * 2;\r\n}\r\nstatic s32 efx_ef10_filter_get_rx_ids(struct efx_nic *efx,\r\nenum efx_filter_priority priority,\r\nu32 *buf, u32 size)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_filter_spec *spec;\r\nunsigned int filter_idx;\r\ns32 count = 0;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (spec && spec->priority == priority) {\r\nif (count == size) {\r\ncount = -EMSGSIZE;\r\nbreak;\r\n}\r\nbuf[count++] =\r\nefx_ef10_make_filter_id(\r\nefx_ef10_filter_pri(table, spec),\r\nfilter_idx);\r\n}\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn count;\r\n}\r\nstatic s32 efx_ef10_filter_rfs_insert(struct efx_nic *efx,\r\nstruct efx_filter_spec *spec)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_EXT_IN_LEN);\r\nstruct efx_filter_spec *saved_spec;\r\nunsigned int hash, i, depth = 1;\r\nbool replacing = false;\r\nint ins_index = -1;\r\nu64 cookie;\r\ns32 rc;\r\nEFX_WARN_ON_PARANOID(spec->flags !=\r\n(EFX_FILTER_FLAG_RX | EFX_FILTER_FLAG_RX_SCATTER));\r\nEFX_WARN_ON_PARANOID(spec->priority != EFX_FILTER_PRI_HINT);\r\nEFX_WARN_ON_PARANOID(efx_filter_is_mc_recipient(spec));\r\nhash = efx_ef10_filter_hash(spec);\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (;;) {\r\ni = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);\r\nsaved_spec = efx_ef10_filter_entry_spec(table, i);\r\nif (!saved_spec) {\r\nif (ins_index < 0)\r\nins_index = i;\r\n} else if (efx_ef10_filter_equal(spec, saved_spec)) {\r\nif (table->entry[i].spec & EFX_EF10_FILTER_FLAG_BUSY) {\r\nrc = -EBUSY;\r\ngoto fail_unlock;\r\n}\r\nif (spec->priority < saved_spec->priority) {\r\nrc = -EPERM;\r\ngoto fail_unlock;\r\n}\r\nins_index = i;\r\nbreak;\r\n}\r\nif (depth == EFX_EF10_FILTER_SEARCH_LIMIT) {\r\nif (ins_index < 0) {\r\nrc = -EBUSY;\r\ngoto fail_unlock;\r\n}\r\nbreak;\r\n}\r\n++depth;\r\n}\r\nsaved_spec = efx_ef10_filter_entry_spec(table, ins_index);\r\nif (saved_spec) {\r\nreplacing = true;\r\n} else {\r\nsaved_spec = kmalloc(sizeof(*spec), GFP_ATOMIC);\r\nif (!saved_spec) {\r\nrc = -ENOMEM;\r\ngoto fail_unlock;\r\n}\r\n*saved_spec = *spec;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, saved_spec,\r\nEFX_EF10_FILTER_FLAG_BUSY);\r\nspin_unlock_bh(&efx->filter_lock);\r\ncookie = replacing << 31 | ins_index << 16 | spec->dmaq_id;\r\nefx_ef10_filter_push_prep(efx, spec, inbuf,\r\ntable->entry[ins_index].handle, replacing);\r\nefx_mcdi_rpc_async(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf),\r\nMC_CMD_FILTER_OP_OUT_LEN,\r\nefx_ef10_filter_rfs_insert_complete, cookie);\r\nreturn ins_index;\r\nfail_unlock:\r\nspin_unlock_bh(&efx->filter_lock);\r\nreturn rc;\r\n}\r\nstatic void\r\nefx_ef10_filter_rfs_insert_complete(struct efx_nic *efx, unsigned long cookie,\r\nint rc, efx_dword_t *outbuf,\r\nsize_t outlen_actual)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nunsigned int ins_index, dmaq_id;\r\nstruct efx_filter_spec *spec;\r\nbool replacing;\r\nreplacing = cookie >> 31;\r\nins_index = (cookie >> 16) & (HUNT_FILTER_TBL_ROWS - 1);\r\ndmaq_id = cookie & 0xffff;\r\nspin_lock_bh(&efx->filter_lock);\r\nspec = efx_ef10_filter_entry_spec(table, ins_index);\r\nif (rc == 0) {\r\ntable->entry[ins_index].handle =\r\nMCDI_QWORD(outbuf, FILTER_OP_OUT_HANDLE);\r\nif (replacing)\r\nspec->dmaq_id = dmaq_id;\r\n} else if (!replacing) {\r\nkfree(spec);\r\nspec = NULL;\r\n}\r\nefx_ef10_filter_set_entry(table, ins_index, spec, 0);\r\nspin_unlock_bh(&efx->filter_lock);\r\nwake_up_all(&table->waitq);\r\n}\r\nstatic bool efx_ef10_filter_rfs_expire_one(struct efx_nic *efx, u32 flow_id,\r\nunsigned int filter_idx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_filter_spec *spec =\r\nefx_ef10_filter_entry_spec(table, filter_idx);\r\nMCDI_DECLARE_BUF(inbuf,\r\nMC_CMD_FILTER_OP_IN_HANDLE_OFST +\r\nMC_CMD_FILTER_OP_IN_HANDLE_LEN);\r\nif (!spec ||\r\n(table->entry[filter_idx].spec & EFX_EF10_FILTER_FLAG_BUSY) ||\r\nspec->priority != EFX_FILTER_PRI_HINT ||\r\n!rps_may_expire_flow(efx->net_dev, spec->dmaq_id,\r\nflow_id, filter_idx))\r\nreturn false;\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nMC_CMD_FILTER_OP_IN_OP_REMOVE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[filter_idx].handle);\r\nif (efx_mcdi_rpc_async(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf), 0,\r\nefx_ef10_filter_rfs_expire_complete, filter_idx))\r\nreturn false;\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_BUSY;\r\nreturn true;\r\n}\r\nstatic void\r\nefx_ef10_filter_rfs_expire_complete(struct efx_nic *efx,\r\nunsigned long filter_idx,\r\nint rc, efx_dword_t *outbuf,\r\nsize_t outlen_actual)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_filter_spec *spec =\r\nefx_ef10_filter_entry_spec(table, filter_idx);\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc == 0) {\r\nkfree(spec);\r\nefx_ef10_filter_set_entry(table, filter_idx, NULL, 0);\r\n}\r\ntable->entry[filter_idx].spec &= ~EFX_EF10_FILTER_FLAG_BUSY;\r\nwake_up_all(&table->waitq);\r\nspin_unlock_bh(&efx->filter_lock);\r\n}\r\nstatic int efx_ef10_filter_match_flags_from_mcdi(bool encap, u32 mcdi_flags)\r\n{\r\nint match_flags = 0;\r\n#define MAP_FLAG(gen_flag, mcdi_field) do { \\r\nu32 old_mcdi_flags = mcdi_flags; \\r\nmcdi_flags &= ~(1 << MC_CMD_FILTER_OP_EXT_IN_MATCH_ ## \\r\nmcdi_field ## _LBN); \\r\nif (mcdi_flags != old_mcdi_flags) \\r\nmatch_flags |= EFX_FILTER_MATCH_ ## gen_flag; \\r\n} while (0)\r\nif (encap) {\r\nmatch_flags |= EFX_FILTER_MATCH_ENCAP_TYPE;\r\nmcdi_flags &=\r\n~(1 << MC_CMD_FILTER_OP_EXT_IN_MATCH_IP_PROTO_LBN);\r\nmcdi_flags &=\r\n~(1 << MC_CMD_FILTER_OP_EXT_IN_MATCH_ETHER_TYPE_LBN);\r\nMAP_FLAG(INNER_VID, INNER_VLAN);\r\nMAP_FLAG(OUTER_VID, OUTER_VLAN);\r\nMAP_FLAG(LOC_MAC_IG, IFRM_UNKNOWN_UCAST_DST);\r\nMAP_FLAG(LOC_MAC_IG, IFRM_UNKNOWN_MCAST_DST);\r\nMAP_FLAG(REM_HOST, IFRM_SRC_IP);\r\nMAP_FLAG(LOC_HOST, IFRM_DST_IP);\r\nMAP_FLAG(REM_MAC, IFRM_SRC_MAC);\r\nMAP_FLAG(REM_PORT, IFRM_SRC_PORT);\r\nMAP_FLAG(LOC_MAC, IFRM_DST_MAC);\r\nMAP_FLAG(LOC_PORT, IFRM_DST_PORT);\r\nMAP_FLAG(ETHER_TYPE, IFRM_ETHER_TYPE);\r\nMAP_FLAG(IP_PROTO, IFRM_IP_PROTO);\r\n} else {\r\nMAP_FLAG(LOC_MAC_IG, UNKNOWN_UCAST_DST);\r\nMAP_FLAG(LOC_MAC_IG, UNKNOWN_MCAST_DST);\r\nMAP_FLAG(REM_HOST, SRC_IP);\r\nMAP_FLAG(LOC_HOST, DST_IP);\r\nMAP_FLAG(REM_MAC, SRC_MAC);\r\nMAP_FLAG(REM_PORT, SRC_PORT);\r\nMAP_FLAG(LOC_MAC, DST_MAC);\r\nMAP_FLAG(LOC_PORT, DST_PORT);\r\nMAP_FLAG(ETHER_TYPE, ETHER_TYPE);\r\nMAP_FLAG(INNER_VID, INNER_VLAN);\r\nMAP_FLAG(OUTER_VID, OUTER_VLAN);\r\nMAP_FLAG(IP_PROTO, IP_PROTO);\r\n}\r\n#undef MAP_FLAG\r\nif (mcdi_flags)\r\nreturn -EINVAL;\r\nreturn match_flags;\r\n}\r\nstatic void efx_ef10_filter_cleanup_vlans(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_filter_vlan *vlan, *next_vlan;\r\nif (!efx_rwsem_assert_write_locked(&efx->filter_sem))\r\nreturn;\r\nif (!table)\r\nreturn;\r\nlist_for_each_entry_safe(vlan, next_vlan, &table->vlan_list, list)\r\nefx_ef10_filter_del_vlan_internal(efx, vlan);\r\n}\r\nstatic bool efx_ef10_filter_match_supported(struct efx_ef10_filter_table *table,\r\nbool encap,\r\nenum efx_filter_match_flags match_flags)\r\n{\r\nunsigned int match_pri;\r\nint mf;\r\nfor (match_pri = 0;\r\nmatch_pri < table->rx_match_count;\r\nmatch_pri++) {\r\nmf = efx_ef10_filter_match_flags_from_mcdi(encap,\r\ntable->rx_match_mcdi_flags[match_pri]);\r\nif (mf == match_flags)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic int\r\nefx_ef10_filter_table_probe_matches(struct efx_nic *efx,\r\nstruct efx_ef10_filter_table *table,\r\nbool encap)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_GET_PARSER_DISP_INFO_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_GET_PARSER_DISP_INFO_OUT_LENMAX);\r\nunsigned int pd_match_pri, pd_match_count;\r\nsize_t outlen;\r\nint rc;\r\nMCDI_SET_DWORD(inbuf, GET_PARSER_DISP_INFO_IN_OP,\r\nencap ?\r\nMC_CMD_GET_PARSER_DISP_INFO_IN_OP_GET_SUPPORTED_ENCAP_RX_MATCHES :\r\nMC_CMD_GET_PARSER_DISP_INFO_IN_OP_GET_SUPPORTED_RX_MATCHES);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_GET_PARSER_DISP_INFO,\r\ninbuf, sizeof(inbuf), outbuf, sizeof(outbuf),\r\n&outlen);\r\nif (rc)\r\nreturn rc;\r\npd_match_count = MCDI_VAR_ARRAY_LEN(\r\noutlen, GET_PARSER_DISP_INFO_OUT_SUPPORTED_MATCHES);\r\nfor (pd_match_pri = 0; pd_match_pri < pd_match_count; pd_match_pri++) {\r\nu32 mcdi_flags =\r\nMCDI_ARRAY_DWORD(\r\noutbuf,\r\nGET_PARSER_DISP_INFO_OUT_SUPPORTED_MATCHES,\r\npd_match_pri);\r\nrc = efx_ef10_filter_match_flags_from_mcdi(encap, mcdi_flags);\r\nif (rc < 0) {\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"%s: fw flags %#x pri %u not supported in driver\n",\r\n__func__, mcdi_flags, pd_match_pri);\r\n} else {\r\nnetif_dbg(efx, probe, efx->net_dev,\r\n"%s: fw flags %#x pri %u supported as driver flags %#x pri %u\n",\r\n__func__, mcdi_flags, pd_match_pri,\r\nrc, table->rx_match_count);\r\ntable->rx_match_mcdi_flags[table->rx_match_count] = mcdi_flags;\r\ntable->rx_match_count++;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_filter_table_probe(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct net_device *net_dev = efx->net_dev;\r\nstruct efx_ef10_filter_table *table;\r\nstruct efx_ef10_vlan *vlan;\r\nint rc;\r\nif (!efx_rwsem_assert_write_locked(&efx->filter_sem))\r\nreturn -EINVAL;\r\nif (efx->filter_state)\r\nreturn 0;\r\ntable = kzalloc(sizeof(*table), GFP_KERNEL);\r\nif (!table)\r\nreturn -ENOMEM;\r\ntable->rx_match_count = 0;\r\nrc = efx_ef10_filter_table_probe_matches(efx, table, false);\r\nif (rc)\r\ngoto fail;\r\nif (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VXLAN_NVGRE_LBN))\r\nrc = efx_ef10_filter_table_probe_matches(efx, table, true);\r\nif (rc)\r\ngoto fail;\r\nif ((efx_supported_features(efx) & NETIF_F_HW_VLAN_CTAG_FILTER) &&\r\n!(efx_ef10_filter_match_supported(table, false,\r\n(EFX_FILTER_MATCH_OUTER_VID | EFX_FILTER_MATCH_LOC_MAC)) &&\r\nefx_ef10_filter_match_supported(table, false,\r\n(EFX_FILTER_MATCH_OUTER_VID | EFX_FILTER_MATCH_LOC_MAC_IG)))) {\r\nnetif_info(efx, probe, net_dev,\r\n"VLAN filters are not supported in this firmware variant\n");\r\nnet_dev->features &= ~NETIF_F_HW_VLAN_CTAG_FILTER;\r\nefx->fixed_features &= ~NETIF_F_HW_VLAN_CTAG_FILTER;\r\nnet_dev->hw_features &= ~NETIF_F_HW_VLAN_CTAG_FILTER;\r\n}\r\ntable->entry = vzalloc(HUNT_FILTER_TBL_ROWS * sizeof(*table->entry));\r\nif (!table->entry) {\r\nrc = -ENOMEM;\r\ngoto fail;\r\n}\r\ntable->mc_promisc_last = false;\r\ntable->vlan_filter =\r\n!!(efx->net_dev->features & NETIF_F_HW_VLAN_CTAG_FILTER);\r\nINIT_LIST_HEAD(&table->vlan_list);\r\nefx->filter_state = table;\r\ninit_waitqueue_head(&table->waitq);\r\nlist_for_each_entry(vlan, &nic_data->vlan_list, list) {\r\nrc = efx_ef10_filter_add_vlan(efx, vlan->vid);\r\nif (rc)\r\ngoto fail_add_vlan;\r\n}\r\nreturn 0;\r\nfail_add_vlan:\r\nefx_ef10_filter_cleanup_vlans(efx);\r\nefx->filter_state = NULL;\r\nfail:\r\nkfree(table);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_filter_table_restore(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nunsigned int invalid_filters = 0, failed = 0;\r\nstruct efx_ef10_filter_vlan *vlan;\r\nstruct efx_filter_spec *spec;\r\nunsigned int filter_idx;\r\nu32 mcdi_flags;\r\nint match_pri;\r\nint rc, i;\r\nWARN_ON(!rwsem_is_locked(&efx->filter_sem));\r\nif (!nic_data->must_restore_filters)\r\nreturn;\r\nif (!table)\r\nreturn;\r\nspin_lock_bh(&efx->filter_lock);\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (!spec)\r\ncontinue;\r\nmcdi_flags = efx_ef10_filter_mcdi_flags_from_spec(spec);\r\nmatch_pri = 0;\r\nwhile (match_pri < table->rx_match_count &&\r\ntable->rx_match_mcdi_flags[match_pri] != mcdi_flags)\r\n++match_pri;\r\nif (match_pri >= table->rx_match_count) {\r\ninvalid_filters++;\r\ngoto not_restored;\r\n}\r\nif (spec->rss_context != EFX_FILTER_RSS_CONTEXT_DEFAULT &&\r\nspec->rss_context != nic_data->rx_rss_context)\r\nnetif_warn(efx, drv, efx->net_dev,\r\n"Warning: unable to restore a filter with specific RSS context.\n");\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_BUSY;\r\nspin_unlock_bh(&efx->filter_lock);\r\nrc = efx_ef10_filter_push(efx, spec,\r\n&table->entry[filter_idx].handle,\r\nfalse);\r\nif (rc)\r\nfailed++;\r\nspin_lock_bh(&efx->filter_lock);\r\nif (rc) {\r\nnot_restored:\r\nlist_for_each_entry(vlan, &table->vlan_list, list)\r\nfor (i = 0; i < EFX_EF10_NUM_DEFAULT_FILTERS; ++i)\r\nif (vlan->default_filters[i] == filter_idx)\r\nvlan->default_filters[i] =\r\nEFX_EF10_FILTER_ID_INVALID;\r\nkfree(spec);\r\nefx_ef10_filter_set_entry(table, filter_idx, NULL, 0);\r\n} else {\r\ntable->entry[filter_idx].spec &=\r\n~EFX_EF10_FILTER_FLAG_BUSY;\r\n}\r\n}\r\nspin_unlock_bh(&efx->filter_lock);\r\nif (invalid_filters)\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"Did not restore %u filters that are now unsupported.\n",\r\ninvalid_filters);\r\nif (failed)\r\nnetif_err(efx, hw, efx->net_dev,\r\n"unable to restore %u filters\n", failed);\r\nelse\r\nnic_data->must_restore_filters = false;\r\n}\r\nstatic void efx_ef10_filter_table_remove(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_EXT_IN_LEN);\r\nstruct efx_filter_spec *spec;\r\nunsigned int filter_idx;\r\nint rc;\r\nefx_ef10_filter_cleanup_vlans(efx);\r\nefx->filter_state = NULL;\r\nif (!efx_rwsem_assert_write_locked(&efx->filter_sem))\r\nreturn;\r\nif (!table)\r\nreturn;\r\nfor (filter_idx = 0; filter_idx < HUNT_FILTER_TBL_ROWS; filter_idx++) {\r\nspec = efx_ef10_filter_entry_spec(table, filter_idx);\r\nif (!spec)\r\ncontinue;\r\nMCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,\r\nefx_ef10_filter_is_exclusive(spec) ?\r\nMC_CMD_FILTER_OP_IN_OP_REMOVE :\r\nMC_CMD_FILTER_OP_IN_OP_UNSUBSCRIBE);\r\nMCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,\r\ntable->entry[filter_idx].handle);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_FILTER_OP, inbuf,\r\nsizeof(inbuf), NULL, 0, NULL);\r\nif (rc)\r\nnetif_info(efx, drv, efx->net_dev,\r\n"%s: filter %04x remove failed\n",\r\n__func__, filter_idx);\r\nkfree(spec);\r\n}\r\nvfree(table->entry);\r\nkfree(table);\r\n}\r\nstatic void efx_ef10_filter_mark_one_old(struct efx_nic *efx, uint16_t *id)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nunsigned int filter_idx;\r\nif (*id != EFX_EF10_FILTER_ID_INVALID) {\r\nfilter_idx = efx_ef10_filter_get_unsafe_id(*id);\r\nif (!table->entry[filter_idx].spec)\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"marked null spec old %04x:%04x\n", *id,\r\nfilter_idx);\r\ntable->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_AUTO_OLD;\r\n*id = EFX_EF10_FILTER_ID_INVALID;\r\n}\r\n}\r\nstatic void _efx_ef10_filter_vlan_mark_old(struct efx_nic *efx,\r\nstruct efx_ef10_filter_vlan *vlan)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nunsigned int i;\r\nfor (i = 0; i < table->dev_uc_count; i++)\r\nefx_ef10_filter_mark_one_old(efx, &vlan->uc[i]);\r\nfor (i = 0; i < table->dev_mc_count; i++)\r\nefx_ef10_filter_mark_one_old(efx, &vlan->mc[i]);\r\nfor (i = 0; i < EFX_EF10_NUM_DEFAULT_FILTERS; i++)\r\nefx_ef10_filter_mark_one_old(efx, &vlan->default_filters[i]);\r\n}\r\nstatic void efx_ef10_filter_mark_old(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_filter_vlan *vlan;\r\nspin_lock_bh(&efx->filter_lock);\r\nlist_for_each_entry(vlan, &table->vlan_list, list)\r\n_efx_ef10_filter_vlan_mark_old(efx, vlan);\r\nspin_unlock_bh(&efx->filter_lock);\r\n}\r\nstatic void efx_ef10_filter_uc_addr_list(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct net_device *net_dev = efx->net_dev;\r\nstruct netdev_hw_addr *uc;\r\nunsigned int i;\r\ntable->uc_promisc = !!(net_dev->flags & IFF_PROMISC);\r\nether_addr_copy(table->dev_uc_list[0].addr, net_dev->dev_addr);\r\ni = 1;\r\nnetdev_for_each_uc_addr(uc, net_dev) {\r\nif (i >= EFX_EF10_FILTER_DEV_UC_MAX) {\r\ntable->uc_promisc = true;\r\nbreak;\r\n}\r\nether_addr_copy(table->dev_uc_list[i].addr, uc->addr);\r\ni++;\r\n}\r\ntable->dev_uc_count = i;\r\n}\r\nstatic void efx_ef10_filter_mc_addr_list(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct net_device *net_dev = efx->net_dev;\r\nstruct netdev_hw_addr *mc;\r\nunsigned int i;\r\ntable->mc_overflow = false;\r\ntable->mc_promisc = !!(net_dev->flags & (IFF_PROMISC | IFF_ALLMULTI));\r\ni = 0;\r\nnetdev_for_each_mc_addr(mc, net_dev) {\r\nif (i >= EFX_EF10_FILTER_DEV_MC_MAX) {\r\ntable->mc_promisc = true;\r\ntable->mc_overflow = true;\r\nbreak;\r\n}\r\nether_addr_copy(table->dev_mc_list[i].addr, mc->addr);\r\ni++;\r\n}\r\ntable->dev_mc_count = i;\r\n}\r\nstatic int efx_ef10_filter_insert_addr_list(struct efx_nic *efx,\r\nstruct efx_ef10_filter_vlan *vlan,\r\nbool multicast, bool rollback)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_dev_addr *addr_list;\r\nenum efx_filter_flags filter_flags;\r\nstruct efx_filter_spec spec;\r\nu8 baddr[ETH_ALEN];\r\nunsigned int i, j;\r\nint addr_count;\r\nu16 *ids;\r\nint rc;\r\nif (multicast) {\r\naddr_list = table->dev_mc_list;\r\naddr_count = table->dev_mc_count;\r\nids = vlan->mc;\r\n} else {\r\naddr_list = table->dev_uc_list;\r\naddr_count = table->dev_uc_count;\r\nids = vlan->uc;\r\n}\r\nfilter_flags = efx_rss_enabled(efx) ? EFX_FILTER_FLAG_RX_RSS : 0;\r\nfor (i = 0; i < addr_count; i++) {\r\nEFX_WARN_ON_PARANOID(ids[i] != EFX_EF10_FILTER_ID_INVALID);\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO, filter_flags, 0);\r\nefx_filter_set_eth_local(&spec, vlan->vid, addr_list[i].addr);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nif (rollback) {\r\nnetif_info(efx, drv, efx->net_dev,\r\n"efx_ef10_filter_insert failed rc=%d\n",\r\nrc);\r\nfor (j = 0; j < i; j++) {\r\nefx_ef10_filter_remove_unsafe(\r\nefx, EFX_FILTER_PRI_AUTO,\r\nids[j]);\r\nids[j] = EFX_EF10_FILTER_ID_INVALID;\r\n}\r\nreturn rc;\r\n} else {\r\n}\r\n} else {\r\nids[i] = efx_ef10_filter_get_unsafe_id(rc);\r\n}\r\n}\r\nif (multicast && rollback) {\r\nEFX_WARN_ON_PARANOID(vlan->default_filters[EFX_EF10_BCAST] !=\r\nEFX_EF10_FILTER_ID_INVALID);\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO, filter_flags, 0);\r\neth_broadcast_addr(baddr);\r\nefx_filter_set_eth_local(&spec, vlan->vid, baddr);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nnetif_warn(efx, drv, efx->net_dev,\r\n"Broadcast filter insert failed rc=%d\n", rc);\r\nfor (j = 0; j < i; j++) {\r\nefx_ef10_filter_remove_unsafe(\r\nefx, EFX_FILTER_PRI_AUTO,\r\nids[j]);\r\nids[j] = EFX_EF10_FILTER_ID_INVALID;\r\n}\r\nreturn rc;\r\n} else {\r\nvlan->default_filters[EFX_EF10_BCAST] =\r\nefx_ef10_filter_get_unsafe_id(rc);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_filter_insert_def(struct efx_nic *efx,\r\nstruct efx_ef10_filter_vlan *vlan,\r\nenum efx_encap_type encap_type,\r\nbool multicast, bool rollback)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nenum efx_filter_flags filter_flags;\r\nstruct efx_filter_spec spec;\r\nu8 baddr[ETH_ALEN];\r\nint rc;\r\nu16 *id;\r\nfilter_flags = efx_rss_enabled(efx) ? EFX_FILTER_FLAG_RX_RSS : 0;\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO, filter_flags, 0);\r\nif (multicast)\r\nefx_filter_set_mc_def(&spec);\r\nelse\r\nefx_filter_set_uc_def(&spec);\r\nif (encap_type) {\r\nif (nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VXLAN_NVGRE_LBN))\r\nefx_filter_set_encap_type(&spec, encap_type);\r\nelse\r\nreturn 0;\r\n}\r\nif (vlan->vid != EFX_FILTER_VID_UNSPEC)\r\nefx_filter_set_eth_local(&spec, vlan->vid, NULL);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nconst char *um = multicast ? "Multicast" : "Unicast";\r\nconst char *encap_name = "";\r\nconst char *encap_ipv = "";\r\nif ((encap_type & EFX_ENCAP_TYPES_MASK) ==\r\nEFX_ENCAP_TYPE_VXLAN)\r\nencap_name = "VXLAN ";\r\nelse if ((encap_type & EFX_ENCAP_TYPES_MASK) ==\r\nEFX_ENCAP_TYPE_NVGRE)\r\nencap_name = "NVGRE ";\r\nelse if ((encap_type & EFX_ENCAP_TYPES_MASK) ==\r\nEFX_ENCAP_TYPE_GENEVE)\r\nencap_name = "GENEVE ";\r\nif (encap_type & EFX_ENCAP_FLAG_IPV6)\r\nencap_ipv = "IPv6 ";\r\nelse if (encap_type)\r\nencap_ipv = "IPv4 ";\r\nnetif_cond_dbg(efx, drv, efx->net_dev,\r\nrc == -EPERM && (encap_type || !multicast), warn,\r\n"%s%s%s mismatch filter insert failed rc=%d\n",\r\nencap_name, encap_ipv, um, rc);\r\n} else if (multicast) {\r\nstatic enum efx_ef10_default_filters map[] = {\r\n[EFX_ENCAP_TYPE_NONE] = EFX_EF10_MCDEF,\r\n[EFX_ENCAP_TYPE_VXLAN] = EFX_EF10_VXLAN4_MCDEF,\r\n[EFX_ENCAP_TYPE_NVGRE] = EFX_EF10_NVGRE4_MCDEF,\r\n[EFX_ENCAP_TYPE_GENEVE] = EFX_EF10_GENEVE4_MCDEF,\r\n[EFX_ENCAP_TYPE_VXLAN | EFX_ENCAP_FLAG_IPV6] =\r\nEFX_EF10_VXLAN6_MCDEF,\r\n[EFX_ENCAP_TYPE_NVGRE | EFX_ENCAP_FLAG_IPV6] =\r\nEFX_EF10_NVGRE6_MCDEF,\r\n[EFX_ENCAP_TYPE_GENEVE | EFX_ENCAP_FLAG_IPV6] =\r\nEFX_EF10_GENEVE6_MCDEF,\r\n};\r\nBUILD_BUG_ON(EFX_EF10_BCAST != 0);\r\nif (encap_type >= ARRAY_SIZE(map) || map[encap_type] == 0) {\r\nWARN_ON(1);\r\nreturn -EINVAL;\r\n}\r\nid = &vlan->default_filters[map[encap_type]];\r\nEFX_WARN_ON_PARANOID(*id != EFX_EF10_FILTER_ID_INVALID);\r\n*id = efx_ef10_filter_get_unsafe_id(rc);\r\nif (!nic_data->workaround_26807 && !encap_type) {\r\nefx_filter_init_rx(&spec, EFX_FILTER_PRI_AUTO,\r\nfilter_flags, 0);\r\neth_broadcast_addr(baddr);\r\nefx_filter_set_eth_local(&spec, vlan->vid, baddr);\r\nrc = efx_ef10_filter_insert(efx, &spec, true);\r\nif (rc < 0) {\r\nnetif_warn(efx, drv, efx->net_dev,\r\n"Broadcast filter insert failed rc=%d\n",\r\nrc);\r\nif (rollback) {\r\nefx_ef10_filter_remove_unsafe(\r\nefx, EFX_FILTER_PRI_AUTO,\r\n*id);\r\n*id = EFX_EF10_FILTER_ID_INVALID;\r\nreturn rc;\r\n}\r\n} else {\r\nEFX_WARN_ON_PARANOID(\r\nvlan->default_filters[EFX_EF10_BCAST] !=\r\nEFX_EF10_FILTER_ID_INVALID);\r\nvlan->default_filters[EFX_EF10_BCAST] =\r\nefx_ef10_filter_get_unsafe_id(rc);\r\n}\r\n}\r\nrc = 0;\r\n} else {\r\nstatic enum efx_ef10_default_filters map[] = {\r\n[EFX_ENCAP_TYPE_NONE] = EFX_EF10_UCDEF,\r\n[EFX_ENCAP_TYPE_VXLAN] = EFX_EF10_VXLAN4_UCDEF,\r\n[EFX_ENCAP_TYPE_NVGRE] = EFX_EF10_NVGRE4_UCDEF,\r\n[EFX_ENCAP_TYPE_GENEVE] = EFX_EF10_GENEVE4_UCDEF,\r\n[EFX_ENCAP_TYPE_VXLAN | EFX_ENCAP_FLAG_IPV6] =\r\nEFX_EF10_VXLAN6_UCDEF,\r\n[EFX_ENCAP_TYPE_NVGRE | EFX_ENCAP_FLAG_IPV6] =\r\nEFX_EF10_NVGRE6_UCDEF,\r\n[EFX_ENCAP_TYPE_GENEVE | EFX_ENCAP_FLAG_IPV6] =\r\nEFX_EF10_GENEVE6_UCDEF,\r\n};\r\nBUILD_BUG_ON(EFX_EF10_BCAST != 0);\r\nif (encap_type >= ARRAY_SIZE(map) || map[encap_type] == 0) {\r\nWARN_ON(1);\r\nreturn -EINVAL;\r\n}\r\nid = &vlan->default_filters[map[encap_type]];\r\nEFX_WARN_ON_PARANOID(*id != EFX_EF10_FILTER_ID_INVALID);\r\n*id = rc;\r\nrc = 0;\r\n}\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_filter_remove_old(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nint remove_failed = 0;\r\nint remove_noent = 0;\r\nint rc;\r\nint i;\r\nfor (i = 0; i < HUNT_FILTER_TBL_ROWS; i++) {\r\nif (ACCESS_ONCE(table->entry[i].spec) &\r\nEFX_EF10_FILTER_FLAG_AUTO_OLD) {\r\nrc = efx_ef10_filter_remove_internal(efx,\r\n1U << EFX_FILTER_PRI_AUTO, i, true);\r\nif (rc == -ENOENT)\r\nremove_noent++;\r\nelse if (rc)\r\nremove_failed++;\r\n}\r\n}\r\nif (remove_failed)\r\nnetif_info(efx, drv, efx->net_dev,\r\n"%s: failed to remove %d filters\n",\r\n__func__, remove_failed);\r\nif (remove_noent)\r\nnetif_info(efx, drv, efx->net_dev,\r\n"%s: failed to remove %d non-existent filters\n",\r\n__func__, remove_noent);\r\n}\r\nstatic int efx_ef10_vport_set_mac_address(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nu8 mac_old[ETH_ALEN];\r\nint rc, rc2;\r\nif (is_zero_ether_addr(nic_data->vport_mac))\r\nreturn 0;\r\nefx_device_detach_sync(efx);\r\nefx_net_stop(efx->net_dev);\r\ndown_write(&efx->filter_sem);\r\nefx_ef10_filter_table_remove(efx);\r\nup_write(&efx->filter_sem);\r\nrc = efx_ef10_vadaptor_free(efx, nic_data->vport_id);\r\nif (rc)\r\ngoto restore_filters;\r\nether_addr_copy(mac_old, nic_data->vport_mac);\r\nrc = efx_ef10_vport_del_mac(efx, nic_data->vport_id,\r\nnic_data->vport_mac);\r\nif (rc)\r\ngoto restore_vadaptor;\r\nrc = efx_ef10_vport_add_mac(efx, nic_data->vport_id,\r\nefx->net_dev->dev_addr);\r\nif (!rc) {\r\nether_addr_copy(nic_data->vport_mac, efx->net_dev->dev_addr);\r\n} else {\r\nrc2 = efx_ef10_vport_add_mac(efx, nic_data->vport_id, mac_old);\r\nif (rc2) {\r\neth_zero_addr(nic_data->vport_mac);\r\ngoto reset_nic;\r\n}\r\n}\r\nrestore_vadaptor:\r\nrc2 = efx_ef10_vadaptor_alloc(efx, nic_data->vport_id);\r\nif (rc2)\r\ngoto reset_nic;\r\nrestore_filters:\r\ndown_write(&efx->filter_sem);\r\nrc2 = efx_ef10_filter_table_probe(efx);\r\nup_write(&efx->filter_sem);\r\nif (rc2)\r\ngoto reset_nic;\r\nrc2 = efx_net_open(efx->net_dev);\r\nif (rc2)\r\ngoto reset_nic;\r\nefx_device_attach_if_not_resetting(efx);\r\nreturn rc;\r\nreset_nic:\r\nnetif_err(efx, drv, efx->net_dev,\r\n"Failed to restore when changing MAC address - scheduling reset\n");\r\nefx_schedule_reset(efx, RESET_TYPE_DATAPATH);\r\nreturn rc ? rc : rc2;\r\n}\r\nstatic void efx_ef10_filter_vlan_sync_rx_mode(struct efx_nic *efx,\r\nstruct efx_ef10_filter_vlan *vlan)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif ((vlan->vid == EFX_FILTER_VID_UNSPEC) == table->vlan_filter)\r\nreturn;\r\nif (table->uc_promisc) {\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_NONE,\r\nfalse, false);\r\nefx_ef10_filter_insert_addr_list(efx, vlan, false, false);\r\n} else {\r\nif (efx_ef10_filter_insert_addr_list(efx, vlan, false, false))\r\nefx_ef10_filter_insert_def(efx, vlan,\r\nEFX_ENCAP_TYPE_NONE,\r\nfalse, false);\r\n}\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_VXLAN,\r\nfalse, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_VXLAN |\r\nEFX_ENCAP_FLAG_IPV6,\r\nfalse, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_NVGRE,\r\nfalse, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_NVGRE |\r\nEFX_ENCAP_FLAG_IPV6,\r\nfalse, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_GENEVE,\r\nfalse, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_GENEVE |\r\nEFX_ENCAP_FLAG_IPV6,\r\nfalse, false);\r\nif (nic_data->workaround_26807 &&\r\ntable->mc_promisc_last != table->mc_promisc)\r\nefx_ef10_filter_remove_old(efx);\r\nif (table->mc_promisc) {\r\nif (nic_data->workaround_26807) {\r\nif (efx_ef10_filter_insert_def(efx, vlan,\r\nEFX_ENCAP_TYPE_NONE,\r\ntrue, true)) {\r\nefx_ef10_filter_remove_old(efx);\r\nefx_ef10_filter_insert_addr_list(efx, vlan,\r\ntrue, false);\r\n}\r\n} else {\r\nefx_ef10_filter_insert_def(efx, vlan,\r\nEFX_ENCAP_TYPE_NONE,\r\ntrue, false);\r\nif (!table->mc_overflow)\r\nefx_ef10_filter_insert_addr_list(efx, vlan,\r\ntrue, false);\r\n}\r\n} else {\r\nif (efx_ef10_filter_insert_addr_list(efx, vlan, true, true)) {\r\nif (nic_data->workaround_26807)\r\nefx_ef10_filter_remove_old(efx);\r\nif (efx_ef10_filter_insert_def(efx, vlan,\r\nEFX_ENCAP_TYPE_NONE,\r\ntrue, true))\r\nefx_ef10_filter_insert_addr_list(efx, vlan,\r\ntrue, false);\r\n}\r\n}\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_VXLAN,\r\ntrue, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_VXLAN |\r\nEFX_ENCAP_FLAG_IPV6,\r\ntrue, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_NVGRE,\r\ntrue, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_NVGRE |\r\nEFX_ENCAP_FLAG_IPV6,\r\ntrue, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_GENEVE,\r\ntrue, false);\r\nefx_ef10_filter_insert_def(efx, vlan, EFX_ENCAP_TYPE_GENEVE |\r\nEFX_ENCAP_FLAG_IPV6,\r\ntrue, false);\r\n}\r\nstatic void efx_ef10_filter_sync_rx_mode(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct net_device *net_dev = efx->net_dev;\r\nstruct efx_ef10_filter_vlan *vlan;\r\nbool vlan_filter;\r\nif (!efx_dev_registered(efx))\r\nreturn;\r\nif (!table)\r\nreturn;\r\nefx_ef10_filter_mark_old(efx);\r\nnetif_addr_lock_bh(net_dev);\r\nefx_ef10_filter_uc_addr_list(efx);\r\nefx_ef10_filter_mc_addr_list(efx);\r\nnetif_addr_unlock_bh(net_dev);\r\nvlan_filter = !!(net_dev->features & NETIF_F_HW_VLAN_CTAG_FILTER);\r\nif (table->vlan_filter != vlan_filter) {\r\ntable->vlan_filter = vlan_filter;\r\nefx_ef10_filter_remove_old(efx);\r\n}\r\nlist_for_each_entry(vlan, &table->vlan_list, list)\r\nefx_ef10_filter_vlan_sync_rx_mode(efx, vlan);\r\nefx_ef10_filter_remove_old(efx);\r\ntable->mc_promisc_last = table->mc_promisc;\r\n}\r\nstatic struct efx_ef10_filter_vlan *efx_ef10_filter_find_vlan(struct efx_nic *efx, u16 vid)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_filter_vlan *vlan;\r\nWARN_ON(!rwsem_is_locked(&efx->filter_sem));\r\nlist_for_each_entry(vlan, &table->vlan_list, list) {\r\nif (vlan->vid == vid)\r\nreturn vlan;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int efx_ef10_filter_add_vlan(struct efx_nic *efx, u16 vid)\r\n{\r\nstruct efx_ef10_filter_table *table = efx->filter_state;\r\nstruct efx_ef10_filter_vlan *vlan;\r\nunsigned int i;\r\nif (!efx_rwsem_assert_write_locked(&efx->filter_sem))\r\nreturn -EINVAL;\r\nvlan = efx_ef10_filter_find_vlan(efx, vid);\r\nif (WARN_ON(vlan)) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"VLAN %u already added\n", vid);\r\nreturn -EALREADY;\r\n}\r\nvlan = kzalloc(sizeof(*vlan), GFP_KERNEL);\r\nif (!vlan)\r\nreturn -ENOMEM;\r\nvlan->vid = vid;\r\nfor (i = 0; i < ARRAY_SIZE(vlan->uc); i++)\r\nvlan->uc[i] = EFX_EF10_FILTER_ID_INVALID;\r\nfor (i = 0; i < ARRAY_SIZE(vlan->mc); i++)\r\nvlan->mc[i] = EFX_EF10_FILTER_ID_INVALID;\r\nfor (i = 0; i < EFX_EF10_NUM_DEFAULT_FILTERS; i++)\r\nvlan->default_filters[i] = EFX_EF10_FILTER_ID_INVALID;\r\nlist_add_tail(&vlan->list, &table->vlan_list);\r\nif (efx_dev_registered(efx))\r\nefx_ef10_filter_vlan_sync_rx_mode(efx, vlan);\r\nreturn 0;\r\n}\r\nstatic void efx_ef10_filter_del_vlan_internal(struct efx_nic *efx,\r\nstruct efx_ef10_filter_vlan *vlan)\r\n{\r\nunsigned int i;\r\nif (!efx_rwsem_assert_write_locked(&efx->filter_sem))\r\nreturn;\r\nlist_del(&vlan->list);\r\nfor (i = 0; i < ARRAY_SIZE(vlan->uc); i++)\r\nefx_ef10_filter_remove_unsafe(efx, EFX_FILTER_PRI_AUTO,\r\nvlan->uc[i]);\r\nfor (i = 0; i < ARRAY_SIZE(vlan->mc); i++)\r\nefx_ef10_filter_remove_unsafe(efx, EFX_FILTER_PRI_AUTO,\r\nvlan->mc[i]);\r\nfor (i = 0; i < EFX_EF10_NUM_DEFAULT_FILTERS; i++)\r\nif (vlan->default_filters[i] != EFX_EF10_FILTER_ID_INVALID)\r\nefx_ef10_filter_remove_unsafe(efx, EFX_FILTER_PRI_AUTO,\r\nvlan->default_filters[i]);\r\nkfree(vlan);\r\n}\r\nstatic void efx_ef10_filter_del_vlan(struct efx_nic *efx, u16 vid)\r\n{\r\nstruct efx_ef10_filter_vlan *vlan;\r\nif (!efx_rwsem_assert_write_locked(&efx->filter_sem))\r\nreturn;\r\nvlan = efx_ef10_filter_find_vlan(efx, vid);\r\nif (!vlan) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"VLAN %u not found in filter state\n", vid);\r\nreturn;\r\n}\r\nefx_ef10_filter_del_vlan_internal(efx, vlan);\r\n}\r\nstatic int efx_ef10_set_mac_address(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_VADAPTOR_SET_MAC_IN_LEN);\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nbool was_enabled = efx->port_enabled;\r\nint rc;\r\nefx_device_detach_sync(efx);\r\nefx_net_stop(efx->net_dev);\r\nmutex_lock(&efx->mac_lock);\r\ndown_write(&efx->filter_sem);\r\nefx_ef10_filter_table_remove(efx);\r\nether_addr_copy(MCDI_PTR(inbuf, VADAPTOR_SET_MAC_IN_MACADDR),\r\nefx->net_dev->dev_addr);\r\nMCDI_SET_DWORD(inbuf, VADAPTOR_SET_MAC_IN_UPSTREAM_PORT_ID,\r\nnic_data->vport_id);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_VADAPTOR_SET_MAC, inbuf,\r\nsizeof(inbuf), NULL, 0, NULL);\r\nefx_ef10_filter_table_probe(efx);\r\nup_write(&efx->filter_sem);\r\nmutex_unlock(&efx->mac_lock);\r\nif (was_enabled)\r\nefx_net_open(efx->net_dev);\r\nefx_device_attach_if_not_resetting(efx);\r\n#ifdef CONFIG_SFC_SRIOV\r\nif (efx->pci_dev->is_virtfn && efx->pci_dev->physfn) {\r\nstruct pci_dev *pci_dev_pf = efx->pci_dev->physfn;\r\nif (rc == -EPERM) {\r\nstruct efx_nic *efx_pf;\r\nefx_pf = pci_get_drvdata(pci_dev_pf);\r\nrc = efx_ef10_sriov_set_vf_mac(efx_pf,\r\nnic_data->vf_index,\r\nefx->net_dev->dev_addr);\r\n} else if (!rc) {\r\nstruct efx_nic *efx_pf = pci_get_drvdata(pci_dev_pf);\r\nstruct efx_ef10_nic_data *nic_data = efx_pf->nic_data;\r\nunsigned int i;\r\nfor (i = 0; i < efx_pf->vf_count; ++i) {\r\nstruct ef10_vf *vf = nic_data->vf + i;\r\nif (vf->efx == efx) {\r\nether_addr_copy(vf->mac,\r\nefx->net_dev->dev_addr);\r\nreturn 0;\r\n}\r\n}\r\n}\r\n} else\r\n#endif\r\nif (rc == -EPERM) {\r\nnetif_err(efx, drv, efx->net_dev,\r\n"Cannot change MAC address; use sfboot to enable"\r\n" mac-spoofing on this interface\n");\r\n} else if (rc == -ENOSYS && !efx_ef10_is_vf(efx)) {\r\nrc = efx_ef10_vport_set_mac_address(efx);\r\n} else {\r\nefx_mcdi_display_error(efx, MC_CMD_VADAPTOR_SET_MAC,\r\nsizeof(inbuf), NULL, 0, rc);\r\n}\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_mac_reconfigure(struct efx_nic *efx)\r\n{\r\nefx_ef10_filter_sync_rx_mode(efx);\r\nreturn efx_mcdi_set_mac(efx);\r\n}\r\nstatic int efx_ef10_mac_reconfigure_vf(struct efx_nic *efx)\r\n{\r\nefx_ef10_filter_sync_rx_mode(efx);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_start_bist(struct efx_nic *efx, u32 bist_type)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_START_BIST_IN_LEN);\r\nMCDI_SET_DWORD(inbuf, START_BIST_IN_TYPE, bist_type);\r\nreturn efx_mcdi_rpc(efx, MC_CMD_START_BIST, inbuf, sizeof(inbuf),\r\nNULL, 0, NULL);\r\n}\r\nstatic int efx_ef10_poll_bist(struct efx_nic *efx)\r\n{\r\nint rc;\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_POLL_BIST_OUT_LEN);\r\nsize_t outlen;\r\nu32 result;\r\nrc = efx_mcdi_rpc(efx, MC_CMD_POLL_BIST, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc != 0)\r\nreturn rc;\r\nif (outlen < MC_CMD_POLL_BIST_OUT_LEN)\r\nreturn -EIO;\r\nresult = MCDI_DWORD(outbuf, POLL_BIST_OUT_RESULT);\r\nswitch (result) {\r\ncase MC_CMD_POLL_BIST_PASSED:\r\nnetif_dbg(efx, hw, efx->net_dev, "BIST passed.\n");\r\nreturn 0;\r\ncase MC_CMD_POLL_BIST_TIMEOUT:\r\nnetif_err(efx, hw, efx->net_dev, "BIST timed out\n");\r\nreturn -EIO;\r\ncase MC_CMD_POLL_BIST_FAILED:\r\nnetif_err(efx, hw, efx->net_dev, "BIST failed.\n");\r\nreturn -EIO;\r\ndefault:\r\nnetif_err(efx, hw, efx->net_dev,\r\n"BIST returned unknown result %u", result);\r\nreturn -EIO;\r\n}\r\n}\r\nstatic int efx_ef10_run_bist(struct efx_nic *efx, u32 bist_type)\r\n{\r\nint rc;\r\nnetif_dbg(efx, drv, efx->net_dev, "starting BIST type %u\n", bist_type);\r\nrc = efx_ef10_start_bist(efx, bist_type);\r\nif (rc != 0)\r\nreturn rc;\r\nreturn efx_ef10_poll_bist(efx);\r\n}\r\nstatic int\r\nefx_ef10_test_chip(struct efx_nic *efx, struct efx_self_tests *tests)\r\n{\r\nint rc, rc2;\r\nefx_reset_down(efx, RESET_TYPE_WORLD);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_ENABLE_OFFLINE_BIST,\r\nNULL, 0, NULL, 0, NULL);\r\nif (rc != 0)\r\ngoto out;\r\ntests->memory = efx_ef10_run_bist(efx, MC_CMD_MC_MEM_BIST) ? -1 : 1;\r\ntests->registers = efx_ef10_run_bist(efx, MC_CMD_REG_BIST) ? -1 : 1;\r\nrc = efx_mcdi_reset(efx, RESET_TYPE_WORLD);\r\nout:\r\nif (rc == -EPERM)\r\nrc = 0;\r\nrc2 = efx_reset_up(efx, RESET_TYPE_WORLD, rc == 0);\r\nreturn rc ? rc : rc2;\r\n}\r\nstatic int efx_ef10_mtd_probe_partition(struct efx_nic *efx,\r\nstruct efx_mcdi_mtd_partition *part,\r\nunsigned int type)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_NVRAM_METADATA_IN_LEN);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_NVRAM_METADATA_OUT_LENMAX);\r\nconst struct efx_ef10_nvram_type_info *info;\r\nsize_t size, erase_size, outlen;\r\nbool protected;\r\nint rc;\r\nfor (info = efx_ef10_nvram_types; ; info++) {\r\nif (info ==\r\nefx_ef10_nvram_types + ARRAY_SIZE(efx_ef10_nvram_types))\r\nreturn -ENODEV;\r\nif ((type & ~info->type_mask) == info->type)\r\nbreak;\r\n}\r\nif (info->port != efx_port_num(efx))\r\nreturn -ENODEV;\r\nrc = efx_mcdi_nvram_info(efx, type, &size, &erase_size, &protected);\r\nif (rc)\r\nreturn rc;\r\nif (protected)\r\nreturn -ENODEV;\r\npart->nvram_type = type;\r\nMCDI_SET_DWORD(inbuf, NVRAM_METADATA_IN_TYPE, type);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_NVRAM_METADATA, inbuf, sizeof(inbuf),\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_NVRAM_METADATA_OUT_LENMIN)\r\nreturn -EIO;\r\nif (MCDI_DWORD(outbuf, NVRAM_METADATA_OUT_FLAGS) &\r\n(1 << MC_CMD_NVRAM_METADATA_OUT_SUBTYPE_VALID_LBN))\r\npart->fw_subtype = MCDI_DWORD(outbuf,\r\nNVRAM_METADATA_OUT_SUBTYPE);\r\npart->common.dev_type_name = "EF10 NVRAM manager";\r\npart->common.type_name = info->name;\r\npart->common.mtd.type = MTD_NORFLASH;\r\npart->common.mtd.flags = MTD_CAP_NORFLASH;\r\npart->common.mtd.size = size;\r\npart->common.mtd.erasesize = erase_size;\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_mtd_probe(struct efx_nic *efx)\r\n{\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_NVRAM_PARTITIONS_OUT_LENMAX);\r\nstruct efx_mcdi_mtd_partition *parts;\r\nsize_t outlen, n_parts_total, i, n_parts;\r\nunsigned int type;\r\nint rc;\r\nASSERT_RTNL();\r\nBUILD_BUG_ON(MC_CMD_NVRAM_PARTITIONS_IN_LEN != 0);\r\nrc = efx_mcdi_rpc(efx, MC_CMD_NVRAM_PARTITIONS, NULL, 0,\r\noutbuf, sizeof(outbuf), &outlen);\r\nif (rc)\r\nreturn rc;\r\nif (outlen < MC_CMD_NVRAM_PARTITIONS_OUT_LENMIN)\r\nreturn -EIO;\r\nn_parts_total = MCDI_DWORD(outbuf, NVRAM_PARTITIONS_OUT_NUM_PARTITIONS);\r\nif (n_parts_total >\r\nMCDI_VAR_ARRAY_LEN(outlen, NVRAM_PARTITIONS_OUT_TYPE_ID))\r\nreturn -EIO;\r\nparts = kcalloc(n_parts_total, sizeof(*parts), GFP_KERNEL);\r\nif (!parts)\r\nreturn -ENOMEM;\r\nn_parts = 0;\r\nfor (i = 0; i < n_parts_total; i++) {\r\ntype = MCDI_ARRAY_DWORD(outbuf, NVRAM_PARTITIONS_OUT_TYPE_ID,\r\ni);\r\nrc = efx_ef10_mtd_probe_partition(efx, &parts[n_parts], type);\r\nif (rc == 0)\r\nn_parts++;\r\nelse if (rc != -ENODEV)\r\ngoto fail;\r\n}\r\nrc = efx_mtd_add(efx, &parts[0].common, n_parts, sizeof(*parts));\r\nfail:\r\nif (rc)\r\nkfree(parts);\r\nreturn rc;\r\n}\r\nstatic void efx_ef10_ptp_write_host_time(struct efx_nic *efx, u32 host_time)\r\n{\r\n_efx_writed(efx, cpu_to_le32(host_time), ER_DZ_MC_DB_LWRD);\r\n}\r\nstatic void efx_ef10_ptp_write_host_time_vf(struct efx_nic *efx,\r\nu32 host_time) {}\r\nstatic int efx_ef10_rx_enable_timestamping(struct efx_channel *channel,\r\nbool temp)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_PTP_IN_TIME_EVENT_SUBSCRIBE_LEN);\r\nint rc;\r\nif (channel->sync_events_state == SYNC_EVENTS_REQUESTED ||\r\nchannel->sync_events_state == SYNC_EVENTS_VALID ||\r\n(temp && channel->sync_events_state == SYNC_EVENTS_DISABLED))\r\nreturn 0;\r\nchannel->sync_events_state = SYNC_EVENTS_REQUESTED;\r\nMCDI_SET_DWORD(inbuf, PTP_IN_OP, MC_CMD_PTP_OP_TIME_EVENT_SUBSCRIBE);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_PERIPH_ID, 0);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_TIME_EVENT_SUBSCRIBE_QUEUE,\r\nchannel->channel);\r\nrc = efx_mcdi_rpc(channel->efx, MC_CMD_PTP,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\nif (rc != 0)\r\nchannel->sync_events_state = temp ? SYNC_EVENTS_QUIESCENT :\r\nSYNC_EVENTS_DISABLED;\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_rx_disable_timestamping(struct efx_channel *channel,\r\nbool temp)\r\n{\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_PTP_IN_TIME_EVENT_UNSUBSCRIBE_LEN);\r\nint rc;\r\nif (channel->sync_events_state == SYNC_EVENTS_DISABLED ||\r\n(temp && channel->sync_events_state == SYNC_EVENTS_QUIESCENT))\r\nreturn 0;\r\nif (channel->sync_events_state == SYNC_EVENTS_QUIESCENT) {\r\nchannel->sync_events_state = SYNC_EVENTS_DISABLED;\r\nreturn 0;\r\n}\r\nchannel->sync_events_state = temp ? SYNC_EVENTS_QUIESCENT :\r\nSYNC_EVENTS_DISABLED;\r\nMCDI_SET_DWORD(inbuf, PTP_IN_OP, MC_CMD_PTP_OP_TIME_EVENT_UNSUBSCRIBE);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_PERIPH_ID, 0);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_TIME_EVENT_UNSUBSCRIBE_CONTROL,\r\nMC_CMD_PTP_IN_TIME_EVENT_UNSUBSCRIBE_SINGLE);\r\nMCDI_SET_DWORD(inbuf, PTP_IN_TIME_EVENT_UNSUBSCRIBE_QUEUE,\r\nchannel->channel);\r\nrc = efx_mcdi_rpc(channel->efx, MC_CMD_PTP,\r\ninbuf, sizeof(inbuf), NULL, 0, NULL);\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_ptp_set_ts_sync_events(struct efx_nic *efx, bool en,\r\nbool temp)\r\n{\r\nint (*set)(struct efx_channel *channel, bool temp);\r\nstruct efx_channel *channel;\r\nset = en ?\r\nefx_ef10_rx_enable_timestamping :\r\nefx_ef10_rx_disable_timestamping;\r\nefx_for_each_channel(channel, efx) {\r\nint rc = set(channel, temp);\r\nif (en && rc != 0) {\r\nefx_ef10_ptp_set_ts_sync_events(efx, false, temp);\r\nreturn rc;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_ptp_set_ts_config_vf(struct efx_nic *efx,\r\nstruct hwtstamp_config *init)\r\n{\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic int efx_ef10_ptp_set_ts_config(struct efx_nic *efx,\r\nstruct hwtstamp_config *init)\r\n{\r\nint rc;\r\nswitch (init->rx_filter) {\r\ncase HWTSTAMP_FILTER_NONE:\r\nefx_ef10_ptp_set_ts_sync_events(efx, false, false);\r\nreturn efx_ptp_change_mode(efx,\r\ninit->tx_type != HWTSTAMP_TX_OFF, 0);\r\ncase HWTSTAMP_FILTER_ALL:\r\ncase HWTSTAMP_FILTER_PTP_V1_L4_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V1_L4_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:\r\ncase HWTSTAMP_FILTER_PTP_V2_L4_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V2_L4_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:\r\ncase HWTSTAMP_FILTER_PTP_V2_L2_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V2_L2_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:\r\ncase HWTSTAMP_FILTER_PTP_V2_EVENT:\r\ncase HWTSTAMP_FILTER_PTP_V2_SYNC:\r\ncase HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:\r\ncase HWTSTAMP_FILTER_NTP_ALL:\r\ninit->rx_filter = HWTSTAMP_FILTER_ALL;\r\nrc = efx_ptp_change_mode(efx, true, 0);\r\nif (!rc)\r\nrc = efx_ef10_ptp_set_ts_sync_events(efx, true, false);\r\nif (rc)\r\nefx_ptp_change_mode(efx, false, 0);\r\nreturn rc;\r\ndefault:\r\nreturn -ERANGE;\r\n}\r\n}\r\nstatic int efx_ef10_get_phys_port_id(struct efx_nic *efx,\r\nstruct netdev_phys_item_id *ppid)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (!is_valid_ether_addr(nic_data->port_id))\r\nreturn -EOPNOTSUPP;\r\nppid->id_len = ETH_ALEN;\r\nmemcpy(ppid->id, nic_data->port_id, ppid->id_len);\r\nreturn 0;\r\n}\r\nstatic int efx_ef10_vlan_rx_add_vid(struct efx_nic *efx, __be16 proto, u16 vid)\r\n{\r\nif (proto != htons(ETH_P_8021Q))\r\nreturn -EINVAL;\r\nreturn efx_ef10_add_vlan(efx, vid);\r\n}\r\nstatic int efx_ef10_vlan_rx_kill_vid(struct efx_nic *efx, __be16 proto, u16 vid)\r\n{\r\nif (proto != htons(ETH_P_8021Q))\r\nreturn -EINVAL;\r\nreturn efx_ef10_del_vlan(efx, vid);\r\n}\r\nstatic int efx_ef10_set_udp_tnl_ports(struct efx_nic *efx, bool unloading)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nMCDI_DECLARE_BUF(inbuf, MC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_IN_LENMAX);\r\nMCDI_DECLARE_BUF(outbuf, MC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_OUT_LEN);\r\nbool will_reset = false;\r\nsize_t num_entries = 0;\r\nsize_t inlen, outlen;\r\nsize_t i;\r\nint rc;\r\nefx_dword_t flags_and_num_entries;\r\nWARN_ON(!mutex_is_locked(&nic_data->udp_tunnels_lock));\r\nnic_data->udp_tunnels_dirty = false;\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VXLAN_NVGRE_LBN))) {\r\nefx_device_attach_if_not_resetting(efx);\r\nreturn 0;\r\n}\r\nBUILD_BUG_ON(ARRAY_SIZE(nic_data->udp_tunnels) >\r\nMC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_IN_ENTRIES_MAXNUM);\r\nfor (i = 0; i < ARRAY_SIZE(nic_data->udp_tunnels); ++i) {\r\nif (nic_data->udp_tunnels[i].count &&\r\nnic_data->udp_tunnels[i].port) {\r\nefx_dword_t entry;\r\nEFX_POPULATE_DWORD_2(entry,\r\nTUNNEL_ENCAP_UDP_PORT_ENTRY_UDP_PORT,\r\nntohs(nic_data->udp_tunnels[i].port),\r\nTUNNEL_ENCAP_UDP_PORT_ENTRY_PROTOCOL,\r\nnic_data->udp_tunnels[i].type);\r\n*_MCDI_ARRAY_DWORD(inbuf,\r\nSET_TUNNEL_ENCAP_UDP_PORTS_IN_ENTRIES,\r\nnum_entries++) = entry;\r\n}\r\n}\r\nBUILD_BUG_ON((MC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_IN_NUM_ENTRIES_OFST -\r\nMC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_IN_FLAGS_OFST) * 8 !=\r\nEFX_WORD_1_LBN);\r\nBUILD_BUG_ON(MC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_IN_NUM_ENTRIES_LEN * 8 !=\r\nEFX_WORD_1_WIDTH);\r\nEFX_POPULATE_DWORD_2(flags_and_num_entries,\r\nMC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_IN_UNLOADING,\r\n!!unloading,\r\nEFX_WORD_1, num_entries);\r\n*_MCDI_DWORD(inbuf, SET_TUNNEL_ENCAP_UDP_PORTS_IN_FLAGS) =\r\nflags_and_num_entries;\r\ninlen = MC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_IN_LEN(num_entries);\r\nrc = efx_mcdi_rpc_quiet(efx, MC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS,\r\ninbuf, inlen, outbuf, sizeof(outbuf), &outlen);\r\nif (rc == -EIO) {\r\nnic_data->udp_tunnels_dirty = true;\r\nreturn 0;\r\n}\r\nif (rc) {\r\nif (rc != -EPERM)\r\nnetif_warn(efx, drv, efx->net_dev,\r\n"Unable to set UDP tunnel ports; rc=%d.\n", rc);\r\n} else if (MCDI_DWORD(outbuf, SET_TUNNEL_ENCAP_UDP_PORTS_OUT_FLAGS) &\r\n(1 << MC_CMD_SET_TUNNEL_ENCAP_UDP_PORTS_OUT_RESETTING_LBN)) {\r\nnetif_info(efx, drv, efx->net_dev,\r\n"Rebooting MC due to UDP tunnel port list change\n");\r\nwill_reset = true;\r\nif (unloading)\r\nmsleep(100);\r\n}\r\nif (!will_reset && !unloading) {\r\nefx_device_attach_if_not_resetting(efx);\r\n}\r\nreturn rc;\r\n}\r\nstatic int efx_ef10_udp_tnl_push_ports(struct efx_nic *efx)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nint rc = 0;\r\nmutex_lock(&nic_data->udp_tunnels_lock);\r\nif (nic_data->udp_tunnels_dirty) {\r\nefx_device_detach_sync(efx);\r\nrc = efx_ef10_set_udp_tnl_ports(efx, false);\r\n}\r\nmutex_unlock(&nic_data->udp_tunnels_lock);\r\nreturn rc;\r\n}\r\nstatic struct efx_udp_tunnel *__efx_ef10_udp_tnl_lookup_port(struct efx_nic *efx,\r\n__be16 port)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nsize_t i;\r\nfor (i = 0; i < ARRAY_SIZE(nic_data->udp_tunnels); ++i) {\r\nif (!nic_data->udp_tunnels[i].count)\r\ncontinue;\r\nif (nic_data->udp_tunnels[i].port == port)\r\nreturn &nic_data->udp_tunnels[i];\r\n}\r\nreturn NULL;\r\n}\r\nstatic int efx_ef10_udp_tnl_add_port(struct efx_nic *efx,\r\nstruct efx_udp_tunnel tnl)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_udp_tunnel *match;\r\nchar typebuf[8];\r\nsize_t i;\r\nint rc;\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VXLAN_NVGRE_LBN)))\r\nreturn 0;\r\nefx_get_udp_tunnel_type_name(tnl.type, typebuf, sizeof(typebuf));\r\nnetif_dbg(efx, drv, efx->net_dev, "Adding UDP tunnel (%s) port %d\n",\r\ntypebuf, ntohs(tnl.port));\r\nmutex_lock(&nic_data->udp_tunnels_lock);\r\nefx_device_detach_sync(efx);\r\nmatch = __efx_ef10_udp_tnl_lookup_port(efx, tnl.port);\r\nif (match != NULL) {\r\nif (match->type == tnl.type) {\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"Referencing existing tunnel entry\n");\r\nmatch->count++;\r\nrc = 0;\r\ngoto unlock_out;\r\n}\r\nefx_get_udp_tunnel_type_name(match->type,\r\ntypebuf, sizeof(typebuf));\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"UDP port %d is already in use by %s\n",\r\nntohs(tnl.port), typebuf);\r\nrc = -EEXIST;\r\ngoto unlock_out;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(nic_data->udp_tunnels); ++i)\r\nif (!nic_data->udp_tunnels[i].count) {\r\nnic_data->udp_tunnels[i] = tnl;\r\nnic_data->udp_tunnels[i].count = 1;\r\nrc = efx_ef10_set_udp_tnl_ports(efx, false);\r\ngoto unlock_out;\r\n}\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"Unable to add UDP tunnel (%s) port %d; insufficient resources.\n",\r\ntypebuf, ntohs(tnl.port));\r\nrc = -ENOMEM;\r\nunlock_out:\r\nmutex_unlock(&nic_data->udp_tunnels_lock);\r\nreturn rc;\r\n}\r\nstatic bool efx_ef10_udp_tnl_has_port(struct efx_nic *efx, __be16 port)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VXLAN_NVGRE_LBN)))\r\nreturn false;\r\nif (nic_data->udp_tunnels_dirty)\r\nreturn false;\r\nreturn __efx_ef10_udp_tnl_lookup_port(efx, port) != NULL;\r\n}\r\nstatic int efx_ef10_udp_tnl_del_port(struct efx_nic *efx,\r\nstruct efx_udp_tunnel tnl)\r\n{\r\nstruct efx_ef10_nic_data *nic_data = efx->nic_data;\r\nstruct efx_udp_tunnel *match;\r\nchar typebuf[8];\r\nint rc;\r\nif (!(nic_data->datapath_caps &\r\n(1 << MC_CMD_GET_CAPABILITIES_OUT_VXLAN_NVGRE_LBN)))\r\nreturn 0;\r\nefx_get_udp_tunnel_type_name(tnl.type, typebuf, sizeof(typebuf));\r\nnetif_dbg(efx, drv, efx->net_dev, "Removing UDP tunnel (%s) port %d\n",\r\ntypebuf, ntohs(tnl.port));\r\nmutex_lock(&nic_data->udp_tunnels_lock);\r\nefx_device_detach_sync(efx);\r\nmatch = __efx_ef10_udp_tnl_lookup_port(efx, tnl.port);\r\nif (match != NULL) {\r\nif (match->type == tnl.type) {\r\nif (--match->count) {\r\nnetif_dbg(efx, drv, efx->net_dev,\r\n"UDP tunnel port %d remains active\n",\r\nntohs(tnl.port));\r\nrc = 0;\r\ngoto out_unlock;\r\n}\r\nrc = efx_ef10_set_udp_tnl_ports(efx, false);\r\ngoto out_unlock;\r\n}\r\nefx_get_udp_tunnel_type_name(match->type,\r\ntypebuf, sizeof(typebuf));\r\nnetif_warn(efx, drv, efx->net_dev,\r\n"UDP port %d is actually in use by %s, not removing\n",\r\nntohs(tnl.port), typebuf);\r\n}\r\nrc = -ENOENT;\r\nout_unlock:\r\nmutex_unlock(&nic_data->udp_tunnels_lock);\r\nreturn rc;\r\n}
