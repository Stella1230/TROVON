static inline void setup_base_pdu(struct usbip_header_basic *base,\r\n__u32 command, __u32 seqnum)\r\n{\r\nbase->command = command;\r\nbase->seqnum = seqnum;\r\nbase->devid = 0;\r\nbase->ep = 0;\r\nbase->direction = 0;\r\n}\r\nstatic void setup_ret_submit_pdu(struct usbip_header *rpdu, struct urbp *urb_p)\r\n{\r\nsetup_base_pdu(&rpdu->base, USBIP_RET_SUBMIT, urb_p->seqnum);\r\nusbip_pack_pdu(rpdu, urb_p->urb, USBIP_RET_SUBMIT, 1);\r\n}\r\nstatic void setup_ret_unlink_pdu(struct usbip_header *rpdu,\r\nstruct v_unlink *unlink)\r\n{\r\nsetup_base_pdu(&rpdu->base, USBIP_RET_UNLINK, unlink->seqnum);\r\nrpdu->u.ret_unlink.status = unlink->status;\r\n}\r\nstatic int v_send_ret_unlink(struct vudc *udc, struct v_unlink *unlink)\r\n{\r\nstruct msghdr msg;\r\nstruct kvec iov[1];\r\nsize_t txsize;\r\nint ret;\r\nstruct usbip_header pdu_header;\r\ntxsize = 0;\r\nmemset(&pdu_header, 0, sizeof(pdu_header));\r\nmemset(&msg, 0, sizeof(msg));\r\nmemset(&iov, 0, sizeof(iov));\r\nsetup_ret_unlink_pdu(&pdu_header, unlink);\r\nusbip_header_correct_endian(&pdu_header, 1);\r\niov[0].iov_base = &pdu_header;\r\niov[0].iov_len = sizeof(pdu_header);\r\ntxsize += sizeof(pdu_header);\r\nret = kernel_sendmsg(udc->ud.tcp_socket, &msg, iov,\r\n1, txsize);\r\nif (ret != txsize) {\r\nusbip_event_add(&udc->ud, VUDC_EVENT_ERROR_TCP);\r\nif (ret >= 0)\r\nreturn -EPIPE;\r\nreturn ret;\r\n}\r\nkfree(unlink);\r\nreturn txsize;\r\n}\r\nstatic int v_send_ret_submit(struct vudc *udc, struct urbp *urb_p)\r\n{\r\nstruct urb *urb = urb_p->urb;\r\nstruct usbip_header pdu_header;\r\nstruct usbip_iso_packet_descriptor *iso_buffer = NULL;\r\nstruct kvec *iov = NULL;\r\nint iovnum = 0;\r\nint ret = 0;\r\nsize_t txsize;\r\nstruct msghdr msg;\r\ntxsize = 0;\r\nmemset(&pdu_header, 0, sizeof(pdu_header));\r\nmemset(&msg, 0, sizeof(msg));\r\nif (urb_p->type == USB_ENDPOINT_XFER_ISOC)\r\niovnum = 2 + urb->number_of_packets;\r\nelse\r\niovnum = 2;\r\niov = kcalloc(iovnum, sizeof(*iov), GFP_KERNEL);\r\nif (!iov) {\r\nusbip_event_add(&udc->ud, VUDC_EVENT_ERROR_MALLOC);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\niovnum = 0;\r\nsetup_ret_submit_pdu(&pdu_header, urb_p);\r\nusbip_dbg_stub_tx("setup txdata seqnum: %d urb: %p\n",\r\npdu_header.base.seqnum, urb);\r\nusbip_header_correct_endian(&pdu_header, 1);\r\niov[iovnum].iov_base = &pdu_header;\r\niov[iovnum].iov_len = sizeof(pdu_header);\r\niovnum++;\r\ntxsize += sizeof(pdu_header);\r\nif (urb_p->type != USB_ENDPOINT_XFER_ISOC &&\r\nusb_pipein(urb->pipe) && urb->actual_length > 0) {\r\niov[iovnum].iov_base = urb->transfer_buffer;\r\niov[iovnum].iov_len = urb->actual_length;\r\niovnum++;\r\ntxsize += urb->actual_length;\r\n} else if (urb_p->type == USB_ENDPOINT_XFER_ISOC &&\r\nusb_pipein(urb->pipe)) {\r\nint i;\r\nfor (i = 0; i < urb->number_of_packets; i++) {\r\niov[iovnum].iov_base = urb->transfer_buffer +\r\nurb->iso_frame_desc[i].offset;\r\niov[iovnum].iov_len =\r\nurb->iso_frame_desc[i].actual_length;\r\niovnum++;\r\ntxsize += urb->iso_frame_desc[i].actual_length;\r\n}\r\nif (txsize != sizeof(pdu_header) + urb->actual_length) {\r\nusbip_event_add(&udc->ud, VUDC_EVENT_ERROR_TCP);\r\nret = -EPIPE;\r\ngoto out;\r\n}\r\n}\r\nif (urb_p->type == USB_ENDPOINT_XFER_ISOC) {\r\nssize_t len = 0;\r\niso_buffer = usbip_alloc_iso_desc_pdu(urb, &len);\r\nif (!iso_buffer) {\r\nusbip_event_add(&udc->ud,\r\nVUDC_EVENT_ERROR_MALLOC);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\niov[iovnum].iov_base = iso_buffer;\r\niov[iovnum].iov_len = len;\r\ntxsize += len;\r\niovnum++;\r\n}\r\nret = kernel_sendmsg(udc->ud.tcp_socket, &msg,\r\niov, iovnum, txsize);\r\nif (ret != txsize) {\r\nusbip_event_add(&udc->ud, VUDC_EVENT_ERROR_TCP);\r\nif (ret >= 0)\r\nret = -EPIPE;\r\ngoto out;\r\n}\r\nout:\r\nkfree(iov);\r\nkfree(iso_buffer);\r\nfree_urbp_and_urb(urb_p);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn txsize;\r\n}\r\nstatic int v_send_ret(struct vudc *udc)\r\n{\r\nunsigned long flags;\r\nstruct tx_item *txi;\r\nsize_t total_size = 0;\r\nint ret = 0;\r\nspin_lock_irqsave(&udc->lock_tx, flags);\r\nwhile (!list_empty(&udc->tx_queue)) {\r\ntxi = list_first_entry(&udc->tx_queue, struct tx_item,\r\ntx_entry);\r\nlist_del(&txi->tx_entry);\r\nspin_unlock_irqrestore(&udc->lock_tx, flags);\r\nswitch (txi->type) {\r\ncase TX_SUBMIT:\r\nret = v_send_ret_submit(udc, txi->s);\r\nbreak;\r\ncase TX_UNLINK:\r\nret = v_send_ret_unlink(udc, txi->u);\r\nbreak;\r\n}\r\nkfree(txi);\r\nif (ret < 0)\r\nreturn ret;\r\ntotal_size += ret;\r\nspin_lock_irqsave(&udc->lock_tx, flags);\r\n}\r\nspin_unlock_irqrestore(&udc->lock_tx, flags);\r\nreturn total_size;\r\n}\r\nint v_tx_loop(void *data)\r\n{\r\nstruct usbip_device *ud = (struct usbip_device *) data;\r\nstruct vudc *udc = container_of(ud, struct vudc, ud);\r\nint ret;\r\nwhile (!kthread_should_stop()) {\r\nif (usbip_event_happened(&udc->ud))\r\nbreak;\r\nret = v_send_ret(udc);\r\nif (ret < 0) {\r\npr_warn("v_tx exit with error %d", ret);\r\nbreak;\r\n}\r\nwait_event_interruptible(udc->tx_waitq,\r\n(!list_empty(&udc->tx_queue) ||\r\nkthread_should_stop()));\r\n}\r\nreturn 0;\r\n}\r\nvoid v_enqueue_ret_unlink(struct vudc *udc, __u32 seqnum, __u32 status)\r\n{\r\nstruct tx_item *txi;\r\nstruct v_unlink *unlink;\r\ntxi = kzalloc(sizeof(*txi), GFP_ATOMIC);\r\nif (!txi) {\r\nusbip_event_add(&udc->ud, VDEV_EVENT_ERROR_MALLOC);\r\nreturn;\r\n}\r\nunlink = kzalloc(sizeof(*unlink), GFP_ATOMIC);\r\nif (!unlink) {\r\nkfree(txi);\r\nusbip_event_add(&udc->ud, VDEV_EVENT_ERROR_MALLOC);\r\nreturn;\r\n}\r\nunlink->seqnum = seqnum;\r\nunlink->status = status;\r\ntxi->type = TX_UNLINK;\r\ntxi->u = unlink;\r\nlist_add_tail(&txi->tx_entry, &udc->tx_queue);\r\n}\r\nvoid v_enqueue_ret_submit(struct vudc *udc, struct urbp *urb_p)\r\n{\r\nstruct tx_item *txi;\r\ntxi = kzalloc(sizeof(*txi), GFP_ATOMIC);\r\nif (!txi) {\r\nusbip_event_add(&udc->ud, VDEV_EVENT_ERROR_MALLOC);\r\nreturn;\r\n}\r\ntxi->type = TX_SUBMIT;\r\ntxi->s = urb_p;\r\nlist_add_tail(&txi->tx_entry, &udc->tx_queue);\r\n}
