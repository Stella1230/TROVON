static inline unsigned long rnrnak_jiffies(u8 timeout)\r\n{\r\nreturn max_t(unsigned long,\r\nusecs_to_jiffies(rnrnak_usec[timeout]), 1);\r\n}\r\nstatic enum ib_wc_opcode wr_to_wc_opcode(enum ib_wr_opcode opcode)\r\n{\r\nswitch (opcode) {\r\ncase IB_WR_RDMA_WRITE: return IB_WC_RDMA_WRITE;\r\ncase IB_WR_RDMA_WRITE_WITH_IMM: return IB_WC_RDMA_WRITE;\r\ncase IB_WR_SEND: return IB_WC_SEND;\r\ncase IB_WR_SEND_WITH_IMM: return IB_WC_SEND;\r\ncase IB_WR_RDMA_READ: return IB_WC_RDMA_READ;\r\ncase IB_WR_ATOMIC_CMP_AND_SWP: return IB_WC_COMP_SWAP;\r\ncase IB_WR_ATOMIC_FETCH_AND_ADD: return IB_WC_FETCH_ADD;\r\ncase IB_WR_LSO: return IB_WC_LSO;\r\ncase IB_WR_SEND_WITH_INV: return IB_WC_SEND;\r\ncase IB_WR_RDMA_READ_WITH_INV: return IB_WC_RDMA_READ;\r\ncase IB_WR_LOCAL_INV: return IB_WC_LOCAL_INV;\r\ncase IB_WR_REG_MR: return IB_WC_REG_MR;\r\ndefault:\r\nreturn 0xff;\r\n}\r\n}\r\nvoid retransmit_timer(unsigned long data)\r\n{\r\nstruct rxe_qp *qp = (struct rxe_qp *)data;\r\nif (qp->valid) {\r\nqp->comp.timeout = 1;\r\nrxe_run_task(&qp->comp.task, 1);\r\n}\r\n}\r\nvoid rxe_comp_queue_pkt(struct rxe_dev *rxe, struct rxe_qp *qp,\r\nstruct sk_buff *skb)\r\n{\r\nint must_sched;\r\nskb_queue_tail(&qp->resp_pkts, skb);\r\nmust_sched = skb_queue_len(&qp->resp_pkts) > 1;\r\nif (must_sched != 0)\r\nrxe_counter_inc(rxe, RXE_CNT_COMPLETER_SCHED);\r\nrxe_run_task(&qp->comp.task, must_sched);\r\n}\r\nstatic inline enum comp_state get_wqe(struct rxe_qp *qp,\r\nstruct rxe_pkt_info *pkt,\r\nstruct rxe_send_wqe **wqe_p)\r\n{\r\nstruct rxe_send_wqe *wqe;\r\nwqe = queue_head(qp->sq.queue);\r\n*wqe_p = wqe;\r\nif (!wqe || wqe->state == wqe_state_posted)\r\nreturn pkt ? COMPST_DONE : COMPST_EXIT;\r\nif (wqe->state == wqe_state_done)\r\nreturn COMPST_COMP_WQE;\r\nif (wqe->state == wqe_state_error)\r\nreturn COMPST_ERROR;\r\nreturn pkt ? COMPST_CHECK_PSN : COMPST_EXIT;\r\n}\r\nstatic inline void reset_retry_counters(struct rxe_qp *qp)\r\n{\r\nqp->comp.retry_cnt = qp->attr.retry_cnt;\r\nqp->comp.rnr_retry = qp->attr.rnr_retry;\r\n}\r\nstatic inline enum comp_state check_psn(struct rxe_qp *qp,\r\nstruct rxe_pkt_info *pkt,\r\nstruct rxe_send_wqe *wqe)\r\n{\r\ns32 diff;\r\ndiff = psn_compare(pkt->psn, wqe->last_psn);\r\nif (diff > 0) {\r\nif (wqe->state == wqe_state_pending) {\r\nif (wqe->mask & WR_ATOMIC_OR_READ_MASK)\r\nreturn COMPST_ERROR_RETRY;\r\nreset_retry_counters(qp);\r\nreturn COMPST_COMP_WQE;\r\n} else {\r\nreturn COMPST_DONE;\r\n}\r\n}\r\ndiff = psn_compare(pkt->psn, qp->comp.psn);\r\nif (diff < 0) {\r\nif (pkt->psn == wqe->last_psn)\r\nreturn COMPST_COMP_ACK;\r\nelse\r\nreturn COMPST_DONE;\r\n} else if ((diff > 0) && (wqe->mask & WR_ATOMIC_OR_READ_MASK)) {\r\nreturn COMPST_DONE;\r\n} else {\r\nreturn COMPST_CHECK_ACK;\r\n}\r\n}\r\nstatic inline enum comp_state check_ack(struct rxe_qp *qp,\r\nstruct rxe_pkt_info *pkt,\r\nstruct rxe_send_wqe *wqe)\r\n{\r\nunsigned int mask = pkt->mask;\r\nu8 syn;\r\nstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\r\nswitch (qp->comp.opcode) {\r\ncase -1:\r\nif (!(mask & RXE_START_MASK))\r\nreturn COMPST_ERROR;\r\nbreak;\r\ncase IB_OPCODE_RC_RDMA_READ_RESPONSE_FIRST:\r\ncase IB_OPCODE_RC_RDMA_READ_RESPONSE_MIDDLE:\r\nif (pkt->opcode != IB_OPCODE_RC_RDMA_READ_RESPONSE_MIDDLE &&\r\npkt->opcode != IB_OPCODE_RC_RDMA_READ_RESPONSE_LAST) {\r\nreturn COMPST_ERROR;\r\n}\r\nbreak;\r\ndefault:\r\nWARN_ON_ONCE(1);\r\n}\r\nswitch (pkt->opcode) {\r\ncase IB_OPCODE_RC_RDMA_READ_RESPONSE_FIRST:\r\ncase IB_OPCODE_RC_RDMA_READ_RESPONSE_LAST:\r\ncase IB_OPCODE_RC_RDMA_READ_RESPONSE_ONLY:\r\nsyn = aeth_syn(pkt);\r\nif ((syn & AETH_TYPE_MASK) != AETH_ACK)\r\nreturn COMPST_ERROR;\r\ncase IB_OPCODE_RC_RDMA_READ_RESPONSE_MIDDLE:\r\nif (wqe->wr.opcode != IB_WR_RDMA_READ &&\r\nwqe->wr.opcode != IB_WR_RDMA_READ_WITH_INV) {\r\nreturn COMPST_ERROR;\r\n}\r\nreset_retry_counters(qp);\r\nreturn COMPST_READ;\r\ncase IB_OPCODE_RC_ATOMIC_ACKNOWLEDGE:\r\nsyn = aeth_syn(pkt);\r\nif ((syn & AETH_TYPE_MASK) != AETH_ACK)\r\nreturn COMPST_ERROR;\r\nif (wqe->wr.opcode != IB_WR_ATOMIC_CMP_AND_SWP &&\r\nwqe->wr.opcode != IB_WR_ATOMIC_FETCH_AND_ADD)\r\nreturn COMPST_ERROR;\r\nreset_retry_counters(qp);\r\nreturn COMPST_ATOMIC;\r\ncase IB_OPCODE_RC_ACKNOWLEDGE:\r\nsyn = aeth_syn(pkt);\r\nswitch (syn & AETH_TYPE_MASK) {\r\ncase AETH_ACK:\r\nreset_retry_counters(qp);\r\nreturn COMPST_WRITE_SEND;\r\ncase AETH_RNR_NAK:\r\nrxe_counter_inc(rxe, RXE_CNT_RCV_RNR);\r\nreturn COMPST_RNR_RETRY;\r\ncase AETH_NAK:\r\nswitch (syn) {\r\ncase AETH_NAK_PSN_SEQ_ERROR:\r\nif (psn_compare(pkt->psn, qp->comp.psn) > 0) {\r\nrxe_counter_inc(rxe,\r\nRXE_CNT_RCV_SEQ_ERR);\r\nqp->comp.psn = pkt->psn;\r\nif (qp->req.wait_psn) {\r\nqp->req.wait_psn = 0;\r\nrxe_run_task(&qp->req.task, 1);\r\n}\r\n}\r\nreturn COMPST_ERROR_RETRY;\r\ncase AETH_NAK_INVALID_REQ:\r\nwqe->status = IB_WC_REM_INV_REQ_ERR;\r\nreturn COMPST_ERROR;\r\ncase AETH_NAK_REM_ACC_ERR:\r\nwqe->status = IB_WC_REM_ACCESS_ERR;\r\nreturn COMPST_ERROR;\r\ncase AETH_NAK_REM_OP_ERR:\r\nwqe->status = IB_WC_REM_OP_ERR;\r\nreturn COMPST_ERROR;\r\ndefault:\r\npr_warn("unexpected nak %x\n", syn);\r\nwqe->status = IB_WC_REM_OP_ERR;\r\nreturn COMPST_ERROR;\r\n}\r\ndefault:\r\nreturn COMPST_ERROR;\r\n}\r\nbreak;\r\ndefault:\r\npr_warn("unexpected opcode\n");\r\n}\r\nreturn COMPST_ERROR;\r\n}\r\nstatic inline enum comp_state do_read(struct rxe_qp *qp,\r\nstruct rxe_pkt_info *pkt,\r\nstruct rxe_send_wqe *wqe)\r\n{\r\nstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\r\nint ret;\r\nret = copy_data(rxe, qp->pd, IB_ACCESS_LOCAL_WRITE,\r\n&wqe->dma, payload_addr(pkt),\r\npayload_size(pkt), to_mem_obj, NULL);\r\nif (ret)\r\nreturn COMPST_ERROR;\r\nif (wqe->dma.resid == 0 && (pkt->mask & RXE_END_MASK))\r\nreturn COMPST_COMP_ACK;\r\nelse\r\nreturn COMPST_UPDATE_COMP;\r\n}\r\nstatic inline enum comp_state do_atomic(struct rxe_qp *qp,\r\nstruct rxe_pkt_info *pkt,\r\nstruct rxe_send_wqe *wqe)\r\n{\r\nstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\r\nint ret;\r\nu64 atomic_orig = atmack_orig(pkt);\r\nret = copy_data(rxe, qp->pd, IB_ACCESS_LOCAL_WRITE,\r\n&wqe->dma, &atomic_orig,\r\nsizeof(u64), to_mem_obj, NULL);\r\nif (ret)\r\nreturn COMPST_ERROR;\r\nelse\r\nreturn COMPST_COMP_ACK;\r\n}\r\nstatic void make_send_cqe(struct rxe_qp *qp, struct rxe_send_wqe *wqe,\r\nstruct rxe_cqe *cqe)\r\n{\r\nmemset(cqe, 0, sizeof(*cqe));\r\nif (!qp->is_user) {\r\nstruct ib_wc *wc = &cqe->ibwc;\r\nwc->wr_id = wqe->wr.wr_id;\r\nwc->status = wqe->status;\r\nwc->opcode = wr_to_wc_opcode(wqe->wr.opcode);\r\nif (wqe->wr.opcode == IB_WR_RDMA_WRITE_WITH_IMM ||\r\nwqe->wr.opcode == IB_WR_SEND_WITH_IMM)\r\nwc->wc_flags = IB_WC_WITH_IMM;\r\nwc->byte_len = wqe->dma.length;\r\nwc->qp = &qp->ibqp;\r\n} else {\r\nstruct ib_uverbs_wc *uwc = &cqe->uibwc;\r\nuwc->wr_id = wqe->wr.wr_id;\r\nuwc->status = wqe->status;\r\nuwc->opcode = wr_to_wc_opcode(wqe->wr.opcode);\r\nif (wqe->wr.opcode == IB_WR_RDMA_WRITE_WITH_IMM ||\r\nwqe->wr.opcode == IB_WR_SEND_WITH_IMM)\r\nuwc->wc_flags = IB_WC_WITH_IMM;\r\nuwc->byte_len = wqe->dma.length;\r\nuwc->qp_num = qp->ibqp.qp_num;\r\n}\r\n}\r\nstatic void do_complete(struct rxe_qp *qp, struct rxe_send_wqe *wqe)\r\n{\r\nstruct rxe_cqe cqe;\r\nif ((qp->sq_sig_type == IB_SIGNAL_ALL_WR) ||\r\n(wqe->wr.send_flags & IB_SEND_SIGNALED) ||\r\nwqe->status != IB_WC_SUCCESS) {\r\nmake_send_cqe(qp, wqe, &cqe);\r\nadvance_consumer(qp->sq.queue);\r\nrxe_cq_post(qp->scq, &cqe, 0);\r\n} else {\r\nadvance_consumer(qp->sq.queue);\r\n}\r\nif (qp->req.wait_fence) {\r\nqp->req.wait_fence = 0;\r\nrxe_run_task(&qp->req.task, 1);\r\n}\r\n}\r\nstatic inline enum comp_state complete_ack(struct rxe_qp *qp,\r\nstruct rxe_pkt_info *pkt,\r\nstruct rxe_send_wqe *wqe)\r\n{\r\nunsigned long flags;\r\nif (wqe->has_rd_atomic) {\r\nwqe->has_rd_atomic = 0;\r\natomic_inc(&qp->req.rd_atomic);\r\nif (qp->req.need_rd_atomic) {\r\nqp->comp.timeout_retry = 0;\r\nqp->req.need_rd_atomic = 0;\r\nrxe_run_task(&qp->req.task, 1);\r\n}\r\n}\r\nif (unlikely(qp->req.state == QP_STATE_DRAIN)) {\r\nspin_lock_irqsave(&qp->state_lock, flags);\r\nif ((qp->req.state == QP_STATE_DRAIN) &&\r\n(qp->comp.psn == qp->req.psn)) {\r\nqp->req.state = QP_STATE_DRAINED;\r\nspin_unlock_irqrestore(&qp->state_lock, flags);\r\nif (qp->ibqp.event_handler) {\r\nstruct ib_event ev;\r\nev.device = qp->ibqp.device;\r\nev.element.qp = &qp->ibqp;\r\nev.event = IB_EVENT_SQ_DRAINED;\r\nqp->ibqp.event_handler(&ev,\r\nqp->ibqp.qp_context);\r\n}\r\n} else {\r\nspin_unlock_irqrestore(&qp->state_lock, flags);\r\n}\r\n}\r\ndo_complete(qp, wqe);\r\nif (psn_compare(pkt->psn, qp->comp.psn) >= 0)\r\nreturn COMPST_UPDATE_COMP;\r\nelse\r\nreturn COMPST_DONE;\r\n}\r\nstatic inline enum comp_state complete_wqe(struct rxe_qp *qp,\r\nstruct rxe_pkt_info *pkt,\r\nstruct rxe_send_wqe *wqe)\r\n{\r\nqp->comp.opcode = -1;\r\nif (pkt) {\r\nif (psn_compare(pkt->psn, qp->comp.psn) >= 0)\r\nqp->comp.psn = (pkt->psn + 1) & BTH_PSN_MASK;\r\nif (qp->req.wait_psn) {\r\nqp->req.wait_psn = 0;\r\nrxe_run_task(&qp->req.task, 1);\r\n}\r\n}\r\ndo_complete(qp, wqe);\r\nreturn COMPST_GET_WQE;\r\n}\r\nstatic void rxe_drain_resp_pkts(struct rxe_qp *qp, bool notify)\r\n{\r\nstruct sk_buff *skb;\r\nstruct rxe_send_wqe *wqe;\r\nwhile ((skb = skb_dequeue(&qp->resp_pkts))) {\r\nrxe_drop_ref(qp);\r\nkfree_skb(skb);\r\n}\r\nwhile ((wqe = queue_head(qp->sq.queue))) {\r\nif (notify) {\r\nwqe->status = IB_WC_WR_FLUSH_ERR;\r\ndo_complete(qp, wqe);\r\n} else {\r\nadvance_consumer(qp->sq.queue);\r\n}\r\n}\r\n}\r\nint rxe_completer(void *arg)\r\n{\r\nstruct rxe_qp *qp = (struct rxe_qp *)arg;\r\nstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\r\nstruct rxe_send_wqe *wqe = wqe;\r\nstruct sk_buff *skb = NULL;\r\nstruct rxe_pkt_info *pkt = NULL;\r\nenum comp_state state;\r\nrxe_add_ref(qp);\r\nif (!qp->valid || qp->req.state == QP_STATE_ERROR ||\r\nqp->req.state == QP_STATE_RESET) {\r\nrxe_drain_resp_pkts(qp, qp->valid &&\r\nqp->req.state == QP_STATE_ERROR);\r\ngoto exit;\r\n}\r\nif (qp->comp.timeout) {\r\nqp->comp.timeout_retry = 1;\r\nqp->comp.timeout = 0;\r\n} else {\r\nqp->comp.timeout_retry = 0;\r\n}\r\nif (qp->req.need_retry)\r\ngoto exit;\r\nstate = COMPST_GET_ACK;\r\nwhile (1) {\r\npr_debug("qp#%d state = %s\n", qp_num(qp),\r\ncomp_state_name[state]);\r\nswitch (state) {\r\ncase COMPST_GET_ACK:\r\nskb = skb_dequeue(&qp->resp_pkts);\r\nif (skb) {\r\npkt = SKB_TO_PKT(skb);\r\nqp->comp.timeout_retry = 0;\r\n}\r\nstate = COMPST_GET_WQE;\r\nbreak;\r\ncase COMPST_GET_WQE:\r\nstate = get_wqe(qp, pkt, &wqe);\r\nbreak;\r\ncase COMPST_CHECK_PSN:\r\nstate = check_psn(qp, pkt, wqe);\r\nbreak;\r\ncase COMPST_CHECK_ACK:\r\nstate = check_ack(qp, pkt, wqe);\r\nbreak;\r\ncase COMPST_READ:\r\nstate = do_read(qp, pkt, wqe);\r\nbreak;\r\ncase COMPST_ATOMIC:\r\nstate = do_atomic(qp, pkt, wqe);\r\nbreak;\r\ncase COMPST_WRITE_SEND:\r\nif (wqe->state == wqe_state_pending &&\r\nwqe->last_psn == pkt->psn)\r\nstate = COMPST_COMP_ACK;\r\nelse\r\nstate = COMPST_UPDATE_COMP;\r\nbreak;\r\ncase COMPST_COMP_ACK:\r\nstate = complete_ack(qp, pkt, wqe);\r\nbreak;\r\ncase COMPST_COMP_WQE:\r\nstate = complete_wqe(qp, pkt, wqe);\r\nbreak;\r\ncase COMPST_UPDATE_COMP:\r\nif (pkt->mask & RXE_END_MASK)\r\nqp->comp.opcode = -1;\r\nelse\r\nqp->comp.opcode = pkt->opcode;\r\nif (psn_compare(pkt->psn, qp->comp.psn) >= 0)\r\nqp->comp.psn = (pkt->psn + 1) & BTH_PSN_MASK;\r\nif (qp->req.wait_psn) {\r\nqp->req.wait_psn = 0;\r\nrxe_run_task(&qp->req.task, 1);\r\n}\r\nstate = COMPST_DONE;\r\nbreak;\r\ncase COMPST_DONE:\r\nif (pkt) {\r\nrxe_drop_ref(pkt->qp);\r\nkfree_skb(skb);\r\nskb = NULL;\r\n}\r\ngoto done;\r\ncase COMPST_EXIT:\r\nif (qp->comp.timeout_retry && wqe) {\r\nstate = COMPST_ERROR_RETRY;\r\nbreak;\r\n}\r\nif ((qp_type(qp) == IB_QPT_RC) &&\r\n(qp->req.state == QP_STATE_READY) &&\r\n(psn_compare(qp->req.psn, qp->comp.psn) > 0) &&\r\nqp->qp_timeout_jiffies)\r\nmod_timer(&qp->retrans_timer,\r\njiffies + qp->qp_timeout_jiffies);\r\nWARN_ON_ONCE(skb);\r\ngoto exit;\r\ncase COMPST_ERROR_RETRY:\r\nif (!wqe || (wqe->state == wqe_state_posted)) {\r\nWARN_ON_ONCE(skb);\r\ngoto exit;\r\n}\r\nif (qp->comp.retry_cnt > 0) {\r\nif (qp->comp.retry_cnt != 7)\r\nqp->comp.retry_cnt--;\r\nif (psn_compare(qp->req.psn,\r\nqp->comp.psn) > 0) {\r\nrxe_counter_inc(rxe,\r\nRXE_CNT_COMP_RETRY);\r\nqp->req.need_retry = 1;\r\nrxe_run_task(&qp->req.task, 1);\r\n}\r\nif (pkt) {\r\nrxe_drop_ref(pkt->qp);\r\nkfree_skb(skb);\r\nskb = NULL;\r\n}\r\nWARN_ON_ONCE(skb);\r\ngoto exit;\r\n} else {\r\nrxe_counter_inc(rxe, RXE_CNT_RETRY_EXCEEDED);\r\nwqe->status = IB_WC_RETRY_EXC_ERR;\r\nstate = COMPST_ERROR;\r\n}\r\nbreak;\r\ncase COMPST_RNR_RETRY:\r\nif (qp->comp.rnr_retry > 0) {\r\nif (qp->comp.rnr_retry != 7)\r\nqp->comp.rnr_retry--;\r\nqp->req.need_retry = 1;\r\npr_debug("qp#%d set rnr nak timer\n",\r\nqp_num(qp));\r\nmod_timer(&qp->rnr_nak_timer,\r\njiffies + rnrnak_jiffies(aeth_syn(pkt)\r\n& ~AETH_TYPE_MASK));\r\nrxe_drop_ref(pkt->qp);\r\nkfree_skb(skb);\r\nskb = NULL;\r\ngoto exit;\r\n} else {\r\nrxe_counter_inc(rxe,\r\nRXE_CNT_RNR_RETRY_EXCEEDED);\r\nwqe->status = IB_WC_RNR_RETRY_EXC_ERR;\r\nstate = COMPST_ERROR;\r\n}\r\nbreak;\r\ncase COMPST_ERROR:\r\nWARN_ON_ONCE(wqe->status == IB_WC_SUCCESS);\r\ndo_complete(qp, wqe);\r\nrxe_qp_error(qp);\r\nif (pkt) {\r\nrxe_drop_ref(pkt->qp);\r\nkfree_skb(skb);\r\nskb = NULL;\r\n}\r\nWARN_ON_ONCE(skb);\r\ngoto exit;\r\n}\r\n}\r\nexit:\r\nWARN_ON_ONCE(skb);\r\nrxe_drop_ref(qp);\r\nreturn -EAGAIN;\r\ndone:\r\nWARN_ON_ONCE(skb);\r\nrxe_drop_ref(qp);\r\nreturn 0;\r\n}
