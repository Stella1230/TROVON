static int hash(struct signal_struct *sig, unsigned int nr)\r\n{\r\nreturn hash_32(hash32_ptr(sig) ^ nr, HASH_BITS(posix_timers_hashtable));\r\n}\r\nstatic struct k_itimer *__posix_timers_find(struct hlist_head *head,\r\nstruct signal_struct *sig,\r\ntimer_t id)\r\n{\r\nstruct k_itimer *timer;\r\nhlist_for_each_entry_rcu(timer, head, t_hash) {\r\nif ((timer->it_signal == sig) && (timer->it_id == id))\r\nreturn timer;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct k_itimer *posix_timer_by_id(timer_t id)\r\n{\r\nstruct signal_struct *sig = current->signal;\r\nstruct hlist_head *head = &posix_timers_hashtable[hash(sig, id)];\r\nreturn __posix_timers_find(head, sig, id);\r\n}\r\nstatic int posix_timer_add(struct k_itimer *timer)\r\n{\r\nstruct signal_struct *sig = current->signal;\r\nint first_free_id = sig->posix_timer_id;\r\nstruct hlist_head *head;\r\nint ret = -ENOENT;\r\ndo {\r\nspin_lock(&hash_lock);\r\nhead = &posix_timers_hashtable[hash(sig, sig->posix_timer_id)];\r\nif (!__posix_timers_find(head, sig, sig->posix_timer_id)) {\r\nhlist_add_head_rcu(&timer->t_hash, head);\r\nret = sig->posix_timer_id;\r\n}\r\nif (++sig->posix_timer_id < 0)\r\nsig->posix_timer_id = 0;\r\nif ((sig->posix_timer_id == first_free_id) && (ret == -ENOENT))\r\nret = -EAGAIN;\r\nspin_unlock(&hash_lock);\r\n} while (ret == -ENOENT);\r\nreturn ret;\r\n}\r\nstatic inline void unlock_timer(struct k_itimer *timr, unsigned long flags)\r\n{\r\nspin_unlock_irqrestore(&timr->it_lock, flags);\r\n}\r\nstatic int posix_clock_realtime_get(clockid_t which_clock, struct timespec64 *tp)\r\n{\r\nktime_get_real_ts64(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_clock_realtime_set(const clockid_t which_clock,\r\nconst struct timespec64 *tp)\r\n{\r\nreturn do_sys_settimeofday64(tp, NULL);\r\n}\r\nstatic int posix_clock_realtime_adj(const clockid_t which_clock,\r\nstruct timex *t)\r\n{\r\nreturn do_adjtimex(t);\r\n}\r\nstatic int posix_ktime_get_ts(clockid_t which_clock, struct timespec64 *tp)\r\n{\r\nktime_get_ts64(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_get_monotonic_raw(clockid_t which_clock, struct timespec64 *tp)\r\n{\r\ngetrawmonotonic64(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_get_realtime_coarse(clockid_t which_clock, struct timespec64 *tp)\r\n{\r\n*tp = current_kernel_time64();\r\nreturn 0;\r\n}\r\nstatic int posix_get_monotonic_coarse(clockid_t which_clock,\r\nstruct timespec64 *tp)\r\n{\r\n*tp = get_monotonic_coarse64();\r\nreturn 0;\r\n}\r\nstatic int posix_get_coarse_res(const clockid_t which_clock, struct timespec64 *tp)\r\n{\r\n*tp = ktime_to_timespec64(KTIME_LOW_RES);\r\nreturn 0;\r\n}\r\nstatic int posix_get_boottime(const clockid_t which_clock, struct timespec64 *tp)\r\n{\r\nget_monotonic_boottime64(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_get_tai(clockid_t which_clock, struct timespec64 *tp)\r\n{\r\ntimekeeping_clocktai64(tp);\r\nreturn 0;\r\n}\r\nstatic int posix_get_hrtimer_res(clockid_t which_clock, struct timespec64 *tp)\r\n{\r\ntp->tv_sec = 0;\r\ntp->tv_nsec = hrtimer_resolution;\r\nreturn 0;\r\n}\r\nstatic __init int init_posix_timers(void)\r\n{\r\nposix_timers_cache = kmem_cache_create("posix_timers_cache",\r\nsizeof (struct k_itimer), 0, SLAB_PANIC,\r\nNULL);\r\nreturn 0;\r\n}\r\nstatic void common_hrtimer_rearm(struct k_itimer *timr)\r\n{\r\nstruct hrtimer *timer = &timr->it.real.timer;\r\nif (!timr->it_interval)\r\nreturn;\r\ntimr->it_overrun += (unsigned int) hrtimer_forward(timer,\r\ntimer->base->get_time(),\r\ntimr->it_interval);\r\nhrtimer_restart(timer);\r\n}\r\nvoid posixtimer_rearm(struct siginfo *info)\r\n{\r\nstruct k_itimer *timr;\r\nunsigned long flags;\r\ntimr = lock_timer(info->si_tid, &flags);\r\nif (!timr)\r\nreturn;\r\nif (timr->it_requeue_pending == info->si_sys_private) {\r\ntimr->kclock->timer_rearm(timr);\r\ntimr->it_active = 1;\r\ntimr->it_overrun_last = timr->it_overrun;\r\ntimr->it_overrun = -1;\r\n++timr->it_requeue_pending;\r\ninfo->si_overrun += timr->it_overrun_last;\r\n}\r\nunlock_timer(timr, flags);\r\n}\r\nint posix_timer_event(struct k_itimer *timr, int si_private)\r\n{\r\nstruct task_struct *task;\r\nint shared, ret = -1;\r\ntimr->sigq->info.si_sys_private = si_private;\r\nrcu_read_lock();\r\ntask = pid_task(timr->it_pid, PIDTYPE_PID);\r\nif (task) {\r\nshared = !(timr->it_sigev_notify & SIGEV_THREAD_ID);\r\nret = send_sigqueue(timr->sigq, task, shared);\r\n}\r\nrcu_read_unlock();\r\nreturn ret > 0;\r\n}\r\nstatic enum hrtimer_restart posix_timer_fn(struct hrtimer *timer)\r\n{\r\nstruct k_itimer *timr;\r\nunsigned long flags;\r\nint si_private = 0;\r\nenum hrtimer_restart ret = HRTIMER_NORESTART;\r\ntimr = container_of(timer, struct k_itimer, it.real.timer);\r\nspin_lock_irqsave(&timr->it_lock, flags);\r\ntimr->it_active = 0;\r\nif (timr->it_interval != 0)\r\nsi_private = ++timr->it_requeue_pending;\r\nif (posix_timer_event(timr, si_private)) {\r\nif (timr->it_interval != 0) {\r\nktime_t now = hrtimer_cb_get_time(timer);\r\n#ifdef CONFIG_HIGH_RES_TIMERS\r\n{\r\nktime_t kj = NSEC_PER_SEC / HZ;\r\nif (timr->it_interval < kj)\r\nnow = ktime_add(now, kj);\r\n}\r\n#endif\r\ntimr->it_overrun += (unsigned int)\r\nhrtimer_forward(timer, now,\r\ntimr->it_interval);\r\nret = HRTIMER_RESTART;\r\n++timr->it_requeue_pending;\r\ntimr->it_active = 1;\r\n}\r\n}\r\nunlock_timer(timr, flags);\r\nreturn ret;\r\n}\r\nstatic struct pid *good_sigevent(sigevent_t * event)\r\n{\r\nstruct task_struct *rtn = current->group_leader;\r\nif ((event->sigev_notify & SIGEV_THREAD_ID ) &&\r\n(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||\r\n!same_thread_group(rtn, current) ||\r\n(event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))\r\nreturn NULL;\r\nif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&\r\n((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))\r\nreturn NULL;\r\nreturn task_pid(rtn);\r\n}\r\nstatic struct k_itimer * alloc_posix_timer(void)\r\n{\r\nstruct k_itimer *tmr;\r\ntmr = kmem_cache_zalloc(posix_timers_cache, GFP_KERNEL);\r\nif (!tmr)\r\nreturn tmr;\r\nif (unlikely(!(tmr->sigq = sigqueue_alloc()))) {\r\nkmem_cache_free(posix_timers_cache, tmr);\r\nreturn NULL;\r\n}\r\nmemset(&tmr->sigq->info, 0, sizeof(siginfo_t));\r\nreturn tmr;\r\n}\r\nstatic void k_itimer_rcu_free(struct rcu_head *head)\r\n{\r\nstruct k_itimer *tmr = container_of(head, struct k_itimer, it.rcu);\r\nkmem_cache_free(posix_timers_cache, tmr);\r\n}\r\nstatic void release_posix_timer(struct k_itimer *tmr, int it_id_set)\r\n{\r\nif (it_id_set) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&hash_lock, flags);\r\nhlist_del_rcu(&tmr->t_hash);\r\nspin_unlock_irqrestore(&hash_lock, flags);\r\n}\r\nput_pid(tmr->it_pid);\r\nsigqueue_free(tmr->sigq);\r\ncall_rcu(&tmr->it.rcu, k_itimer_rcu_free);\r\n}\r\nstatic int common_timer_create(struct k_itimer *new_timer)\r\n{\r\nhrtimer_init(&new_timer->it.real.timer, new_timer->it_clock, 0);\r\nreturn 0;\r\n}\r\nstatic int do_timer_create(clockid_t which_clock, struct sigevent *event,\r\ntimer_t __user *created_timer_id)\r\n{\r\nconst struct k_clock *kc = clockid_to_kclock(which_clock);\r\nstruct k_itimer *new_timer;\r\nint error, new_timer_id;\r\nint it_id_set = IT_ID_NOT_SET;\r\nif (!kc)\r\nreturn -EINVAL;\r\nif (!kc->timer_create)\r\nreturn -EOPNOTSUPP;\r\nnew_timer = alloc_posix_timer();\r\nif (unlikely(!new_timer))\r\nreturn -EAGAIN;\r\nspin_lock_init(&new_timer->it_lock);\r\nnew_timer_id = posix_timer_add(new_timer);\r\nif (new_timer_id < 0) {\r\nerror = new_timer_id;\r\ngoto out;\r\n}\r\nit_id_set = IT_ID_SET;\r\nnew_timer->it_id = (timer_t) new_timer_id;\r\nnew_timer->it_clock = which_clock;\r\nnew_timer->kclock = kc;\r\nnew_timer->it_overrun = -1;\r\nif (event) {\r\nrcu_read_lock();\r\nnew_timer->it_pid = get_pid(good_sigevent(event));\r\nrcu_read_unlock();\r\nif (!new_timer->it_pid) {\r\nerror = -EINVAL;\r\ngoto out;\r\n}\r\nnew_timer->it_sigev_notify = event->sigev_notify;\r\nnew_timer->sigq->info.si_signo = event->sigev_signo;\r\nnew_timer->sigq->info.si_value = event->sigev_value;\r\n} else {\r\nnew_timer->it_sigev_notify = SIGEV_SIGNAL;\r\nnew_timer->sigq->info.si_signo = SIGALRM;\r\nmemset(&new_timer->sigq->info.si_value, 0, sizeof(sigval_t));\r\nnew_timer->sigq->info.si_value.sival_int = new_timer->it_id;\r\nnew_timer->it_pid = get_pid(task_tgid(current));\r\n}\r\nnew_timer->sigq->info.si_tid = new_timer->it_id;\r\nnew_timer->sigq->info.si_code = SI_TIMER;\r\nif (copy_to_user(created_timer_id,\r\n&new_timer_id, sizeof (new_timer_id))) {\r\nerror = -EFAULT;\r\ngoto out;\r\n}\r\nerror = kc->timer_create(new_timer);\r\nif (error)\r\ngoto out;\r\nspin_lock_irq(&current->sighand->siglock);\r\nnew_timer->it_signal = current->signal;\r\nlist_add(&new_timer->list, &current->signal->posix_timers);\r\nspin_unlock_irq(&current->sighand->siglock);\r\nreturn 0;\r\nout:\r\nrelease_posix_timer(new_timer, it_id_set);\r\nreturn error;\r\n}\r\nstatic struct k_itimer *__lock_timer(timer_t timer_id, unsigned long *flags)\r\n{\r\nstruct k_itimer *timr;\r\nif ((unsigned long long)timer_id > INT_MAX)\r\nreturn NULL;\r\nrcu_read_lock();\r\ntimr = posix_timer_by_id(timer_id);\r\nif (timr) {\r\nspin_lock_irqsave(&timr->it_lock, *flags);\r\nif (timr->it_signal == current->signal) {\r\nrcu_read_unlock();\r\nreturn timr;\r\n}\r\nspin_unlock_irqrestore(&timr->it_lock, *flags);\r\n}\r\nrcu_read_unlock();\r\nreturn NULL;\r\n}\r\nstatic ktime_t common_hrtimer_remaining(struct k_itimer *timr, ktime_t now)\r\n{\r\nstruct hrtimer *timer = &timr->it.real.timer;\r\nreturn __hrtimer_expires_remaining_adjusted(timer, now);\r\n}\r\nstatic int common_hrtimer_forward(struct k_itimer *timr, ktime_t now)\r\n{\r\nstruct hrtimer *timer = &timr->it.real.timer;\r\nreturn (int)hrtimer_forward(timer, now, timr->it_interval);\r\n}\r\nvoid common_timer_get(struct k_itimer *timr, struct itimerspec64 *cur_setting)\r\n{\r\nconst struct k_clock *kc = timr->kclock;\r\nktime_t now, remaining, iv;\r\nstruct timespec64 ts64;\r\nbool sig_none;\r\nsig_none = (timr->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE;\r\niv = timr->it_interval;\r\nif (iv) {\r\ncur_setting->it_interval = ktime_to_timespec64(iv);\r\n} else if (!timr->it_active) {\r\nif (!sig_none)\r\nreturn;\r\n}\r\nkc->clock_get(timr->it_clock, &ts64);\r\nnow = timespec64_to_ktime(ts64);\r\nif (iv && (timr->it_requeue_pending & REQUEUE_PENDING || sig_none))\r\ntimr->it_overrun += kc->timer_forward(timr, now);\r\nremaining = kc->timer_remaining(timr, now);\r\nif (remaining <= 0) {\r\nif (!sig_none)\r\ncur_setting->it_value.tv_nsec = 1;\r\n} else {\r\ncur_setting->it_value = ktime_to_timespec64(remaining);\r\n}\r\n}\r\nstatic int do_timer_gettime(timer_t timer_id, struct itimerspec64 *setting)\r\n{\r\nstruct k_itimer *timr;\r\nconst struct k_clock *kc;\r\nunsigned long flags;\r\nint ret = 0;\r\ntimr = lock_timer(timer_id, &flags);\r\nif (!timr)\r\nreturn -EINVAL;\r\nmemset(setting, 0, sizeof(*setting));\r\nkc = timr->kclock;\r\nif (WARN_ON_ONCE(!kc || !kc->timer_get))\r\nret = -EINVAL;\r\nelse\r\nkc->timer_get(timr, setting);\r\nunlock_timer(timr, flags);\r\nreturn ret;\r\n}\r\nstatic void common_hrtimer_arm(struct k_itimer *timr, ktime_t expires,\r\nbool absolute, bool sigev_none)\r\n{\r\nstruct hrtimer *timer = &timr->it.real.timer;\r\nenum hrtimer_mode mode;\r\nmode = absolute ? HRTIMER_MODE_ABS : HRTIMER_MODE_REL;\r\nif (timr->it_clock == CLOCK_REALTIME)\r\ntimr->kclock = absolute ? &clock_realtime : &clock_monotonic;\r\nhrtimer_init(&timr->it.real.timer, timr->it_clock, mode);\r\ntimr->it.real.timer.function = posix_timer_fn;\r\nif (!absolute)\r\nexpires = ktime_add_safe(expires, timer->base->get_time());\r\nhrtimer_set_expires(timer, expires);\r\nif (!sigev_none)\r\nhrtimer_start_expires(timer, HRTIMER_MODE_ABS);\r\n}\r\nstatic int common_hrtimer_try_to_cancel(struct k_itimer *timr)\r\n{\r\nreturn hrtimer_try_to_cancel(&timr->it.real.timer);\r\n}\r\nint common_timer_set(struct k_itimer *timr, int flags,\r\nstruct itimerspec64 *new_setting,\r\nstruct itimerspec64 *old_setting)\r\n{\r\nconst struct k_clock *kc = timr->kclock;\r\nbool sigev_none;\r\nktime_t expires;\r\nif (old_setting)\r\ncommon_timer_get(timr, old_setting);\r\ntimr->it_interval = 0;\r\nif (kc->timer_try_to_cancel(timr) < 0)\r\nreturn TIMER_RETRY;\r\ntimr->it_active = 0;\r\ntimr->it_requeue_pending = (timr->it_requeue_pending + 2) &\r\n~REQUEUE_PENDING;\r\ntimr->it_overrun_last = 0;\r\nif (!new_setting->it_value.tv_sec && !new_setting->it_value.tv_nsec)\r\nreturn 0;\r\ntimr->it_interval = timespec64_to_ktime(new_setting->it_interval);\r\nexpires = timespec64_to_ktime(new_setting->it_value);\r\nsigev_none = (timr->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE;\r\nkc->timer_arm(timr, expires, flags & TIMER_ABSTIME, sigev_none);\r\ntimr->it_active = !sigev_none;\r\nreturn 0;\r\n}\r\nstatic int do_timer_settime(timer_t timer_id, int flags,\r\nstruct itimerspec64 *new_spec64,\r\nstruct itimerspec64 *old_spec64)\r\n{\r\nconst struct k_clock *kc;\r\nstruct k_itimer *timr;\r\nunsigned long flag;\r\nint error = 0;\r\nif (!timespec64_valid(&new_spec64->it_interval) ||\r\n!timespec64_valid(&new_spec64->it_value))\r\nreturn -EINVAL;\r\nif (old_spec64)\r\nmemset(old_spec64, 0, sizeof(*old_spec64));\r\nretry:\r\ntimr = lock_timer(timer_id, &flag);\r\nif (!timr)\r\nreturn -EINVAL;\r\nkc = timr->kclock;\r\nif (WARN_ON_ONCE(!kc || !kc->timer_set))\r\nerror = -EINVAL;\r\nelse\r\nerror = kc->timer_set(timr, flags, new_spec64, old_spec64);\r\nunlock_timer(timr, flag);\r\nif (error == TIMER_RETRY) {\r\nold_spec64 = NULL;\r\ngoto retry;\r\n}\r\nreturn error;\r\n}\r\nint common_timer_del(struct k_itimer *timer)\r\n{\r\nconst struct k_clock *kc = timer->kclock;\r\ntimer->it_interval = 0;\r\nif (kc->timer_try_to_cancel(timer) < 0)\r\nreturn TIMER_RETRY;\r\ntimer->it_active = 0;\r\nreturn 0;\r\n}\r\nstatic inline int timer_delete_hook(struct k_itimer *timer)\r\n{\r\nconst struct k_clock *kc = timer->kclock;\r\nif (WARN_ON_ONCE(!kc || !kc->timer_del))\r\nreturn -EINVAL;\r\nreturn kc->timer_del(timer);\r\n}\r\nstatic void itimer_delete(struct k_itimer *timer)\r\n{\r\nunsigned long flags;\r\nretry_delete:\r\nspin_lock_irqsave(&timer->it_lock, flags);\r\nif (timer_delete_hook(timer) == TIMER_RETRY) {\r\nunlock_timer(timer, flags);\r\ngoto retry_delete;\r\n}\r\nlist_del(&timer->list);\r\ntimer->it_signal = NULL;\r\nunlock_timer(timer, flags);\r\nrelease_posix_timer(timer, IT_ID_SET);\r\n}\r\nvoid exit_itimers(struct signal_struct *sig)\r\n{\r\nstruct k_itimer *tmr;\r\nwhile (!list_empty(&sig->posix_timers)) {\r\ntmr = list_entry(sig->posix_timers.next, struct k_itimer, list);\r\nitimer_delete(tmr);\r\n}\r\n}\r\nstatic int common_nsleep(const clockid_t which_clock, int flags,\r\nconst struct timespec64 *rqtp)\r\n{\r\nreturn hrtimer_nanosleep(rqtp, flags & TIMER_ABSTIME ?\r\nHRTIMER_MODE_ABS : HRTIMER_MODE_REL,\r\nwhich_clock);\r\n}\r\nstatic const struct k_clock *clockid_to_kclock(const clockid_t id)\r\n{\r\nif (id < 0)\r\nreturn (id & CLOCKFD_MASK) == CLOCKFD ?\r\n&clock_posix_dynamic : &clock_posix_cpu;\r\nif (id >= ARRAY_SIZE(posix_clocks) || !posix_clocks[id])\r\nreturn NULL;\r\nreturn posix_clocks[id];\r\n}
