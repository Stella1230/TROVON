static const void *find_first_bad_addr(const void *addr, size_t size)\r\n{\r\nu8 shadow_val = *(u8 *)kasan_mem_to_shadow(addr);\r\nconst void *first_bad_addr = addr;\r\nwhile (!shadow_val && first_bad_addr < addr + size) {\r\nfirst_bad_addr += KASAN_SHADOW_SCALE_SIZE;\r\nshadow_val = *(u8 *)kasan_mem_to_shadow(first_bad_addr);\r\n}\r\nreturn first_bad_addr;\r\n}\r\nstatic bool addr_has_shadow(struct kasan_access_info *info)\r\n{\r\nreturn (info->access_addr >=\r\nkasan_shadow_to_mem((void *)KASAN_SHADOW_START));\r\n}\r\nstatic const char *get_shadow_bug_type(struct kasan_access_info *info)\r\n{\r\nconst char *bug_type = "unknown-crash";\r\nu8 *shadow_addr;\r\ninfo->first_bad_addr = find_first_bad_addr(info->access_addr,\r\ninfo->access_size);\r\nshadow_addr = (u8 *)kasan_mem_to_shadow(info->first_bad_addr);\r\nif (*shadow_addr > 0 && *shadow_addr <= KASAN_SHADOW_SCALE_SIZE - 1)\r\nshadow_addr++;\r\nswitch (*shadow_addr) {\r\ncase 0 ... KASAN_SHADOW_SCALE_SIZE - 1:\r\nbug_type = "out-of-bounds";\r\nbreak;\r\ncase KASAN_PAGE_REDZONE:\r\ncase KASAN_KMALLOC_REDZONE:\r\nbug_type = "slab-out-of-bounds";\r\nbreak;\r\ncase KASAN_GLOBAL_REDZONE:\r\nbug_type = "global-out-of-bounds";\r\nbreak;\r\ncase KASAN_STACK_LEFT:\r\ncase KASAN_STACK_MID:\r\ncase KASAN_STACK_RIGHT:\r\ncase KASAN_STACK_PARTIAL:\r\nbug_type = "stack-out-of-bounds";\r\nbreak;\r\ncase KASAN_FREE_PAGE:\r\ncase KASAN_KMALLOC_FREE:\r\nbug_type = "use-after-free";\r\nbreak;\r\ncase KASAN_USE_AFTER_SCOPE:\r\nbug_type = "use-after-scope";\r\nbreak;\r\n}\r\nreturn bug_type;\r\n}\r\nstatic const char *get_wild_bug_type(struct kasan_access_info *info)\r\n{\r\nconst char *bug_type = "unknown-crash";\r\nif ((unsigned long)info->access_addr < PAGE_SIZE)\r\nbug_type = "null-ptr-deref";\r\nelse if ((unsigned long)info->access_addr < TASK_SIZE)\r\nbug_type = "user-memory-access";\r\nelse\r\nbug_type = "wild-memory-access";\r\nreturn bug_type;\r\n}\r\nstatic const char *get_bug_type(struct kasan_access_info *info)\r\n{\r\nif (addr_has_shadow(info))\r\nreturn get_shadow_bug_type(info);\r\nreturn get_wild_bug_type(info);\r\n}\r\nstatic void print_error_description(struct kasan_access_info *info)\r\n{\r\nconst char *bug_type = get_bug_type(info);\r\npr_err("BUG: KASAN: %s in %pS\n",\r\nbug_type, (void *)info->ip);\r\npr_err("%s of size %zu at addr %p by task %s/%d\n",\r\ninfo->is_write ? "Write" : "Read", info->access_size,\r\ninfo->access_addr, current->comm, task_pid_nr(current));\r\n}\r\nstatic inline bool kernel_or_module_addr(const void *addr)\r\n{\r\nif (addr >= (void *)_stext && addr < (void *)_end)\r\nreturn true;\r\nif (is_module_address((unsigned long)addr))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic inline bool init_task_stack_addr(const void *addr)\r\n{\r\nreturn addr >= (void *)&init_thread_union.stack &&\r\n(addr <= (void *)&init_thread_union.stack +\r\nsizeof(init_thread_union.stack));\r\n}\r\nstatic void kasan_start_report(unsigned long *flags)\r\n{\r\nkasan_disable_current();\r\nspin_lock_irqsave(&report_lock, *flags);\r\npr_err("==================================================================\n");\r\n}\r\nstatic void kasan_end_report(unsigned long *flags)\r\n{\r\npr_err("==================================================================\n");\r\nadd_taint(TAINT_BAD_PAGE, LOCKDEP_NOW_UNRELIABLE);\r\nspin_unlock_irqrestore(&report_lock, *flags);\r\nif (panic_on_warn)\r\npanic("panic_on_warn set ...\n");\r\nkasan_enable_current();\r\n}\r\nstatic void print_track(struct kasan_track *track, const char *prefix)\r\n{\r\npr_err("%s by task %u:\n", prefix, track->pid);\r\nif (track->stack) {\r\nstruct stack_trace trace;\r\ndepot_fetch_stack(track->stack, &trace);\r\nprint_stack_trace(&trace, 0);\r\n} else {\r\npr_err("(stack is not available)\n");\r\n}\r\n}\r\nstatic struct page *addr_to_page(const void *addr)\r\n{\r\nif ((addr >= (void *)PAGE_OFFSET) &&\r\n(addr < high_memory))\r\nreturn virt_to_head_page(addr);\r\nreturn NULL;\r\n}\r\nstatic void describe_object_addr(struct kmem_cache *cache, void *object,\r\nconst void *addr)\r\n{\r\nunsigned long access_addr = (unsigned long)addr;\r\nunsigned long object_addr = (unsigned long)object;\r\nconst char *rel_type;\r\nint rel_bytes;\r\npr_err("The buggy address belongs to the object at %p\n"\r\n" which belongs to the cache %s of size %d\n",\r\nobject, cache->name, cache->object_size);\r\nif (!addr)\r\nreturn;\r\nif (access_addr < object_addr) {\r\nrel_type = "to the left";\r\nrel_bytes = object_addr - access_addr;\r\n} else if (access_addr >= object_addr + cache->object_size) {\r\nrel_type = "to the right";\r\nrel_bytes = access_addr - (object_addr + cache->object_size);\r\n} else {\r\nrel_type = "inside";\r\nrel_bytes = access_addr - object_addr;\r\n}\r\npr_err("The buggy address is located %d bytes %s of\n"\r\n" %d-byte region [%p, %p)\n",\r\nrel_bytes, rel_type, cache->object_size, (void *)object_addr,\r\n(void *)(object_addr + cache->object_size));\r\n}\r\nstatic void describe_object(struct kmem_cache *cache, void *object,\r\nconst void *addr)\r\n{\r\nstruct kasan_alloc_meta *alloc_info = get_alloc_info(cache, object);\r\nif (cache->flags & SLAB_KASAN) {\r\nprint_track(&alloc_info->alloc_track, "Allocated");\r\npr_err("\n");\r\nprint_track(&alloc_info->free_track, "Freed");\r\npr_err("\n");\r\n}\r\ndescribe_object_addr(cache, object, addr);\r\n}\r\nstatic void print_address_description(void *addr)\r\n{\r\nstruct page *page = addr_to_page(addr);\r\ndump_stack();\r\npr_err("\n");\r\nif (page && PageSlab(page)) {\r\nstruct kmem_cache *cache = page->slab_cache;\r\nvoid *object = nearest_obj(cache, page, addr);\r\ndescribe_object(cache, object, addr);\r\n}\r\nif (kernel_or_module_addr(addr) && !init_task_stack_addr(addr)) {\r\npr_err("The buggy address belongs to the variable:\n");\r\npr_err(" %pS\n", addr);\r\n}\r\nif (page) {\r\npr_err("The buggy address belongs to the page:\n");\r\ndump_page(page, "kasan: bad access detected");\r\n}\r\n}\r\nstatic bool row_is_guilty(const void *row, const void *guilty)\r\n{\r\nreturn (row <= guilty) && (guilty < row + SHADOW_BYTES_PER_ROW);\r\n}\r\nstatic int shadow_pointer_offset(const void *row, const void *shadow)\r\n{\r\nreturn 3 + (BITS_PER_LONG/8)*2 + (shadow - row)*2 +\r\n(shadow - row) / SHADOW_BYTES_PER_BLOCK + 1;\r\n}\r\nstatic void print_shadow_for_address(const void *addr)\r\n{\r\nint i;\r\nconst void *shadow = kasan_mem_to_shadow(addr);\r\nconst void *shadow_row;\r\nshadow_row = (void *)round_down((unsigned long)shadow,\r\nSHADOW_BYTES_PER_ROW)\r\n- SHADOW_ROWS_AROUND_ADDR * SHADOW_BYTES_PER_ROW;\r\npr_err("Memory state around the buggy address:\n");\r\nfor (i = -SHADOW_ROWS_AROUND_ADDR; i <= SHADOW_ROWS_AROUND_ADDR; i++) {\r\nconst void *kaddr = kasan_shadow_to_mem(shadow_row);\r\nchar buffer[4 + (BITS_PER_LONG/8)*2];\r\nchar shadow_buf[SHADOW_BYTES_PER_ROW];\r\nsnprintf(buffer, sizeof(buffer),\r\n(i == 0) ? ">%p: " : " %p: ", kaddr);\r\nmemcpy(shadow_buf, shadow_row, SHADOW_BYTES_PER_ROW);\r\nprint_hex_dump(KERN_ERR, buffer,\r\nDUMP_PREFIX_NONE, SHADOW_BYTES_PER_ROW, 1,\r\nshadow_buf, SHADOW_BYTES_PER_ROW, 0);\r\nif (row_is_guilty(shadow_row, shadow))\r\npr_err("%*c\n",\r\nshadow_pointer_offset(shadow_row, shadow),\r\n'^');\r\nshadow_row += SHADOW_BYTES_PER_ROW;\r\n}\r\n}\r\nvoid kasan_report_double_free(struct kmem_cache *cache, void *object,\r\nvoid *ip)\r\n{\r\nunsigned long flags;\r\nkasan_start_report(&flags);\r\npr_err("BUG: KASAN: double-free or invalid-free in %pS\n", ip);\r\npr_err("\n");\r\nprint_address_description(object);\r\npr_err("\n");\r\nprint_shadow_for_address(object);\r\nkasan_end_report(&flags);\r\n}\r\nstatic void kasan_report_error(struct kasan_access_info *info)\r\n{\r\nunsigned long flags;\r\nkasan_start_report(&flags);\r\nprint_error_description(info);\r\npr_err("\n");\r\nif (!addr_has_shadow(info)) {\r\ndump_stack();\r\n} else {\r\nprint_address_description((void *)info->access_addr);\r\npr_err("\n");\r\nprint_shadow_for_address(info->first_bad_addr);\r\n}\r\nkasan_end_report(&flags);\r\n}\r\nbool kasan_save_enable_multi_shot(void)\r\n{\r\nreturn test_and_set_bit(KASAN_BIT_MULTI_SHOT, &kasan_flags);\r\n}\r\nvoid kasan_restore_multi_shot(bool enabled)\r\n{\r\nif (!enabled)\r\nclear_bit(KASAN_BIT_MULTI_SHOT, &kasan_flags);\r\n}\r\nstatic int __init kasan_set_multi_shot(char *str)\r\n{\r\nset_bit(KASAN_BIT_MULTI_SHOT, &kasan_flags);\r\nreturn 1;\r\n}\r\nstatic inline bool kasan_report_enabled(void)\r\n{\r\nif (current->kasan_depth)\r\nreturn false;\r\nif (test_bit(KASAN_BIT_MULTI_SHOT, &kasan_flags))\r\nreturn true;\r\nreturn !test_and_set_bit(KASAN_BIT_REPORTED, &kasan_flags);\r\n}\r\nvoid kasan_report(unsigned long addr, size_t size,\r\nbool is_write, unsigned long ip)\r\n{\r\nstruct kasan_access_info info;\r\nif (likely(!kasan_report_enabled()))\r\nreturn;\r\ndisable_trace_on_warning();\r\ninfo.access_addr = (void *)addr;\r\ninfo.first_bad_addr = (void *)addr;\r\ninfo.access_size = size;\r\ninfo.is_write = is_write;\r\ninfo.ip = ip;\r\nkasan_report_error(&info);\r\n}\r\nvoid __asan_report_load_n_noabort(unsigned long addr, size_t size)\r\n{\r\nkasan_report(addr, size, false, _RET_IP_);\r\n}\r\nvoid __asan_report_store_n_noabort(unsigned long addr, size_t size)\r\n{\r\nkasan_report(addr, size, true, _RET_IP_);\r\n}
