static struct pending_entry *get_free_pending_entry(struct pending_queue *q,\r\nint qlen)\r\n{\r\nstruct pending_entry *ent = NULL;\r\nent = &q->head[q->rear];\r\nif (unlikely(ent->busy)) {\r\nent = NULL;\r\ngoto no_free_entry;\r\n}\r\nq->rear++;\r\nif (unlikely(q->rear == qlen))\r\nq->rear = 0;\r\nno_free_entry:\r\nreturn ent;\r\n}\r\nstatic inline void pending_queue_inc_front(struct pending_qinfo *pqinfo,\r\nint qno)\r\n{\r\nstruct pending_queue *queue = &pqinfo->queue[qno];\r\nqueue->front++;\r\nif (unlikely(queue->front == pqinfo->qlen))\r\nqueue->front = 0;\r\n}\r\nstatic int setup_sgio_components(struct cpt_vf *cptvf, struct buf_ptr *list,\r\nint buf_count, u8 *buffer)\r\n{\r\nint ret = 0, i, j;\r\nint components;\r\nstruct sglist_component *sg_ptr = NULL;\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nif (unlikely(!list)) {\r\ndev_err(&pdev->dev, "Input List pointer is NULL\n");\r\nreturn -EFAULT;\r\n}\r\nfor (i = 0; i < buf_count; i++) {\r\nif (likely(list[i].vptr)) {\r\nlist[i].dma_addr = dma_map_single(&pdev->dev,\r\nlist[i].vptr,\r\nlist[i].size,\r\nDMA_BIDIRECTIONAL);\r\nif (unlikely(dma_mapping_error(&pdev->dev,\r\nlist[i].dma_addr))) {\r\ndev_err(&pdev->dev, "DMA map kernel buffer failed for component: %d\n",\r\ni);\r\nret = -EIO;\r\ngoto sg_cleanup;\r\n}\r\n}\r\n}\r\ncomponents = buf_count / 4;\r\nsg_ptr = (struct sglist_component *)buffer;\r\nfor (i = 0; i < components; i++) {\r\nsg_ptr->u.s.len0 = cpu_to_be16(list[i * 4 + 0].size);\r\nsg_ptr->u.s.len1 = cpu_to_be16(list[i * 4 + 1].size);\r\nsg_ptr->u.s.len2 = cpu_to_be16(list[i * 4 + 2].size);\r\nsg_ptr->u.s.len3 = cpu_to_be16(list[i * 4 + 3].size);\r\nsg_ptr->ptr0 = cpu_to_be64(list[i * 4 + 0].dma_addr);\r\nsg_ptr->ptr1 = cpu_to_be64(list[i * 4 + 1].dma_addr);\r\nsg_ptr->ptr2 = cpu_to_be64(list[i * 4 + 2].dma_addr);\r\nsg_ptr->ptr3 = cpu_to_be64(list[i * 4 + 3].dma_addr);\r\nsg_ptr++;\r\n}\r\ncomponents = buf_count % 4;\r\nswitch (components) {\r\ncase 3:\r\nsg_ptr->u.s.len2 = cpu_to_be16(list[i * 4 + 2].size);\r\nsg_ptr->ptr2 = cpu_to_be64(list[i * 4 + 2].dma_addr);\r\ncase 2:\r\nsg_ptr->u.s.len1 = cpu_to_be16(list[i * 4 + 1].size);\r\nsg_ptr->ptr1 = cpu_to_be64(list[i * 4 + 1].dma_addr);\r\ncase 1:\r\nsg_ptr->u.s.len0 = cpu_to_be16(list[i * 4 + 0].size);\r\nsg_ptr->ptr0 = cpu_to_be64(list[i * 4 + 0].dma_addr);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn ret;\r\nsg_cleanup:\r\nfor (j = 0; j < i; j++) {\r\nif (list[j].dma_addr) {\r\ndma_unmap_single(&pdev->dev, list[i].dma_addr,\r\nlist[i].size, DMA_BIDIRECTIONAL);\r\n}\r\nlist[j].dma_addr = 0;\r\n}\r\nreturn ret;\r\n}\r\nstatic inline int setup_sgio_list(struct cpt_vf *cptvf,\r\nstruct cpt_info_buffer *info,\r\nstruct cpt_request_info *req)\r\n{\r\nu16 g_sz_bytes = 0, s_sz_bytes = 0;\r\nint ret = 0;\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nif (req->incnt > MAX_SG_IN_CNT || req->outcnt > MAX_SG_OUT_CNT) {\r\ndev_err(&pdev->dev, "Request SG components are higher than supported\n");\r\nret = -EINVAL;\r\ngoto scatter_gather_clean;\r\n}\r\ng_sz_bytes = ((req->incnt + 3) / 4) * sizeof(struct sglist_component);\r\ninfo->gather_components = kzalloc(g_sz_bytes, GFP_KERNEL);\r\nif (!info->gather_components) {\r\nret = -ENOMEM;\r\ngoto scatter_gather_clean;\r\n}\r\nret = setup_sgio_components(cptvf, req->in,\r\nreq->incnt,\r\ninfo->gather_components);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Failed to setup gather list\n");\r\nret = -EFAULT;\r\ngoto scatter_gather_clean;\r\n}\r\ns_sz_bytes = ((req->outcnt + 3) / 4) * sizeof(struct sglist_component);\r\ninfo->scatter_components = kzalloc(s_sz_bytes, GFP_KERNEL);\r\nif (!info->scatter_components) {\r\nret = -ENOMEM;\r\ngoto scatter_gather_clean;\r\n}\r\nret = setup_sgio_components(cptvf, req->out,\r\nreq->outcnt,\r\ninfo->scatter_components);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Failed to setup gather list\n");\r\nret = -EFAULT;\r\ngoto scatter_gather_clean;\r\n}\r\ninfo->dlen = g_sz_bytes + s_sz_bytes + SG_LIST_HDR_SIZE;\r\ninfo->in_buffer = kzalloc(info->dlen, GFP_KERNEL);\r\nif (!info->in_buffer) {\r\nret = -ENOMEM;\r\ngoto scatter_gather_clean;\r\n}\r\n((u16 *)info->in_buffer)[0] = req->outcnt;\r\n((u16 *)info->in_buffer)[1] = req->incnt;\r\n((u16 *)info->in_buffer)[2] = 0;\r\n((u16 *)info->in_buffer)[3] = 0;\r\n*(u64 *)info->in_buffer = cpu_to_be64p((u64 *)info->in_buffer);\r\nmemcpy(&info->in_buffer[8], info->gather_components,\r\ng_sz_bytes);\r\nmemcpy(&info->in_buffer[8 + g_sz_bytes],\r\ninfo->scatter_components, s_sz_bytes);\r\ninfo->dptr_baddr = dma_map_single(&pdev->dev,\r\n(void *)info->in_buffer,\r\ninfo->dlen,\r\nDMA_BIDIRECTIONAL);\r\nif (dma_mapping_error(&pdev->dev, info->dptr_baddr)) {\r\ndev_err(&pdev->dev, "Mapping DPTR Failed %d\n", info->dlen);\r\nret = -EIO;\r\ngoto scatter_gather_clean;\r\n}\r\ninfo->out_buffer = kzalloc(COMPLETION_CODE_SIZE, GFP_KERNEL);\r\nif (!info->out_buffer) {\r\nret = -ENOMEM;\r\ngoto scatter_gather_clean;\r\n}\r\n*((u64 *)info->out_buffer) = ~((u64)COMPLETION_CODE_INIT);\r\ninfo->alternate_caddr = (u64 *)info->out_buffer;\r\ninfo->rptr_baddr = dma_map_single(&pdev->dev,\r\n(void *)info->out_buffer,\r\nCOMPLETION_CODE_SIZE,\r\nDMA_BIDIRECTIONAL);\r\nif (dma_mapping_error(&pdev->dev, info->rptr_baddr)) {\r\ndev_err(&pdev->dev, "Mapping RPTR Failed %d\n",\r\nCOMPLETION_CODE_SIZE);\r\nret = -EIO;\r\ngoto scatter_gather_clean;\r\n}\r\nreturn 0;\r\nscatter_gather_clean:\r\nreturn ret;\r\n}\r\nint send_cpt_command(struct cpt_vf *cptvf, union cpt_inst_s *cmd,\r\nu32 qno)\r\n{\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nstruct command_qinfo *qinfo = NULL;\r\nstruct command_queue *queue;\r\nstruct command_chunk *chunk;\r\nu8 *ent;\r\nint ret = 0;\r\nif (unlikely(qno >= cptvf->nr_queues)) {\r\ndev_err(&pdev->dev, "Invalid queue (qno: %d, nr_queues: %d)\n",\r\nqno, cptvf->nr_queues);\r\nreturn -EINVAL;\r\n}\r\nqinfo = &cptvf->cqinfo;\r\nqueue = &qinfo->queue[qno];\r\nspin_lock(&queue->lock);\r\nent = &queue->qhead->head[queue->idx * qinfo->cmd_size];\r\nmemcpy(ent, (void *)cmd, qinfo->cmd_size);\r\nif (++queue->idx >= queue->qhead->size / 64) {\r\nstruct hlist_node *node;\r\nhlist_for_each(node, &queue->chead) {\r\nchunk = hlist_entry(node, struct command_chunk,\r\nnextchunk);\r\nif (chunk == queue->qhead) {\r\ncontinue;\r\n} else {\r\nqueue->qhead = chunk;\r\nbreak;\r\n}\r\n}\r\nqueue->idx = 0;\r\n}\r\nsmp_wmb();\r\ncptvf_write_vq_doorbell(cptvf, 1);\r\nspin_unlock(&queue->lock);\r\nreturn ret;\r\n}\r\nvoid do_request_cleanup(struct cpt_vf *cptvf,\r\nstruct cpt_info_buffer *info)\r\n{\r\nint i;\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nstruct cpt_request_info *req;\r\nif (info->dptr_baddr)\r\ndma_unmap_single(&pdev->dev, info->dptr_baddr,\r\ninfo->dlen, DMA_BIDIRECTIONAL);\r\nif (info->rptr_baddr)\r\ndma_unmap_single(&pdev->dev, info->rptr_baddr,\r\nCOMPLETION_CODE_SIZE, DMA_BIDIRECTIONAL);\r\nif (info->comp_baddr)\r\ndma_unmap_single(&pdev->dev, info->comp_baddr,\r\nsizeof(union cpt_res_s), DMA_BIDIRECTIONAL);\r\nif (info->req) {\r\nreq = info->req;\r\nfor (i = 0; i < req->outcnt; i++) {\r\nif (req->out[i].dma_addr)\r\ndma_unmap_single(&pdev->dev,\r\nreq->out[i].dma_addr,\r\nreq->out[i].size,\r\nDMA_BIDIRECTIONAL);\r\n}\r\nfor (i = 0; i < req->incnt; i++) {\r\nif (req->in[i].dma_addr)\r\ndma_unmap_single(&pdev->dev,\r\nreq->in[i].dma_addr,\r\nreq->in[i].size,\r\nDMA_BIDIRECTIONAL);\r\n}\r\n}\r\nif (info->scatter_components)\r\nkzfree(info->scatter_components);\r\nif (info->gather_components)\r\nkzfree(info->gather_components);\r\nif (info->out_buffer)\r\nkzfree(info->out_buffer);\r\nif (info->in_buffer)\r\nkzfree(info->in_buffer);\r\nif (info->completion_addr)\r\nkzfree((void *)info->completion_addr);\r\nkzfree(info);\r\n}\r\nvoid do_post_process(struct cpt_vf *cptvf, struct cpt_info_buffer *info)\r\n{\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nif (!info) {\r\ndev_err(&pdev->dev, "incorrect cpt_info_buffer for post processing\n");\r\nreturn;\r\n}\r\ndo_request_cleanup(cptvf, info);\r\n}\r\nstatic inline void process_pending_queue(struct cpt_vf *cptvf,\r\nstruct pending_qinfo *pqinfo,\r\nint qno)\r\n{\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nstruct pending_queue *pqueue = &pqinfo->queue[qno];\r\nstruct pending_entry *pentry = NULL;\r\nstruct cpt_info_buffer *info = NULL;\r\nunion cpt_res_s *status = NULL;\r\nunsigned char ccode;\r\nwhile (1) {\r\nspin_lock_bh(&pqueue->lock);\r\npentry = &pqueue->head[pqueue->front];\r\nif (unlikely(!pentry->busy)) {\r\nspin_unlock_bh(&pqueue->lock);\r\nbreak;\r\n}\r\ninfo = (struct cpt_info_buffer *)pentry->post_arg;\r\nif (unlikely(!info)) {\r\ndev_err(&pdev->dev, "Pending Entry post arg NULL\n");\r\npending_queue_inc_front(pqinfo, qno);\r\nspin_unlock_bh(&pqueue->lock);\r\ncontinue;\r\n}\r\nstatus = (union cpt_res_s *)pentry->completion_addr;\r\nccode = status->s.compcode;\r\nif ((status->s.compcode == CPT_COMP_E_FAULT) ||\r\n(status->s.compcode == CPT_COMP_E_SWERR)) {\r\ndev_err(&pdev->dev, "Request failed with %s\n",\r\n(status->s.compcode == CPT_COMP_E_FAULT) ?\r\n"DMA Fault" : "Software error");\r\npentry->completion_addr = NULL;\r\npentry->busy = false;\r\natomic64_dec((&pqueue->pending_count));\r\npentry->post_arg = NULL;\r\npending_queue_inc_front(pqinfo, qno);\r\ndo_request_cleanup(cptvf, info);\r\nspin_unlock_bh(&pqueue->lock);\r\nbreak;\r\n} else if (status->s.compcode == COMPLETION_CODE_INIT) {\r\nif (time_after_eq(jiffies,\r\n(info->time_in +\r\n(CPT_COMMAND_TIMEOUT * HZ)))) {\r\ndev_err(&pdev->dev, "Request timed out");\r\npentry->completion_addr = NULL;\r\npentry->busy = false;\r\natomic64_dec((&pqueue->pending_count));\r\npentry->post_arg = NULL;\r\npending_queue_inc_front(pqinfo, qno);\r\ndo_request_cleanup(cptvf, info);\r\nspin_unlock_bh(&pqueue->lock);\r\nbreak;\r\n} else if ((*info->alternate_caddr ==\r\n(~COMPLETION_CODE_INIT)) &&\r\n(info->extra_time < TIME_IN_RESET_COUNT)) {\r\ninfo->time_in = jiffies;\r\ninfo->extra_time++;\r\nspin_unlock_bh(&pqueue->lock);\r\nbreak;\r\n}\r\n}\r\npentry->completion_addr = NULL;\r\npentry->busy = false;\r\npentry->post_arg = NULL;\r\natomic64_dec((&pqueue->pending_count));\r\npending_queue_inc_front(pqinfo, qno);\r\nspin_unlock_bh(&pqueue->lock);\r\ndo_post_process(info->cptvf, info);\r\npentry->callback(ccode, pentry->callback_arg);\r\n}\r\n}\r\nint process_request(struct cpt_vf *cptvf, struct cpt_request_info *req)\r\n{\r\nint ret = 0, clear = 0, queue = 0;\r\nstruct cpt_info_buffer *info = NULL;\r\nstruct cptvf_request *cpt_req = NULL;\r\nunion ctrl_info *ctrl = NULL;\r\nunion cpt_res_s *result = NULL;\r\nstruct pending_entry *pentry = NULL;\r\nstruct pending_queue *pqueue = NULL;\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nu8 group = 0;\r\nstruct cpt_vq_command vq_cmd;\r\nunion cpt_inst_s cptinst;\r\ninfo = kzalloc(sizeof(*info), GFP_KERNEL);\r\nif (unlikely(!info)) {\r\ndev_err(&pdev->dev, "Unable to allocate memory for info_buffer\n");\r\nreturn -ENOMEM;\r\n}\r\ncpt_req = (struct cptvf_request *)&req->req;\r\nctrl = (union ctrl_info *)&req->ctrl;\r\ninfo->cptvf = cptvf;\r\ngroup = ctrl->s.grp;\r\nret = setup_sgio_list(cptvf, info, req);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Setting up SG list failed");\r\ngoto request_cleanup;\r\n}\r\ncpt_req->dlen = info->dlen;\r\ninfo->completion_addr = kzalloc(sizeof(union cpt_res_s), GFP_KERNEL);\r\nif (unlikely(!info->completion_addr)) {\r\ndev_err(&pdev->dev, "Unable to allocate memory for completion_addr\n");\r\nreturn -ENOMEM;\r\n}\r\nresult = (union cpt_res_s *)info->completion_addr;\r\nresult->s.compcode = COMPLETION_CODE_INIT;\r\ninfo->comp_baddr = dma_map_single(&pdev->dev,\r\n(void *)info->completion_addr,\r\nsizeof(union cpt_res_s),\r\nDMA_BIDIRECTIONAL);\r\nif (dma_mapping_error(&pdev->dev, info->comp_baddr)) {\r\ndev_err(&pdev->dev, "mapping compptr Failed %lu\n",\r\nsizeof(union cpt_res_s));\r\nret = -EFAULT;\r\ngoto request_cleanup;\r\n}\r\nvq_cmd.cmd.u64 = 0;\r\nvq_cmd.cmd.s.opcode = cpu_to_be16(cpt_req->opcode.flags);\r\nvq_cmd.cmd.s.param1 = cpu_to_be16(cpt_req->param1);\r\nvq_cmd.cmd.s.param2 = cpu_to_be16(cpt_req->param2);\r\nvq_cmd.cmd.s.dlen = cpu_to_be16(cpt_req->dlen);\r\nvq_cmd.cmd.u64 = cpu_to_be64(vq_cmd.cmd.u64);\r\nvq_cmd.dptr = info->dptr_baddr;\r\nvq_cmd.rptr = info->rptr_baddr;\r\nvq_cmd.cptr.u64 = 0;\r\nvq_cmd.cptr.s.grp = group;\r\nqueue = 0;\r\npqueue = &cptvf->pqinfo.queue[queue];\r\nif (atomic64_read(&pqueue->pending_count) > PENDING_THOLD) {\r\ndev_err(&pdev->dev, "pending threshold reached\n");\r\nprocess_pending_queue(cptvf, &cptvf->pqinfo, queue);\r\n}\r\nget_pending_entry:\r\nspin_lock_bh(&pqueue->lock);\r\npentry = get_free_pending_entry(pqueue, cptvf->pqinfo.qlen);\r\nif (unlikely(!pentry)) {\r\nspin_unlock_bh(&pqueue->lock);\r\nif (clear == 0) {\r\nprocess_pending_queue(cptvf, &cptvf->pqinfo, queue);\r\nclear = 1;\r\ngoto get_pending_entry;\r\n}\r\ndev_err(&pdev->dev, "Get free entry failed\n");\r\ndev_err(&pdev->dev, "queue: %d, rear: %d, front: %d\n",\r\nqueue, pqueue->rear, pqueue->front);\r\nret = -EFAULT;\r\ngoto request_cleanup;\r\n}\r\npentry->completion_addr = info->completion_addr;\r\npentry->post_arg = (void *)info;\r\npentry->callback = req->callback;\r\npentry->callback_arg = req->callback_arg;\r\ninfo->pentry = pentry;\r\npentry->busy = true;\r\natomic64_inc(&pqueue->pending_count);\r\ninfo->pentry = pentry;\r\ninfo->time_in = jiffies;\r\ninfo->req = req;\r\ncptinst.s.doneint = true;\r\ncptinst.s.res_addr = (u64)info->comp_baddr;\r\ncptinst.s.tag = 0;\r\ncptinst.s.grp = 0;\r\ncptinst.s.wq_ptr = 0;\r\ncptinst.s.ei0 = vq_cmd.cmd.u64;\r\ncptinst.s.ei1 = vq_cmd.dptr;\r\ncptinst.s.ei2 = vq_cmd.rptr;\r\ncptinst.s.ei3 = vq_cmd.cptr.u64;\r\nret = send_cpt_command(cptvf, &cptinst, queue);\r\nspin_unlock_bh(&pqueue->lock);\r\nif (unlikely(ret)) {\r\ndev_err(&pdev->dev, "Send command failed for AE\n");\r\nret = -EFAULT;\r\ngoto request_cleanup;\r\n}\r\nreturn 0;\r\nrequest_cleanup:\r\ndev_dbg(&pdev->dev, "Failed to submit CPT command\n");\r\ndo_request_cleanup(cptvf, info);\r\nreturn ret;\r\n}\r\nvoid vq_post_process(struct cpt_vf *cptvf, u32 qno)\r\n{\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nif (unlikely(qno > cptvf->nr_queues)) {\r\ndev_err(&pdev->dev, "Request for post processing on invalid pending queue: %u\n",\r\nqno);\r\nreturn;\r\n}\r\nprocess_pending_queue(cptvf, &cptvf->pqinfo, qno);\r\n}\r\nint cptvf_do_request(void *vfdev, struct cpt_request_info *req)\r\n{\r\nstruct cpt_vf *cptvf = (struct cpt_vf *)vfdev;\r\nstruct pci_dev *pdev = cptvf->pdev;\r\nif (!cpt_device_ready(cptvf)) {\r\ndev_err(&pdev->dev, "CPT Device is not ready");\r\nreturn -ENODEV;\r\n}\r\nif ((cptvf->vftype == SE_TYPES) && (!req->ctrl.s.se_req)) {\r\ndev_err(&pdev->dev, "CPTVF-%d of SE TYPE got AE request",\r\ncptvf->vfid);\r\nreturn -EINVAL;\r\n} else if ((cptvf->vftype == AE_TYPES) && (req->ctrl.s.se_req)) {\r\ndev_err(&pdev->dev, "CPTVF-%d of AE TYPE got SE request",\r\ncptvf->vfid);\r\nreturn -EINVAL;\r\n}\r\nreturn process_request(cptvf, req);\r\n}
