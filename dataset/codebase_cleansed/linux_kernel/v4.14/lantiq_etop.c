static int\r\nltq_etop_alloc_skb(struct ltq_etop_chan *ch)\r\n{\r\nch->skb[ch->dma.desc] = netdev_alloc_skb(ch->netdev, MAX_DMA_DATA_LEN);\r\nif (!ch->skb[ch->dma.desc])\r\nreturn -ENOMEM;\r\nch->dma.desc_base[ch->dma.desc].addr = dma_map_single(NULL,\r\nch->skb[ch->dma.desc]->data, MAX_DMA_DATA_LEN,\r\nDMA_FROM_DEVICE);\r\nch->dma.desc_base[ch->dma.desc].addr =\r\nCPHYSADDR(ch->skb[ch->dma.desc]->data);\r\nch->dma.desc_base[ch->dma.desc].ctl =\r\nLTQ_DMA_OWN | LTQ_DMA_RX_OFFSET(NET_IP_ALIGN) |\r\nMAX_DMA_DATA_LEN;\r\nskb_reserve(ch->skb[ch->dma.desc], NET_IP_ALIGN);\r\nreturn 0;\r\n}\r\nstatic void\r\nltq_etop_hw_receive(struct ltq_etop_chan *ch)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(ch->netdev);\r\nstruct ltq_dma_desc *desc = &ch->dma.desc_base[ch->dma.desc];\r\nstruct sk_buff *skb = ch->skb[ch->dma.desc];\r\nint len = (desc->ctl & LTQ_DMA_SIZE_MASK) - MAX_DMA_CRC_LEN;\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nif (ltq_etop_alloc_skb(ch)) {\r\nnetdev_err(ch->netdev,\r\n"failed to allocate new rx buffer, stopping DMA\n");\r\nltq_dma_close(&ch->dma);\r\n}\r\nch->dma.desc++;\r\nch->dma.desc %= LTQ_DESC_NUM;\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nskb_put(skb, len);\r\nskb->protocol = eth_type_trans(skb, ch->netdev);\r\nnetif_receive_skb(skb);\r\n}\r\nstatic int\r\nltq_etop_poll_rx(struct napi_struct *napi, int budget)\r\n{\r\nstruct ltq_etop_chan *ch = container_of(napi,\r\nstruct ltq_etop_chan, napi);\r\nint work_done = 0;\r\nwhile (work_done < budget) {\r\nstruct ltq_dma_desc *desc = &ch->dma.desc_base[ch->dma.desc];\r\nif ((desc->ctl & (LTQ_DMA_OWN | LTQ_DMA_C)) != LTQ_DMA_C)\r\nbreak;\r\nltq_etop_hw_receive(ch);\r\nwork_done++;\r\n}\r\nif (work_done < budget) {\r\nnapi_complete_done(&ch->napi, work_done);\r\nltq_dma_ack_irq(&ch->dma);\r\n}\r\nreturn work_done;\r\n}\r\nstatic int\r\nltq_etop_poll_tx(struct napi_struct *napi, int budget)\r\n{\r\nstruct ltq_etop_chan *ch =\r\ncontainer_of(napi, struct ltq_etop_chan, napi);\r\nstruct ltq_etop_priv *priv = netdev_priv(ch->netdev);\r\nstruct netdev_queue *txq =\r\nnetdev_get_tx_queue(ch->netdev, ch->idx >> 1);\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nwhile ((ch->dma.desc_base[ch->tx_free].ctl &\r\n(LTQ_DMA_OWN | LTQ_DMA_C)) == LTQ_DMA_C) {\r\ndev_kfree_skb_any(ch->skb[ch->tx_free]);\r\nch->skb[ch->tx_free] = NULL;\r\nmemset(&ch->dma.desc_base[ch->tx_free], 0,\r\nsizeof(struct ltq_dma_desc));\r\nch->tx_free++;\r\nch->tx_free %= LTQ_DESC_NUM;\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (netif_tx_queue_stopped(txq))\r\nnetif_tx_start_queue(txq);\r\nnapi_complete(&ch->napi);\r\nltq_dma_ack_irq(&ch->dma);\r\nreturn 1;\r\n}\r\nstatic irqreturn_t\r\nltq_etop_dma_irq(int irq, void *_priv)\r\n{\r\nstruct ltq_etop_priv *priv = _priv;\r\nint ch = irq - LTQ_DMA_CH0_INT;\r\nnapi_schedule(&priv->ch[ch].napi);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void\r\nltq_etop_free_channel(struct net_device *dev, struct ltq_etop_chan *ch)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nltq_dma_free(&ch->dma);\r\nif (ch->dma.irq)\r\nfree_irq(ch->dma.irq, priv);\r\nif (IS_RX(ch->idx)) {\r\nint desc;\r\nfor (desc = 0; desc < LTQ_DESC_NUM; desc++)\r\ndev_kfree_skb_any(ch->skb[ch->dma.desc]);\r\n}\r\n}\r\nstatic void\r\nltq_etop_hw_exit(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nint i;\r\nltq_pmu_disable(PMU_PPE);\r\nfor (i = 0; i < MAX_DMA_CHAN; i++)\r\nif (IS_TX(i) || IS_RX(i))\r\nltq_etop_free_channel(dev, &priv->ch[i]);\r\n}\r\nstatic int\r\nltq_etop_hw_init(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nint i;\r\nltq_pmu_enable(PMU_PPE);\r\nswitch (priv->pldata->mii_mode) {\r\ncase PHY_INTERFACE_MODE_RMII:\r\nltq_etop_w32_mask(ETOP_MII_MASK,\r\nETOP_MII_REVERSE, LTQ_ETOP_CFG);\r\nbreak;\r\ncase PHY_INTERFACE_MODE_MII:\r\nltq_etop_w32_mask(ETOP_MII_MASK,\r\nETOP_MII_NORMAL, LTQ_ETOP_CFG);\r\nbreak;\r\ndefault:\r\nnetdev_err(dev, "unknown mii mode %d\n",\r\npriv->pldata->mii_mode);\r\nreturn -ENOTSUPP;\r\n}\r\nltq_etop_w32(PPE32_CGEN, LQ_PPE32_ENET_MAC_CFG);\r\nltq_dma_init_port(DMA_PORT_ETOP);\r\nfor (i = 0; i < MAX_DMA_CHAN; i++) {\r\nint irq = LTQ_DMA_CH0_INT + i;\r\nstruct ltq_etop_chan *ch = &priv->ch[i];\r\nch->idx = ch->dma.nr = i;\r\nif (IS_TX(i)) {\r\nltq_dma_alloc_tx(&ch->dma);\r\nrequest_irq(irq, ltq_etop_dma_irq, 0, "etop_tx", priv);\r\n} else if (IS_RX(i)) {\r\nltq_dma_alloc_rx(&ch->dma);\r\nfor (ch->dma.desc = 0; ch->dma.desc < LTQ_DESC_NUM;\r\nch->dma.desc++)\r\nif (ltq_etop_alloc_skb(ch))\r\nreturn -ENOMEM;\r\nch->dma.desc = 0;\r\nrequest_irq(irq, ltq_etop_dma_irq, 0, "etop_rx", priv);\r\n}\r\nch->dma.irq = irq;\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nltq_etop_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstrlcpy(info->driver, "Lantiq ETOP", sizeof(info->driver));\r\nstrlcpy(info->bus_info, "internal", sizeof(info->bus_info));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\n}\r\nstatic int\r\nltq_etop_mdio_wr(struct mii_bus *bus, int phy_addr, int phy_reg, u16 phy_data)\r\n{\r\nu32 val = MDIO_REQUEST |\r\n((phy_addr & MDIO_ADDR_MASK) << MDIO_ADDR_OFFSET) |\r\n((phy_reg & MDIO_REG_MASK) << MDIO_REG_OFFSET) |\r\nphy_data;\r\nwhile (ltq_etop_r32(LTQ_ETOP_MDIO) & MDIO_REQUEST)\r\n;\r\nltq_etop_w32(val, LTQ_ETOP_MDIO);\r\nreturn 0;\r\n}\r\nstatic int\r\nltq_etop_mdio_rd(struct mii_bus *bus, int phy_addr, int phy_reg)\r\n{\r\nu32 val = MDIO_REQUEST | MDIO_READ |\r\n((phy_addr & MDIO_ADDR_MASK) << MDIO_ADDR_OFFSET) |\r\n((phy_reg & MDIO_REG_MASK) << MDIO_REG_OFFSET);\r\nwhile (ltq_etop_r32(LTQ_ETOP_MDIO) & MDIO_REQUEST)\r\n;\r\nltq_etop_w32(val, LTQ_ETOP_MDIO);\r\nwhile (ltq_etop_r32(LTQ_ETOP_MDIO) & MDIO_REQUEST)\r\n;\r\nval = ltq_etop_r32(LTQ_ETOP_MDIO) & MDIO_VAL_MASK;\r\nreturn val;\r\n}\r\nstatic void\r\nltq_etop_mdio_link(struct net_device *dev)\r\n{\r\n}\r\nstatic int\r\nltq_etop_mdio_probe(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nstruct phy_device *phydev;\r\nphydev = phy_find_first(priv->mii_bus);\r\nif (!phydev) {\r\nnetdev_err(dev, "no PHY found\n");\r\nreturn -ENODEV;\r\n}\r\nphydev = phy_connect(dev, phydev_name(phydev),\r\n&ltq_etop_mdio_link, priv->pldata->mii_mode);\r\nif (IS_ERR(phydev)) {\r\nnetdev_err(dev, "Could not attach to PHY\n");\r\nreturn PTR_ERR(phydev);\r\n}\r\nphydev->supported &= (SUPPORTED_10baseT_Half\r\n| SUPPORTED_10baseT_Full\r\n| SUPPORTED_100baseT_Half\r\n| SUPPORTED_100baseT_Full\r\n| SUPPORTED_Autoneg\r\n| SUPPORTED_MII\r\n| SUPPORTED_TP);\r\nphydev->advertising = phydev->supported;\r\nphy_attached_info(phydev);\r\nreturn 0;\r\n}\r\nstatic int\r\nltq_etop_mdio_init(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nint err;\r\npriv->mii_bus = mdiobus_alloc();\r\nif (!priv->mii_bus) {\r\nnetdev_err(dev, "failed to allocate mii bus\n");\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\npriv->mii_bus->priv = dev;\r\npriv->mii_bus->read = ltq_etop_mdio_rd;\r\npriv->mii_bus->write = ltq_etop_mdio_wr;\r\npriv->mii_bus->name = "ltq_mii";\r\nsnprintf(priv->mii_bus->id, MII_BUS_ID_SIZE, "%s-%x",\r\npriv->pdev->name, priv->pdev->id);\r\nif (mdiobus_register(priv->mii_bus)) {\r\nerr = -ENXIO;\r\ngoto err_out_free_mdiobus;\r\n}\r\nif (ltq_etop_mdio_probe(dev)) {\r\nerr = -ENXIO;\r\ngoto err_out_unregister_bus;\r\n}\r\nreturn 0;\r\nerr_out_unregister_bus:\r\nmdiobus_unregister(priv->mii_bus);\r\nerr_out_free_mdiobus:\r\nmdiobus_free(priv->mii_bus);\r\nerr_out:\r\nreturn err;\r\n}\r\nstatic void\r\nltq_etop_mdio_cleanup(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nphy_disconnect(dev->phydev);\r\nmdiobus_unregister(priv->mii_bus);\r\nmdiobus_free(priv->mii_bus);\r\n}\r\nstatic int\r\nltq_etop_open(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nint i;\r\nfor (i = 0; i < MAX_DMA_CHAN; i++) {\r\nstruct ltq_etop_chan *ch = &priv->ch[i];\r\nif (!IS_TX(i) && (!IS_RX(i)))\r\ncontinue;\r\nltq_dma_open(&ch->dma);\r\nnapi_enable(&ch->napi);\r\n}\r\nphy_start(dev->phydev);\r\nnetif_tx_start_all_queues(dev);\r\nreturn 0;\r\n}\r\nstatic int\r\nltq_etop_stop(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nint i;\r\nnetif_tx_stop_all_queues(dev);\r\nphy_stop(dev->phydev);\r\nfor (i = 0; i < MAX_DMA_CHAN; i++) {\r\nstruct ltq_etop_chan *ch = &priv->ch[i];\r\nif (!IS_RX(i) && !IS_TX(i))\r\ncontinue;\r\nnapi_disable(&ch->napi);\r\nltq_dma_close(&ch->dma);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nltq_etop_tx(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nint queue = skb_get_queue_mapping(skb);\r\nstruct netdev_queue *txq = netdev_get_tx_queue(dev, queue);\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nstruct ltq_etop_chan *ch = &priv->ch[(queue << 1) | 1];\r\nstruct ltq_dma_desc *desc = &ch->dma.desc_base[ch->dma.desc];\r\nint len;\r\nunsigned long flags;\r\nu32 byte_offset;\r\nlen = skb->len < ETH_ZLEN ? ETH_ZLEN : skb->len;\r\nif ((desc->ctl & (LTQ_DMA_OWN | LTQ_DMA_C)) || ch->skb[ch->dma.desc]) {\r\ndev_kfree_skb_any(skb);\r\nnetdev_err(dev, "tx ring full\n");\r\nnetif_tx_stop_queue(txq);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nbyte_offset = CPHYSADDR(skb->data) % 16;\r\nch->skb[ch->dma.desc] = skb;\r\nnetif_trans_update(dev);\r\nspin_lock_irqsave(&priv->lock, flags);\r\ndesc->addr = ((unsigned int) dma_map_single(NULL, skb->data, len,\r\nDMA_TO_DEVICE)) - byte_offset;\r\nwmb();\r\ndesc->ctl = LTQ_DMA_OWN | LTQ_DMA_SOP | LTQ_DMA_EOP |\r\nLTQ_DMA_TX_OFFSET(byte_offset) | (len & LTQ_DMA_SIZE_MASK);\r\nch->dma.desc++;\r\nch->dma.desc %= LTQ_DESC_NUM;\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (ch->dma.desc_base[ch->dma.desc].ctl & LTQ_DMA_OWN)\r\nnetif_tx_stop_queue(txq);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int\r\nltq_etop_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nunsigned long flags;\r\ndev->mtu = new_mtu;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nltq_etop_w32((ETOP_PLEN_UNDER << 16) | new_mtu, LTQ_ETOP_IGPLEN);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nreturn 0;\r\n}\r\nstatic int\r\nltq_etop_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\r\n{\r\nreturn phy_mii_ioctl(dev->phydev, rq, cmd);\r\n}\r\nstatic int\r\nltq_etop_set_mac_address(struct net_device *dev, void *p)\r\n{\r\nint ret = eth_mac_addr(dev, p);\r\nif (!ret) {\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nltq_etop_w32(*((u32 *)dev->dev_addr), LTQ_ETOP_MAC_DA0);\r\nltq_etop_w32(*((u16 *)&dev->dev_addr[4]) << 16,\r\nLTQ_ETOP_MAC_DA1);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nreturn ret;\r\n}\r\nstatic void\r\nltq_etop_set_multicast_list(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nif ((dev->flags & IFF_PROMISC) || (dev->flags & IFF_ALLMULTI))\r\nltq_etop_w32_mask(ETOP_FTCU, 0, LTQ_ETOP_ENETS0);\r\nelse\r\nltq_etop_w32_mask(0, ETOP_FTCU, LTQ_ETOP_ENETS0);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic u16\r\nltq_etop_select_queue(struct net_device *dev, struct sk_buff *skb,\r\nvoid *accel_priv, select_queue_fallback_t fallback)\r\n{\r\nreturn 0;\r\n}\r\nstatic int\r\nltq_etop_init(struct net_device *dev)\r\n{\r\nstruct ltq_etop_priv *priv = netdev_priv(dev);\r\nstruct sockaddr mac;\r\nint err;\r\nbool random_mac = false;\r\ndev->watchdog_timeo = 10 * HZ;\r\nerr = ltq_etop_hw_init(dev);\r\nif (err)\r\ngoto err_hw;\r\nltq_etop_change_mtu(dev, 1500);\r\nmemcpy(&mac, &priv->pldata->mac, sizeof(struct sockaddr));\r\nif (!is_valid_ether_addr(mac.sa_data)) {\r\npr_warn("etop: invalid MAC, using random\n");\r\neth_random_addr(mac.sa_data);\r\nrandom_mac = true;\r\n}\r\nerr = ltq_etop_set_mac_address(dev, &mac);\r\nif (err)\r\ngoto err_netdev;\r\nif (random_mac)\r\ndev->addr_assign_type = NET_ADDR_RANDOM;\r\nltq_etop_set_multicast_list(dev);\r\nerr = ltq_etop_mdio_init(dev);\r\nif (err)\r\ngoto err_netdev;\r\nreturn 0;\r\nerr_netdev:\r\nunregister_netdev(dev);\r\nfree_netdev(dev);\r\nerr_hw:\r\nltq_etop_hw_exit(dev);\r\nreturn err;\r\n}\r\nstatic void\r\nltq_etop_tx_timeout(struct net_device *dev)\r\n{\r\nint err;\r\nltq_etop_hw_exit(dev);\r\nerr = ltq_etop_hw_init(dev);\r\nif (err)\r\ngoto err_hw;\r\nnetif_trans_update(dev);\r\nnetif_wake_queue(dev);\r\nreturn;\r\nerr_hw:\r\nltq_etop_hw_exit(dev);\r\nnetdev_err(dev, "failed to restart etop after TX timeout\n");\r\n}\r\nstatic int __init\r\nltq_etop_probe(struct platform_device *pdev)\r\n{\r\nstruct net_device *dev;\r\nstruct ltq_etop_priv *priv;\r\nstruct resource *res;\r\nint err;\r\nint i;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(&pdev->dev, "failed to get etop resource\n");\r\nerr = -ENOENT;\r\ngoto err_out;\r\n}\r\nres = devm_request_mem_region(&pdev->dev, res->start,\r\nresource_size(res), dev_name(&pdev->dev));\r\nif (!res) {\r\ndev_err(&pdev->dev, "failed to request etop resource\n");\r\nerr = -EBUSY;\r\ngoto err_out;\r\n}\r\nltq_etop_membase = devm_ioremap_nocache(&pdev->dev,\r\nres->start, resource_size(res));\r\nif (!ltq_etop_membase) {\r\ndev_err(&pdev->dev, "failed to remap etop engine %d\n",\r\npdev->id);\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\ndev = alloc_etherdev_mq(sizeof(struct ltq_etop_priv), 4);\r\nif (!dev) {\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\nstrcpy(dev->name, "eth%d");\r\ndev->netdev_ops = &ltq_eth_netdev_ops;\r\ndev->ethtool_ops = &ltq_etop_ethtool_ops;\r\npriv = netdev_priv(dev);\r\npriv->res = res;\r\npriv->pdev = pdev;\r\npriv->pldata = dev_get_platdata(&pdev->dev);\r\npriv->netdev = dev;\r\nspin_lock_init(&priv->lock);\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nfor (i = 0; i < MAX_DMA_CHAN; i++) {\r\nif (IS_TX(i))\r\nnetif_napi_add(dev, &priv->ch[i].napi,\r\nltq_etop_poll_tx, 8);\r\nelse if (IS_RX(i))\r\nnetif_napi_add(dev, &priv->ch[i].napi,\r\nltq_etop_poll_rx, 32);\r\npriv->ch[i].netdev = dev;\r\n}\r\nerr = register_netdev(dev);\r\nif (err)\r\ngoto err_free;\r\nplatform_set_drvdata(pdev, dev);\r\nreturn 0;\r\nerr_free:\r\nfree_netdev(dev);\r\nerr_out:\r\nreturn err;\r\n}\r\nstatic int\r\nltq_etop_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *dev = platform_get_drvdata(pdev);\r\nif (dev) {\r\nnetif_tx_stop_all_queues(dev);\r\nltq_etop_hw_exit(dev);\r\nltq_etop_mdio_cleanup(dev);\r\nunregister_netdev(dev);\r\n}\r\nreturn 0;\r\n}\r\nint __init\r\ninit_ltq_etop(void)\r\n{\r\nint ret = platform_driver_probe(&ltq_mii_driver, ltq_etop_probe);\r\nif (ret)\r\npr_err("ltq_etop: Error registering platform driver!");\r\nreturn ret;\r\n}\r\nstatic void __exit\r\nexit_ltq_etop(void)\r\n{\r\nplatform_driver_unregister(&ltq_mii_driver);\r\n}
