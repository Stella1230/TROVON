static struct drm_i915_gem_object *dma_buf_to_obj(struct dma_buf *buf)\r\n{\r\nreturn to_intel_bo(buf->priv);\r\n}\r\nstatic struct sg_table *i915_gem_map_dma_buf(struct dma_buf_attachment *attachment,\r\nenum dma_data_direction dir)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(attachment->dmabuf);\r\nstruct sg_table *st;\r\nstruct scatterlist *src, *dst;\r\nint ret, i;\r\nret = i915_gem_object_pin_pages(obj);\r\nif (ret)\r\ngoto err;\r\nst = kmalloc(sizeof(struct sg_table), GFP_KERNEL);\r\nif (st == NULL) {\r\nret = -ENOMEM;\r\ngoto err_unpin_pages;\r\n}\r\nret = sg_alloc_table(st, obj->mm.pages->nents, GFP_KERNEL);\r\nif (ret)\r\ngoto err_free;\r\nsrc = obj->mm.pages->sgl;\r\ndst = st->sgl;\r\nfor (i = 0; i < obj->mm.pages->nents; i++) {\r\nsg_set_page(dst, sg_page(src), src->length, 0);\r\ndst = sg_next(dst);\r\nsrc = sg_next(src);\r\n}\r\nif (!dma_map_sg(attachment->dev, st->sgl, st->nents, dir)) {\r\nret = -ENOMEM;\r\ngoto err_free_sg;\r\n}\r\nreturn st;\r\nerr_free_sg:\r\nsg_free_table(st);\r\nerr_free:\r\nkfree(st);\r\nerr_unpin_pages:\r\ni915_gem_object_unpin_pages(obj);\r\nerr:\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic void i915_gem_unmap_dma_buf(struct dma_buf_attachment *attachment,\r\nstruct sg_table *sg,\r\nenum dma_data_direction dir)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(attachment->dmabuf);\r\ndma_unmap_sg(attachment->dev, sg->sgl, sg->nents, dir);\r\nsg_free_table(sg);\r\nkfree(sg);\r\ni915_gem_object_unpin_pages(obj);\r\n}\r\nstatic void *i915_gem_dmabuf_vmap(struct dma_buf *dma_buf)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);\r\nreturn i915_gem_object_pin_map(obj, I915_MAP_WB);\r\n}\r\nstatic void i915_gem_dmabuf_vunmap(struct dma_buf *dma_buf, void *vaddr)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);\r\ni915_gem_object_unpin_map(obj);\r\n}\r\nstatic void *i915_gem_dmabuf_kmap_atomic(struct dma_buf *dma_buf, unsigned long page_num)\r\n{\r\nreturn NULL;\r\n}\r\nstatic void i915_gem_dmabuf_kunmap_atomic(struct dma_buf *dma_buf, unsigned long page_num, void *addr)\r\n{\r\n}\r\nstatic void *i915_gem_dmabuf_kmap(struct dma_buf *dma_buf, unsigned long page_num)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);\r\nstruct page *page;\r\nif (page_num >= obj->base.size >> PAGE_SHIFT)\r\nreturn NULL;\r\nif (!i915_gem_object_has_struct_page(obj))\r\nreturn NULL;\r\nif (i915_gem_object_pin_pages(obj))\r\nreturn NULL;\r\npage = i915_gem_object_get_page(obj, page_num);\r\nif (IS_ERR(page))\r\ngoto err_unpin;\r\nreturn kmap(page);\r\nerr_unpin:\r\ni915_gem_object_unpin_pages(obj);\r\nreturn NULL;\r\n}\r\nstatic void i915_gem_dmabuf_kunmap(struct dma_buf *dma_buf, unsigned long page_num, void *addr)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);\r\nkunmap(virt_to_page(addr));\r\ni915_gem_object_unpin_pages(obj);\r\n}\r\nstatic int i915_gem_dmabuf_mmap(struct dma_buf *dma_buf, struct vm_area_struct *vma)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);\r\nint ret;\r\nif (obj->base.size < vma->vm_end - vma->vm_start)\r\nreturn -EINVAL;\r\nif (!obj->base.filp)\r\nreturn -ENODEV;\r\nret = call_mmap(obj->base.filp, vma);\r\nif (ret)\r\nreturn ret;\r\nfput(vma->vm_file);\r\nvma->vm_file = get_file(obj->base.filp);\r\nreturn 0;\r\n}\r\nstatic int i915_gem_begin_cpu_access(struct dma_buf *dma_buf, enum dma_data_direction direction)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);\r\nstruct drm_device *dev = obj->base.dev;\r\nbool write = (direction == DMA_BIDIRECTIONAL || direction == DMA_TO_DEVICE);\r\nint err;\r\nerr = i915_gem_object_pin_pages(obj);\r\nif (err)\r\nreturn err;\r\nerr = i915_mutex_lock_interruptible(dev);\r\nif (err)\r\ngoto out;\r\nerr = i915_gem_object_set_to_cpu_domain(obj, write);\r\nmutex_unlock(&dev->struct_mutex);\r\nout:\r\ni915_gem_object_unpin_pages(obj);\r\nreturn err;\r\n}\r\nstatic int i915_gem_end_cpu_access(struct dma_buf *dma_buf, enum dma_data_direction direction)\r\n{\r\nstruct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);\r\nstruct drm_device *dev = obj->base.dev;\r\nint err;\r\nerr = i915_gem_object_pin_pages(obj);\r\nif (err)\r\nreturn err;\r\nerr = i915_mutex_lock_interruptible(dev);\r\nif (err)\r\ngoto out;\r\nerr = i915_gem_object_set_to_gtt_domain(obj, false);\r\nmutex_unlock(&dev->struct_mutex);\r\nout:\r\ni915_gem_object_unpin_pages(obj);\r\nreturn err;\r\n}\r\nstruct dma_buf *i915_gem_prime_export(struct drm_device *dev,\r\nstruct drm_gem_object *gem_obj, int flags)\r\n{\r\nstruct drm_i915_gem_object *obj = to_intel_bo(gem_obj);\r\nDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\r\nexp_info.ops = &i915_dmabuf_ops;\r\nexp_info.size = gem_obj->size;\r\nexp_info.flags = flags;\r\nexp_info.priv = gem_obj;\r\nexp_info.resv = obj->resv;\r\nif (obj->ops->dmabuf_export) {\r\nint ret = obj->ops->dmabuf_export(obj);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\n}\r\nreturn drm_gem_dmabuf_export(dev, &exp_info);\r\n}\r\nstatic struct sg_table *\r\ni915_gem_object_get_pages_dmabuf(struct drm_i915_gem_object *obj)\r\n{\r\nreturn dma_buf_map_attachment(obj->base.import_attach,\r\nDMA_BIDIRECTIONAL);\r\n}\r\nstatic void i915_gem_object_put_pages_dmabuf(struct drm_i915_gem_object *obj,\r\nstruct sg_table *pages)\r\n{\r\ndma_buf_unmap_attachment(obj->base.import_attach, pages,\r\nDMA_BIDIRECTIONAL);\r\n}\r\nstruct drm_gem_object *i915_gem_prime_import(struct drm_device *dev,\r\nstruct dma_buf *dma_buf)\r\n{\r\nstruct dma_buf_attachment *attach;\r\nstruct drm_i915_gem_object *obj;\r\nint ret;\r\nif (dma_buf->ops == &i915_dmabuf_ops) {\r\nobj = dma_buf_to_obj(dma_buf);\r\nif (obj->base.dev == dev) {\r\nreturn &i915_gem_object_get(obj)->base;\r\n}\r\n}\r\nattach = dma_buf_attach(dma_buf, dev->dev);\r\nif (IS_ERR(attach))\r\nreturn ERR_CAST(attach);\r\nget_dma_buf(dma_buf);\r\nobj = i915_gem_object_alloc(to_i915(dev));\r\nif (obj == NULL) {\r\nret = -ENOMEM;\r\ngoto fail_detach;\r\n}\r\ndrm_gem_private_object_init(dev, &obj->base, dma_buf->size);\r\ni915_gem_object_init(obj, &i915_gem_object_dmabuf_ops);\r\nobj->base.import_attach = attach;\r\nobj->resv = dma_buf->resv;\r\nobj->base.read_domains = I915_GEM_DOMAIN_GTT;\r\nobj->base.write_domain = 0;\r\nreturn &obj->base;\r\nfail_detach:\r\ndma_buf_detach(dma_buf, attach);\r\ndma_buf_put(dma_buf);\r\nreturn ERR_PTR(ret);\r\n}
