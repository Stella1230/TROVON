static inline struct st_fdma_chan *to_st_fdma_chan(struct dma_chan *c)\r\n{\r\nreturn container_of(c, struct st_fdma_chan, vchan.chan);\r\n}\r\nstatic struct st_fdma_desc *to_st_fdma_desc(struct virt_dma_desc *vd)\r\n{\r\nreturn container_of(vd, struct st_fdma_desc, vdesc);\r\n}\r\nstatic int st_fdma_dreq_get(struct st_fdma_chan *fchan)\r\n{\r\nstruct st_fdma_dev *fdev = fchan->fdev;\r\nu32 req_line_cfg = fchan->cfg.req_line;\r\nu32 dreq_line;\r\nint try = 0;\r\ndo {\r\nif (fdev->dreq_mask == ~0L) {\r\ndev_err(fdev->dev, "No req lines available\n");\r\nreturn -EINVAL;\r\n}\r\nif (try || req_line_cfg >= ST_FDMA_NR_DREQS) {\r\ndev_err(fdev->dev, "Invalid or used req line\n");\r\nreturn -EINVAL;\r\n} else {\r\ndreq_line = req_line_cfg;\r\n}\r\ntry++;\r\n} while (test_and_set_bit(dreq_line, &fdev->dreq_mask));\r\ndev_dbg(fdev->dev, "get dreq_line:%d mask:%#lx\n",\r\ndreq_line, fdev->dreq_mask);\r\nreturn dreq_line;\r\n}\r\nstatic void st_fdma_dreq_put(struct st_fdma_chan *fchan)\r\n{\r\nstruct st_fdma_dev *fdev = fchan->fdev;\r\ndev_dbg(fdev->dev, "put dreq_line:%#x\n", fchan->dreq_line);\r\nclear_bit(fchan->dreq_line, &fdev->dreq_mask);\r\n}\r\nstatic void st_fdma_xfer_desc(struct st_fdma_chan *fchan)\r\n{\r\nstruct virt_dma_desc *vdesc;\r\nunsigned long nbytes, ch_cmd, cmd;\r\nvdesc = vchan_next_desc(&fchan->vchan);\r\nif (!vdesc)\r\nreturn;\r\nfchan->fdesc = to_st_fdma_desc(vdesc);\r\nnbytes = fchan->fdesc->node[0].desc->nbytes;\r\ncmd = FDMA_CMD_START(fchan->vchan.chan.chan_id);\r\nch_cmd = fchan->fdesc->node[0].pdesc | FDMA_CH_CMD_STA_START;\r\nfnode_write(fchan, nbytes, FDMA_CNTN_OFST);\r\nfchan_write(fchan, ch_cmd, FDMA_CH_CMD_OFST);\r\nwritel(cmd,\r\nfchan->fdev->slim_rproc->peri + FDMA_CMD_SET_OFST);\r\ndev_dbg(fchan->fdev->dev, "start chan:%d\n", fchan->vchan.chan.chan_id);\r\n}\r\nstatic void st_fdma_ch_sta_update(struct st_fdma_chan *fchan,\r\nunsigned long int_sta)\r\n{\r\nunsigned long ch_sta, ch_err;\r\nint ch_id = fchan->vchan.chan.chan_id;\r\nstruct st_fdma_dev *fdev = fchan->fdev;\r\nch_sta = fchan_read(fchan, FDMA_CH_CMD_OFST);\r\nch_err = ch_sta & FDMA_CH_CMD_ERR_MASK;\r\nch_sta &= FDMA_CH_CMD_STA_MASK;\r\nif (int_sta & FDMA_INT_STA_ERR) {\r\ndev_warn(fdev->dev, "chan:%d, error:%ld\n", ch_id, ch_err);\r\nfchan->status = DMA_ERROR;\r\nreturn;\r\n}\r\nswitch (ch_sta) {\r\ncase FDMA_CH_CMD_STA_PAUSED:\r\nfchan->status = DMA_PAUSED;\r\nbreak;\r\ncase FDMA_CH_CMD_STA_RUNNING:\r\nfchan->status = DMA_IN_PROGRESS;\r\nbreak;\r\n}\r\n}\r\nstatic irqreturn_t st_fdma_irq_handler(int irq, void *dev_id)\r\n{\r\nstruct st_fdma_dev *fdev = dev_id;\r\nirqreturn_t ret = IRQ_NONE;\r\nstruct st_fdma_chan *fchan = &fdev->chans[0];\r\nunsigned long int_sta, clr;\r\nint_sta = fdma_read(fdev, FDMA_INT_STA_OFST);\r\nclr = int_sta;\r\nfor (; int_sta != 0 ; int_sta >>= 2, fchan++) {\r\nif (!(int_sta & (FDMA_INT_STA_CH | FDMA_INT_STA_ERR)))\r\ncontinue;\r\nspin_lock(&fchan->vchan.lock);\r\nst_fdma_ch_sta_update(fchan, int_sta);\r\nif (fchan->fdesc) {\r\nif (!fchan->fdesc->iscyclic) {\r\nlist_del(&fchan->fdesc->vdesc.node);\r\nvchan_cookie_complete(&fchan->fdesc->vdesc);\r\nfchan->fdesc = NULL;\r\nfchan->status = DMA_COMPLETE;\r\n} else {\r\nvchan_cyclic_callback(&fchan->fdesc->vdesc);\r\n}\r\nif (!fchan->fdesc)\r\nst_fdma_xfer_desc(fchan);\r\n}\r\nspin_unlock(&fchan->vchan.lock);\r\nret = IRQ_HANDLED;\r\n}\r\nfdma_write(fdev, clr, FDMA_INT_CLR_OFST);\r\nreturn ret;\r\n}\r\nstatic struct dma_chan *st_fdma_of_xlate(struct of_phandle_args *dma_spec,\r\nstruct of_dma *ofdma)\r\n{\r\nstruct st_fdma_dev *fdev = ofdma->of_dma_data;\r\nstruct dma_chan *chan;\r\nstruct st_fdma_chan *fchan;\r\nint ret;\r\nif (dma_spec->args_count < 1)\r\nreturn ERR_PTR(-EINVAL);\r\nif (fdev->dma_device.dev->of_node != dma_spec->np)\r\nreturn ERR_PTR(-EINVAL);\r\nret = rproc_boot(fdev->slim_rproc->rproc);\r\nif (ret == -ENOENT)\r\nreturn ERR_PTR(-EPROBE_DEFER);\r\nelse if (ret)\r\nreturn ERR_PTR(ret);\r\nchan = dma_get_any_slave_channel(&fdev->dma_device);\r\nif (!chan)\r\ngoto err_chan;\r\nfchan = to_st_fdma_chan(chan);\r\nfchan->cfg.of_node = dma_spec->np;\r\nfchan->cfg.req_line = dma_spec->args[0];\r\nfchan->cfg.req_ctrl = 0;\r\nfchan->cfg.type = ST_FDMA_TYPE_FREE_RUN;\r\nif (dma_spec->args_count > 1)\r\nfchan->cfg.req_ctrl = dma_spec->args[1]\r\n& FDMA_REQ_CTRL_CFG_MASK;\r\nif (dma_spec->args_count > 2)\r\nfchan->cfg.type = dma_spec->args[2];\r\nif (fchan->cfg.type == ST_FDMA_TYPE_FREE_RUN) {\r\nfchan->dreq_line = 0;\r\n} else {\r\nfchan->dreq_line = st_fdma_dreq_get(fchan);\r\nif (IS_ERR_VALUE(fchan->dreq_line)) {\r\nchan = ERR_PTR(fchan->dreq_line);\r\ngoto err_chan;\r\n}\r\n}\r\ndev_dbg(fdev->dev, "xlate req_line:%d type:%d req_ctrl:%#lx\n",\r\nfchan->cfg.req_line, fchan->cfg.type, fchan->cfg.req_ctrl);\r\nreturn chan;\r\nerr_chan:\r\nrproc_shutdown(fdev->slim_rproc->rproc);\r\nreturn chan;\r\n}\r\nstatic void st_fdma_free_desc(struct virt_dma_desc *vdesc)\r\n{\r\nstruct st_fdma_desc *fdesc;\r\nint i;\r\nfdesc = to_st_fdma_desc(vdesc);\r\nfor (i = 0; i < fdesc->n_nodes; i++)\r\ndma_pool_free(fdesc->fchan->node_pool, fdesc->node[i].desc,\r\nfdesc->node[i].pdesc);\r\nkfree(fdesc);\r\n}\r\nstatic struct st_fdma_desc *st_fdma_alloc_desc(struct st_fdma_chan *fchan,\r\nint sg_len)\r\n{\r\nstruct st_fdma_desc *fdesc;\r\nint i;\r\nfdesc = kzalloc(sizeof(*fdesc) +\r\nsizeof(struct st_fdma_sw_node) * sg_len, GFP_NOWAIT);\r\nif (!fdesc)\r\nreturn NULL;\r\nfdesc->fchan = fchan;\r\nfdesc->n_nodes = sg_len;\r\nfor (i = 0; i < sg_len; i++) {\r\nfdesc->node[i].desc = dma_pool_alloc(fchan->node_pool,\r\nGFP_NOWAIT, &fdesc->node[i].pdesc);\r\nif (!fdesc->node[i].desc)\r\ngoto err;\r\n}\r\nreturn fdesc;\r\nerr:\r\nwhile (--i >= 0)\r\ndma_pool_free(fchan->node_pool, fdesc->node[i].desc,\r\nfdesc->node[i].pdesc);\r\nkfree(fdesc);\r\nreturn NULL;\r\n}\r\nstatic int st_fdma_alloc_chan_res(struct dma_chan *chan)\r\n{\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nfchan->node_pool = dma_pool_create(dev_name(&chan->dev->device),\r\nfchan->fdev->dev,\r\nsizeof(struct st_fdma_hw_node),\r\n__alignof__(struct st_fdma_hw_node),\r\n0);\r\nif (!fchan->node_pool) {\r\ndev_err(fchan->fdev->dev, "unable to allocate desc pool\n");\r\nreturn -ENOMEM;\r\n}\r\ndev_dbg(fchan->fdev->dev, "alloc ch_id:%d type:%d\n",\r\nfchan->vchan.chan.chan_id, fchan->cfg.type);\r\nreturn 0;\r\n}\r\nstatic void st_fdma_free_chan_res(struct dma_chan *chan)\r\n{\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nstruct rproc *rproc = fchan->fdev->slim_rproc->rproc;\r\nunsigned long flags;\r\nLIST_HEAD(head);\r\ndev_dbg(fchan->fdev->dev, "%s: freeing chan:%d\n",\r\n__func__, fchan->vchan.chan.chan_id);\r\nif (fchan->cfg.type != ST_FDMA_TYPE_FREE_RUN)\r\nst_fdma_dreq_put(fchan);\r\nspin_lock_irqsave(&fchan->vchan.lock, flags);\r\nfchan->fdesc = NULL;\r\nspin_unlock_irqrestore(&fchan->vchan.lock, flags);\r\ndma_pool_destroy(fchan->node_pool);\r\nfchan->node_pool = NULL;\r\nmemset(&fchan->cfg, 0, sizeof(struct st_fdma_cfg));\r\nrproc_shutdown(rproc);\r\n}\r\nstatic struct dma_async_tx_descriptor *st_fdma_prep_dma_memcpy(\r\nstruct dma_chan *chan, dma_addr_t dst, dma_addr_t src,\r\nsize_t len, unsigned long flags)\r\n{\r\nstruct st_fdma_chan *fchan;\r\nstruct st_fdma_desc *fdesc;\r\nstruct st_fdma_hw_node *hw_node;\r\nif (!len)\r\nreturn NULL;\r\nfchan = to_st_fdma_chan(chan);\r\nfdesc = st_fdma_alloc_desc(fchan, 1);\r\nif (!fdesc) {\r\ndev_err(fchan->fdev->dev, "no memory for desc\n");\r\nreturn NULL;\r\n}\r\nhw_node = fdesc->node[0].desc;\r\nhw_node->next = 0;\r\nhw_node->control = FDMA_NODE_CTRL_REQ_MAP_FREE_RUN;\r\nhw_node->control |= FDMA_NODE_CTRL_SRC_INCR;\r\nhw_node->control |= FDMA_NODE_CTRL_DST_INCR;\r\nhw_node->control |= FDMA_NODE_CTRL_INT_EON;\r\nhw_node->nbytes = len;\r\nhw_node->saddr = src;\r\nhw_node->daddr = dst;\r\nhw_node->generic.length = len;\r\nhw_node->generic.sstride = 0;\r\nhw_node->generic.dstride = 0;\r\nreturn vchan_tx_prep(&fchan->vchan, &fdesc->vdesc, flags);\r\n}\r\nstatic int config_reqctrl(struct st_fdma_chan *fchan,\r\nenum dma_transfer_direction direction)\r\n{\r\nu32 maxburst = 0, addr = 0;\r\nenum dma_slave_buswidth width;\r\nint ch_id = fchan->vchan.chan.chan_id;\r\nstruct st_fdma_dev *fdev = fchan->fdev;\r\nswitch (direction) {\r\ncase DMA_DEV_TO_MEM:\r\nfchan->cfg.req_ctrl &= ~FDMA_REQ_CTRL_WNR;\r\nmaxburst = fchan->scfg.src_maxburst;\r\nwidth = fchan->scfg.src_addr_width;\r\naddr = fchan->scfg.src_addr;\r\nbreak;\r\ncase DMA_MEM_TO_DEV:\r\nfchan->cfg.req_ctrl |= FDMA_REQ_CTRL_WNR;\r\nmaxburst = fchan->scfg.dst_maxburst;\r\nwidth = fchan->scfg.dst_addr_width;\r\naddr = fchan->scfg.dst_addr;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nfchan->cfg.req_ctrl &= ~FDMA_REQ_CTRL_OPCODE_MASK;\r\nswitch (width) {\r\ncase DMA_SLAVE_BUSWIDTH_1_BYTE:\r\nfchan->cfg.req_ctrl |= FDMA_REQ_CTRL_OPCODE_LD_ST1;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_2_BYTES:\r\nfchan->cfg.req_ctrl |= FDMA_REQ_CTRL_OPCODE_LD_ST2;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_4_BYTES:\r\nfchan->cfg.req_ctrl |= FDMA_REQ_CTRL_OPCODE_LD_ST4;\r\nbreak;\r\ncase DMA_SLAVE_BUSWIDTH_8_BYTES:\r\nfchan->cfg.req_ctrl |= FDMA_REQ_CTRL_OPCODE_LD_ST8;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nfchan->cfg.req_ctrl &= ~FDMA_REQ_CTRL_NUM_OPS_MASK;\r\nfchan->cfg.req_ctrl |= FDMA_REQ_CTRL_NUM_OPS(maxburst-1);\r\ndreq_write(fchan, fchan->cfg.req_ctrl, FDMA_REQ_CTRL_OFST);\r\nfchan->cfg.dev_addr = addr;\r\nfchan->cfg.dir = direction;\r\ndev_dbg(fdev->dev, "chan:%d config_reqctrl:%#x req_ctrl:%#lx\n",\r\nch_id, addr, fchan->cfg.req_ctrl);\r\nreturn 0;\r\n}\r\nstatic void fill_hw_node(struct st_fdma_hw_node *hw_node,\r\nstruct st_fdma_chan *fchan,\r\nenum dma_transfer_direction direction)\r\n{\r\nif (direction == DMA_MEM_TO_DEV) {\r\nhw_node->control |= FDMA_NODE_CTRL_SRC_INCR;\r\nhw_node->control |= FDMA_NODE_CTRL_DST_STATIC;\r\nhw_node->daddr = fchan->cfg.dev_addr;\r\n} else {\r\nhw_node->control |= FDMA_NODE_CTRL_SRC_STATIC;\r\nhw_node->control |= FDMA_NODE_CTRL_DST_INCR;\r\nhw_node->saddr = fchan->cfg.dev_addr;\r\n}\r\nhw_node->generic.sstride = 0;\r\nhw_node->generic.dstride = 0;\r\n}\r\nstatic inline struct st_fdma_chan *st_fdma_prep_common(struct dma_chan *chan,\r\nsize_t len, enum dma_transfer_direction direction)\r\n{\r\nstruct st_fdma_chan *fchan;\r\nif (!chan || !len)\r\nreturn NULL;\r\nfchan = to_st_fdma_chan(chan);\r\nif (!is_slave_direction(direction)) {\r\ndev_err(fchan->fdev->dev, "bad direction?\n");\r\nreturn NULL;\r\n}\r\nreturn fchan;\r\n}\r\nstatic struct dma_async_tx_descriptor *st_fdma_prep_dma_cyclic(\r\nstruct dma_chan *chan, dma_addr_t buf_addr, size_t len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags)\r\n{\r\nstruct st_fdma_chan *fchan;\r\nstruct st_fdma_desc *fdesc;\r\nint sg_len, i;\r\nfchan = st_fdma_prep_common(chan, len, direction);\r\nif (!fchan)\r\nreturn NULL;\r\nif (!period_len)\r\nreturn NULL;\r\nif (config_reqctrl(fchan, direction)) {\r\ndev_err(fchan->fdev->dev, "bad width or direction\n");\r\nreturn NULL;\r\n}\r\nif (len % period_len != 0) {\r\ndev_err(fchan->fdev->dev, "len is not multiple of period\n");\r\nreturn NULL;\r\n}\r\nsg_len = len / period_len;\r\nfdesc = st_fdma_alloc_desc(fchan, sg_len);\r\nif (!fdesc) {\r\ndev_err(fchan->fdev->dev, "no memory for desc\n");\r\nreturn NULL;\r\n}\r\nfdesc->iscyclic = true;\r\nfor (i = 0; i < sg_len; i++) {\r\nstruct st_fdma_hw_node *hw_node = fdesc->node[i].desc;\r\nhw_node->next = fdesc->node[(i + 1) % sg_len].pdesc;\r\nhw_node->control =\r\nFDMA_NODE_CTRL_REQ_MAP_DREQ(fchan->dreq_line);\r\nhw_node->control |= FDMA_NODE_CTRL_INT_EON;\r\nfill_hw_node(hw_node, fchan, direction);\r\nif (direction == DMA_MEM_TO_DEV)\r\nhw_node->saddr = buf_addr + (i * period_len);\r\nelse\r\nhw_node->daddr = buf_addr + (i * period_len);\r\nhw_node->nbytes = period_len;\r\nhw_node->generic.length = period_len;\r\n}\r\nreturn vchan_tx_prep(&fchan->vchan, &fdesc->vdesc, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *st_fdma_prep_slave_sg(\r\nstruct dma_chan *chan, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct st_fdma_chan *fchan;\r\nstruct st_fdma_desc *fdesc;\r\nstruct st_fdma_hw_node *hw_node;\r\nstruct scatterlist *sg;\r\nint i;\r\nfchan = st_fdma_prep_common(chan, sg_len, direction);\r\nif (!fchan)\r\nreturn NULL;\r\nif (!sgl)\r\nreturn NULL;\r\nfdesc = st_fdma_alloc_desc(fchan, sg_len);\r\nif (!fdesc) {\r\ndev_err(fchan->fdev->dev, "no memory for desc\n");\r\nreturn NULL;\r\n}\r\nfdesc->iscyclic = false;\r\nfor_each_sg(sgl, sg, sg_len, i) {\r\nhw_node = fdesc->node[i].desc;\r\nhw_node->next = fdesc->node[(i + 1) % sg_len].pdesc;\r\nhw_node->control = FDMA_NODE_CTRL_REQ_MAP_DREQ(fchan->dreq_line);\r\nfill_hw_node(hw_node, fchan, direction);\r\nif (direction == DMA_MEM_TO_DEV)\r\nhw_node->saddr = sg_dma_address(sg);\r\nelse\r\nhw_node->daddr = sg_dma_address(sg);\r\nhw_node->nbytes = sg_dma_len(sg);\r\nhw_node->generic.length = sg_dma_len(sg);\r\n}\r\nhw_node->control |= FDMA_NODE_CTRL_INT_EON;\r\nreturn vchan_tx_prep(&fchan->vchan, &fdesc->vdesc, flags);\r\n}\r\nstatic size_t st_fdma_desc_residue(struct st_fdma_chan *fchan,\r\nstruct virt_dma_desc *vdesc,\r\nbool in_progress)\r\n{\r\nstruct st_fdma_desc *fdesc = fchan->fdesc;\r\nsize_t residue = 0;\r\ndma_addr_t cur_addr = 0;\r\nint i;\r\nif (in_progress) {\r\ncur_addr = fchan_read(fchan, FDMA_CH_CMD_OFST);\r\ncur_addr &= FDMA_CH_CMD_DATA_MASK;\r\n}\r\nfor (i = fchan->fdesc->n_nodes - 1 ; i >= 0; i--) {\r\nif (cur_addr == fdesc->node[i].pdesc) {\r\nresidue += fnode_read(fchan, FDMA_CNTN_OFST);\r\nbreak;\r\n}\r\nresidue += fdesc->node[i].desc->nbytes;\r\n}\r\nreturn residue;\r\n}\r\nstatic enum dma_status st_fdma_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie,\r\nstruct dma_tx_state *txstate)\r\n{\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nstruct virt_dma_desc *vd;\r\nenum dma_status ret;\r\nunsigned long flags;\r\nret = dma_cookie_status(chan, cookie, txstate);\r\nif (ret == DMA_COMPLETE || !txstate)\r\nreturn ret;\r\nspin_lock_irqsave(&fchan->vchan.lock, flags);\r\nvd = vchan_find_desc(&fchan->vchan, cookie);\r\nif (fchan->fdesc && cookie == fchan->fdesc->vdesc.tx.cookie)\r\ntxstate->residue = st_fdma_desc_residue(fchan, vd, true);\r\nelse if (vd)\r\ntxstate->residue = st_fdma_desc_residue(fchan, vd, false);\r\nelse\r\ntxstate->residue = 0;\r\nspin_unlock_irqrestore(&fchan->vchan.lock, flags);\r\nreturn ret;\r\n}\r\nstatic void st_fdma_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&fchan->vchan.lock, flags);\r\nif (vchan_issue_pending(&fchan->vchan) && !fchan->fdesc)\r\nst_fdma_xfer_desc(fchan);\r\nspin_unlock_irqrestore(&fchan->vchan.lock, flags);\r\n}\r\nstatic int st_fdma_pause(struct dma_chan *chan)\r\n{\r\nunsigned long flags;\r\nLIST_HEAD(head);\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nint ch_id = fchan->vchan.chan.chan_id;\r\nunsigned long cmd = FDMA_CMD_PAUSE(ch_id);\r\ndev_dbg(fchan->fdev->dev, "pause chan:%d\n", ch_id);\r\nspin_lock_irqsave(&fchan->vchan.lock, flags);\r\nif (fchan->fdesc)\r\nfdma_write(fchan->fdev, cmd, FDMA_CMD_SET_OFST);\r\nspin_unlock_irqrestore(&fchan->vchan.lock, flags);\r\nreturn 0;\r\n}\r\nstatic int st_fdma_resume(struct dma_chan *chan)\r\n{\r\nunsigned long flags;\r\nunsigned long val;\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nint ch_id = fchan->vchan.chan.chan_id;\r\ndev_dbg(fchan->fdev->dev, "resume chan:%d\n", ch_id);\r\nspin_lock_irqsave(&fchan->vchan.lock, flags);\r\nif (fchan->fdesc) {\r\nval = fchan_read(fchan, FDMA_CH_CMD_OFST);\r\nval &= FDMA_CH_CMD_DATA_MASK;\r\nfchan_write(fchan, val, FDMA_CH_CMD_OFST);\r\n}\r\nspin_unlock_irqrestore(&fchan->vchan.lock, flags);\r\nreturn 0;\r\n}\r\nstatic int st_fdma_terminate_all(struct dma_chan *chan)\r\n{\r\nunsigned long flags;\r\nLIST_HEAD(head);\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nint ch_id = fchan->vchan.chan.chan_id;\r\nunsigned long cmd = FDMA_CMD_PAUSE(ch_id);\r\ndev_dbg(fchan->fdev->dev, "terminate chan:%d\n", ch_id);\r\nspin_lock_irqsave(&fchan->vchan.lock, flags);\r\nfdma_write(fchan->fdev, cmd, FDMA_CMD_SET_OFST);\r\nfchan->fdesc = NULL;\r\nvchan_get_all_descriptors(&fchan->vchan, &head);\r\nspin_unlock_irqrestore(&fchan->vchan.lock, flags);\r\nvchan_dma_desc_free_list(&fchan->vchan, &head);\r\nreturn 0;\r\n}\r\nstatic int st_fdma_slave_config(struct dma_chan *chan,\r\nstruct dma_slave_config *slave_cfg)\r\n{\r\nstruct st_fdma_chan *fchan = to_st_fdma_chan(chan);\r\nmemcpy(&fchan->scfg, slave_cfg, sizeof(fchan->scfg));\r\nreturn 0;\r\n}\r\nstatic int st_fdma_parse_dt(struct platform_device *pdev,\r\nconst struct st_fdma_driverdata *drvdata,\r\nstruct st_fdma_dev *fdev)\r\n{\r\nsnprintf(fdev->fw_name, FW_NAME_SIZE, "fdma_%s_%d.elf",\r\ndrvdata->name, drvdata->id);\r\nreturn of_property_read_u32(pdev->dev.of_node, "dma-channels",\r\n&fdev->nr_channels);\r\n}\r\nstatic void st_fdma_free(struct st_fdma_dev *fdev)\r\n{\r\nstruct st_fdma_chan *fchan;\r\nint i;\r\nfor (i = 0; i < fdev->nr_channels; i++) {\r\nfchan = &fdev->chans[i];\r\nlist_del(&fchan->vchan.chan.device_node);\r\ntasklet_kill(&fchan->vchan.task);\r\n}\r\n}\r\nstatic int st_fdma_probe(struct platform_device *pdev)\r\n{\r\nstruct st_fdma_dev *fdev;\r\nconst struct of_device_id *match;\r\nstruct device_node *np = pdev->dev.of_node;\r\nconst struct st_fdma_driverdata *drvdata;\r\nint ret, i;\r\nmatch = of_match_device((st_fdma_match), &pdev->dev);\r\nif (!match || !match->data) {\r\ndev_err(&pdev->dev, "No device match found\n");\r\nreturn -ENODEV;\r\n}\r\ndrvdata = match->data;\r\nfdev = devm_kzalloc(&pdev->dev, sizeof(*fdev), GFP_KERNEL);\r\nif (!fdev)\r\nreturn -ENOMEM;\r\nret = st_fdma_parse_dt(pdev, drvdata, fdev);\r\nif (ret) {\r\ndev_err(&pdev->dev, "unable to find platform data\n");\r\ngoto err;\r\n}\r\nfdev->chans = devm_kcalloc(&pdev->dev, fdev->nr_channels,\r\nsizeof(struct st_fdma_chan), GFP_KERNEL);\r\nif (!fdev->chans)\r\nreturn -ENOMEM;\r\nfdev->dev = &pdev->dev;\r\nfdev->drvdata = drvdata;\r\nplatform_set_drvdata(pdev, fdev);\r\nfdev->irq = platform_get_irq(pdev, 0);\r\nif (fdev->irq < 0) {\r\ndev_err(&pdev->dev, "Failed to get irq resource\n");\r\nreturn -EINVAL;\r\n}\r\nret = devm_request_irq(&pdev->dev, fdev->irq, st_fdma_irq_handler, 0,\r\ndev_name(&pdev->dev), fdev);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Failed to request irq (%d)\n", ret);\r\ngoto err;\r\n}\r\nfdev->slim_rproc = st_slim_rproc_alloc(pdev, fdev->fw_name);\r\nif (IS_ERR(fdev->slim_rproc)) {\r\nret = PTR_ERR(fdev->slim_rproc);\r\ndev_err(&pdev->dev, "slim_rproc_alloc failed (%d)\n", ret);\r\ngoto err;\r\n}\r\nINIT_LIST_HEAD(&fdev->dma_device.channels);\r\nfor (i = 0; i < fdev->nr_channels; i++) {\r\nstruct st_fdma_chan *fchan = &fdev->chans[i];\r\nfchan->fdev = fdev;\r\nfchan->vchan.desc_free = st_fdma_free_desc;\r\nvchan_init(&fchan->vchan, &fdev->dma_device);\r\n}\r\nfdev->dreq_mask = BIT(0) | BIT(31);\r\ndma_cap_set(DMA_SLAVE, fdev->dma_device.cap_mask);\r\ndma_cap_set(DMA_CYCLIC, fdev->dma_device.cap_mask);\r\ndma_cap_set(DMA_MEMCPY, fdev->dma_device.cap_mask);\r\nfdev->dma_device.dev = &pdev->dev;\r\nfdev->dma_device.device_alloc_chan_resources = st_fdma_alloc_chan_res;\r\nfdev->dma_device.device_free_chan_resources = st_fdma_free_chan_res;\r\nfdev->dma_device.device_prep_dma_cyclic = st_fdma_prep_dma_cyclic;\r\nfdev->dma_device.device_prep_slave_sg = st_fdma_prep_slave_sg;\r\nfdev->dma_device.device_prep_dma_memcpy = st_fdma_prep_dma_memcpy;\r\nfdev->dma_device.device_tx_status = st_fdma_tx_status;\r\nfdev->dma_device.device_issue_pending = st_fdma_issue_pending;\r\nfdev->dma_device.device_terminate_all = st_fdma_terminate_all;\r\nfdev->dma_device.device_config = st_fdma_slave_config;\r\nfdev->dma_device.device_pause = st_fdma_pause;\r\nfdev->dma_device.device_resume = st_fdma_resume;\r\nfdev->dma_device.src_addr_widths = FDMA_DMA_BUSWIDTHS;\r\nfdev->dma_device.dst_addr_widths = FDMA_DMA_BUSWIDTHS;\r\nfdev->dma_device.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\r\nfdev->dma_device.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\r\nret = dma_async_device_register(&fdev->dma_device);\r\nif (ret) {\r\ndev_err(&pdev->dev,\r\n"Failed to register DMA device (%d)\n", ret);\r\ngoto err_rproc;\r\n}\r\nret = of_dma_controller_register(np, st_fdma_of_xlate, fdev);\r\nif (ret) {\r\ndev_err(&pdev->dev,\r\n"Failed to register controller (%d)\n", ret);\r\ngoto err_dma_dev;\r\n}\r\ndev_info(&pdev->dev, "ST FDMA engine driver, irq:%d\n", fdev->irq);\r\nreturn 0;\r\nerr_dma_dev:\r\ndma_async_device_unregister(&fdev->dma_device);\r\nerr_rproc:\r\nst_fdma_free(fdev);\r\nst_slim_rproc_put(fdev->slim_rproc);\r\nerr:\r\nreturn ret;\r\n}\r\nstatic int st_fdma_remove(struct platform_device *pdev)\r\n{\r\nstruct st_fdma_dev *fdev = platform_get_drvdata(pdev);\r\ndevm_free_irq(&pdev->dev, fdev->irq, fdev);\r\nst_slim_rproc_put(fdev->slim_rproc);\r\nof_dma_controller_free(pdev->dev.of_node);\r\ndma_async_device_unregister(&fdev->dma_device);\r\nreturn 0;\r\n}
