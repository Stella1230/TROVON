static void blk_end_sync_rq(struct request *rq, blk_status_t error)\r\n{\r\nstruct completion *waiting = rq->end_io_data;\r\nrq->end_io_data = NULL;\r\ncomplete(waiting);\r\n}\r\nvoid blk_execute_rq_nowait(struct request_queue *q, struct gendisk *bd_disk,\r\nstruct request *rq, int at_head,\r\nrq_end_io_fn *done)\r\n{\r\nint where = at_head ? ELEVATOR_INSERT_FRONT : ELEVATOR_INSERT_BACK;\r\nWARN_ON(irqs_disabled());\r\nWARN_ON(!blk_rq_is_passthrough(rq));\r\nrq->rq_disk = bd_disk;\r\nrq->end_io = done;\r\nif (q->mq_ops) {\r\nblk_mq_sched_insert_request(rq, at_head, true, false, false);\r\nreturn;\r\n}\r\nspin_lock_irq(q->queue_lock);\r\nif (unlikely(blk_queue_dying(q))) {\r\nrq->rq_flags |= RQF_QUIET;\r\n__blk_end_request_all(rq, BLK_STS_IOERR);\r\nspin_unlock_irq(q->queue_lock);\r\nreturn;\r\n}\r\n__elv_add_request(q, rq, where);\r\n__blk_run_queue(q);\r\nspin_unlock_irq(q->queue_lock);\r\n}\r\nvoid blk_execute_rq(struct request_queue *q, struct gendisk *bd_disk,\r\nstruct request *rq, int at_head)\r\n{\r\nDECLARE_COMPLETION_ONSTACK(wait);\r\nunsigned long hang_check;\r\nrq->end_io_data = &wait;\r\nblk_execute_rq_nowait(q, bd_disk, rq, at_head, blk_end_sync_rq);\r\nhang_check = sysctl_hung_task_timeout_secs;\r\nif (hang_check)\r\nwhile (!wait_for_completion_io_timeout(&wait, hang_check * (HZ/2)));\r\nelse\r\nwait_for_completion_io(&wait);\r\n}
