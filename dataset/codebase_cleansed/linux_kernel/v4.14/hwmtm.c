u_int mac_drv_check_space(void)\r\n{\r\n#ifdef MB_OUTSIDE_SMC\r\n#ifdef COMMON_MB_POOL\r\ncall_count++ ;\r\nif (call_count == 1) {\r\nreturn EXT_VIRT_MEM;\r\n}\r\nelse {\r\nreturn EXT_VIRT_MEM_2;\r\n}\r\n#else\r\nreturn EXT_VIRT_MEM;\r\n#endif\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nint mac_drv_init(struct s_smc *smc)\r\n{\r\nif (sizeof(struct s_smt_fp_rxd) % 16) {\r\nSMT_PANIC(smc,HWM_E0001,HWM_E0001_MSG) ;\r\n}\r\nif (sizeof(struct s_smt_fp_txd) % 16) {\r\nSMT_PANIC(smc,HWM_E0002,HWM_E0002_MSG) ;\r\n}\r\nif (!(smc->os.hwm.descr_p = (union s_fp_descr volatile *)\r\nmac_drv_get_desc_mem(smc,(u_int)\r\n(RXD_TXD_COUNT+1)*sizeof(struct s_smt_fp_txd)))) {\r\nreturn 1;\r\n}\r\n#ifndef MB_OUTSIDE_SMC\r\nsmc->os.hwm.mbuf_pool.mb_start=(SMbuf *)(&smc->os.hwm.mbuf_pool.mb[0]) ;\r\n#else\r\n#ifndef COMMON_MB_POOL\r\nif (!(smc->os.hwm.mbuf_pool.mb_start = (SMbuf *) mac_drv_get_space(smc,\r\nMAX_MBUF*sizeof(SMbuf)))) {\r\nreturn 1;\r\n}\r\n#else\r\nif (!mb_start) {\r\nif (!(mb_start = (SMbuf *) mac_drv_get_space(smc,\r\nMAX_MBUF*sizeof(SMbuf)))) {\r\nreturn 1;\r\n}\r\n}\r\n#endif\r\n#endif\r\nreturn 0;\r\n}\r\nvoid init_driver_fplus(struct s_smc *smc)\r\n{\r\nsmc->hw.fp.mdr2init = FM_LSB | FM_BMMODE | FM_ENNPRQ | FM_ENHSRQ | 3 ;\r\n#ifdef PCI\r\nsmc->hw.fp.mdr2init |= FM_CHKPAR | FM_PARITY ;\r\n#endif\r\nsmc->hw.fp.mdr3init = FM_MENRQAUNLCK | FM_MENRS ;\r\n#ifdef USE_CAN_ADDR\r\nsmc->hw.fp.frselreg_init = FM_ENXMTADSWAP | FM_ENRCVADSWAP ;\r\n#endif\r\n}\r\nstatic u_long init_descr_ring(struct s_smc *smc,\r\nunion s_fp_descr volatile *start,\r\nint count)\r\n{\r\nint i ;\r\nunion s_fp_descr volatile *d1 ;\r\nunion s_fp_descr volatile *d2 ;\r\nu_long phys ;\r\nDB_GEN(3, "descr ring starts at = %p", start);\r\nfor (i=count-1, d1=start; i ; i--) {\r\nd2 = d1 ;\r\nd1++ ;\r\nd2->r.rxd_rbctrl = cpu_to_le32(BMU_CHECK) ;\r\nd2->r.rxd_next = &d1->r ;\r\nphys = mac_drv_virt2phys(smc,(void *)d1) ;\r\nd2->r.rxd_nrdadr = cpu_to_le32(phys) ;\r\n}\r\nDB_GEN(3, "descr ring ends at = %p", d1);\r\nd1->r.rxd_rbctrl = cpu_to_le32(BMU_CHECK) ;\r\nd1->r.rxd_next = &start->r ;\r\nphys = mac_drv_virt2phys(smc,(void *)start) ;\r\nd1->r.rxd_nrdadr = cpu_to_le32(phys) ;\r\nfor (i=count, d1=start; i ; i--) {\r\nDRV_BUF_FLUSH(&d1->r,DDI_DMA_SYNC_FORDEV) ;\r\nd1++;\r\n}\r\nreturn phys;\r\n}\r\nstatic void init_txd_ring(struct s_smc *smc)\r\n{\r\nstruct s_smt_fp_txd volatile *ds ;\r\nstruct s_smt_tx_queue *queue ;\r\nu_long phys ;\r\nds = (struct s_smt_fp_txd volatile *) ((char *)smc->os.hwm.descr_p +\r\nSMT_R1_RXD_COUNT*sizeof(struct s_smt_fp_rxd)) ;\r\nqueue = smc->hw.fp.tx[QUEUE_A0] ;\r\nDB_GEN(3, "Init async TxD ring, %d TxDs", HWM_ASYNC_TXD_COUNT);\r\n(void)init_descr_ring(smc,(union s_fp_descr volatile *)ds,\r\nHWM_ASYNC_TXD_COUNT) ;\r\nphys = le32_to_cpu(ds->txd_ntdadr) ;\r\nds++ ;\r\nqueue->tx_curr_put = queue->tx_curr_get = ds ;\r\nds-- ;\r\nqueue->tx_free = HWM_ASYNC_TXD_COUNT ;\r\nqueue->tx_used = 0 ;\r\noutpd(ADDR(B5_XA_DA),phys) ;\r\nds = (struct s_smt_fp_txd volatile *) ((char *)ds +\r\nHWM_ASYNC_TXD_COUNT*sizeof(struct s_smt_fp_txd)) ;\r\nqueue = smc->hw.fp.tx[QUEUE_S] ;\r\nDB_GEN(3, "Init sync TxD ring, %d TxDs", HWM_SYNC_TXD_COUNT);\r\n(void)init_descr_ring(smc,(union s_fp_descr volatile *)ds,\r\nHWM_SYNC_TXD_COUNT) ;\r\nphys = le32_to_cpu(ds->txd_ntdadr) ;\r\nds++ ;\r\nqueue->tx_curr_put = queue->tx_curr_get = ds ;\r\nqueue->tx_free = HWM_SYNC_TXD_COUNT ;\r\nqueue->tx_used = 0 ;\r\noutpd(ADDR(B5_XS_DA),phys) ;\r\n}\r\nstatic void init_rxd_ring(struct s_smc *smc)\r\n{\r\nstruct s_smt_fp_rxd volatile *ds ;\r\nstruct s_smt_rx_queue *queue ;\r\nu_long phys ;\r\nds = (struct s_smt_fp_rxd volatile *) smc->os.hwm.descr_p ;\r\nqueue = smc->hw.fp.rx[QUEUE_R1] ;\r\nDB_GEN(3, "Init RxD ring, %d RxDs", SMT_R1_RXD_COUNT);\r\n(void)init_descr_ring(smc,(union s_fp_descr volatile *)ds,\r\nSMT_R1_RXD_COUNT) ;\r\nphys = le32_to_cpu(ds->rxd_nrdadr) ;\r\nds++ ;\r\nqueue->rx_curr_put = queue->rx_curr_get = ds ;\r\nqueue->rx_free = SMT_R1_RXD_COUNT ;\r\nqueue->rx_used = 0 ;\r\noutpd(ADDR(B4_R1_DA),phys) ;\r\n}\r\nvoid init_fddi_driver(struct s_smc *smc, u_char *mac_addr)\r\n{\r\nSMbuf *mb ;\r\nint i ;\r\ninit_board(smc,mac_addr) ;\r\n(void)init_fplus(smc) ;\r\n#ifndef COMMON_MB_POOL\r\nmb = smc->os.hwm.mbuf_pool.mb_start ;\r\nsmc->os.hwm.mbuf_pool.mb_free = (SMbuf *)NULL ;\r\nfor (i = 0; i < MAX_MBUF; i++) {\r\nmb->sm_use_count = 1 ;\r\nsmt_free_mbuf(smc,mb) ;\r\nmb++ ;\r\n}\r\n#else\r\nmb = mb_start ;\r\nif (!mb_init) {\r\nmb_free = 0 ;\r\nfor (i = 0; i < MAX_MBUF; i++) {\r\nmb->sm_use_count = 1 ;\r\nsmt_free_mbuf(smc,mb) ;\r\nmb++ ;\r\n}\r\nmb_init = TRUE ;\r\n}\r\n#endif\r\nsmc->os.hwm.llc_rx_pipe = smc->os.hwm.llc_rx_tail = (SMbuf *)NULL ;\r\nsmc->os.hwm.txd_tx_pipe = smc->os.hwm.txd_tx_tail = NULL ;\r\nsmc->os.hwm.pass_SMT = smc->os.hwm.pass_NSA = smc->os.hwm.pass_DB = 0 ;\r\nsmc->os.hwm.pass_llc_promisc = TRUE ;\r\nsmc->os.hwm.queued_rx_frames = smc->os.hwm.queued_txd_mb = 0 ;\r\nsmc->os.hwm.detec_count = 0 ;\r\nsmc->os.hwm.rx_break = 0 ;\r\nsmc->os.hwm.rx_len_error = 0 ;\r\nsmc->os.hwm.isr_flag = FALSE ;\r\ni = 16 - ((long)smc->os.hwm.descr_p & 0xf) ;\r\nif (i != 16) {\r\nDB_GEN(3, "i = %d", i);\r\nsmc->os.hwm.descr_p = (union s_fp_descr volatile *)\r\n((char *)smc->os.hwm.descr_p+i) ;\r\n}\r\nDB_GEN(3, "pt to descr area = %p", smc->os.hwm.descr_p);\r\ninit_txd_ring(smc) ;\r\ninit_rxd_ring(smc) ;\r\nmac_drv_fill_rxd(smc) ;\r\ninit_plc(smc) ;\r\n}\r\nSMbuf *smt_get_mbuf(struct s_smc *smc)\r\n{\r\nregister SMbuf *mb ;\r\n#ifndef COMMON_MB_POOL\r\nmb = smc->os.hwm.mbuf_pool.mb_free ;\r\n#else\r\nmb = mb_free ;\r\n#endif\r\nif (mb) {\r\n#ifndef COMMON_MB_POOL\r\nsmc->os.hwm.mbuf_pool.mb_free = mb->sm_next ;\r\n#else\r\nmb_free = mb->sm_next ;\r\n#endif\r\nmb->sm_off = 8 ;\r\nmb->sm_use_count = 1 ;\r\n}\r\nDB_GEN(3, "get SMbuf: mb = %p", mb);\r\nreturn mb;\r\n}\r\nvoid smt_free_mbuf(struct s_smc *smc, SMbuf *mb)\r\n{\r\nif (mb) {\r\nmb->sm_use_count-- ;\r\nDB_GEN(3, "free_mbuf: sm_use_count = %d", mb->sm_use_count);\r\nif (!mb->sm_use_count) {\r\nDB_GEN(3, "free SMbuf: mb = %p", mb);\r\n#ifndef COMMON_MB_POOL\r\nmb->sm_next = smc->os.hwm.mbuf_pool.mb_free ;\r\nsmc->os.hwm.mbuf_pool.mb_free = mb ;\r\n#else\r\nmb->sm_next = mb_free ;\r\nmb_free = mb ;\r\n#endif\r\n}\r\n}\r\nelse\r\nSMT_PANIC(smc,HWM_E0003,HWM_E0003_MSG) ;\r\n}\r\nvoid mac_drv_repair_descr(struct s_smc *smc)\r\n{\r\nu_long phys ;\r\nif (smc->hw.hw_state != STOPPED) {\r\nSK_BREAK() ;\r\nSMT_PANIC(smc,HWM_E0013,HWM_E0013_MSG) ;\r\nreturn ;\r\n}\r\nphys = repair_txd_ring(smc,smc->hw.fp.tx[QUEUE_A0]) ;\r\noutpd(ADDR(B5_XA_DA),phys) ;\r\nif (smc->hw.fp.tx_q[QUEUE_A0].tx_used) {\r\noutpd(ADDR(B0_XA_CSR),CSR_START) ;\r\n}\r\nphys = repair_txd_ring(smc,smc->hw.fp.tx[QUEUE_S]) ;\r\noutpd(ADDR(B5_XS_DA),phys) ;\r\nif (smc->hw.fp.tx_q[QUEUE_S].tx_used) {\r\noutpd(ADDR(B0_XS_CSR),CSR_START) ;\r\n}\r\nphys = repair_rxd_ring(smc,smc->hw.fp.rx[QUEUE_R1]) ;\r\noutpd(ADDR(B4_R1_DA),phys) ;\r\noutpd(ADDR(B0_R1_CSR),CSR_START) ;\r\n}\r\nstatic u_long repair_txd_ring(struct s_smc *smc, struct s_smt_tx_queue *queue)\r\n{\r\nint i ;\r\nint tx_used ;\r\nu_long phys ;\r\nu_long tbctrl ;\r\nstruct s_smt_fp_txd volatile *t ;\r\nSK_UNUSED(smc) ;\r\nt = queue->tx_curr_get ;\r\ntx_used = queue->tx_used ;\r\nfor (i = tx_used+queue->tx_free-1 ; i ; i-- ) {\r\nt = t->txd_next ;\r\n}\r\nphys = le32_to_cpu(t->txd_ntdadr) ;\r\nt = queue->tx_curr_get ;\r\nwhile (tx_used) {\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORCPU) ;\r\ntbctrl = le32_to_cpu(t->txd_tbctrl) ;\r\nif (tbctrl & BMU_OWN) {\r\nif (tbctrl & BMU_STF) {\r\nbreak ;\r\n}\r\nelse {\r\nt->txd_tbctrl &= ~cpu_to_le32(BMU_OWN) ;\r\n}\r\n}\r\nphys = le32_to_cpu(t->txd_ntdadr) ;\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\r\nt = t->txd_next ;\r\ntx_used-- ;\r\n}\r\nreturn phys;\r\n}\r\nstatic u_long repair_rxd_ring(struct s_smc *smc, struct s_smt_rx_queue *queue)\r\n{\r\nint i ;\r\nint rx_used ;\r\nu_long phys ;\r\nu_long rbctrl ;\r\nstruct s_smt_fp_rxd volatile *r ;\r\nSK_UNUSED(smc) ;\r\nr = queue->rx_curr_get ;\r\nrx_used = queue->rx_used ;\r\nfor (i = SMT_R1_RXD_COUNT-1 ; i ; i-- ) {\r\nr = r->rxd_next ;\r\n}\r\nphys = le32_to_cpu(r->rxd_nrdadr) ;\r\nr = queue->rx_curr_get ;\r\nwhile (rx_used) {\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\r\nrbctrl = le32_to_cpu(r->rxd_rbctrl) ;\r\nif (rbctrl & BMU_OWN) {\r\nif (rbctrl & BMU_STF) {\r\nbreak ;\r\n}\r\nelse {\r\nr->rxd_rbctrl &= ~cpu_to_le32(BMU_OWN) ;\r\n}\r\n}\r\nphys = le32_to_cpu(r->rxd_nrdadr) ;\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\r\nr = r->rxd_next ;\r\nrx_used-- ;\r\n}\r\nreturn phys;\r\n}\r\nvoid fddi_isr(struct s_smc *smc)\r\n{\r\nu_long is ;\r\nu_short stu, stl ;\r\nSMbuf *mb ;\r\n#ifdef USE_BREAK_ISR\r\nint force_irq ;\r\n#endif\r\n#ifdef ODI2\r\nif (smc->os.hwm.rx_break) {\r\nmac_drv_fill_rxd(smc) ;\r\nif (smc->hw.fp.rx_q[QUEUE_R1].rx_used > 0) {\r\nsmc->os.hwm.rx_break = 0 ;\r\nprocess_receive(smc) ;\r\n}\r\nelse {\r\nsmc->os.hwm.detec_count = 0 ;\r\nsmt_force_irq(smc) ;\r\n}\r\n}\r\n#endif\r\nsmc->os.hwm.isr_flag = TRUE ;\r\n#ifdef USE_BREAK_ISR\r\nforce_irq = TRUE ;\r\nif (smc->os.hwm.leave_isr) {\r\nsmc->os.hwm.leave_isr = FALSE ;\r\nprocess_receive(smc) ;\r\n}\r\n#endif\r\nwhile ((is = GET_ISR() & ISR_MASK)) {\r\nNDD_TRACE("CH0B",is,0,0) ;\r\nDB_GEN(7, "ISA = 0x%lx", is);\r\nif (is & IMASK_SLOW) {\r\nNDD_TRACE("CH1b",is,0,0) ;\r\nif (is & IS_PLINT1) {\r\nplc1_irq(smc) ;\r\n}\r\nif (is & IS_PLINT2) {\r\nplc2_irq(smc) ;\r\n}\r\nif (is & IS_MINTR1) {\r\nstu = inpw(FM_A(FM_ST1U)) ;\r\nstl = inpw(FM_A(FM_ST1L)) ;\r\nDB_GEN(6, "Slow transmit complete");\r\nmac1_irq(smc,stu,stl) ;\r\n}\r\nif (is & IS_MINTR2) {\r\nstu= inpw(FM_A(FM_ST2U)) ;\r\nstl= inpw(FM_A(FM_ST2L)) ;\r\nDB_GEN(6, "Slow receive complete");\r\nDB_GEN(7, "stl = %x : stu = %x", stl, stu);\r\nmac2_irq(smc,stu,stl) ;\r\n}\r\nif (is & IS_MINTR3) {\r\nstu= inpw(FM_A(FM_ST3U)) ;\r\nstl= inpw(FM_A(FM_ST3L)) ;\r\nDB_GEN(6, "FORMAC Mode Register 3");\r\nmac3_irq(smc,stu,stl) ;\r\n}\r\nif (is & IS_TIMINT) {\r\ntimer_irq(smc) ;\r\n#ifdef NDIS_OS2\r\nforce_irq_pending = 0 ;\r\n#endif\r\nif (++smc->os.hwm.detec_count > 4) {\r\nprocess_receive(smc) ;\r\n}\r\n}\r\nif (is & IS_TOKEN) {\r\nrtm_irq(smc) ;\r\n}\r\nif (is & IS_R1_P) {\r\noutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_P) ;\r\nSMT_PANIC(smc,HWM_E0004,HWM_E0004_MSG) ;\r\n}\r\nif (is & IS_R1_C) {\r\noutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_C) ;\r\nSMT_PANIC(smc,HWM_E0005,HWM_E0005_MSG) ;\r\n}\r\nif (is & IS_XA_C) {\r\noutpd(ADDR(B5_XA_CSR),CSR_IRQ_CL_C) ;\r\nSMT_PANIC(smc,HWM_E0006,HWM_E0006_MSG) ;\r\n}\r\nif (is & IS_XS_C) {\r\noutpd(ADDR(B5_XS_CSR),CSR_IRQ_CL_C) ;\r\nSMT_PANIC(smc,HWM_E0007,HWM_E0007_MSG) ;\r\n}\r\n}\r\nif (is & (IS_XS_F|IS_XA_F)) {\r\nDB_GEN(6, "Fast tx complete queue");\r\noutpd(ADDR(B5_XS_CSR),CSR_IRQ_CL_F) ;\r\noutpd(ADDR(B5_XA_CSR),CSR_IRQ_CL_F) ;\r\nmac_drv_clear_txd(smc) ;\r\nllc_restart_tx(smc) ;\r\n}\r\nif (is & IS_R1_F) {\r\nDB_GEN(6, "Fast receive complete");\r\n#ifndef USE_BREAK_ISR\r\noutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_F) ;\r\nprocess_receive(smc) ;\r\n#else\r\nprocess_receive(smc) ;\r\nif (smc->os.hwm.leave_isr) {\r\nforce_irq = FALSE ;\r\n} else {\r\noutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_F) ;\r\nprocess_receive(smc) ;\r\n}\r\n#endif\r\n}\r\n#ifndef NDIS_OS2\r\nwhile ((mb = get_llc_rx(smc))) {\r\nsmt_to_llc(smc,mb) ;\r\n}\r\n#else\r\nif (offDepth)\r\npost_proc() ;\r\nwhile (!offDepth && (mb = get_llc_rx(smc))) {\r\nsmt_to_llc(smc,mb) ;\r\n}\r\nif (!offDepth && smc->os.hwm.rx_break) {\r\nprocess_receive(smc) ;\r\n}\r\n#endif\r\nif (smc->q.ev_get != smc->q.ev_put) {\r\nNDD_TRACE("CH2a",0,0,0) ;\r\nev_dispatcher(smc) ;\r\n}\r\n#ifdef NDIS_OS2\r\npost_proc() ;\r\nif (offDepth) {\r\nbreak ;\r\n}\r\n#endif\r\n#ifdef USE_BREAK_ISR\r\nif (smc->os.hwm.leave_isr) {\r\nbreak ;\r\n}\r\n#endif\r\n}\r\n#ifdef USE_BREAK_ISR\r\nif (smc->os.hwm.leave_isr && force_irq) {\r\nsmt_force_irq(smc) ;\r\n}\r\n#endif\r\nsmc->os.hwm.isr_flag = FALSE ;\r\nNDD_TRACE("CH0E",0,0,0) ;\r\n}\r\nvoid mac_drv_rx_mode(struct s_smc *smc, int mode)\r\n{\r\nswitch(mode) {\r\ncase RX_ENABLE_PASS_SMT:\r\nsmc->os.hwm.pass_SMT = TRUE ;\r\nbreak ;\r\ncase RX_DISABLE_PASS_SMT:\r\nsmc->os.hwm.pass_SMT = FALSE ;\r\nbreak ;\r\ncase RX_ENABLE_PASS_NSA:\r\nsmc->os.hwm.pass_NSA = TRUE ;\r\nbreak ;\r\ncase RX_DISABLE_PASS_NSA:\r\nsmc->os.hwm.pass_NSA = FALSE ;\r\nbreak ;\r\ncase RX_ENABLE_PASS_DB:\r\nsmc->os.hwm.pass_DB = TRUE ;\r\nbreak ;\r\ncase RX_DISABLE_PASS_DB:\r\nsmc->os.hwm.pass_DB = FALSE ;\r\nbreak ;\r\ncase RX_DISABLE_PASS_ALL:\r\nsmc->os.hwm.pass_SMT = smc->os.hwm.pass_NSA = FALSE ;\r\nsmc->os.hwm.pass_DB = FALSE ;\r\nsmc->os.hwm.pass_llc_promisc = TRUE ;\r\nmac_set_rx_mode(smc,RX_DISABLE_NSA) ;\r\nbreak ;\r\ncase RX_DISABLE_LLC_PROMISC:\r\nsmc->os.hwm.pass_llc_promisc = FALSE ;\r\nbreak ;\r\ncase RX_ENABLE_LLC_PROMISC:\r\nsmc->os.hwm.pass_llc_promisc = TRUE ;\r\nbreak ;\r\ncase RX_ENABLE_ALLMULTI:\r\ncase RX_DISABLE_ALLMULTI:\r\ncase RX_ENABLE_PROMISC:\r\ncase RX_DISABLE_PROMISC:\r\ncase RX_ENABLE_NSA:\r\ncase RX_DISABLE_NSA:\r\ndefault:\r\nmac_set_rx_mode(smc,mode) ;\r\nbreak ;\r\n}\r\n}\r\nvoid process_receive(struct s_smc *smc)\r\n{\r\nint i ;\r\nint n ;\r\nint frag_count ;\r\nint used_frags ;\r\nstruct s_smt_rx_queue *queue ;\r\nstruct s_smt_fp_rxd volatile *r ;\r\nstruct s_smt_fp_rxd volatile *rxd ;\r\nu_long rbctrl ;\r\nu_long rfsw ;\r\nu_short rx_used ;\r\nu_char far *virt ;\r\nchar far *data ;\r\nSMbuf *mb ;\r\nu_char fc ;\r\nint len ;\r\nsmc->os.hwm.detec_count = 0 ;\r\nqueue = smc->hw.fp.rx[QUEUE_R1] ;\r\nNDD_TRACE("RHxB",0,0,0) ;\r\nfor ( ; ; ) {\r\nr = queue->rx_curr_get ;\r\nrx_used = queue->rx_used ;\r\nfrag_count = 0 ;\r\n#ifdef USE_BREAK_ISR\r\nif (smc->os.hwm.leave_isr) {\r\ngoto rx_end ;\r\n}\r\n#endif\r\n#ifdef NDIS_OS2\r\nif (offDepth) {\r\nsmc->os.hwm.rx_break = 1 ;\r\ngoto rx_end ;\r\n}\r\nsmc->os.hwm.rx_break = 0 ;\r\n#endif\r\n#ifdef ODI2\r\nif (smc->os.hwm.rx_break) {\r\ngoto rx_end ;\r\n}\r\n#endif\r\nn = 0 ;\r\ndo {\r\nDB_RX(5, "Check RxD %p for OWN and EOF", r);\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\r\nrbctrl = le32_to_cpu(CR_READ(r->rxd_rbctrl));\r\nif (rbctrl & BMU_OWN) {\r\nNDD_TRACE("RHxE",r,rfsw,rbctrl) ;\r\nDB_RX(4, "End of RxDs");\r\ngoto rx_end ;\r\n}\r\nif (!rx_used) {\r\nSK_BREAK() ;\r\nSMT_PANIC(smc,HWM_E0009,HWM_E0009_MSG) ;\r\nsmc->hw.hw_state = STOPPED ;\r\nmac_drv_clear_rx_queue(smc) ;\r\nsmc->hw.hw_state = STARTED ;\r\nmac_drv_fill_rxd(smc) ;\r\nsmc->os.hwm.detec_count = 0 ;\r\ngoto rx_end ;\r\n}\r\nrfsw = le32_to_cpu(r->rxd_rfsw) ;\r\nif ((rbctrl & BMU_STF) != ((rbctrl & BMU_ST_BUF) <<5)) {\r\nSK_BREAK() ;\r\nrfsw = 0 ;\r\nif (frag_count) {\r\nbreak ;\r\n}\r\n}\r\nn += rbctrl & 0xffff ;\r\nr = r->rxd_next ;\r\nfrag_count++ ;\r\nrx_used-- ;\r\n} while (!(rbctrl & BMU_EOF)) ;\r\nused_frags = frag_count ;\r\nDB_RX(5, "EOF set in RxD, used_frags = %d", used_frags);\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\r\nwhile (rx_used && !(r->rxd_rbctrl & cpu_to_le32(BMU_ST_BUF))) {\r\nDB_RX(5, "Check STF bit in %p", r);\r\nr = r->rxd_next ;\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\r\nfrag_count++ ;\r\nrx_used-- ;\r\n}\r\nDB_RX(5, "STF bit found");\r\nrxd = queue->rx_curr_get ;\r\nqueue->rx_curr_get = r ;\r\nqueue->rx_free += frag_count ;\r\nqueue->rx_used = rx_used ;\r\nrxd->rxd_rbctrl &= cpu_to_le32(~BMU_STF) ;\r\nfor (r=rxd, i=frag_count ; i ; r=r->rxd_next, i--){\r\nDB_RX(5, "dma_complete for RxD %p", r);\r\ndma_complete(smc,(union s_fp_descr volatile *)r,DMA_WR);\r\n}\r\nsmc->hw.fp.err_stats.err_valid++ ;\r\nsmc->mib.m[MAC0].fddiMACCopied_Ct++ ;\r\nlen = (rfsw & RD_LENGTH) - 4 ;\r\nDB_RX(4, "frame length = %d", len);\r\nif (rfsw & (RX_MSRABT|RX_FS_E|RX_FS_CRC|RX_FS_IMPL)){\r\nif (rfsw & RD_S_MSRABT) {\r\nDB_RX(2, "Frame aborted by the FORMAC");\r\nsmc->hw.fp.err_stats.err_abort++ ;\r\n}\r\nif (rfsw & RD_S_SEAC2) {\r\nDB_RX(2, "E-Indicator set");\r\nsmc->hw.fp.err_stats.err_e_indicator++ ;\r\n}\r\nif (rfsw & RD_S_SFRMERR) {\r\nDB_RX(2, "CRC error");\r\nsmc->hw.fp.err_stats.err_crc++ ;\r\n}\r\nif (rfsw & RX_FS_IMPL) {\r\nDB_RX(2, "Implementer frame");\r\nsmc->hw.fp.err_stats.err_imp_frame++ ;\r\n}\r\ngoto abort_frame ;\r\n}\r\nif (len > FDDI_RAW_MTU-4) {\r\nDB_RX(2, "Frame too long error");\r\nsmc->hw.fp.err_stats.err_too_long++ ;\r\ngoto abort_frame ;\r\n}\r\nif (len <= 4) {\r\nDB_RX(2, "Frame length = 0");\r\ngoto abort_frame ;\r\n}\r\nif (len != (n-4)) {\r\nDB_RX(4, "BMU: rx len differs: [%d:%d]", len, n);\r\nsmc->os.hwm.rx_len_error++ ;\r\ngoto abort_frame ;\r\n}\r\nvirt = (u_char far *) rxd->rxd_virt ;\r\nDB_RX(2, "FC = %x", *virt);\r\nif (virt[12] == MA[5] &&\r\nvirt[11] == MA[4] &&\r\nvirt[10] == MA[3] &&\r\nvirt[9] == MA[2] &&\r\nvirt[8] == MA[1] &&\r\n(virt[7] & ~GROUP_ADDR_BIT) == MA[0]) {\r\ngoto abort_frame ;\r\n}\r\nif (rfsw & RX_FS_LLC) {\r\nif (!smc->os.hwm.pass_llc_promisc) {\r\nif(!(virt[1] & GROUP_ADDR_BIT)) {\r\nif (virt[6] != MA[5] ||\r\nvirt[5] != MA[4] ||\r\nvirt[4] != MA[3] ||\r\nvirt[3] != MA[2] ||\r\nvirt[2] != MA[1] ||\r\nvirt[1] != MA[0]) {\r\nDB_RX(2, "DA != MA and not multi- or broadcast");\r\ngoto abort_frame ;\r\n}\r\n}\r\n}\r\nDB_RX(4, "LLC - receive");\r\nmac_drv_rx_complete(smc,rxd,frag_count,len) ;\r\n}\r\nelse {\r\nif (!(mb = smt_get_mbuf(smc))) {\r\nsmc->hw.fp.err_stats.err_no_buf++ ;\r\nDB_RX(4, "No SMbuf; receive terminated");\r\ngoto abort_frame ;\r\n}\r\ndata = smtod(mb,char *) - 1 ;\r\n#ifdef USE_OS_CPY\r\nhwm_cpy_rxd2mb(rxd,data,len) ;\r\n#else\r\nfor (r=rxd, i=used_frags ; i ; r=r->rxd_next, i--){\r\nn = le32_to_cpu(r->rxd_rbctrl) & RD_LENGTH ;\r\nDB_RX(6, "cp SMT frame to mb: len = %d", n);\r\nmemcpy(data,r->rxd_virt,n) ;\r\ndata += n ;\r\n}\r\ndata = smtod(mb,char *) - 1 ;\r\n#endif\r\nfc = *(char *)mb->sm_data = *data ;\r\nmb->sm_len = len - 1 ;\r\ndata++ ;\r\nswitch(fc) {\r\ncase FC_SMT_INFO :\r\nsmc->hw.fp.err_stats.err_smt_frame++ ;\r\nDB_RX(5, "SMT frame received");\r\nif (smc->os.hwm.pass_SMT) {\r\nDB_RX(5, "pass SMT frame");\r\nmac_drv_rx_complete(smc, rxd,\r\nfrag_count,len) ;\r\n}\r\nelse {\r\nDB_RX(5, "requeue RxD");\r\nmac_drv_requeue_rxd(smc,rxd,frag_count);\r\n}\r\nsmt_received_pack(smc,mb,(int)(rfsw>>25)) ;\r\nbreak ;\r\ncase FC_SMT_NSA :\r\nsmc->hw.fp.err_stats.err_smt_frame++ ;\r\nDB_RX(5, "SMT frame received");\r\nif (smc->os.hwm.pass_NSA ||\r\n(smc->os.hwm.pass_SMT &&\r\n!(rfsw & A_INDIC))) {\r\nDB_RX(5, "pass SMT frame");\r\nmac_drv_rx_complete(smc, rxd,\r\nfrag_count,len) ;\r\n}\r\nelse {\r\nDB_RX(5, "requeue RxD");\r\nmac_drv_requeue_rxd(smc,rxd,frag_count);\r\n}\r\nsmt_received_pack(smc,mb,(int)(rfsw>>25)) ;\r\nbreak ;\r\ncase FC_BEACON :\r\nif (smc->os.hwm.pass_DB) {\r\nDB_RX(5, "pass DB frame");\r\nmac_drv_rx_complete(smc, rxd,\r\nfrag_count,len) ;\r\n}\r\nelse {\r\nDB_RX(5, "requeue RxD");\r\nmac_drv_requeue_rxd(smc,rxd,frag_count);\r\n}\r\nsmt_free_mbuf(smc,mb) ;\r\nbreak ;\r\ndefault :\r\nDB_RX(2, "unknown FC error");\r\nsmt_free_mbuf(smc,mb) ;\r\nDB_RX(5, "requeue RxD");\r\nmac_drv_requeue_rxd(smc,rxd,frag_count) ;\r\nif ((fc & 0xf0) == FC_MAC)\r\nsmc->hw.fp.err_stats.err_mac_frame++ ;\r\nelse\r\nsmc->hw.fp.err_stats.err_imp_frame++ ;\r\nbreak ;\r\n}\r\n}\r\nDB_RX(3, "next RxD is %p", queue->rx_curr_get);\r\nNDD_TRACE("RHx1",queue->rx_curr_get,0,0) ;\r\ncontinue ;\r\nabort_frame:\r\nDB_RX(5, "requeue RxD");\r\nmac_drv_requeue_rxd(smc,rxd,frag_count) ;\r\nDB_RX(3, "next RxD is %p", queue->rx_curr_get);\r\nNDD_TRACE("RHx2",queue->rx_curr_get,0,0) ;\r\n}\r\nrx_end:\r\n#ifdef ALL_RX_COMPLETE\r\nmac_drv_all_receives_complete(smc) ;\r\n#endif\r\nreturn ;\r\n}\r\nstatic void smt_to_llc(struct s_smc *smc, SMbuf *mb)\r\n{\r\nu_char fc ;\r\nDB_RX(4, "send a queued frame to the llc layer");\r\nsmc->os.hwm.r.len = mb->sm_len ;\r\nsmc->os.hwm.r.mb_pos = smtod(mb,char *) ;\r\nfc = *smc->os.hwm.r.mb_pos ;\r\n(void)mac_drv_rx_init(smc,(int)mb->sm_len,(int)fc,\r\nsmc->os.hwm.r.mb_pos,(int)mb->sm_len) ;\r\nsmt_free_mbuf(smc,mb) ;\r\n}\r\nvoid hwm_rx_frag(struct s_smc *smc, char far *virt, u_long phys, int len,\r\nint frame_status)\r\n{\r\nstruct s_smt_fp_rxd volatile *r ;\r\n__le32 rbctrl;\r\nNDD_TRACE("RHfB",virt,len,frame_status) ;\r\nDB_RX(2, "hwm_rx_frag: len = %d, frame_status = %x", len, frame_status);\r\nr = smc->hw.fp.rx_q[QUEUE_R1].rx_curr_put ;\r\nr->rxd_virt = virt ;\r\nr->rxd_rbadr = cpu_to_le32(phys) ;\r\nrbctrl = cpu_to_le32( (((__u32)frame_status &\r\n(FIRST_FRAG|LAST_FRAG))<<26) |\r\n(((u_long) frame_status & FIRST_FRAG) << 21) |\r\nBMU_OWN | BMU_CHECK | BMU_EN_IRQ_EOF | len) ;\r\nr->rxd_rbctrl = rbctrl ;\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\r\noutpd(ADDR(B0_R1_CSR),CSR_START) ;\r\nsmc->hw.fp.rx_q[QUEUE_R1].rx_free-- ;\r\nsmc->hw.fp.rx_q[QUEUE_R1].rx_used++ ;\r\nsmc->hw.fp.rx_q[QUEUE_R1].rx_curr_put = r->rxd_next ;\r\nNDD_TRACE("RHfE",r,le32_to_cpu(r->rxd_rbadr),0) ;\r\n}\r\nvoid mac_drv_clear_rx_queue(struct s_smc *smc)\r\n{\r\nstruct s_smt_fp_rxd volatile *r ;\r\nstruct s_smt_fp_rxd volatile *next_rxd ;\r\nstruct s_smt_rx_queue *queue ;\r\nint frag_count ;\r\nint i ;\r\nif (smc->hw.hw_state != STOPPED) {\r\nSK_BREAK() ;\r\nSMT_PANIC(smc,HWM_E0012,HWM_E0012_MSG) ;\r\nreturn ;\r\n}\r\nqueue = smc->hw.fp.rx[QUEUE_R1] ;\r\nDB_RX(5, "clear_rx_queue");\r\nr = queue->rx_curr_get ;\r\nwhile (queue->rx_used) {\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\r\nDB_RX(5, "switch OWN bit of RxD 0x%p", r);\r\nr->rxd_rbctrl &= ~cpu_to_le32(BMU_OWN) ;\r\nfrag_count = 1 ;\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\r\nr = r->rxd_next ;\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\r\nwhile (r != queue->rx_curr_put &&\r\n!(r->rxd_rbctrl & cpu_to_le32(BMU_ST_BUF))) {\r\nDB_RX(5, "Check STF bit in %p", r);\r\nr->rxd_rbctrl &= ~cpu_to_le32(BMU_OWN) ;\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\r\nr = r->rxd_next ;\r\nDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\r\nfrag_count++ ;\r\n}\r\nDB_RX(5, "STF bit found");\r\nnext_rxd = r ;\r\nfor (r=queue->rx_curr_get,i=frag_count; i ; r=r->rxd_next,i--){\r\nDB_RX(5, "dma_complete for RxD %p", r);\r\ndma_complete(smc,(union s_fp_descr volatile *)r,DMA_WR);\r\n}\r\nDB_RX(5, "mac_drv_clear_rxd: RxD %p frag_count %d",\r\nqueue->rx_curr_get, frag_count);\r\nmac_drv_clear_rxd(smc,queue->rx_curr_get,frag_count) ;\r\nqueue->rx_curr_get = next_rxd ;\r\nqueue->rx_used -= frag_count ;\r\nqueue->rx_free += frag_count ;\r\n}\r\n}\r\nint hwm_tx_init(struct s_smc *smc, u_char fc, int frag_count, int frame_len,\r\nint frame_status)\r\n{\r\nNDD_TRACE("THiB",fc,frag_count,frame_len) ;\r\nsmc->os.hwm.tx_p = smc->hw.fp.tx[frame_status & QUEUE_A0] ;\r\nsmc->os.hwm.tx_descr = TX_DESCRIPTOR | (((u_long)(frame_len-1)&3)<<27) ;\r\nsmc->os.hwm.tx_len = frame_len ;\r\nDB_TX(3, "hwm_tx_init: fc = %x, len = %d", fc, frame_len);\r\nif ((fc & ~(FC_SYNC_BIT|FC_LLC_PRIOR)) == FC_ASYNC_LLC) {\r\nframe_status |= LAN_TX ;\r\n}\r\nelse {\r\nswitch (fc) {\r\ncase FC_SMT_INFO :\r\ncase FC_SMT_NSA :\r\nframe_status |= LAN_TX ;\r\nbreak ;\r\ncase FC_SMT_LOC :\r\nframe_status |= LOC_TX ;\r\nbreak ;\r\ncase FC_SMT_LAN_LOC :\r\nframe_status |= LAN_TX | LOC_TX ;\r\nbreak ;\r\ndefault :\r\nSMT_PANIC(smc,HWM_E0010,HWM_E0010_MSG) ;\r\n}\r\n}\r\nif (!smc->hw.mac_ring_is_up) {\r\nframe_status &= ~LAN_TX ;\r\nframe_status |= RING_DOWN ;\r\nDB_TX(2, "Ring is down: terminate LAN_TX");\r\n}\r\nif (frag_count > smc->os.hwm.tx_p->tx_free) {\r\n#ifndef NDIS_OS2\r\nmac_drv_clear_txd(smc) ;\r\nif (frag_count > smc->os.hwm.tx_p->tx_free) {\r\nDB_TX(2, "Out of TxDs, terminate LAN_TX");\r\nframe_status &= ~LAN_TX ;\r\nframe_status |= OUT_OF_TXD ;\r\n}\r\n#else\r\nDB_TX(2, "Out of TxDs, terminate LAN_TX");\r\nframe_status &= ~LAN_TX ;\r\nframe_status |= OUT_OF_TXD ;\r\n#endif\r\n}\r\nDB_TX(3, "frame_status = %x", frame_status);\r\nNDD_TRACE("THiE",frame_status,smc->os.hwm.tx_p->tx_free,0) ;\r\nreturn frame_status;\r\n}\r\nvoid hwm_tx_frag(struct s_smc *smc, char far *virt, u_long phys, int len,\r\nint frame_status)\r\n{\r\nstruct s_smt_fp_txd volatile *t ;\r\nstruct s_smt_tx_queue *queue ;\r\n__le32 tbctrl ;\r\nqueue = smc->os.hwm.tx_p ;\r\nNDD_TRACE("THfB",virt,len,frame_status) ;\r\nt = queue->tx_curr_put ;\r\nDB_TX(2, "hwm_tx_frag: len = %d, frame_status = %x", len, frame_status);\r\nif (frame_status & LAN_TX) {\r\nDB_TX(3, "LAN_TX: TxD = %p, virt = %p", t, virt);\r\nt->txd_virt = virt ;\r\nt->txd_txdscr = cpu_to_le32(smc->os.hwm.tx_descr) ;\r\nt->txd_tbadr = cpu_to_le32(phys) ;\r\ntbctrl = cpu_to_le32((((__u32)frame_status &\r\n(FIRST_FRAG|LAST_FRAG|EN_IRQ_EOF))<< 26) |\r\nBMU_OWN|BMU_CHECK |len) ;\r\nt->txd_tbctrl = tbctrl ;\r\n#ifndef AIX\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\r\noutpd(queue->tx_bmu_ctl,CSR_START) ;\r\n#else\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\r\nif (frame_status & QUEUE_A0) {\r\noutpd(ADDR(B0_XA_CSR),CSR_START) ;\r\n}\r\nelse {\r\noutpd(ADDR(B0_XS_CSR),CSR_START) ;\r\n}\r\n#endif\r\nqueue->tx_free-- ;\r\nqueue->tx_used++ ;\r\nqueue->tx_curr_put = t->txd_next ;\r\nif (frame_status & LAST_FRAG) {\r\nsmc->mib.m[MAC0].fddiMACTransmit_Ct++ ;\r\n}\r\n}\r\nif (frame_status & LOC_TX) {\r\nDB_TX(3, "LOC_TX:");\r\nif (frame_status & FIRST_FRAG) {\r\nif(!(smc->os.hwm.tx_mb = smt_get_mbuf(smc))) {\r\nsmc->hw.fp.err_stats.err_no_buf++ ;\r\nDB_TX(4, "No SMbuf; transmit terminated");\r\n}\r\nelse {\r\nsmc->os.hwm.tx_data =\r\nsmtod(smc->os.hwm.tx_mb,char *) - 1 ;\r\n#ifdef USE_OS_CPY\r\n#ifdef PASS_1ST_TXD_2_TX_COMP\r\nhwm_cpy_txd2mb(t,smc->os.hwm.tx_data,\r\nsmc->os.hwm.tx_len) ;\r\n#endif\r\n#endif\r\n}\r\n}\r\nif (smc->os.hwm.tx_mb) {\r\n#ifndef USE_OS_CPY\r\nDB_TX(3, "copy fragment into MBuf");\r\nmemcpy(smc->os.hwm.tx_data,virt,len) ;\r\nsmc->os.hwm.tx_data += len ;\r\n#endif\r\nif (frame_status & LAST_FRAG) {\r\n#ifdef USE_OS_CPY\r\n#ifndef PASS_1ST_TXD_2_TX_COMP\r\nhwm_cpy_txd2mb(t,smc->os.hwm.tx_data,\r\nsmc->os.hwm.tx_len) ;\r\n#endif\r\n#endif\r\nsmc->os.hwm.tx_data =\r\nsmtod(smc->os.hwm.tx_mb,char *) - 1 ;\r\n*(char *)smc->os.hwm.tx_mb->sm_data =\r\n*smc->os.hwm.tx_data ;\r\nsmc->os.hwm.tx_data++ ;\r\nsmc->os.hwm.tx_mb->sm_len =\r\nsmc->os.hwm.tx_len - 1 ;\r\nDB_TX(3, "pass LLC frame to SMT");\r\nsmt_received_pack(smc,smc->os.hwm.tx_mb,\r\nRD_FS_LOCAL) ;\r\n}\r\n}\r\n}\r\nNDD_TRACE("THfE",t,queue->tx_free,0) ;\r\n}\r\nstatic void queue_llc_rx(struct s_smc *smc, SMbuf *mb)\r\n{\r\nDB_GEN(4, "queue_llc_rx: mb = %p", mb);\r\nsmc->os.hwm.queued_rx_frames++ ;\r\nmb->sm_next = (SMbuf *)NULL ;\r\nif (smc->os.hwm.llc_rx_pipe == NULL) {\r\nsmc->os.hwm.llc_rx_pipe = mb ;\r\n}\r\nelse {\r\nsmc->os.hwm.llc_rx_tail->sm_next = mb ;\r\n}\r\nsmc->os.hwm.llc_rx_tail = mb ;\r\nif (!smc->os.hwm.isr_flag) {\r\nsmt_force_irq(smc) ;\r\n}\r\n}\r\nstatic SMbuf *get_llc_rx(struct s_smc *smc)\r\n{\r\nSMbuf *mb ;\r\nif ((mb = smc->os.hwm.llc_rx_pipe)) {\r\nsmc->os.hwm.queued_rx_frames-- ;\r\nsmc->os.hwm.llc_rx_pipe = mb->sm_next ;\r\n}\r\nDB_GEN(4, "get_llc_rx: mb = 0x%p", mb);\r\nreturn mb;\r\n}\r\nstatic void queue_txd_mb(struct s_smc *smc, SMbuf *mb)\r\n{\r\nDB_GEN(4, "_rx: queue_txd_mb = %p", mb);\r\nsmc->os.hwm.queued_txd_mb++ ;\r\nmb->sm_next = (SMbuf *)NULL ;\r\nif (smc->os.hwm.txd_tx_pipe == NULL) {\r\nsmc->os.hwm.txd_tx_pipe = mb ;\r\n}\r\nelse {\r\nsmc->os.hwm.txd_tx_tail->sm_next = mb ;\r\n}\r\nsmc->os.hwm.txd_tx_tail = mb ;\r\n}\r\nstatic SMbuf *get_txd_mb(struct s_smc *smc)\r\n{\r\nSMbuf *mb ;\r\nif ((mb = smc->os.hwm.txd_tx_pipe)) {\r\nsmc->os.hwm.queued_txd_mb-- ;\r\nsmc->os.hwm.txd_tx_pipe = mb->sm_next ;\r\n}\r\nDB_GEN(4, "get_txd_mb: mb = 0x%p", mb);\r\nreturn mb;\r\n}\r\nvoid smt_send_mbuf(struct s_smc *smc, SMbuf *mb, int fc)\r\n{\r\nchar far *data ;\r\nint len ;\r\nint n ;\r\nint i ;\r\nint frag_count ;\r\nint frame_status ;\r\nSK_LOC_DECL(char far,*virt[3]) ;\r\nint frag_len[3] ;\r\nstruct s_smt_tx_queue *queue ;\r\nstruct s_smt_fp_txd volatile *t ;\r\nu_long phys ;\r\n__le32 tbctrl;\r\nNDD_TRACE("THSB",mb,fc,0) ;\r\nDB_TX(4, "smt_send_mbuf: mb = 0x%p, fc = 0x%x", mb, fc);\r\nmb->sm_off-- ;\r\nmb->sm_len++ ;\r\ndata = smtod(mb,char *) ;\r\n*data = fc ;\r\nif (fc == FC_SMT_LOC)\r\n*data = FC_SMT_INFO ;\r\nfrag_count = 0 ;\r\nlen = mb->sm_len ;\r\nwhile (len) {\r\nn = SMT_PAGESIZE - ((long)data & (SMT_PAGESIZE-1)) ;\r\nif (n >= len) {\r\nn = len ;\r\n}\r\nDB_TX(5, "frag: virt/len = 0x%p/%d", data, n);\r\nvirt[frag_count] = data ;\r\nfrag_len[frag_count] = n ;\r\nfrag_count++ ;\r\nlen -= n ;\r\ndata += n ;\r\n}\r\nqueue = smc->hw.fp.tx[QUEUE_A0] ;\r\nif (fc == FC_BEACON || fc == FC_SMT_LOC) {\r\nframe_status = LOC_TX ;\r\n}\r\nelse {\r\nframe_status = LAN_TX ;\r\nif ((smc->os.hwm.pass_NSA &&(fc == FC_SMT_NSA)) ||\r\n(smc->os.hwm.pass_SMT &&(fc == FC_SMT_INFO)))\r\nframe_status |= LOC_TX ;\r\n}\r\nif (!smc->hw.mac_ring_is_up || frag_count > queue->tx_free) {\r\nframe_status &= ~LAN_TX;\r\nif (frame_status) {\r\nDB_TX(2, "Ring is down: terminate LAN_TX");\r\n}\r\nelse {\r\nDB_TX(2, "Ring is down: terminate transmission");\r\nsmt_free_mbuf(smc,mb) ;\r\nreturn ;\r\n}\r\n}\r\nDB_TX(5, "frame_status = 0x%x", frame_status);\r\nif ((frame_status & LAN_TX) && (frame_status & LOC_TX)) {\r\nmb->sm_use_count = 2 ;\r\n}\r\nif (frame_status & LAN_TX) {\r\nt = queue->tx_curr_put ;\r\nframe_status |= FIRST_FRAG ;\r\nfor (i = 0; i < frag_count; i++) {\r\nDB_TX(5, "init TxD = 0x%p", t);\r\nif (i == frag_count-1) {\r\nframe_status |= LAST_FRAG ;\r\nt->txd_txdscr = cpu_to_le32(TX_DESCRIPTOR |\r\n(((__u32)(mb->sm_len-1)&3) << 27)) ;\r\n}\r\nt->txd_virt = virt[i] ;\r\nphys = dma_master(smc, (void far *)virt[i],\r\nfrag_len[i], DMA_RD|SMT_BUF) ;\r\nt->txd_tbadr = cpu_to_le32(phys) ;\r\ntbctrl = cpu_to_le32((((__u32)frame_status &\r\n(FIRST_FRAG|LAST_FRAG)) << 26) |\r\nBMU_OWN | BMU_CHECK | BMU_SMT_TX |frag_len[i]) ;\r\nt->txd_tbctrl = tbctrl ;\r\n#ifndef AIX\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\r\noutpd(queue->tx_bmu_ctl,CSR_START) ;\r\n#else\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\r\noutpd(ADDR(B0_XA_CSR),CSR_START) ;\r\n#endif\r\nframe_status &= ~FIRST_FRAG ;\r\nqueue->tx_curr_put = t = t->txd_next ;\r\nqueue->tx_free-- ;\r\nqueue->tx_used++ ;\r\n}\r\nsmc->mib.m[MAC0].fddiMACTransmit_Ct++ ;\r\nqueue_txd_mb(smc,mb) ;\r\n}\r\nif (frame_status & LOC_TX) {\r\nDB_TX(5, "pass Mbuf to LLC queue");\r\nqueue_llc_rx(smc,mb) ;\r\n}\r\nmac_drv_clear_txd(smc) ;\r\nNDD_TRACE("THSE",t,queue->tx_free,frag_count) ;\r\n}\r\nstatic void mac_drv_clear_txd(struct s_smc *smc)\r\n{\r\nstruct s_smt_tx_queue *queue ;\r\nstruct s_smt_fp_txd volatile *t1 ;\r\nstruct s_smt_fp_txd volatile *t2 = NULL ;\r\nSMbuf *mb ;\r\nu_long tbctrl ;\r\nint i ;\r\nint frag_count ;\r\nint n ;\r\nNDD_TRACE("THcB",0,0,0) ;\r\nfor (i = QUEUE_S; i <= QUEUE_A0; i++) {\r\nqueue = smc->hw.fp.tx[i] ;\r\nt1 = queue->tx_curr_get ;\r\nDB_TX(5, "clear_txd: QUEUE = %d (0=sync/1=async)", i);\r\nfor ( ; ; ) {\r\nfrag_count = 0 ;\r\ndo {\r\nDRV_BUF_FLUSH(t1,DDI_DMA_SYNC_FORCPU) ;\r\nDB_TX(5, "check OWN/EOF bit of TxD 0x%p", t1);\r\ntbctrl = le32_to_cpu(CR_READ(t1->txd_tbctrl));\r\nif (tbctrl & BMU_OWN || !queue->tx_used){\r\nDB_TX(4, "End of TxDs queue %d", i);\r\ngoto free_next_queue ;\r\n}\r\nt1 = t1->txd_next ;\r\nfrag_count++ ;\r\n} while (!(tbctrl & BMU_EOF)) ;\r\nt1 = queue->tx_curr_get ;\r\nfor (n = frag_count; n; n--) {\r\ntbctrl = le32_to_cpu(t1->txd_tbctrl) ;\r\ndma_complete(smc,\r\n(union s_fp_descr volatile *) t1,\r\n(int) (DMA_RD |\r\n((tbctrl & BMU_SMT_TX) >> 18))) ;\r\nt2 = t1 ;\r\nt1 = t1->txd_next ;\r\n}\r\nif (tbctrl & BMU_SMT_TX) {\r\nmb = get_txd_mb(smc) ;\r\nsmt_free_mbuf(smc,mb) ;\r\n}\r\nelse {\r\n#ifndef PASS_1ST_TXD_2_TX_COMP\r\nDB_TX(4, "mac_drv_tx_comp for TxD 0x%p", t2);\r\nmac_drv_tx_complete(smc,t2) ;\r\n#else\r\nDB_TX(4, "mac_drv_tx_comp for TxD 0x%x",\r\nqueue->tx_curr_get);\r\nmac_drv_tx_complete(smc,queue->tx_curr_get) ;\r\n#endif\r\n}\r\nqueue->tx_curr_get = t1 ;\r\nqueue->tx_free += frag_count ;\r\nqueue->tx_used -= frag_count ;\r\n}\r\nfree_next_queue: ;\r\n}\r\nNDD_TRACE("THcE",0,0,0) ;\r\n}\r\nvoid mac_drv_clear_tx_queue(struct s_smc *smc)\r\n{\r\nstruct s_smt_fp_txd volatile *t ;\r\nstruct s_smt_tx_queue *queue ;\r\nint tx_used ;\r\nint i ;\r\nif (smc->hw.hw_state != STOPPED) {\r\nSK_BREAK() ;\r\nSMT_PANIC(smc,HWM_E0011,HWM_E0011_MSG) ;\r\nreturn ;\r\n}\r\nfor (i = QUEUE_S; i <= QUEUE_A0; i++) {\r\nqueue = smc->hw.fp.tx[i] ;\r\nDB_TX(5, "clear_tx_queue: QUEUE = %d (0=sync/1=async)", i);\r\nt = queue->tx_curr_get ;\r\ntx_used = queue->tx_used ;\r\nwhile (tx_used) {\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORCPU) ;\r\nDB_TX(5, "switch OWN bit of TxD 0x%p", t);\r\nt->txd_tbctrl &= ~cpu_to_le32(BMU_OWN) ;\r\nDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\r\nt = t->txd_next ;\r\ntx_used-- ;\r\n}\r\n}\r\nmac_drv_clear_txd(smc) ;\r\nfor (i = QUEUE_S; i <= QUEUE_A0; i++) {\r\nqueue = smc->hw.fp.tx[i] ;\r\nt = queue->tx_curr_get ;\r\nif (i == QUEUE_S) {\r\noutpd(ADDR(B5_XS_DA),le32_to_cpu(t->txd_ntdadr)) ;\r\n}\r\nelse {\r\noutpd(ADDR(B5_XA_DA),le32_to_cpu(t->txd_ntdadr)) ;\r\n}\r\nqueue->tx_curr_put = queue->tx_curr_get->txd_next ;\r\nqueue->tx_curr_get = queue->tx_curr_put ;\r\n}\r\n}\r\nvoid mac_drv_debug_lev(struct s_smc *smc, int flag, int lev)\r\n{\r\nswitch(flag) {\r\ncase (int)NULL:\r\nDB_P.d_smtf = DB_P.d_smt = DB_P.d_ecm = DB_P.d_rmt = 0 ;\r\nDB_P.d_cfm = 0 ;\r\nDB_P.d_os.hwm_rx = DB_P.d_os.hwm_tx = DB_P.d_os.hwm_gen = 0 ;\r\n#ifdef SBA\r\nDB_P.d_sba = 0 ;\r\n#endif\r\n#ifdef ESS\r\nDB_P.d_ess = 0 ;\r\n#endif\r\nbreak ;\r\ncase DEBUG_SMTF:\r\nDB_P.d_smtf = lev ;\r\nbreak ;\r\ncase DEBUG_SMT:\r\nDB_P.d_smt = lev ;\r\nbreak ;\r\ncase DEBUG_ECM:\r\nDB_P.d_ecm = lev ;\r\nbreak ;\r\ncase DEBUG_RMT:\r\nDB_P.d_rmt = lev ;\r\nbreak ;\r\ncase DEBUG_CFM:\r\nDB_P.d_cfm = lev ;\r\nbreak ;\r\ncase DEBUG_PCM:\r\nDB_P.d_pcm = lev ;\r\nbreak ;\r\ncase DEBUG_SBA:\r\n#ifdef SBA\r\nDB_P.d_sba = lev ;\r\n#endif\r\nbreak ;\r\ncase DEBUG_ESS:\r\n#ifdef ESS\r\nDB_P.d_ess = lev ;\r\n#endif\r\nbreak ;\r\ncase DB_HWM_RX:\r\nDB_P.d_os.hwm_rx = lev ;\r\nbreak ;\r\ncase DB_HWM_TX:\r\nDB_P.d_os.hwm_tx = lev ;\r\nbreak ;\r\ncase DB_HWM_GEN:\r\nDB_P.d_os.hwm_gen = lev ;\r\nbreak ;\r\ndefault:\r\nbreak ;\r\n}\r\n}
