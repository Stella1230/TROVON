static struct vfio_group *kvm_vfio_group_get_external_user(struct file *filep)\r\n{\r\nstruct vfio_group *vfio_group;\r\nstruct vfio_group *(*fn)(struct file *);\r\nfn = symbol_get(vfio_group_get_external_user);\r\nif (!fn)\r\nreturn ERR_PTR(-EINVAL);\r\nvfio_group = fn(filep);\r\nsymbol_put(vfio_group_get_external_user);\r\nreturn vfio_group;\r\n}\r\nstatic bool kvm_vfio_external_group_match_file(struct vfio_group *group,\r\nstruct file *filep)\r\n{\r\nbool ret, (*fn)(struct vfio_group *, struct file *);\r\nfn = symbol_get(vfio_external_group_match_file);\r\nif (!fn)\r\nreturn false;\r\nret = fn(group, filep);\r\nsymbol_put(vfio_external_group_match_file);\r\nreturn ret;\r\n}\r\nstatic void kvm_vfio_group_put_external_user(struct vfio_group *vfio_group)\r\n{\r\nvoid (*fn)(struct vfio_group *);\r\nfn = symbol_get(vfio_group_put_external_user);\r\nif (!fn)\r\nreturn;\r\nfn(vfio_group);\r\nsymbol_put(vfio_group_put_external_user);\r\n}\r\nstatic void kvm_vfio_group_set_kvm(struct vfio_group *group, struct kvm *kvm)\r\n{\r\nvoid (*fn)(struct vfio_group *, struct kvm *);\r\nfn = symbol_get(vfio_group_set_kvm);\r\nif (!fn)\r\nreturn;\r\nfn(group, kvm);\r\nsymbol_put(vfio_group_set_kvm);\r\n}\r\nstatic bool kvm_vfio_group_is_coherent(struct vfio_group *vfio_group)\r\n{\r\nlong (*fn)(struct vfio_group *, unsigned long);\r\nlong ret;\r\nfn = symbol_get(vfio_external_check_extension);\r\nif (!fn)\r\nreturn false;\r\nret = fn(vfio_group, VFIO_DMA_CC_IOMMU);\r\nsymbol_put(vfio_external_check_extension);\r\nreturn ret > 0;\r\n}\r\nstatic int kvm_vfio_external_user_iommu_id(struct vfio_group *vfio_group)\r\n{\r\nint (*fn)(struct vfio_group *);\r\nint ret = -EINVAL;\r\nfn = symbol_get(vfio_external_user_iommu_id);\r\nif (!fn)\r\nreturn ret;\r\nret = fn(vfio_group);\r\nsymbol_put(vfio_external_user_iommu_id);\r\nreturn ret;\r\n}\r\nstatic struct iommu_group *kvm_vfio_group_get_iommu_group(\r\nstruct vfio_group *group)\r\n{\r\nint group_id = kvm_vfio_external_user_iommu_id(group);\r\nif (group_id < 0)\r\nreturn NULL;\r\nreturn iommu_group_get_by_id(group_id);\r\n}\r\nstatic void kvm_spapr_tce_release_vfio_group(struct kvm *kvm,\r\nstruct vfio_group *vfio_group)\r\n{\r\nstruct iommu_group *grp = kvm_vfio_group_get_iommu_group(vfio_group);\r\nif (WARN_ON_ONCE(!grp))\r\nreturn;\r\nkvm_spapr_tce_release_iommu_group(kvm, grp);\r\niommu_group_put(grp);\r\n}\r\nstatic void kvm_vfio_update_coherency(struct kvm_device *dev)\r\n{\r\nstruct kvm_vfio *kv = dev->private;\r\nbool noncoherent = false;\r\nstruct kvm_vfio_group *kvg;\r\nmutex_lock(&kv->lock);\r\nlist_for_each_entry(kvg, &kv->group_list, node) {\r\nif (!kvm_vfio_group_is_coherent(kvg->vfio_group)) {\r\nnoncoherent = true;\r\nbreak;\r\n}\r\n}\r\nif (noncoherent != kv->noncoherent) {\r\nkv->noncoherent = noncoherent;\r\nif (kv->noncoherent)\r\nkvm_arch_register_noncoherent_dma(dev->kvm);\r\nelse\r\nkvm_arch_unregister_noncoherent_dma(dev->kvm);\r\n}\r\nmutex_unlock(&kv->lock);\r\n}\r\nstatic int kvm_vfio_set_group(struct kvm_device *dev, long attr, u64 arg)\r\n{\r\nstruct kvm_vfio *kv = dev->private;\r\nstruct vfio_group *vfio_group;\r\nstruct kvm_vfio_group *kvg;\r\nint32_t __user *argp = (int32_t __user *)(unsigned long)arg;\r\nstruct fd f;\r\nint32_t fd;\r\nint ret;\r\nswitch (attr) {\r\ncase KVM_DEV_VFIO_GROUP_ADD:\r\nif (get_user(fd, argp))\r\nreturn -EFAULT;\r\nf = fdget(fd);\r\nif (!f.file)\r\nreturn -EBADF;\r\nvfio_group = kvm_vfio_group_get_external_user(f.file);\r\nfdput(f);\r\nif (IS_ERR(vfio_group))\r\nreturn PTR_ERR(vfio_group);\r\nmutex_lock(&kv->lock);\r\nlist_for_each_entry(kvg, &kv->group_list, node) {\r\nif (kvg->vfio_group == vfio_group) {\r\nmutex_unlock(&kv->lock);\r\nkvm_vfio_group_put_external_user(vfio_group);\r\nreturn -EEXIST;\r\n}\r\n}\r\nkvg = kzalloc(sizeof(*kvg), GFP_KERNEL);\r\nif (!kvg) {\r\nmutex_unlock(&kv->lock);\r\nkvm_vfio_group_put_external_user(vfio_group);\r\nreturn -ENOMEM;\r\n}\r\nlist_add_tail(&kvg->node, &kv->group_list);\r\nkvg->vfio_group = vfio_group;\r\nkvm_arch_start_assignment(dev->kvm);\r\nmutex_unlock(&kv->lock);\r\nkvm_vfio_group_set_kvm(vfio_group, dev->kvm);\r\nkvm_vfio_update_coherency(dev);\r\nreturn 0;\r\ncase KVM_DEV_VFIO_GROUP_DEL:\r\nif (get_user(fd, argp))\r\nreturn -EFAULT;\r\nf = fdget(fd);\r\nif (!f.file)\r\nreturn -EBADF;\r\nret = -ENOENT;\r\nmutex_lock(&kv->lock);\r\nlist_for_each_entry(kvg, &kv->group_list, node) {\r\nif (!kvm_vfio_external_group_match_file(kvg->vfio_group,\r\nf.file))\r\ncontinue;\r\nlist_del(&kvg->node);\r\nkvm_arch_end_assignment(dev->kvm);\r\n#ifdef CONFIG_SPAPR_TCE_IOMMU\r\nkvm_spapr_tce_release_vfio_group(dev->kvm,\r\nkvg->vfio_group);\r\n#endif\r\nkvm_vfio_group_set_kvm(kvg->vfio_group, NULL);\r\nkvm_vfio_group_put_external_user(kvg->vfio_group);\r\nkfree(kvg);\r\nret = 0;\r\nbreak;\r\n}\r\nmutex_unlock(&kv->lock);\r\nfdput(f);\r\nkvm_vfio_update_coherency(dev);\r\nreturn ret;\r\n#ifdef CONFIG_SPAPR_TCE_IOMMU\r\ncase KVM_DEV_VFIO_GROUP_SET_SPAPR_TCE: {\r\nstruct kvm_vfio_spapr_tce param;\r\nstruct kvm_vfio *kv = dev->private;\r\nstruct vfio_group *vfio_group;\r\nstruct kvm_vfio_group *kvg;\r\nstruct fd f;\r\nstruct iommu_group *grp;\r\nif (copy_from_user(&param, (void __user *)arg,\r\nsizeof(struct kvm_vfio_spapr_tce)))\r\nreturn -EFAULT;\r\nf = fdget(param.groupfd);\r\nif (!f.file)\r\nreturn -EBADF;\r\nvfio_group = kvm_vfio_group_get_external_user(f.file);\r\nfdput(f);\r\nif (IS_ERR(vfio_group))\r\nreturn PTR_ERR(vfio_group);\r\ngrp = kvm_vfio_group_get_iommu_group(vfio_group);\r\nif (WARN_ON_ONCE(!grp)) {\r\nkvm_vfio_group_put_external_user(vfio_group);\r\nreturn -EIO;\r\n}\r\nret = -ENOENT;\r\nmutex_lock(&kv->lock);\r\nlist_for_each_entry(kvg, &kv->group_list, node) {\r\nif (kvg->vfio_group != vfio_group)\r\ncontinue;\r\nret = kvm_spapr_tce_attach_iommu_group(dev->kvm,\r\nparam.tablefd, grp);\r\nbreak;\r\n}\r\nmutex_unlock(&kv->lock);\r\niommu_group_put(grp);\r\nkvm_vfio_group_put_external_user(vfio_group);\r\nreturn ret;\r\n}\r\n#endif\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int kvm_vfio_set_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nswitch (attr->group) {\r\ncase KVM_DEV_VFIO_GROUP:\r\nreturn kvm_vfio_set_group(dev, attr->attr, attr->addr);\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int kvm_vfio_has_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nswitch (attr->group) {\r\ncase KVM_DEV_VFIO_GROUP:\r\nswitch (attr->attr) {\r\ncase KVM_DEV_VFIO_GROUP_ADD:\r\ncase KVM_DEV_VFIO_GROUP_DEL:\r\n#ifdef CONFIG_SPAPR_TCE_IOMMU\r\ncase KVM_DEV_VFIO_GROUP_SET_SPAPR_TCE:\r\n#endif\r\nreturn 0;\r\n}\r\nbreak;\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic void kvm_vfio_destroy(struct kvm_device *dev)\r\n{\r\nstruct kvm_vfio *kv = dev->private;\r\nstruct kvm_vfio_group *kvg, *tmp;\r\nlist_for_each_entry_safe(kvg, tmp, &kv->group_list, node) {\r\n#ifdef CONFIG_SPAPR_TCE_IOMMU\r\nkvm_spapr_tce_release_vfio_group(dev->kvm, kvg->vfio_group);\r\n#endif\r\nkvm_vfio_group_set_kvm(kvg->vfio_group, NULL);\r\nkvm_vfio_group_put_external_user(kvg->vfio_group);\r\nlist_del(&kvg->node);\r\nkfree(kvg);\r\nkvm_arch_end_assignment(dev->kvm);\r\n}\r\nkvm_vfio_update_coherency(dev);\r\nkfree(kv);\r\nkfree(dev);\r\n}\r\nstatic int kvm_vfio_create(struct kvm_device *dev, u32 type)\r\n{\r\nstruct kvm_device *tmp;\r\nstruct kvm_vfio *kv;\r\nlist_for_each_entry(tmp, &dev->kvm->devices, vm_node)\r\nif (tmp->ops == &kvm_vfio_ops)\r\nreturn -EBUSY;\r\nkv = kzalloc(sizeof(*kv), GFP_KERNEL);\r\nif (!kv)\r\nreturn -ENOMEM;\r\nINIT_LIST_HEAD(&kv->group_list);\r\nmutex_init(&kv->lock);\r\ndev->private = kv;\r\nreturn 0;\r\n}\r\nint kvm_vfio_ops_init(void)\r\n{\r\nreturn kvm_register_device_ops(&kvm_vfio_ops, KVM_DEV_TYPE_VFIO);\r\n}\r\nvoid kvm_vfio_ops_exit(void)\r\n{\r\nkvm_unregister_device_ops(KVM_DEV_TYPE_VFIO);\r\n}
