static void __init acpi_request_region (struct acpi_generic_address *gas,\r\nunsigned int length, char *desc)\r\n{\r\nu64 addr;\r\nmemcpy(&addr, &gas->address, sizeof(addr));\r\nif (!addr || !length)\r\nreturn;\r\nif (gas->space_id == ACPI_ADR_SPACE_SYSTEM_IO)\r\nrequest_region(addr, length, desc);\r\nelse if (gas->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)\r\nrequest_mem_region(addr, length, desc);\r\n}\r\nstatic int __init acpi_reserve_resources(void)\r\n{\r\nacpi_request_region(&acpi_gbl_FADT.xpm1a_event_block, acpi_gbl_FADT.pm1_event_length,\r\n"ACPI PM1a_EVT_BLK");\r\nacpi_request_region(&acpi_gbl_FADT.xpm1b_event_block, acpi_gbl_FADT.pm1_event_length,\r\n"ACPI PM1b_EVT_BLK");\r\nacpi_request_region(&acpi_gbl_FADT.xpm1a_control_block, acpi_gbl_FADT.pm1_control_length,\r\n"ACPI PM1a_CNT_BLK");\r\nacpi_request_region(&acpi_gbl_FADT.xpm1b_control_block, acpi_gbl_FADT.pm1_control_length,\r\n"ACPI PM1b_CNT_BLK");\r\nif (acpi_gbl_FADT.pm_timer_length == 4)\r\nacpi_request_region(&acpi_gbl_FADT.xpm_timer_block, 4, "ACPI PM_TMR");\r\nacpi_request_region(&acpi_gbl_FADT.xpm2_control_block, acpi_gbl_FADT.pm2_control_length,\r\n"ACPI PM2_CNT_BLK");\r\nif (!(acpi_gbl_FADT.gpe0_block_length & 0x1))\r\nacpi_request_region(&acpi_gbl_FADT.xgpe0_block,\r\nacpi_gbl_FADT.gpe0_block_length, "ACPI GPE0_BLK");\r\nif (!(acpi_gbl_FADT.gpe1_block_length & 0x1))\r\nacpi_request_region(&acpi_gbl_FADT.xgpe1_block,\r\nacpi_gbl_FADT.gpe1_block_length, "ACPI GPE1_BLK");\r\nreturn 0;\r\n}\r\nvoid acpi_os_printf(const char *fmt, ...)\r\n{\r\nva_list args;\r\nva_start(args, fmt);\r\nacpi_os_vprintf(fmt, args);\r\nva_end(args);\r\n}\r\nvoid acpi_os_vprintf(const char *fmt, va_list args)\r\n{\r\nstatic char buffer[512];\r\nvsprintf(buffer, fmt, args);\r\n#ifdef ENABLE_DEBUGGER\r\nif (acpi_in_debugger) {\r\nkdb_printf("%s", buffer);\r\n} else {\r\nif (printk_get_level(buffer))\r\nprintk("%s", buffer);\r\nelse\r\nprintk(KERN_CONT "%s", buffer);\r\n}\r\n#else\r\nif (acpi_debugger_write_log(buffer) < 0) {\r\nif (printk_get_level(buffer))\r\nprintk("%s", buffer);\r\nelse\r\nprintk(KERN_CONT "%s", buffer);\r\n}\r\n#endif\r\n}\r\nstatic int __init setup_acpi_rsdp(char *arg)\r\n{\r\nreturn kstrtoul(arg, 16, &acpi_rsdp);\r\n}\r\nacpi_physical_address __init acpi_os_get_root_pointer(void)\r\n{\r\nacpi_physical_address pa = 0;\r\n#ifdef CONFIG_KEXEC\r\nif (acpi_rsdp)\r\nreturn acpi_rsdp;\r\n#endif\r\nif (efi_enabled(EFI_CONFIG_TABLES)) {\r\nif (efi.acpi20 != EFI_INVALID_TABLE_ADDR)\r\nreturn efi.acpi20;\r\nif (efi.acpi != EFI_INVALID_TABLE_ADDR)\r\nreturn efi.acpi;\r\npr_err(PREFIX "System description tables not found\n");\r\n} else if (IS_ENABLED(CONFIG_ACPI_LEGACY_TABLES_LOOKUP)) {\r\nacpi_find_root_pointer(&pa);\r\n}\r\nreturn pa;\r\n}\r\nstatic struct acpi_ioremap *\r\nacpi_map_lookup(acpi_physical_address phys, acpi_size size)\r\n{\r\nstruct acpi_ioremap *map;\r\nlist_for_each_entry_rcu(map, &acpi_ioremaps, list)\r\nif (map->phys <= phys &&\r\nphys + size <= map->phys + map->size)\r\nreturn map;\r\nreturn NULL;\r\n}\r\nstatic void __iomem *\r\nacpi_map_vaddr_lookup(acpi_physical_address phys, unsigned int size)\r\n{\r\nstruct acpi_ioremap *map;\r\nmap = acpi_map_lookup(phys, size);\r\nif (map)\r\nreturn map->virt + (phys - map->phys);\r\nreturn NULL;\r\n}\r\nvoid __iomem *acpi_os_get_iomem(acpi_physical_address phys, unsigned int size)\r\n{\r\nstruct acpi_ioremap *map;\r\nvoid __iomem *virt = NULL;\r\nmutex_lock(&acpi_ioremap_lock);\r\nmap = acpi_map_lookup(phys, size);\r\nif (map) {\r\nvirt = map->virt + (phys - map->phys);\r\nmap->refcount++;\r\n}\r\nmutex_unlock(&acpi_ioremap_lock);\r\nreturn virt;\r\n}\r\nstatic struct acpi_ioremap *\r\nacpi_map_lookup_virt(void __iomem *virt, acpi_size size)\r\n{\r\nstruct acpi_ioremap *map;\r\nlist_for_each_entry_rcu(map, &acpi_ioremaps, list)\r\nif (map->virt <= virt &&\r\nvirt + size <= map->virt + map->size)\r\nreturn map;\r\nreturn NULL;\r\n}\r\nstatic void __iomem *acpi_map(acpi_physical_address pg_off, unsigned long pg_sz)\r\n{\r\nunsigned long pfn;\r\npfn = pg_off >> PAGE_SHIFT;\r\nif (should_use_kmap(pfn)) {\r\nif (pg_sz > PAGE_SIZE)\r\nreturn NULL;\r\nreturn (void __iomem __force *)kmap(pfn_to_page(pfn));\r\n} else\r\nreturn acpi_os_ioremap(pg_off, pg_sz);\r\n}\r\nstatic void acpi_unmap(acpi_physical_address pg_off, void __iomem *vaddr)\r\n{\r\nunsigned long pfn;\r\npfn = pg_off >> PAGE_SHIFT;\r\nif (should_use_kmap(pfn))\r\nkunmap(pfn_to_page(pfn));\r\nelse\r\niounmap(vaddr);\r\n}\r\nvoid __iomem *__ref\r\nacpi_os_map_iomem(acpi_physical_address phys, acpi_size size)\r\n{\r\nstruct acpi_ioremap *map;\r\nvoid __iomem *virt;\r\nacpi_physical_address pg_off;\r\nacpi_size pg_sz;\r\nif (phys > ULONG_MAX) {\r\nprintk(KERN_ERR PREFIX "Cannot map memory that high\n");\r\nreturn NULL;\r\n}\r\nif (!acpi_permanent_mmap)\r\nreturn __acpi_map_table((unsigned long)phys, size);\r\nmutex_lock(&acpi_ioremap_lock);\r\nmap = acpi_map_lookup(phys, size);\r\nif (map) {\r\nmap->refcount++;\r\ngoto out;\r\n}\r\nmap = kzalloc(sizeof(*map), GFP_KERNEL);\r\nif (!map) {\r\nmutex_unlock(&acpi_ioremap_lock);\r\nreturn NULL;\r\n}\r\npg_off = round_down(phys, PAGE_SIZE);\r\npg_sz = round_up(phys + size, PAGE_SIZE) - pg_off;\r\nvirt = acpi_map(pg_off, pg_sz);\r\nif (!virt) {\r\nmutex_unlock(&acpi_ioremap_lock);\r\nkfree(map);\r\nreturn NULL;\r\n}\r\nINIT_LIST_HEAD(&map->list);\r\nmap->virt = virt;\r\nmap->phys = pg_off;\r\nmap->size = pg_sz;\r\nmap->refcount = 1;\r\nlist_add_tail_rcu(&map->list, &acpi_ioremaps);\r\nout:\r\nmutex_unlock(&acpi_ioremap_lock);\r\nreturn map->virt + (phys - map->phys);\r\n}\r\nvoid *__ref acpi_os_map_memory(acpi_physical_address phys, acpi_size size)\r\n{\r\nreturn (void *)acpi_os_map_iomem(phys, size);\r\n}\r\nstatic void acpi_os_drop_map_ref(struct acpi_ioremap *map)\r\n{\r\nif (!--map->refcount)\r\nlist_del_rcu(&map->list);\r\n}\r\nstatic void acpi_os_map_cleanup(struct acpi_ioremap *map)\r\n{\r\nif (!map->refcount) {\r\nsynchronize_rcu_expedited();\r\nacpi_unmap(map->phys, map->virt);\r\nkfree(map);\r\n}\r\n}\r\nvoid __ref acpi_os_unmap_iomem(void __iomem *virt, acpi_size size)\r\n{\r\nstruct acpi_ioremap *map;\r\nif (!acpi_permanent_mmap) {\r\n__acpi_unmap_table(virt, size);\r\nreturn;\r\n}\r\nmutex_lock(&acpi_ioremap_lock);\r\nmap = acpi_map_lookup_virt(virt, size);\r\nif (!map) {\r\nmutex_unlock(&acpi_ioremap_lock);\r\nWARN(true, PREFIX "%s: bad address %p\n", __func__, virt);\r\nreturn;\r\n}\r\nacpi_os_drop_map_ref(map);\r\nmutex_unlock(&acpi_ioremap_lock);\r\nacpi_os_map_cleanup(map);\r\n}\r\nvoid __ref acpi_os_unmap_memory(void *virt, acpi_size size)\r\n{\r\nreturn acpi_os_unmap_iomem((void __iomem *)virt, size);\r\n}\r\nint acpi_os_map_generic_address(struct acpi_generic_address *gas)\r\n{\r\nu64 addr;\r\nvoid __iomem *virt;\r\nif (gas->space_id != ACPI_ADR_SPACE_SYSTEM_MEMORY)\r\nreturn 0;\r\nmemcpy(&addr, &gas->address, sizeof(addr));\r\nif (!addr || !gas->bit_width)\r\nreturn -EINVAL;\r\nvirt = acpi_os_map_iomem(addr, gas->bit_width / 8);\r\nif (!virt)\r\nreturn -EIO;\r\nreturn 0;\r\n}\r\nvoid acpi_os_unmap_generic_address(struct acpi_generic_address *gas)\r\n{\r\nu64 addr;\r\nstruct acpi_ioremap *map;\r\nif (gas->space_id != ACPI_ADR_SPACE_SYSTEM_MEMORY)\r\nreturn;\r\nmemcpy(&addr, &gas->address, sizeof(addr));\r\nif (!addr || !gas->bit_width)\r\nreturn;\r\nmutex_lock(&acpi_ioremap_lock);\r\nmap = acpi_map_lookup(addr, gas->bit_width / 8);\r\nif (!map) {\r\nmutex_unlock(&acpi_ioremap_lock);\r\nreturn;\r\n}\r\nacpi_os_drop_map_ref(map);\r\nmutex_unlock(&acpi_ioremap_lock);\r\nacpi_os_map_cleanup(map);\r\n}\r\nacpi_status\r\nacpi_os_get_physical_address(void *virt, acpi_physical_address * phys)\r\n{\r\nif (!phys || !virt)\r\nreturn AE_BAD_PARAMETER;\r\n*phys = virt_to_phys(virt);\r\nreturn AE_OK;\r\n}\r\nint __init acpi_rev_override_setup(char *str)\r\n{\r\nacpi_rev_override = true;\r\nreturn 1;\r\n}\r\nacpi_status\r\nacpi_os_predefined_override(const struct acpi_predefined_names *init_val,\r\nacpi_string *new_val)\r\n{\r\nif (!init_val || !new_val)\r\nreturn AE_BAD_PARAMETER;\r\n*new_val = NULL;\r\nif (!memcmp(init_val->name, "_OS_", 4) && strlen(acpi_os_name)) {\r\nprintk(KERN_INFO PREFIX "Overriding _OS definition to '%s'\n",\r\nacpi_os_name);\r\n*new_val = acpi_os_name;\r\n}\r\nif (!memcmp(init_val->name, "_REV", 4) && acpi_rev_override) {\r\nprintk(KERN_INFO PREFIX "Overriding _REV return value to 5\n");\r\n*new_val = (char *)5;\r\n}\r\nreturn AE_OK;\r\n}\r\nstatic irqreturn_t acpi_irq(int irq, void *dev_id)\r\n{\r\nu32 handled;\r\nhandled = (*acpi_irq_handler) (acpi_irq_context);\r\nif (handled) {\r\nacpi_irq_handled++;\r\nreturn IRQ_HANDLED;\r\n} else {\r\nacpi_irq_not_handled++;\r\nreturn IRQ_NONE;\r\n}\r\n}\r\nacpi_status\r\nacpi_os_install_interrupt_handler(u32 gsi, acpi_osd_handler handler,\r\nvoid *context)\r\n{\r\nunsigned int irq;\r\nacpi_irq_stats_init();\r\nif (gsi != acpi_gbl_FADT.sci_interrupt)\r\nreturn AE_BAD_PARAMETER;\r\nif (acpi_irq_handler)\r\nreturn AE_ALREADY_ACQUIRED;\r\nif (acpi_gsi_to_irq(gsi, &irq) < 0) {\r\nprintk(KERN_ERR PREFIX "SCI (ACPI GSI %d) not registered\n",\r\ngsi);\r\nreturn AE_OK;\r\n}\r\nacpi_irq_handler = handler;\r\nacpi_irq_context = context;\r\nif (request_irq(irq, acpi_irq, IRQF_SHARED, "acpi", acpi_irq)) {\r\nprintk(KERN_ERR PREFIX "SCI (IRQ%d) allocation failed\n", irq);\r\nacpi_irq_handler = NULL;\r\nreturn AE_NOT_ACQUIRED;\r\n}\r\nacpi_sci_irq = irq;\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_remove_interrupt_handler(u32 gsi, acpi_osd_handler handler)\r\n{\r\nif (gsi != acpi_gbl_FADT.sci_interrupt || !acpi_sci_irq_valid())\r\nreturn AE_BAD_PARAMETER;\r\nfree_irq(acpi_sci_irq, acpi_irq);\r\nacpi_irq_handler = NULL;\r\nacpi_sci_irq = INVALID_ACPI_IRQ;\r\nreturn AE_OK;\r\n}\r\nvoid acpi_os_sleep(u64 ms)\r\n{\r\nmsleep(ms);\r\n}\r\nvoid acpi_os_stall(u32 us)\r\n{\r\nwhile (us) {\r\nu32 delay = 1000;\r\nif (delay > us)\r\ndelay = us;\r\nudelay(delay);\r\ntouch_nmi_watchdog();\r\nus -= delay;\r\n}\r\n}\r\nu64 acpi_os_get_timer(void)\r\n{\r\nu64 time_ns = ktime_to_ns(ktime_get());\r\ndo_div(time_ns, 100);\r\nreturn time_ns;\r\n}\r\nacpi_status acpi_os_read_port(acpi_io_address port, u32 * value, u32 width)\r\n{\r\nu32 dummy;\r\nif (!value)\r\nvalue = &dummy;\r\n*value = 0;\r\nif (width <= 8) {\r\n*(u8 *) value = inb(port);\r\n} else if (width <= 16) {\r\n*(u16 *) value = inw(port);\r\n} else if (width <= 32) {\r\n*(u32 *) value = inl(port);\r\n} else {\r\nBUG();\r\n}\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_write_port(acpi_io_address port, u32 value, u32 width)\r\n{\r\nif (width <= 8) {\r\noutb(value, port);\r\n} else if (width <= 16) {\r\noutw(value, port);\r\n} else if (width <= 32) {\r\noutl(value, port);\r\n} else {\r\nBUG();\r\n}\r\nreturn AE_OK;\r\n}\r\nacpi_status\r\nacpi_os_read_memory(acpi_physical_address phys_addr, u64 *value, u32 width)\r\n{\r\nvoid __iomem *virt_addr;\r\nunsigned int size = width / 8;\r\nbool unmap = false;\r\nu64 dummy;\r\nrcu_read_lock();\r\nvirt_addr = acpi_map_vaddr_lookup(phys_addr, size);\r\nif (!virt_addr) {\r\nrcu_read_unlock();\r\nvirt_addr = acpi_os_ioremap(phys_addr, size);\r\nif (!virt_addr)\r\nreturn AE_BAD_ADDRESS;\r\nunmap = true;\r\n}\r\nif (!value)\r\nvalue = &dummy;\r\nswitch (width) {\r\ncase 8:\r\n*(u8 *) value = readb(virt_addr);\r\nbreak;\r\ncase 16:\r\n*(u16 *) value = readw(virt_addr);\r\nbreak;\r\ncase 32:\r\n*(u32 *) value = readl(virt_addr);\r\nbreak;\r\ncase 64:\r\n*(u64 *) value = readq(virt_addr);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nif (unmap)\r\niounmap(virt_addr);\r\nelse\r\nrcu_read_unlock();\r\nreturn AE_OK;\r\n}\r\nacpi_status\r\nacpi_os_write_memory(acpi_physical_address phys_addr, u64 value, u32 width)\r\n{\r\nvoid __iomem *virt_addr;\r\nunsigned int size = width / 8;\r\nbool unmap = false;\r\nrcu_read_lock();\r\nvirt_addr = acpi_map_vaddr_lookup(phys_addr, size);\r\nif (!virt_addr) {\r\nrcu_read_unlock();\r\nvirt_addr = acpi_os_ioremap(phys_addr, size);\r\nif (!virt_addr)\r\nreturn AE_BAD_ADDRESS;\r\nunmap = true;\r\n}\r\nswitch (width) {\r\ncase 8:\r\nwriteb(value, virt_addr);\r\nbreak;\r\ncase 16:\r\nwritew(value, virt_addr);\r\nbreak;\r\ncase 32:\r\nwritel(value, virt_addr);\r\nbreak;\r\ncase 64:\r\nwriteq(value, virt_addr);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nif (unmap)\r\niounmap(virt_addr);\r\nelse\r\nrcu_read_unlock();\r\nreturn AE_OK;\r\n}\r\nacpi_status\r\nacpi_os_read_pci_configuration(struct acpi_pci_id * pci_id, u32 reg,\r\nu64 *value, u32 width)\r\n{\r\nint result, size;\r\nu32 value32;\r\nif (!value)\r\nreturn AE_BAD_PARAMETER;\r\nswitch (width) {\r\ncase 8:\r\nsize = 1;\r\nbreak;\r\ncase 16:\r\nsize = 2;\r\nbreak;\r\ncase 32:\r\nsize = 4;\r\nbreak;\r\ndefault:\r\nreturn AE_ERROR;\r\n}\r\nresult = raw_pci_read(pci_id->segment, pci_id->bus,\r\nPCI_DEVFN(pci_id->device, pci_id->function),\r\nreg, size, &value32);\r\n*value = value32;\r\nreturn (result ? AE_ERROR : AE_OK);\r\n}\r\nacpi_status\r\nacpi_os_write_pci_configuration(struct acpi_pci_id * pci_id, u32 reg,\r\nu64 value, u32 width)\r\n{\r\nint result, size;\r\nswitch (width) {\r\ncase 8:\r\nsize = 1;\r\nbreak;\r\ncase 16:\r\nsize = 2;\r\nbreak;\r\ncase 32:\r\nsize = 4;\r\nbreak;\r\ndefault:\r\nreturn AE_ERROR;\r\n}\r\nresult = raw_pci_write(pci_id->segment, pci_id->bus,\r\nPCI_DEVFN(pci_id->device, pci_id->function),\r\nreg, size, value);\r\nreturn (result ? AE_ERROR : AE_OK);\r\n}\r\nstatic void acpi_os_execute_deferred(struct work_struct *work)\r\n{\r\nstruct acpi_os_dpc *dpc = container_of(work, struct acpi_os_dpc, work);\r\ndpc->function(dpc->context);\r\nkfree(dpc);\r\n}\r\nint acpi_register_debugger(struct module *owner,\r\nconst struct acpi_debugger_ops *ops)\r\n{\r\nint ret = 0;\r\nmutex_lock(&acpi_debugger.lock);\r\nif (acpi_debugger.ops) {\r\nret = -EBUSY;\r\ngoto err_lock;\r\n}\r\nacpi_debugger.owner = owner;\r\nacpi_debugger.ops = ops;\r\nerr_lock:\r\nmutex_unlock(&acpi_debugger.lock);\r\nreturn ret;\r\n}\r\nvoid acpi_unregister_debugger(const struct acpi_debugger_ops *ops)\r\n{\r\nmutex_lock(&acpi_debugger.lock);\r\nif (ops == acpi_debugger.ops) {\r\nacpi_debugger.ops = NULL;\r\nacpi_debugger.owner = NULL;\r\n}\r\nmutex_unlock(&acpi_debugger.lock);\r\n}\r\nint acpi_debugger_create_thread(acpi_osd_exec_callback function, void *context)\r\n{\r\nint ret;\r\nint (*func)(acpi_osd_exec_callback, void *);\r\nstruct module *owner;\r\nif (!acpi_debugger_initialized)\r\nreturn -ENODEV;\r\nmutex_lock(&acpi_debugger.lock);\r\nif (!acpi_debugger.ops) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nif (!try_module_get(acpi_debugger.owner)) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nfunc = acpi_debugger.ops->create_thread;\r\nowner = acpi_debugger.owner;\r\nmutex_unlock(&acpi_debugger.lock);\r\nret = func(function, context);\r\nmutex_lock(&acpi_debugger.lock);\r\nmodule_put(owner);\r\nerr_lock:\r\nmutex_unlock(&acpi_debugger.lock);\r\nreturn ret;\r\n}\r\nssize_t acpi_debugger_write_log(const char *msg)\r\n{\r\nssize_t ret;\r\nssize_t (*func)(const char *);\r\nstruct module *owner;\r\nif (!acpi_debugger_initialized)\r\nreturn -ENODEV;\r\nmutex_lock(&acpi_debugger.lock);\r\nif (!acpi_debugger.ops) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nif (!try_module_get(acpi_debugger.owner)) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nfunc = acpi_debugger.ops->write_log;\r\nowner = acpi_debugger.owner;\r\nmutex_unlock(&acpi_debugger.lock);\r\nret = func(msg);\r\nmutex_lock(&acpi_debugger.lock);\r\nmodule_put(owner);\r\nerr_lock:\r\nmutex_unlock(&acpi_debugger.lock);\r\nreturn ret;\r\n}\r\nssize_t acpi_debugger_read_cmd(char *buffer, size_t buffer_length)\r\n{\r\nssize_t ret;\r\nssize_t (*func)(char *, size_t);\r\nstruct module *owner;\r\nif (!acpi_debugger_initialized)\r\nreturn -ENODEV;\r\nmutex_lock(&acpi_debugger.lock);\r\nif (!acpi_debugger.ops) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nif (!try_module_get(acpi_debugger.owner)) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nfunc = acpi_debugger.ops->read_cmd;\r\nowner = acpi_debugger.owner;\r\nmutex_unlock(&acpi_debugger.lock);\r\nret = func(buffer, buffer_length);\r\nmutex_lock(&acpi_debugger.lock);\r\nmodule_put(owner);\r\nerr_lock:\r\nmutex_unlock(&acpi_debugger.lock);\r\nreturn ret;\r\n}\r\nint acpi_debugger_wait_command_ready(void)\r\n{\r\nint ret;\r\nint (*func)(bool, char *, size_t);\r\nstruct module *owner;\r\nif (!acpi_debugger_initialized)\r\nreturn -ENODEV;\r\nmutex_lock(&acpi_debugger.lock);\r\nif (!acpi_debugger.ops) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nif (!try_module_get(acpi_debugger.owner)) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nfunc = acpi_debugger.ops->wait_command_ready;\r\nowner = acpi_debugger.owner;\r\nmutex_unlock(&acpi_debugger.lock);\r\nret = func(acpi_gbl_method_executing,\r\nacpi_gbl_db_line_buf, ACPI_DB_LINE_BUFFER_SIZE);\r\nmutex_lock(&acpi_debugger.lock);\r\nmodule_put(owner);\r\nerr_lock:\r\nmutex_unlock(&acpi_debugger.lock);\r\nreturn ret;\r\n}\r\nint acpi_debugger_notify_command_complete(void)\r\n{\r\nint ret;\r\nint (*func)(void);\r\nstruct module *owner;\r\nif (!acpi_debugger_initialized)\r\nreturn -ENODEV;\r\nmutex_lock(&acpi_debugger.lock);\r\nif (!acpi_debugger.ops) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nif (!try_module_get(acpi_debugger.owner)) {\r\nret = -ENODEV;\r\ngoto err_lock;\r\n}\r\nfunc = acpi_debugger.ops->notify_command_complete;\r\nowner = acpi_debugger.owner;\r\nmutex_unlock(&acpi_debugger.lock);\r\nret = func();\r\nmutex_lock(&acpi_debugger.lock);\r\nmodule_put(owner);\r\nerr_lock:\r\nmutex_unlock(&acpi_debugger.lock);\r\nreturn ret;\r\n}\r\nint __init acpi_debugger_init(void)\r\n{\r\nmutex_init(&acpi_debugger.lock);\r\nacpi_debugger_initialized = true;\r\nreturn 0;\r\n}\r\nacpi_status acpi_os_execute(acpi_execute_type type,\r\nacpi_osd_exec_callback function, void *context)\r\n{\r\nacpi_status status = AE_OK;\r\nstruct acpi_os_dpc *dpc;\r\nstruct workqueue_struct *queue;\r\nint ret;\r\nACPI_DEBUG_PRINT((ACPI_DB_EXEC,\r\n"Scheduling function [%p(%p)] for deferred execution.\n",\r\nfunction, context));\r\nif (type == OSL_DEBUGGER_MAIN_THREAD) {\r\nret = acpi_debugger_create_thread(function, context);\r\nif (ret) {\r\npr_err("Call to kthread_create() failed.\n");\r\nstatus = AE_ERROR;\r\n}\r\ngoto out_thread;\r\n}\r\ndpc = kzalloc(sizeof(struct acpi_os_dpc), GFP_ATOMIC);\r\nif (!dpc)\r\nreturn AE_NO_MEMORY;\r\ndpc->function = function;\r\ndpc->context = context;\r\nif (type == OSL_NOTIFY_HANDLER) {\r\nqueue = kacpi_notify_wq;\r\nINIT_WORK(&dpc->work, acpi_os_execute_deferred);\r\n} else if (type == OSL_GPE_HANDLER) {\r\nqueue = kacpid_wq;\r\nINIT_WORK(&dpc->work, acpi_os_execute_deferred);\r\n} else {\r\npr_err("Unsupported os_execute type %d.\n", type);\r\nstatus = AE_ERROR;\r\n}\r\nif (ACPI_FAILURE(status))\r\ngoto err_workqueue;\r\nret = queue_work_on(0, queue, &dpc->work);\r\nif (!ret) {\r\nprintk(KERN_ERR PREFIX\r\n"Call to queue_work() failed.\n");\r\nstatus = AE_ERROR;\r\n}\r\nerr_workqueue:\r\nif (ACPI_FAILURE(status))\r\nkfree(dpc);\r\nout_thread:\r\nreturn status;\r\n}\r\nvoid acpi_os_wait_events_complete(void)\r\n{\r\nif (acpi_sci_irq_valid())\r\nsynchronize_hardirq(acpi_sci_irq);\r\nflush_workqueue(kacpid_wq);\r\nflush_workqueue(kacpi_notify_wq);\r\n}\r\nstatic void acpi_hotplug_work_fn(struct work_struct *work)\r\n{\r\nstruct acpi_hp_work *hpw = container_of(work, struct acpi_hp_work, work);\r\nacpi_os_wait_events_complete();\r\nacpi_device_hotplug(hpw->adev, hpw->src);\r\nkfree(hpw);\r\n}\r\nacpi_status acpi_hotplug_schedule(struct acpi_device *adev, u32 src)\r\n{\r\nstruct acpi_hp_work *hpw;\r\nACPI_DEBUG_PRINT((ACPI_DB_EXEC,\r\n"Scheduling hotplug event (%p, %u) for deferred execution.\n",\r\nadev, src));\r\nhpw = kmalloc(sizeof(*hpw), GFP_KERNEL);\r\nif (!hpw)\r\nreturn AE_NO_MEMORY;\r\nINIT_WORK(&hpw->work, acpi_hotplug_work_fn);\r\nhpw->adev = adev;\r\nhpw->src = src;\r\nif (!queue_work(kacpi_hotplug_wq, &hpw->work)) {\r\nkfree(hpw);\r\nreturn AE_ERROR;\r\n}\r\nreturn AE_OK;\r\n}\r\nbool acpi_queue_hotplug_work(struct work_struct *work)\r\n{\r\nreturn queue_work(kacpi_hotplug_wq, work);\r\n}\r\nacpi_status\r\nacpi_os_create_semaphore(u32 max_units, u32 initial_units, acpi_handle * handle)\r\n{\r\nstruct semaphore *sem = NULL;\r\nsem = acpi_os_allocate_zeroed(sizeof(struct semaphore));\r\nif (!sem)\r\nreturn AE_NO_MEMORY;\r\nsema_init(sem, initial_units);\r\n*handle = (acpi_handle *) sem;\r\nACPI_DEBUG_PRINT((ACPI_DB_MUTEX, "Creating semaphore[%p|%d].\n",\r\n*handle, initial_units));\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_delete_semaphore(acpi_handle handle)\r\n{\r\nstruct semaphore *sem = (struct semaphore *)handle;\r\nif (!sem)\r\nreturn AE_BAD_PARAMETER;\r\nACPI_DEBUG_PRINT((ACPI_DB_MUTEX, "Deleting semaphore[%p].\n", handle));\r\nBUG_ON(!list_empty(&sem->wait_list));\r\nkfree(sem);\r\nsem = NULL;\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_wait_semaphore(acpi_handle handle, u32 units, u16 timeout)\r\n{\r\nacpi_status status = AE_OK;\r\nstruct semaphore *sem = (struct semaphore *)handle;\r\nlong jiffies;\r\nint ret = 0;\r\nif (!acpi_os_initialized)\r\nreturn AE_OK;\r\nif (!sem || (units < 1))\r\nreturn AE_BAD_PARAMETER;\r\nif (units > 1)\r\nreturn AE_SUPPORT;\r\nACPI_DEBUG_PRINT((ACPI_DB_MUTEX, "Waiting for semaphore[%p|%d|%d]\n",\r\nhandle, units, timeout));\r\nif (timeout == ACPI_WAIT_FOREVER)\r\njiffies = MAX_SCHEDULE_TIMEOUT;\r\nelse\r\njiffies = msecs_to_jiffies(timeout);\r\nret = down_timeout(sem, jiffies);\r\nif (ret)\r\nstatus = AE_TIME;\r\nif (ACPI_FAILURE(status)) {\r\nACPI_DEBUG_PRINT((ACPI_DB_MUTEX,\r\n"Failed to acquire semaphore[%p|%d|%d], %s",\r\nhandle, units, timeout,\r\nacpi_format_exception(status)));\r\n} else {\r\nACPI_DEBUG_PRINT((ACPI_DB_MUTEX,\r\n"Acquired semaphore[%p|%d|%d]", handle,\r\nunits, timeout));\r\n}\r\nreturn status;\r\n}\r\nacpi_status acpi_os_signal_semaphore(acpi_handle handle, u32 units)\r\n{\r\nstruct semaphore *sem = (struct semaphore *)handle;\r\nif (!acpi_os_initialized)\r\nreturn AE_OK;\r\nif (!sem || (units < 1))\r\nreturn AE_BAD_PARAMETER;\r\nif (units > 1)\r\nreturn AE_SUPPORT;\r\nACPI_DEBUG_PRINT((ACPI_DB_MUTEX, "Signaling semaphore[%p|%d]\n", handle,\r\nunits));\r\nup(sem);\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_get_line(char *buffer, u32 buffer_length, u32 *bytes_read)\r\n{\r\n#ifdef ENABLE_DEBUGGER\r\nif (acpi_in_debugger) {\r\nu32 chars;\r\nkdb_read(buffer, buffer_length);\r\nchars = strlen(buffer) - 1;\r\nbuffer[chars] = '\0';\r\n}\r\n#else\r\nint ret;\r\nret = acpi_debugger_read_cmd(buffer, buffer_length);\r\nif (ret < 0)\r\nreturn AE_ERROR;\r\nif (bytes_read)\r\n*bytes_read = ret;\r\n#endif\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_wait_command_ready(void)\r\n{\r\nint ret;\r\nret = acpi_debugger_wait_command_ready();\r\nif (ret < 0)\r\nreturn AE_ERROR;\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_notify_command_complete(void)\r\n{\r\nint ret;\r\nret = acpi_debugger_notify_command_complete();\r\nif (ret < 0)\r\nreturn AE_ERROR;\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_signal(u32 function, void *info)\r\n{\r\nswitch (function) {\r\ncase ACPI_SIGNAL_FATAL:\r\nprintk(KERN_ERR PREFIX "Fatal opcode executed\n");\r\nbreak;\r\ncase ACPI_SIGNAL_BREAKPOINT:\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn AE_OK;\r\n}\r\nstatic int __init acpi_os_name_setup(char *str)\r\n{\r\nchar *p = acpi_os_name;\r\nint count = ACPI_MAX_OVERRIDE_LEN - 1;\r\nif (!str || !*str)\r\nreturn 0;\r\nfor (; count-- && *str; str++) {\r\nif (isalnum(*str) || *str == ' ' || *str == ':')\r\n*p++ = *str;\r\nelse if (*str == '\'' || *str == '"')\r\ncontinue;\r\nelse\r\nbreak;\r\n}\r\n*p = 0;\r\nreturn 1;\r\n}\r\nstatic int __init acpi_no_auto_serialize_setup(char *str)\r\n{\r\nacpi_gbl_auto_serialize_methods = FALSE;\r\npr_info("ACPI: auto-serialization disabled\n");\r\nreturn 1;\r\n}\r\nstatic int __init acpi_enforce_resources_setup(char *str)\r\n{\r\nif (str == NULL || *str == '\0')\r\nreturn 0;\r\nif (!strcmp("strict", str))\r\nacpi_enforce_resources = ENFORCE_RESOURCES_STRICT;\r\nelse if (!strcmp("lax", str))\r\nacpi_enforce_resources = ENFORCE_RESOURCES_LAX;\r\nelse if (!strcmp("no", str))\r\nacpi_enforce_resources = ENFORCE_RESOURCES_NO;\r\nreturn 1;\r\n}\r\nint acpi_check_resource_conflict(const struct resource *res)\r\n{\r\nacpi_adr_space_type space_id;\r\nacpi_size length;\r\nu8 warn = 0;\r\nint clash = 0;\r\nif (acpi_enforce_resources == ENFORCE_RESOURCES_NO)\r\nreturn 0;\r\nif (!(res->flags & IORESOURCE_IO) && !(res->flags & IORESOURCE_MEM))\r\nreturn 0;\r\nif (res->flags & IORESOURCE_IO)\r\nspace_id = ACPI_ADR_SPACE_SYSTEM_IO;\r\nelse\r\nspace_id = ACPI_ADR_SPACE_SYSTEM_MEMORY;\r\nlength = resource_size(res);\r\nif (acpi_enforce_resources != ENFORCE_RESOURCES_NO)\r\nwarn = 1;\r\nclash = acpi_check_address_range(space_id, res->start, length, warn);\r\nif (clash) {\r\nif (acpi_enforce_resources != ENFORCE_RESOURCES_NO) {\r\nif (acpi_enforce_resources == ENFORCE_RESOURCES_LAX)\r\nprintk(KERN_NOTICE "ACPI: This conflict may"\r\n" cause random problems and system"\r\n" instability\n");\r\nprintk(KERN_INFO "ACPI: If an ACPI driver is available"\r\n" for this device, you should use it instead of"\r\n" the native driver\n");\r\n}\r\nif (acpi_enforce_resources == ENFORCE_RESOURCES_STRICT)\r\nreturn -EBUSY;\r\n}\r\nreturn 0;\r\n}\r\nint acpi_check_region(resource_size_t start, resource_size_t n,\r\nconst char *name)\r\n{\r\nstruct resource res = {\r\n.start = start,\r\n.end = start + n - 1,\r\n.name = name,\r\n.flags = IORESOURCE_IO,\r\n};\r\nreturn acpi_check_resource_conflict(&res);\r\n}\r\nint acpi_resources_are_enforced(void)\r\n{\r\nreturn acpi_enforce_resources == ENFORCE_RESOURCES_STRICT;\r\n}\r\nvoid acpi_os_delete_lock(acpi_spinlock handle)\r\n{\r\nACPI_FREE(handle);\r\n}\r\nacpi_cpu_flags acpi_os_acquire_lock(acpi_spinlock lockp)\r\n{\r\nacpi_cpu_flags flags;\r\nspin_lock_irqsave(lockp, flags);\r\nreturn flags;\r\n}\r\nvoid acpi_os_release_lock(acpi_spinlock lockp, acpi_cpu_flags flags)\r\n{\r\nspin_unlock_irqrestore(lockp, flags);\r\n}\r\nacpi_status\r\nacpi_os_create_cache(char *name, u16 size, u16 depth, acpi_cache_t ** cache)\r\n{\r\n*cache = kmem_cache_create(name, size, 0, 0, NULL);\r\nif (*cache == NULL)\r\nreturn AE_ERROR;\r\nelse\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_purge_cache(acpi_cache_t * cache)\r\n{\r\nkmem_cache_shrink(cache);\r\nreturn (AE_OK);\r\n}\r\nacpi_status acpi_os_delete_cache(acpi_cache_t * cache)\r\n{\r\nkmem_cache_destroy(cache);\r\nreturn (AE_OK);\r\n}\r\nacpi_status acpi_os_release_object(acpi_cache_t * cache, void *object)\r\n{\r\nkmem_cache_free(cache, object);\r\nreturn (AE_OK);\r\n}\r\nstatic int __init acpi_no_static_ssdt_setup(char *s)\r\n{\r\nacpi_gbl_disable_ssdt_table_install = TRUE;\r\npr_info("ACPI: static SSDT installation disabled\n");\r\nreturn 0;\r\n}\r\nstatic int __init acpi_disable_return_repair(char *s)\r\n{\r\nprintk(KERN_NOTICE PREFIX\r\n"ACPI: Predefined validation mechanism disabled\n");\r\nacpi_gbl_disable_auto_repair = TRUE;\r\nreturn 1;\r\n}\r\nacpi_status __init acpi_os_initialize(void)\r\n{\r\nacpi_os_map_generic_address(&acpi_gbl_FADT.xpm1a_event_block);\r\nacpi_os_map_generic_address(&acpi_gbl_FADT.xpm1b_event_block);\r\nacpi_os_map_generic_address(&acpi_gbl_FADT.xgpe0_block);\r\nacpi_os_map_generic_address(&acpi_gbl_FADT.xgpe1_block);\r\nif (acpi_gbl_FADT.flags & ACPI_FADT_RESET_REGISTER) {\r\nint rv;\r\nrv = acpi_os_map_generic_address(&acpi_gbl_FADT.reset_register);\r\npr_debug(PREFIX "%s: map reset_reg status %d\n", __func__, rv);\r\n}\r\nacpi_os_initialized = true;\r\nreturn AE_OK;\r\n}\r\nacpi_status __init acpi_os_initialize1(void)\r\n{\r\nkacpid_wq = alloc_workqueue("kacpid", 0, 1);\r\nkacpi_notify_wq = alloc_workqueue("kacpi_notify", 0, 1);\r\nkacpi_hotplug_wq = alloc_ordered_workqueue("kacpi_hotplug", 0);\r\nBUG_ON(!kacpid_wq);\r\nBUG_ON(!kacpi_notify_wq);\r\nBUG_ON(!kacpi_hotplug_wq);\r\nacpi_osi_init();\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_terminate(void)\r\n{\r\nif (acpi_irq_handler) {\r\nacpi_os_remove_interrupt_handler(acpi_gbl_FADT.sci_interrupt,\r\nacpi_irq_handler);\r\n}\r\nacpi_os_unmap_generic_address(&acpi_gbl_FADT.xgpe1_block);\r\nacpi_os_unmap_generic_address(&acpi_gbl_FADT.xgpe0_block);\r\nacpi_os_unmap_generic_address(&acpi_gbl_FADT.xpm1b_event_block);\r\nacpi_os_unmap_generic_address(&acpi_gbl_FADT.xpm1a_event_block);\r\nif (acpi_gbl_FADT.flags & ACPI_FADT_RESET_REGISTER)\r\nacpi_os_unmap_generic_address(&acpi_gbl_FADT.reset_register);\r\ndestroy_workqueue(kacpid_wq);\r\ndestroy_workqueue(kacpi_notify_wq);\r\ndestroy_workqueue(kacpi_hotplug_wq);\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_prepare_sleep(u8 sleep_state, u32 pm1a_control,\r\nu32 pm1b_control)\r\n{\r\nint rc = 0;\r\nif (__acpi_os_prepare_sleep)\r\nrc = __acpi_os_prepare_sleep(sleep_state,\r\npm1a_control, pm1b_control);\r\nif (rc < 0)\r\nreturn AE_ERROR;\r\nelse if (rc > 0)\r\nreturn AE_CTRL_TERMINATE;\r\nreturn AE_OK;\r\n}\r\nvoid acpi_os_set_prepare_sleep(int (*func)(u8 sleep_state,\r\nu32 pm1a_ctrl, u32 pm1b_ctrl))\r\n{\r\n__acpi_os_prepare_sleep = func;\r\n}\r\nacpi_status acpi_os_prepare_extended_sleep(u8 sleep_state, u32 val_a,\r\nu32 val_b)\r\n{\r\nint rc = 0;\r\nif (__acpi_os_prepare_extended_sleep)\r\nrc = __acpi_os_prepare_extended_sleep(sleep_state,\r\nval_a, val_b);\r\nif (rc < 0)\r\nreturn AE_ERROR;\r\nelse if (rc > 0)\r\nreturn AE_CTRL_TERMINATE;\r\nreturn AE_OK;\r\n}\r\nacpi_status acpi_os_prepare_extended_sleep(u8 sleep_state, u32 val_a,\r\nu32 val_b)\r\n{\r\nreturn AE_OK;\r\n}\r\nvoid acpi_os_set_prepare_extended_sleep(int (*func)(u8 sleep_state,\r\nu32 val_a, u32 val_b))\r\n{\r\n__acpi_os_prepare_extended_sleep = func;\r\n}\r\nacpi_status acpi_os_enter_sleep(u8 sleep_state,\r\nu32 reg_a_value, u32 reg_b_value)\r\n{\r\nacpi_status status;\r\nif (acpi_gbl_reduced_hardware)\r\nstatus = acpi_os_prepare_extended_sleep(sleep_state,\r\nreg_a_value,\r\nreg_b_value);\r\nelse\r\nstatus = acpi_os_prepare_sleep(sleep_state,\r\nreg_a_value, reg_b_value);\r\nreturn status;\r\n}
