static bool __kprobes aarch64_insn_is_steppable(u32 insn)\r\n{\r\nif (aarch64_get_insn_class(insn) == AARCH64_INSN_CLS_BR_SYS) {\r\nif (aarch64_insn_is_branch(insn) ||\r\naarch64_insn_is_msr_imm(insn) ||\r\naarch64_insn_is_msr_reg(insn) ||\r\naarch64_insn_is_exception(insn) ||\r\naarch64_insn_is_eret(insn))\r\nreturn false;\r\nif (aarch64_insn_is_mrs(insn))\r\nreturn aarch64_insn_extract_system_reg(insn)\r\n!= AARCH64_INSN_SPCLREG_DAIF;\r\nif (aarch64_insn_is_hint(insn))\r\nreturn aarch64_insn_is_nop(insn);\r\nreturn true;\r\n}\r\nif (aarch64_insn_uses_literal(insn) ||\r\naarch64_insn_is_exclusive(insn))\r\nreturn false;\r\nreturn true;\r\n}\r\nenum probe_insn __kprobes\r\narm_probe_decode_insn(probe_opcode_t insn, struct arch_probe_insn *api)\r\n{\r\nif (aarch64_insn_is_steppable(insn))\r\nreturn INSN_GOOD;\r\nif (aarch64_insn_is_bcond(insn)) {\r\napi->handler = simulate_b_cond;\r\n} else if (aarch64_insn_is_cbz(insn) ||\r\naarch64_insn_is_cbnz(insn)) {\r\napi->handler = simulate_cbz_cbnz;\r\n} else if (aarch64_insn_is_tbz(insn) ||\r\naarch64_insn_is_tbnz(insn)) {\r\napi->handler = simulate_tbz_tbnz;\r\n} else if (aarch64_insn_is_adr_adrp(insn)) {\r\napi->handler = simulate_adr_adrp;\r\n} else if (aarch64_insn_is_b(insn) ||\r\naarch64_insn_is_bl(insn)) {\r\napi->handler = simulate_b_bl;\r\n} else if (aarch64_insn_is_br(insn) ||\r\naarch64_insn_is_blr(insn) ||\r\naarch64_insn_is_ret(insn)) {\r\napi->handler = simulate_br_blr_ret;\r\n} else if (aarch64_insn_is_ldr_lit(insn)) {\r\napi->handler = simulate_ldr_literal;\r\n} else if (aarch64_insn_is_ldrsw_lit(insn)) {\r\napi->handler = simulate_ldrsw_literal;\r\n} else {\r\nreturn INSN_REJECTED;\r\n}\r\nreturn INSN_GOOD_NO_SLOT;\r\n}\r\nstatic bool __kprobes\r\nis_probed_address_atomic(kprobe_opcode_t *scan_start, kprobe_opcode_t *scan_end)\r\n{\r\nwhile (scan_start >= scan_end) {\r\nif (aarch64_insn_is_store_ex(le32_to_cpu(*scan_start)))\r\nreturn false;\r\nelse if (aarch64_insn_is_load_ex(le32_to_cpu(*scan_start)))\r\nreturn true;\r\nscan_start--;\r\n}\r\nreturn false;\r\n}\r\nenum probe_insn __kprobes\r\narm_kprobe_decode_insn(kprobe_opcode_t *addr, struct arch_specific_insn *asi)\r\n{\r\nenum probe_insn decoded;\r\nprobe_opcode_t insn = le32_to_cpu(*addr);\r\nprobe_opcode_t *scan_end = NULL;\r\nunsigned long size = 0, offset = 0;\r\nif (kallsyms_lookup_size_offset((unsigned long) addr, &size, &offset)) {\r\nif (offset < (MAX_ATOMIC_CONTEXT_SIZE*sizeof(kprobe_opcode_t)))\r\nscan_end = addr - (offset / sizeof(kprobe_opcode_t));\r\nelse\r\nscan_end = addr - MAX_ATOMIC_CONTEXT_SIZE;\r\n}\r\ndecoded = arm_probe_decode_insn(insn, &asi->api);\r\nif (decoded != INSN_REJECTED && scan_end)\r\nif (is_probed_address_atomic(addr - 1, scan_end))\r\nreturn INSN_REJECTED;\r\nreturn decoded;\r\n}
