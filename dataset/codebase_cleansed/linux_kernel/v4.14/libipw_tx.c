static int libipw_copy_snap(u8 * data, __be16 h_proto)\r\n{\r\nstruct libipw_snap_hdr *snap;\r\nu8 *oui;\r\nsnap = (struct libipw_snap_hdr *)data;\r\nsnap->dsap = 0xaa;\r\nsnap->ssap = 0xaa;\r\nsnap->ctrl = 0x03;\r\nif (h_proto == htons(ETH_P_AARP) || h_proto == htons(ETH_P_IPX))\r\noui = P802_1H_OUI;\r\nelse\r\noui = RFC1042_OUI;\r\nsnap->oui[0] = oui[0];\r\nsnap->oui[1] = oui[1];\r\nsnap->oui[2] = oui[2];\r\nmemcpy(data + SNAP_SIZE, &h_proto, sizeof(u16));\r\nreturn SNAP_SIZE + sizeof(u16);\r\n}\r\nstatic int libipw_encrypt_fragment(struct libipw_device *ieee,\r\nstruct sk_buff *frag, int hdr_len)\r\n{\r\nstruct lib80211_crypt_data *crypt =\r\nieee->crypt_info.crypt[ieee->crypt_info.tx_keyidx];\r\nint res;\r\nif (crypt == NULL)\r\nreturn -1;\r\natomic_inc(&crypt->refcnt);\r\nres = 0;\r\nif (crypt->ops && crypt->ops->encrypt_mpdu)\r\nres = crypt->ops->encrypt_mpdu(frag, hdr_len, crypt->priv);\r\natomic_dec(&crypt->refcnt);\r\nif (res < 0) {\r\nprintk(KERN_INFO "%s: Encryption failed: len=%d.\n",\r\nieee->dev->name, frag->len);\r\nieee->ieee_stats.tx_discards++;\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nvoid libipw_txb_free(struct libipw_txb *txb)\r\n{\r\nint i;\r\nif (unlikely(!txb))\r\nreturn;\r\nfor (i = 0; i < txb->nr_frags; i++)\r\nif (txb->fragments[i])\r\ndev_kfree_skb_any(txb->fragments[i]);\r\nkfree(txb);\r\n}\r\nstatic struct libipw_txb *libipw_alloc_txb(int nr_frags, int txb_size,\r\nint headroom, gfp_t gfp_mask)\r\n{\r\nstruct libipw_txb *txb;\r\nint i;\r\ntxb = kmalloc(sizeof(struct libipw_txb) + (sizeof(u8 *) * nr_frags),\r\ngfp_mask);\r\nif (!txb)\r\nreturn NULL;\r\nmemset(txb, 0, sizeof(struct libipw_txb));\r\ntxb->nr_frags = nr_frags;\r\ntxb->frag_size = txb_size;\r\nfor (i = 0; i < nr_frags; i++) {\r\ntxb->fragments[i] = __dev_alloc_skb(txb_size + headroom,\r\ngfp_mask);\r\nif (unlikely(!txb->fragments[i])) {\r\ni--;\r\nbreak;\r\n}\r\nskb_reserve(txb->fragments[i], headroom);\r\n}\r\nif (unlikely(i != nr_frags)) {\r\nwhile (i >= 0)\r\ndev_kfree_skb_any(txb->fragments[i--]);\r\nkfree(txb);\r\nreturn NULL;\r\n}\r\nreturn txb;\r\n}\r\nstatic int libipw_classify(struct sk_buff *skb)\r\n{\r\nstruct ethhdr *eth;\r\nstruct iphdr *ip;\r\neth = (struct ethhdr *)skb->data;\r\nif (eth->h_proto != htons(ETH_P_IP))\r\nreturn 0;\r\nip = ip_hdr(skb);\r\nswitch (ip->tos & 0xfc) {\r\ncase 0x20:\r\nreturn 2;\r\ncase 0x40:\r\nreturn 1;\r\ncase 0x60:\r\nreturn 3;\r\ncase 0x80:\r\nreturn 4;\r\ncase 0xa0:\r\nreturn 5;\r\ncase 0xc0:\r\nreturn 6;\r\ncase 0xe0:\r\nreturn 7;\r\ndefault:\r\nreturn 0;\r\n}\r\n}\r\nnetdev_tx_t libipw_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct libipw_device *ieee = netdev_priv(dev);\r\nstruct libipw_txb *txb = NULL;\r\nstruct libipw_hdr_3addrqos *frag_hdr;\r\nint i, bytes_per_frag, nr_frags, bytes_last_frag, frag_size,\r\nrts_required;\r\nunsigned long flags;\r\nint encrypt, host_encrypt, host_encrypt_msdu;\r\n__be16 ether_type;\r\nint bytes, fc, hdr_len;\r\nstruct sk_buff *skb_frag;\r\nstruct libipw_hdr_3addrqos header = {\r\n.duration_id = 0,\r\n.seq_ctl = 0,\r\n.qos_ctl = 0\r\n};\r\nu8 dest[ETH_ALEN], src[ETH_ALEN];\r\nstruct lib80211_crypt_data *crypt;\r\nint priority = skb->priority;\r\nint snapped = 0;\r\nif (ieee->is_queue_full && (*ieee->is_queue_full) (dev, priority))\r\nreturn NETDEV_TX_BUSY;\r\nspin_lock_irqsave(&ieee->lock, flags);\r\nif (!ieee->hard_start_xmit) {\r\nprintk(KERN_WARNING "%s: No xmit handler.\n", ieee->dev->name);\r\ngoto success;\r\n}\r\nif (unlikely(skb->len < SNAP_SIZE + sizeof(u16))) {\r\nprintk(KERN_WARNING "%s: skb too small (%d).\n",\r\nieee->dev->name, skb->len);\r\ngoto success;\r\n}\r\nether_type = ((struct ethhdr *)skb->data)->h_proto;\r\ncrypt = ieee->crypt_info.crypt[ieee->crypt_info.tx_keyidx];\r\nencrypt = !(ether_type == htons(ETH_P_PAE) && ieee->ieee802_1x) &&\r\nieee->sec.encrypt;\r\nhost_encrypt = ieee->host_encrypt && encrypt && crypt;\r\nhost_encrypt_msdu = ieee->host_encrypt_msdu && encrypt && crypt;\r\nif (!encrypt && ieee->ieee802_1x &&\r\nieee->drop_unencrypted && ether_type != htons(ETH_P_PAE)) {\r\ndev->stats.tx_dropped++;\r\ngoto success;\r\n}\r\nskb_copy_from_linear_data(skb, dest, ETH_ALEN);\r\nskb_copy_from_linear_data_offset(skb, ETH_ALEN, src, ETH_ALEN);\r\nif (host_encrypt)\r\nfc = IEEE80211_FTYPE_DATA | IEEE80211_STYPE_DATA |\r\nIEEE80211_FCTL_PROTECTED;\r\nelse\r\nfc = IEEE80211_FTYPE_DATA | IEEE80211_STYPE_DATA;\r\nif (ieee->iw_mode == IW_MODE_INFRA) {\r\nfc |= IEEE80211_FCTL_TODS;\r\nmemcpy(header.addr1, ieee->bssid, ETH_ALEN);\r\nmemcpy(header.addr2, src, ETH_ALEN);\r\nmemcpy(header.addr3, dest, ETH_ALEN);\r\n} else if (ieee->iw_mode == IW_MODE_ADHOC) {\r\nmemcpy(header.addr1, dest, ETH_ALEN);\r\nmemcpy(header.addr2, src, ETH_ALEN);\r\nmemcpy(header.addr3, ieee->bssid, ETH_ALEN);\r\n}\r\nhdr_len = LIBIPW_3ADDR_LEN;\r\nif (ieee->is_qos_active && ieee->is_qos_active(dev, skb)) {\r\nfc |= IEEE80211_STYPE_QOS_DATA;\r\nhdr_len += 2;\r\nskb->priority = libipw_classify(skb);\r\nheader.qos_ctl |= cpu_to_le16(skb->priority & LIBIPW_QCTL_TID);\r\n}\r\nheader.frame_ctl = cpu_to_le16(fc);\r\nskb_pull(skb, sizeof(struct ethhdr));\r\nbytes = skb->len + SNAP_SIZE + sizeof(u16);\r\nif ((host_encrypt || host_encrypt_msdu) &&\r\ncrypt && crypt->ops && crypt->ops->encrypt_msdu) {\r\nint res = 0;\r\nint len = bytes + hdr_len + crypt->ops->extra_msdu_prefix_len +\r\ncrypt->ops->extra_msdu_postfix_len;\r\nstruct sk_buff *skb_new = dev_alloc_skb(len);\r\nif (unlikely(!skb_new))\r\ngoto failed;\r\nskb_reserve(skb_new, crypt->ops->extra_msdu_prefix_len);\r\nskb_put_data(skb_new, &header, hdr_len);\r\nsnapped = 1;\r\nlibipw_copy_snap(skb_put(skb_new, SNAP_SIZE + sizeof(u16)),\r\nether_type);\r\nskb_copy_from_linear_data(skb, skb_put(skb_new, skb->len), skb->len);\r\nres = crypt->ops->encrypt_msdu(skb_new, hdr_len, crypt->priv);\r\nif (res < 0) {\r\nLIBIPW_ERROR("msdu encryption failed\n");\r\ndev_kfree_skb_any(skb_new);\r\ngoto failed;\r\n}\r\ndev_kfree_skb_any(skb);\r\nskb = skb_new;\r\nbytes += crypt->ops->extra_msdu_prefix_len +\r\ncrypt->ops->extra_msdu_postfix_len;\r\nskb_pull(skb, hdr_len);\r\n}\r\nif (host_encrypt || ieee->host_open_frag) {\r\nif (is_multicast_ether_addr(dest) ||\r\nis_broadcast_ether_addr(dest))\r\nfrag_size = MAX_FRAG_THRESHOLD;\r\nelse\r\nfrag_size = ieee->fts;\r\nbytes_per_frag = frag_size - hdr_len;\r\nif (ieee->config &\r\n(CFG_LIBIPW_COMPUTE_FCS | CFG_LIBIPW_RESERVE_FCS))\r\nbytes_per_frag -= LIBIPW_FCS_LEN;\r\nif (host_encrypt)\r\nbytes_per_frag -= crypt->ops->extra_mpdu_prefix_len +\r\ncrypt->ops->extra_mpdu_postfix_len;\r\nnr_frags = bytes / bytes_per_frag;\r\nbytes_last_frag = bytes % bytes_per_frag;\r\nif (bytes_last_frag)\r\nnr_frags++;\r\nelse\r\nbytes_last_frag = bytes_per_frag;\r\n} else {\r\nnr_frags = 1;\r\nbytes_per_frag = bytes_last_frag = bytes;\r\nfrag_size = bytes + hdr_len;\r\n}\r\nrts_required = (frag_size > ieee->rts\r\n&& ieee->config & CFG_LIBIPW_RTS);\r\nif (rts_required)\r\nnr_frags++;\r\ntxb = libipw_alloc_txb(nr_frags, frag_size,\r\nieee->tx_headroom, GFP_ATOMIC);\r\nif (unlikely(!txb)) {\r\nprintk(KERN_WARNING "%s: Could not allocate TXB\n",\r\nieee->dev->name);\r\ngoto failed;\r\n}\r\ntxb->encrypted = encrypt;\r\nif (host_encrypt)\r\ntxb->payload_size = frag_size * (nr_frags - 1) +\r\nbytes_last_frag;\r\nelse\r\ntxb->payload_size = bytes;\r\nif (rts_required) {\r\nskb_frag = txb->fragments[0];\r\nfrag_hdr = skb_put(skb_frag, hdr_len);\r\nheader.frame_ctl =\r\ncpu_to_le16(IEEE80211_FTYPE_CTL | IEEE80211_STYPE_RTS);\r\nmemcpy(frag_hdr, &header, hdr_len);\r\nheader.frame_ctl = cpu_to_le16(fc);\r\nif (ieee->config &\r\n(CFG_LIBIPW_COMPUTE_FCS | CFG_LIBIPW_RESERVE_FCS))\r\nskb_put(skb_frag, 4);\r\ntxb->rts_included = 1;\r\ni = 1;\r\n} else\r\ni = 0;\r\nfor (; i < nr_frags; i++) {\r\nskb_frag = txb->fragments[i];\r\nif (host_encrypt)\r\nskb_reserve(skb_frag,\r\ncrypt->ops->extra_mpdu_prefix_len);\r\nfrag_hdr = skb_put_data(skb_frag, &header, hdr_len);\r\nif (i != nr_frags - 1) {\r\nfrag_hdr->frame_ctl =\r\ncpu_to_le16(fc | IEEE80211_FCTL_MOREFRAGS);\r\nbytes = bytes_per_frag;\r\n} else {\r\nbytes = bytes_last_frag;\r\n}\r\nif (i == 0 && !snapped) {\r\nlibipw_copy_snap(skb_put\r\n(skb_frag, SNAP_SIZE + sizeof(u16)),\r\nether_type);\r\nbytes -= SNAP_SIZE + sizeof(u16);\r\n}\r\nskb_copy_from_linear_data(skb, skb_put(skb_frag, bytes), bytes);\r\nskb_pull(skb, bytes);\r\nif (host_encrypt)\r\nlibipw_encrypt_fragment(ieee, skb_frag, hdr_len);\r\nif (ieee->config &\r\n(CFG_LIBIPW_COMPUTE_FCS | CFG_LIBIPW_RESERVE_FCS))\r\nskb_put(skb_frag, 4);\r\n}\r\nsuccess:\r\nspin_unlock_irqrestore(&ieee->lock, flags);\r\ndev_kfree_skb_any(skb);\r\nif (txb) {\r\nnetdev_tx_t ret = (*ieee->hard_start_xmit)(txb, dev, priority);\r\nif (ret == NETDEV_TX_OK) {\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += txb->payload_size;\r\nreturn NETDEV_TX_OK;\r\n}\r\nlibipw_txb_free(txb);\r\n}\r\nreturn NETDEV_TX_OK;\r\nfailed:\r\nspin_unlock_irqrestore(&ieee->lock, flags);\r\nnetif_stop_queue(dev);\r\ndev->stats.tx_errors++;\r\nreturn NETDEV_TX_BUSY;\r\n}
