static struct internal_dev *internal_dev_priv(struct net_device *netdev)\r\n{\r\nreturn netdev_priv(netdev);\r\n}\r\nstatic int internal_dev_xmit(struct sk_buff *skb, struct net_device *netdev)\r\n{\r\nint len, err;\r\nlen = skb->len;\r\nrcu_read_lock();\r\nerr = ovs_vport_receive(internal_dev_priv(netdev)->vport, skb, NULL);\r\nrcu_read_unlock();\r\nif (likely(!err)) {\r\nstruct pcpu_sw_netstats *tstats = this_cpu_ptr(netdev->tstats);\r\nu64_stats_update_begin(&tstats->syncp);\r\ntstats->tx_bytes += len;\r\ntstats->tx_packets++;\r\nu64_stats_update_end(&tstats->syncp);\r\n} else {\r\nnetdev->stats.tx_errors++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int internal_dev_open(struct net_device *netdev)\r\n{\r\nnetif_start_queue(netdev);\r\nreturn 0;\r\n}\r\nstatic int internal_dev_stop(struct net_device *netdev)\r\n{\r\nnetif_stop_queue(netdev);\r\nreturn 0;\r\n}\r\nstatic void internal_dev_getinfo(struct net_device *netdev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstrlcpy(info->driver, "openvswitch", sizeof(info->driver));\r\n}\r\nstatic void internal_dev_destructor(struct net_device *dev)\r\n{\r\nstruct vport *vport = ovs_internal_dev_get_vport(dev);\r\novs_vport_free(vport);\r\n}\r\nstatic void\r\ninternal_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)\r\n{\r\nint i;\r\nmemset(stats, 0, sizeof(*stats));\r\nstats->rx_errors = dev->stats.rx_errors;\r\nstats->tx_errors = dev->stats.tx_errors;\r\nstats->tx_dropped = dev->stats.tx_dropped;\r\nstats->rx_dropped = dev->stats.rx_dropped;\r\nfor_each_possible_cpu(i) {\r\nconst struct pcpu_sw_netstats *percpu_stats;\r\nstruct pcpu_sw_netstats local_stats;\r\nunsigned int start;\r\npercpu_stats = per_cpu_ptr(dev->tstats, i);\r\ndo {\r\nstart = u64_stats_fetch_begin_irq(&percpu_stats->syncp);\r\nlocal_stats = *percpu_stats;\r\n} while (u64_stats_fetch_retry_irq(&percpu_stats->syncp, start));\r\nstats->rx_bytes += local_stats.rx_bytes;\r\nstats->rx_packets += local_stats.rx_packets;\r\nstats->tx_bytes += local_stats.tx_bytes;\r\nstats->tx_packets += local_stats.tx_packets;\r\n}\r\n}\r\nstatic void internal_set_rx_headroom(struct net_device *dev, int new_hr)\r\n{\r\ndev->needed_headroom = new_hr < 0 ? 0 : new_hr;\r\n}\r\nstatic void do_setup(struct net_device *netdev)\r\n{\r\nether_setup(netdev);\r\nnetdev->max_mtu = ETH_MAX_MTU;\r\nnetdev->netdev_ops = &internal_dev_netdev_ops;\r\nnetdev->priv_flags &= ~IFF_TX_SKB_SHARING;\r\nnetdev->priv_flags |= IFF_LIVE_ADDR_CHANGE | IFF_OPENVSWITCH |\r\nIFF_PHONY_HEADROOM | IFF_NO_QUEUE;\r\nnetdev->needs_free_netdev = true;\r\nnetdev->priv_destructor = internal_dev_destructor;\r\nnetdev->ethtool_ops = &internal_dev_ethtool_ops;\r\nnetdev->rtnl_link_ops = &internal_dev_link_ops;\r\nnetdev->features = NETIF_F_LLTX | NETIF_F_SG | NETIF_F_FRAGLIST |\r\nNETIF_F_HIGHDMA | NETIF_F_HW_CSUM |\r\nNETIF_F_GSO_SOFTWARE | NETIF_F_GSO_ENCAP_ALL;\r\nnetdev->vlan_features = netdev->features;\r\nnetdev->hw_enc_features = netdev->features;\r\nnetdev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;\r\nnetdev->hw_features = netdev->features & ~NETIF_F_LLTX;\r\neth_hw_addr_random(netdev);\r\n}\r\nstatic struct vport *internal_dev_create(const struct vport_parms *parms)\r\n{\r\nstruct vport *vport;\r\nstruct internal_dev *internal_dev;\r\nint err;\r\nvport = ovs_vport_alloc(0, &ovs_internal_vport_ops, parms);\r\nif (IS_ERR(vport)) {\r\nerr = PTR_ERR(vport);\r\ngoto error;\r\n}\r\nvport->dev = alloc_netdev(sizeof(struct internal_dev),\r\nparms->name, NET_NAME_USER, do_setup);\r\nif (!vport->dev) {\r\nerr = -ENOMEM;\r\ngoto error_free_vport;\r\n}\r\nvport->dev->tstats = netdev_alloc_pcpu_stats(struct pcpu_sw_netstats);\r\nif (!vport->dev->tstats) {\r\nerr = -ENOMEM;\r\ngoto error_free_netdev;\r\n}\r\nvport->dev->needed_headroom = vport->dp->max_headroom;\r\ndev_net_set(vport->dev, ovs_dp_get_net(vport->dp));\r\ninternal_dev = internal_dev_priv(vport->dev);\r\ninternal_dev->vport = vport;\r\nif (vport->port_no == OVSP_LOCAL)\r\nvport->dev->features |= NETIF_F_NETNS_LOCAL;\r\nrtnl_lock();\r\nerr = register_netdevice(vport->dev);\r\nif (err)\r\ngoto error_unlock;\r\ndev_set_promiscuity(vport->dev, 1);\r\nrtnl_unlock();\r\nnetif_start_queue(vport->dev);\r\nreturn vport;\r\nerror_unlock:\r\nrtnl_unlock();\r\nfree_percpu(vport->dev->tstats);\r\nerror_free_netdev:\r\nfree_netdev(vport->dev);\r\nerror_free_vport:\r\novs_vport_free(vport);\r\nerror:\r\nreturn ERR_PTR(err);\r\n}\r\nstatic void internal_dev_destroy(struct vport *vport)\r\n{\r\nnetif_stop_queue(vport->dev);\r\nrtnl_lock();\r\ndev_set_promiscuity(vport->dev, -1);\r\nunregister_netdevice(vport->dev);\r\nfree_percpu(vport->dev->tstats);\r\nrtnl_unlock();\r\n}\r\nstatic netdev_tx_t internal_dev_recv(struct sk_buff *skb)\r\n{\r\nstruct net_device *netdev = skb->dev;\r\nstruct pcpu_sw_netstats *stats;\r\nif (unlikely(!(netdev->flags & IFF_UP))) {\r\nkfree_skb(skb);\r\nnetdev->stats.rx_dropped++;\r\nreturn NETDEV_TX_OK;\r\n}\r\nskb_dst_drop(skb);\r\nnf_reset(skb);\r\nsecpath_reset(skb);\r\nskb->pkt_type = PACKET_HOST;\r\nskb->protocol = eth_type_trans(skb, netdev);\r\nskb_postpull_rcsum(skb, eth_hdr(skb), ETH_HLEN);\r\nstats = this_cpu_ptr(netdev->tstats);\r\nu64_stats_update_begin(&stats->syncp);\r\nstats->rx_packets++;\r\nstats->rx_bytes += skb->len;\r\nu64_stats_update_end(&stats->syncp);\r\nnetif_rx(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nint ovs_is_internal_dev(const struct net_device *netdev)\r\n{\r\nreturn netdev->netdev_ops == &internal_dev_netdev_ops;\r\n}\r\nstruct vport *ovs_internal_dev_get_vport(struct net_device *netdev)\r\n{\r\nif (!ovs_is_internal_dev(netdev))\r\nreturn NULL;\r\nreturn internal_dev_priv(netdev)->vport;\r\n}\r\nint ovs_internal_dev_rtnl_link_register(void)\r\n{\r\nint err;\r\nerr = rtnl_link_register(&internal_dev_link_ops);\r\nif (err < 0)\r\nreturn err;\r\nerr = ovs_vport_ops_register(&ovs_internal_vport_ops);\r\nif (err < 0)\r\nrtnl_link_unregister(&internal_dev_link_ops);\r\nreturn err;\r\n}\r\nvoid ovs_internal_dev_rtnl_link_unregister(void)\r\n{\r\novs_vport_ops_unregister(&ovs_internal_vport_ops);\r\nrtnl_link_unregister(&internal_dev_link_ops);\r\n}
