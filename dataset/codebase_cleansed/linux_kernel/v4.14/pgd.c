pgd_t *get_pgd_slow(struct mm_struct *mm)\r\n{\r\npgd_t *new_pgd, *init_pgd;\r\npmd_t *new_pmd, *init_pmd;\r\npte_t *new_pte, *init_pte;\r\nnew_pgd = (pgd_t *)__get_free_pages(GFP_KERNEL, 0);\r\nif (!new_pgd)\r\ngoto no_pgd;\r\nmemset(new_pgd, 0, FIRST_KERNEL_PGD_NR * sizeof(pgd_t));\r\ninit_pgd = pgd_offset_k(0);\r\nmemcpy(new_pgd + FIRST_KERNEL_PGD_NR, init_pgd + FIRST_KERNEL_PGD_NR,\r\n(PTRS_PER_PGD - FIRST_KERNEL_PGD_NR) * sizeof(pgd_t));\r\nclean_dcache_area(new_pgd, PTRS_PER_PGD * sizeof(pgd_t));\r\nif (!vectors_high()) {\r\nnew_pmd = pmd_alloc(mm, (pud_t *)new_pgd, 0);\r\nif (!new_pmd)\r\ngoto no_pmd;\r\nnew_pte = pte_alloc_map(mm, new_pmd, 0);\r\nif (!new_pte)\r\ngoto no_pte;\r\ninit_pmd = pmd_offset((pud_t *)init_pgd, 0);\r\ninit_pte = pte_offset_map(init_pmd, 0);\r\nset_pte(new_pte, *init_pte);\r\npte_unmap(init_pte);\r\npte_unmap(new_pte);\r\n}\r\nreturn new_pgd;\r\nno_pte:\r\npmd_free(mm, new_pmd);\r\nmm_dec_nr_pmds(mm);\r\nno_pmd:\r\nfree_pages((unsigned long)new_pgd, 0);\r\nno_pgd:\r\nreturn NULL;\r\n}\r\nvoid free_pgd_slow(struct mm_struct *mm, pgd_t *pgd)\r\n{\r\npmd_t *pmd;\r\npgtable_t pte;\r\nif (!pgd)\r\nreturn;\r\npmd = pmd_off(pgd, 0);\r\nif (pmd_none(*pmd))\r\ngoto free;\r\nif (pmd_bad(*pmd)) {\r\npmd_ERROR(*pmd);\r\npmd_clear(pmd);\r\ngoto free;\r\n}\r\npte = pmd_pgtable(*pmd);\r\npmd_clear(pmd);\r\npte_free(mm, pte);\r\natomic_long_dec(&mm->nr_ptes);\r\npmd_free(mm, pmd);\r\nmm_dec_nr_pmds(mm);\r\nfree:\r\nfree_pages((unsigned long) pgd, 0);\r\n}
