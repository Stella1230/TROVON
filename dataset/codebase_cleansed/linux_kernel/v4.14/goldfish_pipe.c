static int goldfish_cmd_locked(struct goldfish_pipe *pipe, enum PipeCmdCode cmd)\r\n{\r\npipe->command_buffer->cmd = cmd;\r\npipe->command_buffer->status = PIPE_ERROR_INVAL;\r\nwritel(pipe->id, pipe->dev->base + PIPE_REG_CMD);\r\nreturn pipe->command_buffer->status;\r\n}\r\nstatic int goldfish_cmd(struct goldfish_pipe *pipe, enum PipeCmdCode cmd)\r\n{\r\nint status;\r\nif (mutex_lock_interruptible(&pipe->lock))\r\nreturn PIPE_ERROR_IO;\r\nstatus = goldfish_cmd_locked(pipe, cmd);\r\nmutex_unlock(&pipe->lock);\r\nreturn status;\r\n}\r\nstatic int goldfish_pipe_error_convert(int status)\r\n{\r\nswitch (status) {\r\ncase PIPE_ERROR_AGAIN:\r\nreturn -EAGAIN;\r\ncase PIPE_ERROR_NOMEM:\r\nreturn -ENOMEM;\r\ncase PIPE_ERROR_IO:\r\nreturn -EIO;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int pin_user_pages(unsigned long first_page, unsigned long last_page,\r\nunsigned int last_page_size, int is_write,\r\nstruct page *pages[MAX_BUFFERS_PER_COMMAND],\r\nunsigned int *iter_last_page_size)\r\n{\r\nint ret;\r\nint requested_pages = ((last_page - first_page) >> PAGE_SHIFT) + 1;\r\nif (requested_pages > MAX_BUFFERS_PER_COMMAND) {\r\nrequested_pages = MAX_BUFFERS_PER_COMMAND;\r\n*iter_last_page_size = PAGE_SIZE;\r\n} else {\r\n*iter_last_page_size = last_page_size;\r\n}\r\nret = get_user_pages_fast(\r\nfirst_page, requested_pages, !is_write, pages);\r\nif (ret <= 0)\r\nreturn -EFAULT;\r\nif (ret < requested_pages)\r\n*iter_last_page_size = PAGE_SIZE;\r\nreturn ret;\r\n}\r\nstatic void release_user_pages(struct page **pages, int pages_count,\r\nint is_write, s32 consumed_size)\r\n{\r\nint i;\r\nfor (i = 0; i < pages_count; i++) {\r\nif (!is_write && consumed_size > 0)\r\nset_page_dirty(pages[i]);\r\nput_page(pages[i]);\r\n}\r\n}\r\nstatic void populate_rw_params(\r\nstruct page **pages, int pages_count,\r\nunsigned long address, unsigned long address_end,\r\nunsigned long first_page, unsigned long last_page,\r\nunsigned int iter_last_page_size, int is_write,\r\nstruct goldfish_pipe_command *command)\r\n{\r\nunsigned long xaddr = page_to_phys(pages[0]);\r\nunsigned long xaddr_prev = xaddr;\r\nint buffer_idx = 0;\r\nint i = 1;\r\nint size_on_page = first_page == last_page\r\n? (int)(address_end - address)\r\n: (PAGE_SIZE - (address & ~PAGE_MASK));\r\ncommand->rw_params.ptrs[0] = (u64)(xaddr | (address & ~PAGE_MASK));\r\ncommand->rw_params.sizes[0] = size_on_page;\r\nfor (; i < pages_count; ++i) {\r\nxaddr = page_to_phys(pages[i]);\r\nsize_on_page = (i == pages_count - 1) ?\r\niter_last_page_size : PAGE_SIZE;\r\nif (xaddr == xaddr_prev + PAGE_SIZE) {\r\ncommand->rw_params.sizes[buffer_idx] += size_on_page;\r\n} else {\r\n++buffer_idx;\r\ncommand->rw_params.ptrs[buffer_idx] = (u64)xaddr;\r\ncommand->rw_params.sizes[buffer_idx] = size_on_page;\r\n}\r\nxaddr_prev = xaddr;\r\n}\r\ncommand->rw_params.buffers_count = buffer_idx + 1;\r\n}\r\nstatic int transfer_max_buffers(struct goldfish_pipe *pipe,\r\nunsigned long address, unsigned long address_end, int is_write,\r\nunsigned long last_page, unsigned int last_page_size,\r\ns32 *consumed_size, int *status)\r\n{\r\nstatic struct page *pages[MAX_BUFFERS_PER_COMMAND];\r\nunsigned long first_page = address & PAGE_MASK;\r\nunsigned int iter_last_page_size;\r\nint pages_count = pin_user_pages(first_page, last_page,\r\nlast_page_size, is_write,\r\npages, &iter_last_page_size);\r\nif (pages_count < 0)\r\nreturn pages_count;\r\nif (mutex_lock_interruptible(&pipe->lock))\r\nreturn -ERESTARTSYS;\r\npopulate_rw_params(pages, pages_count, address, address_end,\r\nfirst_page, last_page, iter_last_page_size, is_write,\r\npipe->command_buffer);\r\n*status = goldfish_cmd_locked(pipe,\r\nis_write ? PIPE_CMD_WRITE : PIPE_CMD_READ);\r\n*consumed_size = pipe->command_buffer->rw_params.consumed_size;\r\nrelease_user_pages(pages, pages_count, is_write, *consumed_size);\r\nmutex_unlock(&pipe->lock);\r\nreturn 0;\r\n}\r\nstatic int wait_for_host_signal(struct goldfish_pipe *pipe, int is_write)\r\n{\r\nu32 wakeBit = is_write ? BIT_WAKE_ON_WRITE : BIT_WAKE_ON_READ;\r\nset_bit(wakeBit, &pipe->flags);\r\n(void)goldfish_cmd(pipe,\r\nis_write ? PIPE_CMD_WAKE_ON_WRITE : PIPE_CMD_WAKE_ON_READ);\r\nwhile (test_bit(wakeBit, &pipe->flags)) {\r\nif (wait_event_interruptible(\r\npipe->wake_queue,\r\n!test_bit(wakeBit, &pipe->flags)))\r\nreturn -ERESTARTSYS;\r\nif (test_bit(BIT_CLOSED_ON_HOST, &pipe->flags))\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nstatic ssize_t goldfish_pipe_read_write(struct file *filp,\r\nchar __user *buffer, size_t bufflen, int is_write)\r\n{\r\nstruct goldfish_pipe *pipe = filp->private_data;\r\nint count = 0, ret = -EINVAL;\r\nunsigned long address, address_end, last_page;\r\nunsigned int last_page_size;\r\nif (unlikely(test_bit(BIT_CLOSED_ON_HOST, &pipe->flags)))\r\nreturn -EIO;\r\nif (unlikely(bufflen == 0))\r\nreturn 0;\r\nif (unlikely(!access_ok(is_write ? VERIFY_WRITE : VERIFY_READ,\r\nbuffer, bufflen)))\r\nreturn -EFAULT;\r\naddress = (unsigned long)buffer;\r\naddress_end = address + bufflen;\r\nlast_page = (address_end - 1) & PAGE_MASK;\r\nlast_page_size = ((address_end - 1) & ~PAGE_MASK) + 1;\r\nwhile (address < address_end) {\r\ns32 consumed_size;\r\nint status;\r\nret = transfer_max_buffers(pipe, address, address_end, is_write,\r\nlast_page, last_page_size, &consumed_size,\r\n&status);\r\nif (ret < 0)\r\nbreak;\r\nif (consumed_size > 0) {\r\ncount += consumed_size;\r\naddress += consumed_size;\r\n}\r\nif (status > 0)\r\ncontinue;\r\nif (status == 0) {\r\nret = 0;\r\nbreak;\r\n}\r\nif (count > 0) {\r\nif (status != PIPE_ERROR_AGAIN)\r\npr_info_ratelimited("goldfish_pipe: backend error %d on %s\n",\r\nstatus, is_write ? "write" : "read");\r\nbreak;\r\n}\r\nif (status != PIPE_ERROR_AGAIN ||\r\n(filp->f_flags & O_NONBLOCK) != 0) {\r\nret = goldfish_pipe_error_convert(status);\r\nbreak;\r\n}\r\nstatus = wait_for_host_signal(pipe, is_write);\r\nif (status < 0)\r\nreturn status;\r\n}\r\nif (count > 0)\r\nreturn count;\r\nreturn ret;\r\n}\r\nstatic ssize_t goldfish_pipe_read(struct file *filp, char __user *buffer,\r\nsize_t bufflen, loff_t *ppos)\r\n{\r\nreturn goldfish_pipe_read_write(filp, buffer, bufflen,\r\n0);\r\n}\r\nstatic ssize_t goldfish_pipe_write(struct file *filp,\r\nconst char __user *buffer, size_t bufflen,\r\nloff_t *ppos)\r\n{\r\nreturn goldfish_pipe_read_write(filp,\r\n(char __user *)buffer, bufflen,\r\n1);\r\n}\r\nstatic unsigned int goldfish_pipe_poll(struct file *filp, poll_table *wait)\r\n{\r\nstruct goldfish_pipe *pipe = filp->private_data;\r\nunsigned int mask = 0;\r\nint status;\r\npoll_wait(filp, &pipe->wake_queue, wait);\r\nstatus = goldfish_cmd(pipe, PIPE_CMD_POLL);\r\nif (status < 0)\r\nreturn -ERESTARTSYS;\r\nif (status & PIPE_POLL_IN)\r\nmask |= POLLIN | POLLRDNORM;\r\nif (status & PIPE_POLL_OUT)\r\nmask |= POLLOUT | POLLWRNORM;\r\nif (status & PIPE_POLL_HUP)\r\nmask |= POLLHUP;\r\nif (test_bit(BIT_CLOSED_ON_HOST, &pipe->flags))\r\nmask |= POLLERR;\r\nreturn mask;\r\n}\r\nstatic void signalled_pipes_add_locked(struct goldfish_pipe_dev *dev,\r\nu32 id, u32 flags)\r\n{\r\nstruct goldfish_pipe *pipe;\r\nif (WARN_ON(id >= dev->pipes_capacity))\r\nreturn;\r\npipe = dev->pipes[id];\r\nif (!pipe)\r\nreturn;\r\npipe->signalled_flags |= flags;\r\nif (pipe->prev_signalled || pipe->next_signalled\r\n|| dev->first_signalled_pipe == pipe)\r\nreturn;\r\npipe->next_signalled = dev->first_signalled_pipe;\r\nif (dev->first_signalled_pipe)\r\ndev->first_signalled_pipe->prev_signalled = pipe;\r\ndev->first_signalled_pipe = pipe;\r\n}\r\nstatic void signalled_pipes_remove_locked(struct goldfish_pipe_dev *dev,\r\nstruct goldfish_pipe *pipe) {\r\nif (pipe->prev_signalled)\r\npipe->prev_signalled->next_signalled = pipe->next_signalled;\r\nif (pipe->next_signalled)\r\npipe->next_signalled->prev_signalled = pipe->prev_signalled;\r\nif (pipe == dev->first_signalled_pipe)\r\ndev->first_signalled_pipe = pipe->next_signalled;\r\npipe->prev_signalled = NULL;\r\npipe->next_signalled = NULL;\r\n}\r\nstatic struct goldfish_pipe *signalled_pipes_pop_front(\r\nstruct goldfish_pipe_dev *dev, int *wakes)\r\n{\r\nstruct goldfish_pipe *pipe;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dev->lock, flags);\r\npipe = dev->first_signalled_pipe;\r\nif (pipe) {\r\n*wakes = pipe->signalled_flags;\r\npipe->signalled_flags = 0;\r\ndev->first_signalled_pipe = pipe->next_signalled;\r\nif (dev->first_signalled_pipe)\r\ndev->first_signalled_pipe->prev_signalled = NULL;\r\npipe->next_signalled = NULL;\r\n}\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nreturn pipe;\r\n}\r\nstatic void goldfish_interrupt_task(unsigned long unused)\r\n{\r\nstruct goldfish_pipe_dev *dev = pipe_dev;\r\nstruct goldfish_pipe *pipe;\r\nint wakes;\r\nwhile ((pipe = signalled_pipes_pop_front(dev, &wakes)) != NULL) {\r\nif (wakes & PIPE_WAKE_CLOSED) {\r\npipe->flags = 1 << BIT_CLOSED_ON_HOST;\r\n} else {\r\nif (wakes & PIPE_WAKE_READ)\r\nclear_bit(BIT_WAKE_ON_READ, &pipe->flags);\r\nif (wakes & PIPE_WAKE_WRITE)\r\nclear_bit(BIT_WAKE_ON_WRITE, &pipe->flags);\r\n}\r\nwake_up_interruptible(&pipe->wake_queue);\r\n}\r\n}\r\nstatic irqreturn_t goldfish_pipe_interrupt(int irq, void *dev_id)\r\n{\r\nu32 count;\r\nu32 i;\r\nunsigned long flags;\r\nstruct goldfish_pipe_dev *dev = dev_id;\r\nif (dev != pipe_dev)\r\nreturn IRQ_NONE;\r\nspin_lock_irqsave(&dev->lock, flags);\r\ncount = readl(dev->base + PIPE_REG_GET_SIGNALLED);\r\nif (count == 0) {\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nreturn IRQ_NONE;\r\n}\r\nif (count > MAX_SIGNALLED_PIPES)\r\ncount = MAX_SIGNALLED_PIPES;\r\nfor (i = 0; i < count; ++i)\r\nsignalled_pipes_add_locked(dev,\r\ndev->buffers->signalled_pipe_buffers[i].id,\r\ndev->buffers->signalled_pipe_buffers[i].flags);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\ntasklet_schedule(&goldfish_interrupt_tasklet);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int get_free_pipe_id_locked(struct goldfish_pipe_dev *dev)\r\n{\r\nint id;\r\nfor (id = 0; id < dev->pipes_capacity; ++id)\r\nif (!dev->pipes[id])\r\nreturn id;\r\n{\r\nu32 new_capacity = 2 * dev->pipes_capacity;\r\nstruct goldfish_pipe **pipes =\r\nkcalloc(new_capacity, sizeof(*pipes), GFP_ATOMIC);\r\nif (!pipes)\r\nreturn -ENOMEM;\r\nmemcpy(pipes, dev->pipes, sizeof(*pipes) * dev->pipes_capacity);\r\nkfree(dev->pipes);\r\ndev->pipes = pipes;\r\nid = dev->pipes_capacity;\r\ndev->pipes_capacity = new_capacity;\r\n}\r\nreturn id;\r\n}\r\nstatic int goldfish_pipe_open(struct inode *inode, struct file *file)\r\n{\r\nstruct goldfish_pipe_dev *dev = pipe_dev;\r\nunsigned long flags;\r\nint id;\r\nint status;\r\nstruct goldfish_pipe *pipe = kzalloc(sizeof(*pipe), GFP_KERNEL);\r\nif (pipe == NULL)\r\nreturn -ENOMEM;\r\npipe->dev = dev;\r\nmutex_init(&pipe->lock);\r\ninit_waitqueue_head(&pipe->wake_queue);\r\npipe->command_buffer =\r\n(struct goldfish_pipe_command *)__get_free_page(GFP_KERNEL);\r\nif (!pipe->command_buffer) {\r\nstatus = -ENOMEM;\r\ngoto err_pipe;\r\n}\r\nspin_lock_irqsave(&dev->lock, flags);\r\nid = get_free_pipe_id_locked(dev);\r\nif (id < 0) {\r\nstatus = id;\r\ngoto err_id_locked;\r\n}\r\ndev->pipes[id] = pipe;\r\npipe->id = id;\r\npipe->command_buffer->id = id;\r\ndev->buffers->open_command_params.rw_params_max_count =\r\nMAX_BUFFERS_PER_COMMAND;\r\ndev->buffers->open_command_params.command_buffer_ptr =\r\n(u64)(unsigned long)__pa(pipe->command_buffer);\r\nstatus = goldfish_cmd_locked(pipe, PIPE_CMD_OPEN);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nif (status < 0)\r\ngoto err_cmd;\r\nfile->private_data = pipe;\r\nreturn 0;\r\nerr_cmd:\r\nspin_lock_irqsave(&dev->lock, flags);\r\ndev->pipes[id] = NULL;\r\nerr_id_locked:\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nfree_page((unsigned long)pipe->command_buffer);\r\nerr_pipe:\r\nkfree(pipe);\r\nreturn status;\r\n}\r\nstatic int goldfish_pipe_release(struct inode *inode, struct file *filp)\r\n{\r\nunsigned long flags;\r\nstruct goldfish_pipe *pipe = filp->private_data;\r\nstruct goldfish_pipe_dev *dev = pipe->dev;\r\n(void)goldfish_cmd(pipe, PIPE_CMD_CLOSE);\r\nspin_lock_irqsave(&dev->lock, flags);\r\ndev->pipes[pipe->id] = NULL;\r\nsignalled_pipes_remove_locked(dev, pipe);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nfilp->private_data = NULL;\r\nfree_page((unsigned long)pipe->command_buffer);\r\nkfree(pipe);\r\nreturn 0;\r\n}\r\nstatic int goldfish_pipe_device_init(struct platform_device *pdev)\r\n{\r\nchar *page;\r\nstruct goldfish_pipe_dev *dev = pipe_dev;\r\nint err = devm_request_irq(&pdev->dev, dev->irq,\r\ngoldfish_pipe_interrupt,\r\nIRQF_SHARED, "goldfish_pipe", dev);\r\nif (err) {\r\ndev_err(&pdev->dev, "unable to allocate IRQ for v2\n");\r\nreturn err;\r\n}\r\nerr = misc_register(&goldfish_pipe_dev);\r\nif (err) {\r\ndev_err(&pdev->dev, "unable to register v2 device\n");\r\nreturn err;\r\n}\r\ndev->first_signalled_pipe = NULL;\r\ndev->pipes_capacity = INITIAL_PIPES_CAPACITY;\r\ndev->pipes = kcalloc(dev->pipes_capacity, sizeof(*dev->pipes),\r\nGFP_KERNEL);\r\nif (!dev->pipes)\r\nreturn -ENOMEM;\r\nif (WARN_ON(sizeof(*dev->buffers) > PAGE_SIZE))\r\nreturn -ENOMEM;\r\npage = (char *)__get_free_page(GFP_KERNEL);\r\nif (!page) {\r\nkfree(dev->pipes);\r\nreturn -ENOMEM;\r\n}\r\ndev->buffers = (struct goldfish_pipe_dev_buffers *)page;\r\n{\r\nu64 paddr = __pa(&dev->buffers->signalled_pipe_buffers);\r\nwritel((u32)(unsigned long)(paddr >> 32),\r\ndev->base + PIPE_REG_SIGNAL_BUFFER_HIGH);\r\nwritel((u32)(unsigned long)paddr,\r\ndev->base + PIPE_REG_SIGNAL_BUFFER);\r\nwritel((u32)MAX_SIGNALLED_PIPES,\r\ndev->base + PIPE_REG_SIGNAL_BUFFER_COUNT);\r\npaddr = __pa(&dev->buffers->open_command_params);\r\nwritel((u32)(unsigned long)(paddr >> 32),\r\ndev->base + PIPE_REG_OPEN_BUFFER_HIGH);\r\nwritel((u32)(unsigned long)paddr,\r\ndev->base + PIPE_REG_OPEN_BUFFER);\r\n}\r\nreturn 0;\r\n}\r\nstatic void goldfish_pipe_device_deinit(struct platform_device *pdev)\r\n{\r\nstruct goldfish_pipe_dev *dev = pipe_dev;\r\nmisc_deregister(&goldfish_pipe_dev);\r\nkfree(dev->pipes);\r\nfree_page((unsigned long)dev->buffers);\r\n}\r\nstatic int goldfish_pipe_probe(struct platform_device *pdev)\r\n{\r\nint err;\r\nstruct resource *r;\r\nstruct goldfish_pipe_dev *dev = pipe_dev;\r\nif (WARN_ON(sizeof(struct goldfish_pipe_command) > PAGE_SIZE))\r\nreturn -ENOMEM;\r\nWARN_ON(dev->base != NULL);\r\nspin_lock_init(&dev->lock);\r\nr = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (r == NULL || resource_size(r) < PAGE_SIZE) {\r\ndev_err(&pdev->dev, "can't allocate i/o page\n");\r\nreturn -EINVAL;\r\n}\r\ndev->base = devm_ioremap(&pdev->dev, r->start, PAGE_SIZE);\r\nif (dev->base == NULL) {\r\ndev_err(&pdev->dev, "ioremap failed\n");\r\nreturn -EINVAL;\r\n}\r\nr = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\r\nif (r == NULL) {\r\nerr = -EINVAL;\r\ngoto error;\r\n}\r\ndev->irq = r->start;\r\nwritel((u32)PIPE_DRIVER_VERSION, dev->base + PIPE_REG_VERSION);\r\ndev->version = readl(dev->base + PIPE_REG_VERSION);\r\nif (WARN_ON(dev->version < PIPE_CURRENT_DEVICE_VERSION))\r\nreturn -EINVAL;\r\nerr = goldfish_pipe_device_init(pdev);\r\nif (!err)\r\nreturn 0;\r\nerror:\r\ndev->base = NULL;\r\nreturn err;\r\n}\r\nstatic int goldfish_pipe_remove(struct platform_device *pdev)\r\n{\r\nstruct goldfish_pipe_dev *dev = pipe_dev;\r\ngoldfish_pipe_device_deinit(pdev);\r\ndev->base = NULL;\r\nreturn 0;\r\n}
