static u64 bgx_reg_read(struct bgx *bgx, u8 lmac, u64 offset)\r\n{\r\nvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\r\nreturn readq_relaxed(addr);\r\n}\r\nstatic void bgx_reg_write(struct bgx *bgx, u8 lmac, u64 offset, u64 val)\r\n{\r\nvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\r\nwriteq_relaxed(val, addr);\r\n}\r\nstatic void bgx_reg_modify(struct bgx *bgx, u8 lmac, u64 offset, u64 val)\r\n{\r\nvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\r\nwriteq_relaxed(val | readq_relaxed(addr), addr);\r\n}\r\nstatic int bgx_poll_reg(struct bgx *bgx, u8 lmac, u64 reg, u64 mask, bool zero)\r\n{\r\nint timeout = 100;\r\nu64 reg_val;\r\nwhile (timeout) {\r\nreg_val = bgx_reg_read(bgx, lmac, reg);\r\nif (zero && !(reg_val & mask))\r\nreturn 0;\r\nif (!zero && (reg_val & mask))\r\nreturn 0;\r\nusleep_range(1000, 2000);\r\ntimeout--;\r\n}\r\nreturn 1;\r\n}\r\nstatic void set_max_bgx_per_node(struct pci_dev *pdev)\r\n{\r\nu16 sdevid;\r\nif (max_bgx_per_node)\r\nreturn;\r\npci_read_config_word(pdev, PCI_SUBSYSTEM_ID, &sdevid);\r\nswitch (sdevid) {\r\ncase PCI_SUBSYS_DEVID_81XX_BGX:\r\ncase PCI_SUBSYS_DEVID_81XX_RGX:\r\nmax_bgx_per_node = MAX_BGX_PER_CN81XX;\r\nbreak;\r\ncase PCI_SUBSYS_DEVID_83XX_BGX:\r\nmax_bgx_per_node = MAX_BGX_PER_CN83XX;\r\nbreak;\r\ncase PCI_SUBSYS_DEVID_88XX_BGX:\r\ndefault:\r\nmax_bgx_per_node = MAX_BGX_PER_CN88XX;\r\nbreak;\r\n}\r\n}\r\nstatic struct bgx *get_bgx(int node, int bgx_idx)\r\n{\r\nint idx = (node * max_bgx_per_node) + bgx_idx;\r\nreturn bgx_vnic[idx];\r\n}\r\nunsigned bgx_get_map(int node)\r\n{\r\nint i;\r\nunsigned map = 0;\r\nfor (i = 0; i < max_bgx_per_node; i++) {\r\nif (bgx_vnic[(node * max_bgx_per_node) + i])\r\nmap |= (1 << i);\r\n}\r\nreturn map;\r\n}\r\nint bgx_get_lmac_count(int node, int bgx_idx)\r\n{\r\nstruct bgx *bgx;\r\nbgx = get_bgx(node, bgx_idx);\r\nif (bgx)\r\nreturn bgx->lmac_count;\r\nreturn 0;\r\n}\r\nvoid bgx_get_lmac_link_state(int node, int bgx_idx, int lmacid, void *status)\r\n{\r\nstruct bgx_link_status *link = (struct bgx_link_status *)status;\r\nstruct bgx *bgx;\r\nstruct lmac *lmac;\r\nbgx = get_bgx(node, bgx_idx);\r\nif (!bgx)\r\nreturn;\r\nlmac = &bgx->lmac[lmacid];\r\nlink->mac_type = lmac->lmac_type;\r\nlink->link_up = lmac->link_up;\r\nlink->duplex = lmac->last_duplex;\r\nlink->speed = lmac->last_speed;\r\n}\r\nconst u8 *bgx_get_lmac_mac(int node, int bgx_idx, int lmacid)\r\n{\r\nstruct bgx *bgx = get_bgx(node, bgx_idx);\r\nif (bgx)\r\nreturn bgx->lmac[lmacid].mac;\r\nreturn NULL;\r\n}\r\nvoid bgx_set_lmac_mac(int node, int bgx_idx, int lmacid, const u8 *mac)\r\n{\r\nstruct bgx *bgx = get_bgx(node, bgx_idx);\r\nif (!bgx)\r\nreturn;\r\nether_addr_copy(bgx->lmac[lmacid].mac, mac);\r\n}\r\nvoid bgx_lmac_rx_tx_enable(int node, int bgx_idx, int lmacid, bool enable)\r\n{\r\nstruct bgx *bgx = get_bgx(node, bgx_idx);\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nif (!bgx)\r\nreturn;\r\nlmac = &bgx->lmac[lmacid];\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\nif (enable)\r\ncfg |= CMR_PKT_RX_EN | CMR_PKT_TX_EN;\r\nelse\r\ncfg &= ~(CMR_PKT_RX_EN | CMR_PKT_TX_EN);\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nif (bgx->is_rgx)\r\nxcv_setup_link(enable ? lmac->link_up : 0, lmac->last_speed);\r\n}\r\nvoid bgx_lmac_get_pfc(int node, int bgx_idx, int lmacid, void *pause)\r\n{\r\nstruct pfc *pfc = (struct pfc *)pause;\r\nstruct bgx *bgx = get_bgx(node, bgx_idx);\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nif (!bgx)\r\nreturn;\r\nlmac = &bgx->lmac[lmacid];\r\nif (lmac->is_sgmii)\r\nreturn;\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_CBFC_CTL);\r\npfc->fc_rx = cfg & RX_EN;\r\npfc->fc_tx = cfg & TX_EN;\r\npfc->autoneg = 0;\r\n}\r\nvoid bgx_lmac_set_pfc(int node, int bgx_idx, int lmacid, void *pause)\r\n{\r\nstruct pfc *pfc = (struct pfc *)pause;\r\nstruct bgx *bgx = get_bgx(node, bgx_idx);\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nif (!bgx)\r\nreturn;\r\nlmac = &bgx->lmac[lmacid];\r\nif (lmac->is_sgmii)\r\nreturn;\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_CBFC_CTL);\r\ncfg &= ~(RX_EN | TX_EN);\r\ncfg |= (pfc->fc_rx ? RX_EN : 0x00);\r\ncfg |= (pfc->fc_tx ? TX_EN : 0x00);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_CBFC_CTL, cfg);\r\n}\r\nstatic void bgx_sgmii_change_link_state(struct lmac *lmac)\r\n{\r\nstruct bgx *bgx = lmac->bgx;\r\nu64 cmr_cfg;\r\nu64 port_cfg = 0;\r\nu64 misc_ctl = 0;\r\nbool tx_en, rx_en;\r\ncmr_cfg = bgx_reg_read(bgx, lmac->lmacid, BGX_CMRX_CFG);\r\ntx_en = cmr_cfg & CMR_PKT_TX_EN;\r\nrx_en = cmr_cfg & CMR_PKT_RX_EN;\r\ncmr_cfg &= ~(CMR_PKT_RX_EN | CMR_PKT_TX_EN);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_CMRX_CFG, cmr_cfg);\r\nif (bgx_poll_reg(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG,\r\nGMI_PORT_CFG_RX_IDLE, false)) {\r\ndev_err(&bgx->pdev->dev, "BGX%d LMAC%d GMI RX not idle\n",\r\nbgx->bgx_id, lmac->lmacid);\r\nreturn;\r\n}\r\nif (bgx_poll_reg(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG,\r\nGMI_PORT_CFG_TX_IDLE, false)) {\r\ndev_err(&bgx->pdev->dev, "BGX%d LMAC%d GMI TX not idle\n",\r\nbgx->bgx_id, lmac->lmacid);\r\nreturn;\r\n}\r\nport_cfg = bgx_reg_read(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG);\r\nmisc_ctl = bgx_reg_read(bgx, lmac->lmacid, BGX_GMP_PCS_MISCX_CTL);\r\nif (lmac->link_up) {\r\nmisc_ctl &= ~PCS_MISC_CTL_GMX_ENO;\r\nport_cfg &= ~GMI_PORT_CFG_DUPLEX;\r\nport_cfg |= (lmac->last_duplex << 2);\r\n} else {\r\nmisc_ctl |= PCS_MISC_CTL_GMX_ENO;\r\n}\r\nswitch (lmac->last_speed) {\r\ncase 10:\r\nport_cfg &= ~GMI_PORT_CFG_SPEED;\r\nport_cfg |= GMI_PORT_CFG_SPEED_MSB;\r\nport_cfg &= ~GMI_PORT_CFG_SLOT_TIME;\r\nmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\r\nmisc_ctl |= 50;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 64);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_BURST, 0);\r\nbreak;\r\ncase 100:\r\nport_cfg &= ~GMI_PORT_CFG_SPEED;\r\nport_cfg &= ~GMI_PORT_CFG_SPEED_MSB;\r\nport_cfg &= ~GMI_PORT_CFG_SLOT_TIME;\r\nmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\r\nmisc_ctl |= 5;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 64);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_BURST, 0);\r\nbreak;\r\ncase 1000:\r\nport_cfg |= GMI_PORT_CFG_SPEED;\r\nport_cfg &= ~GMI_PORT_CFG_SPEED_MSB;\r\nport_cfg |= GMI_PORT_CFG_SLOT_TIME;\r\nmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\r\nmisc_ctl |= 1;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 512);\r\nif (lmac->last_duplex)\r\nbgx_reg_write(bgx, lmac->lmacid,\r\nBGX_GMP_GMI_TXX_BURST, 0);\r\nelse\r\nbgx_reg_write(bgx, lmac->lmacid,\r\nBGX_GMP_GMI_TXX_BURST, 8192);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_PCS_MISCX_CTL, misc_ctl);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG, port_cfg);\r\ncmr_cfg |= (rx_en ? CMR_PKT_RX_EN : 0) | (tx_en ? CMR_PKT_TX_EN : 0);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_CMRX_CFG, cmr_cfg);\r\nif (bgx->is_rgx && (cmr_cfg & (CMR_PKT_RX_EN | CMR_PKT_TX_EN)))\r\nxcv_setup_link(lmac->link_up, lmac->last_speed);\r\n}\r\nstatic void bgx_lmac_handler(struct net_device *netdev)\r\n{\r\nstruct lmac *lmac = container_of(netdev, struct lmac, netdev);\r\nstruct phy_device *phydev;\r\nint link_changed = 0;\r\nif (!lmac)\r\nreturn;\r\nphydev = lmac->phydev;\r\nif (!phydev->link && lmac->last_link)\r\nlink_changed = -1;\r\nif (phydev->link &&\r\n(lmac->last_duplex != phydev->duplex ||\r\nlmac->last_link != phydev->link ||\r\nlmac->last_speed != phydev->speed)) {\r\nlink_changed = 1;\r\n}\r\nlmac->last_link = phydev->link;\r\nlmac->last_speed = phydev->speed;\r\nlmac->last_duplex = phydev->duplex;\r\nif (!link_changed)\r\nreturn;\r\nif (link_changed > 0)\r\nlmac->link_up = true;\r\nelse\r\nlmac->link_up = false;\r\nif (lmac->is_sgmii)\r\nbgx_sgmii_change_link_state(lmac);\r\nelse\r\nbgx_xaui_check_link(lmac);\r\n}\r\nu64 bgx_get_rx_stats(int node, int bgx_idx, int lmac, int idx)\r\n{\r\nstruct bgx *bgx;\r\nbgx = get_bgx(node, bgx_idx);\r\nif (!bgx)\r\nreturn 0;\r\nif (idx > 8)\r\nlmac = 0;\r\nreturn bgx_reg_read(bgx, lmac, BGX_CMRX_RX_STAT0 + (idx * 8));\r\n}\r\nu64 bgx_get_tx_stats(int node, int bgx_idx, int lmac, int idx)\r\n{\r\nstruct bgx *bgx;\r\nbgx = get_bgx(node, bgx_idx);\r\nif (!bgx)\r\nreturn 0;\r\nreturn bgx_reg_read(bgx, lmac, BGX_CMRX_TX_STAT0 + (idx * 8));\r\n}\r\nstatic void bgx_flush_dmac_addrs(struct bgx *bgx, int lmac)\r\n{\r\nu64 offset;\r\nwhile (bgx->lmac[lmac].dmac > 0) {\r\noffset = ((bgx->lmac[lmac].dmac - 1) * sizeof(u64)) +\r\n(lmac * MAX_DMAC_PER_LMAC * sizeof(u64));\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_DMACX_CAM + offset, 0);\r\nbgx->lmac[lmac].dmac--;\r\n}\r\n}\r\nvoid bgx_lmac_internal_loopback(int node, int bgx_idx,\r\nint lmac_idx, bool enable)\r\n{\r\nstruct bgx *bgx;\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nbgx = get_bgx(node, bgx_idx);\r\nif (!bgx)\r\nreturn;\r\nlmac = &bgx->lmac[lmac_idx];\r\nif (lmac->is_sgmii) {\r\ncfg = bgx_reg_read(bgx, lmac_idx, BGX_GMP_PCS_MRX_CTL);\r\nif (enable)\r\ncfg |= PCS_MRX_CTL_LOOPBACK1;\r\nelse\r\ncfg &= ~PCS_MRX_CTL_LOOPBACK1;\r\nbgx_reg_write(bgx, lmac_idx, BGX_GMP_PCS_MRX_CTL, cfg);\r\n} else {\r\ncfg = bgx_reg_read(bgx, lmac_idx, BGX_SPUX_CONTROL1);\r\nif (enable)\r\ncfg |= SPU_CTL_LOOPBACK;\r\nelse\r\ncfg &= ~SPU_CTL_LOOPBACK;\r\nbgx_reg_write(bgx, lmac_idx, BGX_SPUX_CONTROL1, cfg);\r\n}\r\n}\r\nstatic int bgx_lmac_sgmii_init(struct bgx *bgx, struct lmac *lmac)\r\n{\r\nint lmacid = lmac->lmacid;\r\nu64 cfg;\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_THRESH, 0x30);\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_RXX_JABBER, MAX_FRAME_SIZE);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND);\r\nif (cfg & 1)\r\nbgx_reg_write(bgx, lmacid, BGX_GMP_GMI_TXX_SGMII_CTL, 0);\r\nbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_PCS_MRX_CTL, PCS_MRX_CTL_RESET);\r\nif (bgx_poll_reg(bgx, lmacid, BGX_GMP_PCS_MRX_CTL,\r\nPCS_MRX_CTL_RESET, true)) {\r\ndev_err(&bgx->pdev->dev, "BGX PCS reset not completed\n");\r\nreturn -1;\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_GMP_PCS_MRX_CTL);\r\ncfg &= ~PCS_MRX_CTL_PWR_DN;\r\ncfg |= PCS_MRX_CTL_RST_AN;\r\nif (lmac->phydev) {\r\ncfg |= PCS_MRX_CTL_AN_EN;\r\n} else {\r\nif (cfg & PCS_MRX_CTL_AN_EN)\r\nlmac->autoneg = true;\r\n}\r\nbgx_reg_write(bgx, lmacid, BGX_GMP_PCS_MRX_CTL, cfg);\r\nif (lmac->lmac_type == BGX_MODE_QSGMII) {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_GMP_PCS_MISCX_CTL);\r\ncfg &= ~PCS_MISC_CTL_DISP_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_GMP_PCS_MISCX_CTL, cfg);\r\nreturn 0;\r\n}\r\nif ((lmac->lmac_type == BGX_MODE_SGMII) && lmac->phydev) {\r\nif (bgx_poll_reg(bgx, lmacid, BGX_GMP_PCS_MRX_STATUS,\r\nPCS_MRX_STATUS_AN_CPT, false)) {\r\ndev_err(&bgx->pdev->dev, "BGX AN_CPT not completed\n");\r\nreturn -1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int bgx_lmac_xaui_init(struct bgx *bgx, struct lmac *lmac)\r\n{\r\nu64 cfg;\r\nint lmacid = lmac->lmacid;\r\nbgx_reg_modify(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET);\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET, true)) {\r\ndev_err(&bgx->pdev->dev, "BGX SPU reset not completed\n");\r\nreturn -1;\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nbgx_reg_modify(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_LOW_POWER);\r\nif (lmac->lmac_type == BGX_MODE_RXAUI)\r\nbgx_reg_modify(bgx, lmacid, BGX_SPUX_MISC_CONTROL,\r\nSPU_MISC_CTL_INTLV_RDISP);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_MISC_CONTROL);\r\ncfg &= ~SPU_MISC_CTL_RX_DIS;\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_MISC_CONTROL, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_RX_INT);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_RX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_INT);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\r\nif (lmac->use_training) {\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LP_CUP, 0x00);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LD_CUP, 0x00);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LD_REP, 0x00);\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_SPUX_BR_PMD_CRTL, SPU_PMD_CRTL_TRAIN_EN);\r\n}\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_APPEND, SMU_TX_APPEND_FCS_D);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_FEC_CONTROL);\r\ncfg &= ~SPU_FEC_CTL_FEC_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_FEC_CONTROL, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_AN_CONTROL);\r\ncfg = cfg & ~(SPU_AN_CTL_AN_EN | SPU_AN_CTL_XNP_EN);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_AN_CONTROL, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_AN_ADV);\r\nif (lmac->lmac_type == BGX_MODE_10G_KR)\r\ncfg |= (1 << 23);\r\nelse if (lmac->lmac_type == BGX_MODE_40G_KR)\r\ncfg |= (1 << 24);\r\nelse\r\ncfg &= ~((1 << 23) | (1 << 24));\r\ncfg = cfg & (~((1ULL << 25) | (1ULL << 22) | (1ULL << 12)));\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_AN_ADV, cfg);\r\ncfg = bgx_reg_read(bgx, 0, BGX_SPU_DBG_CONTROL);\r\ncfg &= ~SPU_DBG_CTL_AN_ARB_LINK_CHK_EN;\r\nbgx_reg_write(bgx, 0, BGX_SPU_DBG_CONTROL, cfg);\r\nbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_CONTROL1);\r\ncfg &= ~SPU_CTL_LOW_POWER;\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_CONTROL1, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_CTL);\r\ncfg &= ~SMU_TX_CTL_UNI_EN;\r\ncfg |= SMU_TX_CTL_DIC_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_CTL, cfg);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_CBFC_CTL, ((0xffffULL << 32) |\r\nBCK_EN | DRP_EN | TX_EN | RX_EN));\r\nbgx_reg_write(bgx, lmacid,\r\nBGX_SMUX_TX_PAUSE_PKT_TIME, DEFAULT_PAUSE_TIME);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_PAUSE_PKT_INTERVAL);\r\ncfg &= ~0xFFFFull;\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_PAUSE_PKT_INTERVAL,\r\ncfg | (DEFAULT_PAUSE_TIME - 0x1000));\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_PAUSE_ZERO, 0x01);\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_THRESH, (0x100 - 1));\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_RX_JABBER, MAX_FRAME_SIZE);\r\nreturn 0;\r\n}\r\nstatic int bgx_xaui_check_link(struct lmac *lmac)\r\n{\r\nstruct bgx *bgx = lmac->bgx;\r\nint lmacid = lmac->lmacid;\r\nint lmac_type = lmac->lmac_type;\r\nu64 cfg;\r\nif (lmac->use_training) {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\r\nif (!(cfg & (1ull << 13))) {\r\ncfg = (1ull << 13) | (1ull << 14);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL);\r\ncfg |= (1ull << 0);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL, cfg);\r\nreturn -1;\r\n}\r\n}\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET, true)) {\r\ndev_err(&bgx->pdev->dev, "BGX SPU reset not completed\n");\r\nreturn -1;\r\n}\r\nif ((lmac_type == BGX_MODE_10G_KR) || (lmac_type == BGX_MODE_XFI) ||\r\n(lmac_type == BGX_MODE_40G_KR) || (lmac_type == BGX_MODE_XLAUI)) {\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_BR_STATUS1,\r\nSPU_BR_STATUS_BLK_LOCK, false)) {\r\ndev_err(&bgx->pdev->dev,\r\n"SPU_BR_STATUS_BLK_LOCK not completed\n");\r\nreturn -1;\r\n}\r\n} else {\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_BX_STATUS,\r\nSPU_BX_STATUS_RX_ALIGN, false)) {\r\ndev_err(&bgx->pdev->dev,\r\n"SPU_BX_STATUS_RX_ALIGN not completed\n");\r\nreturn -1;\r\n}\r\n}\r\nif (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) & SPU_STATUS2_RCVFLT)\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_SPUX_STATUS2, SPU_STATUS2_RCVFLT);\r\nif (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) & SPU_STATUS2_RCVFLT) {\r\ndev_err(&bgx->pdev->dev, "Receive fault, retry training\n");\r\nif (lmac->use_training) {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\r\nif (!(cfg & (1ull << 13))) {\r\ncfg = (1ull << 13) | (1ull << 14);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid,\r\nBGX_SPUX_BR_PMD_CRTL);\r\ncfg |= (1ull << 0);\r\nbgx_reg_write(bgx, lmacid,\r\nBGX_SPUX_BR_PMD_CRTL, cfg);\r\nreturn -1;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SMUX_CTL, SMU_CTL_RX_IDLE, false)) {\r\ndev_err(&bgx->pdev->dev, "SMU RX not idle\n");\r\nreturn -1;\r\n}\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SMUX_CTL, SMU_CTL_TX_IDLE, false)) {\r\ndev_err(&bgx->pdev->dev, "SMU TX not idle\n");\r\nreturn -1;\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_RX_CTL);\r\ncfg &= SMU_RX_CTL_STATUS;\r\nif (!cfg)\r\nreturn 0;\r\nbgx_lmac_xaui_init(bgx, lmac);\r\nreturn -1;\r\n}\r\nstatic void bgx_poll_for_sgmii_link(struct lmac *lmac)\r\n{\r\nu64 pcs_link, an_result;\r\nu8 speed;\r\npcs_link = bgx_reg_read(lmac->bgx, lmac->lmacid,\r\nBGX_GMP_PCS_MRX_STATUS);\r\nif (!(pcs_link & PCS_MRX_STATUS_LINK))\r\npcs_link = bgx_reg_read(lmac->bgx, lmac->lmacid,\r\nBGX_GMP_PCS_MRX_STATUS);\r\nif (bgx_poll_reg(lmac->bgx, lmac->lmacid, BGX_GMP_PCS_MRX_STATUS,\r\nPCS_MRX_STATUS_AN_CPT, false)) {\r\nlmac->link_up = false;\r\nlmac->last_speed = SPEED_UNKNOWN;\r\nlmac->last_duplex = DUPLEX_UNKNOWN;\r\ngoto next_poll;\r\n}\r\nlmac->link_up = ((pcs_link & PCS_MRX_STATUS_LINK) != 0) ? true : false;\r\nan_result = bgx_reg_read(lmac->bgx, lmac->lmacid,\r\nBGX_GMP_PCS_ANX_AN_RESULTS);\r\nspeed = (an_result >> 3) & 0x3;\r\nlmac->last_duplex = (an_result >> 1) & 0x1;\r\nswitch (speed) {\r\ncase 0:\r\nlmac->last_speed = 10;\r\nbreak;\r\ncase 1:\r\nlmac->last_speed = 100;\r\nbreak;\r\ncase 2:\r\nlmac->last_speed = 1000;\r\nbreak;\r\ndefault:\r\nlmac->link_up = false;\r\nlmac->last_speed = SPEED_UNKNOWN;\r\nlmac->last_duplex = DUPLEX_UNKNOWN;\r\nbreak;\r\n}\r\nnext_poll:\r\nif (lmac->last_link != lmac->link_up) {\r\nif (lmac->link_up)\r\nbgx_sgmii_change_link_state(lmac);\r\nlmac->last_link = lmac->link_up;\r\n}\r\nqueue_delayed_work(lmac->check_link, &lmac->dwork, HZ * 3);\r\n}\r\nstatic void bgx_poll_for_link(struct work_struct *work)\r\n{\r\nstruct lmac *lmac;\r\nu64 spu_link, smu_link;\r\nlmac = container_of(work, struct lmac, dwork.work);\r\nif (lmac->is_sgmii) {\r\nbgx_poll_for_sgmii_link(lmac);\r\nreturn;\r\n}\r\nbgx_reg_modify(lmac->bgx, lmac->lmacid,\r\nBGX_SPUX_STATUS1, SPU_STATUS1_RCV_LNK);\r\nbgx_poll_reg(lmac->bgx, lmac->lmacid, BGX_SPUX_STATUS1,\r\nSPU_STATUS1_RCV_LNK, false);\r\nspu_link = bgx_reg_read(lmac->bgx, lmac->lmacid, BGX_SPUX_STATUS1);\r\nsmu_link = bgx_reg_read(lmac->bgx, lmac->lmacid, BGX_SMUX_RX_CTL);\r\nif ((spu_link & SPU_STATUS1_RCV_LNK) &&\r\n!(smu_link & SMU_RX_CTL_STATUS)) {\r\nlmac->link_up = 1;\r\nif (lmac->lmac_type == BGX_MODE_XLAUI)\r\nlmac->last_speed = 40000;\r\nelse\r\nlmac->last_speed = 10000;\r\nlmac->last_duplex = 1;\r\n} else {\r\nlmac->link_up = 0;\r\nlmac->last_speed = SPEED_UNKNOWN;\r\nlmac->last_duplex = DUPLEX_UNKNOWN;\r\n}\r\nif (lmac->last_link != lmac->link_up) {\r\nif (lmac->link_up) {\r\nif (bgx_xaui_check_link(lmac)) {\r\nlmac->link_up = 0;\r\nlmac->last_speed = SPEED_UNKNOWN;\r\nlmac->last_duplex = DUPLEX_UNKNOWN;\r\n}\r\n}\r\nlmac->last_link = lmac->link_up;\r\n}\r\nqueue_delayed_work(lmac->check_link, &lmac->dwork, HZ * 2);\r\n}\r\nstatic int phy_interface_mode(u8 lmac_type)\r\n{\r\nif (lmac_type == BGX_MODE_QSGMII)\r\nreturn PHY_INTERFACE_MODE_QSGMII;\r\nif (lmac_type == BGX_MODE_RGMII)\r\nreturn PHY_INTERFACE_MODE_RGMII;\r\nreturn PHY_INTERFACE_MODE_SGMII;\r\n}\r\nstatic int bgx_lmac_enable(struct bgx *bgx, u8 lmacid)\r\n{\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nlmac = &bgx->lmac[lmacid];\r\nlmac->bgx = bgx;\r\nif ((lmac->lmac_type == BGX_MODE_SGMII) ||\r\n(lmac->lmac_type == BGX_MODE_QSGMII) ||\r\n(lmac->lmac_type == BGX_MODE_RGMII)) {\r\nlmac->is_sgmii = 1;\r\nif (bgx_lmac_sgmii_init(bgx, lmac))\r\nreturn -1;\r\n} else {\r\nlmac->is_sgmii = 0;\r\nif (bgx_lmac_xaui_init(bgx, lmac))\r\nreturn -1;\r\n}\r\nif (lmac->is_sgmii) {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND);\r\ncfg |= ((1ull << 2) | (1ull << 1));\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND, cfg);\r\nbgx_reg_write(bgx, lmacid, BGX_GMP_GMI_TXX_MIN_PKT, 60 - 1);\r\n} else {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_APPEND);\r\ncfg |= ((1ull << 2) | (1ull << 1));\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_APPEND, cfg);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_MIN_PKT, 60 + 4);\r\n}\r\nbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_RX_DMAC_CTL, 0x03);\r\nif ((lmac->lmac_type != BGX_MODE_XFI) &&\r\n(lmac->lmac_type != BGX_MODE_XLAUI) &&\r\n(lmac->lmac_type != BGX_MODE_40G_KR) &&\r\n(lmac->lmac_type != BGX_MODE_10G_KR)) {\r\nif (!lmac->phydev) {\r\nif (lmac->autoneg) {\r\nbgx_reg_write(bgx, lmacid,\r\nBGX_GMP_PCS_LINKX_TIMER,\r\nPCS_LINKX_TIMER_COUNT);\r\ngoto poll;\r\n} else {\r\nlmac->link_up = true;\r\nlmac->last_speed = 1000;\r\nlmac->last_duplex = 1;\r\nbgx_sgmii_change_link_state(lmac);\r\nreturn 0;\r\n}\r\n}\r\nlmac->phydev->dev_flags = 0;\r\nif (phy_connect_direct(&lmac->netdev, lmac->phydev,\r\nbgx_lmac_handler,\r\nphy_interface_mode(lmac->lmac_type)))\r\nreturn -ENODEV;\r\nphy_start_aneg(lmac->phydev);\r\nreturn 0;\r\n}\r\npoll:\r\nlmac->check_link = alloc_workqueue("check_link", WQ_UNBOUND |\r\nWQ_MEM_RECLAIM, 1);\r\nif (!lmac->check_link)\r\nreturn -ENOMEM;\r\nINIT_DELAYED_WORK(&lmac->dwork, bgx_poll_for_link);\r\nqueue_delayed_work(lmac->check_link, &lmac->dwork, 0);\r\nreturn 0;\r\n}\r\nstatic void bgx_lmac_disable(struct bgx *bgx, u8 lmacid)\r\n{\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nlmac = &bgx->lmac[lmacid];\r\nif (lmac->check_link) {\r\ncancel_delayed_work_sync(&lmac->dwork);\r\ndestroy_workqueue(lmac->check_link);\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_PKT_RX_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nbgx_poll_reg(bgx, lmacid, BGX_CMRX_RX_FIFO_LEN, (u64)0x1FFF, true);\r\nbgx_poll_reg(bgx, lmacid, BGX_CMRX_TX_FIFO_LEN, (u64)0x3FFF, true);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_PKT_TX_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nif (!lmac->is_sgmii)\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_SPUX_CONTROL1, SPU_CTL_LOW_POWER);\r\nelse\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_GMP_PCS_MRX_CTL, PCS_MRX_CTL_PWR_DN);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nbgx_flush_dmac_addrs(bgx, lmacid);\r\nif ((lmac->lmac_type != BGX_MODE_XFI) &&\r\n(lmac->lmac_type != BGX_MODE_XLAUI) &&\r\n(lmac->lmac_type != BGX_MODE_40G_KR) &&\r\n(lmac->lmac_type != BGX_MODE_10G_KR) && lmac->phydev)\r\nphy_disconnect(lmac->phydev);\r\nlmac->phydev = NULL;\r\n}\r\nstatic void bgx_init_hw(struct bgx *bgx)\r\n{\r\nint i;\r\nstruct lmac *lmac;\r\nbgx_reg_modify(bgx, 0, BGX_CMR_GLOBAL_CFG, CMR_GLOBAL_CFG_FCS_STRIP);\r\nif (bgx_reg_read(bgx, 0, BGX_CMR_BIST_STATUS))\r\ndev_err(&bgx->pdev->dev, "BGX%d BIST failed\n", bgx->bgx_id);\r\nfor (i = 0; i < bgx->lmac_count; i++) {\r\nlmac = &bgx->lmac[i];\r\nbgx_reg_write(bgx, i, BGX_CMRX_CFG,\r\n(lmac->lmac_type << 8) | lmac->lane_to_sds);\r\nbgx->lmac[i].lmacid_bd = lmac_count;\r\nlmac_count++;\r\n}\r\nbgx_reg_write(bgx, 0, BGX_CMR_TX_LMACS, bgx->lmac_count);\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_LMACS, bgx->lmac_count);\r\nfor (i = 0; i < bgx->lmac_count; i++)\r\nbgx_reg_modify(bgx, 0, BGX_CMR_CHAN_MSK_AND,\r\n((1ULL << MAX_BGX_CHANS_PER_LMAC) - 1) <<\r\n(i * MAX_BGX_CHANS_PER_LMAC));\r\nfor (i = 0; i < RX_DMAC_COUNT; i++)\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_DMACX_CAM + (i * 8), 0x00);\r\nfor (i = 0; i < RX_TRAFFIC_STEER_RULE_COUNT; i++)\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_STREERING + (i * 8), 0x00);\r\n}\r\nstatic u8 bgx_get_lane2sds_cfg(struct bgx *bgx, struct lmac *lmac)\r\n{\r\nreturn (u8)(bgx_reg_read(bgx, lmac->lmacid, BGX_CMRX_CFG) & 0xFF);\r\n}\r\nstatic void bgx_print_qlm_mode(struct bgx *bgx, u8 lmacid)\r\n{\r\nstruct device *dev = &bgx->pdev->dev;\r\nstruct lmac *lmac;\r\nchar str[27];\r\nif (!bgx->is_dlm && lmacid)\r\nreturn;\r\nlmac = &bgx->lmac[lmacid];\r\nif (!bgx->is_dlm)\r\nsprintf(str, "BGX%d QLM mode", bgx->bgx_id);\r\nelse\r\nsprintf(str, "BGX%d LMAC%d mode", bgx->bgx_id, lmacid);\r\nswitch (lmac->lmac_type) {\r\ncase BGX_MODE_SGMII:\r\ndev_info(dev, "%s: SGMII\n", (char *)str);\r\nbreak;\r\ncase BGX_MODE_XAUI:\r\ndev_info(dev, "%s: XAUI\n", (char *)str);\r\nbreak;\r\ncase BGX_MODE_RXAUI:\r\ndev_info(dev, "%s: RXAUI\n", (char *)str);\r\nbreak;\r\ncase BGX_MODE_XFI:\r\nif (!lmac->use_training)\r\ndev_info(dev, "%s: XFI\n", (char *)str);\r\nelse\r\ndev_info(dev, "%s: 10G_KR\n", (char *)str);\r\nbreak;\r\ncase BGX_MODE_XLAUI:\r\nif (!lmac->use_training)\r\ndev_info(dev, "%s: XLAUI\n", (char *)str);\r\nelse\r\ndev_info(dev, "%s: 40G_KR4\n", (char *)str);\r\nbreak;\r\ncase BGX_MODE_QSGMII:\r\ndev_info(dev, "%s: QSGMII\n", (char *)str);\r\nbreak;\r\ncase BGX_MODE_RGMII:\r\ndev_info(dev, "%s: RGMII\n", (char *)str);\r\nbreak;\r\ncase BGX_MODE_INVALID:\r\nbreak;\r\n}\r\n}\r\nstatic void lmac_set_lane2sds(struct bgx *bgx, struct lmac *lmac)\r\n{\r\nswitch (lmac->lmac_type) {\r\ncase BGX_MODE_SGMII:\r\ncase BGX_MODE_XFI:\r\nlmac->lane_to_sds = lmac->lmacid;\r\nbreak;\r\ncase BGX_MODE_XAUI:\r\ncase BGX_MODE_XLAUI:\r\ncase BGX_MODE_RGMII:\r\nlmac->lane_to_sds = 0xE4;\r\nbreak;\r\ncase BGX_MODE_RXAUI:\r\nlmac->lane_to_sds = (lmac->lmacid) ? 0xE : 0x4;\r\nbreak;\r\ncase BGX_MODE_QSGMII:\r\nlmac->lane_to_sds = bgx_get_lane2sds_cfg(bgx, lmac);\r\nbreak;\r\ndefault:\r\nlmac->lane_to_sds = 0;\r\nbreak;\r\n}\r\n}\r\nstatic void lmac_set_training(struct bgx *bgx, struct lmac *lmac, int lmacid)\r\n{\r\nif ((lmac->lmac_type != BGX_MODE_10G_KR) &&\r\n(lmac->lmac_type != BGX_MODE_40G_KR)) {\r\nlmac->use_training = 0;\r\nreturn;\r\n}\r\nlmac->use_training = bgx_reg_read(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL) &\r\nSPU_PMD_CRTL_TRAIN_EN;\r\n}\r\nstatic void bgx_set_lmac_config(struct bgx *bgx, u8 idx)\r\n{\r\nstruct lmac *lmac;\r\nu64 cmr_cfg;\r\nu8 lmac_type;\r\nu8 lane_to_sds;\r\nlmac = &bgx->lmac[idx];\r\nif (!bgx->is_dlm || bgx->is_rgx) {\r\ncmr_cfg = bgx_reg_read(bgx, 0, BGX_CMRX_CFG);\r\nlmac->lmac_type = (cmr_cfg >> 8) & 0x07;\r\nif (bgx->is_rgx)\r\nlmac->lmac_type = BGX_MODE_RGMII;\r\nlmac_set_training(bgx, lmac, 0);\r\nlmac_set_lane2sds(bgx, lmac);\r\nreturn;\r\n}\r\ncmr_cfg = bgx_reg_read(bgx, idx, BGX_CMRX_CFG);\r\nlmac_type = (u8)((cmr_cfg >> 8) & 0x07);\r\nlane_to_sds = (u8)(cmr_cfg & 0xFF);\r\nif ((lmac_type == 0) && (lane_to_sds == 0xE4))\r\nlmac->lmac_type = BGX_MODE_INVALID;\r\nelse\r\nlmac->lmac_type = lmac_type;\r\nlmac->lane_to_sds = lane_to_sds;\r\nlmac_set_training(bgx, lmac, lmac->lmacid);\r\n}\r\nstatic void bgx_get_qlm_mode(struct bgx *bgx)\r\n{\r\nstruct lmac *lmac;\r\nu8 idx;\r\nfor (idx = 0; idx < bgx->max_lmac; idx++) {\r\nlmac = &bgx->lmac[idx];\r\nlmac->lmacid = idx;\r\nlmac->lmac_type = BGX_MODE_INVALID;\r\nlmac->use_training = false;\r\n}\r\nbgx->lmac_count = bgx_reg_read(bgx, 0, BGX_CMR_RX_LMACS) & 0x7;\r\nif (bgx->lmac_count > bgx->max_lmac)\r\nbgx->lmac_count = bgx->max_lmac;\r\nfor (idx = 0; idx < bgx->lmac_count; idx++) {\r\nbgx_set_lmac_config(bgx, idx);\r\nbgx_print_qlm_mode(bgx, idx);\r\n}\r\n}\r\nstatic int acpi_get_mac_address(struct device *dev, struct acpi_device *adev,\r\nu8 *dst)\r\n{\r\nu8 mac[ETH_ALEN];\r\nint ret;\r\nret = fwnode_property_read_u8_array(acpi_fwnode_handle(adev),\r\n"mac-address", mac, ETH_ALEN);\r\nif (ret)\r\ngoto out;\r\nif (!is_valid_ether_addr(mac)) {\r\ndev_err(dev, "MAC address invalid: %pM\n", mac);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\ndev_info(dev, "MAC address set to: %pM\n", mac);\r\nmemcpy(dst, mac, ETH_ALEN);\r\nout:\r\nreturn ret;\r\n}\r\nstatic acpi_status bgx_acpi_register_phy(acpi_handle handle,\r\nu32 lvl, void *context, void **rv)\r\n{\r\nstruct bgx *bgx = context;\r\nstruct device *dev = &bgx->pdev->dev;\r\nstruct acpi_device *adev;\r\nif (acpi_bus_get_device(handle, &adev))\r\ngoto out;\r\nacpi_get_mac_address(dev, adev, bgx->lmac[bgx->acpi_lmac_idx].mac);\r\nSET_NETDEV_DEV(&bgx->lmac[bgx->acpi_lmac_idx].netdev, dev);\r\nbgx->lmac[bgx->acpi_lmac_idx].lmacid = bgx->acpi_lmac_idx;\r\nbgx->acpi_lmac_idx++;\r\nout:\r\nreturn AE_OK;\r\n}\r\nstatic acpi_status bgx_acpi_match_id(acpi_handle handle, u32 lvl,\r\nvoid *context, void **ret_val)\r\n{\r\nstruct acpi_buffer string = { ACPI_ALLOCATE_BUFFER, NULL };\r\nstruct bgx *bgx = context;\r\nchar bgx_sel[5];\r\nsnprintf(bgx_sel, 5, "BGX%d", bgx->bgx_id);\r\nif (ACPI_FAILURE(acpi_get_name(handle, ACPI_SINGLE_NAME, &string))) {\r\npr_warn("Invalid link device\n");\r\nreturn AE_OK;\r\n}\r\nif (strncmp(string.pointer, bgx_sel, 4))\r\nreturn AE_OK;\r\nacpi_walk_namespace(ACPI_TYPE_DEVICE, handle, 1,\r\nbgx_acpi_register_phy, NULL, bgx, NULL);\r\nkfree(string.pointer);\r\nreturn AE_CTRL_TERMINATE;\r\n}\r\nstatic int bgx_init_acpi_phy(struct bgx *bgx)\r\n{\r\nacpi_get_devices(NULL, bgx_acpi_match_id, bgx, (void **)NULL);\r\nreturn 0;\r\n}\r\nstatic int bgx_init_acpi_phy(struct bgx *bgx)\r\n{\r\nreturn -ENODEV;\r\n}\r\nstatic int bgx_init_of_phy(struct bgx *bgx)\r\n{\r\nstruct fwnode_handle *fwn;\r\nstruct device_node *node = NULL;\r\nu8 lmac = 0;\r\ndevice_for_each_child_node(&bgx->pdev->dev, fwn) {\r\nstruct phy_device *pd;\r\nstruct device_node *phy_np;\r\nconst char *mac;\r\nnode = to_of_node(fwn);\r\nif (!node)\r\nbreak;\r\nmac = of_get_mac_address(node);\r\nif (mac)\r\nether_addr_copy(bgx->lmac[lmac].mac, mac);\r\nSET_NETDEV_DEV(&bgx->lmac[lmac].netdev, &bgx->pdev->dev);\r\nbgx->lmac[lmac].lmacid = lmac;\r\nphy_np = of_parse_phandle(node, "phy-handle", 0);\r\nif (phy_np &&\r\n!of_device_is_compatible(phy_np, "cortina,cs4223-slice")) {\r\npd = of_phy_find_device(phy_np);\r\nif (!pd)\r\ngoto defer;\r\nbgx->lmac[lmac].phydev = pd;\r\n}\r\nlmac++;\r\nif (lmac == bgx->max_lmac) {\r\nof_node_put(node);\r\nbreak;\r\n}\r\n}\r\nreturn 0;\r\ndefer:\r\nwhile (lmac) {\r\nif (bgx->lmac[lmac].phydev) {\r\nput_device(&bgx->lmac[lmac].phydev->mdio.dev);\r\nbgx->lmac[lmac].phydev = NULL;\r\n}\r\nlmac--;\r\n}\r\nof_node_put(node);\r\nreturn -EPROBE_DEFER;\r\n}\r\nstatic int bgx_init_of_phy(struct bgx *bgx)\r\n{\r\nreturn -ENODEV;\r\n}\r\nstatic int bgx_init_phy(struct bgx *bgx)\r\n{\r\nif (!acpi_disabled)\r\nreturn bgx_init_acpi_phy(bgx);\r\nreturn bgx_init_of_phy(bgx);\r\n}\r\nstatic int bgx_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint err;\r\nstruct device *dev = &pdev->dev;\r\nstruct bgx *bgx = NULL;\r\nu8 lmac;\r\nu16 sdevid;\r\nbgx = devm_kzalloc(dev, sizeof(*bgx), GFP_KERNEL);\r\nif (!bgx)\r\nreturn -ENOMEM;\r\nbgx->pdev = pdev;\r\npci_set_drvdata(pdev, bgx);\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(dev, "Failed to enable PCI device\n");\r\npci_set_drvdata(pdev, NULL);\r\nreturn err;\r\n}\r\nerr = pci_request_regions(pdev, DRV_NAME);\r\nif (err) {\r\ndev_err(dev, "PCI request regions failed 0x%x\n", err);\r\ngoto err_disable_device;\r\n}\r\nbgx->reg_base = pcim_iomap(pdev, PCI_CFG_REG_BAR_NUM, 0);\r\nif (!bgx->reg_base) {\r\ndev_err(dev, "BGX: Cannot map CSR memory space, aborting\n");\r\nerr = -ENOMEM;\r\ngoto err_release_regions;\r\n}\r\nset_max_bgx_per_node(pdev);\r\npci_read_config_word(pdev, PCI_DEVICE_ID, &sdevid);\r\nif (sdevid != PCI_DEVICE_ID_THUNDER_RGX) {\r\nbgx->bgx_id = (pci_resource_start(pdev,\r\nPCI_CFG_REG_BAR_NUM) >> 24) & BGX_ID_MASK;\r\nbgx->bgx_id += nic_get_node_id(pdev) * max_bgx_per_node;\r\nbgx->max_lmac = MAX_LMAC_PER_BGX;\r\nbgx_vnic[bgx->bgx_id] = bgx;\r\n} else {\r\nbgx->is_rgx = true;\r\nbgx->max_lmac = 1;\r\nbgx->bgx_id = MAX_BGX_PER_CN81XX - 1;\r\nbgx_vnic[bgx->bgx_id] = bgx;\r\nxcv_init_hw();\r\n}\r\npci_read_config_word(pdev, PCI_SUBSYSTEM_ID, &sdevid);\r\nif ((sdevid == PCI_SUBSYS_DEVID_81XX_BGX) ||\r\n((sdevid == PCI_SUBSYS_DEVID_83XX_BGX) && (bgx->bgx_id == 2)))\r\nbgx->is_dlm = true;\r\nbgx_get_qlm_mode(bgx);\r\nerr = bgx_init_phy(bgx);\r\nif (err)\r\ngoto err_enable;\r\nbgx_init_hw(bgx);\r\nfor (lmac = 0; lmac < bgx->lmac_count; lmac++) {\r\nerr = bgx_lmac_enable(bgx, lmac);\r\nif (err) {\r\ndev_err(dev, "BGX%d failed to enable lmac%d\n",\r\nbgx->bgx_id, lmac);\r\nwhile (lmac)\r\nbgx_lmac_disable(bgx, --lmac);\r\ngoto err_enable;\r\n}\r\n}\r\nreturn 0;\r\nerr_enable:\r\nbgx_vnic[bgx->bgx_id] = NULL;\r\nerr_release_regions:\r\npci_release_regions(pdev);\r\nerr_disable_device:\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\nreturn err;\r\n}\r\nstatic void bgx_remove(struct pci_dev *pdev)\r\n{\r\nstruct bgx *bgx = pci_get_drvdata(pdev);\r\nu8 lmac;\r\nfor (lmac = 0; lmac < bgx->lmac_count; lmac++)\r\nbgx_lmac_disable(bgx, lmac);\r\nbgx_vnic[bgx->bgx_id] = NULL;\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\n}\r\nstatic int __init bgx_init_module(void)\r\n{\r\npr_info("%s, ver %s\n", DRV_NAME, DRV_VERSION);\r\nreturn pci_register_driver(&bgx_driver);\r\n}\r\nstatic void __exit bgx_cleanup_module(void)\r\n{\r\npci_unregister_driver(&bgx_driver);\r\n}
