static bool zswap_is_full(void)\r\n{\r\nreturn totalram_pages * zswap_max_pool_percent / 100 <\r\nDIV_ROUND_UP(zswap_pool_total_size, PAGE_SIZE);\r\n}\r\nstatic void zswap_update_total_size(void)\r\n{\r\nstruct zswap_pool *pool;\r\nu64 total = 0;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(pool, &zswap_pools, list)\r\ntotal += zpool_get_total_size(pool->zpool);\r\nrcu_read_unlock();\r\nzswap_pool_total_size = total;\r\n}\r\nstatic int __init zswap_entry_cache_create(void)\r\n{\r\nzswap_entry_cache = KMEM_CACHE(zswap_entry, 0);\r\nreturn zswap_entry_cache == NULL;\r\n}\r\nstatic void __init zswap_entry_cache_destroy(void)\r\n{\r\nkmem_cache_destroy(zswap_entry_cache);\r\n}\r\nstatic struct zswap_entry *zswap_entry_cache_alloc(gfp_t gfp)\r\n{\r\nstruct zswap_entry *entry;\r\nentry = kmem_cache_alloc(zswap_entry_cache, gfp);\r\nif (!entry)\r\nreturn NULL;\r\nentry->refcount = 1;\r\nRB_CLEAR_NODE(&entry->rbnode);\r\nreturn entry;\r\n}\r\nstatic void zswap_entry_cache_free(struct zswap_entry *entry)\r\n{\r\nkmem_cache_free(zswap_entry_cache, entry);\r\n}\r\nstatic struct zswap_entry *zswap_rb_search(struct rb_root *root, pgoff_t offset)\r\n{\r\nstruct rb_node *node = root->rb_node;\r\nstruct zswap_entry *entry;\r\nwhile (node) {\r\nentry = rb_entry(node, struct zswap_entry, rbnode);\r\nif (entry->offset > offset)\r\nnode = node->rb_left;\r\nelse if (entry->offset < offset)\r\nnode = node->rb_right;\r\nelse\r\nreturn entry;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int zswap_rb_insert(struct rb_root *root, struct zswap_entry *entry,\r\nstruct zswap_entry **dupentry)\r\n{\r\nstruct rb_node **link = &root->rb_node, *parent = NULL;\r\nstruct zswap_entry *myentry;\r\nwhile (*link) {\r\nparent = *link;\r\nmyentry = rb_entry(parent, struct zswap_entry, rbnode);\r\nif (myentry->offset > entry->offset)\r\nlink = &(*link)->rb_left;\r\nelse if (myentry->offset < entry->offset)\r\nlink = &(*link)->rb_right;\r\nelse {\r\n*dupentry = myentry;\r\nreturn -EEXIST;\r\n}\r\n}\r\nrb_link_node(&entry->rbnode, parent, link);\r\nrb_insert_color(&entry->rbnode, root);\r\nreturn 0;\r\n}\r\nstatic void zswap_rb_erase(struct rb_root *root, struct zswap_entry *entry)\r\n{\r\nif (!RB_EMPTY_NODE(&entry->rbnode)) {\r\nrb_erase(&entry->rbnode, root);\r\nRB_CLEAR_NODE(&entry->rbnode);\r\n}\r\n}\r\nstatic void zswap_free_entry(struct zswap_entry *entry)\r\n{\r\nzpool_free(entry->pool->zpool, entry->handle);\r\nzswap_pool_put(entry->pool);\r\nzswap_entry_cache_free(entry);\r\natomic_dec(&zswap_stored_pages);\r\nzswap_update_total_size();\r\n}\r\nstatic void zswap_entry_get(struct zswap_entry *entry)\r\n{\r\nentry->refcount++;\r\n}\r\nstatic void zswap_entry_put(struct zswap_tree *tree,\r\nstruct zswap_entry *entry)\r\n{\r\nint refcount = --entry->refcount;\r\nBUG_ON(refcount < 0);\r\nif (refcount == 0) {\r\nzswap_rb_erase(&tree->rbroot, entry);\r\nzswap_free_entry(entry);\r\n}\r\n}\r\nstatic struct zswap_entry *zswap_entry_find_get(struct rb_root *root,\r\npgoff_t offset)\r\n{\r\nstruct zswap_entry *entry;\r\nentry = zswap_rb_search(root, offset);\r\nif (entry)\r\nzswap_entry_get(entry);\r\nreturn entry;\r\n}\r\nstatic int zswap_dstmem_prepare(unsigned int cpu)\r\n{\r\nu8 *dst;\r\ndst = kmalloc_node(PAGE_SIZE * 2, GFP_KERNEL, cpu_to_node(cpu));\r\nif (!dst)\r\nreturn -ENOMEM;\r\nper_cpu(zswap_dstmem, cpu) = dst;\r\nreturn 0;\r\n}\r\nstatic int zswap_dstmem_dead(unsigned int cpu)\r\n{\r\nu8 *dst;\r\ndst = per_cpu(zswap_dstmem, cpu);\r\nkfree(dst);\r\nper_cpu(zswap_dstmem, cpu) = NULL;\r\nreturn 0;\r\n}\r\nstatic int zswap_cpu_comp_prepare(unsigned int cpu, struct hlist_node *node)\r\n{\r\nstruct zswap_pool *pool = hlist_entry(node, struct zswap_pool, node);\r\nstruct crypto_comp *tfm;\r\nif (WARN_ON(*per_cpu_ptr(pool->tfm, cpu)))\r\nreturn 0;\r\ntfm = crypto_alloc_comp(pool->tfm_name, 0, 0);\r\nif (IS_ERR_OR_NULL(tfm)) {\r\npr_err("could not alloc crypto comp %s : %ld\n",\r\npool->tfm_name, PTR_ERR(tfm));\r\nreturn -ENOMEM;\r\n}\r\n*per_cpu_ptr(pool->tfm, cpu) = tfm;\r\nreturn 0;\r\n}\r\nstatic int zswap_cpu_comp_dead(unsigned int cpu, struct hlist_node *node)\r\n{\r\nstruct zswap_pool *pool = hlist_entry(node, struct zswap_pool, node);\r\nstruct crypto_comp *tfm;\r\ntfm = *per_cpu_ptr(pool->tfm, cpu);\r\nif (!IS_ERR_OR_NULL(tfm))\r\ncrypto_free_comp(tfm);\r\n*per_cpu_ptr(pool->tfm, cpu) = NULL;\r\nreturn 0;\r\n}\r\nstatic struct zswap_pool *__zswap_pool_current(void)\r\n{\r\nstruct zswap_pool *pool;\r\npool = list_first_or_null_rcu(&zswap_pools, typeof(*pool), list);\r\nWARN_ONCE(!pool && zswap_has_pool,\r\n"%s: no page storage pool!\n", __func__);\r\nreturn pool;\r\n}\r\nstatic struct zswap_pool *zswap_pool_current(void)\r\n{\r\nassert_spin_locked(&zswap_pools_lock);\r\nreturn __zswap_pool_current();\r\n}\r\nstatic struct zswap_pool *zswap_pool_current_get(void)\r\n{\r\nstruct zswap_pool *pool;\r\nrcu_read_lock();\r\npool = __zswap_pool_current();\r\nif (!zswap_pool_get(pool))\r\npool = NULL;\r\nrcu_read_unlock();\r\nreturn pool;\r\n}\r\nstatic struct zswap_pool *zswap_pool_last_get(void)\r\n{\r\nstruct zswap_pool *pool, *last = NULL;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(pool, &zswap_pools, list)\r\nlast = pool;\r\nWARN_ONCE(!last && zswap_has_pool,\r\n"%s: no page storage pool!\n", __func__);\r\nif (!zswap_pool_get(last))\r\nlast = NULL;\r\nrcu_read_unlock();\r\nreturn last;\r\n}\r\nstatic struct zswap_pool *zswap_pool_find_get(char *type, char *compressor)\r\n{\r\nstruct zswap_pool *pool;\r\nassert_spin_locked(&zswap_pools_lock);\r\nlist_for_each_entry_rcu(pool, &zswap_pools, list) {\r\nif (strcmp(pool->tfm_name, compressor))\r\ncontinue;\r\nif (strcmp(zpool_get_type(pool->zpool), type))\r\ncontinue;\r\nif (!zswap_pool_get(pool))\r\ncontinue;\r\nreturn pool;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct zswap_pool *zswap_pool_create(char *type, char *compressor)\r\n{\r\nstruct zswap_pool *pool;\r\nchar name[38];\r\ngfp_t gfp = __GFP_NORETRY | __GFP_NOWARN | __GFP_KSWAPD_RECLAIM;\r\nint ret;\r\nif (!zswap_has_pool) {\r\nif (!strcmp(type, ZSWAP_PARAM_UNSET))\r\nreturn NULL;\r\nif (!strcmp(compressor, ZSWAP_PARAM_UNSET))\r\nreturn NULL;\r\n}\r\npool = kzalloc(sizeof(*pool), GFP_KERNEL);\r\nif (!pool)\r\nreturn NULL;\r\nsnprintf(name, 38, "zswap%x", atomic_inc_return(&zswap_pools_count));\r\npool->zpool = zpool_create_pool(type, name, gfp, &zswap_zpool_ops);\r\nif (!pool->zpool) {\r\npr_err("%s zpool not available\n", type);\r\ngoto error;\r\n}\r\npr_debug("using %s zpool\n", zpool_get_type(pool->zpool));\r\nstrlcpy(pool->tfm_name, compressor, sizeof(pool->tfm_name));\r\npool->tfm = alloc_percpu(struct crypto_comp *);\r\nif (!pool->tfm) {\r\npr_err("percpu alloc failed\n");\r\ngoto error;\r\n}\r\nret = cpuhp_state_add_instance(CPUHP_MM_ZSWP_POOL_PREPARE,\r\n&pool->node);\r\nif (ret)\r\ngoto error;\r\npr_debug("using %s compressor\n", pool->tfm_name);\r\nkref_init(&pool->kref);\r\nINIT_LIST_HEAD(&pool->list);\r\nzswap_pool_debug("created", pool);\r\nreturn pool;\r\nerror:\r\nfree_percpu(pool->tfm);\r\nif (pool->zpool)\r\nzpool_destroy_pool(pool->zpool);\r\nkfree(pool);\r\nreturn NULL;\r\n}\r\nvoid zswap_pool_destroy(struct zswap_pool *pool)\r\n{\r\nzswap_pool_debug("destroying", pool);\r\ncpuhp_state_remove_instance(CPUHP_MM_ZSWP_POOL_PREPARE, &pool->node);\r\nfree_percpu(pool->tfm);\r\nzpool_destroy_pool(pool->zpool);\r\nkfree(pool);\r\n}\r\nstatic int __must_check zswap_pool_get(struct zswap_pool *pool)\r\n{\r\nif (!pool)\r\nreturn 0;\r\nreturn kref_get_unless_zero(&pool->kref);\r\n}\r\nstatic void __zswap_pool_release(struct work_struct *work)\r\n{\r\nstruct zswap_pool *pool = container_of(work, typeof(*pool), work);\r\nsynchronize_rcu();\r\nWARN_ON(kref_get_unless_zero(&pool->kref));\r\nzswap_pool_destroy(pool);\r\n}\r\nstatic void __zswap_pool_empty(struct kref *kref)\r\n{\r\nstruct zswap_pool *pool;\r\npool = container_of(kref, typeof(*pool), kref);\r\nspin_lock(&zswap_pools_lock);\r\nWARN_ON(pool == zswap_pool_current());\r\nlist_del_rcu(&pool->list);\r\nINIT_WORK(&pool->work, __zswap_pool_release);\r\nschedule_work(&pool->work);\r\nspin_unlock(&zswap_pools_lock);\r\n}\r\nstatic void zswap_pool_put(struct zswap_pool *pool)\r\n{\r\nkref_put(&pool->kref, __zswap_pool_empty);\r\n}\r\nstatic int __zswap_param_set(const char *val, const struct kernel_param *kp,\r\nchar *type, char *compressor)\r\n{\r\nstruct zswap_pool *pool, *put_pool = NULL;\r\nchar *s = strstrip((char *)val);\r\nint ret;\r\nif (zswap_init_failed) {\r\npr_err("can't set param, initialization failed\n");\r\nreturn -ENODEV;\r\n}\r\nif (!strcmp(s, *(char **)kp->arg) && zswap_has_pool)\r\nreturn 0;\r\nif (!zswap_init_started)\r\nreturn param_set_charp(s, kp);\r\nif (!type) {\r\nif (!zpool_has_pool(s)) {\r\npr_err("zpool %s not available\n", s);\r\nreturn -ENOENT;\r\n}\r\ntype = s;\r\n} else if (!compressor) {\r\nif (!crypto_has_comp(s, 0, 0)) {\r\npr_err("compressor %s not available\n", s);\r\nreturn -ENOENT;\r\n}\r\ncompressor = s;\r\n} else {\r\nWARN_ON(1);\r\nreturn -EINVAL;\r\n}\r\nspin_lock(&zswap_pools_lock);\r\npool = zswap_pool_find_get(type, compressor);\r\nif (pool) {\r\nzswap_pool_debug("using existing", pool);\r\nWARN_ON(pool == zswap_pool_current());\r\nlist_del_rcu(&pool->list);\r\n}\r\nspin_unlock(&zswap_pools_lock);\r\nif (!pool)\r\npool = zswap_pool_create(type, compressor);\r\nif (pool)\r\nret = param_set_charp(s, kp);\r\nelse\r\nret = -EINVAL;\r\nspin_lock(&zswap_pools_lock);\r\nif (!ret) {\r\nput_pool = zswap_pool_current();\r\nlist_add_rcu(&pool->list, &zswap_pools);\r\nzswap_has_pool = true;\r\n} else if (pool) {\r\nlist_add_tail_rcu(&pool->list, &zswap_pools);\r\nput_pool = pool;\r\n}\r\nspin_unlock(&zswap_pools_lock);\r\nif (!zswap_has_pool && !pool) {\r\nret = param_set_charp(s, kp);\r\n}\r\nif (put_pool)\r\nzswap_pool_put(put_pool);\r\nreturn ret;\r\n}\r\nstatic int zswap_compressor_param_set(const char *val,\r\nconst struct kernel_param *kp)\r\n{\r\nreturn __zswap_param_set(val, kp, zswap_zpool_type, NULL);\r\n}\r\nstatic int zswap_zpool_param_set(const char *val,\r\nconst struct kernel_param *kp)\r\n{\r\nreturn __zswap_param_set(val, kp, NULL, zswap_compressor);\r\n}\r\nstatic int zswap_enabled_param_set(const char *val,\r\nconst struct kernel_param *kp)\r\n{\r\nif (zswap_init_failed) {\r\npr_err("can't enable, initialization failed\n");\r\nreturn -ENODEV;\r\n}\r\nif (!zswap_has_pool && zswap_init_started) {\r\npr_err("can't enable, no pool configured\n");\r\nreturn -ENODEV;\r\n}\r\nreturn param_set_bool(val, kp);\r\n}\r\nstatic int zswap_get_swap_cache_page(swp_entry_t entry,\r\nstruct page **retpage)\r\n{\r\nbool page_was_allocated;\r\n*retpage = __read_swap_cache_async(entry, GFP_KERNEL,\r\nNULL, 0, &page_was_allocated);\r\nif (page_was_allocated)\r\nreturn ZSWAP_SWAPCACHE_NEW;\r\nif (!*retpage)\r\nreturn ZSWAP_SWAPCACHE_FAIL;\r\nreturn ZSWAP_SWAPCACHE_EXIST;\r\n}\r\nstatic int zswap_writeback_entry(struct zpool *pool, unsigned long handle)\r\n{\r\nstruct zswap_header *zhdr;\r\nswp_entry_t swpentry;\r\nstruct zswap_tree *tree;\r\npgoff_t offset;\r\nstruct zswap_entry *entry;\r\nstruct page *page;\r\nstruct crypto_comp *tfm;\r\nu8 *src, *dst;\r\nunsigned int dlen;\r\nint ret;\r\nstruct writeback_control wbc = {\r\n.sync_mode = WB_SYNC_NONE,\r\n};\r\nzhdr = zpool_map_handle(pool, handle, ZPOOL_MM_RO);\r\nswpentry = zhdr->swpentry;\r\nzpool_unmap_handle(pool, handle);\r\ntree = zswap_trees[swp_type(swpentry)];\r\noffset = swp_offset(swpentry);\r\nspin_lock(&tree->lock);\r\nentry = zswap_entry_find_get(&tree->rbroot, offset);\r\nif (!entry) {\r\nspin_unlock(&tree->lock);\r\nreturn 0;\r\n}\r\nspin_unlock(&tree->lock);\r\nBUG_ON(offset != entry->offset);\r\nswitch (zswap_get_swap_cache_page(swpentry, &page)) {\r\ncase ZSWAP_SWAPCACHE_FAIL:\r\nret = -ENOMEM;\r\ngoto fail;\r\ncase ZSWAP_SWAPCACHE_EXIST:\r\nput_page(page);\r\nret = -EEXIST;\r\ngoto fail;\r\ncase ZSWAP_SWAPCACHE_NEW:\r\ndlen = PAGE_SIZE;\r\nsrc = (u8 *)zpool_map_handle(entry->pool->zpool, entry->handle,\r\nZPOOL_MM_RO) + sizeof(struct zswap_header);\r\ndst = kmap_atomic(page);\r\ntfm = *get_cpu_ptr(entry->pool->tfm);\r\nret = crypto_comp_decompress(tfm, src, entry->length,\r\ndst, &dlen);\r\nput_cpu_ptr(entry->pool->tfm);\r\nkunmap_atomic(dst);\r\nzpool_unmap_handle(entry->pool->zpool, entry->handle);\r\nBUG_ON(ret);\r\nBUG_ON(dlen != PAGE_SIZE);\r\nSetPageUptodate(page);\r\n}\r\nSetPageReclaim(page);\r\n__swap_writepage(page, &wbc, end_swap_bio_write);\r\nput_page(page);\r\nzswap_written_back_pages++;\r\nspin_lock(&tree->lock);\r\nzswap_entry_put(tree, entry);\r\nif (entry == zswap_rb_search(&tree->rbroot, offset))\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\ngoto end;\r\nfail:\r\nspin_lock(&tree->lock);\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\nend:\r\nreturn ret;\r\n}\r\nstatic int zswap_shrink(void)\r\n{\r\nstruct zswap_pool *pool;\r\nint ret;\r\npool = zswap_pool_last_get();\r\nif (!pool)\r\nreturn -ENOENT;\r\nret = zpool_shrink(pool->zpool, 1, NULL);\r\nzswap_pool_put(pool);\r\nreturn ret;\r\n}\r\nstatic int zswap_frontswap_store(unsigned type, pgoff_t offset,\r\nstruct page *page)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry, *dupentry;\r\nstruct crypto_comp *tfm;\r\nint ret;\r\nunsigned int dlen = PAGE_SIZE, len;\r\nunsigned long handle;\r\nchar *buf;\r\nu8 *src, *dst;\r\nstruct zswap_header *zhdr;\r\nif (!zswap_enabled || !tree) {\r\nret = -ENODEV;\r\ngoto reject;\r\n}\r\nif (zswap_is_full()) {\r\nzswap_pool_limit_hit++;\r\nif (zswap_shrink()) {\r\nzswap_reject_reclaim_fail++;\r\nret = -ENOMEM;\r\ngoto reject;\r\n}\r\n}\r\nentry = zswap_entry_cache_alloc(GFP_KERNEL);\r\nif (!entry) {\r\nzswap_reject_kmemcache_fail++;\r\nret = -ENOMEM;\r\ngoto reject;\r\n}\r\nentry->pool = zswap_pool_current_get();\r\nif (!entry->pool) {\r\nret = -EINVAL;\r\ngoto freepage;\r\n}\r\ndst = get_cpu_var(zswap_dstmem);\r\ntfm = *get_cpu_ptr(entry->pool->tfm);\r\nsrc = kmap_atomic(page);\r\nret = crypto_comp_compress(tfm, src, PAGE_SIZE, dst, &dlen);\r\nkunmap_atomic(src);\r\nput_cpu_ptr(entry->pool->tfm);\r\nif (ret) {\r\nret = -EINVAL;\r\ngoto put_dstmem;\r\n}\r\nlen = dlen + sizeof(struct zswap_header);\r\nret = zpool_malloc(entry->pool->zpool, len,\r\n__GFP_NORETRY | __GFP_NOWARN | __GFP_KSWAPD_RECLAIM,\r\n&handle);\r\nif (ret == -ENOSPC) {\r\nzswap_reject_compress_poor++;\r\ngoto put_dstmem;\r\n}\r\nif (ret) {\r\nzswap_reject_alloc_fail++;\r\ngoto put_dstmem;\r\n}\r\nzhdr = zpool_map_handle(entry->pool->zpool, handle, ZPOOL_MM_RW);\r\nzhdr->swpentry = swp_entry(type, offset);\r\nbuf = (u8 *)(zhdr + 1);\r\nmemcpy(buf, dst, dlen);\r\nzpool_unmap_handle(entry->pool->zpool, handle);\r\nput_cpu_var(zswap_dstmem);\r\nentry->offset = offset;\r\nentry->handle = handle;\r\nentry->length = dlen;\r\nspin_lock(&tree->lock);\r\ndo {\r\nret = zswap_rb_insert(&tree->rbroot, entry, &dupentry);\r\nif (ret == -EEXIST) {\r\nzswap_duplicate_entry++;\r\nzswap_rb_erase(&tree->rbroot, dupentry);\r\nzswap_entry_put(tree, dupentry);\r\n}\r\n} while (ret == -EEXIST);\r\nspin_unlock(&tree->lock);\r\natomic_inc(&zswap_stored_pages);\r\nzswap_update_total_size();\r\nreturn 0;\r\nput_dstmem:\r\nput_cpu_var(zswap_dstmem);\r\nzswap_pool_put(entry->pool);\r\nfreepage:\r\nzswap_entry_cache_free(entry);\r\nreject:\r\nreturn ret;\r\n}\r\nstatic int zswap_frontswap_load(unsigned type, pgoff_t offset,\r\nstruct page *page)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry;\r\nstruct crypto_comp *tfm;\r\nu8 *src, *dst;\r\nunsigned int dlen;\r\nint ret;\r\nspin_lock(&tree->lock);\r\nentry = zswap_entry_find_get(&tree->rbroot, offset);\r\nif (!entry) {\r\nspin_unlock(&tree->lock);\r\nreturn -1;\r\n}\r\nspin_unlock(&tree->lock);\r\ndlen = PAGE_SIZE;\r\nsrc = (u8 *)zpool_map_handle(entry->pool->zpool, entry->handle,\r\nZPOOL_MM_RO) + sizeof(struct zswap_header);\r\ndst = kmap_atomic(page);\r\ntfm = *get_cpu_ptr(entry->pool->tfm);\r\nret = crypto_comp_decompress(tfm, src, entry->length, dst, &dlen);\r\nput_cpu_ptr(entry->pool->tfm);\r\nkunmap_atomic(dst);\r\nzpool_unmap_handle(entry->pool->zpool, entry->handle);\r\nBUG_ON(ret);\r\nspin_lock(&tree->lock);\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\nreturn 0;\r\n}\r\nstatic void zswap_frontswap_invalidate_page(unsigned type, pgoff_t offset)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry;\r\nspin_lock(&tree->lock);\r\nentry = zswap_rb_search(&tree->rbroot, offset);\r\nif (!entry) {\r\nspin_unlock(&tree->lock);\r\nreturn;\r\n}\r\nzswap_rb_erase(&tree->rbroot, entry);\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\n}\r\nstatic void zswap_frontswap_invalidate_area(unsigned type)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry, *n;\r\nif (!tree)\r\nreturn;\r\nspin_lock(&tree->lock);\r\nrbtree_postorder_for_each_entry_safe(entry, n, &tree->rbroot, rbnode)\r\nzswap_free_entry(entry);\r\ntree->rbroot = RB_ROOT;\r\nspin_unlock(&tree->lock);\r\nkfree(tree);\r\nzswap_trees[type] = NULL;\r\n}\r\nstatic void zswap_frontswap_init(unsigned type)\r\n{\r\nstruct zswap_tree *tree;\r\ntree = kzalloc(sizeof(*tree), GFP_KERNEL);\r\nif (!tree) {\r\npr_err("alloc failed, zswap disabled for swap type %d\n", type);\r\nreturn;\r\n}\r\ntree->rbroot = RB_ROOT;\r\nspin_lock_init(&tree->lock);\r\nzswap_trees[type] = tree;\r\n}\r\nstatic int __init zswap_debugfs_init(void)\r\n{\r\nif (!debugfs_initialized())\r\nreturn -ENODEV;\r\nzswap_debugfs_root = debugfs_create_dir("zswap", NULL);\r\nif (!zswap_debugfs_root)\r\nreturn -ENOMEM;\r\ndebugfs_create_u64("pool_limit_hit", S_IRUGO,\r\nzswap_debugfs_root, &zswap_pool_limit_hit);\r\ndebugfs_create_u64("reject_reclaim_fail", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_reclaim_fail);\r\ndebugfs_create_u64("reject_alloc_fail", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_alloc_fail);\r\ndebugfs_create_u64("reject_kmemcache_fail", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_kmemcache_fail);\r\ndebugfs_create_u64("reject_compress_poor", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_compress_poor);\r\ndebugfs_create_u64("written_back_pages", S_IRUGO,\r\nzswap_debugfs_root, &zswap_written_back_pages);\r\ndebugfs_create_u64("duplicate_entry", S_IRUGO,\r\nzswap_debugfs_root, &zswap_duplicate_entry);\r\ndebugfs_create_u64("pool_total_size", S_IRUGO,\r\nzswap_debugfs_root, &zswap_pool_total_size);\r\ndebugfs_create_atomic_t("stored_pages", S_IRUGO,\r\nzswap_debugfs_root, &zswap_stored_pages);\r\nreturn 0;\r\n}\r\nstatic void __exit zswap_debugfs_exit(void)\r\n{\r\ndebugfs_remove_recursive(zswap_debugfs_root);\r\n}\r\nstatic int __init zswap_debugfs_init(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic void __exit zswap_debugfs_exit(void) { }\r\nstatic int __init init_zswap(void)\r\n{\r\nstruct zswap_pool *pool;\r\nint ret;\r\nzswap_init_started = true;\r\nif (zswap_entry_cache_create()) {\r\npr_err("entry cache creation failed\n");\r\ngoto cache_fail;\r\n}\r\nret = cpuhp_setup_state(CPUHP_MM_ZSWP_MEM_PREPARE, "mm/zswap:prepare",\r\nzswap_dstmem_prepare, zswap_dstmem_dead);\r\nif (ret) {\r\npr_err("dstmem alloc failed\n");\r\ngoto dstmem_fail;\r\n}\r\nret = cpuhp_setup_state_multi(CPUHP_MM_ZSWP_POOL_PREPARE,\r\n"mm/zswap_pool:prepare",\r\nzswap_cpu_comp_prepare,\r\nzswap_cpu_comp_dead);\r\nif (ret)\r\ngoto hp_fail;\r\npool = __zswap_pool_create_fallback();\r\nif (pool) {\r\npr_info("loaded using pool %s/%s\n", pool->tfm_name,\r\nzpool_get_type(pool->zpool));\r\nlist_add(&pool->list, &zswap_pools);\r\nzswap_has_pool = true;\r\n} else {\r\npr_err("pool creation failed\n");\r\nzswap_enabled = false;\r\n}\r\nfrontswap_register_ops(&zswap_frontswap_ops);\r\nif (zswap_debugfs_init())\r\npr_warn("debugfs initialization failed\n");\r\nreturn 0;\r\nhp_fail:\r\ncpuhp_remove_state(CPUHP_MM_ZSWP_MEM_PREPARE);\r\ndstmem_fail:\r\nzswap_entry_cache_destroy();\r\ncache_fail:\r\nzswap_init_failed = true;\r\nzswap_enabled = false;\r\nreturn -ENOMEM;\r\n}
