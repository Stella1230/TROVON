static int uhdlc_init(struct ucc_hdlc_private *priv)\r\n{\r\nstruct ucc_tdm_info *ut_info;\r\nstruct ucc_fast_info *uf_info;\r\nu32 cecr_subblock;\r\nu16 bd_status;\r\nint ret, i;\r\nvoid *bd_buffer;\r\ndma_addr_t bd_dma_addr;\r\nu32 riptr;\r\nu32 tiptr;\r\nu32 gumr;\r\nut_info = priv->ut_info;\r\nuf_info = &ut_info->uf_info;\r\nif (priv->tsa) {\r\nuf_info->tsa = 1;\r\nuf_info->ctsp = 1;\r\n}\r\nif (priv->hdlc_bus)\r\nuf_info->brkpt_support = 1;\r\nuf_info->uccm_mask = ((UCC_HDLC_UCCE_RXB | UCC_HDLC_UCCE_RXF |\r\nUCC_HDLC_UCCE_TXB) << 16);\r\nret = ucc_fast_init(uf_info, &priv->uccf);\r\nif (ret) {\r\ndev_err(priv->dev, "Failed to init uccf.");\r\nreturn ret;\r\n}\r\npriv->uf_regs = priv->uccf->uf_regs;\r\nucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\r\nif (priv->loopback) {\r\ndev_info(priv->dev, "Loopback Mode\n");\r\nqe_setbrg(ut_info->uf_info.rx_clock, 20000000, 1);\r\ngumr = ioread32be(&priv->uf_regs->gumr);\r\ngumr |= (UCC_FAST_GUMR_LOOPBACK | UCC_FAST_GUMR_CDS |\r\nUCC_FAST_GUMR_TCI);\r\ngumr &= ~(UCC_FAST_GUMR_CTSP | UCC_FAST_GUMR_RSYN);\r\niowrite32be(gumr, &priv->uf_regs->gumr);\r\n}\r\nif (priv->tsa)\r\nucc_tdm_init(priv->utdm, priv->ut_info);\r\ncecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\r\nret = qe_issue_cmd(QE_STOP_TX, cecr_subblock,\r\nQE_CR_PROTOCOL_UNSPECIFIED, 0);\r\niowrite32be(0, &priv->uf_regs->upsmr);\r\nif (priv->hdlc_bus) {\r\nu32 upsmr;\r\ndev_info(priv->dev, "HDLC bus Mode\n");\r\nupsmr = ioread32be(&priv->uf_regs->upsmr);\r\nupsmr |= UCC_HDLC_UPSMR_RTE | UCC_HDLC_UPSMR_BUS |\r\nUCC_HDLC_UPSMR_CW8;\r\niowrite32be(upsmr, &priv->uf_regs->upsmr);\r\ngumr = ioread32be(&priv->uf_regs->gumr);\r\ngumr &= ~(UCC_FAST_GUMR_CDS | UCC_FAST_GUMR_CTSP);\r\ngumr |= UCC_FAST_GUMR_SYNL_AUTO;\r\niowrite32be(gumr, &priv->uf_regs->gumr);\r\n}\r\npriv->rx_ring_size = RX_BD_RING_LEN;\r\npriv->tx_ring_size = TX_BD_RING_LEN;\r\npriv->rx_bd_base = dma_alloc_coherent(priv->dev,\r\nRX_BD_RING_LEN * sizeof(struct qe_bd),\r\n&priv->dma_rx_bd, GFP_KERNEL);\r\nif (!priv->rx_bd_base) {\r\ndev_err(priv->dev, "Cannot allocate MURAM memory for RxBDs\n");\r\nret = -ENOMEM;\r\ngoto free_uccf;\r\n}\r\npriv->tx_bd_base = dma_alloc_coherent(priv->dev,\r\nTX_BD_RING_LEN * sizeof(struct qe_bd),\r\n&priv->dma_tx_bd, GFP_KERNEL);\r\nif (!priv->tx_bd_base) {\r\ndev_err(priv->dev, "Cannot allocate MURAM memory for TxBDs\n");\r\nret = -ENOMEM;\r\ngoto free_rx_bd;\r\n}\r\npriv->ucc_pram_offset = qe_muram_alloc(sizeof(struct ucc_hdlc_param),\r\nALIGNMENT_OF_UCC_HDLC_PRAM);\r\nif (priv->ucc_pram_offset < 0) {\r\ndev_err(priv->dev, "Can not allocate MURAM for hdlc parameter.\n");\r\nret = -ENOMEM;\r\ngoto free_tx_bd;\r\n}\r\npriv->rx_skbuff = kzalloc(priv->rx_ring_size * sizeof(*priv->rx_skbuff),\r\nGFP_KERNEL);\r\nif (!priv->rx_skbuff)\r\ngoto free_ucc_pram;\r\npriv->tx_skbuff = kzalloc(priv->tx_ring_size * sizeof(*priv->tx_skbuff),\r\nGFP_KERNEL);\r\nif (!priv->tx_skbuff)\r\ngoto free_rx_skbuff;\r\npriv->skb_curtx = 0;\r\npriv->skb_dirtytx = 0;\r\npriv->curtx_bd = priv->tx_bd_base;\r\npriv->dirty_tx = priv->tx_bd_base;\r\npriv->currx_bd = priv->rx_bd_base;\r\npriv->currx_bdnum = 0;\r\ncecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\r\nret = qe_issue_cmd(QE_ASSIGN_PAGE_TO_DEVICE, cecr_subblock,\r\nQE_CR_PROTOCOL_UNSPECIFIED, priv->ucc_pram_offset);\r\npriv->ucc_pram = (struct ucc_hdlc_param __iomem *)\r\nqe_muram_addr(priv->ucc_pram_offset);\r\nmemset_io(priv->ucc_pram, 0, sizeof(struct ucc_hdlc_param));\r\nriptr = qe_muram_alloc(32, 32);\r\nif (riptr < 0) {\r\ndev_err(priv->dev, "Cannot allocate MURAM mem for Receive internal temp data pointer\n");\r\nret = -ENOMEM;\r\ngoto free_tx_skbuff;\r\n}\r\ntiptr = qe_muram_alloc(32, 32);\r\nif (tiptr < 0) {\r\ndev_err(priv->dev, "Cannot allocate MURAM mem for Transmit internal temp data pointer\n");\r\nret = -ENOMEM;\r\ngoto free_riptr;\r\n}\r\niowrite16be(riptr, &priv->ucc_pram->riptr);\r\niowrite16be(tiptr, &priv->ucc_pram->tiptr);\r\niowrite16be(MAX_RX_BUF_LENGTH, &priv->ucc_pram->mrblr);\r\niowrite32be(priv->dma_rx_bd, &priv->ucc_pram->rbase);\r\niowrite32be(priv->dma_tx_bd, &priv->ucc_pram->tbase);\r\niowrite32be(BMR_GBL | BMR_BIG_ENDIAN, &priv->ucc_pram->rstate);\r\niowrite32be(BMR_GBL | BMR_BIG_ENDIAN, &priv->ucc_pram->tstate);\r\niowrite32be(CRC_16BIT_MASK, &priv->ucc_pram->c_mask);\r\niowrite32be(CRC_16BIT_PRES, &priv->ucc_pram->c_pres);\r\niowrite16be(MAX_FRAME_LENGTH, &priv->ucc_pram->mflr);\r\niowrite16be(DEFAULT_RFTHR, &priv->ucc_pram->rfthr);\r\niowrite16be(DEFAULT_RFTHR, &priv->ucc_pram->rfcnt);\r\niowrite16be(DEFAULT_ADDR_MASK, &priv->ucc_pram->hmask);\r\niowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr1);\r\niowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr2);\r\niowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr3);\r\niowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr4);\r\nbd_buffer = dma_alloc_coherent(priv->dev,\r\n(RX_BD_RING_LEN + TX_BD_RING_LEN) *\r\nMAX_RX_BUF_LENGTH,\r\n&bd_dma_addr, GFP_KERNEL);\r\nif (!bd_buffer) {\r\ndev_err(priv->dev, "Could not allocate buffer descriptors\n");\r\nret = -ENOMEM;\r\ngoto free_tiptr;\r\n}\r\nmemset(bd_buffer, 0, (RX_BD_RING_LEN + TX_BD_RING_LEN)\r\n* MAX_RX_BUF_LENGTH);\r\npriv->rx_buffer = bd_buffer;\r\npriv->tx_buffer = bd_buffer + RX_BD_RING_LEN * MAX_RX_BUF_LENGTH;\r\npriv->dma_rx_addr = bd_dma_addr;\r\npriv->dma_tx_addr = bd_dma_addr + RX_BD_RING_LEN * MAX_RX_BUF_LENGTH;\r\nfor (i = 0; i < RX_BD_RING_LEN; i++) {\r\nif (i < (RX_BD_RING_LEN - 1))\r\nbd_status = R_E_S | R_I_S;\r\nelse\r\nbd_status = R_E_S | R_I_S | R_W_S;\r\niowrite16be(bd_status, &priv->rx_bd_base[i].status);\r\niowrite32be(priv->dma_rx_addr + i * MAX_RX_BUF_LENGTH,\r\n&priv->rx_bd_base[i].buf);\r\n}\r\nfor (i = 0; i < TX_BD_RING_LEN; i++) {\r\nif (i < (TX_BD_RING_LEN - 1))\r\nbd_status = T_I_S | T_TC_S;\r\nelse\r\nbd_status = T_I_S | T_TC_S | T_W_S;\r\niowrite16be(bd_status, &priv->tx_bd_base[i].status);\r\niowrite32be(priv->dma_tx_addr + i * MAX_RX_BUF_LENGTH,\r\n&priv->tx_bd_base[i].buf);\r\n}\r\nreturn 0;\r\nfree_tiptr:\r\nqe_muram_free(tiptr);\r\nfree_riptr:\r\nqe_muram_free(riptr);\r\nfree_tx_skbuff:\r\nkfree(priv->tx_skbuff);\r\nfree_rx_skbuff:\r\nkfree(priv->rx_skbuff);\r\nfree_ucc_pram:\r\nqe_muram_free(priv->ucc_pram_offset);\r\nfree_tx_bd:\r\ndma_free_coherent(priv->dev,\r\nTX_BD_RING_LEN * sizeof(struct qe_bd),\r\npriv->tx_bd_base, priv->dma_tx_bd);\r\nfree_rx_bd:\r\ndma_free_coherent(priv->dev,\r\nRX_BD_RING_LEN * sizeof(struct qe_bd),\r\npriv->rx_bd_base, priv->dma_rx_bd);\r\nfree_uccf:\r\nucc_fast_free(priv->uccf);\r\nreturn ret;\r\n}\r\nstatic netdev_tx_t ucc_hdlc_tx(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nhdlc_device *hdlc = dev_to_hdlc(dev);\r\nstruct ucc_hdlc_private *priv = (struct ucc_hdlc_private *)hdlc->priv;\r\nstruct qe_bd __iomem *bd;\r\nu16 bd_status;\r\nunsigned long flags;\r\nu16 *proto_head;\r\nswitch (dev->type) {\r\ncase ARPHRD_RAWHDLC:\r\nif (skb_headroom(skb) < HDLC_HEAD_LEN) {\r\ndev->stats.tx_dropped++;\r\ndev_kfree_skb(skb);\r\nnetdev_err(dev, "No enough space for hdlc head\n");\r\nreturn -ENOMEM;\r\n}\r\nskb_push(skb, HDLC_HEAD_LEN);\r\nproto_head = (u16 *)skb->data;\r\n*proto_head = htons(DEFAULT_HDLC_HEAD);\r\ndev->stats.tx_bytes += skb->len;\r\nbreak;\r\ncase ARPHRD_PPP:\r\nproto_head = (u16 *)skb->data;\r\nif (*proto_head != htons(DEFAULT_PPP_HEAD)) {\r\ndev->stats.tx_dropped++;\r\ndev_kfree_skb(skb);\r\nnetdev_err(dev, "Wrong ppp header\n");\r\nreturn -ENOMEM;\r\n}\r\ndev->stats.tx_bytes += skb->len;\r\nbreak;\r\ndefault:\r\ndev->stats.tx_dropped++;\r\ndev_kfree_skb(skb);\r\nreturn -ENOMEM;\r\n}\r\nspin_lock_irqsave(&priv->lock, flags);\r\nbd = priv->curtx_bd;\r\nbd_status = ioread16be(&bd->status);\r\npriv->tx_skbuff[priv->skb_curtx] = skb;\r\npriv->skb_curtx =\r\n(priv->skb_curtx + 1) & TX_RING_MOD_MASK(TX_BD_RING_LEN);\r\nmemcpy(priv->tx_buffer + (be32_to_cpu(bd->buf) - priv->dma_tx_addr),\r\nskb->data, skb->len);\r\nbd_status = (bd_status & T_W_S) | T_R_S | T_I_S | T_L_S | T_TC_S;\r\niowrite16be(skb->len, &bd->length);\r\niowrite16be(bd_status, &bd->status);\r\nif (!(bd_status & T_W_S))\r\nbd += 1;\r\nelse\r\nbd = priv->tx_bd_base;\r\nif (bd == priv->dirty_tx) {\r\nif (!netif_queue_stopped(dev))\r\nnetif_stop_queue(dev);\r\n}\r\npriv->curtx_bd = bd;\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int hdlc_tx_done(struct ucc_hdlc_private *priv)\r\n{\r\nstruct net_device *dev = priv->ndev;\r\nstruct qe_bd *bd;\r\nu16 bd_status;\r\nbd = priv->dirty_tx;\r\nbd_status = ioread16be(&bd->status);\r\nwhile ((bd_status & T_R_S) == 0) {\r\nstruct sk_buff *skb;\r\nskb = priv->tx_skbuff[priv->skb_dirtytx];\r\nif (!skb)\r\nbreak;\r\ndev->stats.tx_packets++;\r\nmemset(priv->tx_buffer +\r\n(be32_to_cpu(bd->buf) - priv->dma_tx_addr),\r\n0, skb->len);\r\ndev_kfree_skb_irq(skb);\r\npriv->tx_skbuff[priv->skb_dirtytx] = NULL;\r\npriv->skb_dirtytx =\r\n(priv->skb_dirtytx +\r\n1) & TX_RING_MOD_MASK(TX_BD_RING_LEN);\r\nif (netif_queue_stopped(dev))\r\nnetif_wake_queue(dev);\r\nif (!(bd_status & T_W_S))\r\nbd += 1;\r\nelse\r\nbd = priv->tx_bd_base;\r\nbd_status = ioread16be(&bd->status);\r\n}\r\npriv->dirty_tx = bd;\r\nreturn 0;\r\n}\r\nstatic int hdlc_rx_done(struct ucc_hdlc_private *priv, int rx_work_limit)\r\n{\r\nstruct net_device *dev = priv->ndev;\r\nstruct sk_buff *skb = NULL;\r\nhdlc_device *hdlc = dev_to_hdlc(dev);\r\nstruct qe_bd *bd;\r\nu16 bd_status;\r\nu16 length, howmany = 0;\r\nu8 *bdbuffer;\r\nbd = priv->currx_bd;\r\nbd_status = ioread16be(&bd->status);\r\nwhile (!((bd_status & (R_E_S)) || (--rx_work_limit < 0))) {\r\nif (bd_status & R_OV_S)\r\ndev->stats.rx_over_errors++;\r\nif (bd_status & R_CR_S) {\r\ndev->stats.rx_crc_errors++;\r\ndev->stats.rx_dropped++;\r\ngoto recycle;\r\n}\r\nbdbuffer = priv->rx_buffer +\r\n(priv->currx_bdnum * MAX_RX_BUF_LENGTH);\r\nlength = ioread16be(&bd->length);\r\nswitch (dev->type) {\r\ncase ARPHRD_RAWHDLC:\r\nbdbuffer += HDLC_HEAD_LEN;\r\nlength -= (HDLC_HEAD_LEN + HDLC_CRC_SIZE);\r\nskb = dev_alloc_skb(length);\r\nif (!skb) {\r\ndev->stats.rx_dropped++;\r\nreturn -ENOMEM;\r\n}\r\nskb_put(skb, length);\r\nskb->len = length;\r\nskb->dev = dev;\r\nmemcpy(skb->data, bdbuffer, length);\r\nbreak;\r\ncase ARPHRD_PPP:\r\nlength -= HDLC_CRC_SIZE;\r\nskb = dev_alloc_skb(length);\r\nif (!skb) {\r\ndev->stats.rx_dropped++;\r\nreturn -ENOMEM;\r\n}\r\nskb_put(skb, length);\r\nskb->len = length;\r\nskb->dev = dev;\r\nmemcpy(skb->data, bdbuffer, length);\r\nbreak;\r\n}\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += skb->len;\r\nhowmany++;\r\nif (hdlc->proto)\r\nskb->protocol = hdlc_type_trans(skb, dev);\r\nnetif_receive_skb(skb);\r\nrecycle:\r\niowrite16be(bd_status | R_E_S | R_I_S, &bd->status);\r\nif (bd_status & R_W_S) {\r\npriv->currx_bdnum = 0;\r\nbd = priv->rx_bd_base;\r\n} else {\r\nif (priv->currx_bdnum < (RX_BD_RING_LEN - 1))\r\npriv->currx_bdnum += 1;\r\nelse\r\npriv->currx_bdnum = RX_BD_RING_LEN - 1;\r\nbd += 1;\r\n}\r\nbd_status = ioread16be(&bd->status);\r\n}\r\npriv->currx_bd = bd;\r\nreturn howmany;\r\n}\r\nstatic int ucc_hdlc_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct ucc_hdlc_private *priv = container_of(napi,\r\nstruct ucc_hdlc_private,\r\nnapi);\r\nint howmany;\r\nspin_lock(&priv->lock);\r\nhdlc_tx_done(priv);\r\nspin_unlock(&priv->lock);\r\nhowmany = 0;\r\nhowmany += hdlc_rx_done(priv, budget - howmany);\r\nif (howmany < budget) {\r\nnapi_complete_done(napi, howmany);\r\nqe_setbits32(priv->uccf->p_uccm,\r\n(UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS) << 16);\r\n}\r\nreturn howmany;\r\n}\r\nstatic irqreturn_t ucc_hdlc_irq_handler(int irq, void *dev_id)\r\n{\r\nstruct ucc_hdlc_private *priv = (struct ucc_hdlc_private *)dev_id;\r\nstruct net_device *dev = priv->ndev;\r\nstruct ucc_fast_private *uccf;\r\nstruct ucc_tdm_info *ut_info;\r\nu32 ucce;\r\nu32 uccm;\r\nut_info = priv->ut_info;\r\nuccf = priv->uccf;\r\nucce = ioread32be(uccf->p_ucce);\r\nuccm = ioread32be(uccf->p_uccm);\r\nucce &= uccm;\r\niowrite32be(ucce, uccf->p_ucce);\r\nif (!ucce)\r\nreturn IRQ_NONE;\r\nif ((ucce >> 16) & (UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS)) {\r\nif (napi_schedule_prep(&priv->napi)) {\r\nuccm &= ~((UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS)\r\n<< 16);\r\niowrite32be(uccm, uccf->p_uccm);\r\n__napi_schedule(&priv->napi);\r\n}\r\n}\r\nif (ucce >> 16 & UCC_HDLC_UCCE_BSY)\r\ndev->stats.rx_errors++;\r\nif (ucce >> 16 & UCC_HDLC_UCCE_TXE)\r\ndev->stats.tx_errors++;\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int uhdlc_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nconst size_t size = sizeof(te1_settings);\r\nte1_settings line;\r\nstruct ucc_hdlc_private *priv = netdev_priv(dev);\r\nif (cmd != SIOCWANDEV)\r\nreturn hdlc_ioctl(dev, ifr, cmd);\r\nswitch (ifr->ifr_settings.type) {\r\ncase IF_GET_IFACE:\r\nifr->ifr_settings.type = IF_IFACE_E1;\r\nif (ifr->ifr_settings.size < size) {\r\nifr->ifr_settings.size = size;\r\nreturn -ENOBUFS;\r\n}\r\nmemset(&line, 0, sizeof(line));\r\nline.clock_type = priv->clocking;\r\nif (copy_to_user(ifr->ifr_settings.ifs_ifsu.sync, &line, size))\r\nreturn -EFAULT;\r\nreturn 0;\r\ndefault:\r\nreturn hdlc_ioctl(dev, ifr, cmd);\r\n}\r\n}\r\nstatic int uhdlc_open(struct net_device *dev)\r\n{\r\nu32 cecr_subblock;\r\nhdlc_device *hdlc = dev_to_hdlc(dev);\r\nstruct ucc_hdlc_private *priv = hdlc->priv;\r\nstruct ucc_tdm *utdm = priv->utdm;\r\nif (priv->hdlc_busy != 1) {\r\nif (request_irq(priv->ut_info->uf_info.irq,\r\nucc_hdlc_irq_handler, 0, "hdlc", priv))\r\nreturn -ENODEV;\r\ncecr_subblock = ucc_fast_get_qe_cr_subblock(\r\npriv->ut_info->uf_info.ucc_num);\r\nqe_issue_cmd(QE_INIT_TX_RX, cecr_subblock,\r\nQE_CR_PROTOCOL_UNSPECIFIED, 0);\r\nucc_fast_enable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\r\nif (priv->tsa)\r\nutdm->si_regs->siglmr1_h |= (0x1 << utdm->tdm_port);\r\npriv->hdlc_busy = 1;\r\nnetif_device_attach(priv->ndev);\r\nnapi_enable(&priv->napi);\r\nnetif_start_queue(dev);\r\nhdlc_open(dev);\r\n}\r\nreturn 0;\r\n}\r\nstatic void uhdlc_memclean(struct ucc_hdlc_private *priv)\r\n{\r\nqe_muram_free(priv->ucc_pram->riptr);\r\nqe_muram_free(priv->ucc_pram->tiptr);\r\nif (priv->rx_bd_base) {\r\ndma_free_coherent(priv->dev,\r\nRX_BD_RING_LEN * sizeof(struct qe_bd),\r\npriv->rx_bd_base, priv->dma_rx_bd);\r\npriv->rx_bd_base = NULL;\r\npriv->dma_rx_bd = 0;\r\n}\r\nif (priv->tx_bd_base) {\r\ndma_free_coherent(priv->dev,\r\nTX_BD_RING_LEN * sizeof(struct qe_bd),\r\npriv->tx_bd_base, priv->dma_tx_bd);\r\npriv->tx_bd_base = NULL;\r\npriv->dma_tx_bd = 0;\r\n}\r\nif (priv->ucc_pram) {\r\nqe_muram_free(priv->ucc_pram_offset);\r\npriv->ucc_pram = NULL;\r\npriv->ucc_pram_offset = 0;\r\n}\r\nkfree(priv->rx_skbuff);\r\npriv->rx_skbuff = NULL;\r\nkfree(priv->tx_skbuff);\r\npriv->tx_skbuff = NULL;\r\nif (priv->uf_regs) {\r\niounmap(priv->uf_regs);\r\npriv->uf_regs = NULL;\r\n}\r\nif (priv->uccf) {\r\nucc_fast_free(priv->uccf);\r\npriv->uccf = NULL;\r\n}\r\nif (priv->rx_buffer) {\r\ndma_free_coherent(priv->dev,\r\nRX_BD_RING_LEN * MAX_RX_BUF_LENGTH,\r\npriv->rx_buffer, priv->dma_rx_addr);\r\npriv->rx_buffer = NULL;\r\npriv->dma_rx_addr = 0;\r\n}\r\nif (priv->tx_buffer) {\r\ndma_free_coherent(priv->dev,\r\nTX_BD_RING_LEN * MAX_RX_BUF_LENGTH,\r\npriv->tx_buffer, priv->dma_tx_addr);\r\npriv->tx_buffer = NULL;\r\npriv->dma_tx_addr = 0;\r\n}\r\n}\r\nstatic int uhdlc_close(struct net_device *dev)\r\n{\r\nstruct ucc_hdlc_private *priv = dev_to_hdlc(dev)->priv;\r\nstruct ucc_tdm *utdm = priv->utdm;\r\nu32 cecr_subblock;\r\nnapi_disable(&priv->napi);\r\ncecr_subblock = ucc_fast_get_qe_cr_subblock(\r\npriv->ut_info->uf_info.ucc_num);\r\nqe_issue_cmd(QE_GRACEFUL_STOP_TX, cecr_subblock,\r\n(u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\r\nqe_issue_cmd(QE_CLOSE_RX_BD, cecr_subblock,\r\n(u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\r\nif (priv->tsa)\r\nutdm->si_regs->siglmr1_h &= ~(0x1 << utdm->tdm_port);\r\nucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\r\nfree_irq(priv->ut_info->uf_info.irq, priv);\r\nnetif_stop_queue(dev);\r\npriv->hdlc_busy = 0;\r\nreturn 0;\r\n}\r\nstatic int ucc_hdlc_attach(struct net_device *dev, unsigned short encoding,\r\nunsigned short parity)\r\n{\r\nstruct ucc_hdlc_private *priv = dev_to_hdlc(dev)->priv;\r\nif (encoding != ENCODING_NRZ &&\r\nencoding != ENCODING_NRZI)\r\nreturn -EINVAL;\r\nif (parity != PARITY_NONE &&\r\nparity != PARITY_CRC32_PR1_CCITT &&\r\nparity != PARITY_CRC16_PR1_CCITT)\r\nreturn -EINVAL;\r\npriv->encoding = encoding;\r\npriv->parity = parity;\r\nreturn 0;\r\n}\r\nstatic void store_clk_config(struct ucc_hdlc_private *priv)\r\n{\r\nstruct qe_mux *qe_mux_reg = &qe_immr->qmx;\r\npriv->cmxsi1cr_h = ioread32be(&qe_mux_reg->cmxsi1cr_h);\r\npriv->cmxsi1cr_l = ioread32be(&qe_mux_reg->cmxsi1cr_l);\r\npriv->cmxsi1syr = ioread32be(&qe_mux_reg->cmxsi1syr);\r\nmemcpy_fromio(priv->cmxucr, qe_mux_reg->cmxucr, 4 * sizeof(u32));\r\n}\r\nstatic void resume_clk_config(struct ucc_hdlc_private *priv)\r\n{\r\nstruct qe_mux *qe_mux_reg = &qe_immr->qmx;\r\nmemcpy_toio(qe_mux_reg->cmxucr, priv->cmxucr, 4 * sizeof(u32));\r\niowrite32be(priv->cmxsi1cr_h, &qe_mux_reg->cmxsi1cr_h);\r\niowrite32be(priv->cmxsi1cr_l, &qe_mux_reg->cmxsi1cr_l);\r\niowrite32be(priv->cmxsi1syr, &qe_mux_reg->cmxsi1syr);\r\n}\r\nstatic int uhdlc_suspend(struct device *dev)\r\n{\r\nstruct ucc_hdlc_private *priv = dev_get_drvdata(dev);\r\nstruct ucc_tdm_info *ut_info;\r\nstruct ucc_fast __iomem *uf_regs;\r\nif (!priv)\r\nreturn -EINVAL;\r\nif (!netif_running(priv->ndev))\r\nreturn 0;\r\nnetif_device_detach(priv->ndev);\r\nnapi_disable(&priv->napi);\r\nut_info = priv->ut_info;\r\nuf_regs = priv->uf_regs;\r\npriv->gumr = ioread32be(&uf_regs->gumr);\r\npriv->guemr = ioread8(&uf_regs->guemr);\r\npriv->ucc_pram_bak = kmalloc(sizeof(*priv->ucc_pram_bak),\r\nGFP_KERNEL);\r\nif (!priv->ucc_pram_bak)\r\nreturn -ENOMEM;\r\nmemcpy_fromio(priv->ucc_pram_bak, priv->ucc_pram,\r\nsizeof(struct ucc_hdlc_param));\r\nstore_clk_config(priv);\r\nucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\r\nreturn 0;\r\n}\r\nstatic int uhdlc_resume(struct device *dev)\r\n{\r\nstruct ucc_hdlc_private *priv = dev_get_drvdata(dev);\r\nstruct ucc_tdm *utdm;\r\nstruct ucc_tdm_info *ut_info;\r\nstruct ucc_fast __iomem *uf_regs;\r\nstruct ucc_fast_private *uccf;\r\nstruct ucc_fast_info *uf_info;\r\nint ret, i;\r\nu32 cecr_subblock;\r\nu16 bd_status;\r\nif (!priv)\r\nreturn -EINVAL;\r\nif (!netif_running(priv->ndev))\r\nreturn 0;\r\nutdm = priv->utdm;\r\nut_info = priv->ut_info;\r\nuf_info = &ut_info->uf_info;\r\nuf_regs = priv->uf_regs;\r\nuccf = priv->uccf;\r\niowrite8(priv->guemr, &uf_regs->guemr);\r\niowrite32be(priv->gumr, &uf_regs->gumr);\r\niowrite16be(uf_info->urfs, &uf_regs->urfs);\r\niowrite16be(uf_info->urfet, &uf_regs->urfet);\r\niowrite16be(uf_info->urfset, &uf_regs->urfset);\r\niowrite16be(uf_info->utfs, &uf_regs->utfs);\r\niowrite16be(uf_info->utfet, &uf_regs->utfet);\r\niowrite16be(uf_info->utftt, &uf_regs->utftt);\r\niowrite32be(uccf->ucc_fast_tx_virtual_fifo_base_offset, &uf_regs->utfb);\r\niowrite32be(uccf->ucc_fast_rx_virtual_fifo_base_offset, &uf_regs->urfb);\r\nresume_clk_config(priv);\r\niowrite32be(uf_info->uccm_mask, &uf_regs->uccm);\r\niowrite32be(0xffffffff, &uf_regs->ucce);\r\nucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\r\nif (priv->tsa)\r\nucc_tdm_init(priv->utdm, priv->ut_info);\r\ncecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\r\nret = qe_issue_cmd(QE_STOP_TX, cecr_subblock,\r\n(u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\r\niowrite32be(0, &uf_regs->upsmr);\r\ncecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\r\nret = qe_issue_cmd(QE_ASSIGN_PAGE_TO_DEVICE, cecr_subblock,\r\nQE_CR_PROTOCOL_UNSPECIFIED, priv->ucc_pram_offset);\r\npriv->ucc_pram = (struct ucc_hdlc_param __iomem *)\r\nqe_muram_addr(priv->ucc_pram_offset);\r\nmemcpy_toio(priv->ucc_pram, priv->ucc_pram_bak,\r\nsizeof(struct ucc_hdlc_param));\r\nkfree(priv->ucc_pram_bak);\r\nfor (i = 0; i < RX_BD_RING_LEN; i++) {\r\nif (i < (RX_BD_RING_LEN - 1))\r\nbd_status = R_E_S | R_I_S;\r\nelse\r\nbd_status = R_E_S | R_I_S | R_W_S;\r\niowrite16be(bd_status, &priv->rx_bd_base[i].status);\r\niowrite32be(priv->dma_rx_addr + i * MAX_RX_BUF_LENGTH,\r\n&priv->rx_bd_base[i].buf);\r\n}\r\nfor (i = 0; i < TX_BD_RING_LEN; i++) {\r\nif (i < (TX_BD_RING_LEN - 1))\r\nbd_status = T_I_S | T_TC_S;\r\nelse\r\nbd_status = T_I_S | T_TC_S | T_W_S;\r\niowrite16be(bd_status, &priv->tx_bd_base[i].status);\r\niowrite32be(priv->dma_tx_addr + i * MAX_RX_BUF_LENGTH,\r\n&priv->tx_bd_base[i].buf);\r\n}\r\nif (priv->hdlc_busy == 1) {\r\ncecr_subblock = ucc_fast_get_qe_cr_subblock(\r\npriv->ut_info->uf_info.ucc_num);\r\nqe_issue_cmd(QE_INIT_TX_RX, cecr_subblock,\r\n(u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\r\nucc_fast_enable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\r\nif (priv->tsa)\r\nutdm->si_regs->siglmr1_h |= (0x1 << utdm->tdm_port);\r\n}\r\nnapi_enable(&priv->napi);\r\nnetif_device_attach(priv->ndev);\r\nreturn 0;\r\n}\r\nstatic int ucc_hdlc_probe(struct platform_device *pdev)\r\n{\r\nstruct device_node *np = pdev->dev.of_node;\r\nstruct ucc_hdlc_private *uhdlc_priv = NULL;\r\nstruct ucc_tdm_info *ut_info;\r\nstruct ucc_tdm *utdm = NULL;\r\nstruct resource res;\r\nstruct net_device *dev;\r\nhdlc_device *hdlc;\r\nint ucc_num;\r\nconst char *sprop;\r\nint ret;\r\nu32 val;\r\nret = of_property_read_u32_index(np, "cell-index", 0, &val);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Invalid ucc property\n");\r\nreturn -ENODEV;\r\n}\r\nucc_num = val - 1;\r\nif ((ucc_num > 3) || (ucc_num < 0)) {\r\ndev_err(&pdev->dev, ": Invalid UCC num\n");\r\nreturn -EINVAL;\r\n}\r\nmemcpy(&utdm_info[ucc_num], &utdm_primary_info,\r\nsizeof(utdm_primary_info));\r\nut_info = &utdm_info[ucc_num];\r\nut_info->uf_info.ucc_num = ucc_num;\r\nsprop = of_get_property(np, "rx-clock-name", NULL);\r\nif (sprop) {\r\nut_info->uf_info.rx_clock = qe_clock_source(sprop);\r\nif ((ut_info->uf_info.rx_clock < QE_CLK_NONE) ||\r\n(ut_info->uf_info.rx_clock > QE_CLK24)) {\r\ndev_err(&pdev->dev, "Invalid rx-clock-name property\n");\r\nreturn -EINVAL;\r\n}\r\n} else {\r\ndev_err(&pdev->dev, "Invalid rx-clock-name property\n");\r\nreturn -EINVAL;\r\n}\r\nsprop = of_get_property(np, "tx-clock-name", NULL);\r\nif (sprop) {\r\nut_info->uf_info.tx_clock = qe_clock_source(sprop);\r\nif ((ut_info->uf_info.tx_clock < QE_CLK_NONE) ||\r\n(ut_info->uf_info.tx_clock > QE_CLK24)) {\r\ndev_err(&pdev->dev, "Invalid tx-clock-name property\n");\r\nreturn -EINVAL;\r\n}\r\n} else {\r\ndev_err(&pdev->dev, "Invalid tx-clock-name property\n");\r\nreturn -EINVAL;\r\n}\r\nret = of_address_to_resource(np, 0, &res);\r\nif (ret)\r\nreturn -EINVAL;\r\nut_info->uf_info.regs = res.start;\r\nut_info->uf_info.irq = irq_of_parse_and_map(np, 0);\r\nuhdlc_priv = kzalloc(sizeof(*uhdlc_priv), GFP_KERNEL);\r\nif (!uhdlc_priv) {\r\nreturn -ENOMEM;\r\n}\r\ndev_set_drvdata(&pdev->dev, uhdlc_priv);\r\nuhdlc_priv->dev = &pdev->dev;\r\nuhdlc_priv->ut_info = ut_info;\r\nif (of_get_property(np, "fsl,tdm-interface", NULL))\r\nuhdlc_priv->tsa = 1;\r\nif (of_get_property(np, "fsl,ucc-internal-loopback", NULL))\r\nuhdlc_priv->loopback = 1;\r\nif (of_get_property(np, "fsl,hdlc-bus", NULL))\r\nuhdlc_priv->hdlc_bus = 1;\r\nif (uhdlc_priv->tsa == 1) {\r\nutdm = kzalloc(sizeof(*utdm), GFP_KERNEL);\r\nif (!utdm) {\r\nret = -ENOMEM;\r\ndev_err(&pdev->dev, "No mem to alloc ucc tdm data\n");\r\ngoto free_uhdlc_priv;\r\n}\r\nuhdlc_priv->utdm = utdm;\r\nret = ucc_of_parse_tdm(np, utdm, ut_info);\r\nif (ret)\r\ngoto free_utdm;\r\n}\r\nret = uhdlc_init(uhdlc_priv);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Failed to init uhdlc\n");\r\ngoto free_utdm;\r\n}\r\ndev = alloc_hdlcdev(uhdlc_priv);\r\nif (!dev) {\r\nret = -ENOMEM;\r\npr_err("ucc_hdlc: unable to allocate memory\n");\r\ngoto undo_uhdlc_init;\r\n}\r\nuhdlc_priv->ndev = dev;\r\nhdlc = dev_to_hdlc(dev);\r\ndev->tx_queue_len = 16;\r\ndev->netdev_ops = &uhdlc_ops;\r\nhdlc->attach = ucc_hdlc_attach;\r\nhdlc->xmit = ucc_hdlc_tx;\r\nnetif_napi_add(dev, &uhdlc_priv->napi, ucc_hdlc_poll, 32);\r\nif (register_hdlc_device(dev)) {\r\nret = -ENOBUFS;\r\npr_err("ucc_hdlc: unable to register hdlc device\n");\r\nfree_netdev(dev);\r\ngoto free_dev;\r\n}\r\nreturn 0;\r\nfree_dev:\r\nfree_netdev(dev);\r\nundo_uhdlc_init:\r\nfree_utdm:\r\nif (uhdlc_priv->tsa)\r\nkfree(utdm);\r\nfree_uhdlc_priv:\r\nkfree(uhdlc_priv);\r\nreturn ret;\r\n}\r\nstatic int ucc_hdlc_remove(struct platform_device *pdev)\r\n{\r\nstruct ucc_hdlc_private *priv = dev_get_drvdata(&pdev->dev);\r\nuhdlc_memclean(priv);\r\nif (priv->utdm->si_regs) {\r\niounmap(priv->utdm->si_regs);\r\npriv->utdm->si_regs = NULL;\r\n}\r\nif (priv->utdm->siram) {\r\niounmap(priv->utdm->siram);\r\npriv->utdm->siram = NULL;\r\n}\r\nkfree(priv);\r\ndev_info(&pdev->dev, "UCC based hdlc module removed\n");\r\nreturn 0;\r\n}
