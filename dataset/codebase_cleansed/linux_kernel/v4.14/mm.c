static unsigned long make_page_sizes(unsigned long a, unsigned long b)\r\n{\r\nreturn (a << 56) | (b << 48);\r\n}\r\nstatic void __maybe_unused _debug_dump_map(const struct map *m,\r\nconst char *func, int line)\r\n{\r\nDBG("%s:%d: map.total = %llxh\n", func, line, m->total);\r\nDBG("%s:%d: map.rm.size = %llxh\n", func, line, m->rm.size);\r\nDBG("%s:%d: map.vas_id = %llu\n", func, line, m->vas_id);\r\nDBG("%s:%d: map.htab_size = %llxh\n", func, line, m->htab_size);\r\nDBG("%s:%d: map.r1.base = %llxh\n", func, line, m->r1.base);\r\nDBG("%s:%d: map.r1.offset = %lxh\n", func, line, m->r1.offset);\r\nDBG("%s:%d: map.r1.size = %llxh\n", func, line, m->r1.size);\r\n}\r\nunsigned long ps3_mm_phys_to_lpar(unsigned long phys_addr)\r\n{\r\nBUG_ON(is_kernel_addr(phys_addr));\r\nreturn (phys_addr < map.rm.size || phys_addr >= map.total)\r\n? phys_addr : phys_addr + map.r1.offset;\r\n}\r\nvoid __init ps3_mm_vas_create(unsigned long* htab_size)\r\n{\r\nint result;\r\nu64 start_address;\r\nu64 size;\r\nu64 access_right;\r\nu64 max_page_size;\r\nu64 flags;\r\nresult = lv1_query_logical_partition_address_region_info(0,\r\n&start_address, &size, &access_right, &max_page_size,\r\n&flags);\r\nif (result) {\r\nDBG("%s:%d: lv1_query_logical_partition_address_region_info "\r\n"failed: %s\n", __func__, __LINE__,\r\nps3_result(result));\r\ngoto fail;\r\n}\r\nif (max_page_size < PAGE_SHIFT_16M) {\r\nDBG("%s:%d: bad max_page_size %llxh\n", __func__, __LINE__,\r\nmax_page_size);\r\ngoto fail;\r\n}\r\nBUILD_BUG_ON(CONFIG_PS3_HTAB_SIZE > HTAB_SIZE_MAX);\r\nBUILD_BUG_ON(CONFIG_PS3_HTAB_SIZE < HTAB_SIZE_MIN);\r\nresult = lv1_construct_virtual_address_space(CONFIG_PS3_HTAB_SIZE,\r\n2, make_page_sizes(PAGE_SHIFT_16M, PAGE_SHIFT_64K),\r\n&map.vas_id, &map.htab_size);\r\nif (result) {\r\nDBG("%s:%d: lv1_construct_virtual_address_space failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\ngoto fail;\r\n}\r\nresult = lv1_select_virtual_address_space(map.vas_id);\r\nif (result) {\r\nDBG("%s:%d: lv1_select_virtual_address_space failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\ngoto fail;\r\n}\r\n*htab_size = map.htab_size;\r\ndebug_dump_map(&map);\r\nreturn;\r\nfail:\r\npanic("ps3_mm_vas_create failed");\r\n}\r\nvoid ps3_mm_vas_destroy(void)\r\n{\r\nint result;\r\nDBG("%s:%d: map.vas_id = %llu\n", __func__, __LINE__, map.vas_id);\r\nif (map.vas_id) {\r\nresult = lv1_select_virtual_address_space(0);\r\nBUG_ON(result);\r\nresult = lv1_destruct_virtual_address_space(map.vas_id);\r\nBUG_ON(result);\r\nmap.vas_id = 0;\r\n}\r\n}\r\nstatic int ps3_mm_get_repository_highmem(struct mem_region *r)\r\n{\r\nint result;\r\nresult = ps3_repository_read_highmem_info(0, &r->base, &r->size);\r\nif (result)\r\ngoto zero_region;\r\nif (!r->base || !r->size) {\r\nresult = -1;\r\ngoto zero_region;\r\n}\r\nr->offset = r->base - map.rm.size;\r\nDBG("%s:%d: Found high region in repository: %llxh %llxh\n",\r\n__func__, __LINE__, r->base, r->size);\r\nreturn 0;\r\nzero_region:\r\nDBG("%s:%d: No high region in repository.\n", __func__, __LINE__);\r\nr->size = r->base = r->offset = 0;\r\nreturn result;\r\n}\r\nstatic int ps3_mm_set_repository_highmem(const struct mem_region *r)\r\n{\r\nreturn r ? ps3_repository_write_highmem_info(0, r->base, r->size) :\r\nps3_repository_write_highmem_info(0, 0, 0);\r\n}\r\nstatic int ps3_mm_region_create(struct mem_region *r, unsigned long size)\r\n{\r\nint result;\r\nu64 muid;\r\nr->size = _ALIGN_DOWN(size, 1 << PAGE_SHIFT_16M);\r\nDBG("%s:%d requested %lxh\n", __func__, __LINE__, size);\r\nDBG("%s:%d actual %llxh\n", __func__, __LINE__, r->size);\r\nDBG("%s:%d difference %llxh (%lluMB)\n", __func__, __LINE__,\r\nsize - r->size, (size - r->size) / 1024 / 1024);\r\nif (r->size == 0) {\r\nDBG("%s:%d: size == 0\n", __func__, __LINE__);\r\nresult = -1;\r\ngoto zero_region;\r\n}\r\nresult = lv1_allocate_memory(r->size, PAGE_SHIFT_16M, 0,\r\nALLOCATE_MEMORY_TRY_ALT_UNIT, &r->base, &muid);\r\nif (result || r->base < map.rm.size) {\r\nDBG("%s:%d: lv1_allocate_memory failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\ngoto zero_region;\r\n}\r\nr->destroy = 1;\r\nr->offset = r->base - map.rm.size;\r\nreturn result;\r\nzero_region:\r\nr->size = r->base = r->offset = 0;\r\nreturn result;\r\n}\r\nstatic void ps3_mm_region_destroy(struct mem_region *r)\r\n{\r\nint result;\r\nif (!r->destroy) {\r\npr_info("%s:%d: Not destroying high region: %llxh %llxh\n",\r\n__func__, __LINE__, r->base, r->size);\r\nreturn;\r\n}\r\nDBG("%s:%d: r->base = %llxh\n", __func__, __LINE__, r->base);\r\nif (r->base) {\r\nresult = lv1_release_memory(r->base);\r\nBUG_ON(result);\r\nr->size = r->base = r->offset = 0;\r\nmap.total = map.rm.size;\r\n}\r\nps3_mm_set_repository_highmem(NULL);\r\n}\r\nstatic unsigned long dma_sb_lpar_to_bus(struct ps3_dma_region *r,\r\nunsigned long lpar_addr)\r\n{\r\nif (lpar_addr >= map.rm.size)\r\nlpar_addr -= map.r1.offset;\r\nBUG_ON(lpar_addr < r->offset);\r\nBUG_ON(lpar_addr >= r->offset + r->len);\r\nreturn r->bus_addr + lpar_addr - r->offset;\r\n}\r\nstatic void __maybe_unused _dma_dump_region(const struct ps3_dma_region *r,\r\nconst char *func, int line)\r\n{\r\nDBG("%s:%d: dev %llu:%llu\n", func, line, r->dev->bus_id,\r\nr->dev->dev_id);\r\nDBG("%s:%d: page_size %u\n", func, line, r->page_size);\r\nDBG("%s:%d: bus_addr %lxh\n", func, line, r->bus_addr);\r\nDBG("%s:%d: len %lxh\n", func, line, r->len);\r\nDBG("%s:%d: offset %lxh\n", func, line, r->offset);\r\n}\r\nstatic void _dma_dump_chunk (const struct dma_chunk* c, const char* func,\r\nint line)\r\n{\r\nDBG("%s:%d: r.dev %llu:%llu\n", func, line,\r\nc->region->dev->bus_id, c->region->dev->dev_id);\r\nDBG("%s:%d: r.bus_addr %lxh\n", func, line, c->region->bus_addr);\r\nDBG("%s:%d: r.page_size %u\n", func, line, c->region->page_size);\r\nDBG("%s:%d: r.len %lxh\n", func, line, c->region->len);\r\nDBG("%s:%d: r.offset %lxh\n", func, line, c->region->offset);\r\nDBG("%s:%d: c.lpar_addr %lxh\n", func, line, c->lpar_addr);\r\nDBG("%s:%d: c.bus_addr %lxh\n", func, line, c->bus_addr);\r\nDBG("%s:%d: c.len %lxh\n", func, line, c->len);\r\n}\r\nstatic struct dma_chunk * dma_find_chunk(struct ps3_dma_region *r,\r\nunsigned long bus_addr, unsigned long len)\r\n{\r\nstruct dma_chunk *c;\r\nunsigned long aligned_bus = _ALIGN_DOWN(bus_addr, 1 << r->page_size);\r\nunsigned long aligned_len = _ALIGN_UP(len+bus_addr-aligned_bus,\r\n1 << r->page_size);\r\nlist_for_each_entry(c, &r->chunk_list.head, link) {\r\nif (aligned_bus >= c->bus_addr &&\r\naligned_bus + aligned_len <= c->bus_addr + c->len)\r\nreturn c;\r\nif (aligned_bus + aligned_len <= c->bus_addr)\r\ncontinue;\r\nif (aligned_bus >= c->bus_addr + c->len)\r\ncontinue;\r\ndma_dump_chunk(c);\r\nBUG();\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct dma_chunk *dma_find_chunk_lpar(struct ps3_dma_region *r,\r\nunsigned long lpar_addr, unsigned long len)\r\n{\r\nstruct dma_chunk *c;\r\nunsigned long aligned_lpar = _ALIGN_DOWN(lpar_addr, 1 << r->page_size);\r\nunsigned long aligned_len = _ALIGN_UP(len + lpar_addr - aligned_lpar,\r\n1 << r->page_size);\r\nlist_for_each_entry(c, &r->chunk_list.head, link) {\r\nif (c->lpar_addr <= aligned_lpar &&\r\naligned_lpar < c->lpar_addr + c->len) {\r\nif (aligned_lpar + aligned_len <= c->lpar_addr + c->len)\r\nreturn c;\r\nelse {\r\ndma_dump_chunk(c);\r\nBUG();\r\n}\r\n}\r\nif (aligned_lpar + aligned_len <= c->lpar_addr) {\r\ncontinue;\r\n}\r\nif (c->lpar_addr + c->len <= aligned_lpar) {\r\ncontinue;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic int dma_sb_free_chunk(struct dma_chunk *c)\r\n{\r\nint result = 0;\r\nif (c->bus_addr) {\r\nresult = lv1_unmap_device_dma_region(c->region->dev->bus_id,\r\nc->region->dev->dev_id, c->bus_addr, c->len);\r\nBUG_ON(result);\r\n}\r\nkfree(c);\r\nreturn result;\r\n}\r\nstatic int dma_ioc0_free_chunk(struct dma_chunk *c)\r\n{\r\nint result = 0;\r\nint iopage;\r\nunsigned long offset;\r\nstruct ps3_dma_region *r = c->region;\r\nDBG("%s:start\n", __func__);\r\nfor (iopage = 0; iopage < (c->len >> r->page_size); iopage++) {\r\noffset = (1 << r->page_size) * iopage;\r\nresult = lv1_put_iopte(0,\r\nc->bus_addr + offset,\r\nc->lpar_addr + offset,\r\nr->ioid,\r\n0);\r\nDBG("%s: bus=%#lx, lpar=%#lx, ioid=%d\n", __func__,\r\nc->bus_addr + offset,\r\nc->lpar_addr + offset,\r\nr->ioid);\r\nif (result) {\r\nDBG("%s:%d: lv1_put_iopte failed: %s\n", __func__,\r\n__LINE__, ps3_result(result));\r\n}\r\n}\r\nkfree(c);\r\nDBG("%s:end\n", __func__);\r\nreturn result;\r\n}\r\nstatic int dma_sb_map_pages(struct ps3_dma_region *r, unsigned long phys_addr,\r\nunsigned long len, struct dma_chunk **c_out, u64 iopte_flag)\r\n{\r\nint result;\r\nstruct dma_chunk *c;\r\nc = kzalloc(sizeof(struct dma_chunk), GFP_ATOMIC);\r\nif (!c) {\r\nresult = -ENOMEM;\r\ngoto fail_alloc;\r\n}\r\nc->region = r;\r\nc->lpar_addr = ps3_mm_phys_to_lpar(phys_addr);\r\nc->bus_addr = dma_sb_lpar_to_bus(r, c->lpar_addr);\r\nc->len = len;\r\nBUG_ON(iopte_flag != 0xf800000000000000UL);\r\nresult = lv1_map_device_dma_region(c->region->dev->bus_id,\r\nc->region->dev->dev_id, c->lpar_addr,\r\nc->bus_addr, c->len, iopte_flag);\r\nif (result) {\r\nDBG("%s:%d: lv1_map_device_dma_region failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\ngoto fail_map;\r\n}\r\nlist_add(&c->link, &r->chunk_list.head);\r\n*c_out = c;\r\nreturn 0;\r\nfail_map:\r\nkfree(c);\r\nfail_alloc:\r\n*c_out = NULL;\r\nDBG(" <- %s:%d\n", __func__, __LINE__);\r\nreturn result;\r\n}\r\nstatic int dma_ioc0_map_pages(struct ps3_dma_region *r, unsigned long phys_addr,\r\nunsigned long len, struct dma_chunk **c_out,\r\nu64 iopte_flag)\r\n{\r\nint result;\r\nstruct dma_chunk *c, *last;\r\nint iopage, pages;\r\nunsigned long offset;\r\nDBG(KERN_ERR "%s: phy=%#lx, lpar%#lx, len=%#lx\n", __func__,\r\nphys_addr, ps3_mm_phys_to_lpar(phys_addr), len);\r\nc = kzalloc(sizeof(struct dma_chunk), GFP_ATOMIC);\r\nif (!c) {\r\nresult = -ENOMEM;\r\ngoto fail_alloc;\r\n}\r\nc->region = r;\r\nc->len = len;\r\nc->lpar_addr = ps3_mm_phys_to_lpar(phys_addr);\r\nif (list_empty(&r->chunk_list.head)) {\r\nc->bus_addr = r->bus_addr;\r\n} else {\r\nlast = list_entry(r->chunk_list.head.next,\r\nstruct dma_chunk, link);\r\nc->bus_addr = last->bus_addr + last->len;\r\nDBG("%s: last bus=%#lx, len=%#lx\n", __func__,\r\nlast->bus_addr, last->len);\r\n}\r\npages = len >> r->page_size;\r\nDBG("%s: pgsize=%#x len=%#lx pages=%#x iopteflag=%#llx\n", __func__,\r\nr->page_size, r->len, pages, iopte_flag);\r\nfor (iopage = 0; iopage < pages; iopage++) {\r\noffset = (1 << r->page_size) * iopage;\r\nresult = lv1_put_iopte(0,\r\nc->bus_addr + offset,\r\nc->lpar_addr + offset,\r\nr->ioid,\r\niopte_flag);\r\nif (result) {\r\npr_warning("%s:%d: lv1_put_iopte failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\ngoto fail_map;\r\n}\r\nDBG("%s: pg=%d bus=%#lx, lpar=%#lx, ioid=%#x\n", __func__,\r\niopage, c->bus_addr + offset, c->lpar_addr + offset,\r\nr->ioid);\r\n}\r\nlist_add(&c->link, &r->chunk_list.head);\r\n*c_out = c;\r\nDBG("%s: end\n", __func__);\r\nreturn 0;\r\nfail_map:\r\nfor (iopage--; 0 <= iopage; iopage--) {\r\nlv1_put_iopte(0,\r\nc->bus_addr + offset,\r\nc->lpar_addr + offset,\r\nr->ioid,\r\n0);\r\n}\r\nkfree(c);\r\nfail_alloc:\r\n*c_out = NULL;\r\nreturn result;\r\n}\r\nstatic int dma_sb_region_create(struct ps3_dma_region *r)\r\n{\r\nint result;\r\nu64 bus_addr;\r\nDBG(" -> %s:%d:\n", __func__, __LINE__);\r\nBUG_ON(!r);\r\nif (!r->dev->bus_id) {\r\npr_info("%s:%d: %llu:%llu no dma\n", __func__, __LINE__,\r\nr->dev->bus_id, r->dev->dev_id);\r\nreturn 0;\r\n}\r\nDBG("%s:%u: len = 0x%lx, page_size = %u, offset = 0x%lx\n", __func__,\r\n__LINE__, r->len, r->page_size, r->offset);\r\nBUG_ON(!r->len);\r\nBUG_ON(!r->page_size);\r\nBUG_ON(!r->region_ops);\r\nINIT_LIST_HEAD(&r->chunk_list.head);\r\nspin_lock_init(&r->chunk_list.lock);\r\nresult = lv1_allocate_device_dma_region(r->dev->bus_id, r->dev->dev_id,\r\nroundup_pow_of_two(r->len), r->page_size, r->region_type,\r\n&bus_addr);\r\nr->bus_addr = bus_addr;\r\nif (result) {\r\nDBG("%s:%d: lv1_allocate_device_dma_region failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\nr->len = r->bus_addr = 0;\r\n}\r\nreturn result;\r\n}\r\nstatic int dma_ioc0_region_create(struct ps3_dma_region *r)\r\n{\r\nint result;\r\nu64 bus_addr;\r\nINIT_LIST_HEAD(&r->chunk_list.head);\r\nspin_lock_init(&r->chunk_list.lock);\r\nresult = lv1_allocate_io_segment(0,\r\nr->len,\r\nr->page_size,\r\n&bus_addr);\r\nr->bus_addr = bus_addr;\r\nif (result) {\r\nDBG("%s:%d: lv1_allocate_io_segment failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\nr->len = r->bus_addr = 0;\r\n}\r\nDBG("%s: len=%#lx, pg=%d, bus=%#lx\n", __func__,\r\nr->len, r->page_size, r->bus_addr);\r\nreturn result;\r\n}\r\nstatic int dma_sb_region_free(struct ps3_dma_region *r)\r\n{\r\nint result;\r\nstruct dma_chunk *c;\r\nstruct dma_chunk *tmp;\r\nBUG_ON(!r);\r\nif (!r->dev->bus_id) {\r\npr_info("%s:%d: %llu:%llu no dma\n", __func__, __LINE__,\r\nr->dev->bus_id, r->dev->dev_id);\r\nreturn 0;\r\n}\r\nlist_for_each_entry_safe(c, tmp, &r->chunk_list.head, link) {\r\nlist_del(&c->link);\r\ndma_sb_free_chunk(c);\r\n}\r\nresult = lv1_free_device_dma_region(r->dev->bus_id, r->dev->dev_id,\r\nr->bus_addr);\r\nif (result)\r\nDBG("%s:%d: lv1_free_device_dma_region failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\nr->bus_addr = 0;\r\nreturn result;\r\n}\r\nstatic int dma_ioc0_region_free(struct ps3_dma_region *r)\r\n{\r\nint result;\r\nstruct dma_chunk *c, *n;\r\nDBG("%s: start\n", __func__);\r\nlist_for_each_entry_safe(c, n, &r->chunk_list.head, link) {\r\nlist_del(&c->link);\r\ndma_ioc0_free_chunk(c);\r\n}\r\nresult = lv1_release_io_segment(0, r->bus_addr);\r\nif (result)\r\nDBG("%s:%d: lv1_free_device_dma_region failed: %s\n",\r\n__func__, __LINE__, ps3_result(result));\r\nr->bus_addr = 0;\r\nDBG("%s: end\n", __func__);\r\nreturn result;\r\n}\r\nstatic int dma_sb_map_area(struct ps3_dma_region *r, unsigned long virt_addr,\r\nunsigned long len, dma_addr_t *bus_addr,\r\nu64 iopte_flag)\r\n{\r\nint result;\r\nunsigned long flags;\r\nstruct dma_chunk *c;\r\nunsigned long phys_addr = is_kernel_addr(virt_addr) ? __pa(virt_addr)\r\n: virt_addr;\r\nunsigned long aligned_phys = _ALIGN_DOWN(phys_addr, 1 << r->page_size);\r\nunsigned long aligned_len = _ALIGN_UP(len + phys_addr - aligned_phys,\r\n1 << r->page_size);\r\n*bus_addr = dma_sb_lpar_to_bus(r, ps3_mm_phys_to_lpar(phys_addr));\r\nif (!USE_DYNAMIC_DMA) {\r\nunsigned long lpar_addr = ps3_mm_phys_to_lpar(phys_addr);\r\nDBG(" -> %s:%d\n", __func__, __LINE__);\r\nDBG("%s:%d virt_addr %lxh\n", __func__, __LINE__,\r\nvirt_addr);\r\nDBG("%s:%d phys_addr %lxh\n", __func__, __LINE__,\r\nphys_addr);\r\nDBG("%s:%d lpar_addr %lxh\n", __func__, __LINE__,\r\nlpar_addr);\r\nDBG("%s:%d len %lxh\n", __func__, __LINE__, len);\r\nDBG("%s:%d bus_addr %llxh (%lxh)\n", __func__, __LINE__,\r\n*bus_addr, len);\r\n}\r\nspin_lock_irqsave(&r->chunk_list.lock, flags);\r\nc = dma_find_chunk(r, *bus_addr, len);\r\nif (c) {\r\nDBG("%s:%d: reusing mapped chunk", __func__, __LINE__);\r\ndma_dump_chunk(c);\r\nc->usage_count++;\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nreturn 0;\r\n}\r\nresult = dma_sb_map_pages(r, aligned_phys, aligned_len, &c, iopte_flag);\r\nif (result) {\r\n*bus_addr = 0;\r\nDBG("%s:%d: dma_sb_map_pages failed (%d)\n",\r\n__func__, __LINE__, result);\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nreturn result;\r\n}\r\nc->usage_count = 1;\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nreturn result;\r\n}\r\nstatic int dma_ioc0_map_area(struct ps3_dma_region *r, unsigned long virt_addr,\r\nunsigned long len, dma_addr_t *bus_addr,\r\nu64 iopte_flag)\r\n{\r\nint result;\r\nunsigned long flags;\r\nstruct dma_chunk *c;\r\nunsigned long phys_addr = is_kernel_addr(virt_addr) ? __pa(virt_addr)\r\n: virt_addr;\r\nunsigned long aligned_phys = _ALIGN_DOWN(phys_addr, 1 << r->page_size);\r\nunsigned long aligned_len = _ALIGN_UP(len + phys_addr - aligned_phys,\r\n1 << r->page_size);\r\nDBG(KERN_ERR "%s: vaddr=%#lx, len=%#lx\n", __func__,\r\nvirt_addr, len);\r\nDBG(KERN_ERR "%s: ph=%#lx a_ph=%#lx a_l=%#lx\n", __func__,\r\nphys_addr, aligned_phys, aligned_len);\r\nspin_lock_irqsave(&r->chunk_list.lock, flags);\r\nc = dma_find_chunk_lpar(r, ps3_mm_phys_to_lpar(phys_addr), len);\r\nif (c) {\r\nBUG();\r\n*bus_addr = c->bus_addr + phys_addr - aligned_phys;\r\nc->usage_count++;\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nreturn 0;\r\n}\r\nresult = dma_ioc0_map_pages(r, aligned_phys, aligned_len, &c,\r\niopte_flag);\r\nif (result) {\r\n*bus_addr = 0;\r\nDBG("%s:%d: dma_ioc0_map_pages failed (%d)\n",\r\n__func__, __LINE__, result);\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nreturn result;\r\n}\r\n*bus_addr = c->bus_addr + phys_addr - aligned_phys;\r\nDBG("%s: va=%#lx pa=%#lx a_pa=%#lx bus=%#llx\n", __func__,\r\nvirt_addr, phys_addr, aligned_phys, *bus_addr);\r\nc->usage_count = 1;\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nreturn result;\r\n}\r\nstatic int dma_sb_unmap_area(struct ps3_dma_region *r, dma_addr_t bus_addr,\r\nunsigned long len)\r\n{\r\nunsigned long flags;\r\nstruct dma_chunk *c;\r\nspin_lock_irqsave(&r->chunk_list.lock, flags);\r\nc = dma_find_chunk(r, bus_addr, len);\r\nif (!c) {\r\nunsigned long aligned_bus = _ALIGN_DOWN(bus_addr,\r\n1 << r->page_size);\r\nunsigned long aligned_len = _ALIGN_UP(len + bus_addr\r\n- aligned_bus, 1 << r->page_size);\r\nDBG("%s:%d: not found: bus_addr %llxh\n",\r\n__func__, __LINE__, bus_addr);\r\nDBG("%s:%d: not found: len %lxh\n",\r\n__func__, __LINE__, len);\r\nDBG("%s:%d: not found: aligned_bus %lxh\n",\r\n__func__, __LINE__, aligned_bus);\r\nDBG("%s:%d: not found: aligned_len %lxh\n",\r\n__func__, __LINE__, aligned_len);\r\nBUG();\r\n}\r\nc->usage_count--;\r\nif (!c->usage_count) {\r\nlist_del(&c->link);\r\ndma_sb_free_chunk(c);\r\n}\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nreturn 0;\r\n}\r\nstatic int dma_ioc0_unmap_area(struct ps3_dma_region *r,\r\ndma_addr_t bus_addr, unsigned long len)\r\n{\r\nunsigned long flags;\r\nstruct dma_chunk *c;\r\nDBG("%s: start a=%#llx l=%#lx\n", __func__, bus_addr, len);\r\nspin_lock_irqsave(&r->chunk_list.lock, flags);\r\nc = dma_find_chunk(r, bus_addr, len);\r\nif (!c) {\r\nunsigned long aligned_bus = _ALIGN_DOWN(bus_addr,\r\n1 << r->page_size);\r\nunsigned long aligned_len = _ALIGN_UP(len + bus_addr\r\n- aligned_bus,\r\n1 << r->page_size);\r\nDBG("%s:%d: not found: bus_addr %llxh\n",\r\n__func__, __LINE__, bus_addr);\r\nDBG("%s:%d: not found: len %lxh\n",\r\n__func__, __LINE__, len);\r\nDBG("%s:%d: not found: aligned_bus %lxh\n",\r\n__func__, __LINE__, aligned_bus);\r\nDBG("%s:%d: not found: aligned_len %lxh\n",\r\n__func__, __LINE__, aligned_len);\r\nBUG();\r\n}\r\nc->usage_count--;\r\nif (!c->usage_count) {\r\nlist_del(&c->link);\r\ndma_ioc0_free_chunk(c);\r\n}\r\nspin_unlock_irqrestore(&r->chunk_list.lock, flags);\r\nDBG("%s: end\n", __func__);\r\nreturn 0;\r\n}\r\nstatic int dma_sb_region_create_linear(struct ps3_dma_region *r)\r\n{\r\nint result;\r\nunsigned long virt_addr, len;\r\ndma_addr_t tmp;\r\nif (r->len > 16*1024*1024) {\r\nif (r->page_size != PS3_DMA_16M) {\r\npr_info("%s:%d: forcing 16M pages for linear map\n",\r\n__func__, __LINE__);\r\nr->page_size = PS3_DMA_16M;\r\nr->len = _ALIGN_UP(r->len, 1 << r->page_size);\r\n}\r\n}\r\nresult = dma_sb_region_create(r);\r\nBUG_ON(result);\r\nif (r->offset < map.rm.size) {\r\nvirt_addr = map.rm.base + r->offset;\r\nlen = map.rm.size - r->offset;\r\nif (len > r->len)\r\nlen = r->len;\r\nresult = dma_sb_map_area(r, virt_addr, len, &tmp,\r\nCBE_IOPTE_PP_W | CBE_IOPTE_PP_R | CBE_IOPTE_SO_RW |\r\nCBE_IOPTE_M);\r\nBUG_ON(result);\r\n}\r\nif (r->offset + r->len > map.rm.size) {\r\nvirt_addr = map.rm.size;\r\nlen = r->len;\r\nif (r->offset >= map.rm.size)\r\nvirt_addr += r->offset - map.rm.size;\r\nelse\r\nlen -= map.rm.size - r->offset;\r\nresult = dma_sb_map_area(r, virt_addr, len, &tmp,\r\nCBE_IOPTE_PP_W | CBE_IOPTE_PP_R | CBE_IOPTE_SO_RW |\r\nCBE_IOPTE_M);\r\nBUG_ON(result);\r\n}\r\nreturn result;\r\n}\r\nstatic int dma_sb_region_free_linear(struct ps3_dma_region *r)\r\n{\r\nint result;\r\ndma_addr_t bus_addr;\r\nunsigned long len, lpar_addr;\r\nif (r->offset < map.rm.size) {\r\nlpar_addr = map.rm.base + r->offset;\r\nlen = map.rm.size - r->offset;\r\nif (len > r->len)\r\nlen = r->len;\r\nbus_addr = dma_sb_lpar_to_bus(r, lpar_addr);\r\nresult = dma_sb_unmap_area(r, bus_addr, len);\r\nBUG_ON(result);\r\n}\r\nif (r->offset + r->len > map.rm.size) {\r\nlpar_addr = map.r1.base;\r\nlen = r->len;\r\nif (r->offset >= map.rm.size)\r\nlpar_addr += r->offset - map.rm.size;\r\nelse\r\nlen -= map.rm.size - r->offset;\r\nbus_addr = dma_sb_lpar_to_bus(r, lpar_addr);\r\nresult = dma_sb_unmap_area(r, bus_addr, len);\r\nBUG_ON(result);\r\n}\r\nresult = dma_sb_region_free(r);\r\nBUG_ON(result);\r\nreturn result;\r\n}\r\nstatic int dma_sb_map_area_linear(struct ps3_dma_region *r,\r\nunsigned long virt_addr, unsigned long len, dma_addr_t *bus_addr,\r\nu64 iopte_flag)\r\n{\r\nunsigned long phys_addr = is_kernel_addr(virt_addr) ? __pa(virt_addr)\r\n: virt_addr;\r\n*bus_addr = dma_sb_lpar_to_bus(r, ps3_mm_phys_to_lpar(phys_addr));\r\nreturn 0;\r\n}\r\nstatic int dma_sb_unmap_area_linear(struct ps3_dma_region *r,\r\ndma_addr_t bus_addr, unsigned long len)\r\n{\r\nreturn 0;\r\n}\r\nint ps3_dma_region_init(struct ps3_system_bus_device *dev,\r\nstruct ps3_dma_region *r, enum ps3_dma_page_size page_size,\r\nenum ps3_dma_region_type region_type, void *addr, unsigned long len)\r\n{\r\nunsigned long lpar_addr;\r\nlpar_addr = addr ? ps3_mm_phys_to_lpar(__pa(addr)) : 0;\r\nr->dev = dev;\r\nr->page_size = page_size;\r\nr->region_type = region_type;\r\nr->offset = lpar_addr;\r\nif (r->offset >= map.rm.size)\r\nr->offset -= map.r1.offset;\r\nr->len = len ? len : _ALIGN_UP(map.total, 1 << r->page_size);\r\nswitch (dev->dev_type) {\r\ncase PS3_DEVICE_TYPE_SB:\r\nr->region_ops = (USE_DYNAMIC_DMA)\r\n? &ps3_dma_sb_region_ops\r\n: &ps3_dma_sb_region_linear_ops;\r\nbreak;\r\ncase PS3_DEVICE_TYPE_IOC0:\r\nr->region_ops = &ps3_dma_ioc0_region_ops;\r\nbreak;\r\ndefault:\r\nBUG();\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint ps3_dma_region_create(struct ps3_dma_region *r)\r\n{\r\nBUG_ON(!r);\r\nBUG_ON(!r->region_ops);\r\nBUG_ON(!r->region_ops->create);\r\nreturn r->region_ops->create(r);\r\n}\r\nint ps3_dma_region_free(struct ps3_dma_region *r)\r\n{\r\nBUG_ON(!r);\r\nBUG_ON(!r->region_ops);\r\nBUG_ON(!r->region_ops->free);\r\nreturn r->region_ops->free(r);\r\n}\r\nint ps3_dma_map(struct ps3_dma_region *r, unsigned long virt_addr,\r\nunsigned long len, dma_addr_t *bus_addr,\r\nu64 iopte_flag)\r\n{\r\nreturn r->region_ops->map(r, virt_addr, len, bus_addr, iopte_flag);\r\n}\r\nint ps3_dma_unmap(struct ps3_dma_region *r, dma_addr_t bus_addr,\r\nunsigned long len)\r\n{\r\nreturn r->region_ops->unmap(r, bus_addr, len);\r\n}\r\nvoid __init ps3_mm_init(void)\r\n{\r\nint result;\r\nDBG(" -> %s:%d\n", __func__, __LINE__);\r\nresult = ps3_repository_read_mm_info(&map.rm.base, &map.rm.size,\r\n&map.total);\r\nif (result)\r\npanic("ps3_repository_read_mm_info() failed");\r\nmap.rm.offset = map.rm.base;\r\nmap.vas_id = map.htab_size = 0;\r\nBUG_ON(map.rm.base);\r\nBUG_ON(!map.rm.size);\r\nif (ps3_mm_get_repository_highmem(&map.r1)) {\r\nresult = ps3_mm_region_create(&map.r1, map.total - map.rm.size);\r\nif (!result)\r\nps3_mm_set_repository_highmem(&map.r1);\r\n}\r\nmap.total = map.rm.size + map.r1.size;\r\nif (!map.r1.size) {\r\nDBG("%s:%d: No highmem region found\n", __func__, __LINE__);\r\n} else {\r\nDBG("%s:%d: Adding highmem region: %llxh %llxh\n",\r\n__func__, __LINE__, map.rm.size,\r\nmap.total - map.rm.size);\r\nmemblock_add(map.rm.size, map.total - map.rm.size);\r\n}\r\nDBG(" <- %s:%d\n", __func__, __LINE__);\r\n}\r\nvoid ps3_mm_shutdown(void)\r\n{\r\nps3_mm_region_destroy(&map.r1);\r\n}
