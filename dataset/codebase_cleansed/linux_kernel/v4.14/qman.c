static inline u32 qm_in(struct qm_portal *p, u32 offset)\r\n{\r\nreturn be32_to_cpu(__raw_readl(p->addr.ci + offset));\r\n}\r\nstatic inline void qm_out(struct qm_portal *p, u32 offset, u32 val)\r\n{\r\n__raw_writel(cpu_to_be32(val), p->addr.ci + offset);\r\n}\r\nstatic inline void qm_cl_invalidate(struct qm_portal *p, u32 offset)\r\n{\r\ndpaa_invalidate(p->addr.ce + offset);\r\n}\r\nstatic inline void qm_cl_touch_ro(struct qm_portal *p, u32 offset)\r\n{\r\ndpaa_touch_ro(p->addr.ce + offset);\r\n}\r\nstatic inline u32 qm_ce_in(struct qm_portal *p, u32 offset)\r\n{\r\nreturn be32_to_cpu(__raw_readl(p->addr.ce + offset));\r\n}\r\nstatic struct qm_eqcr_entry *eqcr_carryclear(struct qm_eqcr_entry *p)\r\n{\r\nuintptr_t addr = (uintptr_t)p;\r\naddr &= ~EQCR_CARRY;\r\nreturn (struct qm_eqcr_entry *)addr;\r\n}\r\nstatic int eqcr_ptr2idx(struct qm_eqcr_entry *e)\r\n{\r\nreturn ((uintptr_t)e >> EQCR_SHIFT) & (QM_EQCR_SIZE - 1);\r\n}\r\nstatic inline void eqcr_inc(struct qm_eqcr *eqcr)\r\n{\r\nstruct qm_eqcr_entry *partial = eqcr->cursor + 1;\r\neqcr->cursor = eqcr_carryclear(partial);\r\nif (partial != eqcr->cursor)\r\neqcr->vbit ^= QM_EQCR_VERB_VBIT;\r\n}\r\nstatic inline int qm_eqcr_init(struct qm_portal *portal,\r\nenum qm_eqcr_pmode pmode,\r\nunsigned int eq_stash_thresh,\r\nint eq_stash_prio)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nu32 cfg;\r\nu8 pi;\r\neqcr->ring = portal->addr.ce + QM_CL_EQCR;\r\neqcr->ci = qm_in(portal, QM_REG_EQCR_CI_CINH) & (QM_EQCR_SIZE - 1);\r\nqm_cl_invalidate(portal, QM_CL_EQCR_CI_CENA);\r\npi = qm_in(portal, QM_REG_EQCR_PI_CINH) & (QM_EQCR_SIZE - 1);\r\neqcr->cursor = eqcr->ring + pi;\r\neqcr->vbit = (qm_in(portal, QM_REG_EQCR_PI_CINH) & QM_EQCR_SIZE) ?\r\nQM_EQCR_VERB_VBIT : 0;\r\neqcr->available = QM_EQCR_SIZE - 1 -\r\ndpaa_cyc_diff(QM_EQCR_SIZE, eqcr->ci, pi);\r\neqcr->ithresh = qm_in(portal, QM_REG_EQCR_ITR);\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\neqcr->busy = 0;\r\neqcr->pmode = pmode;\r\n#endif\r\ncfg = (qm_in(portal, QM_REG_CFG) & 0x00ffffff) |\r\n(eq_stash_thresh << 28) |\r\n(eq_stash_prio << 26) |\r\n((pmode & 0x3) << 24);\r\nqm_out(portal, QM_REG_CFG, cfg);\r\nreturn 0;\r\n}\r\nstatic inline unsigned int qm_eqcr_get_ci_stashing(struct qm_portal *portal)\r\n{\r\nreturn (qm_in(portal, QM_REG_CFG) >> 28) & 0x7;\r\n}\r\nstatic inline void qm_eqcr_finish(struct qm_portal *portal)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nu8 pi = qm_in(portal, QM_REG_EQCR_PI_CINH) & (QM_EQCR_SIZE - 1);\r\nu8 ci = qm_in(portal, QM_REG_EQCR_CI_CINH) & (QM_EQCR_SIZE - 1);\r\nDPAA_ASSERT(!eqcr->busy);\r\nif (pi != eqcr_ptr2idx(eqcr->cursor))\r\npr_crit("losing uncommitted EQCR entries\n");\r\nif (ci != eqcr->ci)\r\npr_crit("missing existing EQCR completions\n");\r\nif (eqcr->ci != eqcr_ptr2idx(eqcr->cursor))\r\npr_crit("EQCR destroyed unquiesced\n");\r\n}\r\nstatic inline struct qm_eqcr_entry *qm_eqcr_start_no_stash(struct qm_portal\r\n*portal)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nDPAA_ASSERT(!eqcr->busy);\r\nif (!eqcr->available)\r\nreturn NULL;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\neqcr->busy = 1;\r\n#endif\r\ndpaa_zero(eqcr->cursor);\r\nreturn eqcr->cursor;\r\n}\r\nstatic inline struct qm_eqcr_entry *qm_eqcr_start_stash(struct qm_portal\r\n*portal)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nu8 diff, old_ci;\r\nDPAA_ASSERT(!eqcr->busy);\r\nif (!eqcr->available) {\r\nold_ci = eqcr->ci;\r\neqcr->ci = qm_ce_in(portal, QM_CL_EQCR_CI_CENA) &\r\n(QM_EQCR_SIZE - 1);\r\ndiff = dpaa_cyc_diff(QM_EQCR_SIZE, old_ci, eqcr->ci);\r\neqcr->available += diff;\r\nif (!diff)\r\nreturn NULL;\r\n}\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\neqcr->busy = 1;\r\n#endif\r\ndpaa_zero(eqcr->cursor);\r\nreturn eqcr->cursor;\r\n}\r\nstatic inline void eqcr_commit_checks(struct qm_eqcr *eqcr)\r\n{\r\nDPAA_ASSERT(eqcr->busy);\r\nDPAA_ASSERT(!(be32_to_cpu(eqcr->cursor->fqid) & ~QM_FQID_MASK));\r\nDPAA_ASSERT(eqcr->available >= 1);\r\n}\r\nstatic inline void qm_eqcr_pvb_commit(struct qm_portal *portal, u8 myverb)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nstruct qm_eqcr_entry *eqcursor;\r\neqcr_commit_checks(eqcr);\r\nDPAA_ASSERT(eqcr->pmode == qm_eqcr_pvb);\r\ndma_wmb();\r\neqcursor = eqcr->cursor;\r\neqcursor->_ncw_verb = myverb | eqcr->vbit;\r\ndpaa_flush(eqcursor);\r\neqcr_inc(eqcr);\r\neqcr->available--;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\neqcr->busy = 0;\r\n#endif\r\n}\r\nstatic inline void qm_eqcr_cce_prefetch(struct qm_portal *portal)\r\n{\r\nqm_cl_touch_ro(portal, QM_CL_EQCR_CI_CENA);\r\n}\r\nstatic inline u8 qm_eqcr_cce_update(struct qm_portal *portal)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nu8 diff, old_ci = eqcr->ci;\r\neqcr->ci = qm_ce_in(portal, QM_CL_EQCR_CI_CENA) & (QM_EQCR_SIZE - 1);\r\nqm_cl_invalidate(portal, QM_CL_EQCR_CI_CENA);\r\ndiff = dpaa_cyc_diff(QM_EQCR_SIZE, old_ci, eqcr->ci);\r\neqcr->available += diff;\r\nreturn diff;\r\n}\r\nstatic inline void qm_eqcr_set_ithresh(struct qm_portal *portal, u8 ithresh)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\neqcr->ithresh = ithresh;\r\nqm_out(portal, QM_REG_EQCR_ITR, ithresh);\r\n}\r\nstatic inline u8 qm_eqcr_get_avail(struct qm_portal *portal)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nreturn eqcr->available;\r\n}\r\nstatic inline u8 qm_eqcr_get_fill(struct qm_portal *portal)\r\n{\r\nstruct qm_eqcr *eqcr = &portal->eqcr;\r\nreturn QM_EQCR_SIZE - 1 - eqcr->available;\r\n}\r\nstatic const struct qm_dqrr_entry *dqrr_carryclear(\r\nconst struct qm_dqrr_entry *p)\r\n{\r\nuintptr_t addr = (uintptr_t)p;\r\naddr &= ~DQRR_CARRY;\r\nreturn (const struct qm_dqrr_entry *)addr;\r\n}\r\nstatic inline int dqrr_ptr2idx(const struct qm_dqrr_entry *e)\r\n{\r\nreturn ((uintptr_t)e >> DQRR_SHIFT) & (QM_DQRR_SIZE - 1);\r\n}\r\nstatic const struct qm_dqrr_entry *dqrr_inc(const struct qm_dqrr_entry *e)\r\n{\r\nreturn dqrr_carryclear(e + 1);\r\n}\r\nstatic inline void qm_dqrr_set_maxfill(struct qm_portal *portal, u8 mf)\r\n{\r\nqm_out(portal, QM_REG_CFG, (qm_in(portal, QM_REG_CFG) & 0xff0fffff) |\r\n((mf & (QM_DQRR_SIZE - 1)) << 20));\r\n}\r\nstatic inline int qm_dqrr_init(struct qm_portal *portal,\r\nconst struct qm_portal_config *config,\r\nenum qm_dqrr_dmode dmode,\r\nenum qm_dqrr_pmode pmode,\r\nenum qm_dqrr_cmode cmode, u8 max_fill)\r\n{\r\nstruct qm_dqrr *dqrr = &portal->dqrr;\r\nu32 cfg;\r\nqm_out(portal, QM_REG_DQRR_SDQCR, 0);\r\nqm_out(portal, QM_REG_DQRR_VDQCR, 0);\r\nqm_out(portal, QM_REG_DQRR_PDQCR, 0);\r\ndqrr->ring = portal->addr.ce + QM_CL_DQRR;\r\ndqrr->pi = qm_in(portal, QM_REG_DQRR_PI_CINH) & (QM_DQRR_SIZE - 1);\r\ndqrr->ci = qm_in(portal, QM_REG_DQRR_CI_CINH) & (QM_DQRR_SIZE - 1);\r\ndqrr->cursor = dqrr->ring + dqrr->ci;\r\ndqrr->fill = dpaa_cyc_diff(QM_DQRR_SIZE, dqrr->ci, dqrr->pi);\r\ndqrr->vbit = (qm_in(portal, QM_REG_DQRR_PI_CINH) & QM_DQRR_SIZE) ?\r\nQM_DQRR_VERB_VBIT : 0;\r\ndqrr->ithresh = qm_in(portal, QM_REG_DQRR_ITR);\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\ndqrr->dmode = dmode;\r\ndqrr->pmode = pmode;\r\ndqrr->cmode = cmode;\r\n#endif\r\nfor (cfg = 0; cfg < QM_DQRR_SIZE; cfg++)\r\ndpaa_invalidate(qm_cl(dqrr->ring, cfg));\r\ncfg = (qm_in(portal, QM_REG_CFG) & 0xff000f00) |\r\n((max_fill & (QM_DQRR_SIZE - 1)) << 20) |\r\n((dmode & 1) << 18) |\r\n((cmode & 3) << 16) |\r\n0xa0 |\r\n(0 ? 0x40 : 0) |\r\n(0 ? 0x10 : 0);\r\nqm_out(portal, QM_REG_CFG, cfg);\r\nqm_dqrr_set_maxfill(portal, max_fill);\r\nreturn 0;\r\n}\r\nstatic inline void qm_dqrr_finish(struct qm_portal *portal)\r\n{\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nstruct qm_dqrr *dqrr = &portal->dqrr;\r\nif (dqrr->cmode != qm_dqrr_cdc &&\r\ndqrr->ci != dqrr_ptr2idx(dqrr->cursor))\r\npr_crit("Ignoring completed DQRR entries\n");\r\n#endif\r\n}\r\nstatic inline const struct qm_dqrr_entry *qm_dqrr_current(\r\nstruct qm_portal *portal)\r\n{\r\nstruct qm_dqrr *dqrr = &portal->dqrr;\r\nif (!dqrr->fill)\r\nreturn NULL;\r\nreturn dqrr->cursor;\r\n}\r\nstatic inline u8 qm_dqrr_next(struct qm_portal *portal)\r\n{\r\nstruct qm_dqrr *dqrr = &portal->dqrr;\r\nDPAA_ASSERT(dqrr->fill);\r\ndqrr->cursor = dqrr_inc(dqrr->cursor);\r\nreturn --dqrr->fill;\r\n}\r\nstatic inline void qm_dqrr_pvb_update(struct qm_portal *portal)\r\n{\r\nstruct qm_dqrr *dqrr = &portal->dqrr;\r\nstruct qm_dqrr_entry *res = qm_cl(dqrr->ring, dqrr->pi);\r\nDPAA_ASSERT(dqrr->pmode == qm_dqrr_pvb);\r\n#ifndef CONFIG_FSL_PAMU\r\ndpaa_invalidate_touch_ro(res);\r\n#endif\r\nif ((__raw_readb(&res->verb) & QM_DQRR_VERB_VBIT) == dqrr->vbit) {\r\ndqrr->pi = (dqrr->pi + 1) & (QM_DQRR_SIZE - 1);\r\nif (!dqrr->pi)\r\ndqrr->vbit ^= QM_DQRR_VERB_VBIT;\r\ndqrr->fill++;\r\n}\r\n}\r\nstatic inline void qm_dqrr_cdc_consume_1ptr(struct qm_portal *portal,\r\nconst struct qm_dqrr_entry *dq,\r\nint park)\r\n{\r\n__maybe_unused struct qm_dqrr *dqrr = &portal->dqrr;\r\nint idx = dqrr_ptr2idx(dq);\r\nDPAA_ASSERT(dqrr->cmode == qm_dqrr_cdc);\r\nDPAA_ASSERT((dqrr->ring + idx) == dq);\r\nDPAA_ASSERT(idx < QM_DQRR_SIZE);\r\nqm_out(portal, QM_REG_DQRR_DCAP, (0 << 8) |\r\n((park ? 1 : 0) << 6) |\r\nidx);\r\n}\r\nstatic inline void qm_dqrr_cdc_consume_n(struct qm_portal *portal, u32 bitmask)\r\n{\r\n__maybe_unused struct qm_dqrr *dqrr = &portal->dqrr;\r\nDPAA_ASSERT(dqrr->cmode == qm_dqrr_cdc);\r\nqm_out(portal, QM_REG_DQRR_DCAP, (1 << 8) |\r\n(bitmask << 16));\r\n}\r\nstatic inline void qm_dqrr_sdqcr_set(struct qm_portal *portal, u32 sdqcr)\r\n{\r\nqm_out(portal, QM_REG_DQRR_SDQCR, sdqcr);\r\n}\r\nstatic inline void qm_dqrr_vdqcr_set(struct qm_portal *portal, u32 vdqcr)\r\n{\r\nqm_out(portal, QM_REG_DQRR_VDQCR, vdqcr);\r\n}\r\nstatic inline void qm_dqrr_set_ithresh(struct qm_portal *portal, u8 ithresh)\r\n{\r\nqm_out(portal, QM_REG_DQRR_ITR, ithresh);\r\n}\r\nstatic union qm_mr_entry *mr_carryclear(union qm_mr_entry *p)\r\n{\r\nuintptr_t addr = (uintptr_t)p;\r\naddr &= ~MR_CARRY;\r\nreturn (union qm_mr_entry *)addr;\r\n}\r\nstatic inline int mr_ptr2idx(const union qm_mr_entry *e)\r\n{\r\nreturn ((uintptr_t)e >> MR_SHIFT) & (QM_MR_SIZE - 1);\r\n}\r\nstatic inline union qm_mr_entry *mr_inc(union qm_mr_entry *e)\r\n{\r\nreturn mr_carryclear(e + 1);\r\n}\r\nstatic inline int qm_mr_init(struct qm_portal *portal, enum qm_mr_pmode pmode,\r\nenum qm_mr_cmode cmode)\r\n{\r\nstruct qm_mr *mr = &portal->mr;\r\nu32 cfg;\r\nmr->ring = portal->addr.ce + QM_CL_MR;\r\nmr->pi = qm_in(portal, QM_REG_MR_PI_CINH) & (QM_MR_SIZE - 1);\r\nmr->ci = qm_in(portal, QM_REG_MR_CI_CINH) & (QM_MR_SIZE - 1);\r\nmr->cursor = mr->ring + mr->ci;\r\nmr->fill = dpaa_cyc_diff(QM_MR_SIZE, mr->ci, mr->pi);\r\nmr->vbit = (qm_in(portal, QM_REG_MR_PI_CINH) & QM_MR_SIZE)\r\n? QM_MR_VERB_VBIT : 0;\r\nmr->ithresh = qm_in(portal, QM_REG_MR_ITR);\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nmr->pmode = pmode;\r\nmr->cmode = cmode;\r\n#endif\r\ncfg = (qm_in(portal, QM_REG_CFG) & 0xfffff0ff) |\r\n((cmode & 1) << 8);\r\nqm_out(portal, QM_REG_CFG, cfg);\r\nreturn 0;\r\n}\r\nstatic inline void qm_mr_finish(struct qm_portal *portal)\r\n{\r\nstruct qm_mr *mr = &portal->mr;\r\nif (mr->ci != mr_ptr2idx(mr->cursor))\r\npr_crit("Ignoring completed MR entries\n");\r\n}\r\nstatic inline const union qm_mr_entry *qm_mr_current(struct qm_portal *portal)\r\n{\r\nstruct qm_mr *mr = &portal->mr;\r\nif (!mr->fill)\r\nreturn NULL;\r\nreturn mr->cursor;\r\n}\r\nstatic inline int qm_mr_next(struct qm_portal *portal)\r\n{\r\nstruct qm_mr *mr = &portal->mr;\r\nDPAA_ASSERT(mr->fill);\r\nmr->cursor = mr_inc(mr->cursor);\r\nreturn --mr->fill;\r\n}\r\nstatic inline void qm_mr_pvb_update(struct qm_portal *portal)\r\n{\r\nstruct qm_mr *mr = &portal->mr;\r\nunion qm_mr_entry *res = qm_cl(mr->ring, mr->pi);\r\nDPAA_ASSERT(mr->pmode == qm_mr_pvb);\r\nif ((__raw_readb(&res->verb) & QM_MR_VERB_VBIT) == mr->vbit) {\r\nmr->pi = (mr->pi + 1) & (QM_MR_SIZE - 1);\r\nif (!mr->pi)\r\nmr->vbit ^= QM_MR_VERB_VBIT;\r\nmr->fill++;\r\nres = mr_inc(res);\r\n}\r\ndpaa_invalidate_touch_ro(res);\r\n}\r\nstatic inline void qm_mr_cci_consume(struct qm_portal *portal, u8 num)\r\n{\r\nstruct qm_mr *mr = &portal->mr;\r\nDPAA_ASSERT(mr->cmode == qm_mr_cci);\r\nmr->ci = (mr->ci + num) & (QM_MR_SIZE - 1);\r\nqm_out(portal, QM_REG_MR_CI_CINH, mr->ci);\r\n}\r\nstatic inline void qm_mr_cci_consume_to_current(struct qm_portal *portal)\r\n{\r\nstruct qm_mr *mr = &portal->mr;\r\nDPAA_ASSERT(mr->cmode == qm_mr_cci);\r\nmr->ci = mr_ptr2idx(mr->cursor);\r\nqm_out(portal, QM_REG_MR_CI_CINH, mr->ci);\r\n}\r\nstatic inline void qm_mr_set_ithresh(struct qm_portal *portal, u8 ithresh)\r\n{\r\nqm_out(portal, QM_REG_MR_ITR, ithresh);\r\n}\r\nstatic inline int qm_mc_init(struct qm_portal *portal)\r\n{\r\nstruct qm_mc *mc = &portal->mc;\r\nmc->cr = portal->addr.ce + QM_CL_CR;\r\nmc->rr = portal->addr.ce + QM_CL_RR0;\r\nmc->rridx = (__raw_readb(&mc->cr->_ncw_verb) & QM_MCC_VERB_VBIT)\r\n? 0 : 1;\r\nmc->vbit = mc->rridx ? QM_MCC_VERB_VBIT : 0;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nmc->state = qman_mc_idle;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic inline void qm_mc_finish(struct qm_portal *portal)\r\n{\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nstruct qm_mc *mc = &portal->mc;\r\nDPAA_ASSERT(mc->state == qman_mc_idle);\r\nif (mc->state != qman_mc_idle)\r\npr_crit("Losing incomplete MC command\n");\r\n#endif\r\n}\r\nstatic inline union qm_mc_command *qm_mc_start(struct qm_portal *portal)\r\n{\r\nstruct qm_mc *mc = &portal->mc;\r\nDPAA_ASSERT(mc->state == qman_mc_idle);\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nmc->state = qman_mc_user;\r\n#endif\r\ndpaa_zero(mc->cr);\r\nreturn mc->cr;\r\n}\r\nstatic inline void qm_mc_commit(struct qm_portal *portal, u8 myverb)\r\n{\r\nstruct qm_mc *mc = &portal->mc;\r\nunion qm_mc_result *rr = mc->rr + mc->rridx;\r\nDPAA_ASSERT(mc->state == qman_mc_user);\r\ndma_wmb();\r\nmc->cr->_ncw_verb = myverb | mc->vbit;\r\ndpaa_flush(mc->cr);\r\ndpaa_invalidate_touch_ro(rr);\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nmc->state = qman_mc_hw;\r\n#endif\r\n}\r\nstatic inline union qm_mc_result *qm_mc_result(struct qm_portal *portal)\r\n{\r\nstruct qm_mc *mc = &portal->mc;\r\nunion qm_mc_result *rr = mc->rr + mc->rridx;\r\nDPAA_ASSERT(mc->state == qman_mc_hw);\r\nif (!__raw_readb(&rr->verb)) {\r\ndpaa_invalidate_touch_ro(rr);\r\nreturn NULL;\r\n}\r\nmc->rridx ^= 1;\r\nmc->vbit ^= QM_MCC_VERB_VBIT;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nmc->state = qman_mc_idle;\r\n#endif\r\nreturn rr;\r\n}\r\nstatic inline int qm_mc_result_timeout(struct qm_portal *portal,\r\nunion qm_mc_result **mcr)\r\n{\r\nint timeout = QM_MCR_TIMEOUT;\r\ndo {\r\n*mcr = qm_mc_result(portal);\r\nif (*mcr)\r\nbreak;\r\nudelay(1);\r\n} while (--timeout);\r\nreturn timeout;\r\n}\r\nstatic inline void fq_set(struct qman_fq *fq, u32 mask)\r\n{\r\nset_bits(mask, &fq->flags);\r\n}\r\nstatic inline void fq_clear(struct qman_fq *fq, u32 mask)\r\n{\r\nclear_bits(mask, &fq->flags);\r\n}\r\nstatic inline int fq_isset(struct qman_fq *fq, u32 mask)\r\n{\r\nreturn fq->flags & mask;\r\n}\r\nstatic inline int fq_isclear(struct qman_fq *fq, u32 mask)\r\n{\r\nreturn !(fq->flags & mask);\r\n}\r\nstatic inline struct qman_portal *get_affine_portal(void)\r\n{\r\nreturn &get_cpu_var(qman_affine_portal);\r\n}\r\nstatic inline void put_affine_portal(void)\r\n{\r\nput_cpu_var(qman_affine_portal);\r\n}\r\nint qman_wq_alloc(void)\r\n{\r\nqm_portal_wq = alloc_workqueue("qman_portal_wq", 0, 1);\r\nif (!qm_portal_wq)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nint qman_alloc_fq_table(u32 _num_fqids)\r\n{\r\nnum_fqids = _num_fqids;\r\nfq_table = vzalloc(num_fqids * 2 * sizeof(struct qman_fq *));\r\nif (!fq_table)\r\nreturn -ENOMEM;\r\npr_debug("Allocated fq lookup table at %p, entry count %u\n",\r\nfq_table, num_fqids * 2);\r\nreturn 0;\r\n}\r\nstatic struct qman_fq *idx_to_fq(u32 idx)\r\n{\r\nstruct qman_fq *fq;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nif (WARN_ON(idx >= num_fqids * 2))\r\nreturn NULL;\r\n#endif\r\nfq = fq_table[idx];\r\nDPAA_ASSERT(!fq || idx == fq->idx);\r\nreturn fq;\r\n}\r\nstatic struct qman_fq *fqid_to_fq(u32 fqid)\r\n{\r\nreturn idx_to_fq(fqid * 2);\r\n}\r\nstatic struct qman_fq *tag_to_fq(u32 tag)\r\n{\r\n#if BITS_PER_LONG == 64\r\nreturn idx_to_fq(tag);\r\n#else\r\nreturn (struct qman_fq *)tag;\r\n#endif\r\n}\r\nstatic u32 fq_to_tag(struct qman_fq *fq)\r\n{\r\n#if BITS_PER_LONG == 64\r\nreturn fq->idx;\r\n#else\r\nreturn (u32)fq;\r\n#endif\r\n}\r\nstatic irqreturn_t portal_isr(int irq, void *ptr)\r\n{\r\nstruct qman_portal *p = ptr;\r\nu32 clear = QM_DQAVAIL_MASK | p->irq_sources;\r\nu32 is = qm_in(&p->p, QM_REG_ISR) & p->irq_sources;\r\nif (unlikely(!is))\r\nreturn IRQ_NONE;\r\nif (is & QM_PIRQ_DQRI)\r\n__poll_portal_fast(p, QMAN_POLL_LIMIT);\r\nclear |= __poll_portal_slow(p, is);\r\nqm_out(&p->p, QM_REG_ISR, clear);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int drain_mr_fqrni(struct qm_portal *p)\r\n{\r\nconst union qm_mr_entry *msg;\r\nloop:\r\nmsg = qm_mr_current(p);\r\nif (!msg) {\r\nu64 now, then = jiffies;\r\ndo {\r\nnow = jiffies;\r\n} while ((then + 10000) > now);\r\nmsg = qm_mr_current(p);\r\nif (!msg)\r\nreturn 0;\r\n}\r\nif ((msg->verb & QM_MR_VERB_TYPE_MASK) != QM_MR_VERB_FQRNI) {\r\npr_err("Found verb 0x%x in MR\n", msg->verb);\r\nreturn -1;\r\n}\r\nqm_mr_next(p);\r\nqm_mr_cci_consume(p, 1);\r\ngoto loop;\r\n}\r\nstatic int qman_create_portal(struct qman_portal *portal,\r\nconst struct qm_portal_config *c,\r\nconst struct qman_cgrs *cgrs)\r\n{\r\nstruct qm_portal *p;\r\nint ret;\r\nu32 isdr;\r\np = &portal->p;\r\n#ifdef CONFIG_FSL_PAMU\r\nportal->use_eqcr_ci_stashing = ((qman_ip_rev >= QMAN_REV30) ? 1 : 0);\r\n#else\r\nportal->use_eqcr_ci_stashing = 0;\r\n#endif\r\np->addr.ce = c->addr_virt[DPAA_PORTAL_CE];\r\np->addr.ci = c->addr_virt[DPAA_PORTAL_CI];\r\nif (qm_eqcr_init(p, qm_eqcr_pvb,\r\nportal->use_eqcr_ci_stashing ? 3 : 0, 1)) {\r\ndev_err(c->dev, "EQCR initialisation failed\n");\r\ngoto fail_eqcr;\r\n}\r\nif (qm_dqrr_init(p, c, qm_dqrr_dpush, qm_dqrr_pvb,\r\nqm_dqrr_cdc, DQRR_MAXFILL)) {\r\ndev_err(c->dev, "DQRR initialisation failed\n");\r\ngoto fail_dqrr;\r\n}\r\nif (qm_mr_init(p, qm_mr_pvb, qm_mr_cci)) {\r\ndev_err(c->dev, "MR initialisation failed\n");\r\ngoto fail_mr;\r\n}\r\nif (qm_mc_init(p)) {\r\ndev_err(c->dev, "MC initialisation failed\n");\r\ngoto fail_mc;\r\n}\r\nqm_dqrr_set_ithresh(p, QMAN_PIRQ_DQRR_ITHRESH);\r\nqm_mr_set_ithresh(p, QMAN_PIRQ_MR_ITHRESH);\r\nqm_out(p, QM_REG_ITPR, QMAN_PIRQ_IPERIOD);\r\nportal->cgrs = kmalloc(2 * sizeof(*cgrs), GFP_KERNEL);\r\nif (!portal->cgrs)\r\ngoto fail_cgrs;\r\nqman_cgrs_init(&portal->cgrs[1]);\r\nif (cgrs)\r\nportal->cgrs[0] = *cgrs;\r\nelse\r\nqman_cgrs_fill(&portal->cgrs[0]);\r\nINIT_LIST_HEAD(&portal->cgr_cbs);\r\nspin_lock_init(&portal->cgr_lock);\r\nINIT_WORK(&portal->congestion_work, qm_congestion_task);\r\nINIT_WORK(&portal->mr_work, qm_mr_process_task);\r\nportal->bits = 0;\r\nportal->sdqcr = QM_SDQCR_SOURCE_CHANNELS | QM_SDQCR_COUNT_UPTO3 |\r\nQM_SDQCR_DEDICATED_PRECEDENCE | QM_SDQCR_TYPE_PRIO_QOS |\r\nQM_SDQCR_TOKEN_SET(0xab) | QM_SDQCR_CHANNELS_DEDICATED;\r\nisdr = 0xffffffff;\r\nqm_out(p, QM_REG_ISDR, isdr);\r\nportal->irq_sources = 0;\r\nqm_out(p, QM_REG_IER, 0);\r\nqm_out(p, QM_REG_ISR, 0xffffffff);\r\nsnprintf(portal->irqname, MAX_IRQNAME, IRQNAME, c->cpu);\r\nif (request_irq(c->irq, portal_isr, 0, portal->irqname, portal)) {\r\ndev_err(c->dev, "request_irq() failed\n");\r\ngoto fail_irq;\r\n}\r\nif (c->cpu != -1 && irq_can_set_affinity(c->irq) &&\r\nirq_set_affinity(c->irq, cpumask_of(c->cpu))) {\r\ndev_err(c->dev, "irq_set_affinity() failed\n");\r\ngoto fail_affinity;\r\n}\r\nisdr &= ~QM_PIRQ_EQCI;\r\nqm_out(p, QM_REG_ISDR, isdr);\r\nret = qm_eqcr_get_fill(p);\r\nif (ret) {\r\ndev_err(c->dev, "EQCR unclean\n");\r\ngoto fail_eqcr_empty;\r\n}\r\nisdr &= ~(QM_PIRQ_DQRI | QM_PIRQ_MRI);\r\nqm_out(p, QM_REG_ISDR, isdr);\r\nif (qm_dqrr_current(p)) {\r\ndev_err(c->dev, "DQRR unclean\n");\r\nqm_dqrr_cdc_consume_n(p, 0xffff);\r\n}\r\nif (qm_mr_current(p) && drain_mr_fqrni(p)) {\r\nconst union qm_mr_entry *e = qm_mr_current(p);\r\ndev_err(c->dev, "MR dirty, VB 0x%x, rc 0x%x, addr 0x%llx\n",\r\ne->verb, e->ern.rc, qm_fd_addr_get64(&e->ern.fd));\r\ngoto fail_dqrr_mr_empty;\r\n}\r\nportal->config = c;\r\nqm_out(p, QM_REG_ISDR, 0);\r\nqm_out(p, QM_REG_IIR, 0);\r\nqm_dqrr_sdqcr_set(p, portal->sdqcr);\r\nreturn 0;\r\nfail_dqrr_mr_empty:\r\nfail_eqcr_empty:\r\nfail_affinity:\r\nfree_irq(c->irq, portal);\r\nfail_irq:\r\nkfree(portal->cgrs);\r\nfail_cgrs:\r\nqm_mc_finish(p);\r\nfail_mc:\r\nqm_mr_finish(p);\r\nfail_mr:\r\nqm_dqrr_finish(p);\r\nfail_dqrr:\r\nqm_eqcr_finish(p);\r\nfail_eqcr:\r\nreturn -EIO;\r\n}\r\nstruct qman_portal *qman_create_affine_portal(const struct qm_portal_config *c,\r\nconst struct qman_cgrs *cgrs)\r\n{\r\nstruct qman_portal *portal;\r\nint err;\r\nportal = &per_cpu(qman_affine_portal, c->cpu);\r\nerr = qman_create_portal(portal, c, cgrs);\r\nif (err)\r\nreturn NULL;\r\nspin_lock(&affine_mask_lock);\r\ncpumask_set_cpu(c->cpu, &affine_mask);\r\naffine_channels[c->cpu] = c->channel;\r\naffine_portals[c->cpu] = portal;\r\nspin_unlock(&affine_mask_lock);\r\nreturn portal;\r\n}\r\nstatic void qman_destroy_portal(struct qman_portal *qm)\r\n{\r\nconst struct qm_portal_config *pcfg;\r\nqm_dqrr_sdqcr_set(&qm->p, 0);\r\nqm_eqcr_cce_update(&qm->p);\r\nqm_eqcr_cce_update(&qm->p);\r\npcfg = qm->config;\r\nfree_irq(pcfg->irq, qm);\r\nkfree(qm->cgrs);\r\nqm_mc_finish(&qm->p);\r\nqm_mr_finish(&qm->p);\r\nqm_dqrr_finish(&qm->p);\r\nqm_eqcr_finish(&qm->p);\r\nqm->config = NULL;\r\n}\r\nconst struct qm_portal_config *qman_destroy_affine_portal(void)\r\n{\r\nstruct qman_portal *qm = get_affine_portal();\r\nconst struct qm_portal_config *pcfg;\r\nint cpu;\r\npcfg = qm->config;\r\ncpu = pcfg->cpu;\r\nqman_destroy_portal(qm);\r\nspin_lock(&affine_mask_lock);\r\ncpumask_clear_cpu(cpu, &affine_mask);\r\nspin_unlock(&affine_mask_lock);\r\nput_affine_portal();\r\nreturn pcfg;\r\n}\r\nstatic inline void fq_state_change(struct qman_portal *p, struct qman_fq *fq,\r\nconst union qm_mr_entry *msg, u8 verb)\r\n{\r\nswitch (verb) {\r\ncase QM_MR_VERB_FQRL:\r\nDPAA_ASSERT(fq_isset(fq, QMAN_FQ_STATE_ORL));\r\nfq_clear(fq, QMAN_FQ_STATE_ORL);\r\nbreak;\r\ncase QM_MR_VERB_FQRN:\r\nDPAA_ASSERT(fq->state == qman_fq_state_parked ||\r\nfq->state == qman_fq_state_sched);\r\nDPAA_ASSERT(fq_isset(fq, QMAN_FQ_STATE_CHANGING));\r\nfq_clear(fq, QMAN_FQ_STATE_CHANGING);\r\nif (msg->fq.fqs & QM_MR_FQS_NOTEMPTY)\r\nfq_set(fq, QMAN_FQ_STATE_NE);\r\nif (msg->fq.fqs & QM_MR_FQS_ORLPRESENT)\r\nfq_set(fq, QMAN_FQ_STATE_ORL);\r\nfq->state = qman_fq_state_retired;\r\nbreak;\r\ncase QM_MR_VERB_FQPN:\r\nDPAA_ASSERT(fq->state == qman_fq_state_sched);\r\nDPAA_ASSERT(fq_isclear(fq, QMAN_FQ_STATE_CHANGING));\r\nfq->state = qman_fq_state_parked;\r\n}\r\n}\r\nstatic void qm_congestion_task(struct work_struct *work)\r\n{\r\nstruct qman_portal *p = container_of(work, struct qman_portal,\r\ncongestion_work);\r\nstruct qman_cgrs rr, c;\r\nunion qm_mc_result *mcr;\r\nstruct qman_cgr *cgr;\r\nspin_lock(&p->cgr_lock);\r\nqm_mc_start(&p->p);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_QUERYCONGESTION);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nspin_unlock(&p->cgr_lock);\r\ndev_crit(p->config->dev, "QUERYCONGESTION timeout\n");\r\nqman_p_irqsource_add(p, QM_PIRQ_CSCI);\r\nreturn;\r\n}\r\nqman_cgrs_and(&rr, (struct qman_cgrs *)&mcr->querycongestion.state,\r\n&p->cgrs[0]);\r\nqman_cgrs_xor(&c, &rr, &p->cgrs[1]);\r\nqman_cgrs_cp(&p->cgrs[1], &rr);\r\nlist_for_each_entry(cgr, &p->cgr_cbs, node)\r\nif (cgr->cb && qman_cgrs_get(&c, cgr->cgrid))\r\ncgr->cb(p, cgr, qman_cgrs_get(&rr, cgr->cgrid));\r\nspin_unlock(&p->cgr_lock);\r\nqman_p_irqsource_add(p, QM_PIRQ_CSCI);\r\n}\r\nstatic void qm_mr_process_task(struct work_struct *work)\r\n{\r\nstruct qman_portal *p = container_of(work, struct qman_portal,\r\nmr_work);\r\nconst union qm_mr_entry *msg;\r\nstruct qman_fq *fq;\r\nu8 verb, num = 0;\r\npreempt_disable();\r\nwhile (1) {\r\nqm_mr_pvb_update(&p->p);\r\nmsg = qm_mr_current(&p->p);\r\nif (!msg)\r\nbreak;\r\nverb = msg->verb & QM_MR_VERB_TYPE_MASK;\r\nif (verb & 0x20) {\r\nswitch (verb) {\r\ncase QM_MR_VERB_FQRNI:\r\nbreak;\r\ncase QM_MR_VERB_FQRN:\r\ncase QM_MR_VERB_FQRL:\r\nfq = fqid_to_fq(qm_fqid_get(&msg->fq));\r\nif (WARN_ON(!fq))\r\nbreak;\r\nfq_state_change(p, fq, msg, verb);\r\nif (fq->cb.fqs)\r\nfq->cb.fqs(p, fq, msg);\r\nbreak;\r\ncase QM_MR_VERB_FQPN:\r\nfq = tag_to_fq(be32_to_cpu(msg->fq.context_b));\r\nfq_state_change(p, fq, msg, verb);\r\nif (fq->cb.fqs)\r\nfq->cb.fqs(p, fq, msg);\r\nbreak;\r\ncase QM_MR_VERB_DC_ERN:\r\npr_crit_once("Leaking DCP ERNs!\n");\r\nbreak;\r\ndefault:\r\npr_crit("Invalid MR verb 0x%02x\n", verb);\r\n}\r\n} else {\r\nfq = tag_to_fq(be32_to_cpu(msg->ern.tag));\r\nfq->cb.ern(p, fq, msg);\r\n}\r\nnum++;\r\nqm_mr_next(&p->p);\r\n}\r\nqm_mr_cci_consume(&p->p, num);\r\nqman_p_irqsource_add(p, QM_PIRQ_MRI);\r\npreempt_enable();\r\n}\r\nstatic u32 __poll_portal_slow(struct qman_portal *p, u32 is)\r\n{\r\nif (is & QM_PIRQ_CSCI) {\r\nqman_p_irqsource_remove(p, QM_PIRQ_CSCI);\r\nqueue_work_on(smp_processor_id(), qm_portal_wq,\r\n&p->congestion_work);\r\n}\r\nif (is & QM_PIRQ_EQRI) {\r\nqm_eqcr_cce_update(&p->p);\r\nqm_eqcr_set_ithresh(&p->p, 0);\r\nwake_up(&affine_queue);\r\n}\r\nif (is & QM_PIRQ_MRI) {\r\nqman_p_irqsource_remove(p, QM_PIRQ_MRI);\r\nqueue_work_on(smp_processor_id(), qm_portal_wq,\r\n&p->mr_work);\r\n}\r\nreturn is;\r\n}\r\nstatic noinline void clear_vdqcr(struct qman_portal *p, struct qman_fq *fq)\r\n{\r\np->vdqcr_owned = NULL;\r\nfq_clear(fq, QMAN_FQ_STATE_VDQCR);\r\nwake_up(&affine_queue);\r\n}\r\nstatic inline unsigned int __poll_portal_fast(struct qman_portal *p,\r\nunsigned int poll_limit)\r\n{\r\nconst struct qm_dqrr_entry *dq;\r\nstruct qman_fq *fq;\r\nenum qman_cb_dqrr_result res;\r\nunsigned int limit = 0;\r\ndo {\r\nqm_dqrr_pvb_update(&p->p);\r\ndq = qm_dqrr_current(&p->p);\r\nif (!dq)\r\nbreak;\r\nif (dq->stat & QM_DQRR_STAT_UNSCHEDULED) {\r\nfq = p->vdqcr_owned;\r\nif (dq->stat & QM_DQRR_STAT_FQ_EMPTY)\r\nfq_clear(fq, QMAN_FQ_STATE_NE);\r\nres = fq->cb.dqrr(p, fq, dq);\r\nif (res == qman_cb_dqrr_stop)\r\nbreak;\r\nif (dq->stat & QM_DQRR_STAT_DQCR_EXPIRED)\r\nclear_vdqcr(p, fq);\r\n} else {\r\nfq = tag_to_fq(be32_to_cpu(dq->context_b));\r\nres = fq->cb.dqrr(p, fq, dq);\r\nif (res == qman_cb_dqrr_stop)\r\nbreak;\r\n}\r\nDPAA_ASSERT((dq->stat & QM_DQRR_STAT_FQ_HELDACTIVE) ||\r\n(res != qman_cb_dqrr_park));\r\nif (res != qman_cb_dqrr_defer)\r\nqm_dqrr_cdc_consume_1ptr(&p->p, dq,\r\nres == qman_cb_dqrr_park);\r\nqm_dqrr_next(&p->p);\r\n} while (++limit < poll_limit && res != qman_cb_dqrr_consume_stop);\r\nreturn limit;\r\n}\r\nvoid qman_p_irqsource_add(struct qman_portal *p, u32 bits)\r\n{\r\nunsigned long irqflags;\r\nlocal_irq_save(irqflags);\r\nset_bits(bits & QM_PIRQ_VISIBLE, &p->irq_sources);\r\nqm_out(&p->p, QM_REG_IER, p->irq_sources);\r\nlocal_irq_restore(irqflags);\r\n}\r\nvoid qman_p_irqsource_remove(struct qman_portal *p, u32 bits)\r\n{\r\nunsigned long irqflags;\r\nu32 ier;\r\nlocal_irq_save(irqflags);\r\nbits &= QM_PIRQ_VISIBLE;\r\nclear_bits(bits, &p->irq_sources);\r\nqm_out(&p->p, QM_REG_IER, p->irq_sources);\r\nier = qm_in(&p->p, QM_REG_IER);\r\nqm_out(&p->p, QM_REG_ISR, ~ier);\r\nlocal_irq_restore(irqflags);\r\n}\r\nconst cpumask_t *qman_affine_cpus(void)\r\n{\r\nreturn &affine_mask;\r\n}\r\nu16 qman_affine_channel(int cpu)\r\n{\r\nif (cpu < 0) {\r\nstruct qman_portal *portal = get_affine_portal();\r\ncpu = portal->config->cpu;\r\nput_affine_portal();\r\n}\r\nWARN_ON(!cpumask_test_cpu(cpu, &affine_mask));\r\nreturn affine_channels[cpu];\r\n}\r\nstruct qman_portal *qman_get_affine_portal(int cpu)\r\n{\r\nreturn affine_portals[cpu];\r\n}\r\nint qman_p_poll_dqrr(struct qman_portal *p, unsigned int limit)\r\n{\r\nreturn __poll_portal_fast(p, limit);\r\n}\r\nvoid qman_p_static_dequeue_add(struct qman_portal *p, u32 pools)\r\n{\r\nunsigned long irqflags;\r\nlocal_irq_save(irqflags);\r\npools &= p->config->pools;\r\np->sdqcr |= pools;\r\nqm_dqrr_sdqcr_set(&p->p, p->sdqcr);\r\nlocal_irq_restore(irqflags);\r\n}\r\nstatic const char *mcr_result_str(u8 result)\r\n{\r\nswitch (result) {\r\ncase QM_MCR_RESULT_NULL:\r\nreturn "QM_MCR_RESULT_NULL";\r\ncase QM_MCR_RESULT_OK:\r\nreturn "QM_MCR_RESULT_OK";\r\ncase QM_MCR_RESULT_ERR_FQID:\r\nreturn "QM_MCR_RESULT_ERR_FQID";\r\ncase QM_MCR_RESULT_ERR_FQSTATE:\r\nreturn "QM_MCR_RESULT_ERR_FQSTATE";\r\ncase QM_MCR_RESULT_ERR_NOTEMPTY:\r\nreturn "QM_MCR_RESULT_ERR_NOTEMPTY";\r\ncase QM_MCR_RESULT_PENDING:\r\nreturn "QM_MCR_RESULT_PENDING";\r\ncase QM_MCR_RESULT_ERR_BADCOMMAND:\r\nreturn "QM_MCR_RESULT_ERR_BADCOMMAND";\r\n}\r\nreturn "<unknown MCR result>";\r\n}\r\nint qman_create_fq(u32 fqid, u32 flags, struct qman_fq *fq)\r\n{\r\nif (flags & QMAN_FQ_FLAG_DYNAMIC_FQID) {\r\nint ret = qman_alloc_fqid(&fqid);\r\nif (ret)\r\nreturn ret;\r\n}\r\nfq->fqid = fqid;\r\nfq->flags = flags;\r\nfq->state = qman_fq_state_oos;\r\nfq->cgr_groupid = 0;\r\nif (fqid == 0 || fqid >= num_fqids) {\r\nWARN(1, "bad fqid %d\n", fqid);\r\nreturn -EINVAL;\r\n}\r\nfq->idx = fqid * 2;\r\nif (flags & QMAN_FQ_FLAG_NO_MODIFY)\r\nfq->idx++;\r\nWARN_ON(fq_table[fq->idx]);\r\nfq_table[fq->idx] = fq;\r\nreturn 0;\r\n}\r\nvoid qman_destroy_fq(struct qman_fq *fq)\r\n{\r\nswitch (fq->state) {\r\ncase qman_fq_state_parked:\r\ncase qman_fq_state_oos:\r\nif (fq_isset(fq, QMAN_FQ_FLAG_DYNAMIC_FQID))\r\nqman_release_fqid(fq->fqid);\r\nDPAA_ASSERT(fq_table[fq->idx]);\r\nfq_table[fq->idx] = NULL;\r\nreturn;\r\ndefault:\r\nbreak;\r\n}\r\nDPAA_ASSERT(NULL == "qman_free_fq() on unquiesced FQ!");\r\n}\r\nu32 qman_fq_fqid(struct qman_fq *fq)\r\n{\r\nreturn fq->fqid;\r\n}\r\nint qman_init_fq(struct qman_fq *fq, u32 flags, struct qm_mcc_initfq *opts)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p;\r\nu8 res, myverb;\r\nint ret = 0;\r\nmyverb = (flags & QMAN_INITFQ_FLAG_SCHED)\r\n? QM_MCC_VERB_INITFQ_SCHED : QM_MCC_VERB_INITFQ_PARKED;\r\nif (fq->state != qman_fq_state_oos &&\r\nfq->state != qman_fq_state_parked)\r\nreturn -EINVAL;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\r\nreturn -EINVAL;\r\n#endif\r\nif (opts && (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_OAC)) {\r\nif (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_TDTHRESH)\r\nreturn -EINVAL;\r\n}\r\np = get_affine_portal();\r\nif (fq_isset(fq, QMAN_FQ_STATE_CHANGING) ||\r\n(fq->state != qman_fq_state_oos &&\r\nfq->state != qman_fq_state_parked)) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nmcc = qm_mc_start(&p->p);\r\nif (opts)\r\nmcc->initfq = *opts;\r\nqm_fqid_set(&mcc->fq, fq->fqid);\r\nmcc->initfq.count = 0;\r\nif (fq_isclear(fq, QMAN_FQ_FLAG_TO_DCPORTAL)) {\r\ndma_addr_t phys_fq;\r\nmcc->initfq.we_mask |= cpu_to_be16(QM_INITFQ_WE_CONTEXTB);\r\nmcc->initfq.fqd.context_b = cpu_to_be32(fq_to_tag(fq));\r\nif (!(be16_to_cpu(mcc->initfq.we_mask) &\r\nQM_INITFQ_WE_CONTEXTA)) {\r\nmcc->initfq.we_mask |=\r\ncpu_to_be16(QM_INITFQ_WE_CONTEXTA);\r\nmemset(&mcc->initfq.fqd.context_a, 0,\r\nsizeof(mcc->initfq.fqd.context_a));\r\n} else {\r\nstruct qman_portal *p = qman_dma_portal;\r\nphys_fq = dma_map_single(p->config->dev, fq,\r\nsizeof(*fq), DMA_TO_DEVICE);\r\nif (dma_mapping_error(p->config->dev, phys_fq)) {\r\ndev_err(p->config->dev, "dma_mapping failed\n");\r\nret = -EIO;\r\ngoto out;\r\n}\r\nqm_fqd_stashing_set64(&mcc->initfq.fqd, phys_fq);\r\n}\r\n}\r\nif (flags & QMAN_INITFQ_FLAG_LOCAL) {\r\nint wq = 0;\r\nif (!(be16_to_cpu(mcc->initfq.we_mask) &\r\nQM_INITFQ_WE_DESTWQ)) {\r\nmcc->initfq.we_mask |=\r\ncpu_to_be16(QM_INITFQ_WE_DESTWQ);\r\nwq = 4;\r\n}\r\nqm_fqd_set_destwq(&mcc->initfq.fqd, p->config->channel, wq);\r\n}\r\nqm_mc_commit(&p->p, myverb);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\ndev_err(p->config->dev, "MCR timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == myverb);\r\nres = mcr->result;\r\nif (res != QM_MCR_RESULT_OK) {\r\nret = -EIO;\r\ngoto out;\r\n}\r\nif (opts) {\r\nif (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_FQCTRL) {\r\nif (be16_to_cpu(opts->fqd.fq_ctrl) & QM_FQCTRL_CGE)\r\nfq_set(fq, QMAN_FQ_STATE_CGR_EN);\r\nelse\r\nfq_clear(fq, QMAN_FQ_STATE_CGR_EN);\r\n}\r\nif (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_CGID)\r\nfq->cgr_groupid = opts->fqd.cgid;\r\n}\r\nfq->state = (flags & QMAN_INITFQ_FLAG_SCHED) ?\r\nqman_fq_state_sched : qman_fq_state_parked;\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nint qman_schedule_fq(struct qman_fq *fq)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p;\r\nint ret = 0;\r\nif (fq->state != qman_fq_state_parked)\r\nreturn -EINVAL;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\r\nreturn -EINVAL;\r\n#endif\r\np = get_affine_portal();\r\nif (fq_isset(fq, QMAN_FQ_STATE_CHANGING) ||\r\nfq->state != qman_fq_state_parked) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fq->fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_SCHED);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\ndev_err(p->config->dev, "ALTER_SCHED timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_ALTER_SCHED);\r\nif (mcr->result != QM_MCR_RESULT_OK) {\r\nret = -EIO;\r\ngoto out;\r\n}\r\nfq->state = qman_fq_state_sched;\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nint qman_retire_fq(struct qman_fq *fq, u32 *flags)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p;\r\nint ret;\r\nu8 res;\r\nif (fq->state != qman_fq_state_parked &&\r\nfq->state != qman_fq_state_sched)\r\nreturn -EINVAL;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\r\nreturn -EINVAL;\r\n#endif\r\np = get_affine_portal();\r\nif (fq_isset(fq, QMAN_FQ_STATE_CHANGING) ||\r\nfq->state == qman_fq_state_retired ||\r\nfq->state == qman_fq_state_oos) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fq->fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_RETIRE);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\ndev_crit(p->config->dev, "ALTER_RETIRE timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_ALTER_RETIRE);\r\nres = mcr->result;\r\nif (res == QM_MCR_RESULT_OK) {\r\nret = 0;\r\nif (mcr->alterfq.fqs & QM_MCR_FQS_NOTEMPTY)\r\nfq_set(fq, QMAN_FQ_STATE_NE);\r\nif (mcr->alterfq.fqs & QM_MCR_FQS_ORLPRESENT)\r\nfq_set(fq, QMAN_FQ_STATE_ORL);\r\nif (flags)\r\n*flags = fq->flags;\r\nfq->state = qman_fq_state_retired;\r\nif (fq->cb.fqs) {\r\nunion qm_mr_entry msg;\r\nmsg.verb = QM_MR_VERB_FQRNI;\r\nmsg.fq.fqs = mcr->alterfq.fqs;\r\nqm_fqid_set(&msg.fq, fq->fqid);\r\nmsg.fq.context_b = cpu_to_be32(fq_to_tag(fq));\r\nfq->cb.fqs(p, fq, &msg);\r\n}\r\n} else if (res == QM_MCR_RESULT_PENDING) {\r\nret = 1;\r\nfq_set(fq, QMAN_FQ_STATE_CHANGING);\r\n} else {\r\nret = -EIO;\r\n}\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nint qman_oos_fq(struct qman_fq *fq)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p;\r\nint ret = 0;\r\nif (fq->state != qman_fq_state_retired)\r\nreturn -EINVAL;\r\n#ifdef CONFIG_FSL_DPAA_CHECKING\r\nif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\r\nreturn -EINVAL;\r\n#endif\r\np = get_affine_portal();\r\nif (fq_isset(fq, QMAN_FQ_STATE_BLOCKOOS) ||\r\nfq->state != qman_fq_state_retired) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fq->fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_OOS);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_ALTER_OOS);\r\nif (mcr->result != QM_MCR_RESULT_OK) {\r\nret = -EIO;\r\ngoto out;\r\n}\r\nfq->state = qman_fq_state_oos;\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nint qman_query_fq(struct qman_fq *fq, struct qm_fqd *fqd)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p = get_affine_portal();\r\nint ret = 0;\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fq->fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ);\r\nif (mcr->result == QM_MCR_RESULT_OK)\r\n*fqd = mcr->queryfq.fqd;\r\nelse\r\nret = -EIO;\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nint qman_query_fq_np(struct qman_fq *fq, struct qm_mcr_queryfq_np *np)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p = get_affine_portal();\r\nint ret = 0;\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fq->fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ_NP);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ_NP);\r\nif (mcr->result == QM_MCR_RESULT_OK)\r\n*np = mcr->queryfq_np;\r\nelse if (mcr->result == QM_MCR_RESULT_ERR_FQID)\r\nret = -ERANGE;\r\nelse\r\nret = -EIO;\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nstatic int qman_query_cgr(struct qman_cgr *cgr,\r\nstruct qm_mcr_querycgr *cgrd)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p = get_affine_portal();\r\nint ret = 0;\r\nmcc = qm_mc_start(&p->p);\r\nmcc->cgr.cgid = cgr->cgrid;\r\nqm_mc_commit(&p->p, QM_MCC_VERB_QUERYCGR);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCC_VERB_QUERYCGR);\r\nif (mcr->result == QM_MCR_RESULT_OK)\r\n*cgrd = mcr->querycgr;\r\nelse {\r\ndev_err(p->config->dev, "QUERY_CGR failed: %s\n",\r\nmcr_result_str(mcr->result));\r\nret = -EIO;\r\n}\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nint qman_query_cgr_congested(struct qman_cgr *cgr, bool *result)\r\n{\r\nstruct qm_mcr_querycgr query_cgr;\r\nint err;\r\nerr = qman_query_cgr(cgr, &query_cgr);\r\nif (err)\r\nreturn err;\r\n*result = !!query_cgr.cgr.cs;\r\nreturn 0;\r\n}\r\nstatic int set_p_vdqcr(struct qman_portal *p, struct qman_fq *fq, u32 vdqcr)\r\n{\r\nunsigned long irqflags;\r\nint ret = -EBUSY;\r\nlocal_irq_save(irqflags);\r\nif (p->vdqcr_owned)\r\ngoto out;\r\nif (fq_isset(fq, QMAN_FQ_STATE_VDQCR))\r\ngoto out;\r\nfq_set(fq, QMAN_FQ_STATE_VDQCR);\r\np->vdqcr_owned = fq;\r\nqm_dqrr_vdqcr_set(&p->p, vdqcr);\r\nret = 0;\r\nout:\r\nlocal_irq_restore(irqflags);\r\nreturn ret;\r\n}\r\nstatic int set_vdqcr(struct qman_portal **p, struct qman_fq *fq, u32 vdqcr)\r\n{\r\nint ret;\r\n*p = get_affine_portal();\r\nret = set_p_vdqcr(*p, fq, vdqcr);\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nstatic int wait_vdqcr_start(struct qman_portal **p, struct qman_fq *fq,\r\nu32 vdqcr, u32 flags)\r\n{\r\nint ret = 0;\r\nif (flags & QMAN_VOLATILE_FLAG_WAIT_INT)\r\nret = wait_event_interruptible(affine_queue,\r\n!set_vdqcr(p, fq, vdqcr));\r\nelse\r\nwait_event(affine_queue, !set_vdqcr(p, fq, vdqcr));\r\nreturn ret;\r\n}\r\nint qman_volatile_dequeue(struct qman_fq *fq, u32 flags, u32 vdqcr)\r\n{\r\nstruct qman_portal *p;\r\nint ret;\r\nif (fq->state != qman_fq_state_parked &&\r\nfq->state != qman_fq_state_retired)\r\nreturn -EINVAL;\r\nif (vdqcr & QM_VDQCR_FQID_MASK)\r\nreturn -EINVAL;\r\nif (fq_isset(fq, QMAN_FQ_STATE_VDQCR))\r\nreturn -EBUSY;\r\nvdqcr = (vdqcr & ~QM_VDQCR_FQID_MASK) | fq->fqid;\r\nif (flags & QMAN_VOLATILE_FLAG_WAIT)\r\nret = wait_vdqcr_start(&p, fq, vdqcr, flags);\r\nelse\r\nret = set_vdqcr(&p, fq, vdqcr);\r\nif (ret)\r\nreturn ret;\r\nif (flags & QMAN_VOLATILE_FLAG_FINISH) {\r\nif (flags & QMAN_VOLATILE_FLAG_WAIT_INT)\r\nwait_event_interruptible(affine_queue,\r\n!fq_isset(fq, QMAN_FQ_STATE_VDQCR));\r\nelse\r\nwait_event(affine_queue,\r\n!fq_isset(fq, QMAN_FQ_STATE_VDQCR));\r\n}\r\nreturn 0;\r\n}\r\nstatic void update_eqcr_ci(struct qman_portal *p, u8 avail)\r\n{\r\nif (avail)\r\nqm_eqcr_cce_prefetch(&p->p);\r\nelse\r\nqm_eqcr_cce_update(&p->p);\r\n}\r\nint qman_enqueue(struct qman_fq *fq, const struct qm_fd *fd)\r\n{\r\nstruct qman_portal *p;\r\nstruct qm_eqcr_entry *eq;\r\nunsigned long irqflags;\r\nu8 avail;\r\np = get_affine_portal();\r\nlocal_irq_save(irqflags);\r\nif (p->use_eqcr_ci_stashing) {\r\neq = qm_eqcr_start_stash(&p->p);\r\n} else {\r\navail = qm_eqcr_get_avail(&p->p);\r\nif (avail < 2)\r\nupdate_eqcr_ci(p, avail);\r\neq = qm_eqcr_start_no_stash(&p->p);\r\n}\r\nif (unlikely(!eq))\r\ngoto out;\r\nqm_fqid_set(eq, fq->fqid);\r\neq->tag = cpu_to_be32(fq_to_tag(fq));\r\neq->fd = *fd;\r\nqm_eqcr_pvb_commit(&p->p, QM_EQCR_VERB_CMD_ENQUEUE);\r\nout:\r\nlocal_irq_restore(irqflags);\r\nput_affine_portal();\r\nreturn 0;\r\n}\r\nstatic int qm_modify_cgr(struct qman_cgr *cgr, u32 flags,\r\nstruct qm_mcc_initcgr *opts)\r\n{\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nstruct qman_portal *p = get_affine_portal();\r\nu8 verb = QM_MCC_VERB_MODIFYCGR;\r\nint ret = 0;\r\nmcc = qm_mc_start(&p->p);\r\nif (opts)\r\nmcc->initcgr = *opts;\r\nmcc->initcgr.cgid = cgr->cgrid;\r\nif (flags & QMAN_CGR_FLAG_USE_INIT)\r\nverb = QM_MCC_VERB_INITCGR;\r\nqm_mc_commit(&p->p, verb);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == verb);\r\nif (mcr->result != QM_MCR_RESULT_OK)\r\nret = -EIO;\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nstatic void qm_cgr_cscn_targ_set(struct __qm_mc_cgr *cgr, int pi, u32 val)\r\n{\r\nif (qman_ip_rev >= QMAN_REV30)\r\ncgr->cscn_targ_upd_ctrl = cpu_to_be16(pi |\r\nQM_CGR_TARG_UDP_CTRL_WRITE_BIT);\r\nelse\r\ncgr->cscn_targ = cpu_to_be32(val | QM_CGR_TARG_PORTAL(pi));\r\n}\r\nstatic void qm_cgr_cscn_targ_clear(struct __qm_mc_cgr *cgr, int pi, u32 val)\r\n{\r\nif (qman_ip_rev >= QMAN_REV30)\r\ncgr->cscn_targ_upd_ctrl = cpu_to_be16(pi);\r\nelse\r\ncgr->cscn_targ = cpu_to_be32(val & ~QM_CGR_TARG_PORTAL(pi));\r\n}\r\nvoid qman_init_cgr_all(void)\r\n{\r\nstruct qman_cgr cgr;\r\nint err_cnt = 0;\r\nfor (cgr.cgrid = 0; cgr.cgrid < CGR_NUM; cgr.cgrid++) {\r\nif (qm_modify_cgr(&cgr, QMAN_CGR_FLAG_USE_INIT, NULL))\r\nerr_cnt++;\r\n}\r\nif (err_cnt)\r\npr_err("Warning: %d error%s while initialising CGR h/w\n",\r\nerr_cnt, (err_cnt > 1) ? "s" : "");\r\n}\r\nint qman_create_cgr(struct qman_cgr *cgr, u32 flags,\r\nstruct qm_mcc_initcgr *opts)\r\n{\r\nstruct qm_mcr_querycgr cgr_state;\r\nint ret;\r\nstruct qman_portal *p;\r\nif (cgr->cgrid >= CGR_NUM)\r\nreturn -EINVAL;\r\npreempt_disable();\r\np = get_affine_portal();\r\nqman_cgr_cpus[cgr->cgrid] = smp_processor_id();\r\npreempt_enable();\r\ncgr->chan = p->config->channel;\r\nspin_lock(&p->cgr_lock);\r\nif (opts) {\r\nstruct qm_mcc_initcgr local_opts = *opts;\r\nret = qman_query_cgr(cgr, &cgr_state);\r\nif (ret)\r\ngoto out;\r\nqm_cgr_cscn_targ_set(&local_opts.cgr, PORTAL_IDX(p),\r\nbe32_to_cpu(cgr_state.cgr.cscn_targ));\r\nlocal_opts.we_mask |= cpu_to_be16(QM_CGR_WE_CSCN_TARG);\r\nif (flags & QMAN_CGR_FLAG_USE_INIT)\r\nret = qm_modify_cgr(cgr, QMAN_CGR_FLAG_USE_INIT,\r\n&local_opts);\r\nelse\r\nret = qm_modify_cgr(cgr, 0, &local_opts);\r\nif (ret)\r\ngoto out;\r\n}\r\nlist_add(&cgr->node, &p->cgr_cbs);\r\nret = qman_query_cgr(cgr, &cgr_state);\r\nif (ret) {\r\ndev_err(p->config->dev, "CGR HW state partially modified\n");\r\nret = 0;\r\ngoto out;\r\n}\r\nif (cgr->cb && cgr_state.cgr.cscn_en &&\r\nqman_cgrs_get(&p->cgrs[1], cgr->cgrid))\r\ncgr->cb(p, cgr, 1);\r\nout:\r\nspin_unlock(&p->cgr_lock);\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nint qman_delete_cgr(struct qman_cgr *cgr)\r\n{\r\nunsigned long irqflags;\r\nstruct qm_mcr_querycgr cgr_state;\r\nstruct qm_mcc_initcgr local_opts;\r\nint ret = 0;\r\nstruct qman_cgr *i;\r\nstruct qman_portal *p = get_affine_portal();\r\nif (cgr->chan != p->config->channel) {\r\ndev_err(p->config->dev, "CGR not owned by current portal");\r\ndev_dbg(p->config->dev, " create 0x%x, delete 0x%x\n",\r\ncgr->chan, p->config->channel);\r\nret = -EINVAL;\r\ngoto put_portal;\r\n}\r\nmemset(&local_opts, 0, sizeof(struct qm_mcc_initcgr));\r\nspin_lock_irqsave(&p->cgr_lock, irqflags);\r\nlist_del(&cgr->node);\r\nlist_for_each_entry(i, &p->cgr_cbs, node)\r\nif (i->cgrid == cgr->cgrid && i->cb)\r\ngoto release_lock;\r\nret = qman_query_cgr(cgr, &cgr_state);\r\nif (ret) {\r\nlist_add(&cgr->node, &p->cgr_cbs);\r\ngoto release_lock;\r\n}\r\nlocal_opts.we_mask = cpu_to_be16(QM_CGR_WE_CSCN_TARG);\r\nqm_cgr_cscn_targ_clear(&local_opts.cgr, PORTAL_IDX(p),\r\nbe32_to_cpu(cgr_state.cgr.cscn_targ));\r\nret = qm_modify_cgr(cgr, 0, &local_opts);\r\nif (ret)\r\nlist_add(&cgr->node, &p->cgr_cbs);\r\nrelease_lock:\r\nspin_unlock_irqrestore(&p->cgr_lock, irqflags);\r\nput_portal:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nstatic int qman_delete_cgr_thread(void *p)\r\n{\r\nstruct cgr_comp *cgr_comp = (struct cgr_comp *)p;\r\nint ret;\r\nret = qman_delete_cgr(cgr_comp->cgr);\r\ncomplete(&cgr_comp->completion);\r\nreturn ret;\r\n}\r\nvoid qman_delete_cgr_safe(struct qman_cgr *cgr)\r\n{\r\nstruct task_struct *thread;\r\nstruct cgr_comp cgr_comp;\r\npreempt_disable();\r\nif (qman_cgr_cpus[cgr->cgrid] != smp_processor_id()) {\r\ninit_completion(&cgr_comp.completion);\r\ncgr_comp.cgr = cgr;\r\nthread = kthread_create(qman_delete_cgr_thread, &cgr_comp,\r\n"cgr_del");\r\nif (IS_ERR(thread))\r\ngoto out;\r\nkthread_bind(thread, qman_cgr_cpus[cgr->cgrid]);\r\nwake_up_process(thread);\r\nwait_for_completion(&cgr_comp.completion);\r\npreempt_enable();\r\nreturn;\r\n}\r\nout:\r\nqman_delete_cgr(cgr);\r\npreempt_enable();\r\n}\r\nstatic int _qm_mr_consume_and_match_verb(struct qm_portal *p, int v)\r\n{\r\nconst union qm_mr_entry *msg;\r\nint found = 0;\r\nqm_mr_pvb_update(p);\r\nmsg = qm_mr_current(p);\r\nwhile (msg) {\r\nif ((msg->verb & QM_MR_VERB_TYPE_MASK) == v)\r\nfound = 1;\r\nqm_mr_next(p);\r\nqm_mr_cci_consume_to_current(p);\r\nqm_mr_pvb_update(p);\r\nmsg = qm_mr_current(p);\r\n}\r\nreturn found;\r\n}\r\nstatic int _qm_dqrr_consume_and_match(struct qm_portal *p, u32 fqid, int s,\r\nbool wait)\r\n{\r\nconst struct qm_dqrr_entry *dqrr;\r\nint found = 0;\r\ndo {\r\nqm_dqrr_pvb_update(p);\r\ndqrr = qm_dqrr_current(p);\r\nif (!dqrr)\r\ncpu_relax();\r\n} while (wait && !dqrr);\r\nwhile (dqrr) {\r\nif (qm_fqid_get(dqrr) == fqid && (dqrr->stat & s))\r\nfound = 1;\r\nqm_dqrr_cdc_consume_1ptr(p, dqrr, 0);\r\nqm_dqrr_pvb_update(p);\r\nqm_dqrr_next(p);\r\ndqrr = qm_dqrr_current(p);\r\n}\r\nreturn found;\r\n}\r\nstatic int qman_shutdown_fq(u32 fqid)\r\n{\r\nstruct qman_portal *p;\r\nstruct device *dev;\r\nunion qm_mc_command *mcc;\r\nunion qm_mc_result *mcr;\r\nint orl_empty, drain = 0, ret = 0;\r\nu32 channel, wq, res;\r\nu8 state;\r\np = get_affine_portal();\r\ndev = p->config->dev;\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ_NP);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\ndev_err(dev, "QUERYFQ_NP timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ_NP);\r\nstate = mcr->queryfq_np.state & QM_MCR_NP_STATE_MASK;\r\nif (state == QM_MCR_NP_STATE_OOS)\r\ngoto out;\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\ndev_err(dev, "QUERYFQ timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ);\r\nchannel = qm_fqd_get_chan(&mcr->queryfq.fqd);\r\nwq = qm_fqd_get_wq(&mcr->queryfq.fqd);\r\nswitch (state) {\r\ncase QM_MCR_NP_STATE_TEN_SCHED:\r\ncase QM_MCR_NP_STATE_TRU_SCHED:\r\ncase QM_MCR_NP_STATE_ACTIVE:\r\ncase QM_MCR_NP_STATE_PARKED:\r\norl_empty = 0;\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_RETIRE);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\ndev_err(dev, "QUERYFQ_NP timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) ==\r\nQM_MCR_VERB_ALTER_RETIRE);\r\nres = mcr->result;\r\nif (res == QM_MCR_RESULT_PENDING) {\r\nint found_fqrn = 0;\r\nu16 dequeue_wq = 0;\r\ndrain = 1;\r\nif (channel >= qm_channel_pool1 &&\r\nchannel < qm_channel_pool1 + 15) {\r\ndequeue_wq = (channel -\r\nqm_channel_pool1 + 1)<<4 | wq;\r\n} else if (channel < qm_channel_pool1) {\r\ndequeue_wq = wq;\r\n} else {\r\ndev_err(dev, "Can't recover FQ 0x%x, ch: 0x%x",\r\nfqid, channel);\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nif (channel < qm_channel_pool1)\r\nqm_dqrr_sdqcr_set(&p->p,\r\nQM_SDQCR_TYPE_ACTIVE |\r\nQM_SDQCR_CHANNELS_DEDICATED);\r\nelse\r\nqm_dqrr_sdqcr_set(&p->p,\r\nQM_SDQCR_TYPE_ACTIVE |\r\nQM_SDQCR_CHANNELS_POOL_CONV\r\n(channel));\r\ndo {\r\nqm_dqrr_drain_nomatch(&p->p);\r\nfound_fqrn = qm_mr_drain(&p->p, FQRN);\r\ncpu_relax();\r\n} while (!found_fqrn);\r\n}\r\nif (res != QM_MCR_RESULT_OK &&\r\nres != QM_MCR_RESULT_PENDING) {\r\ndev_err(dev, "retire_fq failed: FQ 0x%x, res=0x%x\n",\r\nfqid, res);\r\nret = -EIO;\r\ngoto out;\r\n}\r\nif (!(mcr->alterfq.fqs & QM_MCR_FQS_ORLPRESENT)) {\r\norl_empty = 1;\r\n}\r\nif (drain || mcr->alterfq.fqs & QM_MCR_FQS_NOTEMPTY) {\r\ndo {\r\nu32 vdqcr = fqid | QM_VDQCR_NUMFRAMES_SET(3);\r\nqm_dqrr_vdqcr_set(&p->p, vdqcr);\r\n} while (qm_dqrr_drain_wait(&p->p, fqid, FQ_EMPTY));\r\n}\r\nqm_dqrr_sdqcr_set(&p->p, 0);\r\nwhile (!orl_empty) {\r\norl_empty = qm_mr_drain(&p->p, FQRL);\r\ncpu_relax();\r\n}\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_OOS);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) ==\r\nQM_MCR_VERB_ALTER_OOS);\r\nif (mcr->result != QM_MCR_RESULT_OK) {\r\ndev_err(dev, "OOS after drain fail: FQ 0x%x (0x%x)\n",\r\nfqid, mcr->result);\r\nret = -EIO;\r\ngoto out;\r\n}\r\nbreak;\r\ncase QM_MCR_NP_STATE_RETIRED:\r\nmcc = qm_mc_start(&p->p);\r\nqm_fqid_set(&mcc->fq, fqid);\r\nqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_OOS);\r\nif (!qm_mc_result_timeout(&p->p, &mcr)) {\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) ==\r\nQM_MCR_VERB_ALTER_OOS);\r\nif (mcr->result) {\r\ndev_err(dev, "OOS fail: FQ 0x%x (0x%x)\n",\r\nfqid, mcr->result);\r\nret = -EIO;\r\ngoto out;\r\n}\r\nbreak;\r\ncase QM_MCR_NP_STATE_OOS:\r\nbreak;\r\ndefault:\r\nret = -EIO;\r\n}\r\nout:\r\nput_affine_portal();\r\nreturn ret;\r\n}\r\nconst struct qm_portal_config *qman_get_qm_portal_config(\r\nstruct qman_portal *portal)\r\n{\r\nreturn portal->config;\r\n}\r\nstatic int qman_alloc_range(struct gen_pool *p, u32 *result, u32 cnt)\r\n{\r\nunsigned long addr;\r\naddr = gen_pool_alloc(p, cnt);\r\nif (!addr)\r\nreturn -ENOMEM;\r\n*result = addr & ~DPAA_GENALLOC_OFF;\r\nreturn 0;\r\n}\r\nint qman_alloc_fqid_range(u32 *result, u32 count)\r\n{\r\nreturn qman_alloc_range(qm_fqalloc, result, count);\r\n}\r\nint qman_alloc_pool_range(u32 *result, u32 count)\r\n{\r\nreturn qman_alloc_range(qm_qpalloc, result, count);\r\n}\r\nint qman_alloc_cgrid_range(u32 *result, u32 count)\r\n{\r\nreturn qman_alloc_range(qm_cgralloc, result, count);\r\n}\r\nint qman_release_fqid(u32 fqid)\r\n{\r\nint ret = qman_shutdown_fq(fqid);\r\nif (ret) {\r\npr_debug("FQID %d leaked\n", fqid);\r\nreturn ret;\r\n}\r\ngen_pool_free(qm_fqalloc, fqid | DPAA_GENALLOC_OFF, 1);\r\nreturn 0;\r\n}\r\nstatic int qpool_cleanup(u32 qp)\r\n{\r\nstruct qman_fq fq = {\r\n.fqid = QM_FQID_RANGE_START\r\n};\r\nint err;\r\ndo {\r\nstruct qm_mcr_queryfq_np np;\r\nerr = qman_query_fq_np(&fq, &np);\r\nif (err == -ERANGE)\r\nreturn 0;\r\nelse if (WARN_ON(err))\r\nreturn err;\r\nif ((np.state & QM_MCR_NP_STATE_MASK) != QM_MCR_NP_STATE_OOS) {\r\nstruct qm_fqd fqd;\r\nerr = qman_query_fq(&fq, &fqd);\r\nif (WARN_ON(err))\r\nreturn err;\r\nif (qm_fqd_get_chan(&fqd) == qp) {\r\nerr = qman_shutdown_fq(fq.fqid);\r\nif (err)\r\nreturn err;\r\n}\r\n}\r\nfq.fqid++;\r\n} while (1);\r\n}\r\nint qman_release_pool(u32 qp)\r\n{\r\nint ret;\r\nret = qpool_cleanup(qp);\r\nif (ret) {\r\npr_debug("CHID %d leaked\n", qp);\r\nreturn ret;\r\n}\r\ngen_pool_free(qm_qpalloc, qp | DPAA_GENALLOC_OFF, 1);\r\nreturn 0;\r\n}\r\nstatic int cgr_cleanup(u32 cgrid)\r\n{\r\nstruct qman_fq fq = {\r\n.fqid = QM_FQID_RANGE_START\r\n};\r\nint err;\r\ndo {\r\nstruct qm_mcr_queryfq_np np;\r\nerr = qman_query_fq_np(&fq, &np);\r\nif (err == -ERANGE)\r\nreturn 0;\r\nelse if (WARN_ON(err))\r\nreturn err;\r\nif ((np.state & QM_MCR_NP_STATE_MASK) != QM_MCR_NP_STATE_OOS) {\r\nstruct qm_fqd fqd;\r\nerr = qman_query_fq(&fq, &fqd);\r\nif (WARN_ON(err))\r\nreturn err;\r\nif (be16_to_cpu(fqd.fq_ctrl) & QM_FQCTRL_CGE &&\r\nfqd.cgid == cgrid) {\r\npr_err("CRGID 0x%x is being used by FQID 0x%x, CGR will be leaked\n",\r\ncgrid, fq.fqid);\r\nreturn -EIO;\r\n}\r\n}\r\nfq.fqid++;\r\n} while (1);\r\n}\r\nint qman_release_cgrid(u32 cgrid)\r\n{\r\nint ret;\r\nret = cgr_cleanup(cgrid);\r\nif (ret) {\r\npr_debug("CGRID %d leaked\n", cgrid);\r\nreturn ret;\r\n}\r\ngen_pool_free(qm_cgralloc, cgrid | DPAA_GENALLOC_OFF, 1);\r\nreturn 0;\r\n}
