static void sync_ast(void *arg)\r\n{\r\nstruct dlm_lock_resource *res;\r\nres = arg;\r\nres->sync_locking_done = true;\r\nwake_up(&res->sync_locking);\r\n}\r\nstatic int dlm_lock_sync(struct dlm_lock_resource *res, int mode)\r\n{\r\nint ret = 0;\r\nret = dlm_lock(res->ls, mode, &res->lksb,\r\nres->flags, res->name, strlen(res->name),\r\n0, sync_ast, res, res->bast);\r\nif (ret)\r\nreturn ret;\r\nwait_event(res->sync_locking, res->sync_locking_done);\r\nres->sync_locking_done = false;\r\nif (res->lksb.sb_status == 0)\r\nres->mode = mode;\r\nreturn res->lksb.sb_status;\r\n}\r\nstatic int dlm_unlock_sync(struct dlm_lock_resource *res)\r\n{\r\nreturn dlm_lock_sync(res, DLM_LOCK_NL);\r\n}\r\nstatic int dlm_lock_sync_interruptible(struct dlm_lock_resource *res, int mode,\r\nstruct mddev *mddev)\r\n{\r\nint ret = 0;\r\nret = dlm_lock(res->ls, mode, &res->lksb,\r\nres->flags, res->name, strlen(res->name),\r\n0, sync_ast, res, res->bast);\r\nif (ret)\r\nreturn ret;\r\nwait_event(res->sync_locking, res->sync_locking_done\r\n|| kthread_should_stop()\r\n|| test_bit(MD_CLOSING, &mddev->flags));\r\nif (!res->sync_locking_done) {\r\nret = dlm_unlock(res->ls, res->lksb.sb_lkid, DLM_LKF_CANCEL,\r\n&res->lksb, res);\r\nres->sync_locking_done = false;\r\nif (unlikely(ret != 0))\r\npr_info("failed to cancel previous lock request "\r\n"%s return %d\n", res->name, ret);\r\nreturn -EPERM;\r\n} else\r\nres->sync_locking_done = false;\r\nif (res->lksb.sb_status == 0)\r\nres->mode = mode;\r\nreturn res->lksb.sb_status;\r\n}\r\nstatic struct dlm_lock_resource *lockres_init(struct mddev *mddev,\r\nchar *name, void (*bastfn)(void *arg, int mode), int with_lvb)\r\n{\r\nstruct dlm_lock_resource *res = NULL;\r\nint ret, namelen;\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nres = kzalloc(sizeof(struct dlm_lock_resource), GFP_KERNEL);\r\nif (!res)\r\nreturn NULL;\r\ninit_waitqueue_head(&res->sync_locking);\r\nres->sync_locking_done = false;\r\nres->ls = cinfo->lockspace;\r\nres->mddev = mddev;\r\nres->mode = DLM_LOCK_IV;\r\nnamelen = strlen(name);\r\nres->name = kzalloc(namelen + 1, GFP_KERNEL);\r\nif (!res->name) {\r\npr_err("md-cluster: Unable to allocate resource name for resource %s\n", name);\r\ngoto out_err;\r\n}\r\nstrlcpy(res->name, name, namelen + 1);\r\nif (with_lvb) {\r\nres->lksb.sb_lvbptr = kzalloc(LVB_SIZE, GFP_KERNEL);\r\nif (!res->lksb.sb_lvbptr) {\r\npr_err("md-cluster: Unable to allocate LVB for resource %s\n", name);\r\ngoto out_err;\r\n}\r\nres->flags = DLM_LKF_VALBLK;\r\n}\r\nif (bastfn)\r\nres->bast = bastfn;\r\nres->flags |= DLM_LKF_EXPEDITE;\r\nret = dlm_lock_sync(res, DLM_LOCK_NL);\r\nif (ret) {\r\npr_err("md-cluster: Unable to lock NL on new lock resource %s\n", name);\r\ngoto out_err;\r\n}\r\nres->flags &= ~DLM_LKF_EXPEDITE;\r\nres->flags |= DLM_LKF_CONVERT;\r\nreturn res;\r\nout_err:\r\nkfree(res->lksb.sb_lvbptr);\r\nkfree(res->name);\r\nkfree(res);\r\nreturn NULL;\r\n}\r\nstatic void lockres_free(struct dlm_lock_resource *res)\r\n{\r\nint ret = 0;\r\nif (!res)\r\nreturn;\r\nret = dlm_unlock(res->ls, res->lksb.sb_lkid, DLM_LKF_FORCEUNLOCK,\r\n&res->lksb, res);\r\nif (unlikely(ret != 0))\r\npr_err("failed to unlock %s return %d\n", res->name, ret);\r\nelse\r\nwait_event(res->sync_locking, res->sync_locking_done);\r\nkfree(res->name);\r\nkfree(res->lksb.sb_lvbptr);\r\nkfree(res);\r\n}\r\nstatic void add_resync_info(struct dlm_lock_resource *lockres,\r\nsector_t lo, sector_t hi)\r\n{\r\nstruct resync_info *ri;\r\nri = (struct resync_info *)lockres->lksb.sb_lvbptr;\r\nri->lo = cpu_to_le64(lo);\r\nri->hi = cpu_to_le64(hi);\r\n}\r\nstatic struct suspend_info *read_resync_info(struct mddev *mddev, struct dlm_lock_resource *lockres)\r\n{\r\nstruct resync_info ri;\r\nstruct suspend_info *s = NULL;\r\nsector_t hi = 0;\r\ndlm_lock_sync(lockres, DLM_LOCK_CR);\r\nmemcpy(&ri, lockres->lksb.sb_lvbptr, sizeof(struct resync_info));\r\nhi = le64_to_cpu(ri.hi);\r\nif (hi > 0) {\r\ns = kzalloc(sizeof(struct suspend_info), GFP_KERNEL);\r\nif (!s)\r\ngoto out;\r\ns->hi = hi;\r\ns->lo = le64_to_cpu(ri.lo);\r\n}\r\ndlm_unlock_sync(lockres);\r\nout:\r\nreturn s;\r\n}\r\nstatic void recover_bitmaps(struct md_thread *thread)\r\n{\r\nstruct mddev *mddev = thread->mddev;\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nstruct dlm_lock_resource *bm_lockres;\r\nchar str[64];\r\nint slot, ret;\r\nstruct suspend_info *s, *tmp;\r\nsector_t lo, hi;\r\nwhile (cinfo->recovery_map) {\r\nslot = fls64((u64)cinfo->recovery_map) - 1;\r\nspin_lock_irq(&cinfo->suspend_lock);\r\nlist_for_each_entry_safe(s, tmp, &cinfo->suspend_list, list)\r\nif (slot == s->slot) {\r\nlist_del(&s->list);\r\nkfree(s);\r\n}\r\nspin_unlock_irq(&cinfo->suspend_lock);\r\nsnprintf(str, 64, "bitmap%04d", slot);\r\nbm_lockres = lockres_init(mddev, str, NULL, 1);\r\nif (!bm_lockres) {\r\npr_err("md-cluster: Cannot initialize bitmaps\n");\r\ngoto clear_bit;\r\n}\r\nret = dlm_lock_sync_interruptible(bm_lockres, DLM_LOCK_PW, mddev);\r\nif (ret) {\r\npr_err("md-cluster: Could not DLM lock %s: %d\n",\r\nstr, ret);\r\ngoto clear_bit;\r\n}\r\nret = bitmap_copy_from_slot(mddev, slot, &lo, &hi, true);\r\nif (ret) {\r\npr_err("md-cluster: Could not copy data from bitmap %d\n", slot);\r\ngoto clear_bit;\r\n}\r\nif (hi > 0) {\r\nif (lo < mddev->recovery_cp)\r\nmddev->recovery_cp = lo;\r\nif (mddev->recovery_cp != MaxSector) {\r\nset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\r\nmd_wakeup_thread(mddev->thread);\r\n}\r\n}\r\nclear_bit:\r\nlockres_free(bm_lockres);\r\nclear_bit(slot, &cinfo->recovery_map);\r\n}\r\n}\r\nstatic void recover_prep(void *arg)\r\n{\r\nstruct mddev *mddev = arg;\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nset_bit(MD_CLUSTER_SUSPEND_READ_BALANCING, &cinfo->state);\r\n}\r\nstatic void __recover_slot(struct mddev *mddev, int slot)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nset_bit(slot, &cinfo->recovery_map);\r\nif (!cinfo->recovery_thread) {\r\ncinfo->recovery_thread = md_register_thread(recover_bitmaps,\r\nmddev, "recover");\r\nif (!cinfo->recovery_thread) {\r\npr_warn("md-cluster: Could not create recovery thread\n");\r\nreturn;\r\n}\r\n}\r\nmd_wakeup_thread(cinfo->recovery_thread);\r\n}\r\nstatic void recover_slot(void *arg, struct dlm_slot *slot)\r\n{\r\nstruct mddev *mddev = arg;\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\npr_info("md-cluster: %s Node %d/%d down. My slot: %d. Initiating recovery.\n",\r\nmddev->bitmap_info.cluster_name,\r\nslot->nodeid, slot->slot,\r\ncinfo->slot_number);\r\n__recover_slot(mddev, slot->slot - 1);\r\n}\r\nstatic void recover_done(void *arg, struct dlm_slot *slots,\r\nint num_slots, int our_slot,\r\nuint32_t generation)\r\n{\r\nstruct mddev *mddev = arg;\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\ncinfo->slot_number = our_slot;\r\nif (test_bit(MD_CLUSTER_BEGIN_JOIN_CLUSTER, &cinfo->state)) {\r\ncomplete(&cinfo->completion);\r\nclear_bit(MD_CLUSTER_BEGIN_JOIN_CLUSTER, &cinfo->state);\r\n}\r\nclear_bit(MD_CLUSTER_SUSPEND_READ_BALANCING, &cinfo->state);\r\n}\r\nstatic void ack_bast(void *arg, int mode)\r\n{\r\nstruct dlm_lock_resource *res = arg;\r\nstruct md_cluster_info *cinfo = res->mddev->cluster_info;\r\nif (mode == DLM_LOCK_EX) {\r\nif (test_bit(MD_CLUSTER_ALREADY_IN_CLUSTER, &cinfo->state))\r\nmd_wakeup_thread(cinfo->recv_thread);\r\nelse\r\nset_bit(MD_CLUSTER_PENDING_RECV_EVENT, &cinfo->state);\r\n}\r\n}\r\nstatic void __remove_suspend_info(struct md_cluster_info *cinfo, int slot)\r\n{\r\nstruct suspend_info *s, *tmp;\r\nlist_for_each_entry_safe(s, tmp, &cinfo->suspend_list, list)\r\nif (slot == s->slot) {\r\nlist_del(&s->list);\r\nkfree(s);\r\nbreak;\r\n}\r\n}\r\nstatic void remove_suspend_info(struct mddev *mddev, int slot)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nspin_lock_irq(&cinfo->suspend_lock);\r\n__remove_suspend_info(cinfo, slot);\r\nspin_unlock_irq(&cinfo->suspend_lock);\r\nmddev->pers->quiesce(mddev, 2);\r\n}\r\nstatic void process_suspend_info(struct mddev *mddev,\r\nint slot, sector_t lo, sector_t hi)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nstruct suspend_info *s;\r\nif (!hi) {\r\nremove_suspend_info(mddev, slot);\r\nset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\r\nmd_wakeup_thread(mddev->thread);\r\nreturn;\r\n}\r\nbitmap_sync_with_cluster(mddev, cinfo->sync_low,\r\ncinfo->sync_hi,\r\nlo, hi);\r\ncinfo->sync_low = lo;\r\ncinfo->sync_hi = hi;\r\ns = kzalloc(sizeof(struct suspend_info), GFP_KERNEL);\r\nif (!s)\r\nreturn;\r\ns->slot = slot;\r\ns->lo = lo;\r\ns->hi = hi;\r\nmddev->pers->quiesce(mddev, 1);\r\nmddev->pers->quiesce(mddev, 0);\r\nspin_lock_irq(&cinfo->suspend_lock);\r\n__remove_suspend_info(cinfo, slot);\r\nlist_add(&s->list, &cinfo->suspend_list);\r\nspin_unlock_irq(&cinfo->suspend_lock);\r\nmddev->pers->quiesce(mddev, 2);\r\n}\r\nstatic void process_add_new_disk(struct mddev *mddev, struct cluster_msg *cmsg)\r\n{\r\nchar disk_uuid[64];\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nchar event_name[] = "EVENT=ADD_DEVICE";\r\nchar raid_slot[16];\r\nchar *envp[] = {event_name, disk_uuid, raid_slot, NULL};\r\nint len;\r\nlen = snprintf(disk_uuid, 64, "DEVICE_UUID=");\r\nsprintf(disk_uuid + len, "%pU", cmsg->uuid);\r\nsnprintf(raid_slot, 16, "RAID_DISK=%d", le32_to_cpu(cmsg->raid_slot));\r\npr_info("%s:%d Sending kobject change with %s and %s\n", __func__, __LINE__, disk_uuid, raid_slot);\r\ninit_completion(&cinfo->newdisk_completion);\r\nset_bit(MD_CLUSTER_WAITING_FOR_NEWDISK, &cinfo->state);\r\nkobject_uevent_env(&disk_to_dev(mddev->gendisk)->kobj, KOBJ_CHANGE, envp);\r\nwait_for_completion_timeout(&cinfo->newdisk_completion,\r\nNEW_DEV_TIMEOUT);\r\nclear_bit(MD_CLUSTER_WAITING_FOR_NEWDISK, &cinfo->state);\r\n}\r\nstatic void process_metadata_update(struct mddev *mddev, struct cluster_msg *msg)\r\n{\r\nint got_lock = 0;\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nmddev->good_device_nr = le32_to_cpu(msg->raid_slot);\r\ndlm_lock_sync(cinfo->no_new_dev_lockres, DLM_LOCK_CR);\r\nwait_event(mddev->thread->wqueue,\r\n(got_lock = mddev_trylock(mddev)) ||\r\ntest_bit(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD, &cinfo->state));\r\nmd_reload_sb(mddev, mddev->good_device_nr);\r\nif (got_lock)\r\nmddev_unlock(mddev);\r\n}\r\nstatic void process_remove_disk(struct mddev *mddev, struct cluster_msg *msg)\r\n{\r\nstruct md_rdev *rdev;\r\nrcu_read_lock();\r\nrdev = md_find_rdev_nr_rcu(mddev, le32_to_cpu(msg->raid_slot));\r\nif (rdev) {\r\nset_bit(ClusterRemove, &rdev->flags);\r\nset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\r\nmd_wakeup_thread(mddev->thread);\r\n}\r\nelse\r\npr_warn("%s: %d Could not find disk(%d) to REMOVE\n",\r\n__func__, __LINE__, le32_to_cpu(msg->raid_slot));\r\nrcu_read_unlock();\r\n}\r\nstatic void process_readd_disk(struct mddev *mddev, struct cluster_msg *msg)\r\n{\r\nstruct md_rdev *rdev;\r\nrcu_read_lock();\r\nrdev = md_find_rdev_nr_rcu(mddev, le32_to_cpu(msg->raid_slot));\r\nif (rdev && test_bit(Faulty, &rdev->flags))\r\nclear_bit(Faulty, &rdev->flags);\r\nelse\r\npr_warn("%s: %d Could not find disk(%d) which is faulty",\r\n__func__, __LINE__, le32_to_cpu(msg->raid_slot));\r\nrcu_read_unlock();\r\n}\r\nstatic int process_recvd_msg(struct mddev *mddev, struct cluster_msg *msg)\r\n{\r\nint ret = 0;\r\nif (WARN(mddev->cluster_info->slot_number - 1 == le32_to_cpu(msg->slot),\r\n"node %d received it's own msg\n", le32_to_cpu(msg->slot)))\r\nreturn -1;\r\nswitch (le32_to_cpu(msg->type)) {\r\ncase METADATA_UPDATED:\r\nprocess_metadata_update(mddev, msg);\r\nbreak;\r\ncase CHANGE_CAPACITY:\r\nset_capacity(mddev->gendisk, mddev->array_sectors);\r\nrevalidate_disk(mddev->gendisk);\r\nbreak;\r\ncase RESYNCING:\r\nprocess_suspend_info(mddev, le32_to_cpu(msg->slot),\r\nle64_to_cpu(msg->low),\r\nle64_to_cpu(msg->high));\r\nbreak;\r\ncase NEWDISK:\r\nprocess_add_new_disk(mddev, msg);\r\nbreak;\r\ncase REMOVE:\r\nprocess_remove_disk(mddev, msg);\r\nbreak;\r\ncase RE_ADD:\r\nprocess_readd_disk(mddev, msg);\r\nbreak;\r\ncase BITMAP_NEEDS_SYNC:\r\n__recover_slot(mddev, le32_to_cpu(msg->slot));\r\nbreak;\r\ndefault:\r\nret = -1;\r\npr_warn("%s:%d Received unknown message from %d\n",\r\n__func__, __LINE__, msg->slot);\r\n}\r\nreturn ret;\r\n}\r\nstatic void recv_daemon(struct md_thread *thread)\r\n{\r\nstruct md_cluster_info *cinfo = thread->mddev->cluster_info;\r\nstruct dlm_lock_resource *ack_lockres = cinfo->ack_lockres;\r\nstruct dlm_lock_resource *message_lockres = cinfo->message_lockres;\r\nstruct cluster_msg msg;\r\nint ret;\r\nmutex_lock(&cinfo->recv_mutex);\r\nif (dlm_lock_sync(message_lockres, DLM_LOCK_CR)) {\r\npr_err("md/raid1:failed to get CR on MESSAGE\n");\r\nmutex_unlock(&cinfo->recv_mutex);\r\nreturn;\r\n}\r\nmemcpy(&msg, message_lockres->lksb.sb_lvbptr, sizeof(struct cluster_msg));\r\nret = process_recvd_msg(thread->mddev, &msg);\r\nif (ret)\r\ngoto out;\r\nret = dlm_unlock_sync(ack_lockres);\r\nif (unlikely(ret != 0))\r\npr_info("unlock ack failed return %d\n", ret);\r\nret = dlm_lock_sync(message_lockres, DLM_LOCK_PR);\r\nif (unlikely(ret != 0))\r\npr_info("lock PR on msg failed return %d\n", ret);\r\nret = dlm_lock_sync(ack_lockres, DLM_LOCK_CR);\r\nif (unlikely(ret != 0))\r\npr_info("lock CR on ack failed return %d\n", ret);\r\nout:\r\nret = dlm_unlock_sync(message_lockres);\r\nif (unlikely(ret != 0))\r\npr_info("unlock msg failed return %d\n", ret);\r\nmutex_unlock(&cinfo->recv_mutex);\r\n}\r\nstatic int lock_token(struct md_cluster_info *cinfo, bool mddev_locked)\r\n{\r\nint error, set_bit = 0;\r\nstruct mddev *mddev = cinfo->mddev;\r\nif (mddev_locked && !test_bit(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD,\r\n&cinfo->state)) {\r\nerror = test_and_set_bit_lock(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD,\r\n&cinfo->state);\r\nWARN_ON_ONCE(error);\r\nmd_wakeup_thread(mddev->thread);\r\nset_bit = 1;\r\n}\r\nerror = dlm_lock_sync(cinfo->token_lockres, DLM_LOCK_EX);\r\nif (set_bit)\r\nclear_bit_unlock(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD, &cinfo->state);\r\nif (error)\r\npr_err("md-cluster(%s:%d): failed to get EX on TOKEN (%d)\n",\r\n__func__, __LINE__, error);\r\nmutex_lock(&cinfo->recv_mutex);\r\nreturn error;\r\n}\r\nstatic int lock_comm(struct md_cluster_info *cinfo, bool mddev_locked)\r\n{\r\nwait_event(cinfo->wait,\r\n!test_and_set_bit(MD_CLUSTER_SEND_LOCK, &cinfo->state));\r\nreturn lock_token(cinfo, mddev_locked);\r\n}\r\nstatic void unlock_comm(struct md_cluster_info *cinfo)\r\n{\r\nWARN_ON(cinfo->token_lockres->mode != DLM_LOCK_EX);\r\nmutex_unlock(&cinfo->recv_mutex);\r\ndlm_unlock_sync(cinfo->token_lockres);\r\nclear_bit(MD_CLUSTER_SEND_LOCK, &cinfo->state);\r\nwake_up(&cinfo->wait);\r\n}\r\nstatic int __sendmsg(struct md_cluster_info *cinfo, struct cluster_msg *cmsg)\r\n{\r\nint error;\r\nint slot = cinfo->slot_number - 1;\r\ncmsg->slot = cpu_to_le32(slot);\r\nerror = dlm_lock_sync(cinfo->message_lockres, DLM_LOCK_EX);\r\nif (error) {\r\npr_err("md-cluster: failed to get EX on MESSAGE (%d)\n", error);\r\ngoto failed_message;\r\n}\r\nmemcpy(cinfo->message_lockres->lksb.sb_lvbptr, (void *)cmsg,\r\nsizeof(struct cluster_msg));\r\nerror = dlm_lock_sync(cinfo->message_lockres, DLM_LOCK_CW);\r\nif (error) {\r\npr_err("md-cluster: failed to convert EX to CW on MESSAGE(%d)\n",\r\nerror);\r\ngoto failed_ack;\r\n}\r\nerror = dlm_lock_sync(cinfo->ack_lockres, DLM_LOCK_EX);\r\nif (error) {\r\npr_err("md-cluster: failed to convert CR to EX on ACK(%d)\n",\r\nerror);\r\ngoto failed_ack;\r\n}\r\nerror = dlm_lock_sync(cinfo->ack_lockres, DLM_LOCK_CR);\r\nif (error) {\r\npr_err("md-cluster: failed to convert EX to CR on ACK(%d)\n",\r\nerror);\r\ngoto failed_ack;\r\n}\r\nfailed_ack:\r\nerror = dlm_unlock_sync(cinfo->message_lockres);\r\nif (unlikely(error != 0)) {\r\npr_err("md-cluster: failed convert to NL on MESSAGE(%d)\n",\r\nerror);\r\ngoto failed_ack;\r\n}\r\nfailed_message:\r\nreturn error;\r\n}\r\nstatic int sendmsg(struct md_cluster_info *cinfo, struct cluster_msg *cmsg,\r\nbool mddev_locked)\r\n{\r\nint ret;\r\nlock_comm(cinfo, mddev_locked);\r\nret = __sendmsg(cinfo, cmsg);\r\nunlock_comm(cinfo);\r\nreturn ret;\r\n}\r\nstatic int gather_all_resync_info(struct mddev *mddev, int total_slots)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nint i, ret = 0;\r\nstruct dlm_lock_resource *bm_lockres;\r\nstruct suspend_info *s;\r\nchar str[64];\r\nsector_t lo, hi;\r\nfor (i = 0; i < total_slots; i++) {\r\nmemset(str, '\0', 64);\r\nsnprintf(str, 64, "bitmap%04d", i);\r\nbm_lockres = lockres_init(mddev, str, NULL, 1);\r\nif (!bm_lockres)\r\nreturn -ENOMEM;\r\nif (i == (cinfo->slot_number - 1)) {\r\nlockres_free(bm_lockres);\r\ncontinue;\r\n}\r\nbm_lockres->flags |= DLM_LKF_NOQUEUE;\r\nret = dlm_lock_sync(bm_lockres, DLM_LOCK_PW);\r\nif (ret == -EAGAIN) {\r\ns = read_resync_info(mddev, bm_lockres);\r\nif (s) {\r\npr_info("%s:%d Resync[%llu..%llu] in progress on %d\n",\r\n__func__, __LINE__,\r\n(unsigned long long) s->lo,\r\n(unsigned long long) s->hi, i);\r\nspin_lock_irq(&cinfo->suspend_lock);\r\ns->slot = i;\r\nlist_add(&s->list, &cinfo->suspend_list);\r\nspin_unlock_irq(&cinfo->suspend_lock);\r\n}\r\nret = 0;\r\nlockres_free(bm_lockres);\r\ncontinue;\r\n}\r\nif (ret) {\r\nlockres_free(bm_lockres);\r\ngoto out;\r\n}\r\nret = bitmap_copy_from_slot(mddev, i, &lo, &hi, false);\r\nif (ret) {\r\npr_warn("md-cluster: Could not gather bitmaps from slot %d", i);\r\nlockres_free(bm_lockres);\r\ncontinue;\r\n}\r\nif ((hi > 0) && (lo < mddev->recovery_cp)) {\r\nset_bit(MD_RECOVERY_NEEDED, &mddev->recovery);\r\nmddev->recovery_cp = lo;\r\nmd_check_recovery(mddev);\r\n}\r\nlockres_free(bm_lockres);\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic int join(struct mddev *mddev, int nodes)\r\n{\r\nstruct md_cluster_info *cinfo;\r\nint ret, ops_rv;\r\nchar str[64];\r\ncinfo = kzalloc(sizeof(struct md_cluster_info), GFP_KERNEL);\r\nif (!cinfo)\r\nreturn -ENOMEM;\r\nINIT_LIST_HEAD(&cinfo->suspend_list);\r\nspin_lock_init(&cinfo->suspend_lock);\r\ninit_completion(&cinfo->completion);\r\nset_bit(MD_CLUSTER_BEGIN_JOIN_CLUSTER, &cinfo->state);\r\ninit_waitqueue_head(&cinfo->wait);\r\nmutex_init(&cinfo->recv_mutex);\r\nmddev->cluster_info = cinfo;\r\ncinfo->mddev = mddev;\r\nmemset(str, 0, 64);\r\nsprintf(str, "%pU", mddev->uuid);\r\nret = dlm_new_lockspace(str, mddev->bitmap_info.cluster_name,\r\nDLM_LSFL_FS, LVB_SIZE,\r\n&md_ls_ops, mddev, &ops_rv, &cinfo->lockspace);\r\nif (ret)\r\ngoto err;\r\nwait_for_completion(&cinfo->completion);\r\nif (nodes < cinfo->slot_number) {\r\npr_err("md-cluster: Slot allotted(%d) is greater than available slots(%d).",\r\ncinfo->slot_number, nodes);\r\nret = -ERANGE;\r\ngoto err;\r\n}\r\nret = -ENOMEM;\r\ncinfo->recv_thread = md_register_thread(recv_daemon, mddev, "cluster_recv");\r\nif (!cinfo->recv_thread) {\r\npr_err("md-cluster: cannot allocate memory for recv_thread!\n");\r\ngoto err;\r\n}\r\ncinfo->message_lockres = lockres_init(mddev, "message", NULL, 1);\r\nif (!cinfo->message_lockres)\r\ngoto err;\r\ncinfo->token_lockres = lockres_init(mddev, "token", NULL, 0);\r\nif (!cinfo->token_lockres)\r\ngoto err;\r\ncinfo->no_new_dev_lockres = lockres_init(mddev, "no-new-dev", NULL, 0);\r\nif (!cinfo->no_new_dev_lockres)\r\ngoto err;\r\nret = dlm_lock_sync(cinfo->token_lockres, DLM_LOCK_EX);\r\nif (ret) {\r\nret = -EAGAIN;\r\npr_err("md-cluster: can't join cluster to avoid lock issue\n");\r\ngoto err;\r\n}\r\ncinfo->ack_lockres = lockres_init(mddev, "ack", ack_bast, 0);\r\nif (!cinfo->ack_lockres) {\r\nret = -ENOMEM;\r\ngoto err;\r\n}\r\nif (dlm_lock_sync(cinfo->ack_lockres, DLM_LOCK_CR))\r\npr_err("md-cluster: failed to get a sync CR lock on ACK!(%d)\n",\r\nret);\r\ndlm_unlock_sync(cinfo->token_lockres);\r\nif (dlm_lock_sync(cinfo->no_new_dev_lockres, DLM_LOCK_CR))\r\npr_err("md-cluster: failed to get a sync CR lock on no-new-dev!(%d)\n", ret);\r\npr_info("md-cluster: Joined cluster %s slot %d\n", str, cinfo->slot_number);\r\nsnprintf(str, 64, "bitmap%04d", cinfo->slot_number - 1);\r\ncinfo->bitmap_lockres = lockres_init(mddev, str, NULL, 1);\r\nif (!cinfo->bitmap_lockres) {\r\nret = -ENOMEM;\r\ngoto err;\r\n}\r\nif (dlm_lock_sync(cinfo->bitmap_lockres, DLM_LOCK_PW)) {\r\npr_err("Failed to get bitmap lock\n");\r\nret = -EINVAL;\r\ngoto err;\r\n}\r\ncinfo->resync_lockres = lockres_init(mddev, "resync", NULL, 0);\r\nif (!cinfo->resync_lockres) {\r\nret = -ENOMEM;\r\ngoto err;\r\n}\r\nreturn 0;\r\nerr:\r\nset_bit(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD, &cinfo->state);\r\nmd_unregister_thread(&cinfo->recovery_thread);\r\nmd_unregister_thread(&cinfo->recv_thread);\r\nlockres_free(cinfo->message_lockres);\r\nlockres_free(cinfo->token_lockres);\r\nlockres_free(cinfo->ack_lockres);\r\nlockres_free(cinfo->no_new_dev_lockres);\r\nlockres_free(cinfo->resync_lockres);\r\nlockres_free(cinfo->bitmap_lockres);\r\nif (cinfo->lockspace)\r\ndlm_release_lockspace(cinfo->lockspace, 2);\r\nmddev->cluster_info = NULL;\r\nkfree(cinfo);\r\nreturn ret;\r\n}\r\nstatic void load_bitmaps(struct mddev *mddev, int total_slots)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nif (gather_all_resync_info(mddev, total_slots))\r\npr_err("md-cluster: failed to gather all resyn infos\n");\r\nset_bit(MD_CLUSTER_ALREADY_IN_CLUSTER, &cinfo->state);\r\nif (test_and_clear_bit(MD_CLUSTER_PENDING_RECV_EVENT, &cinfo->state))\r\nmd_wakeup_thread(cinfo->recv_thread);\r\n}\r\nstatic void resync_bitmap(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nstruct cluster_msg cmsg = {0};\r\nint err;\r\ncmsg.type = cpu_to_le32(BITMAP_NEEDS_SYNC);\r\nerr = sendmsg(cinfo, &cmsg, 1);\r\nif (err)\r\npr_err("%s:%d: failed to send BITMAP_NEEDS_SYNC message (%d)\n",\r\n__func__, __LINE__, err);\r\n}\r\nstatic int leave(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nif (!cinfo)\r\nreturn 0;\r\nif (cinfo->slot_number > 0 && mddev->recovery_cp != MaxSector)\r\nresync_bitmap(mddev);\r\nset_bit(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD, &cinfo->state);\r\nmd_unregister_thread(&cinfo->recovery_thread);\r\nmd_unregister_thread(&cinfo->recv_thread);\r\nlockres_free(cinfo->message_lockres);\r\nlockres_free(cinfo->token_lockres);\r\nlockres_free(cinfo->ack_lockres);\r\nlockres_free(cinfo->no_new_dev_lockres);\r\nlockres_free(cinfo->resync_lockres);\r\nlockres_free(cinfo->bitmap_lockres);\r\nunlock_all_bitmaps(mddev);\r\ndlm_release_lockspace(cinfo->lockspace, 2);\r\nkfree(cinfo);\r\nreturn 0;\r\n}\r\nstatic int slot_number(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nreturn cinfo->slot_number - 1;\r\n}\r\nstatic int metadata_update_start(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nint ret;\r\nret = test_and_set_bit_lock(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD,\r\n&cinfo->state);\r\nWARN_ON_ONCE(ret);\r\nmd_wakeup_thread(mddev->thread);\r\nwait_event(cinfo->wait,\r\n!test_and_set_bit(MD_CLUSTER_SEND_LOCK, &cinfo->state) ||\r\ntest_and_clear_bit(MD_CLUSTER_SEND_LOCKED_ALREADY, &cinfo->state));\r\nif (cinfo->token_lockres->mode == DLM_LOCK_EX) {\r\nclear_bit_unlock(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD, &cinfo->state);\r\nreturn 0;\r\n}\r\nret = lock_token(cinfo, 1);\r\nclear_bit_unlock(MD_CLUSTER_HOLDING_MUTEX_FOR_RECVD, &cinfo->state);\r\nreturn ret;\r\n}\r\nstatic int metadata_update_finish(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nstruct cluster_msg cmsg;\r\nstruct md_rdev *rdev;\r\nint ret = 0;\r\nint raid_slot = -1;\r\nmemset(&cmsg, 0, sizeof(cmsg));\r\ncmsg.type = cpu_to_le32(METADATA_UPDATED);\r\nrdev_for_each(rdev, mddev)\r\nif (rdev->raid_disk > -1 && !test_bit(Faulty, &rdev->flags)) {\r\nraid_slot = rdev->desc_nr;\r\nbreak;\r\n}\r\nif (raid_slot >= 0) {\r\ncmsg.raid_slot = cpu_to_le32(raid_slot);\r\nret = __sendmsg(cinfo, &cmsg);\r\n} else\r\npr_warn("md-cluster: No good device id found to send\n");\r\nclear_bit(MD_CLUSTER_SEND_LOCKED_ALREADY, &cinfo->state);\r\nunlock_comm(cinfo);\r\nreturn ret;\r\n}\r\nstatic void metadata_update_cancel(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nclear_bit(MD_CLUSTER_SEND_LOCKED_ALREADY, &cinfo->state);\r\nunlock_comm(cinfo);\r\n}\r\nint cluster_check_sync_size(struct mddev *mddev)\r\n{\r\nint i, rv;\r\nbitmap_super_t *sb;\r\nunsigned long my_sync_size, sync_size = 0;\r\nint node_num = mddev->bitmap_info.nodes;\r\nint current_slot = md_cluster_ops->slot_number(mddev);\r\nstruct bitmap *bitmap = mddev->bitmap;\r\nchar str[64];\r\nstruct dlm_lock_resource *bm_lockres;\r\nsb = kmap_atomic(bitmap->storage.sb_page);\r\nmy_sync_size = sb->sync_size;\r\nkunmap_atomic(sb);\r\nfor (i = 0; i < node_num; i++) {\r\nif (i == current_slot)\r\ncontinue;\r\nbitmap = get_bitmap_from_slot(mddev, i);\r\nif (IS_ERR(bitmap)) {\r\npr_err("can't get bitmap from slot %d\n", i);\r\nreturn -1;\r\n}\r\nsnprintf(str, 64, "bitmap%04d", i);\r\nbm_lockres = lockres_init(mddev, str, NULL, 1);\r\nif (!bm_lockres) {\r\npr_err("md-cluster: Cannot initialize %s\n", str);\r\nbitmap_free(bitmap);\r\nreturn -1;\r\n}\r\nbm_lockres->flags |= DLM_LKF_NOQUEUE;\r\nrv = dlm_lock_sync(bm_lockres, DLM_LOCK_PW);\r\nif (!rv)\r\nbitmap_update_sb(bitmap);\r\nlockres_free(bm_lockres);\r\nsb = kmap_atomic(bitmap->storage.sb_page);\r\nif (sync_size == 0)\r\nsync_size = sb->sync_size;\r\nelse if (sync_size != sb->sync_size) {\r\nkunmap_atomic(sb);\r\nbitmap_free(bitmap);\r\nreturn -1;\r\n}\r\nkunmap_atomic(sb);\r\nbitmap_free(bitmap);\r\n}\r\nreturn (my_sync_size == sync_size) ? 0 : -1;\r\n}\r\nstatic void update_size(struct mddev *mddev, sector_t old_dev_sectors)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nstruct cluster_msg cmsg;\r\nstruct md_rdev *rdev;\r\nint ret = 0;\r\nint raid_slot = -1;\r\nmd_update_sb(mddev, 1);\r\nlock_comm(cinfo, 1);\r\nmemset(&cmsg, 0, sizeof(cmsg));\r\ncmsg.type = cpu_to_le32(METADATA_UPDATED);\r\nrdev_for_each(rdev, mddev)\r\nif (rdev->raid_disk >= 0 && !test_bit(Faulty, &rdev->flags)) {\r\nraid_slot = rdev->desc_nr;\r\nbreak;\r\n}\r\nif (raid_slot >= 0) {\r\ncmsg.raid_slot = cpu_to_le32(raid_slot);\r\nret = __sendmsg(cinfo, &cmsg);\r\nif (ret) {\r\npr_err("%s:%d: failed to send METADATA_UPDATED msg\n",\r\n__func__, __LINE__);\r\nunlock_comm(cinfo);\r\nreturn;\r\n}\r\n} else {\r\npr_err("md-cluster: No good device id found to send\n");\r\nunlock_comm(cinfo);\r\nreturn;\r\n}\r\nif (cluster_check_sync_size(mddev) == 0) {\r\nmemset(&cmsg, 0, sizeof(cmsg));\r\ncmsg.type = cpu_to_le32(CHANGE_CAPACITY);\r\nret = __sendmsg(cinfo, &cmsg);\r\nif (ret)\r\npr_err("%s:%d: failed to send CHANGE_CAPACITY msg\n",\r\n__func__, __LINE__);\r\nset_capacity(mddev->gendisk, mddev->array_sectors);\r\nrevalidate_disk(mddev->gendisk);\r\n} else {\r\nret = mddev->pers->resize(mddev, old_dev_sectors);\r\nif (!ret)\r\nrevalidate_disk(mddev->gendisk);\r\nret = __sendmsg(cinfo, &cmsg);\r\nif (ret)\r\npr_err("%s:%d: failed to send METADATA_UPDATED msg\n",\r\n__func__, __LINE__);\r\n}\r\nunlock_comm(cinfo);\r\n}\r\nstatic int resync_start(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nreturn dlm_lock_sync_interruptible(cinfo->resync_lockres, DLM_LOCK_EX, mddev);\r\n}\r\nstatic int resync_info_update(struct mddev *mddev, sector_t lo, sector_t hi)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nstruct resync_info ri;\r\nstruct cluster_msg cmsg = {0};\r\nif (hi == 0) {\r\nmemcpy(&ri, cinfo->bitmap_lockres->lksb.sb_lvbptr, sizeof(struct resync_info));\r\nif (le64_to_cpu(ri.hi) == 0)\r\nreturn 0;\r\n}\r\nadd_resync_info(cinfo->bitmap_lockres, lo, hi);\r\ndlm_lock_sync(cinfo->bitmap_lockres, DLM_LOCK_PW);\r\ncmsg.type = cpu_to_le32(RESYNCING);\r\ncmsg.low = cpu_to_le64(lo);\r\ncmsg.high = cpu_to_le64(hi);\r\nif (lo == 0 && hi == 0)\r\nreturn sendmsg(cinfo, &cmsg, 1);\r\nelse\r\nreturn sendmsg(cinfo, &cmsg, 0);\r\n}\r\nstatic int resync_finish(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\ndlm_unlock_sync(cinfo->resync_lockres);\r\nreturn resync_info_update(mddev, 0, 0);\r\n}\r\nstatic int area_resyncing(struct mddev *mddev, int direction,\r\nsector_t lo, sector_t hi)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nint ret = 0;\r\nstruct suspend_info *s;\r\nif ((direction == READ) &&\r\ntest_bit(MD_CLUSTER_SUSPEND_READ_BALANCING, &cinfo->state))\r\nreturn 1;\r\nspin_lock_irq(&cinfo->suspend_lock);\r\nif (list_empty(&cinfo->suspend_list))\r\ngoto out;\r\nlist_for_each_entry(s, &cinfo->suspend_list, list)\r\nif (hi > s->lo && lo < s->hi) {\r\nret = 1;\r\nbreak;\r\n}\r\nout:\r\nspin_unlock_irq(&cinfo->suspend_lock);\r\nreturn ret;\r\n}\r\nstatic int add_new_disk(struct mddev *mddev, struct md_rdev *rdev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nstruct cluster_msg cmsg;\r\nint ret = 0;\r\nstruct mdp_superblock_1 *sb = page_address(rdev->sb_page);\r\nchar *uuid = sb->device_uuid;\r\nmemset(&cmsg, 0, sizeof(cmsg));\r\ncmsg.type = cpu_to_le32(NEWDISK);\r\nmemcpy(cmsg.uuid, uuid, 16);\r\ncmsg.raid_slot = cpu_to_le32(rdev->desc_nr);\r\nlock_comm(cinfo, 1);\r\nret = __sendmsg(cinfo, &cmsg);\r\nif (ret) {\r\nunlock_comm(cinfo);\r\nreturn ret;\r\n}\r\ncinfo->no_new_dev_lockres->flags |= DLM_LKF_NOQUEUE;\r\nret = dlm_lock_sync(cinfo->no_new_dev_lockres, DLM_LOCK_EX);\r\ncinfo->no_new_dev_lockres->flags &= ~DLM_LKF_NOQUEUE;\r\nif (ret == -EAGAIN)\r\nret = -ENOENT;\r\nif (ret)\r\nunlock_comm(cinfo);\r\nelse {\r\ndlm_lock_sync(cinfo->no_new_dev_lockres, DLM_LOCK_CR);\r\nset_bit(MD_CLUSTER_SEND_LOCKED_ALREADY, &cinfo->state);\r\nwake_up(&cinfo->wait);\r\n}\r\nreturn ret;\r\n}\r\nstatic void add_new_disk_cancel(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nclear_bit(MD_CLUSTER_SEND_LOCKED_ALREADY, &cinfo->state);\r\nunlock_comm(cinfo);\r\n}\r\nstatic int new_disk_ack(struct mddev *mddev, bool ack)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nif (!test_bit(MD_CLUSTER_WAITING_FOR_NEWDISK, &cinfo->state)) {\r\npr_warn("md-cluster(%s): Spurious cluster confirmation\n", mdname(mddev));\r\nreturn -EINVAL;\r\n}\r\nif (ack)\r\ndlm_unlock_sync(cinfo->no_new_dev_lockres);\r\ncomplete(&cinfo->newdisk_completion);\r\nreturn 0;\r\n}\r\nstatic int remove_disk(struct mddev *mddev, struct md_rdev *rdev)\r\n{\r\nstruct cluster_msg cmsg = {0};\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\ncmsg.type = cpu_to_le32(REMOVE);\r\ncmsg.raid_slot = cpu_to_le32(rdev->desc_nr);\r\nreturn sendmsg(cinfo, &cmsg, 1);\r\n}\r\nstatic int lock_all_bitmaps(struct mddev *mddev)\r\n{\r\nint slot, my_slot, ret, held = 1, i = 0;\r\nchar str[64];\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\ncinfo->other_bitmap_lockres = kzalloc((mddev->bitmap_info.nodes - 1) *\r\nsizeof(struct dlm_lock_resource *),\r\nGFP_KERNEL);\r\nif (!cinfo->other_bitmap_lockres) {\r\npr_err("md: can't alloc mem for other bitmap locks\n");\r\nreturn 0;\r\n}\r\nmy_slot = slot_number(mddev);\r\nfor (slot = 0; slot < mddev->bitmap_info.nodes; slot++) {\r\nif (slot == my_slot)\r\ncontinue;\r\nmemset(str, '\0', 64);\r\nsnprintf(str, 64, "bitmap%04d", slot);\r\ncinfo->other_bitmap_lockres[i] = lockres_init(mddev, str, NULL, 1);\r\nif (!cinfo->other_bitmap_lockres[i])\r\nreturn -ENOMEM;\r\ncinfo->other_bitmap_lockres[i]->flags |= DLM_LKF_NOQUEUE;\r\nret = dlm_lock_sync(cinfo->other_bitmap_lockres[i], DLM_LOCK_PW);\r\nif (ret)\r\nheld = -1;\r\ni++;\r\n}\r\nreturn held;\r\n}\r\nstatic void unlock_all_bitmaps(struct mddev *mddev)\r\n{\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\nint i;\r\nif (cinfo->other_bitmap_lockres) {\r\nfor (i = 0; i < mddev->bitmap_info.nodes - 1; i++) {\r\nif (cinfo->other_bitmap_lockres[i]) {\r\nlockres_free(cinfo->other_bitmap_lockres[i]);\r\n}\r\n}\r\nkfree(cinfo->other_bitmap_lockres);\r\n}\r\n}\r\nstatic int gather_bitmaps(struct md_rdev *rdev)\r\n{\r\nint sn, err;\r\nsector_t lo, hi;\r\nstruct cluster_msg cmsg = {0};\r\nstruct mddev *mddev = rdev->mddev;\r\nstruct md_cluster_info *cinfo = mddev->cluster_info;\r\ncmsg.type = cpu_to_le32(RE_ADD);\r\ncmsg.raid_slot = cpu_to_le32(rdev->desc_nr);\r\nerr = sendmsg(cinfo, &cmsg, 1);\r\nif (err)\r\ngoto out;\r\nfor (sn = 0; sn < mddev->bitmap_info.nodes; sn++) {\r\nif (sn == (cinfo->slot_number - 1))\r\ncontinue;\r\nerr = bitmap_copy_from_slot(mddev, sn, &lo, &hi, false);\r\nif (err) {\r\npr_warn("md-cluster: Could not gather bitmaps from slot %d", sn);\r\ngoto out;\r\n}\r\nif ((hi > 0) && (lo < mddev->recovery_cp))\r\nmddev->recovery_cp = lo;\r\n}\r\nout:\r\nreturn err;\r\n}\r\nstatic int __init cluster_init(void)\r\n{\r\npr_warn("md-cluster: EXPERIMENTAL. Use with caution\n");\r\npr_info("Registering Cluster MD functions\n");\r\nregister_md_cluster_operations(&cluster_ops, THIS_MODULE);\r\nreturn 0;\r\n}\r\nstatic void cluster_exit(void)\r\n{\r\nunregister_md_cluster_operations();\r\n}
