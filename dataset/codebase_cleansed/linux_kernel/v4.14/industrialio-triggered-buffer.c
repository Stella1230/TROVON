int iio_triggered_buffer_setup(struct iio_dev *indio_dev,\r\nirqreturn_t (*h)(int irq, void *p),\r\nirqreturn_t (*thread)(int irq, void *p),\r\nconst struct iio_buffer_setup_ops *setup_ops)\r\n{\r\nstruct iio_buffer *buffer;\r\nint ret;\r\nbuffer = iio_kfifo_allocate();\r\nif (!buffer) {\r\nret = -ENOMEM;\r\ngoto error_ret;\r\n}\r\niio_device_attach_buffer(indio_dev, buffer);\r\nindio_dev->pollfunc = iio_alloc_pollfunc(h,\r\nthread,\r\nIRQF_ONESHOT,\r\nindio_dev,\r\n"%s_consumer%d",\r\nindio_dev->name,\r\nindio_dev->id);\r\nif (indio_dev->pollfunc == NULL) {\r\nret = -ENOMEM;\r\ngoto error_kfifo_free;\r\n}\r\nif (setup_ops)\r\nindio_dev->setup_ops = setup_ops;\r\nelse\r\nindio_dev->setup_ops = &iio_triggered_buffer_setup_ops;\r\nindio_dev->modes |= INDIO_BUFFER_TRIGGERED;\r\nreturn 0;\r\nerror_kfifo_free:\r\niio_kfifo_free(indio_dev->buffer);\r\nerror_ret:\r\nreturn ret;\r\n}\r\nvoid iio_triggered_buffer_cleanup(struct iio_dev *indio_dev)\r\n{\r\niio_dealloc_pollfunc(indio_dev->pollfunc);\r\niio_kfifo_free(indio_dev->buffer);\r\n}\r\nstatic void devm_iio_triggered_buffer_clean(struct device *dev, void *res)\r\n{\r\niio_triggered_buffer_cleanup(*(struct iio_dev **)res);\r\n}\r\nint devm_iio_triggered_buffer_setup(struct device *dev,\r\nstruct iio_dev *indio_dev,\r\nirqreturn_t (*h)(int irq, void *p),\r\nirqreturn_t (*thread)(int irq, void *p),\r\nconst struct iio_buffer_setup_ops *ops)\r\n{\r\nstruct iio_dev **ptr;\r\nint ret;\r\nptr = devres_alloc(devm_iio_triggered_buffer_clean, sizeof(*ptr),\r\nGFP_KERNEL);\r\nif (!ptr)\r\nreturn -ENOMEM;\r\n*ptr = indio_dev;\r\nret = iio_triggered_buffer_setup(indio_dev, h, thread, ops);\r\nif (!ret)\r\ndevres_add(dev, ptr);\r\nelse\r\ndevres_free(ptr);\r\nreturn ret;\r\n}\r\nvoid devm_iio_triggered_buffer_cleanup(struct device *dev,\r\nstruct iio_dev *indio_dev)\r\n{\r\nint rc;\r\nrc = devres_release(dev, devm_iio_triggered_buffer_clean,\r\ndevm_iio_device_match, indio_dev);\r\nWARN_ON(rc);\r\n}
