static void mvebu_pic_reset(struct mvebu_pic *pic)\r\n{\r\nwritel(0, pic->base + PIC_MASK);\r\nwritel(PIC_MAX_IRQ_MASK, pic->base + PIC_CAUSE);\r\n}\r\nstatic void mvebu_pic_eoi_irq(struct irq_data *d)\r\n{\r\nstruct mvebu_pic *pic = irq_data_get_irq_chip_data(d);\r\nwritel(1 << d->hwirq, pic->base + PIC_CAUSE);\r\n}\r\nstatic void mvebu_pic_mask_irq(struct irq_data *d)\r\n{\r\nstruct mvebu_pic *pic = irq_data_get_irq_chip_data(d);\r\nu32 reg;\r\nreg = readl(pic->base + PIC_MASK);\r\nreg |= (1 << d->hwirq);\r\nwritel(reg, pic->base + PIC_MASK);\r\n}\r\nstatic void mvebu_pic_unmask_irq(struct irq_data *d)\r\n{\r\nstruct mvebu_pic *pic = irq_data_get_irq_chip_data(d);\r\nu32 reg;\r\nreg = readl(pic->base + PIC_MASK);\r\nreg &= ~(1 << d->hwirq);\r\nwritel(reg, pic->base + PIC_MASK);\r\n}\r\nstatic int mvebu_pic_irq_map(struct irq_domain *domain, unsigned int virq,\r\nirq_hw_number_t hwirq)\r\n{\r\nstruct mvebu_pic *pic = domain->host_data;\r\nirq_set_percpu_devid(virq);\r\nirq_set_chip_data(virq, pic);\r\nirq_set_chip_and_handler(virq, &pic->irq_chip,\r\nhandle_percpu_devid_irq);\r\nirq_set_status_flags(virq, IRQ_LEVEL);\r\nirq_set_probe(virq);\r\nreturn 0;\r\n}\r\nstatic void mvebu_pic_handle_cascade_irq(struct irq_desc *desc)\r\n{\r\nstruct mvebu_pic *pic = irq_desc_get_handler_data(desc);\r\nstruct irq_chip *chip = irq_desc_get_chip(desc);\r\nunsigned long irqmap, irqn;\r\nunsigned int cascade_irq;\r\nirqmap = readl_relaxed(pic->base + PIC_CAUSE);\r\nchained_irq_enter(chip, desc);\r\nfor_each_set_bit(irqn, &irqmap, BITS_PER_LONG) {\r\ncascade_irq = irq_find_mapping(pic->domain, irqn);\r\ngeneric_handle_irq(cascade_irq);\r\n}\r\nchained_irq_exit(chip, desc);\r\n}\r\nstatic void mvebu_pic_enable_percpu_irq(void *data)\r\n{\r\nstruct mvebu_pic *pic = data;\r\nmvebu_pic_reset(pic);\r\nenable_percpu_irq(pic->parent_irq, IRQ_TYPE_NONE);\r\n}\r\nstatic void mvebu_pic_disable_percpu_irq(void *data)\r\n{\r\nstruct mvebu_pic *pic = data;\r\ndisable_percpu_irq(pic->parent_irq);\r\n}\r\nstatic int mvebu_pic_probe(struct platform_device *pdev)\r\n{\r\nstruct device_node *node = pdev->dev.of_node;\r\nstruct mvebu_pic *pic;\r\nstruct irq_chip *irq_chip;\r\nstruct resource *res;\r\npic = devm_kzalloc(&pdev->dev, sizeof(struct mvebu_pic), GFP_KERNEL);\r\nif (!pic)\r\nreturn -ENOMEM;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\npic->base = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(pic->base))\r\nreturn PTR_ERR(pic->base);\r\nirq_chip = &pic->irq_chip;\r\nirq_chip->name = dev_name(&pdev->dev);\r\nirq_chip->irq_mask = mvebu_pic_mask_irq;\r\nirq_chip->irq_unmask = mvebu_pic_unmask_irq;\r\nirq_chip->irq_eoi = mvebu_pic_eoi_irq;\r\npic->parent_irq = irq_of_parse_and_map(node, 0);\r\nif (pic->parent_irq <= 0) {\r\ndev_err(&pdev->dev, "Failed to parse parent interrupt\n");\r\nreturn -EINVAL;\r\n}\r\npic->domain = irq_domain_add_linear(node, PIC_MAX_IRQS,\r\n&mvebu_pic_domain_ops, pic);\r\nif (!pic->domain) {\r\ndev_err(&pdev->dev, "Failed to allocate irq domain\n");\r\nreturn -ENOMEM;\r\n}\r\nirq_set_chained_handler(pic->parent_irq, mvebu_pic_handle_cascade_irq);\r\nirq_set_handler_data(pic->parent_irq, pic);\r\non_each_cpu(mvebu_pic_enable_percpu_irq, pic, 1);\r\nplatform_set_drvdata(pdev, pic);\r\nreturn 0;\r\n}\r\nstatic int mvebu_pic_remove(struct platform_device *pdev)\r\n{\r\nstruct mvebu_pic *pic = platform_get_drvdata(pdev);\r\non_each_cpu(mvebu_pic_disable_percpu_irq, pic, 1);\r\nirq_domain_remove(pic->domain);\r\nreturn 0;\r\n}
