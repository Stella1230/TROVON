static int qcom_scm_clk_enable(void)\r\n{\r\nint ret;\r\nret = clk_prepare_enable(__scm->core_clk);\r\nif (ret)\r\ngoto bail;\r\nret = clk_prepare_enable(__scm->iface_clk);\r\nif (ret)\r\ngoto disable_core;\r\nret = clk_prepare_enable(__scm->bus_clk);\r\nif (ret)\r\ngoto disable_iface;\r\nreturn 0;\r\ndisable_iface:\r\nclk_disable_unprepare(__scm->iface_clk);\r\ndisable_core:\r\nclk_disable_unprepare(__scm->core_clk);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic void qcom_scm_clk_disable(void)\r\n{\r\nclk_disable_unprepare(__scm->core_clk);\r\nclk_disable_unprepare(__scm->iface_clk);\r\nclk_disable_unprepare(__scm->bus_clk);\r\n}\r\nint qcom_scm_set_cold_boot_addr(void *entry, const cpumask_t *cpus)\r\n{\r\nreturn __qcom_scm_set_cold_boot_addr(entry, cpus);\r\n}\r\nint qcom_scm_set_warm_boot_addr(void *entry, const cpumask_t *cpus)\r\n{\r\nreturn __qcom_scm_set_warm_boot_addr(__scm->dev, entry, cpus);\r\n}\r\nvoid qcom_scm_cpu_power_down(u32 flags)\r\n{\r\n__qcom_scm_cpu_power_down(flags);\r\n}\r\nbool qcom_scm_hdcp_available(void)\r\n{\r\nint ret = qcom_scm_clk_enable();\r\nif (ret)\r\nreturn ret;\r\nret = __qcom_scm_is_call_available(__scm->dev, QCOM_SCM_SVC_HDCP,\r\nQCOM_SCM_CMD_HDCP);\r\nqcom_scm_clk_disable();\r\nreturn ret > 0 ? true : false;\r\n}\r\nint qcom_scm_hdcp_req(struct qcom_scm_hdcp_req *req, u32 req_cnt, u32 *resp)\r\n{\r\nint ret = qcom_scm_clk_enable();\r\nif (ret)\r\nreturn ret;\r\nret = __qcom_scm_hdcp_req(__scm->dev, req, req_cnt, resp);\r\nqcom_scm_clk_disable();\r\nreturn ret;\r\n}\r\nbool qcom_scm_pas_supported(u32 peripheral)\r\n{\r\nint ret;\r\nret = __qcom_scm_is_call_available(__scm->dev, QCOM_SCM_SVC_PIL,\r\nQCOM_SCM_PAS_IS_SUPPORTED_CMD);\r\nif (ret <= 0)\r\nreturn false;\r\nreturn __qcom_scm_pas_supported(__scm->dev, peripheral);\r\n}\r\nint qcom_scm_pas_init_image(u32 peripheral, const void *metadata, size_t size)\r\n{\r\ndma_addr_t mdata_phys;\r\nvoid *mdata_buf;\r\nint ret;\r\nmdata_buf = dma_alloc_coherent(__scm->dev, size, &mdata_phys,\r\nGFP_KERNEL);\r\nif (!mdata_buf) {\r\ndev_err(__scm->dev, "Allocation of metadata buffer failed.\n");\r\nreturn -ENOMEM;\r\n}\r\nmemcpy(mdata_buf, metadata, size);\r\nret = qcom_scm_clk_enable();\r\nif (ret)\r\ngoto free_metadata;\r\nret = __qcom_scm_pas_init_image(__scm->dev, peripheral, mdata_phys);\r\nqcom_scm_clk_disable();\r\nfree_metadata:\r\ndma_free_coherent(__scm->dev, size, mdata_buf, mdata_phys);\r\nreturn ret;\r\n}\r\nint qcom_scm_pas_mem_setup(u32 peripheral, phys_addr_t addr, phys_addr_t size)\r\n{\r\nint ret;\r\nret = qcom_scm_clk_enable();\r\nif (ret)\r\nreturn ret;\r\nret = __qcom_scm_pas_mem_setup(__scm->dev, peripheral, addr, size);\r\nqcom_scm_clk_disable();\r\nreturn ret;\r\n}\r\nint qcom_scm_pas_auth_and_reset(u32 peripheral)\r\n{\r\nint ret;\r\nret = qcom_scm_clk_enable();\r\nif (ret)\r\nreturn ret;\r\nret = __qcom_scm_pas_auth_and_reset(__scm->dev, peripheral);\r\nqcom_scm_clk_disable();\r\nreturn ret;\r\n}\r\nint qcom_scm_pas_shutdown(u32 peripheral)\r\n{\r\nint ret;\r\nret = qcom_scm_clk_enable();\r\nif (ret)\r\nreturn ret;\r\nret = __qcom_scm_pas_shutdown(__scm->dev, peripheral);\r\nqcom_scm_clk_disable();\r\nreturn ret;\r\n}\r\nstatic int qcom_scm_pas_reset_assert(struct reset_controller_dev *rcdev,\r\nunsigned long idx)\r\n{\r\nif (idx != 0)\r\nreturn -EINVAL;\r\nreturn __qcom_scm_pas_mss_reset(__scm->dev, 1);\r\n}\r\nstatic int qcom_scm_pas_reset_deassert(struct reset_controller_dev *rcdev,\r\nunsigned long idx)\r\n{\r\nif (idx != 0)\r\nreturn -EINVAL;\r\nreturn __qcom_scm_pas_mss_reset(__scm->dev, 0);\r\n}\r\nint qcom_scm_restore_sec_cfg(u32 device_id, u32 spare)\r\n{\r\nreturn __qcom_scm_restore_sec_cfg(__scm->dev, device_id, spare);\r\n}\r\nint qcom_scm_iommu_secure_ptbl_size(u32 spare, size_t *size)\r\n{\r\nreturn __qcom_scm_iommu_secure_ptbl_size(__scm->dev, spare, size);\r\n}\r\nint qcom_scm_iommu_secure_ptbl_init(u64 addr, u32 size, u32 spare)\r\n{\r\nreturn __qcom_scm_iommu_secure_ptbl_init(__scm->dev, addr, size, spare);\r\n}\r\nbool qcom_scm_is_available(void)\r\n{\r\nreturn !!__scm;\r\n}\r\nint qcom_scm_set_remote_state(u32 state, u32 id)\r\n{\r\nreturn __qcom_scm_set_remote_state(__scm->dev, state, id);\r\n}\r\nstatic int qcom_scm_probe(struct platform_device *pdev)\r\n{\r\nstruct qcom_scm *scm;\r\nunsigned long clks;\r\nint ret;\r\nscm = devm_kzalloc(&pdev->dev, sizeof(*scm), GFP_KERNEL);\r\nif (!scm)\r\nreturn -ENOMEM;\r\nclks = (unsigned long)of_device_get_match_data(&pdev->dev);\r\nif (clks & SCM_HAS_CORE_CLK) {\r\nscm->core_clk = devm_clk_get(&pdev->dev, "core");\r\nif (IS_ERR(scm->core_clk)) {\r\nif (PTR_ERR(scm->core_clk) != -EPROBE_DEFER)\r\ndev_err(&pdev->dev,\r\n"failed to acquire core clk\n");\r\nreturn PTR_ERR(scm->core_clk);\r\n}\r\n}\r\nif (clks & SCM_HAS_IFACE_CLK) {\r\nscm->iface_clk = devm_clk_get(&pdev->dev, "iface");\r\nif (IS_ERR(scm->iface_clk)) {\r\nif (PTR_ERR(scm->iface_clk) != -EPROBE_DEFER)\r\ndev_err(&pdev->dev,\r\n"failed to acquire iface clk\n");\r\nreturn PTR_ERR(scm->iface_clk);\r\n}\r\n}\r\nif (clks & SCM_HAS_BUS_CLK) {\r\nscm->bus_clk = devm_clk_get(&pdev->dev, "bus");\r\nif (IS_ERR(scm->bus_clk)) {\r\nif (PTR_ERR(scm->bus_clk) != -EPROBE_DEFER)\r\ndev_err(&pdev->dev,\r\n"failed to acquire bus clk\n");\r\nreturn PTR_ERR(scm->bus_clk);\r\n}\r\n}\r\nscm->reset.ops = &qcom_scm_pas_reset_ops;\r\nscm->reset.nr_resets = 1;\r\nscm->reset.of_node = pdev->dev.of_node;\r\nret = devm_reset_controller_register(&pdev->dev, &scm->reset);\r\nif (ret)\r\nreturn ret;\r\nret = clk_set_rate(scm->core_clk, INT_MAX);\r\nif (ret)\r\nreturn ret;\r\n__scm = scm;\r\n__scm->dev = &pdev->dev;\r\n__qcom_scm_init();\r\nreturn 0;\r\n}\r\nstatic int __init qcom_scm_init(void)\r\n{\r\nstruct device_node *np, *fw_np;\r\nint ret;\r\nfw_np = of_find_node_by_name(NULL, "firmware");\r\nif (!fw_np)\r\nreturn -ENODEV;\r\nnp = of_find_matching_node(fw_np, qcom_scm_dt_match);\r\nif (!np) {\r\nof_node_put(fw_np);\r\nreturn -ENODEV;\r\n}\r\nof_node_put(np);\r\nret = of_platform_populate(fw_np, qcom_scm_dt_match, NULL, NULL);\r\nof_node_put(fw_np);\r\nif (ret)\r\nreturn ret;\r\nreturn platform_driver_register(&qcom_scm_driver);\r\n}
