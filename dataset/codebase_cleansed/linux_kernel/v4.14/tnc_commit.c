static int make_idx_node(struct ubifs_info *c, struct ubifs_idx_node *idx,\r\nstruct ubifs_znode *znode, int lnum, int offs, int len)\r\n{\r\nstruct ubifs_znode *zp;\r\nint i, err;\r\nidx->ch.node_type = UBIFS_IDX_NODE;\r\nidx->child_cnt = cpu_to_le16(znode->child_cnt);\r\nidx->level = cpu_to_le16(znode->level);\r\nfor (i = 0; i < znode->child_cnt; i++) {\r\nstruct ubifs_branch *br = ubifs_idx_branch(c, idx, i);\r\nstruct ubifs_zbranch *zbr = &znode->zbranch[i];\r\nkey_write_idx(c, &zbr->key, &br->key);\r\nbr->lnum = cpu_to_le32(zbr->lnum);\r\nbr->offs = cpu_to_le32(zbr->offs);\r\nbr->len = cpu_to_le32(zbr->len);\r\nif (!zbr->lnum || !zbr->len) {\r\nubifs_err(c, "bad ref in znode");\r\nubifs_dump_znode(c, znode);\r\nif (zbr->znode)\r\nubifs_dump_znode(c, zbr->znode);\r\nreturn -EINVAL;\r\n}\r\n}\r\nubifs_prepare_node(c, idx, len, 0);\r\nznode->lnum = lnum;\r\nznode->offs = offs;\r\nznode->len = len;\r\nerr = insert_old_idx_znode(c, znode);\r\nzp = znode->parent;\r\nif (zp) {\r\nstruct ubifs_zbranch *zbr;\r\nzbr = &zp->zbranch[znode->iip];\r\nzbr->lnum = lnum;\r\nzbr->offs = offs;\r\nzbr->len = len;\r\n} else {\r\nc->zroot.lnum = lnum;\r\nc->zroot.offs = offs;\r\nc->zroot.len = len;\r\n}\r\nc->calc_idx_sz += ALIGN(len, 8);\r\natomic_long_dec(&c->dirty_zn_cnt);\r\nubifs_assert(ubifs_zn_dirty(znode));\r\nubifs_assert(ubifs_zn_cow(znode));\r\n__clear_bit(DIRTY_ZNODE, &znode->flags);\r\n__clear_bit(COW_ZNODE, &znode->flags);\r\nreturn err;\r\n}\r\nstatic int fill_gap(struct ubifs_info *c, int lnum, int gap_start, int gap_end,\r\nint *dirt)\r\n{\r\nint len, gap_remains, gap_pos, written, pad_len;\r\nubifs_assert((gap_start & 7) == 0);\r\nubifs_assert((gap_end & 7) == 0);\r\nubifs_assert(gap_end >= gap_start);\r\ngap_remains = gap_end - gap_start;\r\nif (!gap_remains)\r\nreturn 0;\r\ngap_pos = gap_start;\r\nwritten = 0;\r\nwhile (c->enext) {\r\nlen = ubifs_idx_node_sz(c, c->enext->child_cnt);\r\nif (len < gap_remains) {\r\nstruct ubifs_znode *znode = c->enext;\r\nconst int alen = ALIGN(len, 8);\r\nint err;\r\nubifs_assert(alen <= gap_remains);\r\nerr = make_idx_node(c, c->ileb_buf + gap_pos, znode,\r\nlnum, gap_pos, len);\r\nif (err)\r\nreturn err;\r\ngap_remains -= alen;\r\ngap_pos += alen;\r\nc->enext = znode->cnext;\r\nif (c->enext == c->cnext)\r\nc->enext = NULL;\r\nwritten += 1;\r\n} else\r\nbreak;\r\n}\r\nif (gap_end == c->leb_size) {\r\nc->ileb_len = ALIGN(gap_pos, c->min_io_size);\r\npad_len = c->ileb_len - gap_pos;\r\n} else\r\npad_len = gap_remains;\r\ndbg_gc("LEB %d:%d to %d len %d nodes written %d wasted bytes %d",\r\nlnum, gap_start, gap_end, gap_end - gap_start, written, pad_len);\r\nubifs_pad(c, c->ileb_buf + gap_pos, pad_len);\r\n*dirt += pad_len;\r\nreturn written;\r\n}\r\nstatic int find_old_idx(struct ubifs_info *c, int lnum, int offs)\r\n{\r\nstruct ubifs_old_idx *o;\r\nstruct rb_node *p;\r\np = c->old_idx.rb_node;\r\nwhile (p) {\r\no = rb_entry(p, struct ubifs_old_idx, rb);\r\nif (lnum < o->lnum)\r\np = p->rb_left;\r\nelse if (lnum > o->lnum)\r\np = p->rb_right;\r\nelse if (offs < o->offs)\r\np = p->rb_left;\r\nelse if (offs > o->offs)\r\np = p->rb_right;\r\nelse\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int is_idx_node_in_use(struct ubifs_info *c, union ubifs_key *key,\r\nint level, int lnum, int offs)\r\n{\r\nint ret;\r\nret = is_idx_node_in_tnc(c, key, level, lnum, offs);\r\nif (ret < 0)\r\nreturn ret;\r\nif (ret == 0)\r\nif (find_old_idx(c, lnum, offs))\r\nreturn 1;\r\nreturn ret;\r\n}\r\nstatic int layout_leb_in_gaps(struct ubifs_info *c, int *p)\r\n{\r\nstruct ubifs_scan_leb *sleb;\r\nstruct ubifs_scan_node *snod;\r\nint lnum, dirt = 0, gap_start, gap_end, err, written, tot_written;\r\ntot_written = 0;\r\nlnum = ubifs_find_dirty_idx_leb(c);\r\nif (lnum < 0)\r\nreturn lnum;\r\n*p = lnum;\r\ndbg_gc("LEB %d", lnum);\r\nsleb = ubifs_scan(c, lnum, 0, c->ileb_buf, 0);\r\nc->ileb_len = 0;\r\nif (IS_ERR(sleb))\r\nreturn PTR_ERR(sleb);\r\ngap_start = 0;\r\nlist_for_each_entry(snod, &sleb->nodes, list) {\r\nstruct ubifs_idx_node *idx;\r\nint in_use, level;\r\nubifs_assert(snod->type == UBIFS_IDX_NODE);\r\nidx = snod->node;\r\nkey_read(c, ubifs_idx_key(c, idx), &snod->key);\r\nlevel = le16_to_cpu(idx->level);\r\nin_use = is_idx_node_in_use(c, &snod->key, level, lnum,\r\nsnod->offs);\r\nif (in_use < 0) {\r\nubifs_scan_destroy(sleb);\r\nreturn in_use;\r\n}\r\nif (in_use) {\r\nif (in_use == 1)\r\ndirt += ALIGN(snod->len, 8);\r\ngap_end = snod->offs;\r\nwritten = fill_gap(c, lnum, gap_start, gap_end, &dirt);\r\nif (written < 0) {\r\nubifs_scan_destroy(sleb);\r\nreturn written;\r\n}\r\ntot_written += written;\r\ngap_start = ALIGN(snod->offs + snod->len, 8);\r\n}\r\n}\r\nubifs_scan_destroy(sleb);\r\nc->ileb_len = c->leb_size;\r\ngap_end = c->leb_size;\r\nwritten = fill_gap(c, lnum, gap_start, gap_end, &dirt);\r\nif (written < 0)\r\nreturn written;\r\ntot_written += written;\r\nif (tot_written == 0) {\r\nstruct ubifs_lprops lp;\r\ndbg_gc("LEB %d wrote %d index nodes", lnum, tot_written);\r\nerr = ubifs_read_one_lp(c, lnum, &lp);\r\nif (err)\r\nreturn err;\r\nif (lp.free == c->leb_size) {\r\nerr = ubifs_change_one_lp(c, lnum,\r\nc->leb_size - c->ileb_len,\r\ndirt, 0, 0, 0);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nerr = ubifs_change_one_lp(c, lnum, c->leb_size - c->ileb_len, dirt,\r\n0, 0, 0);\r\nif (err)\r\nreturn err;\r\nerr = ubifs_leb_change(c, lnum, c->ileb_buf, c->ileb_len);\r\nif (err)\r\nreturn err;\r\ndbg_gc("LEB %d wrote %d index nodes", lnum, tot_written);\r\nreturn tot_written;\r\n}\r\nstatic int get_leb_cnt(struct ubifs_info *c, int cnt)\r\n{\r\nint d;\r\ncnt -= (c->leb_size - c->ihead_offs) / c->max_idx_node_sz;\r\nif (cnt < 0)\r\ncnt = 0;\r\nd = c->leb_size / c->max_idx_node_sz;\r\nreturn DIV_ROUND_UP(cnt, d);\r\n}\r\nstatic int layout_in_gaps(struct ubifs_info *c, int cnt)\r\n{\r\nint err, leb_needed_cnt, written, *p;\r\ndbg_gc("%d znodes to write", cnt);\r\nc->gap_lebs = kmalloc(sizeof(int) * (c->lst.idx_lebs + 1), GFP_NOFS);\r\nif (!c->gap_lebs)\r\nreturn -ENOMEM;\r\np = c->gap_lebs;\r\ndo {\r\nubifs_assert(p < c->gap_lebs + c->lst.idx_lebs);\r\nwritten = layout_leb_in_gaps(c, p);\r\nif (written < 0) {\r\nerr = written;\r\nif (err != -ENOSPC) {\r\nkfree(c->gap_lebs);\r\nc->gap_lebs = NULL;\r\nreturn err;\r\n}\r\nif (!dbg_is_chk_index(c)) {\r\nubifs_warn(c, "out of space");\r\nubifs_dump_budg(c, &c->bi);\r\nubifs_dump_lprops(c);\r\n}\r\nbreak;\r\n}\r\np++;\r\ncnt -= written;\r\nleb_needed_cnt = get_leb_cnt(c, cnt);\r\ndbg_gc("%d znodes remaining, need %d LEBs, have %d", cnt,\r\nleb_needed_cnt, c->ileb_cnt);\r\n} while (leb_needed_cnt > c->ileb_cnt);\r\n*p = -1;\r\nreturn 0;\r\n}\r\nstatic int layout_in_empty_space(struct ubifs_info *c)\r\n{\r\nstruct ubifs_znode *znode, *cnext, *zp;\r\nint lnum, offs, len, next_len, buf_len, buf_offs, used, avail;\r\nint wlen, blen, err;\r\ncnext = c->enext;\r\nif (!cnext)\r\nreturn 0;\r\nlnum = c->ihead_lnum;\r\nbuf_offs = c->ihead_offs;\r\nbuf_len = ubifs_idx_node_sz(c, c->fanout);\r\nbuf_len = ALIGN(buf_len, c->min_io_size);\r\nused = 0;\r\navail = buf_len;\r\nnext_len = ubifs_idx_node_sz(c, cnext->child_cnt);\r\nif (buf_offs + next_len > c->leb_size)\r\nlnum = -1;\r\nwhile (1) {\r\nznode = cnext;\r\nlen = ubifs_idx_node_sz(c, znode->child_cnt);\r\nif (lnum == -1) {\r\nif (c->ileb_nxt >= c->ileb_cnt) {\r\nubifs_err(c, "out of space");\r\nreturn -ENOSPC;\r\n}\r\nlnum = c->ilebs[c->ileb_nxt++];\r\nbuf_offs = 0;\r\nused = 0;\r\navail = buf_len;\r\n}\r\noffs = buf_offs + used;\r\nznode->lnum = lnum;\r\nznode->offs = offs;\r\nznode->len = len;\r\nzp = znode->parent;\r\nif (zp) {\r\nstruct ubifs_zbranch *zbr;\r\nint i;\r\ni = znode->iip;\r\nzbr = &zp->zbranch[i];\r\nzbr->lnum = lnum;\r\nzbr->offs = offs;\r\nzbr->len = len;\r\n} else {\r\nc->zroot.lnum = lnum;\r\nc->zroot.offs = offs;\r\nc->zroot.len = len;\r\n}\r\nc->calc_idx_sz += ALIGN(len, 8);\r\natomic_long_dec(&c->dirty_zn_cnt);\r\ncnext = znode->cnext;\r\nif (cnext == c->cnext)\r\nnext_len = 0;\r\nelse\r\nnext_len = ubifs_idx_node_sz(c, cnext->child_cnt);\r\nwlen = used + len;\r\nused += ALIGN(len, 8);\r\navail -= ALIGN(len, 8);\r\nif (next_len != 0 &&\r\nbuf_offs + used + next_len <= c->leb_size &&\r\navail > 0)\r\ncontinue;\r\nif (avail <= 0 && next_len &&\r\nbuf_offs + used + next_len <= c->leb_size)\r\nblen = buf_len;\r\nelse\r\nblen = ALIGN(wlen, c->min_io_size);\r\nbuf_offs += blen;\r\nif (next_len) {\r\nif (buf_offs + next_len > c->leb_size) {\r\nerr = ubifs_update_one_lp(c, lnum,\r\nc->leb_size - buf_offs, blen - used,\r\n0, 0);\r\nif (err)\r\nreturn err;\r\nlnum = -1;\r\n}\r\nused -= blen;\r\nif (used < 0)\r\nused = 0;\r\navail = buf_len - used;\r\ncontinue;\r\n}\r\nerr = ubifs_update_one_lp(c, lnum, c->leb_size - buf_offs,\r\nblen - used, 0, 0);\r\nif (err)\r\nreturn err;\r\nbreak;\r\n}\r\nc->dbg->new_ihead_lnum = lnum;\r\nc->dbg->new_ihead_offs = buf_offs;\r\nreturn 0;\r\n}\r\nstatic int layout_commit(struct ubifs_info *c, int no_space, int cnt)\r\n{\r\nint err;\r\nif (no_space) {\r\nerr = layout_in_gaps(c, cnt);\r\nif (err)\r\nreturn err;\r\n}\r\nerr = layout_in_empty_space(c);\r\nreturn err;\r\n}\r\nstatic struct ubifs_znode *find_first_dirty(struct ubifs_znode *znode)\r\n{\r\nint i, cont;\r\nif (!znode)\r\nreturn NULL;\r\nwhile (1) {\r\nif (znode->level == 0) {\r\nif (ubifs_zn_dirty(znode))\r\nreturn znode;\r\nreturn NULL;\r\n}\r\ncont = 0;\r\nfor (i = 0; i < znode->child_cnt; i++) {\r\nstruct ubifs_zbranch *zbr = &znode->zbranch[i];\r\nif (zbr->znode && ubifs_zn_dirty(zbr->znode)) {\r\nznode = zbr->znode;\r\ncont = 1;\r\nbreak;\r\n}\r\n}\r\nif (!cont) {\r\nif (ubifs_zn_dirty(znode))\r\nreturn znode;\r\nreturn NULL;\r\n}\r\n}\r\n}\r\nstatic struct ubifs_znode *find_next_dirty(struct ubifs_znode *znode)\r\n{\r\nint n = znode->iip + 1;\r\nznode = znode->parent;\r\nif (!znode)\r\nreturn NULL;\r\nfor (; n < znode->child_cnt; n++) {\r\nstruct ubifs_zbranch *zbr = &znode->zbranch[n];\r\nif (zbr->znode && ubifs_zn_dirty(zbr->znode))\r\nreturn find_first_dirty(zbr->znode);\r\n}\r\nreturn znode;\r\n}\r\nstatic int get_znodes_to_commit(struct ubifs_info *c)\r\n{\r\nstruct ubifs_znode *znode, *cnext;\r\nint cnt = 0;\r\nc->cnext = find_first_dirty(c->zroot.znode);\r\nznode = c->enext = c->cnext;\r\nif (!znode) {\r\ndbg_cmt("no znodes to commit");\r\nreturn 0;\r\n}\r\ncnt += 1;\r\nwhile (1) {\r\nubifs_assert(!ubifs_zn_cow(znode));\r\n__set_bit(COW_ZNODE, &znode->flags);\r\nznode->alt = 0;\r\ncnext = find_next_dirty(znode);\r\nif (!cnext) {\r\nznode->cnext = c->cnext;\r\nbreak;\r\n}\r\nznode->cnext = cnext;\r\nznode = cnext;\r\ncnt += 1;\r\n}\r\ndbg_cmt("committing %d znodes", cnt);\r\nubifs_assert(cnt == atomic_long_read(&c->dirty_zn_cnt));\r\nreturn cnt;\r\n}\r\nstatic int alloc_idx_lebs(struct ubifs_info *c, int cnt)\r\n{\r\nint i, leb_cnt, lnum;\r\nc->ileb_cnt = 0;\r\nc->ileb_nxt = 0;\r\nleb_cnt = get_leb_cnt(c, cnt);\r\ndbg_cmt("need about %d empty LEBS for TNC commit", leb_cnt);\r\nif (!leb_cnt)\r\nreturn 0;\r\nc->ilebs = kmalloc(leb_cnt * sizeof(int), GFP_NOFS);\r\nif (!c->ilebs)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < leb_cnt; i++) {\r\nlnum = ubifs_find_free_leb_for_idx(c);\r\nif (lnum < 0)\r\nreturn lnum;\r\nc->ilebs[c->ileb_cnt++] = lnum;\r\ndbg_cmt("LEB %d", lnum);\r\n}\r\nif (dbg_is_chk_index(c) && !(prandom_u32() & 7))\r\nreturn -ENOSPC;\r\nreturn 0;\r\n}\r\nstatic int free_unused_idx_lebs(struct ubifs_info *c)\r\n{\r\nint i, err = 0, lnum, er;\r\nfor (i = c->ileb_nxt; i < c->ileb_cnt; i++) {\r\nlnum = c->ilebs[i];\r\ndbg_cmt("LEB %d", lnum);\r\ner = ubifs_change_one_lp(c, lnum, LPROPS_NC, LPROPS_NC, 0,\r\nLPROPS_INDEX | LPROPS_TAKEN, 0);\r\nif (!err)\r\nerr = er;\r\n}\r\nreturn err;\r\n}\r\nstatic int free_idx_lebs(struct ubifs_info *c)\r\n{\r\nint err;\r\nerr = free_unused_idx_lebs(c);\r\nkfree(c->ilebs);\r\nc->ilebs = NULL;\r\nreturn err;\r\n}\r\nint ubifs_tnc_start_commit(struct ubifs_info *c, struct ubifs_zbranch *zroot)\r\n{\r\nint err = 0, cnt;\r\nmutex_lock(&c->tnc_mutex);\r\nerr = dbg_check_tnc(c, 1);\r\nif (err)\r\ngoto out;\r\ncnt = get_znodes_to_commit(c);\r\nif (cnt != 0) {\r\nint no_space = 0;\r\nerr = alloc_idx_lebs(c, cnt);\r\nif (err == -ENOSPC)\r\nno_space = 1;\r\nelse if (err)\r\ngoto out_free;\r\nerr = layout_commit(c, no_space, cnt);\r\nif (err)\r\ngoto out_free;\r\nubifs_assert(atomic_long_read(&c->dirty_zn_cnt) == 0);\r\nerr = free_unused_idx_lebs(c);\r\nif (err)\r\ngoto out;\r\n}\r\ndestroy_old_idx(c);\r\nmemcpy(zroot, &c->zroot, sizeof(struct ubifs_zbranch));\r\nerr = ubifs_save_dirty_idx_lnums(c);\r\nif (err)\r\ngoto out;\r\nspin_lock(&c->space_lock);\r\nubifs_assert(c->bi.min_idx_lebs == ubifs_calc_min_idx_lebs(c));\r\nc->bi.old_idx_sz = c->calc_idx_sz;\r\nc->bi.uncommitted_idx = 0;\r\nc->bi.min_idx_lebs = ubifs_calc_min_idx_lebs(c);\r\nspin_unlock(&c->space_lock);\r\nmutex_unlock(&c->tnc_mutex);\r\ndbg_cmt("number of index LEBs %d", c->lst.idx_lebs);\r\ndbg_cmt("size of index %llu", c->calc_idx_sz);\r\nreturn err;\r\nout_free:\r\nfree_idx_lebs(c);\r\nout:\r\nmutex_unlock(&c->tnc_mutex);\r\nreturn err;\r\n}\r\nstatic int write_index(struct ubifs_info *c)\r\n{\r\nstruct ubifs_idx_node *idx;\r\nstruct ubifs_znode *znode, *cnext;\r\nint i, lnum, offs, len, next_len, buf_len, buf_offs, used;\r\nint avail, wlen, err, lnum_pos = 0, blen, nxt_offs;\r\ncnext = c->enext;\r\nif (!cnext)\r\nreturn 0;\r\nlnum = c->ihead_lnum;\r\nbuf_offs = c->ihead_offs;\r\nbuf_len = ALIGN(c->max_idx_node_sz, c->min_io_size);\r\nused = 0;\r\navail = buf_len;\r\nnext_len = ubifs_idx_node_sz(c, cnext->child_cnt);\r\nif (buf_offs + next_len > c->leb_size) {\r\nerr = ubifs_update_one_lp(c, lnum, LPROPS_NC, 0, 0,\r\nLPROPS_TAKEN);\r\nif (err)\r\nreturn err;\r\nlnum = -1;\r\n}\r\nwhile (1) {\r\ncond_resched();\r\nznode = cnext;\r\nidx = c->cbuf + used;\r\nidx->ch.node_type = UBIFS_IDX_NODE;\r\nidx->child_cnt = cpu_to_le16(znode->child_cnt);\r\nidx->level = cpu_to_le16(znode->level);\r\nfor (i = 0; i < znode->child_cnt; i++) {\r\nstruct ubifs_branch *br = ubifs_idx_branch(c, idx, i);\r\nstruct ubifs_zbranch *zbr = &znode->zbranch[i];\r\nkey_write_idx(c, &zbr->key, &br->key);\r\nbr->lnum = cpu_to_le32(zbr->lnum);\r\nbr->offs = cpu_to_le32(zbr->offs);\r\nbr->len = cpu_to_le32(zbr->len);\r\nif (!zbr->lnum || !zbr->len) {\r\nubifs_err(c, "bad ref in znode");\r\nubifs_dump_znode(c, znode);\r\nif (zbr->znode)\r\nubifs_dump_znode(c, zbr->znode);\r\nreturn -EINVAL;\r\n}\r\n}\r\nlen = ubifs_idx_node_sz(c, znode->child_cnt);\r\nubifs_prepare_node(c, idx, len, 0);\r\nif (lnum == -1) {\r\nlnum = c->ilebs[lnum_pos++];\r\nbuf_offs = 0;\r\nused = 0;\r\navail = buf_len;\r\n}\r\noffs = buf_offs + used;\r\nif (lnum != znode->lnum || offs != znode->offs ||\r\nlen != znode->len) {\r\nubifs_err(c, "inconsistent znode posn");\r\nreturn -EINVAL;\r\n}\r\ncnext = znode->cnext;\r\nubifs_assert(ubifs_zn_dirty(znode));\r\nubifs_assert(ubifs_zn_cow(znode));\r\nclear_bit(DIRTY_ZNODE, &znode->flags);\r\nsmp_mb__before_atomic();\r\nclear_bit(COW_ZNODE, &znode->flags);\r\nsmp_mb__after_atomic();\r\nwlen = used + len;\r\nused += ALIGN(len, 8);\r\navail -= ALIGN(len, 8);\r\nif (cnext == c->cnext)\r\nnext_len = 0;\r\nelse\r\nnext_len = ubifs_idx_node_sz(c, cnext->child_cnt);\r\nnxt_offs = buf_offs + used + next_len;\r\nif (next_len && nxt_offs <= c->leb_size) {\r\nif (avail > 0)\r\ncontinue;\r\nelse\r\nblen = buf_len;\r\n} else {\r\nwlen = ALIGN(wlen, 8);\r\nblen = ALIGN(wlen, c->min_io_size);\r\nubifs_pad(c, c->cbuf + wlen, blen - wlen);\r\n}\r\nerr = ubifs_leb_write(c, lnum, c->cbuf, buf_offs, blen);\r\nif (err)\r\nreturn err;\r\nbuf_offs += blen;\r\nif (next_len) {\r\nif (nxt_offs > c->leb_size) {\r\nerr = ubifs_update_one_lp(c, lnum, LPROPS_NC, 0,\r\n0, LPROPS_TAKEN);\r\nif (err)\r\nreturn err;\r\nlnum = -1;\r\n}\r\nused -= blen;\r\nif (used < 0)\r\nused = 0;\r\navail = buf_len - used;\r\nmemmove(c->cbuf, c->cbuf + blen, used);\r\ncontinue;\r\n}\r\nbreak;\r\n}\r\nif (lnum != c->dbg->new_ihead_lnum ||\r\nbuf_offs != c->dbg->new_ihead_offs) {\r\nubifs_err(c, "inconsistent ihead");\r\nreturn -EINVAL;\r\n}\r\nc->ihead_lnum = lnum;\r\nc->ihead_offs = buf_offs;\r\nreturn 0;\r\n}\r\nstatic void free_obsolete_znodes(struct ubifs_info *c)\r\n{\r\nstruct ubifs_znode *znode, *cnext;\r\ncnext = c->cnext;\r\ndo {\r\nznode = cnext;\r\ncnext = znode->cnext;\r\nif (ubifs_zn_obsolete(znode))\r\nkfree(znode);\r\nelse {\r\nznode->cnext = NULL;\r\natomic_long_inc(&c->clean_zn_cnt);\r\natomic_long_inc(&ubifs_clean_zn_cnt);\r\n}\r\n} while (cnext != c->cnext);\r\n}\r\nstatic int return_gap_lebs(struct ubifs_info *c)\r\n{\r\nint *p, err;\r\nif (!c->gap_lebs)\r\nreturn 0;\r\ndbg_cmt("");\r\nfor (p = c->gap_lebs; *p != -1; p++) {\r\nerr = ubifs_change_one_lp(c, *p, LPROPS_NC, LPROPS_NC, 0,\r\nLPROPS_TAKEN, 0);\r\nif (err)\r\nreturn err;\r\n}\r\nkfree(c->gap_lebs);\r\nc->gap_lebs = NULL;\r\nreturn 0;\r\n}\r\nint ubifs_tnc_end_commit(struct ubifs_info *c)\r\n{\r\nint err;\r\nif (!c->cnext)\r\nreturn 0;\r\nerr = return_gap_lebs(c);\r\nif (err)\r\nreturn err;\r\nerr = write_index(c);\r\nif (err)\r\nreturn err;\r\nmutex_lock(&c->tnc_mutex);\r\ndbg_cmt("TNC height is %d", c->zroot.znode->level + 1);\r\nfree_obsolete_znodes(c);\r\nc->cnext = NULL;\r\nkfree(c->ilebs);\r\nc->ilebs = NULL;\r\nmutex_unlock(&c->tnc_mutex);\r\nreturn 0;\r\n}
