int allocate_compression_buffers(void)\r\n{\r\nBUG_ON(ntfs_compression_buffer);\r\nntfs_compression_buffer = vmalloc(NTFS_MAX_CB_SIZE);\r\nif (!ntfs_compression_buffer)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid free_compression_buffers(void)\r\n{\r\nBUG_ON(!ntfs_compression_buffer);\r\nvfree(ntfs_compression_buffer);\r\nntfs_compression_buffer = NULL;\r\n}\r\nstatic void zero_partial_compressed_page(struct page *page,\r\nconst s64 initialized_size)\r\n{\r\nu8 *kp = page_address(page);\r\nunsigned int kp_ofs;\r\nntfs_debug("Zeroing page region outside initialized size.");\r\nif (((s64)page->index << PAGE_SHIFT) >= initialized_size) {\r\nclear_page(kp);\r\nreturn;\r\n}\r\nkp_ofs = initialized_size & ~PAGE_MASK;\r\nmemset(kp + kp_ofs, 0, PAGE_SIZE - kp_ofs);\r\nreturn;\r\n}\r\nstatic inline void handle_bounds_compressed_page(struct page *page,\r\nconst loff_t i_size, const s64 initialized_size)\r\n{\r\nif ((page->index >= (initialized_size >> PAGE_SHIFT)) &&\r\n(initialized_size < i_size))\r\nzero_partial_compressed_page(page, initialized_size);\r\nreturn;\r\n}\r\nstatic int ntfs_decompress(struct page *dest_pages[], int *dest_index,\r\nint *dest_ofs, const int dest_max_index, const int dest_max_ofs,\r\nconst int xpage, char *xpage_done, u8 *const cb_start,\r\nconst u32 cb_size, const loff_t i_size,\r\nconst s64 initialized_size)\r\n{\r\nu8 *cb_end = cb_start + cb_size;\r\nu8 *cb = cb_start;\r\nu8 *cb_sb_start = cb;\r\nu8 *cb_sb_end;\r\nstruct page *dp;\r\nu8 *dp_addr;\r\nu8 *dp_sb_start;\r\nu8 *dp_sb_end;\r\nu16 do_sb_start;\r\nu16 do_sb_end;\r\nu8 tag;\r\nint token;\r\nint completed_pages[dest_max_index - *dest_index + 1];\r\nint nr_completed_pages = 0;\r\nint err = -EOVERFLOW;\r\nntfs_debug("Entering, cb_size = 0x%x.", cb_size);\r\ndo_next_sb:\r\nntfs_debug("Beginning sub-block at offset = 0x%zx in the cb.",\r\ncb - cb_start);\r\nif (cb == cb_end || !le16_to_cpup((le16*)cb) ||\r\n(*dest_index == dest_max_index &&\r\n*dest_ofs == dest_max_ofs)) {\r\nint i;\r\nntfs_debug("Completed. Returning success (0).");\r\nerr = 0;\r\nreturn_error:\r\nspin_unlock(&ntfs_cb_lock);\r\nif (nr_completed_pages > 0) {\r\nfor (i = 0; i < nr_completed_pages; i++) {\r\nint di = completed_pages[i];\r\ndp = dest_pages[di];\r\nhandle_bounds_compressed_page(dp, i_size,\r\ninitialized_size);\r\nflush_dcache_page(dp);\r\nkunmap(dp);\r\nSetPageUptodate(dp);\r\nunlock_page(dp);\r\nif (di == xpage)\r\n*xpage_done = 1;\r\nelse\r\nput_page(dp);\r\ndest_pages[di] = NULL;\r\n}\r\n}\r\nreturn err;\r\n}\r\ndo_sb_start = *dest_ofs;\r\ndo_sb_end = do_sb_start + NTFS_SB_SIZE;\r\nif (*dest_index == dest_max_index && do_sb_end > dest_max_ofs)\r\ngoto return_overflow;\r\nif (cb + 6 > cb_end)\r\ngoto return_overflow;\r\ncb_sb_start = cb;\r\ncb_sb_end = cb_sb_start + (le16_to_cpup((le16*)cb) & NTFS_SB_SIZE_MASK)\r\n+ 3;\r\nif (cb_sb_end > cb_end)\r\ngoto return_overflow;\r\ndp = dest_pages[*dest_index];\r\nif (!dp) {\r\ncb = cb_sb_end;\r\n*dest_ofs = (*dest_ofs + NTFS_SB_SIZE) & ~PAGE_MASK;\r\nif (!*dest_ofs && (++*dest_index > dest_max_index))\r\ngoto return_overflow;\r\ngoto do_next_sb;\r\n}\r\ndp_addr = (u8*)page_address(dp) + do_sb_start;\r\nif (!(le16_to_cpup((le16*)cb) & NTFS_SB_IS_COMPRESSED)) {\r\nntfs_debug("Found uncompressed sub-block.");\r\ncb += 2;\r\nif (cb_sb_end - cb != NTFS_SB_SIZE)\r\ngoto return_overflow;\r\nmemcpy(dp_addr, cb, NTFS_SB_SIZE);\r\ncb += NTFS_SB_SIZE;\r\n*dest_ofs += NTFS_SB_SIZE;\r\nif (!(*dest_ofs &= ~PAGE_MASK)) {\r\nfinalize_page:\r\ncompleted_pages[nr_completed_pages++] = *dest_index;\r\nif (++*dest_index > dest_max_index)\r\ngoto return_overflow;\r\n}\r\ngoto do_next_sb;\r\n}\r\nntfs_debug("Found compressed sub-block.");\r\ndp_sb_start = dp_addr;\r\ndp_sb_end = dp_sb_start + NTFS_SB_SIZE;\r\ncb += 2;\r\ndo_next_tag:\r\nif (cb == cb_sb_end) {\r\nif (dp_addr < dp_sb_end) {\r\nint nr_bytes = do_sb_end - *dest_ofs;\r\nntfs_debug("Filling incomplete sub-block with "\r\n"zeroes.");\r\nmemset(dp_addr, 0, nr_bytes);\r\n*dest_ofs += nr_bytes;\r\n}\r\nif (!(*dest_ofs &= ~PAGE_MASK))\r\ngoto finalize_page;\r\ngoto do_next_sb;\r\n}\r\nif (cb > cb_sb_end || dp_addr > dp_sb_end)\r\ngoto return_overflow;\r\ntag = *cb++;\r\nfor (token = 0; token < 8; token++, tag >>= 1) {\r\nu16 lg, pt, length, max_non_overlap;\r\nregister u16 i;\r\nu8 *dp_back_addr;\r\nif (cb >= cb_sb_end || dp_addr > dp_sb_end)\r\nbreak;\r\nif ((tag & NTFS_TOKEN_MASK) == NTFS_SYMBOL_TOKEN) {\r\n*dp_addr++ = *cb++;\r\n++*dest_ofs;\r\ncontinue;\r\n}\r\nif (dp_addr == dp_sb_start)\r\ngoto return_overflow;\r\nlg = 0;\r\nfor (i = *dest_ofs - do_sb_start - 1; i >= 0x10; i >>= 1)\r\nlg++;\r\npt = le16_to_cpup((le16*)cb);\r\ndp_back_addr = dp_addr - (pt >> (12 - lg)) - 1;\r\nif (dp_back_addr < dp_sb_start)\r\ngoto return_overflow;\r\nlength = (pt & (0xfff >> lg)) + 3;\r\n*dest_ofs += length;\r\nif (*dest_ofs > do_sb_end)\r\ngoto return_overflow;\r\nmax_non_overlap = dp_addr - dp_back_addr;\r\nif (length <= max_non_overlap) {\r\nmemcpy(dp_addr, dp_back_addr, length);\r\ndp_addr += length;\r\n} else {\r\nmemcpy(dp_addr, dp_back_addr, max_non_overlap);\r\ndp_addr += max_non_overlap;\r\ndp_back_addr += max_non_overlap;\r\nlength -= max_non_overlap;\r\nwhile (length--)\r\n*dp_addr++ = *dp_back_addr++;\r\n}\r\ncb += 2;\r\n}\r\ngoto do_next_tag;\r\nreturn_overflow:\r\nntfs_error(NULL, "Failed. Returning -EOVERFLOW.");\r\ngoto return_error;\r\n}\r\nint ntfs_read_compressed_block(struct page *page)\r\n{\r\nloff_t i_size;\r\ns64 initialized_size;\r\nstruct address_space *mapping = page->mapping;\r\nntfs_inode *ni = NTFS_I(mapping->host);\r\nntfs_volume *vol = ni->vol;\r\nstruct super_block *sb = vol->sb;\r\nrunlist_element *rl;\r\nunsigned long flags, block_size = sb->s_blocksize;\r\nunsigned char block_size_bits = sb->s_blocksize_bits;\r\nu8 *cb, *cb_pos, *cb_end;\r\nstruct buffer_head **bhs;\r\nunsigned long offset, index = page->index;\r\nu32 cb_size = ni->itype.compressed.block_size;\r\nu64 cb_size_mask = cb_size - 1UL;\r\nVCN vcn;\r\nLCN lcn;\r\nVCN start_vcn = (((s64)index << PAGE_SHIFT) & ~cb_size_mask) >>\r\nvol->cluster_size_bits;\r\nVCN end_vcn = ((((s64)(index + 1UL) << PAGE_SHIFT) + cb_size - 1)\r\n& ~cb_size_mask) >> vol->cluster_size_bits;\r\nunsigned int nr_cbs = (end_vcn - start_vcn) << vol->cluster_size_bits\r\n>> ni->itype.compressed.block_size_bits;\r\nunsigned int nr_pages = (end_vcn - start_vcn) <<\r\nvol->cluster_size_bits >> PAGE_SHIFT;\r\nunsigned int xpage, max_page, cur_page, cur_ofs, i;\r\nunsigned int cb_clusters, cb_max_ofs;\r\nint block, max_block, cb_max_page, bhs_size, nr_bhs, err = 0;\r\nstruct page **pages;\r\nunsigned char xpage_done = 0;\r\nntfs_debug("Entering, page->index = 0x%lx, cb_size = 0x%x, nr_pages = "\r\n"%i.", index, cb_size, nr_pages);\r\nBUG_ON(ni->type != AT_DATA);\r\nBUG_ON(ni->name_len);\r\npages = kmalloc(nr_pages * sizeof(struct page *), GFP_NOFS);\r\nbhs_size = cb_size / block_size * sizeof(struct buffer_head *);\r\nbhs = kmalloc(bhs_size, GFP_NOFS);\r\nif (unlikely(!pages || !bhs)) {\r\nkfree(bhs);\r\nkfree(pages);\r\nunlock_page(page);\r\nntfs_error(vol->sb, "Failed to allocate internal buffers.");\r\nreturn -ENOMEM;\r\n}\r\noffset = start_vcn << vol->cluster_size_bits >> PAGE_SHIFT;\r\nxpage = index - offset;\r\npages[xpage] = page;\r\nread_lock_irqsave(&ni->size_lock, flags);\r\ni_size = i_size_read(VFS_I(ni));\r\ninitialized_size = ni->initialized_size;\r\nread_unlock_irqrestore(&ni->size_lock, flags);\r\nmax_page = ((i_size + PAGE_SIZE - 1) >> PAGE_SHIFT) -\r\noffset;\r\nif (xpage >= max_page) {\r\nkfree(bhs);\r\nkfree(pages);\r\nzero_user(page, 0, PAGE_SIZE);\r\nntfs_debug("Compressed read outside i_size - truncated?");\r\nSetPageUptodate(page);\r\nunlock_page(page);\r\nreturn 0;\r\n}\r\nif (nr_pages < max_page)\r\nmax_page = nr_pages;\r\nfor (i = 0; i < max_page; i++, offset++) {\r\nif (i != xpage)\r\npages[i] = grab_cache_page_nowait(mapping, offset);\r\npage = pages[i];\r\nif (page) {\r\nif (!PageDirty(page) && (!PageUptodate(page) ||\r\nPageError(page))) {\r\nClearPageError(page);\r\nkmap(page);\r\ncontinue;\r\n}\r\nunlock_page(page);\r\nput_page(page);\r\npages[i] = NULL;\r\n}\r\n}\r\ncur_page = 0;\r\ncur_ofs = 0;\r\ncb_clusters = ni->itype.compressed.block_clusters;\r\ndo_next_cb:\r\nnr_cbs--;\r\nnr_bhs = 0;\r\nrl = NULL;\r\nfor (vcn = start_vcn, start_vcn += cb_clusters; vcn < start_vcn;\r\nvcn++) {\r\nbool is_retry = false;\r\nif (!rl) {\r\nlock_retry_remap:\r\ndown_read(&ni->runlist.lock);\r\nrl = ni->runlist.rl;\r\n}\r\nif (likely(rl != NULL)) {\r\nwhile (rl->length && rl[1].vcn <= vcn)\r\nrl++;\r\nlcn = ntfs_rl_vcn_to_lcn(rl, vcn);\r\n} else\r\nlcn = LCN_RL_NOT_MAPPED;\r\nntfs_debug("Reading vcn = 0x%llx, lcn = 0x%llx.",\r\n(unsigned long long)vcn,\r\n(unsigned long long)lcn);\r\nif (lcn < 0) {\r\nif (lcn == LCN_HOLE)\r\nbreak;\r\nif (is_retry || lcn != LCN_RL_NOT_MAPPED)\r\ngoto rl_err;\r\nis_retry = true;\r\nup_read(&ni->runlist.lock);\r\nif (!ntfs_map_runlist(ni, vcn))\r\ngoto lock_retry_remap;\r\ngoto map_rl_err;\r\n}\r\nblock = lcn << vol->cluster_size_bits >> block_size_bits;\r\nmax_block = block + (vol->cluster_size >> block_size_bits);\r\ndo {\r\nntfs_debug("block = 0x%x.", block);\r\nif (unlikely(!(bhs[nr_bhs] = sb_getblk(sb, block))))\r\ngoto getblk_err;\r\nnr_bhs++;\r\n} while (++block < max_block);\r\n}\r\nif (rl)\r\nup_read(&ni->runlist.lock);\r\nfor (i = 0; i < nr_bhs; i++) {\r\nstruct buffer_head *tbh = bhs[i];\r\nif (!trylock_buffer(tbh))\r\ncontinue;\r\nif (unlikely(buffer_uptodate(tbh))) {\r\nunlock_buffer(tbh);\r\ncontinue;\r\n}\r\nget_bh(tbh);\r\ntbh->b_end_io = end_buffer_read_sync;\r\nsubmit_bh(REQ_OP_READ, 0, tbh);\r\n}\r\nfor (i = 0; i < nr_bhs; i++) {\r\nstruct buffer_head *tbh = bhs[i];\r\nif (buffer_uptodate(tbh))\r\ncontinue;\r\nwait_on_buffer(tbh);\r\nbarrier();\r\nif (unlikely(!buffer_uptodate(tbh))) {\r\nntfs_warning(vol->sb, "Buffer is unlocked but not "\r\n"uptodate! Unplugging the disk queue "\r\n"and rescheduling.");\r\nget_bh(tbh);\r\nio_schedule();\r\nput_bh(tbh);\r\nif (unlikely(!buffer_uptodate(tbh)))\r\ngoto read_err;\r\nntfs_warning(vol->sb, "Buffer is now uptodate. Good.");\r\n}\r\n}\r\nspin_lock(&ntfs_cb_lock);\r\ncb = ntfs_compression_buffer;\r\nBUG_ON(!cb);\r\ncb_pos = cb;\r\ncb_end = cb + cb_size;\r\nfor (i = 0; i < nr_bhs; i++) {\r\nmemcpy(cb_pos, bhs[i]->b_data, block_size);\r\ncb_pos += block_size;\r\n}\r\nif (cb_pos + 2 <= cb + cb_size)\r\n*(u16*)cb_pos = 0;\r\ncb_pos = cb;\r\nntfs_debug("Successfully read the compression block.");\r\ncb_max_page = (cur_page << PAGE_SHIFT) + cur_ofs + cb_size;\r\ncb_max_ofs = cb_max_page & ~PAGE_MASK;\r\ncb_max_page >>= PAGE_SHIFT;\r\nif (cb_max_page > max_page)\r\ncb_max_page = max_page;\r\nif (vcn == start_vcn - cb_clusters) {\r\nntfs_debug("Found sparse compression block.");\r\nspin_unlock(&ntfs_cb_lock);\r\nif (cb_max_ofs)\r\ncb_max_page--;\r\nfor (; cur_page < cb_max_page; cur_page++) {\r\npage = pages[cur_page];\r\nif (page) {\r\nif (likely(!cur_ofs))\r\nclear_page(page_address(page));\r\nelse\r\nmemset(page_address(page) + cur_ofs, 0,\r\nPAGE_SIZE -\r\ncur_ofs);\r\nflush_dcache_page(page);\r\nkunmap(page);\r\nSetPageUptodate(page);\r\nunlock_page(page);\r\nif (cur_page == xpage)\r\nxpage_done = 1;\r\nelse\r\nput_page(page);\r\npages[cur_page] = NULL;\r\n}\r\ncb_pos += PAGE_SIZE - cur_ofs;\r\ncur_ofs = 0;\r\nif (cb_pos >= cb_end)\r\nbreak;\r\n}\r\nif (cb_max_ofs && cb_pos < cb_end) {\r\npage = pages[cur_page];\r\nif (page)\r\nmemset(page_address(page) + cur_ofs, 0,\r\ncb_max_ofs - cur_ofs);\r\ncur_ofs = cb_max_ofs;\r\n}\r\n} else if (vcn == start_vcn) {\r\nunsigned int cur2_page = cur_page;\r\nunsigned int cur_ofs2 = cur_ofs;\r\nu8 *cb_pos2 = cb_pos;\r\nntfs_debug("Found uncompressed compression block.");\r\nif (cb_max_ofs)\r\ncb_max_page--;\r\nfor (; cur_page < cb_max_page; cur_page++) {\r\npage = pages[cur_page];\r\nif (page)\r\nmemcpy(page_address(page) + cur_ofs, cb_pos,\r\nPAGE_SIZE - cur_ofs);\r\ncb_pos += PAGE_SIZE - cur_ofs;\r\ncur_ofs = 0;\r\nif (cb_pos >= cb_end)\r\nbreak;\r\n}\r\nif (cb_max_ofs && cb_pos < cb_end) {\r\npage = pages[cur_page];\r\nif (page)\r\nmemcpy(page_address(page) + cur_ofs, cb_pos,\r\ncb_max_ofs - cur_ofs);\r\ncb_pos += cb_max_ofs - cur_ofs;\r\ncur_ofs = cb_max_ofs;\r\n}\r\nspin_unlock(&ntfs_cb_lock);\r\nfor (; cur2_page < cb_max_page; cur2_page++) {\r\npage = pages[cur2_page];\r\nif (page) {\r\nhandle_bounds_compressed_page(page, i_size,\r\ninitialized_size);\r\nflush_dcache_page(page);\r\nkunmap(page);\r\nSetPageUptodate(page);\r\nunlock_page(page);\r\nif (cur2_page == xpage)\r\nxpage_done = 1;\r\nelse\r\nput_page(page);\r\npages[cur2_page] = NULL;\r\n}\r\ncb_pos2 += PAGE_SIZE - cur_ofs2;\r\ncur_ofs2 = 0;\r\nif (cb_pos2 >= cb_end)\r\nbreak;\r\n}\r\n} else {\r\nunsigned int prev_cur_page = cur_page;\r\nntfs_debug("Found compressed compression block.");\r\nerr = ntfs_decompress(pages, &cur_page, &cur_ofs,\r\ncb_max_page, cb_max_ofs, xpage, &xpage_done,\r\ncb_pos, cb_size - (cb_pos - cb), i_size,\r\ninitialized_size);\r\nif (err) {\r\nntfs_error(vol->sb, "ntfs_decompress() failed in inode "\r\n"0x%lx with error code %i. Skipping "\r\n"this compression block.",\r\nni->mft_no, -err);\r\nfor (; prev_cur_page < cur_page; prev_cur_page++) {\r\npage = pages[prev_cur_page];\r\nif (page) {\r\nflush_dcache_page(page);\r\nkunmap(page);\r\nunlock_page(page);\r\nif (prev_cur_page != xpage)\r\nput_page(page);\r\npages[prev_cur_page] = NULL;\r\n}\r\n}\r\n}\r\n}\r\nfor (i = 0; i < nr_bhs; i++)\r\nbrelse(bhs[i]);\r\nif (nr_cbs)\r\ngoto do_next_cb;\r\nkfree(bhs);\r\nfor (cur_page = 0; cur_page < max_page; cur_page++) {\r\npage = pages[cur_page];\r\nif (page) {\r\nntfs_error(vol->sb, "Still have pages left! "\r\n"Terminating them with extreme "\r\n"prejudice. Inode 0x%lx, page index "\r\n"0x%lx.", ni->mft_no, page->index);\r\nflush_dcache_page(page);\r\nkunmap(page);\r\nunlock_page(page);\r\nif (cur_page != xpage)\r\nput_page(page);\r\npages[cur_page] = NULL;\r\n}\r\n}\r\nkfree(pages);\r\nif (likely(xpage_done))\r\nreturn 0;\r\nntfs_debug("Failed. Returning error code %s.", err == -EOVERFLOW ?\r\n"EOVERFLOW" : (!err ? "EIO" : "unknown error"));\r\nreturn err < 0 ? err : -EIO;\r\nread_err:\r\nntfs_error(vol->sb, "IO error while reading compressed data.");\r\nfor (i = 0; i < nr_bhs; i++)\r\nbrelse(bhs[i]);\r\ngoto err_out;\r\nmap_rl_err:\r\nntfs_error(vol->sb, "ntfs_map_runlist() failed. Cannot read "\r\n"compression block.");\r\ngoto err_out;\r\nrl_err:\r\nup_read(&ni->runlist.lock);\r\nntfs_error(vol->sb, "ntfs_rl_vcn_to_lcn() failed. Cannot read "\r\n"compression block.");\r\ngoto err_out;\r\ngetblk_err:\r\nup_read(&ni->runlist.lock);\r\nntfs_error(vol->sb, "getblk() failed. Cannot read compression block.");\r\nerr_out:\r\nkfree(bhs);\r\nfor (i = cur_page; i < max_page; i++) {\r\npage = pages[i];\r\nif (page) {\r\nflush_dcache_page(page);\r\nkunmap(page);\r\nunlock_page(page);\r\nif (i != xpage)\r\nput_page(page);\r\n}\r\n}\r\nkfree(pages);\r\nreturn -EIO;\r\n}
