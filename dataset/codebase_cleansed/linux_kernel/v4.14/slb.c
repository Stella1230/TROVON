static inline unsigned long mk_esid_data(unsigned long ea, int ssize,\r\nenum slb_index index)\r\n{\r\nreturn (ea & slb_esid_mask(ssize)) | SLB_ESID_V | index;\r\n}\r\nstatic inline unsigned long mk_vsid_data(unsigned long ea, int ssize,\r\nunsigned long flags)\r\n{\r\nreturn (get_kernel_vsid(ea, ssize) << slb_vsid_shift(ssize)) | flags |\r\n((unsigned long) ssize << SLB_VSID_SSIZE_SHIFT);\r\n}\r\nstatic inline void slb_shadow_update(unsigned long ea, int ssize,\r\nunsigned long flags,\r\nenum slb_index index)\r\n{\r\nstruct slb_shadow *p = get_slb_shadow();\r\np->save_area[index].esid = 0;\r\np->save_area[index].vsid = cpu_to_be64(mk_vsid_data(ea, ssize, flags));\r\np->save_area[index].esid = cpu_to_be64(mk_esid_data(ea, ssize, index));\r\n}\r\nstatic inline void slb_shadow_clear(enum slb_index index)\r\n{\r\nget_slb_shadow()->save_area[index].esid = 0;\r\n}\r\nstatic inline void create_shadowed_slbe(unsigned long ea, int ssize,\r\nunsigned long flags,\r\nenum slb_index index)\r\n{\r\nslb_shadow_update(ea, ssize, flags, index);\r\nasm volatile("slbmte %0,%1" :\r\n: "r" (mk_vsid_data(ea, ssize, flags)),\r\n"r" (mk_esid_data(ea, ssize, index))\r\n: "memory" );\r\n}\r\nstatic void __slb_flush_and_rebolt(void)\r\n{\r\nunsigned long linear_llp, vmalloc_llp, lflags, vflags;\r\nunsigned long ksp_esid_data, ksp_vsid_data;\r\nlinear_llp = mmu_psize_defs[mmu_linear_psize].sllp;\r\nvmalloc_llp = mmu_psize_defs[mmu_vmalloc_psize].sllp;\r\nlflags = SLB_VSID_KERNEL | linear_llp;\r\nvflags = SLB_VSID_KERNEL | vmalloc_llp;\r\nksp_esid_data = mk_esid_data(get_paca()->kstack, mmu_kernel_ssize, KSTACK_INDEX);\r\nif ((ksp_esid_data & ~0xfffffffUL) <= PAGE_OFFSET) {\r\nksp_esid_data &= ~SLB_ESID_V;\r\nksp_vsid_data = 0;\r\nslb_shadow_clear(KSTACK_INDEX);\r\n} else {\r\nslb_shadow_update(get_paca()->kstack, mmu_kernel_ssize, lflags, KSTACK_INDEX);\r\nksp_vsid_data =\r\nbe64_to_cpu(get_slb_shadow()->save_area[KSTACK_INDEX].vsid);\r\n}\r\nasm volatile("isync\n"\r\n"slbia\n"\r\n"slbmte %0,%1\n"\r\n"slbmte %2,%3\n"\r\n"isync"\r\n:: "r"(mk_vsid_data(VMALLOC_START, mmu_kernel_ssize, vflags)),\r\n"r"(mk_esid_data(VMALLOC_START, mmu_kernel_ssize, VMALLOC_INDEX)),\r\n"r"(ksp_vsid_data),\r\n"r"(ksp_esid_data)\r\n: "memory");\r\n}\r\nvoid slb_flush_and_rebolt(void)\r\n{\r\nWARN_ON(!irqs_disabled());\r\nhard_irq_disable();\r\n__slb_flush_and_rebolt();\r\nget_paca()->slb_cache_ptr = 0;\r\n}\r\nvoid slb_vmalloc_update(void)\r\n{\r\nunsigned long vflags;\r\nvflags = SLB_VSID_KERNEL | mmu_psize_defs[mmu_vmalloc_psize].sllp;\r\nslb_shadow_update(VMALLOC_START, mmu_kernel_ssize, vflags, VMALLOC_INDEX);\r\nslb_flush_and_rebolt();\r\n}\r\nstatic inline int esids_match(unsigned long addr1, unsigned long addr2)\r\n{\r\nint esid_1t_count;\r\nif (!mmu_has_feature(MMU_FTR_1T_SEGMENT))\r\nreturn (GET_ESID(addr1) == GET_ESID(addr2));\r\nesid_1t_count = (((addr1 >> SID_SHIFT_1T) != 0) +\r\n((addr2 >> SID_SHIFT_1T) != 0));\r\nif (esid_1t_count == 0)\r\nreturn (GET_ESID(addr1) == GET_ESID(addr2));\r\nif (esid_1t_count == 1)\r\nreturn 0;\r\nreturn (GET_ESID_1T(addr1) == GET_ESID_1T(addr2));\r\n}\r\nvoid switch_slb(struct task_struct *tsk, struct mm_struct *mm)\r\n{\r\nunsigned long offset;\r\nunsigned long slbie_data = 0;\r\nunsigned long pc = KSTK_EIP(tsk);\r\nunsigned long stack = KSTK_ESP(tsk);\r\nunsigned long exec_base;\r\nhard_irq_disable();\r\noffset = get_paca()->slb_cache_ptr;\r\nif (!mmu_has_feature(MMU_FTR_NO_SLBIE_B) &&\r\noffset <= SLB_CACHE_ENTRIES) {\r\nint i;\r\nasm volatile("isync" : : : "memory");\r\nfor (i = 0; i < offset; i++) {\r\nslbie_data = (unsigned long)get_paca()->slb_cache[i]\r\n<< SID_SHIFT;\r\nslbie_data |= user_segment_size(slbie_data)\r\n<< SLBIE_SSIZE_SHIFT;\r\nslbie_data |= SLBIE_C;\r\nasm volatile("slbie %0" : : "r" (slbie_data));\r\n}\r\nasm volatile("isync" : : : "memory");\r\n} else {\r\n__slb_flush_and_rebolt();\r\n}\r\nif (offset == 1 || offset > SLB_CACHE_ENTRIES)\r\nasm volatile("slbie %0" : : "r" (slbie_data));\r\nget_paca()->slb_cache_ptr = 0;\r\ncopy_mm_to_paca(mm);\r\nexec_base = 0x10000000;\r\nif (is_kernel_addr(pc) || is_kernel_addr(stack) ||\r\nis_kernel_addr(exec_base))\r\nreturn;\r\nslb_allocate(pc);\r\nif (!esids_match(pc, stack))\r\nslb_allocate(stack);\r\nif (!esids_match(pc, exec_base) &&\r\n!esids_match(stack, exec_base))\r\nslb_allocate(exec_base);\r\n}\r\nstatic inline void patch_slb_encoding(unsigned int *insn_addr,\r\nunsigned int immed)\r\n{\r\nunsigned int insn = (*insn_addr & 0xffff0000) | immed;\r\npatch_instruction(insn_addr, insn);\r\n}\r\nvoid slb_set_size(u16 size)\r\n{\r\nif (mmu_slb_size == size)\r\nreturn;\r\nmmu_slb_size = size;\r\npatch_slb_encoding(slb_compare_rr_to_size, mmu_slb_size);\r\n}\r\nvoid slb_initialize(void)\r\n{\r\nunsigned long linear_llp, vmalloc_llp, io_llp;\r\nunsigned long lflags, vflags;\r\nstatic int slb_encoding_inited;\r\n#ifdef CONFIG_SPARSEMEM_VMEMMAP\r\nunsigned long vmemmap_llp;\r\n#endif\r\nlinear_llp = mmu_psize_defs[mmu_linear_psize].sllp;\r\nio_llp = mmu_psize_defs[mmu_io_psize].sllp;\r\nvmalloc_llp = mmu_psize_defs[mmu_vmalloc_psize].sllp;\r\nget_paca()->vmalloc_sllp = SLB_VSID_KERNEL | vmalloc_llp;\r\n#ifdef CONFIG_SPARSEMEM_VMEMMAP\r\nvmemmap_llp = mmu_psize_defs[mmu_vmemmap_psize].sllp;\r\n#endif\r\nif (!slb_encoding_inited) {\r\nslb_encoding_inited = 1;\r\npatch_slb_encoding(slb_miss_kernel_load_linear,\r\nSLB_VSID_KERNEL | linear_llp);\r\npatch_slb_encoding(slb_miss_kernel_load_io,\r\nSLB_VSID_KERNEL | io_llp);\r\npatch_slb_encoding(slb_compare_rr_to_size,\r\nmmu_slb_size);\r\npr_devel("SLB: linear LLP = %04lx\n", linear_llp);\r\npr_devel("SLB: io LLP = %04lx\n", io_llp);\r\n#ifdef CONFIG_SPARSEMEM_VMEMMAP\r\npatch_slb_encoding(slb_miss_kernel_load_vmemmap,\r\nSLB_VSID_KERNEL | vmemmap_llp);\r\npr_devel("SLB: vmemmap LLP = %04lx\n", vmemmap_llp);\r\n#endif\r\n}\r\nget_paca()->stab_rr = SLB_NUM_BOLTED;\r\nlflags = SLB_VSID_KERNEL | linear_llp;\r\nvflags = SLB_VSID_KERNEL | vmalloc_llp;\r\nasm volatile("isync":::"memory");\r\nasm volatile("slbmte %0,%0"::"r" (0) : "memory");\r\nasm volatile("isync; slbia; isync":::"memory");\r\ncreate_shadowed_slbe(PAGE_OFFSET, mmu_kernel_ssize, lflags, LINEAR_INDEX);\r\ncreate_shadowed_slbe(VMALLOC_START, mmu_kernel_ssize, vflags, VMALLOC_INDEX);\r\nslb_shadow_clear(KSTACK_INDEX);\r\nif (raw_smp_processor_id() != boot_cpuid &&\r\n(get_paca()->kstack & slb_esid_mask(mmu_kernel_ssize)) > PAGE_OFFSET)\r\ncreate_shadowed_slbe(get_paca()->kstack,\r\nmmu_kernel_ssize, lflags, KSTACK_INDEX);\r\nasm volatile("isync":::"memory");\r\n}
