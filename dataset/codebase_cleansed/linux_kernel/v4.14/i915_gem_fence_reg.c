static void i965_write_fence_reg(struct drm_i915_fence_reg *fence,\r\nstruct i915_vma *vma)\r\n{\r\ni915_reg_t fence_reg_lo, fence_reg_hi;\r\nint fence_pitch_shift;\r\nu64 val;\r\nif (INTEL_INFO(fence->i915)->gen >= 6) {\r\nfence_reg_lo = FENCE_REG_GEN6_LO(fence->id);\r\nfence_reg_hi = FENCE_REG_GEN6_HI(fence->id);\r\nfence_pitch_shift = GEN6_FENCE_PITCH_SHIFT;\r\n} else {\r\nfence_reg_lo = FENCE_REG_965_LO(fence->id);\r\nfence_reg_hi = FENCE_REG_965_HI(fence->id);\r\nfence_pitch_shift = I965_FENCE_PITCH_SHIFT;\r\n}\r\nval = 0;\r\nif (vma) {\r\nunsigned int stride = i915_gem_object_get_stride(vma->obj);\r\nGEM_BUG_ON(!i915_vma_is_map_and_fenceable(vma));\r\nGEM_BUG_ON(!IS_ALIGNED(vma->node.start, I965_FENCE_PAGE));\r\nGEM_BUG_ON(!IS_ALIGNED(vma->fence_size, I965_FENCE_PAGE));\r\nGEM_BUG_ON(!IS_ALIGNED(stride, 128));\r\nval = (vma->node.start + vma->fence_size - I965_FENCE_PAGE) << 32;\r\nval |= vma->node.start;\r\nval |= (u64)((stride / 128) - 1) << fence_pitch_shift;\r\nif (i915_gem_object_get_tiling(vma->obj) == I915_TILING_Y)\r\nval |= BIT(I965_FENCE_TILING_Y_SHIFT);\r\nval |= I965_FENCE_REG_VALID;\r\n}\r\nif (!pipelined) {\r\nstruct drm_i915_private *dev_priv = fence->i915;\r\nI915_WRITE(fence_reg_lo, 0);\r\nPOSTING_READ(fence_reg_lo);\r\nI915_WRITE(fence_reg_hi, upper_32_bits(val));\r\nI915_WRITE(fence_reg_lo, lower_32_bits(val));\r\nPOSTING_READ(fence_reg_lo);\r\n}\r\n}\r\nstatic void i915_write_fence_reg(struct drm_i915_fence_reg *fence,\r\nstruct i915_vma *vma)\r\n{\r\nu32 val;\r\nval = 0;\r\nif (vma) {\r\nunsigned int tiling = i915_gem_object_get_tiling(vma->obj);\r\nbool is_y_tiled = tiling == I915_TILING_Y;\r\nunsigned int stride = i915_gem_object_get_stride(vma->obj);\r\nGEM_BUG_ON(!i915_vma_is_map_and_fenceable(vma));\r\nGEM_BUG_ON(vma->node.start & ~I915_FENCE_START_MASK);\r\nGEM_BUG_ON(!is_power_of_2(vma->fence_size));\r\nGEM_BUG_ON(!IS_ALIGNED(vma->node.start, vma->fence_size));\r\nif (is_y_tiled && HAS_128_BYTE_Y_TILING(fence->i915))\r\nstride /= 128;\r\nelse\r\nstride /= 512;\r\nGEM_BUG_ON(!is_power_of_2(stride));\r\nval = vma->node.start;\r\nif (is_y_tiled)\r\nval |= BIT(I830_FENCE_TILING_Y_SHIFT);\r\nval |= I915_FENCE_SIZE_BITS(vma->fence_size);\r\nval |= ilog2(stride) << I830_FENCE_PITCH_SHIFT;\r\nval |= I830_FENCE_REG_VALID;\r\n}\r\nif (!pipelined) {\r\nstruct drm_i915_private *dev_priv = fence->i915;\r\ni915_reg_t reg = FENCE_REG(fence->id);\r\nI915_WRITE(reg, val);\r\nPOSTING_READ(reg);\r\n}\r\n}\r\nstatic void i830_write_fence_reg(struct drm_i915_fence_reg *fence,\r\nstruct i915_vma *vma)\r\n{\r\nu32 val;\r\nval = 0;\r\nif (vma) {\r\nunsigned int stride = i915_gem_object_get_stride(vma->obj);\r\nGEM_BUG_ON(!i915_vma_is_map_and_fenceable(vma));\r\nGEM_BUG_ON(vma->node.start & ~I830_FENCE_START_MASK);\r\nGEM_BUG_ON(!is_power_of_2(vma->fence_size));\r\nGEM_BUG_ON(!is_power_of_2(stride / 128));\r\nGEM_BUG_ON(!IS_ALIGNED(vma->node.start, vma->fence_size));\r\nval = vma->node.start;\r\nif (i915_gem_object_get_tiling(vma->obj) == I915_TILING_Y)\r\nval |= BIT(I830_FENCE_TILING_Y_SHIFT);\r\nval |= I830_FENCE_SIZE_BITS(vma->fence_size);\r\nval |= ilog2(stride / 128) << I830_FENCE_PITCH_SHIFT;\r\nval |= I830_FENCE_REG_VALID;\r\n}\r\nif (!pipelined) {\r\nstruct drm_i915_private *dev_priv = fence->i915;\r\ni915_reg_t reg = FENCE_REG(fence->id);\r\nI915_WRITE(reg, val);\r\nPOSTING_READ(reg);\r\n}\r\n}\r\nstatic void fence_write(struct drm_i915_fence_reg *fence,\r\nstruct i915_vma *vma)\r\n{\r\nif (IS_GEN2(fence->i915))\r\ni830_write_fence_reg(fence, vma);\r\nelse if (IS_GEN3(fence->i915))\r\ni915_write_fence_reg(fence, vma);\r\nelse\r\ni965_write_fence_reg(fence, vma);\r\nfence->dirty = false;\r\n}\r\nstatic int fence_update(struct drm_i915_fence_reg *fence,\r\nstruct i915_vma *vma)\r\n{\r\nint ret;\r\nif (vma) {\r\nif (!i915_vma_is_map_and_fenceable(vma))\r\nreturn -EINVAL;\r\nif (WARN(!i915_gem_object_get_stride(vma->obj) ||\r\n!i915_gem_object_get_tiling(vma->obj),\r\n"bogus fence setup with stride: 0x%x, tiling mode: %i\n",\r\ni915_gem_object_get_stride(vma->obj),\r\ni915_gem_object_get_tiling(vma->obj)))\r\nreturn -EINVAL;\r\nret = i915_gem_active_retire(&vma->last_fence,\r\n&vma->obj->base.dev->struct_mutex);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (fence->vma) {\r\nret = i915_gem_active_retire(&fence->vma->last_fence,\r\n&fence->vma->obj->base.dev->struct_mutex);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (fence->vma && fence->vma != vma) {\r\ni915_gem_release_mmap(fence->vma->obj);\r\nfence->vma->fence = NULL;\r\nfence->vma = NULL;\r\nlist_move(&fence->link, &fence->i915->mm.fence_list);\r\n}\r\nif (intel_runtime_pm_get_if_in_use(fence->i915)) {\r\nfence_write(fence, vma);\r\nintel_runtime_pm_put(fence->i915);\r\n}\r\nif (vma) {\r\nif (fence->vma != vma) {\r\nvma->fence = fence;\r\nfence->vma = vma;\r\n}\r\nlist_move_tail(&fence->link, &fence->i915->mm.fence_list);\r\n}\r\nreturn 0;\r\n}\r\nint\r\ni915_vma_put_fence(struct i915_vma *vma)\r\n{\r\nstruct drm_i915_fence_reg *fence = vma->fence;\r\nif (!fence)\r\nreturn 0;\r\nif (fence->pin_count)\r\nreturn -EBUSY;\r\nreturn fence_update(fence, NULL);\r\n}\r\nstatic struct drm_i915_fence_reg *fence_find(struct drm_i915_private *dev_priv)\r\n{\r\nstruct drm_i915_fence_reg *fence;\r\nlist_for_each_entry(fence, &dev_priv->mm.fence_list, link) {\r\nif (fence->pin_count)\r\ncontinue;\r\nreturn fence;\r\n}\r\nif (intel_has_pending_fb_unpin(dev_priv))\r\nreturn ERR_PTR(-EAGAIN);\r\nreturn ERR_PTR(-EDEADLK);\r\n}\r\nint\r\ni915_vma_get_fence(struct i915_vma *vma)\r\n{\r\nstruct drm_i915_fence_reg *fence;\r\nstruct i915_vma *set = i915_gem_object_is_tiled(vma->obj) ? vma : NULL;\r\nassert_rpm_wakelock_held(vma->vm->i915);\r\nif (vma->fence) {\r\nfence = vma->fence;\r\nif (!fence->dirty) {\r\nlist_move_tail(&fence->link,\r\n&fence->i915->mm.fence_list);\r\nreturn 0;\r\n}\r\n} else if (set) {\r\nfence = fence_find(vma->vm->i915);\r\nif (IS_ERR(fence))\r\nreturn PTR_ERR(fence);\r\n} else\r\nreturn 0;\r\nreturn fence_update(fence, set);\r\n}\r\nvoid i915_gem_revoke_fences(struct drm_i915_private *dev_priv)\r\n{\r\nint i;\r\nlockdep_assert_held(&dev_priv->drm.struct_mutex);\r\nfor (i = 0; i < dev_priv->num_fence_regs; i++) {\r\nstruct drm_i915_fence_reg *fence = &dev_priv->fence_regs[i];\r\nif (fence->vma)\r\ni915_gem_release_mmap(fence->vma->obj);\r\n}\r\n}\r\nvoid i915_gem_restore_fences(struct drm_i915_private *dev_priv)\r\n{\r\nint i;\r\nfor (i = 0; i < dev_priv->num_fence_regs; i++) {\r\nstruct drm_i915_fence_reg *reg = &dev_priv->fence_regs[i];\r\nstruct i915_vma *vma = reg->vma;\r\nif (vma && !i915_gem_object_is_tiled(vma->obj)) {\r\nGEM_BUG_ON(!reg->dirty);\r\nGEM_BUG_ON(!list_empty(&vma->obj->userfault_link));\r\nlist_move(&reg->link, &dev_priv->mm.fence_list);\r\nvma->fence = NULL;\r\nvma = NULL;\r\n}\r\nfence_write(reg, vma);\r\nreg->vma = vma;\r\n}\r\n}\r\nvoid\r\ni915_gem_detect_bit_6_swizzle(struct drm_i915_private *dev_priv)\r\n{\r\nuint32_t swizzle_x = I915_BIT_6_SWIZZLE_UNKNOWN;\r\nuint32_t swizzle_y = I915_BIT_6_SWIZZLE_UNKNOWN;\r\nif (INTEL_GEN(dev_priv) >= 8 || IS_VALLEYVIEW(dev_priv)) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_NONE;\r\nswizzle_y = I915_BIT_6_SWIZZLE_NONE;\r\n} else if (INTEL_GEN(dev_priv) >= 6) {\r\nif (dev_priv->preserve_bios_swizzle) {\r\nif (I915_READ(DISP_ARB_CTL) &\r\nDISP_TILE_SURFACE_SWIZZLING) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_9_10;\r\nswizzle_y = I915_BIT_6_SWIZZLE_9;\r\n} else {\r\nswizzle_x = I915_BIT_6_SWIZZLE_NONE;\r\nswizzle_y = I915_BIT_6_SWIZZLE_NONE;\r\n}\r\n} else {\r\nuint32_t dimm_c0, dimm_c1;\r\ndimm_c0 = I915_READ(MAD_DIMM_C0);\r\ndimm_c1 = I915_READ(MAD_DIMM_C1);\r\ndimm_c0 &= MAD_DIMM_A_SIZE_MASK | MAD_DIMM_B_SIZE_MASK;\r\ndimm_c1 &= MAD_DIMM_A_SIZE_MASK | MAD_DIMM_B_SIZE_MASK;\r\nif (dimm_c0 == dimm_c1) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_9_10;\r\nswizzle_y = I915_BIT_6_SWIZZLE_9;\r\n} else {\r\nswizzle_x = I915_BIT_6_SWIZZLE_NONE;\r\nswizzle_y = I915_BIT_6_SWIZZLE_NONE;\r\n}\r\n}\r\n} else if (IS_GEN5(dev_priv)) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_9_10;\r\nswizzle_y = I915_BIT_6_SWIZZLE_9;\r\n} else if (IS_GEN2(dev_priv)) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_NONE;\r\nswizzle_y = I915_BIT_6_SWIZZLE_NONE;\r\n} else if (IS_MOBILE(dev_priv) ||\r\nIS_I915G(dev_priv) || IS_I945G(dev_priv)) {\r\nuint32_t dcc;\r\ndcc = I915_READ(DCC);\r\nswitch (dcc & DCC_ADDRESSING_MODE_MASK) {\r\ncase DCC_ADDRESSING_MODE_SINGLE_CHANNEL:\r\ncase DCC_ADDRESSING_MODE_DUAL_CHANNEL_ASYMMETRIC:\r\nswizzle_x = I915_BIT_6_SWIZZLE_NONE;\r\nswizzle_y = I915_BIT_6_SWIZZLE_NONE;\r\nbreak;\r\ncase DCC_ADDRESSING_MODE_DUAL_CHANNEL_INTERLEAVED:\r\nif (dcc & DCC_CHANNEL_XOR_DISABLE) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_9_10;\r\nswizzle_y = I915_BIT_6_SWIZZLE_9;\r\n} else if ((dcc & DCC_CHANNEL_XOR_BIT_17) == 0) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_9_10_11;\r\nswizzle_y = I915_BIT_6_SWIZZLE_9_11;\r\n} else {\r\nswizzle_x = I915_BIT_6_SWIZZLE_9_10_17;\r\nswizzle_y = I915_BIT_6_SWIZZLE_9_17;\r\n}\r\nbreak;\r\n}\r\nif (IS_GEN4(dev_priv) &&\r\n!(I915_READ(DCC2) & DCC2_MODIFIED_ENHANCED_DISABLE)) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_UNKNOWN;\r\nswizzle_y = I915_BIT_6_SWIZZLE_UNKNOWN;\r\n}\r\nif (dcc == 0xffffffff) {\r\nDRM_ERROR("Couldn't read from MCHBAR. "\r\n"Disabling tiling.\n");\r\nswizzle_x = I915_BIT_6_SWIZZLE_UNKNOWN;\r\nswizzle_y = I915_BIT_6_SWIZZLE_UNKNOWN;\r\n}\r\n} else {\r\nif (I915_READ16(C0DRB3) == I915_READ16(C1DRB3)) {\r\nswizzle_x = I915_BIT_6_SWIZZLE_9_10;\r\nswizzle_y = I915_BIT_6_SWIZZLE_9;\r\n}\r\n}\r\nif (swizzle_x == I915_BIT_6_SWIZZLE_UNKNOWN ||\r\nswizzle_y == I915_BIT_6_SWIZZLE_UNKNOWN) {\r\ndev_priv->quirks |= QUIRK_PIN_SWIZZLED_PAGES;\r\nswizzle_x = I915_BIT_6_SWIZZLE_NONE;\r\nswizzle_y = I915_BIT_6_SWIZZLE_NONE;\r\n}\r\ndev_priv->mm.bit_6_swizzle_x = swizzle_x;\r\ndev_priv->mm.bit_6_swizzle_y = swizzle_y;\r\n}\r\nstatic void\r\ni915_gem_swizzle_page(struct page *page)\r\n{\r\nchar temp[64];\r\nchar *vaddr;\r\nint i;\r\nvaddr = kmap(page);\r\nfor (i = 0; i < PAGE_SIZE; i += 128) {\r\nmemcpy(temp, &vaddr[i], 64);\r\nmemcpy(&vaddr[i], &vaddr[i + 64], 64);\r\nmemcpy(&vaddr[i + 64], temp, 64);\r\n}\r\nkunmap(page);\r\n}\r\nvoid\r\ni915_gem_object_do_bit_17_swizzle(struct drm_i915_gem_object *obj,\r\nstruct sg_table *pages)\r\n{\r\nstruct sgt_iter sgt_iter;\r\nstruct page *page;\r\nint i;\r\nif (obj->bit_17 == NULL)\r\nreturn;\r\ni = 0;\r\nfor_each_sgt_page(page, sgt_iter, pages) {\r\nchar new_bit_17 = page_to_phys(page) >> 17;\r\nif ((new_bit_17 & 0x1) != (test_bit(i, obj->bit_17) != 0)) {\r\ni915_gem_swizzle_page(page);\r\nset_page_dirty(page);\r\n}\r\ni++;\r\n}\r\n}\r\nvoid\r\ni915_gem_object_save_bit_17_swizzle(struct drm_i915_gem_object *obj,\r\nstruct sg_table *pages)\r\n{\r\nconst unsigned int page_count = obj->base.size >> PAGE_SHIFT;\r\nstruct sgt_iter sgt_iter;\r\nstruct page *page;\r\nint i;\r\nif (obj->bit_17 == NULL) {\r\nobj->bit_17 = kcalloc(BITS_TO_LONGS(page_count),\r\nsizeof(long), GFP_KERNEL);\r\nif (obj->bit_17 == NULL) {\r\nDRM_ERROR("Failed to allocate memory for bit 17 "\r\n"record\n");\r\nreturn;\r\n}\r\n}\r\ni = 0;\r\nfor_each_sgt_page(page, sgt_iter, pages) {\r\nif (page_to_phys(page) & (1 << 17))\r\n__set_bit(i, obj->bit_17);\r\nelse\r\n__clear_bit(i, obj->bit_17);\r\ni++;\r\n}\r\n}
