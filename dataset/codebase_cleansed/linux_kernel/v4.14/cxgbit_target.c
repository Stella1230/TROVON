static struct sk_buff *\r\n__cxgbit_alloc_skb(struct cxgbit_sock *csk, u32 len, bool iso)\r\n{\r\nstruct sk_buff *skb = NULL;\r\nu8 submode = 0;\r\nint errcode;\r\nstatic const u32 hdr_len = TX_HDR_LEN + ISCSI_HDR_LEN;\r\nif (len) {\r\nskb = alloc_skb_with_frags(hdr_len, len,\r\n0, &errcode,\r\nGFP_KERNEL);\r\nif (!skb)\r\nreturn NULL;\r\nskb_reserve(skb, TX_HDR_LEN);\r\nskb_reset_transport_header(skb);\r\n__skb_put(skb, ISCSI_HDR_LEN);\r\nskb->data_len = len;\r\nskb->len += len;\r\nsubmode |= (csk->submode & CXGBIT_SUBMODE_DCRC);\r\n} else {\r\nu32 iso_len = iso ? sizeof(struct cpl_tx_data_iso) : 0;\r\nskb = alloc_skb(hdr_len + iso_len, GFP_KERNEL);\r\nif (!skb)\r\nreturn NULL;\r\nskb_reserve(skb, TX_HDR_LEN + iso_len);\r\nskb_reset_transport_header(skb);\r\n__skb_put(skb, ISCSI_HDR_LEN);\r\n}\r\nsubmode |= (csk->submode & CXGBIT_SUBMODE_HCRC);\r\ncxgbit_skcb_submode(skb) = submode;\r\ncxgbit_skcb_tx_extralen(skb) = cxgbit_digest_len[submode];\r\ncxgbit_skcb_flags(skb) |= SKCBF_TX_NEED_HDR;\r\nreturn skb;\r\n}\r\nstatic struct sk_buff *cxgbit_alloc_skb(struct cxgbit_sock *csk, u32 len)\r\n{\r\nreturn __cxgbit_alloc_skb(csk, len, false);\r\n}\r\nstatic int cxgbit_is_ofld_imm(const struct sk_buff *skb)\r\n{\r\nint length = skb->len;\r\nif (likely(cxgbit_skcb_flags(skb) & SKCBF_TX_NEED_HDR))\r\nlength += sizeof(struct fw_ofld_tx_data_wr);\r\nif (likely(cxgbit_skcb_flags(skb) & SKCBF_TX_ISO))\r\nlength += sizeof(struct cpl_tx_data_iso);\r\n#define MAX_IMM_TX_PKT_LEN 256\r\nreturn length <= MAX_IMM_TX_PKT_LEN;\r\n}\r\nstatic inline unsigned int cxgbit_sgl_len(unsigned int n)\r\n{\r\nn--;\r\nreturn (3 * n) / 2 + (n & 1) + 2;\r\n}\r\nstatic unsigned int cxgbit_calc_tx_flits_ofld(const struct sk_buff *skb)\r\n{\r\nunsigned int flits, cnt;\r\nif (cxgbit_is_ofld_imm(skb))\r\nreturn DIV_ROUND_UP(skb->len, 8);\r\nflits = skb_transport_offset(skb) / 8;\r\ncnt = skb_shinfo(skb)->nr_frags;\r\nif (skb_tail_pointer(skb) != skb_transport_header(skb))\r\ncnt++;\r\nreturn flits + cxgbit_sgl_len(cnt);\r\n}\r\nstatic void\r\ncxgbit_cpl_tx_data_iso(struct sk_buff *skb, struct cxgbit_iso_info *iso_info)\r\n{\r\nstruct cpl_tx_data_iso *cpl;\r\nunsigned int submode = cxgbit_skcb_submode(skb);\r\nunsigned int fslice = !!(iso_info->flags & CXGBIT_ISO_FSLICE);\r\nunsigned int lslice = !!(iso_info->flags & CXGBIT_ISO_LSLICE);\r\ncpl = __skb_push(skb, sizeof(*cpl));\r\ncpl->op_to_scsi = htonl(CPL_TX_DATA_ISO_OP_V(CPL_TX_DATA_ISO) |\r\nCPL_TX_DATA_ISO_FIRST_V(fslice) |\r\nCPL_TX_DATA_ISO_LAST_V(lslice) |\r\nCPL_TX_DATA_ISO_CPLHDRLEN_V(0) |\r\nCPL_TX_DATA_ISO_HDRCRC_V(submode & 1) |\r\nCPL_TX_DATA_ISO_PLDCRC_V(((submode >> 1) & 1)) |\r\nCPL_TX_DATA_ISO_IMMEDIATE_V(0) |\r\nCPL_TX_DATA_ISO_SCSI_V(2));\r\ncpl->ahs_len = 0;\r\ncpl->mpdu = htons(DIV_ROUND_UP(iso_info->mpdu, 4));\r\ncpl->burst_size = htonl(DIV_ROUND_UP(iso_info->burst_len, 4));\r\ncpl->len = htonl(iso_info->len);\r\ncpl->reserved2_seglen_offset = htonl(0);\r\ncpl->datasn_offset = htonl(0);\r\ncpl->buffer_offset = htonl(0);\r\ncpl->reserved3 = 0;\r\n__skb_pull(skb, sizeof(*cpl));\r\n}\r\nstatic void\r\ncxgbit_tx_data_wr(struct cxgbit_sock *csk, struct sk_buff *skb, u32 dlen,\r\nu32 len, u32 credits, u32 compl)\r\n{\r\nstruct fw_ofld_tx_data_wr *req;\r\nconst struct cxgb4_lld_info *lldi = &csk->com.cdev->lldi;\r\nu32 submode = cxgbit_skcb_submode(skb);\r\nu32 wr_ulp_mode = 0;\r\nu32 hdr_size = sizeof(*req);\r\nu32 opcode = FW_OFLD_TX_DATA_WR;\r\nu32 immlen = 0;\r\nu32 force = is_t5(lldi->adapter_type) ? TX_FORCE_V(!submode) :\r\nT6_TX_FORCE_F;\r\nif (cxgbit_skcb_flags(skb) & SKCBF_TX_ISO) {\r\nopcode = FW_ISCSI_TX_DATA_WR;\r\nimmlen += sizeof(struct cpl_tx_data_iso);\r\nhdr_size += sizeof(struct cpl_tx_data_iso);\r\nsubmode |= 8;\r\n}\r\nif (cxgbit_is_ofld_imm(skb))\r\nimmlen += dlen;\r\nreq = __skb_push(skb, hdr_size);\r\nreq->op_to_immdlen = cpu_to_be32(FW_WR_OP_V(opcode) |\r\nFW_WR_COMPL_V(compl) |\r\nFW_WR_IMMDLEN_V(immlen));\r\nreq->flowid_len16 = cpu_to_be32(FW_WR_FLOWID_V(csk->tid) |\r\nFW_WR_LEN16_V(credits));\r\nreq->plen = htonl(len);\r\nwr_ulp_mode = FW_OFLD_TX_DATA_WR_ULPMODE_V(ULP_MODE_ISCSI) |\r\nFW_OFLD_TX_DATA_WR_ULPSUBMODE_V(submode);\r\nreq->tunnel_to_proxy = htonl((wr_ulp_mode) | force |\r\nFW_OFLD_TX_DATA_WR_SHOVE_V(skb_peek(&csk->txq) ? 0 : 1));\r\n}\r\nstatic void cxgbit_arp_failure_skb_discard(void *handle, struct sk_buff *skb)\r\n{\r\nkfree_skb(skb);\r\n}\r\nvoid cxgbit_push_tx_frames(struct cxgbit_sock *csk)\r\n{\r\nstruct sk_buff *skb;\r\nwhile (csk->wr_cred && ((skb = skb_peek(&csk->txq)) != NULL)) {\r\nu32 dlen = skb->len;\r\nu32 len = skb->len;\r\nu32 credits_needed;\r\nu32 compl = 0;\r\nu32 flowclen16 = 0;\r\nu32 iso_cpl_len = 0;\r\nif (cxgbit_skcb_flags(skb) & SKCBF_TX_ISO)\r\niso_cpl_len = sizeof(struct cpl_tx_data_iso);\r\nif (cxgbit_is_ofld_imm(skb))\r\ncredits_needed = DIV_ROUND_UP(dlen + iso_cpl_len, 16);\r\nelse\r\ncredits_needed = DIV_ROUND_UP((8 *\r\ncxgbit_calc_tx_flits_ofld(skb)) +\r\niso_cpl_len, 16);\r\nif (likely(cxgbit_skcb_flags(skb) & SKCBF_TX_NEED_HDR))\r\ncredits_needed += DIV_ROUND_UP(\r\nsizeof(struct fw_ofld_tx_data_wr), 16);\r\nif (!test_and_set_bit(CSK_TX_DATA_SENT, &csk->com.flags)) {\r\nflowclen16 = cxgbit_send_tx_flowc_wr(csk);\r\ncsk->wr_cred -= flowclen16;\r\ncsk->wr_una_cred += flowclen16;\r\n}\r\nif (csk->wr_cred < credits_needed) {\r\npr_debug("csk 0x%p, skb %u/%u, wr %d < %u.\n",\r\ncsk, skb->len, skb->data_len,\r\ncredits_needed, csk->wr_cred);\r\nbreak;\r\n}\r\n__skb_unlink(skb, &csk->txq);\r\nset_wr_txq(skb, CPL_PRIORITY_DATA, csk->txq_idx);\r\nskb->csum = (__force __wsum)(credits_needed + flowclen16);\r\ncsk->wr_cred -= credits_needed;\r\ncsk->wr_una_cred += credits_needed;\r\npr_debug("csk 0x%p, skb %u/%u, wr %d, left %u, unack %u.\n",\r\ncsk, skb->len, skb->data_len, credits_needed,\r\ncsk->wr_cred, csk->wr_una_cred);\r\nif (likely(cxgbit_skcb_flags(skb) & SKCBF_TX_NEED_HDR)) {\r\nlen += cxgbit_skcb_tx_extralen(skb);\r\nif ((csk->wr_una_cred >= (csk->wr_max_cred / 2)) ||\r\n(!before(csk->write_seq,\r\ncsk->snd_una + csk->snd_win))) {\r\ncompl = 1;\r\ncsk->wr_una_cred = 0;\r\n}\r\ncxgbit_tx_data_wr(csk, skb, dlen, len, credits_needed,\r\ncompl);\r\ncsk->snd_nxt += len;\r\n} else if ((cxgbit_skcb_flags(skb) & SKCBF_TX_FLAG_COMPL) ||\r\n(csk->wr_una_cred >= (csk->wr_max_cred / 2))) {\r\nstruct cpl_close_con_req *req =\r\n(struct cpl_close_con_req *)skb->data;\r\nreq->wr.wr_hi |= htonl(FW_WR_COMPL_F);\r\ncsk->wr_una_cred = 0;\r\n}\r\ncxgbit_sock_enqueue_wr(csk, skb);\r\nt4_set_arp_err_handler(skb, csk,\r\ncxgbit_arp_failure_skb_discard);\r\npr_debug("csk 0x%p,%u, skb 0x%p, %u.\n",\r\ncsk, csk->tid, skb, len);\r\ncxgbit_l2t_send(csk->com.cdev, skb, csk->l2t);\r\n}\r\n}\r\nstatic bool cxgbit_lock_sock(struct cxgbit_sock *csk)\r\n{\r\nspin_lock_bh(&csk->lock);\r\nif (before(csk->write_seq, csk->snd_una + csk->snd_win))\r\ncsk->lock_owner = true;\r\nspin_unlock_bh(&csk->lock);\r\nreturn csk->lock_owner;\r\n}\r\nstatic void cxgbit_unlock_sock(struct cxgbit_sock *csk)\r\n{\r\nstruct sk_buff_head backlogq;\r\nstruct sk_buff *skb;\r\nvoid (*fn)(struct cxgbit_sock *, struct sk_buff *);\r\nskb_queue_head_init(&backlogq);\r\nspin_lock_bh(&csk->lock);\r\nwhile (skb_queue_len(&csk->backlogq)) {\r\nskb_queue_splice_init(&csk->backlogq, &backlogq);\r\nspin_unlock_bh(&csk->lock);\r\nwhile ((skb = __skb_dequeue(&backlogq))) {\r\nfn = cxgbit_skcb_rx_backlog_fn(skb);\r\nfn(csk, skb);\r\n}\r\nspin_lock_bh(&csk->lock);\r\n}\r\ncsk->lock_owner = false;\r\nspin_unlock_bh(&csk->lock);\r\n}\r\nstatic int cxgbit_queue_skb(struct cxgbit_sock *csk, struct sk_buff *skb)\r\n{\r\nint ret = 0;\r\nwait_event_interruptible(csk->ack_waitq, cxgbit_lock_sock(csk));\r\nif (unlikely((csk->com.state != CSK_STATE_ESTABLISHED) ||\r\nsignal_pending(current))) {\r\n__kfree_skb(skb);\r\n__skb_queue_purge(&csk->ppodq);\r\nret = -1;\r\nspin_lock_bh(&csk->lock);\r\nif (csk->lock_owner) {\r\nspin_unlock_bh(&csk->lock);\r\ngoto unlock;\r\n}\r\nspin_unlock_bh(&csk->lock);\r\nreturn ret;\r\n}\r\ncsk->write_seq += skb->len +\r\ncxgbit_skcb_tx_extralen(skb);\r\nskb_queue_splice_tail_init(&csk->ppodq, &csk->txq);\r\n__skb_queue_tail(&csk->txq, skb);\r\ncxgbit_push_tx_frames(csk);\r\nunlock:\r\ncxgbit_unlock_sock(csk);\r\nreturn ret;\r\n}\r\nstatic int\r\ncxgbit_map_skb(struct iscsi_cmd *cmd, struct sk_buff *skb, u32 data_offset,\r\nu32 data_length)\r\n{\r\nu32 i = 0, nr_frags = MAX_SKB_FRAGS;\r\nu32 padding = ((-data_length) & 3);\r\nstruct scatterlist *sg;\r\nstruct page *page;\r\nunsigned int page_off;\r\nif (padding)\r\nnr_frags--;\r\nsg = &cmd->se_cmd.t_data_sg[data_offset / PAGE_SIZE];\r\npage_off = (data_offset % PAGE_SIZE);\r\nwhile (data_length && (i < nr_frags)) {\r\nu32 cur_len = min_t(u32, data_length, sg->length - page_off);\r\npage = sg_page(sg);\r\nget_page(page);\r\nskb_fill_page_desc(skb, i, page, sg->offset + page_off,\r\ncur_len);\r\nskb->data_len += cur_len;\r\nskb->len += cur_len;\r\nskb->truesize += cur_len;\r\ndata_length -= cur_len;\r\npage_off = 0;\r\nsg = sg_next(sg);\r\ni++;\r\n}\r\nif (data_length)\r\nreturn -1;\r\nif (padding) {\r\npage = alloc_page(GFP_KERNEL | __GFP_ZERO);\r\nif (!page)\r\nreturn -1;\r\nskb_fill_page_desc(skb, i, page, 0, padding);\r\nskb->data_len += padding;\r\nskb->len += padding;\r\nskb->truesize += padding;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\ncxgbit_tx_datain_iso(struct cxgbit_sock *csk, struct iscsi_cmd *cmd,\r\nstruct iscsi_datain_req *dr)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct sk_buff *skb;\r\nstruct iscsi_datain datain;\r\nstruct cxgbit_iso_info iso_info;\r\nu32 data_length = cmd->se_cmd.data_length;\r\nu32 mrdsl = conn->conn_ops->MaxRecvDataSegmentLength;\r\nu32 num_pdu, plen, tx_data = 0;\r\nbool task_sense = !!(cmd->se_cmd.se_cmd_flags &\r\nSCF_TRANSPORT_TASK_SENSE);\r\nbool set_statsn = false;\r\nint ret = -1;\r\nwhile (data_length) {\r\nnum_pdu = (data_length + mrdsl - 1) / mrdsl;\r\nif (num_pdu > csk->max_iso_npdu)\r\nnum_pdu = csk->max_iso_npdu;\r\nplen = num_pdu * mrdsl;\r\nif (plen > data_length)\r\nplen = data_length;\r\nskb = __cxgbit_alloc_skb(csk, 0, true);\r\nif (unlikely(!skb))\r\nreturn -ENOMEM;\r\nmemset(skb->data, 0, ISCSI_HDR_LEN);\r\ncxgbit_skcb_flags(skb) |= SKCBF_TX_ISO;\r\ncxgbit_skcb_submode(skb) |= (csk->submode &\r\nCXGBIT_SUBMODE_DCRC);\r\ncxgbit_skcb_tx_extralen(skb) = (num_pdu *\r\ncxgbit_digest_len[cxgbit_skcb_submode(skb)]) +\r\n((num_pdu - 1) * ISCSI_HDR_LEN);\r\nmemset(&datain, 0, sizeof(struct iscsi_datain));\r\nmemset(&iso_info, 0, sizeof(iso_info));\r\nif (!tx_data)\r\niso_info.flags |= CXGBIT_ISO_FSLICE;\r\nif (!(data_length - plen)) {\r\niso_info.flags |= CXGBIT_ISO_LSLICE;\r\nif (!task_sense) {\r\ndatain.flags = ISCSI_FLAG_DATA_STATUS;\r\niscsit_increment_maxcmdsn(cmd, conn->sess);\r\ncmd->stat_sn = conn->stat_sn++;\r\nset_statsn = true;\r\n}\r\n}\r\niso_info.burst_len = num_pdu * mrdsl;\r\niso_info.mpdu = mrdsl;\r\niso_info.len = ISCSI_HDR_LEN + plen;\r\ncxgbit_cpl_tx_data_iso(skb, &iso_info);\r\ndatain.offset = tx_data;\r\ndatain.data_sn = cmd->data_sn - 1;\r\niscsit_build_datain_pdu(cmd, conn, &datain,\r\n(struct iscsi_data_rsp *)skb->data,\r\nset_statsn);\r\nret = cxgbit_map_skb(cmd, skb, tx_data, plen);\r\nif (unlikely(ret)) {\r\n__kfree_skb(skb);\r\ngoto out;\r\n}\r\nret = cxgbit_queue_skb(csk, skb);\r\nif (unlikely(ret))\r\ngoto out;\r\ntx_data += plen;\r\ndata_length -= plen;\r\ncmd->read_data_done += plen;\r\ncmd->data_sn += num_pdu;\r\n}\r\ndr->dr_complete = DATAIN_COMPLETE_NORMAL;\r\nreturn 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic int\r\ncxgbit_tx_datain(struct cxgbit_sock *csk, struct iscsi_cmd *cmd,\r\nconst struct iscsi_datain *datain)\r\n{\r\nstruct sk_buff *skb;\r\nint ret = 0;\r\nskb = cxgbit_alloc_skb(csk, 0);\r\nif (unlikely(!skb))\r\nreturn -ENOMEM;\r\nmemcpy(skb->data, cmd->pdu, ISCSI_HDR_LEN);\r\nif (datain->length) {\r\ncxgbit_skcb_submode(skb) |= (csk->submode &\r\nCXGBIT_SUBMODE_DCRC);\r\ncxgbit_skcb_tx_extralen(skb) =\r\ncxgbit_digest_len[cxgbit_skcb_submode(skb)];\r\n}\r\nret = cxgbit_map_skb(cmd, skb, datain->offset, datain->length);\r\nif (ret < 0) {\r\n__kfree_skb(skb);\r\nreturn ret;\r\n}\r\nreturn cxgbit_queue_skb(csk, skb);\r\n}\r\nstatic int\r\ncxgbit_xmit_datain_pdu(struct iscsi_conn *conn, struct iscsi_cmd *cmd,\r\nstruct iscsi_datain_req *dr,\r\nconst struct iscsi_datain *datain)\r\n{\r\nstruct cxgbit_sock *csk = conn->context;\r\nu32 data_length = cmd->se_cmd.data_length;\r\nu32 padding = ((-data_length) & 3);\r\nu32 mrdsl = conn->conn_ops->MaxRecvDataSegmentLength;\r\nif ((data_length > mrdsl) && (!dr->recovery) &&\r\n(!padding) && (!datain->offset) && csk->max_iso_npdu) {\r\natomic_long_add(data_length - datain->length,\r\n&conn->sess->tx_data_octets);\r\nreturn cxgbit_tx_datain_iso(csk, cmd, dr);\r\n}\r\nreturn cxgbit_tx_datain(csk, cmd, datain);\r\n}\r\nstatic int\r\ncxgbit_xmit_nondatain_pdu(struct iscsi_conn *conn, struct iscsi_cmd *cmd,\r\nconst void *data_buf, u32 data_buf_len)\r\n{\r\nstruct cxgbit_sock *csk = conn->context;\r\nstruct sk_buff *skb;\r\nu32 padding = ((-data_buf_len) & 3);\r\nskb = cxgbit_alloc_skb(csk, data_buf_len + padding);\r\nif (unlikely(!skb))\r\nreturn -ENOMEM;\r\nmemcpy(skb->data, cmd->pdu, ISCSI_HDR_LEN);\r\nif (data_buf_len) {\r\nu32 pad_bytes = 0;\r\nskb_store_bits(skb, ISCSI_HDR_LEN, data_buf, data_buf_len);\r\nif (padding)\r\nskb_store_bits(skb, ISCSI_HDR_LEN + data_buf_len,\r\n&pad_bytes, padding);\r\n}\r\ncxgbit_skcb_tx_extralen(skb) = cxgbit_digest_len[\r\ncxgbit_skcb_submode(skb)];\r\nreturn cxgbit_queue_skb(csk, skb);\r\n}\r\nint\r\ncxgbit_xmit_pdu(struct iscsi_conn *conn, struct iscsi_cmd *cmd,\r\nstruct iscsi_datain_req *dr, const void *buf, u32 buf_len)\r\n{\r\nif (dr)\r\nreturn cxgbit_xmit_datain_pdu(conn, cmd, dr, buf);\r\nelse\r\nreturn cxgbit_xmit_nondatain_pdu(conn, cmd, buf, buf_len);\r\n}\r\nint cxgbit_validate_params(struct iscsi_conn *conn)\r\n{\r\nstruct cxgbit_sock *csk = conn->context;\r\nstruct cxgbit_device *cdev = csk->com.cdev;\r\nstruct iscsi_param *param;\r\nu32 max_xmitdsl;\r\nparam = iscsi_find_param_from_key(MAXXMITDATASEGMENTLENGTH,\r\nconn->param_list);\r\nif (!param)\r\nreturn -1;\r\nif (kstrtou32(param->value, 0, &max_xmitdsl) < 0)\r\nreturn -1;\r\nif (max_xmitdsl > cdev->mdsl) {\r\nif (iscsi_change_param_sprintf(\r\nconn, "MaxXmitDataSegmentLength=%u", cdev->mdsl))\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cxgbit_set_digest(struct cxgbit_sock *csk)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct iscsi_param *param;\r\nparam = iscsi_find_param_from_key(HEADERDIGEST, conn->param_list);\r\nif (!param) {\r\npr_err("param not found key %s\n", HEADERDIGEST);\r\nreturn -1;\r\n}\r\nif (!strcmp(param->value, CRC32C))\r\ncsk->submode |= CXGBIT_SUBMODE_HCRC;\r\nparam = iscsi_find_param_from_key(DATADIGEST, conn->param_list);\r\nif (!param) {\r\ncsk->submode = 0;\r\npr_err("param not found key %s\n", DATADIGEST);\r\nreturn -1;\r\n}\r\nif (!strcmp(param->value, CRC32C))\r\ncsk->submode |= CXGBIT_SUBMODE_DCRC;\r\nif (cxgbit_setup_conn_digest(csk)) {\r\ncsk->submode = 0;\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cxgbit_set_iso_npdu(struct cxgbit_sock *csk)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct iscsi_conn_ops *conn_ops = conn->conn_ops;\r\nstruct iscsi_param *param;\r\nu32 mrdsl, mbl;\r\nu32 max_npdu, max_iso_npdu;\r\nif (conn->login->leading_connection) {\r\nparam = iscsi_find_param_from_key(MAXBURSTLENGTH,\r\nconn->param_list);\r\nif (!param) {\r\npr_err("param not found key %s\n", MAXBURSTLENGTH);\r\nreturn -1;\r\n}\r\nif (kstrtou32(param->value, 0, &mbl) < 0)\r\nreturn -1;\r\n} else {\r\nmbl = conn->sess->sess_ops->MaxBurstLength;\r\n}\r\nmrdsl = conn_ops->MaxRecvDataSegmentLength;\r\nmax_npdu = mbl / mrdsl;\r\nmax_iso_npdu = CXGBIT_MAX_ISO_PAYLOAD /\r\n(ISCSI_HDR_LEN + mrdsl +\r\ncxgbit_digest_len[csk->submode]);\r\ncsk->max_iso_npdu = min(max_npdu, max_iso_npdu);\r\nif (csk->max_iso_npdu <= 1)\r\ncsk->max_iso_npdu = 0;\r\nreturn 0;\r\n}\r\nstatic int cxgbit_seq_pdu_inorder(struct cxgbit_sock *csk)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct iscsi_param *param;\r\nif (conn->login->leading_connection) {\r\nparam = iscsi_find_param_from_key(DATASEQUENCEINORDER,\r\nconn->param_list);\r\nif (!param) {\r\npr_err("param not found key %s\n", DATASEQUENCEINORDER);\r\nreturn -1;\r\n}\r\nif (strcmp(param->value, YES))\r\nreturn 1;\r\nparam = iscsi_find_param_from_key(DATAPDUINORDER,\r\nconn->param_list);\r\nif (!param) {\r\npr_err("param not found key %s\n", DATAPDUINORDER);\r\nreturn -1;\r\n}\r\nif (strcmp(param->value, YES))\r\nreturn 1;\r\n} else {\r\nif (!conn->sess->sess_ops->DataSequenceInOrder)\r\nreturn 1;\r\nif (!conn->sess->sess_ops->DataPDUInOrder)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cxgbit_set_params(struct iscsi_conn *conn)\r\n{\r\nstruct cxgbit_sock *csk = conn->context;\r\nstruct cxgbit_device *cdev = csk->com.cdev;\r\nstruct cxgbi_ppm *ppm = *csk->com.cdev->lldi.iscsi_ppm;\r\nstruct iscsi_conn_ops *conn_ops = conn->conn_ops;\r\nstruct iscsi_param *param;\r\nu8 erl;\r\nif (conn_ops->MaxRecvDataSegmentLength > cdev->mdsl)\r\nconn_ops->MaxRecvDataSegmentLength = cdev->mdsl;\r\nif (conn->login->leading_connection) {\r\nparam = iscsi_find_param_from_key(ERRORRECOVERYLEVEL,\r\nconn->param_list);\r\nif (!param) {\r\npr_err("param not found key %s\n", ERRORRECOVERYLEVEL);\r\nreturn -1;\r\n}\r\nif (kstrtou8(param->value, 0, &erl) < 0)\r\nreturn -1;\r\n} else {\r\nerl = conn->sess->sess_ops->ErrorRecoveryLevel;\r\n}\r\nif (!erl) {\r\nint ret;\r\nret = cxgbit_seq_pdu_inorder(csk);\r\nif (ret < 0) {\r\nreturn -1;\r\n} else if (ret > 0) {\r\nif (is_t5(cdev->lldi.adapter_type))\r\ngoto enable_ddp;\r\nelse\r\ngoto enable_digest;\r\n}\r\nif (test_bit(CDEV_ISO_ENABLE, &cdev->flags)) {\r\nif (cxgbit_set_iso_npdu(csk))\r\nreturn -1;\r\n}\r\nenable_ddp:\r\nif (test_bit(CDEV_DDP_ENABLE, &cdev->flags)) {\r\nif (cxgbit_setup_conn_pgidx(csk,\r\nppm->tformat.pgsz_idx_dflt))\r\nreturn -1;\r\nset_bit(CSK_DDP_ENABLE, &csk->com.flags);\r\n}\r\n}\r\nenable_digest:\r\nif (cxgbit_set_digest(csk))\r\nreturn -1;\r\nreturn 0;\r\n}\r\nint\r\ncxgbit_put_login_tx(struct iscsi_conn *conn, struct iscsi_login *login,\r\nu32 length)\r\n{\r\nstruct cxgbit_sock *csk = conn->context;\r\nstruct sk_buff *skb;\r\nu32 padding_buf = 0;\r\nu8 padding = ((-length) & 3);\r\nskb = cxgbit_alloc_skb(csk, length + padding);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nskb_store_bits(skb, 0, login->rsp, ISCSI_HDR_LEN);\r\nskb_store_bits(skb, ISCSI_HDR_LEN, login->rsp_buf, length);\r\nif (padding)\r\nskb_store_bits(skb, ISCSI_HDR_LEN + length,\r\n&padding_buf, padding);\r\nif (login->login_complete) {\r\nif (cxgbit_set_params(conn)) {\r\nkfree_skb(skb);\r\nreturn -1;\r\n}\r\nset_bit(CSK_LOGIN_DONE, &csk->com.flags);\r\n}\r\nif (cxgbit_queue_skb(csk, skb))\r\nreturn -1;\r\nif ((!login->login_complete) && (!login->login_failed))\r\nschedule_delayed_work(&conn->login_work, 0);\r\nreturn 0;\r\n}\r\nstatic void\r\ncxgbit_skb_copy_to_sg(struct sk_buff *skb, struct scatterlist *sg,\r\nunsigned int nents, u32 skip)\r\n{\r\nstruct skb_seq_state st;\r\nconst u8 *buf;\r\nunsigned int consumed = 0, buf_len;\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(skb);\r\nskb_prepare_seq_read(skb, pdu_cb->doffset,\r\npdu_cb->doffset + pdu_cb->dlen,\r\n&st);\r\nwhile (true) {\r\nbuf_len = skb_seq_read(consumed, &buf, &st);\r\nif (!buf_len) {\r\nskb_abort_seq_read(&st);\r\nbreak;\r\n}\r\nconsumed += sg_pcopy_from_buffer(sg, nents, (void *)buf,\r\nbuf_len, skip + consumed);\r\n}\r\n}\r\nstatic struct iscsi_cmd *cxgbit_allocate_cmd(struct cxgbit_sock *csk)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct cxgbi_ppm *ppm = cdev2ppm(csk->com.cdev);\r\nstruct cxgbit_cmd *ccmd;\r\nstruct iscsi_cmd *cmd;\r\ncmd = iscsit_allocate_cmd(conn, TASK_INTERRUPTIBLE);\r\nif (!cmd) {\r\npr_err("Unable to allocate iscsi_cmd + cxgbit_cmd\n");\r\nreturn NULL;\r\n}\r\nccmd = iscsit_priv_cmd(cmd);\r\nccmd->ttinfo.tag = ppm->tformat.no_ddp_mask;\r\nccmd->setup_ddp = true;\r\nreturn cmd;\r\n}\r\nstatic int\r\ncxgbit_handle_immediate_data(struct iscsi_cmd *cmd, struct iscsi_scsi_req *hdr,\r\nu32 length)\r\n{\r\nstruct iscsi_conn *conn = cmd->conn;\r\nstruct cxgbit_sock *csk = conn->context;\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nif (pdu_cb->flags & PDUCBF_RX_DCRC_ERR) {\r\npr_err("ImmediateData CRC32C DataDigest error\n");\r\nif (!conn->sess->sess_ops->ErrorRecoveryLevel) {\r\npr_err("Unable to recover from"\r\n" Immediate Data digest failure while"\r\n" in ERL=0.\n");\r\niscsit_reject_cmd(cmd, ISCSI_REASON_DATA_DIGEST_ERROR,\r\n(unsigned char *)hdr);\r\nreturn IMMEDIATE_DATA_CANNOT_RECOVER;\r\n}\r\niscsit_reject_cmd(cmd, ISCSI_REASON_DATA_DIGEST_ERROR,\r\n(unsigned char *)hdr);\r\nreturn IMMEDIATE_DATA_ERL1_CRC_FAILURE;\r\n}\r\nif (cmd->se_cmd.se_cmd_flags & SCF_PASSTHROUGH_SG_TO_MEM_NOALLOC) {\r\nstruct cxgbit_cmd *ccmd = iscsit_priv_cmd(cmd);\r\nstruct skb_shared_info *ssi = skb_shinfo(csk->skb);\r\nskb_frag_t *dfrag = &ssi->frags[pdu_cb->dfrag_idx];\r\nsg_init_table(&ccmd->sg, 1);\r\nsg_set_page(&ccmd->sg, dfrag->page.p, skb_frag_size(dfrag),\r\ndfrag->page_offset);\r\nget_page(dfrag->page.p);\r\ncmd->se_cmd.t_data_sg = &ccmd->sg;\r\ncmd->se_cmd.t_data_nents = 1;\r\nccmd->release = true;\r\n} else {\r\nstruct scatterlist *sg = &cmd->se_cmd.t_data_sg[0];\r\nu32 sg_nents = max(1UL, DIV_ROUND_UP(pdu_cb->dlen, PAGE_SIZE));\r\ncxgbit_skb_copy_to_sg(csk->skb, sg, sg_nents, 0);\r\n}\r\ncmd->write_data_done += pdu_cb->dlen;\r\nif (cmd->write_data_done == cmd->se_cmd.data_length) {\r\nspin_lock_bh(&cmd->istate_lock);\r\ncmd->cmd_flags |= ICF_GOT_LAST_DATAOUT;\r\ncmd->i_state = ISTATE_RECEIVED_LAST_DATAOUT;\r\nspin_unlock_bh(&cmd->istate_lock);\r\n}\r\nreturn IMMEDIATE_DATA_NORMAL_OPERATION;\r\n}\r\nstatic int\r\ncxgbit_get_immediate_data(struct iscsi_cmd *cmd, struct iscsi_scsi_req *hdr,\r\nbool dump_payload)\r\n{\r\nstruct iscsi_conn *conn = cmd->conn;\r\nint cmdsn_ret = 0, immed_ret = IMMEDIATE_DATA_NORMAL_OPERATION;\r\nif (dump_payload)\r\ngoto after_immediate_data;\r\nimmed_ret = cxgbit_handle_immediate_data(cmd, hdr,\r\ncmd->first_burst_len);\r\nafter_immediate_data:\r\nif (immed_ret == IMMEDIATE_DATA_NORMAL_OPERATION) {\r\ncmdsn_ret = iscsit_sequence_cmd(conn, cmd,\r\n(unsigned char *)hdr,\r\nhdr->cmdsn);\r\nif (cmdsn_ret == CMDSN_ERROR_CANNOT_RECOVER)\r\nreturn -1;\r\nif (cmd->sense_reason || cmdsn_ret == CMDSN_LOWER_THAN_EXP) {\r\ntarget_put_sess_cmd(&cmd->se_cmd);\r\nreturn 0;\r\n} else if (cmd->unsolicited_data) {\r\niscsit_set_unsoliticed_dataout(cmd);\r\n}\r\n} else if (immed_ret == IMMEDIATE_DATA_ERL1_CRC_FAILURE) {\r\ncmd->i_state = ISTATE_REMOVE;\r\niscsit_add_cmd_to_immediate_queue(cmd, conn, cmd->i_state);\r\n} else\r\nreturn -1;\r\nreturn 0;\r\n}\r\nstatic int\r\ncxgbit_handle_scsi_cmd(struct cxgbit_sock *csk, struct iscsi_cmd *cmd)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nstruct iscsi_scsi_req *hdr = (struct iscsi_scsi_req *)pdu_cb->hdr;\r\nint rc;\r\nbool dump_payload = false;\r\nrc = iscsit_setup_scsi_cmd(conn, cmd, (unsigned char *)hdr);\r\nif (rc < 0)\r\nreturn rc;\r\nif (pdu_cb->dlen && (pdu_cb->dlen == cmd->se_cmd.data_length) &&\r\n(pdu_cb->nr_dfrags == 1))\r\ncmd->se_cmd.se_cmd_flags |= SCF_PASSTHROUGH_SG_TO_MEM_NOALLOC;\r\nrc = iscsit_process_scsi_cmd(conn, cmd, hdr);\r\nif (rc < 0)\r\nreturn 0;\r\nelse if (rc > 0)\r\ndump_payload = true;\r\nif (!pdu_cb->dlen)\r\nreturn 0;\r\nreturn cxgbit_get_immediate_data(cmd, hdr, dump_payload);\r\n}\r\nstatic int cxgbit_handle_iscsi_dataout(struct cxgbit_sock *csk)\r\n{\r\nstruct scatterlist *sg_start;\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct iscsi_cmd *cmd = NULL;\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nstruct iscsi_data *hdr = (struct iscsi_data *)pdu_cb->hdr;\r\nu32 data_offset = be32_to_cpu(hdr->offset);\r\nu32 data_len = pdu_cb->dlen;\r\nint rc, sg_nents, sg_off;\r\nbool dcrc_err = false;\r\nif (pdu_cb->flags & PDUCBF_RX_DDP_CMP) {\r\nu32 offset = be32_to_cpu(hdr->offset);\r\nu32 ddp_data_len;\r\nu32 payload_length = ntoh24(hdr->dlength);\r\nbool success = false;\r\ncmd = iscsit_find_cmd_from_itt_or_dump(conn, hdr->itt, 0);\r\nif (!cmd)\r\nreturn 0;\r\nddp_data_len = offset - cmd->write_data_done;\r\natomic_long_add(ddp_data_len, &conn->sess->rx_data_octets);\r\ncmd->write_data_done = offset;\r\ncmd->next_burst_len = ddp_data_len;\r\ncmd->data_sn = be32_to_cpu(hdr->datasn);\r\nrc = __iscsit_check_dataout_hdr(conn, (unsigned char *)hdr,\r\ncmd, payload_length, &success);\r\nif (rc < 0)\r\nreturn rc;\r\nelse if (!success)\r\nreturn 0;\r\n} else {\r\nrc = iscsit_check_dataout_hdr(conn, (unsigned char *)hdr, &cmd);\r\nif (rc < 0)\r\nreturn rc;\r\nelse if (!cmd)\r\nreturn 0;\r\n}\r\nif (pdu_cb->flags & PDUCBF_RX_DCRC_ERR) {\r\npr_err("ITT: 0x%08x, Offset: %u, Length: %u,"\r\n" DataSN: 0x%08x\n",\r\nhdr->itt, hdr->offset, data_len,\r\nhdr->datasn);\r\ndcrc_err = true;\r\ngoto check_payload;\r\n}\r\npr_debug("DataOut data_len: %u, "\r\n"write_data_done: %u, data_length: %u\n",\r\ndata_len, cmd->write_data_done,\r\ncmd->se_cmd.data_length);\r\nif (!(pdu_cb->flags & PDUCBF_RX_DATA_DDPD)) {\r\nu32 skip = data_offset % PAGE_SIZE;\r\nsg_off = data_offset / PAGE_SIZE;\r\nsg_start = &cmd->se_cmd.t_data_sg[sg_off];\r\nsg_nents = max(1UL, DIV_ROUND_UP(skip + data_len, PAGE_SIZE));\r\ncxgbit_skb_copy_to_sg(csk->skb, sg_start, sg_nents, skip);\r\n}\r\ncheck_payload:\r\nrc = iscsit_check_dataout_payload(cmd, hdr, dcrc_err);\r\nif (rc < 0)\r\nreturn rc;\r\nreturn 0;\r\n}\r\nstatic int cxgbit_handle_nop_out(struct cxgbit_sock *csk, struct iscsi_cmd *cmd)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nstruct iscsi_nopout *hdr = (struct iscsi_nopout *)pdu_cb->hdr;\r\nunsigned char *ping_data = NULL;\r\nu32 payload_length = pdu_cb->dlen;\r\nint ret;\r\nret = iscsit_setup_nop_out(conn, cmd, hdr);\r\nif (ret < 0)\r\nreturn 0;\r\nif (pdu_cb->flags & PDUCBF_RX_DCRC_ERR) {\r\nif (!conn->sess->sess_ops->ErrorRecoveryLevel) {\r\npr_err("Unable to recover from"\r\n" NOPOUT Ping DataCRC failure while in"\r\n" ERL=0.\n");\r\nret = -1;\r\ngoto out;\r\n} else {\r\npr_info("Dropping NOPOUT"\r\n" Command CmdSN: 0x%08x due to"\r\n" DataCRC error.\n", hdr->cmdsn);\r\nret = 0;\r\ngoto out;\r\n}\r\n}\r\nif (payload_length && hdr->ttt == cpu_to_be32(0xFFFFFFFF)) {\r\nping_data = kzalloc(payload_length + 1, GFP_KERNEL);\r\nif (!ping_data) {\r\npr_err("Unable to allocate memory for"\r\n" NOPOUT ping data.\n");\r\nret = -1;\r\ngoto out;\r\n}\r\nskb_copy_bits(csk->skb, pdu_cb->doffset,\r\nping_data, payload_length);\r\nping_data[payload_length] = '\0';\r\ncmd->buf_ptr = ping_data;\r\ncmd->buf_ptr_size = payload_length;\r\npr_debug("Got %u bytes of NOPOUT ping"\r\n" data.\n", payload_length);\r\npr_debug("Ping Data: \"%s\"\n", ping_data);\r\n}\r\nreturn iscsit_process_nop_out(conn, cmd, hdr);\r\nout:\r\nif (cmd)\r\niscsit_free_cmd(cmd, false);\r\nreturn ret;\r\n}\r\nstatic int\r\ncxgbit_handle_text_cmd(struct cxgbit_sock *csk, struct iscsi_cmd *cmd)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nstruct iscsi_text *hdr = (struct iscsi_text *)pdu_cb->hdr;\r\nu32 payload_length = pdu_cb->dlen;\r\nint rc;\r\nunsigned char *text_in = NULL;\r\nrc = iscsit_setup_text_cmd(conn, cmd, hdr);\r\nif (rc < 0)\r\nreturn rc;\r\nif (pdu_cb->flags & PDUCBF_RX_DCRC_ERR) {\r\nif (!conn->sess->sess_ops->ErrorRecoveryLevel) {\r\npr_err("Unable to recover from"\r\n" Text Data digest failure while in"\r\n" ERL=0.\n");\r\ngoto reject;\r\n} else {\r\npr_info("Dropping Text"\r\n" Command CmdSN: 0x%08x due to"\r\n" DataCRC error.\n", hdr->cmdsn);\r\nreturn 0;\r\n}\r\n}\r\nif (payload_length) {\r\ntext_in = kzalloc(payload_length, GFP_KERNEL);\r\nif (!text_in) {\r\npr_err("Unable to allocate text_in of payload_length: %u\n",\r\npayload_length);\r\nreturn -ENOMEM;\r\n}\r\nskb_copy_bits(csk->skb, pdu_cb->doffset,\r\ntext_in, payload_length);\r\ntext_in[payload_length - 1] = '\0';\r\ncmd->text_in_ptr = text_in;\r\n}\r\nreturn iscsit_process_text_cmd(conn, cmd, hdr);\r\nreject:\r\nreturn iscsit_reject_cmd(cmd, ISCSI_REASON_PROTOCOL_ERROR,\r\npdu_cb->hdr);\r\n}\r\nstatic int cxgbit_target_rx_opcode(struct cxgbit_sock *csk)\r\n{\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nstruct iscsi_hdr *hdr = (struct iscsi_hdr *)pdu_cb->hdr;\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct iscsi_cmd *cmd = NULL;\r\nu8 opcode = (hdr->opcode & ISCSI_OPCODE_MASK);\r\nint ret = -EINVAL;\r\nswitch (opcode) {\r\ncase ISCSI_OP_SCSI_CMD:\r\ncmd = cxgbit_allocate_cmd(csk);\r\nif (!cmd)\r\ngoto reject;\r\nret = cxgbit_handle_scsi_cmd(csk, cmd);\r\nbreak;\r\ncase ISCSI_OP_SCSI_DATA_OUT:\r\nret = cxgbit_handle_iscsi_dataout(csk);\r\nbreak;\r\ncase ISCSI_OP_NOOP_OUT:\r\nif (hdr->ttt == cpu_to_be32(0xFFFFFFFF)) {\r\ncmd = cxgbit_allocate_cmd(csk);\r\nif (!cmd)\r\ngoto reject;\r\n}\r\nret = cxgbit_handle_nop_out(csk, cmd);\r\nbreak;\r\ncase ISCSI_OP_SCSI_TMFUNC:\r\ncmd = cxgbit_allocate_cmd(csk);\r\nif (!cmd)\r\ngoto reject;\r\nret = iscsit_handle_task_mgt_cmd(conn, cmd,\r\n(unsigned char *)hdr);\r\nbreak;\r\ncase ISCSI_OP_TEXT:\r\nif (hdr->ttt != cpu_to_be32(0xFFFFFFFF)) {\r\ncmd = iscsit_find_cmd_from_itt(conn, hdr->itt);\r\nif (!cmd)\r\ngoto reject;\r\n} else {\r\ncmd = cxgbit_allocate_cmd(csk);\r\nif (!cmd)\r\ngoto reject;\r\n}\r\nret = cxgbit_handle_text_cmd(csk, cmd);\r\nbreak;\r\ncase ISCSI_OP_LOGOUT:\r\ncmd = cxgbit_allocate_cmd(csk);\r\nif (!cmd)\r\ngoto reject;\r\nret = iscsit_handle_logout_cmd(conn, cmd, (unsigned char *)hdr);\r\nif (ret > 0)\r\nwait_for_completion_timeout(&conn->conn_logout_comp,\r\nSECONDS_FOR_LOGOUT_COMP\r\n* HZ);\r\nbreak;\r\ncase ISCSI_OP_SNACK:\r\nret = iscsit_handle_snack(conn, (unsigned char *)hdr);\r\nbreak;\r\ndefault:\r\npr_err("Got unknown iSCSI OpCode: 0x%02x\n", opcode);\r\ndump_stack();\r\nbreak;\r\n}\r\nreturn ret;\r\nreject:\r\nreturn iscsit_add_reject(conn, ISCSI_REASON_BOOKMARK_NO_RESOURCES,\r\n(unsigned char *)hdr);\r\nreturn ret;\r\n}\r\nstatic int cxgbit_rx_opcode(struct cxgbit_sock *csk)\r\n{\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct iscsi_hdr *hdr = pdu_cb->hdr;\r\nu8 opcode;\r\nif (pdu_cb->flags & PDUCBF_RX_HCRC_ERR) {\r\natomic_long_inc(&conn->sess->conn_digest_errors);\r\ngoto transport_err;\r\n}\r\nif (conn->conn_state == TARG_CONN_STATE_IN_LOGOUT)\r\ngoto transport_err;\r\nopcode = hdr->opcode & ISCSI_OPCODE_MASK;\r\nif (conn->sess->sess_ops->SessionType &&\r\n((!(opcode & ISCSI_OP_TEXT)) ||\r\n(!(opcode & ISCSI_OP_LOGOUT)))) {\r\npr_err("Received illegal iSCSI Opcode: 0x%02x"\r\n" while in Discovery Session, rejecting.\n", opcode);\r\niscsit_add_reject(conn, ISCSI_REASON_PROTOCOL_ERROR,\r\n(unsigned char *)hdr);\r\ngoto transport_err;\r\n}\r\nif (cxgbit_target_rx_opcode(csk) < 0)\r\ngoto transport_err;\r\nreturn 0;\r\ntransport_err:\r\nreturn -1;\r\n}\r\nstatic int cxgbit_rx_login_pdu(struct cxgbit_sock *csk)\r\n{\r\nstruct iscsi_conn *conn = csk->conn;\r\nstruct iscsi_login *login = conn->login;\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_rx_pdu_cb(csk->skb);\r\nstruct iscsi_login_req *login_req;\r\nlogin_req = (struct iscsi_login_req *)login->req;\r\nmemcpy(login_req, pdu_cb->hdr, sizeof(*login_req));\r\npr_debug("Got Login Command, Flags 0x%02x, ITT: 0x%08x,"\r\n" CmdSN: 0x%08x, ExpStatSN: 0x%08x, CID: %hu, Length: %u\n",\r\nlogin_req->flags, login_req->itt, login_req->cmdsn,\r\nlogin_req->exp_statsn, login_req->cid, pdu_cb->dlen);\r\nif (login->first_request) {\r\nlogin_req = (struct iscsi_login_req *)login->req;\r\nlogin->leading_connection = (!login_req->tsih) ? 1 : 0;\r\nlogin->current_stage = ISCSI_LOGIN_CURRENT_STAGE(\r\nlogin_req->flags);\r\nlogin->version_min = login_req->min_version;\r\nlogin->version_max = login_req->max_version;\r\nmemcpy(login->isid, login_req->isid, 6);\r\nlogin->cmd_sn = be32_to_cpu(login_req->cmdsn);\r\nlogin->init_task_tag = login_req->itt;\r\nlogin->initial_exp_statsn = be32_to_cpu(login_req->exp_statsn);\r\nlogin->cid = be16_to_cpu(login_req->cid);\r\nlogin->tsih = be16_to_cpu(login_req->tsih);\r\n}\r\nif (iscsi_target_check_login_request(conn, login) < 0)\r\nreturn -1;\r\nmemset(login->req_buf, 0, MAX_KEY_VALUE_PAIRS);\r\nskb_copy_bits(csk->skb, pdu_cb->doffset, login->req_buf, pdu_cb->dlen);\r\nreturn 0;\r\n}\r\nstatic int\r\ncxgbit_process_iscsi_pdu(struct cxgbit_sock *csk, struct sk_buff *skb, int idx)\r\n{\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_skb_lro_pdu_cb(skb, idx);\r\nint ret;\r\ncxgbit_rx_pdu_cb(skb) = pdu_cb;\r\ncsk->skb = skb;\r\nif (!test_bit(CSK_LOGIN_DONE, &csk->com.flags)) {\r\nret = cxgbit_rx_login_pdu(csk);\r\nset_bit(CSK_LOGIN_PDU_DONE, &csk->com.flags);\r\n} else {\r\nret = cxgbit_rx_opcode(csk);\r\n}\r\nreturn ret;\r\n}\r\nstatic void cxgbit_lro_skb_dump(struct sk_buff *skb)\r\n{\r\nstruct skb_shared_info *ssi = skb_shinfo(skb);\r\nstruct cxgbit_lro_cb *lro_cb = cxgbit_skb_lro_cb(skb);\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_skb_lro_pdu_cb(skb, 0);\r\nu8 i;\r\npr_info("skb 0x%p, head 0x%p, 0x%p, len %u,%u, frags %u.\n",\r\nskb, skb->head, skb->data, skb->len, skb->data_len,\r\nssi->nr_frags);\r\npr_info("skb 0x%p, lro_cb, csk 0x%p, pdu %u, %u.\n",\r\nskb, lro_cb->csk, lro_cb->pdu_idx, lro_cb->pdu_totallen);\r\nfor (i = 0; i < lro_cb->pdu_idx; i++, pdu_cb++)\r\npr_info("skb 0x%p, pdu %d, %u, f 0x%x, seq 0x%x, dcrc 0x%x, "\r\n"frags %u.\n",\r\nskb, i, pdu_cb->pdulen, pdu_cb->flags, pdu_cb->seq,\r\npdu_cb->ddigest, pdu_cb->frags);\r\nfor (i = 0; i < ssi->nr_frags; i++)\r\npr_info("skb 0x%p, frag %d, off %u, sz %u.\n",\r\nskb, i, ssi->frags[i].page_offset, ssi->frags[i].size);\r\n}\r\nstatic void cxgbit_lro_hskb_reset(struct cxgbit_sock *csk)\r\n{\r\nstruct sk_buff *skb = csk->lro_hskb;\r\nstruct skb_shared_info *ssi = skb_shinfo(skb);\r\nu8 i;\r\nmemset(skb->data, 0, LRO_SKB_MIN_HEADROOM);\r\nfor (i = 0; i < ssi->nr_frags; i++)\r\nput_page(skb_frag_page(&ssi->frags[i]));\r\nssi->nr_frags = 0;\r\nskb->data_len = 0;\r\nskb->truesize -= skb->len;\r\nskb->len = 0;\r\n}\r\nstatic void\r\ncxgbit_lro_skb_merge(struct cxgbit_sock *csk, struct sk_buff *skb, u8 pdu_idx)\r\n{\r\nstruct sk_buff *hskb = csk->lro_hskb;\r\nstruct cxgbit_lro_pdu_cb *hpdu_cb = cxgbit_skb_lro_pdu_cb(hskb, 0);\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_skb_lro_pdu_cb(skb, pdu_idx);\r\nstruct skb_shared_info *hssi = skb_shinfo(hskb);\r\nstruct skb_shared_info *ssi = skb_shinfo(skb);\r\nunsigned int len = 0;\r\nif (pdu_cb->flags & PDUCBF_RX_HDR) {\r\nu8 hfrag_idx = hssi->nr_frags;\r\nhpdu_cb->flags |= pdu_cb->flags;\r\nhpdu_cb->seq = pdu_cb->seq;\r\nhpdu_cb->hdr = pdu_cb->hdr;\r\nhpdu_cb->hlen = pdu_cb->hlen;\r\nmemcpy(&hssi->frags[hfrag_idx], &ssi->frags[pdu_cb->hfrag_idx],\r\nsizeof(skb_frag_t));\r\nget_page(skb_frag_page(&hssi->frags[hfrag_idx]));\r\nhssi->nr_frags++;\r\nhpdu_cb->frags++;\r\nhpdu_cb->hfrag_idx = hfrag_idx;\r\nlen = hssi->frags[hfrag_idx].size;\r\nhskb->len += len;\r\nhskb->data_len += len;\r\nhskb->truesize += len;\r\n}\r\nif (pdu_cb->flags & PDUCBF_RX_DATA) {\r\nu8 dfrag_idx = hssi->nr_frags, i;\r\nhpdu_cb->flags |= pdu_cb->flags;\r\nhpdu_cb->dfrag_idx = dfrag_idx;\r\nlen = 0;\r\nfor (i = 0; i < pdu_cb->nr_dfrags; dfrag_idx++, i++) {\r\nmemcpy(&hssi->frags[dfrag_idx],\r\n&ssi->frags[pdu_cb->dfrag_idx + i],\r\nsizeof(skb_frag_t));\r\nget_page(skb_frag_page(&hssi->frags[dfrag_idx]));\r\nlen += hssi->frags[dfrag_idx].size;\r\nhssi->nr_frags++;\r\nhpdu_cb->frags++;\r\n}\r\nhpdu_cb->dlen = pdu_cb->dlen;\r\nhpdu_cb->doffset = hpdu_cb->hlen;\r\nhpdu_cb->nr_dfrags = pdu_cb->nr_dfrags;\r\nhskb->len += len;\r\nhskb->data_len += len;\r\nhskb->truesize += len;\r\n}\r\nif (pdu_cb->flags & PDUCBF_RX_STATUS) {\r\nhpdu_cb->flags |= pdu_cb->flags;\r\nif (hpdu_cb->flags & PDUCBF_RX_DATA)\r\nhpdu_cb->flags &= ~PDUCBF_RX_DATA_DDPD;\r\nhpdu_cb->ddigest = pdu_cb->ddigest;\r\nhpdu_cb->pdulen = pdu_cb->pdulen;\r\n}\r\n}\r\nstatic int cxgbit_process_lro_skb(struct cxgbit_sock *csk, struct sk_buff *skb)\r\n{\r\nstruct cxgbit_lro_cb *lro_cb = cxgbit_skb_lro_cb(skb);\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_skb_lro_pdu_cb(skb, 0);\r\nu8 pdu_idx = 0, last_idx = 0;\r\nint ret = 0;\r\nif (!pdu_cb->complete) {\r\ncxgbit_lro_skb_merge(csk, skb, 0);\r\nif (pdu_cb->flags & PDUCBF_RX_STATUS) {\r\nstruct sk_buff *hskb = csk->lro_hskb;\r\nret = cxgbit_process_iscsi_pdu(csk, hskb, 0);\r\ncxgbit_lro_hskb_reset(csk);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\npdu_idx = 1;\r\n}\r\nif (lro_cb->pdu_idx)\r\nlast_idx = lro_cb->pdu_idx - 1;\r\nfor (; pdu_idx <= last_idx; pdu_idx++) {\r\nret = cxgbit_process_iscsi_pdu(csk, skb, pdu_idx);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\nif ((!lro_cb->complete) && lro_cb->pdu_idx)\r\ncxgbit_lro_skb_merge(csk, skb, lro_cb->pdu_idx);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int cxgbit_rx_lro_skb(struct cxgbit_sock *csk, struct sk_buff *skb)\r\n{\r\nstruct cxgbit_lro_cb *lro_cb = cxgbit_skb_lro_cb(skb);\r\nstruct cxgbit_lro_pdu_cb *pdu_cb = cxgbit_skb_lro_pdu_cb(skb, 0);\r\nint ret = -1;\r\nif ((pdu_cb->flags & PDUCBF_RX_HDR) &&\r\n(pdu_cb->seq != csk->rcv_nxt)) {\r\npr_info("csk 0x%p, tid 0x%x, seq 0x%x != 0x%x.\n",\r\ncsk, csk->tid, pdu_cb->seq, csk->rcv_nxt);\r\ncxgbit_lro_skb_dump(skb);\r\nreturn ret;\r\n}\r\ncsk->rcv_nxt += lro_cb->pdu_totallen;\r\nret = cxgbit_process_lro_skb(csk, skb);\r\ncsk->rx_credits += lro_cb->pdu_totallen;\r\nif (csk->rx_credits >= (csk->rcv_win / 4))\r\ncxgbit_rx_data_ack(csk);\r\nreturn ret;\r\n}\r\nstatic int cxgbit_rx_skb(struct cxgbit_sock *csk, struct sk_buff *skb)\r\n{\r\nstruct cxgb4_lld_info *lldi = &csk->com.cdev->lldi;\r\nint ret = -1;\r\nif (likely(cxgbit_skcb_flags(skb) & SKCBF_RX_LRO)) {\r\nif (is_t5(lldi->adapter_type))\r\nret = cxgbit_rx_lro_skb(csk, skb);\r\nelse\r\nret = cxgbit_process_lro_skb(csk, skb);\r\n}\r\n__kfree_skb(skb);\r\nreturn ret;\r\n}\r\nstatic bool cxgbit_rxq_len(struct cxgbit_sock *csk, struct sk_buff_head *rxq)\r\n{\r\nspin_lock_bh(&csk->rxq.lock);\r\nif (skb_queue_len(&csk->rxq)) {\r\nskb_queue_splice_init(&csk->rxq, rxq);\r\nspin_unlock_bh(&csk->rxq.lock);\r\nreturn true;\r\n}\r\nspin_unlock_bh(&csk->rxq.lock);\r\nreturn false;\r\n}\r\nstatic int cxgbit_wait_rxq(struct cxgbit_sock *csk)\r\n{\r\nstruct sk_buff *skb;\r\nstruct sk_buff_head rxq;\r\nskb_queue_head_init(&rxq);\r\nwait_event_interruptible(csk->waitq, cxgbit_rxq_len(csk, &rxq));\r\nif (signal_pending(current))\r\ngoto out;\r\nwhile ((skb = __skb_dequeue(&rxq))) {\r\nif (cxgbit_rx_skb(csk, skb))\r\ngoto out;\r\n}\r\nreturn 0;\r\nout:\r\n__skb_queue_purge(&rxq);\r\nreturn -1;\r\n}\r\nint cxgbit_get_login_rx(struct iscsi_conn *conn, struct iscsi_login *login)\r\n{\r\nstruct cxgbit_sock *csk = conn->context;\r\nint ret = -1;\r\nwhile (!test_and_clear_bit(CSK_LOGIN_PDU_DONE, &csk->com.flags)) {\r\nret = cxgbit_wait_rxq(csk);\r\nif (ret) {\r\nclear_bit(CSK_LOGIN_PDU_DONE, &csk->com.flags);\r\nbreak;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid cxgbit_get_rx_pdu(struct iscsi_conn *conn)\r\n{\r\nstruct cxgbit_sock *csk = conn->context;\r\nwhile (!kthread_should_stop()) {\r\niscsit_thread_check_cpumask(conn, current, 0);\r\nif (cxgbit_wait_rxq(csk))\r\nreturn;\r\n}\r\n}
