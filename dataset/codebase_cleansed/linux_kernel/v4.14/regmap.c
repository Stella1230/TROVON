bool regmap_reg_in_ranges(unsigned int reg,\r\nconst struct regmap_range *ranges,\r\nunsigned int nranges)\r\n{\r\nconst struct regmap_range *r;\r\nint i;\r\nfor (i = 0, r = ranges; i < nranges; i++, r++)\r\nif (regmap_reg_in_range(reg, r))\r\nreturn true;\r\nreturn false;\r\n}\r\nbool regmap_check_range_table(struct regmap *map, unsigned int reg,\r\nconst struct regmap_access_table *table)\r\n{\r\nif (regmap_reg_in_ranges(reg, table->no_ranges, table->n_no_ranges))\r\nreturn false;\r\nif (!table->n_yes_ranges)\r\nreturn true;\r\nreturn regmap_reg_in_ranges(reg, table->yes_ranges,\r\ntable->n_yes_ranges);\r\n}\r\nbool regmap_writeable(struct regmap *map, unsigned int reg)\r\n{\r\nif (map->max_register && reg > map->max_register)\r\nreturn false;\r\nif (map->writeable_reg)\r\nreturn map->writeable_reg(map->dev, reg);\r\nif (map->wr_table)\r\nreturn regmap_check_range_table(map, reg, map->wr_table);\r\nreturn true;\r\n}\r\nbool regmap_cached(struct regmap *map, unsigned int reg)\r\n{\r\nint ret;\r\nunsigned int val;\r\nif (map->cache == REGCACHE_NONE)\r\nreturn false;\r\nif (!map->cache_ops)\r\nreturn false;\r\nif (map->max_register && reg > map->max_register)\r\nreturn false;\r\nmap->lock(map->lock_arg);\r\nret = regcache_read(map, reg, &val);\r\nmap->unlock(map->lock_arg);\r\nif (ret)\r\nreturn false;\r\nreturn true;\r\n}\r\nbool regmap_readable(struct regmap *map, unsigned int reg)\r\n{\r\nif (!map->reg_read)\r\nreturn false;\r\nif (map->max_register && reg > map->max_register)\r\nreturn false;\r\nif (map->format.format_write)\r\nreturn false;\r\nif (map->readable_reg)\r\nreturn map->readable_reg(map->dev, reg);\r\nif (map->rd_table)\r\nreturn regmap_check_range_table(map, reg, map->rd_table);\r\nreturn true;\r\n}\r\nbool regmap_volatile(struct regmap *map, unsigned int reg)\r\n{\r\nif (!map->format.format_write && !regmap_readable(map, reg))\r\nreturn false;\r\nif (map->volatile_reg)\r\nreturn map->volatile_reg(map->dev, reg);\r\nif (map->volatile_table)\r\nreturn regmap_check_range_table(map, reg, map->volatile_table);\r\nif (map->cache_ops)\r\nreturn false;\r\nelse\r\nreturn true;\r\n}\r\nbool regmap_precious(struct regmap *map, unsigned int reg)\r\n{\r\nif (!regmap_readable(map, reg))\r\nreturn false;\r\nif (map->precious_reg)\r\nreturn map->precious_reg(map->dev, reg);\r\nif (map->precious_table)\r\nreturn regmap_check_range_table(map, reg, map->precious_table);\r\nreturn false;\r\n}\r\nstatic bool regmap_volatile_range(struct regmap *map, unsigned int reg,\r\nsize_t num)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < num; i++)\r\nif (!regmap_volatile(map, reg + i))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void regmap_format_2_6_write(struct regmap *map,\r\nunsigned int reg, unsigned int val)\r\n{\r\nu8 *out = map->work_buf;\r\n*out = (reg << 6) | val;\r\n}\r\nstatic void regmap_format_4_12_write(struct regmap *map,\r\nunsigned int reg, unsigned int val)\r\n{\r\n__be16 *out = map->work_buf;\r\n*out = cpu_to_be16((reg << 12) | val);\r\n}\r\nstatic void regmap_format_7_9_write(struct regmap *map,\r\nunsigned int reg, unsigned int val)\r\n{\r\n__be16 *out = map->work_buf;\r\n*out = cpu_to_be16((reg << 9) | val);\r\n}\r\nstatic void regmap_format_10_14_write(struct regmap *map,\r\nunsigned int reg, unsigned int val)\r\n{\r\nu8 *out = map->work_buf;\r\nout[2] = val;\r\nout[1] = (val >> 8) | (reg << 6);\r\nout[0] = reg >> 2;\r\n}\r\nstatic void regmap_format_8(void *buf, unsigned int val, unsigned int shift)\r\n{\r\nu8 *b = buf;\r\nb[0] = val << shift;\r\n}\r\nstatic void regmap_format_16_be(void *buf, unsigned int val, unsigned int shift)\r\n{\r\n__be16 *b = buf;\r\nb[0] = cpu_to_be16(val << shift);\r\n}\r\nstatic void regmap_format_16_le(void *buf, unsigned int val, unsigned int shift)\r\n{\r\n__le16 *b = buf;\r\nb[0] = cpu_to_le16(val << shift);\r\n}\r\nstatic void regmap_format_16_native(void *buf, unsigned int val,\r\nunsigned int shift)\r\n{\r\n*(u16 *)buf = val << shift;\r\n}\r\nstatic void regmap_format_24(void *buf, unsigned int val, unsigned int shift)\r\n{\r\nu8 *b = buf;\r\nval <<= shift;\r\nb[0] = val >> 16;\r\nb[1] = val >> 8;\r\nb[2] = val;\r\n}\r\nstatic void regmap_format_32_be(void *buf, unsigned int val, unsigned int shift)\r\n{\r\n__be32 *b = buf;\r\nb[0] = cpu_to_be32(val << shift);\r\n}\r\nstatic void regmap_format_32_le(void *buf, unsigned int val, unsigned int shift)\r\n{\r\n__le32 *b = buf;\r\nb[0] = cpu_to_le32(val << shift);\r\n}\r\nstatic void regmap_format_32_native(void *buf, unsigned int val,\r\nunsigned int shift)\r\n{\r\n*(u32 *)buf = val << shift;\r\n}\r\nstatic void regmap_format_64_be(void *buf, unsigned int val, unsigned int shift)\r\n{\r\n__be64 *b = buf;\r\nb[0] = cpu_to_be64((u64)val << shift);\r\n}\r\nstatic void regmap_format_64_le(void *buf, unsigned int val, unsigned int shift)\r\n{\r\n__le64 *b = buf;\r\nb[0] = cpu_to_le64((u64)val << shift);\r\n}\r\nstatic void regmap_format_64_native(void *buf, unsigned int val,\r\nunsigned int shift)\r\n{\r\n*(u64 *)buf = (u64)val << shift;\r\n}\r\nstatic void regmap_parse_inplace_noop(void *buf)\r\n{\r\n}\r\nstatic unsigned int regmap_parse_8(const void *buf)\r\n{\r\nconst u8 *b = buf;\r\nreturn b[0];\r\n}\r\nstatic unsigned int regmap_parse_16_be(const void *buf)\r\n{\r\nconst __be16 *b = buf;\r\nreturn be16_to_cpu(b[0]);\r\n}\r\nstatic unsigned int regmap_parse_16_le(const void *buf)\r\n{\r\nconst __le16 *b = buf;\r\nreturn le16_to_cpu(b[0]);\r\n}\r\nstatic void regmap_parse_16_be_inplace(void *buf)\r\n{\r\n__be16 *b = buf;\r\nb[0] = be16_to_cpu(b[0]);\r\n}\r\nstatic void regmap_parse_16_le_inplace(void *buf)\r\n{\r\n__le16 *b = buf;\r\nb[0] = le16_to_cpu(b[0]);\r\n}\r\nstatic unsigned int regmap_parse_16_native(const void *buf)\r\n{\r\nreturn *(u16 *)buf;\r\n}\r\nstatic unsigned int regmap_parse_24(const void *buf)\r\n{\r\nconst u8 *b = buf;\r\nunsigned int ret = b[2];\r\nret |= ((unsigned int)b[1]) << 8;\r\nret |= ((unsigned int)b[0]) << 16;\r\nreturn ret;\r\n}\r\nstatic unsigned int regmap_parse_32_be(const void *buf)\r\n{\r\nconst __be32 *b = buf;\r\nreturn be32_to_cpu(b[0]);\r\n}\r\nstatic unsigned int regmap_parse_32_le(const void *buf)\r\n{\r\nconst __le32 *b = buf;\r\nreturn le32_to_cpu(b[0]);\r\n}\r\nstatic void regmap_parse_32_be_inplace(void *buf)\r\n{\r\n__be32 *b = buf;\r\nb[0] = be32_to_cpu(b[0]);\r\n}\r\nstatic void regmap_parse_32_le_inplace(void *buf)\r\n{\r\n__le32 *b = buf;\r\nb[0] = le32_to_cpu(b[0]);\r\n}\r\nstatic unsigned int regmap_parse_32_native(const void *buf)\r\n{\r\nreturn *(u32 *)buf;\r\n}\r\nstatic unsigned int regmap_parse_64_be(const void *buf)\r\n{\r\nconst __be64 *b = buf;\r\nreturn be64_to_cpu(b[0]);\r\n}\r\nstatic unsigned int regmap_parse_64_le(const void *buf)\r\n{\r\nconst __le64 *b = buf;\r\nreturn le64_to_cpu(b[0]);\r\n}\r\nstatic void regmap_parse_64_be_inplace(void *buf)\r\n{\r\n__be64 *b = buf;\r\nb[0] = be64_to_cpu(b[0]);\r\n}\r\nstatic void regmap_parse_64_le_inplace(void *buf)\r\n{\r\n__le64 *b = buf;\r\nb[0] = le64_to_cpu(b[0]);\r\n}\r\nstatic unsigned int regmap_parse_64_native(const void *buf)\r\n{\r\nreturn *(u64 *)buf;\r\n}\r\nstatic void regmap_lock_mutex(void *__map)\r\n{\r\nstruct regmap *map = __map;\r\nmutex_lock(&map->mutex);\r\n}\r\nstatic void regmap_unlock_mutex(void *__map)\r\n{\r\nstruct regmap *map = __map;\r\nmutex_unlock(&map->mutex);\r\n}\r\nstatic void regmap_lock_spinlock(void *__map)\r\n__acquires(&map->spinlock\r\nstatic void regmap_unlock_spinlock(void *__map)\r\n__releases(&map->spinlock\r\nstatic void dev_get_regmap_release(struct device *dev, void *res)\r\n{\r\n}\r\nstatic bool _regmap_range_add(struct regmap *map,\r\nstruct regmap_range_node *data)\r\n{\r\nstruct rb_root *root = &map->range_tree;\r\nstruct rb_node **new = &(root->rb_node), *parent = NULL;\r\nwhile (*new) {\r\nstruct regmap_range_node *this =\r\nrb_entry(*new, struct regmap_range_node, node);\r\nparent = *new;\r\nif (data->range_max < this->range_min)\r\nnew = &((*new)->rb_left);\r\nelse if (data->range_min > this->range_max)\r\nnew = &((*new)->rb_right);\r\nelse\r\nreturn false;\r\n}\r\nrb_link_node(&data->node, parent, new);\r\nrb_insert_color(&data->node, root);\r\nreturn true;\r\n}\r\nstatic struct regmap_range_node *_regmap_range_lookup(struct regmap *map,\r\nunsigned int reg)\r\n{\r\nstruct rb_node *node = map->range_tree.rb_node;\r\nwhile (node) {\r\nstruct regmap_range_node *this =\r\nrb_entry(node, struct regmap_range_node, node);\r\nif (reg < this->range_min)\r\nnode = node->rb_left;\r\nelse if (reg > this->range_max)\r\nnode = node->rb_right;\r\nelse\r\nreturn this;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void regmap_range_exit(struct regmap *map)\r\n{\r\nstruct rb_node *next;\r\nstruct regmap_range_node *range_node;\r\nnext = rb_first(&map->range_tree);\r\nwhile (next) {\r\nrange_node = rb_entry(next, struct regmap_range_node, node);\r\nnext = rb_next(&range_node->node);\r\nrb_erase(&range_node->node, &map->range_tree);\r\nkfree(range_node);\r\n}\r\nkfree(map->selector_work_buf);\r\n}\r\nint regmap_attach_dev(struct device *dev, struct regmap *map,\r\nconst struct regmap_config *config)\r\n{\r\nstruct regmap **m;\r\nmap->dev = dev;\r\nregmap_debugfs_init(map, config->name);\r\nm = devres_alloc(dev_get_regmap_release, sizeof(*m), GFP_KERNEL);\r\nif (!m) {\r\nregmap_debugfs_exit(map);\r\nreturn -ENOMEM;\r\n}\r\n*m = map;\r\ndevres_add(dev, m);\r\nreturn 0;\r\n}\r\nstatic enum regmap_endian regmap_get_reg_endian(const struct regmap_bus *bus,\r\nconst struct regmap_config *config)\r\n{\r\nenum regmap_endian endian;\r\nendian = config->reg_format_endian;\r\nif (endian != REGMAP_ENDIAN_DEFAULT)\r\nreturn endian;\r\nif (bus && bus->reg_format_endian_default)\r\nendian = bus->reg_format_endian_default;\r\nif (endian != REGMAP_ENDIAN_DEFAULT)\r\nreturn endian;\r\nreturn REGMAP_ENDIAN_BIG;\r\n}\r\nenum regmap_endian regmap_get_val_endian(struct device *dev,\r\nconst struct regmap_bus *bus,\r\nconst struct regmap_config *config)\r\n{\r\nstruct device_node *np;\r\nenum regmap_endian endian;\r\nendian = config->val_format_endian;\r\nif (endian != REGMAP_ENDIAN_DEFAULT)\r\nreturn endian;\r\nif (dev && dev->of_node) {\r\nnp = dev->of_node;\r\nif (of_property_read_bool(np, "big-endian"))\r\nendian = REGMAP_ENDIAN_BIG;\r\nelse if (of_property_read_bool(np, "little-endian"))\r\nendian = REGMAP_ENDIAN_LITTLE;\r\nelse if (of_property_read_bool(np, "native-endian"))\r\nendian = REGMAP_ENDIAN_NATIVE;\r\nif (endian != REGMAP_ENDIAN_DEFAULT)\r\nreturn endian;\r\n}\r\nif (bus && bus->val_format_endian_default)\r\nendian = bus->val_format_endian_default;\r\nif (endian != REGMAP_ENDIAN_DEFAULT)\r\nreturn endian;\r\nreturn REGMAP_ENDIAN_BIG;\r\n}\r\nstruct regmap *__regmap_init(struct device *dev,\r\nconst struct regmap_bus *bus,\r\nvoid *bus_context,\r\nconst struct regmap_config *config,\r\nstruct lock_class_key *lock_key,\r\nconst char *lock_name)\r\n{\r\nstruct regmap *map;\r\nint ret = -EINVAL;\r\nenum regmap_endian reg_endian, val_endian;\r\nint i, j;\r\nif (!config)\r\ngoto err;\r\nmap = kzalloc(sizeof(*map), GFP_KERNEL);\r\nif (map == NULL) {\r\nret = -ENOMEM;\r\ngoto err;\r\n}\r\nif (config->lock && config->unlock) {\r\nmap->lock = config->lock;\r\nmap->unlock = config->unlock;\r\nmap->lock_arg = config->lock_arg;\r\n} else {\r\nif ((bus && bus->fast_io) ||\r\nconfig->fast_io) {\r\nspin_lock_init(&map->spinlock);\r\nmap->lock = regmap_lock_spinlock;\r\nmap->unlock = regmap_unlock_spinlock;\r\nlockdep_set_class_and_name(&map->spinlock,\r\nlock_key, lock_name);\r\n} else {\r\nmutex_init(&map->mutex);\r\nmap->lock = regmap_lock_mutex;\r\nmap->unlock = regmap_unlock_mutex;\r\nlockdep_set_class_and_name(&map->mutex,\r\nlock_key, lock_name);\r\n}\r\nmap->lock_arg = map;\r\n}\r\nif ((bus && bus->fast_io) || config->fast_io)\r\nmap->alloc_flags = GFP_ATOMIC;\r\nelse\r\nmap->alloc_flags = GFP_KERNEL;\r\nmap->format.reg_bytes = DIV_ROUND_UP(config->reg_bits, 8);\r\nmap->format.pad_bytes = config->pad_bits / 8;\r\nmap->format.val_bytes = DIV_ROUND_UP(config->val_bits, 8);\r\nmap->format.buf_size = DIV_ROUND_UP(config->reg_bits +\r\nconfig->val_bits + config->pad_bits, 8);\r\nmap->reg_shift = config->pad_bits % 8;\r\nif (config->reg_stride)\r\nmap->reg_stride = config->reg_stride;\r\nelse\r\nmap->reg_stride = 1;\r\nif (is_power_of_2(map->reg_stride))\r\nmap->reg_stride_order = ilog2(map->reg_stride);\r\nelse\r\nmap->reg_stride_order = -1;\r\nmap->use_single_read = config->use_single_rw || !bus || !bus->read;\r\nmap->use_single_write = config->use_single_rw || !bus || !bus->write;\r\nmap->can_multi_write = config->can_multi_write && bus && bus->write;\r\nif (bus) {\r\nmap->max_raw_read = bus->max_raw_read;\r\nmap->max_raw_write = bus->max_raw_write;\r\n}\r\nmap->dev = dev;\r\nmap->bus = bus;\r\nmap->bus_context = bus_context;\r\nmap->max_register = config->max_register;\r\nmap->wr_table = config->wr_table;\r\nmap->rd_table = config->rd_table;\r\nmap->volatile_table = config->volatile_table;\r\nmap->precious_table = config->precious_table;\r\nmap->writeable_reg = config->writeable_reg;\r\nmap->readable_reg = config->readable_reg;\r\nmap->volatile_reg = config->volatile_reg;\r\nmap->precious_reg = config->precious_reg;\r\nmap->cache_type = config->cache_type;\r\nmap->name = config->name;\r\nspin_lock_init(&map->async_lock);\r\nINIT_LIST_HEAD(&map->async_list);\r\nINIT_LIST_HEAD(&map->async_free);\r\ninit_waitqueue_head(&map->async_waitq);\r\nif (config->read_flag_mask || config->write_flag_mask) {\r\nmap->read_flag_mask = config->read_flag_mask;\r\nmap->write_flag_mask = config->write_flag_mask;\r\n} else if (bus) {\r\nmap->read_flag_mask = bus->read_flag_mask;\r\n}\r\nif (!bus) {\r\nmap->reg_read = config->reg_read;\r\nmap->reg_write = config->reg_write;\r\nmap->defer_caching = false;\r\ngoto skip_format_initialization;\r\n} else if (!bus->read || !bus->write) {\r\nmap->reg_read = _regmap_bus_reg_read;\r\nmap->reg_write = _regmap_bus_reg_write;\r\nmap->defer_caching = false;\r\ngoto skip_format_initialization;\r\n} else {\r\nmap->reg_read = _regmap_bus_read;\r\nmap->reg_update_bits = bus->reg_update_bits;\r\n}\r\nreg_endian = regmap_get_reg_endian(bus, config);\r\nval_endian = regmap_get_val_endian(dev, bus, config);\r\nswitch (config->reg_bits + map->reg_shift) {\r\ncase 2:\r\nswitch (config->val_bits) {\r\ncase 6:\r\nmap->format.format_write = regmap_format_2_6_write;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\ncase 4:\r\nswitch (config->val_bits) {\r\ncase 12:\r\nmap->format.format_write = regmap_format_4_12_write;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\ncase 7:\r\nswitch (config->val_bits) {\r\ncase 9:\r\nmap->format.format_write = regmap_format_7_9_write;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\ncase 10:\r\nswitch (config->val_bits) {\r\ncase 14:\r\nmap->format.format_write = regmap_format_10_14_write;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\ncase 8:\r\nmap->format.format_reg = regmap_format_8;\r\nbreak;\r\ncase 16:\r\nswitch (reg_endian) {\r\ncase REGMAP_ENDIAN_BIG:\r\nmap->format.format_reg = regmap_format_16_be;\r\nbreak;\r\ncase REGMAP_ENDIAN_LITTLE:\r\nmap->format.format_reg = regmap_format_16_le;\r\nbreak;\r\ncase REGMAP_ENDIAN_NATIVE:\r\nmap->format.format_reg = regmap_format_16_native;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\ncase 24:\r\nif (reg_endian != REGMAP_ENDIAN_BIG)\r\ngoto err_map;\r\nmap->format.format_reg = regmap_format_24;\r\nbreak;\r\ncase 32:\r\nswitch (reg_endian) {\r\ncase REGMAP_ENDIAN_BIG:\r\nmap->format.format_reg = regmap_format_32_be;\r\nbreak;\r\ncase REGMAP_ENDIAN_LITTLE:\r\nmap->format.format_reg = regmap_format_32_le;\r\nbreak;\r\ncase REGMAP_ENDIAN_NATIVE:\r\nmap->format.format_reg = regmap_format_32_native;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\n#ifdef CONFIG_64BIT\r\ncase 64:\r\nswitch (reg_endian) {\r\ncase REGMAP_ENDIAN_BIG:\r\nmap->format.format_reg = regmap_format_64_be;\r\nbreak;\r\ncase REGMAP_ENDIAN_LITTLE:\r\nmap->format.format_reg = regmap_format_64_le;\r\nbreak;\r\ncase REGMAP_ENDIAN_NATIVE:\r\nmap->format.format_reg = regmap_format_64_native;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\n#endif\r\ndefault:\r\ngoto err_map;\r\n}\r\nif (val_endian == REGMAP_ENDIAN_NATIVE)\r\nmap->format.parse_inplace = regmap_parse_inplace_noop;\r\nswitch (config->val_bits) {\r\ncase 8:\r\nmap->format.format_val = regmap_format_8;\r\nmap->format.parse_val = regmap_parse_8;\r\nmap->format.parse_inplace = regmap_parse_inplace_noop;\r\nbreak;\r\ncase 16:\r\nswitch (val_endian) {\r\ncase REGMAP_ENDIAN_BIG:\r\nmap->format.format_val = regmap_format_16_be;\r\nmap->format.parse_val = regmap_parse_16_be;\r\nmap->format.parse_inplace = regmap_parse_16_be_inplace;\r\nbreak;\r\ncase REGMAP_ENDIAN_LITTLE:\r\nmap->format.format_val = regmap_format_16_le;\r\nmap->format.parse_val = regmap_parse_16_le;\r\nmap->format.parse_inplace = regmap_parse_16_le_inplace;\r\nbreak;\r\ncase REGMAP_ENDIAN_NATIVE:\r\nmap->format.format_val = regmap_format_16_native;\r\nmap->format.parse_val = regmap_parse_16_native;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\ncase 24:\r\nif (val_endian != REGMAP_ENDIAN_BIG)\r\ngoto err_map;\r\nmap->format.format_val = regmap_format_24;\r\nmap->format.parse_val = regmap_parse_24;\r\nbreak;\r\ncase 32:\r\nswitch (val_endian) {\r\ncase REGMAP_ENDIAN_BIG:\r\nmap->format.format_val = regmap_format_32_be;\r\nmap->format.parse_val = regmap_parse_32_be;\r\nmap->format.parse_inplace = regmap_parse_32_be_inplace;\r\nbreak;\r\ncase REGMAP_ENDIAN_LITTLE:\r\nmap->format.format_val = regmap_format_32_le;\r\nmap->format.parse_val = regmap_parse_32_le;\r\nmap->format.parse_inplace = regmap_parse_32_le_inplace;\r\nbreak;\r\ncase REGMAP_ENDIAN_NATIVE:\r\nmap->format.format_val = regmap_format_32_native;\r\nmap->format.parse_val = regmap_parse_32_native;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\n#ifdef CONFIG_64BIT\r\ncase 64:\r\nswitch (val_endian) {\r\ncase REGMAP_ENDIAN_BIG:\r\nmap->format.format_val = regmap_format_64_be;\r\nmap->format.parse_val = regmap_parse_64_be;\r\nmap->format.parse_inplace = regmap_parse_64_be_inplace;\r\nbreak;\r\ncase REGMAP_ENDIAN_LITTLE:\r\nmap->format.format_val = regmap_format_64_le;\r\nmap->format.parse_val = regmap_parse_64_le;\r\nmap->format.parse_inplace = regmap_parse_64_le_inplace;\r\nbreak;\r\ncase REGMAP_ENDIAN_NATIVE:\r\nmap->format.format_val = regmap_format_64_native;\r\nmap->format.parse_val = regmap_parse_64_native;\r\nbreak;\r\ndefault:\r\ngoto err_map;\r\n}\r\nbreak;\r\n#endif\r\n}\r\nif (map->format.format_write) {\r\nif ((reg_endian != REGMAP_ENDIAN_BIG) ||\r\n(val_endian != REGMAP_ENDIAN_BIG))\r\ngoto err_map;\r\nmap->use_single_write = true;\r\n}\r\nif (!map->format.format_write &&\r\n!(map->format.format_reg && map->format.format_val))\r\ngoto err_map;\r\nmap->work_buf = kzalloc(map->format.buf_size, GFP_KERNEL);\r\nif (map->work_buf == NULL) {\r\nret = -ENOMEM;\r\ngoto err_map;\r\n}\r\nif (map->format.format_write) {\r\nmap->defer_caching = false;\r\nmap->reg_write = _regmap_bus_formatted_write;\r\n} else if (map->format.format_val) {\r\nmap->defer_caching = true;\r\nmap->reg_write = _regmap_bus_raw_write;\r\n}\r\nskip_format_initialization:\r\nmap->range_tree = RB_ROOT;\r\nfor (i = 0; i < config->num_ranges; i++) {\r\nconst struct regmap_range_cfg *range_cfg = &config->ranges[i];\r\nstruct regmap_range_node *new;\r\nif (range_cfg->range_max < range_cfg->range_min) {\r\ndev_err(map->dev, "Invalid range %d: %d < %d\n", i,\r\nrange_cfg->range_max, range_cfg->range_min);\r\ngoto err_range;\r\n}\r\nif (range_cfg->range_max > map->max_register) {\r\ndev_err(map->dev, "Invalid range %d: %d > %d\n", i,\r\nrange_cfg->range_max, map->max_register);\r\ngoto err_range;\r\n}\r\nif (range_cfg->selector_reg > map->max_register) {\r\ndev_err(map->dev,\r\n"Invalid range %d: selector out of map\n", i);\r\ngoto err_range;\r\n}\r\nif (range_cfg->window_len == 0) {\r\ndev_err(map->dev, "Invalid range %d: window_len 0\n",\r\ni);\r\ngoto err_range;\r\n}\r\nfor (j = 0; j < config->num_ranges; j++) {\r\nunsigned sel_reg = config->ranges[j].selector_reg;\r\nunsigned win_min = config->ranges[j].window_start;\r\nunsigned win_max = win_min +\r\nconfig->ranges[j].window_len - 1;\r\nif (j == i)\r\ncontinue;\r\nif (range_cfg->range_min <= sel_reg &&\r\nsel_reg <= range_cfg->range_max) {\r\ndev_err(map->dev,\r\n"Range %d: selector for %d in window\n",\r\ni, j);\r\ngoto err_range;\r\n}\r\nif (!(win_max < range_cfg->range_min ||\r\nwin_min > range_cfg->range_max)) {\r\ndev_err(map->dev,\r\n"Range %d: window for %d in window\n",\r\ni, j);\r\ngoto err_range;\r\n}\r\n}\r\nnew = kzalloc(sizeof(*new), GFP_KERNEL);\r\nif (new == NULL) {\r\nret = -ENOMEM;\r\ngoto err_range;\r\n}\r\nnew->map = map;\r\nnew->name = range_cfg->name;\r\nnew->range_min = range_cfg->range_min;\r\nnew->range_max = range_cfg->range_max;\r\nnew->selector_reg = range_cfg->selector_reg;\r\nnew->selector_mask = range_cfg->selector_mask;\r\nnew->selector_shift = range_cfg->selector_shift;\r\nnew->window_start = range_cfg->window_start;\r\nnew->window_len = range_cfg->window_len;\r\nif (!_regmap_range_add(map, new)) {\r\ndev_err(map->dev, "Failed to add range %d\n", i);\r\nkfree(new);\r\ngoto err_range;\r\n}\r\nif (map->selector_work_buf == NULL) {\r\nmap->selector_work_buf =\r\nkzalloc(map->format.buf_size, GFP_KERNEL);\r\nif (map->selector_work_buf == NULL) {\r\nret = -ENOMEM;\r\ngoto err_range;\r\n}\r\n}\r\n}\r\nret = regcache_init(map, config);\r\nif (ret != 0)\r\ngoto err_range;\r\nif (dev) {\r\nret = regmap_attach_dev(dev, map, config);\r\nif (ret != 0)\r\ngoto err_regcache;\r\n}\r\nreturn map;\r\nerr_regcache:\r\nregcache_exit(map);\r\nerr_range:\r\nregmap_range_exit(map);\r\nkfree(map->work_buf);\r\nerr_map:\r\nkfree(map);\r\nerr:\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic void devm_regmap_release(struct device *dev, void *res)\r\n{\r\nregmap_exit(*(struct regmap **)res);\r\n}\r\nstruct regmap *__devm_regmap_init(struct device *dev,\r\nconst struct regmap_bus *bus,\r\nvoid *bus_context,\r\nconst struct regmap_config *config,\r\nstruct lock_class_key *lock_key,\r\nconst char *lock_name)\r\n{\r\nstruct regmap **ptr, *regmap;\r\nptr = devres_alloc(devm_regmap_release, sizeof(*ptr), GFP_KERNEL);\r\nif (!ptr)\r\nreturn ERR_PTR(-ENOMEM);\r\nregmap = __regmap_init(dev, bus, bus_context, config,\r\nlock_key, lock_name);\r\nif (!IS_ERR(regmap)) {\r\n*ptr = regmap;\r\ndevres_add(dev, ptr);\r\n} else {\r\ndevres_free(ptr);\r\n}\r\nreturn regmap;\r\n}\r\nstatic void regmap_field_init(struct regmap_field *rm_field,\r\nstruct regmap *regmap, struct reg_field reg_field)\r\n{\r\nrm_field->regmap = regmap;\r\nrm_field->reg = reg_field.reg;\r\nrm_field->shift = reg_field.lsb;\r\nrm_field->mask = GENMASK(reg_field.msb, reg_field.lsb);\r\nrm_field->id_size = reg_field.id_size;\r\nrm_field->id_offset = reg_field.id_offset;\r\n}\r\nstruct regmap_field *devm_regmap_field_alloc(struct device *dev,\r\nstruct regmap *regmap, struct reg_field reg_field)\r\n{\r\nstruct regmap_field *rm_field = devm_kzalloc(dev,\r\nsizeof(*rm_field), GFP_KERNEL);\r\nif (!rm_field)\r\nreturn ERR_PTR(-ENOMEM);\r\nregmap_field_init(rm_field, regmap, reg_field);\r\nreturn rm_field;\r\n}\r\nvoid devm_regmap_field_free(struct device *dev,\r\nstruct regmap_field *field)\r\n{\r\ndevm_kfree(dev, field);\r\n}\r\nstruct regmap_field *regmap_field_alloc(struct regmap *regmap,\r\nstruct reg_field reg_field)\r\n{\r\nstruct regmap_field *rm_field = kzalloc(sizeof(*rm_field), GFP_KERNEL);\r\nif (!rm_field)\r\nreturn ERR_PTR(-ENOMEM);\r\nregmap_field_init(rm_field, regmap, reg_field);\r\nreturn rm_field;\r\n}\r\nvoid regmap_field_free(struct regmap_field *field)\r\n{\r\nkfree(field);\r\n}\r\nint regmap_reinit_cache(struct regmap *map, const struct regmap_config *config)\r\n{\r\nregcache_exit(map);\r\nregmap_debugfs_exit(map);\r\nmap->max_register = config->max_register;\r\nmap->writeable_reg = config->writeable_reg;\r\nmap->readable_reg = config->readable_reg;\r\nmap->volatile_reg = config->volatile_reg;\r\nmap->precious_reg = config->precious_reg;\r\nmap->cache_type = config->cache_type;\r\nregmap_debugfs_init(map, config->name);\r\nmap->cache_bypass = false;\r\nmap->cache_only = false;\r\nreturn regcache_init(map, config);\r\n}\r\nvoid regmap_exit(struct regmap *map)\r\n{\r\nstruct regmap_async *async;\r\nregcache_exit(map);\r\nregmap_debugfs_exit(map);\r\nregmap_range_exit(map);\r\nif (map->bus && map->bus->free_context)\r\nmap->bus->free_context(map->bus_context);\r\nkfree(map->work_buf);\r\nwhile (!list_empty(&map->async_free)) {\r\nasync = list_first_entry_or_null(&map->async_free,\r\nstruct regmap_async,\r\nlist);\r\nlist_del(&async->list);\r\nkfree(async->work_buf);\r\nkfree(async);\r\n}\r\nkfree(map);\r\n}\r\nstatic int dev_get_regmap_match(struct device *dev, void *res, void *data)\r\n{\r\nstruct regmap **r = res;\r\nif (!r || !*r) {\r\nWARN_ON(!r || !*r);\r\nreturn 0;\r\n}\r\nif (data)\r\nreturn (*r)->name == data;\r\nelse\r\nreturn 1;\r\n}\r\nstruct regmap *dev_get_regmap(struct device *dev, const char *name)\r\n{\r\nstruct regmap **r = devres_find(dev, dev_get_regmap_release,\r\ndev_get_regmap_match, (void *)name);\r\nif (!r)\r\nreturn NULL;\r\nreturn *r;\r\n}\r\nstruct device *regmap_get_device(struct regmap *map)\r\n{\r\nreturn map->dev;\r\n}\r\nstatic int _regmap_select_page(struct regmap *map, unsigned int *reg,\r\nstruct regmap_range_node *range,\r\nunsigned int val_num)\r\n{\r\nvoid *orig_work_buf;\r\nunsigned int win_offset;\r\nunsigned int win_page;\r\nbool page_chg;\r\nint ret;\r\nwin_offset = (*reg - range->range_min) % range->window_len;\r\nwin_page = (*reg - range->range_min) / range->window_len;\r\nif (val_num > 1) {\r\nif (*reg + val_num - 1 > range->range_max)\r\nreturn -EINVAL;\r\nif (val_num > range->window_len - win_offset)\r\nreturn -EINVAL;\r\n}\r\nif (val_num > 1 ||\r\nrange->window_start + win_offset != range->selector_reg) {\r\norig_work_buf = map->work_buf;\r\nmap->work_buf = map->selector_work_buf;\r\nret = _regmap_update_bits(map, range->selector_reg,\r\nrange->selector_mask,\r\nwin_page << range->selector_shift,\r\n&page_chg, false);\r\nmap->work_buf = orig_work_buf;\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\n*reg = range->window_start + win_offset;\r\nreturn 0;\r\n}\r\nstatic void regmap_set_work_buf_flag_mask(struct regmap *map, int max_bytes,\r\nunsigned long mask)\r\n{\r\nu8 *buf;\r\nint i;\r\nif (!mask || !map->work_buf)\r\nreturn;\r\nbuf = map->work_buf;\r\nfor (i = 0; i < max_bytes; i++)\r\nbuf[i] |= (mask >> (8 * i)) & 0xff;\r\n}\r\nint _regmap_raw_write(struct regmap *map, unsigned int reg,\r\nconst void *val, size_t val_len)\r\n{\r\nstruct regmap_range_node *range;\r\nunsigned long flags;\r\nvoid *work_val = map->work_buf + map->format.reg_bytes +\r\nmap->format.pad_bytes;\r\nvoid *buf;\r\nint ret = -ENOTSUPP;\r\nsize_t len;\r\nint i;\r\nWARN_ON(!map->bus);\r\nif (map->writeable_reg)\r\nfor (i = 0; i < val_len / map->format.val_bytes; i++)\r\nif (!map->writeable_reg(map->dev,\r\nreg + regmap_get_offset(map, i)))\r\nreturn -EINVAL;\r\nif (!map->cache_bypass && map->format.parse_val) {\r\nunsigned int ival;\r\nint val_bytes = map->format.val_bytes;\r\nfor (i = 0; i < val_len / val_bytes; i++) {\r\nival = map->format.parse_val(val + (i * val_bytes));\r\nret = regcache_write(map,\r\nreg + regmap_get_offset(map, i),\r\nival);\r\nif (ret) {\r\ndev_err(map->dev,\r\n"Error in caching of register: %x ret: %d\n",\r\nreg + i, ret);\r\nreturn ret;\r\n}\r\n}\r\nif (map->cache_only) {\r\nmap->cache_dirty = true;\r\nreturn 0;\r\n}\r\n}\r\nrange = _regmap_range_lookup(map, reg);\r\nif (range) {\r\nint val_num = val_len / map->format.val_bytes;\r\nint win_offset = (reg - range->range_min) % range->window_len;\r\nint win_residue = range->window_len - win_offset;\r\nwhile (val_num > win_residue) {\r\ndev_dbg(map->dev, "Writing window %d/%zu\n",\r\nwin_residue, val_len / map->format.val_bytes);\r\nret = _regmap_raw_write(map, reg, val, win_residue *\r\nmap->format.val_bytes);\r\nif (ret != 0)\r\nreturn ret;\r\nreg += win_residue;\r\nval_num -= win_residue;\r\nval += win_residue * map->format.val_bytes;\r\nval_len -= win_residue * map->format.val_bytes;\r\nwin_offset = (reg - range->range_min) %\r\nrange->window_len;\r\nwin_residue = range->window_len - win_offset;\r\n}\r\nret = _regmap_select_page(map, &reg, range, val_num);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\nmap->format.format_reg(map->work_buf, reg, map->reg_shift);\r\nregmap_set_work_buf_flag_mask(map, map->format.reg_bytes,\r\nmap->write_flag_mask);\r\nif (val != work_val && val_len == map->format.val_bytes) {\r\nmemcpy(work_val, val, map->format.val_bytes);\r\nval = work_val;\r\n}\r\nif (map->async && map->bus->async_write) {\r\nstruct regmap_async *async;\r\ntrace_regmap_async_write_start(map, reg, val_len);\r\nspin_lock_irqsave(&map->async_lock, flags);\r\nasync = list_first_entry_or_null(&map->async_free,\r\nstruct regmap_async,\r\nlist);\r\nif (async)\r\nlist_del(&async->list);\r\nspin_unlock_irqrestore(&map->async_lock, flags);\r\nif (!async) {\r\nasync = map->bus->async_alloc();\r\nif (!async)\r\nreturn -ENOMEM;\r\nasync->work_buf = kzalloc(map->format.buf_size,\r\nGFP_KERNEL | GFP_DMA);\r\nif (!async->work_buf) {\r\nkfree(async);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nasync->map = map;\r\nmemcpy(async->work_buf, map->work_buf, map->format.pad_bytes +\r\nmap->format.reg_bytes + map->format.val_bytes);\r\nspin_lock_irqsave(&map->async_lock, flags);\r\nlist_add_tail(&async->list, &map->async_list);\r\nspin_unlock_irqrestore(&map->async_lock, flags);\r\nif (val != work_val)\r\nret = map->bus->async_write(map->bus_context,\r\nasync->work_buf,\r\nmap->format.reg_bytes +\r\nmap->format.pad_bytes,\r\nval, val_len, async);\r\nelse\r\nret = map->bus->async_write(map->bus_context,\r\nasync->work_buf,\r\nmap->format.reg_bytes +\r\nmap->format.pad_bytes +\r\nval_len, NULL, 0, async);\r\nif (ret != 0) {\r\ndev_err(map->dev, "Failed to schedule write: %d\n",\r\nret);\r\nspin_lock_irqsave(&map->async_lock, flags);\r\nlist_move(&async->list, &map->async_free);\r\nspin_unlock_irqrestore(&map->async_lock, flags);\r\n}\r\nreturn ret;\r\n}\r\ntrace_regmap_hw_write_start(map, reg, val_len / map->format.val_bytes);\r\nif (val == work_val)\r\nret = map->bus->write(map->bus_context, map->work_buf,\r\nmap->format.reg_bytes +\r\nmap->format.pad_bytes +\r\nval_len);\r\nelse if (map->bus->gather_write)\r\nret = map->bus->gather_write(map->bus_context, map->work_buf,\r\nmap->format.reg_bytes +\r\nmap->format.pad_bytes,\r\nval, val_len);\r\nif (ret == -ENOTSUPP) {\r\nlen = map->format.reg_bytes + map->format.pad_bytes + val_len;\r\nbuf = kzalloc(len, GFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\nmemcpy(buf, map->work_buf, map->format.reg_bytes);\r\nmemcpy(buf + map->format.reg_bytes + map->format.pad_bytes,\r\nval, val_len);\r\nret = map->bus->write(map->bus_context, buf, len);\r\nkfree(buf);\r\n} else if (ret != 0 && !map->cache_bypass && map->format.parse_val) {\r\nif (map->cache_ops && map->cache_ops->drop)\r\nmap->cache_ops->drop(map, reg, reg + 1);\r\n}\r\ntrace_regmap_hw_write_done(map, reg, val_len / map->format.val_bytes);\r\nreturn ret;\r\n}\r\nbool regmap_can_raw_write(struct regmap *map)\r\n{\r\nreturn map->bus && map->bus->write && map->format.format_val &&\r\nmap->format.format_reg;\r\n}\r\nsize_t regmap_get_raw_read_max(struct regmap *map)\r\n{\r\nreturn map->max_raw_read;\r\n}\r\nsize_t regmap_get_raw_write_max(struct regmap *map)\r\n{\r\nreturn map->max_raw_write;\r\n}\r\nstatic int _regmap_bus_formatted_write(void *context, unsigned int reg,\r\nunsigned int val)\r\n{\r\nint ret;\r\nstruct regmap_range_node *range;\r\nstruct regmap *map = context;\r\nWARN_ON(!map->bus || !map->format.format_write);\r\nrange = _regmap_range_lookup(map, reg);\r\nif (range) {\r\nret = _regmap_select_page(map, &reg, range, 1);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\nmap->format.format_write(map, reg, val);\r\ntrace_regmap_hw_write_start(map, reg, 1);\r\nret = map->bus->write(map->bus_context, map->work_buf,\r\nmap->format.buf_size);\r\ntrace_regmap_hw_write_done(map, reg, 1);\r\nreturn ret;\r\n}\r\nstatic int _regmap_bus_reg_write(void *context, unsigned int reg,\r\nunsigned int val)\r\n{\r\nstruct regmap *map = context;\r\nreturn map->bus->reg_write(map->bus_context, reg, val);\r\n}\r\nstatic int _regmap_bus_raw_write(void *context, unsigned int reg,\r\nunsigned int val)\r\n{\r\nstruct regmap *map = context;\r\nWARN_ON(!map->bus || !map->format.format_val);\r\nmap->format.format_val(map->work_buf + map->format.reg_bytes\r\n+ map->format.pad_bytes, val, 0);\r\nreturn _regmap_raw_write(map, reg,\r\nmap->work_buf +\r\nmap->format.reg_bytes +\r\nmap->format.pad_bytes,\r\nmap->format.val_bytes);\r\n}\r\nstatic inline void *_regmap_map_get_context(struct regmap *map)\r\n{\r\nreturn (map->bus) ? map : map->bus_context;\r\n}\r\nint _regmap_write(struct regmap *map, unsigned int reg,\r\nunsigned int val)\r\n{\r\nint ret;\r\nvoid *context = _regmap_map_get_context(map);\r\nif (!regmap_writeable(map, reg))\r\nreturn -EIO;\r\nif (!map->cache_bypass && !map->defer_caching) {\r\nret = regcache_write(map, reg, val);\r\nif (ret != 0)\r\nreturn ret;\r\nif (map->cache_only) {\r\nmap->cache_dirty = true;\r\nreturn 0;\r\n}\r\n}\r\n#ifdef LOG_DEVICE\r\nif (map->dev && strcmp(dev_name(map->dev), LOG_DEVICE) == 0)\r\ndev_info(map->dev, "%x <= %x\n", reg, val);\r\n#endif\r\ntrace_regmap_reg_write(map, reg, val);\r\nreturn map->reg_write(context, reg, val);\r\n}\r\nint regmap_write(struct regmap *map, unsigned int reg, unsigned int val)\r\n{\r\nint ret;\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\nmap->lock(map->lock_arg);\r\nret = _regmap_write(map, reg, val);\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nint regmap_write_async(struct regmap *map, unsigned int reg, unsigned int val)\r\n{\r\nint ret;\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\nmap->lock(map->lock_arg);\r\nmap->async = true;\r\nret = _regmap_write(map, reg, val);\r\nmap->async = false;\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nint regmap_raw_write(struct regmap *map, unsigned int reg,\r\nconst void *val, size_t val_len)\r\n{\r\nint ret;\r\nif (!regmap_can_raw_write(map))\r\nreturn -EINVAL;\r\nif (val_len % map->format.val_bytes)\r\nreturn -EINVAL;\r\nif (map->max_raw_write && map->max_raw_write > val_len)\r\nreturn -E2BIG;\r\nmap->lock(map->lock_arg);\r\nret = _regmap_raw_write(map, reg, val, val_len);\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nint regmap_field_update_bits_base(struct regmap_field *field,\r\nunsigned int mask, unsigned int val,\r\nbool *change, bool async, bool force)\r\n{\r\nmask = (mask << field->shift) & field->mask;\r\nreturn regmap_update_bits_base(field->regmap, field->reg,\r\nmask, val << field->shift,\r\nchange, async, force);\r\n}\r\nint regmap_fields_update_bits_base(struct regmap_field *field, unsigned int id,\r\nunsigned int mask, unsigned int val,\r\nbool *change, bool async, bool force)\r\n{\r\nif (id >= field->id_size)\r\nreturn -EINVAL;\r\nmask = (mask << field->shift) & field->mask;\r\nreturn regmap_update_bits_base(field->regmap,\r\nfield->reg + (field->id_offset * id),\r\nmask, val << field->shift,\r\nchange, async, force);\r\n}\r\nint regmap_bulk_write(struct regmap *map, unsigned int reg, const void *val,\r\nsize_t val_count)\r\n{\r\nint ret = 0, i;\r\nsize_t val_bytes = map->format.val_bytes;\r\nsize_t total_size = val_bytes * val_count;\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\nif (!map->bus) {\r\nmap->lock(map->lock_arg);\r\nfor (i = 0; i < val_count; i++) {\r\nunsigned int ival;\r\nswitch (val_bytes) {\r\ncase 1:\r\nival = *(u8 *)(val + (i * val_bytes));\r\nbreak;\r\ncase 2:\r\nival = *(u16 *)(val + (i * val_bytes));\r\nbreak;\r\ncase 4:\r\nival = *(u32 *)(val + (i * val_bytes));\r\nbreak;\r\n#ifdef CONFIG_64BIT\r\ncase 8:\r\nival = *(u64 *)(val + (i * val_bytes));\r\nbreak;\r\n#endif\r\ndefault:\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nret = _regmap_write(map,\r\nreg + regmap_get_offset(map, i),\r\nival);\r\nif (ret != 0)\r\ngoto out;\r\n}\r\nout:\r\nmap->unlock(map->lock_arg);\r\n} else if (map->bus && !map->format.parse_inplace) {\r\nconst u8 *u8 = val;\r\nconst u16 *u16 = val;\r\nconst u32 *u32 = val;\r\nunsigned int ival;\r\nfor (i = 0; i < val_count; i++) {\r\nswitch (map->format.val_bytes) {\r\ncase 4:\r\nival = u32[i];\r\nbreak;\r\ncase 2:\r\nival = u16[i];\r\nbreak;\r\ncase 1:\r\nival = u8[i];\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nret = regmap_write(map, reg + (i * map->reg_stride),\r\nival);\r\nif (ret)\r\nreturn ret;\r\n}\r\n} else if (map->use_single_write ||\r\n(map->max_raw_write && map->max_raw_write < total_size)) {\r\nint chunk_stride = map->reg_stride;\r\nsize_t chunk_size = val_bytes;\r\nsize_t chunk_count = val_count;\r\nif (!map->use_single_write) {\r\nchunk_size = map->max_raw_write;\r\nif (chunk_size % val_bytes)\r\nchunk_size -= chunk_size % val_bytes;\r\nchunk_count = total_size / chunk_size;\r\nchunk_stride *= chunk_size / val_bytes;\r\n}\r\nmap->lock(map->lock_arg);\r\nfor (i = 0; i < chunk_count; i++) {\r\nret = _regmap_raw_write(map,\r\nreg + (i * chunk_stride),\r\nval + (i * chunk_size),\r\nchunk_size);\r\nif (ret)\r\nbreak;\r\n}\r\nif (!ret && chunk_size * i < total_size) {\r\nret = _regmap_raw_write(map, reg + (i * chunk_stride),\r\nval + (i * chunk_size),\r\ntotal_size - i * chunk_size);\r\n}\r\nmap->unlock(map->lock_arg);\r\n} else {\r\nvoid *wval;\r\nif (!val_count)\r\nreturn -EINVAL;\r\nwval = kmemdup(val, val_count * val_bytes, map->alloc_flags);\r\nif (!wval) {\r\ndev_err(map->dev, "Error in memory allocation\n");\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < val_count * val_bytes; i += val_bytes)\r\nmap->format.parse_inplace(wval + i);\r\nmap->lock(map->lock_arg);\r\nret = _regmap_raw_write(map, reg, wval, val_bytes * val_count);\r\nmap->unlock(map->lock_arg);\r\nkfree(wval);\r\n}\r\nreturn ret;\r\n}\r\nstatic int _regmap_raw_multi_reg_write(struct regmap *map,\r\nconst struct reg_sequence *regs,\r\nsize_t num_regs)\r\n{\r\nint ret;\r\nvoid *buf;\r\nint i;\r\nu8 *u8;\r\nsize_t val_bytes = map->format.val_bytes;\r\nsize_t reg_bytes = map->format.reg_bytes;\r\nsize_t pad_bytes = map->format.pad_bytes;\r\nsize_t pair_size = reg_bytes + pad_bytes + val_bytes;\r\nsize_t len = pair_size * num_regs;\r\nif (!len)\r\nreturn -EINVAL;\r\nbuf = kzalloc(len, GFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\nu8 = buf;\r\nfor (i = 0; i < num_regs; i++) {\r\nunsigned int reg = regs[i].reg;\r\nunsigned int val = regs[i].def;\r\ntrace_regmap_hw_write_start(map, reg, 1);\r\nmap->format.format_reg(u8, reg, map->reg_shift);\r\nu8 += reg_bytes + pad_bytes;\r\nmap->format.format_val(u8, val, 0);\r\nu8 += val_bytes;\r\n}\r\nu8 = buf;\r\n*u8 |= map->write_flag_mask;\r\nret = map->bus->write(map->bus_context, buf, len);\r\nkfree(buf);\r\nfor (i = 0; i < num_regs; i++) {\r\nint reg = regs[i].reg;\r\ntrace_regmap_hw_write_done(map, reg, 1);\r\n}\r\nreturn ret;\r\n}\r\nstatic unsigned int _regmap_register_page(struct regmap *map,\r\nunsigned int reg,\r\nstruct regmap_range_node *range)\r\n{\r\nunsigned int win_page = (reg - range->range_min) / range->window_len;\r\nreturn win_page;\r\n}\r\nstatic int _regmap_range_multi_paged_reg_write(struct regmap *map,\r\nstruct reg_sequence *regs,\r\nsize_t num_regs)\r\n{\r\nint ret;\r\nint i, n;\r\nstruct reg_sequence *base;\r\nunsigned int this_page = 0;\r\nunsigned int page_change = 0;\r\nbase = regs;\r\nfor (i = 0, n = 0; i < num_regs; i++, n++) {\r\nunsigned int reg = regs[i].reg;\r\nstruct regmap_range_node *range;\r\nrange = _regmap_range_lookup(map, reg);\r\nif (range) {\r\nunsigned int win_page = _regmap_register_page(map, reg,\r\nrange);\r\nif (i == 0)\r\nthis_page = win_page;\r\nif (win_page != this_page) {\r\nthis_page = win_page;\r\npage_change = 1;\r\n}\r\n}\r\nif (page_change || regs[i].delay_us) {\r\nif (regs[i].delay_us && i == 0)\r\nn = 1;\r\nret = _regmap_raw_multi_reg_write(map, base, n);\r\nif (ret != 0)\r\nreturn ret;\r\nif (regs[i].delay_us)\r\nudelay(regs[i].delay_us);\r\nbase += n;\r\nn = 0;\r\nif (page_change) {\r\nret = _regmap_select_page(map,\r\n&base[n].reg,\r\nrange, 1);\r\nif (ret != 0)\r\nreturn ret;\r\npage_change = 0;\r\n}\r\n}\r\n}\r\nif (n > 0)\r\nreturn _regmap_raw_multi_reg_write(map, base, n);\r\nreturn 0;\r\n}\r\nstatic int _regmap_multi_reg_write(struct regmap *map,\r\nconst struct reg_sequence *regs,\r\nsize_t num_regs)\r\n{\r\nint i;\r\nint ret;\r\nif (!map->can_multi_write) {\r\nfor (i = 0; i < num_regs; i++) {\r\nret = _regmap_write(map, regs[i].reg, regs[i].def);\r\nif (ret != 0)\r\nreturn ret;\r\nif (regs[i].delay_us)\r\nudelay(regs[i].delay_us);\r\n}\r\nreturn 0;\r\n}\r\nif (!map->format.parse_inplace)\r\nreturn -EINVAL;\r\nif (map->writeable_reg)\r\nfor (i = 0; i < num_regs; i++) {\r\nint reg = regs[i].reg;\r\nif (!map->writeable_reg(map->dev, reg))\r\nreturn -EINVAL;\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\n}\r\nif (!map->cache_bypass) {\r\nfor (i = 0; i < num_regs; i++) {\r\nunsigned int val = regs[i].def;\r\nunsigned int reg = regs[i].reg;\r\nret = regcache_write(map, reg, val);\r\nif (ret) {\r\ndev_err(map->dev,\r\n"Error in caching of register: %x ret: %d\n",\r\nreg, ret);\r\nreturn ret;\r\n}\r\n}\r\nif (map->cache_only) {\r\nmap->cache_dirty = true;\r\nreturn 0;\r\n}\r\n}\r\nWARN_ON(!map->bus);\r\nfor (i = 0; i < num_regs; i++) {\r\nunsigned int reg = regs[i].reg;\r\nstruct regmap_range_node *range;\r\nrange = _regmap_range_lookup(map, reg);\r\nif (range || regs[i].delay_us) {\r\nsize_t len = sizeof(struct reg_sequence)*num_regs;\r\nstruct reg_sequence *base = kmemdup(regs, len,\r\nGFP_KERNEL);\r\nif (!base)\r\nreturn -ENOMEM;\r\nret = _regmap_range_multi_paged_reg_write(map, base,\r\nnum_regs);\r\nkfree(base);\r\nreturn ret;\r\n}\r\n}\r\nreturn _regmap_raw_multi_reg_write(map, regs, num_regs);\r\n}\r\nint regmap_multi_reg_write(struct regmap *map, const struct reg_sequence *regs,\r\nint num_regs)\r\n{\r\nint ret;\r\nmap->lock(map->lock_arg);\r\nret = _regmap_multi_reg_write(map, regs, num_regs);\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nint regmap_multi_reg_write_bypassed(struct regmap *map,\r\nconst struct reg_sequence *regs,\r\nint num_regs)\r\n{\r\nint ret;\r\nbool bypass;\r\nmap->lock(map->lock_arg);\r\nbypass = map->cache_bypass;\r\nmap->cache_bypass = true;\r\nret = _regmap_multi_reg_write(map, regs, num_regs);\r\nmap->cache_bypass = bypass;\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nint regmap_raw_write_async(struct regmap *map, unsigned int reg,\r\nconst void *val, size_t val_len)\r\n{\r\nint ret;\r\nif (val_len % map->format.val_bytes)\r\nreturn -EINVAL;\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\nmap->lock(map->lock_arg);\r\nmap->async = true;\r\nret = _regmap_raw_write(map, reg, val, val_len);\r\nmap->async = false;\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nstatic int _regmap_raw_read(struct regmap *map, unsigned int reg, void *val,\r\nunsigned int val_len)\r\n{\r\nstruct regmap_range_node *range;\r\nint ret;\r\nWARN_ON(!map->bus);\r\nif (!map->bus || !map->bus->read)\r\nreturn -EINVAL;\r\nrange = _regmap_range_lookup(map, reg);\r\nif (range) {\r\nret = _regmap_select_page(map, &reg, range,\r\nval_len / map->format.val_bytes);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\nmap->format.format_reg(map->work_buf, reg, map->reg_shift);\r\nregmap_set_work_buf_flag_mask(map, map->format.reg_bytes,\r\nmap->read_flag_mask);\r\ntrace_regmap_hw_read_start(map, reg, val_len / map->format.val_bytes);\r\nret = map->bus->read(map->bus_context, map->work_buf,\r\nmap->format.reg_bytes + map->format.pad_bytes,\r\nval, val_len);\r\ntrace_regmap_hw_read_done(map, reg, val_len / map->format.val_bytes);\r\nreturn ret;\r\n}\r\nstatic int _regmap_bus_reg_read(void *context, unsigned int reg,\r\nunsigned int *val)\r\n{\r\nstruct regmap *map = context;\r\nreturn map->bus->reg_read(map->bus_context, reg, val);\r\n}\r\nstatic int _regmap_bus_read(void *context, unsigned int reg,\r\nunsigned int *val)\r\n{\r\nint ret;\r\nstruct regmap *map = context;\r\nif (!map->format.parse_val)\r\nreturn -EINVAL;\r\nret = _regmap_raw_read(map, reg, map->work_buf, map->format.val_bytes);\r\nif (ret == 0)\r\n*val = map->format.parse_val(map->work_buf);\r\nreturn ret;\r\n}\r\nstatic int _regmap_read(struct regmap *map, unsigned int reg,\r\nunsigned int *val)\r\n{\r\nint ret;\r\nvoid *context = _regmap_map_get_context(map);\r\nif (!map->cache_bypass) {\r\nret = regcache_read(map, reg, val);\r\nif (ret == 0)\r\nreturn 0;\r\n}\r\nif (map->cache_only)\r\nreturn -EBUSY;\r\nif (!regmap_readable(map, reg))\r\nreturn -EIO;\r\nret = map->reg_read(context, reg, val);\r\nif (ret == 0) {\r\n#ifdef LOG_DEVICE\r\nif (map->dev && strcmp(dev_name(map->dev), LOG_DEVICE) == 0)\r\ndev_info(map->dev, "%x => %x\n", reg, *val);\r\n#endif\r\ntrace_regmap_reg_read(map, reg, *val);\r\nif (!map->cache_bypass)\r\nregcache_write(map, reg, *val);\r\n}\r\nreturn ret;\r\n}\r\nint regmap_read(struct regmap *map, unsigned int reg, unsigned int *val)\r\n{\r\nint ret;\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\nmap->lock(map->lock_arg);\r\nret = _regmap_read(map, reg, val);\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nint regmap_raw_read(struct regmap *map, unsigned int reg, void *val,\r\nsize_t val_len)\r\n{\r\nsize_t val_bytes = map->format.val_bytes;\r\nsize_t val_count = val_len / val_bytes;\r\nunsigned int v;\r\nint ret, i;\r\nif (!map->bus)\r\nreturn -EINVAL;\r\nif (val_len % map->format.val_bytes)\r\nreturn -EINVAL;\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\nif (val_count == 0)\r\nreturn -EINVAL;\r\nmap->lock(map->lock_arg);\r\nif (regmap_volatile_range(map, reg, val_count) || map->cache_bypass ||\r\nmap->cache_type == REGCACHE_NONE) {\r\nif (!map->bus->read) {\r\nret = -ENOTSUPP;\r\ngoto out;\r\n}\r\nif (map->max_raw_read && map->max_raw_read < val_len) {\r\nret = -E2BIG;\r\ngoto out;\r\n}\r\nret = _regmap_raw_read(map, reg, val, val_len);\r\n} else {\r\nfor (i = 0; i < val_count; i++) {\r\nret = _regmap_read(map, reg + regmap_get_offset(map, i),\r\n&v);\r\nif (ret != 0)\r\ngoto out;\r\nmap->format.format_val(val + (i * val_bytes), v, 0);\r\n}\r\n}\r\nout:\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nint regmap_field_read(struct regmap_field *field, unsigned int *val)\r\n{\r\nint ret;\r\nunsigned int reg_val;\r\nret = regmap_read(field->regmap, field->reg, &reg_val);\r\nif (ret != 0)\r\nreturn ret;\r\nreg_val &= field->mask;\r\nreg_val >>= field->shift;\r\n*val = reg_val;\r\nreturn ret;\r\n}\r\nint regmap_fields_read(struct regmap_field *field, unsigned int id,\r\nunsigned int *val)\r\n{\r\nint ret;\r\nunsigned int reg_val;\r\nif (id >= field->id_size)\r\nreturn -EINVAL;\r\nret = regmap_read(field->regmap,\r\nfield->reg + (field->id_offset * id),\r\n&reg_val);\r\nif (ret != 0)\r\nreturn ret;\r\nreg_val &= field->mask;\r\nreg_val >>= field->shift;\r\n*val = reg_val;\r\nreturn ret;\r\n}\r\nint regmap_bulk_read(struct regmap *map, unsigned int reg, void *val,\r\nsize_t val_count)\r\n{\r\nint ret, i;\r\nsize_t val_bytes = map->format.val_bytes;\r\nbool vol = regmap_volatile_range(map, reg, val_count);\r\nif (!IS_ALIGNED(reg, map->reg_stride))\r\nreturn -EINVAL;\r\nif (map->bus && map->format.parse_inplace && (vol || map->cache_type == REGCACHE_NONE)) {\r\nsize_t total_size = val_bytes * val_count;\r\nif (!map->use_single_read &&\r\n(!map->max_raw_read || map->max_raw_read > total_size)) {\r\nret = regmap_raw_read(map, reg, val,\r\nval_bytes * val_count);\r\nif (ret != 0)\r\nreturn ret;\r\n} else {\r\nint chunk_stride = map->reg_stride;\r\nsize_t chunk_size = val_bytes;\r\nsize_t chunk_count = val_count;\r\nif (!map->use_single_read) {\r\nchunk_size = map->max_raw_read;\r\nif (chunk_size % val_bytes)\r\nchunk_size -= chunk_size % val_bytes;\r\nchunk_count = total_size / chunk_size;\r\nchunk_stride *= chunk_size / val_bytes;\r\n}\r\nfor (i = 0; i < chunk_count; i++) {\r\nret = regmap_raw_read(map,\r\nreg + (i * chunk_stride),\r\nval + (i * chunk_size),\r\nchunk_size);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\nif (chunk_size * i < total_size) {\r\nret = regmap_raw_read(map,\r\nreg + (i * chunk_stride),\r\nval + (i * chunk_size),\r\ntotal_size - i * chunk_size);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\n}\r\nfor (i = 0; i < val_count * val_bytes; i += val_bytes)\r\nmap->format.parse_inplace(val + i);\r\n} else {\r\nfor (i = 0; i < val_count; i++) {\r\nunsigned int ival;\r\nret = regmap_read(map, reg + regmap_get_offset(map, i),\r\n&ival);\r\nif (ret != 0)\r\nreturn ret;\r\nif (map->format.format_val) {\r\nmap->format.format_val(val + (i * val_bytes), ival, 0);\r\n} else {\r\n#ifdef CONFIG_64BIT\r\nu64 *u64 = val;\r\n#endif\r\nu32 *u32 = val;\r\nu16 *u16 = val;\r\nu8 *u8 = val;\r\nswitch (map->format.val_bytes) {\r\n#ifdef CONFIG_64BIT\r\ncase 8:\r\nu64[i] = ival;\r\nbreak;\r\n#endif\r\ncase 4:\r\nu32[i] = ival;\r\nbreak;\r\ncase 2:\r\nu16[i] = ival;\r\nbreak;\r\ncase 1:\r\nu8[i] = ival;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int _regmap_update_bits(struct regmap *map, unsigned int reg,\r\nunsigned int mask, unsigned int val,\r\nbool *change, bool force_write)\r\n{\r\nint ret;\r\nunsigned int tmp, orig;\r\nif (change)\r\n*change = false;\r\nif (regmap_volatile(map, reg) && map->reg_update_bits) {\r\nret = map->reg_update_bits(map->bus_context, reg, mask, val);\r\nif (ret == 0 && change)\r\n*change = true;\r\n} else {\r\nret = _regmap_read(map, reg, &orig);\r\nif (ret != 0)\r\nreturn ret;\r\ntmp = orig & ~mask;\r\ntmp |= val & mask;\r\nif (force_write || (tmp != orig)) {\r\nret = _regmap_write(map, reg, tmp);\r\nif (ret == 0 && change)\r\n*change = true;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nint regmap_update_bits_base(struct regmap *map, unsigned int reg,\r\nunsigned int mask, unsigned int val,\r\nbool *change, bool async, bool force)\r\n{\r\nint ret;\r\nmap->lock(map->lock_arg);\r\nmap->async = async;\r\nret = _regmap_update_bits(map, reg, mask, val, change, force);\r\nmap->async = false;\r\nmap->unlock(map->lock_arg);\r\nreturn ret;\r\n}\r\nvoid regmap_async_complete_cb(struct regmap_async *async, int ret)\r\n{\r\nstruct regmap *map = async->map;\r\nbool wake;\r\ntrace_regmap_async_io_complete(map);\r\nspin_lock(&map->async_lock);\r\nlist_move(&async->list, &map->async_free);\r\nwake = list_empty(&map->async_list);\r\nif (ret != 0)\r\nmap->async_ret = ret;\r\nspin_unlock(&map->async_lock);\r\nif (wake)\r\nwake_up(&map->async_waitq);\r\n}\r\nstatic int regmap_async_is_done(struct regmap *map)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&map->async_lock, flags);\r\nret = list_empty(&map->async_list);\r\nspin_unlock_irqrestore(&map->async_lock, flags);\r\nreturn ret;\r\n}\r\nint regmap_async_complete(struct regmap *map)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nif (!map->bus || !map->bus->async_write)\r\nreturn 0;\r\ntrace_regmap_async_complete_start(map);\r\nwait_event(map->async_waitq, regmap_async_is_done(map));\r\nspin_lock_irqsave(&map->async_lock, flags);\r\nret = map->async_ret;\r\nmap->async_ret = 0;\r\nspin_unlock_irqrestore(&map->async_lock, flags);\r\ntrace_regmap_async_complete_done(map);\r\nreturn ret;\r\n}\r\nint regmap_register_patch(struct regmap *map, const struct reg_sequence *regs,\r\nint num_regs)\r\n{\r\nstruct reg_sequence *p;\r\nint ret;\r\nbool bypass;\r\nif (WARN_ONCE(num_regs <= 0, "invalid registers number (%d)\n",\r\nnum_regs))\r\nreturn 0;\r\np = krealloc(map->patch,\r\nsizeof(struct reg_sequence) * (map->patch_regs + num_regs),\r\nGFP_KERNEL);\r\nif (p) {\r\nmemcpy(p + map->patch_regs, regs, num_regs * sizeof(*regs));\r\nmap->patch = p;\r\nmap->patch_regs += num_regs;\r\n} else {\r\nreturn -ENOMEM;\r\n}\r\nmap->lock(map->lock_arg);\r\nbypass = map->cache_bypass;\r\nmap->cache_bypass = true;\r\nmap->async = true;\r\nret = _regmap_multi_reg_write(map, regs, num_regs);\r\nmap->async = false;\r\nmap->cache_bypass = bypass;\r\nmap->unlock(map->lock_arg);\r\nregmap_async_complete(map);\r\nreturn ret;\r\n}\r\nint regmap_get_val_bytes(struct regmap *map)\r\n{\r\nif (map->format.format_write)\r\nreturn -EINVAL;\r\nreturn map->format.val_bytes;\r\n}\r\nint regmap_get_max_register(struct regmap *map)\r\n{\r\nreturn map->max_register ? map->max_register : -EINVAL;\r\n}\r\nint regmap_get_reg_stride(struct regmap *map)\r\n{\r\nreturn map->reg_stride;\r\n}\r\nint regmap_parse_val(struct regmap *map, const void *buf,\r\nunsigned int *val)\r\n{\r\nif (!map->format.parse_val)\r\nreturn -EINVAL;\r\n*val = map->format.parse_val(buf);\r\nreturn 0;\r\n}\r\nstatic int __init regmap_initcall(void)\r\n{\r\nregmap_debugfs_initcall();\r\nreturn 0;\r\n}
