static inline void l2c_wait_mask(void __iomem *reg, unsigned long mask)\r\n{\r\nwhile (readl_relaxed(reg) & mask)\r\ncpu_relax();\r\n}\r\nstatic void l2c_write_sec(unsigned long val, void __iomem *base, unsigned reg)\r\n{\r\nif (val == readl_relaxed(base + reg))\r\nreturn;\r\nif (outer_cache.write_sec)\r\nouter_cache.write_sec(val, reg);\r\nelse\r\nwritel_relaxed(val, base + reg);\r\n}\r\nstatic inline void l2c_set_debug(void __iomem *base, unsigned long val)\r\n{\r\nl2c_write_sec(val, base, L2X0_DEBUG_CTRL);\r\n}\r\nstatic void __l2c_op_way(void __iomem *reg)\r\n{\r\nwritel_relaxed(l2x0_way_mask, reg);\r\nl2c_wait_mask(reg, l2x0_way_mask);\r\n}\r\nstatic inline void l2c_unlock(void __iomem *base, unsigned num)\r\n{\r\nunsigned i;\r\nfor (i = 0; i < num; i++) {\r\nwritel_relaxed(0, base + L2X0_LOCKDOWN_WAY_D_BASE +\r\ni * L2X0_LOCKDOWN_STRIDE);\r\nwritel_relaxed(0, base + L2X0_LOCKDOWN_WAY_I_BASE +\r\ni * L2X0_LOCKDOWN_STRIDE);\r\n}\r\n}\r\nstatic void l2c_configure(void __iomem *base)\r\n{\r\nl2c_write_sec(l2x0_saved_regs.aux_ctrl, base, L2X0_AUX_CTRL);\r\n}\r\nstatic void l2c_enable(void __iomem *base, unsigned num_lock)\r\n{\r\nunsigned long flags;\r\nif (outer_cache.configure)\r\nouter_cache.configure(&l2x0_saved_regs);\r\nelse\r\nl2x0_data->configure(base);\r\nl2x0_data->unlock(base, num_lock);\r\nlocal_irq_save(flags);\r\n__l2c_op_way(base + L2X0_INV_WAY);\r\nwritel_relaxed(0, base + sync_reg_offset);\r\nl2c_wait_mask(base + sync_reg_offset, 1);\r\nlocal_irq_restore(flags);\r\nl2c_write_sec(L2X0_CTRL_EN, base, L2X0_CTRL);\r\n}\r\nstatic void l2c_disable(void)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nl2x0_pmu_suspend();\r\nouter_cache.flush_all();\r\nl2c_write_sec(0, base, L2X0_CTRL);\r\ndsb(st);\r\n}\r\nstatic void l2c_save(void __iomem *base)\r\n{\r\nl2x0_saved_regs.aux_ctrl = readl_relaxed(l2x0_base + L2X0_AUX_CTRL);\r\n}\r\nstatic void l2c_resume(void)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nif (!(readl_relaxed(base + L2X0_CTRL) & L2X0_CTRL_EN))\r\nl2c_enable(base, l2x0_data->num_lock);\r\nl2x0_pmu_resume();\r\n}\r\nstatic void __l2c210_cache_sync(void __iomem *base)\r\n{\r\nwritel_relaxed(0, base + sync_reg_offset);\r\n}\r\nstatic void __l2c210_op_pa_range(void __iomem *reg, unsigned long start,\r\nunsigned long end)\r\n{\r\nwhile (start < end) {\r\nwritel_relaxed(start, reg);\r\nstart += CACHE_LINE_SIZE;\r\n}\r\n}\r\nstatic void l2c210_inv_range(unsigned long start, unsigned long end)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nif (start & (CACHE_LINE_SIZE - 1)) {\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\nwritel_relaxed(start, base + L2X0_CLEAN_INV_LINE_PA);\r\nstart += CACHE_LINE_SIZE;\r\n}\r\nif (end & (CACHE_LINE_SIZE - 1)) {\r\nend &= ~(CACHE_LINE_SIZE - 1);\r\nwritel_relaxed(end, base + L2X0_CLEAN_INV_LINE_PA);\r\n}\r\n__l2c210_op_pa_range(base + L2X0_INV_LINE_PA, start, end);\r\n__l2c210_cache_sync(base);\r\n}\r\nstatic void l2c210_clean_range(unsigned long start, unsigned long end)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\n__l2c210_op_pa_range(base + L2X0_CLEAN_LINE_PA, start, end);\r\n__l2c210_cache_sync(base);\r\n}\r\nstatic void l2c210_flush_range(unsigned long start, unsigned long end)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\n__l2c210_op_pa_range(base + L2X0_CLEAN_INV_LINE_PA, start, end);\r\n__l2c210_cache_sync(base);\r\n}\r\nstatic void l2c210_flush_all(void)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nBUG_ON(!irqs_disabled());\r\n__l2c_op_way(base + L2X0_CLEAN_INV_WAY);\r\n__l2c210_cache_sync(base);\r\n}\r\nstatic void l2c210_sync(void)\r\n{\r\n__l2c210_cache_sync(l2x0_base);\r\n}\r\nstatic inline void __l2c220_cache_sync(void __iomem *base)\r\n{\r\nwritel_relaxed(0, base + L2X0_CACHE_SYNC);\r\nl2c_wait_mask(base + L2X0_CACHE_SYNC, 1);\r\n}\r\nstatic void l2c220_op_way(void __iomem *base, unsigned reg)\r\n{\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\n__l2c_op_way(base + reg);\r\n__l2c220_cache_sync(base);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\nstatic unsigned long l2c220_op_pa_range(void __iomem *reg, unsigned long start,\r\nunsigned long end, unsigned long flags)\r\n{\r\nraw_spinlock_t *lock = &l2x0_lock;\r\nwhile (start < end) {\r\nunsigned long blk_end = start + min(end - start, 4096UL);\r\nwhile (start < blk_end) {\r\nl2c_wait_mask(reg, 1);\r\nwritel_relaxed(start, reg);\r\nstart += CACHE_LINE_SIZE;\r\n}\r\nif (blk_end < end) {\r\nraw_spin_unlock_irqrestore(lock, flags);\r\nraw_spin_lock_irqsave(lock, flags);\r\n}\r\n}\r\nreturn flags;\r\n}\r\nstatic void l2c220_inv_range(unsigned long start, unsigned long end)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\nif ((start | end) & (CACHE_LINE_SIZE - 1)) {\r\nif (start & (CACHE_LINE_SIZE - 1)) {\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\nwritel_relaxed(start, base + L2X0_CLEAN_INV_LINE_PA);\r\nstart += CACHE_LINE_SIZE;\r\n}\r\nif (end & (CACHE_LINE_SIZE - 1)) {\r\nend &= ~(CACHE_LINE_SIZE - 1);\r\nl2c_wait_mask(base + L2X0_CLEAN_INV_LINE_PA, 1);\r\nwritel_relaxed(end, base + L2X0_CLEAN_INV_LINE_PA);\r\n}\r\n}\r\nflags = l2c220_op_pa_range(base + L2X0_INV_LINE_PA,\r\nstart, end, flags);\r\nl2c_wait_mask(base + L2X0_INV_LINE_PA, 1);\r\n__l2c220_cache_sync(base);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\nstatic void l2c220_clean_range(unsigned long start, unsigned long end)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nunsigned long flags;\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\nif ((end - start) >= l2x0_size) {\r\nl2c220_op_way(base, L2X0_CLEAN_WAY);\r\nreturn;\r\n}\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\nflags = l2c220_op_pa_range(base + L2X0_CLEAN_LINE_PA,\r\nstart, end, flags);\r\nl2c_wait_mask(base + L2X0_CLEAN_INV_LINE_PA, 1);\r\n__l2c220_cache_sync(base);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\nstatic void l2c220_flush_range(unsigned long start, unsigned long end)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nunsigned long flags;\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\nif ((end - start) >= l2x0_size) {\r\nl2c220_op_way(base, L2X0_CLEAN_INV_WAY);\r\nreturn;\r\n}\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\nflags = l2c220_op_pa_range(base + L2X0_CLEAN_INV_LINE_PA,\r\nstart, end, flags);\r\nl2c_wait_mask(base + L2X0_CLEAN_INV_LINE_PA, 1);\r\n__l2c220_cache_sync(base);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\nstatic void l2c220_flush_all(void)\r\n{\r\nl2c220_op_way(l2x0_base, L2X0_CLEAN_INV_WAY);\r\n}\r\nstatic void l2c220_sync(void)\r\n{\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\n__l2c220_cache_sync(l2x0_base);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\nstatic void l2c220_enable(void __iomem *base, unsigned num_lock)\r\n{\r\nl2x0_saved_regs.aux_ctrl |= L220_AUX_CTRL_NS_LOCKDOWN;\r\nl2c_enable(base, num_lock);\r\n}\r\nstatic void l2c220_unlock(void __iomem *base, unsigned num_lock)\r\n{\r\nif (readl_relaxed(base + L2X0_AUX_CTRL) & L220_AUX_CTRL_NS_LOCKDOWN)\r\nl2c_unlock(base, num_lock);\r\n}\r\nstatic void l2c310_inv_range_erratum(unsigned long start, unsigned long end)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nif ((start | end) & (CACHE_LINE_SIZE - 1)) {\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\nl2c_set_debug(base, 0x03);\r\nif (start & (CACHE_LINE_SIZE - 1)) {\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\nwritel_relaxed(start, base + L2X0_CLEAN_LINE_PA);\r\nwritel_relaxed(start, base + L2X0_INV_LINE_PA);\r\nstart += CACHE_LINE_SIZE;\r\n}\r\nif (end & (CACHE_LINE_SIZE - 1)) {\r\nend &= ~(CACHE_LINE_SIZE - 1);\r\nwritel_relaxed(end, base + L2X0_CLEAN_LINE_PA);\r\nwritel_relaxed(end, base + L2X0_INV_LINE_PA);\r\n}\r\nl2c_set_debug(base, 0x00);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\n__l2c210_op_pa_range(base + L2X0_INV_LINE_PA, start, end);\r\n__l2c210_cache_sync(base);\r\n}\r\nstatic void l2c310_flush_range_erratum(unsigned long start, unsigned long end)\r\n{\r\nraw_spinlock_t *lock = &l2x0_lock;\r\nunsigned long flags;\r\nvoid __iomem *base = l2x0_base;\r\nraw_spin_lock_irqsave(lock, flags);\r\nwhile (start < end) {\r\nunsigned long blk_end = start + min(end - start, 4096UL);\r\nl2c_set_debug(base, 0x03);\r\nwhile (start < blk_end) {\r\nwritel_relaxed(start, base + L2X0_CLEAN_LINE_PA);\r\nwritel_relaxed(start, base + L2X0_INV_LINE_PA);\r\nstart += CACHE_LINE_SIZE;\r\n}\r\nl2c_set_debug(base, 0x00);\r\nif (blk_end < end) {\r\nraw_spin_unlock_irqrestore(lock, flags);\r\nraw_spin_lock_irqsave(lock, flags);\r\n}\r\n}\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n__l2c210_cache_sync(base);\r\n}\r\nstatic void l2c310_flush_all_erratum(void)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\nl2c_set_debug(base, 0x03);\r\n__l2c_op_way(base + L2X0_CLEAN_INV_WAY);\r\nl2c_set_debug(base, 0x00);\r\n__l2c210_cache_sync(base);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\nstatic void __init l2c310_save(void __iomem *base)\r\n{\r\nunsigned revision;\r\nl2c_save(base);\r\nl2x0_saved_regs.tag_latency = readl_relaxed(base +\r\nL310_TAG_LATENCY_CTRL);\r\nl2x0_saved_regs.data_latency = readl_relaxed(base +\r\nL310_DATA_LATENCY_CTRL);\r\nl2x0_saved_regs.filter_end = readl_relaxed(base +\r\nL310_ADDR_FILTER_END);\r\nl2x0_saved_regs.filter_start = readl_relaxed(base +\r\nL310_ADDR_FILTER_START);\r\nrevision = readl_relaxed(base + L2X0_CACHE_ID) &\r\nL2X0_CACHE_ID_RTL_MASK;\r\nif (revision >= L310_CACHE_ID_RTL_R2P0)\r\nl2x0_saved_regs.prefetch_ctrl = readl_relaxed(base +\r\nL310_PREFETCH_CTRL);\r\nif (revision >= L310_CACHE_ID_RTL_R3P0)\r\nl2x0_saved_regs.pwr_ctrl = readl_relaxed(base +\r\nL310_POWER_CTRL);\r\n}\r\nstatic void l2c310_configure(void __iomem *base)\r\n{\r\nunsigned revision;\r\nl2c_configure(base);\r\nl2c_write_sec(l2x0_saved_regs.tag_latency, base,\r\nL310_TAG_LATENCY_CTRL);\r\nl2c_write_sec(l2x0_saved_regs.data_latency, base,\r\nL310_DATA_LATENCY_CTRL);\r\nl2c_write_sec(l2x0_saved_regs.filter_end, base,\r\nL310_ADDR_FILTER_END);\r\nl2c_write_sec(l2x0_saved_regs.filter_start, base,\r\nL310_ADDR_FILTER_START);\r\nrevision = readl_relaxed(base + L2X0_CACHE_ID) &\r\nL2X0_CACHE_ID_RTL_MASK;\r\nif (revision >= L310_CACHE_ID_RTL_R2P0)\r\nl2c_write_sec(l2x0_saved_regs.prefetch_ctrl, base,\r\nL310_PREFETCH_CTRL);\r\nif (revision >= L310_CACHE_ID_RTL_R3P0)\r\nl2c_write_sec(l2x0_saved_regs.pwr_ctrl, base,\r\nL310_POWER_CTRL);\r\n}\r\nstatic int l2c310_starting_cpu(unsigned int cpu)\r\n{\r\nset_auxcr(get_auxcr() | BIT(3) | BIT(2) | BIT(1));\r\nreturn 0;\r\n}\r\nstatic int l2c310_dying_cpu(unsigned int cpu)\r\n{\r\nset_auxcr(get_auxcr() & ~(BIT(3) | BIT(2) | BIT(1)));\r\nreturn 0;\r\n}\r\nstatic void __init l2c310_enable(void __iomem *base, unsigned num_lock)\r\n{\r\nunsigned rev = readl_relaxed(base + L2X0_CACHE_ID) & L2X0_CACHE_ID_RTL_MASK;\r\nbool cortex_a9 = read_cpuid_part() == ARM_CPU_PART_CORTEX_A9;\r\nu32 aux = l2x0_saved_regs.aux_ctrl;\r\nif (rev >= L310_CACHE_ID_RTL_R2P0) {\r\nif (cortex_a9 && !l2x0_bresp_disable) {\r\naux |= L310_AUX_CTRL_EARLY_BRESP;\r\npr_info("L2C-310 enabling early BRESP for Cortex-A9\n");\r\n} else if (aux & L310_AUX_CTRL_EARLY_BRESP) {\r\npr_warn("L2C-310 early BRESP only supported with Cortex-A9\n");\r\naux &= ~L310_AUX_CTRL_EARLY_BRESP;\r\n}\r\n}\r\nif (cortex_a9 && !l2x0_flz_disable) {\r\nu32 aux_cur = readl_relaxed(base + L2X0_AUX_CTRL);\r\nu32 acr = get_auxcr();\r\npr_debug("Cortex-A9 ACR=0x%08x\n", acr);\r\nif (acr & BIT(3) && !(aux_cur & L310_AUX_CTRL_FULL_LINE_ZERO))\r\npr_err("L2C-310: full line of zeros enabled in Cortex-A9 but not L2C-310 - invalid\n");\r\nif (aux & L310_AUX_CTRL_FULL_LINE_ZERO && !(acr & BIT(3)))\r\npr_err("L2C-310: enabling full line of zeros but not enabled in Cortex-A9\n");\r\nif (!(aux & L310_AUX_CTRL_FULL_LINE_ZERO) && !outer_cache.write_sec) {\r\naux |= L310_AUX_CTRL_FULL_LINE_ZERO;\r\npr_info("L2C-310 full line of zeros enabled for Cortex-A9\n");\r\n}\r\n} else if (aux & (L310_AUX_CTRL_FULL_LINE_ZERO | L310_AUX_CTRL_EARLY_BRESP)) {\r\npr_err("L2C-310: disabling Cortex-A9 specific feature bits\n");\r\naux &= ~(L310_AUX_CTRL_FULL_LINE_ZERO | L310_AUX_CTRL_EARLY_BRESP);\r\n}\r\nl2x0_saved_regs.aux_ctrl = aux | L310_AUX_CTRL_NS_LOCKDOWN;\r\nl2c_enable(base, num_lock);\r\naux = readl_relaxed(base + L2X0_AUX_CTRL);\r\nif (aux & (L310_AUX_CTRL_DATA_PREFETCH | L310_AUX_CTRL_INSTR_PREFETCH)) {\r\nu32 prefetch = readl_relaxed(base + L310_PREFETCH_CTRL);\r\npr_info("L2C-310 %s%s prefetch enabled, offset %u lines\n",\r\naux & L310_AUX_CTRL_INSTR_PREFETCH ? "I" : "",\r\naux & L310_AUX_CTRL_DATA_PREFETCH ? "D" : "",\r\n1 + (prefetch & L310_PREFETCH_CTRL_OFFSET_MASK));\r\n}\r\nif (rev >= L310_CACHE_ID_RTL_R3P0) {\r\nu32 power_ctrl;\r\npower_ctrl = readl_relaxed(base + L310_POWER_CTRL);\r\npr_info("L2C-310 dynamic clock gating %sabled, standby mode %sabled\n",\r\npower_ctrl & L310_DYNAMIC_CLK_GATING_EN ? "en" : "dis",\r\npower_ctrl & L310_STNDBY_MODE_EN ? "en" : "dis");\r\n}\r\nif (aux & L310_AUX_CTRL_FULL_LINE_ZERO)\r\ncpuhp_setup_state(CPUHP_AP_ARM_L2X0_STARTING,\r\n"arm/l2x0:starting", l2c310_starting_cpu,\r\nl2c310_dying_cpu);\r\n}\r\nstatic void __init l2c310_fixup(void __iomem *base, u32 cache_id,\r\nstruct outer_cache_fns *fns)\r\n{\r\nunsigned revision = cache_id & L2X0_CACHE_ID_RTL_MASK;\r\nconst char *errata[8];\r\nunsigned n = 0;\r\nif (IS_ENABLED(CONFIG_PL310_ERRATA_588369) &&\r\nrevision < L310_CACHE_ID_RTL_R2P0 &&\r\nfns->inv_range == l2c210_inv_range) {\r\nfns->inv_range = l2c310_inv_range_erratum;\r\nfns->flush_range = l2c310_flush_range_erratum;\r\nerrata[n++] = "588369";\r\n}\r\nif (IS_ENABLED(CONFIG_PL310_ERRATA_727915) &&\r\nrevision >= L310_CACHE_ID_RTL_R2P0 &&\r\nrevision < L310_CACHE_ID_RTL_R3P1) {\r\nfns->flush_all = l2c310_flush_all_erratum;\r\nerrata[n++] = "727915";\r\n}\r\nif (revision >= L310_CACHE_ID_RTL_R3P0 &&\r\nrevision < L310_CACHE_ID_RTL_R3P2) {\r\nu32 val = l2x0_saved_regs.prefetch_ctrl;\r\nif (val & L310_PREFETCH_CTRL_DBL_LINEFILL) {\r\nval &= ~L310_PREFETCH_CTRL_DBL_LINEFILL;\r\nl2x0_saved_regs.prefetch_ctrl = val;\r\nerrata[n++] = "752271";\r\n}\r\n}\r\nif (IS_ENABLED(CONFIG_PL310_ERRATA_753970) &&\r\nrevision == L310_CACHE_ID_RTL_R3P0) {\r\nsync_reg_offset = L2X0_DUMMY_REG;\r\nerrata[n++] = "753970";\r\n}\r\nif (IS_ENABLED(CONFIG_PL310_ERRATA_769419))\r\nerrata[n++] = "769419";\r\nif (n) {\r\nunsigned i;\r\npr_info("L2C-310 errat%s", n > 1 ? "a" : "um");\r\nfor (i = 0; i < n; i++)\r\npr_cont(" %s", errata[i]);\r\npr_cont(" enabled\n");\r\n}\r\n}\r\nstatic void l2c310_disable(void)\r\n{\r\nif (l2x0_saved_regs.aux_ctrl & L310_AUX_CTRL_FULL_LINE_ZERO)\r\nset_auxcr(get_auxcr() & ~(BIT(3) | BIT(2) | BIT(1)));\r\nl2c_disable();\r\n}\r\nstatic void l2c310_resume(void)\r\n{\r\nl2c_resume();\r\nif (l2x0_saved_regs.aux_ctrl & L310_AUX_CTRL_FULL_LINE_ZERO)\r\nset_auxcr(get_auxcr() | BIT(3) | BIT(2) | BIT(1));\r\n}\r\nstatic void l2c310_unlock(void __iomem *base, unsigned num_lock)\r\n{\r\nif (readl_relaxed(base + L2X0_AUX_CTRL) & L310_AUX_CTRL_NS_LOCKDOWN)\r\nl2c_unlock(base, num_lock);\r\n}\r\nstatic int __init __l2c_init(const struct l2c_init_data *data,\r\nu32 aux_val, u32 aux_mask, u32 cache_id, bool nosync)\r\n{\r\nstruct outer_cache_fns fns;\r\nunsigned way_size_bits, ways;\r\nu32 aux, old_aux;\r\nl2x0_data = kmemdup(data, sizeof(*data), GFP_KERNEL);\r\nif (!l2x0_data)\r\nreturn -ENOMEM;\r\nif (aux_val & aux_mask)\r\npr_alert("L2C: platform provided aux values permit register corruption.\n");\r\nold_aux = aux = readl_relaxed(l2x0_base + L2X0_AUX_CTRL);\r\naux &= aux_mask;\r\naux |= aux_val;\r\nif (old_aux != aux)\r\npr_warn("L2C: DT/platform modifies aux control register: 0x%08x -> 0x%08x\n",\r\nold_aux, aux);\r\nswitch (cache_id & L2X0_CACHE_ID_PART_MASK) {\r\ncase L2X0_CACHE_ID_PART_L310:\r\nif ((aux_val | ~aux_mask) & (L2C_AUX_CTRL_WAY_SIZE_MASK | L310_AUX_CTRL_ASSOCIATIVITY_16))\r\npr_warn("L2C: DT/platform tries to modify or specify cache size\n");\r\nif (aux & (1 << 16))\r\nways = 16;\r\nelse\r\nways = 8;\r\nbreak;\r\ncase L2X0_CACHE_ID_PART_L210:\r\ncase L2X0_CACHE_ID_PART_L220:\r\nways = (aux >> 13) & 0xf;\r\nbreak;\r\ncase AURORA_CACHE_ID:\r\nways = (aux >> 13) & 0xf;\r\nways = 2 << ((ways + 1) >> 2);\r\nbreak;\r\ndefault:\r\nways = 8;\r\nbreak;\r\n}\r\nl2x0_way_mask = (1 << ways) - 1;\r\nway_size_bits = (aux & L2C_AUX_CTRL_WAY_SIZE_MASK) >>\r\nL2C_AUX_CTRL_WAY_SIZE_SHIFT;\r\nl2x0_size = ways * (data->way_size_0 << way_size_bits);\r\nfns = data->outer_cache;\r\nfns.write_sec = outer_cache.write_sec;\r\nfns.configure = outer_cache.configure;\r\nif (data->fixup)\r\ndata->fixup(l2x0_base, cache_id, &fns);\r\nif (nosync) {\r\npr_info("L2C: disabling outer sync\n");\r\nfns.sync = NULL;\r\n}\r\nif (!(readl_relaxed(l2x0_base + L2X0_CTRL) & L2X0_CTRL_EN)) {\r\nl2x0_saved_regs.aux_ctrl = aux;\r\ndata->enable(l2x0_base, data->num_lock);\r\n}\r\nouter_cache = fns;\r\nif (data->save)\r\ndata->save(l2x0_base);\r\naux = readl_relaxed(l2x0_base + L2X0_AUX_CTRL);\r\npr_info("%s cache controller enabled, %d ways, %d kB\n",\r\ndata->type, ways, l2x0_size >> 10);\r\npr_info("%s: CACHE_ID 0x%08x, AUX_CTRL 0x%08x\n",\r\ndata->type, cache_id, aux);\r\nl2x0_pmu_register(l2x0_base, cache_id);\r\nreturn 0;\r\n}\r\nvoid __init l2x0_init(void __iomem *base, u32 aux_val, u32 aux_mask)\r\n{\r\nconst struct l2c_init_data *data;\r\nu32 cache_id;\r\nl2x0_base = base;\r\ncache_id = readl_relaxed(base + L2X0_CACHE_ID);\r\nswitch (cache_id & L2X0_CACHE_ID_PART_MASK) {\r\ndefault:\r\ncase L2X0_CACHE_ID_PART_L210:\r\ndata = &l2c210_data;\r\nbreak;\r\ncase L2X0_CACHE_ID_PART_L220:\r\ndata = &l2c220_data;\r\nbreak;\r\ncase L2X0_CACHE_ID_PART_L310:\r\ndata = &l2c310_init_fns;\r\nbreak;\r\n}\r\nif (data->save)\r\ndata->save(l2x0_base);\r\n__l2c_init(data, aux_val, aux_mask, cache_id, false);\r\n}\r\nstatic int __init l2x0_cache_size_of_parse(const struct device_node *np,\r\nu32 *aux_val, u32 *aux_mask,\r\nu32 *associativity,\r\nu32 max_way_size)\r\n{\r\nu32 mask = 0, val = 0;\r\nu32 cache_size = 0, sets = 0;\r\nu32 way_size_bits = 1;\r\nu32 way_size = 0;\r\nu32 block_size = 0;\r\nu32 line_size = 0;\r\nof_property_read_u32(np, "cache-size", &cache_size);\r\nof_property_read_u32(np, "cache-sets", &sets);\r\nof_property_read_u32(np, "cache-block-size", &block_size);\r\nof_property_read_u32(np, "cache-line-size", &line_size);\r\nif (!cache_size || !sets)\r\nreturn -ENODEV;\r\nif (!line_size) {\r\nif (block_size) {\r\nline_size = block_size;\r\n} else {\r\npr_warn("L2C OF: no cache block/line size given: "\r\n"falling back to default size %d bytes\n",\r\nCACHE_LINE_SIZE);\r\nline_size = CACHE_LINE_SIZE;\r\n}\r\n}\r\nif (line_size != CACHE_LINE_SIZE)\r\npr_warn("L2C OF: DT supplied line size %d bytes does "\r\n"not match hardware line size of %d bytes\n",\r\nline_size,\r\nCACHE_LINE_SIZE);\r\nway_size = sets * line_size;\r\n*associativity = cache_size / way_size;\r\nif (way_size > max_way_size) {\r\npr_err("L2C OF: set size %dKB is too large\n", way_size);\r\nreturn -EINVAL;\r\n}\r\npr_info("L2C OF: override cache size: %d bytes (%dKB)\n",\r\ncache_size, cache_size >> 10);\r\npr_info("L2C OF: override line size: %d bytes\n", line_size);\r\npr_info("L2C OF: override way size: %d bytes (%dKB)\n",\r\nway_size, way_size >> 10);\r\npr_info("L2C OF: override associativity: %d\n", *associativity);\r\nway_size_bits = ilog2(way_size >> 10) - 3;\r\nif (way_size_bits < 1 || way_size_bits > 6) {\r\npr_err("L2C OF: cache way size illegal: %dKB is not mapped\n",\r\nway_size);\r\nreturn -EINVAL;\r\n}\r\nmask |= L2C_AUX_CTRL_WAY_SIZE_MASK;\r\nval |= (way_size_bits << L2C_AUX_CTRL_WAY_SIZE_SHIFT);\r\n*aux_val &= ~mask;\r\n*aux_val |= val;\r\n*aux_mask &= ~mask;\r\nreturn 0;\r\n}\r\nstatic void __init l2x0_of_parse(const struct device_node *np,\r\nu32 *aux_val, u32 *aux_mask)\r\n{\r\nu32 data[2] = { 0, 0 };\r\nu32 tag = 0;\r\nu32 dirty = 0;\r\nu32 val = 0, mask = 0;\r\nu32 assoc;\r\nint ret;\r\nof_property_read_u32(np, "arm,tag-latency", &tag);\r\nif (tag) {\r\nmask |= L2X0_AUX_CTRL_TAG_LATENCY_MASK;\r\nval |= (tag - 1) << L2X0_AUX_CTRL_TAG_LATENCY_SHIFT;\r\n}\r\nof_property_read_u32_array(np, "arm,data-latency",\r\ndata, ARRAY_SIZE(data));\r\nif (data[0] && data[1]) {\r\nmask |= L2X0_AUX_CTRL_DATA_RD_LATENCY_MASK |\r\nL2X0_AUX_CTRL_DATA_WR_LATENCY_MASK;\r\nval |= ((data[0] - 1) << L2X0_AUX_CTRL_DATA_RD_LATENCY_SHIFT) |\r\n((data[1] - 1) << L2X0_AUX_CTRL_DATA_WR_LATENCY_SHIFT);\r\n}\r\nof_property_read_u32(np, "arm,dirty-latency", &dirty);\r\nif (dirty) {\r\nmask |= L2X0_AUX_CTRL_DIRTY_LATENCY_MASK;\r\nval |= (dirty - 1) << L2X0_AUX_CTRL_DIRTY_LATENCY_SHIFT;\r\n}\r\nif (of_property_read_bool(np, "arm,parity-enable")) {\r\nmask &= ~L2C_AUX_CTRL_PARITY_ENABLE;\r\nval |= L2C_AUX_CTRL_PARITY_ENABLE;\r\n} else if (of_property_read_bool(np, "arm,parity-disable")) {\r\nmask &= ~L2C_AUX_CTRL_PARITY_ENABLE;\r\n}\r\nif (of_property_read_bool(np, "arm,shared-override")) {\r\nmask &= ~L2C_AUX_CTRL_SHARED_OVERRIDE;\r\nval |= L2C_AUX_CTRL_SHARED_OVERRIDE;\r\n}\r\nret = l2x0_cache_size_of_parse(np, aux_val, aux_mask, &assoc, SZ_256K);\r\nif (ret)\r\nreturn;\r\nif (assoc > 8) {\r\npr_err("l2x0 of: cache setting yield too high associativity\n");\r\npr_err("l2x0 of: %d calculated, max 8\n", assoc);\r\n} else {\r\nmask |= L2X0_AUX_CTRL_ASSOC_MASK;\r\nval |= (assoc << L2X0_AUX_CTRL_ASSOC_SHIFT);\r\n}\r\n*aux_val &= ~mask;\r\n*aux_val |= val;\r\n*aux_mask &= ~mask;\r\n}\r\nstatic void __init l2c310_of_parse(const struct device_node *np,\r\nu32 *aux_val, u32 *aux_mask)\r\n{\r\nu32 data[3] = { 0, 0, 0 };\r\nu32 tag[3] = { 0, 0, 0 };\r\nu32 filter[2] = { 0, 0 };\r\nu32 assoc;\r\nu32 prefetch;\r\nu32 power;\r\nu32 val;\r\nint ret;\r\nof_property_read_u32_array(np, "arm,tag-latency", tag, ARRAY_SIZE(tag));\r\nif (tag[0] && tag[1] && tag[2])\r\nl2x0_saved_regs.tag_latency =\r\nL310_LATENCY_CTRL_RD(tag[0] - 1) |\r\nL310_LATENCY_CTRL_WR(tag[1] - 1) |\r\nL310_LATENCY_CTRL_SETUP(tag[2] - 1);\r\nof_property_read_u32_array(np, "arm,data-latency",\r\ndata, ARRAY_SIZE(data));\r\nif (data[0] && data[1] && data[2])\r\nl2x0_saved_regs.data_latency =\r\nL310_LATENCY_CTRL_RD(data[0] - 1) |\r\nL310_LATENCY_CTRL_WR(data[1] - 1) |\r\nL310_LATENCY_CTRL_SETUP(data[2] - 1);\r\nof_property_read_u32_array(np, "arm,filter-ranges",\r\nfilter, ARRAY_SIZE(filter));\r\nif (filter[1]) {\r\nl2x0_saved_regs.filter_end =\r\nALIGN(filter[0] + filter[1], SZ_1M);\r\nl2x0_saved_regs.filter_start = (filter[0] & ~(SZ_1M - 1))\r\n| L310_ADDR_FILTER_EN;\r\n}\r\nret = l2x0_cache_size_of_parse(np, aux_val, aux_mask, &assoc, SZ_512K);\r\nif (!ret) {\r\nswitch (assoc) {\r\ncase 16:\r\n*aux_val &= ~L2X0_AUX_CTRL_ASSOC_MASK;\r\n*aux_val |= L310_AUX_CTRL_ASSOCIATIVITY_16;\r\n*aux_mask &= ~L2X0_AUX_CTRL_ASSOC_MASK;\r\nbreak;\r\ncase 8:\r\n*aux_val &= ~L2X0_AUX_CTRL_ASSOC_MASK;\r\n*aux_mask &= ~L2X0_AUX_CTRL_ASSOC_MASK;\r\nbreak;\r\ndefault:\r\npr_err("L2C-310 OF cache associativity %d invalid, only 8 or 16 permitted\n",\r\nassoc);\r\nbreak;\r\n}\r\n}\r\nif (of_property_read_bool(np, "arm,shared-override")) {\r\n*aux_val |= L2C_AUX_CTRL_SHARED_OVERRIDE;\r\n*aux_mask &= ~L2C_AUX_CTRL_SHARED_OVERRIDE;\r\n}\r\nif (of_property_read_bool(np, "arm,parity-enable")) {\r\n*aux_val |= L2C_AUX_CTRL_PARITY_ENABLE;\r\n*aux_mask &= ~L2C_AUX_CTRL_PARITY_ENABLE;\r\n} else if (of_property_read_bool(np, "arm,parity-disable")) {\r\n*aux_val &= ~L2C_AUX_CTRL_PARITY_ENABLE;\r\n*aux_mask &= ~L2C_AUX_CTRL_PARITY_ENABLE;\r\n}\r\nif (of_property_read_bool(np, "arm,early-bresp-disable"))\r\nl2x0_bresp_disable = true;\r\nif (of_property_read_bool(np, "arm,full-line-zero-disable"))\r\nl2x0_flz_disable = true;\r\nprefetch = l2x0_saved_regs.prefetch_ctrl;\r\nret = of_property_read_u32(np, "arm,double-linefill", &val);\r\nif (ret == 0) {\r\nif (val)\r\nprefetch |= L310_PREFETCH_CTRL_DBL_LINEFILL;\r\nelse\r\nprefetch &= ~L310_PREFETCH_CTRL_DBL_LINEFILL;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF arm,double-linefill property value is missing\n");\r\n}\r\nret = of_property_read_u32(np, "arm,double-linefill-incr", &val);\r\nif (ret == 0) {\r\nif (val)\r\nprefetch |= L310_PREFETCH_CTRL_DBL_LINEFILL_INCR;\r\nelse\r\nprefetch &= ~L310_PREFETCH_CTRL_DBL_LINEFILL_INCR;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF arm,double-linefill-incr property value is missing\n");\r\n}\r\nret = of_property_read_u32(np, "arm,double-linefill-wrap", &val);\r\nif (ret == 0) {\r\nif (!val)\r\nprefetch |= L310_PREFETCH_CTRL_DBL_LINEFILL_WRAP;\r\nelse\r\nprefetch &= ~L310_PREFETCH_CTRL_DBL_LINEFILL_WRAP;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF arm,double-linefill-wrap property value is missing\n");\r\n}\r\nret = of_property_read_u32(np, "arm,prefetch-drop", &val);\r\nif (ret == 0) {\r\nif (val)\r\nprefetch |= L310_PREFETCH_CTRL_PREFETCH_DROP;\r\nelse\r\nprefetch &= ~L310_PREFETCH_CTRL_PREFETCH_DROP;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF arm,prefetch-drop property value is missing\n");\r\n}\r\nret = of_property_read_u32(np, "arm,prefetch-offset", &val);\r\nif (ret == 0) {\r\nprefetch &= ~L310_PREFETCH_CTRL_OFFSET_MASK;\r\nprefetch |= val & L310_PREFETCH_CTRL_OFFSET_MASK;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF arm,prefetch-offset property value is missing\n");\r\n}\r\nret = of_property_read_u32(np, "prefetch-data", &val);\r\nif (ret == 0) {\r\nif (val)\r\nprefetch |= L310_PREFETCH_CTRL_DATA_PREFETCH;\r\nelse\r\nprefetch &= ~L310_PREFETCH_CTRL_DATA_PREFETCH;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF prefetch-data property value is missing\n");\r\n}\r\nret = of_property_read_u32(np, "prefetch-instr", &val);\r\nif (ret == 0) {\r\nif (val)\r\nprefetch |= L310_PREFETCH_CTRL_INSTR_PREFETCH;\r\nelse\r\nprefetch &= ~L310_PREFETCH_CTRL_INSTR_PREFETCH;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF prefetch-instr property value is missing\n");\r\n}\r\nl2x0_saved_regs.prefetch_ctrl = prefetch;\r\npower = l2x0_saved_regs.pwr_ctrl |\r\nL310_DYNAMIC_CLK_GATING_EN | L310_STNDBY_MODE_EN;\r\nret = of_property_read_u32(np, "arm,dynamic-clock-gating", &val);\r\nif (!ret) {\r\nif (!val)\r\npower &= ~L310_DYNAMIC_CLK_GATING_EN;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF dynamic-clock-gating property value is missing or invalid\n");\r\n}\r\nret = of_property_read_u32(np, "arm,standby-mode", &val);\r\nif (!ret) {\r\nif (!val)\r\npower &= ~L310_STNDBY_MODE_EN;\r\n} else if (ret != -EINVAL) {\r\npr_err("L2C-310 OF standby-mode property value is missing or invalid\n");\r\n}\r\nl2x0_saved_regs.pwr_ctrl = power;\r\n}\r\nstatic unsigned long aurora_range_end(unsigned long start, unsigned long end)\r\n{\r\nif (end > start + MAX_RANGE_SIZE)\r\nend = start + MAX_RANGE_SIZE;\r\nif (end > PAGE_ALIGN(start+1))\r\nend = PAGE_ALIGN(start+1);\r\nreturn end;\r\n}\r\nstatic void aurora_pa_range(unsigned long start, unsigned long end,\r\nunsigned long offset)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nunsigned long range_end;\r\nunsigned long flags;\r\nstart &= ~(CACHE_LINE_SIZE - 1);\r\nend = ALIGN(end, CACHE_LINE_SIZE);\r\nwhile (start < end) {\r\nrange_end = aurora_range_end(start, end);\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\nwritel_relaxed(start, base + AURORA_RANGE_BASE_ADDR_REG);\r\nwritel_relaxed(range_end - CACHE_LINE_SIZE, base + offset);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\nwritel_relaxed(0, base + AURORA_SYNC_REG);\r\nstart = range_end;\r\n}\r\n}\r\nstatic void aurora_inv_range(unsigned long start, unsigned long end)\r\n{\r\naurora_pa_range(start, end, AURORA_INVAL_RANGE_REG);\r\n}\r\nstatic void aurora_clean_range(unsigned long start, unsigned long end)\r\n{\r\nif (!l2_wt_override)\r\naurora_pa_range(start, end, AURORA_CLEAN_RANGE_REG);\r\n}\r\nstatic void aurora_flush_range(unsigned long start, unsigned long end)\r\n{\r\nif (l2_wt_override)\r\naurora_pa_range(start, end, AURORA_INVAL_RANGE_REG);\r\nelse\r\naurora_pa_range(start, end, AURORA_FLUSH_RANGE_REG);\r\n}\r\nstatic void aurora_flush_all(void)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\n__l2c_op_way(base + L2X0_CLEAN_INV_WAY);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\nwritel_relaxed(0, base + AURORA_SYNC_REG);\r\n}\r\nstatic void aurora_cache_sync(void)\r\n{\r\nwritel_relaxed(0, l2x0_base + AURORA_SYNC_REG);\r\n}\r\nstatic void aurora_disable(void)\r\n{\r\nvoid __iomem *base = l2x0_base;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&l2x0_lock, flags);\r\n__l2c_op_way(base + L2X0_CLEAN_INV_WAY);\r\nwritel_relaxed(0, base + AURORA_SYNC_REG);\r\nl2c_write_sec(0, base, L2X0_CTRL);\r\ndsb(st);\r\nraw_spin_unlock_irqrestore(&l2x0_lock, flags);\r\n}\r\nstatic void aurora_save(void __iomem *base)\r\n{\r\nl2x0_saved_regs.ctrl = readl_relaxed(base + L2X0_CTRL);\r\nl2x0_saved_regs.aux_ctrl = readl_relaxed(base + L2X0_AUX_CTRL);\r\n}\r\nstatic void __init aurora_enable_no_outer(void __iomem *base,\r\nunsigned num_lock)\r\n{\r\nu32 u;\r\nasm volatile("mrc p15, 1, %0, c15, c2, 0" : "=r" (u));\r\nu |= AURORA_CTRL_FW;\r\nasm volatile("mcr p15, 1, %0, c15, c2, 0" : : "r" (u));\r\nisb();\r\nl2c_enable(base, num_lock);\r\n}\r\nstatic void __init aurora_fixup(void __iomem *base, u32 cache_id,\r\nstruct outer_cache_fns *fns)\r\n{\r\nsync_reg_offset = AURORA_SYNC_REG;\r\n}\r\nstatic void __init aurora_of_parse(const struct device_node *np,\r\nu32 *aux_val, u32 *aux_mask)\r\n{\r\nu32 val = AURORA_ACR_REPLACEMENT_TYPE_SEMIPLRU;\r\nu32 mask = AURORA_ACR_REPLACEMENT_MASK;\r\nof_property_read_u32(np, "cache-id-part",\r\n&cache_id_part_number_from_dt);\r\nl2_wt_override = of_property_read_bool(np, "wt-override");\r\nif (l2_wt_override) {\r\nval |= AURORA_ACR_FORCE_WRITE_THRO_POLICY;\r\nmask |= AURORA_ACR_FORCE_WRITE_POLICY_MASK;\r\n}\r\n*aux_val &= ~mask;\r\n*aux_val |= val;\r\n*aux_mask &= ~mask;\r\n}\r\nstatic inline int bcm_addr_is_sys_emi(unsigned long addr)\r\n{\r\nreturn (addr >= BCM_SYS_EMI_START_ADDR) &&\r\n(addr < BCM_VC_EMI_SEC3_START_ADDR);\r\n}\r\nstatic inline unsigned long bcm_l2_phys_addr(unsigned long addr)\r\n{\r\nif (bcm_addr_is_sys_emi(addr))\r\nreturn addr + BCM_SYS_EMI_OFFSET;\r\nelse\r\nreturn addr + BCM_VC_EMI_OFFSET;\r\n}\r\nstatic void bcm_inv_range(unsigned long start, unsigned long end)\r\n{\r\nunsigned long new_start, new_end;\r\nBUG_ON(start < BCM_SYS_EMI_START_ADDR);\r\nif (unlikely(end <= start))\r\nreturn;\r\nnew_start = bcm_l2_phys_addr(start);\r\nnew_end = bcm_l2_phys_addr(end);\r\nif (likely(bcm_addr_is_sys_emi(end) || !bcm_addr_is_sys_emi(start))) {\r\nl2c210_inv_range(new_start, new_end);\r\nreturn;\r\n}\r\nl2c210_inv_range(new_start,\r\nbcm_l2_phys_addr(BCM_VC_EMI_SEC3_START_ADDR-1));\r\nl2c210_inv_range(bcm_l2_phys_addr(BCM_VC_EMI_SEC3_START_ADDR),\r\nnew_end);\r\n}\r\nstatic void bcm_clean_range(unsigned long start, unsigned long end)\r\n{\r\nunsigned long new_start, new_end;\r\nBUG_ON(start < BCM_SYS_EMI_START_ADDR);\r\nif (unlikely(end <= start))\r\nreturn;\r\nnew_start = bcm_l2_phys_addr(start);\r\nnew_end = bcm_l2_phys_addr(end);\r\nif (likely(bcm_addr_is_sys_emi(end) || !bcm_addr_is_sys_emi(start))) {\r\nl2c210_clean_range(new_start, new_end);\r\nreturn;\r\n}\r\nl2c210_clean_range(new_start,\r\nbcm_l2_phys_addr(BCM_VC_EMI_SEC3_START_ADDR-1));\r\nl2c210_clean_range(bcm_l2_phys_addr(BCM_VC_EMI_SEC3_START_ADDR),\r\nnew_end);\r\n}\r\nstatic void bcm_flush_range(unsigned long start, unsigned long end)\r\n{\r\nunsigned long new_start, new_end;\r\nBUG_ON(start < BCM_SYS_EMI_START_ADDR);\r\nif (unlikely(end <= start))\r\nreturn;\r\nif ((end - start) >= l2x0_size) {\r\nouter_cache.flush_all();\r\nreturn;\r\n}\r\nnew_start = bcm_l2_phys_addr(start);\r\nnew_end = bcm_l2_phys_addr(end);\r\nif (likely(bcm_addr_is_sys_emi(end) || !bcm_addr_is_sys_emi(start))) {\r\nl2c210_flush_range(new_start, new_end);\r\nreturn;\r\n}\r\nl2c210_flush_range(new_start,\r\nbcm_l2_phys_addr(BCM_VC_EMI_SEC3_START_ADDR-1));\r\nl2c210_flush_range(bcm_l2_phys_addr(BCM_VC_EMI_SEC3_START_ADDR),\r\nnew_end);\r\n}\r\nstatic void __init tauros3_save(void __iomem *base)\r\n{\r\nl2c_save(base);\r\nl2x0_saved_regs.aux2_ctrl =\r\nreadl_relaxed(base + TAUROS3_AUX2_CTRL);\r\nl2x0_saved_regs.prefetch_ctrl =\r\nreadl_relaxed(base + L310_PREFETCH_CTRL);\r\n}\r\nstatic void tauros3_configure(void __iomem *base)\r\n{\r\nl2c_configure(base);\r\nwritel_relaxed(l2x0_saved_regs.aux2_ctrl,\r\nbase + TAUROS3_AUX2_CTRL);\r\nwritel_relaxed(l2x0_saved_regs.prefetch_ctrl,\r\nbase + L310_PREFETCH_CTRL);\r\n}\r\nint __init l2x0_of_init(u32 aux_val, u32 aux_mask)\r\n{\r\nconst struct l2c_init_data *data;\r\nstruct device_node *np;\r\nstruct resource res;\r\nu32 cache_id, old_aux;\r\nu32 cache_level = 2;\r\nbool nosync = false;\r\nnp = of_find_matching_node(NULL, l2x0_ids);\r\nif (!np)\r\nreturn -ENODEV;\r\nif (of_address_to_resource(np, 0, &res))\r\nreturn -ENODEV;\r\nl2x0_base = ioremap(res.start, resource_size(&res));\r\nif (!l2x0_base)\r\nreturn -ENOMEM;\r\nl2x0_saved_regs.phy_base = res.start;\r\ndata = of_match_node(l2x0_ids, np)->data;\r\nif (of_device_is_compatible(np, "arm,pl310-cache") &&\r\nof_property_read_bool(np, "arm,io-coherent"))\r\ndata = &of_l2c310_coherent_data;\r\nold_aux = readl_relaxed(l2x0_base + L2X0_AUX_CTRL);\r\nif (old_aux != ((old_aux & aux_mask) | aux_val)) {\r\npr_warn("L2C: platform modifies aux control register: 0x%08x -> 0x%08x\n",\r\nold_aux, (old_aux & aux_mask) | aux_val);\r\n} else if (aux_mask != ~0U && aux_val != 0) {\r\npr_alert("L2C: platform provided aux values match the hardware, so have no effect. Please remove them.\n");\r\n}\r\nif (!of_property_read_bool(np, "cache-unified"))\r\npr_err("L2C: device tree omits to specify unified cache\n");\r\nif (of_property_read_u32(np, "cache-level", &cache_level))\r\npr_err("L2C: device tree omits to specify cache-level\n");\r\nif (cache_level != 2)\r\npr_err("L2C: device tree specifies invalid cache level\n");\r\nnosync = of_property_read_bool(np, "arm,outer-sync-disable");\r\nif (data->save)\r\ndata->save(l2x0_base);\r\nif (!(readl_relaxed(l2x0_base + L2X0_CTRL) & L2X0_CTRL_EN))\r\nif (data->of_parse)\r\ndata->of_parse(np, &aux_val, &aux_mask);\r\nif (cache_id_part_number_from_dt)\r\ncache_id = cache_id_part_number_from_dt;\r\nelse\r\ncache_id = readl_relaxed(l2x0_base + L2X0_CACHE_ID);\r\nreturn __l2c_init(data, aux_val, aux_mask, cache_id, nosync);\r\n}
