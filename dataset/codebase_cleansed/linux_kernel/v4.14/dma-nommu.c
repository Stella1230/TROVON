static dma_addr_t nommu_map_page(struct device *dev, struct page *page,\r\nunsigned long offset, size_t size,\r\nenum dma_data_direction dir,\r\nunsigned long attrs)\r\n{\r\ndma_addr_t addr = page_to_phys(page) + offset;\r\nWARN_ON(size == 0);\r\nif (!(attrs & DMA_ATTR_SKIP_CPU_SYNC))\r\ndma_cache_sync(dev, page_address(page) + offset, size, dir);\r\nreturn addr;\r\n}\r\nstatic int nommu_map_sg(struct device *dev, struct scatterlist *sg,\r\nint nents, enum dma_data_direction dir,\r\nunsigned long attrs)\r\n{\r\nstruct scatterlist *s;\r\nint i;\r\nWARN_ON(nents == 0 || sg[0].length == 0);\r\nfor_each_sg(sg, s, nents, i) {\r\nBUG_ON(!sg_page(s));\r\nif (!(attrs & DMA_ATTR_SKIP_CPU_SYNC))\r\ndma_cache_sync(dev, sg_virt(s), s->length, dir);\r\ns->dma_address = sg_phys(s);\r\ns->dma_length = s->length;\r\n}\r\nreturn nents;\r\n}\r\nstatic void nommu_sync_single(struct device *dev, dma_addr_t addr,\r\nsize_t size, enum dma_data_direction dir)\r\n{\r\ndma_cache_sync(dev, phys_to_virt(addr), size, dir);\r\n}\r\nstatic void nommu_sync_sg(struct device *dev, struct scatterlist *sg,\r\nint nelems, enum dma_data_direction dir)\r\n{\r\nstruct scatterlist *s;\r\nint i;\r\nfor_each_sg(sg, s, nelems, i)\r\ndma_cache_sync(dev, sg_virt(s), s->length, dir);\r\n}\r\nvoid __init no_iommu_init(void)\r\n{\r\nif (dma_ops)\r\nreturn;\r\ndma_ops = &nommu_dma_ops;\r\n}
