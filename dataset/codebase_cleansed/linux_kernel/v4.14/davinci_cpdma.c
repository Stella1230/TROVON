static void cpdma_desc_pool_destroy(struct cpdma_ctlr *ctlr)\r\n{\r\nstruct cpdma_desc_pool *pool = ctlr->pool;\r\nif (!pool)\r\nreturn;\r\nWARN(gen_pool_size(pool->gen_pool) != gen_pool_avail(pool->gen_pool),\r\n"cpdma_desc_pool size %d != avail %d",\r\ngen_pool_size(pool->gen_pool),\r\ngen_pool_avail(pool->gen_pool));\r\nif (pool->cpumap)\r\ndma_free_coherent(ctlr->dev, pool->mem_size, pool->cpumap,\r\npool->phys);\r\n}\r\nint cpdma_desc_pool_create(struct cpdma_ctlr *ctlr)\r\n{\r\nstruct cpdma_params *cpdma_params = &ctlr->params;\r\nstruct cpdma_desc_pool *pool;\r\nint ret = -ENOMEM;\r\npool = devm_kzalloc(ctlr->dev, sizeof(*pool), GFP_KERNEL);\r\nif (!pool)\r\ngoto gen_pool_create_fail;\r\nctlr->pool = pool;\r\npool->mem_size = cpdma_params->desc_mem_size;\r\npool->desc_size = ALIGN(sizeof(struct cpdma_desc),\r\ncpdma_params->desc_align);\r\npool->num_desc = pool->mem_size / pool->desc_size;\r\nif (cpdma_params->descs_pool_size) {\r\npool->num_desc = cpdma_params->descs_pool_size;\r\npool->mem_size = pool->desc_size * pool->num_desc;\r\nif (pool->mem_size > cpdma_params->desc_mem_size)\r\ncpdma_params->desc_mem_phys = 0;\r\n}\r\npool->gen_pool = devm_gen_pool_create(ctlr->dev, ilog2(pool->desc_size),\r\n-1, "cpdma");\r\nif (IS_ERR(pool->gen_pool)) {\r\nret = PTR_ERR(pool->gen_pool);\r\ndev_err(ctlr->dev, "pool create failed %d\n", ret);\r\ngoto gen_pool_create_fail;\r\n}\r\nif (cpdma_params->desc_mem_phys) {\r\npool->phys = cpdma_params->desc_mem_phys;\r\npool->iomap = devm_ioremap(ctlr->dev, pool->phys,\r\npool->mem_size);\r\npool->hw_addr = cpdma_params->desc_hw_addr;\r\n} else {\r\npool->cpumap = dma_alloc_coherent(ctlr->dev, pool->mem_size,\r\n&pool->hw_addr, GFP_KERNEL);\r\npool->iomap = (void __iomem __force *)pool->cpumap;\r\npool->phys = pool->hw_addr;\r\n}\r\nif (!pool->iomap)\r\ngoto gen_pool_create_fail;\r\nret = gen_pool_add_virt(pool->gen_pool, (unsigned long)pool->iomap,\r\npool->phys, pool->mem_size, -1);\r\nif (ret < 0) {\r\ndev_err(ctlr->dev, "pool add failed %d\n", ret);\r\ngoto gen_pool_add_virt_fail;\r\n}\r\nreturn 0;\r\ngen_pool_add_virt_fail:\r\ncpdma_desc_pool_destroy(ctlr);\r\ngen_pool_create_fail:\r\nctlr->pool = NULL;\r\nreturn ret;\r\n}\r\nstatic inline dma_addr_t desc_phys(struct cpdma_desc_pool *pool,\r\nstruct cpdma_desc __iomem *desc)\r\n{\r\nif (!desc)\r\nreturn 0;\r\nreturn pool->hw_addr + (__force long)desc - (__force long)pool->iomap;\r\n}\r\nstatic inline struct cpdma_desc __iomem *\r\ndesc_from_phys(struct cpdma_desc_pool *pool, dma_addr_t dma)\r\n{\r\nreturn dma ? pool->iomap + dma - pool->hw_addr : NULL;\r\n}\r\nstatic struct cpdma_desc __iomem *\r\ncpdma_desc_alloc(struct cpdma_desc_pool *pool)\r\n{\r\nreturn (struct cpdma_desc __iomem *)\r\ngen_pool_alloc(pool->gen_pool, pool->desc_size);\r\n}\r\nstatic void cpdma_desc_free(struct cpdma_desc_pool *pool,\r\nstruct cpdma_desc __iomem *desc, int num_desc)\r\n{\r\ngen_pool_free(pool->gen_pool, (unsigned long)desc, pool->desc_size);\r\n}\r\nstatic int _cpdma_control_set(struct cpdma_ctlr *ctlr, int control, int value)\r\n{\r\nstruct cpdma_control_info *info = &controls[control];\r\nu32 val;\r\nif (!ctlr->params.has_ext_regs)\r\nreturn -ENOTSUPP;\r\nif (ctlr->state != CPDMA_STATE_ACTIVE)\r\nreturn -EINVAL;\r\nif (control < 0 || control >= ARRAY_SIZE(controls))\r\nreturn -ENOENT;\r\nif ((info->access & ACCESS_WO) != ACCESS_WO)\r\nreturn -EPERM;\r\nval = dma_reg_read(ctlr, info->reg);\r\nval &= ~(info->mask << info->shift);\r\nval |= (value & info->mask) << info->shift;\r\ndma_reg_write(ctlr, info->reg, val);\r\nreturn 0;\r\n}\r\nstatic int _cpdma_control_get(struct cpdma_ctlr *ctlr, int control)\r\n{\r\nstruct cpdma_control_info *info = &controls[control];\r\nint ret;\r\nif (!ctlr->params.has_ext_regs)\r\nreturn -ENOTSUPP;\r\nif (ctlr->state != CPDMA_STATE_ACTIVE)\r\nreturn -EINVAL;\r\nif (control < 0 || control >= ARRAY_SIZE(controls))\r\nreturn -ENOENT;\r\nif ((info->access & ACCESS_RO) != ACCESS_RO)\r\nreturn -EPERM;\r\nret = (dma_reg_read(ctlr, info->reg) >> info->shift) & info->mask;\r\nreturn ret;\r\n}\r\nstatic int cpdma_chan_set_chan_shaper(struct cpdma_chan *chan)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nu32 rate_reg;\r\nu32 rmask;\r\nint ret;\r\nif (!chan->rate)\r\nreturn 0;\r\nrate_reg = CPDMA_TX_PRI0_RATE + 4 * chan->chan_num;\r\ndma_reg_write(ctlr, rate_reg, chan->rate_factor);\r\nrmask = _cpdma_control_get(ctlr, CPDMA_TX_RLIM);\r\nrmask |= chan->mask;\r\nret = _cpdma_control_set(ctlr, CPDMA_TX_RLIM, rmask);\r\nreturn ret;\r\n}\r\nstatic int cpdma_chan_on(struct cpdma_chan *chan)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nstruct cpdma_desc_pool *pool = ctlr->pool;\r\nunsigned long flags;\r\nspin_lock_irqsave(&chan->lock, flags);\r\nif (chan->state != CPDMA_STATE_IDLE) {\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn -EBUSY;\r\n}\r\nif (ctlr->state != CPDMA_STATE_ACTIVE) {\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn -EINVAL;\r\n}\r\ndma_reg_write(ctlr, chan->int_set, chan->mask);\r\nchan->state = CPDMA_STATE_ACTIVE;\r\nif (chan->head) {\r\nchan_write(chan, hdp, desc_phys(pool, chan->head));\r\nif (chan->rxfree)\r\nchan_write(chan, rxfree, chan->count);\r\n}\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn 0;\r\n}\r\nstatic int cpdma_chan_fit_rate(struct cpdma_chan *ch, u32 rate,\r\nu32 *rmask, int *prio_mode)\r\n{\r\nstruct cpdma_ctlr *ctlr = ch->ctlr;\r\nstruct cpdma_chan *chan;\r\nu32 old_rate = ch->rate;\r\nu32 new_rmask = 0;\r\nint rlim = 1;\r\nint i;\r\n*prio_mode = 0;\r\nfor (i = tx_chan_num(0); i < tx_chan_num(CPDMA_MAX_CHANNELS); i++) {\r\nchan = ctlr->channels[i];\r\nif (!chan) {\r\nrlim = 0;\r\ncontinue;\r\n}\r\nif (chan == ch)\r\nchan->rate = rate;\r\nif (chan->rate) {\r\nif (rlim) {\r\nnew_rmask |= chan->mask;\r\n} else {\r\nch->rate = old_rate;\r\ndev_err(ctlr->dev, "Prev channel of %dch is not rate limited\n",\r\nchan->chan_num);\r\nreturn -EINVAL;\r\n}\r\n} else {\r\n*prio_mode = 1;\r\nrlim = 0;\r\n}\r\n}\r\n*rmask = new_rmask;\r\nreturn 0;\r\n}\r\nstatic u32 cpdma_chan_set_factors(struct cpdma_ctlr *ctlr,\r\nstruct cpdma_chan *ch)\r\n{\r\nu32 delta = UINT_MAX, prev_delta = UINT_MAX, best_delta = UINT_MAX;\r\nu32 best_send_cnt = 0, best_idle_cnt = 0;\r\nu32 new_rate, best_rate = 0, rate_reg;\r\nu64 send_cnt, idle_cnt;\r\nu32 min_send_cnt, freq;\r\nu64 divident, divisor;\r\nif (!ch->rate) {\r\nch->rate_factor = 0;\r\ngoto set_factor;\r\n}\r\nfreq = ctlr->params.bus_freq_mhz * 1000 * 32;\r\nif (!freq) {\r\ndev_err(ctlr->dev, "The bus frequency is not set\n");\r\nreturn -EINVAL;\r\n}\r\nmin_send_cnt = freq - ch->rate;\r\nsend_cnt = DIV_ROUND_UP(min_send_cnt, ch->rate);\r\nwhile (send_cnt <= CPDMA_MAX_RLIM_CNT) {\r\ndivident = ch->rate * send_cnt;\r\ndivisor = min_send_cnt;\r\nidle_cnt = DIV_ROUND_CLOSEST_ULL(divident, divisor);\r\ndivident = freq * idle_cnt;\r\ndivisor = idle_cnt + send_cnt;\r\nnew_rate = DIV_ROUND_CLOSEST_ULL(divident, divisor);\r\ndelta = new_rate >= ch->rate ? new_rate - ch->rate : delta;\r\nif (delta < best_delta) {\r\nbest_delta = delta;\r\nbest_send_cnt = send_cnt;\r\nbest_idle_cnt = idle_cnt;\r\nbest_rate = new_rate;\r\nif (!delta)\r\nbreak;\r\n}\r\nif (prev_delta >= delta) {\r\nprev_delta = delta;\r\nsend_cnt++;\r\ncontinue;\r\n}\r\nidle_cnt++;\r\ndivident = freq * idle_cnt;\r\nsend_cnt = DIV_ROUND_CLOSEST_ULL(divident, ch->rate);\r\nsend_cnt -= idle_cnt;\r\nprev_delta = UINT_MAX;\r\n}\r\nch->rate = best_rate;\r\nch->rate_factor = best_send_cnt | (best_idle_cnt << 16);\r\nset_factor:\r\nrate_reg = CPDMA_TX_PRI0_RATE + 4 * ch->chan_num;\r\ndma_reg_write(ctlr, rate_reg, ch->rate_factor);\r\nreturn 0;\r\n}\r\nstruct cpdma_ctlr *cpdma_ctlr_create(struct cpdma_params *params)\r\n{\r\nstruct cpdma_ctlr *ctlr;\r\nctlr = devm_kzalloc(params->dev, sizeof(*ctlr), GFP_KERNEL);\r\nif (!ctlr)\r\nreturn NULL;\r\nctlr->state = CPDMA_STATE_IDLE;\r\nctlr->params = *params;\r\nctlr->dev = params->dev;\r\nctlr->chan_num = 0;\r\nspin_lock_init(&ctlr->lock);\r\nif (cpdma_desc_pool_create(ctlr))\r\nreturn NULL;\r\nctlr->num_tx_desc = ctlr->pool->num_desc / 2;\r\nctlr->num_rx_desc = ctlr->pool->num_desc - ctlr->num_tx_desc;\r\nif (WARN_ON(ctlr->num_chan > CPDMA_MAX_CHANNELS))\r\nctlr->num_chan = CPDMA_MAX_CHANNELS;\r\nreturn ctlr;\r\n}\r\nint cpdma_ctlr_start(struct cpdma_ctlr *ctlr)\r\n{\r\nstruct cpdma_chan *chan;\r\nunsigned long flags;\r\nint i, prio_mode;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nif (ctlr->state != CPDMA_STATE_IDLE) {\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn -EBUSY;\r\n}\r\nif (ctlr->params.has_soft_reset) {\r\nunsigned timeout = 10 * 100;\r\ndma_reg_write(ctlr, CPDMA_SOFTRESET, 1);\r\nwhile (timeout) {\r\nif (dma_reg_read(ctlr, CPDMA_SOFTRESET) == 0)\r\nbreak;\r\nudelay(10);\r\ntimeout--;\r\n}\r\nWARN_ON(!timeout);\r\n}\r\nfor (i = 0; i < ctlr->num_chan; i++) {\r\nwritel(0, ctlr->params.txhdp + 4 * i);\r\nwritel(0, ctlr->params.rxhdp + 4 * i);\r\nwritel(0, ctlr->params.txcp + 4 * i);\r\nwritel(0, ctlr->params.rxcp + 4 * i);\r\n}\r\ndma_reg_write(ctlr, CPDMA_RXINTMASKCLEAR, 0xffffffff);\r\ndma_reg_write(ctlr, CPDMA_TXINTMASKCLEAR, 0xffffffff);\r\ndma_reg_write(ctlr, CPDMA_TXCONTROL, 1);\r\ndma_reg_write(ctlr, CPDMA_RXCONTROL, 1);\r\nctlr->state = CPDMA_STATE_ACTIVE;\r\nprio_mode = 0;\r\nfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\r\nchan = ctlr->channels[i];\r\nif (chan) {\r\ncpdma_chan_set_chan_shaper(chan);\r\ncpdma_chan_on(chan);\r\nif (is_tx_chan(chan) && !chan->rate)\r\nprio_mode = 1;\r\n}\r\n}\r\n_cpdma_control_set(ctlr, CPDMA_TX_PRIO_FIXED, prio_mode);\r\n_cpdma_control_set(ctlr, CPDMA_RX_BUFFER_OFFSET, 0);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn 0;\r\n}\r\nint cpdma_ctlr_stop(struct cpdma_ctlr *ctlr)\r\n{\r\nunsigned long flags;\r\nint i;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nif (ctlr->state != CPDMA_STATE_ACTIVE) {\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn -EINVAL;\r\n}\r\nctlr->state = CPDMA_STATE_TEARDOWN;\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\r\nif (ctlr->channels[i])\r\ncpdma_chan_stop(ctlr->channels[i]);\r\n}\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\ndma_reg_write(ctlr, CPDMA_RXINTMASKCLEAR, 0xffffffff);\r\ndma_reg_write(ctlr, CPDMA_TXINTMASKCLEAR, 0xffffffff);\r\ndma_reg_write(ctlr, CPDMA_TXCONTROL, 0);\r\ndma_reg_write(ctlr, CPDMA_RXCONTROL, 0);\r\nctlr->state = CPDMA_STATE_IDLE;\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn 0;\r\n}\r\nint cpdma_ctlr_destroy(struct cpdma_ctlr *ctlr)\r\n{\r\nint ret = 0, i;\r\nif (!ctlr)\r\nreturn -EINVAL;\r\nif (ctlr->state != CPDMA_STATE_IDLE)\r\ncpdma_ctlr_stop(ctlr);\r\nfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++)\r\ncpdma_chan_destroy(ctlr->channels[i]);\r\ncpdma_desc_pool_destroy(ctlr);\r\nreturn ret;\r\n}\r\nint cpdma_ctlr_int_ctrl(struct cpdma_ctlr *ctlr, bool enable)\r\n{\r\nunsigned long flags;\r\nint i;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nif (ctlr->state != CPDMA_STATE_ACTIVE) {\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\r\nif (ctlr->channels[i])\r\ncpdma_chan_int_ctrl(ctlr->channels[i], enable);\r\n}\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn 0;\r\n}\r\nvoid cpdma_ctlr_eoi(struct cpdma_ctlr *ctlr, u32 value)\r\n{\r\ndma_reg_write(ctlr, CPDMA_MACEOIVECTOR, value);\r\n}\r\nu32 cpdma_ctrl_rxchs_state(struct cpdma_ctlr *ctlr)\r\n{\r\nreturn dma_reg_read(ctlr, CPDMA_RXINTSTATMASKED);\r\n}\r\nu32 cpdma_ctrl_txchs_state(struct cpdma_ctlr *ctlr)\r\n{\r\nreturn dma_reg_read(ctlr, CPDMA_TXINTSTATMASKED);\r\n}\r\nstatic void cpdma_chan_set_descs(struct cpdma_ctlr *ctlr,\r\nint rx, int desc_num,\r\nint per_ch_desc)\r\n{\r\nstruct cpdma_chan *chan, *most_chan = NULL;\r\nint desc_cnt = desc_num;\r\nint most_dnum = 0;\r\nint min, max, i;\r\nif (!desc_num)\r\nreturn;\r\nif (rx) {\r\nmin = rx_chan_num(0);\r\nmax = rx_chan_num(CPDMA_MAX_CHANNELS);\r\n} else {\r\nmin = tx_chan_num(0);\r\nmax = tx_chan_num(CPDMA_MAX_CHANNELS);\r\n}\r\nfor (i = min; i < max; i++) {\r\nchan = ctlr->channels[i];\r\nif (!chan)\r\ncontinue;\r\nif (chan->weight)\r\nchan->desc_num = (chan->weight * desc_num) / 100;\r\nelse\r\nchan->desc_num = per_ch_desc;\r\ndesc_cnt -= chan->desc_num;\r\nif (most_dnum < chan->desc_num) {\r\nmost_dnum = chan->desc_num;\r\nmost_chan = chan;\r\n}\r\n}\r\nif (most_chan)\r\nmost_chan->desc_num += desc_cnt;\r\n}\r\nint cpdma_chan_split_pool(struct cpdma_ctlr *ctlr)\r\n{\r\nint tx_per_ch_desc = 0, rx_per_ch_desc = 0;\r\nint free_rx_num = 0, free_tx_num = 0;\r\nint rx_weight = 0, tx_weight = 0;\r\nint tx_desc_num, rx_desc_num;\r\nstruct cpdma_chan *chan;\r\nint i;\r\nif (!ctlr->chan_num)\r\nreturn 0;\r\nfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\r\nchan = ctlr->channels[i];\r\nif (!chan)\r\ncontinue;\r\nif (is_rx_chan(chan)) {\r\nif (!chan->weight)\r\nfree_rx_num++;\r\nrx_weight += chan->weight;\r\n} else {\r\nif (!chan->weight)\r\nfree_tx_num++;\r\ntx_weight += chan->weight;\r\n}\r\n}\r\nif (rx_weight > 100 || tx_weight > 100)\r\nreturn -EINVAL;\r\ntx_desc_num = ctlr->num_tx_desc;\r\nrx_desc_num = ctlr->num_rx_desc;\r\nif (free_tx_num) {\r\ntx_per_ch_desc = tx_desc_num - (tx_weight * tx_desc_num) / 100;\r\ntx_per_ch_desc /= free_tx_num;\r\n}\r\nif (free_rx_num) {\r\nrx_per_ch_desc = rx_desc_num - (rx_weight * rx_desc_num) / 100;\r\nrx_per_ch_desc /= free_rx_num;\r\n}\r\ncpdma_chan_set_descs(ctlr, 0, tx_desc_num, tx_per_ch_desc);\r\ncpdma_chan_set_descs(ctlr, 1, rx_desc_num, rx_per_ch_desc);\r\nreturn 0;\r\n}\r\nint cpdma_chan_set_weight(struct cpdma_chan *ch, int weight)\r\n{\r\nstruct cpdma_ctlr *ctlr = ch->ctlr;\r\nunsigned long flags, ch_flags;\r\nint ret;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nspin_lock_irqsave(&ch->lock, ch_flags);\r\nif (ch->weight == weight) {\r\nspin_unlock_irqrestore(&ch->lock, ch_flags);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn 0;\r\n}\r\nch->weight = weight;\r\nspin_unlock_irqrestore(&ch->lock, ch_flags);\r\nret = cpdma_chan_split_pool(ctlr);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn ret;\r\n}\r\nu32 cpdma_chan_get_min_rate(struct cpdma_ctlr *ctlr)\r\n{\r\nunsigned int divident, divisor;\r\ndivident = ctlr->params.bus_freq_mhz * 32 * 1000;\r\ndivisor = 1 + CPDMA_MAX_RLIM_CNT;\r\nreturn DIV_ROUND_UP(divident, divisor);\r\n}\r\nint cpdma_chan_set_rate(struct cpdma_chan *ch, u32 rate)\r\n{\r\nunsigned long flags, ch_flags;\r\nstruct cpdma_ctlr *ctlr;\r\nint ret, prio_mode;\r\nu32 rmask;\r\nif (!ch || !is_tx_chan(ch))\r\nreturn -EINVAL;\r\nif (ch->rate == rate)\r\nreturn rate;\r\nctlr = ch->ctlr;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nspin_lock_irqsave(&ch->lock, ch_flags);\r\nret = cpdma_chan_fit_rate(ch, rate, &rmask, &prio_mode);\r\nif (ret)\r\ngoto err;\r\nret = cpdma_chan_set_factors(ctlr, ch);\r\nif (ret)\r\ngoto err;\r\nspin_unlock_irqrestore(&ch->lock, ch_flags);\r\n_cpdma_control_set(ctlr, CPDMA_TX_RLIM, rmask);\r\n_cpdma_control_set(ctlr, CPDMA_TX_PRIO_FIXED, prio_mode);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn ret;\r\nerr:\r\nspin_unlock_irqrestore(&ch->lock, ch_flags);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn ret;\r\n}\r\nu32 cpdma_chan_get_rate(struct cpdma_chan *ch)\r\n{\r\nunsigned long flags;\r\nu32 rate;\r\nspin_lock_irqsave(&ch->lock, flags);\r\nrate = ch->rate;\r\nspin_unlock_irqrestore(&ch->lock, flags);\r\nreturn rate;\r\n}\r\nstruct cpdma_chan *cpdma_chan_create(struct cpdma_ctlr *ctlr, int chan_num,\r\ncpdma_handler_fn handler, int rx_type)\r\n{\r\nint offset = chan_num * 4;\r\nstruct cpdma_chan *chan;\r\nunsigned long flags;\r\nchan_num = rx_type ? rx_chan_num(chan_num) : tx_chan_num(chan_num);\r\nif (__chan_linear(chan_num) >= ctlr->num_chan)\r\nreturn NULL;\r\nchan = devm_kzalloc(ctlr->dev, sizeof(*chan), GFP_KERNEL);\r\nif (!chan)\r\nreturn ERR_PTR(-ENOMEM);\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nif (ctlr->channels[chan_num]) {\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\ndevm_kfree(ctlr->dev, chan);\r\nreturn ERR_PTR(-EBUSY);\r\n}\r\nchan->ctlr = ctlr;\r\nchan->state = CPDMA_STATE_IDLE;\r\nchan->chan_num = chan_num;\r\nchan->handler = handler;\r\nchan->rate = 0;\r\nchan->weight = 0;\r\nif (is_rx_chan(chan)) {\r\nchan->hdp = ctlr->params.rxhdp + offset;\r\nchan->cp = ctlr->params.rxcp + offset;\r\nchan->rxfree = ctlr->params.rxfree + offset;\r\nchan->int_set = CPDMA_RXINTMASKSET;\r\nchan->int_clear = CPDMA_RXINTMASKCLEAR;\r\nchan->td = CPDMA_RXTEARDOWN;\r\nchan->dir = DMA_FROM_DEVICE;\r\n} else {\r\nchan->hdp = ctlr->params.txhdp + offset;\r\nchan->cp = ctlr->params.txcp + offset;\r\nchan->int_set = CPDMA_TXINTMASKSET;\r\nchan->int_clear = CPDMA_TXINTMASKCLEAR;\r\nchan->td = CPDMA_TXTEARDOWN;\r\nchan->dir = DMA_TO_DEVICE;\r\n}\r\nchan->mask = BIT(chan_linear(chan));\r\nspin_lock_init(&chan->lock);\r\nctlr->channels[chan_num] = chan;\r\nctlr->chan_num++;\r\ncpdma_chan_split_pool(ctlr);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn chan;\r\n}\r\nint cpdma_chan_get_rx_buf_num(struct cpdma_chan *chan)\r\n{\r\nunsigned long flags;\r\nint desc_num;\r\nspin_lock_irqsave(&chan->lock, flags);\r\ndesc_num = chan->desc_num;\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn desc_num;\r\n}\r\nint cpdma_chan_destroy(struct cpdma_chan *chan)\r\n{\r\nstruct cpdma_ctlr *ctlr;\r\nunsigned long flags;\r\nif (!chan)\r\nreturn -EINVAL;\r\nctlr = chan->ctlr;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nif (chan->state != CPDMA_STATE_IDLE)\r\ncpdma_chan_stop(chan);\r\nctlr->channels[chan->chan_num] = NULL;\r\nctlr->chan_num--;\r\ndevm_kfree(ctlr->dev, chan);\r\ncpdma_chan_split_pool(ctlr);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn 0;\r\n}\r\nint cpdma_chan_get_stats(struct cpdma_chan *chan,\r\nstruct cpdma_chan_stats *stats)\r\n{\r\nunsigned long flags;\r\nif (!chan)\r\nreturn -EINVAL;\r\nspin_lock_irqsave(&chan->lock, flags);\r\nmemcpy(stats, &chan->stats, sizeof(*stats));\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn 0;\r\n}\r\nstatic void __cpdma_chan_submit(struct cpdma_chan *chan,\r\nstruct cpdma_desc __iomem *desc)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nstruct cpdma_desc __iomem *prev = chan->tail;\r\nstruct cpdma_desc_pool *pool = ctlr->pool;\r\ndma_addr_t desc_dma;\r\nu32 mode;\r\ndesc_dma = desc_phys(pool, desc);\r\nif (!chan->head) {\r\nchan->stats.head_enqueue++;\r\nchan->head = desc;\r\nchan->tail = desc;\r\nif (chan->state == CPDMA_STATE_ACTIVE)\r\nchan_write(chan, hdp, desc_dma);\r\nreturn;\r\n}\r\ndesc_write(prev, hw_next, desc_dma);\r\nchan->tail = desc;\r\nchan->stats.tail_enqueue++;\r\nmode = desc_read(prev, hw_mode);\r\nif (((mode & (CPDMA_DESC_EOQ | CPDMA_DESC_OWNER)) == CPDMA_DESC_EOQ) &&\r\n(chan->state == CPDMA_STATE_ACTIVE)) {\r\ndesc_write(prev, hw_mode, mode & ~CPDMA_DESC_EOQ);\r\nchan_write(chan, hdp, desc_dma);\r\nchan->stats.misqueued++;\r\n}\r\n}\r\nint cpdma_chan_submit(struct cpdma_chan *chan, void *token, void *data,\r\nint len, int directed)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nstruct cpdma_desc __iomem *desc;\r\ndma_addr_t buffer;\r\nunsigned long flags;\r\nu32 mode;\r\nint ret = 0;\r\nspin_lock_irqsave(&chan->lock, flags);\r\nif (chan->state == CPDMA_STATE_TEARDOWN) {\r\nret = -EINVAL;\r\ngoto unlock_ret;\r\n}\r\nif (chan->count >= chan->desc_num) {\r\nchan->stats.desc_alloc_fail++;\r\nret = -ENOMEM;\r\ngoto unlock_ret;\r\n}\r\ndesc = cpdma_desc_alloc(ctlr->pool);\r\nif (!desc) {\r\nchan->stats.desc_alloc_fail++;\r\nret = -ENOMEM;\r\ngoto unlock_ret;\r\n}\r\nif (len < ctlr->params.min_packet_size) {\r\nlen = ctlr->params.min_packet_size;\r\nchan->stats.runt_transmit_buff++;\r\n}\r\nbuffer = dma_map_single(ctlr->dev, data, len, chan->dir);\r\nret = dma_mapping_error(ctlr->dev, buffer);\r\nif (ret) {\r\ncpdma_desc_free(ctlr->pool, desc, 1);\r\nret = -EINVAL;\r\ngoto unlock_ret;\r\n}\r\nmode = CPDMA_DESC_OWNER | CPDMA_DESC_SOP | CPDMA_DESC_EOP;\r\ncpdma_desc_to_port(chan, mode, directed);\r\nwritel_relaxed(0, &desc->hw_next);\r\nwritel_relaxed(buffer, &desc->hw_buffer);\r\nwritel_relaxed(len, &desc->hw_len);\r\nwritel_relaxed(mode | len, &desc->hw_mode);\r\nwritel_relaxed(token, &desc->sw_token);\r\nwritel_relaxed(buffer, &desc->sw_buffer);\r\nwritel_relaxed(len, &desc->sw_len);\r\ndesc_read(desc, sw_len);\r\n__cpdma_chan_submit(chan, desc);\r\nif (chan->state == CPDMA_STATE_ACTIVE && chan->rxfree)\r\nchan_write(chan, rxfree, 1);\r\nchan->count++;\r\nunlock_ret:\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn ret;\r\n}\r\nbool cpdma_check_free_tx_desc(struct cpdma_chan *chan)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nstruct cpdma_desc_pool *pool = ctlr->pool;\r\nbool free_tx_desc;\r\nunsigned long flags;\r\nspin_lock_irqsave(&chan->lock, flags);\r\nfree_tx_desc = (chan->count < chan->desc_num) &&\r\ngen_pool_avail(pool->gen_pool);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn free_tx_desc;\r\n}\r\nstatic void __cpdma_chan_free(struct cpdma_chan *chan,\r\nstruct cpdma_desc __iomem *desc,\r\nint outlen, int status)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nstruct cpdma_desc_pool *pool = ctlr->pool;\r\ndma_addr_t buff_dma;\r\nint origlen;\r\nvoid *token;\r\ntoken = (void *)desc_read(desc, sw_token);\r\nbuff_dma = desc_read(desc, sw_buffer);\r\noriglen = desc_read(desc, sw_len);\r\ndma_unmap_single(ctlr->dev, buff_dma, origlen, chan->dir);\r\ncpdma_desc_free(pool, desc, 1);\r\n(*chan->handler)(token, outlen, status);\r\n}\r\nstatic int __cpdma_chan_process(struct cpdma_chan *chan)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nstruct cpdma_desc __iomem *desc;\r\nint status, outlen;\r\nint cb_status = 0;\r\nstruct cpdma_desc_pool *pool = ctlr->pool;\r\ndma_addr_t desc_dma;\r\nunsigned long flags;\r\nspin_lock_irqsave(&chan->lock, flags);\r\ndesc = chan->head;\r\nif (!desc) {\r\nchan->stats.empty_dequeue++;\r\nstatus = -ENOENT;\r\ngoto unlock_ret;\r\n}\r\ndesc_dma = desc_phys(pool, desc);\r\nstatus = desc_read(desc, hw_mode);\r\noutlen = status & 0x7ff;\r\nif (status & CPDMA_DESC_OWNER) {\r\nchan->stats.busy_dequeue++;\r\nstatus = -EBUSY;\r\ngoto unlock_ret;\r\n}\r\nif (status & CPDMA_DESC_PASS_CRC)\r\noutlen -= CPDMA_DESC_CRC_LEN;\r\nstatus = status & (CPDMA_DESC_EOQ | CPDMA_DESC_TD_COMPLETE |\r\nCPDMA_DESC_PORT_MASK);\r\nchan->head = desc_from_phys(pool, desc_read(desc, hw_next));\r\nchan_write(chan, cp, desc_dma);\r\nchan->count--;\r\nchan->stats.good_dequeue++;\r\nif ((status & CPDMA_DESC_EOQ) && chan->head) {\r\nchan->stats.requeue++;\r\nchan_write(chan, hdp, desc_phys(pool, chan->head));\r\n}\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nif (unlikely(status & CPDMA_DESC_TD_COMPLETE))\r\ncb_status = -ENOSYS;\r\nelse\r\ncb_status = status;\r\n__cpdma_chan_free(chan, desc, outlen, cb_status);\r\nreturn status;\r\nunlock_ret:\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn status;\r\n}\r\nint cpdma_chan_process(struct cpdma_chan *chan, int quota)\r\n{\r\nint used = 0, ret = 0;\r\nif (chan->state != CPDMA_STATE_ACTIVE)\r\nreturn -EINVAL;\r\nwhile (used < quota) {\r\nret = __cpdma_chan_process(chan);\r\nif (ret < 0)\r\nbreak;\r\nused++;\r\n}\r\nreturn used;\r\n}\r\nint cpdma_chan_start(struct cpdma_chan *chan)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nret = cpdma_chan_set_chan_shaper(chan);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nif (ret)\r\nreturn ret;\r\nret = cpdma_chan_on(chan);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nint cpdma_chan_stop(struct cpdma_chan *chan)\r\n{\r\nstruct cpdma_ctlr *ctlr = chan->ctlr;\r\nstruct cpdma_desc_pool *pool = ctlr->pool;\r\nunsigned long flags;\r\nint ret;\r\nunsigned timeout;\r\nspin_lock_irqsave(&chan->lock, flags);\r\nif (chan->state == CPDMA_STATE_TEARDOWN) {\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn -EINVAL;\r\n}\r\nchan->state = CPDMA_STATE_TEARDOWN;\r\ndma_reg_write(ctlr, chan->int_clear, chan->mask);\r\ndma_reg_write(ctlr, chan->td, chan_linear(chan));\r\ntimeout = 100 * 100;\r\nwhile (timeout) {\r\nu32 cp = chan_read(chan, cp);\r\nif ((cp & CPDMA_TEARDOWN_VALUE) == CPDMA_TEARDOWN_VALUE)\r\nbreak;\r\nudelay(10);\r\ntimeout--;\r\n}\r\nWARN_ON(!timeout);\r\nchan_write(chan, cp, CPDMA_TEARDOWN_VALUE);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\ndo {\r\nret = __cpdma_chan_process(chan);\r\nif (ret < 0)\r\nbreak;\r\n} while ((ret & CPDMA_DESC_TD_COMPLETE) == 0);\r\nspin_lock_irqsave(&chan->lock, flags);\r\nwhile (chan->head) {\r\nstruct cpdma_desc __iomem *desc = chan->head;\r\ndma_addr_t next_dma;\r\nnext_dma = desc_read(desc, hw_next);\r\nchan->head = desc_from_phys(pool, next_dma);\r\nchan->count--;\r\nchan->stats.teardown_dequeue++;\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\n__cpdma_chan_free(chan, desc, 0, -ENOSYS);\r\nspin_lock_irqsave(&chan->lock, flags);\r\n}\r\nchan->state = CPDMA_STATE_IDLE;\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn 0;\r\n}\r\nint cpdma_chan_int_ctrl(struct cpdma_chan *chan, bool enable)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&chan->lock, flags);\r\nif (chan->state != CPDMA_STATE_ACTIVE) {\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn -EINVAL;\r\n}\r\ndma_reg_write(chan->ctlr, enable ? chan->int_set : chan->int_clear,\r\nchan->mask);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn 0;\r\n}\r\nint cpdma_control_get(struct cpdma_ctlr *ctlr, int control)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nret = _cpdma_control_get(ctlr, control);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn ret;\r\n}\r\nint cpdma_control_set(struct cpdma_ctlr *ctlr, int control, int value)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&ctlr->lock, flags);\r\nret = _cpdma_control_set(ctlr, control, value);\r\nspin_unlock_irqrestore(&ctlr->lock, flags);\r\nreturn ret;\r\n}\r\nint cpdma_get_num_rx_descs(struct cpdma_ctlr *ctlr)\r\n{\r\nreturn ctlr->num_rx_desc;\r\n}\r\nint cpdma_get_num_tx_descs(struct cpdma_ctlr *ctlr)\r\n{\r\nreturn ctlr->num_tx_desc;\r\n}\r\nvoid cpdma_set_num_rx_descs(struct cpdma_ctlr *ctlr, int num_rx_desc)\r\n{\r\nctlr->num_rx_desc = num_rx_desc;\r\nctlr->num_tx_desc = ctlr->pool->num_desc - ctlr->num_rx_desc;\r\n}
