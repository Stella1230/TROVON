static ssize_t show_feedback_ctrs(struct kobject *kobj,\r\nstruct attribute *attr, char *buf)\r\n{\r\nstruct cpc_desc *cpc_ptr = to_cpc_desc(kobj);\r\nstruct cppc_perf_fb_ctrs fb_ctrs = {0};\r\nint ret;\r\nret = cppc_get_perf_ctrs(cpc_ptr->cpu_id, &fb_ctrs);\r\nif (ret)\r\nreturn ret;\r\nreturn scnprintf(buf, PAGE_SIZE, "ref:%llu del:%llu\n",\r\nfb_ctrs.reference, fb_ctrs.delivered);\r\n}\r\nstatic int check_pcc_chan(bool chk_err_bit)\r\n{\r\nint ret = -EIO, status = 0;\r\nstruct acpi_pcct_shared_memory __iomem *generic_comm_base = pcc_data.pcc_comm_addr;\r\nktime_t next_deadline = ktime_add(ktime_get(), pcc_data.deadline);\r\nif (!pcc_data.platform_owns_pcc)\r\nreturn 0;\r\nwhile (!ktime_after(ktime_get(), next_deadline)) {\r\nstatus = readw_relaxed(&generic_comm_base->status);\r\nif (status & PCC_CMD_COMPLETE_MASK) {\r\nret = 0;\r\nif (chk_err_bit && (status & PCC_ERROR_MASK))\r\nret = -EIO;\r\nbreak;\r\n}\r\nudelay(3);\r\n}\r\nif (likely(!ret))\r\npcc_data.platform_owns_pcc = false;\r\nelse\r\npr_err("PCC check channel failed. Status=%x\n", status);\r\nreturn ret;\r\n}\r\nstatic int send_pcc_cmd(u16 cmd)\r\n{\r\nint ret = -EIO, i;\r\nstruct acpi_pcct_shared_memory *generic_comm_base =\r\n(struct acpi_pcct_shared_memory *) pcc_data.pcc_comm_addr;\r\nstatic ktime_t last_cmd_cmpl_time, last_mpar_reset;\r\nstatic int mpar_count;\r\nunsigned int time_delta;\r\nif (cmd == CMD_READ) {\r\nif (pcc_data.pending_pcc_write_cmd)\r\nsend_pcc_cmd(CMD_WRITE);\r\nret = check_pcc_chan(false);\r\nif (ret)\r\ngoto end;\r\n} else\r\npcc_data.pending_pcc_write_cmd = FALSE;\r\nif (pcc_data.pcc_mrtt) {\r\ntime_delta = ktime_us_delta(ktime_get(), last_cmd_cmpl_time);\r\nif (pcc_data.pcc_mrtt > time_delta)\r\nudelay(pcc_data.pcc_mrtt - time_delta);\r\n}\r\nif (pcc_data.pcc_mpar) {\r\nif (mpar_count == 0) {\r\ntime_delta = ktime_ms_delta(ktime_get(), last_mpar_reset);\r\nif (time_delta < 60 * MSEC_PER_SEC) {\r\npr_debug("PCC cmd not sent due to MPAR limit");\r\nret = -EIO;\r\ngoto end;\r\n}\r\nlast_mpar_reset = ktime_get();\r\nmpar_count = pcc_data.pcc_mpar;\r\n}\r\nmpar_count--;\r\n}\r\nwritew_relaxed(cmd, &generic_comm_base->command);\r\nwritew_relaxed(0, &generic_comm_base->status);\r\npcc_data.platform_owns_pcc = true;\r\nret = mbox_send_message(pcc_data.pcc_channel, &cmd);\r\nif (ret < 0) {\r\npr_err("Err sending PCC mbox message. cmd:%d, ret:%d\n",\r\ncmd, ret);\r\ngoto end;\r\n}\r\nret = check_pcc_chan(true);\r\nif (pcc_data.pcc_mrtt)\r\nlast_cmd_cmpl_time = ktime_get();\r\nif (pcc_data.pcc_channel->mbox->txdone_irq)\r\nmbox_chan_txdone(pcc_data.pcc_channel, ret);\r\nelse\r\nmbox_client_txdone(pcc_data.pcc_channel, ret);\r\nend:\r\nif (cmd == CMD_WRITE) {\r\nif (unlikely(ret)) {\r\nfor_each_possible_cpu(i) {\r\nstruct cpc_desc *desc = per_cpu(cpc_desc_ptr, i);\r\nif (!desc)\r\ncontinue;\r\nif (desc->write_cmd_id == pcc_data.pcc_write_cnt)\r\ndesc->write_cmd_status = ret;\r\n}\r\n}\r\npcc_data.pcc_write_cnt++;\r\nwake_up_all(&pcc_data.pcc_write_wait_q);\r\n}\r\nreturn ret;\r\n}\r\nstatic void cppc_chan_tx_done(struct mbox_client *cl, void *msg, int ret)\r\n{\r\nif (ret < 0)\r\npr_debug("TX did not complete: CMD sent:%x, ret:%d\n",\r\n*(u16 *)msg, ret);\r\nelse\r\npr_debug("TX completed. CMD sent:%x, ret:%d\n",\r\n*(u16 *)msg, ret);\r\n}\r\nstatic int acpi_get_psd(struct cpc_desc *cpc_ptr, acpi_handle handle)\r\n{\r\nint result = -EFAULT;\r\nacpi_status status = AE_OK;\r\nstruct acpi_buffer buffer = {ACPI_ALLOCATE_BUFFER, NULL};\r\nstruct acpi_buffer format = {sizeof("NNNNN"), "NNNNN"};\r\nstruct acpi_buffer state = {0, NULL};\r\nunion acpi_object *psd = NULL;\r\nstruct acpi_psd_package *pdomain;\r\nstatus = acpi_evaluate_object_typed(handle, "_PSD", NULL, &buffer,\r\nACPI_TYPE_PACKAGE);\r\nif (ACPI_FAILURE(status))\r\nreturn -ENODEV;\r\npsd = buffer.pointer;\r\nif (!psd || psd->package.count != 1) {\r\npr_debug("Invalid _PSD data\n");\r\ngoto end;\r\n}\r\npdomain = &(cpc_ptr->domain_info);\r\nstate.length = sizeof(struct acpi_psd_package);\r\nstate.pointer = pdomain;\r\nstatus = acpi_extract_package(&(psd->package.elements[0]),\r\n&format, &state);\r\nif (ACPI_FAILURE(status)) {\r\npr_debug("Invalid _PSD data for CPU:%d\n", cpc_ptr->cpu_id);\r\ngoto end;\r\n}\r\nif (pdomain->num_entries != ACPI_PSD_REV0_ENTRIES) {\r\npr_debug("Unknown _PSD:num_entries for CPU:%d\n", cpc_ptr->cpu_id);\r\ngoto end;\r\n}\r\nif (pdomain->revision != ACPI_PSD_REV0_REVISION) {\r\npr_debug("Unknown _PSD:revision for CPU: %d\n", cpc_ptr->cpu_id);\r\ngoto end;\r\n}\r\nif (pdomain->coord_type != DOMAIN_COORD_TYPE_SW_ALL &&\r\npdomain->coord_type != DOMAIN_COORD_TYPE_SW_ANY &&\r\npdomain->coord_type != DOMAIN_COORD_TYPE_HW_ALL) {\r\npr_debug("Invalid _PSD:coord_type for CPU:%d\n", cpc_ptr->cpu_id);\r\ngoto end;\r\n}\r\nresult = 0;\r\nend:\r\nkfree(buffer.pointer);\r\nreturn result;\r\n}\r\nint acpi_get_psd_map(struct cppc_cpudata **all_cpu_data)\r\n{\r\nint count_target;\r\nint retval = 0;\r\nunsigned int i, j;\r\ncpumask_var_t covered_cpus;\r\nstruct cppc_cpudata *pr, *match_pr;\r\nstruct acpi_psd_package *pdomain;\r\nstruct acpi_psd_package *match_pdomain;\r\nstruct cpc_desc *cpc_ptr, *match_cpc_ptr;\r\nif (!zalloc_cpumask_var(&covered_cpus, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nfor_each_possible_cpu(i) {\r\npr = all_cpu_data[i];\r\nif (!pr)\r\ncontinue;\r\nif (cpumask_test_cpu(i, covered_cpus))\r\ncontinue;\r\ncpc_ptr = per_cpu(cpc_desc_ptr, i);\r\nif (!cpc_ptr) {\r\nretval = -EFAULT;\r\ngoto err_ret;\r\n}\r\npdomain = &(cpc_ptr->domain_info);\r\ncpumask_set_cpu(i, pr->shared_cpu_map);\r\ncpumask_set_cpu(i, covered_cpus);\r\nif (pdomain->num_processors <= 1)\r\ncontinue;\r\ncount_target = pdomain->num_processors;\r\nif (pdomain->coord_type == DOMAIN_COORD_TYPE_SW_ALL)\r\npr->shared_type = CPUFREQ_SHARED_TYPE_ALL;\r\nelse if (pdomain->coord_type == DOMAIN_COORD_TYPE_HW_ALL)\r\npr->shared_type = CPUFREQ_SHARED_TYPE_HW;\r\nelse if (pdomain->coord_type == DOMAIN_COORD_TYPE_SW_ANY)\r\npr->shared_type = CPUFREQ_SHARED_TYPE_ANY;\r\nfor_each_possible_cpu(j) {\r\nif (i == j)\r\ncontinue;\r\nmatch_cpc_ptr = per_cpu(cpc_desc_ptr, j);\r\nif (!match_cpc_ptr) {\r\nretval = -EFAULT;\r\ngoto err_ret;\r\n}\r\nmatch_pdomain = &(match_cpc_ptr->domain_info);\r\nif (match_pdomain->domain != pdomain->domain)\r\ncontinue;\r\nif (match_pdomain->num_processors != count_target) {\r\nretval = -EFAULT;\r\ngoto err_ret;\r\n}\r\nif (pdomain->coord_type != match_pdomain->coord_type) {\r\nretval = -EFAULT;\r\ngoto err_ret;\r\n}\r\ncpumask_set_cpu(j, covered_cpus);\r\ncpumask_set_cpu(j, pr->shared_cpu_map);\r\n}\r\nfor_each_possible_cpu(j) {\r\nif (i == j)\r\ncontinue;\r\nmatch_pr = all_cpu_data[j];\r\nif (!match_pr)\r\ncontinue;\r\nmatch_cpc_ptr = per_cpu(cpc_desc_ptr, j);\r\nif (!match_cpc_ptr) {\r\nretval = -EFAULT;\r\ngoto err_ret;\r\n}\r\nmatch_pdomain = &(match_cpc_ptr->domain_info);\r\nif (match_pdomain->domain != pdomain->domain)\r\ncontinue;\r\nmatch_pr->shared_type = pr->shared_type;\r\ncpumask_copy(match_pr->shared_cpu_map,\r\npr->shared_cpu_map);\r\n}\r\n}\r\nerr_ret:\r\nfor_each_possible_cpu(i) {\r\npr = all_cpu_data[i];\r\nif (!pr)\r\ncontinue;\r\nif (retval) {\r\ncpumask_clear(pr->shared_cpu_map);\r\ncpumask_set_cpu(i, pr->shared_cpu_map);\r\npr->shared_type = CPUFREQ_SHARED_TYPE_ALL;\r\n}\r\n}\r\nfree_cpumask_var(covered_cpus);\r\nreturn retval;\r\n}\r\nstatic int register_pcc_channel(int pcc_subspace_idx)\r\n{\r\nstruct acpi_pcct_hw_reduced *cppc_ss;\r\nu64 usecs_lat;\r\nif (pcc_subspace_idx >= 0) {\r\npcc_data.pcc_channel = pcc_mbox_request_channel(&cppc_mbox_cl,\r\npcc_subspace_idx);\r\nif (IS_ERR(pcc_data.pcc_channel)) {\r\npr_err("Failed to find PCC communication channel\n");\r\nreturn -ENODEV;\r\n}\r\ncppc_ss = (pcc_data.pcc_channel)->con_priv;\r\nif (!cppc_ss) {\r\npr_err("No PCC subspace found for CPPC\n");\r\nreturn -ENODEV;\r\n}\r\nusecs_lat = NUM_RETRIES * cppc_ss->latency;\r\npcc_data.deadline = ns_to_ktime(usecs_lat * NSEC_PER_USEC);\r\npcc_data.pcc_mrtt = cppc_ss->min_turnaround_time;\r\npcc_data.pcc_mpar = cppc_ss->max_access_rate;\r\npcc_data.pcc_nominal = cppc_ss->latency;\r\npcc_data.pcc_comm_addr = acpi_os_ioremap(cppc_ss->base_address, cppc_ss->length);\r\nif (!pcc_data.pcc_comm_addr) {\r\npr_err("Failed to ioremap PCC comm region mem\n");\r\nreturn -ENOMEM;\r\n}\r\npcc_data.pcc_channel_acquired = true;\r\n}\r\nreturn 0;\r\n}\r\nbool __weak cpc_ffh_supported(void)\r\n{\r\nreturn false;\r\n}\r\nint acpi_cppc_processor_probe(struct acpi_processor *pr)\r\n{\r\nstruct acpi_buffer output = {ACPI_ALLOCATE_BUFFER, NULL};\r\nunion acpi_object *out_obj, *cpc_obj;\r\nstruct cpc_desc *cpc_ptr;\r\nstruct cpc_reg *gas_t;\r\nstruct device *cpu_dev;\r\nacpi_handle handle = pr->handle;\r\nunsigned int num_ent, i, cpc_rev;\r\nacpi_status status;\r\nint ret = -EFAULT;\r\nstatus = acpi_evaluate_object_typed(handle, "_CPC", NULL, &output,\r\nACPI_TYPE_PACKAGE);\r\nif (ACPI_FAILURE(status)) {\r\nret = -ENODEV;\r\ngoto out_buf_free;\r\n}\r\nout_obj = (union acpi_object *) output.pointer;\r\ncpc_ptr = kzalloc(sizeof(struct cpc_desc), GFP_KERNEL);\r\nif (!cpc_ptr) {\r\nret = -ENOMEM;\r\ngoto out_buf_free;\r\n}\r\ncpc_obj = &out_obj->package.elements[0];\r\nif (cpc_obj->type == ACPI_TYPE_INTEGER) {\r\nnum_ent = cpc_obj->integer.value;\r\n} else {\r\npr_debug("Unexpected entry type(%d) for NumEntries\n",\r\ncpc_obj->type);\r\ngoto out_free;\r\n}\r\nif (num_ent != CPPC_NUM_ENT) {\r\npr_debug("Firmware exports %d entries. Expected: %d\n",\r\nnum_ent, CPPC_NUM_ENT);\r\ngoto out_free;\r\n}\r\ncpc_ptr->num_entries = num_ent;\r\ncpc_obj = &out_obj->package.elements[1];\r\nif (cpc_obj->type == ACPI_TYPE_INTEGER) {\r\ncpc_rev = cpc_obj->integer.value;\r\n} else {\r\npr_debug("Unexpected entry type(%d) for Revision\n",\r\ncpc_obj->type);\r\ngoto out_free;\r\n}\r\nif (cpc_rev != CPPC_REV) {\r\npr_debug("Firmware exports revision:%d. Expected:%d\n",\r\ncpc_rev, CPPC_REV);\r\ngoto out_free;\r\n}\r\nfor (i = 2; i < num_ent; i++) {\r\ncpc_obj = &out_obj->package.elements[i];\r\nif (cpc_obj->type == ACPI_TYPE_INTEGER) {\r\ncpc_ptr->cpc_regs[i-2].type = ACPI_TYPE_INTEGER;\r\ncpc_ptr->cpc_regs[i-2].cpc_entry.int_value = cpc_obj->integer.value;\r\n} else if (cpc_obj->type == ACPI_TYPE_BUFFER) {\r\ngas_t = (struct cpc_reg *)\r\ncpc_obj->buffer.pointer;\r\nif (gas_t->space_id == ACPI_ADR_SPACE_PLATFORM_COMM) {\r\nif (pcc_data.pcc_subspace_idx < 0)\r\npcc_data.pcc_subspace_idx = gas_t->access_width;\r\nelse if (pcc_data.pcc_subspace_idx != gas_t->access_width) {\r\npr_debug("Mismatched PCC ids.\n");\r\ngoto out_free;\r\n}\r\n} else if (gas_t->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY) {\r\nif (gas_t->address) {\r\nvoid __iomem *addr;\r\naddr = ioremap(gas_t->address, gas_t->bit_width/8);\r\nif (!addr)\r\ngoto out_free;\r\ncpc_ptr->cpc_regs[i-2].sys_mem_vaddr = addr;\r\n}\r\n} else {\r\nif (gas_t->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE || !cpc_ffh_supported()) {\r\npr_debug("Unsupported register type: %d\n", gas_t->space_id);\r\ngoto out_free;\r\n}\r\n}\r\ncpc_ptr->cpc_regs[i-2].type = ACPI_TYPE_BUFFER;\r\nmemcpy(&cpc_ptr->cpc_regs[i-2].cpc_entry.reg, gas_t, sizeof(*gas_t));\r\n} else {\r\npr_debug("Err in entry:%d in CPC table of CPU:%d \n", i, pr->id);\r\ngoto out_free;\r\n}\r\n}\r\ncpc_ptr->cpu_id = pr->id;\r\nret = acpi_get_psd(cpc_ptr, handle);\r\nif (ret)\r\ngoto out_free;\r\nif (!pcc_data.pcc_channel_acquired) {\r\nret = register_pcc_channel(pcc_data.pcc_subspace_idx);\r\nif (ret)\r\ngoto out_free;\r\ninit_rwsem(&pcc_data.pcc_lock);\r\ninit_waitqueue_head(&pcc_data.pcc_write_wait_q);\r\n}\r\npr_debug("Parsed CPC struct for CPU: %d\n", pr->id);\r\ncpu_dev = get_cpu_device(pr->id);\r\nif (!cpu_dev) {\r\nret = -EINVAL;\r\ngoto out_free;\r\n}\r\nper_cpu(cpc_desc_ptr, pr->id) = cpc_ptr;\r\nret = kobject_init_and_add(&cpc_ptr->kobj, &cppc_ktype, &cpu_dev->kobj,\r\n"acpi_cppc");\r\nif (ret) {\r\nper_cpu(cpc_desc_ptr, pr->id) = NULL;\r\ngoto out_free;\r\n}\r\nkfree(output.pointer);\r\nreturn 0;\r\nout_free:\r\nfor (i = 2; i < cpc_ptr->num_entries; i++) {\r\nvoid __iomem *addr = cpc_ptr->cpc_regs[i-2].sys_mem_vaddr;\r\nif (addr)\r\niounmap(addr);\r\n}\r\nkfree(cpc_ptr);\r\nout_buf_free:\r\nkfree(output.pointer);\r\nreturn ret;\r\n}\r\nvoid acpi_cppc_processor_exit(struct acpi_processor *pr)\r\n{\r\nstruct cpc_desc *cpc_ptr;\r\nunsigned int i;\r\nvoid __iomem *addr;\r\ncpc_ptr = per_cpu(cpc_desc_ptr, pr->id);\r\nif (!cpc_ptr)\r\nreturn;\r\nfor (i = 2; i < cpc_ptr->num_entries; i++) {\r\naddr = cpc_ptr->cpc_regs[i-2].sys_mem_vaddr;\r\nif (addr)\r\niounmap(addr);\r\n}\r\nkobject_put(&cpc_ptr->kobj);\r\nkfree(cpc_ptr);\r\n}\r\nint __weak cpc_read_ffh(int cpunum, struct cpc_reg *reg, u64 *val)\r\n{\r\nreturn -ENOTSUPP;\r\n}\r\nint __weak cpc_write_ffh(int cpunum, struct cpc_reg *reg, u64 val)\r\n{\r\nreturn -ENOTSUPP;\r\n}\r\nstatic int cpc_read(int cpu, struct cpc_register_resource *reg_res, u64 *val)\r\n{\r\nint ret_val = 0;\r\nvoid __iomem *vaddr = 0;\r\nstruct cpc_reg *reg = &reg_res->cpc_entry.reg;\r\nif (reg_res->type == ACPI_TYPE_INTEGER) {\r\n*val = reg_res->cpc_entry.int_value;\r\nreturn ret_val;\r\n}\r\n*val = 0;\r\nif (reg->space_id == ACPI_ADR_SPACE_PLATFORM_COMM)\r\nvaddr = GET_PCC_VADDR(reg->address);\r\nelse if (reg->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)\r\nvaddr = reg_res->sys_mem_vaddr;\r\nelse if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE)\r\nreturn cpc_read_ffh(cpu, reg, val);\r\nelse\r\nreturn acpi_os_read_memory((acpi_physical_address)reg->address,\r\nval, reg->bit_width);\r\nswitch (reg->bit_width) {\r\ncase 8:\r\n*val = readb_relaxed(vaddr);\r\nbreak;\r\ncase 16:\r\n*val = readw_relaxed(vaddr);\r\nbreak;\r\ncase 32:\r\n*val = readl_relaxed(vaddr);\r\nbreak;\r\ncase 64:\r\n*val = readq_relaxed(vaddr);\r\nbreak;\r\ndefault:\r\npr_debug("Error: Cannot read %u bit width from PCC\n",\r\nreg->bit_width);\r\nret_val = -EFAULT;\r\n}\r\nreturn ret_val;\r\n}\r\nstatic int cpc_write(int cpu, struct cpc_register_resource *reg_res, u64 val)\r\n{\r\nint ret_val = 0;\r\nvoid __iomem *vaddr = 0;\r\nstruct cpc_reg *reg = &reg_res->cpc_entry.reg;\r\nif (reg->space_id == ACPI_ADR_SPACE_PLATFORM_COMM)\r\nvaddr = GET_PCC_VADDR(reg->address);\r\nelse if (reg->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)\r\nvaddr = reg_res->sys_mem_vaddr;\r\nelse if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE)\r\nreturn cpc_write_ffh(cpu, reg, val);\r\nelse\r\nreturn acpi_os_write_memory((acpi_physical_address)reg->address,\r\nval, reg->bit_width);\r\nswitch (reg->bit_width) {\r\ncase 8:\r\nwriteb_relaxed(val, vaddr);\r\nbreak;\r\ncase 16:\r\nwritew_relaxed(val, vaddr);\r\nbreak;\r\ncase 32:\r\nwritel_relaxed(val, vaddr);\r\nbreak;\r\ncase 64:\r\nwriteq_relaxed(val, vaddr);\r\nbreak;\r\ndefault:\r\npr_debug("Error: Cannot write %u bit width to PCC\n",\r\nreg->bit_width);\r\nret_val = -EFAULT;\r\nbreak;\r\n}\r\nreturn ret_val;\r\n}\r\nint cppc_get_perf_caps(int cpunum, struct cppc_perf_caps *perf_caps)\r\n{\r\nstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpunum);\r\nstruct cpc_register_resource *highest_reg, *lowest_reg,\r\n*lowest_non_linear_reg, *nominal_reg;\r\nu64 high, low, nom, min_nonlinear;\r\nint ret = 0, regs_in_pcc = 0;\r\nif (!cpc_desc) {\r\npr_debug("No CPC descriptor for CPU:%d\n", cpunum);\r\nreturn -ENODEV;\r\n}\r\nhighest_reg = &cpc_desc->cpc_regs[HIGHEST_PERF];\r\nlowest_reg = &cpc_desc->cpc_regs[LOWEST_PERF];\r\nlowest_non_linear_reg = &cpc_desc->cpc_regs[LOW_NON_LINEAR_PERF];\r\nnominal_reg = &cpc_desc->cpc_regs[NOMINAL_PERF];\r\nif (CPC_IN_PCC(highest_reg) || CPC_IN_PCC(lowest_reg) ||\r\nCPC_IN_PCC(lowest_non_linear_reg) || CPC_IN_PCC(nominal_reg)) {\r\nregs_in_pcc = 1;\r\ndown_write(&pcc_data.pcc_lock);\r\nif (send_pcc_cmd(CMD_READ) < 0) {\r\nret = -EIO;\r\ngoto out_err;\r\n}\r\n}\r\ncpc_read(cpunum, highest_reg, &high);\r\nperf_caps->highest_perf = high;\r\ncpc_read(cpunum, lowest_reg, &low);\r\nperf_caps->lowest_perf = low;\r\ncpc_read(cpunum, nominal_reg, &nom);\r\nperf_caps->nominal_perf = nom;\r\ncpc_read(cpunum, lowest_non_linear_reg, &min_nonlinear);\r\nperf_caps->lowest_nonlinear_perf = min_nonlinear;\r\nif (!high || !low || !nom || !min_nonlinear)\r\nret = -EFAULT;\r\nout_err:\r\nif (regs_in_pcc)\r\nup_write(&pcc_data.pcc_lock);\r\nreturn ret;\r\n}\r\nint cppc_get_perf_ctrs(int cpunum, struct cppc_perf_fb_ctrs *perf_fb_ctrs)\r\n{\r\nstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpunum);\r\nstruct cpc_register_resource *delivered_reg, *reference_reg,\r\n*ref_perf_reg, *ctr_wrap_reg;\r\nu64 delivered, reference, ref_perf, ctr_wrap_time;\r\nint ret = 0, regs_in_pcc = 0;\r\nif (!cpc_desc) {\r\npr_debug("No CPC descriptor for CPU:%d\n", cpunum);\r\nreturn -ENODEV;\r\n}\r\ndelivered_reg = &cpc_desc->cpc_regs[DELIVERED_CTR];\r\nreference_reg = &cpc_desc->cpc_regs[REFERENCE_CTR];\r\nref_perf_reg = &cpc_desc->cpc_regs[REFERENCE_PERF];\r\nctr_wrap_reg = &cpc_desc->cpc_regs[CTR_WRAP_TIME];\r\nif (!CPC_SUPPORTED(ref_perf_reg))\r\nref_perf_reg = &cpc_desc->cpc_regs[NOMINAL_PERF];\r\nif (CPC_IN_PCC(delivered_reg) || CPC_IN_PCC(reference_reg) ||\r\nCPC_IN_PCC(ctr_wrap_reg) || CPC_IN_PCC(ref_perf_reg)) {\r\ndown_write(&pcc_data.pcc_lock);\r\nregs_in_pcc = 1;\r\nif (send_pcc_cmd(CMD_READ) < 0) {\r\nret = -EIO;\r\ngoto out_err;\r\n}\r\n}\r\ncpc_read(cpunum, delivered_reg, &delivered);\r\ncpc_read(cpunum, reference_reg, &reference);\r\ncpc_read(cpunum, ref_perf_reg, &ref_perf);\r\nctr_wrap_time = (u64)(~((u64)0));\r\nif (CPC_SUPPORTED(ctr_wrap_reg))\r\ncpc_read(cpunum, ctr_wrap_reg, &ctr_wrap_time);\r\nif (!delivered || !reference || !ref_perf) {\r\nret = -EFAULT;\r\ngoto out_err;\r\n}\r\nperf_fb_ctrs->delivered = delivered;\r\nperf_fb_ctrs->reference = reference;\r\nperf_fb_ctrs->reference_perf = ref_perf;\r\nperf_fb_ctrs->wraparound_time = ctr_wrap_time;\r\nout_err:\r\nif (regs_in_pcc)\r\nup_write(&pcc_data.pcc_lock);\r\nreturn ret;\r\n}\r\nint cppc_set_perf(int cpu, struct cppc_perf_ctrls *perf_ctrls)\r\n{\r\nstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpu);\r\nstruct cpc_register_resource *desired_reg;\r\nint ret = 0;\r\nif (!cpc_desc) {\r\npr_debug("No CPC descriptor for CPU:%d\n", cpu);\r\nreturn -ENODEV;\r\n}\r\ndesired_reg = &cpc_desc->cpc_regs[DESIRED_PERF];\r\nif (CPC_IN_PCC(desired_reg)) {\r\ndown_read(&pcc_data.pcc_lock);\r\nif (pcc_data.platform_owns_pcc) {\r\nret = check_pcc_chan(false);\r\nif (ret) {\r\nup_read(&pcc_data.pcc_lock);\r\nreturn ret;\r\n}\r\n}\r\npcc_data.pending_pcc_write_cmd = true;\r\ncpc_desc->write_cmd_id = pcc_data.pcc_write_cnt;\r\ncpc_desc->write_cmd_status = 0;\r\n}\r\ncpc_write(cpu, desired_reg, perf_ctrls->desired_perf);\r\nif (CPC_IN_PCC(desired_reg))\r\nup_read(&pcc_data.pcc_lock);\r\nif (CPC_IN_PCC(desired_reg)) {\r\nif (down_write_trylock(&pcc_data.pcc_lock)) {\r\nif (pcc_data.pending_pcc_write_cmd)\r\nsend_pcc_cmd(CMD_WRITE);\r\nup_write(&pcc_data.pcc_lock);\r\n} else\r\nwait_event(pcc_data.pcc_write_wait_q,\r\ncpc_desc->write_cmd_id != pcc_data.pcc_write_cnt);\r\nret = cpc_desc->write_cmd_status;\r\n}\r\nreturn ret;\r\n}\r\nunsigned int cppc_get_transition_latency(int cpu_num)\r\n{\r\nunsigned int latency_ns = 0;\r\nstruct cpc_desc *cpc_desc;\r\nstruct cpc_register_resource *desired_reg;\r\ncpc_desc = per_cpu(cpc_desc_ptr, cpu_num);\r\nif (!cpc_desc)\r\nreturn CPUFREQ_ETERNAL;\r\ndesired_reg = &cpc_desc->cpc_regs[DESIRED_PERF];\r\nif (!CPC_IN_PCC(desired_reg))\r\nreturn CPUFREQ_ETERNAL;\r\nif (pcc_data.pcc_mpar)\r\nlatency_ns = 60 * (1000 * 1000 * 1000 / pcc_data.pcc_mpar);\r\nlatency_ns = max(latency_ns, pcc_data.pcc_nominal * 1000);\r\nlatency_ns = max(latency_ns, pcc_data.pcc_mrtt * 1000);\r\nreturn latency_ns;\r\n}
