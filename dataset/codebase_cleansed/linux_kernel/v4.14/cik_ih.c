static void cik_ih_enable_interrupts(struct amdgpu_device *adev)\r\n{\r\nu32 ih_cntl = RREG32(mmIH_CNTL);\r\nu32 ih_rb_cntl = RREG32(mmIH_RB_CNTL);\r\nih_cntl |= IH_CNTL__ENABLE_INTR_MASK;\r\nih_rb_cntl |= IH_RB_CNTL__RB_ENABLE_MASK;\r\nWREG32(mmIH_CNTL, ih_cntl);\r\nWREG32(mmIH_RB_CNTL, ih_rb_cntl);\r\nadev->irq.ih.enabled = true;\r\n}\r\nstatic void cik_ih_disable_interrupts(struct amdgpu_device *adev)\r\n{\r\nu32 ih_rb_cntl = RREG32(mmIH_RB_CNTL);\r\nu32 ih_cntl = RREG32(mmIH_CNTL);\r\nih_rb_cntl &= ~IH_RB_CNTL__RB_ENABLE_MASK;\r\nih_cntl &= ~IH_CNTL__ENABLE_INTR_MASK;\r\nWREG32(mmIH_RB_CNTL, ih_rb_cntl);\r\nWREG32(mmIH_CNTL, ih_cntl);\r\nWREG32(mmIH_RB_RPTR, 0);\r\nWREG32(mmIH_RB_WPTR, 0);\r\nadev->irq.ih.enabled = false;\r\nadev->irq.ih.rptr = 0;\r\n}\r\nstatic int cik_ih_irq_init(struct amdgpu_device *adev)\r\n{\r\nint rb_bufsz;\r\nu32 interrupt_cntl, ih_cntl, ih_rb_cntl;\r\nu64 wptr_off;\r\ncik_ih_disable_interrupts(adev);\r\nWREG32(mmINTERRUPT_CNTL2, adev->dummy_page.addr >> 8);\r\ninterrupt_cntl = RREG32(mmINTERRUPT_CNTL);\r\ninterrupt_cntl &= ~INTERRUPT_CNTL__IH_DUMMY_RD_OVERRIDE_MASK;\r\ninterrupt_cntl &= ~INTERRUPT_CNTL__IH_REQ_NONSNOOP_EN_MASK;\r\nWREG32(mmINTERRUPT_CNTL, interrupt_cntl);\r\nWREG32(mmIH_RB_BASE, adev->irq.ih.gpu_addr >> 8);\r\nrb_bufsz = order_base_2(adev->irq.ih.ring_size / 4);\r\nih_rb_cntl = (IH_RB_CNTL__WPTR_OVERFLOW_ENABLE_MASK |\r\nIH_RB_CNTL__WPTR_OVERFLOW_CLEAR_MASK |\r\n(rb_bufsz << 1));\r\nih_rb_cntl |= IH_RB_CNTL__WPTR_WRITEBACK_ENABLE_MASK;\r\nwptr_off = adev->wb.gpu_addr + (adev->irq.ih.wptr_offs * 4);\r\nWREG32(mmIH_RB_WPTR_ADDR_LO, lower_32_bits(wptr_off));\r\nWREG32(mmIH_RB_WPTR_ADDR_HI, upper_32_bits(wptr_off) & 0xFF);\r\nWREG32(mmIH_RB_CNTL, ih_rb_cntl);\r\nWREG32(mmIH_RB_RPTR, 0);\r\nWREG32(mmIH_RB_WPTR, 0);\r\nih_cntl = (0x10 << IH_CNTL__MC_WRREQ_CREDIT__SHIFT) |\r\n(0x10 << IH_CNTL__MC_WR_CLEAN_CNT__SHIFT) |\r\n(0 << IH_CNTL__MC_VMID__SHIFT);\r\nif (adev->irq.msi_enabled)\r\nih_cntl |= IH_CNTL__RPTR_REARM_MASK;\r\nWREG32(mmIH_CNTL, ih_cntl);\r\npci_set_master(adev->pdev);\r\ncik_ih_enable_interrupts(adev);\r\nreturn 0;\r\n}\r\nstatic void cik_ih_irq_disable(struct amdgpu_device *adev)\r\n{\r\ncik_ih_disable_interrupts(adev);\r\nmdelay(1);\r\n}\r\nstatic u32 cik_ih_get_wptr(struct amdgpu_device *adev)\r\n{\r\nu32 wptr, tmp;\r\nwptr = le32_to_cpu(adev->wb.wb[adev->irq.ih.wptr_offs]);\r\nif (wptr & IH_RB_WPTR__RB_OVERFLOW_MASK) {\r\nwptr &= ~IH_RB_WPTR__RB_OVERFLOW_MASK;\r\ndev_warn(adev->dev, "IH ring buffer overflow (0x%08X, 0x%08X, 0x%08X)\n",\r\nwptr, adev->irq.ih.rptr, (wptr + 16) & adev->irq.ih.ptr_mask);\r\nadev->irq.ih.rptr = (wptr + 16) & adev->irq.ih.ptr_mask;\r\ntmp = RREG32(mmIH_RB_CNTL);\r\ntmp |= IH_RB_CNTL__WPTR_OVERFLOW_CLEAR_MASK;\r\nWREG32(mmIH_RB_CNTL, tmp);\r\n}\r\nreturn (wptr & adev->irq.ih.ptr_mask);\r\n}\r\nstatic void cik_ih_decode_iv(struct amdgpu_device *adev,\r\nstruct amdgpu_iv_entry *entry)\r\n{\r\nu32 ring_index = adev->irq.ih.rptr >> 2;\r\nuint32_t dw[4];\r\ndw[0] = le32_to_cpu(adev->irq.ih.ring[ring_index + 0]);\r\ndw[1] = le32_to_cpu(adev->irq.ih.ring[ring_index + 1]);\r\ndw[2] = le32_to_cpu(adev->irq.ih.ring[ring_index + 2]);\r\ndw[3] = le32_to_cpu(adev->irq.ih.ring[ring_index + 3]);\r\nentry->client_id = AMDGPU_IH_CLIENTID_LEGACY;\r\nentry->src_id = dw[0] & 0xff;\r\nentry->src_data[0] = dw[1] & 0xfffffff;\r\nentry->ring_id = dw[2] & 0xff;\r\nentry->vm_id = (dw[2] >> 8) & 0xff;\r\nentry->pas_id = (dw[2] >> 16) & 0xffff;\r\nadev->irq.ih.rptr += 16;\r\n}\r\nstatic void cik_ih_set_rptr(struct amdgpu_device *adev)\r\n{\r\nWREG32(mmIH_RB_RPTR, adev->irq.ih.rptr);\r\n}\r\nstatic int cik_ih_early_init(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nint ret;\r\nret = amdgpu_irq_add_domain(adev);\r\nif (ret)\r\nreturn ret;\r\ncik_ih_set_interrupt_funcs(adev);\r\nreturn 0;\r\n}\r\nstatic int cik_ih_sw_init(void *handle)\r\n{\r\nint r;\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nr = amdgpu_ih_ring_init(adev, 64 * 1024, false);\r\nif (r)\r\nreturn r;\r\nr = amdgpu_irq_init(adev);\r\nreturn r;\r\n}\r\nstatic int cik_ih_sw_fini(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\namdgpu_irq_fini(adev);\r\namdgpu_ih_ring_fini(adev);\r\namdgpu_irq_remove_domain(adev);\r\nreturn 0;\r\n}\r\nstatic int cik_ih_hw_init(void *handle)\r\n{\r\nint r;\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nr = cik_ih_irq_init(adev);\r\nif (r)\r\nreturn r;\r\nreturn 0;\r\n}\r\nstatic int cik_ih_hw_fini(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\ncik_ih_irq_disable(adev);\r\nreturn 0;\r\n}\r\nstatic int cik_ih_suspend(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nreturn cik_ih_hw_fini(adev);\r\n}\r\nstatic int cik_ih_resume(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nreturn cik_ih_hw_init(adev);\r\n}\r\nstatic bool cik_ih_is_idle(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nu32 tmp = RREG32(mmSRBM_STATUS);\r\nif (tmp & SRBM_STATUS__IH_BUSY_MASK)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int cik_ih_wait_for_idle(void *handle)\r\n{\r\nunsigned i;\r\nu32 tmp;\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\ntmp = RREG32(mmSRBM_STATUS) & SRBM_STATUS__IH_BUSY_MASK;\r\nif (!tmp)\r\nreturn 0;\r\nudelay(1);\r\n}\r\nreturn -ETIMEDOUT;\r\n}\r\nstatic int cik_ih_soft_reset(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nu32 srbm_soft_reset = 0;\r\nu32 tmp = RREG32(mmSRBM_STATUS);\r\nif (tmp & SRBM_STATUS__IH_BUSY_MASK)\r\nsrbm_soft_reset |= SRBM_SOFT_RESET__SOFT_RESET_IH_MASK;\r\nif (srbm_soft_reset) {\r\ntmp = RREG32(mmSRBM_SOFT_RESET);\r\ntmp |= srbm_soft_reset;\r\ndev_info(adev->dev, "SRBM_SOFT_RESET=0x%08X\n", tmp);\r\nWREG32(mmSRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(mmSRBM_SOFT_RESET);\r\nudelay(50);\r\ntmp &= ~srbm_soft_reset;\r\nWREG32(mmSRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(mmSRBM_SOFT_RESET);\r\nudelay(50);\r\n}\r\nreturn 0;\r\n}\r\nstatic int cik_ih_set_clockgating_state(void *handle,\r\nenum amd_clockgating_state state)\r\n{\r\nreturn 0;\r\n}\r\nstatic int cik_ih_set_powergating_state(void *handle,\r\nenum amd_powergating_state state)\r\n{\r\nreturn 0;\r\n}\r\nstatic void cik_ih_set_interrupt_funcs(struct amdgpu_device *adev)\r\n{\r\nif (adev->irq.ih_funcs == NULL)\r\nadev->irq.ih_funcs = &cik_ih_funcs;\r\n}
