static inline struct dpaa2_io *service_select_by_cpu(struct dpaa2_io *d,\r\nint cpu)\r\n{\r\nif (d)\r\nreturn d;\r\nif (unlikely(cpu >= num_possible_cpus()))\r\nreturn NULL;\r\nif (unlikely(cpu < 0))\r\ncpu = smp_processor_id();\r\nreturn dpio_by_cpu[cpu];\r\n}\r\nstatic inline struct dpaa2_io *service_select(struct dpaa2_io *d)\r\n{\r\nif (d)\r\nreturn d;\r\nspin_lock(&dpio_list_lock);\r\nd = list_entry(dpio_list.next, struct dpaa2_io, node);\r\nlist_del(&d->node);\r\nlist_add_tail(&d->node, &dpio_list);\r\nspin_unlock(&dpio_list_lock);\r\nreturn d;\r\n}\r\nstruct dpaa2_io *dpaa2_io_create(const struct dpaa2_io_desc *desc)\r\n{\r\nstruct dpaa2_io *obj = kmalloc(sizeof(*obj), GFP_KERNEL);\r\nif (!obj)\r\nreturn NULL;\r\nif (desc->cpu >= num_possible_cpus()) {\r\nkfree(obj);\r\nreturn NULL;\r\n}\r\natomic_set(&obj->refs, 1);\r\nobj->dpio_desc = *desc;\r\nobj->swp_desc.cena_bar = obj->dpio_desc.regs_cena;\r\nobj->swp_desc.cinh_bar = obj->dpio_desc.regs_cinh;\r\nobj->swp_desc.qman_version = obj->dpio_desc.qman_version;\r\nobj->swp = qbman_swp_init(&obj->swp_desc);\r\nif (!obj->swp) {\r\nkfree(obj);\r\nreturn NULL;\r\n}\r\nINIT_LIST_HEAD(&obj->node);\r\nspin_lock_init(&obj->lock_mgmt_cmd);\r\nspin_lock_init(&obj->lock_notifications);\r\nINIT_LIST_HEAD(&obj->notifications);\r\nqbman_swp_interrupt_set_trigger(obj->swp,\r\nQBMAN_SWP_INTERRUPT_DQRI);\r\nqbman_swp_interrupt_clear_status(obj->swp, 0xffffffff);\r\nif (obj->dpio_desc.receives_notifications)\r\nqbman_swp_push_set(obj->swp, 0, 1);\r\nspin_lock(&dpio_list_lock);\r\nlist_add_tail(&obj->node, &dpio_list);\r\nif (desc->cpu >= 0 && !dpio_by_cpu[desc->cpu])\r\ndpio_by_cpu[desc->cpu] = obj;\r\nspin_unlock(&dpio_list_lock);\r\nreturn obj;\r\n}\r\nvoid dpaa2_io_down(struct dpaa2_io *d)\r\n{\r\nif (!atomic_dec_and_test(&d->refs))\r\nreturn;\r\nkfree(d);\r\n}\r\nirqreturn_t dpaa2_io_irq(struct dpaa2_io *obj)\r\n{\r\nconst struct dpaa2_dq *dq;\r\nint max = 0;\r\nstruct qbman_swp *swp;\r\nu32 status;\r\nswp = obj->swp;\r\nstatus = qbman_swp_interrupt_read_status(swp);\r\nif (!status)\r\nreturn IRQ_NONE;\r\ndq = qbman_swp_dqrr_next(swp);\r\nwhile (dq) {\r\nif (qbman_result_is_SCN(dq)) {\r\nstruct dpaa2_io_notification_ctx *ctx;\r\nu64 q64;\r\nq64 = qbman_result_SCN_ctx(dq);\r\nctx = (void *)q64;\r\nctx->cb(ctx);\r\n} else {\r\npr_crit("fsl-mc-dpio: Unrecognised/ignored DQRR entry\n");\r\n}\r\nqbman_swp_dqrr_consume(swp, dq);\r\n++max;\r\nif (max > DPAA_POLL_MAX)\r\ngoto done;\r\ndq = qbman_swp_dqrr_next(swp);\r\n}\r\ndone:\r\nqbman_swp_interrupt_clear_status(swp, status);\r\nqbman_swp_interrupt_set_inhibit(swp, 0);\r\nreturn IRQ_HANDLED;\r\n}\r\nint dpaa2_io_service_register(struct dpaa2_io *d,\r\nstruct dpaa2_io_notification_ctx *ctx)\r\n{\r\nunsigned long irqflags;\r\nd = service_select_by_cpu(d, ctx->desired_cpu);\r\nif (!d)\r\nreturn -ENODEV;\r\nctx->dpio_id = d->dpio_desc.dpio_id;\r\nctx->qman64 = (u64)ctx;\r\nctx->dpio_private = d;\r\nspin_lock_irqsave(&d->lock_notifications, irqflags);\r\nlist_add(&ctx->node, &d->notifications);\r\nspin_unlock_irqrestore(&d->lock_notifications, irqflags);\r\nif (ctx->is_cdan)\r\nreturn qbman_swp_CDAN_set_context_enable(d->swp,\r\n(u16)ctx->id,\r\nctx->qman64);\r\nreturn 0;\r\n}\r\nvoid dpaa2_io_service_deregister(struct dpaa2_io *service,\r\nstruct dpaa2_io_notification_ctx *ctx)\r\n{\r\nstruct dpaa2_io *d = ctx->dpio_private;\r\nunsigned long irqflags;\r\nif (ctx->is_cdan)\r\nqbman_swp_CDAN_disable(d->swp, (u16)ctx->id);\r\nspin_lock_irqsave(&d->lock_notifications, irqflags);\r\nlist_del(&ctx->node);\r\nspin_unlock_irqrestore(&d->lock_notifications, irqflags);\r\n}\r\nint dpaa2_io_service_rearm(struct dpaa2_io *d,\r\nstruct dpaa2_io_notification_ctx *ctx)\r\n{\r\nunsigned long irqflags;\r\nint err;\r\nd = service_select_by_cpu(d, ctx->desired_cpu);\r\nif (!unlikely(d))\r\nreturn -ENODEV;\r\nspin_lock_irqsave(&d->lock_mgmt_cmd, irqflags);\r\nif (ctx->is_cdan)\r\nerr = qbman_swp_CDAN_enable(d->swp, (u16)ctx->id);\r\nelse\r\nerr = qbman_swp_fq_schedule(d->swp, ctx->id);\r\nspin_unlock_irqrestore(&d->lock_mgmt_cmd, irqflags);\r\nreturn err;\r\n}\r\nint dpaa2_io_service_pull_fq(struct dpaa2_io *d, u32 fqid,\r\nstruct dpaa2_io_store *s)\r\n{\r\nstruct qbman_pull_desc pd;\r\nint err;\r\nqbman_pull_desc_clear(&pd);\r\nqbman_pull_desc_set_storage(&pd, s->vaddr, s->paddr, 1);\r\nqbman_pull_desc_set_numframes(&pd, (u8)s->max);\r\nqbman_pull_desc_set_fq(&pd, fqid);\r\nd = service_select(d);\r\nif (!d)\r\nreturn -ENODEV;\r\ns->swp = d->swp;\r\nerr = qbman_swp_pull(d->swp, &pd);\r\nif (err)\r\ns->swp = NULL;\r\nreturn err;\r\n}\r\nint dpaa2_io_service_pull_channel(struct dpaa2_io *d, u32 channelid,\r\nstruct dpaa2_io_store *s)\r\n{\r\nstruct qbman_pull_desc pd;\r\nint err;\r\nqbman_pull_desc_clear(&pd);\r\nqbman_pull_desc_set_storage(&pd, s->vaddr, s->paddr, 1);\r\nqbman_pull_desc_set_numframes(&pd, (u8)s->max);\r\nqbman_pull_desc_set_channel(&pd, channelid, qbman_pull_type_prio);\r\nd = service_select(d);\r\nif (!d)\r\nreturn -ENODEV;\r\ns->swp = d->swp;\r\nerr = qbman_swp_pull(d->swp, &pd);\r\nif (err)\r\ns->swp = NULL;\r\nreturn err;\r\n}\r\nint dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,\r\nu32 fqid,\r\nconst struct dpaa2_fd *fd)\r\n{\r\nstruct qbman_eq_desc ed;\r\nd = service_select(d);\r\nif (!d)\r\nreturn -ENODEV;\r\nqbman_eq_desc_clear(&ed);\r\nqbman_eq_desc_set_no_orp(&ed, 0);\r\nqbman_eq_desc_set_fq(&ed, fqid);\r\nreturn qbman_swp_enqueue(d->swp, &ed, fd);\r\n}\r\nint dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,\r\nu32 qdid, u8 prio, u16 qdbin,\r\nconst struct dpaa2_fd *fd)\r\n{\r\nstruct qbman_eq_desc ed;\r\nd = service_select(d);\r\nif (!d)\r\nreturn -ENODEV;\r\nqbman_eq_desc_clear(&ed);\r\nqbman_eq_desc_set_no_orp(&ed, 0);\r\nqbman_eq_desc_set_qd(&ed, qdid, qdbin, prio);\r\nreturn qbman_swp_enqueue(d->swp, &ed, fd);\r\n}\r\nint dpaa2_io_service_release(struct dpaa2_io *d,\r\nu32 bpid,\r\nconst u64 *buffers,\r\nunsigned int num_buffers)\r\n{\r\nstruct qbman_release_desc rd;\r\nd = service_select(d);\r\nif (!d)\r\nreturn -ENODEV;\r\nqbman_release_desc_clear(&rd);\r\nqbman_release_desc_set_bpid(&rd, bpid);\r\nreturn qbman_swp_release(d->swp, &rd, buffers, num_buffers);\r\n}\r\nint dpaa2_io_service_acquire(struct dpaa2_io *d,\r\nu32 bpid,\r\nu64 *buffers,\r\nunsigned int num_buffers)\r\n{\r\nunsigned long irqflags;\r\nint err;\r\nd = service_select(d);\r\nif (!d)\r\nreturn -ENODEV;\r\nspin_lock_irqsave(&d->lock_mgmt_cmd, irqflags);\r\nerr = qbman_swp_acquire(d->swp, bpid, buffers, num_buffers);\r\nspin_unlock_irqrestore(&d->lock_mgmt_cmd, irqflags);\r\nreturn err;\r\n}\r\nstruct dpaa2_io_store *dpaa2_io_store_create(unsigned int max_frames,\r\nstruct device *dev)\r\n{\r\nstruct dpaa2_io_store *ret;\r\nsize_t size;\r\nif (!max_frames || (max_frames > 16))\r\nreturn NULL;\r\nret = kmalloc(sizeof(*ret), GFP_KERNEL);\r\nif (!ret)\r\nreturn NULL;\r\nret->max = max_frames;\r\nsize = max_frames * sizeof(struct dpaa2_dq) + 64;\r\nret->alloced_addr = kzalloc(size, GFP_KERNEL);\r\nif (!ret->alloced_addr) {\r\nkfree(ret);\r\nreturn NULL;\r\n}\r\nret->vaddr = PTR_ALIGN(ret->alloced_addr, 64);\r\nret->paddr = dma_map_single(dev, ret->vaddr,\r\nsizeof(struct dpaa2_dq) * max_frames,\r\nDMA_FROM_DEVICE);\r\nif (dma_mapping_error(dev, ret->paddr)) {\r\nkfree(ret->alloced_addr);\r\nkfree(ret);\r\nreturn NULL;\r\n}\r\nret->idx = 0;\r\nret->dev = dev;\r\nreturn ret;\r\n}\r\nvoid dpaa2_io_store_destroy(struct dpaa2_io_store *s)\r\n{\r\ndma_unmap_single(s->dev, s->paddr, sizeof(struct dpaa2_dq) * s->max,\r\nDMA_FROM_DEVICE);\r\nkfree(s->alloced_addr);\r\nkfree(s);\r\n}\r\nstruct dpaa2_dq *dpaa2_io_store_next(struct dpaa2_io_store *s, int *is_last)\r\n{\r\nint match;\r\nstruct dpaa2_dq *ret = &s->vaddr[s->idx];\r\nmatch = qbman_result_has_new_result(s->swp, ret);\r\nif (!match) {\r\n*is_last = 0;\r\nreturn NULL;\r\n}\r\ns->idx++;\r\nif (dpaa2_dq_is_pull_complete(ret)) {\r\n*is_last = 1;\r\ns->idx = 0;\r\nif (!(dpaa2_dq_flags(ret) & DPAA2_DQ_STAT_VALIDFRAME))\r\nret = NULL;\r\n} else {\r\n*is_last = 0;\r\n}\r\nreturn ret;\r\n}
