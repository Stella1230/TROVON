static u32\r\nread_div(struct nv50_clk *clk)\r\n{\r\nstruct nvkm_device *device = clk->base.subdev.device;\r\nswitch (device->chipset) {\r\ncase 0x50:\r\ncase 0x84:\r\ncase 0x86:\r\ncase 0x98:\r\ncase 0xa0:\r\nreturn nvkm_rd32(device, 0x004700);\r\ncase 0x92:\r\ncase 0x94:\r\ncase 0x96:\r\nreturn nvkm_rd32(device, 0x004800);\r\ndefault:\r\nreturn 0x00000000;\r\n}\r\n}\r\nstatic u32\r\nread_pll_src(struct nv50_clk *clk, u32 base)\r\n{\r\nstruct nvkm_subdev *subdev = &clk->base.subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nu32 coef, ref = nvkm_clk_read(&clk->base, nv_clk_src_crystal);\r\nu32 rsel = nvkm_rd32(device, 0x00e18c);\r\nint P, N, M, id;\r\nswitch (device->chipset) {\r\ncase 0x50:\r\ncase 0xa0:\r\nswitch (base) {\r\ncase 0x4020:\r\ncase 0x4028: id = !!(rsel & 0x00000004); break;\r\ncase 0x4008: id = !!(rsel & 0x00000008); break;\r\ncase 0x4030: id = 0; break;\r\ndefault:\r\nnvkm_error(subdev, "ref: bad pll %06x\n", base);\r\nreturn 0;\r\n}\r\ncoef = nvkm_rd32(device, 0x00e81c + (id * 0x0c));\r\nref *= (coef & 0x01000000) ? 2 : 4;\r\nP = (coef & 0x00070000) >> 16;\r\nN = ((coef & 0x0000ff00) >> 8) + 1;\r\nM = ((coef & 0x000000ff) >> 0) + 1;\r\nbreak;\r\ncase 0x84:\r\ncase 0x86:\r\ncase 0x92:\r\ncoef = nvkm_rd32(device, 0x00e81c);\r\nP = (coef & 0x00070000) >> 16;\r\nN = (coef & 0x0000ff00) >> 8;\r\nM = (coef & 0x000000ff) >> 0;\r\nbreak;\r\ncase 0x94:\r\ncase 0x96:\r\ncase 0x98:\r\nrsel = nvkm_rd32(device, 0x00c050);\r\nswitch (base) {\r\ncase 0x4020: rsel = (rsel & 0x00000003) >> 0; break;\r\ncase 0x4008: rsel = (rsel & 0x0000000c) >> 2; break;\r\ncase 0x4028: rsel = (rsel & 0x00001800) >> 11; break;\r\ncase 0x4030: rsel = 3; break;\r\ndefault:\r\nnvkm_error(subdev, "ref: bad pll %06x\n", base);\r\nreturn 0;\r\n}\r\nswitch (rsel) {\r\ncase 0: id = 1; break;\r\ncase 1: return nvkm_clk_read(&clk->base, nv_clk_src_crystal);\r\ncase 2: return nvkm_clk_read(&clk->base, nv_clk_src_href);\r\ncase 3: id = 0; break;\r\n}\r\ncoef = nvkm_rd32(device, 0x00e81c + (id * 0x28));\r\nP = (nvkm_rd32(device, 0x00e824 + (id * 0x28)) >> 16) & 7;\r\nP += (coef & 0x00070000) >> 16;\r\nN = (coef & 0x0000ff00) >> 8;\r\nM = (coef & 0x000000ff) >> 0;\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nif (M)\r\nreturn (ref * N / M) >> P;\r\nreturn 0;\r\n}\r\nstatic u32\r\nread_pll_ref(struct nv50_clk *clk, u32 base)\r\n{\r\nstruct nvkm_subdev *subdev = &clk->base.subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nu32 src, mast = nvkm_rd32(device, 0x00c040);\r\nswitch (base) {\r\ncase 0x004028:\r\nsrc = !!(mast & 0x00200000);\r\nbreak;\r\ncase 0x004020:\r\nsrc = !!(mast & 0x00400000);\r\nbreak;\r\ncase 0x004008:\r\nsrc = !!(mast & 0x00010000);\r\nbreak;\r\ncase 0x004030:\r\nsrc = !!(mast & 0x02000000);\r\nbreak;\r\ncase 0x00e810:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_crystal);\r\ndefault:\r\nnvkm_error(subdev, "bad pll %06x\n", base);\r\nreturn 0;\r\n}\r\nif (src)\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_href);\r\nreturn read_pll_src(clk, base);\r\n}\r\nstatic u32\r\nread_pll(struct nv50_clk *clk, u32 base)\r\n{\r\nstruct nvkm_device *device = clk->base.subdev.device;\r\nu32 mast = nvkm_rd32(device, 0x00c040);\r\nu32 ctrl = nvkm_rd32(device, base + 0);\r\nu32 coef = nvkm_rd32(device, base + 4);\r\nu32 ref = read_pll_ref(clk, base);\r\nu32 freq = 0;\r\nint N1, N2, M1, M2;\r\nif (base == 0x004028 && (mast & 0x00100000)) {\r\nif (device->chipset != 0xa0)\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_dom6);\r\n}\r\nN2 = (coef & 0xff000000) >> 24;\r\nM2 = (coef & 0x00ff0000) >> 16;\r\nN1 = (coef & 0x0000ff00) >> 8;\r\nM1 = (coef & 0x000000ff);\r\nif ((ctrl & 0x80000000) && M1) {\r\nfreq = ref * N1 / M1;\r\nif ((ctrl & 0x40000100) == 0x40000000) {\r\nif (M2)\r\nfreq = freq * N2 / M2;\r\nelse\r\nfreq = 0;\r\n}\r\n}\r\nreturn freq;\r\n}\r\nint\r\nnv50_clk_read(struct nvkm_clk *base, enum nv_clk_src src)\r\n{\r\nstruct nv50_clk *clk = nv50_clk(base);\r\nstruct nvkm_subdev *subdev = &clk->base.subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nu32 mast = nvkm_rd32(device, 0x00c040);\r\nu32 P = 0;\r\nswitch (src) {\r\ncase nv_clk_src_crystal:\r\nreturn device->crystal;\r\ncase nv_clk_src_href:\r\nreturn 100000;\r\ncase nv_clk_src_hclk:\r\nreturn div_u64((u64)nvkm_clk_read(&clk->base, nv_clk_src_href) * 27778, 10000);\r\ncase nv_clk_src_hclkm3:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_hclk) * 3;\r\ncase nv_clk_src_hclkm3d2:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_hclk) * 3 / 2;\r\ncase nv_clk_src_host:\r\nswitch (mast & 0x30000000) {\r\ncase 0x00000000: return nvkm_clk_read(&clk->base, nv_clk_src_href);\r\ncase 0x10000000: break;\r\ncase 0x20000000:\r\ncase 0x30000000: return nvkm_clk_read(&clk->base, nv_clk_src_hclk);\r\n}\r\nbreak;\r\ncase nv_clk_src_core:\r\nif (!(mast & 0x00100000))\r\nP = (nvkm_rd32(device, 0x004028) & 0x00070000) >> 16;\r\nswitch (mast & 0x00000003) {\r\ncase 0x00000000: return nvkm_clk_read(&clk->base, nv_clk_src_crystal) >> P;\r\ncase 0x00000001: return nvkm_clk_read(&clk->base, nv_clk_src_dom6);\r\ncase 0x00000002: return read_pll(clk, 0x004020) >> P;\r\ncase 0x00000003: return read_pll(clk, 0x004028) >> P;\r\n}\r\nbreak;\r\ncase nv_clk_src_shader:\r\nP = (nvkm_rd32(device, 0x004020) & 0x00070000) >> 16;\r\nswitch (mast & 0x00000030) {\r\ncase 0x00000000:\r\nif (mast & 0x00000080)\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_host) >> P;\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_crystal) >> P;\r\ncase 0x00000010: break;\r\ncase 0x00000020: return read_pll(clk, 0x004028) >> P;\r\ncase 0x00000030: return read_pll(clk, 0x004020) >> P;\r\n}\r\nbreak;\r\ncase nv_clk_src_mem:\r\nP = (nvkm_rd32(device, 0x004008) & 0x00070000) >> 16;\r\nif (nvkm_rd32(device, 0x004008) & 0x00000200) {\r\nswitch (mast & 0x0000c000) {\r\ncase 0x00000000:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_crystal) >> P;\r\ncase 0x00008000:\r\ncase 0x0000c000:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_href) >> P;\r\n}\r\n} else {\r\nreturn read_pll(clk, 0x004008) >> P;\r\n}\r\nbreak;\r\ncase nv_clk_src_vdec:\r\nP = (read_div(clk) & 0x00000700) >> 8;\r\nswitch (device->chipset) {\r\ncase 0x84:\r\ncase 0x86:\r\ncase 0x92:\r\ncase 0x94:\r\ncase 0x96:\r\ncase 0xa0:\r\nswitch (mast & 0x00000c00) {\r\ncase 0x00000000:\r\nif (device->chipset == 0xa0)\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_core) >> P;\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_crystal) >> P;\r\ncase 0x00000400:\r\nreturn 0;\r\ncase 0x00000800:\r\nif (mast & 0x01000000)\r\nreturn read_pll(clk, 0x004028) >> P;\r\nreturn read_pll(clk, 0x004030) >> P;\r\ncase 0x00000c00:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_core) >> P;\r\n}\r\nbreak;\r\ncase 0x98:\r\nswitch (mast & 0x00000c00) {\r\ncase 0x00000000:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_core) >> P;\r\ncase 0x00000400:\r\nreturn 0;\r\ncase 0x00000800:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_hclkm3d2) >> P;\r\ncase 0x00000c00:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_mem) >> P;\r\n}\r\nbreak;\r\n}\r\nbreak;\r\ncase nv_clk_src_dom6:\r\nswitch (device->chipset) {\r\ncase 0x50:\r\ncase 0xa0:\r\nreturn read_pll(clk, 0x00e810) >> 2;\r\ncase 0x84:\r\ncase 0x86:\r\ncase 0x92:\r\ncase 0x94:\r\ncase 0x96:\r\ncase 0x98:\r\nP = (read_div(clk) & 0x00000007) >> 0;\r\nswitch (mast & 0x0c000000) {\r\ncase 0x00000000: return nvkm_clk_read(&clk->base, nv_clk_src_href);\r\ncase 0x04000000: break;\r\ncase 0x08000000: return nvkm_clk_read(&clk->base, nv_clk_src_hclk);\r\ncase 0x0c000000:\r\nreturn nvkm_clk_read(&clk->base, nv_clk_src_hclkm3) >> P;\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\ndefault:\r\nbreak;\r\n}\r\nnvkm_debug(subdev, "unknown clock source %d %08x\n", src, mast);\r\nreturn -EINVAL;\r\n}\r\nstatic u32\r\ncalc_pll(struct nv50_clk *clk, u32 reg, u32 idx, int *N, int *M, int *P)\r\n{\r\nstruct nvkm_subdev *subdev = &clk->base.subdev;\r\nstruct nvbios_pll pll;\r\nint ret;\r\nret = nvbios_pll_parse(subdev->device->bios, reg, &pll);\r\nif (ret)\r\nreturn 0;\r\npll.vco2.max_freq = 0;\r\npll.refclk = read_pll_ref(clk, reg);\r\nif (!pll.refclk)\r\nreturn 0;\r\nreturn nv04_pll_calc(subdev, &pll, idx, N, M, NULL, NULL, P);\r\n}\r\nstatic inline u32\r\ncalc_div(u32 src, u32 target, int *div)\r\n{\r\nu32 clk0 = src, clk1 = src;\r\nfor (*div = 0; *div <= 7; (*div)++) {\r\nif (clk0 <= target) {\r\nclk1 = clk0 << (*div ? 1 : 0);\r\nbreak;\r\n}\r\nclk0 >>= 1;\r\n}\r\nif (target - clk0 <= clk1 - target)\r\nreturn clk0;\r\n(*div)--;\r\nreturn clk1;\r\n}\r\nstatic inline u32\r\nclk_same(u32 a, u32 b)\r\n{\r\nreturn ((a / 1000) == (b / 1000));\r\n}\r\nint\r\nnv50_clk_calc(struct nvkm_clk *base, struct nvkm_cstate *cstate)\r\n{\r\nstruct nv50_clk *clk = nv50_clk(base);\r\nstruct nv50_clk_hwsq *hwsq = &clk->hwsq;\r\nstruct nvkm_subdev *subdev = &clk->base.subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nconst int shader = cstate->domain[nv_clk_src_shader];\r\nconst int core = cstate->domain[nv_clk_src_core];\r\nconst int vdec = cstate->domain[nv_clk_src_vdec];\r\nconst int dom6 = cstate->domain[nv_clk_src_dom6];\r\nu32 mastm = 0, mastv = 0;\r\nu32 divsm = 0, divsv = 0;\r\nint N, M, P1, P2;\r\nint freq, out;\r\nout = clk_init(hwsq, subdev);\r\nif (out)\r\nreturn out;\r\nclk_wr32(hwsq, fifo, 0x00000001);\r\nclk_nsec(hwsq, 8000);\r\nclk_setf(hwsq, 0x10, 0x00);\r\nclk_wait(hwsq, 0x00, 0x01);\r\nif (vdec) {\r\nfreq = calc_div(core, vdec, &P1);\r\nif (device->chipset != 0x98)\r\nout = read_pll(clk, 0x004030);\r\nelse\r\nout = nvkm_clk_read(&clk->base, nv_clk_src_hclkm3d2);\r\nout = calc_div(out, vdec, &P2);\r\nif (abs(vdec - freq) <= abs(vdec - out)) {\r\nif (device->chipset != 0x98)\r\nmastv |= 0x00000c00;\r\ndivsv |= P1 << 8;\r\n} else {\r\nmastv |= 0x00000800;\r\ndivsv |= P2 << 8;\r\n}\r\nmastm |= 0x00000c00;\r\ndivsm |= 0x00000700;\r\n}\r\nif (dom6) {\r\nif (clk_same(dom6, nvkm_clk_read(&clk->base, nv_clk_src_href))) {\r\nmastv |= 0x00000000;\r\n} else\r\nif (clk_same(dom6, nvkm_clk_read(&clk->base, nv_clk_src_hclk))) {\r\nmastv |= 0x08000000;\r\n} else {\r\nfreq = nvkm_clk_read(&clk->base, nv_clk_src_hclk) * 3;\r\ncalc_div(freq, dom6, &P1);\r\nmastv |= 0x0c000000;\r\ndivsv |= P1;\r\n}\r\nmastm |= 0x0c000000;\r\ndivsm |= 0x00000007;\r\n}\r\nclk_mask(hwsq, mast, mastm, 0x00000000);\r\nclk_mask(hwsq, divs, divsm, divsv);\r\nclk_mask(hwsq, mast, mastm, mastv);\r\nif (device->chipset < 0x92)\r\nclk_mask(hwsq, mast, 0x001000b0, 0x00100080);\r\nelse\r\nclk_mask(hwsq, mast, 0x000000b3, 0x00000081);\r\nfreq = calc_pll(clk, 0x4028, core, &N, &M, &P1);\r\nif (freq == 0)\r\nreturn -ERANGE;\r\nclk_mask(hwsq, nvpll[0], 0xc03f0100,\r\n0x80000000 | (P1 << 19) | (P1 << 16));\r\nclk_mask(hwsq, nvpll[1], 0x0000ffff, (N << 8) | M);\r\nif (P1-- && shader == (core << 1)) {\r\nclk_mask(hwsq, spll[0], 0xc03f0100, (P1 << 19) | (P1 << 16));\r\nclk_mask(hwsq, mast, 0x00100033, 0x00000023);\r\n} else {\r\nfreq = calc_pll(clk, 0x4020, shader, &N, &M, &P1);\r\nif (freq == 0)\r\nreturn -ERANGE;\r\nclk_mask(hwsq, spll[0], 0xc03f0100,\r\n0x80000000 | (P1 << 19) | (P1 << 16));\r\nclk_mask(hwsq, spll[1], 0x0000ffff, (N << 8) | M);\r\nclk_mask(hwsq, mast, 0x00100033, 0x00000033);\r\n}\r\nclk_setf(hwsq, 0x10, 0x01);\r\nclk_wait(hwsq, 0x00, 0x00);\r\nclk_wr32(hwsq, fifo, 0x00000000);\r\nreturn 0;\r\n}\r\nint\r\nnv50_clk_prog(struct nvkm_clk *base)\r\n{\r\nstruct nv50_clk *clk = nv50_clk(base);\r\nreturn clk_exec(&clk->hwsq, true);\r\n}\r\nvoid\r\nnv50_clk_tidy(struct nvkm_clk *base)\r\n{\r\nstruct nv50_clk *clk = nv50_clk(base);\r\nclk_exec(&clk->hwsq, false);\r\n}\r\nint\r\nnv50_clk_new_(const struct nvkm_clk_func *func, struct nvkm_device *device,\r\nint index, bool allow_reclock, struct nvkm_clk **pclk)\r\n{\r\nstruct nv50_clk *clk;\r\nint ret;\r\nif (!(clk = kzalloc(sizeof(*clk), GFP_KERNEL)))\r\nreturn -ENOMEM;\r\nret = nvkm_clk_ctor(func, device, index, allow_reclock, &clk->base);\r\n*pclk = &clk->base;\r\nif (ret)\r\nreturn ret;\r\nclk->hwsq.r_fifo = hwsq_reg(0x002504);\r\nclk->hwsq.r_spll[0] = hwsq_reg(0x004020);\r\nclk->hwsq.r_spll[1] = hwsq_reg(0x004024);\r\nclk->hwsq.r_nvpll[0] = hwsq_reg(0x004028);\r\nclk->hwsq.r_nvpll[1] = hwsq_reg(0x00402c);\r\nswitch (device->chipset) {\r\ncase 0x92:\r\ncase 0x94:\r\ncase 0x96:\r\nclk->hwsq.r_divs = hwsq_reg(0x004800);\r\nbreak;\r\ndefault:\r\nclk->hwsq.r_divs = hwsq_reg(0x004700);\r\nbreak;\r\n}\r\nclk->hwsq.r_mast = hwsq_reg(0x00c040);\r\nreturn 0;\r\n}\r\nint\r\nnv50_clk_new(struct nvkm_device *device, int index, struct nvkm_clk **pclk)\r\n{\r\nreturn nv50_clk_new_(&nv50_clk, device, index, false, pclk);\r\n}
