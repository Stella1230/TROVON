static void print_ksym(__u64 addr)\r\n{\r\nstruct ksym *sym;\r\nif (!addr)\r\nreturn;\r\nsym = ksym_search(addr);\r\nprintf("%s;", sym->name);\r\nif (!strcmp(sym->name, "sys_read"))\r\nsys_read_seen = true;\r\nelse if (!strcmp(sym->name, "sys_write"))\r\nsys_write_seen = true;\r\n}\r\nstatic void print_addr(__u64 addr)\r\n{\r\nif (!addr)\r\nreturn;\r\nprintf("%llx;", addr);\r\n}\r\nstatic void print_stack(struct key_t *key, __u64 count)\r\n{\r\n__u64 ip[PERF_MAX_STACK_DEPTH] = {};\r\nstatic bool warned;\r\nint i;\r\nprintf("%3lld %s;", count, key->comm);\r\nif (bpf_map_lookup_elem(map_fd[1], &key->kernstack, ip) != 0) {\r\nprintf("---;");\r\n} else {\r\nfor (i = PERF_MAX_STACK_DEPTH - 1; i >= 0; i--)\r\nprint_ksym(ip[i]);\r\n}\r\nprintf("-;");\r\nif (bpf_map_lookup_elem(map_fd[1], &key->userstack, ip) != 0) {\r\nprintf("---;");\r\n} else {\r\nfor (i = PERF_MAX_STACK_DEPTH - 1; i >= 0; i--)\r\nprint_addr(ip[i]);\r\n}\r\nif (count < 6)\r\nprintf("\r");\r\nelse\r\nprintf("\n");\r\nif (key->kernstack == -EEXIST && !warned) {\r\nprintf("stackmap collisions seen. Consider increasing size\n");\r\nwarned = true;\r\n} else if ((int)key->kernstack < 0 && (int)key->userstack < 0) {\r\nprintf("err stackid %d %d\n", key->kernstack, key->userstack);\r\n}\r\n}\r\nstatic void int_exit(int sig)\r\n{\r\nkill(0, SIGKILL);\r\nexit(0);\r\n}\r\nstatic void print_stacks(void)\r\n{\r\nstruct key_t key = {}, next_key;\r\n__u64 value;\r\n__u32 stackid = 0, next_id;\r\nint fd = map_fd[0], stack_map = map_fd[1];\r\nsys_read_seen = sys_write_seen = false;\r\nwhile (bpf_map_get_next_key(fd, &key, &next_key) == 0) {\r\nbpf_map_lookup_elem(fd, &next_key, &value);\r\nprint_stack(&next_key, value);\r\nbpf_map_delete_elem(fd, &next_key);\r\nkey = next_key;\r\n}\r\nprintf("\n");\r\nif (!sys_read_seen || !sys_write_seen) {\r\nprintf("BUG kernel stack doesn't contain sys_read() and sys_write()\n");\r\nint_exit(0);\r\n}\r\nwhile (bpf_map_get_next_key(stack_map, &stackid, &next_id) == 0) {\r\nbpf_map_delete_elem(stack_map, &next_id);\r\nstackid = next_id;\r\n}\r\n}\r\nstatic void test_perf_event_all_cpu(struct perf_event_attr *attr)\r\n{\r\nint nr_cpus = sysconf(_SC_NPROCESSORS_CONF);\r\nint *pmu_fd = malloc(nr_cpus * sizeof(int));\r\nint i, error = 0;\r\nfor (i = 0; i < nr_cpus; i++) {\r\npmu_fd[i] = sys_perf_event_open(attr, -1, i, -1, 0);\r\nif (pmu_fd[i] < 0) {\r\nprintf("sys_perf_event_open failed\n");\r\nerror = 1;\r\ngoto all_cpu_err;\r\n}\r\nassert(ioctl(pmu_fd[i], PERF_EVENT_IOC_SET_BPF, prog_fd[0]) == 0);\r\nassert(ioctl(pmu_fd[i], PERF_EVENT_IOC_ENABLE) == 0);\r\n}\r\nsystem("dd if=/dev/zero of=/dev/null count=5000k status=none");\r\nprint_stacks();\r\nall_cpu_err:\r\nfor (i--; i >= 0; i--) {\r\nioctl(pmu_fd[i], PERF_EVENT_IOC_DISABLE);\r\nclose(pmu_fd[i]);\r\n}\r\nfree(pmu_fd);\r\nif (error)\r\nint_exit(0);\r\n}\r\nstatic void test_perf_event_task(struct perf_event_attr *attr)\r\n{\r\nint pmu_fd;\r\npmu_fd = sys_perf_event_open(attr, 0, -1, -1, 0);\r\nif (pmu_fd < 0) {\r\nprintf("sys_perf_event_open failed\n");\r\nint_exit(0);\r\n}\r\nassert(ioctl(pmu_fd, PERF_EVENT_IOC_SET_BPF, prog_fd[0]) == 0);\r\nassert(ioctl(pmu_fd, PERF_EVENT_IOC_ENABLE) == 0);\r\nsystem("dd if=/dev/zero of=/dev/null count=5000k status=none");\r\nprint_stacks();\r\nioctl(pmu_fd, PERF_EVENT_IOC_DISABLE);\r\nclose(pmu_fd);\r\n}\r\nstatic void test_bpf_perf_event(void)\r\n{\r\nstruct perf_event_attr attr_type_hw = {\r\n.sample_freq = SAMPLE_FREQ,\r\n.freq = 1,\r\n.type = PERF_TYPE_HARDWARE,\r\n.config = PERF_COUNT_HW_CPU_CYCLES,\r\n.inherit = 1,\r\n};\r\nstruct perf_event_attr attr_type_sw = {\r\n.sample_freq = SAMPLE_FREQ,\r\n.freq = 1,\r\n.type = PERF_TYPE_SOFTWARE,\r\n.config = PERF_COUNT_SW_CPU_CLOCK,\r\n.inherit = 1,\r\n};\r\nstruct perf_event_attr attr_hw_cache_l1d = {\r\n.sample_freq = SAMPLE_FREQ,\r\n.freq = 1,\r\n.type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_L1D |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_ACCESS << 16),\r\n.inherit = 1,\r\n};\r\nstruct perf_event_attr attr_hw_cache_branch_miss = {\r\n.sample_freq = SAMPLE_FREQ,\r\n.freq = 1,\r\n.type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_BPU |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_MISS << 16),\r\n.inherit = 1,\r\n};\r\nstruct perf_event_attr attr_type_raw = {\r\n.sample_freq = SAMPLE_FREQ,\r\n.freq = 1,\r\n.type = PERF_TYPE_RAW,\r\n.config = 0xc0,\r\n.inherit = 1,\r\n};\r\nprintf("Test HW_CPU_CYCLES\n");\r\ntest_perf_event_all_cpu(&attr_type_hw);\r\ntest_perf_event_task(&attr_type_hw);\r\nprintf("Test SW_CPU_CLOCK\n");\r\ntest_perf_event_all_cpu(&attr_type_sw);\r\ntest_perf_event_task(&attr_type_sw);\r\nprintf("Test HW_CACHE_L1D\n");\r\ntest_perf_event_all_cpu(&attr_hw_cache_l1d);\r\ntest_perf_event_task(&attr_hw_cache_l1d);\r\nprintf("Test HW_CACHE_BPU\n");\r\ntest_perf_event_all_cpu(&attr_hw_cache_branch_miss);\r\ntest_perf_event_task(&attr_hw_cache_branch_miss);\r\nprintf("Test Instruction Retired\n");\r\ntest_perf_event_all_cpu(&attr_type_raw);\r\ntest_perf_event_task(&attr_type_raw);\r\nprintf("*** PASS ***\n");\r\n}\r\nint main(int argc, char **argv)\r\n{\r\nstruct rlimit r = {RLIM_INFINITY, RLIM_INFINITY};\r\nchar filename[256];\r\nsnprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);\r\nsetrlimit(RLIMIT_MEMLOCK, &r);\r\nsignal(SIGINT, int_exit);\r\nsignal(SIGTERM, int_exit);\r\nif (load_kallsyms()) {\r\nprintf("failed to process /proc/kallsyms\n");\r\nreturn 1;\r\n}\r\nif (load_bpf_file(filename)) {\r\nprintf("%s", bpf_log_buf);\r\nreturn 2;\r\n}\r\nif (fork() == 0) {\r\nread_trace_pipe();\r\nreturn 0;\r\n}\r\ntest_bpf_perf_event();\r\nint_exit(0);\r\nreturn 0;\r\n}
