int vgic_check_ioaddr(struct kvm *kvm, phys_addr_t *ioaddr,\r\nphys_addr_t addr, phys_addr_t alignment)\r\n{\r\nif (addr & ~KVM_PHYS_MASK)\r\nreturn -E2BIG;\r\nif (!IS_ALIGNED(addr, alignment))\r\nreturn -EINVAL;\r\nif (!IS_VGIC_ADDR_UNDEF(*ioaddr))\r\nreturn -EEXIST;\r\nreturn 0;\r\n}\r\nstatic int vgic_check_type(struct kvm *kvm, int type_needed)\r\n{\r\nif (kvm->arch.vgic.vgic_model != type_needed)\r\nreturn -ENODEV;\r\nelse\r\nreturn 0;\r\n}\r\nint kvm_vgic_addr(struct kvm *kvm, unsigned long type, u64 *addr, bool write)\r\n{\r\nint r = 0;\r\nstruct vgic_dist *vgic = &kvm->arch.vgic;\r\nphys_addr_t *addr_ptr, alignment;\r\nmutex_lock(&kvm->lock);\r\nswitch (type) {\r\ncase KVM_VGIC_V2_ADDR_TYPE_DIST:\r\nr = vgic_check_type(kvm, KVM_DEV_TYPE_ARM_VGIC_V2);\r\naddr_ptr = &vgic->vgic_dist_base;\r\nalignment = SZ_4K;\r\nbreak;\r\ncase KVM_VGIC_V2_ADDR_TYPE_CPU:\r\nr = vgic_check_type(kvm, KVM_DEV_TYPE_ARM_VGIC_V2);\r\naddr_ptr = &vgic->vgic_cpu_base;\r\nalignment = SZ_4K;\r\nbreak;\r\ncase KVM_VGIC_V3_ADDR_TYPE_DIST:\r\nr = vgic_check_type(kvm, KVM_DEV_TYPE_ARM_VGIC_V3);\r\naddr_ptr = &vgic->vgic_dist_base;\r\nalignment = SZ_64K;\r\nbreak;\r\ncase KVM_VGIC_V3_ADDR_TYPE_REDIST:\r\nr = vgic_check_type(kvm, KVM_DEV_TYPE_ARM_VGIC_V3);\r\nif (r)\r\nbreak;\r\nif (write) {\r\nr = vgic_v3_set_redist_base(kvm, *addr);\r\ngoto out;\r\n}\r\naddr_ptr = &vgic->vgic_redist_base;\r\nbreak;\r\ndefault:\r\nr = -ENODEV;\r\n}\r\nif (r)\r\ngoto out;\r\nif (write) {\r\nr = vgic_check_ioaddr(kvm, addr_ptr, *addr, alignment);\r\nif (!r)\r\n*addr_ptr = *addr;\r\n} else {\r\n*addr = *addr_ptr;\r\n}\r\nout:\r\nmutex_unlock(&kvm->lock);\r\nreturn r;\r\n}\r\nstatic int vgic_set_common_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nint r;\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_ADDR: {\r\nu64 __user *uaddr = (u64 __user *)(long)attr->addr;\r\nu64 addr;\r\nunsigned long type = (unsigned long)attr->attr;\r\nif (copy_from_user(&addr, uaddr, sizeof(addr)))\r\nreturn -EFAULT;\r\nr = kvm_vgic_addr(dev->kvm, type, &addr, true);\r\nreturn (r == -ENODEV) ? -ENXIO : r;\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_NR_IRQS: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nu32 val;\r\nint ret = 0;\r\nif (get_user(val, uaddr))\r\nreturn -EFAULT;\r\nif (val < (VGIC_NR_PRIVATE_IRQS + 32) ||\r\nval > VGIC_MAX_RESERVED ||\r\n(val & 31))\r\nreturn -EINVAL;\r\nmutex_lock(&dev->kvm->lock);\r\nif (vgic_ready(dev->kvm) || dev->kvm->arch.vgic.nr_spis)\r\nret = -EBUSY;\r\nelse\r\ndev->kvm->arch.vgic.nr_spis =\r\nval - VGIC_NR_PRIVATE_IRQS;\r\nmutex_unlock(&dev->kvm->lock);\r\nreturn ret;\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_CTRL: {\r\nswitch (attr->attr) {\r\ncase KVM_DEV_ARM_VGIC_CTRL_INIT:\r\nmutex_lock(&dev->kvm->lock);\r\nr = vgic_init(dev->kvm);\r\nmutex_unlock(&dev->kvm->lock);\r\nreturn r;\r\n}\r\nbreak;\r\n}\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int vgic_get_common_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nint r = -ENXIO;\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_ADDR: {\r\nu64 __user *uaddr = (u64 __user *)(long)attr->addr;\r\nu64 addr;\r\nunsigned long type = (unsigned long)attr->attr;\r\nr = kvm_vgic_addr(dev->kvm, type, &addr, false);\r\nif (r)\r\nreturn (r == -ENODEV) ? -ENXIO : r;\r\nif (copy_to_user(uaddr, &addr, sizeof(addr)))\r\nreturn -EFAULT;\r\nbreak;\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_NR_IRQS: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nr = put_user(dev->kvm->arch.vgic.nr_spis +\r\nVGIC_NR_PRIVATE_IRQS, uaddr);\r\nbreak;\r\n}\r\n}\r\nreturn r;\r\n}\r\nstatic int vgic_create(struct kvm_device *dev, u32 type)\r\n{\r\nreturn kvm_vgic_create(dev->kvm, type);\r\n}\r\nstatic void vgic_destroy(struct kvm_device *dev)\r\n{\r\nkfree(dev);\r\n}\r\nint kvm_register_vgic_device(unsigned long type)\r\n{\r\nint ret = -ENODEV;\r\nswitch (type) {\r\ncase KVM_DEV_TYPE_ARM_VGIC_V2:\r\nret = kvm_register_device_ops(&kvm_arm_vgic_v2_ops,\r\nKVM_DEV_TYPE_ARM_VGIC_V2);\r\nbreak;\r\ncase KVM_DEV_TYPE_ARM_VGIC_V3:\r\nret = kvm_register_device_ops(&kvm_arm_vgic_v3_ops,\r\nKVM_DEV_TYPE_ARM_VGIC_V3);\r\nif (ret)\r\nbreak;\r\nret = kvm_vgic_register_its_device();\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nint vgic_v2_parse_attr(struct kvm_device *dev, struct kvm_device_attr *attr,\r\nstruct vgic_reg_attr *reg_attr)\r\n{\r\nint cpuid;\r\ncpuid = (attr->attr & KVM_DEV_ARM_VGIC_CPUID_MASK) >>\r\nKVM_DEV_ARM_VGIC_CPUID_SHIFT;\r\nif (cpuid >= atomic_read(&dev->kvm->online_vcpus))\r\nreturn -EINVAL;\r\nreg_attr->vcpu = kvm_get_vcpu(dev->kvm, cpuid);\r\nreg_attr->addr = attr->attr & KVM_DEV_ARM_VGIC_OFFSET_MASK;\r\nreturn 0;\r\n}\r\nstatic void unlock_vcpus(struct kvm *kvm, int vcpu_lock_idx)\r\n{\r\nstruct kvm_vcpu *tmp_vcpu;\r\nfor (; vcpu_lock_idx >= 0; vcpu_lock_idx--) {\r\ntmp_vcpu = kvm_get_vcpu(kvm, vcpu_lock_idx);\r\nmutex_unlock(&tmp_vcpu->mutex);\r\n}\r\n}\r\nvoid unlock_all_vcpus(struct kvm *kvm)\r\n{\r\nunlock_vcpus(kvm, atomic_read(&kvm->online_vcpus) - 1);\r\n}\r\nbool lock_all_vcpus(struct kvm *kvm)\r\n{\r\nstruct kvm_vcpu *tmp_vcpu;\r\nint c;\r\nkvm_for_each_vcpu(c, tmp_vcpu, kvm) {\r\nif (!mutex_trylock(&tmp_vcpu->mutex)) {\r\nunlock_vcpus(kvm, c - 1);\r\nreturn false;\r\n}\r\n}\r\nreturn true;\r\n}\r\nstatic int vgic_v2_attr_regs_access(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr,\r\nu32 *reg, bool is_write)\r\n{\r\nstruct vgic_reg_attr reg_attr;\r\ngpa_t addr;\r\nstruct kvm_vcpu *vcpu;\r\nint ret;\r\nret = vgic_v2_parse_attr(dev, attr, &reg_attr);\r\nif (ret)\r\nreturn ret;\r\nvcpu = reg_attr.vcpu;\r\naddr = reg_attr.addr;\r\nmutex_lock(&dev->kvm->lock);\r\nret = vgic_init(dev->kvm);\r\nif (ret)\r\ngoto out;\r\nif (!lock_all_vcpus(dev->kvm)) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_REGS:\r\nret = vgic_v2_cpuif_uaccess(vcpu, is_write, addr, reg);\r\nbreak;\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\nret = vgic_v2_dist_uaccess(vcpu, is_write, addr, reg);\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\nbreak;\r\n}\r\nunlock_all_vcpus(dev->kvm);\r\nout:\r\nmutex_unlock(&dev->kvm->lock);\r\nreturn ret;\r\n}\r\nstatic int vgic_v2_set_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nint ret;\r\nret = vgic_set_common_attr(dev, attr);\r\nif (ret != -ENXIO)\r\nreturn ret;\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_REGS: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nu32 reg;\r\nif (get_user(reg, uaddr))\r\nreturn -EFAULT;\r\nreturn vgic_v2_attr_regs_access(dev, attr, &reg, true);\r\n}\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int vgic_v2_get_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nint ret;\r\nret = vgic_get_common_attr(dev, attr);\r\nif (ret != -ENXIO)\r\nreturn ret;\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_REGS: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nu32 reg = 0;\r\nret = vgic_v2_attr_regs_access(dev, attr, &reg, false);\r\nif (ret)\r\nreturn ret;\r\nreturn put_user(reg, uaddr);\r\n}\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int vgic_v2_has_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_ADDR:\r\nswitch (attr->attr) {\r\ncase KVM_VGIC_V2_ADDR_TYPE_DIST:\r\ncase KVM_VGIC_V2_ADDR_TYPE_CPU:\r\nreturn 0;\r\n}\r\nbreak;\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_REGS:\r\nreturn vgic_v2_has_attr_regs(dev, attr);\r\ncase KVM_DEV_ARM_VGIC_GRP_NR_IRQS:\r\nreturn 0;\r\ncase KVM_DEV_ARM_VGIC_GRP_CTRL:\r\nswitch (attr->attr) {\r\ncase KVM_DEV_ARM_VGIC_CTRL_INIT:\r\nreturn 0;\r\n}\r\n}\r\nreturn -ENXIO;\r\n}\r\nint vgic_v3_parse_attr(struct kvm_device *dev, struct kvm_device_attr *attr,\r\nstruct vgic_reg_attr *reg_attr)\r\n{\r\nunsigned long vgic_mpidr, mpidr_reg;\r\nif (attr->group != KVM_DEV_ARM_VGIC_GRP_DIST_REGS) {\r\nvgic_mpidr = (attr->attr & KVM_DEV_ARM_VGIC_V3_MPIDR_MASK) >>\r\nKVM_DEV_ARM_VGIC_V3_MPIDR_SHIFT;\r\nmpidr_reg = VGIC_TO_MPIDR(vgic_mpidr);\r\nreg_attr->vcpu = kvm_mpidr_to_vcpu(dev->kvm, mpidr_reg);\r\n} else {\r\nreg_attr->vcpu = kvm_get_vcpu(dev->kvm, 0);\r\n}\r\nif (!reg_attr->vcpu)\r\nreturn -EINVAL;\r\nreg_attr->addr = attr->attr & KVM_DEV_ARM_VGIC_OFFSET_MASK;\r\nreturn 0;\r\n}\r\nstatic int vgic_v3_attr_regs_access(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr,\r\nu64 *reg, bool is_write)\r\n{\r\nstruct vgic_reg_attr reg_attr;\r\ngpa_t addr;\r\nstruct kvm_vcpu *vcpu;\r\nint ret;\r\nu32 tmp32;\r\nret = vgic_v3_parse_attr(dev, attr, &reg_attr);\r\nif (ret)\r\nreturn ret;\r\nvcpu = reg_attr.vcpu;\r\naddr = reg_attr.addr;\r\nmutex_lock(&dev->kvm->lock);\r\nif (unlikely(!vgic_initialized(dev->kvm))) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nif (!lock_all_vcpus(dev->kvm)) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\nif (is_write)\r\ntmp32 = *reg;\r\nret = vgic_v3_dist_uaccess(vcpu, is_write, addr, &tmp32);\r\nif (!is_write)\r\n*reg = tmp32;\r\nbreak;\r\ncase KVM_DEV_ARM_VGIC_GRP_REDIST_REGS:\r\nif (is_write)\r\ntmp32 = *reg;\r\nret = vgic_v3_redist_uaccess(vcpu, is_write, addr, &tmp32);\r\nif (!is_write)\r\n*reg = tmp32;\r\nbreak;\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_SYSREGS: {\r\nu64 regid;\r\nregid = (attr->attr & KVM_DEV_ARM_VGIC_SYSREG_INSTR_MASK);\r\nret = vgic_v3_cpu_sysregs_uaccess(vcpu, is_write,\r\nregid, reg);\r\nbreak;\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_LEVEL_INFO: {\r\nunsigned int info, intid;\r\ninfo = (attr->attr & KVM_DEV_ARM_VGIC_LINE_LEVEL_INFO_MASK) >>\r\nKVM_DEV_ARM_VGIC_LINE_LEVEL_INFO_SHIFT;\r\nif (info == VGIC_LEVEL_INFO_LINE_LEVEL) {\r\nintid = attr->attr &\r\nKVM_DEV_ARM_VGIC_LINE_LEVEL_INTID_MASK;\r\nret = vgic_v3_line_level_info_uaccess(vcpu, is_write,\r\nintid, reg);\r\n} else {\r\nret = -EINVAL;\r\n}\r\nbreak;\r\n}\r\ndefault:\r\nret = -EINVAL;\r\nbreak;\r\n}\r\nunlock_all_vcpus(dev->kvm);\r\nout:\r\nmutex_unlock(&dev->kvm->lock);\r\nreturn ret;\r\n}\r\nstatic int vgic_v3_set_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nint ret;\r\nret = vgic_set_common_attr(dev, attr);\r\nif (ret != -ENXIO)\r\nreturn ret;\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\ncase KVM_DEV_ARM_VGIC_GRP_REDIST_REGS: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nu32 tmp32;\r\nu64 reg;\r\nif (get_user(tmp32, uaddr))\r\nreturn -EFAULT;\r\nreg = tmp32;\r\nreturn vgic_v3_attr_regs_access(dev, attr, &reg, true);\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_SYSREGS: {\r\nu64 __user *uaddr = (u64 __user *)(long)attr->addr;\r\nu64 reg;\r\nif (get_user(reg, uaddr))\r\nreturn -EFAULT;\r\nreturn vgic_v3_attr_regs_access(dev, attr, &reg, true);\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_LEVEL_INFO: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nu64 reg;\r\nu32 tmp32;\r\nif (get_user(tmp32, uaddr))\r\nreturn -EFAULT;\r\nreg = tmp32;\r\nreturn vgic_v3_attr_regs_access(dev, attr, &reg, true);\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_CTRL: {\r\nint ret;\r\nswitch (attr->attr) {\r\ncase KVM_DEV_ARM_VGIC_SAVE_PENDING_TABLES:\r\nmutex_lock(&dev->kvm->lock);\r\nif (!lock_all_vcpus(dev->kvm)) {\r\nmutex_unlock(&dev->kvm->lock);\r\nreturn -EBUSY;\r\n}\r\nret = vgic_v3_save_pending_tables(dev->kvm);\r\nunlock_all_vcpus(dev->kvm);\r\nmutex_unlock(&dev->kvm->lock);\r\nreturn ret;\r\n}\r\nbreak;\r\n}\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int vgic_v3_get_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nint ret;\r\nret = vgic_get_common_attr(dev, attr);\r\nif (ret != -ENXIO)\r\nreturn ret;\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\ncase KVM_DEV_ARM_VGIC_GRP_REDIST_REGS: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nu64 reg;\r\nu32 tmp32;\r\nret = vgic_v3_attr_regs_access(dev, attr, &reg, false);\r\nif (ret)\r\nreturn ret;\r\ntmp32 = reg;\r\nreturn put_user(tmp32, uaddr);\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_SYSREGS: {\r\nu64 __user *uaddr = (u64 __user *)(long)attr->addr;\r\nu64 reg;\r\nret = vgic_v3_attr_regs_access(dev, attr, &reg, false);\r\nif (ret)\r\nreturn ret;\r\nreturn put_user(reg, uaddr);\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_LEVEL_INFO: {\r\nu32 __user *uaddr = (u32 __user *)(long)attr->addr;\r\nu64 reg;\r\nu32 tmp32;\r\nret = vgic_v3_attr_regs_access(dev, attr, &reg, false);\r\nif (ret)\r\nreturn ret;\r\ntmp32 = reg;\r\nreturn put_user(tmp32, uaddr);\r\n}\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int vgic_v3_has_attr(struct kvm_device *dev,\r\nstruct kvm_device_attr *attr)\r\n{\r\nswitch (attr->group) {\r\ncase KVM_DEV_ARM_VGIC_GRP_ADDR:\r\nswitch (attr->attr) {\r\ncase KVM_VGIC_V3_ADDR_TYPE_DIST:\r\ncase KVM_VGIC_V3_ADDR_TYPE_REDIST:\r\nreturn 0;\r\n}\r\nbreak;\r\ncase KVM_DEV_ARM_VGIC_GRP_DIST_REGS:\r\ncase KVM_DEV_ARM_VGIC_GRP_REDIST_REGS:\r\ncase KVM_DEV_ARM_VGIC_GRP_CPU_SYSREGS:\r\nreturn vgic_v3_has_attr_regs(dev, attr);\r\ncase KVM_DEV_ARM_VGIC_GRP_NR_IRQS:\r\nreturn 0;\r\ncase KVM_DEV_ARM_VGIC_GRP_LEVEL_INFO: {\r\nif (((attr->attr & KVM_DEV_ARM_VGIC_LINE_LEVEL_INFO_MASK) >>\r\nKVM_DEV_ARM_VGIC_LINE_LEVEL_INFO_SHIFT) ==\r\nVGIC_LEVEL_INFO_LINE_LEVEL)\r\nreturn 0;\r\nbreak;\r\n}\r\ncase KVM_DEV_ARM_VGIC_GRP_CTRL:\r\nswitch (attr->attr) {\r\ncase KVM_DEV_ARM_VGIC_CTRL_INIT:\r\nreturn 0;\r\ncase KVM_DEV_ARM_VGIC_SAVE_PENDING_TABLES:\r\nreturn 0;\r\n}\r\n}\r\nreturn -ENXIO;\r\n}
