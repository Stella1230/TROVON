struct uld_ctx *assign_chcr_device(void)\r\n{\r\nstruct uld_ctx *u_ctx = NULL;\r\nmutex_lock(&dev_mutex);\r\nif (!list_empty(&uld_ctx_list)) {\r\nu_ctx = ctx_rr;\r\nif (list_is_last(&ctx_rr->entry, &uld_ctx_list))\r\nctx_rr = list_first_entry(&uld_ctx_list,\r\nstruct uld_ctx,\r\nentry);\r\nelse\r\nctx_rr = list_next_entry(ctx_rr, entry);\r\n}\r\nmutex_unlock(&dev_mutex);\r\nreturn u_ctx;\r\n}\r\nstatic int chcr_dev_add(struct uld_ctx *u_ctx)\r\n{\r\nstruct chcr_dev *dev;\r\ndev = kzalloc(sizeof(*dev), GFP_KERNEL);\r\nif (!dev)\r\nreturn -ENXIO;\r\nspin_lock_init(&dev->lock_chcr_dev);\r\nu_ctx->dev = dev;\r\ndev->u_ctx = u_ctx;\r\natomic_inc(&dev_count);\r\nmutex_lock(&dev_mutex);\r\nlist_add_tail(&u_ctx->entry, &uld_ctx_list);\r\nif (!ctx_rr)\r\nctx_rr = u_ctx;\r\nmutex_unlock(&dev_mutex);\r\nreturn 0;\r\n}\r\nstatic int chcr_dev_remove(struct uld_ctx *u_ctx)\r\n{\r\nif (ctx_rr == u_ctx) {\r\nif (list_is_last(&ctx_rr->entry, &uld_ctx_list))\r\nctx_rr = list_first_entry(&uld_ctx_list,\r\nstruct uld_ctx,\r\nentry);\r\nelse\r\nctx_rr = list_next_entry(ctx_rr, entry);\r\n}\r\nlist_del(&u_ctx->entry);\r\nif (list_empty(&uld_ctx_list))\r\nctx_rr = NULL;\r\nkfree(u_ctx->dev);\r\nu_ctx->dev = NULL;\r\natomic_dec(&dev_count);\r\nreturn 0;\r\n}\r\nstatic int cpl_fw6_pld_handler(struct chcr_dev *dev,\r\nunsigned char *input)\r\n{\r\nstruct crypto_async_request *req;\r\nstruct cpl_fw6_pld *fw6_pld;\r\nu32 ack_err_status = 0;\r\nint error_status = 0;\r\nstruct adapter *adap = padap(dev);\r\nfw6_pld = (struct cpl_fw6_pld *)input;\r\nreq = (struct crypto_async_request *)(uintptr_t)be64_to_cpu(\r\nfw6_pld->data[1]);\r\nack_err_status =\r\nntohl(*(__be32 *)((unsigned char *)&fw6_pld->data[0] + 4));\r\nif (ack_err_status) {\r\nif (CHK_MAC_ERR_BIT(ack_err_status) ||\r\nCHK_PAD_ERR_BIT(ack_err_status))\r\nerror_status = -EBADMSG;\r\natomic_inc(&adap->chcr_stats.error);\r\n}\r\nif (req) {\r\nerror_status = chcr_handle_resp(req, input, error_status);\r\n} else {\r\npr_err("Incorrect request address from the firmware\n");\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nint chcr_send_wr(struct sk_buff *skb)\r\n{\r\nreturn cxgb4_crypto_send(skb->dev, skb);\r\n}\r\nstatic void *chcr_uld_add(const struct cxgb4_lld_info *lld)\r\n{\r\nstruct uld_ctx *u_ctx;\r\nu_ctx = kzalloc(sizeof(*u_ctx), GFP_KERNEL);\r\nif (!u_ctx) {\r\nu_ctx = ERR_PTR(-ENOMEM);\r\ngoto out;\r\n}\r\nif (!(lld->ulp_crypto & ULP_CRYPTO_LOOKASIDE)) {\r\nu_ctx = ERR_PTR(-ENOMEM);\r\ngoto out;\r\n}\r\nu_ctx->lldi = *lld;\r\nout:\r\nreturn u_ctx;\r\n}\r\nint chcr_uld_rx_handler(void *handle, const __be64 *rsp,\r\nconst struct pkt_gl *pgl)\r\n{\r\nstruct uld_ctx *u_ctx = (struct uld_ctx *)handle;\r\nstruct chcr_dev *dev = u_ctx->dev;\r\nconst struct cpl_fw6_pld *rpl = (struct cpl_fw6_pld *)rsp;\r\nif (rpl->opcode != CPL_FW6_PLD) {\r\npr_err("Unsupported opcode\n");\r\nreturn 0;\r\n}\r\nif (!pgl)\r\nwork_handlers[rpl->opcode](dev, (unsigned char *)&rsp[1]);\r\nelse\r\nwork_handlers[rpl->opcode](dev, pgl->va);\r\nreturn 0;\r\n}\r\nstatic int chcr_uld_state_change(void *handle, enum cxgb4_state state)\r\n{\r\nstruct uld_ctx *u_ctx = handle;\r\nint ret = 0;\r\nswitch (state) {\r\ncase CXGB4_STATE_UP:\r\nif (!u_ctx->dev) {\r\nret = chcr_dev_add(u_ctx);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\nif (atomic_read(&dev_count) == 1)\r\nret = start_crypto();\r\nbreak;\r\ncase CXGB4_STATE_DETACH:\r\nif (u_ctx->dev) {\r\nmutex_lock(&dev_mutex);\r\nchcr_dev_remove(u_ctx);\r\nmutex_unlock(&dev_mutex);\r\n}\r\nif (!atomic_read(&dev_count))\r\nstop_crypto();\r\nbreak;\r\ncase CXGB4_STATE_START_RECOVERY:\r\ncase CXGB4_STATE_DOWN:\r\ndefault:\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int __init chcr_crypto_init(void)\r\n{\r\nif (cxgb4_register_uld(CXGB4_ULD_CRYPTO, &chcr_uld_info))\r\npr_err("ULD register fail: No chcr crypto support in cxgb4");\r\nreturn 0;\r\n}\r\nstatic void __exit chcr_crypto_exit(void)\r\n{\r\nstruct uld_ctx *u_ctx, *tmp;\r\nif (atomic_read(&dev_count))\r\nstop_crypto();\r\nmutex_lock(&dev_mutex);\r\nlist_for_each_entry_safe(u_ctx, tmp, &uld_ctx_list, entry) {\r\nif (u_ctx->dev)\r\nchcr_dev_remove(u_ctx);\r\nkfree(u_ctx);\r\n}\r\nmutex_unlock(&dev_mutex);\r\ncxgb4_unregister_uld(CXGB4_ULD_CRYPTO);\r\n}
