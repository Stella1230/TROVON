int qed_rdma_bmap_alloc(struct qed_hwfn *p_hwfn,\r\nstruct qed_bmap *bmap, u32 max_count, char *name)\r\n{\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "max_count = %08x\n", max_count);\r\nbmap->max_count = max_count;\r\nbmap->bitmap = kcalloc(BITS_TO_LONGS(max_count), sizeof(long),\r\nGFP_KERNEL);\r\nif (!bmap->bitmap)\r\nreturn -ENOMEM;\r\nsnprintf(bmap->name, QED_RDMA_MAX_BMAP_NAME, "%s", name);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "0\n");\r\nreturn 0;\r\n}\r\nint qed_rdma_bmap_alloc_id(struct qed_hwfn *p_hwfn,\r\nstruct qed_bmap *bmap, u32 *id_num)\r\n{\r\n*id_num = find_first_zero_bit(bmap->bitmap, bmap->max_count);\r\nif (*id_num >= bmap->max_count)\r\nreturn -EINVAL;\r\n__set_bit(*id_num, bmap->bitmap);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "%s bitmap: allocated id %d\n",\r\nbmap->name, *id_num);\r\nreturn 0;\r\n}\r\nvoid qed_bmap_set_id(struct qed_hwfn *p_hwfn,\r\nstruct qed_bmap *bmap, u32 id_num)\r\n{\r\nif (id_num >= bmap->max_count)\r\nreturn;\r\n__set_bit(id_num, bmap->bitmap);\r\n}\r\nvoid qed_bmap_release_id(struct qed_hwfn *p_hwfn,\r\nstruct qed_bmap *bmap, u32 id_num)\r\n{\r\nbool b_acquired;\r\nif (id_num >= bmap->max_count)\r\nreturn;\r\nb_acquired = test_and_clear_bit(id_num, bmap->bitmap);\r\nif (!b_acquired) {\r\nDP_NOTICE(p_hwfn, "%s bitmap: id %d already released\n",\r\nbmap->name, id_num);\r\nreturn;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "%s bitmap: released id %d\n",\r\nbmap->name, id_num);\r\n}\r\nint qed_bmap_test_id(struct qed_hwfn *p_hwfn,\r\nstruct qed_bmap *bmap, u32 id_num)\r\n{\r\nif (id_num >= bmap->max_count)\r\nreturn -1;\r\nreturn test_bit(id_num, bmap->bitmap);\r\n}\r\nstatic bool qed_bmap_is_empty(struct qed_bmap *bmap)\r\n{\r\nreturn bmap->max_count == find_first_bit(bmap->bitmap, bmap->max_count);\r\n}\r\nu32 qed_rdma_get_sb_id(void *p_hwfn, u32 rel_sb_id)\r\n{\r\nreturn FEAT_NUM((struct qed_hwfn *)p_hwfn, QED_PF_L2_QUE) + rel_sb_id;\r\n}\r\nstatic int qed_rdma_alloc(struct qed_hwfn *p_hwfn,\r\nstruct qed_ptt *p_ptt,\r\nstruct qed_rdma_start_in_params *params)\r\n{\r\nstruct qed_rdma_info *p_rdma_info;\r\nu32 num_cons, num_tasks;\r\nint rc = -ENOMEM;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Allocating RDMA\n");\r\np_rdma_info = kzalloc(sizeof(*p_rdma_info), GFP_KERNEL);\r\nif (!p_rdma_info)\r\nreturn rc;\r\np_hwfn->p_rdma_info = p_rdma_info;\r\np_rdma_info->proto = PROTOCOLID_ROCE;\r\nnum_cons = qed_cxt_get_proto_cid_count(p_hwfn, p_rdma_info->proto,\r\nNULL);\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\np_rdma_info->num_qps = num_cons;\r\nelse\r\np_rdma_info->num_qps = num_cons / 2;\r\nnum_tasks = qed_cxt_get_proto_tid_count(p_hwfn, PROTOCOLID_ROCE);\r\np_rdma_info->num_mrs = num_tasks;\r\np_rdma_info->queue_zone_base = (u16)RESC_START(p_hwfn, QED_L2_QUEUE);\r\np_rdma_info->max_queue_zones = (u16)RESC_NUM(p_hwfn, QED_L2_QUEUE);\r\np_rdma_info->dev = kzalloc(sizeof(*p_rdma_info->dev), GFP_KERNEL);\r\nif (!p_rdma_info->dev)\r\ngoto free_rdma_info;\r\np_rdma_info->port = kzalloc(sizeof(*p_rdma_info->port), GFP_KERNEL);\r\nif (!p_rdma_info->port)\r\ngoto free_rdma_dev;\r\nrc = qed_rdma_bmap_alloc(p_hwfn, &p_rdma_info->pd_map, RDMA_MAX_PDS,\r\n"PD");\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to allocate pd_map, rc = %d\n",\r\nrc);\r\ngoto free_rdma_port;\r\n}\r\nrc = qed_rdma_bmap_alloc(p_hwfn, &p_rdma_info->dpi_map,\r\np_hwfn->dpi_count, "DPI");\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to allocate DPI bitmap, rc = %d\n", rc);\r\ngoto free_pd_map;\r\n}\r\nrc = qed_rdma_bmap_alloc(p_hwfn, &p_rdma_info->cq_map,\r\np_rdma_info->num_qps * 2, "CQ");\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to allocate cq bitmap, rc = %d\n", rc);\r\ngoto free_dpi_map;\r\n}\r\nrc = qed_rdma_bmap_alloc(p_hwfn, &p_rdma_info->toggle_bits,\r\np_rdma_info->num_qps * 2, "Toggle");\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to allocate toogle bits, rc = %d\n", rc);\r\ngoto free_cq_map;\r\n}\r\nrc = qed_rdma_bmap_alloc(p_hwfn, &p_rdma_info->tid_map,\r\np_rdma_info->num_mrs, "MR");\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to allocate itids bitmaps, rc = %d\n", rc);\r\ngoto free_toggle_map;\r\n}\r\nrc = qed_rdma_bmap_alloc(p_hwfn, &p_rdma_info->cid_map, num_cons,\r\n"CID");\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to allocate cid bitmap, rc = %d\n", rc);\r\ngoto free_tid_map;\r\n}\r\nrc = qed_rdma_bmap_alloc(p_hwfn, &p_rdma_info->real_cid_map, num_cons,\r\n"REAL_CID");\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to allocate real cid bitmap, rc = %d\n", rc);\r\ngoto free_cid_map;\r\n}\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\nrc = qed_iwarp_alloc(p_hwfn);\r\nif (rc)\r\ngoto free_cid_map;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Allocation successful\n");\r\nreturn 0;\r\nfree_cid_map:\r\nkfree(p_rdma_info->cid_map.bitmap);\r\nfree_tid_map:\r\nkfree(p_rdma_info->tid_map.bitmap);\r\nfree_toggle_map:\r\nkfree(p_rdma_info->toggle_bits.bitmap);\r\nfree_cq_map:\r\nkfree(p_rdma_info->cq_map.bitmap);\r\nfree_dpi_map:\r\nkfree(p_rdma_info->dpi_map.bitmap);\r\nfree_pd_map:\r\nkfree(p_rdma_info->pd_map.bitmap);\r\nfree_rdma_port:\r\nkfree(p_rdma_info->port);\r\nfree_rdma_dev:\r\nkfree(p_rdma_info->dev);\r\nfree_rdma_info:\r\nkfree(p_rdma_info);\r\nreturn rc;\r\n}\r\nvoid qed_rdma_bmap_free(struct qed_hwfn *p_hwfn,\r\nstruct qed_bmap *bmap, bool check)\r\n{\r\nint weight = bitmap_weight(bmap->bitmap, bmap->max_count);\r\nint last_line = bmap->max_count / (64 * 8);\r\nint last_item = last_line * 8 +\r\nDIV_ROUND_UP(bmap->max_count % (64 * 8), 64);\r\nu64 *pmap = (u64 *)bmap->bitmap;\r\nint line, item, offset;\r\nu8 str_last_line[200] = { 0 };\r\nif (!weight || !check)\r\ngoto end;\r\nDP_NOTICE(p_hwfn,\r\n"%s bitmap not free - size=%d, weight=%d, 512 bits per line\n",\r\nbmap->name, bmap->max_count, weight);\r\nfor (item = 0, line = 0; line < last_line; line++, item += 8)\r\nif (bitmap_weight((unsigned long *)&pmap[item], 64 * 8))\r\nDP_NOTICE(p_hwfn,\r\n"line 0x%04x: 0x%016llx 0x%016llx 0x%016llx 0x%016llx 0x%016llx 0x%016llx 0x%016llx 0x%016llx\n",\r\nline,\r\npmap[item],\r\npmap[item + 1],\r\npmap[item + 2],\r\npmap[item + 3],\r\npmap[item + 4],\r\npmap[item + 5],\r\npmap[item + 6], pmap[item + 7]);\r\nif ((bmap->max_count % (64 * 8)) &&\r\n(bitmap_weight((unsigned long *)&pmap[item],\r\nbmap->max_count - item * 64))) {\r\noffset = sprintf(str_last_line, "line 0x%04x: ", line);\r\nfor (; item < last_item; item++)\r\noffset += sprintf(str_last_line + offset,\r\n"0x%016llx ", pmap[item]);\r\nDP_NOTICE(p_hwfn, "%s\n", str_last_line);\r\n}\r\nend:\r\nkfree(bmap->bitmap);\r\nbmap->bitmap = NULL;\r\n}\r\nstatic void qed_rdma_resc_free(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_rdma_info *p_rdma_info = p_hwfn->p_rdma_info;\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\nqed_iwarp_resc_free(p_hwfn);\r\nqed_rdma_bmap_free(p_hwfn, &p_hwfn->p_rdma_info->cid_map, 1);\r\nqed_rdma_bmap_free(p_hwfn, &p_hwfn->p_rdma_info->pd_map, 1);\r\nqed_rdma_bmap_free(p_hwfn, &p_hwfn->p_rdma_info->dpi_map, 1);\r\nqed_rdma_bmap_free(p_hwfn, &p_hwfn->p_rdma_info->cq_map, 1);\r\nqed_rdma_bmap_free(p_hwfn, &p_hwfn->p_rdma_info->toggle_bits, 0);\r\nqed_rdma_bmap_free(p_hwfn, &p_hwfn->p_rdma_info->tid_map, 1);\r\nkfree(p_rdma_info->port);\r\nkfree(p_rdma_info->dev);\r\nkfree(p_rdma_info);\r\n}\r\nstatic void qed_rdma_free(struct qed_hwfn *p_hwfn)\r\n{\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Freeing RDMA\n");\r\nqed_rdma_resc_free(p_hwfn);\r\n}\r\nstatic void qed_rdma_get_guid(struct qed_hwfn *p_hwfn, u8 *guid)\r\n{\r\nguid[0] = p_hwfn->hw_info.hw_mac_addr[0] ^ 2;\r\nguid[1] = p_hwfn->hw_info.hw_mac_addr[1];\r\nguid[2] = p_hwfn->hw_info.hw_mac_addr[2];\r\nguid[3] = 0xff;\r\nguid[4] = 0xfe;\r\nguid[5] = p_hwfn->hw_info.hw_mac_addr[3];\r\nguid[6] = p_hwfn->hw_info.hw_mac_addr[4];\r\nguid[7] = p_hwfn->hw_info.hw_mac_addr[5];\r\n}\r\nstatic void qed_rdma_init_events(struct qed_hwfn *p_hwfn,\r\nstruct qed_rdma_start_in_params *params)\r\n{\r\nstruct qed_rdma_events *events;\r\nevents = &p_hwfn->p_rdma_info->events;\r\nevents->unaffiliated_event = params->events->unaffiliated_event;\r\nevents->affiliated_event = params->events->affiliated_event;\r\nevents->context = params->events->context;\r\n}\r\nstatic void qed_rdma_init_devinfo(struct qed_hwfn *p_hwfn,\r\nstruct qed_rdma_start_in_params *params)\r\n{\r\nstruct qed_rdma_device *dev = p_hwfn->p_rdma_info->dev;\r\nstruct qed_dev *cdev = p_hwfn->cdev;\r\nu32 pci_status_control;\r\nu32 num_qps;\r\ndev->vendor_id = cdev->vendor_id;\r\ndev->vendor_part_id = cdev->device_id;\r\ndev->hw_ver = 0;\r\ndev->fw_ver = (FW_MAJOR_VERSION << 24) | (FW_MINOR_VERSION << 16) |\r\n(FW_REVISION_VERSION << 8) | (FW_ENGINEERING_VERSION);\r\nqed_rdma_get_guid(p_hwfn, (u8 *)&dev->sys_image_guid);\r\ndev->node_guid = dev->sys_image_guid;\r\ndev->max_sge = min_t(u32, RDMA_MAX_SGE_PER_SQ_WQE,\r\nRDMA_MAX_SGE_PER_RQ_WQE);\r\nif (cdev->rdma_max_sge)\r\ndev->max_sge = min_t(u32, cdev->rdma_max_sge, dev->max_sge);\r\ndev->max_inline = ROCE_REQ_MAX_INLINE_DATA_SIZE;\r\ndev->max_inline = (cdev->rdma_max_inline) ?\r\nmin_t(u32, cdev->rdma_max_inline, dev->max_inline) :\r\ndev->max_inline;\r\ndev->max_wqe = QED_RDMA_MAX_WQE;\r\ndev->max_cnq = (u8)FEAT_NUM(p_hwfn, QED_RDMA_CNQ);\r\nnum_qps = ROCE_MAX_QPS;\r\nnum_qps = min_t(u64, num_qps, p_hwfn->p_rdma_info->num_qps);\r\ndev->max_qp = num_qps;\r\ndev->max_cq = num_qps * 2;\r\ndev->max_mr = p_hwfn->p_rdma_info->num_mrs - 1;\r\ndev->max_mr_size = QED_RDMA_MAX_MR_SIZE;\r\nif (params->cq_mode == QED_RDMA_CQ_MODE_32_BITS)\r\ndev->max_cqe = QED_RDMA_MAX_CQE_32_BIT;\r\nelse\r\ndev->max_cqe = QED_RDMA_MAX_CQE_16_BIT;\r\ndev->max_mw = 0;\r\ndev->max_fmr = QED_RDMA_MAX_FMR;\r\ndev->max_mr_mw_fmr_pbl = (PAGE_SIZE / 8) * (PAGE_SIZE / 8);\r\ndev->max_mr_mw_fmr_size = dev->max_mr_mw_fmr_pbl * PAGE_SIZE;\r\ndev->max_pkey = QED_RDMA_MAX_P_KEY;\r\ndev->max_qp_resp_rd_atomic_resc = RDMA_RING_PAGE_SIZE /\r\n(RDMA_RESP_RD_ATOMIC_ELM_SIZE * 2);\r\ndev->max_qp_req_rd_atomic_resc = RDMA_RING_PAGE_SIZE /\r\nRDMA_REQ_RD_ATOMIC_ELM_SIZE;\r\ndev->max_dev_resp_rd_atomic_resc = dev->max_qp_resp_rd_atomic_resc *\r\np_hwfn->p_rdma_info->num_qps;\r\ndev->page_size_caps = QED_RDMA_PAGE_SIZE_CAPS;\r\ndev->dev_ack_delay = QED_RDMA_ACK_DELAY;\r\ndev->max_pd = RDMA_MAX_PDS;\r\ndev->max_ah = p_hwfn->p_rdma_info->num_qps;\r\ndev->max_stats_queues = (u8)RESC_NUM(p_hwfn, QED_RDMA_STATS_QUEUE);\r\ndev->dev_caps = 0;\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_RNR_NAK, 1);\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_PORT_ACTIVE_EVENT, 1);\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_PORT_CHANGE_EVENT, 1);\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_RESIZE_CQ, 1);\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_BASE_MEMORY_EXT, 1);\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_BASE_QUEUE_EXT, 1);\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_ZBVA, 1);\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_LOCAL_INV_FENCE, 1);\r\npci_read_config_dword(cdev->pdev,\r\ncdev->pdev->pcie_cap + PCI_EXP_DEVCTL2,\r\n&pci_status_control);\r\nif (pci_status_control & PCI_EXP_DEVCTL2_LTR_EN)\r\nSET_FIELD(dev->dev_caps, QED_RDMA_DEV_CAP_ATOMIC_OP, 1);\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\nqed_iwarp_init_devinfo(p_hwfn);\r\n}\r\nstatic void qed_rdma_init_port(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_rdma_port *port = p_hwfn->p_rdma_info->port;\r\nstruct qed_rdma_device *dev = p_hwfn->p_rdma_info->dev;\r\nport->port_state = p_hwfn->mcp_info->link_output.link_up ?\r\nQED_RDMA_PORT_UP : QED_RDMA_PORT_DOWN;\r\nport->max_msg_size = min_t(u64,\r\n(dev->max_mr_mw_fmr_size *\r\np_hwfn->cdev->rdma_max_sge),\r\nBIT(31));\r\nport->pkey_bad_counter = 0;\r\n}\r\nstatic int qed_rdma_init_hw(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\r\n{\r\nint rc = 0;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Initializing HW\n");\r\np_hwfn->b_rdma_enabled_in_prs = false;\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\nqed_iwarp_init_hw(p_hwfn, p_ptt);\r\nelse\r\nrc = qed_roce_init_hw(p_hwfn, p_ptt);\r\nreturn rc;\r\n}\r\nstatic int qed_rdma_start_fw(struct qed_hwfn *p_hwfn,\r\nstruct qed_rdma_start_in_params *params,\r\nstruct qed_ptt *p_ptt)\r\n{\r\nstruct rdma_init_func_ramrod_data *p_ramrod;\r\nstruct qed_rdma_cnq_params *p_cnq_pbl_list;\r\nstruct rdma_init_func_hdr *p_params_header;\r\nstruct rdma_cnq_params *p_cnq_params;\r\nstruct qed_sp_init_data init_data;\r\nstruct qed_spq_entry *p_ent;\r\nu32 cnq_id, sb_id;\r\nu16 igu_sb_id;\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Starting FW\n");\r\np_hwfn->p_rdma_info->num_cnqs = params->desired_cnq;\r\nmemset(&init_data, 0, sizeof(init_data));\r\ninit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\r\ninit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\r\nrc = qed_sp_init_request(p_hwfn, &p_ent, RDMA_RAMROD_FUNC_INIT,\r\np_hwfn->p_rdma_info->proto, &init_data);\r\nif (rc)\r\nreturn rc;\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\np_ramrod = &p_ent->ramrod.iwarp_init_func.rdma;\r\nelse\r\np_ramrod = &p_ent->ramrod.roce_init_func.rdma;\r\np_params_header = &p_ramrod->params_header;\r\np_params_header->cnq_start_offset = (u8)RESC_START(p_hwfn,\r\nQED_RDMA_CNQ_RAM);\r\np_params_header->num_cnqs = params->desired_cnq;\r\nif (params->cq_mode == QED_RDMA_CQ_MODE_16_BITS)\r\np_params_header->cq_ring_mode = 1;\r\nelse\r\np_params_header->cq_ring_mode = 0;\r\nfor (cnq_id = 0; cnq_id < params->desired_cnq; cnq_id++) {\r\nsb_id = qed_rdma_get_sb_id(p_hwfn, cnq_id);\r\nigu_sb_id = qed_get_igu_sb_id(p_hwfn, sb_id);\r\np_ramrod->cnq_params[cnq_id].sb_num = cpu_to_le16(igu_sb_id);\r\np_cnq_params = &p_ramrod->cnq_params[cnq_id];\r\np_cnq_pbl_list = &params->cnq_pbl_list[cnq_id];\r\np_cnq_params->sb_index = p_hwfn->pf_params.rdma_pf_params.gl_pi;\r\np_cnq_params->num_pbl_pages = p_cnq_pbl_list->num_pbl_pages;\r\nDMA_REGPAIR_LE(p_cnq_params->pbl_base_addr,\r\np_cnq_pbl_list->pbl_ptr);\r\np_cnq_params->queue_zone_num =\r\ncpu_to_le16(p_hwfn->p_rdma_info->queue_zone_base +\r\ncnq_id);\r\n}\r\nreturn qed_spq_post(p_hwfn, p_ent, NULL);\r\n}\r\nstatic int qed_rdma_alloc_tid(void *rdma_cxt, u32 *itid)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Allocate TID\n");\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nrc = qed_rdma_bmap_alloc_id(p_hwfn,\r\n&p_hwfn->p_rdma_info->tid_map, itid);\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\nif (rc)\r\ngoto out;\r\nrc = qed_cxt_dynamic_ilt_alloc(p_hwfn, QED_ELEM_TASK, *itid);\r\nout:\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Allocate TID - done, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int qed_rdma_reserve_lkey(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_rdma_device *dev = p_hwfn->p_rdma_info->dev;\r\n__set_bit(0, p_hwfn->p_rdma_info->dpi_map.bitmap);\r\nqed_rdma_alloc_tid(p_hwfn, &dev->reserved_lkey);\r\nif (dev->reserved_lkey != RDMA_RESERVED_LKEY) {\r\nDP_NOTICE(p_hwfn,\r\n"Reserved lkey should be equal to RDMA_RESERVED_LKEY\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int qed_rdma_setup(struct qed_hwfn *p_hwfn,\r\nstruct qed_ptt *p_ptt,\r\nstruct qed_rdma_start_in_params *params)\r\n{\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "RDMA setup\n");\r\nspin_lock_init(&p_hwfn->p_rdma_info->lock);\r\nqed_rdma_init_devinfo(p_hwfn, params);\r\nqed_rdma_init_port(p_hwfn);\r\nqed_rdma_init_events(p_hwfn, params);\r\nrc = qed_rdma_reserve_lkey(p_hwfn);\r\nif (rc)\r\nreturn rc;\r\nrc = qed_rdma_init_hw(p_hwfn, p_ptt);\r\nif (rc)\r\nreturn rc;\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn)) {\r\nrc = qed_iwarp_setup(p_hwfn, p_ptt, params);\r\nif (rc)\r\nreturn rc;\r\n} else {\r\nrc = qed_roce_setup(p_hwfn);\r\nif (rc)\r\nreturn rc;\r\n}\r\nreturn qed_rdma_start_fw(p_hwfn, params, p_ptt);\r\n}\r\nint qed_rdma_stop(void *rdma_cxt)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct rdma_close_func_ramrod_data *p_ramrod;\r\nstruct qed_sp_init_data init_data;\r\nstruct qed_spq_entry *p_ent;\r\nstruct qed_ptt *p_ptt;\r\nu32 ll2_ethertype_en;\r\nint rc = -EBUSY;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "RDMA stop\n");\r\np_ptt = qed_ptt_acquire(p_hwfn);\r\nif (!p_ptt) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Failed to acquire PTT\n");\r\nreturn rc;\r\n}\r\nqed_wr(p_hwfn, p_ptt, p_hwfn->rdma_prs_search_reg, 0);\r\np_hwfn->b_rdma_enabled_in_prs = false;\r\nqed_wr(p_hwfn, p_ptt, PRS_REG_ROCE_DEST_QP_MAX_PF, 0);\r\nll2_ethertype_en = qed_rd(p_hwfn, p_ptt, PRS_REG_LIGHT_L2_ETHERTYPE_EN);\r\nqed_wr(p_hwfn, p_ptt, PRS_REG_LIGHT_L2_ETHERTYPE_EN,\r\n(ll2_ethertype_en & 0xFFFE));\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn)) {\r\nrc = qed_iwarp_stop(p_hwfn, p_ptt);\r\nif (rc) {\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nreturn rc;\r\n}\r\n} else {\r\nqed_roce_stop(p_hwfn);\r\n}\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nmemset(&init_data, 0, sizeof(init_data));\r\ninit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\r\ninit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\r\nrc = qed_sp_init_request(p_hwfn, &p_ent, RDMA_RAMROD_FUNC_CLOSE,\r\np_hwfn->p_rdma_info->proto, &init_data);\r\nif (rc)\r\ngoto out;\r\np_ramrod = &p_ent->ramrod.rdma_close_func;\r\np_ramrod->num_cnqs = p_hwfn->p_rdma_info->num_cnqs;\r\np_ramrod->cnq_start_offset = (u8)RESC_START(p_hwfn, QED_RDMA_CNQ_RAM);\r\nrc = qed_spq_post(p_hwfn, p_ent, NULL);\r\nout:\r\nqed_rdma_free(p_hwfn);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "RDMA stop done, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int qed_rdma_add_user(void *rdma_cxt,\r\nstruct qed_rdma_add_user_out_params *out_params)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nu32 dpi_start_offset;\r\nu32 returned_id = 0;\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Adding User\n");\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nrc = qed_rdma_bmap_alloc_id(p_hwfn, &p_hwfn->p_rdma_info->dpi_map,\r\n&returned_id);\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\nout_params->dpi = (u16)returned_id;\r\ndpi_start_offset = p_hwfn->dpi_start_offset;\r\nout_params->dpi_addr = (u64)((u8 __iomem *)p_hwfn->doorbells +\r\ndpi_start_offset +\r\n((out_params->dpi) * p_hwfn->dpi_size));\r\nout_params->dpi_phys_addr = p_hwfn->cdev->db_phys_addr +\r\ndpi_start_offset +\r\n((out_params->dpi) * p_hwfn->dpi_size);\r\nout_params->dpi_size = p_hwfn->dpi_size;\r\nout_params->wid_count = p_hwfn->wid_count;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Adding user - done, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic struct qed_rdma_port *qed_rdma_query_port(void *rdma_cxt)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct qed_rdma_port *p_port = p_hwfn->p_rdma_info->port;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "RDMA Query port\n");\r\np_port->port_state = p_hwfn->mcp_info->link_output.link_up ?\r\nQED_RDMA_PORT_UP : QED_RDMA_PORT_DOWN;\r\np_port->link_speed = p_hwfn->mcp_info->link_output.speed;\r\np_port->max_msg_size = RDMA_MAX_DATA_SIZE_IN_WQE;\r\nreturn p_port;\r\n}\r\nstatic struct qed_rdma_device *qed_rdma_query_device(void *rdma_cxt)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Query device\n");\r\nreturn p_hwfn->p_rdma_info->dev;\r\n}\r\nstatic void qed_rdma_free_tid(void *rdma_cxt, u32 itid)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "itid = %08x\n", itid);\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nqed_bmap_release_id(p_hwfn, &p_hwfn->p_rdma_info->tid_map, itid);\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\n}\r\nstatic void qed_rdma_cnq_prod_update(void *rdma_cxt, u8 qz_offset, u16 prod)\r\n{\r\nstruct qed_hwfn *p_hwfn;\r\nu16 qz_num;\r\nu32 addr;\r\np_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nif (qz_offset > p_hwfn->p_rdma_info->max_queue_zones) {\r\nDP_NOTICE(p_hwfn,\r\n"queue zone offset %d is too large (max is %d)\n",\r\nqz_offset, p_hwfn->p_rdma_info->max_queue_zones);\r\nreturn;\r\n}\r\nqz_num = p_hwfn->p_rdma_info->queue_zone_base + qz_offset;\r\naddr = GTT_BAR0_MAP_REG_USDM_RAM +\r\nUSTORM_COMMON_QUEUE_CONS_OFFSET(qz_num);\r\nREG_WR16(p_hwfn, addr, prod);\r\nwmb();\r\n}\r\nstatic int qed_fill_rdma_dev_info(struct qed_dev *cdev,\r\nstruct qed_dev_rdma_info *info)\r\n{\r\nstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\r\nmemset(info, 0, sizeof(*info));\r\ninfo->rdma_type = QED_IS_ROCE_PERSONALITY(p_hwfn) ?\r\nQED_RDMA_TYPE_ROCE : QED_RDMA_TYPE_IWARP;\r\ninfo->user_dpm_enabled = (p_hwfn->db_bar_no_edpm == 0);\r\nqed_fill_dev_info(cdev, &info->common);\r\nreturn 0;\r\n}\r\nstatic int qed_rdma_get_sb_start(struct qed_dev *cdev)\r\n{\r\nint feat_num;\r\nif (cdev->num_hwfns > 1)\r\nfeat_num = FEAT_NUM(QED_LEADING_HWFN(cdev), QED_PF_L2_QUE);\r\nelse\r\nfeat_num = FEAT_NUM(QED_LEADING_HWFN(cdev), QED_PF_L2_QUE) *\r\ncdev->num_hwfns;\r\nreturn feat_num;\r\n}\r\nstatic int qed_rdma_get_min_cnq_msix(struct qed_dev *cdev)\r\n{\r\nint n_cnq = FEAT_NUM(QED_LEADING_HWFN(cdev), QED_RDMA_CNQ);\r\nint n_msix = cdev->int_params.rdma_msix_cnt;\r\nreturn min_t(int, n_cnq, n_msix);\r\n}\r\nstatic int qed_rdma_set_int(struct qed_dev *cdev, u16 cnt)\r\n{\r\nint limit = 0;\r\ncdev->int_params.fp_initialized = cnt ? true : false;\r\nif (cdev->int_params.out.int_mode != QED_INT_MODE_MSIX) {\r\nDP_ERR(cdev,\r\n"qed roce supports only MSI-X interrupts (detected %d).\n",\r\ncdev->int_params.out.int_mode);\r\nreturn -EINVAL;\r\n} else if (cdev->int_params.fp_msix_cnt) {\r\nlimit = cdev->int_params.rdma_msix_cnt;\r\n}\r\nif (!limit)\r\nreturn -ENOMEM;\r\nreturn min_t(int, cnt, limit);\r\n}\r\nstatic int qed_rdma_get_int(struct qed_dev *cdev, struct qed_int_info *info)\r\n{\r\nmemset(info, 0, sizeof(*info));\r\nif (!cdev->int_params.fp_initialized) {\r\nDP_INFO(cdev,\r\n"Protocol driver requested interrupt information, but its support is not yet configured\n");\r\nreturn -EINVAL;\r\n}\r\nif (cdev->int_params.out.int_mode == QED_INT_MODE_MSIX) {\r\nint msix_base = cdev->int_params.rdma_msix_base;\r\ninfo->msix_cnt = cdev->int_params.rdma_msix_cnt;\r\ninfo->msix = &cdev->int_params.msix_table[msix_base];\r\nDP_VERBOSE(cdev, QED_MSG_RDMA, "msix_cnt = %d msix_base=%d\n",\r\ninfo->msix_cnt, msix_base);\r\n}\r\nreturn 0;\r\n}\r\nstatic int qed_rdma_alloc_pd(void *rdma_cxt, u16 *pd)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nu32 returned_id;\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Alloc PD\n");\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nrc = qed_rdma_bmap_alloc_id(p_hwfn,\r\n&p_hwfn->p_rdma_info->pd_map, &returned_id);\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\n*pd = (u16)returned_id;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Alloc PD - done, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic void qed_rdma_free_pd(void *rdma_cxt, u16 pd)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "pd = %08x\n", pd);\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nqed_bmap_release_id(p_hwfn, &p_hwfn->p_rdma_info->pd_map, pd);\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\n}\r\nstatic enum qed_rdma_toggle_bit\r\nqed_rdma_toggle_bit_create_resize_cq(struct qed_hwfn *p_hwfn, u16 icid)\r\n{\r\nstruct qed_rdma_info *p_info = p_hwfn->p_rdma_info;\r\nenum qed_rdma_toggle_bit toggle_bit;\r\nu32 bmap_id;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "icid = %08x\n", icid);\r\nbmap_id = icid - qed_cxt_get_proto_cid_start(p_hwfn, p_info->proto);\r\nspin_lock_bh(&p_info->lock);\r\ntoggle_bit = !test_and_change_bit(bmap_id,\r\np_info->toggle_bits.bitmap);\r\nspin_unlock_bh(&p_info->lock);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "QED_RDMA_TOGGLE_BIT_= %d\n",\r\ntoggle_bit);\r\nreturn toggle_bit;\r\n}\r\nstatic int qed_rdma_create_cq(void *rdma_cxt,\r\nstruct qed_rdma_create_cq_in_params *params,\r\nu16 *icid)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct qed_rdma_info *p_info = p_hwfn->p_rdma_info;\r\nstruct rdma_create_cq_ramrod_data *p_ramrod;\r\nenum qed_rdma_toggle_bit toggle_bit;\r\nstruct qed_sp_init_data init_data;\r\nstruct qed_spq_entry *p_ent;\r\nu32 returned_id, start_cid;\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "cq_handle = %08x%08x\n",\r\nparams->cq_handle_hi, params->cq_handle_lo);\r\nspin_lock_bh(&p_info->lock);\r\nrc = qed_rdma_bmap_alloc_id(p_hwfn, &p_info->cq_map, &returned_id);\r\nspin_unlock_bh(&p_info->lock);\r\nif (rc) {\r\nDP_NOTICE(p_hwfn, "Can't create CQ, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstart_cid = qed_cxt_get_proto_cid_start(p_hwfn,\r\np_info->proto);\r\n*icid = returned_id + start_cid;\r\nrc = qed_cxt_dynamic_ilt_alloc(p_hwfn, QED_ELEM_CXT, *icid);\r\nif (rc)\r\ngoto err;\r\nmemset(&init_data, 0, sizeof(init_data));\r\ninit_data.cid = *icid;\r\ninit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\r\ninit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\r\nrc = qed_sp_init_request(p_hwfn, &p_ent,\r\nRDMA_RAMROD_CREATE_CQ,\r\np_info->proto, &init_data);\r\nif (rc)\r\ngoto err;\r\np_ramrod = &p_ent->ramrod.rdma_create_cq;\r\np_ramrod->cq_handle.hi = cpu_to_le32(params->cq_handle_hi);\r\np_ramrod->cq_handle.lo = cpu_to_le32(params->cq_handle_lo);\r\np_ramrod->dpi = cpu_to_le16(params->dpi);\r\np_ramrod->is_two_level_pbl = params->pbl_two_level;\r\np_ramrod->max_cqes = cpu_to_le32(params->cq_size);\r\nDMA_REGPAIR_LE(p_ramrod->pbl_addr, params->pbl_ptr);\r\np_ramrod->pbl_num_pages = cpu_to_le16(params->pbl_num_pages);\r\np_ramrod->cnq_id = (u8)RESC_START(p_hwfn, QED_RDMA_CNQ_RAM) +\r\nparams->cnq_id;\r\np_ramrod->int_timeout = params->int_timeout;\r\ntoggle_bit = qed_rdma_toggle_bit_create_resize_cq(p_hwfn, *icid);\r\np_ramrod->toggle_bit = toggle_bit;\r\nrc = qed_spq_post(p_hwfn, p_ent, NULL);\r\nif (rc) {\r\nqed_rdma_toggle_bit_create_resize_cq(p_hwfn, *icid);\r\ngoto err;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Created CQ, rc = %d\n", rc);\r\nreturn rc;\r\nerr:\r\nspin_lock_bh(&p_info->lock);\r\nqed_bmap_release_id(p_hwfn, &p_info->cq_map, returned_id);\r\nspin_unlock_bh(&p_info->lock);\r\nDP_NOTICE(p_hwfn, "Create CQ failed, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int\r\nqed_rdma_destroy_cq(void *rdma_cxt,\r\nstruct qed_rdma_destroy_cq_in_params *in_params,\r\nstruct qed_rdma_destroy_cq_out_params *out_params)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct rdma_destroy_cq_output_params *p_ramrod_res;\r\nstruct rdma_destroy_cq_ramrod_data *p_ramrod;\r\nstruct qed_sp_init_data init_data;\r\nstruct qed_spq_entry *p_ent;\r\ndma_addr_t ramrod_res_phys;\r\nenum protocol_type proto;\r\nint rc = -ENOMEM;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "icid = %08x\n", in_params->icid);\r\np_ramrod_res =\r\n(struct rdma_destroy_cq_output_params *)\r\ndma_alloc_coherent(&p_hwfn->cdev->pdev->dev,\r\nsizeof(struct rdma_destroy_cq_output_params),\r\n&ramrod_res_phys, GFP_KERNEL);\r\nif (!p_ramrod_res) {\r\nDP_NOTICE(p_hwfn,\r\n"qed destroy cq failed: cannot allocate memory (ramrod)\n");\r\nreturn rc;\r\n}\r\nmemset(&init_data, 0, sizeof(init_data));\r\ninit_data.cid = in_params->icid;\r\ninit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\r\ninit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\r\nproto = p_hwfn->p_rdma_info->proto;\r\nrc = qed_sp_init_request(p_hwfn, &p_ent,\r\nRDMA_RAMROD_DESTROY_CQ,\r\nproto, &init_data);\r\nif (rc)\r\ngoto err;\r\np_ramrod = &p_ent->ramrod.rdma_destroy_cq;\r\nDMA_REGPAIR_LE(p_ramrod->output_params_addr, ramrod_res_phys);\r\nrc = qed_spq_post(p_hwfn, p_ent, NULL);\r\nif (rc)\r\ngoto err;\r\nout_params->num_cq_notif = le16_to_cpu(p_ramrod_res->cnq_num);\r\ndma_free_coherent(&p_hwfn->cdev->pdev->dev,\r\nsizeof(struct rdma_destroy_cq_output_params),\r\np_ramrod_res, ramrod_res_phys);\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nqed_bmap_release_id(p_hwfn,\r\n&p_hwfn->p_rdma_info->cq_map,\r\n(in_params->icid -\r\nqed_cxt_get_proto_cid_start(p_hwfn, proto)));\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Destroyed CQ, rc = %d\n", rc);\r\nreturn rc;\r\nerr: dma_free_coherent(&p_hwfn->cdev->pdev->dev,\r\nsizeof(struct rdma_destroy_cq_output_params),\r\np_ramrod_res, ramrod_res_phys);\r\nreturn rc;\r\n}\r\nvoid qed_rdma_set_fw_mac(u16 *p_fw_mac, u8 *p_qed_mac)\r\n{\r\np_fw_mac[0] = cpu_to_le16((p_qed_mac[0] << 8) + p_qed_mac[1]);\r\np_fw_mac[1] = cpu_to_le16((p_qed_mac[2] << 8) + p_qed_mac[3]);\r\np_fw_mac[2] = cpu_to_le16((p_qed_mac[4] << 8) + p_qed_mac[5]);\r\n}\r\nstatic int qed_rdma_query_qp(void *rdma_cxt,\r\nstruct qed_rdma_qp *qp,\r\nstruct qed_rdma_query_qp_out_params *out_params)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nint rc = 0;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "icid = %08x\n", qp->icid);\r\nout_params->mtu = qp->mtu;\r\nout_params->dest_qp = qp->dest_qp;\r\nout_params->incoming_atomic_en = qp->incoming_atomic_en;\r\nout_params->e2e_flow_control_en = qp->e2e_flow_control_en;\r\nout_params->incoming_rdma_read_en = qp->incoming_rdma_read_en;\r\nout_params->incoming_rdma_write_en = qp->incoming_rdma_write_en;\r\nout_params->dgid = qp->dgid;\r\nout_params->flow_label = qp->flow_label;\r\nout_params->hop_limit_ttl = qp->hop_limit_ttl;\r\nout_params->traffic_class_tos = qp->traffic_class_tos;\r\nout_params->timeout = qp->ack_timeout;\r\nout_params->rnr_retry = qp->rnr_retry_cnt;\r\nout_params->retry_cnt = qp->retry_cnt;\r\nout_params->min_rnr_nak_timer = qp->min_rnr_nak_timer;\r\nout_params->pkey_index = 0;\r\nout_params->max_rd_atomic = qp->max_rd_atomic_req;\r\nout_params->max_dest_rd_atomic = qp->max_rd_atomic_resp;\r\nout_params->sqd_async = qp->sqd_async;\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\nqed_iwarp_query_qp(qp, out_params);\r\nelse\r\nrc = qed_roce_query_qp(p_hwfn, qp, out_params);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Query QP, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int qed_rdma_destroy_qp(void *rdma_cxt, struct qed_rdma_qp *qp)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nint rc = 0;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "icid = %08x\n", qp->icid);\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn))\r\nrc = qed_iwarp_destroy_qp(p_hwfn, qp);\r\nelse\r\nrc = qed_roce_destroy_qp(p_hwfn, qp);\r\nkfree(qp);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "QP destroyed\n");\r\nreturn rc;\r\n}\r\nstatic struct qed_rdma_qp *\r\nqed_rdma_create_qp(void *rdma_cxt,\r\nstruct qed_rdma_create_qp_in_params *in_params,\r\nstruct qed_rdma_create_qp_out_params *out_params)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct qed_rdma_qp *qp;\r\nu8 max_stats_queues;\r\nint rc;\r\nif (!rdma_cxt || !in_params || !out_params || !p_hwfn->p_rdma_info) {\r\nDP_ERR(p_hwfn->cdev,\r\n"qed roce create qp failed due to NULL entry (rdma_cxt=%p, in=%p, out=%p, roce_info=?\n",\r\nrdma_cxt, in_params, out_params);\r\nreturn NULL;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"qed rdma create qp called with qp_handle = %08x%08x\n",\r\nin_params->qp_handle_hi, in_params->qp_handle_lo);\r\nmax_stats_queues = p_hwfn->p_rdma_info->dev->max_stats_queues;\r\nif (in_params->stats_queue >= max_stats_queues) {\r\nDP_ERR(p_hwfn->cdev,\r\n"qed rdma create qp failed due to invalid statistics queue %d. maximum is %d\n",\r\nin_params->stats_queue, max_stats_queues);\r\nreturn NULL;\r\n}\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn)) {\r\nif (in_params->sq_num_pages * sizeof(struct regpair) >\r\nIWARP_SHARED_QUEUE_PAGE_SQ_PBL_MAX_SIZE) {\r\nDP_NOTICE(p_hwfn->cdev,\r\n"Sq num pages: %d exceeds maximum\n",\r\nin_params->sq_num_pages);\r\nreturn NULL;\r\n}\r\nif (in_params->rq_num_pages * sizeof(struct regpair) >\r\nIWARP_SHARED_QUEUE_PAGE_RQ_PBL_MAX_SIZE) {\r\nDP_NOTICE(p_hwfn->cdev,\r\n"Rq num pages: %d exceeds maximum\n",\r\nin_params->rq_num_pages);\r\nreturn NULL;\r\n}\r\n}\r\nqp = kzalloc(sizeof(*qp), GFP_KERNEL);\r\nif (!qp)\r\nreturn NULL;\r\nqp->cur_state = QED_ROCE_QP_STATE_RESET;\r\nqp->qp_handle.hi = cpu_to_le32(in_params->qp_handle_hi);\r\nqp->qp_handle.lo = cpu_to_le32(in_params->qp_handle_lo);\r\nqp->qp_handle_async.hi = cpu_to_le32(in_params->qp_handle_async_hi);\r\nqp->qp_handle_async.lo = cpu_to_le32(in_params->qp_handle_async_lo);\r\nqp->use_srq = in_params->use_srq;\r\nqp->signal_all = in_params->signal_all;\r\nqp->fmr_and_reserved_lkey = in_params->fmr_and_reserved_lkey;\r\nqp->pd = in_params->pd;\r\nqp->dpi = in_params->dpi;\r\nqp->sq_cq_id = in_params->sq_cq_id;\r\nqp->sq_num_pages = in_params->sq_num_pages;\r\nqp->sq_pbl_ptr = in_params->sq_pbl_ptr;\r\nqp->rq_cq_id = in_params->rq_cq_id;\r\nqp->rq_num_pages = in_params->rq_num_pages;\r\nqp->rq_pbl_ptr = in_params->rq_pbl_ptr;\r\nqp->srq_id = in_params->srq_id;\r\nqp->req_offloaded = false;\r\nqp->resp_offloaded = false;\r\nqp->e2e_flow_control_en = qp->use_srq ? false : true;\r\nqp->stats_queue = in_params->stats_queue;\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn)) {\r\nrc = qed_iwarp_create_qp(p_hwfn, qp, out_params);\r\nqp->qpid = qp->icid;\r\n} else {\r\nrc = qed_roce_alloc_cid(p_hwfn, &qp->icid);\r\nqp->qpid = ((0xFF << 16) | qp->icid);\r\n}\r\nif (rc) {\r\nkfree(qp);\r\nreturn NULL;\r\n}\r\nout_params->icid = qp->icid;\r\nout_params->qp_id = qp->qpid;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Create QP, rc = %d\n", rc);\r\nreturn qp;\r\n}\r\nstatic int qed_rdma_modify_qp(void *rdma_cxt,\r\nstruct qed_rdma_qp *qp,\r\nstruct qed_rdma_modify_qp_in_params *params)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nenum qed_roce_qp_state prev_state;\r\nint rc = 0;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "icid = %08x params->new_state=%d\n",\r\nqp->icid, params->new_state);\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nif (GET_FIELD(params->modify_flags,\r\nQED_RDMA_MODIFY_QP_VALID_RDMA_OPS_EN)) {\r\nqp->incoming_rdma_read_en = params->incoming_rdma_read_en;\r\nqp->incoming_rdma_write_en = params->incoming_rdma_write_en;\r\nqp->incoming_atomic_en = params->incoming_atomic_en;\r\n}\r\nif (GET_FIELD(params->modify_flags, QED_ROCE_MODIFY_QP_VALID_ROCE_MODE))\r\nqp->roce_mode = params->roce_mode;\r\nif (GET_FIELD(params->modify_flags, QED_ROCE_MODIFY_QP_VALID_PKEY))\r\nqp->pkey = params->pkey;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_ROCE_MODIFY_QP_VALID_E2E_FLOW_CONTROL_EN))\r\nqp->e2e_flow_control_en = params->e2e_flow_control_en;\r\nif (GET_FIELD(params->modify_flags, QED_ROCE_MODIFY_QP_VALID_DEST_QP))\r\nqp->dest_qp = params->dest_qp;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_ROCE_MODIFY_QP_VALID_ADDRESS_VECTOR)) {\r\nqp->traffic_class_tos = params->traffic_class_tos;\r\nqp->flow_label = params->flow_label;\r\nqp->hop_limit_ttl = params->hop_limit_ttl;\r\nqp->sgid = params->sgid;\r\nqp->dgid = params->dgid;\r\nqp->udp_src_port = 0;\r\nqp->vlan_id = params->vlan_id;\r\nqp->mtu = params->mtu;\r\nqp->lb_indication = params->lb_indication;\r\nmemcpy((u8 *)&qp->remote_mac_addr[0],\r\n(u8 *)&params->remote_mac_addr[0], ETH_ALEN);\r\nif (params->use_local_mac) {\r\nmemcpy((u8 *)&qp->local_mac_addr[0],\r\n(u8 *)&params->local_mac_addr[0], ETH_ALEN);\r\n} else {\r\nmemcpy((u8 *)&qp->local_mac_addr[0],\r\n(u8 *)&p_hwfn->hw_info.hw_mac_addr, ETH_ALEN);\r\n}\r\n}\r\nif (GET_FIELD(params->modify_flags, QED_ROCE_MODIFY_QP_VALID_RQ_PSN))\r\nqp->rq_psn = params->rq_psn;\r\nif (GET_FIELD(params->modify_flags, QED_ROCE_MODIFY_QP_VALID_SQ_PSN))\r\nqp->sq_psn = params->sq_psn;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_RDMA_MODIFY_QP_VALID_MAX_RD_ATOMIC_REQ))\r\nqp->max_rd_atomic_req = params->max_rd_atomic_req;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_RDMA_MODIFY_QP_VALID_MAX_RD_ATOMIC_RESP))\r\nqp->max_rd_atomic_resp = params->max_rd_atomic_resp;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_ROCE_MODIFY_QP_VALID_ACK_TIMEOUT))\r\nqp->ack_timeout = params->ack_timeout;\r\nif (GET_FIELD(params->modify_flags, QED_ROCE_MODIFY_QP_VALID_RETRY_CNT))\r\nqp->retry_cnt = params->retry_cnt;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_ROCE_MODIFY_QP_VALID_RNR_RETRY_CNT))\r\nqp->rnr_retry_cnt = params->rnr_retry_cnt;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_ROCE_MODIFY_QP_VALID_MIN_RNR_NAK_TIMER))\r\nqp->min_rnr_nak_timer = params->min_rnr_nak_timer;\r\nqp->sqd_async = params->sqd_async;\r\nprev_state = qp->cur_state;\r\nif (GET_FIELD(params->modify_flags,\r\nQED_RDMA_MODIFY_QP_VALID_NEW_STATE)) {\r\nqp->cur_state = params->new_state;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "qp->cur_state=%d\n",\r\nqp->cur_state);\r\n}\r\nif (QED_IS_IWARP_PERSONALITY(p_hwfn)) {\r\nenum qed_iwarp_qp_state new_state =\r\nqed_roce2iwarp_state(qp->cur_state);\r\nrc = qed_iwarp_modify_qp(p_hwfn, qp, new_state, 0);\r\n} else {\r\nrc = qed_roce_modify_qp(p_hwfn, qp, prev_state, params);\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Modify QP, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int\r\nqed_rdma_register_tid(void *rdma_cxt,\r\nstruct qed_rdma_register_tid_in_params *params)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct rdma_register_tid_ramrod_data *p_ramrod;\r\nstruct qed_sp_init_data init_data;\r\nstruct qed_spq_entry *p_ent;\r\nenum rdma_tid_type tid_type;\r\nu8 fw_return_code;\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "itid = %08x\n", params->itid);\r\nmemset(&init_data, 0, sizeof(init_data));\r\ninit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\r\ninit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\r\nrc = qed_sp_init_request(p_hwfn, &p_ent, RDMA_RAMROD_REGISTER_MR,\r\np_hwfn->p_rdma_info->proto, &init_data);\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nif (p_hwfn->p_rdma_info->last_tid < params->itid)\r\np_hwfn->p_rdma_info->last_tid = params->itid;\r\np_ramrod = &p_ent->ramrod.rdma_register_tid;\r\np_ramrod->flags = 0;\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_TWO_LEVEL_PBL,\r\nparams->pbl_two_level);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_ZERO_BASED, params->zbva);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_PHY_MR, params->phy_mr);\r\nif (!(params->tid_type == QED_RDMA_TID_FMR) && !(params->dma_mr))\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_PAGE_SIZE_LOG,\r\nparams->page_size_log - 12);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_REMOTE_READ,\r\nparams->remote_read);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_REMOTE_WRITE,\r\nparams->remote_write);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_REMOTE_ATOMIC,\r\nparams->remote_atomic);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_LOCAL_WRITE,\r\nparams->local_write);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_LOCAL_READ, params->local_read);\r\nSET_FIELD(p_ramrod->flags,\r\nRDMA_REGISTER_TID_RAMROD_DATA_ENABLE_MW_BIND,\r\nparams->mw_bind);\r\nSET_FIELD(p_ramrod->flags1,\r\nRDMA_REGISTER_TID_RAMROD_DATA_PBL_PAGE_SIZE_LOG,\r\nparams->pbl_page_size_log - 12);\r\nSET_FIELD(p_ramrod->flags2,\r\nRDMA_REGISTER_TID_RAMROD_DATA_DMA_MR, params->dma_mr);\r\nswitch (params->tid_type) {\r\ncase QED_RDMA_TID_REGISTERED_MR:\r\ntid_type = RDMA_TID_REGISTERED_MR;\r\nbreak;\r\ncase QED_RDMA_TID_FMR:\r\ntid_type = RDMA_TID_FMR;\r\nbreak;\r\ncase QED_RDMA_TID_MW_TYPE1:\r\ntid_type = RDMA_TID_MW_TYPE1;\r\nbreak;\r\ncase QED_RDMA_TID_MW_TYPE2A:\r\ntid_type = RDMA_TID_MW_TYPE2A;\r\nbreak;\r\ndefault:\r\nrc = -EINVAL;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nSET_FIELD(p_ramrod->flags1,\r\nRDMA_REGISTER_TID_RAMROD_DATA_TID_TYPE, tid_type);\r\np_ramrod->itid = cpu_to_le32(params->itid);\r\np_ramrod->key = params->key;\r\np_ramrod->pd = cpu_to_le16(params->pd);\r\np_ramrod->length_hi = (u8)(params->length >> 32);\r\np_ramrod->length_lo = DMA_LO_LE(params->length);\r\nif (params->zbva) {\r\np_ramrod->va.hi = 0;\r\np_ramrod->va.lo = cpu_to_le32(params->fbo);\r\n} else {\r\nDMA_REGPAIR_LE(p_ramrod->va, params->vaddr);\r\n}\r\nDMA_REGPAIR_LE(p_ramrod->pbl_base, params->pbl_ptr);\r\nif (params->dif_enabled) {\r\nSET_FIELD(p_ramrod->flags2,\r\nRDMA_REGISTER_TID_RAMROD_DATA_DIF_ON_HOST_FLG, 1);\r\nDMA_REGPAIR_LE(p_ramrod->dif_error_addr,\r\nparams->dif_error_addr);\r\nDMA_REGPAIR_LE(p_ramrod->dif_runt_addr, params->dif_runt_addr);\r\n}\r\nrc = qed_spq_post(p_hwfn, p_ent, &fw_return_code);\r\nif (rc)\r\nreturn rc;\r\nif (fw_return_code != RDMA_RETURN_OK) {\r\nDP_NOTICE(p_hwfn, "fw_return_code = %d\n", fw_return_code);\r\nreturn -EINVAL;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Register TID, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int qed_rdma_deregister_tid(void *rdma_cxt, u32 itid)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct rdma_deregister_tid_ramrod_data *p_ramrod;\r\nstruct qed_sp_init_data init_data;\r\nstruct qed_spq_entry *p_ent;\r\nstruct qed_ptt *p_ptt;\r\nu8 fw_return_code;\r\nint rc;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "itid = %08x\n", itid);\r\nmemset(&init_data, 0, sizeof(init_data));\r\ninit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\r\ninit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\r\nrc = qed_sp_init_request(p_hwfn, &p_ent, RDMA_RAMROD_DEREGISTER_MR,\r\np_hwfn->p_rdma_info->proto, &init_data);\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "rc = %d\n", rc);\r\nreturn rc;\r\n}\r\np_ramrod = &p_ent->ramrod.rdma_deregister_tid;\r\np_ramrod->itid = cpu_to_le32(itid);\r\nrc = qed_spq_post(p_hwfn, p_ent, &fw_return_code);\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nif (fw_return_code == RDMA_RETURN_DEREGISTER_MR_BAD_STATE_ERR) {\r\nDP_NOTICE(p_hwfn, "fw_return_code = %d\n", fw_return_code);\r\nreturn -EINVAL;\r\n} else if (fw_return_code == RDMA_RETURN_NIG_DRAIN_REQ) {\r\np_ptt = qed_ptt_acquire(p_hwfn);\r\nif (!p_ptt) {\r\nrc = -EBUSY;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to acquire PTT\n");\r\nreturn rc;\r\n}\r\nrc = qed_mcp_drain(p_hwfn, p_ptt);\r\nif (rc) {\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Drain failed\n");\r\nreturn rc;\r\n}\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nrc = qed_sp_init_request(p_hwfn, &p_ent,\r\nRDMA_RAMROD_DEREGISTER_MR,\r\np_hwfn->p_rdma_info->proto,\r\n&init_data);\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Failed to init sp-element\n");\r\nreturn rc;\r\n}\r\nrc = qed_spq_post(p_hwfn, p_ent, &fw_return_code);\r\nif (rc) {\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"Ramrod failed\n");\r\nreturn rc;\r\n}\r\nif (fw_return_code != RDMA_RETURN_OK) {\r\nDP_NOTICE(p_hwfn, "fw_return_code = %d\n",\r\nfw_return_code);\r\nreturn rc;\r\n}\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "De-registered TID, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic void *qed_rdma_get_rdma_ctx(struct qed_dev *cdev)\r\n{\r\nreturn QED_LEADING_HWFN(cdev);\r\n}\r\nbool qed_rdma_allocated_qps(struct qed_hwfn *p_hwfn)\r\n{\r\nbool result;\r\nif (!p_hwfn->p_rdma_info)\r\nreturn false;\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nif (!p_hwfn->p_rdma_info->cid_map.bitmap)\r\nresult = false;\r\nelse\r\nresult = !qed_bmap_is_empty(&p_hwfn->p_rdma_info->cid_map);\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\nreturn result;\r\n}\r\nvoid qed_rdma_dpm_conf(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\r\n{\r\nu32 val;\r\nval = (p_hwfn->dcbx_no_edpm || p_hwfn->db_bar_no_edpm) ? 0 : 1;\r\nqed_wr(p_hwfn, p_ptt, DORQ_REG_PF_DPM_ENABLE, val);\r\nDP_VERBOSE(p_hwfn, (QED_MSG_DCB | QED_MSG_RDMA),\r\n"Changing DPM_EN state to %d (DCBX=%d, DB_BAR=%d)\n",\r\nval, p_hwfn->dcbx_no_edpm, p_hwfn->db_bar_no_edpm);\r\n}\r\nvoid qed_rdma_dpm_bar(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\r\n{\r\np_hwfn->db_bar_no_edpm = true;\r\nqed_rdma_dpm_conf(p_hwfn, p_ptt);\r\n}\r\nstatic int qed_rdma_start(void *rdma_cxt,\r\nstruct qed_rdma_start_in_params *params)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nstruct qed_ptt *p_ptt;\r\nint rc = -EBUSY;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA,\r\n"desired_cnq = %08x\n", params->desired_cnq);\r\np_ptt = qed_ptt_acquire(p_hwfn);\r\nif (!p_ptt)\r\ngoto err;\r\nrc = qed_rdma_alloc(p_hwfn, p_ptt, params);\r\nif (rc)\r\ngoto err1;\r\nrc = qed_rdma_setup(p_hwfn, p_ptt, params);\r\nif (rc)\r\ngoto err2;\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nreturn rc;\r\nerr2:\r\nqed_rdma_free(p_hwfn);\r\nerr1:\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nerr:\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "RDMA start - error, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int qed_rdma_init(struct qed_dev *cdev,\r\nstruct qed_rdma_start_in_params *params)\r\n{\r\nreturn qed_rdma_start(QED_LEADING_HWFN(cdev), params);\r\n}\r\nstatic void qed_rdma_remove_user(void *rdma_cxt, u16 dpi)\r\n{\r\nstruct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;\r\nDP_VERBOSE(p_hwfn, QED_MSG_RDMA, "dpi = %08x\n", dpi);\r\nspin_lock_bh(&p_hwfn->p_rdma_info->lock);\r\nqed_bmap_release_id(p_hwfn, &p_hwfn->p_rdma_info->dpi_map, dpi);\r\nspin_unlock_bh(&p_hwfn->p_rdma_info->lock);\r\n}\r\nstatic int qed_roce_ll2_set_mac_filter(struct qed_dev *cdev,\r\nu8 *old_mac_address,\r\nu8 *new_mac_address)\r\n{\r\nstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\r\nstruct qed_ptt *p_ptt;\r\nint rc = 0;\r\np_ptt = qed_ptt_acquire(p_hwfn);\r\nif (!p_ptt) {\r\nDP_ERR(cdev,\r\n"qed roce ll2 mac filter set: failed to acquire PTT\n");\r\nreturn -EINVAL;\r\n}\r\nif (old_mac_address)\r\nqed_llh_remove_mac_filter(p_hwfn, p_ptt, old_mac_address);\r\nif (new_mac_address)\r\nrc = qed_llh_add_mac_filter(p_hwfn, p_ptt, new_mac_address);\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nif (rc)\r\nDP_ERR(cdev,\r\n"qed roce ll2 mac filter set: failed to add MAC filter\n");\r\nreturn rc;\r\n}\r\nconst struct qed_rdma_ops *qed_get_rdma_ops(void)\r\n{\r\nreturn &qed_rdma_ops_pass;\r\n}
