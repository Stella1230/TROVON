static inline size_t bcm2835_dma_max_frame_length(struct bcm2835_chan *c)\r\n{\r\nreturn c->is_lite_channel ? MAX_LITE_DMA_LEN : MAX_DMA_LEN;\r\n}\r\nstatic inline size_t bcm2835_dma_frames_for_length(size_t len,\r\nsize_t max_len)\r\n{\r\nreturn DIV_ROUND_UP(len, max_len);\r\n}\r\nstatic inline struct bcm2835_dmadev *to_bcm2835_dma_dev(struct dma_device *d)\r\n{\r\nreturn container_of(d, struct bcm2835_dmadev, ddev);\r\n}\r\nstatic inline struct bcm2835_chan *to_bcm2835_dma_chan(struct dma_chan *c)\r\n{\r\nreturn container_of(c, struct bcm2835_chan, vc.chan);\r\n}\r\nstatic inline struct bcm2835_desc *to_bcm2835_dma_desc(\r\nstruct dma_async_tx_descriptor *t)\r\n{\r\nreturn container_of(t, struct bcm2835_desc, vd.tx);\r\n}\r\nstatic void bcm2835_dma_free_cb_chain(struct bcm2835_desc *desc)\r\n{\r\nsize_t i;\r\nfor (i = 0; i < desc->frames; i++)\r\ndma_pool_free(desc->c->cb_pool, desc->cb_list[i].cb,\r\ndesc->cb_list[i].paddr);\r\nkfree(desc);\r\n}\r\nstatic void bcm2835_dma_desc_free(struct virt_dma_desc *vd)\r\n{\r\nbcm2835_dma_free_cb_chain(\r\ncontainer_of(vd, struct bcm2835_desc, vd));\r\n}\r\nstatic void bcm2835_dma_create_cb_set_length(\r\nstruct bcm2835_chan *chan,\r\nstruct bcm2835_dma_cb *control_block,\r\nsize_t len,\r\nsize_t period_len,\r\nsize_t *total_len,\r\nu32 finalextrainfo)\r\n{\r\nsize_t max_len = bcm2835_dma_max_frame_length(chan);\r\ncontrol_block->length = min_t(u32, len, max_len);\r\nif (!period_len)\r\nreturn;\r\nif (*total_len + control_block->length < period_len) {\r\n*total_len += control_block->length;\r\nreturn;\r\n}\r\ncontrol_block->length = period_len - *total_len;\r\n*total_len = 0;\r\ncontrol_block->info |= finalextrainfo;\r\n}\r\nstatic inline size_t bcm2835_dma_count_frames_for_sg(\r\nstruct bcm2835_chan *c,\r\nstruct scatterlist *sgl,\r\nunsigned int sg_len)\r\n{\r\nsize_t frames = 0;\r\nstruct scatterlist *sgent;\r\nunsigned int i;\r\nsize_t plength = bcm2835_dma_max_frame_length(c);\r\nfor_each_sg(sgl, sgent, sg_len, i)\r\nframes += bcm2835_dma_frames_for_length(\r\nsg_dma_len(sgent), plength);\r\nreturn frames;\r\n}\r\nstatic struct bcm2835_desc *bcm2835_dma_create_cb_chain(\r\nstruct dma_chan *chan, enum dma_transfer_direction direction,\r\nbool cyclic, u32 info, u32 finalextrainfo, size_t frames,\r\ndma_addr_t src, dma_addr_t dst, size_t buf_len,\r\nsize_t period_len, gfp_t gfp)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nsize_t len = buf_len, total_len;\r\nsize_t frame;\r\nstruct bcm2835_desc *d;\r\nstruct bcm2835_cb_entry *cb_entry;\r\nstruct bcm2835_dma_cb *control_block;\r\nif (!frames)\r\nreturn NULL;\r\nd = kzalloc(sizeof(*d) + frames * sizeof(struct bcm2835_cb_entry),\r\ngfp);\r\nif (!d)\r\nreturn NULL;\r\nd->c = c;\r\nd->dir = direction;\r\nd->cyclic = cyclic;\r\nfor (frame = 0, total_len = 0; frame < frames; d->frames++, frame++) {\r\ncb_entry = &d->cb_list[frame];\r\ncb_entry->cb = dma_pool_alloc(c->cb_pool, gfp,\r\n&cb_entry->paddr);\r\nif (!cb_entry->cb)\r\ngoto error_cb;\r\ncontrol_block = cb_entry->cb;\r\ncontrol_block->info = info;\r\ncontrol_block->src = src;\r\ncontrol_block->dst = dst;\r\ncontrol_block->stride = 0;\r\ncontrol_block->next = 0;\r\nif (buf_len) {\r\nbcm2835_dma_create_cb_set_length(\r\nc, control_block,\r\nlen, period_len, &total_len,\r\ncyclic ? finalextrainfo : 0);\r\nlen -= control_block->length;\r\n}\r\nif (frame)\r\nd->cb_list[frame - 1].cb->next = cb_entry->paddr;\r\nif (src && (info & BCM2835_DMA_S_INC))\r\nsrc += control_block->length;\r\nif (dst && (info & BCM2835_DMA_D_INC))\r\ndst += control_block->length;\r\nd->size += control_block->length;\r\n}\r\nd->cb_list[d->frames - 1].cb->info |= finalextrainfo;\r\nif (buf_len && (d->size != buf_len))\r\ngoto error_cb;\r\nreturn d;\r\nerror_cb:\r\nbcm2835_dma_free_cb_chain(d);\r\nreturn NULL;\r\n}\r\nstatic void bcm2835_dma_fill_cb_chain_with_sg(\r\nstruct dma_chan *chan,\r\nenum dma_transfer_direction direction,\r\nstruct bcm2835_cb_entry *cb,\r\nstruct scatterlist *sgl,\r\nunsigned int sg_len)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nsize_t len, max_len;\r\nunsigned int i;\r\ndma_addr_t addr;\r\nstruct scatterlist *sgent;\r\nmax_len = bcm2835_dma_max_frame_length(c);\r\nfor_each_sg(sgl, sgent, sg_len, i) {\r\nfor (addr = sg_dma_address(sgent), len = sg_dma_len(sgent);\r\nlen > 0;\r\naddr += cb->cb->length, len -= cb->cb->length, cb++) {\r\nif (direction == DMA_DEV_TO_MEM)\r\ncb->cb->dst = addr;\r\nelse\r\ncb->cb->src = addr;\r\ncb->cb->length = min(len, max_len);\r\n}\r\n}\r\n}\r\nstatic int bcm2835_dma_abort(void __iomem *chan_base)\r\n{\r\nunsigned long cs;\r\nlong int timeout = 10000;\r\ncs = readl(chan_base + BCM2835_DMA_CS);\r\nif (!(cs & BCM2835_DMA_ACTIVE))\r\nreturn 0;\r\nwritel(0, chan_base + BCM2835_DMA_CS);\r\nwhile ((cs & BCM2835_DMA_ISPAUSED) && --timeout) {\r\ncpu_relax();\r\ncs = readl(chan_base + BCM2835_DMA_CS);\r\n}\r\nif (!timeout)\r\nreturn -ETIMEDOUT;\r\nif (!(cs & BCM2835_DMA_ACTIVE))\r\nreturn 0;\r\nwritel(0, chan_base + BCM2835_DMA_NEXTCB);\r\nwritel(BCM2835_DMA_ABORT | BCM2835_DMA_ACTIVE,\r\nchan_base + BCM2835_DMA_CS);\r\nreturn 0;\r\n}\r\nstatic void bcm2835_dma_start_desc(struct bcm2835_chan *c)\r\n{\r\nstruct virt_dma_desc *vd = vchan_next_desc(&c->vc);\r\nstruct bcm2835_desc *d;\r\nif (!vd) {\r\nc->desc = NULL;\r\nreturn;\r\n}\r\nlist_del(&vd->node);\r\nc->desc = d = to_bcm2835_dma_desc(&vd->tx);\r\nwritel(d->cb_list[0].paddr, c->chan_base + BCM2835_DMA_ADDR);\r\nwritel(BCM2835_DMA_ACTIVE, c->chan_base + BCM2835_DMA_CS);\r\n}\r\nstatic irqreturn_t bcm2835_dma_callback(int irq, void *data)\r\n{\r\nstruct bcm2835_chan *c = data;\r\nstruct bcm2835_desc *d;\r\nunsigned long flags;\r\nif (c->irq_flags & IRQF_SHARED) {\r\nflags = readl(c->chan_base + BCM2835_DMA_CS);\r\nif (!(flags & BCM2835_DMA_INT))\r\nreturn IRQ_NONE;\r\n}\r\nspin_lock_irqsave(&c->vc.lock, flags);\r\nwritel(BCM2835_DMA_INT, c->chan_base + BCM2835_DMA_CS);\r\nd = c->desc;\r\nif (d) {\r\nif (d->cyclic) {\r\nvchan_cyclic_callback(&d->vd);\r\nwritel(BCM2835_DMA_ACTIVE,\r\nc->chan_base + BCM2835_DMA_CS);\r\n} else {\r\nvchan_cookie_complete(&c->desc->vd);\r\nbcm2835_dma_start_desc(c);\r\n}\r\n}\r\nspin_unlock_irqrestore(&c->vc.lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int bcm2835_dma_alloc_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nstruct device *dev = c->vc.chan.device->dev;\r\ndev_dbg(dev, "Allocating DMA channel %d\n", c->ch);\r\nc->cb_pool = dma_pool_create(dev_name(dev), dev,\r\nsizeof(struct bcm2835_dma_cb), 0, 0);\r\nif (!c->cb_pool) {\r\ndev_err(dev, "unable to allocate descriptor pool\n");\r\nreturn -ENOMEM;\r\n}\r\nreturn request_irq(c->irq_number, bcm2835_dma_callback,\r\nc->irq_flags, "DMA IRQ", c);\r\n}\r\nstatic void bcm2835_dma_free_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nvchan_free_chan_resources(&c->vc);\r\nfree_irq(c->irq_number, c);\r\ndma_pool_destroy(c->cb_pool);\r\ndev_dbg(c->vc.chan.device->dev, "Freeing DMA channel %u\n", c->ch);\r\n}\r\nstatic size_t bcm2835_dma_desc_size(struct bcm2835_desc *d)\r\n{\r\nreturn d->size;\r\n}\r\nstatic size_t bcm2835_dma_desc_size_pos(struct bcm2835_desc *d, dma_addr_t addr)\r\n{\r\nunsigned int i;\r\nsize_t size;\r\nfor (size = i = 0; i < d->frames; i++) {\r\nstruct bcm2835_dma_cb *control_block = d->cb_list[i].cb;\r\nsize_t this_size = control_block->length;\r\ndma_addr_t dma;\r\nif (d->dir == DMA_DEV_TO_MEM)\r\ndma = control_block->dst;\r\nelse\r\ndma = control_block->src;\r\nif (size)\r\nsize += this_size;\r\nelse if (addr >= dma && addr < dma + this_size)\r\nsize += dma + this_size - addr;\r\n}\r\nreturn size;\r\n}\r\nstatic enum dma_status bcm2835_dma_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie, struct dma_tx_state *txstate)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nstruct virt_dma_desc *vd;\r\nenum dma_status ret;\r\nunsigned long flags;\r\nret = dma_cookie_status(chan, cookie, txstate);\r\nif (ret == DMA_COMPLETE || !txstate)\r\nreturn ret;\r\nspin_lock_irqsave(&c->vc.lock, flags);\r\nvd = vchan_find_desc(&c->vc, cookie);\r\nif (vd) {\r\ntxstate->residue =\r\nbcm2835_dma_desc_size(to_bcm2835_dma_desc(&vd->tx));\r\n} else if (c->desc && c->desc->vd.tx.cookie == cookie) {\r\nstruct bcm2835_desc *d = c->desc;\r\ndma_addr_t pos;\r\nif (d->dir == DMA_MEM_TO_DEV)\r\npos = readl(c->chan_base + BCM2835_DMA_SOURCE_AD);\r\nelse if (d->dir == DMA_DEV_TO_MEM)\r\npos = readl(c->chan_base + BCM2835_DMA_DEST_AD);\r\nelse\r\npos = 0;\r\ntxstate->residue = bcm2835_dma_desc_size_pos(d, pos);\r\n} else {\r\ntxstate->residue = 0;\r\n}\r\nspin_unlock_irqrestore(&c->vc.lock, flags);\r\nreturn ret;\r\n}\r\nstatic void bcm2835_dma_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&c->vc.lock, flags);\r\nif (vchan_issue_pending(&c->vc) && !c->desc)\r\nbcm2835_dma_start_desc(c);\r\nspin_unlock_irqrestore(&c->vc.lock, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *bcm2835_dma_prep_dma_memcpy(\r\nstruct dma_chan *chan, dma_addr_t dst, dma_addr_t src,\r\nsize_t len, unsigned long flags)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nstruct bcm2835_desc *d;\r\nu32 info = BCM2835_DMA_D_INC | BCM2835_DMA_S_INC;\r\nu32 extra = BCM2835_DMA_INT_EN | BCM2835_DMA_WAIT_RESP;\r\nsize_t max_len = bcm2835_dma_max_frame_length(c);\r\nsize_t frames;\r\nif (!src || !dst || !len)\r\nreturn NULL;\r\nframes = bcm2835_dma_frames_for_length(len, max_len);\r\nd = bcm2835_dma_create_cb_chain(chan, DMA_MEM_TO_MEM, false,\r\ninfo, extra, frames,\r\nsrc, dst, len, 0, GFP_KERNEL);\r\nif (!d)\r\nreturn NULL;\r\nreturn vchan_tx_prep(&c->vc, &d->vd, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *bcm2835_dma_prep_slave_sg(\r\nstruct dma_chan *chan,\r\nstruct scatterlist *sgl, unsigned int sg_len,\r\nenum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nstruct bcm2835_desc *d;\r\ndma_addr_t src = 0, dst = 0;\r\nu32 info = BCM2835_DMA_WAIT_RESP;\r\nu32 extra = BCM2835_DMA_INT_EN;\r\nsize_t frames;\r\nif (!is_slave_direction(direction)) {\r\ndev_err(chan->device->dev,\r\n"%s: bad direction?\n", __func__);\r\nreturn NULL;\r\n}\r\nif (c->dreq != 0)\r\ninfo |= BCM2835_DMA_PER_MAP(c->dreq);\r\nif (direction == DMA_DEV_TO_MEM) {\r\nif (c->cfg.src_addr_width != DMA_SLAVE_BUSWIDTH_4_BYTES)\r\nreturn NULL;\r\nsrc = c->cfg.src_addr;\r\ninfo |= BCM2835_DMA_S_DREQ | BCM2835_DMA_D_INC;\r\n} else {\r\nif (c->cfg.dst_addr_width != DMA_SLAVE_BUSWIDTH_4_BYTES)\r\nreturn NULL;\r\ndst = c->cfg.dst_addr;\r\ninfo |= BCM2835_DMA_D_DREQ | BCM2835_DMA_S_INC;\r\n}\r\nframes = bcm2835_dma_count_frames_for_sg(c, sgl, sg_len);\r\nd = bcm2835_dma_create_cb_chain(chan, direction, false,\r\ninfo, extra,\r\nframes, src, dst, 0, 0,\r\nGFP_KERNEL);\r\nif (!d)\r\nreturn NULL;\r\nbcm2835_dma_fill_cb_chain_with_sg(chan, direction, d->cb_list,\r\nsgl, sg_len);\r\nreturn vchan_tx_prep(&c->vc, &d->vd, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *bcm2835_dma_prep_dma_cyclic(\r\nstruct dma_chan *chan, dma_addr_t buf_addr, size_t buf_len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nstruct bcm2835_desc *d;\r\ndma_addr_t src, dst;\r\nu32 info = BCM2835_DMA_WAIT_RESP;\r\nu32 extra = BCM2835_DMA_INT_EN;\r\nsize_t max_len = bcm2835_dma_max_frame_length(c);\r\nsize_t frames;\r\nif (!is_slave_direction(direction)) {\r\ndev_err(chan->device->dev, "%s: bad direction?\n", __func__);\r\nreturn NULL;\r\n}\r\nif (!buf_len) {\r\ndev_err(chan->device->dev,\r\n"%s: bad buffer length (= 0)\n", __func__);\r\nreturn NULL;\r\n}\r\nif (buf_len % period_len)\r\ndev_warn_once(chan->device->dev,\r\n"%s: buffer_length (%zd) is not a multiple of period_len (%zd)\n",\r\n__func__, buf_len, period_len);\r\nif (c->dreq != 0)\r\ninfo |= BCM2835_DMA_PER_MAP(c->dreq);\r\nif (direction == DMA_DEV_TO_MEM) {\r\nif (c->cfg.src_addr_width != DMA_SLAVE_BUSWIDTH_4_BYTES)\r\nreturn NULL;\r\nsrc = c->cfg.src_addr;\r\ndst = buf_addr;\r\ninfo |= BCM2835_DMA_S_DREQ | BCM2835_DMA_D_INC;\r\n} else {\r\nif (c->cfg.dst_addr_width != DMA_SLAVE_BUSWIDTH_4_BYTES)\r\nreturn NULL;\r\ndst = c->cfg.dst_addr;\r\nsrc = buf_addr;\r\ninfo |= BCM2835_DMA_D_DREQ | BCM2835_DMA_S_INC;\r\n}\r\nframes =\r\nDIV_ROUND_UP(buf_len, period_len) *\r\nbcm2835_dma_frames_for_length(period_len, max_len);\r\nd = bcm2835_dma_create_cb_chain(chan, direction, true,\r\ninfo, extra,\r\nframes, src, dst, buf_len,\r\nperiod_len, GFP_NOWAIT);\r\nif (!d)\r\nreturn NULL;\r\nd->cb_list[d->frames - 1].cb->next = d->cb_list[0].paddr;\r\nreturn vchan_tx_prep(&c->vc, &d->vd, flags);\r\n}\r\nstatic int bcm2835_dma_slave_config(struct dma_chan *chan,\r\nstruct dma_slave_config *cfg)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nif ((cfg->direction == DMA_DEV_TO_MEM &&\r\ncfg->src_addr_width != DMA_SLAVE_BUSWIDTH_4_BYTES) ||\r\n(cfg->direction == DMA_MEM_TO_DEV &&\r\ncfg->dst_addr_width != DMA_SLAVE_BUSWIDTH_4_BYTES) ||\r\n!is_slave_direction(cfg->direction)) {\r\nreturn -EINVAL;\r\n}\r\nc->cfg = *cfg;\r\nreturn 0;\r\n}\r\nstatic int bcm2835_dma_terminate_all(struct dma_chan *chan)\r\n{\r\nstruct bcm2835_chan *c = to_bcm2835_dma_chan(chan);\r\nstruct bcm2835_dmadev *d = to_bcm2835_dma_dev(c->vc.chan.device);\r\nunsigned long flags;\r\nint timeout = 10000;\r\nLIST_HEAD(head);\r\nspin_lock_irqsave(&c->vc.lock, flags);\r\nspin_lock(&d->lock);\r\nlist_del_init(&c->node);\r\nspin_unlock(&d->lock);\r\nif (c->desc) {\r\nbcm2835_dma_desc_free(&c->desc->vd);\r\nc->desc = NULL;\r\nbcm2835_dma_abort(c->chan_base);\r\nwhile (--timeout) {\r\nif (!(readl(c->chan_base + BCM2835_DMA_CS) &\r\nBCM2835_DMA_ACTIVE))\r\nbreak;\r\ncpu_relax();\r\n}\r\nif (!timeout)\r\ndev_err(d->ddev.dev, "DMA transfer could not be terminated\n");\r\n}\r\nvchan_get_all_descriptors(&c->vc, &head);\r\nspin_unlock_irqrestore(&c->vc.lock, flags);\r\nvchan_dma_desc_free_list(&c->vc, &head);\r\nreturn 0;\r\n}\r\nstatic int bcm2835_dma_chan_init(struct bcm2835_dmadev *d, int chan_id,\r\nint irq, unsigned int irq_flags)\r\n{\r\nstruct bcm2835_chan *c;\r\nc = devm_kzalloc(d->ddev.dev, sizeof(*c), GFP_KERNEL);\r\nif (!c)\r\nreturn -ENOMEM;\r\nc->vc.desc_free = bcm2835_dma_desc_free;\r\nvchan_init(&c->vc, &d->ddev);\r\nINIT_LIST_HEAD(&c->node);\r\nc->chan_base = BCM2835_DMA_CHANIO(d->base, chan_id);\r\nc->ch = chan_id;\r\nc->irq_number = irq;\r\nc->irq_flags = irq_flags;\r\nif (readl(c->chan_base + BCM2835_DMA_DEBUG) &\r\nBCM2835_DMA_DEBUG_LITE)\r\nc->is_lite_channel = true;\r\nreturn 0;\r\n}\r\nstatic void bcm2835_dma_free(struct bcm2835_dmadev *od)\r\n{\r\nstruct bcm2835_chan *c, *next;\r\nlist_for_each_entry_safe(c, next, &od->ddev.channels,\r\nvc.chan.device_node) {\r\nlist_del(&c->vc.chan.device_node);\r\ntasklet_kill(&c->vc.task);\r\n}\r\n}\r\nstatic struct dma_chan *bcm2835_dma_xlate(struct of_phandle_args *spec,\r\nstruct of_dma *ofdma)\r\n{\r\nstruct bcm2835_dmadev *d = ofdma->of_dma_data;\r\nstruct dma_chan *chan;\r\nchan = dma_get_any_slave_channel(&d->ddev);\r\nif (!chan)\r\nreturn NULL;\r\nto_bcm2835_dma_chan(chan)->dreq = spec->args[0];\r\nreturn chan;\r\n}\r\nstatic int bcm2835_dma_probe(struct platform_device *pdev)\r\n{\r\nstruct bcm2835_dmadev *od;\r\nstruct resource *res;\r\nvoid __iomem *base;\r\nint rc;\r\nint i, j;\r\nint irq[BCM2835_DMA_MAX_DMA_CHAN_SUPPORTED + 1];\r\nint irq_flags;\r\nuint32_t chans_available;\r\nchar chan_name[BCM2835_DMA_CHAN_NAME_SIZE];\r\nif (!pdev->dev.dma_mask)\r\npdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;\r\nrc = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\r\nif (rc)\r\nreturn rc;\r\nod = devm_kzalloc(&pdev->dev, sizeof(*od), GFP_KERNEL);\r\nif (!od)\r\nreturn -ENOMEM;\r\npdev->dev.dma_parms = &od->dma_parms;\r\ndma_set_max_seg_size(&pdev->dev, 0x3FFFFFFF);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nbase = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(base))\r\nreturn PTR_ERR(base);\r\nod->base = base;\r\ndma_cap_set(DMA_SLAVE, od->ddev.cap_mask);\r\ndma_cap_set(DMA_PRIVATE, od->ddev.cap_mask);\r\ndma_cap_set(DMA_CYCLIC, od->ddev.cap_mask);\r\ndma_cap_set(DMA_SLAVE, od->ddev.cap_mask);\r\ndma_cap_set(DMA_MEMCPY, od->ddev.cap_mask);\r\nod->ddev.device_alloc_chan_resources = bcm2835_dma_alloc_chan_resources;\r\nod->ddev.device_free_chan_resources = bcm2835_dma_free_chan_resources;\r\nod->ddev.device_tx_status = bcm2835_dma_tx_status;\r\nod->ddev.device_issue_pending = bcm2835_dma_issue_pending;\r\nod->ddev.device_prep_dma_cyclic = bcm2835_dma_prep_dma_cyclic;\r\nod->ddev.device_prep_slave_sg = bcm2835_dma_prep_slave_sg;\r\nod->ddev.device_prep_dma_memcpy = bcm2835_dma_prep_dma_memcpy;\r\nod->ddev.device_config = bcm2835_dma_slave_config;\r\nod->ddev.device_terminate_all = bcm2835_dma_terminate_all;\r\nod->ddev.src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\nod->ddev.dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\nod->ddev.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV) |\r\nBIT(DMA_MEM_TO_MEM);\r\nod->ddev.residue_granularity = DMA_RESIDUE_GRANULARITY_BURST;\r\nod->ddev.dev = &pdev->dev;\r\nINIT_LIST_HEAD(&od->ddev.channels);\r\nspin_lock_init(&od->lock);\r\nplatform_set_drvdata(pdev, od);\r\nif (of_property_read_u32(pdev->dev.of_node,\r\n"brcm,dma-channel-mask",\r\n&chans_available)) {\r\ndev_err(&pdev->dev, "Failed to get channel mask\n");\r\nrc = -EINVAL;\r\ngoto err_no_dma;\r\n}\r\nfor (i = 0; i <= BCM2835_DMA_MAX_DMA_CHAN_SUPPORTED; i++) {\r\nif (!(chans_available & (1 << i))) {\r\nirq[i] = -1;\r\ncontinue;\r\n}\r\nsnprintf(chan_name, sizeof(chan_name), "dma%i", i);\r\nirq[i] = platform_get_irq_byname(pdev, chan_name);\r\nif (irq[i] >= 0)\r\ncontinue;\r\ndev_warn_once(&pdev->dev,\r\n"missing interrupt-names property in device tree - legacy interpretation is used\n");\r\nirq[i] = platform_get_irq(pdev, i < 11 ? i : 11);\r\n}\r\nfor (i = 0; i <= BCM2835_DMA_MAX_DMA_CHAN_SUPPORTED; i++) {\r\nif (irq[i] < 0)\r\ncontinue;\r\nirq_flags = 0;\r\nfor (j = 0; j <= BCM2835_DMA_MAX_DMA_CHAN_SUPPORTED; j++)\r\nif ((i != j) && (irq[j] == irq[i])) {\r\nirq_flags = IRQF_SHARED;\r\nbreak;\r\n}\r\nrc = bcm2835_dma_chan_init(od, i, irq[i], irq_flags);\r\nif (rc)\r\ngoto err_no_dma;\r\n}\r\ndev_dbg(&pdev->dev, "Initialized %i DMA channels\n", i);\r\nrc = of_dma_controller_register(pdev->dev.of_node,\r\nbcm2835_dma_xlate, od);\r\nif (rc) {\r\ndev_err(&pdev->dev, "Failed to register DMA controller\n");\r\ngoto err_no_dma;\r\n}\r\nrc = dma_async_device_register(&od->ddev);\r\nif (rc) {\r\ndev_err(&pdev->dev,\r\n"Failed to register slave DMA engine device: %d\n", rc);\r\ngoto err_no_dma;\r\n}\r\ndev_dbg(&pdev->dev, "Load BCM2835 DMA engine driver\n");\r\nreturn 0;\r\nerr_no_dma:\r\nbcm2835_dma_free(od);\r\nreturn rc;\r\n}\r\nstatic int bcm2835_dma_remove(struct platform_device *pdev)\r\n{\r\nstruct bcm2835_dmadev *od = platform_get_drvdata(pdev);\r\ndma_async_device_unregister(&od->ddev);\r\nbcm2835_dma_free(od);\r\nreturn 0;\r\n}
