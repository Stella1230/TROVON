static inline const\r\nstruct regmap_irq *irq_to_regmap_irq(struct regmap_irq_chip_data *data,\r\nint irq)\r\n{\r\nreturn &data->chip->irqs[irq];\r\n}\r\nstatic void regmap_irq_lock(struct irq_data *data)\r\n{\r\nstruct regmap_irq_chip_data *d = irq_data_get_irq_chip_data(data);\r\nmutex_lock(&d->lock);\r\n}\r\nstatic int regmap_irq_update_bits(struct regmap_irq_chip_data *d,\r\nunsigned int reg, unsigned int mask,\r\nunsigned int val)\r\n{\r\nif (d->chip->mask_writeonly)\r\nreturn regmap_write_bits(d->map, reg, mask, val);\r\nelse\r\nreturn regmap_update_bits(d->map, reg, mask, val);\r\n}\r\nstatic void regmap_irq_sync_unlock(struct irq_data *data)\r\n{\r\nstruct regmap_irq_chip_data *d = irq_data_get_irq_chip_data(data);\r\nstruct regmap *map = d->map;\r\nint i, ret;\r\nu32 reg;\r\nu32 unmask_offset;\r\nif (d->chip->runtime_pm) {\r\nret = pm_runtime_get_sync(map->dev);\r\nif (ret < 0)\r\ndev_err(map->dev, "IRQ sync failed to resume: %d\n",\r\nret);\r\n}\r\nfor (i = 0; i < d->chip->num_regs; i++) {\r\nreg = d->chip->mask_base +\r\n(i * map->reg_stride * d->irq_reg_stride);\r\nif (d->chip->mask_invert) {\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf_def[i], ~d->mask_buf[i]);\r\n} else if (d->chip->unmask_base) {\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf_def[i], ~d->mask_buf[i]);\r\nif (ret < 0)\r\ndev_err(d->map->dev,\r\n"Failed to sync unmasks in %x\n",\r\nreg);\r\nunmask_offset = d->chip->unmask_base -\r\nd->chip->mask_base;\r\nret = regmap_irq_update_bits(d,\r\nreg + unmask_offset,\r\nd->mask_buf_def[i],\r\nd->mask_buf[i]);\r\n} else {\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf_def[i], d->mask_buf[i]);\r\n}\r\nif (ret != 0)\r\ndev_err(d->map->dev, "Failed to sync masks in %x\n",\r\nreg);\r\nreg = d->chip->wake_base +\r\n(i * map->reg_stride * d->irq_reg_stride);\r\nif (d->wake_buf) {\r\nif (d->chip->wake_invert)\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf_def[i],\r\n~d->wake_buf[i]);\r\nelse\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf_def[i],\r\nd->wake_buf[i]);\r\nif (ret != 0)\r\ndev_err(d->map->dev,\r\n"Failed to sync wakes in %x: %d\n",\r\nreg, ret);\r\n}\r\nif (!d->chip->init_ack_masked)\r\ncontinue;\r\nif (d->mask_buf[i] && (d->chip->ack_base || d->chip->use_ack)) {\r\nreg = d->chip->ack_base +\r\n(i * map->reg_stride * d->irq_reg_stride);\r\nif (d->chip->ack_invert)\r\nret = regmap_write(map, reg, ~d->mask_buf[i]);\r\nelse\r\nret = regmap_write(map, reg, d->mask_buf[i]);\r\nif (ret != 0)\r\ndev_err(d->map->dev, "Failed to ack 0x%x: %d\n",\r\nreg, ret);\r\n}\r\n}\r\nfor (i = 0; i < d->chip->num_type_reg; i++) {\r\nif (!d->type_buf_def[i])\r\ncontinue;\r\nreg = d->chip->type_base +\r\n(i * map->reg_stride * d->type_reg_stride);\r\nif (d->chip->type_invert)\r\nret = regmap_irq_update_bits(d, reg,\r\nd->type_buf_def[i], ~d->type_buf[i]);\r\nelse\r\nret = regmap_irq_update_bits(d, reg,\r\nd->type_buf_def[i], d->type_buf[i]);\r\nif (ret != 0)\r\ndev_err(d->map->dev, "Failed to sync type in %x\n",\r\nreg);\r\n}\r\nif (d->chip->runtime_pm)\r\npm_runtime_put(map->dev);\r\nif (d->wake_count < 0)\r\nfor (i = d->wake_count; i < 0; i++)\r\nirq_set_irq_wake(d->irq, 0);\r\nelse if (d->wake_count > 0)\r\nfor (i = 0; i < d->wake_count; i++)\r\nirq_set_irq_wake(d->irq, 1);\r\nd->wake_count = 0;\r\nmutex_unlock(&d->lock);\r\n}\r\nstatic void regmap_irq_enable(struct irq_data *data)\r\n{\r\nstruct regmap_irq_chip_data *d = irq_data_get_irq_chip_data(data);\r\nstruct regmap *map = d->map;\r\nconst struct regmap_irq *irq_data = irq_to_regmap_irq(d, data->hwirq);\r\nd->mask_buf[irq_data->reg_offset / map->reg_stride] &= ~irq_data->mask;\r\n}\r\nstatic void regmap_irq_disable(struct irq_data *data)\r\n{\r\nstruct regmap_irq_chip_data *d = irq_data_get_irq_chip_data(data);\r\nstruct regmap *map = d->map;\r\nconst struct regmap_irq *irq_data = irq_to_regmap_irq(d, data->hwirq);\r\nd->mask_buf[irq_data->reg_offset / map->reg_stride] |= irq_data->mask;\r\n}\r\nstatic int regmap_irq_set_type(struct irq_data *data, unsigned int type)\r\n{\r\nstruct regmap_irq_chip_data *d = irq_data_get_irq_chip_data(data);\r\nstruct regmap *map = d->map;\r\nconst struct regmap_irq *irq_data = irq_to_regmap_irq(d, data->hwirq);\r\nint reg = irq_data->type_reg_offset / map->reg_stride;\r\nif (!(irq_data->type_rising_mask | irq_data->type_falling_mask))\r\nreturn 0;\r\nd->type_buf[reg] &= ~(irq_data->type_falling_mask |\r\nirq_data->type_rising_mask);\r\nswitch (type) {\r\ncase IRQ_TYPE_EDGE_FALLING:\r\nd->type_buf[reg] |= irq_data->type_falling_mask;\r\nbreak;\r\ncase IRQ_TYPE_EDGE_RISING:\r\nd->type_buf[reg] |= irq_data->type_rising_mask;\r\nbreak;\r\ncase IRQ_TYPE_EDGE_BOTH:\r\nd->type_buf[reg] |= (irq_data->type_falling_mask |\r\nirq_data->type_rising_mask);\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int regmap_irq_set_wake(struct irq_data *data, unsigned int on)\r\n{\r\nstruct regmap_irq_chip_data *d = irq_data_get_irq_chip_data(data);\r\nstruct regmap *map = d->map;\r\nconst struct regmap_irq *irq_data = irq_to_regmap_irq(d, data->hwirq);\r\nif (on) {\r\nif (d->wake_buf)\r\nd->wake_buf[irq_data->reg_offset / map->reg_stride]\r\n&= ~irq_data->mask;\r\nd->wake_count++;\r\n} else {\r\nif (d->wake_buf)\r\nd->wake_buf[irq_data->reg_offset / map->reg_stride]\r\n|= irq_data->mask;\r\nd->wake_count--;\r\n}\r\nreturn 0;\r\n}\r\nstatic irqreturn_t regmap_irq_thread(int irq, void *d)\r\n{\r\nstruct regmap_irq_chip_data *data = d;\r\nconst struct regmap_irq_chip *chip = data->chip;\r\nstruct regmap *map = data->map;\r\nint ret, i;\r\nbool handled = false;\r\nu32 reg;\r\nif (chip->handle_pre_irq)\r\nchip->handle_pre_irq(chip->irq_drv_data);\r\nif (chip->runtime_pm) {\r\nret = pm_runtime_get_sync(map->dev);\r\nif (ret < 0) {\r\ndev_err(map->dev, "IRQ thread failed to resume: %d\n",\r\nret);\r\npm_runtime_put(map->dev);\r\ngoto exit;\r\n}\r\n}\r\nif (!map->use_single_read && map->reg_stride == 1 &&\r\ndata->irq_reg_stride == 1) {\r\nu8 *buf8 = data->status_reg_buf;\r\nu16 *buf16 = data->status_reg_buf;\r\nu32 *buf32 = data->status_reg_buf;\r\nBUG_ON(!data->status_reg_buf);\r\nret = regmap_bulk_read(map, chip->status_base,\r\ndata->status_reg_buf,\r\nchip->num_regs);\r\nif (ret != 0) {\r\ndev_err(map->dev, "Failed to read IRQ status: %d\n",\r\nret);\r\ngoto exit;\r\n}\r\nfor (i = 0; i < data->chip->num_regs; i++) {\r\nswitch (map->format.val_bytes) {\r\ncase 1:\r\ndata->status_buf[i] = buf8[i];\r\nbreak;\r\ncase 2:\r\ndata->status_buf[i] = buf16[i];\r\nbreak;\r\ncase 4:\r\ndata->status_buf[i] = buf32[i];\r\nbreak;\r\ndefault:\r\nBUG();\r\ngoto exit;\r\n}\r\n}\r\n} else {\r\nfor (i = 0; i < data->chip->num_regs; i++) {\r\nret = regmap_read(map, chip->status_base +\r\n(i * map->reg_stride\r\n* data->irq_reg_stride),\r\n&data->status_buf[i]);\r\nif (ret != 0) {\r\ndev_err(map->dev,\r\n"Failed to read IRQ status: %d\n",\r\nret);\r\nif (chip->runtime_pm)\r\npm_runtime_put(map->dev);\r\ngoto exit;\r\n}\r\n}\r\n}\r\nfor (i = 0; i < data->chip->num_regs; i++) {\r\ndata->status_buf[i] &= ~data->mask_buf[i];\r\nif (data->status_buf[i] && (chip->ack_base || chip->use_ack)) {\r\nreg = chip->ack_base +\r\n(i * map->reg_stride * data->irq_reg_stride);\r\nret = regmap_write(map, reg, data->status_buf[i]);\r\nif (ret != 0)\r\ndev_err(map->dev, "Failed to ack 0x%x: %d\n",\r\nreg, ret);\r\n}\r\n}\r\nfor (i = 0; i < chip->num_irqs; i++) {\r\nif (data->status_buf[chip->irqs[i].reg_offset /\r\nmap->reg_stride] & chip->irqs[i].mask) {\r\nhandle_nested_irq(irq_find_mapping(data->domain, i));\r\nhandled = true;\r\n}\r\n}\r\nif (chip->runtime_pm)\r\npm_runtime_put(map->dev);\r\nexit:\r\nif (chip->handle_post_irq)\r\nchip->handle_post_irq(chip->irq_drv_data);\r\nif (handled)\r\nreturn IRQ_HANDLED;\r\nelse\r\nreturn IRQ_NONE;\r\n}\r\nstatic int regmap_irq_map(struct irq_domain *h, unsigned int virq,\r\nirq_hw_number_t hw)\r\n{\r\nstruct regmap_irq_chip_data *data = h->host_data;\r\nirq_set_chip_data(virq, data);\r\nirq_set_chip(virq, &data->irq_chip);\r\nirq_set_nested_thread(virq, 1);\r\nirq_set_parent(virq, data->irq);\r\nirq_set_noprobe(virq);\r\nreturn 0;\r\n}\r\nint regmap_add_irq_chip(struct regmap *map, int irq, int irq_flags,\r\nint irq_base, const struct regmap_irq_chip *chip,\r\nstruct regmap_irq_chip_data **data)\r\n{\r\nstruct regmap_irq_chip_data *d;\r\nint i;\r\nint ret = -ENOMEM;\r\nu32 reg;\r\nu32 unmask_offset;\r\nif (chip->num_regs <= 0)\r\nreturn -EINVAL;\r\nfor (i = 0; i < chip->num_irqs; i++) {\r\nif (chip->irqs[i].reg_offset % map->reg_stride)\r\nreturn -EINVAL;\r\nif (chip->irqs[i].reg_offset / map->reg_stride >=\r\nchip->num_regs)\r\nreturn -EINVAL;\r\n}\r\nif (irq_base) {\r\nirq_base = irq_alloc_descs(irq_base, 0, chip->num_irqs, 0);\r\nif (irq_base < 0) {\r\ndev_warn(map->dev, "Failed to allocate IRQs: %d\n",\r\nirq_base);\r\nreturn irq_base;\r\n}\r\n}\r\nd = kzalloc(sizeof(*d), GFP_KERNEL);\r\nif (!d)\r\nreturn -ENOMEM;\r\nd->status_buf = kcalloc(chip->num_regs, sizeof(unsigned int),\r\nGFP_KERNEL);\r\nif (!d->status_buf)\r\ngoto err_alloc;\r\nd->mask_buf = kcalloc(chip->num_regs, sizeof(unsigned int),\r\nGFP_KERNEL);\r\nif (!d->mask_buf)\r\ngoto err_alloc;\r\nd->mask_buf_def = kcalloc(chip->num_regs, sizeof(unsigned int),\r\nGFP_KERNEL);\r\nif (!d->mask_buf_def)\r\ngoto err_alloc;\r\nif (chip->wake_base) {\r\nd->wake_buf = kcalloc(chip->num_regs, sizeof(unsigned int),\r\nGFP_KERNEL);\r\nif (!d->wake_buf)\r\ngoto err_alloc;\r\n}\r\nif (chip->num_type_reg) {\r\nd->type_buf_def = kcalloc(chip->num_type_reg,\r\nsizeof(unsigned int), GFP_KERNEL);\r\nif (!d->type_buf_def)\r\ngoto err_alloc;\r\nd->type_buf = kcalloc(chip->num_type_reg, sizeof(unsigned int),\r\nGFP_KERNEL);\r\nif (!d->type_buf)\r\ngoto err_alloc;\r\n}\r\nd->irq_chip = regmap_irq_chip;\r\nd->irq_chip.name = chip->name;\r\nd->irq = irq;\r\nd->map = map;\r\nd->chip = chip;\r\nd->irq_base = irq_base;\r\nif (chip->irq_reg_stride)\r\nd->irq_reg_stride = chip->irq_reg_stride;\r\nelse\r\nd->irq_reg_stride = 1;\r\nif (chip->type_reg_stride)\r\nd->type_reg_stride = chip->type_reg_stride;\r\nelse\r\nd->type_reg_stride = 1;\r\nif (!map->use_single_read && map->reg_stride == 1 &&\r\nd->irq_reg_stride == 1) {\r\nd->status_reg_buf = kmalloc_array(chip->num_regs,\r\nmap->format.val_bytes,\r\nGFP_KERNEL);\r\nif (!d->status_reg_buf)\r\ngoto err_alloc;\r\n}\r\nmutex_init(&d->lock);\r\nfor (i = 0; i < chip->num_irqs; i++)\r\nd->mask_buf_def[chip->irqs[i].reg_offset / map->reg_stride]\r\n|= chip->irqs[i].mask;\r\nfor (i = 0; i < chip->num_regs; i++) {\r\nd->mask_buf[i] = d->mask_buf_def[i];\r\nreg = chip->mask_base +\r\n(i * map->reg_stride * d->irq_reg_stride);\r\nif (chip->mask_invert)\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf[i], ~d->mask_buf[i]);\r\nelse if (d->chip->unmask_base) {\r\nunmask_offset = d->chip->unmask_base -\r\nd->chip->mask_base;\r\nret = regmap_irq_update_bits(d,\r\nreg + unmask_offset,\r\nd->mask_buf[i],\r\nd->mask_buf[i]);\r\n} else\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf[i], d->mask_buf[i]);\r\nif (ret != 0) {\r\ndev_err(map->dev, "Failed to set masks in 0x%x: %d\n",\r\nreg, ret);\r\ngoto err_alloc;\r\n}\r\nif (!chip->init_ack_masked)\r\ncontinue;\r\nreg = chip->status_base +\r\n(i * map->reg_stride * d->irq_reg_stride);\r\nret = regmap_read(map, reg, &d->status_buf[i]);\r\nif (ret != 0) {\r\ndev_err(map->dev, "Failed to read IRQ status: %d\n",\r\nret);\r\ngoto err_alloc;\r\n}\r\nif (d->status_buf[i] && (chip->ack_base || chip->use_ack)) {\r\nreg = chip->ack_base +\r\n(i * map->reg_stride * d->irq_reg_stride);\r\nif (chip->ack_invert)\r\nret = regmap_write(map, reg,\r\n~(d->status_buf[i] & d->mask_buf[i]));\r\nelse\r\nret = regmap_write(map, reg,\r\nd->status_buf[i] & d->mask_buf[i]);\r\nif (ret != 0) {\r\ndev_err(map->dev, "Failed to ack 0x%x: %d\n",\r\nreg, ret);\r\ngoto err_alloc;\r\n}\r\n}\r\n}\r\nif (d->wake_buf) {\r\nfor (i = 0; i < chip->num_regs; i++) {\r\nd->wake_buf[i] = d->mask_buf_def[i];\r\nreg = chip->wake_base +\r\n(i * map->reg_stride * d->irq_reg_stride);\r\nif (chip->wake_invert)\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf_def[i],\r\n0);\r\nelse\r\nret = regmap_irq_update_bits(d, reg,\r\nd->mask_buf_def[i],\r\nd->wake_buf[i]);\r\nif (ret != 0) {\r\ndev_err(map->dev, "Failed to set masks in 0x%x: %d\n",\r\nreg, ret);\r\ngoto err_alloc;\r\n}\r\n}\r\n}\r\nif (chip->num_type_reg) {\r\nfor (i = 0; i < chip->num_irqs; i++) {\r\nreg = chip->irqs[i].type_reg_offset / map->reg_stride;\r\nd->type_buf_def[reg] |= chip->irqs[i].type_rising_mask |\r\nchip->irqs[i].type_falling_mask;\r\n}\r\nfor (i = 0; i < chip->num_type_reg; ++i) {\r\nif (!d->type_buf_def[i])\r\ncontinue;\r\nreg = chip->type_base +\r\n(i * map->reg_stride * d->type_reg_stride);\r\nif (chip->type_invert)\r\nret = regmap_irq_update_bits(d, reg,\r\nd->type_buf_def[i], 0xFF);\r\nelse\r\nret = regmap_irq_update_bits(d, reg,\r\nd->type_buf_def[i], 0x0);\r\nif (ret != 0) {\r\ndev_err(map->dev,\r\n"Failed to set type in 0x%x: %x\n",\r\nreg, ret);\r\ngoto err_alloc;\r\n}\r\n}\r\n}\r\nif (irq_base)\r\nd->domain = irq_domain_add_legacy(map->dev->of_node,\r\nchip->num_irqs, irq_base, 0,\r\n&regmap_domain_ops, d);\r\nelse\r\nd->domain = irq_domain_add_linear(map->dev->of_node,\r\nchip->num_irqs,\r\n&regmap_domain_ops, d);\r\nif (!d->domain) {\r\ndev_err(map->dev, "Failed to create IRQ domain\n");\r\nret = -ENOMEM;\r\ngoto err_alloc;\r\n}\r\nret = request_threaded_irq(irq, NULL, regmap_irq_thread,\r\nirq_flags | IRQF_ONESHOT,\r\nchip->name, d);\r\nif (ret != 0) {\r\ndev_err(map->dev, "Failed to request IRQ %d for %s: %d\n",\r\nirq, chip->name, ret);\r\ngoto err_domain;\r\n}\r\n*data = d;\r\nreturn 0;\r\nerr_domain:\r\nerr_alloc:\r\nkfree(d->type_buf);\r\nkfree(d->type_buf_def);\r\nkfree(d->wake_buf);\r\nkfree(d->mask_buf_def);\r\nkfree(d->mask_buf);\r\nkfree(d->status_buf);\r\nkfree(d->status_reg_buf);\r\nkfree(d);\r\nreturn ret;\r\n}\r\nvoid regmap_del_irq_chip(int irq, struct regmap_irq_chip_data *d)\r\n{\r\nunsigned int virq;\r\nint hwirq;\r\nif (!d)\r\nreturn;\r\nfree_irq(irq, d);\r\nfor (hwirq = 0; hwirq < d->chip->num_irqs; hwirq++) {\r\nif (!d->chip->irqs[hwirq].mask)\r\ncontinue;\r\nvirq = irq_find_mapping(d->domain, hwirq);\r\nif (virq)\r\nirq_dispose_mapping(virq);\r\n}\r\nirq_domain_remove(d->domain);\r\nkfree(d->type_buf);\r\nkfree(d->type_buf_def);\r\nkfree(d->wake_buf);\r\nkfree(d->mask_buf_def);\r\nkfree(d->mask_buf);\r\nkfree(d->status_reg_buf);\r\nkfree(d->status_buf);\r\nkfree(d);\r\n}\r\nstatic void devm_regmap_irq_chip_release(struct device *dev, void *res)\r\n{\r\nstruct regmap_irq_chip_data *d = *(struct regmap_irq_chip_data **)res;\r\nregmap_del_irq_chip(d->irq, d);\r\n}\r\nstatic int devm_regmap_irq_chip_match(struct device *dev, void *res, void *data)\r\n{\r\nstruct regmap_irq_chip_data **r = res;\r\nif (!r || !*r) {\r\nWARN_ON(!r || !*r);\r\nreturn 0;\r\n}\r\nreturn *r == data;\r\n}\r\nint devm_regmap_add_irq_chip(struct device *dev, struct regmap *map, int irq,\r\nint irq_flags, int irq_base,\r\nconst struct regmap_irq_chip *chip,\r\nstruct regmap_irq_chip_data **data)\r\n{\r\nstruct regmap_irq_chip_data **ptr, *d;\r\nint ret;\r\nptr = devres_alloc(devm_regmap_irq_chip_release, sizeof(*ptr),\r\nGFP_KERNEL);\r\nif (!ptr)\r\nreturn -ENOMEM;\r\nret = regmap_add_irq_chip(map, irq, irq_flags, irq_base,\r\nchip, &d);\r\nif (ret < 0) {\r\ndevres_free(ptr);\r\nreturn ret;\r\n}\r\n*ptr = d;\r\ndevres_add(dev, ptr);\r\n*data = d;\r\nreturn 0;\r\n}\r\nvoid devm_regmap_del_irq_chip(struct device *dev, int irq,\r\nstruct regmap_irq_chip_data *data)\r\n{\r\nint rc;\r\nWARN_ON(irq != data->irq);\r\nrc = devres_release(dev, devm_regmap_irq_chip_release,\r\ndevm_regmap_irq_chip_match, data);\r\nif (rc != 0)\r\nWARN_ON(rc);\r\n}\r\nint regmap_irq_chip_get_base(struct regmap_irq_chip_data *data)\r\n{\r\nWARN_ON(!data->irq_base);\r\nreturn data->irq_base;\r\n}\r\nint regmap_irq_get_virq(struct regmap_irq_chip_data *data, int irq)\r\n{\r\nif (!data->chip->irqs[irq].mask)\r\nreturn -EINVAL;\r\nreturn irq_create_mapping(data->domain, irq);\r\n}\r\nstruct irq_domain *regmap_irq_get_domain(struct regmap_irq_chip_data *data)\r\n{\r\nif (data)\r\nreturn data->domain;\r\nelse\r\nreturn NULL;\r\n}
