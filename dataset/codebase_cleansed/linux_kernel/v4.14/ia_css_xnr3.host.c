static int32_t\r\ncompute_alpha(int sigma)\r\n{\r\nint32_t alpha;\r\n#if defined(XNR_ATE_ROUNDING_BUG)\r\nint32_t alpha_unscaled;\r\n#else\r\nint offset = sigma / 2;\r\n#endif\r\nif (sigma < XNR_MIN_SIGMA) {\r\nalpha = XNR_MAX_ALPHA;\r\n} else {\r\n#if defined(XNR_ATE_ROUNDING_BUG)\r\nalpha_unscaled = IA_CSS_XNR3_SIGMA_SCALE / sigma;\r\nalpha = alpha_unscaled * XNR_ALPHA_SCALE_FACTOR;\r\n#else\r\nalpha = ((IA_CSS_XNR3_SIGMA_SCALE * XNR_ALPHA_SCALE_FACTOR) + offset)/ sigma;\r\n#endif\r\nif (alpha > XNR_MAX_ALPHA)\r\nalpha = XNR_MAX_ALPHA;\r\n}\r\nreturn alpha;\r\n}\r\nstatic int32_t\r\ncompute_coring(int coring)\r\n{\r\nint32_t isp_coring;\r\nint32_t isp_scale = XNR_CORING_SCALE_FACTOR;\r\nint32_t host_scale = IA_CSS_XNR3_CORING_SCALE;\r\nint32_t offset = host_scale / 2;\r\nisp_coring = ((coring * isp_scale) + offset) / host_scale;\r\nreturn min(max(isp_coring, 0), isp_scale - 1);\r\n}\r\nstatic int32_t\r\ncompute_blending(int strength)\r\n{\r\nint32_t isp_strength;\r\nint32_t isp_scale = XNR_BLENDING_SCALE_FACTOR;\r\nint32_t host_scale = IA_CSS_XNR3_BLENDING_SCALE;\r\nint32_t offset = host_scale / 2;\r\nisp_strength = -(((strength * isp_scale) + offset) / host_scale);\r\nreturn max(min(isp_strength, 0), -XNR_BLENDING_SCALE_FACTOR);\r\n}\r\nvoid\r\nia_css_xnr3_encode(\r\nstruct sh_css_isp_xnr3_params *to,\r\nconst struct ia_css_xnr3_config *from,\r\nunsigned size)\r\n{\r\nint kernel_size = XNR_FILTER_SIZE;\r\nint adjust_factor = ceil_pow2(kernel_size);\r\nint32_t max_diff = (1 << (ISP_VEC_ELEMBITS - 1)) - 1;\r\nint32_t min_diff = -(1 << (ISP_VEC_ELEMBITS - 1));\r\nint32_t alpha_y0 = compute_alpha(from->sigma.y0);\r\nint32_t alpha_y1 = compute_alpha(from->sigma.y1);\r\nint32_t alpha_u0 = compute_alpha(from->sigma.u0);\r\nint32_t alpha_u1 = compute_alpha(from->sigma.u1);\r\nint32_t alpha_v0 = compute_alpha(from->sigma.v0);\r\nint32_t alpha_v1 = compute_alpha(from->sigma.v1);\r\nint32_t alpha_ydiff = (alpha_y1 - alpha_y0) * adjust_factor / kernel_size;\r\nint32_t alpha_udiff = (alpha_u1 - alpha_u0) * adjust_factor / kernel_size;\r\nint32_t alpha_vdiff = (alpha_v1 - alpha_v0) * adjust_factor / kernel_size;\r\nint32_t coring_u0 = compute_coring(from->coring.u0);\r\nint32_t coring_u1 = compute_coring(from->coring.u1);\r\nint32_t coring_v0 = compute_coring(from->coring.v0);\r\nint32_t coring_v1 = compute_coring(from->coring.v1);\r\nint32_t coring_udiff = (coring_u1 - coring_u0) * adjust_factor / kernel_size;\r\nint32_t coring_vdiff = (coring_v1 - coring_v0) * adjust_factor / kernel_size;\r\nint32_t blending = compute_blending(from->blending.strength);\r\n(void)size;\r\nto->alpha.y0 = alpha_y0;\r\nto->alpha.u0 = alpha_u0;\r\nto->alpha.v0 = alpha_v0;\r\nto->alpha.ydiff = min(max(alpha_ydiff, min_diff), max_diff);\r\nto->alpha.udiff = min(max(alpha_udiff, min_diff), max_diff);\r\nto->alpha.vdiff = min(max(alpha_vdiff, min_diff), max_diff);\r\nto->coring.u0 = coring_u0;\r\nto->coring.v0 = coring_v0;\r\nto->coring.udiff = min(max(coring_udiff, min_diff), max_diff);\r\nto->coring.vdiff = min(max(coring_vdiff, min_diff), max_diff);\r\nto->blending.strength = blending;\r\n}\r\nvoid\r\nia_css_xnr3_vmem_encode(\r\nstruct sh_css_isp_xnr3_vmem_params *to,\r\nconst struct ia_css_xnr3_config *from,\r\nunsigned size)\r\n{\r\nunsigned i, j, base;\r\nconst unsigned total_blocks = 4;\r\nconst unsigned shuffle_block = 16;\r\n(void)from;\r\n(void)size;\r\nfor (i = 0; i < ISP_VEC_NELEMS; i++) {\r\nto->x[0][i] = 0;\r\nto->a[0][i] = 0;\r\nto->b[0][i] = 0;\r\nto->c[0][i] = 0;\r\n}\r\nassert(x[0] >= 0);\r\nfor (j = 1; j < XNR3_LOOK_UP_TABLE_POINTS; j++) {\r\nassert(x[j] >= 0);\r\nassert(x[j] > x[j - 1]);\r\n}\r\nfor (i = 0; i < total_blocks; i++) {\r\nbase = shuffle_block * i;\r\nfor (j = 0; j < XNR3_LOOK_UP_TABLE_POINTS; j++) {\r\nto->x[0][base + j] = x[j];\r\nto->a[0][base + j] = a[j];\r\nto->b[0][base + j] = b[j];\r\nto->c[0][base + j] = c[j];\r\n}\r\n}\r\n}\r\nvoid\r\nia_css_xnr3_debug_dtrace(\r\nconst struct ia_css_xnr3_config *config,\r\nunsigned level)\r\n{\r\n(void)config;\r\n(void)level;\r\n}
