static bool bgmac_wait_value(struct bgmac *bgmac, u16 reg, u32 mask,\r\nu32 value, int timeout)\r\n{\r\nu32 val;\r\nint i;\r\nfor (i = 0; i < timeout / 10; i++) {\r\nval = bgmac_read(bgmac, reg);\r\nif ((val & mask) == value)\r\nreturn true;\r\nudelay(10);\r\n}\r\ndev_err(bgmac->dev, "Timeout waiting for reg 0x%X\n", reg);\r\nreturn false;\r\n}\r\nstatic void bgmac_dma_tx_reset(struct bgmac *bgmac, struct bgmac_dma_ring *ring)\r\n{\r\nu32 val;\r\nint i;\r\nif (!ring->mmio_base)\r\nreturn;\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_TX_CTL,\r\nBGMAC_DMA_TX_SUSPEND);\r\nfor (i = 0; i < 10000 / 10; i++) {\r\nval = bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_TX_STATUS);\r\nval &= BGMAC_DMA_TX_STAT;\r\nif (val == BGMAC_DMA_TX_STAT_DISABLED ||\r\nval == BGMAC_DMA_TX_STAT_IDLEWAIT ||\r\nval == BGMAC_DMA_TX_STAT_STOPPED) {\r\ni = 0;\r\nbreak;\r\n}\r\nudelay(10);\r\n}\r\nif (i)\r\ndev_err(bgmac->dev, "Timeout suspending DMA TX ring 0x%X (BGMAC_DMA_TX_STAT: 0x%08X)\n",\r\nring->mmio_base, val);\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_TX_CTL, 0);\r\nif (!bgmac_wait_value(bgmac,\r\nring->mmio_base + BGMAC_DMA_TX_STATUS,\r\nBGMAC_DMA_TX_STAT, BGMAC_DMA_TX_STAT_DISABLED,\r\n10000)) {\r\ndev_warn(bgmac->dev, "DMA TX ring 0x%X wasn't disabled on time, waiting additional 300us\n",\r\nring->mmio_base);\r\nudelay(300);\r\nval = bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_TX_STATUS);\r\nif ((val & BGMAC_DMA_TX_STAT) != BGMAC_DMA_TX_STAT_DISABLED)\r\ndev_err(bgmac->dev, "Reset of DMA TX ring 0x%X failed\n",\r\nring->mmio_base);\r\n}\r\n}\r\nstatic void bgmac_dma_tx_enable(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring)\r\n{\r\nu32 ctl;\r\nctl = bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_TX_CTL);\r\nif (bgmac->feature_flags & BGMAC_FEAT_TX_MASK_SETUP) {\r\nctl &= ~BGMAC_DMA_TX_BL_MASK;\r\nctl |= BGMAC_DMA_TX_BL_128 << BGMAC_DMA_TX_BL_SHIFT;\r\nctl &= ~BGMAC_DMA_TX_MR_MASK;\r\nctl |= BGMAC_DMA_TX_MR_2 << BGMAC_DMA_TX_MR_SHIFT;\r\nctl &= ~BGMAC_DMA_TX_PC_MASK;\r\nctl |= BGMAC_DMA_TX_PC_16 << BGMAC_DMA_TX_PC_SHIFT;\r\nctl &= ~BGMAC_DMA_TX_PT_MASK;\r\nctl |= BGMAC_DMA_TX_PT_8 << BGMAC_DMA_TX_PT_SHIFT;\r\n}\r\nctl |= BGMAC_DMA_TX_ENABLE;\r\nctl |= BGMAC_DMA_TX_PARITY_DISABLE;\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_TX_CTL, ctl);\r\n}\r\nstatic void\r\nbgmac_dma_tx_add_buf(struct bgmac *bgmac, struct bgmac_dma_ring *ring,\r\nint i, int len, u32 ctl0)\r\n{\r\nstruct bgmac_slot_info *slot;\r\nstruct bgmac_dma_desc *dma_desc;\r\nu32 ctl1;\r\nif (i == BGMAC_TX_RING_SLOTS - 1)\r\nctl0 |= BGMAC_DESC_CTL0_EOT;\r\nctl1 = len & BGMAC_DESC_CTL1_LEN;\r\nslot = &ring->slots[i];\r\ndma_desc = &ring->cpu_base[i];\r\ndma_desc->addr_low = cpu_to_le32(lower_32_bits(slot->dma_addr));\r\ndma_desc->addr_high = cpu_to_le32(upper_32_bits(slot->dma_addr));\r\ndma_desc->ctl0 = cpu_to_le32(ctl0);\r\ndma_desc->ctl1 = cpu_to_le32(ctl1);\r\n}\r\nstatic netdev_tx_t bgmac_dma_tx_add(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring,\r\nstruct sk_buff *skb)\r\n{\r\nstruct device *dma_dev = bgmac->dma_dev;\r\nstruct net_device *net_dev = bgmac->net_dev;\r\nint index = ring->end % BGMAC_TX_RING_SLOTS;\r\nstruct bgmac_slot_info *slot = &ring->slots[index];\r\nint nr_frags;\r\nu32 flags;\r\nint i;\r\nif (skb->len > BGMAC_DESC_CTL1_LEN) {\r\nnetdev_err(bgmac->net_dev, "Too long skb (%d)\n", skb->len);\r\ngoto err_drop;\r\n}\r\nif (skb->ip_summed == CHECKSUM_PARTIAL)\r\nskb_checksum_help(skb);\r\nnr_frags = skb_shinfo(skb)->nr_frags;\r\nif (ring->end - ring->start + nr_frags + 1 >= BGMAC_TX_RING_SLOTS) {\r\nnetdev_err(bgmac->net_dev, "TX ring is full, queue should be stopped!\n");\r\nnetif_stop_queue(net_dev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nslot->dma_addr = dma_map_single(dma_dev, skb->data, skb_headlen(skb),\r\nDMA_TO_DEVICE);\r\nif (unlikely(dma_mapping_error(dma_dev, slot->dma_addr)))\r\ngoto err_dma_head;\r\nflags = BGMAC_DESC_CTL0_SOF;\r\nif (!nr_frags)\r\nflags |= BGMAC_DESC_CTL0_EOF | BGMAC_DESC_CTL0_IOC;\r\nbgmac_dma_tx_add_buf(bgmac, ring, index, skb_headlen(skb), flags);\r\nflags = 0;\r\nfor (i = 0; i < nr_frags; i++) {\r\nstruct skb_frag_struct *frag = &skb_shinfo(skb)->frags[i];\r\nint len = skb_frag_size(frag);\r\nindex = (index + 1) % BGMAC_TX_RING_SLOTS;\r\nslot = &ring->slots[index];\r\nslot->dma_addr = skb_frag_dma_map(dma_dev, frag, 0,\r\nlen, DMA_TO_DEVICE);\r\nif (unlikely(dma_mapping_error(dma_dev, slot->dma_addr)))\r\ngoto err_dma;\r\nif (i == nr_frags - 1)\r\nflags |= BGMAC_DESC_CTL0_EOF | BGMAC_DESC_CTL0_IOC;\r\nbgmac_dma_tx_add_buf(bgmac, ring, index, len, flags);\r\n}\r\nslot->skb = skb;\r\nring->end += nr_frags + 1;\r\nnetdev_sent_queue(net_dev, skb->len);\r\nwmb();\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_TX_INDEX,\r\nring->index_base +\r\n(ring->end % BGMAC_TX_RING_SLOTS) *\r\nsizeof(struct bgmac_dma_desc));\r\nif (ring->end - ring->start >= BGMAC_TX_RING_SLOTS - 8)\r\nnetif_stop_queue(net_dev);\r\nreturn NETDEV_TX_OK;\r\nerr_dma:\r\ndma_unmap_single(dma_dev, slot->dma_addr, skb_headlen(skb),\r\nDMA_TO_DEVICE);\r\nwhile (i-- > 0) {\r\nint index = (ring->end + i) % BGMAC_TX_RING_SLOTS;\r\nstruct bgmac_slot_info *slot = &ring->slots[index];\r\nu32 ctl1 = le32_to_cpu(ring->cpu_base[index].ctl1);\r\nint len = ctl1 & BGMAC_DESC_CTL1_LEN;\r\ndma_unmap_page(dma_dev, slot->dma_addr, len, DMA_TO_DEVICE);\r\n}\r\nerr_dma_head:\r\nnetdev_err(bgmac->net_dev, "Mapping error of skb on ring 0x%X\n",\r\nring->mmio_base);\r\nerr_drop:\r\ndev_kfree_skb(skb);\r\nnet_dev->stats.tx_dropped++;\r\nnet_dev->stats.tx_errors++;\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void bgmac_dma_tx_free(struct bgmac *bgmac, struct bgmac_dma_ring *ring)\r\n{\r\nstruct device *dma_dev = bgmac->dma_dev;\r\nint empty_slot;\r\nbool freed = false;\r\nunsigned bytes_compl = 0, pkts_compl = 0;\r\nempty_slot = bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_TX_STATUS);\r\nempty_slot &= BGMAC_DMA_TX_STATDPTR;\r\nempty_slot -= ring->index_base;\r\nempty_slot &= BGMAC_DMA_TX_STATDPTR;\r\nempty_slot /= sizeof(struct bgmac_dma_desc);\r\nwhile (ring->start != ring->end) {\r\nint slot_idx = ring->start % BGMAC_TX_RING_SLOTS;\r\nstruct bgmac_slot_info *slot = &ring->slots[slot_idx];\r\nu32 ctl0, ctl1;\r\nint len;\r\nif (slot_idx == empty_slot)\r\nbreak;\r\nctl0 = le32_to_cpu(ring->cpu_base[slot_idx].ctl0);\r\nctl1 = le32_to_cpu(ring->cpu_base[slot_idx].ctl1);\r\nlen = ctl1 & BGMAC_DESC_CTL1_LEN;\r\nif (ctl0 & BGMAC_DESC_CTL0_SOF)\r\ndma_unmap_single(dma_dev, slot->dma_addr, len,\r\nDMA_TO_DEVICE);\r\nelse\r\ndma_unmap_page(dma_dev, slot->dma_addr, len,\r\nDMA_TO_DEVICE);\r\nif (slot->skb) {\r\nbgmac->net_dev->stats.tx_bytes += slot->skb->len;\r\nbgmac->net_dev->stats.tx_packets++;\r\nbytes_compl += slot->skb->len;\r\npkts_compl++;\r\ndev_kfree_skb(slot->skb);\r\nslot->skb = NULL;\r\n}\r\nslot->dma_addr = 0;\r\nring->start++;\r\nfreed = true;\r\n}\r\nif (!pkts_compl)\r\nreturn;\r\nnetdev_completed_queue(bgmac->net_dev, pkts_compl, bytes_compl);\r\nif (netif_queue_stopped(bgmac->net_dev))\r\nnetif_wake_queue(bgmac->net_dev);\r\n}\r\nstatic void bgmac_dma_rx_reset(struct bgmac *bgmac, struct bgmac_dma_ring *ring)\r\n{\r\nif (!ring->mmio_base)\r\nreturn;\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_RX_CTL, 0);\r\nif (!bgmac_wait_value(bgmac,\r\nring->mmio_base + BGMAC_DMA_RX_STATUS,\r\nBGMAC_DMA_RX_STAT, BGMAC_DMA_RX_STAT_DISABLED,\r\n10000))\r\ndev_err(bgmac->dev, "Reset of ring 0x%X RX failed\n",\r\nring->mmio_base);\r\n}\r\nstatic void bgmac_dma_rx_enable(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring)\r\n{\r\nu32 ctl;\r\nctl = bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_RX_CTL);\r\nctl &= BGMAC_DMA_RX_ADDREXT_MASK;\r\nif (bgmac->feature_flags & BGMAC_FEAT_RX_MASK_SETUP) {\r\nctl &= ~BGMAC_DMA_RX_BL_MASK;\r\nctl |= BGMAC_DMA_RX_BL_128 << BGMAC_DMA_RX_BL_SHIFT;\r\nctl &= ~BGMAC_DMA_RX_PC_MASK;\r\nctl |= BGMAC_DMA_RX_PC_8 << BGMAC_DMA_RX_PC_SHIFT;\r\nctl &= ~BGMAC_DMA_RX_PT_MASK;\r\nctl |= BGMAC_DMA_RX_PT_1 << BGMAC_DMA_RX_PT_SHIFT;\r\n}\r\nctl |= BGMAC_DMA_RX_ENABLE;\r\nctl |= BGMAC_DMA_RX_PARITY_DISABLE;\r\nctl |= BGMAC_DMA_RX_OVERFLOW_CONT;\r\nctl |= BGMAC_RX_FRAME_OFFSET << BGMAC_DMA_RX_FRAME_OFFSET_SHIFT;\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_RX_CTL, ctl);\r\n}\r\nstatic int bgmac_dma_rx_skb_for_slot(struct bgmac *bgmac,\r\nstruct bgmac_slot_info *slot)\r\n{\r\nstruct device *dma_dev = bgmac->dma_dev;\r\ndma_addr_t dma_addr;\r\nstruct bgmac_rx_header *rx;\r\nvoid *buf;\r\nbuf = netdev_alloc_frag(BGMAC_RX_ALLOC_SIZE);\r\nif (!buf)\r\nreturn -ENOMEM;\r\nrx = buf + BGMAC_RX_BUF_OFFSET;\r\nrx->len = cpu_to_le16(0xdead);\r\nrx->flags = cpu_to_le16(0xbeef);\r\ndma_addr = dma_map_single(dma_dev, buf + BGMAC_RX_BUF_OFFSET,\r\nBGMAC_RX_BUF_SIZE, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(dma_dev, dma_addr)) {\r\nnetdev_err(bgmac->net_dev, "DMA mapping error\n");\r\nput_page(virt_to_head_page(buf));\r\nreturn -ENOMEM;\r\n}\r\nslot->buf = buf;\r\nslot->dma_addr = dma_addr;\r\nreturn 0;\r\n}\r\nstatic void bgmac_dma_rx_update_index(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring)\r\n{\r\ndma_wmb();\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_RX_INDEX,\r\nring->index_base +\r\nring->end * sizeof(struct bgmac_dma_desc));\r\n}\r\nstatic void bgmac_dma_rx_setup_desc(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring, int desc_idx)\r\n{\r\nstruct bgmac_dma_desc *dma_desc = ring->cpu_base + desc_idx;\r\nu32 ctl0 = 0, ctl1 = 0;\r\nif (desc_idx == BGMAC_RX_RING_SLOTS - 1)\r\nctl0 |= BGMAC_DESC_CTL0_EOT;\r\nctl1 |= BGMAC_RX_BUF_SIZE & BGMAC_DESC_CTL1_LEN;\r\ndma_desc->addr_low = cpu_to_le32(lower_32_bits(ring->slots[desc_idx].dma_addr));\r\ndma_desc->addr_high = cpu_to_le32(upper_32_bits(ring->slots[desc_idx].dma_addr));\r\ndma_desc->ctl0 = cpu_to_le32(ctl0);\r\ndma_desc->ctl1 = cpu_to_le32(ctl1);\r\nring->end = desc_idx;\r\n}\r\nstatic void bgmac_dma_rx_poison_buf(struct device *dma_dev,\r\nstruct bgmac_slot_info *slot)\r\n{\r\nstruct bgmac_rx_header *rx = slot->buf + BGMAC_RX_BUF_OFFSET;\r\ndma_sync_single_for_cpu(dma_dev, slot->dma_addr, BGMAC_RX_BUF_SIZE,\r\nDMA_FROM_DEVICE);\r\nrx->len = cpu_to_le16(0xdead);\r\nrx->flags = cpu_to_le16(0xbeef);\r\ndma_sync_single_for_device(dma_dev, slot->dma_addr, BGMAC_RX_BUF_SIZE,\r\nDMA_FROM_DEVICE);\r\n}\r\nstatic int bgmac_dma_rx_read(struct bgmac *bgmac, struct bgmac_dma_ring *ring,\r\nint weight)\r\n{\r\nu32 end_slot;\r\nint handled = 0;\r\nend_slot = bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_RX_STATUS);\r\nend_slot &= BGMAC_DMA_RX_STATDPTR;\r\nend_slot -= ring->index_base;\r\nend_slot &= BGMAC_DMA_RX_STATDPTR;\r\nend_slot /= sizeof(struct bgmac_dma_desc);\r\nwhile (ring->start != end_slot) {\r\nstruct device *dma_dev = bgmac->dma_dev;\r\nstruct bgmac_slot_info *slot = &ring->slots[ring->start];\r\nstruct bgmac_rx_header *rx = slot->buf + BGMAC_RX_BUF_OFFSET;\r\nstruct sk_buff *skb;\r\nvoid *buf = slot->buf;\r\ndma_addr_t dma_addr = slot->dma_addr;\r\nu16 len, flags;\r\ndo {\r\nif (bgmac_dma_rx_skb_for_slot(bgmac, slot)) {\r\nbgmac_dma_rx_poison_buf(dma_dev, slot);\r\nbreak;\r\n}\r\ndma_unmap_single(dma_dev, dma_addr,\r\nBGMAC_RX_BUF_SIZE, DMA_FROM_DEVICE);\r\nlen = le16_to_cpu(rx->len);\r\nflags = le16_to_cpu(rx->flags);\r\nif (len == 0xdead && flags == 0xbeef) {\r\nnetdev_err(bgmac->net_dev, "Found poisoned packet at slot %d, DMA issue!\n",\r\nring->start);\r\nput_page(virt_to_head_page(buf));\r\nbgmac->net_dev->stats.rx_errors++;\r\nbreak;\r\n}\r\nif (len > BGMAC_RX_ALLOC_SIZE) {\r\nnetdev_err(bgmac->net_dev, "Found oversized packet at slot %d, DMA issue!\n",\r\nring->start);\r\nput_page(virt_to_head_page(buf));\r\nbgmac->net_dev->stats.rx_length_errors++;\r\nbgmac->net_dev->stats.rx_errors++;\r\nbreak;\r\n}\r\nlen -= ETH_FCS_LEN;\r\nskb = build_skb(buf, BGMAC_RX_ALLOC_SIZE);\r\nif (unlikely(!skb)) {\r\nnetdev_err(bgmac->net_dev, "build_skb failed\n");\r\nput_page(virt_to_head_page(buf));\r\nbgmac->net_dev->stats.rx_errors++;\r\nbreak;\r\n}\r\nskb_put(skb, BGMAC_RX_FRAME_OFFSET +\r\nBGMAC_RX_BUF_OFFSET + len);\r\nskb_pull(skb, BGMAC_RX_FRAME_OFFSET +\r\nBGMAC_RX_BUF_OFFSET);\r\nskb_checksum_none_assert(skb);\r\nskb->protocol = eth_type_trans(skb, bgmac->net_dev);\r\nbgmac->net_dev->stats.rx_bytes += len;\r\nbgmac->net_dev->stats.rx_packets++;\r\nnapi_gro_receive(&bgmac->napi, skb);\r\nhandled++;\r\n} while (0);\r\nbgmac_dma_rx_setup_desc(bgmac, ring, ring->start);\r\nif (++ring->start >= BGMAC_RX_RING_SLOTS)\r\nring->start = 0;\r\nif (handled >= weight)\r\nbreak;\r\n}\r\nbgmac_dma_rx_update_index(bgmac, ring);\r\nreturn handled;\r\n}\r\nstatic bool bgmac_dma_unaligned(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring,\r\nenum bgmac_dma_ring_type ring_type)\r\n{\r\nswitch (ring_type) {\r\ncase BGMAC_DMA_RING_TX:\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_TX_RINGLO,\r\n0xff0);\r\nif (bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_TX_RINGLO))\r\nreturn true;\r\nbreak;\r\ncase BGMAC_DMA_RING_RX:\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_RX_RINGLO,\r\n0xff0);\r\nif (bgmac_read(bgmac, ring->mmio_base + BGMAC_DMA_RX_RINGLO))\r\nreturn true;\r\nbreak;\r\n}\r\nreturn false;\r\n}\r\nstatic void bgmac_dma_tx_ring_free(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring)\r\n{\r\nstruct device *dma_dev = bgmac->dma_dev;\r\nstruct bgmac_dma_desc *dma_desc = ring->cpu_base;\r\nstruct bgmac_slot_info *slot;\r\nint i;\r\nfor (i = 0; i < BGMAC_TX_RING_SLOTS; i++) {\r\nint len = dma_desc[i].ctl1 & BGMAC_DESC_CTL1_LEN;\r\nslot = &ring->slots[i];\r\ndev_kfree_skb(slot->skb);\r\nif (!slot->dma_addr)\r\ncontinue;\r\nif (slot->skb)\r\ndma_unmap_single(dma_dev, slot->dma_addr,\r\nlen, DMA_TO_DEVICE);\r\nelse\r\ndma_unmap_page(dma_dev, slot->dma_addr,\r\nlen, DMA_TO_DEVICE);\r\n}\r\n}\r\nstatic void bgmac_dma_rx_ring_free(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring)\r\n{\r\nstruct device *dma_dev = bgmac->dma_dev;\r\nstruct bgmac_slot_info *slot;\r\nint i;\r\nfor (i = 0; i < BGMAC_RX_RING_SLOTS; i++) {\r\nslot = &ring->slots[i];\r\nif (!slot->dma_addr)\r\ncontinue;\r\ndma_unmap_single(dma_dev, slot->dma_addr,\r\nBGMAC_RX_BUF_SIZE,\r\nDMA_FROM_DEVICE);\r\nput_page(virt_to_head_page(slot->buf));\r\nslot->dma_addr = 0;\r\n}\r\n}\r\nstatic void bgmac_dma_ring_desc_free(struct bgmac *bgmac,\r\nstruct bgmac_dma_ring *ring,\r\nint num_slots)\r\n{\r\nstruct device *dma_dev = bgmac->dma_dev;\r\nint size;\r\nif (!ring->cpu_base)\r\nreturn;\r\nsize = num_slots * sizeof(struct bgmac_dma_desc);\r\ndma_free_coherent(dma_dev, size, ring->cpu_base,\r\nring->dma_base);\r\n}\r\nstatic void bgmac_dma_cleanup(struct bgmac *bgmac)\r\n{\r\nint i;\r\nfor (i = 0; i < BGMAC_MAX_TX_RINGS; i++)\r\nbgmac_dma_tx_ring_free(bgmac, &bgmac->tx_ring[i]);\r\nfor (i = 0; i < BGMAC_MAX_RX_RINGS; i++)\r\nbgmac_dma_rx_ring_free(bgmac, &bgmac->rx_ring[i]);\r\n}\r\nstatic void bgmac_dma_free(struct bgmac *bgmac)\r\n{\r\nint i;\r\nfor (i = 0; i < BGMAC_MAX_TX_RINGS; i++)\r\nbgmac_dma_ring_desc_free(bgmac, &bgmac->tx_ring[i],\r\nBGMAC_TX_RING_SLOTS);\r\nfor (i = 0; i < BGMAC_MAX_RX_RINGS; i++)\r\nbgmac_dma_ring_desc_free(bgmac, &bgmac->rx_ring[i],\r\nBGMAC_RX_RING_SLOTS);\r\n}\r\nstatic int bgmac_dma_alloc(struct bgmac *bgmac)\r\n{\r\nstruct device *dma_dev = bgmac->dma_dev;\r\nstruct bgmac_dma_ring *ring;\r\nstatic const u16 ring_base[] = { BGMAC_DMA_BASE0, BGMAC_DMA_BASE1,\r\nBGMAC_DMA_BASE2, BGMAC_DMA_BASE3, };\r\nint size;\r\nint err;\r\nint i;\r\nBUILD_BUG_ON(BGMAC_MAX_TX_RINGS > ARRAY_SIZE(ring_base));\r\nBUILD_BUG_ON(BGMAC_MAX_RX_RINGS > ARRAY_SIZE(ring_base));\r\nif (!(bgmac->feature_flags & BGMAC_FEAT_IDM_MASK)) {\r\nif (!(bgmac_idm_read(bgmac, BCMA_IOST) & BCMA_IOST_DMA64)) {\r\ndev_err(bgmac->dev, "Core does not report 64-bit DMA\n");\r\nreturn -ENOTSUPP;\r\n}\r\n}\r\nfor (i = 0; i < BGMAC_MAX_TX_RINGS; i++) {\r\nring = &bgmac->tx_ring[i];\r\nring->mmio_base = ring_base[i];\r\nsize = BGMAC_TX_RING_SLOTS * sizeof(struct bgmac_dma_desc);\r\nring->cpu_base = dma_zalloc_coherent(dma_dev, size,\r\n&ring->dma_base,\r\nGFP_KERNEL);\r\nif (!ring->cpu_base) {\r\ndev_err(bgmac->dev, "Allocation of TX ring 0x%X failed\n",\r\nring->mmio_base);\r\ngoto err_dma_free;\r\n}\r\nring->unaligned = bgmac_dma_unaligned(bgmac, ring,\r\nBGMAC_DMA_RING_TX);\r\nif (ring->unaligned)\r\nring->index_base = lower_32_bits(ring->dma_base);\r\nelse\r\nring->index_base = 0;\r\n}\r\nfor (i = 0; i < BGMAC_MAX_RX_RINGS; i++) {\r\nring = &bgmac->rx_ring[i];\r\nring->mmio_base = ring_base[i];\r\nsize = BGMAC_RX_RING_SLOTS * sizeof(struct bgmac_dma_desc);\r\nring->cpu_base = dma_zalloc_coherent(dma_dev, size,\r\n&ring->dma_base,\r\nGFP_KERNEL);\r\nif (!ring->cpu_base) {\r\ndev_err(bgmac->dev, "Allocation of RX ring 0x%X failed\n",\r\nring->mmio_base);\r\nerr = -ENOMEM;\r\ngoto err_dma_free;\r\n}\r\nring->unaligned = bgmac_dma_unaligned(bgmac, ring,\r\nBGMAC_DMA_RING_RX);\r\nif (ring->unaligned)\r\nring->index_base = lower_32_bits(ring->dma_base);\r\nelse\r\nring->index_base = 0;\r\n}\r\nreturn 0;\r\nerr_dma_free:\r\nbgmac_dma_free(bgmac);\r\nreturn -ENOMEM;\r\n}\r\nstatic int bgmac_dma_init(struct bgmac *bgmac)\r\n{\r\nstruct bgmac_dma_ring *ring;\r\nint i, err;\r\nfor (i = 0; i < BGMAC_MAX_TX_RINGS; i++) {\r\nring = &bgmac->tx_ring[i];\r\nif (!ring->unaligned)\r\nbgmac_dma_tx_enable(bgmac, ring);\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_TX_RINGLO,\r\nlower_32_bits(ring->dma_base));\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_TX_RINGHI,\r\nupper_32_bits(ring->dma_base));\r\nif (ring->unaligned)\r\nbgmac_dma_tx_enable(bgmac, ring);\r\nring->start = 0;\r\nring->end = 0;\r\n}\r\nfor (i = 0; i < BGMAC_MAX_RX_RINGS; i++) {\r\nint j;\r\nring = &bgmac->rx_ring[i];\r\nif (!ring->unaligned)\r\nbgmac_dma_rx_enable(bgmac, ring);\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_RX_RINGLO,\r\nlower_32_bits(ring->dma_base));\r\nbgmac_write(bgmac, ring->mmio_base + BGMAC_DMA_RX_RINGHI,\r\nupper_32_bits(ring->dma_base));\r\nif (ring->unaligned)\r\nbgmac_dma_rx_enable(bgmac, ring);\r\nring->start = 0;\r\nring->end = 0;\r\nfor (j = 0; j < BGMAC_RX_RING_SLOTS; j++) {\r\nerr = bgmac_dma_rx_skb_for_slot(bgmac, &ring->slots[j]);\r\nif (err)\r\ngoto error;\r\nbgmac_dma_rx_setup_desc(bgmac, ring, j);\r\n}\r\nbgmac_dma_rx_update_index(bgmac, ring);\r\n}\r\nreturn 0;\r\nerror:\r\nbgmac_dma_cleanup(bgmac);\r\nreturn err;\r\n}\r\nstatic void bgmac_cmdcfg_maskset(struct bgmac *bgmac, u32 mask, u32 set,\r\nbool force)\r\n{\r\nu32 cmdcfg = bgmac_read(bgmac, BGMAC_CMDCFG);\r\nu32 new_val = (cmdcfg & mask) | set;\r\nu32 cmdcfg_sr;\r\nif (bgmac->feature_flags & BGMAC_FEAT_CMDCFG_SR_REV4)\r\ncmdcfg_sr = BGMAC_CMDCFG_SR_REV4;\r\nelse\r\ncmdcfg_sr = BGMAC_CMDCFG_SR_REV0;\r\nbgmac_set(bgmac, BGMAC_CMDCFG, cmdcfg_sr);\r\nudelay(2);\r\nif (new_val != cmdcfg || force)\r\nbgmac_write(bgmac, BGMAC_CMDCFG, new_val);\r\nbgmac_mask(bgmac, BGMAC_CMDCFG, ~cmdcfg_sr);\r\nudelay(2);\r\n}\r\nstatic void bgmac_write_mac_address(struct bgmac *bgmac, u8 *addr)\r\n{\r\nu32 tmp;\r\ntmp = (addr[0] << 24) | (addr[1] << 16) | (addr[2] << 8) | addr[3];\r\nbgmac_write(bgmac, BGMAC_MACADDR_HIGH, tmp);\r\ntmp = (addr[4] << 8) | addr[5];\r\nbgmac_write(bgmac, BGMAC_MACADDR_LOW, tmp);\r\n}\r\nstatic void bgmac_set_rx_mode(struct net_device *net_dev)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(net_dev);\r\nif (net_dev->flags & IFF_PROMISC)\r\nbgmac_cmdcfg_maskset(bgmac, ~0, BGMAC_CMDCFG_PROM, true);\r\nelse\r\nbgmac_cmdcfg_maskset(bgmac, ~BGMAC_CMDCFG_PROM, 0, true);\r\n}\r\nstatic void bgmac_clear_mib(struct bgmac *bgmac)\r\n{\r\nint i;\r\nif (bgmac->feature_flags & BGMAC_FEAT_NO_CLR_MIB)\r\nreturn;\r\nbgmac_set(bgmac, BGMAC_DEV_CTL, BGMAC_DC_MROR);\r\nfor (i = 0; i < BGMAC_NUM_MIB_TX_REGS; i++)\r\nbgmac_read(bgmac, BGMAC_TX_GOOD_OCTETS + (i * 4));\r\nfor (i = 0; i < BGMAC_NUM_MIB_RX_REGS; i++)\r\nbgmac_read(bgmac, BGMAC_RX_GOOD_OCTETS + (i * 4));\r\n}\r\nstatic void bgmac_mac_speed(struct bgmac *bgmac)\r\n{\r\nu32 mask = ~(BGMAC_CMDCFG_ES_MASK | BGMAC_CMDCFG_HD);\r\nu32 set = 0;\r\nswitch (bgmac->mac_speed) {\r\ncase SPEED_10:\r\nset |= BGMAC_CMDCFG_ES_10;\r\nbreak;\r\ncase SPEED_100:\r\nset |= BGMAC_CMDCFG_ES_100;\r\nbreak;\r\ncase SPEED_1000:\r\nset |= BGMAC_CMDCFG_ES_1000;\r\nbreak;\r\ncase SPEED_2500:\r\nset |= BGMAC_CMDCFG_ES_2500;\r\nbreak;\r\ndefault:\r\ndev_err(bgmac->dev, "Unsupported speed: %d\n",\r\nbgmac->mac_speed);\r\n}\r\nif (bgmac->mac_duplex == DUPLEX_HALF)\r\nset |= BGMAC_CMDCFG_HD;\r\nbgmac_cmdcfg_maskset(bgmac, mask, set, true);\r\n}\r\nstatic void bgmac_miiconfig(struct bgmac *bgmac)\r\n{\r\nif (bgmac->feature_flags & BGMAC_FEAT_FORCE_SPEED_2500) {\r\nif (!(bgmac->feature_flags & BGMAC_FEAT_IDM_MASK)) {\r\nbgmac_idm_write(bgmac, BCMA_IOCTL,\r\nbgmac_idm_read(bgmac, BCMA_IOCTL) |\r\n0x40 | BGMAC_BCMA_IOCTL_SW_CLKEN);\r\n}\r\nbgmac->mac_speed = SPEED_2500;\r\nbgmac->mac_duplex = DUPLEX_FULL;\r\nbgmac_mac_speed(bgmac);\r\n} else {\r\nu8 imode;\r\nimode = (bgmac_read(bgmac, BGMAC_DEV_STATUS) &\r\nBGMAC_DS_MM_MASK) >> BGMAC_DS_MM_SHIFT;\r\nif (imode == 0 || imode == 1) {\r\nbgmac->mac_speed = SPEED_100;\r\nbgmac->mac_duplex = DUPLEX_FULL;\r\nbgmac_mac_speed(bgmac);\r\n}\r\n}\r\n}\r\nstatic void bgmac_chip_reset_idm_config(struct bgmac *bgmac)\r\n{\r\nu32 iost;\r\niost = bgmac_idm_read(bgmac, BCMA_IOST);\r\nif (bgmac->feature_flags & BGMAC_FEAT_IOST_ATTACHED)\r\niost &= ~BGMAC_BCMA_IOST_ATTACHED;\r\nif (!(bgmac->feature_flags & BGMAC_FEAT_NO_RESET)) {\r\nu32 flags = 0;\r\nif (iost & BGMAC_BCMA_IOST_ATTACHED) {\r\nflags = BGMAC_BCMA_IOCTL_SW_CLKEN;\r\nif (!bgmac->has_robosw)\r\nflags |= BGMAC_BCMA_IOCTL_SW_RESET;\r\n}\r\nbgmac_clk_enable(bgmac, flags);\r\n}\r\nif (iost & BGMAC_BCMA_IOST_ATTACHED && !bgmac->has_robosw)\r\nbgmac_idm_write(bgmac, BCMA_IOCTL,\r\nbgmac_idm_read(bgmac, BCMA_IOCTL) &\r\n~BGMAC_BCMA_IOCTL_SW_RESET);\r\n}\r\nstatic void bgmac_chip_reset(struct bgmac *bgmac)\r\n{\r\nu32 cmdcfg_sr;\r\nint i;\r\nif (bgmac_clk_enabled(bgmac)) {\r\nif (!bgmac->stats_grabbed) {\r\nbgmac->stats_grabbed = true;\r\n}\r\nfor (i = 0; i < BGMAC_MAX_TX_RINGS; i++)\r\nbgmac_dma_tx_reset(bgmac, &bgmac->tx_ring[i]);\r\nbgmac_cmdcfg_maskset(bgmac, ~0, BGMAC_CMDCFG_ML, false);\r\nudelay(1);\r\nfor (i = 0; i < BGMAC_MAX_RX_RINGS; i++)\r\nbgmac_dma_rx_reset(bgmac, &bgmac->rx_ring[i]);\r\n}\r\nif (!(bgmac->feature_flags & BGMAC_FEAT_IDM_MASK))\r\nbgmac_chip_reset_idm_config(bgmac);\r\nif (bgmac->feature_flags & BGMAC_FEAT_MISC_PLL_REQ) {\r\nbgmac_set(bgmac, BCMA_CLKCTLST,\r\nBGMAC_BCMA_CLKCTLST_MISC_PLL_REQ);\r\nbgmac_wait_value(bgmac, BCMA_CLKCTLST,\r\nBGMAC_BCMA_CLKCTLST_MISC_PLL_ST,\r\nBGMAC_BCMA_CLKCTLST_MISC_PLL_ST,\r\n1000);\r\n}\r\nif (bgmac->feature_flags & BGMAC_FEAT_SW_TYPE_PHY) {\r\nu8 et_swtype = 0;\r\nu8 sw_type = BGMAC_CHIPCTL_1_SW_TYPE_EPHY |\r\nBGMAC_CHIPCTL_1_IF_TYPE_MII;\r\nchar buf[4];\r\nif (bcm47xx_nvram_getenv("et_swtype", buf, sizeof(buf)) > 0) {\r\nif (kstrtou8(buf, 0, &et_swtype))\r\ndev_err(bgmac->dev, "Failed to parse et_swtype (%s)\n",\r\nbuf);\r\net_swtype &= 0x0f;\r\net_swtype <<= 4;\r\nsw_type = et_swtype;\r\n} else if (bgmac->feature_flags & BGMAC_FEAT_SW_TYPE_EPHYRMII) {\r\nsw_type = BGMAC_CHIPCTL_1_IF_TYPE_RMII |\r\nBGMAC_CHIPCTL_1_SW_TYPE_EPHYRMII;\r\n} else if (bgmac->feature_flags & BGMAC_FEAT_SW_TYPE_RGMII) {\r\nsw_type = BGMAC_CHIPCTL_1_IF_TYPE_RGMII |\r\nBGMAC_CHIPCTL_1_SW_TYPE_RGMII;\r\n}\r\nbgmac_cco_ctl_maskset(bgmac, 1, ~(BGMAC_CHIPCTL_1_IF_TYPE_MASK |\r\nBGMAC_CHIPCTL_1_SW_TYPE_MASK),\r\nsw_type);\r\n} else if (bgmac->feature_flags & BGMAC_FEAT_CC4_IF_SW_TYPE) {\r\nu32 sw_type = BGMAC_CHIPCTL_4_IF_TYPE_MII |\r\nBGMAC_CHIPCTL_4_SW_TYPE_EPHY;\r\nu8 et_swtype = 0;\r\nchar buf[4];\r\nif (bcm47xx_nvram_getenv("et_swtype", buf, sizeof(buf)) > 0) {\r\nif (kstrtou8(buf, 0, &et_swtype))\r\ndev_err(bgmac->dev, "Failed to parse et_swtype (%s)\n",\r\nbuf);\r\nsw_type = (et_swtype & 0x0f) << 12;\r\n} else if (bgmac->feature_flags & BGMAC_FEAT_CC4_IF_SW_TYPE_RGMII) {\r\nsw_type = BGMAC_CHIPCTL_4_IF_TYPE_RGMII |\r\nBGMAC_CHIPCTL_4_SW_TYPE_RGMII;\r\n}\r\nbgmac_cco_ctl_maskset(bgmac, 4, ~(BGMAC_CHIPCTL_4_IF_TYPE_MASK |\r\nBGMAC_CHIPCTL_4_SW_TYPE_MASK),\r\nsw_type);\r\n} else if (bgmac->feature_flags & BGMAC_FEAT_CC7_IF_TYPE_RGMII) {\r\nbgmac_cco_ctl_maskset(bgmac, 7, ~BGMAC_CHIPCTL_7_IF_TYPE_MASK,\r\nBGMAC_CHIPCTL_7_IF_TYPE_RGMII);\r\n}\r\nif (bgmac->feature_flags & BGMAC_FEAT_CMDCFG_SR_REV4)\r\ncmdcfg_sr = BGMAC_CMDCFG_SR_REV4;\r\nelse\r\ncmdcfg_sr = BGMAC_CMDCFG_SR_REV0;\r\nbgmac_cmdcfg_maskset(bgmac,\r\n~(BGMAC_CMDCFG_TE |\r\nBGMAC_CMDCFG_RE |\r\nBGMAC_CMDCFG_RPI |\r\nBGMAC_CMDCFG_TAI |\r\nBGMAC_CMDCFG_HD |\r\nBGMAC_CMDCFG_ML |\r\nBGMAC_CMDCFG_CFE |\r\nBGMAC_CMDCFG_RL |\r\nBGMAC_CMDCFG_RED |\r\nBGMAC_CMDCFG_PE |\r\nBGMAC_CMDCFG_TPI |\r\nBGMAC_CMDCFG_PAD_EN |\r\nBGMAC_CMDCFG_PF),\r\nBGMAC_CMDCFG_PROM |\r\nBGMAC_CMDCFG_NLC |\r\nBGMAC_CMDCFG_CFE |\r\ncmdcfg_sr,\r\nfalse);\r\nbgmac->mac_speed = SPEED_UNKNOWN;\r\nbgmac->mac_duplex = DUPLEX_UNKNOWN;\r\nbgmac_clear_mib(bgmac);\r\nif (bgmac->feature_flags & BGMAC_FEAT_CMN_PHY_CTL)\r\nbgmac_cmn_maskset32(bgmac, BCMA_GMAC_CMN_PHY_CTL, ~0,\r\nBCMA_GMAC_CMN_PC_MTE);\r\nelse\r\nbgmac_set(bgmac, BGMAC_PHY_CNTL, BGMAC_PC_MTE);\r\nbgmac_miiconfig(bgmac);\r\nif (bgmac->mii_bus)\r\nbgmac->mii_bus->reset(bgmac->mii_bus);\r\nnetdev_reset_queue(bgmac->net_dev);\r\n}\r\nstatic void bgmac_chip_intrs_on(struct bgmac *bgmac)\r\n{\r\nbgmac_write(bgmac, BGMAC_INT_MASK, bgmac->int_mask);\r\n}\r\nstatic void bgmac_chip_intrs_off(struct bgmac *bgmac)\r\n{\r\nbgmac_write(bgmac, BGMAC_INT_MASK, 0);\r\nbgmac_read(bgmac, BGMAC_INT_MASK);\r\n}\r\nstatic void bgmac_enable(struct bgmac *bgmac)\r\n{\r\nu32 cmdcfg_sr;\r\nu32 cmdcfg;\r\nu32 mode;\r\nif (bgmac->feature_flags & BGMAC_FEAT_CMDCFG_SR_REV4)\r\ncmdcfg_sr = BGMAC_CMDCFG_SR_REV4;\r\nelse\r\ncmdcfg_sr = BGMAC_CMDCFG_SR_REV0;\r\ncmdcfg = bgmac_read(bgmac, BGMAC_CMDCFG);\r\nbgmac_cmdcfg_maskset(bgmac, ~(BGMAC_CMDCFG_TE | BGMAC_CMDCFG_RE),\r\ncmdcfg_sr, true);\r\nudelay(2);\r\ncmdcfg |= BGMAC_CMDCFG_TE | BGMAC_CMDCFG_RE;\r\nbgmac_write(bgmac, BGMAC_CMDCFG, cmdcfg);\r\nmode = (bgmac_read(bgmac, BGMAC_DEV_STATUS) & BGMAC_DS_MM_MASK) >>\r\nBGMAC_DS_MM_SHIFT;\r\nif (bgmac->feature_flags & BGMAC_FEAT_CLKCTLST || mode != 0)\r\nbgmac_set(bgmac, BCMA_CLKCTLST, BCMA_CLKCTLST_FORCEHT);\r\nif (!(bgmac->feature_flags & BGMAC_FEAT_CLKCTLST) && mode == 2)\r\nbgmac_cco_ctl_maskset(bgmac, 1, ~0,\r\nBGMAC_CHIPCTL_1_RXC_DLL_BYPASS);\r\nif (bgmac->feature_flags & (BGMAC_FEAT_FLW_CTRL1 |\r\nBGMAC_FEAT_FLW_CTRL2)) {\r\nu32 fl_ctl;\r\nif (bgmac->feature_flags & BGMAC_FEAT_FLW_CTRL1)\r\nfl_ctl = 0x2300e1;\r\nelse\r\nfl_ctl = 0x03cb04cb;\r\nbgmac_write(bgmac, BGMAC_FLOW_CTL_THRESH, fl_ctl);\r\nbgmac_write(bgmac, BGMAC_PAUSE_CTL, 0x27fff);\r\n}\r\nif (bgmac->feature_flags & BGMAC_FEAT_SET_RXQ_CLK) {\r\nu32 rxq_ctl;\r\nu16 bp_clk;\r\nu8 mdp;\r\nrxq_ctl = bgmac_read(bgmac, BGMAC_RXQ_CTL);\r\nrxq_ctl &= ~BGMAC_RXQ_CTL_MDP_MASK;\r\nbp_clk = bgmac_get_bus_clock(bgmac) / 1000000;\r\nmdp = (bp_clk * 128 / 1000) - 3;\r\nrxq_ctl |= (mdp << BGMAC_RXQ_CTL_MDP_SHIFT);\r\nbgmac_write(bgmac, BGMAC_RXQ_CTL, rxq_ctl);\r\n}\r\n}\r\nstatic void bgmac_chip_init(struct bgmac *bgmac)\r\n{\r\nbgmac_write(bgmac, BGMAC_INT_STATUS, ~0);\r\nbgmac_write(bgmac, BGMAC_INT_RECV_LAZY, 1 << BGMAC_IRL_FC_SHIFT);\r\nbgmac_cmdcfg_maskset(bgmac, ~BGMAC_CMDCFG_RPI, 0, true);\r\nbgmac_set_rx_mode(bgmac->net_dev);\r\nbgmac_write_mac_address(bgmac, bgmac->net_dev->dev_addr);\r\nif (bgmac->loopback)\r\nbgmac_cmdcfg_maskset(bgmac, ~0, BGMAC_CMDCFG_ML, false);\r\nelse\r\nbgmac_cmdcfg_maskset(bgmac, ~BGMAC_CMDCFG_ML, 0, false);\r\nbgmac_write(bgmac, BGMAC_RXMAX_LENGTH, 32 + ETHER_MAX_LEN);\r\nbgmac_chip_intrs_on(bgmac);\r\nbgmac_enable(bgmac);\r\n}\r\nstatic irqreturn_t bgmac_interrupt(int irq, void *dev_id)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(dev_id);\r\nu32 int_status = bgmac_read(bgmac, BGMAC_INT_STATUS);\r\nint_status &= bgmac->int_mask;\r\nif (!int_status)\r\nreturn IRQ_NONE;\r\nint_status &= ~(BGMAC_IS_TX0 | BGMAC_IS_RX);\r\nif (int_status)\r\ndev_err(bgmac->dev, "Unknown IRQs: 0x%08X\n", int_status);\r\nbgmac_chip_intrs_off(bgmac);\r\nnapi_schedule(&bgmac->napi);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int bgmac_poll(struct napi_struct *napi, int weight)\r\n{\r\nstruct bgmac *bgmac = container_of(napi, struct bgmac, napi);\r\nint handled = 0;\r\nbgmac_write(bgmac, BGMAC_INT_STATUS, ~0);\r\nbgmac_dma_tx_free(bgmac, &bgmac->tx_ring[0]);\r\nhandled += bgmac_dma_rx_read(bgmac, &bgmac->rx_ring[0], weight);\r\nif (bgmac_read(bgmac, BGMAC_INT_STATUS) & (BGMAC_IS_TX0 | BGMAC_IS_RX))\r\nreturn weight;\r\nif (handled < weight) {\r\nnapi_complete_done(napi, handled);\r\nbgmac_chip_intrs_on(bgmac);\r\n}\r\nreturn handled;\r\n}\r\nstatic int bgmac_open(struct net_device *net_dev)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(net_dev);\r\nint err = 0;\r\nbgmac_chip_reset(bgmac);\r\nerr = bgmac_dma_init(bgmac);\r\nif (err)\r\nreturn err;\r\nbgmac_chip_init(bgmac);\r\nerr = request_irq(bgmac->irq, bgmac_interrupt, IRQF_SHARED,\r\nKBUILD_MODNAME, net_dev);\r\nif (err < 0) {\r\ndev_err(bgmac->dev, "IRQ request error: %d!\n", err);\r\nbgmac_dma_cleanup(bgmac);\r\nreturn err;\r\n}\r\nnapi_enable(&bgmac->napi);\r\nphy_start(net_dev->phydev);\r\nnetif_start_queue(net_dev);\r\nreturn 0;\r\n}\r\nstatic int bgmac_stop(struct net_device *net_dev)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(net_dev);\r\nnetif_carrier_off(net_dev);\r\nphy_stop(net_dev->phydev);\r\nnapi_disable(&bgmac->napi);\r\nbgmac_chip_intrs_off(bgmac);\r\nfree_irq(bgmac->irq, net_dev);\r\nbgmac_chip_reset(bgmac);\r\nbgmac_dma_cleanup(bgmac);\r\nreturn 0;\r\n}\r\nstatic netdev_tx_t bgmac_start_xmit(struct sk_buff *skb,\r\nstruct net_device *net_dev)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(net_dev);\r\nstruct bgmac_dma_ring *ring;\r\nring = &bgmac->tx_ring[0];\r\nreturn bgmac_dma_tx_add(bgmac, ring, skb);\r\n}\r\nstatic int bgmac_set_mac_address(struct net_device *net_dev, void *addr)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(net_dev);\r\nstruct sockaddr *sa = addr;\r\nint ret;\r\nret = eth_prepare_mac_addr_change(net_dev, addr);\r\nif (ret < 0)\r\nreturn ret;\r\nether_addr_copy(net_dev->dev_addr, sa->sa_data);\r\nbgmac_write_mac_address(bgmac, net_dev->dev_addr);\r\neth_commit_mac_addr_change(net_dev, addr);\r\nreturn 0;\r\n}\r\nstatic int bgmac_ioctl(struct net_device *net_dev, struct ifreq *ifr, int cmd)\r\n{\r\nif (!netif_running(net_dev))\r\nreturn -EINVAL;\r\nreturn phy_mii_ioctl(net_dev->phydev, ifr, cmd);\r\n}\r\nstatic int bgmac_get_sset_count(struct net_device *dev, int string_set)\r\n{\r\nswitch (string_set) {\r\ncase ETH_SS_STATS:\r\nreturn BGMAC_STATS_LEN;\r\n}\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic void bgmac_get_strings(struct net_device *dev, u32 stringset,\r\nu8 *data)\r\n{\r\nint i;\r\nif (stringset != ETH_SS_STATS)\r\nreturn;\r\nfor (i = 0; i < BGMAC_STATS_LEN; i++)\r\nstrlcpy(data + i * ETH_GSTRING_LEN,\r\nbgmac_get_strings_stats[i].name, ETH_GSTRING_LEN);\r\n}\r\nstatic void bgmac_get_ethtool_stats(struct net_device *dev,\r\nstruct ethtool_stats *ss, uint64_t *data)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(dev);\r\nconst struct bgmac_stat *s;\r\nunsigned int i;\r\nu64 val;\r\nif (!netif_running(dev))\r\nreturn;\r\nfor (i = 0; i < BGMAC_STATS_LEN; i++) {\r\ns = &bgmac_get_strings_stats[i];\r\nval = 0;\r\nif (s->size == 8)\r\nval = (u64)bgmac_read(bgmac, s->offset + 4) << 32;\r\nval |= bgmac_read(bgmac, s->offset);\r\ndata[i] = val;\r\n}\r\n}\r\nstatic void bgmac_get_drvinfo(struct net_device *net_dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstrlcpy(info->driver, KBUILD_MODNAME, sizeof(info->driver));\r\nstrlcpy(info->bus_info, "AXI", sizeof(info->bus_info));\r\n}\r\nvoid bgmac_adjust_link(struct net_device *net_dev)\r\n{\r\nstruct bgmac *bgmac = netdev_priv(net_dev);\r\nstruct phy_device *phy_dev = net_dev->phydev;\r\nbool update = false;\r\nif (phy_dev->link) {\r\nif (phy_dev->speed != bgmac->mac_speed) {\r\nbgmac->mac_speed = phy_dev->speed;\r\nupdate = true;\r\n}\r\nif (phy_dev->duplex != bgmac->mac_duplex) {\r\nbgmac->mac_duplex = phy_dev->duplex;\r\nupdate = true;\r\n}\r\n}\r\nif (update) {\r\nbgmac_mac_speed(bgmac);\r\nphy_print_status(phy_dev);\r\n}\r\n}\r\nint bgmac_phy_connect_direct(struct bgmac *bgmac)\r\n{\r\nstruct fixed_phy_status fphy_status = {\r\n.link = 1,\r\n.speed = SPEED_1000,\r\n.duplex = DUPLEX_FULL,\r\n};\r\nstruct phy_device *phy_dev;\r\nint err;\r\nphy_dev = fixed_phy_register(PHY_POLL, &fphy_status, -1, NULL);\r\nif (!phy_dev || IS_ERR(phy_dev)) {\r\ndev_err(bgmac->dev, "Failed to register fixed PHY device\n");\r\nreturn -ENODEV;\r\n}\r\nerr = phy_connect_direct(bgmac->net_dev, phy_dev, bgmac_adjust_link,\r\nPHY_INTERFACE_MODE_MII);\r\nif (err) {\r\ndev_err(bgmac->dev, "Connecting PHY failed\n");\r\nreturn err;\r\n}\r\nreturn err;\r\n}\r\nstruct bgmac *bgmac_alloc(struct device *dev)\r\n{\r\nstruct net_device *net_dev;\r\nstruct bgmac *bgmac;\r\nnet_dev = devm_alloc_etherdev(dev, sizeof(*bgmac));\r\nif (!net_dev)\r\nreturn NULL;\r\nnet_dev->netdev_ops = &bgmac_netdev_ops;\r\nnet_dev->ethtool_ops = &bgmac_ethtool_ops;\r\nbgmac = netdev_priv(net_dev);\r\nbgmac->dev = dev;\r\nbgmac->net_dev = net_dev;\r\nreturn bgmac;\r\n}\r\nint bgmac_enet_probe(struct bgmac *bgmac)\r\n{\r\nstruct net_device *net_dev = bgmac->net_dev;\r\nint err;\r\nnet_dev->irq = bgmac->irq;\r\nSET_NETDEV_DEV(net_dev, bgmac->dev);\r\ndev_set_drvdata(bgmac->dev, bgmac);\r\nif (!is_valid_ether_addr(net_dev->dev_addr)) {\r\ndev_err(bgmac->dev, "Invalid MAC addr: %pM\n",\r\nnet_dev->dev_addr);\r\neth_hw_addr_random(net_dev);\r\ndev_warn(bgmac->dev, "Using random MAC: %pM\n",\r\nnet_dev->dev_addr);\r\n}\r\nbgmac_clk_enable(bgmac, 0);\r\nif (!(bgmac->feature_flags & BGMAC_FEAT_IDM_MASK)) {\r\nif (bgmac->feature_flags & BGMAC_FEAT_IRQ_ID_OOB_6)\r\nbgmac_idm_write(bgmac, BCMA_OOB_SEL_OUT_A30, 0x86);\r\n}\r\nbgmac_chip_reset(bgmac);\r\nerr = bgmac_dma_alloc(bgmac);\r\nif (err) {\r\ndev_err(bgmac->dev, "Unable to alloc memory for DMA\n");\r\ngoto err_out;\r\n}\r\nbgmac->int_mask = BGMAC_IS_ERRMASK | BGMAC_IS_RX | BGMAC_IS_TX_MASK;\r\nif (bcm47xx_nvram_getenv("et0_no_txint", NULL, 0) == 0)\r\nbgmac->int_mask &= ~BGMAC_IS_TX_MASK;\r\nnetif_napi_add(net_dev, &bgmac->napi, bgmac_poll, BGMAC_WEIGHT);\r\nerr = bgmac_phy_connect(bgmac);\r\nif (err) {\r\ndev_err(bgmac->dev, "Cannot connect to phy\n");\r\ngoto err_dma_free;\r\n}\r\nnet_dev->features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM;\r\nnet_dev->hw_features = net_dev->features;\r\nnet_dev->vlan_features = net_dev->features;\r\nerr = register_netdev(bgmac->net_dev);\r\nif (err) {\r\ndev_err(bgmac->dev, "Cannot register net device\n");\r\ngoto err_phy_disconnect;\r\n}\r\nnetif_carrier_off(net_dev);\r\nreturn 0;\r\nerr_phy_disconnect:\r\nphy_disconnect(net_dev->phydev);\r\nerr_dma_free:\r\nbgmac_dma_free(bgmac);\r\nerr_out:\r\nreturn err;\r\n}\r\nvoid bgmac_enet_remove(struct bgmac *bgmac)\r\n{\r\nunregister_netdev(bgmac->net_dev);\r\nphy_disconnect(bgmac->net_dev->phydev);\r\nnetif_napi_del(&bgmac->napi);\r\nbgmac_dma_free(bgmac);\r\nfree_netdev(bgmac->net_dev);\r\n}\r\nint bgmac_enet_suspend(struct bgmac *bgmac)\r\n{\r\nif (!netif_running(bgmac->net_dev))\r\nreturn 0;\r\nphy_stop(bgmac->net_dev->phydev);\r\nnetif_stop_queue(bgmac->net_dev);\r\nnapi_disable(&bgmac->napi);\r\nnetif_tx_lock(bgmac->net_dev);\r\nnetif_device_detach(bgmac->net_dev);\r\nnetif_tx_unlock(bgmac->net_dev);\r\nbgmac_chip_intrs_off(bgmac);\r\nbgmac_chip_reset(bgmac);\r\nbgmac_dma_cleanup(bgmac);\r\nreturn 0;\r\n}\r\nint bgmac_enet_resume(struct bgmac *bgmac)\r\n{\r\nint rc;\r\nif (!netif_running(bgmac->net_dev))\r\nreturn 0;\r\nrc = bgmac_dma_init(bgmac);\r\nif (rc)\r\nreturn rc;\r\nbgmac_chip_init(bgmac);\r\nnapi_enable(&bgmac->napi);\r\nnetif_tx_lock(bgmac->net_dev);\r\nnetif_device_attach(bgmac->net_dev);\r\nnetif_tx_unlock(bgmac->net_dev);\r\nnetif_start_queue(bgmac->net_dev);\r\nphy_start(bgmac->net_dev->phydev);\r\nreturn 0;\r\n}
