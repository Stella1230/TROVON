void memory_present(int nid, unsigned long start, unsigned long end)\r\n{\r\nunsigned long pfn;\r\nprintk(KERN_INFO "Node: %d, start_pfn: %lx, end_pfn: %lx\n",\r\nnid, start, end);\r\nprintk(KERN_DEBUG " Setting physnode_map array to node %d for pfns:\n", nid);\r\nprintk(KERN_DEBUG " ");\r\nstart = round_down(start, PAGES_PER_SECTION);\r\nend = round_up(end, PAGES_PER_SECTION);\r\nfor (pfn = start; pfn < end; pfn += PAGES_PER_SECTION) {\r\nphysnode_map[pfn / PAGES_PER_SECTION] = nid;\r\nprintk(KERN_CONT "%lx ", pfn);\r\n}\r\nprintk(KERN_CONT "\n");\r\n}\r\nunsigned long node_memmap_size_bytes(int nid, unsigned long start_pfn,\r\nunsigned long end_pfn)\r\n{\r\nunsigned long nr_pages = end_pfn - start_pfn;\r\nif (!nr_pages)\r\nreturn 0;\r\nreturn (nr_pages + 1) * sizeof(struct page);\r\n}\r\nvoid __init initmem_init(void)\r\n{\r\nx86_numa_init();\r\n#ifdef CONFIG_HIGHMEM\r\nhighstart_pfn = highend_pfn = max_pfn;\r\nif (max_pfn > max_low_pfn)\r\nhighstart_pfn = max_low_pfn;\r\nprintk(KERN_NOTICE "%ldMB HIGHMEM available.\n",\r\npages_to_mb(highend_pfn - highstart_pfn));\r\nhigh_memory = (void *) __va(highstart_pfn * PAGE_SIZE - 1) + 1;\r\n#else\r\nhigh_memory = (void *) __va(max_low_pfn * PAGE_SIZE - 1) + 1;\r\n#endif\r\nprintk(KERN_NOTICE "%ldMB LOWMEM available.\n",\r\npages_to_mb(max_low_pfn));\r\nprintk(KERN_DEBUG "max_low_pfn = %lx, highstart_pfn = %lx\n",\r\nmax_low_pfn, highstart_pfn);\r\nprintk(KERN_DEBUG "Low memory ends at vaddr %08lx\n",\r\n(ulong) pfn_to_kaddr(max_low_pfn));\r\nprintk(KERN_DEBUG "High memory starts at vaddr %08lx\n",\r\n(ulong) pfn_to_kaddr(highstart_pfn));\r\n__vmalloc_start_set = true;\r\nsetup_bootmem_allocator();\r\n}
