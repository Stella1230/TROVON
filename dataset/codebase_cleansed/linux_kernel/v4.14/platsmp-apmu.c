static int __maybe_unused apmu_power_on(void __iomem *p, int bit)\r\n{\r\nwritel_relaxed(BIT(bit), p + WUPCR_OFFS);\r\nwhile (readl_relaxed(p + WUPCR_OFFS) != 0)\r\n;\r\nreturn 0;\r\n}\r\nstatic int __maybe_unused apmu_power_off(void __iomem *p, int bit)\r\n{\r\nwritel_relaxed(3, p + CPUNCR_OFFS(bit));\r\nreturn 0;\r\n}\r\nstatic int __maybe_unused apmu_power_off_poll(void __iomem *p, int bit)\r\n{\r\nint k;\r\nfor (k = 0; k < 1000; k++) {\r\nif (CPUNST(readl_relaxed(p + PSTR_OFFS), bit) == CPUST_STANDBY)\r\nreturn 1;\r\nmdelay(1);\r\n}\r\nreturn 0;\r\n}\r\nstatic int __maybe_unused apmu_wrap(int cpu, int (*fn)(void __iomem *p, int cpu))\r\n{\r\nvoid __iomem *p = apmu_cpus[cpu].iomem;\r\nreturn p ? fn(p, apmu_cpus[cpu].bit) : -EINVAL;\r\n}\r\nstatic void apmu_init_cpu(struct resource *res, int cpu, int bit)\r\n{\r\nu32 x;\r\nif ((cpu >= ARRAY_SIZE(apmu_cpus)) || apmu_cpus[cpu].iomem)\r\nreturn;\r\napmu_cpus[cpu].iomem = ioremap_nocache(res->start, resource_size(res));\r\napmu_cpus[cpu].bit = bit;\r\npr_debug("apmu ioremap %d %d %pr\n", cpu, bit, res);\r\nx = readl(apmu_cpus[cpu].iomem + DBGRCR_OFFS);\r\nx |= DBGCPUREN | DBGCPUNREN(bit) | DBGCPUPREN;\r\nwritel(x, apmu_cpus[cpu].iomem + DBGRCR_OFFS);\r\n}\r\nstatic void apmu_parse_cfg(void (*fn)(struct resource *res, int cpu, int bit),\r\nstruct rcar_apmu_config *apmu_config, int num)\r\n{\r\nint id;\r\nint k;\r\nint bit, index;\r\nbool is_allowed;\r\nfor (k = 0; k < num; k++) {\r\nis_allowed = false;\r\nfor (bit = 0; bit < ARRAY_SIZE(apmu_config[k].cpus); bit++) {\r\nid = apmu_config[k].cpus[bit];\r\nif (id >= 0) {\r\nif (id == cpu_logical_map(0))\r\nis_allowed = true;\r\n}\r\n}\r\nif (!is_allowed)\r\ncontinue;\r\nfor (bit = 0; bit < ARRAY_SIZE(apmu_config[k].cpus); bit++) {\r\nid = apmu_config[k].cpus[bit];\r\nif (id >= 0) {\r\nindex = get_logical_index(id);\r\nif (index >= 0)\r\nfn(&apmu_config[k].iomem, index, bit);\r\n}\r\n}\r\n}\r\n}\r\nstatic void apmu_parse_dt(void (*fn)(struct resource *res, int cpu, int bit))\r\n{\r\nstruct device_node *np_apmu, *np_cpu;\r\nstruct resource res;\r\nint bit, index;\r\nu32 id;\r\nfor_each_matching_node(np_apmu, apmu_ids) {\r\nbool is_allowed = false;\r\nfor (bit = 0; bit < CONFIG_NR_CPUS; bit++) {\r\nnp_cpu = of_parse_phandle(np_apmu, "cpus", bit);\r\nif (np_cpu) {\r\nif (!of_property_read_u32(np_cpu, "reg", &id)) {\r\nif (id == cpu_logical_map(0)) {\r\nis_allowed = true;\r\nof_node_put(np_cpu);\r\nbreak;\r\n}\r\n}\r\nof_node_put(np_cpu);\r\n}\r\n}\r\nif (!is_allowed)\r\ncontinue;\r\nfor (bit = 0; bit < CONFIG_NR_CPUS; bit++) {\r\nnp_cpu = of_parse_phandle(np_apmu, "cpus", bit);\r\nif (np_cpu) {\r\nif (!of_property_read_u32(np_cpu, "reg", &id)) {\r\nindex = get_logical_index(id);\r\nif ((index >= 0) &&\r\n!of_address_to_resource(np_apmu,\r\n0, &res))\r\nfn(&res, index, bit);\r\n}\r\nof_node_put(np_cpu);\r\n}\r\n}\r\n}\r\n}\r\nstatic void __init shmobile_smp_apmu_setup_boot(void)\r\n{\r\nshmobile_boot_fn = __pa_symbol(shmobile_smp_boot);\r\n}\r\nvoid __init shmobile_smp_apmu_prepare_cpus(unsigned int max_cpus,\r\nstruct rcar_apmu_config *apmu_config,\r\nint num)\r\n{\r\nshmobile_smp_apmu_setup_boot();\r\napmu_parse_cfg(apmu_init_cpu, apmu_config, num);\r\n}\r\nint shmobile_smp_apmu_boot_secondary(unsigned int cpu, struct task_struct *idle)\r\n{\r\nshmobile_smp_hook(cpu, __pa_symbol(secondary_startup), 0);\r\nreturn apmu_wrap(cpu, apmu_power_on);\r\n}\r\nstatic void __init shmobile_smp_apmu_prepare_cpus_dt(unsigned int max_cpus)\r\n{\r\nshmobile_smp_apmu_setup_boot();\r\napmu_parse_dt(apmu_init_cpu);\r\nrcar_gen2_pm_init();\r\n}\r\nstatic inline void cpu_enter_lowpower_a15(void)\r\n{\r\nunsigned int v;\r\nasm volatile(\r\n" mrc p15, 0, %0, c1, c0, 0\n"\r\n" bic %0, %0, %1\n"\r\n" mcr p15, 0, %0, c1, c0, 0\n"\r\n: "=&r" (v)\r\n: "Ir" (CR_C)\r\n: "cc");\r\nflush_cache_louis();\r\nasm volatile(\r\n" mrc p15, 0, %0, c1, c0, 1\n"\r\n" bic %0, %0, %1\n"\r\n" mcr p15, 0, %0, c1, c0, 1\n"\r\n: "=&r" (v)\r\n: "Ir" (0x40)\r\n: "cc");\r\nisb();\r\ndsb();\r\n}\r\nstatic void shmobile_smp_apmu_cpu_shutdown(unsigned int cpu)\r\n{\r\napmu_wrap(cpu, apmu_power_off);\r\ncpu_enter_lowpower_a15();\r\n}\r\nstatic inline void cpu_leave_lowpower(void)\r\n{\r\nunsigned int v;\r\nasm volatile("mrc p15, 0, %0, c1, c0, 0\n"\r\n" orr %0, %0, %1\n"\r\n" mcr p15, 0, %0, c1, c0, 0\n"\r\n" mrc p15, 0, %0, c1, c0, 1\n"\r\n" orr %0, %0, %2\n"\r\n" mcr p15, 0, %0, c1, c0, 1\n"\r\n: "=&r" (v)\r\n: "Ir" (CR_C), "Ir" (0x40)\r\n: "cc");\r\n}\r\nvoid shmobile_smp_apmu_cpu_die(unsigned int cpu)\r\n{\r\nshmobile_smp_hook(cpu, 0, 0);\r\nshmobile_smp_apmu_cpu_shutdown(cpu);\r\nshmobile_smp_sleep();\r\n}\r\nint shmobile_smp_apmu_cpu_kill(unsigned int cpu)\r\n{\r\nreturn apmu_wrap(cpu, apmu_power_off_poll);\r\n}\r\nstatic int shmobile_smp_apmu_do_suspend(unsigned long cpu)\r\n{\r\nshmobile_smp_hook(cpu, __pa_symbol(cpu_resume), 0);\r\nshmobile_smp_apmu_cpu_shutdown(cpu);\r\ncpu_do_idle();\r\nreturn 1;\r\n}\r\nstatic int shmobile_smp_apmu_enter_suspend(suspend_state_t state)\r\n{\r\ncpu_suspend(smp_processor_id(), shmobile_smp_apmu_do_suspend);\r\ncpu_leave_lowpower();\r\nreturn 0;\r\n}\r\nvoid __init shmobile_smp_apmu_suspend_init(void)\r\n{\r\nshmobile_suspend_ops.enter = shmobile_smp_apmu_enter_suspend;\r\n}
