void tracing_map_update_sum(struct tracing_map_elt *elt, unsigned int i, u64 n)\r\n{\r\natomic64_add(n, &elt->fields[i].sum);\r\n}\r\nu64 tracing_map_read_sum(struct tracing_map_elt *elt, unsigned int i)\r\n{\r\nreturn (u64)atomic64_read(&elt->fields[i].sum);\r\n}\r\nint tracing_map_cmp_string(void *val_a, void *val_b)\r\n{\r\nchar *a = val_a;\r\nchar *b = val_b;\r\nreturn strcmp(a, b);\r\n}\r\nint tracing_map_cmp_none(void *val_a, void *val_b)\r\n{\r\nreturn 0;\r\n}\r\nstatic int tracing_map_cmp_atomic64(void *val_a, void *val_b)\r\n{\r\nu64 a = atomic64_read((atomic64_t *)val_a);\r\nu64 b = atomic64_read((atomic64_t *)val_b);\r\nreturn (a > b) ? 1 : ((a < b) ? -1 : 0);\r\n}\r\ntracing_map_cmp_fn_t tracing_map_cmp_num(int field_size,\r\nint field_is_signed)\r\n{\r\ntracing_map_cmp_fn_t fn = tracing_map_cmp_none;\r\nswitch (field_size) {\r\ncase 8:\r\nif (field_is_signed)\r\nfn = tracing_map_cmp_s64;\r\nelse\r\nfn = tracing_map_cmp_u64;\r\nbreak;\r\ncase 4:\r\nif (field_is_signed)\r\nfn = tracing_map_cmp_s32;\r\nelse\r\nfn = tracing_map_cmp_u32;\r\nbreak;\r\ncase 2:\r\nif (field_is_signed)\r\nfn = tracing_map_cmp_s16;\r\nelse\r\nfn = tracing_map_cmp_u16;\r\nbreak;\r\ncase 1:\r\nif (field_is_signed)\r\nfn = tracing_map_cmp_s8;\r\nelse\r\nfn = tracing_map_cmp_u8;\r\nbreak;\r\n}\r\nreturn fn;\r\n}\r\nstatic int tracing_map_add_field(struct tracing_map *map,\r\ntracing_map_cmp_fn_t cmp_fn)\r\n{\r\nint ret = -EINVAL;\r\nif (map->n_fields < TRACING_MAP_FIELDS_MAX) {\r\nret = map->n_fields;\r\nmap->fields[map->n_fields++].cmp_fn = cmp_fn;\r\n}\r\nreturn ret;\r\n}\r\nint tracing_map_add_sum_field(struct tracing_map *map)\r\n{\r\nreturn tracing_map_add_field(map, tracing_map_cmp_atomic64);\r\n}\r\nint tracing_map_add_key_field(struct tracing_map *map,\r\nunsigned int offset,\r\ntracing_map_cmp_fn_t cmp_fn)\r\n{\r\nint idx = tracing_map_add_field(map, cmp_fn);\r\nif (idx < 0)\r\nreturn idx;\r\nmap->fields[idx].offset = offset;\r\nmap->key_idx[map->n_keys++] = idx;\r\nreturn idx;\r\n}\r\nvoid tracing_map_array_clear(struct tracing_map_array *a)\r\n{\r\nunsigned int i;\r\nif (!a->pages)\r\nreturn;\r\nfor (i = 0; i < a->n_pages; i++)\r\nmemset(a->pages[i], 0, PAGE_SIZE);\r\n}\r\nvoid tracing_map_array_free(struct tracing_map_array *a)\r\n{\r\nunsigned int i;\r\nif (!a)\r\nreturn;\r\nif (!a->pages)\r\ngoto free;\r\nfor (i = 0; i < a->n_pages; i++) {\r\nif (!a->pages[i])\r\nbreak;\r\nfree_page((unsigned long)a->pages[i]);\r\n}\r\nkfree(a->pages);\r\nfree:\r\nkfree(a);\r\n}\r\nstruct tracing_map_array *tracing_map_array_alloc(unsigned int n_elts,\r\nunsigned int entry_size)\r\n{\r\nstruct tracing_map_array *a;\r\nunsigned int i;\r\na = kzalloc(sizeof(*a), GFP_KERNEL);\r\nif (!a)\r\nreturn NULL;\r\na->entry_size_shift = fls(roundup_pow_of_two(entry_size) - 1);\r\na->entries_per_page = PAGE_SIZE / (1 << a->entry_size_shift);\r\na->n_pages = n_elts / a->entries_per_page;\r\nif (!a->n_pages)\r\na->n_pages = 1;\r\na->entry_shift = fls(a->entries_per_page) - 1;\r\na->entry_mask = (1 << a->entry_shift) - 1;\r\na->pages = kcalloc(a->n_pages, sizeof(void *), GFP_KERNEL);\r\nif (!a->pages)\r\ngoto free;\r\nfor (i = 0; i < a->n_pages; i++) {\r\na->pages[i] = (void *)get_zeroed_page(GFP_KERNEL);\r\nif (!a->pages[i])\r\ngoto free;\r\n}\r\nout:\r\nreturn a;\r\nfree:\r\ntracing_map_array_free(a);\r\na = NULL;\r\ngoto out;\r\n}\r\nstatic void tracing_map_elt_clear(struct tracing_map_elt *elt)\r\n{\r\nunsigned i;\r\nfor (i = 0; i < elt->map->n_fields; i++)\r\nif (elt->fields[i].cmp_fn == tracing_map_cmp_atomic64)\r\natomic64_set(&elt->fields[i].sum, 0);\r\nif (elt->map->ops && elt->map->ops->elt_clear)\r\nelt->map->ops->elt_clear(elt);\r\n}\r\nstatic void tracing_map_elt_init_fields(struct tracing_map_elt *elt)\r\n{\r\nunsigned int i;\r\ntracing_map_elt_clear(elt);\r\nfor (i = 0; i < elt->map->n_fields; i++) {\r\nelt->fields[i].cmp_fn = elt->map->fields[i].cmp_fn;\r\nif (elt->fields[i].cmp_fn != tracing_map_cmp_atomic64)\r\nelt->fields[i].offset = elt->map->fields[i].offset;\r\n}\r\n}\r\nstatic void tracing_map_elt_free(struct tracing_map_elt *elt)\r\n{\r\nif (!elt)\r\nreturn;\r\nif (elt->map->ops && elt->map->ops->elt_free)\r\nelt->map->ops->elt_free(elt);\r\nkfree(elt->fields);\r\nkfree(elt->key);\r\nkfree(elt);\r\n}\r\nstatic struct tracing_map_elt *tracing_map_elt_alloc(struct tracing_map *map)\r\n{\r\nstruct tracing_map_elt *elt;\r\nint err = 0;\r\nelt = kzalloc(sizeof(*elt), GFP_KERNEL);\r\nif (!elt)\r\nreturn ERR_PTR(-ENOMEM);\r\nelt->map = map;\r\nelt->key = kzalloc(map->key_size, GFP_KERNEL);\r\nif (!elt->key) {\r\nerr = -ENOMEM;\r\ngoto free;\r\n}\r\nelt->fields = kcalloc(map->n_fields, sizeof(*elt->fields), GFP_KERNEL);\r\nif (!elt->fields) {\r\nerr = -ENOMEM;\r\ngoto free;\r\n}\r\ntracing_map_elt_init_fields(elt);\r\nif (map->ops && map->ops->elt_alloc) {\r\nerr = map->ops->elt_alloc(elt);\r\nif (err)\r\ngoto free;\r\n}\r\nreturn elt;\r\nfree:\r\ntracing_map_elt_free(elt);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic struct tracing_map_elt *get_free_elt(struct tracing_map *map)\r\n{\r\nstruct tracing_map_elt *elt = NULL;\r\nint idx;\r\nidx = atomic_inc_return(&map->next_elt);\r\nif (idx < map->max_elts) {\r\nelt = *(TRACING_MAP_ELT(map->elts, idx));\r\nif (map->ops && map->ops->elt_init)\r\nmap->ops->elt_init(elt);\r\n}\r\nreturn elt;\r\n}\r\nstatic void tracing_map_free_elts(struct tracing_map *map)\r\n{\r\nunsigned int i;\r\nif (!map->elts)\r\nreturn;\r\nfor (i = 0; i < map->max_elts; i++) {\r\ntracing_map_elt_free(*(TRACING_MAP_ELT(map->elts, i)));\r\n*(TRACING_MAP_ELT(map->elts, i)) = NULL;\r\n}\r\ntracing_map_array_free(map->elts);\r\nmap->elts = NULL;\r\n}\r\nstatic int tracing_map_alloc_elts(struct tracing_map *map)\r\n{\r\nunsigned int i;\r\nmap->elts = tracing_map_array_alloc(map->max_elts,\r\nsizeof(struct tracing_map_elt *));\r\nif (!map->elts)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < map->max_elts; i++) {\r\n*(TRACING_MAP_ELT(map->elts, i)) = tracing_map_elt_alloc(map);\r\nif (IS_ERR(*(TRACING_MAP_ELT(map->elts, i)))) {\r\n*(TRACING_MAP_ELT(map->elts, i)) = NULL;\r\ntracing_map_free_elts(map);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic inline bool keys_match(void *key, void *test_key, unsigned key_size)\r\n{\r\nbool match = true;\r\nif (memcmp(key, test_key, key_size))\r\nmatch = false;\r\nreturn match;\r\n}\r\nstatic inline struct tracing_map_elt *\r\n__tracing_map_insert(struct tracing_map *map, void *key, bool lookup_only)\r\n{\r\nu32 idx, key_hash, test_key;\r\nstruct tracing_map_entry *entry;\r\nkey_hash = jhash(key, map->key_size, 0);\r\nif (key_hash == 0)\r\nkey_hash = 1;\r\nidx = key_hash >> (32 - (map->map_bits + 1));\r\nwhile (1) {\r\nidx &= (map->map_size - 1);\r\nentry = TRACING_MAP_ENTRY(map->map, idx);\r\ntest_key = entry->key;\r\nif (test_key && test_key == key_hash && entry->val &&\r\nkeys_match(key, entry->val->key, map->key_size)) {\r\natomic64_inc(&map->hits);\r\nreturn entry->val;\r\n}\r\nif (!test_key) {\r\nif (lookup_only)\r\nbreak;\r\nif (!cmpxchg(&entry->key, 0, key_hash)) {\r\nstruct tracing_map_elt *elt;\r\nelt = get_free_elt(map);\r\nif (!elt) {\r\natomic64_inc(&map->drops);\r\nentry->key = 0;\r\nbreak;\r\n}\r\nmemcpy(elt->key, key, map->key_size);\r\nentry->val = elt;\r\natomic64_inc(&map->hits);\r\nreturn entry->val;\r\n}\r\n}\r\nidx++;\r\n}\r\nreturn NULL;\r\n}\r\nstruct tracing_map_elt *tracing_map_insert(struct tracing_map *map, void *key)\r\n{\r\nreturn __tracing_map_insert(map, key, false);\r\n}\r\nstruct tracing_map_elt *tracing_map_lookup(struct tracing_map *map, void *key)\r\n{\r\nreturn __tracing_map_insert(map, key, true);\r\n}\r\nvoid tracing_map_destroy(struct tracing_map *map)\r\n{\r\nif (!map)\r\nreturn;\r\ntracing_map_free_elts(map);\r\ntracing_map_array_free(map->map);\r\nkfree(map);\r\n}\r\nvoid tracing_map_clear(struct tracing_map *map)\r\n{\r\nunsigned int i;\r\natomic_set(&map->next_elt, -1);\r\natomic64_set(&map->hits, 0);\r\natomic64_set(&map->drops, 0);\r\ntracing_map_array_clear(map->map);\r\nfor (i = 0; i < map->max_elts; i++)\r\ntracing_map_elt_clear(*(TRACING_MAP_ELT(map->elts, i)));\r\n}\r\nstatic void set_sort_key(struct tracing_map *map,\r\nstruct tracing_map_sort_key *sort_key)\r\n{\r\nmap->sort_key = *sort_key;\r\n}\r\nstruct tracing_map *tracing_map_create(unsigned int map_bits,\r\nunsigned int key_size,\r\nconst struct tracing_map_ops *ops,\r\nvoid *private_data)\r\n{\r\nstruct tracing_map *map;\r\nunsigned int i;\r\nif (map_bits < TRACING_MAP_BITS_MIN ||\r\nmap_bits > TRACING_MAP_BITS_MAX)\r\nreturn ERR_PTR(-EINVAL);\r\nmap = kzalloc(sizeof(*map), GFP_KERNEL);\r\nif (!map)\r\nreturn ERR_PTR(-ENOMEM);\r\nmap->map_bits = map_bits;\r\nmap->max_elts = (1 << map_bits);\r\natomic_set(&map->next_elt, -1);\r\nmap->map_size = (1 << (map_bits + 1));\r\nmap->ops = ops;\r\nmap->private_data = private_data;\r\nmap->map = tracing_map_array_alloc(map->map_size,\r\nsizeof(struct tracing_map_entry));\r\nif (!map->map)\r\ngoto free;\r\nmap->key_size = key_size;\r\nfor (i = 0; i < TRACING_MAP_KEYS_MAX; i++)\r\nmap->key_idx[i] = -1;\r\nout:\r\nreturn map;\r\nfree:\r\ntracing_map_destroy(map);\r\nmap = ERR_PTR(-ENOMEM);\r\ngoto out;\r\n}\r\nint tracing_map_init(struct tracing_map *map)\r\n{\r\nint err;\r\nif (map->n_fields < 2)\r\nreturn -EINVAL;\r\nerr = tracing_map_alloc_elts(map);\r\nif (err)\r\nreturn err;\r\ntracing_map_clear(map);\r\nreturn err;\r\n}\r\nstatic int cmp_entries_dup(const struct tracing_map_sort_entry **a,\r\nconst struct tracing_map_sort_entry **b)\r\n{\r\nint ret = 0;\r\nif (memcmp((*a)->key, (*b)->key, (*a)->elt->map->key_size))\r\nret = 1;\r\nreturn ret;\r\n}\r\nstatic int cmp_entries_sum(const struct tracing_map_sort_entry **a,\r\nconst struct tracing_map_sort_entry **b)\r\n{\r\nconst struct tracing_map_elt *elt_a, *elt_b;\r\nstruct tracing_map_sort_key *sort_key;\r\nstruct tracing_map_field *field;\r\ntracing_map_cmp_fn_t cmp_fn;\r\nvoid *val_a, *val_b;\r\nint ret = 0;\r\nelt_a = (*a)->elt;\r\nelt_b = (*b)->elt;\r\nsort_key = &elt_a->map->sort_key;\r\nfield = &elt_a->fields[sort_key->field_idx];\r\ncmp_fn = field->cmp_fn;\r\nval_a = &elt_a->fields[sort_key->field_idx].sum;\r\nval_b = &elt_b->fields[sort_key->field_idx].sum;\r\nret = cmp_fn(val_a, val_b);\r\nif (sort_key->descending)\r\nret = -ret;\r\nreturn ret;\r\n}\r\nstatic int cmp_entries_key(const struct tracing_map_sort_entry **a,\r\nconst struct tracing_map_sort_entry **b)\r\n{\r\nconst struct tracing_map_elt *elt_a, *elt_b;\r\nstruct tracing_map_sort_key *sort_key;\r\nstruct tracing_map_field *field;\r\ntracing_map_cmp_fn_t cmp_fn;\r\nvoid *val_a, *val_b;\r\nint ret = 0;\r\nelt_a = (*a)->elt;\r\nelt_b = (*b)->elt;\r\nsort_key = &elt_a->map->sort_key;\r\nfield = &elt_a->fields[sort_key->field_idx];\r\ncmp_fn = field->cmp_fn;\r\nval_a = elt_a->key + field->offset;\r\nval_b = elt_b->key + field->offset;\r\nret = cmp_fn(val_a, val_b);\r\nif (sort_key->descending)\r\nret = -ret;\r\nreturn ret;\r\n}\r\nstatic void destroy_sort_entry(struct tracing_map_sort_entry *entry)\r\n{\r\nif (!entry)\r\nreturn;\r\nif (entry->elt_copied)\r\ntracing_map_elt_free(entry->elt);\r\nkfree(entry);\r\n}\r\nvoid tracing_map_destroy_sort_entries(struct tracing_map_sort_entry **entries,\r\nunsigned int n_entries)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < n_entries; i++)\r\ndestroy_sort_entry(entries[i]);\r\nvfree(entries);\r\n}\r\nstatic struct tracing_map_sort_entry *\r\ncreate_sort_entry(void *key, struct tracing_map_elt *elt)\r\n{\r\nstruct tracing_map_sort_entry *sort_entry;\r\nsort_entry = kzalloc(sizeof(*sort_entry), GFP_KERNEL);\r\nif (!sort_entry)\r\nreturn NULL;\r\nsort_entry->key = key;\r\nsort_entry->elt = elt;\r\nreturn sort_entry;\r\n}\r\nstatic struct tracing_map_elt *copy_elt(struct tracing_map_elt *elt)\r\n{\r\nstruct tracing_map_elt *dup_elt;\r\nunsigned int i;\r\ndup_elt = tracing_map_elt_alloc(elt->map);\r\nif (IS_ERR(dup_elt))\r\nreturn NULL;\r\nif (elt->map->ops && elt->map->ops->elt_copy)\r\nelt->map->ops->elt_copy(dup_elt, elt);\r\ndup_elt->private_data = elt->private_data;\r\nmemcpy(dup_elt->key, elt->key, elt->map->key_size);\r\nfor (i = 0; i < elt->map->n_fields; i++) {\r\natomic64_set(&dup_elt->fields[i].sum,\r\natomic64_read(&elt->fields[i].sum));\r\ndup_elt->fields[i].cmp_fn = elt->fields[i].cmp_fn;\r\n}\r\nreturn dup_elt;\r\n}\r\nstatic int merge_dup(struct tracing_map_sort_entry **sort_entries,\r\nunsigned int target, unsigned int dup)\r\n{\r\nstruct tracing_map_elt *target_elt, *elt;\r\nbool first_dup = (target - dup) == 1;\r\nint i;\r\nif (first_dup) {\r\nelt = sort_entries[target]->elt;\r\ntarget_elt = copy_elt(elt);\r\nif (!target_elt)\r\nreturn -ENOMEM;\r\nsort_entries[target]->elt = target_elt;\r\nsort_entries[target]->elt_copied = true;\r\n} else\r\ntarget_elt = sort_entries[target]->elt;\r\nelt = sort_entries[dup]->elt;\r\nfor (i = 0; i < elt->map->n_fields; i++)\r\natomic64_add(atomic64_read(&elt->fields[i].sum),\r\n&target_elt->fields[i].sum);\r\nsort_entries[dup]->dup = true;\r\nreturn 0;\r\n}\r\nstatic int merge_dups(struct tracing_map_sort_entry **sort_entries,\r\nint n_entries, unsigned int key_size)\r\n{\r\nunsigned int dups = 0, total_dups = 0;\r\nint err, i, j;\r\nvoid *key;\r\nif (n_entries < 2)\r\nreturn total_dups;\r\nsort(sort_entries, n_entries, sizeof(struct tracing_map_sort_entry *),\r\n(int (*)(const void *, const void *))cmp_entries_dup, NULL);\r\nkey = sort_entries[0]->key;\r\nfor (i = 1; i < n_entries; i++) {\r\nif (!memcmp(sort_entries[i]->key, key, key_size)) {\r\ndups++; total_dups++;\r\nerr = merge_dup(sort_entries, i - dups, i);\r\nif (err)\r\nreturn err;\r\ncontinue;\r\n}\r\nkey = sort_entries[i]->key;\r\ndups = 0;\r\n}\r\nif (!total_dups)\r\nreturn total_dups;\r\nfor (i = 0, j = 0; i < n_entries; i++) {\r\nif (!sort_entries[i]->dup) {\r\nsort_entries[j] = sort_entries[i];\r\nif (j++ != i)\r\nsort_entries[i] = NULL;\r\n} else {\r\ndestroy_sort_entry(sort_entries[i]);\r\nsort_entries[i] = NULL;\r\n}\r\n}\r\nreturn total_dups;\r\n}\r\nstatic bool is_key(struct tracing_map *map, unsigned int field_idx)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < map->n_keys; i++)\r\nif (map->key_idx[i] == field_idx)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void sort_secondary(struct tracing_map *map,\r\nconst struct tracing_map_sort_entry **entries,\r\nunsigned int n_entries,\r\nstruct tracing_map_sort_key *primary_key,\r\nstruct tracing_map_sort_key *secondary_key)\r\n{\r\nint (*primary_fn)(const struct tracing_map_sort_entry **,\r\nconst struct tracing_map_sort_entry **);\r\nint (*secondary_fn)(const struct tracing_map_sort_entry **,\r\nconst struct tracing_map_sort_entry **);\r\nunsigned i, start = 0, n_sub = 1;\r\nif (is_key(map, primary_key->field_idx))\r\nprimary_fn = cmp_entries_key;\r\nelse\r\nprimary_fn = cmp_entries_sum;\r\nif (is_key(map, secondary_key->field_idx))\r\nsecondary_fn = cmp_entries_key;\r\nelse\r\nsecondary_fn = cmp_entries_sum;\r\nfor (i = 0; i < n_entries - 1; i++) {\r\nconst struct tracing_map_sort_entry **a = &entries[i];\r\nconst struct tracing_map_sort_entry **b = &entries[i + 1];\r\nif (primary_fn(a, b) == 0) {\r\nn_sub++;\r\nif (i < n_entries - 2)\r\ncontinue;\r\n}\r\nif (n_sub < 2) {\r\nstart = i + 1;\r\nn_sub = 1;\r\ncontinue;\r\n}\r\nset_sort_key(map, secondary_key);\r\nsort(&entries[start], n_sub,\r\nsizeof(struct tracing_map_sort_entry *),\r\n(int (*)(const void *, const void *))secondary_fn, NULL);\r\nset_sort_key(map, primary_key);\r\nstart = i + 1;\r\nn_sub = 1;\r\n}\r\n}\r\nint tracing_map_sort_entries(struct tracing_map *map,\r\nstruct tracing_map_sort_key *sort_keys,\r\nunsigned int n_sort_keys,\r\nstruct tracing_map_sort_entry ***sort_entries)\r\n{\r\nint (*cmp_entries_fn)(const struct tracing_map_sort_entry **,\r\nconst struct tracing_map_sort_entry **);\r\nstruct tracing_map_sort_entry *sort_entry, **entries;\r\nint i, n_entries, ret;\r\nentries = vmalloc(map->max_elts * sizeof(sort_entry));\r\nif (!entries)\r\nreturn -ENOMEM;\r\nfor (i = 0, n_entries = 0; i < map->map_size; i++) {\r\nstruct tracing_map_entry *entry;\r\nentry = TRACING_MAP_ENTRY(map->map, i);\r\nif (!entry->key || !entry->val)\r\ncontinue;\r\nentries[n_entries] = create_sort_entry(entry->val->key,\r\nentry->val);\r\nif (!entries[n_entries++]) {\r\nret = -ENOMEM;\r\ngoto free;\r\n}\r\n}\r\nif (n_entries == 0) {\r\nret = 0;\r\ngoto free;\r\n}\r\nif (n_entries == 1) {\r\n*sort_entries = entries;\r\nreturn 1;\r\n}\r\nret = merge_dups(entries, n_entries, map->key_size);\r\nif (ret < 0)\r\ngoto free;\r\nn_entries -= ret;\r\nif (is_key(map, sort_keys[0].field_idx))\r\ncmp_entries_fn = cmp_entries_key;\r\nelse\r\ncmp_entries_fn = cmp_entries_sum;\r\nset_sort_key(map, &sort_keys[0]);\r\nsort(entries, n_entries, sizeof(struct tracing_map_sort_entry *),\r\n(int (*)(const void *, const void *))cmp_entries_fn, NULL);\r\nif (n_sort_keys > 1)\r\nsort_secondary(map,\r\n(const struct tracing_map_sort_entry **)entries,\r\nn_entries,\r\n&sort_keys[0],\r\n&sort_keys[1]);\r\n*sort_entries = entries;\r\nreturn n_entries;\r\nfree:\r\ntracing_map_destroy_sort_entries(entries, n_entries);\r\nreturn ret;\r\n}
