void ishtp_cl_alloc_dma_buf(struct ishtp_device *dev)\r\n{\r\ndma_addr_t h;\r\nif (dev->ishtp_host_dma_tx_buf)\r\nreturn;\r\ndev->ishtp_host_dma_tx_buf_size = 1024*1024;\r\ndev->ishtp_host_dma_rx_buf_size = 1024*1024;\r\ndev->ishtp_host_dma_tx_buf = dma_alloc_coherent(dev->devc,\r\ndev->ishtp_host_dma_tx_buf_size,\r\n&h, GFP_KERNEL);\r\nif (dev->ishtp_host_dma_tx_buf)\r\ndev->ishtp_host_dma_tx_buf_phys = h;\r\ndev->ishtp_dma_num_slots = dev->ishtp_host_dma_tx_buf_size /\r\nDMA_SLOT_SIZE;\r\ndev->ishtp_dma_tx_map = kcalloc(dev->ishtp_dma_num_slots,\r\nsizeof(uint8_t),\r\nGFP_KERNEL);\r\nspin_lock_init(&dev->ishtp_dma_tx_lock);\r\ndev->ishtp_host_dma_rx_buf = dma_alloc_coherent(dev->devc,\r\ndev->ishtp_host_dma_rx_buf_size,\r\n&h, GFP_KERNEL);\r\nif (dev->ishtp_host_dma_rx_buf)\r\ndev->ishtp_host_dma_rx_buf_phys = h;\r\n}\r\nvoid ishtp_cl_free_dma_buf(struct ishtp_device *dev)\r\n{\r\ndma_addr_t h;\r\nif (dev->ishtp_host_dma_tx_buf) {\r\nh = dev->ishtp_host_dma_tx_buf_phys;\r\ndma_free_coherent(dev->devc, dev->ishtp_host_dma_tx_buf_size,\r\ndev->ishtp_host_dma_tx_buf, h);\r\n}\r\nif (dev->ishtp_host_dma_rx_buf) {\r\nh = dev->ishtp_host_dma_rx_buf_phys;\r\ndma_free_coherent(dev->devc, dev->ishtp_host_dma_rx_buf_size,\r\ndev->ishtp_host_dma_rx_buf, h);\r\n}\r\nkfree(dev->ishtp_dma_tx_map);\r\ndev->ishtp_host_dma_tx_buf = NULL;\r\ndev->ishtp_host_dma_rx_buf = NULL;\r\ndev->ishtp_dma_tx_map = NULL;\r\n}\r\nvoid *ishtp_cl_get_dma_send_buf(struct ishtp_device *dev,\r\nuint32_t size)\r\n{\r\nunsigned long flags;\r\nint i, j, free;\r\nint required_slots = (size / DMA_SLOT_SIZE)\r\n+ 1 * (size % DMA_SLOT_SIZE != 0);\r\nspin_lock_irqsave(&dev->ishtp_dma_tx_lock, flags);\r\nfor (i = 0; i <= (dev->ishtp_dma_num_slots - required_slots); i++) {\r\nfree = 1;\r\nfor (j = 0; j < required_slots; j++)\r\nif (dev->ishtp_dma_tx_map[i+j]) {\r\nfree = 0;\r\ni += j;\r\nbreak;\r\n}\r\nif (free) {\r\nfor (j = 0; j < required_slots; j++)\r\ndev->ishtp_dma_tx_map[i+j] = 1;\r\nspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\r\nreturn (i * DMA_SLOT_SIZE) +\r\n(unsigned char *)dev->ishtp_host_dma_tx_buf;\r\n}\r\n}\r\nspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\r\ndev_err(dev->devc, "No free DMA buffer to send msg\n");\r\nreturn NULL;\r\n}\r\nvoid ishtp_cl_release_dma_acked_mem(struct ishtp_device *dev,\r\nvoid *msg_addr,\r\nuint8_t size)\r\n{\r\nunsigned long flags;\r\nint acked_slots = (size / DMA_SLOT_SIZE)\r\n+ 1 * (size % DMA_SLOT_SIZE != 0);\r\nint i, j;\r\nif ((msg_addr - dev->ishtp_host_dma_tx_buf) % DMA_SLOT_SIZE) {\r\ndev_err(dev->devc, "Bad DMA Tx ack address\n");\r\nreturn;\r\n}\r\ni = (msg_addr - dev->ishtp_host_dma_tx_buf) / DMA_SLOT_SIZE;\r\nspin_lock_irqsave(&dev->ishtp_dma_tx_lock, flags);\r\nfor (j = 0; j < acked_slots; j++) {\r\nif ((i + j) >= dev->ishtp_dma_num_slots ||\r\n!dev->ishtp_dma_tx_map[i+j]) {\r\nspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\r\ndev_err(dev->devc, "Bad DMA Tx ack address\n");\r\nreturn;\r\n}\r\ndev->ishtp_dma_tx_map[i+j] = 0;\r\n}\r\nspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\r\n}
