void irq_timings_enable(void)\r\n{\r\nstatic_branch_enable(&irq_timing_enabled);\r\n}\r\nvoid irq_timings_disable(void)\r\n{\r\nstatic_branch_disable(&irq_timing_enabled);\r\n}\r\nstatic void irqs_update(struct irqt_stat *irqs, u64 ts)\r\n{\r\nu64 old_ts = irqs->last_ts;\r\nu64 variance = 0;\r\nu64 interval;\r\ns64 diff;\r\nirqs->last_ts = ts;\r\ninterval = ts - old_ts;\r\nif (interval >= NSEC_PER_SEC) {\r\nmemset(irqs, 0, sizeof(*irqs));\r\nirqs->last_ts = ts;\r\nreturn;\r\n}\r\ndiff = interval - irqs->avg;\r\nirqs->nr_samples++;\r\nif (likely(irqs->nr_samples > 1))\r\nvariance = irqs->variance >> IRQ_TIMINGS_SHIFT;\r\nif ((irqs->nr_samples >= 30) && ((diff * diff) > (9 * variance))) {\r\nif (irqs->anomalies++ >= 3) {\r\nmemset(irqs, 0, sizeof(*irqs));\r\nirqs->last_ts = ts;\r\nreturn;\r\n}\r\n} else {\r\nirqs->anomalies = 0;\r\n}\r\nirqs->valid = 1;\r\nirqs->avg = irqs->avg + (diff >> IRQ_TIMINGS_SHIFT);\r\nirqs->variance = irqs->variance + (diff * (interval - irqs->avg));\r\nirqs->next_evt = ts + irqs->avg;\r\n}\r\nu64 irq_timings_next_event(u64 now)\r\n{\r\nstruct irq_timings *irqts = this_cpu_ptr(&irq_timings);\r\nstruct irqt_stat *irqs;\r\nstruct irqt_stat __percpu *s;\r\nu64 ts, next_evt = U64_MAX;\r\nint i, irq = 0;\r\nWARN_ON_ONCE(!irqs_disabled());\r\nfor (i = irqts->count & IRQ_TIMINGS_MASK,\r\nirqts->count = min(IRQ_TIMINGS_SIZE, irqts->count);\r\nirqts->count > 0; irqts->count--, i = (i + 1) & IRQ_TIMINGS_MASK) {\r\nirq = irq_timing_decode(irqts->values[i], &ts);\r\ns = idr_find(&irqt_stats, irq);\r\nif (s) {\r\nirqs = this_cpu_ptr(s);\r\nirqs_update(irqs, ts);\r\n}\r\n}\r\nidr_for_each_entry(&irqt_stats, s, i) {\r\nirqs = this_cpu_ptr(s);\r\nif (!irqs->valid)\r\ncontinue;\r\nif (irqs->next_evt <= now) {\r\nirq = i;\r\nnext_evt = now;\r\nirqs->valid = 0;\r\nbreak;\r\n}\r\nif (irqs->next_evt < next_evt) {\r\nirq = i;\r\nnext_evt = irqs->next_evt;\r\n}\r\n}\r\nreturn next_evt;\r\n}\r\nvoid irq_timings_free(int irq)\r\n{\r\nstruct irqt_stat __percpu *s;\r\ns = idr_find(&irqt_stats, irq);\r\nif (s) {\r\nfree_percpu(s);\r\nidr_remove(&irqt_stats, irq);\r\n}\r\n}\r\nint irq_timings_alloc(int irq)\r\n{\r\nstruct irqt_stat __percpu *s;\r\nint id;\r\ns = idr_find(&irqt_stats, irq);\r\nif (s)\r\nreturn 0;\r\ns = alloc_percpu(*s);\r\nif (!s)\r\nreturn -ENOMEM;\r\nidr_preload(GFP_KERNEL);\r\nid = idr_alloc(&irqt_stats, s, irq, irq + 1, GFP_NOWAIT);\r\nidr_preload_end();\r\nif (id < 0) {\r\nfree_percpu(s);\r\nreturn id;\r\n}\r\nreturn 0;\r\n}
