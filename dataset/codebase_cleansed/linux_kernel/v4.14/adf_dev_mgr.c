static int adf_get_vf_id(struct adf_accel_dev *vf)\r\n{\r\nreturn ((7 * (PCI_SLOT(accel_to_pci_dev(vf)->devfn) - 1)) +\r\nPCI_FUNC(accel_to_pci_dev(vf)->devfn) +\r\n(PCI_SLOT(accel_to_pci_dev(vf)->devfn) - 1));\r\n}\r\nstatic int adf_get_vf_num(struct adf_accel_dev *vf)\r\n{\r\nreturn (accel_to_pci_dev(vf)->bus->number << 8) | adf_get_vf_id(vf);\r\n}\r\nstatic struct vf_id_map *adf_find_vf(u32 bdf)\r\n{\r\nstruct list_head *itr;\r\nlist_for_each(itr, &vfs_table) {\r\nstruct vf_id_map *ptr =\r\nlist_entry(itr, struct vf_id_map, list);\r\nif (ptr->bdf == bdf)\r\nreturn ptr;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int adf_get_vf_real_id(u32 fake)\r\n{\r\nstruct list_head *itr;\r\nlist_for_each(itr, &vfs_table) {\r\nstruct vf_id_map *ptr =\r\nlist_entry(itr, struct vf_id_map, list);\r\nif (ptr->fake_id == fake)\r\nreturn ptr->id;\r\n}\r\nreturn -1;\r\n}\r\nvoid adf_clean_vf_map(bool vf)\r\n{\r\nstruct vf_id_map *map;\r\nstruct list_head *ptr, *tmp;\r\nmutex_lock(&table_lock);\r\nlist_for_each_safe(ptr, tmp, &vfs_table) {\r\nmap = list_entry(ptr, struct vf_id_map, list);\r\nif (map->bdf != -1) {\r\nid_map[map->id] = 0;\r\nnum_devices--;\r\n}\r\nif (vf && map->bdf == -1)\r\ncontinue;\r\nlist_del(ptr);\r\nkfree(map);\r\n}\r\nmutex_unlock(&table_lock);\r\n}\r\nvoid adf_devmgr_update_class_index(struct adf_hw_device_data *hw_data)\r\n{\r\nstruct adf_hw_device_class *class = hw_data->dev_class;\r\nstruct list_head *itr;\r\nint i = 0;\r\nlist_for_each(itr, &accel_table) {\r\nstruct adf_accel_dev *ptr =\r\nlist_entry(itr, struct adf_accel_dev, list);\r\nif (ptr->hw_device->dev_class == class)\r\nptr->hw_device->instance_id = i++;\r\nif (i == class->instances)\r\nbreak;\r\n}\r\n}\r\nstatic unsigned int adf_find_free_id(void)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < ADF_MAX_DEVICES; i++) {\r\nif (!id_map[i]) {\r\nid_map[i] = 1;\r\nreturn i;\r\n}\r\n}\r\nreturn ADF_MAX_DEVICES + 1;\r\n}\r\nint adf_devmgr_add_dev(struct adf_accel_dev *accel_dev,\r\nstruct adf_accel_dev *pf)\r\n{\r\nstruct list_head *itr;\r\nint ret = 0;\r\nif (num_devices == ADF_MAX_DEVICES) {\r\ndev_err(&GET_DEV(accel_dev), "Only support up to %d devices\n",\r\nADF_MAX_DEVICES);\r\nreturn -EFAULT;\r\n}\r\nmutex_lock(&table_lock);\r\natomic_set(&accel_dev->ref_count, 0);\r\nif (!accel_dev->is_vf || (accel_dev->is_vf && !pf)) {\r\nstruct vf_id_map *map;\r\nlist_for_each(itr, &accel_table) {\r\nstruct adf_accel_dev *ptr =\r\nlist_entry(itr, struct adf_accel_dev, list);\r\nif (ptr == accel_dev) {\r\nret = -EEXIST;\r\ngoto unlock;\r\n}\r\n}\r\nlist_add_tail(&accel_dev->list, &accel_table);\r\naccel_dev->accel_id = adf_find_free_id();\r\nif (accel_dev->accel_id > ADF_MAX_DEVICES) {\r\nret = -EFAULT;\r\ngoto unlock;\r\n}\r\nnum_devices++;\r\nmap = kzalloc(sizeof(*map), GFP_KERNEL);\r\nif (!map) {\r\nret = -ENOMEM;\r\ngoto unlock;\r\n}\r\nmap->bdf = ~0;\r\nmap->id = accel_dev->accel_id;\r\nmap->fake_id = map->id;\r\nmap->attached = true;\r\nlist_add_tail(&map->list, &vfs_table);\r\n} else if (accel_dev->is_vf && pf) {\r\nstruct adf_accel_vf_info *vf_info;\r\nstruct vf_id_map *map;\r\nvf_info = pf->pf.vf_info + adf_get_vf_id(accel_dev);\r\nmap = adf_find_vf(adf_get_vf_num(accel_dev));\r\nif (map) {\r\nstruct vf_id_map *next;\r\naccel_dev->accel_id = map->id;\r\nlist_add_tail(&accel_dev->list, &accel_table);\r\nmap->fake_id++;\r\nmap->attached = true;\r\nnext = list_next_entry(map, list);\r\nwhile (next && &next->list != &vfs_table) {\r\nnext->fake_id++;\r\nnext = list_next_entry(next, list);\r\n}\r\nret = 0;\r\ngoto unlock;\r\n}\r\nmap = kzalloc(sizeof(*map), GFP_KERNEL);\r\nif (!map) {\r\nret = -ENOMEM;\r\ngoto unlock;\r\n}\r\naccel_dev->accel_id = adf_find_free_id();\r\nif (accel_dev->accel_id > ADF_MAX_DEVICES) {\r\nkfree(map);\r\nret = -EFAULT;\r\ngoto unlock;\r\n}\r\nnum_devices++;\r\nlist_add_tail(&accel_dev->list, &accel_table);\r\nmap->bdf = adf_get_vf_num(accel_dev);\r\nmap->id = accel_dev->accel_id;\r\nmap->fake_id = map->id;\r\nmap->attached = true;\r\nlist_add_tail(&map->list, &vfs_table);\r\n}\r\nunlock:\r\nmutex_unlock(&table_lock);\r\nreturn ret;\r\n}\r\nstruct list_head *adf_devmgr_get_head(void)\r\n{\r\nreturn &accel_table;\r\n}\r\nvoid adf_devmgr_rm_dev(struct adf_accel_dev *accel_dev,\r\nstruct adf_accel_dev *pf)\r\n{\r\nmutex_lock(&table_lock);\r\nif (!accel_dev->is_vf || (accel_dev->is_vf && !pf)) {\r\nid_map[accel_dev->accel_id] = 0;\r\nnum_devices--;\r\n} else if (accel_dev->is_vf && pf) {\r\nstruct vf_id_map *map, *next;\r\nmap = adf_find_vf(adf_get_vf_num(accel_dev));\r\nif (!map) {\r\ndev_err(&GET_DEV(accel_dev), "Failed to find VF map\n");\r\ngoto unlock;\r\n}\r\nmap->fake_id--;\r\nmap->attached = false;\r\nnext = list_next_entry(map, list);\r\nwhile (next && &next->list != &vfs_table) {\r\nnext->fake_id--;\r\nnext = list_next_entry(next, list);\r\n}\r\n}\r\nunlock:\r\nlist_del(&accel_dev->list);\r\nmutex_unlock(&table_lock);\r\n}\r\nstruct adf_accel_dev *adf_devmgr_get_first(void)\r\n{\r\nstruct adf_accel_dev *dev = NULL;\r\nif (!list_empty(&accel_table))\r\ndev = list_first_entry(&accel_table, struct adf_accel_dev,\r\nlist);\r\nreturn dev;\r\n}\r\nstruct adf_accel_dev *adf_devmgr_pci_to_accel_dev(struct pci_dev *pci_dev)\r\n{\r\nstruct list_head *itr;\r\nmutex_lock(&table_lock);\r\nlist_for_each(itr, &accel_table) {\r\nstruct adf_accel_dev *ptr =\r\nlist_entry(itr, struct adf_accel_dev, list);\r\nif (ptr->accel_pci_dev.pci_dev == pci_dev) {\r\nmutex_unlock(&table_lock);\r\nreturn ptr;\r\n}\r\n}\r\nmutex_unlock(&table_lock);\r\nreturn NULL;\r\n}\r\nstruct adf_accel_dev *adf_devmgr_get_dev_by_id(uint32_t id)\r\n{\r\nstruct list_head *itr;\r\nint real_id;\r\nmutex_lock(&table_lock);\r\nreal_id = adf_get_vf_real_id(id);\r\nif (real_id < 0)\r\ngoto unlock;\r\nid = real_id;\r\nlist_for_each(itr, &accel_table) {\r\nstruct adf_accel_dev *ptr =\r\nlist_entry(itr, struct adf_accel_dev, list);\r\nif (ptr->accel_id == id) {\r\nmutex_unlock(&table_lock);\r\nreturn ptr;\r\n}\r\n}\r\nunlock:\r\nmutex_unlock(&table_lock);\r\nreturn NULL;\r\n}\r\nint adf_devmgr_verify_id(uint32_t id)\r\n{\r\nif (id == ADF_CFG_ALL_DEVICES)\r\nreturn 0;\r\nif (adf_devmgr_get_dev_by_id(id))\r\nreturn 0;\r\nreturn -ENODEV;\r\n}\r\nstatic int adf_get_num_dettached_vfs(void)\r\n{\r\nstruct list_head *itr;\r\nint vfs = 0;\r\nmutex_lock(&table_lock);\r\nlist_for_each(itr, &vfs_table) {\r\nstruct vf_id_map *ptr =\r\nlist_entry(itr, struct vf_id_map, list);\r\nif (ptr->bdf != ~0 && !ptr->attached)\r\nvfs++;\r\n}\r\nmutex_unlock(&table_lock);\r\nreturn vfs;\r\n}\r\nvoid adf_devmgr_get_num_dev(uint32_t *num)\r\n{\r\n*num = num_devices - adf_get_num_dettached_vfs();\r\n}\r\nint adf_dev_in_use(struct adf_accel_dev *accel_dev)\r\n{\r\nreturn atomic_read(&accel_dev->ref_count) != 0;\r\n}\r\nint adf_dev_get(struct adf_accel_dev *accel_dev)\r\n{\r\nif (atomic_add_return(1, &accel_dev->ref_count) == 1)\r\nif (!try_module_get(accel_dev->owner))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nvoid adf_dev_put(struct adf_accel_dev *accel_dev)\r\n{\r\nif (atomic_sub_return(1, &accel_dev->ref_count) == 0)\r\nmodule_put(accel_dev->owner);\r\n}\r\nint adf_devmgr_in_reset(struct adf_accel_dev *accel_dev)\r\n{\r\nreturn test_bit(ADF_STATUS_RESTARTING, &accel_dev->status);\r\n}\r\nint adf_dev_started(struct adf_accel_dev *accel_dev)\r\n{\r\nreturn test_bit(ADF_STATUS_STARTED, &accel_dev->status);\r\n}
