static void qed_spq_blocking_cb(struct qed_hwfn *p_hwfn,\r\nvoid *cookie,\r\nunion event_ring_data *data, u8 fw_return_code)\r\n{\r\nstruct qed_spq_comp_done *comp_done;\r\ncomp_done = (struct qed_spq_comp_done *)cookie;\r\ncomp_done->fw_return_code = fw_return_code;\r\nsmp_store_release(&comp_done->done, 0x1);\r\n}\r\nstatic int __qed_spq_block(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq_entry *p_ent,\r\nu8 *p_fw_ret, bool sleep_between_iter)\r\n{\r\nstruct qed_spq_comp_done *comp_done;\r\nu32 iter_cnt;\r\ncomp_done = (struct qed_spq_comp_done *)p_ent->comp_cb.cookie;\r\niter_cnt = sleep_between_iter ? SPQ_BLOCK_SLEEP_MAX_ITER\r\n: SPQ_BLOCK_DELAY_MAX_ITER;\r\nwhile (iter_cnt--) {\r\nif (READ_ONCE(comp_done->done) == 1) {\r\nsmp_read_barrier_depends();\r\nif (p_fw_ret)\r\n*p_fw_ret = comp_done->fw_return_code;\r\nreturn 0;\r\n}\r\nif (sleep_between_iter)\r\nmsleep(SPQ_BLOCK_SLEEP_MS);\r\nelse\r\nudelay(SPQ_BLOCK_DELAY_US);\r\n}\r\nreturn -EBUSY;\r\n}\r\nstatic int qed_spq_block(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq_entry *p_ent,\r\nu8 *p_fw_ret, bool skip_quick_poll)\r\n{\r\nstruct qed_spq_comp_done *comp_done;\r\nstruct qed_ptt *p_ptt;\r\nint rc;\r\nif (!skip_quick_poll) {\r\nrc = __qed_spq_block(p_hwfn, p_ent, p_fw_ret, false);\r\nif (!rc)\r\nreturn 0;\r\n}\r\nrc = __qed_spq_block(p_hwfn, p_ent, p_fw_ret, true);\r\nif (!rc)\r\nreturn 0;\r\np_ptt = qed_ptt_acquire(p_hwfn);\r\nif (!p_ptt) {\r\nDP_NOTICE(p_hwfn, "ptt, failed to acquire\n");\r\nreturn -EAGAIN;\r\n}\r\nDP_INFO(p_hwfn, "Ramrod is stuck, requesting MCP drain\n");\r\nrc = qed_mcp_drain(p_hwfn, p_ptt);\r\nif (rc) {\r\nDP_NOTICE(p_hwfn, "MCP drain failed\n");\r\ngoto err;\r\n}\r\nrc = __qed_spq_block(p_hwfn, p_ent, p_fw_ret, true);\r\nif (!rc)\r\ngoto out;\r\ncomp_done = (struct qed_spq_comp_done *)p_ent->comp_cb.cookie;\r\nif (comp_done->done == 1)\r\nif (p_fw_ret)\r\n*p_fw_ret = comp_done->fw_return_code;\r\nout:\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nreturn 0;\r\nerr:\r\nqed_ptt_release(p_hwfn, p_ptt);\r\nDP_NOTICE(p_hwfn,\r\n"Ramrod is stuck [CID %08x cmd %02x protocol %02x echo %04x]\n",\r\nle32_to_cpu(p_ent->elem.hdr.cid),\r\np_ent->elem.hdr.cmd_id,\r\np_ent->elem.hdr.protocol_id,\r\nle16_to_cpu(p_ent->elem.hdr.echo));\r\nreturn -EBUSY;\r\n}\r\nstatic int qed_spq_fill_entry(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq_entry *p_ent)\r\n{\r\np_ent->flags = 0;\r\nswitch (p_ent->comp_mode) {\r\ncase QED_SPQ_MODE_EBLOCK:\r\ncase QED_SPQ_MODE_BLOCK:\r\np_ent->comp_cb.function = qed_spq_blocking_cb;\r\nbreak;\r\ncase QED_SPQ_MODE_CB:\r\nbreak;\r\ndefault:\r\nDP_NOTICE(p_hwfn, "Unknown SPQE completion mode %d\n",\r\np_ent->comp_mode);\r\nreturn -EINVAL;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\r\n"Ramrod header: [CID 0x%08x CMD 0x%02x protocol 0x%02x] Data pointer: [%08x:%08x] Completion Mode: %s\n",\r\np_ent->elem.hdr.cid,\r\np_ent->elem.hdr.cmd_id,\r\np_ent->elem.hdr.protocol_id,\r\np_ent->elem.data_ptr.hi,\r\np_ent->elem.data_ptr.lo,\r\nD_TRINE(p_ent->comp_mode, QED_SPQ_MODE_EBLOCK,\r\nQED_SPQ_MODE_BLOCK, "MODE_EBLOCK", "MODE_BLOCK",\r\n"MODE_CB"));\r\nreturn 0;\r\n}\r\nstatic void qed_spq_hw_initialize(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq *p_spq)\r\n{\r\nstruct core_conn_context *p_cxt;\r\nstruct qed_cxt_info cxt_info;\r\nu16 physical_q;\r\nint rc;\r\ncxt_info.iid = p_spq->cid;\r\nrc = qed_cxt_get_cid_info(p_hwfn, &cxt_info);\r\nif (rc < 0) {\r\nDP_NOTICE(p_hwfn, "Cannot find context info for cid=%d\n",\r\np_spq->cid);\r\nreturn;\r\n}\r\np_cxt = cxt_info.p_cxt;\r\nSET_FIELD(p_cxt->xstorm_ag_context.flags10,\r\nXSTORM_CORE_CONN_AG_CTX_DQ_CF_EN, 1);\r\nSET_FIELD(p_cxt->xstorm_ag_context.flags1,\r\nXSTORM_CORE_CONN_AG_CTX_DQ_CF_ACTIVE, 1);\r\nSET_FIELD(p_cxt->xstorm_ag_context.flags9,\r\nXSTORM_CORE_CONN_AG_CTX_CONSOLID_PROD_CF_EN, 1);\r\nphysical_q = qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_LB);\r\np_cxt->xstorm_ag_context.physical_q0 = cpu_to_le16(physical_q);\r\np_cxt->xstorm_st_context.spq_base_lo =\r\nDMA_LO_LE(p_spq->chain.p_phys_addr);\r\np_cxt->xstorm_st_context.spq_base_hi =\r\nDMA_HI_LE(p_spq->chain.p_phys_addr);\r\nDMA_REGPAIR_LE(p_cxt->xstorm_st_context.consolid_base_addr,\r\np_hwfn->p_consq->chain.p_phys_addr);\r\n}\r\nstatic int qed_spq_hw_post(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq *p_spq, struct qed_spq_entry *p_ent)\r\n{\r\nstruct qed_chain *p_chain = &p_hwfn->p_spq->chain;\r\nu16 echo = qed_chain_get_prod_idx(p_chain);\r\nstruct slow_path_element *elem;\r\nstruct core_db_data db;\r\np_ent->elem.hdr.echo = cpu_to_le16(echo);\r\nelem = qed_chain_produce(p_chain);\r\nif (!elem) {\r\nDP_NOTICE(p_hwfn, "Failed to produce from SPQ chain\n");\r\nreturn -EINVAL;\r\n}\r\n*elem = p_ent->elem;\r\nmemset(&db, 0, sizeof(db));\r\nSET_FIELD(db.params, CORE_DB_DATA_DEST, DB_DEST_XCM);\r\nSET_FIELD(db.params, CORE_DB_DATA_AGG_CMD, DB_AGG_CMD_SET);\r\nSET_FIELD(db.params, CORE_DB_DATA_AGG_VAL_SEL,\r\nDQ_XCM_CORE_SPQ_PROD_CMD);\r\ndb.agg_flags = DQ_XCM_CORE_DQ_CF_CMD;\r\ndb.spq_prod = cpu_to_le16(qed_chain_get_prod_idx(p_chain));\r\nwmb();\r\nDOORBELL(p_hwfn, qed_db_addr(p_spq->cid, DQ_DEMS_LEGACY), *(u32 *)&db);\r\nwmb();\r\nDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\r\n"Doorbelled [0x%08x, CID 0x%08x] with Flags: %02x agg_params: %02x, prod: %04x\n",\r\nqed_db_addr(p_spq->cid, DQ_DEMS_LEGACY),\r\np_spq->cid, db.params, db.agg_flags,\r\nqed_chain_get_prod_idx(p_chain));\r\nreturn 0;\r\n}\r\nstatic int\r\nqed_async_event_completion(struct qed_hwfn *p_hwfn,\r\nstruct event_ring_entry *p_eqe)\r\n{\r\nqed_spq_async_comp_cb cb;\r\nif (!p_hwfn->p_spq || (p_eqe->protocol_id >= MAX_PROTOCOL_TYPE))\r\nreturn -EINVAL;\r\ncb = p_hwfn->p_spq->async_comp_cb[p_eqe->protocol_id];\r\nif (cb) {\r\nreturn cb(p_hwfn, p_eqe->opcode, p_eqe->echo,\r\n&p_eqe->data, p_eqe->fw_return_code);\r\n} else {\r\nDP_NOTICE(p_hwfn,\r\n"Unknown Async completion for protocol: %d\n",\r\np_eqe->protocol_id);\r\nreturn -EINVAL;\r\n}\r\n}\r\nint\r\nqed_spq_register_async_cb(struct qed_hwfn *p_hwfn,\r\nenum protocol_type protocol_id,\r\nqed_spq_async_comp_cb cb)\r\n{\r\nif (!p_hwfn->p_spq || (protocol_id >= MAX_PROTOCOL_TYPE))\r\nreturn -EINVAL;\r\np_hwfn->p_spq->async_comp_cb[protocol_id] = cb;\r\nreturn 0;\r\n}\r\nvoid\r\nqed_spq_unregister_async_cb(struct qed_hwfn *p_hwfn,\r\nenum protocol_type protocol_id)\r\n{\r\nif (!p_hwfn->p_spq || (protocol_id >= MAX_PROTOCOL_TYPE))\r\nreturn;\r\np_hwfn->p_spq->async_comp_cb[protocol_id] = NULL;\r\n}\r\nvoid qed_eq_prod_update(struct qed_hwfn *p_hwfn, u16 prod)\r\n{\r\nu32 addr = GTT_BAR0_MAP_REG_USDM_RAM +\r\nUSTORM_EQE_CONS_OFFSET(p_hwfn->rel_pf_id);\r\nREG_WR16(p_hwfn, addr, prod);\r\nmmiowb();\r\n}\r\nint qed_eq_completion(struct qed_hwfn *p_hwfn, void *cookie)\r\n{\r\nstruct qed_eq *p_eq = cookie;\r\nstruct qed_chain *p_chain = &p_eq->chain;\r\nint rc = 0;\r\nu16 fw_cons_idx = le16_to_cpu(*p_eq->p_fw_cons);\r\nDP_VERBOSE(p_hwfn, QED_MSG_SPQ, "fw_cons_idx %x\n", fw_cons_idx);\r\nif ((fw_cons_idx & qed_chain_get_usable_per_page(p_chain)) ==\r\nqed_chain_get_usable_per_page(p_chain))\r\nfw_cons_idx += qed_chain_get_unusable_per_page(p_chain);\r\nwhile (fw_cons_idx != qed_chain_get_cons_idx(p_chain)) {\r\nstruct event_ring_entry *p_eqe = qed_chain_consume(p_chain);\r\nif (!p_eqe) {\r\nrc = -EINVAL;\r\nbreak;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\r\n"op %x prot %x res0 %x echo %x fwret %x flags %x\n",\r\np_eqe->opcode,\r\np_eqe->protocol_id,\r\np_eqe->reserved0,\r\nle16_to_cpu(p_eqe->echo),\r\np_eqe->fw_return_code,\r\np_eqe->flags);\r\nif (GET_FIELD(p_eqe->flags, EVENT_RING_ENTRY_ASYNC)) {\r\nif (qed_async_event_completion(p_hwfn, p_eqe))\r\nrc = -EINVAL;\r\n} else if (qed_spq_completion(p_hwfn,\r\np_eqe->echo,\r\np_eqe->fw_return_code,\r\n&p_eqe->data)) {\r\nrc = -EINVAL;\r\n}\r\nqed_chain_recycle_consumed(p_chain);\r\n}\r\nqed_eq_prod_update(p_hwfn, qed_chain_get_prod_idx(p_chain));\r\nreturn rc;\r\n}\r\nint qed_eq_alloc(struct qed_hwfn *p_hwfn, u16 num_elem)\r\n{\r\nstruct qed_eq *p_eq;\r\np_eq = kzalloc(sizeof(*p_eq), GFP_KERNEL);\r\nif (!p_eq)\r\nreturn -ENOMEM;\r\nif (qed_chain_alloc(p_hwfn->cdev,\r\nQED_CHAIN_USE_TO_PRODUCE,\r\nQED_CHAIN_MODE_PBL,\r\nQED_CHAIN_CNT_TYPE_U16,\r\nnum_elem,\r\nsizeof(union event_ring_element),\r\n&p_eq->chain, NULL))\r\ngoto eq_allocate_fail;\r\nqed_int_register_cb(p_hwfn, qed_eq_completion,\r\np_eq, &p_eq->eq_sb_index, &p_eq->p_fw_cons);\r\np_hwfn->p_eq = p_eq;\r\nreturn 0;\r\neq_allocate_fail:\r\nkfree(p_eq);\r\nreturn -ENOMEM;\r\n}\r\nvoid qed_eq_setup(struct qed_hwfn *p_hwfn)\r\n{\r\nqed_chain_reset(&p_hwfn->p_eq->chain);\r\n}\r\nvoid qed_eq_free(struct qed_hwfn *p_hwfn)\r\n{\r\nif (!p_hwfn->p_eq)\r\nreturn;\r\nqed_chain_free(p_hwfn->cdev, &p_hwfn->p_eq->chain);\r\nkfree(p_hwfn->p_eq);\r\np_hwfn->p_eq = NULL;\r\n}\r\nstatic int qed_cqe_completion(struct qed_hwfn *p_hwfn,\r\nstruct eth_slow_path_rx_cqe *cqe,\r\nenum protocol_type protocol)\r\n{\r\nif (IS_VF(p_hwfn->cdev))\r\nreturn 0;\r\nreturn qed_spq_completion(p_hwfn, cqe->echo, 0, NULL);\r\n}\r\nint qed_eth_cqe_completion(struct qed_hwfn *p_hwfn,\r\nstruct eth_slow_path_rx_cqe *cqe)\r\n{\r\nint rc;\r\nrc = qed_cqe_completion(p_hwfn, cqe, PROTOCOLID_ETH);\r\nif (rc)\r\nDP_NOTICE(p_hwfn,\r\n"Failed to handle RXQ CQE [cmd 0x%02x]\n",\r\ncqe->ramrod_cmd_id);\r\nreturn rc;\r\n}\r\nvoid qed_spq_setup(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_spq *p_spq = p_hwfn->p_spq;\r\nstruct qed_spq_entry *p_virt = NULL;\r\ndma_addr_t p_phys = 0;\r\nu32 i, capacity;\r\nINIT_LIST_HEAD(&p_spq->pending);\r\nINIT_LIST_HEAD(&p_spq->completion_pending);\r\nINIT_LIST_HEAD(&p_spq->free_pool);\r\nINIT_LIST_HEAD(&p_spq->unlimited_pending);\r\nspin_lock_init(&p_spq->lock);\r\np_phys = p_spq->p_phys + offsetof(struct qed_spq_entry, ramrod);\r\np_virt = p_spq->p_virt;\r\ncapacity = qed_chain_get_capacity(&p_spq->chain);\r\nfor (i = 0; i < capacity; i++) {\r\nDMA_REGPAIR_LE(p_virt->elem.data_ptr, p_phys);\r\nlist_add_tail(&p_virt->list, &p_spq->free_pool);\r\np_virt++;\r\np_phys += sizeof(struct qed_spq_entry);\r\n}\r\np_spq->normal_count = 0;\r\np_spq->comp_count = 0;\r\np_spq->comp_sent_count = 0;\r\np_spq->unlimited_pending_count = 0;\r\nbitmap_zero(p_spq->p_comp_bitmap, SPQ_RING_SIZE);\r\np_spq->comp_bitmap_idx = 0;\r\nqed_cxt_acquire_cid(p_hwfn, PROTOCOLID_CORE, &p_spq->cid);\r\nqed_spq_hw_initialize(p_hwfn, p_spq);\r\nqed_chain_reset(&p_spq->chain);\r\n}\r\nint qed_spq_alloc(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_spq_entry *p_virt = NULL;\r\nstruct qed_spq *p_spq = NULL;\r\ndma_addr_t p_phys = 0;\r\nu32 capacity;\r\np_spq = kzalloc(sizeof(struct qed_spq), GFP_KERNEL);\r\nif (!p_spq)\r\nreturn -ENOMEM;\r\nif (qed_chain_alloc(p_hwfn->cdev,\r\nQED_CHAIN_USE_TO_PRODUCE,\r\nQED_CHAIN_MODE_SINGLE,\r\nQED_CHAIN_CNT_TYPE_U16,\r\n0,\r\nsizeof(struct slow_path_element),\r\n&p_spq->chain, NULL))\r\ngoto spq_allocate_fail;\r\ncapacity = qed_chain_get_capacity(&p_spq->chain);\r\np_virt = dma_alloc_coherent(&p_hwfn->cdev->pdev->dev,\r\ncapacity * sizeof(struct qed_spq_entry),\r\n&p_phys, GFP_KERNEL);\r\nif (!p_virt)\r\ngoto spq_allocate_fail;\r\np_spq->p_virt = p_virt;\r\np_spq->p_phys = p_phys;\r\np_hwfn->p_spq = p_spq;\r\nreturn 0;\r\nspq_allocate_fail:\r\nqed_chain_free(p_hwfn->cdev, &p_spq->chain);\r\nkfree(p_spq);\r\nreturn -ENOMEM;\r\n}\r\nvoid qed_spq_free(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_spq *p_spq = p_hwfn->p_spq;\r\nu32 capacity;\r\nif (!p_spq)\r\nreturn;\r\nif (p_spq->p_virt) {\r\ncapacity = qed_chain_get_capacity(&p_spq->chain);\r\ndma_free_coherent(&p_hwfn->cdev->pdev->dev,\r\ncapacity *\r\nsizeof(struct qed_spq_entry),\r\np_spq->p_virt, p_spq->p_phys);\r\n}\r\nqed_chain_free(p_hwfn->cdev, &p_spq->chain);\r\nkfree(p_spq);\r\np_hwfn->p_spq = NULL;\r\n}\r\nint qed_spq_get_entry(struct qed_hwfn *p_hwfn, struct qed_spq_entry **pp_ent)\r\n{\r\nstruct qed_spq *p_spq = p_hwfn->p_spq;\r\nstruct qed_spq_entry *p_ent = NULL;\r\nint rc = 0;\r\nspin_lock_bh(&p_spq->lock);\r\nif (list_empty(&p_spq->free_pool)) {\r\np_ent = kzalloc(sizeof(*p_ent), GFP_ATOMIC);\r\nif (!p_ent) {\r\nDP_NOTICE(p_hwfn,\r\n"Failed to allocate an SPQ entry for a pending ramrod\n");\r\nrc = -ENOMEM;\r\ngoto out_unlock;\r\n}\r\np_ent->queue = &p_spq->unlimited_pending;\r\n} else {\r\np_ent = list_first_entry(&p_spq->free_pool,\r\nstruct qed_spq_entry, list);\r\nlist_del(&p_ent->list);\r\np_ent->queue = &p_spq->pending;\r\n}\r\n*pp_ent = p_ent;\r\nout_unlock:\r\nspin_unlock_bh(&p_spq->lock);\r\nreturn rc;\r\n}\r\nstatic void __qed_spq_return_entry(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq_entry *p_ent)\r\n{\r\nlist_add_tail(&p_ent->list, &p_hwfn->p_spq->free_pool);\r\n}\r\nvoid qed_spq_return_entry(struct qed_hwfn *p_hwfn, struct qed_spq_entry *p_ent)\r\n{\r\nspin_lock_bh(&p_hwfn->p_spq->lock);\r\n__qed_spq_return_entry(p_hwfn, p_ent);\r\nspin_unlock_bh(&p_hwfn->p_spq->lock);\r\n}\r\nstatic int qed_spq_add_entry(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq_entry *p_ent,\r\nenum spq_priority priority)\r\n{\r\nstruct qed_spq *p_spq = p_hwfn->p_spq;\r\nif (p_ent->queue == &p_spq->unlimited_pending) {\r\nif (list_empty(&p_spq->free_pool)) {\r\nlist_add_tail(&p_ent->list, &p_spq->unlimited_pending);\r\np_spq->unlimited_pending_count++;\r\nreturn 0;\r\n} else {\r\nstruct qed_spq_entry *p_en2;\r\np_en2 = list_first_entry(&p_spq->free_pool,\r\nstruct qed_spq_entry, list);\r\nlist_del(&p_en2->list);\r\np_ent->elem.data_ptr = p_en2->elem.data_ptr;\r\n*p_en2 = *p_ent;\r\nif (p_ent->comp_mode != QED_SPQ_MODE_EBLOCK)\r\nkfree(p_ent);\r\np_ent = p_en2;\r\n}\r\n}\r\nswitch (priority) {\r\ncase QED_SPQ_PRIORITY_NORMAL:\r\nlist_add_tail(&p_ent->list, &p_spq->pending);\r\np_spq->normal_count++;\r\nbreak;\r\ncase QED_SPQ_PRIORITY_HIGH:\r\nlist_add(&p_ent->list, &p_spq->pending);\r\np_spq->high_count++;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nu32 qed_spq_get_cid(struct qed_hwfn *p_hwfn)\r\n{\r\nif (!p_hwfn->p_spq)\r\nreturn 0xffffffff;\r\nreturn p_hwfn->p_spq->cid;\r\n}\r\nstatic int qed_spq_post_list(struct qed_hwfn *p_hwfn,\r\nstruct list_head *head, u32 keep_reserve)\r\n{\r\nstruct qed_spq *p_spq = p_hwfn->p_spq;\r\nint rc;\r\nwhile (qed_chain_get_elem_left(&p_spq->chain) > keep_reserve &&\r\n!list_empty(head)) {\r\nstruct qed_spq_entry *p_ent =\r\nlist_first_entry(head, struct qed_spq_entry, list);\r\nlist_del(&p_ent->list);\r\nlist_add_tail(&p_ent->list, &p_spq->completion_pending);\r\np_spq->comp_sent_count++;\r\nrc = qed_spq_hw_post(p_hwfn, p_spq, p_ent);\r\nif (rc) {\r\nlist_del(&p_ent->list);\r\n__qed_spq_return_entry(p_hwfn, p_ent);\r\nreturn rc;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int qed_spq_pend_post(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_spq *p_spq = p_hwfn->p_spq;\r\nstruct qed_spq_entry *p_ent = NULL;\r\nwhile (!list_empty(&p_spq->free_pool)) {\r\nif (list_empty(&p_spq->unlimited_pending))\r\nbreak;\r\np_ent = list_first_entry(&p_spq->unlimited_pending,\r\nstruct qed_spq_entry, list);\r\nif (!p_ent)\r\nreturn -EINVAL;\r\nlist_del(&p_ent->list);\r\nqed_spq_add_entry(p_hwfn, p_ent, p_ent->priority);\r\n}\r\nreturn qed_spq_post_list(p_hwfn, &p_spq->pending,\r\nSPQ_HIGH_PRI_RESERVE_DEFAULT);\r\n}\r\nint qed_spq_post(struct qed_hwfn *p_hwfn,\r\nstruct qed_spq_entry *p_ent, u8 *fw_return_code)\r\n{\r\nint rc = 0;\r\nstruct qed_spq *p_spq = p_hwfn ? p_hwfn->p_spq : NULL;\r\nbool b_ret_ent = true;\r\nif (!p_hwfn)\r\nreturn -EINVAL;\r\nif (!p_ent) {\r\nDP_NOTICE(p_hwfn, "Got a NULL pointer\n");\r\nreturn -EINVAL;\r\n}\r\nrc = qed_spq_fill_entry(p_hwfn, p_ent);\r\nspin_lock_bh(&p_spq->lock);\r\nif (rc)\r\ngoto spq_post_fail;\r\nrc = qed_spq_add_entry(p_hwfn, p_ent, p_ent->priority);\r\nif (rc)\r\ngoto spq_post_fail;\r\nrc = qed_spq_pend_post(p_hwfn);\r\nif (rc) {\r\nb_ret_ent = false;\r\ngoto spq_post_fail;\r\n}\r\nspin_unlock_bh(&p_spq->lock);\r\nif (p_ent->comp_mode == QED_SPQ_MODE_EBLOCK) {\r\nrc = qed_spq_block(p_hwfn, p_ent, fw_return_code,\r\np_ent->queue == &p_spq->unlimited_pending);\r\nif (p_ent->queue == &p_spq->unlimited_pending) {\r\nkfree(p_ent);\r\nreturn rc;\r\n}\r\nif (rc)\r\ngoto spq_post_fail2;\r\nqed_spq_return_entry(p_hwfn, p_ent);\r\n}\r\nreturn rc;\r\nspq_post_fail2:\r\nspin_lock_bh(&p_spq->lock);\r\nlist_del(&p_ent->list);\r\nqed_chain_return_produced(&p_spq->chain);\r\nspq_post_fail:\r\nif (b_ret_ent)\r\n__qed_spq_return_entry(p_hwfn, p_ent);\r\nspin_unlock_bh(&p_spq->lock);\r\nreturn rc;\r\n}\r\nint qed_spq_completion(struct qed_hwfn *p_hwfn,\r\n__le16 echo,\r\nu8 fw_return_code,\r\nunion event_ring_data *p_data)\r\n{\r\nstruct qed_spq *p_spq;\r\nstruct qed_spq_entry *p_ent = NULL;\r\nstruct qed_spq_entry *tmp;\r\nstruct qed_spq_entry *found = NULL;\r\nint rc;\r\nif (!p_hwfn)\r\nreturn -EINVAL;\r\np_spq = p_hwfn->p_spq;\r\nif (!p_spq)\r\nreturn -EINVAL;\r\nspin_lock_bh(&p_spq->lock);\r\nlist_for_each_entry_safe(p_ent, tmp, &p_spq->completion_pending, list) {\r\nif (p_ent->elem.hdr.echo == echo) {\r\nu16 pos = le16_to_cpu(echo) % SPQ_RING_SIZE;\r\nlist_del(&p_ent->list);\r\n__set_bit(pos, p_spq->p_comp_bitmap);\r\nwhile (test_bit(p_spq->comp_bitmap_idx,\r\np_spq->p_comp_bitmap)) {\r\n__clear_bit(p_spq->comp_bitmap_idx,\r\np_spq->p_comp_bitmap);\r\np_spq->comp_bitmap_idx++;\r\nqed_chain_return_produced(&p_spq->chain);\r\n}\r\np_spq->comp_count++;\r\nfound = p_ent;\r\nbreak;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\r\n"Got completion for echo %04x - doesn't match echo %04x in completion pending list\n",\r\nle16_to_cpu(echo),\r\nle16_to_cpu(p_ent->elem.hdr.echo));\r\n}\r\nspin_unlock_bh(&p_spq->lock);\r\nif (!found) {\r\nDP_NOTICE(p_hwfn,\r\n"Failed to find an entry this EQE [echo %04x] completes\n",\r\nle16_to_cpu(echo));\r\nreturn -EEXIST;\r\n}\r\nDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\r\n"Complete EQE [echo %04x]: func %p cookie %p)\n",\r\nle16_to_cpu(echo),\r\np_ent->comp_cb.function, p_ent->comp_cb.cookie);\r\nif (found->comp_cb.function)\r\nfound->comp_cb.function(p_hwfn, found->comp_cb.cookie, p_data,\r\nfw_return_code);\r\nelse\r\nDP_VERBOSE(p_hwfn,\r\nQED_MSG_SPQ,\r\n"Got a completion without a callback function\n");\r\nif ((found->comp_mode != QED_SPQ_MODE_EBLOCK) ||\r\n(found->queue == &p_spq->unlimited_pending))\r\nqed_spq_return_entry(p_hwfn, found);\r\nspin_lock_bh(&p_spq->lock);\r\nrc = qed_spq_pend_post(p_hwfn);\r\nspin_unlock_bh(&p_spq->lock);\r\nreturn rc;\r\n}\r\nint qed_consq_alloc(struct qed_hwfn *p_hwfn)\r\n{\r\nstruct qed_consq *p_consq;\r\np_consq = kzalloc(sizeof(*p_consq), GFP_KERNEL);\r\nif (!p_consq)\r\nreturn -ENOMEM;\r\nif (qed_chain_alloc(p_hwfn->cdev,\r\nQED_CHAIN_USE_TO_PRODUCE,\r\nQED_CHAIN_MODE_PBL,\r\nQED_CHAIN_CNT_TYPE_U16,\r\nQED_CHAIN_PAGE_SIZE / 0x80,\r\n0x80, &p_consq->chain, NULL))\r\ngoto consq_allocate_fail;\r\np_hwfn->p_consq = p_consq;\r\nreturn 0;\r\nconsq_allocate_fail:\r\nkfree(p_consq);\r\nreturn -ENOMEM;\r\n}\r\nvoid qed_consq_setup(struct qed_hwfn *p_hwfn)\r\n{\r\nqed_chain_reset(&p_hwfn->p_consq->chain);\r\n}\r\nvoid qed_consq_free(struct qed_hwfn *p_hwfn)\r\n{\r\nif (!p_hwfn->p_consq)\r\nreturn;\r\nqed_chain_free(p_hwfn->cdev, &p_hwfn->p_consq->chain);\r\nkfree(p_hwfn->p_consq);\r\np_hwfn->p_consq = NULL;\r\n}
