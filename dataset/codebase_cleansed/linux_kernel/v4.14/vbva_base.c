static u32 vbva_buffer_available(const struct vbva_buffer *vbva)\r\n{\r\ns32 diff = vbva->data_offset - vbva->free_offset;\r\nreturn diff > 0 ? diff : vbva->data_len + diff;\r\n}\r\nstatic void vbva_buffer_place_data_at(struct vbva_buf_ctx *vbva_ctx,\r\nconst void *p, u32 len, u32 offset)\r\n{\r\nstruct vbva_buffer *vbva = vbva_ctx->vbva;\r\nu32 bytes_till_boundary = vbva->data_len - offset;\r\nu8 *dst = &vbva->data[offset];\r\ns32 diff = len - bytes_till_boundary;\r\nif (diff <= 0) {\r\nmemcpy(dst, p, len);\r\n} else {\r\nmemcpy(dst, p, bytes_till_boundary);\r\nmemcpy(&vbva->data[0], (u8 *)p + bytes_till_boundary, diff);\r\n}\r\n}\r\nstatic void vbva_buffer_flush(struct gen_pool *ctx)\r\n{\r\nstruct vbva_flush *p;\r\np = hgsmi_buffer_alloc(ctx, sizeof(*p), HGSMI_CH_VBVA, VBVA_FLUSH);\r\nif (!p)\r\nreturn;\r\np->reserved = 0;\r\nhgsmi_buffer_submit(ctx, p);\r\nhgsmi_buffer_free(ctx, p);\r\n}\r\nbool vbva_write(struct vbva_buf_ctx *vbva_ctx, struct gen_pool *ctx,\r\nconst void *p, u32 len)\r\n{\r\nstruct vbva_record *record;\r\nstruct vbva_buffer *vbva;\r\nu32 available;\r\nvbva = vbva_ctx->vbva;\r\nrecord = vbva_ctx->record;\r\nif (!vbva || vbva_ctx->buffer_overflow ||\r\n!record || !(record->len_and_flags & VBVA_F_RECORD_PARTIAL))\r\nreturn false;\r\navailable = vbva_buffer_available(vbva);\r\nwhile (len > 0) {\r\nu32 chunk = len;\r\nif (chunk >= available) {\r\nvbva_buffer_flush(ctx);\r\navailable = vbva_buffer_available(vbva);\r\n}\r\nif (chunk >= available) {\r\nif (WARN_ON(available <= vbva->partial_write_tresh)) {\r\nvbva_ctx->buffer_overflow = true;\r\nreturn false;\r\n}\r\nchunk = available - vbva->partial_write_tresh;\r\n}\r\nvbva_buffer_place_data_at(vbva_ctx, p, chunk,\r\nvbva->free_offset);\r\nvbva->free_offset = (vbva->free_offset + chunk) %\r\nvbva->data_len;\r\nrecord->len_and_flags += chunk;\r\navailable -= chunk;\r\nlen -= chunk;\r\np += chunk;\r\n}\r\nreturn true;\r\n}\r\nstatic bool vbva_inform_host(struct vbva_buf_ctx *vbva_ctx,\r\nstruct gen_pool *ctx, s32 screen, bool enable)\r\n{\r\nstruct vbva_enable_ex *p;\r\nbool ret;\r\np = hgsmi_buffer_alloc(ctx, sizeof(*p), HGSMI_CH_VBVA, VBVA_ENABLE);\r\nif (!p)\r\nreturn false;\r\np->base.flags = enable ? VBVA_F_ENABLE : VBVA_F_DISABLE;\r\np->base.offset = vbva_ctx->buffer_offset;\r\np->base.result = VERR_NOT_SUPPORTED;\r\nif (screen >= 0) {\r\np->base.flags |= VBVA_F_EXTENDED | VBVA_F_ABSOFFSET;\r\np->screen_id = screen;\r\n}\r\nhgsmi_buffer_submit(ctx, p);\r\nif (enable)\r\nret = RT_SUCCESS(p->base.result);\r\nelse\r\nret = true;\r\nhgsmi_buffer_free(ctx, p);\r\nreturn ret;\r\n}\r\nbool vbva_enable(struct vbva_buf_ctx *vbva_ctx, struct gen_pool *ctx,\r\nstruct vbva_buffer *vbva, s32 screen)\r\n{\r\nbool ret = false;\r\nmemset(vbva, 0, sizeof(*vbva));\r\nvbva->partial_write_tresh = 256;\r\nvbva->data_len = vbva_ctx->buffer_length - sizeof(struct vbva_buffer);\r\nvbva_ctx->vbva = vbva;\r\nret = vbva_inform_host(vbva_ctx, ctx, screen, true);\r\nif (!ret)\r\nvbva_disable(vbva_ctx, ctx, screen);\r\nreturn ret;\r\n}\r\nvoid vbva_disable(struct vbva_buf_ctx *vbva_ctx, struct gen_pool *ctx,\r\ns32 screen)\r\n{\r\nvbva_ctx->buffer_overflow = false;\r\nvbva_ctx->record = NULL;\r\nvbva_ctx->vbva = NULL;\r\nvbva_inform_host(vbva_ctx, ctx, screen, false);\r\n}\r\nbool vbva_buffer_begin_update(struct vbva_buf_ctx *vbva_ctx,\r\nstruct gen_pool *ctx)\r\n{\r\nstruct vbva_record *record;\r\nu32 next;\r\nif (!vbva_ctx->vbva ||\r\n!(vbva_ctx->vbva->host_flags.host_events & VBVA_F_MODE_ENABLED))\r\nreturn false;\r\nWARN_ON(vbva_ctx->buffer_overflow || vbva_ctx->record);\r\nnext = (vbva_ctx->vbva->record_free_index + 1) % VBVA_MAX_RECORDS;\r\nif (next == vbva_ctx->vbva->record_first_index)\r\nvbva_buffer_flush(ctx);\r\nif (next == vbva_ctx->vbva->record_first_index)\r\nreturn false;\r\nrecord = &vbva_ctx->vbva->records[vbva_ctx->vbva->record_free_index];\r\nrecord->len_and_flags = VBVA_F_RECORD_PARTIAL;\r\nvbva_ctx->vbva->record_free_index = next;\r\nvbva_ctx->record = record;\r\nreturn true;\r\n}\r\nvoid vbva_buffer_end_update(struct vbva_buf_ctx *vbva_ctx)\r\n{\r\nstruct vbva_record *record = vbva_ctx->record;\r\nWARN_ON(!vbva_ctx->vbva || !record ||\r\n!(record->len_and_flags & VBVA_F_RECORD_PARTIAL));\r\nrecord->len_and_flags &= ~VBVA_F_RECORD_PARTIAL;\r\nvbva_ctx->buffer_overflow = false;\r\nvbva_ctx->record = NULL;\r\n}\r\nvoid vbva_setup_buffer_context(struct vbva_buf_ctx *vbva_ctx,\r\nu32 buffer_offset, u32 buffer_length)\r\n{\r\nvbva_ctx->buffer_offset = buffer_offset;\r\nvbva_ctx->buffer_length = buffer_length;\r\n}
