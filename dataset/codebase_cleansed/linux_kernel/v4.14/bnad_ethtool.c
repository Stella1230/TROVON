static int\r\nbnad_get_link_ksettings(struct net_device *netdev,\r\nstruct ethtool_link_ksettings *cmd)\r\n{\r\nu32 supported, advertising;\r\nsupported = SUPPORTED_10000baseT_Full;\r\nadvertising = ADVERTISED_10000baseT_Full;\r\ncmd->base.autoneg = AUTONEG_DISABLE;\r\nsupported |= SUPPORTED_FIBRE;\r\nadvertising |= ADVERTISED_FIBRE;\r\ncmd->base.port = PORT_FIBRE;\r\ncmd->base.phy_address = 0;\r\nif (netif_carrier_ok(netdev)) {\r\ncmd->base.speed = SPEED_10000;\r\ncmd->base.duplex = DUPLEX_FULL;\r\n} else {\r\ncmd->base.speed = SPEED_UNKNOWN;\r\ncmd->base.duplex = DUPLEX_UNKNOWN;\r\n}\r\nethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported,\r\nsupported);\r\nethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.advertising,\r\nadvertising);\r\nreturn 0;\r\n}\r\nstatic int\r\nbnad_set_link_ksettings(struct net_device *netdev,\r\nconst struct ethtool_link_ksettings *cmd)\r\n{\r\nif (cmd->base.autoneg == AUTONEG_ENABLE)\r\nreturn -EOPNOTSUPP;\r\nif ((cmd->base.speed == SPEED_10000) &&\r\n(cmd->base.duplex == DUPLEX_FULL))\r\nreturn 0;\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic void\r\nbnad_get_drvinfo(struct net_device *netdev, struct ethtool_drvinfo *drvinfo)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nstruct bfa_ioc_attr *ioc_attr;\r\nunsigned long flags;\r\nstrlcpy(drvinfo->driver, BNAD_NAME, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, BNAD_VERSION, sizeof(drvinfo->version));\r\nioc_attr = kzalloc(sizeof(*ioc_attr), GFP_KERNEL);\r\nif (ioc_attr) {\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nbfa_nw_ioc_get_attr(&bnad->bna.ioceth.ioc, ioc_attr);\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nstrlcpy(drvinfo->fw_version, ioc_attr->adapter_attr.fw_ver,\r\nsizeof(drvinfo->fw_version));\r\nkfree(ioc_attr);\r\n}\r\nstrlcpy(drvinfo->bus_info, pci_name(bnad->pcidev),\r\nsizeof(drvinfo->bus_info));\r\n}\r\nstatic void\r\nbnad_get_wol(struct net_device *netdev, struct ethtool_wolinfo *wolinfo)\r\n{\r\nwolinfo->supported = 0;\r\nwolinfo->wolopts = 0;\r\n}\r\nstatic int\r\nbnad_get_coalesce(struct net_device *netdev, struct ethtool_coalesce *coalesce)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nunsigned long flags;\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\ncoalesce->use_adaptive_rx_coalesce =\r\n(bnad->cfg_flags & BNAD_CF_DIM_ENABLED) ? true : false;\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\ncoalesce->rx_coalesce_usecs = bnad->rx_coalescing_timeo *\r\nBFI_COALESCING_TIMER_UNIT;\r\ncoalesce->tx_coalesce_usecs = bnad->tx_coalescing_timeo *\r\nBFI_COALESCING_TIMER_UNIT;\r\ncoalesce->tx_max_coalesced_frames = BFI_TX_INTERPKT_COUNT;\r\nreturn 0;\r\n}\r\nstatic int\r\nbnad_set_coalesce(struct net_device *netdev, struct ethtool_coalesce *coalesce)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nunsigned long flags;\r\nint to_del = 0;\r\nif (coalesce->rx_coalesce_usecs == 0 ||\r\ncoalesce->rx_coalesce_usecs >\r\nBFI_MAX_COALESCING_TIMEO * BFI_COALESCING_TIMER_UNIT)\r\nreturn -EINVAL;\r\nif (coalesce->tx_coalesce_usecs == 0 ||\r\ncoalesce->tx_coalesce_usecs >\r\nBFI_MAX_COALESCING_TIMEO * BFI_COALESCING_TIMER_UNIT)\r\nreturn -EINVAL;\r\nmutex_lock(&bnad->conf_mutex);\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nif (coalesce->use_adaptive_rx_coalesce) {\r\nif (!(bnad->cfg_flags & BNAD_CF_DIM_ENABLED)) {\r\nbnad->cfg_flags |= BNAD_CF_DIM_ENABLED;\r\nbnad_dim_timer_start(bnad);\r\n}\r\n} else {\r\nif (bnad->cfg_flags & BNAD_CF_DIM_ENABLED) {\r\nbnad->cfg_flags &= ~BNAD_CF_DIM_ENABLED;\r\nif (bnad->cfg_flags & BNAD_CF_DIM_ENABLED &&\r\ntest_bit(BNAD_RF_DIM_TIMER_RUNNING,\r\n&bnad->run_flags)) {\r\nclear_bit(BNAD_RF_DIM_TIMER_RUNNING,\r\n&bnad->run_flags);\r\nto_del = 1;\r\n}\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nif (to_del)\r\ndel_timer_sync(&bnad->dim_timer);\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nbnad_rx_coalescing_timeo_set(bnad);\r\n}\r\n}\r\nif (bnad->tx_coalescing_timeo != coalesce->tx_coalesce_usecs /\r\nBFI_COALESCING_TIMER_UNIT) {\r\nbnad->tx_coalescing_timeo = coalesce->tx_coalesce_usecs /\r\nBFI_COALESCING_TIMER_UNIT;\r\nbnad_tx_coalescing_timeo_set(bnad);\r\n}\r\nif (bnad->rx_coalescing_timeo != coalesce->rx_coalesce_usecs /\r\nBFI_COALESCING_TIMER_UNIT) {\r\nbnad->rx_coalescing_timeo = coalesce->rx_coalesce_usecs /\r\nBFI_COALESCING_TIMER_UNIT;\r\nif (!(bnad->cfg_flags & BNAD_CF_DIM_ENABLED))\r\nbnad_rx_coalescing_timeo_set(bnad);\r\n}\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn 0;\r\n}\r\nstatic void\r\nbnad_get_ringparam(struct net_device *netdev,\r\nstruct ethtool_ringparam *ringparam)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nringparam->rx_max_pending = BNAD_MAX_RXQ_DEPTH;\r\nringparam->tx_max_pending = BNAD_MAX_TXQ_DEPTH;\r\nringparam->rx_pending = bnad->rxq_depth;\r\nringparam->tx_pending = bnad->txq_depth;\r\n}\r\nstatic int\r\nbnad_set_ringparam(struct net_device *netdev,\r\nstruct ethtool_ringparam *ringparam)\r\n{\r\nint i, current_err, err = 0;\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nunsigned long flags;\r\nmutex_lock(&bnad->conf_mutex);\r\nif (ringparam->rx_pending == bnad->rxq_depth &&\r\nringparam->tx_pending == bnad->txq_depth) {\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn 0;\r\n}\r\nif (ringparam->rx_pending < BNAD_MIN_Q_DEPTH ||\r\nringparam->rx_pending > BNAD_MAX_RXQ_DEPTH ||\r\n!is_power_of_2(ringparam->rx_pending)) {\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn -EINVAL;\r\n}\r\nif (ringparam->tx_pending < BNAD_MIN_Q_DEPTH ||\r\nringparam->tx_pending > BNAD_MAX_TXQ_DEPTH ||\r\n!is_power_of_2(ringparam->tx_pending)) {\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn -EINVAL;\r\n}\r\nif (ringparam->rx_pending != bnad->rxq_depth) {\r\nbnad->rxq_depth = ringparam->rx_pending;\r\nif (!netif_running(netdev)) {\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn 0;\r\n}\r\nfor (i = 0; i < bnad->num_rx; i++) {\r\nif (!bnad->rx_info[i].rx)\r\ncontinue;\r\nbnad_destroy_rx(bnad, i);\r\ncurrent_err = bnad_setup_rx(bnad, i);\r\nif (current_err && !err)\r\nerr = current_err;\r\n}\r\nif (!err && bnad->rx_info[0].rx) {\r\nbnad_restore_vlans(bnad, 0);\r\nbnad_enable_default_bcast(bnad);\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nbnad_mac_addr_set_locked(bnad, netdev->dev_addr);\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nbnad->cfg_flags &= ~(BNAD_CF_ALLMULTI |\r\nBNAD_CF_PROMISC);\r\nbnad_set_rx_mode(netdev);\r\n}\r\n}\r\nif (ringparam->tx_pending != bnad->txq_depth) {\r\nbnad->txq_depth = ringparam->tx_pending;\r\nif (!netif_running(netdev)) {\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn 0;\r\n}\r\nfor (i = 0; i < bnad->num_tx; i++) {\r\nif (!bnad->tx_info[i].tx)\r\ncontinue;\r\nbnad_destroy_tx(bnad, i);\r\ncurrent_err = bnad_setup_tx(bnad, i);\r\nif (current_err && !err)\r\nerr = current_err;\r\n}\r\n}\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn err;\r\n}\r\nstatic void\r\nbnad_get_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *pauseparam)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\npauseparam->autoneg = 0;\r\npauseparam->rx_pause = bnad->bna.enet.pause_config.rx_pause;\r\npauseparam->tx_pause = bnad->bna.enet.pause_config.tx_pause;\r\n}\r\nstatic int\r\nbnad_set_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *pauseparam)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nstruct bna_pause_config pause_config;\r\nunsigned long flags;\r\nif (pauseparam->autoneg == AUTONEG_ENABLE)\r\nreturn -EINVAL;\r\nmutex_lock(&bnad->conf_mutex);\r\nif (pauseparam->rx_pause != bnad->bna.enet.pause_config.rx_pause ||\r\npauseparam->tx_pause != bnad->bna.enet.pause_config.tx_pause) {\r\npause_config.rx_pause = pauseparam->rx_pause;\r\npause_config.tx_pause = pauseparam->tx_pause;\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nbna_enet_pause_config(&bnad->bna.enet, &pause_config);\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\n}\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn 0;\r\n}\r\nstatic void\r\nbnad_get_strings(struct net_device *netdev, u32 stringset, u8 *string)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nint i, j, q_num;\r\nu32 bmap;\r\nmutex_lock(&bnad->conf_mutex);\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nfor (i = 0; i < BNAD_ETHTOOL_STATS_NUM; i++) {\r\nBUG_ON(!(strlen(bnad_net_stats_strings[i]) <\r\nETH_GSTRING_LEN));\r\nstrncpy(string, bnad_net_stats_strings[i],\r\nETH_GSTRING_LEN);\r\nstring += ETH_GSTRING_LEN;\r\n}\r\nbmap = bna_tx_rid_mask(&bnad->bna);\r\nfor (i = 0; bmap; i++) {\r\nif (bmap & 1) {\r\nsprintf(string, "txf%d_ucast_octets", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_ucast", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_ucast_vlan", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_mcast_octets", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_mcast", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_mcast_vlan", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_bcast_octets", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_bcast", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_bcast_vlan", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_errors", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_filter_vlan", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txf%d_filter_mac_sa", i);\r\nstring += ETH_GSTRING_LEN;\r\n}\r\nbmap >>= 1;\r\n}\r\nbmap = bna_rx_rid_mask(&bnad->bna);\r\nfor (i = 0; bmap; i++) {\r\nif (bmap & 1) {\r\nsprintf(string, "rxf%d_ucast_octets", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_ucast", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_ucast_vlan", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_mcast_octets", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_mcast", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_mcast_vlan", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_bcast_octets", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_bcast", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_bcast_vlan", i);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxf%d_frame_drops", i);\r\nstring += ETH_GSTRING_LEN;\r\n}\r\nbmap >>= 1;\r\n}\r\nq_num = 0;\r\nfor (i = 0; i < bnad->num_rx; i++) {\r\nif (!bnad->rx_info[i].rx)\r\ncontinue;\r\nfor (j = 0; j < bnad->num_rxp_per_rx; j++) {\r\nsprintf(string, "cq%d_producer_index", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "cq%d_consumer_index", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "cq%d_hw_producer_index",\r\nq_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "cq%d_intr", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "cq%d_poll", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "cq%d_schedule", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "cq%d_keep_poll", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "cq%d_complete", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nq_num++;\r\n}\r\n}\r\nq_num = 0;\r\nfor (i = 0; i < bnad->num_rx; i++) {\r\nif (!bnad->rx_info[i].rx)\r\ncontinue;\r\nfor (j = 0; j < bnad->num_rxp_per_rx; j++) {\r\nsprintf(string, "rxq%d_packets", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_bytes", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_packets_with_error",\r\nq_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_allocbuf_failed", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_mapbuf_failed", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_producer_index", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_consumer_index", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nq_num++;\r\nif (bnad->rx_info[i].rx_ctrl[j].ccb &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->\r\nrcb[1] &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->\r\nrcb[1]->rxq) {\r\nsprintf(string, "rxq%d_packets", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_bytes", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string,\r\n"rxq%d_packets_with_error", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_allocbuf_failed",\r\nq_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_mapbuf_failed",\r\nq_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_producer_index",\r\nq_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "rxq%d_consumer_index",\r\nq_num);\r\nstring += ETH_GSTRING_LEN;\r\nq_num++;\r\n}\r\n}\r\n}\r\nq_num = 0;\r\nfor (i = 0; i < bnad->num_tx; i++) {\r\nif (!bnad->tx_info[i].tx)\r\ncontinue;\r\nfor (j = 0; j < bnad->num_txq_per_tx; j++) {\r\nsprintf(string, "txq%d_packets", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txq%d_bytes", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txq%d_producer_index", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txq%d_consumer_index", q_num);\r\nstring += ETH_GSTRING_LEN;\r\nsprintf(string, "txq%d_hw_consumer_index",\r\nq_num);\r\nstring += ETH_GSTRING_LEN;\r\nq_num++;\r\n}\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nmutex_unlock(&bnad->conf_mutex);\r\n}\r\nstatic int\r\nbnad_get_stats_count_locked(struct net_device *netdev)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nint i, j, count = 0, rxf_active_num = 0, txf_active_num = 0;\r\nu32 bmap;\r\nbmap = bna_tx_rid_mask(&bnad->bna);\r\nfor (i = 0; bmap; i++) {\r\nif (bmap & 1)\r\ntxf_active_num++;\r\nbmap >>= 1;\r\n}\r\nbmap = bna_rx_rid_mask(&bnad->bna);\r\nfor (i = 0; bmap; i++) {\r\nif (bmap & 1)\r\nrxf_active_num++;\r\nbmap >>= 1;\r\n}\r\ncount = BNAD_ETHTOOL_STATS_NUM +\r\ntxf_active_num * BNAD_NUM_TXF_COUNTERS +\r\nrxf_active_num * BNAD_NUM_RXF_COUNTERS;\r\nfor (i = 0; i < bnad->num_rx; i++) {\r\nif (!bnad->rx_info[i].rx)\r\ncontinue;\r\ncount += bnad->num_rxp_per_rx * BNAD_NUM_CQ_COUNTERS;\r\ncount += bnad->num_rxp_per_rx * BNAD_NUM_RXQ_COUNTERS;\r\nfor (j = 0; j < bnad->num_rxp_per_rx; j++)\r\nif (bnad->rx_info[i].rx_ctrl[j].ccb &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->rcb[1] &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->rcb[1]->rxq)\r\ncount += BNAD_NUM_RXQ_COUNTERS;\r\n}\r\nfor (i = 0; i < bnad->num_tx; i++) {\r\nif (!bnad->tx_info[i].tx)\r\ncontinue;\r\ncount += bnad->num_txq_per_tx * BNAD_NUM_TXQ_COUNTERS;\r\n}\r\nreturn count;\r\n}\r\nstatic int\r\nbnad_per_q_stats_fill(struct bnad *bnad, u64 *buf, int bi)\r\n{\r\nint i, j;\r\nstruct bna_rcb *rcb = NULL;\r\nstruct bna_tcb *tcb = NULL;\r\nfor (i = 0; i < bnad->num_rx; i++) {\r\nif (!bnad->rx_info[i].rx)\r\ncontinue;\r\nfor (j = 0; j < bnad->num_rxp_per_rx; j++)\r\nif (bnad->rx_info[i].rx_ctrl[j].ccb &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->rcb[0] &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->rcb[0]->rxq) {\r\nbuf[bi++] = bnad->rx_info[i].rx_ctrl[j].\r\nccb->producer_index;\r\nbuf[bi++] = 0;\r\nbuf[bi++] = *(bnad->rx_info[i].rx_ctrl[j].\r\nccb->hw_producer_index);\r\nbuf[bi++] = bnad->rx_info[i].\r\nrx_ctrl[j].rx_intr_ctr;\r\nbuf[bi++] = bnad->rx_info[i].\r\nrx_ctrl[j].rx_poll_ctr;\r\nbuf[bi++] = bnad->rx_info[i].\r\nrx_ctrl[j].rx_schedule;\r\nbuf[bi++] = bnad->rx_info[i].\r\nrx_ctrl[j].rx_keep_poll;\r\nbuf[bi++] = bnad->rx_info[i].\r\nrx_ctrl[j].rx_complete;\r\n}\r\n}\r\nfor (i = 0; i < bnad->num_rx; i++) {\r\nif (!bnad->rx_info[i].rx)\r\ncontinue;\r\nfor (j = 0; j < bnad->num_rxp_per_rx; j++)\r\nif (bnad->rx_info[i].rx_ctrl[j].ccb) {\r\nif (bnad->rx_info[i].rx_ctrl[j].ccb->rcb[0] &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->\r\nrcb[0]->rxq) {\r\nrcb = bnad->rx_info[i].rx_ctrl[j].\r\nccb->rcb[0];\r\nbuf[bi++] = rcb->rxq->rx_packets;\r\nbuf[bi++] = rcb->rxq->rx_bytes;\r\nbuf[bi++] = rcb->rxq->\r\nrx_packets_with_error;\r\nbuf[bi++] = rcb->rxq->\r\nrxbuf_alloc_failed;\r\nbuf[bi++] = rcb->rxq->rxbuf_map_failed;\r\nbuf[bi++] = rcb->producer_index;\r\nbuf[bi++] = rcb->consumer_index;\r\n}\r\nif (bnad->rx_info[i].rx_ctrl[j].ccb->rcb[1] &&\r\nbnad->rx_info[i].rx_ctrl[j].ccb->\r\nrcb[1]->rxq) {\r\nrcb = bnad->rx_info[i].rx_ctrl[j].\r\nccb->rcb[1];\r\nbuf[bi++] = rcb->rxq->rx_packets;\r\nbuf[bi++] = rcb->rxq->rx_bytes;\r\nbuf[bi++] = rcb->rxq->\r\nrx_packets_with_error;\r\nbuf[bi++] = rcb->rxq->\r\nrxbuf_alloc_failed;\r\nbuf[bi++] = rcb->rxq->rxbuf_map_failed;\r\nbuf[bi++] = rcb->producer_index;\r\nbuf[bi++] = rcb->consumer_index;\r\n}\r\n}\r\n}\r\nfor (i = 0; i < bnad->num_tx; i++) {\r\nif (!bnad->tx_info[i].tx)\r\ncontinue;\r\nfor (j = 0; j < bnad->num_txq_per_tx; j++)\r\nif (bnad->tx_info[i].tcb[j] &&\r\nbnad->tx_info[i].tcb[j]->txq) {\r\ntcb = bnad->tx_info[i].tcb[j];\r\nbuf[bi++] = tcb->txq->tx_packets;\r\nbuf[bi++] = tcb->txq->tx_bytes;\r\nbuf[bi++] = tcb->producer_index;\r\nbuf[bi++] = tcb->consumer_index;\r\nbuf[bi++] = *(tcb->hw_consumer_index);\r\n}\r\n}\r\nreturn bi;\r\n}\r\nstatic void\r\nbnad_get_ethtool_stats(struct net_device *netdev, struct ethtool_stats *stats,\r\nu64 *buf)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nint i, j, bi = 0;\r\nunsigned long flags;\r\nstruct rtnl_link_stats64 net_stats64;\r\nu64 *stats64;\r\nu32 bmap;\r\nmutex_lock(&bnad->conf_mutex);\r\nif (bnad_get_stats_count_locked(netdev) != stats->n_stats) {\r\nmutex_unlock(&bnad->conf_mutex);\r\nreturn;\r\n}\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nmemset(&net_stats64, 0, sizeof(net_stats64));\r\nbnad_netdev_qstats_fill(bnad, &net_stats64);\r\nbnad_netdev_hwstats_fill(bnad, &net_stats64);\r\nbuf[bi++] = net_stats64.rx_packets;\r\nbuf[bi++] = net_stats64.tx_packets;\r\nbuf[bi++] = net_stats64.rx_bytes;\r\nbuf[bi++] = net_stats64.tx_bytes;\r\nbuf[bi++] = net_stats64.rx_errors;\r\nbuf[bi++] = net_stats64.tx_errors;\r\nbuf[bi++] = net_stats64.rx_dropped;\r\nbuf[bi++] = net_stats64.tx_dropped;\r\nbuf[bi++] = net_stats64.multicast;\r\nbuf[bi++] = net_stats64.collisions;\r\nbuf[bi++] = net_stats64.rx_length_errors;\r\nbuf[bi++] = net_stats64.rx_crc_errors;\r\nbuf[bi++] = net_stats64.rx_frame_errors;\r\nbuf[bi++] = net_stats64.tx_fifo_errors;\r\nbnad->stats.drv_stats.netif_queue_stopped = netif_queue_stopped(netdev);\r\nstats64 = (u64 *)&bnad->stats.drv_stats;\r\nfor (i = 0; i < sizeof(struct bnad_drv_stats) / sizeof(u64); i++)\r\nbuf[bi++] = stats64[i];\r\nstats64 = (u64 *) &bnad->stats.bna_stats->hw_stats;\r\nfor (i = 0;\r\ni < offsetof(struct bfi_enet_stats, rxf_stats[0]) /\r\nsizeof(u64);\r\ni++)\r\nbuf[bi++] = stats64[i];\r\nbmap = bna_tx_rid_mask(&bnad->bna);\r\nfor (i = 0; bmap; i++) {\r\nif (bmap & 1) {\r\nstats64 = (u64 *)&bnad->stats.bna_stats->\r\nhw_stats.txf_stats[i];\r\nfor (j = 0; j < sizeof(struct bfi_enet_stats_txf) /\r\nsizeof(u64); j++)\r\nbuf[bi++] = stats64[j];\r\n}\r\nbmap >>= 1;\r\n}\r\nbmap = bna_rx_rid_mask(&bnad->bna);\r\nfor (i = 0; bmap; i++) {\r\nif (bmap & 1) {\r\nstats64 = (u64 *)&bnad->stats.bna_stats->\r\nhw_stats.rxf_stats[i];\r\nfor (j = 0; j < sizeof(struct bfi_enet_stats_rxf) /\r\nsizeof(u64); j++)\r\nbuf[bi++] = stats64[j];\r\n}\r\nbmap >>= 1;\r\n}\r\nbi = bnad_per_q_stats_fill(bnad, buf, bi);\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nmutex_unlock(&bnad->conf_mutex);\r\n}\r\nstatic int\r\nbnad_get_sset_count(struct net_device *netdev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn bnad_get_stats_count_locked(netdev);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic u32\r\nbnad_get_flash_partition_by_offset(struct bnad *bnad, u32 offset,\r\nu32 *base_offset)\r\n{\r\nstruct bfa_flash_attr *flash_attr;\r\nstruct bnad_iocmd_comp fcomp;\r\nu32 i, flash_part = 0, ret;\r\nunsigned long flags = 0;\r\nflash_attr = kzalloc(sizeof(struct bfa_flash_attr), GFP_KERNEL);\r\nif (!flash_attr)\r\nreturn 0;\r\nfcomp.bnad = bnad;\r\nfcomp.comp_status = 0;\r\ninit_completion(&fcomp.comp);\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nret = bfa_nw_flash_get_attr(&bnad->bna.flash, flash_attr,\r\nbnad_cb_completion, &fcomp);\r\nif (ret != BFA_STATUS_OK) {\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nkfree(flash_attr);\r\nreturn 0;\r\n}\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nwait_for_completion(&fcomp.comp);\r\nret = fcomp.comp_status;\r\nif (ret == BFA_STATUS_OK) {\r\nfor (i = 0; i < flash_attr->npart; i++) {\r\nif (offset >= flash_attr->part[i].part_off &&\r\noffset < (flash_attr->part[i].part_off +\r\nflash_attr->part[i].part_size)) {\r\nflash_part = flash_attr->part[i].part_type;\r\n*base_offset = flash_attr->part[i].part_off;\r\nbreak;\r\n}\r\n}\r\n}\r\nkfree(flash_attr);\r\nreturn flash_part;\r\n}\r\nstatic int\r\nbnad_get_eeprom_len(struct net_device *netdev)\r\n{\r\nreturn BFA_TOTAL_FLASH_SIZE;\r\n}\r\nstatic int\r\nbnad_get_eeprom(struct net_device *netdev, struct ethtool_eeprom *eeprom,\r\nu8 *bytes)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nstruct bnad_iocmd_comp fcomp;\r\nu32 flash_part = 0, base_offset = 0;\r\nunsigned long flags = 0;\r\nint ret = 0;\r\neeprom->magic = bnad->pcidev->vendor | (bnad->pcidev->device << 16);\r\nflash_part = bnad_get_flash_partition_by_offset(bnad,\r\neeprom->offset, &base_offset);\r\nif (flash_part == 0)\r\nreturn -EFAULT;\r\nfcomp.bnad = bnad;\r\nfcomp.comp_status = 0;\r\ninit_completion(&fcomp.comp);\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nret = bfa_nw_flash_read_part(&bnad->bna.flash, flash_part,\r\nbnad->id, bytes, eeprom->len,\r\neeprom->offset - base_offset,\r\nbnad_cb_completion, &fcomp);\r\nif (ret != BFA_STATUS_OK) {\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\ngoto done;\r\n}\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nwait_for_completion(&fcomp.comp);\r\nret = fcomp.comp_status;\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int\r\nbnad_set_eeprom(struct net_device *netdev, struct ethtool_eeprom *eeprom,\r\nu8 *bytes)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nstruct bnad_iocmd_comp fcomp;\r\nu32 flash_part = 0, base_offset = 0;\r\nunsigned long flags = 0;\r\nint ret = 0;\r\nif (eeprom->magic != (bnad->pcidev->vendor |\r\n(bnad->pcidev->device << 16)))\r\nreturn -EINVAL;\r\nflash_part = bnad_get_flash_partition_by_offset(bnad,\r\neeprom->offset, &base_offset);\r\nif (flash_part == 0)\r\nreturn -EFAULT;\r\nfcomp.bnad = bnad;\r\nfcomp.comp_status = 0;\r\ninit_completion(&fcomp.comp);\r\nspin_lock_irqsave(&bnad->bna_lock, flags);\r\nret = bfa_nw_flash_update_part(&bnad->bna.flash, flash_part,\r\nbnad->id, bytes, eeprom->len,\r\neeprom->offset - base_offset,\r\nbnad_cb_completion, &fcomp);\r\nif (ret != BFA_STATUS_OK) {\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\ngoto done;\r\n}\r\nspin_unlock_irqrestore(&bnad->bna_lock, flags);\r\nwait_for_completion(&fcomp.comp);\r\nret = fcomp.comp_status;\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int\r\nbnad_flash_device(struct net_device *netdev, struct ethtool_flash *eflash)\r\n{\r\nstruct bnad *bnad = netdev_priv(netdev);\r\nstruct bnad_iocmd_comp fcomp;\r\nconst struct firmware *fw;\r\nint ret = 0;\r\nret = request_firmware(&fw, eflash->data, &bnad->pcidev->dev);\r\nif (ret) {\r\nnetdev_err(netdev, "can't load firmware %s\n", eflash->data);\r\ngoto out;\r\n}\r\nfcomp.bnad = bnad;\r\nfcomp.comp_status = 0;\r\ninit_completion(&fcomp.comp);\r\nspin_lock_irq(&bnad->bna_lock);\r\nret = bfa_nw_flash_update_part(&bnad->bna.flash, BFA_FLASH_PART_FWIMG,\r\nbnad->id, (u8 *)fw->data, fw->size, 0,\r\nbnad_cb_completion, &fcomp);\r\nif (ret != BFA_STATUS_OK) {\r\nnetdev_warn(netdev, "flash update failed with err=%d\n", ret);\r\nret = -EIO;\r\nspin_unlock_irq(&bnad->bna_lock);\r\ngoto out;\r\n}\r\nspin_unlock_irq(&bnad->bna_lock);\r\nwait_for_completion(&fcomp.comp);\r\nif (fcomp.comp_status != BFA_STATUS_OK) {\r\nret = -EIO;\r\nnetdev_warn(netdev,\r\n"firmware image update failed with err=%d\n",\r\nfcomp.comp_status);\r\n}\r\nout:\r\nrelease_firmware(fw);\r\nreturn ret;\r\n}\r\nvoid\r\nbnad_set_ethtool_ops(struct net_device *netdev)\r\n{\r\nnetdev->ethtool_ops = &bnad_ethtool_ops;\r\n}
