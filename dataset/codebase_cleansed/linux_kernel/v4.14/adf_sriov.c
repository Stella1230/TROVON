static void adf_iov_send_resp(struct work_struct *work)\r\n{\r\nstruct adf_pf2vf_resp *pf2vf_resp =\r\ncontainer_of(work, struct adf_pf2vf_resp, pf2vf_resp_work);\r\nadf_vf2pf_req_hndl(pf2vf_resp->vf_info);\r\nkfree(pf2vf_resp);\r\n}\r\nstatic void adf_vf2pf_bh_handler(void *data)\r\n{\r\nstruct adf_accel_vf_info *vf_info = (struct adf_accel_vf_info *)data;\r\nstruct adf_pf2vf_resp *pf2vf_resp;\r\npf2vf_resp = kzalloc(sizeof(*pf2vf_resp), GFP_ATOMIC);\r\nif (!pf2vf_resp)\r\nreturn;\r\npf2vf_resp->vf_info = vf_info;\r\nINIT_WORK(&pf2vf_resp->pf2vf_resp_work, adf_iov_send_resp);\r\nqueue_work(pf2vf_resp_wq, &pf2vf_resp->pf2vf_resp_work);\r\n}\r\nstatic int adf_enable_sriov(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct pci_dev *pdev = accel_to_pci_dev(accel_dev);\r\nint totalvfs = pci_sriov_get_totalvfs(pdev);\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nstruct adf_bar *pmisc =\r\n&GET_BARS(accel_dev)[hw_data->get_misc_bar_id(hw_data)];\r\nvoid __iomem *pmisc_addr = pmisc->virt_addr;\r\nstruct adf_accel_vf_info *vf_info;\r\nint i;\r\nu32 reg;\r\nfor (i = 0, vf_info = accel_dev->pf.vf_info; i < totalvfs;\r\ni++, vf_info++) {\r\nvf_info->accel_dev = accel_dev;\r\nvf_info->vf_nr = i;\r\ntasklet_init(&vf_info->vf2pf_bh_tasklet,\r\n(void *)adf_vf2pf_bh_handler,\r\n(unsigned long)vf_info);\r\nmutex_init(&vf_info->pf2vf_lock);\r\nratelimit_state_init(&vf_info->vf2pf_ratelimit,\r\nDEFAULT_RATELIMIT_INTERVAL,\r\nDEFAULT_RATELIMIT_BURST);\r\n}\r\nfor (i = 0; i < ME2FUNCTION_MAP_A_NUM_REGS; i++) {\r\nreg = READ_CSR_ME2FUNCTION_MAP_A(pmisc_addr, i);\r\nreg |= ME2FUNCTION_MAP_VALID;\r\nWRITE_CSR_ME2FUNCTION_MAP_A(pmisc_addr, i, reg);\r\n}\r\nfor (i = 0; i < ME2FUNCTION_MAP_B_NUM_REGS; i++) {\r\nreg = READ_CSR_ME2FUNCTION_MAP_B(pmisc_addr, i);\r\nreg |= ME2FUNCTION_MAP_VALID;\r\nWRITE_CSR_ME2FUNCTION_MAP_B(pmisc_addr, i, reg);\r\n}\r\nadf_enable_vf2pf_interrupts(accel_dev, GENMASK_ULL(totalvfs - 1, 0));\r\nreturn pci_enable_sriov(pdev, totalvfs);\r\n}\r\nvoid adf_disable_sriov(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nstruct adf_bar *pmisc =\r\n&GET_BARS(accel_dev)[hw_data->get_misc_bar_id(hw_data)];\r\nvoid __iomem *pmisc_addr = pmisc->virt_addr;\r\nint totalvfs = pci_sriov_get_totalvfs(accel_to_pci_dev(accel_dev));\r\nstruct adf_accel_vf_info *vf;\r\nu32 reg;\r\nint i;\r\nif (!accel_dev->pf.vf_info)\r\nreturn;\r\nadf_pf2vf_notify_restarting(accel_dev);\r\npci_disable_sriov(accel_to_pci_dev(accel_dev));\r\nadf_disable_vf2pf_interrupts(accel_dev, 0xFFFFFFFF);\r\nfor (i = 0; i < ME2FUNCTION_MAP_A_NUM_REGS; i++) {\r\nreg = READ_CSR_ME2FUNCTION_MAP_A(pmisc_addr, i);\r\nreg &= ~ME2FUNCTION_MAP_VALID;\r\nWRITE_CSR_ME2FUNCTION_MAP_A(pmisc_addr, i, reg);\r\n}\r\nfor (i = 0; i < ME2FUNCTION_MAP_B_NUM_REGS; i++) {\r\nreg = READ_CSR_ME2FUNCTION_MAP_B(pmisc_addr, i);\r\nreg &= ~ME2FUNCTION_MAP_VALID;\r\nWRITE_CSR_ME2FUNCTION_MAP_B(pmisc_addr, i, reg);\r\n}\r\nfor (i = 0, vf = accel_dev->pf.vf_info; i < totalvfs; i++, vf++) {\r\ntasklet_disable(&vf->vf2pf_bh_tasklet);\r\ntasklet_kill(&vf->vf2pf_bh_tasklet);\r\nmutex_destroy(&vf->pf2vf_lock);\r\n}\r\nkfree(accel_dev->pf.vf_info);\r\naccel_dev->pf.vf_info = NULL;\r\n}\r\nint adf_sriov_configure(struct pci_dev *pdev, int numvfs)\r\n{\r\nstruct adf_accel_dev *accel_dev = adf_devmgr_pci_to_accel_dev(pdev);\r\nint totalvfs = pci_sriov_get_totalvfs(pdev);\r\nunsigned long val;\r\nint ret;\r\nif (!accel_dev) {\r\ndev_err(&pdev->dev, "Failed to find accel_dev\n");\r\nreturn -EFAULT;\r\n}\r\nif (!iommu_present(&pci_bus_type))\r\ndev_warn(&pdev->dev, "IOMMU should be enabled for SR-IOV to work correctly\n");\r\nif (accel_dev->pf.vf_info) {\r\ndev_info(&pdev->dev, "Already enabled for this device\n");\r\nreturn -EINVAL;\r\n}\r\nif (adf_dev_started(accel_dev)) {\r\nif (adf_devmgr_in_reset(accel_dev) ||\r\nadf_dev_in_use(accel_dev)) {\r\ndev_err(&GET_DEV(accel_dev), "Device busy\n");\r\nreturn -EBUSY;\r\n}\r\nadf_dev_stop(accel_dev);\r\nadf_dev_shutdown(accel_dev);\r\n}\r\nif (adf_cfg_section_add(accel_dev, ADF_KERNEL_SEC))\r\nreturn -EFAULT;\r\nval = 0;\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nADF_NUM_CY, (void *)&val, ADF_DEC))\r\nreturn -EFAULT;\r\nset_bit(ADF_STATUS_CONFIGURED, &accel_dev->status);\r\naccel_dev->pf.vf_info = kcalloc(totalvfs,\r\nsizeof(struct adf_accel_vf_info),\r\nGFP_KERNEL);\r\nif (!accel_dev->pf.vf_info)\r\nreturn -ENOMEM;\r\nif (adf_dev_init(accel_dev)) {\r\ndev_err(&GET_DEV(accel_dev), "Failed to init qat_dev%d\n",\r\naccel_dev->accel_id);\r\nreturn -EFAULT;\r\n}\r\nif (adf_dev_start(accel_dev)) {\r\ndev_err(&GET_DEV(accel_dev), "Failed to start qat_dev%d\n",\r\naccel_dev->accel_id);\r\nreturn -EFAULT;\r\n}\r\nret = adf_enable_sriov(accel_dev);\r\nif (ret)\r\nreturn ret;\r\nreturn numvfs;\r\n}\r\nint __init adf_init_pf_wq(void)\r\n{\r\npf2vf_resp_wq = alloc_workqueue("qat_pf2vf_resp_wq", WQ_MEM_RECLAIM, 0);\r\nreturn !pf2vf_resp_wq ? -ENOMEM : 0;\r\n}\r\nvoid adf_exit_pf_wq(void)\r\n{\r\nif (pf2vf_resp_wq) {\r\ndestroy_workqueue(pf2vf_resp_wq);\r\npf2vf_resp_wq = NULL;\r\n}\r\n}
