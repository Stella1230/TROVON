static inline\r\nstruct hugetlb_cgroup *hugetlb_cgroup_from_css(struct cgroup_subsys_state *s)\r\n{\r\nreturn s ? container_of(s, struct hugetlb_cgroup, css) : NULL;\r\n}\r\nstatic inline\r\nstruct hugetlb_cgroup *hugetlb_cgroup_from_task(struct task_struct *task)\r\n{\r\nreturn hugetlb_cgroup_from_css(task_css(task, hugetlb_cgrp_id));\r\n}\r\nstatic inline bool hugetlb_cgroup_is_root(struct hugetlb_cgroup *h_cg)\r\n{\r\nreturn (h_cg == root_h_cgroup);\r\n}\r\nstatic inline struct hugetlb_cgroup *\r\nparent_hugetlb_cgroup(struct hugetlb_cgroup *h_cg)\r\n{\r\nreturn hugetlb_cgroup_from_css(h_cg->css.parent);\r\n}\r\nstatic inline bool hugetlb_cgroup_have_usage(struct hugetlb_cgroup *h_cg)\r\n{\r\nint idx;\r\nfor (idx = 0; idx < hugetlb_max_hstate; idx++) {\r\nif (page_counter_read(&h_cg->hugepage[idx]))\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic void hugetlb_cgroup_init(struct hugetlb_cgroup *h_cgroup,\r\nstruct hugetlb_cgroup *parent_h_cgroup)\r\n{\r\nint idx;\r\nfor (idx = 0; idx < HUGE_MAX_HSTATE; idx++) {\r\nstruct page_counter *counter = &h_cgroup->hugepage[idx];\r\nstruct page_counter *parent = NULL;\r\nunsigned long limit;\r\nint ret;\r\nif (parent_h_cgroup)\r\nparent = &parent_h_cgroup->hugepage[idx];\r\npage_counter_init(counter, parent);\r\nlimit = round_down(PAGE_COUNTER_MAX,\r\n1 << huge_page_order(&hstates[idx]));\r\nret = page_counter_limit(counter, limit);\r\nVM_BUG_ON(ret);\r\n}\r\n}\r\nstatic struct cgroup_subsys_state *\r\nhugetlb_cgroup_css_alloc(struct cgroup_subsys_state *parent_css)\r\n{\r\nstruct hugetlb_cgroup *parent_h_cgroup = hugetlb_cgroup_from_css(parent_css);\r\nstruct hugetlb_cgroup *h_cgroup;\r\nh_cgroup = kzalloc(sizeof(*h_cgroup), GFP_KERNEL);\r\nif (!h_cgroup)\r\nreturn ERR_PTR(-ENOMEM);\r\nif (!parent_h_cgroup)\r\nroot_h_cgroup = h_cgroup;\r\nhugetlb_cgroup_init(h_cgroup, parent_h_cgroup);\r\nreturn &h_cgroup->css;\r\n}\r\nstatic void hugetlb_cgroup_css_free(struct cgroup_subsys_state *css)\r\n{\r\nstruct hugetlb_cgroup *h_cgroup;\r\nh_cgroup = hugetlb_cgroup_from_css(css);\r\nkfree(h_cgroup);\r\n}\r\nstatic void hugetlb_cgroup_move_parent(int idx, struct hugetlb_cgroup *h_cg,\r\nstruct page *page)\r\n{\r\nunsigned int nr_pages;\r\nstruct page_counter *counter;\r\nstruct hugetlb_cgroup *page_hcg;\r\nstruct hugetlb_cgroup *parent = parent_hugetlb_cgroup(h_cg);\r\npage_hcg = hugetlb_cgroup_from_page(page);\r\nif (!page_hcg || page_hcg != h_cg)\r\ngoto out;\r\nnr_pages = 1 << compound_order(page);\r\nif (!parent) {\r\nparent = root_h_cgroup;\r\npage_counter_charge(&parent->hugepage[idx], nr_pages);\r\n}\r\ncounter = &h_cg->hugepage[idx];\r\npage_counter_cancel(counter, nr_pages);\r\nset_hugetlb_cgroup(page, parent);\r\nout:\r\nreturn;\r\n}\r\nstatic void hugetlb_cgroup_css_offline(struct cgroup_subsys_state *css)\r\n{\r\nstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(css);\r\nstruct hstate *h;\r\nstruct page *page;\r\nint idx = 0;\r\ndo {\r\nfor_each_hstate(h) {\r\nspin_lock(&hugetlb_lock);\r\nlist_for_each_entry(page, &h->hugepage_activelist, lru)\r\nhugetlb_cgroup_move_parent(idx, h_cg, page);\r\nspin_unlock(&hugetlb_lock);\r\nidx++;\r\n}\r\ncond_resched();\r\n} while (hugetlb_cgroup_have_usage(h_cg));\r\n}\r\nint hugetlb_cgroup_charge_cgroup(int idx, unsigned long nr_pages,\r\nstruct hugetlb_cgroup **ptr)\r\n{\r\nint ret = 0;\r\nstruct page_counter *counter;\r\nstruct hugetlb_cgroup *h_cg = NULL;\r\nif (hugetlb_cgroup_disabled())\r\ngoto done;\r\nif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)\r\ngoto done;\r\nagain:\r\nrcu_read_lock();\r\nh_cg = hugetlb_cgroup_from_task(current);\r\nif (!css_tryget_online(&h_cg->css)) {\r\nrcu_read_unlock();\r\ngoto again;\r\n}\r\nrcu_read_unlock();\r\nif (!page_counter_try_charge(&h_cg->hugepage[idx], nr_pages, &counter))\r\nret = -ENOMEM;\r\ncss_put(&h_cg->css);\r\ndone:\r\n*ptr = h_cg;\r\nreturn ret;\r\n}\r\nvoid hugetlb_cgroup_commit_charge(int idx, unsigned long nr_pages,\r\nstruct hugetlb_cgroup *h_cg,\r\nstruct page *page)\r\n{\r\nif (hugetlb_cgroup_disabled() || !h_cg)\r\nreturn;\r\nset_hugetlb_cgroup(page, h_cg);\r\nreturn;\r\n}\r\nvoid hugetlb_cgroup_uncharge_page(int idx, unsigned long nr_pages,\r\nstruct page *page)\r\n{\r\nstruct hugetlb_cgroup *h_cg;\r\nif (hugetlb_cgroup_disabled())\r\nreturn;\r\nlockdep_assert_held(&hugetlb_lock);\r\nh_cg = hugetlb_cgroup_from_page(page);\r\nif (unlikely(!h_cg))\r\nreturn;\r\nset_hugetlb_cgroup(page, NULL);\r\npage_counter_uncharge(&h_cg->hugepage[idx], nr_pages);\r\nreturn;\r\n}\r\nvoid hugetlb_cgroup_uncharge_cgroup(int idx, unsigned long nr_pages,\r\nstruct hugetlb_cgroup *h_cg)\r\n{\r\nif (hugetlb_cgroup_disabled() || !h_cg)\r\nreturn;\r\nif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)\r\nreturn;\r\npage_counter_uncharge(&h_cg->hugepage[idx], nr_pages);\r\nreturn;\r\n}\r\nstatic u64 hugetlb_cgroup_read_u64(struct cgroup_subsys_state *css,\r\nstruct cftype *cft)\r\n{\r\nstruct page_counter *counter;\r\nstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(css);\r\ncounter = &h_cg->hugepage[MEMFILE_IDX(cft->private)];\r\nswitch (MEMFILE_ATTR(cft->private)) {\r\ncase RES_USAGE:\r\nreturn (u64)page_counter_read(counter) * PAGE_SIZE;\r\ncase RES_LIMIT:\r\nreturn (u64)counter->limit * PAGE_SIZE;\r\ncase RES_MAX_USAGE:\r\nreturn (u64)counter->watermark * PAGE_SIZE;\r\ncase RES_FAILCNT:\r\nreturn counter->failcnt;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic ssize_t hugetlb_cgroup_write(struct kernfs_open_file *of,\r\nchar *buf, size_t nbytes, loff_t off)\r\n{\r\nint ret, idx;\r\nunsigned long nr_pages;\r\nstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(of_css(of));\r\nif (hugetlb_cgroup_is_root(h_cg))\r\nreturn -EINVAL;\r\nbuf = strstrip(buf);\r\nret = page_counter_memparse(buf, "-1", &nr_pages);\r\nif (ret)\r\nreturn ret;\r\nidx = MEMFILE_IDX(of_cft(of)->private);\r\nnr_pages = round_down(nr_pages, 1 << huge_page_order(&hstates[idx]));\r\nswitch (MEMFILE_ATTR(of_cft(of)->private)) {\r\ncase RES_LIMIT:\r\nmutex_lock(&hugetlb_limit_mutex);\r\nret = page_counter_limit(&h_cg->hugepage[idx], nr_pages);\r\nmutex_unlock(&hugetlb_limit_mutex);\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\nbreak;\r\n}\r\nreturn ret ?: nbytes;\r\n}\r\nstatic ssize_t hugetlb_cgroup_reset(struct kernfs_open_file *of,\r\nchar *buf, size_t nbytes, loff_t off)\r\n{\r\nint ret = 0;\r\nstruct page_counter *counter;\r\nstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(of_css(of));\r\ncounter = &h_cg->hugepage[MEMFILE_IDX(of_cft(of)->private)];\r\nswitch (MEMFILE_ATTR(of_cft(of)->private)) {\r\ncase RES_MAX_USAGE:\r\npage_counter_reset_watermark(counter);\r\nbreak;\r\ncase RES_FAILCNT:\r\ncounter->failcnt = 0;\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\nbreak;\r\n}\r\nreturn ret ?: nbytes;\r\n}\r\nstatic char *mem_fmt(char *buf, int size, unsigned long hsize)\r\n{\r\nif (hsize >= (1UL << 30))\r\nsnprintf(buf, size, "%luGB", hsize >> 30);\r\nelse if (hsize >= (1UL << 20))\r\nsnprintf(buf, size, "%luMB", hsize >> 20);\r\nelse\r\nsnprintf(buf, size, "%luKB", hsize >> 10);\r\nreturn buf;\r\n}\r\nstatic void __init __hugetlb_cgroup_file_init(int idx)\r\n{\r\nchar buf[32];\r\nstruct cftype *cft;\r\nstruct hstate *h = &hstates[idx];\r\nmem_fmt(buf, 32, huge_page_size(h));\r\ncft = &h->cgroup_files[0];\r\nsnprintf(cft->name, MAX_CFTYPE_NAME, "%s.limit_in_bytes", buf);\r\ncft->private = MEMFILE_PRIVATE(idx, RES_LIMIT);\r\ncft->read_u64 = hugetlb_cgroup_read_u64;\r\ncft->write = hugetlb_cgroup_write;\r\ncft = &h->cgroup_files[1];\r\nsnprintf(cft->name, MAX_CFTYPE_NAME, "%s.usage_in_bytes", buf);\r\ncft->private = MEMFILE_PRIVATE(idx, RES_USAGE);\r\ncft->read_u64 = hugetlb_cgroup_read_u64;\r\ncft = &h->cgroup_files[2];\r\nsnprintf(cft->name, MAX_CFTYPE_NAME, "%s.max_usage_in_bytes", buf);\r\ncft->private = MEMFILE_PRIVATE(idx, RES_MAX_USAGE);\r\ncft->write = hugetlb_cgroup_reset;\r\ncft->read_u64 = hugetlb_cgroup_read_u64;\r\ncft = &h->cgroup_files[3];\r\nsnprintf(cft->name, MAX_CFTYPE_NAME, "%s.failcnt", buf);\r\ncft->private = MEMFILE_PRIVATE(idx, RES_FAILCNT);\r\ncft->write = hugetlb_cgroup_reset;\r\ncft->read_u64 = hugetlb_cgroup_read_u64;\r\ncft = &h->cgroup_files[4];\r\nmemset(cft, 0, sizeof(*cft));\r\nWARN_ON(cgroup_add_legacy_cftypes(&hugetlb_cgrp_subsys,\r\nh->cgroup_files));\r\n}\r\nvoid __init hugetlb_cgroup_file_init(void)\r\n{\r\nstruct hstate *h;\r\nfor_each_hstate(h) {\r\nif (huge_page_order(h) >= HUGETLB_CGROUP_MIN_ORDER)\r\n__hugetlb_cgroup_file_init(hstate_index(h));\r\n}\r\n}\r\nvoid hugetlb_cgroup_migrate(struct page *oldhpage, struct page *newhpage)\r\n{\r\nstruct hugetlb_cgroup *h_cg;\r\nstruct hstate *h = page_hstate(oldhpage);\r\nif (hugetlb_cgroup_disabled())\r\nreturn;\r\nVM_BUG_ON_PAGE(!PageHuge(oldhpage), oldhpage);\r\nspin_lock(&hugetlb_lock);\r\nh_cg = hugetlb_cgroup_from_page(oldhpage);\r\nset_hugetlb_cgroup(oldhpage, NULL);\r\nset_hugetlb_cgroup(newhpage, h_cg);\r\nlist_move(&newhpage->lru, &h->hugepage_activelist);\r\nspin_unlock(&hugetlb_lock);\r\nreturn;\r\n}
