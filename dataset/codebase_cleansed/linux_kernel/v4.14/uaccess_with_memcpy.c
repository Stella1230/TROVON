static int\r\npin_page_for_write(const void __user *_addr, pte_t **ptep, spinlock_t **ptlp)\r\n{\r\nunsigned long addr = (unsigned long)_addr;\r\npgd_t *pgd;\r\npmd_t *pmd;\r\npte_t *pte;\r\npud_t *pud;\r\nspinlock_t *ptl;\r\npgd = pgd_offset(current->mm, addr);\r\nif (unlikely(pgd_none(*pgd) || pgd_bad(*pgd)))\r\nreturn 0;\r\npud = pud_offset(pgd, addr);\r\nif (unlikely(pud_none(*pud) || pud_bad(*pud)))\r\nreturn 0;\r\npmd = pmd_offset(pud, addr);\r\nif (unlikely(pmd_none(*pmd)))\r\nreturn 0;\r\nif (unlikely(pmd_thp_or_huge(*pmd))) {\r\nptl = &current->mm->page_table_lock;\r\nspin_lock(ptl);\r\nif (unlikely(!pmd_thp_or_huge(*pmd)\r\n|| pmd_hugewillfault(*pmd))) {\r\nspin_unlock(ptl);\r\nreturn 0;\r\n}\r\n*ptep = NULL;\r\n*ptlp = ptl;\r\nreturn 1;\r\n}\r\nif (unlikely(pmd_bad(*pmd)))\r\nreturn 0;\r\npte = pte_offset_map_lock(current->mm, pmd, addr, &ptl);\r\nif (unlikely(!pte_present(*pte) || !pte_young(*pte) ||\r\n!pte_write(*pte) || !pte_dirty(*pte))) {\r\npte_unmap_unlock(pte, ptl);\r\nreturn 0;\r\n}\r\n*ptep = pte;\r\n*ptlp = ptl;\r\nreturn 1;\r\n}\r\nstatic unsigned long noinline\r\n__copy_to_user_memcpy(void __user *to, const void *from, unsigned long n)\r\n{\r\nunsigned long ua_flags;\r\nint atomic;\r\nif (uaccess_kernel()) {\r\nmemcpy((void *)to, from, n);\r\nreturn 0;\r\n}\r\natomic = faulthandler_disabled();\r\nif (!atomic)\r\ndown_read(&current->mm->mmap_sem);\r\nwhile (n) {\r\npte_t *pte;\r\nspinlock_t *ptl;\r\nint tocopy;\r\nwhile (!pin_page_for_write(to, &pte, &ptl)) {\r\nif (!atomic)\r\nup_read(&current->mm->mmap_sem);\r\nif (__put_user(0, (char __user *)to))\r\ngoto out;\r\nif (!atomic)\r\ndown_read(&current->mm->mmap_sem);\r\n}\r\ntocopy = (~(unsigned long)to & ~PAGE_MASK) + 1;\r\nif (tocopy > n)\r\ntocopy = n;\r\nua_flags = uaccess_save_and_enable();\r\nmemcpy((void *)to, from, tocopy);\r\nuaccess_restore(ua_flags);\r\nto += tocopy;\r\nfrom += tocopy;\r\nn -= tocopy;\r\nif (pte)\r\npte_unmap_unlock(pte, ptl);\r\nelse\r\nspin_unlock(ptl);\r\n}\r\nif (!atomic)\r\nup_read(&current->mm->mmap_sem);\r\nout:\r\nreturn n;\r\n}\r\nunsigned long\r\narm_copy_to_user(void __user *to, const void *from, unsigned long n)\r\n{\r\nif (n < 64) {\r\nunsigned long ua_flags = uaccess_save_and_enable();\r\nn = __copy_to_user_std(to, from, n);\r\nuaccess_restore(ua_flags);\r\n} else {\r\nn = __copy_to_user_memcpy(to, from, n);\r\n}\r\nreturn n;\r\n}\r\nstatic unsigned long noinline\r\n__clear_user_memset(void __user *addr, unsigned long n)\r\n{\r\nunsigned long ua_flags;\r\nif (uaccess_kernel()) {\r\nmemset((void *)addr, 0, n);\r\nreturn 0;\r\n}\r\ndown_read(&current->mm->mmap_sem);\r\nwhile (n) {\r\npte_t *pte;\r\nspinlock_t *ptl;\r\nint tocopy;\r\nwhile (!pin_page_for_write(addr, &pte, &ptl)) {\r\nup_read(&current->mm->mmap_sem);\r\nif (__put_user(0, (char __user *)addr))\r\ngoto out;\r\ndown_read(&current->mm->mmap_sem);\r\n}\r\ntocopy = (~(unsigned long)addr & ~PAGE_MASK) + 1;\r\nif (tocopy > n)\r\ntocopy = n;\r\nua_flags = uaccess_save_and_enable();\r\nmemset((void *)addr, 0, tocopy);\r\nuaccess_restore(ua_flags);\r\naddr += tocopy;\r\nn -= tocopy;\r\nif (pte)\r\npte_unmap_unlock(pte, ptl);\r\nelse\r\nspin_unlock(ptl);\r\n}\r\nup_read(&current->mm->mmap_sem);\r\nout:\r\nreturn n;\r\n}\r\nunsigned long arm_clear_user(void __user *addr, unsigned long n)\r\n{\r\nif (n < 64) {\r\nunsigned long ua_flags = uaccess_save_and_enable();\r\nn = __clear_user_std(addr, n);\r\nuaccess_restore(ua_flags);\r\n} else {\r\nn = __clear_user_memset(addr, n);\r\n}\r\nreturn n;\r\n}
