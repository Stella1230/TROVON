bool radeon_ring_supports_scratch_reg(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nswitch (ring->idx) {\r\ncase RADEON_RING_TYPE_GFX_INDEX:\r\ncase CAYMAN_RING_TYPE_CP1_INDEX:\r\ncase CAYMAN_RING_TYPE_CP2_INDEX:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nvoid radeon_ring_free_size(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nuint32_t rptr = radeon_ring_get_rptr(rdev, ring);\r\nring->ring_free_dw = rptr + (ring->ring_size / 4);\r\nring->ring_free_dw -= ring->wptr;\r\nring->ring_free_dw &= ring->ptr_mask;\r\nif (!ring->ring_free_dw) {\r\nring->ring_free_dw = ring->ring_size / 4;\r\nradeon_ring_lockup_update(rdev, ring);\r\n}\r\n}\r\nint radeon_ring_alloc(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ndw)\r\n{\r\nint r;\r\nif (ndw > (ring->ring_size / 4))\r\nreturn -ENOMEM;\r\nradeon_ring_free_size(rdev, ring);\r\nndw = (ndw + ring->align_mask) & ~ring->align_mask;\r\nwhile (ndw > (ring->ring_free_dw - 1)) {\r\nradeon_ring_free_size(rdev, ring);\r\nif (ndw < ring->ring_free_dw) {\r\nbreak;\r\n}\r\nr = radeon_fence_wait_next(rdev, ring->idx);\r\nif (r)\r\nreturn r;\r\n}\r\nring->count_dw = ndw;\r\nring->wptr_old = ring->wptr;\r\nreturn 0;\r\n}\r\nint radeon_ring_lock(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ndw)\r\n{\r\nint r;\r\nmutex_lock(&rdev->ring_lock);\r\nr = radeon_ring_alloc(rdev, ring, ndw);\r\nif (r) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nvoid radeon_ring_commit(struct radeon_device *rdev, struct radeon_ring *ring,\r\nbool hdp_flush)\r\n{\r\nif (hdp_flush && rdev->asic->ring[ring->idx]->hdp_flush)\r\nrdev->asic->ring[ring->idx]->hdp_flush(rdev, ring);\r\nwhile (ring->wptr & ring->align_mask) {\r\nradeon_ring_write(ring, ring->nop);\r\n}\r\nmb();\r\nif (hdp_flush && rdev->asic->mmio_hdp_flush)\r\nrdev->asic->mmio_hdp_flush(rdev);\r\nradeon_ring_set_wptr(rdev, ring);\r\n}\r\nvoid radeon_ring_unlock_commit(struct radeon_device *rdev, struct radeon_ring *ring,\r\nbool hdp_flush)\r\n{\r\nradeon_ring_commit(rdev, ring, hdp_flush);\r\nmutex_unlock(&rdev->ring_lock);\r\n}\r\nvoid radeon_ring_undo(struct radeon_ring *ring)\r\n{\r\nring->wptr = ring->wptr_old;\r\n}\r\nvoid radeon_ring_unlock_undo(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nradeon_ring_undo(ring);\r\nmutex_unlock(&rdev->ring_lock);\r\n}\r\nvoid radeon_ring_lockup_update(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\natomic_set(&ring->last_rptr, radeon_ring_get_rptr(rdev, ring));\r\natomic64_set(&ring->last_activity, jiffies_64);\r\n}\r\nbool radeon_ring_test_lockup(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nuint32_t rptr = radeon_ring_get_rptr(rdev, ring);\r\nuint64_t last = atomic64_read(&ring->last_activity);\r\nuint64_t elapsed;\r\nif (rptr != atomic_read(&ring->last_rptr)) {\r\nradeon_ring_lockup_update(rdev, ring);\r\nreturn false;\r\n}\r\nelapsed = jiffies_to_msecs(jiffies_64 - last);\r\nif (radeon_lockup_timeout && elapsed >= radeon_lockup_timeout) {\r\ndev_err(rdev->dev, "ring %d stalled for more than %llumsec\n",\r\nring->idx, elapsed);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nunsigned radeon_ring_backup(struct radeon_device *rdev, struct radeon_ring *ring,\r\nuint32_t **data)\r\n{\r\nunsigned size, ptr, i;\r\nmutex_lock(&rdev->ring_lock);\r\n*data = NULL;\r\nif (ring->ring_obj == NULL) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nif (!radeon_fence_count_emitted(rdev, ring->idx)) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nif (ring->rptr_save_reg)\r\nptr = RREG32(ring->rptr_save_reg);\r\nelse if (rdev->wb.enabled)\r\nptr = le32_to_cpu(*ring->next_rptr_cpu_addr);\r\nelse {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nsize = ring->wptr + (ring->ring_size / 4);\r\nsize -= ptr;\r\nsize &= ring->ptr_mask;\r\nif (size == 0) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\n*data = kvmalloc_array(size, sizeof(uint32_t), GFP_KERNEL);\r\nif (!*data) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nfor (i = 0; i < size; ++i) {\r\n(*data)[i] = ring->ring[ptr++];\r\nptr &= ring->ptr_mask;\r\n}\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn size;\r\n}\r\nint radeon_ring_restore(struct radeon_device *rdev, struct radeon_ring *ring,\r\nunsigned size, uint32_t *data)\r\n{\r\nint i, r;\r\nif (!size || !data)\r\nreturn 0;\r\nr = radeon_ring_lock(rdev, ring, size);\r\nif (r)\r\nreturn r;\r\nfor (i = 0; i < size; ++i) {\r\nradeon_ring_write(ring, data[i]);\r\n}\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\nkvfree(data);\r\nreturn 0;\r\n}\r\nint radeon_ring_init(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ring_size,\r\nunsigned rptr_offs, u32 nop)\r\n{\r\nint r;\r\nring->ring_size = ring_size;\r\nring->rptr_offs = rptr_offs;\r\nring->nop = nop;\r\nif (ring->ring_obj == NULL) {\r\nr = radeon_bo_create(rdev, ring->ring_size, PAGE_SIZE, true,\r\nRADEON_GEM_DOMAIN_GTT, 0, NULL,\r\nNULL, &ring->ring_obj);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) ring create failed\n", r);\r\nreturn r;\r\n}\r\nr = radeon_bo_reserve(ring->ring_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_pin(ring->ring_obj, RADEON_GEM_DOMAIN_GTT,\r\n&ring->gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(ring->ring_obj);\r\ndev_err(rdev->dev, "(%d) ring pin failed\n", r);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(ring->ring_obj,\r\n(void **)&ring->ring);\r\nradeon_bo_unreserve(ring->ring_obj);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) ring map failed\n", r);\r\nreturn r;\r\n}\r\n}\r\nring->ptr_mask = (ring->ring_size / 4) - 1;\r\nring->ring_free_dw = ring->ring_size / 4;\r\nif (rdev->wb.enabled) {\r\nu32 index = RADEON_WB_RING0_NEXT_RPTR + (ring->idx * 4);\r\nring->next_rptr_gpu_addr = rdev->wb.gpu_addr + index;\r\nring->next_rptr_cpu_addr = &rdev->wb.wb[index/4];\r\n}\r\nif (radeon_debugfs_ring_init(rdev, ring)) {\r\nDRM_ERROR("Failed to register debugfs file for rings !\n");\r\n}\r\nradeon_ring_lockup_update(rdev, ring);\r\nreturn 0;\r\n}\r\nvoid radeon_ring_fini(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nint r;\r\nstruct radeon_bo *ring_obj;\r\nmutex_lock(&rdev->ring_lock);\r\nring_obj = ring->ring_obj;\r\nring->ready = false;\r\nring->ring = NULL;\r\nring->ring_obj = NULL;\r\nmutex_unlock(&rdev->ring_lock);\r\nif (ring_obj) {\r\nr = radeon_bo_reserve(ring_obj, false);\r\nif (likely(r == 0)) {\r\nradeon_bo_kunmap(ring_obj);\r\nradeon_bo_unpin(ring_obj);\r\nradeon_bo_unreserve(ring_obj);\r\n}\r\nradeon_bo_unref(&ring_obj);\r\n}\r\n}\r\nstatic int radeon_debugfs_ring_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nint ridx = *(int*)node->info_ent->data;\r\nstruct radeon_ring *ring = &rdev->ring[ridx];\r\nuint32_t rptr, wptr, rptr_next;\r\nunsigned count, i, j;\r\nradeon_ring_free_size(rdev, ring);\r\ncount = (ring->ring_size / 4) - ring->ring_free_dw;\r\nwptr = radeon_ring_get_wptr(rdev, ring);\r\nseq_printf(m, "wptr: 0x%08x [%5d]\n",\r\nwptr, wptr);\r\nrptr = radeon_ring_get_rptr(rdev, ring);\r\nseq_printf(m, "rptr: 0x%08x [%5d]\n",\r\nrptr, rptr);\r\nif (ring->rptr_save_reg) {\r\nrptr_next = RREG32(ring->rptr_save_reg);\r\nseq_printf(m, "rptr next(0x%04x): 0x%08x [%5d]\n",\r\nring->rptr_save_reg, rptr_next, rptr_next);\r\n} else\r\nrptr_next = ~0;\r\nseq_printf(m, "driver's copy of the wptr: 0x%08x [%5d]\n",\r\nring->wptr, ring->wptr);\r\nseq_printf(m, "last semaphore signal addr : 0x%016llx\n",\r\nring->last_semaphore_signal_addr);\r\nseq_printf(m, "last semaphore wait addr : 0x%016llx\n",\r\nring->last_semaphore_wait_addr);\r\nseq_printf(m, "%u free dwords in ring\n", ring->ring_free_dw);\r\nseq_printf(m, "%u dwords in ring\n", count);\r\nif (!ring->ring)\r\nreturn 0;\r\ni = (rptr + ring->ptr_mask + 1 - 32) & ring->ptr_mask;\r\nfor (j = 0; j <= (count + 32); j++) {\r\nseq_printf(m, "r[%5d]=0x%08x", i, ring->ring[i]);\r\nif (rptr == i)\r\nseq_puts(m, " *");\r\nif (rptr_next == i)\r\nseq_puts(m, " #");\r\nseq_puts(m, "\n");\r\ni = (i + 1) & ring->ptr_mask;\r\n}\r\nreturn 0;\r\n}\r\nstatic int radeon_debugfs_ring_init(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nunsigned i;\r\nfor (i = 0; i < ARRAY_SIZE(radeon_debugfs_ring_info_list); ++i) {\r\nstruct drm_info_list *info = &radeon_debugfs_ring_info_list[i];\r\nint ridx = *(int*)radeon_debugfs_ring_info_list[i].data;\r\nunsigned r;\r\nif (&rdev->ring[ridx] != ring)\r\ncontinue;\r\nr = radeon_debugfs_add_files(rdev, info, 1);\r\nif (r)\r\nreturn r;\r\n}\r\n#endif\r\nreturn 0;\r\n}
