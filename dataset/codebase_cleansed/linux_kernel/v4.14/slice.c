static void slice_print_mask(const char *label, struct slice_mask mask)\r\n{\r\nif (!_slice_debug)\r\nreturn;\r\npr_devel("%s low_slice: %*pbl\n", label, (int)SLICE_NUM_LOW, &mask.low_slices);\r\npr_devel("%s high_slice: %*pbl\n", label, (int)SLICE_NUM_HIGH, mask.high_slices);\r\n}\r\nstatic void slice_print_mask(const char *label, struct slice_mask mask) {}\r\nstatic void slice_range_to_mask(unsigned long start, unsigned long len,\r\nstruct slice_mask *ret)\r\n{\r\nunsigned long end = start + len - 1;\r\nret->low_slices = 0;\r\nbitmap_zero(ret->high_slices, SLICE_NUM_HIGH);\r\nif (start < SLICE_LOW_TOP) {\r\nunsigned long mend = min(end, (SLICE_LOW_TOP - 1));\r\nret->low_slices = (1u << (GET_LOW_SLICE_INDEX(mend) + 1))\r\n- (1u << GET_LOW_SLICE_INDEX(start));\r\n}\r\nif ((start + len) > SLICE_LOW_TOP) {\r\nunsigned long start_index = GET_HIGH_SLICE_INDEX(start);\r\nunsigned long align_end = ALIGN(end, (1UL << SLICE_HIGH_SHIFT));\r\nunsigned long count = GET_HIGH_SLICE_INDEX(align_end) - start_index;\r\nbitmap_set(ret->high_slices, start_index, count);\r\n}\r\n}\r\nstatic int slice_area_is_free(struct mm_struct *mm, unsigned long addr,\r\nunsigned long len)\r\n{\r\nstruct vm_area_struct *vma;\r\nif ((mm->task_size - len) < addr)\r\nreturn 0;\r\nvma = find_vma(mm, addr);\r\nreturn (!vma || (addr + len) <= vm_start_gap(vma));\r\n}\r\nstatic int slice_low_has_vma(struct mm_struct *mm, unsigned long slice)\r\n{\r\nreturn !slice_area_is_free(mm, slice << SLICE_LOW_SHIFT,\r\n1ul << SLICE_LOW_SHIFT);\r\n}\r\nstatic int slice_high_has_vma(struct mm_struct *mm, unsigned long slice)\r\n{\r\nunsigned long start = slice << SLICE_HIGH_SHIFT;\r\nunsigned long end = start + (1ul << SLICE_HIGH_SHIFT);\r\nif (start == 0)\r\nstart = SLICE_LOW_TOP;\r\nreturn !slice_area_is_free(mm, start, end - start);\r\n}\r\nstatic void slice_mask_for_free(struct mm_struct *mm, struct slice_mask *ret)\r\n{\r\nunsigned long i;\r\nret->low_slices = 0;\r\nbitmap_zero(ret->high_slices, SLICE_NUM_HIGH);\r\nfor (i = 0; i < SLICE_NUM_LOW; i++)\r\nif (!slice_low_has_vma(mm, i))\r\nret->low_slices |= 1u << i;\r\nif (mm->task_size <= SLICE_LOW_TOP)\r\nreturn;\r\nfor (i = 0; i < GET_HIGH_SLICE_INDEX(mm->context.addr_limit); i++)\r\nif (!slice_high_has_vma(mm, i))\r\n__set_bit(i, ret->high_slices);\r\n}\r\nstatic void slice_mask_for_size(struct mm_struct *mm, int psize, struct slice_mask *ret)\r\n{\r\nunsigned char *hpsizes;\r\nint index, mask_index;\r\nunsigned long i;\r\nu64 lpsizes;\r\nret->low_slices = 0;\r\nbitmap_zero(ret->high_slices, SLICE_NUM_HIGH);\r\nlpsizes = mm->context.low_slices_psize;\r\nfor (i = 0; i < SLICE_NUM_LOW; i++)\r\nif (((lpsizes >> (i * 4)) & 0xf) == psize)\r\nret->low_slices |= 1u << i;\r\nhpsizes = mm->context.high_slices_psize;\r\nfor (i = 0; i < GET_HIGH_SLICE_INDEX(mm->context.addr_limit); i++) {\r\nmask_index = i & 0x1;\r\nindex = i >> 1;\r\nif (((hpsizes[index] >> (mask_index * 4)) & 0xf) == psize)\r\n__set_bit(i, ret->high_slices);\r\n}\r\n}\r\nstatic int slice_check_fit(struct mm_struct *mm,\r\nstruct slice_mask mask, struct slice_mask available)\r\n{\r\nDECLARE_BITMAP(result, SLICE_NUM_HIGH);\r\nunsigned long slice_count = GET_HIGH_SLICE_INDEX(mm->context.addr_limit);\r\nbitmap_and(result, mask.high_slices,\r\navailable.high_slices, slice_count);\r\nreturn (mask.low_slices & available.low_slices) == mask.low_slices &&\r\nbitmap_equal(result, mask.high_slices, slice_count);\r\n}\r\nstatic void slice_flush_segments(void *parm)\r\n{\r\nstruct mm_struct *mm = parm;\r\nunsigned long flags;\r\nif (mm != current->active_mm)\r\nreturn;\r\ncopy_mm_to_paca(current->active_mm);\r\nlocal_irq_save(flags);\r\nslb_flush_and_rebolt();\r\nlocal_irq_restore(flags);\r\n}\r\nstatic void slice_convert(struct mm_struct *mm, struct slice_mask mask, int psize)\r\n{\r\nint index, mask_index;\r\nunsigned char *hpsizes;\r\nu64 lpsizes;\r\nunsigned long i, flags;\r\nslice_dbg("slice_convert(mm=%p, psize=%d)\n", mm, psize);\r\nslice_print_mask(" mask", mask);\r\nspin_lock_irqsave(&slice_convert_lock, flags);\r\nlpsizes = mm->context.low_slices_psize;\r\nfor (i = 0; i < SLICE_NUM_LOW; i++)\r\nif (mask.low_slices & (1u << i))\r\nlpsizes = (lpsizes & ~(0xful << (i * 4))) |\r\n(((unsigned long)psize) << (i * 4));\r\nmm->context.low_slices_psize = lpsizes;\r\nhpsizes = mm->context.high_slices_psize;\r\nfor (i = 0; i < GET_HIGH_SLICE_INDEX(mm->context.addr_limit); i++) {\r\nmask_index = i & 0x1;\r\nindex = i >> 1;\r\nif (test_bit(i, mask.high_slices))\r\nhpsizes[index] = (hpsizes[index] &\r\n~(0xf << (mask_index * 4))) |\r\n(((unsigned long)psize) << (mask_index * 4));\r\n}\r\nslice_dbg(" lsps=%lx, hsps=%lx\n",\r\n(unsigned long)mm->context.low_slices_psize,\r\n(unsigned long)mm->context.high_slices_psize);\r\nspin_unlock_irqrestore(&slice_convert_lock, flags);\r\ncopro_flush_all_slbs(mm);\r\n}\r\nstatic bool slice_scan_available(unsigned long addr,\r\nstruct slice_mask available,\r\nint end,\r\nunsigned long *boundary_addr)\r\n{\r\nunsigned long slice;\r\nif (addr < SLICE_LOW_TOP) {\r\nslice = GET_LOW_SLICE_INDEX(addr);\r\n*boundary_addr = (slice + end) << SLICE_LOW_SHIFT;\r\nreturn !!(available.low_slices & (1u << slice));\r\n} else {\r\nslice = GET_HIGH_SLICE_INDEX(addr);\r\n*boundary_addr = (slice + end) ?\r\n((slice + end) << SLICE_HIGH_SHIFT) : SLICE_LOW_TOP;\r\nreturn !!test_bit(slice, available.high_slices);\r\n}\r\n}\r\nstatic unsigned long slice_find_area_bottomup(struct mm_struct *mm,\r\nunsigned long len,\r\nstruct slice_mask available,\r\nint psize, unsigned long high_limit)\r\n{\r\nint pshift = max_t(int, mmu_psize_defs[psize].shift, PAGE_SHIFT);\r\nunsigned long addr, found, next_end;\r\nstruct vm_unmapped_area_info info;\r\ninfo.flags = 0;\r\ninfo.length = len;\r\ninfo.align_mask = PAGE_MASK & ((1ul << pshift) - 1);\r\ninfo.align_offset = 0;\r\naddr = TASK_UNMAPPED_BASE;\r\nwhile (addr < high_limit) {\r\ninfo.low_limit = addr;\r\nif (!slice_scan_available(addr, available, 1, &addr))\r\ncontinue;\r\nnext_slice:\r\nif (addr >= high_limit)\r\naddr = high_limit;\r\nelse if (slice_scan_available(addr, available, 1, &next_end)) {\r\naddr = next_end;\r\ngoto next_slice;\r\n}\r\ninfo.high_limit = addr;\r\nfound = vm_unmapped_area(&info);\r\nif (!(found & ~PAGE_MASK))\r\nreturn found;\r\n}\r\nreturn -ENOMEM;\r\n}\r\nstatic unsigned long slice_find_area_topdown(struct mm_struct *mm,\r\nunsigned long len,\r\nstruct slice_mask available,\r\nint psize, unsigned long high_limit)\r\n{\r\nint pshift = max_t(int, mmu_psize_defs[psize].shift, PAGE_SHIFT);\r\nunsigned long addr, found, prev;\r\nstruct vm_unmapped_area_info info;\r\ninfo.flags = VM_UNMAPPED_AREA_TOPDOWN;\r\ninfo.length = len;\r\ninfo.align_mask = PAGE_MASK & ((1ul << pshift) - 1);\r\ninfo.align_offset = 0;\r\naddr = mm->mmap_base;\r\nif (high_limit > DEFAULT_MAP_WINDOW)\r\naddr += mm->context.addr_limit - DEFAULT_MAP_WINDOW;\r\nwhile (addr > PAGE_SIZE) {\r\ninfo.high_limit = addr;\r\nif (!slice_scan_available(addr - 1, available, 0, &addr))\r\ncontinue;\r\nprev_slice:\r\nif (addr < PAGE_SIZE)\r\naddr = PAGE_SIZE;\r\nelse if (slice_scan_available(addr - 1, available, 0, &prev)) {\r\naddr = prev;\r\ngoto prev_slice;\r\n}\r\ninfo.low_limit = addr;\r\nfound = vm_unmapped_area(&info);\r\nif (!(found & ~PAGE_MASK))\r\nreturn found;\r\n}\r\nreturn slice_find_area_bottomup(mm, len, available, psize, high_limit);\r\n}\r\nstatic unsigned long slice_find_area(struct mm_struct *mm, unsigned long len,\r\nstruct slice_mask mask, int psize,\r\nint topdown, unsigned long high_limit)\r\n{\r\nif (topdown)\r\nreturn slice_find_area_topdown(mm, len, mask, psize, high_limit);\r\nelse\r\nreturn slice_find_area_bottomup(mm, len, mask, psize, high_limit);\r\n}\r\nstatic inline void slice_or_mask(struct slice_mask *dst, struct slice_mask *src)\r\n{\r\nDECLARE_BITMAP(result, SLICE_NUM_HIGH);\r\ndst->low_slices |= src->low_slices;\r\nbitmap_or(result, dst->high_slices, src->high_slices, SLICE_NUM_HIGH);\r\nbitmap_copy(dst->high_slices, result, SLICE_NUM_HIGH);\r\n}\r\nstatic inline void slice_andnot_mask(struct slice_mask *dst, struct slice_mask *src)\r\n{\r\nDECLARE_BITMAP(result, SLICE_NUM_HIGH);\r\ndst->low_slices &= ~src->low_slices;\r\nbitmap_andnot(result, dst->high_slices, src->high_slices, SLICE_NUM_HIGH);\r\nbitmap_copy(dst->high_slices, result, SLICE_NUM_HIGH);\r\n}\r\nunsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,\r\nunsigned long flags, unsigned int psize,\r\nint topdown)\r\n{\r\nstruct slice_mask mask;\r\nstruct slice_mask good_mask;\r\nstruct slice_mask potential_mask;\r\nstruct slice_mask compat_mask;\r\nint fixed = (flags & MAP_FIXED);\r\nint pshift = max_t(int, mmu_psize_defs[psize].shift, PAGE_SHIFT);\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long newaddr;\r\nunsigned long high_limit;\r\nif (unlikely(addr > mm->context.addr_limit &&\r\nmm->context.addr_limit != TASK_SIZE)) {\r\nmm->context.addr_limit = TASK_SIZE;\r\non_each_cpu(slice_flush_segments, mm, 1);\r\n}\r\nif (addr > DEFAULT_MAP_WINDOW)\r\nhigh_limit = mm->context.addr_limit;\r\nelse\r\nhigh_limit = DEFAULT_MAP_WINDOW;\r\nmask.low_slices = 0;\r\nbitmap_zero(mask.high_slices, SLICE_NUM_HIGH);\r\n;\r\npotential_mask.low_slices = 0;\r\nbitmap_zero(potential_mask.high_slices, SLICE_NUM_HIGH);\r\ncompat_mask.low_slices = 0;\r\nbitmap_zero(compat_mask.high_slices, SLICE_NUM_HIGH);\r\nBUG_ON(mm->task_size == 0);\r\nVM_BUG_ON(radix_enabled());\r\nslice_dbg("slice_get_unmapped_area(mm=%p, psize=%d...\n", mm, psize);\r\nslice_dbg(" addr=%lx, len=%lx, flags=%lx, topdown=%d\n",\r\naddr, len, flags, topdown);\r\nif (len > mm->task_size)\r\nreturn -ENOMEM;\r\nif (len & ((1ul << pshift) - 1))\r\nreturn -EINVAL;\r\nif (fixed && (addr & ((1ul << pshift) - 1)))\r\nreturn -EINVAL;\r\nif (fixed && addr > (mm->task_size - len))\r\nreturn -ENOMEM;\r\nif (!fixed && addr) {\r\naddr = _ALIGN_UP(addr, 1ul << pshift);\r\nslice_dbg(" aligned addr=%lx\n", addr);\r\nif (addr > mm->task_size - len ||\r\n!slice_area_is_free(mm, addr, len))\r\naddr = 0;\r\n}\r\nslice_mask_for_size(mm, psize, &good_mask);\r\nslice_print_mask(" good_mask", good_mask);\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nif (psize == MMU_PAGE_64K) {\r\nslice_mask_for_size(mm, MMU_PAGE_4K, &compat_mask);\r\nif (fixed)\r\nslice_or_mask(&good_mask, &compat_mask);\r\n}\r\n#endif\r\nif (addr != 0 || fixed) {\r\nslice_range_to_mask(addr, len, &mask);\r\nslice_print_mask(" mask", mask);\r\nif (slice_check_fit(mm, mask, good_mask)) {\r\nslice_dbg(" fits good !\n");\r\nreturn addr;\r\n}\r\n} else {\r\nnewaddr = slice_find_area(mm, len, good_mask,\r\npsize, topdown, high_limit);\r\nif (newaddr != -ENOMEM) {\r\nslice_dbg(" found area at 0x%lx\n", newaddr);\r\nreturn newaddr;\r\n}\r\n}\r\nslice_mask_for_free(mm, &potential_mask);\r\nslice_or_mask(&potential_mask, &good_mask);\r\nslice_print_mask(" potential", potential_mask);\r\nif ((addr != 0 || fixed) && slice_check_fit(mm, mask, potential_mask)) {\r\nslice_dbg(" fits potential !\n");\r\ngoto convert;\r\n}\r\nif (fixed)\r\nreturn -EBUSY;\r\nslice_dbg(" search...\n");\r\nif (addr) {\r\naddr = slice_find_area(mm, len, good_mask,\r\npsize, topdown, high_limit);\r\nif (addr != -ENOMEM) {\r\nslice_dbg(" found area at 0x%lx\n", addr);\r\nreturn addr;\r\n}\r\n}\r\naddr = slice_find_area(mm, len, potential_mask,\r\npsize, topdown, high_limit);\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nif (addr == -ENOMEM && psize == MMU_PAGE_64K) {\r\nslice_or_mask(&potential_mask, &compat_mask);\r\naddr = slice_find_area(mm, len, potential_mask,\r\npsize, topdown, high_limit);\r\n}\r\n#endif\r\nif (addr == -ENOMEM)\r\nreturn -ENOMEM;\r\nslice_range_to_mask(addr, len, &mask);\r\nslice_dbg(" found potential area at 0x%lx\n", addr);\r\nslice_print_mask(" mask", mask);\r\nconvert:\r\nslice_andnot_mask(&mask, &good_mask);\r\nslice_andnot_mask(&mask, &compat_mask);\r\nif (mask.low_slices || !bitmap_empty(mask.high_slices, SLICE_NUM_HIGH)) {\r\nslice_convert(mm, mask, psize);\r\nif (psize > MMU_PAGE_BASE)\r\non_each_cpu(slice_flush_segments, mm, 1);\r\n}\r\nreturn addr;\r\n}\r\nunsigned long arch_get_unmapped_area(struct file *filp,\r\nunsigned long addr,\r\nunsigned long len,\r\nunsigned long pgoff,\r\nunsigned long flags)\r\n{\r\nreturn slice_get_unmapped_area(addr, len, flags,\r\ncurrent->mm->context.user_psize, 0);\r\n}\r\nunsigned long arch_get_unmapped_area_topdown(struct file *filp,\r\nconst unsigned long addr0,\r\nconst unsigned long len,\r\nconst unsigned long pgoff,\r\nconst unsigned long flags)\r\n{\r\nreturn slice_get_unmapped_area(addr0, len, flags,\r\ncurrent->mm->context.user_psize, 1);\r\n}\r\nunsigned int get_slice_psize(struct mm_struct *mm, unsigned long addr)\r\n{\r\nunsigned char *hpsizes;\r\nint index, mask_index;\r\nif (radix_enabled()) {\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nreturn MMU_PAGE_64K;\r\n#else\r\nreturn MMU_PAGE_4K;\r\n#endif\r\n}\r\nif (addr < SLICE_LOW_TOP) {\r\nu64 lpsizes;\r\nlpsizes = mm->context.low_slices_psize;\r\nindex = GET_LOW_SLICE_INDEX(addr);\r\nreturn (lpsizes >> (index * 4)) & 0xf;\r\n}\r\nhpsizes = mm->context.high_slices_psize;\r\nindex = GET_HIGH_SLICE_INDEX(addr);\r\nmask_index = index & 0x1;\r\nreturn (hpsizes[index >> 1] >> (mask_index * 4)) & 0xf;\r\n}\r\nvoid slice_set_user_psize(struct mm_struct *mm, unsigned int psize)\r\n{\r\nint index, mask_index;\r\nunsigned char *hpsizes;\r\nunsigned long flags, lpsizes;\r\nunsigned int old_psize;\r\nint i;\r\nslice_dbg("slice_set_user_psize(mm=%p, psize=%d)\n", mm, psize);\r\nVM_BUG_ON(radix_enabled());\r\nspin_lock_irqsave(&slice_convert_lock, flags);\r\nold_psize = mm->context.user_psize;\r\nslice_dbg(" old_psize=%d\n", old_psize);\r\nif (old_psize == psize)\r\ngoto bail;\r\nmm->context.user_psize = psize;\r\nwmb();\r\nlpsizes = mm->context.low_slices_psize;\r\nfor (i = 0; i < SLICE_NUM_LOW; i++)\r\nif (((lpsizes >> (i * 4)) & 0xf) == old_psize)\r\nlpsizes = (lpsizes & ~(0xful << (i * 4))) |\r\n(((unsigned long)psize) << (i * 4));\r\nmm->context.low_slices_psize = lpsizes;\r\nhpsizes = mm->context.high_slices_psize;\r\nfor (i = 0; i < SLICE_NUM_HIGH; i++) {\r\nmask_index = i & 0x1;\r\nindex = i >> 1;\r\nif (((hpsizes[index] >> (mask_index * 4)) & 0xf) == old_psize)\r\nhpsizes[index] = (hpsizes[index] &\r\n~(0xf << (mask_index * 4))) |\r\n(((unsigned long)psize) << (mask_index * 4));\r\n}\r\nslice_dbg(" lsps=%lx, hsps=%lx\n",\r\n(unsigned long)mm->context.low_slices_psize,\r\n(unsigned long)mm->context.high_slices_psize);\r\nbail:\r\nspin_unlock_irqrestore(&slice_convert_lock, flags);\r\n}\r\nvoid slice_set_range_psize(struct mm_struct *mm, unsigned long start,\r\nunsigned long len, unsigned int psize)\r\n{\r\nstruct slice_mask mask;\r\nVM_BUG_ON(radix_enabled());\r\nslice_range_to_mask(start, len, &mask);\r\nslice_convert(mm, mask, psize);\r\n}\r\nint is_hugepage_only_range(struct mm_struct *mm, unsigned long addr,\r\nunsigned long len)\r\n{\r\nstruct slice_mask mask, available;\r\nunsigned int psize = mm->context.user_psize;\r\nif (radix_enabled())\r\nreturn 0;\r\nslice_range_to_mask(addr, len, &mask);\r\nslice_mask_for_size(mm, psize, &available);\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nif (psize == MMU_PAGE_64K) {\r\nstruct slice_mask compat_mask;\r\nslice_mask_for_size(mm, MMU_PAGE_4K, &compat_mask);\r\nslice_or_mask(&available, &compat_mask);\r\n}\r\n#endif\r\n#if 0\r\nslice_dbg("is_hugepage_only_range(mm=%p, addr=%lx, len=%lx)\n",\r\nmm, addr, len);\r\nslice_print_mask(" mask", mask);\r\nslice_print_mask(" available", available);\r\n#endif\r\nreturn !slice_check_fit(mm, mask, available);\r\n}
