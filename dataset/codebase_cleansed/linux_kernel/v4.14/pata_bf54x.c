static unsigned short num_clocks_min(unsigned long tmin,\r\nunsigned long fsclk)\r\n{\r\nunsigned long tmp ;\r\nunsigned short result;\r\ntmp = tmin * (fsclk/1000/1000) / 1000;\r\nresult = (unsigned short)tmp;\r\nif ((tmp*1000*1000) < (tmin*(fsclk/1000))) {\r\nresult++;\r\n}\r\nreturn result;\r\n}\r\nstatic void bfin_set_piomode(struct ata_port *ap, struct ata_device *adev)\r\n{\r\nint mode = adev->pio_mode - XFER_PIO_0;\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nunsigned int fsclk = get_sclk();\r\nunsigned short teoc_reg, t2_reg, teoc_pio;\r\nunsigned short t4_reg, t2_pio, t1_reg;\r\nunsigned short n0, n6, t6min = 5;\r\nn6 = num_clocks_min(t6min, fsclk);\r\nif (mode >= 0 && mode <= 4 && n6 >= 1) {\r\ndev_dbg(adev->link->ap->dev, "set piomode: mode=%d, fsclk=%ud\n", mode, fsclk);\r\nwhile (mode > 0 && pio_fsclk[mode] > fsclk)\r\nmode--;\r\nt2_reg = num_clocks_min(reg_t2min[mode], fsclk);\r\nteoc_reg = num_clocks_min(reg_teocmin[mode], fsclk);\r\nn0 = num_clocks_min(reg_t0min[mode], fsclk);\r\nif (t2_reg + teoc_reg < n0)\r\nt2_reg = n0 - teoc_reg;\r\nt2_pio = num_clocks_min(pio_t2min[mode], fsclk);\r\nteoc_pio = num_clocks_min(pio_teocmin[mode], fsclk);\r\nn0 = num_clocks_min(pio_t0min[mode], fsclk);\r\nif (t2_pio + teoc_pio < n0)\r\nt2_pio = n0 - teoc_pio;\r\nt1_reg = num_clocks_min(pio_t1min[mode], fsclk);\r\nt4_reg = num_clocks_min(pio_t4min[mode], fsclk);\r\nATAPI_SET_REG_TIM_0(base, (teoc_reg<<8 | t2_reg));\r\nATAPI_SET_PIO_TIM_0(base, (t4_reg<<12 | t2_pio<<4 | t1_reg));\r\nATAPI_SET_PIO_TIM_1(base, teoc_pio);\r\nif (mode > 2) {\r\nATAPI_SET_CONTROL(base,\r\nATAPI_GET_CONTROL(base) | IORDY_EN);\r\n} else {\r\nATAPI_SET_CONTROL(base,\r\nATAPI_GET_CONTROL(base) & ~IORDY_EN);\r\n}\r\nATAPI_SET_INT_MASK(base, ATAPI_GET_INT_MASK(base)\r\n& ~(PIO_DONE_MASK | HOST_TERM_XFER_MASK));\r\nSSYNC();\r\n}\r\n}\r\nstatic void bfin_set_dmamode(struct ata_port *ap, struct ata_device *adev)\r\n{\r\nint mode;\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nunsigned long fsclk = get_sclk();\r\nunsigned short tenv, tack, tcyc_tdvs, tdvs, tmli, tss, trp, tzah;\r\nunsigned short tm, td, tkr, tkw, teoc, th;\r\nunsigned short n0, nf, tfmin = 5;\r\nunsigned short nmin, tcyc;\r\nmode = adev->dma_mode - XFER_UDMA_0;\r\nif (mode >= 0 && mode <= 5) {\r\ndev_dbg(adev->link->ap->dev, "set udmamode: mode=%d\n", mode);\r\nwhile (mode > 0 && udma_fsclk[mode] > fsclk)\r\nmode--;\r\nnmin = num_clocks_min(udma_tmin[mode], fsclk);\r\nif (nmin >= 1) {\r\ntdvs = num_clocks_min(udma_tdvsmin[mode], fsclk);\r\ntcyc = num_clocks_min(udma_tcycmin[mode], fsclk);\r\ntcyc_tdvs = 2;\r\nif (tdvs + tcyc_tdvs < tcyc)\r\ntcyc_tdvs = tcyc - tdvs;\r\nif (tcyc_tdvs < 2)\r\ntcyc_tdvs = 2;\r\nif (tdvs < 2)\r\ntdvs = 2;\r\ntack = num_clocks_min(udma_tackmin, fsclk);\r\ntss = num_clocks_min(udma_tssmin, fsclk);\r\ntmli = num_clocks_min(udma_tmlimin, fsclk);\r\ntzah = num_clocks_min(udma_tzahmin, fsclk);\r\ntrp = num_clocks_min(udma_trpmin[mode], fsclk);\r\ntenv = num_clocks_min(udma_tenvmin, fsclk);\r\nif (tenv <= udma_tenvmax[mode]) {\r\nATAPI_SET_ULTRA_TIM_0(base, (tenv<<8 | tack));\r\nATAPI_SET_ULTRA_TIM_1(base,\r\n(tcyc_tdvs<<8 | tdvs));\r\nATAPI_SET_ULTRA_TIM_2(base, (tmli<<8 | tss));\r\nATAPI_SET_ULTRA_TIM_3(base, (trp<<8 | tzah));\r\n}\r\n}\r\n}\r\nmode = adev->dma_mode - XFER_MW_DMA_0;\r\nif (mode >= 0 && mode <= 2) {\r\ndev_dbg(adev->link->ap->dev, "set mdmamode: mode=%d\n", mode);\r\nwhile (mode > 0 && mdma_fsclk[mode] > fsclk)\r\nmode--;\r\nnf = num_clocks_min(tfmin, fsclk);\r\nif (nf >= 1) {\r\ntd = num_clocks_min(mdma_tdmin[mode], fsclk);\r\ntkw = num_clocks_min(mdma_tkwmin[mode], fsclk);\r\nn0 = num_clocks_min(mdma_t0min[mode], fsclk);\r\nif (tkw + td < n0)\r\ntkw = n0 - td;\r\ntkr = num_clocks_min(mdma_tkrmin[mode], fsclk);\r\ntm = num_clocks_min(mdma_tmmin[mode], fsclk);\r\nteoc = num_clocks_min(mdma_tjmin[mode], fsclk);\r\nth = num_clocks_min(mdma_thmin[mode], fsclk);\r\nATAPI_SET_MULTI_TIM_0(base, (tm<<8 | td));\r\nATAPI_SET_MULTI_TIM_1(base, (tkr<<8 | tkw));\r\nATAPI_SET_MULTI_TIM_2(base, (teoc<<8 | th));\r\nSSYNC();\r\n}\r\n}\r\nreturn;\r\n}\r\nstatic inline void wait_complete(void __iomem *base, unsigned short mask)\r\n{\r\nunsigned short status;\r\nunsigned int i = 0;\r\n#define PATA_BF54X_WAIT_TIMEOUT 10000\r\nfor (i = 0; i < PATA_BF54X_WAIT_TIMEOUT; i++) {\r\nstatus = ATAPI_GET_INT_STATUS(base) & mask;\r\nif (status)\r\nbreak;\r\n}\r\nATAPI_SET_INT_STATUS(base, mask);\r\n}\r\nstatic void write_atapi_register(void __iomem *base,\r\nunsigned long ata_reg, unsigned short value)\r\n{\r\nATAPI_SET_DEV_TXBUF(base, value);\r\nATAPI_SET_DEV_ADDR(base, ata_reg);\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | XFER_DIR));\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));\r\nwait_complete(base, PIO_DONE_INT);\r\n}\r\nstatic unsigned short read_atapi_register(void __iomem *base,\r\nunsigned long ata_reg)\r\n{\r\nATAPI_SET_DEV_ADDR(base, ata_reg);\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~XFER_DIR));\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));\r\nwait_complete(base, PIO_DONE_INT);\r\nreturn ATAPI_GET_DEV_RXBUF(base);\r\n}\r\nstatic void write_atapi_data(void __iomem *base,\r\nint len, unsigned short *buf)\r\n{\r\nint i;\r\nATAPI_SET_XFER_LEN(base, 1);\r\nATAPI_SET_DEV_ADDR(base, ATA_REG_DATA);\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | XFER_DIR));\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));\r\nfor (i = 0; i < len; i++) {\r\nATAPI_SET_DEV_TXBUF(base, buf[i]);\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));\r\nwait_complete(base, PIO_DONE_INT);\r\n}\r\n}\r\nstatic void read_atapi_data(void __iomem *base,\r\nint len, unsigned short *buf)\r\n{\r\nint i;\r\nATAPI_SET_XFER_LEN(base, 1);\r\nATAPI_SET_DEV_ADDR(base, ATA_REG_DATA);\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~XFER_DIR));\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) & ~PIO_USE_DMA));\r\nfor (i = 0; i < len; i++) {\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base) | PIO_START));\r\nwait_complete(base, PIO_DONE_INT);\r\nbuf[i] = ATAPI_GET_DEV_RXBUF(base);\r\n}\r\n}\r\nstatic void bfin_tf_load(struct ata_port *ap, const struct ata_taskfile *tf)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nunsigned int is_addr = tf->flags & ATA_TFLAG_ISADDR;\r\nif (tf->ctl != ap->last_ctl) {\r\nwrite_atapi_register(base, ATA_REG_CTRL, tf->ctl);\r\nap->last_ctl = tf->ctl;\r\nata_wait_idle(ap);\r\n}\r\nif (is_addr) {\r\nif (tf->flags & ATA_TFLAG_LBA48) {\r\nwrite_atapi_register(base, ATA_REG_FEATURE,\r\ntf->hob_feature);\r\nwrite_atapi_register(base, ATA_REG_NSECT,\r\ntf->hob_nsect);\r\nwrite_atapi_register(base, ATA_REG_LBAL, tf->hob_lbal);\r\nwrite_atapi_register(base, ATA_REG_LBAM, tf->hob_lbam);\r\nwrite_atapi_register(base, ATA_REG_LBAH, tf->hob_lbah);\r\ndev_dbg(ap->dev, "hob: feat 0x%X nsect 0x%X, lba 0x%X "\r\n"0x%X 0x%X\n",\r\ntf->hob_feature,\r\ntf->hob_nsect,\r\ntf->hob_lbal,\r\ntf->hob_lbam,\r\ntf->hob_lbah);\r\n}\r\nwrite_atapi_register(base, ATA_REG_FEATURE, tf->feature);\r\nwrite_atapi_register(base, ATA_REG_NSECT, tf->nsect);\r\nwrite_atapi_register(base, ATA_REG_LBAL, tf->lbal);\r\nwrite_atapi_register(base, ATA_REG_LBAM, tf->lbam);\r\nwrite_atapi_register(base, ATA_REG_LBAH, tf->lbah);\r\ndev_dbg(ap->dev, "feat 0x%X nsect 0x%X lba 0x%X 0x%X 0x%X\n",\r\ntf->feature,\r\ntf->nsect,\r\ntf->lbal,\r\ntf->lbam,\r\ntf->lbah);\r\n}\r\nif (tf->flags & ATA_TFLAG_DEVICE) {\r\nwrite_atapi_register(base, ATA_REG_DEVICE, tf->device);\r\ndev_dbg(ap->dev, "device 0x%X\n", tf->device);\r\n}\r\nata_wait_idle(ap);\r\n}\r\nstatic u8 bfin_check_status(struct ata_port *ap)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nreturn read_atapi_register(base, ATA_REG_STATUS);\r\n}\r\nstatic void bfin_tf_read(struct ata_port *ap, struct ata_taskfile *tf)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\ntf->command = bfin_check_status(ap);\r\ntf->feature = read_atapi_register(base, ATA_REG_ERR);\r\ntf->nsect = read_atapi_register(base, ATA_REG_NSECT);\r\ntf->lbal = read_atapi_register(base, ATA_REG_LBAL);\r\ntf->lbam = read_atapi_register(base, ATA_REG_LBAM);\r\ntf->lbah = read_atapi_register(base, ATA_REG_LBAH);\r\ntf->device = read_atapi_register(base, ATA_REG_DEVICE);\r\nif (tf->flags & ATA_TFLAG_LBA48) {\r\nwrite_atapi_register(base, ATA_REG_CTRL, tf->ctl | ATA_HOB);\r\ntf->hob_feature = read_atapi_register(base, ATA_REG_ERR);\r\ntf->hob_nsect = read_atapi_register(base, ATA_REG_NSECT);\r\ntf->hob_lbal = read_atapi_register(base, ATA_REG_LBAL);\r\ntf->hob_lbam = read_atapi_register(base, ATA_REG_LBAM);\r\ntf->hob_lbah = read_atapi_register(base, ATA_REG_LBAH);\r\n}\r\n}\r\nstatic void bfin_exec_command(struct ata_port *ap,\r\nconst struct ata_taskfile *tf)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\ndev_dbg(ap->dev, "ata%u: cmd 0x%X\n", ap->print_id, tf->command);\r\nwrite_atapi_register(base, ATA_REG_CMD, tf->command);\r\nata_sff_pause(ap);\r\n}\r\nstatic u8 bfin_check_altstatus(struct ata_port *ap)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nreturn read_atapi_register(base, ATA_REG_ALTSTATUS);\r\n}\r\nstatic void bfin_dev_select(struct ata_port *ap, unsigned int device)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nu8 tmp;\r\nif (device == 0)\r\ntmp = ATA_DEVICE_OBS;\r\nelse\r\ntmp = ATA_DEVICE_OBS | ATA_DEV1;\r\nwrite_atapi_register(base, ATA_REG_DEVICE, tmp);\r\nata_sff_pause(ap);\r\n}\r\nstatic void bfin_set_devctl(struct ata_port *ap, u8 ctl)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nwrite_atapi_register(base, ATA_REG_CTRL, ctl);\r\n}\r\nstatic void bfin_bmdma_setup(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nstruct dma_desc_array *dma_desc_cpu = (struct dma_desc_array *)ap->bmdma_prd;\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nunsigned short config = DMAFLOW_ARRAY | NDSIZE_5 | RESTART | WDSIZE_16 | DMAEN;\r\nstruct scatterlist *sg;\r\nunsigned int si;\r\nunsigned int channel;\r\nunsigned int dir;\r\nunsigned int size = 0;\r\ndev_dbg(qc->ap->dev, "in atapi dma setup\n");\r\nif (qc->tf.flags & ATA_TFLAG_WRITE) {\r\nchannel = CH_ATAPI_TX;\r\ndir = DMA_TO_DEVICE;\r\n} else {\r\nchannel = CH_ATAPI_RX;\r\ndir = DMA_FROM_DEVICE;\r\nconfig |= WNR;\r\n}\r\ndma_map_sg(ap->dev, qc->sg, qc->n_elem, dir);\r\nfor_each_sg(qc->sg, sg, qc->n_elem, si) {\r\ndma_desc_cpu[si].start_addr = sg_dma_address(sg);\r\ndma_desc_cpu[si].cfg = config;\r\ndma_desc_cpu[si].x_count = sg_dma_len(sg) >> 1;\r\ndma_desc_cpu[si].x_modify = 2;\r\nsize += sg_dma_len(sg);\r\n}\r\ndma_desc_cpu[qc->n_elem - 1].cfg &= ~(DMAFLOW | NDSIZE);\r\nflush_dcache_range((unsigned int)dma_desc_cpu,\r\n(unsigned int)dma_desc_cpu +\r\nqc->n_elem * sizeof(struct dma_desc_array));\r\nset_dma_curr_desc_addr(channel, (unsigned long *)ap->bmdma_prd_dma);\r\nset_dma_x_count(channel, 0);\r\nset_dma_x_modify(channel, 0);\r\nset_dma_config(channel, config);\r\nSSYNC();\r\nbfin_exec_command(ap, &qc->tf);\r\nif (qc->tf.flags & ATA_TFLAG_WRITE) {\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base)\r\n| XFER_DIR));\r\n} else {\r\nATAPI_SET_CONTROL(base, (ATAPI_GET_CONTROL(base)\r\n& ~XFER_DIR));\r\n}\r\nATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) | TFRCNT_RST);\r\nATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) | END_ON_TERM);\r\nATAPI_SET_XFER_LEN(base, size >> 1);\r\n}\r\nstatic void bfin_bmdma_start(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\ndev_dbg(qc->ap->dev, "in atapi dma start\n");\r\nif (!(ap->udma_mask || ap->mwdma_mask))\r\nreturn;\r\nif (ap->udma_mask)\r\nATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base)\r\n| ULTRA_START);\r\nelse\r\nATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base)\r\n| MULTI_START);\r\n}\r\nstatic void bfin_bmdma_stop(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nunsigned int dir;\r\ndev_dbg(qc->ap->dev, "in atapi dma stop\n");\r\nif (!(ap->udma_mask || ap->mwdma_mask))\r\nreturn;\r\nif (qc->tf.flags & ATA_TFLAG_WRITE) {\r\ndir = DMA_TO_DEVICE;\r\ndisable_dma(CH_ATAPI_TX);\r\n} else {\r\ndir = DMA_FROM_DEVICE;\r\ndisable_dma(CH_ATAPI_RX);\r\n}\r\ndma_unmap_sg(ap->dev, qc->sg, qc->n_elem, dir);\r\n}\r\nstatic unsigned int bfin_devchk(struct ata_port *ap,\r\nunsigned int device)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nu8 nsect, lbal;\r\nbfin_dev_select(ap, device);\r\nwrite_atapi_register(base, ATA_REG_NSECT, 0x55);\r\nwrite_atapi_register(base, ATA_REG_LBAL, 0xaa);\r\nwrite_atapi_register(base, ATA_REG_NSECT, 0xaa);\r\nwrite_atapi_register(base, ATA_REG_LBAL, 0x55);\r\nwrite_atapi_register(base, ATA_REG_NSECT, 0x55);\r\nwrite_atapi_register(base, ATA_REG_LBAL, 0xaa);\r\nnsect = read_atapi_register(base, ATA_REG_NSECT);\r\nlbal = read_atapi_register(base, ATA_REG_LBAL);\r\nif ((nsect == 0x55) && (lbal == 0xaa))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void bfin_bus_post_reset(struct ata_port *ap, unsigned int devmask)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nunsigned int dev0 = devmask & (1 << 0);\r\nunsigned int dev1 = devmask & (1 << 1);\r\nunsigned long deadline;\r\nif (dev0)\r\nata_sff_busy_sleep(ap, ATA_TMOUT_BOOT_QUICK, ATA_TMOUT_BOOT);\r\ndeadline = ata_deadline(jiffies, ATA_TMOUT_BOOT);\r\nwhile (dev1) {\r\nu8 nsect, lbal;\r\nbfin_dev_select(ap, 1);\r\nnsect = read_atapi_register(base, ATA_REG_NSECT);\r\nlbal = read_atapi_register(base, ATA_REG_LBAL);\r\nif ((nsect == 1) && (lbal == 1))\r\nbreak;\r\nif (time_after(jiffies, deadline)) {\r\ndev1 = 0;\r\nbreak;\r\n}\r\nata_msleep(ap, 50);\r\n}\r\nif (dev1)\r\nata_sff_busy_sleep(ap, ATA_TMOUT_BOOT_QUICK, ATA_TMOUT_BOOT);\r\nbfin_dev_select(ap, 0);\r\nif (dev1)\r\nbfin_dev_select(ap, 1);\r\nif (dev0)\r\nbfin_dev_select(ap, 0);\r\n}\r\nstatic unsigned int bfin_bus_softreset(struct ata_port *ap,\r\nunsigned int devmask)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nwrite_atapi_register(base, ATA_REG_CTRL, ap->ctl);\r\nudelay(20);\r\nwrite_atapi_register(base, ATA_REG_CTRL, ap->ctl | ATA_SRST);\r\nudelay(20);\r\nwrite_atapi_register(base, ATA_REG_CTRL, ap->ctl);\r\nata_msleep(ap, 150);\r\nif (bfin_check_status(ap) == 0xFF)\r\nreturn 0;\r\nbfin_bus_post_reset(ap, devmask);\r\nreturn 0;\r\n}\r\nstatic int bfin_softreset(struct ata_link *link, unsigned int *classes,\r\nunsigned long deadline)\r\n{\r\nstruct ata_port *ap = link->ap;\r\nunsigned int slave_possible = ap->flags & ATA_FLAG_SLAVE_POSS;\r\nunsigned int devmask = 0, err_mask;\r\nu8 err;\r\nif (bfin_devchk(ap, 0))\r\ndevmask |= (1 << 0);\r\nif (slave_possible && bfin_devchk(ap, 1))\r\ndevmask |= (1 << 1);\r\nbfin_dev_select(ap, 0);\r\nerr_mask = bfin_bus_softreset(ap, devmask);\r\nif (err_mask) {\r\nata_port_err(ap, "SRST failed (err_mask=0x%x)\n",\r\nerr_mask);\r\nreturn -EIO;\r\n}\r\nclasses[0] = ata_sff_dev_classify(&ap->link.device[0],\r\ndevmask & (1 << 0), &err);\r\nif (slave_possible && err != 0x81)\r\nclasses[1] = ata_sff_dev_classify(&ap->link.device[1],\r\ndevmask & (1 << 1), &err);\r\nreturn 0;\r\n}\r\nstatic unsigned char bfin_bmdma_status(struct ata_port *ap)\r\n{\r\nunsigned char host_stat = 0;\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nif (ATAPI_GET_STATUS(base) & (MULTI_XFER_ON | ULTRA_XFER_ON))\r\nhost_stat |= ATA_DMA_ACTIVE;\r\nif (ATAPI_GET_INT_STATUS(base) & ATAPI_DEV_INT)\r\nhost_stat |= ATA_DMA_INTR;\r\ndev_dbg(ap->dev, "ATAPI: host_stat=0x%x\n", host_stat);\r\nreturn host_stat;\r\n}\r\nstatic unsigned int bfin_data_xfer(struct ata_queued_cmd *qc,\r\nunsigned char *buf,\r\nunsigned int buflen, int rw)\r\n{\r\nstruct ata_port *ap = qc->dev->link->ap;\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nunsigned int words = buflen >> 1;\r\nunsigned short *buf16 = (u16 *)buf;\r\nif (rw == READ)\r\nread_atapi_data(base, words, buf16);\r\nelse\r\nwrite_atapi_data(base, words, buf16);\r\nif (unlikely(buflen & 0x01)) {\r\nunsigned short align_buf[1] = { 0 };\r\nunsigned char *trailing_buf = buf + buflen - 1;\r\nif (rw == READ) {\r\nread_atapi_data(base, 1, align_buf);\r\nmemcpy(trailing_buf, align_buf, 1);\r\n} else {\r\nmemcpy(align_buf, trailing_buf, 1);\r\nwrite_atapi_data(base, 1, align_buf);\r\n}\r\nwords++;\r\n}\r\nreturn words << 1;\r\n}\r\nstatic void bfin_irq_clear(struct ata_port *ap)\r\n{\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\ndev_dbg(ap->dev, "in atapi irq clear\n");\r\nATAPI_SET_INT_STATUS(base, ATAPI_GET_INT_STATUS(base)|ATAPI_DEV_INT\r\n| MULTI_DONE_INT | UDMAIN_DONE_INT | UDMAOUT_DONE_INT\r\n| MULTI_TERM_INT | UDMAIN_TERM_INT | UDMAOUT_TERM_INT);\r\n}\r\nvoid bfin_thaw(struct ata_port *ap)\r\n{\r\ndev_dbg(ap->dev, "in atapi dma thaw\n");\r\nbfin_check_status(ap);\r\nata_sff_irq_on(ap);\r\n}\r\nstatic void bfin_postreset(struct ata_link *link, unsigned int *classes)\r\n{\r\nstruct ata_port *ap = link->ap;\r\nvoid __iomem *base = (void __iomem *)ap->ioaddr.ctl_addr;\r\nata_sff_irq_on(ap);\r\nif (classes[0] != ATA_DEV_NONE)\r\nbfin_dev_select(ap, 1);\r\nif (classes[1] != ATA_DEV_NONE)\r\nbfin_dev_select(ap, 0);\r\nif (classes[0] == ATA_DEV_NONE && classes[1] == ATA_DEV_NONE) {\r\nreturn;\r\n}\r\nwrite_atapi_register(base, ATA_REG_CTRL, ap->ctl);\r\n}\r\nstatic void bfin_port_stop(struct ata_port *ap)\r\n{\r\ndev_dbg(ap->dev, "in atapi port stop\n");\r\nif (ap->udma_mask != 0 || ap->mwdma_mask != 0) {\r\ndma_free_coherent(ap->dev,\r\nBFIN_MAX_SG_SEGMENTS * sizeof(struct dma_desc_array),\r\nap->bmdma_prd,\r\nap->bmdma_prd_dma);\r\nfree_dma(CH_ATAPI_RX);\r\nfree_dma(CH_ATAPI_TX);\r\n}\r\n}\r\nstatic int bfin_port_start(struct ata_port *ap)\r\n{\r\ndev_dbg(ap->dev, "in atapi port start\n");\r\nif (!(ap->udma_mask || ap->mwdma_mask))\r\nreturn 0;\r\nap->bmdma_prd = dma_alloc_coherent(ap->dev,\r\nBFIN_MAX_SG_SEGMENTS * sizeof(struct dma_desc_array),\r\n&ap->bmdma_prd_dma,\r\nGFP_KERNEL);\r\nif (ap->bmdma_prd == NULL) {\r\ndev_info(ap->dev, "Unable to allocate DMA descriptor array.\n");\r\ngoto out;\r\n}\r\nif (request_dma(CH_ATAPI_RX, "BFIN ATAPI RX DMA") >= 0) {\r\nif (request_dma(CH_ATAPI_TX,\r\n"BFIN ATAPI TX DMA") >= 0)\r\nreturn 0;\r\nfree_dma(CH_ATAPI_RX);\r\ndma_free_coherent(ap->dev,\r\nBFIN_MAX_SG_SEGMENTS * sizeof(struct dma_desc_array),\r\nap->bmdma_prd,\r\nap->bmdma_prd_dma);\r\n}\r\nout:\r\nap->udma_mask = 0;\r\nap->mwdma_mask = 0;\r\ndev_err(ap->dev, "Unable to request ATAPI DMA!"\r\n" Continue in PIO mode.\n");\r\nreturn 0;\r\n}\r\nstatic unsigned int bfin_ata_host_intr(struct ata_port *ap,\r\nstruct ata_queued_cmd *qc)\r\n{\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nu8 status, host_stat = 0;\r\nVPRINTK("ata%u: protocol %d task_state %d\n",\r\nap->print_id, qc->tf.protocol, ap->hsm_task_state);\r\nswitch (ap->hsm_task_state) {\r\ncase HSM_ST_FIRST:\r\nif (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))\r\ngoto idle_irq;\r\nbreak;\r\ncase HSM_ST_LAST:\r\nif (qc->tf.protocol == ATA_PROT_DMA ||\r\nqc->tf.protocol == ATAPI_PROT_DMA) {\r\nhost_stat = ap->ops->bmdma_status(ap);\r\nVPRINTK("ata%u: host_stat 0x%X\n",\r\nap->print_id, host_stat);\r\nif (!(host_stat & ATA_DMA_INTR))\r\ngoto idle_irq;\r\nap->ops->bmdma_stop(qc);\r\nif (unlikely(host_stat & ATA_DMA_ERR)) {\r\nqc->err_mask |= AC_ERR_HOST_BUS;\r\nap->hsm_task_state = HSM_ST_ERR;\r\n}\r\n}\r\nbreak;\r\ncase HSM_ST:\r\nbreak;\r\ndefault:\r\ngoto idle_irq;\r\n}\r\nstatus = ap->ops->sff_check_altstatus(ap);\r\nif (status & ATA_BUSY)\r\ngoto busy_ata;\r\nstatus = ap->ops->sff_check_status(ap);\r\nif (unlikely(status & ATA_BUSY))\r\ngoto busy_ata;\r\nap->ops->sff_irq_clear(ap);\r\nata_sff_hsm_move(ap, qc, status, 0);\r\nif (unlikely(qc->err_mask) && (qc->tf.protocol == ATA_PROT_DMA ||\r\nqc->tf.protocol == ATAPI_PROT_DMA))\r\nata_ehi_push_desc(ehi, "BMDMA stat 0x%x", host_stat);\r\nbusy_ata:\r\nreturn 1;\r\nidle_irq:\r\nap->stats.idle_irq++;\r\n#ifdef ATA_IRQ_TRAP\r\nif ((ap->stats.idle_irq % 1000) == 0) {\r\nap->ops->irq_ack(ap, 0);\r\nata_port_warn(ap, "irq trap\n");\r\nreturn 1;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic irqreturn_t bfin_ata_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nunsigned int i;\r\nunsigned int handled = 0;\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nstruct ata_queued_cmd *qc;\r\nqc = ata_qc_from_tag(ap, ap->link.active_tag);\r\nif (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING)))\r\nhandled |= bfin_ata_host_intr(ap, qc);\r\n}\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic int bfin_reset_controller(struct ata_host *host)\r\n{\r\nvoid __iomem *base = (void __iomem *)host->ports[0]->ioaddr.ctl_addr;\r\nint count;\r\nunsigned short status;\r\nATAPI_SET_INT_MASK(base, 0);\r\nSSYNC();\r\nATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) | DEV_RST);\r\nudelay(30);\r\nATAPI_SET_CONTROL(base, ATAPI_GET_CONTROL(base) & ~DEV_RST);\r\nmsleep(2);\r\ncount = 10000000;\r\ndo {\r\nstatus = read_atapi_register(base, ATA_REG_STATUS);\r\n} while (--count && (status & ATA_BUSY));\r\nATAPI_SET_INT_MASK(base, 1);\r\nSSYNC();\r\nreturn (!count);\r\n}\r\nstatic int bfin_atapi_probe(struct platform_device *pdev)\r\n{\r\nint board_idx = 0;\r\nstruct resource *res;\r\nstruct ata_host *host;\r\nunsigned int fsclk = get_sclk();\r\nint udma_mode = 5;\r\nconst struct ata_port_info *ppi[] =\r\n{ &bfin_port_info[board_idx], NULL };\r\nif (unlikely(pdev->num_resources != 2)) {\r\ndev_err(&pdev->dev, "invalid number of resources\n");\r\nreturn -EINVAL;\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (res == NULL)\r\nreturn -EINVAL;\r\nwhile (bfin_port_info[board_idx].udma_mask > 0 &&\r\nudma_fsclk[udma_mode] > fsclk) {\r\nudma_mode--;\r\nbfin_port_info[board_idx].udma_mask >>= 1;\r\n}\r\nhost = ata_host_alloc_pinfo(&pdev->dev, ppi, 1);\r\nif (!host)\r\nreturn -ENOMEM;\r\nhost->ports[0]->ioaddr.ctl_addr = (void *)res->start;\r\nif (peripheral_request_list(atapi_io_port, "atapi-io-port")) {\r\ndev_err(&pdev->dev, "Requesting Peripherals failed\n");\r\nreturn -EFAULT;\r\n}\r\nif (bfin_reset_controller(host)) {\r\nperipheral_free_list(atapi_io_port);\r\ndev_err(&pdev->dev, "Fail to reset ATAPI device\n");\r\nreturn -EFAULT;\r\n}\r\nif (ata_host_activate(host, platform_get_irq(pdev, 0),\r\nbfin_ata_interrupt, IRQF_SHARED, &bfin_sht) != 0) {\r\nperipheral_free_list(atapi_io_port);\r\ndev_err(&pdev->dev, "Fail to attach ATAPI device\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int bfin_atapi_remove(struct platform_device *pdev)\r\n{\r\nstruct ata_host *host = platform_get_drvdata(pdev);\r\nata_host_detach(host);\r\nperipheral_free_list(atapi_io_port);\r\nreturn 0;\r\n}\r\nstatic int bfin_atapi_suspend(struct platform_device *pdev, pm_message_t state)\r\n{\r\nstruct ata_host *host = platform_get_drvdata(pdev);\r\nif (host)\r\nreturn ata_host_suspend(host, state);\r\nelse\r\nreturn 0;\r\n}\r\nstatic int bfin_atapi_resume(struct platform_device *pdev)\r\n{\r\nstruct ata_host *host = platform_get_drvdata(pdev);\r\nint ret;\r\nif (host) {\r\nret = bfin_reset_controller(host);\r\nif (ret) {\r\nprintk(KERN_ERR DRV_NAME ": Error during HW init\n");\r\nreturn ret;\r\n}\r\nata_host_resume(host);\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init bfin_atapi_init(void)\r\n{\r\npr_info("register bfin atapi driver\n");\r\nswitch(bfin_atapi_mode[0]) {\r\ncase 'p':\r\ncase 'P':\r\nbreak;\r\ncase 'm':\r\ncase 'M':\r\nbfin_port_info[0].mwdma_mask = ATA_MWDMA2;\r\nbreak;\r\ndefault:\r\nbfin_port_info[0].udma_mask = ATA_UDMA5;\r\n};\r\nreturn platform_driver_register(&bfin_atapi_driver);\r\n}\r\nstatic void __exit bfin_atapi_exit(void)\r\n{\r\nplatform_driver_unregister(&bfin_atapi_driver);\r\n}
