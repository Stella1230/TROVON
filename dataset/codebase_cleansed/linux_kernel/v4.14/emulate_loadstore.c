static bool kvmppc_check_fp_disabled(struct kvm_vcpu *vcpu)\r\n{\r\nif (!(kvmppc_get_msr(vcpu) & MSR_FP)) {\r\nkvmppc_core_queue_fpunavail(vcpu);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic bool kvmppc_check_vsx_disabled(struct kvm_vcpu *vcpu)\r\n{\r\nif (!(kvmppc_get_msr(vcpu) & MSR_VSX)) {\r\nkvmppc_core_queue_vsx_unavail(vcpu);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nint kvmppc_emulate_loadstore(struct kvm_vcpu *vcpu)\r\n{\r\nstruct kvm_run *run = vcpu->run;\r\nu32 inst;\r\nint ra, rs, rt;\r\nenum emulation_result emulated;\r\nint advance = 1;\r\nkvmppc_set_exit_type(vcpu, EMULATED_INST_EXITS);\r\nemulated = kvmppc_get_last_inst(vcpu, INST_GENERIC, &inst);\r\nif (emulated != EMULATE_DONE)\r\nreturn emulated;\r\nra = get_ra(inst);\r\nrs = get_rs(inst);\r\nrt = get_rt(inst);\r\nvcpu->arch.mmio_vsx_tx_sx_enabled = get_tx_or_sx(inst);\r\nvcpu->arch.mmio_vsx_copy_nums = 0;\r\nvcpu->arch.mmio_vsx_offset = 0;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_NONE;\r\nvcpu->arch.mmio_sp64_extend = 0;\r\nvcpu->arch.mmio_sign_extend = 0;\r\nswitch (get_op(inst)) {\r\ncase 31:\r\nswitch (get_xop(inst)) {\r\ncase OP_31_XOP_LWZX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 4, 1);\r\nbreak;\r\ncase OP_31_XOP_LWZUX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_LBZX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 1, 1);\r\nbreak;\r\ncase OP_31_XOP_LBZUX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 1, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_STDX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 8, 1);\r\nbreak;\r\ncase OP_31_XOP_STDUX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_STWX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 4, 1);\r\nbreak;\r\ncase OP_31_XOP_STWUX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_STBX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 1, 1);\r\nbreak;\r\ncase OP_31_XOP_STBUX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 1, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_LHAX:\r\nemulated = kvmppc_handle_loads(run, vcpu, rt, 2, 1);\r\nbreak;\r\ncase OP_31_XOP_LHAUX:\r\nemulated = kvmppc_handle_loads(run, vcpu, rt, 2, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_LHZX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 2, 1);\r\nbreak;\r\ncase OP_31_XOP_LHZUX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 2, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_STHX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 2, 1);\r\nbreak;\r\ncase OP_31_XOP_STHUX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 2, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_DCBST:\r\ncase OP_31_XOP_DCBF:\r\ncase OP_31_XOP_DCBI:\r\nbreak;\r\ncase OP_31_XOP_LWBRX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 4, 0);\r\nbreak;\r\ncase OP_31_XOP_STWBRX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 4, 0);\r\nbreak;\r\ncase OP_31_XOP_LHBRX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 2, 0);\r\nbreak;\r\ncase OP_31_XOP_STHBRX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 2, 0);\r\nbreak;\r\ncase OP_31_XOP_LDBRX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 8, 0);\r\nbreak;\r\ncase OP_31_XOP_STDBRX:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 8, 0);\r\nbreak;\r\ncase OP_31_XOP_LDX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 8, 1);\r\nbreak;\r\ncase OP_31_XOP_LDUX:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_LWAX:\r\nemulated = kvmppc_handle_loads(run, vcpu, rt, 4, 1);\r\nbreak;\r\ncase OP_31_XOP_LWAUX:\r\nemulated = kvmppc_handle_loads(run, vcpu, rt, 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\n#ifdef CONFIG_PPC_FPU\r\ncase OP_31_XOP_LFSX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 4, 1);\r\nbreak;\r\ncase OP_31_XOP_LFSUX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_LFDX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 8, 1);\r\nbreak;\r\ncase OP_31_XOP_LFDUX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_LFIWAX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_loads(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 4, 1);\r\nbreak;\r\ncase OP_31_XOP_LFIWZX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 4, 1);\r\nbreak;\r\ncase OP_31_XOP_STFSX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs), 4, 1);\r\nbreak;\r\ncase OP_31_XOP_STFSUX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs), 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_STFDX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs), 8, 1);\r\nbreak;\r\ncase OP_31_XOP_STFDUX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs), 8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_31_XOP_STFIWX:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs), 4, 1);\r\nbreak;\r\n#endif\r\n#ifdef CONFIG_VSX\r\ncase OP_31_XOP_LXSDX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nemulated = kvmppc_handle_vsx_load(run, vcpu,\r\nKVM_MMIO_REG_VSX|rt, 8, 1, 0);\r\nbreak;\r\ncase OP_31_XOP_LXSSPX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_vsx_load(run, vcpu,\r\nKVM_MMIO_REG_VSX|rt, 4, 1, 0);\r\nbreak;\r\ncase OP_31_XOP_LXSIWAX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nemulated = kvmppc_handle_vsx_load(run, vcpu,\r\nKVM_MMIO_REG_VSX|rt, 4, 1, 1);\r\nbreak;\r\ncase OP_31_XOP_LXSIWZX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nemulated = kvmppc_handle_vsx_load(run, vcpu,\r\nKVM_MMIO_REG_VSX|rt, 4, 1, 0);\r\nbreak;\r\ncase OP_31_XOP_LXVD2X:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 2;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nemulated = kvmppc_handle_vsx_load(run, vcpu,\r\nKVM_MMIO_REG_VSX|rt, 8, 1, 0);\r\nbreak;\r\ncase OP_31_XOP_LXVW4X:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 4;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_WORD;\r\nemulated = kvmppc_handle_vsx_load(run, vcpu,\r\nKVM_MMIO_REG_VSX|rt, 4, 1, 0);\r\nbreak;\r\ncase OP_31_XOP_LXVDSX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type =\r\nKVMPPC_VSX_COPY_DWORD_LOAD_DUMP;\r\nemulated = kvmppc_handle_vsx_load(run, vcpu,\r\nKVM_MMIO_REG_VSX|rt, 8, 1, 0);\r\nbreak;\r\ncase OP_31_XOP_STXSDX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nemulated = kvmppc_handle_vsx_store(run, vcpu,\r\nrs, 8, 1);\r\nbreak;\r\ncase OP_31_XOP_STXSSPX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_vsx_store(run, vcpu,\r\nrs, 4, 1);\r\nbreak;\r\ncase OP_31_XOP_STXSIWX:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_offset = 1;\r\nvcpu->arch.mmio_vsx_copy_nums = 1;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_WORD;\r\nemulated = kvmppc_handle_vsx_store(run, vcpu,\r\nrs, 4, 1);\r\nbreak;\r\ncase OP_31_XOP_STXVD2X:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 2;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_DWORD;\r\nemulated = kvmppc_handle_vsx_store(run, vcpu,\r\nrs, 8, 1);\r\nbreak;\r\ncase OP_31_XOP_STXVW4X:\r\nif (kvmppc_check_vsx_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_vsx_copy_nums = 4;\r\nvcpu->arch.mmio_vsx_copy_type = KVMPPC_VSX_COPY_WORD;\r\nemulated = kvmppc_handle_vsx_store(run, vcpu,\r\nrs, 4, 1);\r\nbreak;\r\n#endif\r\ndefault:\r\nemulated = EMULATE_FAIL;\r\nbreak;\r\n}\r\nbreak;\r\ncase OP_LWZ:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 4, 1);\r\nbreak;\r\n#ifdef CONFIG_PPC_FPU\r\ncase OP_STFS:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs),\r\n4, 1);\r\nbreak;\r\ncase OP_STFSU:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs),\r\n4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_STFD:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs),\r\n8, 1);\r\nbreak;\r\ncase OP_STFDU:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nVCPU_FPR(vcpu, rs),\r\n8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\n#endif\r\ncase OP_LD:\r\nrt = get_rt(inst);\r\nswitch (inst & 3) {\r\ncase 0:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 8, 1);\r\nbreak;\r\ncase 1:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase 2:\r\nemulated = kvmppc_handle_loads(run, vcpu, rt, 4, 1);\r\nbreak;\r\ndefault:\r\nemulated = EMULATE_FAIL;\r\n}\r\nbreak;\r\ncase OP_LWZU:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_LBZ:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 1, 1);\r\nbreak;\r\ncase OP_LBZU:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 1, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_STW:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs),\r\n4, 1);\r\nbreak;\r\ncase OP_STD:\r\nrs = get_rs(inst);\r\nswitch (inst & 3) {\r\ncase 0:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 8, 1);\r\nbreak;\r\ncase 1:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ndefault:\r\nemulated = EMULATE_FAIL;\r\n}\r\nbreak;\r\ncase OP_STWU:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_STB:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 1, 1);\r\nbreak;\r\ncase OP_STBU:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 1, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_LHZ:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 2, 1);\r\nbreak;\r\ncase OP_LHZU:\r\nemulated = kvmppc_handle_load(run, vcpu, rt, 2, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_LHA:\r\nemulated = kvmppc_handle_loads(run, vcpu, rt, 2, 1);\r\nbreak;\r\ncase OP_LHAU:\r\nemulated = kvmppc_handle_loads(run, vcpu, rt, 2, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_STH:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 2, 1);\r\nbreak;\r\ncase OP_STHU:\r\nemulated = kvmppc_handle_store(run, vcpu,\r\nkvmppc_get_gpr(vcpu, rs), 2, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\n#ifdef CONFIG_PPC_FPU\r\ncase OP_LFS:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 4, 1);\r\nbreak;\r\ncase OP_LFSU:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nvcpu->arch.mmio_sp64_extend = 1;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 4, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\ncase OP_LFD:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 8, 1);\r\nbreak;\r\ncase OP_LFDU:\r\nif (kvmppc_check_fp_disabled(vcpu))\r\nreturn EMULATE_DONE;\r\nemulated = kvmppc_handle_load(run, vcpu,\r\nKVM_MMIO_REG_FPR|rt, 8, 1);\r\nkvmppc_set_gpr(vcpu, ra, vcpu->arch.vaddr_accessed);\r\nbreak;\r\n#endif\r\ndefault:\r\nemulated = EMULATE_FAIL;\r\nbreak;\r\n}\r\nif (emulated == EMULATE_FAIL) {\r\nadvance = 0;\r\nkvmppc_core_queue_program(vcpu, 0);\r\n}\r\ntrace_kvm_ppc_instr(inst, kvmppc_get_pc(vcpu), emulated);\r\nif (advance)\r\nkvmppc_set_pc(vcpu, kvmppc_get_pc(vcpu) + 4);\r\nreturn emulated;\r\n}
