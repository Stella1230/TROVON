static int s3c24xx_dma_phy_busy(struct s3c24xx_dma_phy *phy)\r\n{\r\nunsigned int val = readl(phy->base + S3C24XX_DSTAT);\r\nreturn val & S3C24XX_DSTAT_STAT_BUSY;\r\n}\r\nstatic bool s3c24xx_dma_phy_valid(struct s3c24xx_dma_chan *s3cchan,\r\nstruct s3c24xx_dma_phy *phy)\r\n{\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nconst struct s3c24xx_dma_platdata *pdata = s3cdma->pdata;\r\nstruct s3c24xx_dma_channel *cdata = &pdata->channels[s3cchan->id];\r\nint phyvalid;\r\nif (!s3cchan->slave)\r\nreturn true;\r\nif (s3cdma->sdata->has_reqsel)\r\nreturn true;\r\nphyvalid = (cdata->chansel >> (phy->id * S3C24XX_CHANSEL_WIDTH));\r\nreturn (phyvalid & S3C24XX_CHANSEL_VALID) ? true : false;\r\n}\r\nstatic\r\nstruct s3c24xx_dma_phy *s3c24xx_dma_get_phy(struct s3c24xx_dma_chan *s3cchan)\r\n{\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nstruct s3c24xx_dma_phy *phy = NULL;\r\nunsigned long flags;\r\nint i;\r\nint ret;\r\nfor (i = 0; i < s3cdma->pdata->num_phy_channels; i++) {\r\nphy = &s3cdma->phy_chans[i];\r\nif (!phy->valid)\r\ncontinue;\r\nif (!s3c24xx_dma_phy_valid(s3cchan, phy))\r\ncontinue;\r\nspin_lock_irqsave(&phy->lock, flags);\r\nif (!phy->serving) {\r\nphy->serving = s3cchan;\r\nspin_unlock_irqrestore(&phy->lock, flags);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&phy->lock, flags);\r\n}\r\nif (i == s3cdma->pdata->num_phy_channels) {\r\ndev_warn(&s3cdma->pdev->dev, "no phy channel available\n");\r\nreturn NULL;\r\n}\r\nif (s3cdma->sdata->has_clocks) {\r\nret = clk_enable(phy->clk);\r\nif (ret) {\r\ndev_err(&s3cdma->pdev->dev, "could not enable clock for channel %d, err %d\n",\r\nphy->id, ret);\r\nphy->serving = NULL;\r\nreturn NULL;\r\n}\r\n}\r\nreturn phy;\r\n}\r\nstatic inline void s3c24xx_dma_put_phy(struct s3c24xx_dma_phy *phy)\r\n{\r\nstruct s3c24xx_dma_engine *s3cdma = phy->host;\r\nif (s3cdma->sdata->has_clocks)\r\nclk_disable(phy->clk);\r\nphy->serving = NULL;\r\n}\r\nstatic void s3c24xx_dma_terminate_phy(struct s3c24xx_dma_phy *phy)\r\n{\r\nwritel(S3C24XX_DMASKTRIG_STOP, phy->base + S3C24XX_DMASKTRIG);\r\n}\r\nstatic inline\r\nstruct s3c24xx_dma_chan *to_s3c24xx_dma_chan(struct dma_chan *chan)\r\n{\r\nreturn container_of(chan, struct s3c24xx_dma_chan, vc.chan);\r\n}\r\nstatic u32 s3c24xx_dma_getbytes_chan(struct s3c24xx_dma_chan *s3cchan)\r\n{\r\nstruct s3c24xx_dma_phy *phy = s3cchan->phy;\r\nstruct s3c24xx_txd *txd = s3cchan->at;\r\nu32 tc = readl(phy->base + S3C24XX_DSTAT) & S3C24XX_DSTAT_CURRTC_MASK;\r\nreturn tc * txd->width;\r\n}\r\nstatic int s3c24xx_dma_set_runtime_config(struct dma_chan *chan,\r\nstruct dma_slave_config *config)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(chan);\r\nunsigned long flags;\r\nint ret = 0;\r\nif (config->src_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES ||\r\nconfig->dst_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES)\r\nreturn -EINVAL;\r\nspin_lock_irqsave(&s3cchan->vc.lock, flags);\r\nif (!s3cchan->slave) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\ns3cchan->cfg = *config;\r\nout:\r\nspin_unlock_irqrestore(&s3cchan->vc.lock, flags);\r\nreturn ret;\r\n}\r\nstatic inline\r\nstruct s3c24xx_txd *to_s3c24xx_txd(struct dma_async_tx_descriptor *tx)\r\n{\r\nreturn container_of(tx, struct s3c24xx_txd, vd.tx);\r\n}\r\nstatic struct s3c24xx_txd *s3c24xx_dma_get_txd(void)\r\n{\r\nstruct s3c24xx_txd *txd = kzalloc(sizeof(*txd), GFP_NOWAIT);\r\nif (txd) {\r\nINIT_LIST_HEAD(&txd->dsg_list);\r\ntxd->dcon = S3C24XX_DCON_INT | S3C24XX_DCON_NORELOAD;\r\n}\r\nreturn txd;\r\n}\r\nstatic void s3c24xx_dma_free_txd(struct s3c24xx_txd *txd)\r\n{\r\nstruct s3c24xx_sg *dsg, *_dsg;\r\nlist_for_each_entry_safe(dsg, _dsg, &txd->dsg_list, node) {\r\nlist_del(&dsg->node);\r\nkfree(dsg);\r\n}\r\nkfree(txd);\r\n}\r\nstatic void s3c24xx_dma_start_next_sg(struct s3c24xx_dma_chan *s3cchan,\r\nstruct s3c24xx_txd *txd)\r\n{\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nstruct s3c24xx_dma_phy *phy = s3cchan->phy;\r\nconst struct s3c24xx_dma_platdata *pdata = s3cdma->pdata;\r\nstruct s3c24xx_sg *dsg = list_entry(txd->at, struct s3c24xx_sg, node);\r\nu32 dcon = txd->dcon;\r\nu32 val;\r\nswitch (txd->width) {\r\ncase 1:\r\ndcon |= S3C24XX_DCON_DSZ_BYTE | dsg->len;\r\nbreak;\r\ncase 2:\r\ndcon |= S3C24XX_DCON_DSZ_HALFWORD | (dsg->len / 2);\r\nbreak;\r\ncase 4:\r\ndcon |= S3C24XX_DCON_DSZ_WORD | (dsg->len / 4);\r\nbreak;\r\n}\r\nif (s3cchan->slave) {\r\nstruct s3c24xx_dma_channel *cdata =\r\n&pdata->channels[s3cchan->id];\r\nif (s3cdma->sdata->has_reqsel) {\r\nwritel_relaxed((cdata->chansel << 1) |\r\nS3C24XX_DMAREQSEL_HW,\r\nphy->base + S3C24XX_DMAREQSEL);\r\n} else {\r\nint csel = cdata->chansel >> (phy->id *\r\nS3C24XX_CHANSEL_WIDTH);\r\ncsel &= S3C24XX_CHANSEL_REQ_MASK;\r\ndcon |= csel << S3C24XX_DCON_HWSRC_SHIFT;\r\ndcon |= S3C24XX_DCON_HWTRIG;\r\n}\r\n} else {\r\nif (s3cdma->sdata->has_reqsel)\r\nwritel_relaxed(0, phy->base + S3C24XX_DMAREQSEL);\r\n}\r\nwritel_relaxed(dsg->src_addr, phy->base + S3C24XX_DISRC);\r\nwritel_relaxed(txd->disrcc, phy->base + S3C24XX_DISRCC);\r\nwritel_relaxed(dsg->dst_addr, phy->base + S3C24XX_DIDST);\r\nwritel_relaxed(txd->didstc, phy->base + S3C24XX_DIDSTC);\r\nwritel_relaxed(dcon, phy->base + S3C24XX_DCON);\r\nval = readl_relaxed(phy->base + S3C24XX_DMASKTRIG);\r\nval &= ~S3C24XX_DMASKTRIG_STOP;\r\nval |= S3C24XX_DMASKTRIG_ON;\r\nif (!s3cchan->slave)\r\nval |= S3C24XX_DMASKTRIG_SWTRIG;\r\nwritel(val, phy->base + S3C24XX_DMASKTRIG);\r\n}\r\nstatic void s3c24xx_dma_start_next_txd(struct s3c24xx_dma_chan *s3cchan)\r\n{\r\nstruct s3c24xx_dma_phy *phy = s3cchan->phy;\r\nstruct virt_dma_desc *vd = vchan_next_desc(&s3cchan->vc);\r\nstruct s3c24xx_txd *txd = to_s3c24xx_txd(&vd->tx);\r\nlist_del(&txd->vd.node);\r\ns3cchan->at = txd;\r\nwhile (s3c24xx_dma_phy_busy(phy))\r\ncpu_relax();\r\ntxd->at = txd->dsg_list.next;\r\ns3c24xx_dma_start_next_sg(s3cchan, txd);\r\n}\r\nstatic void s3c24xx_dma_free_txd_list(struct s3c24xx_dma_engine *s3cdma,\r\nstruct s3c24xx_dma_chan *s3cchan)\r\n{\r\nLIST_HEAD(head);\r\nvchan_get_all_descriptors(&s3cchan->vc, &head);\r\nvchan_dma_desc_free_list(&s3cchan->vc, &head);\r\n}\r\nstatic void s3c24xx_dma_phy_alloc_and_start(struct s3c24xx_dma_chan *s3cchan)\r\n{\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nstruct s3c24xx_dma_phy *phy;\r\nphy = s3c24xx_dma_get_phy(s3cchan);\r\nif (!phy) {\r\ndev_dbg(&s3cdma->pdev->dev, "no physical channel available for xfer on %s\n",\r\ns3cchan->name);\r\ns3cchan->state = S3C24XX_DMA_CHAN_WAITING;\r\nreturn;\r\n}\r\ndev_dbg(&s3cdma->pdev->dev, "allocated physical channel %d for xfer on %s\n",\r\nphy->id, s3cchan->name);\r\ns3cchan->phy = phy;\r\ns3cchan->state = S3C24XX_DMA_CHAN_RUNNING;\r\ns3c24xx_dma_start_next_txd(s3cchan);\r\n}\r\nstatic void s3c24xx_dma_phy_reassign_start(struct s3c24xx_dma_phy *phy,\r\nstruct s3c24xx_dma_chan *s3cchan)\r\n{\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\ndev_dbg(&s3cdma->pdev->dev, "reassigned physical channel %d for xfer on %s\n",\r\nphy->id, s3cchan->name);\r\nphy->serving = s3cchan;\r\ns3cchan->phy = phy;\r\ns3cchan->state = S3C24XX_DMA_CHAN_RUNNING;\r\ns3c24xx_dma_start_next_txd(s3cchan);\r\n}\r\nstatic void s3c24xx_dma_phy_free(struct s3c24xx_dma_chan *s3cchan)\r\n{\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nstruct s3c24xx_dma_chan *p, *next;\r\nretry:\r\nnext = NULL;\r\nlist_for_each_entry(p, &s3cdma->memcpy.channels, vc.chan.device_node)\r\nif (p->state == S3C24XX_DMA_CHAN_WAITING) {\r\nnext = p;\r\nbreak;\r\n}\r\nif (!next) {\r\nlist_for_each_entry(p, &s3cdma->slave.channels,\r\nvc.chan.device_node)\r\nif (p->state == S3C24XX_DMA_CHAN_WAITING &&\r\ns3c24xx_dma_phy_valid(p, s3cchan->phy)) {\r\nnext = p;\r\nbreak;\r\n}\r\n}\r\ns3c24xx_dma_terminate_phy(s3cchan->phy);\r\nif (next) {\r\nbool success;\r\nspin_lock(&next->vc.lock);\r\nsuccess = next->state == S3C24XX_DMA_CHAN_WAITING;\r\nif (success)\r\ns3c24xx_dma_phy_reassign_start(s3cchan->phy, next);\r\nspin_unlock(&next->vc.lock);\r\nif (!success)\r\ngoto retry;\r\n} else {\r\ns3c24xx_dma_put_phy(s3cchan->phy);\r\n}\r\ns3cchan->phy = NULL;\r\ns3cchan->state = S3C24XX_DMA_CHAN_IDLE;\r\n}\r\nstatic void s3c24xx_dma_desc_free(struct virt_dma_desc *vd)\r\n{\r\nstruct s3c24xx_txd *txd = to_s3c24xx_txd(&vd->tx);\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(vd->tx.chan);\r\nif (!s3cchan->slave)\r\ndma_descriptor_unmap(&vd->tx);\r\ns3c24xx_dma_free_txd(txd);\r\n}\r\nstatic irqreturn_t s3c24xx_dma_irq(int irq, void *data)\r\n{\r\nstruct s3c24xx_dma_phy *phy = data;\r\nstruct s3c24xx_dma_chan *s3cchan = phy->serving;\r\nstruct s3c24xx_txd *txd;\r\ndev_dbg(&phy->host->pdev->dev, "interrupt on channel %d\n", phy->id);\r\nif (unlikely(!s3cchan)) {\r\ndev_err(&phy->host->pdev->dev, "interrupt on unused channel %d\n",\r\nphy->id);\r\ns3c24xx_dma_terminate_phy(phy);\r\nreturn IRQ_HANDLED;\r\n}\r\nspin_lock(&s3cchan->vc.lock);\r\ntxd = s3cchan->at;\r\nif (txd) {\r\nif (!list_is_last(txd->at, &txd->dsg_list)) {\r\ntxd->at = txd->at->next;\r\nif (txd->cyclic)\r\nvchan_cyclic_callback(&txd->vd);\r\ns3c24xx_dma_start_next_sg(s3cchan, txd);\r\n} else if (!txd->cyclic) {\r\ns3cchan->at = NULL;\r\nvchan_cookie_complete(&txd->vd);\r\nif (vchan_next_desc(&s3cchan->vc))\r\ns3c24xx_dma_start_next_txd(s3cchan);\r\nelse\r\ns3c24xx_dma_phy_free(s3cchan);\r\n} else {\r\nvchan_cyclic_callback(&txd->vd);\r\ntxd->at = txd->dsg_list.next;\r\ns3c24xx_dma_start_next_sg(s3cchan, txd);\r\n}\r\n}\r\nspin_unlock(&s3cchan->vc.lock);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int s3c24xx_dma_terminate_all(struct dma_chan *chan)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(chan);\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nunsigned long flags;\r\nint ret = 0;\r\nspin_lock_irqsave(&s3cchan->vc.lock, flags);\r\nif (!s3cchan->phy && !s3cchan->at) {\r\ndev_err(&s3cdma->pdev->dev, "trying to terminate already stopped channel %d\n",\r\ns3cchan->id);\r\nret = -EINVAL;\r\ngoto unlock;\r\n}\r\ns3cchan->state = S3C24XX_DMA_CHAN_IDLE;\r\nif (s3cchan->phy)\r\ns3c24xx_dma_phy_free(s3cchan);\r\nif (s3cchan->at) {\r\ns3c24xx_dma_desc_free(&s3cchan->at->vd);\r\ns3cchan->at = NULL;\r\n}\r\ns3c24xx_dma_free_txd_list(s3cdma, s3cchan);\r\nunlock:\r\nspin_unlock_irqrestore(&s3cchan->vc.lock, flags);\r\nreturn ret;\r\n}\r\nstatic void s3c24xx_dma_free_chan_resources(struct dma_chan *chan)\r\n{\r\nvchan_free_chan_resources(to_virt_chan(chan));\r\n}\r\nstatic enum dma_status s3c24xx_dma_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie, struct dma_tx_state *txstate)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(chan);\r\nstruct s3c24xx_txd *txd;\r\nstruct s3c24xx_sg *dsg;\r\nstruct virt_dma_desc *vd;\r\nunsigned long flags;\r\nenum dma_status ret;\r\nsize_t bytes = 0;\r\nspin_lock_irqsave(&s3cchan->vc.lock, flags);\r\nret = dma_cookie_status(chan, cookie, txstate);\r\nif (ret == DMA_COMPLETE || !txstate) {\r\nspin_unlock_irqrestore(&s3cchan->vc.lock, flags);\r\nreturn ret;\r\n}\r\nvd = vchan_find_desc(&s3cchan->vc, cookie);\r\nif (vd) {\r\ntxd = to_s3c24xx_txd(&vd->tx);\r\nlist_for_each_entry(dsg, &txd->dsg_list, node)\r\nbytes += dsg->len;\r\n} else {\r\ntxd = s3cchan->at;\r\ndsg = list_entry(txd->at, struct s3c24xx_sg, node);\r\nlist_for_each_entry_from(dsg, &txd->dsg_list, node)\r\nbytes += dsg->len;\r\nbytes += s3c24xx_dma_getbytes_chan(s3cchan);\r\n}\r\nspin_unlock_irqrestore(&s3cchan->vc.lock, flags);\r\ndma_set_residue(txstate, bytes);\r\nreturn ret;\r\n}\r\nstatic struct dma_async_tx_descriptor *s3c24xx_dma_prep_memcpy(\r\nstruct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\r\nsize_t len, unsigned long flags)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(chan);\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nstruct s3c24xx_txd *txd;\r\nstruct s3c24xx_sg *dsg;\r\nint src_mod, dest_mod;\r\ndev_dbg(&s3cdma->pdev->dev, "prepare memcpy of %zu bytes from %s\n",\r\nlen, s3cchan->name);\r\nif ((len & S3C24XX_DCON_TC_MASK) != len) {\r\ndev_err(&s3cdma->pdev->dev, "memcpy size %zu to large\n", len);\r\nreturn NULL;\r\n}\r\ntxd = s3c24xx_dma_get_txd();\r\nif (!txd)\r\nreturn NULL;\r\ndsg = kzalloc(sizeof(*dsg), GFP_NOWAIT);\r\nif (!dsg) {\r\ns3c24xx_dma_free_txd(txd);\r\nreturn NULL;\r\n}\r\nlist_add_tail(&dsg->node, &txd->dsg_list);\r\ndsg->src_addr = src;\r\ndsg->dst_addr = dest;\r\ndsg->len = len;\r\nsrc_mod = src % 4;\r\ndest_mod = dest % 4;\r\nswitch (len % 4) {\r\ncase 0:\r\ntxd->width = (src_mod == 0 && dest_mod == 0) ? 4 : 1;\r\nbreak;\r\ncase 2:\r\ntxd->width = ((src_mod == 2 || src_mod == 0) &&\r\n(dest_mod == 2 || dest_mod == 0)) ? 2 : 1;\r\nbreak;\r\ndefault:\r\ntxd->width = 1;\r\nbreak;\r\n}\r\ntxd->disrcc = S3C24XX_DISRCC_LOC_AHB | S3C24XX_DISRCC_INC_INCREMENT;\r\ntxd->didstc = S3C24XX_DIDSTC_LOC_AHB | S3C24XX_DIDSTC_INC_INCREMENT;\r\ntxd->dcon |= S3C24XX_DCON_DEMAND | S3C24XX_DCON_SYNC_HCLK |\r\nS3C24XX_DCON_SERV_WHOLE;\r\nreturn vchan_tx_prep(&s3cchan->vc, &txd->vd, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *s3c24xx_dma_prep_dma_cyclic(\r\nstruct dma_chan *chan, dma_addr_t addr, size_t size, size_t period,\r\nenum dma_transfer_direction direction, unsigned long flags)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(chan);\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nconst struct s3c24xx_dma_platdata *pdata = s3cdma->pdata;\r\nstruct s3c24xx_dma_channel *cdata = &pdata->channels[s3cchan->id];\r\nstruct s3c24xx_txd *txd;\r\nstruct s3c24xx_sg *dsg;\r\nunsigned sg_len;\r\ndma_addr_t slave_addr;\r\nu32 hwcfg = 0;\r\nint i;\r\ndev_dbg(&s3cdma->pdev->dev,\r\n"prepare cyclic transaction of %zu bytes with period %zu from %s\n",\r\nsize, period, s3cchan->name);\r\nif (!is_slave_direction(direction)) {\r\ndev_err(&s3cdma->pdev->dev,\r\n"direction %d unsupported\n", direction);\r\nreturn NULL;\r\n}\r\ntxd = s3c24xx_dma_get_txd();\r\nif (!txd)\r\nreturn NULL;\r\ntxd->cyclic = 1;\r\nif (cdata->handshake)\r\ntxd->dcon |= S3C24XX_DCON_HANDSHAKE;\r\nswitch (cdata->bus) {\r\ncase S3C24XX_DMA_APB:\r\ntxd->dcon |= S3C24XX_DCON_SYNC_PCLK;\r\nhwcfg |= S3C24XX_DISRCC_LOC_APB;\r\nbreak;\r\ncase S3C24XX_DMA_AHB:\r\ntxd->dcon |= S3C24XX_DCON_SYNC_HCLK;\r\nhwcfg |= S3C24XX_DISRCC_LOC_AHB;\r\nbreak;\r\n}\r\nhwcfg |= S3C24XX_DISRCC_INC_FIXED;\r\ntxd->dcon |= S3C24XX_DCON_SERV_SINGLE;\r\nif (direction == DMA_MEM_TO_DEV) {\r\ntxd->disrcc = S3C24XX_DISRCC_LOC_AHB |\r\nS3C24XX_DISRCC_INC_INCREMENT;\r\ntxd->didstc = hwcfg;\r\nslave_addr = s3cchan->cfg.dst_addr;\r\ntxd->width = s3cchan->cfg.dst_addr_width;\r\n} else {\r\ntxd->disrcc = hwcfg;\r\ntxd->didstc = S3C24XX_DIDSTC_LOC_AHB |\r\nS3C24XX_DIDSTC_INC_INCREMENT;\r\nslave_addr = s3cchan->cfg.src_addr;\r\ntxd->width = s3cchan->cfg.src_addr_width;\r\n}\r\nsg_len = size / period;\r\nfor (i = 0; i < sg_len; i++) {\r\ndsg = kzalloc(sizeof(*dsg), GFP_NOWAIT);\r\nif (!dsg) {\r\ns3c24xx_dma_free_txd(txd);\r\nreturn NULL;\r\n}\r\nlist_add_tail(&dsg->node, &txd->dsg_list);\r\ndsg->len = period;\r\nif (i == sg_len - 1)\r\ndsg->len = size - period * i;\r\nif (direction == DMA_MEM_TO_DEV) {\r\ndsg->src_addr = addr + period * i;\r\ndsg->dst_addr = slave_addr;\r\n} else {\r\ndsg->src_addr = slave_addr;\r\ndsg->dst_addr = addr + period * i;\r\n}\r\n}\r\nreturn vchan_tx_prep(&s3cchan->vc, &txd->vd, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *s3c24xx_dma_prep_slave_sg(\r\nstruct dma_chan *chan, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(chan);\r\nstruct s3c24xx_dma_engine *s3cdma = s3cchan->host;\r\nconst struct s3c24xx_dma_platdata *pdata = s3cdma->pdata;\r\nstruct s3c24xx_dma_channel *cdata = &pdata->channels[s3cchan->id];\r\nstruct s3c24xx_txd *txd;\r\nstruct s3c24xx_sg *dsg;\r\nstruct scatterlist *sg;\r\ndma_addr_t slave_addr;\r\nu32 hwcfg = 0;\r\nint tmp;\r\ndev_dbg(&s3cdma->pdev->dev, "prepare transaction of %d bytes from %s\n",\r\nsg_dma_len(sgl), s3cchan->name);\r\ntxd = s3c24xx_dma_get_txd();\r\nif (!txd)\r\nreturn NULL;\r\nif (cdata->handshake)\r\ntxd->dcon |= S3C24XX_DCON_HANDSHAKE;\r\nswitch (cdata->bus) {\r\ncase S3C24XX_DMA_APB:\r\ntxd->dcon |= S3C24XX_DCON_SYNC_PCLK;\r\nhwcfg |= S3C24XX_DISRCC_LOC_APB;\r\nbreak;\r\ncase S3C24XX_DMA_AHB:\r\ntxd->dcon |= S3C24XX_DCON_SYNC_HCLK;\r\nhwcfg |= S3C24XX_DISRCC_LOC_AHB;\r\nbreak;\r\n}\r\nhwcfg |= S3C24XX_DISRCC_INC_FIXED;\r\ntxd->dcon |= S3C24XX_DCON_SERV_SINGLE;\r\nif (direction == DMA_MEM_TO_DEV) {\r\ntxd->disrcc = S3C24XX_DISRCC_LOC_AHB |\r\nS3C24XX_DISRCC_INC_INCREMENT;\r\ntxd->didstc = hwcfg;\r\nslave_addr = s3cchan->cfg.dst_addr;\r\ntxd->width = s3cchan->cfg.dst_addr_width;\r\n} else if (direction == DMA_DEV_TO_MEM) {\r\ntxd->disrcc = hwcfg;\r\ntxd->didstc = S3C24XX_DIDSTC_LOC_AHB |\r\nS3C24XX_DIDSTC_INC_INCREMENT;\r\nslave_addr = s3cchan->cfg.src_addr;\r\ntxd->width = s3cchan->cfg.src_addr_width;\r\n} else {\r\ns3c24xx_dma_free_txd(txd);\r\ndev_err(&s3cdma->pdev->dev,\r\n"direction %d unsupported\n", direction);\r\nreturn NULL;\r\n}\r\nfor_each_sg(sgl, sg, sg_len, tmp) {\r\ndsg = kzalloc(sizeof(*dsg), GFP_NOWAIT);\r\nif (!dsg) {\r\ns3c24xx_dma_free_txd(txd);\r\nreturn NULL;\r\n}\r\nlist_add_tail(&dsg->node, &txd->dsg_list);\r\ndsg->len = sg_dma_len(sg);\r\nif (direction == DMA_MEM_TO_DEV) {\r\ndsg->src_addr = sg_dma_address(sg);\r\ndsg->dst_addr = slave_addr;\r\n} else {\r\ndsg->src_addr = slave_addr;\r\ndsg->dst_addr = sg_dma_address(sg);\r\n}\r\n}\r\nreturn vchan_tx_prep(&s3cchan->vc, &txd->vd, flags);\r\n}\r\nstatic void s3c24xx_dma_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan = to_s3c24xx_dma_chan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&s3cchan->vc.lock, flags);\r\nif (vchan_issue_pending(&s3cchan->vc)) {\r\nif (!s3cchan->phy && s3cchan->state != S3C24XX_DMA_CHAN_WAITING)\r\ns3c24xx_dma_phy_alloc_and_start(s3cchan);\r\n}\r\nspin_unlock_irqrestore(&s3cchan->vc.lock, flags);\r\n}\r\nstatic int s3c24xx_dma_init_virtual_channels(struct s3c24xx_dma_engine *s3cdma,\r\nstruct dma_device *dmadev, unsigned int channels, bool slave)\r\n{\r\nstruct s3c24xx_dma_chan *chan;\r\nint i;\r\nINIT_LIST_HEAD(&dmadev->channels);\r\nfor (i = 0; i < channels; i++) {\r\nchan = devm_kzalloc(dmadev->dev, sizeof(*chan), GFP_KERNEL);\r\nif (!chan)\r\nreturn -ENOMEM;\r\nchan->id = i;\r\nchan->host = s3cdma;\r\nchan->state = S3C24XX_DMA_CHAN_IDLE;\r\nif (slave) {\r\nchan->slave = true;\r\nchan->name = kasprintf(GFP_KERNEL, "slave%d", i);\r\nif (!chan->name)\r\nreturn -ENOMEM;\r\n} else {\r\nchan->name = kasprintf(GFP_KERNEL, "memcpy%d", i);\r\nif (!chan->name)\r\nreturn -ENOMEM;\r\n}\r\ndev_dbg(dmadev->dev,\r\n"initialize virtual channel \"%s\"\n",\r\nchan->name);\r\nchan->vc.desc_free = s3c24xx_dma_desc_free;\r\nvchan_init(&chan->vc, dmadev);\r\n}\r\ndev_info(dmadev->dev, "initialized %d virtual %s channels\n",\r\ni, slave ? "slave" : "memcpy");\r\nreturn i;\r\n}\r\nstatic void s3c24xx_dma_free_virtual_channels(struct dma_device *dmadev)\r\n{\r\nstruct s3c24xx_dma_chan *chan = NULL;\r\nstruct s3c24xx_dma_chan *next;\r\nlist_for_each_entry_safe(chan,\r\nnext, &dmadev->channels, vc.chan.device_node) {\r\nlist_del(&chan->vc.chan.device_node);\r\ntasklet_kill(&chan->vc.task);\r\n}\r\n}\r\nstatic struct soc_data *s3c24xx_dma_get_soc_data(struct platform_device *pdev)\r\n{\r\nreturn (struct soc_data *)\r\nplatform_get_device_id(pdev)->driver_data;\r\n}\r\nstatic int s3c24xx_dma_probe(struct platform_device *pdev)\r\n{\r\nconst struct s3c24xx_dma_platdata *pdata = dev_get_platdata(&pdev->dev);\r\nstruct s3c24xx_dma_engine *s3cdma;\r\nstruct soc_data *sdata;\r\nstruct resource *res;\r\nint ret;\r\nint i;\r\nif (!pdata) {\r\ndev_err(&pdev->dev, "platform data missing\n");\r\nreturn -ENODEV;\r\n}\r\nif (pdata->num_phy_channels > MAX_DMA_CHANNELS) {\r\ndev_err(&pdev->dev, "to many dma channels %d, max %d\n",\r\npdata->num_phy_channels, MAX_DMA_CHANNELS);\r\nreturn -EINVAL;\r\n}\r\nsdata = s3c24xx_dma_get_soc_data(pdev);\r\nif (!sdata)\r\nreturn -EINVAL;\r\ns3cdma = devm_kzalloc(&pdev->dev, sizeof(*s3cdma), GFP_KERNEL);\r\nif (!s3cdma)\r\nreturn -ENOMEM;\r\ns3cdma->pdev = pdev;\r\ns3cdma->pdata = pdata;\r\ns3cdma->sdata = sdata;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\ns3cdma->base = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(s3cdma->base))\r\nreturn PTR_ERR(s3cdma->base);\r\ns3cdma->phy_chans = devm_kzalloc(&pdev->dev,\r\nsizeof(struct s3c24xx_dma_phy) *\r\npdata->num_phy_channels,\r\nGFP_KERNEL);\r\nif (!s3cdma->phy_chans)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < pdata->num_phy_channels; i++) {\r\nstruct s3c24xx_dma_phy *phy = &s3cdma->phy_chans[i];\r\nchar clk_name[6];\r\nphy->id = i;\r\nphy->base = s3cdma->base + (i * sdata->stride);\r\nphy->host = s3cdma;\r\nphy->irq = platform_get_irq(pdev, i);\r\nif (phy->irq < 0) {\r\ndev_err(&pdev->dev, "failed to get irq %d, err %d\n",\r\ni, phy->irq);\r\ncontinue;\r\n}\r\nret = devm_request_irq(&pdev->dev, phy->irq, s3c24xx_dma_irq,\r\n0, pdev->name, phy);\r\nif (ret) {\r\ndev_err(&pdev->dev, "Unable to request irq for channel %d, error %d\n",\r\ni, ret);\r\ncontinue;\r\n}\r\nif (sdata->has_clocks) {\r\nsprintf(clk_name, "dma.%d", i);\r\nphy->clk = devm_clk_get(&pdev->dev, clk_name);\r\nif (IS_ERR(phy->clk) && sdata->has_clocks) {\r\ndev_err(&pdev->dev, "unable to acquire clock for channel %d, error %lu\n",\r\ni, PTR_ERR(phy->clk));\r\ncontinue;\r\n}\r\nret = clk_prepare(phy->clk);\r\nif (ret) {\r\ndev_err(&pdev->dev, "clock for phy %d failed, error %d\n",\r\ni, ret);\r\ncontinue;\r\n}\r\n}\r\nspin_lock_init(&phy->lock);\r\nphy->valid = true;\r\ndev_dbg(&pdev->dev, "physical channel %d is %s\n",\r\ni, s3c24xx_dma_phy_busy(phy) ? "BUSY" : "FREE");\r\n}\r\ndma_cap_set(DMA_MEMCPY, s3cdma->memcpy.cap_mask);\r\ndma_cap_set(DMA_PRIVATE, s3cdma->memcpy.cap_mask);\r\ns3cdma->memcpy.dev = &pdev->dev;\r\ns3cdma->memcpy.device_free_chan_resources =\r\ns3c24xx_dma_free_chan_resources;\r\ns3cdma->memcpy.device_prep_dma_memcpy = s3c24xx_dma_prep_memcpy;\r\ns3cdma->memcpy.device_tx_status = s3c24xx_dma_tx_status;\r\ns3cdma->memcpy.device_issue_pending = s3c24xx_dma_issue_pending;\r\ns3cdma->memcpy.device_config = s3c24xx_dma_set_runtime_config;\r\ns3cdma->memcpy.device_terminate_all = s3c24xx_dma_terminate_all;\r\ndma_cap_set(DMA_SLAVE, s3cdma->slave.cap_mask);\r\ndma_cap_set(DMA_CYCLIC, s3cdma->slave.cap_mask);\r\ndma_cap_set(DMA_PRIVATE, s3cdma->slave.cap_mask);\r\ns3cdma->slave.dev = &pdev->dev;\r\ns3cdma->slave.device_free_chan_resources =\r\ns3c24xx_dma_free_chan_resources;\r\ns3cdma->slave.device_tx_status = s3c24xx_dma_tx_status;\r\ns3cdma->slave.device_issue_pending = s3c24xx_dma_issue_pending;\r\ns3cdma->slave.device_prep_slave_sg = s3c24xx_dma_prep_slave_sg;\r\ns3cdma->slave.device_prep_dma_cyclic = s3c24xx_dma_prep_dma_cyclic;\r\ns3cdma->slave.device_config = s3c24xx_dma_set_runtime_config;\r\ns3cdma->slave.device_terminate_all = s3c24xx_dma_terminate_all;\r\ns3cdma->slave.filter.map = pdata->slave_map;\r\ns3cdma->slave.filter.mapcnt = pdata->slavecnt;\r\ns3cdma->slave.filter.fn = s3c24xx_dma_filter;\r\nret = s3c24xx_dma_init_virtual_channels(s3cdma, &s3cdma->memcpy,\r\npdata->num_phy_channels, false);\r\nif (ret <= 0) {\r\ndev_warn(&pdev->dev,\r\n"%s failed to enumerate memcpy channels - %d\n",\r\n__func__, ret);\r\ngoto err_memcpy;\r\n}\r\nret = s3c24xx_dma_init_virtual_channels(s3cdma, &s3cdma->slave,\r\npdata->num_channels, true);\r\nif (ret <= 0) {\r\ndev_warn(&pdev->dev,\r\n"%s failed to enumerate slave channels - %d\n",\r\n__func__, ret);\r\ngoto err_slave;\r\n}\r\nret = dma_async_device_register(&s3cdma->memcpy);\r\nif (ret) {\r\ndev_warn(&pdev->dev,\r\n"%s failed to register memcpy as an async device - %d\n",\r\n__func__, ret);\r\ngoto err_memcpy_reg;\r\n}\r\nret = dma_async_device_register(&s3cdma->slave);\r\nif (ret) {\r\ndev_warn(&pdev->dev,\r\n"%s failed to register slave as an async device - %d\n",\r\n__func__, ret);\r\ngoto err_slave_reg;\r\n}\r\nplatform_set_drvdata(pdev, s3cdma);\r\ndev_info(&pdev->dev, "Loaded dma driver with %d physical channels\n",\r\npdata->num_phy_channels);\r\nreturn 0;\r\nerr_slave_reg:\r\ndma_async_device_unregister(&s3cdma->memcpy);\r\nerr_memcpy_reg:\r\ns3c24xx_dma_free_virtual_channels(&s3cdma->slave);\r\nerr_slave:\r\ns3c24xx_dma_free_virtual_channels(&s3cdma->memcpy);\r\nerr_memcpy:\r\nif (sdata->has_clocks)\r\nfor (i = 0; i < pdata->num_phy_channels; i++) {\r\nstruct s3c24xx_dma_phy *phy = &s3cdma->phy_chans[i];\r\nif (phy->valid)\r\nclk_unprepare(phy->clk);\r\n}\r\nreturn ret;\r\n}\r\nstatic void s3c24xx_dma_free_irq(struct platform_device *pdev,\r\nstruct s3c24xx_dma_engine *s3cdma)\r\n{\r\nint i;\r\nfor (i = 0; i < s3cdma->pdata->num_phy_channels; i++) {\r\nstruct s3c24xx_dma_phy *phy = &s3cdma->phy_chans[i];\r\ndevm_free_irq(&pdev->dev, phy->irq, phy);\r\n}\r\n}\r\nstatic int s3c24xx_dma_remove(struct platform_device *pdev)\r\n{\r\nconst struct s3c24xx_dma_platdata *pdata = dev_get_platdata(&pdev->dev);\r\nstruct s3c24xx_dma_engine *s3cdma = platform_get_drvdata(pdev);\r\nstruct soc_data *sdata = s3c24xx_dma_get_soc_data(pdev);\r\nint i;\r\ndma_async_device_unregister(&s3cdma->slave);\r\ndma_async_device_unregister(&s3cdma->memcpy);\r\ns3c24xx_dma_free_irq(pdev, s3cdma);\r\ns3c24xx_dma_free_virtual_channels(&s3cdma->slave);\r\ns3c24xx_dma_free_virtual_channels(&s3cdma->memcpy);\r\nif (sdata->has_clocks)\r\nfor (i = 0; i < pdata->num_phy_channels; i++) {\r\nstruct s3c24xx_dma_phy *phy = &s3cdma->phy_chans[i];\r\nif (phy->valid)\r\nclk_unprepare(phy->clk);\r\n}\r\nreturn 0;\r\n}\r\nbool s3c24xx_dma_filter(struct dma_chan *chan, void *param)\r\n{\r\nstruct s3c24xx_dma_chan *s3cchan;\r\nif (chan->device->dev->driver != &s3c24xx_dma_driver.driver)\r\nreturn false;\r\ns3cchan = to_s3c24xx_dma_chan(chan);\r\nreturn s3cchan->id == (uintptr_t)param;\r\n}
