static inline struct vdc_port *to_vdc_port(struct vio_driver_state *vio)\r\n{\r\nreturn container_of(vio, struct vdc_port, vio);\r\n}\r\nstatic inline int vdc_version_supported(struct vdc_port *port,\r\nu16 major, u16 minor)\r\n{\r\nreturn port->vio.ver.major == major && port->vio.ver.minor >= minor;\r\n}\r\nstatic inline u32 vdc_tx_dring_avail(struct vio_dring_state *dr)\r\n{\r\nreturn vio_dring_avail(dr, VDC_TX_RING_SIZE);\r\n}\r\nstatic int vdc_getgeo(struct block_device *bdev, struct hd_geometry *geo)\r\n{\r\nstruct gendisk *disk = bdev->bd_disk;\r\nsector_t nsect = get_capacity(disk);\r\nsector_t cylinders = nsect;\r\ngeo->heads = 0xff;\r\ngeo->sectors = 0x3f;\r\nsector_div(cylinders, geo->heads * geo->sectors);\r\ngeo->cylinders = cylinders;\r\nif ((sector_t)(geo->cylinders + 1) * geo->heads * geo->sectors < nsect)\r\ngeo->cylinders = 0xffff;\r\nreturn 0;\r\n}\r\nstatic int vdc_ioctl(struct block_device *bdev, fmode_t mode,\r\nunsigned command, unsigned long argument)\r\n{\r\nint i;\r\nstruct gendisk *disk;\r\nswitch (command) {\r\ncase CDROMMULTISESSION:\r\npr_debug(PFX "Multisession CDs not supported\n");\r\nfor (i = 0; i < sizeof(struct cdrom_multisession); i++)\r\nif (put_user(0, (char __user *)(argument + i)))\r\nreturn -EFAULT;\r\nreturn 0;\r\ncase CDROM_GET_CAPABILITY:\r\ndisk = bdev->bd_disk;\r\nif (bdev->bd_disk && (disk->flags & GENHD_FL_CD))\r\nreturn 0;\r\nreturn -EINVAL;\r\ndefault:\r\npr_debug(PFX "ioctl %08x not supported\n", command);\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic void vdc_blk_queue_start(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nif (port->disk && blk_queue_stopped(port->disk->queue) &&\r\nvdc_tx_dring_avail(dr) * 100 / VDC_TX_RING_SIZE >= 50) {\r\nblk_start_queue(port->disk->queue);\r\n}\r\n}\r\nstatic void vdc_finish(struct vio_driver_state *vio, int err, int waiting_for)\r\n{\r\nif (vio->cmp &&\r\n(waiting_for == -1 ||\r\nvio->cmp->waiting_for == waiting_for)) {\r\nvio->cmp->err = err;\r\ncomplete(&vio->cmp->com);\r\nvio->cmp = NULL;\r\n}\r\n}\r\nstatic void vdc_handshake_complete(struct vio_driver_state *vio)\r\n{\r\nstruct vdc_port *port = to_vdc_port(vio);\r\ndel_timer(&port->ldc_reset_timer);\r\nvdc_finish(vio, 0, WAITING_FOR_LINK_UP);\r\nvdc_blk_queue_start(port);\r\n}\r\nstatic int vdc_handle_unknown(struct vdc_port *port, void *arg)\r\n{\r\nstruct vio_msg_tag *pkt = arg;\r\nprintk(KERN_ERR PFX "Received unknown msg [%02x:%02x:%04x:%08x]\n",\r\npkt->type, pkt->stype, pkt->stype_env, pkt->sid);\r\nprintk(KERN_ERR PFX "Resetting connection.\n");\r\nldc_disconnect(port->vio.lp);\r\nreturn -ECONNRESET;\r\n}\r\nstatic int vdc_send_attr(struct vio_driver_state *vio)\r\n{\r\nstruct vdc_port *port = to_vdc_port(vio);\r\nstruct vio_disk_attr_info pkt;\r\nmemset(&pkt, 0, sizeof(pkt));\r\npkt.tag.type = VIO_TYPE_CTRL;\r\npkt.tag.stype = VIO_SUBTYPE_INFO;\r\npkt.tag.stype_env = VIO_ATTR_INFO;\r\npkt.tag.sid = vio_send_sid(vio);\r\npkt.xfer_mode = VIO_DRING_MODE;\r\npkt.vdisk_block_size = port->vdisk_block_size;\r\npkt.max_xfer_size = port->max_xfer_size;\r\nviodbg(HS, "SEND ATTR xfer_mode[0x%x] blksz[%u] max_xfer[%llu]\n",\r\npkt.xfer_mode, pkt.vdisk_block_size, pkt.max_xfer_size);\r\nreturn vio_ldc_send(&port->vio, &pkt, sizeof(pkt));\r\n}\r\nstatic int vdc_handle_attr(struct vio_driver_state *vio, void *arg)\r\n{\r\nstruct vdc_port *port = to_vdc_port(vio);\r\nstruct vio_disk_attr_info *pkt = arg;\r\nviodbg(HS, "GOT ATTR stype[0x%x] ops[%llx] disk_size[%llu] disk_type[%x] "\r\n"mtype[0x%x] xfer_mode[0x%x] blksz[%u] max_xfer[%llu]\n",\r\npkt->tag.stype, pkt->operations,\r\npkt->vdisk_size, pkt->vdisk_type, pkt->vdisk_mtype,\r\npkt->xfer_mode, pkt->vdisk_block_size,\r\npkt->max_xfer_size);\r\nif (pkt->tag.stype == VIO_SUBTYPE_ACK) {\r\nswitch (pkt->vdisk_type) {\r\ncase VD_DISK_TYPE_DISK:\r\ncase VD_DISK_TYPE_SLICE:\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR PFX "%s: Bogus vdisk_type 0x%x\n",\r\nvio->name, pkt->vdisk_type);\r\nreturn -ECONNRESET;\r\n}\r\nif (pkt->vdisk_block_size > port->vdisk_block_size) {\r\nprintk(KERN_ERR PFX "%s: BLOCK size increased "\r\n"%u --> %u\n",\r\nvio->name,\r\nport->vdisk_block_size, pkt->vdisk_block_size);\r\nreturn -ECONNRESET;\r\n}\r\nport->operations = pkt->operations;\r\nport->vdisk_type = pkt->vdisk_type;\r\nif (vdc_version_supported(port, 1, 1)) {\r\nport->vdisk_size = pkt->vdisk_size;\r\nport->vdisk_mtype = pkt->vdisk_mtype;\r\n}\r\nif (pkt->max_xfer_size < port->max_xfer_size)\r\nport->max_xfer_size = pkt->max_xfer_size;\r\nport->vdisk_block_size = pkt->vdisk_block_size;\r\nport->vdisk_phys_blksz = VDC_DEFAULT_BLK_SIZE;\r\nif (vdc_version_supported(port, 1, 2))\r\nport->vdisk_phys_blksz = pkt->phys_block_size;\r\nreturn 0;\r\n} else {\r\nprintk(KERN_ERR PFX "%s: Attribute NACK\n", vio->name);\r\nreturn -ECONNRESET;\r\n}\r\n}\r\nstatic void vdc_end_special(struct vdc_port *port, struct vio_disk_desc *desc)\r\n{\r\nint err = desc->status;\r\nvdc_finish(&port->vio, -err, WAITING_FOR_GEN_CMD);\r\n}\r\nstatic void vdc_end_one(struct vdc_port *port, struct vio_dring_state *dr,\r\nunsigned int index)\r\n{\r\nstruct vio_disk_desc *desc = vio_dring_entry(dr, index);\r\nstruct vdc_req_entry *rqe = &port->rq_arr[index];\r\nstruct request *req;\r\nif (unlikely(desc->hdr.state != VIO_DESC_DONE))\r\nreturn;\r\nldc_unmap(port->vio.lp, desc->cookies, desc->ncookies);\r\ndesc->hdr.state = VIO_DESC_FREE;\r\ndr->cons = vio_dring_next(dr, index);\r\nreq = rqe->req;\r\nif (req == NULL) {\r\nvdc_end_special(port, desc);\r\nreturn;\r\n}\r\nrqe->req = NULL;\r\n__blk_end_request(req, (desc->status ? BLK_STS_IOERR : 0), desc->size);\r\nvdc_blk_queue_start(port);\r\n}\r\nstatic int vdc_ack(struct vdc_port *port, void *msgbuf)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nstruct vio_dring_data *pkt = msgbuf;\r\nif (unlikely(pkt->dring_ident != dr->ident ||\r\npkt->start_idx != pkt->end_idx ||\r\npkt->start_idx >= VDC_TX_RING_SIZE))\r\nreturn 0;\r\nvdc_end_one(port, dr, pkt->start_idx);\r\nreturn 0;\r\n}\r\nstatic int vdc_nack(struct vdc_port *port, void *msgbuf)\r\n{\r\nreturn 0;\r\n}\r\nstatic void vdc_event(void *arg, int event)\r\n{\r\nstruct vdc_port *port = arg;\r\nstruct vio_driver_state *vio = &port->vio;\r\nunsigned long flags;\r\nint err;\r\nspin_lock_irqsave(&vio->lock, flags);\r\nif (unlikely(event == LDC_EVENT_RESET)) {\r\nvio_link_state_change(vio, event);\r\nqueue_work(sunvdc_wq, &port->ldc_reset_work);\r\ngoto out;\r\n}\r\nif (unlikely(event == LDC_EVENT_UP)) {\r\nvio_link_state_change(vio, event);\r\ngoto out;\r\n}\r\nif (unlikely(event != LDC_EVENT_DATA_READY)) {\r\npr_warn(PFX "Unexpected LDC event %d\n", event);\r\ngoto out;\r\n}\r\nerr = 0;\r\nwhile (1) {\r\nunion {\r\nstruct vio_msg_tag tag;\r\nu64 raw[8];\r\n} msgbuf;\r\nerr = ldc_read(vio->lp, &msgbuf, sizeof(msgbuf));\r\nif (unlikely(err < 0)) {\r\nif (err == -ECONNRESET)\r\nvio_conn_reset(vio);\r\nbreak;\r\n}\r\nif (err == 0)\r\nbreak;\r\nviodbg(DATA, "TAG [%02x:%02x:%04x:%08x]\n",\r\nmsgbuf.tag.type,\r\nmsgbuf.tag.stype,\r\nmsgbuf.tag.stype_env,\r\nmsgbuf.tag.sid);\r\nerr = vio_validate_sid(vio, &msgbuf.tag);\r\nif (err < 0)\r\nbreak;\r\nif (likely(msgbuf.tag.type == VIO_TYPE_DATA)) {\r\nif (msgbuf.tag.stype == VIO_SUBTYPE_ACK)\r\nerr = vdc_ack(port, &msgbuf);\r\nelse if (msgbuf.tag.stype == VIO_SUBTYPE_NACK)\r\nerr = vdc_nack(port, &msgbuf);\r\nelse\r\nerr = vdc_handle_unknown(port, &msgbuf);\r\n} else if (msgbuf.tag.type == VIO_TYPE_CTRL) {\r\nerr = vio_control_pkt_engine(vio, &msgbuf);\r\n} else {\r\nerr = vdc_handle_unknown(port, &msgbuf);\r\n}\r\nif (err < 0)\r\nbreak;\r\n}\r\nif (err < 0)\r\nvdc_finish(&port->vio, err, WAITING_FOR_ANY);\r\nout:\r\nspin_unlock_irqrestore(&vio->lock, flags);\r\n}\r\nstatic int __vdc_tx_trigger(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nstruct vio_dring_data hdr = {\r\n.tag = {\r\n.type = VIO_TYPE_DATA,\r\n.stype = VIO_SUBTYPE_INFO,\r\n.stype_env = VIO_DRING_DATA,\r\n.sid = vio_send_sid(&port->vio),\r\n},\r\n.dring_ident = dr->ident,\r\n.start_idx = dr->prod,\r\n.end_idx = dr->prod,\r\n};\r\nint err, delay;\r\nhdr.seq = dr->snd_nxt;\r\ndelay = 1;\r\ndo {\r\nerr = vio_ldc_send(&port->vio, &hdr, sizeof(hdr));\r\nif (err > 0) {\r\ndr->snd_nxt++;\r\nbreak;\r\n}\r\nudelay(delay);\r\nif ((delay <<= 1) > 128)\r\ndelay = 128;\r\n} while (err == -EAGAIN);\r\nif (err == -ENOTCONN)\r\nvdc_ldc_reset(port);\r\nreturn err;\r\n}\r\nstatic int __send_request(struct request *req)\r\n{\r\nstruct vdc_port *port = req->rq_disk->private_data;\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nstruct scatterlist sg[port->ring_cookies];\r\nstruct vdc_req_entry *rqe;\r\nstruct vio_disk_desc *desc;\r\nunsigned int map_perm;\r\nint nsg, err, i;\r\nu64 len;\r\nu8 op;\r\nmap_perm = LDC_MAP_SHADOW | LDC_MAP_DIRECT | LDC_MAP_IO;\r\nif (rq_data_dir(req) == READ) {\r\nmap_perm |= LDC_MAP_W;\r\nop = VD_OP_BREAD;\r\n} else {\r\nmap_perm |= LDC_MAP_R;\r\nop = VD_OP_BWRITE;\r\n}\r\nsg_init_table(sg, port->ring_cookies);\r\nnsg = blk_rq_map_sg(req->q, req, sg);\r\nlen = 0;\r\nfor (i = 0; i < nsg; i++)\r\nlen += sg[i].length;\r\ndesc = vio_dring_cur(dr);\r\nerr = ldc_map_sg(port->vio.lp, sg, nsg,\r\ndesc->cookies, port->ring_cookies,\r\nmap_perm);\r\nif (err < 0) {\r\nprintk(KERN_ERR PFX "ldc_map_sg() failure, err=%d.\n", err);\r\nreturn err;\r\n}\r\nrqe = &port->rq_arr[dr->prod];\r\nrqe->req = req;\r\ndesc->hdr.ack = VIO_ACK_ENABLE;\r\ndesc->req_id = port->req_id;\r\ndesc->operation = op;\r\nif (port->vdisk_type == VD_DISK_TYPE_DISK) {\r\ndesc->slice = 0xff;\r\n} else {\r\ndesc->slice = 0;\r\n}\r\ndesc->status = ~0;\r\ndesc->offset = (blk_rq_pos(req) << 9) / port->vdisk_block_size;\r\ndesc->size = len;\r\ndesc->ncookies = err;\r\nwmb();\r\ndesc->hdr.state = VIO_DESC_READY;\r\nerr = __vdc_tx_trigger(port);\r\nif (err < 0) {\r\nprintk(KERN_ERR PFX "vdc_tx_trigger() failure, err=%d\n", err);\r\n} else {\r\nport->req_id++;\r\ndr->prod = vio_dring_next(dr, dr->prod);\r\n}\r\nreturn err;\r\n}\r\nstatic void do_vdc_request(struct request_queue *rq)\r\n{\r\nstruct request *req;\r\nwhile ((req = blk_peek_request(rq)) != NULL) {\r\nstruct vdc_port *port;\r\nstruct vio_dring_state *dr;\r\nport = req->rq_disk->private_data;\r\ndr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nif (unlikely(vdc_tx_dring_avail(dr) < 1))\r\ngoto wait;\r\nblk_start_request(req);\r\nif (__send_request(req) < 0) {\r\nblk_requeue_request(rq, req);\r\nwait:\r\nblk_stop_queue(rq);\r\nbreak;\r\n}\r\n}\r\n}\r\nstatic int generic_request(struct vdc_port *port, u8 op, void *buf, int len)\r\n{\r\nstruct vio_dring_state *dr;\r\nstruct vio_completion comp;\r\nstruct vio_disk_desc *desc;\r\nunsigned int map_perm;\r\nunsigned long flags;\r\nint op_len, err;\r\nvoid *req_buf;\r\nif (!(((u64)1 << (u64)op) & port->operations))\r\nreturn -EOPNOTSUPP;\r\nswitch (op) {\r\ncase VD_OP_BREAD:\r\ncase VD_OP_BWRITE:\r\ndefault:\r\nreturn -EINVAL;\r\ncase VD_OP_FLUSH:\r\nop_len = 0;\r\nmap_perm = 0;\r\nbreak;\r\ncase VD_OP_GET_WCE:\r\nop_len = sizeof(u32);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_SET_WCE:\r\nop_len = sizeof(u32);\r\nmap_perm = LDC_MAP_R;\r\nbreak;\r\ncase VD_OP_GET_VTOC:\r\nop_len = sizeof(struct vio_disk_vtoc);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_SET_VTOC:\r\nop_len = sizeof(struct vio_disk_vtoc);\r\nmap_perm = LDC_MAP_R;\r\nbreak;\r\ncase VD_OP_GET_DISKGEOM:\r\nop_len = sizeof(struct vio_disk_geom);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_SET_DISKGEOM:\r\nop_len = sizeof(struct vio_disk_geom);\r\nmap_perm = LDC_MAP_R;\r\nbreak;\r\ncase VD_OP_SCSICMD:\r\nop_len = 16;\r\nmap_perm = LDC_MAP_RW;\r\nbreak;\r\ncase VD_OP_GET_DEVID:\r\nop_len = sizeof(struct vio_disk_devid);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_GET_EFI:\r\ncase VD_OP_SET_EFI:\r\nreturn -EOPNOTSUPP;\r\nbreak;\r\n};\r\nmap_perm |= LDC_MAP_SHADOW | LDC_MAP_DIRECT | LDC_MAP_IO;\r\nop_len = (op_len + 7) & ~7;\r\nreq_buf = kzalloc(op_len, GFP_KERNEL);\r\nif (!req_buf)\r\nreturn -ENOMEM;\r\nif (len > op_len)\r\nlen = op_len;\r\nif (map_perm & LDC_MAP_R)\r\nmemcpy(req_buf, buf, len);\r\nspin_lock_irqsave(&port->vio.lock, flags);\r\ndr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\ndesc = vio_dring_cur(dr);\r\nerr = ldc_map_single(port->vio.lp, req_buf, op_len,\r\ndesc->cookies, port->ring_cookies,\r\nmap_perm);\r\nif (err < 0) {\r\nspin_unlock_irqrestore(&port->vio.lock, flags);\r\nkfree(req_buf);\r\nreturn err;\r\n}\r\ninit_completion(&comp.com);\r\ncomp.waiting_for = WAITING_FOR_GEN_CMD;\r\nport->vio.cmp = &comp;\r\ndesc->hdr.ack = VIO_ACK_ENABLE;\r\ndesc->req_id = port->req_id;\r\ndesc->operation = op;\r\ndesc->slice = 0;\r\ndesc->status = ~0;\r\ndesc->offset = 0;\r\ndesc->size = op_len;\r\ndesc->ncookies = err;\r\nwmb();\r\ndesc->hdr.state = VIO_DESC_READY;\r\nerr = __vdc_tx_trigger(port);\r\nif (err >= 0) {\r\nport->req_id++;\r\ndr->prod = vio_dring_next(dr, dr->prod);\r\nspin_unlock_irqrestore(&port->vio.lock, flags);\r\nwait_for_completion(&comp.com);\r\nerr = comp.err;\r\n} else {\r\nport->vio.cmp = NULL;\r\nspin_unlock_irqrestore(&port->vio.lock, flags);\r\n}\r\nif (map_perm & LDC_MAP_W)\r\nmemcpy(buf, req_buf, len);\r\nkfree(req_buf);\r\nreturn err;\r\n}\r\nstatic int vdc_alloc_tx_ring(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nunsigned long len, entry_size;\r\nint ncookies;\r\nvoid *dring;\r\nentry_size = sizeof(struct vio_disk_desc) +\r\n(sizeof(struct ldc_trans_cookie) * port->ring_cookies);\r\nlen = (VDC_TX_RING_SIZE * entry_size);\r\nncookies = VIO_MAX_RING_COOKIES;\r\ndring = ldc_alloc_exp_dring(port->vio.lp, len,\r\ndr->cookies, &ncookies,\r\n(LDC_MAP_SHADOW |\r\nLDC_MAP_DIRECT |\r\nLDC_MAP_RW));\r\nif (IS_ERR(dring))\r\nreturn PTR_ERR(dring);\r\ndr->base = dring;\r\ndr->entry_size = entry_size;\r\ndr->num_entries = VDC_TX_RING_SIZE;\r\ndr->prod = dr->cons = 0;\r\ndr->pending = VDC_TX_RING_SIZE;\r\ndr->ncookies = ncookies;\r\nreturn 0;\r\n}\r\nstatic void vdc_free_tx_ring(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nif (dr->base) {\r\nldc_free_exp_dring(port->vio.lp, dr->base,\r\n(dr->entry_size * dr->num_entries),\r\ndr->cookies, dr->ncookies);\r\ndr->base = NULL;\r\ndr->entry_size = 0;\r\ndr->num_entries = 0;\r\ndr->pending = 0;\r\ndr->ncookies = 0;\r\n}\r\n}\r\nstatic int vdc_port_up(struct vdc_port *port)\r\n{\r\nstruct vio_completion comp;\r\ninit_completion(&comp.com);\r\ncomp.err = 0;\r\ncomp.waiting_for = WAITING_FOR_LINK_UP;\r\nport->vio.cmp = &comp;\r\nvio_port_up(&port->vio);\r\nwait_for_completion(&comp.com);\r\nreturn comp.err;\r\n}\r\nstatic void vdc_port_down(struct vdc_port *port)\r\n{\r\nldc_disconnect(port->vio.lp);\r\nldc_unbind(port->vio.lp);\r\nvdc_free_tx_ring(port);\r\nvio_ldc_free(&port->vio);\r\n}\r\nstatic int probe_disk(struct vdc_port *port)\r\n{\r\nstruct request_queue *q;\r\nstruct gendisk *g;\r\nint err;\r\nerr = vdc_port_up(port);\r\nif (err)\r\nreturn err;\r\nif (vdc_version_supported(port, 1, 2) && !port->vdisk_phys_blksz)\r\nreturn -ENODEV;\r\nif (vdc_version_supported(port, 1, 1)) {\r\nif (port->vdisk_size == -1)\r\nreturn -ENODEV;\r\n} else {\r\nstruct vio_disk_geom geom;\r\nerr = generic_request(port, VD_OP_GET_DISKGEOM,\r\n&geom, sizeof(geom));\r\nif (err < 0) {\r\nprintk(KERN_ERR PFX "VD_OP_GET_DISKGEOM returns "\r\n"error %d\n", err);\r\nreturn err;\r\n}\r\nport->vdisk_size = ((u64)geom.num_cyl *\r\n(u64)geom.num_hd *\r\n(u64)geom.num_sec);\r\n}\r\nq = blk_init_queue(do_vdc_request, &port->vio.lock);\r\nif (!q) {\r\nprintk(KERN_ERR PFX "%s: Could not allocate queue.\n",\r\nport->vio.name);\r\nreturn -ENOMEM;\r\n}\r\ng = alloc_disk(1 << PARTITION_SHIFT);\r\nif (!g) {\r\nprintk(KERN_ERR PFX "%s: Could not allocate gendisk.\n",\r\nport->vio.name);\r\nblk_cleanup_queue(q);\r\nreturn -ENOMEM;\r\n}\r\nport->disk = g;\r\nblk_queue_segment_boundary(q, PAGE_SIZE - 1);\r\nblk_queue_max_segment_size(q, PAGE_SIZE);\r\nblk_queue_max_segments(q, port->ring_cookies);\r\nblk_queue_max_hw_sectors(q, port->max_xfer_size);\r\ng->major = vdc_major;\r\ng->first_minor = port->vio.vdev->dev_no << PARTITION_SHIFT;\r\nstrcpy(g->disk_name, port->disk_name);\r\ng->fops = &vdc_fops;\r\ng->queue = q;\r\ng->private_data = port;\r\nset_capacity(g, port->vdisk_size);\r\nif (vdc_version_supported(port, 1, 1)) {\r\nswitch (port->vdisk_mtype) {\r\ncase VD_MEDIA_TYPE_CD:\r\npr_info(PFX "Virtual CDROM %s\n", port->disk_name);\r\ng->flags |= GENHD_FL_CD;\r\ng->flags |= GENHD_FL_REMOVABLE;\r\nset_disk_ro(g, 1);\r\nbreak;\r\ncase VD_MEDIA_TYPE_DVD:\r\npr_info(PFX "Virtual DVD %s\n", port->disk_name);\r\ng->flags |= GENHD_FL_CD;\r\ng->flags |= GENHD_FL_REMOVABLE;\r\nset_disk_ro(g, 1);\r\nbreak;\r\ncase VD_MEDIA_TYPE_FIXED:\r\npr_info(PFX "Virtual Hard disk %s\n", port->disk_name);\r\nbreak;\r\n}\r\n}\r\nblk_queue_physical_block_size(q, port->vdisk_phys_blksz);\r\npr_info(PFX "%s: %u sectors (%u MB) protocol %d.%d\n",\r\ng->disk_name,\r\nport->vdisk_size, (port->vdisk_size >> (20 - 9)),\r\nport->vio.ver.major, port->vio.ver.minor);\r\ndevice_add_disk(&port->vio.vdev->dev, g);\r\nreturn 0;\r\n}\r\nstatic void print_version(void)\r\n{\r\nstatic int version_printed;\r\nif (version_printed++ == 0)\r\nprintk(KERN_INFO "%s", version);\r\n}\r\nstatic int vdc_device_probed(struct device *dev, void *arg)\r\n{\r\nstruct vio_dev *vdev = to_vio_dev(dev);\r\nstruct vdc_check_port_data *port_data;\r\nport_data = (struct vdc_check_port_data *)arg;\r\nif ((vdev->dev_no == port_data->dev_no) &&\r\n(!(strcmp((char *)&vdev->type, port_data->type))) &&\r\ndev_get_drvdata(dev)) {\r\nreturn 1;\r\n} else {\r\nreturn 0;\r\n}\r\n}\r\nstatic bool vdc_port_mpgroup_check(struct vio_dev *vdev)\r\n{\r\nstruct vdc_check_port_data port_data;\r\nstruct device *dev;\r\nport_data.dev_no = vdev->dev_no;\r\nport_data.type = (char *)&vdev->type;\r\ndev = device_find_child(vdev->dev.parent, &port_data,\r\nvdc_device_probed);\r\nif (dev)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic int vdc_port_probe(struct vio_dev *vdev, const struct vio_device_id *id)\r\n{\r\nstruct mdesc_handle *hp;\r\nstruct vdc_port *port;\r\nint err;\r\nconst u64 *ldc_timeout;\r\nprint_version();\r\nhp = mdesc_grab();\r\nerr = -ENODEV;\r\nif ((vdev->dev_no << PARTITION_SHIFT) & ~(u64)MINORMASK) {\r\nprintk(KERN_ERR PFX "Port id [%llu] too large.\n",\r\nvdev->dev_no);\r\ngoto err_out_release_mdesc;\r\n}\r\nif (vdc_port_mpgroup_check(vdev)) {\r\nprintk(KERN_WARNING\r\n"VIO: Ignoring extra vdisk port %s",\r\ndev_name(&vdev->dev));\r\ngoto err_out_release_mdesc;\r\n}\r\nport = kzalloc(sizeof(*port), GFP_KERNEL);\r\nerr = -ENOMEM;\r\nif (!port) {\r\nprintk(KERN_ERR PFX "Cannot allocate vdc_port.\n");\r\ngoto err_out_release_mdesc;\r\n}\r\nif (vdev->dev_no >= 26)\r\nsnprintf(port->disk_name, sizeof(port->disk_name),\r\nVDCBLK_NAME "%c%c",\r\n'a' + ((int)vdev->dev_no / 26) - 1,\r\n'a' + ((int)vdev->dev_no % 26));\r\nelse\r\nsnprintf(port->disk_name, sizeof(port->disk_name),\r\nVDCBLK_NAME "%c", 'a' + ((int)vdev->dev_no % 26));\r\nport->vdisk_size = -1;\r\nldc_timeout = mdesc_get_property(hp, vdev->mp, "vdc-timeout", NULL);\r\nport->ldc_timeout = ldc_timeout ? *ldc_timeout : 0;\r\nsetup_timer(&port->ldc_reset_timer, vdc_ldc_reset_timer,\r\n(unsigned long)port);\r\nINIT_WORK(&port->ldc_reset_work, vdc_ldc_reset_work);\r\nerr = vio_driver_init(&port->vio, vdev, VDEV_DISK,\r\nvdc_versions, ARRAY_SIZE(vdc_versions),\r\n&vdc_vio_ops, port->disk_name);\r\nif (err)\r\ngoto err_out_free_port;\r\nport->vdisk_block_size = VDC_DEFAULT_BLK_SIZE;\r\nport->max_xfer_size = ((128 * 1024) / port->vdisk_block_size);\r\nport->ring_cookies = ((port->max_xfer_size *\r\nport->vdisk_block_size) / PAGE_SIZE) + 2;\r\nerr = vio_ldc_alloc(&port->vio, &vdc_ldc_cfg, port);\r\nif (err)\r\ngoto err_out_free_port;\r\nerr = vdc_alloc_tx_ring(port);\r\nif (err)\r\ngoto err_out_free_ldc;\r\nerr = probe_disk(port);\r\nif (err)\r\ngoto err_out_free_tx_ring;\r\ndev_set_drvdata(&vdev->dev, port);\r\nmdesc_release(hp);\r\nreturn 0;\r\nerr_out_free_tx_ring:\r\nvdc_free_tx_ring(port);\r\nerr_out_free_ldc:\r\nvio_ldc_free(&port->vio);\r\nerr_out_free_port:\r\nkfree(port);\r\nerr_out_release_mdesc:\r\nmdesc_release(hp);\r\nreturn err;\r\n}\r\nstatic int vdc_port_remove(struct vio_dev *vdev)\r\n{\r\nstruct vdc_port *port = dev_get_drvdata(&vdev->dev);\r\nif (port) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&port->vio.lock, flags);\r\nblk_stop_queue(port->disk->queue);\r\nspin_unlock_irqrestore(&port->vio.lock, flags);\r\nflush_work(&port->ldc_reset_work);\r\ndel_timer_sync(&port->ldc_reset_timer);\r\ndel_timer_sync(&port->vio.timer);\r\ndel_gendisk(port->disk);\r\nblk_cleanup_queue(port->disk->queue);\r\nput_disk(port->disk);\r\nport->disk = NULL;\r\nvdc_free_tx_ring(port);\r\nvio_ldc_free(&port->vio);\r\ndev_set_drvdata(&vdev->dev, NULL);\r\nkfree(port);\r\n}\r\nreturn 0;\r\n}\r\nstatic void vdc_requeue_inflight(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nu32 idx;\r\nfor (idx = dr->cons; idx != dr->prod; idx = vio_dring_next(dr, idx)) {\r\nstruct vio_disk_desc *desc = vio_dring_entry(dr, idx);\r\nstruct vdc_req_entry *rqe = &port->rq_arr[idx];\r\nstruct request *req;\r\nldc_unmap(port->vio.lp, desc->cookies, desc->ncookies);\r\ndesc->hdr.state = VIO_DESC_FREE;\r\ndr->cons = vio_dring_next(dr, idx);\r\nreq = rqe->req;\r\nif (req == NULL) {\r\nvdc_end_special(port, desc);\r\ncontinue;\r\n}\r\nrqe->req = NULL;\r\nblk_requeue_request(port->disk->queue, req);\r\n}\r\n}\r\nstatic void vdc_queue_drain(struct vdc_port *port)\r\n{\r\nstruct request *req;\r\nwhile ((req = blk_fetch_request(port->disk->queue)) != NULL)\r\n__blk_end_request_all(req, BLK_STS_IOERR);\r\n}\r\nstatic void vdc_ldc_reset_timer(unsigned long _arg)\r\n{\r\nstruct vdc_port *port = (struct vdc_port *) _arg;\r\nstruct vio_driver_state *vio = &port->vio;\r\nunsigned long flags;\r\nspin_lock_irqsave(&vio->lock, flags);\r\nif (!(port->vio.hs_state & VIO_HS_COMPLETE)) {\r\npr_warn(PFX "%s ldc down %llu seconds, draining queue\n",\r\nport->disk_name, port->ldc_timeout);\r\nvdc_queue_drain(port);\r\nvdc_blk_queue_start(port);\r\n}\r\nspin_unlock_irqrestore(&vio->lock, flags);\r\n}\r\nstatic void vdc_ldc_reset_work(struct work_struct *work)\r\n{\r\nstruct vdc_port *port;\r\nstruct vio_driver_state *vio;\r\nunsigned long flags;\r\nport = container_of(work, struct vdc_port, ldc_reset_work);\r\nvio = &port->vio;\r\nspin_lock_irqsave(&vio->lock, flags);\r\nvdc_ldc_reset(port);\r\nspin_unlock_irqrestore(&vio->lock, flags);\r\n}\r\nstatic void vdc_ldc_reset(struct vdc_port *port)\r\n{\r\nint err;\r\nassert_spin_locked(&port->vio.lock);\r\npr_warn(PFX "%s ldc link reset\n", port->disk_name);\r\nblk_stop_queue(port->disk->queue);\r\nvdc_requeue_inflight(port);\r\nvdc_port_down(port);\r\nerr = vio_ldc_alloc(&port->vio, &vdc_ldc_cfg, port);\r\nif (err) {\r\npr_err(PFX "%s vio_ldc_alloc:%d\n", port->disk_name, err);\r\nreturn;\r\n}\r\nerr = vdc_alloc_tx_ring(port);\r\nif (err) {\r\npr_err(PFX "%s vio_alloc_tx_ring:%d\n", port->disk_name, err);\r\ngoto err_free_ldc;\r\n}\r\nif (port->ldc_timeout)\r\nmod_timer(&port->ldc_reset_timer,\r\nround_jiffies(jiffies + HZ * port->ldc_timeout));\r\nmod_timer(&port->vio.timer, round_jiffies(jiffies + HZ));\r\nreturn;\r\nerr_free_ldc:\r\nvio_ldc_free(&port->vio);\r\n}\r\nstatic int __init vdc_init(void)\r\n{\r\nint err;\r\nsunvdc_wq = alloc_workqueue("sunvdc", 0, 0);\r\nif (!sunvdc_wq)\r\nreturn -ENOMEM;\r\nerr = register_blkdev(0, VDCBLK_NAME);\r\nif (err < 0)\r\ngoto out_free_wq;\r\nvdc_major = err;\r\nerr = vio_register_driver(&vdc_port_driver);\r\nif (err)\r\ngoto out_unregister_blkdev;\r\nreturn 0;\r\nout_unregister_blkdev:\r\nunregister_blkdev(vdc_major, VDCBLK_NAME);\r\nvdc_major = 0;\r\nout_free_wq:\r\ndestroy_workqueue(sunvdc_wq);\r\nreturn err;\r\n}\r\nstatic void __exit vdc_exit(void)\r\n{\r\nvio_unregister_driver(&vdc_port_driver);\r\nunregister_blkdev(vdc_major, VDCBLK_NAME);\r\ndestroy_workqueue(sunvdc_wq);\r\n}
