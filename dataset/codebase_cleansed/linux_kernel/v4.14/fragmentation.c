static void batadv_frag_clear_chain(struct hlist_head *head, bool dropped)\r\n{\r\nstruct batadv_frag_list_entry *entry;\r\nstruct hlist_node *node;\r\nhlist_for_each_entry_safe(entry, node, head, list) {\r\nhlist_del(&entry->list);\r\nif (dropped)\r\nkfree_skb(entry->skb);\r\nelse\r\nconsume_skb(entry->skb);\r\nkfree(entry);\r\n}\r\n}\r\nvoid batadv_frag_purge_orig(struct batadv_orig_node *orig_node,\r\nbool (*check_cb)(struct batadv_frag_table_entry *))\r\n{\r\nstruct batadv_frag_table_entry *chain;\r\nu8 i;\r\nfor (i = 0; i < BATADV_FRAG_BUFFER_COUNT; i++) {\r\nchain = &orig_node->fragments[i];\r\nspin_lock_bh(&chain->lock);\r\nif (!check_cb || check_cb(chain)) {\r\nbatadv_frag_clear_chain(&chain->fragment_list, true);\r\nchain->size = 0;\r\n}\r\nspin_unlock_bh(&chain->lock);\r\n}\r\n}\r\nstatic int batadv_frag_size_limit(void)\r\n{\r\nint limit = BATADV_FRAG_MAX_FRAG_SIZE;\r\nlimit -= sizeof(struct batadv_frag_packet);\r\nlimit *= BATADV_FRAG_MAX_FRAGMENTS;\r\nreturn limit;\r\n}\r\nstatic bool batadv_frag_init_chain(struct batadv_frag_table_entry *chain,\r\nu16 seqno)\r\n{\r\nlockdep_assert_held(&chain->lock);\r\nif (chain->seqno == seqno)\r\nreturn false;\r\nif (!hlist_empty(&chain->fragment_list))\r\nbatadv_frag_clear_chain(&chain->fragment_list, true);\r\nchain->size = 0;\r\nchain->seqno = seqno;\r\nreturn true;\r\n}\r\nstatic bool batadv_frag_insert_packet(struct batadv_orig_node *orig_node,\r\nstruct sk_buff *skb,\r\nstruct hlist_head *chain_out)\r\n{\r\nstruct batadv_frag_table_entry *chain;\r\nstruct batadv_frag_list_entry *frag_entry_new = NULL, *frag_entry_curr;\r\nstruct batadv_frag_list_entry *frag_entry_last = NULL;\r\nstruct batadv_frag_packet *frag_packet;\r\nu8 bucket;\r\nu16 seqno, hdr_size = sizeof(struct batadv_frag_packet);\r\nbool ret = false;\r\nif (skb_linearize(skb) < 0)\r\ngoto err;\r\nfrag_packet = (struct batadv_frag_packet *)skb->data;\r\nseqno = ntohs(frag_packet->seqno);\r\nbucket = seqno % BATADV_FRAG_BUFFER_COUNT;\r\nfrag_entry_new = kmalloc(sizeof(*frag_entry_new), GFP_ATOMIC);\r\nif (!frag_entry_new)\r\ngoto err;\r\nfrag_entry_new->skb = skb;\r\nfrag_entry_new->no = frag_packet->no;\r\nchain = &orig_node->fragments[bucket];\r\nspin_lock_bh(&chain->lock);\r\nif (batadv_frag_init_chain(chain, seqno)) {\r\nhlist_add_head(&frag_entry_new->list, &chain->fragment_list);\r\nchain->size = skb->len - hdr_size;\r\nchain->timestamp = jiffies;\r\nchain->total_size = ntohs(frag_packet->total_size);\r\nret = true;\r\ngoto out;\r\n}\r\nhlist_for_each_entry(frag_entry_curr, &chain->fragment_list, list) {\r\nif (frag_entry_curr->no == frag_entry_new->no)\r\ngoto err_unlock;\r\nif (frag_entry_curr->no < frag_entry_new->no) {\r\nhlist_add_before(&frag_entry_new->list,\r\n&frag_entry_curr->list);\r\nchain->size += skb->len - hdr_size;\r\nchain->timestamp = jiffies;\r\nret = true;\r\ngoto out;\r\n}\r\nfrag_entry_last = frag_entry_curr;\r\n}\r\nif (likely(frag_entry_last)) {\r\nhlist_add_behind(&frag_entry_new->list, &frag_entry_last->list);\r\nchain->size += skb->len - hdr_size;\r\nchain->timestamp = jiffies;\r\nret = true;\r\n}\r\nout:\r\nif (chain->size > batadv_frag_size_limit() ||\r\nchain->total_size != ntohs(frag_packet->total_size) ||\r\nchain->total_size > batadv_frag_size_limit()) {\r\nbatadv_frag_clear_chain(&chain->fragment_list, true);\r\nchain->size = 0;\r\n} else if (ntohs(frag_packet->total_size) == chain->size) {\r\nhlist_move_list(&chain->fragment_list, chain_out);\r\nchain->size = 0;\r\n}\r\nerr_unlock:\r\nspin_unlock_bh(&chain->lock);\r\nerr:\r\nif (!ret) {\r\nkfree(frag_entry_new);\r\nkfree_skb(skb);\r\n}\r\nreturn ret;\r\n}\r\nstatic struct sk_buff *\r\nbatadv_frag_merge_packets(struct hlist_head *chain)\r\n{\r\nstruct batadv_frag_packet *packet;\r\nstruct batadv_frag_list_entry *entry;\r\nstruct sk_buff *skb_out;\r\nint size, hdr_size = sizeof(struct batadv_frag_packet);\r\nbool dropped = false;\r\nentry = hlist_entry(chain->first, struct batadv_frag_list_entry, list);\r\nhlist_del(&entry->list);\r\nskb_out = entry->skb;\r\nkfree(entry);\r\npacket = (struct batadv_frag_packet *)skb_out->data;\r\nsize = ntohs(packet->total_size);\r\nif (pskb_expand_head(skb_out, 0, size - skb_out->len, GFP_ATOMIC) < 0) {\r\nkfree_skb(skb_out);\r\nskb_out = NULL;\r\ndropped = true;\r\ngoto free;\r\n}\r\nskb_pull_rcsum(skb_out, hdr_size);\r\nmemmove(skb_out->data - ETH_HLEN, skb_mac_header(skb_out), ETH_HLEN);\r\nskb_set_mac_header(skb_out, -ETH_HLEN);\r\nskb_reset_network_header(skb_out);\r\nskb_reset_transport_header(skb_out);\r\nhlist_for_each_entry(entry, chain, list) {\r\nsize = entry->skb->len - hdr_size;\r\nskb_put_data(skb_out, entry->skb->data + hdr_size, size);\r\n}\r\nfree:\r\nbatadv_frag_clear_chain(chain, dropped);\r\nreturn skb_out;\r\n}\r\nbool batadv_frag_skb_buffer(struct sk_buff **skb,\r\nstruct batadv_orig_node *orig_node_src)\r\n{\r\nstruct sk_buff *skb_out = NULL;\r\nstruct hlist_head head = HLIST_HEAD_INIT;\r\nbool ret = false;\r\nif (!batadv_frag_insert_packet(orig_node_src, *skb, &head))\r\ngoto out_err;\r\nif (hlist_empty(&head))\r\ngoto out;\r\nskb_out = batadv_frag_merge_packets(&head);\r\nif (!skb_out)\r\ngoto out_err;\r\nout:\r\nret = true;\r\nout_err:\r\n*skb = skb_out;\r\nreturn ret;\r\n}\r\nbool batadv_frag_skb_fwd(struct sk_buff *skb,\r\nstruct batadv_hard_iface *recv_if,\r\nstruct batadv_orig_node *orig_node_src)\r\n{\r\nstruct batadv_priv *bat_priv = netdev_priv(recv_if->soft_iface);\r\nstruct batadv_orig_node *orig_node_dst;\r\nstruct batadv_neigh_node *neigh_node = NULL;\r\nstruct batadv_frag_packet *packet;\r\nu16 total_size;\r\nbool ret = false;\r\npacket = (struct batadv_frag_packet *)skb->data;\r\norig_node_dst = batadv_orig_hash_find(bat_priv, packet->dest);\r\nif (!orig_node_dst)\r\ngoto out;\r\nneigh_node = batadv_find_router(bat_priv, orig_node_dst, recv_if);\r\nif (!neigh_node)\r\ngoto out;\r\ntotal_size = ntohs(packet->total_size);\r\nif (total_size > neigh_node->if_incoming->net_dev->mtu) {\r\nbatadv_inc_counter(bat_priv, BATADV_CNT_FRAG_FWD);\r\nbatadv_add_counter(bat_priv, BATADV_CNT_FRAG_FWD_BYTES,\r\nskb->len + ETH_HLEN);\r\npacket->ttl--;\r\nbatadv_send_unicast_skb(skb, neigh_node);\r\nret = true;\r\n}\r\nout:\r\nif (orig_node_dst)\r\nbatadv_orig_node_put(orig_node_dst);\r\nif (neigh_node)\r\nbatadv_neigh_node_put(neigh_node);\r\nreturn ret;\r\n}\r\nstatic struct sk_buff *batadv_frag_create(struct sk_buff *skb,\r\nstruct batadv_frag_packet *frag_head,\r\nunsigned int fragment_size)\r\n{\r\nstruct sk_buff *skb_fragment;\r\nunsigned int header_size = sizeof(*frag_head);\r\nunsigned int mtu = fragment_size + header_size;\r\nskb_fragment = netdev_alloc_skb(NULL, mtu + ETH_HLEN);\r\nif (!skb_fragment)\r\ngoto err;\r\nskb_fragment->priority = skb->priority;\r\nskb_reserve(skb_fragment, header_size + ETH_HLEN);\r\nskb_split(skb, skb_fragment, skb->len - fragment_size);\r\nskb_push(skb_fragment, header_size);\r\nmemcpy(skb_fragment->data, frag_head, header_size);\r\nerr:\r\nreturn skb_fragment;\r\n}\r\nint batadv_frag_send_packet(struct sk_buff *skb,\r\nstruct batadv_orig_node *orig_node,\r\nstruct batadv_neigh_node *neigh_node)\r\n{\r\nstruct batadv_priv *bat_priv;\r\nstruct batadv_hard_iface *primary_if = NULL;\r\nstruct batadv_frag_packet frag_header;\r\nstruct sk_buff *skb_fragment;\r\nunsigned int mtu = neigh_node->if_incoming->net_dev->mtu;\r\nunsigned int header_size = sizeof(frag_header);\r\nunsigned int max_fragment_size, num_fragments;\r\nint ret;\r\nmtu = min_t(unsigned int, mtu, BATADV_FRAG_MAX_FRAG_SIZE);\r\nmax_fragment_size = mtu - header_size;\r\nif (skb->len == 0 || max_fragment_size == 0)\r\nreturn -EINVAL;\r\nnum_fragments = (skb->len - 1) / max_fragment_size + 1;\r\nmax_fragment_size = (skb->len - 1) / num_fragments + 1;\r\nif (num_fragments > BATADV_FRAG_MAX_FRAGMENTS) {\r\nret = -EAGAIN;\r\ngoto free_skb;\r\n}\r\nbat_priv = orig_node->bat_priv;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if) {\r\nret = -EINVAL;\r\ngoto free_skb;\r\n}\r\nfrag_header.packet_type = BATADV_UNICAST_FRAG;\r\nfrag_header.version = BATADV_COMPAT_VERSION;\r\nfrag_header.ttl = BATADV_TTL;\r\nfrag_header.seqno = htons(atomic_inc_return(&bat_priv->frag_seqno));\r\nfrag_header.reserved = 0;\r\nfrag_header.no = 0;\r\nfrag_header.total_size = htons(skb->len);\r\nif (skb->priority >= 256 && skb->priority <= 263)\r\nfrag_header.priority = skb->priority - 256;\r\nether_addr_copy(frag_header.orig, primary_if->net_dev->dev_addr);\r\nether_addr_copy(frag_header.dest, orig_node->orig);\r\nwhile (skb->len > max_fragment_size) {\r\nif (unlikely(frag_header.no == BATADV_FRAG_MAX_FRAGMENTS - 1)) {\r\nret = -EINVAL;\r\ngoto put_primary_if;\r\n}\r\nskb_fragment = batadv_frag_create(skb, &frag_header,\r\nmax_fragment_size);\r\nif (!skb_fragment) {\r\nret = -ENOMEM;\r\ngoto put_primary_if;\r\n}\r\nbatadv_inc_counter(bat_priv, BATADV_CNT_FRAG_TX);\r\nbatadv_add_counter(bat_priv, BATADV_CNT_FRAG_TX_BYTES,\r\nskb_fragment->len + ETH_HLEN);\r\nret = batadv_send_unicast_skb(skb_fragment, neigh_node);\r\nif (ret != NET_XMIT_SUCCESS) {\r\nret = NET_XMIT_DROP;\r\ngoto put_primary_if;\r\n}\r\nfrag_header.no++;\r\n}\r\nif (batadv_skb_head_push(skb, header_size) < 0 ||\r\npskb_expand_head(skb, header_size + ETH_HLEN, 0, GFP_ATOMIC) < 0) {\r\nret = -ENOMEM;\r\ngoto put_primary_if;\r\n}\r\nmemcpy(skb->data, &frag_header, header_size);\r\nbatadv_inc_counter(bat_priv, BATADV_CNT_FRAG_TX);\r\nbatadv_add_counter(bat_priv, BATADV_CNT_FRAG_TX_BYTES,\r\nskb->len + ETH_HLEN);\r\nret = batadv_send_unicast_skb(skb, neigh_node);\r\nskb = NULL;\r\nput_primary_if:\r\nbatadv_hardif_put(primary_if);\r\nfree_skb:\r\nkfree_skb(skb);\r\nreturn ret;\r\n}
