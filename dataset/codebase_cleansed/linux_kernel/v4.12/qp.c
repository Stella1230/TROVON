static struct mlx5_core_rsc_common *mlx5_get_rsc(struct mlx5_core_dev *dev,\r\nu32 rsn)\r\n{\r\nstruct mlx5_qp_table *table = &dev->priv.qp_table;\r\nstruct mlx5_core_rsc_common *common;\r\nspin_lock(&table->lock);\r\ncommon = radix_tree_lookup(&table->tree, rsn);\r\nif (common)\r\natomic_inc(&common->refcount);\r\nspin_unlock(&table->lock);\r\nif (!common) {\r\nmlx5_core_warn(dev, "Async event for bogus resource 0x%x\n",\r\nrsn);\r\nreturn NULL;\r\n}\r\nreturn common;\r\n}\r\nvoid mlx5_core_put_rsc(struct mlx5_core_rsc_common *common)\r\n{\r\nif (atomic_dec_and_test(&common->refcount))\r\ncomplete(&common->free);\r\n}\r\nstatic u64 qp_allowed_event_types(void)\r\n{\r\nu64 mask;\r\nmask = BIT(MLX5_EVENT_TYPE_PATH_MIG) |\r\nBIT(MLX5_EVENT_TYPE_COMM_EST) |\r\nBIT(MLX5_EVENT_TYPE_SQ_DRAINED) |\r\nBIT(MLX5_EVENT_TYPE_SRQ_LAST_WQE) |\r\nBIT(MLX5_EVENT_TYPE_WQ_CATAS_ERROR) |\r\nBIT(MLX5_EVENT_TYPE_PATH_MIG_FAILED) |\r\nBIT(MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR) |\r\nBIT(MLX5_EVENT_TYPE_WQ_ACCESS_ERROR);\r\nreturn mask;\r\n}\r\nstatic u64 rq_allowed_event_types(void)\r\n{\r\nu64 mask;\r\nmask = BIT(MLX5_EVENT_TYPE_SRQ_LAST_WQE) |\r\nBIT(MLX5_EVENT_TYPE_WQ_CATAS_ERROR);\r\nreturn mask;\r\n}\r\nstatic u64 sq_allowed_event_types(void)\r\n{\r\nreturn BIT(MLX5_EVENT_TYPE_WQ_CATAS_ERROR);\r\n}\r\nstatic bool is_event_type_allowed(int rsc_type, int event_type)\r\n{\r\nswitch (rsc_type) {\r\ncase MLX5_EVENT_QUEUE_TYPE_QP:\r\nreturn BIT(event_type) & qp_allowed_event_types();\r\ncase MLX5_EVENT_QUEUE_TYPE_RQ:\r\nreturn BIT(event_type) & rq_allowed_event_types();\r\ncase MLX5_EVENT_QUEUE_TYPE_SQ:\r\nreturn BIT(event_type) & sq_allowed_event_types();\r\ndefault:\r\nWARN(1, "Event arrived for unknown resource type");\r\nreturn false;\r\n}\r\n}\r\nvoid mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type)\r\n{\r\nstruct mlx5_core_rsc_common *common = mlx5_get_rsc(dev, rsn);\r\nstruct mlx5_core_qp *qp;\r\nif (!common)\r\nreturn;\r\nif (!is_event_type_allowed((rsn >> MLX5_USER_INDEX_LEN), event_type)) {\r\nmlx5_core_warn(dev, "event 0x%.2x is not allowed on resource 0x%.8x\n",\r\nevent_type, rsn);\r\nreturn;\r\n}\r\nswitch (common->res) {\r\ncase MLX5_RES_QP:\r\ncase MLX5_RES_RQ:\r\ncase MLX5_RES_SQ:\r\nqp = (struct mlx5_core_qp *)common;\r\nqp->event(qp, event_type);\r\nbreak;\r\ndefault:\r\nmlx5_core_warn(dev, "invalid resource type for 0x%x\n", rsn);\r\n}\r\nmlx5_core_put_rsc(common);\r\n}\r\nstatic int create_qprqsq_common(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_qp *qp,\r\nint rsc_type)\r\n{\r\nstruct mlx5_qp_table *table = &dev->priv.qp_table;\r\nint err;\r\nqp->common.res = rsc_type;\r\nspin_lock_irq(&table->lock);\r\nerr = radix_tree_insert(&table->tree,\r\nqp->qpn | (rsc_type << MLX5_USER_INDEX_LEN),\r\nqp);\r\nspin_unlock_irq(&table->lock);\r\nif (err)\r\nreturn err;\r\natomic_set(&qp->common.refcount, 1);\r\ninit_completion(&qp->common.free);\r\nqp->pid = current->pid;\r\nreturn 0;\r\n}\r\nstatic void destroy_qprqsq_common(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_qp *qp)\r\n{\r\nstruct mlx5_qp_table *table = &dev->priv.qp_table;\r\nunsigned long flags;\r\nspin_lock_irqsave(&table->lock, flags);\r\nradix_tree_delete(&table->tree,\r\nqp->qpn | (qp->common.res << MLX5_USER_INDEX_LEN));\r\nspin_unlock_irqrestore(&table->lock, flags);\r\nmlx5_core_put_rsc((struct mlx5_core_rsc_common *)qp);\r\nwait_for_completion(&qp->common.free);\r\n}\r\nint mlx5_core_create_qp(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_qp *qp,\r\nu32 *in, int inlen)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(create_qp_out)] = {0};\r\nu32 dout[MLX5_ST_SZ_DW(destroy_qp_out)];\r\nu32 din[MLX5_ST_SZ_DW(destroy_qp_in)];\r\nint err;\r\nMLX5_SET(create_qp_in, in, opcode, MLX5_CMD_OP_CREATE_QP);\r\nerr = mlx5_cmd_exec(dev, in, inlen, out, sizeof(out));\r\nif (err)\r\nreturn err;\r\nqp->qpn = MLX5_GET(create_qp_out, out, qpn);\r\nmlx5_core_dbg(dev, "qpn = 0x%x\n", qp->qpn);\r\nerr = create_qprqsq_common(dev, qp, MLX5_RES_QP);\r\nif (err)\r\ngoto err_cmd;\r\nerr = mlx5_debug_qp_add(dev, qp);\r\nif (err)\r\nmlx5_core_dbg(dev, "failed adding QP 0x%x to debug file system\n",\r\nqp->qpn);\r\natomic_inc(&dev->num_qps);\r\nreturn 0;\r\nerr_cmd:\r\nmemset(din, 0, sizeof(din));\r\nmemset(dout, 0, sizeof(dout));\r\nMLX5_SET(destroy_qp_in, in, opcode, MLX5_CMD_OP_DESTROY_QP);\r\nMLX5_SET(destroy_qp_in, in, qpn, qp->qpn);\r\nmlx5_cmd_exec(dev, din, sizeof(din), dout, sizeof(dout));\r\nreturn err;\r\n}\r\nint mlx5_core_destroy_qp(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_qp *qp)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(destroy_qp_out)] = {0};\r\nu32 in[MLX5_ST_SZ_DW(destroy_qp_in)] = {0};\r\nint err;\r\nmlx5_debug_qp_remove(dev, qp);\r\ndestroy_qprqsq_common(dev, qp);\r\nMLX5_SET(destroy_qp_in, in, opcode, MLX5_CMD_OP_DESTROY_QP);\r\nMLX5_SET(destroy_qp_in, in, qpn, qp->qpn);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));\r\nif (err)\r\nreturn err;\r\natomic_dec(&dev->num_qps);\r\nreturn 0;\r\n}\r\nstatic int mbox_alloc(struct mbox_info *mbox, int inlen, int outlen)\r\n{\r\nmbox->inlen = inlen;\r\nmbox->outlen = outlen;\r\nmbox->in = kzalloc(mbox->inlen, GFP_KERNEL);\r\nmbox->out = kzalloc(mbox->outlen, GFP_KERNEL);\r\nif (!mbox->in || !mbox->out) {\r\nkfree(mbox->in);\r\nkfree(mbox->out);\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void mbox_free(struct mbox_info *mbox)\r\n{\r\nkfree(mbox->in);\r\nkfree(mbox->out);\r\n}\r\nstatic int modify_qp_mbox_alloc(struct mlx5_core_dev *dev, u16 opcode, int qpn,\r\nu32 opt_param_mask, void *qpc,\r\nstruct mbox_info *mbox)\r\n{\r\nmbox->out = NULL;\r\nmbox->in = NULL;\r\n#define MBOX_ALLOC(mbox, typ) \\r\nmbox_alloc(mbox, MLX5_ST_SZ_BYTES(typ##_in), MLX5_ST_SZ_BYTES(typ##_out))\r\n#define MOD_QP_IN_SET(typ, in, _opcode, _qpn) \\r\nMLX5_SET(typ##_in, in, opcode, _opcode); \\r\nMLX5_SET(typ##_in, in, qpn, _qpn)\r\n#define MOD_QP_IN_SET_QPC(typ, in, _opcode, _qpn, _opt_p, _qpc) \\r\nMOD_QP_IN_SET(typ, in, _opcode, _qpn); \\r\nMLX5_SET(typ##_in, in, opt_param_mask, _opt_p); \\r\nmemcpy(MLX5_ADDR_OF(typ##_in, in, qpc), _qpc, MLX5_ST_SZ_BYTES(qpc))\r\nswitch (opcode) {\r\ncase MLX5_CMD_OP_2RST_QP:\r\nif (MBOX_ALLOC(mbox, qp_2rst))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET(qp_2rst, mbox->in, opcode, qpn);\r\nbreak;\r\ncase MLX5_CMD_OP_2ERR_QP:\r\nif (MBOX_ALLOC(mbox, qp_2err))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET(qp_2err, mbox->in, opcode, qpn);\r\nbreak;\r\ncase MLX5_CMD_OP_RST2INIT_QP:\r\nif (MBOX_ALLOC(mbox, rst2init_qp))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET_QPC(rst2init_qp, mbox->in, opcode, qpn,\r\nopt_param_mask, qpc);\r\nbreak;\r\ncase MLX5_CMD_OP_INIT2RTR_QP:\r\nif (MBOX_ALLOC(mbox, init2rtr_qp))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET_QPC(init2rtr_qp, mbox->in, opcode, qpn,\r\nopt_param_mask, qpc);\r\nbreak;\r\ncase MLX5_CMD_OP_RTR2RTS_QP:\r\nif (MBOX_ALLOC(mbox, rtr2rts_qp))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET_QPC(rtr2rts_qp, mbox->in, opcode, qpn,\r\nopt_param_mask, qpc);\r\nbreak;\r\ncase MLX5_CMD_OP_RTS2RTS_QP:\r\nif (MBOX_ALLOC(mbox, rts2rts_qp))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET_QPC(rts2rts_qp, mbox->in, opcode, qpn,\r\nopt_param_mask, qpc);\r\nbreak;\r\ncase MLX5_CMD_OP_SQERR2RTS_QP:\r\nif (MBOX_ALLOC(mbox, sqerr2rts_qp))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET_QPC(sqerr2rts_qp, mbox->in, opcode, qpn,\r\nopt_param_mask, qpc);\r\nbreak;\r\ncase MLX5_CMD_OP_INIT2INIT_QP:\r\nif (MBOX_ALLOC(mbox, init2init_qp))\r\nreturn -ENOMEM;\r\nMOD_QP_IN_SET_QPC(init2init_qp, mbox->in, opcode, qpn,\r\nopt_param_mask, qpc);\r\nbreak;\r\ndefault:\r\nmlx5_core_err(dev, "Unknown transition for modify QP: OP(0x%x) QPN(0x%x)\n",\r\nopcode, qpn);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint mlx5_core_qp_modify(struct mlx5_core_dev *dev, u16 opcode,\r\nu32 opt_param_mask, void *qpc,\r\nstruct mlx5_core_qp *qp)\r\n{\r\nstruct mbox_info mbox;\r\nint err;\r\nerr = modify_qp_mbox_alloc(dev, opcode, qp->qpn,\r\nopt_param_mask, qpc, &mbox);\r\nif (err)\r\nreturn err;\r\nerr = mlx5_cmd_exec(dev, mbox.in, mbox.inlen, mbox.out, mbox.outlen);\r\nmbox_free(&mbox);\r\nreturn err;\r\n}\r\nvoid mlx5_init_qp_table(struct mlx5_core_dev *dev)\r\n{\r\nstruct mlx5_qp_table *table = &dev->priv.qp_table;\r\nmemset(table, 0, sizeof(*table));\r\nspin_lock_init(&table->lock);\r\nINIT_RADIX_TREE(&table->tree, GFP_ATOMIC);\r\nmlx5_qp_debugfs_init(dev);\r\n}\r\nvoid mlx5_cleanup_qp_table(struct mlx5_core_dev *dev)\r\n{\r\nmlx5_qp_debugfs_cleanup(dev);\r\n}\r\nint mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,\r\nu32 *out, int outlen)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_qp_in)] = {0};\r\nMLX5_SET(query_qp_in, in, opcode, MLX5_CMD_OP_QUERY_QP);\r\nMLX5_SET(query_qp_in, in, qpn, qp->qpn);\r\nreturn mlx5_cmd_exec(dev, in, sizeof(in), out, outlen);\r\n}\r\nint mlx5_core_xrcd_alloc(struct mlx5_core_dev *dev, u32 *xrcdn)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(alloc_xrcd_out)] = {0};\r\nu32 in[MLX5_ST_SZ_DW(alloc_xrcd_in)] = {0};\r\nint err;\r\nMLX5_SET(alloc_xrcd_in, in, opcode, MLX5_CMD_OP_ALLOC_XRCD);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));\r\nif (!err)\r\n*xrcdn = MLX5_GET(alloc_xrcd_out, out, xrcd);\r\nreturn err;\r\n}\r\nint mlx5_core_xrcd_dealloc(struct mlx5_core_dev *dev, u32 xrcdn)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(dealloc_xrcd_out)] = {0};\r\nu32 in[MLX5_ST_SZ_DW(dealloc_xrcd_in)] = {0};\r\nMLX5_SET(dealloc_xrcd_in, in, opcode, MLX5_CMD_OP_DEALLOC_XRCD);\r\nMLX5_SET(dealloc_xrcd_in, in, xrcd, xrcdn);\r\nreturn mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));\r\n}\r\nint mlx5_core_create_rq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,\r\nstruct mlx5_core_qp *rq)\r\n{\r\nint err;\r\nu32 rqn;\r\nerr = mlx5_core_create_rq(dev, in, inlen, &rqn);\r\nif (err)\r\nreturn err;\r\nrq->qpn = rqn;\r\nerr = create_qprqsq_common(dev, rq, MLX5_RES_RQ);\r\nif (err)\r\ngoto err_destroy_rq;\r\nreturn 0;\r\nerr_destroy_rq:\r\nmlx5_core_destroy_rq(dev, rq->qpn);\r\nreturn err;\r\n}\r\nvoid mlx5_core_destroy_rq_tracked(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_qp *rq)\r\n{\r\ndestroy_qprqsq_common(dev, rq);\r\nmlx5_core_destroy_rq(dev, rq->qpn);\r\n}\r\nint mlx5_core_create_sq_tracked(struct mlx5_core_dev *dev, u32 *in, int inlen,\r\nstruct mlx5_core_qp *sq)\r\n{\r\nint err;\r\nu32 sqn;\r\nerr = mlx5_core_create_sq(dev, in, inlen, &sqn);\r\nif (err)\r\nreturn err;\r\nsq->qpn = sqn;\r\nerr = create_qprqsq_common(dev, sq, MLX5_RES_SQ);\r\nif (err)\r\ngoto err_destroy_sq;\r\nreturn 0;\r\nerr_destroy_sq:\r\nmlx5_core_destroy_sq(dev, sq->qpn);\r\nreturn err;\r\n}\r\nvoid mlx5_core_destroy_sq_tracked(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_qp *sq)\r\n{\r\ndestroy_qprqsq_common(dev, sq);\r\nmlx5_core_destroy_sq(dev, sq->qpn);\r\n}\r\nint mlx5_core_alloc_q_counter(struct mlx5_core_dev *dev, u16 *counter_id)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(alloc_q_counter_in)] = {0};\r\nu32 out[MLX5_ST_SZ_DW(alloc_q_counter_out)] = {0};\r\nint err;\r\nMLX5_SET(alloc_q_counter_in, in, opcode, MLX5_CMD_OP_ALLOC_Q_COUNTER);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));\r\nif (!err)\r\n*counter_id = MLX5_GET(alloc_q_counter_out, out,\r\ncounter_set_id);\r\nreturn err;\r\n}\r\nint mlx5_core_dealloc_q_counter(struct mlx5_core_dev *dev, u16 counter_id)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(dealloc_q_counter_in)] = {0};\r\nu32 out[MLX5_ST_SZ_DW(dealloc_q_counter_out)] = {0};\r\nMLX5_SET(dealloc_q_counter_in, in, opcode,\r\nMLX5_CMD_OP_DEALLOC_Q_COUNTER);\r\nMLX5_SET(dealloc_q_counter_in, in, counter_set_id, counter_id);\r\nreturn mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));\r\n}\r\nint mlx5_core_query_q_counter(struct mlx5_core_dev *dev, u16 counter_id,\r\nint reset, void *out, int out_size)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_q_counter_in)] = {0};\r\nMLX5_SET(query_q_counter_in, in, opcode, MLX5_CMD_OP_QUERY_Q_COUNTER);\r\nMLX5_SET(query_q_counter_in, in, clear, reset);\r\nMLX5_SET(query_q_counter_in, in, counter_set_id, counter_id);\r\nreturn mlx5_cmd_exec(dev, in, sizeof(in), out, out_size);\r\n}\r\nint mlx5_core_query_out_of_buffer(struct mlx5_core_dev *dev, u16 counter_id,\r\nu32 *out_of_buffer)\r\n{\r\nint outlen = MLX5_ST_SZ_BYTES(query_q_counter_out);\r\nvoid *out;\r\nint err;\r\nout = mlx5_vzalloc(outlen);\r\nif (!out)\r\nreturn -ENOMEM;\r\nerr = mlx5_core_query_q_counter(dev, counter_id, 0, out, outlen);\r\nif (!err)\r\n*out_of_buffer = MLX5_GET(query_q_counter_out, out,\r\nout_of_buffer);\r\nkfree(out);\r\nreturn err;\r\n}
