int pmdp_set_access_flags(struct vm_area_struct *vma, unsigned long address,\r\npmd_t *pmdp, pmd_t entry, int dirty)\r\n{\r\nint changed;\r\n#ifdef CONFIG_DEBUG_VM\r\nWARN_ON(!pmd_trans_huge(*pmdp));\r\nassert_spin_locked(&vma->vm_mm->page_table_lock);\r\n#endif\r\nchanged = !pmd_same(*(pmdp), entry);\r\nif (changed) {\r\n__ptep_set_access_flags(vma->vm_mm, pmdp_ptep(pmdp),\r\npmd_pte(entry), address);\r\nflush_pmd_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\n}\r\nreturn changed;\r\n}\r\nint pmdp_test_and_clear_young(struct vm_area_struct *vma,\r\nunsigned long address, pmd_t *pmdp)\r\n{\r\nreturn __pmdp_test_and_clear_young(vma->vm_mm, address, pmdp);\r\n}\r\nvoid set_pmd_at(struct mm_struct *mm, unsigned long addr,\r\npmd_t *pmdp, pmd_t pmd)\r\n{\r\n#ifdef CONFIG_DEBUG_VM\r\nWARN_ON(pte_present(pmd_pte(*pmdp)) && !pte_protnone(pmd_pte(*pmdp)));\r\nassert_spin_locked(&mm->page_table_lock);\r\nWARN_ON(!pmd_trans_huge(pmd));\r\n#endif\r\ntrace_hugepage_set_pmd(addr, pmd_val(pmd));\r\nreturn set_pte_at(mm, addr, pmdp_ptep(pmdp), pmd_pte(pmd));\r\n}\r\nvoid pmdp_invalidate(struct vm_area_struct *vma, unsigned long address,\r\npmd_t *pmdp)\r\n{\r\npmd_hugepage_update(vma->vm_mm, address, pmdp, _PAGE_PRESENT, 0);\r\nflush_pmd_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\nkick_all_cpus_sync();\r\n}\r\nstatic pmd_t pmd_set_protbits(pmd_t pmd, pgprot_t pgprot)\r\n{\r\nreturn __pmd(pmd_val(pmd) | pgprot_val(pgprot));\r\n}\r\npmd_t pfn_pmd(unsigned long pfn, pgprot_t pgprot)\r\n{\r\nunsigned long pmdv;\r\npmdv = (pfn << PAGE_SHIFT) & PTE_RPN_MASK;\r\nreturn pmd_set_protbits(__pmd(pmdv), pgprot);\r\n}\r\npmd_t mk_pmd(struct page *page, pgprot_t pgprot)\r\n{\r\nreturn pfn_pmd(page_to_pfn(page), pgprot);\r\n}\r\npmd_t pmd_modify(pmd_t pmd, pgprot_t newprot)\r\n{\r\nunsigned long pmdv;\r\npmdv = pmd_val(pmd);\r\npmdv &= _HPAGE_CHG_MASK;\r\nreturn pmd_set_protbits(__pmd(pmdv), newprot);\r\n}\r\nvoid update_mmu_cache_pmd(struct vm_area_struct *vma, unsigned long addr,\r\npmd_t *pmd)\r\n{\r\nreturn;\r\n}\r\nvoid mmu_cleanup_all(void)\r\n{\r\nif (radix_enabled())\r\nradix__mmu_cleanup_all();\r\nelse if (mmu_hash_ops.hpte_clear_all)\r\nmmu_hash_ops.hpte_clear_all();\r\n}\r\nint create_section_mapping(unsigned long start, unsigned long end)\r\n{\r\nif (radix_enabled())\r\nreturn radix__create_section_mapping(start, end);\r\nreturn hash__create_section_mapping(start, end);\r\n}\r\nint remove_section_mapping(unsigned long start, unsigned long end)\r\n{\r\nif (radix_enabled())\r\nreturn radix__remove_section_mapping(start, end);\r\nreturn hash__remove_section_mapping(start, end);\r\n}
