static int p8_aes_ctr_init(struct crypto_tfm *tfm)\r\n{\r\nconst char *alg;\r\nstruct crypto_blkcipher *fallback;\r\nstruct p8_aes_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\r\nif (!(alg = crypto_tfm_alg_name(tfm))) {\r\nprintk(KERN_ERR "Failed to get algorithm name.\n");\r\nreturn -ENOENT;\r\n}\r\nfallback =\r\ncrypto_alloc_blkcipher(alg, 0, CRYPTO_ALG_NEED_FALLBACK);\r\nif (IS_ERR(fallback)) {\r\nprintk(KERN_ERR\r\n"Failed to allocate transformation for '%s': %ld\n",\r\nalg, PTR_ERR(fallback));\r\nreturn PTR_ERR(fallback);\r\n}\r\nprintk(KERN_INFO "Using '%s' as fallback implementation.\n",\r\ncrypto_tfm_alg_driver_name((struct crypto_tfm *) fallback));\r\ncrypto_blkcipher_set_flags(\r\nfallback,\r\ncrypto_blkcipher_get_flags((struct crypto_blkcipher *)tfm));\r\nctx->fallback = fallback;\r\nreturn 0;\r\n}\r\nstatic void p8_aes_ctr_exit(struct crypto_tfm *tfm)\r\n{\r\nstruct p8_aes_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\r\nif (ctx->fallback) {\r\ncrypto_free_blkcipher(ctx->fallback);\r\nctx->fallback = NULL;\r\n}\r\n}\r\nstatic int p8_aes_ctr_setkey(struct crypto_tfm *tfm, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nint ret;\r\nstruct p8_aes_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\r\npreempt_disable();\r\npagefault_disable();\r\nenable_kernel_vsx();\r\nret = aes_p8_set_encrypt_key(key, keylen * 8, &ctx->enc_key);\r\ndisable_kernel_vsx();\r\npagefault_enable();\r\npreempt_enable();\r\nret += crypto_blkcipher_setkey(ctx->fallback, key, keylen);\r\nreturn ret;\r\n}\r\nstatic void p8_aes_ctr_final(struct p8_aes_ctr_ctx *ctx,\r\nstruct blkcipher_walk *walk)\r\n{\r\nu8 *ctrblk = walk->iv;\r\nu8 keystream[AES_BLOCK_SIZE];\r\nu8 *src = walk->src.virt.addr;\r\nu8 *dst = walk->dst.virt.addr;\r\nunsigned int nbytes = walk->nbytes;\r\npreempt_disable();\r\npagefault_disable();\r\nenable_kernel_vsx();\r\naes_p8_encrypt(ctrblk, keystream, &ctx->enc_key);\r\ndisable_kernel_vsx();\r\npagefault_enable();\r\npreempt_enable();\r\ncrypto_xor(keystream, src, nbytes);\r\nmemcpy(dst, keystream, nbytes);\r\ncrypto_inc(ctrblk, AES_BLOCK_SIZE);\r\n}\r\nstatic int p8_aes_ctr_crypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nint ret;\r\nu64 inc;\r\nstruct blkcipher_walk walk;\r\nstruct p8_aes_ctr_ctx *ctx =\r\ncrypto_tfm_ctx(crypto_blkcipher_tfm(desc->tfm));\r\nstruct blkcipher_desc fallback_desc = {\r\n.tfm = ctx->fallback,\r\n.info = desc->info,\r\n.flags = desc->flags\r\n};\r\nif (in_interrupt()) {\r\nret = crypto_blkcipher_encrypt(&fallback_desc, dst, src,\r\nnbytes);\r\n} else {\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nret = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\r\nwhile ((nbytes = walk.nbytes) >= AES_BLOCK_SIZE) {\r\npreempt_disable();\r\npagefault_disable();\r\nenable_kernel_vsx();\r\naes_p8_ctr32_encrypt_blocks(walk.src.virt.addr,\r\nwalk.dst.virt.addr,\r\n(nbytes &\r\nAES_BLOCK_MASK) /\r\nAES_BLOCK_SIZE,\r\n&ctx->enc_key,\r\nwalk.iv);\r\ndisable_kernel_vsx();\r\npagefault_enable();\r\npreempt_enable();\r\ninc = (nbytes & AES_BLOCK_MASK) / AES_BLOCK_SIZE;\r\nif (inc > 0)\r\nwhile (inc--)\r\ncrypto_inc(walk.iv, AES_BLOCK_SIZE);\r\nnbytes &= AES_BLOCK_SIZE - 1;\r\nret = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nif (walk.nbytes) {\r\np8_aes_ctr_final(ctx, &walk);\r\nret = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\n}\r\nreturn ret;\r\n}
