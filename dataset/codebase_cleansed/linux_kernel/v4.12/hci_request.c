void hci_req_init(struct hci_request *req, struct hci_dev *hdev)\r\n{\r\nskb_queue_head_init(&req->cmd_q);\r\nreq->hdev = hdev;\r\nreq->err = 0;\r\n}\r\nstatic int req_run(struct hci_request *req, hci_req_complete_t complete,\r\nhci_req_complete_skb_t complete_skb)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct sk_buff *skb;\r\nunsigned long flags;\r\nBT_DBG("length %u", skb_queue_len(&req->cmd_q));\r\nif (req->err) {\r\nskb_queue_purge(&req->cmd_q);\r\nreturn req->err;\r\n}\r\nif (skb_queue_empty(&req->cmd_q))\r\nreturn -ENODATA;\r\nskb = skb_peek_tail(&req->cmd_q);\r\nif (complete) {\r\nbt_cb(skb)->hci.req_complete = complete;\r\n} else if (complete_skb) {\r\nbt_cb(skb)->hci.req_complete_skb = complete_skb;\r\nbt_cb(skb)->hci.req_flags |= HCI_REQ_SKB;\r\n}\r\nspin_lock_irqsave(&hdev->cmd_q.lock, flags);\r\nskb_queue_splice_tail(&req->cmd_q, &hdev->cmd_q);\r\nspin_unlock_irqrestore(&hdev->cmd_q.lock, flags);\r\nqueue_work(hdev->workqueue, &hdev->cmd_work);\r\nreturn 0;\r\n}\r\nint hci_req_run(struct hci_request *req, hci_req_complete_t complete)\r\n{\r\nreturn req_run(req, complete, NULL);\r\n}\r\nint hci_req_run_skb(struct hci_request *req, hci_req_complete_skb_t complete)\r\n{\r\nreturn req_run(req, NULL, complete);\r\n}\r\nstatic void hci_req_sync_complete(struct hci_dev *hdev, u8 result, u16 opcode,\r\nstruct sk_buff *skb)\r\n{\r\nBT_DBG("%s result 0x%2.2x", hdev->name, result);\r\nif (hdev->req_status == HCI_REQ_PEND) {\r\nhdev->req_result = result;\r\nhdev->req_status = HCI_REQ_DONE;\r\nif (skb)\r\nhdev->req_skb = skb_get(skb);\r\nwake_up_interruptible(&hdev->req_wait_q);\r\n}\r\n}\r\nvoid hci_req_sync_cancel(struct hci_dev *hdev, int err)\r\n{\r\nBT_DBG("%s err 0x%2.2x", hdev->name, err);\r\nif (hdev->req_status == HCI_REQ_PEND) {\r\nhdev->req_result = err;\r\nhdev->req_status = HCI_REQ_CANCELED;\r\nwake_up_interruptible(&hdev->req_wait_q);\r\n}\r\n}\r\nstruct sk_buff *__hci_cmd_sync_ev(struct hci_dev *hdev, u16 opcode, u32 plen,\r\nconst void *param, u8 event, u32 timeout)\r\n{\r\nDECLARE_WAITQUEUE(wait, current);\r\nstruct hci_request req;\r\nstruct sk_buff *skb;\r\nint err = 0;\r\nBT_DBG("%s", hdev->name);\r\nhci_req_init(&req, hdev);\r\nhci_req_add_ev(&req, opcode, plen, param, event);\r\nhdev->req_status = HCI_REQ_PEND;\r\nadd_wait_queue(&hdev->req_wait_q, &wait);\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nerr = hci_req_run_skb(&req, hci_req_sync_complete);\r\nif (err < 0) {\r\nremove_wait_queue(&hdev->req_wait_q, &wait);\r\nset_current_state(TASK_RUNNING);\r\nreturn ERR_PTR(err);\r\n}\r\nschedule_timeout(timeout);\r\nremove_wait_queue(&hdev->req_wait_q, &wait);\r\nif (signal_pending(current))\r\nreturn ERR_PTR(-EINTR);\r\nswitch (hdev->req_status) {\r\ncase HCI_REQ_DONE:\r\nerr = -bt_to_errno(hdev->req_result);\r\nbreak;\r\ncase HCI_REQ_CANCELED:\r\nerr = -hdev->req_result;\r\nbreak;\r\ndefault:\r\nerr = -ETIMEDOUT;\r\nbreak;\r\n}\r\nhdev->req_status = hdev->req_result = 0;\r\nskb = hdev->req_skb;\r\nhdev->req_skb = NULL;\r\nBT_DBG("%s end: err %d", hdev->name, err);\r\nif (err < 0) {\r\nkfree_skb(skb);\r\nreturn ERR_PTR(err);\r\n}\r\nif (!skb)\r\nreturn ERR_PTR(-ENODATA);\r\nreturn skb;\r\n}\r\nstruct sk_buff *__hci_cmd_sync(struct hci_dev *hdev, u16 opcode, u32 plen,\r\nconst void *param, u32 timeout)\r\n{\r\nreturn __hci_cmd_sync_ev(hdev, opcode, plen, param, 0, timeout);\r\n}\r\nint __hci_req_sync(struct hci_dev *hdev, int (*func)(struct hci_request *req,\r\nunsigned long opt),\r\nunsigned long opt, u32 timeout, u8 *hci_status)\r\n{\r\nstruct hci_request req;\r\nDECLARE_WAITQUEUE(wait, current);\r\nint err = 0;\r\nBT_DBG("%s start", hdev->name);\r\nhci_req_init(&req, hdev);\r\nhdev->req_status = HCI_REQ_PEND;\r\nerr = func(&req, opt);\r\nif (err) {\r\nif (hci_status)\r\n*hci_status = HCI_ERROR_UNSPECIFIED;\r\nreturn err;\r\n}\r\nadd_wait_queue(&hdev->req_wait_q, &wait);\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nerr = hci_req_run_skb(&req, hci_req_sync_complete);\r\nif (err < 0) {\r\nhdev->req_status = 0;\r\nremove_wait_queue(&hdev->req_wait_q, &wait);\r\nset_current_state(TASK_RUNNING);\r\nif (err == -ENODATA) {\r\nif (hci_status)\r\n*hci_status = 0;\r\nreturn 0;\r\n}\r\nif (hci_status)\r\n*hci_status = HCI_ERROR_UNSPECIFIED;\r\nreturn err;\r\n}\r\nschedule_timeout(timeout);\r\nremove_wait_queue(&hdev->req_wait_q, &wait);\r\nif (signal_pending(current))\r\nreturn -EINTR;\r\nswitch (hdev->req_status) {\r\ncase HCI_REQ_DONE:\r\nerr = -bt_to_errno(hdev->req_result);\r\nif (hci_status)\r\n*hci_status = hdev->req_result;\r\nbreak;\r\ncase HCI_REQ_CANCELED:\r\nerr = -hdev->req_result;\r\nif (hci_status)\r\n*hci_status = HCI_ERROR_UNSPECIFIED;\r\nbreak;\r\ndefault:\r\nerr = -ETIMEDOUT;\r\nif (hci_status)\r\n*hci_status = HCI_ERROR_UNSPECIFIED;\r\nbreak;\r\n}\r\nkfree_skb(hdev->req_skb);\r\nhdev->req_skb = NULL;\r\nhdev->req_status = hdev->req_result = 0;\r\nBT_DBG("%s end: err %d", hdev->name, err);\r\nreturn err;\r\n}\r\nint hci_req_sync(struct hci_dev *hdev, int (*req)(struct hci_request *req,\r\nunsigned long opt),\r\nunsigned long opt, u32 timeout, u8 *hci_status)\r\n{\r\nint ret;\r\nif (!test_bit(HCI_UP, &hdev->flags))\r\nreturn -ENETDOWN;\r\nhci_req_sync_lock(hdev);\r\nret = __hci_req_sync(hdev, req, opt, timeout, hci_status);\r\nhci_req_sync_unlock(hdev);\r\nreturn ret;\r\n}\r\nstruct sk_buff *hci_prepare_cmd(struct hci_dev *hdev, u16 opcode, u32 plen,\r\nconst void *param)\r\n{\r\nint len = HCI_COMMAND_HDR_SIZE + plen;\r\nstruct hci_command_hdr *hdr;\r\nstruct sk_buff *skb;\r\nskb = bt_skb_alloc(len, GFP_ATOMIC);\r\nif (!skb)\r\nreturn NULL;\r\nhdr = (struct hci_command_hdr *) skb_put(skb, HCI_COMMAND_HDR_SIZE);\r\nhdr->opcode = cpu_to_le16(opcode);\r\nhdr->plen = plen;\r\nif (plen)\r\nmemcpy(skb_put(skb, plen), param, plen);\r\nBT_DBG("skb len %d", skb->len);\r\nhci_skb_pkt_type(skb) = HCI_COMMAND_PKT;\r\nhci_skb_opcode(skb) = opcode;\r\nreturn skb;\r\n}\r\nvoid hci_req_add_ev(struct hci_request *req, u16 opcode, u32 plen,\r\nconst void *param, u8 event)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct sk_buff *skb;\r\nBT_DBG("%s opcode 0x%4.4x plen %d", hdev->name, opcode, plen);\r\nif (req->err)\r\nreturn;\r\nskb = hci_prepare_cmd(hdev, opcode, plen, param);\r\nif (!skb) {\r\nBT_ERR("%s no memory for command (opcode 0x%4.4x)",\r\nhdev->name, opcode);\r\nreq->err = -ENOMEM;\r\nreturn;\r\n}\r\nif (skb_queue_empty(&req->cmd_q))\r\nbt_cb(skb)->hci.req_flags |= HCI_REQ_START;\r\nbt_cb(skb)->hci.req_event = event;\r\nskb_queue_tail(&req->cmd_q, skb);\r\n}\r\nvoid hci_req_add(struct hci_request *req, u16 opcode, u32 plen,\r\nconst void *param)\r\n{\r\nhci_req_add_ev(req, opcode, plen, param, 0);\r\n}\r\nvoid __hci_req_write_fast_connectable(struct hci_request *req, bool enable)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_write_page_scan_activity acp;\r\nu8 type;\r\nif (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED))\r\nreturn;\r\nif (hdev->hci_ver < BLUETOOTH_VER_1_2)\r\nreturn;\r\nif (enable) {\r\ntype = PAGE_SCAN_TYPE_INTERLACED;\r\nacp.interval = cpu_to_le16(0x0100);\r\n} else {\r\ntype = PAGE_SCAN_TYPE_STANDARD;\r\nacp.interval = cpu_to_le16(0x0800);\r\n}\r\nacp.window = cpu_to_le16(0x0012);\r\nif (__cpu_to_le16(hdev->page_scan_interval) != acp.interval ||\r\n__cpu_to_le16(hdev->page_scan_window) != acp.window)\r\nhci_req_add(req, HCI_OP_WRITE_PAGE_SCAN_ACTIVITY,\r\nsizeof(acp), &acp);\r\nif (hdev->page_scan_type != type)\r\nhci_req_add(req, HCI_OP_WRITE_PAGE_SCAN_TYPE, 1, &type);\r\n}\r\nstatic void __hci_update_background_scan(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nif (!test_bit(HCI_UP, &hdev->flags) ||\r\ntest_bit(HCI_INIT, &hdev->flags) ||\r\nhci_dev_test_flag(hdev, HCI_SETUP) ||\r\nhci_dev_test_flag(hdev, HCI_CONFIG) ||\r\nhci_dev_test_flag(hdev, HCI_AUTO_OFF) ||\r\nhci_dev_test_flag(hdev, HCI_UNREGISTER))\r\nreturn;\r\nif (!hci_dev_test_flag(hdev, HCI_LE_ENABLED))\r\nreturn;\r\nif (hdev->discovery.state != DISCOVERY_STOPPED)\r\nreturn;\r\nhci_discovery_filter_clear(hdev);\r\nif (list_empty(&hdev->pend_le_conns) &&\r\nlist_empty(&hdev->pend_le_reports)) {\r\nif (!hci_dev_test_flag(hdev, HCI_LE_SCAN))\r\nreturn;\r\nhci_req_add_le_scan_disable(req);\r\nBT_DBG("%s stopping background scanning", hdev->name);\r\n} else {\r\nif (hci_lookup_le_connect(hdev))\r\nreturn;\r\nif (hci_dev_test_flag(hdev, HCI_LE_SCAN))\r\nhci_req_add_le_scan_disable(req);\r\nhci_req_add_le_passive_scan(req);\r\nBT_DBG("%s starting background scanning", hdev->name);\r\n}\r\n}\r\nvoid __hci_req_update_name(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_write_local_name cp;\r\nmemcpy(cp.name, hdev->dev_name, sizeof(cp.name));\r\nhci_req_add(req, HCI_OP_WRITE_LOCAL_NAME, sizeof(cp), &cp);\r\n}\r\nstatic u8 *create_uuid16_list(struct hci_dev *hdev, u8 *data, ptrdiff_t len)\r\n{\r\nu8 *ptr = data, *uuids_start = NULL;\r\nstruct bt_uuid *uuid;\r\nif (len < 4)\r\nreturn ptr;\r\nlist_for_each_entry(uuid, &hdev->uuids, list) {\r\nu16 uuid16;\r\nif (uuid->size != 16)\r\ncontinue;\r\nuuid16 = get_unaligned_le16(&uuid->uuid[12]);\r\nif (uuid16 < 0x1100)\r\ncontinue;\r\nif (uuid16 == PNP_INFO_SVCLASS_ID)\r\ncontinue;\r\nif (!uuids_start) {\r\nuuids_start = ptr;\r\nuuids_start[0] = 1;\r\nuuids_start[1] = EIR_UUID16_ALL;\r\nptr += 2;\r\n}\r\nif ((ptr - data) + sizeof(u16) > len) {\r\nuuids_start[1] = EIR_UUID16_SOME;\r\nbreak;\r\n}\r\n*ptr++ = (uuid16 & 0x00ff);\r\n*ptr++ = (uuid16 & 0xff00) >> 8;\r\nuuids_start[0] += sizeof(uuid16);\r\n}\r\nreturn ptr;\r\n}\r\nstatic u8 *create_uuid32_list(struct hci_dev *hdev, u8 *data, ptrdiff_t len)\r\n{\r\nu8 *ptr = data, *uuids_start = NULL;\r\nstruct bt_uuid *uuid;\r\nif (len < 6)\r\nreturn ptr;\r\nlist_for_each_entry(uuid, &hdev->uuids, list) {\r\nif (uuid->size != 32)\r\ncontinue;\r\nif (!uuids_start) {\r\nuuids_start = ptr;\r\nuuids_start[0] = 1;\r\nuuids_start[1] = EIR_UUID32_ALL;\r\nptr += 2;\r\n}\r\nif ((ptr - data) + sizeof(u32) > len) {\r\nuuids_start[1] = EIR_UUID32_SOME;\r\nbreak;\r\n}\r\nmemcpy(ptr, &uuid->uuid[12], sizeof(u32));\r\nptr += sizeof(u32);\r\nuuids_start[0] += sizeof(u32);\r\n}\r\nreturn ptr;\r\n}\r\nstatic u8 *create_uuid128_list(struct hci_dev *hdev, u8 *data, ptrdiff_t len)\r\n{\r\nu8 *ptr = data, *uuids_start = NULL;\r\nstruct bt_uuid *uuid;\r\nif (len < 18)\r\nreturn ptr;\r\nlist_for_each_entry(uuid, &hdev->uuids, list) {\r\nif (uuid->size != 128)\r\ncontinue;\r\nif (!uuids_start) {\r\nuuids_start = ptr;\r\nuuids_start[0] = 1;\r\nuuids_start[1] = EIR_UUID128_ALL;\r\nptr += 2;\r\n}\r\nif ((ptr - data) + 16 > len) {\r\nuuids_start[1] = EIR_UUID128_SOME;\r\nbreak;\r\n}\r\nmemcpy(ptr, uuid->uuid, 16);\r\nptr += 16;\r\nuuids_start[0] += 16;\r\n}\r\nreturn ptr;\r\n}\r\nstatic void create_eir(struct hci_dev *hdev, u8 *data)\r\n{\r\nu8 *ptr = data;\r\nsize_t name_len;\r\nname_len = strlen(hdev->dev_name);\r\nif (name_len > 0) {\r\nif (name_len > 48) {\r\nname_len = 48;\r\nptr[1] = EIR_NAME_SHORT;\r\n} else\r\nptr[1] = EIR_NAME_COMPLETE;\r\nptr[0] = name_len + 1;\r\nmemcpy(ptr + 2, hdev->dev_name, name_len);\r\nptr += (name_len + 2);\r\n}\r\nif (hdev->inq_tx_power != HCI_TX_POWER_INVALID) {\r\nptr[0] = 2;\r\nptr[1] = EIR_TX_POWER;\r\nptr[2] = (u8) hdev->inq_tx_power;\r\nptr += 3;\r\n}\r\nif (hdev->devid_source > 0) {\r\nptr[0] = 9;\r\nptr[1] = EIR_DEVICE_ID;\r\nput_unaligned_le16(hdev->devid_source, ptr + 2);\r\nput_unaligned_le16(hdev->devid_vendor, ptr + 4);\r\nput_unaligned_le16(hdev->devid_product, ptr + 6);\r\nput_unaligned_le16(hdev->devid_version, ptr + 8);\r\nptr += 10;\r\n}\r\nptr = create_uuid16_list(hdev, ptr, HCI_MAX_EIR_LENGTH - (ptr - data));\r\nptr = create_uuid32_list(hdev, ptr, HCI_MAX_EIR_LENGTH - (ptr - data));\r\nptr = create_uuid128_list(hdev, ptr, HCI_MAX_EIR_LENGTH - (ptr - data));\r\n}\r\nvoid __hci_req_update_eir(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_write_eir cp;\r\nif (!hdev_is_powered(hdev))\r\nreturn;\r\nif (!lmp_ext_inq_capable(hdev))\r\nreturn;\r\nif (!hci_dev_test_flag(hdev, HCI_SSP_ENABLED))\r\nreturn;\r\nif (hci_dev_test_flag(hdev, HCI_SERVICE_CACHE))\r\nreturn;\r\nmemset(&cp, 0, sizeof(cp));\r\ncreate_eir(hdev, cp.data);\r\nif (memcmp(cp.data, hdev->eir, sizeof(cp.data)) == 0)\r\nreturn;\r\nmemcpy(hdev->eir, cp.data, sizeof(cp.data));\r\nhci_req_add(req, HCI_OP_WRITE_EIR, sizeof(cp), &cp);\r\n}\r\nvoid hci_req_add_le_scan_disable(struct hci_request *req)\r\n{\r\nstruct hci_cp_le_set_scan_enable cp;\r\nmemset(&cp, 0, sizeof(cp));\r\ncp.enable = LE_SCAN_DISABLE;\r\nhci_req_add(req, HCI_OP_LE_SET_SCAN_ENABLE, sizeof(cp), &cp);\r\n}\r\nstatic void add_to_white_list(struct hci_request *req,\r\nstruct hci_conn_params *params)\r\n{\r\nstruct hci_cp_le_add_to_white_list cp;\r\ncp.bdaddr_type = params->addr_type;\r\nbacpy(&cp.bdaddr, &params->addr);\r\nhci_req_add(req, HCI_OP_LE_ADD_TO_WHITE_LIST, sizeof(cp), &cp);\r\n}\r\nstatic u8 update_white_list(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_conn_params *params;\r\nstruct bdaddr_list *b;\r\nuint8_t white_list_entries = 0;\r\nlist_for_each_entry(b, &hdev->le_white_list, list) {\r\nif (!hci_pend_le_action_lookup(&hdev->pend_le_conns,\r\n&b->bdaddr, b->bdaddr_type) &&\r\n!hci_pend_le_action_lookup(&hdev->pend_le_reports,\r\n&b->bdaddr, b->bdaddr_type)) {\r\nstruct hci_cp_le_del_from_white_list cp;\r\ncp.bdaddr_type = b->bdaddr_type;\r\nbacpy(&cp.bdaddr, &b->bdaddr);\r\nhci_req_add(req, HCI_OP_LE_DEL_FROM_WHITE_LIST,\r\nsizeof(cp), &cp);\r\ncontinue;\r\n}\r\nif (hci_find_irk_by_addr(hdev, &b->bdaddr, b->bdaddr_type)) {\r\nreturn 0x00;\r\n}\r\nwhite_list_entries++;\r\n}\r\nlist_for_each_entry(params, &hdev->pend_le_conns, action) {\r\nif (hci_bdaddr_list_lookup(&hdev->le_white_list,\r\n&params->addr, params->addr_type))\r\ncontinue;\r\nif (white_list_entries >= hdev->le_white_list_size) {\r\nreturn 0x00;\r\n}\r\nif (hci_find_irk_by_addr(hdev, &params->addr,\r\nparams->addr_type)) {\r\nreturn 0x00;\r\n}\r\nwhite_list_entries++;\r\nadd_to_white_list(req, params);\r\n}\r\nlist_for_each_entry(params, &hdev->pend_le_reports, action) {\r\nif (hci_bdaddr_list_lookup(&hdev->le_white_list,\r\n&params->addr, params->addr_type))\r\ncontinue;\r\nif (white_list_entries >= hdev->le_white_list_size) {\r\nreturn 0x00;\r\n}\r\nif (hci_find_irk_by_addr(hdev, &params->addr,\r\nparams->addr_type)) {\r\nreturn 0x00;\r\n}\r\nwhite_list_entries++;\r\nadd_to_white_list(req, params);\r\n}\r\nreturn 0x01;\r\n}\r\nstatic bool scan_use_rpa(struct hci_dev *hdev)\r\n{\r\nreturn hci_dev_test_flag(hdev, HCI_PRIVACY);\r\n}\r\nvoid hci_req_add_le_passive_scan(struct hci_request *req)\r\n{\r\nstruct hci_cp_le_set_scan_param param_cp;\r\nstruct hci_cp_le_set_scan_enable enable_cp;\r\nstruct hci_dev *hdev = req->hdev;\r\nu8 own_addr_type;\r\nu8 filter_policy;\r\nif (hci_update_random_address(req, false, scan_use_rpa(hdev),\r\n&own_addr_type))\r\nreturn;\r\nfilter_policy = update_white_list(req);\r\nif (hci_dev_test_flag(hdev, HCI_PRIVACY) &&\r\n(hdev->le_features[0] & HCI_LE_EXT_SCAN_POLICY))\r\nfilter_policy |= 0x02;\r\nmemset(&param_cp, 0, sizeof(param_cp));\r\nparam_cp.type = LE_SCAN_PASSIVE;\r\nparam_cp.interval = cpu_to_le16(hdev->le_scan_interval);\r\nparam_cp.window = cpu_to_le16(hdev->le_scan_window);\r\nparam_cp.own_address_type = own_addr_type;\r\nparam_cp.filter_policy = filter_policy;\r\nhci_req_add(req, HCI_OP_LE_SET_SCAN_PARAM, sizeof(param_cp),\r\n&param_cp);\r\nmemset(&enable_cp, 0, sizeof(enable_cp));\r\nenable_cp.enable = LE_SCAN_ENABLE;\r\nenable_cp.filter_dup = LE_SCAN_FILTER_DUP_ENABLE;\r\nhci_req_add(req, HCI_OP_LE_SET_SCAN_ENABLE, sizeof(enable_cp),\r\n&enable_cp);\r\n}\r\nstatic u8 get_cur_adv_instance_scan_rsp_len(struct hci_dev *hdev)\r\n{\r\nu8 instance = hdev->cur_adv_instance;\r\nstruct adv_info *adv_instance;\r\nif (instance == 0x00)\r\nreturn 0;\r\nadv_instance = hci_find_adv_instance(hdev, instance);\r\nif (!adv_instance)\r\nreturn 0;\r\nreturn adv_instance->scan_rsp_len;\r\n}\r\nvoid __hci_req_disable_advertising(struct hci_request *req)\r\n{\r\nu8 enable = 0x00;\r\nhci_req_add(req, HCI_OP_LE_SET_ADV_ENABLE, sizeof(enable), &enable);\r\n}\r\nstatic u32 get_adv_instance_flags(struct hci_dev *hdev, u8 instance)\r\n{\r\nu32 flags;\r\nstruct adv_info *adv_instance;\r\nif (instance == 0x00) {\r\nflags = MGMT_ADV_FLAG_TX_POWER | MGMT_ADV_FLAG_MANAGED_FLAGS;\r\nif (hci_dev_test_flag(hdev, HCI_ADVERTISING_CONNECTABLE))\r\nflags |= MGMT_ADV_FLAG_CONNECTABLE;\r\nif (hci_dev_test_flag(hdev, HCI_LIMITED_DISCOVERABLE))\r\nflags |= MGMT_ADV_FLAG_LIMITED_DISCOV;\r\nelse if (hci_dev_test_flag(hdev, HCI_DISCOVERABLE))\r\nflags |= MGMT_ADV_FLAG_DISCOV;\r\nreturn flags;\r\n}\r\nadv_instance = hci_find_adv_instance(hdev, instance);\r\nif (!adv_instance)\r\nreturn 0;\r\nreturn adv_instance->flags;\r\n}\r\nstatic bool adv_use_rpa(struct hci_dev *hdev, uint32_t flags)\r\n{\r\nif (!hci_dev_test_flag(hdev, HCI_PRIVACY))\r\nreturn false;\r\nif (!hci_dev_test_flag(hdev, HCI_LIMITED_PRIVACY))\r\nreturn true;\r\nif ((flags & MGMT_ADV_FLAG_DISCOV) &&\r\nhci_dev_test_flag(hdev, HCI_BONDABLE))\r\nreturn false;\r\nreturn true;\r\n}\r\nvoid __hci_req_enable_advertising(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_le_set_adv_param cp;\r\nu8 own_addr_type, enable = 0x01;\r\nbool connectable;\r\nu32 flags;\r\nif (hci_conn_num(hdev, LE_LINK) > 0)\r\nreturn;\r\nif (hci_dev_test_flag(hdev, HCI_LE_ADV))\r\n__hci_req_disable_advertising(req);\r\nhci_dev_clear_flag(hdev, HCI_LE_ADV);\r\nflags = get_adv_instance_flags(hdev, hdev->cur_adv_instance);\r\nconnectable = (flags & MGMT_ADV_FLAG_CONNECTABLE) ||\r\nmgmt_get_connectable(hdev);\r\nif (hci_update_random_address(req, !connectable,\r\nadv_use_rpa(hdev, flags),\r\n&own_addr_type) < 0)\r\nreturn;\r\nmemset(&cp, 0, sizeof(cp));\r\ncp.min_interval = cpu_to_le16(hdev->le_adv_min_interval);\r\ncp.max_interval = cpu_to_le16(hdev->le_adv_max_interval);\r\nif (connectable)\r\ncp.type = LE_ADV_IND;\r\nelse if (get_cur_adv_instance_scan_rsp_len(hdev))\r\ncp.type = LE_ADV_SCAN_IND;\r\nelse\r\ncp.type = LE_ADV_NONCONN_IND;\r\ncp.own_address_type = own_addr_type;\r\ncp.channel_map = hdev->le_adv_channel_map;\r\nhci_req_add(req, HCI_OP_LE_SET_ADV_PARAM, sizeof(cp), &cp);\r\nhci_req_add(req, HCI_OP_LE_SET_ADV_ENABLE, sizeof(enable), &enable);\r\n}\r\nu8 append_local_name(struct hci_dev *hdev, u8 *ptr, u8 ad_len)\r\n{\r\nsize_t short_len;\r\nsize_t complete_len;\r\nif ((HCI_MAX_AD_LENGTH - ad_len) < HCI_MAX_SHORT_NAME_LENGTH + 3)\r\nreturn ad_len;\r\ncomplete_len = strlen(hdev->dev_name);\r\nif (complete_len && complete_len <= HCI_MAX_SHORT_NAME_LENGTH)\r\nreturn eir_append_data(ptr, ad_len, EIR_NAME_COMPLETE,\r\nhdev->dev_name, complete_len + 1);\r\nshort_len = strlen(hdev->short_name);\r\nif (short_len)\r\nreturn eir_append_data(ptr, ad_len, EIR_NAME_SHORT,\r\nhdev->short_name, short_len + 1);\r\nif (complete_len) {\r\nu8 name[HCI_MAX_SHORT_NAME_LENGTH + 1];\r\nmemcpy(name, hdev->dev_name, HCI_MAX_SHORT_NAME_LENGTH);\r\nname[HCI_MAX_SHORT_NAME_LENGTH] = '\0';\r\nreturn eir_append_data(ptr, ad_len, EIR_NAME_SHORT, name,\r\nsizeof(name));\r\n}\r\nreturn ad_len;\r\n}\r\nstatic u8 append_appearance(struct hci_dev *hdev, u8 *ptr, u8 ad_len)\r\n{\r\nreturn eir_append_le16(ptr, ad_len, EIR_APPEARANCE, hdev->appearance);\r\n}\r\nstatic u8 create_default_scan_rsp_data(struct hci_dev *hdev, u8 *ptr)\r\n{\r\nu8 scan_rsp_len = 0;\r\nif (hdev->appearance) {\r\nscan_rsp_len = append_appearance(hdev, ptr, scan_rsp_len);\r\n}\r\nreturn append_local_name(hdev, ptr, scan_rsp_len);\r\n}\r\nstatic u8 create_instance_scan_rsp_data(struct hci_dev *hdev, u8 instance,\r\nu8 *ptr)\r\n{\r\nstruct adv_info *adv_instance;\r\nu32 instance_flags;\r\nu8 scan_rsp_len = 0;\r\nadv_instance = hci_find_adv_instance(hdev, instance);\r\nif (!adv_instance)\r\nreturn 0;\r\ninstance_flags = adv_instance->flags;\r\nif ((instance_flags & MGMT_ADV_FLAG_APPEARANCE) && hdev->appearance) {\r\nscan_rsp_len = append_appearance(hdev, ptr, scan_rsp_len);\r\n}\r\nmemcpy(&ptr[scan_rsp_len], adv_instance->scan_rsp_data,\r\nadv_instance->scan_rsp_len);\r\nscan_rsp_len += adv_instance->scan_rsp_len;\r\nif (instance_flags & MGMT_ADV_FLAG_LOCAL_NAME)\r\nscan_rsp_len = append_local_name(hdev, ptr, scan_rsp_len);\r\nreturn scan_rsp_len;\r\n}\r\nvoid __hci_req_update_scan_rsp_data(struct hci_request *req, u8 instance)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_le_set_scan_rsp_data cp;\r\nu8 len;\r\nif (!hci_dev_test_flag(hdev, HCI_LE_ENABLED))\r\nreturn;\r\nmemset(&cp, 0, sizeof(cp));\r\nif (instance)\r\nlen = create_instance_scan_rsp_data(hdev, instance, cp.data);\r\nelse\r\nlen = create_default_scan_rsp_data(hdev, cp.data);\r\nif (hdev->scan_rsp_data_len == len &&\r\n!memcmp(cp.data, hdev->scan_rsp_data, len))\r\nreturn;\r\nmemcpy(hdev->scan_rsp_data, cp.data, sizeof(cp.data));\r\nhdev->scan_rsp_data_len = len;\r\ncp.length = len;\r\nhci_req_add(req, HCI_OP_LE_SET_SCAN_RSP_DATA, sizeof(cp), &cp);\r\n}\r\nstatic u8 create_instance_adv_data(struct hci_dev *hdev, u8 instance, u8 *ptr)\r\n{\r\nstruct adv_info *adv_instance = NULL;\r\nu8 ad_len = 0, flags = 0;\r\nu32 instance_flags;\r\nif (instance) {\r\nadv_instance = hci_find_adv_instance(hdev, instance);\r\nif (!adv_instance)\r\nreturn 0;\r\n}\r\ninstance_flags = get_adv_instance_flags(hdev, instance);\r\nif (instance_flags & MGMT_ADV_FLAG_DISCOV)\r\nflags |= LE_AD_GENERAL;\r\nif (instance_flags & MGMT_ADV_FLAG_LIMITED_DISCOV)\r\nflags |= LE_AD_LIMITED;\r\nif (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED))\r\nflags |= LE_AD_NO_BREDR;\r\nif (flags || (instance_flags & MGMT_ADV_FLAG_MANAGED_FLAGS)) {\r\nif (!flags)\r\nflags |= mgmt_get_adv_discov_flags(hdev);\r\nif (flags) {\r\nptr[0] = 0x02;\r\nptr[1] = EIR_FLAGS;\r\nptr[2] = flags;\r\nad_len += 3;\r\nptr += 3;\r\n}\r\n}\r\nif (adv_instance) {\r\nmemcpy(ptr, adv_instance->adv_data,\r\nadv_instance->adv_data_len);\r\nad_len += adv_instance->adv_data_len;\r\nptr += adv_instance->adv_data_len;\r\n}\r\nif (hdev->adv_tx_power != HCI_TX_POWER_INVALID &&\r\n(instance_flags & MGMT_ADV_FLAG_TX_POWER)) {\r\nptr[0] = 0x02;\r\nptr[1] = EIR_TX_POWER;\r\nptr[2] = (u8)hdev->adv_tx_power;\r\nad_len += 3;\r\nptr += 3;\r\n}\r\nreturn ad_len;\r\n}\r\nvoid __hci_req_update_adv_data(struct hci_request *req, u8 instance)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_le_set_adv_data cp;\r\nu8 len;\r\nif (!hci_dev_test_flag(hdev, HCI_LE_ENABLED))\r\nreturn;\r\nmemset(&cp, 0, sizeof(cp));\r\nlen = create_instance_adv_data(hdev, instance, cp.data);\r\nif (hdev->adv_data_len == len &&\r\nmemcmp(cp.data, hdev->adv_data, len) == 0)\r\nreturn;\r\nmemcpy(hdev->adv_data, cp.data, sizeof(cp.data));\r\nhdev->adv_data_len = len;\r\ncp.length = len;\r\nhci_req_add(req, HCI_OP_LE_SET_ADV_DATA, sizeof(cp), &cp);\r\n}\r\nint hci_req_update_adv_data(struct hci_dev *hdev, u8 instance)\r\n{\r\nstruct hci_request req;\r\nhci_req_init(&req, hdev);\r\n__hci_req_update_adv_data(&req, instance);\r\nreturn hci_req_run(&req, NULL);\r\n}\r\nstatic void adv_enable_complete(struct hci_dev *hdev, u8 status, u16 opcode)\r\n{\r\nBT_DBG("%s status %u", hdev->name, status);\r\n}\r\nvoid hci_req_reenable_advertising(struct hci_dev *hdev)\r\n{\r\nstruct hci_request req;\r\nif (!hci_dev_test_flag(hdev, HCI_ADVERTISING) &&\r\nlist_empty(&hdev->adv_instances))\r\nreturn;\r\nhci_req_init(&req, hdev);\r\nif (hdev->cur_adv_instance) {\r\n__hci_req_schedule_adv_instance(&req, hdev->cur_adv_instance,\r\ntrue);\r\n} else {\r\n__hci_req_update_adv_data(&req, 0x00);\r\n__hci_req_update_scan_rsp_data(&req, 0x00);\r\n__hci_req_enable_advertising(&req);\r\n}\r\nhci_req_run(&req, adv_enable_complete);\r\n}\r\nstatic void adv_timeout_expire(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\nadv_instance_expire.work);\r\nstruct hci_request req;\r\nu8 instance;\r\nBT_DBG("%s", hdev->name);\r\nhci_dev_lock(hdev);\r\nhdev->adv_instance_timeout = 0;\r\ninstance = hdev->cur_adv_instance;\r\nif (instance == 0x00)\r\ngoto unlock;\r\nhci_req_init(&req, hdev);\r\nhci_req_clear_adv_instance(hdev, NULL, &req, instance, false);\r\nif (list_empty(&hdev->adv_instances))\r\n__hci_req_disable_advertising(&req);\r\nhci_req_run(&req, NULL);\r\nunlock:\r\nhci_dev_unlock(hdev);\r\n}\r\nint __hci_req_schedule_adv_instance(struct hci_request *req, u8 instance,\r\nbool force)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct adv_info *adv_instance = NULL;\r\nu16 timeout;\r\nif (hci_dev_test_flag(hdev, HCI_ADVERTISING) ||\r\nlist_empty(&hdev->adv_instances))\r\nreturn -EPERM;\r\nif (hdev->adv_instance_timeout)\r\nreturn -EBUSY;\r\nadv_instance = hci_find_adv_instance(hdev, instance);\r\nif (!adv_instance)\r\nreturn -ENOENT;\r\nif (adv_instance->timeout == 0 ||\r\nadv_instance->duration <= adv_instance->remaining_time)\r\ntimeout = adv_instance->duration;\r\nelse\r\ntimeout = adv_instance->remaining_time;\r\nif (adv_instance->timeout)\r\nadv_instance->remaining_time =\r\nadv_instance->remaining_time - timeout;\r\nhdev->adv_instance_timeout = timeout;\r\nqueue_delayed_work(hdev->req_workqueue,\r\n&hdev->adv_instance_expire,\r\nmsecs_to_jiffies(timeout * 1000));\r\nif (!force && hdev->cur_adv_instance == instance &&\r\nhci_dev_test_flag(hdev, HCI_LE_ADV))\r\nreturn 0;\r\nhdev->cur_adv_instance = instance;\r\n__hci_req_update_adv_data(req, instance);\r\n__hci_req_update_scan_rsp_data(req, instance);\r\n__hci_req_enable_advertising(req);\r\nreturn 0;\r\n}\r\nstatic void cancel_adv_timeout(struct hci_dev *hdev)\r\n{\r\nif (hdev->adv_instance_timeout) {\r\nhdev->adv_instance_timeout = 0;\r\ncancel_delayed_work(&hdev->adv_instance_expire);\r\n}\r\n}\r\nvoid hci_req_clear_adv_instance(struct hci_dev *hdev, struct sock *sk,\r\nstruct hci_request *req, u8 instance,\r\nbool force)\r\n{\r\nstruct adv_info *adv_instance, *n, *next_instance = NULL;\r\nint err;\r\nu8 rem_inst;\r\nif (!instance || hdev->cur_adv_instance == instance)\r\ncancel_adv_timeout(hdev);\r\nif (instance && hdev->cur_adv_instance == instance)\r\nnext_instance = hci_get_next_instance(hdev, instance);\r\nif (instance == 0x00) {\r\nlist_for_each_entry_safe(adv_instance, n, &hdev->adv_instances,\r\nlist) {\r\nif (!(force || adv_instance->timeout))\r\ncontinue;\r\nrem_inst = adv_instance->instance;\r\nerr = hci_remove_adv_instance(hdev, rem_inst);\r\nif (!err)\r\nmgmt_advertising_removed(sk, hdev, rem_inst);\r\n}\r\n} else {\r\nadv_instance = hci_find_adv_instance(hdev, instance);\r\nif (force || (adv_instance && adv_instance->timeout &&\r\n!adv_instance->remaining_time)) {\r\nif (next_instance &&\r\nnext_instance->instance == instance)\r\nnext_instance = NULL;\r\nerr = hci_remove_adv_instance(hdev, instance);\r\nif (!err)\r\nmgmt_advertising_removed(sk, hdev, instance);\r\n}\r\n}\r\nif (!req || !hdev_is_powered(hdev) ||\r\nhci_dev_test_flag(hdev, HCI_ADVERTISING))\r\nreturn;\r\nif (next_instance)\r\n__hci_req_schedule_adv_instance(req, next_instance->instance,\r\nfalse);\r\n}\r\nstatic void set_random_addr(struct hci_request *req, bdaddr_t *rpa)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nif (hci_dev_test_flag(hdev, HCI_LE_ADV) ||\r\nhci_lookup_le_connect(hdev)) {\r\nBT_DBG("Deferring random address update");\r\nhci_dev_set_flag(hdev, HCI_RPA_EXPIRED);\r\nreturn;\r\n}\r\nhci_req_add(req, HCI_OP_LE_SET_RANDOM_ADDR, 6, rpa);\r\n}\r\nint hci_update_random_address(struct hci_request *req, bool require_privacy,\r\nbool use_rpa, u8 *own_addr_type)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nint err;\r\nif (use_rpa) {\r\nint to;\r\n*own_addr_type = ADDR_LE_DEV_RANDOM;\r\nif (!hci_dev_test_and_clear_flag(hdev, HCI_RPA_EXPIRED) &&\r\n!bacmp(&hdev->random_addr, &hdev->rpa))\r\nreturn 0;\r\nerr = smp_generate_rpa(hdev, hdev->irk, &hdev->rpa);\r\nif (err < 0) {\r\nBT_ERR("%s failed to generate new RPA", hdev->name);\r\nreturn err;\r\n}\r\nset_random_addr(req, &hdev->rpa);\r\nto = msecs_to_jiffies(hdev->rpa_timeout * 1000);\r\nqueue_delayed_work(hdev->workqueue, &hdev->rpa_expired, to);\r\nreturn 0;\r\n}\r\nif (require_privacy) {\r\nbdaddr_t nrpa;\r\nwhile (true) {\r\nget_random_bytes(&nrpa, 6);\r\nnrpa.b[5] &= 0x3f;\r\nif (bacmp(&hdev->bdaddr, &nrpa))\r\nbreak;\r\n}\r\n*own_addr_type = ADDR_LE_DEV_RANDOM;\r\nset_random_addr(req, &nrpa);\r\nreturn 0;\r\n}\r\nif (hci_dev_test_flag(hdev, HCI_FORCE_STATIC_ADDR) ||\r\n!bacmp(&hdev->bdaddr, BDADDR_ANY) ||\r\n(!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED) &&\r\nbacmp(&hdev->static_addr, BDADDR_ANY))) {\r\n*own_addr_type = ADDR_LE_DEV_RANDOM;\r\nif (bacmp(&hdev->static_addr, &hdev->random_addr))\r\nhci_req_add(req, HCI_OP_LE_SET_RANDOM_ADDR, 6,\r\n&hdev->static_addr);\r\nreturn 0;\r\n}\r\n*own_addr_type = ADDR_LE_DEV_PUBLIC;\r\nreturn 0;\r\n}\r\nstatic bool disconnected_whitelist_entries(struct hci_dev *hdev)\r\n{\r\nstruct bdaddr_list *b;\r\nlist_for_each_entry(b, &hdev->whitelist, list) {\r\nstruct hci_conn *conn;\r\nconn = hci_conn_hash_lookup_ba(hdev, ACL_LINK, &b->bdaddr);\r\nif (!conn)\r\nreturn true;\r\nif (conn->state != BT_CONNECTED && conn->state != BT_CONFIG)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nvoid __hci_req_update_scan(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nu8 scan;\r\nif (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED))\r\nreturn;\r\nif (!hdev_is_powered(hdev))\r\nreturn;\r\nif (mgmt_powering_down(hdev))\r\nreturn;\r\nif (hci_dev_test_flag(hdev, HCI_CONNECTABLE) ||\r\ndisconnected_whitelist_entries(hdev))\r\nscan = SCAN_PAGE;\r\nelse\r\nscan = SCAN_DISABLED;\r\nif (hci_dev_test_flag(hdev, HCI_DISCOVERABLE))\r\nscan |= SCAN_INQUIRY;\r\nif (test_bit(HCI_PSCAN, &hdev->flags) == !!(scan & SCAN_PAGE) &&\r\ntest_bit(HCI_ISCAN, &hdev->flags) == !!(scan & SCAN_INQUIRY))\r\nreturn;\r\nhci_req_add(req, HCI_OP_WRITE_SCAN_ENABLE, 1, &scan);\r\n}\r\nstatic int update_scan(struct hci_request *req, unsigned long opt)\r\n{\r\nhci_dev_lock(req->hdev);\r\n__hci_req_update_scan(req);\r\nhci_dev_unlock(req->hdev);\r\nreturn 0;\r\n}\r\nstatic void scan_update_work(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev, scan_update);\r\nhci_req_sync(hdev, update_scan, 0, HCI_CMD_TIMEOUT, NULL);\r\n}\r\nstatic int connectable_update(struct hci_request *req, unsigned long opt)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nhci_dev_lock(hdev);\r\n__hci_req_update_scan(req);\r\nif (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED))\r\n__hci_req_update_adv_data(req, hdev->cur_adv_instance);\r\nif (hci_dev_test_flag(hdev, HCI_ADVERTISING) ||\r\n!list_empty(&hdev->adv_instances))\r\n__hci_req_enable_advertising(req);\r\n__hci_update_background_scan(req);\r\nhci_dev_unlock(hdev);\r\nreturn 0;\r\n}\r\nstatic void connectable_update_work(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\nconnectable_update);\r\nu8 status;\r\nhci_req_sync(hdev, connectable_update, 0, HCI_CMD_TIMEOUT, &status);\r\nmgmt_set_connectable_complete(hdev, status);\r\n}\r\nstatic u8 get_service_classes(struct hci_dev *hdev)\r\n{\r\nstruct bt_uuid *uuid;\r\nu8 val = 0;\r\nlist_for_each_entry(uuid, &hdev->uuids, list)\r\nval |= uuid->svc_hint;\r\nreturn val;\r\n}\r\nvoid __hci_req_update_class(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nu8 cod[3];\r\nBT_DBG("%s", hdev->name);\r\nif (!hdev_is_powered(hdev))\r\nreturn;\r\nif (!hci_dev_test_flag(hdev, HCI_BREDR_ENABLED))\r\nreturn;\r\nif (hci_dev_test_flag(hdev, HCI_SERVICE_CACHE))\r\nreturn;\r\ncod[0] = hdev->minor_class;\r\ncod[1] = hdev->major_class;\r\ncod[2] = get_service_classes(hdev);\r\nif (hci_dev_test_flag(hdev, HCI_LIMITED_DISCOVERABLE))\r\ncod[1] |= 0x20;\r\nif (memcmp(cod, hdev->dev_class, 3) == 0)\r\nreturn;\r\nhci_req_add(req, HCI_OP_WRITE_CLASS_OF_DEV, sizeof(cod), cod);\r\n}\r\nstatic void write_iac(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_write_current_iac_lap cp;\r\nif (!hci_dev_test_flag(hdev, HCI_DISCOVERABLE))\r\nreturn;\r\nif (hci_dev_test_flag(hdev, HCI_LIMITED_DISCOVERABLE)) {\r\ncp.num_iac = min_t(u8, hdev->num_iac, 2);\r\ncp.iac_lap[0] = 0x00;\r\ncp.iac_lap[1] = 0x8b;\r\ncp.iac_lap[2] = 0x9e;\r\ncp.iac_lap[3] = 0x33;\r\ncp.iac_lap[4] = 0x8b;\r\ncp.iac_lap[5] = 0x9e;\r\n} else {\r\ncp.num_iac = 1;\r\ncp.iac_lap[0] = 0x33;\r\ncp.iac_lap[1] = 0x8b;\r\ncp.iac_lap[2] = 0x9e;\r\n}\r\nhci_req_add(req, HCI_OP_WRITE_CURRENT_IAC_LAP,\r\n(cp.num_iac * 3) + 1, &cp);\r\n}\r\nstatic int discoverable_update(struct hci_request *req, unsigned long opt)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nhci_dev_lock(hdev);\r\nif (hci_dev_test_flag(hdev, HCI_BREDR_ENABLED)) {\r\nwrite_iac(req);\r\n__hci_req_update_scan(req);\r\n__hci_req_update_class(req);\r\n}\r\nif (hci_dev_test_flag(hdev, HCI_ADVERTISING)) {\r\n__hci_req_update_adv_data(req, 0x00);\r\nif (hci_dev_test_flag(hdev, HCI_LIMITED_PRIVACY))\r\n__hci_req_enable_advertising(req);\r\n}\r\nhci_dev_unlock(hdev);\r\nreturn 0;\r\n}\r\nstatic void discoverable_update_work(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\ndiscoverable_update);\r\nu8 status;\r\nhci_req_sync(hdev, discoverable_update, 0, HCI_CMD_TIMEOUT, &status);\r\nmgmt_set_discoverable_complete(hdev, status);\r\n}\r\nvoid __hci_abort_conn(struct hci_request *req, struct hci_conn *conn,\r\nu8 reason)\r\n{\r\nswitch (conn->state) {\r\ncase BT_CONNECTED:\r\ncase BT_CONFIG:\r\nif (conn->type == AMP_LINK) {\r\nstruct hci_cp_disconn_phy_link cp;\r\ncp.phy_handle = HCI_PHY_HANDLE(conn->handle);\r\ncp.reason = reason;\r\nhci_req_add(req, HCI_OP_DISCONN_PHY_LINK, sizeof(cp),\r\n&cp);\r\n} else {\r\nstruct hci_cp_disconnect dc;\r\ndc.handle = cpu_to_le16(conn->handle);\r\ndc.reason = reason;\r\nhci_req_add(req, HCI_OP_DISCONNECT, sizeof(dc), &dc);\r\n}\r\nconn->state = BT_DISCONN;\r\nbreak;\r\ncase BT_CONNECT:\r\nif (conn->type == LE_LINK) {\r\nif (test_bit(HCI_CONN_SCANNING, &conn->flags))\r\nbreak;\r\nhci_req_add(req, HCI_OP_LE_CREATE_CONN_CANCEL,\r\n0, NULL);\r\n} else if (conn->type == ACL_LINK) {\r\nif (req->hdev->hci_ver < BLUETOOTH_VER_1_2)\r\nbreak;\r\nhci_req_add(req, HCI_OP_CREATE_CONN_CANCEL,\r\n6, &conn->dst);\r\n}\r\nbreak;\r\ncase BT_CONNECT2:\r\nif (conn->type == ACL_LINK) {\r\nstruct hci_cp_reject_conn_req rej;\r\nbacpy(&rej.bdaddr, &conn->dst);\r\nrej.reason = reason;\r\nhci_req_add(req, HCI_OP_REJECT_CONN_REQ,\r\nsizeof(rej), &rej);\r\n} else if (conn->type == SCO_LINK || conn->type == ESCO_LINK) {\r\nstruct hci_cp_reject_sync_conn_req rej;\r\nbacpy(&rej.bdaddr, &conn->dst);\r\nrej.reason = HCI_ERROR_REJ_LIMITED_RESOURCES;\r\nhci_req_add(req, HCI_OP_REJECT_SYNC_CONN_REQ,\r\nsizeof(rej), &rej);\r\n}\r\nbreak;\r\ndefault:\r\nconn->state = BT_CLOSED;\r\nbreak;\r\n}\r\n}\r\nstatic void abort_conn_complete(struct hci_dev *hdev, u8 status, u16 opcode)\r\n{\r\nif (status)\r\nBT_DBG("Failed to abort connection: status 0x%2.2x", status);\r\n}\r\nint hci_abort_conn(struct hci_conn *conn, u8 reason)\r\n{\r\nstruct hci_request req;\r\nint err;\r\nhci_req_init(&req, conn->hdev);\r\n__hci_abort_conn(&req, conn, reason);\r\nerr = hci_req_run(&req, abort_conn_complete);\r\nif (err && err != -ENODATA) {\r\nBT_ERR("Failed to run HCI request: err %d", err);\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic int update_bg_scan(struct hci_request *req, unsigned long opt)\r\n{\r\nhci_dev_lock(req->hdev);\r\n__hci_update_background_scan(req);\r\nhci_dev_unlock(req->hdev);\r\nreturn 0;\r\n}\r\nstatic void bg_scan_update(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\nbg_scan_update);\r\nstruct hci_conn *conn;\r\nu8 status;\r\nint err;\r\nerr = hci_req_sync(hdev, update_bg_scan, 0, HCI_CMD_TIMEOUT, &status);\r\nif (!err)\r\nreturn;\r\nhci_dev_lock(hdev);\r\nconn = hci_conn_hash_lookup_state(hdev, LE_LINK, BT_CONNECT);\r\nif (conn)\r\nhci_le_conn_failed(conn, status);\r\nhci_dev_unlock(hdev);\r\n}\r\nstatic int le_scan_disable(struct hci_request *req, unsigned long opt)\r\n{\r\nhci_req_add_le_scan_disable(req);\r\nreturn 0;\r\n}\r\nstatic int bredr_inquiry(struct hci_request *req, unsigned long opt)\r\n{\r\nu8 length = opt;\r\nconst u8 giac[3] = { 0x33, 0x8b, 0x9e };\r\nconst u8 liac[3] = { 0x00, 0x8b, 0x9e };\r\nstruct hci_cp_inquiry cp;\r\nBT_DBG("%s", req->hdev->name);\r\nhci_dev_lock(req->hdev);\r\nhci_inquiry_cache_flush(req->hdev);\r\nhci_dev_unlock(req->hdev);\r\nmemset(&cp, 0, sizeof(cp));\r\nif (req->hdev->discovery.limited)\r\nmemcpy(&cp.lap, liac, sizeof(cp.lap));\r\nelse\r\nmemcpy(&cp.lap, giac, sizeof(cp.lap));\r\ncp.length = length;\r\nhci_req_add(req, HCI_OP_INQUIRY, sizeof(cp), &cp);\r\nreturn 0;\r\n}\r\nstatic void le_scan_disable_work(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\nle_scan_disable.work);\r\nu8 status;\r\nBT_DBG("%s", hdev->name);\r\nif (!hci_dev_test_flag(hdev, HCI_LE_SCAN))\r\nreturn;\r\ncancel_delayed_work(&hdev->le_scan_restart);\r\nhci_req_sync(hdev, le_scan_disable, 0, HCI_CMD_TIMEOUT, &status);\r\nif (status) {\r\nBT_ERR("Failed to disable LE scan: status 0x%02x", status);\r\nreturn;\r\n}\r\nhdev->discovery.scan_start = 0;\r\nif (hdev->discovery.type == DISCOV_TYPE_LE)\r\ngoto discov_stopped;\r\nif (hdev->discovery.type != DISCOV_TYPE_INTERLEAVED)\r\nreturn;\r\nif (test_bit(HCI_QUIRK_SIMULTANEOUS_DISCOVERY, &hdev->quirks)) {\r\nif (!test_bit(HCI_INQUIRY, &hdev->flags) &&\r\nhdev->discovery.state != DISCOVERY_RESOLVING)\r\ngoto discov_stopped;\r\nreturn;\r\n}\r\nhci_req_sync(hdev, bredr_inquiry, DISCOV_INTERLEAVED_INQUIRY_LEN,\r\nHCI_CMD_TIMEOUT, &status);\r\nif (status) {\r\nBT_ERR("Inquiry failed: status 0x%02x", status);\r\ngoto discov_stopped;\r\n}\r\nreturn;\r\ndiscov_stopped:\r\nhci_dev_lock(hdev);\r\nhci_discovery_set_state(hdev, DISCOVERY_STOPPED);\r\nhci_dev_unlock(hdev);\r\n}\r\nstatic int le_scan_restart(struct hci_request *req, unsigned long opt)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_le_set_scan_enable cp;\r\nif (!hci_dev_test_flag(hdev, HCI_LE_SCAN))\r\nreturn 0;\r\nhci_req_add_le_scan_disable(req);\r\nmemset(&cp, 0, sizeof(cp));\r\ncp.enable = LE_SCAN_ENABLE;\r\ncp.filter_dup = LE_SCAN_FILTER_DUP_ENABLE;\r\nhci_req_add(req, HCI_OP_LE_SET_SCAN_ENABLE, sizeof(cp), &cp);\r\nreturn 0;\r\n}\r\nstatic void le_scan_restart_work(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\nle_scan_restart.work);\r\nunsigned long timeout, duration, scan_start, now;\r\nu8 status;\r\nBT_DBG("%s", hdev->name);\r\nhci_req_sync(hdev, le_scan_restart, 0, HCI_CMD_TIMEOUT, &status);\r\nif (status) {\r\nBT_ERR("Failed to restart LE scan: status %d", status);\r\nreturn;\r\n}\r\nhci_dev_lock(hdev);\r\nif (!test_bit(HCI_QUIRK_STRICT_DUPLICATE_FILTER, &hdev->quirks) ||\r\n!hdev->discovery.scan_start)\r\ngoto unlock;\r\nduration = hdev->discovery.scan_duration;\r\nscan_start = hdev->discovery.scan_start;\r\nnow = jiffies;\r\nif (now - scan_start <= duration) {\r\nint elapsed;\r\nif (now >= scan_start)\r\nelapsed = now - scan_start;\r\nelse\r\nelapsed = ULONG_MAX - scan_start + now;\r\ntimeout = duration - elapsed;\r\n} else {\r\ntimeout = 0;\r\n}\r\nqueue_delayed_work(hdev->req_workqueue,\r\n&hdev->le_scan_disable, timeout);\r\nunlock:\r\nhci_dev_unlock(hdev);\r\n}\r\nstatic void disable_advertising(struct hci_request *req)\r\n{\r\nu8 enable = 0x00;\r\nhci_req_add(req, HCI_OP_LE_SET_ADV_ENABLE, sizeof(enable), &enable);\r\n}\r\nstatic int active_scan(struct hci_request *req, unsigned long opt)\r\n{\r\nuint16_t interval = opt;\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct hci_cp_le_set_scan_param param_cp;\r\nstruct hci_cp_le_set_scan_enable enable_cp;\r\nu8 own_addr_type;\r\nint err;\r\nBT_DBG("%s", hdev->name);\r\nif (hci_dev_test_flag(hdev, HCI_LE_ADV)) {\r\nhci_dev_lock(hdev);\r\nif (hci_lookup_le_connect(hdev)) {\r\nhci_dev_unlock(hdev);\r\nreturn -EBUSY;\r\n}\r\ncancel_adv_timeout(hdev);\r\nhci_dev_unlock(hdev);\r\ndisable_advertising(req);\r\n}\r\nif (hci_dev_test_flag(hdev, HCI_LE_SCAN))\r\nhci_req_add_le_scan_disable(req);\r\nerr = hci_update_random_address(req, true, scan_use_rpa(hdev),\r\n&own_addr_type);\r\nif (err < 0)\r\nown_addr_type = ADDR_LE_DEV_PUBLIC;\r\nmemset(&param_cp, 0, sizeof(param_cp));\r\nparam_cp.type = LE_SCAN_ACTIVE;\r\nparam_cp.interval = cpu_to_le16(interval);\r\nparam_cp.window = cpu_to_le16(DISCOV_LE_SCAN_WIN);\r\nparam_cp.own_address_type = own_addr_type;\r\nhci_req_add(req, HCI_OP_LE_SET_SCAN_PARAM, sizeof(param_cp),\r\n&param_cp);\r\nmemset(&enable_cp, 0, sizeof(enable_cp));\r\nenable_cp.enable = LE_SCAN_ENABLE;\r\nenable_cp.filter_dup = LE_SCAN_FILTER_DUP_ENABLE;\r\nhci_req_add(req, HCI_OP_LE_SET_SCAN_ENABLE, sizeof(enable_cp),\r\n&enable_cp);\r\nreturn 0;\r\n}\r\nstatic int interleaved_discov(struct hci_request *req, unsigned long opt)\r\n{\r\nint err;\r\nBT_DBG("%s", req->hdev->name);\r\nerr = active_scan(req, opt);\r\nif (err)\r\nreturn err;\r\nreturn bredr_inquiry(req, DISCOV_BREDR_INQUIRY_LEN);\r\n}\r\nstatic void start_discovery(struct hci_dev *hdev, u8 *status)\r\n{\r\nunsigned long timeout;\r\nBT_DBG("%s type %u", hdev->name, hdev->discovery.type);\r\nswitch (hdev->discovery.type) {\r\ncase DISCOV_TYPE_BREDR:\r\nif (!hci_dev_test_flag(hdev, HCI_INQUIRY))\r\nhci_req_sync(hdev, bredr_inquiry,\r\nDISCOV_BREDR_INQUIRY_LEN, HCI_CMD_TIMEOUT,\r\nstatus);\r\nreturn;\r\ncase DISCOV_TYPE_INTERLEAVED:\r\nif (test_bit(HCI_QUIRK_SIMULTANEOUS_DISCOVERY,\r\n&hdev->quirks)) {\r\ntimeout = msecs_to_jiffies(DISCOV_LE_TIMEOUT);\r\nhci_req_sync(hdev, interleaved_discov,\r\nDISCOV_LE_SCAN_INT * 2, HCI_CMD_TIMEOUT,\r\nstatus);\r\nbreak;\r\n}\r\ntimeout = msecs_to_jiffies(hdev->discov_interleaved_timeout);\r\nhci_req_sync(hdev, active_scan, DISCOV_LE_SCAN_INT,\r\nHCI_CMD_TIMEOUT, status);\r\nbreak;\r\ncase DISCOV_TYPE_LE:\r\ntimeout = msecs_to_jiffies(DISCOV_LE_TIMEOUT);\r\nhci_req_sync(hdev, active_scan, DISCOV_LE_SCAN_INT,\r\nHCI_CMD_TIMEOUT, status);\r\nbreak;\r\ndefault:\r\n*status = HCI_ERROR_UNSPECIFIED;\r\nreturn;\r\n}\r\nif (*status)\r\nreturn;\r\nBT_DBG("%s timeout %u ms", hdev->name, jiffies_to_msecs(timeout));\r\nif (test_bit(HCI_QUIRK_STRICT_DUPLICATE_FILTER, &hdev->quirks) &&\r\nhdev->discovery.result_filtering) {\r\nhdev->discovery.scan_start = jiffies;\r\nhdev->discovery.scan_duration = timeout;\r\n}\r\nqueue_delayed_work(hdev->req_workqueue, &hdev->le_scan_disable,\r\ntimeout);\r\n}\r\nbool hci_req_stop_discovery(struct hci_request *req)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nstruct discovery_state *d = &hdev->discovery;\r\nstruct hci_cp_remote_name_req_cancel cp;\r\nstruct inquiry_entry *e;\r\nbool ret = false;\r\nBT_DBG("%s state %u", hdev->name, hdev->discovery.state);\r\nif (d->state == DISCOVERY_FINDING || d->state == DISCOVERY_STOPPING) {\r\nif (test_bit(HCI_INQUIRY, &hdev->flags))\r\nhci_req_add(req, HCI_OP_INQUIRY_CANCEL, 0, NULL);\r\nif (hci_dev_test_flag(hdev, HCI_LE_SCAN)) {\r\ncancel_delayed_work(&hdev->le_scan_disable);\r\nhci_req_add_le_scan_disable(req);\r\n}\r\nret = true;\r\n} else {\r\nif (hci_dev_test_flag(hdev, HCI_LE_SCAN)) {\r\nhci_req_add_le_scan_disable(req);\r\nret = true;\r\n}\r\n}\r\nif (d->type == DISCOV_TYPE_LE)\r\nreturn ret;\r\nif (d->state == DISCOVERY_RESOLVING || d->state == DISCOVERY_STOPPING) {\r\ne = hci_inquiry_cache_lookup_resolve(hdev, BDADDR_ANY,\r\nNAME_PENDING);\r\nif (!e)\r\nreturn ret;\r\nbacpy(&cp.bdaddr, &e->data.bdaddr);\r\nhci_req_add(req, HCI_OP_REMOTE_NAME_REQ_CANCEL, sizeof(cp),\r\n&cp);\r\nret = true;\r\n}\r\nreturn ret;\r\n}\r\nstatic int stop_discovery(struct hci_request *req, unsigned long opt)\r\n{\r\nhci_dev_lock(req->hdev);\r\nhci_req_stop_discovery(req);\r\nhci_dev_unlock(req->hdev);\r\nreturn 0;\r\n}\r\nstatic void discov_update(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\ndiscov_update);\r\nu8 status = 0;\r\nswitch (hdev->discovery.state) {\r\ncase DISCOVERY_STARTING:\r\nstart_discovery(hdev, &status);\r\nmgmt_start_discovery_complete(hdev, status);\r\nif (status)\r\nhci_discovery_set_state(hdev, DISCOVERY_STOPPED);\r\nelse\r\nhci_discovery_set_state(hdev, DISCOVERY_FINDING);\r\nbreak;\r\ncase DISCOVERY_STOPPING:\r\nhci_req_sync(hdev, stop_discovery, 0, HCI_CMD_TIMEOUT, &status);\r\nmgmt_stop_discovery_complete(hdev, status);\r\nif (!status)\r\nhci_discovery_set_state(hdev, DISCOVERY_STOPPED);\r\nbreak;\r\ncase DISCOVERY_STOPPED:\r\ndefault:\r\nreturn;\r\n}\r\n}\r\nstatic void discov_off(struct work_struct *work)\r\n{\r\nstruct hci_dev *hdev = container_of(work, struct hci_dev,\r\ndiscov_off.work);\r\nBT_DBG("%s", hdev->name);\r\nhci_dev_lock(hdev);\r\nhci_dev_clear_flag(hdev, HCI_LIMITED_DISCOVERABLE);\r\nhci_dev_clear_flag(hdev, HCI_DISCOVERABLE);\r\nhdev->discov_timeout = 0;\r\nhci_dev_unlock(hdev);\r\nhci_req_sync(hdev, discoverable_update, 0, HCI_CMD_TIMEOUT, NULL);\r\nmgmt_new_settings(hdev);\r\n}\r\nstatic int powered_update_hci(struct hci_request *req, unsigned long opt)\r\n{\r\nstruct hci_dev *hdev = req->hdev;\r\nu8 link_sec;\r\nhci_dev_lock(hdev);\r\nif (hci_dev_test_flag(hdev, HCI_SSP_ENABLED) &&\r\n!lmp_host_ssp_capable(hdev)) {\r\nu8 mode = 0x01;\r\nhci_req_add(req, HCI_OP_WRITE_SSP_MODE, sizeof(mode), &mode);\r\nif (bredr_sc_enabled(hdev) && !lmp_host_sc_capable(hdev)) {\r\nu8 support = 0x01;\r\nhci_req_add(req, HCI_OP_WRITE_SC_SUPPORT,\r\nsizeof(support), &support);\r\n}\r\n}\r\nif (hci_dev_test_flag(hdev, HCI_LE_ENABLED) &&\r\nlmp_bredr_capable(hdev)) {\r\nstruct hci_cp_write_le_host_supported cp;\r\ncp.le = 0x01;\r\ncp.simul = 0x00;\r\nif (cp.le != lmp_host_le_capable(hdev) ||\r\ncp.simul != lmp_host_le_br_capable(hdev))\r\nhci_req_add(req, HCI_OP_WRITE_LE_HOST_SUPPORTED,\r\nsizeof(cp), &cp);\r\n}\r\nif (hci_dev_test_flag(hdev, HCI_LE_ENABLED)) {\r\nif (hci_dev_test_flag(hdev, HCI_ADVERTISING) ||\r\nlist_empty(&hdev->adv_instances)) {\r\n__hci_req_update_adv_data(req, 0x00);\r\n__hci_req_update_scan_rsp_data(req, 0x00);\r\nif (hci_dev_test_flag(hdev, HCI_ADVERTISING))\r\n__hci_req_enable_advertising(req);\r\n} else if (!list_empty(&hdev->adv_instances)) {\r\nstruct adv_info *adv_instance;\r\nadv_instance = list_first_entry(&hdev->adv_instances,\r\nstruct adv_info, list);\r\n__hci_req_schedule_adv_instance(req,\r\nadv_instance->instance,\r\ntrue);\r\n}\r\n}\r\nlink_sec = hci_dev_test_flag(hdev, HCI_LINK_SECURITY);\r\nif (link_sec != test_bit(HCI_AUTH, &hdev->flags))\r\nhci_req_add(req, HCI_OP_WRITE_AUTH_ENABLE,\r\nsizeof(link_sec), &link_sec);\r\nif (lmp_bredr_capable(hdev)) {\r\nif (hci_dev_test_flag(hdev, HCI_FAST_CONNECTABLE))\r\n__hci_req_write_fast_connectable(req, true);\r\nelse\r\n__hci_req_write_fast_connectable(req, false);\r\n__hci_req_update_scan(req);\r\n__hci_req_update_class(req);\r\n__hci_req_update_name(req);\r\n__hci_req_update_eir(req);\r\n}\r\nhci_dev_unlock(hdev);\r\nreturn 0;\r\n}\r\nint __hci_req_hci_power_on(struct hci_dev *hdev)\r\n{\r\nsmp_register(hdev);\r\nreturn __hci_req_sync(hdev, powered_update_hci, 0, HCI_CMD_TIMEOUT,\r\nNULL);\r\n}\r\nvoid hci_request_setup(struct hci_dev *hdev)\r\n{\r\nINIT_WORK(&hdev->discov_update, discov_update);\r\nINIT_WORK(&hdev->bg_scan_update, bg_scan_update);\r\nINIT_WORK(&hdev->scan_update, scan_update_work);\r\nINIT_WORK(&hdev->connectable_update, connectable_update_work);\r\nINIT_WORK(&hdev->discoverable_update, discoverable_update_work);\r\nINIT_DELAYED_WORK(&hdev->discov_off, discov_off);\r\nINIT_DELAYED_WORK(&hdev->le_scan_disable, le_scan_disable_work);\r\nINIT_DELAYED_WORK(&hdev->le_scan_restart, le_scan_restart_work);\r\nINIT_DELAYED_WORK(&hdev->adv_instance_expire, adv_timeout_expire);\r\n}\r\nvoid hci_request_cancel_all(struct hci_dev *hdev)\r\n{\r\nhci_req_sync_cancel(hdev, ENODEV);\r\ncancel_work_sync(&hdev->discov_update);\r\ncancel_work_sync(&hdev->bg_scan_update);\r\ncancel_work_sync(&hdev->scan_update);\r\ncancel_work_sync(&hdev->connectable_update);\r\ncancel_work_sync(&hdev->discoverable_update);\r\ncancel_delayed_work_sync(&hdev->discov_off);\r\ncancel_delayed_work_sync(&hdev->le_scan_disable);\r\ncancel_delayed_work_sync(&hdev->le_scan_restart);\r\nif (hdev->adv_instance_timeout) {\r\ncancel_delayed_work_sync(&hdev->adv_instance_expire);\r\nhdev->adv_instance_timeout = 0;\r\n}\r\n}
