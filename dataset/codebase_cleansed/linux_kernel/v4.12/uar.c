int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(alloc_uar_out)] = {0};\r\nu32 in[MLX5_ST_SZ_DW(alloc_uar_in)] = {0};\r\nint err;\r\nMLX5_SET(alloc_uar_in, in, opcode, MLX5_CMD_OP_ALLOC_UAR);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));\r\nif (!err)\r\n*uarn = MLX5_GET(alloc_uar_out, out, uar);\r\nreturn err;\r\n}\r\nint mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(dealloc_uar_out)] = {0};\r\nu32 in[MLX5_ST_SZ_DW(dealloc_uar_in)] = {0};\r\nMLX5_SET(dealloc_uar_in, in, opcode, MLX5_CMD_OP_DEALLOC_UAR);\r\nMLX5_SET(dealloc_uar_in, in, uar, uarn);\r\nreturn mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));\r\n}\r\nstatic int uars_per_sys_page(struct mlx5_core_dev *mdev)\r\n{\r\nif (MLX5_CAP_GEN(mdev, uar_4k))\r\nreturn MLX5_CAP_GEN(mdev, num_of_uars_per_page);\r\nreturn 1;\r\n}\r\nstatic u64 uar2pfn(struct mlx5_core_dev *mdev, u32 index)\r\n{\r\nu32 system_page_index;\r\nif (MLX5_CAP_GEN(mdev, uar_4k))\r\nsystem_page_index = index >> (PAGE_SHIFT - MLX5_ADAPTER_PAGE_SHIFT);\r\nelse\r\nsystem_page_index = index;\r\nreturn (pci_resource_start(mdev->pdev, 0) >> PAGE_SHIFT) + system_page_index;\r\n}\r\nstatic void up_rel_func(struct kref *kref)\r\n{\r\nstruct mlx5_uars_page *up = container_of(kref, struct mlx5_uars_page, ref_count);\r\nlist_del(&up->list);\r\niounmap(up->map);\r\nif (mlx5_cmd_free_uar(up->mdev, up->index))\r\nmlx5_core_warn(up->mdev, "failed to free uar index %d\n", up->index);\r\nkfree(up->reg_bitmap);\r\nkfree(up->fp_bitmap);\r\nkfree(up);\r\n}\r\nstatic struct mlx5_uars_page *alloc_uars_page(struct mlx5_core_dev *mdev,\r\nbool map_wc)\r\n{\r\nstruct mlx5_uars_page *up;\r\nint err = -ENOMEM;\r\nphys_addr_t pfn;\r\nint bfregs;\r\nint i;\r\nbfregs = uars_per_sys_page(mdev) * MLX5_BFREGS_PER_UAR;\r\nup = kzalloc(sizeof(*up), GFP_KERNEL);\r\nif (!up)\r\nreturn ERR_PTR(err);\r\nup->mdev = mdev;\r\nup->reg_bitmap = kcalloc(BITS_TO_LONGS(bfregs), sizeof(unsigned long), GFP_KERNEL);\r\nif (!up->reg_bitmap)\r\ngoto error1;\r\nup->fp_bitmap = kcalloc(BITS_TO_LONGS(bfregs), sizeof(unsigned long), GFP_KERNEL);\r\nif (!up->fp_bitmap)\r\ngoto error1;\r\nfor (i = 0; i < bfregs; i++)\r\nif ((i % MLX5_BFREGS_PER_UAR) < MLX5_NON_FP_BFREGS_PER_UAR)\r\nset_bit(i, up->reg_bitmap);\r\nelse\r\nset_bit(i, up->fp_bitmap);\r\nup->bfregs = bfregs;\r\nup->fp_avail = bfregs * MLX5_FP_BFREGS_PER_UAR / MLX5_BFREGS_PER_UAR;\r\nup->reg_avail = bfregs * MLX5_NON_FP_BFREGS_PER_UAR / MLX5_BFREGS_PER_UAR;\r\nerr = mlx5_cmd_alloc_uar(mdev, &up->index);\r\nif (err) {\r\nmlx5_core_warn(mdev, "mlx5_cmd_alloc_uar() failed, %d\n", err);\r\ngoto error1;\r\n}\r\npfn = uar2pfn(mdev, up->index);\r\nif (map_wc) {\r\nup->map = ioremap_wc(pfn << PAGE_SHIFT, PAGE_SIZE);\r\nif (!up->map) {\r\nerr = -EAGAIN;\r\ngoto error2;\r\n}\r\n} else {\r\nup->map = ioremap(pfn << PAGE_SHIFT, PAGE_SIZE);\r\nif (!up->map) {\r\nerr = -ENOMEM;\r\ngoto error2;\r\n}\r\n}\r\nkref_init(&up->ref_count);\r\nmlx5_core_dbg(mdev, "allocated UAR page: index %d, total bfregs %d\n",\r\nup->index, up->bfregs);\r\nreturn up;\r\nerror2:\r\nif (mlx5_cmd_free_uar(mdev, up->index))\r\nmlx5_core_warn(mdev, "failed to free uar index %d\n", up->index);\r\nerror1:\r\nkfree(up->fp_bitmap);\r\nkfree(up->reg_bitmap);\r\nkfree(up);\r\nreturn ERR_PTR(err);\r\n}\r\nstruct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev)\r\n{\r\nstruct mlx5_uars_page *ret;\r\nmutex_lock(&mdev->priv.bfregs.reg_head.lock);\r\nif (list_empty(&mdev->priv.bfregs.reg_head.list)) {\r\nret = alloc_uars_page(mdev, false);\r\nif (IS_ERR(ret)) {\r\nret = NULL;\r\ngoto out;\r\n}\r\nlist_add(&ret->list, &mdev->priv.bfregs.reg_head.list);\r\n} else {\r\nret = list_first_entry(&mdev->priv.bfregs.reg_head.list,\r\nstruct mlx5_uars_page, list);\r\nkref_get(&ret->ref_count);\r\n}\r\nout:\r\nmutex_unlock(&mdev->priv.bfregs.reg_head.lock);\r\nreturn ret;\r\n}\r\nvoid mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up)\r\n{\r\nmutex_lock(&mdev->priv.bfregs.reg_head.lock);\r\nkref_put(&up->ref_count, up_rel_func);\r\nmutex_unlock(&mdev->priv.bfregs.reg_head.lock);\r\n}\r\nstatic unsigned long map_offset(struct mlx5_core_dev *mdev, int dbi)\r\n{\r\nreturn dbi / MLX5_BFREGS_PER_UAR * MLX5_ADAPTER_PAGE_SIZE +\r\n(dbi % MLX5_BFREGS_PER_UAR) *\r\n(1 << MLX5_CAP_GEN(mdev, log_bf_reg_size)) + MLX5_BF_OFFSET;\r\n}\r\nstatic int alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,\r\nbool map_wc, bool fast_path)\r\n{\r\nstruct mlx5_bfreg_data *bfregs;\r\nstruct mlx5_uars_page *up;\r\nstruct list_head *head;\r\nunsigned long *bitmap;\r\nunsigned int *avail;\r\nstruct mutex *lock;\r\nint dbi;\r\nbfregs = &mdev->priv.bfregs;\r\nif (map_wc) {\r\nhead = &bfregs->wc_head.list;\r\nlock = &bfregs->wc_head.lock;\r\n} else {\r\nhead = &bfregs->reg_head.list;\r\nlock = &bfregs->reg_head.lock;\r\n}\r\nmutex_lock(lock);\r\nif (list_empty(head)) {\r\nup = alloc_uars_page(mdev, map_wc);\r\nif (IS_ERR(up)) {\r\nmutex_unlock(lock);\r\nreturn PTR_ERR(up);\r\n}\r\nlist_add(&up->list, head);\r\n} else {\r\nup = list_entry(head->next, struct mlx5_uars_page, list);\r\nkref_get(&up->ref_count);\r\n}\r\nif (fast_path) {\r\nbitmap = up->fp_bitmap;\r\navail = &up->fp_avail;\r\n} else {\r\nbitmap = up->reg_bitmap;\r\navail = &up->reg_avail;\r\n}\r\ndbi = find_first_bit(bitmap, up->bfregs);\r\nclear_bit(dbi, bitmap);\r\n(*avail)--;\r\nif (!(*avail))\r\nlist_del(&up->list);\r\nbfreg->map = up->map + map_offset(mdev, dbi);\r\nbfreg->up = up;\r\nbfreg->wc = map_wc;\r\nbfreg->index = up->index + dbi / MLX5_BFREGS_PER_UAR;\r\nmutex_unlock(lock);\r\nreturn 0;\r\n}\r\nint mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,\r\nbool map_wc, bool fast_path)\r\n{\r\nint err;\r\nerr = alloc_bfreg(mdev, bfreg, map_wc, fast_path);\r\nif (!err)\r\nreturn 0;\r\nif (err == -EAGAIN && map_wc)\r\nreturn alloc_bfreg(mdev, bfreg, false, fast_path);\r\nreturn err;\r\n}\r\nstatic unsigned int addr_to_dbi_in_syspage(struct mlx5_core_dev *dev,\r\nstruct mlx5_uars_page *up,\r\nstruct mlx5_sq_bfreg *bfreg)\r\n{\r\nunsigned int uar_idx;\r\nunsigned int bfreg_idx;\r\nunsigned int bf_reg_size;\r\nbf_reg_size = 1 << MLX5_CAP_GEN(dev, log_bf_reg_size);\r\nuar_idx = (bfreg->map - up->map) >> MLX5_ADAPTER_PAGE_SHIFT;\r\nbfreg_idx = (((uintptr_t)bfreg->map % MLX5_ADAPTER_PAGE_SIZE) - MLX5_BF_OFFSET) / bf_reg_size;\r\nreturn uar_idx * MLX5_BFREGS_PER_UAR + bfreg_idx;\r\n}\r\nvoid mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg)\r\n{\r\nstruct mlx5_bfreg_data *bfregs;\r\nstruct mlx5_uars_page *up;\r\nstruct mutex *lock;\r\nunsigned int dbi;\r\nbool fp;\r\nunsigned int *avail;\r\nunsigned long *bitmap;\r\nstruct list_head *head;\r\nbfregs = &mdev->priv.bfregs;\r\nif (bfreg->wc) {\r\nhead = &bfregs->wc_head.list;\r\nlock = &bfregs->wc_head.lock;\r\n} else {\r\nhead = &bfregs->reg_head.list;\r\nlock = &bfregs->reg_head.lock;\r\n}\r\nup = bfreg->up;\r\ndbi = addr_to_dbi_in_syspage(mdev, up, bfreg);\r\nfp = (dbi % MLX5_BFREGS_PER_UAR) >= MLX5_NON_FP_BFREGS_PER_UAR;\r\nif (fp) {\r\navail = &up->fp_avail;\r\nbitmap = up->fp_bitmap;\r\n} else {\r\navail = &up->reg_avail;\r\nbitmap = up->reg_bitmap;\r\n}\r\nmutex_lock(lock);\r\n(*avail)++;\r\nset_bit(dbi, bitmap);\r\nif (*avail == 1)\r\nlist_add_tail(&up->list, head);\r\nkref_put(&up->ref_count, up_rel_func);\r\nmutex_unlock(lock);\r\n}
