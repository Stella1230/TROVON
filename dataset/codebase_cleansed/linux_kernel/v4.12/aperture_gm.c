static int alloc_gm(struct intel_vgpu *vgpu, bool high_gm)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\nstruct drm_i915_private *dev_priv = gvt->dev_priv;\r\nunsigned int flags;\r\nu64 start, end, size;\r\nstruct drm_mm_node *node;\r\nint ret;\r\nif (high_gm) {\r\nnode = &vgpu->gm.high_gm_node;\r\nsize = vgpu_hidden_sz(vgpu);\r\nstart = ALIGN(gvt_hidden_gmadr_base(gvt), I915_GTT_PAGE_SIZE);\r\nend = ALIGN(gvt_hidden_gmadr_end(gvt), I915_GTT_PAGE_SIZE);\r\nflags = PIN_HIGH;\r\n} else {\r\nnode = &vgpu->gm.low_gm_node;\r\nsize = vgpu_aperture_sz(vgpu);\r\nstart = ALIGN(gvt_aperture_gmadr_base(gvt), I915_GTT_PAGE_SIZE);\r\nend = ALIGN(gvt_aperture_gmadr_end(gvt), I915_GTT_PAGE_SIZE);\r\nflags = PIN_MAPPABLE;\r\n}\r\nmutex_lock(&dev_priv->drm.struct_mutex);\r\nret = i915_gem_gtt_insert(&dev_priv->ggtt.base, node,\r\nsize, I915_GTT_PAGE_SIZE,\r\nI915_COLOR_UNEVICTABLE,\r\nstart, end, flags);\r\nmutex_unlock(&dev_priv->drm.struct_mutex);\r\nif (ret)\r\ngvt_err("fail to alloc %s gm space from host\n",\r\nhigh_gm ? "high" : "low");\r\nreturn ret;\r\n}\r\nstatic int alloc_vgpu_gm(struct intel_vgpu *vgpu)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\nstruct drm_i915_private *dev_priv = gvt->dev_priv;\r\nint ret;\r\nret = alloc_gm(vgpu, false);\r\nif (ret)\r\nreturn ret;\r\nret = alloc_gm(vgpu, true);\r\nif (ret)\r\ngoto out_free_aperture;\r\ngvt_dbg_core("vgpu%d: alloc low GM start %llx size %llx\n", vgpu->id,\r\nvgpu_aperture_offset(vgpu), vgpu_aperture_sz(vgpu));\r\ngvt_dbg_core("vgpu%d: alloc high GM start %llx size %llx\n", vgpu->id,\r\nvgpu_hidden_offset(vgpu), vgpu_hidden_sz(vgpu));\r\nreturn 0;\r\nout_free_aperture:\r\nmutex_lock(&dev_priv->drm.struct_mutex);\r\ndrm_mm_remove_node(&vgpu->gm.low_gm_node);\r\nmutex_unlock(&dev_priv->drm.struct_mutex);\r\nreturn ret;\r\n}\r\nstatic void free_vgpu_gm(struct intel_vgpu *vgpu)\r\n{\r\nstruct drm_i915_private *dev_priv = vgpu->gvt->dev_priv;\r\nmutex_lock(&dev_priv->drm.struct_mutex);\r\ndrm_mm_remove_node(&vgpu->gm.low_gm_node);\r\ndrm_mm_remove_node(&vgpu->gm.high_gm_node);\r\nmutex_unlock(&dev_priv->drm.struct_mutex);\r\n}\r\nvoid intel_vgpu_write_fence(struct intel_vgpu *vgpu,\r\nu32 fence, u64 value)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\nstruct drm_i915_private *dev_priv = gvt->dev_priv;\r\nstruct drm_i915_fence_reg *reg;\r\ni915_reg_t fence_reg_lo, fence_reg_hi;\r\nassert_rpm_wakelock_held(dev_priv);\r\nif (WARN_ON(fence > vgpu_fence_sz(vgpu)))\r\nreturn;\r\nreg = vgpu->fence.regs[fence];\r\nif (WARN_ON(!reg))\r\nreturn;\r\nfence_reg_lo = FENCE_REG_GEN6_LO(reg->id);\r\nfence_reg_hi = FENCE_REG_GEN6_HI(reg->id);\r\nI915_WRITE(fence_reg_lo, 0);\r\nPOSTING_READ(fence_reg_lo);\r\nI915_WRITE(fence_reg_hi, upper_32_bits(value));\r\nI915_WRITE(fence_reg_lo, lower_32_bits(value));\r\nPOSTING_READ(fence_reg_lo);\r\n}\r\nstatic void _clear_vgpu_fence(struct intel_vgpu *vgpu)\r\n{\r\nint i;\r\nfor (i = 0; i < vgpu_fence_sz(vgpu); i++)\r\nintel_vgpu_write_fence(vgpu, i, 0);\r\n}\r\nstatic void free_vgpu_fence(struct intel_vgpu *vgpu)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\nstruct drm_i915_private *dev_priv = gvt->dev_priv;\r\nstruct drm_i915_fence_reg *reg;\r\nu32 i;\r\nif (WARN_ON(!vgpu_fence_sz(vgpu)))\r\nreturn;\r\nintel_runtime_pm_get(dev_priv);\r\nmutex_lock(&dev_priv->drm.struct_mutex);\r\n_clear_vgpu_fence(vgpu);\r\nfor (i = 0; i < vgpu_fence_sz(vgpu); i++) {\r\nreg = vgpu->fence.regs[i];\r\nlist_add_tail(&reg->link,\r\n&dev_priv->mm.fence_list);\r\n}\r\nmutex_unlock(&dev_priv->drm.struct_mutex);\r\nintel_runtime_pm_put(dev_priv);\r\n}\r\nstatic int alloc_vgpu_fence(struct intel_vgpu *vgpu)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\nstruct drm_i915_private *dev_priv = gvt->dev_priv;\r\nstruct drm_i915_fence_reg *reg;\r\nint i;\r\nstruct list_head *pos, *q;\r\nintel_runtime_pm_get(dev_priv);\r\nmutex_lock(&dev_priv->drm.struct_mutex);\r\ni = 0;\r\nlist_for_each_safe(pos, q, &dev_priv->mm.fence_list) {\r\nreg = list_entry(pos, struct drm_i915_fence_reg, link);\r\nif (reg->pin_count || reg->vma)\r\ncontinue;\r\nlist_del(pos);\r\nvgpu->fence.regs[i] = reg;\r\nif (++i == vgpu_fence_sz(vgpu))\r\nbreak;\r\n}\r\nif (i != vgpu_fence_sz(vgpu))\r\ngoto out_free_fence;\r\n_clear_vgpu_fence(vgpu);\r\nmutex_unlock(&dev_priv->drm.struct_mutex);\r\nintel_runtime_pm_put(dev_priv);\r\nreturn 0;\r\nout_free_fence:\r\nfor (i = 0; i < vgpu_fence_sz(vgpu); i++) {\r\nreg = vgpu->fence.regs[i];\r\nif (!reg)\r\ncontinue;\r\nlist_add_tail(&reg->link,\r\n&dev_priv->mm.fence_list);\r\n}\r\nmutex_unlock(&dev_priv->drm.struct_mutex);\r\nintel_runtime_pm_put(dev_priv);\r\nreturn -ENOSPC;\r\n}\r\nstatic void free_resource(struct intel_vgpu *vgpu)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\ngvt->gm.vgpu_allocated_low_gm_size -= vgpu_aperture_sz(vgpu);\r\ngvt->gm.vgpu_allocated_high_gm_size -= vgpu_hidden_sz(vgpu);\r\ngvt->fence.vgpu_allocated_fence_num -= vgpu_fence_sz(vgpu);\r\n}\r\nstatic int alloc_resource(struct intel_vgpu *vgpu,\r\nstruct intel_vgpu_creation_params *param)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\nunsigned long request, avail, max, taken;\r\nconst char *item;\r\nif (!param->low_gm_sz || !param->high_gm_sz || !param->fence_sz) {\r\ngvt_vgpu_err("Invalid vGPU creation params\n");\r\nreturn -EINVAL;\r\n}\r\nitem = "low GM space";\r\nmax = gvt_aperture_sz(gvt) - HOST_LOW_GM_SIZE;\r\ntaken = gvt->gm.vgpu_allocated_low_gm_size;\r\navail = max - taken;\r\nrequest = MB_TO_BYTES(param->low_gm_sz);\r\nif (request > avail)\r\ngoto no_enough_resource;\r\nvgpu_aperture_sz(vgpu) = ALIGN(request, I915_GTT_PAGE_SIZE);\r\nitem = "high GM space";\r\nmax = gvt_hidden_sz(gvt) - HOST_HIGH_GM_SIZE;\r\ntaken = gvt->gm.vgpu_allocated_high_gm_size;\r\navail = max - taken;\r\nrequest = MB_TO_BYTES(param->high_gm_sz);\r\nif (request > avail)\r\ngoto no_enough_resource;\r\nvgpu_hidden_sz(vgpu) = ALIGN(request, I915_GTT_PAGE_SIZE);\r\nitem = "fence";\r\nmax = gvt_fence_sz(gvt) - HOST_FENCE;\r\ntaken = gvt->fence.vgpu_allocated_fence_num;\r\navail = max - taken;\r\nrequest = param->fence_sz;\r\nif (request > avail)\r\ngoto no_enough_resource;\r\nvgpu_fence_sz(vgpu) = request;\r\ngvt->gm.vgpu_allocated_low_gm_size += MB_TO_BYTES(param->low_gm_sz);\r\ngvt->gm.vgpu_allocated_high_gm_size += MB_TO_BYTES(param->high_gm_sz);\r\ngvt->fence.vgpu_allocated_fence_num += param->fence_sz;\r\nreturn 0;\r\nno_enough_resource:\r\ngvt_vgpu_err("fail to allocate resource %s\n", item);\r\ngvt_vgpu_err("request %luMB avail %luMB max %luMB taken %luMB\n",\r\nBYTES_TO_MB(request), BYTES_TO_MB(avail),\r\nBYTES_TO_MB(max), BYTES_TO_MB(taken));\r\nreturn -ENOSPC;\r\n}\r\nvoid intel_vgpu_free_resource(struct intel_vgpu *vgpu)\r\n{\r\nfree_vgpu_gm(vgpu);\r\nfree_vgpu_fence(vgpu);\r\nfree_resource(vgpu);\r\n}\r\nvoid intel_vgpu_reset_resource(struct intel_vgpu *vgpu)\r\n{\r\nstruct drm_i915_private *dev_priv = vgpu->gvt->dev_priv;\r\nintel_runtime_pm_get(dev_priv);\r\n_clear_vgpu_fence(vgpu);\r\nintel_runtime_pm_put(dev_priv);\r\n}\r\nint intel_vgpu_alloc_resource(struct intel_vgpu *vgpu,\r\nstruct intel_vgpu_creation_params *param)\r\n{\r\nint ret;\r\nret = alloc_resource(vgpu, param);\r\nif (ret)\r\nreturn ret;\r\nret = alloc_vgpu_gm(vgpu);\r\nif (ret)\r\ngoto out_free_resource;\r\nret = alloc_vgpu_fence(vgpu);\r\nif (ret)\r\ngoto out_free_vgpu_gm;\r\nreturn 0;\r\nout_free_vgpu_gm:\r\nfree_vgpu_gm(vgpu);\r\nout_free_resource:\r\nfree_resource(vgpu);\r\nreturn ret;\r\n}
