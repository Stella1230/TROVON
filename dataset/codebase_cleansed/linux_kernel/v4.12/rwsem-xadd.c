void __init_rwsem(struct rw_semaphore *sem, const char *name,\r\nstruct lock_class_key *key)\r\n{\r\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\r\ndebug_check_no_locks_freed((void *)sem, sizeof(*sem));\r\nlockdep_init_map(&sem->dep_map, name, key, 0);\r\n#endif\r\natomic_long_set(&sem->count, RWSEM_UNLOCKED_VALUE);\r\nraw_spin_lock_init(&sem->wait_lock);\r\nINIT_LIST_HEAD(&sem->wait_list);\r\n#ifdef CONFIG_RWSEM_SPIN_ON_OWNER\r\nsem->owner = NULL;\r\nosq_lock_init(&sem->osq);\r\n#endif\r\n}\r\nstatic void __rwsem_mark_wake(struct rw_semaphore *sem,\r\nenum rwsem_wake_type wake_type,\r\nstruct wake_q_head *wake_q)\r\n{\r\nstruct rwsem_waiter *waiter, *tmp;\r\nlong oldcount, woken = 0, adjustment = 0;\r\nwaiter = list_first_entry(&sem->wait_list, struct rwsem_waiter, list);\r\nif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\r\nif (wake_type == RWSEM_WAKE_ANY) {\r\nwake_q_add(wake_q, waiter->task);\r\n}\r\nreturn;\r\n}\r\nif (wake_type != RWSEM_WAKE_READ_OWNED) {\r\nadjustment = RWSEM_ACTIVE_READ_BIAS;\r\ntry_reader_grant:\r\noldcount = atomic_long_fetch_add(adjustment, &sem->count);\r\nif (unlikely(oldcount < RWSEM_WAITING_BIAS)) {\r\nif (atomic_long_add_return(-adjustment, &sem->count) <\r\nRWSEM_WAITING_BIAS)\r\nreturn;\r\ngoto try_reader_grant;\r\n}\r\nrwsem_set_reader_owned(sem);\r\n}\r\nlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\r\nstruct task_struct *tsk;\r\nif (waiter->type == RWSEM_WAITING_FOR_WRITE)\r\nbreak;\r\nwoken++;\r\ntsk = waiter->task;\r\nwake_q_add(wake_q, tsk);\r\nlist_del(&waiter->list);\r\nsmp_store_release(&waiter->task, NULL);\r\n}\r\nadjustment = woken * RWSEM_ACTIVE_READ_BIAS - adjustment;\r\nif (list_empty(&sem->wait_list)) {\r\nadjustment -= RWSEM_WAITING_BIAS;\r\n}\r\nif (adjustment)\r\natomic_long_add(adjustment, &sem->count);\r\n}\r\n__visible\r\nstruct rw_semaphore __sched *rwsem_down_read_failed(struct rw_semaphore *sem)\r\n{\r\nlong count, adjustment = -RWSEM_ACTIVE_READ_BIAS;\r\nstruct rwsem_waiter waiter;\r\nDEFINE_WAKE_Q(wake_q);\r\nwaiter.task = current;\r\nwaiter.type = RWSEM_WAITING_FOR_READ;\r\nraw_spin_lock_irq(&sem->wait_lock);\r\nif (list_empty(&sem->wait_list))\r\nadjustment += RWSEM_WAITING_BIAS;\r\nlist_add_tail(&waiter.list, &sem->wait_list);\r\ncount = atomic_long_add_return(adjustment, &sem->count);\r\nif (count == RWSEM_WAITING_BIAS ||\r\n(count > RWSEM_WAITING_BIAS &&\r\nadjustment != -RWSEM_ACTIVE_READ_BIAS))\r\n__rwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\r\nraw_spin_unlock_irq(&sem->wait_lock);\r\nwake_up_q(&wake_q);\r\nwhile (true) {\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nif (!waiter.task)\r\nbreak;\r\nschedule();\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nreturn sem;\r\n}\r\nstatic inline bool rwsem_try_write_lock(long count, struct rw_semaphore *sem)\r\n{\r\nif (count != RWSEM_WAITING_BIAS)\r\nreturn false;\r\ncount = list_is_singular(&sem->wait_list) ?\r\nRWSEM_ACTIVE_WRITE_BIAS :\r\nRWSEM_ACTIVE_WRITE_BIAS + RWSEM_WAITING_BIAS;\r\nif (atomic_long_cmpxchg_acquire(&sem->count, RWSEM_WAITING_BIAS, count)\r\n== RWSEM_WAITING_BIAS) {\r\nrwsem_set_owner(sem);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)\r\n{\r\nlong old, count = atomic_long_read(&sem->count);\r\nwhile (true) {\r\nif (!(count == 0 || count == RWSEM_WAITING_BIAS))\r\nreturn false;\r\nold = atomic_long_cmpxchg_acquire(&sem->count, count,\r\ncount + RWSEM_ACTIVE_WRITE_BIAS);\r\nif (old == count) {\r\nrwsem_set_owner(sem);\r\nreturn true;\r\n}\r\ncount = old;\r\n}\r\n}\r\nstatic inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\r\n{\r\nstruct task_struct *owner;\r\nbool ret = true;\r\nif (need_resched())\r\nreturn false;\r\nrcu_read_lock();\r\nowner = READ_ONCE(sem->owner);\r\nif (!rwsem_owner_is_writer(owner)) {\r\nret = !rwsem_owner_is_reader(owner);\r\ngoto done;\r\n}\r\nret = owner->on_cpu && !vcpu_is_preempted(task_cpu(owner));\r\ndone:\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nstatic noinline bool rwsem_spin_on_owner(struct rw_semaphore *sem)\r\n{\r\nstruct task_struct *owner = READ_ONCE(sem->owner);\r\nif (!rwsem_owner_is_writer(owner))\r\ngoto out;\r\nrcu_read_lock();\r\nwhile (sem->owner == owner) {\r\nbarrier();\r\nif (!owner->on_cpu || need_resched() ||\r\nvcpu_is_preempted(task_cpu(owner))) {\r\nrcu_read_unlock();\r\nreturn false;\r\n}\r\ncpu_relax();\r\n}\r\nrcu_read_unlock();\r\nout:\r\nreturn !rwsem_owner_is_reader(READ_ONCE(sem->owner));\r\n}\r\nstatic bool rwsem_optimistic_spin(struct rw_semaphore *sem)\r\n{\r\nbool taken = false;\r\npreempt_disable();\r\nif (!rwsem_can_spin_on_owner(sem))\r\ngoto done;\r\nif (!osq_lock(&sem->osq))\r\ngoto done;\r\nwhile (rwsem_spin_on_owner(sem)) {\r\nif (rwsem_try_write_lock_unqueued(sem)) {\r\ntaken = true;\r\nbreak;\r\n}\r\nif (!sem->owner && (need_resched() || rt_task(current)))\r\nbreak;\r\ncpu_relax();\r\n}\r\nosq_unlock(&sem->osq);\r\ndone:\r\npreempt_enable();\r\nreturn taken;\r\n}\r\nstatic inline bool rwsem_has_spinner(struct rw_semaphore *sem)\r\n{\r\nreturn osq_is_locked(&sem->osq);\r\n}\r\nstatic bool rwsem_optimistic_spin(struct rw_semaphore *sem)\r\n{\r\nreturn false;\r\n}\r\nstatic inline bool rwsem_has_spinner(struct rw_semaphore *sem)\r\n{\r\nreturn false;\r\n}\r\nstatic inline struct rw_semaphore *\r\n__rwsem_down_write_failed_common(struct rw_semaphore *sem, int state)\r\n{\r\nlong count;\r\nbool waiting = true;\r\nstruct rwsem_waiter waiter;\r\nstruct rw_semaphore *ret = sem;\r\nDEFINE_WAKE_Q(wake_q);\r\ncount = atomic_long_sub_return(RWSEM_ACTIVE_WRITE_BIAS, &sem->count);\r\nif (rwsem_optimistic_spin(sem))\r\nreturn sem;\r\nwaiter.task = current;\r\nwaiter.type = RWSEM_WAITING_FOR_WRITE;\r\nraw_spin_lock_irq(&sem->wait_lock);\r\nif (list_empty(&sem->wait_list))\r\nwaiting = false;\r\nlist_add_tail(&waiter.list, &sem->wait_list);\r\nif (waiting) {\r\ncount = atomic_long_read(&sem->count);\r\nif (count > RWSEM_WAITING_BIAS) {\r\n__rwsem_mark_wake(sem, RWSEM_WAKE_READERS, &wake_q);\r\nwake_up_q(&wake_q);\r\nwake_q_init(&wake_q);\r\n}\r\n} else\r\ncount = atomic_long_add_return(RWSEM_WAITING_BIAS, &sem->count);\r\nset_current_state(state);\r\nwhile (true) {\r\nif (rwsem_try_write_lock(count, sem))\r\nbreak;\r\nraw_spin_unlock_irq(&sem->wait_lock);\r\ndo {\r\nif (signal_pending_state(state, current))\r\ngoto out_nolock;\r\nschedule();\r\nset_current_state(state);\r\n} while ((count = atomic_long_read(&sem->count)) & RWSEM_ACTIVE_MASK);\r\nraw_spin_lock_irq(&sem->wait_lock);\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nlist_del(&waiter.list);\r\nraw_spin_unlock_irq(&sem->wait_lock);\r\nreturn ret;\r\nout_nolock:\r\n__set_current_state(TASK_RUNNING);\r\nraw_spin_lock_irq(&sem->wait_lock);\r\nlist_del(&waiter.list);\r\nif (list_empty(&sem->wait_list))\r\natomic_long_add(-RWSEM_WAITING_BIAS, &sem->count);\r\nelse\r\n__rwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\r\nraw_spin_unlock_irq(&sem->wait_lock);\r\nwake_up_q(&wake_q);\r\nreturn ERR_PTR(-EINTR);\r\n}\r\n__visible struct rw_semaphore * __sched\r\nrwsem_down_write_failed(struct rw_semaphore *sem)\r\n{\r\nreturn __rwsem_down_write_failed_common(sem, TASK_UNINTERRUPTIBLE);\r\n}\r\n__visible struct rw_semaphore * __sched\r\nrwsem_down_write_failed_killable(struct rw_semaphore *sem)\r\n{\r\nreturn __rwsem_down_write_failed_common(sem, TASK_KILLABLE);\r\n}\r\n__visible\r\nstruct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\r\n{\r\nunsigned long flags;\r\nDEFINE_WAKE_Q(wake_q);\r\nif (rwsem_has_spinner(sem)) {\r\nsmp_rmb();\r\nif (!raw_spin_trylock_irqsave(&sem->wait_lock, flags))\r\nreturn sem;\r\ngoto locked;\r\n}\r\nraw_spin_lock_irqsave(&sem->wait_lock, flags);\r\nlocked:\r\nif (!list_empty(&sem->wait_list))\r\n__rwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\r\nraw_spin_unlock_irqrestore(&sem->wait_lock, flags);\r\nwake_up_q(&wake_q);\r\nreturn sem;\r\n}\r\n__visible\r\nstruct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)\r\n{\r\nunsigned long flags;\r\nDEFINE_WAKE_Q(wake_q);\r\nraw_spin_lock_irqsave(&sem->wait_lock, flags);\r\nif (!list_empty(&sem->wait_list))\r\n__rwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED, &wake_q);\r\nraw_spin_unlock_irqrestore(&sem->wait_lock, flags);\r\nwake_up_q(&wake_q);\r\nreturn sem;\r\n}
