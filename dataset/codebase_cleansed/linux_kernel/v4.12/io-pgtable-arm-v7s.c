static dma_addr_t __arm_v7s_dma_addr(void *pages)\r\n{\r\nreturn (dma_addr_t)virt_to_phys(pages);\r\n}\r\nstatic arm_v7s_iopte *iopte_deref(arm_v7s_iopte pte, int lvl)\r\n{\r\nif (ARM_V7S_PTE_IS_TABLE(pte, lvl))\r\npte &= ARM_V7S_TABLE_MASK;\r\nelse\r\npte &= ARM_V7S_LVL_MASK(lvl);\r\nreturn phys_to_virt(pte);\r\n}\r\nstatic void *__arm_v7s_alloc_table(int lvl, gfp_t gfp,\r\nstruct arm_v7s_io_pgtable *data)\r\n{\r\nstruct device *dev = data->iop.cfg.iommu_dev;\r\ndma_addr_t dma;\r\nsize_t size = ARM_V7S_TABLE_SIZE(lvl);\r\nvoid *table = NULL;\r\nif (lvl == 1)\r\ntable = (void *)__get_dma_pages(__GFP_ZERO, get_order(size));\r\nelse if (lvl == 2)\r\ntable = kmem_cache_zalloc(data->l2_tables, gfp | GFP_DMA);\r\nif (table && !selftest_running) {\r\ndma = dma_map_single(dev, table, size, DMA_TO_DEVICE);\r\nif (dma_mapping_error(dev, dma))\r\ngoto out_free;\r\nif (dma != virt_to_phys(table))\r\ngoto out_unmap;\r\n}\r\nkmemleak_ignore(table);\r\nreturn table;\r\nout_unmap:\r\ndev_err(dev, "Cannot accommodate DMA translation for IOMMU page tables\n");\r\ndma_unmap_single(dev, dma, size, DMA_TO_DEVICE);\r\nout_free:\r\nif (lvl == 1)\r\nfree_pages((unsigned long)table, get_order(size));\r\nelse\r\nkmem_cache_free(data->l2_tables, table);\r\nreturn NULL;\r\n}\r\nstatic void __arm_v7s_free_table(void *table, int lvl,\r\nstruct arm_v7s_io_pgtable *data)\r\n{\r\nstruct device *dev = data->iop.cfg.iommu_dev;\r\nsize_t size = ARM_V7S_TABLE_SIZE(lvl);\r\nif (!selftest_running)\r\ndma_unmap_single(dev, __arm_v7s_dma_addr(table), size,\r\nDMA_TO_DEVICE);\r\nif (lvl == 1)\r\nfree_pages((unsigned long)table, get_order(size));\r\nelse\r\nkmem_cache_free(data->l2_tables, table);\r\n}\r\nstatic void __arm_v7s_pte_sync(arm_v7s_iopte *ptep, int num_entries,\r\nstruct io_pgtable_cfg *cfg)\r\n{\r\nif (selftest_running)\r\nreturn;\r\ndma_sync_single_for_device(cfg->iommu_dev, __arm_v7s_dma_addr(ptep),\r\nnum_entries * sizeof(*ptep), DMA_TO_DEVICE);\r\n}\r\nstatic void __arm_v7s_set_pte(arm_v7s_iopte *ptep, arm_v7s_iopte pte,\r\nint num_entries, struct io_pgtable_cfg *cfg)\r\n{\r\nint i;\r\nfor (i = 0; i < num_entries; i++)\r\nptep[i] = pte;\r\n__arm_v7s_pte_sync(ptep, num_entries, cfg);\r\n}\r\nstatic arm_v7s_iopte arm_v7s_prot_to_pte(int prot, int lvl,\r\nstruct io_pgtable_cfg *cfg)\r\n{\r\nbool ap = !(cfg->quirks & IO_PGTABLE_QUIRK_NO_PERMS);\r\narm_v7s_iopte pte = ARM_V7S_ATTR_NG | ARM_V7S_ATTR_S;\r\nif (!(prot & IOMMU_MMIO))\r\npte |= ARM_V7S_ATTR_TEX(1);\r\nif (ap) {\r\npte |= ARM_V7S_PTE_AF;\r\nif (!(prot & IOMMU_PRIV))\r\npte |= ARM_V7S_PTE_AP_UNPRIV;\r\nif (!(prot & IOMMU_WRITE))\r\npte |= ARM_V7S_PTE_AP_RDONLY;\r\n}\r\npte <<= ARM_V7S_ATTR_SHIFT(lvl);\r\nif ((prot & IOMMU_NOEXEC) && ap)\r\npte |= ARM_V7S_ATTR_XN(lvl);\r\nif (prot & IOMMU_MMIO)\r\npte |= ARM_V7S_ATTR_B;\r\nelse if (prot & IOMMU_CACHE)\r\npte |= ARM_V7S_ATTR_B | ARM_V7S_ATTR_C;\r\nreturn pte;\r\n}\r\nstatic int arm_v7s_pte_to_prot(arm_v7s_iopte pte, int lvl)\r\n{\r\nint prot = IOMMU_READ;\r\narm_v7s_iopte attr = pte >> ARM_V7S_ATTR_SHIFT(lvl);\r\nif (!(attr & ARM_V7S_PTE_AP_RDONLY))\r\nprot |= IOMMU_WRITE;\r\nif (!(attr & ARM_V7S_PTE_AP_UNPRIV))\r\nprot |= IOMMU_PRIV;\r\nif ((attr & (ARM_V7S_TEX_MASK << ARM_V7S_TEX_SHIFT)) == 0)\r\nprot |= IOMMU_MMIO;\r\nelse if (pte & ARM_V7S_ATTR_C)\r\nprot |= IOMMU_CACHE;\r\nif (pte & ARM_V7S_ATTR_XN(lvl))\r\nprot |= IOMMU_NOEXEC;\r\nreturn prot;\r\n}\r\nstatic arm_v7s_iopte arm_v7s_pte_to_cont(arm_v7s_iopte pte, int lvl)\r\n{\r\nif (lvl == 1) {\r\npte |= ARM_V7S_CONT_SECTION;\r\n} else if (lvl == 2) {\r\narm_v7s_iopte xn = pte & ARM_V7S_ATTR_XN(lvl);\r\narm_v7s_iopte tex = pte & ARM_V7S_CONT_PAGE_TEX_MASK;\r\npte ^= xn | tex | ARM_V7S_PTE_TYPE_PAGE;\r\npte |= (xn << ARM_V7S_CONT_PAGE_XN_SHIFT) |\r\n(tex << ARM_V7S_CONT_PAGE_TEX_SHIFT) |\r\nARM_V7S_PTE_TYPE_CONT_PAGE;\r\n}\r\nreturn pte;\r\n}\r\nstatic arm_v7s_iopte arm_v7s_cont_to_pte(arm_v7s_iopte pte, int lvl)\r\n{\r\nif (lvl == 1) {\r\npte &= ~ARM_V7S_CONT_SECTION;\r\n} else if (lvl == 2) {\r\narm_v7s_iopte xn = pte & BIT(ARM_V7S_CONT_PAGE_XN_SHIFT);\r\narm_v7s_iopte tex = pte & (ARM_V7S_CONT_PAGE_TEX_MASK <<\r\nARM_V7S_CONT_PAGE_TEX_SHIFT);\r\npte ^= xn | tex | ARM_V7S_PTE_TYPE_CONT_PAGE;\r\npte |= (xn >> ARM_V7S_CONT_PAGE_XN_SHIFT) |\r\n(tex >> ARM_V7S_CONT_PAGE_TEX_SHIFT) |\r\nARM_V7S_PTE_TYPE_PAGE;\r\n}\r\nreturn pte;\r\n}\r\nstatic bool arm_v7s_pte_is_cont(arm_v7s_iopte pte, int lvl)\r\n{\r\nif (lvl == 1 && !ARM_V7S_PTE_IS_TABLE(pte, lvl))\r\nreturn pte & ARM_V7S_CONT_SECTION;\r\nelse if (lvl == 2)\r\nreturn !(pte & ARM_V7S_PTE_TYPE_PAGE);\r\nreturn false;\r\n}\r\nstatic int arm_v7s_init_pte(struct arm_v7s_io_pgtable *data,\r\nunsigned long iova, phys_addr_t paddr, int prot,\r\nint lvl, int num_entries, arm_v7s_iopte *ptep)\r\n{\r\nstruct io_pgtable_cfg *cfg = &data->iop.cfg;\r\narm_v7s_iopte pte = arm_v7s_prot_to_pte(prot, lvl, cfg);\r\nint i;\r\nfor (i = 0; i < num_entries; i++)\r\nif (ARM_V7S_PTE_IS_TABLE(ptep[i], lvl)) {\r\narm_v7s_iopte *tblp;\r\nsize_t sz = ARM_V7S_BLOCK_SIZE(lvl);\r\ntblp = ptep - ARM_V7S_LVL_IDX(iova, lvl);\r\nif (WARN_ON(__arm_v7s_unmap(data, iova + i * sz,\r\nsz, lvl, tblp) != sz))\r\nreturn -EINVAL;\r\n} else if (ptep[i]) {\r\nWARN_ON(!selftest_running);\r\nreturn -EEXIST;\r\n}\r\npte |= ARM_V7S_PTE_TYPE_PAGE;\r\nif (lvl == 1 && (cfg->quirks & IO_PGTABLE_QUIRK_ARM_NS))\r\npte |= ARM_V7S_ATTR_NS_SECTION;\r\nif (cfg->quirks & IO_PGTABLE_QUIRK_ARM_MTK_4GB)\r\npte |= ARM_V7S_ATTR_MTK_4GB;\r\nif (num_entries > 1)\r\npte = arm_v7s_pte_to_cont(pte, lvl);\r\npte |= paddr & ARM_V7S_LVL_MASK(lvl);\r\n__arm_v7s_set_pte(ptep, pte, num_entries, cfg);\r\nreturn 0;\r\n}\r\nstatic int __arm_v7s_map(struct arm_v7s_io_pgtable *data, unsigned long iova,\r\nphys_addr_t paddr, size_t size, int prot,\r\nint lvl, arm_v7s_iopte *ptep)\r\n{\r\nstruct io_pgtable_cfg *cfg = &data->iop.cfg;\r\narm_v7s_iopte pte, *cptep;\r\nint num_entries = size >> ARM_V7S_LVL_SHIFT(lvl);\r\nptep += ARM_V7S_LVL_IDX(iova, lvl);\r\nif (num_entries)\r\nreturn arm_v7s_init_pte(data, iova, paddr, prot,\r\nlvl, num_entries, ptep);\r\nif (WARN_ON(lvl == 2))\r\nreturn -EINVAL;\r\npte = *ptep;\r\nif (!pte) {\r\ncptep = __arm_v7s_alloc_table(lvl + 1, GFP_ATOMIC, data);\r\nif (!cptep)\r\nreturn -ENOMEM;\r\npte = virt_to_phys(cptep) | ARM_V7S_PTE_TYPE_TABLE;\r\nif (cfg->quirks & IO_PGTABLE_QUIRK_ARM_NS)\r\npte |= ARM_V7S_ATTR_NS_TABLE;\r\n__arm_v7s_set_pte(ptep, pte, 1, cfg);\r\n} else if (ARM_V7S_PTE_IS_TABLE(pte, lvl)) {\r\ncptep = iopte_deref(pte, lvl);\r\n} else {\r\nWARN_ON(!selftest_running);\r\nreturn -EEXIST;\r\n}\r\nreturn __arm_v7s_map(data, iova, paddr, size, prot, lvl + 1, cptep);\r\n}\r\nstatic int arm_v7s_map(struct io_pgtable_ops *ops, unsigned long iova,\r\nphys_addr_t paddr, size_t size, int prot)\r\n{\r\nstruct arm_v7s_io_pgtable *data = io_pgtable_ops_to_data(ops);\r\nstruct io_pgtable *iop = &data->iop;\r\nint ret;\r\nif (!(prot & (IOMMU_READ | IOMMU_WRITE)))\r\nreturn 0;\r\nret = __arm_v7s_map(data, iova, paddr, size, prot, 1, data->pgd);\r\nif (iop->cfg.quirks & IO_PGTABLE_QUIRK_TLBI_ON_MAP) {\r\nio_pgtable_tlb_add_flush(iop, iova, size,\r\nARM_V7S_BLOCK_SIZE(2), false);\r\nio_pgtable_tlb_sync(iop);\r\n} else {\r\nwmb();\r\n}\r\nreturn ret;\r\n}\r\nstatic void arm_v7s_free_pgtable(struct io_pgtable *iop)\r\n{\r\nstruct arm_v7s_io_pgtable *data = io_pgtable_to_data(iop);\r\nint i;\r\nfor (i = 0; i < ARM_V7S_PTES_PER_LVL(1); i++) {\r\narm_v7s_iopte pte = data->pgd[i];\r\nif (ARM_V7S_PTE_IS_TABLE(pte, 1))\r\n__arm_v7s_free_table(iopte_deref(pte, 1), 2, data);\r\n}\r\n__arm_v7s_free_table(data->pgd, 1, data);\r\nkmem_cache_destroy(data->l2_tables);\r\nkfree(data);\r\n}\r\nstatic void arm_v7s_split_cont(struct arm_v7s_io_pgtable *data,\r\nunsigned long iova, int idx, int lvl,\r\narm_v7s_iopte *ptep)\r\n{\r\nstruct io_pgtable *iop = &data->iop;\r\narm_v7s_iopte pte;\r\nsize_t size = ARM_V7S_BLOCK_SIZE(lvl);\r\nint i;\r\nptep -= idx & (ARM_V7S_CONT_PAGES - 1);\r\npte = arm_v7s_cont_to_pte(*ptep, lvl);\r\nfor (i = 0; i < ARM_V7S_CONT_PAGES; i++) {\r\nptep[i] = pte;\r\npte += size;\r\n}\r\n__arm_v7s_pte_sync(ptep, ARM_V7S_CONT_PAGES, &iop->cfg);\r\nsize *= ARM_V7S_CONT_PAGES;\r\nio_pgtable_tlb_add_flush(iop, iova, size, size, true);\r\nio_pgtable_tlb_sync(iop);\r\n}\r\nstatic int arm_v7s_split_blk_unmap(struct arm_v7s_io_pgtable *data,\r\nunsigned long iova, size_t size,\r\narm_v7s_iopte *ptep)\r\n{\r\nunsigned long blk_start, blk_end, blk_size;\r\nphys_addr_t blk_paddr;\r\narm_v7s_iopte table = 0;\r\nint prot = arm_v7s_pte_to_prot(*ptep, 1);\r\nblk_size = ARM_V7S_BLOCK_SIZE(1);\r\nblk_start = iova & ARM_V7S_LVL_MASK(1);\r\nblk_end = blk_start + ARM_V7S_BLOCK_SIZE(1);\r\nblk_paddr = *ptep & ARM_V7S_LVL_MASK(1);\r\nfor (; blk_start < blk_end; blk_start += size, blk_paddr += size) {\r\narm_v7s_iopte *tablep;\r\nif (blk_start == iova)\r\ncontinue;\r\ntablep = &table - ARM_V7S_LVL_IDX(blk_start, 1);\r\nif (__arm_v7s_map(data, blk_start, blk_paddr, size, prot, 1,\r\ntablep) < 0) {\r\nif (table) {\r\ntablep = iopte_deref(table, 1);\r\n__arm_v7s_free_table(tablep, 2, data);\r\n}\r\nreturn 0;\r\n}\r\n}\r\n__arm_v7s_set_pte(ptep, table, 1, &data->iop.cfg);\r\niova &= ~(blk_size - 1);\r\nio_pgtable_tlb_add_flush(&data->iop, iova, blk_size, blk_size, true);\r\nreturn size;\r\n}\r\nstatic int __arm_v7s_unmap(struct arm_v7s_io_pgtable *data,\r\nunsigned long iova, size_t size, int lvl,\r\narm_v7s_iopte *ptep)\r\n{\r\narm_v7s_iopte pte[ARM_V7S_CONT_PAGES];\r\nstruct io_pgtable *iop = &data->iop;\r\nint idx, i = 0, num_entries = size >> ARM_V7S_LVL_SHIFT(lvl);\r\nif (WARN_ON(lvl > 2))\r\nreturn 0;\r\nidx = ARM_V7S_LVL_IDX(iova, lvl);\r\nptep += idx;\r\ndo {\r\nif (WARN_ON(!ARM_V7S_PTE_IS_VALID(ptep[i])))\r\nreturn 0;\r\npte[i] = ptep[i];\r\n} while (++i < num_entries);\r\nif (num_entries <= 1 && arm_v7s_pte_is_cont(pte[0], lvl))\r\narm_v7s_split_cont(data, iova, idx, lvl, ptep);\r\nif (num_entries) {\r\nsize_t blk_size = ARM_V7S_BLOCK_SIZE(lvl);\r\n__arm_v7s_set_pte(ptep, 0, num_entries, &iop->cfg);\r\nfor (i = 0; i < num_entries; i++) {\r\nif (ARM_V7S_PTE_IS_TABLE(pte[i], lvl)) {\r\nio_pgtable_tlb_add_flush(iop, iova, blk_size,\r\nARM_V7S_BLOCK_SIZE(lvl + 1), false);\r\nio_pgtable_tlb_sync(iop);\r\nptep = iopte_deref(pte[i], lvl);\r\n__arm_v7s_free_table(ptep, lvl + 1, data);\r\n} else {\r\nio_pgtable_tlb_add_flush(iop, iova, blk_size,\r\nblk_size, true);\r\n}\r\niova += blk_size;\r\n}\r\nreturn size;\r\n} else if (lvl == 1 && !ARM_V7S_PTE_IS_TABLE(pte[0], lvl)) {\r\nreturn arm_v7s_split_blk_unmap(data, iova, size, ptep);\r\n}\r\nptep = iopte_deref(pte[0], lvl);\r\nreturn __arm_v7s_unmap(data, iova, size, lvl + 1, ptep);\r\n}\r\nstatic int arm_v7s_unmap(struct io_pgtable_ops *ops, unsigned long iova,\r\nsize_t size)\r\n{\r\nstruct arm_v7s_io_pgtable *data = io_pgtable_ops_to_data(ops);\r\nsize_t unmapped;\r\nunmapped = __arm_v7s_unmap(data, iova, size, 1, data->pgd);\r\nif (unmapped)\r\nio_pgtable_tlb_sync(&data->iop);\r\nreturn unmapped;\r\n}\r\nstatic phys_addr_t arm_v7s_iova_to_phys(struct io_pgtable_ops *ops,\r\nunsigned long iova)\r\n{\r\nstruct arm_v7s_io_pgtable *data = io_pgtable_ops_to_data(ops);\r\narm_v7s_iopte *ptep = data->pgd, pte;\r\nint lvl = 0;\r\nu32 mask;\r\ndo {\r\npte = ptep[ARM_V7S_LVL_IDX(iova, ++lvl)];\r\nptep = iopte_deref(pte, lvl);\r\n} while (ARM_V7S_PTE_IS_TABLE(pte, lvl));\r\nif (!ARM_V7S_PTE_IS_VALID(pte))\r\nreturn 0;\r\nmask = ARM_V7S_LVL_MASK(lvl);\r\nif (arm_v7s_pte_is_cont(pte, lvl))\r\nmask *= ARM_V7S_CONT_PAGES;\r\nreturn (pte & mask) | (iova & ~mask);\r\n}\r\nstatic struct io_pgtable *arm_v7s_alloc_pgtable(struct io_pgtable_cfg *cfg,\r\nvoid *cookie)\r\n{\r\nstruct arm_v7s_io_pgtable *data;\r\n#ifdef PHYS_OFFSET\r\nif (upper_32_bits(PHYS_OFFSET))\r\nreturn NULL;\r\n#endif\r\nif (cfg->ias > ARM_V7S_ADDR_BITS || cfg->oas > ARM_V7S_ADDR_BITS)\r\nreturn NULL;\r\nif (cfg->quirks & ~(IO_PGTABLE_QUIRK_ARM_NS |\r\nIO_PGTABLE_QUIRK_NO_PERMS |\r\nIO_PGTABLE_QUIRK_TLBI_ON_MAP |\r\nIO_PGTABLE_QUIRK_ARM_MTK_4GB))\r\nreturn NULL;\r\nif (cfg->quirks & IO_PGTABLE_QUIRK_ARM_MTK_4GB &&\r\n!(cfg->quirks & IO_PGTABLE_QUIRK_NO_PERMS))\r\nreturn NULL;\r\ndata = kmalloc(sizeof(*data), GFP_KERNEL);\r\nif (!data)\r\nreturn NULL;\r\ndata->l2_tables = kmem_cache_create("io-pgtable_armv7s_l2",\r\nARM_V7S_TABLE_SIZE(2),\r\nARM_V7S_TABLE_SIZE(2),\r\nSLAB_CACHE_DMA, NULL);\r\nif (!data->l2_tables)\r\ngoto out_free_data;\r\ndata->iop.ops = (struct io_pgtable_ops) {\r\n.map = arm_v7s_map,\r\n.unmap = arm_v7s_unmap,\r\n.iova_to_phys = arm_v7s_iova_to_phys,\r\n};\r\ndata->iop.cfg = *cfg;\r\ncfg->pgsize_bitmap &= SZ_4K | SZ_64K | SZ_1M | SZ_16M;\r\ncfg->arm_v7s_cfg.tcr = ARM_V7S_TCR_PD1;\r\ncfg->arm_v7s_cfg.prrr = ARM_V7S_PRRR_TR(1, ARM_V7S_PRRR_TYPE_DEVICE) |\r\nARM_V7S_PRRR_TR(4, ARM_V7S_PRRR_TYPE_NORMAL) |\r\nARM_V7S_PRRR_TR(7, ARM_V7S_PRRR_TYPE_NORMAL) |\r\nARM_V7S_PRRR_DS0 | ARM_V7S_PRRR_DS1 |\r\nARM_V7S_PRRR_NS1 | ARM_V7S_PRRR_NOS(7);\r\ncfg->arm_v7s_cfg.nmrr = ARM_V7S_NMRR_IR(7, ARM_V7S_RGN_WBWA) |\r\nARM_V7S_NMRR_OR(7, ARM_V7S_RGN_WBWA);\r\ndata->pgd = __arm_v7s_alloc_table(1, GFP_KERNEL, data);\r\nif (!data->pgd)\r\ngoto out_free_data;\r\nwmb();\r\ncfg->arm_v7s_cfg.ttbr[0] = virt_to_phys(data->pgd) |\r\nARM_V7S_TTBR_S | ARM_V7S_TTBR_NOS |\r\nARM_V7S_TTBR_IRGN_ATTR(ARM_V7S_RGN_WBWA) |\r\nARM_V7S_TTBR_ORGN_ATTR(ARM_V7S_RGN_WBWA);\r\ncfg->arm_v7s_cfg.ttbr[1] = 0;\r\nreturn &data->iop;\r\nout_free_data:\r\nkmem_cache_destroy(data->l2_tables);\r\nkfree(data);\r\nreturn NULL;\r\n}\r\nstatic void dummy_tlb_flush_all(void *cookie)\r\n{\r\nWARN_ON(cookie != cfg_cookie);\r\n}\r\nstatic void dummy_tlb_add_flush(unsigned long iova, size_t size,\r\nsize_t granule, bool leaf, void *cookie)\r\n{\r\nWARN_ON(cookie != cfg_cookie);\r\nWARN_ON(!(size & cfg_cookie->pgsize_bitmap));\r\n}\r\nstatic void dummy_tlb_sync(void *cookie)\r\n{\r\nWARN_ON(cookie != cfg_cookie);\r\n}\r\nstatic int __init arm_v7s_do_selftests(void)\r\n{\r\nstruct io_pgtable_ops *ops;\r\nstruct io_pgtable_cfg cfg = {\r\n.tlb = &dummy_tlb_ops,\r\n.oas = 32,\r\n.ias = 32,\r\n.quirks = IO_PGTABLE_QUIRK_ARM_NS,\r\n.pgsize_bitmap = SZ_4K | SZ_64K | SZ_1M | SZ_16M,\r\n};\r\nunsigned int iova, size, iova_start;\r\nunsigned int i, loopnr = 0;\r\nselftest_running = true;\r\ncfg_cookie = &cfg;\r\nops = alloc_io_pgtable_ops(ARM_V7S, &cfg, &cfg);\r\nif (!ops) {\r\npr_err("selftest: failed to allocate io pgtable ops\n");\r\nreturn -EINVAL;\r\n}\r\nif (ops->iova_to_phys(ops, 42))\r\nreturn __FAIL(ops);\r\nif (ops->iova_to_phys(ops, SZ_1G + 42))\r\nreturn __FAIL(ops);\r\nif (ops->iova_to_phys(ops, SZ_2G + 42))\r\nreturn __FAIL(ops);\r\niova = 0;\r\nfor_each_set_bit(i, &cfg.pgsize_bitmap, BITS_PER_LONG) {\r\nsize = 1UL << i;\r\nif (ops->map(ops, iova, iova, size, IOMMU_READ |\r\nIOMMU_WRITE |\r\nIOMMU_NOEXEC |\r\nIOMMU_CACHE))\r\nreturn __FAIL(ops);\r\nif (!ops->map(ops, iova, iova + size, size,\r\nIOMMU_READ | IOMMU_NOEXEC))\r\nreturn __FAIL(ops);\r\nif (ops->iova_to_phys(ops, iova + 42) != (iova + 42))\r\nreturn __FAIL(ops);\r\niova += SZ_16M;\r\nloopnr++;\r\n}\r\ni = 1;\r\nsize = 1UL << __ffs(cfg.pgsize_bitmap);\r\nwhile (i < loopnr) {\r\niova_start = i * SZ_16M;\r\nif (ops->unmap(ops, iova_start + size, size) != size)\r\nreturn __FAIL(ops);\r\nif (ops->map(ops, iova_start + size, size, size, IOMMU_READ))\r\nreturn __FAIL(ops);\r\nif (ops->iova_to_phys(ops, iova_start + size + 42)\r\n!= (size + 42))\r\nreturn __FAIL(ops);\r\ni++;\r\n}\r\niova = 0;\r\ni = find_first_bit(&cfg.pgsize_bitmap, BITS_PER_LONG);\r\nwhile (i != BITS_PER_LONG) {\r\nsize = 1UL << i;\r\nif (ops->unmap(ops, iova, size) != size)\r\nreturn __FAIL(ops);\r\nif (ops->iova_to_phys(ops, iova + 42))\r\nreturn __FAIL(ops);\r\nif (ops->map(ops, iova, iova, size, IOMMU_WRITE))\r\nreturn __FAIL(ops);\r\nif (ops->iova_to_phys(ops, iova + 42) != (iova + 42))\r\nreturn __FAIL(ops);\r\niova += SZ_16M;\r\ni++;\r\ni = find_next_bit(&cfg.pgsize_bitmap, BITS_PER_LONG, i);\r\n}\r\nfree_io_pgtable_ops(ops);\r\nselftest_running = false;\r\npr_info("self test ok\n");\r\nreturn 0;\r\n}
