static struct mtk_iommu_domain *to_mtk_domain(struct iommu_domain *dom)\r\n{\r\nreturn container_of(dom, struct mtk_iommu_domain, domain);\r\n}\r\nstatic void mtk_iommu_tlb_flush_all(void *cookie)\r\n{\r\nstruct mtk_iommu_data *data = cookie;\r\nwritel_relaxed(F_INVLD_EN1 | F_INVLD_EN0, data->base + REG_MMU_INV_SEL);\r\nwritel_relaxed(F_ALL_INVLD, data->base + REG_MMU_INVALIDATE);\r\nwmb();\r\n}\r\nstatic void mtk_iommu_tlb_add_flush_nosync(unsigned long iova, size_t size,\r\nsize_t granule, bool leaf,\r\nvoid *cookie)\r\n{\r\nstruct mtk_iommu_data *data = cookie;\r\nwritel_relaxed(F_INVLD_EN1 | F_INVLD_EN0, data->base + REG_MMU_INV_SEL);\r\nwritel_relaxed(iova, data->base + REG_MMU_INVLD_START_A);\r\nwritel_relaxed(iova + size - 1, data->base + REG_MMU_INVLD_END_A);\r\nwritel_relaxed(F_MMU_INV_RANGE, data->base + REG_MMU_INVALIDATE);\r\n}\r\nstatic void mtk_iommu_tlb_sync(void *cookie)\r\n{\r\nstruct mtk_iommu_data *data = cookie;\r\nint ret;\r\nu32 tmp;\r\nret = readl_poll_timeout_atomic(data->base + REG_MMU_CPE_DONE, tmp,\r\ntmp != 0, 10, 100000);\r\nif (ret) {\r\ndev_warn(data->dev,\r\n"Partial TLB flush timed out, falling back to full flush\n");\r\nmtk_iommu_tlb_flush_all(cookie);\r\n}\r\nwritel_relaxed(0, data->base + REG_MMU_CPE_DONE);\r\n}\r\nstatic irqreturn_t mtk_iommu_isr(int irq, void *dev_id)\r\n{\r\nstruct mtk_iommu_data *data = dev_id;\r\nstruct mtk_iommu_domain *dom = data->m4u_dom;\r\nu32 int_state, regval, fault_iova, fault_pa;\r\nunsigned int fault_larb, fault_port;\r\nbool layer, write;\r\nint_state = readl_relaxed(data->base + REG_MMU_FAULT_ST1);\r\nfault_iova = readl_relaxed(data->base + REG_MMU_FAULT_VA);\r\nlayer = fault_iova & F_MMU_FAULT_VA_LAYER_BIT;\r\nwrite = fault_iova & F_MMU_FAULT_VA_WRITE_BIT;\r\nfault_iova &= F_MMU_FAULT_VA_MSK;\r\nfault_pa = readl_relaxed(data->base + REG_MMU_INVLD_PA);\r\nregval = readl_relaxed(data->base + REG_MMU_INT_ID);\r\nfault_larb = F_MMU0_INT_ID_LARB_ID(regval);\r\nfault_port = F_MMU0_INT_ID_PORT_ID(regval);\r\nif (report_iommu_fault(&dom->domain, data->dev, fault_iova,\r\nwrite ? IOMMU_FAULT_WRITE : IOMMU_FAULT_READ)) {\r\ndev_err_ratelimited(\r\ndata->dev,\r\n"fault type=0x%x iova=0x%x pa=0x%x larb=%d port=%d layer=%d %s\n",\r\nint_state, fault_iova, fault_pa, fault_larb, fault_port,\r\nlayer, write ? "write" : "read");\r\n}\r\nregval = readl_relaxed(data->base + REG_MMU_INT_CONTROL0);\r\nregval |= F_INT_CLR_BIT;\r\nwritel_relaxed(regval, data->base + REG_MMU_INT_CONTROL0);\r\nmtk_iommu_tlb_flush_all(data);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void mtk_iommu_config(struct mtk_iommu_data *data,\r\nstruct device *dev, bool enable)\r\n{\r\nstruct mtk_smi_larb_iommu *larb_mmu;\r\nunsigned int larbid, portid;\r\nstruct iommu_fwspec *fwspec = dev->iommu_fwspec;\r\nint i;\r\nfor (i = 0; i < fwspec->num_ids; ++i) {\r\nlarbid = MTK_M4U_TO_LARB(fwspec->ids[i]);\r\nportid = MTK_M4U_TO_PORT(fwspec->ids[i]);\r\nlarb_mmu = &data->smi_imu.larb_imu[larbid];\r\ndev_dbg(dev, "%s iommu port: %d\n",\r\nenable ? "enable" : "disable", portid);\r\nif (enable)\r\nlarb_mmu->mmu |= MTK_SMI_MMU_EN(portid);\r\nelse\r\nlarb_mmu->mmu &= ~MTK_SMI_MMU_EN(portid);\r\n}\r\n}\r\nstatic int mtk_iommu_domain_finalise(struct mtk_iommu_data *data)\r\n{\r\nstruct mtk_iommu_domain *dom = data->m4u_dom;\r\nspin_lock_init(&dom->pgtlock);\r\ndom->cfg = (struct io_pgtable_cfg) {\r\n.quirks = IO_PGTABLE_QUIRK_ARM_NS |\r\nIO_PGTABLE_QUIRK_NO_PERMS |\r\nIO_PGTABLE_QUIRK_TLBI_ON_MAP,\r\n.pgsize_bitmap = mtk_iommu_ops.pgsize_bitmap,\r\n.ias = 32,\r\n.oas = 32,\r\n.tlb = &mtk_iommu_gather_ops,\r\n.iommu_dev = data->dev,\r\n};\r\nif (data->enable_4GB)\r\ndom->cfg.quirks |= IO_PGTABLE_QUIRK_ARM_MTK_4GB;\r\ndom->iop = alloc_io_pgtable_ops(ARM_V7S, &dom->cfg, data);\r\nif (!dom->iop) {\r\ndev_err(data->dev, "Failed to alloc io pgtable\n");\r\nreturn -EINVAL;\r\n}\r\ndom->domain.pgsize_bitmap = dom->cfg.pgsize_bitmap;\r\nwritel(data->m4u_dom->cfg.arm_v7s_cfg.ttbr[0],\r\ndata->base + REG_MMU_PT_BASE_ADDR);\r\nreturn 0;\r\n}\r\nstatic struct iommu_domain *mtk_iommu_domain_alloc(unsigned type)\r\n{\r\nstruct mtk_iommu_domain *dom;\r\nif (type != IOMMU_DOMAIN_DMA)\r\nreturn NULL;\r\ndom = kzalloc(sizeof(*dom), GFP_KERNEL);\r\nif (!dom)\r\nreturn NULL;\r\nif (iommu_get_dma_cookie(&dom->domain)) {\r\nkfree(dom);\r\nreturn NULL;\r\n}\r\ndom->domain.geometry.aperture_start = 0;\r\ndom->domain.geometry.aperture_end = DMA_BIT_MASK(32);\r\ndom->domain.geometry.force_aperture = true;\r\nreturn &dom->domain;\r\n}\r\nstatic void mtk_iommu_domain_free(struct iommu_domain *domain)\r\n{\r\niommu_put_dma_cookie(domain);\r\nkfree(to_mtk_domain(domain));\r\n}\r\nstatic int mtk_iommu_attach_device(struct iommu_domain *domain,\r\nstruct device *dev)\r\n{\r\nstruct mtk_iommu_domain *dom = to_mtk_domain(domain);\r\nstruct mtk_iommu_data *data = dev->iommu_fwspec->iommu_priv;\r\nint ret;\r\nif (!data)\r\nreturn -ENODEV;\r\nif (!data->m4u_dom) {\r\ndata->m4u_dom = dom;\r\nret = mtk_iommu_domain_finalise(data);\r\nif (ret) {\r\ndata->m4u_dom = NULL;\r\nreturn ret;\r\n}\r\n} else if (data->m4u_dom != dom) {\r\ndev_err(dev, "try to attach into the error iommu domain\n");\r\nreturn -EPERM;\r\n}\r\nmtk_iommu_config(data, dev, true);\r\nreturn 0;\r\n}\r\nstatic void mtk_iommu_detach_device(struct iommu_domain *domain,\r\nstruct device *dev)\r\n{\r\nstruct mtk_iommu_data *data = dev->iommu_fwspec->iommu_priv;\r\nif (!data)\r\nreturn;\r\nmtk_iommu_config(data, dev, false);\r\n}\r\nstatic int mtk_iommu_map(struct iommu_domain *domain, unsigned long iova,\r\nphys_addr_t paddr, size_t size, int prot)\r\n{\r\nstruct mtk_iommu_domain *dom = to_mtk_domain(domain);\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&dom->pgtlock, flags);\r\nret = dom->iop->map(dom->iop, iova, paddr, size, prot);\r\nspin_unlock_irqrestore(&dom->pgtlock, flags);\r\nreturn ret;\r\n}\r\nstatic size_t mtk_iommu_unmap(struct iommu_domain *domain,\r\nunsigned long iova, size_t size)\r\n{\r\nstruct mtk_iommu_domain *dom = to_mtk_domain(domain);\r\nunsigned long flags;\r\nsize_t unmapsz;\r\nspin_lock_irqsave(&dom->pgtlock, flags);\r\nunmapsz = dom->iop->unmap(dom->iop, iova, size);\r\nspin_unlock_irqrestore(&dom->pgtlock, flags);\r\nreturn unmapsz;\r\n}\r\nstatic phys_addr_t mtk_iommu_iova_to_phys(struct iommu_domain *domain,\r\ndma_addr_t iova)\r\n{\r\nstruct mtk_iommu_domain *dom = to_mtk_domain(domain);\r\nunsigned long flags;\r\nphys_addr_t pa;\r\nspin_lock_irqsave(&dom->pgtlock, flags);\r\npa = dom->iop->iova_to_phys(dom->iop, iova);\r\nspin_unlock_irqrestore(&dom->pgtlock, flags);\r\nreturn pa;\r\n}\r\nstatic int mtk_iommu_add_device(struct device *dev)\r\n{\r\nstruct mtk_iommu_data *data;\r\nstruct iommu_group *group;\r\nif (!dev->iommu_fwspec || dev->iommu_fwspec->ops != &mtk_iommu_ops)\r\nreturn -ENODEV;\r\ndata = dev->iommu_fwspec->iommu_priv;\r\niommu_device_link(&data->iommu, dev);\r\ngroup = iommu_group_get_for_dev(dev);\r\nif (IS_ERR(group))\r\nreturn PTR_ERR(group);\r\niommu_group_put(group);\r\nreturn 0;\r\n}\r\nstatic void mtk_iommu_remove_device(struct device *dev)\r\n{\r\nstruct mtk_iommu_data *data;\r\nif (!dev->iommu_fwspec || dev->iommu_fwspec->ops != &mtk_iommu_ops)\r\nreturn;\r\ndata = dev->iommu_fwspec->iommu_priv;\r\niommu_device_unlink(&data->iommu, dev);\r\niommu_group_remove_device(dev);\r\niommu_fwspec_free(dev);\r\n}\r\nstatic struct iommu_group *mtk_iommu_device_group(struct device *dev)\r\n{\r\nstruct mtk_iommu_data *data = dev->iommu_fwspec->iommu_priv;\r\nif (!data)\r\nreturn ERR_PTR(-ENODEV);\r\nif (!data->m4u_group) {\r\ndata->m4u_group = iommu_group_alloc();\r\nif (IS_ERR(data->m4u_group))\r\ndev_err(dev, "Failed to allocate M4U IOMMU group\n");\r\n} else {\r\niommu_group_ref_get(data->m4u_group);\r\n}\r\nreturn data->m4u_group;\r\n}\r\nstatic int mtk_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)\r\n{\r\nstruct platform_device *m4updev;\r\nif (args->args_count != 1) {\r\ndev_err(dev, "invalid #iommu-cells(%d) property for IOMMU\n",\r\nargs->args_count);\r\nreturn -EINVAL;\r\n}\r\nif (!dev->iommu_fwspec->iommu_priv) {\r\nm4updev = of_find_device_by_node(args->np);\r\nif (WARN_ON(!m4updev))\r\nreturn -EINVAL;\r\ndev->iommu_fwspec->iommu_priv = platform_get_drvdata(m4updev);\r\n}\r\nreturn iommu_fwspec_add_ids(dev, args->args, 1);\r\n}\r\nstatic int mtk_iommu_hw_init(const struct mtk_iommu_data *data)\r\n{\r\nu32 regval;\r\nint ret;\r\nret = clk_prepare_enable(data->bclk);\r\nif (ret) {\r\ndev_err(data->dev, "Failed to enable iommu bclk(%d)\n", ret);\r\nreturn ret;\r\n}\r\nregval = F_MMU_PREFETCH_RT_REPLACE_MOD |\r\nF_MMU_TF_PROTECT_SEL(2);\r\nwritel_relaxed(regval, data->base + REG_MMU_CTRL_REG);\r\nregval = F_L2_MULIT_HIT_EN |\r\nF_TABLE_WALK_FAULT_INT_EN |\r\nF_PREETCH_FIFO_OVERFLOW_INT_EN |\r\nF_MISS_FIFO_OVERFLOW_INT_EN |\r\nF_PREFETCH_FIFO_ERR_INT_EN |\r\nF_MISS_FIFO_ERR_INT_EN;\r\nwritel_relaxed(regval, data->base + REG_MMU_INT_CONTROL0);\r\nregval = F_INT_TRANSLATION_FAULT |\r\nF_INT_MAIN_MULTI_HIT_FAULT |\r\nF_INT_INVALID_PA_FAULT |\r\nF_INT_ENTRY_REPLACEMENT_FAULT |\r\nF_INT_TLB_MISS_FAULT |\r\nF_INT_MISS_TRANSACTION_FIFO_FAULT |\r\nF_INT_PRETETCH_TRANSATION_FIFO_FAULT;\r\nwritel_relaxed(regval, data->base + REG_MMU_INT_MAIN_CONTROL);\r\nwritel_relaxed(F_MMU_IVRP_PA_SET(data->protect_base, data->enable_4GB),\r\ndata->base + REG_MMU_IVRP_PADDR);\r\nwritel_relaxed(0, data->base + REG_MMU_DCM_DIS);\r\nwritel_relaxed(0, data->base + REG_MMU_STANDARD_AXI_MODE);\r\nif (devm_request_irq(data->dev, data->irq, mtk_iommu_isr, 0,\r\ndev_name(data->dev), (void *)data)) {\r\nwritel_relaxed(0, data->base + REG_MMU_PT_BASE_ADDR);\r\nclk_disable_unprepare(data->bclk);\r\ndev_err(data->dev, "Failed @ IRQ-%d Request\n", data->irq);\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int mtk_iommu_probe(struct platform_device *pdev)\r\n{\r\nstruct mtk_iommu_data *data;\r\nstruct device *dev = &pdev->dev;\r\nstruct resource *res;\r\nresource_size_t ioaddr;\r\nstruct component_match *match = NULL;\r\nvoid *protect;\r\nint i, larb_nr, ret;\r\ndata = devm_kzalloc(dev, sizeof(*data), GFP_KERNEL);\r\nif (!data)\r\nreturn -ENOMEM;\r\ndata->dev = dev;\r\nprotect = devm_kzalloc(dev, MTK_PROTECT_PA_ALIGN * 2, GFP_KERNEL);\r\nif (!protect)\r\nreturn -ENOMEM;\r\ndata->protect_base = ALIGN(virt_to_phys(protect), MTK_PROTECT_PA_ALIGN);\r\ndata->enable_4GB = !!(max_pfn > (0xffffffffUL >> PAGE_SHIFT));\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\ndata->base = devm_ioremap_resource(dev, res);\r\nif (IS_ERR(data->base))\r\nreturn PTR_ERR(data->base);\r\nioaddr = res->start;\r\ndata->irq = platform_get_irq(pdev, 0);\r\nif (data->irq < 0)\r\nreturn data->irq;\r\ndata->bclk = devm_clk_get(dev, "bclk");\r\nif (IS_ERR(data->bclk))\r\nreturn PTR_ERR(data->bclk);\r\nlarb_nr = of_count_phandle_with_args(dev->of_node,\r\n"mediatek,larbs", NULL);\r\nif (larb_nr < 0)\r\nreturn larb_nr;\r\ndata->smi_imu.larb_nr = larb_nr;\r\nfor (i = 0; i < larb_nr; i++) {\r\nstruct device_node *larbnode;\r\nstruct platform_device *plarbdev;\r\nlarbnode = of_parse_phandle(dev->of_node, "mediatek,larbs", i);\r\nif (!larbnode)\r\nreturn -EINVAL;\r\nif (!of_device_is_available(larbnode))\r\ncontinue;\r\nplarbdev = of_find_device_by_node(larbnode);\r\nif (!plarbdev) {\r\nplarbdev = of_platform_device_create(\r\nlarbnode, NULL,\r\nplatform_bus_type.dev_root);\r\nif (!plarbdev) {\r\nof_node_put(larbnode);\r\nreturn -EPROBE_DEFER;\r\n}\r\n}\r\ndata->smi_imu.larb_imu[i].dev = &plarbdev->dev;\r\ncomponent_match_add_release(dev, &match, release_of,\r\ncompare_of, larbnode);\r\n}\r\nplatform_set_drvdata(pdev, data);\r\nret = mtk_iommu_hw_init(data);\r\nif (ret)\r\nreturn ret;\r\nret = iommu_device_sysfs_add(&data->iommu, dev, NULL,\r\n"mtk-iommu.%pa", &ioaddr);\r\nif (ret)\r\nreturn ret;\r\niommu_device_set_ops(&data->iommu, &mtk_iommu_ops);\r\niommu_device_set_fwnode(&data->iommu, &pdev->dev.of_node->fwnode);\r\nret = iommu_device_register(&data->iommu);\r\nif (ret)\r\nreturn ret;\r\nif (!iommu_present(&platform_bus_type))\r\nbus_set_iommu(&platform_bus_type, &mtk_iommu_ops);\r\nreturn component_master_add_with_match(dev, &mtk_iommu_com_ops, match);\r\n}\r\nstatic int mtk_iommu_remove(struct platform_device *pdev)\r\n{\r\nstruct mtk_iommu_data *data = platform_get_drvdata(pdev);\r\niommu_device_sysfs_remove(&data->iommu);\r\niommu_device_unregister(&data->iommu);\r\nif (iommu_present(&platform_bus_type))\r\nbus_set_iommu(&platform_bus_type, NULL);\r\nfree_io_pgtable_ops(data->m4u_dom->iop);\r\nclk_disable_unprepare(data->bclk);\r\ndevm_free_irq(&pdev->dev, data->irq, data);\r\ncomponent_master_del(&pdev->dev, &mtk_iommu_com_ops);\r\nreturn 0;\r\n}\r\nstatic int __maybe_unused mtk_iommu_suspend(struct device *dev)\r\n{\r\nstruct mtk_iommu_data *data = dev_get_drvdata(dev);\r\nstruct mtk_iommu_suspend_reg *reg = &data->reg;\r\nvoid __iomem *base = data->base;\r\nreg->standard_axi_mode = readl_relaxed(base +\r\nREG_MMU_STANDARD_AXI_MODE);\r\nreg->dcm_dis = readl_relaxed(base + REG_MMU_DCM_DIS);\r\nreg->ctrl_reg = readl_relaxed(base + REG_MMU_CTRL_REG);\r\nreg->int_control0 = readl_relaxed(base + REG_MMU_INT_CONTROL0);\r\nreg->int_main_control = readl_relaxed(base + REG_MMU_INT_MAIN_CONTROL);\r\nreturn 0;\r\n}\r\nstatic int __maybe_unused mtk_iommu_resume(struct device *dev)\r\n{\r\nstruct mtk_iommu_data *data = dev_get_drvdata(dev);\r\nstruct mtk_iommu_suspend_reg *reg = &data->reg;\r\nvoid __iomem *base = data->base;\r\nwritel_relaxed(data->m4u_dom->cfg.arm_v7s_cfg.ttbr[0],\r\nbase + REG_MMU_PT_BASE_ADDR);\r\nwritel_relaxed(reg->standard_axi_mode,\r\nbase + REG_MMU_STANDARD_AXI_MODE);\r\nwritel_relaxed(reg->dcm_dis, base + REG_MMU_DCM_DIS);\r\nwritel_relaxed(reg->ctrl_reg, base + REG_MMU_CTRL_REG);\r\nwritel_relaxed(reg->int_control0, base + REG_MMU_INT_CONTROL0);\r\nwritel_relaxed(reg->int_main_control, base + REG_MMU_INT_MAIN_CONTROL);\r\nwritel_relaxed(F_MMU_IVRP_PA_SET(data->protect_base, data->enable_4GB),\r\nbase + REG_MMU_IVRP_PADDR);\r\nreturn 0;\r\n}\r\nstatic int mtk_iommu_init_fn(struct device_node *np)\r\n{\r\nint ret;\r\nstruct platform_device *pdev;\r\npdev = of_platform_device_create(np, NULL, platform_bus_type.dev_root);\r\nif (!pdev)\r\nreturn -ENOMEM;\r\nret = platform_driver_register(&mtk_iommu_driver);\r\nif (ret) {\r\npr_err("%s: Failed to register driver\n", __func__);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}
