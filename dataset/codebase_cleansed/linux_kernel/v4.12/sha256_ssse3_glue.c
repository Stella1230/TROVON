static int sha256_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, sha256_transform_fn *sha256_xform)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\nif (!irq_fpu_usable() ||\r\n(sctx->count % SHA256_BLOCK_SIZE) + len < SHA256_BLOCK_SIZE)\r\nreturn crypto_sha256_update(desc, data, len);\r\nBUILD_BUG_ON(offsetof(struct sha256_state, state) != 0);\r\nkernel_fpu_begin();\r\nsha256_base_do_update(desc, data, len,\r\n(sha256_block_fn *)sha256_xform);\r\nkernel_fpu_end();\r\nreturn 0;\r\n}\r\nstatic int sha256_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out, sha256_transform_fn *sha256_xform)\r\n{\r\nif (!irq_fpu_usable())\r\nreturn crypto_sha256_finup(desc, data, len, out);\r\nkernel_fpu_begin();\r\nif (len)\r\nsha256_base_do_update(desc, data, len,\r\n(sha256_block_fn *)sha256_xform);\r\nsha256_base_do_finalize(desc, (sha256_block_fn *)sha256_xform);\r\nkernel_fpu_end();\r\nreturn sha256_base_finish(desc, out);\r\n}\r\nstatic int sha256_ssse3_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nreturn sha256_update(desc, data, len, sha256_transform_ssse3);\r\n}\r\nstatic int sha256_ssse3_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn sha256_finup(desc, data, len, out, sha256_transform_ssse3);\r\n}\r\nstatic int sha256_ssse3_final(struct shash_desc *desc, u8 *out)\r\n{\r\nreturn sha256_ssse3_finup(desc, NULL, 0, out);\r\n}\r\nstatic int register_sha256_ssse3(void)\r\n{\r\nif (boot_cpu_has(X86_FEATURE_SSSE3))\r\nreturn crypto_register_shashes(sha256_ssse3_algs,\r\nARRAY_SIZE(sha256_ssse3_algs));\r\nreturn 0;\r\n}\r\nstatic void unregister_sha256_ssse3(void)\r\n{\r\nif (boot_cpu_has(X86_FEATURE_SSSE3))\r\ncrypto_unregister_shashes(sha256_ssse3_algs,\r\nARRAY_SIZE(sha256_ssse3_algs));\r\n}\r\nstatic int sha256_avx_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nreturn sha256_update(desc, data, len, sha256_transform_avx);\r\n}\r\nstatic int sha256_avx_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn sha256_finup(desc, data, len, out, sha256_transform_avx);\r\n}\r\nstatic int sha256_avx_final(struct shash_desc *desc, u8 *out)\r\n{\r\nreturn sha256_avx_finup(desc, NULL, 0, out);\r\n}\r\nstatic bool avx_usable(void)\r\n{\r\nif (!cpu_has_xfeatures(XFEATURE_MASK_SSE | XFEATURE_MASK_YMM, NULL)) {\r\nif (boot_cpu_has(X86_FEATURE_AVX))\r\npr_info("AVX detected but unusable.\n");\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic int register_sha256_avx(void)\r\n{\r\nif (avx_usable())\r\nreturn crypto_register_shashes(sha256_avx_algs,\r\nARRAY_SIZE(sha256_avx_algs));\r\nreturn 0;\r\n}\r\nstatic void unregister_sha256_avx(void)\r\n{\r\nif (avx_usable())\r\ncrypto_unregister_shashes(sha256_avx_algs,\r\nARRAY_SIZE(sha256_avx_algs));\r\n}\r\nstatic inline int register_sha256_avx(void) { return 0; }\r\nstatic inline void unregister_sha256_avx(void) { }\r\nstatic int sha256_avx2_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nreturn sha256_update(desc, data, len, sha256_transform_rorx);\r\n}\r\nstatic int sha256_avx2_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn sha256_finup(desc, data, len, out, sha256_transform_rorx);\r\n}\r\nstatic int sha256_avx2_final(struct shash_desc *desc, u8 *out)\r\n{\r\nreturn sha256_avx2_finup(desc, NULL, 0, out);\r\n}\r\nstatic bool avx2_usable(void)\r\n{\r\nif (avx_usable() && boot_cpu_has(X86_FEATURE_AVX2) &&\r\nboot_cpu_has(X86_FEATURE_BMI2))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic int register_sha256_avx2(void)\r\n{\r\nif (avx2_usable())\r\nreturn crypto_register_shashes(sha256_avx2_algs,\r\nARRAY_SIZE(sha256_avx2_algs));\r\nreturn 0;\r\n}\r\nstatic void unregister_sha256_avx2(void)\r\n{\r\nif (avx2_usable())\r\ncrypto_unregister_shashes(sha256_avx2_algs,\r\nARRAY_SIZE(sha256_avx2_algs));\r\n}\r\nstatic inline int register_sha256_avx2(void) { return 0; }\r\nstatic inline void unregister_sha256_avx2(void) { }\r\nstatic int sha256_ni_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nreturn sha256_update(desc, data, len, sha256_ni_transform);\r\n}\r\nstatic int sha256_ni_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn sha256_finup(desc, data, len, out, sha256_ni_transform);\r\n}\r\nstatic int sha256_ni_final(struct shash_desc *desc, u8 *out)\r\n{\r\nreturn sha256_ni_finup(desc, NULL, 0, out);\r\n}\r\nstatic int register_sha256_ni(void)\r\n{\r\nif (boot_cpu_has(X86_FEATURE_SHA_NI))\r\nreturn crypto_register_shashes(sha256_ni_algs,\r\nARRAY_SIZE(sha256_ni_algs));\r\nreturn 0;\r\n}\r\nstatic void unregister_sha256_ni(void)\r\n{\r\nif (boot_cpu_has(X86_FEATURE_SHA_NI))\r\ncrypto_unregister_shashes(sha256_ni_algs,\r\nARRAY_SIZE(sha256_ni_algs));\r\n}\r\nstatic inline int register_sha256_ni(void) { return 0; }\r\nstatic inline void unregister_sha256_ni(void) { }\r\nstatic int __init sha256_ssse3_mod_init(void)\r\n{\r\nif (register_sha256_ssse3())\r\ngoto fail;\r\nif (register_sha256_avx()) {\r\nunregister_sha256_ssse3();\r\ngoto fail;\r\n}\r\nif (register_sha256_avx2()) {\r\nunregister_sha256_avx();\r\nunregister_sha256_ssse3();\r\ngoto fail;\r\n}\r\nif (register_sha256_ni()) {\r\nunregister_sha256_avx2();\r\nunregister_sha256_avx();\r\nunregister_sha256_ssse3();\r\ngoto fail;\r\n}\r\nreturn 0;\r\nfail:\r\nreturn -ENODEV;\r\n}\r\nstatic void __exit sha256_ssse3_mod_fini(void)\r\n{\r\nunregister_sha256_ni();\r\nunregister_sha256_avx2();\r\nunregister_sha256_avx();\r\nunregister_sha256_ssse3();\r\n}
