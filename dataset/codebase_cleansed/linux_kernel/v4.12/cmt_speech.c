static inline void rx_ptr_shift_too_big(void)\r\n{\r\nBUILD_BUG_ON((1LLU << RX_PTR_MAX_SHIFT) > UINT_MAX);\r\n}\r\nstatic void cs_notify(u32 message, struct list_head *head)\r\n{\r\nstruct char_queue *entry;\r\nspin_lock(&cs_char_data.lock);\r\nif (!cs_char_data.opened) {\r\nspin_unlock(&cs_char_data.lock);\r\ngoto out;\r\n}\r\nentry = kmalloc(sizeof(*entry), GFP_ATOMIC);\r\nif (!entry) {\r\ndev_err(&cs_char_data.cl->device,\r\n"Can't allocate new entry for the queue.\n");\r\nspin_unlock(&cs_char_data.lock);\r\ngoto out;\r\n}\r\nentry->msg = message;\r\nlist_add_tail(&entry->list, head);\r\nspin_unlock(&cs_char_data.lock);\r\nwake_up_interruptible(&cs_char_data.wait);\r\nkill_fasync(&cs_char_data.async_queue, SIGIO, POLL_IN);\r\nout:\r\nreturn;\r\n}\r\nstatic u32 cs_pop_entry(struct list_head *head)\r\n{\r\nstruct char_queue *entry;\r\nu32 data;\r\nentry = list_entry(head->next, struct char_queue, list);\r\ndata = entry->msg;\r\nlist_del(&entry->list);\r\nkfree(entry);\r\nreturn data;\r\n}\r\nstatic void cs_notify_control(u32 message)\r\n{\r\ncs_notify(message, &cs_char_data.chardev_queue);\r\n}\r\nstatic void cs_notify_data(u32 message, int maxlength)\r\n{\r\ncs_notify(message, &cs_char_data.dataind_queue);\r\nspin_lock(&cs_char_data.lock);\r\ncs_char_data.dataind_pending++;\r\nwhile (cs_char_data.dataind_pending > maxlength &&\r\n!list_empty(&cs_char_data.dataind_queue)) {\r\ndev_dbg(&cs_char_data.cl->device, "data notification "\r\n"queue overrun (%u entries)\n", cs_char_data.dataind_pending);\r\ncs_pop_entry(&cs_char_data.dataind_queue);\r\ncs_char_data.dataind_pending--;\r\n}\r\nspin_unlock(&cs_char_data.lock);\r\n}\r\nstatic inline void cs_set_cmd(struct hsi_msg *msg, u32 cmd)\r\n{\r\nu32 *data = sg_virt(msg->sgt.sgl);\r\n*data = cmd;\r\n}\r\nstatic inline u32 cs_get_cmd(struct hsi_msg *msg)\r\n{\r\nu32 *data = sg_virt(msg->sgt.sgl);\r\nreturn *data;\r\n}\r\nstatic void cs_release_cmd(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nlist_add_tail(&msg->link, &hi->cmdqueue);\r\n}\r\nstatic void cs_cmd_destructor(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nspin_lock(&hi->lock);\r\ndev_dbg(&cs_char_data.cl->device, "control cmd destructor\n");\r\nif (hi->iface_state != CS_STATE_CLOSED)\r\ndev_err(&hi->cl->device, "Cmd flushed while driver active\n");\r\nif (msg->ttype == HSI_MSG_READ)\r\nhi->control_state &=\r\n~(SSI_CHANNEL_STATE_POLL | SSI_CHANNEL_STATE_READING);\r\nelse if (msg->ttype == HSI_MSG_WRITE &&\r\nhi->control_state & SSI_CHANNEL_STATE_WRITING)\r\nhi->control_state &= ~SSI_CHANNEL_STATE_WRITING;\r\ncs_release_cmd(msg);\r\nspin_unlock(&hi->lock);\r\n}\r\nstatic struct hsi_msg *cs_claim_cmd(struct cs_hsi_iface* ssi)\r\n{\r\nstruct hsi_msg *msg;\r\nBUG_ON(list_empty(&ssi->cmdqueue));\r\nmsg = list_first_entry(&ssi->cmdqueue, struct hsi_msg, link);\r\nlist_del(&msg->link);\r\nmsg->destructor = cs_cmd_destructor;\r\nreturn msg;\r\n}\r\nstatic void cs_free_cmds(struct cs_hsi_iface *ssi)\r\n{\r\nstruct hsi_msg *msg, *tmp;\r\nlist_for_each_entry_safe(msg, tmp, &ssi->cmdqueue, link) {\r\nlist_del(&msg->link);\r\nmsg->destructor = NULL;\r\nkfree(sg_virt(msg->sgt.sgl));\r\nhsi_free_msg(msg);\r\n}\r\n}\r\nstatic int cs_alloc_cmds(struct cs_hsi_iface *hi)\r\n{\r\nstruct hsi_msg *msg;\r\nu32 *buf;\r\nunsigned int i;\r\nINIT_LIST_HEAD(&hi->cmdqueue);\r\nfor (i = 0; i < CS_MAX_CMDS; i++) {\r\nmsg = hsi_alloc_msg(1, GFP_KERNEL);\r\nif (!msg)\r\ngoto out;\r\nbuf = kmalloc(sizeof(*buf), GFP_KERNEL);\r\nif (!buf) {\r\nhsi_free_msg(msg);\r\ngoto out;\r\n}\r\nsg_init_one(msg->sgt.sgl, buf, sizeof(*buf));\r\nmsg->channel = cs_char_data.channel_id_cmd;\r\nmsg->context = hi;\r\nlist_add_tail(&msg->link, &hi->cmdqueue);\r\n}\r\nreturn 0;\r\nout:\r\ncs_free_cmds(hi);\r\nreturn -ENOMEM;\r\n}\r\nstatic void cs_hsi_data_destructor(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nconst char *dir = (msg->ttype == HSI_MSG_READ) ? "TX" : "RX";\r\ndev_dbg(&cs_char_data.cl->device, "Freeing data %s message\n", dir);\r\nspin_lock(&hi->lock);\r\nif (hi->iface_state != CS_STATE_CLOSED)\r\ndev_err(&cs_char_data.cl->device,\r\n"Data %s flush while device active\n", dir);\r\nif (msg->ttype == HSI_MSG_READ)\r\nhi->data_state &=\r\n~(SSI_CHANNEL_STATE_POLL | SSI_CHANNEL_STATE_READING);\r\nelse\r\nhi->data_state &= ~SSI_CHANNEL_STATE_WRITING;\r\nmsg->status = HSI_STATUS_COMPLETED;\r\nif (unlikely(waitqueue_active(&hi->datawait)))\r\nwake_up_interruptible(&hi->datawait);\r\nspin_unlock(&hi->lock);\r\n}\r\nstatic int cs_hsi_alloc_data(struct cs_hsi_iface *hi)\r\n{\r\nstruct hsi_msg *txmsg, *rxmsg;\r\nint res = 0;\r\nrxmsg = hsi_alloc_msg(1, GFP_KERNEL);\r\nif (!rxmsg) {\r\nres = -ENOMEM;\r\ngoto out1;\r\n}\r\nrxmsg->channel = cs_char_data.channel_id_data;\r\nrxmsg->destructor = cs_hsi_data_destructor;\r\nrxmsg->context = hi;\r\ntxmsg = hsi_alloc_msg(1, GFP_KERNEL);\r\nif (!txmsg) {\r\nres = -ENOMEM;\r\ngoto out2;\r\n}\r\ntxmsg->channel = cs_char_data.channel_id_data;\r\ntxmsg->destructor = cs_hsi_data_destructor;\r\ntxmsg->context = hi;\r\nhi->data_rx_msg = rxmsg;\r\nhi->data_tx_msg = txmsg;\r\nreturn 0;\r\nout2:\r\nhsi_free_msg(rxmsg);\r\nout1:\r\nreturn res;\r\n}\r\nstatic void cs_hsi_free_data_msg(struct hsi_msg *msg)\r\n{\r\nWARN_ON(msg->status != HSI_STATUS_COMPLETED &&\r\nmsg->status != HSI_STATUS_ERROR);\r\nhsi_free_msg(msg);\r\n}\r\nstatic void cs_hsi_free_data(struct cs_hsi_iface *hi)\r\n{\r\ncs_hsi_free_data_msg(hi->data_rx_msg);\r\ncs_hsi_free_data_msg(hi->data_tx_msg);\r\n}\r\nstatic inline void __cs_hsi_error_pre(struct cs_hsi_iface *hi,\r\nstruct hsi_msg *msg, const char *info,\r\nunsigned int *state)\r\n{\r\nspin_lock(&hi->lock);\r\ndev_err(&hi->cl->device, "HSI %s error, msg %d, state %u\n",\r\ninfo, msg->status, *state);\r\n}\r\nstatic inline void __cs_hsi_error_post(struct cs_hsi_iface *hi)\r\n{\r\nspin_unlock(&hi->lock);\r\n}\r\nstatic inline void __cs_hsi_error_read_bits(unsigned int *state)\r\n{\r\n*state |= SSI_CHANNEL_STATE_ERROR;\r\n*state &= ~(SSI_CHANNEL_STATE_READING | SSI_CHANNEL_STATE_POLL);\r\n}\r\nstatic inline void __cs_hsi_error_write_bits(unsigned int *state)\r\n{\r\n*state |= SSI_CHANNEL_STATE_ERROR;\r\n*state &= ~SSI_CHANNEL_STATE_WRITING;\r\n}\r\nstatic void cs_hsi_control_read_error(struct cs_hsi_iface *hi,\r\nstruct hsi_msg *msg)\r\n{\r\n__cs_hsi_error_pre(hi, msg, "control read", &hi->control_state);\r\ncs_release_cmd(msg);\r\n__cs_hsi_error_read_bits(&hi->control_state);\r\n__cs_hsi_error_post(hi);\r\n}\r\nstatic void cs_hsi_control_write_error(struct cs_hsi_iface *hi,\r\nstruct hsi_msg *msg)\r\n{\r\n__cs_hsi_error_pre(hi, msg, "control write", &hi->control_state);\r\ncs_release_cmd(msg);\r\n__cs_hsi_error_write_bits(&hi->control_state);\r\n__cs_hsi_error_post(hi);\r\n}\r\nstatic void cs_hsi_data_read_error(struct cs_hsi_iface *hi, struct hsi_msg *msg)\r\n{\r\n__cs_hsi_error_pre(hi, msg, "data read", &hi->data_state);\r\n__cs_hsi_error_read_bits(&hi->data_state);\r\n__cs_hsi_error_post(hi);\r\n}\r\nstatic void cs_hsi_data_write_error(struct cs_hsi_iface *hi,\r\nstruct hsi_msg *msg)\r\n{\r\n__cs_hsi_error_pre(hi, msg, "data write", &hi->data_state);\r\n__cs_hsi_error_write_bits(&hi->data_state);\r\n__cs_hsi_error_post(hi);\r\n}\r\nstatic void cs_hsi_read_on_control_complete(struct hsi_msg *msg)\r\n{\r\nu32 cmd = cs_get_cmd(msg);\r\nstruct cs_hsi_iface *hi = msg->context;\r\nspin_lock(&hi->lock);\r\nhi->control_state &= ~SSI_CHANNEL_STATE_READING;\r\nif (msg->status == HSI_STATUS_ERROR) {\r\ndev_err(&hi->cl->device, "Control RX error detected\n");\r\nspin_unlock(&hi->lock);\r\ncs_hsi_control_read_error(hi, msg);\r\ngoto out;\r\n}\r\ndev_dbg(&hi->cl->device, "Read on control: %08X\n", cmd);\r\ncs_release_cmd(msg);\r\nif (hi->flags & CS_FEAT_TSTAMP_RX_CTRL) {\r\nstruct timespec tspec;\r\nstruct cs_timestamp *tstamp =\r\n&hi->mmap_cfg->tstamp_rx_ctrl;\r\nktime_get_ts(&tspec);\r\ntstamp->tv_sec = (__u32) tspec.tv_sec;\r\ntstamp->tv_nsec = (__u32) tspec.tv_nsec;\r\n}\r\nspin_unlock(&hi->lock);\r\ncs_notify_control(cmd);\r\nout:\r\ncs_hsi_read_on_control(hi);\r\n}\r\nstatic void cs_hsi_peek_on_control_complete(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nint ret;\r\nif (msg->status == HSI_STATUS_ERROR) {\r\ndev_err(&hi->cl->device, "Control peek RX error detected\n");\r\ncs_hsi_control_read_error(hi, msg);\r\nreturn;\r\n}\r\nWARN_ON(!(hi->control_state & SSI_CHANNEL_STATE_READING));\r\ndev_dbg(&hi->cl->device, "Peek on control complete, reading\n");\r\nmsg->sgt.nents = 1;\r\nmsg->complete = cs_hsi_read_on_control_complete;\r\nret = hsi_async_read(hi->cl, msg);\r\nif (ret)\r\ncs_hsi_control_read_error(hi, msg);\r\n}\r\nstatic void cs_hsi_read_on_control(struct cs_hsi_iface *hi)\r\n{\r\nstruct hsi_msg *msg;\r\nint ret;\r\nspin_lock(&hi->lock);\r\nif (hi->control_state & SSI_CHANNEL_STATE_READING) {\r\ndev_err(&hi->cl->device, "Control read already pending (%d)\n",\r\nhi->control_state);\r\nspin_unlock(&hi->lock);\r\nreturn;\r\n}\r\nif (hi->control_state & SSI_CHANNEL_STATE_ERROR) {\r\ndev_err(&hi->cl->device, "Control read error (%d)\n",\r\nhi->control_state);\r\nspin_unlock(&hi->lock);\r\nreturn;\r\n}\r\nhi->control_state |= SSI_CHANNEL_STATE_READING;\r\ndev_dbg(&hi->cl->device, "Issuing RX on control\n");\r\nmsg = cs_claim_cmd(hi);\r\nspin_unlock(&hi->lock);\r\nmsg->sgt.nents = 0;\r\nmsg->complete = cs_hsi_peek_on_control_complete;\r\nret = hsi_async_read(hi->cl, msg);\r\nif (ret)\r\ncs_hsi_control_read_error(hi, msg);\r\n}\r\nstatic void cs_hsi_write_on_control_complete(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nif (msg->status == HSI_STATUS_COMPLETED) {\r\nspin_lock(&hi->lock);\r\nhi->control_state &= ~SSI_CHANNEL_STATE_WRITING;\r\ncs_release_cmd(msg);\r\nspin_unlock(&hi->lock);\r\n} else if (msg->status == HSI_STATUS_ERROR) {\r\ncs_hsi_control_write_error(hi, msg);\r\n} else {\r\ndev_err(&hi->cl->device,\r\n"unexpected status in control write callback %d\n",\r\nmsg->status);\r\n}\r\n}\r\nstatic int cs_hsi_write_on_control(struct cs_hsi_iface *hi, u32 message)\r\n{\r\nstruct hsi_msg *msg;\r\nint ret;\r\nspin_lock(&hi->lock);\r\nif (hi->control_state & SSI_CHANNEL_STATE_ERROR) {\r\nspin_unlock(&hi->lock);\r\nreturn -EIO;\r\n}\r\nif (hi->control_state & SSI_CHANNEL_STATE_WRITING) {\r\ndev_err(&hi->cl->device,\r\n"Write still pending on control channel.\n");\r\nspin_unlock(&hi->lock);\r\nreturn -EBUSY;\r\n}\r\nhi->control_state |= SSI_CHANNEL_STATE_WRITING;\r\nmsg = cs_claim_cmd(hi);\r\nspin_unlock(&hi->lock);\r\ncs_set_cmd(msg, message);\r\nmsg->sgt.nents = 1;\r\nmsg->complete = cs_hsi_write_on_control_complete;\r\ndev_dbg(&hi->cl->device,\r\n"Sending control message %08X\n", message);\r\nret = hsi_async_write(hi->cl, msg);\r\nif (ret) {\r\ndev_err(&hi->cl->device,\r\n"async_write failed with %d\n", ret);\r\ncs_hsi_control_write_error(hi, msg);\r\n}\r\nif (!(hi->control_state & SSI_CHANNEL_STATE_READING)) {\r\ndev_err(&hi->cl->device, "Restarting control reads\n");\r\ncs_hsi_read_on_control(hi);\r\n}\r\nreturn 0;\r\n}\r\nstatic void cs_hsi_read_on_data_complete(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nu32 payload;\r\nif (unlikely(msg->status == HSI_STATUS_ERROR)) {\r\ncs_hsi_data_read_error(hi, msg);\r\nreturn;\r\n}\r\nspin_lock(&hi->lock);\r\nWARN_ON(!(hi->data_state & SSI_CHANNEL_STATE_READING));\r\nhi->data_state &= ~SSI_CHANNEL_STATE_READING;\r\npayload = CS_RX_DATA_RECEIVED;\r\npayload |= hi->rx_slot;\r\nhi->rx_slot++;\r\nhi->rx_slot %= hi->rx_ptr_boundary;\r\nhi->mmap_cfg->rx_ptr = hi->rx_slot;\r\nif (unlikely(waitqueue_active(&hi->datawait)))\r\nwake_up_interruptible(&hi->datawait);\r\nspin_unlock(&hi->lock);\r\ncs_notify_data(payload, hi->rx_bufs);\r\ncs_hsi_read_on_data(hi);\r\n}\r\nstatic void cs_hsi_peek_on_data_complete(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nu32 *address;\r\nint ret;\r\nif (unlikely(msg->status == HSI_STATUS_ERROR)) {\r\ncs_hsi_data_read_error(hi, msg);\r\nreturn;\r\n}\r\nif (unlikely(hi->iface_state != CS_STATE_CONFIGURED)) {\r\ndev_err(&hi->cl->device, "Data received in invalid state\n");\r\ncs_hsi_data_read_error(hi, msg);\r\nreturn;\r\n}\r\nspin_lock(&hi->lock);\r\nWARN_ON(!(hi->data_state & SSI_CHANNEL_STATE_POLL));\r\nhi->data_state &= ~SSI_CHANNEL_STATE_POLL;\r\nhi->data_state |= SSI_CHANNEL_STATE_READING;\r\nspin_unlock(&hi->lock);\r\naddress = (u32 *)(hi->mmap_base +\r\nhi->rx_offsets[hi->rx_slot % hi->rx_bufs]);\r\nsg_init_one(msg->sgt.sgl, address, hi->buf_size);\r\nmsg->sgt.nents = 1;\r\nmsg->complete = cs_hsi_read_on_data_complete;\r\nret = hsi_async_read(hi->cl, msg);\r\nif (ret)\r\ncs_hsi_data_read_error(hi, msg);\r\n}\r\nstatic inline int cs_state_xfer_active(unsigned int state)\r\n{\r\nreturn (state & SSI_CHANNEL_STATE_WRITING) ||\r\n(state & SSI_CHANNEL_STATE_READING);\r\n}\r\nstatic inline int cs_state_idle(unsigned int state)\r\n{\r\nreturn !(state & ~SSI_CHANNEL_STATE_ERROR);\r\n}\r\nstatic void cs_hsi_read_on_data(struct cs_hsi_iface *hi)\r\n{\r\nstruct hsi_msg *rxmsg;\r\nint ret;\r\nspin_lock(&hi->lock);\r\nif (hi->data_state &\r\n(SSI_CHANNEL_STATE_READING | SSI_CHANNEL_STATE_POLL)) {\r\ndev_dbg(&hi->cl->device, "Data read already pending (%u)\n",\r\nhi->data_state);\r\nspin_unlock(&hi->lock);\r\nreturn;\r\n}\r\nhi->data_state |= SSI_CHANNEL_STATE_POLL;\r\nspin_unlock(&hi->lock);\r\nrxmsg = hi->data_rx_msg;\r\nsg_init_one(rxmsg->sgt.sgl, (void *)hi->mmap_base, 0);\r\nrxmsg->sgt.nents = 0;\r\nrxmsg->complete = cs_hsi_peek_on_data_complete;\r\nret = hsi_async_read(hi->cl, rxmsg);\r\nif (ret)\r\ncs_hsi_data_read_error(hi, rxmsg);\r\n}\r\nstatic void cs_hsi_write_on_data_complete(struct hsi_msg *msg)\r\n{\r\nstruct cs_hsi_iface *hi = msg->context;\r\nif (msg->status == HSI_STATUS_COMPLETED) {\r\nspin_lock(&hi->lock);\r\nhi->data_state &= ~SSI_CHANNEL_STATE_WRITING;\r\nif (unlikely(waitqueue_active(&hi->datawait)))\r\nwake_up_interruptible(&hi->datawait);\r\nspin_unlock(&hi->lock);\r\n} else {\r\ncs_hsi_data_write_error(hi, msg);\r\n}\r\n}\r\nstatic int cs_hsi_write_on_data(struct cs_hsi_iface *hi, unsigned int slot)\r\n{\r\nu32 *address;\r\nstruct hsi_msg *txmsg;\r\nint ret;\r\nspin_lock(&hi->lock);\r\nif (hi->iface_state != CS_STATE_CONFIGURED) {\r\ndev_err(&hi->cl->device, "Not configured, aborting\n");\r\nret = -EINVAL;\r\ngoto error;\r\n}\r\nif (hi->data_state & SSI_CHANNEL_STATE_ERROR) {\r\ndev_err(&hi->cl->device, "HSI error, aborting\n");\r\nret = -EIO;\r\ngoto error;\r\n}\r\nif (hi->data_state & SSI_CHANNEL_STATE_WRITING) {\r\ndev_err(&hi->cl->device, "Write pending on data channel.\n");\r\nret = -EBUSY;\r\ngoto error;\r\n}\r\nhi->data_state |= SSI_CHANNEL_STATE_WRITING;\r\nspin_unlock(&hi->lock);\r\nhi->tx_slot = slot;\r\naddress = (u32 *)(hi->mmap_base + hi->tx_offsets[hi->tx_slot]);\r\ntxmsg = hi->data_tx_msg;\r\nsg_init_one(txmsg->sgt.sgl, address, hi->buf_size);\r\ntxmsg->complete = cs_hsi_write_on_data_complete;\r\nret = hsi_async_write(hi->cl, txmsg);\r\nif (ret)\r\ncs_hsi_data_write_error(hi, txmsg);\r\nreturn ret;\r\nerror:\r\nspin_unlock(&hi->lock);\r\nif (ret == -EIO)\r\ncs_hsi_data_write_error(hi, hi->data_tx_msg);\r\nreturn ret;\r\n}\r\nstatic unsigned int cs_hsi_get_state(struct cs_hsi_iface *hi)\r\n{\r\nreturn hi->iface_state;\r\n}\r\nstatic int cs_hsi_command(struct cs_hsi_iface *hi, u32 cmd)\r\n{\r\nint ret = 0;\r\nlocal_bh_disable();\r\nswitch (cmd & TARGET_MASK) {\r\ncase TARGET_REMOTE:\r\nret = cs_hsi_write_on_control(hi, cmd);\r\nbreak;\r\ncase TARGET_LOCAL:\r\nif ((cmd & CS_CMD_MASK) == CS_TX_DATA_READY)\r\nret = cs_hsi_write_on_data(hi, cmd & CS_PARAM_MASK);\r\nelse\r\nret = -EINVAL;\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\nbreak;\r\n}\r\nlocal_bh_enable();\r\nreturn ret;\r\n}\r\nstatic void cs_hsi_set_wakeline(struct cs_hsi_iface *hi, bool new_state)\r\n{\r\nint change = 0;\r\nspin_lock_bh(&hi->lock);\r\nif (hi->wakeline_state != new_state) {\r\nhi->wakeline_state = new_state;\r\nchange = 1;\r\ndev_dbg(&hi->cl->device, "setting wake line to %d (%p)\n",\r\nnew_state, hi->cl);\r\n}\r\nspin_unlock_bh(&hi->lock);\r\nif (change) {\r\nif (new_state)\r\nssip_slave_start_tx(hi->master);\r\nelse\r\nssip_slave_stop_tx(hi->master);\r\n}\r\ndev_dbg(&hi->cl->device, "wake line set to %d (%p)\n",\r\nnew_state, hi->cl);\r\n}\r\nstatic void set_buffer_sizes(struct cs_hsi_iface *hi, int rx_bufs, int tx_bufs)\r\n{\r\nhi->rx_bufs = rx_bufs;\r\nhi->tx_bufs = tx_bufs;\r\nhi->mmap_cfg->rx_bufs = rx_bufs;\r\nhi->mmap_cfg->tx_bufs = tx_bufs;\r\nif (hi->flags & CS_FEAT_ROLLING_RX_COUNTER) {\r\nhi->rx_ptr_boundary = (rx_bufs << RX_PTR_BOUNDARY_SHIFT);\r\nhi->mmap_cfg->rx_ptr_boundary = hi->rx_ptr_boundary;\r\n} else {\r\nhi->rx_ptr_boundary = hi->rx_bufs;\r\n}\r\n}\r\nstatic int check_buf_params(struct cs_hsi_iface *hi,\r\nconst struct cs_buffer_config *buf_cfg)\r\n{\r\nsize_t buf_size_aligned = L1_CACHE_ALIGN(buf_cfg->buf_size) *\r\n(buf_cfg->rx_bufs + buf_cfg->tx_bufs);\r\nsize_t ctrl_size_aligned = L1_CACHE_ALIGN(sizeof(*hi->mmap_cfg));\r\nint r = 0;\r\nif (buf_cfg->rx_bufs > CS_MAX_BUFFERS ||\r\nbuf_cfg->tx_bufs > CS_MAX_BUFFERS) {\r\nr = -EINVAL;\r\n} else if ((buf_size_aligned + ctrl_size_aligned) >= hi->mmap_size) {\r\ndev_err(&hi->cl->device, "No space for the requested buffer "\r\n"configuration\n");\r\nr = -ENOBUFS;\r\n}\r\nreturn r;\r\n}\r\nstatic int cs_hsi_data_sync(struct cs_hsi_iface *hi)\r\n{\r\nint r = 0;\r\nspin_lock_bh(&hi->lock);\r\nif (!cs_state_xfer_active(hi->data_state)) {\r\ndev_dbg(&hi->cl->device, "hsi_data_sync break, idle\n");\r\ngoto out;\r\n}\r\nfor (;;) {\r\nint s;\r\nDEFINE_WAIT(wait);\r\nif (!cs_state_xfer_active(hi->data_state))\r\ngoto out;\r\nif (signal_pending(current)) {\r\nr = -ERESTARTSYS;\r\ngoto out;\r\n}\r\nprepare_to_wait(&hi->datawait, &wait, TASK_INTERRUPTIBLE);\r\nspin_unlock_bh(&hi->lock);\r\ns = schedule_timeout(\r\nmsecs_to_jiffies(CS_HSI_TRANSFER_TIMEOUT_MS));\r\nspin_lock_bh(&hi->lock);\r\nfinish_wait(&hi->datawait, &wait);\r\nif (!s) {\r\ndev_dbg(&hi->cl->device,\r\n"hsi_data_sync timeout after %d ms\n",\r\nCS_HSI_TRANSFER_TIMEOUT_MS);\r\nr = -EIO;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nspin_unlock_bh(&hi->lock);\r\ndev_dbg(&hi->cl->device, "hsi_data_sync done with res %d\n", r);\r\nreturn r;\r\n}\r\nstatic void cs_hsi_data_enable(struct cs_hsi_iface *hi,\r\nstruct cs_buffer_config *buf_cfg)\r\n{\r\nunsigned int data_start, i;\r\nBUG_ON(hi->buf_size == 0);\r\nset_buffer_sizes(hi, buf_cfg->rx_bufs, buf_cfg->tx_bufs);\r\nhi->slot_size = L1_CACHE_ALIGN(hi->buf_size);\r\ndev_dbg(&hi->cl->device,\r\n"setting slot size to %u, buf size %u, align %u\n",\r\nhi->slot_size, hi->buf_size, L1_CACHE_BYTES);\r\ndata_start = L1_CACHE_ALIGN(sizeof(*hi->mmap_cfg));\r\ndev_dbg(&hi->cl->device,\r\n"setting data start at %u, cfg block %u, align %u\n",\r\ndata_start, sizeof(*hi->mmap_cfg), L1_CACHE_BYTES);\r\nfor (i = 0; i < hi->mmap_cfg->rx_bufs; i++) {\r\nhi->rx_offsets[i] = data_start + i * hi->slot_size;\r\nhi->mmap_cfg->rx_offsets[i] = hi->rx_offsets[i];\r\ndev_dbg(&hi->cl->device, "DL buf #%u at %u\n",\r\ni, hi->rx_offsets[i]);\r\n}\r\nfor (i = 0; i < hi->mmap_cfg->tx_bufs; i++) {\r\nhi->tx_offsets[i] = data_start +\r\n(i + hi->mmap_cfg->rx_bufs) * hi->slot_size;\r\nhi->mmap_cfg->tx_offsets[i] = hi->tx_offsets[i];\r\ndev_dbg(&hi->cl->device, "UL buf #%u at %u\n",\r\ni, hi->rx_offsets[i]);\r\n}\r\nhi->iface_state = CS_STATE_CONFIGURED;\r\n}\r\nstatic void cs_hsi_data_disable(struct cs_hsi_iface *hi, int old_state)\r\n{\r\nif (old_state == CS_STATE_CONFIGURED) {\r\ndev_dbg(&hi->cl->device,\r\n"closing data channel with slot size 0\n");\r\nhi->iface_state = CS_STATE_OPENED;\r\n}\r\n}\r\nstatic int cs_hsi_buf_config(struct cs_hsi_iface *hi,\r\nstruct cs_buffer_config *buf_cfg)\r\n{\r\nint r = 0;\r\nunsigned int old_state = hi->iface_state;\r\nspin_lock_bh(&hi->lock);\r\nif (old_state == CS_STATE_CONFIGURED)\r\nhi->iface_state = CS_STATE_OPENED;\r\nspin_unlock_bh(&hi->lock);\r\nr = cs_hsi_data_sync(hi);\r\nif (r < 0)\r\nreturn r;\r\nWARN_ON(cs_state_xfer_active(hi->data_state));\r\nspin_lock_bh(&hi->lock);\r\nr = check_buf_params(hi, buf_cfg);\r\nif (r < 0)\r\ngoto error;\r\nhi->buf_size = buf_cfg->buf_size;\r\nhi->mmap_cfg->buf_size = hi->buf_size;\r\nhi->flags = buf_cfg->flags;\r\nhi->rx_slot = 0;\r\nhi->tx_slot = 0;\r\nhi->slot_size = 0;\r\nif (hi->buf_size)\r\ncs_hsi_data_enable(hi, buf_cfg);\r\nelse\r\ncs_hsi_data_disable(hi, old_state);\r\nspin_unlock_bh(&hi->lock);\r\nif (old_state != hi->iface_state) {\r\nif (hi->iface_state == CS_STATE_CONFIGURED) {\r\npm_qos_add_request(&hi->pm_qos_req,\r\nPM_QOS_CPU_DMA_LATENCY,\r\nCS_QOS_LATENCY_FOR_DATA_USEC);\r\nlocal_bh_disable();\r\ncs_hsi_read_on_data(hi);\r\nlocal_bh_enable();\r\n} else if (old_state == CS_STATE_CONFIGURED) {\r\npm_qos_remove_request(&hi->pm_qos_req);\r\n}\r\n}\r\nreturn r;\r\nerror:\r\nspin_unlock_bh(&hi->lock);\r\nreturn r;\r\n}\r\nstatic int cs_hsi_start(struct cs_hsi_iface **hi, struct hsi_client *cl,\r\nunsigned long mmap_base, unsigned long mmap_size)\r\n{\r\nint err = 0;\r\nstruct cs_hsi_iface *hsi_if = kzalloc(sizeof(*hsi_if), GFP_KERNEL);\r\ndev_dbg(&cl->device, "cs_hsi_start\n");\r\nif (!hsi_if) {\r\nerr = -ENOMEM;\r\ngoto leave0;\r\n}\r\nspin_lock_init(&hsi_if->lock);\r\nhsi_if->cl = cl;\r\nhsi_if->iface_state = CS_STATE_CLOSED;\r\nhsi_if->mmap_cfg = (struct cs_mmap_config_block *)mmap_base;\r\nhsi_if->mmap_base = mmap_base;\r\nhsi_if->mmap_size = mmap_size;\r\nmemset(hsi_if->mmap_cfg, 0, sizeof(*hsi_if->mmap_cfg));\r\ninit_waitqueue_head(&hsi_if->datawait);\r\nerr = cs_alloc_cmds(hsi_if);\r\nif (err < 0) {\r\ndev_err(&cl->device, "Unable to alloc HSI messages\n");\r\ngoto leave1;\r\n}\r\nerr = cs_hsi_alloc_data(hsi_if);\r\nif (err < 0) {\r\ndev_err(&cl->device, "Unable to alloc HSI messages for data\n");\r\ngoto leave2;\r\n}\r\nerr = hsi_claim_port(cl, 1);\r\nif (err < 0) {\r\ndev_err(&cl->device,\r\n"Could not open, HSI port already claimed\n");\r\ngoto leave3;\r\n}\r\nhsi_if->master = ssip_slave_get_master(cl);\r\nif (IS_ERR(hsi_if->master)) {\r\nerr = PTR_ERR(hsi_if->master);\r\ndev_err(&cl->device, "Could not get HSI master client\n");\r\ngoto leave4;\r\n}\r\nif (!ssip_slave_running(hsi_if->master)) {\r\nerr = -ENODEV;\r\ndev_err(&cl->device,\r\n"HSI port not initialized\n");\r\ngoto leave4;\r\n}\r\nhsi_if->iface_state = CS_STATE_OPENED;\r\nlocal_bh_disable();\r\ncs_hsi_read_on_control(hsi_if);\r\nlocal_bh_enable();\r\ndev_dbg(&cl->device, "cs_hsi_start...done\n");\r\nBUG_ON(!hi);\r\n*hi = hsi_if;\r\nreturn 0;\r\nleave4:\r\nhsi_release_port(cl);\r\nleave3:\r\ncs_hsi_free_data(hsi_if);\r\nleave2:\r\ncs_free_cmds(hsi_if);\r\nleave1:\r\nkfree(hsi_if);\r\nleave0:\r\ndev_dbg(&cl->device, "cs_hsi_start...done/error\n\n");\r\nreturn err;\r\n}\r\nstatic void cs_hsi_stop(struct cs_hsi_iface *hi)\r\n{\r\ndev_dbg(&hi->cl->device, "cs_hsi_stop\n");\r\ncs_hsi_set_wakeline(hi, 0);\r\nssip_slave_put_master(hi->master);\r\nhi->iface_state = CS_STATE_CLOSED;\r\nhsi_release_port(hi->cl);\r\nWARN_ON(!cs_state_idle(hi->control_state));\r\nWARN_ON(!cs_state_idle(hi->data_state));\r\nif (pm_qos_request_active(&hi->pm_qos_req))\r\npm_qos_remove_request(&hi->pm_qos_req);\r\nspin_lock_bh(&hi->lock);\r\ncs_hsi_free_data(hi);\r\ncs_free_cmds(hi);\r\nspin_unlock_bh(&hi->lock);\r\nkfree(hi);\r\n}\r\nstatic int cs_char_vma_fault(struct vm_fault *vmf)\r\n{\r\nstruct cs_char *csdata = vmf->vma->vm_private_data;\r\nstruct page *page;\r\npage = virt_to_page(csdata->mmap_base);\r\nget_page(page);\r\nvmf->page = page;\r\nreturn 0;\r\n}\r\nstatic int cs_char_fasync(int fd, struct file *file, int on)\r\n{\r\nstruct cs_char *csdata = file->private_data;\r\nif (fasync_helper(fd, file, on, &csdata->async_queue) < 0)\r\nreturn -EIO;\r\nreturn 0;\r\n}\r\nstatic unsigned int cs_char_poll(struct file *file, poll_table *wait)\r\n{\r\nstruct cs_char *csdata = file->private_data;\r\nunsigned int ret = 0;\r\npoll_wait(file, &cs_char_data.wait, wait);\r\nspin_lock_bh(&csdata->lock);\r\nif (!list_empty(&csdata->chardev_queue))\r\nret = POLLIN | POLLRDNORM;\r\nelse if (!list_empty(&csdata->dataind_queue))\r\nret = POLLIN | POLLRDNORM;\r\nspin_unlock_bh(&csdata->lock);\r\nreturn ret;\r\n}\r\nstatic ssize_t cs_char_read(struct file *file, char __user *buf, size_t count,\r\nloff_t *unused)\r\n{\r\nstruct cs_char *csdata = file->private_data;\r\nu32 data;\r\nssize_t retval;\r\nif (count < sizeof(data))\r\nreturn -EINVAL;\r\nfor (;;) {\r\nDEFINE_WAIT(wait);\r\nspin_lock_bh(&csdata->lock);\r\nif (!list_empty(&csdata->chardev_queue)) {\r\ndata = cs_pop_entry(&csdata->chardev_queue);\r\n} else if (!list_empty(&csdata->dataind_queue)) {\r\ndata = cs_pop_entry(&csdata->dataind_queue);\r\ncsdata->dataind_pending--;\r\n} else {\r\ndata = 0;\r\n}\r\nspin_unlock_bh(&csdata->lock);\r\nif (data)\r\nbreak;\r\nif (file->f_flags & O_NONBLOCK) {\r\nretval = -EAGAIN;\r\ngoto out;\r\n} else if (signal_pending(current)) {\r\nretval = -ERESTARTSYS;\r\ngoto out;\r\n}\r\nprepare_to_wait_exclusive(&csdata->wait, &wait,\r\nTASK_INTERRUPTIBLE);\r\nschedule();\r\nfinish_wait(&csdata->wait, &wait);\r\n}\r\nretval = put_user(data, (u32 __user *)buf);\r\nif (!retval)\r\nretval = sizeof(data);\r\nout:\r\nreturn retval;\r\n}\r\nstatic ssize_t cs_char_write(struct file *file, const char __user *buf,\r\nsize_t count, loff_t *unused)\r\n{\r\nstruct cs_char *csdata = file->private_data;\r\nu32 data;\r\nint err;\r\nssize_t retval;\r\nif (count < sizeof(data))\r\nreturn -EINVAL;\r\nif (get_user(data, (u32 __user *)buf))\r\nretval = -EFAULT;\r\nelse\r\nretval = count;\r\nerr = cs_hsi_command(csdata->hi, data);\r\nif (err < 0)\r\nretval = err;\r\nreturn retval;\r\n}\r\nstatic long cs_char_ioctl(struct file *file, unsigned int cmd,\r\nunsigned long arg)\r\n{\r\nstruct cs_char *csdata = file->private_data;\r\nint r = 0;\r\nswitch (cmd) {\r\ncase CS_GET_STATE: {\r\nunsigned int state;\r\nstate = cs_hsi_get_state(csdata->hi);\r\nif (copy_to_user((void __user *)arg, &state, sizeof(state)))\r\nr = -EFAULT;\r\nbreak;\r\n}\r\ncase CS_SET_WAKELINE: {\r\nunsigned int state;\r\nif (copy_from_user(&state, (void __user *)arg, sizeof(state))) {\r\nr = -EFAULT;\r\nbreak;\r\n}\r\nif (state > 1) {\r\nr = -EINVAL;\r\nbreak;\r\n}\r\ncs_hsi_set_wakeline(csdata->hi, !!state);\r\nbreak;\r\n}\r\ncase CS_GET_IF_VERSION: {\r\nunsigned int ifver = CS_IF_VERSION;\r\nif (copy_to_user((void __user *)arg, &ifver, sizeof(ifver)))\r\nr = -EFAULT;\r\nbreak;\r\n}\r\ncase CS_CONFIG_BUFS: {\r\nstruct cs_buffer_config buf_cfg;\r\nif (copy_from_user(&buf_cfg, (void __user *)arg,\r\nsizeof(buf_cfg)))\r\nr = -EFAULT;\r\nelse\r\nr = cs_hsi_buf_config(csdata->hi, &buf_cfg);\r\nbreak;\r\n}\r\ndefault:\r\nr = -ENOTTY;\r\nbreak;\r\n}\r\nreturn r;\r\n}\r\nstatic int cs_char_mmap(struct file *file, struct vm_area_struct *vma)\r\n{\r\nif (vma->vm_end < vma->vm_start)\r\nreturn -EINVAL;\r\nif (vma_pages(vma) != 1)\r\nreturn -EINVAL;\r\nvma->vm_flags |= VM_IO | VM_DONTDUMP | VM_DONTEXPAND;\r\nvma->vm_ops = &cs_char_vm_ops;\r\nvma->vm_private_data = file->private_data;\r\nreturn 0;\r\n}\r\nstatic int cs_char_open(struct inode *unused, struct file *file)\r\n{\r\nint ret = 0;\r\nunsigned long p;\r\nspin_lock_bh(&cs_char_data.lock);\r\nif (cs_char_data.opened) {\r\nret = -EBUSY;\r\nspin_unlock_bh(&cs_char_data.lock);\r\ngoto out1;\r\n}\r\ncs_char_data.opened = 1;\r\ncs_char_data.dataind_pending = 0;\r\nspin_unlock_bh(&cs_char_data.lock);\r\np = get_zeroed_page(GFP_KERNEL);\r\nif (!p) {\r\nret = -ENOMEM;\r\ngoto out2;\r\n}\r\nret = cs_hsi_start(&cs_char_data.hi, cs_char_data.cl, p, CS_MMAP_SIZE);\r\nif (ret) {\r\ndev_err(&cs_char_data.cl->device, "Unable to initialize HSI\n");\r\ngoto out3;\r\n}\r\ncs_char_data.mmap_base = p;\r\ncs_char_data.mmap_size = CS_MMAP_SIZE;\r\nfile->private_data = &cs_char_data;\r\nreturn 0;\r\nout3:\r\nfree_page(p);\r\nout2:\r\nspin_lock_bh(&cs_char_data.lock);\r\ncs_char_data.opened = 0;\r\nspin_unlock_bh(&cs_char_data.lock);\r\nout1:\r\nreturn ret;\r\n}\r\nstatic void cs_free_char_queue(struct list_head *head)\r\n{\r\nstruct char_queue *entry;\r\nstruct list_head *cursor, *next;\r\nif (!list_empty(head)) {\r\nlist_for_each_safe(cursor, next, head) {\r\nentry = list_entry(cursor, struct char_queue, list);\r\nlist_del(&entry->list);\r\nkfree(entry);\r\n}\r\n}\r\n}\r\nstatic int cs_char_release(struct inode *unused, struct file *file)\r\n{\r\nstruct cs_char *csdata = file->private_data;\r\ncs_hsi_stop(csdata->hi);\r\nspin_lock_bh(&csdata->lock);\r\ncsdata->hi = NULL;\r\nfree_page(csdata->mmap_base);\r\ncs_free_char_queue(&csdata->chardev_queue);\r\ncs_free_char_queue(&csdata->dataind_queue);\r\ncsdata->opened = 0;\r\nspin_unlock_bh(&csdata->lock);\r\nreturn 0;\r\n}\r\nstatic int cs_hsi_client_probe(struct device *dev)\r\n{\r\nint err = 0;\r\nstruct hsi_client *cl = to_hsi_client(dev);\r\ndev_dbg(dev, "hsi_client_probe\n");\r\ninit_waitqueue_head(&cs_char_data.wait);\r\nspin_lock_init(&cs_char_data.lock);\r\ncs_char_data.opened = 0;\r\ncs_char_data.cl = cl;\r\ncs_char_data.hi = NULL;\r\nINIT_LIST_HEAD(&cs_char_data.chardev_queue);\r\nINIT_LIST_HEAD(&cs_char_data.dataind_queue);\r\ncs_char_data.channel_id_cmd = hsi_get_channel_id_by_name(cl,\r\n"speech-control");\r\nif (cs_char_data.channel_id_cmd < 0) {\r\nerr = cs_char_data.channel_id_cmd;\r\ndev_err(dev, "Could not get cmd channel (%d)\n", err);\r\nreturn err;\r\n}\r\ncs_char_data.channel_id_data = hsi_get_channel_id_by_name(cl,\r\n"speech-data");\r\nif (cs_char_data.channel_id_data < 0) {\r\nerr = cs_char_data.channel_id_data;\r\ndev_err(dev, "Could not get data channel (%d)\n", err);\r\nreturn err;\r\n}\r\nerr = misc_register(&cs_char_miscdev);\r\nif (err)\r\ndev_err(dev, "Failed to register: %d\n", err);\r\nreturn err;\r\n}\r\nstatic int cs_hsi_client_remove(struct device *dev)\r\n{\r\nstruct cs_hsi_iface *hi;\r\ndev_dbg(dev, "hsi_client_remove\n");\r\nmisc_deregister(&cs_char_miscdev);\r\nspin_lock_bh(&cs_char_data.lock);\r\nhi = cs_char_data.hi;\r\ncs_char_data.hi = NULL;\r\nspin_unlock_bh(&cs_char_data.lock);\r\nif (hi)\r\ncs_hsi_stop(hi);\r\nreturn 0;\r\n}\r\nstatic int __init cs_char_init(void)\r\n{\r\npr_info("CMT speech driver added\n");\r\nreturn hsi_register_client_driver(&cs_hsi_driver);\r\n}\r\nstatic void __exit cs_char_exit(void)\r\n{\r\nhsi_unregister_client_driver(&cs_hsi_driver);\r\npr_info("CMT speech driver removed\n");\r\n}
