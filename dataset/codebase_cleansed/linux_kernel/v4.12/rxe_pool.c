static inline const char *pool_name(struct rxe_pool *pool)\r\n{\r\nreturn rxe_type_info[pool->type].name;\r\n}\r\nstatic inline struct kmem_cache *pool_cache(struct rxe_pool *pool)\r\n{\r\nreturn rxe_type_info[pool->type].cache;\r\n}\r\nint rxe_cache_init(void)\r\n{\r\nint err;\r\nint i;\r\nsize_t size;\r\nstruct rxe_type_info *type;\r\nfor (i = 0; i < RXE_NUM_TYPES; i++) {\r\ntype = &rxe_type_info[i];\r\nsize = ALIGN(type->size, RXE_POOL_ALIGN);\r\ntype->cache = kmem_cache_create(type->name, size,\r\nRXE_POOL_ALIGN,\r\nRXE_POOL_CACHE_FLAGS, NULL);\r\nif (!type->cache) {\r\npr_err("Unable to init kmem cache for %s\n",\r\ntype->name);\r\nerr = -ENOMEM;\r\ngoto err1;\r\n}\r\n}\r\nreturn 0;\r\nerr1:\r\nwhile (--i >= 0) {\r\nkmem_cache_destroy(type->cache);\r\ntype->cache = NULL;\r\n}\r\nreturn err;\r\n}\r\nvoid rxe_cache_exit(void)\r\n{\r\nint i;\r\nstruct rxe_type_info *type;\r\nfor (i = 0; i < RXE_NUM_TYPES; i++) {\r\ntype = &rxe_type_info[i];\r\nkmem_cache_destroy(type->cache);\r\ntype->cache = NULL;\r\n}\r\n}\r\nstatic int rxe_pool_init_index(struct rxe_pool *pool, u32 max, u32 min)\r\n{\r\nint err = 0;\r\nsize_t size;\r\nif ((max - min + 1) < pool->max_elem) {\r\npr_warn("not enough indices for max_elem\n");\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\npool->max_index = max;\r\npool->min_index = min;\r\nsize = BITS_TO_LONGS(max - min + 1) * sizeof(long);\r\npool->table = kmalloc(size, GFP_KERNEL);\r\nif (!pool->table) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\npool->table_size = size;\r\nbitmap_zero(pool->table, max - min + 1);\r\nout:\r\nreturn err;\r\n}\r\nint rxe_pool_init(\r\nstruct rxe_dev *rxe,\r\nstruct rxe_pool *pool,\r\nenum rxe_elem_type type,\r\nunsigned max_elem)\r\n{\r\nint err = 0;\r\nsize_t size = rxe_type_info[type].size;\r\nmemset(pool, 0, sizeof(*pool));\r\npool->rxe = rxe;\r\npool->type = type;\r\npool->max_elem = max_elem;\r\npool->elem_size = ALIGN(size, RXE_POOL_ALIGN);\r\npool->flags = rxe_type_info[type].flags;\r\npool->tree = RB_ROOT;\r\npool->cleanup = rxe_type_info[type].cleanup;\r\natomic_set(&pool->num_elem, 0);\r\nkref_init(&pool->ref_cnt);\r\nspin_lock_init(&pool->pool_lock);\r\nif (rxe_type_info[type].flags & RXE_POOL_INDEX) {\r\nerr = rxe_pool_init_index(pool,\r\nrxe_type_info[type].max_index,\r\nrxe_type_info[type].min_index);\r\nif (err)\r\ngoto out;\r\n}\r\nif (rxe_type_info[type].flags & RXE_POOL_KEY) {\r\npool->key_offset = rxe_type_info[type].key_offset;\r\npool->key_size = rxe_type_info[type].key_size;\r\n}\r\npool->state = rxe_pool_valid;\r\nout:\r\nreturn err;\r\n}\r\nstatic void rxe_pool_release(struct kref *kref)\r\n{\r\nstruct rxe_pool *pool = container_of(kref, struct rxe_pool, ref_cnt);\r\npool->state = rxe_pool_invalid;\r\nkfree(pool->table);\r\n}\r\nstatic void rxe_pool_put(struct rxe_pool *pool)\r\n{\r\nkref_put(&pool->ref_cnt, rxe_pool_release);\r\n}\r\nint rxe_pool_cleanup(struct rxe_pool *pool)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\npool->state = rxe_pool_invalid;\r\nif (atomic_read(&pool->num_elem) > 0)\r\npr_warn("%s pool destroyed with unfree'd elem\n",\r\npool_name(pool));\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\nrxe_pool_put(pool);\r\nreturn 0;\r\n}\r\nstatic u32 alloc_index(struct rxe_pool *pool)\r\n{\r\nu32 index;\r\nu32 range = pool->max_index - pool->min_index + 1;\r\nindex = find_next_zero_bit(pool->table, range, pool->last);\r\nif (index >= range)\r\nindex = find_first_zero_bit(pool->table, range);\r\nWARN_ON_ONCE(index >= range);\r\nset_bit(index, pool->table);\r\npool->last = index;\r\nreturn index + pool->min_index;\r\n}\r\nstatic void insert_index(struct rxe_pool *pool, struct rxe_pool_entry *new)\r\n{\r\nstruct rb_node **link = &pool->tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct rxe_pool_entry *elem;\r\nwhile (*link) {\r\nparent = *link;\r\nelem = rb_entry(parent, struct rxe_pool_entry, node);\r\nif (elem->index == new->index) {\r\npr_warn("element already exists!\n");\r\ngoto out;\r\n}\r\nif (elem->index > new->index)\r\nlink = &(*link)->rb_left;\r\nelse\r\nlink = &(*link)->rb_right;\r\n}\r\nrb_link_node(&new->node, parent, link);\r\nrb_insert_color(&new->node, &pool->tree);\r\nout:\r\nreturn;\r\n}\r\nstatic void insert_key(struct rxe_pool *pool, struct rxe_pool_entry *new)\r\n{\r\nstruct rb_node **link = &pool->tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct rxe_pool_entry *elem;\r\nint cmp;\r\nwhile (*link) {\r\nparent = *link;\r\nelem = rb_entry(parent, struct rxe_pool_entry, node);\r\ncmp = memcmp((u8 *)elem + pool->key_offset,\r\n(u8 *)new + pool->key_offset, pool->key_size);\r\nif (cmp == 0) {\r\npr_warn("key already exists!\n");\r\ngoto out;\r\n}\r\nif (cmp > 0)\r\nlink = &(*link)->rb_left;\r\nelse\r\nlink = &(*link)->rb_right;\r\n}\r\nrb_link_node(&new->node, parent, link);\r\nrb_insert_color(&new->node, &pool->tree);\r\nout:\r\nreturn;\r\n}\r\nvoid rxe_add_key(void *arg, void *key)\r\n{\r\nstruct rxe_pool_entry *elem = arg;\r\nstruct rxe_pool *pool = elem->pool;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\nmemcpy((u8 *)elem + pool->key_offset, key, pool->key_size);\r\ninsert_key(pool, elem);\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\n}\r\nvoid rxe_drop_key(void *arg)\r\n{\r\nstruct rxe_pool_entry *elem = arg;\r\nstruct rxe_pool *pool = elem->pool;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\nrb_erase(&elem->node, &pool->tree);\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\n}\r\nvoid rxe_add_index(void *arg)\r\n{\r\nstruct rxe_pool_entry *elem = arg;\r\nstruct rxe_pool *pool = elem->pool;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\nelem->index = alloc_index(pool);\r\ninsert_index(pool, elem);\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\n}\r\nvoid rxe_drop_index(void *arg)\r\n{\r\nstruct rxe_pool_entry *elem = arg;\r\nstruct rxe_pool *pool = elem->pool;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\nclear_bit(elem->index - pool->min_index, pool->table);\r\nrb_erase(&elem->node, &pool->tree);\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\n}\r\nvoid *rxe_alloc(struct rxe_pool *pool)\r\n{\r\nstruct rxe_pool_entry *elem;\r\nunsigned long flags;\r\nmight_sleep_if(!(pool->flags & RXE_POOL_ATOMIC));\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\nif (pool->state != rxe_pool_valid) {\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\nreturn NULL;\r\n}\r\nkref_get(&pool->ref_cnt);\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\nkref_get(&pool->rxe->ref_cnt);\r\nif (atomic_inc_return(&pool->num_elem) > pool->max_elem) {\r\natomic_dec(&pool->num_elem);\r\nrxe_dev_put(pool->rxe);\r\nrxe_pool_put(pool);\r\nreturn NULL;\r\n}\r\nelem = kmem_cache_zalloc(pool_cache(pool),\r\n(pool->flags & RXE_POOL_ATOMIC) ?\r\nGFP_ATOMIC : GFP_KERNEL);\r\nelem->pool = pool;\r\nkref_init(&elem->ref_cnt);\r\nreturn elem;\r\n}\r\nvoid rxe_elem_release(struct kref *kref)\r\n{\r\nstruct rxe_pool_entry *elem =\r\ncontainer_of(kref, struct rxe_pool_entry, ref_cnt);\r\nstruct rxe_pool *pool = elem->pool;\r\nif (pool->cleanup)\r\npool->cleanup(elem);\r\nkmem_cache_free(pool_cache(pool), elem);\r\natomic_dec(&pool->num_elem);\r\nrxe_dev_put(pool->rxe);\r\nrxe_pool_put(pool);\r\n}\r\nvoid *rxe_pool_get_index(struct rxe_pool *pool, u32 index)\r\n{\r\nstruct rb_node *node = NULL;\r\nstruct rxe_pool_entry *elem = NULL;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\nif (pool->state != rxe_pool_valid)\r\ngoto out;\r\nnode = pool->tree.rb_node;\r\nwhile (node) {\r\nelem = rb_entry(node, struct rxe_pool_entry, node);\r\nif (elem->index > index)\r\nnode = node->rb_left;\r\nelse if (elem->index < index)\r\nnode = node->rb_right;\r\nelse\r\nbreak;\r\n}\r\nif (node)\r\nkref_get(&elem->ref_cnt);\r\nout:\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\nreturn node ? elem : NULL;\r\n}\r\nvoid *rxe_pool_get_key(struct rxe_pool *pool, void *key)\r\n{\r\nstruct rb_node *node = NULL;\r\nstruct rxe_pool_entry *elem = NULL;\r\nint cmp;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pool->pool_lock, flags);\r\nif (pool->state != rxe_pool_valid)\r\ngoto out;\r\nnode = pool->tree.rb_node;\r\nwhile (node) {\r\nelem = rb_entry(node, struct rxe_pool_entry, node);\r\ncmp = memcmp((u8 *)elem + pool->key_offset,\r\nkey, pool->key_size);\r\nif (cmp > 0)\r\nnode = node->rb_left;\r\nelse if (cmp < 0)\r\nnode = node->rb_right;\r\nelse\r\nbreak;\r\n}\r\nif (node)\r\nkref_get(&elem->ref_cnt);\r\nout:\r\nspin_unlock_irqrestore(&pool->pool_lock, flags);\r\nreturn node ? elem : NULL;\r\n}
