static int\r\ngk104_fifo_gpfifo_kick(struct gk104_fifo_chan *chan)\r\n{\r\nstruct gk104_fifo *fifo = chan->fifo;\r\nstruct nvkm_subdev *subdev = &fifo->base.engine.subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nstruct nvkm_client *client = chan->base.object.client;\r\nint ret = 0;\r\nmutex_lock(&subdev->mutex);\r\nnvkm_wr32(device, 0x002634, chan->base.chid);\r\nif (nvkm_msec(device, 2000,\r\nif (!(nvkm_rd32(device, 0x002634) & 0x00100000))\r\nbreak;\r\n) < 0) {\r\nnvkm_error(subdev, "channel %d [%s] kick timeout\n",\r\nchan->base.chid, client->name);\r\nnvkm_fifo_recover_chan(&fifo->base, chan->base.chid);\r\nret = -ETIMEDOUT;\r\n}\r\nmutex_unlock(&subdev->mutex);\r\nreturn ret;\r\n}\r\nstatic u32\r\ngk104_fifo_gpfifo_engine_addr(struct nvkm_engine *engine)\r\n{\r\nswitch (engine->subdev.index) {\r\ncase NVKM_ENGINE_SW :\r\ncase NVKM_ENGINE_CE0 :\r\ncase NVKM_ENGINE_CE1 :\r\ncase NVKM_ENGINE_CE2 : return 0x0000;\r\ncase NVKM_ENGINE_GR : return 0x0210;\r\ncase NVKM_ENGINE_SEC : return 0x0220;\r\ncase NVKM_ENGINE_MSPDEC: return 0x0250;\r\ncase NVKM_ENGINE_MSPPP : return 0x0260;\r\ncase NVKM_ENGINE_MSVLD : return 0x0270;\r\ncase NVKM_ENGINE_VIC : return 0x0280;\r\ncase NVKM_ENGINE_MSENC : return 0x0290;\r\ncase NVKM_ENGINE_NVDEC : return 0x02100270;\r\ncase NVKM_ENGINE_NVENC0: return 0x02100290;\r\ncase NVKM_ENGINE_NVENC1: return 0x0210;\r\ndefault:\r\nWARN_ON(1);\r\nreturn 0;\r\n}\r\n}\r\nstatic int\r\ngk104_fifo_gpfifo_engine_fini(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine, bool suspend)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct nvkm_gpuobj *inst = chan->base.inst;\r\nu32 offset = gk104_fifo_gpfifo_engine_addr(engine);\r\nint ret;\r\nret = gk104_fifo_gpfifo_kick(chan);\r\nif (ret && suspend)\r\nreturn ret;\r\nif (offset) {\r\nnvkm_kmap(inst);\r\nnvkm_wo32(inst, (offset & 0xffff) + 0x00, 0x00000000);\r\nnvkm_wo32(inst, (offset & 0xffff) + 0x04, 0x00000000);\r\nif ((offset >>= 16)) {\r\nnvkm_wo32(inst, offset + 0x00, 0x00000000);\r\nnvkm_wo32(inst, offset + 0x04, 0x00000000);\r\n}\r\nnvkm_done(inst);\r\n}\r\nreturn ret;\r\n}\r\nstatic int\r\ngk104_fifo_gpfifo_engine_init(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct nvkm_gpuobj *inst = chan->base.inst;\r\nu32 offset = gk104_fifo_gpfifo_engine_addr(engine);\r\nif (offset) {\r\nu64 addr = chan->engn[engine->subdev.index].vma.offset;\r\nu32 datalo = lower_32_bits(addr) | 0x00000004;\r\nu32 datahi = upper_32_bits(addr);\r\nnvkm_kmap(inst);\r\nnvkm_wo32(inst, (offset & 0xffff) + 0x00, datalo);\r\nnvkm_wo32(inst, (offset & 0xffff) + 0x04, datahi);\r\nif ((offset >>= 16)) {\r\nnvkm_wo32(inst, offset + 0x00, datalo);\r\nnvkm_wo32(inst, offset + 0x04, datahi);\r\n}\r\nnvkm_done(inst);\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\ngk104_fifo_gpfifo_engine_dtor(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nnvkm_gpuobj_unmap(&chan->engn[engine->subdev.index].vma);\r\nnvkm_gpuobj_del(&chan->engn[engine->subdev.index].inst);\r\n}\r\nstatic int\r\ngk104_fifo_gpfifo_engine_ctor(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine,\r\nstruct nvkm_object *object)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nint engn = engine->subdev.index;\r\nint ret;\r\nif (!gk104_fifo_gpfifo_engine_addr(engine))\r\nreturn 0;\r\nret = nvkm_object_bind(object, NULL, 0, &chan->engn[engn].inst);\r\nif (ret)\r\nreturn ret;\r\nreturn nvkm_gpuobj_map(chan->engn[engn].inst, chan->vm,\r\nNV_MEM_ACCESS_RW, &chan->engn[engn].vma);\r\n}\r\nstatic void\r\ngk104_fifo_gpfifo_fini(struct nvkm_fifo_chan *base)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct gk104_fifo *fifo = chan->fifo;\r\nstruct nvkm_device *device = fifo->base.engine.subdev.device;\r\nu32 coff = chan->base.chid * 8;\r\nif (!list_empty(&chan->head)) {\r\ngk104_fifo_runlist_remove(fifo, chan);\r\nnvkm_mask(device, 0x800004 + coff, 0x00000800, 0x00000800);\r\ngk104_fifo_gpfifo_kick(chan);\r\ngk104_fifo_runlist_commit(fifo, chan->runl);\r\n}\r\nnvkm_wr32(device, 0x800000 + coff, 0x00000000);\r\n}\r\nstatic void\r\ngk104_fifo_gpfifo_init(struct nvkm_fifo_chan *base)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct gk104_fifo *fifo = chan->fifo;\r\nstruct nvkm_device *device = fifo->base.engine.subdev.device;\r\nu32 addr = chan->base.inst->addr >> 12;\r\nu32 coff = chan->base.chid * 8;\r\nnvkm_mask(device, 0x800004 + coff, 0x000f0000, chan->runl << 16);\r\nnvkm_wr32(device, 0x800000 + coff, 0x80000000 | addr);\r\nif (list_empty(&chan->head) && !chan->killed) {\r\ngk104_fifo_runlist_insert(fifo, chan);\r\nnvkm_mask(device, 0x800004 + coff, 0x00000400, 0x00000400);\r\ngk104_fifo_runlist_commit(fifo, chan->runl);\r\nnvkm_mask(device, 0x800004 + coff, 0x00000400, 0x00000400);\r\n}\r\n}\r\nstatic void *\r\ngk104_fifo_gpfifo_dtor(struct nvkm_fifo_chan *base)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nnvkm_vm_ref(NULL, &chan->vm, chan->pgd);\r\nnvkm_gpuobj_del(&chan->pgd);\r\nreturn chan;\r\n}\r\nstatic int\r\ngk104_fifo_gpfifo_new_(const struct gk104_fifo_chan_func *func,\r\nstruct gk104_fifo *fifo, u32 *engmask, u16 *chid,\r\nu64 vm, u64 ioffset, u64 ilength,\r\nconst struct nvkm_oclass *oclass,\r\nstruct nvkm_object **pobject)\r\n{\r\nstruct nvkm_device *device = fifo->base.engine.subdev.device;\r\nstruct gk104_fifo_chan *chan;\r\nint runlist = -1, ret = -ENOSYS, i, j;\r\nu32 engines = 0, present = 0;\r\nu64 subdevs = 0;\r\nu64 usermem;\r\nfor (i = 0; i < fifo->engine_nr; i++) {\r\nstruct nvkm_engine *engine = fifo->engine[i].engine;\r\nif (engine) {\r\nu64 submask = BIT_ULL(engine->subdev.index);\r\nfor (j = 0; func[j].subdev; j++) {\r\nif (func[j].subdev & submask) {\r\npresent |= func[j].engine;\r\nbreak;\r\n}\r\n}\r\nif (!func[j].subdev)\r\ncontinue;\r\nif (runlist < 0 && (*engmask & present))\r\nrunlist = fifo->engine[i].runl;\r\nif (runlist == fifo->engine[i].runl) {\r\nengines |= func[j].engine;\r\nsubdevs |= func[j].subdev;\r\n}\r\n}\r\n}\r\nif (!*engmask) {\r\n*engmask = present;\r\nreturn nvkm_object_new(oclass, NULL, 0, pobject);\r\n}\r\n*engmask = present;\r\nif (runlist < 0)\r\nreturn -ENODEV;\r\n*engmask = engines;\r\nif (!(chan = kzalloc(sizeof(*chan), GFP_KERNEL)))\r\nreturn -ENOMEM;\r\n*pobject = &chan->base.object;\r\nchan->fifo = fifo;\r\nchan->runl = runlist;\r\nINIT_LIST_HEAD(&chan->head);\r\nret = nvkm_fifo_chan_ctor(&gk104_fifo_gpfifo_func, &fifo->base,\r\n0x1000, 0x1000, true, vm, 0, subdevs,\r\n1, fifo->user.bar.offset, 0x200,\r\noclass, &chan->base);\r\nif (ret)\r\nreturn ret;\r\n*chid = chan->base.chid;\r\nret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &chan->pgd);\r\nif (ret)\r\nreturn ret;\r\nnvkm_kmap(chan->base.inst);\r\nnvkm_wo32(chan->base.inst, 0x0200, lower_32_bits(chan->pgd->addr));\r\nnvkm_wo32(chan->base.inst, 0x0204, upper_32_bits(chan->pgd->addr));\r\nnvkm_wo32(chan->base.inst, 0x0208, 0xffffffff);\r\nnvkm_wo32(chan->base.inst, 0x020c, 0x000000ff);\r\nnvkm_done(chan->base.inst);\r\nret = nvkm_vm_ref(chan->base.vm, &chan->vm, chan->pgd);\r\nif (ret)\r\nreturn ret;\r\nusermem = chan->base.chid * 0x200;\r\nilength = order_base_2(ilength / 8);\r\nnvkm_kmap(fifo->user.mem);\r\nfor (i = 0; i < 0x200; i += 4)\r\nnvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);\r\nnvkm_done(fifo->user.mem);\r\nusermem = nvkm_memory_addr(fifo->user.mem) + usermem;\r\nnvkm_kmap(chan->base.inst);\r\nnvkm_wo32(chan->base.inst, 0x08, lower_32_bits(usermem));\r\nnvkm_wo32(chan->base.inst, 0x0c, upper_32_bits(usermem));\r\nnvkm_wo32(chan->base.inst, 0x10, 0x0000face);\r\nnvkm_wo32(chan->base.inst, 0x30, 0xfffff902);\r\nnvkm_wo32(chan->base.inst, 0x48, lower_32_bits(ioffset));\r\nnvkm_wo32(chan->base.inst, 0x4c, upper_32_bits(ioffset) |\r\n(ilength << 16));\r\nnvkm_wo32(chan->base.inst, 0x84, 0x20400000);\r\nnvkm_wo32(chan->base.inst, 0x94, 0x30000001);\r\nnvkm_wo32(chan->base.inst, 0x9c, 0x00000100);\r\nnvkm_wo32(chan->base.inst, 0xac, 0x0000001f);\r\nnvkm_wo32(chan->base.inst, 0xe8, chan->base.chid);\r\nnvkm_wo32(chan->base.inst, 0xb8, 0xf8000000);\r\nnvkm_wo32(chan->base.inst, 0xf8, 0x10003080);\r\nnvkm_wo32(chan->base.inst, 0xfc, 0x10000010);\r\nnvkm_done(chan->base.inst);\r\nreturn 0;\r\n}\r\nint\r\ngk104_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,\r\nvoid *data, u32 size, struct nvkm_object **pobject)\r\n{\r\nstruct nvkm_object *parent = oclass->parent;\r\nunion {\r\nstruct kepler_channel_gpfifo_a_v0 v0;\r\n} *args = data;\r\nstruct gk104_fifo *fifo = gk104_fifo(base);\r\nint ret = -ENOSYS;\r\nnvif_ioctl(parent, "create channel gpfifo size %d\n", size);\r\nif (!(ret = nvif_unpack(ret, &data, &size, args->v0, 0, 0, false))) {\r\nnvif_ioctl(parent, "create channel gpfifo vers %d vm %llx "\r\n"ioffset %016llx ilength %08x engine %08x\n",\r\nargs->v0.version, args->v0.vm, args->v0.ioffset,\r\nargs->v0.ilength, args->v0.engines);\r\nreturn gk104_fifo_gpfifo_new_(gk104_fifo_gpfifo, fifo,\r\n&args->v0.engines,\r\n&args->v0.chid,\r\nargs->v0.vm,\r\nargs->v0.ioffset,\r\nargs->v0.ilength,\r\noclass, pobject);\r\n}\r\nreturn ret;\r\n}
