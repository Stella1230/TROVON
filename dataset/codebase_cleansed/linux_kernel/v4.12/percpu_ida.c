static inline void move_tags(unsigned *dst, unsigned *dst_nr,\r\nunsigned *src, unsigned *src_nr,\r\nunsigned nr)\r\n{\r\n*src_nr -= nr;\r\nmemcpy(dst + *dst_nr, src + *src_nr, sizeof(unsigned) * nr);\r\n*dst_nr += nr;\r\n}\r\nstatic inline void steal_tags(struct percpu_ida *pool,\r\nstruct percpu_ida_cpu *tags)\r\n{\r\nunsigned cpus_have_tags, cpu = pool->cpu_last_stolen;\r\nstruct percpu_ida_cpu *remote;\r\nfor (cpus_have_tags = cpumask_weight(&pool->cpus_have_tags);\r\ncpus_have_tags; cpus_have_tags--) {\r\ncpu = cpumask_next(cpu, &pool->cpus_have_tags);\r\nif (cpu >= nr_cpu_ids) {\r\ncpu = cpumask_first(&pool->cpus_have_tags);\r\nif (cpu >= nr_cpu_ids)\r\nBUG();\r\n}\r\npool->cpu_last_stolen = cpu;\r\nremote = per_cpu_ptr(pool->tag_cpu, cpu);\r\ncpumask_clear_cpu(cpu, &pool->cpus_have_tags);\r\nif (remote == tags)\r\ncontinue;\r\nspin_lock(&remote->lock);\r\nif (remote->nr_free) {\r\nmemcpy(tags->freelist,\r\nremote->freelist,\r\nsizeof(unsigned) * remote->nr_free);\r\ntags->nr_free = remote->nr_free;\r\nremote->nr_free = 0;\r\n}\r\nspin_unlock(&remote->lock);\r\nif (tags->nr_free)\r\nbreak;\r\n}\r\n}\r\nstatic inline void alloc_global_tags(struct percpu_ida *pool,\r\nstruct percpu_ida_cpu *tags)\r\n{\r\nmove_tags(tags->freelist, &tags->nr_free,\r\npool->freelist, &pool->nr_free,\r\nmin(pool->nr_free, pool->percpu_batch_size));\r\n}\r\nstatic inline unsigned alloc_local_tag(struct percpu_ida_cpu *tags)\r\n{\r\nint tag = -ENOSPC;\r\nspin_lock(&tags->lock);\r\nif (tags->nr_free)\r\ntag = tags->freelist[--tags->nr_free];\r\nspin_unlock(&tags->lock);\r\nreturn tag;\r\n}\r\nint percpu_ida_alloc(struct percpu_ida *pool, int state)\r\n{\r\nDEFINE_WAIT(wait);\r\nstruct percpu_ida_cpu *tags;\r\nunsigned long flags;\r\nint tag;\r\nlocal_irq_save(flags);\r\ntags = this_cpu_ptr(pool->tag_cpu);\r\ntag = alloc_local_tag(tags);\r\nif (likely(tag >= 0)) {\r\nlocal_irq_restore(flags);\r\nreturn tag;\r\n}\r\nwhile (1) {\r\nspin_lock(&pool->lock);\r\nif (state != TASK_RUNNING)\r\nprepare_to_wait(&pool->wait, &wait, state);\r\nif (!tags->nr_free)\r\nalloc_global_tags(pool, tags);\r\nif (!tags->nr_free)\r\nsteal_tags(pool, tags);\r\nif (tags->nr_free) {\r\ntag = tags->freelist[--tags->nr_free];\r\nif (tags->nr_free)\r\ncpumask_set_cpu(smp_processor_id(),\r\n&pool->cpus_have_tags);\r\n}\r\nspin_unlock(&pool->lock);\r\nlocal_irq_restore(flags);\r\nif (tag >= 0 || state == TASK_RUNNING)\r\nbreak;\r\nif (signal_pending_state(state, current)) {\r\ntag = -ERESTARTSYS;\r\nbreak;\r\n}\r\nschedule();\r\nlocal_irq_save(flags);\r\ntags = this_cpu_ptr(pool->tag_cpu);\r\n}\r\nif (state != TASK_RUNNING)\r\nfinish_wait(&pool->wait, &wait);\r\nreturn tag;\r\n}\r\nvoid percpu_ida_free(struct percpu_ida *pool, unsigned tag)\r\n{\r\nstruct percpu_ida_cpu *tags;\r\nunsigned long flags;\r\nunsigned nr_free;\r\nBUG_ON(tag >= pool->nr_tags);\r\nlocal_irq_save(flags);\r\ntags = this_cpu_ptr(pool->tag_cpu);\r\nspin_lock(&tags->lock);\r\ntags->freelist[tags->nr_free++] = tag;\r\nnr_free = tags->nr_free;\r\nspin_unlock(&tags->lock);\r\nif (nr_free == 1) {\r\ncpumask_set_cpu(smp_processor_id(),\r\n&pool->cpus_have_tags);\r\nwake_up(&pool->wait);\r\n}\r\nif (nr_free == pool->percpu_max_size) {\r\nspin_lock(&pool->lock);\r\nif (tags->nr_free == pool->percpu_max_size) {\r\nmove_tags(pool->freelist, &pool->nr_free,\r\ntags->freelist, &tags->nr_free,\r\npool->percpu_batch_size);\r\nwake_up(&pool->wait);\r\n}\r\nspin_unlock(&pool->lock);\r\n}\r\nlocal_irq_restore(flags);\r\n}\r\nvoid percpu_ida_destroy(struct percpu_ida *pool)\r\n{\r\nfree_percpu(pool->tag_cpu);\r\nfree_pages((unsigned long) pool->freelist,\r\nget_order(pool->nr_tags * sizeof(unsigned)));\r\n}\r\nint __percpu_ida_init(struct percpu_ida *pool, unsigned long nr_tags,\r\nunsigned long max_size, unsigned long batch_size)\r\n{\r\nunsigned i, cpu, order;\r\nmemset(pool, 0, sizeof(*pool));\r\ninit_waitqueue_head(&pool->wait);\r\nspin_lock_init(&pool->lock);\r\npool->nr_tags = nr_tags;\r\npool->percpu_max_size = max_size;\r\npool->percpu_batch_size = batch_size;\r\nif (nr_tags > (unsigned) INT_MAX + 1) {\r\npr_err("percpu_ida_init(): nr_tags too large\n");\r\nreturn -EINVAL;\r\n}\r\norder = get_order(nr_tags * sizeof(unsigned));\r\npool->freelist = (void *) __get_free_pages(GFP_KERNEL, order);\r\nif (!pool->freelist)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < nr_tags; i++)\r\npool->freelist[i] = i;\r\npool->nr_free = nr_tags;\r\npool->tag_cpu = __alloc_percpu(sizeof(struct percpu_ida_cpu) +\r\npool->percpu_max_size * sizeof(unsigned),\r\nsizeof(unsigned));\r\nif (!pool->tag_cpu)\r\ngoto err;\r\nfor_each_possible_cpu(cpu)\r\nspin_lock_init(&per_cpu_ptr(pool->tag_cpu, cpu)->lock);\r\nreturn 0;\r\nerr:\r\npercpu_ida_destroy(pool);\r\nreturn -ENOMEM;\r\n}\r\nint percpu_ida_for_each_free(struct percpu_ida *pool, percpu_ida_cb fn,\r\nvoid *data)\r\n{\r\nunsigned long flags;\r\nstruct percpu_ida_cpu *remote;\r\nunsigned cpu, i, err = 0;\r\nlocal_irq_save(flags);\r\nfor_each_possible_cpu(cpu) {\r\nremote = per_cpu_ptr(pool->tag_cpu, cpu);\r\nspin_lock(&remote->lock);\r\nfor (i = 0; i < remote->nr_free; i++) {\r\nerr = fn(remote->freelist[i], data);\r\nif (err)\r\nbreak;\r\n}\r\nspin_unlock(&remote->lock);\r\nif (err)\r\ngoto out;\r\n}\r\nspin_lock(&pool->lock);\r\nfor (i = 0; i < pool->nr_free; i++) {\r\nerr = fn(pool->freelist[i], data);\r\nif (err)\r\nbreak;\r\n}\r\nspin_unlock(&pool->lock);\r\nout:\r\nlocal_irq_restore(flags);\r\nreturn err;\r\n}\r\nunsigned percpu_ida_free_tags(struct percpu_ida *pool, int cpu)\r\n{\r\nstruct percpu_ida_cpu *remote;\r\nif (cpu == nr_cpu_ids)\r\nreturn pool->nr_free;\r\nremote = per_cpu_ptr(pool->tag_cpu, cpu);\r\nreturn remote->nr_free;\r\n}
