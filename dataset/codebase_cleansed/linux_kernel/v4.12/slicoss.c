static inline int slic_next_queue_idx(unsigned int idx, unsigned int qlen)\r\n{\r\nreturn (idx + 1) & (qlen - 1);\r\n}\r\nstatic inline int slic_get_free_queue_descs(unsigned int put_idx,\r\nunsigned int done_idx,\r\nunsigned int qlen)\r\n{\r\nif (put_idx >= done_idx)\r\nreturn (qlen - (put_idx - done_idx) - 1);\r\nreturn (done_idx - put_idx - 1);\r\n}\r\nstatic unsigned int slic_next_compl_idx(struct slic_device *sdev)\r\n{\r\nstruct slic_stat_queue *stq = &sdev->stq;\r\nunsigned int active = stq->active_array;\r\nstruct slic_stat_desc *descs;\r\nstruct slic_stat_desc *stat;\r\nunsigned int idx;\r\ndescs = stq->descs[active];\r\nstat = &descs[stq->done_idx];\r\nif (!stat->status)\r\nreturn SLIC_INVALID_STAT_DESC_IDX;\r\nidx = (le32_to_cpu(stat->hnd) & 0xffff) - 1;\r\nstat->hnd = 0;\r\nstat->status = 0;\r\nstq->done_idx = slic_next_queue_idx(stq->done_idx, stq->len);\r\nif (!stq->done_idx) {\r\ndma_addr_t paddr = stq->paddr[active];\r\nslic_write(sdev, SLIC_REG_RBAR, lower_32_bits(paddr) |\r\nstq->len);\r\nslic_flush_write(sdev);\r\nactive++;\r\nactive &= (SLIC_NUM_STAT_DESC_ARRAYS - 1);\r\nstq->active_array = active;\r\n}\r\nreturn idx;\r\n}\r\nstatic unsigned int slic_get_free_tx_descs(struct slic_tx_queue *txq)\r\n{\r\nsmp_mb();\r\nreturn slic_get_free_queue_descs(txq->put_idx, txq->done_idx, txq->len);\r\n}\r\nstatic unsigned int slic_get_free_rx_descs(struct slic_rx_queue *rxq)\r\n{\r\nreturn slic_get_free_queue_descs(rxq->put_idx, rxq->done_idx, rxq->len);\r\n}\r\nstatic void slic_clear_upr_list(struct slic_upr_list *upr_list)\r\n{\r\nstruct slic_upr *upr;\r\nstruct slic_upr *tmp;\r\nspin_lock_bh(&upr_list->lock);\r\nlist_for_each_entry_safe(upr, tmp, &upr_list->list, list) {\r\nlist_del(&upr->list);\r\nkfree(upr);\r\n}\r\nupr_list->pending = false;\r\nspin_unlock_bh(&upr_list->lock);\r\n}\r\nstatic void slic_start_upr(struct slic_device *sdev, struct slic_upr *upr)\r\n{\r\nu32 reg;\r\nreg = (upr->type == SLIC_UPR_CONFIG) ? SLIC_REG_RCONFIG :\r\nSLIC_REG_LSTAT;\r\nslic_write(sdev, reg, lower_32_bits(upr->paddr));\r\nslic_flush_write(sdev);\r\n}\r\nstatic void slic_queue_upr(struct slic_device *sdev, struct slic_upr *upr)\r\n{\r\nstruct slic_upr_list *upr_list = &sdev->upr_list;\r\nbool pending;\r\nspin_lock_bh(&upr_list->lock);\r\npending = upr_list->pending;\r\nINIT_LIST_HEAD(&upr->list);\r\nlist_add_tail(&upr->list, &upr_list->list);\r\nupr_list->pending = true;\r\nspin_unlock_bh(&upr_list->lock);\r\nif (!pending)\r\nslic_start_upr(sdev, upr);\r\n}\r\nstatic struct slic_upr *slic_dequeue_upr(struct slic_device *sdev)\r\n{\r\nstruct slic_upr_list *upr_list = &sdev->upr_list;\r\nstruct slic_upr *next_upr = NULL;\r\nstruct slic_upr *upr = NULL;\r\nspin_lock_bh(&upr_list->lock);\r\nif (!list_empty(&upr_list->list)) {\r\nupr = list_first_entry(&upr_list->list, struct slic_upr, list);\r\nlist_del(&upr->list);\r\nif (list_empty(&upr_list->list))\r\nupr_list->pending = false;\r\nelse\r\nnext_upr = list_first_entry(&upr_list->list,\r\nstruct slic_upr, list);\r\n}\r\nspin_unlock_bh(&upr_list->lock);\r\nif (next_upr)\r\nslic_start_upr(sdev, next_upr);\r\nreturn upr;\r\n}\r\nstatic int slic_new_upr(struct slic_device *sdev, unsigned int type,\r\ndma_addr_t paddr)\r\n{\r\nstruct slic_upr *upr;\r\nupr = kmalloc(sizeof(*upr), GFP_ATOMIC);\r\nif (!upr)\r\nreturn -ENOMEM;\r\nupr->type = type;\r\nupr->paddr = paddr;\r\nslic_queue_upr(sdev, upr);\r\nreturn 0;\r\n}\r\nstatic void slic_set_mcast_bit(u64 *mcmask, unsigned char const *addr)\r\n{\r\nu64 mask = *mcmask;\r\nu8 crc;\r\ncrc = ether_crc(ETH_ALEN, addr) >> 23;\r\ncrc &= 0x3F;\r\nmask |= (u64)1 << crc;\r\n*mcmask = mask;\r\n}\r\nstatic void slic_configure_rcv(struct slic_device *sdev)\r\n{\r\nu32 val;\r\nval = SLIC_GRCR_RESET | SLIC_GRCR_ADDRAEN | SLIC_GRCR_RCVEN |\r\nSLIC_GRCR_HASHSIZE << SLIC_GRCR_HASHSIZE_SHIFT | SLIC_GRCR_RCVBAD;\r\nif (sdev->duplex == DUPLEX_FULL)\r\nval |= SLIC_GRCR_CTLEN;\r\nif (sdev->promisc)\r\nval |= SLIC_GRCR_RCVALL;\r\nslic_write(sdev, SLIC_REG_WRCFG, val);\r\n}\r\nstatic void slic_configure_xmt(struct slic_device *sdev)\r\n{\r\nu32 val;\r\nval = SLIC_GXCR_RESET | SLIC_GXCR_XMTEN;\r\nif (sdev->duplex == DUPLEX_FULL)\r\nval |= SLIC_GXCR_PAUSEEN;\r\nslic_write(sdev, SLIC_REG_WXCFG, val);\r\n}\r\nstatic void slic_configure_mac(struct slic_device *sdev)\r\n{\r\nu32 val;\r\nif (sdev->speed == SPEED_1000) {\r\nval = SLIC_GMCR_GAPBB_1000 << SLIC_GMCR_GAPBB_SHIFT |\r\nSLIC_GMCR_GAPR1_1000 << SLIC_GMCR_GAPR1_SHIFT |\r\nSLIC_GMCR_GAPR2_1000 << SLIC_GMCR_GAPR2_SHIFT |\r\nSLIC_GMCR_GBIT;\r\n} else {\r\nval = SLIC_GMCR_GAPBB_100 << SLIC_GMCR_GAPBB_SHIFT |\r\nSLIC_GMCR_GAPR1_100 << SLIC_GMCR_GAPR1_SHIFT |\r\nSLIC_GMCR_GAPR2_100 << SLIC_GMCR_GAPR2_SHIFT;\r\n}\r\nif (sdev->duplex == DUPLEX_FULL)\r\nval |= SLIC_GMCR_FULLD;\r\nslic_write(sdev, SLIC_REG_WMCFG, val);\r\n}\r\nstatic void slic_configure_link_locked(struct slic_device *sdev, int speed,\r\nunsigned int duplex)\r\n{\r\nstruct net_device *dev = sdev->netdev;\r\nif (sdev->speed == speed && sdev->duplex == duplex)\r\nreturn;\r\nsdev->speed = speed;\r\nsdev->duplex = duplex;\r\nif (sdev->speed == SPEED_UNKNOWN) {\r\nif (netif_carrier_ok(dev))\r\nnetif_carrier_off(dev);\r\n} else {\r\nslic_configure_mac(sdev);\r\nslic_configure_xmt(sdev);\r\nslic_configure_rcv(sdev);\r\nslic_flush_write(sdev);\r\nif (!netif_carrier_ok(dev))\r\nnetif_carrier_on(dev);\r\n}\r\n}\r\nstatic void slic_configure_link(struct slic_device *sdev, int speed,\r\nunsigned int duplex)\r\n{\r\nspin_lock_bh(&sdev->link_lock);\r\nslic_configure_link_locked(sdev, speed, duplex);\r\nspin_unlock_bh(&sdev->link_lock);\r\n}\r\nstatic void slic_set_rx_mode(struct net_device *dev)\r\n{\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nstruct netdev_hw_addr *hwaddr;\r\nbool set_promisc;\r\nu64 mcmask;\r\nif (dev->flags & (IFF_PROMISC | IFF_ALLMULTI)) {\r\nmcmask = ~(u64)0;\r\n} else {\r\nmcmask = 0;\r\nnetdev_for_each_mc_addr(hwaddr, dev) {\r\nslic_set_mcast_bit(&mcmask, hwaddr->addr);\r\n}\r\n}\r\nslic_write(sdev, SLIC_REG_MCASTLOW, lower_32_bits(mcmask));\r\nslic_write(sdev, SLIC_REG_MCASTHIGH, upper_32_bits(mcmask));\r\nset_promisc = !!(dev->flags & IFF_PROMISC);\r\nspin_lock_bh(&sdev->link_lock);\r\nif (sdev->promisc != set_promisc) {\r\nsdev->promisc = set_promisc;\r\nslic_configure_rcv(sdev);\r\nmmiowb();\r\n}\r\nspin_unlock_bh(&sdev->link_lock);\r\n}\r\nstatic void slic_xmit_complete(struct slic_device *sdev)\r\n{\r\nstruct slic_tx_queue *txq = &sdev->txq;\r\nstruct net_device *dev = sdev->netdev;\r\nunsigned int idx = txq->done_idx;\r\nstruct slic_tx_buffer *buff;\r\nunsigned int frames = 0;\r\nunsigned int bytes = 0;\r\ndo {\r\nidx = slic_next_compl_idx(sdev);\r\nif (idx == SLIC_INVALID_STAT_DESC_IDX)\r\nbreak;\r\ntxq->done_idx = idx;\r\nbuff = &txq->txbuffs[idx];\r\nif (unlikely(!buff->skb)) {\r\nnetdev_warn(dev,\r\n"no skb found for desc idx %i\n", idx);\r\ncontinue;\r\n}\r\ndma_unmap_single(&sdev->pdev->dev,\r\ndma_unmap_addr(buff, map_addr),\r\ndma_unmap_len(buff, map_len), DMA_TO_DEVICE);\r\nbytes += buff->skb->len;\r\nframes++;\r\ndev_kfree_skb_any(buff->skb);\r\nbuff->skb = NULL;\r\n} while (frames < SLIC_MAX_TX_COMPLETIONS);\r\nsmp_wmb();\r\nu64_stats_update_begin(&sdev->stats.syncp);\r\nsdev->stats.tx_bytes += bytes;\r\nsdev->stats.tx_packets += frames;\r\nu64_stats_update_end(&sdev->stats.syncp);\r\nnetif_tx_lock(dev);\r\nif (netif_queue_stopped(dev) &&\r\n(slic_get_free_tx_descs(txq) >= SLIC_MIN_TX_WAKEUP_DESCS))\r\nnetif_wake_queue(dev);\r\nnetif_tx_unlock(dev);\r\n}\r\nstatic void slic_refill_rx_queue(struct slic_device *sdev, gfp_t gfp)\r\n{\r\nconst unsigned int ALIGN_MASK = SLIC_RX_BUFF_ALIGN - 1;\r\nunsigned int maplen = SLIC_RX_BUFF_SIZE;\r\nstruct slic_rx_queue *rxq = &sdev->rxq;\r\nstruct net_device *dev = sdev->netdev;\r\nstruct slic_rx_buffer *buff;\r\nstruct slic_rx_desc *desc;\r\nunsigned int misalign;\r\nunsigned int offset;\r\nstruct sk_buff *skb;\r\ndma_addr_t paddr;\r\nwhile (slic_get_free_rx_descs(rxq) > SLIC_MAX_REQ_RX_DESCS) {\r\nskb = alloc_skb(maplen + ALIGN_MASK, gfp);\r\nif (!skb)\r\nbreak;\r\npaddr = dma_map_single(&sdev->pdev->dev, skb->data, maplen,\r\nDMA_FROM_DEVICE);\r\nif (dma_mapping_error(&sdev->pdev->dev, paddr)) {\r\nnetdev_err(dev, "mapping rx packet failed\n");\r\ndev_kfree_skb_any(skb);\r\nbreak;\r\n}\r\noffset = 0;\r\nmisalign = paddr & ALIGN_MASK;\r\nif (misalign) {\r\noffset = SLIC_RX_BUFF_ALIGN - misalign;\r\nskb_reserve(skb, offset);\r\n}\r\ndesc = (struct slic_rx_desc *)skb->data;\r\ndma_sync_single_for_cpu(&sdev->pdev->dev, paddr,\r\noffset + sizeof(*desc),\r\nDMA_FROM_DEVICE);\r\ndesc->status = 0;\r\ndma_sync_single_for_device(&sdev->pdev->dev, paddr,\r\noffset + sizeof(*desc),\r\nDMA_FROM_DEVICE);\r\nbuff = &rxq->rxbuffs[rxq->put_idx];\r\nbuff->skb = skb;\r\ndma_unmap_addr_set(buff, map_addr, paddr);\r\ndma_unmap_len_set(buff, map_len, maplen);\r\nbuff->addr_offset = offset;\r\nwmb();\r\nslic_write(sdev, SLIC_REG_HBAR, lower_32_bits(paddr) + offset);\r\nrxq->put_idx = slic_next_queue_idx(rxq->put_idx, rxq->len);\r\n}\r\n}\r\nstatic void slic_handle_frame_error(struct slic_device *sdev,\r\nstruct sk_buff *skb)\r\n{\r\nstruct slic_stats *stats = &sdev->stats;\r\nif (sdev->model == SLIC_MODEL_OASIS) {\r\nstruct slic_rx_info_oasis *info;\r\nu32 status_b;\r\nu32 status;\r\ninfo = (struct slic_rx_info_oasis *)skb->data;\r\nstatus = le32_to_cpu(info->frame_status);\r\nstatus_b = le32_to_cpu(info->frame_status_b);\r\nif (status_b & SLIC_VRHSTATB_TPCSUM)\r\nSLIC_INC_STATS_COUNTER(stats, rx_tpcsum);\r\nif (status & SLIC_VRHSTAT_TPOFLO)\r\nSLIC_INC_STATS_COUNTER(stats, rx_tpoflow);\r\nif (status_b & SLIC_VRHSTATB_TPHLEN)\r\nSLIC_INC_STATS_COUNTER(stats, rx_tphlen);\r\nif (status_b & SLIC_VRHSTATB_IPCSUM)\r\nSLIC_INC_STATS_COUNTER(stats, rx_ipcsum);\r\nif (status_b & SLIC_VRHSTATB_IPLERR)\r\nSLIC_INC_STATS_COUNTER(stats, rx_iplen);\r\nif (status_b & SLIC_VRHSTATB_IPHERR)\r\nSLIC_INC_STATS_COUNTER(stats, rx_iphlen);\r\nif (status_b & SLIC_VRHSTATB_RCVE)\r\nSLIC_INC_STATS_COUNTER(stats, rx_early);\r\nif (status_b & SLIC_VRHSTATB_BUFF)\r\nSLIC_INC_STATS_COUNTER(stats, rx_buffoflow);\r\nif (status_b & SLIC_VRHSTATB_CODE)\r\nSLIC_INC_STATS_COUNTER(stats, rx_lcode);\r\nif (status_b & SLIC_VRHSTATB_DRBL)\r\nSLIC_INC_STATS_COUNTER(stats, rx_drbl);\r\nif (status_b & SLIC_VRHSTATB_CRC)\r\nSLIC_INC_STATS_COUNTER(stats, rx_crc);\r\nif (status & SLIC_VRHSTAT_802OE)\r\nSLIC_INC_STATS_COUNTER(stats, rx_oflow802);\r\nif (status_b & SLIC_VRHSTATB_802UE)\r\nSLIC_INC_STATS_COUNTER(stats, rx_uflow802);\r\nif (status_b & SLIC_VRHSTATB_CARRE)\r\nSLIC_INC_STATS_COUNTER(stats, tx_carrier);\r\n} else {\r\nstruct slic_rx_info_mojave *info;\r\nu32 status;\r\ninfo = (struct slic_rx_info_mojave *)skb->data;\r\nstatus = le32_to_cpu(info->frame_status);\r\nif (status & SLIC_VGBSTAT_XPERR) {\r\nu32 xerr = status >> SLIC_VGBSTAT_XERRSHFT;\r\nif (xerr == SLIC_VGBSTAT_XCSERR)\r\nSLIC_INC_STATS_COUNTER(stats, rx_tpcsum);\r\nif (xerr == SLIC_VGBSTAT_XUFLOW)\r\nSLIC_INC_STATS_COUNTER(stats, rx_tpoflow);\r\nif (xerr == SLIC_VGBSTAT_XHLEN)\r\nSLIC_INC_STATS_COUNTER(stats, rx_tphlen);\r\n}\r\nif (status & SLIC_VGBSTAT_NETERR) {\r\nu32 nerr = status >> SLIC_VGBSTAT_NERRSHFT &\r\nSLIC_VGBSTAT_NERRMSK;\r\nif (nerr == SLIC_VGBSTAT_NCSERR)\r\nSLIC_INC_STATS_COUNTER(stats, rx_ipcsum);\r\nif (nerr == SLIC_VGBSTAT_NUFLOW)\r\nSLIC_INC_STATS_COUNTER(stats, rx_iplen);\r\nif (nerr == SLIC_VGBSTAT_NHLEN)\r\nSLIC_INC_STATS_COUNTER(stats, rx_iphlen);\r\n}\r\nif (status & SLIC_VGBSTAT_LNKERR) {\r\nu32 lerr = status & SLIC_VGBSTAT_LERRMSK;\r\nif (lerr == SLIC_VGBSTAT_LDEARLY)\r\nSLIC_INC_STATS_COUNTER(stats, rx_early);\r\nif (lerr == SLIC_VGBSTAT_LBOFLO)\r\nSLIC_INC_STATS_COUNTER(stats, rx_buffoflow);\r\nif (lerr == SLIC_VGBSTAT_LCODERR)\r\nSLIC_INC_STATS_COUNTER(stats, rx_lcode);\r\nif (lerr == SLIC_VGBSTAT_LDBLNBL)\r\nSLIC_INC_STATS_COUNTER(stats, rx_drbl);\r\nif (lerr == SLIC_VGBSTAT_LCRCERR)\r\nSLIC_INC_STATS_COUNTER(stats, rx_crc);\r\nif (lerr == SLIC_VGBSTAT_LOFLO)\r\nSLIC_INC_STATS_COUNTER(stats, rx_oflow802);\r\nif (lerr == SLIC_VGBSTAT_LUFLO)\r\nSLIC_INC_STATS_COUNTER(stats, rx_uflow802);\r\n}\r\n}\r\nSLIC_INC_STATS_COUNTER(stats, rx_errors);\r\n}\r\nstatic void slic_handle_receive(struct slic_device *sdev, unsigned int todo,\r\nunsigned int *done)\r\n{\r\nstruct slic_rx_queue *rxq = &sdev->rxq;\r\nstruct net_device *dev = sdev->netdev;\r\nstruct slic_rx_buffer *buff;\r\nstruct slic_rx_desc *desc;\r\nunsigned int frames = 0;\r\nunsigned int bytes = 0;\r\nstruct sk_buff *skb;\r\nu32 status;\r\nu32 len;\r\nwhile (todo && (rxq->done_idx != rxq->put_idx)) {\r\nbuff = &rxq->rxbuffs[rxq->done_idx];\r\nskb = buff->skb;\r\nif (!skb)\r\nbreak;\r\ndesc = (struct slic_rx_desc *)skb->data;\r\ndma_sync_single_for_cpu(&sdev->pdev->dev,\r\ndma_unmap_addr(buff, map_addr),\r\nbuff->addr_offset + sizeof(*desc),\r\nDMA_FROM_DEVICE);\r\nstatus = le32_to_cpu(desc->status);\r\nif (!(status & SLIC_IRHDDR_SVALID)) {\r\ndma_sync_single_for_device(&sdev->pdev->dev,\r\ndma_unmap_addr(buff,\r\nmap_addr),\r\nbuff->addr_offset +\r\nsizeof(*desc),\r\nDMA_FROM_DEVICE);\r\nbreak;\r\n}\r\nbuff->skb = NULL;\r\ndma_unmap_single(&sdev->pdev->dev,\r\ndma_unmap_addr(buff, map_addr),\r\ndma_unmap_len(buff, map_len),\r\nDMA_FROM_DEVICE);\r\nskb_reserve(skb, SLIC_RX_BUFF_HDR_SIZE);\r\nif (unlikely(status & SLIC_IRHDDR_ERR)) {\r\nslic_handle_frame_error(sdev, skb);\r\ndev_kfree_skb_any(skb);\r\n} else {\r\nstruct ethhdr *eh = (struct ethhdr *)skb->data;\r\nif (is_multicast_ether_addr(eh->h_dest))\r\nSLIC_INC_STATS_COUNTER(&sdev->stats, rx_mcasts);\r\nlen = le32_to_cpu(desc->length) & SLIC_IRHDDR_FLEN_MSK;\r\nskb_put(skb, len);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nnapi_gro_receive(&sdev->napi, skb);\r\nbytes += len;\r\nframes++;\r\n}\r\nrxq->done_idx = slic_next_queue_idx(rxq->done_idx, rxq->len);\r\ntodo--;\r\n}\r\nu64_stats_update_begin(&sdev->stats.syncp);\r\nsdev->stats.rx_bytes += bytes;\r\nsdev->stats.rx_packets += frames;\r\nu64_stats_update_end(&sdev->stats.syncp);\r\nslic_refill_rx_queue(sdev, GFP_ATOMIC);\r\n}\r\nstatic void slic_handle_link_irq(struct slic_device *sdev)\r\n{\r\nstruct slic_shmem *sm = &sdev->shmem;\r\nstruct slic_shmem_data *sm_data = sm->shmem_data;\r\nunsigned int duplex;\r\nint speed;\r\nu32 link;\r\nlink = le32_to_cpu(sm_data->link);\r\nif (link & SLIC_GIG_LINKUP) {\r\nif (link & SLIC_GIG_SPEED_1000)\r\nspeed = SPEED_1000;\r\nelse if (link & SLIC_GIG_SPEED_100)\r\nspeed = SPEED_100;\r\nelse\r\nspeed = SPEED_10;\r\nduplex = (link & SLIC_GIG_FULLDUPLEX) ? DUPLEX_FULL :\r\nDUPLEX_HALF;\r\n} else {\r\nduplex = DUPLEX_UNKNOWN;\r\nspeed = SPEED_UNKNOWN;\r\n}\r\nslic_configure_link(sdev, speed, duplex);\r\n}\r\nstatic void slic_handle_upr_irq(struct slic_device *sdev, u32 irqs)\r\n{\r\nstruct slic_upr *upr;\r\nupr = slic_dequeue_upr(sdev);\r\nif (!upr) {\r\nnetdev_warn(sdev->netdev, "no upr found on list\n");\r\nreturn;\r\n}\r\nif (upr->type == SLIC_UPR_LSTAT) {\r\nif (unlikely(irqs & SLIC_ISR_UPCERR_MASK)) {\r\nslic_queue_upr(sdev, upr);\r\nreturn;\r\n}\r\nslic_handle_link_irq(sdev);\r\n}\r\nkfree(upr);\r\n}\r\nstatic int slic_handle_link_change(struct slic_device *sdev)\r\n{\r\nreturn slic_new_upr(sdev, SLIC_UPR_LSTAT, sdev->shmem.link_paddr);\r\n}\r\nstatic void slic_handle_err_irq(struct slic_device *sdev, u32 isr)\r\n{\r\nstruct slic_stats *stats = &sdev->stats;\r\nif (isr & SLIC_ISR_RMISS)\r\nSLIC_INC_STATS_COUNTER(stats, rx_buff_miss);\r\nif (isr & SLIC_ISR_XDROP)\r\nSLIC_INC_STATS_COUNTER(stats, tx_dropped);\r\nif (!(isr & (SLIC_ISR_RMISS | SLIC_ISR_XDROP)))\r\nSLIC_INC_STATS_COUNTER(stats, irq_errs);\r\n}\r\nstatic void slic_handle_irq(struct slic_device *sdev, u32 isr,\r\nunsigned int todo, unsigned int *done)\r\n{\r\nif (isr & SLIC_ISR_ERR)\r\nslic_handle_err_irq(sdev, isr);\r\nif (isr & SLIC_ISR_LEVENT)\r\nslic_handle_link_change(sdev);\r\nif (isr & SLIC_ISR_UPC_MASK)\r\nslic_handle_upr_irq(sdev, isr);\r\nif (isr & SLIC_ISR_RCV)\r\nslic_handle_receive(sdev, todo, done);\r\nif (isr & SLIC_ISR_CMD)\r\nslic_xmit_complete(sdev);\r\n}\r\nstatic int slic_poll(struct napi_struct *napi, int todo)\r\n{\r\nstruct slic_device *sdev = container_of(napi, struct slic_device, napi);\r\nstruct slic_shmem *sm = &sdev->shmem;\r\nstruct slic_shmem_data *sm_data = sm->shmem_data;\r\nu32 isr = le32_to_cpu(sm_data->isr);\r\nint done = 0;\r\nslic_handle_irq(sdev, isr, todo, &done);\r\nif (done < todo) {\r\nnapi_complete_done(napi, done);\r\nsm_data->isr = 0;\r\nwmb();\r\nslic_write(sdev, SLIC_REG_ISR, 0);\r\nslic_flush_write(sdev);\r\n}\r\nreturn done;\r\n}\r\nstatic irqreturn_t slic_irq(int irq, void *dev_id)\r\n{\r\nstruct slic_device *sdev = dev_id;\r\nstruct slic_shmem *sm = &sdev->shmem;\r\nstruct slic_shmem_data *sm_data = sm->shmem_data;\r\nslic_write(sdev, SLIC_REG_ICR, SLIC_ICR_INT_MASK);\r\nslic_flush_write(sdev);\r\nwmb();\r\nif (!sm_data->isr) {\r\ndma_rmb();\r\nslic_write(sdev, SLIC_REG_ISR, 0);\r\nslic_flush_write(sdev);\r\nreturn IRQ_NONE;\r\n}\r\nnapi_schedule_irqoff(&sdev->napi);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void slic_card_reset(struct slic_device *sdev)\r\n{\r\nu16 cmd;\r\nslic_write(sdev, SLIC_REG_RESET, SLIC_RESET_MAGIC);\r\npci_read_config_word(sdev->pdev, PCI_COMMAND, &cmd);\r\nmdelay(1);\r\n}\r\nstatic int slic_init_stat_queue(struct slic_device *sdev)\r\n{\r\nconst unsigned int DESC_ALIGN_MASK = SLIC_STATS_DESC_ALIGN - 1;\r\nstruct slic_stat_queue *stq = &sdev->stq;\r\nstruct slic_stat_desc *descs;\r\nunsigned int misalign;\r\nunsigned int offset;\r\ndma_addr_t paddr;\r\nsize_t size;\r\nint err;\r\nint i;\r\nstq->len = SLIC_NUM_STAT_DESCS;\r\nstq->active_array = 0;\r\nstq->done_idx = 0;\r\nsize = stq->len * sizeof(*descs) + DESC_ALIGN_MASK;\r\nfor (i = 0; i < SLIC_NUM_STAT_DESC_ARRAYS; i++) {\r\ndescs = dma_zalloc_coherent(&sdev->pdev->dev, size, &paddr,\r\nGFP_KERNEL);\r\nif (!descs) {\r\nnetdev_err(sdev->netdev,\r\n"failed to allocate status descriptors\n");\r\nerr = -ENOMEM;\r\ngoto free_descs;\r\n}\r\noffset = 0;\r\nmisalign = paddr & DESC_ALIGN_MASK;\r\nif (misalign) {\r\noffset = SLIC_STATS_DESC_ALIGN - misalign;\r\ndescs += offset;\r\npaddr += offset;\r\n}\r\nslic_write(sdev, SLIC_REG_RBAR, lower_32_bits(paddr) |\r\nstq->len);\r\nstq->descs[i] = descs;\r\nstq->paddr[i] = paddr;\r\nstq->addr_offset[i] = offset;\r\n}\r\nstq->mem_size = size;\r\nreturn 0;\r\nfree_descs:\r\nwhile (i--) {\r\ndma_free_coherent(&sdev->pdev->dev, stq->mem_size,\r\nstq->descs[i] - stq->addr_offset[i],\r\nstq->paddr[i] - stq->addr_offset[i]);\r\n}\r\nreturn err;\r\n}\r\nstatic void slic_free_stat_queue(struct slic_device *sdev)\r\n{\r\nstruct slic_stat_queue *stq = &sdev->stq;\r\nint i;\r\nfor (i = 0; i < SLIC_NUM_STAT_DESC_ARRAYS; i++) {\r\ndma_free_coherent(&sdev->pdev->dev, stq->mem_size,\r\nstq->descs[i] - stq->addr_offset[i],\r\nstq->paddr[i] - stq->addr_offset[i]);\r\n}\r\n}\r\nstatic int slic_init_tx_queue(struct slic_device *sdev)\r\n{\r\nstruct slic_tx_queue *txq = &sdev->txq;\r\nstruct slic_tx_buffer *buff;\r\nstruct slic_tx_desc *desc;\r\nunsigned int i;\r\nint err;\r\ntxq->len = SLIC_NUM_TX_DESCS;\r\ntxq->put_idx = 0;\r\ntxq->done_idx = 0;\r\ntxq->txbuffs = kcalloc(txq->len, sizeof(*buff), GFP_KERNEL);\r\nif (!txq->txbuffs)\r\nreturn -ENOMEM;\r\ntxq->dma_pool = dma_pool_create("slic_pool", &sdev->pdev->dev,\r\nsizeof(*desc), SLIC_TX_DESC_ALIGN,\r\n4096);\r\nif (!txq->dma_pool) {\r\nerr = -ENOMEM;\r\nnetdev_err(sdev->netdev, "failed to create dma pool\n");\r\ngoto free_buffs;\r\n}\r\nfor (i = 0; i < txq->len; i++) {\r\nbuff = &txq->txbuffs[i];\r\ndesc = dma_pool_zalloc(txq->dma_pool, GFP_KERNEL,\r\n&buff->desc_paddr);\r\nif (!desc) {\r\nnetdev_err(sdev->netdev,\r\n"failed to alloc pool chunk (%i)\n", i);\r\nerr = -ENOMEM;\r\ngoto free_descs;\r\n}\r\ndesc->hnd = cpu_to_le32((u32)(i + 1));\r\ndesc->cmd = SLIC_CMD_XMT_REQ;\r\ndesc->flags = 0;\r\ndesc->type = cpu_to_le32(SLIC_CMD_TYPE_DUMB);\r\nbuff->desc = desc;\r\n}\r\nreturn 0;\r\nfree_descs:\r\nwhile (i--) {\r\nbuff = &txq->txbuffs[i];\r\ndma_pool_free(txq->dma_pool, buff->desc, buff->desc_paddr);\r\n}\r\ndma_pool_destroy(txq->dma_pool);\r\nfree_buffs:\r\nkfree(txq->txbuffs);\r\nreturn err;\r\n}\r\nstatic void slic_free_tx_queue(struct slic_device *sdev)\r\n{\r\nstruct slic_tx_queue *txq = &sdev->txq;\r\nstruct slic_tx_buffer *buff;\r\nunsigned int i;\r\nfor (i = 0; i < txq->len; i++) {\r\nbuff = &txq->txbuffs[i];\r\ndma_pool_free(txq->dma_pool, buff->desc, buff->desc_paddr);\r\nif (!buff->skb)\r\ncontinue;\r\ndma_unmap_single(&sdev->pdev->dev,\r\ndma_unmap_addr(buff, map_addr),\r\ndma_unmap_len(buff, map_len), DMA_TO_DEVICE);\r\nconsume_skb(buff->skb);\r\n}\r\ndma_pool_destroy(txq->dma_pool);\r\nkfree(txq->txbuffs);\r\n}\r\nstatic int slic_init_rx_queue(struct slic_device *sdev)\r\n{\r\nstruct slic_rx_queue *rxq = &sdev->rxq;\r\nstruct slic_rx_buffer *buff;\r\nrxq->len = SLIC_NUM_RX_LES;\r\nrxq->done_idx = 0;\r\nrxq->put_idx = 0;\r\nbuff = kcalloc(rxq->len, sizeof(*buff), GFP_KERNEL);\r\nif (!buff)\r\nreturn -ENOMEM;\r\nrxq->rxbuffs = buff;\r\nslic_refill_rx_queue(sdev, GFP_KERNEL);\r\nreturn 0;\r\n}\r\nstatic void slic_free_rx_queue(struct slic_device *sdev)\r\n{\r\nstruct slic_rx_queue *rxq = &sdev->rxq;\r\nstruct slic_rx_buffer *buff;\r\nunsigned int i;\r\nfor (i = 0; i < rxq->len; i++) {\r\nbuff = &rxq->rxbuffs[i];\r\nif (!buff->skb)\r\ncontinue;\r\ndma_unmap_single(&sdev->pdev->dev,\r\ndma_unmap_addr(buff, map_addr),\r\ndma_unmap_len(buff, map_len),\r\nDMA_FROM_DEVICE);\r\nconsume_skb(buff->skb);\r\n}\r\nkfree(rxq->rxbuffs);\r\n}\r\nstatic void slic_set_link_autoneg(struct slic_device *sdev)\r\n{\r\nunsigned int subid = sdev->pdev->subsystem_device;\r\nu32 val;\r\nif (sdev->is_fiber) {\r\nval = MII_ADVERTISE << 16 | ADVERTISE_1000XFULL |\r\nADVERTISE_1000XPAUSE | ADVERTISE_1000XPSE_ASYM;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\nval = MII_BMCR << 16 | BMCR_RESET | BMCR_ANENABLE |\r\nBMCR_ANRESTART;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\n} else {\r\nval = MII_ADVERTISE << 16 | ADVERTISE_100FULL |\r\nADVERTISE_100HALF | ADVERTISE_10FULL | ADVERTISE_10HALF;\r\nval |= ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM;\r\nval |= ADVERTISE_CSMA;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\nval = MII_CTRL1000 << 16 | ADVERTISE_1000FULL;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\nif (subid != PCI_SUBDEVICE_ID_ALACRITECH_CICADA) {\r\nval = SLIC_MIICR_REG_16 | SLIC_MRV_REG16_XOVERON;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\nval = MII_BMCR << 16 | BMCR_RESET | BMCR_ANENABLE |\r\nBMCR_ANRESTART;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\n} else {\r\nval = MII_BMCR << 16 | BMCR_ANENABLE | BMCR_ANRESTART;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\n}\r\n}\r\n}\r\nstatic void slic_set_mac_address(struct slic_device *sdev)\r\n{\r\nu8 *addr = sdev->netdev->dev_addr;\r\nu32 val;\r\nval = addr[5] | addr[4] << 8 | addr[3] << 16 | addr[2] << 24;\r\nslic_write(sdev, SLIC_REG_WRADDRAL, val);\r\nslic_write(sdev, SLIC_REG_WRADDRBL, val);\r\nval = addr[0] << 8 | addr[1];\r\nslic_write(sdev, SLIC_REG_WRADDRAH, val);\r\nslic_write(sdev, SLIC_REG_WRADDRBH, val);\r\nslic_flush_write(sdev);\r\n}\r\nstatic u32 slic_read_dword_from_firmware(const struct firmware *fw, int *offset)\r\n{\r\nint idx = *offset;\r\n__le32 val;\r\nmemcpy(&val, fw->data + *offset, sizeof(val));\r\nidx += 4;\r\n*offset = idx;\r\nreturn le32_to_cpu(val);\r\n}\r\nstatic int slic_load_rcvseq_firmware(struct slic_device *sdev)\r\n{\r\nconst struct firmware *fw;\r\nconst char *file;\r\nu32 codelen;\r\nint idx = 0;\r\nu32 instr;\r\nu32 addr;\r\nint err;\r\nfile = (sdev->model == SLIC_MODEL_OASIS) ? SLIC_RCV_FIRMWARE_OASIS :\r\nSLIC_RCV_FIRMWARE_MOJAVE;\r\nerr = request_firmware(&fw, file, &sdev->pdev->dev);\r\nif (err) {\r\ndev_err(&sdev->pdev->dev,\r\n"failed to load receive sequencer firmware %s\n", file);\r\nreturn err;\r\n}\r\nif (fw->size < SLIC_FIRMWARE_MIN_SIZE) {\r\ndev_err(&sdev->pdev->dev,\r\n"invalid firmware size %zu (min %u expected)\n",\r\nfw->size, SLIC_FIRMWARE_MIN_SIZE);\r\nerr = -EINVAL;\r\ngoto release;\r\n}\r\ncodelen = slic_read_dword_from_firmware(fw, &idx);\r\nif ((codelen + 4) > fw->size) {\r\ndev_err(&sdev->pdev->dev,\r\n"invalid rcv-sequencer firmware size %zu\n", fw->size);\r\nerr = -EINVAL;\r\ngoto release;\r\n}\r\nslic_write(sdev, SLIC_REG_RCV_WCS, SLIC_RCVWCS_BEGIN);\r\nfor (addr = 0; addr < codelen; addr++) {\r\n__le32 val;\r\nslic_write(sdev, SLIC_REG_RCV_WCS, addr);\r\ninstr = slic_read_dword_from_firmware(fw, &idx);\r\nslic_write(sdev, SLIC_REG_RCV_WCS, instr);\r\nval = (__le32)fw->data[idx];\r\ninstr = le32_to_cpu(val);\r\nidx++;\r\nslic_write(sdev, SLIC_REG_RCV_WCS, instr);\r\n}\r\nslic_write(sdev, SLIC_REG_RCV_WCS, SLIC_RCVWCS_FINISH);\r\nslic_flush_write(sdev);\r\nrelease:\r\nrelease_firmware(fw);\r\nreturn err;\r\n}\r\nstatic int slic_load_firmware(struct slic_device *sdev)\r\n{\r\nu32 sectstart[SLIC_FIRMWARE_MAX_SECTIONS];\r\nu32 sectsize[SLIC_FIRMWARE_MAX_SECTIONS];\r\nconst struct firmware *fw;\r\nunsigned int datalen;\r\nconst char *file;\r\nint code_start;\r\nunsigned int i;\r\nu32 numsects;\r\nint idx = 0;\r\nu32 sect;\r\nu32 instr;\r\nu32 addr;\r\nu32 base;\r\nint err;\r\nfile = (sdev->model == SLIC_MODEL_OASIS) ? SLIC_FIRMWARE_OASIS :\r\nSLIC_FIRMWARE_MOJAVE;\r\nerr = request_firmware(&fw, file, &sdev->pdev->dev);\r\nif (err) {\r\ndev_err(&sdev->pdev->dev, "failed to load firmware %s\n", file);\r\nreturn err;\r\n}\r\nif (fw->size < SLIC_FIRMWARE_MIN_SIZE) {\r\ndev_err(&sdev->pdev->dev,\r\n"invalid firmware size %zu (min is %u)\n", fw->size,\r\nSLIC_FIRMWARE_MIN_SIZE);\r\nerr = -EINVAL;\r\ngoto release;\r\n}\r\nnumsects = slic_read_dword_from_firmware(fw, &idx);\r\nif (numsects == 0 || numsects > SLIC_FIRMWARE_MAX_SECTIONS) {\r\ndev_err(&sdev->pdev->dev,\r\n"invalid number of sections in firmware: %u", numsects);\r\nerr = -EINVAL;\r\ngoto release;\r\n}\r\ndatalen = numsects * 8 + 4;\r\nfor (i = 0; i < numsects; i++) {\r\nsectsize[i] = slic_read_dword_from_firmware(fw, &idx);\r\ndatalen += sectsize[i];\r\n}\r\nif (datalen > fw->size) {\r\ndev_err(&sdev->pdev->dev,\r\n"invalid firmware size %zu (expected >= %u)\n",\r\nfw->size, datalen);\r\nerr = -EINVAL;\r\ngoto release;\r\n}\r\nfor (i = 0; i < numsects; i++)\r\nsectstart[i] = slic_read_dword_from_firmware(fw, &idx);\r\ncode_start = idx;\r\ninstr = slic_read_dword_from_firmware(fw, &idx);\r\nfor (sect = 0; sect < numsects; sect++) {\r\nunsigned int ssize = sectsize[sect] >> 3;\r\nbase = sectstart[sect];\r\nfor (addr = 0; addr < ssize; addr++) {\r\nslic_write(sdev, SLIC_REG_WCS, base + addr);\r\nslic_write(sdev, SLIC_REG_WCS, instr);\r\ninstr = slic_read_dword_from_firmware(fw, &idx);\r\nslic_write(sdev, SLIC_REG_WCS, instr);\r\ninstr = slic_read_dword_from_firmware(fw, &idx);\r\n}\r\n}\r\nidx = code_start;\r\nfor (sect = 0; sect < numsects; sect++) {\r\nunsigned int ssize = sectsize[sect] >> 3;\r\ninstr = slic_read_dword_from_firmware(fw, &idx);\r\nbase = sectstart[sect];\r\nif (base < 0x8000)\r\ncontinue;\r\nfor (addr = 0; addr < ssize; addr++) {\r\nslic_write(sdev, SLIC_REG_WCS,\r\nSLIC_WCS_COMPARE | (base + addr));\r\nslic_write(sdev, SLIC_REG_WCS, instr);\r\ninstr = slic_read_dword_from_firmware(fw, &idx);\r\nslic_write(sdev, SLIC_REG_WCS, instr);\r\ninstr = slic_read_dword_from_firmware(fw, &idx);\r\n}\r\n}\r\nslic_flush_write(sdev);\r\nmdelay(10);\r\nslic_write(sdev, SLIC_REG_WCS, SLIC_WCS_START);\r\nslic_flush_write(sdev);\r\nmdelay(20);\r\nrelease:\r\nrelease_firmware(fw);\r\nreturn err;\r\n}\r\nstatic int slic_init_shmem(struct slic_device *sdev)\r\n{\r\nstruct slic_shmem *sm = &sdev->shmem;\r\nstruct slic_shmem_data *sm_data;\r\ndma_addr_t paddr;\r\nsm_data = dma_zalloc_coherent(&sdev->pdev->dev, sizeof(*sm_data),\r\n&paddr, GFP_KERNEL);\r\nif (!sm_data) {\r\ndev_err(&sdev->pdev->dev, "failed to allocate shared memory\n");\r\nreturn -ENOMEM;\r\n}\r\nsm->shmem_data = sm_data;\r\nsm->isr_paddr = paddr;\r\nsm->link_paddr = paddr + offsetof(struct slic_shmem_data, link);\r\nreturn 0;\r\n}\r\nstatic void slic_free_shmem(struct slic_device *sdev)\r\n{\r\nstruct slic_shmem *sm = &sdev->shmem;\r\nstruct slic_shmem_data *sm_data = sm->shmem_data;\r\ndma_free_coherent(&sdev->pdev->dev, sizeof(*sm_data), sm_data,\r\nsm->isr_paddr);\r\n}\r\nstatic int slic_init_iface(struct slic_device *sdev)\r\n{\r\nstruct slic_shmem *sm = &sdev->shmem;\r\nint err;\r\nsdev->upr_list.pending = false;\r\nerr = slic_init_shmem(sdev);\r\nif (err) {\r\nnetdev_err(sdev->netdev, "failed to init shared memory\n");\r\nreturn err;\r\n}\r\nerr = slic_load_firmware(sdev);\r\nif (err) {\r\nnetdev_err(sdev->netdev, "failed to load firmware\n");\r\ngoto free_sm;\r\n}\r\nerr = slic_load_rcvseq_firmware(sdev);\r\nif (err) {\r\nnetdev_err(sdev->netdev,\r\n"failed to load firmware for receive sequencer\n");\r\ngoto free_sm;\r\n}\r\nslic_write(sdev, SLIC_REG_ICR, SLIC_ICR_INT_OFF);\r\nslic_flush_write(sdev);\r\nmdelay(1);\r\nerr = slic_init_rx_queue(sdev);\r\nif (err) {\r\nnetdev_err(sdev->netdev, "failed to init rx queue: %u\n", err);\r\ngoto free_sm;\r\n}\r\nerr = slic_init_tx_queue(sdev);\r\nif (err) {\r\nnetdev_err(sdev->netdev, "failed to init tx queue: %u\n", err);\r\ngoto free_rxq;\r\n}\r\nerr = slic_init_stat_queue(sdev);\r\nif (err) {\r\nnetdev_err(sdev->netdev, "failed to init status queue: %u\n",\r\nerr);\r\ngoto free_txq;\r\n}\r\nslic_write(sdev, SLIC_REG_ISP, lower_32_bits(sm->isr_paddr));\r\nnapi_enable(&sdev->napi);\r\nslic_write(sdev, SLIC_REG_INTAGG, 0);\r\nslic_write(sdev, SLIC_REG_ISR, 0);\r\nslic_flush_write(sdev);\r\nslic_set_mac_address(sdev);\r\nspin_lock_bh(&sdev->link_lock);\r\nsdev->duplex = DUPLEX_UNKNOWN;\r\nsdev->speed = SPEED_UNKNOWN;\r\nspin_unlock_bh(&sdev->link_lock);\r\nslic_set_link_autoneg(sdev);\r\nerr = request_irq(sdev->pdev->irq, slic_irq, IRQF_SHARED, DRV_NAME,\r\nsdev);\r\nif (err) {\r\nnetdev_err(sdev->netdev, "failed to request irq: %u\n", err);\r\ngoto disable_napi;\r\n}\r\nslic_write(sdev, SLIC_REG_ICR, SLIC_ICR_INT_ON);\r\nslic_flush_write(sdev);\r\nerr = slic_handle_link_change(sdev);\r\nif (err)\r\nnetdev_warn(sdev->netdev,\r\n"failed to set initial link state: %u\n", err);\r\nreturn 0;\r\ndisable_napi:\r\nnapi_disable(&sdev->napi);\r\nslic_free_stat_queue(sdev);\r\nfree_txq:\r\nslic_free_tx_queue(sdev);\r\nfree_rxq:\r\nslic_free_rx_queue(sdev);\r\nfree_sm:\r\nslic_free_shmem(sdev);\r\nslic_card_reset(sdev);\r\nreturn err;\r\n}\r\nstatic int slic_open(struct net_device *dev)\r\n{\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nint err;\r\nnetif_carrier_off(dev);\r\nerr = slic_init_iface(sdev);\r\nif (err) {\r\nnetdev_err(dev, "failed to initialize interface: %i\n", err);\r\nreturn err;\r\n}\r\nnetif_start_queue(dev);\r\nreturn 0;\r\n}\r\nstatic int slic_close(struct net_device *dev)\r\n{\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nu32 val;\r\nnetif_stop_queue(dev);\r\nnapi_disable(&sdev->napi);\r\nslic_write(sdev, SLIC_REG_ICR, SLIC_ICR_INT_OFF);\r\nslic_write(sdev, SLIC_REG_ISR, 0);\r\nslic_flush_write(sdev);\r\nfree_irq(sdev->pdev->irq, sdev);\r\nval = SLIC_GXCR_RESET | SLIC_GXCR_PAUSEEN;\r\nslic_write(sdev, SLIC_REG_WXCFG, val);\r\nval = SLIC_GRCR_RESET | SLIC_GRCR_CTLEN | SLIC_GRCR_ADDRAEN |\r\nSLIC_GRCR_HASHSIZE << SLIC_GRCR_HASHSIZE_SHIFT;\r\nslic_write(sdev, SLIC_REG_WRCFG, val);\r\nval = MII_BMCR << 16 | BMCR_PDOWN;\r\nslic_write(sdev, SLIC_REG_WPHY, val);\r\nslic_flush_write(sdev);\r\nslic_clear_upr_list(&sdev->upr_list);\r\nslic_write(sdev, SLIC_REG_QUIESCE, 0);\r\nslic_free_stat_queue(sdev);\r\nslic_free_tx_queue(sdev);\r\nslic_free_rx_queue(sdev);\r\nslic_free_shmem(sdev);\r\nslic_card_reset(sdev);\r\nnetif_carrier_off(dev);\r\nreturn 0;\r\n}\r\nstatic netdev_tx_t slic_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nstruct slic_tx_queue *txq = &sdev->txq;\r\nstruct slic_tx_buffer *buff;\r\nstruct slic_tx_desc *desc;\r\ndma_addr_t paddr;\r\nu32 cbar_val;\r\nu32 maplen;\r\nif (unlikely(slic_get_free_tx_descs(txq) < SLIC_MAX_REQ_TX_DESCS)) {\r\nnetdev_err(dev, "BUG! not enough tx LEs left: %u\n",\r\nslic_get_free_tx_descs(txq));\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nmaplen = skb_headlen(skb);\r\npaddr = dma_map_single(&sdev->pdev->dev, skb->data, maplen,\r\nDMA_TO_DEVICE);\r\nif (dma_mapping_error(&sdev->pdev->dev, paddr)) {\r\nnetdev_err(dev, "failed to map tx buffer\n");\r\ngoto drop_skb;\r\n}\r\nbuff = &txq->txbuffs[txq->put_idx];\r\nbuff->skb = skb;\r\ndma_unmap_addr_set(buff, map_addr, paddr);\r\ndma_unmap_len_set(buff, map_len, maplen);\r\ndesc = buff->desc;\r\ndesc->totlen = cpu_to_le32(maplen);\r\ndesc->paddrl = cpu_to_le32(lower_32_bits(paddr));\r\ndesc->paddrh = cpu_to_le32(upper_32_bits(paddr));\r\ndesc->len = cpu_to_le32(maplen);\r\ntxq->put_idx = slic_next_queue_idx(txq->put_idx, txq->len);\r\ncbar_val = lower_32_bits(buff->desc_paddr) | 1;\r\nwmb();\r\nslic_write(sdev, SLIC_REG_CBAR, cbar_val);\r\nif (slic_get_free_tx_descs(txq) < SLIC_MAX_REQ_TX_DESCS)\r\nnetif_stop_queue(dev);\r\nmmiowb();\r\nreturn NETDEV_TX_OK;\r\ndrop_skb:\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void slic_get_stats(struct net_device *dev,\r\nstruct rtnl_link_stats64 *lst)\r\n{\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nstruct slic_stats *stats = &sdev->stats;\r\nSLIC_GET_STATS_COUNTER(lst->rx_packets, stats, rx_packets);\r\nSLIC_GET_STATS_COUNTER(lst->tx_packets, stats, tx_packets);\r\nSLIC_GET_STATS_COUNTER(lst->rx_bytes, stats, rx_bytes);\r\nSLIC_GET_STATS_COUNTER(lst->tx_bytes, stats, tx_bytes);\r\nSLIC_GET_STATS_COUNTER(lst->rx_errors, stats, rx_errors);\r\nSLIC_GET_STATS_COUNTER(lst->rx_dropped, stats, rx_buff_miss);\r\nSLIC_GET_STATS_COUNTER(lst->tx_dropped, stats, tx_dropped);\r\nSLIC_GET_STATS_COUNTER(lst->multicast, stats, rx_mcasts);\r\nSLIC_GET_STATS_COUNTER(lst->rx_over_errors, stats, rx_buffoflow);\r\nSLIC_GET_STATS_COUNTER(lst->rx_crc_errors, stats, rx_crc);\r\nSLIC_GET_STATS_COUNTER(lst->rx_fifo_errors, stats, rx_oflow802);\r\nSLIC_GET_STATS_COUNTER(lst->tx_carrier_errors, stats, tx_carrier);\r\n}\r\nstatic int slic_get_sset_count(struct net_device *dev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn ARRAY_SIZE(slic_stats_strings);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void slic_get_ethtool_stats(struct net_device *dev,\r\nstruct ethtool_stats *eth_stats, u64 *data)\r\n{\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nstruct slic_stats *stats = &sdev->stats;\r\nSLIC_GET_STATS_COUNTER(data[0], stats, rx_packets);\r\nSLIC_GET_STATS_COUNTER(data[1], stats, rx_bytes);\r\nSLIC_GET_STATS_COUNTER(data[2], stats, rx_mcasts);\r\nSLIC_GET_STATS_COUNTER(data[3], stats, rx_errors);\r\nSLIC_GET_STATS_COUNTER(data[4], stats, rx_buff_miss);\r\nSLIC_GET_STATS_COUNTER(data[5], stats, rx_tpcsum);\r\nSLIC_GET_STATS_COUNTER(data[6], stats, rx_tpoflow);\r\nSLIC_GET_STATS_COUNTER(data[7], stats, rx_tphlen);\r\nSLIC_GET_STATS_COUNTER(data[8], stats, rx_ipcsum);\r\nSLIC_GET_STATS_COUNTER(data[9], stats, rx_iplen);\r\nSLIC_GET_STATS_COUNTER(data[10], stats, rx_iphlen);\r\nSLIC_GET_STATS_COUNTER(data[11], stats, rx_early);\r\nSLIC_GET_STATS_COUNTER(data[12], stats, rx_buffoflow);\r\nSLIC_GET_STATS_COUNTER(data[13], stats, rx_lcode);\r\nSLIC_GET_STATS_COUNTER(data[14], stats, rx_drbl);\r\nSLIC_GET_STATS_COUNTER(data[15], stats, rx_crc);\r\nSLIC_GET_STATS_COUNTER(data[16], stats, rx_oflow802);\r\nSLIC_GET_STATS_COUNTER(data[17], stats, rx_uflow802);\r\nSLIC_GET_STATS_COUNTER(data[18], stats, tx_packets);\r\nSLIC_GET_STATS_COUNTER(data[19], stats, tx_bytes);\r\nSLIC_GET_STATS_COUNTER(data[20], stats, tx_carrier);\r\nSLIC_GET_STATS_COUNTER(data[21], stats, tx_dropped);\r\nSLIC_GET_STATS_COUNTER(data[22], stats, irq_errs);\r\n}\r\nstatic void slic_get_strings(struct net_device *dev, u32 stringset, u8 *data)\r\n{\r\nif (stringset == ETH_SS_STATS) {\r\nmemcpy(data, slic_stats_strings, sizeof(slic_stats_strings));\r\ndata += sizeof(slic_stats_strings);\r\n}\r\n}\r\nstatic void slic_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(sdev->pdev), sizeof(info->bus_info));\r\n}\r\nstatic u16 slic_eeprom_csum(unsigned char *eeprom, unsigned int len)\r\n{\r\nunsigned char *ptr = eeprom;\r\nu32 csum = 0;\r\n__le16 data;\r\nwhile (len > 1) {\r\nmemcpy(&data, ptr, sizeof(data));\r\ncsum += le16_to_cpu(data);\r\nptr += 2;\r\nlen -= 2;\r\n}\r\nif (len > 0)\r\ncsum += *(u8 *)ptr;\r\nwhile (csum >> 16)\r\ncsum = (csum & 0xFFFF) + ((csum >> 16) & 0xFFFF);\r\nreturn ~csum;\r\n}\r\nstatic bool slic_eeprom_valid(unsigned char *eeprom, unsigned int size)\r\n{\r\nconst unsigned int MAX_SIZE = 128;\r\nconst unsigned int MIN_SIZE = 98;\r\n__le16 magic;\r\n__le16 csum;\r\nif (size < MIN_SIZE || size > MAX_SIZE)\r\nreturn false;\r\nmemcpy(&magic, eeprom, sizeof(magic));\r\nif (le16_to_cpu(magic) != SLIC_EEPROM_MAGIC)\r\nreturn false;\r\nsize -= 2;\r\nmemcpy(&csum, eeprom + size, sizeof(csum));\r\nreturn (le16_to_cpu(csum) == slic_eeprom_csum(eeprom, size));\r\n}\r\nstatic int slic_read_eeprom(struct slic_device *sdev)\r\n{\r\nunsigned int devfn = PCI_FUNC(sdev->pdev->devfn);\r\nstruct slic_shmem *sm = &sdev->shmem;\r\nstruct slic_shmem_data *sm_data = sm->shmem_data;\r\nconst unsigned int MAX_LOOPS = 5000;\r\nunsigned int codesize;\r\nunsigned char *eeprom;\r\nstruct slic_upr *upr;\r\nunsigned int i = 0;\r\ndma_addr_t paddr;\r\nint err = 0;\r\nu8 *mac[2];\r\neeprom = dma_zalloc_coherent(&sdev->pdev->dev, SLIC_EEPROM_SIZE,\r\n&paddr, GFP_KERNEL);\r\nif (!eeprom)\r\nreturn -ENOMEM;\r\nslic_write(sdev, SLIC_REG_ICR, SLIC_ICR_INT_OFF);\r\nslic_write(sdev, SLIC_REG_ISP, lower_32_bits(sm->isr_paddr));\r\nerr = slic_new_upr(sdev, SLIC_UPR_CONFIG, paddr);\r\nif (!err) {\r\nfor (i = 0; i < MAX_LOOPS; i++) {\r\nif (le32_to_cpu(sm_data->isr) & SLIC_ISR_UPC)\r\nbreak;\r\nmdelay(1);\r\n}\r\nif (i == MAX_LOOPS) {\r\ndev_err(&sdev->pdev->dev,\r\n"timed out while waiting for eeprom data\n");\r\nerr = -ETIMEDOUT;\r\n}\r\nupr = slic_dequeue_upr(sdev);\r\nkfree(upr);\r\n}\r\nslic_write(sdev, SLIC_REG_ISP, 0);\r\nslic_write(sdev, SLIC_REG_ISR, 0);\r\nslic_flush_write(sdev);\r\nif (err)\r\ngoto free_eeprom;\r\nif (sdev->model == SLIC_MODEL_OASIS) {\r\nstruct slic_oasis_eeprom *oee;\r\noee = (struct slic_oasis_eeprom *)eeprom;\r\nmac[0] = oee->mac;\r\nmac[1] = oee->mac2;\r\ncodesize = le16_to_cpu(oee->eeprom_code_size);\r\n} else {\r\nstruct slic_mojave_eeprom *mee;\r\nmee = (struct slic_mojave_eeprom *)eeprom;\r\nmac[0] = mee->mac;\r\nmac[1] = mee->mac2;\r\ncodesize = le16_to_cpu(mee->eeprom_code_size);\r\n}\r\nif (!slic_eeprom_valid(eeprom, codesize)) {\r\ndev_err(&sdev->pdev->dev, "invalid checksum in eeprom\n");\r\nerr = -EINVAL;\r\ngoto free_eeprom;\r\n}\r\nether_addr_copy(sdev->netdev->dev_addr, mac[devfn]);\r\nfree_eeprom:\r\ndma_free_coherent(&sdev->pdev->dev, SLIC_EEPROM_SIZE, eeprom, paddr);\r\nreturn err;\r\n}\r\nstatic int slic_init(struct slic_device *sdev)\r\n{\r\nint err;\r\nspin_lock_init(&sdev->upper_lock);\r\nspin_lock_init(&sdev->link_lock);\r\nINIT_LIST_HEAD(&sdev->upr_list.list);\r\nspin_lock_init(&sdev->upr_list.lock);\r\nu64_stats_init(&sdev->stats.syncp);\r\nslic_card_reset(sdev);\r\nerr = slic_load_firmware(sdev);\r\nif (err) {\r\ndev_err(&sdev->pdev->dev, "failed to load firmware\n");\r\nreturn err;\r\n}\r\nerr = slic_init_shmem(sdev);\r\nif (err) {\r\ndev_err(&sdev->pdev->dev, "failed to init shared memory\n");\r\nreturn err;\r\n}\r\nerr = slic_read_eeprom(sdev);\r\nif (err) {\r\ndev_err(&sdev->pdev->dev, "failed to read eeprom\n");\r\ngoto free_sm;\r\n}\r\nslic_card_reset(sdev);\r\nslic_free_shmem(sdev);\r\nreturn 0;\r\nfree_sm:\r\nslic_free_shmem(sdev);\r\nreturn err;\r\n}\r\nstatic bool slic_is_fiber(unsigned short subdev)\r\n{\r\nswitch (subdev) {\r\ncase PCI_SUBDEVICE_ID_ALACRITECH_1000X1F:\r\ncase PCI_SUBDEVICE_ID_ALACRITECH_SES1001F:\r\ncase PCI_SUBDEVICE_ID_ALACRITECH_SEN2002XF:\r\ncase PCI_SUBDEVICE_ID_ALACRITECH_SEN2001XF:\r\ncase PCI_SUBDEVICE_ID_ALACRITECH_SEN2104EF:\r\ncase PCI_SUBDEVICE_ID_ALACRITECH_SEN2102EF:\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic void slic_configure_pci(struct pci_dev *pdev)\r\n{\r\nu16 old;\r\nu16 cmd;\r\npci_read_config_word(pdev, PCI_COMMAND, &old);\r\ncmd = old | PCI_COMMAND_PARITY | PCI_COMMAND_SERR;\r\nif (old != cmd)\r\npci_write_config_word(pdev, PCI_COMMAND, cmd);\r\n}\r\nstatic int slic_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct slic_device *sdev;\r\nstruct net_device *dev;\r\nint err;\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to enable PCI device\n");\r\nreturn err;\r\n}\r\npci_set_master(pdev);\r\npci_try_set_mwi(pdev);\r\nslic_configure_pci(pdev);\r\nerr = dma_set_mask(&pdev->dev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to setup DMA\n");\r\ngoto disable;\r\n}\r\ndma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(32));\r\nerr = pci_request_regions(pdev, DRV_NAME);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to obtain PCI regions\n");\r\ngoto disable;\r\n}\r\ndev = alloc_etherdev(sizeof(*sdev));\r\nif (!dev) {\r\ndev_err(&pdev->dev, "failed to alloc ethernet device\n");\r\nerr = -ENOMEM;\r\ngoto free_regions;\r\n}\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\npci_set_drvdata(pdev, dev);\r\ndev->irq = pdev->irq;\r\ndev->netdev_ops = &slic_netdev_ops;\r\ndev->hw_features = NETIF_F_RXCSUM;\r\ndev->features |= dev->hw_features;\r\ndev->ethtool_ops = &slic_ethtool_ops;\r\nsdev = netdev_priv(dev);\r\nsdev->model = (pdev->device == PCI_DEVICE_ID_ALACRITECH_OASIS) ?\r\nSLIC_MODEL_OASIS : SLIC_MODEL_MOJAVE;\r\nsdev->is_fiber = slic_is_fiber(pdev->subsystem_device);\r\nsdev->pdev = pdev;\r\nsdev->netdev = dev;\r\nsdev->regs = ioremap_nocache(pci_resource_start(pdev, 0),\r\npci_resource_len(pdev, 0));\r\nif (!sdev->regs) {\r\ndev_err(&pdev->dev, "failed to map registers\n");\r\nerr = -ENOMEM;\r\ngoto free_netdev;\r\n}\r\nerr = slic_init(sdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to initialize driver\n");\r\ngoto unmap;\r\n}\r\nnetif_napi_add(dev, &sdev->napi, slic_poll, SLIC_NAPI_WEIGHT);\r\nnetif_carrier_off(dev);\r\nerr = register_netdev(dev);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to register net device: %i\n", err);\r\ngoto unmap;\r\n}\r\nreturn 0;\r\nunmap:\r\niounmap(sdev->regs);\r\nfree_netdev:\r\nfree_netdev(dev);\r\nfree_regions:\r\npci_release_regions(pdev);\r\ndisable:\r\npci_disable_device(pdev);\r\nreturn err;\r\n}\r\nstatic void slic_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct slic_device *sdev = netdev_priv(dev);\r\nunregister_netdev(dev);\r\niounmap(sdev->regs);\r\nfree_netdev(dev);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\n}
