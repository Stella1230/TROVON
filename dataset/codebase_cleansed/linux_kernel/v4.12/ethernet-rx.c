static irqreturn_t cvm_oct_do_interrupt(int irq, void *napi_id)\r\n{\r\ndisable_irq_nosync(irq);\r\nnapi_schedule(napi_id);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic inline int cvm_oct_check_rcv_error(cvmx_wqe_t *work)\r\n{\r\nint port;\r\nif (octeon_has_feature(OCTEON_FEATURE_PKND))\r\nport = work->word0.pip.cn68xx.pknd;\r\nelse\r\nport = work->word1.cn38xx.ipprt;\r\nif ((work->word2.snoip.err_code == 10) && (work->word1.len <= 64)) {\r\n} else if (work->word2.snoip.err_code == 5 ||\r\nwork->word2.snoip.err_code == 7) {\r\nint interface = cvmx_helper_get_interface_num(port);\r\nint index = cvmx_helper_get_interface_index_num(port);\r\nunion cvmx_gmxx_rxx_frm_ctl gmxx_rxx_frm_ctl;\r\ngmxx_rxx_frm_ctl.u64 =\r\ncvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(index, interface));\r\nif (gmxx_rxx_frm_ctl.s.pre_chk == 0) {\r\nu8 *ptr =\r\ncvmx_phys_to_ptr(work->packet_ptr.s.addr);\r\nint i = 0;\r\nwhile (i < work->word1.len - 1) {\r\nif (*ptr != 0x55)\r\nbreak;\r\nptr++;\r\ni++;\r\n}\r\nif (*ptr == 0xd5) {\r\nwork->packet_ptr.s.addr += i + 1;\r\nwork->word1.len -= i + 5;\r\n} else if ((*ptr & 0xf) == 0xd) {\r\nwork->packet_ptr.s.addr += i;\r\nwork->word1.len -= i + 4;\r\nfor (i = 0; i < work->word1.len; i++) {\r\n*ptr =\r\n((*ptr & 0xf0) >> 4) |\r\n((*(ptr + 1) & 0xf) << 4);\r\nptr++;\r\n}\r\n} else {\r\nprintk_ratelimited("Port %d unknown preamble, packet dropped\n",\r\nport);\r\ncvm_oct_free_work(work);\r\nreturn 1;\r\n}\r\n}\r\n} else {\r\nprintk_ratelimited("Port %d receive error code %d, packet dropped\n",\r\nport, work->word2.snoip.err_code);\r\ncvm_oct_free_work(work);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cvm_oct_poll(struct oct_rx_group *rx_group, int budget)\r\n{\r\nconst int coreid = cvmx_get_core_num();\r\nu64 old_group_mask;\r\nu64 old_scratch;\r\nint rx_count = 0;\r\nint did_work_request = 0;\r\nint packet_not_copied;\r\nprefetch(cvm_oct_device);\r\nif (USE_ASYNC_IOBDMA) {\r\nCVMX_SYNCIOBDMA;\r\nold_scratch = cvmx_scratch_read64(CVMX_SCR_SCRATCH);\r\n}\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX)) {\r\nold_group_mask = cvmx_read_csr(CVMX_SSO_PPX_GRP_MSK(coreid));\r\ncvmx_write_csr(CVMX_SSO_PPX_GRP_MSK(coreid),\r\nBIT(rx_group->group));\r\ncvmx_read_csr(CVMX_SSO_PPX_GRP_MSK(coreid));\r\n} else {\r\nold_group_mask = cvmx_read_csr(CVMX_POW_PP_GRP_MSKX(coreid));\r\ncvmx_write_csr(CVMX_POW_PP_GRP_MSKX(coreid),\r\n(old_group_mask & ~0xFFFFull) |\r\nBIT(rx_group->group));\r\n}\r\nif (USE_ASYNC_IOBDMA) {\r\ncvmx_pow_work_request_async(CVMX_SCR_SCRATCH, CVMX_POW_NO_WAIT);\r\ndid_work_request = 1;\r\n}\r\nwhile (rx_count < budget) {\r\nstruct sk_buff *skb = NULL;\r\nstruct sk_buff **pskb = NULL;\r\nint skb_in_hw;\r\ncvmx_wqe_t *work;\r\nint port;\r\nif (USE_ASYNC_IOBDMA && did_work_request)\r\nwork = cvmx_pow_work_response_async(CVMX_SCR_SCRATCH);\r\nelse\r\nwork = cvmx_pow_work_request_sync(CVMX_POW_NO_WAIT);\r\nprefetch(work);\r\ndid_work_request = 0;\r\nif (!work) {\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX)) {\r\ncvmx_write_csr(CVMX_SSO_WQ_IQ_DIS,\r\nBIT(rx_group->group));\r\ncvmx_write_csr(CVMX_SSO_WQ_INT,\r\nBIT(rx_group->group));\r\n} else {\r\nunion cvmx_pow_wq_int wq_int;\r\nwq_int.u64 = 0;\r\nwq_int.s.iq_dis = BIT(rx_group->group);\r\nwq_int.s.wq_int = BIT(rx_group->group);\r\ncvmx_write_csr(CVMX_POW_WQ_INT, wq_int.u64);\r\n}\r\nbreak;\r\n}\r\npskb = (struct sk_buff **)\r\n(cvm_oct_get_buffer_ptr(work->packet_ptr) -\r\nsizeof(void *));\r\nprefetch(pskb);\r\nif (USE_ASYNC_IOBDMA && rx_count < (budget - 1)) {\r\ncvmx_pow_work_request_async_nocheck(CVMX_SCR_SCRATCH,\r\nCVMX_POW_NO_WAIT);\r\ndid_work_request = 1;\r\n}\r\nrx_count++;\r\nskb_in_hw = work->word2.s.bufs == 1;\r\nif (likely(skb_in_hw)) {\r\nskb = *pskb;\r\nprefetch(&skb->head);\r\nprefetch(&skb->len);\r\n}\r\nif (octeon_has_feature(OCTEON_FEATURE_PKND))\r\nport = work->word0.pip.cn68xx.pknd;\r\nelse\r\nport = work->word1.cn38xx.ipprt;\r\nprefetch(cvm_oct_device[port]);\r\nif (unlikely(work->word2.snoip.rcv_error)) {\r\nif (cvm_oct_check_rcv_error(work))\r\ncontinue;\r\n}\r\nif (likely(skb_in_hw)) {\r\nskb->data = skb->head + work->packet_ptr.s.addr -\r\ncvmx_ptr_to_phys(skb->head);\r\nprefetch(skb->data);\r\nskb->len = work->word1.len;\r\nskb_set_tail_pointer(skb, skb->len);\r\npacket_not_copied = 1;\r\n} else {\r\nskb = dev_alloc_skb(work->word1.len);\r\nif (!skb) {\r\ncvm_oct_free_work(work);\r\ncontinue;\r\n}\r\nif (unlikely(work->word2.s.bufs == 0)) {\r\nu8 *ptr = work->packet_data;\r\nif (likely(!work->word2.s.not_IP)) {\r\nif (work->word2.s.is_v6)\r\nptr += 2;\r\nelse\r\nptr += 6;\r\n}\r\nmemcpy(skb_put(skb, work->word1.len), ptr,\r\nwork->word1.len);\r\n} else {\r\nint segments = work->word2.s.bufs;\r\nunion cvmx_buf_ptr segment_ptr =\r\nwork->packet_ptr;\r\nint len = work->word1.len;\r\nwhile (segments--) {\r\nunion cvmx_buf_ptr next_ptr =\r\n*(union cvmx_buf_ptr *)\r\ncvmx_phys_to_ptr(\r\nsegment_ptr.s.addr - 8);\r\nint segment_size =\r\nCVMX_FPA_PACKET_POOL_SIZE -\r\n(segment_ptr.s.addr -\r\n(((segment_ptr.s.addr >> 7) -\r\nsegment_ptr.s.back) << 7));\r\nif (segment_size > len)\r\nsegment_size = len;\r\nmemcpy(skb_put(skb, segment_size),\r\ncvmx_phys_to_ptr(\r\nsegment_ptr.s.addr),\r\nsegment_size);\r\nlen -= segment_size;\r\nsegment_ptr = next_ptr;\r\n}\r\n}\r\npacket_not_copied = 0;\r\n}\r\nif (likely((port < TOTAL_NUMBER_OF_PORTS) &&\r\ncvm_oct_device[port])) {\r\nstruct net_device *dev = cvm_oct_device[port];\r\nif (likely(dev->flags & IFF_UP)) {\r\nskb->protocol = eth_type_trans(skb, dev);\r\nskb->dev = dev;\r\nif (unlikely(work->word2.s.not_IP ||\r\nwork->word2.s.IP_exc ||\r\nwork->word2.s.L4_error ||\r\n!work->word2.s.tcp_or_udp))\r\nskb->ip_summed = CHECKSUM_NONE;\r\nelse\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nif (port >= CVMX_PIP_NUM_INPUT_PORTS) {\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += skb->len;\r\n}\r\nnetif_receive_skb(skb);\r\n} else {\r\ndev->stats.rx_dropped++;\r\ndev_kfree_skb_irq(skb);\r\n}\r\n} else {\r\nprintk_ratelimited("Port %d not controlled by Linux, packet dropped\n",\r\nport);\r\ndev_kfree_skb_irq(skb);\r\n}\r\nif (likely(packet_not_copied)) {\r\ncvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,\r\n1);\r\ncvmx_fpa_free(work, CVMX_FPA_WQE_POOL, 1);\r\n} else {\r\ncvm_oct_free_work(work);\r\n}\r\n}\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX)) {\r\ncvmx_write_csr(CVMX_SSO_PPX_GRP_MSK(coreid), old_group_mask);\r\ncvmx_read_csr(CVMX_SSO_PPX_GRP_MSK(coreid));\r\n} else {\r\ncvmx_write_csr(CVMX_POW_PP_GRP_MSKX(coreid), old_group_mask);\r\n}\r\nif (USE_ASYNC_IOBDMA) {\r\ncvmx_scratch_write64(CVMX_SCR_SCRATCH, old_scratch);\r\n}\r\ncvm_oct_rx_refill_pool(0);\r\nreturn rx_count;\r\n}\r\nstatic int cvm_oct_napi_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct oct_rx_group *rx_group = container_of(napi, struct oct_rx_group,\r\nnapi);\r\nint rx_count;\r\nrx_count = cvm_oct_poll(rx_group, budget);\r\nif (rx_count < budget) {\r\nnapi_complete_done(napi, rx_count);\r\nenable_irq(rx_group->irq);\r\n}\r\nreturn rx_count;\r\n}\r\nvoid cvm_oct_poll_controller(struct net_device *dev)\r\n{\r\nint i;\r\nif (!atomic_read(&oct_rx_ready))\r\nreturn;\r\nfor (i = 0; i < ARRAY_SIZE(oct_rx_group); i++) {\r\nif (!(pow_receive_groups & BIT(i)))\r\ncontinue;\r\ncvm_oct_poll(&oct_rx_group[i], 16);\r\n}\r\n}\r\nvoid cvm_oct_rx_initialize(void)\r\n{\r\nint i;\r\nstruct net_device *dev_for_napi = NULL;\r\nfor (i = 0; i < TOTAL_NUMBER_OF_PORTS; i++) {\r\nif (cvm_oct_device[i]) {\r\ndev_for_napi = cvm_oct_device[i];\r\nbreak;\r\n}\r\n}\r\nif (!dev_for_napi)\r\npanic("No net_devices were allocated.");\r\nfor (i = 0; i < ARRAY_SIZE(oct_rx_group); i++) {\r\nint ret;\r\nif (!(pow_receive_groups & BIT(i)))\r\ncontinue;\r\nnetif_napi_add(dev_for_napi, &oct_rx_group[i].napi,\r\ncvm_oct_napi_poll, rx_napi_weight);\r\nnapi_enable(&oct_rx_group[i].napi);\r\noct_rx_group[i].irq = OCTEON_IRQ_WORKQ0 + i;\r\noct_rx_group[i].group = i;\r\nret = request_irq(oct_rx_group[i].irq, cvm_oct_do_interrupt, 0,\r\n"Ethernet", &oct_rx_group[i].napi);\r\nif (ret)\r\npanic("Could not acquire Ethernet IRQ %d\n",\r\noct_rx_group[i].irq);\r\ndisable_irq_nosync(oct_rx_group[i].irq);\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX)) {\r\nunion cvmx_sso_wq_int_thrx int_thr;\r\nunion cvmx_pow_wq_int_pc int_pc;\r\nint_thr.u64 = 0;\r\nint_thr.s.tc_en = 1;\r\nint_thr.s.tc_thr = 1;\r\ncvmx_write_csr(CVMX_SSO_WQ_INT_THRX(i), int_thr.u64);\r\nint_pc.u64 = 0;\r\nint_pc.s.pc_thr = 5;\r\ncvmx_write_csr(CVMX_SSO_WQ_INT_PC, int_pc.u64);\r\n} else {\r\nunion cvmx_pow_wq_int_thrx int_thr;\r\nunion cvmx_pow_wq_int_pc int_pc;\r\nint_thr.u64 = 0;\r\nint_thr.s.tc_en = 1;\r\nint_thr.s.tc_thr = 1;\r\ncvmx_write_csr(CVMX_POW_WQ_INT_THRX(i), int_thr.u64);\r\nint_pc.u64 = 0;\r\nint_pc.s.pc_thr = 5;\r\ncvmx_write_csr(CVMX_POW_WQ_INT_PC, int_pc.u64);\r\n}\r\nnapi_schedule(&oct_rx_group[i].napi);\r\n}\r\natomic_inc(&oct_rx_ready);\r\n}\r\nvoid cvm_oct_rx_shutdown(void)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(oct_rx_group); i++) {\r\nif (!(pow_receive_groups & BIT(i)))\r\ncontinue;\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX))\r\ncvmx_write_csr(CVMX_SSO_WQ_INT_THRX(i), 0);\r\nelse\r\ncvmx_write_csr(CVMX_POW_WQ_INT_THRX(i), 0);\r\nfree_irq(oct_rx_group[i].irq, cvm_oct_device);\r\nnetif_napi_del(&oct_rx_group[i].napi);\r\n}\r\n}
