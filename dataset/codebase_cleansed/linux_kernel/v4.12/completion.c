void complete(struct completion *x)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&x->wait.lock, flags);\r\nif (x->done != UINT_MAX)\r\nx->done++;\r\n__wake_up_locked(&x->wait, TASK_NORMAL, 1);\r\nspin_unlock_irqrestore(&x->wait.lock, flags);\r\n}\r\nvoid complete_all(struct completion *x)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&x->wait.lock, flags);\r\nx->done = UINT_MAX;\r\n__wake_up_locked(&x->wait, TASK_NORMAL, 0);\r\nspin_unlock_irqrestore(&x->wait.lock, flags);\r\n}\r\nstatic inline long __sched\r\ndo_wait_for_common(struct completion *x,\r\nlong (*action)(long), long timeout, int state)\r\n{\r\nif (!x->done) {\r\nDECLARE_WAITQUEUE(wait, current);\r\n__add_wait_queue_tail_exclusive(&x->wait, &wait);\r\ndo {\r\nif (signal_pending_state(state, current)) {\r\ntimeout = -ERESTARTSYS;\r\nbreak;\r\n}\r\n__set_current_state(state);\r\nspin_unlock_irq(&x->wait.lock);\r\ntimeout = action(timeout);\r\nspin_lock_irq(&x->wait.lock);\r\n} while (!x->done && timeout);\r\n__remove_wait_queue(&x->wait, &wait);\r\nif (!x->done)\r\nreturn timeout;\r\n}\r\nif (x->done != UINT_MAX)\r\nx->done--;\r\nreturn timeout ?: 1;\r\n}\r\nstatic inline long __sched\r\n__wait_for_common(struct completion *x,\r\nlong (*action)(long), long timeout, int state)\r\n{\r\nmight_sleep();\r\nspin_lock_irq(&x->wait.lock);\r\ntimeout = do_wait_for_common(x, action, timeout, state);\r\nspin_unlock_irq(&x->wait.lock);\r\nreturn timeout;\r\n}\r\nstatic long __sched\r\nwait_for_common(struct completion *x, long timeout, int state)\r\n{\r\nreturn __wait_for_common(x, schedule_timeout, timeout, state);\r\n}\r\nstatic long __sched\r\nwait_for_common_io(struct completion *x, long timeout, int state)\r\n{\r\nreturn __wait_for_common(x, io_schedule_timeout, timeout, state);\r\n}\r\nvoid __sched wait_for_completion(struct completion *x)\r\n{\r\nwait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_UNINTERRUPTIBLE);\r\n}\r\nunsigned long __sched\r\nwait_for_completion_timeout(struct completion *x, unsigned long timeout)\r\n{\r\nreturn wait_for_common(x, timeout, TASK_UNINTERRUPTIBLE);\r\n}\r\nvoid __sched wait_for_completion_io(struct completion *x)\r\n{\r\nwait_for_common_io(x, MAX_SCHEDULE_TIMEOUT, TASK_UNINTERRUPTIBLE);\r\n}\r\nunsigned long __sched\r\nwait_for_completion_io_timeout(struct completion *x, unsigned long timeout)\r\n{\r\nreturn wait_for_common_io(x, timeout, TASK_UNINTERRUPTIBLE);\r\n}\r\nint __sched wait_for_completion_interruptible(struct completion *x)\r\n{\r\nlong t = wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_INTERRUPTIBLE);\r\nif (t == -ERESTARTSYS)\r\nreturn t;\r\nreturn 0;\r\n}\r\nlong __sched\r\nwait_for_completion_interruptible_timeout(struct completion *x,\r\nunsigned long timeout)\r\n{\r\nreturn wait_for_common(x, timeout, TASK_INTERRUPTIBLE);\r\n}\r\nint __sched wait_for_completion_killable(struct completion *x)\r\n{\r\nlong t = wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_KILLABLE);\r\nif (t == -ERESTARTSYS)\r\nreturn t;\r\nreturn 0;\r\n}\r\nlong __sched\r\nwait_for_completion_killable_timeout(struct completion *x,\r\nunsigned long timeout)\r\n{\r\nreturn wait_for_common(x, timeout, TASK_KILLABLE);\r\n}\r\nbool try_wait_for_completion(struct completion *x)\r\n{\r\nunsigned long flags;\r\nint ret = 1;\r\nif (!READ_ONCE(x->done))\r\nreturn 0;\r\nspin_lock_irqsave(&x->wait.lock, flags);\r\nif (!x->done)\r\nret = 0;\r\nelse if (x->done != UINT_MAX)\r\nx->done--;\r\nspin_unlock_irqrestore(&x->wait.lock, flags);\r\nreturn ret;\r\n}\r\nbool completion_done(struct completion *x)\r\n{\r\nif (!READ_ONCE(x->done))\r\nreturn false;\r\nsmp_rmb();\r\nspin_unlock_wait(&x->wait.lock);\r\nreturn true;\r\n}
