static void put_pending_block(struct log_writes_c *lc)\r\n{\r\nif (atomic_dec_and_test(&lc->pending_blocks)) {\r\nsmp_mb__after_atomic();\r\nif (waitqueue_active(&lc->wait))\r\nwake_up(&lc->wait);\r\n}\r\n}\r\nstatic void put_io_block(struct log_writes_c *lc)\r\n{\r\nif (atomic_dec_and_test(&lc->io_blocks)) {\r\nsmp_mb__after_atomic();\r\nif (waitqueue_active(&lc->wait))\r\nwake_up(&lc->wait);\r\n}\r\n}\r\nstatic void log_end_io(struct bio *bio)\r\n{\r\nstruct log_writes_c *lc = bio->bi_private;\r\nif (bio->bi_error) {\r\nunsigned long flags;\r\nDMERR("Error writing log block, error=%d", bio->bi_error);\r\nspin_lock_irqsave(&lc->blocks_lock, flags);\r\nlc->logging_enabled = false;\r\nspin_unlock_irqrestore(&lc->blocks_lock, flags);\r\n}\r\nbio_free_pages(bio);\r\nput_io_block(lc);\r\nbio_put(bio);\r\n}\r\nstatic void free_pending_block(struct log_writes_c *lc,\r\nstruct pending_block *block)\r\n{\r\nint i;\r\nfor (i = 0; i < block->vec_cnt; i++) {\r\nif (block->vecs[i].bv_page)\r\n__free_page(block->vecs[i].bv_page);\r\n}\r\nkfree(block->data);\r\nkfree(block);\r\nput_pending_block(lc);\r\n}\r\nstatic int write_metadata(struct log_writes_c *lc, void *entry,\r\nsize_t entrylen, void *data, size_t datalen,\r\nsector_t sector)\r\n{\r\nstruct bio *bio;\r\nstruct page *page;\r\nvoid *ptr;\r\nsize_t ret;\r\nbio = bio_alloc(GFP_KERNEL, 1);\r\nif (!bio) {\r\nDMERR("Couldn't alloc log bio");\r\ngoto error;\r\n}\r\nbio->bi_iter.bi_size = 0;\r\nbio->bi_iter.bi_sector = sector;\r\nbio->bi_bdev = lc->logdev->bdev;\r\nbio->bi_end_io = log_end_io;\r\nbio->bi_private = lc;\r\nbio_set_op_attrs(bio, REQ_OP_WRITE, 0);\r\npage = alloc_page(GFP_KERNEL);\r\nif (!page) {\r\nDMERR("Couldn't alloc log page");\r\nbio_put(bio);\r\ngoto error;\r\n}\r\nptr = kmap_atomic(page);\r\nmemcpy(ptr, entry, entrylen);\r\nif (datalen)\r\nmemcpy(ptr + entrylen, data, datalen);\r\nmemset(ptr + entrylen + datalen, 0,\r\nlc->sectorsize - entrylen - datalen);\r\nkunmap_atomic(ptr);\r\nret = bio_add_page(bio, page, lc->sectorsize, 0);\r\nif (ret != lc->sectorsize) {\r\nDMERR("Couldn't add page to the log block");\r\ngoto error_bio;\r\n}\r\nsubmit_bio(bio);\r\nreturn 0;\r\nerror_bio:\r\nbio_put(bio);\r\n__free_page(page);\r\nerror:\r\nput_io_block(lc);\r\nreturn -1;\r\n}\r\nstatic int log_one_block(struct log_writes_c *lc,\r\nstruct pending_block *block, sector_t sector)\r\n{\r\nstruct bio *bio;\r\nstruct log_write_entry entry;\r\nsize_t ret;\r\nint i;\r\nentry.sector = cpu_to_le64(block->sector);\r\nentry.nr_sectors = cpu_to_le64(block->nr_sectors);\r\nentry.flags = cpu_to_le64(block->flags);\r\nentry.data_len = cpu_to_le64(block->datalen);\r\nif (write_metadata(lc, &entry, sizeof(entry), block->data,\r\nblock->datalen, sector)) {\r\nfree_pending_block(lc, block);\r\nreturn -1;\r\n}\r\nif (!block->vec_cnt)\r\ngoto out;\r\nsector++;\r\natomic_inc(&lc->io_blocks);\r\nbio = bio_alloc(GFP_KERNEL, min(block->vec_cnt, BIO_MAX_PAGES));\r\nif (!bio) {\r\nDMERR("Couldn't alloc log bio");\r\ngoto error;\r\n}\r\nbio->bi_iter.bi_size = 0;\r\nbio->bi_iter.bi_sector = sector;\r\nbio->bi_bdev = lc->logdev->bdev;\r\nbio->bi_end_io = log_end_io;\r\nbio->bi_private = lc;\r\nbio_set_op_attrs(bio, REQ_OP_WRITE, 0);\r\nfor (i = 0; i < block->vec_cnt; i++) {\r\nret = bio_add_page(bio, block->vecs[i].bv_page,\r\nblock->vecs[i].bv_len, 0);\r\nif (ret != block->vecs[i].bv_len) {\r\natomic_inc(&lc->io_blocks);\r\nsubmit_bio(bio);\r\nbio = bio_alloc(GFP_KERNEL, min(block->vec_cnt - i, BIO_MAX_PAGES));\r\nif (!bio) {\r\nDMERR("Couldn't alloc log bio");\r\ngoto error;\r\n}\r\nbio->bi_iter.bi_size = 0;\r\nbio->bi_iter.bi_sector = sector;\r\nbio->bi_bdev = lc->logdev->bdev;\r\nbio->bi_end_io = log_end_io;\r\nbio->bi_private = lc;\r\nbio_set_op_attrs(bio, REQ_OP_WRITE, 0);\r\nret = bio_add_page(bio, block->vecs[i].bv_page,\r\nblock->vecs[i].bv_len, 0);\r\nif (ret != block->vecs[i].bv_len) {\r\nDMERR("Couldn't add page on new bio?");\r\nbio_put(bio);\r\ngoto error;\r\n}\r\n}\r\nsector += block->vecs[i].bv_len >> SECTOR_SHIFT;\r\n}\r\nsubmit_bio(bio);\r\nout:\r\nkfree(block->data);\r\nkfree(block);\r\nput_pending_block(lc);\r\nreturn 0;\r\nerror:\r\nfree_pending_block(lc, block);\r\nput_io_block(lc);\r\nreturn -1;\r\n}\r\nstatic int log_super(struct log_writes_c *lc)\r\n{\r\nstruct log_write_super super;\r\nsuper.magic = cpu_to_le64(WRITE_LOG_MAGIC);\r\nsuper.version = cpu_to_le64(WRITE_LOG_VERSION);\r\nsuper.nr_entries = cpu_to_le64(lc->logged_entries);\r\nsuper.sectorsize = cpu_to_le32(lc->sectorsize);\r\nif (write_metadata(lc, &super, sizeof(super), NULL, 0, 0)) {\r\nDMERR("Couldn't write super");\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline sector_t logdev_last_sector(struct log_writes_c *lc)\r\n{\r\nreturn i_size_read(lc->logdev->bdev->bd_inode) >> SECTOR_SHIFT;\r\n}\r\nstatic int log_writes_kthread(void *arg)\r\n{\r\nstruct log_writes_c *lc = (struct log_writes_c *)arg;\r\nsector_t sector = 0;\r\nwhile (!kthread_should_stop()) {\r\nbool super = false;\r\nbool logging_enabled;\r\nstruct pending_block *block = NULL;\r\nint ret;\r\nspin_lock_irq(&lc->blocks_lock);\r\nif (!list_empty(&lc->logging_blocks)) {\r\nblock = list_first_entry(&lc->logging_blocks,\r\nstruct pending_block, list);\r\nlist_del_init(&block->list);\r\nif (!lc->logging_enabled)\r\ngoto next;\r\nsector = lc->next_sector;\r\nif (block->flags & LOG_DISCARD_FLAG)\r\nlc->next_sector++;\r\nelse\r\nlc->next_sector += block->nr_sectors + 1;\r\nif (!lc->end_sector)\r\nlc->end_sector = logdev_last_sector(lc);\r\nif (lc->end_sector &&\r\nlc->next_sector >= lc->end_sector) {\r\nDMERR("Ran out of space on the logdev");\r\nlc->logging_enabled = false;\r\ngoto next;\r\n}\r\nlc->logged_entries++;\r\natomic_inc(&lc->io_blocks);\r\nsuper = (block->flags & (LOG_FUA_FLAG | LOG_MARK_FLAG));\r\nif (super)\r\natomic_inc(&lc->io_blocks);\r\n}\r\nnext:\r\nlogging_enabled = lc->logging_enabled;\r\nspin_unlock_irq(&lc->blocks_lock);\r\nif (block) {\r\nif (logging_enabled) {\r\nret = log_one_block(lc, block, sector);\r\nif (!ret && super)\r\nret = log_super(lc);\r\nif (ret) {\r\nspin_lock_irq(&lc->blocks_lock);\r\nlc->logging_enabled = false;\r\nspin_unlock_irq(&lc->blocks_lock);\r\n}\r\n} else\r\nfree_pending_block(lc, block);\r\ncontinue;\r\n}\r\nif (!try_to_freeze()) {\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nif (!kthread_should_stop() &&\r\n!atomic_read(&lc->pending_blocks))\r\nschedule();\r\n__set_current_state(TASK_RUNNING);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int log_writes_ctr(struct dm_target *ti, unsigned int argc, char **argv)\r\n{\r\nstruct log_writes_c *lc;\r\nstruct dm_arg_set as;\r\nconst char *devname, *logdevname;\r\nint ret;\r\nas.argc = argc;\r\nas.argv = argv;\r\nif (argc < 2) {\r\nti->error = "Invalid argument count";\r\nreturn -EINVAL;\r\n}\r\nlc = kzalloc(sizeof(struct log_writes_c), GFP_KERNEL);\r\nif (!lc) {\r\nti->error = "Cannot allocate context";\r\nreturn -ENOMEM;\r\n}\r\nspin_lock_init(&lc->blocks_lock);\r\nINIT_LIST_HEAD(&lc->unflushed_blocks);\r\nINIT_LIST_HEAD(&lc->logging_blocks);\r\ninit_waitqueue_head(&lc->wait);\r\nlc->sectorsize = 1 << SECTOR_SHIFT;\r\natomic_set(&lc->io_blocks, 0);\r\natomic_set(&lc->pending_blocks, 0);\r\ndevname = dm_shift_arg(&as);\r\nret = dm_get_device(ti, devname, dm_table_get_mode(ti->table), &lc->dev);\r\nif (ret) {\r\nti->error = "Device lookup failed";\r\ngoto bad;\r\n}\r\nlogdevname = dm_shift_arg(&as);\r\nret = dm_get_device(ti, logdevname, dm_table_get_mode(ti->table),\r\n&lc->logdev);\r\nif (ret) {\r\nti->error = "Log device lookup failed";\r\ndm_put_device(ti, lc->dev);\r\ngoto bad;\r\n}\r\nlc->log_kthread = kthread_run(log_writes_kthread, lc, "log-write");\r\nif (IS_ERR(lc->log_kthread)) {\r\nret = PTR_ERR(lc->log_kthread);\r\nti->error = "Couldn't alloc kthread";\r\ndm_put_device(ti, lc->dev);\r\ndm_put_device(ti, lc->logdev);\r\ngoto bad;\r\n}\r\nlc->next_sector = 1;\r\nlc->logging_enabled = true;\r\nlc->end_sector = logdev_last_sector(lc);\r\nlc->device_supports_discard = true;\r\nti->num_flush_bios = 1;\r\nti->flush_supported = true;\r\nti->num_discard_bios = 1;\r\nti->discards_supported = true;\r\nti->per_io_data_size = sizeof(struct per_bio_data);\r\nti->private = lc;\r\nreturn 0;\r\nbad:\r\nkfree(lc);\r\nreturn ret;\r\n}\r\nstatic int log_mark(struct log_writes_c *lc, char *data)\r\n{\r\nstruct pending_block *block;\r\nsize_t maxsize = lc->sectorsize - sizeof(struct log_write_entry);\r\nblock = kzalloc(sizeof(struct pending_block), GFP_KERNEL);\r\nif (!block) {\r\nDMERR("Error allocating pending block");\r\nreturn -ENOMEM;\r\n}\r\nblock->data = kstrndup(data, maxsize, GFP_KERNEL);\r\nif (!block->data) {\r\nDMERR("Error copying mark data");\r\nkfree(block);\r\nreturn -ENOMEM;\r\n}\r\natomic_inc(&lc->pending_blocks);\r\nblock->datalen = strlen(block->data);\r\nblock->flags |= LOG_MARK_FLAG;\r\nspin_lock_irq(&lc->blocks_lock);\r\nlist_add_tail(&block->list, &lc->logging_blocks);\r\nspin_unlock_irq(&lc->blocks_lock);\r\nwake_up_process(lc->log_kthread);\r\nreturn 0;\r\n}\r\nstatic void log_writes_dtr(struct dm_target *ti)\r\n{\r\nstruct log_writes_c *lc = ti->private;\r\nspin_lock_irq(&lc->blocks_lock);\r\nlist_splice_init(&lc->unflushed_blocks, &lc->logging_blocks);\r\nspin_unlock_irq(&lc->blocks_lock);\r\nlog_mark(lc, "dm-log-writes-end");\r\nwake_up_process(lc->log_kthread);\r\nwait_event(lc->wait, !atomic_read(&lc->io_blocks) &&\r\n!atomic_read(&lc->pending_blocks));\r\nkthread_stop(lc->log_kthread);\r\nWARN_ON(!list_empty(&lc->logging_blocks));\r\nWARN_ON(!list_empty(&lc->unflushed_blocks));\r\ndm_put_device(ti, lc->dev);\r\ndm_put_device(ti, lc->logdev);\r\nkfree(lc);\r\n}\r\nstatic void normal_map_bio(struct dm_target *ti, struct bio *bio)\r\n{\r\nstruct log_writes_c *lc = ti->private;\r\nbio->bi_bdev = lc->dev->bdev;\r\n}\r\nstatic int log_writes_map(struct dm_target *ti, struct bio *bio)\r\n{\r\nstruct log_writes_c *lc = ti->private;\r\nstruct per_bio_data *pb = dm_per_bio_data(bio, sizeof(struct per_bio_data));\r\nstruct pending_block *block;\r\nstruct bvec_iter iter;\r\nstruct bio_vec bv;\r\nsize_t alloc_size;\r\nint i = 0;\r\nbool flush_bio = (bio->bi_opf & REQ_PREFLUSH);\r\nbool fua_bio = (bio->bi_opf & REQ_FUA);\r\nbool discard_bio = (bio_op(bio) == REQ_OP_DISCARD);\r\npb->block = NULL;\r\nif (!lc->logging_enabled)\r\ngoto map_bio;\r\nif (bio_data_dir(bio) == READ)\r\ngoto map_bio;\r\nif (!bio_sectors(bio) && !flush_bio)\r\ngoto map_bio;\r\nif (discard_bio)\r\nalloc_size = sizeof(struct pending_block);\r\nelse\r\nalloc_size = sizeof(struct pending_block) + sizeof(struct bio_vec) * bio_segments(bio);\r\nblock = kzalloc(alloc_size, GFP_NOIO);\r\nif (!block) {\r\nDMERR("Error allocating pending block");\r\nspin_lock_irq(&lc->blocks_lock);\r\nlc->logging_enabled = false;\r\nspin_unlock_irq(&lc->blocks_lock);\r\nreturn -ENOMEM;\r\n}\r\nINIT_LIST_HEAD(&block->list);\r\npb->block = block;\r\natomic_inc(&lc->pending_blocks);\r\nif (flush_bio)\r\nblock->flags |= LOG_FLUSH_FLAG;\r\nif (fua_bio)\r\nblock->flags |= LOG_FUA_FLAG;\r\nif (discard_bio)\r\nblock->flags |= LOG_DISCARD_FLAG;\r\nblock->sector = bio->bi_iter.bi_sector;\r\nblock->nr_sectors = bio_sectors(bio);\r\nif (discard_bio) {\r\nWARN_ON(flush_bio || fua_bio);\r\nif (lc->device_supports_discard)\r\ngoto map_bio;\r\nbio_endio(bio);\r\nreturn DM_MAPIO_SUBMITTED;\r\n}\r\nif (flush_bio && !bio_sectors(bio)) {\r\nspin_lock_irq(&lc->blocks_lock);\r\nlist_splice_init(&lc->unflushed_blocks, &block->list);\r\nspin_unlock_irq(&lc->blocks_lock);\r\ngoto map_bio;\r\n}\r\nbio_for_each_segment(bv, bio, iter) {\r\nstruct page *page;\r\nvoid *src, *dst;\r\npage = alloc_page(GFP_NOIO);\r\nif (!page) {\r\nDMERR("Error allocing page");\r\nfree_pending_block(lc, block);\r\nspin_lock_irq(&lc->blocks_lock);\r\nlc->logging_enabled = false;\r\nspin_unlock_irq(&lc->blocks_lock);\r\nreturn -ENOMEM;\r\n}\r\nsrc = kmap_atomic(bv.bv_page);\r\ndst = kmap_atomic(page);\r\nmemcpy(dst, src + bv.bv_offset, bv.bv_len);\r\nkunmap_atomic(dst);\r\nkunmap_atomic(src);\r\nblock->vecs[i].bv_page = page;\r\nblock->vecs[i].bv_len = bv.bv_len;\r\nblock->vec_cnt++;\r\ni++;\r\n}\r\nif (flush_bio) {\r\nspin_lock_irq(&lc->blocks_lock);\r\nlist_splice_init(&lc->unflushed_blocks, &block->list);\r\nspin_unlock_irq(&lc->blocks_lock);\r\n}\r\nmap_bio:\r\nnormal_map_bio(ti, bio);\r\nreturn DM_MAPIO_REMAPPED;\r\n}\r\nstatic int normal_end_io(struct dm_target *ti, struct bio *bio, int error)\r\n{\r\nstruct log_writes_c *lc = ti->private;\r\nstruct per_bio_data *pb = dm_per_bio_data(bio, sizeof(struct per_bio_data));\r\nif (bio_data_dir(bio) == WRITE && pb->block) {\r\nstruct pending_block *block = pb->block;\r\nunsigned long flags;\r\nspin_lock_irqsave(&lc->blocks_lock, flags);\r\nif (block->flags & LOG_FLUSH_FLAG) {\r\nlist_splice_tail_init(&block->list, &lc->logging_blocks);\r\nlist_add_tail(&block->list, &lc->logging_blocks);\r\nwake_up_process(lc->log_kthread);\r\n} else if (block->flags & LOG_FUA_FLAG) {\r\nlist_add_tail(&block->list, &lc->logging_blocks);\r\nwake_up_process(lc->log_kthread);\r\n} else\r\nlist_add_tail(&block->list, &lc->unflushed_blocks);\r\nspin_unlock_irqrestore(&lc->blocks_lock, flags);\r\n}\r\nreturn error;\r\n}\r\nstatic void log_writes_status(struct dm_target *ti, status_type_t type,\r\nunsigned status_flags, char *result,\r\nunsigned maxlen)\r\n{\r\nunsigned sz = 0;\r\nstruct log_writes_c *lc = ti->private;\r\nswitch (type) {\r\ncase STATUSTYPE_INFO:\r\nDMEMIT("%llu %llu", lc->logged_entries,\r\n(unsigned long long)lc->next_sector - 1);\r\nif (!lc->logging_enabled)\r\nDMEMIT(" logging_disabled");\r\nbreak;\r\ncase STATUSTYPE_TABLE:\r\nDMEMIT("%s %s", lc->dev->name, lc->logdev->name);\r\nbreak;\r\n}\r\n}\r\nstatic int log_writes_prepare_ioctl(struct dm_target *ti,\r\nstruct block_device **bdev, fmode_t *mode)\r\n{\r\nstruct log_writes_c *lc = ti->private;\r\nstruct dm_dev *dev = lc->dev;\r\n*bdev = dev->bdev;\r\nif (ti->len != i_size_read(dev->bdev->bd_inode) >> SECTOR_SHIFT)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int log_writes_iterate_devices(struct dm_target *ti,\r\niterate_devices_callout_fn fn,\r\nvoid *data)\r\n{\r\nstruct log_writes_c *lc = ti->private;\r\nreturn fn(ti, lc->dev, 0, ti->len, data);\r\n}\r\nstatic int log_writes_message(struct dm_target *ti, unsigned argc, char **argv)\r\n{\r\nint r = -EINVAL;\r\nstruct log_writes_c *lc = ti->private;\r\nif (argc != 2) {\r\nDMWARN("Invalid log-writes message arguments, expect 2 arguments, got %d", argc);\r\nreturn r;\r\n}\r\nif (!strcasecmp(argv[0], "mark"))\r\nr = log_mark(lc, argv[1]);\r\nelse\r\nDMWARN("Unrecognised log writes target message received: %s", argv[0]);\r\nreturn r;\r\n}\r\nstatic void log_writes_io_hints(struct dm_target *ti, struct queue_limits *limits)\r\n{\r\nstruct log_writes_c *lc = ti->private;\r\nstruct request_queue *q = bdev_get_queue(lc->dev->bdev);\r\nif (!q || !blk_queue_discard(q)) {\r\nlc->device_supports_discard = false;\r\nlimits->discard_granularity = 1 << SECTOR_SHIFT;\r\nlimits->max_discard_sectors = (UINT_MAX >> SECTOR_SHIFT);\r\n}\r\n}\r\nstatic int __init dm_log_writes_init(void)\r\n{\r\nint r = dm_register_target(&log_writes_target);\r\nif (r < 0)\r\nDMERR("register failed %d", r);\r\nreturn r;\r\n}\r\nstatic void __exit dm_log_writes_exit(void)\r\n{\r\ndm_unregister_target(&log_writes_target);\r\n}
