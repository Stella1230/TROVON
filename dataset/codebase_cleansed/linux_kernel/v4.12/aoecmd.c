static struct sk_buff *\r\nnew_skb(ulong len)\r\n{\r\nstruct sk_buff *skb;\r\nskb = alloc_skb(len + MAX_HEADER, GFP_ATOMIC);\r\nif (skb) {\r\nskb_reserve(skb, MAX_HEADER);\r\nskb_reset_mac_header(skb);\r\nskb_reset_network_header(skb);\r\nskb->protocol = __constant_htons(ETH_P_AOE);\r\nskb_checksum_none_assert(skb);\r\n}\r\nreturn skb;\r\n}\r\nstatic struct frame *\r\ngetframe_deferred(struct aoedev *d, u32 tag)\r\n{\r\nstruct list_head *head, *pos, *nx;\r\nstruct frame *f;\r\nhead = &d->rexmitq;\r\nlist_for_each_safe(pos, nx, head) {\r\nf = list_entry(pos, struct frame, head);\r\nif (f->tag == tag) {\r\nlist_del(pos);\r\nreturn f;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct frame *\r\ngetframe(struct aoedev *d, u32 tag)\r\n{\r\nstruct frame *f;\r\nstruct list_head *head, *pos, *nx;\r\nu32 n;\r\nn = tag % NFACTIVE;\r\nhead = &d->factive[n];\r\nlist_for_each_safe(pos, nx, head) {\r\nf = list_entry(pos, struct frame, head);\r\nif (f->tag == tag) {\r\nlist_del(pos);\r\nreturn f;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic int\r\nnewtag(struct aoedev *d)\r\n{\r\nregister ulong n;\r\nn = jiffies & 0xffff;\r\nreturn n |= (++d->lasttag & 0x7fff) << 16;\r\n}\r\nstatic u32\r\naoehdr_atainit(struct aoedev *d, struct aoetgt *t, struct aoe_hdr *h)\r\n{\r\nu32 host_tag = newtag(d);\r\nmemcpy(h->src, t->ifp->nd->dev_addr, sizeof h->src);\r\nmemcpy(h->dst, t->addr, sizeof h->dst);\r\nh->type = __constant_cpu_to_be16(ETH_P_AOE);\r\nh->verfl = AOE_HVER;\r\nh->major = cpu_to_be16(d->aoemajor);\r\nh->minor = d->aoeminor;\r\nh->cmd = AOECMD_ATA;\r\nh->tag = cpu_to_be32(host_tag);\r\nreturn host_tag;\r\n}\r\nstatic inline void\r\nput_lba(struct aoe_atahdr *ah, sector_t lba)\r\n{\r\nah->lba0 = lba;\r\nah->lba1 = lba >>= 8;\r\nah->lba2 = lba >>= 8;\r\nah->lba3 = lba >>= 8;\r\nah->lba4 = lba >>= 8;\r\nah->lba5 = lba >>= 8;\r\n}\r\nstatic struct aoeif *\r\nifrotate(struct aoetgt *t)\r\n{\r\nstruct aoeif *ifp;\r\nifp = t->ifp;\r\nifp++;\r\nif (ifp >= &t->ifs[NAOEIFS] || ifp->nd == NULL)\r\nifp = t->ifs;\r\nif (ifp->nd == NULL)\r\nreturn NULL;\r\nreturn t->ifp = ifp;\r\n}\r\nstatic void\r\nskb_pool_put(struct aoedev *d, struct sk_buff *skb)\r\n{\r\n__skb_queue_tail(&d->skbpool, skb);\r\n}\r\nstatic struct sk_buff *\r\nskb_pool_get(struct aoedev *d)\r\n{\r\nstruct sk_buff *skb = skb_peek(&d->skbpool);\r\nif (skb && atomic_read(&skb_shinfo(skb)->dataref) == 1) {\r\n__skb_unlink(skb, &d->skbpool);\r\nreturn skb;\r\n}\r\nif (skb_queue_len(&d->skbpool) < NSKBPOOLMAX &&\r\n(skb = new_skb(ETH_ZLEN)))\r\nreturn skb;\r\nreturn NULL;\r\n}\r\nvoid\r\naoe_freetframe(struct frame *f)\r\n{\r\nstruct aoetgt *t;\r\nt = f->t;\r\nf->buf = NULL;\r\nmemset(&f->iter, 0, sizeof(f->iter));\r\nf->r_skb = NULL;\r\nf->flags = 0;\r\nlist_add(&f->head, &t->ffree);\r\n}\r\nstatic struct frame *\r\nnewtframe(struct aoedev *d, struct aoetgt *t)\r\n{\r\nstruct frame *f;\r\nstruct sk_buff *skb;\r\nstruct list_head *pos;\r\nif (list_empty(&t->ffree)) {\r\nif (t->falloc >= NSKBPOOLMAX*2)\r\nreturn NULL;\r\nf = kcalloc(1, sizeof(*f), GFP_ATOMIC);\r\nif (f == NULL)\r\nreturn NULL;\r\nt->falloc++;\r\nf->t = t;\r\n} else {\r\npos = t->ffree.next;\r\nlist_del(pos);\r\nf = list_entry(pos, struct frame, head);\r\n}\r\nskb = f->skb;\r\nif (skb == NULL) {\r\nf->skb = skb = new_skb(ETH_ZLEN);\r\nif (!skb) {\r\nbail: aoe_freetframe(f);\r\nreturn NULL;\r\n}\r\n}\r\nif (atomic_read(&skb_shinfo(skb)->dataref) != 1) {\r\nskb = skb_pool_get(d);\r\nif (skb == NULL)\r\ngoto bail;\r\nskb_pool_put(d, f->skb);\r\nf->skb = skb;\r\n}\r\nskb->truesize -= skb->data_len;\r\nskb_shinfo(skb)->nr_frags = skb->data_len = 0;\r\nskb_trim(skb, 0);\r\nreturn f;\r\n}\r\nstatic struct frame *\r\nnewframe(struct aoedev *d)\r\n{\r\nstruct frame *f;\r\nstruct aoetgt *t, **tt;\r\nint totout = 0;\r\nint use_tainted;\r\nint has_untainted;\r\nif (!d->targets || !d->targets[0]) {\r\nprintk(KERN_ERR "aoe: NULL TARGETS!\n");\r\nreturn NULL;\r\n}\r\ntt = d->tgt;\r\nfor (use_tainted = 0, has_untainted = 0;;) {\r\ntt++;\r\nif (tt >= &d->targets[d->ntargets] || !*tt)\r\ntt = d->targets;\r\nt = *tt;\r\nif (!t->taint) {\r\nhas_untainted = 1;\r\ntotout += t->nout;\r\n}\r\nif (t->nout < t->maxout\r\n&& (use_tainted || !t->taint)\r\n&& t->ifp->nd) {\r\nf = newtframe(d, t);\r\nif (f) {\r\nifrotate(t);\r\nd->tgt = tt;\r\nreturn f;\r\n}\r\n}\r\nif (tt == d->tgt) {\r\nif (!use_tainted && !has_untainted)\r\nuse_tainted = 1;\r\nelse\r\nbreak;\r\n}\r\n}\r\nif (totout == 0) {\r\nd->kicked++;\r\nd->flags |= DEVFL_KICKME;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void\r\nskb_fillup(struct sk_buff *skb, struct bio *bio, struct bvec_iter iter)\r\n{\r\nint frag = 0;\r\nstruct bio_vec bv;\r\n__bio_for_each_segment(bv, bio, iter, iter)\r\nskb_fill_page_desc(skb, frag++, bv.bv_page,\r\nbv.bv_offset, bv.bv_len);\r\n}\r\nstatic void\r\nfhash(struct frame *f)\r\n{\r\nstruct aoedev *d = f->t->d;\r\nu32 n;\r\nn = f->tag % NFACTIVE;\r\nlist_add_tail(&f->head, &d->factive[n]);\r\n}\r\nstatic void\r\nata_rw_frameinit(struct frame *f)\r\n{\r\nstruct aoetgt *t;\r\nstruct aoe_hdr *h;\r\nstruct aoe_atahdr *ah;\r\nstruct sk_buff *skb;\r\nchar writebit, extbit;\r\nskb = f->skb;\r\nh = (struct aoe_hdr *) skb_mac_header(skb);\r\nah = (struct aoe_atahdr *) (h + 1);\r\nskb_put(skb, sizeof(*h) + sizeof(*ah));\r\nmemset(h, 0, skb->len);\r\nwritebit = 0x10;\r\nextbit = 0x4;\r\nt = f->t;\r\nf->tag = aoehdr_atainit(t->d, t, h);\r\nfhash(f);\r\nt->nout++;\r\nf->waited = 0;\r\nf->waited_total = 0;\r\nah->scnt = f->iter.bi_size >> 9;\r\nput_lba(ah, f->iter.bi_sector);\r\nif (t->d->flags & DEVFL_EXT) {\r\nah->aflags |= AOEAFL_EXT;\r\n} else {\r\nextbit = 0;\r\nah->lba3 &= 0x0f;\r\nah->lba3 |= 0xe0;\r\n}\r\nif (f->buf && bio_data_dir(f->buf->bio) == WRITE) {\r\nskb_fillup(skb, f->buf->bio, f->iter);\r\nah->aflags |= AOEAFL_WRITE;\r\nskb->len += f->iter.bi_size;\r\nskb->data_len = f->iter.bi_size;\r\nskb->truesize += f->iter.bi_size;\r\nt->wpkts++;\r\n} else {\r\nt->rpkts++;\r\nwritebit = 0;\r\n}\r\nah->cmdstat = ATA_CMD_PIO_READ | writebit | extbit;\r\nskb->dev = t->ifp->nd;\r\n}\r\nstatic int\r\naoecmd_ata_rw(struct aoedev *d)\r\n{\r\nstruct frame *f;\r\nstruct buf *buf;\r\nstruct sk_buff *skb;\r\nstruct sk_buff_head queue;\r\nbuf = nextbuf(d);\r\nif (buf == NULL)\r\nreturn 0;\r\nf = newframe(d);\r\nif (f == NULL)\r\nreturn 0;\r\nf->buf = buf;\r\nf->iter = buf->iter;\r\nf->iter.bi_size = min_t(unsigned long,\r\nd->maxbcnt ?: DEFAULTBCNT,\r\nf->iter.bi_size);\r\nbio_advance_iter(buf->bio, &buf->iter, f->iter.bi_size);\r\nif (!buf->iter.bi_size)\r\nd->ip.buf = NULL;\r\nbuf->nframesout += 1;\r\nata_rw_frameinit(f);\r\nskb = skb_clone(f->skb, GFP_ATOMIC);\r\nif (skb) {\r\ndo_gettimeofday(&f->sent);\r\nf->sent_jiffs = (u32) jiffies;\r\n__skb_queue_head_init(&queue);\r\n__skb_queue_tail(&queue, skb);\r\naoenet_xmit(&queue);\r\n}\r\nreturn 1;\r\n}\r\nstatic void\r\naoecmd_cfg_pkts(ushort aoemajor, unsigned char aoeminor, struct sk_buff_head *queue)\r\n{\r\nstruct aoe_hdr *h;\r\nstruct aoe_cfghdr *ch;\r\nstruct sk_buff *skb;\r\nstruct net_device *ifp;\r\nrcu_read_lock();\r\nfor_each_netdev_rcu(&init_net, ifp) {\r\ndev_hold(ifp);\r\nif (!is_aoe_netif(ifp))\r\ngoto cont;\r\nskb = new_skb(sizeof *h + sizeof *ch);\r\nif (skb == NULL) {\r\nprintk(KERN_INFO "aoe: skb alloc failure\n");\r\ngoto cont;\r\n}\r\nskb_put(skb, sizeof *h + sizeof *ch);\r\nskb->dev = ifp;\r\n__skb_queue_tail(queue, skb);\r\nh = (struct aoe_hdr *) skb_mac_header(skb);\r\nmemset(h, 0, sizeof *h + sizeof *ch);\r\nmemset(h->dst, 0xff, sizeof h->dst);\r\nmemcpy(h->src, ifp->dev_addr, sizeof h->src);\r\nh->type = __constant_cpu_to_be16(ETH_P_AOE);\r\nh->verfl = AOE_HVER;\r\nh->major = cpu_to_be16(aoemajor);\r\nh->minor = aoeminor;\r\nh->cmd = AOECMD_CFG;\r\ncont:\r\ndev_put(ifp);\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic void\r\nresend(struct aoedev *d, struct frame *f)\r\n{\r\nstruct sk_buff *skb;\r\nstruct sk_buff_head queue;\r\nstruct aoe_hdr *h;\r\nstruct aoetgt *t;\r\nchar buf[128];\r\nu32 n;\r\nt = f->t;\r\nn = newtag(d);\r\nskb = f->skb;\r\nif (ifrotate(t) == NULL) {\r\npr_info("aoe: resend: no interfaces to rotate to.\n");\r\nktcomplete(f, NULL);\r\nreturn;\r\n}\r\nh = (struct aoe_hdr *) skb_mac_header(skb);\r\nif (!(f->flags & FFL_PROBE)) {\r\nsnprintf(buf, sizeof(buf),\r\n"%15s e%ld.%d oldtag=%08x@%08lx newtag=%08x s=%pm d=%pm nout=%d\n",\r\n"retransmit", d->aoemajor, d->aoeminor,\r\nf->tag, jiffies, n,\r\nh->src, h->dst, t->nout);\r\naoechr_error(buf);\r\n}\r\nf->tag = n;\r\nfhash(f);\r\nh->tag = cpu_to_be32(n);\r\nmemcpy(h->dst, t->addr, sizeof h->dst);\r\nmemcpy(h->src, t->ifp->nd->dev_addr, sizeof h->src);\r\nskb->dev = t->ifp->nd;\r\nskb = skb_clone(skb, GFP_ATOMIC);\r\nif (skb == NULL)\r\nreturn;\r\ndo_gettimeofday(&f->sent);\r\nf->sent_jiffs = (u32) jiffies;\r\n__skb_queue_head_init(&queue);\r\n__skb_queue_tail(&queue, skb);\r\naoenet_xmit(&queue);\r\n}\r\nstatic int\r\ntsince_hr(struct frame *f)\r\n{\r\nstruct timeval now;\r\nint n;\r\ndo_gettimeofday(&now);\r\nn = now.tv_usec - f->sent.tv_usec;\r\nn += (now.tv_sec - f->sent.tv_sec) * USEC_PER_SEC;\r\nif (n < 0)\r\nn = -n;\r\nif (n > USEC_PER_SEC / 4) {\r\nn = ((u32) jiffies) - f->sent_jiffs;\r\nn *= USEC_PER_SEC / HZ;\r\n}\r\nreturn n;\r\n}\r\nstatic int\r\ntsince(u32 tag)\r\n{\r\nint n;\r\nn = jiffies & 0xffff;\r\nn -= tag & 0xffff;\r\nif (n < 0)\r\nn += 1<<16;\r\nreturn jiffies_to_usecs(n + 1);\r\n}\r\nstatic struct aoeif *\r\ngetif(struct aoetgt *t, struct net_device *nd)\r\n{\r\nstruct aoeif *p, *e;\r\np = t->ifs;\r\ne = p + NAOEIFS;\r\nfor (; p < e; p++)\r\nif (p->nd == nd)\r\nreturn p;\r\nreturn NULL;\r\n}\r\nstatic void\r\nejectif(struct aoetgt *t, struct aoeif *ifp)\r\n{\r\nstruct aoeif *e;\r\nstruct net_device *nd;\r\nulong n;\r\nnd = ifp->nd;\r\ne = t->ifs + NAOEIFS - 1;\r\nn = (e - ifp) * sizeof *ifp;\r\nmemmove(ifp, ifp+1, n);\r\ne->nd = NULL;\r\ndev_put(nd);\r\n}\r\nstatic struct frame *\r\nreassign_frame(struct frame *f)\r\n{\r\nstruct frame *nf;\r\nstruct sk_buff *skb;\r\nnf = newframe(f->t->d);\r\nif (!nf)\r\nreturn NULL;\r\nif (nf->t == f->t) {\r\naoe_freetframe(nf);\r\nreturn NULL;\r\n}\r\nskb = nf->skb;\r\nnf->skb = f->skb;\r\nnf->buf = f->buf;\r\nnf->iter = f->iter;\r\nnf->waited = 0;\r\nnf->waited_total = f->waited_total;\r\nnf->sent = f->sent;\r\nnf->sent_jiffs = f->sent_jiffs;\r\nf->skb = skb;\r\nreturn nf;\r\n}\r\nstatic void\r\nprobe(struct aoetgt *t)\r\n{\r\nstruct aoedev *d;\r\nstruct frame *f;\r\nstruct sk_buff *skb;\r\nstruct sk_buff_head queue;\r\nsize_t n, m;\r\nint frag;\r\nd = t->d;\r\nf = newtframe(d, t);\r\nif (!f) {\r\npr_err("%s %pm for e%ld.%d: %s\n",\r\n"aoe: cannot probe remote address",\r\nt->addr,\r\n(long) d->aoemajor, d->aoeminor,\r\n"no frame available");\r\nreturn;\r\n}\r\nf->flags |= FFL_PROBE;\r\nifrotate(t);\r\nf->iter.bi_size = t->d->maxbcnt ? t->d->maxbcnt : DEFAULTBCNT;\r\nata_rw_frameinit(f);\r\nskb = f->skb;\r\nfor (frag = 0, n = f->iter.bi_size; n > 0; ++frag, n -= m) {\r\nif (n < PAGE_SIZE)\r\nm = n;\r\nelse\r\nm = PAGE_SIZE;\r\nskb_fill_page_desc(skb, frag, empty_page, 0, m);\r\n}\r\nskb->len += f->iter.bi_size;\r\nskb->data_len = f->iter.bi_size;\r\nskb->truesize += f->iter.bi_size;\r\nskb = skb_clone(f->skb, GFP_ATOMIC);\r\nif (skb) {\r\ndo_gettimeofday(&f->sent);\r\nf->sent_jiffs = (u32) jiffies;\r\n__skb_queue_head_init(&queue);\r\n__skb_queue_tail(&queue, skb);\r\naoenet_xmit(&queue);\r\n}\r\n}\r\nstatic long\r\nrto(struct aoedev *d)\r\n{\r\nlong t;\r\nt = 2 * d->rttavg >> RTTSCALE;\r\nt += 8 * d->rttdev >> RTTDSCALE;\r\nif (t == 0)\r\nt = 1;\r\nreturn t;\r\n}\r\nstatic void\r\nrexmit_deferred(struct aoedev *d)\r\n{\r\nstruct aoetgt *t;\r\nstruct frame *f;\r\nstruct frame *nf;\r\nstruct list_head *pos, *nx, *head;\r\nint since;\r\nint untainted;\r\ncount_targets(d, &untainted);\r\nhead = &d->rexmitq;\r\nlist_for_each_safe(pos, nx, head) {\r\nf = list_entry(pos, struct frame, head);\r\nt = f->t;\r\nif (t->taint) {\r\nif (!(f->flags & FFL_PROBE)) {\r\nnf = reassign_frame(f);\r\nif (nf) {\r\nif (t->nout_probes == 0\r\n&& untainted > 0) {\r\nprobe(t);\r\nt->nout_probes++;\r\n}\r\nlist_replace(&f->head, &nf->head);\r\npos = &nf->head;\r\naoe_freetframe(f);\r\nf = nf;\r\nt = f->t;\r\n}\r\n} else if (untainted < 1) {\r\ngoto stop_probe;\r\n} else if (tsince_hr(f) < t->taint * rto(d)) {\r\ncontinue;\r\n}\r\n} else if (f->flags & FFL_PROBE) {\r\nstop_probe:\r\nlist_del(pos);\r\naoe_freetframe(f);\r\nf->t->d->flags |= DEVFL_KICKME;\r\ncontinue;\r\n}\r\nif (t->nout >= t->maxout)\r\ncontinue;\r\nlist_del(pos);\r\nt->nout++;\r\nif (f->flags & FFL_PROBE)\r\nt->nout_probes++;\r\nsince = tsince_hr(f);\r\nf->waited += since;\r\nf->waited_total += since;\r\nresend(d, f);\r\n}\r\n}\r\nstatic void\r\nscorn(struct aoetgt *t)\r\n{\r\nint n;\r\nn = t->taint++;\r\nt->taint += t->taint * 2;\r\nif (n > t->taint)\r\nt->taint = n;\r\nif (t->taint > MAX_TAINT)\r\nt->taint = MAX_TAINT;\r\n}\r\nstatic int\r\ncount_targets(struct aoedev *d, int *untainted)\r\n{\r\nint i, good;\r\nfor (i = good = 0; i < d->ntargets && d->targets[i]; ++i)\r\nif (d->targets[i]->taint == 0)\r\ngood++;\r\nif (untainted)\r\n*untainted = good;\r\nreturn i;\r\n}\r\nstatic void\r\nrexmit_timer(ulong vp)\r\n{\r\nstruct aoedev *d;\r\nstruct aoetgt *t;\r\nstruct aoeif *ifp;\r\nstruct frame *f;\r\nstruct list_head *head, *pos, *nx;\r\nLIST_HEAD(flist);\r\nregister long timeout;\r\nulong flags, n;\r\nint i;\r\nint utgts;\r\nint since;\r\nd = (struct aoedev *) vp;\r\nspin_lock_irqsave(&d->lock, flags);\r\ntimeout = rto(d);\r\nutgts = count_targets(d, NULL);\r\nif (d->flags & DEVFL_TKILL) {\r\nspin_unlock_irqrestore(&d->lock, flags);\r\nreturn;\r\n}\r\nfor (i = 0; i < NFACTIVE; i++) {\r\nhead = &d->factive[i];\r\nlist_for_each_safe(pos, nx, head) {\r\nf = list_entry(pos, struct frame, head);\r\nif (tsince_hr(f) < timeout)\r\nbreak;\r\nlist_move_tail(pos, &flist);\r\n}\r\n}\r\nwhile (!list_empty(&flist)) {\r\npos = flist.next;\r\nf = list_entry(pos, struct frame, head);\r\nsince = tsince_hr(f);\r\nn = f->waited_total + since;\r\nn /= USEC_PER_SEC;\r\nif (aoe_deadsecs\r\n&& n > aoe_deadsecs\r\n&& !(f->flags & FFL_PROBE)) {\r\nlist_splice(&flist, &d->factive[0]);\r\naoedev_downdev(d);\r\ngoto out;\r\n}\r\nt = f->t;\r\nn = f->waited + since;\r\nn /= USEC_PER_SEC;\r\nif (aoe_deadsecs && utgts > 0\r\n&& (n > aoe_deadsecs / utgts || n > HARD_SCORN_SECS))\r\nscorn(t);\r\nif (t->maxout != 1) {\r\nt->ssthresh = t->maxout / 2;\r\nt->maxout = 1;\r\n}\r\nif (f->flags & FFL_PROBE) {\r\nt->nout_probes--;\r\n} else {\r\nifp = getif(t, f->skb->dev);\r\nif (ifp && ++ifp->lost > (t->nframes << 1)\r\n&& (ifp != t->ifs || t->ifs[1].nd)) {\r\nejectif(t, ifp);\r\nifp = NULL;\r\n}\r\n}\r\nlist_move_tail(pos, &d->rexmitq);\r\nt->nout--;\r\n}\r\nrexmit_deferred(d);\r\nout:\r\nif ((d->flags & DEVFL_KICKME) && d->blkq) {\r\nd->flags &= ~DEVFL_KICKME;\r\nd->blkq->request_fn(d->blkq);\r\n}\r\nd->timer.expires = jiffies + TIMERTICK;\r\nadd_timer(&d->timer);\r\nspin_unlock_irqrestore(&d->lock, flags);\r\n}\r\nstatic unsigned long\r\nrqbiocnt(struct request *r)\r\n{\r\nstruct bio *bio;\r\nunsigned long n = 0;\r\n__rq_for_each_bio(bio, r)\r\nn++;\r\nreturn n;\r\n}\r\nstatic void\r\nbufinit(struct buf *buf, struct request *rq, struct bio *bio)\r\n{\r\nmemset(buf, 0, sizeof(*buf));\r\nbuf->rq = rq;\r\nbuf->bio = bio;\r\nbuf->iter = bio->bi_iter;\r\n}\r\nstatic struct buf *\r\nnextbuf(struct aoedev *d)\r\n{\r\nstruct request *rq;\r\nstruct request_queue *q;\r\nstruct buf *buf;\r\nstruct bio *bio;\r\nq = d->blkq;\r\nif (q == NULL)\r\nreturn NULL;\r\nif (d->ip.buf)\r\nreturn d->ip.buf;\r\nrq = d->ip.rq;\r\nif (rq == NULL) {\r\nrq = blk_peek_request(q);\r\nif (rq == NULL)\r\nreturn NULL;\r\nblk_start_request(rq);\r\nd->ip.rq = rq;\r\nd->ip.nxbio = rq->bio;\r\nrq->special = (void *) rqbiocnt(rq);\r\n}\r\nbuf = mempool_alloc(d->bufpool, GFP_ATOMIC);\r\nif (buf == NULL) {\r\npr_err("aoe: nextbuf: unable to mempool_alloc!\n");\r\nreturn NULL;\r\n}\r\nbio = d->ip.nxbio;\r\nbufinit(buf, rq, bio);\r\nbio = bio->bi_next;\r\nd->ip.nxbio = bio;\r\nif (bio == NULL)\r\nd->ip.rq = NULL;\r\nreturn d->ip.buf = buf;\r\n}\r\nvoid\r\naoecmd_work(struct aoedev *d)\r\n{\r\nrexmit_deferred(d);\r\nwhile (aoecmd_ata_rw(d))\r\n;\r\n}\r\nvoid\r\naoecmd_sleepwork(struct work_struct *work)\r\n{\r\nstruct aoedev *d = container_of(work, struct aoedev, work);\r\nstruct block_device *bd;\r\nu64 ssize;\r\nif (d->flags & DEVFL_GDALLOC)\r\naoeblk_gdalloc(d);\r\nif (d->flags & DEVFL_NEWSIZE) {\r\nssize = get_capacity(d->gd);\r\nbd = bdget_disk(d->gd, 0);\r\nif (bd) {\r\ninode_lock(bd->bd_inode);\r\ni_size_write(bd->bd_inode, (loff_t)ssize<<9);\r\ninode_unlock(bd->bd_inode);\r\nbdput(bd);\r\n}\r\nspin_lock_irq(&d->lock);\r\nd->flags |= DEVFL_UP;\r\nd->flags &= ~DEVFL_NEWSIZE;\r\nspin_unlock_irq(&d->lock);\r\n}\r\n}\r\nstatic void\r\nata_ident_fixstring(u16 *id, int ns)\r\n{\r\nu16 s;\r\nwhile (ns-- > 0) {\r\ns = *id;\r\n*id++ = s >> 8 | s << 8;\r\n}\r\n}\r\nstatic void\r\nataid_complete(struct aoedev *d, struct aoetgt *t, unsigned char *id)\r\n{\r\nu64 ssize;\r\nu16 n;\r\nn = get_unaligned_le16(&id[83 << 1]);\r\nn |= get_unaligned_le16(&id[86 << 1]);\r\nif (n & (1<<10)) {\r\nd->flags |= DEVFL_EXT;\r\nssize = get_unaligned_le64(&id[100 << 1]);\r\nd->geo.cylinders = ssize;\r\nd->geo.cylinders /= (255 * 63);\r\nd->geo.heads = 255;\r\nd->geo.sectors = 63;\r\n} else {\r\nd->flags &= ~DEVFL_EXT;\r\nssize = get_unaligned_le32(&id[60 << 1]);\r\nd->geo.cylinders = get_unaligned_le16(&id[54 << 1]);\r\nd->geo.heads = get_unaligned_le16(&id[55 << 1]);\r\nd->geo.sectors = get_unaligned_le16(&id[56 << 1]);\r\n}\r\nata_ident_fixstring((u16 *) &id[10<<1], 10);\r\nata_ident_fixstring((u16 *) &id[23<<1], 4);\r\nata_ident_fixstring((u16 *) &id[27<<1], 20);\r\nmemcpy(d->ident, id, sizeof(d->ident));\r\nif (d->ssize != ssize)\r\nprintk(KERN_INFO\r\n"aoe: %pm e%ld.%d v%04x has %llu sectors\n",\r\nt->addr,\r\nd->aoemajor, d->aoeminor,\r\nd->fw_ver, (long long)ssize);\r\nd->ssize = ssize;\r\nd->geo.start = 0;\r\nif (d->flags & (DEVFL_GDALLOC|DEVFL_NEWSIZE))\r\nreturn;\r\nif (d->gd != NULL) {\r\nset_capacity(d->gd, ssize);\r\nd->flags |= DEVFL_NEWSIZE;\r\n} else\r\nd->flags |= DEVFL_GDALLOC;\r\nschedule_work(&d->work);\r\n}\r\nstatic void\r\ncalc_rttavg(struct aoedev *d, struct aoetgt *t, int rtt)\r\n{\r\nregister long n;\r\nn = rtt;\r\nn -= d->rttavg >> RTTSCALE;\r\nd->rttavg += n;\r\nif (n < 0)\r\nn = -n;\r\nn -= d->rttdev >> RTTDSCALE;\r\nd->rttdev += n;\r\nif (!t || t->maxout >= t->nframes)\r\nreturn;\r\nif (t->maxout < t->ssthresh)\r\nt->maxout += 1;\r\nelse if (t->nout == t->maxout && t->next_cwnd-- == 0) {\r\nt->maxout += 1;\r\nt->next_cwnd = t->maxout;\r\n}\r\n}\r\nstatic struct aoetgt *\r\ngettgt(struct aoedev *d, char *addr)\r\n{\r\nstruct aoetgt **t, **e;\r\nt = d->targets;\r\ne = t + d->ntargets;\r\nfor (; t < e && *t; t++)\r\nif (memcmp((*t)->addr, addr, sizeof((*t)->addr)) == 0)\r\nreturn *t;\r\nreturn NULL;\r\n}\r\nstatic void\r\nbvcpy(struct sk_buff *skb, struct bio *bio, struct bvec_iter iter, long cnt)\r\n{\r\nint soff = 0;\r\nstruct bio_vec bv;\r\niter.bi_size = cnt;\r\n__bio_for_each_segment(bv, bio, iter, iter) {\r\nchar *p = page_address(bv.bv_page) + bv.bv_offset;\r\nskb_copy_bits(skb, soff, p, bv.bv_len);\r\nsoff += bv.bv_len;\r\n}\r\n}\r\nvoid\r\naoe_end_request(struct aoedev *d, struct request *rq, int fastfail)\r\n{\r\nstruct bio *bio;\r\nint bok;\r\nstruct request_queue *q;\r\nq = d->blkq;\r\nif (rq == d->ip.rq)\r\nd->ip.rq = NULL;\r\ndo {\r\nbio = rq->bio;\r\nbok = !fastfail && !bio->bi_error;\r\n} while (__blk_end_request(rq, bok ? 0 : -EIO, bio->bi_iter.bi_size));\r\nif (!fastfail)\r\n__blk_run_queue(q);\r\n}\r\nstatic void\r\naoe_end_buf(struct aoedev *d, struct buf *buf)\r\n{\r\nstruct request *rq;\r\nunsigned long n;\r\nif (buf == d->ip.buf)\r\nd->ip.buf = NULL;\r\nrq = buf->rq;\r\nmempool_free(buf, d->bufpool);\r\nn = (unsigned long) rq->special;\r\nrq->special = (void *) --n;\r\nif (n == 0)\r\naoe_end_request(d, rq, 0);\r\n}\r\nstatic void\r\nktiocomplete(struct frame *f)\r\n{\r\nstruct aoe_hdr *hin, *hout;\r\nstruct aoe_atahdr *ahin, *ahout;\r\nstruct buf *buf;\r\nstruct sk_buff *skb;\r\nstruct aoetgt *t;\r\nstruct aoeif *ifp;\r\nstruct aoedev *d;\r\nlong n;\r\nint untainted;\r\nif (f == NULL)\r\nreturn;\r\nt = f->t;\r\nd = t->d;\r\nskb = f->r_skb;\r\nbuf = f->buf;\r\nif (f->flags & FFL_PROBE)\r\ngoto out;\r\nif (!skb)\r\ngoto noskb;\r\nhout = (struct aoe_hdr *) skb_mac_header(f->skb);\r\nahout = (struct aoe_atahdr *) (hout+1);\r\nhin = (struct aoe_hdr *) skb->data;\r\nskb_pull(skb, sizeof(*hin));\r\nahin = (struct aoe_atahdr *) skb->data;\r\nskb_pull(skb, sizeof(*ahin));\r\nif (ahin->cmdstat & 0xa9) {\r\npr_err("aoe: ata error cmd=%2.2Xh stat=%2.2Xh from e%ld.%d\n",\r\nahout->cmdstat, ahin->cmdstat,\r\nd->aoemajor, d->aoeminor);\r\nnoskb: if (buf)\r\nbuf->bio->bi_error = -EIO;\r\ngoto out;\r\n}\r\nn = ahout->scnt << 9;\r\nswitch (ahout->cmdstat) {\r\ncase ATA_CMD_PIO_READ:\r\ncase ATA_CMD_PIO_READ_EXT:\r\nif (skb->len < n) {\r\npr_err("%s e%ld.%d. skb->len=%d need=%ld\n",\r\n"aoe: runt data size in read from",\r\n(long) d->aoemajor, d->aoeminor,\r\nskb->len, n);\r\nbuf->bio->bi_error = -EIO;\r\nbreak;\r\n}\r\nif (n > f->iter.bi_size) {\r\npr_err_ratelimited("%s e%ld.%d. bytes=%ld need=%u\n",\r\n"aoe: too-large data size in read from",\r\n(long) d->aoemajor, d->aoeminor,\r\nn, f->iter.bi_size);\r\nbuf->bio->bi_error = -EIO;\r\nbreak;\r\n}\r\nbvcpy(skb, f->buf->bio, f->iter, n);\r\ncase ATA_CMD_PIO_WRITE:\r\ncase ATA_CMD_PIO_WRITE_EXT:\r\nspin_lock_irq(&d->lock);\r\nifp = getif(t, skb->dev);\r\nif (ifp)\r\nifp->lost = 0;\r\nspin_unlock_irq(&d->lock);\r\nbreak;\r\ncase ATA_CMD_ID_ATA:\r\nif (skb->len < 512) {\r\npr_info("%s e%ld.%d. skb->len=%d need=512\n",\r\n"aoe: runt data size in ataid from",\r\n(long) d->aoemajor, d->aoeminor,\r\nskb->len);\r\nbreak;\r\n}\r\nif (skb_linearize(skb))\r\nbreak;\r\nspin_lock_irq(&d->lock);\r\nataid_complete(d, t, skb->data);\r\nspin_unlock_irq(&d->lock);\r\nbreak;\r\ndefault:\r\npr_info("aoe: unrecognized ata command %2.2Xh for %d.%d\n",\r\nahout->cmdstat,\r\nbe16_to_cpu(get_unaligned(&hin->major)),\r\nhin->minor);\r\n}\r\nout:\r\nspin_lock_irq(&d->lock);\r\nif (t->taint > 0\r\n&& --t->taint > 0\r\n&& t->nout_probes == 0) {\r\ncount_targets(d, &untainted);\r\nif (untainted > 0) {\r\nprobe(t);\r\nt->nout_probes++;\r\n}\r\n}\r\naoe_freetframe(f);\r\nif (buf && --buf->nframesout == 0 && buf->iter.bi_size == 0)\r\naoe_end_buf(d, buf);\r\nspin_unlock_irq(&d->lock);\r\naoedev_put(d);\r\ndev_kfree_skb(skb);\r\n}\r\nstatic int\r\nktio(int id)\r\n{\r\nstruct frame *f;\r\nstruct list_head *pos;\r\nint i;\r\nint actual_id;\r\nfor (i = 0; ; ++i) {\r\nif (i == MAXIOC)\r\nreturn 1;\r\nif (list_empty(&iocq[id].head))\r\nreturn 0;\r\npos = iocq[id].head.next;\r\nlist_del(pos);\r\nf = list_entry(pos, struct frame, head);\r\nspin_unlock_irq(&iocq[id].lock);\r\nktiocomplete(f);\r\nactual_id = f->t->d->aoeminor % ncpus;\r\nif (!kts[actual_id].active) {\r\nBUG_ON(id != 0);\r\nmutex_lock(&ktio_spawn_lock);\r\nif (!kts[actual_id].active\r\n&& aoe_ktstart(&kts[actual_id]) == 0)\r\nkts[actual_id].active = 1;\r\nmutex_unlock(&ktio_spawn_lock);\r\n}\r\nspin_lock_irq(&iocq[id].lock);\r\n}\r\n}\r\nstatic int\r\nkthread(void *vp)\r\n{\r\nstruct ktstate *k;\r\nDECLARE_WAITQUEUE(wait, current);\r\nint more;\r\nk = vp;\r\ncurrent->flags |= PF_NOFREEZE;\r\nset_user_nice(current, -10);\r\ncomplete(&k->rendez);\r\ndo {\r\nspin_lock_irq(k->lock);\r\nmore = k->fn(k->id);\r\nif (!more) {\r\nadd_wait_queue(k->waitq, &wait);\r\n__set_current_state(TASK_INTERRUPTIBLE);\r\n}\r\nspin_unlock_irq(k->lock);\r\nif (!more) {\r\nschedule();\r\nremove_wait_queue(k->waitq, &wait);\r\n} else\r\ncond_resched();\r\n} while (!kthread_should_stop());\r\ncomplete(&k->rendez);\r\nreturn 0;\r\n}\r\nvoid\r\naoe_ktstop(struct ktstate *k)\r\n{\r\nkthread_stop(k->task);\r\nwait_for_completion(&k->rendez);\r\n}\r\nint\r\naoe_ktstart(struct ktstate *k)\r\n{\r\nstruct task_struct *task;\r\ninit_completion(&k->rendez);\r\ntask = kthread_run(kthread, k, "%s", k->name);\r\nif (task == NULL || IS_ERR(task))\r\nreturn -ENOMEM;\r\nk->task = task;\r\nwait_for_completion(&k->rendez);\r\ninit_completion(&k->rendez);\r\nreturn 0;\r\n}\r\nstatic void\r\nktcomplete(struct frame *f, struct sk_buff *skb)\r\n{\r\nint id;\r\nulong flags;\r\nf->r_skb = skb;\r\nid = f->t->d->aoeminor % ncpus;\r\nspin_lock_irqsave(&iocq[id].lock, flags);\r\nif (!kts[id].active) {\r\nspin_unlock_irqrestore(&iocq[id].lock, flags);\r\nid = 0;\r\nspin_lock_irqsave(&iocq[id].lock, flags);\r\n}\r\nlist_add_tail(&f->head, &iocq[id].head);\r\nspin_unlock_irqrestore(&iocq[id].lock, flags);\r\nwake_up(&ktiowq[id]);\r\n}\r\nstruct sk_buff *\r\naoecmd_ata_rsp(struct sk_buff *skb)\r\n{\r\nstruct aoedev *d;\r\nstruct aoe_hdr *h;\r\nstruct frame *f;\r\nu32 n;\r\nulong flags;\r\nchar ebuf[128];\r\nu16 aoemajor;\r\nh = (struct aoe_hdr *) skb->data;\r\naoemajor = be16_to_cpu(get_unaligned(&h->major));\r\nd = aoedev_by_aoeaddr(aoemajor, h->minor, 0);\r\nif (d == NULL) {\r\nsnprintf(ebuf, sizeof ebuf, "aoecmd_ata_rsp: ata response "\r\n"for unknown device %d.%d\n",\r\naoemajor, h->minor);\r\naoechr_error(ebuf);\r\nreturn skb;\r\n}\r\nspin_lock_irqsave(&d->lock, flags);\r\nn = be32_to_cpu(get_unaligned(&h->tag));\r\nf = getframe(d, n);\r\nif (f) {\r\ncalc_rttavg(d, f->t, tsince_hr(f));\r\nf->t->nout--;\r\nif (f->flags & FFL_PROBE)\r\nf->t->nout_probes--;\r\n} else {\r\nf = getframe_deferred(d, n);\r\nif (f) {\r\ncalc_rttavg(d, NULL, tsince_hr(f));\r\n} else {\r\ncalc_rttavg(d, NULL, tsince(n));\r\nspin_unlock_irqrestore(&d->lock, flags);\r\naoedev_put(d);\r\nsnprintf(ebuf, sizeof(ebuf),\r\n"%15s e%d.%d tag=%08x@%08lx s=%pm d=%pm\n",\r\n"unexpected rsp",\r\nget_unaligned_be16(&h->major),\r\nh->minor,\r\nget_unaligned_be32(&h->tag),\r\njiffies,\r\nh->src,\r\nh->dst);\r\naoechr_error(ebuf);\r\nreturn skb;\r\n}\r\n}\r\naoecmd_work(d);\r\nspin_unlock_irqrestore(&d->lock, flags);\r\nktcomplete(f, skb);\r\nreturn NULL;\r\n}\r\nvoid\r\naoecmd_cfg(ushort aoemajor, unsigned char aoeminor)\r\n{\r\nstruct sk_buff_head queue;\r\n__skb_queue_head_init(&queue);\r\naoecmd_cfg_pkts(aoemajor, aoeminor, &queue);\r\naoenet_xmit(&queue);\r\n}\r\nstruct sk_buff *\r\naoecmd_ata_id(struct aoedev *d)\r\n{\r\nstruct aoe_hdr *h;\r\nstruct aoe_atahdr *ah;\r\nstruct frame *f;\r\nstruct sk_buff *skb;\r\nstruct aoetgt *t;\r\nf = newframe(d);\r\nif (f == NULL)\r\nreturn NULL;\r\nt = *d->tgt;\r\nskb = f->skb;\r\nh = (struct aoe_hdr *) skb_mac_header(skb);\r\nah = (struct aoe_atahdr *) (h+1);\r\nskb_put(skb, sizeof *h + sizeof *ah);\r\nmemset(h, 0, skb->len);\r\nf->tag = aoehdr_atainit(d, t, h);\r\nfhash(f);\r\nt->nout++;\r\nf->waited = 0;\r\nf->waited_total = 0;\r\nah->scnt = 1;\r\nah->cmdstat = ATA_CMD_ID_ATA;\r\nah->lba3 = 0xa0;\r\nskb->dev = t->ifp->nd;\r\nd->rttavg = RTTAVG_INIT;\r\nd->rttdev = RTTDEV_INIT;\r\nd->timer.function = rexmit_timer;\r\nskb = skb_clone(skb, GFP_ATOMIC);\r\nif (skb) {\r\ndo_gettimeofday(&f->sent);\r\nf->sent_jiffs = (u32) jiffies;\r\n}\r\nreturn skb;\r\n}\r\nstatic struct aoetgt **\r\ngrow_targets(struct aoedev *d)\r\n{\r\nulong oldn, newn;\r\nstruct aoetgt **tt;\r\noldn = d->ntargets;\r\nnewn = oldn * 2;\r\ntt = kcalloc(newn, sizeof(*d->targets), GFP_ATOMIC);\r\nif (!tt)\r\nreturn NULL;\r\nmemmove(tt, d->targets, sizeof(*d->targets) * oldn);\r\nd->tgt = tt + (d->tgt - d->targets);\r\nkfree(d->targets);\r\nd->targets = tt;\r\nd->ntargets = newn;\r\nreturn &d->targets[oldn];\r\n}\r\nstatic struct aoetgt *\r\naddtgt(struct aoedev *d, char *addr, ulong nframes)\r\n{\r\nstruct aoetgt *t, **tt, **te;\r\ntt = d->targets;\r\nte = tt + d->ntargets;\r\nfor (; tt < te && *tt; tt++)\r\n;\r\nif (tt == te) {\r\ntt = grow_targets(d);\r\nif (!tt)\r\ngoto nomem;\r\n}\r\nt = kzalloc(sizeof(*t), GFP_ATOMIC);\r\nif (!t)\r\ngoto nomem;\r\nt->nframes = nframes;\r\nt->d = d;\r\nmemcpy(t->addr, addr, sizeof t->addr);\r\nt->ifp = t->ifs;\r\naoecmd_wreset(t);\r\nt->maxout = t->nframes / 2;\r\nINIT_LIST_HEAD(&t->ffree);\r\nreturn *tt = t;\r\nnomem:\r\npr_info("aoe: cannot allocate memory to add target\n");\r\nreturn NULL;\r\n}\r\nstatic void\r\nsetdbcnt(struct aoedev *d)\r\n{\r\nstruct aoetgt **t, **e;\r\nint bcnt = 0;\r\nt = d->targets;\r\ne = t + d->ntargets;\r\nfor (; t < e && *t; t++)\r\nif (bcnt == 0 || bcnt > (*t)->minbcnt)\r\nbcnt = (*t)->minbcnt;\r\nif (bcnt != d->maxbcnt) {\r\nd->maxbcnt = bcnt;\r\npr_info("aoe: e%ld.%d: setting %d byte data frames\n",\r\nd->aoemajor, d->aoeminor, bcnt);\r\n}\r\n}\r\nstatic void\r\nsetifbcnt(struct aoetgt *t, struct net_device *nd, int bcnt)\r\n{\r\nstruct aoedev *d;\r\nstruct aoeif *p, *e;\r\nint minbcnt;\r\nd = t->d;\r\nminbcnt = bcnt;\r\np = t->ifs;\r\ne = p + NAOEIFS;\r\nfor (; p < e; p++) {\r\nif (p->nd == NULL)\r\nbreak;\r\nif (p->nd == nd) {\r\np->bcnt = bcnt;\r\nnd = NULL;\r\n} else if (minbcnt > p->bcnt)\r\nminbcnt = p->bcnt;\r\n}\r\nif (nd) {\r\nif (p == e) {\r\npr_err("aoe: device setifbcnt failure; too many interfaces.\n");\r\nreturn;\r\n}\r\ndev_hold(nd);\r\np->nd = nd;\r\np->bcnt = bcnt;\r\n}\r\nt->minbcnt = minbcnt;\r\nsetdbcnt(d);\r\n}\r\nvoid\r\naoecmd_cfg_rsp(struct sk_buff *skb)\r\n{\r\nstruct aoedev *d;\r\nstruct aoe_hdr *h;\r\nstruct aoe_cfghdr *ch;\r\nstruct aoetgt *t;\r\nulong flags, aoemajor;\r\nstruct sk_buff *sl;\r\nstruct sk_buff_head queue;\r\nu16 n;\r\nsl = NULL;\r\nh = (struct aoe_hdr *) skb_mac_header(skb);\r\nch = (struct aoe_cfghdr *) (h+1);\r\naoemajor = get_unaligned_be16(&h->major);\r\nif (aoemajor == 0xfff) {\r\nprintk(KERN_ERR "aoe: Warning: shelf address is all ones. "\r\n"Check shelf dip switches.\n");\r\nreturn;\r\n}\r\nif (aoemajor == 0xffff) {\r\npr_info("aoe: e%ld.%d: broadcast shelf number invalid\n",\r\naoemajor, (int) h->minor);\r\nreturn;\r\n}\r\nif (h->minor == 0xff) {\r\npr_info("aoe: e%ld.%d: broadcast slot number invalid\n",\r\naoemajor, (int) h->minor);\r\nreturn;\r\n}\r\nn = be16_to_cpu(ch->bufcnt);\r\nif (n > aoe_maxout)\r\nn = aoe_maxout;\r\nd = aoedev_by_aoeaddr(aoemajor, h->minor, 1);\r\nif (d == NULL) {\r\npr_info("aoe: device allocation failure\n");\r\nreturn;\r\n}\r\nspin_lock_irqsave(&d->lock, flags);\r\nt = gettgt(d, h->src);\r\nif (t) {\r\nt->nframes = n;\r\nif (n < t->maxout)\r\naoecmd_wreset(t);\r\n} else {\r\nt = addtgt(d, h->src, n);\r\nif (!t)\r\ngoto bail;\r\n}\r\nn = skb->dev->mtu;\r\nn -= sizeof(struct aoe_hdr) + sizeof(struct aoe_atahdr);\r\nn /= 512;\r\nif (n > ch->scnt)\r\nn = ch->scnt;\r\nn = n ? n * 512 : DEFAULTBCNT;\r\nsetifbcnt(t, skb->dev, n);\r\nif (d->nopen == 0) {\r\nd->fw_ver = be16_to_cpu(ch->fwver);\r\nsl = aoecmd_ata_id(d);\r\n}\r\nbail:\r\nspin_unlock_irqrestore(&d->lock, flags);\r\naoedev_put(d);\r\nif (sl) {\r\n__skb_queue_head_init(&queue);\r\n__skb_queue_tail(&queue, sl);\r\naoenet_xmit(&queue);\r\n}\r\n}\r\nvoid\r\naoecmd_wreset(struct aoetgt *t)\r\n{\r\nt->maxout = 1;\r\nt->ssthresh = t->nframes / 2;\r\nt->next_cwnd = t->nframes;\r\n}\r\nvoid\r\naoecmd_cleanslate(struct aoedev *d)\r\n{\r\nstruct aoetgt **t, **te;\r\nd->rttavg = RTTAVG_INIT;\r\nd->rttdev = RTTDEV_INIT;\r\nd->maxbcnt = 0;\r\nt = d->targets;\r\nte = t + d->ntargets;\r\nfor (; t < te && *t; t++)\r\naoecmd_wreset(*t);\r\n}\r\nvoid\r\naoe_failbuf(struct aoedev *d, struct buf *buf)\r\n{\r\nif (buf == NULL)\r\nreturn;\r\nbuf->iter.bi_size = 0;\r\nbuf->bio->bi_error = -EIO;\r\nif (buf->nframesout == 0)\r\naoe_end_buf(d, buf);\r\n}\r\nvoid\r\naoe_flush_iocq(void)\r\n{\r\nint i;\r\nfor (i = 0; i < ncpus; i++) {\r\nif (kts[i].active)\r\naoe_flush_iocq_by_index(i);\r\n}\r\n}\r\nvoid\r\naoe_flush_iocq_by_index(int id)\r\n{\r\nstruct frame *f;\r\nstruct aoedev *d;\r\nLIST_HEAD(flist);\r\nstruct list_head *pos;\r\nstruct sk_buff *skb;\r\nulong flags;\r\nspin_lock_irqsave(&iocq[id].lock, flags);\r\nlist_splice_init(&iocq[id].head, &flist);\r\nspin_unlock_irqrestore(&iocq[id].lock, flags);\r\nwhile (!list_empty(&flist)) {\r\npos = flist.next;\r\nlist_del(pos);\r\nf = list_entry(pos, struct frame, head);\r\nd = f->t->d;\r\nskb = f->r_skb;\r\nspin_lock_irqsave(&d->lock, flags);\r\nif (f->buf) {\r\nf->buf->nframesout--;\r\naoe_failbuf(d, f->buf);\r\n}\r\naoe_freetframe(f);\r\nspin_unlock_irqrestore(&d->lock, flags);\r\ndev_kfree_skb(skb);\r\naoedev_put(d);\r\n}\r\n}\r\nint __init\r\naoecmd_init(void)\r\n{\r\nvoid *p;\r\nint i;\r\nint ret;\r\np = (void *) get_zeroed_page(GFP_KERNEL);\r\nif (!p)\r\nreturn -ENOMEM;\r\nempty_page = virt_to_page(p);\r\nncpus = num_online_cpus();\r\niocq = kcalloc(ncpus, sizeof(struct iocq_ktio), GFP_KERNEL);\r\nif (!iocq)\r\nreturn -ENOMEM;\r\nkts = kcalloc(ncpus, sizeof(struct ktstate), GFP_KERNEL);\r\nif (!kts) {\r\nret = -ENOMEM;\r\ngoto kts_fail;\r\n}\r\nktiowq = kcalloc(ncpus, sizeof(wait_queue_head_t), GFP_KERNEL);\r\nif (!ktiowq) {\r\nret = -ENOMEM;\r\ngoto ktiowq_fail;\r\n}\r\nmutex_init(&ktio_spawn_lock);\r\nfor (i = 0; i < ncpus; i++) {\r\nINIT_LIST_HEAD(&iocq[i].head);\r\nspin_lock_init(&iocq[i].lock);\r\ninit_waitqueue_head(&ktiowq[i]);\r\nsnprintf(kts[i].name, sizeof(kts[i].name), "aoe_ktio%d", i);\r\nkts[i].fn = ktio;\r\nkts[i].waitq = &ktiowq[i];\r\nkts[i].lock = &iocq[i].lock;\r\nkts[i].id = i;\r\nkts[i].active = 0;\r\n}\r\nkts[0].active = 1;\r\nif (aoe_ktstart(&kts[0])) {\r\nret = -ENOMEM;\r\ngoto ktstart_fail;\r\n}\r\nreturn 0;\r\nktstart_fail:\r\nkfree(ktiowq);\r\nktiowq_fail:\r\nkfree(kts);\r\nkts_fail:\r\nkfree(iocq);\r\nreturn ret;\r\n}\r\nvoid\r\naoecmd_exit(void)\r\n{\r\nint i;\r\nfor (i = 0; i < ncpus; i++)\r\nif (kts[i].active)\r\naoe_ktstop(&kts[i]);\r\naoe_flush_iocq();\r\nkfree(iocq);\r\nkfree(kts);\r\nkfree(ktiowq);\r\nfree_page((unsigned long) page_address(empty_page));\r\nempty_page = NULL;\r\n}
