static void release_port_group(struct kref *kref)\r\n{\r\nstruct alua_port_group *pg;\r\npg = container_of(kref, struct alua_port_group, kref);\r\nif (pg->rtpg_sdev)\r\nflush_delayed_work(&pg->rtpg_work);\r\nspin_lock(&port_group_lock);\r\nlist_del(&pg->node);\r\nspin_unlock(&port_group_lock);\r\nkfree_rcu(pg, rcu);\r\n}\r\nstatic int submit_rtpg(struct scsi_device *sdev, unsigned char *buff,\r\nint bufflen, struct scsi_sense_hdr *sshdr, int flags)\r\n{\r\nu8 cdb[COMMAND_SIZE(MAINTENANCE_IN)];\r\nint req_flags = REQ_FAILFAST_DEV | REQ_FAILFAST_TRANSPORT |\r\nREQ_FAILFAST_DRIVER;\r\nmemset(cdb, 0x0, COMMAND_SIZE(MAINTENANCE_IN));\r\ncdb[0] = MAINTENANCE_IN;\r\nif (!(flags & ALUA_RTPG_EXT_HDR_UNSUPP))\r\ncdb[1] = MI_REPORT_TARGET_PGS | MI_EXT_HDR_PARAM_FMT;\r\nelse\r\ncdb[1] = MI_REPORT_TARGET_PGS;\r\nput_unaligned_be32(bufflen, &cdb[6]);\r\nreturn scsi_execute(sdev, cdb, DMA_FROM_DEVICE, buff, bufflen, NULL,\r\nsshdr, ALUA_FAILOVER_TIMEOUT * HZ,\r\nALUA_FAILOVER_RETRIES, req_flags, 0, NULL);\r\n}\r\nstatic int submit_stpg(struct scsi_device *sdev, int group_id,\r\nstruct scsi_sense_hdr *sshdr)\r\n{\r\nu8 cdb[COMMAND_SIZE(MAINTENANCE_OUT)];\r\nunsigned char stpg_data[8];\r\nint stpg_len = 8;\r\nint req_flags = REQ_FAILFAST_DEV | REQ_FAILFAST_TRANSPORT |\r\nREQ_FAILFAST_DRIVER;\r\nmemset(stpg_data, 0, stpg_len);\r\nstpg_data[4] = SCSI_ACCESS_STATE_OPTIMAL;\r\nput_unaligned_be16(group_id, &stpg_data[6]);\r\nmemset(cdb, 0x0, COMMAND_SIZE(MAINTENANCE_OUT));\r\ncdb[0] = MAINTENANCE_OUT;\r\ncdb[1] = MO_SET_TARGET_PGS;\r\nput_unaligned_be32(stpg_len, &cdb[6]);\r\nreturn scsi_execute(sdev, cdb, DMA_TO_DEVICE, stpg_data, stpg_len, NULL,\r\nsshdr, ALUA_FAILOVER_TIMEOUT * HZ,\r\nALUA_FAILOVER_RETRIES, req_flags, 0, NULL);\r\n}\r\nstatic struct alua_port_group *alua_find_get_pg(char *id_str, size_t id_size,\r\nint group_id)\r\n{\r\nstruct alua_port_group *pg;\r\nif (!id_str || !id_size || !strlen(id_str))\r\nreturn NULL;\r\nlist_for_each_entry(pg, &port_group_list, node) {\r\nif (pg->group_id != group_id)\r\ncontinue;\r\nif (!pg->device_id_len || pg->device_id_len != id_size)\r\ncontinue;\r\nif (strncmp(pg->device_id_str, id_str, id_size))\r\ncontinue;\r\nif (!kref_get_unless_zero(&pg->kref))\r\ncontinue;\r\nreturn pg;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct alua_port_group *alua_alloc_pg(struct scsi_device *sdev,\r\nint group_id, int tpgs)\r\n{\r\nstruct alua_port_group *pg, *tmp_pg;\r\npg = kzalloc(sizeof(struct alua_port_group), GFP_KERNEL);\r\nif (!pg)\r\nreturn ERR_PTR(-ENOMEM);\r\npg->device_id_len = scsi_vpd_lun_id(sdev, pg->device_id_str,\r\nsizeof(pg->device_id_str));\r\nif (pg->device_id_len <= 0) {\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: No device descriptors found\n",\r\nALUA_DH_NAME);\r\npg->device_id_str[0] = '\0';\r\npg->device_id_len = 0;\r\n}\r\npg->group_id = group_id;\r\npg->tpgs = tpgs;\r\npg->state = SCSI_ACCESS_STATE_OPTIMAL;\r\nif (optimize_stpg)\r\npg->flags |= ALUA_OPTIMIZE_STPG;\r\nkref_init(&pg->kref);\r\nINIT_DELAYED_WORK(&pg->rtpg_work, alua_rtpg_work);\r\nINIT_LIST_HEAD(&pg->rtpg_list);\r\nINIT_LIST_HEAD(&pg->node);\r\nINIT_LIST_HEAD(&pg->dh_list);\r\nspin_lock_init(&pg->lock);\r\nspin_lock(&port_group_lock);\r\ntmp_pg = alua_find_get_pg(pg->device_id_str, pg->device_id_len,\r\ngroup_id);\r\nif (tmp_pg) {\r\nspin_unlock(&port_group_lock);\r\nkfree(pg);\r\nreturn tmp_pg;\r\n}\r\nlist_add(&pg->node, &port_group_list);\r\nspin_unlock(&port_group_lock);\r\nreturn pg;\r\n}\r\nstatic int alua_check_tpgs(struct scsi_device *sdev)\r\n{\r\nint tpgs = TPGS_MODE_NONE;\r\nif (sdev->type != TYPE_DISK) {\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: disable for non-disk devices\n",\r\nALUA_DH_NAME);\r\nreturn tpgs;\r\n}\r\ntpgs = scsi_device_tpgs(sdev);\r\nswitch (tpgs) {\r\ncase TPGS_MODE_EXPLICIT|TPGS_MODE_IMPLICIT:\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: supports implicit and explicit TPGS\n",\r\nALUA_DH_NAME);\r\nbreak;\r\ncase TPGS_MODE_EXPLICIT:\r\nsdev_printk(KERN_INFO, sdev, "%s: supports explicit TPGS\n",\r\nALUA_DH_NAME);\r\nbreak;\r\ncase TPGS_MODE_IMPLICIT:\r\nsdev_printk(KERN_INFO, sdev, "%s: supports implicit TPGS\n",\r\nALUA_DH_NAME);\r\nbreak;\r\ncase TPGS_MODE_NONE:\r\nsdev_printk(KERN_INFO, sdev, "%s: not supported\n",\r\nALUA_DH_NAME);\r\nbreak;\r\ndefault:\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: unsupported TPGS setting %d\n",\r\nALUA_DH_NAME, tpgs);\r\ntpgs = TPGS_MODE_NONE;\r\nbreak;\r\n}\r\nreturn tpgs;\r\n}\r\nstatic int alua_check_vpd(struct scsi_device *sdev, struct alua_dh_data *h,\r\nint tpgs)\r\n{\r\nint rel_port = -1, group_id;\r\nstruct alua_port_group *pg, *old_pg = NULL;\r\nbool pg_updated = false;\r\nunsigned long flags;\r\ngroup_id = scsi_vpd_tpg_id(sdev, &rel_port);\r\nif (group_id < 0) {\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: No target port descriptors found\n",\r\nALUA_DH_NAME);\r\nreturn SCSI_DH_DEV_UNSUPP;\r\n}\r\npg = alua_alloc_pg(sdev, group_id, tpgs);\r\nif (IS_ERR(pg)) {\r\nif (PTR_ERR(pg) == -ENOMEM)\r\nreturn SCSI_DH_NOMEM;\r\nreturn SCSI_DH_DEV_UNSUPP;\r\n}\r\nif (pg->device_id_len)\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: device %s port group %x rel port %x\n",\r\nALUA_DH_NAME, pg->device_id_str,\r\ngroup_id, rel_port);\r\nelse\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: port group %x rel port %x\n",\r\nALUA_DH_NAME, group_id, rel_port);\r\nspin_lock(&h->pg_lock);\r\nold_pg = rcu_dereference_protected(h->pg, lockdep_is_held(&h->pg_lock));\r\nif (old_pg != pg) {\r\nif (h->pg) {\r\nspin_lock_irqsave(&old_pg->lock, flags);\r\nlist_del_rcu(&h->node);\r\nspin_unlock_irqrestore(&old_pg->lock, flags);\r\n}\r\nrcu_assign_pointer(h->pg, pg);\r\npg_updated = true;\r\n}\r\nspin_lock_irqsave(&pg->lock, flags);\r\nif (sdev->synchronous_alua)\r\npg->flags |= ALUA_SYNC_STPG;\r\nif (pg_updated)\r\nlist_add_rcu(&h->node, &pg->dh_list);\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nalua_rtpg_queue(rcu_dereference_protected(h->pg,\r\nlockdep_is_held(&h->pg_lock)),\r\nsdev, NULL, true);\r\nspin_unlock(&h->pg_lock);\r\nif (old_pg)\r\nkref_put(&old_pg->kref, release_port_group);\r\nreturn SCSI_DH_OK;\r\n}\r\nstatic char print_alua_state(unsigned char state)\r\n{\r\nswitch (state) {\r\ncase SCSI_ACCESS_STATE_OPTIMAL:\r\nreturn 'A';\r\ncase SCSI_ACCESS_STATE_ACTIVE:\r\nreturn 'N';\r\ncase SCSI_ACCESS_STATE_STANDBY:\r\nreturn 'S';\r\ncase SCSI_ACCESS_STATE_UNAVAILABLE:\r\nreturn 'U';\r\ncase SCSI_ACCESS_STATE_LBA:\r\nreturn 'L';\r\ncase SCSI_ACCESS_STATE_OFFLINE:\r\nreturn 'O';\r\ncase SCSI_ACCESS_STATE_TRANSITIONING:\r\nreturn 'T';\r\ndefault:\r\nreturn 'X';\r\n}\r\n}\r\nstatic int alua_check_sense(struct scsi_device *sdev,\r\nstruct scsi_sense_hdr *sense_hdr)\r\n{\r\nswitch (sense_hdr->sense_key) {\r\ncase NOT_READY:\r\nif (sense_hdr->asc == 0x04 && sense_hdr->ascq == 0x0a) {\r\nalua_check(sdev, false);\r\nreturn NEEDS_RETRY;\r\n}\r\nbreak;\r\ncase UNIT_ATTENTION:\r\nif (sense_hdr->asc == 0x29 && sense_hdr->ascq == 0x00) {\r\nalua_check(sdev, true);\r\nreturn ADD_TO_MLQUEUE;\r\n}\r\nif (sense_hdr->asc == 0x29 && sense_hdr->ascq == 0x04)\r\nreturn ADD_TO_MLQUEUE;\r\nif (sense_hdr->asc == 0x2a && sense_hdr->ascq == 0x01)\r\nreturn ADD_TO_MLQUEUE;\r\nif (sense_hdr->asc == 0x2a && sense_hdr->ascq == 0x06) {\r\nalua_check(sdev, true);\r\nreturn ADD_TO_MLQUEUE;\r\n}\r\nif (sense_hdr->asc == 0x2a && sense_hdr->ascq == 0x07) {\r\nalua_check(sdev, true);\r\nreturn ADD_TO_MLQUEUE;\r\n}\r\nif (sense_hdr->asc == 0x3f && sense_hdr->ascq == 0x03)\r\nreturn ADD_TO_MLQUEUE;\r\nif (sense_hdr->asc == 0x3f && sense_hdr->ascq == 0x0e)\r\nreturn ADD_TO_MLQUEUE;\r\nbreak;\r\n}\r\nreturn SCSI_RETURN_NOT_HANDLED;\r\n}\r\nstatic int alua_tur(struct scsi_device *sdev)\r\n{\r\nstruct scsi_sense_hdr sense_hdr;\r\nint retval;\r\nretval = scsi_test_unit_ready(sdev, ALUA_FAILOVER_TIMEOUT * HZ,\r\nALUA_FAILOVER_RETRIES, &sense_hdr);\r\nif (sense_hdr.sense_key == NOT_READY &&\r\nsense_hdr.asc == 0x04 && sense_hdr.ascq == 0x0a)\r\nreturn SCSI_DH_RETRY;\r\nelse if (retval)\r\nreturn SCSI_DH_IO;\r\nelse\r\nreturn SCSI_DH_OK;\r\n}\r\nstatic int alua_rtpg(struct scsi_device *sdev, struct alua_port_group *pg)\r\n{\r\nstruct scsi_sense_hdr sense_hdr;\r\nstruct alua_port_group *tmp_pg;\r\nint len, k, off, valid_states = 0, bufflen = ALUA_RTPG_SIZE;\r\nunsigned char *desc, *buff;\r\nunsigned err, retval;\r\nunsigned int tpg_desc_tbl_off;\r\nunsigned char orig_transition_tmo;\r\nunsigned long flags;\r\nif (!pg->expiry) {\r\nunsigned long transition_tmo = ALUA_FAILOVER_TIMEOUT * HZ;\r\nif (pg->transition_tmo)\r\ntransition_tmo = pg->transition_tmo * HZ;\r\npg->expiry = round_jiffies_up(jiffies + transition_tmo);\r\n}\r\nbuff = kzalloc(bufflen, GFP_KERNEL);\r\nif (!buff)\r\nreturn SCSI_DH_DEV_TEMP_BUSY;\r\nretry:\r\nerr = 0;\r\nretval = submit_rtpg(sdev, buff, bufflen, &sense_hdr, pg->flags);\r\nif (retval) {\r\nif (!scsi_sense_valid(&sense_hdr)) {\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: rtpg failed, result %d\n",\r\nALUA_DH_NAME, retval);\r\nkfree(buff);\r\nif (driver_byte(retval) == DRIVER_ERROR)\r\nreturn SCSI_DH_DEV_TEMP_BUSY;\r\nreturn SCSI_DH_IO;\r\n}\r\nif (!(pg->flags & ALUA_RTPG_EXT_HDR_UNSUPP) &&\r\nsense_hdr.sense_key == ILLEGAL_REQUEST &&\r\nsense_hdr.asc == 0x24 && sense_hdr.ascq == 0) {\r\npg->flags |= ALUA_RTPG_EXT_HDR_UNSUPP;\r\ngoto retry;\r\n}\r\nif (sense_hdr.sense_key == NOT_READY &&\r\nsense_hdr.asc == 0x04 && sense_hdr.ascq == 0x0a)\r\nerr = SCSI_DH_RETRY;\r\nelse if (sense_hdr.sense_key == UNIT_ATTENTION)\r\nerr = SCSI_DH_RETRY;\r\nif (err == SCSI_DH_RETRY &&\r\npg->expiry != 0 && time_before(jiffies, pg->expiry)) {\r\nsdev_printk(KERN_ERR, sdev, "%s: rtpg retry\n",\r\nALUA_DH_NAME);\r\nscsi_print_sense_hdr(sdev, ALUA_DH_NAME, &sense_hdr);\r\nkfree(buff);\r\nreturn err;\r\n}\r\nsdev_printk(KERN_ERR, sdev, "%s: rtpg failed\n",\r\nALUA_DH_NAME);\r\nscsi_print_sense_hdr(sdev, ALUA_DH_NAME, &sense_hdr);\r\nkfree(buff);\r\npg->expiry = 0;\r\nreturn SCSI_DH_IO;\r\n}\r\nlen = get_unaligned_be32(&buff[0]) + 4;\r\nif (len > bufflen) {\r\nkfree(buff);\r\nbufflen = len;\r\nbuff = kmalloc(bufflen, GFP_KERNEL);\r\nif (!buff) {\r\nsdev_printk(KERN_WARNING, sdev,\r\n"%s: kmalloc buffer failed\n",__func__);\r\npg->expiry = 0;\r\nreturn SCSI_DH_DEV_TEMP_BUSY;\r\n}\r\ngoto retry;\r\n}\r\norig_transition_tmo = pg->transition_tmo;\r\nif ((buff[4] & RTPG_FMT_MASK) == RTPG_FMT_EXT_HDR && buff[5] != 0)\r\npg->transition_tmo = buff[5];\r\nelse\r\npg->transition_tmo = ALUA_FAILOVER_TIMEOUT;\r\nif (orig_transition_tmo != pg->transition_tmo) {\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: transition timeout set to %d seconds\n",\r\nALUA_DH_NAME, pg->transition_tmo);\r\npg->expiry = jiffies + pg->transition_tmo * HZ;\r\n}\r\nif ((buff[4] & RTPG_FMT_MASK) == RTPG_FMT_EXT_HDR)\r\ntpg_desc_tbl_off = 8;\r\nelse\r\ntpg_desc_tbl_off = 4;\r\nfor (k = tpg_desc_tbl_off, desc = buff + tpg_desc_tbl_off;\r\nk < len;\r\nk += off, desc += off) {\r\nu16 group_id = get_unaligned_be16(&desc[2]);\r\nspin_lock_irqsave(&port_group_lock, flags);\r\ntmp_pg = alua_find_get_pg(pg->device_id_str, pg->device_id_len,\r\ngroup_id);\r\nspin_unlock_irqrestore(&port_group_lock, flags);\r\nif (tmp_pg) {\r\nif (spin_trylock_irqsave(&tmp_pg->lock, flags)) {\r\nif ((tmp_pg == pg) ||\r\n!(tmp_pg->flags & ALUA_PG_RUNNING)) {\r\nstruct alua_dh_data *h;\r\ntmp_pg->state = desc[0] & 0x0f;\r\ntmp_pg->pref = desc[0] >> 7;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(h,\r\n&tmp_pg->dh_list, node) {\r\nBUG_ON(!h->sdev);\r\nh->sdev->access_state = desc[0];\r\n}\r\nrcu_read_unlock();\r\n}\r\nif (tmp_pg == pg)\r\nvalid_states = desc[1];\r\nspin_unlock_irqrestore(&tmp_pg->lock, flags);\r\n}\r\nkref_put(&tmp_pg->kref, release_port_group);\r\n}\r\noff = 8 + (desc[7] * 4);\r\n}\r\nspin_lock_irqsave(&pg->lock, flags);\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: port group %02x state %c %s supports %c%c%c%c%c%c%c\n",\r\nALUA_DH_NAME, pg->group_id, print_alua_state(pg->state),\r\npg->pref ? "preferred" : "non-preferred",\r\nvalid_states&TPGS_SUPPORT_TRANSITION?'T':'t',\r\nvalid_states&TPGS_SUPPORT_OFFLINE?'O':'o',\r\nvalid_states&TPGS_SUPPORT_LBA_DEPENDENT?'L':'l',\r\nvalid_states&TPGS_SUPPORT_UNAVAILABLE?'U':'u',\r\nvalid_states&TPGS_SUPPORT_STANDBY?'S':'s',\r\nvalid_states&TPGS_SUPPORT_NONOPTIMIZED?'N':'n',\r\nvalid_states&TPGS_SUPPORT_OPTIMIZED?'A':'a');\r\nswitch (pg->state) {\r\ncase SCSI_ACCESS_STATE_TRANSITIONING:\r\nif (time_before(jiffies, pg->expiry)) {\r\npg->interval = 2;\r\nerr = SCSI_DH_RETRY;\r\n} else {\r\nstruct alua_dh_data *h;\r\nerr = SCSI_DH_IO;\r\npg->state = SCSI_ACCESS_STATE_STANDBY;\r\npg->expiry = 0;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(h, &pg->dh_list, node) {\r\nBUG_ON(!h->sdev);\r\nh->sdev->access_state =\r\n(pg->state & SCSI_ACCESS_STATE_MASK);\r\nif (pg->pref)\r\nh->sdev->access_state |=\r\nSCSI_ACCESS_STATE_PREFERRED;\r\n}\r\nrcu_read_unlock();\r\n}\r\nbreak;\r\ncase SCSI_ACCESS_STATE_OFFLINE:\r\nerr = SCSI_DH_DEV_OFFLINED;\r\npg->expiry = 0;\r\nbreak;\r\ndefault:\r\nerr = SCSI_DH_OK;\r\npg->expiry = 0;\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nkfree(buff);\r\nreturn err;\r\n}\r\nstatic unsigned alua_stpg(struct scsi_device *sdev, struct alua_port_group *pg)\r\n{\r\nint retval;\r\nstruct scsi_sense_hdr sense_hdr;\r\nif (!(pg->tpgs & TPGS_MODE_EXPLICIT)) {\r\nreturn SCSI_DH_RETRY;\r\n}\r\nswitch (pg->state) {\r\ncase SCSI_ACCESS_STATE_OPTIMAL:\r\nreturn SCSI_DH_OK;\r\ncase SCSI_ACCESS_STATE_ACTIVE:\r\nif ((pg->flags & ALUA_OPTIMIZE_STPG) &&\r\n!pg->pref &&\r\n(pg->tpgs & TPGS_MODE_IMPLICIT))\r\nreturn SCSI_DH_OK;\r\nbreak;\r\ncase SCSI_ACCESS_STATE_STANDBY:\r\ncase SCSI_ACCESS_STATE_UNAVAILABLE:\r\nbreak;\r\ncase SCSI_ACCESS_STATE_OFFLINE:\r\nreturn SCSI_DH_IO;\r\ncase SCSI_ACCESS_STATE_TRANSITIONING:\r\nbreak;\r\ndefault:\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: stpg failed, unhandled TPGS state %d",\r\nALUA_DH_NAME, pg->state);\r\nreturn SCSI_DH_NOSYS;\r\n}\r\nretval = submit_stpg(sdev, pg->group_id, &sense_hdr);\r\nif (retval) {\r\nif (!scsi_sense_valid(&sense_hdr)) {\r\nsdev_printk(KERN_INFO, sdev,\r\n"%s: stpg failed, result %d",\r\nALUA_DH_NAME, retval);\r\nif (driver_byte(retval) == DRIVER_ERROR)\r\nreturn SCSI_DH_DEV_TEMP_BUSY;\r\n} else {\r\nsdev_printk(KERN_INFO, sdev, "%s: stpg failed\n",\r\nALUA_DH_NAME);\r\nscsi_print_sense_hdr(sdev, ALUA_DH_NAME, &sense_hdr);\r\n}\r\n}\r\nreturn SCSI_DH_RETRY;\r\n}\r\nstatic void alua_rtpg_work(struct work_struct *work)\r\n{\r\nstruct alua_port_group *pg =\r\ncontainer_of(work, struct alua_port_group, rtpg_work.work);\r\nstruct scsi_device *sdev;\r\nLIST_HEAD(qdata_list);\r\nint err = SCSI_DH_OK;\r\nstruct alua_queue_data *qdata, *tmp;\r\nunsigned long flags;\r\nstruct workqueue_struct *alua_wq = kaluad_wq;\r\nspin_lock_irqsave(&pg->lock, flags);\r\nsdev = pg->rtpg_sdev;\r\nif (!sdev) {\r\nWARN_ON(pg->flags & ALUA_PG_RUN_RTPG);\r\nWARN_ON(pg->flags & ALUA_PG_RUN_STPG);\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nkref_put(&pg->kref, release_port_group);\r\nreturn;\r\n}\r\nif (pg->flags & ALUA_SYNC_STPG)\r\nalua_wq = kaluad_sync_wq;\r\npg->flags |= ALUA_PG_RUNNING;\r\nif (pg->flags & ALUA_PG_RUN_RTPG) {\r\nint state = pg->state;\r\npg->flags &= ~ALUA_PG_RUN_RTPG;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nif (state == SCSI_ACCESS_STATE_TRANSITIONING) {\r\nif (alua_tur(sdev) == SCSI_DH_RETRY) {\r\nspin_lock_irqsave(&pg->lock, flags);\r\npg->flags &= ~ALUA_PG_RUNNING;\r\npg->flags |= ALUA_PG_RUN_RTPG;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nqueue_delayed_work(alua_wq, &pg->rtpg_work,\r\npg->interval * HZ);\r\nreturn;\r\n}\r\n}\r\nerr = alua_rtpg(sdev, pg);\r\nspin_lock_irqsave(&pg->lock, flags);\r\nif (err == SCSI_DH_RETRY || pg->flags & ALUA_PG_RUN_RTPG) {\r\npg->flags &= ~ALUA_PG_RUNNING;\r\npg->flags |= ALUA_PG_RUN_RTPG;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nqueue_delayed_work(alua_wq, &pg->rtpg_work,\r\npg->interval * HZ);\r\nreturn;\r\n}\r\nif (err != SCSI_DH_OK)\r\npg->flags &= ~ALUA_PG_RUN_STPG;\r\n}\r\nif (pg->flags & ALUA_PG_RUN_STPG) {\r\npg->flags &= ~ALUA_PG_RUN_STPG;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nerr = alua_stpg(sdev, pg);\r\nspin_lock_irqsave(&pg->lock, flags);\r\nif (err == SCSI_DH_RETRY || pg->flags & ALUA_PG_RUN_RTPG) {\r\npg->flags |= ALUA_PG_RUN_RTPG;\r\npg->interval = 0;\r\npg->flags &= ~ALUA_PG_RUNNING;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nqueue_delayed_work(alua_wq, &pg->rtpg_work,\r\npg->interval * HZ);\r\nreturn;\r\n}\r\n}\r\nlist_splice_init(&pg->rtpg_list, &qdata_list);\r\npg->rtpg_sdev = NULL;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nlist_for_each_entry_safe(qdata, tmp, &qdata_list, entry) {\r\nlist_del(&qdata->entry);\r\nif (qdata->callback_fn)\r\nqdata->callback_fn(qdata->callback_data, err);\r\nkfree(qdata);\r\n}\r\nspin_lock_irqsave(&pg->lock, flags);\r\npg->flags &= ~ALUA_PG_RUNNING;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nscsi_device_put(sdev);\r\nkref_put(&pg->kref, release_port_group);\r\n}\r\nstatic bool alua_rtpg_queue(struct alua_port_group *pg,\r\nstruct scsi_device *sdev,\r\nstruct alua_queue_data *qdata, bool force)\r\n{\r\nint start_queue = 0;\r\nunsigned long flags;\r\nstruct workqueue_struct *alua_wq = kaluad_wq;\r\nif (WARN_ON_ONCE(!pg) || scsi_device_get(sdev))\r\nreturn false;\r\nspin_lock_irqsave(&pg->lock, flags);\r\nif (qdata) {\r\nlist_add_tail(&qdata->entry, &pg->rtpg_list);\r\npg->flags |= ALUA_PG_RUN_STPG;\r\nforce = true;\r\n}\r\nif (pg->rtpg_sdev == NULL) {\r\npg->interval = 0;\r\npg->flags |= ALUA_PG_RUN_RTPG;\r\nkref_get(&pg->kref);\r\npg->rtpg_sdev = sdev;\r\nstart_queue = 1;\r\n} else if (!(pg->flags & ALUA_PG_RUN_RTPG) && force) {\r\npg->flags |= ALUA_PG_RUN_RTPG;\r\nif (!(pg->flags & ALUA_PG_RUNNING)) {\r\nkref_get(&pg->kref);\r\nstart_queue = 1;\r\n}\r\n}\r\nif (pg->flags & ALUA_SYNC_STPG)\r\nalua_wq = kaluad_sync_wq;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nif (start_queue) {\r\nif (queue_delayed_work(alua_wq, &pg->rtpg_work,\r\nmsecs_to_jiffies(ALUA_RTPG_DELAY_MSECS)))\r\nsdev = NULL;\r\nelse\r\nkref_put(&pg->kref, release_port_group);\r\n}\r\nif (sdev)\r\nscsi_device_put(sdev);\r\nreturn true;\r\n}\r\nstatic int alua_initialize(struct scsi_device *sdev, struct alua_dh_data *h)\r\n{\r\nint err = SCSI_DH_DEV_UNSUPP, tpgs;\r\nmutex_lock(&h->init_mutex);\r\ntpgs = alua_check_tpgs(sdev);\r\nif (tpgs != TPGS_MODE_NONE)\r\nerr = alua_check_vpd(sdev, h, tpgs);\r\nh->init_error = err;\r\nmutex_unlock(&h->init_mutex);\r\nreturn err;\r\n}\r\nstatic int alua_set_params(struct scsi_device *sdev, const char *params)\r\n{\r\nstruct alua_dh_data *h = sdev->handler_data;\r\nstruct alua_port_group *pg = NULL;\r\nunsigned int optimize = 0, argc;\r\nconst char *p = params;\r\nint result = SCSI_DH_OK;\r\nunsigned long flags;\r\nif ((sscanf(params, "%u", &argc) != 1) || (argc != 1))\r\nreturn -EINVAL;\r\nwhile (*p++)\r\n;\r\nif ((sscanf(p, "%u", &optimize) != 1) || (optimize > 1))\r\nreturn -EINVAL;\r\nrcu_read_lock();\r\npg = rcu_dereference(h->pg);\r\nif (!pg) {\r\nrcu_read_unlock();\r\nreturn -ENXIO;\r\n}\r\nspin_lock_irqsave(&pg->lock, flags);\r\nif (optimize)\r\npg->flags |= ALUA_OPTIMIZE_STPG;\r\nelse\r\npg->flags &= ~ALUA_OPTIMIZE_STPG;\r\nspin_unlock_irqrestore(&pg->lock, flags);\r\nrcu_read_unlock();\r\nreturn result;\r\n}\r\nstatic int alua_activate(struct scsi_device *sdev,\r\nactivate_complete fn, void *data)\r\n{\r\nstruct alua_dh_data *h = sdev->handler_data;\r\nint err = SCSI_DH_OK;\r\nstruct alua_queue_data *qdata;\r\nstruct alua_port_group *pg;\r\nqdata = kzalloc(sizeof(*qdata), GFP_KERNEL);\r\nif (!qdata) {\r\nerr = SCSI_DH_RES_TEMP_UNAVAIL;\r\ngoto out;\r\n}\r\nqdata->callback_fn = fn;\r\nqdata->callback_data = data;\r\nmutex_lock(&h->init_mutex);\r\nrcu_read_lock();\r\npg = rcu_dereference(h->pg);\r\nif (!pg || !kref_get_unless_zero(&pg->kref)) {\r\nrcu_read_unlock();\r\nkfree(qdata);\r\nerr = h->init_error;\r\nmutex_unlock(&h->init_mutex);\r\ngoto out;\r\n}\r\nrcu_read_unlock();\r\nmutex_unlock(&h->init_mutex);\r\nif (alua_rtpg_queue(pg, sdev, qdata, true))\r\nfn = NULL;\r\nelse\r\nerr = SCSI_DH_DEV_OFFLINED;\r\nkref_put(&pg->kref, release_port_group);\r\nout:\r\nif (fn)\r\nfn(data, err);\r\nreturn 0;\r\n}\r\nstatic void alua_check(struct scsi_device *sdev, bool force)\r\n{\r\nstruct alua_dh_data *h = sdev->handler_data;\r\nstruct alua_port_group *pg;\r\nrcu_read_lock();\r\npg = rcu_dereference(h->pg);\r\nif (!pg || !kref_get_unless_zero(&pg->kref)) {\r\nrcu_read_unlock();\r\nreturn;\r\n}\r\nrcu_read_unlock();\r\nalua_rtpg_queue(pg, sdev, NULL, force);\r\nkref_put(&pg->kref, release_port_group);\r\n}\r\nstatic int alua_prep_fn(struct scsi_device *sdev, struct request *req)\r\n{\r\nstruct alua_dh_data *h = sdev->handler_data;\r\nstruct alua_port_group *pg;\r\nunsigned char state = SCSI_ACCESS_STATE_OPTIMAL;\r\nint ret = BLKPREP_OK;\r\nrcu_read_lock();\r\npg = rcu_dereference(h->pg);\r\nif (pg)\r\nstate = pg->state;\r\nrcu_read_unlock();\r\nif (state == SCSI_ACCESS_STATE_TRANSITIONING)\r\nret = BLKPREP_DEFER;\r\nelse if (state != SCSI_ACCESS_STATE_OPTIMAL &&\r\nstate != SCSI_ACCESS_STATE_ACTIVE &&\r\nstate != SCSI_ACCESS_STATE_LBA) {\r\nret = BLKPREP_KILL;\r\nreq->rq_flags |= RQF_QUIET;\r\n}\r\nreturn ret;\r\n}\r\nstatic void alua_rescan(struct scsi_device *sdev)\r\n{\r\nstruct alua_dh_data *h = sdev->handler_data;\r\nalua_initialize(sdev, h);\r\n}\r\nstatic int alua_bus_attach(struct scsi_device *sdev)\r\n{\r\nstruct alua_dh_data *h;\r\nint err, ret = -EINVAL;\r\nh = kzalloc(sizeof(*h) , GFP_KERNEL);\r\nif (!h)\r\nreturn -ENOMEM;\r\nspin_lock_init(&h->pg_lock);\r\nrcu_assign_pointer(h->pg, NULL);\r\nh->init_error = SCSI_DH_OK;\r\nh->sdev = sdev;\r\nINIT_LIST_HEAD(&h->node);\r\nmutex_init(&h->init_mutex);\r\nerr = alua_initialize(sdev, h);\r\nif (err == SCSI_DH_NOMEM)\r\nret = -ENOMEM;\r\nif (err != SCSI_DH_OK && err != SCSI_DH_DEV_OFFLINED)\r\ngoto failed;\r\nsdev->handler_data = h;\r\nreturn 0;\r\nfailed:\r\nkfree(h);\r\nreturn ret;\r\n}\r\nstatic void alua_bus_detach(struct scsi_device *sdev)\r\n{\r\nstruct alua_dh_data *h = sdev->handler_data;\r\nstruct alua_port_group *pg;\r\nspin_lock(&h->pg_lock);\r\npg = rcu_dereference_protected(h->pg, lockdep_is_held(&h->pg_lock));\r\nrcu_assign_pointer(h->pg, NULL);\r\nh->sdev = NULL;\r\nspin_unlock(&h->pg_lock);\r\nif (pg) {\r\nspin_lock_irq(&pg->lock);\r\nlist_del_rcu(&h->node);\r\nspin_unlock_irq(&pg->lock);\r\nkref_put(&pg->kref, release_port_group);\r\n}\r\nsdev->handler_data = NULL;\r\nkfree(h);\r\n}\r\nstatic int __init alua_init(void)\r\n{\r\nint r;\r\nkaluad_wq = alloc_workqueue("kaluad", WQ_MEM_RECLAIM, 0);\r\nif (!kaluad_wq) {\r\nreturn SCSI_DH_DEV_TEMP_BUSY;\r\n}\r\nkaluad_sync_wq = create_workqueue("kaluad_sync");\r\nif (!kaluad_sync_wq) {\r\ndestroy_workqueue(kaluad_wq);\r\nreturn SCSI_DH_DEV_TEMP_BUSY;\r\n}\r\nr = scsi_register_device_handler(&alua_dh);\r\nif (r != 0) {\r\nprintk(KERN_ERR "%s: Failed to register scsi device handler",\r\nALUA_DH_NAME);\r\ndestroy_workqueue(kaluad_sync_wq);\r\ndestroy_workqueue(kaluad_wq);\r\n}\r\nreturn r;\r\n}\r\nstatic void __exit alua_exit(void)\r\n{\r\nscsi_unregister_device_handler(&alua_dh);\r\ndestroy_workqueue(kaluad_sync_wq);\r\ndestroy_workqueue(kaluad_wq);\r\n}
