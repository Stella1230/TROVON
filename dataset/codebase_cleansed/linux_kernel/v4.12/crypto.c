void fscrypt_release_ctx(struct fscrypt_ctx *ctx)\r\n{\r\nunsigned long flags;\r\nif (ctx->flags & FS_CTX_HAS_BOUNCE_BUFFER_FL && ctx->w.bounce_page) {\r\nmempool_free(ctx->w.bounce_page, fscrypt_bounce_page_pool);\r\nctx->w.bounce_page = NULL;\r\n}\r\nctx->w.control_page = NULL;\r\nif (ctx->flags & FS_CTX_REQUIRES_FREE_ENCRYPT_FL) {\r\nkmem_cache_free(fscrypt_ctx_cachep, ctx);\r\n} else {\r\nspin_lock_irqsave(&fscrypt_ctx_lock, flags);\r\nlist_add(&ctx->free_list, &fscrypt_free_ctxs);\r\nspin_unlock_irqrestore(&fscrypt_ctx_lock, flags);\r\n}\r\n}\r\nstruct fscrypt_ctx *fscrypt_get_ctx(const struct inode *inode, gfp_t gfp_flags)\r\n{\r\nstruct fscrypt_ctx *ctx = NULL;\r\nstruct fscrypt_info *ci = inode->i_crypt_info;\r\nunsigned long flags;\r\nif (ci == NULL)\r\nreturn ERR_PTR(-ENOKEY);\r\nspin_lock_irqsave(&fscrypt_ctx_lock, flags);\r\nctx = list_first_entry_or_null(&fscrypt_free_ctxs,\r\nstruct fscrypt_ctx, free_list);\r\nif (ctx)\r\nlist_del(&ctx->free_list);\r\nspin_unlock_irqrestore(&fscrypt_ctx_lock, flags);\r\nif (!ctx) {\r\nctx = kmem_cache_zalloc(fscrypt_ctx_cachep, gfp_flags);\r\nif (!ctx)\r\nreturn ERR_PTR(-ENOMEM);\r\nctx->flags |= FS_CTX_REQUIRES_FREE_ENCRYPT_FL;\r\n} else {\r\nctx->flags &= ~FS_CTX_REQUIRES_FREE_ENCRYPT_FL;\r\n}\r\nctx->flags &= ~FS_CTX_HAS_BOUNCE_BUFFER_FL;\r\nreturn ctx;\r\n}\r\nstatic void page_crypt_complete(struct crypto_async_request *req, int res)\r\n{\r\nstruct fscrypt_completion_result *ecr = req->data;\r\nif (res == -EINPROGRESS)\r\nreturn;\r\necr->res = res;\r\ncomplete(&ecr->completion);\r\n}\r\nint fscrypt_do_page_crypto(const struct inode *inode, fscrypt_direction_t rw,\r\nu64 lblk_num, struct page *src_page,\r\nstruct page *dest_page, unsigned int len,\r\nunsigned int offs, gfp_t gfp_flags)\r\n{\r\nstruct {\r\n__le64 index;\r\nu8 padding[FS_XTS_TWEAK_SIZE - sizeof(__le64)];\r\n} xts_tweak;\r\nstruct skcipher_request *req = NULL;\r\nDECLARE_FS_COMPLETION_RESULT(ecr);\r\nstruct scatterlist dst, src;\r\nstruct fscrypt_info *ci = inode->i_crypt_info;\r\nstruct crypto_skcipher *tfm = ci->ci_ctfm;\r\nint res = 0;\r\nBUG_ON(len == 0);\r\nreq = skcipher_request_alloc(tfm, gfp_flags);\r\nif (!req) {\r\nprintk_ratelimited(KERN_ERR\r\n"%s: crypto_request_alloc() failed\n",\r\n__func__);\r\nreturn -ENOMEM;\r\n}\r\nskcipher_request_set_callback(\r\nreq, CRYPTO_TFM_REQ_MAY_BACKLOG | CRYPTO_TFM_REQ_MAY_SLEEP,\r\npage_crypt_complete, &ecr);\r\nBUILD_BUG_ON(sizeof(xts_tweak) != FS_XTS_TWEAK_SIZE);\r\nxts_tweak.index = cpu_to_le64(lblk_num);\r\nmemset(xts_tweak.padding, 0, sizeof(xts_tweak.padding));\r\nsg_init_table(&dst, 1);\r\nsg_set_page(&dst, dest_page, len, offs);\r\nsg_init_table(&src, 1);\r\nsg_set_page(&src, src_page, len, offs);\r\nskcipher_request_set_crypt(req, &src, &dst, len, &xts_tweak);\r\nif (rw == FS_DECRYPT)\r\nres = crypto_skcipher_decrypt(req);\r\nelse\r\nres = crypto_skcipher_encrypt(req);\r\nif (res == -EINPROGRESS || res == -EBUSY) {\r\nBUG_ON(req->base.data != &ecr);\r\nwait_for_completion(&ecr.completion);\r\nres = ecr.res;\r\n}\r\nskcipher_request_free(req);\r\nif (res) {\r\nprintk_ratelimited(KERN_ERR\r\n"%s: crypto_skcipher_encrypt() returned %d\n",\r\n__func__, res);\r\nreturn res;\r\n}\r\nreturn 0;\r\n}\r\nstruct page *fscrypt_alloc_bounce_page(struct fscrypt_ctx *ctx,\r\ngfp_t gfp_flags)\r\n{\r\nctx->w.bounce_page = mempool_alloc(fscrypt_bounce_page_pool, gfp_flags);\r\nif (ctx->w.bounce_page == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nctx->flags |= FS_CTX_HAS_BOUNCE_BUFFER_FL;\r\nreturn ctx->w.bounce_page;\r\n}\r\nstruct page *fscrypt_encrypt_page(const struct inode *inode,\r\nstruct page *page,\r\nunsigned int len,\r\nunsigned int offs,\r\nu64 lblk_num, gfp_t gfp_flags)\r\n{\r\nstruct fscrypt_ctx *ctx;\r\nstruct page *ciphertext_page = page;\r\nint err;\r\nBUG_ON(len % FS_CRYPTO_BLOCK_SIZE != 0);\r\nif (inode->i_sb->s_cop->flags & FS_CFLG_OWN_PAGES) {\r\nerr = fscrypt_do_page_crypto(inode, FS_ENCRYPT, lblk_num, page,\r\nciphertext_page, len, offs,\r\ngfp_flags);\r\nif (err)\r\nreturn ERR_PTR(err);\r\nreturn ciphertext_page;\r\n}\r\nBUG_ON(!PageLocked(page));\r\nctx = fscrypt_get_ctx(inode, gfp_flags);\r\nif (IS_ERR(ctx))\r\nreturn (struct page *)ctx;\r\nciphertext_page = fscrypt_alloc_bounce_page(ctx, gfp_flags);\r\nif (IS_ERR(ciphertext_page))\r\ngoto errout;\r\nctx->w.control_page = page;\r\nerr = fscrypt_do_page_crypto(inode, FS_ENCRYPT, lblk_num,\r\npage, ciphertext_page, len, offs,\r\ngfp_flags);\r\nif (err) {\r\nciphertext_page = ERR_PTR(err);\r\ngoto errout;\r\n}\r\nSetPagePrivate(ciphertext_page);\r\nset_page_private(ciphertext_page, (unsigned long)ctx);\r\nlock_page(ciphertext_page);\r\nreturn ciphertext_page;\r\nerrout:\r\nfscrypt_release_ctx(ctx);\r\nreturn ciphertext_page;\r\n}\r\nint fscrypt_decrypt_page(const struct inode *inode, struct page *page,\r\nunsigned int len, unsigned int offs, u64 lblk_num)\r\n{\r\nif (!(inode->i_sb->s_cop->flags & FS_CFLG_OWN_PAGES))\r\nBUG_ON(!PageLocked(page));\r\nreturn fscrypt_do_page_crypto(inode, FS_DECRYPT, lblk_num, page, page,\r\nlen, offs, GFP_NOFS);\r\n}\r\nstatic int fscrypt_d_revalidate(struct dentry *dentry, unsigned int flags)\r\n{\r\nstruct dentry *dir;\r\nint dir_has_key, cached_with_key;\r\nif (flags & LOOKUP_RCU)\r\nreturn -ECHILD;\r\ndir = dget_parent(dentry);\r\nif (!d_inode(dir)->i_sb->s_cop->is_encrypted(d_inode(dir))) {\r\ndput(dir);\r\nreturn 0;\r\n}\r\nspin_lock(&dentry->d_lock);\r\ncached_with_key = dentry->d_flags & DCACHE_ENCRYPTED_WITH_KEY;\r\nspin_unlock(&dentry->d_lock);\r\ndir_has_key = (d_inode(dir)->i_crypt_info != NULL);\r\ndput(dir);\r\nif ((!cached_with_key && d_is_negative(dentry)) ||\r\n(!cached_with_key && dir_has_key) ||\r\n(cached_with_key && !dir_has_key))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nvoid fscrypt_restore_control_page(struct page *page)\r\n{\r\nstruct fscrypt_ctx *ctx;\r\nctx = (struct fscrypt_ctx *)page_private(page);\r\nset_page_private(page, (unsigned long)NULL);\r\nClearPagePrivate(page);\r\nunlock_page(page);\r\nfscrypt_release_ctx(ctx);\r\n}\r\nstatic void fscrypt_destroy(void)\r\n{\r\nstruct fscrypt_ctx *pos, *n;\r\nlist_for_each_entry_safe(pos, n, &fscrypt_free_ctxs, free_list)\r\nkmem_cache_free(fscrypt_ctx_cachep, pos);\r\nINIT_LIST_HEAD(&fscrypt_free_ctxs);\r\nmempool_destroy(fscrypt_bounce_page_pool);\r\nfscrypt_bounce_page_pool = NULL;\r\n}\r\nint fscrypt_initialize(unsigned int cop_flags)\r\n{\r\nint i, res = -ENOMEM;\r\nif (cop_flags & FS_CFLG_OWN_PAGES || fscrypt_bounce_page_pool)\r\nreturn 0;\r\nmutex_lock(&fscrypt_init_mutex);\r\nif (fscrypt_bounce_page_pool)\r\ngoto already_initialized;\r\nfor (i = 0; i < num_prealloc_crypto_ctxs; i++) {\r\nstruct fscrypt_ctx *ctx;\r\nctx = kmem_cache_zalloc(fscrypt_ctx_cachep, GFP_NOFS);\r\nif (!ctx)\r\ngoto fail;\r\nlist_add(&ctx->free_list, &fscrypt_free_ctxs);\r\n}\r\nfscrypt_bounce_page_pool =\r\nmempool_create_page_pool(num_prealloc_crypto_pages, 0);\r\nif (!fscrypt_bounce_page_pool)\r\ngoto fail;\r\nalready_initialized:\r\nmutex_unlock(&fscrypt_init_mutex);\r\nreturn 0;\r\nfail:\r\nfscrypt_destroy();\r\nmutex_unlock(&fscrypt_init_mutex);\r\nreturn res;\r\n}\r\nstatic int __init fscrypt_init(void)\r\n{\r\nfscrypt_read_workqueue = alloc_workqueue("fscrypt_read_queue",\r\nWQ_HIGHPRI, 0);\r\nif (!fscrypt_read_workqueue)\r\ngoto fail;\r\nfscrypt_ctx_cachep = KMEM_CACHE(fscrypt_ctx, SLAB_RECLAIM_ACCOUNT);\r\nif (!fscrypt_ctx_cachep)\r\ngoto fail_free_queue;\r\nfscrypt_info_cachep = KMEM_CACHE(fscrypt_info, SLAB_RECLAIM_ACCOUNT);\r\nif (!fscrypt_info_cachep)\r\ngoto fail_free_ctx;\r\nreturn 0;\r\nfail_free_ctx:\r\nkmem_cache_destroy(fscrypt_ctx_cachep);\r\nfail_free_queue:\r\ndestroy_workqueue(fscrypt_read_workqueue);\r\nfail:\r\nreturn -ENOMEM;\r\n}\r\nstatic void __exit fscrypt_exit(void)\r\n{\r\nfscrypt_destroy();\r\nif (fscrypt_read_workqueue)\r\ndestroy_workqueue(fscrypt_read_workqueue);\r\nkmem_cache_destroy(fscrypt_ctx_cachep);\r\nkmem_cache_destroy(fscrypt_info_cachep);\r\n}
