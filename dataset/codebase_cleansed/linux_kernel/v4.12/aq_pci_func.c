struct aq_pci_func_s *aq_pci_func_alloc(struct aq_hw_ops *aq_hw_ops,\r\nstruct pci_dev *pdev,\r\nconst struct net_device_ops *ndev_ops,\r\nconst struct ethtool_ops *eth_ops)\r\n{\r\nstruct aq_pci_func_s *self = NULL;\r\nint err = 0;\r\nunsigned int port = 0U;\r\nif (!aq_hw_ops) {\r\nerr = -EFAULT;\r\ngoto err_exit;\r\n}\r\nself = kzalloc(sizeof(*self), GFP_KERNEL);\r\nif (!self) {\r\nerr = -ENOMEM;\r\ngoto err_exit;\r\n}\r\npci_set_drvdata(pdev, self);\r\nself->pdev = pdev;\r\nerr = aq_hw_ops->get_hw_caps(NULL, &self->aq_hw_caps);\r\nif (err < 0)\r\ngoto err_exit;\r\nself->ports = self->aq_hw_caps.ports;\r\nfor (port = 0; port < self->ports; ++port) {\r\nstruct aq_nic_s *aq_nic = aq_nic_alloc_cold(ndev_ops, eth_ops,\r\n&pdev->dev, self,\r\nport, aq_hw_ops);\r\nif (!aq_nic) {\r\nerr = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nself->port[port] = aq_nic;\r\n}\r\nerr_exit:\r\nif (err < 0) {\r\nif (self)\r\naq_pci_func_free(self);\r\nself = NULL;\r\n}\r\n(void)err;\r\nreturn self;\r\n}\r\nint aq_pci_func_init(struct aq_pci_func_s *self)\r\n{\r\nint err = 0;\r\nunsigned int bar = 0U;\r\nunsigned int port = 0U;\r\nerr = pci_enable_device(self->pdev);\r\nif (err < 0)\r\ngoto err_exit;\r\nself->is_pci_enabled = true;\r\nerr = pci_set_dma_mask(self->pdev, DMA_BIT_MASK(64));\r\nif (!err) {\r\nerr = pci_set_consistent_dma_mask(self->pdev, DMA_BIT_MASK(64));\r\nself->is_pci_using_dac = 1;\r\n}\r\nif (err) {\r\nerr = pci_set_dma_mask(self->pdev, DMA_BIT_MASK(32));\r\nif (!err)\r\nerr = pci_set_consistent_dma_mask(self->pdev,\r\nDMA_BIT_MASK(32));\r\nself->is_pci_using_dac = 0;\r\n}\r\nif (err != 0) {\r\nerr = -ENOSR;\r\ngoto err_exit;\r\n}\r\nerr = pci_request_regions(self->pdev, AQ_CFG_DRV_NAME "_mmio");\r\nif (err < 0)\r\ngoto err_exit;\r\nself->is_regions = true;\r\npci_set_master(self->pdev);\r\nfor (bar = 0; bar < 4; ++bar) {\r\nif (IORESOURCE_MEM & pci_resource_flags(self->pdev, bar)) {\r\nresource_size_t reg_sz;\r\nself->mmio_pa = pci_resource_start(self->pdev, bar);\r\nif (self->mmio_pa == 0U) {\r\nerr = -EIO;\r\ngoto err_exit;\r\n}\r\nreg_sz = pci_resource_len(self->pdev, bar);\r\nif ((reg_sz <= 24 )) {\r\nerr = -EIO;\r\ngoto err_exit;\r\n}\r\nself->mmio = ioremap_nocache(self->mmio_pa, reg_sz);\r\nif (!self->mmio) {\r\nerr = -EIO;\r\ngoto err_exit;\r\n}\r\nbreak;\r\n}\r\n}\r\n#if !AQ_CFG_FORCE_LEGACY_INT\r\nerr = pci_alloc_irq_vectors(self->pdev, self->aq_hw_caps.msix_irqs,\r\nself->aq_hw_caps.msix_irqs, PCI_IRQ_MSIX);\r\nif (err < 0) {\r\nerr = pci_alloc_irq_vectors(self->pdev, 1, 1,\r\nPCI_IRQ_MSI | PCI_IRQ_LEGACY);\r\nif (err < 0)\r\ngoto err_exit;\r\n}\r\n#endif\r\nfor (port = 0; port < self->ports; ++port) {\r\nif (!self->port[port])\r\ncontinue;\r\nerr = aq_nic_cfg_start(self->port[port]);\r\nif (err < 0)\r\ngoto err_exit;\r\nerr = aq_nic_ndev_init(self->port[port]);\r\nif (err < 0)\r\ngoto err_exit;\r\nerr = aq_nic_ndev_register(self->port[port]);\r\nif (err < 0)\r\ngoto err_exit;\r\n}\r\nerr_exit:\r\nif (err < 0)\r\naq_pci_func_deinit(self);\r\nreturn err;\r\n}\r\nint aq_pci_func_alloc_irq(struct aq_pci_func_s *self, unsigned int i,\r\nchar *name, void *aq_vec, cpumask_t *affinity_mask)\r\n{\r\nstruct pci_dev *pdev = self->pdev;\r\nint err = 0;\r\nif (pdev->msix_enabled || pdev->msi_enabled)\r\nerr = request_irq(pci_irq_vector(pdev, i), aq_vec_isr, 0,\r\nname, aq_vec);\r\nelse\r\nerr = request_irq(pci_irq_vector(pdev, i), aq_vec_isr_legacy,\r\nIRQF_SHARED, name, aq_vec);\r\nif (err >= 0) {\r\nself->msix_entry_mask |= (1 << i);\r\nself->aq_vec[i] = aq_vec;\r\nif (pdev->msix_enabled)\r\nirq_set_affinity_hint(pci_irq_vector(pdev, i),\r\naffinity_mask);\r\n}\r\nreturn err;\r\n}\r\nvoid aq_pci_func_free_irqs(struct aq_pci_func_s *self)\r\n{\r\nstruct pci_dev *pdev = self->pdev;\r\nunsigned int i = 0U;\r\nfor (i = 32U; i--;) {\r\nif (!((1U << i) & self->msix_entry_mask))\r\ncontinue;\r\nif (pdev->msix_enabled)\r\nirq_set_affinity_hint(pci_irq_vector(pdev, i), NULL);\r\nfree_irq(pci_irq_vector(pdev, i), self->aq_vec[i]);\r\nself->msix_entry_mask &= ~(1U << i);\r\n}\r\n}\r\nvoid __iomem *aq_pci_func_get_mmio(struct aq_pci_func_s *self)\r\n{\r\nreturn self->mmio;\r\n}\r\nunsigned int aq_pci_func_get_irq_type(struct aq_pci_func_s *self)\r\n{\r\nif (self->pdev->msix_enabled)\r\nreturn AQ_HW_IRQ_MSIX;\r\nif (self->pdev->msi_enabled)\r\nreturn AQ_HW_IRQ_MSIX;\r\nreturn AQ_HW_IRQ_LEGACY;\r\n}\r\nvoid aq_pci_func_deinit(struct aq_pci_func_s *self)\r\n{\r\nif (!self)\r\ngoto err_exit;\r\naq_pci_func_free_irqs(self);\r\npci_free_irq_vectors(self->pdev);\r\nif (self->is_regions)\r\npci_release_regions(self->pdev);\r\nif (self->is_pci_enabled)\r\npci_disable_device(self->pdev);\r\nerr_exit:;\r\n}\r\nvoid aq_pci_func_free(struct aq_pci_func_s *self)\r\n{\r\nunsigned int port = 0U;\r\nif (!self)\r\ngoto err_exit;\r\nfor (port = 0; port < self->ports; ++port) {\r\nif (!self->port[port])\r\ncontinue;\r\naq_nic_ndev_free(self->port[port]);\r\n}\r\nkfree(self);\r\nerr_exit:;\r\n}\r\nint aq_pci_func_change_pm_state(struct aq_pci_func_s *self,\r\npm_message_t *pm_msg)\r\n{\r\nint err = 0;\r\nunsigned int port = 0U;\r\nif (!self) {\r\nerr = -EFAULT;\r\ngoto err_exit;\r\n}\r\nfor (port = 0; port < self->ports; ++port) {\r\nif (!self->port[port])\r\ncontinue;\r\n(void)aq_nic_change_pm_state(self->port[port], pm_msg);\r\n}\r\nerr_exit:\r\nreturn err;\r\n}
