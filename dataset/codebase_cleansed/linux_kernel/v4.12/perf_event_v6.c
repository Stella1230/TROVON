static inline unsigned long\r\narmv6_pmcr_read(void)\r\n{\r\nu32 val;\r\nasm volatile("mrc p15, 0, %0, c15, c12, 0" : "=r"(val));\r\nreturn val;\r\n}\r\nstatic inline void\r\narmv6_pmcr_write(unsigned long val)\r\n{\r\nasm volatile("mcr p15, 0, %0, c15, c12, 0" : : "r"(val));\r\n}\r\nstatic inline int\r\narmv6_pmcr_has_overflowed(unsigned long pmcr)\r\n{\r\nreturn pmcr & ARMV6_PMCR_OVERFLOWED_MASK;\r\n}\r\nstatic inline int\r\narmv6_pmcr_counter_has_overflowed(unsigned long pmcr,\r\nenum armv6_counters counter)\r\n{\r\nint ret = 0;\r\nif (ARMV6_CYCLE_COUNTER == counter)\r\nret = pmcr & ARMV6_PMCR_CCOUNT_OVERFLOW;\r\nelse if (ARMV6_COUNTER0 == counter)\r\nret = pmcr & ARMV6_PMCR_COUNT0_OVERFLOW;\r\nelse if (ARMV6_COUNTER1 == counter)\r\nret = pmcr & ARMV6_PMCR_COUNT1_OVERFLOW;\r\nelse\r\nWARN_ONCE(1, "invalid counter number (%d)\n", counter);\r\nreturn ret;\r\n}\r\nstatic inline u32 armv6pmu_read_counter(struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nint counter = hwc->idx;\r\nunsigned long value = 0;\r\nif (ARMV6_CYCLE_COUNTER == counter)\r\nasm volatile("mrc p15, 0, %0, c15, c12, 1" : "=r"(value));\r\nelse if (ARMV6_COUNTER0 == counter)\r\nasm volatile("mrc p15, 0, %0, c15, c12, 2" : "=r"(value));\r\nelse if (ARMV6_COUNTER1 == counter)\r\nasm volatile("mrc p15, 0, %0, c15, c12, 3" : "=r"(value));\r\nelse\r\nWARN_ONCE(1, "invalid counter number (%d)\n", counter);\r\nreturn value;\r\n}\r\nstatic inline void armv6pmu_write_counter(struct perf_event *event, u32 value)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nint counter = hwc->idx;\r\nif (ARMV6_CYCLE_COUNTER == counter)\r\nasm volatile("mcr p15, 0, %0, c15, c12, 1" : : "r"(value));\r\nelse if (ARMV6_COUNTER0 == counter)\r\nasm volatile("mcr p15, 0, %0, c15, c12, 2" : : "r"(value));\r\nelse if (ARMV6_COUNTER1 == counter)\r\nasm volatile("mcr p15, 0, %0, c15, c12, 3" : : "r"(value));\r\nelse\r\nWARN_ONCE(1, "invalid counter number (%d)\n", counter);\r\n}\r\nstatic void armv6pmu_enable_event(struct perf_event *event)\r\n{\r\nunsigned long val, mask, evt, flags;\r\nstruct arm_pmu *cpu_pmu = to_arm_pmu(event->pmu);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct pmu_hw_events *events = this_cpu_ptr(cpu_pmu->hw_events);\r\nint idx = hwc->idx;\r\nif (ARMV6_CYCLE_COUNTER == idx) {\r\nmask = 0;\r\nevt = ARMV6_PMCR_CCOUNT_IEN;\r\n} else if (ARMV6_COUNTER0 == idx) {\r\nmask = ARMV6_PMCR_EVT_COUNT0_MASK;\r\nevt = (hwc->config_base << ARMV6_PMCR_EVT_COUNT0_SHIFT) |\r\nARMV6_PMCR_COUNT0_IEN;\r\n} else if (ARMV6_COUNTER1 == idx) {\r\nmask = ARMV6_PMCR_EVT_COUNT1_MASK;\r\nevt = (hwc->config_base << ARMV6_PMCR_EVT_COUNT1_SHIFT) |\r\nARMV6_PMCR_COUNT1_IEN;\r\n} else {\r\nWARN_ONCE(1, "invalid counter number (%d)\n", idx);\r\nreturn;\r\n}\r\nraw_spin_lock_irqsave(&events->pmu_lock, flags);\r\nval = armv6_pmcr_read();\r\nval &= ~mask;\r\nval |= evt;\r\narmv6_pmcr_write(val);\r\nraw_spin_unlock_irqrestore(&events->pmu_lock, flags);\r\n}\r\nstatic irqreturn_t\r\narmv6pmu_handle_irq(int irq_num,\r\nvoid *dev)\r\n{\r\nunsigned long pmcr = armv6_pmcr_read();\r\nstruct perf_sample_data data;\r\nstruct arm_pmu *cpu_pmu = (struct arm_pmu *)dev;\r\nstruct pmu_hw_events *cpuc = this_cpu_ptr(cpu_pmu->hw_events);\r\nstruct pt_regs *regs;\r\nint idx;\r\nif (!armv6_pmcr_has_overflowed(pmcr))\r\nreturn IRQ_NONE;\r\nregs = get_irq_regs();\r\narmv6_pmcr_write(pmcr);\r\nfor (idx = 0; idx < cpu_pmu->num_events; ++idx) {\r\nstruct perf_event *event = cpuc->events[idx];\r\nstruct hw_perf_event *hwc;\r\nif (!event)\r\ncontinue;\r\nif (!armv6_pmcr_counter_has_overflowed(pmcr, idx))\r\ncontinue;\r\nhwc = &event->hw;\r\narmpmu_event_update(event);\r\nperf_sample_data_init(&data, 0, hwc->last_period);\r\nif (!armpmu_event_set_period(event))\r\ncontinue;\r\nif (perf_event_overflow(event, &data, regs))\r\ncpu_pmu->disable(event);\r\n}\r\nirq_work_run();\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void armv6pmu_start(struct arm_pmu *cpu_pmu)\r\n{\r\nunsigned long flags, val;\r\nstruct pmu_hw_events *events = this_cpu_ptr(cpu_pmu->hw_events);\r\nraw_spin_lock_irqsave(&events->pmu_lock, flags);\r\nval = armv6_pmcr_read();\r\nval |= ARMV6_PMCR_ENABLE;\r\narmv6_pmcr_write(val);\r\nraw_spin_unlock_irqrestore(&events->pmu_lock, flags);\r\n}\r\nstatic void armv6pmu_stop(struct arm_pmu *cpu_pmu)\r\n{\r\nunsigned long flags, val;\r\nstruct pmu_hw_events *events = this_cpu_ptr(cpu_pmu->hw_events);\r\nraw_spin_lock_irqsave(&events->pmu_lock, flags);\r\nval = armv6_pmcr_read();\r\nval &= ~ARMV6_PMCR_ENABLE;\r\narmv6_pmcr_write(val);\r\nraw_spin_unlock_irqrestore(&events->pmu_lock, flags);\r\n}\r\nstatic int\r\narmv6pmu_get_event_idx(struct pmu_hw_events *cpuc,\r\nstruct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nif (ARMV6_PERFCTR_CPU_CYCLES == hwc->config_base) {\r\nif (test_and_set_bit(ARMV6_CYCLE_COUNTER, cpuc->used_mask))\r\nreturn -EAGAIN;\r\nreturn ARMV6_CYCLE_COUNTER;\r\n} else {\r\nif (!test_and_set_bit(ARMV6_COUNTER1, cpuc->used_mask))\r\nreturn ARMV6_COUNTER1;\r\nif (!test_and_set_bit(ARMV6_COUNTER0, cpuc->used_mask))\r\nreturn ARMV6_COUNTER0;\r\nreturn -EAGAIN;\r\n}\r\n}\r\nstatic void armv6pmu_disable_event(struct perf_event *event)\r\n{\r\nunsigned long val, mask, evt, flags;\r\nstruct arm_pmu *cpu_pmu = to_arm_pmu(event->pmu);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct pmu_hw_events *events = this_cpu_ptr(cpu_pmu->hw_events);\r\nint idx = hwc->idx;\r\nif (ARMV6_CYCLE_COUNTER == idx) {\r\nmask = ARMV6_PMCR_CCOUNT_IEN;\r\nevt = 0;\r\n} else if (ARMV6_COUNTER0 == idx) {\r\nmask = ARMV6_PMCR_COUNT0_IEN | ARMV6_PMCR_EVT_COUNT0_MASK;\r\nevt = ARMV6_PERFCTR_NOP << ARMV6_PMCR_EVT_COUNT0_SHIFT;\r\n} else if (ARMV6_COUNTER1 == idx) {\r\nmask = ARMV6_PMCR_COUNT1_IEN | ARMV6_PMCR_EVT_COUNT1_MASK;\r\nevt = ARMV6_PERFCTR_NOP << ARMV6_PMCR_EVT_COUNT1_SHIFT;\r\n} else {\r\nWARN_ONCE(1, "invalid counter number (%d)\n", idx);\r\nreturn;\r\n}\r\nraw_spin_lock_irqsave(&events->pmu_lock, flags);\r\nval = armv6_pmcr_read();\r\nval &= ~mask;\r\nval |= evt;\r\narmv6_pmcr_write(val);\r\nraw_spin_unlock_irqrestore(&events->pmu_lock, flags);\r\n}\r\nstatic void armv6mpcore_pmu_disable_event(struct perf_event *event)\r\n{\r\nunsigned long val, mask, flags, evt = 0;\r\nstruct arm_pmu *cpu_pmu = to_arm_pmu(event->pmu);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct pmu_hw_events *events = this_cpu_ptr(cpu_pmu->hw_events);\r\nint idx = hwc->idx;\r\nif (ARMV6_CYCLE_COUNTER == idx) {\r\nmask = ARMV6_PMCR_CCOUNT_IEN;\r\n} else if (ARMV6_COUNTER0 == idx) {\r\nmask = ARMV6_PMCR_COUNT0_IEN;\r\n} else if (ARMV6_COUNTER1 == idx) {\r\nmask = ARMV6_PMCR_COUNT1_IEN;\r\n} else {\r\nWARN_ONCE(1, "invalid counter number (%d)\n", idx);\r\nreturn;\r\n}\r\nraw_spin_lock_irqsave(&events->pmu_lock, flags);\r\nval = armv6_pmcr_read();\r\nval &= ~mask;\r\nval |= evt;\r\narmv6_pmcr_write(val);\r\nraw_spin_unlock_irqrestore(&events->pmu_lock, flags);\r\n}\r\nstatic int armv6_map_event(struct perf_event *event)\r\n{\r\nreturn armpmu_map_event(event, &armv6_perf_map,\r\n&armv6_perf_cache_map, 0xFF);\r\n}\r\nstatic void armv6pmu_init(struct arm_pmu *cpu_pmu)\r\n{\r\ncpu_pmu->handle_irq = armv6pmu_handle_irq;\r\ncpu_pmu->enable = armv6pmu_enable_event;\r\ncpu_pmu->disable = armv6pmu_disable_event;\r\ncpu_pmu->read_counter = armv6pmu_read_counter;\r\ncpu_pmu->write_counter = armv6pmu_write_counter;\r\ncpu_pmu->get_event_idx = armv6pmu_get_event_idx;\r\ncpu_pmu->start = armv6pmu_start;\r\ncpu_pmu->stop = armv6pmu_stop;\r\ncpu_pmu->map_event = armv6_map_event;\r\ncpu_pmu->num_events = 3;\r\ncpu_pmu->max_period = (1LLU << 32) - 1;\r\n}\r\nstatic int armv6_1136_pmu_init(struct arm_pmu *cpu_pmu)\r\n{\r\narmv6pmu_init(cpu_pmu);\r\ncpu_pmu->name = "armv6_1136";\r\nreturn 0;\r\n}\r\nstatic int armv6_1156_pmu_init(struct arm_pmu *cpu_pmu)\r\n{\r\narmv6pmu_init(cpu_pmu);\r\ncpu_pmu->name = "armv6_1156";\r\nreturn 0;\r\n}\r\nstatic int armv6_1176_pmu_init(struct arm_pmu *cpu_pmu)\r\n{\r\narmv6pmu_init(cpu_pmu);\r\ncpu_pmu->name = "armv6_1176";\r\nreturn 0;\r\n}\r\nstatic int armv6mpcore_map_event(struct perf_event *event)\r\n{\r\nreturn armpmu_map_event(event, &armv6mpcore_perf_map,\r\n&armv6mpcore_perf_cache_map, 0xFF);\r\n}\r\nstatic int armv6mpcore_pmu_init(struct arm_pmu *cpu_pmu)\r\n{\r\ncpu_pmu->name = "armv6_11mpcore";\r\ncpu_pmu->handle_irq = armv6pmu_handle_irq;\r\ncpu_pmu->enable = armv6pmu_enable_event;\r\ncpu_pmu->disable = armv6mpcore_pmu_disable_event;\r\ncpu_pmu->read_counter = armv6pmu_read_counter;\r\ncpu_pmu->write_counter = armv6pmu_write_counter;\r\ncpu_pmu->get_event_idx = armv6pmu_get_event_idx;\r\ncpu_pmu->start = armv6pmu_start;\r\ncpu_pmu->stop = armv6pmu_stop;\r\ncpu_pmu->map_event = armv6mpcore_map_event;\r\ncpu_pmu->num_events = 3;\r\ncpu_pmu->max_period = (1LLU << 32) - 1;\r\nreturn 0;\r\n}\r\nstatic int armv6_pmu_device_probe(struct platform_device *pdev)\r\n{\r\nreturn arm_pmu_device_probe(pdev, armv6_pmu_of_device_ids,\r\narmv6_pmu_probe_table);\r\n}
