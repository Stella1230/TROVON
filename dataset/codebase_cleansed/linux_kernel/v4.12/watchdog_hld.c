void hardlockup_detector_disable(void)\r\n{\r\nwatchdog_enabled &= ~NMI_WATCHDOG_ENABLED;\r\n}\r\nstatic int __init hardlockup_panic_setup(char *str)\r\n{\r\nif (!strncmp(str, "panic", 5))\r\nhardlockup_panic = 1;\r\nelse if (!strncmp(str, "nopanic", 7))\r\nhardlockup_panic = 0;\r\nelse if (!strncmp(str, "0", 1))\r\nwatchdog_enabled &= ~NMI_WATCHDOG_ENABLED;\r\nelse if (!strncmp(str, "1", 1))\r\nwatchdog_enabled |= NMI_WATCHDOG_ENABLED;\r\nreturn 1;\r\n}\r\nvoid touch_nmi_watchdog(void)\r\n{\r\nraw_cpu_write(watchdog_nmi_touch, true);\r\ntouch_softlockup_watchdog();\r\n}\r\nstatic void watchdog_overflow_callback(struct perf_event *event,\r\nstruct perf_sample_data *data,\r\nstruct pt_regs *regs)\r\n{\r\nevent->hw.interrupts = 0;\r\nif (atomic_read(&watchdog_park_in_progress) != 0)\r\nreturn;\r\nif (__this_cpu_read(watchdog_nmi_touch) == true) {\r\n__this_cpu_write(watchdog_nmi_touch, false);\r\nreturn;\r\n}\r\nif (is_hardlockup()) {\r\nint this_cpu = smp_processor_id();\r\nif (__this_cpu_read(hard_watchdog_warn) == true)\r\nreturn;\r\npr_emerg("Watchdog detected hard LOCKUP on cpu %d", this_cpu);\r\nprint_modules();\r\nprint_irqtrace_events(current);\r\nif (regs)\r\nshow_regs(regs);\r\nelse\r\ndump_stack();\r\nif (sysctl_hardlockup_all_cpu_backtrace &&\r\n!test_and_set_bit(0, &hardlockup_allcpu_dumped))\r\ntrigger_allbutself_cpu_backtrace();\r\nif (hardlockup_panic)\r\nnmi_panic(regs, "Hard LOCKUP");\r\n__this_cpu_write(hard_watchdog_warn, true);\r\nreturn;\r\n}\r\n__this_cpu_write(hard_watchdog_warn, false);\r\nreturn;\r\n}\r\nint watchdog_nmi_enable(unsigned int cpu)\r\n{\r\nstruct perf_event_attr *wd_attr;\r\nstruct perf_event *event = per_cpu(watchdog_ev, cpu);\r\nint firstcpu = 0;\r\nif (!(watchdog_enabled & NMI_WATCHDOG_ENABLED))\r\ngoto out;\r\nif (event && event->state > PERF_EVENT_STATE_OFF)\r\ngoto out;\r\nif (event != NULL)\r\ngoto out_enable;\r\nif (atomic_inc_return(&watchdog_cpus) == 1)\r\nfirstcpu = 1;\r\nwd_attr = &wd_hw_attr;\r\nwd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);\r\nevent = perf_event_create_kernel_counter(wd_attr, cpu, NULL, watchdog_overflow_callback, NULL);\r\nif (firstcpu && IS_ERR(event))\r\nfirstcpu_err = PTR_ERR(event);\r\nif (!IS_ERR(event)) {\r\nif (firstcpu || firstcpu_err)\r\npr_info("enabled on all CPUs, permanently consumes one hw-PMU counter.\n");\r\ngoto out_save;\r\n}\r\nsmp_mb__before_atomic();\r\nclear_bit(NMI_WATCHDOG_ENABLED_BIT, &watchdog_enabled);\r\nsmp_mb__after_atomic();\r\nif (!firstcpu && (PTR_ERR(event) == firstcpu_err))\r\nreturn PTR_ERR(event);\r\nif (PTR_ERR(event) == -EOPNOTSUPP)\r\npr_info("disabled (cpu%i): not supported (no LAPIC?)\n", cpu);\r\nelse if (PTR_ERR(event) == -ENOENT)\r\npr_warn("disabled (cpu%i): hardware events not enabled\n",\r\ncpu);\r\nelse\r\npr_err("disabled (cpu%i): unable to create perf event: %ld\n",\r\ncpu, PTR_ERR(event));\r\npr_info("Shutting down hard lockup detector on all cpus\n");\r\nreturn PTR_ERR(event);\r\nout_save:\r\nper_cpu(watchdog_ev, cpu) = event;\r\nout_enable:\r\nperf_event_enable(per_cpu(watchdog_ev, cpu));\r\nout:\r\nreturn 0;\r\n}\r\nvoid watchdog_nmi_disable(unsigned int cpu)\r\n{\r\nstruct perf_event *event = per_cpu(watchdog_ev, cpu);\r\nif (event) {\r\nperf_event_disable(event);\r\nper_cpu(watchdog_ev, cpu) = NULL;\r\nperf_event_release_kernel(event);\r\nif (atomic_dec_and_test(&watchdog_cpus))\r\nfirstcpu_err = 0;\r\n}\r\n}
