static int l2x0_pmu_find_idx(void)\r\n{\r\nint i;\r\nfor (i = 0; i < PMU_NR_COUNTERS; i++) {\r\nif (!events[i])\r\nreturn i;\r\n}\r\nreturn -1;\r\n}\r\nstatic int l2x0_pmu_num_active_counters(void)\r\n{\r\nint i, cnt = 0;\r\nfor (i = 0; i < PMU_NR_COUNTERS; i++) {\r\nif (events[i])\r\ncnt++;\r\n}\r\nreturn cnt;\r\n}\r\nstatic void l2x0_pmu_counter_config_write(int idx, u32 val)\r\n{\r\nwritel_relaxed(val, l2x0_base + L2X0_EVENT_CNT0_CFG - 4 * idx);\r\n}\r\nstatic u32 l2x0_pmu_counter_read(int idx)\r\n{\r\nreturn readl_relaxed(l2x0_base + L2X0_EVENT_CNT0_VAL - 4 * idx);\r\n}\r\nstatic void l2x0_pmu_counter_write(int idx, u32 val)\r\n{\r\nwritel_relaxed(val, l2x0_base + L2X0_EVENT_CNT0_VAL - 4 * idx);\r\n}\r\nstatic void __l2x0_pmu_enable(void)\r\n{\r\nu32 val = readl_relaxed(l2x0_base + L2X0_EVENT_CNT_CTRL);\r\nval |= L2X0_EVENT_CNT_CTRL_ENABLE;\r\nwritel_relaxed(val, l2x0_base + L2X0_EVENT_CNT_CTRL);\r\n}\r\nstatic void __l2x0_pmu_disable(void)\r\n{\r\nu32 val = readl_relaxed(l2x0_base + L2X0_EVENT_CNT_CTRL);\r\nval &= ~L2X0_EVENT_CNT_CTRL_ENABLE;\r\nwritel_relaxed(val, l2x0_base + L2X0_EVENT_CNT_CTRL);\r\n}\r\nstatic void l2x0_pmu_enable(struct pmu *pmu)\r\n{\r\nif (l2x0_pmu_num_active_counters() == 0)\r\nreturn;\r\n__l2x0_pmu_enable();\r\n}\r\nstatic void l2x0_pmu_disable(struct pmu *pmu)\r\n{\r\nif (l2x0_pmu_num_active_counters() == 0)\r\nreturn;\r\n__l2x0_pmu_disable();\r\n}\r\nstatic void warn_if_saturated(u32 count)\r\n{\r\nif (count != 0xffffffff)\r\nreturn;\r\npr_warn_ratelimited("L2X0 counter saturated. Poll period too long\n");\r\n}\r\nstatic void l2x0_pmu_event_read(struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nu64 prev_count, new_count, mask;\r\ndo {\r\nprev_count = local64_read(&hw->prev_count);\r\nnew_count = l2x0_pmu_counter_read(hw->idx);\r\n} while (local64_xchg(&hw->prev_count, new_count) != prev_count);\r\nmask = GENMASK_ULL(31, 0);\r\nlocal64_add((new_count - prev_count) & mask, &event->count);\r\nwarn_if_saturated(new_count);\r\n}\r\nstatic void l2x0_pmu_event_configure(struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nlocal64_set(&hw->prev_count, 0);\r\nl2x0_pmu_counter_write(hw->idx, 0);\r\n}\r\nstatic enum hrtimer_restart l2x0_pmu_poll(struct hrtimer *hrtimer)\r\n{\r\nunsigned long flags;\r\nint i;\r\nlocal_irq_save(flags);\r\n__l2x0_pmu_disable();\r\nfor (i = 0; i < PMU_NR_COUNTERS; i++) {\r\nstruct perf_event *event = events[i];\r\nif (!event)\r\ncontinue;\r\nl2x0_pmu_event_read(event);\r\nl2x0_pmu_event_configure(event);\r\n}\r\n__l2x0_pmu_enable();\r\nlocal_irq_restore(flags);\r\nhrtimer_forward_now(hrtimer, l2x0_pmu_poll_period);\r\nreturn HRTIMER_RESTART;\r\n}\r\nstatic void __l2x0_pmu_event_enable(int idx, u32 event)\r\n{\r\nu32 val;\r\nval = event << L2X0_EVENT_CNT_CFG_SRC_SHIFT;\r\nval |= L2X0_EVENT_CNT_CFG_INT_DISABLED;\r\nl2x0_pmu_counter_config_write(idx, val);\r\n}\r\nstatic void l2x0_pmu_event_start(struct perf_event *event, int flags)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nif (WARN_ON_ONCE(!(event->hw.state & PERF_HES_STOPPED)))\r\nreturn;\r\nif (flags & PERF_EF_RELOAD) {\r\nWARN_ON_ONCE(!(hw->state & PERF_HES_UPTODATE));\r\nl2x0_pmu_event_configure(event);\r\n}\r\nhw->state = 0;\r\n__l2x0_pmu_event_enable(hw->idx, hw->config_base);\r\n}\r\nstatic void __l2x0_pmu_event_disable(int idx)\r\n{\r\nu32 val;\r\nval = L2X0_EVENT_CNT_CFG_SRC_DISABLED << L2X0_EVENT_CNT_CFG_SRC_SHIFT;\r\nval |= L2X0_EVENT_CNT_CFG_INT_DISABLED;\r\nl2x0_pmu_counter_config_write(idx, val);\r\n}\r\nstatic void l2x0_pmu_event_stop(struct perf_event *event, int flags)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nif (WARN_ON_ONCE(event->hw.state & PERF_HES_STOPPED))\r\nreturn;\r\n__l2x0_pmu_event_disable(hw->idx);\r\nhw->state |= PERF_HES_STOPPED;\r\nif (flags & PERF_EF_UPDATE) {\r\nl2x0_pmu_event_read(event);\r\nhw->state |= PERF_HES_UPTODATE;\r\n}\r\n}\r\nstatic int l2x0_pmu_event_add(struct perf_event *event, int flags)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nint idx = l2x0_pmu_find_idx();\r\nif (idx == -1)\r\nreturn -EAGAIN;\r\nif (l2x0_pmu_num_active_counters() == 0)\r\nhrtimer_start(&l2x0_pmu_hrtimer, l2x0_pmu_poll_period,\r\nHRTIMER_MODE_REL_PINNED);\r\nevents[idx] = event;\r\nhw->idx = idx;\r\nl2x0_pmu_event_configure(event);\r\nhw->state = PERF_HES_STOPPED | PERF_HES_UPTODATE;\r\nif (flags & PERF_EF_START)\r\nl2x0_pmu_event_start(event, 0);\r\nreturn 0;\r\n}\r\nstatic void l2x0_pmu_event_del(struct perf_event *event, int flags)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nl2x0_pmu_event_stop(event, PERF_EF_UPDATE);\r\nevents[hw->idx] = NULL;\r\nhw->idx = -1;\r\nif (l2x0_pmu_num_active_counters() == 0)\r\nhrtimer_cancel(&l2x0_pmu_hrtimer);\r\n}\r\nstatic bool l2x0_pmu_group_is_valid(struct perf_event *event)\r\n{\r\nstruct pmu *pmu = event->pmu;\r\nstruct perf_event *leader = event->group_leader;\r\nstruct perf_event *sibling;\r\nint num_hw = 0;\r\nif (leader->pmu == pmu)\r\nnum_hw++;\r\nelse if (!is_software_event(leader))\r\nreturn false;\r\nlist_for_each_entry(sibling, &leader->sibling_list, group_entry) {\r\nif (sibling->pmu == pmu)\r\nnum_hw++;\r\nelse if (!is_software_event(sibling))\r\nreturn false;\r\n}\r\nreturn num_hw <= PMU_NR_COUNTERS;\r\n}\r\nstatic int l2x0_pmu_event_init(struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nif (event->attr.type != l2x0_pmu->type)\r\nreturn -ENOENT;\r\nif (is_sampling_event(event) ||\r\nevent->attach_state & PERF_ATTACH_TASK)\r\nreturn -EINVAL;\r\nif (event->attr.exclude_user ||\r\nevent->attr.exclude_kernel ||\r\nevent->attr.exclude_hv ||\r\nevent->attr.exclude_idle ||\r\nevent->attr.exclude_host ||\r\nevent->attr.exclude_guest)\r\nreturn -EINVAL;\r\nif (event->cpu < 0)\r\nreturn -EINVAL;\r\nif (event->attr.config & ~L2X0_EVENT_CNT_CFG_SRC_MASK)\r\nreturn -EINVAL;\r\nhw->config_base = event->attr.config;\r\nif (!l2x0_pmu_group_is_valid(event))\r\nreturn -EINVAL;\r\nevent->cpu = cpumask_first(&pmu_cpu);\r\nreturn 0;\r\n}\r\nstatic ssize_t l2x0_pmu_event_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct l2x0_event_attribute *lattr;\r\nlattr = container_of(attr, typeof(*lattr), attr);\r\nreturn snprintf(buf, PAGE_SIZE, "config=0x%x\n", lattr->config);\r\n}\r\nstatic umode_t l2x0_pmu_event_attr_is_visible(struct kobject *kobj,\r\nstruct attribute *attr,\r\nint unused)\r\n{\r\nstruct device *dev = kobj_to_dev(kobj);\r\nstruct pmu *pmu = dev_get_drvdata(dev);\r\nstruct l2x0_event_attribute *lattr;\r\nlattr = container_of(attr, typeof(*lattr), attr.attr);\r\nif (!lattr->pl310_only || strcmp("l2c_310", pmu->name) == 0)\r\nreturn attr->mode;\r\nreturn 0;\r\n}\r\nstatic ssize_t l2x0_pmu_cpumask_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nreturn cpumap_print_to_pagebuf(true, buf, &pmu_cpu);\r\n}\r\nstatic void l2x0_pmu_reset(void)\r\n{\r\nint i;\r\n__l2x0_pmu_disable();\r\nfor (i = 0; i < PMU_NR_COUNTERS; i++)\r\n__l2x0_pmu_event_disable(i);\r\n}\r\nstatic int l2x0_pmu_offline_cpu(unsigned int cpu)\r\n{\r\nunsigned int target;\r\nif (!cpumask_test_and_clear_cpu(cpu, &pmu_cpu))\r\nreturn 0;\r\ntarget = cpumask_any_but(cpu_online_mask, cpu);\r\nif (target >= nr_cpu_ids)\r\nreturn 0;\r\nperf_pmu_migrate_context(l2x0_pmu, cpu, target);\r\ncpumask_set_cpu(target, &pmu_cpu);\r\nreturn 0;\r\n}\r\nvoid l2x0_pmu_suspend(void)\r\n{\r\nint i;\r\nif (!l2x0_pmu)\r\nreturn;\r\nl2x0_pmu_disable(l2x0_pmu);\r\nfor (i = 0; i < PMU_NR_COUNTERS; i++) {\r\nif (events[i])\r\nl2x0_pmu_event_stop(events[i], PERF_EF_UPDATE);\r\n}\r\n}\r\nvoid l2x0_pmu_resume(void)\r\n{\r\nint i;\r\nif (!l2x0_pmu)\r\nreturn;\r\nl2x0_pmu_reset();\r\nfor (i = 0; i < PMU_NR_COUNTERS; i++) {\r\nif (events[i])\r\nl2x0_pmu_event_start(events[i], PERF_EF_RELOAD);\r\n}\r\nl2x0_pmu_enable(l2x0_pmu);\r\n}\r\nvoid __init l2x0_pmu_register(void __iomem *base, u32 part)\r\n{\r\nswitch (part & L2X0_CACHE_ID_PART_MASK) {\r\ncase L2X0_CACHE_ID_PART_L220:\r\nl2x0_name = "l2c_220";\r\nbreak;\r\ncase L2X0_CACHE_ID_PART_L310:\r\nl2x0_name = "l2c_310";\r\nbreak;\r\ndefault:\r\nreturn;\r\n}\r\nl2x0_base = base;\r\n}\r\nstatic __init int l2x0_pmu_init(void)\r\n{\r\nint ret;\r\nif (!l2x0_base)\r\nreturn 0;\r\nl2x0_pmu = kzalloc(sizeof(*l2x0_pmu), GFP_KERNEL);\r\nif (!l2x0_pmu) {\r\npr_warn("Unable to allocate L2x0 PMU\n");\r\nreturn -ENOMEM;\r\n}\r\n*l2x0_pmu = (struct pmu) {\r\n.task_ctx_nr = perf_invalid_context,\r\n.pmu_enable = l2x0_pmu_enable,\r\n.pmu_disable = l2x0_pmu_disable,\r\n.read = l2x0_pmu_event_read,\r\n.start = l2x0_pmu_event_start,\r\n.stop = l2x0_pmu_event_stop,\r\n.add = l2x0_pmu_event_add,\r\n.del = l2x0_pmu_event_del,\r\n.event_init = l2x0_pmu_event_init,\r\n.attr_groups = l2x0_pmu_attr_groups,\r\n};\r\nl2x0_pmu_reset();\r\nl2x0_pmu_poll_period = ms_to_ktime(1000);\r\nhrtimer_init(&l2x0_pmu_hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\r\nl2x0_pmu_hrtimer.function = l2x0_pmu_poll;\r\ncpumask_set_cpu(0, &pmu_cpu);\r\nret = cpuhp_setup_state_nocalls(CPUHP_AP_PERF_ARM_L2X0_ONLINE,\r\n"perf/arm/l2x0:online", NULL,\r\nl2x0_pmu_offline_cpu);\r\nif (ret)\r\ngoto out_pmu;\r\nret = perf_pmu_register(l2x0_pmu, l2x0_name, -1);\r\nif (ret)\r\ngoto out_cpuhp;\r\nreturn 0;\r\nout_cpuhp:\r\ncpuhp_remove_state_nocalls(CPUHP_AP_PERF_ARM_L2X0_ONLINE);\r\nout_pmu:\r\nkfree(l2x0_pmu);\r\nl2x0_pmu = NULL;\r\nreturn ret;\r\n}
