static ssize_t xgene_pmu_format_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct dev_ext_attribute *eattr;\r\neattr = container_of(attr, struct dev_ext_attribute, attr);\r\nreturn sprintf(buf, "%s\n", (char *) eattr->var);\r\n}\r\nstatic ssize_t xgene_pmu_event_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct dev_ext_attribute *eattr;\r\neattr = container_of(attr, struct dev_ext_attribute, attr);\r\nreturn sprintf(buf, "config=0x%lx\n", (unsigned long) eattr->var);\r\n}\r\nstatic ssize_t xgene_pmu_cpumask_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(dev_get_drvdata(dev));\r\nreturn cpumap_print_to_pagebuf(true, buf, &pmu_dev->parent->cpu);\r\n}\r\nstatic int get_next_avail_cntr(struct xgene_pmu_dev *pmu_dev)\r\n{\r\nint cntr;\r\ncntr = find_first_zero_bit(pmu_dev->cntr_assign_mask,\r\npmu_dev->max_counters);\r\nif (cntr == pmu_dev->max_counters)\r\nreturn -ENOSPC;\r\nset_bit(cntr, pmu_dev->cntr_assign_mask);\r\nreturn cntr;\r\n}\r\nstatic void clear_avail_cntr(struct xgene_pmu_dev *pmu_dev, int cntr)\r\n{\r\nclear_bit(cntr, pmu_dev->cntr_assign_mask);\r\n}\r\nstatic inline void xgene_pmu_mask_int(struct xgene_pmu *xgene_pmu)\r\n{\r\nwritel(PCPPMU_INTENMASK, xgene_pmu->pcppmu_csr + PCPPMU_INTMASK_REG);\r\n}\r\nstatic inline void xgene_pmu_unmask_int(struct xgene_pmu *xgene_pmu)\r\n{\r\nwritel(PCPPMU_INTCLRMASK, xgene_pmu->pcppmu_csr + PCPPMU_INTMASK_REG);\r\n}\r\nstatic inline u32 xgene_pmu_read_counter(struct xgene_pmu_dev *pmu_dev, int idx)\r\n{\r\nreturn readl(pmu_dev->inf->csr + PMU_PMEVCNTR0 + (4 * idx));\r\n}\r\nstatic inline void\r\nxgene_pmu_write_counter(struct xgene_pmu_dev *pmu_dev, int idx, u32 val)\r\n{\r\nwritel(val, pmu_dev->inf->csr + PMU_PMEVCNTR0 + (4 * idx));\r\n}\r\nstatic inline void\r\nxgene_pmu_write_evttype(struct xgene_pmu_dev *pmu_dev, int idx, u32 val)\r\n{\r\nwritel(val, pmu_dev->inf->csr + PMU_PMEVTYPER0 + (4 * idx));\r\n}\r\nstatic inline void\r\nxgene_pmu_write_agentmsk(struct xgene_pmu_dev *pmu_dev, u32 val)\r\n{\r\nwritel(val, pmu_dev->inf->csr + PMU_PMAMR0);\r\n}\r\nstatic inline void\r\nxgene_pmu_write_agent1msk(struct xgene_pmu_dev *pmu_dev, u32 val)\r\n{\r\nwritel(val, pmu_dev->inf->csr + PMU_PMAMR1);\r\n}\r\nstatic inline void\r\nxgene_pmu_enable_counter(struct xgene_pmu_dev *pmu_dev, int idx)\r\n{\r\nu32 val;\r\nval = readl(pmu_dev->inf->csr + PMU_PMCNTENSET);\r\nval |= 1 << idx;\r\nwritel(val, pmu_dev->inf->csr + PMU_PMCNTENSET);\r\n}\r\nstatic inline void\r\nxgene_pmu_disable_counter(struct xgene_pmu_dev *pmu_dev, int idx)\r\n{\r\nu32 val;\r\nval = readl(pmu_dev->inf->csr + PMU_PMCNTENCLR);\r\nval |= 1 << idx;\r\nwritel(val, pmu_dev->inf->csr + PMU_PMCNTENCLR);\r\n}\r\nstatic inline void\r\nxgene_pmu_enable_counter_int(struct xgene_pmu_dev *pmu_dev, int idx)\r\n{\r\nu32 val;\r\nval = readl(pmu_dev->inf->csr + PMU_PMINTENSET);\r\nval |= 1 << idx;\r\nwritel(val, pmu_dev->inf->csr + PMU_PMINTENSET);\r\n}\r\nstatic inline void\r\nxgene_pmu_disable_counter_int(struct xgene_pmu_dev *pmu_dev, int idx)\r\n{\r\nu32 val;\r\nval = readl(pmu_dev->inf->csr + PMU_PMINTENCLR);\r\nval |= 1 << idx;\r\nwritel(val, pmu_dev->inf->csr + PMU_PMINTENCLR);\r\n}\r\nstatic inline void xgene_pmu_reset_counters(struct xgene_pmu_dev *pmu_dev)\r\n{\r\nu32 val;\r\nval = readl(pmu_dev->inf->csr + PMU_PMCR);\r\nval |= PMU_PMCR_P;\r\nwritel(val, pmu_dev->inf->csr + PMU_PMCR);\r\n}\r\nstatic inline void xgene_pmu_start_counters(struct xgene_pmu_dev *pmu_dev)\r\n{\r\nu32 val;\r\nval = readl(pmu_dev->inf->csr + PMU_PMCR);\r\nval |= PMU_PMCR_E;\r\nwritel(val, pmu_dev->inf->csr + PMU_PMCR);\r\n}\r\nstatic inline void xgene_pmu_stop_counters(struct xgene_pmu_dev *pmu_dev)\r\n{\r\nu32 val;\r\nval = readl(pmu_dev->inf->csr + PMU_PMCR);\r\nval &= ~PMU_PMCR_E;\r\nwritel(val, pmu_dev->inf->csr + PMU_PMCR);\r\n}\r\nstatic void xgene_perf_pmu_enable(struct pmu *pmu)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(pmu);\r\nint enabled = bitmap_weight(pmu_dev->cntr_assign_mask,\r\npmu_dev->max_counters);\r\nif (!enabled)\r\nreturn;\r\nxgene_pmu_start_counters(pmu_dev);\r\n}\r\nstatic void xgene_perf_pmu_disable(struct pmu *pmu)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(pmu);\r\nxgene_pmu_stop_counters(pmu_dev);\r\n}\r\nstatic int xgene_perf_event_init(struct perf_event *event)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nstruct perf_event *sibling;\r\nif (event->attr.type != event->pmu->type)\r\nreturn -ENOENT;\r\nif (is_sampling_event(event) || event->attach_state & PERF_ATTACH_TASK)\r\nreturn -EINVAL;\r\nif (event->attr.exclude_user || event->attr.exclude_kernel ||\r\nevent->attr.exclude_host || event->attr.exclude_guest)\r\nreturn -EINVAL;\r\nif (event->cpu < 0)\r\nreturn -EINVAL;\r\nevent->cpu = cpumask_first(&pmu_dev->parent->cpu);\r\nhw->config = event->attr.config;\r\nhw->config_base = event->attr.config1;\r\nif (event->group_leader->pmu != event->pmu &&\r\n!is_software_event(event->group_leader))\r\nreturn -EINVAL;\r\nlist_for_each_entry(sibling, &event->group_leader->sibling_list,\r\ngroup_entry)\r\nif (sibling->pmu != event->pmu &&\r\n!is_software_event(sibling))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic void xgene_perf_enable_event(struct perf_event *event)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nxgene_pmu_write_evttype(pmu_dev, GET_CNTR(event), GET_EVENTID(event));\r\nxgene_pmu_write_agentmsk(pmu_dev, ~((u32)GET_AGENTID(event)));\r\nif (pmu_dev->inf->type == PMU_TYPE_IOB)\r\nxgene_pmu_write_agent1msk(pmu_dev, ~((u32)GET_AGENT1ID(event)));\r\nxgene_pmu_enable_counter(pmu_dev, GET_CNTR(event));\r\nxgene_pmu_enable_counter_int(pmu_dev, GET_CNTR(event));\r\n}\r\nstatic void xgene_perf_disable_event(struct perf_event *event)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nxgene_pmu_disable_counter(pmu_dev, GET_CNTR(event));\r\nxgene_pmu_disable_counter_int(pmu_dev, GET_CNTR(event));\r\n}\r\nstatic void xgene_perf_event_set_period(struct perf_event *event)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nu64 val = 1ULL << 31;\r\nlocal64_set(&hw->prev_count, val);\r\nxgene_pmu_write_counter(pmu_dev, hw->idx, (u32) val);\r\n}\r\nstatic void xgene_perf_event_update(struct perf_event *event)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nu64 delta, prev_raw_count, new_raw_count;\r\nagain:\r\nprev_raw_count = local64_read(&hw->prev_count);\r\nnew_raw_count = xgene_pmu_read_counter(pmu_dev, GET_CNTR(event));\r\nif (local64_cmpxchg(&hw->prev_count, prev_raw_count,\r\nnew_raw_count) != prev_raw_count)\r\ngoto again;\r\ndelta = (new_raw_count - prev_raw_count) & pmu_dev->max_period;\r\nlocal64_add(delta, &event->count);\r\n}\r\nstatic void xgene_perf_read(struct perf_event *event)\r\n{\r\nxgene_perf_event_update(event);\r\n}\r\nstatic void xgene_perf_start(struct perf_event *event, int flags)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nif (WARN_ON_ONCE(!(hw->state & PERF_HES_STOPPED)))\r\nreturn;\r\nWARN_ON_ONCE(!(hw->state & PERF_HES_UPTODATE));\r\nhw->state = 0;\r\nxgene_perf_event_set_period(event);\r\nif (flags & PERF_EF_RELOAD) {\r\nu64 prev_raw_count = local64_read(&hw->prev_count);\r\nxgene_pmu_write_counter(pmu_dev, GET_CNTR(event),\r\n(u32) prev_raw_count);\r\n}\r\nxgene_perf_enable_event(event);\r\nperf_event_update_userpage(event);\r\n}\r\nstatic void xgene_perf_stop(struct perf_event *event, int flags)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\nu64 config;\r\nif (hw->state & PERF_HES_UPTODATE)\r\nreturn;\r\nxgene_perf_disable_event(event);\r\nWARN_ON_ONCE(hw->state & PERF_HES_STOPPED);\r\nhw->state |= PERF_HES_STOPPED;\r\nif (hw->state & PERF_HES_UPTODATE)\r\nreturn;\r\nconfig = hw->config;\r\nxgene_perf_read(event);\r\nhw->state |= PERF_HES_UPTODATE;\r\n}\r\nstatic int xgene_perf_add(struct perf_event *event, int flags)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nhw->state = PERF_HES_UPTODATE | PERF_HES_STOPPED;\r\nhw->idx = get_next_avail_cntr(pmu_dev);\r\nif (hw->idx < 0)\r\nreturn -EAGAIN;\r\npmu_dev->pmu_counter_event[hw->idx] = event;\r\nif (flags & PERF_EF_START)\r\nxgene_perf_start(event, PERF_EF_RELOAD);\r\nreturn 0;\r\n}\r\nstatic void xgene_perf_del(struct perf_event *event, int flags)\r\n{\r\nstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nxgene_perf_stop(event, PERF_EF_UPDATE);\r\nclear_avail_cntr(pmu_dev, GET_CNTR(event));\r\nperf_event_update_userpage(event);\r\npmu_dev->pmu_counter_event[hw->idx] = NULL;\r\n}\r\nstatic int xgene_init_perf(struct xgene_pmu_dev *pmu_dev, char *name)\r\n{\r\nstruct xgene_pmu *xgene_pmu;\r\npmu_dev->max_period = PMU_CNT_MAX_PERIOD - 1;\r\nxgene_pmu = pmu_dev->parent;\r\nif (xgene_pmu->version == PCP_PMU_V1)\r\npmu_dev->max_counters = 1;\r\nelse\r\npmu_dev->max_counters = PMU_MAX_COUNTERS;\r\npmu_dev->pmu = (struct pmu) {\r\n.attr_groups = pmu_dev->attr_groups,\r\n.task_ctx_nr = perf_invalid_context,\r\n.pmu_enable = xgene_perf_pmu_enable,\r\n.pmu_disable = xgene_perf_pmu_disable,\r\n.event_init = xgene_perf_event_init,\r\n.add = xgene_perf_add,\r\n.del = xgene_perf_del,\r\n.start = xgene_perf_start,\r\n.stop = xgene_perf_stop,\r\n.read = xgene_perf_read,\r\n};\r\nxgene_pmu_stop_counters(pmu_dev);\r\nxgene_pmu_reset_counters(pmu_dev);\r\nreturn perf_pmu_register(&pmu_dev->pmu, name, -1);\r\n}\r\nstatic int\r\nxgene_pmu_dev_add(struct xgene_pmu *xgene_pmu, struct xgene_pmu_dev_ctx *ctx)\r\n{\r\nstruct device *dev = xgene_pmu->dev;\r\nstruct xgene_pmu_dev *pmu;\r\nint rc;\r\npmu = devm_kzalloc(dev, sizeof(*pmu), GFP_KERNEL);\r\nif (!pmu)\r\nreturn -ENOMEM;\r\npmu->parent = xgene_pmu;\r\npmu->inf = &ctx->inf;\r\nctx->pmu_dev = pmu;\r\nswitch (pmu->inf->type) {\r\ncase PMU_TYPE_L3C:\r\npmu->attr_groups = l3c_pmu_attr_groups;\r\nbreak;\r\ncase PMU_TYPE_IOB:\r\npmu->attr_groups = iob_pmu_attr_groups;\r\nbreak;\r\ncase PMU_TYPE_MCB:\r\nif (!(xgene_pmu->mcb_active_mask & pmu->inf->enable_mask))\r\ngoto dev_err;\r\npmu->attr_groups = mcb_pmu_attr_groups;\r\nbreak;\r\ncase PMU_TYPE_MC:\r\nif (!(xgene_pmu->mc_active_mask & pmu->inf->enable_mask))\r\ngoto dev_err;\r\npmu->attr_groups = mc_pmu_attr_groups;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nrc = xgene_init_perf(pmu, ctx->name);\r\nif (rc) {\r\ndev_err(dev, "%s PMU: Failed to init perf driver\n", ctx->name);\r\ngoto dev_err;\r\n}\r\ndev_info(dev, "%s PMU registered\n", ctx->name);\r\nreturn rc;\r\ndev_err:\r\ndevm_kfree(dev, pmu);\r\nreturn -ENODEV;\r\n}\r\nstatic void _xgene_pmu_isr(int irq, struct xgene_pmu_dev *pmu_dev)\r\n{\r\nstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\r\nu32 pmovsr;\r\nint idx;\r\npmovsr = readl(pmu_dev->inf->csr + PMU_PMOVSR) & PMU_OVERFLOW_MASK;\r\nif (!pmovsr)\r\nreturn;\r\nif (xgene_pmu->version == PCP_PMU_V1)\r\nwritel(0x0, pmu_dev->inf->csr + PMU_PMOVSR);\r\nelse\r\nwritel(pmovsr, pmu_dev->inf->csr + PMU_PMOVSR);\r\nfor (idx = 0; idx < PMU_MAX_COUNTERS; idx++) {\r\nstruct perf_event *event = pmu_dev->pmu_counter_event[idx];\r\nint overflowed = pmovsr & BIT(idx);\r\nif (!event || !overflowed)\r\ncontinue;\r\nxgene_perf_event_update(event);\r\nxgene_perf_event_set_period(event);\r\n}\r\n}\r\nstatic irqreturn_t xgene_pmu_isr(int irq, void *dev_id)\r\n{\r\nstruct xgene_pmu_dev_ctx *ctx;\r\nstruct xgene_pmu *xgene_pmu = dev_id;\r\nunsigned long flags;\r\nu32 val;\r\nraw_spin_lock_irqsave(&xgene_pmu->lock, flags);\r\nval = readl(xgene_pmu->pcppmu_csr + PCPPMU_INTSTATUS_REG);\r\nif (val & PCPPMU_INT_MCU) {\r\nlist_for_each_entry(ctx, &xgene_pmu->mcpmus, next) {\r\n_xgene_pmu_isr(irq, ctx->pmu_dev);\r\n}\r\n}\r\nif (val & PCPPMU_INT_MCB) {\r\nlist_for_each_entry(ctx, &xgene_pmu->mcbpmus, next) {\r\n_xgene_pmu_isr(irq, ctx->pmu_dev);\r\n}\r\n}\r\nif (val & PCPPMU_INT_L3C) {\r\nlist_for_each_entry(ctx, &xgene_pmu->l3cpmus, next) {\r\n_xgene_pmu_isr(irq, ctx->pmu_dev);\r\n}\r\n}\r\nif (val & PCPPMU_INT_IOB) {\r\nlist_for_each_entry(ctx, &xgene_pmu->iobpmus, next) {\r\n_xgene_pmu_isr(irq, ctx->pmu_dev);\r\n}\r\n}\r\nraw_spin_unlock_irqrestore(&xgene_pmu->lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int acpi_pmu_probe_active_mcb_mcu(struct xgene_pmu *xgene_pmu,\r\nstruct platform_device *pdev)\r\n{\r\nvoid __iomem *csw_csr, *mcba_csr, *mcbb_csr;\r\nstruct resource *res;\r\nunsigned int reg;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 1);\r\ncsw_csr = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(csw_csr)) {\r\ndev_err(&pdev->dev, "ioremap failed for CSW CSR resource\n");\r\nreturn PTR_ERR(csw_csr);\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 2);\r\nmcba_csr = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(mcba_csr)) {\r\ndev_err(&pdev->dev, "ioremap failed for MCBA CSR resource\n");\r\nreturn PTR_ERR(mcba_csr);\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 3);\r\nmcbb_csr = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(mcbb_csr)) {\r\ndev_err(&pdev->dev, "ioremap failed for MCBB CSR resource\n");\r\nreturn PTR_ERR(mcbb_csr);\r\n}\r\nreg = readl(csw_csr + CSW_CSWCR);\r\nif (reg & CSW_CSWCR_DUALMCB_MASK) {\r\nxgene_pmu->mcb_active_mask = 0x3;\r\nreg = readl(mcbb_csr + CSW_CSWCR);\r\nxgene_pmu->mc_active_mask =\r\n(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0xF : 0x5;\r\n} else {\r\nxgene_pmu->mcb_active_mask = 0x1;\r\nreg = readl(mcba_csr + CSW_CSWCR);\r\nxgene_pmu->mc_active_mask =\r\n(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0x3 : 0x1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int fdt_pmu_probe_active_mcb_mcu(struct xgene_pmu *xgene_pmu,\r\nstruct platform_device *pdev)\r\n{\r\nstruct regmap *csw_map, *mcba_map, *mcbb_map;\r\nstruct device_node *np = pdev->dev.of_node;\r\nunsigned int reg;\r\ncsw_map = syscon_regmap_lookup_by_phandle(np, "regmap-csw");\r\nif (IS_ERR(csw_map)) {\r\ndev_err(&pdev->dev, "unable to get syscon regmap csw\n");\r\nreturn PTR_ERR(csw_map);\r\n}\r\nmcba_map = syscon_regmap_lookup_by_phandle(np, "regmap-mcba");\r\nif (IS_ERR(mcba_map)) {\r\ndev_err(&pdev->dev, "unable to get syscon regmap mcba\n");\r\nreturn PTR_ERR(mcba_map);\r\n}\r\nmcbb_map = syscon_regmap_lookup_by_phandle(np, "regmap-mcbb");\r\nif (IS_ERR(mcbb_map)) {\r\ndev_err(&pdev->dev, "unable to get syscon regmap mcbb\n");\r\nreturn PTR_ERR(mcbb_map);\r\n}\r\nif (regmap_read(csw_map, CSW_CSWCR, &reg))\r\nreturn -EINVAL;\r\nif (reg & CSW_CSWCR_DUALMCB_MASK) {\r\nxgene_pmu->mcb_active_mask = 0x3;\r\nif (regmap_read(mcbb_map, MCBADDRMR, &reg))\r\nreturn 0;\r\nxgene_pmu->mc_active_mask =\r\n(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0xF : 0x5;\r\n} else {\r\nxgene_pmu->mcb_active_mask = 0x1;\r\nif (regmap_read(mcba_map, MCBADDRMR, &reg))\r\nreturn 0;\r\nxgene_pmu->mc_active_mask =\r\n(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0x3 : 0x1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int xgene_pmu_probe_active_mcb_mcu(struct xgene_pmu *xgene_pmu,\r\nstruct platform_device *pdev)\r\n{\r\nif (has_acpi_companion(&pdev->dev))\r\nreturn acpi_pmu_probe_active_mcb_mcu(xgene_pmu, pdev);\r\nreturn fdt_pmu_probe_active_mcb_mcu(xgene_pmu, pdev);\r\n}\r\nstatic char *xgene_pmu_dev_name(struct device *dev, u32 type, int id)\r\n{\r\nswitch (type) {\r\ncase PMU_TYPE_L3C:\r\nreturn devm_kasprintf(dev, GFP_KERNEL, "l3c%d", id);\r\ncase PMU_TYPE_IOB:\r\nreturn devm_kasprintf(dev, GFP_KERNEL, "iob%d", id);\r\ncase PMU_TYPE_MCB:\r\nreturn devm_kasprintf(dev, GFP_KERNEL, "mcb%d", id);\r\ncase PMU_TYPE_MC:\r\nreturn devm_kasprintf(dev, GFP_KERNEL, "mc%d", id);\r\ndefault:\r\nreturn devm_kasprintf(dev, GFP_KERNEL, "unknown");\r\n}\r\n}\r\nstatic int acpi_pmu_dev_add_resource(struct acpi_resource *ares, void *data)\r\n{\r\nstruct resource *res = data;\r\nif (ares->type == ACPI_RESOURCE_TYPE_FIXED_MEMORY32)\r\nacpi_dev_resource_memory(ares, res);\r\nreturn 1;\r\n}\r\nstatic struct\r\nxgene_pmu_dev_ctx *acpi_get_pmu_hw_inf(struct xgene_pmu *xgene_pmu,\r\nstruct acpi_device *adev, u32 type)\r\n{\r\nstruct device *dev = xgene_pmu->dev;\r\nstruct list_head resource_list;\r\nstruct xgene_pmu_dev_ctx *ctx;\r\nconst union acpi_object *obj;\r\nstruct hw_pmu_info *inf;\r\nvoid __iomem *dev_csr;\r\nstruct resource res;\r\nint enable_bit;\r\nint rc;\r\nctx = devm_kzalloc(dev, sizeof(*ctx), GFP_KERNEL);\r\nif (!ctx)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&resource_list);\r\nrc = acpi_dev_get_resources(adev, &resource_list,\r\nacpi_pmu_dev_add_resource, &res);\r\nacpi_dev_free_resource_list(&resource_list);\r\nif (rc < 0) {\r\ndev_err(dev, "PMU type %d: No resource address found\n", type);\r\ngoto err;\r\n}\r\ndev_csr = devm_ioremap_resource(dev, &res);\r\nif (IS_ERR(dev_csr)) {\r\ndev_err(dev, "PMU type %d: Fail to map resource\n", type);\r\ngoto err;\r\n}\r\nrc = acpi_dev_get_property(adev, "enable-bit-index",\r\nACPI_TYPE_INTEGER, &obj);\r\nif (rc < 0)\r\nenable_bit = 0;\r\nelse\r\nenable_bit = (int) obj->integer.value;\r\nctx->name = xgene_pmu_dev_name(dev, type, enable_bit);\r\nif (!ctx->name) {\r\ndev_err(dev, "PMU type %d: Fail to get device name\n", type);\r\ngoto err;\r\n}\r\ninf = &ctx->inf;\r\ninf->type = type;\r\ninf->csr = dev_csr;\r\ninf->enable_mask = 1 << enable_bit;\r\nreturn ctx;\r\nerr:\r\ndevm_kfree(dev, ctx);\r\nreturn NULL;\r\n}\r\nstatic acpi_status acpi_pmu_dev_add(acpi_handle handle, u32 level,\r\nvoid *data, void **return_value)\r\n{\r\nstruct xgene_pmu *xgene_pmu = data;\r\nstruct xgene_pmu_dev_ctx *ctx;\r\nstruct acpi_device *adev;\r\nif (acpi_bus_get_device(handle, &adev))\r\nreturn AE_OK;\r\nif (acpi_bus_get_status(adev) || !adev->status.present)\r\nreturn AE_OK;\r\nif (!strcmp(acpi_device_hid(adev), "APMC0D5D"))\r\nctx = acpi_get_pmu_hw_inf(xgene_pmu, adev, PMU_TYPE_L3C);\r\nelse if (!strcmp(acpi_device_hid(adev), "APMC0D5E"))\r\nctx = acpi_get_pmu_hw_inf(xgene_pmu, adev, PMU_TYPE_IOB);\r\nelse if (!strcmp(acpi_device_hid(adev), "APMC0D5F"))\r\nctx = acpi_get_pmu_hw_inf(xgene_pmu, adev, PMU_TYPE_MCB);\r\nelse if (!strcmp(acpi_device_hid(adev), "APMC0D60"))\r\nctx = acpi_get_pmu_hw_inf(xgene_pmu, adev, PMU_TYPE_MC);\r\nelse\r\nctx = NULL;\r\nif (!ctx)\r\nreturn AE_OK;\r\nif (xgene_pmu_dev_add(xgene_pmu, ctx)) {\r\ndevm_kfree(xgene_pmu->dev, ctx);\r\nreturn AE_OK;\r\n}\r\nswitch (ctx->inf.type) {\r\ncase PMU_TYPE_L3C:\r\nlist_add(&ctx->next, &xgene_pmu->l3cpmus);\r\nbreak;\r\ncase PMU_TYPE_IOB:\r\nlist_add(&ctx->next, &xgene_pmu->iobpmus);\r\nbreak;\r\ncase PMU_TYPE_MCB:\r\nlist_add(&ctx->next, &xgene_pmu->mcbpmus);\r\nbreak;\r\ncase PMU_TYPE_MC:\r\nlist_add(&ctx->next, &xgene_pmu->mcpmus);\r\nbreak;\r\n}\r\nreturn AE_OK;\r\n}\r\nstatic int acpi_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\r\nstruct platform_device *pdev)\r\n{\r\nstruct device *dev = xgene_pmu->dev;\r\nacpi_handle handle;\r\nacpi_status status;\r\nhandle = ACPI_HANDLE(dev);\r\nif (!handle)\r\nreturn -EINVAL;\r\nstatus = acpi_walk_namespace(ACPI_TYPE_DEVICE, handle, 1,\r\nacpi_pmu_dev_add, NULL, xgene_pmu, NULL);\r\nif (ACPI_FAILURE(status)) {\r\ndev_err(dev, "failed to probe PMU devices\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int acpi_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\r\nstruct platform_device *pdev)\r\n{\r\nreturn 0;\r\n}\r\nstatic struct\r\nxgene_pmu_dev_ctx *fdt_get_pmu_hw_inf(struct xgene_pmu *xgene_pmu,\r\nstruct device_node *np, u32 type)\r\n{\r\nstruct device *dev = xgene_pmu->dev;\r\nstruct xgene_pmu_dev_ctx *ctx;\r\nstruct hw_pmu_info *inf;\r\nvoid __iomem *dev_csr;\r\nstruct resource res;\r\nint enable_bit;\r\nint rc;\r\nctx = devm_kzalloc(dev, sizeof(*ctx), GFP_KERNEL);\r\nif (!ctx)\r\nreturn NULL;\r\nrc = of_address_to_resource(np, 0, &res);\r\nif (rc < 0) {\r\ndev_err(dev, "PMU type %d: No resource address found\n", type);\r\ngoto err;\r\n}\r\ndev_csr = devm_ioremap_resource(dev, &res);\r\nif (IS_ERR(dev_csr)) {\r\ndev_err(dev, "PMU type %d: Fail to map resource\n", type);\r\ngoto err;\r\n}\r\nif (of_property_read_u32(np, "enable-bit-index", &enable_bit))\r\nenable_bit = 0;\r\nctx->name = xgene_pmu_dev_name(dev, type, enable_bit);\r\nif (!ctx->name) {\r\ndev_err(dev, "PMU type %d: Fail to get device name\n", type);\r\ngoto err;\r\n}\r\ninf = &ctx->inf;\r\ninf->type = type;\r\ninf->csr = dev_csr;\r\ninf->enable_mask = 1 << enable_bit;\r\nreturn ctx;\r\nerr:\r\ndevm_kfree(dev, ctx);\r\nreturn NULL;\r\n}\r\nstatic int fdt_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\r\nstruct platform_device *pdev)\r\n{\r\nstruct xgene_pmu_dev_ctx *ctx;\r\nstruct device_node *np;\r\nfor_each_child_of_node(pdev->dev.of_node, np) {\r\nif (!of_device_is_available(np))\r\ncontinue;\r\nif (of_device_is_compatible(np, "apm,xgene-pmu-l3c"))\r\nctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_L3C);\r\nelse if (of_device_is_compatible(np, "apm,xgene-pmu-iob"))\r\nctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_IOB);\r\nelse if (of_device_is_compatible(np, "apm,xgene-pmu-mcb"))\r\nctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_MCB);\r\nelse if (of_device_is_compatible(np, "apm,xgene-pmu-mc"))\r\nctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_MC);\r\nelse\r\nctx = NULL;\r\nif (!ctx)\r\ncontinue;\r\nif (xgene_pmu_dev_add(xgene_pmu, ctx)) {\r\ndevm_kfree(xgene_pmu->dev, ctx);\r\ncontinue;\r\n}\r\nswitch (ctx->inf.type) {\r\ncase PMU_TYPE_L3C:\r\nlist_add(&ctx->next, &xgene_pmu->l3cpmus);\r\nbreak;\r\ncase PMU_TYPE_IOB:\r\nlist_add(&ctx->next, &xgene_pmu->iobpmus);\r\nbreak;\r\ncase PMU_TYPE_MCB:\r\nlist_add(&ctx->next, &xgene_pmu->mcbpmus);\r\nbreak;\r\ncase PMU_TYPE_MC:\r\nlist_add(&ctx->next, &xgene_pmu->mcpmus);\r\nbreak;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int xgene_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\r\nstruct platform_device *pdev)\r\n{\r\nif (has_acpi_companion(&pdev->dev))\r\nreturn acpi_pmu_probe_pmu_dev(xgene_pmu, pdev);\r\nreturn fdt_pmu_probe_pmu_dev(xgene_pmu, pdev);\r\n}\r\nstatic int xgene_pmu_probe(struct platform_device *pdev)\r\n{\r\nconst struct xgene_pmu_data *dev_data;\r\nconst struct of_device_id *of_id;\r\nstruct xgene_pmu *xgene_pmu;\r\nstruct resource *res;\r\nint irq, rc;\r\nint version;\r\nxgene_pmu = devm_kzalloc(&pdev->dev, sizeof(*xgene_pmu), GFP_KERNEL);\r\nif (!xgene_pmu)\r\nreturn -ENOMEM;\r\nxgene_pmu->dev = &pdev->dev;\r\nplatform_set_drvdata(pdev, xgene_pmu);\r\nversion = -EINVAL;\r\nof_id = of_match_device(xgene_pmu_of_match, &pdev->dev);\r\nif (of_id) {\r\ndev_data = (const struct xgene_pmu_data *) of_id->data;\r\nversion = dev_data->id;\r\n}\r\n#ifdef CONFIG_ACPI\r\nif (ACPI_COMPANION(&pdev->dev)) {\r\nconst struct acpi_device_id *acpi_id;\r\nacpi_id = acpi_match_device(xgene_pmu_acpi_match, &pdev->dev);\r\nif (acpi_id)\r\nversion = (int) acpi_id->driver_data;\r\n}\r\n#endif\r\nif (version < 0)\r\nreturn -ENODEV;\r\nINIT_LIST_HEAD(&xgene_pmu->l3cpmus);\r\nINIT_LIST_HEAD(&xgene_pmu->iobpmus);\r\nINIT_LIST_HEAD(&xgene_pmu->mcbpmus);\r\nINIT_LIST_HEAD(&xgene_pmu->mcpmus);\r\nxgene_pmu->version = version;\r\ndev_info(&pdev->dev, "X-Gene PMU version %d\n", xgene_pmu->version);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nxgene_pmu->pcppmu_csr = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(xgene_pmu->pcppmu_csr)) {\r\ndev_err(&pdev->dev, "ioremap failed for PCP PMU resource\n");\r\nrc = PTR_ERR(xgene_pmu->pcppmu_csr);\r\ngoto err;\r\n}\r\nirq = platform_get_irq(pdev, 0);\r\nif (irq < 0) {\r\ndev_err(&pdev->dev, "No IRQ resource\n");\r\nrc = -EINVAL;\r\ngoto err;\r\n}\r\nrc = devm_request_irq(&pdev->dev, irq, xgene_pmu_isr,\r\nIRQF_NOBALANCING | IRQF_NO_THREAD,\r\ndev_name(&pdev->dev), xgene_pmu);\r\nif (rc) {\r\ndev_err(&pdev->dev, "Could not request IRQ %d\n", irq);\r\ngoto err;\r\n}\r\nraw_spin_lock_init(&xgene_pmu->lock);\r\nrc = xgene_pmu_probe_active_mcb_mcu(xgene_pmu, pdev);\r\nif (rc) {\r\ndev_warn(&pdev->dev, "Unknown MCB/MCU active status\n");\r\nxgene_pmu->mcb_active_mask = 0x1;\r\nxgene_pmu->mc_active_mask = 0x1;\r\n}\r\ncpumask_set_cpu(smp_processor_id(), &xgene_pmu->cpu);\r\nrc = irq_set_affinity(irq, &xgene_pmu->cpu);\r\nif (rc) {\r\ndev_err(&pdev->dev, "Failed to set interrupt affinity!\n");\r\ngoto err;\r\n}\r\nrc = xgene_pmu_probe_pmu_dev(xgene_pmu, pdev);\r\nif (rc) {\r\ndev_err(&pdev->dev, "No PMU perf devices found!\n");\r\ngoto err;\r\n}\r\nxgene_pmu_unmask_int(xgene_pmu);\r\nreturn 0;\r\nerr:\r\nif (xgene_pmu->pcppmu_csr)\r\ndevm_iounmap(&pdev->dev, xgene_pmu->pcppmu_csr);\r\ndevm_kfree(&pdev->dev, xgene_pmu);\r\nreturn rc;\r\n}\r\nstatic void\r\nxgene_pmu_dev_cleanup(struct xgene_pmu *xgene_pmu, struct list_head *pmus)\r\n{\r\nstruct xgene_pmu_dev_ctx *ctx;\r\nstruct device *dev = xgene_pmu->dev;\r\nstruct xgene_pmu_dev *pmu_dev;\r\nlist_for_each_entry(ctx, pmus, next) {\r\npmu_dev = ctx->pmu_dev;\r\nif (pmu_dev->inf->csr)\r\ndevm_iounmap(dev, pmu_dev->inf->csr);\r\ndevm_kfree(dev, ctx);\r\ndevm_kfree(dev, pmu_dev);\r\n}\r\n}\r\nstatic int xgene_pmu_remove(struct platform_device *pdev)\r\n{\r\nstruct xgene_pmu *xgene_pmu = dev_get_drvdata(&pdev->dev);\r\nxgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->l3cpmus);\r\nxgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->iobpmus);\r\nxgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->mcbpmus);\r\nxgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->mcpmus);\r\nif (xgene_pmu->pcppmu_csr)\r\ndevm_iounmap(&pdev->dev, xgene_pmu->pcppmu_csr);\r\ndevm_kfree(&pdev->dev, xgene_pmu);\r\nreturn 0;\r\n}
