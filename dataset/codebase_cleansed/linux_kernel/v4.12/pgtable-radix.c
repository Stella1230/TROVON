static int native_register_process_table(unsigned long base, unsigned long pg_sz,\r\nunsigned long table_size)\r\n{\r\nunsigned long patb1 = base | table_size | PATB_GR;\r\npartition_tb->patb1 = cpu_to_be64(patb1);\r\nreturn 0;\r\n}\r\nstatic __ref void *early_alloc_pgtable(unsigned long size)\r\n{\r\nvoid *pt;\r\npt = __va(memblock_alloc_base(size, size, MEMBLOCK_ALLOC_ANYWHERE));\r\nmemset(pt, 0, size);\r\nreturn pt;\r\n}\r\nint radix__map_kernel_page(unsigned long ea, unsigned long pa,\r\npgprot_t flags,\r\nunsigned int map_page_size)\r\n{\r\npgd_t *pgdp;\r\npud_t *pudp;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\nBUILD_BUG_ON(TASK_SIZE_USER64 > RADIX_PGTABLE_RANGE);\r\nif (slab_is_available()) {\r\npgdp = pgd_offset_k(ea);\r\npudp = pud_alloc(&init_mm, pgdp, ea);\r\nif (!pudp)\r\nreturn -ENOMEM;\r\nif (map_page_size == PUD_SIZE) {\r\nptep = (pte_t *)pudp;\r\ngoto set_the_pte;\r\n}\r\npmdp = pmd_alloc(&init_mm, pudp, ea);\r\nif (!pmdp)\r\nreturn -ENOMEM;\r\nif (map_page_size == PMD_SIZE) {\r\nptep = pmdp_ptep(pmdp);\r\ngoto set_the_pte;\r\n}\r\nptep = pte_alloc_kernel(pmdp, ea);\r\nif (!ptep)\r\nreturn -ENOMEM;\r\n} else {\r\npgdp = pgd_offset_k(ea);\r\nif (pgd_none(*pgdp)) {\r\npudp = early_alloc_pgtable(PUD_TABLE_SIZE);\r\nBUG_ON(pudp == NULL);\r\npgd_populate(&init_mm, pgdp, pudp);\r\n}\r\npudp = pud_offset(pgdp, ea);\r\nif (map_page_size == PUD_SIZE) {\r\nptep = (pte_t *)pudp;\r\ngoto set_the_pte;\r\n}\r\nif (pud_none(*pudp)) {\r\npmdp = early_alloc_pgtable(PMD_TABLE_SIZE);\r\nBUG_ON(pmdp == NULL);\r\npud_populate(&init_mm, pudp, pmdp);\r\n}\r\npmdp = pmd_offset(pudp, ea);\r\nif (map_page_size == PMD_SIZE) {\r\nptep = pmdp_ptep(pmdp);\r\ngoto set_the_pte;\r\n}\r\nif (!pmd_present(*pmdp)) {\r\nptep = early_alloc_pgtable(PAGE_SIZE);\r\nBUG_ON(ptep == NULL);\r\npmd_populate_kernel(&init_mm, pmdp, ptep);\r\n}\r\nptep = pte_offset_kernel(pmdp, ea);\r\n}\r\nset_the_pte:\r\nset_pte_at(&init_mm, ea, ptep, pfn_pte(pa >> PAGE_SHIFT, flags));\r\nsmp_wmb();\r\nreturn 0;\r\n}\r\nstatic inline void __meminit print_mapping(unsigned long start,\r\nunsigned long end,\r\nunsigned long size)\r\n{\r\nif (end <= start)\r\nreturn;\r\npr_info("Mapped range 0x%lx - 0x%lx with 0x%lx\n", start, end, size);\r\n}\r\nstatic int __meminit create_physical_mapping(unsigned long start,\r\nunsigned long end)\r\n{\r\nunsigned long addr, mapping_size = 0;\r\nstart = _ALIGN_UP(start, PAGE_SIZE);\r\nfor (addr = start; addr < end; addr += mapping_size) {\r\nunsigned long gap, previous_size;\r\nint rc;\r\ngap = end - addr;\r\nprevious_size = mapping_size;\r\nif (IS_ALIGNED(addr, PUD_SIZE) && gap >= PUD_SIZE &&\r\nmmu_psize_defs[MMU_PAGE_1G].shift)\r\nmapping_size = PUD_SIZE;\r\nelse if (IS_ALIGNED(addr, PMD_SIZE) && gap >= PMD_SIZE &&\r\nmmu_psize_defs[MMU_PAGE_2M].shift)\r\nmapping_size = PMD_SIZE;\r\nelse\r\nmapping_size = PAGE_SIZE;\r\nif (mapping_size != previous_size) {\r\nprint_mapping(start, addr, previous_size);\r\nstart = addr;\r\n}\r\nrc = radix__map_kernel_page((unsigned long)__va(addr), addr,\r\nPAGE_KERNEL_X, mapping_size);\r\nif (rc)\r\nreturn rc;\r\n}\r\nprint_mapping(start, addr, mapping_size);\r\nreturn 0;\r\n}\r\nstatic void __init radix_init_pgtable(void)\r\n{\r\nunsigned long rts_field;\r\nstruct memblock_region *reg;\r\nmmu_slb_size = 0;\r\nfor_each_memblock(memory, reg)\r\nWARN_ON(create_physical_mapping(reg->base,\r\nreg->base + reg->size));\r\nBUILD_BUG_ON_MSG((PRTB_SIZE_SHIFT > 36), "Process table size too large.");\r\nprocess_tb = early_alloc_pgtable(1UL << PRTB_SIZE_SHIFT);\r\nrts_field = radix__get_tree_size();\r\nprocess_tb->prtb0 = cpu_to_be64(rts_field | __pa(init_mm.pgd) | RADIX_PGD_INDEX_SIZE);\r\nregister_process_table(__pa(process_tb), 0, PRTB_SIZE_SHIFT - 12);\r\npr_info("Process table %p and radix root for kernel: %p\n", process_tb, init_mm.pgd);\r\nasm volatile("ptesync" : : : "memory");\r\nasm volatile(PPC_TLBIE_5(%0,%1,2,1,1) : :\r\n"r" (TLBIEL_INVAL_SET_LPID), "r" (0));\r\nasm volatile("eieio; tlbsync; ptesync" : : : "memory");\r\n}\r\nstatic void __init radix_init_partition_table(void)\r\n{\r\nunsigned long rts_field, dw0;\r\nmmu_partition_table_init();\r\nrts_field = radix__get_tree_size();\r\ndw0 = rts_field | __pa(init_mm.pgd) | RADIX_PGD_INDEX_SIZE | PATB_HR;\r\nmmu_partition_table_set_entry(0, dw0, 0);\r\npr_info("Initializing Radix MMU\n");\r\npr_info("Partition table %p\n", partition_tb);\r\n}\r\nvoid __init radix_init_native(void)\r\n{\r\nregister_process_table = native_register_process_table;\r\n}\r\nstatic int __init get_idx_from_shift(unsigned int shift)\r\n{\r\nint idx = -1;\r\nswitch (shift) {\r\ncase 0xc:\r\nidx = MMU_PAGE_4K;\r\nbreak;\r\ncase 0x10:\r\nidx = MMU_PAGE_64K;\r\nbreak;\r\ncase 0x15:\r\nidx = MMU_PAGE_2M;\r\nbreak;\r\ncase 0x1e:\r\nidx = MMU_PAGE_1G;\r\nbreak;\r\n}\r\nreturn idx;\r\n}\r\nstatic int __init radix_dt_scan_page_sizes(unsigned long node,\r\nconst char *uname, int depth,\r\nvoid *data)\r\n{\r\nint size = 0;\r\nint shift, idx;\r\nunsigned int ap;\r\nconst __be32 *prop;\r\nconst char *type = of_get_flat_dt_prop(node, "device_type", NULL);\r\nif (type == NULL || strcmp(type, "cpu") != 0)\r\nreturn 0;\r\nprop = of_get_flat_dt_prop(node, "ibm,processor-radix-AP-encodings", &size);\r\nif (!prop)\r\nreturn 0;\r\npr_info("Page sizes from device-tree:\n");\r\nfor (; size >= 4; size -= 4, ++prop) {\r\nstruct mmu_psize_def *def;\r\nshift = be32_to_cpu(prop[0]) & ~(0xe << 28);\r\nap = be32_to_cpu(prop[0]) >> 29;\r\npr_info("Page size shift = %d AP=0x%x\n", shift, ap);\r\nidx = get_idx_from_shift(shift);\r\nif (idx < 0)\r\ncontinue;\r\ndef = &mmu_psize_defs[idx];\r\ndef->shift = shift;\r\ndef->ap = ap;\r\n}\r\ncur_cpu_spec->mmu_features &= ~MMU_FTR_NO_SLBIE_B;\r\nreturn 1;\r\n}\r\nvoid __init radix__early_init_devtree(void)\r\n{\r\nint rc;\r\nrc = of_scan_flat_dt(radix_dt_scan_page_sizes, NULL);\r\nif (rc != 0)\r\ngoto found;\r\nmmu_psize_defs[MMU_PAGE_4K].shift = 12;\r\nmmu_psize_defs[MMU_PAGE_4K].ap = 0x0;\r\nmmu_psize_defs[MMU_PAGE_64K].shift = 16;\r\nmmu_psize_defs[MMU_PAGE_64K].ap = 0x5;\r\nfound:\r\n#ifdef CONFIG_SPARSEMEM_VMEMMAP\r\nif (mmu_psize_defs[MMU_PAGE_2M].shift) {\r\nmmu_vmemmap_psize = MMU_PAGE_2M;\r\n}\r\n#endif\r\nreturn;\r\n}\r\nstatic void update_hid_for_radix(void)\r\n{\r\nunsigned long hid0;\r\nunsigned long rb = 3UL << PPC_BITLSHIFT(53);\r\nasm volatile("ptesync": : :"memory");\r\nasm volatile(PPC_TLBIE_5(%0, %4, %3, %2, %1)\r\n: : "r"(rb), "i"(1), "i"(0), "i"(2), "r"(0) : "memory");\r\nasm volatile(PPC_TLBIE_5(%0, %4, %3, %2, %1)\r\n: : "r"(rb), "i"(1), "i"(1), "i"(2), "r"(0) : "memory");\r\nasm volatile("eieio; tlbsync; ptesync; isync; slbia": : :"memory");\r\nhid0 = mfspr(SPRN_HID0);\r\nhid0 |= HID0_POWER9_RADIX;\r\nmtspr(SPRN_HID0, hid0);\r\nasm volatile("isync": : :"memory");\r\nwhile (!(mfspr(SPRN_HID0) & HID0_POWER9_RADIX))\r\ncpu_relax();\r\n}\r\nstatic void radix_init_amor(void)\r\n{\r\nmtspr(SPRN_AMOR, (3ul << 62));\r\n}\r\nstatic void radix_init_iamr(void)\r\n{\r\nunsigned long iamr;\r\nif (cpu_has_feature(CPU_FTR_POWER9_DD1))\r\niamr = 0;\r\nelse\r\niamr = (1ul << 62);\r\nmtspr(SPRN_IAMR, iamr);\r\n}\r\nvoid __init radix__early_init_mmu(void)\r\n{\r\nunsigned long lpcr;\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nmmu_virtual_psize = MMU_PAGE_64K;\r\n#else\r\nmmu_virtual_psize = MMU_PAGE_4K;\r\n#endif\r\n#ifdef CONFIG_SPARSEMEM_VMEMMAP\r\nmmu_vmemmap_psize = mmu_virtual_psize;\r\n#endif\r\n__pte_index_size = RADIX_PTE_INDEX_SIZE;\r\n__pmd_index_size = RADIX_PMD_INDEX_SIZE;\r\n__pud_index_size = RADIX_PUD_INDEX_SIZE;\r\n__pgd_index_size = RADIX_PGD_INDEX_SIZE;\r\n__pmd_cache_index = RADIX_PMD_INDEX_SIZE;\r\n__pte_table_size = RADIX_PTE_TABLE_SIZE;\r\n__pmd_table_size = RADIX_PMD_TABLE_SIZE;\r\n__pud_table_size = RADIX_PUD_TABLE_SIZE;\r\n__pgd_table_size = RADIX_PGD_TABLE_SIZE;\r\n__pmd_val_bits = RADIX_PMD_VAL_BITS;\r\n__pud_val_bits = RADIX_PUD_VAL_BITS;\r\n__pgd_val_bits = RADIX_PGD_VAL_BITS;\r\n__kernel_virt_start = RADIX_KERN_VIRT_START;\r\n__kernel_virt_size = RADIX_KERN_VIRT_SIZE;\r\n__vmalloc_start = RADIX_VMALLOC_START;\r\n__vmalloc_end = RADIX_VMALLOC_END;\r\nvmemmap = (struct page *)RADIX_VMEMMAP_BASE;\r\nioremap_bot = IOREMAP_BASE;\r\n#ifdef CONFIG_PCI\r\npci_io_base = ISA_IO_BASE;\r\n#endif\r\n__pte_frag_nr = H_PTE_FRAG_NR;\r\n__pte_frag_size_shift = H_PTE_FRAG_SIZE_SHIFT;\r\nif (!firmware_has_feature(FW_FEATURE_LPAR)) {\r\nradix_init_native();\r\nif (cpu_has_feature(CPU_FTR_POWER9_DD1))\r\nupdate_hid_for_radix();\r\nlpcr = mfspr(SPRN_LPCR);\r\nmtspr(SPRN_LPCR, lpcr | LPCR_UPRT | LPCR_HR);\r\nradix_init_partition_table();\r\nradix_init_amor();\r\n} else {\r\nradix_init_pseries();\r\n}\r\nmemblock_set_current_limit(MEMBLOCK_ALLOC_ANYWHERE);\r\nradix_init_iamr();\r\nradix_init_pgtable();\r\n}\r\nvoid radix__early_init_mmu_secondary(void)\r\n{\r\nunsigned long lpcr;\r\nif (!firmware_has_feature(FW_FEATURE_LPAR)) {\r\nif (cpu_has_feature(CPU_FTR_POWER9_DD1))\r\nupdate_hid_for_radix();\r\nlpcr = mfspr(SPRN_LPCR);\r\nmtspr(SPRN_LPCR, lpcr | LPCR_UPRT | LPCR_HR);\r\nmtspr(SPRN_PTCR,\r\n__pa(partition_tb) | (PATB_SIZE_SHIFT - 12));\r\nradix_init_amor();\r\n}\r\nradix_init_iamr();\r\n}\r\nvoid radix__mmu_cleanup_all(void)\r\n{\r\nunsigned long lpcr;\r\nif (!firmware_has_feature(FW_FEATURE_LPAR)) {\r\nlpcr = mfspr(SPRN_LPCR);\r\nmtspr(SPRN_LPCR, lpcr & ~LPCR_UPRT);\r\nmtspr(SPRN_PTCR, 0);\r\npowernv_set_nmmu_ptcr(0);\r\nradix__flush_tlb_all();\r\n}\r\n}\r\nvoid radix__setup_initial_memory_limit(phys_addr_t first_memblock_base,\r\nphys_addr_t first_memblock_size)\r\n{\r\nBUG_ON(first_memblock_base != 0);\r\nppc64_rma_size = min_t(u64, first_memblock_size, 0x40000000);\r\nmemblock_set_current_limit(first_memblock_base + first_memblock_size);\r\n}\r\nstatic void free_pte_table(pte_t *pte_start, pmd_t *pmd)\r\n{\r\npte_t *pte;\r\nint i;\r\nfor (i = 0; i < PTRS_PER_PTE; i++) {\r\npte = pte_start + i;\r\nif (!pte_none(*pte))\r\nreturn;\r\n}\r\npte_free_kernel(&init_mm, pte_start);\r\npmd_clear(pmd);\r\n}\r\nstatic void free_pmd_table(pmd_t *pmd_start, pud_t *pud)\r\n{\r\npmd_t *pmd;\r\nint i;\r\nfor (i = 0; i < PTRS_PER_PMD; i++) {\r\npmd = pmd_start + i;\r\nif (!pmd_none(*pmd))\r\nreturn;\r\n}\r\npmd_free(&init_mm, pmd_start);\r\npud_clear(pud);\r\n}\r\nstatic void remove_pte_table(pte_t *pte_start, unsigned long addr,\r\nunsigned long end)\r\n{\r\nunsigned long next;\r\npte_t *pte;\r\npte = pte_start + pte_index(addr);\r\nfor (; addr < end; addr = next, pte++) {\r\nnext = (addr + PAGE_SIZE) & PAGE_MASK;\r\nif (next > end)\r\nnext = end;\r\nif (!pte_present(*pte))\r\ncontinue;\r\nif (!PAGE_ALIGNED(addr) || !PAGE_ALIGNED(next)) {\r\nWARN_ONCE(1, "%s: unaligned range\n", __func__);\r\ncontinue;\r\n}\r\npte_clear(&init_mm, addr, pte);\r\n}\r\n}\r\nstatic void remove_pmd_table(pmd_t *pmd_start, unsigned long addr,\r\nunsigned long end)\r\n{\r\nunsigned long next;\r\npte_t *pte_base;\r\npmd_t *pmd;\r\npmd = pmd_start + pmd_index(addr);\r\nfor (; addr < end; addr = next, pmd++) {\r\nnext = pmd_addr_end(addr, end);\r\nif (!pmd_present(*pmd))\r\ncontinue;\r\nif (pmd_huge(*pmd)) {\r\nif (!IS_ALIGNED(addr, PMD_SIZE) ||\r\n!IS_ALIGNED(next, PMD_SIZE)) {\r\nWARN_ONCE(1, "%s: unaligned range\n", __func__);\r\ncontinue;\r\n}\r\npte_clear(&init_mm, addr, (pte_t *)pmd);\r\ncontinue;\r\n}\r\npte_base = (pte_t *)pmd_page_vaddr(*pmd);\r\nremove_pte_table(pte_base, addr, next);\r\nfree_pte_table(pte_base, pmd);\r\n}\r\n}\r\nstatic void remove_pud_table(pud_t *pud_start, unsigned long addr,\r\nunsigned long end)\r\n{\r\nunsigned long next;\r\npmd_t *pmd_base;\r\npud_t *pud;\r\npud = pud_start + pud_index(addr);\r\nfor (; addr < end; addr = next, pud++) {\r\nnext = pud_addr_end(addr, end);\r\nif (!pud_present(*pud))\r\ncontinue;\r\nif (pud_huge(*pud)) {\r\nif (!IS_ALIGNED(addr, PUD_SIZE) ||\r\n!IS_ALIGNED(next, PUD_SIZE)) {\r\nWARN_ONCE(1, "%s: unaligned range\n", __func__);\r\ncontinue;\r\n}\r\npte_clear(&init_mm, addr, (pte_t *)pud);\r\ncontinue;\r\n}\r\npmd_base = (pmd_t *)pud_page_vaddr(*pud);\r\nremove_pmd_table(pmd_base, addr, next);\r\nfree_pmd_table(pmd_base, pud);\r\n}\r\n}\r\nstatic void remove_pagetable(unsigned long start, unsigned long end)\r\n{\r\nunsigned long addr, next;\r\npud_t *pud_base;\r\npgd_t *pgd;\r\nspin_lock(&init_mm.page_table_lock);\r\nfor (addr = start; addr < end; addr = next) {\r\nnext = pgd_addr_end(addr, end);\r\npgd = pgd_offset_k(addr);\r\nif (!pgd_present(*pgd))\r\ncontinue;\r\nif (pgd_huge(*pgd)) {\r\nif (!IS_ALIGNED(addr, PGDIR_SIZE) ||\r\n!IS_ALIGNED(next, PGDIR_SIZE)) {\r\nWARN_ONCE(1, "%s: unaligned range\n", __func__);\r\ncontinue;\r\n}\r\npte_clear(&init_mm, addr, (pte_t *)pgd);\r\ncontinue;\r\n}\r\npud_base = (pud_t *)pgd_page_vaddr(*pgd);\r\nremove_pud_table(pud_base, addr, next);\r\n}\r\nspin_unlock(&init_mm.page_table_lock);\r\nradix__flush_tlb_kernel_range(start, end);\r\n}\r\nint __ref radix__create_section_mapping(unsigned long start, unsigned long end)\r\n{\r\nreturn create_physical_mapping(start, end);\r\n}\r\nint radix__remove_section_mapping(unsigned long start, unsigned long end)\r\n{\r\nremove_pagetable(start, end);\r\nreturn 0;\r\n}\r\nint __meminit radix__vmemmap_create_mapping(unsigned long start,\r\nunsigned long page_size,\r\nunsigned long phys)\r\n{\r\nunsigned long flags = _PAGE_PRESENT | _PAGE_ACCESSED | _PAGE_KERNEL_RW;\r\nBUG_ON(radix__map_kernel_page(start, phys, __pgprot(flags), page_size));\r\nreturn 0;\r\n}\r\nvoid radix__vmemmap_remove_mapping(unsigned long start, unsigned long page_size)\r\n{\r\nremove_pagetable(start, start + page_size);\r\n}\r\nunsigned long radix__pmd_hugepage_update(struct mm_struct *mm, unsigned long addr,\r\npmd_t *pmdp, unsigned long clr,\r\nunsigned long set)\r\n{\r\nunsigned long old;\r\n#ifdef CONFIG_DEBUG_VM\r\nWARN_ON(!radix__pmd_trans_huge(*pmdp));\r\nassert_spin_locked(&mm->page_table_lock);\r\n#endif\r\nold = radix__pte_update(mm, addr, (pte_t *)pmdp, clr, set, 1);\r\ntrace_hugepage_update(addr, old, clr, set);\r\nreturn old;\r\n}\r\npmd_t radix__pmdp_collapse_flush(struct vm_area_struct *vma, unsigned long address,\r\npmd_t *pmdp)\r\n{\r\npmd_t pmd;\r\nVM_BUG_ON(address & ~HPAGE_PMD_MASK);\r\nVM_BUG_ON(radix__pmd_trans_huge(*pmdp));\r\npmd = *pmdp;\r\npmd_clear(pmdp);\r\nkick_all_cpus_sync();\r\nflush_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\nreturn pmd;\r\n}\r\nvoid radix__pgtable_trans_huge_deposit(struct mm_struct *mm, pmd_t *pmdp,\r\npgtable_t pgtable)\r\n{\r\nstruct list_head *lh = (struct list_head *) pgtable;\r\nassert_spin_locked(pmd_lockptr(mm, pmdp));\r\nif (!pmd_huge_pte(mm, pmdp))\r\nINIT_LIST_HEAD(lh);\r\nelse\r\nlist_add(lh, (struct list_head *) pmd_huge_pte(mm, pmdp));\r\npmd_huge_pte(mm, pmdp) = pgtable;\r\n}\r\npgtable_t radix__pgtable_trans_huge_withdraw(struct mm_struct *mm, pmd_t *pmdp)\r\n{\r\npte_t *ptep;\r\npgtable_t pgtable;\r\nstruct list_head *lh;\r\nassert_spin_locked(pmd_lockptr(mm, pmdp));\r\npgtable = pmd_huge_pte(mm, pmdp);\r\nlh = (struct list_head *) pgtable;\r\nif (list_empty(lh))\r\npmd_huge_pte(mm, pmdp) = NULL;\r\nelse {\r\npmd_huge_pte(mm, pmdp) = (pgtable_t) lh->next;\r\nlist_del(lh);\r\n}\r\nptep = (pte_t *) pgtable;\r\n*ptep = __pte(0);\r\nptep++;\r\n*ptep = __pte(0);\r\nreturn pgtable;\r\n}\r\npmd_t radix__pmdp_huge_get_and_clear(struct mm_struct *mm,\r\nunsigned long addr, pmd_t *pmdp)\r\n{\r\npmd_t old_pmd;\r\nunsigned long old;\r\nold = radix__pmd_hugepage_update(mm, addr, pmdp, ~0UL, 0);\r\nold_pmd = __pmd(old);\r\nkick_all_cpus_sync();\r\nreturn old_pmd;\r\n}\r\nint radix__has_transparent_hugepage(void)\r\n{\r\nif (mmu_psize_defs[MMU_PAGE_2M].shift == PMD_SHIFT)\r\nreturn 1;\r\nreturn 0;\r\n}
