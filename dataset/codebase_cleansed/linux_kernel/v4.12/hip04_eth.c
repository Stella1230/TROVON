static inline unsigned int tx_count(unsigned int head, unsigned int tail)\r\n{\r\nreturn (head - tail) % (TX_DESC_NUM - 1);\r\n}\r\nstatic void hip04_config_port(struct net_device *ndev, u32 speed, u32 duplex)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nu32 val;\r\npriv->speed = speed;\r\npriv->duplex = duplex;\r\nswitch (priv->phy_mode) {\r\ncase PHY_INTERFACE_MODE_SGMII:\r\nif (speed == SPEED_1000)\r\nval = SGMII_SPEED_1000;\r\nelse if (speed == SPEED_100)\r\nval = SGMII_SPEED_100;\r\nelse\r\nval = SGMII_SPEED_10;\r\nbreak;\r\ncase PHY_INTERFACE_MODE_MII:\r\nif (speed == SPEED_100)\r\nval = MII_SPEED_100;\r\nelse\r\nval = MII_SPEED_10;\r\nbreak;\r\ndefault:\r\nnetdev_warn(ndev, "not supported mode\n");\r\nval = MII_SPEED_10;\r\nbreak;\r\n}\r\nwritel_relaxed(val, priv->base + GE_PORT_MODE);\r\nval = duplex ? GE_DUPLEX_FULL : GE_DUPLEX_HALF;\r\nwritel_relaxed(val, priv->base + GE_DUPLEX_TYPE);\r\nval = GE_MODE_CHANGE_EN;\r\nwritel_relaxed(val, priv->base + GE_MODE_CHANGE_REG);\r\n}\r\nstatic void hip04_reset_ppe(struct hip04_priv *priv)\r\n{\r\nu32 val, tmp, timeout = 0;\r\ndo {\r\nregmap_read(priv->map, priv->port * 4 + PPE_CURR_BUF_CNT, &val);\r\nregmap_read(priv->map, priv->port * 4 + PPE_CFG_RX_ADDR, &tmp);\r\nif (timeout++ > RESET_TIMEOUT)\r\nbreak;\r\n} while (val & 0xfff);\r\n}\r\nstatic void hip04_config_fifo(struct hip04_priv *priv)\r\n{\r\nu32 val;\r\nval = readl_relaxed(priv->base + PPE_CFG_STS_MODE);\r\nval |= PPE_CFG_STS_RX_PKT_CNT_RC;\r\nwritel_relaxed(val, priv->base + PPE_CFG_STS_MODE);\r\nval = BIT(priv->port);\r\nregmap_write(priv->map, priv->port * 4 + PPE_CFG_POOL_GRP, val);\r\nval = priv->port << PPE_CFG_QOS_VMID_GRP_SHIFT;\r\nval |= PPE_CFG_QOS_VMID_MODE;\r\nwritel_relaxed(val, priv->base + PPE_CFG_QOS_VMID_GEN);\r\nval = RX_BUF_SIZE;\r\nregmap_write(priv->map, priv->port * 4 + PPE_CFG_RX_BUF_SIZE, val);\r\nval = RX_DESC_NUM << PPE_CFG_RX_DEPTH_SHIFT;\r\nval |= PPE_CFG_RX_FIFO_FSFU;\r\nval |= priv->chan << PPE_CFG_RX_START_SHIFT;\r\nregmap_write(priv->map, priv->port * 4 + PPE_CFG_RX_FIFO_SIZE, val);\r\nval = NET_IP_ALIGN << PPE_CFG_RX_CTRL_ALIGN_SHIFT;\r\nwritel_relaxed(val, priv->base + PPE_CFG_RX_CTRL_REG);\r\nval = PPE_CFG_RX_PKT_ALIGN;\r\nwritel_relaxed(val, priv->base + PPE_CFG_RX_PKT_MODE_REG);\r\nval = PPE_CFG_BUS_LOCAL_REL | PPE_CFG_BUS_BIG_ENDIEN;\r\nwritel_relaxed(val, priv->base + PPE_CFG_BUS_CTRL_REG);\r\nval = GMAC_PPE_RX_PKT_MAX_LEN;\r\nwritel_relaxed(val, priv->base + PPE_CFG_MAX_FRAME_LEN_REG);\r\nval = GMAC_MAX_PKT_LEN;\r\nwritel_relaxed(val, priv->base + GE_MAX_FRM_SIZE_REG);\r\nval = GMAC_MIN_PKT_LEN;\r\nwritel_relaxed(val, priv->base + GE_SHORT_RUNTS_THR_REG);\r\nval = readl_relaxed(priv->base + GE_TRANSMIT_CONTROL_REG);\r\nval |= GE_TX_AUTO_NEG | GE_TX_ADD_CRC | GE_TX_SHORT_PAD_THROUGH;\r\nwritel_relaxed(val, priv->base + GE_TRANSMIT_CONTROL_REG);\r\nval = GE_RX_STRIP_CRC;\r\nwritel_relaxed(val, priv->base + GE_CF_CRC_STRIP_REG);\r\nval = readl_relaxed(priv->base + GE_RECV_CONTROL_REG);\r\nval |= GE_RX_STRIP_PAD | GE_RX_PAD_EN;\r\nwritel_relaxed(val, priv->base + GE_RECV_CONTROL_REG);\r\nval = GE_AUTO_NEG_CTL;\r\nwritel_relaxed(val, priv->base + GE_TX_LOCAL_PAGE_REG);\r\n}\r\nstatic void hip04_mac_enable(struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nu32 val;\r\nval = readl_relaxed(priv->base + GE_PORT_EN);\r\nval |= GE_RX_PORT_EN | GE_TX_PORT_EN;\r\nwritel_relaxed(val, priv->base + GE_PORT_EN);\r\nval = RCV_INT;\r\nwritel_relaxed(val, priv->base + PPE_RINT);\r\nval = GE_RX_INT_THRESHOLD | GE_RX_TIMEOUT;\r\nwritel_relaxed(val, priv->base + PPE_CFG_RX_PKT_INT);\r\npriv->reg_inten = DEF_INT_MASK;\r\nwritel_relaxed(priv->reg_inten, priv->base + PPE_INTEN);\r\n}\r\nstatic void hip04_mac_disable(struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nu32 val;\r\npriv->reg_inten &= ~(DEF_INT_MASK);\r\nwritel_relaxed(priv->reg_inten, priv->base + PPE_INTEN);\r\nval = readl_relaxed(priv->base + GE_PORT_EN);\r\nval &= ~(GE_RX_PORT_EN | GE_TX_PORT_EN);\r\nwritel_relaxed(val, priv->base + GE_PORT_EN);\r\n}\r\nstatic void hip04_set_xmit_desc(struct hip04_priv *priv, dma_addr_t phys)\r\n{\r\nwritel(phys, priv->base + PPE_CFG_CPU_ADD_ADDR);\r\n}\r\nstatic void hip04_set_recv_desc(struct hip04_priv *priv, dma_addr_t phys)\r\n{\r\nregmap_write(priv->map, priv->port * 4 + PPE_CFG_RX_ADDR, phys);\r\n}\r\nstatic u32 hip04_recv_cnt(struct hip04_priv *priv)\r\n{\r\nreturn readl(priv->base + PPE_HIS_RX_PKT_CNT);\r\n}\r\nstatic void hip04_update_mac_address(struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nwritel_relaxed(((ndev->dev_addr[0] << 8) | (ndev->dev_addr[1])),\r\npriv->base + GE_STATION_MAC_ADDRESS);\r\nwritel_relaxed(((ndev->dev_addr[2] << 24) | (ndev->dev_addr[3] << 16) |\r\n(ndev->dev_addr[4] << 8) | (ndev->dev_addr[5])),\r\npriv->base + GE_STATION_MAC_ADDRESS + 4);\r\n}\r\nstatic int hip04_set_mac_address(struct net_device *ndev, void *addr)\r\n{\r\neth_mac_addr(ndev, addr);\r\nhip04_update_mac_address(ndev);\r\nreturn 0;\r\n}\r\nstatic int hip04_tx_reclaim(struct net_device *ndev, bool force)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nunsigned tx_tail = priv->tx_tail;\r\nstruct tx_desc *desc;\r\nunsigned int bytes_compl = 0, pkts_compl = 0;\r\nunsigned int count;\r\nsmp_rmb();\r\ncount = tx_count(ACCESS_ONCE(priv->tx_head), tx_tail);\r\nif (count == 0)\r\ngoto out;\r\nwhile (count) {\r\ndesc = &priv->tx_desc[tx_tail];\r\nif (desc->send_addr != 0) {\r\nif (force)\r\ndesc->send_addr = 0;\r\nelse\r\nbreak;\r\n}\r\nif (priv->tx_phys[tx_tail]) {\r\ndma_unmap_single(&ndev->dev, priv->tx_phys[tx_tail],\r\npriv->tx_skb[tx_tail]->len,\r\nDMA_TO_DEVICE);\r\npriv->tx_phys[tx_tail] = 0;\r\n}\r\npkts_compl++;\r\nbytes_compl += priv->tx_skb[tx_tail]->len;\r\ndev_kfree_skb(priv->tx_skb[tx_tail]);\r\npriv->tx_skb[tx_tail] = NULL;\r\ntx_tail = TX_NEXT(tx_tail);\r\ncount--;\r\n}\r\npriv->tx_tail = tx_tail;\r\nsmp_wmb();\r\nout:\r\nif (pkts_compl || bytes_compl)\r\nnetdev_completed_queue(ndev, pkts_compl, bytes_compl);\r\nif (unlikely(netif_queue_stopped(ndev)) && (count < (TX_DESC_NUM - 1)))\r\nnetif_wake_queue(ndev);\r\nreturn count;\r\n}\r\nstatic void hip04_start_tx_timer(struct hip04_priv *priv)\r\n{\r\nunsigned long ns = priv->tx_coalesce_usecs * NSEC_PER_USEC / 2;\r\nhrtimer_start_range_ns(&priv->tx_coalesce_timer, ns_to_ktime(ns),\r\nns, HRTIMER_MODE_REL);\r\n}\r\nstatic int hip04_mac_start_xmit(struct sk_buff *skb, struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nstruct net_device_stats *stats = &ndev->stats;\r\nunsigned int tx_head = priv->tx_head, count;\r\nstruct tx_desc *desc = &priv->tx_desc[tx_head];\r\ndma_addr_t phys;\r\nsmp_rmb();\r\ncount = tx_count(tx_head, ACCESS_ONCE(priv->tx_tail));\r\nif (count == (TX_DESC_NUM - 1)) {\r\nnetif_stop_queue(ndev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nphys = dma_map_single(&ndev->dev, skb->data, skb->len, DMA_TO_DEVICE);\r\nif (dma_mapping_error(&ndev->dev, phys)) {\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\npriv->tx_skb[tx_head] = skb;\r\npriv->tx_phys[tx_head] = phys;\r\ndesc->send_addr = cpu_to_be32(phys);\r\ndesc->send_size = cpu_to_be32(skb->len);\r\ndesc->cfg = cpu_to_be32(TX_CLEAR_WB | TX_FINISH_CACHE_INV);\r\nphys = priv->tx_desc_dma + tx_head * sizeof(struct tx_desc);\r\ndesc->wb_addr = cpu_to_be32(phys);\r\nskb_tx_timestamp(skb);\r\nhip04_set_xmit_desc(priv, phys);\r\npriv->tx_head = TX_NEXT(tx_head);\r\ncount++;\r\nnetdev_sent_queue(ndev, skb->len);\r\nstats->tx_bytes += skb->len;\r\nstats->tx_packets++;\r\nsmp_wmb();\r\nif (count >= priv->tx_coalesce_frames) {\r\nif (napi_schedule_prep(&priv->napi)) {\r\npriv->reg_inten &= ~(RCV_INT);\r\nwritel_relaxed(DEF_INT_MASK & ~RCV_INT,\r\npriv->base + PPE_INTEN);\r\nhrtimer_cancel(&priv->tx_coalesce_timer);\r\n__napi_schedule(&priv->napi);\r\n}\r\n} else if (!hrtimer_is_queued(&priv->tx_coalesce_timer)) {\r\nhip04_start_tx_timer(priv);\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int hip04_rx_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct hip04_priv *priv = container_of(napi, struct hip04_priv, napi);\r\nstruct net_device *ndev = priv->ndev;\r\nstruct net_device_stats *stats = &ndev->stats;\r\nunsigned int cnt = hip04_recv_cnt(priv);\r\nstruct rx_desc *desc;\r\nstruct sk_buff *skb;\r\nunsigned char *buf;\r\nbool last = false;\r\ndma_addr_t phys;\r\nint rx = 0;\r\nint tx_remaining;\r\nu16 len;\r\nu32 err;\r\nwhile (cnt && !last) {\r\nbuf = priv->rx_buf[priv->rx_head];\r\nskb = build_skb(buf, priv->rx_buf_size);\r\nif (unlikely(!skb)) {\r\nnet_dbg_ratelimited("build_skb failed\n");\r\ngoto refill;\r\n}\r\ndma_unmap_single(&ndev->dev, priv->rx_phys[priv->rx_head],\r\nRX_BUF_SIZE, DMA_FROM_DEVICE);\r\npriv->rx_phys[priv->rx_head] = 0;\r\ndesc = (struct rx_desc *)skb->data;\r\nlen = be16_to_cpu(desc->pkt_len);\r\nerr = be32_to_cpu(desc->pkt_err);\r\nif (0 == len) {\r\ndev_kfree_skb_any(skb);\r\nlast = true;\r\n} else if ((err & RX_PKT_ERR) || (len >= GMAC_MAX_PKT_LEN)) {\r\ndev_kfree_skb_any(skb);\r\nstats->rx_dropped++;\r\nstats->rx_errors++;\r\n} else {\r\nskb_reserve(skb, NET_SKB_PAD + NET_IP_ALIGN);\r\nskb_put(skb, len);\r\nskb->protocol = eth_type_trans(skb, ndev);\r\nnapi_gro_receive(&priv->napi, skb);\r\nstats->rx_packets++;\r\nstats->rx_bytes += len;\r\nrx++;\r\n}\r\nrefill:\r\nbuf = netdev_alloc_frag(priv->rx_buf_size);\r\nif (!buf)\r\ngoto done;\r\nphys = dma_map_single(&ndev->dev, buf,\r\nRX_BUF_SIZE, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(&ndev->dev, phys))\r\ngoto done;\r\npriv->rx_buf[priv->rx_head] = buf;\r\npriv->rx_phys[priv->rx_head] = phys;\r\nhip04_set_recv_desc(priv, phys);\r\npriv->rx_head = RX_NEXT(priv->rx_head);\r\nif (rx >= budget)\r\ngoto done;\r\nif (--cnt == 0)\r\ncnt = hip04_recv_cnt(priv);\r\n}\r\nif (!(priv->reg_inten & RCV_INT)) {\r\npriv->reg_inten |= RCV_INT;\r\nwritel_relaxed(priv->reg_inten, priv->base + PPE_INTEN);\r\n}\r\nnapi_complete_done(napi, rx);\r\ndone:\r\ntx_remaining = hip04_tx_reclaim(ndev, false);\r\nif (rx < budget && tx_remaining)\r\nhip04_start_tx_timer(priv);\r\nreturn rx;\r\n}\r\nstatic irqreturn_t hip04_mac_interrupt(int irq, void *dev_id)\r\n{\r\nstruct net_device *ndev = (struct net_device *)dev_id;\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nstruct net_device_stats *stats = &ndev->stats;\r\nu32 ists = readl_relaxed(priv->base + PPE_INTSTS);\r\nif (!ists)\r\nreturn IRQ_NONE;\r\nwritel_relaxed(DEF_INT_MASK, priv->base + PPE_RINT);\r\nif (unlikely(ists & DEF_INT_ERR)) {\r\nif (ists & (RCV_NOBUF | RCV_DROP)) {\r\nstats->rx_errors++;\r\nstats->rx_dropped++;\r\nnetdev_err(ndev, "rx drop\n");\r\n}\r\nif (ists & TX_DROP) {\r\nstats->tx_dropped++;\r\nnetdev_err(ndev, "tx drop\n");\r\n}\r\n}\r\nif (ists & RCV_INT && napi_schedule_prep(&priv->napi)) {\r\npriv->reg_inten &= ~(RCV_INT);\r\nwritel_relaxed(DEF_INT_MASK & ~RCV_INT, priv->base + PPE_INTEN);\r\nhrtimer_cancel(&priv->tx_coalesce_timer);\r\n__napi_schedule(&priv->napi);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic enum hrtimer_restart tx_done(struct hrtimer *hrtimer)\r\n{\r\nstruct hip04_priv *priv;\r\npriv = container_of(hrtimer, struct hip04_priv, tx_coalesce_timer);\r\nif (napi_schedule_prep(&priv->napi)) {\r\npriv->reg_inten &= ~(RCV_INT);\r\nwritel_relaxed(DEF_INT_MASK & ~RCV_INT, priv->base + PPE_INTEN);\r\n__napi_schedule(&priv->napi);\r\n}\r\nreturn HRTIMER_NORESTART;\r\n}\r\nstatic void hip04_adjust_link(struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nstruct phy_device *phy = priv->phy;\r\nif ((priv->speed != phy->speed) || (priv->duplex != phy->duplex)) {\r\nhip04_config_port(ndev, phy->speed, phy->duplex);\r\nphy_print_status(phy);\r\n}\r\n}\r\nstatic int hip04_mac_open(struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nint i;\r\npriv->rx_head = 0;\r\npriv->tx_head = 0;\r\npriv->tx_tail = 0;\r\nhip04_reset_ppe(priv);\r\nfor (i = 0; i < RX_DESC_NUM; i++) {\r\ndma_addr_t phys;\r\nphys = dma_map_single(&ndev->dev, priv->rx_buf[i],\r\nRX_BUF_SIZE, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(&ndev->dev, phys))\r\nreturn -EIO;\r\npriv->rx_phys[i] = phys;\r\nhip04_set_recv_desc(priv, phys);\r\n}\r\nif (priv->phy)\r\nphy_start(priv->phy);\r\nnetdev_reset_queue(ndev);\r\nnetif_start_queue(ndev);\r\nhip04_mac_enable(ndev);\r\nnapi_enable(&priv->napi);\r\nreturn 0;\r\n}\r\nstatic int hip04_mac_stop(struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nint i;\r\nnapi_disable(&priv->napi);\r\nnetif_stop_queue(ndev);\r\nhip04_mac_disable(ndev);\r\nhip04_tx_reclaim(ndev, true);\r\nhip04_reset_ppe(priv);\r\nif (priv->phy)\r\nphy_stop(priv->phy);\r\nfor (i = 0; i < RX_DESC_NUM; i++) {\r\nif (priv->rx_phys[i]) {\r\ndma_unmap_single(&ndev->dev, priv->rx_phys[i],\r\nRX_BUF_SIZE, DMA_FROM_DEVICE);\r\npriv->rx_phys[i] = 0;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void hip04_timeout(struct net_device *ndev)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nschedule_work(&priv->tx_timeout_task);\r\n}\r\nstatic void hip04_tx_timeout_task(struct work_struct *work)\r\n{\r\nstruct hip04_priv *priv;\r\npriv = container_of(work, struct hip04_priv, tx_timeout_task);\r\nhip04_mac_stop(priv->ndev);\r\nhip04_mac_open(priv->ndev);\r\n}\r\nstatic int hip04_get_coalesce(struct net_device *netdev,\r\nstruct ethtool_coalesce *ec)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(netdev);\r\nec->tx_coalesce_usecs = priv->tx_coalesce_usecs;\r\nec->tx_max_coalesced_frames = priv->tx_coalesce_frames;\r\nreturn 0;\r\n}\r\nstatic int hip04_set_coalesce(struct net_device *netdev,\r\nstruct ethtool_coalesce *ec)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(netdev);\r\nif ((ec->rx_max_coalesced_frames) || (ec->rx_coalesce_usecs_irq) ||\r\n(ec->rx_max_coalesced_frames_irq) || (ec->tx_coalesce_usecs_irq) ||\r\n(ec->use_adaptive_rx_coalesce) || (ec->use_adaptive_tx_coalesce) ||\r\n(ec->pkt_rate_low) || (ec->rx_coalesce_usecs_low) ||\r\n(ec->rx_max_coalesced_frames_low) || (ec->tx_coalesce_usecs_high) ||\r\n(ec->tx_max_coalesced_frames_low) || (ec->pkt_rate_high) ||\r\n(ec->tx_coalesce_usecs_low) || (ec->rx_coalesce_usecs_high) ||\r\n(ec->rx_max_coalesced_frames_high) || (ec->rx_coalesce_usecs) ||\r\n(ec->tx_max_coalesced_frames_irq) ||\r\n(ec->stats_block_coalesce_usecs) ||\r\n(ec->tx_max_coalesced_frames_high) || (ec->rate_sample_interval))\r\nreturn -EOPNOTSUPP;\r\nif ((ec->tx_coalesce_usecs > HIP04_MAX_TX_COALESCE_USECS ||\r\nec->tx_coalesce_usecs < HIP04_MIN_TX_COALESCE_USECS) ||\r\n(ec->tx_max_coalesced_frames > HIP04_MAX_TX_COALESCE_FRAMES ||\r\nec->tx_max_coalesced_frames < HIP04_MIN_TX_COALESCE_FRAMES))\r\nreturn -EINVAL;\r\npriv->tx_coalesce_usecs = ec->tx_coalesce_usecs;\r\npriv->tx_coalesce_frames = ec->tx_max_coalesced_frames;\r\nreturn 0;\r\n}\r\nstatic void hip04_get_drvinfo(struct net_device *netdev,\r\nstruct ethtool_drvinfo *drvinfo)\r\n{\r\nstrlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));\r\n}\r\nstatic int hip04_alloc_ring(struct net_device *ndev, struct device *d)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nint i;\r\npriv->tx_desc = dma_alloc_coherent(d,\r\nTX_DESC_NUM * sizeof(struct tx_desc),\r\n&priv->tx_desc_dma, GFP_KERNEL);\r\nif (!priv->tx_desc)\r\nreturn -ENOMEM;\r\npriv->rx_buf_size = RX_BUF_SIZE +\r\nSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\r\nfor (i = 0; i < RX_DESC_NUM; i++) {\r\npriv->rx_buf[i] = netdev_alloc_frag(priv->rx_buf_size);\r\nif (!priv->rx_buf[i])\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void hip04_free_ring(struct net_device *ndev, struct device *d)\r\n{\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nint i;\r\nfor (i = 0; i < RX_DESC_NUM; i++)\r\nif (priv->rx_buf[i])\r\nskb_free_frag(priv->rx_buf[i]);\r\nfor (i = 0; i < TX_DESC_NUM; i++)\r\nif (priv->tx_skb[i])\r\ndev_kfree_skb_any(priv->tx_skb[i]);\r\ndma_free_coherent(d, TX_DESC_NUM * sizeof(struct tx_desc),\r\npriv->tx_desc, priv->tx_desc_dma);\r\n}\r\nstatic int hip04_mac_probe(struct platform_device *pdev)\r\n{\r\nstruct device *d = &pdev->dev;\r\nstruct device_node *node = d->of_node;\r\nstruct of_phandle_args arg;\r\nstruct net_device *ndev;\r\nstruct hip04_priv *priv;\r\nstruct resource *res;\r\nint irq;\r\nint ret;\r\nndev = alloc_etherdev(sizeof(struct hip04_priv));\r\nif (!ndev)\r\nreturn -ENOMEM;\r\npriv = netdev_priv(ndev);\r\npriv->ndev = ndev;\r\nplatform_set_drvdata(pdev, ndev);\r\nSET_NETDEV_DEV(ndev, &pdev->dev);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\npriv->base = devm_ioremap_resource(d, res);\r\nif (IS_ERR(priv->base)) {\r\nret = PTR_ERR(priv->base);\r\ngoto init_fail;\r\n}\r\nret = of_parse_phandle_with_fixed_args(node, "port-handle", 2, 0, &arg);\r\nif (ret < 0) {\r\ndev_warn(d, "no port-handle\n");\r\ngoto init_fail;\r\n}\r\npriv->port = arg.args[0];\r\npriv->chan = arg.args[1] * RX_DESC_NUM;\r\nhrtimer_init(&priv->tx_coalesce_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\r\npriv->tx_coalesce_frames = TX_DESC_NUM * 3 / 4;\r\npriv->tx_coalesce_usecs = 200;\r\npriv->tx_coalesce_timer.function = tx_done;\r\npriv->map = syscon_node_to_regmap(arg.np);\r\nif (IS_ERR(priv->map)) {\r\ndev_warn(d, "no syscon hisilicon,hip04-ppe\n");\r\nret = PTR_ERR(priv->map);\r\ngoto init_fail;\r\n}\r\npriv->phy_mode = of_get_phy_mode(node);\r\nif (priv->phy_mode < 0) {\r\ndev_warn(d, "not find phy-mode\n");\r\nret = -EINVAL;\r\ngoto init_fail;\r\n}\r\nirq = platform_get_irq(pdev, 0);\r\nif (irq <= 0) {\r\nret = -EINVAL;\r\ngoto init_fail;\r\n}\r\nret = devm_request_irq(d, irq, hip04_mac_interrupt,\r\n0, pdev->name, ndev);\r\nif (ret) {\r\nnetdev_err(ndev, "devm_request_irq failed\n");\r\ngoto init_fail;\r\n}\r\npriv->phy_node = of_parse_phandle(node, "phy-handle", 0);\r\nif (priv->phy_node) {\r\npriv->phy = of_phy_connect(ndev, priv->phy_node,\r\n&hip04_adjust_link,\r\n0, priv->phy_mode);\r\nif (!priv->phy) {\r\nret = -EPROBE_DEFER;\r\ngoto init_fail;\r\n}\r\n}\r\nINIT_WORK(&priv->tx_timeout_task, hip04_tx_timeout_task);\r\nndev->netdev_ops = &hip04_netdev_ops;\r\nndev->ethtool_ops = &hip04_ethtool_ops;\r\nndev->watchdog_timeo = TX_TIMEOUT;\r\nndev->priv_flags |= IFF_UNICAST_FLT;\r\nndev->irq = irq;\r\nnetif_napi_add(ndev, &priv->napi, hip04_rx_poll, NAPI_POLL_WEIGHT);\r\nhip04_reset_ppe(priv);\r\nif (priv->phy_mode == PHY_INTERFACE_MODE_MII)\r\nhip04_config_port(ndev, SPEED_100, DUPLEX_FULL);\r\nhip04_config_fifo(priv);\r\nrandom_ether_addr(ndev->dev_addr);\r\nhip04_update_mac_address(ndev);\r\nret = hip04_alloc_ring(ndev, d);\r\nif (ret) {\r\nnetdev_err(ndev, "alloc ring fail\n");\r\ngoto alloc_fail;\r\n}\r\nret = register_netdev(ndev);\r\nif (ret) {\r\nfree_netdev(ndev);\r\ngoto alloc_fail;\r\n}\r\nreturn 0;\r\nalloc_fail:\r\nhip04_free_ring(ndev, d);\r\ninit_fail:\r\nof_node_put(priv->phy_node);\r\nfree_netdev(ndev);\r\nreturn ret;\r\n}\r\nstatic int hip04_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *ndev = platform_get_drvdata(pdev);\r\nstruct hip04_priv *priv = netdev_priv(ndev);\r\nstruct device *d = &pdev->dev;\r\nif (priv->phy)\r\nphy_disconnect(priv->phy);\r\nhip04_free_ring(ndev, d);\r\nunregister_netdev(ndev);\r\nfree_irq(ndev->irq, ndev);\r\nof_node_put(priv->phy_node);\r\ncancel_work_sync(&priv->tx_timeout_task);\r\nfree_netdev(ndev);\r\nreturn 0;\r\n}
