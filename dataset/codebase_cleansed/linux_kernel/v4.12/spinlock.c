static void xen_qlock_kick(int cpu)\r\n{\r\nint irq = per_cpu(lock_kicker_irq, cpu);\r\nif (irq == -1)\r\nreturn;\r\nxen_send_IPI_one(cpu, XEN_SPIN_UNLOCK_VECTOR);\r\n}\r\nstatic void xen_qlock_wait(u8 *byte, u8 val)\r\n{\r\nint irq = __this_cpu_read(lock_kicker_irq);\r\nif (irq == -1)\r\nreturn;\r\nxen_clear_irq_pending(irq);\r\nbarrier();\r\nif (READ_ONCE(*byte) != val)\r\nreturn;\r\nxen_poll_irq(irq);\r\n}\r\nstatic irqreturn_t dummy_handler(int irq, void *dev_id)\r\n{\r\nBUG();\r\nreturn IRQ_HANDLED;\r\n}\r\nvoid xen_init_lock_cpu(int cpu)\r\n{\r\nint irq;\r\nchar *name;\r\nif (!xen_pvspin)\r\nreturn;\r\nWARN(per_cpu(lock_kicker_irq, cpu) >= 0, "spinlock on CPU%d exists on IRQ%d!\n",\r\ncpu, per_cpu(lock_kicker_irq, cpu));\r\nname = kasprintf(GFP_KERNEL, "spinlock%d", cpu);\r\nirq = bind_ipi_to_irqhandler(XEN_SPIN_UNLOCK_VECTOR,\r\ncpu,\r\ndummy_handler,\r\nIRQF_PERCPU|IRQF_NOBALANCING,\r\nname,\r\nNULL);\r\nif (irq >= 0) {\r\ndisable_irq(irq);\r\nper_cpu(lock_kicker_irq, cpu) = irq;\r\nper_cpu(irq_name, cpu) = name;\r\n}\r\nprintk("cpu %d spinlock event irq %d\n", cpu, irq);\r\n}\r\nvoid xen_uninit_lock_cpu(int cpu)\r\n{\r\nif (!xen_pvspin)\r\nreturn;\r\nunbind_from_irqhandler(per_cpu(lock_kicker_irq, cpu), NULL);\r\nper_cpu(lock_kicker_irq, cpu) = -1;\r\nkfree(per_cpu(irq_name, cpu));\r\nper_cpu(irq_name, cpu) = NULL;\r\n}\r\nvoid __init xen_init_spinlocks(void)\r\n{\r\nif (!xen_pvspin) {\r\nprintk(KERN_DEBUG "xen: PV spinlocks disabled\n");\r\nreturn;\r\n}\r\nprintk(KERN_DEBUG "xen: PV spinlocks enabled\n");\r\n__pv_init_lock_hash();\r\npv_lock_ops.queued_spin_lock_slowpath = __pv_queued_spin_lock_slowpath;\r\npv_lock_ops.queued_spin_unlock = PV_CALLEE_SAVE(__pv_queued_spin_unlock);\r\npv_lock_ops.wait = xen_qlock_wait;\r\npv_lock_ops.kick = xen_qlock_kick;\r\npv_lock_ops.vcpu_is_preempted = PV_CALLEE_SAVE(xen_vcpu_stolen);\r\n}\r\nstatic __init int xen_parse_nopvspin(char *arg)\r\n{\r\nxen_pvspin = false;\r\nreturn 0;\r\n}
