static inline bool vfio_vga_disabled(void)\r\n{\r\n#ifdef CONFIG_VFIO_PCI_VGA\r\nreturn disable_vga;\r\n#else\r\nreturn true;\r\n#endif\r\n}\r\nstatic unsigned int vfio_pci_set_vga_decode(void *opaque, bool single_vga)\r\n{\r\nstruct vfio_pci_device *vdev = opaque;\r\nstruct pci_dev *tmp = NULL, *pdev = vdev->pdev;\r\nunsigned char max_busnr;\r\nunsigned int decodes;\r\nif (single_vga || !vfio_vga_disabled() || pci_is_root_bus(pdev->bus))\r\nreturn VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM |\r\nVGA_RSRC_LEGACY_IO | VGA_RSRC_LEGACY_MEM;\r\nmax_busnr = pci_bus_max_busnr(pdev->bus);\r\ndecodes = VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM;\r\nwhile ((tmp = pci_get_class(PCI_CLASS_DISPLAY_VGA << 8, tmp)) != NULL) {\r\nif (tmp == pdev ||\r\npci_domain_nr(tmp->bus) != pci_domain_nr(pdev->bus) ||\r\npci_is_root_bus(tmp->bus))\r\ncontinue;\r\nif (tmp->bus->number >= pdev->bus->number &&\r\ntmp->bus->number <= max_busnr) {\r\npci_dev_put(tmp);\r\ndecodes |= VGA_RSRC_LEGACY_IO | VGA_RSRC_LEGACY_MEM;\r\nbreak;\r\n}\r\n}\r\nreturn decodes;\r\n}\r\nstatic inline bool vfio_pci_is_vga(struct pci_dev *pdev)\r\n{\r\nreturn (pdev->class >> 8) == PCI_CLASS_DISPLAY_VGA;\r\n}\r\nstatic void vfio_pci_probe_mmaps(struct vfio_pci_device *vdev)\r\n{\r\nstruct resource *res;\r\nint bar;\r\nstruct vfio_pci_dummy_resource *dummy_res;\r\nINIT_LIST_HEAD(&vdev->dummy_resources_list);\r\nfor (bar = PCI_STD_RESOURCES; bar <= PCI_STD_RESOURCE_END; bar++) {\r\nres = vdev->pdev->resource + bar;\r\nif (!IS_ENABLED(CONFIG_VFIO_PCI_MMAP))\r\ngoto no_mmap;\r\nif (!(res->flags & IORESOURCE_MEM))\r\ngoto no_mmap;\r\nif (!resource_size(res))\r\ngoto no_mmap;\r\nif (resource_size(res) >= PAGE_SIZE) {\r\nvdev->bar_mmap_supported[bar] = true;\r\ncontinue;\r\n}\r\nif (!(res->start & ~PAGE_MASK)) {\r\ndummy_res = kzalloc(sizeof(*dummy_res), GFP_KERNEL);\r\nif (dummy_res == NULL)\r\ngoto no_mmap;\r\ndummy_res->resource.name = "vfio sub-page reserved";\r\ndummy_res->resource.start = res->end + 1;\r\ndummy_res->resource.end = res->start + PAGE_SIZE - 1;\r\ndummy_res->resource.flags = res->flags;\r\nif (request_resource(res->parent,\r\n&dummy_res->resource)) {\r\nkfree(dummy_res);\r\ngoto no_mmap;\r\n}\r\ndummy_res->index = bar;\r\nlist_add(&dummy_res->res_next,\r\n&vdev->dummy_resources_list);\r\nvdev->bar_mmap_supported[bar] = true;\r\ncontinue;\r\n}\r\nno_mmap:\r\nvdev->bar_mmap_supported[bar] = false;\r\n}\r\n}\r\nstatic bool vfio_pci_nointx(struct pci_dev *pdev)\r\n{\r\nswitch (pdev->vendor) {\r\ncase PCI_VENDOR_ID_INTEL:\r\nswitch (pdev->device) {\r\ncase 0x1572:\r\ncase 0x1574:\r\ncase 0x1580 ... 0x1581:\r\ncase 0x1583 ... 0x1589:\r\ncase 0x37d0 ... 0x37d2:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nreturn false;\r\n}\r\nstatic int vfio_pci_enable(struct vfio_pci_device *vdev)\r\n{\r\nstruct pci_dev *pdev = vdev->pdev;\r\nint ret;\r\nu16 cmd;\r\nu8 msix_pos;\r\npci_set_power_state(pdev, PCI_D0);\r\npci_clear_master(pdev);\r\nret = pci_enable_device(pdev);\r\nif (ret)\r\nreturn ret;\r\nvdev->reset_works = (pci_reset_function(pdev) == 0);\r\npci_save_state(pdev);\r\nvdev->pci_saved_state = pci_store_saved_state(pdev);\r\nif (!vdev->pci_saved_state)\r\npr_debug("%s: Couldn't store %s saved state\n",\r\n__func__, dev_name(&pdev->dev));\r\nif (likely(!nointxmask)) {\r\nif (vfio_pci_nointx(pdev)) {\r\ndev_info(&pdev->dev, "Masking broken INTx support\n");\r\nvdev->nointx = true;\r\npci_intx(pdev, 0);\r\n} else\r\nvdev->pci_2_3 = pci_intx_mask_supported(pdev);\r\n}\r\npci_read_config_word(pdev, PCI_COMMAND, &cmd);\r\nif (vdev->pci_2_3 && (cmd & PCI_COMMAND_INTX_DISABLE)) {\r\ncmd &= ~PCI_COMMAND_INTX_DISABLE;\r\npci_write_config_word(pdev, PCI_COMMAND, cmd);\r\n}\r\nret = vfio_config_init(vdev);\r\nif (ret) {\r\nkfree(vdev->pci_saved_state);\r\nvdev->pci_saved_state = NULL;\r\npci_disable_device(pdev);\r\nreturn ret;\r\n}\r\nmsix_pos = pdev->msix_cap;\r\nif (msix_pos) {\r\nu16 flags;\r\nu32 table;\r\npci_read_config_word(pdev, msix_pos + PCI_MSIX_FLAGS, &flags);\r\npci_read_config_dword(pdev, msix_pos + PCI_MSIX_TABLE, &table);\r\nvdev->msix_bar = table & PCI_MSIX_TABLE_BIR;\r\nvdev->msix_offset = table & PCI_MSIX_TABLE_OFFSET;\r\nvdev->msix_size = ((flags & PCI_MSIX_FLAGS_QSIZE) + 1) * 16;\r\n} else\r\nvdev->msix_bar = 0xFF;\r\nif (!vfio_vga_disabled() && vfio_pci_is_vga(pdev))\r\nvdev->has_vga = true;\r\nif (vfio_pci_is_vga(pdev) &&\r\npdev->vendor == PCI_VENDOR_ID_INTEL &&\r\nIS_ENABLED(CONFIG_VFIO_PCI_IGD)) {\r\nret = vfio_pci_igd_init(vdev);\r\nif (ret) {\r\ndev_warn(&vdev->pdev->dev,\r\n"Failed to setup Intel IGD regions\n");\r\nvfio_pci_disable(vdev);\r\nreturn ret;\r\n}\r\n}\r\nvfio_pci_probe_mmaps(vdev);\r\nreturn 0;\r\n}\r\nstatic void vfio_pci_disable(struct vfio_pci_device *vdev)\r\n{\r\nstruct pci_dev *pdev = vdev->pdev;\r\nstruct vfio_pci_dummy_resource *dummy_res, *tmp;\r\nint i, bar;\r\npci_clear_master(pdev);\r\nvfio_pci_set_irqs_ioctl(vdev, VFIO_IRQ_SET_DATA_NONE |\r\nVFIO_IRQ_SET_ACTION_TRIGGER,\r\nvdev->irq_type, 0, 0, NULL);\r\nvdev->virq_disabled = false;\r\nfor (i = 0; i < vdev->num_regions; i++)\r\nvdev->region[i].ops->release(vdev, &vdev->region[i]);\r\nvdev->num_regions = 0;\r\nkfree(vdev->region);\r\nvdev->region = NULL;\r\nvfio_config_free(vdev);\r\nfor (bar = PCI_STD_RESOURCES; bar <= PCI_STD_RESOURCE_END; bar++) {\r\nif (!vdev->barmap[bar])\r\ncontinue;\r\npci_iounmap(pdev, vdev->barmap[bar]);\r\npci_release_selected_regions(pdev, 1 << bar);\r\nvdev->barmap[bar] = NULL;\r\n}\r\nlist_for_each_entry_safe(dummy_res, tmp,\r\n&vdev->dummy_resources_list, res_next) {\r\nlist_del(&dummy_res->res_next);\r\nrelease_resource(&dummy_res->resource);\r\nkfree(dummy_res);\r\n}\r\nvdev->needs_reset = true;\r\nif (pci_load_and_free_saved_state(pdev, &vdev->pci_saved_state)) {\r\npr_info("%s: Couldn't reload %s saved state\n",\r\n__func__, dev_name(&pdev->dev));\r\nif (!vdev->reset_works)\r\ngoto out;\r\npci_save_state(pdev);\r\n}\r\npci_write_config_word(pdev, PCI_COMMAND, PCI_COMMAND_INTX_DISABLE);\r\nif (vdev->reset_works && !pci_try_reset_function(pdev))\r\nvdev->needs_reset = false;\r\npci_restore_state(pdev);\r\nout:\r\npci_disable_device(pdev);\r\nvfio_pci_try_bus_reset(vdev);\r\nif (!disable_idle_d3)\r\npci_set_power_state(pdev, PCI_D3hot);\r\n}\r\nstatic void vfio_pci_release(void *device_data)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nmutex_lock(&driver_lock);\r\nif (!(--vdev->refcnt)) {\r\nvfio_spapr_pci_eeh_release(vdev->pdev);\r\nvfio_pci_disable(vdev);\r\n}\r\nmutex_unlock(&driver_lock);\r\nmodule_put(THIS_MODULE);\r\n}\r\nstatic int vfio_pci_open(void *device_data)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nint ret = 0;\r\nif (!try_module_get(THIS_MODULE))\r\nreturn -ENODEV;\r\nmutex_lock(&driver_lock);\r\nif (!vdev->refcnt) {\r\nret = vfio_pci_enable(vdev);\r\nif (ret)\r\ngoto error;\r\nvfio_spapr_pci_eeh_open(vdev->pdev);\r\n}\r\nvdev->refcnt++;\r\nerror:\r\nmutex_unlock(&driver_lock);\r\nif (ret)\r\nmodule_put(THIS_MODULE);\r\nreturn ret;\r\n}\r\nstatic int vfio_pci_get_irq_count(struct vfio_pci_device *vdev, int irq_type)\r\n{\r\nif (irq_type == VFIO_PCI_INTX_IRQ_INDEX) {\r\nu8 pin;\r\npci_read_config_byte(vdev->pdev, PCI_INTERRUPT_PIN, &pin);\r\nif (IS_ENABLED(CONFIG_VFIO_PCI_INTX) && !vdev->nointx && pin)\r\nreturn 1;\r\n} else if (irq_type == VFIO_PCI_MSI_IRQ_INDEX) {\r\nu8 pos;\r\nu16 flags;\r\npos = vdev->pdev->msi_cap;\r\nif (pos) {\r\npci_read_config_word(vdev->pdev,\r\npos + PCI_MSI_FLAGS, &flags);\r\nreturn 1 << ((flags & PCI_MSI_FLAGS_QMASK) >> 1);\r\n}\r\n} else if (irq_type == VFIO_PCI_MSIX_IRQ_INDEX) {\r\nu8 pos;\r\nu16 flags;\r\npos = vdev->pdev->msix_cap;\r\nif (pos) {\r\npci_read_config_word(vdev->pdev,\r\npos + PCI_MSIX_FLAGS, &flags);\r\nreturn (flags & PCI_MSIX_FLAGS_QSIZE) + 1;\r\n}\r\n} else if (irq_type == VFIO_PCI_ERR_IRQ_INDEX) {\r\nif (pci_is_pcie(vdev->pdev))\r\nreturn 1;\r\n} else if (irq_type == VFIO_PCI_REQ_IRQ_INDEX) {\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vfio_pci_count_devs(struct pci_dev *pdev, void *data)\r\n{\r\n(*(int *)data)++;\r\nreturn 0;\r\n}\r\nstatic int vfio_pci_fill_devs(struct pci_dev *pdev, void *data)\r\n{\r\nstruct vfio_pci_fill_info *fill = data;\r\nstruct iommu_group *iommu_group;\r\nif (fill->cur == fill->max)\r\nreturn -EAGAIN;\r\niommu_group = iommu_group_get(&pdev->dev);\r\nif (!iommu_group)\r\nreturn -EPERM;\r\nfill->devices[fill->cur].group_id = iommu_group_id(iommu_group);\r\nfill->devices[fill->cur].segment = pci_domain_nr(pdev->bus);\r\nfill->devices[fill->cur].bus = pdev->bus->number;\r\nfill->devices[fill->cur].devfn = pdev->devfn;\r\nfill->cur++;\r\niommu_group_put(iommu_group);\r\nreturn 0;\r\n}\r\nstatic int vfio_pci_validate_devs(struct pci_dev *pdev, void *data)\r\n{\r\nstruct vfio_pci_group_info *info = data;\r\nstruct iommu_group *group;\r\nint id, i;\r\ngroup = iommu_group_get(&pdev->dev);\r\nif (!group)\r\nreturn -EPERM;\r\nid = iommu_group_id(group);\r\nfor (i = 0; i < info->count; i++)\r\nif (info->groups[i].id == id)\r\nbreak;\r\niommu_group_put(group);\r\nreturn (i == info->count) ? -EINVAL : 0;\r\n}\r\nstatic bool vfio_pci_dev_below_slot(struct pci_dev *pdev, struct pci_slot *slot)\r\n{\r\nfor (; pdev; pdev = pdev->bus->self)\r\nif (pdev->bus == slot->bus)\r\nreturn (pdev->slot == slot);\r\nreturn false;\r\n}\r\nstatic int vfio_pci_walk_wrapper(struct pci_dev *pdev, void *data)\r\n{\r\nstruct vfio_pci_walk_info *walk = data;\r\nif (!walk->slot || vfio_pci_dev_below_slot(pdev, walk->pdev->slot))\r\nwalk->ret = walk->fn(pdev, walk->data);\r\nreturn walk->ret;\r\n}\r\nstatic int vfio_pci_for_each_slot_or_bus(struct pci_dev *pdev,\r\nint (*fn)(struct pci_dev *,\r\nvoid *data), void *data,\r\nbool slot)\r\n{\r\nstruct vfio_pci_walk_info walk = {\r\n.fn = fn, .data = data, .pdev = pdev, .slot = slot, .ret = 0,\r\n};\r\npci_walk_bus(pdev->bus, vfio_pci_walk_wrapper, &walk);\r\nreturn walk.ret;\r\n}\r\nstatic int msix_sparse_mmap_cap(struct vfio_pci_device *vdev,\r\nstruct vfio_info_cap *caps)\r\n{\r\nstruct vfio_region_info_cap_sparse_mmap *sparse;\r\nsize_t end, size;\r\nint nr_areas = 2, i = 0, ret;\r\nend = pci_resource_len(vdev->pdev, vdev->msix_bar);\r\nif (((vdev->msix_offset & PAGE_MASK) == 0) ||\r\n(PAGE_ALIGN(vdev->msix_offset + vdev->msix_size) >= end))\r\nnr_areas = 1;\r\nsize = sizeof(*sparse) + (nr_areas * sizeof(*sparse->areas));\r\nsparse = kzalloc(size, GFP_KERNEL);\r\nif (!sparse)\r\nreturn -ENOMEM;\r\nsparse->nr_areas = nr_areas;\r\nif (vdev->msix_offset & PAGE_MASK) {\r\nsparse->areas[i].offset = 0;\r\nsparse->areas[i].size = vdev->msix_offset & PAGE_MASK;\r\ni++;\r\n}\r\nif (PAGE_ALIGN(vdev->msix_offset + vdev->msix_size) < end) {\r\nsparse->areas[i].offset = PAGE_ALIGN(vdev->msix_offset +\r\nvdev->msix_size);\r\nsparse->areas[i].size = end - sparse->areas[i].offset;\r\ni++;\r\n}\r\nret = vfio_info_add_capability(caps, VFIO_REGION_INFO_CAP_SPARSE_MMAP,\r\nsparse);\r\nkfree(sparse);\r\nreturn ret;\r\n}\r\nint vfio_pci_register_dev_region(struct vfio_pci_device *vdev,\r\nunsigned int type, unsigned int subtype,\r\nconst struct vfio_pci_regops *ops,\r\nsize_t size, u32 flags, void *data)\r\n{\r\nstruct vfio_pci_region *region;\r\nregion = krealloc(vdev->region,\r\n(vdev->num_regions + 1) * sizeof(*region),\r\nGFP_KERNEL);\r\nif (!region)\r\nreturn -ENOMEM;\r\nvdev->region = region;\r\nvdev->region[vdev->num_regions].type = type;\r\nvdev->region[vdev->num_regions].subtype = subtype;\r\nvdev->region[vdev->num_regions].ops = ops;\r\nvdev->region[vdev->num_regions].size = size;\r\nvdev->region[vdev->num_regions].flags = flags;\r\nvdev->region[vdev->num_regions].data = data;\r\nvdev->num_regions++;\r\nreturn 0;\r\n}\r\nstatic long vfio_pci_ioctl(void *device_data,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nunsigned long minsz;\r\nif (cmd == VFIO_DEVICE_GET_INFO) {\r\nstruct vfio_device_info info;\r\nminsz = offsetofend(struct vfio_device_info, num_irqs);\r\nif (copy_from_user(&info, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (info.argsz < minsz)\r\nreturn -EINVAL;\r\ninfo.flags = VFIO_DEVICE_FLAGS_PCI;\r\nif (vdev->reset_works)\r\ninfo.flags |= VFIO_DEVICE_FLAGS_RESET;\r\ninfo.num_regions = VFIO_PCI_NUM_REGIONS + vdev->num_regions;\r\ninfo.num_irqs = VFIO_PCI_NUM_IRQS;\r\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\r\n-EFAULT : 0;\r\n} else if (cmd == VFIO_DEVICE_GET_REGION_INFO) {\r\nstruct pci_dev *pdev = vdev->pdev;\r\nstruct vfio_region_info info;\r\nstruct vfio_info_cap caps = { .buf = NULL, .size = 0 };\r\nint i, ret;\r\nminsz = offsetofend(struct vfio_region_info, offset);\r\nif (copy_from_user(&info, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (info.argsz < minsz)\r\nreturn -EINVAL;\r\nswitch (info.index) {\r\ncase VFIO_PCI_CONFIG_REGION_INDEX:\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.size = pdev->cfg_size;\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\r\nVFIO_REGION_INFO_FLAG_WRITE;\r\nbreak;\r\ncase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.size = pci_resource_len(pdev, info.index);\r\nif (!info.size) {\r\ninfo.flags = 0;\r\nbreak;\r\n}\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\r\nVFIO_REGION_INFO_FLAG_WRITE;\r\nif (vdev->bar_mmap_supported[info.index]) {\r\ninfo.flags |= VFIO_REGION_INFO_FLAG_MMAP;\r\nif (info.index == vdev->msix_bar) {\r\nret = msix_sparse_mmap_cap(vdev, &caps);\r\nif (ret)\r\nreturn ret;\r\n}\r\n}\r\nbreak;\r\ncase VFIO_PCI_ROM_REGION_INDEX:\r\n{\r\nvoid __iomem *io;\r\nsize_t size;\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.flags = 0;\r\ninfo.size = pci_resource_len(pdev, info.index);\r\nif (!info.size) {\r\nif (pdev->resource[PCI_ROM_RESOURCE].flags &\r\nIORESOURCE_ROM_SHADOW)\r\ninfo.size = 0x20000;\r\nelse\r\nbreak;\r\n}\r\nio = pci_map_rom(pdev, &size);\r\nif (!io || !size) {\r\ninfo.size = 0;\r\nbreak;\r\n}\r\npci_unmap_rom(pdev, io);\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ;\r\nbreak;\r\n}\r\ncase VFIO_PCI_VGA_REGION_INDEX:\r\nif (!vdev->has_vga)\r\nreturn -EINVAL;\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.size = 0xc0000;\r\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\r\nVFIO_REGION_INFO_FLAG_WRITE;\r\nbreak;\r\ndefault:\r\n{\r\nstruct vfio_region_info_cap_type cap_type;\r\nif (info.index >=\r\nVFIO_PCI_NUM_REGIONS + vdev->num_regions)\r\nreturn -EINVAL;\r\ni = info.index - VFIO_PCI_NUM_REGIONS;\r\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\r\ninfo.size = vdev->region[i].size;\r\ninfo.flags = vdev->region[i].flags;\r\ncap_type.type = vdev->region[i].type;\r\ncap_type.subtype = vdev->region[i].subtype;\r\nret = vfio_info_add_capability(&caps,\r\nVFIO_REGION_INFO_CAP_TYPE,\r\n&cap_type);\r\nif (ret)\r\nreturn ret;\r\n}\r\n}\r\nif (caps.size) {\r\ninfo.flags |= VFIO_REGION_INFO_FLAG_CAPS;\r\nif (info.argsz < sizeof(info) + caps.size) {\r\ninfo.argsz = sizeof(info) + caps.size;\r\ninfo.cap_offset = 0;\r\n} else {\r\nvfio_info_cap_shift(&caps, sizeof(info));\r\nif (copy_to_user((void __user *)arg +\r\nsizeof(info), caps.buf,\r\ncaps.size)) {\r\nkfree(caps.buf);\r\nreturn -EFAULT;\r\n}\r\ninfo.cap_offset = sizeof(info);\r\n}\r\nkfree(caps.buf);\r\n}\r\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\r\n-EFAULT : 0;\r\n} else if (cmd == VFIO_DEVICE_GET_IRQ_INFO) {\r\nstruct vfio_irq_info info;\r\nminsz = offsetofend(struct vfio_irq_info, count);\r\nif (copy_from_user(&info, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (info.argsz < minsz || info.index >= VFIO_PCI_NUM_IRQS)\r\nreturn -EINVAL;\r\nswitch (info.index) {\r\ncase VFIO_PCI_INTX_IRQ_INDEX ... VFIO_PCI_MSIX_IRQ_INDEX:\r\ncase VFIO_PCI_REQ_IRQ_INDEX:\r\nbreak;\r\ncase VFIO_PCI_ERR_IRQ_INDEX:\r\nif (pci_is_pcie(vdev->pdev))\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ninfo.flags = VFIO_IRQ_INFO_EVENTFD;\r\ninfo.count = vfio_pci_get_irq_count(vdev, info.index);\r\nif (info.index == VFIO_PCI_INTX_IRQ_INDEX)\r\ninfo.flags |= (VFIO_IRQ_INFO_MASKABLE |\r\nVFIO_IRQ_INFO_AUTOMASKED);\r\nelse\r\ninfo.flags |= VFIO_IRQ_INFO_NORESIZE;\r\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\r\n-EFAULT : 0;\r\n} else if (cmd == VFIO_DEVICE_SET_IRQS) {\r\nstruct vfio_irq_set hdr;\r\nu8 *data = NULL;\r\nint max, ret = 0;\r\nsize_t data_size = 0;\r\nminsz = offsetofend(struct vfio_irq_set, count);\r\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nmax = vfio_pci_get_irq_count(vdev, hdr.index);\r\nret = vfio_set_irqs_validate_and_prepare(&hdr, max,\r\nVFIO_PCI_NUM_IRQS, &data_size);\r\nif (ret)\r\nreturn ret;\r\nif (data_size) {\r\ndata = memdup_user((void __user *)(arg + minsz),\r\ndata_size);\r\nif (IS_ERR(data))\r\nreturn PTR_ERR(data);\r\n}\r\nmutex_lock(&vdev->igate);\r\nret = vfio_pci_set_irqs_ioctl(vdev, hdr.flags, hdr.index,\r\nhdr.start, hdr.count, data);\r\nmutex_unlock(&vdev->igate);\r\nkfree(data);\r\nreturn ret;\r\n} else if (cmd == VFIO_DEVICE_RESET) {\r\nreturn vdev->reset_works ?\r\npci_try_reset_function(vdev->pdev) : -EINVAL;\r\n} else if (cmd == VFIO_DEVICE_GET_PCI_HOT_RESET_INFO) {\r\nstruct vfio_pci_hot_reset_info hdr;\r\nstruct vfio_pci_fill_info fill = { 0 };\r\nstruct vfio_pci_dependent_device *devices = NULL;\r\nbool slot = false;\r\nint ret = 0;\r\nminsz = offsetofend(struct vfio_pci_hot_reset_info, count);\r\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (hdr.argsz < minsz)\r\nreturn -EINVAL;\r\nhdr.flags = 0;\r\nif (!pci_probe_reset_slot(vdev->pdev->slot))\r\nslot = true;\r\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\r\nreturn -ENODEV;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_count_devs,\r\n&fill.max, slot);\r\nif (ret)\r\nreturn ret;\r\nWARN_ON(!fill.max);\r\nif (hdr.argsz < sizeof(hdr) + (fill.max * sizeof(*devices))) {\r\nret = -ENOSPC;\r\nhdr.count = fill.max;\r\ngoto reset_info_exit;\r\n}\r\ndevices = kcalloc(fill.max, sizeof(*devices), GFP_KERNEL);\r\nif (!devices)\r\nreturn -ENOMEM;\r\nfill.devices = devices;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_fill_devs,\r\n&fill, slot);\r\nif (!ret)\r\nhdr.count = fill.cur;\r\nreset_info_exit:\r\nif (copy_to_user((void __user *)arg, &hdr, minsz))\r\nret = -EFAULT;\r\nif (!ret) {\r\nif (copy_to_user((void __user *)(arg + minsz), devices,\r\nhdr.count * sizeof(*devices)))\r\nret = -EFAULT;\r\n}\r\nkfree(devices);\r\nreturn ret;\r\n} else if (cmd == VFIO_DEVICE_PCI_HOT_RESET) {\r\nstruct vfio_pci_hot_reset hdr;\r\nint32_t *group_fds;\r\nstruct vfio_pci_group_entry *groups;\r\nstruct vfio_pci_group_info info;\r\nbool slot = false;\r\nint i, count = 0, ret = 0;\r\nminsz = offsetofend(struct vfio_pci_hot_reset, count);\r\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\r\nreturn -EFAULT;\r\nif (hdr.argsz < minsz || hdr.flags)\r\nreturn -EINVAL;\r\nif (!pci_probe_reset_slot(vdev->pdev->slot))\r\nslot = true;\r\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\r\nreturn -ENODEV;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_count_devs,\r\n&count, slot);\r\nif (ret)\r\nreturn ret;\r\nif (!hdr.count || hdr.count > count)\r\nreturn -EINVAL;\r\ngroup_fds = kcalloc(hdr.count, sizeof(*group_fds), GFP_KERNEL);\r\ngroups = kcalloc(hdr.count, sizeof(*groups), GFP_KERNEL);\r\nif (!group_fds || !groups) {\r\nkfree(group_fds);\r\nkfree(groups);\r\nreturn -ENOMEM;\r\n}\r\nif (copy_from_user(group_fds, (void __user *)(arg + minsz),\r\nhdr.count * sizeof(*group_fds))) {\r\nkfree(group_fds);\r\nkfree(groups);\r\nreturn -EFAULT;\r\n}\r\nfor (i = 0; i < hdr.count; i++) {\r\nstruct vfio_group *group;\r\nstruct fd f = fdget(group_fds[i]);\r\nif (!f.file) {\r\nret = -EBADF;\r\nbreak;\r\n}\r\ngroup = vfio_group_get_external_user(f.file);\r\nfdput(f);\r\nif (IS_ERR(group)) {\r\nret = PTR_ERR(group);\r\nbreak;\r\n}\r\ngroups[i].group = group;\r\ngroups[i].id = vfio_external_user_iommu_id(group);\r\n}\r\nkfree(group_fds);\r\nif (ret)\r\ngoto hot_reset_release;\r\ninfo.count = hdr.count;\r\ninfo.groups = groups;\r\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_validate_devs,\r\n&info, slot);\r\nif (!ret)\r\nret = slot ? pci_try_reset_slot(vdev->pdev->slot) :\r\npci_try_reset_bus(vdev->pdev->bus);\r\nhot_reset_release:\r\nfor (i--; i >= 0; i--)\r\nvfio_group_put_external_user(groups[i].group);\r\nkfree(groups);\r\nreturn ret;\r\n}\r\nreturn -ENOTTY;\r\n}\r\nstatic ssize_t vfio_pci_rw(void *device_data, char __user *buf,\r\nsize_t count, loff_t *ppos, bool iswrite)\r\n{\r\nunsigned int index = VFIO_PCI_OFFSET_TO_INDEX(*ppos);\r\nstruct vfio_pci_device *vdev = device_data;\r\nif (index >= VFIO_PCI_NUM_REGIONS + vdev->num_regions)\r\nreturn -EINVAL;\r\nswitch (index) {\r\ncase VFIO_PCI_CONFIG_REGION_INDEX:\r\nreturn vfio_pci_config_rw(vdev, buf, count, ppos, iswrite);\r\ncase VFIO_PCI_ROM_REGION_INDEX:\r\nif (iswrite)\r\nreturn -EINVAL;\r\nreturn vfio_pci_bar_rw(vdev, buf, count, ppos, false);\r\ncase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\r\nreturn vfio_pci_bar_rw(vdev, buf, count, ppos, iswrite);\r\ncase VFIO_PCI_VGA_REGION_INDEX:\r\nreturn vfio_pci_vga_rw(vdev, buf, count, ppos, iswrite);\r\ndefault:\r\nindex -= VFIO_PCI_NUM_REGIONS;\r\nreturn vdev->region[index].ops->rw(vdev, buf,\r\ncount, ppos, iswrite);\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic ssize_t vfio_pci_read(void *device_data, char __user *buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nif (!count)\r\nreturn 0;\r\nreturn vfio_pci_rw(device_data, buf, count, ppos, false);\r\n}\r\nstatic ssize_t vfio_pci_write(void *device_data, const char __user *buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nif (!count)\r\nreturn 0;\r\nreturn vfio_pci_rw(device_data, (char __user *)buf, count, ppos, true);\r\n}\r\nstatic int vfio_pci_mmap(void *device_data, struct vm_area_struct *vma)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nstruct pci_dev *pdev = vdev->pdev;\r\nunsigned int index;\r\nu64 phys_len, req_len, pgoff, req_start;\r\nint ret;\r\nindex = vma->vm_pgoff >> (VFIO_PCI_OFFSET_SHIFT - PAGE_SHIFT);\r\nif (vma->vm_end < vma->vm_start)\r\nreturn -EINVAL;\r\nif ((vma->vm_flags & VM_SHARED) == 0)\r\nreturn -EINVAL;\r\nif (index >= VFIO_PCI_ROM_REGION_INDEX)\r\nreturn -EINVAL;\r\nif (!vdev->bar_mmap_supported[index])\r\nreturn -EINVAL;\r\nphys_len = PAGE_ALIGN(pci_resource_len(pdev, index));\r\nreq_len = vma->vm_end - vma->vm_start;\r\npgoff = vma->vm_pgoff &\r\n((1U << (VFIO_PCI_OFFSET_SHIFT - PAGE_SHIFT)) - 1);\r\nreq_start = pgoff << PAGE_SHIFT;\r\nif (req_start + req_len > phys_len)\r\nreturn -EINVAL;\r\nif (index == vdev->msix_bar) {\r\nif (!(req_start >= vdev->msix_offset + vdev->msix_size ||\r\nreq_start + req_len <= vdev->msix_offset))\r\nreturn -EINVAL;\r\n}\r\nif (!vdev->barmap[index]) {\r\nret = pci_request_selected_regions(pdev,\r\n1 << index, "vfio-pci");\r\nif (ret)\r\nreturn ret;\r\nvdev->barmap[index] = pci_iomap(pdev, index, 0);\r\nif (!vdev->barmap[index]) {\r\npci_release_selected_regions(pdev, 1 << index);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nvma->vm_private_data = vdev;\r\nvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\r\nvma->vm_pgoff = (pci_resource_start(pdev, index) >> PAGE_SHIFT) + pgoff;\r\nreturn remap_pfn_range(vma, vma->vm_start, vma->vm_pgoff,\r\nreq_len, vma->vm_page_prot);\r\n}\r\nstatic void vfio_pci_request(void *device_data, unsigned int count)\r\n{\r\nstruct vfio_pci_device *vdev = device_data;\r\nmutex_lock(&vdev->igate);\r\nif (vdev->req_trigger) {\r\nif (!(count % 10))\r\ndev_notice_ratelimited(&vdev->pdev->dev,\r\n"Relaying device request to user (#%u)\n",\r\ncount);\r\neventfd_signal(vdev->req_trigger, 1);\r\n} else if (count == 0) {\r\ndev_warn(&vdev->pdev->dev,\r\n"No device request channel registered, blocked until released by user\n");\r\n}\r\nmutex_unlock(&vdev->igate);\r\n}\r\nstatic int vfio_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nstruct vfio_pci_device *vdev;\r\nstruct iommu_group *group;\r\nint ret;\r\nif (pdev->hdr_type != PCI_HEADER_TYPE_NORMAL)\r\nreturn -EINVAL;\r\ngroup = vfio_iommu_group_get(&pdev->dev);\r\nif (!group)\r\nreturn -EINVAL;\r\nvdev = kzalloc(sizeof(*vdev), GFP_KERNEL);\r\nif (!vdev) {\r\nvfio_iommu_group_put(group, &pdev->dev);\r\nreturn -ENOMEM;\r\n}\r\nvdev->pdev = pdev;\r\nvdev->irq_type = VFIO_PCI_NUM_IRQS;\r\nmutex_init(&vdev->igate);\r\nspin_lock_init(&vdev->irqlock);\r\nret = vfio_add_group_dev(&pdev->dev, &vfio_pci_ops, vdev);\r\nif (ret) {\r\nvfio_iommu_group_put(group, &pdev->dev);\r\nkfree(vdev);\r\nreturn ret;\r\n}\r\nif (vfio_pci_is_vga(pdev)) {\r\nvga_client_register(pdev, vdev, NULL, vfio_pci_set_vga_decode);\r\nvga_set_legacy_decoding(pdev,\r\nvfio_pci_set_vga_decode(vdev, false));\r\n}\r\nif (!disable_idle_d3) {\r\npci_set_power_state(pdev, PCI_D0);\r\npci_set_power_state(pdev, PCI_D3hot);\r\n}\r\nreturn ret;\r\n}\r\nstatic void vfio_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct vfio_pci_device *vdev;\r\nvdev = vfio_del_group_dev(&pdev->dev);\r\nif (!vdev)\r\nreturn;\r\nvfio_iommu_group_put(pdev->dev.iommu_group, &pdev->dev);\r\nkfree(vdev->region);\r\nkfree(vdev);\r\nif (vfio_pci_is_vga(pdev)) {\r\nvga_client_register(pdev, NULL, NULL, NULL);\r\nvga_set_legacy_decoding(pdev,\r\nVGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM |\r\nVGA_RSRC_LEGACY_IO | VGA_RSRC_LEGACY_MEM);\r\n}\r\nif (!disable_idle_d3)\r\npci_set_power_state(pdev, PCI_D0);\r\n}\r\nstatic pci_ers_result_t vfio_pci_aer_err_detected(struct pci_dev *pdev,\r\npci_channel_state_t state)\r\n{\r\nstruct vfio_pci_device *vdev;\r\nstruct vfio_device *device;\r\ndevice = vfio_device_get_from_dev(&pdev->dev);\r\nif (device == NULL)\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\nvdev = vfio_device_data(device);\r\nif (vdev == NULL) {\r\nvfio_device_put(device);\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nmutex_lock(&vdev->igate);\r\nif (vdev->err_trigger)\r\neventfd_signal(vdev->err_trigger, 1);\r\nmutex_unlock(&vdev->igate);\r\nvfio_device_put(device);\r\nreturn PCI_ERS_RESULT_CAN_RECOVER;\r\n}\r\nstatic int vfio_pci_get_devs(struct pci_dev *pdev, void *data)\r\n{\r\nstruct vfio_devices *devs = data;\r\nstruct vfio_device *device;\r\nif (devs->cur_index == devs->max_index)\r\nreturn -ENOSPC;\r\ndevice = vfio_device_get_from_dev(&pdev->dev);\r\nif (!device)\r\nreturn -EINVAL;\r\nif (pci_dev_driver(pdev) != &vfio_pci_driver) {\r\nvfio_device_put(device);\r\nreturn -EBUSY;\r\n}\r\ndevs->devices[devs->cur_index++] = device;\r\nreturn 0;\r\n}\r\nstatic void vfio_pci_try_bus_reset(struct vfio_pci_device *vdev)\r\n{\r\nstruct vfio_devices devs = { .cur_index = 0 };\r\nint i = 0, ret = -EINVAL;\r\nbool needs_reset = false, slot = false;\r\nstruct vfio_pci_device *tmp;\r\nif (!pci_probe_reset_slot(vdev->pdev->slot))\r\nslot = true;\r\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\r\nreturn;\r\nif (vfio_pci_for_each_slot_or_bus(vdev->pdev, vfio_pci_count_devs,\r\n&i, slot) || !i)\r\nreturn;\r\ndevs.max_index = i;\r\ndevs.devices = kcalloc(i, sizeof(struct vfio_device *), GFP_KERNEL);\r\nif (!devs.devices)\r\nreturn;\r\nif (vfio_pci_for_each_slot_or_bus(vdev->pdev,\r\nvfio_pci_get_devs, &devs, slot))\r\ngoto put_devs;\r\nfor (i = 0; i < devs.cur_index; i++) {\r\ntmp = vfio_device_data(devs.devices[i]);\r\nif (tmp->needs_reset)\r\nneeds_reset = true;\r\nif (tmp->refcnt)\r\ngoto put_devs;\r\n}\r\nif (needs_reset)\r\nret = slot ? pci_try_reset_slot(vdev->pdev->slot) :\r\npci_try_reset_bus(vdev->pdev->bus);\r\nput_devs:\r\nfor (i = 0; i < devs.cur_index; i++) {\r\ntmp = vfio_device_data(devs.devices[i]);\r\nif (!ret)\r\ntmp->needs_reset = false;\r\nif (!tmp->refcnt && !disable_idle_d3)\r\npci_set_power_state(tmp->pdev, PCI_D3hot);\r\nvfio_device_put(devs.devices[i]);\r\n}\r\nkfree(devs.devices);\r\n}\r\nstatic void __exit vfio_pci_cleanup(void)\r\n{\r\npci_unregister_driver(&vfio_pci_driver);\r\nvfio_pci_uninit_perm_bits();\r\n}\r\nstatic void __init vfio_pci_fill_ids(void)\r\n{\r\nchar *p, *id;\r\nint rc;\r\nif (ids[0] == '\0')\r\nreturn;\r\np = ids;\r\nwhile ((id = strsep(&p, ","))) {\r\nunsigned int vendor, device, subvendor = PCI_ANY_ID,\r\nsubdevice = PCI_ANY_ID, class = 0, class_mask = 0;\r\nint fields;\r\nif (!strlen(id))\r\ncontinue;\r\nfields = sscanf(id, "%x:%x:%x:%x:%x:%x",\r\n&vendor, &device, &subvendor, &subdevice,\r\n&class, &class_mask);\r\nif (fields < 2) {\r\npr_warn("invalid id string \"%s\"\n", id);\r\ncontinue;\r\n}\r\nrc = pci_add_dynid(&vfio_pci_driver, vendor, device,\r\nsubvendor, subdevice, class, class_mask, 0);\r\nif (rc)\r\npr_warn("failed to add dynamic id [%04hx:%04hx[%04hx:%04hx]] class %#08x/%08x (%d)\n",\r\nvendor, device, subvendor, subdevice,\r\nclass, class_mask, rc);\r\nelse\r\npr_info("add [%04hx:%04hx[%04hx:%04hx]] class %#08x/%08x\n",\r\nvendor, device, subvendor, subdevice,\r\nclass, class_mask);\r\n}\r\n}\r\nstatic int __init vfio_pci_init(void)\r\n{\r\nint ret;\r\nret = vfio_pci_init_perm_bits();\r\nif (ret)\r\nreturn ret;\r\nret = pci_register_driver(&vfio_pci_driver);\r\nif (ret)\r\ngoto out_driver;\r\nvfio_pci_fill_ids();\r\nreturn 0;\r\nout_driver:\r\nvfio_pci_uninit_perm_bits();\r\nreturn ret;\r\n}
