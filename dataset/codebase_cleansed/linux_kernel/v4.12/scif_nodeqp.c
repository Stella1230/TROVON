int scif_setup_qp_connect(struct scif_qp *qp, dma_addr_t *qp_offset,\r\nint local_size, struct scif_dev *scifdev)\r\n{\r\nvoid *local_q = qp->inbound_q.rb_base;\r\nint err = 0;\r\nu32 tmp_rd = 0;\r\nspin_lock_init(&qp->send_lock);\r\nspin_lock_init(&qp->recv_lock);\r\nif (!local_q) {\r\nlocal_q = kzalloc(local_size, GFP_KERNEL);\r\nif (!local_q) {\r\nerr = -ENOMEM;\r\nreturn err;\r\n}\r\n}\r\nerr = scif_map_single(&qp->local_buf, local_q, scifdev, local_size);\r\nif (err)\r\ngoto kfree;\r\nscif_rb_init(&qp->inbound_q,\r\n&tmp_rd,\r\n&qp->local_write,\r\nlocal_q, get_count_order(local_size));\r\nqp->inbound_q.read_ptr = NULL;\r\nerr = scif_map_single(qp_offset, qp,\r\nscifdev, sizeof(struct scif_qp));\r\nif (err)\r\ngoto unmap;\r\nqp->local_qp = *qp_offset;\r\nreturn err;\r\nunmap:\r\nscif_unmap_single(qp->local_buf, scifdev, local_size);\r\nqp->local_buf = 0;\r\nkfree:\r\nkfree(local_q);\r\nreturn err;\r\n}\r\nint scif_setup_qp_accept(struct scif_qp *qp, dma_addr_t *qp_offset,\r\ndma_addr_t phys, int local_size,\r\nstruct scif_dev *scifdev)\r\n{\r\nvoid *local_q;\r\nvoid *remote_q;\r\nstruct scif_qp *remote_qp;\r\nint remote_size;\r\nint err = 0;\r\nspin_lock_init(&qp->send_lock);\r\nspin_lock_init(&qp->recv_lock);\r\nremote_qp = scif_ioremap(phys, sizeof(struct scif_qp), scifdev);\r\nif (!remote_qp)\r\nreturn -EIO;\r\nqp->remote_qp = remote_qp;\r\nif (qp->remote_qp->magic != SCIFEP_MAGIC) {\r\nerr = -EIO;\r\ngoto iounmap;\r\n}\r\nqp->remote_buf = remote_qp->local_buf;\r\nremote_size = qp->remote_qp->inbound_q.size;\r\nremote_q = scif_ioremap(qp->remote_buf, remote_size, scifdev);\r\nif (!remote_q) {\r\nerr = -EIO;\r\ngoto iounmap;\r\n}\r\nqp->remote_qp->local_write = 0;\r\nscif_rb_init(&qp->outbound_q,\r\n&qp->local_read,\r\n&qp->remote_qp->local_write,\r\nremote_q,\r\nget_count_order(remote_size));\r\nlocal_q = kzalloc(local_size, GFP_KERNEL);\r\nif (!local_q) {\r\nerr = -ENOMEM;\r\ngoto iounmap_1;\r\n}\r\nerr = scif_map_single(&qp->local_buf, local_q, scifdev, local_size);\r\nif (err)\r\ngoto kfree;\r\nqp->remote_qp->local_read = 0;\r\nscif_rb_init(&qp->inbound_q,\r\n&qp->remote_qp->local_read,\r\n&qp->local_write,\r\nlocal_q, get_count_order(local_size));\r\nerr = scif_map_single(qp_offset, qp, scifdev,\r\nsizeof(struct scif_qp));\r\nif (err)\r\ngoto unmap;\r\nqp->local_qp = *qp_offset;\r\nreturn err;\r\nunmap:\r\nscif_unmap_single(qp->local_buf, scifdev, local_size);\r\nqp->local_buf = 0;\r\nkfree:\r\nkfree(local_q);\r\niounmap_1:\r\nscif_iounmap(remote_q, remote_size, scifdev);\r\nqp->outbound_q.rb_base = NULL;\r\niounmap:\r\nscif_iounmap(qp->remote_qp, sizeof(struct scif_qp), scifdev);\r\nqp->remote_qp = NULL;\r\nreturn err;\r\n}\r\nint scif_setup_qp_connect_response(struct scif_dev *scifdev,\r\nstruct scif_qp *qp, u64 payload)\r\n{\r\nint err = 0;\r\nvoid *r_buf;\r\nint remote_size;\r\nphys_addr_t tmp_phys;\r\nqp->remote_qp = scif_ioremap(payload, sizeof(struct scif_qp), scifdev);\r\nif (!qp->remote_qp) {\r\nerr = -ENOMEM;\r\ngoto error;\r\n}\r\nif (qp->remote_qp->magic != SCIFEP_MAGIC) {\r\ndev_err(&scifdev->sdev->dev,\r\n"SCIFEP_MAGIC mismatch between self %d remote %d\n",\r\nscif_dev[scif_info.nodeid].node, scifdev->node);\r\nerr = -ENODEV;\r\ngoto error;\r\n}\r\ntmp_phys = qp->remote_qp->local_buf;\r\nremote_size = qp->remote_qp->inbound_q.size;\r\nr_buf = scif_ioremap(tmp_phys, remote_size, scifdev);\r\nif (!r_buf)\r\nreturn -EIO;\r\nqp->local_read = 0;\r\nscif_rb_init(&qp->outbound_q,\r\n&qp->local_read,\r\n&qp->remote_qp->local_write,\r\nr_buf,\r\nget_count_order(remote_size));\r\nqp->remote_qp->local_read = qp->inbound_q.current_read_offset;\r\nscif_rb_init(&qp->inbound_q,\r\n&qp->remote_qp->local_read,\r\n&qp->local_write,\r\nqp->inbound_q.rb_base,\r\nget_count_order(qp->inbound_q.size));\r\nerror:\r\nreturn err;\r\n}\r\nstatic __always_inline void\r\nscif_send_msg_intr(struct scif_dev *scifdev)\r\n{\r\nstruct scif_hw_dev *sdev = scifdev->sdev;\r\nif (scifdev_is_p2p(scifdev))\r\nsdev->hw_ops->send_p2p_intr(sdev, scifdev->rdb, &scifdev->mmio);\r\nelse\r\nsdev->hw_ops->send_intr(sdev, scifdev->rdb);\r\n}\r\nint scif_qp_response(phys_addr_t phys, struct scif_dev *scifdev)\r\n{\r\nint err = 0;\r\nstruct scifmsg msg;\r\nerr = scif_setup_qp_connect_response(scifdev, scifdev->qpairs, phys);\r\nif (!err) {\r\nmsg.uop = SCIF_INIT;\r\nmsg.dst.node = scifdev->node;\r\nerr = scif_nodeqp_send(scifdev, &msg);\r\n}\r\nreturn err;\r\n}\r\nvoid scif_send_exit(struct scif_dev *scifdev)\r\n{\r\nstruct scifmsg msg;\r\nint ret;\r\nscifdev->exit = OP_IN_PROGRESS;\r\nmsg.uop = SCIF_EXIT;\r\nmsg.src.node = scif_info.nodeid;\r\nmsg.dst.node = scifdev->node;\r\nret = scif_nodeqp_send(scifdev, &msg);\r\nif (ret)\r\ngoto done;\r\nwait_event_timeout(scif_info.exitwq, scifdev->exit == OP_COMPLETED,\r\nSCIF_NODE_ALIVE_TIMEOUT);\r\ndone:\r\nscifdev->exit = OP_IDLE;\r\n}\r\nint scif_setup_qp(struct scif_dev *scifdev)\r\n{\r\nint err = 0;\r\nint local_size;\r\nstruct scif_qp *qp;\r\nlocal_size = SCIF_NODE_QP_SIZE;\r\nqp = kzalloc(sizeof(*qp), GFP_KERNEL);\r\nif (!qp) {\r\nerr = -ENOMEM;\r\nreturn err;\r\n}\r\nqp->magic = SCIFEP_MAGIC;\r\nscifdev->qpairs = qp;\r\nerr = scif_setup_qp_connect(qp, &scifdev->qp_dma_addr,\r\nlocal_size, scifdev);\r\nif (err)\r\ngoto free_qp;\r\nreturn err;\r\nfree_qp:\r\nkfree(scifdev->qpairs);\r\nscifdev->qpairs = NULL;\r\nreturn err;\r\n}\r\nstatic void scif_p2p_freesg(struct scatterlist *sg)\r\n{\r\nkfree(sg);\r\n}\r\nstatic struct scatterlist *\r\nscif_p2p_setsg(phys_addr_t pa, int page_size, int page_cnt)\r\n{\r\nstruct scatterlist *sg;\r\nstruct page *page;\r\nint i;\r\nsg = kcalloc(page_cnt, sizeof(struct scatterlist), GFP_KERNEL);\r\nif (!sg)\r\nreturn NULL;\r\nsg_init_table(sg, page_cnt);\r\nfor (i = 0; i < page_cnt; i++) {\r\npage = pfn_to_page(pa >> PAGE_SHIFT);\r\nsg_set_page(&sg[i], page, page_size, 0);\r\npa += page_size;\r\n}\r\nreturn sg;\r\n}\r\nstatic struct scif_p2p_info *\r\nscif_init_p2p_info(struct scif_dev *scifdev, struct scif_dev *peerdev)\r\n{\r\nstruct scif_p2p_info *p2p;\r\nint num_mmio_pages, num_aper_pages, sg_page_shift, err, num_aper_chunks;\r\nstruct scif_hw_dev *psdev = peerdev->sdev;\r\nstruct scif_hw_dev *sdev = scifdev->sdev;\r\nnum_mmio_pages = psdev->mmio->len >> PAGE_SHIFT;\r\nnum_aper_pages = psdev->aper->len >> PAGE_SHIFT;\r\np2p = kzalloc(sizeof(*p2p), GFP_KERNEL);\r\nif (!p2p)\r\nreturn NULL;\r\np2p->ppi_sg[SCIF_PPI_MMIO] = scif_p2p_setsg(psdev->mmio->pa,\r\nPAGE_SIZE, num_mmio_pages);\r\nif (!p2p->ppi_sg[SCIF_PPI_MMIO])\r\ngoto free_p2p;\r\np2p->sg_nentries[SCIF_PPI_MMIO] = num_mmio_pages;\r\nsg_page_shift = get_order(min(psdev->aper->len, (u64)(1 << 30)));\r\nnum_aper_chunks = num_aper_pages >> (sg_page_shift - PAGE_SHIFT);\r\np2p->ppi_sg[SCIF_PPI_APER] = scif_p2p_setsg(psdev->aper->pa,\r\n1 << sg_page_shift,\r\nnum_aper_chunks);\r\np2p->sg_nentries[SCIF_PPI_APER] = num_aper_chunks;\r\nerr = dma_map_sg(&sdev->dev, p2p->ppi_sg[SCIF_PPI_MMIO],\r\nnum_mmio_pages, PCI_DMA_BIDIRECTIONAL);\r\nif (err != num_mmio_pages)\r\ngoto scif_p2p_free;\r\nerr = dma_map_sg(&sdev->dev, p2p->ppi_sg[SCIF_PPI_APER],\r\nnum_aper_chunks, PCI_DMA_BIDIRECTIONAL);\r\nif (err != num_aper_chunks)\r\ngoto dma_unmap;\r\np2p->ppi_da[SCIF_PPI_MMIO] = sg_dma_address(p2p->ppi_sg[SCIF_PPI_MMIO]);\r\np2p->ppi_da[SCIF_PPI_APER] = sg_dma_address(p2p->ppi_sg[SCIF_PPI_APER]);\r\np2p->ppi_len[SCIF_PPI_MMIO] = num_mmio_pages;\r\np2p->ppi_len[SCIF_PPI_APER] = num_aper_pages;\r\np2p->ppi_peer_id = peerdev->node;\r\nreturn p2p;\r\ndma_unmap:\r\ndma_unmap_sg(&sdev->dev, p2p->ppi_sg[SCIF_PPI_MMIO],\r\np2p->sg_nentries[SCIF_PPI_MMIO], DMA_BIDIRECTIONAL);\r\nscif_p2p_free:\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_MMIO]);\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_APER]);\r\nfree_p2p:\r\nkfree(p2p);\r\nreturn NULL;\r\n}\r\nstatic void scif_deinit_p2p_info(struct scif_dev *scifdev,\r\nstruct scif_p2p_info *p2p)\r\n{\r\nstruct scif_hw_dev *sdev = scifdev->sdev;\r\ndma_unmap_sg(&sdev->dev, p2p->ppi_sg[SCIF_PPI_MMIO],\r\np2p->sg_nentries[SCIF_PPI_MMIO], DMA_BIDIRECTIONAL);\r\ndma_unmap_sg(&sdev->dev, p2p->ppi_sg[SCIF_PPI_APER],\r\np2p->sg_nentries[SCIF_PPI_APER], DMA_BIDIRECTIONAL);\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_MMIO]);\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_APER]);\r\nkfree(p2p);\r\n}\r\nstatic void scif_node_connect(struct scif_dev *scifdev, int dst)\r\n{\r\nstruct scif_dev *dev_j = scifdev;\r\nstruct scif_dev *dev_i = NULL;\r\nstruct scif_p2p_info *p2p_ij = NULL;\r\nstruct scif_p2p_info *p2p_ji = NULL;\r\nstruct scif_p2p_info *p2p;\r\nstruct list_head *pos, *tmp;\r\nstruct scifmsg msg;\r\nint err;\r\nu64 tmppayload;\r\nif (dst < 1 || dst > scif_info.maxid)\r\nreturn;\r\ndev_i = &scif_dev[dst];\r\nif (!_scifdev_alive(dev_i))\r\nreturn;\r\nif (!list_empty(&dev_i->p2p)) {\r\nlist_for_each_safe(pos, tmp, &dev_i->p2p) {\r\np2p = list_entry(pos, struct scif_p2p_info, ppi_list);\r\nif (p2p->ppi_peer_id == dev_j->node)\r\nreturn;\r\n}\r\n}\r\np2p_ij = scif_init_p2p_info(dev_i, dev_j);\r\nif (!p2p_ij)\r\nreturn;\r\np2p_ji = scif_init_p2p_info(dev_j, dev_i);\r\nif (!p2p_ji) {\r\nscif_deinit_p2p_info(dev_i, p2p_ij);\r\nreturn;\r\n}\r\nlist_add_tail(&p2p_ij->ppi_list, &dev_i->p2p);\r\nlist_add_tail(&p2p_ji->ppi_list, &dev_j->p2p);\r\nmsg.uop = SCIF_NODE_ADD;\r\nmsg.src.node = dev_j->node;\r\nmsg.dst.node = dev_i->node;\r\nmsg.payload[0] = p2p_ji->ppi_da[SCIF_PPI_APER];\r\nmsg.payload[1] = p2p_ij->ppi_da[SCIF_PPI_MMIO];\r\nmsg.payload[2] = p2p_ij->ppi_da[SCIF_PPI_APER];\r\nmsg.payload[3] = p2p_ij->ppi_len[SCIF_PPI_APER] << PAGE_SHIFT;\r\nerr = scif_nodeqp_send(dev_i, &msg);\r\nif (err) {\r\ndev_err(&scifdev->sdev->dev,\r\n"%s %d error %d\n", __func__, __LINE__, err);\r\nreturn;\r\n}\r\nmsg.uop = SCIF_NODE_ADD;\r\nmsg.src.node = dev_i->node;\r\nmsg.dst.node = dev_j->node;\r\ntmppayload = msg.payload[0];\r\nmsg.payload[0] = msg.payload[2];\r\nmsg.payload[2] = tmppayload;\r\nmsg.payload[1] = p2p_ji->ppi_da[SCIF_PPI_MMIO];\r\nmsg.payload[3] = p2p_ji->ppi_len[SCIF_PPI_APER] << PAGE_SHIFT;\r\nscif_nodeqp_send(dev_j, &msg);\r\n}\r\nstatic void scif_p2p_setup(void)\r\n{\r\nint i, j;\r\nif (!scif_info.p2p_enable)\r\nreturn;\r\nfor (i = 1; i <= scif_info.maxid; i++)\r\nif (!_scifdev_alive(&scif_dev[i]))\r\nreturn;\r\nfor (i = 1; i <= scif_info.maxid; i++) {\r\nfor (j = 1; j <= scif_info.maxid; j++) {\r\nstruct scif_dev *scifdev = &scif_dev[i];\r\nif (i == j)\r\ncontinue;\r\nscif_node_connect(scifdev, j);\r\n}\r\n}\r\n}\r\nstatic void\r\nscif_display_message(struct scif_dev *scifdev, struct scifmsg *msg,\r\nconst char *label)\r\n{\r\nif (!scif_info.en_msg_log)\r\nreturn;\r\nif (msg->uop > SCIF_MAX_MSG) {\r\ndev_err(&scifdev->sdev->dev,\r\n"%s: unknown msg type %d\n", label, msg->uop);\r\nreturn;\r\n}\r\ndev_info(&scifdev->sdev->dev,\r\n"%s: msg type %s, src %d:%d, dest %d:%d payload 0x%llx:0x%llx:0x%llx:0x%llx\n",\r\nlabel, message_types[msg->uop], msg->src.node, msg->src.port,\r\nmsg->dst.node, msg->dst.port, msg->payload[0], msg->payload[1],\r\nmsg->payload[2], msg->payload[3]);\r\n}\r\nint _scif_nodeqp_send(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_qp *qp = scifdev->qpairs;\r\nint err = -ENOMEM, loop_cnt = 0;\r\nscif_display_message(scifdev, msg, "Sent");\r\nif (!qp) {\r\nerr = -EINVAL;\r\ngoto error;\r\n}\r\nspin_lock(&qp->send_lock);\r\nwhile ((err = scif_rb_write(&qp->outbound_q,\r\nmsg, sizeof(struct scifmsg)))) {\r\nmdelay(1);\r\n#define SCIF_NODEQP_SEND_TO_MSEC (3 * 1000)\r\nif (loop_cnt++ > (SCIF_NODEQP_SEND_TO_MSEC)) {\r\nerr = -ENODEV;\r\nbreak;\r\n}\r\n}\r\nif (!err)\r\nscif_rb_commit(&qp->outbound_q);\r\nspin_unlock(&qp->send_lock);\r\nif (!err) {\r\nif (scifdev_self(scifdev))\r\nqueue_work(scifdev->intr_wq, &scifdev->intr_bh);\r\nelse\r\nscif_send_msg_intr(scifdev);\r\n}\r\nerror:\r\nif (err)\r\ndev_dbg(&scifdev->sdev->dev,\r\n"%s %d error %d uop %d\n",\r\n__func__, __LINE__, err, msg->uop);\r\nreturn err;\r\n}\r\nint scif_nodeqp_send(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nint err;\r\nstruct device *spdev = NULL;\r\nif (msg->uop > SCIF_EXIT_ACK) {\r\nif (OP_IDLE != scifdev->exit)\r\nreturn -ENODEV;\r\nspdev = scif_get_peer_dev(scifdev);\r\nif (IS_ERR(spdev)) {\r\nerr = PTR_ERR(spdev);\r\nreturn err;\r\n}\r\n}\r\nerr = _scif_nodeqp_send(scifdev, msg);\r\nif (msg->uop > SCIF_EXIT_ACK)\r\nscif_put_peer_dev(spdev);\r\nreturn err;\r\n}\r\nvoid scif_misc_handler(struct work_struct *work)\r\n{\r\nscif_rma_handle_remote_fences();\r\nscif_rma_destroy_windows();\r\nscif_rma_destroy_tcw_invalid();\r\nscif_cleanup_zombie_epd();\r\n}\r\nstatic __always_inline void\r\nscif_init(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nflush_delayed_work(&scifdev->qp_dwork);\r\nscif_peer_register_device(scifdev);\r\nif (scif_is_mgmt_node()) {\r\nmutex_lock(&scif_info.conflock);\r\nscif_p2p_setup();\r\nmutex_unlock(&scif_info.conflock);\r\n}\r\n}\r\nstatic __always_inline void\r\nscif_exit(struct scif_dev *scifdev, struct scifmsg *unused)\r\n{\r\nscifdev->exit_ack_pending = true;\r\nif (scif_is_mgmt_node())\r\nscif_disconnect_node(scifdev->node, false);\r\nelse\r\nscif_stop(scifdev);\r\nschedule_delayed_work(&scifdev->qp_dwork,\r\nmsecs_to_jiffies(1000));\r\n}\r\nstatic __always_inline void\r\nscif_exit_ack(struct scif_dev *scifdev, struct scifmsg *unused)\r\n{\r\nscifdev->exit = OP_COMPLETED;\r\nwake_up(&scif_info.exitwq);\r\n}\r\nstatic __always_inline void\r\nscif_node_add(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_dev *newdev;\r\ndma_addr_t qp_offset;\r\nint qp_connect;\r\nstruct scif_hw_dev *sdev;\r\ndev_dbg(&scifdev->sdev->dev,\r\n"Scifdev %d:%d received NODE_ADD msg for node %d\n",\r\nscifdev->node, msg->dst.node, msg->src.node);\r\ndev_dbg(&scifdev->sdev->dev,\r\n"Remote address for this node's aperture %llx\n",\r\nmsg->payload[0]);\r\nnewdev = &scif_dev[msg->src.node];\r\nnewdev->node = msg->src.node;\r\nnewdev->sdev = scif_dev[SCIF_MGMT_NODE].sdev;\r\nsdev = newdev->sdev;\r\nif (scif_setup_intr_wq(newdev)) {\r\ndev_err(&scifdev->sdev->dev,\r\n"failed to setup interrupts for %d\n", msg->src.node);\r\ngoto interrupt_setup_error;\r\n}\r\nnewdev->mmio.va = ioremap_nocache(msg->payload[1], sdev->mmio->len);\r\nif (!newdev->mmio.va) {\r\ndev_err(&scifdev->sdev->dev,\r\n"failed to map mmio for %d\n", msg->src.node);\r\ngoto mmio_map_error;\r\n}\r\nnewdev->qpairs = kzalloc(sizeof(*newdev->qpairs), GFP_KERNEL);\r\nif (!newdev->qpairs)\r\ngoto qp_alloc_error;\r\nnewdev->base_addr = msg->payload[0];\r\nqp_connect = scif_setup_qp_connect(newdev->qpairs, &qp_offset,\r\nSCIF_NODE_QP_SIZE, newdev);\r\nif (qp_connect) {\r\ndev_err(&scifdev->sdev->dev,\r\n"failed to setup qp_connect %d\n", qp_connect);\r\ngoto qp_connect_error;\r\n}\r\nnewdev->db = sdev->hw_ops->next_db(sdev);\r\nnewdev->cookie = sdev->hw_ops->request_irq(sdev, scif_intr_handler,\r\n"SCIF_INTR", newdev,\r\nnewdev->db);\r\nif (IS_ERR(newdev->cookie))\r\ngoto qp_connect_error;\r\nnewdev->qpairs->magic = SCIFEP_MAGIC;\r\nnewdev->qpairs->qp_state = SCIF_QP_OFFLINE;\r\nmsg->uop = SCIF_NODE_ADD_ACK;\r\nmsg->dst.node = msg->src.node;\r\nmsg->src.node = scif_info.nodeid;\r\nmsg->payload[0] = qp_offset;\r\nmsg->payload[2] = newdev->db;\r\nscif_nodeqp_send(&scif_dev[SCIF_MGMT_NODE], msg);\r\nreturn;\r\nqp_connect_error:\r\nkfree(newdev->qpairs);\r\nnewdev->qpairs = NULL;\r\nqp_alloc_error:\r\niounmap(newdev->mmio.va);\r\nnewdev->mmio.va = NULL;\r\nmmio_map_error:\r\ninterrupt_setup_error:\r\ndev_err(&scifdev->sdev->dev,\r\n"node add failed for node %d\n", msg->src.node);\r\nmsg->uop = SCIF_NODE_ADD_NACK;\r\nmsg->dst.node = msg->src.node;\r\nmsg->src.node = scif_info.nodeid;\r\nscif_nodeqp_send(&scif_dev[SCIF_MGMT_NODE], msg);\r\n}\r\nvoid scif_poll_qp_state(struct work_struct *work)\r\n{\r\n#define SCIF_NODE_QP_RETRY 100\r\n#define SCIF_NODE_QP_TIMEOUT 100\r\nstruct scif_dev *peerdev = container_of(work, struct scif_dev,\r\np2p_dwork.work);\r\nstruct scif_qp *qp = &peerdev->qpairs[0];\r\nif (qp->qp_state != SCIF_QP_ONLINE ||\r\nqp->remote_qp->qp_state != SCIF_QP_ONLINE) {\r\nif (peerdev->p2p_retry++ == SCIF_NODE_QP_RETRY) {\r\ndev_err(&peerdev->sdev->dev,\r\n"Warning: QP check timeout with state %d\n",\r\nqp->qp_state);\r\ngoto timeout;\r\n}\r\nschedule_delayed_work(&peerdev->p2p_dwork,\r\nmsecs_to_jiffies(SCIF_NODE_QP_TIMEOUT));\r\nreturn;\r\n}\r\nreturn;\r\ntimeout:\r\ndev_err(&peerdev->sdev->dev,\r\n"%s %d remote node %d offline, state = 0x%x\n",\r\n__func__, __LINE__, peerdev->node, qp->qp_state);\r\nqp->remote_qp->qp_state = SCIF_QP_OFFLINE;\r\nscif_peer_unregister_device(peerdev);\r\nscif_cleanup_scifdev(peerdev);\r\n}\r\nstatic __always_inline void\r\nscif_node_add_ack(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_dev *peerdev;\r\nstruct scif_qp *qp;\r\nstruct scif_dev *dst_dev = &scif_dev[msg->dst.node];\r\ndev_dbg(&scifdev->sdev->dev,\r\n"Scifdev %d received SCIF_NODE_ADD_ACK msg src %d dst %d\n",\r\nscifdev->node, msg->src.node, msg->dst.node);\r\ndev_dbg(&scifdev->sdev->dev,\r\n"payload %llx %llx %llx %llx\n", msg->payload[0],\r\nmsg->payload[1], msg->payload[2], msg->payload[3]);\r\nif (scif_is_mgmt_node()) {\r\nmutex_lock(&scif_info.conflock);\r\nmsg->payload[1] = scif_info.maxid;\r\nscif_nodeqp_send(dst_dev, msg);\r\nmutex_unlock(&scif_info.conflock);\r\nreturn;\r\n}\r\npeerdev = &scif_dev[msg->src.node];\r\npeerdev->sdev = scif_dev[SCIF_MGMT_NODE].sdev;\r\npeerdev->node = msg->src.node;\r\nqp = &peerdev->qpairs[0];\r\nif ((scif_setup_qp_connect_response(peerdev, &peerdev->qpairs[0],\r\nmsg->payload[0])))\r\ngoto local_error;\r\npeerdev->rdb = msg->payload[2];\r\nqp->remote_qp->qp_state = SCIF_QP_ONLINE;\r\nscif_peer_register_device(peerdev);\r\nschedule_delayed_work(&peerdev->p2p_dwork, 0);\r\nreturn;\r\nlocal_error:\r\nscif_cleanup_scifdev(peerdev);\r\n}\r\nstatic __always_inline void\r\nscif_node_add_nack(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nif (scif_is_mgmt_node()) {\r\nstruct scif_dev *dst_dev = &scif_dev[msg->dst.node];\r\ndev_dbg(&scifdev->sdev->dev,\r\n"SCIF_NODE_ADD_NACK received from %d\n", scifdev->node);\r\nscif_nodeqp_send(dst_dev, msg);\r\n}\r\n}\r\nstatic __always_inline void\r\nscif_node_remove(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nint node = msg->payload[0];\r\nstruct scif_dev *scdev = &scif_dev[node];\r\nscdev->node_remove_ack_pending = true;\r\nscif_handle_remove_node(node);\r\n}\r\nstatic __always_inline void\r\nscif_node_remove_ack(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nstruct scif_dev *sdev = &scif_dev[msg->payload[0]];\r\natomic_inc(&sdev->disconn_rescnt);\r\nwake_up(&sdev->disconn_wq);\r\n}\r\nstatic __always_inline void\r\nscif_get_node_info_resp(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\nif (scif_is_mgmt_node()) {\r\nswap(msg->dst.node, msg->src.node);\r\nmutex_lock(&scif_info.conflock);\r\nmsg->payload[1] = scif_info.maxid;\r\nmsg->payload[2] = scif_info.total;\r\nmutex_unlock(&scif_info.conflock);\r\nscif_nodeqp_send(scifdev, msg);\r\n} else {\r\nstruct completion *node_info =\r\n(struct completion *)msg->payload[3];\r\nmutex_lock(&scif_info.conflock);\r\nscif_info.maxid = msg->payload[1];\r\nscif_info.total = msg->payload[2];\r\ncomplete_all(node_info);\r\nmutex_unlock(&scif_info.conflock);\r\n}\r\n}\r\nstatic void\r\nscif_msg_unknown(struct scif_dev *scifdev, struct scifmsg *msg)\r\n{\r\ndev_err(&scifdev->sdev->dev,\r\n"Unknown message 0x%xn scifdev->node 0x%x\n",\r\nmsg->uop, scifdev->node);\r\n}\r\nstatic void\r\nscif_nodeqp_msg_handler(struct scif_dev *scifdev,\r\nstruct scif_qp *qp, struct scifmsg *msg)\r\n{\r\nscif_display_message(scifdev, msg, "Rcvd");\r\nif (msg->uop > (u32)scif_max_msg_id) {\r\ndev_err(&scifdev->sdev->dev,\r\n"Unknown message 0x%xn scifdev->node 0x%x\n",\r\nmsg->uop, scifdev->node);\r\nreturn;\r\n}\r\nscif_intr_func[msg->uop](scifdev, msg);\r\n}\r\nvoid scif_nodeqp_intrhandler(struct scif_dev *scifdev, struct scif_qp *qp)\r\n{\r\nstruct scifmsg msg;\r\nint read_size;\r\ndo {\r\nread_size = scif_rb_get_next(&qp->inbound_q, &msg, sizeof(msg));\r\nif (!read_size)\r\nbreak;\r\nscif_nodeqp_msg_handler(scifdev, qp, &msg);\r\nif (SCIF_EXIT_ACK == msg.uop)\r\nbreak;\r\nscif_rb_update_read_ptr(&qp->inbound_q);\r\n} while (1);\r\n}\r\nstatic void scif_loopb_wq_handler(struct work_struct *unused)\r\n{\r\nstruct scif_dev *scifdev = scif_info.loopb_dev;\r\nstruct scif_qp *qp = scifdev->qpairs;\r\nstruct scif_loopb_msg *msg;\r\ndo {\r\nmsg = NULL;\r\nspin_lock(&qp->recv_lock);\r\nif (!list_empty(&scif_info.loopb_recv_q)) {\r\nmsg = list_first_entry(&scif_info.loopb_recv_q,\r\nstruct scif_loopb_msg,\r\nlist);\r\nlist_del(&msg->list);\r\n}\r\nspin_unlock(&qp->recv_lock);\r\nif (msg) {\r\nscif_nodeqp_msg_handler(scifdev, qp, &msg->msg);\r\nkfree(msg);\r\n}\r\n} while (msg);\r\n}\r\nint\r\nscif_loopb_msg_handler(struct scif_dev *scifdev, struct scif_qp *qp)\r\n{\r\nint read_size;\r\nstruct scif_loopb_msg *msg;\r\ndo {\r\nmsg = kmalloc(sizeof(*msg), GFP_KERNEL);\r\nif (!msg)\r\nreturn -ENOMEM;\r\nread_size = scif_rb_get_next(&qp->inbound_q, &msg->msg,\r\nsizeof(struct scifmsg));\r\nif (read_size != sizeof(struct scifmsg)) {\r\nkfree(msg);\r\nscif_rb_update_read_ptr(&qp->inbound_q);\r\nbreak;\r\n}\r\nspin_lock(&qp->recv_lock);\r\nlist_add_tail(&msg->list, &scif_info.loopb_recv_q);\r\nspin_unlock(&qp->recv_lock);\r\nqueue_work(scif_info.loopb_wq, &scif_info.loopb_work);\r\nscif_rb_update_read_ptr(&qp->inbound_q);\r\n} while (read_size == sizeof(struct scifmsg));\r\nreturn read_size;\r\n}\r\nint scif_setup_loopback_qp(struct scif_dev *scifdev)\r\n{\r\nint err = 0;\r\nvoid *local_q;\r\nstruct scif_qp *qp;\r\nerr = scif_setup_intr_wq(scifdev);\r\nif (err)\r\ngoto exit;\r\nINIT_LIST_HEAD(&scif_info.loopb_recv_q);\r\nsnprintf(scif_info.loopb_wqname, sizeof(scif_info.loopb_wqname),\r\n"SCIF LOOPB %d", scifdev->node);\r\nscif_info.loopb_wq =\r\nalloc_ordered_workqueue(scif_info.loopb_wqname, 0);\r\nif (!scif_info.loopb_wq) {\r\nerr = -ENOMEM;\r\ngoto destroy_intr;\r\n}\r\nINIT_WORK(&scif_info.loopb_work, scif_loopb_wq_handler);\r\nscifdev->qpairs = kzalloc(sizeof(*scifdev->qpairs), GFP_KERNEL);\r\nif (!scifdev->qpairs) {\r\nerr = -ENOMEM;\r\ngoto destroy_loopb_wq;\r\n}\r\nqp = scifdev->qpairs;\r\nqp->magic = SCIFEP_MAGIC;\r\nspin_lock_init(&qp->send_lock);\r\nspin_lock_init(&qp->recv_lock);\r\nlocal_q = kzalloc(SCIF_NODE_QP_SIZE, GFP_KERNEL);\r\nif (!local_q) {\r\nerr = -ENOMEM;\r\ngoto free_qpairs;\r\n}\r\nscif_rb_init(&qp->outbound_q,\r\n&qp->local_read,\r\n&qp->local_write,\r\nlocal_q, get_count_order(SCIF_NODE_QP_SIZE));\r\nscif_rb_init(&qp->inbound_q,\r\n&qp->local_read,\r\n&qp->local_write,\r\nlocal_q, get_count_order(SCIF_NODE_QP_SIZE));\r\nscif_info.nodeid = scifdev->node;\r\nscif_peer_register_device(scifdev);\r\nscif_info.loopb_dev = scifdev;\r\nreturn err;\r\nfree_qpairs:\r\nkfree(scifdev->qpairs);\r\ndestroy_loopb_wq:\r\ndestroy_workqueue(scif_info.loopb_wq);\r\ndestroy_intr:\r\nscif_destroy_intr_wq(scifdev);\r\nexit:\r\nreturn err;\r\n}\r\nint scif_destroy_loopback_qp(struct scif_dev *scifdev)\r\n{\r\nscif_peer_unregister_device(scifdev);\r\ndestroy_workqueue(scif_info.loopb_wq);\r\nscif_destroy_intr_wq(scifdev);\r\nkfree(scifdev->qpairs->outbound_q.rb_base);\r\nkfree(scifdev->qpairs);\r\nscifdev->sdev = NULL;\r\nscif_info.loopb_dev = NULL;\r\nreturn 0;\r\n}\r\nvoid scif_destroy_p2p(struct scif_dev *scifdev)\r\n{\r\nstruct scif_dev *peer_dev;\r\nstruct scif_p2p_info *p2p;\r\nstruct list_head *pos, *tmp;\r\nint bd;\r\nmutex_lock(&scif_info.conflock);\r\nlist_for_each_safe(pos, tmp, &scifdev->p2p) {\r\np2p = list_entry(pos, struct scif_p2p_info, ppi_list);\r\ndma_unmap_sg(&scifdev->sdev->dev, p2p->ppi_sg[SCIF_PPI_MMIO],\r\np2p->sg_nentries[SCIF_PPI_MMIO],\r\nDMA_BIDIRECTIONAL);\r\ndma_unmap_sg(&scifdev->sdev->dev, p2p->ppi_sg[SCIF_PPI_APER],\r\np2p->sg_nentries[SCIF_PPI_APER],\r\nDMA_BIDIRECTIONAL);\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_MMIO]);\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_APER]);\r\nlist_del(pos);\r\nkfree(p2p);\r\n}\r\nfor (bd = SCIF_MGMT_NODE + 1; bd <= scif_info.maxid; bd++) {\r\npeer_dev = &scif_dev[bd];\r\nlist_for_each_safe(pos, tmp, &peer_dev->p2p) {\r\np2p = list_entry(pos, struct scif_p2p_info, ppi_list);\r\nif (p2p->ppi_peer_id == scifdev->node) {\r\ndma_unmap_sg(&peer_dev->sdev->dev,\r\np2p->ppi_sg[SCIF_PPI_MMIO],\r\np2p->sg_nentries[SCIF_PPI_MMIO],\r\nDMA_BIDIRECTIONAL);\r\ndma_unmap_sg(&peer_dev->sdev->dev,\r\np2p->ppi_sg[SCIF_PPI_APER],\r\np2p->sg_nentries[SCIF_PPI_APER],\r\nDMA_BIDIRECTIONAL);\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_MMIO]);\r\nscif_p2p_freesg(p2p->ppi_sg[SCIF_PPI_APER]);\r\nlist_del(pos);\r\nkfree(p2p);\r\n}\r\n}\r\n}\r\nmutex_unlock(&scif_info.conflock);\r\n}
