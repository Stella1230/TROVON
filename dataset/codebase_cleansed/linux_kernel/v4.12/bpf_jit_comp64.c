static void bpf_jit_fill_ill_insns(void *area, unsigned int size)\r\n{\r\nint *p = area;\r\nwhile (p < (int *)((char *)area + size))\r\n*p++ = BREAKPOINT_INSTRUCTION;\r\n}\r\nstatic inline void bpf_flush_icache(void *start, void *end)\r\n{\r\nsmp_wmb();\r\nflush_icache_range((unsigned long)start, (unsigned long)end);\r\n}\r\nstatic inline bool bpf_is_seen_register(struct codegen_context *ctx, int i)\r\n{\r\nreturn (ctx->seen & (1 << (31 - b2p[i])));\r\n}\r\nstatic inline void bpf_set_seen_register(struct codegen_context *ctx, int i)\r\n{\r\nctx->seen |= (1 << (31 - b2p[i]));\r\n}\r\nstatic inline bool bpf_has_stack_frame(struct codegen_context *ctx)\r\n{\r\nreturn ctx->seen & SEEN_FUNC || bpf_is_seen_register(ctx, BPF_REG_FP);\r\n}\r\nstatic int bpf_jit_stack_local(struct codegen_context *ctx)\r\n{\r\nif (bpf_has_stack_frame(ctx))\r\nreturn STACK_FRAME_MIN_SIZE + MAX_BPF_STACK;\r\nelse\r\nreturn -(BPF_PPC_STACK_SAVE + 16);\r\n}\r\nstatic int bpf_jit_stack_tailcallcnt(struct codegen_context *ctx)\r\n{\r\nreturn bpf_jit_stack_local(ctx) + 8;\r\n}\r\nstatic int bpf_jit_stack_offsetof(struct codegen_context *ctx, int reg)\r\n{\r\nif (reg >= BPF_PPC_NVR_MIN && reg < 32)\r\nreturn (bpf_has_stack_frame(ctx) ? BPF_PPC_STACKFRAME : 0)\r\n- (8 * (32 - reg));\r\npr_err("BPF JIT is asking about unknown registers");\r\nBUG();\r\n}\r\nstatic void bpf_jit_emit_skb_loads(u32 *image, struct codegen_context *ctx)\r\n{\r\nPPC_LWZ(b2p[SKB_HLEN_REG], 3, offsetof(struct sk_buff, len));\r\nPPC_LWZ(b2p[TMP_REG_1], 3, offsetof(struct sk_buff, data_len));\r\nPPC_SUB(b2p[SKB_HLEN_REG], b2p[SKB_HLEN_REG], b2p[TMP_REG_1]);\r\nPPC_BPF_LL(b2p[SKB_DATA_REG], 3, offsetof(struct sk_buff, data));\r\n}\r\nstatic void bpf_jit_build_prologue(u32 *image, struct codegen_context *ctx)\r\n{\r\nint i;\r\nif (ctx->seen & SEEN_TAILCALL) {\r\nPPC_LI(b2p[TMP_REG_1], 0);\r\nPPC_BPF_STL(b2p[TMP_REG_1], 1, -(BPF_PPC_STACK_SAVE + 8));\r\n} else {\r\nPPC_NOP();\r\nPPC_NOP();\r\n}\r\n#define BPF_TAILCALL_PROLOGUE_SIZE 8\r\nif (bpf_has_stack_frame(ctx)) {\r\nif (ctx->seen & SEEN_FUNC) {\r\nEMIT(PPC_INST_MFLR | __PPC_RT(R0));\r\nPPC_BPF_STL(0, 1, PPC_LR_STKOFF);\r\n}\r\nPPC_BPF_STLU(1, 1, -BPF_PPC_STACKFRAME);\r\n}\r\nfor (i = BPF_REG_6; i <= BPF_REG_10; i++)\r\nif (bpf_is_seen_register(ctx, i))\r\nPPC_BPF_STL(b2p[i], 1, bpf_jit_stack_offsetof(ctx, b2p[i]));\r\nif (ctx->seen & SEEN_SKB) {\r\nPPC_BPF_STL(b2p[SKB_HLEN_REG], 1,\r\nbpf_jit_stack_offsetof(ctx, b2p[SKB_HLEN_REG]));\r\nPPC_BPF_STL(b2p[SKB_DATA_REG], 1,\r\nbpf_jit_stack_offsetof(ctx, b2p[SKB_DATA_REG]));\r\nbpf_jit_emit_skb_loads(image, ctx);\r\n}\r\nif (bpf_is_seen_register(ctx, BPF_REG_FP))\r\nPPC_ADDI(b2p[BPF_REG_FP], 1,\r\nSTACK_FRAME_MIN_SIZE + MAX_BPF_STACK);\r\n}\r\nstatic void bpf_jit_emit_common_epilogue(u32 *image, struct codegen_context *ctx)\r\n{\r\nint i;\r\nfor (i = BPF_REG_6; i <= BPF_REG_10; i++)\r\nif (bpf_is_seen_register(ctx, i))\r\nPPC_BPF_LL(b2p[i], 1, bpf_jit_stack_offsetof(ctx, b2p[i]));\r\nif (ctx->seen & SEEN_SKB) {\r\nPPC_BPF_LL(b2p[SKB_HLEN_REG], 1,\r\nbpf_jit_stack_offsetof(ctx, b2p[SKB_HLEN_REG]));\r\nPPC_BPF_LL(b2p[SKB_DATA_REG], 1,\r\nbpf_jit_stack_offsetof(ctx, b2p[SKB_DATA_REG]));\r\n}\r\nif (bpf_has_stack_frame(ctx)) {\r\nPPC_ADDI(1, 1, BPF_PPC_STACKFRAME);\r\nif (ctx->seen & SEEN_FUNC) {\r\nPPC_BPF_LL(0, 1, PPC_LR_STKOFF);\r\nPPC_MTLR(0);\r\n}\r\n}\r\n}\r\nstatic void bpf_jit_build_epilogue(u32 *image, struct codegen_context *ctx)\r\n{\r\nbpf_jit_emit_common_epilogue(image, ctx);\r\nPPC_MR(3, b2p[BPF_REG_0]);\r\nPPC_BLR();\r\n}\r\nstatic void bpf_jit_emit_func_call(u32 *image, struct codegen_context *ctx, u64 func)\r\n{\r\n#ifdef PPC64_ELF_ABI_v1\r\nPPC_LI64(b2p[TMP_REG_2], func);\r\nPPC_BPF_LL(b2p[TMP_REG_1], b2p[TMP_REG_2], 0);\r\nPPC_MTLR(b2p[TMP_REG_1]);\r\nPPC_BPF_LL(2, b2p[TMP_REG_2], 8);\r\n#else\r\nPPC_FUNC_ADDR(12, func);\r\nPPC_MTLR(12);\r\n#endif\r\nPPC_BLRL();\r\n}\r\nstatic void bpf_jit_emit_tail_call(u32 *image, struct codegen_context *ctx, u32 out)\r\n{\r\nint b2p_bpf_array = b2p[BPF_REG_2];\r\nint b2p_index = b2p[BPF_REG_3];\r\nPPC_LWZ(b2p[TMP_REG_1], b2p_bpf_array, offsetof(struct bpf_array, map.max_entries));\r\nPPC_CMPLW(b2p_index, b2p[TMP_REG_1]);\r\nPPC_BCC(COND_GE, out);\r\nPPC_LD(b2p[TMP_REG_1], 1, bpf_jit_stack_tailcallcnt(ctx));\r\nPPC_CMPLWI(b2p[TMP_REG_1], MAX_TAIL_CALL_CNT);\r\nPPC_BCC(COND_GT, out);\r\nPPC_ADDI(b2p[TMP_REG_1], b2p[TMP_REG_1], 1);\r\nPPC_BPF_STL(b2p[TMP_REG_1], 1, bpf_jit_stack_tailcallcnt(ctx));\r\nPPC_MULI(b2p[TMP_REG_1], b2p_index, 8);\r\nPPC_ADD(b2p[TMP_REG_1], b2p[TMP_REG_1], b2p_bpf_array);\r\nPPC_LD(b2p[TMP_REG_1], b2p[TMP_REG_1], offsetof(struct bpf_array, ptrs));\r\nPPC_CMPLDI(b2p[TMP_REG_1], 0);\r\nPPC_BCC(COND_EQ, out);\r\nPPC_LD(b2p[TMP_REG_1], b2p[TMP_REG_1], offsetof(struct bpf_prog, bpf_func));\r\n#ifdef PPC64_ELF_ABI_v1\r\nPPC_ADDI(b2p[TMP_REG_1], b2p[TMP_REG_1],\r\nFUNCTION_DESCR_SIZE + BPF_TAILCALL_PROLOGUE_SIZE);\r\n#else\r\nPPC_ADDI(b2p[TMP_REG_1], b2p[TMP_REG_1], BPF_TAILCALL_PROLOGUE_SIZE);\r\n#endif\r\nPPC_MTCTR(b2p[TMP_REG_1]);\r\nbpf_jit_emit_common_epilogue(image, ctx);\r\nPPC_BCTR();\r\n}\r\nstatic int bpf_jit_build_body(struct bpf_prog *fp, u32 *image,\r\nstruct codegen_context *ctx,\r\nu32 *addrs)\r\n{\r\nconst struct bpf_insn *insn = fp->insnsi;\r\nint flen = fp->len;\r\nint i;\r\nu32 exit_addr = addrs[flen];\r\nfor (i = 0; i < flen; i++) {\r\nu32 code = insn[i].code;\r\nu32 dst_reg = b2p[insn[i].dst_reg];\r\nu32 src_reg = b2p[insn[i].src_reg];\r\ns16 off = insn[i].off;\r\ns32 imm = insn[i].imm;\r\nu64 imm64;\r\nu8 *func;\r\nu32 true_cond;\r\naddrs[i] = ctx->idx * 4;\r\nif (dst_reg >= BPF_PPC_NVR_MIN && dst_reg < 32)\r\nbpf_set_seen_register(ctx, insn[i].dst_reg);\r\nif (src_reg >= BPF_PPC_NVR_MIN && src_reg < 32)\r\nbpf_set_seen_register(ctx, insn[i].src_reg);\r\nswitch (code) {\r\ncase BPF_ALU | BPF_ADD | BPF_X:\r\ncase BPF_ALU64 | BPF_ADD | BPF_X:\r\nPPC_ADD(dst_reg, dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_SUB | BPF_X:\r\ncase BPF_ALU64 | BPF_SUB | BPF_X:\r\nPPC_SUB(dst_reg, dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_ADD | BPF_K:\r\ncase BPF_ALU | BPF_SUB | BPF_K:\r\ncase BPF_ALU64 | BPF_ADD | BPF_K:\r\ncase BPF_ALU64 | BPF_SUB | BPF_K:\r\nif (BPF_OP(code) == BPF_SUB)\r\nimm = -imm;\r\nif (imm) {\r\nif (imm >= -32768 && imm < 32768)\r\nPPC_ADDI(dst_reg, dst_reg, IMM_L(imm));\r\nelse {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_ADD(dst_reg, dst_reg, b2p[TMP_REG_1]);\r\n}\r\n}\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_MUL | BPF_X:\r\ncase BPF_ALU64 | BPF_MUL | BPF_X:\r\nif (BPF_CLASS(code) == BPF_ALU)\r\nPPC_MULW(dst_reg, dst_reg, src_reg);\r\nelse\r\nPPC_MULD(dst_reg, dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_MUL | BPF_K:\r\ncase BPF_ALU64 | BPF_MUL | BPF_K:\r\nif (imm >= -32768 && imm < 32768)\r\nPPC_MULI(dst_reg, dst_reg, IMM_L(imm));\r\nelse {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nif (BPF_CLASS(code) == BPF_ALU)\r\nPPC_MULW(dst_reg, dst_reg,\r\nb2p[TMP_REG_1]);\r\nelse\r\nPPC_MULD(dst_reg, dst_reg,\r\nb2p[TMP_REG_1]);\r\n}\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_DIV | BPF_X:\r\ncase BPF_ALU | BPF_MOD | BPF_X:\r\nPPC_CMPWI(src_reg, 0);\r\nPPC_BCC_SHORT(COND_NE, (ctx->idx * 4) + 12);\r\nPPC_LI(b2p[BPF_REG_0], 0);\r\nPPC_JMP(exit_addr);\r\nif (BPF_OP(code) == BPF_MOD) {\r\nPPC_DIVWU(b2p[TMP_REG_1], dst_reg, src_reg);\r\nPPC_MULW(b2p[TMP_REG_1], src_reg,\r\nb2p[TMP_REG_1]);\r\nPPC_SUB(dst_reg, dst_reg, b2p[TMP_REG_1]);\r\n} else\r\nPPC_DIVWU(dst_reg, dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU64 | BPF_DIV | BPF_X:\r\ncase BPF_ALU64 | BPF_MOD | BPF_X:\r\nPPC_CMPDI(src_reg, 0);\r\nPPC_BCC_SHORT(COND_NE, (ctx->idx * 4) + 12);\r\nPPC_LI(b2p[BPF_REG_0], 0);\r\nPPC_JMP(exit_addr);\r\nif (BPF_OP(code) == BPF_MOD) {\r\nPPC_DIVD(b2p[TMP_REG_1], dst_reg, src_reg);\r\nPPC_MULD(b2p[TMP_REG_1], src_reg,\r\nb2p[TMP_REG_1]);\r\nPPC_SUB(dst_reg, dst_reg, b2p[TMP_REG_1]);\r\n} else\r\nPPC_DIVD(dst_reg, dst_reg, src_reg);\r\nbreak;\r\ncase BPF_ALU | BPF_MOD | BPF_K:\r\ncase BPF_ALU | BPF_DIV | BPF_K:\r\ncase BPF_ALU64 | BPF_MOD | BPF_K:\r\ncase BPF_ALU64 | BPF_DIV | BPF_K:\r\nif (imm == 0)\r\nreturn -EINVAL;\r\nelse if (imm == 1)\r\ngoto bpf_alu32_trunc;\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nswitch (BPF_CLASS(code)) {\r\ncase BPF_ALU:\r\nif (BPF_OP(code) == BPF_MOD) {\r\nPPC_DIVWU(b2p[TMP_REG_2], dst_reg,\r\nb2p[TMP_REG_1]);\r\nPPC_MULW(b2p[TMP_REG_1],\r\nb2p[TMP_REG_1],\r\nb2p[TMP_REG_2]);\r\nPPC_SUB(dst_reg, dst_reg,\r\nb2p[TMP_REG_1]);\r\n} else\r\nPPC_DIVWU(dst_reg, dst_reg,\r\nb2p[TMP_REG_1]);\r\nbreak;\r\ncase BPF_ALU64:\r\nif (BPF_OP(code) == BPF_MOD) {\r\nPPC_DIVD(b2p[TMP_REG_2], dst_reg,\r\nb2p[TMP_REG_1]);\r\nPPC_MULD(b2p[TMP_REG_1],\r\nb2p[TMP_REG_1],\r\nb2p[TMP_REG_2]);\r\nPPC_SUB(dst_reg, dst_reg,\r\nb2p[TMP_REG_1]);\r\n} else\r\nPPC_DIVD(dst_reg, dst_reg,\r\nb2p[TMP_REG_1]);\r\nbreak;\r\n}\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_NEG:\r\ncase BPF_ALU64 | BPF_NEG:\r\nPPC_NEG(dst_reg, dst_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_AND | BPF_X:\r\ncase BPF_ALU64 | BPF_AND | BPF_X:\r\nPPC_AND(dst_reg, dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_AND | BPF_K:\r\ncase BPF_ALU64 | BPF_AND | BPF_K:\r\nif (!IMM_H(imm))\r\nPPC_ANDI(dst_reg, dst_reg, IMM_L(imm));\r\nelse {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_AND(dst_reg, dst_reg, b2p[TMP_REG_1]);\r\n}\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_OR | BPF_X:\r\ncase BPF_ALU64 | BPF_OR | BPF_X:\r\nPPC_OR(dst_reg, dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_OR | BPF_K:\r\ncase BPF_ALU64 | BPF_OR | BPF_K:\r\nif (imm < 0 && BPF_CLASS(code) == BPF_ALU64) {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_OR(dst_reg, dst_reg, b2p[TMP_REG_1]);\r\n} else {\r\nif (IMM_L(imm))\r\nPPC_ORI(dst_reg, dst_reg, IMM_L(imm));\r\nif (IMM_H(imm))\r\nPPC_ORIS(dst_reg, dst_reg, IMM_H(imm));\r\n}\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_XOR | BPF_X:\r\ncase BPF_ALU64 | BPF_XOR | BPF_X:\r\nPPC_XOR(dst_reg, dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_XOR | BPF_K:\r\ncase BPF_ALU64 | BPF_XOR | BPF_K:\r\nif (imm < 0 && BPF_CLASS(code) == BPF_ALU64) {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_XOR(dst_reg, dst_reg, b2p[TMP_REG_1]);\r\n} else {\r\nif (IMM_L(imm))\r\nPPC_XORI(dst_reg, dst_reg, IMM_L(imm));\r\nif (IMM_H(imm))\r\nPPC_XORIS(dst_reg, dst_reg, IMM_H(imm));\r\n}\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_LSH | BPF_X:\r\nPPC_SLW(dst_reg, dst_reg, src_reg);\r\nbreak;\r\ncase BPF_ALU64 | BPF_LSH | BPF_X:\r\nPPC_SLD(dst_reg, dst_reg, src_reg);\r\nbreak;\r\ncase BPF_ALU | BPF_LSH | BPF_K:\r\nPPC_SLWI(dst_reg, dst_reg, imm);\r\nbreak;\r\ncase BPF_ALU64 | BPF_LSH | BPF_K:\r\nif (imm != 0)\r\nPPC_SLDI(dst_reg, dst_reg, imm);\r\nbreak;\r\ncase BPF_ALU | BPF_RSH | BPF_X:\r\nPPC_SRW(dst_reg, dst_reg, src_reg);\r\nbreak;\r\ncase BPF_ALU64 | BPF_RSH | BPF_X:\r\nPPC_SRD(dst_reg, dst_reg, src_reg);\r\nbreak;\r\ncase BPF_ALU | BPF_RSH | BPF_K:\r\nPPC_SRWI(dst_reg, dst_reg, imm);\r\nbreak;\r\ncase BPF_ALU64 | BPF_RSH | BPF_K:\r\nif (imm != 0)\r\nPPC_SRDI(dst_reg, dst_reg, imm);\r\nbreak;\r\ncase BPF_ALU64 | BPF_ARSH | BPF_X:\r\nPPC_SRAD(dst_reg, dst_reg, src_reg);\r\nbreak;\r\ncase BPF_ALU64 | BPF_ARSH | BPF_K:\r\nif (imm != 0)\r\nPPC_SRADI(dst_reg, dst_reg, imm);\r\nbreak;\r\ncase BPF_ALU | BPF_MOV | BPF_X:\r\ncase BPF_ALU64 | BPF_MOV | BPF_X:\r\nPPC_MR(dst_reg, src_reg);\r\ngoto bpf_alu32_trunc;\r\ncase BPF_ALU | BPF_MOV | BPF_K:\r\ncase BPF_ALU64 | BPF_MOV | BPF_K:\r\nPPC_LI32(dst_reg, imm);\r\nif (imm < 0)\r\ngoto bpf_alu32_trunc;\r\nbreak;\r\nbpf_alu32_trunc:\r\nif (BPF_CLASS(code) == BPF_ALU)\r\nPPC_RLWINM(dst_reg, dst_reg, 0, 0, 31);\r\nbreak;\r\ncase BPF_ALU | BPF_END | BPF_FROM_LE:\r\ncase BPF_ALU | BPF_END | BPF_FROM_BE:\r\n#ifdef __BIG_ENDIAN__\r\nif (BPF_SRC(code) == BPF_FROM_BE)\r\ngoto emit_clear;\r\n#else\r\nif (BPF_SRC(code) == BPF_FROM_LE)\r\ngoto emit_clear;\r\n#endif\r\nswitch (imm) {\r\ncase 16:\r\nPPC_RLWINM(b2p[TMP_REG_1], dst_reg, 8, 16, 23);\r\nPPC_RLWIMI(b2p[TMP_REG_1], dst_reg, 24, 24, 31);\r\nPPC_MR(dst_reg, b2p[TMP_REG_1]);\r\nbreak;\r\ncase 32:\r\nPPC_RLWINM(b2p[TMP_REG_1], dst_reg, 8, 0, 31);\r\nPPC_RLWIMI(b2p[TMP_REG_1], dst_reg, 24, 0, 7);\r\nPPC_RLWIMI(b2p[TMP_REG_1], dst_reg, 24, 16, 23);\r\nPPC_MR(dst_reg, b2p[TMP_REG_1]);\r\nbreak;\r\ncase 64:\r\nPPC_STD(dst_reg, 1, bpf_jit_stack_local(ctx));\r\nPPC_ADDI(b2p[TMP_REG_1], 1, bpf_jit_stack_local(ctx));\r\nPPC_LDBRX(dst_reg, 0, b2p[TMP_REG_1]);\r\nbreak;\r\n}\r\nbreak;\r\nemit_clear:\r\nswitch (imm) {\r\ncase 16:\r\nPPC_RLDICL(dst_reg, dst_reg, 0, 48);\r\nbreak;\r\ncase 32:\r\nPPC_RLDICL(dst_reg, dst_reg, 0, 32);\r\nbreak;\r\ncase 64:\r\nbreak;\r\n}\r\nbreak;\r\ncase BPF_STX | BPF_MEM | BPF_B:\r\ncase BPF_ST | BPF_MEM | BPF_B:\r\nif (BPF_CLASS(code) == BPF_ST) {\r\nPPC_LI(b2p[TMP_REG_1], imm);\r\nsrc_reg = b2p[TMP_REG_1];\r\n}\r\nPPC_STB(src_reg, dst_reg, off);\r\nbreak;\r\ncase BPF_STX | BPF_MEM | BPF_H:\r\ncase BPF_ST | BPF_MEM | BPF_H:\r\nif (BPF_CLASS(code) == BPF_ST) {\r\nPPC_LI(b2p[TMP_REG_1], imm);\r\nsrc_reg = b2p[TMP_REG_1];\r\n}\r\nPPC_STH(src_reg, dst_reg, off);\r\nbreak;\r\ncase BPF_STX | BPF_MEM | BPF_W:\r\ncase BPF_ST | BPF_MEM | BPF_W:\r\nif (BPF_CLASS(code) == BPF_ST) {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nsrc_reg = b2p[TMP_REG_1];\r\n}\r\nPPC_STW(src_reg, dst_reg, off);\r\nbreak;\r\ncase BPF_STX | BPF_MEM | BPF_DW:\r\ncase BPF_ST | BPF_MEM | BPF_DW:\r\nif (BPF_CLASS(code) == BPF_ST) {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nsrc_reg = b2p[TMP_REG_1];\r\n}\r\nPPC_STD(src_reg, dst_reg, off);\r\nbreak;\r\ncase BPF_STX | BPF_XADD | BPF_W:\r\nPPC_ADDI(b2p[TMP_REG_1], dst_reg, off);\r\nPPC_ANDI(b2p[TMP_REG_2], b2p[TMP_REG_1], 0x03);\r\nPPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + 12);\r\nPPC_LI(b2p[BPF_REG_0], 0);\r\nPPC_JMP(exit_addr);\r\nPPC_BPF_LWARX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1], 0);\r\nPPC_ADD(b2p[TMP_REG_2], b2p[TMP_REG_2], src_reg);\r\nPPC_BPF_STWCX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1]);\r\nPPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + (7*4));\r\nPPC_BPF_LWARX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1], 0);\r\nPPC_ADD(b2p[TMP_REG_2], b2p[TMP_REG_2], src_reg);\r\nPPC_BPF_STWCX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1]);\r\nPPC_LI(b2p[BPF_REG_0], 0);\r\nPPC_BCC(COND_NE, exit_addr);\r\nbreak;\r\ncase BPF_STX | BPF_XADD | BPF_DW:\r\nPPC_ADDI(b2p[TMP_REG_1], dst_reg, off);\r\nPPC_ANDI(b2p[TMP_REG_2], b2p[TMP_REG_1], 0x07);\r\nPPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + (3*4));\r\nPPC_LI(b2p[BPF_REG_0], 0);\r\nPPC_JMP(exit_addr);\r\nPPC_BPF_LDARX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1], 0);\r\nPPC_ADD(b2p[TMP_REG_2], b2p[TMP_REG_2], src_reg);\r\nPPC_BPF_STDCX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1]);\r\nPPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + (7*4));\r\nPPC_BPF_LDARX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1], 0);\r\nPPC_ADD(b2p[TMP_REG_2], b2p[TMP_REG_2], src_reg);\r\nPPC_BPF_STDCX(b2p[TMP_REG_2], 0, b2p[TMP_REG_1]);\r\nPPC_LI(b2p[BPF_REG_0], 0);\r\nPPC_BCC(COND_NE, exit_addr);\r\nbreak;\r\ncase BPF_LDX | BPF_MEM | BPF_B:\r\nPPC_LBZ(dst_reg, src_reg, off);\r\nbreak;\r\ncase BPF_LDX | BPF_MEM | BPF_H:\r\nPPC_LHZ(dst_reg, src_reg, off);\r\nbreak;\r\ncase BPF_LDX | BPF_MEM | BPF_W:\r\nPPC_LWZ(dst_reg, src_reg, off);\r\nbreak;\r\ncase BPF_LDX | BPF_MEM | BPF_DW:\r\nPPC_LD(dst_reg, src_reg, off);\r\nbreak;\r\ncase BPF_LD | BPF_IMM | BPF_DW:\r\nimm64 = ((u64)(u32) insn[i].imm) |\r\n(((u64)(u32) insn[i+1].imm) << 32);\r\naddrs[++i] = ctx->idx * 4;\r\nPPC_LI64(dst_reg, imm64);\r\nbreak;\r\ncase BPF_JMP | BPF_EXIT:\r\nif (i != flen - 1)\r\nPPC_JMP(exit_addr);\r\nbreak;\r\ncase BPF_JMP | BPF_CALL:\r\nctx->seen |= SEEN_FUNC;\r\nfunc = (u8 *) __bpf_call_base + imm;\r\nif (bpf_helper_changes_pkt_data(func))\r\nPPC_BPF_STL(3, 1, bpf_jit_stack_local(ctx));\r\nbpf_jit_emit_func_call(image, ctx, (u64)func);\r\nPPC_MR(b2p[BPF_REG_0], 3);\r\nif (bpf_helper_changes_pkt_data(func)) {\r\nPPC_BPF_LL(3, 1, bpf_jit_stack_local(ctx));\r\nbpf_jit_emit_skb_loads(image, ctx);\r\n}\r\nbreak;\r\ncase BPF_JMP | BPF_JA:\r\nPPC_JMP(addrs[i + 1 + off]);\r\nbreak;\r\ncase BPF_JMP | BPF_JGT | BPF_K:\r\ncase BPF_JMP | BPF_JGT | BPF_X:\r\ncase BPF_JMP | BPF_JSGT | BPF_K:\r\ncase BPF_JMP | BPF_JSGT | BPF_X:\r\ntrue_cond = COND_GT;\r\ngoto cond_branch;\r\ncase BPF_JMP | BPF_JGE | BPF_K:\r\ncase BPF_JMP | BPF_JGE | BPF_X:\r\ncase BPF_JMP | BPF_JSGE | BPF_K:\r\ncase BPF_JMP | BPF_JSGE | BPF_X:\r\ntrue_cond = COND_GE;\r\ngoto cond_branch;\r\ncase BPF_JMP | BPF_JEQ | BPF_K:\r\ncase BPF_JMP | BPF_JEQ | BPF_X:\r\ntrue_cond = COND_EQ;\r\ngoto cond_branch;\r\ncase BPF_JMP | BPF_JNE | BPF_K:\r\ncase BPF_JMP | BPF_JNE | BPF_X:\r\ntrue_cond = COND_NE;\r\ngoto cond_branch;\r\ncase BPF_JMP | BPF_JSET | BPF_K:\r\ncase BPF_JMP | BPF_JSET | BPF_X:\r\ntrue_cond = COND_NE;\r\ncond_branch:\r\nswitch (code) {\r\ncase BPF_JMP | BPF_JGT | BPF_X:\r\ncase BPF_JMP | BPF_JGE | BPF_X:\r\ncase BPF_JMP | BPF_JEQ | BPF_X:\r\ncase BPF_JMP | BPF_JNE | BPF_X:\r\nPPC_CMPLD(dst_reg, src_reg);\r\nbreak;\r\ncase BPF_JMP | BPF_JSGT | BPF_X:\r\ncase BPF_JMP | BPF_JSGE | BPF_X:\r\nPPC_CMPD(dst_reg, src_reg);\r\nbreak;\r\ncase BPF_JMP | BPF_JSET | BPF_X:\r\nPPC_AND_DOT(b2p[TMP_REG_1], dst_reg, src_reg);\r\nbreak;\r\ncase BPF_JMP | BPF_JNE | BPF_K:\r\ncase BPF_JMP | BPF_JEQ | BPF_K:\r\ncase BPF_JMP | BPF_JGT | BPF_K:\r\ncase BPF_JMP | BPF_JGE | BPF_K:\r\nif (imm >= 0 && imm < 32768)\r\nPPC_CMPLDI(dst_reg, imm);\r\nelse {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_CMPLD(dst_reg, b2p[TMP_REG_1]);\r\n}\r\nbreak;\r\ncase BPF_JMP | BPF_JSGT | BPF_K:\r\ncase BPF_JMP | BPF_JSGE | BPF_K:\r\nif (imm >= -32768 && imm < 32768)\r\nPPC_CMPDI(dst_reg, imm);\r\nelse {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_CMPD(dst_reg, b2p[TMP_REG_1]);\r\n}\r\nbreak;\r\ncase BPF_JMP | BPF_JSET | BPF_K:\r\nif (imm >= 0 && imm < 32768)\r\nPPC_ANDI(b2p[TMP_REG_1], dst_reg, imm);\r\nelse {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_AND_DOT(b2p[TMP_REG_1], dst_reg,\r\nb2p[TMP_REG_1]);\r\n}\r\nbreak;\r\n}\r\nPPC_BCC(true_cond, addrs[i + 1 + off]);\r\nbreak;\r\ncase BPF_LD | BPF_W | BPF_ABS:\r\nfunc = (u8 *)CHOOSE_LOAD_FUNC(imm, sk_load_word);\r\ngoto common_load_abs;\r\ncase BPF_LD | BPF_H | BPF_ABS:\r\nfunc = (u8 *)CHOOSE_LOAD_FUNC(imm, sk_load_half);\r\ngoto common_load_abs;\r\ncase BPF_LD | BPF_B | BPF_ABS:\r\nfunc = (u8 *)CHOOSE_LOAD_FUNC(imm, sk_load_byte);\r\ncommon_load_abs:\r\nPPC_LI32(4, imm);\r\ngoto common_load;\r\ncase BPF_LD | BPF_W | BPF_IND:\r\nfunc = (u8 *)sk_load_word;\r\ngoto common_load_ind;\r\ncase BPF_LD | BPF_H | BPF_IND:\r\nfunc = (u8 *)sk_load_half;\r\ngoto common_load_ind;\r\ncase BPF_LD | BPF_B | BPF_IND:\r\nfunc = (u8 *)sk_load_byte;\r\ncommon_load_ind:\r\nPPC_EXTSW(4, src_reg);\r\nif (imm) {\r\nif (imm >= -32768 && imm < 32768)\r\nPPC_ADDI(4, 4, IMM_L(imm));\r\nelse {\r\nPPC_LI32(b2p[TMP_REG_1], imm);\r\nPPC_ADD(4, 4, b2p[TMP_REG_1]);\r\n}\r\n}\r\ncommon_load:\r\nctx->seen |= SEEN_SKB;\r\nctx->seen |= SEEN_FUNC;\r\nbpf_jit_emit_func_call(image, ctx, (u64)func);\r\nPPC_BCC(COND_LT, exit_addr);\r\nbreak;\r\ncase BPF_JMP | BPF_CALL | BPF_X:\r\nctx->seen |= SEEN_TAILCALL;\r\nbpf_jit_emit_tail_call(image, ctx, addrs[i + 1]);\r\nbreak;\r\ndefault:\r\npr_err_ratelimited("eBPF filter opcode %04x (@%d) unsupported\n",\r\ncode, i);\r\nreturn -ENOTSUPP;\r\n}\r\n}\r\naddrs[i] = ctx->idx * 4;\r\nreturn 0;\r\n}\r\nstruct bpf_prog *bpf_int_jit_compile(struct bpf_prog *fp)\r\n{\r\nu32 proglen;\r\nu32 alloclen;\r\nu8 *image = NULL;\r\nu32 *code_base;\r\nu32 *addrs;\r\nstruct codegen_context cgctx;\r\nint pass;\r\nint flen;\r\nstruct bpf_binary_header *bpf_hdr;\r\nstruct bpf_prog *org_fp = fp;\r\nstruct bpf_prog *tmp_fp;\r\nbool bpf_blinded = false;\r\nif (!bpf_jit_enable)\r\nreturn org_fp;\r\ntmp_fp = bpf_jit_blind_constants(org_fp);\r\nif (IS_ERR(tmp_fp))\r\nreturn org_fp;\r\nif (tmp_fp != org_fp) {\r\nbpf_blinded = true;\r\nfp = tmp_fp;\r\n}\r\nflen = fp->len;\r\naddrs = kzalloc((flen+1) * sizeof(*addrs), GFP_KERNEL);\r\nif (addrs == NULL) {\r\nfp = org_fp;\r\ngoto out;\r\n}\r\nmemset(&cgctx, 0, sizeof(struct codegen_context));\r\nif (bpf_jit_build_body(fp, 0, &cgctx, addrs)) {\r\nfp = org_fp;\r\ngoto out;\r\n}\r\nbpf_jit_build_prologue(0, &cgctx);\r\nbpf_jit_build_epilogue(0, &cgctx);\r\nproglen = cgctx.idx * 4;\r\nalloclen = proglen + FUNCTION_DESCR_SIZE;\r\nbpf_hdr = bpf_jit_binary_alloc(alloclen, &image, 4,\r\nbpf_jit_fill_ill_insns);\r\nif (!bpf_hdr) {\r\nfp = org_fp;\r\ngoto out;\r\n}\r\ncode_base = (u32 *)(image + FUNCTION_DESCR_SIZE);\r\nfor (pass = 1; pass < 3; pass++) {\r\ncgctx.idx = 0;\r\nbpf_jit_build_prologue(code_base, &cgctx);\r\nbpf_jit_build_body(fp, code_base, &cgctx, addrs);\r\nbpf_jit_build_epilogue(code_base, &cgctx);\r\nif (bpf_jit_enable > 1)\r\npr_info("Pass %d: shrink = %d, seen = 0x%x\n", pass,\r\nproglen - (cgctx.idx * 4), cgctx.seen);\r\n}\r\nif (bpf_jit_enable > 1)\r\nbpf_jit_dump(flen, proglen, pass, code_base);\r\n#ifdef PPC64_ELF_ABI_v1\r\n((u64 *)image)[0] = (u64)code_base;\r\n((u64 *)image)[1] = local_paca->kernel_toc;\r\n#endif\r\nfp->bpf_func = (void *)image;\r\nfp->jited = 1;\r\nbpf_flush_icache(bpf_hdr, (u8 *)bpf_hdr + (bpf_hdr->pages * PAGE_SIZE));\r\nout:\r\nkfree(addrs);\r\nif (bpf_blinded)\r\nbpf_jit_prog_release_other(fp, fp == org_fp ? tmp_fp : org_fp);\r\nreturn fp;\r\n}\r\nvoid bpf_jit_free(struct bpf_prog *fp)\r\n{\r\nunsigned long addr = (unsigned long)fp->bpf_func & PAGE_MASK;\r\nstruct bpf_binary_header *bpf_hdr = (void *)addr;\r\nif (fp->jited)\r\nbpf_jit_binary_free(bpf_hdr);\r\nbpf_prog_unlock_free(fp);\r\n}
