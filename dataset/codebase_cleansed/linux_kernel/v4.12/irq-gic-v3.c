static inline unsigned int gic_irq(struct irq_data *d)\r\n{\r\nreturn d->hwirq;\r\n}\r\nstatic inline int gic_irq_in_rdist(struct irq_data *d)\r\n{\r\nreturn gic_irq(d) < 32;\r\n}\r\nstatic inline void __iomem *gic_dist_base(struct irq_data *d)\r\n{\r\nif (gic_irq_in_rdist(d))\r\nreturn gic_data_rdist_sgi_base();\r\nif (d->hwirq <= 1023)\r\nreturn gic_data.dist_base;\r\nreturn NULL;\r\n}\r\nstatic void gic_do_wait_for_rwp(void __iomem *base)\r\n{\r\nu32 count = 1000000;\r\nwhile (readl_relaxed(base + GICD_CTLR) & GICD_CTLR_RWP) {\r\ncount--;\r\nif (!count) {\r\npr_err_ratelimited("RWP timeout, gone fishing\n");\r\nreturn;\r\n}\r\ncpu_relax();\r\nudelay(1);\r\n};\r\n}\r\nstatic void gic_dist_wait_for_rwp(void)\r\n{\r\ngic_do_wait_for_rwp(gic_data.dist_base);\r\n}\r\nstatic void gic_redist_wait_for_rwp(void)\r\n{\r\ngic_do_wait_for_rwp(gic_data_rdist_rd_base());\r\n}\r\nstatic u64 __maybe_unused gic_read_iar(void)\r\n{\r\nif (cpus_have_const_cap(ARM64_WORKAROUND_CAVIUM_23154))\r\nreturn gic_read_iar_cavium_thunderx();\r\nelse\r\nreturn gic_read_iar_common();\r\n}\r\nstatic void gic_enable_redist(bool enable)\r\n{\r\nvoid __iomem *rbase;\r\nu32 count = 1000000;\r\nu32 val;\r\nrbase = gic_data_rdist_rd_base();\r\nval = readl_relaxed(rbase + GICR_WAKER);\r\nif (enable)\r\nval &= ~GICR_WAKER_ProcessorSleep;\r\nelse\r\nval |= GICR_WAKER_ProcessorSleep;\r\nwritel_relaxed(val, rbase + GICR_WAKER);\r\nif (!enable) {\r\nval = readl_relaxed(rbase + GICR_WAKER);\r\nif (!(val & GICR_WAKER_ProcessorSleep))\r\nreturn;\r\n}\r\nwhile (--count) {\r\nval = readl_relaxed(rbase + GICR_WAKER);\r\nif (enable ^ (bool)(val & GICR_WAKER_ChildrenAsleep))\r\nbreak;\r\ncpu_relax();\r\nudelay(1);\r\n};\r\nif (!count)\r\npr_err_ratelimited("redistributor failed to %s...\n",\r\nenable ? "wakeup" : "sleep");\r\n}\r\nstatic int gic_peek_irq(struct irq_data *d, u32 offset)\r\n{\r\nu32 mask = 1 << (gic_irq(d) % 32);\r\nvoid __iomem *base;\r\nif (gic_irq_in_rdist(d))\r\nbase = gic_data_rdist_sgi_base();\r\nelse\r\nbase = gic_data.dist_base;\r\nreturn !!(readl_relaxed(base + offset + (gic_irq(d) / 32) * 4) & mask);\r\n}\r\nstatic void gic_poke_irq(struct irq_data *d, u32 offset)\r\n{\r\nu32 mask = 1 << (gic_irq(d) % 32);\r\nvoid (*rwp_wait)(void);\r\nvoid __iomem *base;\r\nif (gic_irq_in_rdist(d)) {\r\nbase = gic_data_rdist_sgi_base();\r\nrwp_wait = gic_redist_wait_for_rwp;\r\n} else {\r\nbase = gic_data.dist_base;\r\nrwp_wait = gic_dist_wait_for_rwp;\r\n}\r\nwritel_relaxed(mask, base + offset + (gic_irq(d) / 32) * 4);\r\nrwp_wait();\r\n}\r\nstatic void gic_mask_irq(struct irq_data *d)\r\n{\r\ngic_poke_irq(d, GICD_ICENABLER);\r\n}\r\nstatic void gic_eoimode1_mask_irq(struct irq_data *d)\r\n{\r\ngic_mask_irq(d);\r\nif (irqd_is_forwarded_to_vcpu(d))\r\ngic_poke_irq(d, GICD_ICACTIVER);\r\n}\r\nstatic void gic_unmask_irq(struct irq_data *d)\r\n{\r\ngic_poke_irq(d, GICD_ISENABLER);\r\n}\r\nstatic int gic_irq_set_irqchip_state(struct irq_data *d,\r\nenum irqchip_irq_state which, bool val)\r\n{\r\nu32 reg;\r\nif (d->hwirq >= gic_data.irq_nr)\r\nreturn -EINVAL;\r\nswitch (which) {\r\ncase IRQCHIP_STATE_PENDING:\r\nreg = val ? GICD_ISPENDR : GICD_ICPENDR;\r\nbreak;\r\ncase IRQCHIP_STATE_ACTIVE:\r\nreg = val ? GICD_ISACTIVER : GICD_ICACTIVER;\r\nbreak;\r\ncase IRQCHIP_STATE_MASKED:\r\nreg = val ? GICD_ICENABLER : GICD_ISENABLER;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ngic_poke_irq(d, reg);\r\nreturn 0;\r\n}\r\nstatic int gic_irq_get_irqchip_state(struct irq_data *d,\r\nenum irqchip_irq_state which, bool *val)\r\n{\r\nif (d->hwirq >= gic_data.irq_nr)\r\nreturn -EINVAL;\r\nswitch (which) {\r\ncase IRQCHIP_STATE_PENDING:\r\n*val = gic_peek_irq(d, GICD_ISPENDR);\r\nbreak;\r\ncase IRQCHIP_STATE_ACTIVE:\r\n*val = gic_peek_irq(d, GICD_ISACTIVER);\r\nbreak;\r\ncase IRQCHIP_STATE_MASKED:\r\n*val = !gic_peek_irq(d, GICD_ISENABLER);\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void gic_eoi_irq(struct irq_data *d)\r\n{\r\ngic_write_eoir(gic_irq(d));\r\n}\r\nstatic void gic_eoimode1_eoi_irq(struct irq_data *d)\r\n{\r\nif (gic_irq(d) >= 8192 || irqd_is_forwarded_to_vcpu(d))\r\nreturn;\r\ngic_write_dir(gic_irq(d));\r\n}\r\nstatic int gic_set_type(struct irq_data *d, unsigned int type)\r\n{\r\nunsigned int irq = gic_irq(d);\r\nvoid (*rwp_wait)(void);\r\nvoid __iomem *base;\r\nif (irq < 16)\r\nreturn -EINVAL;\r\nif (irq >= 32 && type != IRQ_TYPE_LEVEL_HIGH &&\r\ntype != IRQ_TYPE_EDGE_RISING)\r\nreturn -EINVAL;\r\nif (gic_irq_in_rdist(d)) {\r\nbase = gic_data_rdist_sgi_base();\r\nrwp_wait = gic_redist_wait_for_rwp;\r\n} else {\r\nbase = gic_data.dist_base;\r\nrwp_wait = gic_dist_wait_for_rwp;\r\n}\r\nreturn gic_configure_irq(irq, type, base, rwp_wait);\r\n}\r\nstatic int gic_irq_set_vcpu_affinity(struct irq_data *d, void *vcpu)\r\n{\r\nif (vcpu)\r\nirqd_set_forwarded_to_vcpu(d);\r\nelse\r\nirqd_clr_forwarded_to_vcpu(d);\r\nreturn 0;\r\n}\r\nstatic u64 gic_mpidr_to_affinity(unsigned long mpidr)\r\n{\r\nu64 aff;\r\naff = ((u64)MPIDR_AFFINITY_LEVEL(mpidr, 3) << 32 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 2) << 16 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 1) << 8 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 0));\r\nreturn aff;\r\n}\r\nstatic asmlinkage void __exception_irq_entry gic_handle_irq(struct pt_regs *regs)\r\n{\r\nu32 irqnr;\r\ndo {\r\nirqnr = gic_read_iar();\r\nif (likely(irqnr > 15 && irqnr < 1020) || irqnr >= 8192) {\r\nint err;\r\nif (static_key_true(&supports_deactivate))\r\ngic_write_eoir(irqnr);\r\nerr = handle_domain_irq(gic_data.domain, irqnr, regs);\r\nif (err) {\r\nWARN_ONCE(true, "Unexpected interrupt received!\n");\r\nif (static_key_true(&supports_deactivate)) {\r\nif (irqnr < 8192)\r\ngic_write_dir(irqnr);\r\n} else {\r\ngic_write_eoir(irqnr);\r\n}\r\n}\r\ncontinue;\r\n}\r\nif (irqnr < 16) {\r\ngic_write_eoir(irqnr);\r\nif (static_key_true(&supports_deactivate))\r\ngic_write_dir(irqnr);\r\n#ifdef CONFIG_SMP\r\nhandle_IPI(irqnr, regs);\r\n#else\r\nWARN_ONCE(true, "Unexpected SGI received!\n");\r\n#endif\r\ncontinue;\r\n}\r\n} while (irqnr != ICC_IAR1_EL1_SPURIOUS);\r\n}\r\nstatic void __init gic_dist_init(void)\r\n{\r\nunsigned int i;\r\nu64 affinity;\r\nvoid __iomem *base = gic_data.dist_base;\r\nwritel_relaxed(0, base + GICD_CTLR);\r\ngic_dist_wait_for_rwp();\r\nfor (i = 32; i < gic_data.irq_nr; i += 32)\r\nwritel_relaxed(~0, base + GICD_IGROUPR + i / 8);\r\ngic_dist_config(base, gic_data.irq_nr, gic_dist_wait_for_rwp);\r\nwritel_relaxed(GICD_CTLR_ARE_NS | GICD_CTLR_ENABLE_G1A | GICD_CTLR_ENABLE_G1,\r\nbase + GICD_CTLR);\r\naffinity = gic_mpidr_to_affinity(cpu_logical_map(smp_processor_id()));\r\nfor (i = 32; i < gic_data.irq_nr; i++)\r\ngic_write_irouter(affinity, base + GICD_IROUTER + i * 8);\r\n}\r\nstatic int gic_populate_rdist(void)\r\n{\r\nunsigned long mpidr = cpu_logical_map(smp_processor_id());\r\nu64 typer;\r\nu32 aff;\r\nint i;\r\naff = (MPIDR_AFFINITY_LEVEL(mpidr, 3) << 24 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 2) << 16 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 1) << 8 |\r\nMPIDR_AFFINITY_LEVEL(mpidr, 0));\r\nfor (i = 0; i < gic_data.nr_redist_regions; i++) {\r\nvoid __iomem *ptr = gic_data.redist_regions[i].redist_base;\r\nu32 reg;\r\nreg = readl_relaxed(ptr + GICR_PIDR2) & GIC_PIDR2_ARCH_MASK;\r\nif (reg != GIC_PIDR2_ARCH_GICv3 &&\r\nreg != GIC_PIDR2_ARCH_GICv4) {\r\npr_warn("No redistributor present @%p\n", ptr);\r\nbreak;\r\n}\r\ndo {\r\ntyper = gic_read_typer(ptr + GICR_TYPER);\r\nif ((typer >> 32) == aff) {\r\nu64 offset = ptr - gic_data.redist_regions[i].redist_base;\r\ngic_data_rdist_rd_base() = ptr;\r\ngic_data_rdist()->phys_base = gic_data.redist_regions[i].phys_base + offset;\r\npr_info("CPU%d: found redistributor %lx region %d:%pa\n",\r\nsmp_processor_id(), mpidr, i,\r\n&gic_data_rdist()->phys_base);\r\nreturn 0;\r\n}\r\nif (gic_data.redist_regions[i].single_redist)\r\nbreak;\r\nif (gic_data.redist_stride) {\r\nptr += gic_data.redist_stride;\r\n} else {\r\nptr += SZ_64K * 2;\r\nif (typer & GICR_TYPER_VLPIS)\r\nptr += SZ_64K * 2;\r\n}\r\n} while (!(typer & GICR_TYPER_LAST));\r\n}\r\nWARN(true, "CPU%d: mpidr %lx has no re-distributor!\n",\r\nsmp_processor_id(), mpidr);\r\nreturn -ENODEV;\r\n}\r\nstatic void gic_cpu_sys_reg_init(void)\r\n{\r\nif (!gic_enable_sre())\r\npr_err("GIC: unable to set SRE (disabled at EL2), panic ahead\n");\r\ngic_write_pmr(DEFAULT_PMR_VALUE);\r\ngic_write_bpr1(0);\r\nif (static_key_true(&supports_deactivate)) {\r\ngic_write_ctlr(ICC_CTLR_EL1_EOImode_drop);\r\n} else {\r\ngic_write_ctlr(ICC_CTLR_EL1_EOImode_drop_dir);\r\n}\r\ngic_write_grpen1(1);\r\n}\r\nstatic int gic_dist_supports_lpis(void)\r\n{\r\nreturn !!(readl_relaxed(gic_data.dist_base + GICD_TYPER) & GICD_TYPER_LPIS);\r\n}\r\nstatic void gic_cpu_init(void)\r\n{\r\nvoid __iomem *rbase;\r\nif (gic_populate_rdist())\r\nreturn;\r\ngic_enable_redist(true);\r\nrbase = gic_data_rdist_sgi_base();\r\nwritel_relaxed(~0, rbase + GICR_IGROUPR0);\r\ngic_cpu_config(rbase, gic_redist_wait_for_rwp);\r\nif (IS_ENABLED(CONFIG_ARM_GIC_V3_ITS) && gic_dist_supports_lpis())\r\nits_cpu_init();\r\ngic_cpu_sys_reg_init();\r\n}\r\nstatic int gic_starting_cpu(unsigned int cpu)\r\n{\r\ngic_cpu_init();\r\nreturn 0;\r\n}\r\nstatic u16 gic_compute_target_list(int *base_cpu, const struct cpumask *mask,\r\nunsigned long cluster_id)\r\n{\r\nint next_cpu, cpu = *base_cpu;\r\nunsigned long mpidr = cpu_logical_map(cpu);\r\nu16 tlist = 0;\r\nwhile (cpu < nr_cpu_ids) {\r\nif (WARN_ON((mpidr & 0xff) >= 16))\r\ngoto out;\r\ntlist |= 1 << (mpidr & 0xf);\r\nnext_cpu = cpumask_next(cpu, mask);\r\nif (next_cpu >= nr_cpu_ids)\r\ngoto out;\r\ncpu = next_cpu;\r\nmpidr = cpu_logical_map(cpu);\r\nif (cluster_id != (mpidr & ~0xffUL)) {\r\ncpu--;\r\ngoto out;\r\n}\r\n}\r\nout:\r\n*base_cpu = cpu;\r\nreturn tlist;\r\n}\r\nstatic void gic_send_sgi(u64 cluster_id, u16 tlist, unsigned int irq)\r\n{\r\nu64 val;\r\nval = (MPIDR_TO_SGI_AFFINITY(cluster_id, 3) |\r\nMPIDR_TO_SGI_AFFINITY(cluster_id, 2) |\r\nirq << ICC_SGI1R_SGI_ID_SHIFT |\r\nMPIDR_TO_SGI_AFFINITY(cluster_id, 1) |\r\ntlist << ICC_SGI1R_TARGET_LIST_SHIFT);\r\npr_debug("CPU%d: ICC_SGI1R_EL1 %llx\n", smp_processor_id(), val);\r\ngic_write_sgi1r(val);\r\n}\r\nstatic void gic_raise_softirq(const struct cpumask *mask, unsigned int irq)\r\n{\r\nint cpu;\r\nif (WARN_ON(irq >= 16))\r\nreturn;\r\nsmp_wmb();\r\nfor_each_cpu(cpu, mask) {\r\nunsigned long cluster_id = cpu_logical_map(cpu) & ~0xffUL;\r\nu16 tlist;\r\ntlist = gic_compute_target_list(&cpu, mask, cluster_id);\r\ngic_send_sgi(cluster_id, tlist, irq);\r\n}\r\nisb();\r\n}\r\nstatic void gic_smp_init(void)\r\n{\r\nset_smp_cross_call(gic_raise_softirq);\r\ncpuhp_setup_state_nocalls(CPUHP_AP_IRQ_GIC_STARTING,\r\n"irqchip/arm/gicv3:starting",\r\ngic_starting_cpu, NULL);\r\n}\r\nstatic int gic_set_affinity(struct irq_data *d, const struct cpumask *mask_val,\r\nbool force)\r\n{\r\nunsigned int cpu = cpumask_any_and(mask_val, cpu_online_mask);\r\nvoid __iomem *reg;\r\nint enabled;\r\nu64 val;\r\nif (gic_irq_in_rdist(d))\r\nreturn -EINVAL;\r\nenabled = gic_peek_irq(d, GICD_ISENABLER);\r\nif (enabled)\r\ngic_mask_irq(d);\r\nreg = gic_dist_base(d) + GICD_IROUTER + (gic_irq(d) * 8);\r\nval = gic_mpidr_to_affinity(cpu_logical_map(cpu));\r\ngic_write_irouter(val, reg);\r\nif (enabled)\r\ngic_unmask_irq(d);\r\nelse\r\ngic_dist_wait_for_rwp();\r\nreturn IRQ_SET_MASK_OK_DONE;\r\n}\r\nstatic bool gic_dist_security_disabled(void)\r\n{\r\nreturn readl_relaxed(gic_data.dist_base + GICD_CTLR) & GICD_CTLR_DS;\r\n}\r\nstatic int gic_cpu_pm_notifier(struct notifier_block *self,\r\nunsigned long cmd, void *v)\r\n{\r\nif (cmd == CPU_PM_EXIT) {\r\nif (gic_dist_security_disabled())\r\ngic_enable_redist(true);\r\ngic_cpu_sys_reg_init();\r\n} else if (cmd == CPU_PM_ENTER && gic_dist_security_disabled()) {\r\ngic_write_grpen1(0);\r\ngic_enable_redist(false);\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic void gic_cpu_pm_init(void)\r\n{\r\ncpu_pm_register_notifier(&gic_cpu_pm_notifier_block);\r\n}\r\nstatic inline void gic_cpu_pm_init(void) { }\r\nstatic int gic_irq_domain_map(struct irq_domain *d, unsigned int irq,\r\nirq_hw_number_t hw)\r\n{\r\nstruct irq_chip *chip = &gic_chip;\r\nif (static_key_true(&supports_deactivate))\r\nchip = &gic_eoimode1_chip;\r\nif (hw < 16)\r\nreturn -EPERM;\r\nif (hw >= gic_data.irq_nr && hw < 8192)\r\nreturn -EPERM;\r\nif (hw >= GIC_ID_NR)\r\nreturn -EPERM;\r\nif (hw < 32) {\r\nirq_set_percpu_devid(irq);\r\nirq_domain_set_info(d, irq, hw, chip, d->host_data,\r\nhandle_percpu_devid_irq, NULL, NULL);\r\nirq_set_status_flags(irq, IRQ_NOAUTOEN);\r\n}\r\nif (hw >= 32 && hw < gic_data.irq_nr) {\r\nirq_domain_set_info(d, irq, hw, chip, d->host_data,\r\nhandle_fasteoi_irq, NULL, NULL);\r\nirq_set_probe(irq);\r\n}\r\nif (hw >= 8192 && hw < GIC_ID_NR) {\r\nif (!gic_dist_supports_lpis())\r\nreturn -EPERM;\r\nirq_domain_set_info(d, irq, hw, chip, d->host_data,\r\nhandle_fasteoi_irq, NULL, NULL);\r\n}\r\nreturn 0;\r\n}\r\nstatic int gic_irq_domain_translate(struct irq_domain *d,\r\nstruct irq_fwspec *fwspec,\r\nunsigned long *hwirq,\r\nunsigned int *type)\r\n{\r\nif (is_of_node(fwspec->fwnode)) {\r\nif (fwspec->param_count < 3)\r\nreturn -EINVAL;\r\nswitch (fwspec->param[0]) {\r\ncase 0:\r\n*hwirq = fwspec->param[1] + 32;\r\nbreak;\r\ncase 1:\r\n*hwirq = fwspec->param[1] + 16;\r\nbreak;\r\ncase GIC_IRQ_TYPE_LPI:\r\n*hwirq = fwspec->param[1];\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n*type = fwspec->param[2] & IRQ_TYPE_SENSE_MASK;\r\nreturn 0;\r\n}\r\nif (is_fwnode_irqchip(fwspec->fwnode)) {\r\nif(fwspec->param_count != 2)\r\nreturn -EINVAL;\r\n*hwirq = fwspec->param[0];\r\n*type = fwspec->param[1];\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int gic_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,\r\nunsigned int nr_irqs, void *arg)\r\n{\r\nint i, ret;\r\nirq_hw_number_t hwirq;\r\nunsigned int type = IRQ_TYPE_NONE;\r\nstruct irq_fwspec *fwspec = arg;\r\nret = gic_irq_domain_translate(domain, fwspec, &hwirq, &type);\r\nif (ret)\r\nreturn ret;\r\nfor (i = 0; i < nr_irqs; i++)\r\ngic_irq_domain_map(domain, virq + i, hwirq + i);\r\nreturn 0;\r\n}\r\nstatic void gic_irq_domain_free(struct irq_domain *domain, unsigned int virq,\r\nunsigned int nr_irqs)\r\n{\r\nint i;\r\nfor (i = 0; i < nr_irqs; i++) {\r\nstruct irq_data *d = irq_domain_get_irq_data(domain, virq + i);\r\nirq_set_handler(virq + i, NULL);\r\nirq_domain_reset_irq_data(d);\r\n}\r\n}\r\nstatic int gic_irq_domain_select(struct irq_domain *d,\r\nstruct irq_fwspec *fwspec,\r\nenum irq_domain_bus_token bus_token)\r\n{\r\nif (fwspec->fwnode != d->fwnode)\r\nreturn 0;\r\nif (!is_of_node(fwspec->fwnode))\r\nreturn 1;\r\nif (fwspec->param_count >= 4 &&\r\nfwspec->param[0] == 1 && fwspec->param[3] != 0)\r\nreturn d == partition_get_domain(gic_data.ppi_descs[fwspec->param[1]]);\r\nreturn d == gic_data.domain;\r\n}\r\nstatic int partition_domain_translate(struct irq_domain *d,\r\nstruct irq_fwspec *fwspec,\r\nunsigned long *hwirq,\r\nunsigned int *type)\r\n{\r\nstruct device_node *np;\r\nint ret;\r\nnp = of_find_node_by_phandle(fwspec->param[3]);\r\nif (WARN_ON(!np))\r\nreturn -EINVAL;\r\nret = partition_translate_id(gic_data.ppi_descs[fwspec->param[1]],\r\nof_node_to_fwnode(np));\r\nif (ret < 0)\r\nreturn ret;\r\n*hwirq = ret;\r\n*type = fwspec->param[2] & IRQ_TYPE_SENSE_MASK;\r\nreturn 0;\r\n}\r\nstatic int __init gic_init_bases(void __iomem *dist_base,\r\nstruct redist_region *rdist_regs,\r\nu32 nr_redist_regions,\r\nu64 redist_stride,\r\nstruct fwnode_handle *handle)\r\n{\r\nu32 typer;\r\nint gic_irqs;\r\nint err;\r\nif (!is_hyp_mode_available())\r\nstatic_key_slow_dec(&supports_deactivate);\r\nif (static_key_true(&supports_deactivate))\r\npr_info("GIC: Using split EOI/Deactivate mode\n");\r\ngic_data.fwnode = handle;\r\ngic_data.dist_base = dist_base;\r\ngic_data.redist_regions = rdist_regs;\r\ngic_data.nr_redist_regions = nr_redist_regions;\r\ngic_data.redist_stride = redist_stride;\r\ntyper = readl_relaxed(gic_data.dist_base + GICD_TYPER);\r\ngic_data.rdists.id_bits = GICD_TYPER_ID_BITS(typer);\r\ngic_irqs = GICD_TYPER_IRQS(typer);\r\nif (gic_irqs > 1020)\r\ngic_irqs = 1020;\r\ngic_data.irq_nr = gic_irqs;\r\ngic_data.domain = irq_domain_create_tree(handle, &gic_irq_domain_ops,\r\n&gic_data);\r\ngic_data.rdists.rdist = alloc_percpu(typeof(*gic_data.rdists.rdist));\r\nif (WARN_ON(!gic_data.domain) || WARN_ON(!gic_data.rdists.rdist)) {\r\nerr = -ENOMEM;\r\ngoto out_free;\r\n}\r\nset_handle_irq(gic_handle_irq);\r\nif (IS_ENABLED(CONFIG_ARM_GIC_V3_ITS) && gic_dist_supports_lpis())\r\nits_init(handle, &gic_data.rdists, gic_data.domain);\r\ngic_smp_init();\r\ngic_dist_init();\r\ngic_cpu_init();\r\ngic_cpu_pm_init();\r\nreturn 0;\r\nout_free:\r\nif (gic_data.domain)\r\nirq_domain_remove(gic_data.domain);\r\nfree_percpu(gic_data.rdists.rdist);\r\nreturn err;\r\n}\r\nstatic int __init gic_validate_dist_version(void __iomem *dist_base)\r\n{\r\nu32 reg = readl_relaxed(dist_base + GICD_PIDR2) & GIC_PIDR2_ARCH_MASK;\r\nif (reg != GIC_PIDR2_ARCH_GICv3 && reg != GIC_PIDR2_ARCH_GICv4)\r\nreturn -ENODEV;\r\nreturn 0;\r\n}\r\nstatic int get_cpu_number(struct device_node *dn)\r\n{\r\nconst __be32 *cell;\r\nu64 hwid;\r\nint i;\r\ncell = of_get_property(dn, "reg", NULL);\r\nif (!cell)\r\nreturn -1;\r\nhwid = of_read_number(cell, of_n_addr_cells(dn));\r\nif (hwid & ~MPIDR_HWID_BITMASK)\r\nreturn -1;\r\nfor (i = 0; i < num_possible_cpus(); i++)\r\nif (cpu_logical_map(i) == hwid)\r\nreturn i;\r\nreturn -1;\r\n}\r\nstatic void __init gic_populate_ppi_partitions(struct device_node *gic_node)\r\n{\r\nstruct device_node *parts_node, *child_part;\r\nint part_idx = 0, i;\r\nint nr_parts;\r\nstruct partition_affinity *parts;\r\nparts_node = of_find_node_by_name(gic_node, "ppi-partitions");\r\nif (!parts_node)\r\nreturn;\r\nnr_parts = of_get_child_count(parts_node);\r\nif (!nr_parts)\r\nreturn;\r\nparts = kzalloc(sizeof(*parts) * nr_parts, GFP_KERNEL);\r\nif (WARN_ON(!parts))\r\nreturn;\r\nfor_each_child_of_node(parts_node, child_part) {\r\nstruct partition_affinity *part;\r\nint n;\r\npart = &parts[part_idx];\r\npart->partition_id = of_node_to_fwnode(child_part);\r\npr_info("GIC: PPI partition %s[%d] { ",\r\nchild_part->name, part_idx);\r\nn = of_property_count_elems_of_size(child_part, "affinity",\r\nsizeof(u32));\r\nWARN_ON(n <= 0);\r\nfor (i = 0; i < n; i++) {\r\nint err, cpu;\r\nu32 cpu_phandle;\r\nstruct device_node *cpu_node;\r\nerr = of_property_read_u32_index(child_part, "affinity",\r\ni, &cpu_phandle);\r\nif (WARN_ON(err))\r\ncontinue;\r\ncpu_node = of_find_node_by_phandle(cpu_phandle);\r\nif (WARN_ON(!cpu_node))\r\ncontinue;\r\ncpu = get_cpu_number(cpu_node);\r\nif (WARN_ON(cpu == -1))\r\ncontinue;\r\npr_cont("%s[%d] ", cpu_node->full_name, cpu);\r\ncpumask_set_cpu(cpu, &part->mask);\r\n}\r\npr_cont("}\n");\r\npart_idx++;\r\n}\r\nfor (i = 0; i < 16; i++) {\r\nunsigned int irq;\r\nstruct partition_desc *desc;\r\nstruct irq_fwspec ppi_fwspec = {\r\n.fwnode = gic_data.fwnode,\r\n.param_count = 3,\r\n.param = {\r\n[0] = 1,\r\n[1] = i,\r\n[2] = IRQ_TYPE_NONE,\r\n},\r\n};\r\nirq = irq_create_fwspec_mapping(&ppi_fwspec);\r\nif (WARN_ON(!irq))\r\ncontinue;\r\ndesc = partition_create_desc(gic_data.fwnode, parts, nr_parts,\r\nirq, &partition_domain_ops);\r\nif (WARN_ON(!desc))\r\ncontinue;\r\ngic_data.ppi_descs[i] = desc;\r\n}\r\n}\r\nstatic void __init gic_of_setup_kvm_info(struct device_node *node)\r\n{\r\nint ret;\r\nstruct resource r;\r\nu32 gicv_idx;\r\ngic_v3_kvm_info.type = GIC_V3;\r\ngic_v3_kvm_info.maint_irq = irq_of_parse_and_map(node, 0);\r\nif (!gic_v3_kvm_info.maint_irq)\r\nreturn;\r\nif (of_property_read_u32(node, "#redistributor-regions",\r\n&gicv_idx))\r\ngicv_idx = 1;\r\ngicv_idx += 3;\r\nret = of_address_to_resource(node, gicv_idx, &r);\r\nif (!ret)\r\ngic_v3_kvm_info.vcpu = r;\r\ngic_set_kvm_info(&gic_v3_kvm_info);\r\n}\r\nstatic int __init gic_of_init(struct device_node *node, struct device_node *parent)\r\n{\r\nvoid __iomem *dist_base;\r\nstruct redist_region *rdist_regs;\r\nu64 redist_stride;\r\nu32 nr_redist_regions;\r\nint err, i;\r\ndist_base = of_iomap(node, 0);\r\nif (!dist_base) {\r\npr_err("%s: unable to map gic dist registers\n",\r\nnode->full_name);\r\nreturn -ENXIO;\r\n}\r\nerr = gic_validate_dist_version(dist_base);\r\nif (err) {\r\npr_err("%s: no distributor detected, giving up\n",\r\nnode->full_name);\r\ngoto out_unmap_dist;\r\n}\r\nif (of_property_read_u32(node, "#redistributor-regions", &nr_redist_regions))\r\nnr_redist_regions = 1;\r\nrdist_regs = kzalloc(sizeof(*rdist_regs) * nr_redist_regions, GFP_KERNEL);\r\nif (!rdist_regs) {\r\nerr = -ENOMEM;\r\ngoto out_unmap_dist;\r\n}\r\nfor (i = 0; i < nr_redist_regions; i++) {\r\nstruct resource res;\r\nint ret;\r\nret = of_address_to_resource(node, 1 + i, &res);\r\nrdist_regs[i].redist_base = of_iomap(node, 1 + i);\r\nif (ret || !rdist_regs[i].redist_base) {\r\npr_err("%s: couldn't map region %d\n",\r\nnode->full_name, i);\r\nerr = -ENODEV;\r\ngoto out_unmap_rdist;\r\n}\r\nrdist_regs[i].phys_base = res.start;\r\n}\r\nif (of_property_read_u64(node, "redistributor-stride", &redist_stride))\r\nredist_stride = 0;\r\nerr = gic_init_bases(dist_base, rdist_regs, nr_redist_regions,\r\nredist_stride, &node->fwnode);\r\nif (err)\r\ngoto out_unmap_rdist;\r\ngic_populate_ppi_partitions(node);\r\ngic_of_setup_kvm_info(node);\r\nreturn 0;\r\nout_unmap_rdist:\r\nfor (i = 0; i < nr_redist_regions; i++)\r\nif (rdist_regs[i].redist_base)\r\niounmap(rdist_regs[i].redist_base);\r\nkfree(rdist_regs);\r\nout_unmap_dist:\r\niounmap(dist_base);\r\nreturn err;\r\n}\r\nstatic void __init\r\ngic_acpi_register_redist(phys_addr_t phys_base, void __iomem *redist_base)\r\n{\r\nstatic int count = 0;\r\nacpi_data.redist_regs[count].phys_base = phys_base;\r\nacpi_data.redist_regs[count].redist_base = redist_base;\r\nacpi_data.redist_regs[count].single_redist = acpi_data.single_redist;\r\ncount++;\r\n}\r\nstatic int __init\r\ngic_acpi_parse_madt_redist(struct acpi_subtable_header *header,\r\nconst unsigned long end)\r\n{\r\nstruct acpi_madt_generic_redistributor *redist =\r\n(struct acpi_madt_generic_redistributor *)header;\r\nvoid __iomem *redist_base;\r\nredist_base = ioremap(redist->base_address, redist->length);\r\nif (!redist_base) {\r\npr_err("Couldn't map GICR region @%llx\n", redist->base_address);\r\nreturn -ENOMEM;\r\n}\r\ngic_acpi_register_redist(redist->base_address, redist_base);\r\nreturn 0;\r\n}\r\nstatic int __init\r\ngic_acpi_parse_madt_gicc(struct acpi_subtable_header *header,\r\nconst unsigned long end)\r\n{\r\nstruct acpi_madt_generic_interrupt *gicc =\r\n(struct acpi_madt_generic_interrupt *)header;\r\nu32 reg = readl_relaxed(acpi_data.dist_base + GICD_PIDR2) & GIC_PIDR2_ARCH_MASK;\r\nu32 size = reg == GIC_PIDR2_ARCH_GICv4 ? SZ_64K * 4 : SZ_64K * 2;\r\nvoid __iomem *redist_base;\r\nredist_base = ioremap(gicc->gicr_base_address, size);\r\nif (!redist_base)\r\nreturn -ENOMEM;\r\ngic_acpi_register_redist(gicc->gicr_base_address, redist_base);\r\nreturn 0;\r\n}\r\nstatic int __init gic_acpi_collect_gicr_base(void)\r\n{\r\nacpi_tbl_entry_handler redist_parser;\r\nenum acpi_madt_type type;\r\nif (acpi_data.single_redist) {\r\ntype = ACPI_MADT_TYPE_GENERIC_INTERRUPT;\r\nredist_parser = gic_acpi_parse_madt_gicc;\r\n} else {\r\ntype = ACPI_MADT_TYPE_GENERIC_REDISTRIBUTOR;\r\nredist_parser = gic_acpi_parse_madt_redist;\r\n}\r\nif (acpi_table_parse_madt(type, redist_parser, 0) > 0)\r\nreturn 0;\r\npr_info("No valid GICR entries exist\n");\r\nreturn -ENODEV;\r\n}\r\nstatic int __init gic_acpi_match_gicr(struct acpi_subtable_header *header,\r\nconst unsigned long end)\r\n{\r\nreturn 0;\r\n}\r\nstatic int __init gic_acpi_match_gicc(struct acpi_subtable_header *header,\r\nconst unsigned long end)\r\n{\r\nstruct acpi_madt_generic_interrupt *gicc =\r\n(struct acpi_madt_generic_interrupt *)header;\r\nif ((gicc->flags & ACPI_MADT_ENABLED) && gicc->gicr_base_address)\r\nreturn 0;\r\nreturn -ENODEV;\r\n}\r\nstatic int __init gic_acpi_count_gicr_regions(void)\r\n{\r\nint count;\r\ncount = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_REDISTRIBUTOR,\r\ngic_acpi_match_gicr, 0);\r\nif (count > 0) {\r\nacpi_data.single_redist = false;\r\nreturn count;\r\n}\r\ncount = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_INTERRUPT,\r\ngic_acpi_match_gicc, 0);\r\nif (count > 0)\r\nacpi_data.single_redist = true;\r\nreturn count;\r\n}\r\nstatic bool __init acpi_validate_gic_table(struct acpi_subtable_header *header,\r\nstruct acpi_probe_entry *ape)\r\n{\r\nstruct acpi_madt_generic_distributor *dist;\r\nint count;\r\ndist = (struct acpi_madt_generic_distributor *)header;\r\nif (dist->version != ape->driver_data)\r\nreturn false;\r\ncount = gic_acpi_count_gicr_regions();\r\nif (count <= 0)\r\nreturn false;\r\nacpi_data.nr_redist_regions = count;\r\nreturn true;\r\n}\r\nstatic int __init gic_acpi_parse_virt_madt_gicc(struct acpi_subtable_header *header,\r\nconst unsigned long end)\r\n{\r\nstruct acpi_madt_generic_interrupt *gicc =\r\n(struct acpi_madt_generic_interrupt *)header;\r\nint maint_irq_mode;\r\nstatic int first_madt = true;\r\nif (!(gicc->flags & ACPI_MADT_ENABLED))\r\nreturn 0;\r\nmaint_irq_mode = (gicc->flags & ACPI_MADT_VGIC_IRQ_MODE) ?\r\nACPI_EDGE_SENSITIVE : ACPI_LEVEL_SENSITIVE;\r\nif (first_madt) {\r\nfirst_madt = false;\r\nacpi_data.maint_irq = gicc->vgic_interrupt;\r\nacpi_data.maint_irq_mode = maint_irq_mode;\r\nacpi_data.vcpu_base = gicc->gicv_base_address;\r\nreturn 0;\r\n}\r\nif ((acpi_data.maint_irq != gicc->vgic_interrupt) ||\r\n(acpi_data.maint_irq_mode != maint_irq_mode) ||\r\n(acpi_data.vcpu_base != gicc->gicv_base_address))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic bool __init gic_acpi_collect_virt_info(void)\r\n{\r\nint count;\r\ncount = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_INTERRUPT,\r\ngic_acpi_parse_virt_madt_gicc, 0);\r\nreturn (count > 0);\r\n}\r\nstatic void __init gic_acpi_setup_kvm_info(void)\r\n{\r\nint irq;\r\nif (!gic_acpi_collect_virt_info()) {\r\npr_warn("Unable to get hardware information used for virtualization\n");\r\nreturn;\r\n}\r\ngic_v3_kvm_info.type = GIC_V3;\r\nirq = acpi_register_gsi(NULL, acpi_data.maint_irq,\r\nacpi_data.maint_irq_mode,\r\nACPI_ACTIVE_HIGH);\r\nif (irq <= 0)\r\nreturn;\r\ngic_v3_kvm_info.maint_irq = irq;\r\nif (acpi_data.vcpu_base) {\r\nstruct resource *vcpu = &gic_v3_kvm_info.vcpu;\r\nvcpu->flags = IORESOURCE_MEM;\r\nvcpu->start = acpi_data.vcpu_base;\r\nvcpu->end = vcpu->start + ACPI_GICV2_VCPU_MEM_SIZE - 1;\r\n}\r\ngic_set_kvm_info(&gic_v3_kvm_info);\r\n}\r\nstatic int __init\r\ngic_acpi_init(struct acpi_subtable_header *header, const unsigned long end)\r\n{\r\nstruct acpi_madt_generic_distributor *dist;\r\nstruct fwnode_handle *domain_handle;\r\nsize_t size;\r\nint i, err;\r\ndist = (struct acpi_madt_generic_distributor *)header;\r\nacpi_data.dist_base = ioremap(dist->base_address,\r\nACPI_GICV3_DIST_MEM_SIZE);\r\nif (!acpi_data.dist_base) {\r\npr_err("Unable to map GICD registers\n");\r\nreturn -ENOMEM;\r\n}\r\nerr = gic_validate_dist_version(acpi_data.dist_base);\r\nif (err) {\r\npr_err("No distributor detected at @%p, giving up",\r\nacpi_data.dist_base);\r\ngoto out_dist_unmap;\r\n}\r\nsize = sizeof(*acpi_data.redist_regs) * acpi_data.nr_redist_regions;\r\nacpi_data.redist_regs = kzalloc(size, GFP_KERNEL);\r\nif (!acpi_data.redist_regs) {\r\nerr = -ENOMEM;\r\ngoto out_dist_unmap;\r\n}\r\nerr = gic_acpi_collect_gicr_base();\r\nif (err)\r\ngoto out_redist_unmap;\r\ndomain_handle = irq_domain_alloc_fwnode(acpi_data.dist_base);\r\nif (!domain_handle) {\r\nerr = -ENOMEM;\r\ngoto out_redist_unmap;\r\n}\r\nerr = gic_init_bases(acpi_data.dist_base, acpi_data.redist_regs,\r\nacpi_data.nr_redist_regions, 0, domain_handle);\r\nif (err)\r\ngoto out_fwhandle_free;\r\nacpi_set_irq_model(ACPI_IRQ_MODEL_GIC, domain_handle);\r\ngic_acpi_setup_kvm_info();\r\nreturn 0;\r\nout_fwhandle_free:\r\nirq_domain_free_fwnode(domain_handle);\r\nout_redist_unmap:\r\nfor (i = 0; i < acpi_data.nr_redist_regions; i++)\r\nif (acpi_data.redist_regs[i].redist_base)\r\niounmap(acpi_data.redist_regs[i].redist_base);\r\nkfree(acpi_data.redist_regs);\r\nout_dist_unmap:\r\niounmap(acpi_data.dist_base);\r\nreturn err;\r\n}
