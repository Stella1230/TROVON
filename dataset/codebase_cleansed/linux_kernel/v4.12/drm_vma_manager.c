void drm_vma_offset_manager_init(struct drm_vma_offset_manager *mgr,\r\nunsigned long page_offset, unsigned long size)\r\n{\r\nrwlock_init(&mgr->vm_lock);\r\ndrm_mm_init(&mgr->vm_addr_space_mm, page_offset, size);\r\n}\r\nvoid drm_vma_offset_manager_destroy(struct drm_vma_offset_manager *mgr)\r\n{\r\nwrite_lock(&mgr->vm_lock);\r\ndrm_mm_takedown(&mgr->vm_addr_space_mm);\r\nwrite_unlock(&mgr->vm_lock);\r\n}\r\nstruct drm_vma_offset_node *drm_vma_offset_lookup_locked(struct drm_vma_offset_manager *mgr,\r\nunsigned long start,\r\nunsigned long pages)\r\n{\r\nstruct drm_mm_node *node, *best;\r\nstruct rb_node *iter;\r\nunsigned long offset;\r\niter = mgr->vm_addr_space_mm.interval_tree.rb_node;\r\nbest = NULL;\r\nwhile (likely(iter)) {\r\nnode = rb_entry(iter, struct drm_mm_node, rb);\r\noffset = node->start;\r\nif (start >= offset) {\r\niter = iter->rb_right;\r\nbest = node;\r\nif (start == offset)\r\nbreak;\r\n} else {\r\niter = iter->rb_left;\r\n}\r\n}\r\nif (best) {\r\noffset = best->start + best->size;\r\nif (offset < start + pages)\r\nbest = NULL;\r\n}\r\nif (!best)\r\nreturn NULL;\r\nreturn container_of(best, struct drm_vma_offset_node, vm_node);\r\n}\r\nint drm_vma_offset_add(struct drm_vma_offset_manager *mgr,\r\nstruct drm_vma_offset_node *node, unsigned long pages)\r\n{\r\nint ret;\r\nwrite_lock(&mgr->vm_lock);\r\nif (drm_mm_node_allocated(&node->vm_node)) {\r\nret = 0;\r\ngoto out_unlock;\r\n}\r\nret = drm_mm_insert_node(&mgr->vm_addr_space_mm, &node->vm_node, pages);\r\nif (ret)\r\ngoto out_unlock;\r\nout_unlock:\r\nwrite_unlock(&mgr->vm_lock);\r\nreturn ret;\r\n}\r\nvoid drm_vma_offset_remove(struct drm_vma_offset_manager *mgr,\r\nstruct drm_vma_offset_node *node)\r\n{\r\nwrite_lock(&mgr->vm_lock);\r\nif (drm_mm_node_allocated(&node->vm_node)) {\r\ndrm_mm_remove_node(&node->vm_node);\r\nmemset(&node->vm_node, 0, sizeof(node->vm_node));\r\n}\r\nwrite_unlock(&mgr->vm_lock);\r\n}\r\nint drm_vma_node_allow(struct drm_vma_offset_node *node, struct drm_file *tag)\r\n{\r\nstruct rb_node **iter;\r\nstruct rb_node *parent = NULL;\r\nstruct drm_vma_offset_file *new, *entry;\r\nint ret = 0;\r\nnew = kmalloc(sizeof(*entry), GFP_KERNEL);\r\nwrite_lock(&node->vm_lock);\r\niter = &node->vm_files.rb_node;\r\nwhile (likely(*iter)) {\r\nparent = *iter;\r\nentry = rb_entry(*iter, struct drm_vma_offset_file, vm_rb);\r\nif (tag == entry->vm_tag) {\r\nentry->vm_count++;\r\ngoto unlock;\r\n} else if (tag > entry->vm_tag) {\r\niter = &(*iter)->rb_right;\r\n} else {\r\niter = &(*iter)->rb_left;\r\n}\r\n}\r\nif (!new) {\r\nret = -ENOMEM;\r\ngoto unlock;\r\n}\r\nnew->vm_tag = tag;\r\nnew->vm_count = 1;\r\nrb_link_node(&new->vm_rb, parent, iter);\r\nrb_insert_color(&new->vm_rb, &node->vm_files);\r\nnew = NULL;\r\nunlock:\r\nwrite_unlock(&node->vm_lock);\r\nkfree(new);\r\nreturn ret;\r\n}\r\nvoid drm_vma_node_revoke(struct drm_vma_offset_node *node,\r\nstruct drm_file *tag)\r\n{\r\nstruct drm_vma_offset_file *entry;\r\nstruct rb_node *iter;\r\nwrite_lock(&node->vm_lock);\r\niter = node->vm_files.rb_node;\r\nwhile (likely(iter)) {\r\nentry = rb_entry(iter, struct drm_vma_offset_file, vm_rb);\r\nif (tag == entry->vm_tag) {\r\nif (!--entry->vm_count) {\r\nrb_erase(&entry->vm_rb, &node->vm_files);\r\nkfree(entry);\r\n}\r\nbreak;\r\n} else if (tag > entry->vm_tag) {\r\niter = iter->rb_right;\r\n} else {\r\niter = iter->rb_left;\r\n}\r\n}\r\nwrite_unlock(&node->vm_lock);\r\n}\r\nbool drm_vma_node_is_allowed(struct drm_vma_offset_node *node,\r\nstruct drm_file *tag)\r\n{\r\nstruct drm_vma_offset_file *entry;\r\nstruct rb_node *iter;\r\nread_lock(&node->vm_lock);\r\niter = node->vm_files.rb_node;\r\nwhile (likely(iter)) {\r\nentry = rb_entry(iter, struct drm_vma_offset_file, vm_rb);\r\nif (tag == entry->vm_tag)\r\nbreak;\r\nelse if (tag > entry->vm_tag)\r\niter = iter->rb_right;\r\nelse\r\niter = iter->rb_left;\r\n}\r\nread_unlock(&node->vm_lock);\r\nreturn iter;\r\n}
