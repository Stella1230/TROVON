static void *dma_virt_alloc(struct device *dev, size_t size,\r\ndma_addr_t *dma_handle, gfp_t gfp,\r\nunsigned long attrs)\r\n{\r\nvoid *ret;\r\nret = (void *)__get_free_pages(gfp, get_order(size));\r\nif (ret)\r\n*dma_handle = (uintptr_t)ret;\r\nreturn ret;\r\n}\r\nstatic void dma_virt_free(struct device *dev, size_t size,\r\nvoid *cpu_addr, dma_addr_t dma_addr,\r\nunsigned long attrs)\r\n{\r\nfree_pages((unsigned long)cpu_addr, get_order(size));\r\n}\r\nstatic dma_addr_t dma_virt_map_page(struct device *dev, struct page *page,\r\nunsigned long offset, size_t size,\r\nenum dma_data_direction dir,\r\nunsigned long attrs)\r\n{\r\nreturn (uintptr_t)(page_address(page) + offset);\r\n}\r\nstatic int dma_virt_map_sg(struct device *dev, struct scatterlist *sgl,\r\nint nents, enum dma_data_direction dir,\r\nunsigned long attrs)\r\n{\r\nint i;\r\nstruct scatterlist *sg;\r\nfor_each_sg(sgl, sg, nents, i) {\r\nBUG_ON(!sg_page(sg));\r\nsg_dma_address(sg) = (uintptr_t)sg_virt(sg);\r\nsg_dma_len(sg) = sg->length;\r\n}\r\nreturn nents;\r\n}\r\nstatic int dma_virt_mapping_error(struct device *dev, dma_addr_t dma_addr)\r\n{\r\nreturn false;\r\n}\r\nstatic int dma_virt_supported(struct device *dev, u64 mask)\r\n{\r\nreturn true;\r\n}
