static int _mlx5_query_vport_state(struct mlx5_core_dev *mdev, u8 opmod,\r\nu16 vport, u32 *out, int outlen)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_vport_state_in)] = {0};\r\nMLX5_SET(query_vport_state_in, in, opcode,\r\nMLX5_CMD_OP_QUERY_VPORT_STATE);\r\nMLX5_SET(query_vport_state_in, in, op_mod, opmod);\r\nMLX5_SET(query_vport_state_in, in, vport_number, vport);\r\nif (vport)\r\nMLX5_SET(query_vport_state_in, in, other_vport, 1);\r\nreturn mlx5_cmd_exec(mdev, in, sizeof(in), out, outlen);\r\n}\r\nu8 mlx5_query_vport_state(struct mlx5_core_dev *mdev, u8 opmod, u16 vport)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(query_vport_state_out)] = {0};\r\n_mlx5_query_vport_state(mdev, opmod, vport, out, sizeof(out));\r\nreturn MLX5_GET(query_vport_state_out, out, state);\r\n}\r\nu8 mlx5_query_vport_admin_state(struct mlx5_core_dev *mdev, u8 opmod, u16 vport)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(query_vport_state_out)] = {0};\r\n_mlx5_query_vport_state(mdev, opmod, vport, out, sizeof(out));\r\nreturn MLX5_GET(query_vport_state_out, out, admin_state);\r\n}\r\nint mlx5_modify_vport_admin_state(struct mlx5_core_dev *mdev, u8 opmod,\r\nu16 vport, u8 state)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(modify_vport_state_in)] = {0};\r\nu32 out[MLX5_ST_SZ_DW(modify_vport_state_out)] = {0};\r\nMLX5_SET(modify_vport_state_in, in, opcode,\r\nMLX5_CMD_OP_MODIFY_VPORT_STATE);\r\nMLX5_SET(modify_vport_state_in, in, op_mod, opmod);\r\nMLX5_SET(modify_vport_state_in, in, vport_number, vport);\r\nif (vport)\r\nMLX5_SET(modify_vport_state_in, in, other_vport, 1);\r\nMLX5_SET(modify_vport_state_in, in, admin_state, state);\r\nreturn mlx5_cmd_exec(mdev, in, sizeof(in), out, sizeof(out));\r\n}\r\nstatic int mlx5_query_nic_vport_context(struct mlx5_core_dev *mdev, u16 vport,\r\nu32 *out, int outlen)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_nic_vport_context_in)] = {0};\r\nMLX5_SET(query_nic_vport_context_in, in, opcode,\r\nMLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT);\r\nMLX5_SET(query_nic_vport_context_in, in, vport_number, vport);\r\nif (vport)\r\nMLX5_SET(query_nic_vport_context_in, in, other_vport, 1);\r\nreturn mlx5_cmd_exec(mdev, in, sizeof(in), out, outlen);\r\n}\r\nstatic int mlx5_modify_nic_vport_context(struct mlx5_core_dev *mdev, void *in,\r\nint inlen)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(modify_nic_vport_context_out)] = {0};\r\nMLX5_SET(modify_nic_vport_context_in, in, opcode,\r\nMLX5_CMD_OP_MODIFY_NIC_VPORT_CONTEXT);\r\nreturn mlx5_cmd_exec(mdev, in, inlen, out, sizeof(out));\r\n}\r\nint mlx5_query_nic_vport_min_inline(struct mlx5_core_dev *mdev,\r\nu16 vport, u8 *min_inline)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(query_nic_vport_context_out)] = {0};\r\nint err;\r\nerr = mlx5_query_nic_vport_context(mdev, vport, out, sizeof(out));\r\nif (!err)\r\n*min_inline = MLX5_GET(query_nic_vport_context_out, out,\r\nnic_vport_context.min_wqe_inline_mode);\r\nreturn err;\r\n}\r\nvoid mlx5_query_min_inline(struct mlx5_core_dev *mdev,\r\nu8 *min_inline_mode)\r\n{\r\nswitch (MLX5_CAP_ETH(mdev, wqe_inline_mode)) {\r\ncase MLX5_CAP_INLINE_MODE_L2:\r\n*min_inline_mode = MLX5_INLINE_MODE_L2;\r\nbreak;\r\ncase MLX5_CAP_INLINE_MODE_VPORT_CONTEXT:\r\nmlx5_query_nic_vport_min_inline(mdev, 0, min_inline_mode);\r\nbreak;\r\ncase MLX5_CAP_INLINE_MODE_NOT_REQUIRED:\r\n*min_inline_mode = MLX5_INLINE_MODE_NONE;\r\nbreak;\r\n}\r\n}\r\nint mlx5_modify_nic_vport_min_inline(struct mlx5_core_dev *mdev,\r\nu16 vport, u8 min_inline)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(modify_nic_vport_context_in)] = {0};\r\nint inlen = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in);\r\nvoid *nic_vport_ctx;\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nfield_select.min_inline, 1);\r\nMLX5_SET(modify_nic_vport_context_in, in, vport_number, vport);\r\nMLX5_SET(modify_nic_vport_context_in, in, other_vport, 1);\r\nnic_vport_ctx = MLX5_ADDR_OF(modify_nic_vport_context_in,\r\nin, nic_vport_context);\r\nMLX5_SET(nic_vport_context, nic_vport_ctx,\r\nmin_wqe_inline_mode, min_inline);\r\nreturn mlx5_modify_nic_vport_context(mdev, in, inlen);\r\n}\r\nint mlx5_query_nic_vport_mac_address(struct mlx5_core_dev *mdev,\r\nu16 vport, u8 *addr)\r\n{\r\nu32 *out;\r\nint outlen = MLX5_ST_SZ_BYTES(query_nic_vport_context_out);\r\nu8 *out_addr;\r\nint err;\r\nout = mlx5_vzalloc(outlen);\r\nif (!out)\r\nreturn -ENOMEM;\r\nout_addr = MLX5_ADDR_OF(query_nic_vport_context_out, out,\r\nnic_vport_context.permanent_address);\r\nerr = mlx5_query_nic_vport_context(mdev, vport, out, outlen);\r\nif (!err)\r\nether_addr_copy(addr, &out_addr[2]);\r\nkvfree(out);\r\nreturn err;\r\n}\r\nint mlx5_modify_nic_vport_mac_address(struct mlx5_core_dev *mdev,\r\nu16 vport, u8 *addr)\r\n{\r\nvoid *in;\r\nint inlen = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in);\r\nint err;\r\nvoid *nic_vport_ctx;\r\nu8 *perm_mac;\r\nin = mlx5_vzalloc(inlen);\r\nif (!in) {\r\nmlx5_core_warn(mdev, "failed to allocate inbox\n");\r\nreturn -ENOMEM;\r\n}\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nfield_select.permanent_address, 1);\r\nMLX5_SET(modify_nic_vport_context_in, in, vport_number, vport);\r\nif (vport)\r\nMLX5_SET(modify_nic_vport_context_in, in, other_vport, 1);\r\nnic_vport_ctx = MLX5_ADDR_OF(modify_nic_vport_context_in,\r\nin, nic_vport_context);\r\nperm_mac = MLX5_ADDR_OF(nic_vport_context, nic_vport_ctx,\r\npermanent_address);\r\nether_addr_copy(&perm_mac[2], addr);\r\nerr = mlx5_modify_nic_vport_context(mdev, in, inlen);\r\nkvfree(in);\r\nreturn err;\r\n}\r\nint mlx5_query_nic_vport_mtu(struct mlx5_core_dev *mdev, u16 *mtu)\r\n{\r\nint outlen = MLX5_ST_SZ_BYTES(query_nic_vport_context_out);\r\nu32 *out;\r\nint err;\r\nout = mlx5_vzalloc(outlen);\r\nif (!out)\r\nreturn -ENOMEM;\r\nerr = mlx5_query_nic_vport_context(mdev, 0, out, outlen);\r\nif (!err)\r\n*mtu = MLX5_GET(query_nic_vport_context_out, out,\r\nnic_vport_context.mtu);\r\nkvfree(out);\r\nreturn err;\r\n}\r\nint mlx5_modify_nic_vport_mtu(struct mlx5_core_dev *mdev, u16 mtu)\r\n{\r\nint inlen = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in);\r\nvoid *in;\r\nint err;\r\nin = mlx5_vzalloc(inlen);\r\nif (!in)\r\nreturn -ENOMEM;\r\nMLX5_SET(modify_nic_vport_context_in, in, field_select.mtu, 1);\r\nMLX5_SET(modify_nic_vport_context_in, in, nic_vport_context.mtu, mtu);\r\nerr = mlx5_modify_nic_vport_context(mdev, in, inlen);\r\nkvfree(in);\r\nreturn err;\r\n}\r\nint mlx5_query_nic_vport_mac_list(struct mlx5_core_dev *dev,\r\nu32 vport,\r\nenum mlx5_list_type list_type,\r\nu8 addr_list[][ETH_ALEN],\r\nint *list_size)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_nic_vport_context_in)] = {0};\r\nvoid *nic_vport_ctx;\r\nint max_list_size;\r\nint req_list_size;\r\nint out_sz;\r\nvoid *out;\r\nint err;\r\nint i;\r\nreq_list_size = *list_size;\r\nmax_list_size = list_type == MLX5_NVPRT_LIST_TYPE_UC ?\r\n1 << MLX5_CAP_GEN(dev, log_max_current_uc_list) :\r\n1 << MLX5_CAP_GEN(dev, log_max_current_mc_list);\r\nif (req_list_size > max_list_size) {\r\nmlx5_core_warn(dev, "Requested list size (%d) > (%d) max_list_size\n",\r\nreq_list_size, max_list_size);\r\nreq_list_size = max_list_size;\r\n}\r\nout_sz = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in) +\r\nreq_list_size * MLX5_ST_SZ_BYTES(mac_address_layout);\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!out)\r\nreturn -ENOMEM;\r\nMLX5_SET(query_nic_vport_context_in, in, opcode,\r\nMLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT);\r\nMLX5_SET(query_nic_vport_context_in, in, allowed_list_type, list_type);\r\nMLX5_SET(query_nic_vport_context_in, in, vport_number, vport);\r\nif (vport)\r\nMLX5_SET(query_nic_vport_context_in, in, other_vport, 1);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, out_sz);\r\nif (err)\r\ngoto out;\r\nnic_vport_ctx = MLX5_ADDR_OF(query_nic_vport_context_out, out,\r\nnic_vport_context);\r\nreq_list_size = MLX5_GET(nic_vport_context, nic_vport_ctx,\r\nallowed_list_size);\r\n*list_size = req_list_size;\r\nfor (i = 0; i < req_list_size; i++) {\r\nu8 *mac_addr = MLX5_ADDR_OF(nic_vport_context,\r\nnic_vport_ctx,\r\ncurrent_uc_mac_address[i]) + 2;\r\nether_addr_copy(addr_list[i], mac_addr);\r\n}\r\nout:\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_modify_nic_vport_mac_list(struct mlx5_core_dev *dev,\r\nenum mlx5_list_type list_type,\r\nu8 addr_list[][ETH_ALEN],\r\nint list_size)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(modify_nic_vport_context_out)];\r\nvoid *nic_vport_ctx;\r\nint max_list_size;\r\nint in_sz;\r\nvoid *in;\r\nint err;\r\nint i;\r\nmax_list_size = list_type == MLX5_NVPRT_LIST_TYPE_UC ?\r\n1 << MLX5_CAP_GEN(dev, log_max_current_uc_list) :\r\n1 << MLX5_CAP_GEN(dev, log_max_current_mc_list);\r\nif (list_size > max_list_size)\r\nreturn -ENOSPC;\r\nin_sz = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in) +\r\nlist_size * MLX5_ST_SZ_BYTES(mac_address_layout);\r\nmemset(out, 0, sizeof(out));\r\nin = kzalloc(in_sz, GFP_KERNEL);\r\nif (!in)\r\nreturn -ENOMEM;\r\nMLX5_SET(modify_nic_vport_context_in, in, opcode,\r\nMLX5_CMD_OP_MODIFY_NIC_VPORT_CONTEXT);\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nfield_select.addresses_list, 1);\r\nnic_vport_ctx = MLX5_ADDR_OF(modify_nic_vport_context_in, in,\r\nnic_vport_context);\r\nMLX5_SET(nic_vport_context, nic_vport_ctx,\r\nallowed_list_type, list_type);\r\nMLX5_SET(nic_vport_context, nic_vport_ctx,\r\nallowed_list_size, list_size);\r\nfor (i = 0; i < list_size; i++) {\r\nu8 *curr_mac = MLX5_ADDR_OF(nic_vport_context,\r\nnic_vport_ctx,\r\ncurrent_uc_mac_address[i]) + 2;\r\nether_addr_copy(curr_mac, addr_list[i]);\r\n}\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, sizeof(out));\r\nkfree(in);\r\nreturn err;\r\n}\r\nint mlx5_query_nic_vport_vlans(struct mlx5_core_dev *dev,\r\nu32 vport,\r\nu16 vlans[],\r\nint *size)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_nic_vport_context_in)];\r\nvoid *nic_vport_ctx;\r\nint req_list_size;\r\nint max_list_size;\r\nint out_sz;\r\nvoid *out;\r\nint err;\r\nint i;\r\nreq_list_size = *size;\r\nmax_list_size = 1 << MLX5_CAP_GEN(dev, log_max_vlan_list);\r\nif (req_list_size > max_list_size) {\r\nmlx5_core_warn(dev, "Requested list size (%d) > (%d) max list size\n",\r\nreq_list_size, max_list_size);\r\nreq_list_size = max_list_size;\r\n}\r\nout_sz = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in) +\r\nreq_list_size * MLX5_ST_SZ_BYTES(vlan_layout);\r\nmemset(in, 0, sizeof(in));\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!out)\r\nreturn -ENOMEM;\r\nMLX5_SET(query_nic_vport_context_in, in, opcode,\r\nMLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT);\r\nMLX5_SET(query_nic_vport_context_in, in, allowed_list_type,\r\nMLX5_NVPRT_LIST_TYPE_VLAN);\r\nMLX5_SET(query_nic_vport_context_in, in, vport_number, vport);\r\nif (vport)\r\nMLX5_SET(query_nic_vport_context_in, in, other_vport, 1);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, out_sz);\r\nif (err)\r\ngoto out;\r\nnic_vport_ctx = MLX5_ADDR_OF(query_nic_vport_context_out, out,\r\nnic_vport_context);\r\nreq_list_size = MLX5_GET(nic_vport_context, nic_vport_ctx,\r\nallowed_list_size);\r\n*size = req_list_size;\r\nfor (i = 0; i < req_list_size; i++) {\r\nvoid *vlan_addr = MLX5_ADDR_OF(nic_vport_context,\r\nnic_vport_ctx,\r\ncurrent_uc_mac_address[i]);\r\nvlans[i] = MLX5_GET(vlan_layout, vlan_addr, vlan);\r\n}\r\nout:\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_modify_nic_vport_vlans(struct mlx5_core_dev *dev,\r\nu16 vlans[],\r\nint list_size)\r\n{\r\nu32 out[MLX5_ST_SZ_DW(modify_nic_vport_context_out)];\r\nvoid *nic_vport_ctx;\r\nint max_list_size;\r\nint in_sz;\r\nvoid *in;\r\nint err;\r\nint i;\r\nmax_list_size = 1 << MLX5_CAP_GEN(dev, log_max_vlan_list);\r\nif (list_size > max_list_size)\r\nreturn -ENOSPC;\r\nin_sz = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in) +\r\nlist_size * MLX5_ST_SZ_BYTES(vlan_layout);\r\nmemset(out, 0, sizeof(out));\r\nin = kzalloc(in_sz, GFP_KERNEL);\r\nif (!in)\r\nreturn -ENOMEM;\r\nMLX5_SET(modify_nic_vport_context_in, in, opcode,\r\nMLX5_CMD_OP_MODIFY_NIC_VPORT_CONTEXT);\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nfield_select.addresses_list, 1);\r\nnic_vport_ctx = MLX5_ADDR_OF(modify_nic_vport_context_in, in,\r\nnic_vport_context);\r\nMLX5_SET(nic_vport_context, nic_vport_ctx,\r\nallowed_list_type, MLX5_NVPRT_LIST_TYPE_VLAN);\r\nMLX5_SET(nic_vport_context, nic_vport_ctx,\r\nallowed_list_size, list_size);\r\nfor (i = 0; i < list_size; i++) {\r\nvoid *vlan_addr = MLX5_ADDR_OF(nic_vport_context,\r\nnic_vport_ctx,\r\ncurrent_uc_mac_address[i]);\r\nMLX5_SET(vlan_layout, vlan_addr, vlan, vlans[i]);\r\n}\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, sizeof(out));\r\nkfree(in);\r\nreturn err;\r\n}\r\nint mlx5_query_nic_vport_system_image_guid(struct mlx5_core_dev *mdev,\r\nu64 *system_image_guid)\r\n{\r\nu32 *out;\r\nint outlen = MLX5_ST_SZ_BYTES(query_nic_vport_context_out);\r\nout = mlx5_vzalloc(outlen);\r\nif (!out)\r\nreturn -ENOMEM;\r\nmlx5_query_nic_vport_context(mdev, 0, out, outlen);\r\n*system_image_guid = MLX5_GET64(query_nic_vport_context_out, out,\r\nnic_vport_context.system_image_guid);\r\nkfree(out);\r\nreturn 0;\r\n}\r\nint mlx5_query_nic_vport_node_guid(struct mlx5_core_dev *mdev, u64 *node_guid)\r\n{\r\nu32 *out;\r\nint outlen = MLX5_ST_SZ_BYTES(query_nic_vport_context_out);\r\nout = mlx5_vzalloc(outlen);\r\nif (!out)\r\nreturn -ENOMEM;\r\nmlx5_query_nic_vport_context(mdev, 0, out, outlen);\r\n*node_guid = MLX5_GET64(query_nic_vport_context_out, out,\r\nnic_vport_context.node_guid);\r\nkfree(out);\r\nreturn 0;\r\n}\r\nint mlx5_modify_nic_vport_node_guid(struct mlx5_core_dev *mdev,\r\nu32 vport, u64 node_guid)\r\n{\r\nint inlen = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in);\r\nvoid *nic_vport_context;\r\nvoid *in;\r\nint err;\r\nif (!vport)\r\nreturn -EINVAL;\r\nif (!MLX5_CAP_GEN(mdev, vport_group_manager))\r\nreturn -EACCES;\r\nif (!MLX5_CAP_ESW(mdev, nic_vport_node_guid_modify))\r\nreturn -EOPNOTSUPP;\r\nin = mlx5_vzalloc(inlen);\r\nif (!in)\r\nreturn -ENOMEM;\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nfield_select.node_guid, 1);\r\nMLX5_SET(modify_nic_vport_context_in, in, vport_number, vport);\r\nMLX5_SET(modify_nic_vport_context_in, in, other_vport, !!vport);\r\nnic_vport_context = MLX5_ADDR_OF(modify_nic_vport_context_in,\r\nin, nic_vport_context);\r\nMLX5_SET64(nic_vport_context, nic_vport_context, node_guid, node_guid);\r\nerr = mlx5_modify_nic_vport_context(mdev, in, inlen);\r\nkvfree(in);\r\nreturn err;\r\n}\r\nint mlx5_query_nic_vport_qkey_viol_cntr(struct mlx5_core_dev *mdev,\r\nu16 *qkey_viol_cntr)\r\n{\r\nu32 *out;\r\nint outlen = MLX5_ST_SZ_BYTES(query_nic_vport_context_out);\r\nout = mlx5_vzalloc(outlen);\r\nif (!out)\r\nreturn -ENOMEM;\r\nmlx5_query_nic_vport_context(mdev, 0, out, outlen);\r\n*qkey_viol_cntr = MLX5_GET(query_nic_vport_context_out, out,\r\nnic_vport_context.qkey_violation_counter);\r\nkfree(out);\r\nreturn 0;\r\n}\r\nint mlx5_query_hca_vport_gid(struct mlx5_core_dev *dev, u8 other_vport,\r\nu8 port_num, u16 vf_num, u16 gid_index,\r\nunion ib_gid *gid)\r\n{\r\nint in_sz = MLX5_ST_SZ_BYTES(query_hca_vport_gid_in);\r\nint out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_gid_out);\r\nint is_group_manager;\r\nvoid *out = NULL;\r\nvoid *in = NULL;\r\nunion ib_gid *tmp;\r\nint tbsz;\r\nint nout;\r\nint err;\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\ntbsz = mlx5_get_gid_table_len(MLX5_CAP_GEN(dev, gid_table_size));\r\nmlx5_core_dbg(dev, "vf_num %d, index %d, gid_table_size %d\n",\r\nvf_num, gid_index, tbsz);\r\nif (gid_index > tbsz && gid_index != 0xffff)\r\nreturn -EINVAL;\r\nif (gid_index == 0xffff)\r\nnout = tbsz;\r\nelse\r\nnout = 1;\r\nout_sz += nout * sizeof(*gid);\r\nin = kzalloc(in_sz, GFP_KERNEL);\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!in || !out) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nMLX5_SET(query_hca_vport_gid_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_GID);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(query_hca_vport_gid_in, in, vport_number, vf_num);\r\nMLX5_SET(query_hca_vport_gid_in, in, other_vport, 1);\r\n} else {\r\nerr = -EPERM;\r\ngoto out;\r\n}\r\n}\r\nMLX5_SET(query_hca_vport_gid_in, in, gid_index, gid_index);\r\nif (MLX5_CAP_GEN(dev, num_ports) == 2)\r\nMLX5_SET(query_hca_vport_gid_in, in, port_num, port_num);\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, out_sz);\r\nif (err)\r\ngoto out;\r\ntmp = out + MLX5_ST_SZ_BYTES(query_hca_vport_gid_out);\r\ngid->global.subnet_prefix = tmp->global.subnet_prefix;\r\ngid->global.interface_id = tmp->global.interface_id;\r\nout:\r\nkfree(in);\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_pkey(struct mlx5_core_dev *dev, u8 other_vport,\r\nu8 port_num, u16 vf_num, u16 pkey_index,\r\nu16 *pkey)\r\n{\r\nint in_sz = MLX5_ST_SZ_BYTES(query_hca_vport_pkey_in);\r\nint out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_pkey_out);\r\nint is_group_manager;\r\nvoid *out = NULL;\r\nvoid *in = NULL;\r\nvoid *pkarr;\r\nint nout;\r\nint tbsz;\r\nint err;\r\nint i;\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\ntbsz = mlx5_to_sw_pkey_sz(MLX5_CAP_GEN(dev, pkey_table_size));\r\nif (pkey_index > tbsz && pkey_index != 0xffff)\r\nreturn -EINVAL;\r\nif (pkey_index == 0xffff)\r\nnout = tbsz;\r\nelse\r\nnout = 1;\r\nout_sz += nout * MLX5_ST_SZ_BYTES(pkey);\r\nin = kzalloc(in_sz, GFP_KERNEL);\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!in || !out) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nMLX5_SET(query_hca_vport_pkey_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_PKEY);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(query_hca_vport_pkey_in, in, vport_number, vf_num);\r\nMLX5_SET(query_hca_vport_pkey_in, in, other_vport, 1);\r\n} else {\r\nerr = -EPERM;\r\ngoto out;\r\n}\r\n}\r\nMLX5_SET(query_hca_vport_pkey_in, in, pkey_index, pkey_index);\r\nif (MLX5_CAP_GEN(dev, num_ports) == 2)\r\nMLX5_SET(query_hca_vport_pkey_in, in, port_num, port_num);\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, out_sz);\r\nif (err)\r\ngoto out;\r\npkarr = MLX5_ADDR_OF(query_hca_vport_pkey_out, out, pkey);\r\nfor (i = 0; i < nout; i++, pkey++, pkarr += MLX5_ST_SZ_BYTES(pkey))\r\n*pkey = MLX5_GET_PR(pkey, pkarr, pkey);\r\nout:\r\nkfree(in);\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_context(struct mlx5_core_dev *dev,\r\nu8 other_vport, u8 port_num,\r\nu16 vf_num,\r\nstruct mlx5_hca_vport_context *rep)\r\n{\r\nint out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_context_out);\r\nint in[MLX5_ST_SZ_DW(query_hca_vport_context_in)] = {0};\r\nint is_group_manager;\r\nvoid *out;\r\nvoid *ctx;\r\nint err;\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!out)\r\nreturn -ENOMEM;\r\nMLX5_SET(query_hca_vport_context_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(query_hca_vport_context_in, in, other_vport, 1);\r\nMLX5_SET(query_hca_vport_context_in, in, vport_number, vf_num);\r\n} else {\r\nerr = -EPERM;\r\ngoto ex;\r\n}\r\n}\r\nif (MLX5_CAP_GEN(dev, num_ports) == 2)\r\nMLX5_SET(query_hca_vport_context_in, in, port_num, port_num);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, out_sz);\r\nif (err)\r\ngoto ex;\r\nctx = MLX5_ADDR_OF(query_hca_vport_context_out, out, hca_vport_context);\r\nrep->field_select = MLX5_GET_PR(hca_vport_context, ctx, field_select);\r\nrep->sm_virt_aware = MLX5_GET_PR(hca_vport_context, ctx, sm_virt_aware);\r\nrep->has_smi = MLX5_GET_PR(hca_vport_context, ctx, has_smi);\r\nrep->has_raw = MLX5_GET_PR(hca_vport_context, ctx, has_raw);\r\nrep->policy = MLX5_GET_PR(hca_vport_context, ctx, vport_state_policy);\r\nrep->phys_state = MLX5_GET_PR(hca_vport_context, ctx,\r\nport_physical_state);\r\nrep->vport_state = MLX5_GET_PR(hca_vport_context, ctx, vport_state);\r\nrep->port_physical_state = MLX5_GET_PR(hca_vport_context, ctx,\r\nport_physical_state);\r\nrep->port_guid = MLX5_GET64_PR(hca_vport_context, ctx, port_guid);\r\nrep->node_guid = MLX5_GET64_PR(hca_vport_context, ctx, node_guid);\r\nrep->cap_mask1 = MLX5_GET_PR(hca_vport_context, ctx, cap_mask1);\r\nrep->cap_mask1_perm = MLX5_GET_PR(hca_vport_context, ctx,\r\ncap_mask1_field_select);\r\nrep->cap_mask2 = MLX5_GET_PR(hca_vport_context, ctx, cap_mask2);\r\nrep->cap_mask2_perm = MLX5_GET_PR(hca_vport_context, ctx,\r\ncap_mask2_field_select);\r\nrep->lid = MLX5_GET_PR(hca_vport_context, ctx, lid);\r\nrep->init_type_reply = MLX5_GET_PR(hca_vport_context, ctx,\r\ninit_type_reply);\r\nrep->lmc = MLX5_GET_PR(hca_vport_context, ctx, lmc);\r\nrep->subnet_timeout = MLX5_GET_PR(hca_vport_context, ctx,\r\nsubnet_timeout);\r\nrep->sm_lid = MLX5_GET_PR(hca_vport_context, ctx, sm_lid);\r\nrep->sm_sl = MLX5_GET_PR(hca_vport_context, ctx, sm_sl);\r\nrep->qkey_violation_counter = MLX5_GET_PR(hca_vport_context, ctx,\r\nqkey_violation_counter);\r\nrep->pkey_violation_counter = MLX5_GET_PR(hca_vport_context, ctx,\r\npkey_violation_counter);\r\nrep->grh_required = MLX5_GET_PR(hca_vport_context, ctx, grh_required);\r\nrep->sys_image_guid = MLX5_GET64_PR(hca_vport_context, ctx,\r\nsystem_image_guid);\r\nex:\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_system_image_guid(struct mlx5_core_dev *dev,\r\nu64 *sys_image_guid)\r\n{\r\nstruct mlx5_hca_vport_context *rep;\r\nint err;\r\nrep = kzalloc(sizeof(*rep), GFP_KERNEL);\r\nif (!rep)\r\nreturn -ENOMEM;\r\nerr = mlx5_query_hca_vport_context(dev, 0, 1, 0, rep);\r\nif (!err)\r\n*sys_image_guid = rep->sys_image_guid;\r\nkfree(rep);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_node_guid(struct mlx5_core_dev *dev,\r\nu64 *node_guid)\r\n{\r\nstruct mlx5_hca_vport_context *rep;\r\nint err;\r\nrep = kzalloc(sizeof(*rep), GFP_KERNEL);\r\nif (!rep)\r\nreturn -ENOMEM;\r\nerr = mlx5_query_hca_vport_context(dev, 0, 1, 0, rep);\r\nif (!err)\r\n*node_guid = rep->node_guid;\r\nkfree(rep);\r\nreturn err;\r\n}\r\nint mlx5_query_nic_vport_promisc(struct mlx5_core_dev *mdev,\r\nu32 vport,\r\nint *promisc_uc,\r\nint *promisc_mc,\r\nint *promisc_all)\r\n{\r\nu32 *out;\r\nint outlen = MLX5_ST_SZ_BYTES(query_nic_vport_context_out);\r\nint err;\r\nout = kzalloc(outlen, GFP_KERNEL);\r\nif (!out)\r\nreturn -ENOMEM;\r\nerr = mlx5_query_nic_vport_context(mdev, vport, out, outlen);\r\nif (err)\r\ngoto out;\r\n*promisc_uc = MLX5_GET(query_nic_vport_context_out, out,\r\nnic_vport_context.promisc_uc);\r\n*promisc_mc = MLX5_GET(query_nic_vport_context_out, out,\r\nnic_vport_context.promisc_mc);\r\n*promisc_all = MLX5_GET(query_nic_vport_context_out, out,\r\nnic_vport_context.promisc_all);\r\nout:\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_modify_nic_vport_promisc(struct mlx5_core_dev *mdev,\r\nint promisc_uc,\r\nint promisc_mc,\r\nint promisc_all)\r\n{\r\nvoid *in;\r\nint inlen = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in);\r\nint err;\r\nin = mlx5_vzalloc(inlen);\r\nif (!in) {\r\nmlx5_core_err(mdev, "failed to allocate inbox\n");\r\nreturn -ENOMEM;\r\n}\r\nMLX5_SET(modify_nic_vport_context_in, in, field_select.promisc, 1);\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nnic_vport_context.promisc_uc, promisc_uc);\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nnic_vport_context.promisc_mc, promisc_mc);\r\nMLX5_SET(modify_nic_vport_context_in, in,\r\nnic_vport_context.promisc_all, promisc_all);\r\nerr = mlx5_modify_nic_vport_context(mdev, in, inlen);\r\nkvfree(in);\r\nreturn err;\r\n}\r\nstatic int mlx5_nic_vport_update_roce_state(struct mlx5_core_dev *mdev,\r\nenum mlx5_vport_roce_state state)\r\n{\r\nvoid *in;\r\nint inlen = MLX5_ST_SZ_BYTES(modify_nic_vport_context_in);\r\nint err;\r\nin = mlx5_vzalloc(inlen);\r\nif (!in) {\r\nmlx5_core_warn(mdev, "failed to allocate inbox\n");\r\nreturn -ENOMEM;\r\n}\r\nMLX5_SET(modify_nic_vport_context_in, in, field_select.roce_en, 1);\r\nMLX5_SET(modify_nic_vport_context_in, in, nic_vport_context.roce_en,\r\nstate);\r\nerr = mlx5_modify_nic_vport_context(mdev, in, inlen);\r\nkvfree(in);\r\nreturn err;\r\n}\r\nint mlx5_nic_vport_enable_roce(struct mlx5_core_dev *mdev)\r\n{\r\nreturn mlx5_nic_vport_update_roce_state(mdev, MLX5_VPORT_ROCE_ENABLED);\r\n}\r\nint mlx5_nic_vport_disable_roce(struct mlx5_core_dev *mdev)\r\n{\r\nreturn mlx5_nic_vport_update_roce_state(mdev, MLX5_VPORT_ROCE_DISABLED);\r\n}\r\nint mlx5_core_query_vport_counter(struct mlx5_core_dev *dev, u8 other_vport,\r\nint vf, u8 port_num, void *out,\r\nsize_t out_sz)\r\n{\r\nint in_sz = MLX5_ST_SZ_BYTES(query_vport_counter_in);\r\nint is_group_manager;\r\nvoid *in;\r\nint err;\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\nin = mlx5_vzalloc(in_sz);\r\nif (!in) {\r\nerr = -ENOMEM;\r\nreturn err;\r\n}\r\nMLX5_SET(query_vport_counter_in, in, opcode,\r\nMLX5_CMD_OP_QUERY_VPORT_COUNTER);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(query_vport_counter_in, in, other_vport, 1);\r\nMLX5_SET(query_vport_counter_in, in, vport_number, vf + 1);\r\n} else {\r\nerr = -EPERM;\r\ngoto free;\r\n}\r\n}\r\nif (MLX5_CAP_GEN(dev, num_ports) == 2)\r\nMLX5_SET(query_vport_counter_in, in, port_num, port_num);\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, out_sz);\r\nfree:\r\nkvfree(in);\r\nreturn err;\r\n}\r\nint mlx5_core_modify_hca_vport_context(struct mlx5_core_dev *dev,\r\nu8 other_vport, u8 port_num,\r\nint vf,\r\nstruct mlx5_hca_vport_context *req)\r\n{\r\nint in_sz = MLX5_ST_SZ_BYTES(modify_hca_vport_context_in);\r\nu8 out[MLX5_ST_SZ_BYTES(modify_hca_vport_context_out)];\r\nint is_group_manager;\r\nvoid *in;\r\nint err;\r\nvoid *ctx;\r\nmlx5_core_dbg(dev, "vf %d\n", vf);\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\nin = kzalloc(in_sz, GFP_KERNEL);\r\nif (!in)\r\nreturn -ENOMEM;\r\nmemset(out, 0, sizeof(out));\r\nMLX5_SET(modify_hca_vport_context_in, in, opcode, MLX5_CMD_OP_MODIFY_HCA_VPORT_CONTEXT);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(modify_hca_vport_context_in, in, other_vport, 1);\r\nMLX5_SET(modify_hca_vport_context_in, in, vport_number, vf);\r\n} else {\r\nerr = -EPERM;\r\ngoto ex;\r\n}\r\n}\r\nif (MLX5_CAP_GEN(dev, num_ports) > 1)\r\nMLX5_SET(modify_hca_vport_context_in, in, port_num, port_num);\r\nctx = MLX5_ADDR_OF(modify_hca_vport_context_in, in, hca_vport_context);\r\nMLX5_SET(hca_vport_context, ctx, field_select, req->field_select);\r\nMLX5_SET(hca_vport_context, ctx, sm_virt_aware, req->sm_virt_aware);\r\nMLX5_SET(hca_vport_context, ctx, has_smi, req->has_smi);\r\nMLX5_SET(hca_vport_context, ctx, has_raw, req->has_raw);\r\nMLX5_SET(hca_vport_context, ctx, vport_state_policy, req->policy);\r\nMLX5_SET(hca_vport_context, ctx, port_physical_state, req->phys_state);\r\nMLX5_SET(hca_vport_context, ctx, vport_state, req->vport_state);\r\nMLX5_SET64(hca_vport_context, ctx, port_guid, req->port_guid);\r\nMLX5_SET64(hca_vport_context, ctx, node_guid, req->node_guid);\r\nMLX5_SET(hca_vport_context, ctx, cap_mask1, req->cap_mask1);\r\nMLX5_SET(hca_vport_context, ctx, cap_mask1_field_select, req->cap_mask1_perm);\r\nMLX5_SET(hca_vport_context, ctx, cap_mask2, req->cap_mask2);\r\nMLX5_SET(hca_vport_context, ctx, cap_mask2_field_select, req->cap_mask2_perm);\r\nMLX5_SET(hca_vport_context, ctx, lid, req->lid);\r\nMLX5_SET(hca_vport_context, ctx, init_type_reply, req->init_type_reply);\r\nMLX5_SET(hca_vport_context, ctx, lmc, req->lmc);\r\nMLX5_SET(hca_vport_context, ctx, subnet_timeout, req->subnet_timeout);\r\nMLX5_SET(hca_vport_context, ctx, sm_lid, req->sm_lid);\r\nMLX5_SET(hca_vport_context, ctx, sm_sl, req->sm_sl);\r\nMLX5_SET(hca_vport_context, ctx, qkey_violation_counter, req->qkey_violation_counter);\r\nMLX5_SET(hca_vport_context, ctx, pkey_violation_counter, req->pkey_violation_counter);\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, sizeof(out));\r\nex:\r\nkfree(in);\r\nreturn err;\r\n}
