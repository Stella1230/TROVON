static void vgpu_pci_cfg_mem_write(struct intel_vgpu *vgpu, unsigned int off,\r\nu8 *src, unsigned int bytes)\r\n{\r\nu8 *cfg_base = vgpu_cfg_space(vgpu);\r\nu8 mask, new, old;\r\nint i = 0;\r\nfor (; i < bytes && (off + i < sizeof(pci_cfg_space_rw_bmp)); i++) {\r\nmask = pci_cfg_space_rw_bmp[off + i];\r\nold = cfg_base[off + i];\r\nnew = src[i] & mask;\r\nif (off + i == PCI_STATUS + 1)\r\nnew = (~new & old) & mask;\r\ncfg_base[off + i] = (old & ~mask) | new;\r\n}\r\nif (i < bytes)\r\nmemcpy(cfg_base + off + i, src + i, bytes - i);\r\n}\r\nint intel_vgpu_emulate_cfg_read(struct intel_vgpu *vgpu, unsigned int offset,\r\nvoid *p_data, unsigned int bytes)\r\n{\r\nif (WARN_ON(bytes > 4))\r\nreturn -EINVAL;\r\nif (WARN_ON(offset + bytes > INTEL_GVT_MAX_CFG_SPACE_SZ))\r\nreturn -EINVAL;\r\nmemcpy(p_data, vgpu_cfg_space(vgpu) + offset, bytes);\r\nreturn 0;\r\n}\r\nstatic int map_aperture(struct intel_vgpu *vgpu, bool map)\r\n{\r\nu64 first_gfn, first_mfn;\r\nu64 val;\r\nint ret;\r\nif (map == vgpu->cfg_space.bar[INTEL_GVT_PCI_BAR_APERTURE].tracked)\r\nreturn 0;\r\nval = vgpu_cfg_space(vgpu)[PCI_BASE_ADDRESS_2];\r\nif (val & PCI_BASE_ADDRESS_MEM_TYPE_64)\r\nval = *(u64 *)(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_2);\r\nelse\r\nval = *(u32 *)(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_2);\r\nfirst_gfn = (val + vgpu_aperture_offset(vgpu)) >> PAGE_SHIFT;\r\nfirst_mfn = vgpu_aperture_pa_base(vgpu) >> PAGE_SHIFT;\r\nret = intel_gvt_hypervisor_map_gfn_to_mfn(vgpu, first_gfn,\r\nfirst_mfn,\r\nvgpu_aperture_sz(vgpu) >>\r\nPAGE_SHIFT, map);\r\nif (ret)\r\nreturn ret;\r\nvgpu->cfg_space.bar[INTEL_GVT_PCI_BAR_APERTURE].tracked = map;\r\nreturn 0;\r\n}\r\nstatic int trap_gttmmio(struct intel_vgpu *vgpu, bool trap)\r\n{\r\nu64 start, end;\r\nu64 val;\r\nint ret;\r\nif (trap == vgpu->cfg_space.bar[INTEL_GVT_PCI_BAR_GTTMMIO].tracked)\r\nreturn 0;\r\nval = vgpu_cfg_space(vgpu)[PCI_BASE_ADDRESS_0];\r\nif (val & PCI_BASE_ADDRESS_MEM_TYPE_64)\r\nstart = *(u64 *)(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_0);\r\nelse\r\nstart = *(u32 *)(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_0);\r\nstart &= ~GENMASK(3, 0);\r\nend = start + vgpu->cfg_space.bar[INTEL_GVT_PCI_BAR_GTTMMIO].size - 1;\r\nret = intel_gvt_hypervisor_set_trap_area(vgpu, start, end, trap);\r\nif (ret)\r\nreturn ret;\r\nvgpu->cfg_space.bar[INTEL_GVT_PCI_BAR_GTTMMIO].tracked = trap;\r\nreturn 0;\r\n}\r\nstatic int emulate_pci_command_write(struct intel_vgpu *vgpu,\r\nunsigned int offset, void *p_data, unsigned int bytes)\r\n{\r\nu8 old = vgpu_cfg_space(vgpu)[offset];\r\nu8 new = *(u8 *)p_data;\r\nu8 changed = old ^ new;\r\nint ret;\r\nvgpu_pci_cfg_mem_write(vgpu, offset, p_data, bytes);\r\nif (!(changed & PCI_COMMAND_MEMORY))\r\nreturn 0;\r\nif (old & PCI_COMMAND_MEMORY) {\r\nret = trap_gttmmio(vgpu, false);\r\nif (ret)\r\nreturn ret;\r\nret = map_aperture(vgpu, false);\r\nif (ret)\r\nreturn ret;\r\n} else {\r\nret = trap_gttmmio(vgpu, true);\r\nif (ret)\r\nreturn ret;\r\nret = map_aperture(vgpu, true);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int emulate_pci_bar_write(struct intel_vgpu *vgpu, unsigned int offset,\r\nvoid *p_data, unsigned int bytes)\r\n{\r\nunsigned int bar_index =\r\n(rounddown(offset, 8) % PCI_BASE_ADDRESS_0) / 8;\r\nu32 new = *(u32 *)(p_data);\r\nbool lo = IS_ALIGNED(offset, 8);\r\nu64 size;\r\nint ret = 0;\r\nbool mmio_enabled =\r\nvgpu_cfg_space(vgpu)[PCI_COMMAND] & PCI_COMMAND_MEMORY;\r\nif (WARN_ON(bar_index >= INTEL_GVT_PCI_BAR_MAX))\r\nreturn -EINVAL;\r\nif (new == 0xffffffff) {\r\nsize = vgpu->cfg_space.bar[bar_index].size;\r\nif (lo) {\r\nnew = rounddown(new, size);\r\n} else {\r\nu32 val = vgpu_cfg_space(vgpu)[rounddown(offset, 8)];\r\nif (val & PCI_BASE_ADDRESS_MEM_TYPE_64)\r\nnew &= (~(size-1)) >> 32;\r\nelse\r\nnew = 0;\r\n}\r\nswitch (bar_index) {\r\ncase INTEL_GVT_PCI_BAR_GTTMMIO:\r\nret = trap_gttmmio(vgpu, false);\r\nbreak;\r\ncase INTEL_GVT_PCI_BAR_APERTURE:\r\nret = map_aperture(vgpu, false);\r\nbreak;\r\n}\r\nintel_vgpu_write_pci_bar(vgpu, offset, new, lo);\r\n} else {\r\nswitch (bar_index) {\r\ncase INTEL_GVT_PCI_BAR_GTTMMIO:\r\nret = trap_gttmmio(vgpu, false);\r\nbreak;\r\ncase INTEL_GVT_PCI_BAR_APERTURE:\r\nret = map_aperture(vgpu, false);\r\nbreak;\r\n}\r\nintel_vgpu_write_pci_bar(vgpu, offset, new, lo);\r\nif (mmio_enabled) {\r\nswitch (bar_index) {\r\ncase INTEL_GVT_PCI_BAR_GTTMMIO:\r\nret = trap_gttmmio(vgpu, true);\r\nbreak;\r\ncase INTEL_GVT_PCI_BAR_APERTURE:\r\nret = map_aperture(vgpu, true);\r\nbreak;\r\n}\r\n}\r\n}\r\nreturn ret;\r\n}\r\nint intel_vgpu_emulate_cfg_write(struct intel_vgpu *vgpu, unsigned int offset,\r\nvoid *p_data, unsigned int bytes)\r\n{\r\nint ret;\r\nif (WARN_ON(bytes > 4))\r\nreturn -EINVAL;\r\nif (WARN_ON(offset + bytes > INTEL_GVT_MAX_CFG_SPACE_SZ))\r\nreturn -EINVAL;\r\nif (IS_ALIGNED(offset, 2) && offset == PCI_COMMAND) {\r\nif (WARN_ON(bytes > 2))\r\nreturn -EINVAL;\r\nreturn emulate_pci_command_write(vgpu, offset, p_data, bytes);\r\n}\r\nswitch (rounddown(offset, 4)) {\r\ncase PCI_BASE_ADDRESS_0:\r\ncase PCI_BASE_ADDRESS_1:\r\ncase PCI_BASE_ADDRESS_2:\r\ncase PCI_BASE_ADDRESS_3:\r\nif (WARN_ON(!IS_ALIGNED(offset, 4)))\r\nreturn -EINVAL;\r\nreturn emulate_pci_bar_write(vgpu, offset, p_data, bytes);\r\ncase INTEL_GVT_PCI_SWSCI:\r\nif (WARN_ON(!IS_ALIGNED(offset, 4)))\r\nreturn -EINVAL;\r\nret = intel_vgpu_emulate_opregion_request(vgpu, *(u32 *)p_data);\r\nif (ret)\r\nreturn ret;\r\nbreak;\r\ncase INTEL_GVT_PCI_OPREGION:\r\nif (WARN_ON(!IS_ALIGNED(offset, 4)))\r\nreturn -EINVAL;\r\nret = intel_vgpu_init_opregion(vgpu, *(u32 *)p_data);\r\nif (ret)\r\nreturn ret;\r\nvgpu_pci_cfg_mem_write(vgpu, offset, p_data, bytes);\r\nbreak;\r\ndefault:\r\nvgpu_pci_cfg_mem_write(vgpu, offset, p_data, bytes);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nvoid intel_vgpu_init_cfg_space(struct intel_vgpu *vgpu,\r\nbool primary)\r\n{\r\nstruct intel_gvt *gvt = vgpu->gvt;\r\nconst struct intel_gvt_device_info *info = &gvt->device_info;\r\nu16 *gmch_ctl;\r\nint i;\r\nmemcpy(vgpu_cfg_space(vgpu), gvt->firmware.cfg_space,\r\ninfo->cfg_space_size);\r\nif (!primary) {\r\nvgpu_cfg_space(vgpu)[PCI_CLASS_DEVICE] =\r\nINTEL_GVT_PCI_CLASS_VGA_OTHER;\r\nvgpu_cfg_space(vgpu)[PCI_CLASS_PROG] =\r\nINTEL_GVT_PCI_CLASS_VGA_OTHER;\r\n}\r\ngmch_ctl = (u16 *)(vgpu_cfg_space(vgpu) + INTEL_GVT_PCI_GMCH_CONTROL);\r\n*gmch_ctl &= ~(BDW_GMCH_GMS_MASK << BDW_GMCH_GMS_SHIFT);\r\nintel_vgpu_write_pci_bar(vgpu, PCI_BASE_ADDRESS_2,\r\ngvt_aperture_pa_base(gvt), true);\r\nvgpu_cfg_space(vgpu)[PCI_COMMAND] &= ~(PCI_COMMAND_IO\r\n| PCI_COMMAND_MEMORY\r\n| PCI_COMMAND_MASTER);\r\nmemset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_1, 0, 4);\r\nmemset(vgpu_cfg_space(vgpu) + PCI_BASE_ADDRESS_3, 0, 4);\r\nmemset(vgpu_cfg_space(vgpu) + INTEL_GVT_PCI_OPREGION, 0, 4);\r\nfor (i = 0; i < INTEL_GVT_MAX_BAR_NUM; i++) {\r\nvgpu->cfg_space.bar[i].size = pci_resource_len(\r\ngvt->dev_priv->drm.pdev, i * 2);\r\nvgpu->cfg_space.bar[i].tracked = false;\r\n}\r\n}\r\nvoid intel_vgpu_reset_cfg_space(struct intel_vgpu *vgpu)\r\n{\r\nu8 cmd = vgpu_cfg_space(vgpu)[PCI_COMMAND];\r\nbool primary = vgpu_cfg_space(vgpu)[PCI_CLASS_DEVICE] !=\r\nINTEL_GVT_PCI_CLASS_VGA_OTHER;\r\nif (cmd & PCI_COMMAND_MEMORY) {\r\ntrap_gttmmio(vgpu, false);\r\nmap_aperture(vgpu, false);\r\n}\r\nintel_vgpu_init_cfg_space(vgpu, primary);\r\n}
