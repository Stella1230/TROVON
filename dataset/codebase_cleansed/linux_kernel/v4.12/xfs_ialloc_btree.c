STATIC int\r\nxfs_inobt_get_minrecs(\r\nstruct xfs_btree_cur *cur,\r\nint level)\r\n{\r\nreturn cur->bc_mp->m_inobt_mnr[level != 0];\r\n}\r\nSTATIC struct xfs_btree_cur *\r\nxfs_inobt_dup_cursor(\r\nstruct xfs_btree_cur *cur)\r\n{\r\nreturn xfs_inobt_init_cursor(cur->bc_mp, cur->bc_tp,\r\ncur->bc_private.a.agbp, cur->bc_private.a.agno,\r\ncur->bc_btnum);\r\n}\r\nSTATIC void\r\nxfs_inobt_set_root(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *nptr,\r\nint inc)\r\n{\r\nstruct xfs_buf *agbp = cur->bc_private.a.agbp;\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nagi->agi_root = nptr->s;\r\nbe32_add_cpu(&agi->agi_level, inc);\r\nxfs_ialloc_log_agi(cur->bc_tp, agbp, XFS_AGI_ROOT | XFS_AGI_LEVEL);\r\n}\r\nSTATIC void\r\nxfs_finobt_set_root(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *nptr,\r\nint inc)\r\n{\r\nstruct xfs_buf *agbp = cur->bc_private.a.agbp;\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nagi->agi_free_root = nptr->s;\r\nbe32_add_cpu(&agi->agi_free_level, inc);\r\nxfs_ialloc_log_agi(cur->bc_tp, agbp,\r\nXFS_AGI_FREE_ROOT | XFS_AGI_FREE_LEVEL);\r\n}\r\nSTATIC int\r\n__xfs_inobt_alloc_block(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *start,\r\nunion xfs_btree_ptr *new,\r\nint *stat,\r\nenum xfs_ag_resv_type resv)\r\n{\r\nxfs_alloc_arg_t args;\r\nint error;\r\nxfs_agblock_t sbno = be32_to_cpu(start->s);\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nmemset(&args, 0, sizeof(args));\r\nargs.tp = cur->bc_tp;\r\nargs.mp = cur->bc_mp;\r\nxfs_rmap_ag_owner(&args.oinfo, XFS_RMAP_OWN_INOBT);\r\nargs.fsbno = XFS_AGB_TO_FSB(args.mp, cur->bc_private.a.agno, sbno);\r\nargs.minlen = 1;\r\nargs.maxlen = 1;\r\nargs.prod = 1;\r\nargs.type = XFS_ALLOCTYPE_NEAR_BNO;\r\nargs.resv = resv;\r\nerror = xfs_alloc_vextent(&args);\r\nif (error) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nif (args.fsbno == NULLFSBLOCK) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\nASSERT(args.len == 1);\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\nnew->s = cpu_to_be32(XFS_FSB_TO_AGBNO(args.mp, args.fsbno));\r\n*stat = 1;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_inobt_alloc_block(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *start,\r\nunion xfs_btree_ptr *new,\r\nint *stat)\r\n{\r\nreturn __xfs_inobt_alloc_block(cur, start, new, stat, XFS_AG_RESV_NONE);\r\n}\r\nSTATIC int\r\nxfs_finobt_alloc_block(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *start,\r\nunion xfs_btree_ptr *new,\r\nint *stat)\r\n{\r\nreturn __xfs_inobt_alloc_block(cur, start, new, stat,\r\nXFS_AG_RESV_METADATA);\r\n}\r\nSTATIC int\r\nxfs_inobt_free_block(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_owner_info oinfo;\r\nxfs_rmap_ag_owner(&oinfo, XFS_RMAP_OWN_INOBT);\r\nreturn xfs_free_extent(cur->bc_tp,\r\nXFS_DADDR_TO_FSB(cur->bc_mp, XFS_BUF_ADDR(bp)), 1,\r\n&oinfo, XFS_AG_RESV_NONE);\r\n}\r\nSTATIC int\r\nxfs_inobt_get_maxrecs(\r\nstruct xfs_btree_cur *cur,\r\nint level)\r\n{\r\nreturn cur->bc_mp->m_inobt_mxr[level != 0];\r\n}\r\nSTATIC void\r\nxfs_inobt_init_key_from_rec(\r\nunion xfs_btree_key *key,\r\nunion xfs_btree_rec *rec)\r\n{\r\nkey->inobt.ir_startino = rec->inobt.ir_startino;\r\n}\r\nSTATIC void\r\nxfs_inobt_init_rec_from_cur(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec *rec)\r\n{\r\nrec->inobt.ir_startino = cpu_to_be32(cur->bc_rec.i.ir_startino);\r\nif (xfs_sb_version_hassparseinodes(&cur->bc_mp->m_sb)) {\r\nrec->inobt.ir_u.sp.ir_holemask =\r\ncpu_to_be16(cur->bc_rec.i.ir_holemask);\r\nrec->inobt.ir_u.sp.ir_count = cur->bc_rec.i.ir_count;\r\nrec->inobt.ir_u.sp.ir_freecount = cur->bc_rec.i.ir_freecount;\r\n} else {\r\nrec->inobt.ir_u.f.ir_freecount =\r\ncpu_to_be32(cur->bc_rec.i.ir_freecount);\r\n}\r\nrec->inobt.ir_free = cpu_to_be64(cur->bc_rec.i.ir_free);\r\n}\r\nSTATIC void\r\nxfs_inobt_init_ptr_from_cur(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr)\r\n{\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(cur->bc_private.a.agbp);\r\nASSERT(cur->bc_private.a.agno == be32_to_cpu(agi->agi_seqno));\r\nptr->s = agi->agi_root;\r\n}\r\nSTATIC void\r\nxfs_finobt_init_ptr_from_cur(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr)\r\n{\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(cur->bc_private.a.agbp);\r\nASSERT(cur->bc_private.a.agno == be32_to_cpu(agi->agi_seqno));\r\nptr->s = agi->agi_free_root;\r\n}\r\nSTATIC __int64_t\r\nxfs_inobt_key_diff(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_key *key)\r\n{\r\nreturn (__int64_t)be32_to_cpu(key->inobt.ir_startino) -\r\ncur->bc_rec.i.ir_startino;\r\n}\r\nstatic int\r\nxfs_inobt_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_btree_block *block = XFS_BUF_TO_BLOCK(bp);\r\nunsigned int level;\r\nswitch (block->bb_magic) {\r\ncase cpu_to_be32(XFS_IBT_CRC_MAGIC):\r\ncase cpu_to_be32(XFS_FIBT_CRC_MAGIC):\r\nif (!xfs_btree_sblock_v5hdr_verify(bp))\r\nreturn false;\r\ncase cpu_to_be32(XFS_IBT_MAGIC):\r\ncase cpu_to_be32(XFS_FIBT_MAGIC):\r\nbreak;\r\ndefault:\r\nreturn 0;\r\n}\r\nlevel = be16_to_cpu(block->bb_level);\r\nif (level >= mp->m_in_maxlevels)\r\nreturn false;\r\nreturn xfs_btree_sblock_verify(bp, mp->m_inobt_mxr[level != 0]);\r\n}\r\nstatic void\r\nxfs_inobt_read_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nif (!xfs_btree_sblock_verify_crc(bp))\r\nxfs_buf_ioerror(bp, -EFSBADCRC);\r\nelse if (!xfs_inobt_verify(bp))\r\nxfs_buf_ioerror(bp, -EFSCORRUPTED);\r\nif (bp->b_error) {\r\ntrace_xfs_btree_corrupt(bp, _RET_IP_);\r\nxfs_verifier_error(bp);\r\n}\r\n}\r\nstatic void\r\nxfs_inobt_write_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nif (!xfs_inobt_verify(bp)) {\r\ntrace_xfs_btree_corrupt(bp, _RET_IP_);\r\nxfs_buf_ioerror(bp, -EFSCORRUPTED);\r\nxfs_verifier_error(bp);\r\nreturn;\r\n}\r\nxfs_btree_sblock_calc_crc(bp);\r\n}\r\nSTATIC int\r\nxfs_inobt_keys_inorder(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_key *k1,\r\nunion xfs_btree_key *k2)\r\n{\r\nreturn be32_to_cpu(k1->inobt.ir_startino) <\r\nbe32_to_cpu(k2->inobt.ir_startino);\r\n}\r\nSTATIC int\r\nxfs_inobt_recs_inorder(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec *r1,\r\nunion xfs_btree_rec *r2)\r\n{\r\nreturn be32_to_cpu(r1->inobt.ir_startino) + XFS_INODES_PER_CHUNK <=\r\nbe32_to_cpu(r2->inobt.ir_startino);\r\n}\r\nstruct xfs_btree_cur *\r\nxfs_inobt_init_cursor(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nxfs_agnumber_t agno,\r\nxfs_btnum_t btnum)\r\n{\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nstruct xfs_btree_cur *cur;\r\ncur = kmem_zone_zalloc(xfs_btree_cur_zone, KM_NOFS);\r\ncur->bc_tp = tp;\r\ncur->bc_mp = mp;\r\ncur->bc_btnum = btnum;\r\nif (btnum == XFS_BTNUM_INO) {\r\ncur->bc_nlevels = be32_to_cpu(agi->agi_level);\r\ncur->bc_ops = &xfs_inobt_ops;\r\ncur->bc_statoff = XFS_STATS_CALC_INDEX(xs_ibt_2);\r\n} else {\r\ncur->bc_nlevels = be32_to_cpu(agi->agi_free_level);\r\ncur->bc_ops = &xfs_finobt_ops;\r\ncur->bc_statoff = XFS_STATS_CALC_INDEX(xs_fibt_2);\r\n}\r\ncur->bc_blocklog = mp->m_sb.sb_blocklog;\r\nif (xfs_sb_version_hascrc(&mp->m_sb))\r\ncur->bc_flags |= XFS_BTREE_CRC_BLOCKS;\r\ncur->bc_private.a.agbp = agbp;\r\ncur->bc_private.a.agno = agno;\r\nreturn cur;\r\n}\r\nint\r\nxfs_inobt_maxrecs(\r\nstruct xfs_mount *mp,\r\nint blocklen,\r\nint leaf)\r\n{\r\nblocklen -= XFS_INOBT_BLOCK_LEN(mp);\r\nif (leaf)\r\nreturn blocklen / sizeof(xfs_inobt_rec_t);\r\nreturn blocklen / (sizeof(xfs_inobt_key_t) + sizeof(xfs_inobt_ptr_t));\r\n}\r\nuint64_t\r\nxfs_inobt_irec_to_allocmask(\r\nstruct xfs_inobt_rec_incore *rec)\r\n{\r\nuint64_t bitmap = 0;\r\nuint64_t inodespbit;\r\nint nextbit;\r\nuint allocbitmap;\r\ninodespbit = (1 << XFS_INODES_PER_HOLEMASK_BIT) - 1;\r\nallocbitmap = ~rec->ir_holemask & ((1 << XFS_INOBT_HOLEMASK_BITS) - 1);\r\nnextbit = xfs_next_bit(&allocbitmap, 1, 0);\r\nwhile (nextbit != -1) {\r\nASSERT(nextbit < (sizeof(rec->ir_holemask) * NBBY));\r\nbitmap |= (inodespbit <<\r\n(nextbit * XFS_INODES_PER_HOLEMASK_BIT));\r\nnextbit = xfs_next_bit(&allocbitmap, 1, nextbit + 1);\r\n}\r\nreturn bitmap;\r\n}\r\nint\r\nxfs_inobt_rec_check_count(\r\nstruct xfs_mount *mp,\r\nstruct xfs_inobt_rec_incore *rec)\r\n{\r\nint inocount = 0;\r\nint nextbit = 0;\r\nuint64_t allocbmap;\r\nint wordsz;\r\nwordsz = sizeof(allocbmap) / sizeof(unsigned int);\r\nallocbmap = xfs_inobt_irec_to_allocmask(rec);\r\nnextbit = xfs_next_bit((uint *) &allocbmap, wordsz, nextbit);\r\nwhile (nextbit != -1) {\r\ninocount++;\r\nnextbit = xfs_next_bit((uint *) &allocbmap, wordsz,\r\nnextbit + 1);\r\n}\r\nif (inocount != rec->ir_count)\r\nreturn -EFSCORRUPTED;\r\nreturn 0;\r\n}\r\nstatic xfs_extlen_t\r\nxfs_inobt_max_size(\r\nstruct xfs_mount *mp)\r\n{\r\nif (mp->m_inobt_mxr[0] == 0)\r\nreturn 0;\r\nreturn xfs_btree_calc_size(mp, mp->m_inobt_mnr,\r\n(uint64_t)mp->m_sb.sb_agblocks * mp->m_sb.sb_inopblock /\r\nXFS_INODES_PER_CHUNK);\r\n}\r\nstatic int\r\nxfs_inobt_count_blocks(\r\nstruct xfs_mount *mp,\r\nxfs_agnumber_t agno,\r\nxfs_btnum_t btnum,\r\nxfs_extlen_t *tree_blocks)\r\n{\r\nstruct xfs_buf *agbp;\r\nstruct xfs_btree_cur *cur;\r\nint error;\r\nerror = xfs_ialloc_read_agi(mp, NULL, agno, &agbp);\r\nif (error)\r\nreturn error;\r\ncur = xfs_inobt_init_cursor(mp, NULL, agbp, agno, btnum);\r\nerror = xfs_btree_count_blocks(cur, tree_blocks);\r\nxfs_btree_del_cursor(cur, error ? XFS_BTREE_ERROR : XFS_BTREE_NOERROR);\r\nxfs_buf_relse(agbp);\r\nreturn error;\r\n}\r\nint\r\nxfs_finobt_calc_reserves(\r\nstruct xfs_mount *mp,\r\nxfs_agnumber_t agno,\r\nxfs_extlen_t *ask,\r\nxfs_extlen_t *used)\r\n{\r\nxfs_extlen_t tree_len = 0;\r\nint error;\r\nif (!xfs_sb_version_hasfinobt(&mp->m_sb))\r\nreturn 0;\r\nerror = xfs_inobt_count_blocks(mp, agno, XFS_BTNUM_FINO, &tree_len);\r\nif (error)\r\nreturn error;\r\n*ask += xfs_inobt_max_size(mp);\r\n*used += tree_len;\r\nreturn 0;\r\n}
