bool vmci_guest_code_active(void)\r\n{\r\nreturn atomic_read(&vmci_num_guest_devices) != 0;\r\n}\r\nu32 vmci_get_vm_context_id(void)\r\n{\r\nif (vm_context_id == VMCI_INVALID_ID) {\r\nstruct vmci_datagram get_cid_msg;\r\nget_cid_msg.dst =\r\nvmci_make_handle(VMCI_HYPERVISOR_CONTEXT_ID,\r\nVMCI_GET_CONTEXT_ID);\r\nget_cid_msg.src = VMCI_ANON_SRC_HANDLE;\r\nget_cid_msg.payload_size = 0;\r\nvm_context_id = vmci_send_datagram(&get_cid_msg);\r\n}\r\nreturn vm_context_id;\r\n}\r\nint vmci_send_datagram(struct vmci_datagram *dg)\r\n{\r\nunsigned long flags;\r\nint result;\r\nif (dg == NULL)\r\nreturn VMCI_ERROR_INVALID_ARGS;\r\nspin_lock_irqsave(&vmci_dev_spinlock, flags);\r\nif (vmci_dev_g) {\r\niowrite8_rep(vmci_dev_g->iobase + VMCI_DATA_OUT_ADDR,\r\ndg, VMCI_DG_SIZE(dg));\r\nresult = ioread32(vmci_dev_g->iobase + VMCI_RESULT_LOW_ADDR);\r\n} else {\r\nresult = VMCI_ERROR_UNAVAILABLE;\r\n}\r\nspin_unlock_irqrestore(&vmci_dev_spinlock, flags);\r\nreturn result;\r\n}\r\nstatic void vmci_guest_cid_update(u32 sub_id,\r\nconst struct vmci_event_data *event_data,\r\nvoid *client_data)\r\n{\r\nconst struct vmci_event_payld_ctx *ev_payload =\r\nvmci_event_data_const_payload(event_data);\r\nif (sub_id != ctx_update_sub_id) {\r\npr_devel("Invalid subscriber (ID=0x%x)\n", sub_id);\r\nreturn;\r\n}\r\nif (!event_data || ev_payload->context_id == VMCI_INVALID_ID) {\r\npr_devel("Invalid event data\n");\r\nreturn;\r\n}\r\npr_devel("Updating context from (ID=0x%x) to (ID=0x%x) on event (type=%d)\n",\r\nvm_context_id, ev_payload->context_id, event_data->event);\r\nvm_context_id = ev_payload->context_id;\r\n}\r\nstatic int vmci_check_host_caps(struct pci_dev *pdev)\r\n{\r\nbool result;\r\nstruct vmci_resource_query_msg *msg;\r\nu32 msg_size = sizeof(struct vmci_resource_query_hdr) +\r\nVMCI_UTIL_NUM_RESOURCES * sizeof(u32);\r\nstruct vmci_datagram *check_msg;\r\ncheck_msg = kmalloc(msg_size, GFP_KERNEL);\r\nif (!check_msg) {\r\ndev_err(&pdev->dev, "%s: Insufficient memory\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\ncheck_msg->dst = vmci_make_handle(VMCI_HYPERVISOR_CONTEXT_ID,\r\nVMCI_RESOURCES_QUERY);\r\ncheck_msg->src = VMCI_ANON_SRC_HANDLE;\r\ncheck_msg->payload_size = msg_size - VMCI_DG_HEADERSIZE;\r\nmsg = (struct vmci_resource_query_msg *)VMCI_DG_PAYLOAD(check_msg);\r\nmsg->num_resources = VMCI_UTIL_NUM_RESOURCES;\r\nmsg->resources[0] = VMCI_GET_CONTEXT_ID;\r\nresult = vmci_send_datagram(check_msg) == 0x01;\r\nkfree(check_msg);\r\ndev_dbg(&pdev->dev, "%s: Host capability check: %s\n",\r\n__func__, result ? "PASSED" : "FAILED");\r\nreturn result ? 0 : -ENXIO;\r\n}\r\nstatic void vmci_dispatch_dgs(unsigned long data)\r\n{\r\nstruct vmci_guest_device *vmci_dev = (struct vmci_guest_device *)data;\r\nu8 *dg_in_buffer = vmci_dev->data_buffer;\r\nstruct vmci_datagram *dg;\r\nsize_t dg_in_buffer_size = VMCI_MAX_DG_SIZE;\r\nsize_t current_dg_in_buffer_size = PAGE_SIZE;\r\nsize_t remaining_bytes;\r\nBUILD_BUG_ON(VMCI_MAX_DG_SIZE < PAGE_SIZE);\r\nioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,\r\nvmci_dev->data_buffer, current_dg_in_buffer_size);\r\ndg = (struct vmci_datagram *)dg_in_buffer;\r\nremaining_bytes = current_dg_in_buffer_size;\r\nwhile (dg->dst.resource != VMCI_INVALID_ID ||\r\nremaining_bytes > PAGE_SIZE) {\r\nunsigned dg_in_size;\r\nif (dg->dst.resource == VMCI_INVALID_ID) {\r\ndg = (struct vmci_datagram *)roundup(\r\n(uintptr_t)dg + 1, PAGE_SIZE);\r\nremaining_bytes =\r\n(size_t)(dg_in_buffer +\r\ncurrent_dg_in_buffer_size -\r\n(u8 *)dg);\r\ncontinue;\r\n}\r\ndg_in_size = VMCI_DG_SIZE_ALIGNED(dg);\r\nif (dg_in_size <= dg_in_buffer_size) {\r\nint result;\r\nif (dg_in_size > remaining_bytes) {\r\nif (remaining_bytes !=\r\ncurrent_dg_in_buffer_size) {\r\nmemmove(dg_in_buffer, dg_in_buffer +\r\ncurrent_dg_in_buffer_size -\r\nremaining_bytes,\r\nremaining_bytes);\r\ndg = (struct vmci_datagram *)\r\ndg_in_buffer;\r\n}\r\nif (current_dg_in_buffer_size !=\r\ndg_in_buffer_size)\r\ncurrent_dg_in_buffer_size =\r\ndg_in_buffer_size;\r\nioread8_rep(vmci_dev->iobase +\r\nVMCI_DATA_IN_ADDR,\r\nvmci_dev->data_buffer +\r\nremaining_bytes,\r\ncurrent_dg_in_buffer_size -\r\nremaining_bytes);\r\n}\r\nif (dg->src.context == VMCI_HYPERVISOR_CONTEXT_ID &&\r\ndg->dst.resource == VMCI_EVENT_HANDLER) {\r\nresult = vmci_event_dispatch(dg);\r\n} else {\r\nresult = vmci_datagram_invoke_guest_handler(dg);\r\n}\r\nif (result < VMCI_SUCCESS)\r\ndev_dbg(vmci_dev->dev,\r\n"Datagram with resource (ID=0x%x) failed (err=%d)\n",\r\ndg->dst.resource, result);\r\ndg = (struct vmci_datagram *)((u8 *)dg +\r\ndg_in_size);\r\n} else {\r\nsize_t bytes_to_skip;\r\ndev_dbg(vmci_dev->dev,\r\n"Failed to receive datagram (size=%u bytes)\n",\r\ndg_in_size);\r\nbytes_to_skip = dg_in_size - remaining_bytes;\r\nif (current_dg_in_buffer_size != dg_in_buffer_size)\r\ncurrent_dg_in_buffer_size = dg_in_buffer_size;\r\nfor (;;) {\r\nioread8_rep(vmci_dev->iobase +\r\nVMCI_DATA_IN_ADDR,\r\nvmci_dev->data_buffer,\r\ncurrent_dg_in_buffer_size);\r\nif (bytes_to_skip <= current_dg_in_buffer_size)\r\nbreak;\r\nbytes_to_skip -= current_dg_in_buffer_size;\r\n}\r\ndg = (struct vmci_datagram *)(dg_in_buffer +\r\nbytes_to_skip);\r\n}\r\nremaining_bytes =\r\n(size_t) (dg_in_buffer + current_dg_in_buffer_size -\r\n(u8 *)dg);\r\nif (remaining_bytes < VMCI_DG_HEADERSIZE) {\r\nioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,\r\nvmci_dev->data_buffer,\r\ncurrent_dg_in_buffer_size);\r\ndg = (struct vmci_datagram *)dg_in_buffer;\r\nremaining_bytes = current_dg_in_buffer_size;\r\n}\r\n}\r\n}\r\nstatic void vmci_process_bitmap(unsigned long data)\r\n{\r\nstruct vmci_guest_device *dev = (struct vmci_guest_device *)data;\r\nif (!dev->notification_bitmap) {\r\ndev_dbg(dev->dev, "No bitmap present in %s\n", __func__);\r\nreturn;\r\n}\r\nvmci_dbell_scan_notification_entries(dev->notification_bitmap);\r\n}\r\nstatic irqreturn_t vmci_interrupt(int irq, void *_dev)\r\n{\r\nstruct vmci_guest_device *dev = _dev;\r\nif (dev->exclusive_vectors) {\r\ntasklet_schedule(&dev->datagram_tasklet);\r\n} else {\r\nunsigned int icr;\r\nicr = ioread32(dev->iobase + VMCI_ICR_ADDR);\r\nif (icr == 0 || icr == ~0)\r\nreturn IRQ_NONE;\r\nif (icr & VMCI_ICR_DATAGRAM) {\r\ntasklet_schedule(&dev->datagram_tasklet);\r\nicr &= ~VMCI_ICR_DATAGRAM;\r\n}\r\nif (icr & VMCI_ICR_NOTIFICATION) {\r\ntasklet_schedule(&dev->bm_tasklet);\r\nicr &= ~VMCI_ICR_NOTIFICATION;\r\n}\r\nif (icr != 0)\r\ndev_warn(dev->dev,\r\n"Ignoring unknown interrupt cause (%d)\n",\r\nicr);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t vmci_interrupt_bm(int irq, void *_dev)\r\n{\r\nstruct vmci_guest_device *dev = _dev;\r\ntasklet_schedule(&dev->bm_tasklet);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int vmci_guest_probe_device(struct pci_dev *pdev,\r\nconst struct pci_device_id *id)\r\n{\r\nstruct vmci_guest_device *vmci_dev;\r\nvoid __iomem *iobase;\r\nunsigned int capabilities;\r\nunsigned long cmd;\r\nint vmci_err;\r\nint error;\r\ndev_dbg(&pdev->dev, "Probing for vmci/PCI guest device\n");\r\nerror = pcim_enable_device(pdev);\r\nif (error) {\r\ndev_err(&pdev->dev,\r\n"Failed to enable VMCI device: %d\n", error);\r\nreturn error;\r\n}\r\nerror = pcim_iomap_regions(pdev, 1 << 0, KBUILD_MODNAME);\r\nif (error) {\r\ndev_err(&pdev->dev, "Failed to reserve/map IO regions\n");\r\nreturn error;\r\n}\r\niobase = pcim_iomap_table(pdev)[0];\r\ndev_info(&pdev->dev, "Found VMCI PCI device at %#lx, irq %u\n",\r\n(unsigned long)iobase, pdev->irq);\r\nvmci_dev = devm_kzalloc(&pdev->dev, sizeof(*vmci_dev), GFP_KERNEL);\r\nif (!vmci_dev) {\r\ndev_err(&pdev->dev,\r\n"Can't allocate memory for VMCI device\n");\r\nreturn -ENOMEM;\r\n}\r\nvmci_dev->dev = &pdev->dev;\r\nvmci_dev->exclusive_vectors = false;\r\nvmci_dev->iobase = iobase;\r\ntasklet_init(&vmci_dev->datagram_tasklet,\r\nvmci_dispatch_dgs, (unsigned long)vmci_dev);\r\ntasklet_init(&vmci_dev->bm_tasklet,\r\nvmci_process_bitmap, (unsigned long)vmci_dev);\r\nvmci_dev->data_buffer = vmalloc(VMCI_MAX_DG_SIZE);\r\nif (!vmci_dev->data_buffer) {\r\ndev_err(&pdev->dev,\r\n"Can't allocate memory for datagram buffer\n");\r\nreturn -ENOMEM;\r\n}\r\npci_set_master(pdev);\r\ncapabilities = ioread32(vmci_dev->iobase + VMCI_CAPS_ADDR);\r\nif (!(capabilities & VMCI_CAPS_DATAGRAM)) {\r\ndev_err(&pdev->dev, "Device does not support datagrams\n");\r\nerror = -ENXIO;\r\ngoto err_free_data_buffer;\r\n}\r\nif (capabilities & VMCI_CAPS_NOTIFICATIONS) {\r\nvmci_dev->notification_bitmap = dma_alloc_coherent(\r\n&pdev->dev, PAGE_SIZE, &vmci_dev->notification_base,\r\nGFP_KERNEL);\r\nif (!vmci_dev->notification_bitmap) {\r\ndev_warn(&pdev->dev,\r\n"Unable to allocate notification bitmap\n");\r\n} else {\r\nmemset(vmci_dev->notification_bitmap, 0, PAGE_SIZE);\r\ncapabilities |= VMCI_CAPS_NOTIFICATIONS;\r\n}\r\n}\r\ndev_info(&pdev->dev, "Using capabilities 0x%x\n", capabilities);\r\niowrite32(capabilities, vmci_dev->iobase + VMCI_CAPS_ADDR);\r\nspin_lock_irq(&vmci_dev_spinlock);\r\nvmci_dev_g = vmci_dev;\r\nvmci_pdev = pdev;\r\nspin_unlock_irq(&vmci_dev_spinlock);\r\nif (capabilities & VMCI_CAPS_NOTIFICATIONS) {\r\nunsigned long bitmap_ppn =\r\nvmci_dev->notification_base >> PAGE_SHIFT;\r\nif (!vmci_dbell_register_notification_bitmap(bitmap_ppn)) {\r\ndev_warn(&pdev->dev,\r\n"VMCI device unable to register notification bitmap with PPN 0x%x\n",\r\n(u32) bitmap_ppn);\r\nerror = -ENXIO;\r\ngoto err_remove_vmci_dev_g;\r\n}\r\n}\r\nerror = vmci_check_host_caps(pdev);\r\nif (error)\r\ngoto err_remove_bitmap;\r\nvmci_err = vmci_event_subscribe(VMCI_EVENT_CTX_ID_UPDATE,\r\nvmci_guest_cid_update, NULL,\r\n&ctx_update_sub_id);\r\nif (vmci_err < VMCI_SUCCESS)\r\ndev_warn(&pdev->dev,\r\n"Failed to subscribe to event (type=%d): %d\n",\r\nVMCI_EVENT_CTX_ID_UPDATE, vmci_err);\r\nerror = pci_alloc_irq_vectors(pdev, VMCI_MAX_INTRS, VMCI_MAX_INTRS,\r\nPCI_IRQ_MSIX);\r\nif (error < 0) {\r\nerror = pci_alloc_irq_vectors(pdev, 1, 1,\r\nPCI_IRQ_MSIX | PCI_IRQ_MSI | PCI_IRQ_LEGACY);\r\nif (error < 0)\r\ngoto err_remove_bitmap;\r\n} else {\r\nvmci_dev->exclusive_vectors = true;\r\n}\r\nerror = request_irq(pci_irq_vector(pdev, 0), vmci_interrupt,\r\nIRQF_SHARED, KBUILD_MODNAME, vmci_dev);\r\nif (error) {\r\ndev_err(&pdev->dev, "Irq %u in use: %d\n",\r\npci_irq_vector(pdev, 0), error);\r\ngoto err_disable_msi;\r\n}\r\nif (vmci_dev->exclusive_vectors) {\r\nerror = request_irq(pci_irq_vector(pdev, 1),\r\nvmci_interrupt_bm, 0, KBUILD_MODNAME,\r\nvmci_dev);\r\nif (error) {\r\ndev_err(&pdev->dev,\r\n"Failed to allocate irq %u: %d\n",\r\npci_irq_vector(pdev, 1), error);\r\ngoto err_free_irq;\r\n}\r\n}\r\ndev_dbg(&pdev->dev, "Registered device\n");\r\natomic_inc(&vmci_num_guest_devices);\r\ncmd = VMCI_IMR_DATAGRAM;\r\nif (capabilities & VMCI_CAPS_NOTIFICATIONS)\r\ncmd |= VMCI_IMR_NOTIFICATION;\r\niowrite32(cmd, vmci_dev->iobase + VMCI_IMR_ADDR);\r\niowrite32(VMCI_CONTROL_INT_ENABLE,\r\nvmci_dev->iobase + VMCI_CONTROL_ADDR);\r\npci_set_drvdata(pdev, vmci_dev);\r\nreturn 0;\r\nerr_free_irq:\r\nfree_irq(pci_irq_vector(pdev, 0), vmci_dev);\r\ntasklet_kill(&vmci_dev->datagram_tasklet);\r\ntasklet_kill(&vmci_dev->bm_tasklet);\r\nerr_disable_msi:\r\npci_free_irq_vectors(pdev);\r\nvmci_err = vmci_event_unsubscribe(ctx_update_sub_id);\r\nif (vmci_err < VMCI_SUCCESS)\r\ndev_warn(&pdev->dev,\r\n"Failed to unsubscribe from event (type=%d) with subscriber (ID=0x%x): %d\n",\r\nVMCI_EVENT_CTX_ID_UPDATE, ctx_update_sub_id, vmci_err);\r\nerr_remove_bitmap:\r\nif (vmci_dev->notification_bitmap) {\r\niowrite32(VMCI_CONTROL_RESET,\r\nvmci_dev->iobase + VMCI_CONTROL_ADDR);\r\ndma_free_coherent(&pdev->dev, PAGE_SIZE,\r\nvmci_dev->notification_bitmap,\r\nvmci_dev->notification_base);\r\n}\r\nerr_remove_vmci_dev_g:\r\nspin_lock_irq(&vmci_dev_spinlock);\r\nvmci_pdev = NULL;\r\nvmci_dev_g = NULL;\r\nspin_unlock_irq(&vmci_dev_spinlock);\r\nerr_free_data_buffer:\r\nvfree(vmci_dev->data_buffer);\r\nreturn error;\r\n}\r\nstatic void vmci_guest_remove_device(struct pci_dev *pdev)\r\n{\r\nstruct vmci_guest_device *vmci_dev = pci_get_drvdata(pdev);\r\nint vmci_err;\r\ndev_dbg(&pdev->dev, "Removing device\n");\r\natomic_dec(&vmci_num_guest_devices);\r\nvmci_qp_guest_endpoints_exit();\r\nvmci_err = vmci_event_unsubscribe(ctx_update_sub_id);\r\nif (vmci_err < VMCI_SUCCESS)\r\ndev_warn(&pdev->dev,\r\n"Failed to unsubscribe from event (type=%d) with subscriber (ID=0x%x): %d\n",\r\nVMCI_EVENT_CTX_ID_UPDATE, ctx_update_sub_id, vmci_err);\r\nspin_lock_irq(&vmci_dev_spinlock);\r\nvmci_dev_g = NULL;\r\nvmci_pdev = NULL;\r\nspin_unlock_irq(&vmci_dev_spinlock);\r\ndev_dbg(&pdev->dev, "Resetting vmci device\n");\r\niowrite32(VMCI_CONTROL_RESET, vmci_dev->iobase + VMCI_CONTROL_ADDR);\r\nif (vmci_dev->exclusive_vectors)\r\nfree_irq(pci_irq_vector(pdev, 1), vmci_dev);\r\nfree_irq(pci_irq_vector(pdev, 0), vmci_dev);\r\npci_free_irq_vectors(pdev);\r\ntasklet_kill(&vmci_dev->datagram_tasklet);\r\ntasklet_kill(&vmci_dev->bm_tasklet);\r\nif (vmci_dev->notification_bitmap) {\r\ndma_free_coherent(&pdev->dev, PAGE_SIZE,\r\nvmci_dev->notification_bitmap,\r\nvmci_dev->notification_base);\r\n}\r\nvfree(vmci_dev->data_buffer);\r\n}\r\nint __init vmci_guest_init(void)\r\n{\r\nreturn pci_register_driver(&vmci_guest_driver);\r\n}\r\nvoid __exit vmci_guest_exit(void)\r\n{\r\npci_unregister_driver(&vmci_guest_driver);\r\n}
