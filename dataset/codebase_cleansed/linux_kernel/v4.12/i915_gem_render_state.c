static const struct intel_renderstate_rodata *\r\nrender_state_get_rodata(const struct intel_engine_cs *engine)\r\n{\r\nswitch (INTEL_GEN(engine->i915)) {\r\ncase 6:\r\nreturn &gen6_null_state;\r\ncase 7:\r\nreturn &gen7_null_state;\r\ncase 8:\r\nreturn &gen8_null_state;\r\ncase 9:\r\nreturn &gen9_null_state;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int render_state_setup(struct intel_render_state *so,\r\nstruct drm_i915_private *i915)\r\n{\r\nconst struct intel_renderstate_rodata *rodata = so->rodata;\r\nstruct drm_i915_gem_object *obj = so->vma->obj;\r\nunsigned int i = 0, reloc_index = 0;\r\nunsigned int needs_clflush;\r\nu32 *d;\r\nint ret;\r\nret = i915_gem_obj_prepare_shmem_write(obj, &needs_clflush);\r\nif (ret)\r\nreturn ret;\r\nd = kmap_atomic(i915_gem_object_get_dirty_page(obj, 0));\r\nwhile (i < rodata->batch_items) {\r\nu32 s = rodata->batch[i];\r\nif (i * 4 == rodata->reloc[reloc_index]) {\r\nu64 r = s + so->vma->node.start;\r\ns = lower_32_bits(r);\r\nif (HAS_64BIT_RELOC(i915)) {\r\nif (i + 1 >= rodata->batch_items ||\r\nrodata->batch[i + 1] != 0)\r\ngoto err;\r\nd[i++] = s;\r\ns = upper_32_bits(r);\r\n}\r\nreloc_index++;\r\n}\r\nd[i++] = s;\r\n}\r\nif (rodata->reloc[reloc_index] != -1) {\r\nDRM_ERROR("only %d relocs resolved\n", reloc_index);\r\ngoto err;\r\n}\r\nso->batch_offset = so->vma->node.start;\r\nso->batch_size = rodata->batch_items * sizeof(u32);\r\nwhile (i % CACHELINE_DWORDS)\r\nOUT_BATCH(d, i, MI_NOOP);\r\nso->aux_offset = i * sizeof(u32);\r\nif (HAS_POOLED_EU(i915)) {\r\nu32 eu_pool_config = 0x00777000;\r\nOUT_BATCH(d, i, GEN9_MEDIA_POOL_STATE);\r\nOUT_BATCH(d, i, GEN9_MEDIA_POOL_ENABLE);\r\nOUT_BATCH(d, i, eu_pool_config);\r\nOUT_BATCH(d, i, 0);\r\nOUT_BATCH(d, i, 0);\r\nOUT_BATCH(d, i, 0);\r\n}\r\nOUT_BATCH(d, i, MI_BATCH_BUFFER_END);\r\nso->aux_size = i * sizeof(u32) - so->aux_offset;\r\nso->aux_offset += so->batch_offset;\r\nso->aux_size = ALIGN(so->aux_size, 8);\r\nif (needs_clflush)\r\ndrm_clflush_virt_range(d, i * sizeof(u32));\r\nkunmap_atomic(d);\r\nret = i915_gem_object_set_to_gtt_domain(obj, false);\r\nout:\r\ni915_gem_obj_finish_shmem_access(obj);\r\nreturn ret;\r\nerr:\r\nkunmap_atomic(d);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nint i915_gem_render_state_init(struct intel_engine_cs *engine)\r\n{\r\nstruct intel_render_state *so;\r\nconst struct intel_renderstate_rodata *rodata;\r\nstruct drm_i915_gem_object *obj;\r\nint ret;\r\nif (engine->id != RCS)\r\nreturn 0;\r\nrodata = render_state_get_rodata(engine);\r\nif (!rodata)\r\nreturn 0;\r\nif (rodata->batch_items * 4 > PAGE_SIZE)\r\nreturn -EINVAL;\r\nso = kmalloc(sizeof(*so), GFP_KERNEL);\r\nif (!so)\r\nreturn -ENOMEM;\r\nobj = i915_gem_object_create_internal(engine->i915, PAGE_SIZE);\r\nif (IS_ERR(obj)) {\r\nret = PTR_ERR(obj);\r\ngoto err_free;\r\n}\r\nso->vma = i915_vma_instance(obj, &engine->i915->ggtt.base, NULL);\r\nif (IS_ERR(so->vma)) {\r\nret = PTR_ERR(so->vma);\r\ngoto err_obj;\r\n}\r\nso->rodata = rodata;\r\nengine->render_state = so;\r\nreturn 0;\r\nerr_obj:\r\ni915_gem_object_put(obj);\r\nerr_free:\r\nkfree(so);\r\nreturn ret;\r\n}\r\nint i915_gem_render_state_emit(struct drm_i915_gem_request *req)\r\n{\r\nstruct intel_render_state *so;\r\nint ret;\r\nlockdep_assert_held(&req->i915->drm.struct_mutex);\r\nso = req->engine->render_state;\r\nif (!so)\r\nreturn 0;\r\nif (!so->vma->obj->mm.pages)\r\nso->batch_offset = -1;\r\nret = i915_vma_pin(so->vma, 0, 0, PIN_GLOBAL | PIN_HIGH);\r\nif (ret)\r\nreturn ret;\r\nif (so->vma->node.start != so->batch_offset) {\r\nret = render_state_setup(so, req->i915);\r\nif (ret)\r\ngoto err_unpin;\r\n}\r\nret = req->engine->emit_bb_start(req,\r\nso->batch_offset, so->batch_size,\r\nI915_DISPATCH_SECURE);\r\nif (ret)\r\ngoto err_unpin;\r\nif (so->aux_size > 8) {\r\nret = req->engine->emit_bb_start(req,\r\nso->aux_offset, so->aux_size,\r\nI915_DISPATCH_SECURE);\r\nif (ret)\r\ngoto err_unpin;\r\n}\r\ni915_vma_move_to_active(so->vma, req, 0);\r\nerr_unpin:\r\ni915_vma_unpin(so->vma);\r\nreturn ret;\r\n}\r\nvoid i915_gem_render_state_fini(struct intel_engine_cs *engine)\r\n{\r\nstruct intel_render_state *so;\r\nstruct drm_i915_gem_object *obj;\r\nso = fetch_and_zero(&engine->render_state);\r\nif (!so)\r\nreturn;\r\nobj = so->vma->obj;\r\ni915_vma_close(so->vma);\r\n__i915_gem_object_release_unless_active(obj);\r\nkfree(so);\r\n}
