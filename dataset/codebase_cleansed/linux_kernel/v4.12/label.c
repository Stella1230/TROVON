static u32 best_seq(u32 a, u32 b)\r\n{\r\na &= NSINDEX_SEQ_MASK;\r\nb &= NSINDEX_SEQ_MASK;\r\nif (a == 0 || a == b)\r\nreturn b;\r\nelse if (b == 0)\r\nreturn a;\r\nelse if (nd_inc_seq(a) == b)\r\nreturn b;\r\nelse\r\nreturn a;\r\n}\r\nsize_t sizeof_namespace_index(struct nvdimm_drvdata *ndd)\r\n{\r\nu32 index_span;\r\nif (ndd->nsindex_size)\r\nreturn ndd->nsindex_size;\r\nindex_span = ndd->nsarea.config_size / 129;\r\nindex_span /= NSINDEX_ALIGN * 2;\r\nndd->nsindex_size = index_span * NSINDEX_ALIGN;\r\nreturn ndd->nsindex_size;\r\n}\r\nint nvdimm_num_label_slots(struct nvdimm_drvdata *ndd)\r\n{\r\nreturn ndd->nsarea.config_size / 129;\r\n}\r\nint nd_label_validate(struct nvdimm_drvdata *ndd)\r\n{\r\nstruct nd_namespace_index *nsindex[] = {\r\nto_namespace_index(ndd, 0),\r\nto_namespace_index(ndd, 1),\r\n};\r\nconst int num_index = ARRAY_SIZE(nsindex);\r\nstruct device *dev = ndd->dev;\r\nbool valid[2] = { 0 };\r\nint i, num_valid = 0;\r\nu32 seq;\r\nfor (i = 0; i < num_index; i++) {\r\nu32 nslot;\r\nu8 sig[NSINDEX_SIG_LEN];\r\nu64 sum_save, sum, size;\r\nmemcpy(sig, nsindex[i]->sig, NSINDEX_SIG_LEN);\r\nif (memcmp(sig, NSINDEX_SIGNATURE, NSINDEX_SIG_LEN) != 0) {\r\ndev_dbg(dev, "%s: nsindex%d signature invalid\n",\r\n__func__, i);\r\ncontinue;\r\n}\r\nsum_save = __le64_to_cpu(nsindex[i]->checksum);\r\nnsindex[i]->checksum = __cpu_to_le64(0);\r\nsum = nd_fletcher64(nsindex[i], sizeof_namespace_index(ndd), 1);\r\nnsindex[i]->checksum = __cpu_to_le64(sum_save);\r\nif (sum != sum_save) {\r\ndev_dbg(dev, "%s: nsindex%d checksum invalid\n",\r\n__func__, i);\r\ncontinue;\r\n}\r\nseq = __le32_to_cpu(nsindex[i]->seq);\r\nif ((seq & NSINDEX_SEQ_MASK) == 0) {\r\ndev_dbg(dev, "%s: nsindex%d sequence: %#x invalid\n",\r\n__func__, i, seq);\r\ncontinue;\r\n}\r\nif (__le64_to_cpu(nsindex[i]->myoff)\r\n!= i * sizeof_namespace_index(ndd)) {\r\ndev_dbg(dev, "%s: nsindex%d myoff: %#llx invalid\n",\r\n__func__, i, (unsigned long long)\r\n__le64_to_cpu(nsindex[i]->myoff));\r\ncontinue;\r\n}\r\nif (__le64_to_cpu(nsindex[i]->otheroff)\r\n!= (!i) * sizeof_namespace_index(ndd)) {\r\ndev_dbg(dev, "%s: nsindex%d otheroff: %#llx invalid\n",\r\n__func__, i, (unsigned long long)\r\n__le64_to_cpu(nsindex[i]->otheroff));\r\ncontinue;\r\n}\r\nsize = __le64_to_cpu(nsindex[i]->mysize);\r\nif (size > sizeof_namespace_index(ndd)\r\n|| size < sizeof(struct nd_namespace_index)) {\r\ndev_dbg(dev, "%s: nsindex%d mysize: %#llx invalid\n",\r\n__func__, i, size);\r\ncontinue;\r\n}\r\nnslot = __le32_to_cpu(nsindex[i]->nslot);\r\nif (nslot * sizeof(struct nd_namespace_label)\r\n+ 2 * sizeof_namespace_index(ndd)\r\n> ndd->nsarea.config_size) {\r\ndev_dbg(dev, "%s: nsindex%d nslot: %u invalid, config_size: %#x\n",\r\n__func__, i, nslot,\r\nndd->nsarea.config_size);\r\ncontinue;\r\n}\r\nvalid[i] = true;\r\nnum_valid++;\r\n}\r\nswitch (num_valid) {\r\ncase 0:\r\nbreak;\r\ncase 1:\r\nfor (i = 0; i < num_index; i++)\r\nif (valid[i])\r\nreturn i;\r\nWARN_ON(1);\r\nbreak;\r\ndefault:\r\nseq = best_seq(__le32_to_cpu(nsindex[0]->seq),\r\n__le32_to_cpu(nsindex[1]->seq));\r\nif (seq == (__le32_to_cpu(nsindex[1]->seq) & NSINDEX_SEQ_MASK))\r\nreturn 1;\r\nelse\r\nreturn 0;\r\nbreak;\r\n}\r\nreturn -1;\r\n}\r\nvoid nd_label_copy(struct nvdimm_drvdata *ndd, struct nd_namespace_index *dst,\r\nstruct nd_namespace_index *src)\r\n{\r\nif (dst && src)\r\n;\r\nelse\r\nreturn;\r\nmemcpy(dst, src, sizeof_namespace_index(ndd));\r\n}\r\nstatic struct nd_namespace_label *nd_label_base(struct nvdimm_drvdata *ndd)\r\n{\r\nvoid *base = to_namespace_index(ndd, 0);\r\nreturn base + 2 * sizeof_namespace_index(ndd);\r\n}\r\nstatic int to_slot(struct nvdimm_drvdata *ndd,\r\nstruct nd_namespace_label *nd_label)\r\n{\r\nreturn nd_label - nd_label_base(ndd);\r\n}\r\nstatic bool preamble_index(struct nvdimm_drvdata *ndd, int idx,\r\nstruct nd_namespace_index **nsindex_out,\r\nunsigned long **free, u32 *nslot)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nnsindex = to_namespace_index(ndd, idx);\r\nif (nsindex == NULL)\r\nreturn false;\r\n*free = (unsigned long *) nsindex->free;\r\n*nslot = __le32_to_cpu(nsindex->nslot);\r\n*nsindex_out = nsindex;\r\nreturn true;\r\n}\r\nchar *nd_label_gen_id(struct nd_label_id *label_id, u8 *uuid, u32 flags)\r\n{\r\nif (!label_id || !uuid)\r\nreturn NULL;\r\nsnprintf(label_id->id, ND_LABEL_ID_SIZE, "%s-%pUb",\r\nflags & NSLABEL_FLAG_LOCAL ? "blk" : "pmem", uuid);\r\nreturn label_id->id;\r\n}\r\nstatic bool preamble_current(struct nvdimm_drvdata *ndd,\r\nstruct nd_namespace_index **nsindex,\r\nunsigned long **free, u32 *nslot)\r\n{\r\nreturn preamble_index(ndd, ndd->ns_current, nsindex,\r\nfree, nslot);\r\n}\r\nstatic bool preamble_next(struct nvdimm_drvdata *ndd,\r\nstruct nd_namespace_index **nsindex,\r\nunsigned long **free, u32 *nslot)\r\n{\r\nreturn preamble_index(ndd, ndd->ns_next, nsindex,\r\nfree, nslot);\r\n}\r\nstatic bool slot_valid(struct nd_namespace_label *nd_label, u32 slot)\r\n{\r\nif (slot != __le32_to_cpu(nd_label->slot))\r\nreturn false;\r\nif ((__le64_to_cpu(nd_label->dpa)\r\n| __le64_to_cpu(nd_label->rawsize)) % SZ_4K)\r\nreturn false;\r\nreturn true;\r\n}\r\nint nd_label_reserve_dpa(struct nvdimm_drvdata *ndd)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long *free;\r\nu32 nslot, slot;\r\nif (!preamble_current(ndd, &nsindex, &free, &nslot))\r\nreturn 0;\r\nfor_each_clear_bit_le(slot, free, nslot) {\r\nstruct nd_namespace_label *nd_label;\r\nstruct nd_region *nd_region = NULL;\r\nu8 label_uuid[NSLABEL_UUID_LEN];\r\nstruct nd_label_id label_id;\r\nstruct resource *res;\r\nu32 flags;\r\nnd_label = nd_label_base(ndd) + slot;\r\nif (!slot_valid(nd_label, slot))\r\ncontinue;\r\nmemcpy(label_uuid, nd_label->uuid, NSLABEL_UUID_LEN);\r\nflags = __le32_to_cpu(nd_label->flags);\r\nnd_label_gen_id(&label_id, label_uuid, flags);\r\nres = nvdimm_allocate_dpa(ndd, &label_id,\r\n__le64_to_cpu(nd_label->dpa),\r\n__le64_to_cpu(nd_label->rawsize));\r\nnd_dbg_dpa(nd_region, ndd, res, "reserve\n");\r\nif (!res)\r\nreturn -EBUSY;\r\n}\r\nreturn 0;\r\n}\r\nint nd_label_active_count(struct nvdimm_drvdata *ndd)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long *free;\r\nu32 nslot, slot;\r\nint count = 0;\r\nif (!preamble_current(ndd, &nsindex, &free, &nslot))\r\nreturn 0;\r\nfor_each_clear_bit_le(slot, free, nslot) {\r\nstruct nd_namespace_label *nd_label;\r\nnd_label = nd_label_base(ndd) + slot;\r\nif (!slot_valid(nd_label, slot)) {\r\nu32 label_slot = __le32_to_cpu(nd_label->slot);\r\nu64 size = __le64_to_cpu(nd_label->rawsize);\r\nu64 dpa = __le64_to_cpu(nd_label->dpa);\r\ndev_dbg(ndd->dev,\r\n"%s: slot%d invalid slot: %d dpa: %llx size: %llx\n",\r\n__func__, slot, label_slot, dpa, size);\r\ncontinue;\r\n}\r\ncount++;\r\n}\r\nreturn count;\r\n}\r\nstruct nd_namespace_label *nd_label_active(struct nvdimm_drvdata *ndd, int n)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long *free;\r\nu32 nslot, slot;\r\nif (!preamble_current(ndd, &nsindex, &free, &nslot))\r\nreturn NULL;\r\nfor_each_clear_bit_le(slot, free, nslot) {\r\nstruct nd_namespace_label *nd_label;\r\nnd_label = nd_label_base(ndd) + slot;\r\nif (!slot_valid(nd_label, slot))\r\ncontinue;\r\nif (n-- == 0)\r\nreturn nd_label_base(ndd) + slot;\r\n}\r\nreturn NULL;\r\n}\r\nu32 nd_label_alloc_slot(struct nvdimm_drvdata *ndd)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long *free;\r\nu32 nslot, slot;\r\nif (!preamble_next(ndd, &nsindex, &free, &nslot))\r\nreturn UINT_MAX;\r\nWARN_ON(!is_nvdimm_bus_locked(ndd->dev));\r\nslot = find_next_bit_le(free, nslot, 0);\r\nif (slot == nslot)\r\nreturn UINT_MAX;\r\nclear_bit_le(slot, free);\r\nreturn slot;\r\n}\r\nbool nd_label_free_slot(struct nvdimm_drvdata *ndd, u32 slot)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long *free;\r\nu32 nslot;\r\nif (!preamble_next(ndd, &nsindex, &free, &nslot))\r\nreturn false;\r\nWARN_ON(!is_nvdimm_bus_locked(ndd->dev));\r\nif (slot < nslot)\r\nreturn !test_and_set_bit_le(slot, free);\r\nreturn false;\r\n}\r\nu32 nd_label_nfree(struct nvdimm_drvdata *ndd)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long *free;\r\nu32 nslot;\r\nWARN_ON(!is_nvdimm_bus_locked(ndd->dev));\r\nif (!preamble_next(ndd, &nsindex, &free, &nslot))\r\nreturn nvdimm_num_label_slots(ndd);\r\nreturn bitmap_weight(free, nslot);\r\n}\r\nstatic int nd_label_write_index(struct nvdimm_drvdata *ndd, int index, u32 seq,\r\nunsigned long flags)\r\n{\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long offset;\r\nu64 checksum;\r\nu32 nslot;\r\nint rc;\r\nnsindex = to_namespace_index(ndd, index);\r\nif (flags & ND_NSINDEX_INIT)\r\nnslot = nvdimm_num_label_slots(ndd);\r\nelse\r\nnslot = __le32_to_cpu(nsindex->nslot);\r\nmemcpy(nsindex->sig, NSINDEX_SIGNATURE, NSINDEX_SIG_LEN);\r\nnsindex->flags = __cpu_to_le32(0);\r\nnsindex->seq = __cpu_to_le32(seq);\r\noffset = (unsigned long) nsindex\r\n- (unsigned long) to_namespace_index(ndd, 0);\r\nnsindex->myoff = __cpu_to_le64(offset);\r\nnsindex->mysize = __cpu_to_le64(sizeof_namespace_index(ndd));\r\noffset = (unsigned long) to_namespace_index(ndd,\r\nnd_label_next_nsindex(index))\r\n- (unsigned long) to_namespace_index(ndd, 0);\r\nnsindex->otheroff = __cpu_to_le64(offset);\r\noffset = (unsigned long) nd_label_base(ndd)\r\n- (unsigned long) to_namespace_index(ndd, 0);\r\nnsindex->labeloff = __cpu_to_le64(offset);\r\nnsindex->nslot = __cpu_to_le32(nslot);\r\nnsindex->major = __cpu_to_le16(1);\r\nnsindex->minor = __cpu_to_le16(1);\r\nnsindex->checksum = __cpu_to_le64(0);\r\nif (flags & ND_NSINDEX_INIT) {\r\nunsigned long *free = (unsigned long *) nsindex->free;\r\nu32 nfree = ALIGN(nslot, BITS_PER_LONG);\r\nint last_bits, i;\r\nmemset(nsindex->free, 0xff, nfree / 8);\r\nfor (i = 0, last_bits = nfree - nslot; i < last_bits; i++)\r\nclear_bit_le(nslot + i, free);\r\n}\r\nchecksum = nd_fletcher64(nsindex, sizeof_namespace_index(ndd), 1);\r\nnsindex->checksum = __cpu_to_le64(checksum);\r\nrc = nvdimm_set_config_data(ndd, __le64_to_cpu(nsindex->myoff),\r\nnsindex, sizeof_namespace_index(ndd));\r\nif (rc < 0)\r\nreturn rc;\r\nif (flags & ND_NSINDEX_INIT)\r\nreturn 0;\r\nWARN_ON(index != ndd->ns_next);\r\nnd_label_copy(ndd, to_current_namespace_index(ndd), nsindex);\r\nndd->ns_current = nd_label_next_nsindex(ndd->ns_current);\r\nndd->ns_next = nd_label_next_nsindex(ndd->ns_next);\r\nWARN_ON(ndd->ns_current == ndd->ns_next);\r\nreturn 0;\r\n}\r\nstatic unsigned long nd_label_offset(struct nvdimm_drvdata *ndd,\r\nstruct nd_namespace_label *nd_label)\r\n{\r\nreturn (unsigned long) nd_label\r\n- (unsigned long) to_namespace_index(ndd, 0);\r\n}\r\nstatic int __pmem_label_update(struct nd_region *nd_region,\r\nstruct nd_mapping *nd_mapping, struct nd_namespace_pmem *nspm,\r\nint pos)\r\n{\r\nu64 cookie = nd_region_interleave_set_cookie(nd_region);\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct nd_label_ent *label_ent, *victim = NULL;\r\nstruct nd_namespace_label *nd_label;\r\nstruct nd_namespace_index *nsindex;\r\nstruct nd_label_id label_id;\r\nstruct resource *res;\r\nunsigned long *free;\r\nu32 nslot, slot;\r\nsize_t offset;\r\nint rc;\r\nif (!preamble_next(ndd, &nsindex, &free, &nslot))\r\nreturn -ENXIO;\r\nnd_label_gen_id(&label_id, nspm->uuid, 0);\r\nfor_each_dpa_resource(ndd, res)\r\nif (strcmp(res->name, label_id.id) == 0)\r\nbreak;\r\nif (!res) {\r\nWARN_ON_ONCE(1);\r\nreturn -ENXIO;\r\n}\r\nslot = nd_label_alloc_slot(ndd);\r\nif (slot == UINT_MAX)\r\nreturn -ENXIO;\r\ndev_dbg(ndd->dev, "%s: allocated: %d\n", __func__, slot);\r\nnd_label = nd_label_base(ndd) + slot;\r\nmemset(nd_label, 0, sizeof(struct nd_namespace_label));\r\nmemcpy(nd_label->uuid, nspm->uuid, NSLABEL_UUID_LEN);\r\nif (nspm->alt_name)\r\nmemcpy(nd_label->name, nspm->alt_name, NSLABEL_NAME_LEN);\r\nnd_label->flags = __cpu_to_le32(NSLABEL_FLAG_UPDATING);\r\nnd_label->nlabel = __cpu_to_le16(nd_region->ndr_mappings);\r\nnd_label->position = __cpu_to_le16(pos);\r\nnd_label->isetcookie = __cpu_to_le64(cookie);\r\nnd_label->rawsize = __cpu_to_le64(resource_size(res));\r\nnd_label->dpa = __cpu_to_le64(res->start);\r\nnd_label->slot = __cpu_to_le32(slot);\r\nnd_dbg_dpa(nd_region, ndd, res, "%s\n", __func__);\r\noffset = nd_label_offset(ndd, nd_label);\r\nrc = nvdimm_set_config_data(ndd, offset, nd_label,\r\nsizeof(struct nd_namespace_label));\r\nif (rc < 0)\r\nreturn rc;\r\nmutex_lock(&nd_mapping->lock);\r\nlist_for_each_entry(label_ent, &nd_mapping->labels, list) {\r\nif (!label_ent->label)\r\ncontinue;\r\nif (memcmp(nspm->uuid, label_ent->label->uuid,\r\nNSLABEL_UUID_LEN) != 0)\r\ncontinue;\r\nvictim = label_ent;\r\nlist_move_tail(&victim->list, &nd_mapping->labels);\r\nbreak;\r\n}\r\nif (victim) {\r\ndev_dbg(ndd->dev, "%s: free: %d\n", __func__, slot);\r\nslot = to_slot(ndd, victim->label);\r\nnd_label_free_slot(ndd, slot);\r\nvictim->label = NULL;\r\n}\r\nrc = nd_label_write_index(ndd, ndd->ns_next,\r\nnd_inc_seq(__le32_to_cpu(nsindex->seq)), 0);\r\nif (rc == 0) {\r\nlist_for_each_entry(label_ent, &nd_mapping->labels, list)\r\nif (!label_ent->label) {\r\nlabel_ent->label = nd_label;\r\nnd_label = NULL;\r\nbreak;\r\n}\r\ndev_WARN_ONCE(&nspm->nsio.common.dev, nd_label,\r\n"failed to track label: %d\n",\r\nto_slot(ndd, nd_label));\r\nif (nd_label)\r\nrc = -ENXIO;\r\n}\r\nmutex_unlock(&nd_mapping->lock);\r\nreturn rc;\r\n}\r\nstatic bool is_old_resource(struct resource *res, struct resource **list, int n)\r\n{\r\nint i;\r\nif (res->flags & DPA_RESOURCE_ADJUSTED)\r\nreturn false;\r\nfor (i = 0; i < n; i++)\r\nif (res == list[i])\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic struct resource *to_resource(struct nvdimm_drvdata *ndd,\r\nstruct nd_namespace_label *nd_label)\r\n{\r\nstruct resource *res;\r\nfor_each_dpa_resource(ndd, res) {\r\nif (res->start != __le64_to_cpu(nd_label->dpa))\r\ncontinue;\r\nif (resource_size(res) != __le64_to_cpu(nd_label->rawsize))\r\ncontinue;\r\nreturn res;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int __blk_label_update(struct nd_region *nd_region,\r\nstruct nd_mapping *nd_mapping, struct nd_namespace_blk *nsblk,\r\nint num_labels)\r\n{\r\nint i, alloc, victims, nfree, old_num_resources, nlabel, rc = -ENXIO;\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct nd_namespace_label *nd_label;\r\nstruct nd_label_ent *label_ent, *e;\r\nstruct nd_namespace_index *nsindex;\r\nunsigned long *free, *victim_map = NULL;\r\nstruct resource *res, **old_res_list;\r\nstruct nd_label_id label_id;\r\nu8 uuid[NSLABEL_UUID_LEN];\r\nLIST_HEAD(list);\r\nu32 nslot, slot;\r\nif (!preamble_next(ndd, &nsindex, &free, &nslot))\r\nreturn -ENXIO;\r\nold_res_list = nsblk->res;\r\nnfree = nd_label_nfree(ndd);\r\nold_num_resources = nsblk->num_resources;\r\nnd_label_gen_id(&label_id, nsblk->uuid, NSLABEL_FLAG_LOCAL);\r\nalloc = 0;\r\nfor_each_dpa_resource(ndd, res) {\r\nif (strcmp(res->name, label_id.id) != 0)\r\ncontinue;\r\nif (!is_old_resource(res, old_res_list, old_num_resources))\r\nalloc++;\r\n}\r\nvictims = 0;\r\nif (old_num_resources) {\r\nvictim_map = kcalloc(BITS_TO_LONGS(nslot), sizeof(long),\r\nGFP_KERNEL);\r\nif (!victim_map)\r\nreturn -ENOMEM;\r\nfor_each_clear_bit_le(slot, free, nslot) {\r\nnd_label = nd_label_base(ndd) + slot;\r\nmemcpy(uuid, nd_label->uuid, NSLABEL_UUID_LEN);\r\nif (memcmp(uuid, nsblk->uuid, NSLABEL_UUID_LEN) != 0)\r\ncontinue;\r\nres = to_resource(ndd, nd_label);\r\nif (res && is_old_resource(res, old_res_list,\r\nold_num_resources))\r\ncontinue;\r\nslot = to_slot(ndd, nd_label);\r\nset_bit(slot, victim_map);\r\nvictims++;\r\n}\r\n}\r\nif (nfree - alloc < 0 || nfree - alloc + victims < 1) {\r\ndev_info(&nsblk->common.dev, "insufficient label space\n");\r\nkfree(victim_map);\r\nreturn -ENOSPC;\r\n}\r\nnsblk->res = NULL;\r\nnsblk->num_resources = 0;\r\nfor_each_dpa_resource(ndd, res) {\r\nif (strcmp(res->name, label_id.id) != 0)\r\ncontinue;\r\nif (!nsblk_add_resource(nd_region, ndd, nsblk, res->start)) {\r\nrc = -ENOMEM;\r\ngoto abort;\r\n}\r\n}\r\nfor (i = 0; i < nsblk->num_resources; i++) {\r\nsize_t offset;\r\nres = nsblk->res[i];\r\nif (is_old_resource(res, old_res_list, old_num_resources))\r\ncontinue;\r\nslot = nd_label_alloc_slot(ndd);\r\nif (slot == UINT_MAX)\r\ngoto abort;\r\ndev_dbg(ndd->dev, "%s: allocated: %d\n", __func__, slot);\r\nnd_label = nd_label_base(ndd) + slot;\r\nmemset(nd_label, 0, sizeof(struct nd_namespace_label));\r\nmemcpy(nd_label->uuid, nsblk->uuid, NSLABEL_UUID_LEN);\r\nif (nsblk->alt_name)\r\nmemcpy(nd_label->name, nsblk->alt_name,\r\nNSLABEL_NAME_LEN);\r\nnd_label->flags = __cpu_to_le32(NSLABEL_FLAG_LOCAL);\r\nnd_label->nlabel = __cpu_to_le16(0);\r\nnd_label->position = __cpu_to_le16(0);\r\nnd_label->isetcookie = __cpu_to_le64(0);\r\nnd_label->dpa = __cpu_to_le64(res->start);\r\nnd_label->rawsize = __cpu_to_le64(resource_size(res));\r\nnd_label->lbasize = __cpu_to_le64(nsblk->lbasize);\r\nnd_label->slot = __cpu_to_le32(slot);\r\noffset = nd_label_offset(ndd, nd_label);\r\nrc = nvdimm_set_config_data(ndd, offset, nd_label,\r\nsizeof(struct nd_namespace_label));\r\nif (rc < 0)\r\ngoto abort;\r\n}\r\nfor_each_set_bit(slot, victim_map, victim_map ? nslot : 0) {\r\ndev_dbg(ndd->dev, "%s: free: %d\n", __func__, slot);\r\nnd_label_free_slot(ndd, slot);\r\n}\r\nrc = nd_label_write_index(ndd, ndd->ns_next,\r\nnd_inc_seq(__le32_to_cpu(nsindex->seq)), 0);\r\nif (rc)\r\ngoto abort;\r\nnlabel = 0;\r\nmutex_lock(&nd_mapping->lock);\r\nlist_for_each_entry_safe(label_ent, e, &nd_mapping->labels, list) {\r\nnd_label = label_ent->label;\r\nif (!nd_label)\r\ncontinue;\r\nnlabel++;\r\nmemcpy(uuid, nd_label->uuid, NSLABEL_UUID_LEN);\r\nif (memcmp(uuid, nsblk->uuid, NSLABEL_UUID_LEN) != 0)\r\ncontinue;\r\nnlabel--;\r\nlist_move(&label_ent->list, &list);\r\nlabel_ent->label = NULL;\r\n}\r\nlist_splice_tail_init(&list, &nd_mapping->labels);\r\nmutex_unlock(&nd_mapping->lock);\r\nif (nlabel + nsblk->num_resources > num_labels) {\r\nWARN_ON_ONCE(1);\r\nrc = -ENXIO;\r\ngoto out;\r\n}\r\nmutex_lock(&nd_mapping->lock);\r\nlabel_ent = list_first_entry_or_null(&nd_mapping->labels,\r\ntypeof(*label_ent), list);\r\nif (!label_ent) {\r\nWARN_ON(1);\r\nmutex_unlock(&nd_mapping->lock);\r\nrc = -ENXIO;\r\ngoto out;\r\n}\r\nfor_each_clear_bit_le(slot, free, nslot) {\r\nnd_label = nd_label_base(ndd) + slot;\r\nmemcpy(uuid, nd_label->uuid, NSLABEL_UUID_LEN);\r\nif (memcmp(uuid, nsblk->uuid, NSLABEL_UUID_LEN) != 0)\r\ncontinue;\r\nres = to_resource(ndd, nd_label);\r\nres->flags &= ~DPA_RESOURCE_ADJUSTED;\r\ndev_vdbg(&nsblk->common.dev, "assign label slot: %d\n", slot);\r\nlist_for_each_entry_from(label_ent, &nd_mapping->labels, list) {\r\nif (label_ent->label)\r\ncontinue;\r\nlabel_ent->label = nd_label;\r\nnd_label = NULL;\r\nbreak;\r\n}\r\nif (nd_label)\r\ndev_WARN(&nsblk->common.dev,\r\n"failed to track label slot%d\n", slot);\r\n}\r\nmutex_unlock(&nd_mapping->lock);\r\nout:\r\nkfree(old_res_list);\r\nkfree(victim_map);\r\nreturn rc;\r\nabort:\r\nnd_label_copy(ndd, nsindex, to_current_namespace_index(ndd));\r\nkfree(nsblk->res);\r\nnsblk->res = old_res_list;\r\nnsblk->num_resources = old_num_resources;\r\nold_res_list = NULL;\r\ngoto out;\r\n}\r\nstatic int init_labels(struct nd_mapping *nd_mapping, int num_labels)\r\n{\r\nint i, old_num_labels = 0;\r\nstruct nd_label_ent *label_ent;\r\nstruct nd_namespace_index *nsindex;\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nmutex_lock(&nd_mapping->lock);\r\nlist_for_each_entry(label_ent, &nd_mapping->labels, list)\r\nold_num_labels++;\r\nmutex_unlock(&nd_mapping->lock);\r\nfor (i = old_num_labels; i < num_labels; i++) {\r\nlabel_ent = kzalloc(sizeof(*label_ent), GFP_KERNEL);\r\nif (!label_ent)\r\nreturn -ENOMEM;\r\nmutex_lock(&nd_mapping->lock);\r\nlist_add_tail(&label_ent->list, &nd_mapping->labels);\r\nmutex_unlock(&nd_mapping->lock);\r\n}\r\nif (ndd->ns_current == -1 || ndd->ns_next == -1)\r\n;\r\nelse\r\nreturn max(num_labels, old_num_labels);\r\nnsindex = to_namespace_index(ndd, 0);\r\nmemset(nsindex, 0, ndd->nsarea.config_size);\r\nfor (i = 0; i < 2; i++) {\r\nint rc = nd_label_write_index(ndd, i, i*2, ND_NSINDEX_INIT);\r\nif (rc)\r\nreturn rc;\r\n}\r\nndd->ns_next = 1;\r\nndd->ns_current = 0;\r\nreturn max(num_labels, old_num_labels);\r\n}\r\nstatic int del_labels(struct nd_mapping *nd_mapping, u8 *uuid)\r\n{\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct nd_label_ent *label_ent, *e;\r\nstruct nd_namespace_index *nsindex;\r\nu8 label_uuid[NSLABEL_UUID_LEN];\r\nunsigned long *free;\r\nLIST_HEAD(list);\r\nu32 nslot, slot;\r\nint active = 0;\r\nif (!uuid)\r\nreturn 0;\r\nif (!preamble_next(ndd, &nsindex, &free, &nslot))\r\nreturn 0;\r\nmutex_lock(&nd_mapping->lock);\r\nlist_for_each_entry_safe(label_ent, e, &nd_mapping->labels, list) {\r\nstruct nd_namespace_label *nd_label = label_ent->label;\r\nif (!nd_label)\r\ncontinue;\r\nactive++;\r\nmemcpy(label_uuid, nd_label->uuid, NSLABEL_UUID_LEN);\r\nif (memcmp(label_uuid, uuid, NSLABEL_UUID_LEN) != 0)\r\ncontinue;\r\nactive--;\r\nslot = to_slot(ndd, nd_label);\r\nnd_label_free_slot(ndd, slot);\r\ndev_dbg(ndd->dev, "%s: free: %d\n", __func__, slot);\r\nlist_move_tail(&label_ent->list, &list);\r\nlabel_ent->label = NULL;\r\n}\r\nlist_splice_tail_init(&list, &nd_mapping->labels);\r\nif (active == 0) {\r\nnd_mapping_free_labels(nd_mapping);\r\ndev_dbg(ndd->dev, "%s: no more active labels\n", __func__);\r\n}\r\nmutex_unlock(&nd_mapping->lock);\r\nreturn nd_label_write_index(ndd, ndd->ns_next,\r\nnd_inc_seq(__le32_to_cpu(nsindex->seq)), 0);\r\n}\r\nint nd_pmem_namespace_label_update(struct nd_region *nd_region,\r\nstruct nd_namespace_pmem *nspm, resource_size_t size)\r\n{\r\nint i;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct resource *res;\r\nint rc, count = 0;\r\nif (size == 0) {\r\nrc = del_labels(nd_mapping, nspm->uuid);\r\nif (rc)\r\nreturn rc;\r\ncontinue;\r\n}\r\nfor_each_dpa_resource(ndd, res)\r\nif (strncmp(res->name, "pmem", 4) == 0)\r\ncount++;\r\nWARN_ON_ONCE(!count);\r\nrc = init_labels(nd_mapping, count);\r\nif (rc < 0)\r\nreturn rc;\r\nrc = __pmem_label_update(nd_region, nd_mapping, nspm, i);\r\nif (rc)\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nint nd_blk_namespace_label_update(struct nd_region *nd_region,\r\nstruct nd_namespace_blk *nsblk, resource_size_t size)\r\n{\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[0];\r\nstruct resource *res;\r\nint count = 0;\r\nif (size == 0)\r\nreturn del_labels(nd_mapping, nsblk->uuid);\r\nfor_each_dpa_resource(to_ndd(nd_mapping), res)\r\ncount++;\r\ncount = init_labels(nd_mapping, count);\r\nif (count < 0)\r\nreturn count;\r\nreturn __blk_label_update(nd_region, nd_mapping, nsblk, count);\r\n}
