static void populate_seccomp_data(struct seccomp_data *sd)\r\n{\r\nstruct task_struct *task = current;\r\nstruct pt_regs *regs = task_pt_regs(task);\r\nunsigned long args[6];\r\nsd->nr = syscall_get_nr(task, regs);\r\nsd->arch = syscall_get_arch();\r\nsyscall_get_arguments(task, regs, 0, 6, args);\r\nsd->args[0] = args[0];\r\nsd->args[1] = args[1];\r\nsd->args[2] = args[2];\r\nsd->args[3] = args[3];\r\nsd->args[4] = args[4];\r\nsd->args[5] = args[5];\r\nsd->instruction_pointer = KSTK_EIP(task);\r\n}\r\nstatic int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)\r\n{\r\nint pc;\r\nfor (pc = 0; pc < flen; pc++) {\r\nstruct sock_filter *ftest = &filter[pc];\r\nu16 code = ftest->code;\r\nu32 k = ftest->k;\r\nswitch (code) {\r\ncase BPF_LD | BPF_W | BPF_ABS:\r\nftest->code = BPF_LDX | BPF_W | BPF_ABS;\r\nif (k >= sizeof(struct seccomp_data) || k & 3)\r\nreturn -EINVAL;\r\ncontinue;\r\ncase BPF_LD | BPF_W | BPF_LEN:\r\nftest->code = BPF_LD | BPF_IMM;\r\nftest->k = sizeof(struct seccomp_data);\r\ncontinue;\r\ncase BPF_LDX | BPF_W | BPF_LEN:\r\nftest->code = BPF_LDX | BPF_IMM;\r\nftest->k = sizeof(struct seccomp_data);\r\ncontinue;\r\ncase BPF_RET | BPF_K:\r\ncase BPF_RET | BPF_A:\r\ncase BPF_ALU | BPF_ADD | BPF_K:\r\ncase BPF_ALU | BPF_ADD | BPF_X:\r\ncase BPF_ALU | BPF_SUB | BPF_K:\r\ncase BPF_ALU | BPF_SUB | BPF_X:\r\ncase BPF_ALU | BPF_MUL | BPF_K:\r\ncase BPF_ALU | BPF_MUL | BPF_X:\r\ncase BPF_ALU | BPF_DIV | BPF_K:\r\ncase BPF_ALU | BPF_DIV | BPF_X:\r\ncase BPF_ALU | BPF_AND | BPF_K:\r\ncase BPF_ALU | BPF_AND | BPF_X:\r\ncase BPF_ALU | BPF_OR | BPF_K:\r\ncase BPF_ALU | BPF_OR | BPF_X:\r\ncase BPF_ALU | BPF_XOR | BPF_K:\r\ncase BPF_ALU | BPF_XOR | BPF_X:\r\ncase BPF_ALU | BPF_LSH | BPF_K:\r\ncase BPF_ALU | BPF_LSH | BPF_X:\r\ncase BPF_ALU | BPF_RSH | BPF_K:\r\ncase BPF_ALU | BPF_RSH | BPF_X:\r\ncase BPF_ALU | BPF_NEG:\r\ncase BPF_LD | BPF_IMM:\r\ncase BPF_LDX | BPF_IMM:\r\ncase BPF_MISC | BPF_TAX:\r\ncase BPF_MISC | BPF_TXA:\r\ncase BPF_LD | BPF_MEM:\r\ncase BPF_LDX | BPF_MEM:\r\ncase BPF_ST:\r\ncase BPF_STX:\r\ncase BPF_JMP | BPF_JA:\r\ncase BPF_JMP | BPF_JEQ | BPF_K:\r\ncase BPF_JMP | BPF_JEQ | BPF_X:\r\ncase BPF_JMP | BPF_JGE | BPF_K:\r\ncase BPF_JMP | BPF_JGE | BPF_X:\r\ncase BPF_JMP | BPF_JGT | BPF_K:\r\ncase BPF_JMP | BPF_JGT | BPF_X:\r\ncase BPF_JMP | BPF_JSET | BPF_K:\r\ncase BPF_JMP | BPF_JSET | BPF_X:\r\ncontinue;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic u32 seccomp_run_filters(const struct seccomp_data *sd)\r\n{\r\nstruct seccomp_data sd_local;\r\nu32 ret = SECCOMP_RET_ALLOW;\r\nstruct seccomp_filter *f =\r\nlockless_dereference(current->seccomp.filter);\r\nif (unlikely(WARN_ON(f == NULL)))\r\nreturn SECCOMP_RET_KILL;\r\nif (!sd) {\r\npopulate_seccomp_data(&sd_local);\r\nsd = &sd_local;\r\n}\r\nfor (; f; f = f->prev) {\r\nu32 cur_ret = BPF_PROG_RUN(f->prog, sd);\r\nif ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))\r\nret = cur_ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)\r\n{\r\nassert_spin_locked(&current->sighand->siglock);\r\nif (current->seccomp.mode && current->seccomp.mode != seccomp_mode)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic inline void seccomp_assign_mode(struct task_struct *task,\r\nunsigned long seccomp_mode)\r\n{\r\nassert_spin_locked(&task->sighand->siglock);\r\ntask->seccomp.mode = seccomp_mode;\r\nsmp_mb__before_atomic();\r\nset_tsk_thread_flag(task, TIF_SECCOMP);\r\n}\r\nstatic int is_ancestor(struct seccomp_filter *parent,\r\nstruct seccomp_filter *child)\r\n{\r\nif (parent == NULL)\r\nreturn 1;\r\nfor (; child; child = child->prev)\r\nif (child == parent)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic inline pid_t seccomp_can_sync_threads(void)\r\n{\r\nstruct task_struct *thread, *caller;\r\nBUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));\r\nassert_spin_locked(&current->sighand->siglock);\r\ncaller = current;\r\nfor_each_thread(caller, thread) {\r\npid_t failed;\r\nif (thread == caller)\r\ncontinue;\r\nif (thread->seccomp.mode == SECCOMP_MODE_DISABLED ||\r\n(thread->seccomp.mode == SECCOMP_MODE_FILTER &&\r\nis_ancestor(thread->seccomp.filter,\r\ncaller->seccomp.filter)))\r\ncontinue;\r\nfailed = task_pid_vnr(thread);\r\nif (unlikely(WARN_ON(failed == 0)))\r\nfailed = -ESRCH;\r\nreturn failed;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline void seccomp_sync_threads(void)\r\n{\r\nstruct task_struct *thread, *caller;\r\nBUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));\r\nassert_spin_locked(&current->sighand->siglock);\r\ncaller = current;\r\nfor_each_thread(caller, thread) {\r\nif (thread == caller)\r\ncontinue;\r\nget_seccomp_filter(caller);\r\nput_seccomp_filter(thread);\r\nsmp_store_release(&thread->seccomp.filter,\r\ncaller->seccomp.filter);\r\nif (task_no_new_privs(caller))\r\ntask_set_no_new_privs(thread);\r\nif (thread->seccomp.mode == SECCOMP_MODE_DISABLED)\r\nseccomp_assign_mode(thread, SECCOMP_MODE_FILTER);\r\n}\r\n}\r\nstatic struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)\r\n{\r\nstruct seccomp_filter *sfilter;\r\nint ret;\r\nconst bool save_orig = IS_ENABLED(CONFIG_CHECKPOINT_RESTORE);\r\nif (fprog->len == 0 || fprog->len > BPF_MAXINSNS)\r\nreturn ERR_PTR(-EINVAL);\r\nBUG_ON(INT_MAX / fprog->len < sizeof(struct sock_filter));\r\nif (!task_no_new_privs(current) &&\r\nsecurity_capable_noaudit(current_cred(), current_user_ns(),\r\nCAP_SYS_ADMIN) != 0)\r\nreturn ERR_PTR(-EACCES);\r\nsfilter = kzalloc(sizeof(*sfilter), GFP_KERNEL | __GFP_NOWARN);\r\nif (!sfilter)\r\nreturn ERR_PTR(-ENOMEM);\r\nret = bpf_prog_create_from_user(&sfilter->prog, fprog,\r\nseccomp_check_filter, save_orig);\r\nif (ret < 0) {\r\nkfree(sfilter);\r\nreturn ERR_PTR(ret);\r\n}\r\natomic_set(&sfilter->usage, 1);\r\nreturn sfilter;\r\n}\r\nstatic struct seccomp_filter *\r\nseccomp_prepare_user_filter(const char __user *user_filter)\r\n{\r\nstruct sock_fprog fprog;\r\nstruct seccomp_filter *filter = ERR_PTR(-EFAULT);\r\n#ifdef CONFIG_COMPAT\r\nif (in_compat_syscall()) {\r\nstruct compat_sock_fprog fprog32;\r\nif (copy_from_user(&fprog32, user_filter, sizeof(fprog32)))\r\ngoto out;\r\nfprog.len = fprog32.len;\r\nfprog.filter = compat_ptr(fprog32.filter);\r\n} else\r\n#endif\r\nif (copy_from_user(&fprog, user_filter, sizeof(fprog)))\r\ngoto out;\r\nfilter = seccomp_prepare_filter(&fprog);\r\nout:\r\nreturn filter;\r\n}\r\nstatic long seccomp_attach_filter(unsigned int flags,\r\nstruct seccomp_filter *filter)\r\n{\r\nunsigned long total_insns;\r\nstruct seccomp_filter *walker;\r\nassert_spin_locked(&current->sighand->siglock);\r\ntotal_insns = filter->prog->len;\r\nfor (walker = current->seccomp.filter; walker; walker = walker->prev)\r\ntotal_insns += walker->prog->len + 4;\r\nif (total_insns > MAX_INSNS_PER_PATH)\r\nreturn -ENOMEM;\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC) {\r\nint ret;\r\nret = seccomp_can_sync_threads();\r\nif (ret)\r\nreturn ret;\r\n}\r\nfilter->prev = current->seccomp.filter;\r\ncurrent->seccomp.filter = filter;\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC)\r\nseccomp_sync_threads();\r\nreturn 0;\r\n}\r\nvoid get_seccomp_filter(struct task_struct *tsk)\r\n{\r\nstruct seccomp_filter *orig = tsk->seccomp.filter;\r\nif (!orig)\r\nreturn;\r\natomic_inc(&orig->usage);\r\n}\r\nstatic inline void seccomp_filter_free(struct seccomp_filter *filter)\r\n{\r\nif (filter) {\r\nbpf_prog_destroy(filter->prog);\r\nkfree(filter);\r\n}\r\n}\r\nvoid put_seccomp_filter(struct task_struct *tsk)\r\n{\r\nstruct seccomp_filter *orig = tsk->seccomp.filter;\r\nwhile (orig && atomic_dec_and_test(&orig->usage)) {\r\nstruct seccomp_filter *freeme = orig;\r\norig = orig->prev;\r\nseccomp_filter_free(freeme);\r\n}\r\n}\r\nstatic void seccomp_init_siginfo(siginfo_t *info, int syscall, int reason)\r\n{\r\nmemset(info, 0, sizeof(*info));\r\ninfo->si_signo = SIGSYS;\r\ninfo->si_code = SYS_SECCOMP;\r\ninfo->si_call_addr = (void __user *)KSTK_EIP(current);\r\ninfo->si_errno = reason;\r\ninfo->si_arch = syscall_get_arch();\r\ninfo->si_syscall = syscall;\r\n}\r\nstatic void seccomp_send_sigsys(int syscall, int reason)\r\n{\r\nstruct siginfo info;\r\nseccomp_init_siginfo(&info, syscall, reason);\r\nforce_sig_info(SIGSYS, &info, current);\r\n}\r\nstatic void __secure_computing_strict(int this_syscall)\r\n{\r\nconst int *syscall_whitelist = mode1_syscalls;\r\n#ifdef CONFIG_COMPAT\r\nif (in_compat_syscall())\r\nsyscall_whitelist = get_compat_mode1_syscalls();\r\n#endif\r\ndo {\r\nif (*syscall_whitelist == this_syscall)\r\nreturn;\r\n} while (*++syscall_whitelist);\r\n#ifdef SECCOMP_DEBUG\r\ndump_stack();\r\n#endif\r\naudit_seccomp(this_syscall, SIGKILL, SECCOMP_RET_KILL);\r\ndo_exit(SIGKILL);\r\n}\r\nvoid secure_computing_strict(int this_syscall)\r\n{\r\nint mode = current->seccomp.mode;\r\nif (IS_ENABLED(CONFIG_CHECKPOINT_RESTORE) &&\r\nunlikely(current->ptrace & PT_SUSPEND_SECCOMP))\r\nreturn;\r\nif (mode == SECCOMP_MODE_DISABLED)\r\nreturn;\r\nelse if (mode == SECCOMP_MODE_STRICT)\r\n__secure_computing_strict(this_syscall);\r\nelse\r\nBUG();\r\n}\r\nstatic int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,\r\nconst bool recheck_after_trace)\r\n{\r\nu32 filter_ret, action;\r\nint data;\r\nrmb();\r\nfilter_ret = seccomp_run_filters(sd);\r\ndata = filter_ret & SECCOMP_RET_DATA;\r\naction = filter_ret & SECCOMP_RET_ACTION;\r\nswitch (action) {\r\ncase SECCOMP_RET_ERRNO:\r\nif (data > MAX_ERRNO)\r\ndata = MAX_ERRNO;\r\nsyscall_set_return_value(current, task_pt_regs(current),\r\n-data, 0);\r\ngoto skip;\r\ncase SECCOMP_RET_TRAP:\r\nsyscall_rollback(current, task_pt_regs(current));\r\nseccomp_send_sigsys(this_syscall, data);\r\ngoto skip;\r\ncase SECCOMP_RET_TRACE:\r\nif (recheck_after_trace)\r\nreturn 0;\r\nif (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {\r\nsyscall_set_return_value(current,\r\ntask_pt_regs(current),\r\n-ENOSYS, 0);\r\ngoto skip;\r\n}\r\nptrace_event(PTRACE_EVENT_SECCOMP, data);\r\nif (fatal_signal_pending(current))\r\ngoto skip;\r\nthis_syscall = syscall_get_nr(current, task_pt_regs(current));\r\nif (this_syscall < 0)\r\ngoto skip;\r\nif (__seccomp_filter(this_syscall, NULL, true))\r\nreturn -1;\r\nreturn 0;\r\ncase SECCOMP_RET_ALLOW:\r\nreturn 0;\r\ncase SECCOMP_RET_KILL:\r\ndefault: {\r\nsiginfo_t info;\r\naudit_seccomp(this_syscall, SIGSYS, action);\r\nif (get_nr_threads(current) == 1) {\r\nsyscall_rollback(current, task_pt_regs(current));\r\nseccomp_init_siginfo(&info, this_syscall, data);\r\ndo_coredump(&info);\r\n}\r\ndo_exit(SIGSYS);\r\n}\r\n}\r\nunreachable();\r\nskip:\r\naudit_seccomp(this_syscall, 0, action);\r\nreturn -1;\r\n}\r\nstatic int __seccomp_filter(int this_syscall, const struct seccomp_data *sd,\r\nconst bool recheck_after_trace)\r\n{\r\nBUG();\r\n}\r\nint __secure_computing(const struct seccomp_data *sd)\r\n{\r\nint mode = current->seccomp.mode;\r\nint this_syscall;\r\nif (IS_ENABLED(CONFIG_CHECKPOINT_RESTORE) &&\r\nunlikely(current->ptrace & PT_SUSPEND_SECCOMP))\r\nreturn 0;\r\nthis_syscall = sd ? sd->nr :\r\nsyscall_get_nr(current, task_pt_regs(current));\r\nswitch (mode) {\r\ncase SECCOMP_MODE_STRICT:\r\n__secure_computing_strict(this_syscall);\r\nreturn 0;\r\ncase SECCOMP_MODE_FILTER:\r\nreturn __seccomp_filter(this_syscall, sd, false);\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nlong prctl_get_seccomp(void)\r\n{\r\nreturn current->seccomp.mode;\r\n}\r\nstatic long seccomp_set_mode_strict(void)\r\n{\r\nconst unsigned long seccomp_mode = SECCOMP_MODE_STRICT;\r\nlong ret = -EINVAL;\r\nspin_lock_irq(&current->sighand->siglock);\r\nif (!seccomp_may_assign_mode(seccomp_mode))\r\ngoto out;\r\n#ifdef TIF_NOTSC\r\ndisable_TSC();\r\n#endif\r\nseccomp_assign_mode(current, seccomp_mode);\r\nret = 0;\r\nout:\r\nspin_unlock_irq(&current->sighand->siglock);\r\nreturn ret;\r\n}\r\nstatic long seccomp_set_mode_filter(unsigned int flags,\r\nconst char __user *filter)\r\n{\r\nconst unsigned long seccomp_mode = SECCOMP_MODE_FILTER;\r\nstruct seccomp_filter *prepared = NULL;\r\nlong ret = -EINVAL;\r\nif (flags & ~SECCOMP_FILTER_FLAG_MASK)\r\nreturn -EINVAL;\r\nprepared = seccomp_prepare_user_filter(filter);\r\nif (IS_ERR(prepared))\r\nreturn PTR_ERR(prepared);\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC &&\r\nmutex_lock_killable(&current->signal->cred_guard_mutex))\r\ngoto out_free;\r\nspin_lock_irq(&current->sighand->siglock);\r\nif (!seccomp_may_assign_mode(seccomp_mode))\r\ngoto out;\r\nret = seccomp_attach_filter(flags, prepared);\r\nif (ret)\r\ngoto out;\r\nprepared = NULL;\r\nseccomp_assign_mode(current, seccomp_mode);\r\nout:\r\nspin_unlock_irq(&current->sighand->siglock);\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC)\r\nmutex_unlock(&current->signal->cred_guard_mutex);\r\nout_free:\r\nseccomp_filter_free(prepared);\r\nreturn ret;\r\n}\r\nstatic inline long seccomp_set_mode_filter(unsigned int flags,\r\nconst char __user *filter)\r\n{\r\nreturn -EINVAL;\r\n}\r\nstatic long do_seccomp(unsigned int op, unsigned int flags,\r\nconst char __user *uargs)\r\n{\r\nswitch (op) {\r\ncase SECCOMP_SET_MODE_STRICT:\r\nif (flags != 0 || uargs != NULL)\r\nreturn -EINVAL;\r\nreturn seccomp_set_mode_strict();\r\ncase SECCOMP_SET_MODE_FILTER:\r\nreturn seccomp_set_mode_filter(flags, uargs);\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nlong prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)\r\n{\r\nunsigned int op;\r\nchar __user *uargs;\r\nswitch (seccomp_mode) {\r\ncase SECCOMP_MODE_STRICT:\r\nop = SECCOMP_SET_MODE_STRICT;\r\nuargs = NULL;\r\nbreak;\r\ncase SECCOMP_MODE_FILTER:\r\nop = SECCOMP_SET_MODE_FILTER;\r\nuargs = filter;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn do_seccomp(op, 0, uargs);\r\n}\r\nlong seccomp_get_filter(struct task_struct *task, unsigned long filter_off,\r\nvoid __user *data)\r\n{\r\nstruct seccomp_filter *filter;\r\nstruct sock_fprog_kern *fprog;\r\nlong ret;\r\nunsigned long count = 0;\r\nif (!capable(CAP_SYS_ADMIN) ||\r\ncurrent->seccomp.mode != SECCOMP_MODE_DISABLED) {\r\nreturn -EACCES;\r\n}\r\nspin_lock_irq(&task->sighand->siglock);\r\nif (task->seccomp.mode != SECCOMP_MODE_FILTER) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nfilter = task->seccomp.filter;\r\nwhile (filter) {\r\nfilter = filter->prev;\r\ncount++;\r\n}\r\nif (filter_off >= count) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\ncount -= filter_off;\r\nfilter = task->seccomp.filter;\r\nwhile (filter && count > 1) {\r\nfilter = filter->prev;\r\ncount--;\r\n}\r\nif (WARN_ON(count != 1 || !filter)) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nfprog = filter->prog->orig_prog;\r\nif (!fprog) {\r\nret = -EMEDIUMTYPE;\r\ngoto out;\r\n}\r\nret = fprog->len;\r\nif (!data)\r\ngoto out;\r\nget_seccomp_filter(task);\r\nspin_unlock_irq(&task->sighand->siglock);\r\nif (copy_to_user(data, fprog->filter, bpf_classic_proglen(fprog)))\r\nret = -EFAULT;\r\nput_seccomp_filter(task);\r\nreturn ret;\r\nout:\r\nspin_unlock_irq(&task->sighand->siglock);\r\nreturn ret;\r\n}
