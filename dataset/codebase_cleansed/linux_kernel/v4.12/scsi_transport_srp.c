static inline struct Scsi_Host *rport_to_shost(struct srp_rport *r)\r\n{\r\nreturn dev_to_shost(r->dev.parent);\r\n}\r\nstatic inline struct srp_rport *shost_to_rport(struct Scsi_Host *shost)\r\n{\r\nreturn transport_class_to_srp_rport(&shost->shost_gendev);\r\n}\r\nint srp_tmo_valid(int reconnect_delay, int fast_io_fail_tmo, int dev_loss_tmo)\r\n{\r\nif (reconnect_delay < 0 && fast_io_fail_tmo < 0 && dev_loss_tmo < 0)\r\nreturn -EINVAL;\r\nif (reconnect_delay == 0)\r\nreturn -EINVAL;\r\nif (fast_io_fail_tmo > SCSI_DEVICE_BLOCK_MAX_TIMEOUT)\r\nreturn -EINVAL;\r\nif (fast_io_fail_tmo < 0 &&\r\ndev_loss_tmo > SCSI_DEVICE_BLOCK_MAX_TIMEOUT)\r\nreturn -EINVAL;\r\nif (dev_loss_tmo >= LONG_MAX / HZ)\r\nreturn -EINVAL;\r\nif (fast_io_fail_tmo >= 0 && dev_loss_tmo >= 0 &&\r\nfast_io_fail_tmo >= dev_loss_tmo)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int srp_host_setup(struct transport_container *tc, struct device *dev,\r\nstruct device *cdev)\r\n{\r\nstruct Scsi_Host *shost = dev_to_shost(dev);\r\nstruct srp_host_attrs *srp_host = to_srp_host_attrs(shost);\r\natomic_set(&srp_host->next_port_id, 0);\r\nreturn 0;\r\n}\r\nstatic ssize_t\r\nshow_srp_rport_id(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nreturn sprintf(buf, "%16phC\n", rport->port_id);\r\n}\r\nstatic ssize_t\r\nshow_srp_rport_roles(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nint i;\r\nchar *name = NULL;\r\nfor (i = 0; i < ARRAY_SIZE(srp_rport_role_names); i++)\r\nif (srp_rport_role_names[i].value == rport->roles) {\r\nname = srp_rport_role_names[i].name;\r\nbreak;\r\n}\r\nreturn sprintf(buf, "%s\n", name ? : "unknown");\r\n}\r\nstatic ssize_t store_srp_rport_delete(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nstruct Scsi_Host *shost = dev_to_shost(dev);\r\nstruct srp_internal *i = to_srp_internal(shost->transportt);\r\nif (i->f->rport_delete) {\r\ni->f->rport_delete(rport);\r\nreturn count;\r\n} else {\r\nreturn -ENOSYS;\r\n}\r\n}\r\nstatic ssize_t show_srp_rport_state(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstatic const char *const state_name[] = {\r\n[SRP_RPORT_RUNNING] = "running",\r\n[SRP_RPORT_BLOCKED] = "blocked",\r\n[SRP_RPORT_FAIL_FAST] = "fail-fast",\r\n[SRP_RPORT_LOST] = "lost",\r\n};\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nenum srp_rport_state state = rport->state;\r\nreturn sprintf(buf, "%s\n",\r\n(unsigned)state < ARRAY_SIZE(state_name) ?\r\nstate_name[state] : "???");\r\n}\r\nstatic ssize_t srp_show_tmo(char *buf, int tmo)\r\n{\r\nreturn tmo >= 0 ? sprintf(buf, "%d\n", tmo) : sprintf(buf, "off\n");\r\n}\r\nint srp_parse_tmo(int *tmo, const char *buf)\r\n{\r\nint res = 0;\r\nif (strncmp(buf, "off", 3) != 0)\r\nres = kstrtoint(buf, 0, tmo);\r\nelse\r\n*tmo = -1;\r\nreturn res;\r\n}\r\nstatic ssize_t show_reconnect_delay(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nreturn srp_show_tmo(buf, rport->reconnect_delay);\r\n}\r\nstatic ssize_t store_reconnect_delay(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, const size_t count)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nint res, delay;\r\nres = srp_parse_tmo(&delay, buf);\r\nif (res)\r\ngoto out;\r\nres = srp_tmo_valid(delay, rport->fast_io_fail_tmo,\r\nrport->dev_loss_tmo);\r\nif (res)\r\ngoto out;\r\nif (rport->reconnect_delay <= 0 && delay > 0 &&\r\nrport->state != SRP_RPORT_RUNNING) {\r\nqueue_delayed_work(system_long_wq, &rport->reconnect_work,\r\ndelay * HZ);\r\n} else if (delay <= 0) {\r\ncancel_delayed_work(&rport->reconnect_work);\r\n}\r\nrport->reconnect_delay = delay;\r\nres = count;\r\nout:\r\nreturn res;\r\n}\r\nstatic ssize_t show_failed_reconnects(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nreturn sprintf(buf, "%d\n", rport->failed_reconnects);\r\n}\r\nstatic ssize_t show_srp_rport_fast_io_fail_tmo(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nreturn srp_show_tmo(buf, rport->fast_io_fail_tmo);\r\n}\r\nstatic ssize_t store_srp_rport_fast_io_fail_tmo(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nint res;\r\nint fast_io_fail_tmo;\r\nres = srp_parse_tmo(&fast_io_fail_tmo, buf);\r\nif (res)\r\ngoto out;\r\nres = srp_tmo_valid(rport->reconnect_delay, fast_io_fail_tmo,\r\nrport->dev_loss_tmo);\r\nif (res)\r\ngoto out;\r\nrport->fast_io_fail_tmo = fast_io_fail_tmo;\r\nres = count;\r\nout:\r\nreturn res;\r\n}\r\nstatic ssize_t show_srp_rport_dev_loss_tmo(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nreturn srp_show_tmo(buf, rport->dev_loss_tmo);\r\n}\r\nstatic ssize_t store_srp_rport_dev_loss_tmo(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct srp_rport *rport = transport_class_to_srp_rport(dev);\r\nint res;\r\nint dev_loss_tmo;\r\nres = srp_parse_tmo(&dev_loss_tmo, buf);\r\nif (res)\r\ngoto out;\r\nres = srp_tmo_valid(rport->reconnect_delay, rport->fast_io_fail_tmo,\r\ndev_loss_tmo);\r\nif (res)\r\ngoto out;\r\nrport->dev_loss_tmo = dev_loss_tmo;\r\nres = count;\r\nout:\r\nreturn res;\r\n}\r\nstatic int srp_rport_set_state(struct srp_rport *rport,\r\nenum srp_rport_state new_state)\r\n{\r\nenum srp_rport_state old_state = rport->state;\r\nlockdep_assert_held(&rport->mutex);\r\nswitch (new_state) {\r\ncase SRP_RPORT_RUNNING:\r\nswitch (old_state) {\r\ncase SRP_RPORT_LOST:\r\ngoto invalid;\r\ndefault:\r\nbreak;\r\n}\r\nbreak;\r\ncase SRP_RPORT_BLOCKED:\r\nswitch (old_state) {\r\ncase SRP_RPORT_RUNNING:\r\nbreak;\r\ndefault:\r\ngoto invalid;\r\n}\r\nbreak;\r\ncase SRP_RPORT_FAIL_FAST:\r\nswitch (old_state) {\r\ncase SRP_RPORT_LOST:\r\ngoto invalid;\r\ndefault:\r\nbreak;\r\n}\r\nbreak;\r\ncase SRP_RPORT_LOST:\r\nbreak;\r\n}\r\nrport->state = new_state;\r\nreturn 0;\r\ninvalid:\r\nreturn -EINVAL;\r\n}\r\nstatic void srp_reconnect_work(struct work_struct *work)\r\n{\r\nstruct srp_rport *rport = container_of(to_delayed_work(work),\r\nstruct srp_rport, reconnect_work);\r\nstruct Scsi_Host *shost = rport_to_shost(rport);\r\nint delay, res;\r\nres = srp_reconnect_rport(rport);\r\nif (res != 0) {\r\nshost_printk(KERN_ERR, shost,\r\n"reconnect attempt %d failed (%d)\n",\r\n++rport->failed_reconnects, res);\r\ndelay = rport->reconnect_delay *\r\nmin(100, max(1, rport->failed_reconnects - 10));\r\nif (delay > 0)\r\nqueue_delayed_work(system_long_wq,\r\n&rport->reconnect_work, delay * HZ);\r\n}\r\n}\r\nstatic void __rport_fail_io_fast(struct srp_rport *rport)\r\n{\r\nstruct Scsi_Host *shost = rport_to_shost(rport);\r\nstruct srp_internal *i;\r\nlockdep_assert_held(&rport->mutex);\r\nif (srp_rport_set_state(rport, SRP_RPORT_FAIL_FAST))\r\nreturn;\r\nscsi_target_block(rport->dev.parent);\r\nscsi_target_unblock(rport->dev.parent, SDEV_TRANSPORT_OFFLINE);\r\ni = to_srp_internal(shost->transportt);\r\nif (i->f->terminate_rport_io)\r\ni->f->terminate_rport_io(rport);\r\n}\r\nstatic void rport_fast_io_fail_timedout(struct work_struct *work)\r\n{\r\nstruct srp_rport *rport = container_of(to_delayed_work(work),\r\nstruct srp_rport, fast_io_fail_work);\r\nstruct Scsi_Host *shost = rport_to_shost(rport);\r\npr_info("fast_io_fail_tmo expired for SRP %s / %s.\n",\r\ndev_name(&rport->dev), dev_name(&shost->shost_gendev));\r\nmutex_lock(&rport->mutex);\r\nif (rport->state == SRP_RPORT_BLOCKED)\r\n__rport_fail_io_fast(rport);\r\nmutex_unlock(&rport->mutex);\r\n}\r\nstatic void rport_dev_loss_timedout(struct work_struct *work)\r\n{\r\nstruct srp_rport *rport = container_of(to_delayed_work(work),\r\nstruct srp_rport, dev_loss_work);\r\nstruct Scsi_Host *shost = rport_to_shost(rport);\r\nstruct srp_internal *i = to_srp_internal(shost->transportt);\r\npr_info("dev_loss_tmo expired for SRP %s / %s.\n",\r\ndev_name(&rport->dev), dev_name(&shost->shost_gendev));\r\nmutex_lock(&rport->mutex);\r\nWARN_ON(srp_rport_set_state(rport, SRP_RPORT_LOST) != 0);\r\nscsi_target_unblock(rport->dev.parent, SDEV_TRANSPORT_OFFLINE);\r\nmutex_unlock(&rport->mutex);\r\ni->f->rport_delete(rport);\r\n}\r\nstatic void __srp_start_tl_fail_timers(struct srp_rport *rport)\r\n{\r\nstruct Scsi_Host *shost = rport_to_shost(rport);\r\nint delay, fast_io_fail_tmo, dev_loss_tmo;\r\nlockdep_assert_held(&rport->mutex);\r\ndelay = rport->reconnect_delay;\r\nfast_io_fail_tmo = rport->fast_io_fail_tmo;\r\ndev_loss_tmo = rport->dev_loss_tmo;\r\npr_debug("%s current state: %d\n", dev_name(&shost->shost_gendev),\r\nrport->state);\r\nif (rport->state == SRP_RPORT_LOST)\r\nreturn;\r\nif (delay > 0)\r\nqueue_delayed_work(system_long_wq, &rport->reconnect_work,\r\n1UL * delay * HZ);\r\nif ((fast_io_fail_tmo >= 0 || dev_loss_tmo >= 0) &&\r\nsrp_rport_set_state(rport, SRP_RPORT_BLOCKED) == 0) {\r\npr_debug("%s new state: %d\n", dev_name(&shost->shost_gendev),\r\nrport->state);\r\nscsi_target_block(&shost->shost_gendev);\r\nif (fast_io_fail_tmo >= 0)\r\nqueue_delayed_work(system_long_wq,\r\n&rport->fast_io_fail_work,\r\n1UL * fast_io_fail_tmo * HZ);\r\nif (dev_loss_tmo >= 0)\r\nqueue_delayed_work(system_long_wq,\r\n&rport->dev_loss_work,\r\n1UL * dev_loss_tmo * HZ);\r\n}\r\n}\r\nvoid srp_start_tl_fail_timers(struct srp_rport *rport)\r\n{\r\nmutex_lock(&rport->mutex);\r\n__srp_start_tl_fail_timers(rport);\r\nmutex_unlock(&rport->mutex);\r\n}\r\nint srp_reconnect_rport(struct srp_rport *rport)\r\n{\r\nstruct Scsi_Host *shost = rport_to_shost(rport);\r\nstruct srp_internal *i = to_srp_internal(shost->transportt);\r\nstruct scsi_device *sdev;\r\nint res;\r\npr_debug("SCSI host %s\n", dev_name(&shost->shost_gendev));\r\nres = mutex_lock_interruptible(&rport->mutex);\r\nif (res)\r\ngoto out;\r\nscsi_target_block(&shost->shost_gendev);\r\nres = rport->state != SRP_RPORT_LOST ? i->f->reconnect(rport) : -ENODEV;\r\npr_debug("%s (state %d): transport.reconnect() returned %d\n",\r\ndev_name(&shost->shost_gendev), rport->state, res);\r\nif (res == 0) {\r\ncancel_delayed_work(&rport->fast_io_fail_work);\r\ncancel_delayed_work(&rport->dev_loss_work);\r\nrport->failed_reconnects = 0;\r\nsrp_rport_set_state(rport, SRP_RPORT_RUNNING);\r\nscsi_target_unblock(&shost->shost_gendev, SDEV_RUNNING);\r\nspin_lock_irq(shost->host_lock);\r\n__shost_for_each_device(sdev, shost)\r\nif (sdev->sdev_state == SDEV_OFFLINE)\r\nsdev->sdev_state = SDEV_RUNNING;\r\nspin_unlock_irq(shost->host_lock);\r\n} else if (rport->state == SRP_RPORT_RUNNING) {\r\n__rport_fail_io_fast(rport);\r\nscsi_target_unblock(&shost->shost_gendev,\r\nSDEV_TRANSPORT_OFFLINE);\r\n__srp_start_tl_fail_timers(rport);\r\n} else if (rport->state != SRP_RPORT_BLOCKED) {\r\nscsi_target_unblock(&shost->shost_gendev,\r\nSDEV_TRANSPORT_OFFLINE);\r\n}\r\nmutex_unlock(&rport->mutex);\r\nout:\r\nreturn res;\r\n}\r\nenum blk_eh_timer_return srp_timed_out(struct scsi_cmnd *scmd)\r\n{\r\nstruct scsi_device *sdev = scmd->device;\r\nstruct Scsi_Host *shost = sdev->host;\r\nstruct srp_internal *i = to_srp_internal(shost->transportt);\r\nstruct srp_rport *rport = shost_to_rport(shost);\r\npr_debug("timeout for sdev %s\n", dev_name(&sdev->sdev_gendev));\r\nreturn rport->fast_io_fail_tmo < 0 && rport->dev_loss_tmo < 0 &&\r\ni->f->reset_timer_if_blocked && scsi_device_blocked(sdev) ?\r\nBLK_EH_RESET_TIMER : BLK_EH_NOT_HANDLED;\r\n}\r\nstatic void srp_rport_release(struct device *dev)\r\n{\r\nstruct srp_rport *rport = dev_to_rport(dev);\r\nput_device(dev->parent);\r\nkfree(rport);\r\n}\r\nstatic int scsi_is_srp_rport(const struct device *dev)\r\n{\r\nreturn dev->release == srp_rport_release;\r\n}\r\nstatic int srp_rport_match(struct attribute_container *cont,\r\nstruct device *dev)\r\n{\r\nstruct Scsi_Host *shost;\r\nstruct srp_internal *i;\r\nif (!scsi_is_srp_rport(dev))\r\nreturn 0;\r\nshost = dev_to_shost(dev->parent);\r\nif (!shost->transportt)\r\nreturn 0;\r\nif (shost->transportt->host_attrs.ac.class != &srp_host_class.class)\r\nreturn 0;\r\ni = to_srp_internal(shost->transportt);\r\nreturn &i->rport_attr_cont.ac == cont;\r\n}\r\nstatic int srp_host_match(struct attribute_container *cont, struct device *dev)\r\n{\r\nstruct Scsi_Host *shost;\r\nstruct srp_internal *i;\r\nif (!scsi_is_host_device(dev))\r\nreturn 0;\r\nshost = dev_to_shost(dev);\r\nif (!shost->transportt)\r\nreturn 0;\r\nif (shost->transportt->host_attrs.ac.class != &srp_host_class.class)\r\nreturn 0;\r\ni = to_srp_internal(shost->transportt);\r\nreturn &i->t.host_attrs.ac == cont;\r\n}\r\nvoid srp_rport_get(struct srp_rport *rport)\r\n{\r\nget_device(&rport->dev);\r\n}\r\nvoid srp_rport_put(struct srp_rport *rport)\r\n{\r\nput_device(&rport->dev);\r\n}\r\nstruct srp_rport *srp_rport_add(struct Scsi_Host *shost,\r\nstruct srp_rport_identifiers *ids)\r\n{\r\nstruct srp_rport *rport;\r\nstruct device *parent = &shost->shost_gendev;\r\nstruct srp_internal *i = to_srp_internal(shost->transportt);\r\nint id, ret;\r\nrport = kzalloc(sizeof(*rport), GFP_KERNEL);\r\nif (!rport)\r\nreturn ERR_PTR(-ENOMEM);\r\nmutex_init(&rport->mutex);\r\ndevice_initialize(&rport->dev);\r\nrport->dev.parent = get_device(parent);\r\nrport->dev.release = srp_rport_release;\r\nmemcpy(rport->port_id, ids->port_id, sizeof(rport->port_id));\r\nrport->roles = ids->roles;\r\nif (i->f->reconnect)\r\nrport->reconnect_delay = i->f->reconnect_delay ?\r\n*i->f->reconnect_delay : 10;\r\nINIT_DELAYED_WORK(&rport->reconnect_work, srp_reconnect_work);\r\nrport->fast_io_fail_tmo = i->f->fast_io_fail_tmo ?\r\n*i->f->fast_io_fail_tmo : 15;\r\nrport->dev_loss_tmo = i->f->dev_loss_tmo ? *i->f->dev_loss_tmo : 60;\r\nINIT_DELAYED_WORK(&rport->fast_io_fail_work,\r\nrport_fast_io_fail_timedout);\r\nINIT_DELAYED_WORK(&rport->dev_loss_work, rport_dev_loss_timedout);\r\nid = atomic_inc_return(&to_srp_host_attrs(shost)->next_port_id);\r\ndev_set_name(&rport->dev, "port-%d:%d", shost->host_no, id);\r\ntransport_setup_device(&rport->dev);\r\nret = device_add(&rport->dev);\r\nif (ret) {\r\ntransport_destroy_device(&rport->dev);\r\nput_device(&rport->dev);\r\nreturn ERR_PTR(ret);\r\n}\r\ntransport_add_device(&rport->dev);\r\ntransport_configure_device(&rport->dev);\r\nreturn rport;\r\n}\r\nvoid srp_rport_del(struct srp_rport *rport)\r\n{\r\nstruct device *dev = &rport->dev;\r\ntransport_remove_device(dev);\r\ndevice_del(dev);\r\ntransport_destroy_device(dev);\r\nput_device(dev);\r\n}\r\nstatic int do_srp_rport_del(struct device *dev, void *data)\r\n{\r\nif (scsi_is_srp_rport(dev))\r\nsrp_rport_del(dev_to_rport(dev));\r\nreturn 0;\r\n}\r\nvoid srp_remove_host(struct Scsi_Host *shost)\r\n{\r\ndevice_for_each_child(&shost->shost_gendev, NULL, do_srp_rport_del);\r\n}\r\nvoid srp_stop_rport_timers(struct srp_rport *rport)\r\n{\r\nmutex_lock(&rport->mutex);\r\nif (rport->state == SRP_RPORT_BLOCKED)\r\n__rport_fail_io_fast(rport);\r\nsrp_rport_set_state(rport, SRP_RPORT_LOST);\r\nmutex_unlock(&rport->mutex);\r\ncancel_delayed_work_sync(&rport->reconnect_work);\r\ncancel_delayed_work_sync(&rport->fast_io_fail_work);\r\ncancel_delayed_work_sync(&rport->dev_loss_work);\r\n}\r\nstruct scsi_transport_template *\r\nsrp_attach_transport(struct srp_function_template *ft)\r\n{\r\nint count;\r\nstruct srp_internal *i;\r\ni = kzalloc(sizeof(*i), GFP_KERNEL);\r\nif (!i)\r\nreturn NULL;\r\ni->t.host_size = sizeof(struct srp_host_attrs);\r\ni->t.host_attrs.ac.attrs = &i->host_attrs[0];\r\ni->t.host_attrs.ac.class = &srp_host_class.class;\r\ni->t.host_attrs.ac.match = srp_host_match;\r\ni->host_attrs[0] = NULL;\r\ntransport_container_register(&i->t.host_attrs);\r\ni->rport_attr_cont.ac.attrs = &i->rport_attrs[0];\r\ni->rport_attr_cont.ac.class = &srp_rport_class.class;\r\ni->rport_attr_cont.ac.match = srp_rport_match;\r\ncount = 0;\r\ni->rport_attrs[count++] = &dev_attr_port_id;\r\ni->rport_attrs[count++] = &dev_attr_roles;\r\nif (ft->has_rport_state) {\r\ni->rport_attrs[count++] = &dev_attr_state;\r\ni->rport_attrs[count++] = &dev_attr_fast_io_fail_tmo;\r\ni->rport_attrs[count++] = &dev_attr_dev_loss_tmo;\r\n}\r\nif (ft->reconnect) {\r\ni->rport_attrs[count++] = &dev_attr_reconnect_delay;\r\ni->rport_attrs[count++] = &dev_attr_failed_reconnects;\r\n}\r\nif (ft->rport_delete)\r\ni->rport_attrs[count++] = &dev_attr_delete;\r\ni->rport_attrs[count++] = NULL;\r\nBUG_ON(count > ARRAY_SIZE(i->rport_attrs));\r\ntransport_container_register(&i->rport_attr_cont);\r\ni->f = ft;\r\nreturn &i->t;\r\n}\r\nvoid srp_release_transport(struct scsi_transport_template *t)\r\n{\r\nstruct srp_internal *i = to_srp_internal(t);\r\ntransport_container_unregister(&i->t.host_attrs);\r\ntransport_container_unregister(&i->rport_attr_cont);\r\nkfree(i);\r\n}\r\nstatic __init int srp_transport_init(void)\r\n{\r\nint ret;\r\nret = transport_class_register(&srp_host_class);\r\nif (ret)\r\nreturn ret;\r\nret = transport_class_register(&srp_rport_class);\r\nif (ret)\r\ngoto unregister_host_class;\r\nreturn 0;\r\nunregister_host_class:\r\ntransport_class_unregister(&srp_host_class);\r\nreturn ret;\r\n}\r\nstatic void __exit srp_transport_exit(void)\r\n{\r\ntransport_class_unregister(&srp_host_class);\r\ntransport_class_unregister(&srp_rport_class);\r\n}
