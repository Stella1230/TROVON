static int __init softlockup_panic_setup(char *str)\r\n{\r\nsoftlockup_panic = simple_strtoul(str, NULL, 0);\r\nreturn 1;\r\n}\r\nstatic int __init nowatchdog_setup(char *str)\r\n{\r\nwatchdog_enabled = 0;\r\nreturn 1;\r\n}\r\nstatic int __init nosoftlockup_setup(char *str)\r\n{\r\nwatchdog_enabled &= ~SOFT_WATCHDOG_ENABLED;\r\nreturn 1;\r\n}\r\nstatic int __init softlockup_all_cpu_backtrace_setup(char *str)\r\n{\r\nsysctl_softlockup_all_cpu_backtrace =\r\n!!simple_strtol(str, NULL, 0);\r\nreturn 1;\r\n}\r\nstatic int __init hardlockup_all_cpu_backtrace_setup(char *str)\r\n{\r\nsysctl_hardlockup_all_cpu_backtrace =\r\n!!simple_strtol(str, NULL, 0);\r\nreturn 1;\r\n}\r\nstatic int get_softlockup_thresh(void)\r\n{\r\nreturn watchdog_thresh * 2;\r\n}\r\nstatic unsigned long get_timestamp(void)\r\n{\r\nreturn running_clock() >> 30LL;\r\n}\r\nstatic void set_sample_period(void)\r\n{\r\nsample_period = get_softlockup_thresh() * ((u64)NSEC_PER_SEC / 5);\r\n}\r\nstatic void __touch_watchdog(void)\r\n{\r\n__this_cpu_write(watchdog_touch_ts, get_timestamp());\r\n}\r\nvoid touch_softlockup_watchdog_sched(void)\r\n{\r\nraw_cpu_write(watchdog_touch_ts, 0);\r\n}\r\nvoid touch_softlockup_watchdog(void)\r\n{\r\ntouch_softlockup_watchdog_sched();\r\nwq_watchdog_touch(raw_smp_processor_id());\r\n}\r\nvoid touch_all_softlockup_watchdogs(void)\r\n{\r\nint cpu;\r\nfor_each_watchdog_cpu(cpu)\r\nper_cpu(watchdog_touch_ts, cpu) = 0;\r\nwq_watchdog_touch(-1);\r\n}\r\nvoid touch_softlockup_watchdog_sync(void)\r\n{\r\n__this_cpu_write(softlockup_touch_sync, true);\r\n__this_cpu_write(watchdog_touch_ts, 0);\r\n}\r\nbool is_hardlockup(void)\r\n{\r\nunsigned long hrint = __this_cpu_read(hrtimer_interrupts);\r\nif (__this_cpu_read(hrtimer_interrupts_saved) == hrint)\r\nreturn true;\r\n__this_cpu_write(hrtimer_interrupts_saved, hrint);\r\nreturn false;\r\n}\r\nstatic int is_softlockup(unsigned long touch_ts)\r\n{\r\nunsigned long now = get_timestamp();\r\nif ((watchdog_enabled & SOFT_WATCHDOG_ENABLED) && watchdog_thresh){\r\nif (time_after(now, touch_ts + get_softlockup_thresh()))\r\nreturn now - touch_ts;\r\n}\r\nreturn 0;\r\n}\r\nstatic void watchdog_interrupt_count(void)\r\n{\r\n__this_cpu_inc(hrtimer_interrupts);\r\n}\r\nint __weak watchdog_nmi_enable(unsigned int cpu)\r\n{\r\nreturn 0;\r\n}\r\nvoid __weak watchdog_nmi_disable(unsigned int cpu)\r\n{\r\n}\r\nstatic enum hrtimer_restart watchdog_timer_fn(struct hrtimer *hrtimer)\r\n{\r\nunsigned long touch_ts = __this_cpu_read(watchdog_touch_ts);\r\nstruct pt_regs *regs = get_irq_regs();\r\nint duration;\r\nint softlockup_all_cpu_backtrace = sysctl_softlockup_all_cpu_backtrace;\r\nif (atomic_read(&watchdog_park_in_progress) != 0)\r\nreturn HRTIMER_NORESTART;\r\nwatchdog_interrupt_count();\r\nwake_up_process(__this_cpu_read(softlockup_watchdog));\r\nhrtimer_forward_now(hrtimer, ns_to_ktime(sample_period));\r\nif (touch_ts == 0) {\r\nif (unlikely(__this_cpu_read(softlockup_touch_sync))) {\r\n__this_cpu_write(softlockup_touch_sync, false);\r\nsched_clock_tick();\r\n}\r\nkvm_check_and_clear_guest_paused();\r\n__touch_watchdog();\r\nreturn HRTIMER_RESTART;\r\n}\r\nduration = is_softlockup(touch_ts);\r\nif (unlikely(duration)) {\r\nif (kvm_check_and_clear_guest_paused())\r\nreturn HRTIMER_RESTART;\r\nif (__this_cpu_read(soft_watchdog_warn) == true) {\r\nif (__this_cpu_read(softlockup_task_ptr_saved) !=\r\ncurrent) {\r\n__this_cpu_write(soft_watchdog_warn, false);\r\n__touch_watchdog();\r\n}\r\nreturn HRTIMER_RESTART;\r\n}\r\nif (softlockup_all_cpu_backtrace) {\r\nif (test_and_set_bit(0, &soft_lockup_nmi_warn)) {\r\n__this_cpu_write(soft_watchdog_warn, true);\r\nreturn HRTIMER_RESTART;\r\n}\r\n}\r\npr_emerg("BUG: soft lockup - CPU#%d stuck for %us! [%s:%d]\n",\r\nsmp_processor_id(), duration,\r\ncurrent->comm, task_pid_nr(current));\r\n__this_cpu_write(softlockup_task_ptr_saved, current);\r\nprint_modules();\r\nprint_irqtrace_events(current);\r\nif (regs)\r\nshow_regs(regs);\r\nelse\r\ndump_stack();\r\nif (softlockup_all_cpu_backtrace) {\r\ntrigger_allbutself_cpu_backtrace();\r\nclear_bit(0, &soft_lockup_nmi_warn);\r\nsmp_mb__after_atomic();\r\n}\r\nadd_taint(TAINT_SOFTLOCKUP, LOCKDEP_STILL_OK);\r\nif (softlockup_panic)\r\npanic("softlockup: hung tasks");\r\n__this_cpu_write(soft_watchdog_warn, true);\r\n} else\r\n__this_cpu_write(soft_watchdog_warn, false);\r\nreturn HRTIMER_RESTART;\r\n}\r\nstatic void watchdog_set_prio(unsigned int policy, unsigned int prio)\r\n{\r\nstruct sched_param param = { .sched_priority = prio };\r\nsched_setscheduler(current, policy, &param);\r\n}\r\nstatic void watchdog_enable(unsigned int cpu)\r\n{\r\nstruct hrtimer *hrtimer = raw_cpu_ptr(&watchdog_hrtimer);\r\nhrtimer_init(hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\r\nhrtimer->function = watchdog_timer_fn;\r\nwatchdog_nmi_enable(cpu);\r\nhrtimer_start(hrtimer, ns_to_ktime(sample_period),\r\nHRTIMER_MODE_REL_PINNED);\r\nwatchdog_set_prio(SCHED_FIFO, MAX_RT_PRIO - 1);\r\n__touch_watchdog();\r\n}\r\nstatic void watchdog_disable(unsigned int cpu)\r\n{\r\nstruct hrtimer *hrtimer = raw_cpu_ptr(&watchdog_hrtimer);\r\nwatchdog_set_prio(SCHED_NORMAL, 0);\r\nhrtimer_cancel(hrtimer);\r\nwatchdog_nmi_disable(cpu);\r\n}\r\nstatic void watchdog_cleanup(unsigned int cpu, bool online)\r\n{\r\nwatchdog_disable(cpu);\r\n}\r\nstatic int watchdog_should_run(unsigned int cpu)\r\n{\r\nreturn __this_cpu_read(hrtimer_interrupts) !=\r\n__this_cpu_read(soft_lockup_hrtimer_cnt);\r\n}\r\nstatic void watchdog(unsigned int cpu)\r\n{\r\n__this_cpu_write(soft_lockup_hrtimer_cnt,\r\n__this_cpu_read(hrtimer_interrupts));\r\n__touch_watchdog();\r\nif (!(watchdog_enabled & NMI_WATCHDOG_ENABLED))\r\nwatchdog_nmi_disable(cpu);\r\n}\r\nstatic int watchdog_park_threads(void)\r\n{\r\nint cpu, ret = 0;\r\natomic_set(&watchdog_park_in_progress, 1);\r\nfor_each_watchdog_cpu(cpu) {\r\nret = kthread_park(per_cpu(softlockup_watchdog, cpu));\r\nif (ret)\r\nbreak;\r\n}\r\natomic_set(&watchdog_park_in_progress, 0);\r\nreturn ret;\r\n}\r\nstatic void watchdog_unpark_threads(void)\r\n{\r\nint cpu;\r\nfor_each_watchdog_cpu(cpu)\r\nkthread_unpark(per_cpu(softlockup_watchdog, cpu));\r\n}\r\nint lockup_detector_suspend(void)\r\n{\r\nint ret = 0;\r\nget_online_cpus();\r\nmutex_lock(&watchdog_proc_mutex);\r\nif (watchdog_running && !watchdog_suspended)\r\nret = watchdog_park_threads();\r\nif (ret == 0)\r\nwatchdog_suspended++;\r\nelse {\r\nwatchdog_disable_all_cpus();\r\npr_err("Failed to suspend lockup detectors, disabled\n");\r\nwatchdog_enabled = 0;\r\n}\r\nmutex_unlock(&watchdog_proc_mutex);\r\nreturn ret;\r\n}\r\nvoid lockup_detector_resume(void)\r\n{\r\nmutex_lock(&watchdog_proc_mutex);\r\nwatchdog_suspended--;\r\nif (watchdog_running && !watchdog_suspended)\r\nwatchdog_unpark_threads();\r\nmutex_unlock(&watchdog_proc_mutex);\r\nput_online_cpus();\r\n}\r\nstatic int update_watchdog_all_cpus(void)\r\n{\r\nint ret;\r\nret = watchdog_park_threads();\r\nif (ret)\r\nreturn ret;\r\nwatchdog_unpark_threads();\r\nreturn 0;\r\n}\r\nstatic int watchdog_enable_all_cpus(void)\r\n{\r\nint err = 0;\r\nif (!watchdog_running) {\r\nerr = smpboot_register_percpu_thread_cpumask(&watchdog_threads,\r\n&watchdog_cpumask);\r\nif (err)\r\npr_err("Failed to create watchdog threads, disabled\n");\r\nelse\r\nwatchdog_running = 1;\r\n} else {\r\nerr = update_watchdog_all_cpus();\r\nif (err) {\r\nwatchdog_disable_all_cpus();\r\npr_err("Failed to update lockup detectors, disabled\n");\r\n}\r\n}\r\nif (err)\r\nwatchdog_enabled = 0;\r\nreturn err;\r\n}\r\nstatic void watchdog_disable_all_cpus(void)\r\n{\r\nif (watchdog_running) {\r\nwatchdog_running = 0;\r\nsmpboot_unregister_percpu_thread(&watchdog_threads);\r\n}\r\n}\r\nstatic int proc_watchdog_update(void)\r\n{\r\nint err = 0;\r\nif (watchdog_enabled && watchdog_thresh)\r\nerr = watchdog_enable_all_cpus();\r\nelse\r\nwatchdog_disable_all_cpus();\r\nreturn err;\r\n}\r\nstatic int proc_watchdog_common(int which, struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nint err, old, new;\r\nint *watchdog_param = (int *)table->data;\r\nget_online_cpus();\r\nmutex_lock(&watchdog_proc_mutex);\r\nif (watchdog_suspended) {\r\nerr = -EAGAIN;\r\ngoto out;\r\n}\r\nif (!write) {\r\n*watchdog_param = (watchdog_enabled & which) != 0;\r\nerr = proc_dointvec_minmax(table, write, buffer, lenp, ppos);\r\n} else {\r\nerr = proc_dointvec_minmax(table, write, buffer, lenp, ppos);\r\nif (err)\r\ngoto out;\r\ndo {\r\nold = watchdog_enabled;\r\nif (*watchdog_param)\r\nnew = old | which;\r\nelse\r\nnew = old & ~which;\r\n} while (cmpxchg(&watchdog_enabled, old, new) != old);\r\nif (old == new)\r\ngoto out;\r\nerr = proc_watchdog_update();\r\n}\r\nout:\r\nmutex_unlock(&watchdog_proc_mutex);\r\nput_online_cpus();\r\nreturn err;\r\n}\r\nint proc_watchdog(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nreturn proc_watchdog_common(NMI_WATCHDOG_ENABLED|SOFT_WATCHDOG_ENABLED,\r\ntable, write, buffer, lenp, ppos);\r\n}\r\nint proc_nmi_watchdog(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nreturn proc_watchdog_common(NMI_WATCHDOG_ENABLED,\r\ntable, write, buffer, lenp, ppos);\r\n}\r\nint proc_soft_watchdog(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nreturn proc_watchdog_common(SOFT_WATCHDOG_ENABLED,\r\ntable, write, buffer, lenp, ppos);\r\n}\r\nint proc_watchdog_thresh(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nint err, old, new;\r\nget_online_cpus();\r\nmutex_lock(&watchdog_proc_mutex);\r\nif (watchdog_suspended) {\r\nerr = -EAGAIN;\r\ngoto out;\r\n}\r\nold = ACCESS_ONCE(watchdog_thresh);\r\nerr = proc_dointvec_minmax(table, write, buffer, lenp, ppos);\r\nif (err || !write)\r\ngoto out;\r\nnew = ACCESS_ONCE(watchdog_thresh);\r\nif (old == new)\r\ngoto out;\r\nset_sample_period();\r\nerr = proc_watchdog_update();\r\nif (err) {\r\nwatchdog_thresh = old;\r\nset_sample_period();\r\n}\r\nout:\r\nmutex_unlock(&watchdog_proc_mutex);\r\nput_online_cpus();\r\nreturn err;\r\n}\r\nint proc_watchdog_cpumask(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nint err;\r\nget_online_cpus();\r\nmutex_lock(&watchdog_proc_mutex);\r\nif (watchdog_suspended) {\r\nerr = -EAGAIN;\r\ngoto out;\r\n}\r\nerr = proc_do_large_bitmap(table, write, buffer, lenp, ppos);\r\nif (!err && write) {\r\ncpumask_and(&watchdog_cpumask, &watchdog_cpumask,\r\ncpu_possible_mask);\r\nif (watchdog_running) {\r\nif (smpboot_update_cpumask_percpu_thread(\r\n&watchdog_threads, &watchdog_cpumask) != 0)\r\npr_err("cpumask update failed\n");\r\n}\r\n}\r\nout:\r\nmutex_unlock(&watchdog_proc_mutex);\r\nput_online_cpus();\r\nreturn err;\r\n}\r\nvoid __init lockup_detector_init(void)\r\n{\r\nset_sample_period();\r\n#ifdef CONFIG_NO_HZ_FULL\r\nif (tick_nohz_full_enabled()) {\r\npr_info("Disabling watchdog on nohz_full cores by default\n");\r\ncpumask_copy(&watchdog_cpumask, housekeeping_mask);\r\n} else\r\ncpumask_copy(&watchdog_cpumask, cpu_possible_mask);\r\n#else\r\ncpumask_copy(&watchdog_cpumask, cpu_possible_mask);\r\n#endif\r\nif (watchdog_enabled)\r\nwatchdog_enable_all_cpus();\r\n}
