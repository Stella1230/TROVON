static int bnxt_register_dev(struct bnxt_en_dev *edev, int ulp_id,\r\nstruct bnxt_ulp_ops *ulp_ops, void *handle)\r\n{\r\nstruct net_device *dev = edev->net;\r\nstruct bnxt *bp = netdev_priv(dev);\r\nstruct bnxt_ulp *ulp;\r\nASSERT_RTNL();\r\nif (ulp_id >= BNXT_MAX_ULP)\r\nreturn -EINVAL;\r\nulp = &edev->ulp_tbl[ulp_id];\r\nif (rcu_access_pointer(ulp->ulp_ops)) {\r\nnetdev_err(bp->dev, "ulp id %d already registered\n", ulp_id);\r\nreturn -EBUSY;\r\n}\r\nif (ulp_id == BNXT_ROCE_ULP) {\r\nunsigned int max_stat_ctxs;\r\nmax_stat_ctxs = bnxt_get_max_func_stat_ctxs(bp);\r\nif (max_stat_ctxs <= BNXT_MIN_ROCE_STAT_CTXS ||\r\nbp->num_stat_ctxs == max_stat_ctxs)\r\nreturn -ENOMEM;\r\nbnxt_set_max_func_stat_ctxs(bp, max_stat_ctxs -\r\nBNXT_MIN_ROCE_STAT_CTXS);\r\n}\r\natomic_set(&ulp->ref_count, 0);\r\nulp->handle = handle;\r\nrcu_assign_pointer(ulp->ulp_ops, ulp_ops);\r\nif (ulp_id == BNXT_ROCE_ULP) {\r\nif (test_bit(BNXT_STATE_OPEN, &bp->state))\r\nbnxt_hwrm_vnic_cfg(bp, 0);\r\n}\r\nreturn 0;\r\n}\r\nstatic int bnxt_unregister_dev(struct bnxt_en_dev *edev, int ulp_id)\r\n{\r\nstruct net_device *dev = edev->net;\r\nstruct bnxt *bp = netdev_priv(dev);\r\nstruct bnxt_ulp *ulp;\r\nint i = 0;\r\nASSERT_RTNL();\r\nif (ulp_id >= BNXT_MAX_ULP)\r\nreturn -EINVAL;\r\nulp = &edev->ulp_tbl[ulp_id];\r\nif (!rcu_access_pointer(ulp->ulp_ops)) {\r\nnetdev_err(bp->dev, "ulp id %d not registered\n", ulp_id);\r\nreturn -EINVAL;\r\n}\r\nif (ulp_id == BNXT_ROCE_ULP) {\r\nunsigned int max_stat_ctxs;\r\nmax_stat_ctxs = bnxt_get_max_func_stat_ctxs(bp);\r\nbnxt_set_max_func_stat_ctxs(bp, max_stat_ctxs + 1);\r\n}\r\nif (ulp->max_async_event_id)\r\nbnxt_hwrm_func_rgtr_async_events(bp, NULL, 0);\r\nRCU_INIT_POINTER(ulp->ulp_ops, NULL);\r\nsynchronize_rcu();\r\nulp->max_async_event_id = 0;\r\nulp->async_events_bmap = NULL;\r\nwhile (atomic_read(&ulp->ref_count) != 0 && i < 10) {\r\nmsleep(100);\r\ni++;\r\n}\r\nreturn 0;\r\n}\r\nstatic int bnxt_req_msix_vecs(struct bnxt_en_dev *edev, int ulp_id,\r\nstruct bnxt_msix_entry *ent, int num_msix)\r\n{\r\nstruct net_device *dev = edev->net;\r\nstruct bnxt *bp = netdev_priv(dev);\r\nint max_idx, max_cp_rings;\r\nint avail_msix, i, idx;\r\nASSERT_RTNL();\r\nif (ulp_id != BNXT_ROCE_ULP)\r\nreturn -EINVAL;\r\nif (!(bp->flags & BNXT_FLAG_USING_MSIX))\r\nreturn -ENODEV;\r\nmax_cp_rings = bnxt_get_max_func_cp_rings(bp);\r\nmax_idx = min_t(int, bp->total_irqs, max_cp_rings);\r\navail_msix = max_idx - bp->cp_nr_rings;\r\nif (!avail_msix)\r\nreturn -ENOMEM;\r\nif (avail_msix > num_msix)\r\navail_msix = num_msix;\r\nidx = max_idx - avail_msix;\r\nfor (i = 0; i < avail_msix; i++) {\r\nent[i].vector = bp->irq_tbl[idx + i].vector;\r\nent[i].ring_idx = idx + i;\r\nent[i].db_offset = (idx + i) * 0x80;\r\n}\r\nbnxt_set_max_func_irqs(bp, max_idx - avail_msix);\r\nbnxt_set_max_func_cp_rings(bp, max_cp_rings - avail_msix);\r\nedev->ulp_tbl[ulp_id].msix_requested = avail_msix;\r\nreturn avail_msix;\r\n}\r\nstatic int bnxt_free_msix_vecs(struct bnxt_en_dev *edev, int ulp_id)\r\n{\r\nstruct net_device *dev = edev->net;\r\nstruct bnxt *bp = netdev_priv(dev);\r\nint max_cp_rings, msix_requested;\r\nASSERT_RTNL();\r\nif (ulp_id != BNXT_ROCE_ULP)\r\nreturn -EINVAL;\r\nmax_cp_rings = bnxt_get_max_func_cp_rings(bp);\r\nmsix_requested = edev->ulp_tbl[ulp_id].msix_requested;\r\nbnxt_set_max_func_cp_rings(bp, max_cp_rings + msix_requested);\r\nedev->ulp_tbl[ulp_id].msix_requested = 0;\r\nbnxt_set_max_func_irqs(bp, bp->total_irqs);\r\nreturn 0;\r\n}\r\nvoid bnxt_subtract_ulp_resources(struct bnxt *bp, int ulp_id)\r\n{\r\nASSERT_RTNL();\r\nif (bnxt_ulp_registered(bp->edev, ulp_id)) {\r\nstruct bnxt_en_dev *edev = bp->edev;\r\nunsigned int msix_req, max;\r\nmsix_req = edev->ulp_tbl[ulp_id].msix_requested;\r\nmax = bnxt_get_max_func_cp_rings(bp);\r\nbnxt_set_max_func_cp_rings(bp, max - msix_req);\r\nmax = bnxt_get_max_func_stat_ctxs(bp);\r\nbnxt_set_max_func_stat_ctxs(bp, max - 1);\r\n}\r\n}\r\nstatic int bnxt_send_msg(struct bnxt_en_dev *edev, int ulp_id,\r\nstruct bnxt_fw_msg *fw_msg)\r\n{\r\nstruct net_device *dev = edev->net;\r\nstruct bnxt *bp = netdev_priv(dev);\r\nstruct input *req;\r\nint rc;\r\nmutex_lock(&bp->hwrm_cmd_lock);\r\nreq = fw_msg->msg;\r\nreq->resp_addr = cpu_to_le64(bp->hwrm_cmd_resp_dma_addr);\r\nrc = _hwrm_send_message(bp, fw_msg->msg, fw_msg->msg_len,\r\nfw_msg->timeout);\r\nif (!rc) {\r\nstruct output *resp = bp->hwrm_cmd_resp_addr;\r\nu32 len = le16_to_cpu(resp->resp_len);\r\nif (fw_msg->resp_max_len < len)\r\nlen = fw_msg->resp_max_len;\r\nmemcpy(fw_msg->resp, resp, len);\r\n}\r\nmutex_unlock(&bp->hwrm_cmd_lock);\r\nreturn rc;\r\n}\r\nstatic void bnxt_ulp_get(struct bnxt_ulp *ulp)\r\n{\r\natomic_inc(&ulp->ref_count);\r\n}\r\nstatic void bnxt_ulp_put(struct bnxt_ulp *ulp)\r\n{\r\natomic_dec(&ulp->ref_count);\r\n}\r\nvoid bnxt_ulp_stop(struct bnxt *bp)\r\n{\r\nstruct bnxt_en_dev *edev = bp->edev;\r\nstruct bnxt_ulp_ops *ops;\r\nint i;\r\nif (!edev)\r\nreturn;\r\nfor (i = 0; i < BNXT_MAX_ULP; i++) {\r\nstruct bnxt_ulp *ulp = &edev->ulp_tbl[i];\r\nops = rtnl_dereference(ulp->ulp_ops);\r\nif (!ops || !ops->ulp_stop)\r\ncontinue;\r\nops->ulp_stop(ulp->handle);\r\n}\r\n}\r\nvoid bnxt_ulp_start(struct bnxt *bp)\r\n{\r\nstruct bnxt_en_dev *edev = bp->edev;\r\nstruct bnxt_ulp_ops *ops;\r\nint i;\r\nif (!edev)\r\nreturn;\r\nfor (i = 0; i < BNXT_MAX_ULP; i++) {\r\nstruct bnxt_ulp *ulp = &edev->ulp_tbl[i];\r\nops = rtnl_dereference(ulp->ulp_ops);\r\nif (!ops || !ops->ulp_start)\r\ncontinue;\r\nops->ulp_start(ulp->handle);\r\n}\r\n}\r\nvoid bnxt_ulp_sriov_cfg(struct bnxt *bp, int num_vfs)\r\n{\r\nstruct bnxt_en_dev *edev = bp->edev;\r\nstruct bnxt_ulp_ops *ops;\r\nint i;\r\nif (!edev)\r\nreturn;\r\nfor (i = 0; i < BNXT_MAX_ULP; i++) {\r\nstruct bnxt_ulp *ulp = &edev->ulp_tbl[i];\r\nrcu_read_lock();\r\nops = rcu_dereference(ulp->ulp_ops);\r\nif (!ops || !ops->ulp_sriov_config) {\r\nrcu_read_unlock();\r\ncontinue;\r\n}\r\nbnxt_ulp_get(ulp);\r\nrcu_read_unlock();\r\nops->ulp_sriov_config(ulp->handle, num_vfs);\r\nbnxt_ulp_put(ulp);\r\n}\r\n}\r\nvoid bnxt_ulp_async_events(struct bnxt *bp, struct hwrm_async_event_cmpl *cmpl)\r\n{\r\nu16 event_id = le16_to_cpu(cmpl->event_id);\r\nstruct bnxt_en_dev *edev = bp->edev;\r\nstruct bnxt_ulp_ops *ops;\r\nint i;\r\nif (!edev)\r\nreturn;\r\nrcu_read_lock();\r\nfor (i = 0; i < BNXT_MAX_ULP; i++) {\r\nstruct bnxt_ulp *ulp = &edev->ulp_tbl[i];\r\nops = rcu_dereference(ulp->ulp_ops);\r\nif (!ops || !ops->ulp_async_notifier)\r\ncontinue;\r\nif (!ulp->async_events_bmap ||\r\nevent_id > ulp->max_async_event_id)\r\ncontinue;\r\nsmp_rmb();\r\nif (test_bit(event_id, ulp->async_events_bmap))\r\nops->ulp_async_notifier(ulp->handle, cmpl);\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic int bnxt_register_async_events(struct bnxt_en_dev *edev, int ulp_id,\r\nunsigned long *events_bmap, u16 max_id)\r\n{\r\nstruct net_device *dev = edev->net;\r\nstruct bnxt *bp = netdev_priv(dev);\r\nstruct bnxt_ulp *ulp;\r\nif (ulp_id >= BNXT_MAX_ULP)\r\nreturn -EINVAL;\r\nulp = &edev->ulp_tbl[ulp_id];\r\nulp->async_events_bmap = events_bmap;\r\nsmp_wmb();\r\nulp->max_async_event_id = max_id;\r\nbnxt_hwrm_func_rgtr_async_events(bp, events_bmap, max_id + 1);\r\nreturn 0;\r\n}\r\nstruct bnxt_en_dev *bnxt_ulp_probe(struct net_device *dev)\r\n{\r\nstruct bnxt *bp = netdev_priv(dev);\r\nstruct bnxt_en_dev *edev;\r\nedev = bp->edev;\r\nif (!edev) {\r\nedev = kzalloc(sizeof(*edev), GFP_KERNEL);\r\nif (!edev)\r\nreturn ERR_PTR(-ENOMEM);\r\nedev->en_ops = &bnxt_en_ops_tbl;\r\nif (bp->flags & BNXT_FLAG_ROCEV1_CAP)\r\nedev->flags |= BNXT_EN_FLAG_ROCEV1_CAP;\r\nif (bp->flags & BNXT_FLAG_ROCEV2_CAP)\r\nedev->flags |= BNXT_EN_FLAG_ROCEV2_CAP;\r\nedev->net = dev;\r\nedev->pdev = bp->pdev;\r\nbp->edev = edev;\r\n}\r\nreturn bp->edev;\r\n}
