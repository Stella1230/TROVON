void fpu__xstate_clear_all_cpu_caps(void)\r\n{\r\nsetup_clear_cpu_cap(X86_FEATURE_XSAVE);\r\nsetup_clear_cpu_cap(X86_FEATURE_XSAVEOPT);\r\nsetup_clear_cpu_cap(X86_FEATURE_XSAVEC);\r\nsetup_clear_cpu_cap(X86_FEATURE_XSAVES);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX2);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512F);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512IFMA);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512PF);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512ER);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512CD);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512DQ);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512BW);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512VL);\r\nsetup_clear_cpu_cap(X86_FEATURE_MPX);\r\nsetup_clear_cpu_cap(X86_FEATURE_XGETBV1);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512VBMI);\r\nsetup_clear_cpu_cap(X86_FEATURE_PKU);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512_4VNNIW);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512_4FMAPS);\r\nsetup_clear_cpu_cap(X86_FEATURE_AVX512_VPOPCNTDQ);\r\n}\r\nint cpu_has_xfeatures(u64 xfeatures_needed, const char **feature_name)\r\n{\r\nu64 xfeatures_missing = xfeatures_needed & ~xfeatures_mask;\r\nif (unlikely(feature_name)) {\r\nlong xfeature_idx, max_idx;\r\nu64 xfeatures_print;\r\nif (xfeatures_missing)\r\nxfeatures_print = xfeatures_missing;\r\nelse\r\nxfeatures_print = xfeatures_needed;\r\nxfeature_idx = fls64(xfeatures_print)-1;\r\nmax_idx = ARRAY_SIZE(xfeature_names)-1;\r\nxfeature_idx = min(xfeature_idx, max_idx);\r\n*feature_name = xfeature_names[xfeature_idx];\r\n}\r\nif (xfeatures_missing)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic int xfeature_is_supervisor(int xfeature_nr)\r\n{\r\nu32 eax, ebx, ecx, edx;\r\ncpuid_count(XSTATE_CPUID, xfeature_nr, &eax, &ebx, &ecx, &edx);\r\nreturn !!(ecx & 1);\r\n}\r\nstatic int xfeature_is_user(int xfeature_nr)\r\n{\r\nreturn !xfeature_is_supervisor(xfeature_nr);\r\n}\r\nvoid fpstate_sanitize_xstate(struct fpu *fpu)\r\n{\r\nstruct fxregs_state *fx = &fpu->state.fxsave;\r\nint feature_bit;\r\nu64 xfeatures;\r\nif (!use_xsaveopt())\r\nreturn;\r\nxfeatures = fpu->state.xsave.header.xfeatures;\r\nif ((xfeatures & xfeatures_mask) == xfeatures_mask)\r\nreturn;\r\nif (!(xfeatures & XFEATURE_MASK_FP)) {\r\nfx->cwd = 0x37f;\r\nfx->swd = 0;\r\nfx->twd = 0;\r\nfx->fop = 0;\r\nfx->rip = 0;\r\nfx->rdp = 0;\r\nmemset(&fx->st_space[0], 0, 128);\r\n}\r\nif (!(xfeatures & XFEATURE_MASK_SSE))\r\nmemset(&fx->xmm_space[0], 0, 256);\r\nfeature_bit = 0x2;\r\nxfeatures = (xfeatures_mask & ~xfeatures) >> 2;\r\nwhile (xfeatures) {\r\nif (xfeatures & 0x1) {\r\nint offset = xstate_comp_offsets[feature_bit];\r\nint size = xstate_sizes[feature_bit];\r\nmemcpy((void *)fx + offset,\r\n(void *)&init_fpstate.xsave + offset,\r\nsize);\r\n}\r\nxfeatures >>= 1;\r\nfeature_bit++;\r\n}\r\n}\r\nvoid fpu__init_cpu_xstate(void)\r\n{\r\nif (!boot_cpu_has(X86_FEATURE_XSAVE) || !xfeatures_mask)\r\nreturn;\r\nWARN_ONCE((xfeatures_mask & XFEATURE_MASK_SUPERVISOR),\r\n"x86/fpu: XSAVES supervisor states are not yet implemented.\n");\r\nxfeatures_mask &= ~XFEATURE_MASK_SUPERVISOR;\r\ncr4_set_bits(X86_CR4_OSXSAVE);\r\nxsetbv(XCR_XFEATURE_ENABLED_MASK, xfeatures_mask);\r\n}\r\nstatic int xfeature_enabled(enum xfeature xfeature)\r\n{\r\nreturn !!(xfeatures_mask & (1UL << xfeature));\r\n}\r\nstatic void __init setup_xstate_features(void)\r\n{\r\nu32 eax, ebx, ecx, edx, i;\r\nunsigned int last_good_offset = offsetof(struct xregs_state,\r\nextended_state_area);\r\nxstate_offsets[0] = 0;\r\nxstate_sizes[0] = offsetof(struct fxregs_state, xmm_space);\r\nxstate_offsets[1] = xstate_sizes[0];\r\nxstate_sizes[1] = FIELD_SIZEOF(struct fxregs_state, xmm_space);\r\nfor (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {\r\nif (!xfeature_enabled(i))\r\ncontinue;\r\ncpuid_count(XSTATE_CPUID, i, &eax, &ebx, &ecx, &edx);\r\nif (xfeature_is_user(i))\r\nxstate_offsets[i] = ebx;\r\nxstate_sizes[i] = eax;\r\nWARN_ONCE(last_good_offset > xstate_offsets[i],\r\n"x86/fpu: misordered xstate at %d\n", last_good_offset);\r\nlast_good_offset = xstate_offsets[i];\r\n}\r\n}\r\nstatic void __init print_xstate_feature(u64 xstate_mask)\r\n{\r\nconst char *feature_name;\r\nif (cpu_has_xfeatures(xstate_mask, &feature_name))\r\npr_info("x86/fpu: Supporting XSAVE feature 0x%03Lx: '%s'\n", xstate_mask, feature_name);\r\n}\r\nstatic void __init print_xstate_features(void)\r\n{\r\nprint_xstate_feature(XFEATURE_MASK_FP);\r\nprint_xstate_feature(XFEATURE_MASK_SSE);\r\nprint_xstate_feature(XFEATURE_MASK_YMM);\r\nprint_xstate_feature(XFEATURE_MASK_BNDREGS);\r\nprint_xstate_feature(XFEATURE_MASK_BNDCSR);\r\nprint_xstate_feature(XFEATURE_MASK_OPMASK);\r\nprint_xstate_feature(XFEATURE_MASK_ZMM_Hi256);\r\nprint_xstate_feature(XFEATURE_MASK_Hi16_ZMM);\r\nprint_xstate_feature(XFEATURE_MASK_PKRU);\r\n}\r\nstatic int xfeature_is_aligned(int xfeature_nr)\r\n{\r\nu32 eax, ebx, ecx, edx;\r\nCHECK_XFEATURE(xfeature_nr);\r\ncpuid_count(XSTATE_CPUID, xfeature_nr, &eax, &ebx, &ecx, &edx);\r\nreturn !!(ecx & 2);\r\n}\r\nstatic void __init setup_xstate_comp(void)\r\n{\r\nunsigned int xstate_comp_sizes[sizeof(xfeatures_mask)*8];\r\nint i;\r\nxstate_comp_offsets[0] = 0;\r\nxstate_comp_offsets[1] = offsetof(struct fxregs_state, xmm_space);\r\nif (!boot_cpu_has(X86_FEATURE_XSAVES)) {\r\nfor (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {\r\nif (xfeature_enabled(i)) {\r\nxstate_comp_offsets[i] = xstate_offsets[i];\r\nxstate_comp_sizes[i] = xstate_sizes[i];\r\n}\r\n}\r\nreturn;\r\n}\r\nxstate_comp_offsets[FIRST_EXTENDED_XFEATURE] =\r\nFXSAVE_SIZE + XSAVE_HDR_SIZE;\r\nfor (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {\r\nif (xfeature_enabled(i))\r\nxstate_comp_sizes[i] = xstate_sizes[i];\r\nelse\r\nxstate_comp_sizes[i] = 0;\r\nif (i > FIRST_EXTENDED_XFEATURE) {\r\nxstate_comp_offsets[i] = xstate_comp_offsets[i-1]\r\n+ xstate_comp_sizes[i-1];\r\nif (xfeature_is_aligned(i))\r\nxstate_comp_offsets[i] =\r\nALIGN(xstate_comp_offsets[i], 64);\r\n}\r\n}\r\n}\r\nstatic void __init print_xstate_offset_size(void)\r\n{\r\nint i;\r\nfor (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {\r\nif (!xfeature_enabled(i))\r\ncontinue;\r\npr_info("x86/fpu: xstate_offset[%d]: %4d, xstate_sizes[%d]: %4d\n",\r\ni, xstate_comp_offsets[i], i, xstate_sizes[i]);\r\n}\r\n}\r\nstatic void __init setup_init_fpu_buf(void)\r\n{\r\nstatic int on_boot_cpu __initdata = 1;\r\nWARN_ON_FPU(!on_boot_cpu);\r\non_boot_cpu = 0;\r\nif (!boot_cpu_has(X86_FEATURE_XSAVE))\r\nreturn;\r\nsetup_xstate_features();\r\nprint_xstate_features();\r\nif (boot_cpu_has(X86_FEATURE_XSAVES))\r\ninit_fpstate.xsave.header.xcomp_bv = (u64)1 << 63 | xfeatures_mask;\r\ncopy_kernel_to_xregs_booting(&init_fpstate.xsave);\r\ncopy_xregs_to_kernel_booting(&init_fpstate.xsave);\r\n}\r\nstatic int xfeature_uncompacted_offset(int xfeature_nr)\r\n{\r\nu32 eax, ebx, ecx, edx;\r\nif (XFEATURE_MASK_SUPERVISOR & (1 << xfeature_nr)) {\r\nWARN_ONCE(1, "No fixed offset for xstate %d\n", xfeature_nr);\r\nreturn -1;\r\n}\r\nCHECK_XFEATURE(xfeature_nr);\r\ncpuid_count(XSTATE_CPUID, xfeature_nr, &eax, &ebx, &ecx, &edx);\r\nreturn ebx;\r\n}\r\nstatic int xfeature_size(int xfeature_nr)\r\n{\r\nu32 eax, ebx, ecx, edx;\r\nCHECK_XFEATURE(xfeature_nr);\r\ncpuid_count(XSTATE_CPUID, xfeature_nr, &eax, &ebx, &ecx, &edx);\r\nreturn eax;\r\n}\r\nint using_compacted_format(void)\r\n{\r\nreturn boot_cpu_has(X86_FEATURE_XSAVES);\r\n}\r\nstatic void __xstate_dump_leaves(void)\r\n{\r\nint i;\r\nu32 eax, ebx, ecx, edx;\r\nstatic int should_dump = 1;\r\nif (!should_dump)\r\nreturn;\r\nshould_dump = 0;\r\nfor (i = 0; i < XFEATURE_MAX + 10; i++) {\r\ncpuid_count(XSTATE_CPUID, i, &eax, &ebx, &ecx, &edx);\r\npr_warn("CPUID[%02x, %02x]: eax=%08x ebx=%08x ecx=%08x edx=%08x\n",\r\nXSTATE_CPUID, i, eax, ebx, ecx, edx);\r\n}\r\n}\r\nstatic void check_xstate_against_struct(int nr)\r\n{\r\nint sz = xfeature_size(nr);\r\nXCHECK_SZ(sz, nr, XFEATURE_YMM, struct ymmh_struct);\r\nXCHECK_SZ(sz, nr, XFEATURE_BNDREGS, struct mpx_bndreg_state);\r\nXCHECK_SZ(sz, nr, XFEATURE_BNDCSR, struct mpx_bndcsr_state);\r\nXCHECK_SZ(sz, nr, XFEATURE_OPMASK, struct avx_512_opmask_state);\r\nXCHECK_SZ(sz, nr, XFEATURE_ZMM_Hi256, struct avx_512_zmm_uppers_state);\r\nXCHECK_SZ(sz, nr, XFEATURE_Hi16_ZMM, struct avx_512_hi16_state);\r\nXCHECK_SZ(sz, nr, XFEATURE_PKRU, struct pkru_state);\r\nif ((nr < XFEATURE_YMM) ||\r\n(nr >= XFEATURE_MAX) ||\r\n(nr == XFEATURE_PT_UNIMPLEMENTED_SO_FAR)) {\r\nWARN_ONCE(1, "no structure for xstate: %d\n", nr);\r\nXSTATE_WARN_ON(1);\r\n}\r\n}\r\nstatic void do_extra_xstate_size_checks(void)\r\n{\r\nint paranoid_xstate_size = FXSAVE_SIZE + XSAVE_HDR_SIZE;\r\nint i;\r\nfor (i = FIRST_EXTENDED_XFEATURE; i < XFEATURE_MAX; i++) {\r\nif (!xfeature_enabled(i))\r\ncontinue;\r\ncheck_xstate_against_struct(i);\r\nif (!using_compacted_format())\r\nXSTATE_WARN_ON(xfeature_is_supervisor(i));\r\nif (xfeature_is_aligned(i))\r\nparanoid_xstate_size = ALIGN(paranoid_xstate_size, 64);\r\nif (!using_compacted_format())\r\nparanoid_xstate_size = xfeature_uncompacted_offset(i);\r\nparanoid_xstate_size += xfeature_size(i);\r\n}\r\nXSTATE_WARN_ON(paranoid_xstate_size != fpu_kernel_xstate_size);\r\n}\r\nstatic unsigned int __init get_xsaves_size(void)\r\n{\r\nunsigned int eax, ebx, ecx, edx;\r\ncpuid_count(XSTATE_CPUID, 1, &eax, &ebx, &ecx, &edx);\r\nreturn ebx;\r\n}\r\nstatic unsigned int __init get_xsave_size(void)\r\n{\r\nunsigned int eax, ebx, ecx, edx;\r\ncpuid_count(XSTATE_CPUID, 0, &eax, &ebx, &ecx, &edx);\r\nreturn ebx;\r\n}\r\nstatic bool is_supported_xstate_size(unsigned int test_xstate_size)\r\n{\r\nif (test_xstate_size <= sizeof(union fpregs_state))\r\nreturn true;\r\npr_warn("x86/fpu: xstate buffer too small (%zu < %d), disabling xsave\n",\r\nsizeof(union fpregs_state), test_xstate_size);\r\nreturn false;\r\n}\r\nstatic int init_xstate_size(void)\r\n{\r\nunsigned int possible_xstate_size;\r\nunsigned int xsave_size;\r\nxsave_size = get_xsave_size();\r\nif (boot_cpu_has(X86_FEATURE_XSAVES))\r\npossible_xstate_size = get_xsaves_size();\r\nelse\r\npossible_xstate_size = xsave_size;\r\nif (!is_supported_xstate_size(possible_xstate_size))\r\nreturn -EINVAL;\r\nfpu_kernel_xstate_size = possible_xstate_size;\r\ndo_extra_xstate_size_checks();\r\nfpu_user_xstate_size = xsave_size;\r\nreturn 0;\r\n}\r\nstatic void fpu__init_disable_system_xstate(void)\r\n{\r\nxfeatures_mask = 0;\r\ncr4_clear_bits(X86_CR4_OSXSAVE);\r\nfpu__xstate_clear_all_cpu_caps();\r\n}\r\nvoid __init fpu__init_system_xstate(void)\r\n{\r\nunsigned int eax, ebx, ecx, edx;\r\nstatic int on_boot_cpu __initdata = 1;\r\nint err;\r\nWARN_ON_FPU(!on_boot_cpu);\r\non_boot_cpu = 0;\r\nif (!boot_cpu_has(X86_FEATURE_FPU)) {\r\npr_info("x86/fpu: No FPU detected\n");\r\nreturn;\r\n}\r\nif (!boot_cpu_has(X86_FEATURE_XSAVE)) {\r\npr_info("x86/fpu: x87 FPU will use %s\n",\r\nboot_cpu_has(X86_FEATURE_FXSR) ? "FXSAVE" : "FSAVE");\r\nreturn;\r\n}\r\nif (boot_cpu_data.cpuid_level < XSTATE_CPUID) {\r\nWARN_ON_FPU(1);\r\nreturn;\r\n}\r\ncpuid_count(XSTATE_CPUID, 0, &eax, &ebx, &ecx, &edx);\r\nxfeatures_mask = eax + ((u64)edx << 32);\r\nif ((xfeatures_mask & XFEATURE_MASK_FPSSE) != XFEATURE_MASK_FPSSE) {\r\npr_err("x86/fpu: FP/SSE not present amongst the CPU's xstate features: 0x%llx.\n", xfeatures_mask);\r\ngoto out_disable;\r\n}\r\nxfeatures_mask &= fpu__get_supported_xfeatures_mask();\r\nfpu__init_cpu_xstate();\r\nerr = init_xstate_size();\r\nif (err)\r\ngoto out_disable;\r\nupdate_regset_xstate_info(fpu_user_xstate_size, xfeatures_mask & ~XFEATURE_MASK_SUPERVISOR);\r\nfpu__init_prepare_fx_sw_frame();\r\nsetup_init_fpu_buf();\r\nsetup_xstate_comp();\r\nprint_xstate_offset_size();\r\npr_info("x86/fpu: Enabled xstate features 0x%llx, context size is %d bytes, using '%s' format.\n",\r\nxfeatures_mask,\r\nfpu_kernel_xstate_size,\r\nboot_cpu_has(X86_FEATURE_XSAVES) ? "compacted" : "standard");\r\nreturn;\r\nout_disable:\r\nfpu__init_disable_system_xstate();\r\n}\r\nvoid fpu__resume_cpu(void)\r\n{\r\nif (boot_cpu_has(X86_FEATURE_XSAVE))\r\nxsetbv(XCR_XFEATURE_ENABLED_MASK, xfeatures_mask);\r\n}\r\nvoid *__raw_xsave_addr(struct xregs_state *xsave, int xstate_feature_mask)\r\n{\r\nint feature_nr = fls64(xstate_feature_mask) - 1;\r\nif (!xfeature_enabled(feature_nr)) {\r\nWARN_ON_FPU(1);\r\nreturn NULL;\r\n}\r\nreturn (void *)xsave + xstate_comp_offsets[feature_nr];\r\n}\r\nvoid *get_xsave_addr(struct xregs_state *xsave, int xstate_feature)\r\n{\r\nif (!boot_cpu_has(X86_FEATURE_XSAVE))\r\nreturn NULL;\r\nWARN_ONCE(!(xfeatures_mask & xstate_feature),\r\n"get of unsupported state");\r\nif (!(xsave->header.xfeatures & xstate_feature))\r\nreturn NULL;\r\nreturn __raw_xsave_addr(xsave, xstate_feature);\r\n}\r\nconst void *get_xsave_field_ptr(int xsave_state)\r\n{\r\nstruct fpu *fpu = &current->thread.fpu;\r\nif (!fpu->fpstate_active)\r\nreturn NULL;\r\nfpu__save(fpu);\r\nreturn get_xsave_addr(&fpu->state.xsave, xsave_state);\r\n}\r\nint arch_set_user_pkey_access(struct task_struct *tsk, int pkey,\r\nunsigned long init_val)\r\n{\r\nu32 old_pkru;\r\nint pkey_shift = (pkey * PKRU_BITS_PER_PKEY);\r\nu32 new_pkru_bits = 0;\r\nif (!boot_cpu_has(X86_FEATURE_OSPKE))\r\nreturn -EINVAL;\r\nif (init_val & PKEY_DISABLE_ACCESS)\r\nnew_pkru_bits |= PKRU_AD_BIT;\r\nif (init_val & PKEY_DISABLE_WRITE)\r\nnew_pkru_bits |= PKRU_WD_BIT;\r\nnew_pkru_bits <<= pkey_shift;\r\nold_pkru = read_pkru();\r\nold_pkru &= ~((PKRU_AD_BIT|PKRU_WD_BIT) << pkey_shift);\r\nwrite_pkru(old_pkru | new_pkru_bits);\r\nreturn 0;\r\n}\r\nstatic inline int xstate_copyout(unsigned int pos, unsigned int count,\r\nvoid *kbuf, void __user *ubuf,\r\nconst void *data, const int start_pos,\r\nconst int end_pos)\r\n{\r\nif ((count == 0) || (pos < start_pos))\r\nreturn 0;\r\nif (end_pos < 0 || pos < end_pos) {\r\nunsigned int copy = (end_pos < 0 ? count : min(count, end_pos - pos));\r\nif (kbuf) {\r\nmemcpy(kbuf + pos, data, copy);\r\n} else {\r\nif (__copy_to_user(ubuf + pos, data, copy))\r\nreturn -EFAULT;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint copyout_from_xsaves(unsigned int pos, unsigned int count, void *kbuf,\r\nvoid __user *ubuf, struct xregs_state *xsave)\r\n{\r\nunsigned int offset, size;\r\nint ret, i;\r\nstruct xstate_header header;\r\nif (unlikely(pos != 0))\r\nreturn -EFAULT;\r\nmemset(&header, 0, sizeof(header));\r\nheader.xfeatures = xsave->header.xfeatures;\r\nheader.xfeatures &= ~XFEATURE_MASK_SUPERVISOR;\r\noffset = offsetof(struct xregs_state, header);\r\nsize = sizeof(header);\r\nret = xstate_copyout(offset, size, kbuf, ubuf, &header, 0, count);\r\nif (ret)\r\nreturn ret;\r\nfor (i = 0; i < XFEATURE_MAX; i++) {\r\nif ((header.xfeatures >> i) & 1) {\r\nvoid *src = __raw_xsave_addr(xsave, 1 << i);\r\noffset = xstate_offsets[i];\r\nsize = xstate_sizes[i];\r\nret = xstate_copyout(offset, size, kbuf, ubuf, src, 0, count);\r\nif (ret)\r\nreturn ret;\r\nif (offset + size >= count)\r\nbreak;\r\n}\r\n}\r\noffset = offsetof(struct fxregs_state, sw_reserved);\r\nsize = sizeof(xstate_fx_sw_bytes);\r\nret = xstate_copyout(offset, size, kbuf, ubuf, xstate_fx_sw_bytes, 0, count);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nint copyin_to_xsaves(const void *kbuf, const void __user *ubuf,\r\nstruct xregs_state *xsave)\r\n{\r\nunsigned int offset, size;\r\nint i;\r\nu64 xfeatures;\r\nu64 allowed_features;\r\noffset = offsetof(struct xregs_state, header);\r\nsize = sizeof(xfeatures);\r\nif (kbuf) {\r\nmemcpy(&xfeatures, kbuf + offset, size);\r\n} else {\r\nif (__copy_from_user(&xfeatures, ubuf + offset, size))\r\nreturn -EFAULT;\r\n}\r\nallowed_features = xfeatures_mask & ~XFEATURE_MASK_SUPERVISOR;\r\nif (xfeatures & ~allowed_features)\r\nreturn -EINVAL;\r\nfor (i = 0; i < XFEATURE_MAX; i++) {\r\nu64 mask = ((u64)1 << i);\r\nif (xfeatures & mask) {\r\nvoid *dst = __raw_xsave_addr(xsave, 1 << i);\r\noffset = xstate_offsets[i];\r\nsize = xstate_sizes[i];\r\nif (kbuf) {\r\nmemcpy(dst, kbuf + offset, size);\r\n} else {\r\nif (__copy_from_user(dst, ubuf + offset, size))\r\nreturn -EFAULT;\r\n}\r\n}\r\n}\r\nxsave->header.xfeatures &= XFEATURE_MASK_SUPERVISOR;\r\nxsave->header.xfeatures |= xfeatures;\r\nreturn 0;\r\n}
