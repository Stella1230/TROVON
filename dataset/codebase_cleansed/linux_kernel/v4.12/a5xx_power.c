static inline uint32_t _get_mvolts(struct msm_gpu *gpu, uint32_t freq)\r\n{\r\nstruct drm_device *dev = gpu->dev;\r\nstruct msm_drm_private *priv = dev->dev_private;\r\nstruct platform_device *pdev = priv->gpu_pdev;\r\nstruct dev_pm_opp *opp;\r\nopp = dev_pm_opp_find_freq_exact(&pdev->dev, freq, true);\r\nreturn (!IS_ERR(opp)) ? dev_pm_opp_get_voltage(opp) / 1000 : 0;\r\n}\r\nstatic void a5xx_lm_setup(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(a5xx_sequence_regs); i++)\r\ngpu_write(gpu, a5xx_sequence_regs[i].reg,\r\na5xx_sequence_regs[i].value);\r\ngpu_write(gpu, REG_A5XX_GPMU_TEMP_SENSOR_ID, 0x60007);\r\ngpu_write(gpu, REG_A5XX_GPMU_DELTA_TEMP_THRESHOLD, 0x01);\r\ngpu_write(gpu, REG_A5XX_GPMU_TEMP_SENSOR_CONFIG, 0x01);\r\ngpu_write(gpu, REG_A5XX_GPMU_GPMU_VOLTAGE, 0x80000000 | 0);\r\ngpu_write(gpu, REG_A5XX_GPMU_BASE_LEAKAGE, a5xx_gpu->lm_leakage);\r\ngpu_write(gpu, REG_A5XX_GPMU_GPMU_PWR_THRESHOLD, 0x80000000 | 6000);\r\ngpu_write(gpu, REG_A5XX_GPMU_BEC_ENABLE, 0x10001FFF);\r\ngpu_write(gpu, REG_A5XX_GDPM_CONFIG1, 0x00201FF1);\r\ngpu_write(gpu, REG_A5XX_GPMU_BEC_ENABLE, 0x10001FFF);\r\ngpu_write(gpu, REG_A5XX_GDPM_CONFIG1, 0x201FF1);\r\ngpu_write(gpu, AGC_MSG_STATE, 1);\r\ngpu_write(gpu, AGC_MSG_COMMAND, AGC_POWER_CONFIG_PRODUCTION_ID);\r\ngpu_write(gpu, AGC_MSG_PAYLOAD(0), 5448);\r\ngpu_write(gpu, AGC_MSG_PAYLOAD(1), 1);\r\ngpu_write(gpu, AGC_MSG_PAYLOAD(2), _get_mvolts(gpu, gpu->fast_rate));\r\ngpu_write(gpu, AGC_MSG_PAYLOAD(3), gpu->fast_rate / 1000000);\r\ngpu_write(gpu, AGC_MSG_PAYLOAD_SIZE, 4 * sizeof(uint32_t));\r\ngpu_write(gpu, AGC_INIT_MSG_MAGIC, AGC_INIT_MSG_VALUE);\r\n}\r\nstatic void a5xx_pc_init(struct msm_gpu *gpu)\r\n{\r\ngpu_write(gpu, REG_A5XX_GPMU_PWR_COL_INTER_FRAME_CTRL, 0x7F);\r\ngpu_write(gpu, REG_A5XX_GPMU_PWR_COL_BINNING_CTRL, 0);\r\ngpu_write(gpu, REG_A5XX_GPMU_PWR_COL_INTER_FRAME_HYST, 0xA0080);\r\ngpu_write(gpu, REG_A5XX_GPMU_PWR_COL_STAGGER_DELAY, 0x600040);\r\n}\r\nstatic int a5xx_gpmu_init(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\r\nstruct msm_ringbuffer *ring = gpu->rb;\r\nif (!a5xx_gpu->gpmu_dwords)\r\nreturn 0;\r\nOUT_PKT7(ring, CP_SET_PROTECTED_MODE, 1);\r\nOUT_RING(ring, 0);\r\nOUT_PKT7(ring, CP_INDIRECT_BUFFER_PFE, 3);\r\nOUT_RING(ring, lower_32_bits(a5xx_gpu->gpmu_iova));\r\nOUT_RING(ring, upper_32_bits(a5xx_gpu->gpmu_iova));\r\nOUT_RING(ring, a5xx_gpu->gpmu_dwords);\r\nOUT_PKT7(ring, CP_SET_PROTECTED_MODE, 1);\r\nOUT_RING(ring, 1);\r\ngpu->funcs->flush(gpu);\r\nif (!gpu->funcs->idle(gpu)) {\r\nDRM_ERROR("%s: Unable to load GPMU firmware. GPMU will not be active\n",\r\ngpu->name);\r\nreturn -EINVAL;\r\n}\r\ngpu_write(gpu, REG_A5XX_GPMU_WFI_CONFIG, 0x4014);\r\ngpu_write(gpu, REG_A5XX_GPMU_CM3_SYSRESET, 0x0);\r\nif (spin_usecs(gpu, 25, REG_A5XX_GPMU_GENERAL_0, 0xFFFFFFFF,\r\n0xBABEFACE))\r\nDRM_ERROR("%s: GPMU firmware initialization timed out\n",\r\ngpu->name);\r\nreturn 0;\r\n}\r\nstatic void a5xx_lm_enable(struct msm_gpu *gpu)\r\n{\r\ngpu_write(gpu, REG_A5XX_GDPM_INT_MASK, 0x0);\r\ngpu_write(gpu, REG_A5XX_GDPM_INT_EN, 0x0A);\r\ngpu_write(gpu, REG_A5XX_GPMU_GPMU_VOLTAGE_INTR_EN_MASK, 0x01);\r\ngpu_write(gpu, REG_A5XX_GPMU_TEMP_THRESHOLD_INTR_EN_MASK, 0x50000);\r\ngpu_write(gpu, REG_A5XX_GPMU_THROTTLE_UNMASK_FORCE_CTRL, 0x30000);\r\ngpu_write(gpu, REG_A5XX_GPMU_CLOCK_THROTTLE_CTRL, 0x011);\r\n}\r\nint a5xx_power_init(struct msm_gpu *gpu)\r\n{\r\nint ret;\r\na5xx_lm_setup(gpu);\r\na5xx_pc_init(gpu);\r\nret = a5xx_gpmu_init(gpu);\r\nif (ret)\r\nreturn ret;\r\na5xx_lm_enable(gpu);\r\nreturn 0;\r\n}\r\nvoid a5xx_gpmu_ucode_init(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\r\nstruct drm_device *drm = gpu->dev;\r\nconst struct firmware *fw;\r\nuint32_t dwords = 0, offset = 0, bosize;\r\nunsigned int *data, *ptr, *cmds;\r\nunsigned int cmds_size;\r\nif (a5xx_gpu->gpmu_bo)\r\nreturn;\r\nif (request_firmware(&fw, adreno_gpu->info->gpmufw, drm->dev)) {\r\nDRM_ERROR("%s: Could not get GPMU firmware. GPMU will not be active\n",\r\ngpu->name);\r\nreturn;\r\n}\r\ndata = (unsigned int *) fw->data;\r\nif (fw->size < 8 || (data[0] < 2) || (data[0] >= (fw->size >> 2)))\r\ngoto out;\r\nif (data[1] != 2)\r\ngoto out;\r\ncmds = data + data[2] + 3;\r\ncmds_size = data[0] - data[2] - 2;\r\nbosize = (cmds_size + (cmds_size / TYPE4_MAX_PAYLOAD) + 1) << 2;\r\nmutex_lock(&drm->struct_mutex);\r\na5xx_gpu->gpmu_bo = msm_gem_new(drm, bosize, MSM_BO_UNCACHED);\r\nmutex_unlock(&drm->struct_mutex);\r\nif (IS_ERR(a5xx_gpu->gpmu_bo))\r\ngoto err;\r\nif (msm_gem_get_iova(a5xx_gpu->gpmu_bo, gpu->id, &a5xx_gpu->gpmu_iova))\r\ngoto err;\r\nptr = msm_gem_get_vaddr(a5xx_gpu->gpmu_bo);\r\nif (!ptr)\r\ngoto err;\r\nwhile (cmds_size > 0) {\r\nint i;\r\nuint32_t _size = cmds_size > TYPE4_MAX_PAYLOAD ?\r\nTYPE4_MAX_PAYLOAD : cmds_size;\r\nptr[dwords++] = PKT4(REG_A5XX_GPMU_INST_RAM_BASE + offset,\r\n_size);\r\nfor (i = 0; i < _size; i++)\r\nptr[dwords++] = *cmds++;\r\noffset += _size;\r\ncmds_size -= _size;\r\n}\r\nmsm_gem_put_vaddr(a5xx_gpu->gpmu_bo);\r\na5xx_gpu->gpmu_dwords = dwords;\r\ngoto out;\r\nerr:\r\nif (a5xx_gpu->gpmu_iova)\r\nmsm_gem_put_iova(a5xx_gpu->gpmu_bo, gpu->id);\r\nif (a5xx_gpu->gpmu_bo)\r\ndrm_gem_object_unreference_unlocked(a5xx_gpu->gpmu_bo);\r\na5xx_gpu->gpmu_bo = NULL;\r\na5xx_gpu->gpmu_iova = 0;\r\na5xx_gpu->gpmu_dwords = 0;\r\nout:\r\nrelease_firmware(fw);\r\n}
