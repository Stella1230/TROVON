u64 __siphash_aligned(const void *data, size_t len, const siphash_key_t *key)\r\n{\r\nconst u8 *end = data + len - (len % sizeof(u64));\r\nconst u8 left = len & (sizeof(u64) - 1);\r\nu64 m;\r\nPREAMBLE(len)\r\nfor (; data != end; data += sizeof(u64)) {\r\nm = le64_to_cpup(data);\r\nv3 ^= m;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= m;\r\n}\r\n#if defined(CONFIG_DCACHE_WORD_ACCESS) && BITS_PER_LONG == 64\r\nif (left)\r\nb |= le64_to_cpu((__force __le64)(load_unaligned_zeropad(data) &\r\nbytemask_from_count(left)));\r\n#else\r\nswitch (left) {\r\ncase 7: b |= ((u64)end[6]) << 48;\r\ncase 6: b |= ((u64)end[5]) << 40;\r\ncase 5: b |= ((u64)end[4]) << 32;\r\ncase 4: b |= le32_to_cpup(data); break;\r\ncase 3: b |= ((u64)end[2]) << 16;\r\ncase 2: b |= le16_to_cpup(data); break;\r\ncase 1: b |= end[0];\r\n}\r\n#endif\r\nPOSTAMBLE\r\n}\r\nu64 __siphash_unaligned(const void *data, size_t len, const siphash_key_t *key)\r\n{\r\nconst u8 *end = data + len - (len % sizeof(u64));\r\nconst u8 left = len & (sizeof(u64) - 1);\r\nu64 m;\r\nPREAMBLE(len)\r\nfor (; data != end; data += sizeof(u64)) {\r\nm = get_unaligned_le64(data);\r\nv3 ^= m;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= m;\r\n}\r\n#if defined(CONFIG_DCACHE_WORD_ACCESS) && BITS_PER_LONG == 64\r\nif (left)\r\nb |= le64_to_cpu((__force __le64)(load_unaligned_zeropad(data) &\r\nbytemask_from_count(left)));\r\n#else\r\nswitch (left) {\r\ncase 7: b |= ((u64)end[6]) << 48;\r\ncase 6: b |= ((u64)end[5]) << 40;\r\ncase 5: b |= ((u64)end[4]) << 32;\r\ncase 4: b |= get_unaligned_le32(end); break;\r\ncase 3: b |= ((u64)end[2]) << 16;\r\ncase 2: b |= get_unaligned_le16(end); break;\r\ncase 1: b |= end[0];\r\n}\r\n#endif\r\nPOSTAMBLE\r\n}\r\nu64 siphash_1u64(const u64 first, const siphash_key_t *key)\r\n{\r\nPREAMBLE(8)\r\nv3 ^= first;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= first;\r\nPOSTAMBLE\r\n}\r\nu64 siphash_2u64(const u64 first, const u64 second, const siphash_key_t *key)\r\n{\r\nPREAMBLE(16)\r\nv3 ^= first;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= first;\r\nv3 ^= second;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= second;\r\nPOSTAMBLE\r\n}\r\nu64 siphash_3u64(const u64 first, const u64 second, const u64 third,\r\nconst siphash_key_t *key)\r\n{\r\nPREAMBLE(24)\r\nv3 ^= first;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= first;\r\nv3 ^= second;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= second;\r\nv3 ^= third;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= third;\r\nPOSTAMBLE\r\n}\r\nu64 siphash_4u64(const u64 first, const u64 second, const u64 third,\r\nconst u64 forth, const siphash_key_t *key)\r\n{\r\nPREAMBLE(32)\r\nv3 ^= first;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= first;\r\nv3 ^= second;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= second;\r\nv3 ^= third;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= third;\r\nv3 ^= forth;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= forth;\r\nPOSTAMBLE\r\n}\r\nu64 siphash_1u32(const u32 first, const siphash_key_t *key)\r\n{\r\nPREAMBLE(4)\r\nb |= first;\r\nPOSTAMBLE\r\n}\r\nu64 siphash_3u32(const u32 first, const u32 second, const u32 third,\r\nconst siphash_key_t *key)\r\n{\r\nu64 combined = (u64)second << 32 | first;\r\nPREAMBLE(12)\r\nv3 ^= combined;\r\nSIPROUND;\r\nSIPROUND;\r\nv0 ^= combined;\r\nb |= third;\r\nPOSTAMBLE\r\n}\r\nu32 __hsiphash_aligned(const void *data, size_t len, const hsiphash_key_t *key)\r\n{\r\nconst u8 *end = data + len - (len % sizeof(u64));\r\nconst u8 left = len & (sizeof(u64) - 1);\r\nu64 m;\r\nHPREAMBLE(len)\r\nfor (; data != end; data += sizeof(u64)) {\r\nm = le64_to_cpup(data);\r\nv3 ^= m;\r\nHSIPROUND;\r\nv0 ^= m;\r\n}\r\n#if defined(CONFIG_DCACHE_WORD_ACCESS) && BITS_PER_LONG == 64\r\nif (left)\r\nb |= le64_to_cpu((__force __le64)(load_unaligned_zeropad(data) &\r\nbytemask_from_count(left)));\r\n#else\r\nswitch (left) {\r\ncase 7: b |= ((u64)end[6]) << 48;\r\ncase 6: b |= ((u64)end[5]) << 40;\r\ncase 5: b |= ((u64)end[4]) << 32;\r\ncase 4: b |= le32_to_cpup(data); break;\r\ncase 3: b |= ((u64)end[2]) << 16;\r\ncase 2: b |= le16_to_cpup(data); break;\r\ncase 1: b |= end[0];\r\n}\r\n#endif\r\nHPOSTAMBLE\r\n}\r\nu32 __hsiphash_unaligned(const void *data, size_t len,\r\nconst hsiphash_key_t *key)\r\n{\r\nconst u8 *end = data + len - (len % sizeof(u64));\r\nconst u8 left = len & (sizeof(u64) - 1);\r\nu64 m;\r\nHPREAMBLE(len)\r\nfor (; data != end; data += sizeof(u64)) {\r\nm = get_unaligned_le64(data);\r\nv3 ^= m;\r\nHSIPROUND;\r\nv0 ^= m;\r\n}\r\n#if defined(CONFIG_DCACHE_WORD_ACCESS) && BITS_PER_LONG == 64\r\nif (left)\r\nb |= le64_to_cpu((__force __le64)(load_unaligned_zeropad(data) &\r\nbytemask_from_count(left)));\r\n#else\r\nswitch (left) {\r\ncase 7: b |= ((u64)end[6]) << 48;\r\ncase 6: b |= ((u64)end[5]) << 40;\r\ncase 5: b |= ((u64)end[4]) << 32;\r\ncase 4: b |= get_unaligned_le32(end); break;\r\ncase 3: b |= ((u64)end[2]) << 16;\r\ncase 2: b |= get_unaligned_le16(end); break;\r\ncase 1: b |= end[0];\r\n}\r\n#endif\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_1u32(const u32 first, const hsiphash_key_t *key)\r\n{\r\nHPREAMBLE(4)\r\nb |= first;\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_2u32(const u32 first, const u32 second, const hsiphash_key_t *key)\r\n{\r\nu64 combined = (u64)second << 32 | first;\r\nHPREAMBLE(8)\r\nv3 ^= combined;\r\nHSIPROUND;\r\nv0 ^= combined;\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_3u32(const u32 first, const u32 second, const u32 third,\r\nconst hsiphash_key_t *key)\r\n{\r\nu64 combined = (u64)second << 32 | first;\r\nHPREAMBLE(12)\r\nv3 ^= combined;\r\nHSIPROUND;\r\nv0 ^= combined;\r\nb |= third;\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_4u32(const u32 first, const u32 second, const u32 third,\r\nconst u32 forth, const hsiphash_key_t *key)\r\n{\r\nu64 combined = (u64)second << 32 | first;\r\nHPREAMBLE(16)\r\nv3 ^= combined;\r\nHSIPROUND;\r\nv0 ^= combined;\r\ncombined = (u64)forth << 32 | third;\r\nv3 ^= combined;\r\nHSIPROUND;\r\nv0 ^= combined;\r\nHPOSTAMBLE\r\n}\r\nu32 __hsiphash_aligned(const void *data, size_t len, const hsiphash_key_t *key)\r\n{\r\nconst u8 *end = data + len - (len % sizeof(u32));\r\nconst u8 left = len & (sizeof(u32) - 1);\r\nu32 m;\r\nHPREAMBLE(len)\r\nfor (; data != end; data += sizeof(u32)) {\r\nm = le32_to_cpup(data);\r\nv3 ^= m;\r\nHSIPROUND;\r\nv0 ^= m;\r\n}\r\nswitch (left) {\r\ncase 3: b |= ((u32)end[2]) << 16;\r\ncase 2: b |= le16_to_cpup(data); break;\r\ncase 1: b |= end[0];\r\n}\r\nHPOSTAMBLE\r\n}\r\nu32 __hsiphash_unaligned(const void *data, size_t len,\r\nconst hsiphash_key_t *key)\r\n{\r\nconst u8 *end = data + len - (len % sizeof(u32));\r\nconst u8 left = len & (sizeof(u32) - 1);\r\nu32 m;\r\nHPREAMBLE(len)\r\nfor (; data != end; data += sizeof(u32)) {\r\nm = get_unaligned_le32(data);\r\nv3 ^= m;\r\nHSIPROUND;\r\nv0 ^= m;\r\n}\r\nswitch (left) {\r\ncase 3: b |= ((u32)end[2]) << 16;\r\ncase 2: b |= get_unaligned_le16(end); break;\r\ncase 1: b |= end[0];\r\n}\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_1u32(const u32 first, const hsiphash_key_t *key)\r\n{\r\nHPREAMBLE(4)\r\nv3 ^= first;\r\nHSIPROUND;\r\nv0 ^= first;\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_2u32(const u32 first, const u32 second, const hsiphash_key_t *key)\r\n{\r\nHPREAMBLE(8)\r\nv3 ^= first;\r\nHSIPROUND;\r\nv0 ^= first;\r\nv3 ^= second;\r\nHSIPROUND;\r\nv0 ^= second;\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_3u32(const u32 first, const u32 second, const u32 third,\r\nconst hsiphash_key_t *key)\r\n{\r\nHPREAMBLE(12)\r\nv3 ^= first;\r\nHSIPROUND;\r\nv0 ^= first;\r\nv3 ^= second;\r\nHSIPROUND;\r\nv0 ^= second;\r\nv3 ^= third;\r\nHSIPROUND;\r\nv0 ^= third;\r\nHPOSTAMBLE\r\n}\r\nu32 hsiphash_4u32(const u32 first, const u32 second, const u32 third,\r\nconst u32 forth, const hsiphash_key_t *key)\r\n{\r\nHPREAMBLE(16)\r\nv3 ^= first;\r\nHSIPROUND;\r\nv0 ^= first;\r\nv3 ^= second;\r\nHSIPROUND;\r\nv0 ^= second;\r\nv3 ^= third;\r\nHSIPROUND;\r\nv0 ^= third;\r\nv3 ^= forth;\r\nHSIPROUND;\r\nv0 ^= forth;\r\nHPOSTAMBLE\r\n}
