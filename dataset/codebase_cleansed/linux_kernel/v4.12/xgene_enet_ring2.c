static void xgene_enet_ring_init(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 *ring_cfg = ring->state;\r\nu64 addr = ring->dma;\r\nif (xgene_enet_ring_owner(ring->id) == RING_OWNER_CPU) {\r\nring_cfg[0] |= SET_VAL(X2_INTLINE, ring->id & RING_BUFNUM_MASK);\r\nring_cfg[3] |= SET_BIT(X2_DEQINTEN);\r\n}\r\nring_cfg[0] |= SET_VAL(X2_CFGCRID, 2);\r\naddr >>= 8;\r\nring_cfg[2] |= QCOHERENT | SET_VAL(RINGADDRL, addr);\r\naddr >>= 27;\r\nring_cfg[3] |= SET_VAL(RINGSIZE, ring->cfgsize)\r\n| ACCEPTLERR\r\n| SET_VAL(RINGADDRH, addr);\r\nring_cfg[4] |= SET_VAL(X2_SELTHRSH, 1);\r\nring_cfg[5] |= SET_BIT(X2_QBASE_AM) | SET_BIT(X2_MSG_AM);\r\n}\r\nstatic void xgene_enet_ring_set_type(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 *ring_cfg = ring->state;\r\nbool is_bufpool;\r\nu32 val;\r\nis_bufpool = xgene_enet_is_bufpool(ring->id);\r\nval = (is_bufpool) ? RING_BUFPOOL : RING_REGULAR;\r\nring_cfg[4] |= SET_VAL(X2_RINGTYPE, val);\r\nif (is_bufpool)\r\nring_cfg[3] |= SET_VAL(RINGMODE, BUFPOOL_MODE);\r\n}\r\nstatic void xgene_enet_ring_set_recombbuf(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 *ring_cfg = ring->state;\r\nring_cfg[3] |= RECOMBBUF;\r\nring_cfg[4] |= SET_VAL(X2_RECOMTIMEOUT, 0x7);\r\n}\r\nstatic void xgene_enet_ring_wr32(struct xgene_enet_desc_ring *ring,\r\nu32 offset, u32 data)\r\n{\r\nstruct xgene_enet_pdata *pdata = netdev_priv(ring->ndev);\r\niowrite32(data, pdata->ring_csr_addr + offset);\r\n}\r\nstatic void xgene_enet_write_ring_state(struct xgene_enet_desc_ring *ring)\r\n{\r\nstruct xgene_enet_pdata *pdata = netdev_priv(ring->ndev);\r\nint i;\r\nxgene_enet_ring_wr32(ring, CSR_RING_CONFIG, ring->num);\r\nfor (i = 0; i < pdata->ring_ops->num_ring_config; i++) {\r\nxgene_enet_ring_wr32(ring, CSR_RING_WR_BASE + (i * 4),\r\nring->state[i]);\r\n}\r\n}\r\nstatic void xgene_enet_clr_ring_state(struct xgene_enet_desc_ring *ring)\r\n{\r\nmemset(ring->state, 0, sizeof(ring->state));\r\nxgene_enet_write_ring_state(ring);\r\n}\r\nstatic void xgene_enet_set_ring_state(struct xgene_enet_desc_ring *ring)\r\n{\r\nenum xgene_ring_owner owner;\r\nxgene_enet_ring_set_type(ring);\r\nowner = xgene_enet_ring_owner(ring->id);\r\nif (owner == RING_OWNER_ETH0 || owner == RING_OWNER_ETH1)\r\nxgene_enet_ring_set_recombbuf(ring);\r\nxgene_enet_ring_init(ring);\r\nxgene_enet_write_ring_state(ring);\r\n}\r\nstatic void xgene_enet_set_ring_id(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 ring_id_val, ring_id_buf;\r\nbool is_bufpool;\r\nif (xgene_enet_ring_owner(ring->id) == RING_OWNER_CPU)\r\nreturn;\r\nis_bufpool = xgene_enet_is_bufpool(ring->id);\r\nring_id_val = ring->id & GENMASK(9, 0);\r\nring_id_val |= OVERWRITE;\r\nring_id_buf = (ring->num << 9) & GENMASK(18, 9);\r\nring_id_buf |= PREFETCH_BUF_EN;\r\nif (is_bufpool)\r\nring_id_buf |= IS_BUFFER_POOL;\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID, ring_id_val);\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID_BUF, ring_id_buf);\r\n}\r\nstatic void xgene_enet_clr_desc_ring_id(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 ring_id;\r\nring_id = ring->id | OVERWRITE;\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID, ring_id);\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID_BUF, 0);\r\n}\r\nstatic struct xgene_enet_desc_ring *xgene_enet_setup_ring(\r\nstruct xgene_enet_desc_ring *ring)\r\n{\r\nbool is_bufpool;\r\nu32 addr, i;\r\nxgene_enet_clr_ring_state(ring);\r\nxgene_enet_set_ring_state(ring);\r\nxgene_enet_set_ring_id(ring);\r\nring->slots = xgene_enet_get_numslots(ring->id, ring->size);\r\nis_bufpool = xgene_enet_is_bufpool(ring->id);\r\nif (is_bufpool || xgene_enet_ring_owner(ring->id) != RING_OWNER_CPU)\r\nreturn ring;\r\naddr = CSR_VMID0_INTR_MBOX + (4 * (ring->id & RING_BUFNUM_MASK));\r\nxgene_enet_ring_wr32(ring, addr, ring->irq_mbox_dma >> 10);\r\nfor (i = 0; i < ring->slots; i++)\r\nxgene_enet_mark_desc_slot_empty(&ring->raw_desc[i]);\r\nreturn ring;\r\n}\r\nstatic void xgene_enet_clear_ring(struct xgene_enet_desc_ring *ring)\r\n{\r\nxgene_enet_clr_desc_ring_id(ring);\r\nxgene_enet_clr_ring_state(ring);\r\n}\r\nstatic void xgene_enet_wr_cmd(struct xgene_enet_desc_ring *ring, int count)\r\n{\r\nu32 data = 0;\r\nif (xgene_enet_ring_owner(ring->id) == RING_OWNER_CPU) {\r\ndata = SET_VAL(X2_INTLINE, ring->id & RING_BUFNUM_MASK) |\r\nINTR_CLEAR;\r\n}\r\ndata |= (count & GENMASK(16, 0));\r\niowrite32(data, ring->cmd);\r\n}\r\nstatic u32 xgene_enet_ring_len(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 __iomem *cmd_base = ring->cmd_base;\r\nu32 ring_state, num_msgs;\r\nring_state = ioread32(&cmd_base[1]);\r\nnum_msgs = GET_VAL(X2_NUMMSGSINQ, ring_state);\r\nreturn num_msgs;\r\n}\r\nstatic void xgene_enet_setup_coalescing(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 data = 0x77777777;\r\nxgene_enet_ring_wr32(ring, CSR_PBM_COAL, 0x8e);\r\nxgene_enet_ring_wr32(ring, CSR_PBM_CTICK0, data);\r\nxgene_enet_ring_wr32(ring, CSR_PBM_CTICK1, data);\r\nxgene_enet_ring_wr32(ring, CSR_PBM_CTICK2, data);\r\nxgene_enet_ring_wr32(ring, CSR_PBM_CTICK3, data);\r\nxgene_enet_ring_wr32(ring, CSR_THRESHOLD0_SET1, 0x08);\r\nxgene_enet_ring_wr32(ring, CSR_THRESHOLD1_SET1, 0x10);\r\n}
