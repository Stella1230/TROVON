static struct mlx5_ib_gsi_qp *gsi_qp(struct ib_qp *qp)\r\n{\r\nreturn container_of(qp, struct mlx5_ib_gsi_qp, ibqp);\r\n}\r\nstatic bool mlx5_ib_deth_sqpn_cap(struct mlx5_ib_dev *dev)\r\n{\r\nreturn MLX5_CAP_GEN(dev->mdev, set_deth_sqpn);\r\n}\r\nstatic void generate_completions(struct mlx5_ib_gsi_qp *gsi)\r\n{\r\nstruct ib_cq *gsi_cq = gsi->ibqp.send_cq;\r\nstruct mlx5_ib_gsi_wr *wr;\r\nu32 index;\r\nfor (index = gsi->outstanding_ci; index != gsi->outstanding_pi;\r\nindex++) {\r\nwr = &gsi->outstanding_wrs[index % gsi->cap.max_send_wr];\r\nif (!wr->completed)\r\nbreak;\r\nif (gsi->sq_sig_type == IB_SIGNAL_ALL_WR ||\r\nwr->send_flags & IB_SEND_SIGNALED)\r\nWARN_ON_ONCE(mlx5_ib_generate_wc(gsi_cq, &wr->wc));\r\nwr->completed = false;\r\n}\r\ngsi->outstanding_ci = index;\r\n}\r\nstatic void handle_single_completion(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\nstruct mlx5_ib_gsi_qp *gsi = cq->cq_context;\r\nstruct mlx5_ib_gsi_wr *wr =\r\ncontainer_of(wc->wr_cqe, struct mlx5_ib_gsi_wr, cqe);\r\nu64 wr_id;\r\nunsigned long flags;\r\nspin_lock_irqsave(&gsi->lock, flags);\r\nwr->completed = true;\r\nwr_id = wr->wc.wr_id;\r\nwr->wc = *wc;\r\nwr->wc.wr_id = wr_id;\r\nwr->wc.qp = &gsi->ibqp;\r\ngenerate_completions(gsi);\r\nspin_unlock_irqrestore(&gsi->lock, flags);\r\n}\r\nstruct ib_qp *mlx5_ib_gsi_create_qp(struct ib_pd *pd,\r\nstruct ib_qp_init_attr *init_attr)\r\n{\r\nstruct mlx5_ib_dev *dev = to_mdev(pd->device);\r\nstruct mlx5_ib_gsi_qp *gsi;\r\nstruct ib_qp_init_attr hw_init_attr = *init_attr;\r\nconst u8 port_num = init_attr->port_num;\r\nconst int num_pkeys = pd->device->attrs.max_pkeys;\r\nconst int num_qps = mlx5_ib_deth_sqpn_cap(dev) ? num_pkeys : 0;\r\nint ret;\r\nmlx5_ib_dbg(dev, "creating GSI QP\n");\r\nif (port_num > ARRAY_SIZE(dev->devr.ports) || port_num < 1) {\r\nmlx5_ib_warn(dev,\r\n"invalid port number %d during GSI QP creation\n",\r\nport_num);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\ngsi = kzalloc(sizeof(*gsi), GFP_KERNEL);\r\nif (!gsi)\r\nreturn ERR_PTR(-ENOMEM);\r\ngsi->tx_qps = kcalloc(num_qps, sizeof(*gsi->tx_qps), GFP_KERNEL);\r\nif (!gsi->tx_qps) {\r\nret = -ENOMEM;\r\ngoto err_free;\r\n}\r\ngsi->outstanding_wrs = kcalloc(init_attr->cap.max_send_wr,\r\nsizeof(*gsi->outstanding_wrs),\r\nGFP_KERNEL);\r\nif (!gsi->outstanding_wrs) {\r\nret = -ENOMEM;\r\ngoto err_free_tx;\r\n}\r\nmutex_init(&gsi->mutex);\r\nmutex_lock(&dev->devr.mutex);\r\nif (dev->devr.ports[port_num - 1].gsi) {\r\nmlx5_ib_warn(dev, "GSI QP already exists on port %d\n",\r\nport_num);\r\nret = -EBUSY;\r\ngoto err_free_wrs;\r\n}\r\ngsi->num_qps = num_qps;\r\nspin_lock_init(&gsi->lock);\r\ngsi->cap = init_attr->cap;\r\ngsi->sq_sig_type = init_attr->sq_sig_type;\r\ngsi->ibqp.qp_num = 1;\r\ngsi->port_num = port_num;\r\ngsi->cq = ib_alloc_cq(pd->device, gsi, init_attr->cap.max_send_wr, 0,\r\nIB_POLL_SOFTIRQ);\r\nif (IS_ERR(gsi->cq)) {\r\nmlx5_ib_warn(dev, "unable to create send CQ for GSI QP. error %ld\n",\r\nPTR_ERR(gsi->cq));\r\nret = PTR_ERR(gsi->cq);\r\ngoto err_free_wrs;\r\n}\r\nhw_init_attr.qp_type = MLX5_IB_QPT_HW_GSI;\r\nhw_init_attr.send_cq = gsi->cq;\r\nif (num_qps) {\r\nhw_init_attr.cap.max_send_wr = 0;\r\nhw_init_attr.cap.max_send_sge = 0;\r\nhw_init_attr.cap.max_inline_data = 0;\r\n}\r\ngsi->rx_qp = ib_create_qp(pd, &hw_init_attr);\r\nif (IS_ERR(gsi->rx_qp)) {\r\nmlx5_ib_warn(dev, "unable to create hardware GSI QP. error %ld\n",\r\nPTR_ERR(gsi->rx_qp));\r\nret = PTR_ERR(gsi->rx_qp);\r\ngoto err_destroy_cq;\r\n}\r\ndev->devr.ports[init_attr->port_num - 1].gsi = gsi;\r\nmutex_unlock(&dev->devr.mutex);\r\nreturn &gsi->ibqp;\r\nerr_destroy_cq:\r\nib_free_cq(gsi->cq);\r\nerr_free_wrs:\r\nmutex_unlock(&dev->devr.mutex);\r\nkfree(gsi->outstanding_wrs);\r\nerr_free_tx:\r\nkfree(gsi->tx_qps);\r\nerr_free:\r\nkfree(gsi);\r\nreturn ERR_PTR(ret);\r\n}\r\nint mlx5_ib_gsi_destroy_qp(struct ib_qp *qp)\r\n{\r\nstruct mlx5_ib_dev *dev = to_mdev(qp->device);\r\nstruct mlx5_ib_gsi_qp *gsi = gsi_qp(qp);\r\nconst int port_num = gsi->port_num;\r\nint qp_index;\r\nint ret;\r\nmlx5_ib_dbg(dev, "destroying GSI QP\n");\r\nmutex_lock(&dev->devr.mutex);\r\nret = ib_destroy_qp(gsi->rx_qp);\r\nif (ret) {\r\nmlx5_ib_warn(dev, "unable to destroy hardware GSI QP. error %d\n",\r\nret);\r\nmutex_unlock(&dev->devr.mutex);\r\nreturn ret;\r\n}\r\ndev->devr.ports[port_num - 1].gsi = NULL;\r\nmutex_unlock(&dev->devr.mutex);\r\ngsi->rx_qp = NULL;\r\nfor (qp_index = 0; qp_index < gsi->num_qps; ++qp_index) {\r\nif (!gsi->tx_qps[qp_index])\r\ncontinue;\r\nWARN_ON_ONCE(ib_destroy_qp(gsi->tx_qps[qp_index]));\r\ngsi->tx_qps[qp_index] = NULL;\r\n}\r\nib_free_cq(gsi->cq);\r\nkfree(gsi->outstanding_wrs);\r\nkfree(gsi->tx_qps);\r\nkfree(gsi);\r\nreturn 0;\r\n}\r\nstatic struct ib_qp *create_gsi_ud_qp(struct mlx5_ib_gsi_qp *gsi)\r\n{\r\nstruct ib_pd *pd = gsi->rx_qp->pd;\r\nstruct ib_qp_init_attr init_attr = {\r\n.event_handler = gsi->rx_qp->event_handler,\r\n.qp_context = gsi->rx_qp->qp_context,\r\n.send_cq = gsi->cq,\r\n.recv_cq = gsi->rx_qp->recv_cq,\r\n.cap = {\r\n.max_send_wr = gsi->cap.max_send_wr,\r\n.max_send_sge = gsi->cap.max_send_sge,\r\n.max_inline_data = gsi->cap.max_inline_data,\r\n},\r\n.sq_sig_type = gsi->sq_sig_type,\r\n.qp_type = IB_QPT_UD,\r\n.create_flags = mlx5_ib_create_qp_sqpn_qp1(),\r\n};\r\nreturn ib_create_qp(pd, &init_attr);\r\n}\r\nstatic int modify_to_rts(struct mlx5_ib_gsi_qp *gsi, struct ib_qp *qp,\r\nu16 qp_index)\r\n{\r\nstruct mlx5_ib_dev *dev = to_mdev(qp->device);\r\nstruct ib_qp_attr attr;\r\nint mask;\r\nint ret;\r\nmask = IB_QP_STATE | IB_QP_PKEY_INDEX | IB_QP_QKEY | IB_QP_PORT;\r\nattr.qp_state = IB_QPS_INIT;\r\nattr.pkey_index = qp_index;\r\nattr.qkey = IB_QP1_QKEY;\r\nattr.port_num = gsi->port_num;\r\nret = ib_modify_qp(qp, &attr, mask);\r\nif (ret) {\r\nmlx5_ib_err(dev, "could not change QP%d state to INIT: %d\n",\r\nqp->qp_num, ret);\r\nreturn ret;\r\n}\r\nattr.qp_state = IB_QPS_RTR;\r\nret = ib_modify_qp(qp, &attr, IB_QP_STATE);\r\nif (ret) {\r\nmlx5_ib_err(dev, "could not change QP%d state to RTR: %d\n",\r\nqp->qp_num, ret);\r\nreturn ret;\r\n}\r\nattr.qp_state = IB_QPS_RTS;\r\nattr.sq_psn = 0;\r\nret = ib_modify_qp(qp, &attr, IB_QP_STATE | IB_QP_SQ_PSN);\r\nif (ret) {\r\nmlx5_ib_err(dev, "could not change QP%d state to RTS: %d\n",\r\nqp->qp_num, ret);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void setup_qp(struct mlx5_ib_gsi_qp *gsi, u16 qp_index)\r\n{\r\nstruct ib_device *device = gsi->rx_qp->device;\r\nstruct mlx5_ib_dev *dev = to_mdev(device);\r\nstruct ib_qp *qp;\r\nunsigned long flags;\r\nu16 pkey;\r\nint ret;\r\nret = ib_query_pkey(device, gsi->port_num, qp_index, &pkey);\r\nif (ret) {\r\nmlx5_ib_warn(dev, "unable to read P_Key at port %d, index %d\n",\r\ngsi->port_num, qp_index);\r\nreturn;\r\n}\r\nif (!pkey) {\r\nmlx5_ib_dbg(dev, "invalid P_Key at port %d, index %d. Skipping.\n",\r\ngsi->port_num, qp_index);\r\nreturn;\r\n}\r\nspin_lock_irqsave(&gsi->lock, flags);\r\nqp = gsi->tx_qps[qp_index];\r\nspin_unlock_irqrestore(&gsi->lock, flags);\r\nif (qp) {\r\nmlx5_ib_dbg(dev, "already existing GSI TX QP at port %d, index %d. Skipping\n",\r\ngsi->port_num, qp_index);\r\nreturn;\r\n}\r\nqp = create_gsi_ud_qp(gsi);\r\nif (IS_ERR(qp)) {\r\nmlx5_ib_warn(dev, "unable to create hardware UD QP for GSI: %ld\n",\r\nPTR_ERR(qp));\r\nreturn;\r\n}\r\nret = modify_to_rts(gsi, qp, qp_index);\r\nif (ret)\r\ngoto err_destroy_qp;\r\nspin_lock_irqsave(&gsi->lock, flags);\r\nWARN_ON_ONCE(gsi->tx_qps[qp_index]);\r\ngsi->tx_qps[qp_index] = qp;\r\nspin_unlock_irqrestore(&gsi->lock, flags);\r\nreturn;\r\nerr_destroy_qp:\r\nWARN_ON_ONCE(qp);\r\n}\r\nstatic void setup_qps(struct mlx5_ib_gsi_qp *gsi)\r\n{\r\nu16 qp_index;\r\nfor (qp_index = 0; qp_index < gsi->num_qps; ++qp_index)\r\nsetup_qp(gsi, qp_index);\r\n}\r\nint mlx5_ib_gsi_modify_qp(struct ib_qp *qp, struct ib_qp_attr *attr,\r\nint attr_mask)\r\n{\r\nstruct mlx5_ib_dev *dev = to_mdev(qp->device);\r\nstruct mlx5_ib_gsi_qp *gsi = gsi_qp(qp);\r\nint ret;\r\nmlx5_ib_dbg(dev, "modifying GSI QP to state %d\n", attr->qp_state);\r\nmutex_lock(&gsi->mutex);\r\nret = ib_modify_qp(gsi->rx_qp, attr, attr_mask);\r\nif (ret) {\r\nmlx5_ib_warn(dev, "unable to modify GSI rx QP: %d\n", ret);\r\ngoto unlock;\r\n}\r\nif (to_mqp(gsi->rx_qp)->state == IB_QPS_RTS)\r\nsetup_qps(gsi);\r\nunlock:\r\nmutex_unlock(&gsi->mutex);\r\nreturn ret;\r\n}\r\nint mlx5_ib_gsi_query_qp(struct ib_qp *qp, struct ib_qp_attr *qp_attr,\r\nint qp_attr_mask,\r\nstruct ib_qp_init_attr *qp_init_attr)\r\n{\r\nstruct mlx5_ib_gsi_qp *gsi = gsi_qp(qp);\r\nint ret;\r\nmutex_lock(&gsi->mutex);\r\nret = ib_query_qp(gsi->rx_qp, qp_attr, qp_attr_mask, qp_init_attr);\r\nqp_init_attr->cap = gsi->cap;\r\nmutex_unlock(&gsi->mutex);\r\nreturn ret;\r\n}\r\nstatic int mlx5_ib_add_outstanding_wr(struct mlx5_ib_gsi_qp *gsi,\r\nstruct ib_ud_wr *wr, struct ib_wc *wc)\r\n{\r\nstruct mlx5_ib_dev *dev = to_mdev(gsi->rx_qp->device);\r\nstruct mlx5_ib_gsi_wr *gsi_wr;\r\nif (gsi->outstanding_pi == gsi->outstanding_ci + gsi->cap.max_send_wr) {\r\nmlx5_ib_warn(dev, "no available GSI work request.\n");\r\nreturn -ENOMEM;\r\n}\r\ngsi_wr = &gsi->outstanding_wrs[gsi->outstanding_pi %\r\ngsi->cap.max_send_wr];\r\ngsi->outstanding_pi++;\r\nif (!wc) {\r\nmemset(&gsi_wr->wc, 0, sizeof(gsi_wr->wc));\r\ngsi_wr->wc.pkey_index = wr->pkey_index;\r\ngsi_wr->wc.wr_id = wr->wr.wr_id;\r\n} else {\r\ngsi_wr->wc = *wc;\r\ngsi_wr->completed = true;\r\n}\r\ngsi_wr->cqe.done = &handle_single_completion;\r\nwr->wr.wr_cqe = &gsi_wr->cqe;\r\nreturn 0;\r\n}\r\nstatic int mlx5_ib_gsi_silent_drop(struct mlx5_ib_gsi_qp *gsi,\r\nstruct ib_ud_wr *wr)\r\n{\r\nstruct ib_wc wc = {\r\n{ .wr_id = wr->wr.wr_id },\r\n.status = IB_WC_SUCCESS,\r\n.opcode = IB_WC_SEND,\r\n.qp = &gsi->ibqp,\r\n};\r\nint ret;\r\nret = mlx5_ib_add_outstanding_wr(gsi, wr, &wc);\r\nif (ret)\r\nreturn ret;\r\ngenerate_completions(gsi);\r\nreturn 0;\r\n}\r\nstatic struct ib_qp *get_tx_qp(struct mlx5_ib_gsi_qp *gsi, struct ib_ud_wr *wr)\r\n{\r\nstruct mlx5_ib_dev *dev = to_mdev(gsi->rx_qp->device);\r\nint qp_index = wr->pkey_index;\r\nif (!mlx5_ib_deth_sqpn_cap(dev))\r\nreturn gsi->rx_qp;\r\nif (qp_index >= gsi->num_qps)\r\nreturn NULL;\r\nreturn gsi->tx_qps[qp_index];\r\n}\r\nint mlx5_ib_gsi_post_send(struct ib_qp *qp, struct ib_send_wr *wr,\r\nstruct ib_send_wr **bad_wr)\r\n{\r\nstruct mlx5_ib_gsi_qp *gsi = gsi_qp(qp);\r\nstruct ib_qp *tx_qp;\r\nunsigned long flags;\r\nint ret;\r\nfor (; wr; wr = wr->next) {\r\nstruct ib_ud_wr cur_wr = *ud_wr(wr);\r\ncur_wr.wr.next = NULL;\r\nspin_lock_irqsave(&gsi->lock, flags);\r\ntx_qp = get_tx_qp(gsi, &cur_wr);\r\nif (!tx_qp) {\r\nret = mlx5_ib_gsi_silent_drop(gsi, &cur_wr);\r\nif (ret)\r\ngoto err;\r\nspin_unlock_irqrestore(&gsi->lock, flags);\r\ncontinue;\r\n}\r\nret = mlx5_ib_add_outstanding_wr(gsi, &cur_wr, NULL);\r\nif (ret)\r\ngoto err;\r\nret = ib_post_send(tx_qp, &cur_wr.wr, bad_wr);\r\nif (ret) {\r\ngsi->outstanding_pi = (gsi->outstanding_pi - 1) %\r\ngsi->cap.max_send_wr;\r\ngoto err;\r\n}\r\nspin_unlock_irqrestore(&gsi->lock, flags);\r\n}\r\nreturn 0;\r\nerr:\r\nspin_unlock_irqrestore(&gsi->lock, flags);\r\n*bad_wr = wr;\r\nreturn ret;\r\n}\r\nint mlx5_ib_gsi_post_recv(struct ib_qp *qp, struct ib_recv_wr *wr,\r\nstruct ib_recv_wr **bad_wr)\r\n{\r\nstruct mlx5_ib_gsi_qp *gsi = gsi_qp(qp);\r\nreturn ib_post_recv(gsi->rx_qp, wr, bad_wr);\r\n}\r\nvoid mlx5_ib_gsi_pkey_change(struct mlx5_ib_gsi_qp *gsi)\r\n{\r\nif (!gsi)\r\nreturn;\r\nmutex_lock(&gsi->mutex);\r\nsetup_qps(gsi);\r\nmutex_unlock(&gsi->mutex);\r\n}
