static int init_vgpu_opregion(struct intel_vgpu *vgpu, u32 gpa)\r\n{\r\nu8 *buf;\r\nint i;\r\nif (WARN((vgpu_opregion(vgpu)->va),\r\n"vgpu%d: opregion has been initialized already.\n",\r\nvgpu->id))\r\nreturn -EINVAL;\r\nvgpu_opregion(vgpu)->va = (void *)__get_free_pages(GFP_KERNEL |\r\n__GFP_ZERO,\r\nget_order(INTEL_GVT_OPREGION_SIZE));\r\nif (!vgpu_opregion(vgpu)->va)\r\nreturn -ENOMEM;\r\nmemcpy(vgpu_opregion(vgpu)->va, vgpu->gvt->opregion.opregion_va,\r\nINTEL_GVT_OPREGION_SIZE);\r\nfor (i = 0; i < INTEL_GVT_OPREGION_PAGES; i++)\r\nvgpu_opregion(vgpu)->gfn[i] = (gpa >> PAGE_SHIFT) + i;\r\nbuf = (u8 *)vgpu_opregion(vgpu)->va;\r\nbuf[INTEL_GVT_OPREGION_CLID] = 0x3;\r\nreturn 0;\r\n}\r\nstatic int map_vgpu_opregion(struct intel_vgpu *vgpu, bool map)\r\n{\r\nu64 mfn;\r\nint i, ret;\r\nfor (i = 0; i < INTEL_GVT_OPREGION_PAGES; i++) {\r\nmfn = intel_gvt_hypervisor_virt_to_mfn(vgpu_opregion(vgpu)->va\r\n+ i * PAGE_SIZE);\r\nif (mfn == INTEL_GVT_INVALID_ADDR) {\r\ngvt_vgpu_err("fail to get MFN from VA\n");\r\nreturn -EINVAL;\r\n}\r\nret = intel_gvt_hypervisor_map_gfn_to_mfn(vgpu,\r\nvgpu_opregion(vgpu)->gfn[i],\r\nmfn, 1, map);\r\nif (ret) {\r\ngvt_vgpu_err("fail to map GFN to MFN, errno: %d\n",\r\nret);\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid intel_vgpu_clean_opregion(struct intel_vgpu *vgpu)\r\n{\r\ngvt_dbg_core("vgpu%d: clean vgpu opregion\n", vgpu->id);\r\nif (!vgpu_opregion(vgpu)->va)\r\nreturn;\r\nif (intel_gvt_host.hypervisor_type == INTEL_GVT_HYPERVISOR_XEN) {\r\nmap_vgpu_opregion(vgpu, false);\r\nfree_pages((unsigned long)vgpu_opregion(vgpu)->va,\r\nget_order(INTEL_GVT_OPREGION_SIZE));\r\nvgpu_opregion(vgpu)->va = NULL;\r\n}\r\n}\r\nint intel_vgpu_init_opregion(struct intel_vgpu *vgpu, u32 gpa)\r\n{\r\nint ret;\r\ngvt_dbg_core("vgpu%d: init vgpu opregion\n", vgpu->id);\r\nif (intel_gvt_host.hypervisor_type == INTEL_GVT_HYPERVISOR_XEN) {\r\ngvt_dbg_core("emulate opregion from kernel\n");\r\nret = init_vgpu_opregion(vgpu, gpa);\r\nif (ret)\r\nreturn ret;\r\nret = map_vgpu_opregion(vgpu, true);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nvoid intel_gvt_clean_opregion(struct intel_gvt *gvt)\r\n{\r\nmemunmap(gvt->opregion.opregion_va);\r\ngvt->opregion.opregion_va = NULL;\r\n}\r\nint intel_gvt_init_opregion(struct intel_gvt *gvt)\r\n{\r\ngvt_dbg_core("init host opregion\n");\r\npci_read_config_dword(gvt->dev_priv->drm.pdev, INTEL_GVT_PCI_OPREGION,\r\n&gvt->opregion.opregion_pa);\r\ngvt->opregion.opregion_va = memremap(gvt->opregion.opregion_pa,\r\nINTEL_GVT_OPREGION_SIZE, MEMREMAP_WB);\r\nif (!gvt->opregion.opregion_va) {\r\ngvt_err("fail to map host opregion\n");\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nstatic const char *opregion_func_name(u32 func)\r\n{\r\nconst char *name = NULL;\r\nswitch (func) {\r\ncase 0 ... 3:\r\ncase 5:\r\ncase 7 ... 15:\r\nname = "Reserved";\r\nbreak;\r\ncase 4:\r\nname = "Get BIOS Data";\r\nbreak;\r\ncase 6:\r\nname = "System BIOS Callbacks";\r\nbreak;\r\ndefault:\r\nname = "Unknown";\r\nbreak;\r\n}\r\nreturn name;\r\n}\r\nstatic const char *opregion_subfunc_name(u32 subfunc)\r\n{\r\nconst char *name = NULL;\r\nswitch (subfunc) {\r\ncase 0:\r\nname = "Supported Calls";\r\nbreak;\r\ncase 1:\r\nname = "Requested Callbacks";\r\nbreak;\r\ncase 2 ... 3:\r\ncase 8 ... 9:\r\nname = "Reserved";\r\nbreak;\r\ncase 5:\r\nname = "Boot Display";\r\nbreak;\r\ncase 6:\r\nname = "TV-Standard/Video-Connector";\r\nbreak;\r\ncase 7:\r\nname = "Internal Graphics";\r\nbreak;\r\ncase 10:\r\nname = "Spread Spectrum Clocks";\r\nbreak;\r\ncase 11:\r\nname = "Get AKSV";\r\nbreak;\r\ndefault:\r\nname = "Unknown";\r\nbreak;\r\n}\r\nreturn name;\r\n}\r\nstatic bool querying_capabilities(u32 scic)\r\n{\r\nu32 func, subfunc;\r\nfunc = GVT_OPREGION_FUNC(scic);\r\nsubfunc = GVT_OPREGION_SUBFUNC(scic);\r\nif ((func == INTEL_GVT_OPREGION_SCIC_F_GETBIOSDATA &&\r\nsubfunc == INTEL_GVT_OPREGION_SCIC_SF_SUPPRTEDCALLS)\r\n|| (func == INTEL_GVT_OPREGION_SCIC_F_GETBIOSDATA &&\r\nsubfunc == INTEL_GVT_OPREGION_SCIC_SF_REQEUSTEDCALLBACKS)\r\n|| (func == INTEL_GVT_OPREGION_SCIC_F_GETBIOSCALLBACKS &&\r\nsubfunc == INTEL_GVT_OPREGION_SCIC_SF_SUPPRTEDCALLS)) {\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nint intel_vgpu_emulate_opregion_request(struct intel_vgpu *vgpu, u32 swsci)\r\n{\r\nu32 *scic, *parm;\r\nu32 func, subfunc;\r\nscic = vgpu_opregion(vgpu)->va + INTEL_GVT_OPREGION_SCIC;\r\nparm = vgpu_opregion(vgpu)->va + INTEL_GVT_OPREGION_PARM;\r\nif (!(swsci & SWSCI_SCI_SELECT)) {\r\ngvt_vgpu_err("requesting SMI service\n");\r\nreturn 0;\r\n}\r\nif ((vgpu_cfg_space(vgpu)[INTEL_GVT_PCI_SWSCI]\r\n& SWSCI_SCI_TRIGGER) ||\r\n!(swsci & SWSCI_SCI_TRIGGER)) {\r\nreturn 0;\r\n}\r\nfunc = GVT_OPREGION_FUNC(*scic);\r\nsubfunc = GVT_OPREGION_SUBFUNC(*scic);\r\nif (!querying_capabilities(*scic)) {\r\ngvt_vgpu_err("requesting runtime service: func \"%s\","\r\n" subfunc \"%s\"\n",\r\nopregion_func_name(func),\r\nopregion_subfunc_name(subfunc));\r\n*scic &= ~OPREGION_SCIC_EXIT_MASK;\r\nreturn 0;\r\n}\r\n*scic = 0;\r\n*parm = 0;\r\nreturn 0;\r\n}
