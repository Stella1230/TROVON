static inline int parent(int i)\r\n{\r\nreturn (i - 1) >> 1;\r\n}\r\nstatic inline int left_child(int i)\r\n{\r\nreturn (i << 1) + 1;\r\n}\r\nstatic inline int right_child(int i)\r\n{\r\nreturn (i << 1) + 2;\r\n}\r\nstatic void cpudl_heapify_down(struct cpudl *cp, int idx)\r\n{\r\nint l, r, largest;\r\nint orig_cpu = cp->elements[idx].cpu;\r\nu64 orig_dl = cp->elements[idx].dl;\r\nif (left_child(idx) >= cp->size)\r\nreturn;\r\nwhile(1) {\r\nu64 largest_dl;\r\nl = left_child(idx);\r\nr = right_child(idx);\r\nlargest = idx;\r\nlargest_dl = orig_dl;\r\nif ((l < cp->size) && dl_time_before(orig_dl,\r\ncp->elements[l].dl)) {\r\nlargest = l;\r\nlargest_dl = cp->elements[l].dl;\r\n}\r\nif ((r < cp->size) && dl_time_before(largest_dl,\r\ncp->elements[r].dl))\r\nlargest = r;\r\nif (largest == idx)\r\nbreak;\r\ncp->elements[idx].cpu = cp->elements[largest].cpu;\r\ncp->elements[idx].dl = cp->elements[largest].dl;\r\ncp->elements[cp->elements[idx].cpu].idx = idx;\r\nidx = largest;\r\n}\r\ncp->elements[idx].cpu = orig_cpu;\r\ncp->elements[idx].dl = orig_dl;\r\ncp->elements[cp->elements[idx].cpu].idx = idx;\r\n}\r\nstatic void cpudl_heapify_up(struct cpudl *cp, int idx)\r\n{\r\nint p;\r\nint orig_cpu = cp->elements[idx].cpu;\r\nu64 orig_dl = cp->elements[idx].dl;\r\nif (idx == 0)\r\nreturn;\r\ndo {\r\np = parent(idx);\r\nif (dl_time_before(orig_dl, cp->elements[p].dl))\r\nbreak;\r\ncp->elements[idx].cpu = cp->elements[p].cpu;\r\ncp->elements[idx].dl = cp->elements[p].dl;\r\ncp->elements[cp->elements[idx].cpu].idx = idx;\r\nidx = p;\r\n} while (idx != 0);\r\ncp->elements[idx].cpu = orig_cpu;\r\ncp->elements[idx].dl = orig_dl;\r\ncp->elements[cp->elements[idx].cpu].idx = idx;\r\n}\r\nstatic void cpudl_heapify(struct cpudl *cp, int idx)\r\n{\r\nif (idx > 0 && dl_time_before(cp->elements[parent(idx)].dl,\r\ncp->elements[idx].dl))\r\ncpudl_heapify_up(cp, idx);\r\nelse\r\ncpudl_heapify_down(cp, idx);\r\n}\r\nstatic inline int cpudl_maximum(struct cpudl *cp)\r\n{\r\nreturn cp->elements[0].cpu;\r\n}\r\nint cpudl_find(struct cpudl *cp, struct task_struct *p,\r\nstruct cpumask *later_mask)\r\n{\r\nint best_cpu = -1;\r\nconst struct sched_dl_entity *dl_se = &p->dl;\r\nif (later_mask &&\r\ncpumask_and(later_mask, cp->free_cpus, &p->cpus_allowed)) {\r\nbest_cpu = cpumask_any(later_mask);\r\ngoto out;\r\n} else if (cpumask_test_cpu(cpudl_maximum(cp), &p->cpus_allowed) &&\r\ndl_time_before(dl_se->deadline, cp->elements[0].dl)) {\r\nbest_cpu = cpudl_maximum(cp);\r\nif (later_mask)\r\ncpumask_set_cpu(best_cpu, later_mask);\r\n}\r\nout:\r\nWARN_ON(best_cpu != -1 && !cpu_present(best_cpu));\r\nreturn best_cpu;\r\n}\r\nvoid cpudl_clear(struct cpudl *cp, int cpu)\r\n{\r\nint old_idx, new_cpu;\r\nunsigned long flags;\r\nWARN_ON(!cpu_present(cpu));\r\nraw_spin_lock_irqsave(&cp->lock, flags);\r\nold_idx = cp->elements[cpu].idx;\r\nif (old_idx == IDX_INVALID) {\r\n} else {\r\nnew_cpu = cp->elements[cp->size - 1].cpu;\r\ncp->elements[old_idx].dl = cp->elements[cp->size - 1].dl;\r\ncp->elements[old_idx].cpu = new_cpu;\r\ncp->size--;\r\ncp->elements[new_cpu].idx = old_idx;\r\ncp->elements[cpu].idx = IDX_INVALID;\r\ncpudl_heapify(cp, old_idx);\r\ncpumask_set_cpu(cpu, cp->free_cpus);\r\n}\r\nraw_spin_unlock_irqrestore(&cp->lock, flags);\r\n}\r\nvoid cpudl_set(struct cpudl *cp, int cpu, u64 dl)\r\n{\r\nint old_idx;\r\nunsigned long flags;\r\nWARN_ON(!cpu_present(cpu));\r\nraw_spin_lock_irqsave(&cp->lock, flags);\r\nold_idx = cp->elements[cpu].idx;\r\nif (old_idx == IDX_INVALID) {\r\nint new_idx = cp->size++;\r\ncp->elements[new_idx].dl = dl;\r\ncp->elements[new_idx].cpu = cpu;\r\ncp->elements[cpu].idx = new_idx;\r\ncpudl_heapify_up(cp, new_idx);\r\ncpumask_clear_cpu(cpu, cp->free_cpus);\r\n} else {\r\ncp->elements[old_idx].dl = dl;\r\ncpudl_heapify(cp, old_idx);\r\n}\r\nraw_spin_unlock_irqrestore(&cp->lock, flags);\r\n}\r\nvoid cpudl_set_freecpu(struct cpudl *cp, int cpu)\r\n{\r\ncpumask_set_cpu(cpu, cp->free_cpus);\r\n}\r\nvoid cpudl_clear_freecpu(struct cpudl *cp, int cpu)\r\n{\r\ncpumask_clear_cpu(cpu, cp->free_cpus);\r\n}\r\nint cpudl_init(struct cpudl *cp)\r\n{\r\nint i;\r\nmemset(cp, 0, sizeof(*cp));\r\nraw_spin_lock_init(&cp->lock);\r\ncp->size = 0;\r\ncp->elements = kcalloc(nr_cpu_ids,\r\nsizeof(struct cpudl_item),\r\nGFP_KERNEL);\r\nif (!cp->elements)\r\nreturn -ENOMEM;\r\nif (!zalloc_cpumask_var(&cp->free_cpus, GFP_KERNEL)) {\r\nkfree(cp->elements);\r\nreturn -ENOMEM;\r\n}\r\nfor_each_possible_cpu(i)\r\ncp->elements[i].idx = IDX_INVALID;\r\nreturn 0;\r\n}\r\nvoid cpudl_cleanup(struct cpudl *cp)\r\n{\r\nfree_cpumask_var(cp->free_cpus);\r\nkfree(cp->elements);\r\n}
