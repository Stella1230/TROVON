static FORCE_INLINE U32 LZ4_hash4(\r\nU32 sequence,\r\ntableType_t const tableType)\r\n{\r\nif (tableType == byU16)\r\nreturn ((sequence * 2654435761U)\r\n>> ((MINMATCH * 8) - (LZ4_HASHLOG + 1)));\r\nelse\r\nreturn ((sequence * 2654435761U)\r\n>> ((MINMATCH * 8) - LZ4_HASHLOG));\r\n}\r\nstatic FORCE_INLINE U32 LZ4_hash5(\r\nU64 sequence,\r\ntableType_t const tableType)\r\n{\r\nconst U32 hashLog = (tableType == byU16)\r\n? LZ4_HASHLOG + 1\r\n: LZ4_HASHLOG;\r\n#if LZ4_LITTLE_ENDIAN\r\nstatic const U64 prime5bytes = 889523592379ULL;\r\nreturn (U32)(((sequence << 24) * prime5bytes) >> (64 - hashLog));\r\n#else\r\nstatic const U64 prime8bytes = 11400714785074694791ULL;\r\nreturn (U32)(((sequence >> 24) * prime8bytes) >> (64 - hashLog));\r\n#endif\r\n}\r\nstatic FORCE_INLINE U32 LZ4_hashPosition(\r\nconst void *p,\r\ntableType_t const tableType)\r\n{\r\n#if LZ4_ARCH64\r\nif (tableType == byU32)\r\nreturn LZ4_hash5(LZ4_read_ARCH(p), tableType);\r\n#endif\r\nreturn LZ4_hash4(LZ4_read32(p), tableType);\r\n}\r\nstatic void LZ4_putPositionOnHash(\r\nconst BYTE *p,\r\nU32 h,\r\nvoid *tableBase,\r\ntableType_t const tableType,\r\nconst BYTE *srcBase)\r\n{\r\nswitch (tableType) {\r\ncase byPtr:\r\n{\r\nconst BYTE **hashTable = (const BYTE **)tableBase;\r\nhashTable[h] = p;\r\nreturn;\r\n}\r\ncase byU32:\r\n{\r\nU32 *hashTable = (U32 *) tableBase;\r\nhashTable[h] = (U32)(p - srcBase);\r\nreturn;\r\n}\r\ncase byU16:\r\n{\r\nU16 *hashTable = (U16 *) tableBase;\r\nhashTable[h] = (U16)(p - srcBase);\r\nreturn;\r\n}\r\n}\r\n}\r\nstatic FORCE_INLINE void LZ4_putPosition(\r\nconst BYTE *p,\r\nvoid *tableBase,\r\ntableType_t tableType,\r\nconst BYTE *srcBase)\r\n{\r\nU32 const h = LZ4_hashPosition(p, tableType);\r\nLZ4_putPositionOnHash(p, h, tableBase, tableType, srcBase);\r\n}\r\nstatic const BYTE *LZ4_getPositionOnHash(\r\nU32 h,\r\nvoid *tableBase,\r\ntableType_t tableType,\r\nconst BYTE *srcBase)\r\n{\r\nif (tableType == byPtr) {\r\nconst BYTE **hashTable = (const BYTE **) tableBase;\r\nreturn hashTable[h];\r\n}\r\nif (tableType == byU32) {\r\nconst U32 * const hashTable = (U32 *) tableBase;\r\nreturn hashTable[h] + srcBase;\r\n}\r\n{\r\nconst U16 * const hashTable = (U16 *) tableBase;\r\nreturn hashTable[h] + srcBase;\r\n}\r\n}\r\nstatic FORCE_INLINE const BYTE *LZ4_getPosition(\r\nconst BYTE *p,\r\nvoid *tableBase,\r\ntableType_t tableType,\r\nconst BYTE *srcBase)\r\n{\r\nU32 const h = LZ4_hashPosition(p, tableType);\r\nreturn LZ4_getPositionOnHash(h, tableBase, tableType, srcBase);\r\n}\r\nstatic FORCE_INLINE int LZ4_compress_generic(\r\nLZ4_stream_t_internal * const dictPtr,\r\nconst char * const source,\r\nchar * const dest,\r\nconst int inputSize,\r\nconst int maxOutputSize,\r\nconst limitedOutput_directive outputLimited,\r\nconst tableType_t tableType,\r\nconst dict_directive dict,\r\nconst dictIssue_directive dictIssue,\r\nconst U32 acceleration)\r\n{\r\nconst BYTE *ip = (const BYTE *) source;\r\nconst BYTE *base;\r\nconst BYTE *lowLimit;\r\nconst BYTE * const lowRefLimit = ip - dictPtr->dictSize;\r\nconst BYTE * const dictionary = dictPtr->dictionary;\r\nconst BYTE * const dictEnd = dictionary + dictPtr->dictSize;\r\nconst size_t dictDelta = dictEnd - (const BYTE *)source;\r\nconst BYTE *anchor = (const BYTE *) source;\r\nconst BYTE * const iend = ip + inputSize;\r\nconst BYTE * const mflimit = iend - MFLIMIT;\r\nconst BYTE * const matchlimit = iend - LASTLITERALS;\r\nBYTE *op = (BYTE *) dest;\r\nBYTE * const olimit = op + maxOutputSize;\r\nU32 forwardH;\r\nsize_t refDelta = 0;\r\nif ((U32)inputSize > (U32)LZ4_MAX_INPUT_SIZE) {\r\nreturn 0;\r\n}\r\nswitch (dict) {\r\ncase noDict:\r\ndefault:\r\nbase = (const BYTE *)source;\r\nlowLimit = (const BYTE *)source;\r\nbreak;\r\ncase withPrefix64k:\r\nbase = (const BYTE *)source - dictPtr->currentOffset;\r\nlowLimit = (const BYTE *)source - dictPtr->dictSize;\r\nbreak;\r\ncase usingExtDict:\r\nbase = (const BYTE *)source - dictPtr->currentOffset;\r\nlowLimit = (const BYTE *)source;\r\nbreak;\r\n}\r\nif ((tableType == byU16)\r\n&& (inputSize >= LZ4_64Klimit)) {\r\nreturn 0;\r\n}\r\nif (inputSize < LZ4_minLength) {\r\ngoto _last_literals;\r\n}\r\nLZ4_putPosition(ip, dictPtr->hashTable, tableType, base);\r\nip++;\r\nforwardH = LZ4_hashPosition(ip, tableType);\r\nfor ( ; ; ) {\r\nconst BYTE *match;\r\nBYTE *token;\r\n{\r\nconst BYTE *forwardIp = ip;\r\nunsigned int step = 1;\r\nunsigned int searchMatchNb = acceleration << LZ4_SKIPTRIGGER;\r\ndo {\r\nU32 const h = forwardH;\r\nip = forwardIp;\r\nforwardIp += step;\r\nstep = (searchMatchNb++ >> LZ4_SKIPTRIGGER);\r\nif (unlikely(forwardIp > mflimit))\r\ngoto _last_literals;\r\nmatch = LZ4_getPositionOnHash(h,\r\ndictPtr->hashTable,\r\ntableType, base);\r\nif (dict == usingExtDict) {\r\nif (match < (const BYTE *)source) {\r\nrefDelta = dictDelta;\r\nlowLimit = dictionary;\r\n} else {\r\nrefDelta = 0;\r\nlowLimit = (const BYTE *)source;\r\n} }\r\nforwardH = LZ4_hashPosition(forwardIp,\r\ntableType);\r\nLZ4_putPositionOnHash(ip, h, dictPtr->hashTable,\r\ntableType, base);\r\n} while (((dictIssue == dictSmall)\r\n? (match < lowRefLimit)\r\n: 0)\r\n|| ((tableType == byU16)\r\n? 0\r\n: (match + MAX_DISTANCE < ip))\r\n|| (LZ4_read32(match + refDelta)\r\n!= LZ4_read32(ip)));\r\n}\r\nwhile (((ip > anchor) & (match + refDelta > lowLimit))\r\n&& (unlikely(ip[-1] == match[refDelta - 1]))) {\r\nip--;\r\nmatch--;\r\n}\r\n{\r\nunsigned const int litLength = (unsigned int)(ip - anchor);\r\ntoken = op++;\r\nif ((outputLimited) &&\r\n(unlikely(op + litLength +\r\n(2 + 1 + LASTLITERALS) +\r\n(litLength / 255) > olimit)))\r\nreturn 0;\r\nif (litLength >= RUN_MASK) {\r\nint len = (int)litLength - RUN_MASK;\r\n*token = (RUN_MASK << ML_BITS);\r\nfor (; len >= 255; len -= 255)\r\n*op++ = 255;\r\n*op++ = (BYTE)len;\r\n} else\r\n*token = (BYTE)(litLength << ML_BITS);\r\nLZ4_wildCopy(op, anchor, op + litLength);\r\nop += litLength;\r\n}\r\n_next_match:\r\nLZ4_writeLE16(op, (U16)(ip - match));\r\nop += 2;\r\n{\r\nunsigned int matchCode;\r\nif ((dict == usingExtDict)\r\n&& (lowLimit == dictionary)) {\r\nconst BYTE *limit;\r\nmatch += refDelta;\r\nlimit = ip + (dictEnd - match);\r\nif (limit > matchlimit)\r\nlimit = matchlimit;\r\nmatchCode = LZ4_count(ip + MINMATCH,\r\nmatch + MINMATCH, limit);\r\nip += MINMATCH + matchCode;\r\nif (ip == limit) {\r\nunsigned const int more = LZ4_count(ip,\r\n(const BYTE *)source,\r\nmatchlimit);\r\nmatchCode += more;\r\nip += more;\r\n}\r\n} else {\r\nmatchCode = LZ4_count(ip + MINMATCH,\r\nmatch + MINMATCH, matchlimit);\r\nip += MINMATCH + matchCode;\r\n}\r\nif (outputLimited &&\r\n(unlikely(op +\r\n(1 + LASTLITERALS) +\r\n(matchCode >> 8) > olimit)))\r\nreturn 0;\r\nif (matchCode >= ML_MASK) {\r\n*token += ML_MASK;\r\nmatchCode -= ML_MASK;\r\nLZ4_write32(op, 0xFFFFFFFF);\r\nwhile (matchCode >= 4 * 255) {\r\nop += 4;\r\nLZ4_write32(op, 0xFFFFFFFF);\r\nmatchCode -= 4 * 255;\r\n}\r\nop += matchCode / 255;\r\n*op++ = (BYTE)(matchCode % 255);\r\n} else\r\n*token += (BYTE)(matchCode);\r\n}\r\nanchor = ip;\r\nif (ip > mflimit)\r\nbreak;\r\nLZ4_putPosition(ip - 2, dictPtr->hashTable, tableType, base);\r\nmatch = LZ4_getPosition(ip, dictPtr->hashTable,\r\ntableType, base);\r\nif (dict == usingExtDict) {\r\nif (match < (const BYTE *)source) {\r\nrefDelta = dictDelta;\r\nlowLimit = dictionary;\r\n} else {\r\nrefDelta = 0;\r\nlowLimit = (const BYTE *)source;\r\n}\r\n}\r\nLZ4_putPosition(ip, dictPtr->hashTable, tableType, base);\r\nif (((dictIssue == dictSmall) ? (match >= lowRefLimit) : 1)\r\n&& (match + MAX_DISTANCE >= ip)\r\n&& (LZ4_read32(match + refDelta) == LZ4_read32(ip))) {\r\ntoken = op++;\r\n*token = 0;\r\ngoto _next_match;\r\n}\r\nforwardH = LZ4_hashPosition(++ip, tableType);\r\n}\r\n_last_literals:\r\n{\r\nsize_t const lastRun = (size_t)(iend - anchor);\r\nif ((outputLimited) &&\r\n((op - (BYTE *)dest) + lastRun + 1 +\r\n((lastRun + 255 - RUN_MASK) / 255) > (U32)maxOutputSize))\r\nreturn 0;\r\nif (lastRun >= RUN_MASK) {\r\nsize_t accumulator = lastRun - RUN_MASK;\r\n*op++ = RUN_MASK << ML_BITS;\r\nfor (; accumulator >= 255; accumulator -= 255)\r\n*op++ = 255;\r\n*op++ = (BYTE) accumulator;\r\n} else {\r\n*op++ = (BYTE)(lastRun << ML_BITS);\r\n}\r\nmemcpy(op, anchor, lastRun);\r\nop += lastRun;\r\n}\r\nreturn (int) (((char *)op) - dest);\r\n}\r\nstatic int LZ4_compress_fast_extState(\r\nvoid *state,\r\nconst char *source,\r\nchar *dest,\r\nint inputSize,\r\nint maxOutputSize,\r\nint acceleration)\r\n{\r\nLZ4_stream_t_internal *ctx = &((LZ4_stream_t *)state)->internal_donotuse;\r\n#if LZ4_ARCH64\r\nconst tableType_t tableType = byU32;\r\n#else\r\nconst tableType_t tableType = byPtr;\r\n#endif\r\nLZ4_resetStream((LZ4_stream_t *)state);\r\nif (acceleration < 1)\r\nacceleration = LZ4_ACCELERATION_DEFAULT;\r\nif (maxOutputSize >= LZ4_COMPRESSBOUND(inputSize)) {\r\nif (inputSize < LZ4_64Klimit)\r\nreturn LZ4_compress_generic(ctx, source,\r\ndest, inputSize, 0,\r\nnoLimit, byU16, noDict,\r\nnoDictIssue, acceleration);\r\nelse\r\nreturn LZ4_compress_generic(ctx, source,\r\ndest, inputSize, 0,\r\nnoLimit, tableType, noDict,\r\nnoDictIssue, acceleration);\r\n} else {\r\nif (inputSize < LZ4_64Klimit)\r\nreturn LZ4_compress_generic(ctx, source,\r\ndest, inputSize,\r\nmaxOutputSize, limitedOutput, byU16, noDict,\r\nnoDictIssue, acceleration);\r\nelse\r\nreturn LZ4_compress_generic(ctx, source,\r\ndest, inputSize,\r\nmaxOutputSize, limitedOutput, tableType, noDict,\r\nnoDictIssue, acceleration);\r\n}\r\n}\r\nint LZ4_compress_fast(const char *source, char *dest, int inputSize,\r\nint maxOutputSize, int acceleration, void *wrkmem)\r\n{\r\nreturn LZ4_compress_fast_extState(wrkmem, source, dest, inputSize,\r\nmaxOutputSize, acceleration);\r\n}\r\nint LZ4_compress_default(const char *source, char *dest, int inputSize,\r\nint maxOutputSize, void *wrkmem)\r\n{\r\nreturn LZ4_compress_fast(source, dest, inputSize,\r\nmaxOutputSize, LZ4_ACCELERATION_DEFAULT, wrkmem);\r\n}\r\nstatic int LZ4_compress_destSize_generic(\r\nLZ4_stream_t_internal * const ctx,\r\nconst char * const src,\r\nchar * const dst,\r\nint * const srcSizePtr,\r\nconst int targetDstSize,\r\nconst tableType_t tableType)\r\n{\r\nconst BYTE *ip = (const BYTE *) src;\r\nconst BYTE *base = (const BYTE *) src;\r\nconst BYTE *lowLimit = (const BYTE *) src;\r\nconst BYTE *anchor = ip;\r\nconst BYTE * const iend = ip + *srcSizePtr;\r\nconst BYTE * const mflimit = iend - MFLIMIT;\r\nconst BYTE * const matchlimit = iend - LASTLITERALS;\r\nBYTE *op = (BYTE *) dst;\r\nBYTE * const oend = op + targetDstSize;\r\nBYTE * const oMaxLit = op + targetDstSize - 2\r\n- 8 - 1 ;\r\nBYTE * const oMaxMatch = op + targetDstSize\r\n- (LASTLITERALS + 1 );\r\nBYTE * const oMaxSeq = oMaxLit - 1 ;\r\nU32 forwardH;\r\nif (targetDstSize < 1)\r\nreturn 0;\r\nif ((U32)*srcSizePtr > (U32)LZ4_MAX_INPUT_SIZE)\r\nreturn 0;\r\nif ((tableType == byU16) && (*srcSizePtr >= LZ4_64Klimit))\r\nreturn 0;\r\nif (*srcSizePtr < LZ4_minLength)\r\ngoto _last_literals;\r\n*srcSizePtr = 0;\r\nLZ4_putPosition(ip, ctx->hashTable, tableType, base);\r\nip++; forwardH = LZ4_hashPosition(ip, tableType);\r\nfor ( ; ; ) {\r\nconst BYTE *match;\r\nBYTE *token;\r\n{\r\nconst BYTE *forwardIp = ip;\r\nunsigned int step = 1;\r\nunsigned int searchMatchNb = 1 << LZ4_SKIPTRIGGER;\r\ndo {\r\nU32 h = forwardH;\r\nip = forwardIp;\r\nforwardIp += step;\r\nstep = (searchMatchNb++ >> LZ4_SKIPTRIGGER);\r\nif (unlikely(forwardIp > mflimit))\r\ngoto _last_literals;\r\nmatch = LZ4_getPositionOnHash(h, ctx->hashTable,\r\ntableType, base);\r\nforwardH = LZ4_hashPosition(forwardIp,\r\ntableType);\r\nLZ4_putPositionOnHash(ip, h,\r\nctx->hashTable, tableType,\r\nbase);\r\n} while (((tableType == byU16)\r\n? 0\r\n: (match + MAX_DISTANCE < ip))\r\n|| (LZ4_read32(match) != LZ4_read32(ip)));\r\n}\r\nwhile ((ip > anchor)\r\n&& (match > lowLimit)\r\n&& (unlikely(ip[-1] == match[-1]))) {\r\nip--;\r\nmatch--;\r\n}\r\n{\r\nunsigned int litLength = (unsigned int)(ip - anchor);\r\ntoken = op++;\r\nif (op + ((litLength + 240) / 255)\r\n+ litLength > oMaxLit) {\r\nop--;\r\ngoto _last_literals;\r\n}\r\nif (litLength >= RUN_MASK) {\r\nunsigned int len = litLength - RUN_MASK;\r\n*token = (RUN_MASK<<ML_BITS);\r\nfor (; len >= 255; len -= 255)\r\n*op++ = 255;\r\n*op++ = (BYTE)len;\r\n} else\r\n*token = (BYTE)(litLength << ML_BITS);\r\nLZ4_wildCopy(op, anchor, op + litLength);\r\nop += litLength;\r\n}\r\n_next_match:\r\nLZ4_writeLE16(op, (U16)(ip - match)); op += 2;\r\n{\r\nsize_t matchLength = LZ4_count(ip + MINMATCH,\r\nmatch + MINMATCH, matchlimit);\r\nif (op + ((matchLength + 240)/255) > oMaxMatch) {\r\nmatchLength = (15 - 1) + (oMaxMatch - op) * 255;\r\n}\r\nip += MINMATCH + matchLength;\r\nif (matchLength >= ML_MASK) {\r\n*token += ML_MASK;\r\nmatchLength -= ML_MASK;\r\nwhile (matchLength >= 255) {\r\nmatchLength -= 255;\r\n*op++ = 255;\r\n}\r\n*op++ = (BYTE)matchLength;\r\n} else\r\n*token += (BYTE)(matchLength);\r\n}\r\nanchor = ip;\r\nif (ip > mflimit)\r\nbreak;\r\nif (op > oMaxSeq)\r\nbreak;\r\nLZ4_putPosition(ip - 2, ctx->hashTable, tableType, base);\r\nmatch = LZ4_getPosition(ip, ctx->hashTable, tableType, base);\r\nLZ4_putPosition(ip, ctx->hashTable, tableType, base);\r\nif ((match + MAX_DISTANCE >= ip)\r\n&& (LZ4_read32(match) == LZ4_read32(ip))) {\r\ntoken = op++; *token = 0;\r\ngoto _next_match;\r\n}\r\nforwardH = LZ4_hashPosition(++ip, tableType);\r\n}\r\n_last_literals:\r\n{\r\nsize_t lastRunSize = (size_t)(iend - anchor);\r\nif (op + 1\r\n+ ((lastRunSize + 240) / 255)\r\n+ lastRunSize > oend) {\r\nlastRunSize = (oend - op) - 1;\r\nlastRunSize -= (lastRunSize + 240) / 255;\r\n}\r\nip = anchor + lastRunSize;\r\nif (lastRunSize >= RUN_MASK) {\r\nsize_t accumulator = lastRunSize - RUN_MASK;\r\n*op++ = RUN_MASK << ML_BITS;\r\nfor (; accumulator >= 255; accumulator -= 255)\r\n*op++ = 255;\r\n*op++ = (BYTE) accumulator;\r\n} else {\r\n*op++ = (BYTE)(lastRunSize<<ML_BITS);\r\n}\r\nmemcpy(op, anchor, lastRunSize);\r\nop += lastRunSize;\r\n}\r\n*srcSizePtr = (int) (((const char *)ip) - src);\r\nreturn (int) (((char *)op) - dst);\r\n}\r\nstatic int LZ4_compress_destSize_extState(\r\nLZ4_stream_t *state,\r\nconst char *src,\r\nchar *dst,\r\nint *srcSizePtr,\r\nint targetDstSize)\r\n{\r\n#if LZ4_ARCH64\r\nconst tableType_t tableType = byU32;\r\n#else\r\nconst tableType_t tableType = byPtr;\r\n#endif\r\nLZ4_resetStream(state);\r\nif (targetDstSize >= LZ4_COMPRESSBOUND(*srcSizePtr)) {\r\nreturn LZ4_compress_fast_extState(\r\nstate, src, dst, *srcSizePtr,\r\ntargetDstSize, 1);\r\n} else {\r\nif (*srcSizePtr < LZ4_64Klimit)\r\nreturn LZ4_compress_destSize_generic(\r\n&state->internal_donotuse,\r\nsrc, dst, srcSizePtr,\r\ntargetDstSize, byU16);\r\nelse\r\nreturn LZ4_compress_destSize_generic(\r\n&state->internal_donotuse,\r\nsrc, dst, srcSizePtr,\r\ntargetDstSize, tableType);\r\n}\r\n}\r\nint LZ4_compress_destSize(\r\nconst char *src,\r\nchar *dst,\r\nint *srcSizePtr,\r\nint targetDstSize,\r\nvoid *wrkmem)\r\n{\r\nreturn LZ4_compress_destSize_extState(wrkmem, src, dst, srcSizePtr,\r\ntargetDstSize);\r\n}\r\nvoid LZ4_resetStream(LZ4_stream_t *LZ4_stream)\r\n{\r\nmemset(LZ4_stream, 0, sizeof(LZ4_stream_t));\r\n}\r\nint LZ4_loadDict(LZ4_stream_t *LZ4_dict,\r\nconst char *dictionary, int dictSize)\r\n{\r\nLZ4_stream_t_internal *dict = &LZ4_dict->internal_donotuse;\r\nconst BYTE *p = (const BYTE *)dictionary;\r\nconst BYTE * const dictEnd = p + dictSize;\r\nconst BYTE *base;\r\nif ((dict->initCheck)\r\n|| (dict->currentOffset > 1 * GB)) {\r\nLZ4_resetStream(LZ4_dict);\r\n}\r\nif (dictSize < (int)HASH_UNIT) {\r\ndict->dictionary = NULL;\r\ndict->dictSize = 0;\r\nreturn 0;\r\n}\r\nif ((dictEnd - p) > 64 * KB)\r\np = dictEnd - 64 * KB;\r\ndict->currentOffset += 64 * KB;\r\nbase = p - dict->currentOffset;\r\ndict->dictionary = p;\r\ndict->dictSize = (U32)(dictEnd - p);\r\ndict->currentOffset += dict->dictSize;\r\nwhile (p <= dictEnd - HASH_UNIT) {\r\nLZ4_putPosition(p, dict->hashTable, byU32, base);\r\np += 3;\r\n}\r\nreturn dict->dictSize;\r\n}\r\nstatic void LZ4_renormDictT(LZ4_stream_t_internal *LZ4_dict,\r\nconst BYTE *src)\r\n{\r\nif ((LZ4_dict->currentOffset > 0x80000000) ||\r\n((uptrval)LZ4_dict->currentOffset > (uptrval)src)) {\r\nU32 const delta = LZ4_dict->currentOffset - 64 * KB;\r\nconst BYTE *dictEnd = LZ4_dict->dictionary + LZ4_dict->dictSize;\r\nint i;\r\nfor (i = 0; i < LZ4_HASH_SIZE_U32; i++) {\r\nif (LZ4_dict->hashTable[i] < delta)\r\nLZ4_dict->hashTable[i] = 0;\r\nelse\r\nLZ4_dict->hashTable[i] -= delta;\r\n}\r\nLZ4_dict->currentOffset = 64 * KB;\r\nif (LZ4_dict->dictSize > 64 * KB)\r\nLZ4_dict->dictSize = 64 * KB;\r\nLZ4_dict->dictionary = dictEnd - LZ4_dict->dictSize;\r\n}\r\n}\r\nint LZ4_saveDict(LZ4_stream_t *LZ4_dict, char *safeBuffer, int dictSize)\r\n{\r\nLZ4_stream_t_internal * const dict = &LZ4_dict->internal_donotuse;\r\nconst BYTE * const previousDictEnd = dict->dictionary + dict->dictSize;\r\nif ((U32)dictSize > 64 * KB) {\r\ndictSize = 64 * KB;\r\n}\r\nif ((U32)dictSize > dict->dictSize)\r\ndictSize = dict->dictSize;\r\nmemmove(safeBuffer, previousDictEnd - dictSize, dictSize);\r\ndict->dictionary = (const BYTE *)safeBuffer;\r\ndict->dictSize = (U32)dictSize;\r\nreturn dictSize;\r\n}\r\nint LZ4_compress_fast_continue(LZ4_stream_t *LZ4_stream, const char *source,\r\nchar *dest, int inputSize, int maxOutputSize, int acceleration)\r\n{\r\nLZ4_stream_t_internal *streamPtr = &LZ4_stream->internal_donotuse;\r\nconst BYTE * const dictEnd = streamPtr->dictionary\r\n+ streamPtr->dictSize;\r\nconst BYTE *smallest = (const BYTE *) source;\r\nif (streamPtr->initCheck) {\r\nreturn 0;\r\n}\r\nif ((streamPtr->dictSize > 0) && (smallest > dictEnd))\r\nsmallest = dictEnd;\r\nLZ4_renormDictT(streamPtr, smallest);\r\nif (acceleration < 1)\r\nacceleration = LZ4_ACCELERATION_DEFAULT;\r\n{\r\nconst BYTE *sourceEnd = (const BYTE *) source + inputSize;\r\nif ((sourceEnd > streamPtr->dictionary)\r\n&& (sourceEnd < dictEnd)) {\r\nstreamPtr->dictSize = (U32)(dictEnd - sourceEnd);\r\nif (streamPtr->dictSize > 64 * KB)\r\nstreamPtr->dictSize = 64 * KB;\r\nif (streamPtr->dictSize < 4)\r\nstreamPtr->dictSize = 0;\r\nstreamPtr->dictionary = dictEnd - streamPtr->dictSize;\r\n}\r\n}\r\nif (dictEnd == (const BYTE *)source) {\r\nint result;\r\nif ((streamPtr->dictSize < 64 * KB) &&\r\n(streamPtr->dictSize < streamPtr->currentOffset)) {\r\nresult = LZ4_compress_generic(\r\nstreamPtr, source, dest, inputSize,\r\nmaxOutputSize, limitedOutput, byU32,\r\nwithPrefix64k, dictSmall, acceleration);\r\n} else {\r\nresult = LZ4_compress_generic(\r\nstreamPtr, source, dest, inputSize,\r\nmaxOutputSize, limitedOutput, byU32,\r\nwithPrefix64k, noDictIssue, acceleration);\r\n}\r\nstreamPtr->dictSize += (U32)inputSize;\r\nstreamPtr->currentOffset += (U32)inputSize;\r\nreturn result;\r\n}\r\n{\r\nint result;\r\nif ((streamPtr->dictSize < 64 * KB) &&\r\n(streamPtr->dictSize < streamPtr->currentOffset)) {\r\nresult = LZ4_compress_generic(\r\nstreamPtr, source, dest, inputSize,\r\nmaxOutputSize, limitedOutput, byU32,\r\nusingExtDict, dictSmall, acceleration);\r\n} else {\r\nresult = LZ4_compress_generic(\r\nstreamPtr, source, dest, inputSize,\r\nmaxOutputSize, limitedOutput, byU32,\r\nusingExtDict, noDictIssue, acceleration);\r\n}\r\nstreamPtr->dictionary = (const BYTE *)source;\r\nstreamPtr->dictSize = (U32)inputSize;\r\nstreamPtr->currentOffset += (U32)inputSize;\r\nreturn result;\r\n}\r\n}
