static inline u32 request_hash(u32 xid)\r\n{\r\nu32 h = xid;\r\nh ^= (xid >> 24);\r\nreturn h & (HASHSIZE-1);\r\n}\r\nint nfsd_reply_cache_init(void)\r\n{\r\nstruct svc_cacherep *rp;\r\nint i;\r\nINIT_LIST_HEAD(&lru_head);\r\ni = CACHESIZE;\r\nwhile (i) {\r\nrp = kmalloc(sizeof(*rp), GFP_KERNEL);\r\nif (!rp)\r\ngoto out_nomem;\r\nlist_add(&rp->c_lru, &lru_head);\r\nrp->c_state = RC_UNUSED;\r\nrp->c_type = RC_NOCACHE;\r\nINIT_HLIST_NODE(&rp->c_hash);\r\ni--;\r\n}\r\ncache_hash = kcalloc (HASHSIZE, sizeof(struct hlist_head), GFP_KERNEL);\r\nif (!cache_hash)\r\ngoto out_nomem;\r\ncache_disabled = 0;\r\nreturn 0;\r\nout_nomem:\r\nprintk(KERN_ERR "nfsd: failed to allocate reply cache\n");\r\nnfsd_reply_cache_shutdown();\r\nreturn -ENOMEM;\r\n}\r\nvoid nfsd_reply_cache_shutdown(void)\r\n{\r\nstruct svc_cacherep *rp;\r\nwhile (!list_empty(&lru_head)) {\r\nrp = list_entry(lru_head.next, struct svc_cacherep, c_lru);\r\nif (rp->c_state == RC_DONE && rp->c_type == RC_REPLBUFF)\r\nkfree(rp->c_replvec.iov_base);\r\nlist_del(&rp->c_lru);\r\nkfree(rp);\r\n}\r\ncache_disabled = 1;\r\nkfree (cache_hash);\r\ncache_hash = NULL;\r\n}\r\nstatic void\r\nlru_put_end(struct svc_cacherep *rp)\r\n{\r\nlist_move_tail(&rp->c_lru, &lru_head);\r\n}\r\nstatic void\r\nhash_refile(struct svc_cacherep *rp)\r\n{\r\nhlist_del_init(&rp->c_hash);\r\nhlist_add_head(&rp->c_hash, cache_hash + request_hash(rp->c_xid));\r\n}\r\nint\r\nnfsd_cache_lookup(struct svc_rqst *rqstp)\r\n{\r\nstruct hlist_node *hn;\r\nstruct hlist_head *rh;\r\nstruct svc_cacherep *rp;\r\n__be32 xid = rqstp->rq_xid;\r\nu32 proto = rqstp->rq_prot,\r\nvers = rqstp->rq_vers,\r\nproc = rqstp->rq_proc;\r\nunsigned long age;\r\nint type = rqstp->rq_cachetype;\r\nint rtn;\r\nrqstp->rq_cacherep = NULL;\r\nif (cache_disabled || type == RC_NOCACHE) {\r\nnfsdstats.rcnocache++;\r\nreturn RC_DOIT;\r\n}\r\nspin_lock(&cache_lock);\r\nrtn = RC_DOIT;\r\nrh = &cache_hash[request_hash(xid)];\r\nhlist_for_each_entry(rp, hn, rh, c_hash) {\r\nif (rp->c_state != RC_UNUSED &&\r\nxid == rp->c_xid && proc == rp->c_proc &&\r\nproto == rp->c_prot && vers == rp->c_vers &&\r\ntime_before(jiffies, rp->c_timestamp + 120*HZ) &&\r\nmemcmp((char*)&rqstp->rq_addr, (char*)&rp->c_addr, sizeof(rp->c_addr))==0) {\r\nnfsdstats.rchits++;\r\ngoto found_entry;\r\n}\r\n}\r\nnfsdstats.rcmisses++;\r\n{\r\nint safe = 0;\r\nlist_for_each_entry(rp, &lru_head, c_lru) {\r\nif (rp->c_state != RC_INPROG)\r\nbreak;\r\nif (safe++ > CACHESIZE) {\r\nprintk("nfsd: loop in repcache LRU list\n");\r\ncache_disabled = 1;\r\ngoto out;\r\n}\r\n}\r\n}\r\nif (&rp->c_lru == &lru_head) {\r\nstatic int complaints;\r\nprintk(KERN_WARNING "nfsd: all repcache entries locked!\n");\r\nif (++complaints > 5) {\r\nprintk(KERN_WARNING "nfsd: disabling repcache.\n");\r\ncache_disabled = 1;\r\n}\r\ngoto out;\r\n}\r\nrqstp->rq_cacherep = rp;\r\nrp->c_state = RC_INPROG;\r\nrp->c_xid = xid;\r\nrp->c_proc = proc;\r\nmemcpy(&rp->c_addr, svc_addr_in(rqstp), sizeof(rp->c_addr));\r\nrp->c_prot = proto;\r\nrp->c_vers = vers;\r\nrp->c_timestamp = jiffies;\r\nhash_refile(rp);\r\nif (rp->c_type == RC_REPLBUFF) {\r\nkfree(rp->c_replvec.iov_base);\r\nrp->c_replvec.iov_base = NULL;\r\n}\r\nrp->c_type = RC_NOCACHE;\r\nout:\r\nspin_unlock(&cache_lock);\r\nreturn rtn;\r\nfound_entry:\r\nage = jiffies - rp->c_timestamp;\r\nrp->c_timestamp = jiffies;\r\nlru_put_end(rp);\r\nrtn = RC_DROPIT;\r\nif (rp->c_state == RC_INPROG || age < RC_DELAY)\r\ngoto out;\r\nrtn = RC_DOIT;\r\nif (!rqstp->rq_secure && rp->c_secure)\r\ngoto out;\r\nswitch (rp->c_type) {\r\ncase RC_NOCACHE:\r\nbreak;\r\ncase RC_REPLSTAT:\r\nsvc_putu32(&rqstp->rq_res.head[0], rp->c_replstat);\r\nrtn = RC_REPLY;\r\nbreak;\r\ncase RC_REPLBUFF:\r\nif (!nfsd_cache_append(rqstp, &rp->c_replvec))\r\ngoto out;\r\nrtn = RC_REPLY;\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING "nfsd: bad repcache type %d\n", rp->c_type);\r\nrp->c_state = RC_UNUSED;\r\n}\r\ngoto out;\r\n}\r\nvoid\r\nnfsd_cache_update(struct svc_rqst *rqstp, int cachetype, __be32 *statp)\r\n{\r\nstruct svc_cacherep *rp;\r\nstruct kvec *resv = &rqstp->rq_res.head[0], *cachv;\r\nint len;\r\nif (!(rp = rqstp->rq_cacherep) || cache_disabled)\r\nreturn;\r\nlen = resv->iov_len - ((char*)statp - (char*)resv->iov_base);\r\nlen >>= 2;\r\nif (!statp || len > (256 >> 2)) {\r\nrp->c_state = RC_UNUSED;\r\nreturn;\r\n}\r\nswitch (cachetype) {\r\ncase RC_REPLSTAT:\r\nif (len != 1)\r\nprintk("nfsd: RC_REPLSTAT/reply len %d!\n",len);\r\nrp->c_replstat = *statp;\r\nbreak;\r\ncase RC_REPLBUFF:\r\ncachv = &rp->c_replvec;\r\ncachv->iov_base = kmalloc(len << 2, GFP_KERNEL);\r\nif (!cachv->iov_base) {\r\nspin_lock(&cache_lock);\r\nrp->c_state = RC_UNUSED;\r\nspin_unlock(&cache_lock);\r\nreturn;\r\n}\r\ncachv->iov_len = len << 2;\r\nmemcpy(cachv->iov_base, statp, len << 2);\r\nbreak;\r\n}\r\nspin_lock(&cache_lock);\r\nlru_put_end(rp);\r\nrp->c_secure = rqstp->rq_secure;\r\nrp->c_type = cachetype;\r\nrp->c_state = RC_DONE;\r\nrp->c_timestamp = jiffies;\r\nspin_unlock(&cache_lock);\r\nreturn;\r\n}\r\nstatic int\r\nnfsd_cache_append(struct svc_rqst *rqstp, struct kvec *data)\r\n{\r\nstruct kvec *vec = &rqstp->rq_res.head[0];\r\nif (vec->iov_len + data->iov_len > PAGE_SIZE) {\r\nprintk(KERN_WARNING "nfsd: cached reply too large (%Zd).\n",\r\ndata->iov_len);\r\nreturn 0;\r\n}\r\nmemcpy((char*)vec->iov_base + vec->iov_len, data->iov_base, data->iov_len);\r\nvec->iov_len += data->iov_len;\r\nreturn 1;\r\n}
