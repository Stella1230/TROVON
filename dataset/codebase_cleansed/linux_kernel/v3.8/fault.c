static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)\r\n{\r\nint ret = 0;\r\nif (!user_mode(regs)) {\r\npreempt_disable();\r\nif (kprobe_running() && kprobe_fault_handler(regs, fsr))\r\nret = 1;\r\npreempt_enable();\r\n}\r\nreturn ret;\r\n}\r\nstatic inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr)\r\n{\r\nreturn 0;\r\n}\r\nvoid show_pte(struct mm_struct *mm, unsigned long addr)\r\n{\r\npgd_t *pgd;\r\nif (!mm)\r\nmm = &init_mm;\r\nprintk(KERN_ALERT "pgd = %p\n", mm->pgd);\r\npgd = pgd_offset(mm, addr);\r\nprintk(KERN_ALERT "[%08lx] *pgd=%08llx",\r\naddr, (long long)pgd_val(*pgd));\r\ndo {\r\npud_t *pud;\r\npmd_t *pmd;\r\npte_t *pte;\r\nif (pgd_none(*pgd))\r\nbreak;\r\nif (pgd_bad(*pgd)) {\r\nprintk("(bad)");\r\nbreak;\r\n}\r\npud = pud_offset(pgd, addr);\r\nif (PTRS_PER_PUD != 1)\r\nprintk(", *pud=%08llx", (long long)pud_val(*pud));\r\nif (pud_none(*pud))\r\nbreak;\r\nif (pud_bad(*pud)) {\r\nprintk("(bad)");\r\nbreak;\r\n}\r\npmd = pmd_offset(pud, addr);\r\nif (PTRS_PER_PMD != 1)\r\nprintk(", *pmd=%08llx", (long long)pmd_val(*pmd));\r\nif (pmd_none(*pmd))\r\nbreak;\r\nif (pmd_bad(*pmd)) {\r\nprintk("(bad)");\r\nbreak;\r\n}\r\nif (PageHighMem(pfn_to_page(pmd_val(*pmd) >> PAGE_SHIFT)))\r\nbreak;\r\npte = pte_offset_map(pmd, addr);\r\nprintk(", *pte=%08llx", (long long)pte_val(*pte));\r\n#ifndef CONFIG_ARM_LPAE\r\nprintk(", *ppte=%08llx",\r\n(long long)pte_val(pte[PTE_HWTABLE_PTRS]));\r\n#endif\r\npte_unmap(pte);\r\n} while(0);\r\nprintk("\n");\r\n}\r\nvoid show_pte(struct mm_struct *mm, unsigned long addr)\r\n{ }\r\nstatic void\r\n__do_kernel_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,\r\nstruct pt_regs *regs)\r\n{\r\nif (fixup_exception(regs))\r\nreturn;\r\nbust_spinlocks(1);\r\nprintk(KERN_ALERT\r\n"Unable to handle kernel %s at virtual address %08lx\n",\r\n(addr < PAGE_SIZE) ? "NULL pointer dereference" :\r\n"paging request", addr);\r\nshow_pte(mm, addr);\r\ndie("Oops", regs, fsr);\r\nbust_spinlocks(0);\r\ndo_exit(SIGKILL);\r\n}\r\nstatic void\r\n__do_user_fault(struct task_struct *tsk, unsigned long addr,\r\nunsigned int fsr, unsigned int sig, int code,\r\nstruct pt_regs *regs)\r\n{\r\nstruct siginfo si;\r\n#ifdef CONFIG_DEBUG_USER\r\nif (((user_debug & UDBG_SEGV) && (sig == SIGSEGV)) ||\r\n((user_debug & UDBG_BUS) && (sig == SIGBUS))) {\r\nprintk(KERN_DEBUG "%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",\r\ntsk->comm, sig, addr, fsr);\r\nshow_pte(tsk->mm, addr);\r\nshow_regs(regs);\r\n}\r\n#endif\r\ntsk->thread.address = addr;\r\ntsk->thread.error_code = fsr;\r\ntsk->thread.trap_no = 14;\r\nsi.si_signo = sig;\r\nsi.si_errno = 0;\r\nsi.si_code = code;\r\nsi.si_addr = (void __user *)addr;\r\nforce_sig_info(sig, &si, tsk);\r\n}\r\nvoid do_bad_area(unsigned long addr, unsigned int fsr, struct pt_regs *regs)\r\n{\r\nstruct task_struct *tsk = current;\r\nstruct mm_struct *mm = tsk->active_mm;\r\nif (user_mode(regs))\r\n__do_user_fault(tsk, addr, fsr, SIGSEGV, SEGV_MAPERR, regs);\r\nelse\r\n__do_kernel_fault(mm, addr, fsr, regs);\r\n}\r\nstatic inline bool access_error(unsigned int fsr, struct vm_area_struct *vma)\r\n{\r\nunsigned int mask = VM_READ | VM_WRITE | VM_EXEC;\r\nif (fsr & FSR_WRITE)\r\nmask = VM_WRITE;\r\nif (fsr & FSR_LNX_PF)\r\nmask = VM_EXEC;\r\nreturn vma->vm_flags & mask ? false : true;\r\n}\r\nstatic int __kprobes\r\n__do_page_fault(struct mm_struct *mm, unsigned long addr, unsigned int fsr,\r\nunsigned int flags, struct task_struct *tsk)\r\n{\r\nstruct vm_area_struct *vma;\r\nint fault;\r\nvma = find_vma(mm, addr);\r\nfault = VM_FAULT_BADMAP;\r\nif (unlikely(!vma))\r\ngoto out;\r\nif (unlikely(vma->vm_start > addr))\r\ngoto check_stack;\r\ngood_area:\r\nif (access_error(fsr, vma)) {\r\nfault = VM_FAULT_BADACCESS;\r\ngoto out;\r\n}\r\nreturn handle_mm_fault(mm, vma, addr & PAGE_MASK, flags);\r\ncheck_stack:\r\nif (vma->vm_flags & VM_GROWSDOWN &&\r\naddr >= FIRST_USER_ADDRESS && !expand_stack(vma, addr))\r\ngoto good_area;\r\nout:\r\nreturn fault;\r\n}\r\nstatic int __kprobes\r\ndo_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)\r\n{\r\nstruct task_struct *tsk;\r\nstruct mm_struct *mm;\r\nint fault, sig, code;\r\nint write = fsr & FSR_WRITE;\r\nunsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE |\r\n(write ? FAULT_FLAG_WRITE : 0);\r\nif (notify_page_fault(regs, fsr))\r\nreturn 0;\r\ntsk = current;\r\nmm = tsk->mm;\r\nif (interrupts_enabled(regs))\r\nlocal_irq_enable();\r\nif (in_atomic() || !mm)\r\ngoto no_context;\r\nif (!down_read_trylock(&mm->mmap_sem)) {\r\nif (!user_mode(regs) && !search_exception_tables(regs->ARM_pc))\r\ngoto no_context;\r\nretry:\r\ndown_read(&mm->mmap_sem);\r\n} else {\r\nmight_sleep();\r\n#ifdef CONFIG_DEBUG_VM\r\nif (!user_mode(regs) &&\r\n!search_exception_tables(regs->ARM_pc))\r\ngoto no_context;\r\n#endif\r\n}\r\nfault = __do_page_fault(mm, addr, fsr, flags, tsk);\r\nif ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))\r\nreturn 0;\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);\r\nif (!(fault & VM_FAULT_ERROR) && flags & FAULT_FLAG_ALLOW_RETRY) {\r\nif (fault & VM_FAULT_MAJOR) {\r\ntsk->maj_flt++;\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1,\r\nregs, addr);\r\n} else {\r\ntsk->min_flt++;\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1,\r\nregs, addr);\r\n}\r\nif (fault & VM_FAULT_RETRY) {\r\nflags &= ~FAULT_FLAG_ALLOW_RETRY;\r\nflags |= FAULT_FLAG_TRIED;\r\ngoto retry;\r\n}\r\n}\r\nup_read(&mm->mmap_sem);\r\nif (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP | VM_FAULT_BADACCESS))))\r\nreturn 0;\r\nif (fault & VM_FAULT_OOM) {\r\npagefault_out_of_memory();\r\nreturn 0;\r\n}\r\nif (!user_mode(regs))\r\ngoto no_context;\r\nif (fault & VM_FAULT_SIGBUS) {\r\nsig = SIGBUS;\r\ncode = BUS_ADRERR;\r\n} else {\r\nsig = SIGSEGV;\r\ncode = fault == VM_FAULT_BADACCESS ?\r\nSEGV_ACCERR : SEGV_MAPERR;\r\n}\r\n__do_user_fault(tsk, addr, fsr, sig, code, regs);\r\nreturn 0;\r\nno_context:\r\n__do_kernel_fault(mm, addr, fsr, regs);\r\nreturn 0;\r\n}\r\nstatic int\r\ndo_page_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)\r\n{\r\nreturn 0;\r\n}\r\nstatic int __kprobes\r\ndo_translation_fault(unsigned long addr, unsigned int fsr,\r\nstruct pt_regs *regs)\r\n{\r\nunsigned int index;\r\npgd_t *pgd, *pgd_k;\r\npud_t *pud, *pud_k;\r\npmd_t *pmd, *pmd_k;\r\nif (addr < TASK_SIZE)\r\nreturn do_page_fault(addr, fsr, regs);\r\nif (user_mode(regs))\r\ngoto bad_area;\r\nindex = pgd_index(addr);\r\npgd = cpu_get_pgd() + index;\r\npgd_k = init_mm.pgd + index;\r\nif (pgd_none(*pgd_k))\r\ngoto bad_area;\r\nif (!pgd_present(*pgd))\r\nset_pgd(pgd, *pgd_k);\r\npud = pud_offset(pgd, addr);\r\npud_k = pud_offset(pgd_k, addr);\r\nif (pud_none(*pud_k))\r\ngoto bad_area;\r\nif (!pud_present(*pud))\r\nset_pud(pud, *pud_k);\r\npmd = pmd_offset(pud, addr);\r\npmd_k = pmd_offset(pud_k, addr);\r\n#ifdef CONFIG_ARM_LPAE\r\nindex = 0;\r\n#else\r\nindex = (addr >> SECTION_SHIFT) & 1;\r\n#endif\r\nif (pmd_none(pmd_k[index]))\r\ngoto bad_area;\r\ncopy_pmd(pmd, pmd_k);\r\nreturn 0;\r\nbad_area:\r\ndo_bad_area(addr, fsr, regs);\r\nreturn 0;\r\n}\r\nstatic int\r\ndo_translation_fault(unsigned long addr, unsigned int fsr,\r\nstruct pt_regs *regs)\r\n{\r\nreturn 0;\r\n}\r\nstatic int\r\ndo_sect_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)\r\n{\r\ndo_bad_area(addr, fsr, regs);\r\nreturn 0;\r\n}\r\nstatic int\r\ndo_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs)\r\n{\r\nreturn 1;\r\n}\r\nvoid __init\r\nhook_fault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),\r\nint sig, int code, const char *name)\r\n{\r\nif (nr < 0 || nr >= ARRAY_SIZE(fsr_info))\r\nBUG();\r\nfsr_info[nr].fn = fn;\r\nfsr_info[nr].sig = sig;\r\nfsr_info[nr].code = code;\r\nfsr_info[nr].name = name;\r\n}\r\nasmlinkage void __exception\r\ndo_DataAbort(unsigned long addr, unsigned int fsr, struct pt_regs *regs)\r\n{\r\nconst struct fsr_info *inf = fsr_info + fsr_fs(fsr);\r\nstruct siginfo info;\r\nif (!inf->fn(addr, fsr & ~FSR_LNX_PF, regs))\r\nreturn;\r\nprintk(KERN_ALERT "Unhandled fault: %s (0x%03x) at 0x%08lx\n",\r\ninf->name, fsr, addr);\r\ninfo.si_signo = inf->sig;\r\ninfo.si_errno = 0;\r\ninfo.si_code = inf->code;\r\ninfo.si_addr = (void __user *)addr;\r\narm_notify_die("", regs, &info, fsr, 0);\r\n}\r\nvoid __init\r\nhook_ifault_code(int nr, int (*fn)(unsigned long, unsigned int, struct pt_regs *),\r\nint sig, int code, const char *name)\r\n{\r\nif (nr < 0 || nr >= ARRAY_SIZE(ifsr_info))\r\nBUG();\r\nifsr_info[nr].fn = fn;\r\nifsr_info[nr].sig = sig;\r\nifsr_info[nr].code = code;\r\nifsr_info[nr].name = name;\r\n}\r\nasmlinkage void __exception\r\ndo_PrefetchAbort(unsigned long addr, unsigned int ifsr, struct pt_regs *regs)\r\n{\r\nconst struct fsr_info *inf = ifsr_info + fsr_fs(ifsr);\r\nstruct siginfo info;\r\nif (!inf->fn(addr, ifsr | FSR_LNX_PF, regs))\r\nreturn;\r\nprintk(KERN_ALERT "Unhandled prefetch abort: %s (0x%03x) at 0x%08lx\n",\r\ninf->name, ifsr, addr);\r\ninfo.si_signo = inf->sig;\r\ninfo.si_errno = 0;\r\ninfo.si_code = inf->code;\r\ninfo.si_addr = (void __user *)addr;\r\narm_notify_die("", regs, &info, ifsr, 0);\r\n}\r\nstatic int __init exceptions_init(void)\r\n{\r\nif (cpu_architecture() >= CPU_ARCH_ARMv6) {\r\nhook_fault_code(4, do_translation_fault, SIGSEGV, SEGV_MAPERR,\r\n"I-cache maintenance fault");\r\n}\r\nif (cpu_architecture() >= CPU_ARCH_ARMv7) {\r\nhook_fault_code(3, do_bad, SIGSEGV, SEGV_MAPERR,\r\n"section access flag fault");\r\nhook_fault_code(6, do_bad, SIGSEGV, SEGV_MAPERR,\r\n"section access flag fault");\r\n}\r\nreturn 0;\r\n}
