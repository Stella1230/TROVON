int ipoib_open(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_dbg(priv, "bringing up interface\n");\r\nset_bit(IPOIB_FLAG_ADMIN_UP, &priv->flags);\r\nif (ipoib_pkey_dev_delay_open(dev))\r\nreturn 0;\r\nif (ipoib_ib_dev_open(dev))\r\ngoto err_disable;\r\nif (ipoib_ib_dev_up(dev))\r\ngoto err_stop;\r\nif (!test_bit(IPOIB_FLAG_SUBINTERFACE, &priv->flags)) {\r\nstruct ipoib_dev_priv *cpriv;\r\nmutex_lock(&priv->vlan_mutex);\r\nlist_for_each_entry(cpriv, &priv->child_intfs, list) {\r\nint flags;\r\nflags = cpriv->dev->flags;\r\nif (flags & IFF_UP)\r\ncontinue;\r\ndev_change_flags(cpriv->dev, flags | IFF_UP);\r\n}\r\nmutex_unlock(&priv->vlan_mutex);\r\n}\r\nnetif_start_queue(dev);\r\nreturn 0;\r\nerr_stop:\r\nipoib_ib_dev_stop(dev, 1);\r\nerr_disable:\r\nclear_bit(IPOIB_FLAG_ADMIN_UP, &priv->flags);\r\nreturn -EINVAL;\r\n}\r\nstatic int ipoib_stop(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_dbg(priv, "stopping interface\n");\r\nclear_bit(IPOIB_FLAG_ADMIN_UP, &priv->flags);\r\nnetif_stop_queue(dev);\r\nipoib_ib_dev_down(dev, 1);\r\nipoib_ib_dev_stop(dev, 0);\r\nif (!test_bit(IPOIB_FLAG_SUBINTERFACE, &priv->flags)) {\r\nstruct ipoib_dev_priv *cpriv;\r\nmutex_lock(&priv->vlan_mutex);\r\nlist_for_each_entry(cpriv, &priv->child_intfs, list) {\r\nint flags;\r\nflags = cpriv->dev->flags;\r\nif (!(flags & IFF_UP))\r\ncontinue;\r\ndev_change_flags(cpriv->dev, flags & ~IFF_UP);\r\n}\r\nmutex_unlock(&priv->vlan_mutex);\r\n}\r\nreturn 0;\r\n}\r\nstatic void ipoib_uninit(struct net_device *dev)\r\n{\r\nipoib_dev_cleanup(dev);\r\n}\r\nstatic netdev_features_t ipoib_fix_features(struct net_device *dev, netdev_features_t features)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (test_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags))\r\nfeatures &= ~(NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_TSO);\r\nreturn features;\r\n}\r\nstatic int ipoib_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (ipoib_cm_admin_enabled(dev)) {\r\nif (new_mtu > ipoib_cm_max_mtu(dev))\r\nreturn -EINVAL;\r\nif (new_mtu > priv->mcast_mtu)\r\nipoib_warn(priv, "mtu > %d will cause multicast packet drops.\n",\r\npriv->mcast_mtu);\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nif (new_mtu > IPOIB_UD_MTU(priv->max_ib_mtu))\r\nreturn -EINVAL;\r\npriv->admin_mtu = new_mtu;\r\ndev->mtu = min(priv->mcast_mtu, priv->admin_mtu);\r\nreturn 0;\r\n}\r\nint ipoib_set_mode(struct net_device *dev, const char *buf)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (IPOIB_CM_SUPPORTED(dev->dev_addr) && !strcmp(buf, "connected\n")) {\r\nset_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);\r\nipoib_warn(priv, "enabling connected mode "\r\n"will cause multicast packet drops\n");\r\nnetdev_update_features(dev);\r\nrtnl_unlock();\r\npriv->tx_wr.send_flags &= ~IB_SEND_IP_CSUM;\r\nipoib_flush_paths(dev);\r\nrtnl_lock();\r\nreturn 0;\r\n}\r\nif (!strcmp(buf, "datagram\n")) {\r\nclear_bit(IPOIB_FLAG_ADMIN_CM, &priv->flags);\r\nnetdev_update_features(dev);\r\ndev_set_mtu(dev, min(priv->mcast_mtu, dev->mtu));\r\nrtnl_unlock();\r\nipoib_flush_paths(dev);\r\nrtnl_lock();\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic struct ipoib_path *__path_find(struct net_device *dev, void *gid)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct rb_node *n = priv->path_tree.rb_node;\r\nstruct ipoib_path *path;\r\nint ret;\r\nwhile (n) {\r\npath = rb_entry(n, struct ipoib_path, rb_node);\r\nret = memcmp(gid, path->pathrec.dgid.raw,\r\nsizeof (union ib_gid));\r\nif (ret < 0)\r\nn = n->rb_left;\r\nelse if (ret > 0)\r\nn = n->rb_right;\r\nelse\r\nreturn path;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int __path_add(struct net_device *dev, struct ipoib_path *path)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct rb_node **n = &priv->path_tree.rb_node;\r\nstruct rb_node *pn = NULL;\r\nstruct ipoib_path *tpath;\r\nint ret;\r\nwhile (*n) {\r\npn = *n;\r\ntpath = rb_entry(pn, struct ipoib_path, rb_node);\r\nret = memcmp(path->pathrec.dgid.raw, tpath->pathrec.dgid.raw,\r\nsizeof (union ib_gid));\r\nif (ret < 0)\r\nn = &pn->rb_left;\r\nelse if (ret > 0)\r\nn = &pn->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&path->rb_node, pn, n);\r\nrb_insert_color(&path->rb_node, &priv->path_tree);\r\nlist_add_tail(&path->list, &priv->path_list);\r\nreturn 0;\r\n}\r\nstatic void path_free(struct net_device *dev, struct ipoib_path *path)\r\n{\r\nstruct sk_buff *skb;\r\nwhile ((skb = __skb_dequeue(&path->queue)))\r\ndev_kfree_skb_irq(skb);\r\nipoib_dbg(netdev_priv(dev), "path_free\n");\r\nipoib_del_neighs_by_gid(dev, path->pathrec.dgid.raw);\r\nif (path->ah)\r\nipoib_put_ah(path->ah);\r\nkfree(path);\r\n}\r\nstruct ipoib_path_iter *ipoib_path_iter_init(struct net_device *dev)\r\n{\r\nstruct ipoib_path_iter *iter;\r\niter = kmalloc(sizeof *iter, GFP_KERNEL);\r\nif (!iter)\r\nreturn NULL;\r\niter->dev = dev;\r\nmemset(iter->path.pathrec.dgid.raw, 0, 16);\r\nif (ipoib_path_iter_next(iter)) {\r\nkfree(iter);\r\nreturn NULL;\r\n}\r\nreturn iter;\r\n}\r\nint ipoib_path_iter_next(struct ipoib_path_iter *iter)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(iter->dev);\r\nstruct rb_node *n;\r\nstruct ipoib_path *path;\r\nint ret = 1;\r\nspin_lock_irq(&priv->lock);\r\nn = rb_first(&priv->path_tree);\r\nwhile (n) {\r\npath = rb_entry(n, struct ipoib_path, rb_node);\r\nif (memcmp(iter->path.pathrec.dgid.raw, path->pathrec.dgid.raw,\r\nsizeof (union ib_gid)) < 0) {\r\niter->path = *path;\r\nret = 0;\r\nbreak;\r\n}\r\nn = rb_next(n);\r\n}\r\nspin_unlock_irq(&priv->lock);\r\nreturn ret;\r\n}\r\nvoid ipoib_path_iter_read(struct ipoib_path_iter *iter,\r\nstruct ipoib_path *path)\r\n{\r\n*path = iter->path;\r\n}\r\nvoid ipoib_mark_paths_invalid(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path, *tp;\r\nspin_lock_irq(&priv->lock);\r\nlist_for_each_entry_safe(path, tp, &priv->path_list, list) {\r\nipoib_dbg(priv, "mark path LID 0x%04x GID %pI6 invalid\n",\r\nbe16_to_cpu(path->pathrec.dlid),\r\npath->pathrec.dgid.raw);\r\npath->valid = 0;\r\n}\r\nspin_unlock_irq(&priv->lock);\r\n}\r\nvoid ipoib_flush_paths(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path, *tp;\r\nLIST_HEAD(remove_list);\r\nunsigned long flags;\r\nnetif_tx_lock_bh(dev);\r\nspin_lock_irqsave(&priv->lock, flags);\r\nlist_splice_init(&priv->path_list, &remove_list);\r\nlist_for_each_entry(path, &remove_list, list)\r\nrb_erase(&path->rb_node, &priv->path_tree);\r\nlist_for_each_entry_safe(path, tp, &remove_list, list) {\r\nif (path->query)\r\nib_sa_cancel_query(path->query_id, path->query);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nnetif_tx_unlock_bh(dev);\r\nwait_for_completion(&path->done);\r\npath_free(dev, path);\r\nnetif_tx_lock_bh(dev);\r\nspin_lock_irqsave(&priv->lock, flags);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nnetif_tx_unlock_bh(dev);\r\n}\r\nstatic void path_rec_completion(int status,\r\nstruct ib_sa_path_rec *pathrec,\r\nvoid *path_ptr)\r\n{\r\nstruct ipoib_path *path = path_ptr;\r\nstruct net_device *dev = path->dev;\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_ah *ah = NULL;\r\nstruct ipoib_ah *old_ah = NULL;\r\nstruct ipoib_neigh *neigh, *tn;\r\nstruct sk_buff_head skqueue;\r\nstruct sk_buff *skb;\r\nunsigned long flags;\r\nif (!status)\r\nipoib_dbg(priv, "PathRec LID 0x%04x for GID %pI6\n",\r\nbe16_to_cpu(pathrec->dlid), pathrec->dgid.raw);\r\nelse\r\nipoib_dbg(priv, "PathRec status %d for GID %pI6\n",\r\nstatus, path->pathrec.dgid.raw);\r\nskb_queue_head_init(&skqueue);\r\nif (!status) {\r\nstruct ib_ah_attr av;\r\nif (!ib_init_ah_from_path(priv->ca, priv->port, pathrec, &av))\r\nah = ipoib_create_ah(dev, priv->pd, &av);\r\n}\r\nspin_lock_irqsave(&priv->lock, flags);\r\nif (!IS_ERR_OR_NULL(ah)) {\r\npath->pathrec = *pathrec;\r\nold_ah = path->ah;\r\npath->ah = ah;\r\nipoib_dbg(priv, "created address handle %p for LID 0x%04x, SL %d\n",\r\nah, be16_to_cpu(pathrec->dlid), pathrec->sl);\r\nwhile ((skb = __skb_dequeue(&path->queue)))\r\n__skb_queue_tail(&skqueue, skb);\r\nlist_for_each_entry_safe(neigh, tn, &path->neigh_list, list) {\r\nif (neigh->ah) {\r\nWARN_ON(neigh->ah != old_ah);\r\nipoib_put_ah(neigh->ah);\r\n}\r\nkref_get(&path->ah->ref);\r\nneigh->ah = path->ah;\r\nif (ipoib_cm_enabled(dev, neigh->daddr)) {\r\nif (!ipoib_cm_get(neigh))\r\nipoib_cm_set(neigh, ipoib_cm_create_tx(dev,\r\npath,\r\nneigh));\r\nif (!ipoib_cm_get(neigh)) {\r\nlist_del(&neigh->list);\r\nipoib_neigh_free(neigh);\r\ncontinue;\r\n}\r\n}\r\nwhile ((skb = __skb_dequeue(&neigh->queue)))\r\n__skb_queue_tail(&skqueue, skb);\r\n}\r\npath->valid = 1;\r\n}\r\npath->query = NULL;\r\ncomplete(&path->done);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (old_ah)\r\nipoib_put_ah(old_ah);\r\nwhile ((skb = __skb_dequeue(&skqueue))) {\r\nskb->dev = dev;\r\nif (dev_queue_xmit(skb))\r\nipoib_warn(priv, "dev_queue_xmit failed "\r\n"to requeue packet\n");\r\n}\r\n}\r\nstatic struct ipoib_path *path_rec_create(struct net_device *dev, void *gid)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path;\r\nif (!priv->broadcast)\r\nreturn NULL;\r\npath = kzalloc(sizeof *path, GFP_ATOMIC);\r\nif (!path)\r\nreturn NULL;\r\npath->dev = dev;\r\nskb_queue_head_init(&path->queue);\r\nINIT_LIST_HEAD(&path->neigh_list);\r\nmemcpy(path->pathrec.dgid.raw, gid, sizeof (union ib_gid));\r\npath->pathrec.sgid = priv->local_gid;\r\npath->pathrec.pkey = cpu_to_be16(priv->pkey);\r\npath->pathrec.numb_path = 1;\r\npath->pathrec.traffic_class = priv->broadcast->mcmember.traffic_class;\r\nreturn path;\r\n}\r\nstatic int path_rec_start(struct net_device *dev,\r\nstruct ipoib_path *path)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_dbg(priv, "Start path record lookup for %pI6\n",\r\npath->pathrec.dgid.raw);\r\ninit_completion(&path->done);\r\npath->query_id =\r\nib_sa_path_rec_get(&ipoib_sa_client, priv->ca, priv->port,\r\n&path->pathrec,\r\nIB_SA_PATH_REC_DGID |\r\nIB_SA_PATH_REC_SGID |\r\nIB_SA_PATH_REC_NUMB_PATH |\r\nIB_SA_PATH_REC_TRAFFIC_CLASS |\r\nIB_SA_PATH_REC_PKEY,\r\n1000, GFP_ATOMIC,\r\npath_rec_completion,\r\npath, &path->query);\r\nif (path->query_id < 0) {\r\nipoib_warn(priv, "ib_sa_path_rec_get failed: %d\n", path->query_id);\r\npath->query = NULL;\r\ncomplete(&path->done);\r\nreturn path->query_id;\r\n}\r\nreturn 0;\r\n}\r\nstatic void neigh_add_path(struct sk_buff *skb, u8 *daddr,\r\nstruct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path;\r\nstruct ipoib_neigh *neigh;\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nneigh = ipoib_neigh_alloc(daddr, dev);\r\nif (!neigh) {\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\nreturn;\r\n}\r\npath = __path_find(dev, daddr + 4);\r\nif (!path) {\r\npath = path_rec_create(dev, daddr + 4);\r\nif (!path)\r\ngoto err_path;\r\n__path_add(dev, path);\r\n}\r\nlist_add_tail(&neigh->list, &path->neigh_list);\r\nif (path->ah) {\r\nkref_get(&path->ah->ref);\r\nneigh->ah = path->ah;\r\nif (ipoib_cm_enabled(dev, neigh->daddr)) {\r\nif (!ipoib_cm_get(neigh))\r\nipoib_cm_set(neigh, ipoib_cm_create_tx(dev, path, neigh));\r\nif (!ipoib_cm_get(neigh)) {\r\nlist_del(&neigh->list);\r\nipoib_neigh_free(neigh);\r\ngoto err_drop;\r\n}\r\nif (skb_queue_len(&neigh->queue) < IPOIB_MAX_PATH_REC_QUEUE)\r\n__skb_queue_tail(&neigh->queue, skb);\r\nelse {\r\nipoib_warn(priv, "queue length limit %d. Packet drop.\n",\r\nskb_queue_len(&neigh->queue));\r\ngoto err_drop;\r\n}\r\n} else {\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nipoib_send(dev, skb, path->ah, IPOIB_QPN(daddr));\r\nipoib_neigh_put(neigh);\r\nreturn;\r\n}\r\n} else {\r\nneigh->ah = NULL;\r\nif (!path->query && path_rec_start(dev, path))\r\ngoto err_list;\r\n__skb_queue_tail(&neigh->queue, skb);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nipoib_neigh_put(neigh);\r\nreturn;\r\nerr_list:\r\nlist_del(&neigh->list);\r\nerr_path:\r\nipoib_neigh_free(neigh);\r\nerr_drop:\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nipoib_neigh_put(neigh);\r\n}\r\nstatic void unicast_arp_send(struct sk_buff *skb, struct net_device *dev,\r\nstruct ipoib_cb *cb)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_path *path;\r\nunsigned long flags;\r\nspin_lock_irqsave(&priv->lock, flags);\r\npath = __path_find(dev, cb->hwaddr + 4);\r\nif (!path || !path->valid) {\r\nint new_path = 0;\r\nif (!path) {\r\npath = path_rec_create(dev, cb->hwaddr + 4);\r\nnew_path = 1;\r\n}\r\nif (path) {\r\n__skb_queue_tail(&path->queue, skb);\r\nif (!path->query && path_rec_start(dev, path)) {\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (new_path)\r\npath_free(dev, path);\r\nreturn;\r\n} else\r\n__path_add(dev, path);\r\n} else {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nreturn;\r\n}\r\nif (path->ah) {\r\nipoib_dbg(priv, "Send unicast ARP to %04x\n",\r\nbe16_to_cpu(path->pathrec.dlid));\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nipoib_send(dev, skb, path->ah, IPOIB_QPN(cb->hwaddr));\r\nreturn;\r\n} else if ((path->query || !path_rec_start(dev, path)) &&\r\nskb_queue_len(&path->queue) < IPOIB_MAX_PATH_REC_QUEUE) {\r\n__skb_queue_tail(&path->queue, skb);\r\n} else {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic int ipoib_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_neigh *neigh;\r\nstruct ipoib_cb *cb = (struct ipoib_cb *) skb->cb;\r\nstruct ipoib_header *header;\r\nunsigned long flags;\r\nheader = (struct ipoib_header *) skb->data;\r\nif (unlikely(cb->hwaddr[4] == 0xff)) {\r\nif ((header->proto != htons(ETH_P_IP)) &&\r\n(header->proto != htons(ETH_P_IPV6)) &&\r\n(header->proto != htons(ETH_P_ARP)) &&\r\n(header->proto != htons(ETH_P_RARP))) {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\ncb->hwaddr[8] = (priv->pkey >> 8) & 0xff;\r\ncb->hwaddr[9] = priv->pkey & 0xff;\r\nneigh = ipoib_neigh_get(dev, cb->hwaddr);\r\nif (likely(neigh))\r\ngoto send_using_neigh;\r\nipoib_mcast_send(dev, cb->hwaddr, skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nswitch (header->proto) {\r\ncase htons(ETH_P_IP):\r\ncase htons(ETH_P_IPV6):\r\nneigh = ipoib_neigh_get(dev, cb->hwaddr);\r\nif (unlikely(!neigh)) {\r\nneigh_add_path(skb, cb->hwaddr, dev);\r\nreturn NETDEV_TX_OK;\r\n}\r\nbreak;\r\ncase htons(ETH_P_ARP):\r\ncase htons(ETH_P_RARP):\r\nunicast_arp_send(skb, dev, cb);\r\nreturn NETDEV_TX_OK;\r\ndefault:\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nsend_using_neigh:\r\nif (ipoib_cm_get(neigh)) {\r\nif (ipoib_cm_up(neigh)) {\r\nipoib_cm_send(dev, skb, ipoib_cm_get(neigh));\r\ngoto unref;\r\n}\r\n} else if (neigh->ah) {\r\nipoib_send(dev, skb, neigh->ah, IPOIB_QPN(cb->hwaddr));\r\ngoto unref;\r\n}\r\nif (skb_queue_len(&neigh->queue) < IPOIB_MAX_PATH_REC_QUEUE) {\r\nspin_lock_irqsave(&priv->lock, flags);\r\n__skb_queue_tail(&neigh->queue, skb);\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n} else {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\nunref:\r\nipoib_neigh_put(neigh);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void ipoib_timeout(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nipoib_warn(priv, "transmit timeout: latency %d msecs\n",\r\njiffies_to_msecs(jiffies - dev->trans_start));\r\nipoib_warn(priv, "queue stopped %d, tx_head %u, tx_tail %u\n",\r\nnetif_queue_stopped(dev),\r\npriv->tx_head, priv->tx_tail);\r\n}\r\nstatic int ipoib_hard_header(struct sk_buff *skb,\r\nstruct net_device *dev,\r\nunsigned short type,\r\nconst void *daddr, const void *saddr, unsigned len)\r\n{\r\nstruct ipoib_header *header;\r\nstruct ipoib_cb *cb = (struct ipoib_cb *) skb->cb;\r\nheader = (struct ipoib_header *) skb_push(skb, sizeof *header);\r\nheader->proto = htons(type);\r\nheader->reserved = 0;\r\nmemcpy(cb->hwaddr, daddr, INFINIBAND_ALEN);\r\nreturn 0;\r\n}\r\nstatic void ipoib_set_mcast_list(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (!test_bit(IPOIB_FLAG_OPER_UP, &priv->flags)) {\r\nipoib_dbg(priv, "IPOIB_FLAG_OPER_UP not set");\r\nreturn;\r\n}\r\nqueue_work(ipoib_workqueue, &priv->restart_task);\r\n}\r\nstatic u32 ipoib_addr_hash(struct ipoib_neigh_hash *htbl, u8 *daddr)\r\n{\r\nu32 *daddr_32 = (u32 *) daddr;\r\nu32 hv;\r\nhv = jhash_3words(daddr_32[3], daddr_32[4], 0xFFFFFF & daddr_32[0], 0);\r\nreturn hv & htbl->mask;\r\n}\r\nstruct ipoib_neigh *ipoib_neigh_get(struct net_device *dev, u8 *daddr)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_neigh_table *ntbl = &priv->ntbl;\r\nstruct ipoib_neigh_hash *htbl;\r\nstruct ipoib_neigh *neigh = NULL;\r\nu32 hash_val;\r\nrcu_read_lock_bh();\r\nhtbl = rcu_dereference_bh(ntbl->htbl);\r\nif (!htbl)\r\ngoto out_unlock;\r\nhash_val = ipoib_addr_hash(htbl, daddr);\r\nfor (neigh = rcu_dereference_bh(htbl->buckets[hash_val]);\r\nneigh != NULL;\r\nneigh = rcu_dereference_bh(neigh->hnext)) {\r\nif (memcmp(daddr, neigh->daddr, INFINIBAND_ALEN) == 0) {\r\nif (!atomic_inc_not_zero(&neigh->refcnt)) {\r\nneigh = NULL;\r\ngoto out_unlock;\r\n}\r\nneigh->alive = jiffies;\r\ngoto out_unlock;\r\n}\r\n}\r\nout_unlock:\r\nrcu_read_unlock_bh();\r\nreturn neigh;\r\n}\r\nstatic void __ipoib_reap_neigh(struct ipoib_dev_priv *priv)\r\n{\r\nstruct ipoib_neigh_table *ntbl = &priv->ntbl;\r\nstruct ipoib_neigh_hash *htbl;\r\nunsigned long neigh_obsolete;\r\nunsigned long dt;\r\nunsigned long flags;\r\nint i;\r\nif (test_bit(IPOIB_STOP_NEIGH_GC, &priv->flags))\r\nreturn;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nhtbl = rcu_dereference_protected(ntbl->htbl,\r\nlockdep_is_held(&priv->lock));\r\nif (!htbl)\r\ngoto out_unlock;\r\ndt = 2 * arp_tbl.gc_interval;\r\nneigh_obsolete = jiffies - dt;\r\nif (test_bit(IPOIB_STOP_NEIGH_GC, &priv->flags))\r\ngoto out_unlock;\r\nfor (i = 0; i < htbl->size; i++) {\r\nstruct ipoib_neigh *neigh;\r\nstruct ipoib_neigh __rcu **np = &htbl->buckets[i];\r\nwhile ((neigh = rcu_dereference_protected(*np,\r\nlockdep_is_held(&priv->lock))) != NULL) {\r\nif (time_after(neigh_obsolete, neigh->alive)) {\r\nrcu_assign_pointer(*np,\r\nrcu_dereference_protected(neigh->hnext,\r\nlockdep_is_held(&priv->lock)));\r\nlist_del(&neigh->list);\r\ncall_rcu(&neigh->rcu, ipoib_neigh_reclaim);\r\n} else {\r\nnp = &neigh->hnext;\r\n}\r\n}\r\n}\r\nout_unlock:\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic void ipoib_reap_neigh(struct work_struct *work)\r\n{\r\nstruct ipoib_dev_priv *priv =\r\ncontainer_of(work, struct ipoib_dev_priv, neigh_reap_task.work);\r\n__ipoib_reap_neigh(priv);\r\nif (!test_bit(IPOIB_STOP_NEIGH_GC, &priv->flags))\r\nqueue_delayed_work(ipoib_workqueue, &priv->neigh_reap_task,\r\narp_tbl.gc_interval);\r\n}\r\nstatic struct ipoib_neigh *ipoib_neigh_ctor(u8 *daddr,\r\nstruct net_device *dev)\r\n{\r\nstruct ipoib_neigh *neigh;\r\nneigh = kzalloc(sizeof *neigh, GFP_ATOMIC);\r\nif (!neigh)\r\nreturn NULL;\r\nneigh->dev = dev;\r\nmemcpy(&neigh->daddr, daddr, sizeof(neigh->daddr));\r\nskb_queue_head_init(&neigh->queue);\r\nINIT_LIST_HEAD(&neigh->list);\r\nipoib_cm_set(neigh, NULL);\r\natomic_set(&neigh->refcnt, 1);\r\nreturn neigh;\r\n}\r\nstruct ipoib_neigh *ipoib_neigh_alloc(u8 *daddr,\r\nstruct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_neigh_table *ntbl = &priv->ntbl;\r\nstruct ipoib_neigh_hash *htbl;\r\nstruct ipoib_neigh *neigh;\r\nu32 hash_val;\r\nhtbl = rcu_dereference_protected(ntbl->htbl,\r\nlockdep_is_held(&priv->lock));\r\nif (!htbl) {\r\nneigh = NULL;\r\ngoto out_unlock;\r\n}\r\nhash_val = ipoib_addr_hash(htbl, daddr);\r\nfor (neigh = rcu_dereference_protected(htbl->buckets[hash_val],\r\nlockdep_is_held(&priv->lock));\r\nneigh != NULL;\r\nneigh = rcu_dereference_protected(neigh->hnext,\r\nlockdep_is_held(&priv->lock))) {\r\nif (memcmp(daddr, neigh->daddr, INFINIBAND_ALEN) == 0) {\r\nif (!atomic_inc_not_zero(&neigh->refcnt)) {\r\nneigh = NULL;\r\nbreak;\r\n}\r\nneigh->alive = jiffies;\r\ngoto out_unlock;\r\n}\r\n}\r\nneigh = ipoib_neigh_ctor(daddr, dev);\r\nif (!neigh)\r\ngoto out_unlock;\r\natomic_inc(&neigh->refcnt);\r\nneigh->alive = jiffies;\r\nrcu_assign_pointer(neigh->hnext,\r\nrcu_dereference_protected(htbl->buckets[hash_val],\r\nlockdep_is_held(&priv->lock)));\r\nrcu_assign_pointer(htbl->buckets[hash_val], neigh);\r\natomic_inc(&ntbl->entries);\r\nout_unlock:\r\nreturn neigh;\r\n}\r\nvoid ipoib_neigh_dtor(struct ipoib_neigh *neigh)\r\n{\r\nstruct net_device *dev = neigh->dev;\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct sk_buff *skb;\r\nif (neigh->ah)\r\nipoib_put_ah(neigh->ah);\r\nwhile ((skb = __skb_dequeue(&neigh->queue))) {\r\n++dev->stats.tx_dropped;\r\ndev_kfree_skb_any(skb);\r\n}\r\nif (ipoib_cm_get(neigh))\r\nipoib_cm_destroy_tx(ipoib_cm_get(neigh));\r\nipoib_dbg(netdev_priv(dev),\r\n"neigh free for %06x %pI6\n",\r\nIPOIB_QPN(neigh->daddr),\r\nneigh->daddr + 4);\r\nkfree(neigh);\r\nif (atomic_dec_and_test(&priv->ntbl.entries)) {\r\nif (test_bit(IPOIB_NEIGH_TBL_FLUSH, &priv->flags))\r\ncomplete(&priv->ntbl.flushed);\r\n}\r\n}\r\nstatic void ipoib_neigh_reclaim(struct rcu_head *rp)\r\n{\r\nstruct ipoib_neigh *neigh = container_of(rp, struct ipoib_neigh, rcu);\r\nipoib_neigh_put(neigh);\r\n}\r\nvoid ipoib_neigh_free(struct ipoib_neigh *neigh)\r\n{\r\nstruct net_device *dev = neigh->dev;\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_neigh_table *ntbl = &priv->ntbl;\r\nstruct ipoib_neigh_hash *htbl;\r\nstruct ipoib_neigh __rcu **np;\r\nstruct ipoib_neigh *n;\r\nu32 hash_val;\r\nhtbl = rcu_dereference_protected(ntbl->htbl,\r\nlockdep_is_held(&priv->lock));\r\nif (!htbl)\r\nreturn;\r\nhash_val = ipoib_addr_hash(htbl, neigh->daddr);\r\nnp = &htbl->buckets[hash_val];\r\nfor (n = rcu_dereference_protected(*np,\r\nlockdep_is_held(&priv->lock));\r\nn != NULL;\r\nn = rcu_dereference_protected(*np,\r\nlockdep_is_held(&priv->lock))) {\r\nif (n == neigh) {\r\nrcu_assign_pointer(*np,\r\nrcu_dereference_protected(neigh->hnext,\r\nlockdep_is_held(&priv->lock)));\r\ncall_rcu(&neigh->rcu, ipoib_neigh_reclaim);\r\nreturn;\r\n} else {\r\nnp = &n->hnext;\r\n}\r\n}\r\n}\r\nstatic int ipoib_neigh_hash_init(struct ipoib_dev_priv *priv)\r\n{\r\nstruct ipoib_neigh_table *ntbl = &priv->ntbl;\r\nstruct ipoib_neigh_hash *htbl;\r\nstruct ipoib_neigh **buckets;\r\nu32 size;\r\nclear_bit(IPOIB_NEIGH_TBL_FLUSH, &priv->flags);\r\nntbl->htbl = NULL;\r\nhtbl = kzalloc(sizeof(*htbl), GFP_KERNEL);\r\nif (!htbl)\r\nreturn -ENOMEM;\r\nset_bit(IPOIB_STOP_NEIGH_GC, &priv->flags);\r\nsize = roundup_pow_of_two(arp_tbl.gc_thresh3);\r\nbuckets = kzalloc(size * sizeof(*buckets), GFP_KERNEL);\r\nif (!buckets) {\r\nkfree(htbl);\r\nreturn -ENOMEM;\r\n}\r\nhtbl->size = size;\r\nhtbl->mask = (size - 1);\r\nhtbl->buckets = buckets;\r\nntbl->htbl = htbl;\r\nhtbl->ntbl = ntbl;\r\natomic_set(&ntbl->entries, 0);\r\nclear_bit(IPOIB_STOP_NEIGH_GC, &priv->flags);\r\nqueue_delayed_work(ipoib_workqueue, &priv->neigh_reap_task,\r\narp_tbl.gc_interval);\r\nreturn 0;\r\n}\r\nstatic void neigh_hash_free_rcu(struct rcu_head *head)\r\n{\r\nstruct ipoib_neigh_hash *htbl = container_of(head,\r\nstruct ipoib_neigh_hash,\r\nrcu);\r\nstruct ipoib_neigh __rcu **buckets = htbl->buckets;\r\nstruct ipoib_neigh_table *ntbl = htbl->ntbl;\r\nkfree(buckets);\r\nkfree(htbl);\r\ncomplete(&ntbl->deleted);\r\n}\r\nvoid ipoib_del_neighs_by_gid(struct net_device *dev, u8 *gid)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nstruct ipoib_neigh_table *ntbl = &priv->ntbl;\r\nstruct ipoib_neigh_hash *htbl;\r\nunsigned long flags;\r\nint i;\r\nspin_lock_irqsave(&priv->lock, flags);\r\nhtbl = rcu_dereference_protected(ntbl->htbl,\r\nlockdep_is_held(&priv->lock));\r\nif (!htbl)\r\ngoto out_unlock;\r\nfor (i = 0; i < htbl->size; i++) {\r\nstruct ipoib_neigh *neigh;\r\nstruct ipoib_neigh __rcu **np = &htbl->buckets[i];\r\nwhile ((neigh = rcu_dereference_protected(*np,\r\nlockdep_is_held(&priv->lock))) != NULL) {\r\nif (!memcmp(gid, neigh->daddr + 4, sizeof (union ib_gid))) {\r\nrcu_assign_pointer(*np,\r\nrcu_dereference_protected(neigh->hnext,\r\nlockdep_is_held(&priv->lock)));\r\nlist_del(&neigh->list);\r\ncall_rcu(&neigh->rcu, ipoib_neigh_reclaim);\r\n} else {\r\nnp = &neigh->hnext;\r\n}\r\n}\r\n}\r\nout_unlock:\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\n}\r\nstatic void ipoib_flush_neighs(struct ipoib_dev_priv *priv)\r\n{\r\nstruct ipoib_neigh_table *ntbl = &priv->ntbl;\r\nstruct ipoib_neigh_hash *htbl;\r\nunsigned long flags;\r\nint i, wait_flushed = 0;\r\ninit_completion(&priv->ntbl.flushed);\r\nspin_lock_irqsave(&priv->lock, flags);\r\nhtbl = rcu_dereference_protected(ntbl->htbl,\r\nlockdep_is_held(&priv->lock));\r\nif (!htbl)\r\ngoto out_unlock;\r\nwait_flushed = atomic_read(&priv->ntbl.entries);\r\nif (!wait_flushed)\r\ngoto free_htbl;\r\nfor (i = 0; i < htbl->size; i++) {\r\nstruct ipoib_neigh *neigh;\r\nstruct ipoib_neigh __rcu **np = &htbl->buckets[i];\r\nwhile ((neigh = rcu_dereference_protected(*np,\r\nlockdep_is_held(&priv->lock))) != NULL) {\r\nrcu_assign_pointer(*np,\r\nrcu_dereference_protected(neigh->hnext,\r\nlockdep_is_held(&priv->lock)));\r\nlist_del(&neigh->list);\r\ncall_rcu(&neigh->rcu, ipoib_neigh_reclaim);\r\n}\r\n}\r\nfree_htbl:\r\nrcu_assign_pointer(ntbl->htbl, NULL);\r\ncall_rcu(&htbl->rcu, neigh_hash_free_rcu);\r\nout_unlock:\r\nspin_unlock_irqrestore(&priv->lock, flags);\r\nif (wait_flushed)\r\nwait_for_completion(&priv->ntbl.flushed);\r\n}\r\nstatic void ipoib_neigh_hash_uninit(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nint stopped;\r\nipoib_dbg(priv, "ipoib_neigh_hash_uninit\n");\r\ninit_completion(&priv->ntbl.deleted);\r\nset_bit(IPOIB_NEIGH_TBL_FLUSH, &priv->flags);\r\nstopped = test_and_set_bit(IPOIB_STOP_NEIGH_GC, &priv->flags);\r\nif (!stopped)\r\ncancel_delayed_work(&priv->neigh_reap_task);\r\nipoib_flush_neighs(priv);\r\nwait_for_completion(&priv->ntbl.deleted);\r\n}\r\nint ipoib_dev_init(struct net_device *dev, struct ib_device *ca, int port)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\nif (ipoib_neigh_hash_init(priv) < 0)\r\ngoto out;\r\npriv->rx_ring = kzalloc(ipoib_recvq_size * sizeof *priv->rx_ring,\r\nGFP_KERNEL);\r\nif (!priv->rx_ring) {\r\nprintk(KERN_WARNING "%s: failed to allocate RX ring (%d entries)\n",\r\nca->name, ipoib_recvq_size);\r\ngoto out_neigh_hash_cleanup;\r\n}\r\npriv->tx_ring = vzalloc(ipoib_sendq_size * sizeof *priv->tx_ring);\r\nif (!priv->tx_ring) {\r\nprintk(KERN_WARNING "%s: failed to allocate TX ring (%d entries)\n",\r\nca->name, ipoib_sendq_size);\r\ngoto out_rx_ring_cleanup;\r\n}\r\nif (ipoib_ib_dev_init(dev, ca, port))\r\ngoto out_tx_ring_cleanup;\r\nreturn 0;\r\nout_tx_ring_cleanup:\r\nvfree(priv->tx_ring);\r\nout_rx_ring_cleanup:\r\nkfree(priv->rx_ring);\r\nout_neigh_hash_cleanup:\r\nipoib_neigh_hash_uninit(dev);\r\nout:\r\nreturn -ENOMEM;\r\n}\r\nvoid ipoib_dev_cleanup(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev), *cpriv, *tcpriv;\r\nLIST_HEAD(head);\r\nASSERT_RTNL();\r\nipoib_delete_debug_files(dev);\r\nlist_for_each_entry_safe(cpriv, tcpriv, &priv->child_intfs, list) {\r\nset_bit(IPOIB_STOP_NEIGH_GC, &cpriv->flags);\r\ncancel_delayed_work(&cpriv->neigh_reap_task);\r\nunregister_netdevice_queue(cpriv->dev, &head);\r\n}\r\nunregister_netdevice_many(&head);\r\nipoib_ib_dev_cleanup(dev);\r\nkfree(priv->rx_ring);\r\nvfree(priv->tx_ring);\r\npriv->rx_ring = NULL;\r\npriv->tx_ring = NULL;\r\nipoib_neigh_hash_uninit(dev);\r\n}\r\nvoid ipoib_setup(struct net_device *dev)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(dev);\r\ndev->netdev_ops = &ipoib_netdev_ops;\r\ndev->header_ops = &ipoib_header_ops;\r\nipoib_set_ethtool_ops(dev);\r\nnetif_napi_add(dev, &priv->napi, ipoib_poll, 100);\r\ndev->watchdog_timeo = HZ;\r\ndev->flags |= IFF_BROADCAST | IFF_MULTICAST;\r\ndev->hard_header_len = IPOIB_ENCAP_LEN;\r\ndev->addr_len = INFINIBAND_ALEN;\r\ndev->type = ARPHRD_INFINIBAND;\r\ndev->tx_queue_len = ipoib_sendq_size * 2;\r\ndev->features = (NETIF_F_VLAN_CHALLENGED |\r\nNETIF_F_HIGHDMA);\r\ndev->priv_flags &= ~IFF_XMIT_DST_RELEASE;\r\nmemcpy(dev->broadcast, ipv4_bcast_addr, INFINIBAND_ALEN);\r\nnetif_carrier_off(dev);\r\npriv->dev = dev;\r\nspin_lock_init(&priv->lock);\r\nmutex_init(&priv->vlan_mutex);\r\nINIT_LIST_HEAD(&priv->path_list);\r\nINIT_LIST_HEAD(&priv->child_intfs);\r\nINIT_LIST_HEAD(&priv->dead_ahs);\r\nINIT_LIST_HEAD(&priv->multicast_list);\r\nINIT_DELAYED_WORK(&priv->pkey_poll_task, ipoib_pkey_poll);\r\nINIT_DELAYED_WORK(&priv->mcast_task, ipoib_mcast_join_task);\r\nINIT_WORK(&priv->carrier_on_task, ipoib_mcast_carrier_on_task);\r\nINIT_WORK(&priv->flush_light, ipoib_ib_dev_flush_light);\r\nINIT_WORK(&priv->flush_normal, ipoib_ib_dev_flush_normal);\r\nINIT_WORK(&priv->flush_heavy, ipoib_ib_dev_flush_heavy);\r\nINIT_WORK(&priv->restart_task, ipoib_mcast_restart_task);\r\nINIT_DELAYED_WORK(&priv->ah_reap_task, ipoib_reap_ah);\r\nINIT_DELAYED_WORK(&priv->neigh_reap_task, ipoib_reap_neigh);\r\n}\r\nstruct ipoib_dev_priv *ipoib_intf_alloc(const char *name)\r\n{\r\nstruct net_device *dev;\r\ndev = alloc_netdev((int) sizeof (struct ipoib_dev_priv), name,\r\nipoib_setup);\r\nif (!dev)\r\nreturn NULL;\r\nreturn netdev_priv(dev);\r\n}\r\nstatic ssize_t show_pkey(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(to_net_dev(dev));\r\nreturn sprintf(buf, "0x%04x\n", priv->pkey);\r\n}\r\nstatic ssize_t show_umcast(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(to_net_dev(dev));\r\nreturn sprintf(buf, "%d\n", test_bit(IPOIB_FLAG_UMCAST, &priv->flags));\r\n}\r\nvoid ipoib_set_umcast(struct net_device *ndev, int umcast_val)\r\n{\r\nstruct ipoib_dev_priv *priv = netdev_priv(ndev);\r\nif (umcast_val > 0) {\r\nset_bit(IPOIB_FLAG_UMCAST, &priv->flags);\r\nipoib_warn(priv, "ignoring multicast groups joined directly "\r\n"by userspace\n");\r\n} else\r\nclear_bit(IPOIB_FLAG_UMCAST, &priv->flags);\r\n}\r\nstatic ssize_t set_umcast(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nunsigned long umcast_val = simple_strtoul(buf, NULL, 0);\r\nipoib_set_umcast(to_net_dev(dev), umcast_val);\r\nreturn count;\r\n}\r\nint ipoib_add_umcast_attr(struct net_device *dev)\r\n{\r\nreturn device_create_file(&dev->dev, &dev_attr_umcast);\r\n}\r\nstatic ssize_t create_child(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nint pkey;\r\nint ret;\r\nif (sscanf(buf, "%i", &pkey) != 1)\r\nreturn -EINVAL;\r\nif (pkey < 0 || pkey > 0xffff)\r\nreturn -EINVAL;\r\npkey |= 0x8000;\r\nret = ipoib_vlan_add(to_net_dev(dev), pkey);\r\nreturn ret ? ret : count;\r\n}\r\nstatic ssize_t delete_child(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nint pkey;\r\nint ret;\r\nif (sscanf(buf, "%i", &pkey) != 1)\r\nreturn -EINVAL;\r\nif (pkey < 0 || pkey > 0xffff)\r\nreturn -EINVAL;\r\nret = ipoib_vlan_delete(to_net_dev(dev), pkey);\r\nreturn ret ? ret : count;\r\n}\r\nint ipoib_add_pkey_attr(struct net_device *dev)\r\n{\r\nreturn device_create_file(&dev->dev, &dev_attr_pkey);\r\n}\r\nint ipoib_set_dev_features(struct ipoib_dev_priv *priv, struct ib_device *hca)\r\n{\r\nstruct ib_device_attr *device_attr;\r\nint result = -ENOMEM;\r\ndevice_attr = kmalloc(sizeof *device_attr, GFP_KERNEL);\r\nif (!device_attr) {\r\nprintk(KERN_WARNING "%s: allocation of %zu bytes failed\n",\r\nhca->name, sizeof *device_attr);\r\nreturn result;\r\n}\r\nresult = ib_query_device(hca, device_attr);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: ib_query_device failed (ret = %d)\n",\r\nhca->name, result);\r\nkfree(device_attr);\r\nreturn result;\r\n}\r\npriv->hca_caps = device_attr->device_cap_flags;\r\nkfree(device_attr);\r\nif (priv->hca_caps & IB_DEVICE_UD_IP_CSUM) {\r\npriv->dev->hw_features = NETIF_F_SG |\r\nNETIF_F_IP_CSUM | NETIF_F_RXCSUM;\r\nif (priv->hca_caps & IB_DEVICE_UD_TSO)\r\npriv->dev->hw_features |= NETIF_F_TSO;\r\npriv->dev->features |= priv->dev->hw_features;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct net_device *ipoib_add_port(const char *format,\r\nstruct ib_device *hca, u8 port)\r\n{\r\nstruct ipoib_dev_priv *priv;\r\nstruct ib_port_attr attr;\r\nint result = -ENOMEM;\r\npriv = ipoib_intf_alloc(format);\r\nif (!priv)\r\ngoto alloc_mem_failed;\r\nSET_NETDEV_DEV(priv->dev, hca->dma_device);\r\npriv->dev->dev_id = port - 1;\r\nif (!ib_query_port(hca, port, &attr))\r\npriv->max_ib_mtu = ib_mtu_enum_to_int(attr.max_mtu);\r\nelse {\r\nprintk(KERN_WARNING "%s: ib_query_port %d failed\n",\r\nhca->name, port);\r\ngoto device_init_failed;\r\n}\r\npriv->dev->mtu = IPOIB_UD_MTU(priv->max_ib_mtu);\r\npriv->mcast_mtu = priv->admin_mtu = priv->dev->mtu;\r\npriv->dev->neigh_priv_len = sizeof(struct ipoib_neigh);\r\nresult = ib_query_pkey(hca, port, 0, &priv->pkey);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: ib_query_pkey port %d failed (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto device_init_failed;\r\n}\r\nif (ipoib_set_dev_features(priv, hca))\r\ngoto device_init_failed;\r\npriv->pkey |= 0x8000;\r\npriv->dev->broadcast[8] = priv->pkey >> 8;\r\npriv->dev->broadcast[9] = priv->pkey & 0xff;\r\nresult = ib_query_gid(hca, port, 0, &priv->local_gid);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: ib_query_gid port %d failed (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto device_init_failed;\r\n} else\r\nmemcpy(priv->dev->dev_addr + 4, priv->local_gid.raw, sizeof (union ib_gid));\r\nresult = ipoib_dev_init(priv->dev, hca, port);\r\nif (result < 0) {\r\nprintk(KERN_WARNING "%s: failed to initialize port %d (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto device_init_failed;\r\n}\r\nINIT_IB_EVENT_HANDLER(&priv->event_handler,\r\npriv->ca, ipoib_event);\r\nresult = ib_register_event_handler(&priv->event_handler);\r\nif (result < 0) {\r\nprintk(KERN_WARNING "%s: ib_register_event_handler failed for "\r\n"port %d (ret = %d)\n",\r\nhca->name, port, result);\r\ngoto event_failed;\r\n}\r\nresult = register_netdev(priv->dev);\r\nif (result) {\r\nprintk(KERN_WARNING "%s: couldn't register ipoib port %d; error %d\n",\r\nhca->name, port, result);\r\ngoto register_failed;\r\n}\r\nipoib_create_debug_files(priv->dev);\r\nif (ipoib_cm_add_mode_attr(priv->dev))\r\ngoto sysfs_failed;\r\nif (ipoib_add_pkey_attr(priv->dev))\r\ngoto sysfs_failed;\r\nif (ipoib_add_umcast_attr(priv->dev))\r\ngoto sysfs_failed;\r\nif (device_create_file(&priv->dev->dev, &dev_attr_create_child))\r\ngoto sysfs_failed;\r\nif (device_create_file(&priv->dev->dev, &dev_attr_delete_child))\r\ngoto sysfs_failed;\r\nreturn priv->dev;\r\nsysfs_failed:\r\nipoib_delete_debug_files(priv->dev);\r\nunregister_netdev(priv->dev);\r\nregister_failed:\r\nib_unregister_event_handler(&priv->event_handler);\r\nset_bit(IPOIB_STOP_NEIGH_GC, &priv->flags);\r\ncancel_delayed_work(&priv->neigh_reap_task);\r\nflush_workqueue(ipoib_workqueue);\r\nevent_failed:\r\nipoib_dev_cleanup(priv->dev);\r\ndevice_init_failed:\r\nfree_netdev(priv->dev);\r\nalloc_mem_failed:\r\nreturn ERR_PTR(result);\r\n}\r\nstatic void ipoib_add_one(struct ib_device *device)\r\n{\r\nstruct list_head *dev_list;\r\nstruct net_device *dev;\r\nstruct ipoib_dev_priv *priv;\r\nint s, e, p;\r\nif (rdma_node_get_transport(device->node_type) != RDMA_TRANSPORT_IB)\r\nreturn;\r\ndev_list = kmalloc(sizeof *dev_list, GFP_KERNEL);\r\nif (!dev_list)\r\nreturn;\r\nINIT_LIST_HEAD(dev_list);\r\nif (device->node_type == RDMA_NODE_IB_SWITCH) {\r\ns = 0;\r\ne = 0;\r\n} else {\r\ns = 1;\r\ne = device->phys_port_cnt;\r\n}\r\nfor (p = s; p <= e; ++p) {\r\nif (rdma_port_get_link_layer(device, p) != IB_LINK_LAYER_INFINIBAND)\r\ncontinue;\r\ndev = ipoib_add_port("ib%d", device, p);\r\nif (!IS_ERR(dev)) {\r\npriv = netdev_priv(dev);\r\nlist_add_tail(&priv->list, dev_list);\r\n}\r\n}\r\nib_set_client_data(device, &ipoib_client, dev_list);\r\n}\r\nstatic void ipoib_remove_one(struct ib_device *device)\r\n{\r\nstruct ipoib_dev_priv *priv, *tmp;\r\nstruct list_head *dev_list;\r\nif (rdma_node_get_transport(device->node_type) != RDMA_TRANSPORT_IB)\r\nreturn;\r\ndev_list = ib_get_client_data(device, &ipoib_client);\r\nlist_for_each_entry_safe(priv, tmp, dev_list, list) {\r\nib_unregister_event_handler(&priv->event_handler);\r\nrtnl_lock();\r\ndev_change_flags(priv->dev, priv->dev->flags & ~IFF_UP);\r\nrtnl_unlock();\r\nset_bit(IPOIB_STOP_NEIGH_GC, &priv->flags);\r\ncancel_delayed_work(&priv->neigh_reap_task);\r\nflush_workqueue(ipoib_workqueue);\r\nunregister_netdev(priv->dev);\r\nfree_netdev(priv->dev);\r\n}\r\nkfree(dev_list);\r\n}\r\nstatic int __init ipoib_init_module(void)\r\n{\r\nint ret;\r\nipoib_recvq_size = roundup_pow_of_two(ipoib_recvq_size);\r\nipoib_recvq_size = min(ipoib_recvq_size, IPOIB_MAX_QUEUE_SIZE);\r\nipoib_recvq_size = max(ipoib_recvq_size, IPOIB_MIN_QUEUE_SIZE);\r\nipoib_sendq_size = roundup_pow_of_two(ipoib_sendq_size);\r\nipoib_sendq_size = min(ipoib_sendq_size, IPOIB_MAX_QUEUE_SIZE);\r\nipoib_sendq_size = max3(ipoib_sendq_size, 2 * MAX_SEND_CQE, IPOIB_MIN_QUEUE_SIZE);\r\n#ifdef CONFIG_INFINIBAND_IPOIB_CM\r\nipoib_max_conn_qp = min(ipoib_max_conn_qp, IPOIB_CM_MAX_CONN_QP);\r\n#endif\r\nBUILD_BUG_ON(IPOIB_CM_COPYBREAK > IPOIB_CM_HEAD_SIZE);\r\nret = ipoib_register_debugfs();\r\nif (ret)\r\nreturn ret;\r\nipoib_workqueue = create_singlethread_workqueue("ipoib");\r\nif (!ipoib_workqueue) {\r\nret = -ENOMEM;\r\ngoto err_fs;\r\n}\r\nib_sa_register_client(&ipoib_sa_client);\r\nret = ib_register_client(&ipoib_client);\r\nif (ret)\r\ngoto err_sa;\r\nret = ipoib_netlink_init();\r\nif (ret)\r\ngoto err_client;\r\nreturn 0;\r\nerr_client:\r\nib_unregister_client(&ipoib_client);\r\nerr_sa:\r\nib_sa_unregister_client(&ipoib_sa_client);\r\ndestroy_workqueue(ipoib_workqueue);\r\nerr_fs:\r\nipoib_unregister_debugfs();\r\nreturn ret;\r\n}\r\nstatic void __exit ipoib_cleanup_module(void)\r\n{\r\nipoib_netlink_fini();\r\nib_unregister_client(&ipoib_client);\r\nib_sa_unregister_client(&ipoib_sa_client);\r\nipoib_unregister_debugfs();\r\ndestroy_workqueue(ipoib_workqueue);\r\n}
