static struct drm_map_list *drm_find_matching_map(struct drm_device *dev,\r\nstruct drm_local_map *map)\r\n{\r\nstruct drm_map_list *entry;\r\nlist_for_each_entry(entry, &dev->maplist, head) {\r\nif (!entry->map ||\r\nmap->type != entry->map->type ||\r\nentry->master != dev->primary->master)\r\ncontinue;\r\nswitch (map->type) {\r\ncase _DRM_SHM:\r\nif (map->flags != _DRM_CONTAINS_LOCK)\r\nbreak;\r\nreturn entry;\r\ncase _DRM_REGISTERS:\r\ncase _DRM_FRAME_BUFFER:\r\nif ((entry->map->offset & 0xffffffff) ==\r\n(map->offset & 0xffffffff))\r\nreturn entry;\r\ndefault:\r\n;\r\n}\r\nif (entry->map->offset == map->offset)\r\nreturn entry;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int drm_map_handle(struct drm_device *dev, struct drm_hash_item *hash,\r\nunsigned long user_token, int hashed_handle, int shm)\r\n{\r\nint use_hashed_handle, shift;\r\nunsigned long add;\r\n#if (BITS_PER_LONG == 64)\r\nuse_hashed_handle = ((user_token & 0xFFFFFFFF00000000UL) || hashed_handle);\r\n#elif (BITS_PER_LONG == 32)\r\nuse_hashed_handle = hashed_handle;\r\n#else\r\n#error Unsupported long size. Neither 64 nor 32 bits.\r\n#endif\r\nif (!use_hashed_handle) {\r\nint ret;\r\nhash->key = user_token >> PAGE_SHIFT;\r\nret = drm_ht_insert_item(&dev->map_hash, hash);\r\nif (ret != -EINVAL)\r\nreturn ret;\r\n}\r\nshift = 0;\r\nadd = DRM_MAP_HASH_OFFSET >> PAGE_SHIFT;\r\nif (shm && (SHMLBA > PAGE_SIZE)) {\r\nint bits = ilog2(SHMLBA >> PAGE_SHIFT) + 1;\r\nshift = bits;\r\nadd |= ((user_token >> PAGE_SHIFT) & ((1UL << bits) - 1UL));\r\n}\r\nreturn drm_ht_just_insert_please(&dev->map_hash, hash,\r\nuser_token, 32 - PAGE_SHIFT - 3,\r\nshift, add);\r\n}\r\nstatic int drm_addmap_core(struct drm_device * dev, resource_size_t offset,\r\nunsigned int size, enum drm_map_type type,\r\nenum drm_map_flags flags,\r\nstruct drm_map_list ** maplist)\r\n{\r\nstruct drm_local_map *map;\r\nstruct drm_map_list *list;\r\ndrm_dma_handle_t *dmah;\r\nunsigned long user_token;\r\nint ret;\r\nmap = kmalloc(sizeof(*map), GFP_KERNEL);\r\nif (!map)\r\nreturn -ENOMEM;\r\nmap->offset = offset;\r\nmap->size = size;\r\nmap->flags = flags;\r\nmap->type = type;\r\nif ((map->flags & _DRM_REMOVABLE) && map->type != _DRM_SHM) {\r\nkfree(map);\r\nreturn -EINVAL;\r\n}\r\nDRM_DEBUG("offset = 0x%08llx, size = 0x%08lx, type = %d\n",\r\n(unsigned long long)map->offset, map->size, map->type);\r\nif (map->type == _DRM_SHM)\r\nmap->size = PAGE_ALIGN(map->size);\r\nif ((map->offset & (~(resource_size_t)PAGE_MASK)) || (map->size & (~PAGE_MASK))) {\r\nkfree(map);\r\nreturn -EINVAL;\r\n}\r\nmap->mtrr = -1;\r\nmap->handle = NULL;\r\nswitch (map->type) {\r\ncase _DRM_REGISTERS:\r\ncase _DRM_FRAME_BUFFER:\r\n#if !defined(__sparc__) && !defined(__alpha__) && !defined(__ia64__) && !defined(__powerpc64__) && !defined(__x86_64__) && !defined(__arm__)\r\nif (map->offset + (map->size-1) < map->offset ||\r\nmap->offset < virt_to_phys(high_memory)) {\r\nkfree(map);\r\nreturn -EINVAL;\r\n}\r\n#endif\r\nlist = drm_find_matching_map(dev, map);\r\nif (list != NULL) {\r\nif (list->map->size != map->size) {\r\nDRM_DEBUG("Matching maps of type %d with "\r\n"mismatched sizes, (%ld vs %ld)\n",\r\nmap->type, map->size,\r\nlist->map->size);\r\nlist->map->size = map->size;\r\n}\r\nkfree(map);\r\n*maplist = list;\r\nreturn 0;\r\n}\r\nif (drm_core_has_MTRR(dev)) {\r\nif (map->type == _DRM_FRAME_BUFFER ||\r\n(map->flags & _DRM_WRITE_COMBINING)) {\r\nmap->mtrr = mtrr_add(map->offset, map->size,\r\nMTRR_TYPE_WRCOMB, 1);\r\n}\r\n}\r\nif (map->type == _DRM_REGISTERS) {\r\nmap->handle = ioremap(map->offset, map->size);\r\nif (!map->handle) {\r\nkfree(map);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nbreak;\r\ncase _DRM_SHM:\r\nlist = drm_find_matching_map(dev, map);\r\nif (list != NULL) {\r\nif(list->map->size != map->size) {\r\nDRM_DEBUG("Matching maps of type %d with "\r\n"mismatched sizes, (%ld vs %ld)\n",\r\nmap->type, map->size, list->map->size);\r\nlist->map->size = map->size;\r\n}\r\nkfree(map);\r\n*maplist = list;\r\nreturn 0;\r\n}\r\nmap->handle = vmalloc_user(map->size);\r\nDRM_DEBUG("%lu %d %p\n",\r\nmap->size, drm_order(map->size), map->handle);\r\nif (!map->handle) {\r\nkfree(map);\r\nreturn -ENOMEM;\r\n}\r\nmap->offset = (unsigned long)map->handle;\r\nif (map->flags & _DRM_CONTAINS_LOCK) {\r\nif (dev->primary->master->lock.hw_lock != NULL) {\r\nvfree(map->handle);\r\nkfree(map);\r\nreturn -EBUSY;\r\n}\r\ndev->sigdata.lock = dev->primary->master->lock.hw_lock = map->handle;\r\n}\r\nbreak;\r\ncase _DRM_AGP: {\r\nstruct drm_agp_mem *entry;\r\nint valid = 0;\r\nif (!drm_core_has_AGP(dev)) {\r\nkfree(map);\r\nreturn -EINVAL;\r\n}\r\n#ifdef __alpha__\r\nmap->offset += dev->hose->mem_space->start;\r\n#endif\r\nif (map->offset < dev->agp->base ||\r\nmap->offset > dev->agp->base +\r\ndev->agp->agp_info.aper_size * 1024 * 1024 - 1) {\r\nmap->offset += dev->agp->base;\r\n}\r\nmap->mtrr = dev->agp->agp_mtrr;\r\nlist_for_each_entry(entry, &dev->agp->memory, head) {\r\nif ((map->offset >= entry->bound) &&\r\n(map->offset + map->size <= entry->bound + entry->pages * PAGE_SIZE)) {\r\nvalid = 1;\r\nbreak;\r\n}\r\n}\r\nif (!list_empty(&dev->agp->memory) && !valid) {\r\nkfree(map);\r\nreturn -EPERM;\r\n}\r\nDRM_DEBUG("AGP offset = 0x%08llx, size = 0x%08lx\n",\r\n(unsigned long long)map->offset, map->size);\r\nbreak;\r\n}\r\ncase _DRM_GEM:\r\nDRM_ERROR("tried to addmap GEM object\n");\r\nbreak;\r\ncase _DRM_SCATTER_GATHER:\r\nif (!dev->sg) {\r\nkfree(map);\r\nreturn -EINVAL;\r\n}\r\nmap->offset += (unsigned long)dev->sg->virtual;\r\nbreak;\r\ncase _DRM_CONSISTENT:\r\ndmah = drm_pci_alloc(dev, map->size, map->size);\r\nif (!dmah) {\r\nkfree(map);\r\nreturn -ENOMEM;\r\n}\r\nmap->handle = dmah->vaddr;\r\nmap->offset = (unsigned long)dmah->busaddr;\r\nkfree(dmah);\r\nbreak;\r\ndefault:\r\nkfree(map);\r\nreturn -EINVAL;\r\n}\r\nlist = kzalloc(sizeof(*list), GFP_KERNEL);\r\nif (!list) {\r\nif (map->type == _DRM_REGISTERS)\r\niounmap(map->handle);\r\nkfree(map);\r\nreturn -EINVAL;\r\n}\r\nlist->map = map;\r\nmutex_lock(&dev->struct_mutex);\r\nlist_add(&list->head, &dev->maplist);\r\nuser_token = (map->type == _DRM_SHM) ? (unsigned long)map->handle :\r\nmap->offset;\r\nret = drm_map_handle(dev, &list->hash, user_token, 0,\r\n(map->type == _DRM_SHM));\r\nif (ret) {\r\nif (map->type == _DRM_REGISTERS)\r\niounmap(map->handle);\r\nkfree(map);\r\nkfree(list);\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn ret;\r\n}\r\nlist->user_token = list->hash.key << PAGE_SHIFT;\r\nmutex_unlock(&dev->struct_mutex);\r\nif (!(map->flags & _DRM_DRIVER))\r\nlist->master = dev->primary->master;\r\n*maplist = list;\r\nreturn 0;\r\n}\r\nint drm_addmap(struct drm_device * dev, resource_size_t offset,\r\nunsigned int size, enum drm_map_type type,\r\nenum drm_map_flags flags, struct drm_local_map ** map_ptr)\r\n{\r\nstruct drm_map_list *list;\r\nint rc;\r\nrc = drm_addmap_core(dev, offset, size, type, flags, &list);\r\nif (!rc)\r\n*map_ptr = list->map;\r\nreturn rc;\r\n}\r\nint drm_addmap_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_map *map = data;\r\nstruct drm_map_list *maplist;\r\nint err;\r\nif (!(capable(CAP_SYS_ADMIN) || map->type == _DRM_AGP || map->type == _DRM_SHM))\r\nreturn -EPERM;\r\nerr = drm_addmap_core(dev, map->offset, map->size, map->type,\r\nmap->flags, &maplist);\r\nif (err)\r\nreturn err;\r\nmap->handle = (void *)(unsigned long)maplist->user_token;\r\nreturn 0;\r\n}\r\nint drm_rmmap_locked(struct drm_device *dev, struct drm_local_map *map)\r\n{\r\nstruct drm_map_list *r_list = NULL, *list_t;\r\ndrm_dma_handle_t dmah;\r\nint found = 0;\r\nstruct drm_master *master;\r\nlist_for_each_entry_safe(r_list, list_t, &dev->maplist, head) {\r\nif (r_list->map == map) {\r\nmaster = r_list->master;\r\nlist_del(&r_list->head);\r\ndrm_ht_remove_key(&dev->map_hash,\r\nr_list->user_token >> PAGE_SHIFT);\r\nkfree(r_list);\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (!found)\r\nreturn -EINVAL;\r\nswitch (map->type) {\r\ncase _DRM_REGISTERS:\r\niounmap(map->handle);\r\ncase _DRM_FRAME_BUFFER:\r\nif (drm_core_has_MTRR(dev) && map->mtrr >= 0) {\r\nint retcode;\r\nretcode = mtrr_del(map->mtrr, map->offset, map->size);\r\nDRM_DEBUG("mtrr_del=%d\n", retcode);\r\n}\r\nbreak;\r\ncase _DRM_SHM:\r\nvfree(map->handle);\r\nif (master) {\r\nif (dev->sigdata.lock == master->lock.hw_lock)\r\ndev->sigdata.lock = NULL;\r\nmaster->lock.hw_lock = NULL;\r\nmaster->lock.file_priv = NULL;\r\nwake_up_interruptible_all(&master->lock.lock_queue);\r\n}\r\nbreak;\r\ncase _DRM_AGP:\r\ncase _DRM_SCATTER_GATHER:\r\nbreak;\r\ncase _DRM_CONSISTENT:\r\ndmah.vaddr = map->handle;\r\ndmah.busaddr = map->offset;\r\ndmah.size = map->size;\r\n__drm_pci_free(dev, &dmah);\r\nbreak;\r\ncase _DRM_GEM:\r\nDRM_ERROR("tried to rmmap GEM object\n");\r\nbreak;\r\n}\r\nkfree(map);\r\nreturn 0;\r\n}\r\nint drm_rmmap(struct drm_device *dev, struct drm_local_map *map)\r\n{\r\nint ret;\r\nmutex_lock(&dev->struct_mutex);\r\nret = drm_rmmap_locked(dev, map);\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn ret;\r\n}\r\nint drm_rmmap_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_map *request = data;\r\nstruct drm_local_map *map = NULL;\r\nstruct drm_map_list *r_list;\r\nint ret;\r\nmutex_lock(&dev->struct_mutex);\r\nlist_for_each_entry(r_list, &dev->maplist, head) {\r\nif (r_list->map &&\r\nr_list->user_token == (unsigned long)request->handle &&\r\nr_list->map->flags & _DRM_REMOVABLE) {\r\nmap = r_list->map;\r\nbreak;\r\n}\r\n}\r\nif (list_empty(&dev->maplist) || !map) {\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn -EINVAL;\r\n}\r\nif ((map->type == _DRM_REGISTERS) || (map->type == _DRM_FRAME_BUFFER)) {\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn 0;\r\n}\r\nret = drm_rmmap_locked(dev, map);\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn ret;\r\n}\r\nstatic void drm_cleanup_buf_error(struct drm_device * dev,\r\nstruct drm_buf_entry * entry)\r\n{\r\nint i;\r\nif (entry->seg_count) {\r\nfor (i = 0; i < entry->seg_count; i++) {\r\nif (entry->seglist[i]) {\r\ndrm_pci_free(dev, entry->seglist[i]);\r\n}\r\n}\r\nkfree(entry->seglist);\r\nentry->seg_count = 0;\r\n}\r\nif (entry->buf_count) {\r\nfor (i = 0; i < entry->buf_count; i++) {\r\nkfree(entry->buflist[i].dev_private);\r\n}\r\nkfree(entry->buflist);\r\nentry->buf_count = 0;\r\n}\r\n}\r\nint drm_addbufs_agp(struct drm_device * dev, struct drm_buf_desc * request)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nstruct drm_buf_entry *entry;\r\nstruct drm_agp_mem *agp_entry;\r\nstruct drm_buf *buf;\r\nunsigned long offset;\r\nunsigned long agp_offset;\r\nint count;\r\nint order;\r\nint size;\r\nint alignment;\r\nint page_order;\r\nint total;\r\nint byte_count;\r\nint i, valid;\r\nstruct drm_buf **temp_buflist;\r\nif (!dma)\r\nreturn -EINVAL;\r\ncount = request->count;\r\norder = drm_order(request->size);\r\nsize = 1 << order;\r\nalignment = (request->flags & _DRM_PAGE_ALIGN)\r\n? PAGE_ALIGN(size) : size;\r\npage_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;\r\ntotal = PAGE_SIZE << page_order;\r\nbyte_count = 0;\r\nagp_offset = dev->agp->base + request->agp_start;\r\nDRM_DEBUG("count: %d\n", count);\r\nDRM_DEBUG("order: %d\n", order);\r\nDRM_DEBUG("size: %d\n", size);\r\nDRM_DEBUG("agp_offset: %lx\n", agp_offset);\r\nDRM_DEBUG("alignment: %d\n", alignment);\r\nDRM_DEBUG("page_order: %d\n", page_order);\r\nDRM_DEBUG("total: %d\n", total);\r\nif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\r\nreturn -EINVAL;\r\nvalid = 0;\r\nlist_for_each_entry(agp_entry, &dev->agp->memory, head) {\r\nif ((agp_offset >= agp_entry->bound) &&\r\n(agp_offset + total * count <= agp_entry->bound + agp_entry->pages * PAGE_SIZE)) {\r\nvalid = 1;\r\nbreak;\r\n}\r\n}\r\nif (!list_empty(&dev->agp->memory) && !valid) {\r\nDRM_DEBUG("zone invalid\n");\r\nreturn -EINVAL;\r\n}\r\nspin_lock(&dev->count_lock);\r\nif (dev->buf_use) {\r\nspin_unlock(&dev->count_lock);\r\nreturn -EBUSY;\r\n}\r\natomic_inc(&dev->buf_alloc);\r\nspin_unlock(&dev->count_lock);\r\nmutex_lock(&dev->struct_mutex);\r\nentry = &dma->bufs[order];\r\nif (entry->buf_count) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nif (count < 0 || count > 4096) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -EINVAL;\r\n}\r\nentry->buflist = kzalloc(count * sizeof(*entry->buflist), GFP_KERNEL);\r\nif (!entry->buflist) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nentry->buf_size = size;\r\nentry->page_order = page_order;\r\noffset = 0;\r\nwhile (entry->buf_count < count) {\r\nbuf = &entry->buflist[entry->buf_count];\r\nbuf->idx = dma->buf_count + entry->buf_count;\r\nbuf->total = alignment;\r\nbuf->order = order;\r\nbuf->used = 0;\r\nbuf->offset = (dma->byte_count + offset);\r\nbuf->bus_address = agp_offset + offset;\r\nbuf->address = (void *)(agp_offset + offset);\r\nbuf->next = NULL;\r\nbuf->waiting = 0;\r\nbuf->pending = 0;\r\nbuf->file_priv = NULL;\r\nbuf->dev_priv_size = dev->driver->dev_priv_size;\r\nbuf->dev_private = kzalloc(buf->dev_priv_size, GFP_KERNEL);\r\nif (!buf->dev_private) {\r\nentry->buf_count = count;\r\ndrm_cleanup_buf_error(dev, entry);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nDRM_DEBUG("buffer %d @ %p\n", entry->buf_count, buf->address);\r\noffset += alignment;\r\nentry->buf_count++;\r\nbyte_count += PAGE_SIZE << page_order;\r\n}\r\nDRM_DEBUG("byte_count: %d\n", byte_count);\r\ntemp_buflist = krealloc(dma->buflist,\r\n(dma->buf_count + entry->buf_count) *\r\nsizeof(*dma->buflist), GFP_KERNEL);\r\nif (!temp_buflist) {\r\ndrm_cleanup_buf_error(dev, entry);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\ndma->buflist = temp_buflist;\r\nfor (i = 0; i < entry->buf_count; i++) {\r\ndma->buflist[i + dma->buf_count] = &entry->buflist[i];\r\n}\r\ndma->buf_count += entry->buf_count;\r\ndma->seg_count += entry->seg_count;\r\ndma->page_count += byte_count >> PAGE_SHIFT;\r\ndma->byte_count += byte_count;\r\nDRM_DEBUG("dma->buf_count : %d\n", dma->buf_count);\r\nDRM_DEBUG("entry->buf_count : %d\n", entry->buf_count);\r\nmutex_unlock(&dev->struct_mutex);\r\nrequest->count = entry->buf_count;\r\nrequest->size = size;\r\ndma->flags = _DRM_DMA_USE_AGP;\r\natomic_dec(&dev->buf_alloc);\r\nreturn 0;\r\n}\r\nint drm_addbufs_pci(struct drm_device * dev, struct drm_buf_desc * request)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nint count;\r\nint order;\r\nint size;\r\nint total;\r\nint page_order;\r\nstruct drm_buf_entry *entry;\r\ndrm_dma_handle_t *dmah;\r\nstruct drm_buf *buf;\r\nint alignment;\r\nunsigned long offset;\r\nint i;\r\nint byte_count;\r\nint page_count;\r\nunsigned long *temp_pagelist;\r\nstruct drm_buf **temp_buflist;\r\nif (!drm_core_check_feature(dev, DRIVER_PCI_DMA))\r\nreturn -EINVAL;\r\nif (!dma)\r\nreturn -EINVAL;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\ncount = request->count;\r\norder = drm_order(request->size);\r\nsize = 1 << order;\r\nDRM_DEBUG("count=%d, size=%d (%d), order=%d\n",\r\nrequest->count, request->size, size, order);\r\nif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\r\nreturn -EINVAL;\r\nalignment = (request->flags & _DRM_PAGE_ALIGN)\r\n? PAGE_ALIGN(size) : size;\r\npage_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;\r\ntotal = PAGE_SIZE << page_order;\r\nspin_lock(&dev->count_lock);\r\nif (dev->buf_use) {\r\nspin_unlock(&dev->count_lock);\r\nreturn -EBUSY;\r\n}\r\natomic_inc(&dev->buf_alloc);\r\nspin_unlock(&dev->count_lock);\r\nmutex_lock(&dev->struct_mutex);\r\nentry = &dma->bufs[order];\r\nif (entry->buf_count) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nif (count < 0 || count > 4096) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -EINVAL;\r\n}\r\nentry->buflist = kzalloc(count * sizeof(*entry->buflist), GFP_KERNEL);\r\nif (!entry->buflist) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nentry->seglist = kzalloc(count * sizeof(*entry->seglist), GFP_KERNEL);\r\nif (!entry->seglist) {\r\nkfree(entry->buflist);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\ntemp_pagelist = kmalloc((dma->page_count + (count << page_order)) *\r\nsizeof(*dma->pagelist), GFP_KERNEL);\r\nif (!temp_pagelist) {\r\nkfree(entry->buflist);\r\nkfree(entry->seglist);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nmemcpy(temp_pagelist,\r\ndma->pagelist, dma->page_count * sizeof(*dma->pagelist));\r\nDRM_DEBUG("pagelist: %d entries\n",\r\ndma->page_count + (count << page_order));\r\nentry->buf_size = size;\r\nentry->page_order = page_order;\r\nbyte_count = 0;\r\npage_count = 0;\r\nwhile (entry->buf_count < count) {\r\ndmah = drm_pci_alloc(dev, PAGE_SIZE << page_order, 0x1000);\r\nif (!dmah) {\r\nentry->buf_count = count;\r\nentry->seg_count = count;\r\ndrm_cleanup_buf_error(dev, entry);\r\nkfree(temp_pagelist);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nentry->seglist[entry->seg_count++] = dmah;\r\nfor (i = 0; i < (1 << page_order); i++) {\r\nDRM_DEBUG("page %d @ 0x%08lx\n",\r\ndma->page_count + page_count,\r\n(unsigned long)dmah->vaddr + PAGE_SIZE * i);\r\ntemp_pagelist[dma->page_count + page_count++]\r\n= (unsigned long)dmah->vaddr + PAGE_SIZE * i;\r\n}\r\nfor (offset = 0;\r\noffset + size <= total && entry->buf_count < count;\r\noffset += alignment, ++entry->buf_count) {\r\nbuf = &entry->buflist[entry->buf_count];\r\nbuf->idx = dma->buf_count + entry->buf_count;\r\nbuf->total = alignment;\r\nbuf->order = order;\r\nbuf->used = 0;\r\nbuf->offset = (dma->byte_count + byte_count + offset);\r\nbuf->address = (void *)(dmah->vaddr + offset);\r\nbuf->bus_address = dmah->busaddr + offset;\r\nbuf->next = NULL;\r\nbuf->waiting = 0;\r\nbuf->pending = 0;\r\nbuf->file_priv = NULL;\r\nbuf->dev_priv_size = dev->driver->dev_priv_size;\r\nbuf->dev_private = kzalloc(buf->dev_priv_size,\r\nGFP_KERNEL);\r\nif (!buf->dev_private) {\r\nentry->buf_count = count;\r\nentry->seg_count = count;\r\ndrm_cleanup_buf_error(dev, entry);\r\nkfree(temp_pagelist);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nDRM_DEBUG("buffer %d @ %p\n",\r\nentry->buf_count, buf->address);\r\n}\r\nbyte_count += PAGE_SIZE << page_order;\r\n}\r\ntemp_buflist = krealloc(dma->buflist,\r\n(dma->buf_count + entry->buf_count) *\r\nsizeof(*dma->buflist), GFP_KERNEL);\r\nif (!temp_buflist) {\r\ndrm_cleanup_buf_error(dev, entry);\r\nkfree(temp_pagelist);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\ndma->buflist = temp_buflist;\r\nfor (i = 0; i < entry->buf_count; i++) {\r\ndma->buflist[i + dma->buf_count] = &entry->buflist[i];\r\n}\r\nif (dma->page_count) {\r\nkfree(dma->pagelist);\r\n}\r\ndma->pagelist = temp_pagelist;\r\ndma->buf_count += entry->buf_count;\r\ndma->seg_count += entry->seg_count;\r\ndma->page_count += entry->seg_count << page_order;\r\ndma->byte_count += PAGE_SIZE * (entry->seg_count << page_order);\r\nmutex_unlock(&dev->struct_mutex);\r\nrequest->count = entry->buf_count;\r\nrequest->size = size;\r\nif (request->flags & _DRM_PCI_BUFFER_RO)\r\ndma->flags = _DRM_DMA_USE_PCI_RO;\r\natomic_dec(&dev->buf_alloc);\r\nreturn 0;\r\n}\r\nstatic int drm_addbufs_sg(struct drm_device * dev, struct drm_buf_desc * request)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nstruct drm_buf_entry *entry;\r\nstruct drm_buf *buf;\r\nunsigned long offset;\r\nunsigned long agp_offset;\r\nint count;\r\nint order;\r\nint size;\r\nint alignment;\r\nint page_order;\r\nint total;\r\nint byte_count;\r\nint i;\r\nstruct drm_buf **temp_buflist;\r\nif (!drm_core_check_feature(dev, DRIVER_SG))\r\nreturn -EINVAL;\r\nif (!dma)\r\nreturn -EINVAL;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\ncount = request->count;\r\norder = drm_order(request->size);\r\nsize = 1 << order;\r\nalignment = (request->flags & _DRM_PAGE_ALIGN)\r\n? PAGE_ALIGN(size) : size;\r\npage_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;\r\ntotal = PAGE_SIZE << page_order;\r\nbyte_count = 0;\r\nagp_offset = request->agp_start;\r\nDRM_DEBUG("count: %d\n", count);\r\nDRM_DEBUG("order: %d\n", order);\r\nDRM_DEBUG("size: %d\n", size);\r\nDRM_DEBUG("agp_offset: %lu\n", agp_offset);\r\nDRM_DEBUG("alignment: %d\n", alignment);\r\nDRM_DEBUG("page_order: %d\n", page_order);\r\nDRM_DEBUG("total: %d\n", total);\r\nif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\r\nreturn -EINVAL;\r\nspin_lock(&dev->count_lock);\r\nif (dev->buf_use) {\r\nspin_unlock(&dev->count_lock);\r\nreturn -EBUSY;\r\n}\r\natomic_inc(&dev->buf_alloc);\r\nspin_unlock(&dev->count_lock);\r\nmutex_lock(&dev->struct_mutex);\r\nentry = &dma->bufs[order];\r\nif (entry->buf_count) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nif (count < 0 || count > 4096) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -EINVAL;\r\n}\r\nentry->buflist = kzalloc(count * sizeof(*entry->buflist),\r\nGFP_KERNEL);\r\nif (!entry->buflist) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nentry->buf_size = size;\r\nentry->page_order = page_order;\r\noffset = 0;\r\nwhile (entry->buf_count < count) {\r\nbuf = &entry->buflist[entry->buf_count];\r\nbuf->idx = dma->buf_count + entry->buf_count;\r\nbuf->total = alignment;\r\nbuf->order = order;\r\nbuf->used = 0;\r\nbuf->offset = (dma->byte_count + offset);\r\nbuf->bus_address = agp_offset + offset;\r\nbuf->address = (void *)(agp_offset + offset\r\n+ (unsigned long)dev->sg->virtual);\r\nbuf->next = NULL;\r\nbuf->waiting = 0;\r\nbuf->pending = 0;\r\nbuf->file_priv = NULL;\r\nbuf->dev_priv_size = dev->driver->dev_priv_size;\r\nbuf->dev_private = kzalloc(buf->dev_priv_size, GFP_KERNEL);\r\nif (!buf->dev_private) {\r\nentry->buf_count = count;\r\ndrm_cleanup_buf_error(dev, entry);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nDRM_DEBUG("buffer %d @ %p\n", entry->buf_count, buf->address);\r\noffset += alignment;\r\nentry->buf_count++;\r\nbyte_count += PAGE_SIZE << page_order;\r\n}\r\nDRM_DEBUG("byte_count: %d\n", byte_count);\r\ntemp_buflist = krealloc(dma->buflist,\r\n(dma->buf_count + entry->buf_count) *\r\nsizeof(*dma->buflist), GFP_KERNEL);\r\nif (!temp_buflist) {\r\ndrm_cleanup_buf_error(dev, entry);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\ndma->buflist = temp_buflist;\r\nfor (i = 0; i < entry->buf_count; i++) {\r\ndma->buflist[i + dma->buf_count] = &entry->buflist[i];\r\n}\r\ndma->buf_count += entry->buf_count;\r\ndma->seg_count += entry->seg_count;\r\ndma->page_count += byte_count >> PAGE_SHIFT;\r\ndma->byte_count += byte_count;\r\nDRM_DEBUG("dma->buf_count : %d\n", dma->buf_count);\r\nDRM_DEBUG("entry->buf_count : %d\n", entry->buf_count);\r\nmutex_unlock(&dev->struct_mutex);\r\nrequest->count = entry->buf_count;\r\nrequest->size = size;\r\ndma->flags = _DRM_DMA_USE_SG;\r\natomic_dec(&dev->buf_alloc);\r\nreturn 0;\r\n}\r\nstatic int drm_addbufs_fb(struct drm_device * dev, struct drm_buf_desc * request)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nstruct drm_buf_entry *entry;\r\nstruct drm_buf *buf;\r\nunsigned long offset;\r\nunsigned long agp_offset;\r\nint count;\r\nint order;\r\nint size;\r\nint alignment;\r\nint page_order;\r\nint total;\r\nint byte_count;\r\nint i;\r\nstruct drm_buf **temp_buflist;\r\nif (!drm_core_check_feature(dev, DRIVER_FB_DMA))\r\nreturn -EINVAL;\r\nif (!dma)\r\nreturn -EINVAL;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\ncount = request->count;\r\norder = drm_order(request->size);\r\nsize = 1 << order;\r\nalignment = (request->flags & _DRM_PAGE_ALIGN)\r\n? PAGE_ALIGN(size) : size;\r\npage_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;\r\ntotal = PAGE_SIZE << page_order;\r\nbyte_count = 0;\r\nagp_offset = request->agp_start;\r\nDRM_DEBUG("count: %d\n", count);\r\nDRM_DEBUG("order: %d\n", order);\r\nDRM_DEBUG("size: %d\n", size);\r\nDRM_DEBUG("agp_offset: %lu\n", agp_offset);\r\nDRM_DEBUG("alignment: %d\n", alignment);\r\nDRM_DEBUG("page_order: %d\n", page_order);\r\nDRM_DEBUG("total: %d\n", total);\r\nif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\r\nreturn -EINVAL;\r\nspin_lock(&dev->count_lock);\r\nif (dev->buf_use) {\r\nspin_unlock(&dev->count_lock);\r\nreturn -EBUSY;\r\n}\r\natomic_inc(&dev->buf_alloc);\r\nspin_unlock(&dev->count_lock);\r\nmutex_lock(&dev->struct_mutex);\r\nentry = &dma->bufs[order];\r\nif (entry->buf_count) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nif (count < 0 || count > 4096) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -EINVAL;\r\n}\r\nentry->buflist = kzalloc(count * sizeof(*entry->buflist),\r\nGFP_KERNEL);\r\nif (!entry->buflist) {\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nentry->buf_size = size;\r\nentry->page_order = page_order;\r\noffset = 0;\r\nwhile (entry->buf_count < count) {\r\nbuf = &entry->buflist[entry->buf_count];\r\nbuf->idx = dma->buf_count + entry->buf_count;\r\nbuf->total = alignment;\r\nbuf->order = order;\r\nbuf->used = 0;\r\nbuf->offset = (dma->byte_count + offset);\r\nbuf->bus_address = agp_offset + offset;\r\nbuf->address = (void *)(agp_offset + offset);\r\nbuf->next = NULL;\r\nbuf->waiting = 0;\r\nbuf->pending = 0;\r\nbuf->file_priv = NULL;\r\nbuf->dev_priv_size = dev->driver->dev_priv_size;\r\nbuf->dev_private = kzalloc(buf->dev_priv_size, GFP_KERNEL);\r\nif (!buf->dev_private) {\r\nentry->buf_count = count;\r\ndrm_cleanup_buf_error(dev, entry);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\nDRM_DEBUG("buffer %d @ %p\n", entry->buf_count, buf->address);\r\noffset += alignment;\r\nentry->buf_count++;\r\nbyte_count += PAGE_SIZE << page_order;\r\n}\r\nDRM_DEBUG("byte_count: %d\n", byte_count);\r\ntemp_buflist = krealloc(dma->buflist,\r\n(dma->buf_count + entry->buf_count) *\r\nsizeof(*dma->buflist), GFP_KERNEL);\r\nif (!temp_buflist) {\r\ndrm_cleanup_buf_error(dev, entry);\r\nmutex_unlock(&dev->struct_mutex);\r\natomic_dec(&dev->buf_alloc);\r\nreturn -ENOMEM;\r\n}\r\ndma->buflist = temp_buflist;\r\nfor (i = 0; i < entry->buf_count; i++) {\r\ndma->buflist[i + dma->buf_count] = &entry->buflist[i];\r\n}\r\ndma->buf_count += entry->buf_count;\r\ndma->seg_count += entry->seg_count;\r\ndma->page_count += byte_count >> PAGE_SHIFT;\r\ndma->byte_count += byte_count;\r\nDRM_DEBUG("dma->buf_count : %d\n", dma->buf_count);\r\nDRM_DEBUG("entry->buf_count : %d\n", entry->buf_count);\r\nmutex_unlock(&dev->struct_mutex);\r\nrequest->count = entry->buf_count;\r\nrequest->size = size;\r\ndma->flags = _DRM_DMA_USE_FB;\r\natomic_dec(&dev->buf_alloc);\r\nreturn 0;\r\n}\r\nint drm_addbufs(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_buf_desc *request = data;\r\nint ret;\r\nif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\r\nreturn -EINVAL;\r\n#if __OS_HAS_AGP\r\nif (request->flags & _DRM_AGP_BUFFER)\r\nret = drm_addbufs_agp(dev, request);\r\nelse\r\n#endif\r\nif (request->flags & _DRM_SG_BUFFER)\r\nret = drm_addbufs_sg(dev, request);\r\nelse if (request->flags & _DRM_FB_BUFFER)\r\nret = drm_addbufs_fb(dev, request);\r\nelse\r\nret = drm_addbufs_pci(dev, request);\r\nreturn ret;\r\n}\r\nint drm_infobufs(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nstruct drm_buf_info *request = data;\r\nint i;\r\nint count;\r\nif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\r\nreturn -EINVAL;\r\nif (!dma)\r\nreturn -EINVAL;\r\nspin_lock(&dev->count_lock);\r\nif (atomic_read(&dev->buf_alloc)) {\r\nspin_unlock(&dev->count_lock);\r\nreturn -EBUSY;\r\n}\r\n++dev->buf_use;\r\nspin_unlock(&dev->count_lock);\r\nfor (i = 0, count = 0; i < DRM_MAX_ORDER + 1; i++) {\r\nif (dma->bufs[i].buf_count)\r\n++count;\r\n}\r\nDRM_DEBUG("count = %d\n", count);\r\nif (request->count >= count) {\r\nfor (i = 0, count = 0; i < DRM_MAX_ORDER + 1; i++) {\r\nif (dma->bufs[i].buf_count) {\r\nstruct drm_buf_desc __user *to =\r\n&request->list[count];\r\nstruct drm_buf_entry *from = &dma->bufs[i];\r\nstruct drm_freelist *list = &dma->bufs[i].freelist;\r\nif (copy_to_user(&to->count,\r\n&from->buf_count,\r\nsizeof(from->buf_count)) ||\r\ncopy_to_user(&to->size,\r\n&from->buf_size,\r\nsizeof(from->buf_size)) ||\r\ncopy_to_user(&to->low_mark,\r\n&list->low_mark,\r\nsizeof(list->low_mark)) ||\r\ncopy_to_user(&to->high_mark,\r\n&list->high_mark,\r\nsizeof(list->high_mark)))\r\nreturn -EFAULT;\r\nDRM_DEBUG("%d %d %d %d %d\n",\r\ni,\r\ndma->bufs[i].buf_count,\r\ndma->bufs[i].buf_size,\r\ndma->bufs[i].freelist.low_mark,\r\ndma->bufs[i].freelist.high_mark);\r\n++count;\r\n}\r\n}\r\n}\r\nrequest->count = count;\r\nreturn 0;\r\n}\r\nint drm_markbufs(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nstruct drm_buf_desc *request = data;\r\nint order;\r\nstruct drm_buf_entry *entry;\r\nif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\r\nreturn -EINVAL;\r\nif (!dma)\r\nreturn -EINVAL;\r\nDRM_DEBUG("%d, %d, %d\n",\r\nrequest->size, request->low_mark, request->high_mark);\r\norder = drm_order(request->size);\r\nif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\r\nreturn -EINVAL;\r\nentry = &dma->bufs[order];\r\nif (request->low_mark < 0 || request->low_mark > entry->buf_count)\r\nreturn -EINVAL;\r\nif (request->high_mark < 0 || request->high_mark > entry->buf_count)\r\nreturn -EINVAL;\r\nentry->freelist.low_mark = request->low_mark;\r\nentry->freelist.high_mark = request->high_mark;\r\nreturn 0;\r\n}\r\nint drm_freebufs(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nstruct drm_buf_free *request = data;\r\nint i;\r\nint idx;\r\nstruct drm_buf *buf;\r\nif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\r\nreturn -EINVAL;\r\nif (!dma)\r\nreturn -EINVAL;\r\nDRM_DEBUG("%d\n", request->count);\r\nfor (i = 0; i < request->count; i++) {\r\nif (copy_from_user(&idx, &request->list[i], sizeof(idx)))\r\nreturn -EFAULT;\r\nif (idx < 0 || idx >= dma->buf_count) {\r\nDRM_ERROR("Index %d (of %d max)\n",\r\nidx, dma->buf_count - 1);\r\nreturn -EINVAL;\r\n}\r\nbuf = dma->buflist[idx];\r\nif (buf->file_priv != file_priv) {\r\nDRM_ERROR("Process %d freeing buffer not owned\n",\r\ntask_pid_nr(current));\r\nreturn -EINVAL;\r\n}\r\ndrm_free_buffer(dev, buf);\r\n}\r\nreturn 0;\r\n}\r\nint drm_mapbufs(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_device_dma *dma = dev->dma;\r\nint retcode = 0;\r\nconst int zero = 0;\r\nunsigned long virtual;\r\nunsigned long address;\r\nstruct drm_buf_map *request = data;\r\nint i;\r\nif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\r\nreturn -EINVAL;\r\nif (!dma)\r\nreturn -EINVAL;\r\nspin_lock(&dev->count_lock);\r\nif (atomic_read(&dev->buf_alloc)) {\r\nspin_unlock(&dev->count_lock);\r\nreturn -EBUSY;\r\n}\r\ndev->buf_use++;\r\nspin_unlock(&dev->count_lock);\r\nif (request->count >= dma->buf_count) {\r\nif ((drm_core_has_AGP(dev) && (dma->flags & _DRM_DMA_USE_AGP))\r\n|| (drm_core_check_feature(dev, DRIVER_SG)\r\n&& (dma->flags & _DRM_DMA_USE_SG))\r\n|| (drm_core_check_feature(dev, DRIVER_FB_DMA)\r\n&& (dma->flags & _DRM_DMA_USE_FB))) {\r\nstruct drm_local_map *map = dev->agp_buffer_map;\r\nunsigned long token = dev->agp_buffer_token;\r\nif (!map) {\r\nretcode = -EINVAL;\r\ngoto done;\r\n}\r\nvirtual = vm_mmap(file_priv->filp, 0, map->size,\r\nPROT_READ | PROT_WRITE,\r\nMAP_SHARED,\r\ntoken);\r\n} else {\r\nvirtual = vm_mmap(file_priv->filp, 0, dma->byte_count,\r\nPROT_READ | PROT_WRITE,\r\nMAP_SHARED, 0);\r\n}\r\nif (virtual > -1024UL) {\r\nretcode = (signed long)virtual;\r\ngoto done;\r\n}\r\nrequest->virtual = (void __user *)virtual;\r\nfor (i = 0; i < dma->buf_count; i++) {\r\nif (copy_to_user(&request->list[i].idx,\r\n&dma->buflist[i]->idx,\r\nsizeof(request->list[0].idx))) {\r\nretcode = -EFAULT;\r\ngoto done;\r\n}\r\nif (copy_to_user(&request->list[i].total,\r\n&dma->buflist[i]->total,\r\nsizeof(request->list[0].total))) {\r\nretcode = -EFAULT;\r\ngoto done;\r\n}\r\nif (copy_to_user(&request->list[i].used,\r\n&zero, sizeof(zero))) {\r\nretcode = -EFAULT;\r\ngoto done;\r\n}\r\naddress = virtual + dma->buflist[i]->offset;\r\nif (copy_to_user(&request->list[i].address,\r\n&address, sizeof(address))) {\r\nretcode = -EFAULT;\r\ngoto done;\r\n}\r\n}\r\n}\r\ndone:\r\nrequest->count = dma->buf_count;\r\nDRM_DEBUG("%d buffers, retcode = %d\n", request->count, retcode);\r\nreturn retcode;\r\n}\r\nint drm_order(unsigned long size)\r\n{\r\nint order;\r\nunsigned long tmp;\r\nfor (order = 0, tmp = size >> 1; tmp; tmp >>= 1, order++) ;\r\nif (size & (size - 1))\r\n++order;\r\nreturn order;\r\n}
