static inline void tgt_ring_idx_inc(struct tgt_ring *ring)\r\n{\r\nif (ring->tr_idx == TGT_MAX_EVENTS - 1)\r\nring->tr_idx = 0;\r\nelse\r\nring->tr_idx++;\r\n}\r\nstatic struct tgt_event *tgt_head_event(struct tgt_ring *ring, u32 idx)\r\n{\r\nu32 pidx, off;\r\npidx = idx / TGT_EVENT_PER_PAGE;\r\noff = idx % TGT_EVENT_PER_PAGE;\r\nreturn (struct tgt_event *)\r\n(ring->tr_pages[pidx] + sizeof(struct tgt_event) * off);\r\n}\r\nstatic int tgt_uspace_send_event(u32 type, struct tgt_event *p)\r\n{\r\nstruct tgt_event *ev;\r\nstruct tgt_ring *ring = &tx_ring;\r\nunsigned long flags;\r\nint err = 0;\r\nspin_lock_irqsave(&ring->tr_lock, flags);\r\nev = tgt_head_event(ring, ring->tr_idx);\r\nif (!ev->hdr.status)\r\ntgt_ring_idx_inc(ring);\r\nelse\r\nerr = -BUSY;\r\nspin_unlock_irqrestore(&ring->tr_lock, flags);\r\nif (err)\r\nreturn err;\r\nmemcpy(ev, p, sizeof(*ev));\r\nev->hdr.type = type;\r\nmb();\r\nev->hdr.status = 1;\r\nflush_dcache_page(virt_to_page(ev));\r\nwake_up_interruptible(&tgt_poll_wait);\r\nreturn 0;\r\n}\r\nint scsi_tgt_uspace_send_cmd(struct scsi_cmnd *cmd, u64 itn_id,\r\nstruct scsi_lun *lun, u64 tag)\r\n{\r\nstruct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);\r\nstruct tgt_event ev;\r\nint err;\r\nmemset(&ev, 0, sizeof(ev));\r\nev.p.cmd_req.host_no = shost->host_no;\r\nev.p.cmd_req.itn_id = itn_id;\r\nev.p.cmd_req.data_len = scsi_bufflen(cmd);\r\nmemcpy(ev.p.cmd_req.scb, cmd->cmnd, sizeof(ev.p.cmd_req.scb));\r\nmemcpy(ev.p.cmd_req.lun, lun, sizeof(ev.p.cmd_req.lun));\r\nev.p.cmd_req.attribute = cmd->tag;\r\nev.p.cmd_req.tag = tag;\r\ndprintk("%p %d %u %x %llx\n", cmd, shost->host_no,\r\nev.p.cmd_req.data_len, cmd->tag,\r\n(unsigned long long) ev.p.cmd_req.tag);\r\nerr = tgt_uspace_send_event(TGT_KEVENT_CMD_REQ, &ev);\r\nif (err)\r\neprintk("tx buf is full, could not send\n");\r\nreturn err;\r\n}\r\nint scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, u64 itn_id, u64 tag)\r\n{\r\nstruct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);\r\nstruct tgt_event ev;\r\nint err;\r\nmemset(&ev, 0, sizeof(ev));\r\nev.p.cmd_done.host_no = shost->host_no;\r\nev.p.cmd_done.itn_id = itn_id;\r\nev.p.cmd_done.tag = tag;\r\nev.p.cmd_done.result = cmd->result;\r\ndprintk("%p %d %llu %u %x\n", cmd, shost->host_no,\r\n(unsigned long long) ev.p.cmd_req.tag,\r\nev.p.cmd_req.data_len, cmd->tag);\r\nerr = tgt_uspace_send_event(TGT_KEVENT_CMD_DONE, &ev);\r\nif (err)\r\neprintk("tx buf is full, could not send\n");\r\nreturn err;\r\n}\r\nint scsi_tgt_uspace_send_tsk_mgmt(int host_no, u64 itn_id, int function,\r\nu64 tag, struct scsi_lun *scsilun, void *data)\r\n{\r\nstruct tgt_event ev;\r\nint err;\r\nmemset(&ev, 0, sizeof(ev));\r\nev.p.tsk_mgmt_req.host_no = host_no;\r\nev.p.tsk_mgmt_req.itn_id = itn_id;\r\nev.p.tsk_mgmt_req.function = function;\r\nev.p.tsk_mgmt_req.tag = tag;\r\nmemcpy(ev.p.tsk_mgmt_req.lun, scsilun, sizeof(ev.p.tsk_mgmt_req.lun));\r\nev.p.tsk_mgmt_req.mid = (u64) (unsigned long) data;\r\ndprintk("%d %x %llx %llx\n", host_no, function, (unsigned long long) tag,\r\n(unsigned long long) ev.p.tsk_mgmt_req.mid);\r\nerr = tgt_uspace_send_event(TGT_KEVENT_TSK_MGMT_REQ, &ev);\r\nif (err)\r\neprintk("tx buf is full, could not send\n");\r\nreturn err;\r\n}\r\nint scsi_tgt_uspace_send_it_nexus_request(int host_no, u64 itn_id,\r\nint function, char *initiator_id)\r\n{\r\nstruct tgt_event ev;\r\nint err;\r\nmemset(&ev, 0, sizeof(ev));\r\nev.p.it_nexus_req.host_no = host_no;\r\nev.p.it_nexus_req.function = function;\r\nev.p.it_nexus_req.itn_id = itn_id;\r\nif (initiator_id)\r\nstrncpy(ev.p.it_nexus_req.initiator_id, initiator_id,\r\nsizeof(ev.p.it_nexus_req.initiator_id));\r\ndprintk("%d %x %llx\n", host_no, function, (unsigned long long)itn_id);\r\nerr = tgt_uspace_send_event(TGT_KEVENT_IT_NEXUS_REQ, &ev);\r\nif (err)\r\neprintk("tx buf is full, could not send\n");\r\nreturn err;\r\n}\r\nstatic int event_recv_msg(struct tgt_event *ev)\r\n{\r\nint err = 0;\r\nswitch (ev->hdr.type) {\r\ncase TGT_UEVENT_CMD_RSP:\r\nerr = scsi_tgt_kspace_exec(ev->p.cmd_rsp.host_no,\r\nev->p.cmd_rsp.itn_id,\r\nev->p.cmd_rsp.result,\r\nev->p.cmd_rsp.tag,\r\nev->p.cmd_rsp.uaddr,\r\nev->p.cmd_rsp.len,\r\nev->p.cmd_rsp.sense_uaddr,\r\nev->p.cmd_rsp.sense_len,\r\nev->p.cmd_rsp.rw);\r\nbreak;\r\ncase TGT_UEVENT_TSK_MGMT_RSP:\r\nerr = scsi_tgt_kspace_tsk_mgmt(ev->p.tsk_mgmt_rsp.host_no,\r\nev->p.tsk_mgmt_rsp.itn_id,\r\nev->p.tsk_mgmt_rsp.mid,\r\nev->p.tsk_mgmt_rsp.result);\r\nbreak;\r\ncase TGT_UEVENT_IT_NEXUS_RSP:\r\nerr = scsi_tgt_kspace_it_nexus_rsp(ev->p.it_nexus_rsp.host_no,\r\nev->p.it_nexus_rsp.itn_id,\r\nev->p.it_nexus_rsp.result);\r\nbreak;\r\ndefault:\r\neprintk("unknown type %d\n", ev->hdr.type);\r\nerr = -EINVAL;\r\n}\r\nreturn err;\r\n}\r\nstatic ssize_t tgt_write(struct file *file, const char __user * buffer,\r\nsize_t count, loff_t * ppos)\r\n{\r\nstruct tgt_event *ev;\r\nstruct tgt_ring *ring = &rx_ring;\r\nwhile (1) {\r\nev = tgt_head_event(ring, ring->tr_idx);\r\nflush_dcache_page(virt_to_page(ev));\r\nif (!ev->hdr.status)\r\nbreak;\r\ntgt_ring_idx_inc(ring);\r\nevent_recv_msg(ev);\r\nev->hdr.status = 0;\r\n};\r\nreturn count;\r\n}\r\nstatic unsigned int tgt_poll(struct file * file, struct poll_table_struct *wait)\r\n{\r\nstruct tgt_event *ev;\r\nstruct tgt_ring *ring = &tx_ring;\r\nunsigned long flags;\r\nunsigned int mask = 0;\r\nu32 idx;\r\npoll_wait(file, &tgt_poll_wait, wait);\r\nspin_lock_irqsave(&ring->tr_lock, flags);\r\nidx = ring->tr_idx ? ring->tr_idx - 1 : TGT_MAX_EVENTS - 1;\r\nev = tgt_head_event(ring, idx);\r\nif (ev->hdr.status)\r\nmask |= POLLIN | POLLRDNORM;\r\nspin_unlock_irqrestore(&ring->tr_lock, flags);\r\nreturn mask;\r\n}\r\nstatic int uspace_ring_map(struct vm_area_struct *vma, unsigned long addr,\r\nstruct tgt_ring *ring)\r\n{\r\nint i, err;\r\nfor (i = 0; i < TGT_RING_PAGES; i++) {\r\nstruct page *page = virt_to_page(ring->tr_pages[i]);\r\nerr = vm_insert_page(vma, addr, page);\r\nif (err)\r\nreturn err;\r\naddr += PAGE_SIZE;\r\n}\r\nreturn 0;\r\n}\r\nstatic int tgt_mmap(struct file *filp, struct vm_area_struct *vma)\r\n{\r\nunsigned long addr;\r\nint err;\r\nif (vma->vm_pgoff)\r\nreturn -EINVAL;\r\nif (vma->vm_end - vma->vm_start != TGT_RING_SIZE * 2) {\r\neprintk("mmap size must be %lu, not %lu \n",\r\nTGT_RING_SIZE * 2, vma->vm_end - vma->vm_start);\r\nreturn -EINVAL;\r\n}\r\naddr = vma->vm_start;\r\nerr = uspace_ring_map(vma, addr, &tx_ring);\r\nif (err)\r\nreturn err;\r\nerr = uspace_ring_map(vma, addr + TGT_RING_SIZE, &rx_ring);\r\nreturn err;\r\n}\r\nstatic int tgt_open(struct inode *inode, struct file *file)\r\n{\r\ntx_ring.tr_idx = rx_ring.tr_idx = 0;\r\nreturn 0;\r\n}\r\nstatic void tgt_ring_exit(struct tgt_ring *ring)\r\n{\r\nint i;\r\nfor (i = 0; i < TGT_RING_PAGES; i++)\r\nfree_page(ring->tr_pages[i]);\r\n}\r\nstatic int tgt_ring_init(struct tgt_ring *ring)\r\n{\r\nint i;\r\nspin_lock_init(&ring->tr_lock);\r\nfor (i = 0; i < TGT_RING_PAGES; i++) {\r\nring->tr_pages[i] = get_zeroed_page(GFP_KERNEL);\r\nif (!ring->tr_pages[i]) {\r\neprintk("out of memory\n");\r\nreturn -ENOMEM;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid scsi_tgt_if_exit(void)\r\n{\r\ntgt_ring_exit(&tx_ring);\r\ntgt_ring_exit(&rx_ring);\r\nmisc_deregister(&tgt_miscdev);\r\n}\r\nint scsi_tgt_if_init(void)\r\n{\r\nint err;\r\nerr = tgt_ring_init(&tx_ring);\r\nif (err)\r\nreturn err;\r\nerr = tgt_ring_init(&rx_ring);\r\nif (err)\r\ngoto free_tx_ring;\r\nerr = misc_register(&tgt_miscdev);\r\nif (err)\r\ngoto free_rx_ring;\r\nreturn 0;\r\nfree_rx_ring:\r\ntgt_ring_exit(&rx_ring);\r\nfree_tx_ring:\r\ntgt_ring_exit(&tx_ring);\r\nreturn err;\r\n}
