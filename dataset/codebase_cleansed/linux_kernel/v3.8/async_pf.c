int kvm_async_pf_init(void)\r\n{\r\nasync_pf_cache = KMEM_CACHE(kvm_async_pf, 0);\r\nif (!async_pf_cache)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid kvm_async_pf_deinit(void)\r\n{\r\nif (async_pf_cache)\r\nkmem_cache_destroy(async_pf_cache);\r\nasync_pf_cache = NULL;\r\n}\r\nvoid kvm_async_pf_vcpu_init(struct kvm_vcpu *vcpu)\r\n{\r\nINIT_LIST_HEAD(&vcpu->async_pf.done);\r\nINIT_LIST_HEAD(&vcpu->async_pf.queue);\r\nspin_lock_init(&vcpu->async_pf.lock);\r\n}\r\nstatic void async_pf_execute(struct work_struct *work)\r\n{\r\nstruct page *page = NULL;\r\nstruct kvm_async_pf *apf =\r\ncontainer_of(work, struct kvm_async_pf, work);\r\nstruct mm_struct *mm = apf->mm;\r\nstruct kvm_vcpu *vcpu = apf->vcpu;\r\nunsigned long addr = apf->addr;\r\ngva_t gva = apf->gva;\r\nmight_sleep();\r\nuse_mm(mm);\r\ndown_read(&mm->mmap_sem);\r\nget_user_pages(current, mm, addr, 1, 1, 0, &page, NULL);\r\nup_read(&mm->mmap_sem);\r\nunuse_mm(mm);\r\nspin_lock(&vcpu->async_pf.lock);\r\nlist_add_tail(&apf->link, &vcpu->async_pf.done);\r\napf->page = page;\r\napf->done = true;\r\nspin_unlock(&vcpu->async_pf.lock);\r\ntrace_kvm_async_pf_completed(addr, page, gva);\r\nif (waitqueue_active(&vcpu->wq))\r\nwake_up_interruptible(&vcpu->wq);\r\nmmdrop(mm);\r\nkvm_put_kvm(vcpu->kvm);\r\n}\r\nvoid kvm_clear_async_pf_completion_queue(struct kvm_vcpu *vcpu)\r\n{\r\nwhile (!list_empty(&vcpu->async_pf.queue)) {\r\nstruct kvm_async_pf *work =\r\nlist_entry(vcpu->async_pf.queue.next,\r\ntypeof(*work), queue);\r\ncancel_work_sync(&work->work);\r\nlist_del(&work->queue);\r\nif (!work->done)\r\nkmem_cache_free(async_pf_cache, work);\r\n}\r\nspin_lock(&vcpu->async_pf.lock);\r\nwhile (!list_empty(&vcpu->async_pf.done)) {\r\nstruct kvm_async_pf *work =\r\nlist_entry(vcpu->async_pf.done.next,\r\ntypeof(*work), link);\r\nlist_del(&work->link);\r\nif (!is_error_page(work->page))\r\nkvm_release_page_clean(work->page);\r\nkmem_cache_free(async_pf_cache, work);\r\n}\r\nspin_unlock(&vcpu->async_pf.lock);\r\nvcpu->async_pf.queued = 0;\r\n}\r\nvoid kvm_check_async_pf_completion(struct kvm_vcpu *vcpu)\r\n{\r\nstruct kvm_async_pf *work;\r\nwhile (!list_empty_careful(&vcpu->async_pf.done) &&\r\nkvm_arch_can_inject_async_page_present(vcpu)) {\r\nspin_lock(&vcpu->async_pf.lock);\r\nwork = list_first_entry(&vcpu->async_pf.done, typeof(*work),\r\nlink);\r\nlist_del(&work->link);\r\nspin_unlock(&vcpu->async_pf.lock);\r\nif (work->page)\r\nkvm_arch_async_page_ready(vcpu, work);\r\nkvm_arch_async_page_present(vcpu, work);\r\nlist_del(&work->queue);\r\nvcpu->async_pf.queued--;\r\nif (!is_error_page(work->page))\r\nkvm_release_page_clean(work->page);\r\nkmem_cache_free(async_pf_cache, work);\r\n}\r\n}\r\nint kvm_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn,\r\nstruct kvm_arch_async_pf *arch)\r\n{\r\nstruct kvm_async_pf *work;\r\nif (vcpu->async_pf.queued >= ASYNC_PF_PER_VCPU)\r\nreturn 0;\r\nwork = kmem_cache_zalloc(async_pf_cache, GFP_NOWAIT);\r\nif (!work)\r\nreturn 0;\r\nwork->page = NULL;\r\nwork->done = false;\r\nwork->vcpu = vcpu;\r\nwork->gva = gva;\r\nwork->addr = gfn_to_hva(vcpu->kvm, gfn);\r\nwork->arch = *arch;\r\nwork->mm = current->mm;\r\natomic_inc(&work->mm->mm_count);\r\nkvm_get_kvm(work->vcpu->kvm);\r\nif (unlikely(kvm_is_error_hva(work->addr)))\r\ngoto retry_sync;\r\nINIT_WORK(&work->work, async_pf_execute);\r\nif (!schedule_work(&work->work))\r\ngoto retry_sync;\r\nlist_add_tail(&work->queue, &vcpu->async_pf.queue);\r\nvcpu->async_pf.queued++;\r\nkvm_arch_async_page_not_present(vcpu, work);\r\nreturn 1;\r\nretry_sync:\r\nkvm_put_kvm(work->vcpu->kvm);\r\nmmdrop(work->mm);\r\nkmem_cache_free(async_pf_cache, work);\r\nreturn 0;\r\n}\r\nint kvm_async_pf_wakeup_all(struct kvm_vcpu *vcpu)\r\n{\r\nstruct kvm_async_pf *work;\r\nif (!list_empty_careful(&vcpu->async_pf.done))\r\nreturn 0;\r\nwork = kmem_cache_zalloc(async_pf_cache, GFP_ATOMIC);\r\nif (!work)\r\nreturn -ENOMEM;\r\nwork->page = KVM_ERR_PTR_BAD_PAGE;\r\nINIT_LIST_HEAD(&work->queue);\r\nspin_lock(&vcpu->async_pf.lock);\r\nlist_add_tail(&work->link, &vcpu->async_pf.done);\r\nspin_unlock(&vcpu->async_pf.lock);\r\nvcpu->async_pf.queued++;\r\nreturn 0;\r\n}
