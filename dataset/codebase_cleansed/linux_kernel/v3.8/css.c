int\r\nfor_each_subchannel(int(*fn)(struct subchannel_id, void *), void *data)\r\n{\r\nstruct subchannel_id schid;\r\nint ret;\r\ninit_subchannel_id(&schid);\r\nret = -ENODEV;\r\ndo {\r\ndo {\r\nret = fn(schid, data);\r\nif (ret)\r\nbreak;\r\n} while (schid.sch_no++ < __MAX_SUBCHANNEL);\r\nschid.sch_no = 0;\r\n} while (schid.ssid++ < max_ssid);\r\nreturn ret;\r\n}\r\nstatic int call_fn_known_sch(struct device *dev, void *data)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nstruct cb_data *cb = data;\r\nint rc = 0;\r\nidset_sch_del(cb->set, sch->schid);\r\nif (cb->fn_known_sch)\r\nrc = cb->fn_known_sch(sch, cb->data);\r\nreturn rc;\r\n}\r\nstatic int call_fn_unknown_sch(struct subchannel_id schid, void *data)\r\n{\r\nstruct cb_data *cb = data;\r\nint rc = 0;\r\nif (idset_sch_contains(cb->set, schid))\r\nrc = cb->fn_unknown_sch(schid, cb->data);\r\nreturn rc;\r\n}\r\nstatic int call_fn_all_sch(struct subchannel_id schid, void *data)\r\n{\r\nstruct cb_data *cb = data;\r\nstruct subchannel *sch;\r\nint rc = 0;\r\nsch = get_subchannel_by_schid(schid);\r\nif (sch) {\r\nif (cb->fn_known_sch)\r\nrc = cb->fn_known_sch(sch, cb->data);\r\nput_device(&sch->dev);\r\n} else {\r\nif (cb->fn_unknown_sch)\r\nrc = cb->fn_unknown_sch(schid, cb->data);\r\n}\r\nreturn rc;\r\n}\r\nint for_each_subchannel_staged(int (*fn_known)(struct subchannel *, void *),\r\nint (*fn_unknown)(struct subchannel_id,\r\nvoid *), void *data)\r\n{\r\nstruct cb_data cb;\r\nint rc;\r\ncb.data = data;\r\ncb.fn_known_sch = fn_known;\r\ncb.fn_unknown_sch = fn_unknown;\r\ncb.set = idset_sch_new();\r\nif (!cb.set)\r\nreturn for_each_subchannel(call_fn_all_sch, &cb);\r\nidset_fill(cb.set);\r\nrc = bus_for_each_dev(&css_bus_type, NULL, &cb, call_fn_known_sch);\r\nif (rc)\r\ngoto out;\r\nif (fn_unknown)\r\nrc = for_each_subchannel(call_fn_unknown_sch, &cb);\r\nout:\r\nidset_free(cb.set);\r\nreturn rc;\r\n}\r\nstatic struct subchannel *\r\ncss_alloc_subchannel(struct subchannel_id schid)\r\n{\r\nstruct subchannel *sch;\r\nint ret;\r\nsch = kmalloc (sizeof (*sch), GFP_KERNEL | GFP_DMA);\r\nif (sch == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nret = cio_validate_subchannel (sch, schid);\r\nif (ret < 0) {\r\nkfree(sch);\r\nreturn ERR_PTR(ret);\r\n}\r\nINIT_WORK(&sch->todo_work, css_sch_todo);\r\nreturn sch;\r\n}\r\nstatic void\r\ncss_subchannel_release(struct device *dev)\r\n{\r\nstruct subchannel *sch;\r\nsch = to_subchannel(dev);\r\nif (!cio_is_console(sch->schid)) {\r\nsch->config.intparm = 0;\r\ncio_commit_config(sch);\r\nkfree(sch->lock);\r\nkfree(sch);\r\n}\r\n}\r\nstatic int css_sch_device_register(struct subchannel *sch)\r\n{\r\nint ret;\r\nmutex_lock(&sch->reg_mutex);\r\ndev_set_name(&sch->dev, "0.%x.%04x", sch->schid.ssid,\r\nsch->schid.sch_no);\r\nret = device_register(&sch->dev);\r\nmutex_unlock(&sch->reg_mutex);\r\nreturn ret;\r\n}\r\nvoid css_sch_device_unregister(struct subchannel *sch)\r\n{\r\nmutex_lock(&sch->reg_mutex);\r\nif (device_is_registered(&sch->dev))\r\ndevice_unregister(&sch->dev);\r\nmutex_unlock(&sch->reg_mutex);\r\n}\r\nstatic void ssd_from_pmcw(struct chsc_ssd_info *ssd, struct pmcw *pmcw)\r\n{\r\nint i;\r\nint mask;\r\nmemset(ssd, 0, sizeof(struct chsc_ssd_info));\r\nssd->path_mask = pmcw->pim;\r\nfor (i = 0; i < 8; i++) {\r\nmask = 0x80 >> i;\r\nif (pmcw->pim & mask) {\r\nchp_id_init(&ssd->chpid[i]);\r\nssd->chpid[i].id = pmcw->chpid[i];\r\n}\r\n}\r\n}\r\nstatic void ssd_register_chpids(struct chsc_ssd_info *ssd)\r\n{\r\nint i;\r\nint mask;\r\nfor (i = 0; i < 8; i++) {\r\nmask = 0x80 >> i;\r\nif (ssd->path_mask & mask)\r\nif (!chp_is_registered(ssd->chpid[i]))\r\nchp_new(ssd->chpid[i]);\r\n}\r\n}\r\nvoid css_update_ssd_info(struct subchannel *sch)\r\n{\r\nint ret;\r\nif (cio_is_console(sch->schid)) {\r\nssd_from_pmcw(&sch->ssd_info, &sch->schib.pmcw);\r\n} else {\r\nret = chsc_get_ssd_info(sch->schid, &sch->ssd_info);\r\nif (ret)\r\nssd_from_pmcw(&sch->ssd_info, &sch->schib.pmcw);\r\nssd_register_chpids(&sch->ssd_info);\r\n}\r\n}\r\nstatic ssize_t type_show(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nreturn sprintf(buf, "%01x\n", sch->st);\r\n}\r\nstatic ssize_t modalias_show(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nreturn sprintf(buf, "css:t%01X\n", sch->st);\r\n}\r\nstatic int css_register_subchannel(struct subchannel *sch)\r\n{\r\nint ret;\r\nsch->dev.parent = &channel_subsystems[0]->device;\r\nsch->dev.bus = &css_bus_type;\r\nsch->dev.release = &css_subchannel_release;\r\nsch->dev.groups = default_subch_attr_groups;\r\ndev_set_uevent_suppress(&sch->dev, 1);\r\ncss_update_ssd_info(sch);\r\nret = css_sch_device_register(sch);\r\nif (ret) {\r\nCIO_MSG_EVENT(0, "Could not register sch 0.%x.%04x: %d\n",\r\nsch->schid.ssid, sch->schid.sch_no, ret);\r\nreturn ret;\r\n}\r\nif (!sch->driver) {\r\ndev_set_uevent_suppress(&sch->dev, 0);\r\nkobject_uevent(&sch->dev.kobj, KOBJ_ADD);\r\n}\r\nreturn ret;\r\n}\r\nint css_probe_device(struct subchannel_id schid)\r\n{\r\nint ret;\r\nstruct subchannel *sch;\r\nif (cio_is_console(schid))\r\nsch = cio_get_console_subchannel();\r\nelse {\r\nsch = css_alloc_subchannel(schid);\r\nif (IS_ERR(sch))\r\nreturn PTR_ERR(sch);\r\n}\r\nret = css_register_subchannel(sch);\r\nif (ret) {\r\nif (!cio_is_console(schid))\r\nput_device(&sch->dev);\r\n}\r\nreturn ret;\r\n}\r\nstatic int\r\ncheck_subchannel(struct device * dev, void * data)\r\n{\r\nstruct subchannel *sch;\r\nstruct subchannel_id *schid = data;\r\nsch = to_subchannel(dev);\r\nreturn schid_equal(&sch->schid, schid);\r\n}\r\nstruct subchannel *\r\nget_subchannel_by_schid(struct subchannel_id schid)\r\n{\r\nstruct device *dev;\r\ndev = bus_find_device(&css_bus_type, NULL,\r\n&schid, check_subchannel);\r\nreturn dev ? to_subchannel(dev) : NULL;\r\n}\r\nint css_sch_is_valid(struct schib *schib)\r\n{\r\nif ((schib->pmcw.st == SUBCHANNEL_TYPE_IO) && !schib->pmcw.dnv)\r\nreturn 0;\r\nif ((schib->pmcw.st == SUBCHANNEL_TYPE_MSG) && !schib->pmcw.w)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic int css_evaluate_new_subchannel(struct subchannel_id schid, int slow)\r\n{\r\nstruct schib schib;\r\nif (!slow) {\r\nreturn -EAGAIN;\r\n}\r\nif (stsch_err(schid, &schib)) {\r\nreturn -ENXIO;\r\n}\r\nif (!css_sch_is_valid(&schib)) {\r\nreturn 0;\r\n}\r\nCIO_MSG_EVENT(4, "event: sch 0.%x.%04x, new\n", schid.ssid,\r\nschid.sch_no);\r\nreturn css_probe_device(schid);\r\n}\r\nstatic int css_evaluate_known_subchannel(struct subchannel *sch, int slow)\r\n{\r\nint ret = 0;\r\nif (sch->driver) {\r\nif (sch->driver->sch_event)\r\nret = sch->driver->sch_event(sch, slow);\r\nelse\r\ndev_dbg(&sch->dev,\r\n"Got subchannel machine check but "\r\n"no sch_event handler provided.\n");\r\n}\r\nif (ret != 0 && ret != -EAGAIN) {\r\nCIO_MSG_EVENT(2, "eval: sch 0.%x.%04x, rc=%d\n",\r\nsch->schid.ssid, sch->schid.sch_no, ret);\r\n}\r\nreturn ret;\r\n}\r\nstatic void css_evaluate_subchannel(struct subchannel_id schid, int slow)\r\n{\r\nstruct subchannel *sch;\r\nint ret;\r\nsch = get_subchannel_by_schid(schid);\r\nif (sch) {\r\nret = css_evaluate_known_subchannel(sch, slow);\r\nput_device(&sch->dev);\r\n} else\r\nret = css_evaluate_new_subchannel(schid, slow);\r\nif (ret == -EAGAIN)\r\ncss_schedule_eval(schid);\r\n}\r\nvoid css_sched_sch_todo(struct subchannel *sch, enum sch_todo todo)\r\n{\r\nCIO_MSG_EVENT(4, "sch_todo: sched sch=0.%x.%04x todo=%d\n",\r\nsch->schid.ssid, sch->schid.sch_no, todo);\r\nif (sch->todo >= todo)\r\nreturn;\r\nif (!get_device(&sch->dev))\r\nreturn;\r\nsch->todo = todo;\r\nif (!queue_work(cio_work_q, &sch->todo_work)) {\r\nput_device(&sch->dev);\r\n}\r\n}\r\nstatic void css_sch_todo(struct work_struct *work)\r\n{\r\nstruct subchannel *sch;\r\nenum sch_todo todo;\r\nint ret;\r\nsch = container_of(work, struct subchannel, todo_work);\r\nspin_lock_irq(sch->lock);\r\ntodo = sch->todo;\r\nCIO_MSG_EVENT(4, "sch_todo: sch=0.%x.%04x, todo=%d\n", sch->schid.ssid,\r\nsch->schid.sch_no, todo);\r\nsch->todo = SCH_TODO_NOTHING;\r\nspin_unlock_irq(sch->lock);\r\nswitch (todo) {\r\ncase SCH_TODO_NOTHING:\r\nbreak;\r\ncase SCH_TODO_EVAL:\r\nret = css_evaluate_known_subchannel(sch, 1);\r\nif (ret == -EAGAIN) {\r\nspin_lock_irq(sch->lock);\r\ncss_sched_sch_todo(sch, todo);\r\nspin_unlock_irq(sch->lock);\r\n}\r\nbreak;\r\ncase SCH_TODO_UNREG:\r\ncss_sch_device_unregister(sch);\r\nbreak;\r\n}\r\nput_device(&sch->dev);\r\n}\r\nstatic int __init slow_subchannel_init(void)\r\n{\r\nspin_lock_init(&slow_subchannel_lock);\r\natomic_set(&css_eval_scheduled, 0);\r\ninit_waitqueue_head(&css_eval_wq);\r\nslow_subchannel_set = idset_sch_new();\r\nif (!slow_subchannel_set) {\r\nCIO_MSG_EVENT(0, "could not allocate slow subchannel set\n");\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic int slow_eval_known_fn(struct subchannel *sch, void *data)\r\n{\r\nint eval;\r\nint rc;\r\nspin_lock_irq(&slow_subchannel_lock);\r\neval = idset_sch_contains(slow_subchannel_set, sch->schid);\r\nidset_sch_del(slow_subchannel_set, sch->schid);\r\nspin_unlock_irq(&slow_subchannel_lock);\r\nif (eval) {\r\nrc = css_evaluate_known_subchannel(sch, 1);\r\nif (rc == -EAGAIN)\r\ncss_schedule_eval(sch->schid);\r\n}\r\nreturn 0;\r\n}\r\nstatic int slow_eval_unknown_fn(struct subchannel_id schid, void *data)\r\n{\r\nint eval;\r\nint rc = 0;\r\nspin_lock_irq(&slow_subchannel_lock);\r\neval = idset_sch_contains(slow_subchannel_set, schid);\r\nidset_sch_del(slow_subchannel_set, schid);\r\nspin_unlock_irq(&slow_subchannel_lock);\r\nif (eval) {\r\nrc = css_evaluate_new_subchannel(schid, 1);\r\nswitch (rc) {\r\ncase -EAGAIN:\r\ncss_schedule_eval(schid);\r\nrc = 0;\r\nbreak;\r\ncase -ENXIO:\r\ncase -ENOMEM:\r\ncase -EIO:\r\nidset_sch_del_subseq(slow_subchannel_set, schid);\r\nbreak;\r\ndefault:\r\nrc = 0;\r\n}\r\n}\r\nreturn rc;\r\n}\r\nstatic void css_slow_path_func(struct work_struct *unused)\r\n{\r\nunsigned long flags;\r\nCIO_TRACE_EVENT(4, "slowpath");\r\nfor_each_subchannel_staged(slow_eval_known_fn, slow_eval_unknown_fn,\r\nNULL);\r\nspin_lock_irqsave(&slow_subchannel_lock, flags);\r\nif (idset_is_empty(slow_subchannel_set)) {\r\natomic_set(&css_eval_scheduled, 0);\r\nwake_up(&css_eval_wq);\r\n}\r\nspin_unlock_irqrestore(&slow_subchannel_lock, flags);\r\n}\r\nvoid css_schedule_eval(struct subchannel_id schid)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&slow_subchannel_lock, flags);\r\nidset_sch_add(slow_subchannel_set, schid);\r\natomic_set(&css_eval_scheduled, 1);\r\nqueue_work(cio_work_q, &slow_path_work);\r\nspin_unlock_irqrestore(&slow_subchannel_lock, flags);\r\n}\r\nvoid css_schedule_eval_all(void)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&slow_subchannel_lock, flags);\r\nidset_fill(slow_subchannel_set);\r\natomic_set(&css_eval_scheduled, 1);\r\nqueue_work(cio_work_q, &slow_path_work);\r\nspin_unlock_irqrestore(&slow_subchannel_lock, flags);\r\n}\r\nstatic int __unset_registered(struct device *dev, void *data)\r\n{\r\nstruct idset *set = data;\r\nstruct subchannel *sch = to_subchannel(dev);\r\nidset_sch_del(set, sch->schid);\r\nreturn 0;\r\n}\r\nstatic void css_schedule_eval_all_unreg(void)\r\n{\r\nunsigned long flags;\r\nstruct idset *unreg_set;\r\nunreg_set = idset_sch_new();\r\nif (!unreg_set) {\r\ncss_schedule_eval_all();\r\nreturn;\r\n}\r\nidset_fill(unreg_set);\r\nbus_for_each_dev(&css_bus_type, NULL, unreg_set, __unset_registered);\r\nspin_lock_irqsave(&slow_subchannel_lock, flags);\r\nidset_add_set(slow_subchannel_set, unreg_set);\r\natomic_set(&css_eval_scheduled, 1);\r\nqueue_work(cio_work_q, &slow_path_work);\r\nspin_unlock_irqrestore(&slow_subchannel_lock, flags);\r\nidset_free(unreg_set);\r\n}\r\nvoid css_wait_for_slow_path(void)\r\n{\r\nflush_workqueue(cio_work_q);\r\n}\r\nvoid css_schedule_reprobe(void)\r\n{\r\ncss_schedule_eval_all_unreg();\r\n}\r\nstatic void css_process_crw(struct crw *crw0, struct crw *crw1, int overflow)\r\n{\r\nstruct subchannel_id mchk_schid;\r\nstruct subchannel *sch;\r\nif (overflow) {\r\ncss_schedule_eval_all();\r\nreturn;\r\n}\r\nCIO_CRW_EVENT(2, "CRW0 reports slct=%d, oflw=%d, "\r\n"chn=%d, rsc=%X, anc=%d, erc=%X, rsid=%X\n",\r\ncrw0->slct, crw0->oflw, crw0->chn, crw0->rsc, crw0->anc,\r\ncrw0->erc, crw0->rsid);\r\nif (crw1)\r\nCIO_CRW_EVENT(2, "CRW1 reports slct=%d, oflw=%d, "\r\n"chn=%d, rsc=%X, anc=%d, erc=%X, rsid=%X\n",\r\ncrw1->slct, crw1->oflw, crw1->chn, crw1->rsc,\r\ncrw1->anc, crw1->erc, crw1->rsid);\r\ninit_subchannel_id(&mchk_schid);\r\nmchk_schid.sch_no = crw0->rsid;\r\nif (crw1)\r\nmchk_schid.ssid = (crw1->rsid >> 4) & 3;\r\nif (crw0->erc == CRW_ERC_PMOD) {\r\nsch = get_subchannel_by_schid(mchk_schid);\r\nif (sch) {\r\ncss_update_ssd_info(sch);\r\nput_device(&sch->dev);\r\n}\r\n}\r\ncss_evaluate_subchannel(mchk_schid, 0);\r\n}\r\nstatic void __init\r\ncss_generate_pgid(struct channel_subsystem *css, u32 tod_high)\r\n{\r\nstruct cpuid cpu_id;\r\nif (css_general_characteristics.mcss) {\r\ncss->global_pgid.pgid_high.ext_cssid.version = 0x80;\r\ncss->global_pgid.pgid_high.ext_cssid.cssid = css->cssid;\r\n} else {\r\n#ifdef CONFIG_SMP\r\ncss->global_pgid.pgid_high.cpu_addr = stap();\r\n#else\r\ncss->global_pgid.pgid_high.cpu_addr = 0;\r\n#endif\r\n}\r\nget_cpu_id(&cpu_id);\r\ncss->global_pgid.cpu_id = cpu_id.ident;\r\ncss->global_pgid.cpu_model = cpu_id.machine;\r\ncss->global_pgid.tod_high = tod_high;\r\n}\r\nstatic void\r\nchannel_subsystem_release(struct device *dev)\r\n{\r\nstruct channel_subsystem *css;\r\ncss = to_css(dev);\r\nmutex_destroy(&css->mutex);\r\nif (css->pseudo_subchannel) {\r\ncss_subchannel_release(&css->pseudo_subchannel->dev);\r\ncss->pseudo_subchannel = NULL;\r\n}\r\nkfree(css);\r\n}\r\nstatic ssize_t\r\ncss_cm_enable_show(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct channel_subsystem *css = to_css(dev);\r\nint ret;\r\nif (!css)\r\nreturn 0;\r\nmutex_lock(&css->mutex);\r\nret = sprintf(buf, "%x\n", css->cm_enabled);\r\nmutex_unlock(&css->mutex);\r\nreturn ret;\r\n}\r\nstatic ssize_t\r\ncss_cm_enable_store(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct channel_subsystem *css = to_css(dev);\r\nint ret;\r\nunsigned long val;\r\nret = strict_strtoul(buf, 16, &val);\r\nif (ret)\r\nreturn ret;\r\nmutex_lock(&css->mutex);\r\nswitch (val) {\r\ncase 0:\r\nret = css->cm_enabled ? chsc_secm(css, 0) : 0;\r\nbreak;\r\ncase 1:\r\nret = css->cm_enabled ? 0 : chsc_secm(css, 1);\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\n}\r\nmutex_unlock(&css->mutex);\r\nreturn ret < 0 ? ret : count;\r\n}\r\nstatic int __init setup_css(int nr)\r\n{\r\nu32 tod_high;\r\nint ret;\r\nstruct channel_subsystem *css;\r\ncss = channel_subsystems[nr];\r\nmemset(css, 0, sizeof(struct channel_subsystem));\r\ncss->pseudo_subchannel =\r\nkzalloc(sizeof(*css->pseudo_subchannel), GFP_KERNEL);\r\nif (!css->pseudo_subchannel)\r\nreturn -ENOMEM;\r\ncss->pseudo_subchannel->dev.parent = &css->device;\r\ncss->pseudo_subchannel->dev.release = css_subchannel_release;\r\ndev_set_name(&css->pseudo_subchannel->dev, "defunct");\r\nmutex_init(&css->pseudo_subchannel->reg_mutex);\r\nret = cio_create_sch_lock(css->pseudo_subchannel);\r\nif (ret) {\r\nkfree(css->pseudo_subchannel);\r\nreturn ret;\r\n}\r\nmutex_init(&css->mutex);\r\ncss->valid = 1;\r\ncss->cssid = nr;\r\ndev_set_name(&css->device, "css%x", nr);\r\ncss->device.release = channel_subsystem_release;\r\ntod_high = (u32) (get_clock() >> 32);\r\ncss_generate_pgid(css, tod_high);\r\nreturn 0;\r\n}\r\nstatic int css_reboot_event(struct notifier_block *this,\r\nunsigned long event,\r\nvoid *ptr)\r\n{\r\nint ret, i;\r\nret = NOTIFY_DONE;\r\nfor (i = 0; i <= __MAX_CSSID; i++) {\r\nstruct channel_subsystem *css;\r\ncss = channel_subsystems[i];\r\nmutex_lock(&css->mutex);\r\nif (css->cm_enabled)\r\nif (chsc_secm(css, 0))\r\nret = NOTIFY_BAD;\r\nmutex_unlock(&css->mutex);\r\n}\r\nreturn ret;\r\n}\r\nstatic int css_power_event(struct notifier_block *this, unsigned long event,\r\nvoid *ptr)\r\n{\r\nint ret, i;\r\nswitch (event) {\r\ncase PM_HIBERNATION_PREPARE:\r\ncase PM_SUSPEND_PREPARE:\r\nret = NOTIFY_DONE;\r\nfor (i = 0; i <= __MAX_CSSID; i++) {\r\nstruct channel_subsystem *css;\r\ncss = channel_subsystems[i];\r\nmutex_lock(&css->mutex);\r\nif (!css->cm_enabled) {\r\nmutex_unlock(&css->mutex);\r\ncontinue;\r\n}\r\nret = __chsc_do_secm(css, 0);\r\nret = notifier_from_errno(ret);\r\nmutex_unlock(&css->mutex);\r\n}\r\nbreak;\r\ncase PM_POST_HIBERNATION:\r\ncase PM_POST_SUSPEND:\r\nret = NOTIFY_DONE;\r\nfor (i = 0; i <= __MAX_CSSID; i++) {\r\nstruct channel_subsystem *css;\r\ncss = channel_subsystems[i];\r\nmutex_lock(&css->mutex);\r\nif (!css->cm_enabled) {\r\nmutex_unlock(&css->mutex);\r\ncontinue;\r\n}\r\nret = __chsc_do_secm(css, 1);\r\nret = notifier_from_errno(ret);\r\nmutex_unlock(&css->mutex);\r\n}\r\ncss_schedule_reprobe();\r\nbreak;\r\ndefault:\r\nret = NOTIFY_DONE;\r\n}\r\nreturn ret;\r\n}\r\nstatic int __init css_bus_init(void)\r\n{\r\nint ret, i;\r\nret = chsc_init();\r\nif (ret)\r\nreturn ret;\r\nchsc_determine_css_characteristics();\r\nret = chsc_enable_facility(CHSC_SDA_OC_MSS);\r\nif (ret)\r\nmax_ssid = 0;\r\nelse\r\nmax_ssid = __MAX_SSID;\r\nret = slow_subchannel_init();\r\nif (ret)\r\ngoto out;\r\nret = crw_register_handler(CRW_RSC_SCH, css_process_crw);\r\nif (ret)\r\ngoto out;\r\nif ((ret = bus_register(&css_bus_type)))\r\ngoto out;\r\nfor (i = 0; i <= __MAX_CSSID; i++) {\r\nstruct channel_subsystem *css;\r\ncss = kmalloc(sizeof(struct channel_subsystem), GFP_KERNEL);\r\nif (!css) {\r\nret = -ENOMEM;\r\ngoto out_unregister;\r\n}\r\nchannel_subsystems[i] = css;\r\nret = setup_css(i);\r\nif (ret) {\r\nkfree(channel_subsystems[i]);\r\ngoto out_unregister;\r\n}\r\nret = device_register(&css->device);\r\nif (ret) {\r\nput_device(&css->device);\r\ngoto out_unregister;\r\n}\r\nif (css_chsc_characteristics.secm) {\r\nret = device_create_file(&css->device,\r\n&dev_attr_cm_enable);\r\nif (ret)\r\ngoto out_device;\r\n}\r\nret = device_register(&css->pseudo_subchannel->dev);\r\nif (ret) {\r\nput_device(&css->pseudo_subchannel->dev);\r\ngoto out_file;\r\n}\r\n}\r\nret = register_reboot_notifier(&css_reboot_notifier);\r\nif (ret)\r\ngoto out_unregister;\r\nret = register_pm_notifier(&css_power_notifier);\r\nif (ret) {\r\nunregister_reboot_notifier(&css_reboot_notifier);\r\ngoto out_unregister;\r\n}\r\ncss_init_done = 1;\r\nisc_register(IO_SCH_ISC);\r\nreturn 0;\r\nout_file:\r\nif (css_chsc_characteristics.secm)\r\ndevice_remove_file(&channel_subsystems[i]->device,\r\n&dev_attr_cm_enable);\r\nout_device:\r\ndevice_unregister(&channel_subsystems[i]->device);\r\nout_unregister:\r\nwhile (i > 0) {\r\nstruct channel_subsystem *css;\r\ni--;\r\ncss = channel_subsystems[i];\r\ndevice_unregister(&css->pseudo_subchannel->dev);\r\ncss->pseudo_subchannel = NULL;\r\nif (css_chsc_characteristics.secm)\r\ndevice_remove_file(&css->device,\r\n&dev_attr_cm_enable);\r\ndevice_unregister(&css->device);\r\n}\r\nbus_unregister(&css_bus_type);\r\nout:\r\ncrw_unregister_handler(CRW_RSC_SCH);\r\nidset_free(slow_subchannel_set);\r\nchsc_init_cleanup();\r\npr_alert("The CSS device driver initialization failed with "\r\n"errno=%d\n", ret);\r\nreturn ret;\r\n}\r\nstatic void __init css_bus_cleanup(void)\r\n{\r\nstruct channel_subsystem *css;\r\nint i;\r\nfor (i = 0; i <= __MAX_CSSID; i++) {\r\ncss = channel_subsystems[i];\r\ndevice_unregister(&css->pseudo_subchannel->dev);\r\ncss->pseudo_subchannel = NULL;\r\nif (css_chsc_characteristics.secm)\r\ndevice_remove_file(&css->device, &dev_attr_cm_enable);\r\ndevice_unregister(&css->device);\r\n}\r\nbus_unregister(&css_bus_type);\r\ncrw_unregister_handler(CRW_RSC_SCH);\r\nidset_free(slow_subchannel_set);\r\nchsc_init_cleanup();\r\nisc_unregister(IO_SCH_ISC);\r\n}\r\nstatic int __init channel_subsystem_init(void)\r\n{\r\nint ret;\r\nret = css_bus_init();\r\nif (ret)\r\nreturn ret;\r\ncio_work_q = create_singlethread_workqueue("cio");\r\nif (!cio_work_q) {\r\nret = -ENOMEM;\r\ngoto out_bus;\r\n}\r\nret = io_subchannel_init();\r\nif (ret)\r\ngoto out_wq;\r\nreturn ret;\r\nout_wq:\r\ndestroy_workqueue(cio_work_q);\r\nout_bus:\r\ncss_bus_cleanup();\r\nreturn ret;\r\n}\r\nstatic int css_settle(struct device_driver *drv, void *unused)\r\n{\r\nstruct css_driver *cssdrv = to_cssdriver(drv);\r\nif (cssdrv->settle)\r\nreturn cssdrv->settle();\r\nreturn 0;\r\n}\r\nint css_complete_work(void)\r\n{\r\nint ret;\r\nret = wait_event_interruptible(css_eval_wq,\r\natomic_read(&css_eval_scheduled) == 0);\r\nif (ret)\r\nreturn -EINTR;\r\nflush_workqueue(cio_work_q);\r\nreturn bus_for_each_drv(&css_bus_type, NULL, NULL, css_settle);\r\n}\r\nstatic int __init channel_subsystem_init_sync(void)\r\n{\r\ncss_schedule_eval_all();\r\ncss_complete_work();\r\nreturn 0;\r\n}\r\nvoid channel_subsystem_reinit(void)\r\n{\r\nstruct channel_path *chp;\r\nstruct chp_id chpid;\r\nchsc_enable_facility(CHSC_SDA_OC_MSS);\r\nchp_id_for_each(&chpid) {\r\nchp = chpid_to_chp(chpid);\r\nif (!chp)\r\ncontinue;\r\nchsc_determine_base_channel_path_desc(chpid, &chp->desc);\r\n}\r\n}\r\nstatic ssize_t cio_settle_write(struct file *file, const char __user *buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nint ret;\r\ncrw_wait_for_channel_report();\r\nret = css_complete_work();\r\nreturn ret ? ret : count;\r\n}\r\nstatic int __init cio_settle_init(void)\r\n{\r\nstruct proc_dir_entry *entry;\r\nentry = proc_create("cio_settle", S_IWUSR, NULL,\r\n&cio_settle_proc_fops);\r\nif (!entry)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nint sch_is_pseudo_sch(struct subchannel *sch)\r\n{\r\nreturn sch == to_css(sch->dev.parent)->pseudo_subchannel;\r\n}\r\nstatic int css_bus_match(struct device *dev, struct device_driver *drv)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nstruct css_driver *driver = to_cssdriver(drv);\r\nstruct css_device_id *id;\r\nfor (id = driver->subchannel_type; id->match_flags; id++) {\r\nif (sch->st == id->type)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int css_probe(struct device *dev)\r\n{\r\nstruct subchannel *sch;\r\nint ret;\r\nsch = to_subchannel(dev);\r\nsch->driver = to_cssdriver(dev->driver);\r\nret = sch->driver->probe ? sch->driver->probe(sch) : 0;\r\nif (ret)\r\nsch->driver = NULL;\r\nreturn ret;\r\n}\r\nstatic int css_remove(struct device *dev)\r\n{\r\nstruct subchannel *sch;\r\nint ret;\r\nsch = to_subchannel(dev);\r\nret = sch->driver->remove ? sch->driver->remove(sch) : 0;\r\nsch->driver = NULL;\r\nreturn ret;\r\n}\r\nstatic void css_shutdown(struct device *dev)\r\n{\r\nstruct subchannel *sch;\r\nsch = to_subchannel(dev);\r\nif (sch->driver && sch->driver->shutdown)\r\nsch->driver->shutdown(sch);\r\n}\r\nstatic int css_uevent(struct device *dev, struct kobj_uevent_env *env)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nint ret;\r\nret = add_uevent_var(env, "ST=%01X", sch->st);\r\nif (ret)\r\nreturn ret;\r\nret = add_uevent_var(env, "MODALIAS=css:t%01X", sch->st);\r\nreturn ret;\r\n}\r\nstatic int css_pm_prepare(struct device *dev)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nstruct css_driver *drv;\r\nif (mutex_is_locked(&sch->reg_mutex))\r\nreturn -EAGAIN;\r\nif (!sch->dev.driver)\r\nreturn 0;\r\ndrv = to_cssdriver(sch->dev.driver);\r\nreturn drv->prepare ? drv->prepare(sch) : 0;\r\n}\r\nstatic void css_pm_complete(struct device *dev)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nstruct css_driver *drv;\r\nif (!sch->dev.driver)\r\nreturn;\r\ndrv = to_cssdriver(sch->dev.driver);\r\nif (drv->complete)\r\ndrv->complete(sch);\r\n}\r\nstatic int css_pm_freeze(struct device *dev)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nstruct css_driver *drv;\r\nif (!sch->dev.driver)\r\nreturn 0;\r\ndrv = to_cssdriver(sch->dev.driver);\r\nreturn drv->freeze ? drv->freeze(sch) : 0;\r\n}\r\nstatic int css_pm_thaw(struct device *dev)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nstruct css_driver *drv;\r\nif (!sch->dev.driver)\r\nreturn 0;\r\ndrv = to_cssdriver(sch->dev.driver);\r\nreturn drv->thaw ? drv->thaw(sch) : 0;\r\n}\r\nstatic int css_pm_restore(struct device *dev)\r\n{\r\nstruct subchannel *sch = to_subchannel(dev);\r\nstruct css_driver *drv;\r\ncss_update_ssd_info(sch);\r\nif (!sch->dev.driver)\r\nreturn 0;\r\ndrv = to_cssdriver(sch->dev.driver);\r\nreturn drv->restore ? drv->restore(sch) : 0;\r\n}\r\nint css_driver_register(struct css_driver *cdrv)\r\n{\r\ncdrv->drv.bus = &css_bus_type;\r\nreturn driver_register(&cdrv->drv);\r\n}\r\nvoid css_driver_unregister(struct css_driver *cdrv)\r\n{\r\ndriver_unregister(&cdrv->drv);\r\n}
