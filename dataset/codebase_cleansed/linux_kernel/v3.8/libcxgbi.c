int cxgbi_device_portmap_create(struct cxgbi_device *cdev, unsigned int base,\r\nunsigned int max_conn)\r\n{\r\nstruct cxgbi_ports_map *pmap = &cdev->pmap;\r\npmap->port_csk = cxgbi_alloc_big_mem(max_conn *\r\nsizeof(struct cxgbi_sock *),\r\nGFP_KERNEL);\r\nif (!pmap->port_csk) {\r\npr_warn("cdev 0x%p, portmap OOM %u.\n", cdev, max_conn);\r\nreturn -ENOMEM;\r\n}\r\npmap->max_connect = max_conn;\r\npmap->sport_base = base;\r\nspin_lock_init(&pmap->lock);\r\nreturn 0;\r\n}\r\nvoid cxgbi_device_portmap_cleanup(struct cxgbi_device *cdev)\r\n{\r\nstruct cxgbi_ports_map *pmap = &cdev->pmap;\r\nstruct cxgbi_sock *csk;\r\nint i;\r\nfor (i = 0; i < pmap->max_connect; i++) {\r\nif (pmap->port_csk[i]) {\r\ncsk = pmap->port_csk[i];\r\npmap->port_csk[i] = NULL;\r\nlog_debug(1 << CXGBI_DBG_SOCK,\r\n"csk 0x%p, cdev 0x%p, offload down.\n",\r\ncsk, cdev);\r\nspin_lock_bh(&csk->lock);\r\ncxgbi_sock_set_flag(csk, CTPF_OFFLOAD_DOWN);\r\ncxgbi_sock_closed(csk);\r\nspin_unlock_bh(&csk->lock);\r\ncxgbi_sock_put(csk);\r\n}\r\n}\r\n}\r\nstatic inline void cxgbi_device_destroy(struct cxgbi_device *cdev)\r\n{\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"cdev 0x%p, p# %u.\n", cdev, cdev->nports);\r\ncxgbi_hbas_remove(cdev);\r\ncxgbi_device_portmap_cleanup(cdev);\r\nif (cdev->dev_ddp_cleanup)\r\ncdev->dev_ddp_cleanup(cdev);\r\nelse\r\ncxgbi_ddp_cleanup(cdev);\r\nif (cdev->ddp)\r\ncxgbi_ddp_cleanup(cdev);\r\nif (cdev->pmap.max_connect)\r\ncxgbi_free_big_mem(cdev->pmap.port_csk);\r\nkfree(cdev);\r\n}\r\nstruct cxgbi_device *cxgbi_device_register(unsigned int extra,\r\nunsigned int nports)\r\n{\r\nstruct cxgbi_device *cdev;\r\ncdev = kzalloc(sizeof(*cdev) + extra + nports *\r\n(sizeof(struct cxgbi_hba *) +\r\nsizeof(struct net_device *)),\r\nGFP_KERNEL);\r\nif (!cdev) {\r\npr_warn("nport %d, OOM.\n", nports);\r\nreturn NULL;\r\n}\r\ncdev->ports = (struct net_device **)(cdev + 1);\r\ncdev->hbas = (struct cxgbi_hba **)(((char*)cdev->ports) + nports *\r\nsizeof(struct net_device *));\r\nif (extra)\r\ncdev->dd_data = ((char *)cdev->hbas) +\r\nnports * sizeof(struct cxgbi_hba *);\r\nspin_lock_init(&cdev->pmap.lock);\r\nmutex_lock(&cdev_mutex);\r\nlist_add_tail(&cdev->list_head, &cdev_list);\r\nmutex_unlock(&cdev_mutex);\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"cdev 0x%p, p# %u.\n", cdev, nports);\r\nreturn cdev;\r\n}\r\nvoid cxgbi_device_unregister(struct cxgbi_device *cdev)\r\n{\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"cdev 0x%p, p# %u,%s.\n",\r\ncdev, cdev->nports, cdev->nports ? cdev->ports[0]->name : "");\r\nmutex_lock(&cdev_mutex);\r\nlist_del(&cdev->list_head);\r\nmutex_unlock(&cdev_mutex);\r\ncxgbi_device_destroy(cdev);\r\n}\r\nvoid cxgbi_device_unregister_all(unsigned int flag)\r\n{\r\nstruct cxgbi_device *cdev, *tmp;\r\nmutex_lock(&cdev_mutex);\r\nlist_for_each_entry_safe(cdev, tmp, &cdev_list, list_head) {\r\nif ((cdev->flags & flag) == flag) {\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"cdev 0x%p, p# %u,%s.\n",\r\ncdev, cdev->nports, cdev->nports ?\r\ncdev->ports[0]->name : "");\r\nlist_del(&cdev->list_head);\r\ncxgbi_device_destroy(cdev);\r\n}\r\n}\r\nmutex_unlock(&cdev_mutex);\r\n}\r\nstruct cxgbi_device *cxgbi_device_find_by_lldev(void *lldev)\r\n{\r\nstruct cxgbi_device *cdev, *tmp;\r\nmutex_lock(&cdev_mutex);\r\nlist_for_each_entry_safe(cdev, tmp, &cdev_list, list_head) {\r\nif (cdev->lldev == lldev) {\r\nmutex_unlock(&cdev_mutex);\r\nreturn cdev;\r\n}\r\n}\r\nmutex_unlock(&cdev_mutex);\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"lldev 0x%p, NO match found.\n", lldev);\r\nreturn NULL;\r\n}\r\nstatic struct cxgbi_device *cxgbi_device_find_by_netdev(struct net_device *ndev,\r\nint *port)\r\n{\r\nstruct net_device *vdev = NULL;\r\nstruct cxgbi_device *cdev, *tmp;\r\nint i;\r\nif (ndev->priv_flags & IFF_802_1Q_VLAN) {\r\nvdev = ndev;\r\nndev = vlan_dev_real_dev(ndev);\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"vlan dev %s -> %s.\n", vdev->name, ndev->name);\r\n}\r\nmutex_lock(&cdev_mutex);\r\nlist_for_each_entry_safe(cdev, tmp, &cdev_list, list_head) {\r\nfor (i = 0; i < cdev->nports; i++) {\r\nif (ndev == cdev->ports[i]) {\r\ncdev->hbas[i]->vdev = vdev;\r\nmutex_unlock(&cdev_mutex);\r\nif (port)\r\n*port = i;\r\nreturn cdev;\r\n}\r\n}\r\n}\r\nmutex_unlock(&cdev_mutex);\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"ndev 0x%p, %s, NO match found.\n", ndev, ndev->name);\r\nreturn NULL;\r\n}\r\nvoid cxgbi_hbas_remove(struct cxgbi_device *cdev)\r\n{\r\nint i;\r\nstruct cxgbi_hba *chba;\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"cdev 0x%p, p#%u.\n", cdev, cdev->nports);\r\nfor (i = 0; i < cdev->nports; i++) {\r\nchba = cdev->hbas[i];\r\nif (chba) {\r\ncdev->hbas[i] = NULL;\r\niscsi_host_remove(chba->shost);\r\npci_dev_put(cdev->pdev);\r\niscsi_host_free(chba->shost);\r\n}\r\n}\r\n}\r\nint cxgbi_hbas_add(struct cxgbi_device *cdev, unsigned int max_lun,\r\nunsigned int max_id, struct scsi_host_template *sht,\r\nstruct scsi_transport_template *stt)\r\n{\r\nstruct cxgbi_hba *chba;\r\nstruct Scsi_Host *shost;\r\nint i, err;\r\nlog_debug(1 << CXGBI_DBG_DEV, "cdev 0x%p, p#%u.\n", cdev, cdev->nports);\r\nfor (i = 0; i < cdev->nports; i++) {\r\nshost = iscsi_host_alloc(sht, sizeof(*chba), 1);\r\nif (!shost) {\r\npr_info("0x%p, p%d, %s, host alloc failed.\n",\r\ncdev, i, cdev->ports[i]->name);\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\nshost->transportt = stt;\r\nshost->max_lun = max_lun;\r\nshost->max_id = max_id;\r\nshost->max_channel = 0;\r\nshost->max_cmd_len = 16;\r\nchba = iscsi_host_priv(shost);\r\nchba->cdev = cdev;\r\nchba->ndev = cdev->ports[i];\r\nchba->shost = shost;\r\nlog_debug(1 << CXGBI_DBG_DEV,\r\n"cdev 0x%p, p#%d %s: chba 0x%p.\n",\r\ncdev, i, cdev->ports[i]->name, chba);\r\npci_dev_get(cdev->pdev);\r\nerr = iscsi_host_add(shost, &cdev->pdev->dev);\r\nif (err) {\r\npr_info("cdev 0x%p, p#%d %s, host add failed.\n",\r\ncdev, i, cdev->ports[i]->name);\r\npci_dev_put(cdev->pdev);\r\nscsi_host_put(shost);\r\ngoto err_out;\r\n}\r\ncdev->hbas[i] = chba;\r\n}\r\nreturn 0;\r\nerr_out:\r\ncxgbi_hbas_remove(cdev);\r\nreturn err;\r\n}\r\nstatic int sock_get_port(struct cxgbi_sock *csk)\r\n{\r\nstruct cxgbi_device *cdev = csk->cdev;\r\nstruct cxgbi_ports_map *pmap = &cdev->pmap;\r\nunsigned int start;\r\nint idx;\r\nif (!pmap->max_connect) {\r\npr_err("cdev 0x%p, p#%u %s, NO port map.\n",\r\ncdev, csk->port_id, cdev->ports[csk->port_id]->name);\r\nreturn -EADDRNOTAVAIL;\r\n}\r\nif (csk->saddr.sin_port) {\r\npr_err("source port NON-ZERO %u.\n",\r\nntohs(csk->saddr.sin_port));\r\nreturn -EADDRINUSE;\r\n}\r\nspin_lock_bh(&pmap->lock);\r\nif (pmap->used >= pmap->max_connect) {\r\nspin_unlock_bh(&pmap->lock);\r\npr_info("cdev 0x%p, p#%u %s, ALL ports used.\n",\r\ncdev, csk->port_id, cdev->ports[csk->port_id]->name);\r\nreturn -EADDRNOTAVAIL;\r\n}\r\nstart = idx = pmap->next;\r\ndo {\r\nif (++idx >= pmap->max_connect)\r\nidx = 0;\r\nif (!pmap->port_csk[idx]) {\r\npmap->used++;\r\ncsk->saddr.sin_port =\r\nhtons(pmap->sport_base + idx);\r\npmap->next = idx;\r\npmap->port_csk[idx] = csk;\r\nspin_unlock_bh(&pmap->lock);\r\ncxgbi_sock_get(csk);\r\nlog_debug(1 << CXGBI_DBG_SOCK,\r\n"cdev 0x%p, p#%u %s, p %u, %u.\n",\r\ncdev, csk->port_id,\r\ncdev->ports[csk->port_id]->name,\r\npmap->sport_base + idx, pmap->next);\r\nreturn 0;\r\n}\r\n} while (idx != start);\r\nspin_unlock_bh(&pmap->lock);\r\npr_warn("cdev 0x%p, p#%u %s, next %u?\n",\r\ncdev, csk->port_id, cdev->ports[csk->port_id]->name,\r\npmap->next);\r\nreturn -EADDRNOTAVAIL;\r\n}\r\nstatic void sock_put_port(struct cxgbi_sock *csk)\r\n{\r\nstruct cxgbi_device *cdev = csk->cdev;\r\nstruct cxgbi_ports_map *pmap = &cdev->pmap;\r\nif (csk->saddr.sin_port) {\r\nint idx = ntohs(csk->saddr.sin_port) - pmap->sport_base;\r\ncsk->saddr.sin_port = 0;\r\nif (idx < 0 || idx >= pmap->max_connect) {\r\npr_err("cdev 0x%p, p#%u %s, port %u OOR.\n",\r\ncdev, csk->port_id,\r\ncdev->ports[csk->port_id]->name,\r\nntohs(csk->saddr.sin_port));\r\nreturn;\r\n}\r\nspin_lock_bh(&pmap->lock);\r\npmap->port_csk[idx] = NULL;\r\npmap->used--;\r\nspin_unlock_bh(&pmap->lock);\r\nlog_debug(1 << CXGBI_DBG_SOCK,\r\n"cdev 0x%p, p#%u %s, release %u.\n",\r\ncdev, csk->port_id, cdev->ports[csk->port_id]->name,\r\npmap->sport_base + idx);\r\ncxgbi_sock_put(csk);\r\n}\r\n}\r\nvoid cxgbi_sock_free_cpl_skbs(struct cxgbi_sock *csk)\r\n{\r\nif (csk->cpl_close) {\r\nkfree_skb(csk->cpl_close);\r\ncsk->cpl_close = NULL;\r\n}\r\nif (csk->cpl_abort_req) {\r\nkfree_skb(csk->cpl_abort_req);\r\ncsk->cpl_abort_req = NULL;\r\n}\r\nif (csk->cpl_abort_rpl) {\r\nkfree_skb(csk->cpl_abort_rpl);\r\ncsk->cpl_abort_rpl = NULL;\r\n}\r\n}\r\nstatic struct cxgbi_sock *cxgbi_sock_create(struct cxgbi_device *cdev)\r\n{\r\nstruct cxgbi_sock *csk = kzalloc(sizeof(*csk), GFP_NOIO);\r\nif (!csk) {\r\npr_info("alloc csk %zu failed.\n", sizeof(*csk));\r\nreturn NULL;\r\n}\r\nif (cdev->csk_alloc_cpls(csk) < 0) {\r\npr_info("csk 0x%p, alloc cpls failed.\n", csk);\r\nkfree(csk);\r\nreturn NULL;\r\n}\r\nspin_lock_init(&csk->lock);\r\nkref_init(&csk->refcnt);\r\nskb_queue_head_init(&csk->receive_queue);\r\nskb_queue_head_init(&csk->write_queue);\r\nsetup_timer(&csk->retry_timer, NULL, (unsigned long)csk);\r\nrwlock_init(&csk->callback_lock);\r\ncsk->cdev = cdev;\r\ncsk->flags = 0;\r\ncxgbi_sock_set_state(csk, CTP_CLOSED);\r\nlog_debug(1 << CXGBI_DBG_SOCK, "cdev 0x%p, new csk 0x%p.\n", cdev, csk);\r\nreturn csk;\r\n}\r\nstatic struct rtable *find_route_ipv4(struct flowi4 *fl4,\r\n__be32 saddr, __be32 daddr,\r\n__be16 sport, __be16 dport, u8 tos)\r\n{\r\nstruct rtable *rt;\r\nrt = ip_route_output_ports(&init_net, fl4, NULL, daddr, saddr,\r\ndport, sport, IPPROTO_TCP, tos, 0);\r\nif (IS_ERR(rt))\r\nreturn NULL;\r\nreturn rt;\r\n}\r\nstatic struct cxgbi_sock *cxgbi_check_route(struct sockaddr *dst_addr)\r\n{\r\nstruct sockaddr_in *daddr = (struct sockaddr_in *)dst_addr;\r\nstruct dst_entry *dst;\r\nstruct net_device *ndev;\r\nstruct cxgbi_device *cdev;\r\nstruct rtable *rt = NULL;\r\nstruct neighbour *n;\r\nstruct flowi4 fl4;\r\nstruct cxgbi_sock *csk = NULL;\r\nunsigned int mtu = 0;\r\nint port = 0xFFFF;\r\nint err = 0;\r\nif (daddr->sin_family != AF_INET) {\r\npr_info("address family 0x%x NOT supported.\n",\r\ndaddr->sin_family);\r\nerr = -EAFNOSUPPORT;\r\ngoto err_out;\r\n}\r\nrt = find_route_ipv4(&fl4, 0, daddr->sin_addr.s_addr, 0, daddr->sin_port, 0);\r\nif (!rt) {\r\npr_info("no route to ipv4 0x%x, port %u.\n",\r\ndaddr->sin_addr.s_addr, daddr->sin_port);\r\nerr = -ENETUNREACH;\r\ngoto err_out;\r\n}\r\ndst = &rt->dst;\r\nn = dst_neigh_lookup(dst, &daddr->sin_addr.s_addr);\r\nif (!n) {\r\nerr = -ENODEV;\r\ngoto rel_rt;\r\n}\r\nndev = n->dev;\r\nif (rt->rt_flags & (RTCF_MULTICAST | RTCF_BROADCAST)) {\r\npr_info("multi-cast route %pI4, port %u, dev %s.\n",\r\n&daddr->sin_addr.s_addr, ntohs(daddr->sin_port),\r\nndev->name);\r\nerr = -ENETUNREACH;\r\ngoto rel_neigh;\r\n}\r\nif (ndev->flags & IFF_LOOPBACK) {\r\nndev = ip_dev_find(&init_net, daddr->sin_addr.s_addr);\r\nmtu = ndev->mtu;\r\npr_info("rt dev %s, loopback -> %s, mtu %u.\n",\r\nn->dev->name, ndev->name, mtu);\r\n}\r\ncdev = cxgbi_device_find_by_netdev(ndev, &port);\r\nif (!cdev) {\r\npr_info("dst %pI4, %s, NOT cxgbi device.\n",\r\n&daddr->sin_addr.s_addr, ndev->name);\r\nerr = -ENETUNREACH;\r\ngoto rel_neigh;\r\n}\r\nlog_debug(1 << CXGBI_DBG_SOCK,\r\n"route to %pI4 :%u, ndev p#%d,%s, cdev 0x%p.\n",\r\n&daddr->sin_addr.s_addr, ntohs(daddr->sin_port),\r\nport, ndev->name, cdev);\r\ncsk = cxgbi_sock_create(cdev);\r\nif (!csk) {\r\nerr = -ENOMEM;\r\ngoto rel_neigh;\r\n}\r\ncsk->cdev = cdev;\r\ncsk->port_id = port;\r\ncsk->mtu = mtu;\r\ncsk->dst = dst;\r\ncsk->daddr.sin_addr.s_addr = daddr->sin_addr.s_addr;\r\ncsk->daddr.sin_port = daddr->sin_port;\r\ncsk->daddr.sin_family = daddr->sin_family;\r\ncsk->saddr.sin_addr.s_addr = fl4.saddr;\r\nneigh_release(n);\r\nreturn csk;\r\nrel_neigh:\r\nneigh_release(n);\r\nrel_rt:\r\nip_rt_put(rt);\r\nif (csk)\r\ncxgbi_sock_closed(csk);\r\nerr_out:\r\nreturn ERR_PTR(err);\r\n}\r\nvoid cxgbi_sock_established(struct cxgbi_sock *csk, unsigned int snd_isn,\r\nunsigned int opt)\r\n{\r\ncsk->write_seq = csk->snd_nxt = csk->snd_una = snd_isn;\r\ndst_confirm(csk->dst);\r\nsmp_mb();\r\ncxgbi_sock_set_state(csk, CTP_ESTABLISHED);\r\n}\r\nstatic void cxgbi_inform_iscsi_conn_closing(struct cxgbi_sock *csk)\r\n{\r\nlog_debug(1 << CXGBI_DBG_SOCK,\r\n"csk 0x%p, state %u, flags 0x%lx, conn 0x%p.\n",\r\ncsk, csk->state, csk->flags, csk->user_data);\r\nif (csk->state != CTP_ESTABLISHED) {\r\nread_lock_bh(&csk->callback_lock);\r\nif (csk->user_data)\r\niscsi_conn_failure(csk->user_data,\r\nISCSI_ERR_CONN_FAILED);\r\nread_unlock_bh(&csk->callback_lock);\r\n}\r\n}\r\nvoid cxgbi_sock_closed(struct cxgbi_sock *csk)\r\n{\r\nlog_debug(1 << CXGBI_DBG_SOCK, "csk 0x%p,%u,0x%lx,%u.\n",\r\ncsk, (csk)->state, (csk)->flags, (csk)->tid);\r\ncxgbi_sock_set_flag(csk, CTPF_ACTIVE_CLOSE_NEEDED);\r\nif (csk->state == CTP_ACTIVE_OPEN || csk->state == CTP_CLOSED)\r\nreturn;\r\nif (csk->saddr.sin_port)\r\nsock_put_port(csk);\r\nif (csk->dst)\r\ndst_release(csk->dst);\r\ncsk->cdev->csk_release_offload_resources(csk);\r\ncxgbi_sock_set_state(csk, CTP_CLOSED);\r\ncxgbi_inform_iscsi_conn_closing(csk);\r\ncxgbi_sock_put(csk);\r\n}\r\nstatic void need_active_close(struct cxgbi_sock *csk)\r\n{\r\nint data_lost;\r\nint close_req = 0;\r\nlog_debug(1 << CXGBI_DBG_SOCK, "csk 0x%p,%u,0x%lx,%u.\n",\r\ncsk, (csk)->state, (csk)->flags, (csk)->tid);\r\nspin_lock_bh(&csk->lock);\r\ndst_confirm(csk->dst);\r\ndata_lost = skb_queue_len(&csk->receive_queue);\r\n__skb_queue_purge(&csk->receive_queue);\r\nif (csk->state == CTP_ACTIVE_OPEN)\r\ncxgbi_sock_set_flag(csk, CTPF_ACTIVE_CLOSE_NEEDED);\r\nelse if (csk->state == CTP_ESTABLISHED) {\r\nclose_req = 1;\r\ncxgbi_sock_set_state(csk, CTP_ACTIVE_CLOSE);\r\n} else if (csk->state == CTP_PASSIVE_CLOSE) {\r\nclose_req = 1;\r\ncxgbi_sock_set_state(csk, CTP_CLOSE_WAIT_2);\r\n}\r\nif (close_req) {\r\nif (data_lost)\r\ncsk->cdev->csk_send_abort_req(csk);\r\nelse\r\ncsk->cdev->csk_send_close_req(csk);\r\n}\r\nspin_unlock_bh(&csk->lock);\r\n}\r\nvoid cxgbi_sock_fail_act_open(struct cxgbi_sock *csk, int errno)\r\n{\r\npr_info("csk 0x%p,%u,%lx, %pI4:%u-%pI4:%u, err %d.\n",\r\ncsk, csk->state, csk->flags,\r\n&csk->saddr.sin_addr.s_addr, csk->saddr.sin_port,\r\n&csk->daddr.sin_addr.s_addr, csk->daddr.sin_port,\r\nerrno);\r\ncxgbi_sock_set_state(csk, CTP_CONNECTING);\r\ncsk->err = errno;\r\ncxgbi_sock_closed(csk);\r\n}\r\nvoid cxgbi_sock_act_open_req_arp_failure(void *handle, struct sk_buff *skb)\r\n{\r\nstruct cxgbi_sock *csk = (struct cxgbi_sock *)skb->sk;\r\nlog_debug(1 << CXGBI_DBG_SOCK, "csk 0x%p,%u,0x%lx,%u.\n",\r\ncsk, (csk)->state, (csk)->flags, (csk)->tid);\r\ncxgbi_sock_get(csk);\r\nspin_lock_bh(&csk->lock);\r\nif (csk->state == CTP_ACTIVE_OPEN)\r\ncxgbi_sock_fail_act_open(csk, -EHOSTUNREACH);\r\nspin_unlock_bh(&csk->lock);\r\ncxgbi_sock_put(csk);\r\n__kfree_skb(skb);\r\n}\r\nvoid cxgbi_sock_rcv_abort_rpl(struct cxgbi_sock *csk)\r\n{\r\ncxgbi_sock_get(csk);\r\nspin_lock_bh(&csk->lock);\r\nif (cxgbi_sock_flag(csk, CTPF_ABORT_RPL_PENDING)) {\r\nif (!cxgbi_sock_flag(csk, CTPF_ABORT_RPL_RCVD))\r\ncxgbi_sock_set_flag(csk, CTPF_ABORT_RPL_RCVD);\r\nelse {\r\ncxgbi_sock_clear_flag(csk, CTPF_ABORT_RPL_RCVD);\r\ncxgbi_sock_clear_flag(csk, CTPF_ABORT_RPL_PENDING);\r\nif (cxgbi_sock_flag(csk, CTPF_ABORT_REQ_RCVD))\r\npr_err("csk 0x%p,%u,0x%lx,%u,ABT_RPL_RSS.\n",\r\ncsk, csk->state, csk->flags, csk->tid);\r\ncxgbi_sock_closed(csk);\r\n}\r\n}\r\nspin_unlock_bh(&csk->lock);\r\ncxgbi_sock_put(csk);\r\n}\r\nvoid cxgbi_sock_rcv_peer_close(struct cxgbi_sock *csk)\r\n{\r\nlog_debug(1 << CXGBI_DBG_SOCK, "csk 0x%p,%u,0x%lx,%u.\n",\r\ncsk, (csk)->state, (csk)->flags, (csk)->tid);\r\ncxgbi_sock_get(csk);\r\nspin_lock_bh(&csk->lock);\r\nif (cxgbi_sock_flag(csk, CTPF_ABORT_RPL_PENDING))\r\ngoto done;\r\nswitch (csk->state) {\r\ncase CTP_ESTABLISHED:\r\ncxgbi_sock_set_state(csk, CTP_PASSIVE_CLOSE);\r\nbreak;\r\ncase CTP_ACTIVE_CLOSE:\r\ncxgbi_sock_set_state(csk, CTP_CLOSE_WAIT_2);\r\nbreak;\r\ncase CTP_CLOSE_WAIT_1:\r\ncxgbi_sock_closed(csk);\r\nbreak;\r\ncase CTP_ABORTING:\r\nbreak;\r\ndefault:\r\npr_err("csk 0x%p,%u,0x%lx,%u, bad state.\n",\r\ncsk, csk->state, csk->flags, csk->tid);\r\n}\r\ncxgbi_inform_iscsi_conn_closing(csk);\r\ndone:\r\nspin_unlock_bh(&csk->lock);\r\ncxgbi_sock_put(csk);\r\n}\r\nvoid cxgbi_sock_rcv_close_conn_rpl(struct cxgbi_sock *csk, u32 snd_nxt)\r\n{\r\nlog_debug(1 << CXGBI_DBG_SOCK, "csk 0x%p,%u,0x%lx,%u.\n",\r\ncsk, (csk)->state, (csk)->flags, (csk)->tid);\r\ncxgbi_sock_get(csk);\r\nspin_lock_bh(&csk->lock);\r\ncsk->snd_una = snd_nxt - 1;\r\nif (cxgbi_sock_flag(csk, CTPF_ABORT_RPL_PENDING))\r\ngoto done;\r\nswitch (csk->state) {\r\ncase CTP_ACTIVE_CLOSE:\r\ncxgbi_sock_set_state(csk, CTP_CLOSE_WAIT_1);\r\nbreak;\r\ncase CTP_CLOSE_WAIT_1:\r\ncase CTP_CLOSE_WAIT_2:\r\ncxgbi_sock_closed(csk);\r\nbreak;\r\ncase CTP_ABORTING:\r\nbreak;\r\ndefault:\r\npr_err("csk 0x%p,%u,0x%lx,%u, bad state.\n",\r\ncsk, csk->state, csk->flags, csk->tid);\r\n}\r\ndone:\r\nspin_unlock_bh(&csk->lock);\r\ncxgbi_sock_put(csk);\r\n}\r\nvoid cxgbi_sock_rcv_wr_ack(struct cxgbi_sock *csk, unsigned int credits,\r\nunsigned int snd_una, int seq_chk)\r\n{\r\nlog_debug(1 << CXGBI_DBG_TOE | 1 << CXGBI_DBG_SOCK,\r\n"csk 0x%p,%u,0x%lx,%u, cr %u,%u+%u, snd_una %u,%d.\n",\r\ncsk, csk->state, csk->flags, csk->tid, credits,\r\ncsk->wr_cred, csk->wr_una_cred, snd_una, seq_chk);\r\nspin_lock_bh(&csk->lock);\r\ncsk->wr_cred += credits;\r\nif (csk->wr_una_cred > csk->wr_max_cred - csk->wr_cred)\r\ncsk->wr_una_cred = csk->wr_max_cred - csk->wr_cred;\r\nwhile (credits) {\r\nstruct sk_buff *p = cxgbi_sock_peek_wr(csk);\r\nif (unlikely(!p)) {\r\npr_err("csk 0x%p,%u,0x%lx,%u, cr %u,%u+%u, empty.\n",\r\ncsk, csk->state, csk->flags, csk->tid, credits,\r\ncsk->wr_cred, csk->wr_una_cred);\r\nbreak;\r\n}\r\nif (unlikely(credits < p->csum)) {\r\npr_warn("csk 0x%p,%u,0x%lx,%u, cr %u,%u+%u, < %u.\n",\r\ncsk, csk->state, csk->flags, csk->tid,\r\ncredits, csk->wr_cred, csk->wr_una_cred,\r\np->csum);\r\np->csum -= credits;\r\nbreak;\r\n} else {\r\ncxgbi_sock_dequeue_wr(csk);\r\ncredits -= p->csum;\r\nkfree_skb(p);\r\n}\r\n}\r\ncxgbi_sock_check_wr_invariants(csk);\r\nif (seq_chk) {\r\nif (unlikely(before(snd_una, csk->snd_una))) {\r\npr_warn("csk 0x%p,%u,0x%lx,%u, snd_una %u/%u.",\r\ncsk, csk->state, csk->flags, csk->tid, snd_una,\r\ncsk->snd_una);\r\ngoto done;\r\n}\r\nif (csk->snd_una != snd_una) {\r\ncsk->snd_una = snd_una;\r\ndst_confirm(csk->dst);\r\n}\r\n}\r\nif (skb_queue_len(&csk->write_queue)) {\r\nif (csk->cdev->csk_push_tx_frames(csk, 0))\r\ncxgbi_conn_tx_open(csk);\r\n} else\r\ncxgbi_conn_tx_open(csk);\r\ndone:\r\nspin_unlock_bh(&csk->lock);\r\n}\r\nstatic unsigned int cxgbi_sock_find_best_mtu(struct cxgbi_sock *csk,\r\nunsigned short mtu)\r\n{\r\nint i = 0;\r\nwhile (i < csk->cdev->nmtus - 1 && csk->cdev->mtus[i + 1] <= mtu)\r\n++i;\r\nreturn i;\r\n}\r\nunsigned int cxgbi_sock_select_mss(struct cxgbi_sock *csk, unsigned int pmtu)\r\n{\r\nunsigned int idx;\r\nstruct dst_entry *dst = csk->dst;\r\ncsk->advmss = dst_metric_advmss(dst);\r\nif (csk->advmss > pmtu - 40)\r\ncsk->advmss = pmtu - 40;\r\nif (csk->advmss < csk->cdev->mtus[0] - 40)\r\ncsk->advmss = csk->cdev->mtus[0] - 40;\r\nidx = cxgbi_sock_find_best_mtu(csk, csk->advmss + 40);\r\nreturn idx;\r\n}\r\nvoid cxgbi_sock_skb_entail(struct cxgbi_sock *csk, struct sk_buff *skb)\r\n{\r\ncxgbi_skcb_tcp_seq(skb) = csk->write_seq;\r\n__skb_queue_tail(&csk->write_queue, skb);\r\n}\r\nvoid cxgbi_sock_purge_wr_queue(struct cxgbi_sock *csk)\r\n{\r\nstruct sk_buff *skb;\r\nwhile ((skb = cxgbi_sock_dequeue_wr(csk)) != NULL)\r\nkfree_skb(skb);\r\n}\r\nvoid cxgbi_sock_check_wr_invariants(const struct cxgbi_sock *csk)\r\n{\r\nint pending = cxgbi_sock_count_pending_wrs(csk);\r\nif (unlikely(csk->wr_cred + pending != csk->wr_max_cred))\r\npr_err("csk 0x%p, tid %u, credit %u + %u != %u.\n",\r\ncsk, csk->tid, csk->wr_cred, pending, csk->wr_max_cred);\r\n}\r\nstatic int cxgbi_sock_send_pdus(struct cxgbi_sock *csk, struct sk_buff *skb)\r\n{\r\nstruct cxgbi_device *cdev = csk->cdev;\r\nstruct sk_buff *next;\r\nint err, copied = 0;\r\nspin_lock_bh(&csk->lock);\r\nif (csk->state != CTP_ESTABLISHED) {\r\nlog_debug(1 << CXGBI_DBG_PDU_TX,\r\n"csk 0x%p,%u,0x%lx,%u, EAGAIN.\n",\r\ncsk, csk->state, csk->flags, csk->tid);\r\nerr = -EAGAIN;\r\ngoto out_err;\r\n}\r\nif (csk->err) {\r\nlog_debug(1 << CXGBI_DBG_PDU_TX,\r\n"csk 0x%p,%u,0x%lx,%u, EPIPE %d.\n",\r\ncsk, csk->state, csk->flags, csk->tid, csk->err);\r\nerr = -EPIPE;\r\ngoto out_err;\r\n}\r\nif (csk->write_seq - csk->snd_una >= cdev->snd_win) {\r\nlog_debug(1 << CXGBI_DBG_PDU_TX,\r\n"csk 0x%p,%u,0x%lx,%u, FULL %u-%u >= %u.\n",\r\ncsk, csk->state, csk->flags, csk->tid, csk->write_seq,\r\ncsk->snd_una, cdev->snd_win);\r\nerr = -ENOBUFS;\r\ngoto out_err;\r\n}\r\nwhile (skb) {\r\nint frags = skb_shinfo(skb)->nr_frags +\r\n(skb->len != skb->data_len);\r\nif (unlikely(skb_headroom(skb) < cdev->skb_tx_rsvd)) {\r\npr_err("csk 0x%p, skb head %u < %u.\n",\r\ncsk, skb_headroom(skb), cdev->skb_tx_rsvd);\r\nerr = -EINVAL;\r\ngoto out_err;\r\n}\r\nif (frags >= SKB_WR_LIST_SIZE) {\r\npr_err("csk 0x%p, frags %d, %u,%u >%u.\n",\r\ncsk, skb_shinfo(skb)->nr_frags, skb->len,\r\nskb->data_len, (uint)(SKB_WR_LIST_SIZE));\r\nerr = -EINVAL;\r\ngoto out_err;\r\n}\r\nnext = skb->next;\r\nskb->next = NULL;\r\ncxgbi_skcb_set_flag(skb, SKCBF_TX_NEED_HDR);\r\ncxgbi_sock_skb_entail(csk, skb);\r\ncopied += skb->len;\r\ncsk->write_seq += skb->len +\r\ncxgbi_ulp_extra_len(cxgbi_skcb_ulp_mode(skb));\r\nskb = next;\r\n}\r\ndone:\r\nif (likely(skb_queue_len(&csk->write_queue)))\r\ncdev->csk_push_tx_frames(csk, 1);\r\nspin_unlock_bh(&csk->lock);\r\nreturn copied;\r\nout_err:\r\nif (copied == 0 && err == -EPIPE)\r\ncopied = csk->err ? csk->err : -EPIPE;\r\nelse\r\ncopied = err;\r\ngoto done;\r\n}\r\nstatic int ddp_adjust_page_table(void)\r\n{\r\nint i;\r\nunsigned int base_order, order;\r\nif (PAGE_SIZE < (1UL << ddp_page_shift[0])) {\r\npr_info("PAGE_SIZE 0x%lx too small, min 0x%lx\n",\r\nPAGE_SIZE, 1UL << ddp_page_shift[0]);\r\nreturn -EINVAL;\r\n}\r\nbase_order = get_order(1UL << ddp_page_shift[0]);\r\norder = get_order(1UL << PAGE_SHIFT);\r\nfor (i = 0; i < DDP_PGIDX_MAX; i++) {\r\nddp_page_order[i] = order - base_order + i;\r\nddp_page_shift[i] = PAGE_SHIFT + i;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ddp_find_page_index(unsigned long pgsz)\r\n{\r\nint i;\r\nfor (i = 0; i < DDP_PGIDX_MAX; i++) {\r\nif (pgsz == (1UL << ddp_page_shift[i]))\r\nreturn i;\r\n}\r\npr_info("ddp page size %lu not supported.\n", pgsz);\r\nreturn DDP_PGIDX_MAX;\r\n}\r\nstatic void ddp_setup_host_page_size(void)\r\n{\r\nif (page_idx == DDP_PGIDX_MAX) {\r\npage_idx = ddp_find_page_index(PAGE_SIZE);\r\nif (page_idx == DDP_PGIDX_MAX) {\r\npr_info("system PAGE %lu, update hw.\n", PAGE_SIZE);\r\nif (ddp_adjust_page_table() < 0) {\r\npr_info("PAGE %lu, disable ddp.\n", PAGE_SIZE);\r\nreturn;\r\n}\r\npage_idx = ddp_find_page_index(PAGE_SIZE);\r\n}\r\npr_info("system PAGE %lu, ddp idx %u.\n", PAGE_SIZE, page_idx);\r\n}\r\n}\r\nvoid cxgbi_ddp_page_size_factor(int *pgsz_factor)\r\n{\r\nint i;\r\nfor (i = 0; i < DDP_PGIDX_MAX; i++)\r\npgsz_factor[i] = ddp_page_order[i];\r\n}\r\nvoid cxgbi_ddp_ppod_set(struct cxgbi_pagepod *ppod,\r\nstruct cxgbi_pagepod_hdr *hdr,\r\nstruct cxgbi_gather_list *gl, unsigned int gidx)\r\n{\r\nint i;\r\nmemcpy(ppod, hdr, sizeof(*hdr));\r\nfor (i = 0; i < (PPOD_PAGES_MAX + 1); i++, gidx++) {\r\nppod->addr[i] = gidx < gl->nelem ?\r\ncpu_to_be64(gl->phys_addr[gidx]) : 0ULL;\r\n}\r\n}\r\nvoid cxgbi_ddp_ppod_clear(struct cxgbi_pagepod *ppod)\r\n{\r\nmemset(ppod, 0, sizeof(*ppod));\r\n}\r\nstatic inline int ddp_find_unused_entries(struct cxgbi_ddp_info *ddp,\r\nunsigned int start, unsigned int max,\r\nunsigned int count,\r\nstruct cxgbi_gather_list *gl)\r\n{\r\nunsigned int i, j, k;\r\nif ((max - start) < count) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"NOT enough entries %u+%u < %u.\n", start, count, max);\r\nreturn -EBUSY;\r\n}\r\nmax -= count;\r\nspin_lock(&ddp->map_lock);\r\nfor (i = start; i < max;) {\r\nfor (j = 0, k = i; j < count; j++, k++) {\r\nif (ddp->gl_map[k])\r\nbreak;\r\n}\r\nif (j == count) {\r\nfor (j = 0, k = i; j < count; j++, k++)\r\nddp->gl_map[k] = gl;\r\nspin_unlock(&ddp->map_lock);\r\nreturn i;\r\n}\r\ni += j + 1;\r\n}\r\nspin_unlock(&ddp->map_lock);\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"NO suitable entries %u available.\n", count);\r\nreturn -EBUSY;\r\n}\r\nstatic inline void ddp_unmark_entries(struct cxgbi_ddp_info *ddp,\r\nint start, int count)\r\n{\r\nspin_lock(&ddp->map_lock);\r\nmemset(&ddp->gl_map[start], 0,\r\ncount * sizeof(struct cxgbi_gather_list *));\r\nspin_unlock(&ddp->map_lock);\r\n}\r\nstatic inline void ddp_gl_unmap(struct pci_dev *pdev,\r\nstruct cxgbi_gather_list *gl)\r\n{\r\nint i;\r\nfor (i = 0; i < gl->nelem; i++)\r\ndma_unmap_page(&pdev->dev, gl->phys_addr[i], PAGE_SIZE,\r\nPCI_DMA_FROMDEVICE);\r\n}\r\nstatic inline int ddp_gl_map(struct pci_dev *pdev,\r\nstruct cxgbi_gather_list *gl)\r\n{\r\nint i;\r\nfor (i = 0; i < gl->nelem; i++) {\r\ngl->phys_addr[i] = dma_map_page(&pdev->dev, gl->pages[i], 0,\r\nPAGE_SIZE,\r\nPCI_DMA_FROMDEVICE);\r\nif (unlikely(dma_mapping_error(&pdev->dev, gl->phys_addr[i]))) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"page %d 0x%p, 0x%p dma mapping err.\n",\r\ni, gl->pages[i], pdev);\r\ngoto unmap;\r\n}\r\n}\r\nreturn i;\r\nunmap:\r\nif (i) {\r\nunsigned int nelem = gl->nelem;\r\ngl->nelem = i;\r\nddp_gl_unmap(pdev, gl);\r\ngl->nelem = nelem;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic void ddp_release_gl(struct cxgbi_gather_list *gl,\r\nstruct pci_dev *pdev)\r\n{\r\nddp_gl_unmap(pdev, gl);\r\nkfree(gl);\r\n}\r\nstatic struct cxgbi_gather_list *ddp_make_gl(unsigned int xferlen,\r\nstruct scatterlist *sgl,\r\nunsigned int sgcnt,\r\nstruct pci_dev *pdev,\r\ngfp_t gfp)\r\n{\r\nstruct cxgbi_gather_list *gl;\r\nstruct scatterlist *sg = sgl;\r\nstruct page *sgpage = sg_page(sg);\r\nunsigned int sglen = sg->length;\r\nunsigned int sgoffset = sg->offset;\r\nunsigned int npages = (xferlen + sgoffset + PAGE_SIZE - 1) >>\r\nPAGE_SHIFT;\r\nint i = 1, j = 0;\r\nif (xferlen < DDP_THRESHOLD) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"xfer %u < threshold %u, no ddp.\n",\r\nxferlen, DDP_THRESHOLD);\r\nreturn NULL;\r\n}\r\ngl = kzalloc(sizeof(struct cxgbi_gather_list) +\r\nnpages * (sizeof(dma_addr_t) +\r\nsizeof(struct page *)), gfp);\r\nif (!gl) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"xfer %u, %u pages, OOM.\n", xferlen, npages);\r\nreturn NULL;\r\n}\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"xfer %u, sgl %u, gl max %u.\n", xferlen, sgcnt, npages);\r\ngl->pages = (struct page **)&gl->phys_addr[npages];\r\ngl->nelem = npages;\r\ngl->length = xferlen;\r\ngl->offset = sgoffset;\r\ngl->pages[0] = sgpage;\r\nfor (i = 1, sg = sg_next(sgl), j = 0; i < sgcnt;\r\ni++, sg = sg_next(sg)) {\r\nstruct page *page = sg_page(sg);\r\nif (sgpage == page && sg->offset == sgoffset + sglen)\r\nsglen += sg->length;\r\nelse {\r\nif ((j && sgoffset) || ((i != sgcnt - 1) &&\r\n((sglen + sgoffset) & ~PAGE_MASK))) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"page %d/%u, %u + %u.\n",\r\ni, sgcnt, sgoffset, sglen);\r\ngoto error_out;\r\n}\r\nj++;\r\nif (j == gl->nelem || sg->offset) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"page %d/%u, offset %u.\n",\r\nj, gl->nelem, sg->offset);\r\ngoto error_out;\r\n}\r\ngl->pages[j] = page;\r\nsglen = sg->length;\r\nsgoffset = sg->offset;\r\nsgpage = page;\r\n}\r\n}\r\ngl->nelem = ++j;\r\nif (ddp_gl_map(pdev, gl) < 0)\r\ngoto error_out;\r\nreturn gl;\r\nerror_out:\r\nkfree(gl);\r\nreturn NULL;\r\n}\r\nstatic void ddp_tag_release(struct cxgbi_hba *chba, u32 tag)\r\n{\r\nstruct cxgbi_device *cdev = chba->cdev;\r\nstruct cxgbi_ddp_info *ddp = cdev->ddp;\r\nu32 idx;\r\nidx = (tag >> PPOD_IDX_SHIFT) & ddp->idx_mask;\r\nif (idx < ddp->nppods) {\r\nstruct cxgbi_gather_list *gl = ddp->gl_map[idx];\r\nunsigned int npods;\r\nif (!gl || !gl->nelem) {\r\npr_warn("tag 0x%x, idx %u, gl 0x%p, %u.\n",\r\ntag, idx, gl, gl ? gl->nelem : 0);\r\nreturn;\r\n}\r\nnpods = (gl->nelem + PPOD_PAGES_MAX - 1) >> PPOD_PAGES_SHIFT;\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"tag 0x%x, release idx %u, npods %u.\n",\r\ntag, idx, npods);\r\ncdev->csk_ddp_clear(chba, tag, idx, npods);\r\nddp_unmark_entries(ddp, idx, npods);\r\nddp_release_gl(gl, ddp->pdev);\r\n} else\r\npr_warn("tag 0x%x, idx %u > max %u.\n", tag, idx, ddp->nppods);\r\n}\r\nstatic int ddp_tag_reserve(struct cxgbi_sock *csk, unsigned int tid,\r\nu32 sw_tag, u32 *tagp, struct cxgbi_gather_list *gl,\r\ngfp_t gfp)\r\n{\r\nstruct cxgbi_device *cdev = csk->cdev;\r\nstruct cxgbi_ddp_info *ddp = cdev->ddp;\r\nstruct cxgbi_tag_format *tformat = &cdev->tag_format;\r\nstruct cxgbi_pagepod_hdr hdr;\r\nunsigned int npods;\r\nint idx = -1;\r\nint err = -ENOMEM;\r\nu32 tag;\r\nnpods = (gl->nelem + PPOD_PAGES_MAX - 1) >> PPOD_PAGES_SHIFT;\r\nif (ddp->idx_last == ddp->nppods)\r\nidx = ddp_find_unused_entries(ddp, 0, ddp->nppods,\r\nnpods, gl);\r\nelse {\r\nidx = ddp_find_unused_entries(ddp, ddp->idx_last + 1,\r\nddp->nppods, npods,\r\ngl);\r\nif (idx < 0 && ddp->idx_last >= npods) {\r\nidx = ddp_find_unused_entries(ddp, 0,\r\nmin(ddp->idx_last + npods, ddp->nppods),\r\nnpods, gl);\r\n}\r\n}\r\nif (idx < 0) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"xferlen %u, gl %u, npods %u NO DDP.\n",\r\ngl->length, gl->nelem, npods);\r\nreturn idx;\r\n}\r\ntag = cxgbi_ddp_tag_base(tformat, sw_tag);\r\ntag |= idx << PPOD_IDX_SHIFT;\r\nhdr.rsvd = 0;\r\nhdr.vld_tid = htonl(PPOD_VALID_FLAG | PPOD_TID(tid));\r\nhdr.pgsz_tag_clr = htonl(tag & ddp->rsvd_tag_mask);\r\nhdr.max_offset = htonl(gl->length);\r\nhdr.page_offset = htonl(gl->offset);\r\nerr = cdev->csk_ddp_set(csk, &hdr, idx, npods, gl);\r\nif (err < 0)\r\ngoto unmark_entries;\r\nddp->idx_last = idx;\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"xfer %u, gl %u,%u, tid 0x%x, tag 0x%x->0x%x(%u,%u).\n",\r\ngl->length, gl->nelem, gl->offset, tid, sw_tag, tag, idx,\r\nnpods);\r\n*tagp = tag;\r\nreturn 0;\r\nunmark_entries:\r\nddp_unmark_entries(ddp, idx, npods);\r\nreturn err;\r\n}\r\nint cxgbi_ddp_reserve(struct cxgbi_sock *csk, unsigned int *tagp,\r\nunsigned int sw_tag, unsigned int xferlen,\r\nstruct scatterlist *sgl, unsigned int sgcnt, gfp_t gfp)\r\n{\r\nstruct cxgbi_device *cdev = csk->cdev;\r\nstruct cxgbi_tag_format *tformat = &cdev->tag_format;\r\nstruct cxgbi_gather_list *gl;\r\nint err;\r\nif (page_idx >= DDP_PGIDX_MAX || !cdev->ddp ||\r\nxferlen < DDP_THRESHOLD) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"pgidx %u, xfer %u, NO ddp.\n", page_idx, xferlen);\r\nreturn -EINVAL;\r\n}\r\nif (!cxgbi_sw_tag_usable(tformat, sw_tag)) {\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"sw_tag 0x%x NOT usable.\n", sw_tag);\r\nreturn -EINVAL;\r\n}\r\ngl = ddp_make_gl(xferlen, sgl, sgcnt, cdev->pdev, gfp);\r\nif (!gl)\r\nreturn -ENOMEM;\r\nerr = ddp_tag_reserve(csk, csk->tid, sw_tag, tagp, gl, gfp);\r\nif (err < 0)\r\nddp_release_gl(gl, cdev->pdev);\r\nreturn err;\r\n}\r\nstatic void ddp_destroy(struct kref *kref)\r\n{\r\nstruct cxgbi_ddp_info *ddp = container_of(kref,\r\nstruct cxgbi_ddp_info,\r\nrefcnt);\r\nstruct cxgbi_device *cdev = ddp->cdev;\r\nint i = 0;\r\npr_info("kref 0, destroy ddp 0x%p, cdev 0x%p.\n", ddp, cdev);\r\nwhile (i < ddp->nppods) {\r\nstruct cxgbi_gather_list *gl = ddp->gl_map[i];\r\nif (gl) {\r\nint npods = (gl->nelem + PPOD_PAGES_MAX - 1)\r\n>> PPOD_PAGES_SHIFT;\r\npr_info("cdev 0x%p, ddp %d + %d.\n", cdev, i, npods);\r\nkfree(gl);\r\ni += npods;\r\n} else\r\ni++;\r\n}\r\ncxgbi_free_big_mem(ddp);\r\n}\r\nint cxgbi_ddp_cleanup(struct cxgbi_device *cdev)\r\n{\r\nstruct cxgbi_ddp_info *ddp = cdev->ddp;\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"cdev 0x%p, release ddp 0x%p.\n", cdev, ddp);\r\ncdev->ddp = NULL;\r\nif (ddp)\r\nreturn kref_put(&ddp->refcnt, ddp_destroy);\r\nreturn 0;\r\n}\r\nint cxgbi_ddp_init(struct cxgbi_device *cdev,\r\nunsigned int llimit, unsigned int ulimit,\r\nunsigned int max_txsz, unsigned int max_rxsz)\r\n{\r\nstruct cxgbi_ddp_info *ddp;\r\nunsigned int ppmax, bits;\r\nppmax = (ulimit - llimit + 1) >> PPOD_SIZE_SHIFT;\r\nbits = __ilog2_u32(ppmax) + 1;\r\nif (bits > PPOD_IDX_MAX_SIZE)\r\nbits = PPOD_IDX_MAX_SIZE;\r\nppmax = (1 << (bits - 1)) - 1;\r\nddp = cxgbi_alloc_big_mem(sizeof(struct cxgbi_ddp_info) +\r\nppmax * (sizeof(struct cxgbi_gather_list *) +\r\nsizeof(struct sk_buff *)),\r\nGFP_KERNEL);\r\nif (!ddp) {\r\npr_warn("cdev 0x%p, ddp ppmax %u OOM.\n", cdev, ppmax);\r\nreturn -ENOMEM;\r\n}\r\nddp->gl_map = (struct cxgbi_gather_list **)(ddp + 1);\r\ncdev->ddp = ddp;\r\nspin_lock_init(&ddp->map_lock);\r\nkref_init(&ddp->refcnt);\r\nddp->cdev = cdev;\r\nddp->pdev = cdev->pdev;\r\nddp->llimit = llimit;\r\nddp->ulimit = ulimit;\r\nddp->max_txsz = min_t(unsigned int, max_txsz, ULP2_MAX_PKT_SIZE);\r\nddp->max_rxsz = min_t(unsigned int, max_rxsz, ULP2_MAX_PKT_SIZE);\r\nddp->nppods = ppmax;\r\nddp->idx_last = ppmax;\r\nddp->idx_bits = bits;\r\nddp->idx_mask = (1 << bits) - 1;\r\nddp->rsvd_tag_mask = (1 << (bits + PPOD_IDX_SHIFT)) - 1;\r\ncdev->tag_format.sw_bits = sw_tag_idx_bits + sw_tag_age_bits;\r\ncdev->tag_format.rsvd_bits = ddp->idx_bits;\r\ncdev->tag_format.rsvd_shift = PPOD_IDX_SHIFT;\r\ncdev->tag_format.rsvd_mask = (1 << cdev->tag_format.rsvd_bits) - 1;\r\npr_info("%s tag format, sw %u, rsvd %u,%u, mask 0x%x.\n",\r\ncdev->ports[0]->name, cdev->tag_format.sw_bits,\r\ncdev->tag_format.rsvd_bits, cdev->tag_format.rsvd_shift,\r\ncdev->tag_format.rsvd_mask);\r\ncdev->tx_max_size = min_t(unsigned int, ULP2_MAX_PDU_PAYLOAD,\r\nddp->max_txsz - ISCSI_PDU_NONPAYLOAD_LEN);\r\ncdev->rx_max_size = min_t(unsigned int, ULP2_MAX_PDU_PAYLOAD,\r\nddp->max_rxsz - ISCSI_PDU_NONPAYLOAD_LEN);\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"%s max payload size: %u/%u, %u/%u.\n",\r\ncdev->ports[0]->name, cdev->tx_max_size, ddp->max_txsz,\r\ncdev->rx_max_size, ddp->max_rxsz);\r\nreturn 0;\r\n}\r\nstatic void task_release_itt(struct iscsi_task *task, itt_t hdr_itt)\r\n{\r\nstruct scsi_cmnd *sc = task->sc;\r\nstruct iscsi_tcp_conn *tcp_conn = task->conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct cxgbi_hba *chba = cconn->chba;\r\nstruct cxgbi_tag_format *tformat = &chba->cdev->tag_format;\r\nu32 tag = ntohl((__force u32)hdr_itt);\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"cdev 0x%p, release tag 0x%x.\n", chba->cdev, tag);\r\nif (sc &&\r\n(scsi_bidi_cmnd(sc) || sc->sc_data_direction == DMA_FROM_DEVICE) &&\r\ncxgbi_is_ddp_tag(tformat, tag))\r\nddp_tag_release(chba, tag);\r\n}\r\nstatic int task_reserve_itt(struct iscsi_task *task, itt_t *hdr_itt)\r\n{\r\nstruct scsi_cmnd *sc = task->sc;\r\nstruct iscsi_conn *conn = task->conn;\r\nstruct iscsi_session *sess = conn->session;\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct cxgbi_hba *chba = cconn->chba;\r\nstruct cxgbi_tag_format *tformat = &chba->cdev->tag_format;\r\nu32 sw_tag = (sess->age << cconn->task_idx_bits) | task->itt;\r\nu32 tag = 0;\r\nint err = -EINVAL;\r\nif (sc &&\r\n(scsi_bidi_cmnd(sc) || sc->sc_data_direction == DMA_FROM_DEVICE)) {\r\nerr = cxgbi_ddp_reserve(cconn->cep->csk, &tag, sw_tag,\r\nscsi_in(sc)->length,\r\nscsi_in(sc)->table.sgl,\r\nscsi_in(sc)->table.nents,\r\nGFP_ATOMIC);\r\nif (err < 0)\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"csk 0x%p, R task 0x%p, %u,%u, no ddp.\n",\r\ncconn->cep->csk, task, scsi_in(sc)->length,\r\nscsi_in(sc)->table.nents);\r\n}\r\nif (err < 0)\r\ntag = cxgbi_set_non_ddp_tag(tformat, sw_tag);\r\n*hdr_itt = (__force itt_t)htonl(tag);\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"cdev 0x%p, task 0x%p, 0x%x(0x%x,0x%x)->0x%x/0x%x.\n",\r\nchba->cdev, task, sw_tag, task->itt, sess->age, tag, *hdr_itt);\r\nreturn 0;\r\n}\r\nvoid cxgbi_parse_pdu_itt(struct iscsi_conn *conn, itt_t itt, int *idx, int *age)\r\n{\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct cxgbi_device *cdev = cconn->chba->cdev;\r\nu32 tag = ntohl((__force u32) itt);\r\nu32 sw_bits;\r\nsw_bits = cxgbi_tag_nonrsvd_bits(&cdev->tag_format, tag);\r\nif (idx)\r\n*idx = sw_bits & ((1 << cconn->task_idx_bits) - 1);\r\nif (age)\r\n*age = (sw_bits >> cconn->task_idx_bits) & ISCSI_AGE_MASK;\r\nlog_debug(1 << CXGBI_DBG_DDP,\r\n"cdev 0x%p, tag 0x%x/0x%x, -> 0x%x(0x%x,0x%x).\n",\r\ncdev, tag, itt, sw_bits, idx ? *idx : 0xFFFFF,\r\nage ? *age : 0xFF);\r\n}\r\nvoid cxgbi_conn_tx_open(struct cxgbi_sock *csk)\r\n{\r\nstruct iscsi_conn *conn = csk->user_data;\r\nif (conn) {\r\nlog_debug(1 << CXGBI_DBG_SOCK,\r\n"csk 0x%p, cid %d.\n", csk, conn->id);\r\niscsi_conn_queue_work(conn);\r\n}\r\n}\r\nstatic inline int read_pdu_skb(struct iscsi_conn *conn,\r\nstruct sk_buff *skb,\r\nunsigned int offset,\r\nint offloaded)\r\n{\r\nint status = 0;\r\nint bytes_read;\r\nbytes_read = iscsi_tcp_recv_skb(conn, skb, offset, offloaded, &status);\r\nswitch (status) {\r\ncase ISCSI_TCP_CONN_ERR:\r\npr_info("skb 0x%p, off %u, %d, TCP_ERR.\n",\r\nskb, offset, offloaded);\r\nreturn -EIO;\r\ncase ISCSI_TCP_SUSPENDED:\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"skb 0x%p, off %u, %d, TCP_SUSPEND, rc %d.\n",\r\nskb, offset, offloaded, bytes_read);\r\nreturn bytes_read;\r\ncase ISCSI_TCP_SKB_DONE:\r\npr_info("skb 0x%p, off %u, %d, TCP_SKB_DONE.\n",\r\nskb, offset, offloaded);\r\niscsi_conn_printk(KERN_ERR, conn, "Invalid pdu or skb.");\r\nreturn -EFAULT;\r\ncase ISCSI_TCP_SEGMENT_DONE:\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"skb 0x%p, off %u, %d, TCP_SEG_DONE, rc %d.\n",\r\nskb, offset, offloaded, bytes_read);\r\nreturn bytes_read;\r\ndefault:\r\npr_info("skb 0x%p, off %u, %d, invalid status %d.\n",\r\nskb, offset, offloaded, status);\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int skb_read_pdu_bhs(struct iscsi_conn *conn, struct sk_buff *skb)\r\n{\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"conn 0x%p, skb 0x%p, len %u, flag 0x%lx.\n",\r\nconn, skb, skb->len, cxgbi_skcb_flags(skb));\r\nif (!iscsi_tcp_recv_segment_is_hdr(tcp_conn)) {\r\npr_info("conn 0x%p, skb 0x%p, not hdr.\n", conn, skb);\r\niscsi_conn_failure(conn, ISCSI_ERR_PROTO);\r\nreturn -EIO;\r\n}\r\nif (conn->hdrdgst_en &&\r\ncxgbi_skcb_test_flag(skb, SKCBF_RX_HCRC_ERR)) {\r\npr_info("conn 0x%p, skb 0x%p, hcrc.\n", conn, skb);\r\niscsi_conn_failure(conn, ISCSI_ERR_HDR_DGST);\r\nreturn -EIO;\r\n}\r\nreturn read_pdu_skb(conn, skb, 0, 0);\r\n}\r\nstatic int skb_read_pdu_data(struct iscsi_conn *conn, struct sk_buff *lskb,\r\nstruct sk_buff *skb, unsigned int offset)\r\n{\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nbool offloaded = 0;\r\nint opcode = tcp_conn->in.hdr->opcode & ISCSI_OPCODE_MASK;\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"conn 0x%p, skb 0x%p, len %u, flag 0x%lx.\n",\r\nconn, skb, skb->len, cxgbi_skcb_flags(skb));\r\nif (conn->datadgst_en &&\r\ncxgbi_skcb_test_flag(lskb, SKCBF_RX_DCRC_ERR)) {\r\npr_info("conn 0x%p, skb 0x%p, dcrc 0x%lx.\n",\r\nconn, lskb, cxgbi_skcb_flags(lskb));\r\niscsi_conn_failure(conn, ISCSI_ERR_DATA_DGST);\r\nreturn -EIO;\r\n}\r\nif (iscsi_tcp_recv_segment_is_hdr(tcp_conn))\r\nreturn 0;\r\nif (lskb == skb && conn->hdrdgst_en)\r\noffset += ISCSI_DIGEST_SIZE;\r\nif (cxgbi_skcb_test_flag(lskb, SKCBF_RX_DATA_DDPD))\r\noffloaded = 1;\r\nif (opcode == ISCSI_OP_SCSI_DATA_IN)\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"skb 0x%p, op 0x%x, itt 0x%x, %u %s ddp'ed.\n",\r\nskb, opcode, ntohl(tcp_conn->in.hdr->itt),\r\ntcp_conn->in.datalen, offloaded ? "is" : "not");\r\nreturn read_pdu_skb(conn, skb, offset, offloaded);\r\n}\r\nstatic void csk_return_rx_credits(struct cxgbi_sock *csk, int copied)\r\n{\r\nstruct cxgbi_device *cdev = csk->cdev;\r\nint must_send;\r\nu32 credits;\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"csk 0x%p,%u,0x%lu,%u, seq %u, wup %u, thre %u, %u.\n",\r\ncsk, csk->state, csk->flags, csk->tid, csk->copied_seq,\r\ncsk->rcv_wup, cdev->rx_credit_thres,\r\ncdev->rcv_win);\r\nif (csk->state != CTP_ESTABLISHED)\r\nreturn;\r\ncredits = csk->copied_seq - csk->rcv_wup;\r\nif (unlikely(!credits))\r\nreturn;\r\nif (unlikely(cdev->rx_credit_thres == 0))\r\nreturn;\r\nmust_send = credits + 16384 >= cdev->rcv_win;\r\nif (must_send || credits >= cdev->rx_credit_thres)\r\ncsk->rcv_wup += cdev->csk_send_rx_credits(csk, credits);\r\n}\r\nvoid cxgbi_conn_pdu_ready(struct cxgbi_sock *csk)\r\n{\r\nstruct cxgbi_device *cdev = csk->cdev;\r\nstruct iscsi_conn *conn = csk->user_data;\r\nstruct sk_buff *skb;\r\nunsigned int read = 0;\r\nint err = 0;\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"csk 0x%p, conn 0x%p.\n", csk, conn);\r\nif (unlikely(!conn || conn->suspend_rx)) {\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"csk 0x%p, conn 0x%p, id %d, suspend_rx %lu!\n",\r\ncsk, conn, conn ? conn->id : 0xFF,\r\nconn ? conn->suspend_rx : 0xFF);\r\nreturn;\r\n}\r\nwhile (!err) {\r\nskb = skb_peek(&csk->receive_queue);\r\nif (!skb ||\r\n!(cxgbi_skcb_test_flag(skb, SKCBF_RX_STATUS))) {\r\nif (skb)\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"skb 0x%p, NOT ready 0x%lx.\n",\r\nskb, cxgbi_skcb_flags(skb));\r\nbreak;\r\n}\r\n__skb_unlink(skb, &csk->receive_queue);\r\nread += cxgbi_skcb_rx_pdulen(skb);\r\nlog_debug(1 << CXGBI_DBG_PDU_RX,\r\n"csk 0x%p, skb 0x%p,%u,f 0x%lx, pdu len %u.\n",\r\ncsk, skb, skb->len, cxgbi_skcb_flags(skb),\r\ncxgbi_skcb_rx_pdulen(skb));\r\nif (cxgbi_skcb_test_flag(skb, SKCBF_RX_COALESCED)) {\r\nerr = skb_read_pdu_bhs(conn, skb);\r\nif (err < 0) {\r\npr_err("coalesced bhs, csk 0x%p, skb 0x%p,%u, "\r\n"f 0x%lx, plen %u.\n",\r\ncsk, skb, skb->len,\r\ncxgbi_skcb_flags(skb),\r\ncxgbi_skcb_rx_pdulen(skb));\r\ngoto skb_done;\r\n}\r\nerr = skb_read_pdu_data(conn, skb, skb,\r\nerr + cdev->skb_rx_extra);\r\nif (err < 0)\r\npr_err("coalesced data, csk 0x%p, skb 0x%p,%u, "\r\n"f 0x%lx, plen %u.\n",\r\ncsk, skb, skb->len,\r\ncxgbi_skcb_flags(skb),\r\ncxgbi_skcb_rx_pdulen(skb));\r\n} else {\r\nerr = skb_read_pdu_bhs(conn, skb);\r\nif (err < 0) {\r\npr_err("bhs, csk 0x%p, skb 0x%p,%u, "\r\n"f 0x%lx, plen %u.\n",\r\ncsk, skb, skb->len,\r\ncxgbi_skcb_flags(skb),\r\ncxgbi_skcb_rx_pdulen(skb));\r\ngoto skb_done;\r\n}\r\nif (cxgbi_skcb_test_flag(skb, SKCBF_RX_DATA)) {\r\nstruct sk_buff *dskb;\r\ndskb = skb_peek(&csk->receive_queue);\r\nif (!dskb) {\r\npr_err("csk 0x%p, skb 0x%p,%u, f 0x%lx,"\r\n" plen %u, NO data.\n",\r\ncsk, skb, skb->len,\r\ncxgbi_skcb_flags(skb),\r\ncxgbi_skcb_rx_pdulen(skb));\r\nerr = -EIO;\r\ngoto skb_done;\r\n}\r\n__skb_unlink(dskb, &csk->receive_queue);\r\nerr = skb_read_pdu_data(conn, skb, dskb, 0);\r\nif (err < 0)\r\npr_err("data, csk 0x%p, skb 0x%p,%u, "\r\n"f 0x%lx, plen %u, dskb 0x%p,"\r\n"%u.\n",\r\ncsk, skb, skb->len,\r\ncxgbi_skcb_flags(skb),\r\ncxgbi_skcb_rx_pdulen(skb),\r\ndskb, dskb->len);\r\n__kfree_skb(dskb);\r\n} else\r\nerr = skb_read_pdu_data(conn, skb, skb, 0);\r\n}\r\nskb_done:\r\n__kfree_skb(skb);\r\nif (err < 0)\r\nbreak;\r\n}\r\nlog_debug(1 << CXGBI_DBG_PDU_RX, "csk 0x%p, read %u.\n", csk, read);\r\nif (read) {\r\ncsk->copied_seq += read;\r\ncsk_return_rx_credits(csk, read);\r\nconn->rxdata_octets += read;\r\n}\r\nif (err < 0) {\r\npr_info("csk 0x%p, 0x%p, rx failed %d, read %u.\n",\r\ncsk, conn, err, read);\r\niscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);\r\n}\r\n}\r\nstatic int sgl_seek_offset(struct scatterlist *sgl, unsigned int sgcnt,\r\nunsigned int offset, unsigned int *off,\r\nstruct scatterlist **sgp)\r\n{\r\nint i;\r\nstruct scatterlist *sg;\r\nfor_each_sg(sgl, sg, sgcnt, i) {\r\nif (offset < sg->length) {\r\n*off = offset;\r\n*sgp = sg;\r\nreturn 0;\r\n}\r\noffset -= sg->length;\r\n}\r\nreturn -EFAULT;\r\n}\r\nstatic int sgl_read_to_frags(struct scatterlist *sg, unsigned int sgoffset,\r\nunsigned int dlen, struct page_frag *frags,\r\nint frag_max)\r\n{\r\nunsigned int datalen = dlen;\r\nunsigned int sglen = sg->length - sgoffset;\r\nstruct page *page = sg_page(sg);\r\nint i;\r\ni = 0;\r\ndo {\r\nunsigned int copy;\r\nif (!sglen) {\r\nsg = sg_next(sg);\r\nif (!sg) {\r\npr_warn("sg %d NULL, len %u/%u.\n",\r\ni, datalen, dlen);\r\nreturn -EINVAL;\r\n}\r\nsgoffset = 0;\r\nsglen = sg->length;\r\npage = sg_page(sg);\r\n}\r\ncopy = min(datalen, sglen);\r\nif (i && page == frags[i - 1].page &&\r\nsgoffset + sg->offset ==\r\nfrags[i - 1].offset + frags[i - 1].size) {\r\nfrags[i - 1].size += copy;\r\n} else {\r\nif (i >= frag_max) {\r\npr_warn("too many pages %u, dlen %u.\n",\r\nfrag_max, dlen);\r\nreturn -EINVAL;\r\n}\r\nfrags[i].page = page;\r\nfrags[i].offset = sg->offset + sgoffset;\r\nfrags[i].size = copy;\r\ni++;\r\n}\r\ndatalen -= copy;\r\nsgoffset += copy;\r\nsglen -= copy;\r\n} while (datalen);\r\nreturn i;\r\n}\r\nint cxgbi_conn_alloc_pdu(struct iscsi_task *task, u8 opcode)\r\n{\r\nstruct iscsi_tcp_conn *tcp_conn = task->conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct cxgbi_device *cdev = cconn->chba->cdev;\r\nstruct iscsi_conn *conn = task->conn;\r\nstruct iscsi_tcp_task *tcp_task = task->dd_data;\r\nstruct cxgbi_task_data *tdata = iscsi_task_cxgbi_data(task);\r\nstruct scsi_cmnd *sc = task->sc;\r\nint headroom = SKB_TX_ISCSI_PDU_HEADER_MAX;\r\ntcp_task->dd_data = tdata;\r\ntask->hdr = NULL;\r\nif (SKB_MAX_HEAD(cdev->skb_tx_rsvd) > (512 * MAX_SKB_FRAGS) &&\r\n(opcode == ISCSI_OP_SCSI_DATA_OUT ||\r\n(opcode == ISCSI_OP_SCSI_CMD &&\r\n(scsi_bidi_cmnd(sc) || sc->sc_data_direction == DMA_TO_DEVICE))))\r\nheadroom += min_t(unsigned int,\r\nSKB_MAX_HEAD(cdev->skb_tx_rsvd),\r\nconn->max_xmit_dlength);\r\ntdata->skb = alloc_skb(cdev->skb_tx_rsvd + headroom, GFP_ATOMIC);\r\nif (!tdata->skb) {\r\nstruct cxgbi_sock *csk = cconn->cep->csk;\r\nstruct net_device *ndev = cdev->ports[csk->port_id];\r\nndev->stats.tx_dropped++;\r\nreturn -ENOMEM;\r\n}\r\nskb_reserve(tdata->skb, cdev->skb_tx_rsvd);\r\ntask->hdr = (struct iscsi_hdr *)tdata->skb->data;\r\ntask->hdr_max = SKB_TX_ISCSI_PDU_HEADER_MAX;\r\nif (opcode != ISCSI_OP_SCSI_DATA_OUT)\r\ntask_reserve_itt(task, &task->hdr->itt);\r\nlog_debug(1 << CXGBI_DBG_ISCSI | 1 << CXGBI_DBG_PDU_TX,\r\n"task 0x%p, op 0x%x, skb 0x%p,%u+%u/%u, itt 0x%x.\n",\r\ntask, opcode, tdata->skb, cdev->skb_tx_rsvd, headroom,\r\nconn->max_xmit_dlength, ntohl(task->hdr->itt));\r\nreturn 0;\r\n}\r\nstatic inline void tx_skb_setmode(struct sk_buff *skb, int hcrc, int dcrc)\r\n{\r\nif (hcrc || dcrc) {\r\nu8 submode = 0;\r\nif (hcrc)\r\nsubmode |= 1;\r\nif (dcrc)\r\nsubmode |= 2;\r\ncxgbi_skcb_ulp_mode(skb) = (ULP2_MODE_ISCSI << 4) | submode;\r\n} else\r\ncxgbi_skcb_ulp_mode(skb) = 0;\r\n}\r\nint cxgbi_conn_init_pdu(struct iscsi_task *task, unsigned int offset,\r\nunsigned int count)\r\n{\r\nstruct iscsi_conn *conn = task->conn;\r\nstruct cxgbi_task_data *tdata = iscsi_task_cxgbi_data(task);\r\nstruct sk_buff *skb = tdata->skb;\r\nunsigned int datalen = count;\r\nint i, padlen = iscsi_padding(count);\r\nstruct page *pg;\r\nlog_debug(1 << CXGBI_DBG_ISCSI | 1 << CXGBI_DBG_PDU_TX,\r\n"task 0x%p,0x%p, skb 0x%p, 0x%x,0x%x,0x%x, %u+%u.\n",\r\ntask, task->sc, skb, (*skb->data) & ISCSI_OPCODE_MASK,\r\nntohl(task->cmdsn), ntohl(task->hdr->itt), offset, count);\r\nskb_put(skb, task->hdr_len);\r\ntx_skb_setmode(skb, conn->hdrdgst_en, datalen ? conn->datadgst_en : 0);\r\nif (!count)\r\nreturn 0;\r\nif (task->sc) {\r\nstruct scsi_data_buffer *sdb = scsi_out(task->sc);\r\nstruct scatterlist *sg = NULL;\r\nint err;\r\ntdata->offset = offset;\r\ntdata->count = count;\r\nerr = sgl_seek_offset(\r\nsdb->table.sgl, sdb->table.nents,\r\ntdata->offset, &tdata->sgoffset, &sg);\r\nif (err < 0) {\r\npr_warn("tpdu, sgl %u, bad offset %u/%u.\n",\r\nsdb->table.nents, tdata->offset, sdb->length);\r\nreturn err;\r\n}\r\nerr = sgl_read_to_frags(sg, tdata->sgoffset, tdata->count,\r\ntdata->frags, MAX_PDU_FRAGS);\r\nif (err < 0) {\r\npr_warn("tpdu, sgl %u, bad offset %u + %u.\n",\r\nsdb->table.nents, tdata->offset, tdata->count);\r\nreturn err;\r\n}\r\ntdata->nr_frags = err;\r\nif (tdata->nr_frags > MAX_SKB_FRAGS ||\r\n(padlen && tdata->nr_frags == MAX_SKB_FRAGS)) {\r\nchar *dst = skb->data + task->hdr_len;\r\nstruct page_frag *frag = tdata->frags;\r\nfor (i = 0; i < tdata->nr_frags; i++, frag++) {\r\nchar *src = kmap_atomic(frag->page);\r\nmemcpy(dst, src+frag->offset, frag->size);\r\ndst += frag->size;\r\nkunmap_atomic(src);\r\n}\r\nif (padlen) {\r\nmemset(dst, 0, padlen);\r\npadlen = 0;\r\n}\r\nskb_put(skb, count + padlen);\r\n} else {\r\nfor (i = 0; i < tdata->nr_frags; i++) {\r\n__skb_fill_page_desc(skb, i,\r\ntdata->frags[i].page,\r\ntdata->frags[i].offset,\r\ntdata->frags[i].size);\r\nskb_frag_ref(skb, i);\r\n}\r\nskb_shinfo(skb)->nr_frags = tdata->nr_frags;\r\nskb->len += count;\r\nskb->data_len += count;\r\nskb->truesize += count;\r\n}\r\n} else {\r\npg = virt_to_page(task->data);\r\nget_page(pg);\r\nskb_fill_page_desc(skb, 0, pg, offset_in_page(task->data),\r\ncount);\r\nskb->len += count;\r\nskb->data_len += count;\r\nskb->truesize += count;\r\n}\r\nif (padlen) {\r\ni = skb_shinfo(skb)->nr_frags;\r\nskb_fill_page_desc(skb, skb_shinfo(skb)->nr_frags,\r\nvirt_to_page(padding), offset_in_page(padding),\r\npadlen);\r\nskb->data_len += padlen;\r\nskb->truesize += padlen;\r\nskb->len += padlen;\r\n}\r\nreturn 0;\r\n}\r\nint cxgbi_conn_xmit_pdu(struct iscsi_task *task)\r\n{\r\nstruct iscsi_tcp_conn *tcp_conn = task->conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct cxgbi_task_data *tdata = iscsi_task_cxgbi_data(task);\r\nstruct sk_buff *skb = tdata->skb;\r\nunsigned int datalen;\r\nint err;\r\nif (!skb) {\r\nlog_debug(1 << CXGBI_DBG_ISCSI | 1 << CXGBI_DBG_PDU_TX,\r\n"task 0x%p, skb NULL.\n", task);\r\nreturn 0;\r\n}\r\ndatalen = skb->data_len;\r\ntdata->skb = NULL;\r\nerr = cxgbi_sock_send_pdus(cconn->cep->csk, skb);\r\nif (err > 0) {\r\nint pdulen = err;\r\nlog_debug(1 << CXGBI_DBG_PDU_TX,\r\n"task 0x%p,0x%p, skb 0x%p, len %u/%u, rv %d.\n",\r\ntask, task->sc, skb, skb->len, skb->data_len, err);\r\nif (task->conn->hdrdgst_en)\r\npdulen += ISCSI_DIGEST_SIZE;\r\nif (datalen && task->conn->datadgst_en)\r\npdulen += ISCSI_DIGEST_SIZE;\r\ntask->conn->txdata_octets += pdulen;\r\nreturn 0;\r\n}\r\nif (err == -EAGAIN || err == -ENOBUFS) {\r\nlog_debug(1 << CXGBI_DBG_PDU_TX,\r\n"task 0x%p, skb 0x%p, len %u/%u, %d EAGAIN.\n",\r\ntask, skb, skb->len, skb->data_len, err);\r\ntdata->skb = skb;\r\nreturn err;\r\n}\r\nkfree_skb(skb);\r\nlog_debug(1 << CXGBI_DBG_ISCSI | 1 << CXGBI_DBG_PDU_TX,\r\n"itt 0x%x, skb 0x%p, len %u/%u, xmit err %d.\n",\r\ntask->itt, skb, skb->len, skb->data_len, err);\r\niscsi_conn_printk(KERN_ERR, task->conn, "xmit err %d.\n", err);\r\niscsi_conn_failure(task->conn, ISCSI_ERR_XMIT_FAILED);\r\nreturn err;\r\n}\r\nvoid cxgbi_cleanup_task(struct iscsi_task *task)\r\n{\r\nstruct cxgbi_task_data *tdata = iscsi_task_cxgbi_data(task);\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"task 0x%p, skb 0x%p, itt 0x%x.\n",\r\ntask, tdata->skb, task->hdr_itt);\r\nif (tdata->skb)\r\n__kfree_skb(tdata->skb);\r\nmemset(tdata, 0, sizeof(*tdata));\r\ntask_release_itt(task, task->hdr_itt);\r\niscsi_tcp_cleanup_task(task);\r\n}\r\nvoid cxgbi_get_conn_stats(struct iscsi_cls_conn *cls_conn,\r\nstruct iscsi_stats *stats)\r\n{\r\nstruct iscsi_conn *conn = cls_conn->dd_data;\r\nstats->txdata_octets = conn->txdata_octets;\r\nstats->rxdata_octets = conn->rxdata_octets;\r\nstats->scsicmd_pdus = conn->scsicmd_pdus_cnt;\r\nstats->dataout_pdus = conn->dataout_pdus_cnt;\r\nstats->scsirsp_pdus = conn->scsirsp_pdus_cnt;\r\nstats->datain_pdus = conn->datain_pdus_cnt;\r\nstats->r2t_pdus = conn->r2t_pdus_cnt;\r\nstats->tmfcmd_pdus = conn->tmfcmd_pdus_cnt;\r\nstats->tmfrsp_pdus = conn->tmfrsp_pdus_cnt;\r\nstats->digest_err = 0;\r\nstats->timeout_err = 0;\r\nstats->custom_length = 1;\r\nstrcpy(stats->custom[0].desc, "eh_abort_cnt");\r\nstats->custom[0].value = conn->eh_abort_cnt;\r\n}\r\nstatic int cxgbi_conn_max_xmit_dlength(struct iscsi_conn *conn)\r\n{\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct cxgbi_device *cdev = cconn->chba->cdev;\r\nunsigned int headroom = SKB_MAX_HEAD(cdev->skb_tx_rsvd);\r\nunsigned int max_def = 512 * MAX_SKB_FRAGS;\r\nunsigned int max = max(max_def, headroom);\r\nmax = min(cconn->chba->cdev->tx_max_size, max);\r\nif (conn->max_xmit_dlength)\r\nconn->max_xmit_dlength = min(conn->max_xmit_dlength, max);\r\nelse\r\nconn->max_xmit_dlength = max;\r\ncxgbi_align_pdu_size(conn->max_xmit_dlength);\r\nreturn 0;\r\n}\r\nstatic int cxgbi_conn_max_recv_dlength(struct iscsi_conn *conn)\r\n{\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nunsigned int max = cconn->chba->cdev->rx_max_size;\r\ncxgbi_align_pdu_size(max);\r\nif (conn->max_recv_dlength) {\r\nif (conn->max_recv_dlength > max) {\r\npr_err("MaxRecvDataSegmentLength %u > %u.\n",\r\nconn->max_recv_dlength, max);\r\nreturn -EINVAL;\r\n}\r\nconn->max_recv_dlength = min(conn->max_recv_dlength, max);\r\ncxgbi_align_pdu_size(conn->max_recv_dlength);\r\n} else\r\nconn->max_recv_dlength = max;\r\nreturn 0;\r\n}\r\nint cxgbi_set_conn_param(struct iscsi_cls_conn *cls_conn,\r\nenum iscsi_param param, char *buf, int buflen)\r\n{\r\nstruct iscsi_conn *conn = cls_conn->dd_data;\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct cxgbi_sock *csk = cconn->cep->csk;\r\nint err;\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"cls_conn 0x%p, param %d, buf(%d) %s.\n",\r\ncls_conn, param, buflen, buf);\r\nswitch (param) {\r\ncase ISCSI_PARAM_HDRDGST_EN:\r\nerr = iscsi_set_param(cls_conn, param, buf, buflen);\r\nif (!err && conn->hdrdgst_en)\r\nerr = csk->cdev->csk_ddp_setup_digest(csk, csk->tid,\r\nconn->hdrdgst_en,\r\nconn->datadgst_en, 0);\r\nbreak;\r\ncase ISCSI_PARAM_DATADGST_EN:\r\nerr = iscsi_set_param(cls_conn, param, buf, buflen);\r\nif (!err && conn->datadgst_en)\r\nerr = csk->cdev->csk_ddp_setup_digest(csk, csk->tid,\r\nconn->hdrdgst_en,\r\nconn->datadgst_en, 0);\r\nbreak;\r\ncase ISCSI_PARAM_MAX_R2T:\r\nreturn iscsi_tcp_set_max_r2t(conn, buf);\r\ncase ISCSI_PARAM_MAX_RECV_DLENGTH:\r\nerr = iscsi_set_param(cls_conn, param, buf, buflen);\r\nif (!err)\r\nerr = cxgbi_conn_max_recv_dlength(conn);\r\nbreak;\r\ncase ISCSI_PARAM_MAX_XMIT_DLENGTH:\r\nerr = iscsi_set_param(cls_conn, param, buf, buflen);\r\nif (!err)\r\nerr = cxgbi_conn_max_xmit_dlength(conn);\r\nbreak;\r\ndefault:\r\nreturn iscsi_set_param(cls_conn, param, buf, buflen);\r\n}\r\nreturn err;\r\n}\r\nint cxgbi_get_ep_param(struct iscsi_endpoint *ep, enum iscsi_param param,\r\nchar *buf)\r\n{\r\nstruct cxgbi_endpoint *cep = ep->dd_data;\r\nstruct cxgbi_sock *csk;\r\nint len;\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"cls_conn 0x%p, param %d.\n", ep, param);\r\nswitch (param) {\r\ncase ISCSI_PARAM_CONN_PORT:\r\ncase ISCSI_PARAM_CONN_ADDRESS:\r\nif (!cep)\r\nreturn -ENOTCONN;\r\ncsk = cep->csk;\r\nif (!csk)\r\nreturn -ENOTCONN;\r\nreturn iscsi_conn_get_addr_param((struct sockaddr_storage *)\r\n&csk->daddr, param, buf);\r\ndefault:\r\nreturn -ENOSYS;\r\n}\r\nreturn len;\r\n}\r\nstruct iscsi_cls_conn *\r\ncxgbi_create_conn(struct iscsi_cls_session *cls_session, u32 cid)\r\n{\r\nstruct iscsi_cls_conn *cls_conn;\r\nstruct iscsi_conn *conn;\r\nstruct iscsi_tcp_conn *tcp_conn;\r\nstruct cxgbi_conn *cconn;\r\ncls_conn = iscsi_tcp_conn_setup(cls_session, sizeof(*cconn), cid);\r\nif (!cls_conn)\r\nreturn NULL;\r\nconn = cls_conn->dd_data;\r\ntcp_conn = conn->dd_data;\r\ncconn = tcp_conn->dd_data;\r\ncconn->iconn = conn;\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"cid %u(0x%x), cls 0x%p,0x%p, conn 0x%p,0x%p,0x%p.\n",\r\ncid, cid, cls_session, cls_conn, conn, tcp_conn, cconn);\r\nreturn cls_conn;\r\n}\r\nint cxgbi_bind_conn(struct iscsi_cls_session *cls_session,\r\nstruct iscsi_cls_conn *cls_conn,\r\nu64 transport_eph, int is_leading)\r\n{\r\nstruct iscsi_conn *conn = cls_conn->dd_data;\r\nstruct iscsi_tcp_conn *tcp_conn = conn->dd_data;\r\nstruct cxgbi_conn *cconn = tcp_conn->dd_data;\r\nstruct iscsi_endpoint *ep;\r\nstruct cxgbi_endpoint *cep;\r\nstruct cxgbi_sock *csk;\r\nint err;\r\nep = iscsi_lookup_endpoint(transport_eph);\r\nif (!ep)\r\nreturn -EINVAL;\r\ncep = ep->dd_data;\r\ncsk = cep->csk;\r\nerr = csk->cdev->csk_ddp_setup_pgidx(csk, csk->tid, page_idx, 0);\r\nif (err < 0)\r\nreturn err;\r\nerr = iscsi_conn_bind(cls_session, cls_conn, is_leading);\r\nif (err)\r\nreturn -EINVAL;\r\ncconn->task_idx_bits = (__ilog2_u32(conn->session->cmds_max - 1)) + 1;\r\nwrite_lock_bh(&csk->callback_lock);\r\ncsk->user_data = conn;\r\ncconn->chba = cep->chba;\r\ncconn->cep = cep;\r\ncep->cconn = cconn;\r\nwrite_unlock_bh(&csk->callback_lock);\r\ncxgbi_conn_max_xmit_dlength(conn);\r\ncxgbi_conn_max_recv_dlength(conn);\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"cls 0x%p,0x%p, ep 0x%p, cconn 0x%p, csk 0x%p.\n",\r\ncls_session, cls_conn, ep, cconn, csk);\r\niscsi_tcp_hdr_recv_prep(tcp_conn);\r\nreturn 0;\r\n}\r\nstruct iscsi_cls_session *cxgbi_create_session(struct iscsi_endpoint *ep,\r\nu16 cmds_max, u16 qdepth,\r\nu32 initial_cmdsn)\r\n{\r\nstruct cxgbi_endpoint *cep;\r\nstruct cxgbi_hba *chba;\r\nstruct Scsi_Host *shost;\r\nstruct iscsi_cls_session *cls_session;\r\nstruct iscsi_session *session;\r\nif (!ep) {\r\npr_err("missing endpoint.\n");\r\nreturn NULL;\r\n}\r\ncep = ep->dd_data;\r\nchba = cep->chba;\r\nshost = chba->shost;\r\nBUG_ON(chba != iscsi_host_priv(shost));\r\ncls_session = iscsi_session_setup(chba->cdev->itp, shost,\r\ncmds_max, 0,\r\nsizeof(struct iscsi_tcp_task) +\r\nsizeof(struct cxgbi_task_data),\r\ninitial_cmdsn, ISCSI_MAX_TARGET);\r\nif (!cls_session)\r\nreturn NULL;\r\nsession = cls_session->dd_data;\r\nif (iscsi_tcp_r2tpool_alloc(session))\r\ngoto remove_session;\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"ep 0x%p, cls sess 0x%p.\n", ep, cls_session);\r\nreturn cls_session;\r\nremove_session:\r\niscsi_session_teardown(cls_session);\r\nreturn NULL;\r\n}\r\nvoid cxgbi_destroy_session(struct iscsi_cls_session *cls_session)\r\n{\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"cls sess 0x%p.\n", cls_session);\r\niscsi_tcp_r2tpool_free(cls_session->dd_data);\r\niscsi_session_teardown(cls_session);\r\n}\r\nint cxgbi_set_host_param(struct Scsi_Host *shost, enum iscsi_host_param param,\r\nchar *buf, int buflen)\r\n{\r\nstruct cxgbi_hba *chba = iscsi_host_priv(shost);\r\nif (!chba->ndev) {\r\nshost_printk(KERN_ERR, shost, "Could not get host param. "\r\n"netdev for host not set.\n");\r\nreturn -ENODEV;\r\n}\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"shost 0x%p, hba 0x%p,%s, param %d, buf(%d) %s.\n",\r\nshost, chba, chba->ndev->name, param, buflen, buf);\r\nswitch (param) {\r\ncase ISCSI_HOST_PARAM_IPADDRESS:\r\n{\r\n__be32 addr = in_aton(buf);\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"hba %s, req. ipv4 %pI4.\n", chba->ndev->name, &addr);\r\ncxgbi_set_iscsi_ipv4(chba, addr);\r\nreturn 0;\r\n}\r\ncase ISCSI_HOST_PARAM_HWADDRESS:\r\ncase ISCSI_HOST_PARAM_NETDEV_NAME:\r\nreturn 0;\r\ndefault:\r\nreturn iscsi_host_set_param(shost, param, buf, buflen);\r\n}\r\n}\r\nint cxgbi_get_host_param(struct Scsi_Host *shost, enum iscsi_host_param param,\r\nchar *buf)\r\n{\r\nstruct cxgbi_hba *chba = iscsi_host_priv(shost);\r\nint len = 0;\r\nif (!chba->ndev) {\r\nshost_printk(KERN_ERR, shost, "Could not get host param. "\r\n"netdev for host not set.\n");\r\nreturn -ENODEV;\r\n}\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"shost 0x%p, hba 0x%p,%s, param %d.\n",\r\nshost, chba, chba->ndev->name, param);\r\nswitch (param) {\r\ncase ISCSI_HOST_PARAM_HWADDRESS:\r\nlen = sysfs_format_mac(buf, chba->ndev->dev_addr, 6);\r\nbreak;\r\ncase ISCSI_HOST_PARAM_NETDEV_NAME:\r\nlen = sprintf(buf, "%s\n", chba->ndev->name);\r\nbreak;\r\ncase ISCSI_HOST_PARAM_IPADDRESS:\r\n{\r\n__be32 addr;\r\naddr = cxgbi_get_iscsi_ipv4(chba);\r\nlen = sprintf(buf, "%pI4", &addr);\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"hba %s, ipv4 %pI4.\n", chba->ndev->name, &addr);\r\nbreak;\r\n}\r\ndefault:\r\nreturn iscsi_host_get_param(shost, param, buf);\r\n}\r\nreturn len;\r\n}\r\nstruct iscsi_endpoint *cxgbi_ep_connect(struct Scsi_Host *shost,\r\nstruct sockaddr *dst_addr,\r\nint non_blocking)\r\n{\r\nstruct iscsi_endpoint *ep;\r\nstruct cxgbi_endpoint *cep;\r\nstruct cxgbi_hba *hba = NULL;\r\nstruct cxgbi_sock *csk;\r\nint err = -EINVAL;\r\nlog_debug(1 << CXGBI_DBG_ISCSI | 1 << CXGBI_DBG_SOCK,\r\n"shost 0x%p, non_blocking %d, dst_addr 0x%p.\n",\r\nshost, non_blocking, dst_addr);\r\nif (shost) {\r\nhba = iscsi_host_priv(shost);\r\nif (!hba) {\r\npr_info("shost 0x%p, priv NULL.\n", shost);\r\ngoto err_out;\r\n}\r\n}\r\ncsk = cxgbi_check_route(dst_addr);\r\nif (IS_ERR(csk))\r\nreturn (struct iscsi_endpoint *)csk;\r\ncxgbi_sock_get(csk);\r\nif (!hba)\r\nhba = csk->cdev->hbas[csk->port_id];\r\nelse if (hba != csk->cdev->hbas[csk->port_id]) {\r\npr_info("Could not connect through requested host %u"\r\n"hba 0x%p != 0x%p (%u).\n",\r\nshost->host_no, hba,\r\ncsk->cdev->hbas[csk->port_id], csk->port_id);\r\nerr = -ENOSPC;\r\ngoto release_conn;\r\n}\r\nerr = sock_get_port(csk);\r\nif (err)\r\ngoto release_conn;\r\ncxgbi_sock_set_state(csk, CTP_CONNECTING);\r\nerr = csk->cdev->csk_init_act_open(csk);\r\nif (err)\r\ngoto release_conn;\r\nif (cxgbi_sock_is_closing(csk)) {\r\nerr = -ENOSPC;\r\npr_info("csk 0x%p is closing.\n", csk);\r\ngoto release_conn;\r\n}\r\nep = iscsi_create_endpoint(sizeof(*cep));\r\nif (!ep) {\r\nerr = -ENOMEM;\r\npr_info("iscsi alloc ep, OOM.\n");\r\ngoto release_conn;\r\n}\r\ncep = ep->dd_data;\r\ncep->csk = csk;\r\ncep->chba = hba;\r\nlog_debug(1 << CXGBI_DBG_ISCSI | 1 << CXGBI_DBG_SOCK,\r\n"ep 0x%p, cep 0x%p, csk 0x%p, hba 0x%p,%s.\n",\r\nep, cep, csk, hba, hba->ndev->name);\r\nreturn ep;\r\nrelease_conn:\r\ncxgbi_sock_put(csk);\r\ncxgbi_sock_closed(csk);\r\nerr_out:\r\nreturn ERR_PTR(err);\r\n}\r\nint cxgbi_ep_poll(struct iscsi_endpoint *ep, int timeout_ms)\r\n{\r\nstruct cxgbi_endpoint *cep = ep->dd_data;\r\nstruct cxgbi_sock *csk = cep->csk;\r\nif (!cxgbi_sock_is_established(csk))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nvoid cxgbi_ep_disconnect(struct iscsi_endpoint *ep)\r\n{\r\nstruct cxgbi_endpoint *cep = ep->dd_data;\r\nstruct cxgbi_conn *cconn = cep->cconn;\r\nstruct cxgbi_sock *csk = cep->csk;\r\nlog_debug(1 << CXGBI_DBG_ISCSI | 1 << CXGBI_DBG_SOCK,\r\n"ep 0x%p, cep 0x%p, cconn 0x%p, csk 0x%p,%u,0x%lx.\n",\r\nep, cep, cconn, csk, csk->state, csk->flags);\r\nif (cconn && cconn->iconn) {\r\niscsi_suspend_tx(cconn->iconn);\r\nwrite_lock_bh(&csk->callback_lock);\r\ncep->csk->user_data = NULL;\r\ncconn->cep = NULL;\r\nwrite_unlock_bh(&csk->callback_lock);\r\n}\r\niscsi_destroy_endpoint(ep);\r\nif (likely(csk->state >= CTP_ESTABLISHED))\r\nneed_active_close(csk);\r\nelse\r\ncxgbi_sock_closed(csk);\r\ncxgbi_sock_put(csk);\r\n}\r\nint cxgbi_iscsi_init(struct iscsi_transport *itp,\r\nstruct scsi_transport_template **stt)\r\n{\r\n*stt = iscsi_register_transport(itp);\r\nif (*stt == NULL) {\r\npr_err("unable to register %s transport 0x%p.\n",\r\nitp->name, itp);\r\nreturn -ENODEV;\r\n}\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"%s, registered iscsi transport 0x%p.\n",\r\nitp->name, stt);\r\nreturn 0;\r\n}\r\nvoid cxgbi_iscsi_cleanup(struct iscsi_transport *itp,\r\nstruct scsi_transport_template **stt)\r\n{\r\nif (*stt) {\r\nlog_debug(1 << CXGBI_DBG_ISCSI,\r\n"de-register transport 0x%p, %s, stt 0x%p.\n",\r\nitp, itp->name, *stt);\r\n*stt = NULL;\r\niscsi_unregister_transport(itp);\r\n}\r\n}\r\numode_t cxgbi_attr_is_visible(int param_type, int param)\r\n{\r\nswitch (param_type) {\r\ncase ISCSI_HOST_PARAM:\r\nswitch (param) {\r\ncase ISCSI_HOST_PARAM_NETDEV_NAME:\r\ncase ISCSI_HOST_PARAM_HWADDRESS:\r\ncase ISCSI_HOST_PARAM_IPADDRESS:\r\ncase ISCSI_HOST_PARAM_INITIATOR_NAME:\r\nreturn S_IRUGO;\r\ndefault:\r\nreturn 0;\r\n}\r\ncase ISCSI_PARAM:\r\nswitch (param) {\r\ncase ISCSI_PARAM_MAX_RECV_DLENGTH:\r\ncase ISCSI_PARAM_MAX_XMIT_DLENGTH:\r\ncase ISCSI_PARAM_HDRDGST_EN:\r\ncase ISCSI_PARAM_DATADGST_EN:\r\ncase ISCSI_PARAM_CONN_ADDRESS:\r\ncase ISCSI_PARAM_CONN_PORT:\r\ncase ISCSI_PARAM_EXP_STATSN:\r\ncase ISCSI_PARAM_PERSISTENT_ADDRESS:\r\ncase ISCSI_PARAM_PERSISTENT_PORT:\r\ncase ISCSI_PARAM_PING_TMO:\r\ncase ISCSI_PARAM_RECV_TMO:\r\ncase ISCSI_PARAM_INITIAL_R2T_EN:\r\ncase ISCSI_PARAM_MAX_R2T:\r\ncase ISCSI_PARAM_IMM_DATA_EN:\r\ncase ISCSI_PARAM_FIRST_BURST:\r\ncase ISCSI_PARAM_MAX_BURST:\r\ncase ISCSI_PARAM_PDU_INORDER_EN:\r\ncase ISCSI_PARAM_DATASEQ_INORDER_EN:\r\ncase ISCSI_PARAM_ERL:\r\ncase ISCSI_PARAM_TARGET_NAME:\r\ncase ISCSI_PARAM_TPGT:\r\ncase ISCSI_PARAM_USERNAME:\r\ncase ISCSI_PARAM_PASSWORD:\r\ncase ISCSI_PARAM_USERNAME_IN:\r\ncase ISCSI_PARAM_PASSWORD_IN:\r\ncase ISCSI_PARAM_FAST_ABORT:\r\ncase ISCSI_PARAM_ABORT_TMO:\r\ncase ISCSI_PARAM_LU_RESET_TMO:\r\ncase ISCSI_PARAM_TGT_RESET_TMO:\r\ncase ISCSI_PARAM_IFACE_NAME:\r\ncase ISCSI_PARAM_INITIATOR_NAME:\r\nreturn S_IRUGO;\r\ndefault:\r\nreturn 0;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init libcxgbi_init_module(void)\r\n{\r\nsw_tag_idx_bits = (__ilog2_u32(ISCSI_ITT_MASK)) + 1;\r\nsw_tag_age_bits = (__ilog2_u32(ISCSI_AGE_MASK)) + 1;\r\npr_info("tag itt 0x%x, %u bits, age 0x%x, %u bits.\n",\r\nISCSI_ITT_MASK, sw_tag_idx_bits,\r\nISCSI_AGE_MASK, sw_tag_age_bits);\r\nddp_setup_host_page_size();\r\nreturn 0;\r\n}\r\nstatic void __exit libcxgbi_exit_module(void)\r\n{\r\ncxgbi_device_unregister_all(0xFF);\r\nreturn;\r\n}
