void\r\nnfs4_print_deviceid(const struct nfs4_deviceid *id)\r\n{\r\nu32 *p = (u32 *)id;\r\ndprintk("%s: device id= [%x%x%x%x]\n", __func__,\r\np[0], p[1], p[2], p[3]);\r\n}\r\nstatic inline u32\r\nnfs4_deviceid_hash(const struct nfs4_deviceid *id)\r\n{\r\nunsigned char *cptr = (unsigned char *)id->data;\r\nunsigned int nbytes = NFS4_DEVICEID4_SIZE;\r\nu32 x = 0;\r\nwhile (nbytes--) {\r\nx *= 37;\r\nx += *cptr++;\r\n}\r\nreturn x & NFS4_DEVICE_ID_HASH_MASK;\r\n}\r\nstatic struct nfs4_deviceid_node *\r\n_lookup_deviceid(const struct pnfs_layoutdriver_type *ld,\r\nconst struct nfs_client *clp, const struct nfs4_deviceid *id,\r\nlong hash)\r\n{\r\nstruct nfs4_deviceid_node *d;\r\nstruct hlist_node *n;\r\nhlist_for_each_entry_rcu(d, n, &nfs4_deviceid_cache[hash], node)\r\nif (d->ld == ld && d->nfs_client == clp &&\r\n!memcmp(&d->deviceid, id, sizeof(*id))) {\r\nif (atomic_read(&d->ref))\r\nreturn d;\r\nelse\r\ncontinue;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct nfs4_deviceid_node *\r\n_find_get_deviceid(const struct pnfs_layoutdriver_type *ld,\r\nconst struct nfs_client *clp, const struct nfs4_deviceid *id,\r\nlong hash)\r\n{\r\nstruct nfs4_deviceid_node *d;\r\nrcu_read_lock();\r\nd = _lookup_deviceid(ld, clp, id, hash);\r\nif (d != NULL)\r\natomic_inc(&d->ref);\r\nrcu_read_unlock();\r\nreturn d;\r\n}\r\nstruct nfs4_deviceid_node *\r\nnfs4_find_get_deviceid(const struct pnfs_layoutdriver_type *ld,\r\nconst struct nfs_client *clp, const struct nfs4_deviceid *id)\r\n{\r\nreturn _find_get_deviceid(ld, clp, id, nfs4_deviceid_hash(id));\r\n}\r\nvoid\r\nnfs4_delete_deviceid(const struct pnfs_layoutdriver_type *ld,\r\nconst struct nfs_client *clp, const struct nfs4_deviceid *id)\r\n{\r\nstruct nfs4_deviceid_node *d;\r\nspin_lock(&nfs4_deviceid_lock);\r\nrcu_read_lock();\r\nd = _lookup_deviceid(ld, clp, id, nfs4_deviceid_hash(id));\r\nrcu_read_unlock();\r\nif (!d) {\r\nspin_unlock(&nfs4_deviceid_lock);\r\nreturn;\r\n}\r\nhlist_del_init_rcu(&d->node);\r\nspin_unlock(&nfs4_deviceid_lock);\r\nsynchronize_rcu();\r\nif (atomic_dec_and_test(&d->ref))\r\nd->ld->free_deviceid_node(d);\r\n}\r\nvoid\r\nnfs4_init_deviceid_node(struct nfs4_deviceid_node *d,\r\nconst struct pnfs_layoutdriver_type *ld,\r\nconst struct nfs_client *nfs_client,\r\nconst struct nfs4_deviceid *id)\r\n{\r\nINIT_HLIST_NODE(&d->node);\r\nINIT_HLIST_NODE(&d->tmpnode);\r\nd->ld = ld;\r\nd->nfs_client = nfs_client;\r\nd->flags = 0;\r\nd->deviceid = *id;\r\natomic_set(&d->ref, 1);\r\n}\r\nstruct nfs4_deviceid_node *\r\nnfs4_insert_deviceid_node(struct nfs4_deviceid_node *new)\r\n{\r\nstruct nfs4_deviceid_node *d;\r\nlong hash;\r\nspin_lock(&nfs4_deviceid_lock);\r\nhash = nfs4_deviceid_hash(&new->deviceid);\r\nd = _find_get_deviceid(new->ld, new->nfs_client, &new->deviceid, hash);\r\nif (d) {\r\nspin_unlock(&nfs4_deviceid_lock);\r\nreturn d;\r\n}\r\nhlist_add_head_rcu(&new->node, &nfs4_deviceid_cache[hash]);\r\nspin_unlock(&nfs4_deviceid_lock);\r\natomic_inc(&new->ref);\r\nreturn new;\r\n}\r\nbool\r\nnfs4_put_deviceid_node(struct nfs4_deviceid_node *d)\r\n{\r\nif (!atomic_dec_and_test(&d->ref))\r\nreturn false;\r\nd->ld->free_deviceid_node(d);\r\nreturn true;\r\n}\r\nvoid\r\nnfs4_mark_deviceid_unavailable(struct nfs4_deviceid_node *node)\r\n{\r\nnode->timestamp_unavailable = jiffies;\r\nset_bit(NFS_DEVICEID_UNAVAILABLE, &node->flags);\r\n}\r\nbool\r\nnfs4_test_deviceid_unavailable(struct nfs4_deviceid_node *node)\r\n{\r\nif (test_bit(NFS_DEVICEID_UNAVAILABLE, &node->flags)) {\r\nunsigned long start, end;\r\nend = jiffies;\r\nstart = end - PNFS_DEVICE_RETRY_TIMEOUT;\r\nif (time_in_range(node->timestamp_unavailable, start, end))\r\nreturn true;\r\nclear_bit(NFS_DEVICEID_UNAVAILABLE, &node->flags);\r\n}\r\nreturn false;\r\n}\r\nstatic void\r\n_deviceid_purge_client(const struct nfs_client *clp, long hash)\r\n{\r\nstruct nfs4_deviceid_node *d;\r\nstruct hlist_node *n;\r\nHLIST_HEAD(tmp);\r\nspin_lock(&nfs4_deviceid_lock);\r\nrcu_read_lock();\r\nhlist_for_each_entry_rcu(d, n, &nfs4_deviceid_cache[hash], node)\r\nif (d->nfs_client == clp && atomic_read(&d->ref)) {\r\nhlist_del_init_rcu(&d->node);\r\nhlist_add_head(&d->tmpnode, &tmp);\r\n}\r\nrcu_read_unlock();\r\nspin_unlock(&nfs4_deviceid_lock);\r\nif (hlist_empty(&tmp))\r\nreturn;\r\nsynchronize_rcu();\r\nwhile (!hlist_empty(&tmp)) {\r\nd = hlist_entry(tmp.first, struct nfs4_deviceid_node, tmpnode);\r\nhlist_del(&d->tmpnode);\r\nif (atomic_dec_and_test(&d->ref))\r\nd->ld->free_deviceid_node(d);\r\n}\r\n}\r\nvoid\r\nnfs4_deviceid_purge_client(const struct nfs_client *clp)\r\n{\r\nlong h;\r\nif (!(clp->cl_exchange_flags & EXCHGID4_FLAG_USE_PNFS_MDS))\r\nreturn;\r\nfor (h = 0; h < NFS4_DEVICE_ID_HASH_SIZE; h++)\r\n_deviceid_purge_client(clp, h);\r\n}\r\nvoid\r\nnfs4_deviceid_mark_client_invalid(struct nfs_client *clp)\r\n{\r\nstruct nfs4_deviceid_node *d;\r\nstruct hlist_node *n;\r\nint i;\r\nrcu_read_lock();\r\nfor (i = 0; i < NFS4_DEVICE_ID_HASH_SIZE; i ++){\r\nhlist_for_each_entry_rcu(d, n, &nfs4_deviceid_cache[i], node)\r\nif (d->nfs_client == clp)\r\nset_bit(NFS_DEVICEID_INVALID, &d->flags);\r\n}\r\nrcu_read_unlock();\r\n}
