int register_oldmem_pfn_is_ram(int (*fn)(unsigned long pfn))\r\n{\r\nif (oldmem_pfn_is_ram)\r\nreturn -EBUSY;\r\noldmem_pfn_is_ram = fn;\r\nreturn 0;\r\n}\r\nvoid unregister_oldmem_pfn_is_ram(void)\r\n{\r\noldmem_pfn_is_ram = NULL;\r\nwmb();\r\n}\r\nstatic int pfn_is_ram(unsigned long pfn)\r\n{\r\nint (*fn)(unsigned long pfn);\r\nint ret = 1;\r\nfn = oldmem_pfn_is_ram;\r\nif (fn)\r\nret = fn(pfn);\r\nreturn ret;\r\n}\r\nstatic ssize_t read_from_oldmem(char *buf, size_t count,\r\nu64 *ppos, int userbuf)\r\n{\r\nunsigned long pfn, offset;\r\nsize_t nr_bytes;\r\nssize_t read = 0, tmp;\r\nif (!count)\r\nreturn 0;\r\noffset = (unsigned long)(*ppos % PAGE_SIZE);\r\npfn = (unsigned long)(*ppos / PAGE_SIZE);\r\ndo {\r\nif (count > (PAGE_SIZE - offset))\r\nnr_bytes = PAGE_SIZE - offset;\r\nelse\r\nnr_bytes = count;\r\nif (pfn_is_ram(pfn) == 0)\r\nmemset(buf, 0, nr_bytes);\r\nelse {\r\ntmp = copy_oldmem_page(pfn, buf, nr_bytes,\r\noffset, userbuf);\r\nif (tmp < 0)\r\nreturn tmp;\r\n}\r\n*ppos += nr_bytes;\r\ncount -= nr_bytes;\r\nbuf += nr_bytes;\r\nread += nr_bytes;\r\n++pfn;\r\noffset = 0;\r\n} while (count);\r\nreturn read;\r\n}\r\nstatic u64 map_offset_to_paddr(loff_t offset, struct list_head *vc_list,\r\nstruct vmcore **m_ptr)\r\n{\r\nstruct vmcore *m;\r\nu64 paddr;\r\nlist_for_each_entry(m, vc_list, list) {\r\nu64 start, end;\r\nstart = m->offset;\r\nend = m->offset + m->size - 1;\r\nif (offset >= start && offset <= end) {\r\npaddr = m->paddr + offset - start;\r\n*m_ptr = m;\r\nreturn paddr;\r\n}\r\n}\r\n*m_ptr = NULL;\r\nreturn 0;\r\n}\r\nstatic ssize_t read_vmcore(struct file *file, char __user *buffer,\r\nsize_t buflen, loff_t *fpos)\r\n{\r\nssize_t acc = 0, tmp;\r\nsize_t tsz;\r\nu64 start, nr_bytes;\r\nstruct vmcore *curr_m = NULL;\r\nif (buflen == 0 || *fpos >= vmcore_size)\r\nreturn 0;\r\nif (buflen > vmcore_size - *fpos)\r\nbuflen = vmcore_size - *fpos;\r\nif (*fpos < elfcorebuf_sz) {\r\ntsz = elfcorebuf_sz - *fpos;\r\nif (buflen < tsz)\r\ntsz = buflen;\r\nif (copy_to_user(buffer, elfcorebuf + *fpos, tsz))\r\nreturn -EFAULT;\r\nbuflen -= tsz;\r\n*fpos += tsz;\r\nbuffer += tsz;\r\nacc += tsz;\r\nif (buflen == 0)\r\nreturn acc;\r\n}\r\nstart = map_offset_to_paddr(*fpos, &vmcore_list, &curr_m);\r\nif (!curr_m)\r\nreturn -EINVAL;\r\nif ((tsz = (PAGE_SIZE - (start & ~PAGE_MASK))) > buflen)\r\ntsz = buflen;\r\nnr_bytes = (curr_m->size - (start - curr_m->paddr));\r\nif (tsz > nr_bytes)\r\ntsz = nr_bytes;\r\nwhile (buflen) {\r\ntmp = read_from_oldmem(buffer, tsz, &start, 1);\r\nif (tmp < 0)\r\nreturn tmp;\r\nbuflen -= tsz;\r\n*fpos += tsz;\r\nbuffer += tsz;\r\nacc += tsz;\r\nif (start >= (curr_m->paddr + curr_m->size)) {\r\nif (curr_m->list.next == &vmcore_list)\r\nreturn acc;\r\ncurr_m = list_entry(curr_m->list.next,\r\nstruct vmcore, list);\r\nstart = curr_m->paddr;\r\n}\r\nif ((tsz = (PAGE_SIZE - (start & ~PAGE_MASK))) > buflen)\r\ntsz = buflen;\r\nnr_bytes = (curr_m->size - (start - curr_m->paddr));\r\nif (tsz > nr_bytes)\r\ntsz = nr_bytes;\r\n}\r\nreturn acc;\r\n}\r\nstatic struct vmcore* __init get_new_element(void)\r\n{\r\nreturn kzalloc(sizeof(struct vmcore), GFP_KERNEL);\r\n}\r\nstatic u64 __init get_vmcore_size_elf64(char *elfptr)\r\n{\r\nint i;\r\nu64 size;\r\nElf64_Ehdr *ehdr_ptr;\r\nElf64_Phdr *phdr_ptr;\r\nehdr_ptr = (Elf64_Ehdr *)elfptr;\r\nphdr_ptr = (Elf64_Phdr*)(elfptr + sizeof(Elf64_Ehdr));\r\nsize = sizeof(Elf64_Ehdr) + ((ehdr_ptr->e_phnum) * sizeof(Elf64_Phdr));\r\nfor (i = 0; i < ehdr_ptr->e_phnum; i++) {\r\nsize += phdr_ptr->p_memsz;\r\nphdr_ptr++;\r\n}\r\nreturn size;\r\n}\r\nstatic u64 __init get_vmcore_size_elf32(char *elfptr)\r\n{\r\nint i;\r\nu64 size;\r\nElf32_Ehdr *ehdr_ptr;\r\nElf32_Phdr *phdr_ptr;\r\nehdr_ptr = (Elf32_Ehdr *)elfptr;\r\nphdr_ptr = (Elf32_Phdr*)(elfptr + sizeof(Elf32_Ehdr));\r\nsize = sizeof(Elf32_Ehdr) + ((ehdr_ptr->e_phnum) * sizeof(Elf32_Phdr));\r\nfor (i = 0; i < ehdr_ptr->e_phnum; i++) {\r\nsize += phdr_ptr->p_memsz;\r\nphdr_ptr++;\r\n}\r\nreturn size;\r\n}\r\nstatic int __init merge_note_headers_elf64(char *elfptr, size_t *elfsz,\r\nstruct list_head *vc_list)\r\n{\r\nint i, nr_ptnote=0, rc=0;\r\nchar *tmp;\r\nElf64_Ehdr *ehdr_ptr;\r\nElf64_Phdr phdr, *phdr_ptr;\r\nElf64_Nhdr *nhdr_ptr;\r\nu64 phdr_sz = 0, note_off;\r\nehdr_ptr = (Elf64_Ehdr *)elfptr;\r\nphdr_ptr = (Elf64_Phdr*)(elfptr + sizeof(Elf64_Ehdr));\r\nfor (i = 0; i < ehdr_ptr->e_phnum; i++, phdr_ptr++) {\r\nint j;\r\nvoid *notes_section;\r\nstruct vmcore *new;\r\nu64 offset, max_sz, sz, real_sz = 0;\r\nif (phdr_ptr->p_type != PT_NOTE)\r\ncontinue;\r\nnr_ptnote++;\r\nmax_sz = phdr_ptr->p_memsz;\r\noffset = phdr_ptr->p_offset;\r\nnotes_section = kmalloc(max_sz, GFP_KERNEL);\r\nif (!notes_section)\r\nreturn -ENOMEM;\r\nrc = read_from_oldmem(notes_section, max_sz, &offset, 0);\r\nif (rc < 0) {\r\nkfree(notes_section);\r\nreturn rc;\r\n}\r\nnhdr_ptr = notes_section;\r\nfor (j = 0; j < max_sz; j += sz) {\r\nif (nhdr_ptr->n_namesz == 0)\r\nbreak;\r\nsz = sizeof(Elf64_Nhdr) +\r\n((nhdr_ptr->n_namesz + 3) & ~3) +\r\n((nhdr_ptr->n_descsz + 3) & ~3);\r\nreal_sz += sz;\r\nnhdr_ptr = (Elf64_Nhdr*)((char*)nhdr_ptr + sz);\r\n}\r\nnew = get_new_element();\r\nif (!new) {\r\nkfree(notes_section);\r\nreturn -ENOMEM;\r\n}\r\nnew->paddr = phdr_ptr->p_offset;\r\nnew->size = real_sz;\r\nlist_add_tail(&new->list, vc_list);\r\nphdr_sz += real_sz;\r\nkfree(notes_section);\r\n}\r\nphdr.p_type = PT_NOTE;\r\nphdr.p_flags = 0;\r\nnote_off = sizeof(Elf64_Ehdr) +\r\n(ehdr_ptr->e_phnum - nr_ptnote +1) * sizeof(Elf64_Phdr);\r\nphdr.p_offset = note_off;\r\nphdr.p_vaddr = phdr.p_paddr = 0;\r\nphdr.p_filesz = phdr.p_memsz = phdr_sz;\r\nphdr.p_align = 0;\r\ntmp = elfptr + sizeof(Elf64_Ehdr);\r\nmemcpy(tmp, &phdr, sizeof(phdr));\r\ntmp += sizeof(phdr);\r\ni = (nr_ptnote - 1) * sizeof(Elf64_Phdr);\r\n*elfsz = *elfsz - i;\r\nmemmove(tmp, tmp+i, ((*elfsz)-sizeof(Elf64_Ehdr)-sizeof(Elf64_Phdr)));\r\nehdr_ptr->e_phnum = ehdr_ptr->e_phnum - nr_ptnote + 1;\r\nreturn 0;\r\n}\r\nstatic int __init merge_note_headers_elf32(char *elfptr, size_t *elfsz,\r\nstruct list_head *vc_list)\r\n{\r\nint i, nr_ptnote=0, rc=0;\r\nchar *tmp;\r\nElf32_Ehdr *ehdr_ptr;\r\nElf32_Phdr phdr, *phdr_ptr;\r\nElf32_Nhdr *nhdr_ptr;\r\nu64 phdr_sz = 0, note_off;\r\nehdr_ptr = (Elf32_Ehdr *)elfptr;\r\nphdr_ptr = (Elf32_Phdr*)(elfptr + sizeof(Elf32_Ehdr));\r\nfor (i = 0; i < ehdr_ptr->e_phnum; i++, phdr_ptr++) {\r\nint j;\r\nvoid *notes_section;\r\nstruct vmcore *new;\r\nu64 offset, max_sz, sz, real_sz = 0;\r\nif (phdr_ptr->p_type != PT_NOTE)\r\ncontinue;\r\nnr_ptnote++;\r\nmax_sz = phdr_ptr->p_memsz;\r\noffset = phdr_ptr->p_offset;\r\nnotes_section = kmalloc(max_sz, GFP_KERNEL);\r\nif (!notes_section)\r\nreturn -ENOMEM;\r\nrc = read_from_oldmem(notes_section, max_sz, &offset, 0);\r\nif (rc < 0) {\r\nkfree(notes_section);\r\nreturn rc;\r\n}\r\nnhdr_ptr = notes_section;\r\nfor (j = 0; j < max_sz; j += sz) {\r\nif (nhdr_ptr->n_namesz == 0)\r\nbreak;\r\nsz = sizeof(Elf32_Nhdr) +\r\n((nhdr_ptr->n_namesz + 3) & ~3) +\r\n((nhdr_ptr->n_descsz + 3) & ~3);\r\nreal_sz += sz;\r\nnhdr_ptr = (Elf32_Nhdr*)((char*)nhdr_ptr + sz);\r\n}\r\nnew = get_new_element();\r\nif (!new) {\r\nkfree(notes_section);\r\nreturn -ENOMEM;\r\n}\r\nnew->paddr = phdr_ptr->p_offset;\r\nnew->size = real_sz;\r\nlist_add_tail(&new->list, vc_list);\r\nphdr_sz += real_sz;\r\nkfree(notes_section);\r\n}\r\nphdr.p_type = PT_NOTE;\r\nphdr.p_flags = 0;\r\nnote_off = sizeof(Elf32_Ehdr) +\r\n(ehdr_ptr->e_phnum - nr_ptnote +1) * sizeof(Elf32_Phdr);\r\nphdr.p_offset = note_off;\r\nphdr.p_vaddr = phdr.p_paddr = 0;\r\nphdr.p_filesz = phdr.p_memsz = phdr_sz;\r\nphdr.p_align = 0;\r\ntmp = elfptr + sizeof(Elf32_Ehdr);\r\nmemcpy(tmp, &phdr, sizeof(phdr));\r\ntmp += sizeof(phdr);\r\ni = (nr_ptnote - 1) * sizeof(Elf32_Phdr);\r\n*elfsz = *elfsz - i;\r\nmemmove(tmp, tmp+i, ((*elfsz)-sizeof(Elf32_Ehdr)-sizeof(Elf32_Phdr)));\r\nehdr_ptr->e_phnum = ehdr_ptr->e_phnum - nr_ptnote + 1;\r\nreturn 0;\r\n}\r\nstatic int __init process_ptload_program_headers_elf64(char *elfptr,\r\nsize_t elfsz,\r\nstruct list_head *vc_list)\r\n{\r\nint i;\r\nElf64_Ehdr *ehdr_ptr;\r\nElf64_Phdr *phdr_ptr;\r\nloff_t vmcore_off;\r\nstruct vmcore *new;\r\nehdr_ptr = (Elf64_Ehdr *)elfptr;\r\nphdr_ptr = (Elf64_Phdr*)(elfptr + sizeof(Elf64_Ehdr));\r\nvmcore_off = sizeof(Elf64_Ehdr) +\r\n(ehdr_ptr->e_phnum) * sizeof(Elf64_Phdr) +\r\nphdr_ptr->p_memsz;\r\nfor (i = 0; i < ehdr_ptr->e_phnum; i++, phdr_ptr++) {\r\nif (phdr_ptr->p_type != PT_LOAD)\r\ncontinue;\r\nnew = get_new_element();\r\nif (!new)\r\nreturn -ENOMEM;\r\nnew->paddr = phdr_ptr->p_offset;\r\nnew->size = phdr_ptr->p_memsz;\r\nlist_add_tail(&new->list, vc_list);\r\nphdr_ptr->p_offset = vmcore_off;\r\nvmcore_off = vmcore_off + phdr_ptr->p_memsz;\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init process_ptload_program_headers_elf32(char *elfptr,\r\nsize_t elfsz,\r\nstruct list_head *vc_list)\r\n{\r\nint i;\r\nElf32_Ehdr *ehdr_ptr;\r\nElf32_Phdr *phdr_ptr;\r\nloff_t vmcore_off;\r\nstruct vmcore *new;\r\nehdr_ptr = (Elf32_Ehdr *)elfptr;\r\nphdr_ptr = (Elf32_Phdr*)(elfptr + sizeof(Elf32_Ehdr));\r\nvmcore_off = sizeof(Elf32_Ehdr) +\r\n(ehdr_ptr->e_phnum) * sizeof(Elf32_Phdr) +\r\nphdr_ptr->p_memsz;\r\nfor (i = 0; i < ehdr_ptr->e_phnum; i++, phdr_ptr++) {\r\nif (phdr_ptr->p_type != PT_LOAD)\r\ncontinue;\r\nnew = get_new_element();\r\nif (!new)\r\nreturn -ENOMEM;\r\nnew->paddr = phdr_ptr->p_offset;\r\nnew->size = phdr_ptr->p_memsz;\r\nlist_add_tail(&new->list, vc_list);\r\nphdr_ptr->p_offset = vmcore_off;\r\nvmcore_off = vmcore_off + phdr_ptr->p_memsz;\r\n}\r\nreturn 0;\r\n}\r\nstatic void __init set_vmcore_list_offsets_elf64(char *elfptr,\r\nstruct list_head *vc_list)\r\n{\r\nloff_t vmcore_off;\r\nElf64_Ehdr *ehdr_ptr;\r\nstruct vmcore *m;\r\nehdr_ptr = (Elf64_Ehdr *)elfptr;\r\nvmcore_off = sizeof(Elf64_Ehdr) +\r\n(ehdr_ptr->e_phnum) * sizeof(Elf64_Phdr);\r\nlist_for_each_entry(m, vc_list, list) {\r\nm->offset = vmcore_off;\r\nvmcore_off += m->size;\r\n}\r\n}\r\nstatic void __init set_vmcore_list_offsets_elf32(char *elfptr,\r\nstruct list_head *vc_list)\r\n{\r\nloff_t vmcore_off;\r\nElf32_Ehdr *ehdr_ptr;\r\nstruct vmcore *m;\r\nehdr_ptr = (Elf32_Ehdr *)elfptr;\r\nvmcore_off = sizeof(Elf32_Ehdr) +\r\n(ehdr_ptr->e_phnum) * sizeof(Elf32_Phdr);\r\nlist_for_each_entry(m, vc_list, list) {\r\nm->offset = vmcore_off;\r\nvmcore_off += m->size;\r\n}\r\n}\r\nstatic int __init parse_crash_elf64_headers(void)\r\n{\r\nint rc=0;\r\nElf64_Ehdr ehdr;\r\nu64 addr;\r\naddr = elfcorehdr_addr;\r\nrc = read_from_oldmem((char*)&ehdr, sizeof(Elf64_Ehdr), &addr, 0);\r\nif (rc < 0)\r\nreturn rc;\r\nif (memcmp(ehdr.e_ident, ELFMAG, SELFMAG) != 0 ||\r\n(ehdr.e_type != ET_CORE) ||\r\n!vmcore_elf64_check_arch(&ehdr) ||\r\nehdr.e_ident[EI_CLASS] != ELFCLASS64 ||\r\nehdr.e_ident[EI_VERSION] != EV_CURRENT ||\r\nehdr.e_version != EV_CURRENT ||\r\nehdr.e_ehsize != sizeof(Elf64_Ehdr) ||\r\nehdr.e_phentsize != sizeof(Elf64_Phdr) ||\r\nehdr.e_phnum == 0) {\r\nprintk(KERN_WARNING "Warning: Core image elf header is not"\r\n"sane\n");\r\nreturn -EINVAL;\r\n}\r\nelfcorebuf_sz = sizeof(Elf64_Ehdr) + ehdr.e_phnum * sizeof(Elf64_Phdr);\r\nelfcorebuf = kmalloc(elfcorebuf_sz, GFP_KERNEL);\r\nif (!elfcorebuf)\r\nreturn -ENOMEM;\r\naddr = elfcorehdr_addr;\r\nrc = read_from_oldmem(elfcorebuf, elfcorebuf_sz, &addr, 0);\r\nif (rc < 0) {\r\nkfree(elfcorebuf);\r\nreturn rc;\r\n}\r\nrc = merge_note_headers_elf64(elfcorebuf, &elfcorebuf_sz, &vmcore_list);\r\nif (rc) {\r\nkfree(elfcorebuf);\r\nreturn rc;\r\n}\r\nrc = process_ptload_program_headers_elf64(elfcorebuf, elfcorebuf_sz,\r\n&vmcore_list);\r\nif (rc) {\r\nkfree(elfcorebuf);\r\nreturn rc;\r\n}\r\nset_vmcore_list_offsets_elf64(elfcorebuf, &vmcore_list);\r\nreturn 0;\r\n}\r\nstatic int __init parse_crash_elf32_headers(void)\r\n{\r\nint rc=0;\r\nElf32_Ehdr ehdr;\r\nu64 addr;\r\naddr = elfcorehdr_addr;\r\nrc = read_from_oldmem((char*)&ehdr, sizeof(Elf32_Ehdr), &addr, 0);\r\nif (rc < 0)\r\nreturn rc;\r\nif (memcmp(ehdr.e_ident, ELFMAG, SELFMAG) != 0 ||\r\n(ehdr.e_type != ET_CORE) ||\r\n!elf_check_arch(&ehdr) ||\r\nehdr.e_ident[EI_CLASS] != ELFCLASS32||\r\nehdr.e_ident[EI_VERSION] != EV_CURRENT ||\r\nehdr.e_version != EV_CURRENT ||\r\nehdr.e_ehsize != sizeof(Elf32_Ehdr) ||\r\nehdr.e_phentsize != sizeof(Elf32_Phdr) ||\r\nehdr.e_phnum == 0) {\r\nprintk(KERN_WARNING "Warning: Core image elf header is not"\r\n"sane\n");\r\nreturn -EINVAL;\r\n}\r\nelfcorebuf_sz = sizeof(Elf32_Ehdr) + ehdr.e_phnum * sizeof(Elf32_Phdr);\r\nelfcorebuf = kmalloc(elfcorebuf_sz, GFP_KERNEL);\r\nif (!elfcorebuf)\r\nreturn -ENOMEM;\r\naddr = elfcorehdr_addr;\r\nrc = read_from_oldmem(elfcorebuf, elfcorebuf_sz, &addr, 0);\r\nif (rc < 0) {\r\nkfree(elfcorebuf);\r\nreturn rc;\r\n}\r\nrc = merge_note_headers_elf32(elfcorebuf, &elfcorebuf_sz, &vmcore_list);\r\nif (rc) {\r\nkfree(elfcorebuf);\r\nreturn rc;\r\n}\r\nrc = process_ptload_program_headers_elf32(elfcorebuf, elfcorebuf_sz,\r\n&vmcore_list);\r\nif (rc) {\r\nkfree(elfcorebuf);\r\nreturn rc;\r\n}\r\nset_vmcore_list_offsets_elf32(elfcorebuf, &vmcore_list);\r\nreturn 0;\r\n}\r\nstatic int __init parse_crash_elf_headers(void)\r\n{\r\nunsigned char e_ident[EI_NIDENT];\r\nu64 addr;\r\nint rc=0;\r\naddr = elfcorehdr_addr;\r\nrc = read_from_oldmem(e_ident, EI_NIDENT, &addr, 0);\r\nif (rc < 0)\r\nreturn rc;\r\nif (memcmp(e_ident, ELFMAG, SELFMAG) != 0) {\r\nprintk(KERN_WARNING "Warning: Core image elf header"\r\n" not found\n");\r\nreturn -EINVAL;\r\n}\r\nif (e_ident[EI_CLASS] == ELFCLASS64) {\r\nrc = parse_crash_elf64_headers();\r\nif (rc)\r\nreturn rc;\r\nvmcore_size = get_vmcore_size_elf64(elfcorebuf);\r\n} else if (e_ident[EI_CLASS] == ELFCLASS32) {\r\nrc = parse_crash_elf32_headers();\r\nif (rc)\r\nreturn rc;\r\nvmcore_size = get_vmcore_size_elf32(elfcorebuf);\r\n} else {\r\nprintk(KERN_WARNING "Warning: Core image elf header is not"\r\n" sane\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init vmcore_init(void)\r\n{\r\nint rc = 0;\r\nif (!(is_vmcore_usable()))\r\nreturn rc;\r\nrc = parse_crash_elf_headers();\r\nif (rc) {\r\nprintk(KERN_WARNING "Kdump: vmcore not initialized\n");\r\nreturn rc;\r\n}\r\nproc_vmcore = proc_create("vmcore", S_IRUSR, NULL, &proc_vmcore_operations);\r\nif (proc_vmcore)\r\nproc_vmcore->size = vmcore_size;\r\nreturn 0;\r\n}\r\nvoid vmcore_cleanup(void)\r\n{\r\nstruct list_head *pos, *next;\r\nif (proc_vmcore) {\r\nremove_proc_entry(proc_vmcore->name, proc_vmcore->parent);\r\nproc_vmcore = NULL;\r\n}\r\nlist_for_each_safe(pos, next, &vmcore_list) {\r\nstruct vmcore *m;\r\nm = list_entry(pos, struct vmcore, list);\r\nlist_del(&m->list);\r\nkfree(m);\r\n}\r\nkfree(elfcorebuf);\r\nelfcorebuf = NULL;\r\n}
