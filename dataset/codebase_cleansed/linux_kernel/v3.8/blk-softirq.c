static void blk_done_softirq(struct softirq_action *h)\r\n{\r\nstruct list_head *cpu_list, local_list;\r\nlocal_irq_disable();\r\ncpu_list = &__get_cpu_var(blk_cpu_done);\r\nlist_replace_init(cpu_list, &local_list);\r\nlocal_irq_enable();\r\nwhile (!list_empty(&local_list)) {\r\nstruct request *rq;\r\nrq = list_entry(local_list.next, struct request, csd.list);\r\nlist_del_init(&rq->csd.list);\r\nrq->q->softirq_done_fn(rq);\r\n}\r\n}\r\nstatic void trigger_softirq(void *data)\r\n{\r\nstruct request *rq = data;\r\nunsigned long flags;\r\nstruct list_head *list;\r\nlocal_irq_save(flags);\r\nlist = &__get_cpu_var(blk_cpu_done);\r\nlist_add_tail(&rq->csd.list, list);\r\nif (list->next == &rq->csd.list)\r\nraise_softirq_irqoff(BLOCK_SOFTIRQ);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int raise_blk_irq(int cpu, struct request *rq)\r\n{\r\nif (cpu_online(cpu)) {\r\nstruct call_single_data *data = &rq->csd;\r\ndata->func = trigger_softirq;\r\ndata->info = rq;\r\ndata->flags = 0;\r\n__smp_call_function_single(cpu, data, 0);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic int raise_blk_irq(int cpu, struct request *rq)\r\n{\r\nreturn 1;\r\n}\r\nstatic int __cpuinit blk_cpu_notify(struct notifier_block *self,\r\nunsigned long action, void *hcpu)\r\n{\r\nif (action == CPU_DEAD || action == CPU_DEAD_FROZEN) {\r\nint cpu = (unsigned long) hcpu;\r\nlocal_irq_disable();\r\nlist_splice_init(&per_cpu(blk_cpu_done, cpu),\r\n&__get_cpu_var(blk_cpu_done));\r\nraise_softirq_irqoff(BLOCK_SOFTIRQ);\r\nlocal_irq_enable();\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nvoid __blk_complete_request(struct request *req)\r\n{\r\nint ccpu, cpu;\r\nstruct request_queue *q = req->q;\r\nunsigned long flags;\r\nbool shared = false;\r\nBUG_ON(!q->softirq_done_fn);\r\nlocal_irq_save(flags);\r\ncpu = smp_processor_id();\r\nif (req->cpu != -1) {\r\nccpu = req->cpu;\r\nif (!test_bit(QUEUE_FLAG_SAME_FORCE, &q->queue_flags))\r\nshared = cpus_share_cache(cpu, ccpu);\r\n} else\r\nccpu = cpu;\r\nif (ccpu == cpu || shared) {\r\nstruct list_head *list;\r\ndo_local:\r\nlist = &__get_cpu_var(blk_cpu_done);\r\nlist_add_tail(&req->csd.list, list);\r\nif (list->next == &req->csd.list)\r\nraise_softirq_irqoff(BLOCK_SOFTIRQ);\r\n} else if (raise_blk_irq(ccpu, req))\r\ngoto do_local;\r\nlocal_irq_restore(flags);\r\n}\r\nvoid blk_complete_request(struct request *req)\r\n{\r\nif (unlikely(blk_should_fake_timeout(req->q)))\r\nreturn;\r\nif (!blk_mark_rq_complete(req))\r\n__blk_complete_request(req);\r\n}\r\nstatic __init int blk_softirq_init(void)\r\n{\r\nint i;\r\nfor_each_possible_cpu(i)\r\nINIT_LIST_HEAD(&per_cpu(blk_cpu_done, i));\r\nopen_softirq(BLOCK_SOFTIRQ, blk_done_softirq);\r\nregister_hotcpu_notifier(&blk_cpu_notifier);\r\nreturn 0;\r\n}
