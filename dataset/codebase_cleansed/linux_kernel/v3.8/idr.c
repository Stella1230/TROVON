static struct idr_layer *get_from_free_list(struct idr *idp)\r\n{\r\nstruct idr_layer *p;\r\nunsigned long flags;\r\nspin_lock_irqsave(&idp->lock, flags);\r\nif ((p = idp->id_free)) {\r\nidp->id_free = p->ary[0];\r\nidp->id_free_cnt--;\r\np->ary[0] = NULL;\r\n}\r\nspin_unlock_irqrestore(&idp->lock, flags);\r\nreturn(p);\r\n}\r\nstatic void idr_layer_rcu_free(struct rcu_head *head)\r\n{\r\nstruct idr_layer *layer;\r\nlayer = container_of(head, struct idr_layer, rcu_head);\r\nkmem_cache_free(idr_layer_cache, layer);\r\n}\r\nstatic inline void free_layer(struct idr_layer *p)\r\n{\r\ncall_rcu(&p->rcu_head, idr_layer_rcu_free);\r\n}\r\nstatic void __move_to_free_list(struct idr *idp, struct idr_layer *p)\r\n{\r\np->ary[0] = idp->id_free;\r\nidp->id_free = p;\r\nidp->id_free_cnt++;\r\n}\r\nstatic void move_to_free_list(struct idr *idp, struct idr_layer *p)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&idp->lock, flags);\r\n__move_to_free_list(idp, p);\r\nspin_unlock_irqrestore(&idp->lock, flags);\r\n}\r\nstatic void idr_mark_full(struct idr_layer **pa, int id)\r\n{\r\nstruct idr_layer *p = pa[0];\r\nint l = 0;\r\n__set_bit(id & IDR_MASK, &p->bitmap);\r\nwhile (p->bitmap == IDR_FULL) {\r\nif (!(p = pa[++l]))\r\nbreak;\r\nid = id >> IDR_BITS;\r\n__set_bit((id & IDR_MASK), &p->bitmap);\r\n}\r\n}\r\nint idr_pre_get(struct idr *idp, gfp_t gfp_mask)\r\n{\r\nwhile (idp->id_free_cnt < MAX_IDR_FREE) {\r\nstruct idr_layer *new;\r\nnew = kmem_cache_zalloc(idr_layer_cache, gfp_mask);\r\nif (new == NULL)\r\nreturn (0);\r\nmove_to_free_list(idp, new);\r\n}\r\nreturn 1;\r\n}\r\nstatic int sub_alloc(struct idr *idp, int *starting_id, struct idr_layer **pa)\r\n{\r\nint n, m, sh;\r\nstruct idr_layer *p, *new;\r\nint l, id, oid;\r\nunsigned long bm;\r\nid = *starting_id;\r\nrestart:\r\np = idp->top;\r\nl = idp->layers;\r\npa[l--] = NULL;\r\nwhile (1) {\r\nn = (id >> (IDR_BITS*l)) & IDR_MASK;\r\nbm = ~p->bitmap;\r\nm = find_next_bit(&bm, IDR_SIZE, n);\r\nif (m == IDR_SIZE) {\r\nl++;\r\noid = id;\r\nid = (id | ((1 << (IDR_BITS * l)) - 1)) + 1;\r\nif (id >= 1 << (idp->layers * IDR_BITS)) {\r\n*starting_id = id;\r\nreturn IDR_NEED_TO_GROW;\r\n}\r\np = pa[l];\r\nBUG_ON(!p);\r\nsh = IDR_BITS * (l + 1);\r\nif (oid >> sh == id >> sh)\r\ncontinue;\r\nelse\r\ngoto restart;\r\n}\r\nif (m != n) {\r\nsh = IDR_BITS*l;\r\nid = ((id >> sh) ^ n ^ m) << sh;\r\n}\r\nif ((id >= MAX_IDR_BIT) || (id < 0))\r\nreturn IDR_NOMORE_SPACE;\r\nif (l == 0)\r\nbreak;\r\nif (!p->ary[m]) {\r\nnew = get_from_free_list(idp);\r\nif (!new)\r\nreturn -1;\r\nnew->layer = l-1;\r\nrcu_assign_pointer(p->ary[m], new);\r\np->count++;\r\n}\r\npa[l--] = p;\r\np = p->ary[m];\r\n}\r\npa[l] = p;\r\nreturn id;\r\n}\r\nstatic int idr_get_empty_slot(struct idr *idp, int starting_id,\r\nstruct idr_layer **pa)\r\n{\r\nstruct idr_layer *p, *new;\r\nint layers, v, id;\r\nunsigned long flags;\r\nid = starting_id;\r\nbuild_up:\r\np = idp->top;\r\nlayers = idp->layers;\r\nif (unlikely(!p)) {\r\nif (!(p = get_from_free_list(idp)))\r\nreturn -1;\r\np->layer = 0;\r\nlayers = 1;\r\n}\r\nwhile ((layers < (MAX_IDR_LEVEL - 1)) && (id >= (1 << (layers*IDR_BITS)))) {\r\nlayers++;\r\nif (!p->count) {\r\np->layer++;\r\ncontinue;\r\n}\r\nif (!(new = get_from_free_list(idp))) {\r\nspin_lock_irqsave(&idp->lock, flags);\r\nfor (new = p; p && p != idp->top; new = p) {\r\np = p->ary[0];\r\nnew->ary[0] = NULL;\r\nnew->bitmap = new->count = 0;\r\n__move_to_free_list(idp, new);\r\n}\r\nspin_unlock_irqrestore(&idp->lock, flags);\r\nreturn -1;\r\n}\r\nnew->ary[0] = p;\r\nnew->count = 1;\r\nnew->layer = layers-1;\r\nif (p->bitmap == IDR_FULL)\r\n__set_bit(0, &new->bitmap);\r\np = new;\r\n}\r\nrcu_assign_pointer(idp->top, p);\r\nidp->layers = layers;\r\nv = sub_alloc(idp, &id, pa);\r\nif (v == IDR_NEED_TO_GROW)\r\ngoto build_up;\r\nreturn(v);\r\n}\r\nstatic int idr_get_new_above_int(struct idr *idp, void *ptr, int starting_id)\r\n{\r\nstruct idr_layer *pa[MAX_IDR_LEVEL];\r\nint id;\r\nid = idr_get_empty_slot(idp, starting_id, pa);\r\nif (id >= 0) {\r\nrcu_assign_pointer(pa[0]->ary[id & IDR_MASK],\r\n(struct idr_layer *)ptr);\r\npa[0]->count++;\r\nidr_mark_full(pa, id);\r\n}\r\nreturn id;\r\n}\r\nint idr_get_new_above(struct idr *idp, void *ptr, int starting_id, int *id)\r\n{\r\nint rv;\r\nrv = idr_get_new_above_int(idp, ptr, starting_id);\r\nif (rv < 0)\r\nreturn _idr_rc_to_errno(rv);\r\n*id = rv;\r\nreturn 0;\r\n}\r\nint idr_get_new(struct idr *idp, void *ptr, int *id)\r\n{\r\nint rv;\r\nrv = idr_get_new_above_int(idp, ptr, 0);\r\nif (rv < 0)\r\nreturn _idr_rc_to_errno(rv);\r\n*id = rv;\r\nreturn 0;\r\n}\r\nstatic void idr_remove_warning(int id)\r\n{\r\nprintk(KERN_WARNING\r\n"idr_remove called for id=%d which is not allocated.\n", id);\r\ndump_stack();\r\n}\r\nstatic void sub_remove(struct idr *idp, int shift, int id)\r\n{\r\nstruct idr_layer *p = idp->top;\r\nstruct idr_layer **pa[MAX_IDR_LEVEL];\r\nstruct idr_layer ***paa = &pa[0];\r\nstruct idr_layer *to_free;\r\nint n;\r\n*paa = NULL;\r\n*++paa = &idp->top;\r\nwhile ((shift > 0) && p) {\r\nn = (id >> shift) & IDR_MASK;\r\n__clear_bit(n, &p->bitmap);\r\n*++paa = &p->ary[n];\r\np = p->ary[n];\r\nshift -= IDR_BITS;\r\n}\r\nn = id & IDR_MASK;\r\nif (likely(p != NULL && test_bit(n, &p->bitmap))){\r\n__clear_bit(n, &p->bitmap);\r\nrcu_assign_pointer(p->ary[n], NULL);\r\nto_free = NULL;\r\nwhile(*paa && ! --((**paa)->count)){\r\nif (to_free)\r\nfree_layer(to_free);\r\nto_free = **paa;\r\n**paa-- = NULL;\r\n}\r\nif (!*paa)\r\nidp->layers = 0;\r\nif (to_free)\r\nfree_layer(to_free);\r\n} else\r\nidr_remove_warning(id);\r\n}\r\nvoid idr_remove(struct idr *idp, int id)\r\n{\r\nstruct idr_layer *p;\r\nstruct idr_layer *to_free;\r\nid &= MAX_IDR_MASK;\r\nsub_remove(idp, (idp->layers - 1) * IDR_BITS, id);\r\nif (idp->top && idp->top->count == 1 && (idp->layers > 1) &&\r\nidp->top->ary[0]) {\r\nto_free = idp->top;\r\np = idp->top->ary[0];\r\nrcu_assign_pointer(idp->top, p);\r\n--idp->layers;\r\nto_free->bitmap = to_free->count = 0;\r\nfree_layer(to_free);\r\n}\r\nwhile (idp->id_free_cnt >= MAX_IDR_FREE) {\r\np = get_from_free_list(idp);\r\nkmem_cache_free(idr_layer_cache, p);\r\n}\r\nreturn;\r\n}\r\nvoid idr_remove_all(struct idr *idp)\r\n{\r\nint n, id, max;\r\nint bt_mask;\r\nstruct idr_layer *p;\r\nstruct idr_layer *pa[MAX_IDR_LEVEL];\r\nstruct idr_layer **paa = &pa[0];\r\nn = idp->layers * IDR_BITS;\r\np = idp->top;\r\nrcu_assign_pointer(idp->top, NULL);\r\nmax = 1 << n;\r\nid = 0;\r\nwhile (id < max) {\r\nwhile (n > IDR_BITS && p) {\r\nn -= IDR_BITS;\r\n*paa++ = p;\r\np = p->ary[(id >> n) & IDR_MASK];\r\n}\r\nbt_mask = id;\r\nid += 1 << n;\r\nwhile (n < fls(id ^ bt_mask)) {\r\nif (p)\r\nfree_layer(p);\r\nn += IDR_BITS;\r\np = *--paa;\r\n}\r\n}\r\nidp->layers = 0;\r\n}\r\nvoid idr_destroy(struct idr *idp)\r\n{\r\nwhile (idp->id_free_cnt) {\r\nstruct idr_layer *p = get_from_free_list(idp);\r\nkmem_cache_free(idr_layer_cache, p);\r\n}\r\n}\r\nvoid *idr_find(struct idr *idp, int id)\r\n{\r\nint n;\r\nstruct idr_layer *p;\r\np = rcu_dereference_raw(idp->top);\r\nif (!p)\r\nreturn NULL;\r\nn = (p->layer+1) * IDR_BITS;\r\nid &= MAX_IDR_MASK;\r\nif (id >= (1 << n))\r\nreturn NULL;\r\nBUG_ON(n == 0);\r\nwhile (n > 0 && p) {\r\nn -= IDR_BITS;\r\nBUG_ON(n != p->layer*IDR_BITS);\r\np = rcu_dereference_raw(p->ary[(id >> n) & IDR_MASK]);\r\n}\r\nreturn((void *)p);\r\n}\r\nint idr_for_each(struct idr *idp,\r\nint (*fn)(int id, void *p, void *data), void *data)\r\n{\r\nint n, id, max, error = 0;\r\nstruct idr_layer *p;\r\nstruct idr_layer *pa[MAX_IDR_LEVEL];\r\nstruct idr_layer **paa = &pa[0];\r\nn = idp->layers * IDR_BITS;\r\np = rcu_dereference_raw(idp->top);\r\nmax = 1 << n;\r\nid = 0;\r\nwhile (id < max) {\r\nwhile (n > 0 && p) {\r\nn -= IDR_BITS;\r\n*paa++ = p;\r\np = rcu_dereference_raw(p->ary[(id >> n) & IDR_MASK]);\r\n}\r\nif (p) {\r\nerror = fn(id, (void *)p, data);\r\nif (error)\r\nbreak;\r\n}\r\nid += 1 << n;\r\nwhile (n < fls(id)) {\r\nn += IDR_BITS;\r\np = *--paa;\r\n}\r\n}\r\nreturn error;\r\n}\r\nvoid *idr_get_next(struct idr *idp, int *nextidp)\r\n{\r\nstruct idr_layer *p, *pa[MAX_IDR_LEVEL];\r\nstruct idr_layer **paa = &pa[0];\r\nint id = *nextidp;\r\nint n, max;\r\np = rcu_dereference_raw(idp->top);\r\nif (!p)\r\nreturn NULL;\r\nn = (p->layer + 1) * IDR_BITS;\r\nmax = 1 << n;\r\nwhile (id < max) {\r\nwhile (n > 0 && p) {\r\nn -= IDR_BITS;\r\n*paa++ = p;\r\np = rcu_dereference_raw(p->ary[(id >> n) & IDR_MASK]);\r\n}\r\nif (p) {\r\n*nextidp = id;\r\nreturn p;\r\n}\r\nid += 1 << n;\r\nwhile (n < fls(id)) {\r\nn += IDR_BITS;\r\np = *--paa;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nvoid *idr_replace(struct idr *idp, void *ptr, int id)\r\n{\r\nint n;\r\nstruct idr_layer *p, *old_p;\r\np = idp->top;\r\nif (!p)\r\nreturn ERR_PTR(-EINVAL);\r\nn = (p->layer+1) * IDR_BITS;\r\nid &= MAX_IDR_MASK;\r\nif (id >= (1 << n))\r\nreturn ERR_PTR(-EINVAL);\r\nn -= IDR_BITS;\r\nwhile ((n > 0) && p) {\r\np = p->ary[(id >> n) & IDR_MASK];\r\nn -= IDR_BITS;\r\n}\r\nn = id & IDR_MASK;\r\nif (unlikely(p == NULL || !test_bit(n, &p->bitmap)))\r\nreturn ERR_PTR(-ENOENT);\r\nold_p = p->ary[n];\r\nrcu_assign_pointer(p->ary[n], ptr);\r\nreturn old_p;\r\n}\r\nvoid __init idr_init_cache(void)\r\n{\r\nidr_layer_cache = kmem_cache_create("idr_layer_cache",\r\nsizeof(struct idr_layer), 0, SLAB_PANIC, NULL);\r\n}\r\nvoid idr_init(struct idr *idp)\r\n{\r\nmemset(idp, 0, sizeof(struct idr));\r\nspin_lock_init(&idp->lock);\r\n}\r\nstatic void free_bitmap(struct ida *ida, struct ida_bitmap *bitmap)\r\n{\r\nunsigned long flags;\r\nif (!ida->free_bitmap) {\r\nspin_lock_irqsave(&ida->idr.lock, flags);\r\nif (!ida->free_bitmap) {\r\nida->free_bitmap = bitmap;\r\nbitmap = NULL;\r\n}\r\nspin_unlock_irqrestore(&ida->idr.lock, flags);\r\n}\r\nkfree(bitmap);\r\n}\r\nint ida_pre_get(struct ida *ida, gfp_t gfp_mask)\r\n{\r\nif (!idr_pre_get(&ida->idr, gfp_mask))\r\nreturn 0;\r\nif (!ida->free_bitmap) {\r\nstruct ida_bitmap *bitmap;\r\nbitmap = kmalloc(sizeof(struct ida_bitmap), gfp_mask);\r\nif (!bitmap)\r\nreturn 0;\r\nfree_bitmap(ida, bitmap);\r\n}\r\nreturn 1;\r\n}\r\nint ida_get_new_above(struct ida *ida, int starting_id, int *p_id)\r\n{\r\nstruct idr_layer *pa[MAX_IDR_LEVEL];\r\nstruct ida_bitmap *bitmap;\r\nunsigned long flags;\r\nint idr_id = starting_id / IDA_BITMAP_BITS;\r\nint offset = starting_id % IDA_BITMAP_BITS;\r\nint t, id;\r\nrestart:\r\nt = idr_get_empty_slot(&ida->idr, idr_id, pa);\r\nif (t < 0)\r\nreturn _idr_rc_to_errno(t);\r\nif (t * IDA_BITMAP_BITS >= MAX_IDR_BIT)\r\nreturn -ENOSPC;\r\nif (t != idr_id)\r\noffset = 0;\r\nidr_id = t;\r\nbitmap = (void *)pa[0]->ary[idr_id & IDR_MASK];\r\nif (!bitmap) {\r\nspin_lock_irqsave(&ida->idr.lock, flags);\r\nbitmap = ida->free_bitmap;\r\nida->free_bitmap = NULL;\r\nspin_unlock_irqrestore(&ida->idr.lock, flags);\r\nif (!bitmap)\r\nreturn -EAGAIN;\r\nmemset(bitmap, 0, sizeof(struct ida_bitmap));\r\nrcu_assign_pointer(pa[0]->ary[idr_id & IDR_MASK],\r\n(void *)bitmap);\r\npa[0]->count++;\r\n}\r\nt = find_next_zero_bit(bitmap->bitmap, IDA_BITMAP_BITS, offset);\r\nif (t == IDA_BITMAP_BITS) {\r\nidr_id++;\r\noffset = 0;\r\ngoto restart;\r\n}\r\nid = idr_id * IDA_BITMAP_BITS + t;\r\nif (id >= MAX_IDR_BIT)\r\nreturn -ENOSPC;\r\n__set_bit(t, bitmap->bitmap);\r\nif (++bitmap->nr_busy == IDA_BITMAP_BITS)\r\nidr_mark_full(pa, idr_id);\r\n*p_id = id;\r\nif (ida->idr.id_free_cnt || ida->free_bitmap) {\r\nstruct idr_layer *p = get_from_free_list(&ida->idr);\r\nif (p)\r\nkmem_cache_free(idr_layer_cache, p);\r\n}\r\nreturn 0;\r\n}\r\nint ida_get_new(struct ida *ida, int *p_id)\r\n{\r\nreturn ida_get_new_above(ida, 0, p_id);\r\n}\r\nvoid ida_remove(struct ida *ida, int id)\r\n{\r\nstruct idr_layer *p = ida->idr.top;\r\nint shift = (ida->idr.layers - 1) * IDR_BITS;\r\nint idr_id = id / IDA_BITMAP_BITS;\r\nint offset = id % IDA_BITMAP_BITS;\r\nint n;\r\nstruct ida_bitmap *bitmap;\r\nwhile ((shift > 0) && p) {\r\nn = (idr_id >> shift) & IDR_MASK;\r\n__clear_bit(n, &p->bitmap);\r\np = p->ary[n];\r\nshift -= IDR_BITS;\r\n}\r\nif (p == NULL)\r\ngoto err;\r\nn = idr_id & IDR_MASK;\r\n__clear_bit(n, &p->bitmap);\r\nbitmap = (void *)p->ary[n];\r\nif (!test_bit(offset, bitmap->bitmap))\r\ngoto err;\r\n__clear_bit(offset, bitmap->bitmap);\r\nif (--bitmap->nr_busy == 0) {\r\n__set_bit(n, &p->bitmap);\r\nidr_remove(&ida->idr, idr_id);\r\nfree_bitmap(ida, bitmap);\r\n}\r\nreturn;\r\nerr:\r\nprintk(KERN_WARNING\r\n"ida_remove called for id=%d which is not allocated.\n", id);\r\n}\r\nvoid ida_destroy(struct ida *ida)\r\n{\r\nidr_destroy(&ida->idr);\r\nkfree(ida->free_bitmap);\r\n}\r\nint ida_simple_get(struct ida *ida, unsigned int start, unsigned int end,\r\ngfp_t gfp_mask)\r\n{\r\nint ret, id;\r\nunsigned int max;\r\nunsigned long flags;\r\nBUG_ON((int)start < 0);\r\nBUG_ON((int)end < 0);\r\nif (end == 0)\r\nmax = 0x80000000;\r\nelse {\r\nBUG_ON(end < start);\r\nmax = end - 1;\r\n}\r\nagain:\r\nif (!ida_pre_get(ida, gfp_mask))\r\nreturn -ENOMEM;\r\nspin_lock_irqsave(&simple_ida_lock, flags);\r\nret = ida_get_new_above(ida, start, &id);\r\nif (!ret) {\r\nif (id > max) {\r\nida_remove(ida, id);\r\nret = -ENOSPC;\r\n} else {\r\nret = id;\r\n}\r\n}\r\nspin_unlock_irqrestore(&simple_ida_lock, flags);\r\nif (unlikely(ret == -EAGAIN))\r\ngoto again;\r\nreturn ret;\r\n}\r\nvoid ida_simple_remove(struct ida *ida, unsigned int id)\r\n{\r\nunsigned long flags;\r\nBUG_ON((int)id < 0);\r\nspin_lock_irqsave(&simple_ida_lock, flags);\r\nida_remove(ida, id);\r\nspin_unlock_irqrestore(&simple_ida_lock, flags);\r\n}\r\nvoid ida_init(struct ida *ida)\r\n{\r\nmemset(ida, 0, sizeof(struct ida));\r\nidr_init(&ida->idr);\r\n}
