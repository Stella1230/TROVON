void nf_ct_unlink_expect_report(struct nf_conntrack_expect *exp,\r\nu32 pid, int report)\r\n{\r\nstruct nf_conn_help *master_help = nfct_help(exp->master);\r\nstruct net *net = nf_ct_exp_net(exp);\r\nNF_CT_ASSERT(master_help);\r\nNF_CT_ASSERT(!timer_pending(&exp->timeout));\r\nhlist_del_rcu(&exp->hnode);\r\nnet->ct.expect_count--;\r\nhlist_del(&exp->lnode);\r\nmaster_help->expecting[exp->class]--;\r\nnf_ct_expect_event_report(IPEXP_DESTROY, exp, pid, report);\r\nnf_ct_expect_put(exp);\r\nNF_CT_STAT_INC(net, expect_delete);\r\n}\r\nstatic void nf_ct_expectation_timed_out(unsigned long ul_expect)\r\n{\r\nstruct nf_conntrack_expect *exp = (void *)ul_expect;\r\nspin_lock_bh(&nf_conntrack_lock);\r\nnf_ct_unlink_expect(exp);\r\nspin_unlock_bh(&nf_conntrack_lock);\r\nnf_ct_expect_put(exp);\r\n}\r\nstatic unsigned int nf_ct_expect_dst_hash(const struct nf_conntrack_tuple *tuple)\r\n{\r\nunsigned int hash;\r\nif (unlikely(!nf_conntrack_hash_rnd)) {\r\ninit_nf_conntrack_hash_rnd();\r\n}\r\nhash = jhash2(tuple->dst.u3.all, ARRAY_SIZE(tuple->dst.u3.all),\r\n(((tuple->dst.protonum ^ tuple->src.l3num) << 16) |\r\n(__force __u16)tuple->dst.u.all) ^ nf_conntrack_hash_rnd);\r\nreturn ((u64)hash * nf_ct_expect_hsize) >> 32;\r\n}\r\nstruct nf_conntrack_expect *\r\n__nf_ct_expect_find(struct net *net, u16 zone,\r\nconst struct nf_conntrack_tuple *tuple)\r\n{\r\nstruct nf_conntrack_expect *i;\r\nstruct hlist_node *n;\r\nunsigned int h;\r\nif (!net->ct.expect_count)\r\nreturn NULL;\r\nh = nf_ct_expect_dst_hash(tuple);\r\nhlist_for_each_entry_rcu(i, n, &net->ct.expect_hash[h], hnode) {\r\nif (nf_ct_tuple_mask_cmp(tuple, &i->tuple, &i->mask) &&\r\nnf_ct_zone(i->master) == zone)\r\nreturn i;\r\n}\r\nreturn NULL;\r\n}\r\nstruct nf_conntrack_expect *\r\nnf_ct_expect_find_get(struct net *net, u16 zone,\r\nconst struct nf_conntrack_tuple *tuple)\r\n{\r\nstruct nf_conntrack_expect *i;\r\nrcu_read_lock();\r\ni = __nf_ct_expect_find(net, zone, tuple);\r\nif (i && !atomic_inc_not_zero(&i->use))\r\ni = NULL;\r\nrcu_read_unlock();\r\nreturn i;\r\n}\r\nstruct nf_conntrack_expect *\r\nnf_ct_find_expectation(struct net *net, u16 zone,\r\nconst struct nf_conntrack_tuple *tuple)\r\n{\r\nstruct nf_conntrack_expect *i, *exp = NULL;\r\nstruct hlist_node *n;\r\nunsigned int h;\r\nif (!net->ct.expect_count)\r\nreturn NULL;\r\nh = nf_ct_expect_dst_hash(tuple);\r\nhlist_for_each_entry(i, n, &net->ct.expect_hash[h], hnode) {\r\nif (!(i->flags & NF_CT_EXPECT_INACTIVE) &&\r\nnf_ct_tuple_mask_cmp(tuple, &i->tuple, &i->mask) &&\r\nnf_ct_zone(i->master) == zone) {\r\nexp = i;\r\nbreak;\r\n}\r\n}\r\nif (!exp)\r\nreturn NULL;\r\nif (!nf_ct_is_confirmed(exp->master))\r\nreturn NULL;\r\nif (exp->flags & NF_CT_EXPECT_PERMANENT) {\r\natomic_inc(&exp->use);\r\nreturn exp;\r\n} else if (del_timer(&exp->timeout)) {\r\nnf_ct_unlink_expect(exp);\r\nreturn exp;\r\n}\r\nreturn NULL;\r\n}\r\nvoid nf_ct_remove_expectations(struct nf_conn *ct)\r\n{\r\nstruct nf_conn_help *help = nfct_help(ct);\r\nstruct nf_conntrack_expect *exp;\r\nstruct hlist_node *n, *next;\r\nif (!help)\r\nreturn;\r\nhlist_for_each_entry_safe(exp, n, next, &help->expectations, lnode) {\r\nif (del_timer(&exp->timeout)) {\r\nnf_ct_unlink_expect(exp);\r\nnf_ct_expect_put(exp);\r\n}\r\n}\r\n}\r\nstatic inline int expect_clash(const struct nf_conntrack_expect *a,\r\nconst struct nf_conntrack_expect *b)\r\n{\r\nstruct nf_conntrack_tuple_mask intersect_mask;\r\nint count;\r\nintersect_mask.src.u.all = a->mask.src.u.all & b->mask.src.u.all;\r\nfor (count = 0; count < NF_CT_TUPLE_L3SIZE; count++){\r\nintersect_mask.src.u3.all[count] =\r\na->mask.src.u3.all[count] & b->mask.src.u3.all[count];\r\n}\r\nreturn nf_ct_tuple_mask_cmp(&a->tuple, &b->tuple, &intersect_mask);\r\n}\r\nstatic inline int expect_matches(const struct nf_conntrack_expect *a,\r\nconst struct nf_conntrack_expect *b)\r\n{\r\nreturn a->master == b->master && a->class == b->class &&\r\nnf_ct_tuple_equal(&a->tuple, &b->tuple) &&\r\nnf_ct_tuple_mask_equal(&a->mask, &b->mask) &&\r\nnf_ct_zone(a->master) == nf_ct_zone(b->master);\r\n}\r\nvoid nf_ct_unexpect_related(struct nf_conntrack_expect *exp)\r\n{\r\nspin_lock_bh(&nf_conntrack_lock);\r\nif (del_timer(&exp->timeout)) {\r\nnf_ct_unlink_expect(exp);\r\nnf_ct_expect_put(exp);\r\n}\r\nspin_unlock_bh(&nf_conntrack_lock);\r\n}\r\nstruct nf_conntrack_expect *nf_ct_expect_alloc(struct nf_conn *me)\r\n{\r\nstruct nf_conntrack_expect *new;\r\nnew = kmem_cache_alloc(nf_ct_expect_cachep, GFP_ATOMIC);\r\nif (!new)\r\nreturn NULL;\r\nnew->master = me;\r\natomic_set(&new->use, 1);\r\nreturn new;\r\n}\r\nvoid nf_ct_expect_init(struct nf_conntrack_expect *exp, unsigned int class,\r\nu_int8_t family,\r\nconst union nf_inet_addr *saddr,\r\nconst union nf_inet_addr *daddr,\r\nu_int8_t proto, const __be16 *src, const __be16 *dst)\r\n{\r\nint len;\r\nif (family == AF_INET)\r\nlen = 4;\r\nelse\r\nlen = 16;\r\nexp->flags = 0;\r\nexp->class = class;\r\nexp->expectfn = NULL;\r\nexp->helper = NULL;\r\nexp->tuple.src.l3num = family;\r\nexp->tuple.dst.protonum = proto;\r\nif (saddr) {\r\nmemcpy(&exp->tuple.src.u3, saddr, len);\r\nif (sizeof(exp->tuple.src.u3) > len)\r\nmemset((void *)&exp->tuple.src.u3 + len, 0x00,\r\nsizeof(exp->tuple.src.u3) - len);\r\nmemset(&exp->mask.src.u3, 0xFF, len);\r\nif (sizeof(exp->mask.src.u3) > len)\r\nmemset((void *)&exp->mask.src.u3 + len, 0x00,\r\nsizeof(exp->mask.src.u3) - len);\r\n} else {\r\nmemset(&exp->tuple.src.u3, 0x00, sizeof(exp->tuple.src.u3));\r\nmemset(&exp->mask.src.u3, 0x00, sizeof(exp->mask.src.u3));\r\n}\r\nif (src) {\r\nexp->tuple.src.u.all = *src;\r\nexp->mask.src.u.all = htons(0xFFFF);\r\n} else {\r\nexp->tuple.src.u.all = 0;\r\nexp->mask.src.u.all = 0;\r\n}\r\nmemcpy(&exp->tuple.dst.u3, daddr, len);\r\nif (sizeof(exp->tuple.dst.u3) > len)\r\nmemset((void *)&exp->tuple.dst.u3 + len, 0x00,\r\nsizeof(exp->tuple.dst.u3) - len);\r\nexp->tuple.dst.u.all = *dst;\r\n}\r\nstatic void nf_ct_expect_free_rcu(struct rcu_head *head)\r\n{\r\nstruct nf_conntrack_expect *exp;\r\nexp = container_of(head, struct nf_conntrack_expect, rcu);\r\nkmem_cache_free(nf_ct_expect_cachep, exp);\r\n}\r\nvoid nf_ct_expect_put(struct nf_conntrack_expect *exp)\r\n{\r\nif (atomic_dec_and_test(&exp->use))\r\ncall_rcu(&exp->rcu, nf_ct_expect_free_rcu);\r\n}\r\nstatic int nf_ct_expect_insert(struct nf_conntrack_expect *exp)\r\n{\r\nstruct nf_conn_help *master_help = nfct_help(exp->master);\r\nstruct nf_conntrack_helper *helper;\r\nstruct net *net = nf_ct_exp_net(exp);\r\nunsigned int h = nf_ct_expect_dst_hash(&exp->tuple);\r\natomic_add(2, &exp->use);\r\nhlist_add_head(&exp->lnode, &master_help->expectations);\r\nmaster_help->expecting[exp->class]++;\r\nhlist_add_head_rcu(&exp->hnode, &net->ct.expect_hash[h]);\r\nnet->ct.expect_count++;\r\nsetup_timer(&exp->timeout, nf_ct_expectation_timed_out,\r\n(unsigned long)exp);\r\nhelper = rcu_dereference_protected(master_help->helper,\r\nlockdep_is_held(&nf_conntrack_lock));\r\nif (helper) {\r\nexp->timeout.expires = jiffies +\r\nhelper->expect_policy[exp->class].timeout * HZ;\r\n}\r\nadd_timer(&exp->timeout);\r\nNF_CT_STAT_INC(net, expect_create);\r\nreturn 0;\r\n}\r\nstatic void evict_oldest_expect(struct nf_conn *master,\r\nstruct nf_conntrack_expect *new)\r\n{\r\nstruct nf_conn_help *master_help = nfct_help(master);\r\nstruct nf_conntrack_expect *exp, *last = NULL;\r\nstruct hlist_node *n;\r\nhlist_for_each_entry(exp, n, &master_help->expectations, lnode) {\r\nif (exp->class == new->class)\r\nlast = exp;\r\n}\r\nif (last && del_timer(&last->timeout)) {\r\nnf_ct_unlink_expect(last);\r\nnf_ct_expect_put(last);\r\n}\r\n}\r\nstatic inline int __nf_ct_expect_check(struct nf_conntrack_expect *expect)\r\n{\r\nconst struct nf_conntrack_expect_policy *p;\r\nstruct nf_conntrack_expect *i;\r\nstruct nf_conn *master = expect->master;\r\nstruct nf_conn_help *master_help = nfct_help(master);\r\nstruct nf_conntrack_helper *helper;\r\nstruct net *net = nf_ct_exp_net(expect);\r\nstruct hlist_node *n, *next;\r\nunsigned int h;\r\nint ret = 1;\r\nif (!master_help) {\r\nret = -ESHUTDOWN;\r\ngoto out;\r\n}\r\nh = nf_ct_expect_dst_hash(&expect->tuple);\r\nhlist_for_each_entry_safe(i, n, next, &net->ct.expect_hash[h], hnode) {\r\nif (expect_matches(i, expect)) {\r\nif (del_timer(&i->timeout)) {\r\nnf_ct_unlink_expect(i);\r\nnf_ct_expect_put(i);\r\nbreak;\r\n}\r\n} else if (expect_clash(i, expect)) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\n}\r\nhelper = rcu_dereference_protected(master_help->helper,\r\nlockdep_is_held(&nf_conntrack_lock));\r\nif (helper) {\r\np = &helper->expect_policy[expect->class];\r\nif (p->max_expected &&\r\nmaster_help->expecting[expect->class] >= p->max_expected) {\r\nevict_oldest_expect(master, expect);\r\nif (master_help->expecting[expect->class]\r\n>= p->max_expected) {\r\nret = -EMFILE;\r\ngoto out;\r\n}\r\n}\r\n}\r\nif (net->ct.expect_count >= nf_ct_expect_max) {\r\nnet_warn_ratelimited("nf_conntrack: expectation table full\n");\r\nret = -EMFILE;\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nint nf_ct_expect_related_report(struct nf_conntrack_expect *expect,\r\nu32 pid, int report)\r\n{\r\nint ret;\r\nspin_lock_bh(&nf_conntrack_lock);\r\nret = __nf_ct_expect_check(expect);\r\nif (ret <= 0)\r\ngoto out;\r\nret = nf_ct_expect_insert(expect);\r\nif (ret < 0)\r\ngoto out;\r\nspin_unlock_bh(&nf_conntrack_lock);\r\nnf_ct_expect_event_report(IPEXP_NEW, expect, pid, report);\r\nreturn ret;\r\nout:\r\nspin_unlock_bh(&nf_conntrack_lock);\r\nreturn ret;\r\n}\r\nstatic struct hlist_node *ct_expect_get_first(struct seq_file *seq)\r\n{\r\nstruct net *net = seq_file_net(seq);\r\nstruct ct_expect_iter_state *st = seq->private;\r\nstruct hlist_node *n;\r\nfor (st->bucket = 0; st->bucket < nf_ct_expect_hsize; st->bucket++) {\r\nn = rcu_dereference(hlist_first_rcu(&net->ct.expect_hash[st->bucket]));\r\nif (n)\r\nreturn n;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct hlist_node *ct_expect_get_next(struct seq_file *seq,\r\nstruct hlist_node *head)\r\n{\r\nstruct net *net = seq_file_net(seq);\r\nstruct ct_expect_iter_state *st = seq->private;\r\nhead = rcu_dereference(hlist_next_rcu(head));\r\nwhile (head == NULL) {\r\nif (++st->bucket >= nf_ct_expect_hsize)\r\nreturn NULL;\r\nhead = rcu_dereference(hlist_first_rcu(&net->ct.expect_hash[st->bucket]));\r\n}\r\nreturn head;\r\n}\r\nstatic struct hlist_node *ct_expect_get_idx(struct seq_file *seq, loff_t pos)\r\n{\r\nstruct hlist_node *head = ct_expect_get_first(seq);\r\nif (head)\r\nwhile (pos && (head = ct_expect_get_next(seq, head)))\r\npos--;\r\nreturn pos ? NULL : head;\r\n}\r\nstatic void *exp_seq_start(struct seq_file *seq, loff_t *pos)\r\n__acquires(RCU)\r\n{\r\nrcu_read_lock();\r\nreturn ct_expect_get_idx(seq, *pos);\r\n}\r\nstatic void *exp_seq_next(struct seq_file *seq, void *v, loff_t *pos)\r\n{\r\n(*pos)++;\r\nreturn ct_expect_get_next(seq, v);\r\n}\r\nstatic void exp_seq_stop(struct seq_file *seq, void *v)\r\n__releases(RCU)\r\n{\r\nrcu_read_unlock();\r\n}\r\nstatic int exp_seq_show(struct seq_file *s, void *v)\r\n{\r\nstruct nf_conntrack_expect *expect;\r\nstruct nf_conntrack_helper *helper;\r\nstruct hlist_node *n = v;\r\nchar *delim = "";\r\nexpect = hlist_entry(n, struct nf_conntrack_expect, hnode);\r\nif (expect->timeout.function)\r\nseq_printf(s, "%ld ", timer_pending(&expect->timeout)\r\n? (long)(expect->timeout.expires - jiffies)/HZ : 0);\r\nelse\r\nseq_printf(s, "- ");\r\nseq_printf(s, "l3proto = %u proto=%u ",\r\nexpect->tuple.src.l3num,\r\nexpect->tuple.dst.protonum);\r\nprint_tuple(s, &expect->tuple,\r\n__nf_ct_l3proto_find(expect->tuple.src.l3num),\r\n__nf_ct_l4proto_find(expect->tuple.src.l3num,\r\nexpect->tuple.dst.protonum));\r\nif (expect->flags & NF_CT_EXPECT_PERMANENT) {\r\nseq_printf(s, "PERMANENT");\r\ndelim = ",";\r\n}\r\nif (expect->flags & NF_CT_EXPECT_INACTIVE) {\r\nseq_printf(s, "%sINACTIVE", delim);\r\ndelim = ",";\r\n}\r\nif (expect->flags & NF_CT_EXPECT_USERSPACE)\r\nseq_printf(s, "%sUSERSPACE", delim);\r\nhelper = rcu_dereference(nfct_help(expect->master)->helper);\r\nif (helper) {\r\nseq_printf(s, "%s%s", expect->flags ? " " : "", helper->name);\r\nif (helper->expect_policy[expect->class].name)\r\nseq_printf(s, "/%s",\r\nhelper->expect_policy[expect->class].name);\r\n}\r\nreturn seq_putc(s, '\n');\r\n}\r\nstatic int exp_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open_net(inode, file, &exp_seq_ops,\r\nsizeof(struct ct_expect_iter_state));\r\n}\r\nstatic int exp_proc_init(struct net *net)\r\n{\r\n#ifdef CONFIG_NF_CONNTRACK_PROCFS\r\nstruct proc_dir_entry *proc;\r\nproc = proc_net_fops_create(net, "nf_conntrack_expect", 0440, &exp_file_ops);\r\nif (!proc)\r\nreturn -ENOMEM;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void exp_proc_remove(struct net *net)\r\n{\r\n#ifdef CONFIG_NF_CONNTRACK_PROCFS\r\nproc_net_remove(net, "nf_conntrack_expect");\r\n#endif\r\n}\r\nint nf_conntrack_expect_init(struct net *net)\r\n{\r\nint err = -ENOMEM;\r\nif (net_eq(net, &init_net)) {\r\nif (!nf_ct_expect_hsize) {\r\nnf_ct_expect_hsize = net->ct.htable_size / 256;\r\nif (!nf_ct_expect_hsize)\r\nnf_ct_expect_hsize = 1;\r\n}\r\nnf_ct_expect_max = nf_ct_expect_hsize * 4;\r\n}\r\nnet->ct.expect_count = 0;\r\nnet->ct.expect_hash = nf_ct_alloc_hashtable(&nf_ct_expect_hsize, 0);\r\nif (net->ct.expect_hash == NULL)\r\ngoto err1;\r\nif (net_eq(net, &init_net)) {\r\nnf_ct_expect_cachep = kmem_cache_create("nf_conntrack_expect",\r\nsizeof(struct nf_conntrack_expect),\r\n0, 0, NULL);\r\nif (!nf_ct_expect_cachep)\r\ngoto err2;\r\n}\r\nerr = exp_proc_init(net);\r\nif (err < 0)\r\ngoto err3;\r\nreturn 0;\r\nerr3:\r\nif (net_eq(net, &init_net))\r\nkmem_cache_destroy(nf_ct_expect_cachep);\r\nerr2:\r\nnf_ct_free_hashtable(net->ct.expect_hash, nf_ct_expect_hsize);\r\nerr1:\r\nreturn err;\r\n}\r\nvoid nf_conntrack_expect_fini(struct net *net)\r\n{\r\nexp_proc_remove(net);\r\nif (net_eq(net, &init_net)) {\r\nrcu_barrier();\r\nkmem_cache_destroy(nf_ct_expect_cachep);\r\n}\r\nnf_ct_free_hashtable(net->ct.expect_hash, nf_ct_expect_hsize);\r\n}
