static int ia64_set_msi_irq_affinity(struct irq_data *idata,\r\nconst cpumask_t *cpu_mask, bool force)\r\n{\r\nstruct msi_msg msg;\r\nu32 addr, data;\r\nint cpu = first_cpu(*cpu_mask);\r\nunsigned int irq = idata->irq;\r\nif (!cpu_online(cpu))\r\nreturn -1;\r\nif (irq_prepare_move(irq, cpu))\r\nreturn -1;\r\nget_cached_msi_msg(irq, &msg);\r\naddr = msg.address_lo;\r\naddr &= MSI_ADDR_DEST_ID_MASK;\r\naddr |= MSI_ADDR_DEST_ID_CPU(cpu_physical_id(cpu));\r\nmsg.address_lo = addr;\r\ndata = msg.data;\r\ndata &= MSI_DATA_VECTOR_MASK;\r\ndata |= MSI_DATA_VECTOR(irq_to_vector(irq));\r\nmsg.data = data;\r\nwrite_msi_msg(irq, &msg);\r\ncpumask_copy(idata->affinity, cpumask_of(cpu));\r\nreturn 0;\r\n}\r\nint ia64_setup_msi_irq(struct pci_dev *pdev, struct msi_desc *desc)\r\n{\r\nstruct msi_msg msg;\r\nunsigned long dest_phys_id;\r\nint irq, vector;\r\ncpumask_t mask;\r\nirq = create_irq();\r\nif (irq < 0)\r\nreturn irq;\r\nirq_set_msi_desc(irq, desc);\r\ncpumask_and(&mask, &(irq_to_domain(irq)), cpu_online_mask);\r\ndest_phys_id = cpu_physical_id(first_cpu(mask));\r\nvector = irq_to_vector(irq);\r\nmsg.address_hi = 0;\r\nmsg.address_lo =\r\nMSI_ADDR_HEADER |\r\nMSI_ADDR_DEST_MODE_PHYS |\r\nMSI_ADDR_REDIRECTION_CPU |\r\nMSI_ADDR_DEST_ID_CPU(dest_phys_id);\r\nmsg.data =\r\nMSI_DATA_TRIGGER_EDGE |\r\nMSI_DATA_LEVEL_ASSERT |\r\nMSI_DATA_DELIVERY_FIXED |\r\nMSI_DATA_VECTOR(vector);\r\nwrite_msi_msg(irq, &msg);\r\nirq_set_chip_and_handler(irq, &ia64_msi_chip, handle_edge_irq);\r\nreturn 0;\r\n}\r\nvoid ia64_teardown_msi_irq(unsigned int irq)\r\n{\r\ndestroy_irq(irq);\r\n}\r\nstatic void ia64_ack_msi_irq(struct irq_data *data)\r\n{\r\nirq_complete_move(data->irq);\r\nirq_move_irq(data);\r\nia64_eoi();\r\n}\r\nstatic int ia64_msi_retrigger_irq(struct irq_data *data)\r\n{\r\nunsigned int vector = irq_to_vector(data->irq);\r\nia64_resend_irq(vector);\r\nreturn 1;\r\n}\r\nint arch_setup_msi_irq(struct pci_dev *pdev, struct msi_desc *desc)\r\n{\r\nif (platform_setup_msi_irq)\r\nreturn platform_setup_msi_irq(pdev, desc);\r\nreturn ia64_setup_msi_irq(pdev, desc);\r\n}\r\nvoid arch_teardown_msi_irq(unsigned int irq)\r\n{\r\nif (platform_teardown_msi_irq)\r\nreturn platform_teardown_msi_irq(irq);\r\nreturn ia64_teardown_msi_irq(irq);\r\n}\r\nstatic int dmar_msi_set_affinity(struct irq_data *data,\r\nconst struct cpumask *mask, bool force)\r\n{\r\nunsigned int irq = data->irq;\r\nstruct irq_cfg *cfg = irq_cfg + irq;\r\nstruct msi_msg msg;\r\nint cpu = cpumask_first(mask);\r\nif (!cpu_online(cpu))\r\nreturn -1;\r\nif (irq_prepare_move(irq, cpu))\r\nreturn -1;\r\ndmar_msi_read(irq, &msg);\r\nmsg.data &= ~MSI_DATA_VECTOR_MASK;\r\nmsg.data |= MSI_DATA_VECTOR(cfg->vector);\r\nmsg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;\r\nmsg.address_lo |= MSI_ADDR_DEST_ID_CPU(cpu_physical_id(cpu));\r\ndmar_msi_write(irq, &msg);\r\ncpumask_copy(data->affinity, mask);\r\nreturn 0;\r\n}\r\nstatic int\r\nmsi_compose_msg(struct pci_dev *pdev, unsigned int irq, struct msi_msg *msg)\r\n{\r\nstruct irq_cfg *cfg = irq_cfg + irq;\r\nunsigned dest;\r\ncpumask_t mask;\r\ncpumask_and(&mask, &(irq_to_domain(irq)), cpu_online_mask);\r\ndest = cpu_physical_id(first_cpu(mask));\r\nmsg->address_hi = 0;\r\nmsg->address_lo =\r\nMSI_ADDR_HEADER |\r\nMSI_ADDR_DEST_MODE_PHYS |\r\nMSI_ADDR_REDIRECTION_CPU |\r\nMSI_ADDR_DEST_ID_CPU(dest);\r\nmsg->data =\r\nMSI_DATA_TRIGGER_EDGE |\r\nMSI_DATA_LEVEL_ASSERT |\r\nMSI_DATA_DELIVERY_FIXED |\r\nMSI_DATA_VECTOR(cfg->vector);\r\nreturn 0;\r\n}\r\nint arch_setup_dmar_msi(unsigned int irq)\r\n{\r\nint ret;\r\nstruct msi_msg msg;\r\nret = msi_compose_msg(NULL, irq, &msg);\r\nif (ret < 0)\r\nreturn ret;\r\ndmar_msi_write(irq, &msg);\r\nirq_set_chip_and_handler_name(irq, &dmar_msi_type, handle_edge_irq,\r\n"edge");\r\nreturn 0;\r\n}
