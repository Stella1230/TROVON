static inline void *octeon_get_dispatch_arg(struct octeon_device *octeon_dev,\r\nu16 opcode, u16 subcode)\r\n{\r\nint idx;\r\nstruct list_head *dispatch;\r\nvoid *fn_arg = NULL;\r\nu16 combined_opcode = OPCODE_SUBCODE(opcode, subcode);\r\nidx = combined_opcode & OCTEON_OPCODE_MASK;\r\nspin_lock_bh(&octeon_dev->dispatch.lock);\r\nif (octeon_dev->dispatch.count == 0) {\r\nspin_unlock_bh(&octeon_dev->dispatch.lock);\r\nreturn NULL;\r\n}\r\nif (octeon_dev->dispatch.dlist[idx].opcode == combined_opcode) {\r\nfn_arg = octeon_dev->dispatch.dlist[idx].arg;\r\n} else {\r\nlist_for_each(dispatch,\r\n&octeon_dev->dispatch.dlist[idx].list) {\r\nif (((struct octeon_dispatch *)dispatch)->opcode ==\r\ncombined_opcode) {\r\nfn_arg = ((struct octeon_dispatch *)\r\ndispatch)->arg;\r\nbreak;\r\n}\r\n}\r\n}\r\nspin_unlock_bh(&octeon_dev->dispatch.lock);\r\nreturn fn_arg;\r\n}\r\nu32 octeon_droq_check_hw_for_pkts(struct octeon_device *oct,\r\nstruct octeon_droq *droq)\r\n{\r\nu32 pkt_count = 0;\r\npkt_count = readl(droq->pkts_sent_reg);\r\nif (pkt_count) {\r\natomic_add(pkt_count, &droq->pkts_pending);\r\nwritel(pkt_count, droq->pkts_sent_reg);\r\n}\r\nreturn pkt_count;\r\n}\r\nstatic void octeon_droq_compute_max_packet_bufs(struct octeon_droq *droq)\r\n{\r\nu32 count = 0;\r\ndroq->max_empty_descs = 0;\r\ndo {\r\ndroq->max_empty_descs++;\r\ncount += droq->buffer_size;\r\n} while (count < (64 * 1024));\r\ndroq->max_empty_descs = droq->max_count - droq->max_empty_descs;\r\n}\r\nstatic void octeon_droq_reset_indices(struct octeon_droq *droq)\r\n{\r\ndroq->read_idx = 0;\r\ndroq->write_idx = 0;\r\ndroq->refill_idx = 0;\r\ndroq->refill_count = 0;\r\natomic_set(&droq->pkts_pending, 0);\r\n}\r\nstatic void\r\nocteon_droq_destroy_ring_buffers(struct octeon_device *oct,\r\nstruct octeon_droq *droq)\r\n{\r\nu32 i;\r\nfor (i = 0; i < droq->max_count; i++) {\r\nif (droq->recv_buf_list[i].buffer) {\r\nif (droq->desc_ring) {\r\nlio_unmap_ring_info(oct->pci_dev,\r\n(u64)droq->\r\ndesc_ring[i].info_ptr,\r\nOCT_DROQ_INFO_SIZE);\r\nlio_unmap_ring(oct->pci_dev,\r\n(u64)droq->desc_ring[i].\r\nbuffer_ptr,\r\ndroq->buffer_size);\r\n}\r\nrecv_buffer_free(droq->recv_buf_list[i].buffer);\r\ndroq->recv_buf_list[i].buffer = NULL;\r\n}\r\n}\r\nocteon_droq_reset_indices(droq);\r\n}\r\nstatic int\r\nocteon_droq_setup_ring_buffers(struct octeon_device *oct,\r\nstruct octeon_droq *droq)\r\n{\r\nu32 i;\r\nvoid *buf;\r\nstruct octeon_droq_desc *desc_ring = droq->desc_ring;\r\nfor (i = 0; i < droq->max_count; i++) {\r\nbuf = recv_buffer_alloc(oct, droq->q_no, droq->buffer_size);\r\nif (!buf) {\r\ndev_err(&oct->pci_dev->dev, "%s buffer alloc failed\n",\r\n__func__);\r\nreturn -ENOMEM;\r\n}\r\ndroq->recv_buf_list[i].buffer = buf;\r\ndroq->recv_buf_list[i].data = get_rbd(buf);\r\ndroq->info_list[i].length = 0;\r\ndesc_ring[i].info_ptr = lio_map_ring_info(droq, i);\r\ndesc_ring[i].buffer_ptr =\r\nlio_map_ring(oct->pci_dev,\r\ndroq->recv_buf_list[i].buffer,\r\ndroq->buffer_size);\r\n}\r\nocteon_droq_reset_indices(droq);\r\nocteon_droq_compute_max_packet_bufs(droq);\r\nreturn 0;\r\n}\r\nint octeon_delete_droq(struct octeon_device *oct, u32 q_no)\r\n{\r\nstruct octeon_droq *droq = oct->droq[q_no];\r\ndev_dbg(&oct->pci_dev->dev, "%s[%d]\n", __func__, q_no);\r\nocteon_droq_destroy_ring_buffers(oct, droq);\r\nvfree(droq->recv_buf_list);\r\nif (droq->info_base_addr)\r\ncnnic_free_aligned_dma(oct->pci_dev, droq->info_list,\r\ndroq->info_alloc_size,\r\ndroq->info_base_addr,\r\ndroq->info_list_dma);\r\nif (droq->desc_ring)\r\nlio_dma_free(oct, (droq->max_count * OCT_DROQ_DESC_SIZE),\r\ndroq->desc_ring, droq->desc_ring_dma);\r\nmemset(droq, 0, OCT_DROQ_SIZE);\r\nreturn 0;\r\n}\r\nint octeon_init_droq(struct octeon_device *oct,\r\nu32 q_no,\r\nu32 num_descs,\r\nu32 desc_size,\r\nvoid *app_ctx)\r\n{\r\nstruct octeon_droq *droq;\r\nu32 desc_ring_size = 0, c_num_descs = 0, c_buf_size = 0;\r\nu32 c_pkts_per_intr = 0, c_refill_threshold = 0;\r\ndev_dbg(&oct->pci_dev->dev, "%s[%d]\n", __func__, q_no);\r\ndroq = oct->droq[q_no];\r\nmemset(droq, 0, OCT_DROQ_SIZE);\r\ndroq->oct_dev = oct;\r\ndroq->q_no = q_no;\r\nif (app_ctx)\r\ndroq->app_ctx = app_ctx;\r\nelse\r\ndroq->app_ctx = (void *)(size_t)q_no;\r\nc_num_descs = num_descs;\r\nc_buf_size = desc_size;\r\nif (OCTEON_CN6XXX(oct)) {\r\nstruct octeon_config *conf6x = CHIP_FIELD(oct, cn6xxx, conf);\r\nc_pkts_per_intr = (u32)CFG_GET_OQ_PKTS_PER_INTR(conf6x);\r\nc_refill_threshold = (u32)CFG_GET_OQ_REFILL_THRESHOLD(conf6x);\r\n}\r\ndroq->max_count = c_num_descs;\r\ndroq->buffer_size = c_buf_size;\r\ndesc_ring_size = droq->max_count * OCT_DROQ_DESC_SIZE;\r\ndroq->desc_ring = lio_dma_alloc(oct, desc_ring_size,\r\n(dma_addr_t *)&droq->desc_ring_dma);\r\nif (!droq->desc_ring) {\r\ndev_err(&oct->pci_dev->dev,\r\n"Output queue %d ring alloc failed\n", q_no);\r\nreturn 1;\r\n}\r\ndev_dbg(&oct->pci_dev->dev, "droq[%d]: desc_ring: virt: 0x%p, dma: %lx\n",\r\nq_no, droq->desc_ring, droq->desc_ring_dma);\r\ndev_dbg(&oct->pci_dev->dev, "droq[%d]: num_desc: %d\n", q_no,\r\ndroq->max_count);\r\ndroq->info_list =\r\ncnnic_alloc_aligned_dma(oct->pci_dev,\r\n(droq->max_count * OCT_DROQ_INFO_SIZE),\r\n&droq->info_alloc_size,\r\n&droq->info_base_addr,\r\n&droq->info_list_dma);\r\nif (!droq->info_list) {\r\ndev_err(&oct->pci_dev->dev, "Cannot allocate memory for info list.\n");\r\nlio_dma_free(oct, (droq->max_count * OCT_DROQ_DESC_SIZE),\r\ndroq->desc_ring, droq->desc_ring_dma);\r\nreturn 1;\r\n}\r\ndroq->recv_buf_list = (struct octeon_recv_buffer *)\r\nvmalloc(droq->max_count *\r\nOCT_DROQ_RECVBUF_SIZE);\r\nif (!droq->recv_buf_list) {\r\ndev_err(&oct->pci_dev->dev, "Output queue recv buf list alloc failed\n");\r\ngoto init_droq_fail;\r\n}\r\nif (octeon_droq_setup_ring_buffers(oct, droq))\r\ngoto init_droq_fail;\r\ndroq->pkts_per_intr = c_pkts_per_intr;\r\ndroq->refill_threshold = c_refill_threshold;\r\ndev_dbg(&oct->pci_dev->dev, "DROQ INIT: max_empty_descs: %d\n",\r\ndroq->max_empty_descs);\r\nspin_lock_init(&droq->lock);\r\nINIT_LIST_HEAD(&droq->dispatch_list);\r\noct->fn_list.setup_oq_regs(oct, q_no);\r\noct->io_qmask.oq |= (1 << q_no);\r\nreturn 0;\r\ninit_droq_fail:\r\nocteon_delete_droq(oct, q_no);\r\nreturn 1;\r\n}\r\nstatic inline struct octeon_recv_info *octeon_create_recv_info(\r\nstruct octeon_device *octeon_dev,\r\nstruct octeon_droq *droq,\r\nu32 buf_cnt,\r\nu32 idx)\r\n{\r\nstruct octeon_droq_info *info;\r\nstruct octeon_recv_pkt *recv_pkt;\r\nstruct octeon_recv_info *recv_info;\r\nu32 i, bytes_left;\r\ninfo = &droq->info_list[idx];\r\nrecv_info = octeon_alloc_recv_info(sizeof(struct __dispatch));\r\nif (!recv_info)\r\nreturn NULL;\r\nrecv_pkt = recv_info->recv_pkt;\r\nrecv_pkt->rh = info->rh;\r\nrecv_pkt->length = (u32)info->length;\r\nrecv_pkt->buffer_count = (u16)buf_cnt;\r\nrecv_pkt->octeon_id = (u16)octeon_dev->octeon_id;\r\ni = 0;\r\nbytes_left = (u32)info->length;\r\nwhile (buf_cnt) {\r\nlio_unmap_ring(octeon_dev->pci_dev,\r\n(u64)droq->desc_ring[idx].buffer_ptr,\r\ndroq->buffer_size);\r\nrecv_pkt->buffer_size[i] =\r\n(bytes_left >=\r\ndroq->buffer_size) ? droq->buffer_size : bytes_left;\r\nrecv_pkt->buffer_ptr[i] = droq->recv_buf_list[idx].buffer;\r\ndroq->recv_buf_list[idx].buffer = NULL;\r\nINCR_INDEX_BY1(idx, droq->max_count);\r\nbytes_left -= droq->buffer_size;\r\ni++;\r\nbuf_cnt--;\r\n}\r\nreturn recv_info;\r\n}\r\nstatic inline u32\r\nocteon_droq_refill_pullup_descs(struct octeon_droq *droq,\r\nstruct octeon_droq_desc *desc_ring)\r\n{\r\nu32 desc_refilled = 0;\r\nu32 refill_index = droq->refill_idx;\r\nwhile (refill_index != droq->read_idx) {\r\nif (droq->recv_buf_list[refill_index].buffer) {\r\ndroq->recv_buf_list[droq->refill_idx].buffer =\r\ndroq->recv_buf_list[refill_index].buffer;\r\ndroq->recv_buf_list[droq->refill_idx].data =\r\ndroq->recv_buf_list[refill_index].data;\r\ndesc_ring[droq->refill_idx].buffer_ptr =\r\ndesc_ring[refill_index].buffer_ptr;\r\ndroq->recv_buf_list[refill_index].buffer = NULL;\r\ndesc_ring[refill_index].buffer_ptr = 0;\r\ndo {\r\nINCR_INDEX_BY1(droq->refill_idx,\r\ndroq->max_count);\r\ndesc_refilled++;\r\ndroq->refill_count--;\r\n} while (droq->recv_buf_list[droq->refill_idx].\r\nbuffer);\r\n}\r\nINCR_INDEX_BY1(refill_index, droq->max_count);\r\n}\r\nreturn desc_refilled;\r\n}\r\nstatic u32\r\nocteon_droq_refill(struct octeon_device *octeon_dev, struct octeon_droq *droq)\r\n{\r\nstruct octeon_droq_desc *desc_ring;\r\nvoid *buf = NULL;\r\nu8 *data;\r\nu32 desc_refilled = 0;\r\ndesc_ring = droq->desc_ring;\r\nwhile (droq->refill_count && (desc_refilled < droq->max_count)) {\r\nif (!droq->recv_buf_list[droq->refill_idx].buffer) {\r\nbuf = recv_buffer_alloc(octeon_dev, droq->q_no,\r\ndroq->buffer_size);\r\nif (!buf)\r\nbreak;\r\ndroq->recv_buf_list[droq->refill_idx].buffer =\r\nbuf;\r\ndata = get_rbd(buf);\r\n} else {\r\ndata = get_rbd(droq->recv_buf_list\r\n[droq->refill_idx].buffer);\r\n}\r\ndroq->recv_buf_list[droq->refill_idx].data = data;\r\ndesc_ring[droq->refill_idx].buffer_ptr =\r\nlio_map_ring(octeon_dev->pci_dev,\r\ndroq->recv_buf_list[droq->\r\nrefill_idx].buffer,\r\ndroq->buffer_size);\r\ndroq->info_list[droq->refill_idx].length = 0;\r\nINCR_INDEX_BY1(droq->refill_idx, droq->max_count);\r\ndesc_refilled++;\r\ndroq->refill_count--;\r\n}\r\nif (droq->refill_count)\r\ndesc_refilled +=\r\nocteon_droq_refill_pullup_descs(droq, desc_ring);\r\nreturn desc_refilled;\r\n}\r\nstatic inline u32\r\nocteon_droq_get_bufcount(u32 buf_size, u32 total_len)\r\n{\r\nu32 buf_cnt = 0;\r\nwhile (total_len > (buf_size * buf_cnt))\r\nbuf_cnt++;\r\nreturn buf_cnt;\r\n}\r\nstatic int\r\nocteon_droq_dispatch_pkt(struct octeon_device *oct,\r\nstruct octeon_droq *droq,\r\nunion octeon_rh *rh,\r\nstruct octeon_droq_info *info)\r\n{\r\nu32 cnt;\r\nocteon_dispatch_fn_t disp_fn;\r\nstruct octeon_recv_info *rinfo;\r\ncnt = octeon_droq_get_bufcount(droq->buffer_size, (u32)info->length);\r\ndisp_fn = octeon_get_dispatch(oct, (u16)rh->r.opcode,\r\n(u16)rh->r.subcode);\r\nif (disp_fn) {\r\nrinfo = octeon_create_recv_info(oct, droq, cnt, droq->read_idx);\r\nif (rinfo) {\r\nstruct __dispatch *rdisp = rinfo->rsvd;\r\nrdisp->rinfo = rinfo;\r\nrdisp->disp_fn = disp_fn;\r\nrinfo->recv_pkt->rh = *rh;\r\nlist_add_tail(&rdisp->list,\r\n&droq->dispatch_list);\r\n} else {\r\ndroq->stats.dropped_nomem++;\r\n}\r\n} else {\r\ndev_err(&oct->pci_dev->dev, "DROQ: No dispatch function\n");\r\ndroq->stats.dropped_nodispatch++;\r\n}\r\nreturn cnt;\r\n}\r\nstatic inline void octeon_droq_drop_packets(struct octeon_device *oct,\r\nstruct octeon_droq *droq,\r\nu32 cnt)\r\n{\r\nu32 i = 0, buf_cnt;\r\nstruct octeon_droq_info *info;\r\nfor (i = 0; i < cnt; i++) {\r\ninfo = &droq->info_list[droq->read_idx];\r\nocteon_swap_8B_data((u64 *)info, 2);\r\nif (info->length) {\r\ninfo->length -= OCT_RH_SIZE;\r\ndroq->stats.bytes_received += info->length;\r\nbuf_cnt = octeon_droq_get_bufcount(droq->buffer_size,\r\n(u32)info->length);\r\n} else {\r\ndev_err(&oct->pci_dev->dev, "DROQ: In drop: pkt with len 0\n");\r\nbuf_cnt = 1;\r\n}\r\nINCR_INDEX(droq->read_idx, buf_cnt, droq->max_count);\r\ndroq->refill_count += buf_cnt;\r\n}\r\n}\r\nstatic u32\r\nocteon_droq_fast_process_packets(struct octeon_device *oct,\r\nstruct octeon_droq *droq,\r\nu32 pkts_to_process)\r\n{\r\nstruct octeon_droq_info *info;\r\nunion octeon_rh *rh;\r\nu32 pkt, total_len = 0, pkt_count;\r\npkt_count = pkts_to_process;\r\nfor (pkt = 0; pkt < pkt_count; pkt++) {\r\nu32 pkt_len = 0;\r\nstruct sk_buff *nicbuf = NULL;\r\ninfo = &droq->info_list[droq->read_idx];\r\nocteon_swap_8B_data((u64 *)info, 2);\r\nif (!info->length) {\r\ndev_err(&oct->pci_dev->dev,\r\n"DROQ[%d] idx: %d len:0, pkt_cnt: %d\n",\r\ndroq->q_no, droq->read_idx, pkt_count);\r\nprint_hex_dump_bytes("", DUMP_PREFIX_ADDRESS,\r\n(u8 *)info,\r\nOCT_DROQ_INFO_SIZE);\r\nbreak;\r\n}\r\ninfo->length -= OCT_RH_SIZE;\r\nrh = &info->rh;\r\ntotal_len += (u32)info->length;\r\nif (OPCODE_SLOW_PATH(rh)) {\r\nu32 buf_cnt;\r\nbuf_cnt = octeon_droq_dispatch_pkt(oct, droq, rh, info);\r\nINCR_INDEX(droq->read_idx, buf_cnt, droq->max_count);\r\ndroq->refill_count += buf_cnt;\r\n} else {\r\nif (info->length <= droq->buffer_size) {\r\nlio_unmap_ring(oct->pci_dev,\r\n(u64)droq->desc_ring[\r\ndroq->read_idx].buffer_ptr,\r\ndroq->buffer_size);\r\npkt_len = (u32)info->length;\r\nnicbuf = droq->recv_buf_list[\r\ndroq->read_idx].buffer;\r\ndroq->recv_buf_list[droq->read_idx].buffer =\r\nNULL;\r\nINCR_INDEX_BY1(droq->read_idx, droq->max_count);\r\nskb_put(nicbuf, pkt_len);\r\ndroq->refill_count++;\r\n} else {\r\nnicbuf = octeon_fast_packet_alloc(oct, droq,\r\ndroq->q_no,\r\n(u32)\r\ninfo->length);\r\npkt_len = 0;\r\nwhile (pkt_len < info->length) {\r\nint cpy_len;\r\ncpy_len = ((pkt_len +\r\ndroq->buffer_size) >\r\ninfo->length) ?\r\n((u32)info->length - pkt_len) :\r\ndroq->buffer_size;\r\nif (nicbuf) {\r\nlio_unmap_ring(oct->pci_dev,\r\n(u64)\r\ndroq->desc_ring\r\n[droq->read_idx].\r\nbuffer_ptr,\r\ndroq->\r\nbuffer_size);\r\nocteon_fast_packet_next(droq,\r\nnicbuf,\r\ncpy_len,\r\ndroq->\r\nread_idx\r\n);\r\n}\r\npkt_len += cpy_len;\r\nINCR_INDEX_BY1(droq->read_idx,\r\ndroq->max_count);\r\ndroq->refill_count++;\r\n}\r\n}\r\nif (nicbuf) {\r\nif (droq->ops.fptr)\r\ndroq->ops.fptr(oct->octeon_id,\r\nnicbuf, pkt_len,\r\nrh, &droq->napi);\r\nelse\r\nrecv_buffer_free(nicbuf);\r\n}\r\n}\r\nif (droq->refill_count >= droq->refill_threshold) {\r\nint desc_refilled = octeon_droq_refill(oct, droq);\r\nwmb();\r\nwritel((desc_refilled), droq->pkts_credit_reg);\r\nmmiowb();\r\n}\r\n}\r\ndroq->stats.pkts_received += pkt;\r\ndroq->stats.bytes_received += total_len;\r\nif ((droq->ops.drop_on_max) && (pkts_to_process - pkt)) {\r\nocteon_droq_drop_packets(oct, droq, (pkts_to_process - pkt));\r\ndroq->stats.dropped_toomany += (pkts_to_process - pkt);\r\nreturn pkts_to_process;\r\n}\r\nreturn pkt;\r\n}\r\nint\r\nocteon_droq_process_packets(struct octeon_device *oct,\r\nstruct octeon_droq *droq,\r\nu32 budget)\r\n{\r\nu32 pkt_count = 0, pkts_processed = 0;\r\nstruct list_head *tmp, *tmp2;\r\npkt_count = atomic_read(&droq->pkts_pending);\r\nif (!pkt_count)\r\nreturn 0;\r\nif (pkt_count > budget)\r\npkt_count = budget;\r\nspin_lock(&droq->lock);\r\npkts_processed = octeon_droq_fast_process_packets(oct, droq, pkt_count);\r\natomic_sub(pkts_processed, &droq->pkts_pending);\r\nspin_unlock(&droq->lock);\r\nlist_for_each_safe(tmp, tmp2, &droq->dispatch_list) {\r\nstruct __dispatch *rdisp = (struct __dispatch *)tmp;\r\nlist_del(tmp);\r\nrdisp->disp_fn(rdisp->rinfo,\r\nocteon_get_dispatch_arg\r\n(oct,\r\n(u16)rdisp->rinfo->recv_pkt->rh.r.opcode,\r\n(u16)rdisp->rinfo->recv_pkt->rh.r.subcode));\r\n}\r\nif (atomic_read(&droq->pkts_pending))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int\r\nocteon_droq_process_poll_pkts(struct octeon_device *oct,\r\nstruct octeon_droq *droq, u32 budget)\r\n{\r\nstruct list_head *tmp, *tmp2;\r\nu32 pkts_available = 0, pkts_processed = 0;\r\nu32 total_pkts_processed = 0;\r\nif (budget > droq->max_count)\r\nbudget = droq->max_count;\r\nspin_lock(&droq->lock);\r\nwhile (total_pkts_processed < budget) {\r\npkts_available =\r\nCVM_MIN((budget - total_pkts_processed),\r\n(u32)(atomic_read(&droq->pkts_pending)));\r\nif (pkts_available == 0)\r\nbreak;\r\npkts_processed =\r\nocteon_droq_fast_process_packets(oct, droq,\r\npkts_available);\r\natomic_sub(pkts_processed, &droq->pkts_pending);\r\ntotal_pkts_processed += pkts_processed;\r\nocteon_droq_check_hw_for_pkts(oct, droq);\r\n}\r\nspin_unlock(&droq->lock);\r\nlist_for_each_safe(tmp, tmp2, &droq->dispatch_list) {\r\nstruct __dispatch *rdisp = (struct __dispatch *)tmp;\r\nlist_del(tmp);\r\nrdisp->disp_fn(rdisp->rinfo,\r\nocteon_get_dispatch_arg\r\n(oct,\r\n(u16)rdisp->rinfo->recv_pkt->rh.r.opcode,\r\n(u16)rdisp->rinfo->recv_pkt->rh.r.subcode));\r\n}\r\nreturn total_pkts_processed;\r\n}\r\nint\r\nocteon_process_droq_poll_cmd(struct octeon_device *oct, u32 q_no, int cmd,\r\nu32 arg)\r\n{\r\nstruct octeon_droq *droq;\r\nstruct octeon_config *oct_cfg = NULL;\r\noct_cfg = octeon_get_conf(oct);\r\nif (!oct_cfg)\r\nreturn -EINVAL;\r\nif (q_no >= CFG_GET_OQ_MAX_Q(oct_cfg)) {\r\ndev_err(&oct->pci_dev->dev, "%s: droq id (%d) exceeds MAX (%d)\n",\r\n__func__, q_no, (oct->num_oqs - 1));\r\nreturn -EINVAL;\r\n}\r\ndroq = oct->droq[q_no];\r\nif (cmd == POLL_EVENT_PROCESS_PKTS)\r\nreturn octeon_droq_process_poll_pkts(oct, droq, arg);\r\nif (cmd == POLL_EVENT_PENDING_PKTS) {\r\nu32 pkt_cnt = atomic_read(&droq->pkts_pending);\r\nreturn octeon_droq_process_packets(oct, droq, pkt_cnt);\r\n}\r\nif (cmd == POLL_EVENT_ENABLE_INTR) {\r\nu32 value;\r\nunsigned long flags;\r\nswitch (oct->chip_id) {\r\ncase OCTEON_CN66XX:\r\ncase OCTEON_CN68XX: {\r\nstruct octeon_cn6xxx *cn6xxx =\r\n(struct octeon_cn6xxx *)oct->chip;\r\nspin_lock_irqsave\r\n(&cn6xxx->lock_for_droq_int_enb_reg, flags);\r\nvalue =\r\nocteon_read_csr(oct,\r\nCN6XXX_SLI_PKT_TIME_INT_ENB);\r\nvalue |= (1 << q_no);\r\nocteon_write_csr(oct,\r\nCN6XXX_SLI_PKT_TIME_INT_ENB,\r\nvalue);\r\nvalue =\r\nocteon_read_csr(oct,\r\nCN6XXX_SLI_PKT_CNT_INT_ENB);\r\nvalue |= (1 << q_no);\r\nocteon_write_csr(oct,\r\nCN6XXX_SLI_PKT_CNT_INT_ENB,\r\nvalue);\r\nspin_unlock_irqrestore\r\n(&cn6xxx->lock_for_droq_int_enb_reg, flags);\r\nreturn 0;\r\n}\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\ndev_err(&oct->pci_dev->dev, "%s Unknown command: %d\n", __func__, cmd);\r\nreturn -EINVAL;\r\n}\r\nint octeon_register_droq_ops(struct octeon_device *oct, u32 q_no,\r\nstruct octeon_droq_ops *ops)\r\n{\r\nstruct octeon_droq *droq;\r\nunsigned long flags;\r\nstruct octeon_config *oct_cfg = NULL;\r\noct_cfg = octeon_get_conf(oct);\r\nif (!oct_cfg)\r\nreturn -EINVAL;\r\nif (!(ops)) {\r\ndev_err(&oct->pci_dev->dev, "%s: droq_ops pointer is NULL\n",\r\n__func__);\r\nreturn -EINVAL;\r\n}\r\nif (q_no >= CFG_GET_OQ_MAX_Q(oct_cfg)) {\r\ndev_err(&oct->pci_dev->dev, "%s: droq id (%d) exceeds MAX (%d)\n",\r\n__func__, q_no, (oct->num_oqs - 1));\r\nreturn -EINVAL;\r\n}\r\ndroq = oct->droq[q_no];\r\nspin_lock_irqsave(&droq->lock, flags);\r\nmemcpy(&droq->ops, ops, sizeof(struct octeon_droq_ops));\r\nspin_unlock_irqrestore(&droq->lock, flags);\r\nreturn 0;\r\n}\r\nint octeon_unregister_droq_ops(struct octeon_device *oct, u32 q_no)\r\n{\r\nunsigned long flags;\r\nstruct octeon_droq *droq;\r\nstruct octeon_config *oct_cfg = NULL;\r\noct_cfg = octeon_get_conf(oct);\r\nif (!oct_cfg)\r\nreturn -EINVAL;\r\nif (q_no >= CFG_GET_OQ_MAX_Q(oct_cfg)) {\r\ndev_err(&oct->pci_dev->dev, "%s: droq id (%d) exceeds MAX (%d)\n",\r\n__func__, q_no, oct->num_oqs - 1);\r\nreturn -EINVAL;\r\n}\r\ndroq = oct->droq[q_no];\r\nif (!droq) {\r\ndev_info(&oct->pci_dev->dev,\r\n"Droq id (%d) not available.\n", q_no);\r\nreturn 0;\r\n}\r\nspin_lock_irqsave(&droq->lock, flags);\r\ndroq->ops.fptr = NULL;\r\ndroq->ops.drop_on_max = 0;\r\nspin_unlock_irqrestore(&droq->lock, flags);\r\nreturn 0;\r\n}\r\nint octeon_create_droq(struct octeon_device *oct,\r\nu32 q_no, u32 num_descs,\r\nu32 desc_size, void *app_ctx)\r\n{\r\nstruct octeon_droq *droq;\r\nif (oct->droq[q_no]) {\r\ndev_dbg(&oct->pci_dev->dev, "Droq already in use. Cannot create droq %d again\n",\r\nq_no);\r\nreturn 1;\r\n}\r\ndroq = vmalloc(sizeof(*droq));\r\nif (!droq)\r\ngoto create_droq_fail;\r\nmemset(droq, 0, sizeof(struct octeon_droq));\r\nocteon_set_droq_pkt_op(oct, q_no, 0);\r\noct->droq[q_no] = droq;\r\nocteon_init_droq(oct, q_no, num_descs, desc_size, app_ctx);\r\noct->num_oqs++;\r\ndev_dbg(&oct->pci_dev->dev, "%s: Total number of OQ: %d\n", __func__,\r\noct->num_oqs);\r\nreturn 0;\r\ncreate_droq_fail:\r\nocteon_delete_droq(oct, q_no);\r\nreturn -1;\r\n}
