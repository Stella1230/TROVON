static int eeprom_wait_ready(struct pci_dev *pdev, u32 *status)\r\n{\r\nu32 reg;\r\nint i;\r\nfor (i = 0; i < MAX_NUM_REGISTER_POLLS; i++) {\r\nif (pci_read_config_dword(pdev, LBCIF_DWORD1_GROUP, &reg))\r\nreturn -EIO;\r\nif ((reg & 0x3000) == 0x3000) {\r\nif (status)\r\n*status = reg;\r\nreturn reg & 0xFF;\r\n}\r\n}\r\nreturn -ETIMEDOUT;\r\n}\r\nstatic int eeprom_write(struct et131x_adapter *adapter, u32 addr, u8 data)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint index = 0;\r\nint retries;\r\nint err = 0;\r\nint writeok = 0;\r\nu32 status;\r\nu32 val = 0;\r\nerr = eeprom_wait_ready(pdev, NULL);\r\nif (err < 0)\r\nreturn err;\r\nif (pci_write_config_byte(pdev, LBCIF_CONTROL_REGISTER,\r\nLBCIF_CONTROL_LBCIF_ENABLE |\r\nLBCIF_CONTROL_I2C_WRITE))\r\nreturn -EIO;\r\nfor (retries = 0; retries < MAX_NUM_WRITE_RETRIES; retries++) {\r\nif (pci_write_config_dword(pdev, LBCIF_ADDRESS_REGISTER, addr))\r\nbreak;\r\nif (pci_write_config_byte(pdev, LBCIF_DATA_REGISTER, data))\r\nbreak;\r\nerr = eeprom_wait_ready(pdev, &status);\r\nif (err < 0)\r\nreturn 0;\r\nif ((status & LBCIF_STATUS_GENERAL_ERROR) &&\r\nadapter->pdev->revision == 0)\r\nbreak;\r\nif (status & LBCIF_STATUS_ACK_ERROR) {\r\nudelay(10);\r\ncontinue;\r\n}\r\nwriteok = 1;\r\nbreak;\r\n}\r\nudelay(10);\r\nwhile (1) {\r\nif (pci_write_config_byte(pdev, LBCIF_CONTROL_REGISTER,\r\nLBCIF_CONTROL_LBCIF_ENABLE))\r\nwriteok = 0;\r\ndo {\r\npci_write_config_dword(pdev,\r\nLBCIF_ADDRESS_REGISTER,\r\naddr);\r\ndo {\r\npci_read_config_dword(pdev,\r\nLBCIF_DATA_REGISTER,\r\n&val);\r\n} while ((val & 0x00010000) == 0);\r\n} while (val & 0x00040000);\r\nif ((val & 0xFF00) != 0xC000 || index == 10000)\r\nbreak;\r\nindex++;\r\n}\r\nreturn writeok ? 0 : -EIO;\r\n}\r\nstatic int eeprom_read(struct et131x_adapter *adapter, u32 addr, u8 *pdata)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint err;\r\nu32 status;\r\nerr = eeprom_wait_ready(pdev, NULL);\r\nif (err < 0)\r\nreturn err;\r\nif (pci_write_config_byte(pdev, LBCIF_CONTROL_REGISTER,\r\nLBCIF_CONTROL_LBCIF_ENABLE))\r\nreturn -EIO;\r\nif (pci_write_config_dword(pdev, LBCIF_ADDRESS_REGISTER, addr))\r\nreturn -EIO;\r\nerr = eeprom_wait_ready(pdev, &status);\r\nif (err < 0)\r\nreturn err;\r\n*pdata = err;\r\nreturn (status & LBCIF_STATUS_ACK_ERROR) ? -EIO : 0;\r\n}\r\nstatic int et131x_init_eeprom(struct et131x_adapter *adapter)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nu8 eestatus;\r\npci_read_config_byte(pdev, ET1310_PCI_EEPROM_STATUS, &eestatus);\r\nif (pci_read_config_byte(pdev, ET1310_PCI_EEPROM_STATUS, &eestatus)) {\r\ndev_err(&pdev->dev,\r\n"Could not read PCI config space for EEPROM Status\n");\r\nreturn -EIO;\r\n}\r\nif (eestatus & 0x4C) {\r\nint write_failed = 0;\r\nif (pdev->revision == 0x01) {\r\nint i;\r\nstatic const u8 eedata[4] = { 0xFE, 0x13, 0x10, 0xFF };\r\nfor (i = 0; i < 3; i++)\r\nif (eeprom_write(adapter, i, eedata[i]) < 0)\r\nwrite_failed = 1;\r\n}\r\nif (pdev->revision != 0x01 || write_failed) {\r\ndev_err(&pdev->dev,\r\n"Fatal EEPROM Status Error - 0x%04x\n",\r\neestatus);\r\nadapter->has_eeprom = 0;\r\nreturn -EIO;\r\n}\r\n}\r\nadapter->has_eeprom = 1;\r\neeprom_read(adapter, 0x70, &adapter->eeprom_data[0]);\r\neeprom_read(adapter, 0x71, &adapter->eeprom_data[1]);\r\nif (adapter->eeprom_data[0] != 0xcd)\r\nadapter->eeprom_data[1] = 0x00;\r\nreturn 0;\r\n}\r\nstatic void et131x_rx_dma_enable(struct et131x_adapter *adapter)\r\n{\r\nu32 csr = ET_RXDMA_CSR_FBR1_ENABLE;\r\nstruct rx_ring *rx_ring = &adapter->rx_ring;\r\nif (rx_ring->fbr[1]->buffsize == 4096)\r\ncsr |= ET_RXDMA_CSR_FBR1_SIZE_LO;\r\nelse if (rx_ring->fbr[1]->buffsize == 8192)\r\ncsr |= ET_RXDMA_CSR_FBR1_SIZE_HI;\r\nelse if (rx_ring->fbr[1]->buffsize == 16384)\r\ncsr |= ET_RXDMA_CSR_FBR1_SIZE_LO | ET_RXDMA_CSR_FBR1_SIZE_HI;\r\ncsr |= ET_RXDMA_CSR_FBR0_ENABLE;\r\nif (rx_ring->fbr[0]->buffsize == 256)\r\ncsr |= ET_RXDMA_CSR_FBR0_SIZE_LO;\r\nelse if (rx_ring->fbr[0]->buffsize == 512)\r\ncsr |= ET_RXDMA_CSR_FBR0_SIZE_HI;\r\nelse if (rx_ring->fbr[0]->buffsize == 1024)\r\ncsr |= ET_RXDMA_CSR_FBR0_SIZE_LO | ET_RXDMA_CSR_FBR0_SIZE_HI;\r\nwritel(csr, &adapter->regs->rxdma.csr);\r\ncsr = readl(&adapter->regs->rxdma.csr);\r\nif (csr & ET_RXDMA_CSR_HALT_STATUS) {\r\nudelay(5);\r\ncsr = readl(&adapter->regs->rxdma.csr);\r\nif (csr & ET_RXDMA_CSR_HALT_STATUS) {\r\ndev_err(&adapter->pdev->dev,\r\n"RX Dma failed to exit halt state. CSR 0x%08x\n",\r\ncsr);\r\n}\r\n}\r\n}\r\nstatic void et131x_rx_dma_disable(struct et131x_adapter *adapter)\r\n{\r\nu32 csr;\r\nwritel(ET_RXDMA_CSR_HALT | ET_RXDMA_CSR_FBR1_ENABLE,\r\n&adapter->regs->rxdma.csr);\r\ncsr = readl(&adapter->regs->rxdma.csr);\r\nif (!(csr & ET_RXDMA_CSR_HALT_STATUS)) {\r\nudelay(5);\r\ncsr = readl(&adapter->regs->rxdma.csr);\r\nif (!(csr & ET_RXDMA_CSR_HALT_STATUS))\r\ndev_err(&adapter->pdev->dev,\r\n"RX Dma failed to enter halt state. CSR 0x%08x\n",\r\ncsr);\r\n}\r\n}\r\nstatic void et131x_tx_dma_enable(struct et131x_adapter *adapter)\r\n{\r\nwritel(ET_TXDMA_SNGL_EPKT | (PARM_DMA_CACHE_DEF << ET_TXDMA_CACHE_SHIFT),\r\n&adapter->regs->txdma.csr);\r\n}\r\nstatic inline void add_10bit(u32 *v, int n)\r\n{\r\n*v = INDEX10(*v + n) | (*v & ET_DMA10_WRAP);\r\n}\r\nstatic inline void add_12bit(u32 *v, int n)\r\n{\r\n*v = INDEX12(*v + n) | (*v & ET_DMA12_WRAP);\r\n}\r\nstatic void et1310_config_mac_regs1(struct et131x_adapter *adapter)\r\n{\r\nstruct mac_regs __iomem *macregs = &adapter->regs->mac;\r\nu32 station1;\r\nu32 station2;\r\nu32 ipg;\r\nwritel(ET_MAC_CFG1_SOFT_RESET | ET_MAC_CFG1_SIM_RESET |\r\nET_MAC_CFG1_RESET_RXMC | ET_MAC_CFG1_RESET_TXMC |\r\nET_MAC_CFG1_RESET_RXFUNC | ET_MAC_CFG1_RESET_TXFUNC,\r\n&macregs->cfg1);\r\nipg = 0x38005860;\r\nipg |= 0x50 << 8;\r\nwritel(ipg, &macregs->ipg);\r\nwritel(0x00A1F037, &macregs->hfdp);\r\nwritel(0, &macregs->if_ctrl);\r\nwritel(ET_MAC_MIIMGMT_CLK_RST, &macregs->mii_mgmt_cfg);\r\nstation2 = (adapter->addr[1] << ET_MAC_STATION_ADDR2_OC2_SHIFT) |\r\n(adapter->addr[0] << ET_MAC_STATION_ADDR2_OC1_SHIFT);\r\nstation1 = (adapter->addr[5] << ET_MAC_STATION_ADDR1_OC6_SHIFT) |\r\n(adapter->addr[4] << ET_MAC_STATION_ADDR1_OC5_SHIFT) |\r\n(adapter->addr[3] << ET_MAC_STATION_ADDR1_OC4_SHIFT) |\r\nadapter->addr[2];\r\nwritel(station1, &macregs->station_addr_1);\r\nwritel(station2, &macregs->station_addr_2);\r\nwritel(adapter->registry_jumbo_packet + 4, &macregs->max_fm_len);\r\nwritel(0, &macregs->cfg1);\r\n}\r\nstatic void et1310_config_mac_regs2(struct et131x_adapter *adapter)\r\n{\r\nint32_t delay = 0;\r\nstruct mac_regs __iomem *mac = &adapter->regs->mac;\r\nstruct phy_device *phydev = adapter->phydev;\r\nu32 cfg1;\r\nu32 cfg2;\r\nu32 ifctrl;\r\nu32 ctl;\r\nctl = readl(&adapter->regs->txmac.ctl);\r\ncfg1 = readl(&mac->cfg1);\r\ncfg2 = readl(&mac->cfg2);\r\nifctrl = readl(&mac->if_ctrl);\r\ncfg2 &= ~ET_MAC_CFG2_IFMODE_MASK;\r\nif (phydev->speed == SPEED_1000) {\r\ncfg2 |= ET_MAC_CFG2_IFMODE_1000;\r\nifctrl &= ~ET_MAC_IFCTRL_PHYMODE;\r\n} else {\r\ncfg2 |= ET_MAC_CFG2_IFMODE_100;\r\nifctrl |= ET_MAC_IFCTRL_PHYMODE;\r\n}\r\ncfg1 |= ET_MAC_CFG1_RX_ENABLE | ET_MAC_CFG1_TX_ENABLE |\r\nET_MAC_CFG1_TX_FLOW;\r\ncfg1 &= ~(ET_MAC_CFG1_LOOPBACK | ET_MAC_CFG1_RX_FLOW);\r\nif (adapter->flow == FLOW_RXONLY || adapter->flow == FLOW_BOTH)\r\ncfg1 |= ET_MAC_CFG1_RX_FLOW;\r\nwritel(cfg1, &mac->cfg1);\r\ncfg2 |= 0x7 << ET_MAC_CFG2_PREAMBLE_SHIFT;\r\ncfg2 |= ET_MAC_CFG2_IFMODE_LEN_CHECK;\r\ncfg2 |= ET_MAC_CFG2_IFMODE_PAD_CRC;\r\ncfg2 |= ET_MAC_CFG2_IFMODE_CRC_ENABLE;\r\ncfg2 &= ~ET_MAC_CFG2_IFMODE_HUGE_FRAME;\r\ncfg2 &= ~ET_MAC_CFG2_IFMODE_FULL_DPLX;\r\nif (phydev->duplex == DUPLEX_FULL)\r\ncfg2 |= ET_MAC_CFG2_IFMODE_FULL_DPLX;\r\nifctrl &= ~ET_MAC_IFCTRL_GHDMODE;\r\nif (phydev->duplex == DUPLEX_HALF)\r\nifctrl |= ET_MAC_IFCTRL_GHDMODE;\r\nwritel(ifctrl, &mac->if_ctrl);\r\nwritel(cfg2, &mac->cfg2);\r\ndo {\r\nudelay(10);\r\ndelay++;\r\ncfg1 = readl(&mac->cfg1);\r\n} while ((cfg1 & ET_MAC_CFG1_WAIT) != ET_MAC_CFG1_WAIT && delay < 100);\r\nif (delay == 100) {\r\ndev_warn(&adapter->pdev->dev,\r\n"Syncd bits did not respond correctly cfg1 word 0x%08x\n",\r\ncfg1);\r\n}\r\nctl |= ET_TX_CTRL_TXMAC_ENABLE | ET_TX_CTRL_FC_DISABLE;\r\nwritel(ctl, &adapter->regs->txmac.ctl);\r\nif (adapter->flags & FMP_ADAPTER_LOWER_POWER) {\r\net131x_rx_dma_enable(adapter);\r\net131x_tx_dma_enable(adapter);\r\n}\r\n}\r\nstatic int et1310_in_phy_coma(struct et131x_adapter *adapter)\r\n{\r\nu32 pmcsr = readl(&adapter->regs->global.pm_csr);\r\nreturn ET_PM_PHY_SW_COMA & pmcsr ? 1 : 0;\r\n}\r\nstatic void et1310_setup_device_for_multicast(struct et131x_adapter *adapter)\r\n{\r\nstruct rxmac_regs __iomem *rxmac = &adapter->regs->rxmac;\r\nu32 hash1 = 0;\r\nu32 hash2 = 0;\r\nu32 hash3 = 0;\r\nu32 hash4 = 0;\r\nu32 pm_csr;\r\nif (adapter->packet_filter & ET131X_PACKET_TYPE_MULTICAST) {\r\nint i;\r\nfor (i = 0; i < adapter->multicast_addr_count; i++) {\r\nu32 result;\r\nresult = ether_crc(6, adapter->multicast_list[i]);\r\nresult = (result & 0x3F800000) >> 23;\r\nif (result < 32) {\r\nhash1 |= (1 << result);\r\n} else if ((31 < result) && (result < 64)) {\r\nresult -= 32;\r\nhash2 |= (1 << result);\r\n} else if ((63 < result) && (result < 96)) {\r\nresult -= 64;\r\nhash3 |= (1 << result);\r\n} else {\r\nresult -= 96;\r\nhash4 |= (1 << result);\r\n}\r\n}\r\n}\r\npm_csr = readl(&adapter->regs->global.pm_csr);\r\nif (!et1310_in_phy_coma(adapter)) {\r\nwritel(hash1, &rxmac->multi_hash1);\r\nwritel(hash2, &rxmac->multi_hash2);\r\nwritel(hash3, &rxmac->multi_hash3);\r\nwritel(hash4, &rxmac->multi_hash4);\r\n}\r\n}\r\nstatic void et1310_setup_device_for_unicast(struct et131x_adapter *adapter)\r\n{\r\nstruct rxmac_regs __iomem *rxmac = &adapter->regs->rxmac;\r\nu32 uni_pf1;\r\nu32 uni_pf2;\r\nu32 uni_pf3;\r\nu32 pm_csr;\r\nuni_pf3 = (adapter->addr[0] << ET_RX_UNI_PF_ADDR2_1_SHIFT) |\r\n(adapter->addr[1] << ET_RX_UNI_PF_ADDR2_2_SHIFT) |\r\n(adapter->addr[0] << ET_RX_UNI_PF_ADDR1_1_SHIFT) |\r\nadapter->addr[1];\r\nuni_pf2 = (adapter->addr[2] << ET_RX_UNI_PF_ADDR2_3_SHIFT) |\r\n(adapter->addr[3] << ET_RX_UNI_PF_ADDR2_4_SHIFT) |\r\n(adapter->addr[4] << ET_RX_UNI_PF_ADDR2_5_SHIFT) |\r\nadapter->addr[5];\r\nuni_pf1 = (adapter->addr[2] << ET_RX_UNI_PF_ADDR1_3_SHIFT) |\r\n(adapter->addr[3] << ET_RX_UNI_PF_ADDR1_4_SHIFT) |\r\n(adapter->addr[4] << ET_RX_UNI_PF_ADDR1_5_SHIFT) |\r\nadapter->addr[5];\r\npm_csr = readl(&adapter->regs->global.pm_csr);\r\nif (!et1310_in_phy_coma(adapter)) {\r\nwritel(uni_pf1, &rxmac->uni_pf_addr1);\r\nwritel(uni_pf2, &rxmac->uni_pf_addr2);\r\nwritel(uni_pf3, &rxmac->uni_pf_addr3);\r\n}\r\n}\r\nstatic void et1310_config_rxmac_regs(struct et131x_adapter *adapter)\r\n{\r\nstruct rxmac_regs __iomem *rxmac = &adapter->regs->rxmac;\r\nstruct phy_device *phydev = adapter->phydev;\r\nu32 sa_lo;\r\nu32 sa_hi = 0;\r\nu32 pf_ctrl = 0;\r\nu32 __iomem *wolw;\r\nwritel(0x8, &rxmac->ctrl);\r\nwritel(0, &rxmac->crc0);\r\nwritel(0, &rxmac->crc12);\r\nwritel(0, &rxmac->crc34);\r\nfor (wolw = &rxmac->mask0_word0; wolw <= &rxmac->mask4_word3; wolw++)\r\nwritel(0, wolw);\r\nsa_lo = (adapter->addr[2] << ET_RX_WOL_LO_SA3_SHIFT) |\r\n(adapter->addr[3] << ET_RX_WOL_LO_SA4_SHIFT) |\r\n(adapter->addr[4] << ET_RX_WOL_LO_SA5_SHIFT) |\r\nadapter->addr[5];\r\nwritel(sa_lo, &rxmac->sa_lo);\r\nsa_hi = (u32)(adapter->addr[0] << ET_RX_WOL_HI_SA1_SHIFT) |\r\nadapter->addr[1];\r\nwritel(sa_hi, &rxmac->sa_hi);\r\nwritel(0, &rxmac->pf_ctrl);\r\nif (adapter->packet_filter & ET131X_PACKET_TYPE_DIRECTED) {\r\net1310_setup_device_for_unicast(adapter);\r\npf_ctrl |= ET_RX_PFCTRL_UNICST_FILTER_ENABLE;\r\n} else {\r\nwritel(0, &rxmac->uni_pf_addr1);\r\nwritel(0, &rxmac->uni_pf_addr2);\r\nwritel(0, &rxmac->uni_pf_addr3);\r\n}\r\nif (!(adapter->packet_filter & ET131X_PACKET_TYPE_ALL_MULTICAST)) {\r\npf_ctrl |= ET_RX_PFCTRL_MLTCST_FILTER_ENABLE;\r\net1310_setup_device_for_multicast(adapter);\r\n}\r\npf_ctrl |= (NIC_MIN_PACKET_SIZE + 4) << ET_RX_PFCTRL_MIN_PKT_SZ_SHIFT;\r\npf_ctrl |= ET_RX_PFCTRL_FRAG_FILTER_ENABLE;\r\nif (adapter->registry_jumbo_packet > 8192)\r\nwritel(0x41, &rxmac->mcif_ctrl_max_seg);\r\nelse\r\nwritel(0, &rxmac->mcif_ctrl_max_seg);\r\nwritel(0, &rxmac->mcif_water_mark);\r\nwritel(0, &rxmac->mif_ctrl);\r\nwritel(0, &rxmac->space_avail);\r\nif (phydev && phydev->speed == SPEED_100)\r\nwritel(0x30038, &rxmac->mif_ctrl);\r\nelse\r\nwritel(0x30030, &rxmac->mif_ctrl);\r\nwritel(pf_ctrl, &rxmac->pf_ctrl);\r\nwritel(ET_RX_CTRL_RXMAC_ENABLE | ET_RX_CTRL_WOL_DISABLE, &rxmac->ctrl);\r\n}\r\nstatic void et1310_config_txmac_regs(struct et131x_adapter *adapter)\r\n{\r\nstruct txmac_regs __iomem *txmac = &adapter->regs->txmac;\r\nif (adapter->flow == FLOW_NONE)\r\nwritel(0, &txmac->cf_param);\r\nelse\r\nwritel(0x40, &txmac->cf_param);\r\n}\r\nstatic void et1310_config_macstat_regs(struct et131x_adapter *adapter)\r\n{\r\nstruct macstat_regs __iomem *macstat = &adapter->regs->macstat;\r\nu32 __iomem *reg;\r\nfor (reg = &macstat->txrx_0_64_byte_frames;\r\nreg <= &macstat->carry_reg2; reg++)\r\nwritel(0, reg);\r\nwritel(0xFFFFBE32, &macstat->carry_reg1_mask);\r\nwritel(0xFFFE7E8B, &macstat->carry_reg2_mask);\r\n}\r\nstatic int et131x_phy_mii_read(struct et131x_adapter *adapter, u8 addr,\r\nu8 reg, u16 *value)\r\n{\r\nstruct mac_regs __iomem *mac = &adapter->regs->mac;\r\nint status = 0;\r\nu32 delay = 0;\r\nu32 mii_addr;\r\nu32 mii_cmd;\r\nu32 mii_indicator;\r\nmii_addr = readl(&mac->mii_mgmt_addr);\r\nmii_cmd = readl(&mac->mii_mgmt_cmd);\r\nwritel(0, &mac->mii_mgmt_cmd);\r\nwritel(ET_MAC_MII_ADDR(addr, reg), &mac->mii_mgmt_addr);\r\nwritel(0x1, &mac->mii_mgmt_cmd);\r\ndo {\r\nudelay(50);\r\ndelay++;\r\nmii_indicator = readl(&mac->mii_mgmt_indicator);\r\n} while ((mii_indicator & ET_MAC_MGMT_WAIT) && delay < 50);\r\nif (delay == 50) {\r\ndev_warn(&adapter->pdev->dev,\r\n"reg 0x%08x could not be read\n", reg);\r\ndev_warn(&adapter->pdev->dev, "status is 0x%08x\n",\r\nmii_indicator);\r\nstatus = -EIO;\r\ngoto out;\r\n}\r\n*value = readl(&mac->mii_mgmt_stat) & ET_MAC_MIIMGMT_STAT_PHYCRTL_MASK;\r\nout:\r\nwritel(0, &mac->mii_mgmt_cmd);\r\nwritel(mii_addr, &mac->mii_mgmt_addr);\r\nwritel(mii_cmd, &mac->mii_mgmt_cmd);\r\nreturn status;\r\n}\r\nstatic int et131x_mii_read(struct et131x_adapter *adapter, u8 reg, u16 *value)\r\n{\r\nstruct phy_device *phydev = adapter->phydev;\r\nif (!phydev)\r\nreturn -EIO;\r\nreturn et131x_phy_mii_read(adapter, phydev->addr, reg, value);\r\n}\r\nstatic int et131x_mii_write(struct et131x_adapter *adapter, u8 addr, u8 reg,\r\nu16 value)\r\n{\r\nstruct mac_regs __iomem *mac = &adapter->regs->mac;\r\nint status = 0;\r\nu32 delay = 0;\r\nu32 mii_addr;\r\nu32 mii_cmd;\r\nu32 mii_indicator;\r\nmii_addr = readl(&mac->mii_mgmt_addr);\r\nmii_cmd = readl(&mac->mii_mgmt_cmd);\r\nwritel(0, &mac->mii_mgmt_cmd);\r\nwritel(ET_MAC_MII_ADDR(addr, reg), &mac->mii_mgmt_addr);\r\nwritel(value, &mac->mii_mgmt_ctrl);\r\ndo {\r\nudelay(50);\r\ndelay++;\r\nmii_indicator = readl(&mac->mii_mgmt_indicator);\r\n} while ((mii_indicator & ET_MAC_MGMT_BUSY) && delay < 100);\r\nif (delay == 100) {\r\nu16 tmp;\r\ndev_warn(&adapter->pdev->dev,\r\n"reg 0x%08x could not be written", reg);\r\ndev_warn(&adapter->pdev->dev, "status is 0x%08x\n",\r\nmii_indicator);\r\ndev_warn(&adapter->pdev->dev, "command is 0x%08x\n",\r\nreadl(&mac->mii_mgmt_cmd));\r\net131x_mii_read(adapter, reg, &tmp);\r\nstatus = -EIO;\r\n}\r\nwritel(0, &mac->mii_mgmt_cmd);\r\nwritel(mii_addr, &mac->mii_mgmt_addr);\r\nwritel(mii_cmd, &mac->mii_mgmt_cmd);\r\nreturn status;\r\n}\r\nstatic void et1310_phy_read_mii_bit(struct et131x_adapter *adapter,\r\nu16 regnum,\r\nu16 bitnum,\r\nu8 *value)\r\n{\r\nu16 reg;\r\nu16 mask = 1 << bitnum;\r\net131x_mii_read(adapter, regnum, &reg);\r\n*value = (reg & mask) >> bitnum;\r\n}\r\nstatic void et1310_config_flow_control(struct et131x_adapter *adapter)\r\n{\r\nstruct phy_device *phydev = adapter->phydev;\r\nif (phydev->duplex == DUPLEX_HALF) {\r\nadapter->flow = FLOW_NONE;\r\n} else {\r\nchar remote_pause, remote_async_pause;\r\net1310_phy_read_mii_bit(adapter, 5, 10, &remote_pause);\r\net1310_phy_read_mii_bit(adapter, 5, 11, &remote_async_pause);\r\nif (remote_pause && remote_async_pause) {\r\nadapter->flow = adapter->wanted_flow;\r\n} else if (remote_pause && !remote_async_pause) {\r\nif (adapter->wanted_flow == FLOW_BOTH)\r\nadapter->flow = FLOW_BOTH;\r\nelse\r\nadapter->flow = FLOW_NONE;\r\n} else if (!remote_pause && !remote_async_pause) {\r\nadapter->flow = FLOW_NONE;\r\n} else {\r\nif (adapter->wanted_flow == FLOW_BOTH)\r\nadapter->flow = FLOW_RXONLY;\r\nelse\r\nadapter->flow = FLOW_NONE;\r\n}\r\n}\r\n}\r\nstatic void et1310_update_macstat_host_counters(struct et131x_adapter *adapter)\r\n{\r\nstruct ce_stats *stats = &adapter->stats;\r\nstruct macstat_regs __iomem *macstat =\r\n&adapter->regs->macstat;\r\nstats->tx_collisions += readl(&macstat->tx_total_collisions);\r\nstats->tx_first_collisions += readl(&macstat->tx_single_collisions);\r\nstats->tx_deferred += readl(&macstat->tx_deferred);\r\nstats->tx_excessive_collisions +=\r\nreadl(&macstat->tx_multiple_collisions);\r\nstats->tx_late_collisions += readl(&macstat->tx_late_collisions);\r\nstats->tx_underflows += readl(&macstat->tx_undersize_frames);\r\nstats->tx_max_pkt_errs += readl(&macstat->tx_oversize_frames);\r\nstats->rx_align_errs += readl(&macstat->rx_align_errs);\r\nstats->rx_crc_errs += readl(&macstat->rx_code_errs);\r\nstats->rcvd_pkts_dropped += readl(&macstat->rx_drops);\r\nstats->rx_overflows += readl(&macstat->rx_oversize_packets);\r\nstats->rx_code_violations += readl(&macstat->rx_fcs_errs);\r\nstats->rx_length_errs += readl(&macstat->rx_frame_len_errs);\r\nstats->rx_other_errs += readl(&macstat->rx_fragment_packets);\r\n}\r\nstatic void et1310_handle_macstat_interrupt(struct et131x_adapter *adapter)\r\n{\r\nu32 carry_reg1;\r\nu32 carry_reg2;\r\ncarry_reg1 = readl(&adapter->regs->macstat.carry_reg1);\r\ncarry_reg2 = readl(&adapter->regs->macstat.carry_reg2);\r\nwritel(carry_reg1, &adapter->regs->macstat.carry_reg1);\r\nwritel(carry_reg2, &adapter->regs->macstat.carry_reg2);\r\nif (carry_reg1 & (1 << 14))\r\nadapter->stats.rx_code_violations += COUNTER_WRAP_16_BIT;\r\nif (carry_reg1 & (1 << 8))\r\nadapter->stats.rx_align_errs += COUNTER_WRAP_12_BIT;\r\nif (carry_reg1 & (1 << 7))\r\nadapter->stats.rx_length_errs += COUNTER_WRAP_16_BIT;\r\nif (carry_reg1 & (1 << 2))\r\nadapter->stats.rx_other_errs += COUNTER_WRAP_16_BIT;\r\nif (carry_reg1 & (1 << 6))\r\nadapter->stats.rx_crc_errs += COUNTER_WRAP_16_BIT;\r\nif (carry_reg1 & (1 << 3))\r\nadapter->stats.rx_overflows += COUNTER_WRAP_16_BIT;\r\nif (carry_reg1 & (1 << 0))\r\nadapter->stats.rcvd_pkts_dropped += COUNTER_WRAP_16_BIT;\r\nif (carry_reg2 & (1 << 16))\r\nadapter->stats.tx_max_pkt_errs += COUNTER_WRAP_12_BIT;\r\nif (carry_reg2 & (1 << 15))\r\nadapter->stats.tx_underflows += COUNTER_WRAP_12_BIT;\r\nif (carry_reg2 & (1 << 6))\r\nadapter->stats.tx_first_collisions += COUNTER_WRAP_12_BIT;\r\nif (carry_reg2 & (1 << 8))\r\nadapter->stats.tx_deferred += COUNTER_WRAP_12_BIT;\r\nif (carry_reg2 & (1 << 5))\r\nadapter->stats.tx_excessive_collisions += COUNTER_WRAP_12_BIT;\r\nif (carry_reg2 & (1 << 4))\r\nadapter->stats.tx_late_collisions += COUNTER_WRAP_12_BIT;\r\nif (carry_reg2 & (1 << 2))\r\nadapter->stats.tx_collisions += COUNTER_WRAP_12_BIT;\r\n}\r\nstatic int et131x_mdio_read(struct mii_bus *bus, int phy_addr, int reg)\r\n{\r\nstruct net_device *netdev = bus->priv;\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nu16 value;\r\nint ret;\r\nret = et131x_phy_mii_read(adapter, phy_addr, reg, &value);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn value;\r\n}\r\nstatic int et131x_mdio_write(struct mii_bus *bus, int phy_addr,\r\nint reg, u16 value)\r\n{\r\nstruct net_device *netdev = bus->priv;\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nreturn et131x_mii_write(adapter, phy_addr, reg, value);\r\n}\r\nstatic void et1310_phy_power_switch(struct et131x_adapter *adapter, bool down)\r\n{\r\nu16 data;\r\nstruct phy_device *phydev = adapter->phydev;\r\net131x_mii_read(adapter, MII_BMCR, &data);\r\ndata &= ~BMCR_PDOWN;\r\nif (down)\r\ndata |= BMCR_PDOWN;\r\net131x_mii_write(adapter, phydev->addr, MII_BMCR, data);\r\n}\r\nstatic void et131x_xcvr_init(struct et131x_adapter *adapter)\r\n{\r\nu16 lcr2;\r\nstruct phy_device *phydev = adapter->phydev;\r\nif ((adapter->eeprom_data[1] & 0x4) == 0) {\r\net131x_mii_read(adapter, PHY_LED_2, &lcr2);\r\nlcr2 &= (ET_LED2_LED_100TX | ET_LED2_LED_1000T);\r\nlcr2 |= (LED_VAL_LINKON_ACTIVE << LED_LINK_SHIFT);\r\nif ((adapter->eeprom_data[1] & 0x8) == 0)\r\nlcr2 |= (LED_VAL_1000BT_100BTX << LED_TXRX_SHIFT);\r\nelse\r\nlcr2 |= (LED_VAL_LINKON << LED_TXRX_SHIFT);\r\net131x_mii_write(adapter, phydev->addr, PHY_LED_2, lcr2);\r\n}\r\n}\r\nstatic void et131x_configure_global_regs(struct et131x_adapter *adapter)\r\n{\r\nstruct global_regs __iomem *regs = &adapter->regs->global;\r\nwritel(0, &regs->rxq_start_addr);\r\nwritel(INTERNAL_MEM_SIZE - 1, &regs->txq_end_addr);\r\nif (adapter->registry_jumbo_packet < 2048) {\r\nwritel(PARM_RX_MEM_END_DEF, &regs->rxq_end_addr);\r\nwritel(PARM_RX_MEM_END_DEF + 1, &regs->txq_start_addr);\r\n} else if (adapter->registry_jumbo_packet < 8192) {\r\nwritel(INTERNAL_MEM_RX_OFFSET, &regs->rxq_end_addr);\r\nwritel(INTERNAL_MEM_RX_OFFSET + 1, &regs->txq_start_addr);\r\n} else {\r\nwritel(0x01b3, &regs->rxq_end_addr);\r\nwritel(0x01b4, &regs->txq_start_addr);\r\n}\r\nwritel(0, &regs->loopback);\r\nwritel(0, &regs->msi_config);\r\nwritel(0, &regs->watchdog_timer);\r\n}\r\nstatic void et131x_config_rx_dma_regs(struct et131x_adapter *adapter)\r\n{\r\nstruct rxdma_regs __iomem *rx_dma = &adapter->regs->rxdma;\r\nstruct rx_ring *rx_local = &adapter->rx_ring;\r\nstruct fbr_desc *fbr_entry;\r\nu32 entry;\r\nu32 psr_num_des;\r\nunsigned long flags;\r\nu8 id;\r\net131x_rx_dma_disable(adapter);\r\nwritel(upper_32_bits(rx_local->rx_status_bus), &rx_dma->dma_wb_base_hi);\r\nwritel(lower_32_bits(rx_local->rx_status_bus), &rx_dma->dma_wb_base_lo);\r\nmemset(rx_local->rx_status_block, 0, sizeof(struct rx_status_block));\r\nwritel(upper_32_bits(rx_local->ps_ring_physaddr), &rx_dma->psr_base_hi);\r\nwritel(lower_32_bits(rx_local->ps_ring_physaddr), &rx_dma->psr_base_lo);\r\nwritel(rx_local->psr_entries - 1, &rx_dma->psr_num_des);\r\nwritel(0, &rx_dma->psr_full_offset);\r\npsr_num_des = readl(&rx_dma->psr_num_des) & ET_RXDMA_PSR_NUM_DES_MASK;\r\nwritel((psr_num_des * LO_MARK_PERCENT_FOR_PSR) / 100,\r\n&rx_dma->psr_min_des);\r\nspin_lock_irqsave(&adapter->rcv_lock, flags);\r\nrx_local->local_psr_full = 0;\r\nfor (id = 0; id < NUM_FBRS; id++) {\r\nu32 __iomem *num_des;\r\nu32 __iomem *full_offset;\r\nu32 __iomem *min_des;\r\nu32 __iomem *base_hi;\r\nu32 __iomem *base_lo;\r\nstruct fbr_lookup *fbr = rx_local->fbr[id];\r\nif (id == 0) {\r\nnum_des = &rx_dma->fbr0_num_des;\r\nfull_offset = &rx_dma->fbr0_full_offset;\r\nmin_des = &rx_dma->fbr0_min_des;\r\nbase_hi = &rx_dma->fbr0_base_hi;\r\nbase_lo = &rx_dma->fbr0_base_lo;\r\n} else {\r\nnum_des = &rx_dma->fbr1_num_des;\r\nfull_offset = &rx_dma->fbr1_full_offset;\r\nmin_des = &rx_dma->fbr1_min_des;\r\nbase_hi = &rx_dma->fbr1_base_hi;\r\nbase_lo = &rx_dma->fbr1_base_lo;\r\n}\r\nfbr_entry = fbr->ring_virtaddr;\r\nfor (entry = 0; entry < fbr->num_entries; entry++) {\r\nfbr_entry->addr_hi = fbr->bus_high[entry];\r\nfbr_entry->addr_lo = fbr->bus_low[entry];\r\nfbr_entry->word2 = entry;\r\nfbr_entry++;\r\n}\r\nwritel(upper_32_bits(fbr->ring_physaddr), base_hi);\r\nwritel(lower_32_bits(fbr->ring_physaddr), base_lo);\r\nwritel(fbr->num_entries - 1, num_des);\r\nwritel(ET_DMA10_WRAP, full_offset);\r\nfbr->local_full = ET_DMA10_WRAP;\r\nwritel(((fbr->num_entries * LO_MARK_PERCENT_FOR_RX) / 100) - 1,\r\nmin_des);\r\n}\r\nwritel(PARM_RX_NUM_BUFS_DEF, &rx_dma->num_pkt_done);\r\nwritel(PARM_RX_TIME_INT_DEF, &rx_dma->max_pkt_time);\r\nspin_unlock_irqrestore(&adapter->rcv_lock, flags);\r\n}\r\nstatic void et131x_config_tx_dma_regs(struct et131x_adapter *adapter)\r\n{\r\nstruct txdma_regs __iomem *txdma = &adapter->regs->txdma;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nwritel(upper_32_bits(tx_ring->tx_desc_ring_pa), &txdma->pr_base_hi);\r\nwritel(lower_32_bits(tx_ring->tx_desc_ring_pa), &txdma->pr_base_lo);\r\nwritel(NUM_DESC_PER_RING_TX - 1, &txdma->pr_num_des);\r\nwritel(upper_32_bits(tx_ring->tx_status_pa), &txdma->dma_wb_base_hi);\r\nwritel(lower_32_bits(tx_ring->tx_status_pa), &txdma->dma_wb_base_lo);\r\n*tx_ring->tx_status = 0;\r\nwritel(0, &txdma->service_request);\r\ntx_ring->send_idx = 0;\r\n}\r\nstatic void et131x_adapter_setup(struct et131x_adapter *adapter)\r\n{\r\net131x_configure_global_regs(adapter);\r\net1310_config_mac_regs1(adapter);\r\nwritel(ET_MMC_ENABLE, &adapter->regs->mmc.mmc_ctrl);\r\net1310_config_rxmac_regs(adapter);\r\net1310_config_txmac_regs(adapter);\r\net131x_config_rx_dma_regs(adapter);\r\net131x_config_tx_dma_regs(adapter);\r\net1310_config_macstat_regs(adapter);\r\net1310_phy_power_switch(adapter, 0);\r\net131x_xcvr_init(adapter);\r\n}\r\nstatic void et131x_soft_reset(struct et131x_adapter *adapter)\r\n{\r\nu32 reg;\r\nreg = ET_MAC_CFG1_SOFT_RESET | ET_MAC_CFG1_SIM_RESET |\r\nET_MAC_CFG1_RESET_RXMC | ET_MAC_CFG1_RESET_TXMC |\r\nET_MAC_CFG1_RESET_RXFUNC | ET_MAC_CFG1_RESET_TXFUNC;\r\nwritel(reg, &adapter->regs->mac.cfg1);\r\nreg = ET_RESET_ALL;\r\nwritel(reg, &adapter->regs->global.sw_reset);\r\nreg = ET_MAC_CFG1_RESET_RXMC | ET_MAC_CFG1_RESET_TXMC |\r\nET_MAC_CFG1_RESET_RXFUNC | ET_MAC_CFG1_RESET_TXFUNC;\r\nwritel(reg, &adapter->regs->mac.cfg1);\r\nwritel(0, &adapter->regs->mac.cfg1);\r\n}\r\nstatic void et131x_enable_interrupts(struct et131x_adapter *adapter)\r\n{\r\nu32 mask;\r\nif (adapter->flow == FLOW_TXONLY || adapter->flow == FLOW_BOTH)\r\nmask = INT_MASK_ENABLE;\r\nelse\r\nmask = INT_MASK_ENABLE_NO_FLOW;\r\nwritel(mask, &adapter->regs->global.int_mask);\r\n}\r\nstatic void et131x_disable_interrupts(struct et131x_adapter *adapter)\r\n{\r\nwritel(INT_MASK_DISABLE, &adapter->regs->global.int_mask);\r\n}\r\nstatic void et131x_tx_dma_disable(struct et131x_adapter *adapter)\r\n{\r\nwritel(ET_TXDMA_CSR_HALT | ET_TXDMA_SNGL_EPKT,\r\n&adapter->regs->txdma.csr);\r\n}\r\nstatic void et131x_enable_txrx(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\net131x_rx_dma_enable(adapter);\r\net131x_tx_dma_enable(adapter);\r\nif (adapter->flags & FMP_ADAPTER_INTERRUPT_IN_USE)\r\net131x_enable_interrupts(adapter);\r\nnetif_start_queue(netdev);\r\n}\r\nstatic void et131x_disable_txrx(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nnetif_stop_queue(netdev);\r\net131x_rx_dma_disable(adapter);\r\net131x_tx_dma_disable(adapter);\r\net131x_disable_interrupts(adapter);\r\n}\r\nstatic void et131x_init_send(struct et131x_adapter *adapter)\r\n{\r\nint i;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nstruct tcb *tcb = tx_ring->tcb_ring;\r\ntx_ring->tcb_qhead = tcb;\r\nmemset(tcb, 0, sizeof(struct tcb) * NUM_TCB);\r\nfor (i = 0; i < NUM_TCB; i++) {\r\ntcb->next = tcb + 1;\r\ntcb++;\r\n}\r\ntcb--;\r\ntx_ring->tcb_qtail = tcb;\r\ntcb->next = NULL;\r\ntx_ring->send_head = NULL;\r\ntx_ring->send_tail = NULL;\r\n}\r\nstatic void et1310_enable_phy_coma(struct et131x_adapter *adapter)\r\n{\r\nu32 pmcsr = readl(&adapter->regs->global.pm_csr);\r\nadapter->flags |= FMP_ADAPTER_LOWER_POWER;\r\net131x_disable_txrx(adapter->netdev);\r\npmcsr &= ~ET_PMCSR_INIT;\r\nwritel(pmcsr, &adapter->regs->global.pm_csr);\r\npmcsr |= ET_PM_PHY_SW_COMA;\r\nwritel(pmcsr, &adapter->regs->global.pm_csr);\r\n}\r\nstatic void et1310_disable_phy_coma(struct et131x_adapter *adapter)\r\n{\r\nu32 pmcsr;\r\npmcsr = readl(&adapter->regs->global.pm_csr);\r\npmcsr |= ET_PMCSR_INIT;\r\npmcsr &= ~ET_PM_PHY_SW_COMA;\r\nwritel(pmcsr, &adapter->regs->global.pm_csr);\r\net131x_init_send(adapter);\r\net131x_soft_reset(adapter);\r\net131x_adapter_setup(adapter);\r\nadapter->flags &= ~FMP_ADAPTER_LOWER_POWER;\r\net131x_enable_txrx(adapter->netdev);\r\n}\r\nstatic inline u32 bump_free_buff_ring(u32 *free_buff_ring, u32 limit)\r\n{\r\nu32 tmp_free_buff_ring = *free_buff_ring;\r\ntmp_free_buff_ring++;\r\nif ((tmp_free_buff_ring & ET_DMA10_MASK) > limit) {\r\ntmp_free_buff_ring &= ~ET_DMA10_MASK;\r\ntmp_free_buff_ring ^= ET_DMA10_WRAP;\r\n}\r\ntmp_free_buff_ring &= (ET_DMA10_MASK | ET_DMA10_WRAP);\r\n*free_buff_ring = tmp_free_buff_ring;\r\nreturn tmp_free_buff_ring;\r\n}\r\nstatic int et131x_rx_dma_memory_alloc(struct et131x_adapter *adapter)\r\n{\r\nu8 id;\r\nu32 i, j;\r\nu32 bufsize;\r\nu32 psr_size;\r\nu32 fbr_chunksize;\r\nstruct rx_ring *rx_ring = &adapter->rx_ring;\r\nstruct fbr_lookup *fbr;\r\nrx_ring->fbr[0] = kzalloc(sizeof(*fbr), GFP_KERNEL);\r\nif (rx_ring->fbr[0] == NULL)\r\nreturn -ENOMEM;\r\nrx_ring->fbr[1] = kzalloc(sizeof(*fbr), GFP_KERNEL);\r\nif (rx_ring->fbr[1] == NULL)\r\nreturn -ENOMEM;\r\nif (adapter->registry_jumbo_packet < 2048) {\r\nrx_ring->fbr[0]->buffsize = 256;\r\nrx_ring->fbr[0]->num_entries = 512;\r\nrx_ring->fbr[1]->buffsize = 2048;\r\nrx_ring->fbr[1]->num_entries = 512;\r\n} else if (adapter->registry_jumbo_packet < 4096) {\r\nrx_ring->fbr[0]->buffsize = 512;\r\nrx_ring->fbr[0]->num_entries = 1024;\r\nrx_ring->fbr[1]->buffsize = 4096;\r\nrx_ring->fbr[1]->num_entries = 512;\r\n} else {\r\nrx_ring->fbr[0]->buffsize = 1024;\r\nrx_ring->fbr[0]->num_entries = 768;\r\nrx_ring->fbr[1]->buffsize = 16384;\r\nrx_ring->fbr[1]->num_entries = 128;\r\n}\r\nrx_ring->psr_entries = rx_ring->fbr[0]->num_entries +\r\nrx_ring->fbr[1]->num_entries;\r\nfor (id = 0; id < NUM_FBRS; id++) {\r\nfbr = rx_ring->fbr[id];\r\nbufsize = sizeof(struct fbr_desc) * fbr->num_entries;\r\nfbr->ring_virtaddr = dma_alloc_coherent(&adapter->pdev->dev,\r\nbufsize,\r\n&fbr->ring_physaddr,\r\nGFP_KERNEL);\r\nif (!fbr->ring_virtaddr) {\r\ndev_err(&adapter->pdev->dev,\r\n"Cannot alloc memory for Free Buffer Ring %d\n",\r\nid);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nfor (id = 0; id < NUM_FBRS; id++) {\r\nfbr = rx_ring->fbr[id];\r\nfbr_chunksize = (FBR_CHUNKS * fbr->buffsize);\r\nfor (i = 0; i < fbr->num_entries / FBR_CHUNKS; i++) {\r\ndma_addr_t fbr_physaddr;\r\nfbr->mem_virtaddrs[i] = dma_alloc_coherent(\r\n&adapter->pdev->dev, fbr_chunksize,\r\n&fbr->mem_physaddrs[i],\r\nGFP_KERNEL);\r\nif (!fbr->mem_virtaddrs[i]) {\r\ndev_err(&adapter->pdev->dev,\r\n"Could not alloc memory\n");\r\nreturn -ENOMEM;\r\n}\r\nfbr_physaddr = fbr->mem_physaddrs[i];\r\nfor (j = 0; j < FBR_CHUNKS; j++) {\r\nu32 k = (i * FBR_CHUNKS) + j;\r\nfbr->virt[k] = (u8 *)fbr->mem_virtaddrs[i] +\r\n(j * fbr->buffsize);\r\nfbr->bus_high[k] = upper_32_bits(fbr_physaddr);\r\nfbr->bus_low[k] = lower_32_bits(fbr_physaddr);\r\nfbr_physaddr += fbr->buffsize;\r\n}\r\n}\r\n}\r\npsr_size = sizeof(struct pkt_stat_desc) * rx_ring->psr_entries;\r\nrx_ring->ps_ring_virtaddr = dma_alloc_coherent(&adapter->pdev->dev,\r\npsr_size,\r\n&rx_ring->ps_ring_physaddr,\r\nGFP_KERNEL);\r\nif (!rx_ring->ps_ring_virtaddr) {\r\ndev_err(&adapter->pdev->dev,\r\n"Cannot alloc memory for Packet Status Ring\n");\r\nreturn -ENOMEM;\r\n}\r\nrx_ring->rx_status_block = dma_alloc_coherent(&adapter->pdev->dev,\r\nsizeof(struct rx_status_block),\r\n&rx_ring->rx_status_bus,\r\nGFP_KERNEL);\r\nif (!rx_ring->rx_status_block) {\r\ndev_err(&adapter->pdev->dev,\r\n"Cannot alloc memory for Status Block\n");\r\nreturn -ENOMEM;\r\n}\r\nrx_ring->num_rfd = NIC_DEFAULT_NUM_RFD;\r\nINIT_LIST_HEAD(&rx_ring->recv_list);\r\nreturn 0;\r\n}\r\nstatic void et131x_rx_dma_memory_free(struct et131x_adapter *adapter)\r\n{\r\nu8 id;\r\nu32 ii;\r\nu32 bufsize;\r\nu32 psr_size;\r\nstruct rfd *rfd;\r\nstruct rx_ring *rx_ring = &adapter->rx_ring;\r\nstruct fbr_lookup *fbr;\r\nWARN_ON(rx_ring->num_ready_recv != rx_ring->num_rfd);\r\nwhile (!list_empty(&rx_ring->recv_list)) {\r\nrfd = list_entry(rx_ring->recv_list.next,\r\nstruct rfd, list_node);\r\nlist_del(&rfd->list_node);\r\nrfd->skb = NULL;\r\nkfree(rfd);\r\n}\r\nfor (id = 0; id < NUM_FBRS; id++) {\r\nfbr = rx_ring->fbr[id];\r\nif (!fbr || !fbr->ring_virtaddr)\r\ncontinue;\r\nfor (ii = 0; ii < fbr->num_entries / FBR_CHUNKS; ii++) {\r\nif (fbr->mem_virtaddrs[ii]) {\r\nbufsize = fbr->buffsize * FBR_CHUNKS;\r\ndma_free_coherent(&adapter->pdev->dev,\r\nbufsize,\r\nfbr->mem_virtaddrs[ii],\r\nfbr->mem_physaddrs[ii]);\r\nfbr->mem_virtaddrs[ii] = NULL;\r\n}\r\n}\r\nbufsize = sizeof(struct fbr_desc) * fbr->num_entries;\r\ndma_free_coherent(&adapter->pdev->dev,\r\nbufsize,\r\nfbr->ring_virtaddr,\r\nfbr->ring_physaddr);\r\nfbr->ring_virtaddr = NULL;\r\n}\r\nif (rx_ring->ps_ring_virtaddr) {\r\npsr_size = sizeof(struct pkt_stat_desc) * rx_ring->psr_entries;\r\ndma_free_coherent(&adapter->pdev->dev, psr_size,\r\nrx_ring->ps_ring_virtaddr,\r\nrx_ring->ps_ring_physaddr);\r\nrx_ring->ps_ring_virtaddr = NULL;\r\n}\r\nif (rx_ring->rx_status_block) {\r\ndma_free_coherent(&adapter->pdev->dev,\r\nsizeof(struct rx_status_block),\r\nrx_ring->rx_status_block,\r\nrx_ring->rx_status_bus);\r\nrx_ring->rx_status_block = NULL;\r\n}\r\nkfree(rx_ring->fbr[0]);\r\nkfree(rx_ring->fbr[1]);\r\nrx_ring->num_ready_recv = 0;\r\n}\r\nstatic int et131x_init_recv(struct et131x_adapter *adapter)\r\n{\r\nstruct rfd *rfd;\r\nu32 rfdct;\r\nstruct rx_ring *rx_ring = &adapter->rx_ring;\r\nfor (rfdct = 0; rfdct < rx_ring->num_rfd; rfdct++) {\r\nrfd = kzalloc(sizeof(*rfd), GFP_ATOMIC | GFP_DMA);\r\nif (!rfd)\r\nreturn -ENOMEM;\r\nrfd->skb = NULL;\r\nlist_add_tail(&rfd->list_node, &rx_ring->recv_list);\r\nrx_ring->num_ready_recv++;\r\n}\r\nreturn 0;\r\n}\r\nstatic void et131x_set_rx_dma_timer(struct et131x_adapter *adapter)\r\n{\r\nstruct phy_device *phydev = adapter->phydev;\r\nif ((phydev->speed == SPEED_100) || (phydev->speed == SPEED_10)) {\r\nwritel(0, &adapter->regs->rxdma.max_pkt_time);\r\nwritel(1, &adapter->regs->rxdma.num_pkt_done);\r\n}\r\n}\r\nstatic void nic_return_rfd(struct et131x_adapter *adapter, struct rfd *rfd)\r\n{\r\nstruct rx_ring *rx_local = &adapter->rx_ring;\r\nstruct rxdma_regs __iomem *rx_dma = &adapter->regs->rxdma;\r\nu16 buff_index = rfd->bufferindex;\r\nu8 ring_index = rfd->ringindex;\r\nunsigned long flags;\r\nstruct fbr_lookup *fbr = rx_local->fbr[ring_index];\r\nif (buff_index < fbr->num_entries) {\r\nu32 free_buff_ring;\r\nu32 __iomem *offset;\r\nstruct fbr_desc *next;\r\nif (ring_index == 0)\r\noffset = &rx_dma->fbr0_full_offset;\r\nelse\r\noffset = &rx_dma->fbr1_full_offset;\r\nnext = (struct fbr_desc *)(fbr->ring_virtaddr) +\r\nINDEX10(fbr->local_full);\r\nnext->addr_hi = fbr->bus_high[buff_index];\r\nnext->addr_lo = fbr->bus_low[buff_index];\r\nnext->word2 = buff_index;\r\nfree_buff_ring = bump_free_buff_ring(&fbr->local_full,\r\nfbr->num_entries - 1);\r\nwritel(free_buff_ring, offset);\r\n} else {\r\ndev_err(&adapter->pdev->dev,\r\n"%s illegal Buffer Index returned\n", __func__);\r\n}\r\nspin_lock_irqsave(&adapter->rcv_lock, flags);\r\nlist_add_tail(&rfd->list_node, &rx_local->recv_list);\r\nrx_local->num_ready_recv++;\r\nspin_unlock_irqrestore(&adapter->rcv_lock, flags);\r\nWARN_ON(rx_local->num_ready_recv > rx_local->num_rfd);\r\n}\r\nstatic struct rfd *nic_rx_pkts(struct et131x_adapter *adapter)\r\n{\r\nstruct rx_ring *rx_local = &adapter->rx_ring;\r\nstruct rx_status_block *status;\r\nstruct pkt_stat_desc *psr;\r\nstruct rfd *rfd;\r\nunsigned long flags;\r\nstruct list_head *element;\r\nu8 ring_index;\r\nu16 buff_index;\r\nu32 len;\r\nu32 word0;\r\nu32 word1;\r\nstruct sk_buff *skb;\r\nstruct fbr_lookup *fbr;\r\nstatus = rx_local->rx_status_block;\r\nword1 = status->word1 >> 16;\r\nif ((word1 & 0x1FFF) == (rx_local->local_psr_full & 0x1FFF))\r\nreturn NULL;\r\npsr = (struct pkt_stat_desc *)(rx_local->ps_ring_virtaddr) +\r\n(rx_local->local_psr_full & 0xFFF);\r\nlen = psr->word1 & 0xFFFF;\r\nring_index = (psr->word1 >> 26) & 0x03;\r\nfbr = rx_local->fbr[ring_index];\r\nbuff_index = (psr->word1 >> 16) & 0x3FF;\r\nword0 = psr->word0;\r\nadd_12bit(&rx_local->local_psr_full, 1);\r\nif ((rx_local->local_psr_full & 0xFFF) > rx_local->psr_entries - 1) {\r\nrx_local->local_psr_full &= ~0xFFF;\r\nrx_local->local_psr_full ^= 0x1000;\r\n}\r\nwritel(rx_local->local_psr_full, &adapter->regs->rxdma.psr_full_offset);\r\nif (ring_index > 1 || buff_index > fbr->num_entries - 1) {\r\ndev_err(&adapter->pdev->dev,\r\n"NICRxPkts PSR Entry %d indicates length of %d and/or bad bi(%d)\n",\r\nrx_local->local_psr_full & 0xFFF, len, buff_index);\r\nreturn NULL;\r\n}\r\nspin_lock_irqsave(&adapter->rcv_lock, flags);\r\nelement = rx_local->recv_list.next;\r\nrfd = list_entry(element, struct rfd, list_node);\r\nif (!rfd) {\r\nspin_unlock_irqrestore(&adapter->rcv_lock, flags);\r\nreturn NULL;\r\n}\r\nlist_del(&rfd->list_node);\r\nrx_local->num_ready_recv--;\r\nspin_unlock_irqrestore(&adapter->rcv_lock, flags);\r\nrfd->bufferindex = buff_index;\r\nrfd->ringindex = ring_index;\r\nif (len < (NIC_MIN_PACKET_SIZE + 4)) {\r\nadapter->stats.rx_other_errs++;\r\nrfd->len = 0;\r\ngoto out;\r\n}\r\nif ((word0 & ALCATEL_MULTICAST_PKT) && !(word0 & ALCATEL_BROADCAST_PKT))\r\nadapter->stats.multicast_pkts_rcvd++;\r\nrfd->len = len;\r\nskb = dev_alloc_skb(rfd->len + 2);\r\nif (!skb)\r\nreturn NULL;\r\nadapter->netdev->stats.rx_bytes += rfd->len;\r\nmemcpy(skb_put(skb, rfd->len), fbr->virt[buff_index], rfd->len);\r\nskb->protocol = eth_type_trans(skb, adapter->netdev);\r\nskb->ip_summed = CHECKSUM_NONE;\r\nnetif_receive_skb(skb);\r\nout:\r\nnic_return_rfd(adapter, rfd);\r\nreturn rfd;\r\n}\r\nstatic int et131x_handle_recv_pkts(struct et131x_adapter *adapter, int budget)\r\n{\r\nstruct rfd *rfd = NULL;\r\nint count = 0;\r\nint limit = budget;\r\nbool done = true;\r\nstruct rx_ring *rx_ring = &adapter->rx_ring;\r\nif (budget > MAX_PACKETS_HANDLED)\r\nlimit = MAX_PACKETS_HANDLED;\r\nwhile (count < limit) {\r\nif (list_empty(&rx_ring->recv_list)) {\r\nWARN_ON(rx_ring->num_ready_recv != 0);\r\ndone = false;\r\nbreak;\r\n}\r\nrfd = nic_rx_pkts(adapter);\r\nif (rfd == NULL)\r\nbreak;\r\nif (!adapter->packet_filter ||\r\n!netif_carrier_ok(adapter->netdev) ||\r\nrfd->len == 0)\r\ncontinue;\r\nadapter->netdev->stats.rx_packets++;\r\nif (rx_ring->num_ready_recv < RFD_LOW_WATER_MARK)\r\ndev_warn(&adapter->pdev->dev, "RFD's are running out\n");\r\ncount++;\r\n}\r\nif (count == limit || !done) {\r\nrx_ring->unfinished_receives = true;\r\nwritel(PARM_TX_TIME_INT_DEF * NANO_IN_A_MICRO,\r\n&adapter->regs->global.watchdog_timer);\r\n} else {\r\nrx_ring->unfinished_receives = false;\r\n}\r\nreturn count;\r\n}\r\nstatic int et131x_tx_dma_memory_alloc(struct et131x_adapter *adapter)\r\n{\r\nint desc_size = 0;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\ntx_ring->tcb_ring = kcalloc(NUM_TCB, sizeof(struct tcb),\r\nGFP_ATOMIC | GFP_DMA);\r\nif (!tx_ring->tcb_ring)\r\nreturn -ENOMEM;\r\ndesc_size = (sizeof(struct tx_desc) * NUM_DESC_PER_RING_TX);\r\ntx_ring->tx_desc_ring = dma_alloc_coherent(&adapter->pdev->dev,\r\ndesc_size,\r\n&tx_ring->tx_desc_ring_pa,\r\nGFP_KERNEL);\r\nif (!tx_ring->tx_desc_ring) {\r\ndev_err(&adapter->pdev->dev,\r\n"Cannot alloc memory for Tx Ring\n");\r\nreturn -ENOMEM;\r\n}\r\ntx_ring->tx_status = dma_alloc_coherent(&adapter->pdev->dev,\r\nsizeof(u32),\r\n&tx_ring->tx_status_pa,\r\nGFP_KERNEL);\r\nif (!tx_ring->tx_status_pa) {\r\ndev_err(&adapter->pdev->dev,\r\n"Cannot alloc memory for Tx status block\n");\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void et131x_tx_dma_memory_free(struct et131x_adapter *adapter)\r\n{\r\nint desc_size = 0;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nif (tx_ring->tx_desc_ring) {\r\ndesc_size = (sizeof(struct tx_desc) * NUM_DESC_PER_RING_TX);\r\ndma_free_coherent(&adapter->pdev->dev,\r\ndesc_size,\r\ntx_ring->tx_desc_ring,\r\ntx_ring->tx_desc_ring_pa);\r\ntx_ring->tx_desc_ring = NULL;\r\n}\r\nif (tx_ring->tx_status) {\r\ndma_free_coherent(&adapter->pdev->dev,\r\nsizeof(u32),\r\ntx_ring->tx_status,\r\ntx_ring->tx_status_pa);\r\ntx_ring->tx_status = NULL;\r\n}\r\nkfree(tx_ring->tcb_ring);\r\n}\r\nstatic int nic_send_packet(struct et131x_adapter *adapter, struct tcb *tcb)\r\n{\r\nu32 i;\r\nstruct tx_desc desc[24];\r\nu32 frag = 0;\r\nu32 thiscopy, remainder;\r\nstruct sk_buff *skb = tcb->skb;\r\nu32 nr_frags = skb_shinfo(skb)->nr_frags + 1;\r\nstruct skb_frag_struct *frags = &skb_shinfo(skb)->frags[0];\r\nstruct phy_device *phydev = adapter->phydev;\r\ndma_addr_t dma_addr;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nBUILD_BUG_ON(MAX_SKB_FRAGS + 1 > 23);\r\nmemset(desc, 0, sizeof(struct tx_desc) * (nr_frags + 1));\r\nfor (i = 0; i < nr_frags; i++) {\r\nif (i == 0) {\r\nif (skb_headlen(skb) <= 1514) {\r\ndesc[frag].len_vlan = skb_headlen(skb);\r\ndma_addr = dma_map_single(&adapter->pdev->dev,\r\nskb->data,\r\nskb_headlen(skb),\r\nDMA_TO_DEVICE);\r\ndesc[frag].addr_lo = lower_32_bits(dma_addr);\r\ndesc[frag].addr_hi = upper_32_bits(dma_addr);\r\nfrag++;\r\n} else {\r\ndesc[frag].len_vlan = skb_headlen(skb) / 2;\r\ndma_addr = dma_map_single(&adapter->pdev->dev,\r\nskb->data,\r\nskb_headlen(skb) / 2,\r\nDMA_TO_DEVICE);\r\ndesc[frag].addr_lo = lower_32_bits(dma_addr);\r\ndesc[frag].addr_hi = upper_32_bits(dma_addr);\r\nfrag++;\r\ndesc[frag].len_vlan = skb_headlen(skb) / 2;\r\ndma_addr = dma_map_single(&adapter->pdev->dev,\r\nskb->data +\r\nskb_headlen(skb) / 2,\r\nskb_headlen(skb) / 2,\r\nDMA_TO_DEVICE);\r\ndesc[frag].addr_lo = lower_32_bits(dma_addr);\r\ndesc[frag].addr_hi = upper_32_bits(dma_addr);\r\nfrag++;\r\n}\r\n} else {\r\ndesc[frag].len_vlan = frags[i - 1].size;\r\ndma_addr = skb_frag_dma_map(&adapter->pdev->dev,\r\n&frags[i - 1],\r\n0,\r\nfrags[i - 1].size,\r\nDMA_TO_DEVICE);\r\ndesc[frag].addr_lo = lower_32_bits(dma_addr);\r\ndesc[frag].addr_hi = upper_32_bits(dma_addr);\r\nfrag++;\r\n}\r\n}\r\nif (phydev && phydev->speed == SPEED_1000) {\r\nif (++tx_ring->since_irq == PARM_TX_NUM_BUFS_DEF) {\r\ndesc[frag - 1].flags =\r\nTXDESC_FLAG_INTPROC | TXDESC_FLAG_LASTPKT;\r\ntx_ring->since_irq = 0;\r\n} else {\r\ndesc[frag - 1].flags = TXDESC_FLAG_LASTPKT;\r\n}\r\n} else {\r\ndesc[frag - 1].flags =\r\nTXDESC_FLAG_INTPROC | TXDESC_FLAG_LASTPKT;\r\n}\r\ndesc[0].flags |= TXDESC_FLAG_FIRSTPKT;\r\ntcb->index_start = tx_ring->send_idx;\r\ntcb->stale = 0;\r\nthiscopy = NUM_DESC_PER_RING_TX - INDEX10(tx_ring->send_idx);\r\nif (thiscopy >= frag) {\r\nremainder = 0;\r\nthiscopy = frag;\r\n} else {\r\nremainder = frag - thiscopy;\r\n}\r\nmemcpy(tx_ring->tx_desc_ring + INDEX10(tx_ring->send_idx),\r\ndesc,\r\nsizeof(struct tx_desc) * thiscopy);\r\nadd_10bit(&tx_ring->send_idx, thiscopy);\r\nif (INDEX10(tx_ring->send_idx) == 0 ||\r\nINDEX10(tx_ring->send_idx) == NUM_DESC_PER_RING_TX) {\r\ntx_ring->send_idx &= ~ET_DMA10_MASK;\r\ntx_ring->send_idx ^= ET_DMA10_WRAP;\r\n}\r\nif (remainder) {\r\nmemcpy(tx_ring->tx_desc_ring,\r\ndesc + thiscopy,\r\nsizeof(struct tx_desc) * remainder);\r\nadd_10bit(&tx_ring->send_idx, remainder);\r\n}\r\nif (INDEX10(tx_ring->send_idx) == 0) {\r\nif (tx_ring->send_idx)\r\ntcb->index = NUM_DESC_PER_RING_TX - 1;\r\nelse\r\ntcb->index = ET_DMA10_WRAP|(NUM_DESC_PER_RING_TX - 1);\r\n} else {\r\ntcb->index = tx_ring->send_idx - 1;\r\n}\r\nspin_lock(&adapter->tcb_send_qlock);\r\nif (tx_ring->send_tail)\r\ntx_ring->send_tail->next = tcb;\r\nelse\r\ntx_ring->send_head = tcb;\r\ntx_ring->send_tail = tcb;\r\nWARN_ON(tcb->next != NULL);\r\ntx_ring->used++;\r\nspin_unlock(&adapter->tcb_send_qlock);\r\nwritel(tx_ring->send_idx, &adapter->regs->txdma.service_request);\r\nif (phydev && phydev->speed == SPEED_1000) {\r\nwritel(PARM_TX_TIME_INT_DEF * NANO_IN_A_MICRO,\r\n&adapter->regs->global.watchdog_timer);\r\n}\r\nreturn 0;\r\n}\r\nstatic int send_packet(struct sk_buff *skb, struct et131x_adapter *adapter)\r\n{\r\nint status;\r\nstruct tcb *tcb;\r\nunsigned long flags;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nif (skb->len < ETH_HLEN)\r\nreturn -EIO;\r\nspin_lock_irqsave(&adapter->tcb_ready_qlock, flags);\r\ntcb = tx_ring->tcb_qhead;\r\nif (tcb == NULL) {\r\nspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\r\nreturn -ENOMEM;\r\n}\r\ntx_ring->tcb_qhead = tcb->next;\r\nif (tx_ring->tcb_qhead == NULL)\r\ntx_ring->tcb_qtail = NULL;\r\nspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\r\ntcb->skb = skb;\r\ntcb->next = NULL;\r\nstatus = nic_send_packet(adapter, tcb);\r\nif (status != 0) {\r\nspin_lock_irqsave(&adapter->tcb_ready_qlock, flags);\r\nif (tx_ring->tcb_qtail)\r\ntx_ring->tcb_qtail->next = tcb;\r\nelse\r\ntx_ring->tcb_qhead = tcb;\r\ntx_ring->tcb_qtail = tcb;\r\nspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\r\nreturn status;\r\n}\r\nWARN_ON(tx_ring->used > NUM_TCB);\r\nreturn 0;\r\n}\r\nstatic inline void free_send_packet(struct et131x_adapter *adapter,\r\nstruct tcb *tcb)\r\n{\r\nunsigned long flags;\r\nstruct tx_desc *desc = NULL;\r\nstruct net_device_stats *stats = &adapter->netdev->stats;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nu64 dma_addr;\r\nif (tcb->skb) {\r\nstats->tx_bytes += tcb->skb->len;\r\ndo {\r\ndesc = tx_ring->tx_desc_ring +\r\nINDEX10(tcb->index_start);\r\ndma_addr = desc->addr_lo;\r\ndma_addr |= (u64)desc->addr_hi << 32;\r\ndma_unmap_single(&adapter->pdev->dev,\r\ndma_addr,\r\ndesc->len_vlan, DMA_TO_DEVICE);\r\nadd_10bit(&tcb->index_start, 1);\r\nif (INDEX10(tcb->index_start) >=\r\nNUM_DESC_PER_RING_TX) {\r\ntcb->index_start &= ~ET_DMA10_MASK;\r\ntcb->index_start ^= ET_DMA10_WRAP;\r\n}\r\n} while (desc != tx_ring->tx_desc_ring + INDEX10(tcb->index));\r\ndev_kfree_skb_any(tcb->skb);\r\n}\r\nmemset(tcb, 0, sizeof(struct tcb));\r\nspin_lock_irqsave(&adapter->tcb_ready_qlock, flags);\r\nstats->tx_packets++;\r\nif (tx_ring->tcb_qtail)\r\ntx_ring->tcb_qtail->next = tcb;\r\nelse\r\ntx_ring->tcb_qhead = tcb;\r\ntx_ring->tcb_qtail = tcb;\r\nspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\r\nWARN_ON(tx_ring->used < 0);\r\n}\r\nstatic void et131x_free_busy_send_packets(struct et131x_adapter *adapter)\r\n{\r\nstruct tcb *tcb;\r\nunsigned long flags;\r\nu32 freed = 0;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\r\ntcb = tx_ring->send_head;\r\nwhile (tcb != NULL && freed < NUM_TCB) {\r\nstruct tcb *next = tcb->next;\r\ntx_ring->send_head = next;\r\nif (next == NULL)\r\ntx_ring->send_tail = NULL;\r\ntx_ring->used--;\r\nspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\r\nfreed++;\r\nfree_send_packet(adapter, tcb);\r\nspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\r\ntcb = tx_ring->send_head;\r\n}\r\nWARN_ON(freed == NUM_TCB);\r\nspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\r\ntx_ring->used = 0;\r\n}\r\nstatic void et131x_handle_send_pkts(struct et131x_adapter *adapter)\r\n{\r\nunsigned long flags;\r\nu32 serviced;\r\nstruct tcb *tcb;\r\nu32 index;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nserviced = readl(&adapter->regs->txdma.new_service_complete);\r\nindex = INDEX10(serviced);\r\nspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\r\ntcb = tx_ring->send_head;\r\nwhile (tcb &&\r\n((serviced ^ tcb->index) & ET_DMA10_WRAP) &&\r\nindex < INDEX10(tcb->index)) {\r\ntx_ring->used--;\r\ntx_ring->send_head = tcb->next;\r\nif (tcb->next == NULL)\r\ntx_ring->send_tail = NULL;\r\nspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\r\nfree_send_packet(adapter, tcb);\r\nspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\r\ntcb = tx_ring->send_head;\r\n}\r\nwhile (tcb &&\r\n!((serviced ^ tcb->index) & ET_DMA10_WRAP) &&\r\nindex > (tcb->index & ET_DMA10_MASK)) {\r\ntx_ring->used--;\r\ntx_ring->send_head = tcb->next;\r\nif (tcb->next == NULL)\r\ntx_ring->send_tail = NULL;\r\nspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\r\nfree_send_packet(adapter, tcb);\r\nspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\r\ntcb = tx_ring->send_head;\r\n}\r\nif (tx_ring->used <= NUM_TCB / 3)\r\nnetif_wake_queue(adapter->netdev);\r\nspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\r\n}\r\nstatic int et131x_get_settings(struct net_device *netdev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nreturn phy_ethtool_gset(adapter->phydev, cmd);\r\n}\r\nstatic int et131x_set_settings(struct net_device *netdev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nreturn phy_ethtool_sset(adapter->phydev, cmd);\r\n}\r\nstatic int et131x_get_regs_len(struct net_device *netdev)\r\n{\r\n#define ET131X_REGS_LEN 256\r\nreturn ET131X_REGS_LEN * sizeof(u32);\r\n}\r\nstatic void et131x_get_regs(struct net_device *netdev,\r\nstruct ethtool_regs *regs, void *regs_data)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct address_map __iomem *aregs = adapter->regs;\r\nu32 *regs_buff = regs_data;\r\nu32 num = 0;\r\nu16 tmp;\r\nmemset(regs_data, 0, et131x_get_regs_len(netdev));\r\nregs->version = (1 << 24) | (adapter->pdev->revision << 16) |\r\nadapter->pdev->device;\r\net131x_mii_read(adapter, MII_BMCR, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_BMSR, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_PHYSID1, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_PHYSID2, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_ADVERTISE, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_LPA, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_EXPANSION, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, 0x07, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, 0x08, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_CTRL1000, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_STAT1000, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, 0x0b, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, 0x0c, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_MMD_CTRL, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_MMD_DATA, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, MII_ESTATUS, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_INDEX_REG, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_DATA_REG, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_MPHY_CONTROL_REG, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_LOOPBACK_CONTROL, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_LOOPBACK_CONTROL + 1, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_REGISTER_MGMT_CONTROL, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_CONFIG, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_PHY_CONTROL, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_INTERRUPT_MASK, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_INTERRUPT_STATUS, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_PHY_STATUS, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_LED_1, &tmp);\r\nregs_buff[num++] = tmp;\r\net131x_mii_read(adapter, PHY_LED_2, &tmp);\r\nregs_buff[num++] = tmp;\r\nregs_buff[num++] = readl(&aregs->global.txq_start_addr);\r\nregs_buff[num++] = readl(&aregs->global.txq_end_addr);\r\nregs_buff[num++] = readl(&aregs->global.rxq_start_addr);\r\nregs_buff[num++] = readl(&aregs->global.rxq_end_addr);\r\nregs_buff[num++] = readl(&aregs->global.pm_csr);\r\nregs_buff[num++] = adapter->stats.interrupt_status;\r\nregs_buff[num++] = readl(&aregs->global.int_mask);\r\nregs_buff[num++] = readl(&aregs->global.int_alias_clr_en);\r\nregs_buff[num++] = readl(&aregs->global.int_status_alias);\r\nregs_buff[num++] = readl(&aregs->global.sw_reset);\r\nregs_buff[num++] = readl(&aregs->global.slv_timer);\r\nregs_buff[num++] = readl(&aregs->global.msi_config);\r\nregs_buff[num++] = readl(&aregs->global.loopback);\r\nregs_buff[num++] = readl(&aregs->global.watchdog_timer);\r\nregs_buff[num++] = readl(&aregs->txdma.csr);\r\nregs_buff[num++] = readl(&aregs->txdma.pr_base_hi);\r\nregs_buff[num++] = readl(&aregs->txdma.pr_base_lo);\r\nregs_buff[num++] = readl(&aregs->txdma.pr_num_des);\r\nregs_buff[num++] = readl(&aregs->txdma.txq_wr_addr);\r\nregs_buff[num++] = readl(&aregs->txdma.txq_wr_addr_ext);\r\nregs_buff[num++] = readl(&aregs->txdma.txq_rd_addr);\r\nregs_buff[num++] = readl(&aregs->txdma.dma_wb_base_hi);\r\nregs_buff[num++] = readl(&aregs->txdma.dma_wb_base_lo);\r\nregs_buff[num++] = readl(&aregs->txdma.service_request);\r\nregs_buff[num++] = readl(&aregs->txdma.service_complete);\r\nregs_buff[num++] = readl(&aregs->txdma.cache_rd_index);\r\nregs_buff[num++] = readl(&aregs->txdma.cache_wr_index);\r\nregs_buff[num++] = readl(&aregs->txdma.tx_dma_error);\r\nregs_buff[num++] = readl(&aregs->txdma.desc_abort_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.payload_abort_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.writeback_abort_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.desc_timeout_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.payload_timeout_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.writeback_timeout_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.desc_error_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.payload_error_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.writeback_error_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.dropped_tlp_cnt);\r\nregs_buff[num++] = readl(&aregs->txdma.new_service_complete);\r\nregs_buff[num++] = readl(&aregs->txdma.ethernet_packet_cnt);\r\nregs_buff[num++] = readl(&aregs->rxdma.csr);\r\nregs_buff[num++] = readl(&aregs->rxdma.dma_wb_base_hi);\r\nregs_buff[num++] = readl(&aregs->rxdma.dma_wb_base_lo);\r\nregs_buff[num++] = readl(&aregs->rxdma.num_pkt_done);\r\nregs_buff[num++] = readl(&aregs->rxdma.max_pkt_time);\r\nregs_buff[num++] = readl(&aregs->rxdma.rxq_rd_addr);\r\nregs_buff[num++] = readl(&aregs->rxdma.rxq_rd_addr_ext);\r\nregs_buff[num++] = readl(&aregs->rxdma.rxq_wr_addr);\r\nregs_buff[num++] = readl(&aregs->rxdma.psr_base_hi);\r\nregs_buff[num++] = readl(&aregs->rxdma.psr_base_lo);\r\nregs_buff[num++] = readl(&aregs->rxdma.psr_num_des);\r\nregs_buff[num++] = readl(&aregs->rxdma.psr_avail_offset);\r\nregs_buff[num++] = readl(&aregs->rxdma.psr_full_offset);\r\nregs_buff[num++] = readl(&aregs->rxdma.psr_access_index);\r\nregs_buff[num++] = readl(&aregs->rxdma.psr_min_des);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr0_base_lo);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr0_base_hi);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr0_num_des);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr0_avail_offset);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr0_full_offset);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr0_rd_index);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr0_min_des);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr1_base_lo);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr1_base_hi);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr1_num_des);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr1_avail_offset);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr1_full_offset);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr1_rd_index);\r\nregs_buff[num++] = readl(&aregs->rxdma.fbr1_min_des);\r\n}\r\nstatic void et131x_get_drvinfo(struct net_device *netdev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstrlcpy(info->driver, DRIVER_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRIVER_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(adapter->pdev),\r\nsizeof(info->bus_info));\r\n}\r\nstatic void et131x_hwaddr_init(struct et131x_adapter *adapter)\r\n{\r\nif (is_zero_ether_addr(adapter->rom_addr)) {\r\nget_random_bytes(&adapter->addr[5], 1);\r\nether_addr_copy(adapter->rom_addr, adapter->addr);\r\n} else {\r\nether_addr_copy(adapter->addr, adapter->rom_addr);\r\n}\r\n}\r\nstatic int et131x_pci_init(struct et131x_adapter *adapter,\r\nstruct pci_dev *pdev)\r\n{\r\nu16 max_payload;\r\nint i, rc;\r\nrc = et131x_init_eeprom(adapter);\r\nif (rc < 0)\r\ngoto out;\r\nif (!pci_is_pcie(pdev)) {\r\ndev_err(&pdev->dev, "Missing PCIe capabilities\n");\r\ngoto err_out;\r\n}\r\nmax_payload = pdev->pcie_mpss;\r\nif (max_payload < 2) {\r\nstatic const u16 acknak[2] = { 0x76, 0xD0 };\r\nstatic const u16 replay[2] = { 0x1E0, 0x2ED };\r\nif (pci_write_config_word(pdev, ET1310_PCI_ACK_NACK,\r\nacknak[max_payload])) {\r\ndev_err(&pdev->dev,\r\n"Could not write PCI config space for ACK/NAK\n");\r\ngoto err_out;\r\n}\r\nif (pci_write_config_word(pdev, ET1310_PCI_REPLAY,\r\nreplay[max_payload])) {\r\ndev_err(&pdev->dev,\r\n"Could not write PCI config space for Replay Timer\n");\r\ngoto err_out;\r\n}\r\n}\r\nif (pci_write_config_byte(pdev, ET1310_PCI_L0L1LATENCY, 0x11)) {\r\ndev_err(&pdev->dev,\r\n"Could not write PCI config space for Latency Timers\n");\r\ngoto err_out;\r\n}\r\nif (pcie_set_readrq(pdev, 2048)) {\r\ndev_err(&pdev->dev,\r\n"Couldn't change PCI config space for Max read size\n");\r\ngoto err_out;\r\n}\r\nif (!adapter->has_eeprom) {\r\net131x_hwaddr_init(adapter);\r\nreturn 0;\r\n}\r\nfor (i = 0; i < ETH_ALEN; i++) {\r\nif (pci_read_config_byte(pdev, ET1310_PCI_MAC_ADDRESS + i,\r\nadapter->rom_addr + i)) {\r\ndev_err(&pdev->dev, "Could not read PCI config space for MAC address\n");\r\ngoto err_out;\r\n}\r\n}\r\nether_addr_copy(adapter->addr, adapter->rom_addr);\r\nout:\r\nreturn rc;\r\nerr_out:\r\nrc = -EIO;\r\ngoto out;\r\n}\r\nstatic void et131x_error_timer_handler(unsigned long data)\r\n{\r\nstruct et131x_adapter *adapter = (struct et131x_adapter *)data;\r\nstruct phy_device *phydev = adapter->phydev;\r\nif (et1310_in_phy_coma(adapter)) {\r\net1310_disable_phy_coma(adapter);\r\nadapter->boot_coma = 20;\r\n} else {\r\net1310_update_macstat_host_counters(adapter);\r\n}\r\nif (!phydev->link && adapter->boot_coma < 11)\r\nadapter->boot_coma++;\r\nif (adapter->boot_coma == 10) {\r\nif (!phydev->link) {\r\nif (!et1310_in_phy_coma(adapter)) {\r\net131x_enable_interrupts(adapter);\r\net1310_enable_phy_coma(adapter);\r\n}\r\n}\r\n}\r\nmod_timer(&adapter->error_timer, jiffies +\r\nmsecs_to_jiffies(TX_ERROR_PERIOD));\r\n}\r\nstatic void et131x_adapter_memory_free(struct et131x_adapter *adapter)\r\n{\r\net131x_tx_dma_memory_free(adapter);\r\net131x_rx_dma_memory_free(adapter);\r\n}\r\nstatic int et131x_adapter_memory_alloc(struct et131x_adapter *adapter)\r\n{\r\nint status;\r\nstatus = et131x_tx_dma_memory_alloc(adapter);\r\nif (status) {\r\ndev_err(&adapter->pdev->dev,\r\n"et131x_tx_dma_memory_alloc FAILED\n");\r\net131x_tx_dma_memory_free(adapter);\r\nreturn status;\r\n}\r\nstatus = et131x_rx_dma_memory_alloc(adapter);\r\nif (status) {\r\ndev_err(&adapter->pdev->dev,\r\n"et131x_rx_dma_memory_alloc FAILED\n");\r\net131x_adapter_memory_free(adapter);\r\nreturn status;\r\n}\r\nstatus = et131x_init_recv(adapter);\r\nif (status) {\r\ndev_err(&adapter->pdev->dev, "et131x_init_recv FAILED\n");\r\net131x_adapter_memory_free(adapter);\r\n}\r\nreturn status;\r\n}\r\nstatic void et131x_adjust_link(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct phy_device *phydev = adapter->phydev;\r\nif (!phydev)\r\nreturn;\r\nif (phydev->link == adapter->link)\r\nreturn;\r\nif (et1310_in_phy_coma(adapter))\r\net1310_disable_phy_coma(adapter);\r\nadapter->link = phydev->link;\r\nphy_print_status(phydev);\r\nif (phydev->link) {\r\nadapter->boot_coma = 20;\r\nif (phydev->speed == SPEED_10) {\r\nu16 register18;\r\net131x_mii_read(adapter, PHY_MPHY_CONTROL_REG,\r\n&register18);\r\net131x_mii_write(adapter, phydev->addr,\r\nPHY_MPHY_CONTROL_REG,\r\nregister18 | 0x4);\r\net131x_mii_write(adapter, phydev->addr, PHY_INDEX_REG,\r\nregister18 | 0x8402);\r\net131x_mii_write(adapter, phydev->addr, PHY_DATA_REG,\r\nregister18 | 511);\r\net131x_mii_write(adapter, phydev->addr,\r\nPHY_MPHY_CONTROL_REG, register18);\r\n}\r\net1310_config_flow_control(adapter);\r\nif (phydev->speed == SPEED_1000 &&\r\nadapter->registry_jumbo_packet > 2048) {\r\nu16 reg;\r\net131x_mii_read(adapter, PHY_CONFIG, &reg);\r\nreg &= ~ET_PHY_CONFIG_TX_FIFO_DEPTH;\r\nreg |= ET_PHY_CONFIG_FIFO_DEPTH_32;\r\net131x_mii_write(adapter, phydev->addr, PHY_CONFIG,\r\nreg);\r\n}\r\net131x_set_rx_dma_timer(adapter);\r\net1310_config_mac_regs2(adapter);\r\n} else {\r\nadapter->boot_coma = 0;\r\nif (phydev->speed == SPEED_10) {\r\nu16 register18;\r\net131x_mii_read(adapter, PHY_MPHY_CONTROL_REG,\r\n&register18);\r\net131x_mii_write(adapter, phydev->addr,\r\nPHY_MPHY_CONTROL_REG,\r\nregister18 | 0x4);\r\net131x_mii_write(adapter, phydev->addr,\r\nPHY_INDEX_REG, register18 | 0x8402);\r\net131x_mii_write(adapter, phydev->addr,\r\nPHY_DATA_REG, register18 | 511);\r\net131x_mii_write(adapter, phydev->addr,\r\nPHY_MPHY_CONTROL_REG, register18);\r\n}\r\net131x_free_busy_send_packets(adapter);\r\net131x_init_send(adapter);\r\net131x_soft_reset(adapter);\r\net131x_adapter_setup(adapter);\r\net131x_disable_txrx(netdev);\r\net131x_enable_txrx(netdev);\r\n}\r\n}\r\nstatic int et131x_mii_probe(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct phy_device *phydev = NULL;\r\nphydev = phy_find_first(adapter->mii_bus);\r\nif (!phydev) {\r\ndev_err(&adapter->pdev->dev, "no PHY found\n");\r\nreturn -ENODEV;\r\n}\r\nphydev = phy_connect(netdev, dev_name(&phydev->dev),\r\n&et131x_adjust_link, PHY_INTERFACE_MODE_MII);\r\nif (IS_ERR(phydev)) {\r\ndev_err(&adapter->pdev->dev, "Could not attach to PHY\n");\r\nreturn PTR_ERR(phydev);\r\n}\r\nphydev->supported &= (SUPPORTED_10baseT_Half |\r\nSUPPORTED_10baseT_Full |\r\nSUPPORTED_100baseT_Half |\r\nSUPPORTED_100baseT_Full |\r\nSUPPORTED_Autoneg |\r\nSUPPORTED_MII |\r\nSUPPORTED_TP);\r\nif (adapter->pdev->device != ET131X_PCI_DEVICE_ID_FAST)\r\nphydev->supported |= SUPPORTED_1000baseT_Half |\r\nSUPPORTED_1000baseT_Full;\r\nphydev->advertising = phydev->supported;\r\nphydev->autoneg = AUTONEG_ENABLE;\r\nadapter->phydev = phydev;\r\ndev_info(&adapter->pdev->dev,\r\n"attached PHY driver [%s] (mii_bus:phy_addr=%s)\n",\r\nphydev->drv->name, dev_name(&phydev->dev));\r\nreturn 0;\r\n}\r\nstatic struct et131x_adapter *et131x_adapter_init(struct net_device *netdev,\r\nstruct pci_dev *pdev)\r\n{\r\nstatic const u8 default_mac[] = { 0x00, 0x05, 0x3d, 0x00, 0x02, 0x00 };\r\nstruct et131x_adapter *adapter;\r\nadapter = netdev_priv(netdev);\r\nadapter->pdev = pci_dev_get(pdev);\r\nadapter->netdev = netdev;\r\nspin_lock_init(&adapter->tcb_send_qlock);\r\nspin_lock_init(&adapter->tcb_ready_qlock);\r\nspin_lock_init(&adapter->rcv_lock);\r\nadapter->registry_jumbo_packet = 1514;\r\nether_addr_copy(adapter->addr, default_mac);\r\nreturn adapter;\r\n}\r\nstatic void et131x_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nunregister_netdev(netdev);\r\nnetif_napi_del(&adapter->napi);\r\nphy_disconnect(adapter->phydev);\r\nmdiobus_unregister(adapter->mii_bus);\r\nkfree(adapter->mii_bus->irq);\r\nmdiobus_free(adapter->mii_bus);\r\net131x_adapter_memory_free(adapter);\r\niounmap(adapter->regs);\r\npci_dev_put(pdev);\r\nfree_netdev(netdev);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic void et131x_up(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\net131x_enable_txrx(netdev);\r\nphy_start(adapter->phydev);\r\n}\r\nstatic void et131x_down(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nnetdev->trans_start = jiffies;\r\nphy_stop(adapter->phydev);\r\net131x_disable_txrx(netdev);\r\n}\r\nstatic int et131x_suspend(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nif (netif_running(netdev)) {\r\nnetif_device_detach(netdev);\r\net131x_down(netdev);\r\npci_save_state(pdev);\r\n}\r\nreturn 0;\r\n}\r\nstatic int et131x_resume(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nif (netif_running(netdev)) {\r\npci_restore_state(pdev);\r\net131x_up(netdev);\r\nnetif_device_attach(netdev);\r\n}\r\nreturn 0;\r\n}\r\nstatic irqreturn_t et131x_isr(int irq, void *dev_id)\r\n{\r\nbool handled = true;\r\nbool enable_interrupts = true;\r\nstruct net_device *netdev = dev_id;\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct address_map __iomem *iomem = adapter->regs;\r\nstruct rx_ring *rx_ring = &adapter->rx_ring;\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nu32 status;\r\nif (!netif_device_present(netdev)) {\r\nhandled = false;\r\nenable_interrupts = false;\r\ngoto out;\r\n}\r\net131x_disable_interrupts(adapter);\r\nstatus = readl(&adapter->regs->global.int_status);\r\nif (adapter->flow == FLOW_TXONLY || adapter->flow == FLOW_BOTH)\r\nstatus &= ~INT_MASK_ENABLE;\r\nelse\r\nstatus &= ~INT_MASK_ENABLE_NO_FLOW;\r\nif (!status) {\r\nhandled = false;\r\net131x_enable_interrupts(adapter);\r\ngoto out;\r\n}\r\nif (status & ET_INTR_WATCHDOG) {\r\nstruct tcb *tcb = tx_ring->send_head;\r\nif (tcb)\r\nif (++tcb->stale > 1)\r\nstatus |= ET_INTR_TXDMA_ISR;\r\nif (rx_ring->unfinished_receives)\r\nstatus |= ET_INTR_RXDMA_XFR_DONE;\r\nelse if (tcb == NULL)\r\nwritel(0, &adapter->regs->global.watchdog_timer);\r\nstatus &= ~ET_INTR_WATCHDOG;\r\n}\r\nif (status & (ET_INTR_RXDMA_XFR_DONE | ET_INTR_TXDMA_ISR)) {\r\nenable_interrupts = false;\r\nnapi_schedule(&adapter->napi);\r\n}\r\nstatus &= ~(ET_INTR_TXDMA_ISR | ET_INTR_RXDMA_XFR_DONE);\r\nif (!status)\r\ngoto out;\r\nif (status & ET_INTR_TXDMA_ERR) {\r\nu32 txdma_err = readl(&iomem->txdma.tx_dma_error);\r\ndev_warn(&adapter->pdev->dev,\r\n"TXDMA_ERR interrupt, error = %d\n",\r\ntxdma_err);\r\n}\r\nif (status & (ET_INTR_RXDMA_FB_R0_LOW | ET_INTR_RXDMA_FB_R1_LOW)) {\r\nif (adapter->flow == FLOW_TXONLY || adapter->flow == FLOW_BOTH) {\r\nu32 pm_csr;\r\npm_csr = readl(&iomem->global.pm_csr);\r\nif (!et1310_in_phy_coma(adapter))\r\nwritel(3, &iomem->txmac.bp_ctrl);\r\n}\r\n}\r\nif (status & ET_INTR_RXDMA_STAT_LOW) {\r\n}\r\nif (status & ET_INTR_RXDMA_ERR) {\r\ndev_warn(&adapter->pdev->dev, "RxDMA_ERR interrupt, error %x\n",\r\nreadl(&iomem->txmac.tx_test));\r\n}\r\nif (status & ET_INTR_WOL) {\r\ndev_err(&adapter->pdev->dev, "WAKE_ON_LAN interrupt\n");\r\n}\r\nif (status & ET_INTR_TXMAC) {\r\nu32 err = readl(&iomem->txmac.err);\r\ndev_warn(&adapter->pdev->dev, "TXMAC interrupt, error 0x%08x\n",\r\nerr);\r\n}\r\nif (status & ET_INTR_RXMAC) {\r\ndev_warn(&adapter->pdev->dev,\r\n"RXMAC interrupt, error 0x%08x. Requesting reset\n",\r\nreadl(&iomem->rxmac.err_reg));\r\ndev_warn(&adapter->pdev->dev,\r\n"Enable 0x%08x, Diag 0x%08x\n",\r\nreadl(&iomem->rxmac.ctrl),\r\nreadl(&iomem->rxmac.rxq_diag));\r\n}\r\nif (status & ET_INTR_MAC_STAT) {\r\net1310_handle_macstat_interrupt(adapter);\r\n}\r\nif (status & ET_INTR_SLV_TIMEOUT) {\r\n}\r\nout:\r\nif (enable_interrupts)\r\net131x_enable_interrupts(adapter);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic int et131x_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct et131x_adapter *adapter =\r\ncontainer_of(napi, struct et131x_adapter, napi);\r\nint work_done = et131x_handle_recv_pkts(adapter, budget);\r\net131x_handle_send_pkts(adapter);\r\nif (work_done < budget) {\r\nnapi_complete(&adapter->napi);\r\net131x_enable_interrupts(adapter);\r\n}\r\nreturn work_done;\r\n}\r\nstatic struct net_device_stats *et131x_stats(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct net_device_stats *stats = &adapter->netdev->stats;\r\nstruct ce_stats *devstat = &adapter->stats;\r\nstats->rx_errors = devstat->rx_length_errs +\r\ndevstat->rx_align_errs +\r\ndevstat->rx_crc_errs +\r\ndevstat->rx_code_violations +\r\ndevstat->rx_other_errs;\r\nstats->tx_errors = devstat->tx_max_pkt_errs;\r\nstats->multicast = devstat->multicast_pkts_rcvd;\r\nstats->collisions = devstat->tx_collisions;\r\nstats->rx_length_errors = devstat->rx_length_errs;\r\nstats->rx_over_errors = devstat->rx_overflows;\r\nstats->rx_crc_errors = devstat->rx_crc_errs;\r\nstats->rx_dropped = devstat->rcvd_pkts_dropped;\r\nreturn stats;\r\n}\r\nstatic int et131x_open(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct pci_dev *pdev = adapter->pdev;\r\nunsigned int irq = pdev->irq;\r\nint result;\r\ninit_timer(&adapter->error_timer);\r\nadapter->error_timer.expires = jiffies +\r\nmsecs_to_jiffies(TX_ERROR_PERIOD);\r\nadapter->error_timer.function = et131x_error_timer_handler;\r\nadapter->error_timer.data = (unsigned long)adapter;\r\nadd_timer(&adapter->error_timer);\r\nresult = request_irq(irq, et131x_isr,\r\nIRQF_SHARED, netdev->name, netdev);\r\nif (result) {\r\ndev_err(&pdev->dev, "could not register IRQ %d\n", irq);\r\nreturn result;\r\n}\r\nadapter->flags |= FMP_ADAPTER_INTERRUPT_IN_USE;\r\nnapi_enable(&adapter->napi);\r\net131x_up(netdev);\r\nreturn result;\r\n}\r\nstatic int et131x_close(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\net131x_down(netdev);\r\nnapi_disable(&adapter->napi);\r\nadapter->flags &= ~FMP_ADAPTER_INTERRUPT_IN_USE;\r\nfree_irq(adapter->pdev->irq, netdev);\r\nreturn del_timer_sync(&adapter->error_timer);\r\n}\r\nstatic int et131x_ioctl(struct net_device *netdev, struct ifreq *reqbuf,\r\nint cmd)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nif (!adapter->phydev)\r\nreturn -EINVAL;\r\nreturn phy_mii_ioctl(adapter->phydev, reqbuf, cmd);\r\n}\r\nstatic int et131x_set_packet_filter(struct et131x_adapter *adapter)\r\n{\r\nint filter = adapter->packet_filter;\r\nu32 ctrl;\r\nu32 pf_ctrl;\r\nctrl = readl(&adapter->regs->rxmac.ctrl);\r\npf_ctrl = readl(&adapter->regs->rxmac.pf_ctrl);\r\nctrl |= 0x04;\r\nif ((filter & ET131X_PACKET_TYPE_PROMISCUOUS) || filter == 0)\r\npf_ctrl &= ~7;\r\nelse {\r\nif (filter & ET131X_PACKET_TYPE_ALL_MULTICAST)\r\npf_ctrl &= ~2;\r\nelse {\r\net1310_setup_device_for_multicast(adapter);\r\npf_ctrl |= 2;\r\nctrl &= ~0x04;\r\n}\r\nif (filter & ET131X_PACKET_TYPE_DIRECTED) {\r\net1310_setup_device_for_unicast(adapter);\r\npf_ctrl |= 4;\r\nctrl &= ~0x04;\r\n}\r\nif (filter & ET131X_PACKET_TYPE_BROADCAST) {\r\npf_ctrl |= 1;\r\nctrl &= ~0x04;\r\n} else {\r\npf_ctrl &= ~1;\r\n}\r\nwritel(pf_ctrl, &adapter->regs->rxmac.pf_ctrl);\r\nwritel(ctrl, &adapter->regs->rxmac.ctrl);\r\n}\r\nreturn 0;\r\n}\r\nstatic void et131x_multicast(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nint packet_filter;\r\nstruct netdev_hw_addr *ha;\r\nint i;\r\npacket_filter = adapter->packet_filter;\r\npacket_filter &= ~ET131X_PACKET_TYPE_MULTICAST;\r\nif (netdev->flags & IFF_PROMISC)\r\nadapter->packet_filter |= ET131X_PACKET_TYPE_PROMISCUOUS;\r\nelse\r\nadapter->packet_filter &= ~ET131X_PACKET_TYPE_PROMISCUOUS;\r\nif ((netdev->flags & IFF_ALLMULTI) ||\r\n(netdev_mc_count(netdev) > NIC_MAX_MCAST_LIST))\r\nadapter->packet_filter |= ET131X_PACKET_TYPE_ALL_MULTICAST;\r\nif (netdev_mc_count(netdev) < 1) {\r\nadapter->packet_filter &= ~ET131X_PACKET_TYPE_ALL_MULTICAST;\r\nadapter->packet_filter &= ~ET131X_PACKET_TYPE_MULTICAST;\r\n} else {\r\nadapter->packet_filter |= ET131X_PACKET_TYPE_MULTICAST;\r\n}\r\ni = 0;\r\nnetdev_for_each_mc_addr(ha, netdev) {\r\nif (i == NIC_MAX_MCAST_LIST)\r\nbreak;\r\nether_addr_copy(adapter->multicast_list[i++], ha->addr);\r\n}\r\nadapter->multicast_addr_count = i;\r\nif (packet_filter != adapter->packet_filter)\r\net131x_set_packet_filter(adapter);\r\n}\r\nstatic netdev_tx_t et131x_tx(struct sk_buff *skb, struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nif (tx_ring->used >= NUM_TCB - 1 && !netif_queue_stopped(netdev))\r\nnetif_stop_queue(netdev);\r\nnetdev->trans_start = jiffies;\r\nif (tx_ring->used >= NUM_TCB)\r\ngoto drop_err;\r\nif ((adapter->flags & FMP_ADAPTER_FAIL_SEND_MASK) ||\r\n!netif_carrier_ok(netdev))\r\ngoto drop_err;\r\nif (send_packet(skb, adapter))\r\ngoto drop_err;\r\nreturn NETDEV_TX_OK;\r\ndrop_err:\r\ndev_kfree_skb_any(skb);\r\nadapter->netdev->stats.tx_dropped++;\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void et131x_tx_timeout(struct net_device *netdev)\r\n{\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nstruct tx_ring *tx_ring = &adapter->tx_ring;\r\nstruct tcb *tcb;\r\nunsigned long flags;\r\nif (~(adapter->flags & FMP_ADAPTER_INTERRUPT_IN_USE))\r\nreturn;\r\nif (adapter->flags & FMP_ADAPTER_NON_RECOVER_ERROR)\r\nreturn;\r\nif (adapter->flags & FMP_ADAPTER_HARDWARE_ERROR) {\r\ndev_err(&adapter->pdev->dev, "hardware error - reset\n");\r\nreturn;\r\n}\r\nspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\r\ntcb = tx_ring->send_head;\r\nspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\r\nif (tcb) {\r\ntcb->count++;\r\nif (tcb->count > NIC_SEND_HANG_THRESHOLD) {\r\ndev_warn(&adapter->pdev->dev,\r\n"Send stuck - reset. tcb->WrIndex %x\n",\r\ntcb->index);\r\nadapter->netdev->stats.tx_errors++;\r\net131x_disable_txrx(netdev);\r\net131x_enable_txrx(netdev);\r\n}\r\n}\r\n}\r\nstatic int et131x_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nint result = 0;\r\nstruct et131x_adapter *adapter = netdev_priv(netdev);\r\nif (new_mtu < 64 || new_mtu > 9216)\r\nreturn -EINVAL;\r\net131x_disable_txrx(netdev);\r\nnetdev->mtu = new_mtu;\r\net131x_adapter_memory_free(adapter);\r\nadapter->registry_jumbo_packet = new_mtu + 14;\r\net131x_soft_reset(adapter);\r\nresult = et131x_adapter_memory_alloc(adapter);\r\nif (result != 0) {\r\ndev_warn(&adapter->pdev->dev,\r\n"Change MTU failed; couldn't re-alloc DMA memory\n");\r\nreturn result;\r\n}\r\net131x_init_send(adapter);\r\net131x_hwaddr_init(adapter);\r\nether_addr_copy(netdev->dev_addr, adapter->addr);\r\net131x_adapter_setup(adapter);\r\net131x_enable_txrx(netdev);\r\nreturn result;\r\n}\r\nstatic int et131x_pci_setup(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nstruct net_device *netdev;\r\nstruct et131x_adapter *adapter;\r\nint rc;\r\nint ii;\r\nrc = pci_enable_device(pdev);\r\nif (rc < 0) {\r\ndev_err(&pdev->dev, "pci_enable_device() failed\n");\r\ngoto out;\r\n}\r\nif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\r\ndev_err(&pdev->dev, "Can't find PCI device's base address\n");\r\nrc = -ENODEV;\r\ngoto err_disable;\r\n}\r\nrc = pci_request_regions(pdev, DRIVER_NAME);\r\nif (rc < 0) {\r\ndev_err(&pdev->dev, "Can't get PCI resources\n");\r\ngoto err_disable;\r\n}\r\npci_set_master(pdev);\r\nif (dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64)) &&\r\ndma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32))) {\r\ndev_err(&pdev->dev, "No usable DMA addressing method\n");\r\nrc = -EIO;\r\ngoto err_release_res;\r\n}\r\nnetdev = alloc_etherdev(sizeof(struct et131x_adapter));\r\nif (!netdev) {\r\ndev_err(&pdev->dev, "Couldn't alloc netdev struct\n");\r\nrc = -ENOMEM;\r\ngoto err_release_res;\r\n}\r\nnetdev->watchdog_timeo = ET131X_TX_TIMEOUT;\r\nnetdev->netdev_ops = &et131x_netdev_ops;\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\nnetdev->ethtool_ops = &et131x_ethtool_ops;\r\nadapter = et131x_adapter_init(netdev, pdev);\r\nrc = et131x_pci_init(adapter, pdev);\r\nif (rc < 0)\r\ngoto err_free_dev;\r\nadapter->regs = pci_ioremap_bar(pdev, 0);\r\nif (!adapter->regs) {\r\ndev_err(&pdev->dev, "Cannot map device registers\n");\r\nrc = -ENOMEM;\r\ngoto err_free_dev;\r\n}\r\nwritel(ET_PMCSR_INIT, &adapter->regs->global.pm_csr);\r\net131x_soft_reset(adapter);\r\net131x_disable_interrupts(adapter);\r\nrc = et131x_adapter_memory_alloc(adapter);\r\nif (rc < 0) {\r\ndev_err(&pdev->dev, "Could not alloc adapter memory (DMA)\n");\r\ngoto err_iounmap;\r\n}\r\net131x_init_send(adapter);\r\nnetif_napi_add(netdev, &adapter->napi, et131x_poll, 64);\r\nether_addr_copy(netdev->dev_addr, adapter->addr);\r\nrc = -ENOMEM;\r\nadapter->mii_bus = mdiobus_alloc();\r\nif (!adapter->mii_bus) {\r\ndev_err(&pdev->dev, "Alloc of mii_bus struct failed\n");\r\ngoto err_mem_free;\r\n}\r\nadapter->mii_bus->name = "et131x_eth_mii";\r\nsnprintf(adapter->mii_bus->id, MII_BUS_ID_SIZE, "%x",\r\n(adapter->pdev->bus->number << 8) | adapter->pdev->devfn);\r\nadapter->mii_bus->priv = netdev;\r\nadapter->mii_bus->read = et131x_mdio_read;\r\nadapter->mii_bus->write = et131x_mdio_write;\r\nadapter->mii_bus->irq = kmalloc_array(PHY_MAX_ADDR, sizeof(int),\r\nGFP_KERNEL);\r\nif (!adapter->mii_bus->irq)\r\ngoto err_mdio_free;\r\nfor (ii = 0; ii < PHY_MAX_ADDR; ii++)\r\nadapter->mii_bus->irq[ii] = PHY_POLL;\r\nrc = mdiobus_register(adapter->mii_bus);\r\nif (rc < 0) {\r\ndev_err(&pdev->dev, "failed to register MII bus\n");\r\ngoto err_mdio_free_irq;\r\n}\r\nrc = et131x_mii_probe(netdev);\r\nif (rc < 0) {\r\ndev_err(&pdev->dev, "failed to probe MII bus\n");\r\ngoto err_mdio_unregister;\r\n}\r\net131x_adapter_setup(adapter);\r\nadapter->boot_coma = 0;\r\net1310_disable_phy_coma(adapter);\r\nrc = register_netdev(netdev);\r\nif (rc < 0) {\r\ndev_err(&pdev->dev, "register_netdev() failed\n");\r\ngoto err_phy_disconnect;\r\n}\r\npci_set_drvdata(pdev, netdev);\r\nout:\r\nreturn rc;\r\nerr_phy_disconnect:\r\nphy_disconnect(adapter->phydev);\r\nerr_mdio_unregister:\r\nmdiobus_unregister(adapter->mii_bus);\r\nerr_mdio_free_irq:\r\nkfree(adapter->mii_bus->irq);\r\nerr_mdio_free:\r\nmdiobus_free(adapter->mii_bus);\r\nerr_mem_free:\r\net131x_adapter_memory_free(adapter);\r\nerr_iounmap:\r\niounmap(adapter->regs);\r\nerr_free_dev:\r\npci_dev_put(pdev);\r\nfree_netdev(netdev);\r\nerr_release_res:\r\npci_release_regions(pdev);\r\nerr_disable:\r\npci_disable_device(pdev);\r\ngoto out;\r\n}
