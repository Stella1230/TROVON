static unsigned short int fl_mask_range(const struct fl_flow_mask *mask)\r\n{\r\nreturn mask->range.end - mask->range.start;\r\n}\r\nstatic void fl_mask_update_range(struct fl_flow_mask *mask)\r\n{\r\nconst u8 *bytes = (const u8 *) &mask->key;\r\nsize_t size = sizeof(mask->key);\r\nsize_t i, first = 0, last = size - 1;\r\nfor (i = 0; i < sizeof(mask->key); i++) {\r\nif (bytes[i]) {\r\nif (!first && i)\r\nfirst = i;\r\nlast = i;\r\n}\r\n}\r\nmask->range.start = rounddown(first, sizeof(long));\r\nmask->range.end = roundup(last + 1, sizeof(long));\r\n}\r\nstatic void *fl_key_get_start(struct fl_flow_key *key,\r\nconst struct fl_flow_mask *mask)\r\n{\r\nreturn (u8 *) key + mask->range.start;\r\n}\r\nstatic void fl_set_masked_key(struct fl_flow_key *mkey, struct fl_flow_key *key,\r\nstruct fl_flow_mask *mask)\r\n{\r\nconst long *lkey = fl_key_get_start(key, mask);\r\nconst long *lmask = fl_key_get_start(&mask->key, mask);\r\nlong *lmkey = fl_key_get_start(mkey, mask);\r\nint i;\r\nfor (i = 0; i < fl_mask_range(mask); i += sizeof(long))\r\n*lmkey++ = *lkey++ & *lmask++;\r\n}\r\nstatic void fl_clear_masked_range(struct fl_flow_key *key,\r\nstruct fl_flow_mask *mask)\r\n{\r\nmemset(fl_key_get_start(key, mask), 0, fl_mask_range(mask));\r\n}\r\nstatic int fl_classify(struct sk_buff *skb, const struct tcf_proto *tp,\r\nstruct tcf_result *res)\r\n{\r\nstruct cls_fl_head *head = rcu_dereference_bh(tp->root);\r\nstruct cls_fl_filter *f;\r\nstruct fl_flow_key skb_key;\r\nstruct fl_flow_key skb_mkey;\r\nfl_clear_masked_range(&skb_key, &head->mask);\r\nskb_key.indev_ifindex = skb->skb_iif;\r\nskb_key.basic.n_proto = skb->protocol;\r\nskb_flow_dissect(skb, &head->dissector, &skb_key, 0);\r\nfl_set_masked_key(&skb_mkey, &skb_key, &head->mask);\r\nf = rhashtable_lookup_fast(&head->ht,\r\nfl_key_get_start(&skb_mkey, &head->mask),\r\nhead->ht_params);\r\nif (f) {\r\n*res = f->res;\r\nreturn tcf_exts_exec(skb, &f->exts, res);\r\n}\r\nreturn -1;\r\n}\r\nstatic int fl_init(struct tcf_proto *tp)\r\n{\r\nstruct cls_fl_head *head;\r\nhead = kzalloc(sizeof(*head), GFP_KERNEL);\r\nif (!head)\r\nreturn -ENOBUFS;\r\nINIT_LIST_HEAD_RCU(&head->filters);\r\nrcu_assign_pointer(tp->root, head);\r\nreturn 0;\r\n}\r\nstatic void fl_destroy_filter(struct rcu_head *head)\r\n{\r\nstruct cls_fl_filter *f = container_of(head, struct cls_fl_filter, rcu);\r\ntcf_exts_destroy(&f->exts);\r\nkfree(f);\r\n}\r\nstatic bool fl_destroy(struct tcf_proto *tp, bool force)\r\n{\r\nstruct cls_fl_head *head = rtnl_dereference(tp->root);\r\nstruct cls_fl_filter *f, *next;\r\nif (!force && !list_empty(&head->filters))\r\nreturn false;\r\nlist_for_each_entry_safe(f, next, &head->filters, list) {\r\nlist_del_rcu(&f->list);\r\ncall_rcu(&f->rcu, fl_destroy_filter);\r\n}\r\nRCU_INIT_POINTER(tp->root, NULL);\r\nif (head->mask_assigned)\r\nrhashtable_destroy(&head->ht);\r\nkfree_rcu(head, rcu);\r\nreturn true;\r\n}\r\nstatic unsigned long fl_get(struct tcf_proto *tp, u32 handle)\r\n{\r\nstruct cls_fl_head *head = rtnl_dereference(tp->root);\r\nstruct cls_fl_filter *f;\r\nlist_for_each_entry(f, &head->filters, list)\r\nif (f->handle == handle)\r\nreturn (unsigned long) f;\r\nreturn 0;\r\n}\r\nstatic void fl_set_key_val(struct nlattr **tb,\r\nvoid *val, int val_type,\r\nvoid *mask, int mask_type, int len)\r\n{\r\nif (!tb[val_type])\r\nreturn;\r\nmemcpy(val, nla_data(tb[val_type]), len);\r\nif (mask_type == TCA_FLOWER_UNSPEC || !tb[mask_type])\r\nmemset(mask, 0xff, len);\r\nelse\r\nmemcpy(mask, nla_data(tb[mask_type]), len);\r\n}\r\nstatic int fl_set_key(struct net *net, struct nlattr **tb,\r\nstruct fl_flow_key *key, struct fl_flow_key *mask)\r\n{\r\n#ifdef CONFIG_NET_CLS_IND\r\nif (tb[TCA_FLOWER_INDEV]) {\r\nint err = tcf_change_indev(net, tb[TCA_FLOWER_INDEV]);\r\nif (err < 0)\r\nreturn err;\r\nkey->indev_ifindex = err;\r\nmask->indev_ifindex = 0xffffffff;\r\n}\r\n#endif\r\nfl_set_key_val(tb, key->eth.dst, TCA_FLOWER_KEY_ETH_DST,\r\nmask->eth.dst, TCA_FLOWER_KEY_ETH_DST_MASK,\r\nsizeof(key->eth.dst));\r\nfl_set_key_val(tb, key->eth.src, TCA_FLOWER_KEY_ETH_SRC,\r\nmask->eth.src, TCA_FLOWER_KEY_ETH_SRC_MASK,\r\nsizeof(key->eth.src));\r\nfl_set_key_val(tb, &key->basic.n_proto, TCA_FLOWER_KEY_ETH_TYPE,\r\n&mask->basic.n_proto, TCA_FLOWER_UNSPEC,\r\nsizeof(key->basic.n_proto));\r\nif (key->basic.n_proto == htons(ETH_P_IP) ||\r\nkey->basic.n_proto == htons(ETH_P_IPV6)) {\r\nfl_set_key_val(tb, &key->basic.ip_proto, TCA_FLOWER_KEY_IP_PROTO,\r\n&mask->basic.ip_proto, TCA_FLOWER_UNSPEC,\r\nsizeof(key->basic.ip_proto));\r\n}\r\nif (key->control.addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\r\nfl_set_key_val(tb, &key->ipv4.src, TCA_FLOWER_KEY_IPV4_SRC,\r\n&mask->ipv4.src, TCA_FLOWER_KEY_IPV4_SRC_MASK,\r\nsizeof(key->ipv4.src));\r\nfl_set_key_val(tb, &key->ipv4.dst, TCA_FLOWER_KEY_IPV4_DST,\r\n&mask->ipv4.dst, TCA_FLOWER_KEY_IPV4_DST_MASK,\r\nsizeof(key->ipv4.dst));\r\n} else if (key->control.addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\r\nfl_set_key_val(tb, &key->ipv6.src, TCA_FLOWER_KEY_IPV6_SRC,\r\n&mask->ipv6.src, TCA_FLOWER_KEY_IPV6_SRC_MASK,\r\nsizeof(key->ipv6.src));\r\nfl_set_key_val(tb, &key->ipv6.dst, TCA_FLOWER_KEY_IPV6_DST,\r\n&mask->ipv6.dst, TCA_FLOWER_KEY_IPV6_DST_MASK,\r\nsizeof(key->ipv6.dst));\r\n}\r\nif (key->basic.ip_proto == IPPROTO_TCP) {\r\nfl_set_key_val(tb, &key->tp.src, TCA_FLOWER_KEY_TCP_SRC,\r\n&mask->tp.src, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.src));\r\nfl_set_key_val(tb, &key->tp.dst, TCA_FLOWER_KEY_TCP_DST,\r\n&mask->tp.dst, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.dst));\r\n} else if (key->basic.ip_proto == IPPROTO_UDP) {\r\nfl_set_key_val(tb, &key->tp.src, TCA_FLOWER_KEY_UDP_SRC,\r\n&mask->tp.src, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.src));\r\nfl_set_key_val(tb, &key->tp.dst, TCA_FLOWER_KEY_UDP_DST,\r\n&mask->tp.dst, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.dst));\r\n}\r\nreturn 0;\r\n}\r\nstatic bool fl_mask_eq(struct fl_flow_mask *mask1,\r\nstruct fl_flow_mask *mask2)\r\n{\r\nconst long *lmask1 = fl_key_get_start(&mask1->key, mask1);\r\nconst long *lmask2 = fl_key_get_start(&mask2->key, mask2);\r\nreturn !memcmp(&mask1->range, &mask2->range, sizeof(mask1->range)) &&\r\n!memcmp(lmask1, lmask2, fl_mask_range(mask1));\r\n}\r\nstatic int fl_init_hashtable(struct cls_fl_head *head,\r\nstruct fl_flow_mask *mask)\r\n{\r\nhead->ht_params = fl_ht_params;\r\nhead->ht_params.key_len = fl_mask_range(mask);\r\nhead->ht_params.key_offset += mask->range.start;\r\nreturn rhashtable_init(&head->ht, &head->ht_params);\r\n}\r\nstatic void fl_init_dissector(struct cls_fl_head *head,\r\nstruct fl_flow_mask *mask)\r\n{\r\nstruct flow_dissector_key keys[FLOW_DISSECTOR_KEY_MAX];\r\nsize_t cnt = 0;\r\nFL_KEY_SET(keys, cnt, FLOW_DISSECTOR_KEY_CONTROL, control);\r\nFL_KEY_SET(keys, cnt, FLOW_DISSECTOR_KEY_BASIC, basic);\r\nFL_KEY_SET_IF_IN_RANGE(mask, keys, cnt,\r\nFLOW_DISSECTOR_KEY_ETH_ADDRS, eth);\r\nFL_KEY_SET_IF_IN_RANGE(mask, keys, cnt,\r\nFLOW_DISSECTOR_KEY_IPV4_ADDRS, ipv4);\r\nFL_KEY_SET_IF_IN_RANGE(mask, keys, cnt,\r\nFLOW_DISSECTOR_KEY_IPV6_ADDRS, ipv6);\r\nFL_KEY_SET_IF_IN_RANGE(mask, keys, cnt,\r\nFLOW_DISSECTOR_KEY_PORTS, tp);\r\nskb_flow_dissector_init(&head->dissector, keys, cnt);\r\n}\r\nstatic int fl_check_assign_mask(struct cls_fl_head *head,\r\nstruct fl_flow_mask *mask)\r\n{\r\nint err;\r\nif (head->mask_assigned) {\r\nif (!fl_mask_eq(&head->mask, mask))\r\nreturn -EINVAL;\r\nelse\r\nreturn 0;\r\n}\r\nerr = fl_init_hashtable(head, mask);\r\nif (err)\r\nreturn err;\r\nmemcpy(&head->mask, mask, sizeof(head->mask));\r\nhead->mask_assigned = true;\r\nfl_init_dissector(head, mask);\r\nreturn 0;\r\n}\r\nstatic int fl_set_parms(struct net *net, struct tcf_proto *tp,\r\nstruct cls_fl_filter *f, struct fl_flow_mask *mask,\r\nunsigned long base, struct nlattr **tb,\r\nstruct nlattr *est, bool ovr)\r\n{\r\nstruct tcf_exts e;\r\nint err;\r\ntcf_exts_init(&e, TCA_FLOWER_ACT, 0);\r\nerr = tcf_exts_validate(net, tp, tb, est, &e, ovr);\r\nif (err < 0)\r\nreturn err;\r\nif (tb[TCA_FLOWER_CLASSID]) {\r\nf->res.classid = nla_get_u32(tb[TCA_FLOWER_CLASSID]);\r\ntcf_bind_filter(tp, &f->res, base);\r\n}\r\nerr = fl_set_key(net, tb, &f->key, &mask->key);\r\nif (err)\r\ngoto errout;\r\nfl_mask_update_range(mask);\r\nfl_set_masked_key(&f->mkey, &f->key, mask);\r\ntcf_exts_change(tp, &f->exts, &e);\r\nreturn 0;\r\nerrout:\r\ntcf_exts_destroy(&e);\r\nreturn err;\r\n}\r\nstatic u32 fl_grab_new_handle(struct tcf_proto *tp,\r\nstruct cls_fl_head *head)\r\n{\r\nunsigned int i = 0x80000000;\r\nu32 handle;\r\ndo {\r\nif (++head->hgen == 0x7FFFFFFF)\r\nhead->hgen = 1;\r\n} while (--i > 0 && fl_get(tp, head->hgen));\r\nif (unlikely(i == 0)) {\r\npr_err("Insufficient number of handles\n");\r\nhandle = 0;\r\n} else {\r\nhandle = head->hgen;\r\n}\r\nreturn handle;\r\n}\r\nstatic int fl_change(struct net *net, struct sk_buff *in_skb,\r\nstruct tcf_proto *tp, unsigned long base,\r\nu32 handle, struct nlattr **tca,\r\nunsigned long *arg, bool ovr)\r\n{\r\nstruct cls_fl_head *head = rtnl_dereference(tp->root);\r\nstruct cls_fl_filter *fold = (struct cls_fl_filter *) *arg;\r\nstruct cls_fl_filter *fnew;\r\nstruct nlattr *tb[TCA_FLOWER_MAX + 1];\r\nstruct fl_flow_mask mask = {};\r\nint err;\r\nif (!tca[TCA_OPTIONS])\r\nreturn -EINVAL;\r\nerr = nla_parse_nested(tb, TCA_FLOWER_MAX, tca[TCA_OPTIONS], fl_policy);\r\nif (err < 0)\r\nreturn err;\r\nif (fold && handle && fold->handle != handle)\r\nreturn -EINVAL;\r\nfnew = kzalloc(sizeof(*fnew), GFP_KERNEL);\r\nif (!fnew)\r\nreturn -ENOBUFS;\r\ntcf_exts_init(&fnew->exts, TCA_FLOWER_ACT, 0);\r\nif (!handle) {\r\nhandle = fl_grab_new_handle(tp, head);\r\nif (!handle) {\r\nerr = -EINVAL;\r\ngoto errout;\r\n}\r\n}\r\nfnew->handle = handle;\r\nerr = fl_set_parms(net, tp, fnew, &mask, base, tb, tca[TCA_RATE], ovr);\r\nif (err)\r\ngoto errout;\r\nerr = fl_check_assign_mask(head, &mask);\r\nif (err)\r\ngoto errout;\r\nerr = rhashtable_insert_fast(&head->ht, &fnew->ht_node,\r\nhead->ht_params);\r\nif (err)\r\ngoto errout;\r\nif (fold)\r\nrhashtable_remove_fast(&head->ht, &fold->ht_node,\r\nhead->ht_params);\r\n*arg = (unsigned long) fnew;\r\nif (fold) {\r\nlist_replace_rcu(&fold->list, &fnew->list);\r\ntcf_unbind_filter(tp, &fold->res);\r\ncall_rcu(&fold->rcu, fl_destroy_filter);\r\n} else {\r\nlist_add_tail_rcu(&fnew->list, &head->filters);\r\n}\r\nreturn 0;\r\nerrout:\r\nkfree(fnew);\r\nreturn err;\r\n}\r\nstatic int fl_delete(struct tcf_proto *tp, unsigned long arg)\r\n{\r\nstruct cls_fl_head *head = rtnl_dereference(tp->root);\r\nstruct cls_fl_filter *f = (struct cls_fl_filter *) arg;\r\nrhashtable_remove_fast(&head->ht, &f->ht_node,\r\nhead->ht_params);\r\nlist_del_rcu(&f->list);\r\ntcf_unbind_filter(tp, &f->res);\r\ncall_rcu(&f->rcu, fl_destroy_filter);\r\nreturn 0;\r\n}\r\nstatic void fl_walk(struct tcf_proto *tp, struct tcf_walker *arg)\r\n{\r\nstruct cls_fl_head *head = rtnl_dereference(tp->root);\r\nstruct cls_fl_filter *f;\r\nlist_for_each_entry_rcu(f, &head->filters, list) {\r\nif (arg->count < arg->skip)\r\ngoto skip;\r\nif (arg->fn(tp, (unsigned long) f, arg) < 0) {\r\narg->stop = 1;\r\nbreak;\r\n}\r\nskip:\r\narg->count++;\r\n}\r\n}\r\nstatic int fl_dump_key_val(struct sk_buff *skb,\r\nvoid *val, int val_type,\r\nvoid *mask, int mask_type, int len)\r\n{\r\nint err;\r\nif (!memchr_inv(mask, 0, len))\r\nreturn 0;\r\nerr = nla_put(skb, val_type, len, val);\r\nif (err)\r\nreturn err;\r\nif (mask_type != TCA_FLOWER_UNSPEC) {\r\nerr = nla_put(skb, mask_type, len, mask);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic int fl_dump(struct net *net, struct tcf_proto *tp, unsigned long fh,\r\nstruct sk_buff *skb, struct tcmsg *t)\r\n{\r\nstruct cls_fl_head *head = rtnl_dereference(tp->root);\r\nstruct cls_fl_filter *f = (struct cls_fl_filter *) fh;\r\nstruct nlattr *nest;\r\nstruct fl_flow_key *key, *mask;\r\nif (!f)\r\nreturn skb->len;\r\nt->tcm_handle = f->handle;\r\nnest = nla_nest_start(skb, TCA_OPTIONS);\r\nif (!nest)\r\ngoto nla_put_failure;\r\nif (f->res.classid &&\r\nnla_put_u32(skb, TCA_FLOWER_CLASSID, f->res.classid))\r\ngoto nla_put_failure;\r\nkey = &f->key;\r\nmask = &head->mask.key;\r\nif (mask->indev_ifindex) {\r\nstruct net_device *dev;\r\ndev = __dev_get_by_index(net, key->indev_ifindex);\r\nif (dev && nla_put_string(skb, TCA_FLOWER_INDEV, dev->name))\r\ngoto nla_put_failure;\r\n}\r\nif (fl_dump_key_val(skb, key->eth.dst, TCA_FLOWER_KEY_ETH_DST,\r\nmask->eth.dst, TCA_FLOWER_KEY_ETH_DST_MASK,\r\nsizeof(key->eth.dst)) ||\r\nfl_dump_key_val(skb, key->eth.src, TCA_FLOWER_KEY_ETH_SRC,\r\nmask->eth.src, TCA_FLOWER_KEY_ETH_SRC_MASK,\r\nsizeof(key->eth.src)) ||\r\nfl_dump_key_val(skb, &key->basic.n_proto, TCA_FLOWER_KEY_ETH_TYPE,\r\n&mask->basic.n_proto, TCA_FLOWER_UNSPEC,\r\nsizeof(key->basic.n_proto)))\r\ngoto nla_put_failure;\r\nif ((key->basic.n_proto == htons(ETH_P_IP) ||\r\nkey->basic.n_proto == htons(ETH_P_IPV6)) &&\r\nfl_dump_key_val(skb, &key->basic.ip_proto, TCA_FLOWER_KEY_IP_PROTO,\r\n&mask->basic.ip_proto, TCA_FLOWER_UNSPEC,\r\nsizeof(key->basic.ip_proto)))\r\ngoto nla_put_failure;\r\nif (key->control.addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS &&\r\n(fl_dump_key_val(skb, &key->ipv4.src, TCA_FLOWER_KEY_IPV4_SRC,\r\n&mask->ipv4.src, TCA_FLOWER_KEY_IPV4_SRC_MASK,\r\nsizeof(key->ipv4.src)) ||\r\nfl_dump_key_val(skb, &key->ipv4.dst, TCA_FLOWER_KEY_IPV4_DST,\r\n&mask->ipv4.dst, TCA_FLOWER_KEY_IPV4_DST_MASK,\r\nsizeof(key->ipv4.dst))))\r\ngoto nla_put_failure;\r\nelse if (key->control.addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS &&\r\n(fl_dump_key_val(skb, &key->ipv6.src, TCA_FLOWER_KEY_IPV6_SRC,\r\n&mask->ipv6.src, TCA_FLOWER_KEY_IPV6_SRC_MASK,\r\nsizeof(key->ipv6.src)) ||\r\nfl_dump_key_val(skb, &key->ipv6.dst, TCA_FLOWER_KEY_IPV6_DST,\r\n&mask->ipv6.dst, TCA_FLOWER_KEY_IPV6_DST_MASK,\r\nsizeof(key->ipv6.dst))))\r\ngoto nla_put_failure;\r\nif (key->basic.ip_proto == IPPROTO_TCP &&\r\n(fl_dump_key_val(skb, &key->tp.src, TCA_FLOWER_KEY_TCP_SRC,\r\n&mask->tp.src, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.src)) ||\r\nfl_dump_key_val(skb, &key->tp.dst, TCA_FLOWER_KEY_TCP_DST,\r\n&mask->tp.dst, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.dst))))\r\ngoto nla_put_failure;\r\nelse if (key->basic.ip_proto == IPPROTO_UDP &&\r\n(fl_dump_key_val(skb, &key->tp.src, TCA_FLOWER_KEY_UDP_SRC,\r\n&mask->tp.src, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.src)) ||\r\nfl_dump_key_val(skb, &key->tp.dst, TCA_FLOWER_KEY_UDP_DST,\r\n&mask->tp.dst, TCA_FLOWER_UNSPEC,\r\nsizeof(key->tp.dst))))\r\ngoto nla_put_failure;\r\nif (tcf_exts_dump(skb, &f->exts))\r\ngoto nla_put_failure;\r\nnla_nest_end(skb, nest);\r\nif (tcf_exts_dump_stats(skb, &f->exts) < 0)\r\ngoto nla_put_failure;\r\nreturn skb->len;\r\nnla_put_failure:\r\nnla_nest_cancel(skb, nest);\r\nreturn -1;\r\n}\r\nstatic int __init cls_fl_init(void)\r\n{\r\nreturn register_tcf_proto_ops(&cls_fl_ops);\r\n}\r\nstatic void __exit cls_fl_exit(void)\r\n{\r\nunregister_tcf_proto_ops(&cls_fl_ops);\r\n}
