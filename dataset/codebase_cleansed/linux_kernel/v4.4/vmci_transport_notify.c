static bool vmci_transport_notify_waiting_write(struct vsock_sock *vsk)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nbool retval;\r\nu64 notify_limit;\r\nif (!PKT_FIELD(vsk, peer_waiting_write))\r\nreturn false;\r\n#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL\r\nif (!PKT_FIELD(vsk, peer_waiting_write_detected)) {\r\nPKT_FIELD(vsk, peer_waiting_write_detected) = true;\r\nif (PKT_FIELD(vsk, write_notify_window) < PAGE_SIZE) {\r\nPKT_FIELD(vsk, write_notify_window) =\r\nPKT_FIELD(vsk, write_notify_min_window);\r\n} else {\r\nPKT_FIELD(vsk, write_notify_window) -= PAGE_SIZE;\r\nif (PKT_FIELD(vsk, write_notify_window) <\r\nPKT_FIELD(vsk, write_notify_min_window))\r\nPKT_FIELD(vsk, write_notify_window) =\r\nPKT_FIELD(vsk, write_notify_min_window);\r\n}\r\n}\r\nnotify_limit = vmci_trans(vsk)->consume_size -\r\nPKT_FIELD(vsk, write_notify_window);\r\n#else\r\nnotify_limit = 0;\r\n#endif\r\nretval = vmci_qpair_consume_free_space(vmci_trans(vsk)->qpair) >\r\nnotify_limit;\r\n#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL\r\nif (retval) {\r\nPKT_FIELD(vsk, peer_waiting_write_detected) = false;\r\n}\r\n#endif\r\nreturn retval;\r\n#else\r\nreturn true;\r\n#endif\r\n}\r\nstatic bool vmci_transport_notify_waiting_read(struct vsock_sock *vsk)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nif (!PKT_FIELD(vsk, peer_waiting_read))\r\nreturn false;\r\nreturn vmci_qpair_produce_buf_ready(vmci_trans(vsk)->qpair) > 0;\r\n#else\r\nreturn true;\r\n#endif\r\n}\r\nstatic void\r\nvmci_transport_handle_waiting_read(struct sock *sk,\r\nstruct vmci_transport_packet *pkt,\r\nbool bottom_half,\r\nstruct sockaddr_vm *dst,\r\nstruct sockaddr_vm *src)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nstruct vsock_sock *vsk;\r\nvsk = vsock_sk(sk);\r\nPKT_FIELD(vsk, peer_waiting_read) = true;\r\nmemcpy(&PKT_FIELD(vsk, peer_waiting_read_info), &pkt->u.wait,\r\nsizeof(PKT_FIELD(vsk, peer_waiting_read_info)));\r\nif (vmci_transport_notify_waiting_read(vsk)) {\r\nbool sent;\r\nif (bottom_half)\r\nsent = vmci_transport_send_wrote_bh(dst, src) > 0;\r\nelse\r\nsent = vmci_transport_send_wrote(sk) > 0;\r\nif (sent)\r\nPKT_FIELD(vsk, peer_waiting_read) = false;\r\n}\r\n#endif\r\n}\r\nstatic void\r\nvmci_transport_handle_waiting_write(struct sock *sk,\r\nstruct vmci_transport_packet *pkt,\r\nbool bottom_half,\r\nstruct sockaddr_vm *dst,\r\nstruct sockaddr_vm *src)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nstruct vsock_sock *vsk;\r\nvsk = vsock_sk(sk);\r\nPKT_FIELD(vsk, peer_waiting_write) = true;\r\nmemcpy(&PKT_FIELD(vsk, peer_waiting_write_info), &pkt->u.wait,\r\nsizeof(PKT_FIELD(vsk, peer_waiting_write_info)));\r\nif (vmci_transport_notify_waiting_write(vsk)) {\r\nbool sent;\r\nif (bottom_half)\r\nsent = vmci_transport_send_read_bh(dst, src) > 0;\r\nelse\r\nsent = vmci_transport_send_read(sk) > 0;\r\nif (sent)\r\nPKT_FIELD(vsk, peer_waiting_write) = false;\r\n}\r\n#endif\r\n}\r\nstatic void\r\nvmci_transport_handle_read(struct sock *sk,\r\nstruct vmci_transport_packet *pkt,\r\nbool bottom_half,\r\nstruct sockaddr_vm *dst, struct sockaddr_vm *src)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nstruct vsock_sock *vsk;\r\nvsk = vsock_sk(sk);\r\nPKT_FIELD(vsk, sent_waiting_write) = false;\r\n#endif\r\nsk->sk_write_space(sk);\r\n}\r\nstatic bool send_waiting_read(struct sock *sk, u64 room_needed)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nstruct vsock_sock *vsk;\r\nstruct vmci_transport_waiting_info waiting_info;\r\nu64 tail;\r\nu64 head;\r\nu64 room_left;\r\nbool ret;\r\nvsk = vsock_sk(sk);\r\nif (PKT_FIELD(vsk, sent_waiting_read))\r\nreturn true;\r\nif (PKT_FIELD(vsk, write_notify_window) <\r\nvmci_trans(vsk)->consume_size)\r\nPKT_FIELD(vsk, write_notify_window) =\r\nmin(PKT_FIELD(vsk, write_notify_window) + PAGE_SIZE,\r\nvmci_trans(vsk)->consume_size);\r\nvmci_qpair_get_consume_indexes(vmci_trans(vsk)->qpair, &tail, &head);\r\nroom_left = vmci_trans(vsk)->consume_size - head;\r\nif (room_needed >= room_left) {\r\nwaiting_info.offset = room_needed - room_left;\r\nwaiting_info.generation =\r\nPKT_FIELD(vsk, consume_q_generation) + 1;\r\n} else {\r\nwaiting_info.offset = head + room_needed;\r\nwaiting_info.generation = PKT_FIELD(vsk, consume_q_generation);\r\n}\r\nret = vmci_transport_send_waiting_read(sk, &waiting_info) > 0;\r\nif (ret)\r\nPKT_FIELD(vsk, sent_waiting_read) = true;\r\nreturn ret;\r\n#else\r\nreturn true;\r\n#endif\r\n}\r\nstatic bool send_waiting_write(struct sock *sk, u64 room_needed)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nstruct vsock_sock *vsk;\r\nstruct vmci_transport_waiting_info waiting_info;\r\nu64 tail;\r\nu64 head;\r\nu64 room_left;\r\nbool ret;\r\nvsk = vsock_sk(sk);\r\nif (PKT_FIELD(vsk, sent_waiting_write))\r\nreturn true;\r\nvmci_qpair_get_produce_indexes(vmci_trans(vsk)->qpair, &tail, &head);\r\nroom_left = vmci_trans(vsk)->produce_size - tail;\r\nif (room_needed + 1 >= room_left) {\r\nwaiting_info.offset = room_needed + 1 - room_left;\r\nwaiting_info.generation = PKT_FIELD(vsk, produce_q_generation);\r\n} else {\r\nwaiting_info.offset = tail + room_needed + 1;\r\nwaiting_info.generation =\r\nPKT_FIELD(vsk, produce_q_generation) - 1;\r\n}\r\nret = vmci_transport_send_waiting_write(sk, &waiting_info) > 0;\r\nif (ret)\r\nPKT_FIELD(vsk, sent_waiting_write) = true;\r\nreturn ret;\r\n#else\r\nreturn true;\r\n#endif\r\n}\r\nstatic int vmci_transport_send_read_notification(struct sock *sk)\r\n{\r\nstruct vsock_sock *vsk;\r\nbool sent_read;\r\nunsigned int retries;\r\nint err;\r\nvsk = vsock_sk(sk);\r\nsent_read = false;\r\nretries = 0;\r\nerr = 0;\r\nif (vmci_transport_notify_waiting_write(vsk)) {\r\nwhile (!(vsk->peer_shutdown & RCV_SHUTDOWN) &&\r\n!sent_read &&\r\nretries < VMCI_TRANSPORT_MAX_DGRAM_RESENDS) {\r\nerr = vmci_transport_send_read(sk);\r\nif (err >= 0)\r\nsent_read = true;\r\nretries++;\r\n}\r\nif (retries >= VMCI_TRANSPORT_MAX_DGRAM_RESENDS)\r\npr_err("%p unable to send read notify to peer\n", sk);\r\nelse\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nPKT_FIELD(vsk, peer_waiting_write) = false;\r\n#endif\r\n}\r\nreturn err;\r\n}\r\nstatic void\r\nvmci_transport_handle_wrote(struct sock *sk,\r\nstruct vmci_transport_packet *pkt,\r\nbool bottom_half,\r\nstruct sockaddr_vm *dst, struct sockaddr_vm *src)\r\n{\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\nPKT_FIELD(vsk, sent_waiting_read) = false;\r\n#endif\r\nsk->sk_data_ready(sk);\r\n}\r\nstatic void vmci_transport_notify_pkt_socket_init(struct sock *sk)\r\n{\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\nPKT_FIELD(vsk, write_notify_window) = PAGE_SIZE;\r\nPKT_FIELD(vsk, write_notify_min_window) = PAGE_SIZE;\r\nPKT_FIELD(vsk, peer_waiting_read) = false;\r\nPKT_FIELD(vsk, peer_waiting_write) = false;\r\nPKT_FIELD(vsk, peer_waiting_write_detected) = false;\r\nPKT_FIELD(vsk, sent_waiting_read) = false;\r\nPKT_FIELD(vsk, sent_waiting_write) = false;\r\nPKT_FIELD(vsk, produce_q_generation) = 0;\r\nPKT_FIELD(vsk, consume_q_generation) = 0;\r\nmemset(&PKT_FIELD(vsk, peer_waiting_read_info), 0,\r\nsizeof(PKT_FIELD(vsk, peer_waiting_read_info)));\r\nmemset(&PKT_FIELD(vsk, peer_waiting_write_info), 0,\r\nsizeof(PKT_FIELD(vsk, peer_waiting_write_info)));\r\n}\r\nstatic void vmci_transport_notify_pkt_socket_destruct(struct vsock_sock *vsk)\r\n{\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_poll_in(struct sock *sk,\r\nsize_t target, bool *data_ready_now)\r\n{\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\nif (vsock_stream_has_data(vsk)) {\r\n*data_ready_now = true;\r\n} else {\r\nif (sk->sk_state == SS_CONNECTED) {\r\nif (!send_waiting_read(sk, 1))\r\nreturn -1;\r\n}\r\n*data_ready_now = false;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_poll_out(struct sock *sk,\r\nsize_t target, bool *space_avail_now)\r\n{\r\ns64 produce_q_free_space;\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\nproduce_q_free_space = vsock_stream_has_space(vsk);\r\nif (produce_q_free_space > 0) {\r\n*space_avail_now = true;\r\nreturn 0;\r\n} else if (produce_q_free_space == 0) {\r\nif (!send_waiting_write(sk, 1))\r\nreturn -1;\r\n*space_avail_now = false;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_recv_init(\r\nstruct sock *sk,\r\nsize_t target,\r\nstruct vmci_transport_recv_notify_data *data)\r\n{\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\n#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY\r\ndata->consume_head = 0;\r\ndata->produce_tail = 0;\r\n#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL\r\ndata->notify_on_block = false;\r\nif (PKT_FIELD(vsk, write_notify_min_window) < target + 1) {\r\nPKT_FIELD(vsk, write_notify_min_window) = target + 1;\r\nif (PKT_FIELD(vsk, write_notify_window) <\r\nPKT_FIELD(vsk, write_notify_min_window)) {\r\nPKT_FIELD(vsk, write_notify_window) =\r\nPKT_FIELD(vsk, write_notify_min_window);\r\ndata->notify_on_block = true;\r\n}\r\n}\r\n#endif\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_recv_pre_block(\r\nstruct sock *sk,\r\nsize_t target,\r\nstruct vmci_transport_recv_notify_data *data)\r\n{\r\nint err = 0;\r\nif (!send_waiting_read(sk, target)) {\r\nerr = -EHOSTUNREACH;\r\nreturn err;\r\n}\r\n#ifdef VSOCK_OPTIMIZATION_FLOW_CONTROL\r\nif (data->notify_on_block) {\r\nerr = vmci_transport_send_read_notification(sk);\r\nif (err < 0)\r\nreturn err;\r\ndata->notify_on_block = false;\r\n}\r\n#endif\r\nreturn err;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_recv_pre_dequeue(\r\nstruct sock *sk,\r\nsize_t target,\r\nstruct vmci_transport_recv_notify_data *data)\r\n{\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nvmci_qpair_get_consume_indexes(vmci_trans(vsk)->qpair,\r\n&data->produce_tail,\r\n&data->consume_head);\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_recv_post_dequeue(\r\nstruct sock *sk,\r\nsize_t target,\r\nssize_t copied,\r\nbool data_read,\r\nstruct vmci_transport_recv_notify_data *data)\r\n{\r\nstruct vsock_sock *vsk;\r\nint err;\r\nvsk = vsock_sk(sk);\r\nerr = 0;\r\nif (data_read) {\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nif (copied >=\r\nvmci_trans(vsk)->consume_size - data->consume_head)\r\nPKT_FIELD(vsk, consume_q_generation)++;\r\n#endif\r\nerr = vmci_transport_send_read_notification(sk);\r\nif (err < 0)\r\nreturn err;\r\n}\r\nreturn err;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_send_init(\r\nstruct sock *sk,\r\nstruct vmci_transport_send_notify_data *data)\r\n{\r\n#ifdef VSOCK_OPTIMIZATION_WAITING_NOTIFY\r\ndata->consume_head = 0;\r\ndata->produce_tail = 0;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_send_pre_block(\r\nstruct sock *sk,\r\nstruct vmci_transport_send_notify_data *data)\r\n{\r\nif (!send_waiting_write(sk, 1))\r\nreturn -EHOSTUNREACH;\r\nreturn 0;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_send_pre_enqueue(\r\nstruct sock *sk,\r\nstruct vmci_transport_send_notify_data *data)\r\n{\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nvmci_qpair_get_produce_indexes(vmci_trans(vsk)->qpair,\r\n&data->produce_tail,\r\n&data->consume_head);\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int\r\nvmci_transport_notify_pkt_send_post_enqueue(\r\nstruct sock *sk,\r\nssize_t written,\r\nstruct vmci_transport_send_notify_data *data)\r\n{\r\nint err = 0;\r\nstruct vsock_sock *vsk;\r\nbool sent_wrote = false;\r\nint retries = 0;\r\nvsk = vsock_sk(sk);\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nif (written >= vmci_trans(vsk)->produce_size - data->produce_tail)\r\nPKT_FIELD(vsk, produce_q_generation)++;\r\n#endif\r\nif (vmci_transport_notify_waiting_read(vsk)) {\r\nwhile (!(vsk->peer_shutdown & RCV_SHUTDOWN) &&\r\n!sent_wrote &&\r\nretries < VMCI_TRANSPORT_MAX_DGRAM_RESENDS) {\r\nerr = vmci_transport_send_wrote(sk);\r\nif (err >= 0)\r\nsent_wrote = true;\r\nretries++;\r\n}\r\nif (retries >= VMCI_TRANSPORT_MAX_DGRAM_RESENDS) {\r\npr_err("%p unable to send wrote notify to peer\n", sk);\r\nreturn err;\r\n} else {\r\n#if defined(VSOCK_OPTIMIZATION_WAITING_NOTIFY)\r\nPKT_FIELD(vsk, peer_waiting_read) = false;\r\n#endif\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic void\r\nvmci_transport_notify_pkt_handle_pkt(\r\nstruct sock *sk,\r\nstruct vmci_transport_packet *pkt,\r\nbool bottom_half,\r\nstruct sockaddr_vm *dst,\r\nstruct sockaddr_vm *src, bool *pkt_processed)\r\n{\r\nbool processed = false;\r\nswitch (pkt->type) {\r\ncase VMCI_TRANSPORT_PACKET_TYPE_WROTE:\r\nvmci_transport_handle_wrote(sk, pkt, bottom_half, dst, src);\r\nprocessed = true;\r\nbreak;\r\ncase VMCI_TRANSPORT_PACKET_TYPE_READ:\r\nvmci_transport_handle_read(sk, pkt, bottom_half, dst, src);\r\nprocessed = true;\r\nbreak;\r\ncase VMCI_TRANSPORT_PACKET_TYPE_WAITING_WRITE:\r\nvmci_transport_handle_waiting_write(sk, pkt, bottom_half,\r\ndst, src);\r\nprocessed = true;\r\nbreak;\r\ncase VMCI_TRANSPORT_PACKET_TYPE_WAITING_READ:\r\nvmci_transport_handle_waiting_read(sk, pkt, bottom_half,\r\ndst, src);\r\nprocessed = true;\r\nbreak;\r\n}\r\nif (pkt_processed)\r\n*pkt_processed = processed;\r\n}\r\nstatic void vmci_transport_notify_pkt_process_request(struct sock *sk)\r\n{\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\nPKT_FIELD(vsk, write_notify_window) = vmci_trans(vsk)->consume_size;\r\nif (vmci_trans(vsk)->consume_size <\r\nPKT_FIELD(vsk, write_notify_min_window))\r\nPKT_FIELD(vsk, write_notify_min_window) =\r\nvmci_trans(vsk)->consume_size;\r\n}\r\nstatic void vmci_transport_notify_pkt_process_negotiate(struct sock *sk)\r\n{\r\nstruct vsock_sock *vsk = vsock_sk(sk);\r\nPKT_FIELD(vsk, write_notify_window) = vmci_trans(vsk)->consume_size;\r\nif (vmci_trans(vsk)->consume_size <\r\nPKT_FIELD(vsk, write_notify_min_window))\r\nPKT_FIELD(vsk, write_notify_min_window) =\r\nvmci_trans(vsk)->consume_size;\r\n}
