static void namespace_io_release(struct device *dev)\r\n{\r\nstruct nd_namespace_io *nsio = to_nd_namespace_io(dev);\r\nkfree(nsio);\r\n}\r\nstatic void namespace_pmem_release(struct device *dev)\r\n{\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nkfree(nspm->alt_name);\r\nkfree(nspm->uuid);\r\nkfree(nspm);\r\n}\r\nstatic void namespace_blk_release(struct device *dev)\r\n{\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nif (nsblk->id >= 0)\r\nida_simple_remove(&nd_region->ns_ida, nsblk->id);\r\nkfree(nsblk->alt_name);\r\nkfree(nsblk->uuid);\r\nkfree(nsblk->res);\r\nkfree(nsblk);\r\n}\r\nstatic bool is_namespace_pmem(struct device *dev)\r\n{\r\nreturn dev ? dev->type == &namespace_pmem_device_type : false;\r\n}\r\nstatic bool is_namespace_blk(struct device *dev)\r\n{\r\nreturn dev ? dev->type == &namespace_blk_device_type : false;\r\n}\r\nstatic bool is_namespace_io(struct device *dev)\r\n{\r\nreturn dev ? dev->type == &namespace_io_device_type : false;\r\n}\r\nbool pmem_should_map_pages(struct device *dev)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nif (!IS_ENABLED(CONFIG_ZONE_DEVICE))\r\nreturn false;\r\nif (!test_bit(ND_REGION_PAGEMAP, &nd_region->flags))\r\nreturn false;\r\nif (is_nd_pfn(dev) || is_nd_btt(dev))\r\nreturn false;\r\n#ifdef ARCH_MEMREMAP_PMEM\r\nreturn ARCH_MEMREMAP_PMEM == MEMREMAP_WB;\r\n#else\r\nreturn false;\r\n#endif\r\n}\r\nconst char *nvdimm_namespace_disk_name(struct nd_namespace_common *ndns,\r\nchar *name)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(ndns->dev.parent);\r\nconst char *suffix = NULL;\r\nif (ndns->claim) {\r\nif (is_nd_btt(ndns->claim))\r\nsuffix = "s";\r\nelse if (is_nd_pfn(ndns->claim))\r\nsuffix = "m";\r\nelse\r\ndev_WARN_ONCE(&ndns->dev, 1,\r\n"unknown claim type by %s\n",\r\ndev_name(ndns->claim));\r\n}\r\nif (is_namespace_pmem(&ndns->dev) || is_namespace_io(&ndns->dev)) {\r\nif (!suffix && pmem_should_map_pages(&ndns->dev))\r\nsuffix = "m";\r\nsprintf(name, "pmem%d%s", nd_region->id, suffix ? suffix : "");\r\n} else if (is_namespace_blk(&ndns->dev)) {\r\nstruct nd_namespace_blk *nsblk;\r\nnsblk = to_nd_namespace_blk(&ndns->dev);\r\nsprintf(name, "ndblk%d.%d%s", nd_region->id, nsblk->id,\r\nsuffix ? suffix : "");\r\n} else {\r\nreturn NULL;\r\n}\r\nreturn name;\r\n}\r\nconst u8 *nd_dev_to_uuid(struct device *dev)\r\n{\r\nstatic const u8 null_uuid[16];\r\nif (!dev)\r\nreturn null_uuid;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nreturn nspm->uuid;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nreturn nsblk->uuid;\r\n} else\r\nreturn null_uuid;\r\n}\r\nstatic ssize_t nstype_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nreturn sprintf(buf, "%d\n", nd_region_to_nstype(nd_region));\r\n}\r\nstatic ssize_t __alt_name_store(struct device *dev, const char *buf,\r\nconst size_t len)\r\n{\r\nchar *input, *pos, *alt_name, **ns_altname;\r\nssize_t rc;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nns_altname = &nspm->alt_name;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nns_altname = &nsblk->alt_name;\r\n} else\r\nreturn -ENXIO;\r\nif (dev->driver || to_ndns(dev)->claim)\r\nreturn -EBUSY;\r\ninput = kmemdup(buf, len + 1, GFP_KERNEL);\r\nif (!input)\r\nreturn -ENOMEM;\r\ninput[len] = '\0';\r\npos = strim(input);\r\nif (strlen(pos) + 1 > NSLABEL_NAME_LEN) {\r\nrc = -EINVAL;\r\ngoto out;\r\n}\r\nalt_name = kzalloc(NSLABEL_NAME_LEN, GFP_KERNEL);\r\nif (!alt_name) {\r\nrc = -ENOMEM;\r\ngoto out;\r\n}\r\nkfree(*ns_altname);\r\n*ns_altname = alt_name;\r\nsprintf(*ns_altname, "%s", pos);\r\nrc = len;\r\nout:\r\nkfree(input);\r\nreturn rc;\r\n}\r\nstatic resource_size_t nd_namespace_blk_size(struct nd_namespace_blk *nsblk)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(nsblk->common.dev.parent);\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[0];\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct nd_label_id label_id;\r\nresource_size_t size = 0;\r\nstruct resource *res;\r\nif (!nsblk->uuid)\r\nreturn 0;\r\nnd_label_gen_id(&label_id, nsblk->uuid, NSLABEL_FLAG_LOCAL);\r\nfor_each_dpa_resource(ndd, res)\r\nif (strcmp(res->name, label_id.id) == 0)\r\nsize += resource_size(res);\r\nreturn size;\r\n}\r\nstatic bool __nd_namespace_blk_validate(struct nd_namespace_blk *nsblk)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(nsblk->common.dev.parent);\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[0];\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct nd_label_id label_id;\r\nstruct resource *res;\r\nint count, i;\r\nif (!nsblk->uuid || !nsblk->lbasize || !ndd)\r\nreturn false;\r\ncount = 0;\r\nnd_label_gen_id(&label_id, nsblk->uuid, NSLABEL_FLAG_LOCAL);\r\nfor_each_dpa_resource(ndd, res) {\r\nif (strcmp(res->name, label_id.id) != 0)\r\ncontinue;\r\nif (res->flags & DPA_RESOURCE_ADJUSTED)\r\nreturn false;\r\ncount++;\r\n}\r\nif (count != nsblk->num_resources)\r\nreturn false;\r\nfor (i = 0; i < nsblk->num_resources; i++) {\r\nstruct resource *found = NULL;\r\nfor_each_dpa_resource(ndd, res)\r\nif (res == nsblk->res[i]) {\r\nfound = res;\r\nbreak;\r\n}\r\nif (!found)\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nresource_size_t nd_namespace_blk_validate(struct nd_namespace_blk *nsblk)\r\n{\r\nresource_size_t size;\r\nnvdimm_bus_lock(&nsblk->common.dev);\r\nsize = __nd_namespace_blk_validate(nsblk);\r\nnvdimm_bus_unlock(&nsblk->common.dev);\r\nreturn size;\r\n}\r\nstatic int nd_namespace_label_update(struct nd_region *nd_region,\r\nstruct device *dev)\r\n{\r\ndev_WARN_ONCE(dev, dev->driver || to_ndns(dev)->claim,\r\n"namespace must be idle during label update\n");\r\nif (dev->driver || to_ndns(dev)->claim)\r\nreturn 0;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nresource_size_t size = resource_size(&nspm->nsio.res);\r\nif (size == 0 && nspm->uuid)\r\n;\r\nelse if (!nspm->uuid)\r\nreturn 0;\r\nreturn nd_pmem_namespace_label_update(nd_region, nspm, size);\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nresource_size_t size = nd_namespace_blk_size(nsblk);\r\nif (size == 0 && nsblk->uuid)\r\n;\r\nelse if (!nsblk->uuid || !nsblk->lbasize)\r\nreturn 0;\r\nreturn nd_blk_namespace_label_update(nd_region, nsblk, size);\r\n} else\r\nreturn -ENXIO;\r\n}\r\nstatic ssize_t alt_name_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t len)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nssize_t rc;\r\ndevice_lock(dev);\r\nnvdimm_bus_lock(dev);\r\nwait_nvdimm_bus_probe_idle(dev);\r\nrc = __alt_name_store(dev, buf, len);\r\nif (rc >= 0)\r\nrc = nd_namespace_label_update(nd_region, dev);\r\ndev_dbg(dev, "%s: %s(%zd)\n", __func__, rc < 0 ? "fail " : "", rc);\r\nnvdimm_bus_unlock(dev);\r\ndevice_unlock(dev);\r\nreturn rc < 0 ? rc : len;\r\n}\r\nstatic ssize_t alt_name_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nchar *ns_altname;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nns_altname = nspm->alt_name;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nns_altname = nsblk->alt_name;\r\n} else\r\nreturn -ENXIO;\r\nreturn sprintf(buf, "%s\n", ns_altname ? ns_altname : "");\r\n}\r\nstatic int scan_free(struct nd_region *nd_region,\r\nstruct nd_mapping *nd_mapping, struct nd_label_id *label_id,\r\nresource_size_t n)\r\n{\r\nbool is_blk = strncmp(label_id->id, "blk", 3) == 0;\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nint rc = 0;\r\nwhile (n) {\r\nstruct resource *res, *last;\r\nresource_size_t new_start;\r\nlast = NULL;\r\nfor_each_dpa_resource(ndd, res)\r\nif (strcmp(res->name, label_id->id) == 0)\r\nlast = res;\r\nres = last;\r\nif (!res)\r\nreturn 0;\r\nif (n >= resource_size(res)) {\r\nn -= resource_size(res);\r\nnd_dbg_dpa(nd_region, ndd, res, "delete %d\n", rc);\r\nnvdimm_free_dpa(ndd, res);\r\ncontinue;\r\n}\r\nif (is_blk)\r\nnew_start = res->start + n;\r\nelse\r\nnew_start = res->start;\r\nrc = adjust_resource(res, new_start, resource_size(res) - n);\r\nif (rc == 0)\r\nres->flags |= DPA_RESOURCE_ADJUSTED;\r\nnd_dbg_dpa(nd_region, ndd, res, "shrink %d\n", rc);\r\nbreak;\r\n}\r\nreturn rc;\r\n}\r\nstatic int shrink_dpa_allocation(struct nd_region *nd_region,\r\nstruct nd_label_id *label_id, resource_size_t n)\r\n{\r\nint i;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nint rc;\r\nrc = scan_free(nd_region, nd_mapping, label_id, n);\r\nif (rc)\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic resource_size_t init_dpa_allocation(struct nd_label_id *label_id,\r\nstruct nd_region *nd_region, struct nd_mapping *nd_mapping,\r\nresource_size_t n)\r\n{\r\nbool is_blk = strncmp(label_id->id, "blk", 3) == 0;\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nresource_size_t first_dpa;\r\nstruct resource *res;\r\nint rc = 0;\r\nif (is_blk)\r\nfirst_dpa = nd_mapping->start + nd_mapping->size - n;\r\nelse\r\nfirst_dpa = nd_mapping->start;\r\nres = nvdimm_allocate_dpa(ndd, label_id, first_dpa, n);\r\nif (!res)\r\nrc = -EBUSY;\r\nnd_dbg_dpa(nd_region, ndd, res, "init %d\n", rc);\r\nreturn rc ? n : 0;\r\n}\r\nstatic bool space_valid(bool is_pmem, bool is_reserve,\r\nstruct nd_label_id *label_id, struct resource *res)\r\n{\r\nif (is_reserve || !is_pmem)\r\nreturn true;\r\nif (!res || strcmp(res->name, label_id->id) == 0)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic resource_size_t scan_allocate(struct nd_region *nd_region,\r\nstruct nd_mapping *nd_mapping, struct nd_label_id *label_id,\r\nresource_size_t n)\r\n{\r\nresource_size_t mapping_end = nd_mapping->start + nd_mapping->size - 1;\r\nbool is_reserve = strcmp(label_id->id, "pmem-reserve") == 0;\r\nbool is_pmem = strncmp(label_id->id, "pmem", 4) == 0;\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nconst resource_size_t to_allocate = n;\r\nstruct resource *res;\r\nint first;\r\nretry:\r\nfirst = 0;\r\nfor_each_dpa_resource(ndd, res) {\r\nresource_size_t allocate, available = 0, free_start, free_end;\r\nstruct resource *next = res->sibling, *new_res = NULL;\r\nenum alloc_loc loc = ALLOC_ERR;\r\nconst char *action;\r\nint rc = 0;\r\nif (res->start > mapping_end)\r\ncontinue;\r\nif (res->end < nd_mapping->start)\r\ncontinue;\r\nif (!first++ && res->start > nd_mapping->start) {\r\nfree_start = nd_mapping->start;\r\navailable = res->start - free_start;\r\nif (space_valid(is_pmem, is_reserve, label_id, NULL))\r\nloc = ALLOC_BEFORE;\r\n}\r\nif (!loc && next) {\r\nfree_start = res->start + resource_size(res);\r\nfree_end = min(mapping_end, next->start - 1);\r\nif (space_valid(is_pmem, is_reserve, label_id, res)\r\n&& free_start < free_end) {\r\navailable = free_end + 1 - free_start;\r\nloc = ALLOC_MID;\r\n}\r\n}\r\nif (!loc && !next) {\r\nfree_start = res->start + resource_size(res);\r\nfree_end = mapping_end;\r\nif (space_valid(is_pmem, is_reserve, label_id, res)\r\n&& free_start < free_end) {\r\navailable = free_end + 1 - free_start;\r\nloc = ALLOC_AFTER;\r\n}\r\n}\r\nif (!loc || !available)\r\ncontinue;\r\nallocate = min(available, n);\r\nswitch (loc) {\r\ncase ALLOC_BEFORE:\r\nif (strcmp(res->name, label_id->id) == 0) {\r\nif (is_pmem && !is_reserve)\r\nreturn n;\r\nrc = adjust_resource(res, res->start - allocate,\r\nresource_size(res) + allocate);\r\naction = "cur grow up";\r\n} else\r\naction = "allocate";\r\nbreak;\r\ncase ALLOC_MID:\r\nif (strcmp(next->name, label_id->id) == 0) {\r\nif (is_pmem && !is_reserve)\r\nreturn n;\r\nrc = adjust_resource(next, next->start\r\n- allocate, resource_size(next)\r\n+ allocate);\r\nnew_res = next;\r\naction = "next grow up";\r\n} else if (strcmp(res->name, label_id->id) == 0) {\r\naction = "grow down";\r\n} else\r\naction = "allocate";\r\nbreak;\r\ncase ALLOC_AFTER:\r\nif (strcmp(res->name, label_id->id) == 0)\r\naction = "grow down";\r\nelse\r\naction = "allocate";\r\nbreak;\r\ndefault:\r\nreturn n;\r\n}\r\nif (strcmp(action, "allocate") == 0) {\r\nif (!is_pmem)\r\nfree_start += available - allocate;\r\nelse if (!is_reserve && free_start != nd_mapping->start)\r\nreturn n;\r\nnew_res = nvdimm_allocate_dpa(ndd, label_id,\r\nfree_start, allocate);\r\nif (!new_res)\r\nrc = -EBUSY;\r\n} else if (strcmp(action, "grow down") == 0) {\r\nrc = adjust_resource(res, res->start, resource_size(res)\r\n+ allocate);\r\nif (rc == 0)\r\nres->flags |= DPA_RESOURCE_ADJUSTED;\r\n}\r\nif (!new_res)\r\nnew_res = res;\r\nnd_dbg_dpa(nd_region, ndd, new_res, "%s(%d) %d\n",\r\naction, loc, rc);\r\nif (rc)\r\nreturn n;\r\nn -= allocate;\r\nif (n) {\r\ngoto retry;\r\n} else\r\nreturn 0;\r\n}\r\nif ((is_pmem || !ndd->dpa.child) && n == to_allocate)\r\nreturn init_dpa_allocation(label_id, nd_region, nd_mapping, n);\r\nreturn n;\r\n}\r\nstatic int merge_dpa(struct nd_region *nd_region,\r\nstruct nd_mapping *nd_mapping, struct nd_label_id *label_id)\r\n{\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct resource *res;\r\nif (strncmp("pmem", label_id->id, 4) == 0)\r\nreturn 0;\r\nretry:\r\nfor_each_dpa_resource(ndd, res) {\r\nint rc;\r\nstruct resource *next = res->sibling;\r\nresource_size_t end = res->start + resource_size(res);\r\nif (!next || strcmp(res->name, label_id->id) != 0\r\n|| strcmp(next->name, label_id->id) != 0\r\n|| end != next->start)\r\ncontinue;\r\nend += resource_size(next);\r\nnvdimm_free_dpa(ndd, next);\r\nrc = adjust_resource(res, res->start, end - res->start);\r\nnd_dbg_dpa(nd_region, ndd, res, "merge %d\n", rc);\r\nif (rc)\r\nreturn rc;\r\nres->flags |= DPA_RESOURCE_ADJUSTED;\r\ngoto retry;\r\n}\r\nreturn 0;\r\n}\r\nstatic int __reserve_free_pmem(struct device *dev, void *data)\r\n{\r\nstruct nvdimm *nvdimm = data;\r\nstruct nd_region *nd_region;\r\nstruct nd_label_id label_id;\r\nint i;\r\nif (!is_nd_pmem(dev))\r\nreturn 0;\r\nnd_region = to_nd_region(dev);\r\nif (nd_region->ndr_mappings == 0)\r\nreturn 0;\r\nmemset(&label_id, 0, sizeof(label_id));\r\nstrcat(label_id.id, "pmem-reserve");\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nresource_size_t n, rem = 0;\r\nif (nd_mapping->nvdimm != nvdimm)\r\ncontinue;\r\nn = nd_pmem_available_dpa(nd_region, nd_mapping, &rem);\r\nif (n == 0)\r\nreturn 0;\r\nrem = scan_allocate(nd_region, nd_mapping, &label_id, n);\r\ndev_WARN_ONCE(&nd_region->dev, rem,\r\n"pmem reserve underrun: %#llx of %#llx bytes\n",\r\n(unsigned long long) n - rem,\r\n(unsigned long long) n);\r\nreturn rem ? -ENXIO : 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic void release_free_pmem(struct nvdimm_bus *nvdimm_bus,\r\nstruct nd_mapping *nd_mapping)\r\n{\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct resource *res, *_res;\r\nfor_each_dpa_resource_safe(ndd, res, _res)\r\nif (strcmp(res->name, "pmem-reserve") == 0)\r\nnvdimm_free_dpa(ndd, res);\r\n}\r\nstatic int reserve_free_pmem(struct nvdimm_bus *nvdimm_bus,\r\nstruct nd_mapping *nd_mapping)\r\n{\r\nstruct nvdimm *nvdimm = nd_mapping->nvdimm;\r\nint rc;\r\nrc = device_for_each_child(&nvdimm_bus->dev, nvdimm,\r\n__reserve_free_pmem);\r\nif (rc)\r\nrelease_free_pmem(nvdimm_bus, nd_mapping);\r\nreturn rc;\r\n}\r\nstatic int grow_dpa_allocation(struct nd_region *nd_region,\r\nstruct nd_label_id *label_id, resource_size_t n)\r\n{\r\nstruct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(&nd_region->dev);\r\nbool is_pmem = strncmp(label_id->id, "pmem", 4) == 0;\r\nint i;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nresource_size_t rem = n;\r\nint rc, j;\r\nfor (j = is_pmem; j < 2; j++) {\r\nbool blk_only = j == 0;\r\nif (blk_only) {\r\nrc = reserve_free_pmem(nvdimm_bus, nd_mapping);\r\nif (rc)\r\nreturn rc;\r\n}\r\nrem = scan_allocate(nd_region, nd_mapping,\r\nlabel_id, rem);\r\nif (blk_only)\r\nrelease_free_pmem(nvdimm_bus, nd_mapping);\r\nif (rem == 0)\r\nbreak;\r\n}\r\ndev_WARN_ONCE(&nd_region->dev, rem,\r\n"allocation underrun: %#llx of %#llx bytes\n",\r\n(unsigned long long) n - rem,\r\n(unsigned long long) n);\r\nif (rem)\r\nreturn -ENXIO;\r\nrc = merge_dpa(nd_region, nd_mapping, label_id);\r\nif (rc)\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic void nd_namespace_pmem_set_size(struct nd_region *nd_region,\r\nstruct nd_namespace_pmem *nspm, resource_size_t size)\r\n{\r\nstruct resource *res = &nspm->nsio.res;\r\nres->start = nd_region->ndr_start;\r\nres->end = nd_region->ndr_start + size - 1;\r\n}\r\nstatic ssize_t __size_store(struct device *dev, unsigned long long val)\r\n{\r\nresource_size_t allocated = 0, available = 0;\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nstruct nd_mapping *nd_mapping;\r\nstruct nvdimm_drvdata *ndd;\r\nstruct nd_label_id label_id;\r\nu32 flags = 0, remainder;\r\nu8 *uuid = NULL;\r\nint rc, i;\r\nif (dev->driver || to_ndns(dev)->claim)\r\nreturn -EBUSY;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nuuid = nspm->uuid;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nuuid = nsblk->uuid;\r\nflags = NSLABEL_FLAG_LOCAL;\r\n}\r\nif (!uuid || nd_region->ndr_mappings == 0)\r\nreturn -ENXIO;\r\ndiv_u64_rem(val, SZ_4K * nd_region->ndr_mappings, &remainder);\r\nif (remainder) {\r\ndev_dbg(dev, "%llu is not %dK aligned\n", val,\r\n(SZ_4K * nd_region->ndr_mappings) / SZ_1K);\r\nreturn -EINVAL;\r\n}\r\nnd_label_gen_id(&label_id, uuid, flags);\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nnd_mapping = &nd_region->mapping[i];\r\nndd = to_ndd(nd_mapping);\r\nif (!ndd)\r\nreturn -ENXIO;\r\nallocated += nvdimm_allocated_dpa(ndd, &label_id);\r\n}\r\navailable = nd_region_available_dpa(nd_region);\r\nif (val > available + allocated)\r\nreturn -ENOSPC;\r\nif (val == allocated)\r\nreturn 0;\r\nval = div_u64(val, nd_region->ndr_mappings);\r\nallocated = div_u64(allocated, nd_region->ndr_mappings);\r\nif (val < allocated)\r\nrc = shrink_dpa_allocation(nd_region, &label_id,\r\nallocated - val);\r\nelse\r\nrc = grow_dpa_allocation(nd_region, &label_id, val - allocated);\r\nif (rc)\r\nreturn rc;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nnd_namespace_pmem_set_size(nd_region, nspm,\r\nval * nd_region->ndr_mappings);\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nif (val == 0 && nd_region->ns_seed != dev\r\n&& !nsblk->common.claim)\r\nnd_device_unregister(dev, ND_ASYNC);\r\n}\r\nreturn rc;\r\n}\r\nstatic ssize_t size_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t len)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nunsigned long long val;\r\nu8 **uuid = NULL;\r\nint rc;\r\nrc = kstrtoull(buf, 0, &val);\r\nif (rc)\r\nreturn rc;\r\ndevice_lock(dev);\r\nnvdimm_bus_lock(dev);\r\nwait_nvdimm_bus_probe_idle(dev);\r\nrc = __size_store(dev, val);\r\nif (rc >= 0)\r\nrc = nd_namespace_label_update(nd_region, dev);\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nuuid = &nspm->uuid;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nuuid = &nsblk->uuid;\r\n}\r\nif (rc == 0 && val == 0 && uuid) {\r\nkfree(*uuid);\r\n*uuid = NULL;\r\n}\r\ndev_dbg(dev, "%s: %llx %s (%d)\n", __func__, val, rc < 0\r\n? "fail" : "success", rc);\r\nnvdimm_bus_unlock(dev);\r\ndevice_unlock(dev);\r\nreturn rc < 0 ? rc : len;\r\n}\r\nresource_size_t __nvdimm_namespace_capacity(struct nd_namespace_common *ndns)\r\n{\r\nstruct device *dev = &ndns->dev;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nreturn resource_size(&nspm->nsio.res);\r\n} else if (is_namespace_blk(dev)) {\r\nreturn nd_namespace_blk_size(to_nd_namespace_blk(dev));\r\n} else if (is_namespace_io(dev)) {\r\nstruct nd_namespace_io *nsio = to_nd_namespace_io(dev);\r\nreturn resource_size(&nsio->res);\r\n} else\r\nWARN_ONCE(1, "unknown namespace type\n");\r\nreturn 0;\r\n}\r\nresource_size_t nvdimm_namespace_capacity(struct nd_namespace_common *ndns)\r\n{\r\nresource_size_t size;\r\nnvdimm_bus_lock(&ndns->dev);\r\nsize = __nvdimm_namespace_capacity(ndns);\r\nnvdimm_bus_unlock(&ndns->dev);\r\nreturn size;\r\n}\r\nstatic ssize_t size_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nreturn sprintf(buf, "%llu\n", (unsigned long long)\r\nnvdimm_namespace_capacity(to_ndns(dev)));\r\n}\r\nstatic ssize_t uuid_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nu8 *uuid;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nuuid = nspm->uuid;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nuuid = nsblk->uuid;\r\n} else\r\nreturn -ENXIO;\r\nif (uuid)\r\nreturn sprintf(buf, "%pUb\n", uuid);\r\nreturn sprintf(buf, "\n");\r\n}\r\nstatic int namespace_update_uuid(struct nd_region *nd_region,\r\nstruct device *dev, u8 *new_uuid, u8 **old_uuid)\r\n{\r\nu32 flags = is_namespace_blk(dev) ? NSLABEL_FLAG_LOCAL : 0;\r\nstruct nd_label_id old_label_id;\r\nstruct nd_label_id new_label_id;\r\nint i;\r\nif (!nd_is_uuid_unique(dev, new_uuid))\r\nreturn -EINVAL;\r\nif (*old_uuid == NULL)\r\ngoto out;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nif (nd_mapping->labels)\r\nreturn -EBUSY;\r\n}\r\nnd_label_gen_id(&old_label_id, *old_uuid, flags);\r\nnd_label_gen_id(&new_label_id, new_uuid, flags);\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct resource *res;\r\nfor_each_dpa_resource(ndd, res)\r\nif (strcmp(res->name, old_label_id.id) == 0)\r\nsprintf((void *) res->name, "%s",\r\nnew_label_id.id);\r\n}\r\nkfree(*old_uuid);\r\nout:\r\n*old_uuid = new_uuid;\r\nreturn 0;\r\n}\r\nstatic ssize_t uuid_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t len)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nu8 *uuid = NULL;\r\nssize_t rc = 0;\r\nu8 **ns_uuid;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nns_uuid = &nspm->uuid;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nns_uuid = &nsblk->uuid;\r\n} else\r\nreturn -ENXIO;\r\ndevice_lock(dev);\r\nnvdimm_bus_lock(dev);\r\nwait_nvdimm_bus_probe_idle(dev);\r\nif (to_ndns(dev)->claim)\r\nrc = -EBUSY;\r\nif (rc >= 0)\r\nrc = nd_uuid_store(dev, &uuid, buf, len);\r\nif (rc >= 0)\r\nrc = namespace_update_uuid(nd_region, dev, uuid, ns_uuid);\r\nif (rc >= 0)\r\nrc = nd_namespace_label_update(nd_region, dev);\r\nelse\r\nkfree(uuid);\r\ndev_dbg(dev, "%s: result: %zd wrote: %s%s", __func__,\r\nrc, buf, buf[len - 1] == '\n' ? "" : "\n");\r\nnvdimm_bus_unlock(dev);\r\ndevice_unlock(dev);\r\nreturn rc < 0 ? rc : len;\r\n}\r\nstatic ssize_t resource_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct resource *res;\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nres = &nspm->nsio.res;\r\n} else if (is_namespace_io(dev)) {\r\nstruct nd_namespace_io *nsio = to_nd_namespace_io(dev);\r\nres = &nsio->res;\r\n} else\r\nreturn -ENXIO;\r\nif (resource_size(res) == 0)\r\nreturn -ENXIO;\r\nreturn sprintf(buf, "%#llx\n", (unsigned long long) res->start);\r\n}\r\nstatic ssize_t sector_size_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nif (!is_namespace_blk(dev))\r\nreturn -ENXIO;\r\nreturn nd_sector_size_show(nsblk->lbasize, ns_lbasize_supported, buf);\r\n}\r\nstatic ssize_t sector_size_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t len)\r\n{\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nssize_t rc = 0;\r\nif (!is_namespace_blk(dev))\r\nreturn -ENXIO;\r\ndevice_lock(dev);\r\nnvdimm_bus_lock(dev);\r\nif (to_ndns(dev)->claim)\r\nrc = -EBUSY;\r\nif (rc >= 0)\r\nrc = nd_sector_size_store(dev, buf, &nsblk->lbasize,\r\nns_lbasize_supported);\r\nif (rc >= 0)\r\nrc = nd_namespace_label_update(nd_region, dev);\r\ndev_dbg(dev, "%s: result: %zd %s: %s%s", __func__,\r\nrc, rc < 0 ? "tried" : "wrote", buf,\r\nbuf[len - 1] == '\n' ? "" : "\n");\r\nnvdimm_bus_unlock(dev);\r\ndevice_unlock(dev);\r\nreturn rc ? rc : len;\r\n}\r\nstatic ssize_t dpa_extents_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct nd_region *nd_region = to_nd_region(dev->parent);\r\nstruct nd_label_id label_id;\r\nint count = 0, i;\r\nu8 *uuid = NULL;\r\nu32 flags = 0;\r\nnvdimm_bus_lock(dev);\r\nif (is_namespace_pmem(dev)) {\r\nstruct nd_namespace_pmem *nspm = to_nd_namespace_pmem(dev);\r\nuuid = nspm->uuid;\r\nflags = 0;\r\n} else if (is_namespace_blk(dev)) {\r\nstruct nd_namespace_blk *nsblk = to_nd_namespace_blk(dev);\r\nuuid = nsblk->uuid;\r\nflags = NSLABEL_FLAG_LOCAL;\r\n}\r\nif (!uuid)\r\ngoto out;\r\nnd_label_gen_id(&label_id, uuid, flags);\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct resource *res;\r\nfor_each_dpa_resource(ndd, res)\r\nif (strcmp(res->name, label_id.id) == 0)\r\ncount++;\r\n}\r\nout:\r\nnvdimm_bus_unlock(dev);\r\nreturn sprintf(buf, "%d\n", count);\r\n}\r\nstatic ssize_t holder_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct nd_namespace_common *ndns = to_ndns(dev);\r\nssize_t rc;\r\ndevice_lock(dev);\r\nrc = sprintf(buf, "%s\n", ndns->claim ? dev_name(ndns->claim) : "");\r\ndevice_unlock(dev);\r\nreturn rc;\r\n}\r\nstatic ssize_t force_raw_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t len)\r\n{\r\nbool force_raw;\r\nint rc = strtobool(buf, &force_raw);\r\nif (rc)\r\nreturn rc;\r\nto_ndns(dev)->force_raw = force_raw;\r\nreturn len;\r\n}\r\nstatic ssize_t force_raw_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nreturn sprintf(buf, "%d\n", to_ndns(dev)->force_raw);\r\n}\r\nstatic umode_t namespace_visible(struct kobject *kobj,\r\nstruct attribute *a, int n)\r\n{\r\nstruct device *dev = container_of(kobj, struct device, kobj);\r\nif (a == &dev_attr_resource.attr) {\r\nif (is_namespace_blk(dev))\r\nreturn 0;\r\nreturn a->mode;\r\n}\r\nif (is_namespace_pmem(dev) || is_namespace_blk(dev)) {\r\nif (a == &dev_attr_size.attr)\r\nreturn S_IWUSR | S_IRUGO;\r\nif (is_namespace_pmem(dev) && a == &dev_attr_sector_size.attr)\r\nreturn 0;\r\nreturn a->mode;\r\n}\r\nif (a == &dev_attr_nstype.attr || a == &dev_attr_size.attr\r\n|| a == &dev_attr_holder.attr\r\n|| a == &dev_attr_force_raw.attr)\r\nreturn a->mode;\r\nreturn 0;\r\n}\r\nstruct nd_namespace_common *nvdimm_namespace_common_probe(struct device *dev)\r\n{\r\nstruct nd_btt *nd_btt = is_nd_btt(dev) ? to_nd_btt(dev) : NULL;\r\nstruct nd_pfn *nd_pfn = is_nd_pfn(dev) ? to_nd_pfn(dev) : NULL;\r\nstruct nd_namespace_common *ndns;\r\nresource_size_t size;\r\nif (nd_btt || nd_pfn) {\r\nstruct device *host = NULL;\r\nif (nd_btt) {\r\nhost = &nd_btt->dev;\r\nndns = nd_btt->ndns;\r\n} else if (nd_pfn) {\r\nhost = &nd_pfn->dev;\r\nndns = nd_pfn->ndns;\r\n}\r\nif (!ndns || !host)\r\nreturn ERR_PTR(-ENODEV);\r\ndevice_lock(&ndns->dev);\r\ndevice_unlock(&ndns->dev);\r\nif (ndns->dev.driver) {\r\ndev_dbg(&ndns->dev, "is active, can't bind %s\n",\r\ndev_name(host));\r\nreturn ERR_PTR(-EBUSY);\r\n}\r\nif (dev_WARN_ONCE(&ndns->dev, ndns->claim != host,\r\n"host (%s) vs claim (%s) mismatch\n",\r\ndev_name(host),\r\ndev_name(ndns->claim)))\r\nreturn ERR_PTR(-ENXIO);\r\n} else {\r\nndns = to_ndns(dev);\r\nif (ndns->claim) {\r\ndev_dbg(dev, "claimed by %s, failing probe\n",\r\ndev_name(ndns->claim));\r\nreturn ERR_PTR(-ENXIO);\r\n}\r\n}\r\nsize = nvdimm_namespace_capacity(ndns);\r\nif (size < ND_MIN_NAMESPACE_SIZE) {\r\ndev_dbg(&ndns->dev, "%pa, too small must be at least %#x\n",\r\n&size, ND_MIN_NAMESPACE_SIZE);\r\nreturn ERR_PTR(-ENODEV);\r\n}\r\nif (is_namespace_pmem(&ndns->dev)) {\r\nstruct nd_namespace_pmem *nspm;\r\nnspm = to_nd_namespace_pmem(&ndns->dev);\r\nif (!nspm->uuid) {\r\ndev_dbg(&ndns->dev, "%s: uuid not set\n", __func__);\r\nreturn ERR_PTR(-ENODEV);\r\n}\r\n} else if (is_namespace_blk(&ndns->dev)) {\r\nstruct nd_namespace_blk *nsblk;\r\nnsblk = to_nd_namespace_blk(&ndns->dev);\r\nif (!nd_namespace_blk_validate(nsblk))\r\nreturn ERR_PTR(-ENODEV);\r\n}\r\nreturn ndns;\r\n}\r\nstatic struct device **create_namespace_io(struct nd_region *nd_region)\r\n{\r\nstruct nd_namespace_io *nsio;\r\nstruct device *dev, **devs;\r\nstruct resource *res;\r\nnsio = kzalloc(sizeof(*nsio), GFP_KERNEL);\r\nif (!nsio)\r\nreturn NULL;\r\ndevs = kcalloc(2, sizeof(struct device *), GFP_KERNEL);\r\nif (!devs) {\r\nkfree(nsio);\r\nreturn NULL;\r\n}\r\ndev = &nsio->common.dev;\r\ndev->type = &namespace_io_device_type;\r\ndev->parent = &nd_region->dev;\r\nres = &nsio->res;\r\nres->name = dev_name(&nd_region->dev);\r\nres->flags = IORESOURCE_MEM;\r\nres->start = nd_region->ndr_start;\r\nres->end = res->start + nd_region->ndr_size - 1;\r\ndevs[0] = dev;\r\nreturn devs;\r\n}\r\nstatic bool has_uuid_at_pos(struct nd_region *nd_region, u8 *uuid,\r\nu64 cookie, u16 pos)\r\n{\r\nstruct nd_namespace_label *found = NULL;\r\nint i;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nstruct nd_namespace_label *nd_label;\r\nbool found_uuid = false;\r\nint l;\r\nfor_each_label(l, nd_label, nd_mapping->labels) {\r\nu64 isetcookie = __le64_to_cpu(nd_label->isetcookie);\r\nu16 position = __le16_to_cpu(nd_label->position);\r\nu16 nlabel = __le16_to_cpu(nd_label->nlabel);\r\nif (isetcookie != cookie)\r\ncontinue;\r\nif (memcmp(nd_label->uuid, uuid, NSLABEL_UUID_LEN) != 0)\r\ncontinue;\r\nif (found_uuid) {\r\ndev_dbg(to_ndd(nd_mapping)->dev,\r\n"%s duplicate entry for uuid\n",\r\n__func__);\r\nreturn false;\r\n}\r\nfound_uuid = true;\r\nif (nlabel != nd_region->ndr_mappings)\r\ncontinue;\r\nif (position != pos)\r\ncontinue;\r\nfound = nd_label;\r\nbreak;\r\n}\r\nif (found)\r\nbreak;\r\n}\r\nreturn found != NULL;\r\n}\r\nstatic int select_pmem_id(struct nd_region *nd_region, u8 *pmem_id)\r\n{\r\nstruct nd_namespace_label *select = NULL;\r\nint i;\r\nif (!pmem_id)\r\nreturn -ENODEV;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nstruct nd_namespace_label *nd_label;\r\nu64 hw_start, hw_end, pmem_start, pmem_end;\r\nint l;\r\nfor_each_label(l, nd_label, nd_mapping->labels)\r\nif (memcmp(nd_label->uuid, pmem_id, NSLABEL_UUID_LEN) == 0)\r\nbreak;\r\nif (!nd_label) {\r\nWARN_ON(1);\r\nreturn -EINVAL;\r\n}\r\nselect = nd_label;\r\nhw_start = nd_mapping->start;\r\nhw_end = hw_start + nd_mapping->size;\r\npmem_start = __le64_to_cpu(select->dpa);\r\npmem_end = pmem_start + __le64_to_cpu(select->rawsize);\r\nif (pmem_start == hw_start && pmem_end <= hw_end)\r\n;\r\nelse\r\nreturn -EINVAL;\r\nnd_mapping->labels[0] = select;\r\nnd_mapping->labels[1] = NULL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int find_pmem_label_set(struct nd_region *nd_region,\r\nstruct nd_namespace_pmem *nspm)\r\n{\r\nu64 cookie = nd_region_interleave_set_cookie(nd_region);\r\nstruct nd_namespace_label *nd_label;\r\nu8 select_id[NSLABEL_UUID_LEN];\r\nresource_size_t size = 0;\r\nu8 *pmem_id = NULL;\r\nint rc = -ENODEV, l;\r\nu16 i;\r\nif (cookie == 0)\r\nreturn -ENXIO;\r\nfor_each_label(l, nd_label, nd_region->mapping[0].labels) {\r\nu64 isetcookie = __le64_to_cpu(nd_label->isetcookie);\r\nif (isetcookie != cookie)\r\ncontinue;\r\nfor (i = 0; nd_region->ndr_mappings; i++)\r\nif (!has_uuid_at_pos(nd_region, nd_label->uuid,\r\ncookie, i))\r\nbreak;\r\nif (i < nd_region->ndr_mappings) {\r\nrc = -EINVAL;\r\ngoto err;\r\n} else if (pmem_id) {\r\nrc = -EBUSY;\r\ngoto err;\r\n}\r\nmemcpy(select_id, nd_label->uuid, NSLABEL_UUID_LEN);\r\npmem_id = select_id;\r\n}\r\nrc = select_pmem_id(nd_region, pmem_id);\r\nif (rc)\r\ngoto err;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nstruct nd_namespace_label *label0 = nd_mapping->labels[0];\r\nsize += __le64_to_cpu(label0->rawsize);\r\nif (__le16_to_cpu(label0->position) != 0)\r\ncontinue;\r\nWARN_ON(nspm->alt_name || nspm->uuid);\r\nnspm->alt_name = kmemdup((void __force *) label0->name,\r\nNSLABEL_NAME_LEN, GFP_KERNEL);\r\nnspm->uuid = kmemdup((void __force *) label0->uuid,\r\nNSLABEL_UUID_LEN, GFP_KERNEL);\r\n}\r\nif (!nspm->alt_name || !nspm->uuid) {\r\nrc = -ENOMEM;\r\ngoto err;\r\n}\r\nnd_namespace_pmem_set_size(nd_region, nspm, size);\r\nreturn 0;\r\nerr:\r\nswitch (rc) {\r\ncase -EINVAL:\r\ndev_dbg(&nd_region->dev, "%s: invalid label(s)\n", __func__);\r\nbreak;\r\ncase -ENODEV:\r\ndev_dbg(&nd_region->dev, "%s: label not found\n", __func__);\r\nbreak;\r\ndefault:\r\ndev_dbg(&nd_region->dev, "%s: unexpected err: %d\n",\r\n__func__, rc);\r\nbreak;\r\n}\r\nreturn rc;\r\n}\r\nstatic struct device **create_namespace_pmem(struct nd_region *nd_region)\r\n{\r\nstruct nd_namespace_pmem *nspm;\r\nstruct device *dev, **devs;\r\nstruct resource *res;\r\nint rc;\r\nnspm = kzalloc(sizeof(*nspm), GFP_KERNEL);\r\nif (!nspm)\r\nreturn NULL;\r\ndev = &nspm->nsio.common.dev;\r\ndev->type = &namespace_pmem_device_type;\r\ndev->parent = &nd_region->dev;\r\nres = &nspm->nsio.res;\r\nres->name = dev_name(&nd_region->dev);\r\nres->flags = IORESOURCE_MEM;\r\nrc = find_pmem_label_set(nd_region, nspm);\r\nif (rc == -ENODEV) {\r\nint i;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nkfree(nd_mapping->labels);\r\nnd_mapping->labels = NULL;\r\n}\r\nnd_namespace_pmem_set_size(nd_region, nspm, 0);\r\nrc = 0;\r\n} else if (rc)\r\ngoto err;\r\ndevs = kcalloc(2, sizeof(struct device *), GFP_KERNEL);\r\nif (!devs)\r\ngoto err;\r\ndevs[0] = dev;\r\nreturn devs;\r\nerr:\r\nnamespace_pmem_release(&nspm->nsio.common.dev);\r\nreturn NULL;\r\n}\r\nstruct resource *nsblk_add_resource(struct nd_region *nd_region,\r\nstruct nvdimm_drvdata *ndd, struct nd_namespace_blk *nsblk,\r\nresource_size_t start)\r\n{\r\nstruct nd_label_id label_id;\r\nstruct resource *res;\r\nnd_label_gen_id(&label_id, nsblk->uuid, NSLABEL_FLAG_LOCAL);\r\nres = krealloc(nsblk->res,\r\nsizeof(void *) * (nsblk->num_resources + 1),\r\nGFP_KERNEL);\r\nif (!res)\r\nreturn NULL;\r\nnsblk->res = (struct resource **) res;\r\nfor_each_dpa_resource(ndd, res)\r\nif (strcmp(res->name, label_id.id) == 0\r\n&& res->start == start) {\r\nnsblk->res[nsblk->num_resources++] = res;\r\nreturn res;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct device *nd_namespace_blk_create(struct nd_region *nd_region)\r\n{\r\nstruct nd_namespace_blk *nsblk;\r\nstruct device *dev;\r\nif (!is_nd_blk(&nd_region->dev))\r\nreturn NULL;\r\nnsblk = kzalloc(sizeof(*nsblk), GFP_KERNEL);\r\nif (!nsblk)\r\nreturn NULL;\r\ndev = &nsblk->common.dev;\r\ndev->type = &namespace_blk_device_type;\r\nnsblk->id = ida_simple_get(&nd_region->ns_ida, 0, 0, GFP_KERNEL);\r\nif (nsblk->id < 0) {\r\nkfree(nsblk);\r\nreturn NULL;\r\n}\r\ndev_set_name(dev, "namespace%d.%d", nd_region->id, nsblk->id);\r\ndev->parent = &nd_region->dev;\r\ndev->groups = nd_namespace_attribute_groups;\r\nreturn &nsblk->common.dev;\r\n}\r\nvoid nd_region_create_blk_seed(struct nd_region *nd_region)\r\n{\r\nWARN_ON(!is_nvdimm_bus_locked(&nd_region->dev));\r\nnd_region->ns_seed = nd_namespace_blk_create(nd_region);\r\nif (!nd_region->ns_seed)\r\ndev_err(&nd_region->dev, "failed to create blk namespace\n");\r\nelse\r\nnd_device_register(nd_region->ns_seed);\r\n}\r\nvoid nd_region_create_btt_seed(struct nd_region *nd_region)\r\n{\r\nWARN_ON(!is_nvdimm_bus_locked(&nd_region->dev));\r\nnd_region->btt_seed = nd_btt_create(nd_region);\r\nif (!nd_region->btt_seed)\r\ndev_err(&nd_region->dev, "failed to create btt namespace\n");\r\n}\r\nstatic struct device **create_namespace_blk(struct nd_region *nd_region)\r\n{\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[0];\r\nstruct nd_namespace_label *nd_label;\r\nstruct device *dev, **devs = NULL;\r\nstruct nd_namespace_blk *nsblk;\r\nstruct nvdimm_drvdata *ndd;\r\nint i, l, count = 0;\r\nstruct resource *res;\r\nif (nd_region->ndr_mappings == 0)\r\nreturn NULL;\r\nndd = to_ndd(nd_mapping);\r\nfor_each_label(l, nd_label, nd_mapping->labels) {\r\nu32 flags = __le32_to_cpu(nd_label->flags);\r\nchar *name[NSLABEL_NAME_LEN];\r\nstruct device **__devs;\r\nif (flags & NSLABEL_FLAG_LOCAL)\r\n;\r\nelse\r\ncontinue;\r\nfor (i = 0; i < count; i++) {\r\nnsblk = to_nd_namespace_blk(devs[i]);\r\nif (memcmp(nsblk->uuid, nd_label->uuid,\r\nNSLABEL_UUID_LEN) == 0) {\r\nres = nsblk_add_resource(nd_region, ndd, nsblk,\r\n__le64_to_cpu(nd_label->dpa));\r\nif (!res)\r\ngoto err;\r\nnd_dbg_dpa(nd_region, ndd, res, "%s assign\n",\r\ndev_name(&nsblk->common.dev));\r\nbreak;\r\n}\r\n}\r\nif (i < count)\r\ncontinue;\r\n__devs = kcalloc(count + 2, sizeof(dev), GFP_KERNEL);\r\nif (!__devs)\r\ngoto err;\r\nmemcpy(__devs, devs, sizeof(dev) * count);\r\nkfree(devs);\r\ndevs = __devs;\r\nnsblk = kzalloc(sizeof(*nsblk), GFP_KERNEL);\r\nif (!nsblk)\r\ngoto err;\r\ndev = &nsblk->common.dev;\r\ndev->type = &namespace_blk_device_type;\r\ndev->parent = &nd_region->dev;\r\ndev_set_name(dev, "namespace%d.%d", nd_region->id, count);\r\ndevs[count++] = dev;\r\nnsblk->id = -1;\r\nnsblk->lbasize = __le64_to_cpu(nd_label->lbasize);\r\nnsblk->uuid = kmemdup(nd_label->uuid, NSLABEL_UUID_LEN,\r\nGFP_KERNEL);\r\nif (!nsblk->uuid)\r\ngoto err;\r\nmemcpy(name, nd_label->name, NSLABEL_NAME_LEN);\r\nif (name[0])\r\nnsblk->alt_name = kmemdup(name, NSLABEL_NAME_LEN,\r\nGFP_KERNEL);\r\nres = nsblk_add_resource(nd_region, ndd, nsblk,\r\n__le64_to_cpu(nd_label->dpa));\r\nif (!res)\r\ngoto err;\r\nnd_dbg_dpa(nd_region, ndd, res, "%s assign\n",\r\ndev_name(&nsblk->common.dev));\r\n}\r\ndev_dbg(&nd_region->dev, "%s: discovered %d blk namespace%s\n",\r\n__func__, count, count == 1 ? "" : "s");\r\nif (count == 0) {\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nkfree(nd_mapping->labels);\r\nnd_mapping->labels = NULL;\r\n}\r\ndevs = kcalloc(2, sizeof(dev), GFP_KERNEL);\r\nif (!devs)\r\ngoto err;\r\nnsblk = kzalloc(sizeof(*nsblk), GFP_KERNEL);\r\nif (!nsblk)\r\ngoto err;\r\ndev = &nsblk->common.dev;\r\ndev->type = &namespace_blk_device_type;\r\ndev->parent = &nd_region->dev;\r\ndevs[count++] = dev;\r\n}\r\nreturn devs;\r\nerr:\r\nfor (i = 0; i < count; i++) {\r\nnsblk = to_nd_namespace_blk(devs[i]);\r\nnamespace_blk_release(&nsblk->common.dev);\r\n}\r\nkfree(devs);\r\nreturn NULL;\r\n}\r\nstatic int init_active_labels(struct nd_region *nd_region)\r\n{\r\nint i;\r\nfor (i = 0; i < nd_region->ndr_mappings; i++) {\r\nstruct nd_mapping *nd_mapping = &nd_region->mapping[i];\r\nstruct nvdimm_drvdata *ndd = to_ndd(nd_mapping);\r\nstruct nvdimm *nvdimm = nd_mapping->nvdimm;\r\nint count, j;\r\nif (!ndd) {\r\nif ((nvdimm->flags & NDD_ALIASING) == 0)\r\nreturn 0;\r\ndev_dbg(&nd_region->dev, "%s: is disabled, failing probe\n",\r\ndev_name(&nd_mapping->nvdimm->dev));\r\nreturn -ENXIO;\r\n}\r\nnd_mapping->ndd = ndd;\r\natomic_inc(&nvdimm->busy);\r\nget_ndd(ndd);\r\ncount = nd_label_active_count(ndd);\r\ndev_dbg(ndd->dev, "%s: %d\n", __func__, count);\r\nif (!count)\r\ncontinue;\r\nnd_mapping->labels = kcalloc(count + 1, sizeof(void *),\r\nGFP_KERNEL);\r\nif (!nd_mapping->labels)\r\nreturn -ENOMEM;\r\nfor (j = 0; j < count; j++) {\r\nstruct nd_namespace_label *label;\r\nlabel = nd_label_active(ndd, j);\r\nnd_mapping->labels[j] = label;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint nd_region_register_namespaces(struct nd_region *nd_region, int *err)\r\n{\r\nstruct device **devs = NULL;\r\nint i, rc = 0, type;\r\n*err = 0;\r\nnvdimm_bus_lock(&nd_region->dev);\r\nrc = init_active_labels(nd_region);\r\nif (rc) {\r\nnvdimm_bus_unlock(&nd_region->dev);\r\nreturn rc;\r\n}\r\ntype = nd_region_to_nstype(nd_region);\r\nswitch (type) {\r\ncase ND_DEVICE_NAMESPACE_IO:\r\ndevs = create_namespace_io(nd_region);\r\nbreak;\r\ncase ND_DEVICE_NAMESPACE_PMEM:\r\ndevs = create_namespace_pmem(nd_region);\r\nbreak;\r\ncase ND_DEVICE_NAMESPACE_BLK:\r\ndevs = create_namespace_blk(nd_region);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nnvdimm_bus_unlock(&nd_region->dev);\r\nif (!devs)\r\nreturn -ENODEV;\r\nfor (i = 0; devs[i]; i++) {\r\nstruct device *dev = devs[i];\r\nint id;\r\nif (type == ND_DEVICE_NAMESPACE_BLK) {\r\nstruct nd_namespace_blk *nsblk;\r\nnsblk = to_nd_namespace_blk(dev);\r\nid = ida_simple_get(&nd_region->ns_ida, 0, 0,\r\nGFP_KERNEL);\r\nnsblk->id = id;\r\n} else\r\nid = i;\r\nif (id < 0)\r\nbreak;\r\ndev_set_name(dev, "namespace%d.%d", nd_region->id, id);\r\ndev->groups = nd_namespace_attribute_groups;\r\nnd_device_register(dev);\r\n}\r\nif (i)\r\nnd_region->ns_seed = devs[0];\r\nif (devs[i]) {\r\nint j;\r\nfor (j = i; devs[j]; j++) {\r\nstruct device *dev = devs[j];\r\ndevice_initialize(dev);\r\nput_device(dev);\r\n}\r\n*err = j - i;\r\nif (*err == 0)\r\nrc = -ENODEV;\r\n}\r\nkfree(devs);\r\nif (rc == -ENODEV)\r\nreturn rc;\r\nreturn i;\r\n}
