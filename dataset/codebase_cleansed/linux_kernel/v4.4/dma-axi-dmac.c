static struct axi_dmac *chan_to_axi_dmac(struct axi_dmac_chan *chan)\r\n{\r\nreturn container_of(chan->vchan.chan.device, struct axi_dmac,\r\ndma_dev);\r\n}\r\nstatic struct axi_dmac_chan *to_axi_dmac_chan(struct dma_chan *c)\r\n{\r\nreturn container_of(c, struct axi_dmac_chan, vchan.chan);\r\n}\r\nstatic struct axi_dmac_desc *to_axi_dmac_desc(struct virt_dma_desc *vdesc)\r\n{\r\nreturn container_of(vdesc, struct axi_dmac_desc, vdesc);\r\n}\r\nstatic void axi_dmac_write(struct axi_dmac *axi_dmac, unsigned int reg,\r\nunsigned int val)\r\n{\r\nwritel(val, axi_dmac->base + reg);\r\n}\r\nstatic int axi_dmac_read(struct axi_dmac *axi_dmac, unsigned int reg)\r\n{\r\nreturn readl(axi_dmac->base + reg);\r\n}\r\nstatic int axi_dmac_src_is_mem(struct axi_dmac_chan *chan)\r\n{\r\nreturn chan->src_type == AXI_DMAC_BUS_TYPE_AXI_MM;\r\n}\r\nstatic int axi_dmac_dest_is_mem(struct axi_dmac_chan *chan)\r\n{\r\nreturn chan->dest_type == AXI_DMAC_BUS_TYPE_AXI_MM;\r\n}\r\nstatic bool axi_dmac_check_len(struct axi_dmac_chan *chan, unsigned int len)\r\n{\r\nif (len == 0 || len > chan->max_length)\r\nreturn false;\r\nif ((len & chan->align_mask) != 0)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic bool axi_dmac_check_addr(struct axi_dmac_chan *chan, dma_addr_t addr)\r\n{\r\nif ((addr & chan->align_mask) != 0)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void axi_dmac_start_transfer(struct axi_dmac_chan *chan)\r\n{\r\nstruct axi_dmac *dmac = chan_to_axi_dmac(chan);\r\nstruct virt_dma_desc *vdesc;\r\nstruct axi_dmac_desc *desc;\r\nstruct axi_dmac_sg *sg;\r\nunsigned int flags = 0;\r\nunsigned int val;\r\nval = axi_dmac_read(dmac, AXI_DMAC_REG_START_TRANSFER);\r\nif (val)\r\nreturn;\r\ndesc = chan->next_desc;\r\nif (!desc) {\r\nvdesc = vchan_next_desc(&chan->vchan);\r\nif (!vdesc)\r\nreturn;\r\nlist_move_tail(&vdesc->node, &chan->active_descs);\r\ndesc = to_axi_dmac_desc(vdesc);\r\n}\r\nsg = &desc->sg[desc->num_submitted];\r\ndesc->num_submitted++;\r\nif (desc->num_submitted == desc->num_sgs)\r\nchan->next_desc = NULL;\r\nelse\r\nchan->next_desc = desc;\r\nsg->id = axi_dmac_read(dmac, AXI_DMAC_REG_TRANSFER_ID);\r\nif (axi_dmac_dest_is_mem(chan)) {\r\naxi_dmac_write(dmac, AXI_DMAC_REG_DEST_ADDRESS, sg->dest_addr);\r\naxi_dmac_write(dmac, AXI_DMAC_REG_DEST_STRIDE, sg->dest_stride);\r\n}\r\nif (axi_dmac_src_is_mem(chan)) {\r\naxi_dmac_write(dmac, AXI_DMAC_REG_SRC_ADDRESS, sg->src_addr);\r\naxi_dmac_write(dmac, AXI_DMAC_REG_SRC_STRIDE, sg->src_stride);\r\n}\r\nif (chan->hw_cyclic && desc->cyclic && !desc->vdesc.tx.callback)\r\nflags |= AXI_DMAC_FLAG_CYCLIC;\r\naxi_dmac_write(dmac, AXI_DMAC_REG_X_LENGTH, sg->x_len - 1);\r\naxi_dmac_write(dmac, AXI_DMAC_REG_Y_LENGTH, sg->y_len - 1);\r\naxi_dmac_write(dmac, AXI_DMAC_REG_FLAGS, flags);\r\naxi_dmac_write(dmac, AXI_DMAC_REG_START_TRANSFER, 1);\r\n}\r\nstatic struct axi_dmac_desc *axi_dmac_active_desc(struct axi_dmac_chan *chan)\r\n{\r\nreturn list_first_entry_or_null(&chan->active_descs,\r\nstruct axi_dmac_desc, vdesc.node);\r\n}\r\nstatic void axi_dmac_transfer_done(struct axi_dmac_chan *chan,\r\nunsigned int completed_transfers)\r\n{\r\nstruct axi_dmac_desc *active;\r\nstruct axi_dmac_sg *sg;\r\nactive = axi_dmac_active_desc(chan);\r\nif (!active)\r\nreturn;\r\nif (active->cyclic) {\r\nvchan_cyclic_callback(&active->vdesc);\r\n} else {\r\ndo {\r\nsg = &active->sg[active->num_completed];\r\nif (!(BIT(sg->id) & completed_transfers))\r\nbreak;\r\nactive->num_completed++;\r\nif (active->num_completed == active->num_sgs) {\r\nlist_del(&active->vdesc.node);\r\nvchan_cookie_complete(&active->vdesc);\r\nactive = axi_dmac_active_desc(chan);\r\n}\r\n} while (active);\r\n}\r\n}\r\nstatic irqreturn_t axi_dmac_interrupt_handler(int irq, void *devid)\r\n{\r\nstruct axi_dmac *dmac = devid;\r\nunsigned int pending;\r\npending = axi_dmac_read(dmac, AXI_DMAC_REG_IRQ_PENDING);\r\naxi_dmac_write(dmac, AXI_DMAC_REG_IRQ_PENDING, pending);\r\nspin_lock(&dmac->chan.vchan.lock);\r\nif (pending & AXI_DMAC_IRQ_EOT) {\r\nunsigned int completed;\r\ncompleted = axi_dmac_read(dmac, AXI_DMAC_REG_TRANSFER_DONE);\r\naxi_dmac_transfer_done(&dmac->chan, completed);\r\n}\r\nif (pending & AXI_DMAC_IRQ_SOT)\r\naxi_dmac_start_transfer(&dmac->chan);\r\nspin_unlock(&dmac->chan.vchan.lock);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int axi_dmac_terminate_all(struct dma_chan *c)\r\n{\r\nstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\r\nstruct axi_dmac *dmac = chan_to_axi_dmac(chan);\r\nunsigned long flags;\r\nLIST_HEAD(head);\r\nspin_lock_irqsave(&chan->vchan.lock, flags);\r\naxi_dmac_write(dmac, AXI_DMAC_REG_CTRL, 0);\r\nchan->next_desc = NULL;\r\nvchan_get_all_descriptors(&chan->vchan, &head);\r\nlist_splice_tail_init(&chan->active_descs, &head);\r\nspin_unlock_irqrestore(&chan->vchan.lock, flags);\r\nvchan_dma_desc_free_list(&chan->vchan, &head);\r\nreturn 0;\r\n}\r\nstatic void axi_dmac_issue_pending(struct dma_chan *c)\r\n{\r\nstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\r\nstruct axi_dmac *dmac = chan_to_axi_dmac(chan);\r\nunsigned long flags;\r\naxi_dmac_write(dmac, AXI_DMAC_REG_CTRL, AXI_DMAC_CTRL_ENABLE);\r\nspin_lock_irqsave(&chan->vchan.lock, flags);\r\nif (vchan_issue_pending(&chan->vchan))\r\naxi_dmac_start_transfer(chan);\r\nspin_unlock_irqrestore(&chan->vchan.lock, flags);\r\n}\r\nstatic struct axi_dmac_desc *axi_dmac_alloc_desc(unsigned int num_sgs)\r\n{\r\nstruct axi_dmac_desc *desc;\r\ndesc = kzalloc(sizeof(struct axi_dmac_desc) +\r\nsizeof(struct axi_dmac_sg) * num_sgs, GFP_NOWAIT);\r\nif (!desc)\r\nreturn NULL;\r\ndesc->num_sgs = num_sgs;\r\nreturn desc;\r\n}\r\nstatic struct dma_async_tx_descriptor *axi_dmac_prep_slave_sg(\r\nstruct dma_chan *c, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\r\nstruct axi_dmac_desc *desc;\r\nstruct scatterlist *sg;\r\nunsigned int i;\r\nif (direction != chan->direction)\r\nreturn NULL;\r\ndesc = axi_dmac_alloc_desc(sg_len);\r\nif (!desc)\r\nreturn NULL;\r\nfor_each_sg(sgl, sg, sg_len, i) {\r\nif (!axi_dmac_check_addr(chan, sg_dma_address(sg)) ||\r\n!axi_dmac_check_len(chan, sg_dma_len(sg))) {\r\nkfree(desc);\r\nreturn NULL;\r\n}\r\nif (direction == DMA_DEV_TO_MEM)\r\ndesc->sg[i].dest_addr = sg_dma_address(sg);\r\nelse\r\ndesc->sg[i].src_addr = sg_dma_address(sg);\r\ndesc->sg[i].x_len = sg_dma_len(sg);\r\ndesc->sg[i].y_len = 1;\r\n}\r\ndesc->cyclic = false;\r\nreturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *axi_dmac_prep_dma_cyclic(\r\nstruct dma_chan *c, dma_addr_t buf_addr, size_t buf_len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags)\r\n{\r\nstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\r\nstruct axi_dmac_desc *desc;\r\nunsigned int num_periods, i;\r\nif (direction != chan->direction)\r\nreturn NULL;\r\nif (!axi_dmac_check_len(chan, buf_len) ||\r\n!axi_dmac_check_addr(chan, buf_addr))\r\nreturn NULL;\r\nif (period_len == 0 || buf_len % period_len)\r\nreturn NULL;\r\nnum_periods = buf_len / period_len;\r\ndesc = axi_dmac_alloc_desc(num_periods);\r\nif (!desc)\r\nreturn NULL;\r\nfor (i = 0; i < num_periods; i++) {\r\nif (direction == DMA_DEV_TO_MEM)\r\ndesc->sg[i].dest_addr = buf_addr;\r\nelse\r\ndesc->sg[i].src_addr = buf_addr;\r\ndesc->sg[i].x_len = period_len;\r\ndesc->sg[i].y_len = 1;\r\nbuf_addr += period_len;\r\n}\r\ndesc->cyclic = true;\r\nreturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *axi_dmac_prep_interleaved(\r\nstruct dma_chan *c, struct dma_interleaved_template *xt,\r\nunsigned long flags)\r\n{\r\nstruct axi_dmac_chan *chan = to_axi_dmac_chan(c);\r\nstruct axi_dmac_desc *desc;\r\nsize_t dst_icg, src_icg;\r\nif (xt->frame_size != 1)\r\nreturn NULL;\r\nif (xt->dir != chan->direction)\r\nreturn NULL;\r\nif (axi_dmac_src_is_mem(chan)) {\r\nif (!xt->src_inc || !axi_dmac_check_addr(chan, xt->src_start))\r\nreturn NULL;\r\n}\r\nif (axi_dmac_dest_is_mem(chan)) {\r\nif (!xt->dst_inc || !axi_dmac_check_addr(chan, xt->dst_start))\r\nreturn NULL;\r\n}\r\ndst_icg = dmaengine_get_dst_icg(xt, &xt->sgl[0]);\r\nsrc_icg = dmaengine_get_src_icg(xt, &xt->sgl[0]);\r\nif (chan->hw_2d) {\r\nif (!axi_dmac_check_len(chan, xt->sgl[0].size) ||\r\n!axi_dmac_check_len(chan, xt->numf))\r\nreturn NULL;\r\nif (xt->sgl[0].size + dst_icg > chan->max_length ||\r\nxt->sgl[0].size + src_icg > chan->max_length)\r\nreturn NULL;\r\n} else {\r\nif (dst_icg != 0 || src_icg != 0)\r\nreturn NULL;\r\nif (chan->max_length / xt->sgl[0].size < xt->numf)\r\nreturn NULL;\r\nif (!axi_dmac_check_len(chan, xt->sgl[0].size * xt->numf))\r\nreturn NULL;\r\n}\r\ndesc = axi_dmac_alloc_desc(1);\r\nif (!desc)\r\nreturn NULL;\r\nif (axi_dmac_src_is_mem(chan)) {\r\ndesc->sg[0].src_addr = xt->src_start;\r\ndesc->sg[0].src_stride = xt->sgl[0].size + src_icg;\r\n}\r\nif (axi_dmac_dest_is_mem(chan)) {\r\ndesc->sg[0].dest_addr = xt->dst_start;\r\ndesc->sg[0].dest_stride = xt->sgl[0].size + dst_icg;\r\n}\r\nif (chan->hw_2d) {\r\ndesc->sg[0].x_len = xt->sgl[0].size;\r\ndesc->sg[0].y_len = xt->numf;\r\n} else {\r\ndesc->sg[0].x_len = xt->sgl[0].size * xt->numf;\r\ndesc->sg[0].y_len = 1;\r\n}\r\nreturn vchan_tx_prep(&chan->vchan, &desc->vdesc, flags);\r\n}\r\nstatic void axi_dmac_free_chan_resources(struct dma_chan *c)\r\n{\r\nvchan_free_chan_resources(to_virt_chan(c));\r\n}\r\nstatic void axi_dmac_desc_free(struct virt_dma_desc *vdesc)\r\n{\r\nkfree(container_of(vdesc, struct axi_dmac_desc, vdesc));\r\n}\r\nstatic int axi_dmac_parse_chan_dt(struct device_node *of_chan,\r\nstruct axi_dmac_chan *chan)\r\n{\r\nu32 val;\r\nint ret;\r\nret = of_property_read_u32(of_chan, "reg", &val);\r\nif (ret)\r\nreturn ret;\r\nif (val != 0)\r\nreturn -EINVAL;\r\nret = of_property_read_u32(of_chan, "adi,source-bus-type", &val);\r\nif (ret)\r\nreturn ret;\r\nif (val > AXI_DMAC_BUS_TYPE_FIFO)\r\nreturn -EINVAL;\r\nchan->src_type = val;\r\nret = of_property_read_u32(of_chan, "adi,destination-bus-type", &val);\r\nif (ret)\r\nreturn ret;\r\nif (val > AXI_DMAC_BUS_TYPE_FIFO)\r\nreturn -EINVAL;\r\nchan->dest_type = val;\r\nret = of_property_read_u32(of_chan, "adi,source-bus-width", &val);\r\nif (ret)\r\nreturn ret;\r\nchan->src_width = val / 8;\r\nret = of_property_read_u32(of_chan, "adi,destination-bus-width", &val);\r\nif (ret)\r\nreturn ret;\r\nchan->dest_width = val / 8;\r\nret = of_property_read_u32(of_chan, "adi,length-width", &val);\r\nif (ret)\r\nreturn ret;\r\nif (val >= 32)\r\nchan->max_length = UINT_MAX;\r\nelse\r\nchan->max_length = (1ULL << val) - 1;\r\nchan->align_mask = max(chan->dest_width, chan->src_width) - 1;\r\nif (axi_dmac_dest_is_mem(chan) && axi_dmac_src_is_mem(chan))\r\nchan->direction = DMA_MEM_TO_MEM;\r\nelse if (!axi_dmac_dest_is_mem(chan) && axi_dmac_src_is_mem(chan))\r\nchan->direction = DMA_MEM_TO_DEV;\r\nelse if (axi_dmac_dest_is_mem(chan) && !axi_dmac_src_is_mem(chan))\r\nchan->direction = DMA_DEV_TO_MEM;\r\nelse\r\nchan->direction = DMA_DEV_TO_DEV;\r\nchan->hw_cyclic = of_property_read_bool(of_chan, "adi,cyclic");\r\nchan->hw_2d = of_property_read_bool(of_chan, "adi,2d");\r\nreturn 0;\r\n}\r\nstatic int axi_dmac_probe(struct platform_device *pdev)\r\n{\r\nstruct device_node *of_channels, *of_chan;\r\nstruct dma_device *dma_dev;\r\nstruct axi_dmac *dmac;\r\nstruct resource *res;\r\nint ret;\r\ndmac = devm_kzalloc(&pdev->dev, sizeof(*dmac), GFP_KERNEL);\r\nif (!dmac)\r\nreturn -ENOMEM;\r\ndmac->irq = platform_get_irq(pdev, 0);\r\nif (dmac->irq <= 0)\r\nreturn -EINVAL;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\ndmac->base = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(dmac->base))\r\nreturn PTR_ERR(dmac->base);\r\ndmac->clk = devm_clk_get(&pdev->dev, NULL);\r\nif (IS_ERR(dmac->clk))\r\nreturn PTR_ERR(dmac->clk);\r\nINIT_LIST_HEAD(&dmac->chan.active_descs);\r\nof_channels = of_get_child_by_name(pdev->dev.of_node, "adi,channels");\r\nif (of_channels == NULL)\r\nreturn -ENODEV;\r\nfor_each_child_of_node(of_channels, of_chan) {\r\nret = axi_dmac_parse_chan_dt(of_chan, &dmac->chan);\r\nif (ret) {\r\nof_node_put(of_chan);\r\nof_node_put(of_channels);\r\nreturn -EINVAL;\r\n}\r\n}\r\nof_node_put(of_channels);\r\npdev->dev.dma_parms = &dmac->dma_parms;\r\ndma_set_max_seg_size(&pdev->dev, dmac->chan.max_length);\r\ndma_dev = &dmac->dma_dev;\r\ndma_cap_set(DMA_SLAVE, dma_dev->cap_mask);\r\ndma_cap_set(DMA_CYCLIC, dma_dev->cap_mask);\r\ndma_dev->device_free_chan_resources = axi_dmac_free_chan_resources;\r\ndma_dev->device_tx_status = dma_cookie_status;\r\ndma_dev->device_issue_pending = axi_dmac_issue_pending;\r\ndma_dev->device_prep_slave_sg = axi_dmac_prep_slave_sg;\r\ndma_dev->device_prep_dma_cyclic = axi_dmac_prep_dma_cyclic;\r\ndma_dev->device_prep_interleaved_dma = axi_dmac_prep_interleaved;\r\ndma_dev->device_terminate_all = axi_dmac_terminate_all;\r\ndma_dev->dev = &pdev->dev;\r\ndma_dev->chancnt = 1;\r\ndma_dev->src_addr_widths = BIT(dmac->chan.src_width);\r\ndma_dev->dst_addr_widths = BIT(dmac->chan.dest_width);\r\ndma_dev->directions = BIT(dmac->chan.direction);\r\ndma_dev->residue_granularity = DMA_RESIDUE_GRANULARITY_DESCRIPTOR;\r\nINIT_LIST_HEAD(&dma_dev->channels);\r\ndmac->chan.vchan.desc_free = axi_dmac_desc_free;\r\nvchan_init(&dmac->chan.vchan, dma_dev);\r\nret = clk_prepare_enable(dmac->clk);\r\nif (ret < 0)\r\nreturn ret;\r\naxi_dmac_write(dmac, AXI_DMAC_REG_IRQ_MASK, 0x00);\r\nret = dma_async_device_register(dma_dev);\r\nif (ret)\r\ngoto err_clk_disable;\r\nret = of_dma_controller_register(pdev->dev.of_node,\r\nof_dma_xlate_by_chan_id, dma_dev);\r\nif (ret)\r\ngoto err_unregister_device;\r\nret = request_irq(dmac->irq, axi_dmac_interrupt_handler, 0,\r\ndev_name(&pdev->dev), dmac);\r\nif (ret)\r\ngoto err_unregister_of;\r\nplatform_set_drvdata(pdev, dmac);\r\nreturn 0;\r\nerr_unregister_of:\r\nof_dma_controller_free(pdev->dev.of_node);\r\nerr_unregister_device:\r\ndma_async_device_unregister(&dmac->dma_dev);\r\nerr_clk_disable:\r\nclk_disable_unprepare(dmac->clk);\r\nreturn ret;\r\n}\r\nstatic int axi_dmac_remove(struct platform_device *pdev)\r\n{\r\nstruct axi_dmac *dmac = platform_get_drvdata(pdev);\r\nof_dma_controller_free(pdev->dev.of_node);\r\nfree_irq(dmac->irq, dmac);\r\ntasklet_kill(&dmac->chan.vchan.task);\r\ndma_async_device_unregister(&dmac->dma_dev);\r\nclk_disable_unprepare(dmac->clk);\r\nreturn 0;\r\n}
