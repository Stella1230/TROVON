static char *get_dma_direction(u32 status)\r\n{\r\nswitch (status & DIRECTIONAL_MSK) {\r\ncase INPUT_ONLY: return "Input";\r\ncase OUTPUT_ONLY: return "Output";\r\ncase BIDIRECTIONAL: return "Bidirectional";\r\n}\r\nreturn "";\r\n}\r\nstatic void show_dma_capability(struct cobalt *cobalt)\r\n{\r\nu32 header = ioread32(CAPABILITY_HEADER);\r\nu32 capa = ioread32(CAPABILITY_REGISTER);\r\nu32 i;\r\ncobalt_info("Omnitek DMA capability: ID 0x%02x Version 0x%02x Next 0x%x Size 0x%x\n",\r\nheader & 0xff, (header >> 8) & 0xff,\r\n(header >> 16) & 0xffff, (capa >> 24) & 0xff);\r\nswitch ((capa >> 8) & 0x3) {\r\ncase 0:\r\ncobalt_info("Omnitek DMA: 32 bits PCIe and Local\n");\r\nbreak;\r\ncase 1:\r\ncobalt_info("Omnitek DMA: 64 bits PCIe, 32 bits Local\n");\r\nbreak;\r\ncase 3:\r\ncobalt_info("Omnitek DMA: 64 bits PCIe and Local\n");\r\nbreak;\r\n}\r\nfor (i = 0; i < (capa & 0xf); i++) {\r\nu32 status = ioread32(CS_REG(i));\r\ncobalt_info("Omnitek DMA channel #%d: %s %s\n", i,\r\nstatus & DMA_TYPE_FIFO ? "FIFO" : "MEMORY",\r\nget_dma_direction(status));\r\n}\r\n}\r\nvoid omni_sg_dma_start(struct cobalt_stream *s, struct sg_dma_desc_info *desc)\r\n{\r\nstruct cobalt *cobalt = s->cobalt;\r\niowrite32((u32)((u64)desc->bus >> 32), DESCRIPTOR(s->dma_channel) + 4);\r\niowrite32((u32)desc->bus & NEXT_ADRS_MSK, DESCRIPTOR(s->dma_channel));\r\niowrite32(ENABLE | SCATTER_GATHER_MODE | START, CS_REG(s->dma_channel));\r\n}\r\nbool is_dma_done(struct cobalt_stream *s)\r\n{\r\nstruct cobalt *cobalt = s->cobalt;\r\nif (ioread32(CS_REG(s->dma_channel)) & DONE)\r\nreturn true;\r\nreturn false;\r\n}\r\nvoid omni_sg_dma_abort_channel(struct cobalt_stream *s)\r\n{\r\nstruct cobalt *cobalt = s->cobalt;\r\nif (is_dma_done(s) == false)\r\niowrite32(ABORT, CS_REG(s->dma_channel));\r\n}\r\nint omni_sg_dma_init(struct cobalt *cobalt)\r\n{\r\nu32 capa = ioread32(CAPABILITY_REGISTER);\r\nint i;\r\ncobalt->first_fifo_channel = 0;\r\ncobalt->dma_channels = capa & 0xf;\r\nif (capa & PCI_64BIT)\r\ncobalt->pci_32_bit = false;\r\nelse\r\ncobalt->pci_32_bit = true;\r\nfor (i = 0; i < cobalt->dma_channels; i++) {\r\nu32 status = ioread32(CS_REG(i));\r\nu32 ctrl = ioread32(CS_REG(i));\r\nif (!(ctrl & DONE))\r\niowrite32(ABORT, CS_REG(i));\r\nif (!(status & DMA_TYPE_FIFO))\r\ncobalt->first_fifo_channel++;\r\n}\r\nshow_dma_capability(cobalt);\r\nreturn 0;\r\n}\r\nint descriptor_list_create(struct cobalt *cobalt,\r\nstruct scatterlist *scatter_list, bool to_pci, unsigned sglen,\r\nunsigned size, unsigned width, unsigned stride,\r\nstruct sg_dma_desc_info *desc)\r\n{\r\nstruct sg_dma_descriptor *d = (struct sg_dma_descriptor *)desc->virt;\r\ndma_addr_t next = desc->bus;\r\nunsigned offset = 0;\r\nunsigned copy_bytes = width;\r\nunsigned copied = 0;\r\nbool first = true;\r\nWARN_ON(sg_dma_address(scatter_list) & 3);\r\nWARN_ON(size & 3);\r\nWARN_ON(next & 3);\r\nWARN_ON(stride & 3);\r\nWARN_ON(stride < width);\r\nif (width >= stride)\r\ncopy_bytes = stride = size;\r\nwhile (size) {\r\ndma_addr_t addr = sg_dma_address(scatter_list) + offset;\r\nunsigned bytes;\r\nif (addr == 0)\r\nreturn -EFAULT;\r\nif (cobalt->pci_32_bit) {\r\nWARN_ON((u64)addr >> 32);\r\nif ((u64)addr >> 32)\r\nreturn -EFAULT;\r\n}\r\nd->pci_l = addr & 0xffffffff;\r\nd->pci_h = (u64)addr >> 32;\r\nd->local = 0;\r\nd->reserved0 = 0;\r\nbytes = min(sg_dma_len(scatter_list) - offset,\r\ncopy_bytes - copied);\r\nif (first) {\r\nif (to_pci)\r\nd->local = 0x11111111;\r\nfirst = false;\r\nif (sglen == 1) {\r\nd->bytes = (bytes / 2) & ~3;\r\nd->reserved1 = 0;\r\nsize -= d->bytes;\r\ncopied += d->bytes;\r\noffset += d->bytes;\r\naddr += d->bytes;\r\nnext += sizeof(struct sg_dma_descriptor);\r\nd->next_h = (u32)((u64)next >> 32);\r\nd->next_l = (u32)next |\r\n(to_pci ? WRITE_TO_PCI : 0);\r\nbytes -= d->bytes;\r\nd++;\r\nd->pci_l = addr & 0xffffffff;\r\nd->pci_h = (u64)addr >> 32;\r\nd->local = 0;\r\nd->reserved0 = 0;\r\n}\r\n}\r\nd->bytes = bytes;\r\nd->reserved1 = 0;\r\nsize -= bytes;\r\ncopied += bytes;\r\noffset += bytes;\r\nif (copied == copy_bytes) {\r\nwhile (copied < stride) {\r\nbytes = min(sg_dma_len(scatter_list) - offset,\r\nstride - copied);\r\ncopied += bytes;\r\noffset += bytes;\r\nsize -= bytes;\r\nif (sg_dma_len(scatter_list) == offset) {\r\noffset = 0;\r\nscatter_list = sg_next(scatter_list);\r\n}\r\n}\r\ncopied = 0;\r\n} else {\r\noffset = 0;\r\nscatter_list = sg_next(scatter_list);\r\n}\r\nnext += sizeof(struct sg_dma_descriptor);\r\nif (size == 0) {\r\nd->next_h = (u32)((u64)desc->bus >> 32);\r\nd->next_l = (u32)desc->bus |\r\n(to_pci ? WRITE_TO_PCI : 0) | INTERRUPT_ENABLE;\r\nif (!to_pci)\r\nd->local = 0x22222222;\r\ndesc->last_desc_virt = d;\r\n} else {\r\nd->next_h = (u32)((u64)next >> 32);\r\nd->next_l = (u32)next | (to_pci ? WRITE_TO_PCI : 0);\r\n}\r\nd++;\r\n}\r\nreturn 0;\r\n}\r\nvoid descriptor_list_chain(struct sg_dma_desc_info *this,\r\nstruct sg_dma_desc_info *next)\r\n{\r\nstruct sg_dma_descriptor *d = this->last_desc_virt;\r\nu32 direction = d->next_l & WRITE_TO_PCI;\r\nif (next == NULL) {\r\nd->next_h = 0;\r\nd->next_l = direction | INTERRUPT_ENABLE | END_OF_CHAIN;\r\n} else {\r\nd->next_h = (u32)((u64)next->bus >> 32);\r\nd->next_l = (u32)next->bus | direction | INTERRUPT_ENABLE;\r\n}\r\n}\r\nvoid *descriptor_list_allocate(struct sg_dma_desc_info *desc, size_t bytes)\r\n{\r\ndesc->size = bytes;\r\ndesc->virt = dma_alloc_coherent(desc->dev, bytes,\r\n&desc->bus, GFP_KERNEL);\r\nreturn desc->virt;\r\n}\r\nvoid descriptor_list_free(struct sg_dma_desc_info *desc)\r\n{\r\nif (desc->virt)\r\ndma_free_coherent(desc->dev, desc->size,\r\ndesc->virt, desc->bus);\r\ndesc->virt = NULL;\r\n}\r\nvoid descriptor_list_interrupt_enable(struct sg_dma_desc_info *desc)\r\n{\r\nstruct sg_dma_descriptor *d = desc->last_desc_virt;\r\nd->next_l |= INTERRUPT_ENABLE;\r\n}\r\nvoid descriptor_list_interrupt_disable(struct sg_dma_desc_info *desc)\r\n{\r\nstruct sg_dma_descriptor *d = desc->last_desc_virt;\r\nd->next_l &= ~INTERRUPT_ENABLE;\r\n}\r\nvoid descriptor_list_loopback(struct sg_dma_desc_info *desc)\r\n{\r\nstruct sg_dma_descriptor *d = desc->last_desc_virt;\r\nd->next_h = (u32)((u64)desc->bus >> 32);\r\nd->next_l = (u32)desc->bus | (d->next_l & DESCRIPTOR_FLAG_MSK);\r\n}\r\nvoid descriptor_list_end_of_chain(struct sg_dma_desc_info *desc)\r\n{\r\nstruct sg_dma_descriptor *d = desc->last_desc_virt;\r\nd->next_l |= END_OF_CHAIN;\r\n}
