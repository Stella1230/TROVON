static int adf_enable_msix(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_accel_pci *pci_dev_info = &accel_dev->accel_pci_dev;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nu32 msix_num_entries = 1;\r\nif (!accel_dev->pf.vf_info) {\r\nint i;\r\nmsix_num_entries += hw_data->num_banks;\r\nfor (i = 0; i < msix_num_entries; i++)\r\npci_dev_info->msix_entries.entries[i].entry = i;\r\n} else {\r\npci_dev_info->msix_entries.entries[0].entry =\r\nhw_data->num_banks;\r\n}\r\nif (pci_enable_msix_exact(pci_dev_info->pci_dev,\r\npci_dev_info->msix_entries.entries,\r\nmsix_num_entries)) {\r\ndev_err(&GET_DEV(accel_dev), "Failed to enable MSI-X IRQ(s)\n");\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nstatic void adf_disable_msix(struct adf_accel_pci *pci_dev_info)\r\n{\r\npci_disable_msix(pci_dev_info->pci_dev);\r\n}\r\nstatic irqreturn_t adf_msix_isr_bundle(int irq, void *bank_ptr)\r\n{\r\nstruct adf_etr_bank_data *bank = bank_ptr;\r\nWRITE_CSR_INT_FLAG_AND_COL(bank->csr_addr, bank->bank_number, 0);\r\ntasklet_hi_schedule(&bank->resp_handler);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t adf_msix_isr_ae(int irq, void *dev_ptr)\r\n{\r\nstruct adf_accel_dev *accel_dev = dev_ptr;\r\n#ifdef CONFIG_PCI_IOV\r\nif (accel_dev->pf.vf_info) {\r\nvoid __iomem *pmisc_bar_addr =\r\n(&GET_BARS(accel_dev)[ADF_DH895XCC_PMISC_BAR])->virt_addr;\r\nu32 vf_mask;\r\nvf_mask = ((ADF_CSR_RD(pmisc_bar_addr, ADF_DH895XCC_ERRSOU5) &\r\n0x0000FFFF) << 16) |\r\n((ADF_CSR_RD(pmisc_bar_addr, ADF_DH895XCC_ERRSOU3) &\r\n0x01FFFE00) >> 9);\r\nif (vf_mask) {\r\nstruct adf_accel_vf_info *vf_info;\r\nbool irq_handled = false;\r\nint i;\r\nadf_disable_vf2pf_interrupts(accel_dev, vf_mask);\r\nfor_each_set_bit(i, (const unsigned long *)&vf_mask,\r\n(sizeof(vf_mask) * BITS_PER_BYTE)) {\r\nvf_info = accel_dev->pf.vf_info + i;\r\nif (!__ratelimit(&vf_info->vf2pf_ratelimit)) {\r\ndev_info(&GET_DEV(accel_dev),\r\n"Too many ints from VF%d\n",\r\nvf_info->vf_nr + 1);\r\ncontinue;\r\n}\r\ntasklet_hi_schedule(&vf_info->vf2pf_bh_tasklet);\r\nirq_handled = true;\r\n}\r\nif (irq_handled)\r\nreturn IRQ_HANDLED;\r\n}\r\n}\r\n#endif\r\ndev_dbg(&GET_DEV(accel_dev), "qat_dev%d spurious AE interrupt\n",\r\naccel_dev->accel_id);\r\nreturn IRQ_NONE;\r\n}\r\nstatic int adf_request_irqs(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_accel_pci *pci_dev_info = &accel_dev->accel_pci_dev;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nstruct msix_entry *msixe = pci_dev_info->msix_entries.entries;\r\nstruct adf_etr_data *etr_data = accel_dev->transport;\r\nint ret, i = 0;\r\nchar *name;\r\nif (!accel_dev->pf.vf_info) {\r\nfor (i = 0; i < hw_data->num_banks; i++) {\r\nstruct adf_etr_bank_data *bank = &etr_data->banks[i];\r\nunsigned int cpu, cpus = num_online_cpus();\r\nname = *(pci_dev_info->msix_entries.names + i);\r\nsnprintf(name, ADF_MAX_MSIX_VECTOR_NAME,\r\n"qat%d-bundle%d", accel_dev->accel_id, i);\r\nret = request_irq(msixe[i].vector,\r\nadf_msix_isr_bundle, 0, name, bank);\r\nif (ret) {\r\ndev_err(&GET_DEV(accel_dev),\r\n"failed to enable irq %d for %s\n",\r\nmsixe[i].vector, name);\r\nreturn ret;\r\n}\r\ncpu = ((accel_dev->accel_id * hw_data->num_banks) +\r\ni) % cpus;\r\nirq_set_affinity_hint(msixe[i].vector,\r\nget_cpu_mask(cpu));\r\n}\r\n}\r\nname = *(pci_dev_info->msix_entries.names + i);\r\nsnprintf(name, ADF_MAX_MSIX_VECTOR_NAME,\r\n"qat%d-ae-cluster", accel_dev->accel_id);\r\nret = request_irq(msixe[i].vector, adf_msix_isr_ae, 0, name, accel_dev);\r\nif (ret) {\r\ndev_err(&GET_DEV(accel_dev),\r\n"failed to enable irq %d, for %s\n",\r\nmsixe[i].vector, name);\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic void adf_free_irqs(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_accel_pci *pci_dev_info = &accel_dev->accel_pci_dev;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nstruct msix_entry *msixe = pci_dev_info->msix_entries.entries;\r\nstruct adf_etr_data *etr_data = accel_dev->transport;\r\nint i = 0;\r\nif (pci_dev_info->msix_entries.num_entries > 1) {\r\nfor (i = 0; i < hw_data->num_banks; i++) {\r\nirq_set_affinity_hint(msixe[i].vector, NULL);\r\nfree_irq(msixe[i].vector, &etr_data->banks[i]);\r\n}\r\n}\r\nirq_set_affinity_hint(msixe[i].vector, NULL);\r\nfree_irq(msixe[i].vector, accel_dev);\r\n}\r\nstatic int adf_isr_alloc_msix_entry_table(struct adf_accel_dev *accel_dev)\r\n{\r\nint i;\r\nchar **names;\r\nstruct msix_entry *entries;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nu32 msix_num_entries = 1;\r\nif (!accel_dev->pf.vf_info)\r\nmsix_num_entries += hw_data->num_banks;\r\nentries = kzalloc_node(msix_num_entries * sizeof(*entries),\r\nGFP_KERNEL, dev_to_node(&GET_DEV(accel_dev)));\r\nif (!entries)\r\nreturn -ENOMEM;\r\nnames = kcalloc(msix_num_entries, sizeof(char *), GFP_KERNEL);\r\nif (!names) {\r\nkfree(entries);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < msix_num_entries; i++) {\r\n*(names + i) = kzalloc(ADF_MAX_MSIX_VECTOR_NAME, GFP_KERNEL);\r\nif (!(*(names + i)))\r\ngoto err;\r\n}\r\naccel_dev->accel_pci_dev.msix_entries.num_entries = msix_num_entries;\r\naccel_dev->accel_pci_dev.msix_entries.entries = entries;\r\naccel_dev->accel_pci_dev.msix_entries.names = names;\r\nreturn 0;\r\nerr:\r\nfor (i = 0; i < msix_num_entries; i++)\r\nkfree(*(names + i));\r\nkfree(entries);\r\nkfree(names);\r\nreturn -ENOMEM;\r\n}\r\nstatic void adf_isr_free_msix_entry_table(struct adf_accel_dev *accel_dev)\r\n{\r\nchar **names = accel_dev->accel_pci_dev.msix_entries.names;\r\nint i;\r\nkfree(accel_dev->accel_pci_dev.msix_entries.entries);\r\nfor (i = 0; i < accel_dev->accel_pci_dev.msix_entries.num_entries; i++)\r\nkfree(*(names + i));\r\nkfree(names);\r\n}\r\nstatic int adf_setup_bh(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_etr_data *priv_data = accel_dev->transport;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nint i;\r\nfor (i = 0; i < hw_data->num_banks; i++)\r\ntasklet_init(&priv_data->banks[i].resp_handler,\r\nadf_response_handler,\r\n(unsigned long)&priv_data->banks[i]);\r\nreturn 0;\r\n}\r\nstatic void adf_cleanup_bh(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct adf_etr_data *priv_data = accel_dev->transport;\r\nstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\r\nint i;\r\nfor (i = 0; i < hw_data->num_banks; i++) {\r\ntasklet_disable(&priv_data->banks[i].resp_handler);\r\ntasklet_kill(&priv_data->banks[i].resp_handler);\r\n}\r\n}\r\nvoid adf_isr_resource_free(struct adf_accel_dev *accel_dev)\r\n{\r\nadf_free_irqs(accel_dev);\r\nadf_cleanup_bh(accel_dev);\r\nadf_disable_msix(&accel_dev->accel_pci_dev);\r\nadf_isr_free_msix_entry_table(accel_dev);\r\n}\r\nint adf_isr_resource_alloc(struct adf_accel_dev *accel_dev)\r\n{\r\nint ret;\r\nret = adf_isr_alloc_msix_entry_table(accel_dev);\r\nif (ret)\r\nreturn ret;\r\nif (adf_enable_msix(accel_dev))\r\ngoto err_out;\r\nif (adf_setup_bh(accel_dev))\r\ngoto err_out;\r\nif (adf_request_irqs(accel_dev))\r\ngoto err_out;\r\nreturn 0;\r\nerr_out:\r\nadf_isr_resource_free(accel_dev);\r\nreturn -EFAULT;\r\n}
