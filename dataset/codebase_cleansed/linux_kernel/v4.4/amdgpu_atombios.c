static void amdgpu_atombios_lookup_i2c_gpio_quirks(struct amdgpu_device *adev,\r\nATOM_GPIO_I2C_ASSIGMENT *gpio,\r\nu8 index)\r\n{\r\n}\r\nstatic struct amdgpu_i2c_bus_rec amdgpu_atombios_get_bus_rec_for_i2c_gpio(ATOM_GPIO_I2C_ASSIGMENT *gpio)\r\n{\r\nstruct amdgpu_i2c_bus_rec i2c;\r\nmemset(&i2c, 0, sizeof(struct amdgpu_i2c_bus_rec));\r\ni2c.mask_clk_reg = le16_to_cpu(gpio->usClkMaskRegisterIndex);\r\ni2c.mask_data_reg = le16_to_cpu(gpio->usDataMaskRegisterIndex);\r\ni2c.en_clk_reg = le16_to_cpu(gpio->usClkEnRegisterIndex);\r\ni2c.en_data_reg = le16_to_cpu(gpio->usDataEnRegisterIndex);\r\ni2c.y_clk_reg = le16_to_cpu(gpio->usClkY_RegisterIndex);\r\ni2c.y_data_reg = le16_to_cpu(gpio->usDataY_RegisterIndex);\r\ni2c.a_clk_reg = le16_to_cpu(gpio->usClkA_RegisterIndex);\r\ni2c.a_data_reg = le16_to_cpu(gpio->usDataA_RegisterIndex);\r\ni2c.mask_clk_mask = (1 << gpio->ucClkMaskShift);\r\ni2c.mask_data_mask = (1 << gpio->ucDataMaskShift);\r\ni2c.en_clk_mask = (1 << gpio->ucClkEnShift);\r\ni2c.en_data_mask = (1 << gpio->ucDataEnShift);\r\ni2c.y_clk_mask = (1 << gpio->ucClkY_Shift);\r\ni2c.y_data_mask = (1 << gpio->ucDataY_Shift);\r\ni2c.a_clk_mask = (1 << gpio->ucClkA_Shift);\r\ni2c.a_data_mask = (1 << gpio->ucDataA_Shift);\r\nif (gpio->sucI2cId.sbfAccess.bfHW_Capable)\r\ni2c.hw_capable = true;\r\nelse\r\ni2c.hw_capable = false;\r\nif (gpio->sucI2cId.ucAccess == 0xa0)\r\ni2c.mm_i2c = true;\r\nelse\r\ni2c.mm_i2c = false;\r\ni2c.i2c_id = gpio->sucI2cId.ucAccess;\r\nif (i2c.mask_clk_reg)\r\ni2c.valid = true;\r\nelse\r\ni2c.valid = false;\r\nreturn i2c;\r\n}\r\nstruct amdgpu_i2c_bus_rec amdgpu_atombios_lookup_i2c_gpio(struct amdgpu_device *adev,\r\nuint8_t id)\r\n{\r\nstruct atom_context *ctx = adev->mode_info.atom_context;\r\nATOM_GPIO_I2C_ASSIGMENT *gpio;\r\nstruct amdgpu_i2c_bus_rec i2c;\r\nint index = GetIndexIntoMasterTable(DATA, GPIO_I2C_Info);\r\nstruct _ATOM_GPIO_I2C_INFO *i2c_info;\r\nuint16_t data_offset, size;\r\nint i, num_indices;\r\nmemset(&i2c, 0, sizeof(struct amdgpu_i2c_bus_rec));\r\ni2c.valid = false;\r\nif (amdgpu_atom_parse_data_header(ctx, index, &size, NULL, NULL, &data_offset)) {\r\ni2c_info = (struct _ATOM_GPIO_I2C_INFO *)(ctx->bios + data_offset);\r\nnum_indices = (size - sizeof(ATOM_COMMON_TABLE_HEADER)) /\r\nsizeof(ATOM_GPIO_I2C_ASSIGMENT);\r\ngpio = &i2c_info->asGPIO_Info[0];\r\nfor (i = 0; i < num_indices; i++) {\r\namdgpu_atombios_lookup_i2c_gpio_quirks(adev, gpio, i);\r\nif (gpio->sucI2cId.ucAccess == id) {\r\ni2c = amdgpu_atombios_get_bus_rec_for_i2c_gpio(gpio);\r\nbreak;\r\n}\r\ngpio = (ATOM_GPIO_I2C_ASSIGMENT *)\r\n((u8 *)gpio + sizeof(ATOM_GPIO_I2C_ASSIGMENT));\r\n}\r\n}\r\nreturn i2c;\r\n}\r\nvoid amdgpu_atombios_i2c_init(struct amdgpu_device *adev)\r\n{\r\nstruct atom_context *ctx = adev->mode_info.atom_context;\r\nATOM_GPIO_I2C_ASSIGMENT *gpio;\r\nstruct amdgpu_i2c_bus_rec i2c;\r\nint index = GetIndexIntoMasterTable(DATA, GPIO_I2C_Info);\r\nstruct _ATOM_GPIO_I2C_INFO *i2c_info;\r\nuint16_t data_offset, size;\r\nint i, num_indices;\r\nchar stmp[32];\r\nif (amdgpu_atom_parse_data_header(ctx, index, &size, NULL, NULL, &data_offset)) {\r\ni2c_info = (struct _ATOM_GPIO_I2C_INFO *)(ctx->bios + data_offset);\r\nnum_indices = (size - sizeof(ATOM_COMMON_TABLE_HEADER)) /\r\nsizeof(ATOM_GPIO_I2C_ASSIGMENT);\r\ngpio = &i2c_info->asGPIO_Info[0];\r\nfor (i = 0; i < num_indices; i++) {\r\namdgpu_atombios_lookup_i2c_gpio_quirks(adev, gpio, i);\r\ni2c = amdgpu_atombios_get_bus_rec_for_i2c_gpio(gpio);\r\nif (i2c.valid) {\r\nsprintf(stmp, "0x%x", i2c.i2c_id);\r\nadev->i2c_bus[i] = amdgpu_i2c_create(adev->ddev, &i2c, stmp);\r\n}\r\ngpio = (ATOM_GPIO_I2C_ASSIGMENT *)\r\n((u8 *)gpio + sizeof(ATOM_GPIO_I2C_ASSIGMENT));\r\n}\r\n}\r\n}\r\nstruct amdgpu_gpio_rec\r\namdgpu_atombios_lookup_gpio(struct amdgpu_device *adev,\r\nu8 id)\r\n{\r\nstruct atom_context *ctx = adev->mode_info.atom_context;\r\nstruct amdgpu_gpio_rec gpio;\r\nint index = GetIndexIntoMasterTable(DATA, GPIO_Pin_LUT);\r\nstruct _ATOM_GPIO_PIN_LUT *gpio_info;\r\nATOM_GPIO_PIN_ASSIGNMENT *pin;\r\nu16 data_offset, size;\r\nint i, num_indices;\r\nmemset(&gpio, 0, sizeof(struct amdgpu_gpio_rec));\r\ngpio.valid = false;\r\nif (amdgpu_atom_parse_data_header(ctx, index, &size, NULL, NULL, &data_offset)) {\r\ngpio_info = (struct _ATOM_GPIO_PIN_LUT *)(ctx->bios + data_offset);\r\nnum_indices = (size - sizeof(ATOM_COMMON_TABLE_HEADER)) /\r\nsizeof(ATOM_GPIO_PIN_ASSIGNMENT);\r\npin = gpio_info->asGPIO_Pin;\r\nfor (i = 0; i < num_indices; i++) {\r\nif (id == pin->ucGPIO_ID) {\r\ngpio.id = pin->ucGPIO_ID;\r\ngpio.reg = le16_to_cpu(pin->usGpioPin_AIndex);\r\ngpio.shift = pin->ucGpioPinBitShift;\r\ngpio.mask = (1 << pin->ucGpioPinBitShift);\r\ngpio.valid = true;\r\nbreak;\r\n}\r\npin = (ATOM_GPIO_PIN_ASSIGNMENT *)\r\n((u8 *)pin + sizeof(ATOM_GPIO_PIN_ASSIGNMENT));\r\n}\r\n}\r\nreturn gpio;\r\n}\r\nstatic struct amdgpu_hpd\r\namdgpu_atombios_get_hpd_info_from_gpio(struct amdgpu_device *adev,\r\nstruct amdgpu_gpio_rec *gpio)\r\n{\r\nstruct amdgpu_hpd hpd;\r\nu32 reg;\r\nmemset(&hpd, 0, sizeof(struct amdgpu_hpd));\r\nreg = amdgpu_display_hpd_get_gpio_reg(adev);\r\nhpd.gpio = *gpio;\r\nif (gpio->reg == reg) {\r\nswitch(gpio->mask) {\r\ncase (1 << 0):\r\nhpd.hpd = AMDGPU_HPD_1;\r\nbreak;\r\ncase (1 << 8):\r\nhpd.hpd = AMDGPU_HPD_2;\r\nbreak;\r\ncase (1 << 16):\r\nhpd.hpd = AMDGPU_HPD_3;\r\nbreak;\r\ncase (1 << 24):\r\nhpd.hpd = AMDGPU_HPD_4;\r\nbreak;\r\ncase (1 << 26):\r\nhpd.hpd = AMDGPU_HPD_5;\r\nbreak;\r\ncase (1 << 28):\r\nhpd.hpd = AMDGPU_HPD_6;\r\nbreak;\r\ndefault:\r\nhpd.hpd = AMDGPU_HPD_NONE;\r\nbreak;\r\n}\r\n} else\r\nhpd.hpd = AMDGPU_HPD_NONE;\r\nreturn hpd;\r\n}\r\nstatic bool amdgpu_atombios_apply_quirks(struct amdgpu_device *adev,\r\nuint32_t supported_device,\r\nint *connector_type,\r\nstruct amdgpu_i2c_bus_rec *i2c_bus,\r\nuint16_t *line_mux,\r\nstruct amdgpu_hpd *hpd)\r\n{\r\nreturn true;\r\n}\r\nbool amdgpu_atombios_get_connector_info_from_object_table(struct amdgpu_device *adev)\r\n{\r\nstruct amdgpu_mode_info *mode_info = &adev->mode_info;\r\nstruct atom_context *ctx = mode_info->atom_context;\r\nint index = GetIndexIntoMasterTable(DATA, Object_Header);\r\nu16 size, data_offset;\r\nu8 frev, crev;\r\nATOM_CONNECTOR_OBJECT_TABLE *con_obj;\r\nATOM_ENCODER_OBJECT_TABLE *enc_obj;\r\nATOM_OBJECT_TABLE *router_obj;\r\nATOM_DISPLAY_OBJECT_PATH_TABLE *path_obj;\r\nATOM_OBJECT_HEADER *obj_header;\r\nint i, j, k, path_size, device_support;\r\nint connector_type;\r\nu16 conn_id, connector_object_id;\r\nstruct amdgpu_i2c_bus_rec ddc_bus;\r\nstruct amdgpu_router router;\r\nstruct amdgpu_gpio_rec gpio;\r\nstruct amdgpu_hpd hpd;\r\nif (!amdgpu_atom_parse_data_header(ctx, index, &size, &frev, &crev, &data_offset))\r\nreturn false;\r\nif (crev < 2)\r\nreturn false;\r\nobj_header = (ATOM_OBJECT_HEADER *) (ctx->bios + data_offset);\r\npath_obj = (ATOM_DISPLAY_OBJECT_PATH_TABLE *)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(obj_header->usDisplayPathTableOffset));\r\ncon_obj = (ATOM_CONNECTOR_OBJECT_TABLE *)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(obj_header->usConnectorObjectTableOffset));\r\nenc_obj = (ATOM_ENCODER_OBJECT_TABLE *)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(obj_header->usEncoderObjectTableOffset));\r\nrouter_obj = (ATOM_OBJECT_TABLE *)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(obj_header->usRouterObjectTableOffset));\r\ndevice_support = le16_to_cpu(obj_header->usDeviceSupport);\r\npath_size = 0;\r\nfor (i = 0; i < path_obj->ucNumOfDispPath; i++) {\r\nuint8_t *addr = (uint8_t *) path_obj->asDispPath;\r\nATOM_DISPLAY_OBJECT_PATH *path;\r\naddr += path_size;\r\npath = (ATOM_DISPLAY_OBJECT_PATH *) addr;\r\npath_size += le16_to_cpu(path->usSize);\r\nif (device_support & le16_to_cpu(path->usDeviceTag)) {\r\nuint8_t con_obj_id, con_obj_num, con_obj_type;\r\ncon_obj_id =\r\n(le16_to_cpu(path->usConnObjectId) & OBJECT_ID_MASK)\r\n>> OBJECT_ID_SHIFT;\r\ncon_obj_num =\r\n(le16_to_cpu(path->usConnObjectId) & ENUM_ID_MASK)\r\n>> ENUM_ID_SHIFT;\r\ncon_obj_type =\r\n(le16_to_cpu(path->usConnObjectId) &\r\nOBJECT_TYPE_MASK) >> OBJECT_TYPE_SHIFT;\r\nconnector_type =\r\nobject_connector_convert[con_obj_id];\r\nconnector_object_id = con_obj_id;\r\nif (connector_type == DRM_MODE_CONNECTOR_Unknown)\r\ncontinue;\r\nrouter.ddc_valid = false;\r\nrouter.cd_valid = false;\r\nfor (j = 0; j < ((le16_to_cpu(path->usSize) - 8) / 2); j++) {\r\nuint8_t grph_obj_id, grph_obj_num, grph_obj_type;\r\ngrph_obj_id =\r\n(le16_to_cpu(path->usGraphicObjIds[j]) &\r\nOBJECT_ID_MASK) >> OBJECT_ID_SHIFT;\r\ngrph_obj_num =\r\n(le16_to_cpu(path->usGraphicObjIds[j]) &\r\nENUM_ID_MASK) >> ENUM_ID_SHIFT;\r\ngrph_obj_type =\r\n(le16_to_cpu(path->usGraphicObjIds[j]) &\r\nOBJECT_TYPE_MASK) >> OBJECT_TYPE_SHIFT;\r\nif (grph_obj_type == GRAPH_OBJECT_TYPE_ENCODER) {\r\nfor (k = 0; k < enc_obj->ucNumberOfObjects; k++) {\r\nu16 encoder_obj = le16_to_cpu(enc_obj->asObjects[k].usObjectID);\r\nif (le16_to_cpu(path->usGraphicObjIds[j]) == encoder_obj) {\r\nATOM_COMMON_RECORD_HEADER *record = (ATOM_COMMON_RECORD_HEADER *)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(enc_obj->asObjects[k].usRecordOffset));\r\nATOM_ENCODER_CAP_RECORD *cap_record;\r\nu16 caps = 0;\r\nwhile (record->ucRecordSize > 0 &&\r\nrecord->ucRecordType > 0 &&\r\nrecord->ucRecordType <= ATOM_MAX_OBJECT_RECORD_NUMBER) {\r\nswitch (record->ucRecordType) {\r\ncase ATOM_ENCODER_CAP_RECORD_TYPE:\r\ncap_record =(ATOM_ENCODER_CAP_RECORD *)\r\nrecord;\r\ncaps = le16_to_cpu(cap_record->usEncoderCap);\r\nbreak;\r\n}\r\nrecord = (ATOM_COMMON_RECORD_HEADER *)\r\n((char *)record + record->ucRecordSize);\r\n}\r\namdgpu_display_add_encoder(adev, encoder_obj,\r\nle16_to_cpu(path->usDeviceTag),\r\ncaps);\r\n}\r\n}\r\n} else if (grph_obj_type == GRAPH_OBJECT_TYPE_ROUTER) {\r\nfor (k = 0; k < router_obj->ucNumberOfObjects; k++) {\r\nu16 router_obj_id = le16_to_cpu(router_obj->asObjects[k].usObjectID);\r\nif (le16_to_cpu(path->usGraphicObjIds[j]) == router_obj_id) {\r\nATOM_COMMON_RECORD_HEADER *record = (ATOM_COMMON_RECORD_HEADER *)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(router_obj->asObjects[k].usRecordOffset));\r\nATOM_I2C_RECORD *i2c_record;\r\nATOM_I2C_ID_CONFIG_ACCESS *i2c_config;\r\nATOM_ROUTER_DDC_PATH_SELECT_RECORD *ddc_path;\r\nATOM_ROUTER_DATA_CLOCK_PATH_SELECT_RECORD *cd_path;\r\nATOM_SRC_DST_TABLE_FOR_ONE_OBJECT *router_src_dst_table =\r\n(ATOM_SRC_DST_TABLE_FOR_ONE_OBJECT *)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(router_obj->asObjects[k].usSrcDstTableOffset));\r\nu8 *num_dst_objs = (u8 *)\r\n((u8 *)router_src_dst_table + 1 +\r\n(router_src_dst_table->ucNumberOfSrc * 2));\r\nu16 *dst_objs = (u16 *)(num_dst_objs + 1);\r\nint enum_id;\r\nrouter.router_id = router_obj_id;\r\nfor (enum_id = 0; enum_id < (*num_dst_objs); enum_id++) {\r\nif (le16_to_cpu(path->usConnObjectId) ==\r\nle16_to_cpu(dst_objs[enum_id]))\r\nbreak;\r\n}\r\nwhile (record->ucRecordSize > 0 &&\r\nrecord->ucRecordType > 0 &&\r\nrecord->ucRecordType <= ATOM_MAX_OBJECT_RECORD_NUMBER) {\r\nswitch (record->ucRecordType) {\r\ncase ATOM_I2C_RECORD_TYPE:\r\ni2c_record =\r\n(ATOM_I2C_RECORD *)\r\nrecord;\r\ni2c_config =\r\n(ATOM_I2C_ID_CONFIG_ACCESS *)\r\n&i2c_record->sucI2cId;\r\nrouter.i2c_info =\r\namdgpu_atombios_lookup_i2c_gpio(adev,\r\ni2c_config->\r\nucAccess);\r\nrouter.i2c_addr = i2c_record->ucI2CAddr >> 1;\r\nbreak;\r\ncase ATOM_ROUTER_DDC_PATH_SELECT_RECORD_TYPE:\r\nddc_path = (ATOM_ROUTER_DDC_PATH_SELECT_RECORD *)\r\nrecord;\r\nrouter.ddc_valid = true;\r\nrouter.ddc_mux_type = ddc_path->ucMuxType;\r\nrouter.ddc_mux_control_pin = ddc_path->ucMuxControlPin;\r\nrouter.ddc_mux_state = ddc_path->ucMuxState[enum_id];\r\nbreak;\r\ncase ATOM_ROUTER_DATA_CLOCK_PATH_SELECT_RECORD_TYPE:\r\ncd_path = (ATOM_ROUTER_DATA_CLOCK_PATH_SELECT_RECORD *)\r\nrecord;\r\nrouter.cd_valid = true;\r\nrouter.cd_mux_type = cd_path->ucMuxType;\r\nrouter.cd_mux_control_pin = cd_path->ucMuxControlPin;\r\nrouter.cd_mux_state = cd_path->ucMuxState[enum_id];\r\nbreak;\r\n}\r\nrecord = (ATOM_COMMON_RECORD_HEADER *)\r\n((char *)record + record->ucRecordSize);\r\n}\r\n}\r\n}\r\n}\r\n}\r\nddc_bus.valid = false;\r\nhpd.hpd = AMDGPU_HPD_NONE;\r\nif ((le16_to_cpu(path->usDeviceTag) &\r\n(ATOM_DEVICE_TV_SUPPORT | ATOM_DEVICE_CV_SUPPORT)) == 0) {\r\nfor (j = 0; j < con_obj->ucNumberOfObjects; j++) {\r\nif (le16_to_cpu(path->usConnObjectId) ==\r\nle16_to_cpu(con_obj->asObjects[j].\r\nusObjectID)) {\r\nATOM_COMMON_RECORD_HEADER\r\n*record =\r\n(ATOM_COMMON_RECORD_HEADER\r\n*)\r\n(ctx->bios + data_offset +\r\nle16_to_cpu(con_obj->\r\nasObjects[j].\r\nusRecordOffset));\r\nATOM_I2C_RECORD *i2c_record;\r\nATOM_HPD_INT_RECORD *hpd_record;\r\nATOM_I2C_ID_CONFIG_ACCESS *i2c_config;\r\nwhile (record->ucRecordSize > 0 &&\r\nrecord->ucRecordType > 0 &&\r\nrecord->ucRecordType <= ATOM_MAX_OBJECT_RECORD_NUMBER) {\r\nswitch (record->ucRecordType) {\r\ncase ATOM_I2C_RECORD_TYPE:\r\ni2c_record =\r\n(ATOM_I2C_RECORD *)\r\nrecord;\r\ni2c_config =\r\n(ATOM_I2C_ID_CONFIG_ACCESS *)\r\n&i2c_record->sucI2cId;\r\nddc_bus = amdgpu_atombios_lookup_i2c_gpio(adev,\r\ni2c_config->\r\nucAccess);\r\nbreak;\r\ncase ATOM_HPD_INT_RECORD_TYPE:\r\nhpd_record =\r\n(ATOM_HPD_INT_RECORD *)\r\nrecord;\r\ngpio = amdgpu_atombios_lookup_gpio(adev,\r\nhpd_record->ucHPDIntGPIOID);\r\nhpd = amdgpu_atombios_get_hpd_info_from_gpio(adev, &gpio);\r\nhpd.plugged_state = hpd_record->ucPlugged_PinState;\r\nbreak;\r\n}\r\nrecord =\r\n(ATOM_COMMON_RECORD_HEADER\r\n*) ((char *)record\r\n+\r\nrecord->\r\nucRecordSize);\r\n}\r\nbreak;\r\n}\r\n}\r\n}\r\nddc_bus.hpd = hpd.hpd;\r\nconn_id = le16_to_cpu(path->usConnObjectId);\r\nif (!amdgpu_atombios_apply_quirks\r\n(adev, le16_to_cpu(path->usDeviceTag), &connector_type,\r\n&ddc_bus, &conn_id, &hpd))\r\ncontinue;\r\namdgpu_display_add_connector(adev,\r\nconn_id,\r\nle16_to_cpu(path->usDeviceTag),\r\nconnector_type, &ddc_bus,\r\nconnector_object_id,\r\n&hpd,\r\n&router);\r\n}\r\n}\r\namdgpu_link_encoder_connector(adev->ddev);\r\nreturn true;\r\n}\r\nint amdgpu_atombios_get_clock_info(struct amdgpu_device *adev)\r\n{\r\nstruct amdgpu_mode_info *mode_info = &adev->mode_info;\r\nint index = GetIndexIntoMasterTable(DATA, FirmwareInfo);\r\nuint8_t frev, crev;\r\nuint16_t data_offset;\r\nint ret = -EINVAL;\r\nif (amdgpu_atom_parse_data_header(mode_info->atom_context, index, NULL,\r\n&frev, &crev, &data_offset)) {\r\nint i;\r\nstruct amdgpu_pll *ppll = &adev->clock.ppll[0];\r\nstruct amdgpu_pll *spll = &adev->clock.spll;\r\nstruct amdgpu_pll *mpll = &adev->clock.mpll;\r\nunion firmware_info *firmware_info =\r\n(union firmware_info *)(mode_info->atom_context->bios +\r\ndata_offset);\r\nppll->reference_freq =\r\nle16_to_cpu(firmware_info->info.usReferenceClock);\r\nppll->reference_div = 0;\r\nif (crev < 2)\r\nppll->pll_out_min =\r\nle16_to_cpu(firmware_info->info.usMinPixelClockPLL_Output);\r\nelse\r\nppll->pll_out_min =\r\nle32_to_cpu(firmware_info->info_12.ulMinPixelClockPLL_Output);\r\nppll->pll_out_max =\r\nle32_to_cpu(firmware_info->info.ulMaxPixelClockPLL_Output);\r\nif (crev >= 4) {\r\nppll->lcd_pll_out_min =\r\nle16_to_cpu(firmware_info->info_14.usLcdMinPixelClockPLL_Output) * 100;\r\nif (ppll->lcd_pll_out_min == 0)\r\nppll->lcd_pll_out_min = ppll->pll_out_min;\r\nppll->lcd_pll_out_max =\r\nle16_to_cpu(firmware_info->info_14.usLcdMaxPixelClockPLL_Output) * 100;\r\nif (ppll->lcd_pll_out_max == 0)\r\nppll->lcd_pll_out_max = ppll->pll_out_max;\r\n} else {\r\nppll->lcd_pll_out_min = ppll->pll_out_min;\r\nppll->lcd_pll_out_max = ppll->pll_out_max;\r\n}\r\nif (ppll->pll_out_min == 0)\r\nppll->pll_out_min = 64800;\r\nppll->pll_in_min =\r\nle16_to_cpu(firmware_info->info.usMinPixelClockPLL_Input);\r\nppll->pll_in_max =\r\nle16_to_cpu(firmware_info->info.usMaxPixelClockPLL_Input);\r\nppll->min_post_div = 2;\r\nppll->max_post_div = 0x7f;\r\nppll->min_frac_feedback_div = 0;\r\nppll->max_frac_feedback_div = 9;\r\nppll->min_ref_div = 2;\r\nppll->max_ref_div = 0x3ff;\r\nppll->min_feedback_div = 4;\r\nppll->max_feedback_div = 0xfff;\r\nppll->best_vco = 0;\r\nfor (i = 1; i < AMDGPU_MAX_PPLL; i++)\r\nadev->clock.ppll[i] = *ppll;\r\nspll->reference_freq =\r\nle16_to_cpu(firmware_info->info_21.usCoreReferenceClock);\r\nspll->reference_div = 0;\r\nspll->pll_out_min =\r\nle16_to_cpu(firmware_info->info.usMinEngineClockPLL_Output);\r\nspll->pll_out_max =\r\nle32_to_cpu(firmware_info->info.ulMaxEngineClockPLL_Output);\r\nif (spll->pll_out_min == 0)\r\nspll->pll_out_min = 64800;\r\nspll->pll_in_min =\r\nle16_to_cpu(firmware_info->info.usMinEngineClockPLL_Input);\r\nspll->pll_in_max =\r\nle16_to_cpu(firmware_info->info.usMaxEngineClockPLL_Input);\r\nspll->min_post_div = 1;\r\nspll->max_post_div = 1;\r\nspll->min_ref_div = 2;\r\nspll->max_ref_div = 0xff;\r\nspll->min_feedback_div = 4;\r\nspll->max_feedback_div = 0xff;\r\nspll->best_vco = 0;\r\nmpll->reference_freq =\r\nle16_to_cpu(firmware_info->info_21.usMemoryReferenceClock);\r\nmpll->reference_div = 0;\r\nmpll->pll_out_min =\r\nle16_to_cpu(firmware_info->info.usMinMemoryClockPLL_Output);\r\nmpll->pll_out_max =\r\nle32_to_cpu(firmware_info->info.ulMaxMemoryClockPLL_Output);\r\nif (mpll->pll_out_min == 0)\r\nmpll->pll_out_min = 64800;\r\nmpll->pll_in_min =\r\nle16_to_cpu(firmware_info->info.usMinMemoryClockPLL_Input);\r\nmpll->pll_in_max =\r\nle16_to_cpu(firmware_info->info.usMaxMemoryClockPLL_Input);\r\nadev->clock.default_sclk =\r\nle32_to_cpu(firmware_info->info.ulDefaultEngineClock);\r\nadev->clock.default_mclk =\r\nle32_to_cpu(firmware_info->info.ulDefaultMemoryClock);\r\nmpll->min_post_div = 1;\r\nmpll->max_post_div = 1;\r\nmpll->min_ref_div = 2;\r\nmpll->max_ref_div = 0xff;\r\nmpll->min_feedback_div = 4;\r\nmpll->max_feedback_div = 0xff;\r\nmpll->best_vco = 0;\r\nadev->clock.default_dispclk =\r\nle32_to_cpu(firmware_info->info_21.ulDefaultDispEngineClkFreq);\r\nif (adev->clock.default_dispclk < 53900) {\r\nDRM_INFO("Changing default dispclk from %dMhz to 600Mhz\n",\r\nadev->clock.default_dispclk / 100);\r\nadev->clock.default_dispclk = 60000;\r\n}\r\nadev->clock.dp_extclk =\r\nle16_to_cpu(firmware_info->info_21.usUniphyDPModeExtClkFreq);\r\nadev->clock.current_dispclk = adev->clock.default_dispclk;\r\nadev->clock.max_pixel_clock = le16_to_cpu(firmware_info->info.usMaxPixelClock);\r\nif (adev->clock.max_pixel_clock == 0)\r\nadev->clock.max_pixel_clock = 40000;\r\nadev->mode_info.firmware_flags =\r\nle16_to_cpu(firmware_info->info.usFirmwareCapability.susAccess);\r\nret = 0;\r\n}\r\nadev->pm.current_sclk = adev->clock.default_sclk;\r\nadev->pm.current_mclk = adev->clock.default_mclk;\r\nreturn ret;\r\n}\r\nstatic void amdgpu_atombios_get_igp_ss_overrides(struct amdgpu_device *adev,\r\nstruct amdgpu_atom_ss *ss,\r\nint id)\r\n{\r\nstruct amdgpu_mode_info *mode_info = &adev->mode_info;\r\nint index = GetIndexIntoMasterTable(DATA, IntegratedSystemInfo);\r\nu16 data_offset, size;\r\nunion igp_info *igp_info;\r\nu8 frev, crev;\r\nu16 percentage = 0, rate = 0;\r\nif (amdgpu_atom_parse_data_header(mode_info->atom_context, index, &size,\r\n&frev, &crev, &data_offset)) {\r\nigp_info = (union igp_info *)\r\n(mode_info->atom_context->bios + data_offset);\r\nswitch (crev) {\r\ncase 6:\r\nswitch (id) {\r\ncase ASIC_INTERNAL_SS_ON_TMDS:\r\npercentage = le16_to_cpu(igp_info->info_6.usDVISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_6.usDVISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_HDMI:\r\npercentage = le16_to_cpu(igp_info->info_6.usHDMISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_6.usHDMISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_LVDS:\r\npercentage = le16_to_cpu(igp_info->info_6.usLvdsSSPercentage);\r\nrate = le16_to_cpu(igp_info->info_6.usLvdsSSpreadRateIn10Hz);\r\nbreak;\r\n}\r\nbreak;\r\ncase 7:\r\nswitch (id) {\r\ncase ASIC_INTERNAL_SS_ON_TMDS:\r\npercentage = le16_to_cpu(igp_info->info_7.usDVISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_7.usDVISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_HDMI:\r\npercentage = le16_to_cpu(igp_info->info_7.usHDMISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_7.usHDMISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_LVDS:\r\npercentage = le16_to_cpu(igp_info->info_7.usLvdsSSPercentage);\r\nrate = le16_to_cpu(igp_info->info_7.usLvdsSSpreadRateIn10Hz);\r\nbreak;\r\n}\r\nbreak;\r\ncase 8:\r\nswitch (id) {\r\ncase ASIC_INTERNAL_SS_ON_TMDS:\r\npercentage = le16_to_cpu(igp_info->info_8.usDVISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_8.usDVISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_HDMI:\r\npercentage = le16_to_cpu(igp_info->info_8.usHDMISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_8.usHDMISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_LVDS:\r\npercentage = le16_to_cpu(igp_info->info_8.usLvdsSSPercentage);\r\nrate = le16_to_cpu(igp_info->info_8.usLvdsSSpreadRateIn10Hz);\r\nbreak;\r\n}\r\nbreak;\r\ncase 9:\r\nswitch (id) {\r\ncase ASIC_INTERNAL_SS_ON_TMDS:\r\npercentage = le16_to_cpu(igp_info->info_9.usDVISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_9.usDVISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_HDMI:\r\npercentage = le16_to_cpu(igp_info->info_9.usHDMISSPercentage);\r\nrate = le16_to_cpu(igp_info->info_9.usHDMISSpreadRateIn10Hz);\r\nbreak;\r\ncase ASIC_INTERNAL_SS_ON_LVDS:\r\npercentage = le16_to_cpu(igp_info->info_9.usLvdsSSPercentage);\r\nrate = le16_to_cpu(igp_info->info_9.usLvdsSSpreadRateIn10Hz);\r\nbreak;\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unsupported IGP table: %d %d\n", frev, crev);\r\nbreak;\r\n}\r\nif (percentage)\r\nss->percentage = percentage;\r\nif (rate)\r\nss->rate = rate;\r\n}\r\n}\r\nbool amdgpu_atombios_get_asic_ss_info(struct amdgpu_device *adev,\r\nstruct amdgpu_atom_ss *ss,\r\nint id, u32 clock)\r\n{\r\nstruct amdgpu_mode_info *mode_info = &adev->mode_info;\r\nint index = GetIndexIntoMasterTable(DATA, ASIC_InternalSS_Info);\r\nuint16_t data_offset, size;\r\nunion asic_ss_info *ss_info;\r\nunion asic_ss_assignment *ss_assign;\r\nuint8_t frev, crev;\r\nint i, num_indices;\r\nif (id == ASIC_INTERNAL_MEMORY_SS) {\r\nif (!(adev->mode_info.firmware_flags & ATOM_BIOS_INFO_MEMORY_CLOCK_SS_SUPPORT))\r\nreturn false;\r\n}\r\nif (id == ASIC_INTERNAL_ENGINE_SS) {\r\nif (!(adev->mode_info.firmware_flags & ATOM_BIOS_INFO_ENGINE_CLOCK_SS_SUPPORT))\r\nreturn false;\r\n}\r\nmemset(ss, 0, sizeof(struct amdgpu_atom_ss));\r\nif (amdgpu_atom_parse_data_header(mode_info->atom_context, index, &size,\r\n&frev, &crev, &data_offset)) {\r\nss_info =\r\n(union asic_ss_info *)(mode_info->atom_context->bios + data_offset);\r\nswitch (frev) {\r\ncase 1:\r\nnum_indices = (size - sizeof(ATOM_COMMON_TABLE_HEADER)) /\r\nsizeof(ATOM_ASIC_SS_ASSIGNMENT);\r\nss_assign = (union asic_ss_assignment *)((u8 *)&ss_info->info.asSpreadSpectrum[0]);\r\nfor (i = 0; i < num_indices; i++) {\r\nif ((ss_assign->v1.ucClockIndication == id) &&\r\n(clock <= le32_to_cpu(ss_assign->v1.ulTargetClockRange))) {\r\nss->percentage =\r\nle16_to_cpu(ss_assign->v1.usSpreadSpectrumPercentage);\r\nss->type = ss_assign->v1.ucSpreadSpectrumMode;\r\nss->rate = le16_to_cpu(ss_assign->v1.usSpreadRateInKhz);\r\nss->percentage_divider = 100;\r\nreturn true;\r\n}\r\nss_assign = (union asic_ss_assignment *)\r\n((u8 *)ss_assign + sizeof(ATOM_ASIC_SS_ASSIGNMENT));\r\n}\r\nbreak;\r\ncase 2:\r\nnum_indices = (size - sizeof(ATOM_COMMON_TABLE_HEADER)) /\r\nsizeof(ATOM_ASIC_SS_ASSIGNMENT_V2);\r\nss_assign = (union asic_ss_assignment *)((u8 *)&ss_info->info_2.asSpreadSpectrum[0]);\r\nfor (i = 0; i < num_indices; i++) {\r\nif ((ss_assign->v2.ucClockIndication == id) &&\r\n(clock <= le32_to_cpu(ss_assign->v2.ulTargetClockRange))) {\r\nss->percentage =\r\nle16_to_cpu(ss_assign->v2.usSpreadSpectrumPercentage);\r\nss->type = ss_assign->v2.ucSpreadSpectrumMode;\r\nss->rate = le16_to_cpu(ss_assign->v2.usSpreadRateIn10Hz);\r\nss->percentage_divider = 100;\r\nif ((crev == 2) &&\r\n((id == ASIC_INTERNAL_ENGINE_SS) ||\r\n(id == ASIC_INTERNAL_MEMORY_SS)))\r\nss->rate /= 100;\r\nreturn true;\r\n}\r\nss_assign = (union asic_ss_assignment *)\r\n((u8 *)ss_assign + sizeof(ATOM_ASIC_SS_ASSIGNMENT_V2));\r\n}\r\nbreak;\r\ncase 3:\r\nnum_indices = (size - sizeof(ATOM_COMMON_TABLE_HEADER)) /\r\nsizeof(ATOM_ASIC_SS_ASSIGNMENT_V3);\r\nss_assign = (union asic_ss_assignment *)((u8 *)&ss_info->info_3.asSpreadSpectrum[0]);\r\nfor (i = 0; i < num_indices; i++) {\r\nif ((ss_assign->v3.ucClockIndication == id) &&\r\n(clock <= le32_to_cpu(ss_assign->v3.ulTargetClockRange))) {\r\nss->percentage =\r\nle16_to_cpu(ss_assign->v3.usSpreadSpectrumPercentage);\r\nss->type = ss_assign->v3.ucSpreadSpectrumMode;\r\nss->rate = le16_to_cpu(ss_assign->v3.usSpreadRateIn10Hz);\r\nif (ss_assign->v3.ucSpreadSpectrumMode &\r\nSS_MODE_V3_PERCENTAGE_DIV_BY_1000_MASK)\r\nss->percentage_divider = 1000;\r\nelse\r\nss->percentage_divider = 100;\r\nif ((id == ASIC_INTERNAL_ENGINE_SS) ||\r\n(id == ASIC_INTERNAL_MEMORY_SS))\r\nss->rate /= 100;\r\nif (adev->flags & AMD_IS_APU)\r\namdgpu_atombios_get_igp_ss_overrides(adev, ss, id);\r\nreturn true;\r\n}\r\nss_assign = (union asic_ss_assignment *)\r\n((u8 *)ss_assign + sizeof(ATOM_ASIC_SS_ASSIGNMENT_V3));\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unsupported ASIC_InternalSS_Info table: %d %d\n", frev, crev);\r\nbreak;\r\n}\r\n}\r\nreturn false;\r\n}\r\nint amdgpu_atombios_get_clock_dividers(struct amdgpu_device *adev,\r\nu8 clock_type,\r\nu32 clock,\r\nbool strobe_mode,\r\nstruct atom_clock_dividers *dividers)\r\n{\r\nunion get_clock_dividers args;\r\nint index = GetIndexIntoMasterTable(COMMAND, ComputeMemoryEnginePLL);\r\nu8 frev, crev;\r\nmemset(&args, 0, sizeof(args));\r\nmemset(dividers, 0, sizeof(struct atom_clock_dividers));\r\nif (!amdgpu_atom_parse_cmd_header(adev->mode_info.atom_context, index, &frev, &crev))\r\nreturn -EINVAL;\r\nswitch (crev) {\r\ncase 4:\r\nargs.v4.ulClock = cpu_to_le32(clock);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\ndividers->post_divider = dividers->post_div = args.v4.ucPostDiv;\r\ndividers->real_clock = le32_to_cpu(args.v4.ulClock);\r\nbreak;\r\ncase 6:\r\nargs.v6_in.ulClock.ulComputeClockFlag = clock_type;\r\nargs.v6_in.ulClock.ulClockFreq = cpu_to_le32(clock);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\ndividers->whole_fb_div = le16_to_cpu(args.v6_out.ulFbDiv.usFbDiv);\r\ndividers->frac_fb_div = le16_to_cpu(args.v6_out.ulFbDiv.usFbDivFrac);\r\ndividers->ref_div = args.v6_out.ucPllRefDiv;\r\ndividers->post_div = args.v6_out.ucPllPostDiv;\r\ndividers->flags = args.v6_out.ucPllCntlFlag;\r\ndividers->real_clock = le32_to_cpu(args.v6_out.ulClock.ulClock);\r\ndividers->post_divider = args.v6_out.ulClock.ucPostDiv;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint amdgpu_atombios_get_memory_pll_dividers(struct amdgpu_device *adev,\r\nu32 clock,\r\nbool strobe_mode,\r\nstruct atom_mpll_param *mpll_param)\r\n{\r\nCOMPUTE_MEMORY_CLOCK_PARAM_PARAMETERS_V2_1 args;\r\nint index = GetIndexIntoMasterTable(COMMAND, ComputeMemoryClockParam);\r\nu8 frev, crev;\r\nmemset(&args, 0, sizeof(args));\r\nmemset(mpll_param, 0, sizeof(struct atom_mpll_param));\r\nif (!amdgpu_atom_parse_cmd_header(adev->mode_info.atom_context, index, &frev, &crev))\r\nreturn -EINVAL;\r\nswitch (frev) {\r\ncase 2:\r\nswitch (crev) {\r\ncase 1:\r\nargs.ulClock = cpu_to_le32(clock);\r\nargs.ucInputFlag = 0;\r\nif (strobe_mode)\r\nargs.ucInputFlag |= MPLL_INPUT_FLAG_STROBE_MODE_EN;\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\nmpll_param->clkfrac = le16_to_cpu(args.ulFbDiv.usFbDivFrac);\r\nmpll_param->clkf = le16_to_cpu(args.ulFbDiv.usFbDiv);\r\nmpll_param->post_div = args.ucPostDiv;\r\nmpll_param->dll_speed = args.ucDllSpeed;\r\nmpll_param->bwcntl = args.ucBWCntl;\r\nmpll_param->vco_mode =\r\n(args.ucPllCntlFlag & MPLL_CNTL_FLAG_VCO_MODE_MASK);\r\nmpll_param->yclk_sel =\r\n(args.ucPllCntlFlag & MPLL_CNTL_FLAG_BYPASS_DQ_PLL) ? 1 : 0;\r\nmpll_param->qdr =\r\n(args.ucPllCntlFlag & MPLL_CNTL_FLAG_QDR_ENABLE) ? 1 : 0;\r\nmpll_param->half_rate =\r\n(args.ucPllCntlFlag & MPLL_CNTL_FLAG_AD_HALF_RATE) ? 1 : 0;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nuint32_t amdgpu_atombios_get_engine_clock(struct amdgpu_device *adev)\r\n{\r\nGET_ENGINE_CLOCK_PS_ALLOCATION args;\r\nint index = GetIndexIntoMasterTable(COMMAND, GetEngineClock);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\nreturn le32_to_cpu(args.ulReturnEngineClock);\r\n}\r\nuint32_t amdgpu_atombios_get_memory_clock(struct amdgpu_device *adev)\r\n{\r\nGET_MEMORY_CLOCK_PS_ALLOCATION args;\r\nint index = GetIndexIntoMasterTable(COMMAND, GetMemoryClock);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\nreturn le32_to_cpu(args.ulReturnMemoryClock);\r\n}\r\nvoid amdgpu_atombios_set_engine_clock(struct amdgpu_device *adev,\r\nuint32_t eng_clock)\r\n{\r\nSET_ENGINE_CLOCK_PS_ALLOCATION args;\r\nint index = GetIndexIntoMasterTable(COMMAND, SetEngineClock);\r\nargs.ulTargetEngineClock = cpu_to_le32(eng_clock);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\n}\r\nvoid amdgpu_atombios_set_memory_clock(struct amdgpu_device *adev,\r\nuint32_t mem_clock)\r\n{\r\nSET_MEMORY_CLOCK_PS_ALLOCATION args;\r\nint index = GetIndexIntoMasterTable(COMMAND, SetMemoryClock);\r\nif (adev->flags & AMD_IS_APU)\r\nreturn;\r\nargs.ulTargetMemoryClock = cpu_to_le32(mem_clock);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\n}\r\nvoid amdgpu_atombios_set_engine_dram_timings(struct amdgpu_device *adev,\r\nu32 eng_clock, u32 mem_clock)\r\n{\r\nSET_ENGINE_CLOCK_PS_ALLOCATION args;\r\nint index = GetIndexIntoMasterTable(COMMAND, DynamicMemorySettings);\r\nu32 tmp;\r\nmemset(&args, 0, sizeof(args));\r\ntmp = eng_clock & SET_CLOCK_FREQ_MASK;\r\ntmp |= (COMPUTE_ENGINE_PLL_PARAM << 24);\r\nargs.ulTargetEngineClock = cpu_to_le32(tmp);\r\nif (mem_clock)\r\nargs.sReserved.ulClock = cpu_to_le32(mem_clock & SET_CLOCK_FREQ_MASK);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\n}\r\nvoid amdgpu_atombios_set_voltage(struct amdgpu_device *adev,\r\nu16 voltage_level,\r\nu8 voltage_type)\r\n{\r\nunion set_voltage args;\r\nint index = GetIndexIntoMasterTable(COMMAND, SetVoltage);\r\nu8 frev, crev, volt_index = voltage_level;\r\nif (!amdgpu_atom_parse_cmd_header(adev->mode_info.atom_context, index, &frev, &crev))\r\nreturn;\r\nif (voltage_level == 0xff01)\r\nreturn;\r\nswitch (crev) {\r\ncase 1:\r\nargs.v1.ucVoltageType = voltage_type;\r\nargs.v1.ucVoltageMode = SET_ASIC_VOLTAGE_MODE_ALL_SOURCE;\r\nargs.v1.ucVoltageIndex = volt_index;\r\nbreak;\r\ncase 2:\r\nargs.v2.ucVoltageType = voltage_type;\r\nargs.v2.ucVoltageMode = SET_ASIC_VOLTAGE_MODE_SET_VOLTAGE;\r\nargs.v2.usVoltageLevel = cpu_to_le16(voltage_level);\r\nbreak;\r\ncase 3:\r\nargs.v3.ucVoltageType = voltage_type;\r\nargs.v3.ucVoltageMode = ATOM_SET_VOLTAGE;\r\nargs.v3.usVoltageLevel = cpu_to_le16(voltage_level);\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unknown table version %d, %d\n", frev, crev);\r\nreturn;\r\n}\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\n}\r\nint amdgpu_atombios_get_leakage_id_from_vbios(struct amdgpu_device *adev,\r\nu16 *leakage_id)\r\n{\r\nunion set_voltage args;\r\nint index = GetIndexIntoMasterTable(COMMAND, SetVoltage);\r\nu8 frev, crev;\r\nif (!amdgpu_atom_parse_cmd_header(adev->mode_info.atom_context, index, &frev, &crev))\r\nreturn -EINVAL;\r\nswitch (crev) {\r\ncase 3:\r\ncase 4:\r\nargs.v3.ucVoltageType = 0;\r\nargs.v3.ucVoltageMode = ATOM_GET_LEAKAGE_ID;\r\nargs.v3.usVoltageLevel = 0;\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\n*leakage_id = le16_to_cpu(args.v3.usVoltageLevel);\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unknown table version %d, %d\n", frev, crev);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint amdgpu_atombios_get_leakage_vddc_based_on_leakage_params(struct amdgpu_device *adev,\r\nu16 *vddc, u16 *vddci,\r\nu16 virtual_voltage_id,\r\nu16 vbios_voltage_id)\r\n{\r\nint index = GetIndexIntoMasterTable(DATA, ASIC_ProfilingInfo);\r\nu8 frev, crev;\r\nu16 data_offset, size;\r\nint i, j;\r\nATOM_ASIC_PROFILING_INFO_V2_1 *profile;\r\nu16 *leakage_bin, *vddc_id_buf, *vddc_buf, *vddci_id_buf, *vddci_buf;\r\n*vddc = 0;\r\n*vddci = 0;\r\nif (!amdgpu_atom_parse_data_header(adev->mode_info.atom_context, index, &size,\r\n&frev, &crev, &data_offset))\r\nreturn -EINVAL;\r\nprofile = (ATOM_ASIC_PROFILING_INFO_V2_1 *)\r\n(adev->mode_info.atom_context->bios + data_offset);\r\nswitch (frev) {\r\ncase 1:\r\nreturn -EINVAL;\r\ncase 2:\r\nswitch (crev) {\r\ncase 1:\r\nif (size < sizeof(ATOM_ASIC_PROFILING_INFO_V2_1))\r\nreturn -EINVAL;\r\nleakage_bin = (u16 *)\r\n(adev->mode_info.atom_context->bios + data_offset +\r\nle16_to_cpu(profile->usLeakageBinArrayOffset));\r\nvddc_id_buf = (u16 *)\r\n(adev->mode_info.atom_context->bios + data_offset +\r\nle16_to_cpu(profile->usElbVDDC_IdArrayOffset));\r\nvddc_buf = (u16 *)\r\n(adev->mode_info.atom_context->bios + data_offset +\r\nle16_to_cpu(profile->usElbVDDC_LevelArrayOffset));\r\nvddci_id_buf = (u16 *)\r\n(adev->mode_info.atom_context->bios + data_offset +\r\nle16_to_cpu(profile->usElbVDDCI_IdArrayOffset));\r\nvddci_buf = (u16 *)\r\n(adev->mode_info.atom_context->bios + data_offset +\r\nle16_to_cpu(profile->usElbVDDCI_LevelArrayOffset));\r\nif (profile->ucElbVDDC_Num > 0) {\r\nfor (i = 0; i < profile->ucElbVDDC_Num; i++) {\r\nif (vddc_id_buf[i] == virtual_voltage_id) {\r\nfor (j = 0; j < profile->ucLeakageBinNum; j++) {\r\nif (vbios_voltage_id <= leakage_bin[j]) {\r\n*vddc = vddc_buf[j * profile->ucElbVDDC_Num + i];\r\nbreak;\r\n}\r\n}\r\nbreak;\r\n}\r\n}\r\n}\r\nif (profile->ucElbVDDCI_Num > 0) {\r\nfor (i = 0; i < profile->ucElbVDDCI_Num; i++) {\r\nif (vddci_id_buf[i] == virtual_voltage_id) {\r\nfor (j = 0; j < profile->ucLeakageBinNum; j++) {\r\nif (vbios_voltage_id <= leakage_bin[j]) {\r\n*vddci = vddci_buf[j * profile->ucElbVDDCI_Num + i];\r\nbreak;\r\n}\r\n}\r\nbreak;\r\n}\r\n}\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unknown table version %d, %d\n", frev, crev);\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unknown table version %d, %d\n", frev, crev);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint amdgpu_atombios_get_voltage_evv(struct amdgpu_device *adev,\r\nu16 virtual_voltage_id,\r\nu16 *voltage)\r\n{\r\nint index = GetIndexIntoMasterTable(COMMAND, GetVoltageInfo);\r\nu32 entry_id;\r\nu32 count = adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count;\r\nunion get_voltage_info args;\r\nfor (entry_id = 0; entry_id < count; entry_id++) {\r\nif (adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[entry_id].v ==\r\nvirtual_voltage_id)\r\nbreak;\r\n}\r\nif (entry_id >= count)\r\nreturn -EINVAL;\r\nargs.in.ucVoltageType = VOLTAGE_TYPE_VDDC;\r\nargs.in.ucVoltageMode = ATOM_GET_VOLTAGE_EVV_VOLTAGE;\r\nargs.in.usVoltageLevel = cpu_to_le16(virtual_voltage_id);\r\nargs.in.ulSCLKFreq =\r\ncpu_to_le32(adev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[entry_id].clk);\r\namdgpu_atom_execute_table(adev->mode_info.atom_context, index, (uint32_t *)&args);\r\n*voltage = le16_to_cpu(args.evv_out.usVoltageLevel);\r\nreturn 0;\r\n}\r\nstatic ATOM_VOLTAGE_OBJECT_V3 *amdgpu_atombios_lookup_voltage_object_v3(ATOM_VOLTAGE_OBJECT_INFO_V3_1 *v3,\r\nu8 voltage_type, u8 voltage_mode)\r\n{\r\nu32 size = le16_to_cpu(v3->sHeader.usStructureSize);\r\nu32 offset = offsetof(ATOM_VOLTAGE_OBJECT_INFO_V3_1, asVoltageObj[0]);\r\nu8 *start = (u8*)v3;\r\nwhile (offset < size) {\r\nATOM_VOLTAGE_OBJECT_V3 *vo = (ATOM_VOLTAGE_OBJECT_V3 *)(start + offset);\r\nif ((vo->asGpioVoltageObj.sHeader.ucVoltageType == voltage_type) &&\r\n(vo->asGpioVoltageObj.sHeader.ucVoltageMode == voltage_mode))\r\nreturn vo;\r\noffset += le16_to_cpu(vo->asGpioVoltageObj.sHeader.usSize);\r\n}\r\nreturn NULL;\r\n}\r\nbool\r\namdgpu_atombios_is_voltage_gpio(struct amdgpu_device *adev,\r\nu8 voltage_type, u8 voltage_mode)\r\n{\r\nint index = GetIndexIntoMasterTable(DATA, VoltageObjectInfo);\r\nu8 frev, crev;\r\nu16 data_offset, size;\r\nunion voltage_object_info *voltage_info;\r\nif (amdgpu_atom_parse_data_header(adev->mode_info.atom_context, index, &size,\r\n&frev, &crev, &data_offset)) {\r\nvoltage_info = (union voltage_object_info *)\r\n(adev->mode_info.atom_context->bios + data_offset);\r\nswitch (frev) {\r\ncase 3:\r\nswitch (crev) {\r\ncase 1:\r\nif (amdgpu_atombios_lookup_voltage_object_v3(&voltage_info->v3,\r\nvoltage_type, voltage_mode))\r\nreturn true;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("unknown voltage object table\n");\r\nreturn false;\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("unknown voltage object table\n");\r\nreturn false;\r\n}\r\n}\r\nreturn false;\r\n}\r\nint amdgpu_atombios_get_voltage_table(struct amdgpu_device *adev,\r\nu8 voltage_type, u8 voltage_mode,\r\nstruct atom_voltage_table *voltage_table)\r\n{\r\nint index = GetIndexIntoMasterTable(DATA, VoltageObjectInfo);\r\nu8 frev, crev;\r\nu16 data_offset, size;\r\nint i;\r\nunion voltage_object_info *voltage_info;\r\nunion voltage_object *voltage_object = NULL;\r\nif (amdgpu_atom_parse_data_header(adev->mode_info.atom_context, index, &size,\r\n&frev, &crev, &data_offset)) {\r\nvoltage_info = (union voltage_object_info *)\r\n(adev->mode_info.atom_context->bios + data_offset);\r\nswitch (frev) {\r\ncase 3:\r\nswitch (crev) {\r\ncase 1:\r\nvoltage_object = (union voltage_object *)\r\namdgpu_atombios_lookup_voltage_object_v3(&voltage_info->v3,\r\nvoltage_type, voltage_mode);\r\nif (voltage_object) {\r\nATOM_GPIO_VOLTAGE_OBJECT_V3 *gpio =\r\n&voltage_object->v3.asGpioVoltageObj;\r\nVOLTAGE_LUT_ENTRY_V2 *lut;\r\nif (gpio->ucGpioEntryNum > MAX_VOLTAGE_ENTRIES)\r\nreturn -EINVAL;\r\nlut = &gpio->asVolGpioLut[0];\r\nfor (i = 0; i < gpio->ucGpioEntryNum; i++) {\r\nvoltage_table->entries[i].value =\r\nle16_to_cpu(lut->usVoltageValue);\r\nvoltage_table->entries[i].smio_low =\r\nle32_to_cpu(lut->ulVoltageId);\r\nlut = (VOLTAGE_LUT_ENTRY_V2 *)\r\n((u8 *)lut + sizeof(VOLTAGE_LUT_ENTRY_V2));\r\n}\r\nvoltage_table->mask_low = le32_to_cpu(gpio->ulGpioMaskVal);\r\nvoltage_table->count = gpio->ucGpioEntryNum;\r\nvoltage_table->phase_delay = gpio->ucPhaseDelay;\r\nreturn 0;\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("unknown voltage object table\n");\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("unknown voltage object table\n");\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn -EINVAL;\r\n}\r\nint amdgpu_atombios_init_mc_reg_table(struct amdgpu_device *adev,\r\nu8 module_index,\r\nstruct atom_mc_reg_table *reg_table)\r\n{\r\nint index = GetIndexIntoMasterTable(DATA, VRAM_Info);\r\nu8 frev, crev, num_entries, t_mem_id, num_ranges = 0;\r\nu32 i = 0, j;\r\nu16 data_offset, size;\r\nunion vram_info *vram_info;\r\nmemset(reg_table, 0, sizeof(struct atom_mc_reg_table));\r\nif (amdgpu_atom_parse_data_header(adev->mode_info.atom_context, index, &size,\r\n&frev, &crev, &data_offset)) {\r\nvram_info = (union vram_info *)\r\n(adev->mode_info.atom_context->bios + data_offset);\r\nswitch (frev) {\r\ncase 1:\r\nDRM_ERROR("old table version %d, %d\n", frev, crev);\r\nreturn -EINVAL;\r\ncase 2:\r\nswitch (crev) {\r\ncase 1:\r\nif (module_index < vram_info->v2_1.ucNumOfVRAMModule) {\r\nATOM_INIT_REG_BLOCK *reg_block =\r\n(ATOM_INIT_REG_BLOCK *)\r\n((u8 *)vram_info + le16_to_cpu(vram_info->v2_1.usMemClkPatchTblOffset));\r\nATOM_MEMORY_SETTING_DATA_BLOCK *reg_data =\r\n(ATOM_MEMORY_SETTING_DATA_BLOCK *)\r\n((u8 *)reg_block + (2 * sizeof(u16)) +\r\nle16_to_cpu(reg_block->usRegIndexTblSize));\r\nATOM_INIT_REG_INDEX_FORMAT *format = &reg_block->asRegIndexBuf[0];\r\nnum_entries = (u8)((le16_to_cpu(reg_block->usRegIndexTblSize)) /\r\nsizeof(ATOM_INIT_REG_INDEX_FORMAT)) - 1;\r\nif (num_entries > VBIOS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nwhile (i < num_entries) {\r\nif (format->ucPreRegDataLength & ACCESS_PLACEHOLDER)\r\nbreak;\r\nreg_table->mc_reg_address[i].s1 =\r\n(u16)(le16_to_cpu(format->usRegIndex));\r\nreg_table->mc_reg_address[i].pre_reg_data =\r\n(u8)(format->ucPreRegDataLength);\r\ni++;\r\nformat = (ATOM_INIT_REG_INDEX_FORMAT *)\r\n((u8 *)format + sizeof(ATOM_INIT_REG_INDEX_FORMAT));\r\n}\r\nreg_table->last = i;\r\nwhile ((le32_to_cpu(*(u32 *)reg_data) != END_OF_REG_DATA_BLOCK) &&\r\n(num_ranges < VBIOS_MAX_AC_TIMING_ENTRIES)) {\r\nt_mem_id = (u8)((le32_to_cpu(*(u32 *)reg_data) & MEM_ID_MASK)\r\n>> MEM_ID_SHIFT);\r\nif (module_index == t_mem_id) {\r\nreg_table->mc_reg_table_entry[num_ranges].mclk_max =\r\n(u32)((le32_to_cpu(*(u32 *)reg_data) & CLOCK_RANGE_MASK)\r\n>> CLOCK_RANGE_SHIFT);\r\nfor (i = 0, j = 1; i < reg_table->last; i++) {\r\nif ((reg_table->mc_reg_address[i].pre_reg_data & LOW_NIBBLE_MASK) == DATA_FROM_TABLE) {\r\nreg_table->mc_reg_table_entry[num_ranges].mc_data[i] =\r\n(u32)le32_to_cpu(*((u32 *)reg_data + j));\r\nj++;\r\n} else if ((reg_table->mc_reg_address[i].pre_reg_data & LOW_NIBBLE_MASK) == DATA_EQU_PREV) {\r\nreg_table->mc_reg_table_entry[num_ranges].mc_data[i] =\r\nreg_table->mc_reg_table_entry[num_ranges].mc_data[i - 1];\r\n}\r\n}\r\nnum_ranges++;\r\n}\r\nreg_data = (ATOM_MEMORY_SETTING_DATA_BLOCK *)\r\n((u8 *)reg_data + le16_to_cpu(reg_block->usRegDataBlkSize));\r\n}\r\nif (le32_to_cpu(*(u32 *)reg_data) != END_OF_REG_DATA_BLOCK)\r\nreturn -EINVAL;\r\nreg_table->num_entries = num_ranges;\r\n} else\r\nreturn -EINVAL;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unknown table version %d, %d\n", frev, crev);\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unknown table version %d, %d\n", frev, crev);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nvoid amdgpu_atombios_scratch_regs_lock(struct amdgpu_device *adev, bool lock)\r\n{\r\nuint32_t bios_6_scratch;\r\nbios_6_scratch = RREG32(mmBIOS_SCRATCH_6);\r\nif (lock) {\r\nbios_6_scratch |= ATOM_S6_CRITICAL_STATE;\r\nbios_6_scratch &= ~ATOM_S6_ACC_MODE;\r\n} else {\r\nbios_6_scratch &= ~ATOM_S6_CRITICAL_STATE;\r\nbios_6_scratch |= ATOM_S6_ACC_MODE;\r\n}\r\nWREG32(mmBIOS_SCRATCH_6, bios_6_scratch);\r\n}\r\nvoid amdgpu_atombios_scratch_regs_init(struct amdgpu_device *adev)\r\n{\r\nuint32_t bios_2_scratch, bios_6_scratch;\r\nbios_2_scratch = RREG32(mmBIOS_SCRATCH_2);\r\nbios_6_scratch = RREG32(mmBIOS_SCRATCH_6);\r\nbios_2_scratch &= ~ATOM_S2_VRI_BRIGHT_ENABLE;\r\nbios_6_scratch |= ATOM_S6_ACC_BLOCK_DISPLAY_SWITCH;\r\nbios_2_scratch &= ~ATOM_S2_DEVICE_DPMS_STATE;\r\nWREG32(mmBIOS_SCRATCH_2, bios_2_scratch);\r\nWREG32(mmBIOS_SCRATCH_6, bios_6_scratch);\r\n}\r\nvoid amdgpu_atombios_scratch_regs_save(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nfor (i = 0; i < AMDGPU_BIOS_NUM_SCRATCH; i++)\r\nadev->bios_scratch[i] = RREG32(mmBIOS_SCRATCH_0 + i);\r\n}\r\nvoid amdgpu_atombios_scratch_regs_restore(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nfor (i = 0; i < AMDGPU_BIOS_NUM_SCRATCH; i++)\r\nWREG32(mmBIOS_SCRATCH_0 + i, adev->bios_scratch[i]);\r\n}\r\nvoid amdgpu_atombios_copy_swap(u8 *dst, u8 *src, u8 num_bytes, bool to_le)\r\n{\r\n#ifdef __BIG_ENDIAN\r\nu8 src_tmp[20], dst_tmp[20];\r\nu32 *dst32, *src32;\r\nint i;\r\nmemcpy(src_tmp, src, num_bytes);\r\nsrc32 = (u32 *)src_tmp;\r\ndst32 = (u32 *)dst_tmp;\r\nif (to_le) {\r\nfor (i = 0; i < ((num_bytes + 3) / 4); i++)\r\ndst32[i] = cpu_to_le32(src32[i]);\r\nmemcpy(dst, dst_tmp, num_bytes);\r\n} else {\r\nu8 dws = num_bytes & ~3;\r\nfor (i = 0; i < ((num_bytes + 3) / 4); i++)\r\ndst32[i] = le32_to_cpu(src32[i]);\r\nmemcpy(dst, dst_tmp, dws);\r\nif (num_bytes % 4) {\r\nfor (i = 0; i < (num_bytes % 4); i++)\r\ndst[dws+i] = dst_tmp[dws+i];\r\n}\r\n}\r\n#else\r\nmemcpy(dst, src, num_bytes);\r\n#endif\r\n}
