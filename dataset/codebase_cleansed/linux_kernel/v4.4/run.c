void spufs_stop_callback(struct spu *spu, int irq)\r\n{\r\nstruct spu_context *ctx = spu->ctx;\r\nif (ctx) {\r\nswitch(irq) {\r\ncase 0 :\r\nctx->csa.class_0_pending = spu->class_0_pending;\r\nctx->csa.class_0_dar = spu->class_0_dar;\r\nbreak;\r\ncase 1 :\r\nctx->csa.class_1_dsisr = spu->class_1_dsisr;\r\nctx->csa.class_1_dar = spu->class_1_dar;\r\nbreak;\r\ncase 2 :\r\nbreak;\r\n}\r\nsmp_wmb();\r\nwake_up_all(&ctx->stop_wq);\r\n}\r\n}\r\nint spu_stopped(struct spu_context *ctx, u32 *stat)\r\n{\r\nu64 dsisr;\r\nu32 stopped;\r\nstopped = SPU_STATUS_INVALID_INSTR | SPU_STATUS_SINGLE_STEP |\r\nSPU_STATUS_STOPPED_BY_HALT | SPU_STATUS_STOPPED_BY_STOP;\r\ntop:\r\n*stat = ctx->ops->status_read(ctx);\r\nif (*stat & stopped) {\r\nif (*stat & SPU_STATUS_RUNNING)\r\ngoto top;\r\nreturn 1;\r\n}\r\nif (test_bit(SPU_SCHED_NOTIFY_ACTIVE, &ctx->sched_flags))\r\nreturn 1;\r\ndsisr = ctx->csa.class_1_dsisr;\r\nif (dsisr & (MFC_DSISR_PTE_NOT_FOUND | MFC_DSISR_ACCESS_DENIED))\r\nreturn 1;\r\nif (ctx->csa.class_0_pending)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int spu_setup_isolated(struct spu_context *ctx)\r\n{\r\nint ret;\r\nu64 __iomem *mfc_cntl;\r\nu64 sr1;\r\nu32 status;\r\nunsigned long timeout;\r\nconst u32 status_loading = SPU_STATUS_RUNNING\r\n| SPU_STATUS_ISOLATED_STATE | SPU_STATUS_ISOLATED_LOAD_STATUS;\r\nret = -ENODEV;\r\nif (!isolated_loader)\r\ngoto out;\r\nspu_unmap_mappings(ctx);\r\nmfc_cntl = &ctx->spu->priv2->mfc_control_RW;\r\ntimeout = jiffies + HZ;\r\nout_be64(mfc_cntl, MFC_CNTL_PURGE_DMA_REQUEST);\r\nwhile ((in_be64(mfc_cntl) & MFC_CNTL_PURGE_DMA_STATUS_MASK)\r\n!= MFC_CNTL_PURGE_DMA_COMPLETE) {\r\nif (time_after(jiffies, timeout)) {\r\nprintk(KERN_ERR "%s: timeout flushing MFC DMA queue\n",\r\n__func__);\r\nret = -EIO;\r\ngoto out;\r\n}\r\ncond_resched();\r\n}\r\nout_be64(mfc_cntl, 0);\r\nsr1 = spu_mfc_sr1_get(ctx->spu);\r\nsr1 &= ~MFC_STATE1_PROBLEM_STATE_MASK;\r\nspu_mfc_sr1_set(ctx->spu, sr1);\r\nctx->ops->signal1_write(ctx, (unsigned long)isolated_loader >> 32);\r\nctx->ops->signal2_write(ctx,\r\n(unsigned long)isolated_loader & 0xffffffff);\r\nctx->ops->runcntl_write(ctx,\r\nSPU_RUNCNTL_RUNNABLE | SPU_RUNCNTL_ISOLATE);\r\nret = 0;\r\ntimeout = jiffies + HZ;\r\nwhile (((status = ctx->ops->status_read(ctx)) & status_loading) ==\r\nstatus_loading) {\r\nif (time_after(jiffies, timeout)) {\r\nprintk(KERN_ERR "%s: timeout waiting for loader\n",\r\n__func__);\r\nret = -EIO;\r\ngoto out_drop_priv;\r\n}\r\ncond_resched();\r\n}\r\nif (!(status & SPU_STATUS_RUNNING)) {\r\npr_debug("%s: isolated LOAD failed\n", __func__);\r\nctx->ops->runcntl_write(ctx, SPU_RUNCNTL_RUNNABLE);\r\nret = -EACCES;\r\ngoto out_drop_priv;\r\n}\r\nif (!(status & SPU_STATUS_ISOLATED_STATE)) {\r\npr_debug("%s: SPU fell out of isolated mode?\n", __func__);\r\nctx->ops->runcntl_write(ctx, SPU_RUNCNTL_STOP);\r\nret = -EINVAL;\r\ngoto out_drop_priv;\r\n}\r\nout_drop_priv:\r\nsr1 |= MFC_STATE1_PROBLEM_STATE_MASK;\r\nspu_mfc_sr1_set(ctx->spu, sr1);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int spu_run_init(struct spu_context *ctx, u32 *npc)\r\n{\r\nunsigned long runcntl = SPU_RUNCNTL_RUNNABLE;\r\nint ret;\r\nspuctx_switch_state(ctx, SPU_UTIL_SYSTEM);\r\nif (ctx->flags & SPU_CREATE_NOSCHED) {\r\nif (ctx->state == SPU_STATE_SAVED) {\r\nret = spu_activate(ctx, 0);\r\nif (ret)\r\nreturn ret;\r\n}\r\n}\r\nif (ctx->flags & SPU_CREATE_ISOLATE) {\r\nif (!(ctx->ops->status_read(ctx) & SPU_STATUS_ISOLATED_STATE)) {\r\nret = spu_setup_isolated(ctx);\r\nif (ret)\r\nreturn ret;\r\n}\r\nruncntl = ctx->ops->runcntl_read(ctx) &\r\n(SPU_RUNCNTL_RUNNABLE | SPU_RUNCNTL_ISOLATE);\r\nif (runcntl == 0)\r\nruncntl = SPU_RUNCNTL_RUNNABLE;\r\n} else {\r\nunsigned long privcntl;\r\nif (test_thread_flag(TIF_SINGLESTEP))\r\nprivcntl = SPU_PRIVCNTL_MODE_SINGLE_STEP;\r\nelse\r\nprivcntl = SPU_PRIVCNTL_MODE_NORMAL;\r\nctx->ops->privcntl_write(ctx, privcntl);\r\nctx->ops->npc_write(ctx, *npc);\r\n}\r\nctx->ops->runcntl_write(ctx, runcntl);\r\nif (ctx->flags & SPU_CREATE_NOSCHED) {\r\nspuctx_switch_state(ctx, SPU_UTIL_USER);\r\n} else {\r\nif (ctx->state == SPU_STATE_SAVED) {\r\nret = spu_activate(ctx, 0);\r\nif (ret)\r\nreturn ret;\r\n} else {\r\nspuctx_switch_state(ctx, SPU_UTIL_USER);\r\n}\r\n}\r\nset_bit(SPU_SCHED_SPU_RUN, &ctx->sched_flags);\r\nreturn 0;\r\n}\r\nstatic int spu_run_fini(struct spu_context *ctx, u32 *npc,\r\nu32 *status)\r\n{\r\nint ret = 0;\r\nspu_del_from_rq(ctx);\r\n*status = ctx->ops->status_read(ctx);\r\n*npc = ctx->ops->npc_read(ctx);\r\nspuctx_switch_state(ctx, SPU_UTIL_IDLE_LOADED);\r\nclear_bit(SPU_SCHED_SPU_RUN, &ctx->sched_flags);\r\nspu_switch_log_notify(NULL, ctx, SWITCH_LOG_EXIT, *status);\r\nspu_release(ctx);\r\nif (signal_pending(current))\r\nret = -ERESTARTSYS;\r\nreturn ret;\r\n}\r\nstatic int spu_handle_restartsys(struct spu_context *ctx, long *spu_ret,\r\nunsigned int *npc)\r\n{\r\nint ret;\r\nswitch (*spu_ret) {\r\ncase -ERESTARTSYS:\r\ncase -ERESTARTNOINTR:\r\n*npc -= 8;\r\nret = -ERESTARTSYS;\r\nbreak;\r\ncase -ERESTARTNOHAND:\r\ncase -ERESTART_RESTARTBLOCK:\r\n*spu_ret = -EINTR;\r\nret = -ERESTARTSYS;\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING "%s: unexpected return code %ld\n",\r\n__func__, *spu_ret);\r\nret = 0;\r\n}\r\nreturn ret;\r\n}\r\nstatic int spu_process_callback(struct spu_context *ctx)\r\n{\r\nstruct spu_syscall_block s;\r\nu32 ls_pointer, npc;\r\nvoid __iomem *ls;\r\nlong spu_ret;\r\nint ret;\r\nnpc = ctx->ops->npc_read(ctx) & ~3;\r\nls = (void __iomem *)ctx->ops->get_ls(ctx);\r\nls_pointer = in_be32(ls + npc);\r\nif (ls_pointer > (LS_SIZE - sizeof(s)))\r\nreturn -EFAULT;\r\nmemcpy_fromio(&s, ls + ls_pointer, sizeof(s));\r\nret = 0;\r\nspu_ret = -ENOSYS;\r\nnpc += 4;\r\nif (s.nr_ret < __NR_syscalls) {\r\nspu_release(ctx);\r\nspu_ret = spu_sys_callback(&s);\r\nif (spu_ret <= -ERESTARTSYS) {\r\nret = spu_handle_restartsys(ctx, &spu_ret, &npc);\r\n}\r\nmutex_lock(&ctx->state_mutex);\r\nif (ret == -ERESTARTSYS)\r\nreturn ret;\r\n}\r\nls = (void __iomem *)ctx->ops->get_ls(ctx);\r\nmemcpy_toio(ls + ls_pointer, &spu_ret, sizeof(spu_ret));\r\nctx->ops->npc_write(ctx, npc);\r\nctx->ops->runcntl_write(ctx, SPU_RUNCNTL_RUNNABLE);\r\nreturn ret;\r\n}\r\nlong spufs_run_spu(struct spu_context *ctx, u32 *npc, u32 *event)\r\n{\r\nint ret;\r\nstruct spu *spu;\r\nu32 status;\r\nif (mutex_lock_interruptible(&ctx->run_mutex))\r\nreturn -ERESTARTSYS;\r\nctx->event_return = 0;\r\nret = spu_acquire(ctx);\r\nif (ret)\r\ngoto out_unlock;\r\nspu_enable_spu(ctx);\r\nspu_update_sched_info(ctx);\r\nret = spu_run_init(ctx, npc);\r\nif (ret) {\r\nspu_release(ctx);\r\ngoto out;\r\n}\r\ndo {\r\nret = spufs_wait(ctx->stop_wq, spu_stopped(ctx, &status));\r\nif (unlikely(ret)) {\r\nmutex_lock(&ctx->state_mutex);\r\nbreak;\r\n}\r\nspu = ctx->spu;\r\nif (unlikely(test_and_clear_bit(SPU_SCHED_NOTIFY_ACTIVE,\r\n&ctx->sched_flags))) {\r\nif (!(status & SPU_STATUS_STOPPED_BY_STOP)) {\r\nspu_switch_notify(spu, ctx);\r\ncontinue;\r\n}\r\n}\r\nspuctx_switch_state(ctx, SPU_UTIL_SYSTEM);\r\nif ((status & SPU_STATUS_STOPPED_BY_STOP) &&\r\n(status >> SPU_STOP_STATUS_SHIFT == 0x2104)) {\r\nret = spu_process_callback(ctx);\r\nif (ret)\r\nbreak;\r\nstatus &= ~SPU_STATUS_STOPPED_BY_STOP;\r\n}\r\nret = spufs_handle_class1(ctx);\r\nif (ret)\r\nbreak;\r\nret = spufs_handle_class0(ctx);\r\nif (ret)\r\nbreak;\r\nif (signal_pending(current))\r\nret = -ERESTARTSYS;\r\n} while (!ret && !(status & (SPU_STATUS_STOPPED_BY_STOP |\r\nSPU_STATUS_STOPPED_BY_HALT |\r\nSPU_STATUS_SINGLE_STEP)));\r\nspu_disable_spu(ctx);\r\nret = spu_run_fini(ctx, npc, &status);\r\nspu_yield(ctx);\r\nif ((status & SPU_STATUS_STOPPED_BY_STOP) &&\r\n(((status >> SPU_STOP_STATUS_SHIFT) & 0x3f00) == 0x2100))\r\nctx->stats.libassist++;\r\nif ((ret == 0) ||\r\n((ret == -ERESTARTSYS) &&\r\n((status & SPU_STATUS_STOPPED_BY_HALT) ||\r\n(status & SPU_STATUS_SINGLE_STEP) ||\r\n((status & SPU_STATUS_STOPPED_BY_STOP) &&\r\n(status >> SPU_STOP_STATUS_SHIFT != 0x2104)))))\r\nret = status;\r\nif (unlikely(status & SPU_STATUS_SINGLE_STEP))\r\nret = -ERESTARTSYS;\r\nelse if (unlikely((status & SPU_STATUS_STOPPED_BY_STOP)\r\n&& (status >> SPU_STOP_STATUS_SHIFT) == 0x3fff)) {\r\nforce_sig(SIGTRAP, current);\r\nret = -ERESTARTSYS;\r\n}\r\nout:\r\n*event = ctx->event_return;\r\nout_unlock:\r\nmutex_unlock(&ctx->run_mutex);\r\nreturn ret;\r\n}
