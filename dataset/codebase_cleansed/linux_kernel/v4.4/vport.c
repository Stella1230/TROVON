u8 mlx5_query_vport_state(struct mlx5_core_dev *mdev, u8 opmod)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_vport_state_in)];\r\nu32 out[MLX5_ST_SZ_DW(query_vport_state_out)];\r\nint err;\r\nmemset(in, 0, sizeof(in));\r\nMLX5_SET(query_vport_state_in, in, opcode,\r\nMLX5_CMD_OP_QUERY_VPORT_STATE);\r\nMLX5_SET(query_vport_state_in, in, op_mod, opmod);\r\nerr = mlx5_cmd_exec_check_status(mdev, in, sizeof(in), out,\r\nsizeof(out));\r\nif (err)\r\nmlx5_core_warn(mdev, "MLX5_CMD_OP_QUERY_VPORT_STATE failed\n");\r\nreturn MLX5_GET(query_vport_state_out, out, state);\r\n}\r\nvoid mlx5_query_nic_vport_mac_address(struct mlx5_core_dev *mdev, u8 *addr)\r\n{\r\nu32 in[MLX5_ST_SZ_DW(query_nic_vport_context_in)];\r\nu32 *out;\r\nint outlen = MLX5_ST_SZ_BYTES(query_nic_vport_context_out);\r\nu8 *out_addr;\r\nout = mlx5_vzalloc(outlen);\r\nif (!out)\r\nreturn;\r\nout_addr = MLX5_ADDR_OF(query_nic_vport_context_out, out,\r\nnic_vport_context.permanent_address);\r\nmemset(in, 0, sizeof(in));\r\nMLX5_SET(query_nic_vport_context_in, in, opcode,\r\nMLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT);\r\nmemset(out, 0, outlen);\r\nmlx5_cmd_exec_check_status(mdev, in, sizeof(in), out, outlen);\r\nether_addr_copy(addr, &out_addr[2]);\r\nkvfree(out);\r\n}\r\nint mlx5_query_hca_vport_gid(struct mlx5_core_dev *dev, u8 other_vport,\r\nu8 port_num, u16 vf_num, u16 gid_index,\r\nunion ib_gid *gid)\r\n{\r\nint in_sz = MLX5_ST_SZ_BYTES(query_hca_vport_gid_in);\r\nint out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_gid_out);\r\nint is_group_manager;\r\nvoid *out = NULL;\r\nvoid *in = NULL;\r\nunion ib_gid *tmp;\r\nint tbsz;\r\nint nout;\r\nint err;\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\ntbsz = mlx5_get_gid_table_len(MLX5_CAP_GEN(dev, gid_table_size));\r\nmlx5_core_dbg(dev, "vf_num %d, index %d, gid_table_size %d\n",\r\nvf_num, gid_index, tbsz);\r\nif (gid_index > tbsz && gid_index != 0xffff)\r\nreturn -EINVAL;\r\nif (gid_index == 0xffff)\r\nnout = tbsz;\r\nelse\r\nnout = 1;\r\nout_sz += nout * sizeof(*gid);\r\nin = kzalloc(in_sz, GFP_KERNEL);\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!in || !out) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nMLX5_SET(query_hca_vport_gid_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_GID);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(query_hca_vport_gid_in, in, vport_number, vf_num);\r\nMLX5_SET(query_hca_vport_gid_in, in, other_vport, 1);\r\n} else {\r\nerr = -EPERM;\r\ngoto out;\r\n}\r\n}\r\nMLX5_SET(query_hca_vport_gid_in, in, gid_index, gid_index);\r\nif (MLX5_CAP_GEN(dev, num_ports) == 2)\r\nMLX5_SET(query_hca_vport_gid_in, in, port_num, port_num);\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, out_sz);\r\nif (err)\r\ngoto out;\r\nerr = mlx5_cmd_status_to_err_v2(out);\r\nif (err)\r\ngoto out;\r\ntmp = out + MLX5_ST_SZ_BYTES(query_hca_vport_gid_out);\r\ngid->global.subnet_prefix = tmp->global.subnet_prefix;\r\ngid->global.interface_id = tmp->global.interface_id;\r\nout:\r\nkfree(in);\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_pkey(struct mlx5_core_dev *dev, u8 other_vport,\r\nu8 port_num, u16 vf_num, u16 pkey_index,\r\nu16 *pkey)\r\n{\r\nint in_sz = MLX5_ST_SZ_BYTES(query_hca_vport_pkey_in);\r\nint out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_pkey_out);\r\nint is_group_manager;\r\nvoid *out = NULL;\r\nvoid *in = NULL;\r\nvoid *pkarr;\r\nint nout;\r\nint tbsz;\r\nint err;\r\nint i;\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\ntbsz = mlx5_to_sw_pkey_sz(MLX5_CAP_GEN(dev, pkey_table_size));\r\nif (pkey_index > tbsz && pkey_index != 0xffff)\r\nreturn -EINVAL;\r\nif (pkey_index == 0xffff)\r\nnout = tbsz;\r\nelse\r\nnout = 1;\r\nout_sz += nout * MLX5_ST_SZ_BYTES(pkey);\r\nin = kzalloc(in_sz, GFP_KERNEL);\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!in || !out) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nMLX5_SET(query_hca_vport_pkey_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_PKEY);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(query_hca_vport_pkey_in, in, vport_number, vf_num);\r\nMLX5_SET(query_hca_vport_pkey_in, in, other_vport, 1);\r\n} else {\r\nerr = -EPERM;\r\ngoto out;\r\n}\r\n}\r\nMLX5_SET(query_hca_vport_pkey_in, in, pkey_index, pkey_index);\r\nif (MLX5_CAP_GEN(dev, num_ports) == 2)\r\nMLX5_SET(query_hca_vport_pkey_in, in, port_num, port_num);\r\nerr = mlx5_cmd_exec(dev, in, in_sz, out, out_sz);\r\nif (err)\r\ngoto out;\r\nerr = mlx5_cmd_status_to_err_v2(out);\r\nif (err)\r\ngoto out;\r\npkarr = MLX5_ADDR_OF(query_hca_vport_pkey_out, out, pkey);\r\nfor (i = 0; i < nout; i++, pkey++, pkarr += MLX5_ST_SZ_BYTES(pkey))\r\n*pkey = MLX5_GET_PR(pkey, pkarr, pkey);\r\nout:\r\nkfree(in);\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_context(struct mlx5_core_dev *dev,\r\nu8 other_vport, u8 port_num,\r\nu16 vf_num,\r\nstruct mlx5_hca_vport_context *rep)\r\n{\r\nint out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_context_out);\r\nint in[MLX5_ST_SZ_DW(query_hca_vport_context_in)];\r\nint is_group_manager;\r\nvoid *out;\r\nvoid *ctx;\r\nint err;\r\nis_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);\r\nmemset(in, 0, sizeof(in));\r\nout = kzalloc(out_sz, GFP_KERNEL);\r\nif (!out)\r\nreturn -ENOMEM;\r\nMLX5_SET(query_hca_vport_context_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT);\r\nif (other_vport) {\r\nif (is_group_manager) {\r\nMLX5_SET(query_hca_vport_context_in, in, other_vport, 1);\r\nMLX5_SET(query_hca_vport_context_in, in, vport_number, vf_num);\r\n} else {\r\nerr = -EPERM;\r\ngoto ex;\r\n}\r\n}\r\nif (MLX5_CAP_GEN(dev, num_ports) == 2)\r\nMLX5_SET(query_hca_vport_context_in, in, port_num, port_num);\r\nerr = mlx5_cmd_exec(dev, in, sizeof(in), out, out_sz);\r\nif (err)\r\ngoto ex;\r\nerr = mlx5_cmd_status_to_err_v2(out);\r\nif (err)\r\ngoto ex;\r\nctx = MLX5_ADDR_OF(query_hca_vport_context_out, out, hca_vport_context);\r\nrep->field_select = MLX5_GET_PR(hca_vport_context, ctx, field_select);\r\nrep->sm_virt_aware = MLX5_GET_PR(hca_vport_context, ctx, sm_virt_aware);\r\nrep->has_smi = MLX5_GET_PR(hca_vport_context, ctx, has_smi);\r\nrep->has_raw = MLX5_GET_PR(hca_vport_context, ctx, has_raw);\r\nrep->policy = MLX5_GET_PR(hca_vport_context, ctx, vport_state_policy);\r\nrep->phys_state = MLX5_GET_PR(hca_vport_context, ctx,\r\nport_physical_state);\r\nrep->vport_state = MLX5_GET_PR(hca_vport_context, ctx, vport_state);\r\nrep->port_physical_state = MLX5_GET_PR(hca_vport_context, ctx,\r\nport_physical_state);\r\nrep->port_guid = MLX5_GET64_PR(hca_vport_context, ctx, port_guid);\r\nrep->node_guid = MLX5_GET64_PR(hca_vport_context, ctx, node_guid);\r\nrep->cap_mask1 = MLX5_GET_PR(hca_vport_context, ctx, cap_mask1);\r\nrep->cap_mask1_perm = MLX5_GET_PR(hca_vport_context, ctx,\r\ncap_mask1_field_select);\r\nrep->cap_mask2 = MLX5_GET_PR(hca_vport_context, ctx, cap_mask2);\r\nrep->cap_mask2_perm = MLX5_GET_PR(hca_vport_context, ctx,\r\ncap_mask2_field_select);\r\nrep->lid = MLX5_GET_PR(hca_vport_context, ctx, lid);\r\nrep->init_type_reply = MLX5_GET_PR(hca_vport_context, ctx,\r\ninit_type_reply);\r\nrep->lmc = MLX5_GET_PR(hca_vport_context, ctx, lmc);\r\nrep->subnet_timeout = MLX5_GET_PR(hca_vport_context, ctx,\r\nsubnet_timeout);\r\nrep->sm_lid = MLX5_GET_PR(hca_vport_context, ctx, sm_lid);\r\nrep->sm_sl = MLX5_GET_PR(hca_vport_context, ctx, sm_sl);\r\nrep->qkey_violation_counter = MLX5_GET_PR(hca_vport_context, ctx,\r\nqkey_violation_counter);\r\nrep->pkey_violation_counter = MLX5_GET_PR(hca_vport_context, ctx,\r\npkey_violation_counter);\r\nrep->grh_required = MLX5_GET_PR(hca_vport_context, ctx, grh_required);\r\nrep->sys_image_guid = MLX5_GET64_PR(hca_vport_context, ctx,\r\nsystem_image_guid);\r\nex:\r\nkfree(out);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_system_image_guid(struct mlx5_core_dev *dev,\r\nu64 *sys_image_guid)\r\n{\r\nstruct mlx5_hca_vport_context *rep;\r\nint err;\r\nrep = kzalloc(sizeof(*rep), GFP_KERNEL);\r\nif (!rep)\r\nreturn -ENOMEM;\r\nerr = mlx5_query_hca_vport_context(dev, 0, 1, 0, rep);\r\nif (!err)\r\n*sys_image_guid = rep->sys_image_guid;\r\nkfree(rep);\r\nreturn err;\r\n}\r\nint mlx5_query_hca_vport_node_guid(struct mlx5_core_dev *dev,\r\nu64 *node_guid)\r\n{\r\nstruct mlx5_hca_vport_context *rep;\r\nint err;\r\nrep = kzalloc(sizeof(*rep), GFP_KERNEL);\r\nif (!rep)\r\nreturn -ENOMEM;\r\nerr = mlx5_query_hca_vport_context(dev, 0, 1, 0, rep);\r\nif (!err)\r\n*node_guid = rep->node_guid;\r\nkfree(rep);\r\nreturn err;\r\n}
