void amdgpu_pm_acpi_event_handler(struct amdgpu_device *adev)\r\n{\r\nif (adev->pm.dpm_enabled) {\r\nmutex_lock(&adev->pm.mutex);\r\nif (power_supply_is_system_supplied() > 0)\r\nadev->pm.dpm.ac_power = true;\r\nelse\r\nadev->pm.dpm.ac_power = false;\r\nif (adev->pm.funcs->enable_bapm)\r\namdgpu_dpm_enable_bapm(adev, adev->pm.dpm.ac_power);\r\nmutex_unlock(&adev->pm.mutex);\r\n}\r\n}\r\nstatic ssize_t amdgpu_get_dpm_state(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct drm_device *ddev = dev_get_drvdata(dev);\r\nstruct amdgpu_device *adev = ddev->dev_private;\r\nenum amdgpu_pm_state_type pm = adev->pm.dpm.user_state;\r\nreturn snprintf(buf, PAGE_SIZE, "%s\n",\r\n(pm == POWER_STATE_TYPE_BATTERY) ? "battery" :\r\n(pm == POWER_STATE_TYPE_BALANCED) ? "balanced" : "performance");\r\n}\r\nstatic ssize_t amdgpu_set_dpm_state(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t count)\r\n{\r\nstruct drm_device *ddev = dev_get_drvdata(dev);\r\nstruct amdgpu_device *adev = ddev->dev_private;\r\nmutex_lock(&adev->pm.mutex);\r\nif (strncmp("battery", buf, strlen("battery")) == 0)\r\nadev->pm.dpm.user_state = POWER_STATE_TYPE_BATTERY;\r\nelse if (strncmp("balanced", buf, strlen("balanced")) == 0)\r\nadev->pm.dpm.user_state = POWER_STATE_TYPE_BALANCED;\r\nelse if (strncmp("performance", buf, strlen("performance")) == 0)\r\nadev->pm.dpm.user_state = POWER_STATE_TYPE_PERFORMANCE;\r\nelse {\r\nmutex_unlock(&adev->pm.mutex);\r\ncount = -EINVAL;\r\ngoto fail;\r\n}\r\nmutex_unlock(&adev->pm.mutex);\r\nif (!(adev->flags & AMD_IS_PX) ||\r\n(ddev->switch_power_state == DRM_SWITCH_POWER_ON))\r\namdgpu_pm_compute_clocks(adev);\r\nfail:\r\nreturn count;\r\n}\r\nstatic ssize_t amdgpu_get_dpm_forced_performance_level(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct drm_device *ddev = dev_get_drvdata(dev);\r\nstruct amdgpu_device *adev = ddev->dev_private;\r\nenum amdgpu_dpm_forced_level level = adev->pm.dpm.forced_level;\r\nreturn snprintf(buf, PAGE_SIZE, "%s\n",\r\n(level == AMDGPU_DPM_FORCED_LEVEL_AUTO) ? "auto" :\r\n(level == AMDGPU_DPM_FORCED_LEVEL_LOW) ? "low" : "high");\r\n}\r\nstatic ssize_t amdgpu_set_dpm_forced_performance_level(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t count)\r\n{\r\nstruct drm_device *ddev = dev_get_drvdata(dev);\r\nstruct amdgpu_device *adev = ddev->dev_private;\r\nenum amdgpu_dpm_forced_level level;\r\nint ret = 0;\r\nmutex_lock(&adev->pm.mutex);\r\nif (strncmp("low", buf, strlen("low")) == 0) {\r\nlevel = AMDGPU_DPM_FORCED_LEVEL_LOW;\r\n} else if (strncmp("high", buf, strlen("high")) == 0) {\r\nlevel = AMDGPU_DPM_FORCED_LEVEL_HIGH;\r\n} else if (strncmp("auto", buf, strlen("auto")) == 0) {\r\nlevel = AMDGPU_DPM_FORCED_LEVEL_AUTO;\r\n} else {\r\ncount = -EINVAL;\r\ngoto fail;\r\n}\r\nif (adev->pm.funcs->force_performance_level) {\r\nif (adev->pm.dpm.thermal_active) {\r\ncount = -EINVAL;\r\ngoto fail;\r\n}\r\nret = amdgpu_dpm_force_performance_level(adev, level);\r\nif (ret)\r\ncount = -EINVAL;\r\n}\r\nfail:\r\nmutex_unlock(&adev->pm.mutex);\r\nreturn count;\r\n}\r\nstatic ssize_t amdgpu_hwmon_show_temp(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct amdgpu_device *adev = dev_get_drvdata(dev);\r\nint temp;\r\nif (adev->pm.funcs->get_temperature)\r\ntemp = amdgpu_dpm_get_temperature(adev);\r\nelse\r\ntemp = 0;\r\nreturn snprintf(buf, PAGE_SIZE, "%d\n", temp);\r\n}\r\nstatic ssize_t amdgpu_hwmon_show_temp_thresh(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct amdgpu_device *adev = dev_get_drvdata(dev);\r\nint hyst = to_sensor_dev_attr(attr)->index;\r\nint temp;\r\nif (hyst)\r\ntemp = adev->pm.dpm.thermal.min_temp;\r\nelse\r\ntemp = adev->pm.dpm.thermal.max_temp;\r\nreturn snprintf(buf, PAGE_SIZE, "%d\n", temp);\r\n}\r\nstatic ssize_t amdgpu_hwmon_get_pwm1_enable(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct amdgpu_device *adev = dev_get_drvdata(dev);\r\nu32 pwm_mode = 0;\r\nif (adev->pm.funcs->get_fan_control_mode)\r\npwm_mode = amdgpu_dpm_get_fan_control_mode(adev);\r\nreturn sprintf(buf, "%i\n", pwm_mode == FDO_PWM_MODE_STATIC ? 1 : 2);\r\n}\r\nstatic ssize_t amdgpu_hwmon_set_pwm1_enable(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t count)\r\n{\r\nstruct amdgpu_device *adev = dev_get_drvdata(dev);\r\nint err;\r\nint value;\r\nif(!adev->pm.funcs->set_fan_control_mode)\r\nreturn -EINVAL;\r\nerr = kstrtoint(buf, 10, &value);\r\nif (err)\r\nreturn err;\r\nswitch (value) {\r\ncase 1:\r\namdgpu_dpm_set_fan_control_mode(adev, FDO_PWM_MODE_STATIC);\r\nbreak;\r\ndefault:\r\namdgpu_dpm_set_fan_control_mode(adev, 0);\r\nbreak;\r\n}\r\nreturn count;\r\n}\r\nstatic ssize_t amdgpu_hwmon_get_pwm1_min(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nreturn sprintf(buf, "%i\n", 0);\r\n}\r\nstatic ssize_t amdgpu_hwmon_get_pwm1_max(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nreturn sprintf(buf, "%i\n", 255);\r\n}\r\nstatic ssize_t amdgpu_hwmon_set_pwm1(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct amdgpu_device *adev = dev_get_drvdata(dev);\r\nint err;\r\nu32 value;\r\nerr = kstrtou32(buf, 10, &value);\r\nif (err)\r\nreturn err;\r\nvalue = (value * 100) / 255;\r\nerr = amdgpu_dpm_set_fan_speed_percent(adev, value);\r\nif (err)\r\nreturn err;\r\nreturn count;\r\n}\r\nstatic ssize_t amdgpu_hwmon_get_pwm1(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct amdgpu_device *adev = dev_get_drvdata(dev);\r\nint err;\r\nu32 speed;\r\nerr = amdgpu_dpm_get_fan_speed_percent(adev, &speed);\r\nif (err)\r\nreturn err;\r\nspeed = (speed * 255) / 100;\r\nreturn sprintf(buf, "%i\n", speed);\r\n}\r\nstatic umode_t hwmon_attributes_visible(struct kobject *kobj,\r\nstruct attribute *attr, int index)\r\n{\r\nstruct device *dev = container_of(kobj, struct device, kobj);\r\nstruct amdgpu_device *adev = dev_get_drvdata(dev);\r\numode_t effective_mode = attr->mode;\r\nif (!adev->pm.dpm_enabled &&\r\n(attr == &sensor_dev_attr_temp1_crit.dev_attr.attr ||\r\nattr == &sensor_dev_attr_temp1_crit_hyst.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1_enable.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1_max.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1_min.dev_attr.attr))\r\nreturn 0;\r\nif (adev->pm.no_fan &&\r\n(attr == &sensor_dev_attr_pwm1.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1_enable.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1_max.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1_min.dev_attr.attr))\r\nreturn 0;\r\nif ((!adev->pm.funcs->get_fan_speed_percent &&\r\nattr == &sensor_dev_attr_pwm1.dev_attr.attr) ||\r\n(!adev->pm.funcs->get_fan_control_mode &&\r\nattr == &sensor_dev_attr_pwm1_enable.dev_attr.attr))\r\neffective_mode &= ~S_IRUGO;\r\nif ((!adev->pm.funcs->set_fan_speed_percent &&\r\nattr == &sensor_dev_attr_pwm1.dev_attr.attr) ||\r\n(!adev->pm.funcs->set_fan_control_mode &&\r\nattr == &sensor_dev_attr_pwm1_enable.dev_attr.attr))\r\neffective_mode &= ~S_IWUSR;\r\nif ((!adev->pm.funcs->set_fan_speed_percent &&\r\n!adev->pm.funcs->get_fan_speed_percent) &&\r\n(attr == &sensor_dev_attr_pwm1_max.dev_attr.attr ||\r\nattr == &sensor_dev_attr_pwm1_min.dev_attr.attr))\r\nreturn 0;\r\nreturn effective_mode;\r\n}\r\nvoid amdgpu_dpm_thermal_work_handler(struct work_struct *work)\r\n{\r\nstruct amdgpu_device *adev =\r\ncontainer_of(work, struct amdgpu_device,\r\npm.dpm.thermal.work);\r\nenum amdgpu_pm_state_type dpm_state = POWER_STATE_TYPE_INTERNAL_THERMAL;\r\nif (!adev->pm.dpm_enabled)\r\nreturn;\r\nif (adev->pm.funcs->get_temperature) {\r\nint temp = amdgpu_dpm_get_temperature(adev);\r\nif (temp < adev->pm.dpm.thermal.min_temp)\r\ndpm_state = adev->pm.dpm.user_state;\r\n} else {\r\nif (adev->pm.dpm.thermal.high_to_low)\r\ndpm_state = adev->pm.dpm.user_state;\r\n}\r\nmutex_lock(&adev->pm.mutex);\r\nif (dpm_state == POWER_STATE_TYPE_INTERNAL_THERMAL)\r\nadev->pm.dpm.thermal_active = true;\r\nelse\r\nadev->pm.dpm.thermal_active = false;\r\nadev->pm.dpm.state = dpm_state;\r\nmutex_unlock(&adev->pm.mutex);\r\namdgpu_pm_compute_clocks(adev);\r\n}\r\nstatic struct amdgpu_ps *amdgpu_dpm_pick_power_state(struct amdgpu_device *adev,\r\nenum amdgpu_pm_state_type dpm_state)\r\n{\r\nint i;\r\nstruct amdgpu_ps *ps;\r\nu32 ui_class;\r\nbool single_display = (adev->pm.dpm.new_active_crtc_count < 2) ?\r\ntrue : false;\r\nif (single_display && adev->pm.funcs->vblank_too_short) {\r\nif (amdgpu_dpm_vblank_too_short(adev))\r\nsingle_display = false;\r\n}\r\nif (dpm_state == POWER_STATE_TYPE_PERFORMANCE)\r\ndpm_state = POWER_STATE_TYPE_INTERNAL_3DPERF;\r\nif (dpm_state == POWER_STATE_TYPE_BALANCED)\r\ndpm_state = POWER_STATE_TYPE_PERFORMANCE;\r\nrestart_search:\r\nfor (i = 0; i < adev->pm.dpm.num_ps; i++) {\r\nps = &adev->pm.dpm.ps[i];\r\nui_class = ps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK;\r\nswitch (dpm_state) {\r\ncase POWER_STATE_TYPE_BATTERY:\r\nif (ui_class == ATOM_PPLIB_CLASSIFICATION_UI_BATTERY) {\r\nif (ps->caps & ATOM_PPLIB_SINGLE_DISPLAY_ONLY) {\r\nif (single_display)\r\nreturn ps;\r\n} else\r\nreturn ps;\r\n}\r\nbreak;\r\ncase POWER_STATE_TYPE_BALANCED:\r\nif (ui_class == ATOM_PPLIB_CLASSIFICATION_UI_BALANCED) {\r\nif (ps->caps & ATOM_PPLIB_SINGLE_DISPLAY_ONLY) {\r\nif (single_display)\r\nreturn ps;\r\n} else\r\nreturn ps;\r\n}\r\nbreak;\r\ncase POWER_STATE_TYPE_PERFORMANCE:\r\nif (ui_class == ATOM_PPLIB_CLASSIFICATION_UI_PERFORMANCE) {\r\nif (ps->caps & ATOM_PPLIB_SINGLE_DISPLAY_ONLY) {\r\nif (single_display)\r\nreturn ps;\r\n} else\r\nreturn ps;\r\n}\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_UVD:\r\nif (adev->pm.dpm.uvd_ps)\r\nreturn adev->pm.dpm.uvd_ps;\r\nelse\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_SD:\r\nif (ps->class & ATOM_PPLIB_CLASSIFICATION_SDSTATE)\r\nreturn ps;\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_HD:\r\nif (ps->class & ATOM_PPLIB_CLASSIFICATION_HDSTATE)\r\nreturn ps;\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_HD2:\r\nif (ps->class & ATOM_PPLIB_CLASSIFICATION_HD2STATE)\r\nreturn ps;\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_MVC:\r\nif (ps->class2 & ATOM_PPLIB_CLASSIFICATION2_MVC)\r\nreturn ps;\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_BOOT:\r\nreturn adev->pm.dpm.boot_ps;\r\ncase POWER_STATE_TYPE_INTERNAL_THERMAL:\r\nif (ps->class & ATOM_PPLIB_CLASSIFICATION_THERMAL)\r\nreturn ps;\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_ACPI:\r\nif (ps->class & ATOM_PPLIB_CLASSIFICATION_ACPI)\r\nreturn ps;\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_ULV:\r\nif (ps->class2 & ATOM_PPLIB_CLASSIFICATION2_ULV)\r\nreturn ps;\r\nbreak;\r\ncase POWER_STATE_TYPE_INTERNAL_3DPERF:\r\nif (ps->class & ATOM_PPLIB_CLASSIFICATION_3DPERFORMANCE)\r\nreturn ps;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nswitch (dpm_state) {\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_SD:\r\ndpm_state = POWER_STATE_TYPE_INTERNAL_UVD_HD;\r\ngoto restart_search;\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_HD:\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_HD2:\r\ncase POWER_STATE_TYPE_INTERNAL_UVD_MVC:\r\nif (adev->pm.dpm.uvd_ps) {\r\nreturn adev->pm.dpm.uvd_ps;\r\n} else {\r\ndpm_state = POWER_STATE_TYPE_PERFORMANCE;\r\ngoto restart_search;\r\n}\r\ncase POWER_STATE_TYPE_INTERNAL_THERMAL:\r\ndpm_state = POWER_STATE_TYPE_INTERNAL_ACPI;\r\ngoto restart_search;\r\ncase POWER_STATE_TYPE_INTERNAL_ACPI:\r\ndpm_state = POWER_STATE_TYPE_BATTERY;\r\ngoto restart_search;\r\ncase POWER_STATE_TYPE_BATTERY:\r\ncase POWER_STATE_TYPE_BALANCED:\r\ncase POWER_STATE_TYPE_INTERNAL_3DPERF:\r\ndpm_state = POWER_STATE_TYPE_PERFORMANCE;\r\ngoto restart_search;\r\ndefault:\r\nbreak;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void amdgpu_dpm_change_power_state_locked(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nstruct amdgpu_ps *ps;\r\nenum amdgpu_pm_state_type dpm_state;\r\nint ret;\r\nif (!adev->pm.dpm_enabled)\r\nreturn;\r\nif (adev->pm.dpm.user_state != adev->pm.dpm.state) {\r\nif ((!adev->pm.dpm.thermal_active) &&\r\n(!adev->pm.dpm.uvd_active))\r\nadev->pm.dpm.state = adev->pm.dpm.user_state;\r\n}\r\ndpm_state = adev->pm.dpm.state;\r\nps = amdgpu_dpm_pick_power_state(adev, dpm_state);\r\nif (ps)\r\nadev->pm.dpm.requested_ps = ps;\r\nelse\r\nreturn;\r\nif (adev->pm.dpm.current_ps == adev->pm.dpm.requested_ps) {\r\nif (ps->vce_active != adev->pm.dpm.vce_active)\r\ngoto force;\r\nif (adev->flags & AMD_IS_APU) {\r\nif (adev->pm.dpm.new_active_crtcs != adev->pm.dpm.current_active_crtcs) {\r\namdgpu_display_bandwidth_update(adev);\r\namdgpu_dpm_display_configuration_changed(adev);\r\nadev->pm.dpm.current_active_crtcs = adev->pm.dpm.new_active_crtcs;\r\nadev->pm.dpm.current_active_crtc_count = adev->pm.dpm.new_active_crtc_count;\r\n}\r\nreturn;\r\n} else {\r\nif (adev->pm.dpm.new_active_crtcs ==\r\nadev->pm.dpm.current_active_crtcs) {\r\nreturn;\r\n} else if ((adev->pm.dpm.current_active_crtc_count > 1) &&\r\n(adev->pm.dpm.new_active_crtc_count > 1)) {\r\namdgpu_display_bandwidth_update(adev);\r\namdgpu_dpm_display_configuration_changed(adev);\r\nadev->pm.dpm.current_active_crtcs = adev->pm.dpm.new_active_crtcs;\r\nadev->pm.dpm.current_active_crtc_count = adev->pm.dpm.new_active_crtc_count;\r\nreturn;\r\n}\r\n}\r\n}\r\nforce:\r\nif (amdgpu_dpm == 1) {\r\nprintk("switching from power state:\n");\r\namdgpu_dpm_print_power_state(adev, adev->pm.dpm.current_ps);\r\nprintk("switching to power state:\n");\r\namdgpu_dpm_print_power_state(adev, adev->pm.dpm.requested_ps);\r\n}\r\nmutex_lock(&adev->ring_lock);\r\nps->vce_active = adev->pm.dpm.vce_active;\r\nret = amdgpu_dpm_pre_set_power_state(adev);\r\nif (ret)\r\ngoto done;\r\namdgpu_display_bandwidth_update(adev);\r\namdgpu_dpm_display_configuration_changed(adev);\r\nadev->pm.dpm.current_active_crtcs = adev->pm.dpm.new_active_crtcs;\r\nadev->pm.dpm.current_active_crtc_count = adev->pm.dpm.new_active_crtc_count;\r\nfor (i = 0; i < AMDGPU_MAX_RINGS; i++) {\r\nstruct amdgpu_ring *ring = adev->rings[i];\r\nif (ring && ring->ready)\r\namdgpu_fence_wait_empty(ring);\r\n}\r\namdgpu_dpm_set_power_state(adev);\r\nadev->pm.dpm.current_ps = adev->pm.dpm.requested_ps;\r\namdgpu_dpm_post_set_power_state(adev);\r\nif (adev->pm.funcs->force_performance_level) {\r\nif (adev->pm.dpm.thermal_active) {\r\nenum amdgpu_dpm_forced_level level = adev->pm.dpm.forced_level;\r\namdgpu_dpm_force_performance_level(adev, AMDGPU_DPM_FORCED_LEVEL_LOW);\r\nadev->pm.dpm.forced_level = level;\r\n} else {\r\namdgpu_dpm_force_performance_level(adev, adev->pm.dpm.forced_level);\r\n}\r\n}\r\ndone:\r\nmutex_unlock(&adev->ring_lock);\r\n}\r\nvoid amdgpu_dpm_enable_uvd(struct amdgpu_device *adev, bool enable)\r\n{\r\nif (adev->pm.funcs->powergate_uvd) {\r\nmutex_lock(&adev->pm.mutex);\r\namdgpu_dpm_powergate_uvd(adev, !enable);\r\nmutex_unlock(&adev->pm.mutex);\r\n} else {\r\nif (enable) {\r\nmutex_lock(&adev->pm.mutex);\r\nadev->pm.dpm.uvd_active = true;\r\nadev->pm.dpm.state = POWER_STATE_TYPE_INTERNAL_UVD;\r\nmutex_unlock(&adev->pm.mutex);\r\n} else {\r\nmutex_lock(&adev->pm.mutex);\r\nadev->pm.dpm.uvd_active = false;\r\nmutex_unlock(&adev->pm.mutex);\r\n}\r\namdgpu_pm_compute_clocks(adev);\r\n}\r\n}\r\nvoid amdgpu_dpm_enable_vce(struct amdgpu_device *adev, bool enable)\r\n{\r\nif (adev->pm.funcs->powergate_vce) {\r\nmutex_lock(&adev->pm.mutex);\r\namdgpu_dpm_powergate_vce(adev, !enable);\r\nmutex_unlock(&adev->pm.mutex);\r\n} else {\r\nif (enable) {\r\nmutex_lock(&adev->pm.mutex);\r\nadev->pm.dpm.vce_active = true;\r\nadev->pm.dpm.vce_level = AMDGPU_VCE_LEVEL_AC_ALL;\r\nmutex_unlock(&adev->pm.mutex);\r\n} else {\r\nmutex_lock(&adev->pm.mutex);\r\nadev->pm.dpm.vce_active = false;\r\nmutex_unlock(&adev->pm.mutex);\r\n}\r\namdgpu_pm_compute_clocks(adev);\r\n}\r\n}\r\nvoid amdgpu_pm_print_power_states(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nfor (i = 0; i < adev->pm.dpm.num_ps; i++) {\r\nprintk("== power state %d ==\n", i);\r\namdgpu_dpm_print_power_state(adev, &adev->pm.dpm.ps[i]);\r\n}\r\n}\r\nint amdgpu_pm_sysfs_init(struct amdgpu_device *adev)\r\n{\r\nint ret;\r\nif (adev->pm.sysfs_initialized)\r\nreturn 0;\r\nif (adev->pm.funcs->get_temperature == NULL)\r\nreturn 0;\r\nadev->pm.int_hwmon_dev = hwmon_device_register_with_groups(adev->dev,\r\nDRIVER_NAME, adev,\r\nhwmon_groups);\r\nif (IS_ERR(adev->pm.int_hwmon_dev)) {\r\nret = PTR_ERR(adev->pm.int_hwmon_dev);\r\ndev_err(adev->dev,\r\n"Unable to register hwmon device: %d\n", ret);\r\nreturn ret;\r\n}\r\nret = device_create_file(adev->dev, &dev_attr_power_dpm_state);\r\nif (ret) {\r\nDRM_ERROR("failed to create device file for dpm state\n");\r\nreturn ret;\r\n}\r\nret = device_create_file(adev->dev, &dev_attr_power_dpm_force_performance_level);\r\nif (ret) {\r\nDRM_ERROR("failed to create device file for dpm state\n");\r\nreturn ret;\r\n}\r\nret = amdgpu_debugfs_pm_init(adev);\r\nif (ret) {\r\nDRM_ERROR("Failed to register debugfs file for dpm!\n");\r\nreturn ret;\r\n}\r\nadev->pm.sysfs_initialized = true;\r\nreturn 0;\r\n}\r\nvoid amdgpu_pm_sysfs_fini(struct amdgpu_device *adev)\r\n{\r\nif (adev->pm.int_hwmon_dev)\r\nhwmon_device_unregister(adev->pm.int_hwmon_dev);\r\ndevice_remove_file(adev->dev, &dev_attr_power_dpm_state);\r\ndevice_remove_file(adev->dev, &dev_attr_power_dpm_force_performance_level);\r\n}\r\nvoid amdgpu_pm_compute_clocks(struct amdgpu_device *adev)\r\n{\r\nstruct drm_device *ddev = adev->ddev;\r\nstruct drm_crtc *crtc;\r\nstruct amdgpu_crtc *amdgpu_crtc;\r\nif (!adev->pm.dpm_enabled)\r\nreturn;\r\nmutex_lock(&adev->pm.mutex);\r\nadev->pm.dpm.new_active_crtcs = 0;\r\nadev->pm.dpm.new_active_crtc_count = 0;\r\nif (adev->mode_info.num_crtc && adev->mode_info.mode_config_initialized) {\r\nlist_for_each_entry(crtc,\r\n&ddev->mode_config.crtc_list, head) {\r\namdgpu_crtc = to_amdgpu_crtc(crtc);\r\nif (crtc->enabled) {\r\nadev->pm.dpm.new_active_crtcs |= (1 << amdgpu_crtc->crtc_id);\r\nadev->pm.dpm.new_active_crtc_count++;\r\n}\r\n}\r\n}\r\nif (power_supply_is_system_supplied() > 0)\r\nadev->pm.dpm.ac_power = true;\r\nelse\r\nadev->pm.dpm.ac_power = false;\r\namdgpu_dpm_change_power_state_locked(adev);\r\nmutex_unlock(&adev->pm.mutex);\r\n}\r\nstatic int amdgpu_debugfs_pm_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nif (adev->pm.dpm_enabled) {\r\nmutex_lock(&adev->pm.mutex);\r\nif (adev->pm.funcs->debugfs_print_current_performance_level)\r\namdgpu_dpm_debugfs_print_current_performance_level(adev, m);\r\nelse\r\nseq_printf(m, "Debugfs support not implemented for this asic\n");\r\nmutex_unlock(&adev->pm.mutex);\r\n}\r\nreturn 0;\r\n}\r\nstatic int amdgpu_debugfs_pm_init(struct amdgpu_device *adev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nreturn amdgpu_debugfs_add_files(adev, amdgpu_pm_info_list, ARRAY_SIZE(amdgpu_pm_info_list));\r\n#else\r\nreturn 0;\r\n#endif\r\n}
