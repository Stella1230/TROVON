struct tick_sched *tick_get_tick_sched(int cpu)\r\n{\r\nreturn &per_cpu(tick_cpu_sched, cpu);\r\n}\r\nstatic void tick_do_update_jiffies64(ktime_t now)\r\n{\r\nunsigned long ticks = 0;\r\nktime_t delta;\r\ndelta = ktime_sub(now, last_jiffies_update);\r\nif (delta.tv64 < tick_period.tv64)\r\nreturn;\r\nwrite_seqlock(&jiffies_lock);\r\ndelta = ktime_sub(now, last_jiffies_update);\r\nif (delta.tv64 >= tick_period.tv64) {\r\ndelta = ktime_sub(delta, tick_period);\r\nlast_jiffies_update = ktime_add(last_jiffies_update,\r\ntick_period);\r\nif (unlikely(delta.tv64 >= tick_period.tv64)) {\r\ns64 incr = ktime_to_ns(tick_period);\r\nticks = ktime_divns(delta, incr);\r\nlast_jiffies_update = ktime_add_ns(last_jiffies_update,\r\nincr * ticks);\r\n}\r\ndo_timer(++ticks);\r\ntick_next_period = ktime_add(last_jiffies_update, tick_period);\r\n} else {\r\nwrite_sequnlock(&jiffies_lock);\r\nreturn;\r\n}\r\nwrite_sequnlock(&jiffies_lock);\r\nupdate_wall_time();\r\n}\r\nstatic ktime_t tick_init_jiffy_update(void)\r\n{\r\nktime_t period;\r\nwrite_seqlock(&jiffies_lock);\r\nif (last_jiffies_update.tv64 == 0)\r\nlast_jiffies_update = tick_next_period;\r\nperiod = last_jiffies_update;\r\nwrite_sequnlock(&jiffies_lock);\r\nreturn period;\r\n}\r\nstatic void tick_sched_do_timer(ktime_t now)\r\n{\r\nint cpu = smp_processor_id();\r\n#ifdef CONFIG_NO_HZ_COMMON\r\nif (unlikely(tick_do_timer_cpu == TICK_DO_TIMER_NONE)\r\n&& !tick_nohz_full_cpu(cpu))\r\ntick_do_timer_cpu = cpu;\r\n#endif\r\nif (tick_do_timer_cpu == cpu)\r\ntick_do_update_jiffies64(now);\r\n}\r\nstatic void tick_sched_handle(struct tick_sched *ts, struct pt_regs *regs)\r\n{\r\n#ifdef CONFIG_NO_HZ_COMMON\r\nif (ts->tick_stopped) {\r\ntouch_softlockup_watchdog();\r\nif (is_idle_task(current))\r\nts->idle_jiffies++;\r\n}\r\n#endif\r\nupdate_process_times(user_mode(regs));\r\nprofile_tick(CPU_PROFILING);\r\n}\r\nstatic bool can_stop_full_tick(void)\r\n{\r\nWARN_ON_ONCE(!irqs_disabled());\r\nif (!sched_can_stop_tick()) {\r\ntrace_tick_stop(0, "more than 1 task in runqueue\n");\r\nreturn false;\r\n}\r\nif (!posix_cpu_timers_can_stop_tick(current)) {\r\ntrace_tick_stop(0, "posix timers running\n");\r\nreturn false;\r\n}\r\nif (!perf_event_can_stop_tick()) {\r\ntrace_tick_stop(0, "perf events running\n");\r\nreturn false;\r\n}\r\n#ifdef CONFIG_HAVE_UNSTABLE_SCHED_CLOCK\r\nif (!sched_clock_stable()) {\r\ntrace_tick_stop(0, "unstable sched clock\n");\r\nWARN_ONCE(tick_nohz_full_running,\r\n"NO_HZ FULL will not work with unstable sched clock");\r\nreturn false;\r\n}\r\n#endif\r\nreturn true;\r\n}\r\nstatic void nohz_full_kick_work_func(struct irq_work *work)\r\n{\r\n}\r\nvoid tick_nohz_full_kick(void)\r\n{\r\nif (!tick_nohz_full_cpu(smp_processor_id()))\r\nreturn;\r\nirq_work_queue(this_cpu_ptr(&nohz_full_kick_work));\r\n}\r\nvoid tick_nohz_full_kick_cpu(int cpu)\r\n{\r\nif (!tick_nohz_full_cpu(cpu))\r\nreturn;\r\nirq_work_queue_on(&per_cpu(nohz_full_kick_work, cpu), cpu);\r\n}\r\nstatic void nohz_full_kick_ipi(void *info)\r\n{\r\n}\r\nvoid tick_nohz_full_kick_all(void)\r\n{\r\nif (!tick_nohz_full_running)\r\nreturn;\r\npreempt_disable();\r\nsmp_call_function_many(tick_nohz_full_mask,\r\nnohz_full_kick_ipi, NULL, false);\r\ntick_nohz_full_kick();\r\npreempt_enable();\r\n}\r\nvoid __tick_nohz_task_switch(void)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nif (!tick_nohz_full_cpu(smp_processor_id()))\r\ngoto out;\r\nif (tick_nohz_tick_stopped() && !can_stop_full_tick())\r\ntick_nohz_full_kick();\r\nout:\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int __init tick_nohz_full_setup(char *str)\r\n{\r\nalloc_bootmem_cpumask_var(&tick_nohz_full_mask);\r\nif (cpulist_parse(str, tick_nohz_full_mask) < 0) {\r\npr_warning("NOHZ: Incorrect nohz_full cpumask\n");\r\nfree_bootmem_cpumask_var(tick_nohz_full_mask);\r\nreturn 1;\r\n}\r\ntick_nohz_full_running = true;\r\nreturn 1;\r\n}\r\nstatic int tick_nohz_cpu_down_callback(struct notifier_block *nfb,\r\nunsigned long action,\r\nvoid *hcpu)\r\n{\r\nunsigned int cpu = (unsigned long)hcpu;\r\nswitch (action & ~CPU_TASKS_FROZEN) {\r\ncase CPU_DOWN_PREPARE:\r\nif (tick_nohz_full_running && tick_do_timer_cpu == cpu)\r\nreturn NOTIFY_BAD;\r\nbreak;\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic int tick_nohz_init_all(void)\r\n{\r\nint err = -1;\r\n#ifdef CONFIG_NO_HZ_FULL_ALL\r\nif (!alloc_cpumask_var(&tick_nohz_full_mask, GFP_KERNEL)) {\r\nWARN(1, "NO_HZ: Can't allocate full dynticks cpumask\n");\r\nreturn err;\r\n}\r\nerr = 0;\r\ncpumask_setall(tick_nohz_full_mask);\r\ntick_nohz_full_running = true;\r\n#endif\r\nreturn err;\r\n}\r\nvoid __init tick_nohz_init(void)\r\n{\r\nint cpu;\r\nif (!tick_nohz_full_running) {\r\nif (tick_nohz_init_all() < 0)\r\nreturn;\r\n}\r\nif (!alloc_cpumask_var(&housekeeping_mask, GFP_KERNEL)) {\r\nWARN(1, "NO_HZ: Can't allocate not-full dynticks cpumask\n");\r\ncpumask_clear(tick_nohz_full_mask);\r\ntick_nohz_full_running = false;\r\nreturn;\r\n}\r\nif (!arch_irq_work_has_interrupt()) {\r\npr_warning("NO_HZ: Can't run full dynticks because arch doesn't "\r\n"support irq work self-IPIs\n");\r\ncpumask_clear(tick_nohz_full_mask);\r\ncpumask_copy(housekeeping_mask, cpu_possible_mask);\r\ntick_nohz_full_running = false;\r\nreturn;\r\n}\r\ncpu = smp_processor_id();\r\nif (cpumask_test_cpu(cpu, tick_nohz_full_mask)) {\r\npr_warning("NO_HZ: Clearing %d from nohz_full range for timekeeping\n", cpu);\r\ncpumask_clear_cpu(cpu, tick_nohz_full_mask);\r\n}\r\ncpumask_andnot(housekeeping_mask,\r\ncpu_possible_mask, tick_nohz_full_mask);\r\nfor_each_cpu(cpu, tick_nohz_full_mask)\r\ncontext_tracking_cpu_set(cpu);\r\ncpu_notifier(tick_nohz_cpu_down_callback, 0);\r\npr_info("NO_HZ: Full dynticks CPUs: %*pbl.\n",\r\ncpumask_pr_args(tick_nohz_full_mask));\r\nWARN_ON_ONCE(cpumask_empty(housekeeping_mask));\r\n}\r\nstatic int __init setup_tick_nohz(char *str)\r\n{\r\nif (!strcmp(str, "off"))\r\ntick_nohz_enabled = 0;\r\nelse if (!strcmp(str, "on"))\r\ntick_nohz_enabled = 1;\r\nelse\r\nreturn 0;\r\nreturn 1;\r\n}\r\nint tick_nohz_tick_stopped(void)\r\n{\r\nreturn __this_cpu_read(tick_cpu_sched.tick_stopped);\r\n}\r\nstatic void tick_nohz_update_jiffies(ktime_t now)\r\n{\r\nunsigned long flags;\r\n__this_cpu_write(tick_cpu_sched.idle_waketime, now);\r\nlocal_irq_save(flags);\r\ntick_do_update_jiffies64(now);\r\nlocal_irq_restore(flags);\r\ntouch_softlockup_watchdog();\r\n}\r\nstatic void\r\nupdate_ts_time_stats(int cpu, struct tick_sched *ts, ktime_t now, u64 *last_update_time)\r\n{\r\nktime_t delta;\r\nif (ts->idle_active) {\r\ndelta = ktime_sub(now, ts->idle_entrytime);\r\nif (nr_iowait_cpu(cpu) > 0)\r\nts->iowait_sleeptime = ktime_add(ts->iowait_sleeptime, delta);\r\nelse\r\nts->idle_sleeptime = ktime_add(ts->idle_sleeptime, delta);\r\nts->idle_entrytime = now;\r\n}\r\nif (last_update_time)\r\n*last_update_time = ktime_to_us(now);\r\n}\r\nstatic void tick_nohz_stop_idle(struct tick_sched *ts, ktime_t now)\r\n{\r\nupdate_ts_time_stats(smp_processor_id(), ts, now, NULL);\r\nts->idle_active = 0;\r\nsched_clock_idle_wakeup_event(0);\r\n}\r\nstatic ktime_t tick_nohz_start_idle(struct tick_sched *ts)\r\n{\r\nktime_t now = ktime_get();\r\nts->idle_entrytime = now;\r\nts->idle_active = 1;\r\nsched_clock_idle_sleep_event();\r\nreturn now;\r\n}\r\nu64 get_cpu_idle_time_us(int cpu, u64 *last_update_time)\r\n{\r\nstruct tick_sched *ts = &per_cpu(tick_cpu_sched, cpu);\r\nktime_t now, idle;\r\nif (!tick_nohz_active)\r\nreturn -1;\r\nnow = ktime_get();\r\nif (last_update_time) {\r\nupdate_ts_time_stats(cpu, ts, now, last_update_time);\r\nidle = ts->idle_sleeptime;\r\n} else {\r\nif (ts->idle_active && !nr_iowait_cpu(cpu)) {\r\nktime_t delta = ktime_sub(now, ts->idle_entrytime);\r\nidle = ktime_add(ts->idle_sleeptime, delta);\r\n} else {\r\nidle = ts->idle_sleeptime;\r\n}\r\n}\r\nreturn ktime_to_us(idle);\r\n}\r\nu64 get_cpu_iowait_time_us(int cpu, u64 *last_update_time)\r\n{\r\nstruct tick_sched *ts = &per_cpu(tick_cpu_sched, cpu);\r\nktime_t now, iowait;\r\nif (!tick_nohz_active)\r\nreturn -1;\r\nnow = ktime_get();\r\nif (last_update_time) {\r\nupdate_ts_time_stats(cpu, ts, now, last_update_time);\r\niowait = ts->iowait_sleeptime;\r\n} else {\r\nif (ts->idle_active && nr_iowait_cpu(cpu) > 0) {\r\nktime_t delta = ktime_sub(now, ts->idle_entrytime);\r\niowait = ktime_add(ts->iowait_sleeptime, delta);\r\n} else {\r\niowait = ts->iowait_sleeptime;\r\n}\r\n}\r\nreturn ktime_to_us(iowait);\r\n}\r\nstatic void tick_nohz_restart(struct tick_sched *ts, ktime_t now)\r\n{\r\nhrtimer_cancel(&ts->sched_timer);\r\nhrtimer_set_expires(&ts->sched_timer, ts->last_tick);\r\nhrtimer_forward(&ts->sched_timer, now, tick_period);\r\nif (ts->nohz_mode == NOHZ_MODE_HIGHRES)\r\nhrtimer_start_expires(&ts->sched_timer, HRTIMER_MODE_ABS_PINNED);\r\nelse\r\ntick_program_event(hrtimer_get_expires(&ts->sched_timer), 1);\r\n}\r\nstatic ktime_t tick_nohz_stop_sched_tick(struct tick_sched *ts,\r\nktime_t now, int cpu)\r\n{\r\nstruct clock_event_device *dev = __this_cpu_read(tick_cpu_device.evtdev);\r\nu64 basemono, next_tick, next_tmr, next_rcu, delta, expires;\r\nunsigned long seq, basejiff;\r\nktime_t tick;\r\ndo {\r\nseq = read_seqbegin(&jiffies_lock);\r\nbasemono = last_jiffies_update.tv64;\r\nbasejiff = jiffies;\r\n} while (read_seqretry(&jiffies_lock, seq));\r\nts->last_jiffies = basejiff;\r\nif (rcu_needs_cpu(basemono, &next_rcu) ||\r\narch_needs_cpu() || irq_work_needs_cpu()) {\r\nnext_tick = basemono + TICK_NSEC;\r\n} else {\r\nnext_tmr = get_next_timer_interrupt(basejiff, basemono);\r\nts->next_timer = next_tmr;\r\nnext_tick = next_rcu < next_tmr ? next_rcu : next_tmr;\r\n}\r\ndelta = next_tick - basemono;\r\nif (delta <= (u64)TICK_NSEC) {\r\ntick.tv64 = 0;\r\nif (!ts->tick_stopped)\r\ngoto out;\r\nif (delta == 0) {\r\ntick_nohz_restart(ts, now);\r\ngoto out;\r\n}\r\n}\r\ndelta = timekeeping_max_deferment();\r\nif (cpu == tick_do_timer_cpu) {\r\ntick_do_timer_cpu = TICK_DO_TIMER_NONE;\r\nts->do_timer_last = 1;\r\n} else if (tick_do_timer_cpu != TICK_DO_TIMER_NONE) {\r\ndelta = KTIME_MAX;\r\nts->do_timer_last = 0;\r\n} else if (!ts->do_timer_last) {\r\ndelta = KTIME_MAX;\r\n}\r\n#ifdef CONFIG_NO_HZ_FULL\r\nif (!ts->inidle)\r\ndelta = min(delta, scheduler_tick_max_deferment());\r\n#endif\r\nif (delta < (KTIME_MAX - basemono))\r\nexpires = basemono + delta;\r\nelse\r\nexpires = KTIME_MAX;\r\nexpires = min_t(u64, expires, next_tick);\r\ntick.tv64 = expires;\r\nif (ts->tick_stopped && (expires == dev->next_event.tv64))\r\ngoto out;\r\nif (!ts->tick_stopped) {\r\nnohz_balance_enter_idle(cpu);\r\ncalc_load_enter_idle();\r\nts->last_tick = hrtimer_get_expires(&ts->sched_timer);\r\nts->tick_stopped = 1;\r\ntrace_tick_stop(1, " ");\r\n}\r\nif (unlikely(expires == KTIME_MAX)) {\r\nif (ts->nohz_mode == NOHZ_MODE_HIGHRES)\r\nhrtimer_cancel(&ts->sched_timer);\r\ngoto out;\r\n}\r\nif (ts->nohz_mode == NOHZ_MODE_HIGHRES)\r\nhrtimer_start(&ts->sched_timer, tick, HRTIMER_MODE_ABS_PINNED);\r\nelse\r\ntick_program_event(tick, 1);\r\nout:\r\nts->sleep_length = ktime_sub(dev->next_event, now);\r\nreturn tick;\r\n}\r\nstatic void tick_nohz_restart_sched_tick(struct tick_sched *ts, ktime_t now)\r\n{\r\ntick_do_update_jiffies64(now);\r\nupdate_cpu_load_nohz();\r\ncalc_load_exit_idle();\r\ntouch_softlockup_watchdog();\r\nts->tick_stopped = 0;\r\nts->idle_exittime = now;\r\ntick_nohz_restart(ts, now);\r\n}\r\nstatic void tick_nohz_full_update_tick(struct tick_sched *ts)\r\n{\r\n#ifdef CONFIG_NO_HZ_FULL\r\nint cpu = smp_processor_id();\r\nif (!tick_nohz_full_cpu(cpu))\r\nreturn;\r\nif (!ts->tick_stopped && ts->nohz_mode == NOHZ_MODE_INACTIVE)\r\nreturn;\r\nif (can_stop_full_tick())\r\ntick_nohz_stop_sched_tick(ts, ktime_get(), cpu);\r\nelse if (ts->tick_stopped)\r\ntick_nohz_restart_sched_tick(ts, ktime_get());\r\n#endif\r\n}\r\nstatic bool can_stop_idle_tick(int cpu, struct tick_sched *ts)\r\n{\r\nif (unlikely(!cpu_online(cpu))) {\r\nif (cpu == tick_do_timer_cpu)\r\ntick_do_timer_cpu = TICK_DO_TIMER_NONE;\r\nreturn false;\r\n}\r\nif (unlikely(ts->nohz_mode == NOHZ_MODE_INACTIVE)) {\r\nts->sleep_length = (ktime_t) { .tv64 = NSEC_PER_SEC/HZ };\r\nreturn false;\r\n}\r\nif (need_resched())\r\nreturn false;\r\nif (unlikely(local_softirq_pending() && cpu_online(cpu))) {\r\nstatic int ratelimit;\r\nif (ratelimit < 10 &&\r\n(local_softirq_pending() & SOFTIRQ_STOP_IDLE_MASK)) {\r\npr_warn("NOHZ: local_softirq_pending %02x\n",\r\n(unsigned int) local_softirq_pending());\r\nratelimit++;\r\n}\r\nreturn false;\r\n}\r\nif (tick_nohz_full_enabled()) {\r\nif (tick_do_timer_cpu == cpu)\r\nreturn false;\r\nif (tick_do_timer_cpu == TICK_DO_TIMER_NONE)\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic void __tick_nohz_idle_enter(struct tick_sched *ts)\r\n{\r\nktime_t now, expires;\r\nint cpu = smp_processor_id();\r\nnow = tick_nohz_start_idle(ts);\r\nif (can_stop_idle_tick(cpu, ts)) {\r\nint was_stopped = ts->tick_stopped;\r\nts->idle_calls++;\r\nexpires = tick_nohz_stop_sched_tick(ts, now, cpu);\r\nif (expires.tv64 > 0LL) {\r\nts->idle_sleeps++;\r\nts->idle_expires = expires;\r\n}\r\nif (!was_stopped && ts->tick_stopped)\r\nts->idle_jiffies = ts->last_jiffies;\r\n}\r\n}\r\nvoid tick_nohz_idle_enter(void)\r\n{\r\nstruct tick_sched *ts;\r\nWARN_ON_ONCE(irqs_disabled());\r\nset_cpu_sd_state_idle();\r\nlocal_irq_disable();\r\nts = this_cpu_ptr(&tick_cpu_sched);\r\nts->inidle = 1;\r\n__tick_nohz_idle_enter(ts);\r\nlocal_irq_enable();\r\n}\r\nvoid tick_nohz_irq_exit(void)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nif (ts->inidle)\r\n__tick_nohz_idle_enter(ts);\r\nelse\r\ntick_nohz_full_update_tick(ts);\r\n}\r\nktime_t tick_nohz_get_sleep_length(void)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nreturn ts->sleep_length;\r\n}\r\nstatic void tick_nohz_account_idle_ticks(struct tick_sched *ts)\r\n{\r\n#ifndef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE\r\nunsigned long ticks;\r\nif (vtime_accounting_enabled())\r\nreturn;\r\nticks = jiffies - ts->idle_jiffies;\r\nif (ticks && ticks < LONG_MAX)\r\naccount_idle_ticks(ticks);\r\n#endif\r\n}\r\nvoid tick_nohz_idle_exit(void)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nktime_t now;\r\nlocal_irq_disable();\r\nWARN_ON_ONCE(!ts->inidle);\r\nts->inidle = 0;\r\nif (ts->idle_active || ts->tick_stopped)\r\nnow = ktime_get();\r\nif (ts->idle_active)\r\ntick_nohz_stop_idle(ts, now);\r\nif (ts->tick_stopped) {\r\ntick_nohz_restart_sched_tick(ts, now);\r\ntick_nohz_account_idle_ticks(ts);\r\n}\r\nlocal_irq_enable();\r\n}\r\nstatic void tick_nohz_handler(struct clock_event_device *dev)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nstruct pt_regs *regs = get_irq_regs();\r\nktime_t now = ktime_get();\r\ndev->next_event.tv64 = KTIME_MAX;\r\ntick_sched_do_timer(now);\r\ntick_sched_handle(ts, regs);\r\nif (unlikely(ts->tick_stopped))\r\nreturn;\r\nhrtimer_forward(&ts->sched_timer, now, tick_period);\r\ntick_program_event(hrtimer_get_expires(&ts->sched_timer), 1);\r\n}\r\nstatic inline void tick_nohz_activate(struct tick_sched *ts, int mode)\r\n{\r\nif (!tick_nohz_enabled)\r\nreturn;\r\nts->nohz_mode = mode;\r\nif (!test_and_set_bit(0, &tick_nohz_active))\r\ntimers_update_migration(true);\r\n}\r\nstatic void tick_nohz_switch_to_nohz(void)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nktime_t next;\r\nif (!tick_nohz_enabled)\r\nreturn;\r\nif (tick_switch_to_oneshot(tick_nohz_handler))\r\nreturn;\r\nhrtimer_init(&ts->sched_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS);\r\nnext = tick_init_jiffy_update();\r\nhrtimer_forward_now(&ts->sched_timer, tick_period);\r\nhrtimer_set_expires(&ts->sched_timer, next);\r\ntick_program_event(next, 1);\r\ntick_nohz_activate(ts, NOHZ_MODE_LOWRES);\r\n}\r\nstatic void tick_nohz_kick_tick(struct tick_sched *ts, ktime_t now)\r\n{\r\n#if 0\r\nktime_t delta;\r\ndelta = ktime_sub(hrtimer_get_expires(&ts->sched_timer), now);\r\nif (delta.tv64 <= tick_period.tv64)\r\nreturn;\r\ntick_nohz_restart(ts, now);\r\n#endif\r\n}\r\nstatic inline void tick_nohz_irq_enter(void)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nktime_t now;\r\nif (!ts->idle_active && !ts->tick_stopped)\r\nreturn;\r\nnow = ktime_get();\r\nif (ts->idle_active)\r\ntick_nohz_stop_idle(ts, now);\r\nif (ts->tick_stopped) {\r\ntick_nohz_update_jiffies(now);\r\ntick_nohz_kick_tick(ts, now);\r\n}\r\n}\r\nstatic inline void tick_nohz_switch_to_nohz(void) { }\r\nstatic inline void tick_nohz_irq_enter(void) { }\r\nstatic inline void tick_nohz_activate(struct tick_sched *ts, int mode) { }\r\nvoid tick_irq_enter(void)\r\n{\r\ntick_check_oneshot_broadcast_this_cpu();\r\ntick_nohz_irq_enter();\r\n}\r\nstatic enum hrtimer_restart tick_sched_timer(struct hrtimer *timer)\r\n{\r\nstruct tick_sched *ts =\r\ncontainer_of(timer, struct tick_sched, sched_timer);\r\nstruct pt_regs *regs = get_irq_regs();\r\nktime_t now = ktime_get();\r\ntick_sched_do_timer(now);\r\nif (regs)\r\ntick_sched_handle(ts, regs);\r\nif (unlikely(ts->tick_stopped))\r\nreturn HRTIMER_NORESTART;\r\nhrtimer_forward(timer, now, tick_period);\r\nreturn HRTIMER_RESTART;\r\n}\r\nstatic int __init skew_tick(char *str)\r\n{\r\nget_option(&str, &sched_skew_tick);\r\nreturn 0;\r\n}\r\nvoid tick_setup_sched_timer(void)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nktime_t now = ktime_get();\r\nhrtimer_init(&ts->sched_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS);\r\nts->sched_timer.function = tick_sched_timer;\r\nhrtimer_set_expires(&ts->sched_timer, tick_init_jiffy_update());\r\nif (sched_skew_tick) {\r\nu64 offset = ktime_to_ns(tick_period) >> 1;\r\ndo_div(offset, num_possible_cpus());\r\noffset *= smp_processor_id();\r\nhrtimer_add_expires_ns(&ts->sched_timer, offset);\r\n}\r\nhrtimer_forward(&ts->sched_timer, now, tick_period);\r\nhrtimer_start_expires(&ts->sched_timer, HRTIMER_MODE_ABS_PINNED);\r\ntick_nohz_activate(ts, NOHZ_MODE_HIGHRES);\r\n}\r\nvoid tick_cancel_sched_timer(int cpu)\r\n{\r\nstruct tick_sched *ts = &per_cpu(tick_cpu_sched, cpu);\r\n# ifdef CONFIG_HIGH_RES_TIMERS\r\nif (ts->sched_timer.base)\r\nhrtimer_cancel(&ts->sched_timer);\r\n# endif\r\nmemset(ts, 0, sizeof(*ts));\r\n}\r\nvoid tick_clock_notify(void)\r\n{\r\nint cpu;\r\nfor_each_possible_cpu(cpu)\r\nset_bit(0, &per_cpu(tick_cpu_sched, cpu).check_clocks);\r\n}\r\nvoid tick_oneshot_notify(void)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nset_bit(0, &ts->check_clocks);\r\n}\r\nint tick_check_oneshot_change(int allow_nohz)\r\n{\r\nstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\r\nif (!test_and_clear_bit(0, &ts->check_clocks))\r\nreturn 0;\r\nif (ts->nohz_mode != NOHZ_MODE_INACTIVE)\r\nreturn 0;\r\nif (!timekeeping_valid_for_hres() || !tick_is_oneshot_available())\r\nreturn 0;\r\nif (!allow_nohz)\r\nreturn 1;\r\ntick_nohz_switch_to_nohz();\r\nreturn 0;\r\n}
