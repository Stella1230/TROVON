static int\r\ngk104_fifo_gpfifo_kick(struct gk104_fifo_chan *chan)\r\n{\r\nstruct gk104_fifo *fifo = chan->fifo;\r\nstruct nvkm_subdev *subdev = &fifo->base.engine.subdev;\r\nstruct nvkm_device *device = subdev->device;\r\nstruct nvkm_client *client = chan->base.object.client;\r\nnvkm_wr32(device, 0x002634, chan->base.chid);\r\nif (nvkm_msec(device, 2000,\r\nif (!(nvkm_rd32(device, 0x002634) & 0x00100000))\r\nbreak;\r\n) < 0) {\r\nnvkm_error(subdev, "channel %d [%s] kick timeout\n",\r\nchan->base.chid, client->name);\r\nreturn -EBUSY;\r\n}\r\nreturn 0;\r\n}\r\nstatic u32\r\ngk104_fifo_gpfifo_engine_addr(struct nvkm_engine *engine)\r\n{\r\nswitch (engine->subdev.index) {\r\ncase NVKM_ENGINE_SW :\r\ncase NVKM_ENGINE_CE0 :\r\ncase NVKM_ENGINE_CE1 :\r\ncase NVKM_ENGINE_CE2 : return 0x0000;\r\ncase NVKM_ENGINE_GR : return 0x0210;\r\ncase NVKM_ENGINE_MSPDEC: return 0x0250;\r\ncase NVKM_ENGINE_MSPPP : return 0x0260;\r\ncase NVKM_ENGINE_MSVLD : return 0x0270;\r\ndefault:\r\nWARN_ON(1);\r\nreturn 0;\r\n}\r\n}\r\nstatic int\r\ngk104_fifo_gpfifo_engine_fini(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine, bool suspend)\r\n{\r\nconst u32 offset = gk104_fifo_gpfifo_engine_addr(engine);\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct nvkm_gpuobj *inst = chan->base.inst;\r\nint ret;\r\nret = gk104_fifo_gpfifo_kick(chan);\r\nif (ret && suspend)\r\nreturn ret;\r\nif (offset) {\r\nnvkm_kmap(inst);\r\nnvkm_wo32(inst, offset + 0x00, 0x00000000);\r\nnvkm_wo32(inst, offset + 0x04, 0x00000000);\r\nnvkm_done(inst);\r\n}\r\nreturn ret;\r\n}\r\nstatic int\r\ngk104_fifo_gpfifo_engine_init(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine)\r\n{\r\nconst u32 offset = gk104_fifo_gpfifo_engine_addr(engine);\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct nvkm_gpuobj *inst = chan->base.inst;\r\nif (offset) {\r\nu64 addr = chan->engn[engine->subdev.index].vma.offset;\r\nnvkm_kmap(inst);\r\nnvkm_wo32(inst, offset + 0x00, lower_32_bits(addr) | 4);\r\nnvkm_wo32(inst, offset + 0x04, upper_32_bits(addr));\r\nnvkm_done(inst);\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\ngk104_fifo_gpfifo_engine_dtor(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nnvkm_gpuobj_unmap(&chan->engn[engine->subdev.index].vma);\r\nnvkm_gpuobj_del(&chan->engn[engine->subdev.index].inst);\r\n}\r\nstatic int\r\ngk104_fifo_gpfifo_engine_ctor(struct nvkm_fifo_chan *base,\r\nstruct nvkm_engine *engine,\r\nstruct nvkm_object *object)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nint engn = engine->subdev.index;\r\nint ret;\r\nif (!gk104_fifo_gpfifo_engine_addr(engine))\r\nreturn 0;\r\nret = nvkm_object_bind(object, NULL, 0, &chan->engn[engn].inst);\r\nif (ret)\r\nreturn ret;\r\nreturn nvkm_gpuobj_map(chan->engn[engn].inst, chan->vm,\r\nNV_MEM_ACCESS_RW, &chan->engn[engn].vma);\r\n}\r\nstatic void\r\ngk104_fifo_gpfifo_fini(struct nvkm_fifo_chan *base)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct gk104_fifo *fifo = chan->fifo;\r\nstruct nvkm_device *device = fifo->base.engine.subdev.device;\r\nu32 coff = chan->base.chid * 8;\r\nif (!list_empty(&chan->head)) {\r\nlist_del_init(&chan->head);\r\nnvkm_mask(device, 0x800004 + coff, 0x00000800, 0x00000800);\r\ngk104_fifo_runlist_update(fifo, chan->engine);\r\n}\r\nnvkm_wr32(device, 0x800000 + coff, 0x00000000);\r\n}\r\nstatic void\r\ngk104_fifo_gpfifo_init(struct nvkm_fifo_chan *base)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nstruct gk104_fifo *fifo = chan->fifo;\r\nstruct nvkm_device *device = fifo->base.engine.subdev.device;\r\nu32 addr = chan->base.inst->addr >> 12;\r\nu32 coff = chan->base.chid * 8;\r\nnvkm_mask(device, 0x800004 + coff, 0x000f0000, chan->engine << 16);\r\nnvkm_wr32(device, 0x800000 + coff, 0x80000000 | addr);\r\nif (list_empty(&chan->head) && !chan->killed) {\r\nlist_add_tail(&chan->head, &fifo->engine[chan->engine].chan);\r\nnvkm_mask(device, 0x800004 + coff, 0x00000400, 0x00000400);\r\ngk104_fifo_runlist_update(fifo, chan->engine);\r\nnvkm_mask(device, 0x800004 + coff, 0x00000400, 0x00000400);\r\n}\r\n}\r\nstatic void *\r\ngk104_fifo_gpfifo_dtor(struct nvkm_fifo_chan *base)\r\n{\r\nstruct gk104_fifo_chan *chan = gk104_fifo_chan(base);\r\nnvkm_vm_ref(NULL, &chan->vm, chan->pgd);\r\nnvkm_gpuobj_del(&chan->pgd);\r\nreturn chan;\r\n}\r\nint\r\ngk104_fifo_gpfifo_new(struct nvkm_fifo *base, const struct nvkm_oclass *oclass,\r\nvoid *data, u32 size, struct nvkm_object **pobject)\r\n{\r\nunion {\r\nstruct kepler_channel_gpfifo_a_v0 v0;\r\n} *args = data;\r\nstruct gk104_fifo *fifo = gk104_fifo(base);\r\nstruct nvkm_device *device = fifo->base.engine.subdev.device;\r\nstruct nvkm_object *parent = oclass->parent;\r\nstruct gk104_fifo_chan *chan;\r\nu64 usermem, ioffset, ilength;\r\nu32 engines;\r\nint ret, i;\r\nnvif_ioctl(parent, "create channel gpfifo size %d\n", size);\r\nif (nvif_unpack(args->v0, 0, 0, false)) {\r\nnvif_ioctl(parent, "create channel gpfifo vers %d vm %llx "\r\n"ioffset %016llx ilength %08x engine %08x\n",\r\nargs->v0.version, args->v0.vm, args->v0.ioffset,\r\nargs->v0.ilength, args->v0.engine);\r\n} else\r\nreturn ret;\r\nfor (i = 0, engines = 0; i < ARRAY_SIZE(fifo->engine); i++) {\r\nu64 subdevs = gk104_fifo_engine_subdev(i);\r\nif (!nvkm_device_engine(device, __ffs64(subdevs)))\r\ncontinue;\r\nengines |= (1 << i);\r\n}\r\nif (!args->v0.engine) {\r\nargs->v0.engine = engines;\r\nreturn nvkm_object_new(oclass, NULL, 0, pobject);\r\n}\r\nargs->v0.engine &= engines;\r\nif (!args->v0.engine) {\r\nnvif_ioctl(parent, "no supported engine\n");\r\nreturn -ENODEV;\r\n}\r\nif (!(chan = kzalloc(sizeof(*chan), GFP_KERNEL)))\r\nreturn -ENOMEM;\r\n*pobject = &chan->base.object;\r\nchan->fifo = fifo;\r\nchan->engine = __ffs(args->v0.engine);\r\nINIT_LIST_HEAD(&chan->head);\r\nret = nvkm_fifo_chan_ctor(&gk104_fifo_gpfifo_func, &fifo->base,\r\n0x1000, 0x1000, true, args->v0.vm, 0,\r\ngk104_fifo_engine_subdev(chan->engine),\r\n1, fifo->user.bar.offset, 0x200,\r\noclass, &chan->base);\r\nif (ret)\r\nreturn ret;\r\nargs->v0.chid = chan->base.chid;\r\nret = nvkm_gpuobj_new(device, 0x10000, 0x1000, false, NULL, &chan->pgd);\r\nif (ret)\r\nreturn ret;\r\nnvkm_kmap(chan->base.inst);\r\nnvkm_wo32(chan->base.inst, 0x0200, lower_32_bits(chan->pgd->addr));\r\nnvkm_wo32(chan->base.inst, 0x0204, upper_32_bits(chan->pgd->addr));\r\nnvkm_wo32(chan->base.inst, 0x0208, 0xffffffff);\r\nnvkm_wo32(chan->base.inst, 0x020c, 0x000000ff);\r\nnvkm_done(chan->base.inst);\r\nret = nvkm_vm_ref(chan->base.vm, &chan->vm, chan->pgd);\r\nif (ret)\r\nreturn ret;\r\nusermem = chan->base.chid * 0x200;\r\nioffset = args->v0.ioffset;\r\nilength = order_base_2(args->v0.ilength / 8);\r\nnvkm_kmap(fifo->user.mem);\r\nfor (i = 0; i < 0x200; i += 4)\r\nnvkm_wo32(fifo->user.mem, usermem + i, 0x00000000);\r\nnvkm_done(fifo->user.mem);\r\nusermem = nvkm_memory_addr(fifo->user.mem) + usermem;\r\nnvkm_kmap(chan->base.inst);\r\nnvkm_wo32(chan->base.inst, 0x08, lower_32_bits(usermem));\r\nnvkm_wo32(chan->base.inst, 0x0c, upper_32_bits(usermem));\r\nnvkm_wo32(chan->base.inst, 0x10, 0x0000face);\r\nnvkm_wo32(chan->base.inst, 0x30, 0xfffff902);\r\nnvkm_wo32(chan->base.inst, 0x48, lower_32_bits(ioffset));\r\nnvkm_wo32(chan->base.inst, 0x4c, upper_32_bits(ioffset) |\r\n(ilength << 16));\r\nnvkm_wo32(chan->base.inst, 0x84, 0x20400000);\r\nnvkm_wo32(chan->base.inst, 0x94, 0x30000001);\r\nnvkm_wo32(chan->base.inst, 0x9c, 0x00000100);\r\nnvkm_wo32(chan->base.inst, 0xac, 0x0000001f);\r\nnvkm_wo32(chan->base.inst, 0xe8, chan->base.chid);\r\nnvkm_wo32(chan->base.inst, 0xb8, 0xf8000000);\r\nnvkm_wo32(chan->base.inst, 0xf8, 0x10003080);\r\nnvkm_wo32(chan->base.inst, 0xfc, 0x10000010);\r\nnvkm_done(chan->base.inst);\r\nreturn 0;\r\n}
