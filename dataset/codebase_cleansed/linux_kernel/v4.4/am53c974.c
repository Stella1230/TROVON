static inline struct pci_esp_priv *pci_esp_get_priv(struct esp *esp)\r\n{\r\nstruct pci_dev *pdev = esp->dev;\r\nreturn pci_get_drvdata(pdev);\r\n}\r\nstatic void pci_esp_write8(struct esp *esp, u8 val, unsigned long reg)\r\n{\r\niowrite8(val, esp->regs + (reg * 4UL));\r\n}\r\nstatic u8 pci_esp_read8(struct esp *esp, unsigned long reg)\r\n{\r\nreturn ioread8(esp->regs + (reg * 4UL));\r\n}\r\nstatic void pci_esp_write32(struct esp *esp, u32 val, unsigned long reg)\r\n{\r\nreturn iowrite32(val, esp->regs + (reg * 4UL));\r\n}\r\nstatic dma_addr_t pci_esp_map_single(struct esp *esp, void *buf,\r\nsize_t sz, int dir)\r\n{\r\nreturn pci_map_single(esp->dev, buf, sz, dir);\r\n}\r\nstatic int pci_esp_map_sg(struct esp *esp, struct scatterlist *sg,\r\nint num_sg, int dir)\r\n{\r\nreturn pci_map_sg(esp->dev, sg, num_sg, dir);\r\n}\r\nstatic void pci_esp_unmap_single(struct esp *esp, dma_addr_t addr,\r\nsize_t sz, int dir)\r\n{\r\npci_unmap_single(esp->dev, addr, sz, dir);\r\n}\r\nstatic void pci_esp_unmap_sg(struct esp *esp, struct scatterlist *sg,\r\nint num_sg, int dir)\r\n{\r\npci_unmap_sg(esp->dev, sg, num_sg, dir);\r\n}\r\nstatic int pci_esp_irq_pending(struct esp *esp)\r\n{\r\nstruct pci_esp_priv *pep = pci_esp_get_priv(esp);\r\npep->dma_status = pci_esp_read8(esp, ESP_DMA_STATUS);\r\nesp_dma_log("dma intr dreg[%02x]\n", pep->dma_status);\r\nif (pep->dma_status & (ESP_DMA_STAT_ERROR |\r\nESP_DMA_STAT_ABORT |\r\nESP_DMA_STAT_DONE |\r\nESP_DMA_STAT_SCSIINT))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void pci_esp_reset_dma(struct esp *esp)\r\n{\r\n}\r\nstatic void pci_esp_dma_drain(struct esp *esp)\r\n{\r\nu8 resid;\r\nint lim = 1000;\r\nif ((esp->sreg & ESP_STAT_PMASK) == ESP_DOP ||\r\n(esp->sreg & ESP_STAT_PMASK) == ESP_DIP)\r\nreturn;\r\nwhile (--lim > 0) {\r\nresid = pci_esp_read8(esp, ESP_FFLAGS) & ESP_FF_FBYTES;\r\nif (resid <= 1)\r\nbreak;\r\ncpu_relax();\r\n}\r\nlim = 1000;\r\npci_esp_write8(esp, ESP_DMA_CMD_DIR | ESP_DMA_CMD_BLAST, ESP_DMA_CMD);\r\nwhile (pci_esp_read8(esp, ESP_DMA_STATUS) & ESP_DMA_STAT_BCMPLT) {\r\nif (--lim == 0)\r\nbreak;\r\ncpu_relax();\r\n}\r\npci_esp_write8(esp, ESP_DMA_CMD_DIR | ESP_DMA_CMD_IDLE, ESP_DMA_CMD);\r\nesp_dma_log("DMA blast done (%d tries, %d bytes left)\n", lim, resid);\r\nif (WARN_ON_ONCE(resid == 1)) {\r\nstruct esp_cmd_entry *ent = esp->active_cmd;\r\nent->flags |= ESP_CMD_FLAG_RESIDUAL;\r\n}\r\n}\r\nstatic void pci_esp_dma_invalidate(struct esp *esp)\r\n{\r\nstruct pci_esp_priv *pep = pci_esp_get_priv(esp);\r\nesp_dma_log("invalidate DMA\n");\r\npci_esp_write8(esp, ESP_DMA_CMD_IDLE, ESP_DMA_CMD);\r\npep->dma_status = 0;\r\n}\r\nstatic int pci_esp_dma_error(struct esp *esp)\r\n{\r\nstruct pci_esp_priv *pep = pci_esp_get_priv(esp);\r\nif (pep->dma_status & ESP_DMA_STAT_ERROR) {\r\nu8 dma_cmd = pci_esp_read8(esp, ESP_DMA_CMD);\r\nif ((dma_cmd & ESP_DMA_CMD_MASK) == ESP_DMA_CMD_START)\r\npci_esp_write8(esp, ESP_DMA_CMD_ABORT, ESP_DMA_CMD);\r\nreturn 1;\r\n}\r\nif (pep->dma_status & ESP_DMA_STAT_ABORT) {\r\npci_esp_write8(esp, ESP_DMA_CMD_IDLE, ESP_DMA_CMD);\r\npep->dma_status = pci_esp_read8(esp, ESP_DMA_CMD);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void pci_esp_send_dma_cmd(struct esp *esp, u32 addr, u32 esp_count,\r\nu32 dma_count, int write, u8 cmd)\r\n{\r\nstruct pci_esp_priv *pep = pci_esp_get_priv(esp);\r\nu32 val = 0;\r\nBUG_ON(!(cmd & ESP_CMD_DMA));\r\npep->dma_status = 0;\r\nif (write)\r\nval |= ESP_DMA_CMD_DIR;\r\npci_esp_write8(esp, ESP_DMA_CMD_IDLE | val, ESP_DMA_CMD);\r\npci_esp_write8(esp, (esp_count >> 0) & 0xff, ESP_TCLOW);\r\npci_esp_write8(esp, (esp_count >> 8) & 0xff, ESP_TCMED);\r\nif (esp->config2 & ESP_CONFIG2_FENAB)\r\npci_esp_write8(esp, (esp_count >> 16) & 0xff, ESP_TCHI);\r\npci_esp_write32(esp, esp_count, ESP_DMA_STC);\r\npci_esp_write32(esp, addr, ESP_DMA_SPA);\r\nesp_dma_log("start dma addr[%x] count[%d:%d]\n",\r\naddr, esp_count, dma_count);\r\nscsi_esp_cmd(esp, cmd);\r\npci_esp_write8(esp, ESP_DMA_CMD_START | val, ESP_DMA_CMD);\r\n}\r\nstatic u32 pci_esp_dma_length_limit(struct esp *esp, u32 dma_addr, u32 dma_len)\r\n{\r\nint dma_limit = 16;\r\nu32 base, end;\r\nif (esp->config2 & ESP_CONFIG2_FENAB)\r\ndma_limit = 24;\r\nif (dma_len > (1U << dma_limit))\r\ndma_len = (1U << dma_limit);\r\nbase = dma_addr & ((1U << 24) - 1U);\r\nend = base + dma_len;\r\nif (end > (1U << 24))\r\nend = (1U <<24);\r\ndma_len = end - base;\r\nreturn dma_len;\r\n}\r\nstatic void dc390_eeprom_prepare_read(struct pci_dev *pdev, u8 cmd)\r\n{\r\nu8 carry_flag = 1, j = 0x80, bval;\r\nint i;\r\nfor (i = 0; i < 9; i++) {\r\nif (carry_flag) {\r\npci_write_config_byte(pdev, 0x80, 0x40);\r\nbval = 0xc0;\r\n} else\r\nbval = 0x80;\r\nudelay(160);\r\npci_write_config_byte(pdev, 0x80, bval);\r\nudelay(160);\r\npci_write_config_byte(pdev, 0x80, 0);\r\nudelay(160);\r\ncarry_flag = (cmd & j) ? 1 : 0;\r\nj >>= 1;\r\n}\r\n}\r\nstatic u16 dc390_eeprom_get_data(struct pci_dev *pdev)\r\n{\r\nint i;\r\nu16 wval = 0;\r\nu8 bval;\r\nfor (i = 0; i < 16; i++) {\r\nwval <<= 1;\r\npci_write_config_byte(pdev, 0x80, 0x80);\r\nudelay(160);\r\npci_write_config_byte(pdev, 0x80, 0x40);\r\nudelay(160);\r\npci_read_config_byte(pdev, 0x00, &bval);\r\nif (bval == 0x22)\r\nwval |= 1;\r\n}\r\nreturn wval;\r\n}\r\nstatic void dc390_read_eeprom(struct pci_dev *pdev, u16 *ptr)\r\n{\r\nu8 cmd = DC390_EEPROM_READ, i;\r\nfor (i = 0; i < DC390_EEPROM_LEN; i++) {\r\npci_write_config_byte(pdev, 0xc0, 0);\r\nudelay(160);\r\ndc390_eeprom_prepare_read(pdev, cmd++);\r\n*ptr++ = dc390_eeprom_get_data(pdev);\r\npci_write_config_byte(pdev, 0x80, 0);\r\npci_write_config_byte(pdev, 0x80, 0);\r\nudelay(160);\r\n}\r\n}\r\nstatic void dc390_check_eeprom(struct esp *esp)\r\n{\r\nu8 EEbuf[128];\r\nu16 *ptr = (u16 *)EEbuf, wval = 0;\r\nint i;\r\ndc390_read_eeprom((struct pci_dev *)esp->dev, ptr);\r\nfor (i = 0; i < DC390_EEPROM_LEN; i++, ptr++)\r\nwval += *ptr;\r\nif (wval != 0x1234) {\r\nstruct pci_dev *pdev = esp->dev;\r\ndev_printk(KERN_INFO, &pdev->dev,\r\n"No valid Tekram EEprom found\n");\r\nreturn;\r\n}\r\nesp->scsi_id = EEbuf[DC390_EE_ADAPT_SCSI_ID];\r\nesp->num_tags = 2 << EEbuf[DC390_EE_TAG_CMD_NUM];\r\nif (EEbuf[DC390_EE_MODE2] & DC390_EE_MODE2_ACTIVE_NEGATION)\r\nesp->config4 |= ESP_CONFIG4_RADE | ESP_CONFIG4_RAE;\r\n}\r\nstatic int pci_esp_probe_one(struct pci_dev *pdev,\r\nconst struct pci_device_id *id)\r\n{\r\nstruct scsi_host_template *hostt = &scsi_esp_template;\r\nint err = -ENODEV;\r\nstruct Scsi_Host *shost;\r\nstruct esp *esp;\r\nstruct pci_esp_priv *pep;\r\nif (pci_enable_device(pdev)) {\r\ndev_printk(KERN_INFO, &pdev->dev, "cannot enable device\n");\r\nreturn -ENODEV;\r\n}\r\nif (pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) {\r\ndev_printk(KERN_INFO, &pdev->dev,\r\n"failed to set 32bit DMA mask\n");\r\ngoto fail_disable_device;\r\n}\r\nshost = scsi_host_alloc(hostt, sizeof(struct esp));\r\nif (!shost) {\r\ndev_printk(KERN_INFO, &pdev->dev,\r\n"failed to allocate scsi host\n");\r\nerr = -ENOMEM;\r\ngoto fail_disable_device;\r\n}\r\npep = kzalloc(sizeof(struct pci_esp_priv), GFP_KERNEL);\r\nif (!pep) {\r\ndev_printk(KERN_INFO, &pdev->dev,\r\n"failed to allocate esp_priv\n");\r\nerr = -ENOMEM;\r\ngoto fail_host_alloc;\r\n}\r\nesp = shost_priv(shost);\r\nesp->host = shost;\r\nesp->dev = pdev;\r\nesp->ops = &pci_esp_ops;\r\nesp->flags |= ESP_FLAG_USE_FIFO;\r\nif (am53c974_fenab)\r\nesp->config2 |= ESP_CONFIG2_FENAB;\r\npep->esp = esp;\r\nif (pci_request_regions(pdev, DRV_MODULE_NAME)) {\r\ndev_printk(KERN_ERR, &pdev->dev,\r\n"pci memory selection failed\n");\r\ngoto fail_priv_alloc;\r\n}\r\nesp->regs = pci_iomap(pdev, 0, pci_resource_len(pdev, 0));\r\nif (!esp->regs) {\r\ndev_printk(KERN_ERR, &pdev->dev, "pci I/O map failed\n");\r\nerr = -EINVAL;\r\ngoto fail_release_regions;\r\n}\r\nesp->dma_regs = esp->regs;\r\npci_set_master(pdev);\r\nesp->command_block = pci_alloc_consistent(pdev, 16,\r\n&esp->command_block_dma);\r\nif (!esp->command_block) {\r\ndev_printk(KERN_ERR, &pdev->dev,\r\n"failed to allocate command block\n");\r\nerr = -ENOMEM;\r\ngoto fail_unmap_regs;\r\n}\r\npci_set_drvdata(pdev, pep);\r\nerr = request_irq(pdev->irq, scsi_esp_intr, IRQF_SHARED,\r\nDRV_MODULE_NAME, esp);\r\nif (err < 0) {\r\ndev_printk(KERN_ERR, &pdev->dev, "failed to register IRQ\n");\r\ngoto fail_unmap_command_block;\r\n}\r\nesp->scsi_id = 7;\r\ndc390_check_eeprom(esp);\r\nshost->this_id = esp->scsi_id;\r\nshost->max_id = 8;\r\nshost->irq = pdev->irq;\r\nshost->io_port = pci_resource_start(pdev, 0);\r\nshost->n_io_port = pci_resource_len(pdev, 0);\r\nshost->unique_id = shost->io_port;\r\nesp->scsi_id_mask = (1 << esp->scsi_id);\r\nesp->cfreq = 40000000;\r\nerr = scsi_esp_register(esp, &pdev->dev);\r\nif (err)\r\ngoto fail_free_irq;\r\nreturn 0;\r\nfail_free_irq:\r\nfree_irq(pdev->irq, esp);\r\nfail_unmap_command_block:\r\npci_set_drvdata(pdev, NULL);\r\npci_free_consistent(pdev, 16, esp->command_block,\r\nesp->command_block_dma);\r\nfail_unmap_regs:\r\npci_iounmap(pdev, esp->regs);\r\nfail_release_regions:\r\npci_release_regions(pdev);\r\nfail_priv_alloc:\r\nkfree(pep);\r\nfail_host_alloc:\r\nscsi_host_put(shost);\r\nfail_disable_device:\r\npci_disable_device(pdev);\r\nreturn err;\r\n}\r\nstatic void pci_esp_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct pci_esp_priv *pep = pci_get_drvdata(pdev);\r\nstruct esp *esp = pep->esp;\r\nscsi_esp_unregister(esp);\r\nfree_irq(pdev->irq, esp);\r\npci_set_drvdata(pdev, NULL);\r\npci_free_consistent(pdev, 16, esp->command_block,\r\nesp->command_block_dma);\r\npci_iounmap(pdev, esp->regs);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\nkfree(pep);\r\nscsi_host_put(esp->host);\r\n}\r\nstatic int __init am53c974_module_init(void)\r\n{\r\nreturn pci_register_driver(&am53c974_driver);\r\n}\r\nstatic void __exit am53c974_module_exit(void)\r\n{\r\npci_unregister_driver(&am53c974_driver);\r\n}
