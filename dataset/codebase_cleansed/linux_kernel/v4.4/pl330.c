static inline bool _queue_empty(struct pl330_thread *thrd)\r\n{\r\nreturn thrd->req[0].desc == NULL && thrd->req[1].desc == NULL;\r\n}\r\nstatic inline bool _queue_full(struct pl330_thread *thrd)\r\n{\r\nreturn thrd->req[0].desc != NULL && thrd->req[1].desc != NULL;\r\n}\r\nstatic inline bool is_manager(struct pl330_thread *thrd)\r\n{\r\nreturn thrd->dmac->manager == thrd;\r\n}\r\nstatic inline bool _manager_ns(struct pl330_thread *thrd)\r\n{\r\nreturn (thrd->dmac->pcfg.mode & DMAC_MODE_NS) ? true : false;\r\n}\r\nstatic inline u32 get_revision(u32 periph_id)\r\n{\r\nreturn (periph_id >> PERIPH_REV_SHIFT) & PERIPH_REV_MASK;\r\n}\r\nstatic inline u32 _emit_ADDH(unsigned dry_run, u8 buf[],\r\nenum pl330_dst da, u16 val)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAADDH;\r\nbuf[0] = CMD_DMAADDH;\r\nbuf[0] |= (da << 1);\r\n*((__le16 *)&buf[1]) = cpu_to_le16(val);\r\nPL330_DBGCMD_DUMP(SZ_DMAADDH, "\tDMAADDH %s %u\n",\r\nda == 1 ? "DA" : "SA", val);\r\nreturn SZ_DMAADDH;\r\n}\r\nstatic inline u32 _emit_END(unsigned dry_run, u8 buf[])\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAEND;\r\nbuf[0] = CMD_DMAEND;\r\nPL330_DBGCMD_DUMP(SZ_DMAEND, "\tDMAEND\n");\r\nreturn SZ_DMAEND;\r\n}\r\nstatic inline u32 _emit_FLUSHP(unsigned dry_run, u8 buf[], u8 peri)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAFLUSHP;\r\nbuf[0] = CMD_DMAFLUSHP;\r\nperi &= 0x1f;\r\nperi <<= 3;\r\nbuf[1] = peri;\r\nPL330_DBGCMD_DUMP(SZ_DMAFLUSHP, "\tDMAFLUSHP %u\n", peri >> 3);\r\nreturn SZ_DMAFLUSHP;\r\n}\r\nstatic inline u32 _emit_LD(unsigned dry_run, u8 buf[], enum pl330_cond cond)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMALD;\r\nbuf[0] = CMD_DMALD;\r\nif (cond == SINGLE)\r\nbuf[0] |= (0 << 1) | (1 << 0);\r\nelse if (cond == BURST)\r\nbuf[0] |= (1 << 1) | (1 << 0);\r\nPL330_DBGCMD_DUMP(SZ_DMALD, "\tDMALD%c\n",\r\ncond == SINGLE ? 'S' : (cond == BURST ? 'B' : 'A'));\r\nreturn SZ_DMALD;\r\n}\r\nstatic inline u32 _emit_LDP(unsigned dry_run, u8 buf[],\r\nenum pl330_cond cond, u8 peri)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMALDP;\r\nbuf[0] = CMD_DMALDP;\r\nif (cond == BURST)\r\nbuf[0] |= (1 << 1);\r\nperi &= 0x1f;\r\nperi <<= 3;\r\nbuf[1] = peri;\r\nPL330_DBGCMD_DUMP(SZ_DMALDP, "\tDMALDP%c %u\n",\r\ncond == SINGLE ? 'S' : 'B', peri >> 3);\r\nreturn SZ_DMALDP;\r\n}\r\nstatic inline u32 _emit_LP(unsigned dry_run, u8 buf[],\r\nunsigned loop, u8 cnt)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMALP;\r\nbuf[0] = CMD_DMALP;\r\nif (loop)\r\nbuf[0] |= (1 << 1);\r\ncnt--;\r\nbuf[1] = cnt;\r\nPL330_DBGCMD_DUMP(SZ_DMALP, "\tDMALP_%c %u\n", loop ? '1' : '0', cnt);\r\nreturn SZ_DMALP;\r\n}\r\nstatic inline u32 _emit_LPEND(unsigned dry_run, u8 buf[],\r\nconst struct _arg_LPEND *arg)\r\n{\r\nenum pl330_cond cond = arg->cond;\r\nbool forever = arg->forever;\r\nunsigned loop = arg->loop;\r\nu8 bjump = arg->bjump;\r\nif (dry_run)\r\nreturn SZ_DMALPEND;\r\nbuf[0] = CMD_DMALPEND;\r\nif (loop)\r\nbuf[0] |= (1 << 2);\r\nif (!forever)\r\nbuf[0] |= (1 << 4);\r\nif (cond == SINGLE)\r\nbuf[0] |= (0 << 1) | (1 << 0);\r\nelse if (cond == BURST)\r\nbuf[0] |= (1 << 1) | (1 << 0);\r\nbuf[1] = bjump;\r\nPL330_DBGCMD_DUMP(SZ_DMALPEND, "\tDMALP%s%c_%c bjmpto_%x\n",\r\nforever ? "FE" : "END",\r\ncond == SINGLE ? 'S' : (cond == BURST ? 'B' : 'A'),\r\nloop ? '1' : '0',\r\nbjump);\r\nreturn SZ_DMALPEND;\r\n}\r\nstatic inline u32 _emit_KILL(unsigned dry_run, u8 buf[])\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAKILL;\r\nbuf[0] = CMD_DMAKILL;\r\nreturn SZ_DMAKILL;\r\n}\r\nstatic inline u32 _emit_MOV(unsigned dry_run, u8 buf[],\r\nenum dmamov_dst dst, u32 val)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAMOV;\r\nbuf[0] = CMD_DMAMOV;\r\nbuf[1] = dst;\r\n*((__le32 *)&buf[2]) = cpu_to_le32(val);\r\nPL330_DBGCMD_DUMP(SZ_DMAMOV, "\tDMAMOV %s 0x%x\n",\r\ndst == SAR ? "SAR" : (dst == DAR ? "DAR" : "CCR"), val);\r\nreturn SZ_DMAMOV;\r\n}\r\nstatic inline u32 _emit_NOP(unsigned dry_run, u8 buf[])\r\n{\r\nif (dry_run)\r\nreturn SZ_DMANOP;\r\nbuf[0] = CMD_DMANOP;\r\nPL330_DBGCMD_DUMP(SZ_DMANOP, "\tDMANOP\n");\r\nreturn SZ_DMANOP;\r\n}\r\nstatic inline u32 _emit_RMB(unsigned dry_run, u8 buf[])\r\n{\r\nif (dry_run)\r\nreturn SZ_DMARMB;\r\nbuf[0] = CMD_DMARMB;\r\nPL330_DBGCMD_DUMP(SZ_DMARMB, "\tDMARMB\n");\r\nreturn SZ_DMARMB;\r\n}\r\nstatic inline u32 _emit_SEV(unsigned dry_run, u8 buf[], u8 ev)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMASEV;\r\nbuf[0] = CMD_DMASEV;\r\nev &= 0x1f;\r\nev <<= 3;\r\nbuf[1] = ev;\r\nPL330_DBGCMD_DUMP(SZ_DMASEV, "\tDMASEV %u\n", ev >> 3);\r\nreturn SZ_DMASEV;\r\n}\r\nstatic inline u32 _emit_ST(unsigned dry_run, u8 buf[], enum pl330_cond cond)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAST;\r\nbuf[0] = CMD_DMAST;\r\nif (cond == SINGLE)\r\nbuf[0] |= (0 << 1) | (1 << 0);\r\nelse if (cond == BURST)\r\nbuf[0] |= (1 << 1) | (1 << 0);\r\nPL330_DBGCMD_DUMP(SZ_DMAST, "\tDMAST%c\n",\r\ncond == SINGLE ? 'S' : (cond == BURST ? 'B' : 'A'));\r\nreturn SZ_DMAST;\r\n}\r\nstatic inline u32 _emit_STP(unsigned dry_run, u8 buf[],\r\nenum pl330_cond cond, u8 peri)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMASTP;\r\nbuf[0] = CMD_DMASTP;\r\nif (cond == BURST)\r\nbuf[0] |= (1 << 1);\r\nperi &= 0x1f;\r\nperi <<= 3;\r\nbuf[1] = peri;\r\nPL330_DBGCMD_DUMP(SZ_DMASTP, "\tDMASTP%c %u\n",\r\ncond == SINGLE ? 'S' : 'B', peri >> 3);\r\nreturn SZ_DMASTP;\r\n}\r\nstatic inline u32 _emit_STZ(unsigned dry_run, u8 buf[])\r\n{\r\nif (dry_run)\r\nreturn SZ_DMASTZ;\r\nbuf[0] = CMD_DMASTZ;\r\nPL330_DBGCMD_DUMP(SZ_DMASTZ, "\tDMASTZ\n");\r\nreturn SZ_DMASTZ;\r\n}\r\nstatic inline u32 _emit_WFE(unsigned dry_run, u8 buf[], u8 ev,\r\nunsigned invalidate)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAWFE;\r\nbuf[0] = CMD_DMAWFE;\r\nev &= 0x1f;\r\nev <<= 3;\r\nbuf[1] = ev;\r\nif (invalidate)\r\nbuf[1] |= (1 << 1);\r\nPL330_DBGCMD_DUMP(SZ_DMAWFE, "\tDMAWFE %u%s\n",\r\nev >> 3, invalidate ? ", I" : "");\r\nreturn SZ_DMAWFE;\r\n}\r\nstatic inline u32 _emit_WFP(unsigned dry_run, u8 buf[],\r\nenum pl330_cond cond, u8 peri)\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAWFP;\r\nbuf[0] = CMD_DMAWFP;\r\nif (cond == SINGLE)\r\nbuf[0] |= (0 << 1) | (0 << 0);\r\nelse if (cond == BURST)\r\nbuf[0] |= (1 << 1) | (0 << 0);\r\nelse\r\nbuf[0] |= (0 << 1) | (1 << 0);\r\nperi &= 0x1f;\r\nperi <<= 3;\r\nbuf[1] = peri;\r\nPL330_DBGCMD_DUMP(SZ_DMAWFP, "\tDMAWFP%c %u\n",\r\ncond == SINGLE ? 'S' : (cond == BURST ? 'B' : 'P'), peri >> 3);\r\nreturn SZ_DMAWFP;\r\n}\r\nstatic inline u32 _emit_WMB(unsigned dry_run, u8 buf[])\r\n{\r\nif (dry_run)\r\nreturn SZ_DMAWMB;\r\nbuf[0] = CMD_DMAWMB;\r\nPL330_DBGCMD_DUMP(SZ_DMAWMB, "\tDMAWMB\n");\r\nreturn SZ_DMAWMB;\r\n}\r\nstatic inline u32 _emit_GO(unsigned dry_run, u8 buf[],\r\nconst struct _arg_GO *arg)\r\n{\r\nu8 chan = arg->chan;\r\nu32 addr = arg->addr;\r\nunsigned ns = arg->ns;\r\nif (dry_run)\r\nreturn SZ_DMAGO;\r\nbuf[0] = CMD_DMAGO;\r\nbuf[0] |= (ns << 1);\r\nbuf[1] = chan & 0x7;\r\n*((__le32 *)&buf[2]) = cpu_to_le32(addr);\r\nreturn SZ_DMAGO;\r\n}\r\nstatic bool _until_dmac_idle(struct pl330_thread *thrd)\r\n{\r\nvoid __iomem *regs = thrd->dmac->base;\r\nunsigned long loops = msecs_to_loops(5);\r\ndo {\r\nif (!(readl(regs + DBGSTATUS) & DBG_BUSY))\r\nbreak;\r\ncpu_relax();\r\n} while (--loops);\r\nif (!loops)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic inline void _execute_DBGINSN(struct pl330_thread *thrd,\r\nu8 insn[], bool as_manager)\r\n{\r\nvoid __iomem *regs = thrd->dmac->base;\r\nu32 val;\r\nval = (insn[0] << 16) | (insn[1] << 24);\r\nif (!as_manager) {\r\nval |= (1 << 0);\r\nval |= (thrd->id << 8);\r\n}\r\nwritel(val, regs + DBGINST0);\r\nval = le32_to_cpu(*((__le32 *)&insn[2]));\r\nwritel(val, regs + DBGINST1);\r\nif (_until_dmac_idle(thrd)) {\r\ndev_err(thrd->dmac->ddma.dev, "DMAC halted!\n");\r\nreturn;\r\n}\r\nwritel(0, regs + DBGCMD);\r\n}\r\nstatic inline u32 _state(struct pl330_thread *thrd)\r\n{\r\nvoid __iomem *regs = thrd->dmac->base;\r\nu32 val;\r\nif (is_manager(thrd))\r\nval = readl(regs + DS) & 0xf;\r\nelse\r\nval = readl(regs + CS(thrd->id)) & 0xf;\r\nswitch (val) {\r\ncase DS_ST_STOP:\r\nreturn PL330_STATE_STOPPED;\r\ncase DS_ST_EXEC:\r\nreturn PL330_STATE_EXECUTING;\r\ncase DS_ST_CMISS:\r\nreturn PL330_STATE_CACHEMISS;\r\ncase DS_ST_UPDTPC:\r\nreturn PL330_STATE_UPDTPC;\r\ncase DS_ST_WFE:\r\nreturn PL330_STATE_WFE;\r\ncase DS_ST_FAULT:\r\nreturn PL330_STATE_FAULTING;\r\ncase DS_ST_ATBRR:\r\nif (is_manager(thrd))\r\nreturn PL330_STATE_INVALID;\r\nelse\r\nreturn PL330_STATE_ATBARRIER;\r\ncase DS_ST_QBUSY:\r\nif (is_manager(thrd))\r\nreturn PL330_STATE_INVALID;\r\nelse\r\nreturn PL330_STATE_QUEUEBUSY;\r\ncase DS_ST_WFP:\r\nif (is_manager(thrd))\r\nreturn PL330_STATE_INVALID;\r\nelse\r\nreturn PL330_STATE_WFP;\r\ncase DS_ST_KILL:\r\nif (is_manager(thrd))\r\nreturn PL330_STATE_INVALID;\r\nelse\r\nreturn PL330_STATE_KILLING;\r\ncase DS_ST_CMPLT:\r\nif (is_manager(thrd))\r\nreturn PL330_STATE_INVALID;\r\nelse\r\nreturn PL330_STATE_COMPLETING;\r\ncase DS_ST_FLTCMP:\r\nif (is_manager(thrd))\r\nreturn PL330_STATE_INVALID;\r\nelse\r\nreturn PL330_STATE_FAULT_COMPLETING;\r\ndefault:\r\nreturn PL330_STATE_INVALID;\r\n}\r\n}\r\nstatic void _stop(struct pl330_thread *thrd)\r\n{\r\nvoid __iomem *regs = thrd->dmac->base;\r\nu8 insn[6] = {0, 0, 0, 0, 0, 0};\r\nif (_state(thrd) == PL330_STATE_FAULT_COMPLETING)\r\nUNTIL(thrd, PL330_STATE_FAULTING | PL330_STATE_KILLING);\r\nif (_state(thrd) == PL330_STATE_COMPLETING\r\n|| _state(thrd) == PL330_STATE_KILLING\r\n|| _state(thrd) == PL330_STATE_STOPPED)\r\nreturn;\r\n_emit_KILL(0, insn);\r\nwritel(readl(regs + INTEN) & ~(1 << thrd->ev), regs + INTEN);\r\n_execute_DBGINSN(thrd, insn, is_manager(thrd));\r\n}\r\nstatic bool _trigger(struct pl330_thread *thrd)\r\n{\r\nvoid __iomem *regs = thrd->dmac->base;\r\nstruct _pl330_req *req;\r\nstruct dma_pl330_desc *desc;\r\nstruct _arg_GO go;\r\nunsigned ns;\r\nu8 insn[6] = {0, 0, 0, 0, 0, 0};\r\nint idx;\r\nif (_state(thrd) != PL330_STATE_STOPPED)\r\nreturn true;\r\nidx = 1 - thrd->lstenq;\r\nif (thrd->req[idx].desc != NULL) {\r\nreq = &thrd->req[idx];\r\n} else {\r\nidx = thrd->lstenq;\r\nif (thrd->req[idx].desc != NULL)\r\nreq = &thrd->req[idx];\r\nelse\r\nreq = NULL;\r\n}\r\nif (!req)\r\nreturn true;\r\nif (idx == thrd->req_running)\r\nreturn true;\r\ndesc = req->desc;\r\nns = desc->rqcfg.nonsecure ? 1 : 0;\r\nif (_manager_ns(thrd) && !ns)\r\ndev_info(thrd->dmac->ddma.dev, "%s:%d Recipe for ABORT!\n",\r\n__func__, __LINE__);\r\ngo.chan = thrd->id;\r\ngo.addr = req->mc_bus;\r\ngo.ns = ns;\r\n_emit_GO(0, insn, &go);\r\nwritel(readl(regs + INTEN) | (1 << thrd->ev), regs + INTEN);\r\n_execute_DBGINSN(thrd, insn, true);\r\nthrd->req_running = idx;\r\nreturn true;\r\n}\r\nstatic bool _start(struct pl330_thread *thrd)\r\n{\r\nswitch (_state(thrd)) {\r\ncase PL330_STATE_FAULT_COMPLETING:\r\nUNTIL(thrd, PL330_STATE_FAULTING | PL330_STATE_KILLING);\r\nif (_state(thrd) == PL330_STATE_KILLING)\r\nUNTIL(thrd, PL330_STATE_STOPPED)\r\ncase PL330_STATE_FAULTING:\r\n_stop(thrd);\r\ncase PL330_STATE_KILLING:\r\ncase PL330_STATE_COMPLETING:\r\nUNTIL(thrd, PL330_STATE_STOPPED)\r\ncase PL330_STATE_STOPPED:\r\nreturn _trigger(thrd);\r\ncase PL330_STATE_WFP:\r\ncase PL330_STATE_QUEUEBUSY:\r\ncase PL330_STATE_ATBARRIER:\r\ncase PL330_STATE_UPDTPC:\r\ncase PL330_STATE_CACHEMISS:\r\ncase PL330_STATE_EXECUTING:\r\nreturn true;\r\ncase PL330_STATE_WFE:\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nstatic inline int _ldst_memtomem(unsigned dry_run, u8 buf[],\r\nconst struct _xfer_spec *pxs, int cyc)\r\n{\r\nint off = 0;\r\nstruct pl330_config *pcfg = pxs->desc->rqcfg.pcfg;\r\nif (get_revision(pcfg->periph_id) >= PERIPH_REV_R1P0) {\r\nwhile (cyc--) {\r\noff += _emit_LD(dry_run, &buf[off], ALWAYS);\r\noff += _emit_ST(dry_run, &buf[off], ALWAYS);\r\n}\r\n} else {\r\nwhile (cyc--) {\r\noff += _emit_LD(dry_run, &buf[off], ALWAYS);\r\noff += _emit_RMB(dry_run, &buf[off]);\r\noff += _emit_ST(dry_run, &buf[off], ALWAYS);\r\noff += _emit_WMB(dry_run, &buf[off]);\r\n}\r\n}\r\nreturn off;\r\n}\r\nstatic inline int _ldst_devtomem(unsigned dry_run, u8 buf[],\r\nconst struct _xfer_spec *pxs, int cyc)\r\n{\r\nint off = 0;\r\nwhile (cyc--) {\r\noff += _emit_WFP(dry_run, &buf[off], SINGLE, pxs->desc->peri);\r\noff += _emit_LDP(dry_run, &buf[off], SINGLE, pxs->desc->peri);\r\noff += _emit_ST(dry_run, &buf[off], ALWAYS);\r\noff += _emit_FLUSHP(dry_run, &buf[off], pxs->desc->peri);\r\n}\r\nreturn off;\r\n}\r\nstatic inline int _ldst_memtodev(unsigned dry_run, u8 buf[],\r\nconst struct _xfer_spec *pxs, int cyc)\r\n{\r\nint off = 0;\r\nwhile (cyc--) {\r\noff += _emit_WFP(dry_run, &buf[off], SINGLE, pxs->desc->peri);\r\noff += _emit_LD(dry_run, &buf[off], ALWAYS);\r\noff += _emit_STP(dry_run, &buf[off], SINGLE, pxs->desc->peri);\r\noff += _emit_FLUSHP(dry_run, &buf[off], pxs->desc->peri);\r\n}\r\nreturn off;\r\n}\r\nstatic int _bursts(unsigned dry_run, u8 buf[],\r\nconst struct _xfer_spec *pxs, int cyc)\r\n{\r\nint off = 0;\r\nswitch (pxs->desc->rqtype) {\r\ncase DMA_MEM_TO_DEV:\r\noff += _ldst_memtodev(dry_run, &buf[off], pxs, cyc);\r\nbreak;\r\ncase DMA_DEV_TO_MEM:\r\noff += _ldst_devtomem(dry_run, &buf[off], pxs, cyc);\r\nbreak;\r\ncase DMA_MEM_TO_MEM:\r\noff += _ldst_memtomem(dry_run, &buf[off], pxs, cyc);\r\nbreak;\r\ndefault:\r\noff += 0x40000000;\r\nbreak;\r\n}\r\nreturn off;\r\n}\r\nstatic inline int _loop(unsigned dry_run, u8 buf[],\r\nunsigned long *bursts, const struct _xfer_spec *pxs)\r\n{\r\nint cyc, cycmax, szlp, szlpend, szbrst, off;\r\nunsigned lcnt0, lcnt1, ljmp0, ljmp1;\r\nstruct _arg_LPEND lpend;\r\nif (*bursts == 1)\r\nreturn _bursts(dry_run, buf, pxs, 1);\r\nif (*bursts >= 256*256) {\r\nlcnt1 = 256;\r\nlcnt0 = 256;\r\ncyc = *bursts / lcnt1 / lcnt0;\r\n} else if (*bursts > 256) {\r\nlcnt1 = 256;\r\nlcnt0 = *bursts / lcnt1;\r\ncyc = 1;\r\n} else {\r\nlcnt1 = *bursts;\r\nlcnt0 = 0;\r\ncyc = 1;\r\n}\r\nszlp = _emit_LP(1, buf, 0, 0);\r\nszbrst = _bursts(1, buf, pxs, 1);\r\nlpend.cond = ALWAYS;\r\nlpend.forever = false;\r\nlpend.loop = 0;\r\nlpend.bjump = 0;\r\nszlpend = _emit_LPEND(1, buf, &lpend);\r\nif (lcnt0) {\r\nszlp *= 2;\r\nszlpend *= 2;\r\n}\r\ncycmax = (255 - (szlp + szlpend)) / szbrst;\r\ncyc = (cycmax < cyc) ? cycmax : cyc;\r\noff = 0;\r\nif (lcnt0) {\r\noff += _emit_LP(dry_run, &buf[off], 0, lcnt0);\r\nljmp0 = off;\r\n}\r\noff += _emit_LP(dry_run, &buf[off], 1, lcnt1);\r\nljmp1 = off;\r\noff += _bursts(dry_run, &buf[off], pxs, cyc);\r\nlpend.cond = ALWAYS;\r\nlpend.forever = false;\r\nlpend.loop = 1;\r\nlpend.bjump = off - ljmp1;\r\noff += _emit_LPEND(dry_run, &buf[off], &lpend);\r\nif (lcnt0) {\r\nlpend.cond = ALWAYS;\r\nlpend.forever = false;\r\nlpend.loop = 0;\r\nlpend.bjump = off - ljmp0;\r\noff += _emit_LPEND(dry_run, &buf[off], &lpend);\r\n}\r\n*bursts = lcnt1 * cyc;\r\nif (lcnt0)\r\n*bursts *= lcnt0;\r\nreturn off;\r\n}\r\nstatic inline int _setup_loops(unsigned dry_run, u8 buf[],\r\nconst struct _xfer_spec *pxs)\r\n{\r\nstruct pl330_xfer *x = &pxs->desc->px;\r\nu32 ccr = pxs->ccr;\r\nunsigned long c, bursts = BYTE_TO_BURST(x->bytes, ccr);\r\nint off = 0;\r\nwhile (bursts) {\r\nc = bursts;\r\noff += _loop(dry_run, &buf[off], &c, pxs);\r\nbursts -= c;\r\n}\r\nreturn off;\r\n}\r\nstatic inline int _setup_xfer(unsigned dry_run, u8 buf[],\r\nconst struct _xfer_spec *pxs)\r\n{\r\nstruct pl330_xfer *x = &pxs->desc->px;\r\nint off = 0;\r\noff += _emit_MOV(dry_run, &buf[off], SAR, x->src_addr);\r\noff += _emit_MOV(dry_run, &buf[off], DAR, x->dst_addr);\r\noff += _setup_loops(dry_run, &buf[off], pxs);\r\nreturn off;\r\n}\r\nstatic int _setup_req(unsigned dry_run, struct pl330_thread *thrd,\r\nunsigned index, struct _xfer_spec *pxs)\r\n{\r\nstruct _pl330_req *req = &thrd->req[index];\r\nstruct pl330_xfer *x;\r\nu8 *buf = req->mc_cpu;\r\nint off = 0;\r\nPL330_DBGMC_START(req->mc_bus);\r\noff += _emit_MOV(dry_run, &buf[off], CCR, pxs->ccr);\r\nx = &pxs->desc->px;\r\nif (x->bytes % (BRST_SIZE(pxs->ccr) * BRST_LEN(pxs->ccr)))\r\nreturn -EINVAL;\r\noff += _setup_xfer(dry_run, &buf[off], pxs);\r\noff += _emit_SEV(dry_run, &buf[off], thrd->ev);\r\noff += _emit_END(dry_run, &buf[off]);\r\nreturn off;\r\n}\r\nstatic inline u32 _prepare_ccr(const struct pl330_reqcfg *rqc)\r\n{\r\nu32 ccr = 0;\r\nif (rqc->src_inc)\r\nccr |= CC_SRCINC;\r\nif (rqc->dst_inc)\r\nccr |= CC_DSTINC;\r\nif (rqc->privileged)\r\nccr |= CC_SRCPRI | CC_DSTPRI;\r\nif (rqc->nonsecure)\r\nccr |= CC_SRCNS | CC_DSTNS;\r\nif (rqc->insnaccess)\r\nccr |= CC_SRCIA | CC_DSTIA;\r\nccr |= (((rqc->brst_len - 1) & 0xf) << CC_SRCBRSTLEN_SHFT);\r\nccr |= (((rqc->brst_len - 1) & 0xf) << CC_DSTBRSTLEN_SHFT);\r\nccr |= (rqc->brst_size << CC_SRCBRSTSIZE_SHFT);\r\nccr |= (rqc->brst_size << CC_DSTBRSTSIZE_SHFT);\r\nccr |= (rqc->scctl << CC_SRCCCTRL_SHFT);\r\nccr |= (rqc->dcctl << CC_DSTCCTRL_SHFT);\r\nccr |= (rqc->swap << CC_SWAP_SHFT);\r\nreturn ccr;\r\n}\r\nstatic int pl330_submit_req(struct pl330_thread *thrd,\r\nstruct dma_pl330_desc *desc)\r\n{\r\nstruct pl330_dmac *pl330 = thrd->dmac;\r\nstruct _xfer_spec xs;\r\nunsigned long flags;\r\nunsigned idx;\r\nu32 ccr;\r\nint ret = 0;\r\nif (pl330->state == DYING\r\n|| pl330->dmac_tbd.reset_chan & (1 << thrd->id)) {\r\ndev_info(thrd->dmac->ddma.dev, "%s:%d\n",\r\n__func__, __LINE__);\r\nreturn -EAGAIN;\r\n}\r\nif (desc->rqtype != DMA_MEM_TO_MEM &&\r\ndesc->peri >= pl330->pcfg.num_peri) {\r\ndev_info(thrd->dmac->ddma.dev,\r\n"%s:%d Invalid peripheral(%u)!\n",\r\n__func__, __LINE__, desc->peri);\r\nreturn -EINVAL;\r\n}\r\nspin_lock_irqsave(&pl330->lock, flags);\r\nif (_queue_full(thrd)) {\r\nret = -EAGAIN;\r\ngoto xfer_exit;\r\n}\r\nif (!_manager_ns(thrd))\r\ndesc->rqcfg.nonsecure = 0;\r\nelse\r\ndesc->rqcfg.nonsecure = 1;\r\nccr = _prepare_ccr(&desc->rqcfg);\r\nidx = thrd->req[0].desc == NULL ? 0 : 1;\r\nxs.ccr = ccr;\r\nxs.desc = desc;\r\nret = _setup_req(1, thrd, idx, &xs);\r\nif (ret < 0)\r\ngoto xfer_exit;\r\nif (ret > pl330->mcbufsz / 2) {\r\ndev_info(pl330->ddma.dev, "%s:%d Try increasing mcbufsz (%i/%i)\n",\r\n__func__, __LINE__, ret, pl330->mcbufsz / 2);\r\nret = -ENOMEM;\r\ngoto xfer_exit;\r\n}\r\nthrd->lstenq = idx;\r\nthrd->req[idx].desc = desc;\r\n_setup_req(0, thrd, idx, &xs);\r\nret = 0;\r\nxfer_exit:\r\nspin_unlock_irqrestore(&pl330->lock, flags);\r\nreturn ret;\r\n}\r\nstatic void dma_pl330_rqcb(struct dma_pl330_desc *desc, enum pl330_op_err err)\r\n{\r\nstruct dma_pl330_chan *pch;\r\nunsigned long flags;\r\nif (!desc)\r\nreturn;\r\npch = desc->pchan;\r\nif (!pch)\r\nreturn;\r\nspin_lock_irqsave(&pch->lock, flags);\r\ndesc->status = DONE;\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\ntasklet_schedule(&pch->task);\r\n}\r\nstatic void pl330_dotask(unsigned long data)\r\n{\r\nstruct pl330_dmac *pl330 = (struct pl330_dmac *) data;\r\nunsigned long flags;\r\nint i;\r\nspin_lock_irqsave(&pl330->lock, flags);\r\nif (pl330->dmac_tbd.reset_dmac) {\r\npl330->state = DYING;\r\npl330->dmac_tbd.reset_mngr = true;\r\npl330->dmac_tbd.reset_dmac = false;\r\n}\r\nif (pl330->dmac_tbd.reset_mngr) {\r\n_stop(pl330->manager);\r\npl330->dmac_tbd.reset_chan = (1 << pl330->pcfg.num_chan) - 1;\r\npl330->dmac_tbd.reset_mngr = false;\r\n}\r\nfor (i = 0; i < pl330->pcfg.num_chan; i++) {\r\nif (pl330->dmac_tbd.reset_chan & (1 << i)) {\r\nstruct pl330_thread *thrd = &pl330->channels[i];\r\nvoid __iomem *regs = pl330->base;\r\nenum pl330_op_err err;\r\n_stop(thrd);\r\nif (readl(regs + FSC) & (1 << thrd->id))\r\nerr = PL330_ERR_FAIL;\r\nelse\r\nerr = PL330_ERR_ABORT;\r\nspin_unlock_irqrestore(&pl330->lock, flags);\r\ndma_pl330_rqcb(thrd->req[1 - thrd->lstenq].desc, err);\r\ndma_pl330_rqcb(thrd->req[thrd->lstenq].desc, err);\r\nspin_lock_irqsave(&pl330->lock, flags);\r\nthrd->req[0].desc = NULL;\r\nthrd->req[1].desc = NULL;\r\nthrd->req_running = -1;\r\npl330->dmac_tbd.reset_chan &= ~(1 << i);\r\n}\r\n}\r\nspin_unlock_irqrestore(&pl330->lock, flags);\r\nreturn;\r\n}\r\nstatic int pl330_update(struct pl330_dmac *pl330)\r\n{\r\nstruct dma_pl330_desc *descdone, *tmp;\r\nunsigned long flags;\r\nvoid __iomem *regs;\r\nu32 val;\r\nint id, ev, ret = 0;\r\nregs = pl330->base;\r\nspin_lock_irqsave(&pl330->lock, flags);\r\nval = readl(regs + FSM) & 0x1;\r\nif (val)\r\npl330->dmac_tbd.reset_mngr = true;\r\nelse\r\npl330->dmac_tbd.reset_mngr = false;\r\nval = readl(regs + FSC) & ((1 << pl330->pcfg.num_chan) - 1);\r\npl330->dmac_tbd.reset_chan |= val;\r\nif (val) {\r\nint i = 0;\r\nwhile (i < pl330->pcfg.num_chan) {\r\nif (val & (1 << i)) {\r\ndev_info(pl330->ddma.dev,\r\n"Reset Channel-%d\t CS-%x FTC-%x\n",\r\ni, readl(regs + CS(i)),\r\nreadl(regs + FTC(i)));\r\n_stop(&pl330->channels[i]);\r\n}\r\ni++;\r\n}\r\n}\r\nval = readl(regs + ES);\r\nif (pl330->pcfg.num_events < 32\r\n&& val & ~((1 << pl330->pcfg.num_events) - 1)) {\r\npl330->dmac_tbd.reset_dmac = true;\r\ndev_err(pl330->ddma.dev, "%s:%d Unexpected!\n", __func__,\r\n__LINE__);\r\nret = 1;\r\ngoto updt_exit;\r\n}\r\nfor (ev = 0; ev < pl330->pcfg.num_events; ev++) {\r\nif (val & (1 << ev)) {\r\nstruct pl330_thread *thrd;\r\nu32 inten = readl(regs + INTEN);\r\nint active;\r\nif (inten & (1 << ev))\r\nwritel(1 << ev, regs + INTCLR);\r\nret = 1;\r\nid = pl330->events[ev];\r\nthrd = &pl330->channels[id];\r\nactive = thrd->req_running;\r\nif (active == -1)\r\ncontinue;\r\ndescdone = thrd->req[active].desc;\r\nthrd->req[active].desc = NULL;\r\nthrd->req_running = -1;\r\n_start(thrd);\r\nlist_add_tail(&descdone->rqd, &pl330->req_done);\r\n}\r\n}\r\nlist_for_each_entry_safe(descdone, tmp, &pl330->req_done, rqd) {\r\nlist_del(&descdone->rqd);\r\nspin_unlock_irqrestore(&pl330->lock, flags);\r\ndma_pl330_rqcb(descdone, PL330_ERR_NONE);\r\nspin_lock_irqsave(&pl330->lock, flags);\r\n}\r\nupdt_exit:\r\nspin_unlock_irqrestore(&pl330->lock, flags);\r\nif (pl330->dmac_tbd.reset_dmac\r\n|| pl330->dmac_tbd.reset_mngr\r\n|| pl330->dmac_tbd.reset_chan) {\r\nret = 1;\r\ntasklet_schedule(&pl330->tasks);\r\n}\r\nreturn ret;\r\n}\r\nstatic inline int _alloc_event(struct pl330_thread *thrd)\r\n{\r\nstruct pl330_dmac *pl330 = thrd->dmac;\r\nint ev;\r\nfor (ev = 0; ev < pl330->pcfg.num_events; ev++)\r\nif (pl330->events[ev] == -1) {\r\npl330->events[ev] = thrd->id;\r\nreturn ev;\r\n}\r\nreturn -1;\r\n}\r\nstatic bool _chan_ns(const struct pl330_dmac *pl330, int i)\r\n{\r\nreturn pl330->pcfg.irq_ns & (1 << i);\r\n}\r\nstatic struct pl330_thread *pl330_request_channel(struct pl330_dmac *pl330)\r\n{\r\nstruct pl330_thread *thrd = NULL;\r\nunsigned long flags;\r\nint chans, i;\r\nif (pl330->state == DYING)\r\nreturn NULL;\r\nchans = pl330->pcfg.num_chan;\r\nspin_lock_irqsave(&pl330->lock, flags);\r\nfor (i = 0; i < chans; i++) {\r\nthrd = &pl330->channels[i];\r\nif ((thrd->free) && (!_manager_ns(thrd) ||\r\n_chan_ns(pl330, i))) {\r\nthrd->ev = _alloc_event(thrd);\r\nif (thrd->ev >= 0) {\r\nthrd->free = false;\r\nthrd->lstenq = 1;\r\nthrd->req[0].desc = NULL;\r\nthrd->req[1].desc = NULL;\r\nthrd->req_running = -1;\r\nbreak;\r\n}\r\n}\r\nthrd = NULL;\r\n}\r\nspin_unlock_irqrestore(&pl330->lock, flags);\r\nreturn thrd;\r\n}\r\nstatic inline void _free_event(struct pl330_thread *thrd, int ev)\r\n{\r\nstruct pl330_dmac *pl330 = thrd->dmac;\r\nif (ev >= 0 && ev < pl330->pcfg.num_events\r\n&& pl330->events[ev] == thrd->id)\r\npl330->events[ev] = -1;\r\n}\r\nstatic void pl330_release_channel(struct pl330_thread *thrd)\r\n{\r\nstruct pl330_dmac *pl330;\r\nunsigned long flags;\r\nif (!thrd || thrd->free)\r\nreturn;\r\n_stop(thrd);\r\ndma_pl330_rqcb(thrd->req[1 - thrd->lstenq].desc, PL330_ERR_ABORT);\r\ndma_pl330_rqcb(thrd->req[thrd->lstenq].desc, PL330_ERR_ABORT);\r\npl330 = thrd->dmac;\r\nspin_lock_irqsave(&pl330->lock, flags);\r\n_free_event(thrd, thrd->ev);\r\nthrd->free = true;\r\nspin_unlock_irqrestore(&pl330->lock, flags);\r\n}\r\nstatic void read_dmac_config(struct pl330_dmac *pl330)\r\n{\r\nvoid __iomem *regs = pl330->base;\r\nu32 val;\r\nval = readl(regs + CRD) >> CRD_DATA_WIDTH_SHIFT;\r\nval &= CRD_DATA_WIDTH_MASK;\r\npl330->pcfg.data_bus_width = 8 * (1 << val);\r\nval = readl(regs + CRD) >> CRD_DATA_BUFF_SHIFT;\r\nval &= CRD_DATA_BUFF_MASK;\r\npl330->pcfg.data_buf_dep = val + 1;\r\nval = readl(regs + CR0) >> CR0_NUM_CHANS_SHIFT;\r\nval &= CR0_NUM_CHANS_MASK;\r\nval += 1;\r\npl330->pcfg.num_chan = val;\r\nval = readl(regs + CR0);\r\nif (val & CR0_PERIPH_REQ_SET) {\r\nval = (val >> CR0_NUM_PERIPH_SHIFT) & CR0_NUM_PERIPH_MASK;\r\nval += 1;\r\npl330->pcfg.num_peri = val;\r\npl330->pcfg.peri_ns = readl(regs + CR4);\r\n} else {\r\npl330->pcfg.num_peri = 0;\r\n}\r\nval = readl(regs + CR0);\r\nif (val & CR0_BOOT_MAN_NS)\r\npl330->pcfg.mode |= DMAC_MODE_NS;\r\nelse\r\npl330->pcfg.mode &= ~DMAC_MODE_NS;\r\nval = readl(regs + CR0) >> CR0_NUM_EVENTS_SHIFT;\r\nval &= CR0_NUM_EVENTS_MASK;\r\nval += 1;\r\npl330->pcfg.num_events = val;\r\npl330->pcfg.irq_ns = readl(regs + CR3);\r\n}\r\nstatic inline void _reset_thread(struct pl330_thread *thrd)\r\n{\r\nstruct pl330_dmac *pl330 = thrd->dmac;\r\nthrd->req[0].mc_cpu = pl330->mcode_cpu\r\n+ (thrd->id * pl330->mcbufsz);\r\nthrd->req[0].mc_bus = pl330->mcode_bus\r\n+ (thrd->id * pl330->mcbufsz);\r\nthrd->req[0].desc = NULL;\r\nthrd->req[1].mc_cpu = thrd->req[0].mc_cpu\r\n+ pl330->mcbufsz / 2;\r\nthrd->req[1].mc_bus = thrd->req[0].mc_bus\r\n+ pl330->mcbufsz / 2;\r\nthrd->req[1].desc = NULL;\r\nthrd->req_running = -1;\r\n}\r\nstatic int dmac_alloc_threads(struct pl330_dmac *pl330)\r\n{\r\nint chans = pl330->pcfg.num_chan;\r\nstruct pl330_thread *thrd;\r\nint i;\r\npl330->channels = kzalloc((1 + chans) * sizeof(*thrd),\r\nGFP_KERNEL);\r\nif (!pl330->channels)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < chans; i++) {\r\nthrd = &pl330->channels[i];\r\nthrd->id = i;\r\nthrd->dmac = pl330;\r\n_reset_thread(thrd);\r\nthrd->free = true;\r\n}\r\nthrd = &pl330->channels[chans];\r\nthrd->id = chans;\r\nthrd->dmac = pl330;\r\nthrd->free = false;\r\npl330->manager = thrd;\r\nreturn 0;\r\n}\r\nstatic int dmac_alloc_resources(struct pl330_dmac *pl330)\r\n{\r\nint chans = pl330->pcfg.num_chan;\r\nint ret;\r\npl330->mcode_cpu = dma_alloc_coherent(pl330->ddma.dev,\r\nchans * pl330->mcbufsz,\r\n&pl330->mcode_bus, GFP_KERNEL);\r\nif (!pl330->mcode_cpu) {\r\ndev_err(pl330->ddma.dev, "%s:%d Can't allocate memory!\n",\r\n__func__, __LINE__);\r\nreturn -ENOMEM;\r\n}\r\nret = dmac_alloc_threads(pl330);\r\nif (ret) {\r\ndev_err(pl330->ddma.dev, "%s:%d Can't to create channels for DMAC!\n",\r\n__func__, __LINE__);\r\ndma_free_coherent(pl330->ddma.dev,\r\nchans * pl330->mcbufsz,\r\npl330->mcode_cpu, pl330->mcode_bus);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int pl330_add(struct pl330_dmac *pl330)\r\n{\r\nvoid __iomem *regs;\r\nint i, ret;\r\nregs = pl330->base;\r\nif ((pl330->pcfg.periph_id & 0xfffff) != PERIPH_ID_VAL) {\r\ndev_err(pl330->ddma.dev, "PERIPH_ID 0x%x !\n",\r\npl330->pcfg.periph_id);\r\nreturn -EINVAL;\r\n}\r\nread_dmac_config(pl330);\r\nif (pl330->pcfg.num_events == 0) {\r\ndev_err(pl330->ddma.dev, "%s:%d Can't work without events!\n",\r\n__func__, __LINE__);\r\nreturn -EINVAL;\r\n}\r\nspin_lock_init(&pl330->lock);\r\nINIT_LIST_HEAD(&pl330->req_done);\r\nif (!pl330->mcbufsz)\r\npl330->mcbufsz = MCODE_BUFF_PER_REQ * 2;\r\nfor (i = 0; i < pl330->pcfg.num_events; i++)\r\npl330->events[i] = -1;\r\nret = dmac_alloc_resources(pl330);\r\nif (ret) {\r\ndev_err(pl330->ddma.dev, "Unable to create channels for DMAC\n");\r\nreturn ret;\r\n}\r\ntasklet_init(&pl330->tasks, pl330_dotask, (unsigned long) pl330);\r\npl330->state = INIT;\r\nreturn 0;\r\n}\r\nstatic int dmac_free_threads(struct pl330_dmac *pl330)\r\n{\r\nstruct pl330_thread *thrd;\r\nint i;\r\nfor (i = 0; i < pl330->pcfg.num_chan; i++) {\r\nthrd = &pl330->channels[i];\r\npl330_release_channel(thrd);\r\n}\r\nkfree(pl330->channels);\r\nreturn 0;\r\n}\r\nstatic void pl330_del(struct pl330_dmac *pl330)\r\n{\r\npl330->state = UNINIT;\r\ntasklet_kill(&pl330->tasks);\r\ndmac_free_threads(pl330);\r\ndma_free_coherent(pl330->ddma.dev,\r\npl330->pcfg.num_chan * pl330->mcbufsz, pl330->mcode_cpu,\r\npl330->mcode_bus);\r\n}\r\nstatic inline struct dma_pl330_chan *\r\nto_pchan(struct dma_chan *ch)\r\n{\r\nif (!ch)\r\nreturn NULL;\r\nreturn container_of(ch, struct dma_pl330_chan, chan);\r\n}\r\nstatic inline struct dma_pl330_desc *\r\nto_desc(struct dma_async_tx_descriptor *tx)\r\n{\r\nreturn container_of(tx, struct dma_pl330_desc, txd);\r\n}\r\nstatic inline void fill_queue(struct dma_pl330_chan *pch)\r\n{\r\nstruct dma_pl330_desc *desc;\r\nint ret;\r\nlist_for_each_entry(desc, &pch->work_list, node) {\r\nif (desc->status == BUSY)\r\ncontinue;\r\nret = pl330_submit_req(pch->thread, desc);\r\nif (!ret) {\r\ndesc->status = BUSY;\r\n} else if (ret == -EAGAIN) {\r\nbreak;\r\n} else {\r\ndesc->status = DONE;\r\ndev_err(pch->dmac->ddma.dev, "%s:%d Bad Desc(%d)\n",\r\n__func__, __LINE__, desc->txd.cookie);\r\ntasklet_schedule(&pch->task);\r\n}\r\n}\r\n}\r\nstatic void pl330_tasklet(unsigned long data)\r\n{\r\nstruct dma_pl330_chan *pch = (struct dma_pl330_chan *)data;\r\nstruct dma_pl330_desc *desc, *_dt;\r\nunsigned long flags;\r\nbool power_down = false;\r\nspin_lock_irqsave(&pch->lock, flags);\r\nlist_for_each_entry_safe(desc, _dt, &pch->work_list, node)\r\nif (desc->status == DONE) {\r\nif (!pch->cyclic)\r\ndma_cookie_complete(&desc->txd);\r\nlist_move_tail(&desc->node, &pch->completed_list);\r\n}\r\nfill_queue(pch);\r\nif (list_empty(&pch->work_list)) {\r\nspin_lock(&pch->thread->dmac->lock);\r\n_stop(pch->thread);\r\nspin_unlock(&pch->thread->dmac->lock);\r\npower_down = true;\r\n} else {\r\nspin_lock(&pch->thread->dmac->lock);\r\n_start(pch->thread);\r\nspin_unlock(&pch->thread->dmac->lock);\r\n}\r\nwhile (!list_empty(&pch->completed_list)) {\r\ndma_async_tx_callback callback;\r\nvoid *callback_param;\r\ndesc = list_first_entry(&pch->completed_list,\r\nstruct dma_pl330_desc, node);\r\ncallback = desc->txd.callback;\r\ncallback_param = desc->txd.callback_param;\r\nif (pch->cyclic) {\r\ndesc->status = PREP;\r\nlist_move_tail(&desc->node, &pch->work_list);\r\nif (power_down) {\r\nspin_lock(&pch->thread->dmac->lock);\r\n_start(pch->thread);\r\nspin_unlock(&pch->thread->dmac->lock);\r\npower_down = false;\r\n}\r\n} else {\r\ndesc->status = FREE;\r\nlist_move_tail(&desc->node, &pch->dmac->desc_pool);\r\n}\r\ndma_descriptor_unmap(&desc->txd);\r\nif (callback) {\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\ncallback(callback_param);\r\nspin_lock_irqsave(&pch->lock, flags);\r\n}\r\n}\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\nif (power_down) {\r\npm_runtime_mark_last_busy(pch->dmac->ddma.dev);\r\npm_runtime_put_autosuspend(pch->dmac->ddma.dev);\r\n}\r\n}\r\nbool pl330_filter(struct dma_chan *chan, void *param)\r\n{\r\nu8 *peri_id;\r\nif (chan->device->dev->driver != &pl330_driver.drv)\r\nreturn false;\r\nperi_id = chan->private;\r\nreturn *peri_id == (unsigned long)param;\r\n}\r\nstatic struct dma_chan *of_dma_pl330_xlate(struct of_phandle_args *dma_spec,\r\nstruct of_dma *ofdma)\r\n{\r\nint count = dma_spec->args_count;\r\nstruct pl330_dmac *pl330 = ofdma->of_dma_data;\r\nunsigned int chan_id;\r\nif (!pl330)\r\nreturn NULL;\r\nif (count != 1)\r\nreturn NULL;\r\nchan_id = dma_spec->args[0];\r\nif (chan_id >= pl330->num_peripherals)\r\nreturn NULL;\r\nreturn dma_get_slave_channel(&pl330->peripherals[chan_id].chan);\r\n}\r\nstatic int pl330_alloc_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pch->lock, flags);\r\ndma_cookie_init(chan);\r\npch->cyclic = false;\r\npch->thread = pl330_request_channel(pl330);\r\nif (!pch->thread) {\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\nreturn -ENOMEM;\r\n}\r\ntasklet_init(&pch->task, pl330_tasklet, (unsigned long) pch);\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\nreturn 1;\r\n}\r\nstatic int pl330_config(struct dma_chan *chan,\r\nstruct dma_slave_config *slave_config)\r\n{\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nif (slave_config->direction == DMA_MEM_TO_DEV) {\r\nif (slave_config->dst_addr)\r\npch->fifo_addr = slave_config->dst_addr;\r\nif (slave_config->dst_addr_width)\r\npch->burst_sz = __ffs(slave_config->dst_addr_width);\r\nif (slave_config->dst_maxburst)\r\npch->burst_len = slave_config->dst_maxburst;\r\n} else if (slave_config->direction == DMA_DEV_TO_MEM) {\r\nif (slave_config->src_addr)\r\npch->fifo_addr = slave_config->src_addr;\r\nif (slave_config->src_addr_width)\r\npch->burst_sz = __ffs(slave_config->src_addr_width);\r\nif (slave_config->src_maxburst)\r\npch->burst_len = slave_config->src_maxburst;\r\n}\r\nreturn 0;\r\n}\r\nstatic int pl330_terminate_all(struct dma_chan *chan)\r\n{\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nstruct dma_pl330_desc *desc;\r\nunsigned long flags;\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\nLIST_HEAD(list);\r\npm_runtime_get_sync(pl330->ddma.dev);\r\nspin_lock_irqsave(&pch->lock, flags);\r\nspin_lock(&pl330->lock);\r\n_stop(pch->thread);\r\nspin_unlock(&pl330->lock);\r\npch->thread->req[0].desc = NULL;\r\npch->thread->req[1].desc = NULL;\r\npch->thread->req_running = -1;\r\nlist_for_each_entry(desc, &pch->submitted_list, node) {\r\ndesc->status = FREE;\r\ndma_cookie_complete(&desc->txd);\r\n}\r\nlist_for_each_entry(desc, &pch->work_list , node) {\r\ndesc->status = FREE;\r\ndma_cookie_complete(&desc->txd);\r\n}\r\nlist_splice_tail_init(&pch->submitted_list, &pl330->desc_pool);\r\nlist_splice_tail_init(&pch->work_list, &pl330->desc_pool);\r\nlist_splice_tail_init(&pch->completed_list, &pl330->desc_pool);\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\npm_runtime_mark_last_busy(pl330->ddma.dev);\r\npm_runtime_put_autosuspend(pl330->ddma.dev);\r\nreturn 0;\r\n}\r\nstatic int pl330_pause(struct dma_chan *chan)\r\n{\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\nunsigned long flags;\r\npm_runtime_get_sync(pl330->ddma.dev);\r\nspin_lock_irqsave(&pch->lock, flags);\r\nspin_lock(&pl330->lock);\r\n_stop(pch->thread);\r\nspin_unlock(&pl330->lock);\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\npm_runtime_mark_last_busy(pl330->ddma.dev);\r\npm_runtime_put_autosuspend(pl330->ddma.dev);\r\nreturn 0;\r\n}\r\nstatic void pl330_free_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nunsigned long flags;\r\ntasklet_kill(&pch->task);\r\npm_runtime_get_sync(pch->dmac->ddma.dev);\r\nspin_lock_irqsave(&pch->lock, flags);\r\npl330_release_channel(pch->thread);\r\npch->thread = NULL;\r\nif (pch->cyclic)\r\nlist_splice_tail_init(&pch->work_list, &pch->dmac->desc_pool);\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\npm_runtime_mark_last_busy(pch->dmac->ddma.dev);\r\npm_runtime_put_autosuspend(pch->dmac->ddma.dev);\r\n}\r\nstatic int pl330_get_current_xferred_count(struct dma_pl330_chan *pch,\r\nstruct dma_pl330_desc *desc)\r\n{\r\nstruct pl330_thread *thrd = pch->thread;\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\nvoid __iomem *regs = thrd->dmac->base;\r\nu32 val, addr;\r\npm_runtime_get_sync(pl330->ddma.dev);\r\nval = addr = 0;\r\nif (desc->rqcfg.src_inc) {\r\nval = readl(regs + SA(thrd->id));\r\naddr = desc->px.src_addr;\r\n} else {\r\nval = readl(regs + DA(thrd->id));\r\naddr = desc->px.dst_addr;\r\n}\r\npm_runtime_mark_last_busy(pch->dmac->ddma.dev);\r\npm_runtime_put_autosuspend(pl330->ddma.dev);\r\nreturn val - addr;\r\n}\r\nstatic enum dma_status\r\npl330_tx_status(struct dma_chan *chan, dma_cookie_t cookie,\r\nstruct dma_tx_state *txstate)\r\n{\r\nenum dma_status ret;\r\nunsigned long flags;\r\nstruct dma_pl330_desc *desc, *running = NULL;\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nunsigned int transferred, residual = 0;\r\nret = dma_cookie_status(chan, cookie, txstate);\r\nif (!txstate)\r\nreturn ret;\r\nif (ret == DMA_COMPLETE)\r\ngoto out;\r\nspin_lock_irqsave(&pch->lock, flags);\r\nif (pch->thread->req_running != -1)\r\nrunning = pch->thread->req[pch->thread->req_running].desc;\r\nlist_for_each_entry(desc, &pch->work_list, node) {\r\nif (desc->status == DONE)\r\ntransferred = desc->bytes_requested;\r\nelse if (running && desc == running)\r\ntransferred =\r\npl330_get_current_xferred_count(pch, desc);\r\nelse\r\ntransferred = 0;\r\nresidual += desc->bytes_requested - transferred;\r\nif (desc->txd.cookie == cookie) {\r\nswitch (desc->status) {\r\ncase DONE:\r\nret = DMA_COMPLETE;\r\nbreak;\r\ncase PREP:\r\ncase BUSY:\r\nret = DMA_IN_PROGRESS;\r\nbreak;\r\ndefault:\r\nWARN_ON(1);\r\n}\r\nbreak;\r\n}\r\nif (desc->last)\r\nresidual = 0;\r\n}\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\nout:\r\ndma_set_residue(txstate, residual);\r\nreturn ret;\r\n}\r\nstatic void pl330_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&pch->lock, flags);\r\nif (list_empty(&pch->work_list)) {\r\nWARN_ON(list_empty(&pch->submitted_list));\r\npm_runtime_get_sync(pch->dmac->ddma.dev);\r\n}\r\nlist_splice_tail_init(&pch->submitted_list, &pch->work_list);\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\npl330_tasklet((unsigned long)pch);\r\n}\r\nstatic dma_cookie_t pl330_tx_submit(struct dma_async_tx_descriptor *tx)\r\n{\r\nstruct dma_pl330_desc *desc, *last = to_desc(tx);\r\nstruct dma_pl330_chan *pch = to_pchan(tx->chan);\r\ndma_cookie_t cookie;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pch->lock, flags);\r\nwhile (!list_empty(&last->node)) {\r\ndesc = list_entry(last->node.next, struct dma_pl330_desc, node);\r\nif (pch->cyclic) {\r\ndesc->txd.callback = last->txd.callback;\r\ndesc->txd.callback_param = last->txd.callback_param;\r\n}\r\ndesc->last = false;\r\ndma_cookie_assign(&desc->txd);\r\nlist_move_tail(&desc->node, &pch->submitted_list);\r\n}\r\nlast->last = true;\r\ncookie = dma_cookie_assign(&last->txd);\r\nlist_add_tail(&last->node, &pch->submitted_list);\r\nspin_unlock_irqrestore(&pch->lock, flags);\r\nreturn cookie;\r\n}\r\nstatic inline void _init_desc(struct dma_pl330_desc *desc)\r\n{\r\ndesc->rqcfg.swap = SWAP_NO;\r\ndesc->rqcfg.scctl = CCTRL0;\r\ndesc->rqcfg.dcctl = CCTRL0;\r\ndesc->txd.tx_submit = pl330_tx_submit;\r\nINIT_LIST_HEAD(&desc->node);\r\n}\r\nstatic int add_desc(struct pl330_dmac *pl330, gfp_t flg, int count)\r\n{\r\nstruct dma_pl330_desc *desc;\r\nunsigned long flags;\r\nint i;\r\ndesc = kcalloc(count, sizeof(*desc), flg);\r\nif (!desc)\r\nreturn 0;\r\nspin_lock_irqsave(&pl330->pool_lock, flags);\r\nfor (i = 0; i < count; i++) {\r\n_init_desc(&desc[i]);\r\nlist_add_tail(&desc[i].node, &pl330->desc_pool);\r\n}\r\nspin_unlock_irqrestore(&pl330->pool_lock, flags);\r\nreturn count;\r\n}\r\nstatic struct dma_pl330_desc *pluck_desc(struct pl330_dmac *pl330)\r\n{\r\nstruct dma_pl330_desc *desc = NULL;\r\nunsigned long flags;\r\nspin_lock_irqsave(&pl330->pool_lock, flags);\r\nif (!list_empty(&pl330->desc_pool)) {\r\ndesc = list_entry(pl330->desc_pool.next,\r\nstruct dma_pl330_desc, node);\r\nlist_del_init(&desc->node);\r\ndesc->status = PREP;\r\ndesc->txd.callback = NULL;\r\n}\r\nspin_unlock_irqrestore(&pl330->pool_lock, flags);\r\nreturn desc;\r\n}\r\nstatic struct dma_pl330_desc *pl330_get_desc(struct dma_pl330_chan *pch)\r\n{\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\nu8 *peri_id = pch->chan.private;\r\nstruct dma_pl330_desc *desc;\r\ndesc = pluck_desc(pl330);\r\nif (!desc) {\r\nif (!add_desc(pl330, GFP_ATOMIC, 1))\r\nreturn NULL;\r\ndesc = pluck_desc(pl330);\r\nif (!desc) {\r\ndev_err(pch->dmac->ddma.dev,\r\n"%s:%d ALERT!\n", __func__, __LINE__);\r\nreturn NULL;\r\n}\r\n}\r\ndesc->pchan = pch;\r\ndesc->txd.cookie = 0;\r\nasync_tx_ack(&desc->txd);\r\ndesc->peri = peri_id ? pch->chan.chan_id : 0;\r\ndesc->rqcfg.pcfg = &pch->dmac->pcfg;\r\ndma_async_tx_descriptor_init(&desc->txd, &pch->chan);\r\nreturn desc;\r\n}\r\nstatic inline void fill_px(struct pl330_xfer *px,\r\ndma_addr_t dst, dma_addr_t src, size_t len)\r\n{\r\npx->bytes = len;\r\npx->dst_addr = dst;\r\npx->src_addr = src;\r\n}\r\nstatic struct dma_pl330_desc *\r\n__pl330_prep_dma_memcpy(struct dma_pl330_chan *pch, dma_addr_t dst,\r\ndma_addr_t src, size_t len)\r\n{\r\nstruct dma_pl330_desc *desc = pl330_get_desc(pch);\r\nif (!desc) {\r\ndev_err(pch->dmac->ddma.dev, "%s:%d Unable to fetch desc\n",\r\n__func__, __LINE__);\r\nreturn NULL;\r\n}\r\nfill_px(&desc->px, dst, src, len);\r\nreturn desc;\r\n}\r\nstatic inline int get_burst_len(struct dma_pl330_desc *desc, size_t len)\r\n{\r\nstruct dma_pl330_chan *pch = desc->pchan;\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\nint burst_len;\r\nburst_len = pl330->pcfg.data_bus_width / 8;\r\nburst_len *= pl330->pcfg.data_buf_dep / pl330->pcfg.num_chan;\r\nburst_len >>= desc->rqcfg.brst_size;\r\nif (burst_len > 16)\r\nburst_len = 16;\r\nwhile (burst_len > 1) {\r\nif (!(len % (burst_len << desc->rqcfg.brst_size)))\r\nbreak;\r\nburst_len--;\r\n}\r\nreturn burst_len;\r\n}\r\nstatic struct dma_async_tx_descriptor *pl330_prep_dma_cyclic(\r\nstruct dma_chan *chan, dma_addr_t dma_addr, size_t len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags)\r\n{\r\nstruct dma_pl330_desc *desc = NULL, *first = NULL;\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\nunsigned int i;\r\ndma_addr_t dst;\r\ndma_addr_t src;\r\nif (len % period_len != 0)\r\nreturn NULL;\r\nif (!is_slave_direction(direction)) {\r\ndev_err(pch->dmac->ddma.dev, "%s:%d Invalid dma direction\n",\r\n__func__, __LINE__);\r\nreturn NULL;\r\n}\r\nfor (i = 0; i < len / period_len; i++) {\r\ndesc = pl330_get_desc(pch);\r\nif (!desc) {\r\ndev_err(pch->dmac->ddma.dev, "%s:%d Unable to fetch desc\n",\r\n__func__, __LINE__);\r\nif (!first)\r\nreturn NULL;\r\nspin_lock_irqsave(&pl330->pool_lock, flags);\r\nwhile (!list_empty(&first->node)) {\r\ndesc = list_entry(first->node.next,\r\nstruct dma_pl330_desc, node);\r\nlist_move_tail(&desc->node, &pl330->desc_pool);\r\n}\r\nlist_move_tail(&first->node, &pl330->desc_pool);\r\nspin_unlock_irqrestore(&pl330->pool_lock, flags);\r\nreturn NULL;\r\n}\r\nswitch (direction) {\r\ncase DMA_MEM_TO_DEV:\r\ndesc->rqcfg.src_inc = 1;\r\ndesc->rqcfg.dst_inc = 0;\r\nsrc = dma_addr;\r\ndst = pch->fifo_addr;\r\nbreak;\r\ncase DMA_DEV_TO_MEM:\r\ndesc->rqcfg.src_inc = 0;\r\ndesc->rqcfg.dst_inc = 1;\r\nsrc = pch->fifo_addr;\r\ndst = dma_addr;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\ndesc->rqtype = direction;\r\ndesc->rqcfg.brst_size = pch->burst_sz;\r\ndesc->rqcfg.brst_len = 1;\r\ndesc->bytes_requested = period_len;\r\nfill_px(&desc->px, dst, src, period_len);\r\nif (!first)\r\nfirst = desc;\r\nelse\r\nlist_add_tail(&desc->node, &first->node);\r\ndma_addr += period_len;\r\n}\r\nif (!desc)\r\nreturn NULL;\r\npch->cyclic = true;\r\ndesc->txd.flags = flags;\r\nreturn &desc->txd;\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\npl330_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dst,\r\ndma_addr_t src, size_t len, unsigned long flags)\r\n{\r\nstruct dma_pl330_desc *desc;\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nstruct pl330_dmac *pl330;\r\nint burst;\r\nif (unlikely(!pch || !len))\r\nreturn NULL;\r\npl330 = pch->dmac;\r\ndesc = __pl330_prep_dma_memcpy(pch, dst, src, len);\r\nif (!desc)\r\nreturn NULL;\r\ndesc->rqcfg.src_inc = 1;\r\ndesc->rqcfg.dst_inc = 1;\r\ndesc->rqtype = DMA_MEM_TO_MEM;\r\nburst = pl330->pcfg.data_bus_width / 8;\r\nwhile ((src | dst | len) & (burst - 1))\r\nburst /= 2;\r\ndesc->rqcfg.brst_size = 0;\r\nwhile (burst != (1 << desc->rqcfg.brst_size))\r\ndesc->rqcfg.brst_size++;\r\nif (desc->rqcfg.brst_size * 8 < pl330->pcfg.data_bus_width)\r\ndesc->rqcfg.brst_len = 1;\r\ndesc->rqcfg.brst_len = get_burst_len(desc, len);\r\ndesc->bytes_requested = len;\r\ndesc->txd.flags = flags;\r\nreturn &desc->txd;\r\n}\r\nstatic void __pl330_giveback_desc(struct pl330_dmac *pl330,\r\nstruct dma_pl330_desc *first)\r\n{\r\nunsigned long flags;\r\nstruct dma_pl330_desc *desc;\r\nif (!first)\r\nreturn;\r\nspin_lock_irqsave(&pl330->pool_lock, flags);\r\nwhile (!list_empty(&first->node)) {\r\ndesc = list_entry(first->node.next,\r\nstruct dma_pl330_desc, node);\r\nlist_move_tail(&desc->node, &pl330->desc_pool);\r\n}\r\nlist_move_tail(&first->node, &pl330->desc_pool);\r\nspin_unlock_irqrestore(&pl330->pool_lock, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\npl330_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction direction,\r\nunsigned long flg, void *context)\r\n{\r\nstruct dma_pl330_desc *first, *desc = NULL;\r\nstruct dma_pl330_chan *pch = to_pchan(chan);\r\nstruct scatterlist *sg;\r\nint i;\r\ndma_addr_t addr;\r\nif (unlikely(!pch || !sgl || !sg_len))\r\nreturn NULL;\r\naddr = pch->fifo_addr;\r\nfirst = NULL;\r\nfor_each_sg(sgl, sg, sg_len, i) {\r\ndesc = pl330_get_desc(pch);\r\nif (!desc) {\r\nstruct pl330_dmac *pl330 = pch->dmac;\r\ndev_err(pch->dmac->ddma.dev,\r\n"%s:%d Unable to fetch desc\n",\r\n__func__, __LINE__);\r\n__pl330_giveback_desc(pl330, first);\r\nreturn NULL;\r\n}\r\nif (!first)\r\nfirst = desc;\r\nelse\r\nlist_add_tail(&desc->node, &first->node);\r\nif (direction == DMA_MEM_TO_DEV) {\r\ndesc->rqcfg.src_inc = 1;\r\ndesc->rqcfg.dst_inc = 0;\r\nfill_px(&desc->px,\r\naddr, sg_dma_address(sg), sg_dma_len(sg));\r\n} else {\r\ndesc->rqcfg.src_inc = 0;\r\ndesc->rqcfg.dst_inc = 1;\r\nfill_px(&desc->px,\r\nsg_dma_address(sg), addr, sg_dma_len(sg));\r\n}\r\ndesc->rqcfg.brst_size = pch->burst_sz;\r\ndesc->rqcfg.brst_len = 1;\r\ndesc->rqtype = direction;\r\ndesc->bytes_requested = sg_dma_len(sg);\r\n}\r\ndesc->txd.flags = flg;\r\nreturn &desc->txd;\r\n}\r\nstatic irqreturn_t pl330_irq_handler(int irq, void *data)\r\n{\r\nif (pl330_update(data))\r\nreturn IRQ_HANDLED;\r\nelse\r\nreturn IRQ_NONE;\r\n}\r\nstatic int __maybe_unused pl330_suspend(struct device *dev)\r\n{\r\nstruct amba_device *pcdev = to_amba_device(dev);\r\npm_runtime_disable(dev);\r\nif (!pm_runtime_status_suspended(dev)) {\r\namba_pclk_disable(pcdev);\r\n}\r\namba_pclk_unprepare(pcdev);\r\nreturn 0;\r\n}\r\nstatic int __maybe_unused pl330_resume(struct device *dev)\r\n{\r\nstruct amba_device *pcdev = to_amba_device(dev);\r\nint ret;\r\nret = amba_pclk_prepare(pcdev);\r\nif (ret)\r\nreturn ret;\r\nif (!pm_runtime_status_suspended(dev))\r\nret = amba_pclk_enable(pcdev);\r\npm_runtime_enable(dev);\r\nreturn ret;\r\n}\r\nstatic int\r\npl330_probe(struct amba_device *adev, const struct amba_id *id)\r\n{\r\nstruct dma_pl330_platdata *pdat;\r\nstruct pl330_config *pcfg;\r\nstruct pl330_dmac *pl330;\r\nstruct dma_pl330_chan *pch, *_p;\r\nstruct dma_device *pd;\r\nstruct resource *res;\r\nint i, ret, irq;\r\nint num_chan;\r\npdat = dev_get_platdata(&adev->dev);\r\nret = dma_set_mask_and_coherent(&adev->dev, DMA_BIT_MASK(32));\r\nif (ret)\r\nreturn ret;\r\npl330 = devm_kzalloc(&adev->dev, sizeof(*pl330), GFP_KERNEL);\r\nif (!pl330) {\r\ndev_err(&adev->dev, "unable to allocate mem\n");\r\nreturn -ENOMEM;\r\n}\r\npd = &pl330->ddma;\r\npd->dev = &adev->dev;\r\npl330->mcbufsz = pdat ? pdat->mcbuf_sz : 0;\r\nres = &adev->res;\r\npl330->base = devm_ioremap_resource(&adev->dev, res);\r\nif (IS_ERR(pl330->base))\r\nreturn PTR_ERR(pl330->base);\r\namba_set_drvdata(adev, pl330);\r\nfor (i = 0; i < AMBA_NR_IRQS; i++) {\r\nirq = adev->irq[i];\r\nif (irq) {\r\nret = devm_request_irq(&adev->dev, irq,\r\npl330_irq_handler, 0,\r\ndev_name(&adev->dev), pl330);\r\nif (ret)\r\nreturn ret;\r\n} else {\r\nbreak;\r\n}\r\n}\r\npcfg = &pl330->pcfg;\r\npcfg->periph_id = adev->periphid;\r\nret = pl330_add(pl330);\r\nif (ret)\r\nreturn ret;\r\nINIT_LIST_HEAD(&pl330->desc_pool);\r\nspin_lock_init(&pl330->pool_lock);\r\nif (!add_desc(pl330, GFP_KERNEL, NR_DEFAULT_DESC))\r\ndev_warn(&adev->dev, "unable to allocate desc\n");\r\nINIT_LIST_HEAD(&pd->channels);\r\nif (pdat)\r\nnum_chan = max_t(int, pdat->nr_valid_peri, pcfg->num_chan);\r\nelse\r\nnum_chan = max_t(int, pcfg->num_peri, pcfg->num_chan);\r\npl330->num_peripherals = num_chan;\r\npl330->peripherals = kzalloc(num_chan * sizeof(*pch), GFP_KERNEL);\r\nif (!pl330->peripherals) {\r\nret = -ENOMEM;\r\ndev_err(&adev->dev, "unable to allocate pl330->peripherals\n");\r\ngoto probe_err2;\r\n}\r\nfor (i = 0; i < num_chan; i++) {\r\npch = &pl330->peripherals[i];\r\nif (!adev->dev.of_node)\r\npch->chan.private = pdat ? &pdat->peri_id[i] : NULL;\r\nelse\r\npch->chan.private = adev->dev.of_node;\r\nINIT_LIST_HEAD(&pch->submitted_list);\r\nINIT_LIST_HEAD(&pch->work_list);\r\nINIT_LIST_HEAD(&pch->completed_list);\r\nspin_lock_init(&pch->lock);\r\npch->thread = NULL;\r\npch->chan.device = pd;\r\npch->dmac = pl330;\r\nlist_add_tail(&pch->chan.device_node, &pd->channels);\r\n}\r\nif (pdat) {\r\npd->cap_mask = pdat->cap_mask;\r\n} else {\r\ndma_cap_set(DMA_MEMCPY, pd->cap_mask);\r\nif (pcfg->num_peri) {\r\ndma_cap_set(DMA_SLAVE, pd->cap_mask);\r\ndma_cap_set(DMA_CYCLIC, pd->cap_mask);\r\ndma_cap_set(DMA_PRIVATE, pd->cap_mask);\r\n}\r\n}\r\npd->device_alloc_chan_resources = pl330_alloc_chan_resources;\r\npd->device_free_chan_resources = pl330_free_chan_resources;\r\npd->device_prep_dma_memcpy = pl330_prep_dma_memcpy;\r\npd->device_prep_dma_cyclic = pl330_prep_dma_cyclic;\r\npd->device_tx_status = pl330_tx_status;\r\npd->device_prep_slave_sg = pl330_prep_slave_sg;\r\npd->device_config = pl330_config;\r\npd->device_pause = pl330_pause;\r\npd->device_terminate_all = pl330_terminate_all;\r\npd->device_issue_pending = pl330_issue_pending;\r\npd->src_addr_widths = PL330_DMA_BUSWIDTHS;\r\npd->dst_addr_widths = PL330_DMA_BUSWIDTHS;\r\npd->directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\r\npd->residue_granularity = DMA_RESIDUE_GRANULARITY_SEGMENT;\r\nret = dma_async_device_register(pd);\r\nif (ret) {\r\ndev_err(&adev->dev, "unable to register DMAC\n");\r\ngoto probe_err3;\r\n}\r\nif (adev->dev.of_node) {\r\nret = of_dma_controller_register(adev->dev.of_node,\r\nof_dma_pl330_xlate, pl330);\r\nif (ret) {\r\ndev_err(&adev->dev,\r\n"unable to register DMA to the generic DT DMA helpers\n");\r\n}\r\n}\r\nadev->dev.dma_parms = &pl330->dma_parms;\r\nret = dma_set_max_seg_size(&adev->dev, 1900800);\r\nif (ret)\r\ndev_err(&adev->dev, "unable to set the seg size\n");\r\ndev_info(&adev->dev,\r\n"Loaded driver for PL330 DMAC-%x\n", adev->periphid);\r\ndev_info(&adev->dev,\r\n"\tDBUFF-%ux%ubytes Num_Chans-%u Num_Peri-%u Num_Events-%u\n",\r\npcfg->data_buf_dep, pcfg->data_bus_width / 8, pcfg->num_chan,\r\npcfg->num_peri, pcfg->num_events);\r\npm_runtime_irq_safe(&adev->dev);\r\npm_runtime_use_autosuspend(&adev->dev);\r\npm_runtime_set_autosuspend_delay(&adev->dev, PL330_AUTOSUSPEND_DELAY);\r\npm_runtime_mark_last_busy(&adev->dev);\r\npm_runtime_put_autosuspend(&adev->dev);\r\nreturn 0;\r\nprobe_err3:\r\nlist_for_each_entry_safe(pch, _p, &pl330->ddma.channels,\r\nchan.device_node) {\r\nlist_del(&pch->chan.device_node);\r\nif (pch->thread) {\r\npl330_terminate_all(&pch->chan);\r\npl330_free_chan_resources(&pch->chan);\r\n}\r\n}\r\nprobe_err2:\r\npl330_del(pl330);\r\nreturn ret;\r\n}\r\nstatic int pl330_remove(struct amba_device *adev)\r\n{\r\nstruct pl330_dmac *pl330 = amba_get_drvdata(adev);\r\nstruct dma_pl330_chan *pch, *_p;\r\npm_runtime_get_noresume(pl330->ddma.dev);\r\nif (adev->dev.of_node)\r\nof_dma_controller_free(adev->dev.of_node);\r\ndma_async_device_unregister(&pl330->ddma);\r\nlist_for_each_entry_safe(pch, _p, &pl330->ddma.channels,\r\nchan.device_node) {\r\nlist_del(&pch->chan.device_node);\r\nif (pch->thread) {\r\npl330_terminate_all(&pch->chan);\r\npl330_free_chan_resources(&pch->chan);\r\n}\r\n}\r\npl330_del(pl330);\r\nreturn 0;\r\n}
