static inline int virtblk_result(struct virtblk_req *vbr)\r\n{\r\nswitch (vbr->status) {\r\ncase VIRTIO_BLK_S_OK:\r\nreturn 0;\r\ncase VIRTIO_BLK_S_UNSUPP:\r\nreturn -ENOTTY;\r\ndefault:\r\nreturn -EIO;\r\n}\r\n}\r\nstatic int __virtblk_add_req(struct virtqueue *vq,\r\nstruct virtblk_req *vbr,\r\nstruct scatterlist *data_sg,\r\nbool have_data)\r\n{\r\nstruct scatterlist hdr, status, cmd, sense, inhdr, *sgs[6];\r\nunsigned int num_out = 0, num_in = 0;\r\n__virtio32 type = vbr->out_hdr.type & ~cpu_to_virtio32(vq->vdev, VIRTIO_BLK_T_OUT);\r\nsg_init_one(&hdr, &vbr->out_hdr, sizeof(vbr->out_hdr));\r\nsgs[num_out++] = &hdr;\r\nif (type == cpu_to_virtio32(vq->vdev, VIRTIO_BLK_T_SCSI_CMD)) {\r\nsg_init_one(&cmd, vbr->req->cmd, vbr->req->cmd_len);\r\nsgs[num_out++] = &cmd;\r\n}\r\nif (have_data) {\r\nif (vbr->out_hdr.type & cpu_to_virtio32(vq->vdev, VIRTIO_BLK_T_OUT))\r\nsgs[num_out++] = data_sg;\r\nelse\r\nsgs[num_out + num_in++] = data_sg;\r\n}\r\nif (type == cpu_to_virtio32(vq->vdev, VIRTIO_BLK_T_SCSI_CMD)) {\r\nsg_init_one(&sense, vbr->req->sense, SCSI_SENSE_BUFFERSIZE);\r\nsgs[num_out + num_in++] = &sense;\r\nsg_init_one(&inhdr, &vbr->in_hdr, sizeof(vbr->in_hdr));\r\nsgs[num_out + num_in++] = &inhdr;\r\n}\r\nsg_init_one(&status, &vbr->status, sizeof(vbr->status));\r\nsgs[num_out + num_in++] = &status;\r\nreturn virtqueue_add_sgs(vq, sgs, num_out, num_in, vbr, GFP_ATOMIC);\r\n}\r\nstatic inline void virtblk_request_done(struct request *req)\r\n{\r\nstruct virtblk_req *vbr = blk_mq_rq_to_pdu(req);\r\nstruct virtio_blk *vblk = req->q->queuedata;\r\nint error = virtblk_result(vbr);\r\nif (req->cmd_type == REQ_TYPE_BLOCK_PC) {\r\nreq->resid_len = virtio32_to_cpu(vblk->vdev, vbr->in_hdr.residual);\r\nreq->sense_len = virtio32_to_cpu(vblk->vdev, vbr->in_hdr.sense_len);\r\nreq->errors = virtio32_to_cpu(vblk->vdev, vbr->in_hdr.errors);\r\n} else if (req->cmd_type == REQ_TYPE_DRV_PRIV) {\r\nreq->errors = (error != 0);\r\n}\r\nblk_mq_end_request(req, error);\r\n}\r\nstatic void virtblk_done(struct virtqueue *vq)\r\n{\r\nstruct virtio_blk *vblk = vq->vdev->priv;\r\nbool req_done = false;\r\nint qid = vq->index;\r\nstruct virtblk_req *vbr;\r\nunsigned long flags;\r\nunsigned int len;\r\nspin_lock_irqsave(&vblk->vqs[qid].lock, flags);\r\ndo {\r\nvirtqueue_disable_cb(vq);\r\nwhile ((vbr = virtqueue_get_buf(vblk->vqs[qid].vq, &len)) != NULL) {\r\nblk_mq_complete_request(vbr->req, vbr->req->errors);\r\nreq_done = true;\r\n}\r\nif (unlikely(virtqueue_is_broken(vq)))\r\nbreak;\r\n} while (!virtqueue_enable_cb(vq));\r\nif (req_done)\r\nblk_mq_start_stopped_hw_queues(vblk->disk->queue, true);\r\nspin_unlock_irqrestore(&vblk->vqs[qid].lock, flags);\r\n}\r\nstatic int virtio_queue_rq(struct blk_mq_hw_ctx *hctx,\r\nconst struct blk_mq_queue_data *bd)\r\n{\r\nstruct virtio_blk *vblk = hctx->queue->queuedata;\r\nstruct request *req = bd->rq;\r\nstruct virtblk_req *vbr = blk_mq_rq_to_pdu(req);\r\nunsigned long flags;\r\nunsigned int num;\r\nint qid = hctx->queue_num;\r\nint err;\r\nbool notify = false;\r\nBUG_ON(req->nr_phys_segments + 2 > vblk->sg_elems);\r\nvbr->req = req;\r\nif (req->cmd_flags & REQ_FLUSH) {\r\nvbr->out_hdr.type = cpu_to_virtio32(vblk->vdev, VIRTIO_BLK_T_FLUSH);\r\nvbr->out_hdr.sector = 0;\r\nvbr->out_hdr.ioprio = cpu_to_virtio32(vblk->vdev, req_get_ioprio(vbr->req));\r\n} else {\r\nswitch (req->cmd_type) {\r\ncase REQ_TYPE_FS:\r\nvbr->out_hdr.type = 0;\r\nvbr->out_hdr.sector = cpu_to_virtio64(vblk->vdev, blk_rq_pos(vbr->req));\r\nvbr->out_hdr.ioprio = cpu_to_virtio32(vblk->vdev, req_get_ioprio(vbr->req));\r\nbreak;\r\ncase REQ_TYPE_BLOCK_PC:\r\nvbr->out_hdr.type = cpu_to_virtio32(vblk->vdev, VIRTIO_BLK_T_SCSI_CMD);\r\nvbr->out_hdr.sector = 0;\r\nvbr->out_hdr.ioprio = cpu_to_virtio32(vblk->vdev, req_get_ioprio(vbr->req));\r\nbreak;\r\ncase REQ_TYPE_DRV_PRIV:\r\nvbr->out_hdr.type = cpu_to_virtio32(vblk->vdev, VIRTIO_BLK_T_GET_ID);\r\nvbr->out_hdr.sector = 0;\r\nvbr->out_hdr.ioprio = cpu_to_virtio32(vblk->vdev, req_get_ioprio(vbr->req));\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nblk_mq_start_request(req);\r\nnum = blk_rq_map_sg(hctx->queue, vbr->req, vbr->sg);\r\nif (num) {\r\nif (rq_data_dir(vbr->req) == WRITE)\r\nvbr->out_hdr.type |= cpu_to_virtio32(vblk->vdev, VIRTIO_BLK_T_OUT);\r\nelse\r\nvbr->out_hdr.type |= cpu_to_virtio32(vblk->vdev, VIRTIO_BLK_T_IN);\r\n}\r\nspin_lock_irqsave(&vblk->vqs[qid].lock, flags);\r\nerr = __virtblk_add_req(vblk->vqs[qid].vq, vbr, vbr->sg, num);\r\nif (err) {\r\nvirtqueue_kick(vblk->vqs[qid].vq);\r\nblk_mq_stop_hw_queue(hctx);\r\nspin_unlock_irqrestore(&vblk->vqs[qid].lock, flags);\r\nif (err == -ENOMEM || err == -ENOSPC)\r\nreturn BLK_MQ_RQ_QUEUE_BUSY;\r\nreturn BLK_MQ_RQ_QUEUE_ERROR;\r\n}\r\nif (bd->last && virtqueue_kick_prepare(vblk->vqs[qid].vq))\r\nnotify = true;\r\nspin_unlock_irqrestore(&vblk->vqs[qid].lock, flags);\r\nif (notify)\r\nvirtqueue_notify(vblk->vqs[qid].vq);\r\nreturn BLK_MQ_RQ_QUEUE_OK;\r\n}\r\nstatic int virtblk_get_id(struct gendisk *disk, char *id_str)\r\n{\r\nstruct virtio_blk *vblk = disk->private_data;\r\nstruct request *req;\r\nstruct bio *bio;\r\nint err;\r\nbio = bio_map_kern(vblk->disk->queue, id_str, VIRTIO_BLK_ID_BYTES,\r\nGFP_KERNEL);\r\nif (IS_ERR(bio))\r\nreturn PTR_ERR(bio);\r\nreq = blk_make_request(vblk->disk->queue, bio, GFP_KERNEL);\r\nif (IS_ERR(req)) {\r\nbio_put(bio);\r\nreturn PTR_ERR(req);\r\n}\r\nreq->cmd_type = REQ_TYPE_DRV_PRIV;\r\nerr = blk_execute_rq(vblk->disk->queue, vblk->disk, req, false);\r\nblk_put_request(req);\r\nreturn err;\r\n}\r\nstatic int virtblk_ioctl(struct block_device *bdev, fmode_t mode,\r\nunsigned int cmd, unsigned long data)\r\n{\r\nstruct gendisk *disk = bdev->bd_disk;\r\nstruct virtio_blk *vblk = disk->private_data;\r\nif (!virtio_has_feature(vblk->vdev, VIRTIO_BLK_F_SCSI))\r\nreturn -ENOTTY;\r\nreturn scsi_cmd_blk_ioctl(bdev, mode, cmd,\r\n(void __user *)data);\r\n}\r\nstatic int virtblk_getgeo(struct block_device *bd, struct hd_geometry *geo)\r\n{\r\nstruct virtio_blk *vblk = bd->bd_disk->private_data;\r\nif (virtio_has_feature(vblk->vdev, VIRTIO_BLK_F_GEOMETRY)) {\r\nvirtio_cread(vblk->vdev, struct virtio_blk_config,\r\ngeometry.cylinders, &geo->cylinders);\r\nvirtio_cread(vblk->vdev, struct virtio_blk_config,\r\ngeometry.heads, &geo->heads);\r\nvirtio_cread(vblk->vdev, struct virtio_blk_config,\r\ngeometry.sectors, &geo->sectors);\r\n} else {\r\ngeo->heads = 1 << 6;\r\ngeo->sectors = 1 << 5;\r\ngeo->cylinders = get_capacity(bd->bd_disk) >> 11;\r\n}\r\nreturn 0;\r\n}\r\nstatic int index_to_minor(int index)\r\n{\r\nreturn index << PART_BITS;\r\n}\r\nstatic int minor_to_index(int minor)\r\n{\r\nreturn minor >> PART_BITS;\r\n}\r\nstatic ssize_t virtblk_serial_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nint err;\r\nBUILD_BUG_ON(PAGE_SIZE < VIRTIO_BLK_ID_BYTES);\r\nbuf[VIRTIO_BLK_ID_BYTES] = '\0';\r\nerr = virtblk_get_id(disk, buf);\r\nif (!err)\r\nreturn strlen(buf);\r\nif (err == -EIO)\r\nreturn 0;\r\nreturn err;\r\n}\r\nstatic void virtblk_config_changed_work(struct work_struct *work)\r\n{\r\nstruct virtio_blk *vblk =\r\ncontainer_of(work, struct virtio_blk, config_work);\r\nstruct virtio_device *vdev = vblk->vdev;\r\nstruct request_queue *q = vblk->disk->queue;\r\nchar cap_str_2[10], cap_str_10[10];\r\nchar *envp[] = { "RESIZE=1", NULL };\r\nu64 capacity;\r\nvirtio_cread(vdev, struct virtio_blk_config, capacity, &capacity);\r\nif ((sector_t)capacity != capacity) {\r\ndev_warn(&vdev->dev, "Capacity %llu too large: truncating\n",\r\n(unsigned long long)capacity);\r\ncapacity = (sector_t)-1;\r\n}\r\nstring_get_size(capacity, queue_logical_block_size(q),\r\nSTRING_UNITS_2, cap_str_2, sizeof(cap_str_2));\r\nstring_get_size(capacity, queue_logical_block_size(q),\r\nSTRING_UNITS_10, cap_str_10, sizeof(cap_str_10));\r\ndev_notice(&vdev->dev,\r\n"new size: %llu %d-byte logical blocks (%s/%s)\n",\r\n(unsigned long long)capacity,\r\nqueue_logical_block_size(q),\r\ncap_str_10, cap_str_2);\r\nset_capacity(vblk->disk, capacity);\r\nrevalidate_disk(vblk->disk);\r\nkobject_uevent_env(&disk_to_dev(vblk->disk)->kobj, KOBJ_CHANGE, envp);\r\n}\r\nstatic void virtblk_config_changed(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nqueue_work(virtblk_wq, &vblk->config_work);\r\n}\r\nstatic int init_vq(struct virtio_blk *vblk)\r\n{\r\nint err = 0;\r\nint i;\r\nvq_callback_t **callbacks;\r\nconst char **names;\r\nstruct virtqueue **vqs;\r\nunsigned short num_vqs;\r\nstruct virtio_device *vdev = vblk->vdev;\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_MQ,\r\nstruct virtio_blk_config, num_queues,\r\n&num_vqs);\r\nif (err)\r\nnum_vqs = 1;\r\nvblk->vqs = kmalloc(sizeof(*vblk->vqs) * num_vqs, GFP_KERNEL);\r\nif (!vblk->vqs) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nnames = kmalloc(sizeof(*names) * num_vqs, GFP_KERNEL);\r\nif (!names)\r\ngoto err_names;\r\ncallbacks = kmalloc(sizeof(*callbacks) * num_vqs, GFP_KERNEL);\r\nif (!callbacks)\r\ngoto err_callbacks;\r\nvqs = kmalloc(sizeof(*vqs) * num_vqs, GFP_KERNEL);\r\nif (!vqs)\r\ngoto err_vqs;\r\nfor (i = 0; i < num_vqs; i++) {\r\ncallbacks[i] = virtblk_done;\r\nsnprintf(vblk->vqs[i].name, VQ_NAME_LEN, "req.%d", i);\r\nnames[i] = vblk->vqs[i].name;\r\n}\r\nerr = vdev->config->find_vqs(vdev, num_vqs, vqs, callbacks, names);\r\nif (err)\r\ngoto err_find_vqs;\r\nfor (i = 0; i < num_vqs; i++) {\r\nspin_lock_init(&vblk->vqs[i].lock);\r\nvblk->vqs[i].vq = vqs[i];\r\n}\r\nvblk->num_vqs = num_vqs;\r\nerr_find_vqs:\r\nkfree(vqs);\r\nerr_vqs:\r\nkfree(callbacks);\r\nerr_callbacks:\r\nkfree(names);\r\nerr_names:\r\nif (err)\r\nkfree(vblk->vqs);\r\nout:\r\nreturn err;\r\n}\r\nstatic int virtblk_name_format(char *prefix, int index, char *buf, int buflen)\r\n{\r\nconst int base = 'z' - 'a' + 1;\r\nchar *begin = buf + strlen(prefix);\r\nchar *end = buf + buflen;\r\nchar *p;\r\nint unit;\r\np = end - 1;\r\n*p = '\0';\r\nunit = base;\r\ndo {\r\nif (p == begin)\r\nreturn -EINVAL;\r\n*--p = 'a' + (index % unit);\r\nindex = (index / unit) - 1;\r\n} while (index >= 0);\r\nmemmove(begin, p, end - p);\r\nmemcpy(buf, prefix, strlen(prefix));\r\nreturn 0;\r\n}\r\nstatic int virtblk_get_cache_mode(struct virtio_device *vdev)\r\n{\r\nu8 writeback;\r\nint err;\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_CONFIG_WCE,\r\nstruct virtio_blk_config, wce,\r\n&writeback);\r\nif (err)\r\nwriteback = virtio_has_feature(vdev, VIRTIO_BLK_F_WCE);\r\nreturn writeback;\r\n}\r\nstatic void virtblk_update_cache_mode(struct virtio_device *vdev)\r\n{\r\nu8 writeback = virtblk_get_cache_mode(vdev);\r\nstruct virtio_blk *vblk = vdev->priv;\r\nif (writeback)\r\nblk_queue_flush(vblk->disk->queue, REQ_FLUSH);\r\nelse\r\nblk_queue_flush(vblk->disk->queue, 0);\r\nrevalidate_disk(vblk->disk);\r\n}\r\nstatic ssize_t\r\nvirtblk_cache_type_store(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nstruct virtio_blk *vblk = disk->private_data;\r\nstruct virtio_device *vdev = vblk->vdev;\r\nint i;\r\nBUG_ON(!virtio_has_feature(vblk->vdev, VIRTIO_BLK_F_CONFIG_WCE));\r\nfor (i = ARRAY_SIZE(virtblk_cache_types); --i >= 0; )\r\nif (sysfs_streq(buf, virtblk_cache_types[i]))\r\nbreak;\r\nif (i < 0)\r\nreturn -EINVAL;\r\nvirtio_cwrite8(vdev, offsetof(struct virtio_blk_config, wce), i);\r\nvirtblk_update_cache_mode(vdev);\r\nreturn count;\r\n}\r\nstatic ssize_t\r\nvirtblk_cache_type_show(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nstruct virtio_blk *vblk = disk->private_data;\r\nu8 writeback = virtblk_get_cache_mode(vblk->vdev);\r\nBUG_ON(writeback >= ARRAY_SIZE(virtblk_cache_types));\r\nreturn snprintf(buf, 40, "%s\n", virtblk_cache_types[writeback]);\r\n}\r\nstatic int virtblk_init_request(void *data, struct request *rq,\r\nunsigned int hctx_idx, unsigned int request_idx,\r\nunsigned int numa_node)\r\n{\r\nstruct virtio_blk *vblk = data;\r\nstruct virtblk_req *vbr = blk_mq_rq_to_pdu(rq);\r\nsg_init_table(vbr->sg, vblk->sg_elems);\r\nreturn 0;\r\n}\r\nstatic int virtblk_probe(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk;\r\nstruct request_queue *q;\r\nint err, index;\r\nu64 cap;\r\nu32 v, blk_size, sg_elems, opt_io_size;\r\nu16 min_io_size;\r\nu8 physical_block_exp, alignment_offset;\r\nif (!vdev->config->get) {\r\ndev_err(&vdev->dev, "%s failure: config access disabled\n",\r\n__func__);\r\nreturn -EINVAL;\r\n}\r\nerr = ida_simple_get(&vd_index_ida, 0, minor_to_index(1 << MINORBITS),\r\nGFP_KERNEL);\r\nif (err < 0)\r\ngoto out;\r\nindex = err;\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_SEG_MAX,\r\nstruct virtio_blk_config, seg_max,\r\n&sg_elems);\r\nif (err || !sg_elems)\r\nsg_elems = 1;\r\nsg_elems += 2;\r\nvdev->priv = vblk = kmalloc(sizeof(*vblk), GFP_KERNEL);\r\nif (!vblk) {\r\nerr = -ENOMEM;\r\ngoto out_free_index;\r\n}\r\nvblk->vdev = vdev;\r\nvblk->sg_elems = sg_elems;\r\nINIT_WORK(&vblk->config_work, virtblk_config_changed_work);\r\nerr = init_vq(vblk);\r\nif (err)\r\ngoto out_free_vblk;\r\nvblk->disk = alloc_disk(1 << PART_BITS);\r\nif (!vblk->disk) {\r\nerr = -ENOMEM;\r\ngoto out_free_vq;\r\n}\r\nif (!virtblk_queue_depth) {\r\nvirtblk_queue_depth = vblk->vqs[0].vq->num_free;\r\nif (!virtio_has_feature(vdev, VIRTIO_RING_F_INDIRECT_DESC))\r\nvirtblk_queue_depth /= 2;\r\n}\r\nmemset(&vblk->tag_set, 0, sizeof(vblk->tag_set));\r\nvblk->tag_set.ops = &virtio_mq_ops;\r\nvblk->tag_set.queue_depth = virtblk_queue_depth;\r\nvblk->tag_set.numa_node = NUMA_NO_NODE;\r\nvblk->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;\r\nvblk->tag_set.cmd_size =\r\nsizeof(struct virtblk_req) +\r\nsizeof(struct scatterlist) * sg_elems;\r\nvblk->tag_set.driver_data = vblk;\r\nvblk->tag_set.nr_hw_queues = vblk->num_vqs;\r\nerr = blk_mq_alloc_tag_set(&vblk->tag_set);\r\nif (err)\r\ngoto out_put_disk;\r\nq = vblk->disk->queue = blk_mq_init_queue(&vblk->tag_set);\r\nif (IS_ERR(q)) {\r\nerr = -ENOMEM;\r\ngoto out_free_tags;\r\n}\r\nq->queuedata = vblk;\r\nvirtblk_name_format("vd", index, vblk->disk->disk_name, DISK_NAME_LEN);\r\nvblk->disk->major = major;\r\nvblk->disk->first_minor = index_to_minor(index);\r\nvblk->disk->private_data = vblk;\r\nvblk->disk->fops = &virtblk_fops;\r\nvblk->disk->driverfs_dev = &vdev->dev;\r\nvblk->disk->flags |= GENHD_FL_EXT_DEVT;\r\nvblk->index = index;\r\nvirtblk_update_cache_mode(vdev);\r\nif (virtio_has_feature(vdev, VIRTIO_BLK_F_RO))\r\nset_disk_ro(vblk->disk, 1);\r\nvirtio_cread(vdev, struct virtio_blk_config, capacity, &cap);\r\nif ((sector_t)cap != cap) {\r\ndev_warn(&vdev->dev, "Capacity %llu too large: truncating\n",\r\n(unsigned long long)cap);\r\ncap = (sector_t)-1;\r\n}\r\nset_capacity(vblk->disk, cap);\r\nblk_queue_max_segments(q, vblk->sg_elems-2);\r\nblk_queue_bounce_limit(q, BLK_BOUNCE_ANY);\r\nblk_queue_max_hw_sectors(q, -1U);\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_SIZE_MAX,\r\nstruct virtio_blk_config, size_max, &v);\r\nif (!err)\r\nblk_queue_max_segment_size(q, v);\r\nelse\r\nblk_queue_max_segment_size(q, -1U);\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_BLK_SIZE,\r\nstruct virtio_blk_config, blk_size,\r\n&blk_size);\r\nif (!err)\r\nblk_queue_logical_block_size(q, blk_size);\r\nelse\r\nblk_size = queue_logical_block_size(q);\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\nstruct virtio_blk_config, physical_block_exp,\r\n&physical_block_exp);\r\nif (!err && physical_block_exp)\r\nblk_queue_physical_block_size(q,\r\nblk_size * (1 << physical_block_exp));\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\nstruct virtio_blk_config, alignment_offset,\r\n&alignment_offset);\r\nif (!err && alignment_offset)\r\nblk_queue_alignment_offset(q, blk_size * alignment_offset);\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\nstruct virtio_blk_config, min_io_size,\r\n&min_io_size);\r\nif (!err && min_io_size)\r\nblk_queue_io_min(q, blk_size * min_io_size);\r\nerr = virtio_cread_feature(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\nstruct virtio_blk_config, opt_io_size,\r\n&opt_io_size);\r\nif (!err && opt_io_size)\r\nblk_queue_io_opt(q, blk_size * opt_io_size);\r\nvirtio_device_ready(vdev);\r\nadd_disk(vblk->disk);\r\nerr = device_create_file(disk_to_dev(vblk->disk), &dev_attr_serial);\r\nif (err)\r\ngoto out_del_disk;\r\nif (virtio_has_feature(vdev, VIRTIO_BLK_F_CONFIG_WCE))\r\nerr = device_create_file(disk_to_dev(vblk->disk),\r\n&dev_attr_cache_type_rw);\r\nelse\r\nerr = device_create_file(disk_to_dev(vblk->disk),\r\n&dev_attr_cache_type_ro);\r\nif (err)\r\ngoto out_del_disk;\r\nreturn 0;\r\nout_del_disk:\r\ndel_gendisk(vblk->disk);\r\nblk_cleanup_queue(vblk->disk->queue);\r\nout_free_tags:\r\nblk_mq_free_tag_set(&vblk->tag_set);\r\nout_put_disk:\r\nput_disk(vblk->disk);\r\nout_free_vq:\r\nvdev->config->del_vqs(vdev);\r\nout_free_vblk:\r\nkfree(vblk);\r\nout_free_index:\r\nida_simple_remove(&vd_index_ida, index);\r\nout:\r\nreturn err;\r\n}\r\nstatic void virtblk_remove(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nint index = vblk->index;\r\nint refc;\r\nflush_work(&vblk->config_work);\r\ndel_gendisk(vblk->disk);\r\nblk_cleanup_queue(vblk->disk->queue);\r\nblk_mq_free_tag_set(&vblk->tag_set);\r\nvdev->config->reset(vdev);\r\nrefc = atomic_read(&disk_to_dev(vblk->disk)->kobj.kref.refcount);\r\nput_disk(vblk->disk);\r\nvdev->config->del_vqs(vdev);\r\nkfree(vblk->vqs);\r\nkfree(vblk);\r\nif (refc == 1)\r\nida_simple_remove(&vd_index_ida, index);\r\n}\r\nstatic int virtblk_freeze(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nvdev->config->reset(vdev);\r\nflush_work(&vblk->config_work);\r\nblk_mq_stop_hw_queues(vblk->disk->queue);\r\nvdev->config->del_vqs(vdev);\r\nreturn 0;\r\n}\r\nstatic int virtblk_restore(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nint ret;\r\nret = init_vq(vdev->priv);\r\nif (ret)\r\nreturn ret;\r\nvirtio_device_ready(vdev);\r\nblk_mq_start_stopped_hw_queues(vblk->disk->queue, true);\r\nreturn 0;\r\n}\r\nstatic int __init init(void)\r\n{\r\nint error;\r\nvirtblk_wq = alloc_workqueue("virtio-blk", 0, 0);\r\nif (!virtblk_wq)\r\nreturn -ENOMEM;\r\nmajor = register_blkdev(0, "virtblk");\r\nif (major < 0) {\r\nerror = major;\r\ngoto out_destroy_workqueue;\r\n}\r\nerror = register_virtio_driver(&virtio_blk);\r\nif (error)\r\ngoto out_unregister_blkdev;\r\nreturn 0;\r\nout_unregister_blkdev:\r\nunregister_blkdev(major, "virtblk");\r\nout_destroy_workqueue:\r\ndestroy_workqueue(virtblk_wq);\r\nreturn error;\r\n}\r\nstatic void __exit fini(void)\r\n{\r\nunregister_virtio_driver(&virtio_blk);\r\nunregister_blkdev(major, "virtblk");\r\ndestroy_workqueue(virtblk_wq);\r\n}
