static void *esp_alloc_tmp(struct crypto_aead *aead, int nfrags, int seqihlen)\r\n{\r\nunsigned int len;\r\nlen = seqihlen;\r\nlen += crypto_aead_ivsize(aead);\r\nif (len) {\r\nlen += crypto_aead_alignmask(aead) &\r\n~(crypto_tfm_ctx_alignment() - 1);\r\nlen = ALIGN(len, crypto_tfm_ctx_alignment());\r\n}\r\nlen += sizeof(struct aead_request) + crypto_aead_reqsize(aead);\r\nlen = ALIGN(len, __alignof__(struct scatterlist));\r\nlen += sizeof(struct scatterlist) * nfrags;\r\nreturn kmalloc(len, GFP_ATOMIC);\r\n}\r\nstatic inline __be32 *esp_tmp_seqhi(void *tmp)\r\n{\r\nreturn PTR_ALIGN((__be32 *)tmp, __alignof__(__be32));\r\n}\r\nstatic inline u8 *esp_tmp_iv(struct crypto_aead *aead, void *tmp, int seqhilen)\r\n{\r\nreturn crypto_aead_ivsize(aead) ?\r\nPTR_ALIGN((u8 *)tmp + seqhilen,\r\ncrypto_aead_alignmask(aead) + 1) : tmp + seqhilen;\r\n}\r\nstatic inline struct aead_request *esp_tmp_req(struct crypto_aead *aead, u8 *iv)\r\n{\r\nstruct aead_request *req;\r\nreq = (void *)PTR_ALIGN(iv + crypto_aead_ivsize(aead),\r\ncrypto_tfm_ctx_alignment());\r\naead_request_set_tfm(req, aead);\r\nreturn req;\r\n}\r\nstatic inline struct scatterlist *esp_req_sg(struct crypto_aead *aead,\r\nstruct aead_request *req)\r\n{\r\nreturn (void *)ALIGN((unsigned long)(req + 1) +\r\ncrypto_aead_reqsize(aead),\r\n__alignof__(struct scatterlist));\r\n}\r\nstatic void esp_output_done(struct crypto_async_request *base, int err)\r\n{\r\nstruct sk_buff *skb = base->data;\r\nkfree(ESP_SKB_CB(skb)->tmp);\r\nxfrm_output_resume(skb, err);\r\n}\r\nstatic void esp_restore_header(struct sk_buff *skb, unsigned int offset)\r\n{\r\nstruct ip_esp_hdr *esph = (void *)(skb->data + offset);\r\nvoid *tmp = ESP_SKB_CB(skb)->tmp;\r\n__be32 *seqhi = esp_tmp_seqhi(tmp);\r\nesph->seq_no = esph->spi;\r\nesph->spi = *seqhi;\r\n}\r\nstatic void esp_output_restore_header(struct sk_buff *skb)\r\n{\r\nesp_restore_header(skb, skb_transport_offset(skb) - sizeof(__be32));\r\n}\r\nstatic void esp_output_done_esn(struct crypto_async_request *base, int err)\r\n{\r\nstruct sk_buff *skb = base->data;\r\nesp_output_restore_header(skb);\r\nesp_output_done(base, err);\r\n}\r\nstatic int esp6_output(struct xfrm_state *x, struct sk_buff *skb)\r\n{\r\nint err;\r\nstruct ip_esp_hdr *esph;\r\nstruct crypto_aead *aead;\r\nstruct aead_request *req;\r\nstruct scatterlist *sg;\r\nstruct sk_buff *trailer;\r\nvoid *tmp;\r\nint blksize;\r\nint clen;\r\nint alen;\r\nint plen;\r\nint ivlen;\r\nint tfclen;\r\nint nfrags;\r\nint assoclen;\r\nint seqhilen;\r\nu8 *iv;\r\nu8 *tail;\r\n__be32 *seqhi;\r\n__be64 seqno;\r\naead = x->data;\r\nalen = crypto_aead_authsize(aead);\r\nivlen = crypto_aead_ivsize(aead);\r\ntfclen = 0;\r\nif (x->tfcpad) {\r\nstruct xfrm_dst *dst = (struct xfrm_dst *)skb_dst(skb);\r\nu32 padto;\r\npadto = min(x->tfcpad, esp6_get_mtu(x, dst->child_mtu_cached));\r\nif (skb->len < padto)\r\ntfclen = padto - skb->len;\r\n}\r\nblksize = ALIGN(crypto_aead_blocksize(aead), 4);\r\nclen = ALIGN(skb->len + 2 + tfclen, blksize);\r\nplen = clen - skb->len - tfclen;\r\nerr = skb_cow_data(skb, tfclen + plen + alen, &trailer);\r\nif (err < 0)\r\ngoto error;\r\nnfrags = err;\r\nassoclen = sizeof(*esph);\r\nseqhilen = 0;\r\nif (x->props.flags & XFRM_STATE_ESN) {\r\nseqhilen += sizeof(__be32);\r\nassoclen += seqhilen;\r\n}\r\ntmp = esp_alloc_tmp(aead, nfrags, seqhilen);\r\nif (!tmp) {\r\nerr = -ENOMEM;\r\ngoto error;\r\n}\r\nseqhi = esp_tmp_seqhi(tmp);\r\niv = esp_tmp_iv(aead, tmp, seqhilen);\r\nreq = esp_tmp_req(aead, iv);\r\nsg = esp_req_sg(aead, req);\r\ntail = skb_tail_pointer(trailer);\r\nif (tfclen) {\r\nmemset(tail, 0, tfclen);\r\ntail += tfclen;\r\n}\r\ndo {\r\nint i;\r\nfor (i = 0; i < plen - 2; i++)\r\ntail[i] = i + 1;\r\n} while (0);\r\ntail[plen - 2] = plen - 2;\r\ntail[plen - 1] = *skb_mac_header(skb);\r\npskb_put(skb, trailer, clen - skb->len + alen);\r\nskb_push(skb, -skb_network_offset(skb));\r\nesph = ip_esp_hdr(skb);\r\n*skb_mac_header(skb) = IPPROTO_ESP;\r\nesph->seq_no = htonl(XFRM_SKB_CB(skb)->seq.output.low);\r\naead_request_set_callback(req, 0, esp_output_done, skb);\r\nif ((x->props.flags & XFRM_STATE_ESN)) {\r\nesph = (void *)(skb_transport_header(skb) - sizeof(__be32));\r\n*seqhi = esph->spi;\r\nesph->seq_no = htonl(XFRM_SKB_CB(skb)->seq.output.hi);\r\naead_request_set_callback(req, 0, esp_output_done_esn, skb);\r\n}\r\nesph->spi = x->id.spi;\r\nsg_init_table(sg, nfrags);\r\nskb_to_sgvec(skb, sg,\r\n(unsigned char *)esph - skb->data,\r\nassoclen + ivlen + clen + alen);\r\naead_request_set_crypt(req, sg, sg, ivlen + clen, iv);\r\naead_request_set_ad(req, assoclen);\r\nseqno = cpu_to_be64(XFRM_SKB_CB(skb)->seq.output.low +\r\n((u64)XFRM_SKB_CB(skb)->seq.output.hi << 32));\r\nmemset(iv, 0, ivlen);\r\nmemcpy(iv + ivlen - min(ivlen, 8), (u8 *)&seqno + 8 - min(ivlen, 8),\r\nmin(ivlen, 8));\r\nESP_SKB_CB(skb)->tmp = tmp;\r\nerr = crypto_aead_encrypt(req);\r\nswitch (err) {\r\ncase -EINPROGRESS:\r\ngoto error;\r\ncase -EBUSY:\r\nerr = NET_XMIT_DROP;\r\nbreak;\r\ncase 0:\r\nif ((x->props.flags & XFRM_STATE_ESN))\r\nesp_output_restore_header(skb);\r\n}\r\nkfree(tmp);\r\nerror:\r\nreturn err;\r\n}\r\nstatic int esp_input_done2(struct sk_buff *skb, int err)\r\n{\r\nstruct xfrm_state *x = xfrm_input_state(skb);\r\nstruct crypto_aead *aead = x->data;\r\nint alen = crypto_aead_authsize(aead);\r\nint hlen = sizeof(struct ip_esp_hdr) + crypto_aead_ivsize(aead);\r\nint elen = skb->len - hlen;\r\nint hdr_len = skb_network_header_len(skb);\r\nint padlen;\r\nu8 nexthdr[2];\r\nkfree(ESP_SKB_CB(skb)->tmp);\r\nif (unlikely(err))\r\ngoto out;\r\nif (skb_copy_bits(skb, skb->len - alen - 2, nexthdr, 2))\r\nBUG();\r\nerr = -EINVAL;\r\npadlen = nexthdr[0];\r\nif (padlen + 2 + alen >= elen) {\r\nnet_dbg_ratelimited("ipsec esp packet is garbage padlen=%d, elen=%d\n",\r\npadlen + 2, elen - alen);\r\ngoto out;\r\n}\r\npskb_trim(skb, skb->len - alen - padlen - 2);\r\n__skb_pull(skb, hlen);\r\nif (x->props.mode == XFRM_MODE_TUNNEL)\r\nskb_reset_transport_header(skb);\r\nelse\r\nskb_set_transport_header(skb, -hdr_len);\r\nerr = nexthdr[1];\r\nif (err == IPPROTO_NONE)\r\nerr = -EINVAL;\r\nout:\r\nreturn err;\r\n}\r\nstatic void esp_input_done(struct crypto_async_request *base, int err)\r\n{\r\nstruct sk_buff *skb = base->data;\r\nxfrm_input_resume(skb, esp_input_done2(skb, err));\r\n}\r\nstatic void esp_input_restore_header(struct sk_buff *skb)\r\n{\r\nesp_restore_header(skb, 0);\r\n__skb_pull(skb, 4);\r\n}\r\nstatic void esp_input_done_esn(struct crypto_async_request *base, int err)\r\n{\r\nstruct sk_buff *skb = base->data;\r\nesp_input_restore_header(skb);\r\nesp_input_done(base, err);\r\n}\r\nstatic int esp6_input(struct xfrm_state *x, struct sk_buff *skb)\r\n{\r\nstruct ip_esp_hdr *esph;\r\nstruct crypto_aead *aead = x->data;\r\nstruct aead_request *req;\r\nstruct sk_buff *trailer;\r\nint ivlen = crypto_aead_ivsize(aead);\r\nint elen = skb->len - sizeof(*esph) - ivlen;\r\nint nfrags;\r\nint assoclen;\r\nint seqhilen;\r\nint ret = 0;\r\nvoid *tmp;\r\n__be32 *seqhi;\r\nu8 *iv;\r\nstruct scatterlist *sg;\r\nif (!pskb_may_pull(skb, sizeof(*esph) + ivlen)) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nif (elen <= 0) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nnfrags = skb_cow_data(skb, 0, &trailer);\r\nif (nfrags < 0) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nret = -ENOMEM;\r\nassoclen = sizeof(*esph);\r\nseqhilen = 0;\r\nif (x->props.flags & XFRM_STATE_ESN) {\r\nseqhilen += sizeof(__be32);\r\nassoclen += seqhilen;\r\n}\r\ntmp = esp_alloc_tmp(aead, nfrags, seqhilen);\r\nif (!tmp)\r\ngoto out;\r\nESP_SKB_CB(skb)->tmp = tmp;\r\nseqhi = esp_tmp_seqhi(tmp);\r\niv = esp_tmp_iv(aead, tmp, seqhilen);\r\nreq = esp_tmp_req(aead, iv);\r\nsg = esp_req_sg(aead, req);\r\nskb->ip_summed = CHECKSUM_NONE;\r\nesph = (struct ip_esp_hdr *)skb->data;\r\naead_request_set_callback(req, 0, esp_input_done, skb);\r\nif ((x->props.flags & XFRM_STATE_ESN)) {\r\nesph = (void *)skb_push(skb, 4);\r\n*seqhi = esph->spi;\r\nesph->spi = esph->seq_no;\r\nesph->seq_no = htonl(XFRM_SKB_CB(skb)->seq.input.hi);\r\naead_request_set_callback(req, 0, esp_input_done_esn, skb);\r\n}\r\nsg_init_table(sg, nfrags);\r\nskb_to_sgvec(skb, sg, 0, skb->len);\r\naead_request_set_crypt(req, sg, sg, elen + ivlen, iv);\r\naead_request_set_ad(req, assoclen);\r\nret = crypto_aead_decrypt(req);\r\nif (ret == -EINPROGRESS)\r\ngoto out;\r\nif ((x->props.flags & XFRM_STATE_ESN))\r\nesp_input_restore_header(skb);\r\nret = esp_input_done2(skb, ret);\r\nout:\r\nreturn ret;\r\n}\r\nstatic u32 esp6_get_mtu(struct xfrm_state *x, int mtu)\r\n{\r\nstruct crypto_aead *aead = x->data;\r\nu32 blksize = ALIGN(crypto_aead_blocksize(aead), 4);\r\nunsigned int net_adj;\r\nif (x->props.mode != XFRM_MODE_TUNNEL)\r\nnet_adj = sizeof(struct ipv6hdr);\r\nelse\r\nnet_adj = 0;\r\nreturn ((mtu - x->props.header_len - crypto_aead_authsize(aead) -\r\nnet_adj) & ~(blksize - 1)) + net_adj - 2;\r\n}\r\nstatic int esp6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,\r\nu8 type, u8 code, int offset, __be32 info)\r\n{\r\nstruct net *net = dev_net(skb->dev);\r\nconst struct ipv6hdr *iph = (const struct ipv6hdr *)skb->data;\r\nstruct ip_esp_hdr *esph = (struct ip_esp_hdr *)(skb->data + offset);\r\nstruct xfrm_state *x;\r\nif (type != ICMPV6_PKT_TOOBIG &&\r\ntype != NDISC_REDIRECT)\r\nreturn 0;\r\nx = xfrm_state_lookup(net, skb->mark, (const xfrm_address_t *)&iph->daddr,\r\nesph->spi, IPPROTO_ESP, AF_INET6);\r\nif (!x)\r\nreturn 0;\r\nif (type == NDISC_REDIRECT)\r\nip6_redirect(skb, net, skb->dev->ifindex, 0);\r\nelse\r\nip6_update_pmtu(skb, net, info, 0, 0);\r\nxfrm_state_put(x);\r\nreturn 0;\r\n}\r\nstatic void esp6_destroy(struct xfrm_state *x)\r\n{\r\nstruct crypto_aead *aead = x->data;\r\nif (!aead)\r\nreturn;\r\ncrypto_free_aead(aead);\r\n}\r\nstatic int esp_init_aead(struct xfrm_state *x)\r\n{\r\nchar aead_name[CRYPTO_MAX_ALG_NAME];\r\nstruct crypto_aead *aead;\r\nint err;\r\nerr = -ENAMETOOLONG;\r\nif (snprintf(aead_name, CRYPTO_MAX_ALG_NAME, "%s(%s)",\r\nx->geniv, x->aead->alg_name) >= CRYPTO_MAX_ALG_NAME)\r\ngoto error;\r\naead = crypto_alloc_aead(aead_name, 0, 0);\r\nerr = PTR_ERR(aead);\r\nif (IS_ERR(aead))\r\ngoto error;\r\nx->data = aead;\r\nerr = crypto_aead_setkey(aead, x->aead->alg_key,\r\n(x->aead->alg_key_len + 7) / 8);\r\nif (err)\r\ngoto error;\r\nerr = crypto_aead_setauthsize(aead, x->aead->alg_icv_len / 8);\r\nif (err)\r\ngoto error;\r\nerror:\r\nreturn err;\r\n}\r\nstatic int esp_init_authenc(struct xfrm_state *x)\r\n{\r\nstruct crypto_aead *aead;\r\nstruct crypto_authenc_key_param *param;\r\nstruct rtattr *rta;\r\nchar *key;\r\nchar *p;\r\nchar authenc_name[CRYPTO_MAX_ALG_NAME];\r\nunsigned int keylen;\r\nint err;\r\nerr = -EINVAL;\r\nif (!x->ealg)\r\ngoto error;\r\nerr = -ENAMETOOLONG;\r\nif ((x->props.flags & XFRM_STATE_ESN)) {\r\nif (snprintf(authenc_name, CRYPTO_MAX_ALG_NAME,\r\n"%s%sauthencesn(%s,%s)%s",\r\nx->geniv ?: "", x->geniv ? "(" : "",\r\nx->aalg ? x->aalg->alg_name : "digest_null",\r\nx->ealg->alg_name,\r\nx->geniv ? ")" : "") >= CRYPTO_MAX_ALG_NAME)\r\ngoto error;\r\n} else {\r\nif (snprintf(authenc_name, CRYPTO_MAX_ALG_NAME,\r\n"%s%sauthenc(%s,%s)%s",\r\nx->geniv ?: "", x->geniv ? "(" : "",\r\nx->aalg ? x->aalg->alg_name : "digest_null",\r\nx->ealg->alg_name,\r\nx->geniv ? ")" : "") >= CRYPTO_MAX_ALG_NAME)\r\ngoto error;\r\n}\r\naead = crypto_alloc_aead(authenc_name, 0, 0);\r\nerr = PTR_ERR(aead);\r\nif (IS_ERR(aead))\r\ngoto error;\r\nx->data = aead;\r\nkeylen = (x->aalg ? (x->aalg->alg_key_len + 7) / 8 : 0) +\r\n(x->ealg->alg_key_len + 7) / 8 + RTA_SPACE(sizeof(*param));\r\nerr = -ENOMEM;\r\nkey = kmalloc(keylen, GFP_KERNEL);\r\nif (!key)\r\ngoto error;\r\np = key;\r\nrta = (void *)p;\r\nrta->rta_type = CRYPTO_AUTHENC_KEYA_PARAM;\r\nrta->rta_len = RTA_LENGTH(sizeof(*param));\r\nparam = RTA_DATA(rta);\r\np += RTA_SPACE(sizeof(*param));\r\nif (x->aalg) {\r\nstruct xfrm_algo_desc *aalg_desc;\r\nmemcpy(p, x->aalg->alg_key, (x->aalg->alg_key_len + 7) / 8);\r\np += (x->aalg->alg_key_len + 7) / 8;\r\naalg_desc = xfrm_aalg_get_byname(x->aalg->alg_name, 0);\r\nBUG_ON(!aalg_desc);\r\nerr = -EINVAL;\r\nif (aalg_desc->uinfo.auth.icv_fullbits / 8 !=\r\ncrypto_aead_authsize(aead)) {\r\npr_info("ESP: %s digestsize %u != %hu\n",\r\nx->aalg->alg_name,\r\ncrypto_aead_authsize(aead),\r\naalg_desc->uinfo.auth.icv_fullbits / 8);\r\ngoto free_key;\r\n}\r\nerr = crypto_aead_setauthsize(\r\naead, x->aalg->alg_trunc_len / 8);\r\nif (err)\r\ngoto free_key;\r\n}\r\nparam->enckeylen = cpu_to_be32((x->ealg->alg_key_len + 7) / 8);\r\nmemcpy(p, x->ealg->alg_key, (x->ealg->alg_key_len + 7) / 8);\r\nerr = crypto_aead_setkey(aead, key, keylen);\r\nfree_key:\r\nkfree(key);\r\nerror:\r\nreturn err;\r\n}\r\nstatic int esp6_init_state(struct xfrm_state *x)\r\n{\r\nstruct crypto_aead *aead;\r\nu32 align;\r\nint err;\r\nif (x->encap)\r\nreturn -EINVAL;\r\nx->data = NULL;\r\nif (x->aead)\r\nerr = esp_init_aead(x);\r\nelse\r\nerr = esp_init_authenc(x);\r\nif (err)\r\ngoto error;\r\naead = x->data;\r\nx->props.header_len = sizeof(struct ip_esp_hdr) +\r\ncrypto_aead_ivsize(aead);\r\nswitch (x->props.mode) {\r\ncase XFRM_MODE_BEET:\r\nif (x->sel.family != AF_INET6)\r\nx->props.header_len += IPV4_BEET_PHMAXLEN +\r\n(sizeof(struct ipv6hdr) - sizeof(struct iphdr));\r\nbreak;\r\ncase XFRM_MODE_TRANSPORT:\r\nbreak;\r\ncase XFRM_MODE_TUNNEL:\r\nx->props.header_len += sizeof(struct ipv6hdr);\r\nbreak;\r\ndefault:\r\ngoto error;\r\n}\r\nalign = ALIGN(crypto_aead_blocksize(aead), 4);\r\nx->props.trailer_len = align + 1 + crypto_aead_authsize(aead);\r\nerror:\r\nreturn err;\r\n}\r\nstatic int esp6_rcv_cb(struct sk_buff *skb, int err)\r\n{\r\nreturn 0;\r\n}\r\nstatic int __init esp6_init(void)\r\n{\r\nif (xfrm_register_type(&esp6_type, AF_INET6) < 0) {\r\npr_info("%s: can't add xfrm type\n", __func__);\r\nreturn -EAGAIN;\r\n}\r\nif (xfrm6_protocol_register(&esp6_protocol, IPPROTO_ESP) < 0) {\r\npr_info("%s: can't add protocol\n", __func__);\r\nxfrm_unregister_type(&esp6_type, AF_INET6);\r\nreturn -EAGAIN;\r\n}\r\nreturn 0;\r\n}\r\nstatic void __exit esp6_fini(void)\r\n{\r\nif (xfrm6_protocol_deregister(&esp6_protocol, IPPROTO_ESP) < 0)\r\npr_info("%s: can't remove protocol\n", __func__);\r\nif (xfrm_unregister_type(&esp6_type, AF_INET6) < 0)\r\npr_info("%s: can't remove xfrm type\n", __func__);\r\n}
