static struct buffer_head *\r\n__nilfs_get_page_block(struct page *page, unsigned long block, pgoff_t index,\r\nint blkbits, unsigned long b_state)\r\n{\r\nunsigned long first_block;\r\nstruct buffer_head *bh;\r\nif (!page_has_buffers(page))\r\ncreate_empty_buffers(page, 1 << blkbits, b_state);\r\nfirst_block = (unsigned long)index << (PAGE_CACHE_SHIFT - blkbits);\r\nbh = nilfs_page_get_nth_block(page, block - first_block);\r\ntouch_buffer(bh);\r\nwait_on_buffer(bh);\r\nreturn bh;\r\n}\r\nstruct buffer_head *nilfs_grab_buffer(struct inode *inode,\r\nstruct address_space *mapping,\r\nunsigned long blkoff,\r\nunsigned long b_state)\r\n{\r\nint blkbits = inode->i_blkbits;\r\npgoff_t index = blkoff >> (PAGE_CACHE_SHIFT - blkbits);\r\nstruct page *page;\r\nstruct buffer_head *bh;\r\npage = grab_cache_page(mapping, index);\r\nif (unlikely(!page))\r\nreturn NULL;\r\nbh = __nilfs_get_page_block(page, blkoff, index, blkbits, b_state);\r\nif (unlikely(!bh)) {\r\nunlock_page(page);\r\npage_cache_release(page);\r\nreturn NULL;\r\n}\r\nreturn bh;\r\n}\r\nvoid nilfs_forget_buffer(struct buffer_head *bh)\r\n{\r\nstruct page *page = bh->b_page;\r\nconst unsigned long clear_bits =\r\n(1 << BH_Uptodate | 1 << BH_Dirty | 1 << BH_Mapped |\r\n1 << BH_Async_Write | 1 << BH_NILFS_Volatile |\r\n1 << BH_NILFS_Checked | 1 << BH_NILFS_Redirected);\r\nlock_buffer(bh);\r\nset_mask_bits(&bh->b_state, clear_bits, 0);\r\nif (nilfs_page_buffers_clean(page))\r\n__nilfs_clear_page_dirty(page);\r\nbh->b_blocknr = -1;\r\nClearPageUptodate(page);\r\nClearPageMappedToDisk(page);\r\nunlock_buffer(bh);\r\nbrelse(bh);\r\n}\r\nvoid nilfs_copy_buffer(struct buffer_head *dbh, struct buffer_head *sbh)\r\n{\r\nvoid *kaddr0, *kaddr1;\r\nunsigned long bits;\r\nstruct page *spage = sbh->b_page, *dpage = dbh->b_page;\r\nstruct buffer_head *bh;\r\nkaddr0 = kmap_atomic(spage);\r\nkaddr1 = kmap_atomic(dpage);\r\nmemcpy(kaddr1 + bh_offset(dbh), kaddr0 + bh_offset(sbh), sbh->b_size);\r\nkunmap_atomic(kaddr1);\r\nkunmap_atomic(kaddr0);\r\ndbh->b_state = sbh->b_state & NILFS_BUFFER_INHERENT_BITS;\r\ndbh->b_blocknr = sbh->b_blocknr;\r\ndbh->b_bdev = sbh->b_bdev;\r\nbh = dbh;\r\nbits = sbh->b_state & ((1UL << BH_Uptodate) | (1UL << BH_Mapped));\r\nwhile ((bh = bh->b_this_page) != dbh) {\r\nlock_buffer(bh);\r\nbits &= bh->b_state;\r\nunlock_buffer(bh);\r\n}\r\nif (bits & (1UL << BH_Uptodate))\r\nSetPageUptodate(dpage);\r\nelse\r\nClearPageUptodate(dpage);\r\nif (bits & (1UL << BH_Mapped))\r\nSetPageMappedToDisk(dpage);\r\nelse\r\nClearPageMappedToDisk(dpage);\r\n}\r\nint nilfs_page_buffers_clean(struct page *page)\r\n{\r\nstruct buffer_head *bh, *head;\r\nbh = head = page_buffers(page);\r\ndo {\r\nif (buffer_dirty(bh))\r\nreturn 0;\r\nbh = bh->b_this_page;\r\n} while (bh != head);\r\nreturn 1;\r\n}\r\nvoid nilfs_page_bug(struct page *page)\r\n{\r\nstruct address_space *m;\r\nunsigned long ino;\r\nif (unlikely(!page)) {\r\nprintk(KERN_CRIT "NILFS_PAGE_BUG(NULL)\n");\r\nreturn;\r\n}\r\nm = page->mapping;\r\nino = m ? m->host->i_ino : 0;\r\nprintk(KERN_CRIT "NILFS_PAGE_BUG(%p): cnt=%d index#=%llu flags=0x%lx "\r\n"mapping=%p ino=%lu\n",\r\npage, atomic_read(&page->_count),\r\n(unsigned long long)page->index, page->flags, m, ino);\r\nif (page_has_buffers(page)) {\r\nstruct buffer_head *bh, *head;\r\nint i = 0;\r\nbh = head = page_buffers(page);\r\ndo {\r\nprintk(KERN_CRIT\r\n" BH[%d] %p: cnt=%d block#=%llu state=0x%lx\n",\r\ni++, bh, atomic_read(&bh->b_count),\r\n(unsigned long long)bh->b_blocknr, bh->b_state);\r\nbh = bh->b_this_page;\r\n} while (bh != head);\r\n}\r\n}\r\nstatic void nilfs_copy_page(struct page *dst, struct page *src, int copy_dirty)\r\n{\r\nstruct buffer_head *dbh, *dbufs, *sbh, *sbufs;\r\nunsigned long mask = NILFS_BUFFER_INHERENT_BITS;\r\nBUG_ON(PageWriteback(dst));\r\nsbh = sbufs = page_buffers(src);\r\nif (!page_has_buffers(dst))\r\ncreate_empty_buffers(dst, sbh->b_size, 0);\r\nif (copy_dirty)\r\nmask |= (1UL << BH_Dirty);\r\ndbh = dbufs = page_buffers(dst);\r\ndo {\r\nlock_buffer(sbh);\r\nlock_buffer(dbh);\r\ndbh->b_state = sbh->b_state & mask;\r\ndbh->b_blocknr = sbh->b_blocknr;\r\ndbh->b_bdev = sbh->b_bdev;\r\nsbh = sbh->b_this_page;\r\ndbh = dbh->b_this_page;\r\n} while (dbh != dbufs);\r\ncopy_highpage(dst, src);\r\nif (PageUptodate(src) && !PageUptodate(dst))\r\nSetPageUptodate(dst);\r\nelse if (!PageUptodate(src) && PageUptodate(dst))\r\nClearPageUptodate(dst);\r\nif (PageMappedToDisk(src) && !PageMappedToDisk(dst))\r\nSetPageMappedToDisk(dst);\r\nelse if (!PageMappedToDisk(src) && PageMappedToDisk(dst))\r\nClearPageMappedToDisk(dst);\r\ndo {\r\nunlock_buffer(sbh);\r\nunlock_buffer(dbh);\r\nsbh = sbh->b_this_page;\r\ndbh = dbh->b_this_page;\r\n} while (dbh != dbufs);\r\n}\r\nint nilfs_copy_dirty_pages(struct address_space *dmap,\r\nstruct address_space *smap)\r\n{\r\nstruct pagevec pvec;\r\nunsigned int i;\r\npgoff_t index = 0;\r\nint err = 0;\r\npagevec_init(&pvec, 0);\r\nrepeat:\r\nif (!pagevec_lookup_tag(&pvec, smap, &index, PAGECACHE_TAG_DIRTY,\r\nPAGEVEC_SIZE))\r\nreturn 0;\r\nfor (i = 0; i < pagevec_count(&pvec); i++) {\r\nstruct page *page = pvec.pages[i], *dpage;\r\nlock_page(page);\r\nif (unlikely(!PageDirty(page)))\r\nNILFS_PAGE_BUG(page, "inconsistent dirty state");\r\ndpage = grab_cache_page(dmap, page->index);\r\nif (unlikely(!dpage)) {\r\nerr = -ENOMEM;\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (unlikely(!page_has_buffers(page)))\r\nNILFS_PAGE_BUG(page,\r\n"found empty page in dat page cache");\r\nnilfs_copy_page(dpage, page, 1);\r\n__set_page_dirty_nobuffers(dpage);\r\nunlock_page(dpage);\r\npage_cache_release(dpage);\r\nunlock_page(page);\r\n}\r\npagevec_release(&pvec);\r\ncond_resched();\r\nif (likely(!err))\r\ngoto repeat;\r\nreturn err;\r\n}\r\nvoid nilfs_copy_back_pages(struct address_space *dmap,\r\nstruct address_space *smap)\r\n{\r\nstruct pagevec pvec;\r\nunsigned int i, n;\r\npgoff_t index = 0;\r\nint err;\r\npagevec_init(&pvec, 0);\r\nrepeat:\r\nn = pagevec_lookup(&pvec, smap, index, PAGEVEC_SIZE);\r\nif (!n)\r\nreturn;\r\nindex = pvec.pages[n - 1]->index + 1;\r\nfor (i = 0; i < pagevec_count(&pvec); i++) {\r\nstruct page *page = pvec.pages[i], *dpage;\r\npgoff_t offset = page->index;\r\nlock_page(page);\r\ndpage = find_lock_page(dmap, offset);\r\nif (dpage) {\r\nWARN_ON(PageDirty(dpage));\r\nnilfs_copy_page(dpage, page, 0);\r\nunlock_page(dpage);\r\npage_cache_release(dpage);\r\n} else {\r\nstruct page *page2;\r\nspin_lock_irq(&smap->tree_lock);\r\npage2 = radix_tree_delete(&smap->page_tree, offset);\r\nWARN_ON(page2 != page);\r\nsmap->nrpages--;\r\nspin_unlock_irq(&smap->tree_lock);\r\nspin_lock_irq(&dmap->tree_lock);\r\nerr = radix_tree_insert(&dmap->page_tree, offset, page);\r\nif (unlikely(err < 0)) {\r\nWARN_ON(err == -EEXIST);\r\npage->mapping = NULL;\r\npage_cache_release(page);\r\n} else {\r\npage->mapping = dmap;\r\ndmap->nrpages++;\r\nif (PageDirty(page))\r\nradix_tree_tag_set(&dmap->page_tree,\r\noffset,\r\nPAGECACHE_TAG_DIRTY);\r\n}\r\nspin_unlock_irq(&dmap->tree_lock);\r\n}\r\nunlock_page(page);\r\n}\r\npagevec_release(&pvec);\r\ncond_resched();\r\ngoto repeat;\r\n}\r\nvoid nilfs_clear_dirty_pages(struct address_space *mapping, bool silent)\r\n{\r\nstruct pagevec pvec;\r\nunsigned int i;\r\npgoff_t index = 0;\r\npagevec_init(&pvec, 0);\r\nwhile (pagevec_lookup_tag(&pvec, mapping, &index, PAGECACHE_TAG_DIRTY,\r\nPAGEVEC_SIZE)) {\r\nfor (i = 0; i < pagevec_count(&pvec); i++) {\r\nstruct page *page = pvec.pages[i];\r\nlock_page(page);\r\nnilfs_clear_dirty_page(page, silent);\r\nunlock_page(page);\r\n}\r\npagevec_release(&pvec);\r\ncond_resched();\r\n}\r\n}\r\nvoid nilfs_clear_dirty_page(struct page *page, bool silent)\r\n{\r\nstruct inode *inode = page->mapping->host;\r\nstruct super_block *sb = inode->i_sb;\r\nBUG_ON(!PageLocked(page));\r\nif (!silent) {\r\nnilfs_warning(sb, __func__,\r\n"discard page: offset %lld, ino %lu",\r\npage_offset(page), inode->i_ino);\r\n}\r\nClearPageUptodate(page);\r\nClearPageMappedToDisk(page);\r\nif (page_has_buffers(page)) {\r\nstruct buffer_head *bh, *head;\r\nconst unsigned long clear_bits =\r\n(1 << BH_Uptodate | 1 << BH_Dirty | 1 << BH_Mapped |\r\n1 << BH_Async_Write | 1 << BH_NILFS_Volatile |\r\n1 << BH_NILFS_Checked | 1 << BH_NILFS_Redirected);\r\nbh = head = page_buffers(page);\r\ndo {\r\nlock_buffer(bh);\r\nif (!silent) {\r\nnilfs_warning(sb, __func__,\r\n"discard block %llu, size %zu",\r\n(u64)bh->b_blocknr, bh->b_size);\r\n}\r\nset_mask_bits(&bh->b_state, clear_bits, 0);\r\nunlock_buffer(bh);\r\n} while (bh = bh->b_this_page, bh != head);\r\n}\r\n__nilfs_clear_page_dirty(page);\r\n}\r\nunsigned nilfs_page_count_clean_buffers(struct page *page,\r\nunsigned from, unsigned to)\r\n{\r\nunsigned block_start, block_end;\r\nstruct buffer_head *bh, *head;\r\nunsigned nc = 0;\r\nfor (bh = head = page_buffers(page), block_start = 0;\r\nbh != head || !block_start;\r\nblock_start = block_end, bh = bh->b_this_page) {\r\nblock_end = block_start + bh->b_size;\r\nif (block_end > from && block_start < to && !buffer_dirty(bh))\r\nnc++;\r\n}\r\nreturn nc;\r\n}\r\nvoid nilfs_mapping_init(struct address_space *mapping, struct inode *inode)\r\n{\r\nmapping->host = inode;\r\nmapping->flags = 0;\r\nmapping_set_gfp_mask(mapping, GFP_NOFS);\r\nmapping->private_data = NULL;\r\nmapping->a_ops = &empty_aops;\r\n}\r\nint __nilfs_clear_page_dirty(struct page *page)\r\n{\r\nstruct address_space *mapping = page->mapping;\r\nif (mapping) {\r\nspin_lock_irq(&mapping->tree_lock);\r\nif (test_bit(PG_dirty, &page->flags)) {\r\nradix_tree_tag_clear(&mapping->page_tree,\r\npage_index(page),\r\nPAGECACHE_TAG_DIRTY);\r\nspin_unlock_irq(&mapping->tree_lock);\r\nreturn clear_page_dirty_for_io(page);\r\n}\r\nspin_unlock_irq(&mapping->tree_lock);\r\nreturn 0;\r\n}\r\nreturn TestClearPageDirty(page);\r\n}\r\nunsigned long nilfs_find_uncommitted_extent(struct inode *inode,\r\nsector_t start_blk,\r\nsector_t *blkoff)\r\n{\r\nunsigned int i;\r\npgoff_t index;\r\nunsigned int nblocks_in_page;\r\nunsigned long length = 0;\r\nsector_t b;\r\nstruct pagevec pvec;\r\nstruct page *page;\r\nif (inode->i_mapping->nrpages == 0)\r\nreturn 0;\r\nindex = start_blk >> (PAGE_CACHE_SHIFT - inode->i_blkbits);\r\nnblocks_in_page = 1U << (PAGE_CACHE_SHIFT - inode->i_blkbits);\r\npagevec_init(&pvec, 0);\r\nrepeat:\r\npvec.nr = find_get_pages_contig(inode->i_mapping, index, PAGEVEC_SIZE,\r\npvec.pages);\r\nif (pvec.nr == 0)\r\nreturn length;\r\nif (length > 0 && pvec.pages[0]->index > index)\r\ngoto out;\r\nb = pvec.pages[0]->index << (PAGE_CACHE_SHIFT - inode->i_blkbits);\r\ni = 0;\r\ndo {\r\npage = pvec.pages[i];\r\nlock_page(page);\r\nif (page_has_buffers(page)) {\r\nstruct buffer_head *bh, *head;\r\nbh = head = page_buffers(page);\r\ndo {\r\nif (b < start_blk)\r\ncontinue;\r\nif (buffer_delay(bh)) {\r\nif (length == 0)\r\n*blkoff = b;\r\nlength++;\r\n} else if (length > 0) {\r\ngoto out_locked;\r\n}\r\n} while (++b, bh = bh->b_this_page, bh != head);\r\n} else {\r\nif (length > 0)\r\ngoto out_locked;\r\nb += nblocks_in_page;\r\n}\r\nunlock_page(page);\r\n} while (++i < pagevec_count(&pvec));\r\nindex = page->index + 1;\r\npagevec_release(&pvec);\r\ncond_resched();\r\ngoto repeat;\r\nout_locked:\r\nunlock_page(page);\r\nout:\r\npagevec_release(&pvec);\r\nreturn length;\r\n}
