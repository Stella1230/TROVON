static inline struct pnfs_block_extent *\r\next_node(struct rb_node *node)\r\n{\r\nreturn rb_entry(node, struct pnfs_block_extent, be_node);\r\n}\r\nstatic struct pnfs_block_extent *\r\next_tree_first(struct rb_root *root)\r\n{\r\nstruct rb_node *node = rb_first(root);\r\nreturn node ? ext_node(node) : NULL;\r\n}\r\nstatic struct pnfs_block_extent *\r\next_tree_prev(struct pnfs_block_extent *be)\r\n{\r\nstruct rb_node *node = rb_prev(&be->be_node);\r\nreturn node ? ext_node(node) : NULL;\r\n}\r\nstatic struct pnfs_block_extent *\r\next_tree_next(struct pnfs_block_extent *be)\r\n{\r\nstruct rb_node *node = rb_next(&be->be_node);\r\nreturn node ? ext_node(node) : NULL;\r\n}\r\nstatic inline sector_t\r\next_f_end(struct pnfs_block_extent *be)\r\n{\r\nreturn be->be_f_offset + be->be_length;\r\n}\r\nstatic struct pnfs_block_extent *\r\n__ext_tree_search(struct rb_root *root, sector_t start)\r\n{\r\nstruct rb_node *node = root->rb_node;\r\nstruct pnfs_block_extent *be = NULL;\r\nwhile (node) {\r\nbe = ext_node(node);\r\nif (start < be->be_f_offset)\r\nnode = node->rb_left;\r\nelse if (start >= ext_f_end(be))\r\nnode = node->rb_right;\r\nelse\r\nreturn be;\r\n}\r\nif (be) {\r\nif (start < be->be_f_offset)\r\nreturn be;\r\nif (start >= ext_f_end(be))\r\nreturn ext_tree_next(be);\r\n}\r\nreturn NULL;\r\n}\r\nstatic bool\r\next_can_merge(struct pnfs_block_extent *be1, struct pnfs_block_extent *be2)\r\n{\r\nif (be1->be_state != be2->be_state)\r\nreturn false;\r\nif (be1->be_device != be2->be_device)\r\nreturn false;\r\nif (be1->be_f_offset + be1->be_length != be2->be_f_offset)\r\nreturn false;\r\nif (be1->be_state != PNFS_BLOCK_NONE_DATA &&\r\n(be1->be_v_offset + be1->be_length != be2->be_v_offset))\r\nreturn false;\r\nif (be1->be_state == PNFS_BLOCK_INVALID_DATA &&\r\nbe1->be_tag != be2->be_tag)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic struct pnfs_block_extent *\r\next_try_to_merge_left(struct rb_root *root, struct pnfs_block_extent *be)\r\n{\r\nstruct pnfs_block_extent *left = ext_tree_prev(be);\r\nif (left && ext_can_merge(left, be)) {\r\nleft->be_length += be->be_length;\r\nrb_erase(&be->be_node, root);\r\nnfs4_put_deviceid_node(be->be_device);\r\nkfree(be);\r\nreturn left;\r\n}\r\nreturn be;\r\n}\r\nstatic struct pnfs_block_extent *\r\next_try_to_merge_right(struct rb_root *root, struct pnfs_block_extent *be)\r\n{\r\nstruct pnfs_block_extent *right = ext_tree_next(be);\r\nif (right && ext_can_merge(be, right)) {\r\nbe->be_length += right->be_length;\r\nrb_erase(&right->be_node, root);\r\nnfs4_put_deviceid_node(right->be_device);\r\nkfree(right);\r\n}\r\nreturn be;\r\n}\r\nstatic void\r\n__ext_tree_insert(struct rb_root *root,\r\nstruct pnfs_block_extent *new, bool merge_ok)\r\n{\r\nstruct rb_node **p = &root->rb_node, *parent = NULL;\r\nstruct pnfs_block_extent *be;\r\nwhile (*p) {\r\nparent = *p;\r\nbe = ext_node(parent);\r\nif (new->be_f_offset < be->be_f_offset) {\r\nif (merge_ok && ext_can_merge(new, be)) {\r\nbe->be_f_offset = new->be_f_offset;\r\nif (be->be_state != PNFS_BLOCK_NONE_DATA)\r\nbe->be_v_offset = new->be_v_offset;\r\nbe->be_length += new->be_length;\r\nbe = ext_try_to_merge_left(root, be);\r\ngoto free_new;\r\n}\r\np = &(*p)->rb_left;\r\n} else if (new->be_f_offset >= ext_f_end(be)) {\r\nif (merge_ok && ext_can_merge(be, new)) {\r\nbe->be_length += new->be_length;\r\nbe = ext_try_to_merge_right(root, be);\r\ngoto free_new;\r\n}\r\np = &(*p)->rb_right;\r\n} else {\r\nBUG();\r\n}\r\n}\r\nrb_link_node(&new->be_node, parent, p);\r\nrb_insert_color(&new->be_node, root);\r\nreturn;\r\nfree_new:\r\nnfs4_put_deviceid_node(new->be_device);\r\nkfree(new);\r\n}\r\nstatic int\r\n__ext_tree_remove(struct rb_root *root, sector_t start, sector_t end)\r\n{\r\nstruct pnfs_block_extent *be;\r\nsector_t len1 = 0, len2 = 0;\r\nsector_t orig_v_offset;\r\nsector_t orig_len;\r\nbe = __ext_tree_search(root, start);\r\nif (!be)\r\nreturn 0;\r\nif (be->be_f_offset >= end)\r\nreturn 0;\r\norig_v_offset = be->be_v_offset;\r\norig_len = be->be_length;\r\nif (start > be->be_f_offset)\r\nlen1 = start - be->be_f_offset;\r\nif (ext_f_end(be) > end)\r\nlen2 = ext_f_end(be) - end;\r\nif (len2 > 0) {\r\nif (len1 > 0) {\r\nstruct pnfs_block_extent *new;\r\nnew = kzalloc(sizeof(*new), GFP_ATOMIC);\r\nif (!new)\r\nreturn -ENOMEM;\r\nbe->be_length = len1;\r\nnew->be_f_offset = end;\r\nif (be->be_state != PNFS_BLOCK_NONE_DATA) {\r\nnew->be_v_offset =\r\norig_v_offset + orig_len - len2;\r\n}\r\nnew->be_length = len2;\r\nnew->be_state = be->be_state;\r\nnew->be_tag = be->be_tag;\r\nnew->be_device = nfs4_get_deviceid(be->be_device);\r\n__ext_tree_insert(root, new, true);\r\n} else {\r\nbe->be_f_offset = end;\r\nif (be->be_state != PNFS_BLOCK_NONE_DATA) {\r\nbe->be_v_offset =\r\norig_v_offset + orig_len - len2;\r\n}\r\nbe->be_length = len2;\r\n}\r\n} else {\r\nif (len1 > 0) {\r\nbe->be_length = len1;\r\nbe = ext_tree_next(be);\r\n}\r\nwhile (be && ext_f_end(be) <= end) {\r\nstruct pnfs_block_extent *next = ext_tree_next(be);\r\nrb_erase(&be->be_node, root);\r\nnfs4_put_deviceid_node(be->be_device);\r\nkfree(be);\r\nbe = next;\r\n}\r\nif (be && be->be_f_offset < end) {\r\nlen1 = ext_f_end(be) - end;\r\nbe->be_f_offset = end;\r\nif (be->be_state != PNFS_BLOCK_NONE_DATA)\r\nbe->be_v_offset += be->be_length - len1;\r\nbe->be_length = len1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint\r\next_tree_insert(struct pnfs_block_layout *bl, struct pnfs_block_extent *new)\r\n{\r\nstruct pnfs_block_extent *be;\r\nstruct rb_root *root;\r\nint err = 0;\r\nswitch (new->be_state) {\r\ncase PNFS_BLOCK_READWRITE_DATA:\r\ncase PNFS_BLOCK_INVALID_DATA:\r\nroot = &bl->bl_ext_rw;\r\nbreak;\r\ncase PNFS_BLOCK_READ_DATA:\r\ncase PNFS_BLOCK_NONE_DATA:\r\nroot = &bl->bl_ext_ro;\r\nbreak;\r\ndefault:\r\ndprintk("invalid extent type\n");\r\nreturn -EINVAL;\r\n}\r\nspin_lock(&bl->bl_ext_lock);\r\nretry:\r\nbe = __ext_tree_search(root, new->be_f_offset);\r\nif (!be || be->be_f_offset >= ext_f_end(new)) {\r\n__ext_tree_insert(root, new, true);\r\n} else if (new->be_f_offset >= be->be_f_offset) {\r\nif (ext_f_end(new) <= ext_f_end(be)) {\r\nnfs4_put_deviceid_node(new->be_device);\r\nkfree(new);\r\n} else {\r\nsector_t new_len = ext_f_end(new) - ext_f_end(be);\r\nsector_t diff = new->be_length - new_len;\r\nnew->be_f_offset += diff;\r\nnew->be_v_offset += diff;\r\nnew->be_length = new_len;\r\ngoto retry;\r\n}\r\n} else if (ext_f_end(new) <= ext_f_end(be)) {\r\nnew->be_length = be->be_f_offset - new->be_f_offset;\r\n__ext_tree_insert(root, new, true);\r\n} else {\r\nstruct pnfs_block_extent *split;\r\nsector_t new_len = ext_f_end(new) - ext_f_end(be);\r\nsector_t diff = new->be_length - new_len;\r\nsplit = kmemdup(new, sizeof(*new), GFP_ATOMIC);\r\nif (!split) {\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\nsplit->be_length = be->be_f_offset - split->be_f_offset;\r\nsplit->be_device = nfs4_get_deviceid(new->be_device);\r\n__ext_tree_insert(root, split, true);\r\nnew->be_f_offset += diff;\r\nnew->be_v_offset += diff;\r\nnew->be_length = new_len;\r\ngoto retry;\r\n}\r\nout:\r\nspin_unlock(&bl->bl_ext_lock);\r\nreturn err;\r\n}\r\nstatic bool\r\n__ext_tree_lookup(struct rb_root *root, sector_t isect,\r\nstruct pnfs_block_extent *ret)\r\n{\r\nstruct rb_node *node;\r\nstruct pnfs_block_extent *be;\r\nnode = root->rb_node;\r\nwhile (node) {\r\nbe = ext_node(node);\r\nif (isect < be->be_f_offset)\r\nnode = node->rb_left;\r\nelse if (isect >= ext_f_end(be))\r\nnode = node->rb_right;\r\nelse {\r\n*ret = *be;\r\nreturn true;\r\n}\r\n}\r\nreturn false;\r\n}\r\nbool\r\next_tree_lookup(struct pnfs_block_layout *bl, sector_t isect,\r\nstruct pnfs_block_extent *ret, bool rw)\r\n{\r\nbool found = false;\r\nspin_lock(&bl->bl_ext_lock);\r\nif (!rw)\r\nfound = __ext_tree_lookup(&bl->bl_ext_ro, isect, ret);\r\nif (!found)\r\nfound = __ext_tree_lookup(&bl->bl_ext_rw, isect, ret);\r\nspin_unlock(&bl->bl_ext_lock);\r\nreturn found;\r\n}\r\nint ext_tree_remove(struct pnfs_block_layout *bl, bool rw,\r\nsector_t start, sector_t end)\r\n{\r\nint err, err2;\r\nspin_lock(&bl->bl_ext_lock);\r\nerr = __ext_tree_remove(&bl->bl_ext_ro, start, end);\r\nif (rw) {\r\nerr2 = __ext_tree_remove(&bl->bl_ext_rw, start, end);\r\nif (!err)\r\nerr = err2;\r\n}\r\nspin_unlock(&bl->bl_ext_lock);\r\nreturn err;\r\n}\r\nstatic int\r\next_tree_split(struct rb_root *root, struct pnfs_block_extent *be,\r\nsector_t split)\r\n{\r\nstruct pnfs_block_extent *new;\r\nsector_t orig_len = be->be_length;\r\nnew = kzalloc(sizeof(*new), GFP_ATOMIC);\r\nif (!new)\r\nreturn -ENOMEM;\r\nbe->be_length = split - be->be_f_offset;\r\nnew->be_f_offset = split;\r\nif (be->be_state != PNFS_BLOCK_NONE_DATA)\r\nnew->be_v_offset = be->be_v_offset + be->be_length;\r\nnew->be_length = orig_len - be->be_length;\r\nnew->be_state = be->be_state;\r\nnew->be_tag = be->be_tag;\r\nnew->be_device = nfs4_get_deviceid(be->be_device);\r\n__ext_tree_insert(root, new, false);\r\nreturn 0;\r\n}\r\nint\r\next_tree_mark_written(struct pnfs_block_layout *bl, sector_t start,\r\nsector_t len)\r\n{\r\nstruct rb_root *root = &bl->bl_ext_rw;\r\nsector_t end = start + len;\r\nstruct pnfs_block_extent *be;\r\nint err = 0;\r\nspin_lock(&bl->bl_ext_lock);\r\nerr = __ext_tree_remove(&bl->bl_ext_ro, start, end);\r\nif (err)\r\ngoto out;\r\nfor (be = __ext_tree_search(root, start); be; be = ext_tree_next(be)) {\r\nif (be->be_f_offset >= end)\r\nbreak;\r\nif (be->be_state != PNFS_BLOCK_INVALID_DATA || be->be_tag)\r\ncontinue;\r\nif (be->be_f_offset < start) {\r\nstruct pnfs_block_extent *left = ext_tree_prev(be);\r\nif (left && ext_can_merge(left, be)) {\r\nsector_t diff = start - be->be_f_offset;\r\nleft->be_length += diff;\r\nbe->be_f_offset += diff;\r\nbe->be_v_offset += diff;\r\nbe->be_length -= diff;\r\n} else {\r\nerr = ext_tree_split(root, be, start);\r\nif (err)\r\ngoto out;\r\n}\r\n}\r\nif (ext_f_end(be) > end) {\r\nstruct pnfs_block_extent *right = ext_tree_next(be);\r\nif (right && ext_can_merge(be, right)) {\r\nsector_t diff = end - be->be_f_offset;\r\nbe->be_length -= diff;\r\nright->be_f_offset -= diff;\r\nright->be_v_offset -= diff;\r\nright->be_length += diff;\r\n} else {\r\nerr = ext_tree_split(root, be, end);\r\nif (err)\r\ngoto out;\r\n}\r\n}\r\nif (be->be_f_offset >= start && ext_f_end(be) <= end) {\r\nbe->be_tag = EXTENT_WRITTEN;\r\nbe = ext_try_to_merge_left(root, be);\r\nbe = ext_try_to_merge_right(root, be);\r\n}\r\n}\r\nout:\r\nspin_unlock(&bl->bl_ext_lock);\r\nreturn err;\r\n}\r\nstatic size_t ext_tree_layoutupdate_size(size_t count)\r\n{\r\nreturn sizeof(__be32) +\r\nPNFS_BLOCK_EXTENT_SIZE * count;\r\n}\r\nstatic void ext_tree_free_commitdata(struct nfs4_layoutcommit_args *arg,\r\nsize_t buffer_size)\r\n{\r\nif (arg->layoutupdate_pages != &arg->layoutupdate_page) {\r\nint nr_pages = DIV_ROUND_UP(buffer_size, PAGE_SIZE), i;\r\nfor (i = 0; i < nr_pages; i++)\r\nput_page(arg->layoutupdate_pages[i]);\r\nkfree(arg->layoutupdate_pages);\r\n} else {\r\nput_page(arg->layoutupdate_page);\r\n}\r\n}\r\nstatic int ext_tree_encode_commit(struct pnfs_block_layout *bl, __be32 *p,\r\nsize_t buffer_size, size_t *count)\r\n{\r\nstruct pnfs_block_extent *be;\r\nint ret = 0;\r\nspin_lock(&bl->bl_ext_lock);\r\nfor (be = ext_tree_first(&bl->bl_ext_rw); be; be = ext_tree_next(be)) {\r\nif (be->be_state != PNFS_BLOCK_INVALID_DATA ||\r\nbe->be_tag != EXTENT_WRITTEN)\r\ncontinue;\r\n(*count)++;\r\nif (ext_tree_layoutupdate_size(*count) > buffer_size) {\r\nret = -ENOSPC;\r\ncontinue;\r\n}\r\np = xdr_encode_opaque_fixed(p, be->be_device->deviceid.data,\r\nNFS4_DEVICEID4_SIZE);\r\np = xdr_encode_hyper(p, be->be_f_offset << SECTOR_SHIFT);\r\np = xdr_encode_hyper(p, be->be_length << SECTOR_SHIFT);\r\np = xdr_encode_hyper(p, 0LL);\r\n*p++ = cpu_to_be32(PNFS_BLOCK_READWRITE_DATA);\r\nbe->be_tag = EXTENT_COMMITTING;\r\n}\r\nspin_unlock(&bl->bl_ext_lock);\r\nreturn ret;\r\n}\r\nint\r\next_tree_prepare_commit(struct nfs4_layoutcommit_args *arg)\r\n{\r\nstruct pnfs_block_layout *bl = BLK_LO2EXT(NFS_I(arg->inode)->layout);\r\nsize_t count = 0, buffer_size = PAGE_SIZE;\r\n__be32 *start_p;\r\nint ret;\r\ndprintk("%s enter\n", __func__);\r\narg->layoutupdate_page = alloc_page(GFP_NOFS);\r\nif (!arg->layoutupdate_page)\r\nreturn -ENOMEM;\r\nstart_p = page_address(arg->layoutupdate_page);\r\narg->layoutupdate_pages = &arg->layoutupdate_page;\r\nretry:\r\nret = ext_tree_encode_commit(bl, start_p + 1, buffer_size, &count);\r\nif (unlikely(ret)) {\r\next_tree_free_commitdata(arg, buffer_size);\r\nbuffer_size = ext_tree_layoutupdate_size(count);\r\ncount = 0;\r\narg->layoutupdate_pages =\r\nkcalloc(DIV_ROUND_UP(buffer_size, PAGE_SIZE),\r\nsizeof(struct page *), GFP_NOFS);\r\nif (!arg->layoutupdate_pages)\r\nreturn -ENOMEM;\r\nstart_p = __vmalloc(buffer_size, GFP_NOFS, PAGE_KERNEL);\r\nif (!start_p) {\r\nkfree(arg->layoutupdate_pages);\r\nreturn -ENOMEM;\r\n}\r\ngoto retry;\r\n}\r\n*start_p = cpu_to_be32(count);\r\narg->layoutupdate_len = ext_tree_layoutupdate_size(count);\r\nif (unlikely(arg->layoutupdate_pages != &arg->layoutupdate_page)) {\r\nvoid *p = start_p, *end = p + arg->layoutupdate_len;\r\nint i = 0;\r\nfor ( ; p < end; p += PAGE_SIZE)\r\narg->layoutupdate_pages[i++] = vmalloc_to_page(p);\r\n}\r\ndprintk("%s found %zu ranges\n", __func__, count);\r\nreturn 0;\r\n}\r\nvoid\r\next_tree_mark_committed(struct nfs4_layoutcommit_args *arg, int status)\r\n{\r\nstruct pnfs_block_layout *bl = BLK_LO2EXT(NFS_I(arg->inode)->layout);\r\nstruct rb_root *root = &bl->bl_ext_rw;\r\nstruct pnfs_block_extent *be;\r\ndprintk("%s status %d\n", __func__, status);\r\next_tree_free_commitdata(arg, arg->layoutupdate_len);\r\nspin_lock(&bl->bl_ext_lock);\r\nfor (be = ext_tree_first(root); be; be = ext_tree_next(be)) {\r\nif (be->be_state != PNFS_BLOCK_INVALID_DATA ||\r\nbe->be_tag != EXTENT_COMMITTING)\r\ncontinue;\r\nif (status) {\r\nbe->be_tag = EXTENT_WRITTEN;\r\n} else {\r\nbe->be_state = PNFS_BLOCK_READWRITE_DATA;\r\nbe->be_tag = 0;\r\n}\r\nbe = ext_try_to_merge_left(root, be);\r\nbe = ext_try_to_merge_right(root, be);\r\n}\r\nspin_unlock(&bl->bl_ext_lock);\r\n}
