static void hyperv_report_panic(struct pt_regs *regs)\r\n{\r\nstatic bool panic_reported;\r\nif (panic_reported)\r\nreturn;\r\npanic_reported = true;\r\nwrmsrl(HV_X64_MSR_CRASH_P0, regs->ip);\r\nwrmsrl(HV_X64_MSR_CRASH_P1, regs->ax);\r\nwrmsrl(HV_X64_MSR_CRASH_P2, regs->bx);\r\nwrmsrl(HV_X64_MSR_CRASH_P3, regs->cx);\r\nwrmsrl(HV_X64_MSR_CRASH_P4, regs->dx);\r\nwrmsrl(HV_X64_MSR_CRASH_CTL, HV_CRASH_CTL_CRASH_NOTIFY);\r\n}\r\nstatic int hyperv_panic_event(struct notifier_block *nb, unsigned long val,\r\nvoid *args)\r\n{\r\nstruct pt_regs *regs;\r\nregs = current_pt_regs();\r\nhyperv_report_panic(regs);\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int hyperv_die_event(struct notifier_block *nb, unsigned long val,\r\nvoid *args)\r\n{\r\nstruct die_args *die = (struct die_args *)args;\r\nstruct pt_regs *regs = die->regs;\r\nhyperv_report_panic(regs);\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int vmbus_exists(void)\r\n{\r\nif (hv_acpi_dev == NULL)\r\nreturn -ENODEV;\r\nreturn 0;\r\n}\r\nstatic void print_alias_name(struct hv_device *hv_dev, char *alias_name)\r\n{\r\nint i;\r\nfor (i = 0; i < VMBUS_ALIAS_LEN; i += 2)\r\nsprintf(&alias_name[i], "%02x", hv_dev->dev_type.b[i/2]);\r\n}\r\nstatic u8 channel_monitor_group(struct vmbus_channel *channel)\r\n{\r\nreturn (u8)channel->offermsg.monitorid / 32;\r\n}\r\nstatic u8 channel_monitor_offset(struct vmbus_channel *channel)\r\n{\r\nreturn (u8)channel->offermsg.monitorid % 32;\r\n}\r\nstatic u32 channel_pending(struct vmbus_channel *channel,\r\nstruct hv_monitor_page *monitor_page)\r\n{\r\nu8 monitor_group = channel_monitor_group(channel);\r\nreturn monitor_page->trigger_group[monitor_group].pending;\r\n}\r\nstatic u32 channel_latency(struct vmbus_channel *channel,\r\nstruct hv_monitor_page *monitor_page)\r\n{\r\nu8 monitor_group = channel_monitor_group(channel);\r\nu8 monitor_offset = channel_monitor_offset(channel);\r\nreturn monitor_page->latency[monitor_group][monitor_offset];\r\n}\r\nstatic u32 channel_conn_id(struct vmbus_channel *channel,\r\nstruct hv_monitor_page *monitor_page)\r\n{\r\nu8 monitor_group = channel_monitor_group(channel);\r\nu8 monitor_offset = channel_monitor_offset(channel);\r\nreturn monitor_page->parameter[monitor_group][monitor_offset].connectionid.u.id;\r\n}\r\nstatic ssize_t id_show(struct device *dev, struct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n", hv_dev->channel->offermsg.child_relid);\r\n}\r\nstatic ssize_t state_show(struct device *dev, struct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n", hv_dev->channel->state);\r\n}\r\nstatic ssize_t monitor_id_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n", hv_dev->channel->offermsg.monitorid);\r\n}\r\nstatic ssize_t class_id_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "{%pUl}\n",\r\nhv_dev->channel->offermsg.offer.if_type.b);\r\n}\r\nstatic ssize_t device_id_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "{%pUl}\n",\r\nhv_dev->channel->offermsg.offer.if_instance.b);\r\n}\r\nstatic ssize_t modalias_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nchar alias_name[VMBUS_ALIAS_LEN + 1];\r\nprint_alias_name(hv_dev, alias_name);\r\nreturn sprintf(buf, "vmbus:%s\n", alias_name);\r\n}\r\nstatic ssize_t server_monitor_pending_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n",\r\nchannel_pending(hv_dev->channel,\r\nvmbus_connection.monitor_pages[1]));\r\n}\r\nstatic ssize_t client_monitor_pending_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n",\r\nchannel_pending(hv_dev->channel,\r\nvmbus_connection.monitor_pages[1]));\r\n}\r\nstatic ssize_t server_monitor_latency_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n",\r\nchannel_latency(hv_dev->channel,\r\nvmbus_connection.monitor_pages[0]));\r\n}\r\nstatic ssize_t client_monitor_latency_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n",\r\nchannel_latency(hv_dev->channel,\r\nvmbus_connection.monitor_pages[1]));\r\n}\r\nstatic ssize_t server_monitor_conn_id_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n",\r\nchannel_conn_id(hv_dev->channel,\r\nvmbus_connection.monitor_pages[0]));\r\n}\r\nstatic ssize_t client_monitor_conn_id_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nreturn sprintf(buf, "%d\n",\r\nchannel_conn_id(hv_dev->channel,\r\nvmbus_connection.monitor_pages[1]));\r\n}\r\nstatic ssize_t out_intr_mask_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info outbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);\r\nreturn sprintf(buf, "%d\n", outbound.current_interrupt_mask);\r\n}\r\nstatic ssize_t out_read_index_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info outbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);\r\nreturn sprintf(buf, "%d\n", outbound.current_read_index);\r\n}\r\nstatic ssize_t out_write_index_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info outbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);\r\nreturn sprintf(buf, "%d\n", outbound.current_write_index);\r\n}\r\nstatic ssize_t out_read_bytes_avail_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info outbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);\r\nreturn sprintf(buf, "%d\n", outbound.bytes_avail_toread);\r\n}\r\nstatic ssize_t out_write_bytes_avail_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info outbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->outbound, &outbound);\r\nreturn sprintf(buf, "%d\n", outbound.bytes_avail_towrite);\r\n}\r\nstatic ssize_t in_intr_mask_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info inbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);\r\nreturn sprintf(buf, "%d\n", inbound.current_interrupt_mask);\r\n}\r\nstatic ssize_t in_read_index_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info inbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);\r\nreturn sprintf(buf, "%d\n", inbound.current_read_index);\r\n}\r\nstatic ssize_t in_write_index_show(struct device *dev,\r\nstruct device_attribute *dev_attr, char *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info inbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);\r\nreturn sprintf(buf, "%d\n", inbound.current_write_index);\r\n}\r\nstatic ssize_t in_read_bytes_avail_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info inbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);\r\nreturn sprintf(buf, "%d\n", inbound.bytes_avail_toread);\r\n}\r\nstatic ssize_t in_write_bytes_avail_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct hv_ring_buffer_debug_info inbound;\r\nif (!hv_dev->channel)\r\nreturn -ENODEV;\r\nhv_ringbuffer_get_debuginfo(&hv_dev->channel->inbound, &inbound);\r\nreturn sprintf(buf, "%d\n", inbound.bytes_avail_towrite);\r\n}\r\nstatic ssize_t channel_vp_mapping_show(struct device *dev,\r\nstruct device_attribute *dev_attr,\r\nchar *buf)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(dev);\r\nstruct vmbus_channel *channel = hv_dev->channel, *cur_sc;\r\nunsigned long flags;\r\nint buf_size = PAGE_SIZE, n_written, tot_written;\r\nstruct list_head *cur;\r\nif (!channel)\r\nreturn -ENODEV;\r\ntot_written = snprintf(buf, buf_size, "%u:%u\n",\r\nchannel->offermsg.child_relid, channel->target_cpu);\r\nspin_lock_irqsave(&channel->lock, flags);\r\nlist_for_each(cur, &channel->sc_list) {\r\nif (tot_written >= buf_size - 1)\r\nbreak;\r\ncur_sc = list_entry(cur, struct vmbus_channel, sc_list);\r\nn_written = scnprintf(buf + tot_written,\r\nbuf_size - tot_written,\r\n"%u:%u\n",\r\ncur_sc->offermsg.child_relid,\r\ncur_sc->target_cpu);\r\ntot_written += n_written;\r\n}\r\nspin_unlock_irqrestore(&channel->lock, flags);\r\nreturn tot_written;\r\n}\r\nstatic int vmbus_uevent(struct device *device, struct kobj_uevent_env *env)\r\n{\r\nstruct hv_device *dev = device_to_hv_device(device);\r\nint ret;\r\nchar alias_name[VMBUS_ALIAS_LEN + 1];\r\nprint_alias_name(dev, alias_name);\r\nret = add_uevent_var(env, "MODALIAS=vmbus:%s", alias_name);\r\nreturn ret;\r\n}\r\nstatic inline bool is_null_guid(const __u8 *guid)\r\n{\r\nif (memcmp(guid, &null_guid, sizeof(uuid_le)))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic const struct hv_vmbus_device_id *hv_vmbus_get_id(\r\nconst struct hv_vmbus_device_id *id,\r\nconst __u8 *guid)\r\n{\r\nfor (; !is_null_guid(id->guid); id++)\r\nif (!memcmp(&id->guid, guid, sizeof(uuid_le)))\r\nreturn id;\r\nreturn NULL;\r\n}\r\nstatic int vmbus_match(struct device *device, struct device_driver *driver)\r\n{\r\nstruct hv_driver *drv = drv_to_hv_drv(driver);\r\nstruct hv_device *hv_dev = device_to_hv_device(device);\r\nif (hv_vmbus_get_id(drv->id_table, hv_dev->dev_type.b))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int vmbus_probe(struct device *child_device)\r\n{\r\nint ret = 0;\r\nstruct hv_driver *drv =\r\ndrv_to_hv_drv(child_device->driver);\r\nstruct hv_device *dev = device_to_hv_device(child_device);\r\nconst struct hv_vmbus_device_id *dev_id;\r\ndev_id = hv_vmbus_get_id(drv->id_table, dev->dev_type.b);\r\nif (drv->probe) {\r\nret = drv->probe(dev, dev_id);\r\nif (ret != 0)\r\npr_err("probe failed for device %s (%d)\n",\r\ndev_name(child_device), ret);\r\n} else {\r\npr_err("probe not set for driver %s\n",\r\ndev_name(child_device));\r\nret = -ENODEV;\r\n}\r\nreturn ret;\r\n}\r\nstatic int vmbus_remove(struct device *child_device)\r\n{\r\nstruct hv_driver *drv;\r\nstruct hv_device *dev = device_to_hv_device(child_device);\r\nu32 relid = dev->channel->offermsg.child_relid;\r\nif (child_device->driver) {\r\ndrv = drv_to_hv_drv(child_device->driver);\r\nif (drv->remove)\r\ndrv->remove(dev);\r\nelse {\r\nhv_process_channel_removal(dev->channel, relid);\r\npr_err("remove not set for driver %s\n",\r\ndev_name(child_device));\r\n}\r\n} else {\r\nhv_process_channel_removal(dev->channel, relid);\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmbus_shutdown(struct device *child_device)\r\n{\r\nstruct hv_driver *drv;\r\nstruct hv_device *dev = device_to_hv_device(child_device);\r\nif (!child_device->driver)\r\nreturn;\r\ndrv = drv_to_hv_drv(child_device->driver);\r\nif (drv->shutdown)\r\ndrv->shutdown(dev);\r\nreturn;\r\n}\r\nstatic void vmbus_device_release(struct device *device)\r\n{\r\nstruct hv_device *hv_dev = device_to_hv_device(device);\r\nkfree(hv_dev);\r\n}\r\nstatic void vmbus_onmessage_work(struct work_struct *work)\r\n{\r\nstruct onmessage_work_context *ctx;\r\nif (vmbus_connection.conn_state == DISCONNECTED)\r\nreturn;\r\nctx = container_of(work, struct onmessage_work_context,\r\nwork);\r\nvmbus_onmessage(&ctx->msg);\r\nkfree(ctx);\r\n}\r\nstatic void hv_process_timer_expiration(struct hv_message *msg, int cpu)\r\n{\r\nstruct clock_event_device *dev = hv_context.clk_evt[cpu];\r\nif (dev->event_handler)\r\ndev->event_handler(dev);\r\nmsg->header.message_type = HVMSG_NONE;\r\nmb();\r\nif (msg->header.message_flags.msg_pending) {\r\nwrmsrl(HV_X64_MSR_EOM, 0);\r\n}\r\n}\r\nstatic void vmbus_on_msg_dpc(unsigned long data)\r\n{\r\nint cpu = smp_processor_id();\r\nvoid *page_addr = hv_context.synic_message_page[cpu];\r\nstruct hv_message *msg = (struct hv_message *)page_addr +\r\nVMBUS_MESSAGE_SINT;\r\nstruct vmbus_channel_message_header *hdr;\r\nstruct vmbus_channel_message_table_entry *entry;\r\nstruct onmessage_work_context *ctx;\r\nwhile (1) {\r\nif (msg->header.message_type == HVMSG_NONE)\r\nbreak;\r\nhdr = (struct vmbus_channel_message_header *)msg->u.payload;\r\nif (hdr->msgtype >= CHANNELMSG_COUNT) {\r\nWARN_ONCE(1, "unknown msgtype=%d\n", hdr->msgtype);\r\ngoto msg_handled;\r\n}\r\nentry = &channel_message_table[hdr->msgtype];\r\nif (entry->handler_type == VMHT_BLOCKING) {\r\nctx = kmalloc(sizeof(*ctx), GFP_ATOMIC);\r\nif (ctx == NULL)\r\ncontinue;\r\nINIT_WORK(&ctx->work, vmbus_onmessage_work);\r\nmemcpy(&ctx->msg, msg, sizeof(*msg));\r\nqueue_work(vmbus_connection.work_queue, &ctx->work);\r\n} else\r\nentry->message_handler(hdr);\r\nmsg_handled:\r\nmsg->header.message_type = HVMSG_NONE;\r\nmb();\r\nif (msg->header.message_flags.msg_pending) {\r\nwrmsrl(HV_X64_MSR_EOM, 0);\r\n}\r\n}\r\n}\r\nstatic void vmbus_isr(void)\r\n{\r\nint cpu = smp_processor_id();\r\nvoid *page_addr;\r\nstruct hv_message *msg;\r\nunion hv_synic_event_flags *event;\r\nbool handled = false;\r\npage_addr = hv_context.synic_event_page[cpu];\r\nif (page_addr == NULL)\r\nreturn;\r\nevent = (union hv_synic_event_flags *)page_addr +\r\nVMBUS_MESSAGE_SINT;\r\nif ((vmbus_proto_version == VERSION_WS2008) ||\r\n(vmbus_proto_version == VERSION_WIN7)) {\r\nif (sync_test_and_clear_bit(0,\r\n(unsigned long *) &event->flags32[0])) {\r\nhandled = true;\r\n}\r\n} else {\r\nhandled = true;\r\n}\r\nif (handled)\r\ntasklet_schedule(hv_context.event_dpc[cpu]);\r\npage_addr = hv_context.synic_message_page[cpu];\r\nmsg = (struct hv_message *)page_addr + VMBUS_MESSAGE_SINT;\r\nif (msg->header.message_type != HVMSG_NONE) {\r\nif (msg->header.message_type == HVMSG_TIMER_EXPIRED)\r\nhv_process_timer_expiration(msg, cpu);\r\nelse\r\ntasklet_schedule(&msg_dpc);\r\n}\r\n}\r\nstatic int vmbus_bus_init(int irq)\r\n{\r\nint ret;\r\nret = hv_init();\r\nif (ret != 0) {\r\npr_err("Unable to initialize the hypervisor - 0x%x\n", ret);\r\nreturn ret;\r\n}\r\ntasklet_init(&msg_dpc, vmbus_on_msg_dpc, 0);\r\nret = bus_register(&hv_bus);\r\nif (ret)\r\ngoto err_cleanup;\r\nhv_setup_vmbus_irq(vmbus_isr);\r\nret = hv_synic_alloc();\r\nif (ret)\r\ngoto err_alloc;\r\non_each_cpu(hv_synic_init, NULL, 1);\r\nret = vmbus_connect();\r\nif (ret)\r\ngoto err_alloc;\r\nif (vmbus_proto_version > VERSION_WIN7)\r\ncpu_hotplug_disable();\r\nif (ms_hyperv.misc_features & HV_FEATURE_GUEST_CRASH_MSR_AVAILABLE) {\r\nregister_die_notifier(&hyperv_die_block);\r\natomic_notifier_chain_register(&panic_notifier_list,\r\n&hyperv_panic_block);\r\n}\r\nvmbus_request_offers();\r\nreturn 0;\r\nerr_alloc:\r\nhv_synic_free();\r\nhv_remove_vmbus_irq();\r\nbus_unregister(&hv_bus);\r\nerr_cleanup:\r\nhv_cleanup();\r\nreturn ret;\r\n}\r\nint __vmbus_driver_register(struct hv_driver *hv_driver, struct module *owner, const char *mod_name)\r\n{\r\nint ret;\r\npr_info("registering driver %s\n", hv_driver->name);\r\nret = vmbus_exists();\r\nif (ret < 0)\r\nreturn ret;\r\nhv_driver->driver.name = hv_driver->name;\r\nhv_driver->driver.owner = owner;\r\nhv_driver->driver.mod_name = mod_name;\r\nhv_driver->driver.bus = &hv_bus;\r\nret = driver_register(&hv_driver->driver);\r\nreturn ret;\r\n}\r\nvoid vmbus_driver_unregister(struct hv_driver *hv_driver)\r\n{\r\npr_info("unregistering driver %s\n", hv_driver->name);\r\nif (!vmbus_exists())\r\ndriver_unregister(&hv_driver->driver);\r\n}\r\nstruct hv_device *vmbus_device_create(const uuid_le *type,\r\nconst uuid_le *instance,\r\nstruct vmbus_channel *channel)\r\n{\r\nstruct hv_device *child_device_obj;\r\nchild_device_obj = kzalloc(sizeof(struct hv_device), GFP_KERNEL);\r\nif (!child_device_obj) {\r\npr_err("Unable to allocate device object for child device\n");\r\nreturn NULL;\r\n}\r\nchild_device_obj->channel = channel;\r\nmemcpy(&child_device_obj->dev_type, type, sizeof(uuid_le));\r\nmemcpy(&child_device_obj->dev_instance, instance,\r\nsizeof(uuid_le));\r\nreturn child_device_obj;\r\n}\r\nint vmbus_device_register(struct hv_device *child_device_obj)\r\n{\r\nint ret = 0;\r\ndev_set_name(&child_device_obj->device, "vmbus_%d",\r\nchild_device_obj->channel->id);\r\nchild_device_obj->device.bus = &hv_bus;\r\nchild_device_obj->device.parent = &hv_acpi_dev->dev;\r\nchild_device_obj->device.release = vmbus_device_release;\r\nret = device_register(&child_device_obj->device);\r\nif (ret)\r\npr_err("Unable to register child device\n");\r\nelse\r\npr_debug("child device %s registered\n",\r\ndev_name(&child_device_obj->device));\r\nreturn ret;\r\n}\r\nvoid vmbus_device_unregister(struct hv_device *device_obj)\r\n{\r\npr_debug("child device %s unregistered\n",\r\ndev_name(&device_obj->device));\r\ndevice_unregister(&device_obj->device);\r\n}\r\nstatic acpi_status vmbus_walk_resources(struct acpi_resource *res, void *ctx)\r\n{\r\nresource_size_t start = 0;\r\nresource_size_t end = 0;\r\nstruct resource *new_res;\r\nstruct resource **old_res = &hyperv_mmio;\r\nstruct resource **prev_res = NULL;\r\nswitch (res->type) {\r\ncase ACPI_RESOURCE_TYPE_IRQ:\r\nirq = res->data.irq.interrupts[0];\r\nreturn AE_OK;\r\ncase ACPI_RESOURCE_TYPE_ADDRESS32:\r\nstart = res->data.address32.address.minimum;\r\nend = res->data.address32.address.maximum;\r\nbreak;\r\ncase ACPI_RESOURCE_TYPE_ADDRESS64:\r\nstart = res->data.address64.address.minimum;\r\nend = res->data.address64.address.maximum;\r\nbreak;\r\ndefault:\r\nreturn AE_OK;\r\n}\r\nif (end < 0x100000)\r\nreturn AE_OK;\r\nnew_res = kzalloc(sizeof(*new_res), GFP_ATOMIC);\r\nif (!new_res)\r\nreturn AE_NO_MEMORY;\r\nif (end > VTPM_BASE_ADDRESS && start < VTPM_BASE_ADDRESS)\r\nend = VTPM_BASE_ADDRESS;\r\nnew_res->name = "hyperv mmio";\r\nnew_res->flags = IORESOURCE_MEM;\r\nnew_res->start = start;\r\nnew_res->end = end;\r\ndo {\r\nif (!*old_res) {\r\n*old_res = new_res;\r\nbreak;\r\n}\r\nif ((*old_res)->end < new_res->start) {\r\nnew_res->sibling = *old_res;\r\nif (prev_res)\r\n(*prev_res)->sibling = new_res;\r\n*old_res = new_res;\r\nbreak;\r\n}\r\nprev_res = old_res;\r\nold_res = &(*old_res)->sibling;\r\n} while (1);\r\nreturn AE_OK;\r\n}\r\nstatic int vmbus_acpi_remove(struct acpi_device *device)\r\n{\r\nstruct resource *cur_res;\r\nstruct resource *next_res;\r\nif (hyperv_mmio) {\r\nfor (cur_res = hyperv_mmio; cur_res; cur_res = next_res) {\r\nnext_res = cur_res->sibling;\r\nkfree(cur_res);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint vmbus_allocate_mmio(struct resource **new, struct hv_device *device_obj,\r\nresource_size_t min, resource_size_t max,\r\nresource_size_t size, resource_size_t align,\r\nbool fb_overlap_ok)\r\n{\r\nstruct resource *iter;\r\nresource_size_t range_min, range_max, start, local_min, local_max;\r\nconst char *dev_n = dev_name(&device_obj->device);\r\nu32 fb_end = screen_info.lfb_base + (screen_info.lfb_size << 1);\r\nint i;\r\nfor (iter = hyperv_mmio; iter; iter = iter->sibling) {\r\nif ((iter->start >= max) || (iter->end <= min))\r\ncontinue;\r\nrange_min = iter->start;\r\nrange_max = iter->end;\r\nfor (i = 0; i < 2; i++) {\r\nlocal_min = range_min;\r\nlocal_max = range_max;\r\nif (fb_overlap_ok || (range_min >= fb_end) ||\r\n(range_max <= screen_info.lfb_base)) {\r\ni++;\r\n} else {\r\nif ((range_min <= screen_info.lfb_base) &&\r\n(range_max >= screen_info.lfb_base)) {\r\nlocal_max = screen_info.lfb_base - 1;\r\nrange_min = fb_end;\r\n} else {\r\nrange_min = fb_end;\r\ncontinue;\r\n}\r\n}\r\nstart = (local_min + align - 1) & ~(align - 1);\r\nfor (; start + size - 1 <= local_max; start += align) {\r\n*new = request_mem_region_exclusive(start, size,\r\ndev_n);\r\nif (*new)\r\nreturn 0;\r\n}\r\n}\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int vmbus_acpi_add(struct acpi_device *device)\r\n{\r\nacpi_status result;\r\nint ret_val = -ENODEV;\r\nstruct acpi_device *ancestor;\r\nhv_acpi_dev = device;\r\nresult = acpi_walk_resources(device->handle, METHOD_NAME__CRS,\r\nvmbus_walk_resources, NULL);\r\nif (ACPI_FAILURE(result))\r\ngoto acpi_walk_err;\r\nfor (ancestor = device->parent; ancestor; ancestor = ancestor->parent) {\r\nresult = acpi_walk_resources(ancestor->handle, METHOD_NAME__CRS,\r\nvmbus_walk_resources, NULL);\r\nif (ACPI_FAILURE(result))\r\ncontinue;\r\nif (hyperv_mmio)\r\nbreak;\r\n}\r\nret_val = 0;\r\nacpi_walk_err:\r\ncomplete(&probe_event);\r\nif (ret_val)\r\nvmbus_acpi_remove(device);\r\nreturn ret_val;\r\n}\r\nstatic void hv_kexec_handler(void)\r\n{\r\nint cpu;\r\nhv_synic_clockevents_cleanup();\r\nvmbus_initiate_unload();\r\nfor_each_online_cpu(cpu)\r\nsmp_call_function_single(cpu, hv_synic_cleanup, NULL, 1);\r\nhv_cleanup();\r\n}\r\nstatic void hv_crash_handler(struct pt_regs *regs)\r\n{\r\nvmbus_initiate_unload();\r\nhv_synic_cleanup(NULL);\r\nhv_cleanup();\r\n}\r\nstatic int __init hv_acpi_init(void)\r\n{\r\nint ret, t;\r\nif (x86_hyper != &x86_hyper_ms_hyperv)\r\nreturn -ENODEV;\r\ninit_completion(&probe_event);\r\nret = acpi_bus_register_driver(&vmbus_acpi_driver);\r\nif (ret)\r\nreturn ret;\r\nt = wait_for_completion_timeout(&probe_event, 5*HZ);\r\nif (t == 0) {\r\nret = -ETIMEDOUT;\r\ngoto cleanup;\r\n}\r\nif (irq <= 0) {\r\nret = -ENODEV;\r\ngoto cleanup;\r\n}\r\nret = vmbus_bus_init(irq);\r\nif (ret)\r\ngoto cleanup;\r\nhv_setup_kexec_handler(hv_kexec_handler);\r\nhv_setup_crash_handler(hv_crash_handler);\r\nreturn 0;\r\ncleanup:\r\nacpi_bus_unregister_driver(&vmbus_acpi_driver);\r\nhv_acpi_dev = NULL;\r\nreturn ret;\r\n}\r\nstatic void __exit vmbus_exit(void)\r\n{\r\nint cpu;\r\nhv_remove_kexec_handler();\r\nhv_remove_crash_handler();\r\nvmbus_connection.conn_state = DISCONNECTED;\r\nhv_synic_clockevents_cleanup();\r\nvmbus_disconnect();\r\nhv_remove_vmbus_irq();\r\ntasklet_kill(&msg_dpc);\r\nvmbus_free_channels();\r\nif (ms_hyperv.misc_features & HV_FEATURE_GUEST_CRASH_MSR_AVAILABLE) {\r\nunregister_die_notifier(&hyperv_die_block);\r\natomic_notifier_chain_unregister(&panic_notifier_list,\r\n&hyperv_panic_block);\r\n}\r\nbus_unregister(&hv_bus);\r\nhv_cleanup();\r\nfor_each_online_cpu(cpu) {\r\ntasklet_kill(hv_context.event_dpc[cpu]);\r\nsmp_call_function_single(cpu, hv_synic_cleanup, NULL, 1);\r\n}\r\nhv_synic_free();\r\nacpi_bus_unregister_driver(&vmbus_acpi_driver);\r\nif (vmbus_proto_version > VERSION_WIN7)\r\ncpu_hotplug_enable();\r\n}
