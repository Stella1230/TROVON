void tmio_mmc_enable_mmc_irqs(struct tmio_mmc_host *host, u32 i)\r\n{\r\nhost->sdcard_irq_mask &= ~(i & TMIO_MASK_IRQ);\r\nsd_ctrl_write32(host, CTL_IRQ_MASK, host->sdcard_irq_mask);\r\n}\r\nvoid tmio_mmc_disable_mmc_irqs(struct tmio_mmc_host *host, u32 i)\r\n{\r\nhost->sdcard_irq_mask |= (i & TMIO_MASK_IRQ);\r\nsd_ctrl_write32(host, CTL_IRQ_MASK, host->sdcard_irq_mask);\r\n}\r\nstatic void tmio_mmc_ack_mmc_irqs(struct tmio_mmc_host *host, u32 i)\r\n{\r\nsd_ctrl_write32(host, CTL_STATUS, ~i);\r\n}\r\nstatic void tmio_mmc_init_sg(struct tmio_mmc_host *host, struct mmc_data *data)\r\n{\r\nhost->sg_len = data->sg_len;\r\nhost->sg_ptr = data->sg;\r\nhost->sg_orig = data->sg;\r\nhost->sg_off = 0;\r\n}\r\nstatic int tmio_mmc_next_sg(struct tmio_mmc_host *host)\r\n{\r\nhost->sg_ptr = sg_next(host->sg_ptr);\r\nhost->sg_off = 0;\r\nreturn --host->sg_len;\r\n}\r\nstatic void pr_debug_status(u32 status)\r\n{\r\nint i = 0;\r\npr_debug("status: %08x = ", status);\r\nSTATUS_TO_TEXT(CARD_REMOVE, status, i);\r\nSTATUS_TO_TEXT(CARD_INSERT, status, i);\r\nSTATUS_TO_TEXT(SIGSTATE, status, i);\r\nSTATUS_TO_TEXT(WRPROTECT, status, i);\r\nSTATUS_TO_TEXT(CARD_REMOVE_A, status, i);\r\nSTATUS_TO_TEXT(CARD_INSERT_A, status, i);\r\nSTATUS_TO_TEXT(SIGSTATE_A, status, i);\r\nSTATUS_TO_TEXT(CMD_IDX_ERR, status, i);\r\nSTATUS_TO_TEXT(STOPBIT_ERR, status, i);\r\nSTATUS_TO_TEXT(ILL_FUNC, status, i);\r\nSTATUS_TO_TEXT(CMD_BUSY, status, i);\r\nSTATUS_TO_TEXT(CMDRESPEND, status, i);\r\nSTATUS_TO_TEXT(DATAEND, status, i);\r\nSTATUS_TO_TEXT(CRCFAIL, status, i);\r\nSTATUS_TO_TEXT(DATATIMEOUT, status, i);\r\nSTATUS_TO_TEXT(CMDTIMEOUT, status, i);\r\nSTATUS_TO_TEXT(RXOVERFLOW, status, i);\r\nSTATUS_TO_TEXT(TXUNDERRUN, status, i);\r\nSTATUS_TO_TEXT(RXRDY, status, i);\r\nSTATUS_TO_TEXT(TXRQ, status, i);\r\nSTATUS_TO_TEXT(ILL_ACCESS, status, i);\r\nprintk("\n");\r\n}\r\nstatic void tmio_mmc_enable_sdio_irq(struct mmc_host *mmc, int enable)\r\n{\r\nstruct tmio_mmc_host *host = mmc_priv(mmc);\r\nif (enable && !host->sdio_irq_enabled) {\r\npm_runtime_get_sync(mmc_dev(mmc));\r\nhost->sdio_irq_enabled = true;\r\nhost->sdio_irq_mask = TMIO_SDIO_MASK_ALL &\r\n~TMIO_SDIO_STAT_IOIRQ;\r\nsd_ctrl_write16(host, CTL_TRANSACTION_CTL, 0x0001);\r\nsd_ctrl_write16(host, CTL_SDIO_IRQ_MASK, host->sdio_irq_mask);\r\n} else if (!enable && host->sdio_irq_enabled) {\r\nhost->sdio_irq_mask = TMIO_SDIO_MASK_ALL;\r\nsd_ctrl_write16(host, CTL_SDIO_IRQ_MASK, host->sdio_irq_mask);\r\nsd_ctrl_write16(host, CTL_TRANSACTION_CTL, 0x0000);\r\nhost->sdio_irq_enabled = false;\r\npm_runtime_mark_last_busy(mmc_dev(mmc));\r\npm_runtime_put_autosuspend(mmc_dev(mmc));\r\n}\r\n}\r\nstatic void tmio_mmc_set_clock(struct tmio_mmc_host *host,\r\nunsigned int new_clock)\r\n{\r\nu32 clk = 0, clock;\r\nif (new_clock) {\r\nfor (clock = host->mmc->f_min, clk = 0x80000080;\r\nnew_clock >= (clock<<1); clk >>= 1)\r\nclock <<= 1;\r\nif ((host->pdata->flags & TMIO_MMC_CLK_ACTUAL) &&\r\n((clk >> 22) & 0x1))\r\nclk |= 0xff;\r\n}\r\nif (host->set_clk_div)\r\nhost->set_clk_div(host->pdev, (clk>>22) & 1);\r\nsd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, clk & 0x1ff);\r\nmsleep(10);\r\n}\r\nstatic void tmio_mmc_clk_stop(struct tmio_mmc_host *host)\r\n{\r\nif (host->pdata->flags & TMIO_MMC_HAVE_HIGH_REG) {\r\nsd_ctrl_write16(host, CTL_CLK_AND_WAIT_CTL, 0x0000);\r\nmsleep(10);\r\n}\r\nsd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, ~0x0100 &\r\nsd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));\r\nmsleep(10);\r\n}\r\nstatic void tmio_mmc_clk_start(struct tmio_mmc_host *host)\r\n{\r\nsd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, 0x0100 |\r\nsd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));\r\nmsleep(10);\r\nif (host->pdata->flags & TMIO_MMC_HAVE_HIGH_REG) {\r\nsd_ctrl_write16(host, CTL_CLK_AND_WAIT_CTL, 0x0100);\r\nmsleep(10);\r\n}\r\n}\r\nstatic void tmio_mmc_reset(struct tmio_mmc_host *host)\r\n{\r\nsd_ctrl_write16(host, CTL_RESET_SD, 0x0000);\r\nif (host->pdata->flags & TMIO_MMC_HAVE_HIGH_REG)\r\nsd_ctrl_write16(host, CTL_RESET_SDIO, 0x0000);\r\nmsleep(10);\r\nsd_ctrl_write16(host, CTL_RESET_SD, 0x0001);\r\nif (host->pdata->flags & TMIO_MMC_HAVE_HIGH_REG)\r\nsd_ctrl_write16(host, CTL_RESET_SDIO, 0x0001);\r\nmsleep(10);\r\n}\r\nstatic void tmio_mmc_reset_work(struct work_struct *work)\r\n{\r\nstruct tmio_mmc_host *host = container_of(work, struct tmio_mmc_host,\r\ndelayed_reset_work.work);\r\nstruct mmc_request *mrq;\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nmrq = host->mrq;\r\nif (IS_ERR_OR_NULL(mrq)\r\n|| time_is_after_jiffies(host->last_req_ts +\r\nmsecs_to_jiffies(CMDREQ_TIMEOUT))) {\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn;\r\n}\r\ndev_warn(&host->pdev->dev,\r\n"timeout waiting for hardware interrupt (CMD%u)\n",\r\nmrq->cmd->opcode);\r\nif (host->data)\r\nhost->data->error = -ETIMEDOUT;\r\nelse if (host->cmd)\r\nhost->cmd->error = -ETIMEDOUT;\r\nelse\r\nmrq->cmd->error = -ETIMEDOUT;\r\nhost->cmd = NULL;\r\nhost->data = NULL;\r\nhost->force_pio = false;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\ntmio_mmc_reset(host);\r\nhost->mrq = NULL;\r\ntmio_mmc_abort_dma(host);\r\nmmc_request_done(host->mmc, mrq);\r\npm_runtime_mark_last_busy(mmc_dev(host->mmc));\r\npm_runtime_put_autosuspend(mmc_dev(host->mmc));\r\n}\r\nstatic void tmio_mmc_finish_request(struct tmio_mmc_host *host)\r\n{\r\nstruct mmc_request *mrq;\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nmrq = host->mrq;\r\nif (IS_ERR_OR_NULL(mrq)) {\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn;\r\n}\r\nhost->cmd = NULL;\r\nhost->data = NULL;\r\nhost->force_pio = false;\r\ncancel_delayed_work(&host->delayed_reset_work);\r\nhost->mrq = NULL;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nif (mrq->cmd->error || (mrq->data && mrq->data->error))\r\ntmio_mmc_abort_dma(host);\r\nmmc_request_done(host->mmc, mrq);\r\npm_runtime_mark_last_busy(mmc_dev(host->mmc));\r\npm_runtime_put_autosuspend(mmc_dev(host->mmc));\r\n}\r\nstatic void tmio_mmc_done_work(struct work_struct *work)\r\n{\r\nstruct tmio_mmc_host *host = container_of(work, struct tmio_mmc_host,\r\ndone);\r\ntmio_mmc_finish_request(host);\r\n}\r\nstatic int tmio_mmc_start_command(struct tmio_mmc_host *host, struct mmc_command *cmd)\r\n{\r\nstruct mmc_data *data = host->data;\r\nint c = cmd->opcode;\r\nu32 irq_mask = TMIO_MASK_CMD;\r\nif (cmd->opcode == MMC_STOP_TRANSMISSION && !cmd->arg) {\r\nsd_ctrl_write16(host, CTL_STOP_INTERNAL_ACTION, 0x001);\r\nreturn 0;\r\n}\r\nswitch (mmc_resp_type(cmd)) {\r\ncase MMC_RSP_NONE: c |= RESP_NONE; break;\r\ncase MMC_RSP_R1: c |= RESP_R1; break;\r\ncase MMC_RSP_R1B: c |= RESP_R1B; break;\r\ncase MMC_RSP_R2: c |= RESP_R2; break;\r\ncase MMC_RSP_R3: c |= RESP_R3; break;\r\ndefault:\r\npr_debug("Unknown response type %d\n", mmc_resp_type(cmd));\r\nreturn -EINVAL;\r\n}\r\nhost->cmd = cmd;\r\nif (data) {\r\nc |= DATA_PRESENT;\r\nif (data->blocks > 1) {\r\nsd_ctrl_write16(host, CTL_STOP_INTERNAL_ACTION, 0x100);\r\nc |= TRANSFER_MULTI;\r\nif ((host->pdata->flags & TMIO_MMC_HAVE_CMD12_CTRL) &&\r\n(cmd->opcode == SD_IO_RW_EXTENDED))\r\nc |= NO_CMD12_ISSUE;\r\n}\r\nif (data->flags & MMC_DATA_READ)\r\nc |= TRANSFER_READ;\r\n}\r\nif (!host->native_hotplug)\r\nirq_mask &= ~(TMIO_STAT_CARD_REMOVE | TMIO_STAT_CARD_INSERT);\r\ntmio_mmc_enable_mmc_irqs(host, irq_mask);\r\nsd_ctrl_write32(host, CTL_ARG_REG, cmd->arg);\r\nsd_ctrl_write16(host, CTL_SD_CMD, c);\r\nreturn 0;\r\n}\r\nstatic void tmio_mmc_transfer_data(struct tmio_mmc_host *host,\r\nunsigned short *buf,\r\nunsigned int count)\r\n{\r\nint is_read = host->data->flags & MMC_DATA_READ;\r\nu8 *buf8;\r\nif (is_read)\r\nsd_ctrl_read16_rep(host, CTL_SD_DATA_PORT, buf, count >> 1);\r\nelse\r\nsd_ctrl_write16_rep(host, CTL_SD_DATA_PORT, buf, count >> 1);\r\nif (!(count & 0x1))\r\nreturn;\r\nbuf8 = (u8 *)(buf + (count >> 1));\r\nif (is_read)\r\n*buf8 = sd_ctrl_read16(host, CTL_SD_DATA_PORT) & 0xff;\r\nelse\r\nsd_ctrl_write16(host, CTL_SD_DATA_PORT, *buf8);\r\n}\r\nstatic void tmio_mmc_pio_irq(struct tmio_mmc_host *host)\r\n{\r\nstruct mmc_data *data = host->data;\r\nvoid *sg_virt;\r\nunsigned short *buf;\r\nunsigned int count;\r\nunsigned long flags;\r\nif ((host->chan_tx || host->chan_rx) && !host->force_pio) {\r\npr_err("PIO IRQ in DMA mode!\n");\r\nreturn;\r\n} else if (!data) {\r\npr_debug("Spurious PIO IRQ\n");\r\nreturn;\r\n}\r\nsg_virt = tmio_mmc_kmap_atomic(host->sg_ptr, &flags);\r\nbuf = (unsigned short *)(sg_virt + host->sg_off);\r\ncount = host->sg_ptr->length - host->sg_off;\r\nif (count > data->blksz)\r\ncount = data->blksz;\r\npr_debug("count: %08x offset: %08x flags %08x\n",\r\ncount, host->sg_off, data->flags);\r\ntmio_mmc_transfer_data(host, buf, count);\r\nhost->sg_off += count;\r\ntmio_mmc_kunmap_atomic(host->sg_ptr, &flags, sg_virt);\r\nif (host->sg_off == host->sg_ptr->length)\r\ntmio_mmc_next_sg(host);\r\nreturn;\r\n}\r\nstatic void tmio_mmc_check_bounce_buffer(struct tmio_mmc_host *host)\r\n{\r\nif (host->sg_ptr == &host->bounce_sg) {\r\nunsigned long flags;\r\nvoid *sg_vaddr = tmio_mmc_kmap_atomic(host->sg_orig, &flags);\r\nmemcpy(sg_vaddr, host->bounce_buf, host->bounce_sg.length);\r\ntmio_mmc_kunmap_atomic(host->sg_orig, &flags, sg_vaddr);\r\n}\r\n}\r\nvoid tmio_mmc_do_data_irq(struct tmio_mmc_host *host)\r\n{\r\nstruct mmc_data *data = host->data;\r\nstruct mmc_command *stop;\r\nhost->data = NULL;\r\nif (!data) {\r\ndev_warn(&host->pdev->dev, "Spurious data end IRQ\n");\r\nreturn;\r\n}\r\nstop = data->stop;\r\nif (!data->error)\r\ndata->bytes_xfered = data->blocks * data->blksz;\r\nelse\r\ndata->bytes_xfered = 0;\r\npr_debug("Completed data request\n");\r\nif (data->flags & MMC_DATA_READ) {\r\nif (host->chan_rx && !host->force_pio)\r\ntmio_mmc_check_bounce_buffer(host);\r\ndev_dbg(&host->pdev->dev, "Complete Rx request %p\n",\r\nhost->mrq);\r\n} else {\r\ndev_dbg(&host->pdev->dev, "Complete Tx request %p\n",\r\nhost->mrq);\r\n}\r\nif (stop) {\r\nif (stop->opcode == MMC_STOP_TRANSMISSION && !stop->arg)\r\nsd_ctrl_write16(host, CTL_STOP_INTERNAL_ACTION, 0x000);\r\nelse\r\nBUG();\r\n}\r\nschedule_work(&host->done);\r\n}\r\nstatic void tmio_mmc_data_irq(struct tmio_mmc_host *host)\r\n{\r\nstruct mmc_data *data;\r\nspin_lock(&host->lock);\r\ndata = host->data;\r\nif (!data)\r\ngoto out;\r\nif (host->chan_tx && (data->flags & MMC_DATA_WRITE) && !host->force_pio) {\r\nu32 status = sd_ctrl_read32(host, CTL_STATUS);\r\nbool done = false;\r\nif (host->pdata->flags & TMIO_MMC_HAS_IDLE_WAIT) {\r\nif (status & TMIO_STAT_ILL_FUNC)\r\ndone = true;\r\n} else {\r\nif (!(status & TMIO_STAT_CMD_BUSY))\r\ndone = true;\r\n}\r\nif (done) {\r\ntmio_mmc_disable_mmc_irqs(host, TMIO_STAT_DATAEND);\r\ntasklet_schedule(&host->dma_complete);\r\n}\r\n} else if (host->chan_rx && (data->flags & MMC_DATA_READ) && !host->force_pio) {\r\ntmio_mmc_disable_mmc_irqs(host, TMIO_STAT_DATAEND);\r\ntasklet_schedule(&host->dma_complete);\r\n} else {\r\ntmio_mmc_do_data_irq(host);\r\ntmio_mmc_disable_mmc_irqs(host, TMIO_MASK_READOP | TMIO_MASK_WRITEOP);\r\n}\r\nout:\r\nspin_unlock(&host->lock);\r\n}\r\nstatic void tmio_mmc_cmd_irq(struct tmio_mmc_host *host,\r\nunsigned int stat)\r\n{\r\nstruct mmc_command *cmd = host->cmd;\r\nint i, addr;\r\nspin_lock(&host->lock);\r\nif (!host->cmd) {\r\npr_debug("Spurious CMD irq\n");\r\ngoto out;\r\n}\r\nhost->cmd = NULL;\r\nfor (i = 3, addr = CTL_RESPONSE ; i >= 0 ; i--, addr += 4)\r\ncmd->resp[i] = sd_ctrl_read32(host, addr);\r\nif (cmd->flags & MMC_RSP_136) {\r\ncmd->resp[0] = (cmd->resp[0] << 8) | (cmd->resp[1] >> 24);\r\ncmd->resp[1] = (cmd->resp[1] << 8) | (cmd->resp[2] >> 24);\r\ncmd->resp[2] = (cmd->resp[2] << 8) | (cmd->resp[3] >> 24);\r\ncmd->resp[3] <<= 8;\r\n} else if (cmd->flags & MMC_RSP_R3) {\r\ncmd->resp[0] = cmd->resp[3];\r\n}\r\nif (stat & TMIO_STAT_CMDTIMEOUT)\r\ncmd->error = -ETIMEDOUT;\r\nelse if (stat & TMIO_STAT_CRCFAIL && cmd->flags & MMC_RSP_CRC)\r\ncmd->error = -EILSEQ;\r\nif (host->data && !cmd->error) {\r\nif (host->data->flags & MMC_DATA_READ) {\r\nif (host->force_pio || !host->chan_rx)\r\ntmio_mmc_enable_mmc_irqs(host, TMIO_MASK_READOP);\r\nelse\r\ntasklet_schedule(&host->dma_issue);\r\n} else {\r\nif (host->force_pio || !host->chan_tx)\r\ntmio_mmc_enable_mmc_irqs(host, TMIO_MASK_WRITEOP);\r\nelse\r\ntasklet_schedule(&host->dma_issue);\r\n}\r\n} else {\r\nschedule_work(&host->done);\r\n}\r\nout:\r\nspin_unlock(&host->lock);\r\n}\r\nstatic void tmio_mmc_card_irq_status(struct tmio_mmc_host *host,\r\nint *ireg, int *status)\r\n{\r\n*status = sd_ctrl_read32(host, CTL_STATUS);\r\n*ireg = *status & TMIO_MASK_IRQ & ~host->sdcard_irq_mask;\r\npr_debug_status(*status);\r\npr_debug_status(*ireg);\r\nsd_ctrl_write32(host, CTL_STATUS, TMIO_MASK_IRQ);\r\n}\r\nstatic bool __tmio_mmc_card_detect_irq(struct tmio_mmc_host *host,\r\nint ireg, int status)\r\n{\r\nstruct mmc_host *mmc = host->mmc;\r\nif (ireg & (TMIO_STAT_CARD_INSERT | TMIO_STAT_CARD_REMOVE)) {\r\ntmio_mmc_ack_mmc_irqs(host, TMIO_STAT_CARD_INSERT |\r\nTMIO_STAT_CARD_REMOVE);\r\nif ((((ireg & TMIO_STAT_CARD_REMOVE) && mmc->card) ||\r\n((ireg & TMIO_STAT_CARD_INSERT) && !mmc->card)) &&\r\n!work_pending(&mmc->detect.work))\r\nmmc_detect_change(host->mmc, msecs_to_jiffies(100));\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nirqreturn_t tmio_mmc_card_detect_irq(int irq, void *devid)\r\n{\r\nunsigned int ireg, status;\r\nstruct tmio_mmc_host *host = devid;\r\ntmio_mmc_card_irq_status(host, &ireg, &status);\r\n__tmio_mmc_card_detect_irq(host, ireg, status);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic bool __tmio_mmc_sdcard_irq(struct tmio_mmc_host *host,\r\nint ireg, int status)\r\n{\r\nif (ireg & (TMIO_STAT_CMDRESPEND | TMIO_STAT_CMDTIMEOUT)) {\r\ntmio_mmc_ack_mmc_irqs(host,\r\nTMIO_STAT_CMDRESPEND |\r\nTMIO_STAT_CMDTIMEOUT);\r\ntmio_mmc_cmd_irq(host, status);\r\nreturn true;\r\n}\r\nif (ireg & (TMIO_STAT_RXRDY | TMIO_STAT_TXRQ)) {\r\ntmio_mmc_ack_mmc_irqs(host, TMIO_STAT_RXRDY | TMIO_STAT_TXRQ);\r\ntmio_mmc_pio_irq(host);\r\nreturn true;\r\n}\r\nif (ireg & TMIO_STAT_DATAEND) {\r\ntmio_mmc_ack_mmc_irqs(host, TMIO_STAT_DATAEND);\r\ntmio_mmc_data_irq(host);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nirqreturn_t tmio_mmc_sdcard_irq(int irq, void *devid)\r\n{\r\nunsigned int ireg, status;\r\nstruct tmio_mmc_host *host = devid;\r\ntmio_mmc_card_irq_status(host, &ireg, &status);\r\n__tmio_mmc_sdcard_irq(host, ireg, status);\r\nreturn IRQ_HANDLED;\r\n}\r\nirqreturn_t tmio_mmc_sdio_irq(int irq, void *devid)\r\n{\r\nstruct tmio_mmc_host *host = devid;\r\nstruct mmc_host *mmc = host->mmc;\r\nstruct tmio_mmc_data *pdata = host->pdata;\r\nunsigned int ireg, status;\r\nunsigned int sdio_status;\r\nif (!(pdata->flags & TMIO_MMC_SDIO_IRQ))\r\nreturn IRQ_HANDLED;\r\nstatus = sd_ctrl_read16(host, CTL_SDIO_STATUS);\r\nireg = status & TMIO_SDIO_MASK_ALL & ~host->sdcard_irq_mask;\r\nsdio_status = status & ~TMIO_SDIO_MASK_ALL;\r\nif (pdata->flags & TMIO_MMC_SDIO_STATUS_QUIRK)\r\nsdio_status |= 6;\r\nsd_ctrl_write16(host, CTL_SDIO_STATUS, sdio_status);\r\nif (mmc->caps & MMC_CAP_SDIO_IRQ && ireg & TMIO_SDIO_STAT_IOIRQ)\r\nmmc_signal_sdio_irq(mmc);\r\nreturn IRQ_HANDLED;\r\n}\r\nirqreturn_t tmio_mmc_irq(int irq, void *devid)\r\n{\r\nstruct tmio_mmc_host *host = devid;\r\nunsigned int ireg, status;\r\npr_debug("MMC IRQ begin\n");\r\ntmio_mmc_card_irq_status(host, &ireg, &status);\r\nif (__tmio_mmc_card_detect_irq(host, ireg, status))\r\nreturn IRQ_HANDLED;\r\nif (__tmio_mmc_sdcard_irq(host, ireg, status))\r\nreturn IRQ_HANDLED;\r\ntmio_mmc_sdio_irq(irq, devid);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int tmio_mmc_start_data(struct tmio_mmc_host *host,\r\nstruct mmc_data *data)\r\n{\r\nstruct tmio_mmc_data *pdata = host->pdata;\r\npr_debug("setup data transfer: blocksize %08x nr_blocks %d\n",\r\ndata->blksz, data->blocks);\r\nif (host->mmc->ios.bus_width == MMC_BUS_WIDTH_4) {\r\nint blksz_2bytes = pdata->flags & TMIO_MMC_BLKSZ_2BYTES;\r\nif (data->blksz < 2 || (data->blksz < 4 && !blksz_2bytes)) {\r\npr_err("%s: %d byte block unsupported in 4 bit mode\n",\r\nmmc_hostname(host->mmc), data->blksz);\r\nreturn -EINVAL;\r\n}\r\n}\r\ntmio_mmc_init_sg(host, data);\r\nhost->data = data;\r\nsd_ctrl_write16(host, CTL_SD_XFER_LEN, data->blksz);\r\nsd_ctrl_write16(host, CTL_XFER_BLK_COUNT, data->blocks);\r\ntmio_mmc_start_dma(host, data);\r\nreturn 0;\r\n}\r\nstatic void tmio_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)\r\n{\r\nstruct tmio_mmc_host *host = mmc_priv(mmc);\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&host->lock, flags);\r\nif (host->mrq) {\r\npr_debug("request not null\n");\r\nif (IS_ERR(host->mrq)) {\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nmrq->cmd->error = -EAGAIN;\r\nmmc_request_done(mmc, mrq);\r\nreturn;\r\n}\r\n}\r\nhost->last_req_ts = jiffies;\r\nwmb();\r\nhost->mrq = mrq;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\npm_runtime_get_sync(mmc_dev(mmc));\r\nif (mrq->data) {\r\nret = tmio_mmc_start_data(host, mrq->data);\r\nif (ret)\r\ngoto fail;\r\n}\r\nret = tmio_mmc_start_command(host, mrq->cmd);\r\nif (!ret) {\r\nschedule_delayed_work(&host->delayed_reset_work,\r\nmsecs_to_jiffies(CMDREQ_TIMEOUT));\r\nreturn;\r\n}\r\nfail:\r\nhost->force_pio = false;\r\nhost->mrq = NULL;\r\nmrq->cmd->error = ret;\r\nmmc_request_done(mmc, mrq);\r\npm_runtime_mark_last_busy(mmc_dev(mmc));\r\npm_runtime_put_autosuspend(mmc_dev(mmc));\r\n}\r\nstatic int tmio_mmc_clk_update(struct tmio_mmc_host *host)\r\n{\r\nstruct mmc_host *mmc = host->mmc;\r\nint ret;\r\nif (!host->clk_enable)\r\nreturn -ENOTSUPP;\r\nret = host->clk_enable(host->pdev, &mmc->f_max);\r\nif (!ret)\r\nmmc->f_min = mmc->f_max / 512;\r\nreturn ret;\r\n}\r\nstatic void tmio_mmc_power_on(struct tmio_mmc_host *host, unsigned short vdd)\r\n{\r\nstruct mmc_host *mmc = host->mmc;\r\nint ret = 0;\r\nif (host->set_pwr)\r\nhost->set_pwr(host->pdev, 1);\r\nif (!IS_ERR(mmc->supply.vmmc)) {\r\nret = mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, vdd);\r\nudelay(200);\r\n}\r\nif (!IS_ERR(mmc->supply.vqmmc) && !ret) {\r\nret = regulator_enable(mmc->supply.vqmmc);\r\nudelay(200);\r\n}\r\nif (ret < 0)\r\ndev_dbg(&host->pdev->dev, "Regulators failed to power up: %d\n",\r\nret);\r\n}\r\nstatic void tmio_mmc_power_off(struct tmio_mmc_host *host)\r\n{\r\nstruct mmc_host *mmc = host->mmc;\r\nif (!IS_ERR(mmc->supply.vqmmc))\r\nregulator_disable(mmc->supply.vqmmc);\r\nif (!IS_ERR(mmc->supply.vmmc))\r\nmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);\r\nif (host->set_pwr)\r\nhost->set_pwr(host->pdev, 0);\r\n}\r\nstatic void tmio_mmc_set_bus_width(struct tmio_mmc_host *host,\r\nunsigned char bus_width)\r\n{\r\nswitch (bus_width) {\r\ncase MMC_BUS_WIDTH_1:\r\nsd_ctrl_write16(host, CTL_SD_MEM_CARD_OPT, 0x80e0);\r\nbreak;\r\ncase MMC_BUS_WIDTH_4:\r\nsd_ctrl_write16(host, CTL_SD_MEM_CARD_OPT, 0x00e0);\r\nbreak;\r\n}\r\n}\r\nstatic void tmio_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)\r\n{\r\nstruct tmio_mmc_host *host = mmc_priv(mmc);\r\nstruct device *dev = &host->pdev->dev;\r\nunsigned long flags;\r\npm_runtime_get_sync(mmc_dev(mmc));\r\nmutex_lock(&host->ios_lock);\r\nspin_lock_irqsave(&host->lock, flags);\r\nif (host->mrq) {\r\nif (IS_ERR(host->mrq)) {\r\ndev_dbg(dev,\r\n"%s.%d: concurrent .set_ios(), clk %u, mode %u\n",\r\ncurrent->comm, task_pid_nr(current),\r\nios->clock, ios->power_mode);\r\nhost->mrq = ERR_PTR(-EINTR);\r\n} else {\r\ndev_dbg(dev,\r\n"%s.%d: CMD%u active since %lu, now %lu!\n",\r\ncurrent->comm, task_pid_nr(current),\r\nhost->mrq->cmd->opcode, host->last_req_ts, jiffies);\r\n}\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nmutex_unlock(&host->ios_lock);\r\nreturn;\r\n}\r\nhost->mrq = ERR_PTR(-EBUSY);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nswitch (ios->power_mode) {\r\ncase MMC_POWER_OFF:\r\ntmio_mmc_power_off(host);\r\ntmio_mmc_clk_stop(host);\r\nbreak;\r\ncase MMC_POWER_UP:\r\ntmio_mmc_set_clock(host, ios->clock);\r\ntmio_mmc_power_on(host, ios->vdd);\r\ntmio_mmc_clk_start(host);\r\ntmio_mmc_set_bus_width(host, ios->bus_width);\r\nbreak;\r\ncase MMC_POWER_ON:\r\ntmio_mmc_set_clock(host, ios->clock);\r\ntmio_mmc_clk_start(host);\r\ntmio_mmc_set_bus_width(host, ios->bus_width);\r\nbreak;\r\n}\r\nudelay(140);\r\nif (PTR_ERR(host->mrq) == -EINTR)\r\ndev_dbg(&host->pdev->dev,\r\n"%s.%d: IOS interrupted: clk %u, mode %u",\r\ncurrent->comm, task_pid_nr(current),\r\nios->clock, ios->power_mode);\r\nhost->mrq = NULL;\r\nhost->clk_cache = ios->clock;\r\nmutex_unlock(&host->ios_lock);\r\npm_runtime_mark_last_busy(mmc_dev(mmc));\r\npm_runtime_put_autosuspend(mmc_dev(mmc));\r\n}\r\nstatic int tmio_mmc_get_ro(struct mmc_host *mmc)\r\n{\r\nstruct tmio_mmc_host *host = mmc_priv(mmc);\r\nstruct tmio_mmc_data *pdata = host->pdata;\r\nint ret = mmc_gpio_get_ro(mmc);\r\nif (ret >= 0)\r\nreturn ret;\r\npm_runtime_get_sync(mmc_dev(mmc));\r\nret = !((pdata->flags & TMIO_MMC_WRPROTECT_DISABLE) ||\r\n(sd_ctrl_read32(host, CTL_STATUS) & TMIO_STAT_WRPROTECT));\r\npm_runtime_mark_last_busy(mmc_dev(mmc));\r\npm_runtime_put_autosuspend(mmc_dev(mmc));\r\nreturn ret;\r\n}\r\nstatic int tmio_multi_io_quirk(struct mmc_card *card,\r\nunsigned int direction, int blk_size)\r\n{\r\nstruct tmio_mmc_host *host = mmc_priv(card->host);\r\nif (host->multi_io_quirk)\r\nreturn host->multi_io_quirk(card, direction, blk_size);\r\nreturn blk_size;\r\n}\r\nstatic int tmio_mmc_init_ocr(struct tmio_mmc_host *host)\r\n{\r\nstruct tmio_mmc_data *pdata = host->pdata;\r\nstruct mmc_host *mmc = host->mmc;\r\nmmc_regulator_get_supply(mmc);\r\nif (!mmc->ocr_avail)\r\nmmc->ocr_avail = pdata->ocr_mask;\r\nif (!mmc->ocr_avail)\r\nreturn -EPROBE_DEFER;\r\nreturn 0;\r\n}\r\nstatic void tmio_mmc_of_parse(struct platform_device *pdev,\r\nstruct tmio_mmc_data *pdata)\r\n{\r\nconst struct device_node *np = pdev->dev.of_node;\r\nif (!np)\r\nreturn;\r\nif (of_get_property(np, "toshiba,mmc-wrprotect-disable", NULL))\r\npdata->flags |= TMIO_MMC_WRPROTECT_DISABLE;\r\n}\r\nstruct tmio_mmc_host*\r\ntmio_mmc_host_alloc(struct platform_device *pdev)\r\n{\r\nstruct tmio_mmc_host *host;\r\nstruct mmc_host *mmc;\r\nmmc = mmc_alloc_host(sizeof(struct tmio_mmc_host), &pdev->dev);\r\nif (!mmc)\r\nreturn NULL;\r\nhost = mmc_priv(mmc);\r\nhost->mmc = mmc;\r\nhost->pdev = pdev;\r\nreturn host;\r\n}\r\nvoid tmio_mmc_host_free(struct tmio_mmc_host *host)\r\n{\r\nmmc_free_host(host->mmc);\r\n}\r\nint tmio_mmc_host_probe(struct tmio_mmc_host *_host,\r\nstruct tmio_mmc_data *pdata)\r\n{\r\nstruct platform_device *pdev = _host->pdev;\r\nstruct mmc_host *mmc = _host->mmc;\r\nstruct resource *res_ctl;\r\nint ret;\r\nu32 irq_mask = TMIO_MASK_CMD;\r\ntmio_mmc_of_parse(pdev, pdata);\r\nif (!(pdata->flags & TMIO_MMC_HAS_IDLE_WAIT))\r\n_host->write16_hook = NULL;\r\nres_ctl = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res_ctl)\r\nreturn -EINVAL;\r\nret = mmc_of_parse(mmc);\r\nif (ret < 0)\r\ngoto host_free;\r\n_host->pdata = pdata;\r\nplatform_set_drvdata(pdev, mmc);\r\n_host->set_pwr = pdata->set_pwr;\r\n_host->set_clk_div = pdata->set_clk_div;\r\nret = tmio_mmc_init_ocr(_host);\r\nif (ret < 0)\r\ngoto host_free;\r\n_host->ctl = devm_ioremap(&pdev->dev,\r\nres_ctl->start, resource_size(res_ctl));\r\nif (!_host->ctl) {\r\nret = -ENOMEM;\r\ngoto host_free;\r\n}\r\nmmc->ops = &tmio_mmc_ops;\r\nmmc->caps |= MMC_CAP_4_BIT_DATA | pdata->capabilities;\r\nmmc->caps2 |= pdata->capabilities2;\r\nmmc->max_segs = 32;\r\nmmc->max_blk_size = 512;\r\nmmc->max_blk_count = (PAGE_CACHE_SIZE / mmc->max_blk_size) *\r\nmmc->max_segs;\r\nmmc->max_req_size = mmc->max_blk_size * mmc->max_blk_count;\r\nmmc->max_seg_size = mmc->max_req_size;\r\n_host->native_hotplug = !(pdata->flags & TMIO_MMC_USE_GPIO_CD ||\r\nmmc->caps & MMC_CAP_NEEDS_POLL ||\r\nmmc->caps & MMC_CAP_NONREMOVABLE ||\r\nmmc->slot.cd_irq >= 0);\r\nif (tmio_mmc_clk_update(_host) < 0) {\r\nmmc->f_max = pdata->hclk;\r\nmmc->f_min = mmc->f_max / 512;\r\n}\r\nif (mmc->f_min == 0) {\r\nret = -EINVAL;\r\ngoto host_free;\r\n}\r\nif (_host->native_hotplug)\r\npm_runtime_get_noresume(&pdev->dev);\r\ntmio_mmc_clk_stop(_host);\r\ntmio_mmc_reset(_host);\r\n_host->sdcard_irq_mask = sd_ctrl_read32(_host, CTL_IRQ_MASK);\r\ntmio_mmc_disable_mmc_irqs(_host, TMIO_MASK_ALL);\r\nif (!_host->chan_rx)\r\nirq_mask |= TMIO_MASK_READOP;\r\nif (!_host->chan_tx)\r\nirq_mask |= TMIO_MASK_WRITEOP;\r\nif (!_host->native_hotplug)\r\nirq_mask &= ~(TMIO_STAT_CARD_REMOVE | TMIO_STAT_CARD_INSERT);\r\n_host->sdcard_irq_mask &= ~irq_mask;\r\n_host->sdio_irq_enabled = false;\r\nif (pdata->flags & TMIO_MMC_SDIO_IRQ) {\r\n_host->sdio_irq_mask = TMIO_SDIO_MASK_ALL;\r\nsd_ctrl_write16(_host, CTL_SDIO_IRQ_MASK, _host->sdio_irq_mask);\r\nsd_ctrl_write16(_host, CTL_TRANSACTION_CTL, 0x0000);\r\n}\r\nspin_lock_init(&_host->lock);\r\nmutex_init(&_host->ios_lock);\r\nINIT_DELAYED_WORK(&_host->delayed_reset_work, tmio_mmc_reset_work);\r\nINIT_WORK(&_host->done, tmio_mmc_done_work);\r\ntmio_mmc_request_dma(_host, pdata);\r\npm_runtime_set_active(&pdev->dev);\r\npm_runtime_set_autosuspend_delay(&pdev->dev, 50);\r\npm_runtime_use_autosuspend(&pdev->dev);\r\npm_runtime_enable(&pdev->dev);\r\nret = mmc_add_host(mmc);\r\nif (ret < 0) {\r\ntmio_mmc_host_remove(_host);\r\nreturn ret;\r\n}\r\ndev_pm_qos_expose_latency_limit(&pdev->dev, 100);\r\nif (pdata->flags & TMIO_MMC_USE_GPIO_CD) {\r\nret = mmc_gpio_request_cd(mmc, pdata->cd_gpio, 0);\r\nif (ret < 0) {\r\ntmio_mmc_host_remove(_host);\r\nreturn ret;\r\n}\r\nmmc_gpiod_request_cd_irq(mmc);\r\n}\r\nreturn 0;\r\nhost_free:\r\nreturn ret;\r\n}\r\nvoid tmio_mmc_host_remove(struct tmio_mmc_host *host)\r\n{\r\nstruct platform_device *pdev = host->pdev;\r\nstruct mmc_host *mmc = host->mmc;\r\nif (!host->native_hotplug)\r\npm_runtime_get_sync(&pdev->dev);\r\ndev_pm_qos_hide_latency_limit(&pdev->dev);\r\nmmc_remove_host(mmc);\r\ncancel_work_sync(&host->done);\r\ncancel_delayed_work_sync(&host->delayed_reset_work);\r\ntmio_mmc_release_dma(host);\r\npm_runtime_put_sync(&pdev->dev);\r\npm_runtime_disable(&pdev->dev);\r\n}\r\nint tmio_mmc_host_runtime_suspend(struct device *dev)\r\n{\r\nstruct mmc_host *mmc = dev_get_drvdata(dev);\r\nstruct tmio_mmc_host *host = mmc_priv(mmc);\r\ntmio_mmc_disable_mmc_irqs(host, TMIO_MASK_ALL);\r\nif (host->clk_cache)\r\ntmio_mmc_clk_stop(host);\r\nif (host->clk_disable)\r\nhost->clk_disable(host->pdev);\r\nreturn 0;\r\n}\r\nint tmio_mmc_host_runtime_resume(struct device *dev)\r\n{\r\nstruct mmc_host *mmc = dev_get_drvdata(dev);\r\nstruct tmio_mmc_host *host = mmc_priv(mmc);\r\ntmio_mmc_reset(host);\r\ntmio_mmc_clk_update(host);\r\nif (host->clk_cache) {\r\ntmio_mmc_set_clock(host, host->clk_cache);\r\ntmio_mmc_clk_start(host);\r\n}\r\ntmio_mmc_enable_dma(host, true);\r\nreturn 0;\r\n}
