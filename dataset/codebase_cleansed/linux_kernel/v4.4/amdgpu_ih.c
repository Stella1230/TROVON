static int amdgpu_ih_ring_alloc(struct amdgpu_device *adev)\r\n{\r\nint r;\r\nif (adev->irq.ih.ring_obj == NULL) {\r\nr = amdgpu_bo_create(adev, adev->irq.ih.ring_size,\r\nPAGE_SIZE, true,\r\nAMDGPU_GEM_DOMAIN_GTT, 0,\r\nNULL, NULL, &adev->irq.ih.ring_obj);\r\nif (r) {\r\nDRM_ERROR("amdgpu: failed to create ih ring buffer (%d).\n", r);\r\nreturn r;\r\n}\r\nr = amdgpu_bo_reserve(adev->irq.ih.ring_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = amdgpu_bo_pin(adev->irq.ih.ring_obj,\r\nAMDGPU_GEM_DOMAIN_GTT,\r\n&adev->irq.ih.gpu_addr);\r\nif (r) {\r\namdgpu_bo_unreserve(adev->irq.ih.ring_obj);\r\nDRM_ERROR("amdgpu: failed to pin ih ring buffer (%d).\n", r);\r\nreturn r;\r\n}\r\nr = amdgpu_bo_kmap(adev->irq.ih.ring_obj,\r\n(void **)&adev->irq.ih.ring);\r\namdgpu_bo_unreserve(adev->irq.ih.ring_obj);\r\nif (r) {\r\nDRM_ERROR("amdgpu: failed to map ih ring buffer (%d).\n", r);\r\nreturn r;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint amdgpu_ih_ring_init(struct amdgpu_device *adev, unsigned ring_size,\r\nbool use_bus_addr)\r\n{\r\nu32 rb_bufsz;\r\nint r;\r\nrb_bufsz = order_base_2(ring_size / 4);\r\nring_size = (1 << rb_bufsz) * 4;\r\nadev->irq.ih.ring_size = ring_size;\r\nadev->irq.ih.ptr_mask = adev->irq.ih.ring_size - 1;\r\nadev->irq.ih.rptr = 0;\r\nadev->irq.ih.use_bus_addr = use_bus_addr;\r\nif (adev->irq.ih.use_bus_addr) {\r\nif (!adev->irq.ih.ring) {\r\nadev->irq.ih.ring = pci_alloc_consistent(adev->pdev,\r\nadev->irq.ih.ring_size + 8,\r\n&adev->irq.ih.rb_dma_addr);\r\nif (adev->irq.ih.ring == NULL)\r\nreturn -ENOMEM;\r\nmemset((void *)adev->irq.ih.ring, 0, adev->irq.ih.ring_size + 8);\r\nadev->irq.ih.wptr_offs = (adev->irq.ih.ring_size / 4) + 0;\r\nadev->irq.ih.rptr_offs = (adev->irq.ih.ring_size / 4) + 1;\r\n}\r\nreturn 0;\r\n} else {\r\nr = amdgpu_wb_get(adev, &adev->irq.ih.wptr_offs);\r\nif (r) {\r\ndev_err(adev->dev, "(%d) ih wptr_offs wb alloc failed\n", r);\r\nreturn r;\r\n}\r\nr = amdgpu_wb_get(adev, &adev->irq.ih.rptr_offs);\r\nif (r) {\r\namdgpu_wb_free(adev, adev->irq.ih.wptr_offs);\r\ndev_err(adev->dev, "(%d) ih rptr_offs wb alloc failed\n", r);\r\nreturn r;\r\n}\r\nreturn amdgpu_ih_ring_alloc(adev);\r\n}\r\n}\r\nvoid amdgpu_ih_ring_fini(struct amdgpu_device *adev)\r\n{\r\nint r;\r\nif (adev->irq.ih.use_bus_addr) {\r\nif (adev->irq.ih.ring) {\r\npci_free_consistent(adev->pdev, adev->irq.ih.ring_size + 8,\r\n(void *)adev->irq.ih.ring,\r\nadev->irq.ih.rb_dma_addr);\r\nadev->irq.ih.ring = NULL;\r\n}\r\n} else {\r\nif (adev->irq.ih.ring_obj) {\r\nr = amdgpu_bo_reserve(adev->irq.ih.ring_obj, false);\r\nif (likely(r == 0)) {\r\namdgpu_bo_kunmap(adev->irq.ih.ring_obj);\r\namdgpu_bo_unpin(adev->irq.ih.ring_obj);\r\namdgpu_bo_unreserve(adev->irq.ih.ring_obj);\r\n}\r\namdgpu_bo_unref(&adev->irq.ih.ring_obj);\r\nadev->irq.ih.ring = NULL;\r\nadev->irq.ih.ring_obj = NULL;\r\n}\r\namdgpu_wb_free(adev, adev->irq.ih.wptr_offs);\r\namdgpu_wb_free(adev, adev->irq.ih.rptr_offs);\r\n}\r\n}\r\nint amdgpu_ih_process(struct amdgpu_device *adev)\r\n{\r\nstruct amdgpu_iv_entry entry;\r\nu32 wptr;\r\nif (!adev->irq.ih.enabled || adev->shutdown)\r\nreturn IRQ_NONE;\r\nwptr = amdgpu_ih_get_wptr(adev);\r\nrestart_ih:\r\nif (atomic_xchg(&adev->irq.ih.lock, 1))\r\nreturn IRQ_NONE;\r\nDRM_DEBUG("%s: rptr %d, wptr %d\n", __func__, adev->irq.ih.rptr, wptr);\r\nrmb();\r\nwhile (adev->irq.ih.rptr != wptr) {\r\nu32 ring_index = adev->irq.ih.rptr >> 2;\r\namdgpu_amdkfd_interrupt(adev,\r\n(const void *) &adev->irq.ih.ring[ring_index]);\r\nentry.iv_entry = (const uint32_t *)\r\n&adev->irq.ih.ring[ring_index];\r\namdgpu_ih_decode_iv(adev, &entry);\r\nadev->irq.ih.rptr &= adev->irq.ih.ptr_mask;\r\namdgpu_irq_dispatch(adev, &entry);\r\n}\r\namdgpu_ih_set_rptr(adev);\r\natomic_set(&adev->irq.ih.lock, 0);\r\nwptr = amdgpu_ih_get_wptr(adev);\r\nif (wptr != adev->irq.ih.rptr)\r\ngoto restart_ih;\r\nreturn IRQ_HANDLED;\r\n}
