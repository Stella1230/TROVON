void nfs4_ff_layout_put_deviceid(struct nfs4_ff_layout_ds *mirror_ds)\r\n{\r\nif (mirror_ds)\r\nnfs4_put_deviceid_node(&mirror_ds->id_node);\r\n}\r\nvoid nfs4_ff_layout_free_deviceid(struct nfs4_ff_layout_ds *mirror_ds)\r\n{\r\nnfs4_print_deviceid(&mirror_ds->id_node.deviceid);\r\nnfs4_pnfs_ds_put(mirror_ds->ds);\r\nkfree_rcu(mirror_ds, id_node.rcu);\r\n}\r\nstruct nfs4_ff_layout_ds *\r\nnfs4_ff_alloc_deviceid_node(struct nfs_server *server, struct pnfs_device *pdev,\r\ngfp_t gfp_flags)\r\n{\r\nstruct xdr_stream stream;\r\nstruct xdr_buf buf;\r\nstruct page *scratch;\r\nstruct list_head dsaddrs;\r\nstruct nfs4_pnfs_ds_addr *da;\r\nstruct nfs4_ff_layout_ds *new_ds = NULL;\r\nstruct nfs4_ff_ds_version *ds_versions = NULL;\r\nu32 mp_count;\r\nu32 version_count;\r\n__be32 *p;\r\nint i, ret = -ENOMEM;\r\nscratch = alloc_page(gfp_flags);\r\nif (!scratch)\r\ngoto out_err;\r\nnew_ds = kzalloc(sizeof(struct nfs4_ff_layout_ds), gfp_flags);\r\nif (!new_ds)\r\ngoto out_scratch;\r\nnfs4_init_deviceid_node(&new_ds->id_node,\r\nserver,\r\n&pdev->dev_id);\r\nINIT_LIST_HEAD(&dsaddrs);\r\nxdr_init_decode_pages(&stream, &buf, pdev->pages, pdev->pglen);\r\nxdr_set_scratch_buffer(&stream, page_address(scratch), PAGE_SIZE);\r\np = xdr_inline_decode(&stream, 4);\r\nif (unlikely(!p))\r\ngoto out_err_drain_dsaddrs;\r\nmp_count = be32_to_cpup(p);\r\ndprintk("%s: multipath ds count %d\n", __func__, mp_count);\r\nfor (i = 0; i < mp_count; i++) {\r\nda = nfs4_decode_mp_ds_addr(server->nfs_client->cl_net,\r\n&stream, gfp_flags);\r\nif (da)\r\nlist_add_tail(&da->da_node, &dsaddrs);\r\n}\r\nif (list_empty(&dsaddrs)) {\r\ndprintk("%s: no suitable DS addresses found\n",\r\n__func__);\r\nret = -ENOMEDIUM;\r\ngoto out_err_drain_dsaddrs;\r\n}\r\np = xdr_inline_decode(&stream, 4);\r\nif (unlikely(!p))\r\ngoto out_err_drain_dsaddrs;\r\nversion_count = be32_to_cpup(p);\r\ndprintk("%s: version count %d\n", __func__, version_count);\r\nds_versions = kzalloc(version_count * sizeof(struct nfs4_ff_ds_version),\r\ngfp_flags);\r\nif (!ds_versions)\r\ngoto out_scratch;\r\nfor (i = 0; i < version_count; i++) {\r\np = xdr_inline_decode(&stream, 20);\r\nif (unlikely(!p))\r\ngoto out_err_drain_dsaddrs;\r\nds_versions[i].version = be32_to_cpup(p++);\r\nds_versions[i].minor_version = be32_to_cpup(p++);\r\nds_versions[i].rsize = nfs_block_size(be32_to_cpup(p++), NULL);\r\nds_versions[i].wsize = nfs_block_size(be32_to_cpup(p++), NULL);\r\nds_versions[i].tightly_coupled = be32_to_cpup(p);\r\nif (ds_versions[i].rsize > NFS_MAX_FILE_IO_SIZE)\r\nds_versions[i].rsize = NFS_MAX_FILE_IO_SIZE;\r\nif (ds_versions[i].wsize > NFS_MAX_FILE_IO_SIZE)\r\nds_versions[i].wsize = NFS_MAX_FILE_IO_SIZE;\r\nif (ds_versions[i].version != 3 || ds_versions[i].minor_version != 0) {\r\ndprintk("%s: [%d] unsupported ds version %d-%d\n", __func__,\r\ni, ds_versions[i].version,\r\nds_versions[i].minor_version);\r\nret = -EPROTONOSUPPORT;\r\ngoto out_err_drain_dsaddrs;\r\n}\r\ndprintk("%s: [%d] vers %u minor_ver %u rsize %u wsize %u coupled %d\n",\r\n__func__, i, ds_versions[i].version,\r\nds_versions[i].minor_version,\r\nds_versions[i].rsize,\r\nds_versions[i].wsize,\r\nds_versions[i].tightly_coupled);\r\n}\r\nnew_ds->ds_versions = ds_versions;\r\nnew_ds->ds_versions_cnt = version_count;\r\nnew_ds->ds = nfs4_pnfs_ds_add(&dsaddrs, gfp_flags);\r\nif (!new_ds->ds)\r\ngoto out_err_drain_dsaddrs;\r\nwhile (!list_empty(&dsaddrs)) {\r\nda = list_first_entry(&dsaddrs,\r\nstruct nfs4_pnfs_ds_addr,\r\nda_node);\r\nlist_del_init(&da->da_node);\r\nkfree(da->da_remotestr);\r\nkfree(da);\r\n}\r\n__free_page(scratch);\r\nreturn new_ds;\r\nout_err_drain_dsaddrs:\r\nwhile (!list_empty(&dsaddrs)) {\r\nda = list_first_entry(&dsaddrs, struct nfs4_pnfs_ds_addr,\r\nda_node);\r\nlist_del_init(&da->da_node);\r\nkfree(da->da_remotestr);\r\nkfree(da);\r\n}\r\nkfree(ds_versions);\r\nout_scratch:\r\n__free_page(scratch);\r\nout_err:\r\nkfree(new_ds);\r\ndprintk("%s ERROR: returning %d\n", __func__, ret);\r\nreturn NULL;\r\n}\r\nstatic void ff_layout_mark_devid_invalid(struct pnfs_layout_segment *lseg,\r\nstruct nfs4_deviceid_node *devid)\r\n{\r\nnfs4_mark_deviceid_unavailable(devid);\r\nif (!ff_layout_has_available_ds(lseg))\r\npnfs_error_mark_layout_for_return(lseg->pls_layout->plh_inode,\r\nlseg);\r\n}\r\nstatic bool ff_layout_mirror_valid(struct pnfs_layout_segment *lseg,\r\nstruct nfs4_ff_layout_mirror *mirror)\r\n{\r\nif (mirror == NULL || mirror->mirror_ds == NULL) {\r\npnfs_error_mark_layout_for_return(lseg->pls_layout->plh_inode,\r\nlseg);\r\nreturn false;\r\n}\r\nif (mirror->mirror_ds->ds == NULL) {\r\nstruct nfs4_deviceid_node *devid;\r\ndevid = &mirror->mirror_ds->id_node;\r\nff_layout_mark_devid_invalid(lseg, devid);\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic u64\r\nend_offset(u64 start, u64 len)\r\n{\r\nu64 end;\r\nend = start + len;\r\nreturn end >= start ? end : NFS4_MAX_UINT64;\r\n}\r\nstatic void extend_ds_error(struct nfs4_ff_layout_ds_err *err,\r\nu64 offset, u64 length)\r\n{\r\nu64 end;\r\nend = max_t(u64, end_offset(err->offset, err->length),\r\nend_offset(offset, length));\r\nerr->offset = min_t(u64, err->offset, offset);\r\nerr->length = end - err->offset;\r\n}\r\nstatic bool ds_error_can_merge(struct nfs4_ff_layout_ds_err *err, u64 offset,\r\nu64 length, int status, enum nfs_opnum4 opnum,\r\nnfs4_stateid *stateid,\r\nstruct nfs4_deviceid *deviceid)\r\n{\r\nreturn err->status == status && err->opnum == opnum &&\r\nnfs4_stateid_match(&err->stateid, stateid) &&\r\n!memcmp(&err->deviceid, deviceid, sizeof(*deviceid)) &&\r\nend_offset(err->offset, err->length) >= offset &&\r\nerr->offset <= end_offset(offset, length);\r\n}\r\nstatic bool merge_ds_error(struct nfs4_ff_layout_ds_err *old,\r\nstruct nfs4_ff_layout_ds_err *new)\r\n{\r\nif (!ds_error_can_merge(old, new->offset, new->length, new->status,\r\nnew->opnum, &new->stateid, &new->deviceid))\r\nreturn false;\r\nextend_ds_error(old, new->offset, new->length);\r\nreturn true;\r\n}\r\nstatic bool\r\nff_layout_add_ds_error_locked(struct nfs4_flexfile_layout *flo,\r\nstruct nfs4_ff_layout_ds_err *dserr)\r\n{\r\nstruct nfs4_ff_layout_ds_err *err;\r\nlist_for_each_entry(err, &flo->error_list, list) {\r\nif (merge_ds_error(err, dserr)) {\r\nreturn true;\r\n}\r\n}\r\nlist_add(&dserr->list, &flo->error_list);\r\nreturn false;\r\n}\r\nstatic bool\r\nff_layout_update_ds_error(struct nfs4_flexfile_layout *flo, u64 offset,\r\nu64 length, int status, enum nfs_opnum4 opnum,\r\nnfs4_stateid *stateid, struct nfs4_deviceid *deviceid)\r\n{\r\nbool found = false;\r\nstruct nfs4_ff_layout_ds_err *err;\r\nlist_for_each_entry(err, &flo->error_list, list) {\r\nif (ds_error_can_merge(err, offset, length, status, opnum,\r\nstateid, deviceid)) {\r\nfound = true;\r\nextend_ds_error(err, offset, length);\r\nbreak;\r\n}\r\n}\r\nreturn found;\r\n}\r\nint ff_layout_track_ds_error(struct nfs4_flexfile_layout *flo,\r\nstruct nfs4_ff_layout_mirror *mirror, u64 offset,\r\nu64 length, int status, enum nfs_opnum4 opnum,\r\ngfp_t gfp_flags)\r\n{\r\nstruct nfs4_ff_layout_ds_err *dserr;\r\nbool needfree;\r\nif (status == 0)\r\nreturn 0;\r\nif (mirror->mirror_ds == NULL)\r\nreturn -EINVAL;\r\nspin_lock(&flo->generic_hdr.plh_inode->i_lock);\r\nif (ff_layout_update_ds_error(flo, offset, length, status, opnum,\r\n&mirror->stateid,\r\n&mirror->mirror_ds->id_node.deviceid)) {\r\nspin_unlock(&flo->generic_hdr.plh_inode->i_lock);\r\nreturn 0;\r\n}\r\nspin_unlock(&flo->generic_hdr.plh_inode->i_lock);\r\ndserr = kmalloc(sizeof(*dserr), gfp_flags);\r\nif (!dserr)\r\nreturn -ENOMEM;\r\nINIT_LIST_HEAD(&dserr->list);\r\ndserr->offset = offset;\r\ndserr->length = length;\r\ndserr->status = status;\r\ndserr->opnum = opnum;\r\nnfs4_stateid_copy(&dserr->stateid, &mirror->stateid);\r\nmemcpy(&dserr->deviceid, &mirror->mirror_ds->id_node.deviceid,\r\nNFS4_DEVICEID4_SIZE);\r\nspin_lock(&flo->generic_hdr.plh_inode->i_lock);\r\nneedfree = ff_layout_add_ds_error_locked(flo, dserr);\r\nspin_unlock(&flo->generic_hdr.plh_inode->i_lock);\r\nif (needfree)\r\nkfree(dserr);\r\nreturn 0;\r\n}\r\nstatic rpc_authflavor_t\r\nnfs4_ff_layout_choose_authflavor(struct nfs4_ff_layout_mirror *mirror)\r\n{\r\nif (mirror->uid == (u32)-1)\r\nreturn RPC_AUTH_NULL;\r\nreturn RPC_AUTH_UNIX;\r\n}\r\nstatic int ff_layout_update_mirror_cred(struct nfs4_ff_layout_mirror *mirror,\r\nstruct nfs4_pnfs_ds *ds)\r\n{\r\nif (ds->ds_clp && !mirror->cred &&\r\nmirror->mirror_ds->ds_versions[0].version == 3) {\r\nstruct rpc_auth *auth = ds->ds_clp->cl_rpcclient->cl_auth;\r\nstruct rpc_cred *cred;\r\nstruct auth_cred acred = {\r\n.uid = make_kuid(&init_user_ns, mirror->uid),\r\n.gid = make_kgid(&init_user_ns, mirror->gid),\r\n};\r\ncred = auth->au_ops->lookup_cred(auth, &acred, 0);\r\nif (IS_ERR(cred)) {\r\ndprintk("%s: lookup_cred failed with %ld\n",\r\n__func__, PTR_ERR(cred));\r\nreturn PTR_ERR(cred);\r\n} else {\r\nif (cmpxchg(&mirror->cred, NULL, cred))\r\nput_rpccred(cred);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstruct nfs_fh *\r\nnfs4_ff_layout_select_ds_fh(struct pnfs_layout_segment *lseg, u32 mirror_idx)\r\n{\r\nstruct nfs4_ff_layout_mirror *mirror = FF_LAYOUT_COMP(lseg, mirror_idx);\r\nstruct nfs_fh *fh = NULL;\r\nif (!ff_layout_mirror_valid(lseg, mirror)) {\r\npr_err_ratelimited("NFS: %s: No data server for mirror offset index %d\n",\r\n__func__, mirror_idx);\r\ngoto out;\r\n}\r\nfh = &mirror->fh_versions[0];\r\nout:\r\nreturn fh;\r\n}\r\nstruct nfs4_pnfs_ds *\r\nnfs4_ff_layout_prepare_ds(struct pnfs_layout_segment *lseg, u32 ds_idx,\r\nbool fail_return)\r\n{\r\nstruct nfs4_ff_layout_mirror *mirror = FF_LAYOUT_COMP(lseg, ds_idx);\r\nstruct nfs4_pnfs_ds *ds = NULL;\r\nstruct nfs4_deviceid_node *devid;\r\nstruct inode *ino = lseg->pls_layout->plh_inode;\r\nstruct nfs_server *s = NFS_SERVER(ino);\r\nunsigned int max_payload;\r\nrpc_authflavor_t flavor;\r\nif (!ff_layout_mirror_valid(lseg, mirror)) {\r\npr_err_ratelimited("NFS: %s: No data server for offset index %d\n",\r\n__func__, ds_idx);\r\ngoto out;\r\n}\r\ndevid = &mirror->mirror_ds->id_node;\r\nif (ff_layout_test_devid_unavailable(devid))\r\ngoto out;\r\nds = mirror->mirror_ds->ds;\r\nsmp_rmb();\r\nif (ds->ds_clp)\r\ngoto out_update_creds;\r\nflavor = nfs4_ff_layout_choose_authflavor(mirror);\r\nnfs4_pnfs_ds_connect(s, ds, devid, dataserver_timeo,\r\ndataserver_retrans,\r\nmirror->mirror_ds->ds_versions[0].version,\r\nmirror->mirror_ds->ds_versions[0].minor_version,\r\nflavor);\r\nif (ds->ds_clp) {\r\nmax_payload =\r\nnfs_block_size(rpc_max_payload(ds->ds_clp->cl_rpcclient),\r\nNULL);\r\nif (mirror->mirror_ds->ds_versions[0].rsize > max_payload)\r\nmirror->mirror_ds->ds_versions[0].rsize = max_payload;\r\nif (mirror->mirror_ds->ds_versions[0].wsize > max_payload)\r\nmirror->mirror_ds->ds_versions[0].wsize = max_payload;\r\n} else {\r\nff_layout_track_ds_error(FF_LAYOUT_FROM_HDR(lseg->pls_layout),\r\nmirror, lseg->pls_range.offset,\r\nlseg->pls_range.length, NFS4ERR_NXIO,\r\nOP_ILLEGAL, GFP_NOIO);\r\nif (fail_return) {\r\npnfs_error_mark_layout_for_return(ino, lseg);\r\nif (ff_layout_has_available_ds(lseg))\r\npnfs_set_retry_layoutget(lseg->pls_layout);\r\nelse\r\npnfs_clear_retry_layoutget(lseg->pls_layout);\r\n} else {\r\nif (ff_layout_has_available_ds(lseg))\r\nset_bit(NFS_LAYOUT_RETURN_BEFORE_CLOSE,\r\n&lseg->pls_layout->plh_flags);\r\nelse {\r\npnfs_error_mark_layout_for_return(ino, lseg);\r\npnfs_clear_retry_layoutget(lseg->pls_layout);\r\n}\r\n}\r\n}\r\nout_update_creds:\r\nif (ff_layout_update_mirror_cred(mirror, ds))\r\nds = NULL;\r\nout:\r\nreturn ds;\r\n}\r\nstruct rpc_cred *\r\nff_layout_get_ds_cred(struct pnfs_layout_segment *lseg, u32 ds_idx,\r\nstruct rpc_cred *mdscred)\r\n{\r\nstruct nfs4_ff_layout_mirror *mirror = FF_LAYOUT_COMP(lseg, ds_idx);\r\nstruct rpc_cred *cred = ERR_PTR(-EINVAL);\r\nif (!nfs4_ff_layout_prepare_ds(lseg, ds_idx, true))\r\ngoto out;\r\nif (mirror && mirror->cred)\r\ncred = mirror->cred;\r\nelse\r\ncred = mdscred;\r\nout:\r\nreturn cred;\r\n}\r\nstruct rpc_clnt *\r\nnfs4_ff_find_or_create_ds_client(struct pnfs_layout_segment *lseg, u32 ds_idx,\r\nstruct nfs_client *ds_clp, struct inode *inode)\r\n{\r\nstruct nfs4_ff_layout_mirror *mirror = FF_LAYOUT_COMP(lseg, ds_idx);\r\nswitch (mirror->mirror_ds->ds_versions[0].version) {\r\ncase 3:\r\nreturn ds_clp->cl_rpcclient;\r\ncase 4:\r\nreturn nfs4_find_or_create_ds_client(ds_clp, inode);\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic bool is_range_intersecting(u64 offset1, u64 length1,\r\nu64 offset2, u64 length2)\r\n{\r\nu64 end1 = end_offset(offset1, length1);\r\nu64 end2 = end_offset(offset2, length2);\r\nreturn (end1 == NFS4_MAX_UINT64 || end1 > offset2) &&\r\n(end2 == NFS4_MAX_UINT64 || end2 > offset1);\r\n}\r\nint ff_layout_encode_ds_ioerr(struct nfs4_flexfile_layout *flo,\r\nstruct xdr_stream *xdr, int *count,\r\nconst struct pnfs_layout_range *range)\r\n{\r\nstruct nfs4_ff_layout_ds_err *err, *n;\r\n__be32 *p;\r\nlist_for_each_entry_safe(err, n, &flo->error_list, list) {\r\nif (!is_range_intersecting(err->offset, err->length,\r\nrange->offset, range->length))\r\ncontinue;\r\np = xdr_reserve_space(xdr,\r\n28 + NFS4_STATEID_SIZE + NFS4_DEVICEID4_SIZE);\r\nif (unlikely(!p))\r\nreturn -ENOBUFS;\r\np = xdr_encode_hyper(p, err->offset);\r\np = xdr_encode_hyper(p, err->length);\r\np = xdr_encode_opaque_fixed(p, &err->stateid,\r\nNFS4_STATEID_SIZE);\r\n*p++ = cpu_to_be32(1);\r\np = xdr_encode_opaque_fixed(p, &err->deviceid,\r\nNFS4_DEVICEID4_SIZE);\r\n*p++ = cpu_to_be32(err->status);\r\n*p++ = cpu_to_be32(err->opnum);\r\n*count += 1;\r\nlist_del(&err->list);\r\ndprintk("%s: offset %llu length %llu status %d op %d count %d\n",\r\n__func__, err->offset, err->length, err->status,\r\nerr->opnum, *count);\r\nkfree(err);\r\n}\r\nreturn 0;\r\n}\r\nstatic bool ff_read_layout_has_available_ds(struct pnfs_layout_segment *lseg)\r\n{\r\nstruct nfs4_ff_layout_mirror *mirror;\r\nstruct nfs4_deviceid_node *devid;\r\nu32 idx;\r\nfor (idx = 0; idx < FF_LAYOUT_MIRROR_COUNT(lseg); idx++) {\r\nmirror = FF_LAYOUT_COMP(lseg, idx);\r\nif (mirror && mirror->mirror_ds) {\r\ndevid = &mirror->mirror_ds->id_node;\r\nif (!ff_layout_test_devid_unavailable(devid))\r\nreturn true;\r\n}\r\n}\r\nreturn false;\r\n}\r\nstatic bool ff_rw_layout_has_available_ds(struct pnfs_layout_segment *lseg)\r\n{\r\nstruct nfs4_ff_layout_mirror *mirror;\r\nstruct nfs4_deviceid_node *devid;\r\nu32 idx;\r\nfor (idx = 0; idx < FF_LAYOUT_MIRROR_COUNT(lseg); idx++) {\r\nmirror = FF_LAYOUT_COMP(lseg, idx);\r\nif (!mirror || !mirror->mirror_ds)\r\nreturn false;\r\ndevid = &mirror->mirror_ds->id_node;\r\nif (ff_layout_test_devid_unavailable(devid))\r\nreturn false;\r\n}\r\nreturn FF_LAYOUT_MIRROR_COUNT(lseg) != 0;\r\n}\r\nbool ff_layout_has_available_ds(struct pnfs_layout_segment *lseg)\r\n{\r\nif (lseg->pls_range.iomode == IOMODE_READ)\r\nreturn ff_read_layout_has_available_ds(lseg);\r\nreturn ff_rw_layout_has_available_ds(lseg);\r\n}
