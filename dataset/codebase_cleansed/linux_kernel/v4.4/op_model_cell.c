static int\r\nrtas_ibm_cbe_perftools(int subfunc, int passthru,\r\nvoid *address, unsigned long length)\r\n{\r\nu64 paddr = __pa(address);\r\nreturn rtas_call(pm_rtas_token, 5, 1, NULL, subfunc,\r\npassthru, paddr >> 32, paddr & 0xffffffff, length);\r\n}\r\nstatic void pm_rtas_reset_signals(u32 node)\r\n{\r\nint ret;\r\nstruct pm_signal pm_signal_local;\r\npm_signal_local.cpu = node;\r\npm_signal_local.signal_group = 21;\r\npm_signal_local.bus_word = 1;\r\npm_signal_local.sub_unit = 0;\r\npm_signal_local.bit = 0;\r\nret = rtas_ibm_cbe_perftools(SUBFUNC_RESET, PASSTHRU_DISABLE,\r\n&pm_signal_local,\r\nsizeof(struct pm_signal));\r\nif (unlikely(ret))\r\nprintk(KERN_WARNING "%s: rtas returned: %d\n",\r\n__func__, ret);\r\n}\r\nstatic int pm_rtas_activate_signals(u32 node, u32 count)\r\n{\r\nint ret;\r\nint i, j;\r\nstruct pm_signal pm_signal_local[NR_PHYS_CTRS];\r\ni = 0;\r\nfor (j = 0; j < count; j++) {\r\nif (pm_signal[j].signal_group != PPU_CYCLES_GRP_NUM) {\r\npm_signal_local[i].cpu = node;\r\npm_signal_local[i].signal_group\r\n= pm_signal[j].signal_group;\r\npm_signal_local[i].bus_word = pm_signal[j].bus_word;\r\npm_signal_local[i].sub_unit = pm_signal[j].sub_unit;\r\npm_signal_local[i].bit = pm_signal[j].bit;\r\ni++;\r\n}\r\n}\r\nif (i != 0) {\r\nret = rtas_ibm_cbe_perftools(SUBFUNC_ACTIVATE, PASSTHRU_ENABLE,\r\npm_signal_local,\r\ni * sizeof(struct pm_signal));\r\nif (unlikely(ret)) {\r\nprintk(KERN_WARNING "%s: rtas returned: %d\n",\r\n__func__, ret);\r\nreturn -EIO;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void set_pm_event(u32 ctr, int event, u32 unit_mask)\r\n{\r\nstruct pm_signal *p;\r\nu32 signal_bit;\r\nu32 bus_word, bus_type, count_cycles, polarity, input_control;\r\nint j, i;\r\nif (event == PPU_CYCLES_EVENT_NUM) {\r\npm_regs.pm07_cntrl[ctr] = CBE_COUNT_ALL_CYCLES;\r\np = &(pm_signal[ctr]);\r\np->signal_group = PPU_CYCLES_GRP_NUM;\r\np->bus_word = 1;\r\np->sub_unit = 0;\r\np->bit = 0;\r\ngoto out;\r\n} else {\r\npm_regs.pm07_cntrl[ctr] = 0;\r\n}\r\nbus_word = GET_BUS_WORD(unit_mask);\r\nbus_type = GET_BUS_TYPE(unit_mask);\r\ncount_cycles = GET_COUNT_CYCLES(unit_mask);\r\npolarity = GET_POLARITY(unit_mask);\r\ninput_control = GET_INPUT_CONTROL(unit_mask);\r\nsignal_bit = (event % 100);\r\np = &(pm_signal[ctr]);\r\np->signal_group = event / 100;\r\np->bus_word = bus_word;\r\np->sub_unit = GET_SUB_UNIT(unit_mask);\r\npm_regs.pm07_cntrl[ctr] = 0;\r\npm_regs.pm07_cntrl[ctr] |= PM07_CTR_COUNT_CYCLES(count_cycles);\r\npm_regs.pm07_cntrl[ctr] |= PM07_CTR_POLARITY(polarity);\r\npm_regs.pm07_cntrl[ctr] |= PM07_CTR_INPUT_CONTROL(input_control);\r\nif (input_control == 0) {\r\nif (signal_bit > 31) {\r\nsignal_bit -= 32;\r\nif (bus_word == 0x3)\r\nbus_word = 0x2;\r\nelse if (bus_word == 0xc)\r\nbus_word = 0x8;\r\n}\r\nif ((bus_type == 0) && p->signal_group >= 60)\r\nbus_type = 2;\r\nif ((bus_type == 1) && p->signal_group >= 50)\r\nbus_type = 0;\r\npm_regs.pm07_cntrl[ctr] |= PM07_CTR_INPUT_MUX(signal_bit);\r\n} else {\r\npm_regs.pm07_cntrl[ctr] = 0;\r\np->bit = signal_bit;\r\n}\r\nfor (i = 0; i < NUM_DEBUG_BUS_WORDS; i++) {\r\nif (bus_word & (1 << i)) {\r\npm_regs.debug_bus_control |=\r\n(bus_type << (30 - (2 * i)));\r\nfor (j = 0; j < NUM_INPUT_BUS_WORDS; j++) {\r\nif (input_bus[j] == 0xff) {\r\ninput_bus[j] = i;\r\npm_regs.group_control |=\r\n(i << (30 - (2 * j)));\r\nbreak;\r\n}\r\n}\r\n}\r\n}\r\nout:\r\n;\r\n}\r\nstatic void write_pm_cntrl(int cpu)\r\n{\r\nu32 val = 0;\r\nif (pm_regs.pm_cntrl.enable == 1)\r\nval |= CBE_PM_ENABLE_PERF_MON;\r\nif (pm_regs.pm_cntrl.stop_at_max == 1)\r\nval |= CBE_PM_STOP_AT_MAX;\r\nif (pm_regs.pm_cntrl.trace_mode != 0)\r\nval |= CBE_PM_TRACE_MODE_SET(pm_regs.pm_cntrl.trace_mode);\r\nif (pm_regs.pm_cntrl.trace_buf_ovflw == 1)\r\nval |= CBE_PM_TRACE_BUF_OVFLW(pm_regs.pm_cntrl.trace_buf_ovflw);\r\nif (pm_regs.pm_cntrl.freeze == 1)\r\nval |= CBE_PM_FREEZE_ALL_CTRS;\r\nval |= CBE_PM_SPU_ADDR_TRACE_SET(pm_regs.pm_cntrl.spu_addr_trace);\r\nval |= CBE_PM_COUNT_MODE_SET(pm_regs.pm_cntrl.count_mode);\r\ncbe_write_pm(cpu, pm_control, val);\r\n}\r\nstatic inline void\r\nset_count_mode(u32 kernel, u32 user)\r\n{\r\nif (kernel) {\r\nif (user)\r\npm_regs.pm_cntrl.count_mode = CBE_COUNT_ALL_MODES;\r\nelse\r\npm_regs.pm_cntrl.count_mode =\r\nCBE_COUNT_SUPERVISOR_MODE;\r\n} else {\r\nif (user)\r\npm_regs.pm_cntrl.count_mode = CBE_COUNT_PROBLEM_MODE;\r\nelse\r\npm_regs.pm_cntrl.count_mode =\r\nCBE_COUNT_HYPERVISOR_MODE;\r\n}\r\n}\r\nstatic inline void enable_ctr(u32 cpu, u32 ctr, u32 *pm07_cntrl)\r\n{\r\npm07_cntrl[ctr] |= CBE_PM_CTR_ENABLE;\r\ncbe_write_pm07_control(cpu, ctr, pm07_cntrl[ctr]);\r\n}\r\nstatic void cell_virtual_cntr(unsigned long data)\r\n{\r\nint i, prev_hdw_thread, next_hdw_thread;\r\nu32 cpu;\r\nunsigned long flags;\r\nspin_lock_irqsave(&cntr_lock, flags);\r\nprev_hdw_thread = hdw_thread;\r\nhdw_thread = 1 ^ hdw_thread;\r\nnext_hdw_thread = hdw_thread;\r\npm_regs.group_control = 0;\r\npm_regs.debug_bus_control = 0;\r\nfor (i = 0; i < NUM_INPUT_BUS_WORDS; i++)\r\ninput_bus[i] = 0xff;\r\nfor (i = 0; i < num_counters; i++)\r\nset_pm_event(i,\r\npmc_cntrl[next_hdw_thread][i].evnts,\r\npmc_cntrl[next_hdw_thread][i].masks);\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\ncbe_disable_pm(cpu);\r\ncbe_disable_pm_interrupts(cpu);\r\nfor (i = 0; i < num_counters; i++) {\r\nper_cpu(pmc_values, cpu + prev_hdw_thread)[i]\r\n= cbe_read_ctr(cpu, i);\r\nif (per_cpu(pmc_values, cpu + next_hdw_thread)[i]\r\n== 0xFFFFFFFF)\r\ncbe_write_ctr(cpu, i, 0xFFFFFFF0);\r\nelse\r\ncbe_write_ctr(cpu, i,\r\nper_cpu(pmc_values,\r\ncpu +\r\nnext_hdw_thread)[i]);\r\n}\r\nfor (i = 0; i < num_counters; i++) {\r\nif (pmc_cntrl[next_hdw_thread][i].enabled) {\r\nenable_ctr(cpu, i,\r\npm_regs.pm07_cntrl);\r\n} else {\r\ncbe_write_pm07_control(cpu, i, 0);\r\n}\r\n}\r\ncbe_enable_pm_interrupts(cpu, next_hdw_thread,\r\nvirt_cntr_inter_mask);\r\ncbe_enable_pm(cpu);\r\n}\r\nspin_unlock_irqrestore(&cntr_lock, flags);\r\nmod_timer(&timer_virt_cntr, jiffies + HZ / 10);\r\n}\r\nstatic void start_virt_cntrs(void)\r\n{\r\ninit_timer(&timer_virt_cntr);\r\ntimer_virt_cntr.function = cell_virtual_cntr;\r\ntimer_virt_cntr.data = 0UL;\r\ntimer_virt_cntr.expires = jiffies + HZ / 10;\r\nadd_timer(&timer_virt_cntr);\r\n}\r\nstatic int cell_reg_setup_spu_cycles(struct op_counter_config *ctr,\r\nstruct op_system_config *sys, int num_ctrs)\r\n{\r\nspu_cycle_reset = ctr[0].count;\r\nspu_rtas_token = rtas_token("ibm,cbe-spu-perftools");\r\nif (unlikely(spu_rtas_token == RTAS_UNKNOWN_SERVICE)) {\r\nprintk(KERN_ERR\r\n"%s: rtas token ibm,cbe-spu-perftools unknown\n",\r\n__func__);\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nstatic void spu_evnt_swap(unsigned long data)\r\n{\r\nint node;\r\nint cur_phys_spu, nxt_phys_spu, cur_spu_evnt_phys_spu_indx;\r\nunsigned long flags;\r\nint cpu;\r\nint ret;\r\nu32 interrupt_mask;\r\ninterrupt_mask = CBE_PM_CTR_OVERFLOW_INTR(0);\r\nhdw_thread = 0;\r\nspin_lock_irqsave(&cntr_lock, flags);\r\ncur_spu_evnt_phys_spu_indx = spu_evnt_phys_spu_indx;\r\nif (++(spu_evnt_phys_spu_indx) == NUM_SPUS_PER_NODE)\r\nspu_evnt_phys_spu_indx = 0;\r\npm_signal[0].sub_unit = spu_evnt_phys_spu_indx;\r\npm_signal[1].sub_unit = spu_evnt_phys_spu_indx;\r\npm_signal[2].sub_unit = spu_evnt_phys_spu_indx;\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\nnode = cbe_cpu_to_node(cpu);\r\ncur_phys_spu = (node * NUM_SPUS_PER_NODE)\r\n+ cur_spu_evnt_phys_spu_indx;\r\nnxt_phys_spu = (node * NUM_SPUS_PER_NODE)\r\n+ spu_evnt_phys_spu_indx;\r\ncbe_disable_pm(cpu);\r\ncbe_disable_pm_interrupts(cpu);\r\nspu_pm_cnt[cur_phys_spu]\r\n= cbe_read_ctr(cpu, 0);\r\nif (spu_pm_cnt[nxt_phys_spu] >= 0xFFFFFFFF)\r\ncbe_write_ctr(cpu, 0, 0xFFFFFFF0);\r\nelse\r\ncbe_write_ctr(cpu, 0, spu_pm_cnt[nxt_phys_spu]);\r\npm_rtas_reset_signals(cbe_cpu_to_node(cpu));\r\nret = pm_rtas_activate_signals(cbe_cpu_to_node(cpu), 3);\r\nif (ret)\r\nprintk(KERN_ERR "%s: pm_rtas_activate_signals failed, "\r\n"SPU event swap\n", __func__);\r\ncbe_write_pm(cpu, trace_address, 0);\r\nenable_ctr(cpu, 0, pm_regs.pm07_cntrl);\r\ncbe_enable_pm_interrupts(cpu, hdw_thread,\r\ninterrupt_mask);\r\ncbe_enable_pm(cpu);\r\n}\r\nspin_unlock_irqrestore(&cntr_lock, flags);\r\nmod_timer(&timer_spu_event_swap, jiffies + HZ / 25);\r\n}\r\nstatic void start_spu_event_swap(void)\r\n{\r\ninit_timer(&timer_spu_event_swap);\r\ntimer_spu_event_swap.function = spu_evnt_swap;\r\ntimer_spu_event_swap.data = 0UL;\r\ntimer_spu_event_swap.expires = jiffies + HZ / 25;\r\nadd_timer(&timer_spu_event_swap);\r\n}\r\nstatic int cell_reg_setup_spu_events(struct op_counter_config *ctr,\r\nstruct op_system_config *sys, int num_ctrs)\r\n{\r\nint i;\r\nspu_evnt_phys_spu_indx = 0;\r\npm_rtas_token = rtas_token("ibm,cbe-perftools");\r\nif (unlikely(pm_rtas_token == RTAS_UNKNOWN_SERVICE)) {\r\nprintk(KERN_ERR\r\n"%s: rtas token ibm,cbe-perftools unknown\n",\r\n__func__);\r\nreturn -EIO;\r\n}\r\npm_regs.pm_cntrl.trace_buf_ovflw = 1;\r\npm_regs.pm_cntrl.trace_mode = 2;\r\npm_regs.pm_cntrl.spu_addr_trace = 0x1;\r\npm_signal[1].signal_group = SPU_PROFILE_EVENT_ADDR / 100;\r\npm_signal[1].bus_word = GET_BUS_WORD(SPU_PROFILE_EVENT_ADDR_MASK_A);\r\npm_signal[1].bit = SPU_PROFILE_EVENT_ADDR % 100;\r\npm_signal[1].sub_unit = spu_evnt_phys_spu_indx;\r\npm_signal[2].signal_group = SPU_PROFILE_EVENT_ADDR / 100;\r\npm_signal[2].bus_word = GET_BUS_WORD(SPU_PROFILE_EVENT_ADDR_MASK_B);\r\npm_signal[2].bit = SPU_PROFILE_EVENT_ADDR % 100;\r\npm_signal[2].sub_unit = spu_evnt_phys_spu_indx;\r\nnum_counters = 1;\r\nset_pm_event(0, ctr[0].event, ctr[0].unit_mask);\r\nreset_value[0] = 0xFFFFFFFF - ctr[0].count;\r\nctr_enabled |= 1;\r\nfor (i=0; i < MAX_NUMNODES * NUM_SPUS_PER_NODE; i++)\r\nspu_pm_cnt[i] = reset_value[0];\r\nreturn 0;\r\n}\r\nstatic int cell_reg_setup_ppu(struct op_counter_config *ctr,\r\nstruct op_system_config *sys, int num_ctrs)\r\n{\r\nint i, j, cpu;\r\nnum_counters = num_ctrs;\r\nif (unlikely(num_ctrs > NR_PHYS_CTRS)) {\r\nprintk(KERN_ERR\r\n"%s: Oprofile, number of specified events " \\r\n"exceeds number of physical counters\n",\r\n__func__);\r\nreturn -EIO;\r\n}\r\nset_count_mode(sys->enable_kernel, sys->enable_user);\r\nfor (i = 0; i < num_ctrs; ++i) {\r\npmc_cntrl[0][i].evnts = ctr[i].event;\r\npmc_cntrl[0][i].masks = ctr[i].unit_mask;\r\npmc_cntrl[0][i].enabled = ctr[i].enabled;\r\npmc_cntrl[0][i].vcntr = i;\r\nfor_each_possible_cpu(j)\r\nper_cpu(pmc_values, j)[i] = 0;\r\n}\r\nfor (i = 0; i < num_ctrs; ++i) {\r\nif ((ctr[i].event >= 2100) && (ctr[i].event <= 2111))\r\npmc_cntrl[1][i].evnts = ctr[i].event + 19;\r\nelse if (ctr[i].event == 2203)\r\npmc_cntrl[1][i].evnts = ctr[i].event;\r\nelse if ((ctr[i].event >= 2200) && (ctr[i].event <= 2215))\r\npmc_cntrl[1][i].evnts = ctr[i].event + 16;\r\nelse\r\npmc_cntrl[1][i].evnts = ctr[i].event;\r\npmc_cntrl[1][i].masks = ctr[i].unit_mask;\r\npmc_cntrl[1][i].enabled = ctr[i].enabled;\r\npmc_cntrl[1][i].vcntr = i;\r\n}\r\nfor (i = 0; i < NUM_INPUT_BUS_WORDS; i++)\r\ninput_bus[i] = 0xff;\r\nfor (i = 0; i < num_counters; ++i) {\r\nif (pmc_cntrl[0][i].enabled) {\r\nreset_value[i] = 0xFFFFFFFF - ctr[i].count;\r\nset_pm_event(i,\r\npmc_cntrl[0][i].evnts,\r\npmc_cntrl[0][i].masks);\r\nctr_enabled |= (1 << i);\r\n}\r\n}\r\nfor_each_online_cpu(cpu)\r\nfor (i = 0; i < num_counters; ++i) {\r\nper_cpu(pmc_values, cpu)[i] = reset_value[i];\r\n}\r\nreturn 0;\r\n}\r\nstatic int cell_reg_setup(struct op_counter_config *ctr,\r\nstruct op_system_config *sys, int num_ctrs)\r\n{\r\nint ret=0;\r\nspu_cycle_reset = 0;\r\npm_regs.group_control = 0;\r\npm_regs.debug_bus_control = 0;\r\npm_regs.pm_cntrl.stop_at_max = 1;\r\npm_regs.pm_cntrl.trace_mode = 0;\r\npm_regs.pm_cntrl.freeze = 1;\r\npm_regs.pm_cntrl.trace_buf_ovflw = 0;\r\npm_regs.pm_cntrl.spu_addr_trace = 0;\r\npm_rtas_token = rtas_token("ibm,cbe-perftools");\r\nif (unlikely(pm_rtas_token == RTAS_UNKNOWN_SERVICE)) {\r\nprintk(KERN_ERR\r\n"%s: rtas token ibm,cbe-perftools unknown\n",\r\n__func__);\r\nreturn -EIO;\r\n}\r\nif (ctr[0].event == SPU_CYCLES_EVENT_NUM) {\r\nprofiling_mode = SPU_PROFILING_CYCLES;\r\nret = cell_reg_setup_spu_cycles(ctr, sys, num_ctrs);\r\n} else if ((ctr[0].event >= SPU_EVENT_NUM_START) &&\r\n(ctr[0].event <= SPU_EVENT_NUM_STOP)) {\r\nprofiling_mode = SPU_PROFILING_EVENTS;\r\nspu_cycle_reset = ctr[0].count;\r\ncell_reg_setup_spu_events(ctr, sys, num_ctrs);\r\n} else {\r\nprofiling_mode = PPU_PROFILING;\r\nret = cell_reg_setup_ppu(ctr, sys, num_ctrs);\r\n}\r\nreturn ret;\r\n}\r\nstatic int cell_cpu_setup(struct op_counter_config *cntr)\r\n{\r\nu32 cpu = smp_processor_id();\r\nu32 num_enabled = 0;\r\nint i;\r\nint ret;\r\nif (profiling_mode == SPU_PROFILING_CYCLES)\r\nreturn 0;\r\nif (cbe_get_hw_thread_id(cpu))\r\nreturn 0;\r\ncbe_disable_pm(cpu);\r\ncbe_disable_pm_interrupts(cpu);\r\ncbe_write_pm(cpu, pm_start_stop, 0);\r\ncbe_write_pm(cpu, group_control, pm_regs.group_control);\r\ncbe_write_pm(cpu, debug_bus_control, pm_regs.debug_bus_control);\r\nwrite_pm_cntrl(cpu);\r\nfor (i = 0; i < num_counters; ++i) {\r\nif (ctr_enabled & (1 << i)) {\r\npm_signal[num_enabled].cpu = cbe_cpu_to_node(cpu);\r\nnum_enabled++;\r\n}\r\n}\r\nif (profiling_mode == SPU_PROFILING_EVENTS) {\r\nret = pm_rtas_activate_signals(cbe_cpu_to_node(cpu),\r\nnum_enabled+2);\r\ncbe_write_pm(cpu, pm_interval, NUM_INTERVAL_CYC);\r\nreturn ret;\r\n} else\r\nreturn pm_rtas_activate_signals(cbe_cpu_to_node(cpu),\r\nnum_enabled);\r\n}\r\nstatic int calculate_lfsr(int n)\r\n{\r\nint index;\r\nif ((n >> 16) == 0)\r\nindex = 0;\r\nelse if (((n - V2_16) >> 19) == 0)\r\nindex = ((n - V2_16) >> 12) + 1;\r\nelse if (((n - V2_16 - V2_19) >> 22) == 0)\r\nindex = ((n - V2_16 - V2_19) >> 15 ) + 1 + 128;\r\nelse if (((n - V2_16 - V2_19 - V2_22) >> 24) == 0)\r\nindex = ((n - V2_16 - V2_19 - V2_22) >> 18 ) + 1 + 256;\r\nelse\r\nindex = ENTRIES-1;\r\nif ((index >= ENTRIES) || (index < 0))\r\nindex = ENTRIES-1;\r\nreturn initial_lfsr[index];\r\n}\r\nstatic int pm_rtas_activate_spu_profiling(u32 node)\r\n{\r\nint ret, i;\r\nstruct pm_signal pm_signal_local[NUM_SPUS_PER_NODE];\r\nfor (i = 0; i < ARRAY_SIZE(pm_signal_local); i++) {\r\npm_signal_local[i].cpu = node;\r\npm_signal_local[i].signal_group = 41;\r\npm_signal_local[i].bus_word = 1 << i / 2;\r\npm_signal_local[i].sub_unit = i;\r\npm_signal_local[i].bit = 63;\r\n}\r\nret = rtas_ibm_cbe_perftools(SUBFUNC_ACTIVATE,\r\nPASSTHRU_ENABLE, pm_signal_local,\r\n(ARRAY_SIZE(pm_signal_local)\r\n* sizeof(struct pm_signal)));\r\nif (unlikely(ret)) {\r\nprintk(KERN_WARNING "%s: rtas returned: %d\n",\r\n__func__, ret);\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\noprof_cpufreq_notify(struct notifier_block *nb, unsigned long val, void *data)\r\n{\r\nint ret = 0;\r\nstruct cpufreq_freqs *frq = data;\r\nif ((val == CPUFREQ_PRECHANGE && frq->old < frq->new) ||\r\n(val == CPUFREQ_POSTCHANGE && frq->old > frq->new))\r\nset_spu_profiling_frequency(frq->new, spu_cycle_reset);\r\nreturn ret;\r\n}\r\nstatic void cell_global_stop_spu_cycles(void)\r\n{\r\nint subfunc, rtn_value;\r\nunsigned int lfsr_value;\r\nint cpu;\r\noprofile_running = 0;\r\nsmp_wmb();\r\n#ifdef CONFIG_CPU_FREQ\r\ncpufreq_unregister_notifier(&cpu_freq_notifier_block,\r\nCPUFREQ_TRANSITION_NOTIFIER);\r\n#endif\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\nsubfunc = 3;\r\nlfsr_value = 0x8f100000;\r\nrtn_value = rtas_call(spu_rtas_token, 3, 1, NULL,\r\nsubfunc, cbe_cpu_to_node(cpu),\r\nlfsr_value);\r\nif (unlikely(rtn_value != 0)) {\r\nprintk(KERN_ERR\r\n"%s: rtas call ibm,cbe-spu-perftools " \\r\n"failed, return = %d\n",\r\n__func__, rtn_value);\r\n}\r\npm_rtas_reset_signals(cbe_cpu_to_node(cpu));\r\n}\r\nstop_spu_profiling_cycles();\r\n}\r\nstatic void cell_global_stop_spu_events(void)\r\n{\r\nint cpu;\r\noprofile_running = 0;\r\nstop_spu_profiling_events();\r\nsmp_wmb();\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\ncbe_sync_irq(cbe_cpu_to_node(cpu));\r\ncbe_disable_pm(cpu);\r\ncbe_write_pm07_control(cpu, 0, 0);\r\npm_rtas_reset_signals(cbe_cpu_to_node(cpu));\r\ncbe_disable_pm_interrupts(cpu);\r\n}\r\ndel_timer_sync(&timer_spu_event_swap);\r\n}\r\nstatic void cell_global_stop_ppu(void)\r\n{\r\nint cpu;\r\ndel_timer_sync(&timer_virt_cntr);\r\noprofile_running = 0;\r\nsmp_wmb();\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\ncbe_sync_irq(cbe_cpu_to_node(cpu));\r\ncbe_disable_pm(cpu);\r\npm_rtas_reset_signals(cbe_cpu_to_node(cpu));\r\ncbe_disable_pm_interrupts(cpu);\r\n}\r\n}\r\nstatic void cell_global_stop(void)\r\n{\r\nif (profiling_mode == PPU_PROFILING)\r\ncell_global_stop_ppu();\r\nelse if (profiling_mode == SPU_PROFILING_EVENTS)\r\ncell_global_stop_spu_events();\r\nelse\r\ncell_global_stop_spu_cycles();\r\n}\r\nstatic int cell_global_start_spu_cycles(struct op_counter_config *ctr)\r\n{\r\nint subfunc;\r\nunsigned int lfsr_value;\r\nint cpu;\r\nint ret;\r\nint rtas_error;\r\nunsigned int cpu_khzfreq = 0;\r\n#ifdef CONFIG_CPU_FREQ\r\nret = cpufreq_register_notifier(&cpu_freq_notifier_block,\r\nCPUFREQ_TRANSITION_NOTIFIER);\r\nif (ret < 0)\r\nprintk(KERN_ERR "CPU freq change registration failed: %d\n",\r\nret);\r\nelse\r\ncpu_khzfreq = cpufreq_quick_get(smp_processor_id());\r\n#endif\r\nset_spu_profiling_frequency(cpu_khzfreq, spu_cycle_reset);\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\ncbe_write_pm(cpu, pm_control, 0);\r\nif (spu_cycle_reset > MAX_SPU_COUNT)\r\nlfsr_value = calculate_lfsr(MAX_SPU_COUNT-1);\r\nelse\r\nlfsr_value = calculate_lfsr(spu_cycle_reset);\r\nif (lfsr_value == 0)\r\nlfsr_value = calculate_lfsr(1);\r\nlfsr_value = lfsr_value << 8;\r\nret = pm_rtas_activate_spu_profiling(cbe_cpu_to_node(cpu));\r\nif (unlikely(ret)) {\r\nrtas_error = ret;\r\ngoto out;\r\n}\r\nsubfunc = 2;\r\nret = rtas_call(spu_rtas_token, 3, 1, NULL, subfunc,\r\ncbe_cpu_to_node(cpu), lfsr_value);\r\nif (unlikely(ret != 0)) {\r\nprintk(KERN_ERR\r\n"%s: rtas call ibm,cbe-spu-perftools failed, " \\r\n"return = %d\n", __func__, ret);\r\nrtas_error = -EIO;\r\ngoto out;\r\n}\r\n}\r\nrtas_error = start_spu_profiling_cycles(spu_cycle_reset);\r\nif (rtas_error)\r\ngoto out_stop;\r\noprofile_running = 1;\r\nreturn 0;\r\nout_stop:\r\ncell_global_stop_spu_cycles();\r\nout:\r\nreturn rtas_error;\r\n}\r\nstatic int cell_global_start_spu_events(struct op_counter_config *ctr)\r\n{\r\nint cpu;\r\nu32 interrupt_mask = 0;\r\nint rtn = 0;\r\nhdw_thread = 0;\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\nif (ctr_enabled & 1) {\r\ncbe_write_ctr(cpu, 0, reset_value[0]);\r\nenable_ctr(cpu, 0, pm_regs.pm07_cntrl);\r\ninterrupt_mask |=\r\nCBE_PM_CTR_OVERFLOW_INTR(0);\r\n} else {\r\ncbe_write_pm07_control(cpu, 0, 0);\r\n}\r\ncbe_get_and_clear_pm_interrupts(cpu);\r\ncbe_enable_pm_interrupts(cpu, hdw_thread, interrupt_mask);\r\ncbe_enable_pm(cpu);\r\ncbe_write_pm(cpu, trace_address, 0);\r\n}\r\nstart_spu_event_swap();\r\nstart_spu_profiling_events();\r\noprofile_running = 1;\r\nsmp_wmb();\r\nreturn rtn;\r\n}\r\nstatic int cell_global_start_ppu(struct op_counter_config *ctr)\r\n{\r\nu32 cpu, i;\r\nu32 interrupt_mask = 0;\r\nfor_each_online_cpu(cpu) {\r\nif (cbe_get_hw_thread_id(cpu))\r\ncontinue;\r\ninterrupt_mask = 0;\r\nfor (i = 0; i < num_counters; ++i) {\r\nif (ctr_enabled & (1 << i)) {\r\ncbe_write_ctr(cpu, i, reset_value[i]);\r\nenable_ctr(cpu, i, pm_regs.pm07_cntrl);\r\ninterrupt_mask |= CBE_PM_CTR_OVERFLOW_INTR(i);\r\n} else {\r\ncbe_write_pm07_control(cpu, i, 0);\r\n}\r\n}\r\ncbe_get_and_clear_pm_interrupts(cpu);\r\ncbe_enable_pm_interrupts(cpu, hdw_thread, interrupt_mask);\r\ncbe_enable_pm(cpu);\r\n}\r\nvirt_cntr_inter_mask = interrupt_mask;\r\noprofile_running = 1;\r\nsmp_wmb();\r\nstart_virt_cntrs();\r\nreturn 0;\r\n}\r\nstatic int cell_global_start(struct op_counter_config *ctr)\r\n{\r\nif (profiling_mode == SPU_PROFILING_CYCLES)\r\nreturn cell_global_start_spu_cycles(ctr);\r\nelse if (profiling_mode == SPU_PROFILING_EVENTS)\r\nreturn cell_global_start_spu_events(ctr);\r\nelse\r\nreturn cell_global_start_ppu(ctr);\r\n}\r\nstatic void cell_handle_interrupt_spu(struct pt_regs *regs,\r\nstruct op_counter_config *ctr)\r\n{\r\nu32 cpu, cpu_tmp;\r\nu64 trace_entry;\r\nu32 interrupt_mask;\r\nu64 trace_buffer[2];\r\nu64 last_trace_buffer;\r\nu32 sample;\r\nu32 trace_addr;\r\nunsigned long sample_array_lock_flags;\r\nint spu_num;\r\nunsigned long flags;\r\ncpu = smp_processor_id();\r\nspin_lock_irqsave(&cntr_lock, flags);\r\ncpu_tmp = cpu;\r\ncbe_disable_pm(cpu);\r\ninterrupt_mask = cbe_get_and_clear_pm_interrupts(cpu);\r\nsample = 0xABCDEF;\r\ntrace_entry = 0xfedcba;\r\nlast_trace_buffer = 0xdeadbeaf;\r\nif ((oprofile_running == 1) && (interrupt_mask != 0)) {\r\ncbe_write_pm(cpu, pm_interval, 0);\r\nif ((interrupt_mask & CBE_PM_CTR_OVERFLOW_INTR(0))\r\n&& ctr[0].enabled)\r\ncbe_write_ctr(cpu, 0, reset_value[0]);\r\ntrace_addr = cbe_read_pm(cpu, trace_address);\r\nwhile (!(trace_addr & CBE_PM_TRACE_BUF_EMPTY)) {\r\ncbe_read_trace_buffer(cpu, trace_buffer);\r\ntrace_addr = cbe_read_pm(cpu, trace_address);\r\n}\r\ntrace_entry = trace_buffer[0]\r\n& 0x00000000FFFF0000;\r\nsample = trace_entry >> 14;\r\nlast_trace_buffer = trace_buffer[0];\r\nspu_num = spu_evnt_phys_spu_indx\r\n+ (cbe_cpu_to_node(cpu) * NUM_SPUS_PER_NODE);\r\nspin_lock_irqsave(&oprof_spu_smpl_arry_lck,\r\nsample_array_lock_flags);\r\nspu_sync_buffer(spu_num, &sample, 1);\r\nspin_unlock_irqrestore(&oprof_spu_smpl_arry_lck,\r\nsample_array_lock_flags);\r\nsmp_wmb();\r\ncbe_write_pm(cpu, pm_interval, NUM_INTERVAL_CYC);\r\ncbe_enable_pm_interrupts(cpu, hdw_thread,\r\nvirt_cntr_inter_mask);\r\ncbe_write_pm(cpu, trace_address, 0);\r\ncbe_write_pm(cpu, pm_interval, NUM_INTERVAL_CYC);\r\nwrite_pm_cntrl(cpu);\r\ncbe_enable_pm(cpu);\r\n}\r\nspin_unlock_irqrestore(&cntr_lock, flags);\r\n}\r\nstatic void cell_handle_interrupt_ppu(struct pt_regs *regs,\r\nstruct op_counter_config *ctr)\r\n{\r\nu32 cpu;\r\nu64 pc;\r\nint is_kernel;\r\nunsigned long flags = 0;\r\nu32 interrupt_mask;\r\nint i;\r\ncpu = smp_processor_id();\r\nspin_lock_irqsave(&cntr_lock, flags);\r\ncbe_disable_pm(cpu);\r\ninterrupt_mask = cbe_get_and_clear_pm_interrupts(cpu);\r\nif ((oprofile_running == 1) && (interrupt_mask != 0)) {\r\npc = regs->nip;\r\nis_kernel = is_kernel_addr(pc);\r\nfor (i = 0; i < num_counters; ++i) {\r\nif ((interrupt_mask & CBE_PM_CTR_OVERFLOW_INTR(i))\r\n&& ctr[i].enabled) {\r\noprofile_add_ext_sample(pc, regs, i, is_kernel);\r\ncbe_write_ctr(cpu, i, reset_value[i]);\r\n}\r\n}\r\ncbe_enable_pm_interrupts(cpu, hdw_thread,\r\nvirt_cntr_inter_mask);\r\ncbe_enable_pm(cpu);\r\n}\r\nspin_unlock_irqrestore(&cntr_lock, flags);\r\n}\r\nstatic void cell_handle_interrupt(struct pt_regs *regs,\r\nstruct op_counter_config *ctr)\r\n{\r\nif (profiling_mode == PPU_PROFILING)\r\ncell_handle_interrupt_ppu(regs, ctr);\r\nelse\r\ncell_handle_interrupt_spu(regs, ctr);\r\n}\r\nstatic int cell_sync_start(void)\r\n{\r\nif ((profiling_mode == SPU_PROFILING_CYCLES) ||\r\n(profiling_mode == SPU_PROFILING_EVENTS))\r\nreturn spu_sync_start();\r\nelse\r\nreturn DO_GENERIC_SYNC;\r\n}\r\nstatic int cell_sync_stop(void)\r\n{\r\nif ((profiling_mode == SPU_PROFILING_CYCLES) ||\r\n(profiling_mode == SPU_PROFILING_EVENTS))\r\nreturn spu_sync_stop();\r\nelse\r\nreturn 1;\r\n}
