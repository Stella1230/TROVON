static void poison_error(mempool_t *pool, void *element, size_t size,\r\nsize_t byte)\r\n{\r\nconst int nr = pool->curr_nr;\r\nconst int start = max_t(int, byte - (BITS_PER_LONG / 8), 0);\r\nconst int end = min_t(int, byte + (BITS_PER_LONG / 8), size);\r\nint i;\r\npr_err("BUG: mempool element poison mismatch\n");\r\npr_err("Mempool %p size %zu\n", pool, size);\r\npr_err(" nr=%d @ %p: %s0x", nr, element, start > 0 ? "... " : "");\r\nfor (i = start; i < end; i++)\r\npr_cont("%x ", *(u8 *)(element + i));\r\npr_cont("%s\n", end < size ? "..." : "");\r\ndump_stack();\r\n}\r\nstatic void __check_element(mempool_t *pool, void *element, size_t size)\r\n{\r\nu8 *obj = element;\r\nsize_t i;\r\nfor (i = 0; i < size; i++) {\r\nu8 exp = (i < size - 1) ? POISON_FREE : POISON_END;\r\nif (obj[i] != exp) {\r\npoison_error(pool, element, size, i);\r\nreturn;\r\n}\r\n}\r\nmemset(obj, POISON_INUSE, size);\r\n}\r\nstatic void check_element(mempool_t *pool, void *element)\r\n{\r\nif (pool->free == mempool_free_slab || pool->free == mempool_kfree)\r\n__check_element(pool, element, ksize(element));\r\nif (pool->free == mempool_free_pages) {\r\nint order = (int)(long)pool->pool_data;\r\nvoid *addr = kmap_atomic((struct page *)element);\r\n__check_element(pool, addr, 1UL << (PAGE_SHIFT + order));\r\nkunmap_atomic(addr);\r\n}\r\n}\r\nstatic void __poison_element(void *element, size_t size)\r\n{\r\nu8 *obj = element;\r\nmemset(obj, POISON_FREE, size - 1);\r\nobj[size - 1] = POISON_END;\r\n}\r\nstatic void poison_element(mempool_t *pool, void *element)\r\n{\r\nif (pool->alloc == mempool_alloc_slab || pool->alloc == mempool_kmalloc)\r\n__poison_element(element, ksize(element));\r\nif (pool->alloc == mempool_alloc_pages) {\r\nint order = (int)(long)pool->pool_data;\r\nvoid *addr = kmap_atomic((struct page *)element);\r\n__poison_element(addr, 1UL << (PAGE_SHIFT + order));\r\nkunmap_atomic(addr);\r\n}\r\n}\r\nstatic inline void check_element(mempool_t *pool, void *element)\r\n{\r\n}\r\nstatic inline void poison_element(mempool_t *pool, void *element)\r\n{\r\n}\r\nstatic void kasan_poison_element(mempool_t *pool, void *element)\r\n{\r\nif (pool->alloc == mempool_alloc_slab || pool->alloc == mempool_kmalloc)\r\nkasan_poison_kfree(element);\r\nif (pool->alloc == mempool_alloc_pages)\r\nkasan_free_pages(element, (unsigned long)pool->pool_data);\r\n}\r\nstatic void kasan_unpoison_element(mempool_t *pool, void *element, gfp_t flags)\r\n{\r\nif (pool->alloc == mempool_alloc_slab || pool->alloc == mempool_kmalloc)\r\nkasan_unpoison_slab(element);\r\nif (pool->alloc == mempool_alloc_pages)\r\nkasan_alloc_pages(element, (unsigned long)pool->pool_data);\r\n}\r\nstatic void add_element(mempool_t *pool, void *element)\r\n{\r\nBUG_ON(pool->curr_nr >= pool->min_nr);\r\npoison_element(pool, element);\r\nkasan_poison_element(pool, element);\r\npool->elements[pool->curr_nr++] = element;\r\n}\r\nstatic void *remove_element(mempool_t *pool, gfp_t flags)\r\n{\r\nvoid *element = pool->elements[--pool->curr_nr];\r\nBUG_ON(pool->curr_nr < 0);\r\nkasan_unpoison_element(pool, element, flags);\r\ncheck_element(pool, element);\r\nreturn element;\r\n}\r\nvoid mempool_destroy(mempool_t *pool)\r\n{\r\nif (unlikely(!pool))\r\nreturn;\r\nwhile (pool->curr_nr) {\r\nvoid *element = remove_element(pool, GFP_KERNEL);\r\npool->free(element, pool->pool_data);\r\n}\r\nkfree(pool->elements);\r\nkfree(pool);\r\n}\r\nmempool_t *mempool_create(int min_nr, mempool_alloc_t *alloc_fn,\r\nmempool_free_t *free_fn, void *pool_data)\r\n{\r\nreturn mempool_create_node(min_nr,alloc_fn,free_fn, pool_data,\r\nGFP_KERNEL, NUMA_NO_NODE);\r\n}\r\nmempool_t *mempool_create_node(int min_nr, mempool_alloc_t *alloc_fn,\r\nmempool_free_t *free_fn, void *pool_data,\r\ngfp_t gfp_mask, int node_id)\r\n{\r\nmempool_t *pool;\r\npool = kzalloc_node(sizeof(*pool), gfp_mask, node_id);\r\nif (!pool)\r\nreturn NULL;\r\npool->elements = kmalloc_node(min_nr * sizeof(void *),\r\ngfp_mask, node_id);\r\nif (!pool->elements) {\r\nkfree(pool);\r\nreturn NULL;\r\n}\r\nspin_lock_init(&pool->lock);\r\npool->min_nr = min_nr;\r\npool->pool_data = pool_data;\r\ninit_waitqueue_head(&pool->wait);\r\npool->alloc = alloc_fn;\r\npool->free = free_fn;\r\nwhile (pool->curr_nr < pool->min_nr) {\r\nvoid *element;\r\nelement = pool->alloc(gfp_mask, pool->pool_data);\r\nif (unlikely(!element)) {\r\nmempool_destroy(pool);\r\nreturn NULL;\r\n}\r\nadd_element(pool, element);\r\n}\r\nreturn pool;\r\n}\r\nint mempool_resize(mempool_t *pool, int new_min_nr)\r\n{\r\nvoid *element;\r\nvoid **new_elements;\r\nunsigned long flags;\r\nBUG_ON(new_min_nr <= 0);\r\nmight_sleep();\r\nspin_lock_irqsave(&pool->lock, flags);\r\nif (new_min_nr <= pool->min_nr) {\r\nwhile (new_min_nr < pool->curr_nr) {\r\nelement = remove_element(pool, GFP_KERNEL);\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\npool->free(element, pool->pool_data);\r\nspin_lock_irqsave(&pool->lock, flags);\r\n}\r\npool->min_nr = new_min_nr;\r\ngoto out_unlock;\r\n}\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nnew_elements = kmalloc_array(new_min_nr, sizeof(*new_elements),\r\nGFP_KERNEL);\r\nif (!new_elements)\r\nreturn -ENOMEM;\r\nspin_lock_irqsave(&pool->lock, flags);\r\nif (unlikely(new_min_nr <= pool->min_nr)) {\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nkfree(new_elements);\r\ngoto out;\r\n}\r\nmemcpy(new_elements, pool->elements,\r\npool->curr_nr * sizeof(*new_elements));\r\nkfree(pool->elements);\r\npool->elements = new_elements;\r\npool->min_nr = new_min_nr;\r\nwhile (pool->curr_nr < pool->min_nr) {\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nelement = pool->alloc(GFP_KERNEL, pool->pool_data);\r\nif (!element)\r\ngoto out;\r\nspin_lock_irqsave(&pool->lock, flags);\r\nif (pool->curr_nr < pool->min_nr) {\r\nadd_element(pool, element);\r\n} else {\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\npool->free(element, pool->pool_data);\r\ngoto out;\r\n}\r\n}\r\nout_unlock:\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nout:\r\nreturn 0;\r\n}\r\nvoid *mempool_alloc(mempool_t *pool, gfp_t gfp_mask)\r\n{\r\nvoid *element;\r\nunsigned long flags;\r\nwait_queue_t wait;\r\ngfp_t gfp_temp;\r\nVM_WARN_ON_ONCE(gfp_mask & __GFP_ZERO);\r\nmight_sleep_if(gfp_mask & __GFP_DIRECT_RECLAIM);\r\ngfp_mask |= __GFP_NOMEMALLOC;\r\ngfp_mask |= __GFP_NORETRY;\r\ngfp_mask |= __GFP_NOWARN;\r\ngfp_temp = gfp_mask & ~(__GFP_DIRECT_RECLAIM|__GFP_IO);\r\nrepeat_alloc:\r\nelement = pool->alloc(gfp_temp, pool->pool_data);\r\nif (likely(element != NULL))\r\nreturn element;\r\nspin_lock_irqsave(&pool->lock, flags);\r\nif (likely(pool->curr_nr)) {\r\nelement = remove_element(pool, gfp_temp);\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nsmp_wmb();\r\nkmemleak_update_trace(element);\r\nreturn element;\r\n}\r\nif (gfp_temp != gfp_mask) {\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\ngfp_temp = gfp_mask;\r\ngoto repeat_alloc;\r\n}\r\nif (!(gfp_mask & __GFP_DIRECT_RECLAIM)) {\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nreturn NULL;\r\n}\r\ninit_wait(&wait);\r\nprepare_to_wait(&pool->wait, &wait, TASK_UNINTERRUPTIBLE);\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nio_schedule_timeout(5*HZ);\r\nfinish_wait(&pool->wait, &wait);\r\ngoto repeat_alloc;\r\n}\r\nvoid mempool_free(void *element, mempool_t *pool)\r\n{\r\nunsigned long flags;\r\nif (unlikely(element == NULL))\r\nreturn;\r\nsmp_rmb();\r\nif (unlikely(pool->curr_nr < pool->min_nr)) {\r\nspin_lock_irqsave(&pool->lock, flags);\r\nif (likely(pool->curr_nr < pool->min_nr)) {\r\nadd_element(pool, element);\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nwake_up(&pool->wait);\r\nreturn;\r\n}\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\n}\r\npool->free(element, pool->pool_data);\r\n}\r\nvoid *mempool_alloc_slab(gfp_t gfp_mask, void *pool_data)\r\n{\r\nstruct kmem_cache *mem = pool_data;\r\nVM_BUG_ON(mem->ctor);\r\nreturn kmem_cache_alloc(mem, gfp_mask);\r\n}\r\nvoid mempool_free_slab(void *element, void *pool_data)\r\n{\r\nstruct kmem_cache *mem = pool_data;\r\nkmem_cache_free(mem, element);\r\n}\r\nvoid *mempool_kmalloc(gfp_t gfp_mask, void *pool_data)\r\n{\r\nsize_t size = (size_t)pool_data;\r\nreturn kmalloc(size, gfp_mask);\r\n}\r\nvoid mempool_kfree(void *element, void *pool_data)\r\n{\r\nkfree(element);\r\n}\r\nvoid *mempool_alloc_pages(gfp_t gfp_mask, void *pool_data)\r\n{\r\nint order = (int)(long)pool_data;\r\nreturn alloc_pages(gfp_mask, order);\r\n}\r\nvoid mempool_free_pages(void *element, void *pool_data)\r\n{\r\nint order = (int)(long)pool_data;\r\n__free_pages(element, order);\r\n}
