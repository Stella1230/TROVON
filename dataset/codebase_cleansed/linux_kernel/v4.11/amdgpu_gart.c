int amdgpu_gart_table_ram_alloc(struct amdgpu_device *adev)\r\n{\r\nvoid *ptr;\r\nptr = pci_alloc_consistent(adev->pdev, adev->gart.table_size,\r\n&adev->gart.table_addr);\r\nif (ptr == NULL) {\r\nreturn -ENOMEM;\r\n}\r\n#ifdef CONFIG_X86\r\nif (0) {\r\nset_memory_uc((unsigned long)ptr,\r\nadev->gart.table_size >> PAGE_SHIFT);\r\n}\r\n#endif\r\nadev->gart.ptr = ptr;\r\nmemset((void *)adev->gart.ptr, 0, adev->gart.table_size);\r\nreturn 0;\r\n}\r\nvoid amdgpu_gart_table_ram_free(struct amdgpu_device *adev)\r\n{\r\nif (adev->gart.ptr == NULL) {\r\nreturn;\r\n}\r\n#ifdef CONFIG_X86\r\nif (0) {\r\nset_memory_wb((unsigned long)adev->gart.ptr,\r\nadev->gart.table_size >> PAGE_SHIFT);\r\n}\r\n#endif\r\npci_free_consistent(adev->pdev, adev->gart.table_size,\r\n(void *)adev->gart.ptr,\r\nadev->gart.table_addr);\r\nadev->gart.ptr = NULL;\r\nadev->gart.table_addr = 0;\r\n}\r\nint amdgpu_gart_table_vram_alloc(struct amdgpu_device *adev)\r\n{\r\nint r;\r\nif (adev->gart.robj == NULL) {\r\nr = amdgpu_bo_create(adev, adev->gart.table_size,\r\nPAGE_SIZE, true, AMDGPU_GEM_DOMAIN_VRAM,\r\nAMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED |\r\nAMDGPU_GEM_CREATE_VRAM_CONTIGUOUS,\r\nNULL, NULL, &adev->gart.robj);\r\nif (r) {\r\nreturn r;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint amdgpu_gart_table_vram_pin(struct amdgpu_device *adev)\r\n{\r\nuint64_t gpu_addr;\r\nint r;\r\nr = amdgpu_bo_reserve(adev->gart.robj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = amdgpu_bo_pin(adev->gart.robj,\r\nAMDGPU_GEM_DOMAIN_VRAM, &gpu_addr);\r\nif (r) {\r\namdgpu_bo_unreserve(adev->gart.robj);\r\nreturn r;\r\n}\r\nr = amdgpu_bo_kmap(adev->gart.robj, &adev->gart.ptr);\r\nif (r)\r\namdgpu_bo_unpin(adev->gart.robj);\r\namdgpu_bo_unreserve(adev->gart.robj);\r\nadev->gart.table_addr = gpu_addr;\r\nreturn r;\r\n}\r\nvoid amdgpu_gart_table_vram_unpin(struct amdgpu_device *adev)\r\n{\r\nint r;\r\nif (adev->gart.robj == NULL) {\r\nreturn;\r\n}\r\nr = amdgpu_bo_reserve(adev->gart.robj, false);\r\nif (likely(r == 0)) {\r\namdgpu_bo_kunmap(adev->gart.robj);\r\namdgpu_bo_unpin(adev->gart.robj);\r\namdgpu_bo_unreserve(adev->gart.robj);\r\nadev->gart.ptr = NULL;\r\n}\r\n}\r\nvoid amdgpu_gart_table_vram_free(struct amdgpu_device *adev)\r\n{\r\nif (adev->gart.robj == NULL) {\r\nreturn;\r\n}\r\namdgpu_bo_unref(&adev->gart.robj);\r\n}\r\nvoid amdgpu_gart_unbind(struct amdgpu_device *adev, uint64_t offset,\r\nint pages)\r\n{\r\nunsigned t;\r\nunsigned p;\r\nint i, j;\r\nu64 page_base;\r\nuint32_t flags = AMDGPU_PTE_SYSTEM;\r\nif (!adev->gart.ready) {\r\nWARN(1, "trying to unbind memory from uninitialized GART !\n");\r\nreturn;\r\n}\r\nt = offset / AMDGPU_GPU_PAGE_SIZE;\r\np = t / (PAGE_SIZE / AMDGPU_GPU_PAGE_SIZE);\r\nfor (i = 0; i < pages; i++, p++) {\r\n#ifdef CONFIG_DRM_AMDGPU_GART_DEBUGFS\r\nadev->gart.pages[p] = NULL;\r\n#endif\r\npage_base = adev->dummy_page.addr;\r\nif (!adev->gart.ptr)\r\ncontinue;\r\nfor (j = 0; j < (PAGE_SIZE / AMDGPU_GPU_PAGE_SIZE); j++, t++) {\r\namdgpu_gart_set_pte_pde(adev, adev->gart.ptr,\r\nt, page_base, flags);\r\npage_base += AMDGPU_GPU_PAGE_SIZE;\r\n}\r\n}\r\nmb();\r\namdgpu_gart_flush_gpu_tlb(adev, 0);\r\n}\r\nint amdgpu_gart_bind(struct amdgpu_device *adev, uint64_t offset,\r\nint pages, struct page **pagelist, dma_addr_t *dma_addr,\r\nuint32_t flags)\r\n{\r\nunsigned t;\r\nunsigned p;\r\nuint64_t page_base;\r\nint i, j;\r\nif (!adev->gart.ready) {\r\nWARN(1, "trying to bind memory to uninitialized GART !\n");\r\nreturn -EINVAL;\r\n}\r\nt = offset / AMDGPU_GPU_PAGE_SIZE;\r\np = t / (PAGE_SIZE / AMDGPU_GPU_PAGE_SIZE);\r\nfor (i = 0; i < pages; i++, p++) {\r\n#ifdef CONFIG_DRM_AMDGPU_GART_DEBUGFS\r\nadev->gart.pages[p] = pagelist[i];\r\n#endif\r\nif (adev->gart.ptr) {\r\npage_base = dma_addr[i];\r\nfor (j = 0; j < (PAGE_SIZE / AMDGPU_GPU_PAGE_SIZE); j++, t++) {\r\namdgpu_gart_set_pte_pde(adev, adev->gart.ptr, t, page_base, flags);\r\npage_base += AMDGPU_GPU_PAGE_SIZE;\r\n}\r\n}\r\n}\r\nmb();\r\namdgpu_gart_flush_gpu_tlb(adev, 0);\r\nreturn 0;\r\n}\r\nint amdgpu_gart_init(struct amdgpu_device *adev)\r\n{\r\nint r;\r\nif (adev->dummy_page.page)\r\nreturn 0;\r\nif (PAGE_SIZE < AMDGPU_GPU_PAGE_SIZE) {\r\nDRM_ERROR("Page size is smaller than GPU page size!\n");\r\nreturn -EINVAL;\r\n}\r\nr = amdgpu_dummy_page_init(adev);\r\nif (r)\r\nreturn r;\r\nadev->gart.num_cpu_pages = adev->mc.gtt_size / PAGE_SIZE;\r\nadev->gart.num_gpu_pages = adev->mc.gtt_size / AMDGPU_GPU_PAGE_SIZE;\r\nDRM_INFO("GART: num cpu pages %u, num gpu pages %u\n",\r\nadev->gart.num_cpu_pages, adev->gart.num_gpu_pages);\r\n#ifdef CONFIG_DRM_AMDGPU_GART_DEBUGFS\r\nadev->gart.pages = vzalloc(sizeof(void *) * adev->gart.num_cpu_pages);\r\nif (adev->gart.pages == NULL) {\r\namdgpu_gart_fini(adev);\r\nreturn -ENOMEM;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nvoid amdgpu_gart_fini(struct amdgpu_device *adev)\r\n{\r\nif (adev->gart.ready) {\r\namdgpu_gart_unbind(adev, 0, adev->gart.num_cpu_pages);\r\n}\r\nadev->gart.ready = false;\r\n#ifdef CONFIG_DRM_AMDGPU_GART_DEBUGFS\r\nvfree(adev->gart.pages);\r\nadev->gart.pages = NULL;\r\n#endif\r\namdgpu_dummy_page_fini(adev);\r\n}
