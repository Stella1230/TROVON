static inline void tdma_write(struct tegra_adma *tdma, u32 reg, u32 val)\r\n{\r\nwritel(val, tdma->base_addr + reg);\r\n}\r\nstatic inline u32 tdma_read(struct tegra_adma *tdma, u32 reg)\r\n{\r\nreturn readl(tdma->base_addr + reg);\r\n}\r\nstatic inline void tdma_ch_write(struct tegra_adma_chan *tdc, u32 reg, u32 val)\r\n{\r\nwritel(val, tdc->chan_addr + reg);\r\n}\r\nstatic inline u32 tdma_ch_read(struct tegra_adma_chan *tdc, u32 reg)\r\n{\r\nreturn readl(tdc->chan_addr + reg);\r\n}\r\nstatic inline struct tegra_adma_chan *to_tegra_adma_chan(struct dma_chan *dc)\r\n{\r\nreturn container_of(dc, struct tegra_adma_chan, vc.chan);\r\n}\r\nstatic inline struct tegra_adma_desc *to_tegra_adma_desc(\r\nstruct dma_async_tx_descriptor *td)\r\n{\r\nreturn container_of(td, struct tegra_adma_desc, vd.tx);\r\n}\r\nstatic inline struct device *tdc2dev(struct tegra_adma_chan *tdc)\r\n{\r\nreturn tdc->tdma->dev;\r\n}\r\nstatic void tegra_adma_desc_free(struct virt_dma_desc *vd)\r\n{\r\nkfree(container_of(vd, struct tegra_adma_desc, vd));\r\n}\r\nstatic int tegra_adma_slave_config(struct dma_chan *dc,\r\nstruct dma_slave_config *sconfig)\r\n{\r\nstruct tegra_adma_chan *tdc = to_tegra_adma_chan(dc);\r\nmemcpy(&tdc->sconfig, sconfig, sizeof(*sconfig));\r\nreturn 0;\r\n}\r\nstatic int tegra_adma_init(struct tegra_adma *tdma)\r\n{\r\nu32 status;\r\nint ret;\r\ntdma_write(tdma, ADMA_GLOBAL_INT_CLEAR, 0x1);\r\ntdma_write(tdma, ADMA_GLOBAL_SOFT_RESET, 0x1);\r\nret = readx_poll_timeout(readl,\r\ntdma->base_addr + ADMA_GLOBAL_SOFT_RESET,\r\nstatus, status == 0, 20, 10000);\r\nif (ret)\r\nreturn ret;\r\ntdma_write(tdma, ADMA_GLOBAL_CMD, 1);\r\nreturn 0;\r\n}\r\nstatic int tegra_adma_request_alloc(struct tegra_adma_chan *tdc,\r\nenum dma_transfer_direction direction)\r\n{\r\nstruct tegra_adma *tdma = tdc->tdma;\r\nunsigned int sreq_index = tdc->sreq_index;\r\nif (tdc->sreq_reserved)\r\nreturn tdc->sreq_dir == direction ? 0 : -EINVAL;\r\nswitch (direction) {\r\ncase DMA_MEM_TO_DEV:\r\nif (sreq_index > ADMA_CH_CTRL_TX_REQ_MAX) {\r\ndev_err(tdma->dev, "invalid DMA request\n");\r\nreturn -EINVAL;\r\n}\r\nif (test_and_set_bit(sreq_index, &tdma->tx_requests_reserved)) {\r\ndev_err(tdma->dev, "DMA request reserved\n");\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ncase DMA_DEV_TO_MEM:\r\nif (sreq_index > ADMA_CH_CTRL_RX_REQ_MAX) {\r\ndev_err(tdma->dev, "invalid DMA request\n");\r\nreturn -EINVAL;\r\n}\r\nif (test_and_set_bit(sreq_index, &tdma->rx_requests_reserved)) {\r\ndev_err(tdma->dev, "DMA request reserved\n");\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\ndev_WARN(tdma->dev, "channel %s has invalid transfer type\n",\r\ndma_chan_name(&tdc->vc.chan));\r\nreturn -EINVAL;\r\n}\r\ntdc->sreq_dir = direction;\r\ntdc->sreq_reserved = true;\r\nreturn 0;\r\n}\r\nstatic void tegra_adma_request_free(struct tegra_adma_chan *tdc)\r\n{\r\nstruct tegra_adma *tdma = tdc->tdma;\r\nif (!tdc->sreq_reserved)\r\nreturn;\r\nswitch (tdc->sreq_dir) {\r\ncase DMA_MEM_TO_DEV:\r\nclear_bit(tdc->sreq_index, &tdma->tx_requests_reserved);\r\nbreak;\r\ncase DMA_DEV_TO_MEM:\r\nclear_bit(tdc->sreq_index, &tdma->rx_requests_reserved);\r\nbreak;\r\ndefault:\r\ndev_WARN(tdma->dev, "channel %s has invalid transfer type\n",\r\ndma_chan_name(&tdc->vc.chan));\r\nreturn;\r\n}\r\ntdc->sreq_reserved = false;\r\n}\r\nstatic u32 tegra_adma_irq_status(struct tegra_adma_chan *tdc)\r\n{\r\nu32 status = tdma_ch_read(tdc, ADMA_CH_INT_STATUS);\r\nreturn status & ADMA_CH_INT_STATUS_XFER_DONE;\r\n}\r\nstatic u32 tegra_adma_irq_clear(struct tegra_adma_chan *tdc)\r\n{\r\nu32 status = tegra_adma_irq_status(tdc);\r\nif (status)\r\ntdma_ch_write(tdc, ADMA_CH_INT_CLEAR, status);\r\nreturn status;\r\n}\r\nstatic void tegra_adma_stop(struct tegra_adma_chan *tdc)\r\n{\r\nunsigned int status;\r\ntdma_ch_write(tdc, ADMA_CH_CMD, 0);\r\ntegra_adma_irq_clear(tdc);\r\nif (readx_poll_timeout_atomic(readl, tdc->chan_addr + ADMA_CH_STATUS,\r\nstatus, !(status & ADMA_CH_STATUS_XFER_EN),\r\n20, 10000)) {\r\ndev_err(tdc2dev(tdc), "unable to stop DMA channel\n");\r\nreturn;\r\n}\r\nkfree(tdc->desc);\r\ntdc->desc = NULL;\r\n}\r\nstatic void tegra_adma_start(struct tegra_adma_chan *tdc)\r\n{\r\nstruct virt_dma_desc *vd = vchan_next_desc(&tdc->vc);\r\nstruct tegra_adma_chan_regs *ch_regs;\r\nstruct tegra_adma_desc *desc;\r\nif (!vd)\r\nreturn;\r\nlist_del(&vd->node);\r\ndesc = to_tegra_adma_desc(&vd->tx);\r\nif (!desc) {\r\ndev_warn(tdc2dev(tdc), "unable to start DMA, no descriptor\n");\r\nreturn;\r\n}\r\nch_regs = &desc->ch_regs;\r\ntdc->tx_buf_pos = 0;\r\ntdc->tx_buf_count = 0;\r\ntdma_ch_write(tdc, ADMA_CH_TC, ch_regs->tc);\r\ntdma_ch_write(tdc, ADMA_CH_CTRL, ch_regs->ctrl);\r\ntdma_ch_write(tdc, ADMA_CH_LOWER_SRC_ADDR, ch_regs->src_addr);\r\ntdma_ch_write(tdc, ADMA_CH_LOWER_TRG_ADDR, ch_regs->trg_addr);\r\ntdma_ch_write(tdc, ADMA_CH_FIFO_CTRL, ch_regs->fifo_ctrl);\r\ntdma_ch_write(tdc, ADMA_CH_CONFIG, ch_regs->config);\r\ntdma_ch_write(tdc, ADMA_CH_CMD, 1);\r\ntdc->desc = desc;\r\n}\r\nstatic unsigned int tegra_adma_get_residue(struct tegra_adma_chan *tdc)\r\n{\r\nstruct tegra_adma_desc *desc = tdc->desc;\r\nunsigned int max = ADMA_CH_XFER_STATUS_COUNT_MASK + 1;\r\nunsigned int pos = tdma_ch_read(tdc, ADMA_CH_XFER_STATUS);\r\nunsigned int periods_remaining;\r\nif (pos < tdc->tx_buf_pos)\r\ntdc->tx_buf_count += pos + (max - tdc->tx_buf_pos);\r\nelse\r\ntdc->tx_buf_count += pos - tdc->tx_buf_pos;\r\nperiods_remaining = tdc->tx_buf_count % desc->num_periods;\r\ntdc->tx_buf_pos = pos;\r\nreturn desc->buf_len - (periods_remaining * desc->period_len);\r\n}\r\nstatic irqreturn_t tegra_adma_isr(int irq, void *dev_id)\r\n{\r\nstruct tegra_adma_chan *tdc = dev_id;\r\nunsigned long status;\r\nunsigned long flags;\r\nspin_lock_irqsave(&tdc->vc.lock, flags);\r\nstatus = tegra_adma_irq_clear(tdc);\r\nif (status == 0 || !tdc->desc) {\r\nspin_unlock_irqrestore(&tdc->vc.lock, flags);\r\nreturn IRQ_NONE;\r\n}\r\nvchan_cyclic_callback(&tdc->desc->vd);\r\nspin_unlock_irqrestore(&tdc->vc.lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void tegra_adma_issue_pending(struct dma_chan *dc)\r\n{\r\nstruct tegra_adma_chan *tdc = to_tegra_adma_chan(dc);\r\nunsigned long flags;\r\nspin_lock_irqsave(&tdc->vc.lock, flags);\r\nif (vchan_issue_pending(&tdc->vc)) {\r\nif (!tdc->desc)\r\ntegra_adma_start(tdc);\r\n}\r\nspin_unlock_irqrestore(&tdc->vc.lock, flags);\r\n}\r\nstatic int tegra_adma_terminate_all(struct dma_chan *dc)\r\n{\r\nstruct tegra_adma_chan *tdc = to_tegra_adma_chan(dc);\r\nunsigned long flags;\r\nLIST_HEAD(head);\r\nspin_lock_irqsave(&tdc->vc.lock, flags);\r\nif (tdc->desc)\r\ntegra_adma_stop(tdc);\r\ntegra_adma_request_free(tdc);\r\nvchan_get_all_descriptors(&tdc->vc, &head);\r\nspin_unlock_irqrestore(&tdc->vc.lock, flags);\r\nvchan_dma_desc_free_list(&tdc->vc, &head);\r\nreturn 0;\r\n}\r\nstatic enum dma_status tegra_adma_tx_status(struct dma_chan *dc,\r\ndma_cookie_t cookie,\r\nstruct dma_tx_state *txstate)\r\n{\r\nstruct tegra_adma_chan *tdc = to_tegra_adma_chan(dc);\r\nstruct tegra_adma_desc *desc;\r\nstruct virt_dma_desc *vd;\r\nenum dma_status ret;\r\nunsigned long flags;\r\nunsigned int residual;\r\nret = dma_cookie_status(dc, cookie, txstate);\r\nif (ret == DMA_COMPLETE || !txstate)\r\nreturn ret;\r\nspin_lock_irqsave(&tdc->vc.lock, flags);\r\nvd = vchan_find_desc(&tdc->vc, cookie);\r\nif (vd) {\r\ndesc = to_tegra_adma_desc(&vd->tx);\r\nresidual = desc->ch_regs.tc;\r\n} else if (tdc->desc && tdc->desc->vd.tx.cookie == cookie) {\r\nresidual = tegra_adma_get_residue(tdc);\r\n} else {\r\nresidual = 0;\r\n}\r\nspin_unlock_irqrestore(&tdc->vc.lock, flags);\r\ndma_set_residue(txstate, residual);\r\nreturn ret;\r\n}\r\nstatic int tegra_adma_set_xfer_params(struct tegra_adma_chan *tdc,\r\nstruct tegra_adma_desc *desc,\r\ndma_addr_t buf_addr,\r\nenum dma_transfer_direction direction)\r\n{\r\nstruct tegra_adma_chan_regs *ch_regs = &desc->ch_regs;\r\nunsigned int burst_size, adma_dir;\r\nif (desc->num_periods > ADMA_CH_CONFIG_MAX_BUFS)\r\nreturn -EINVAL;\r\nswitch (direction) {\r\ncase DMA_MEM_TO_DEV:\r\nadma_dir = ADMA_CH_CTRL_DIR_MEM2AHUB;\r\nburst_size = fls(tdc->sconfig.dst_maxburst);\r\nch_regs->config = ADMA_CH_CONFIG_SRC_BUF(desc->num_periods - 1);\r\nch_regs->ctrl = ADMA_CH_CTRL_TX_REQ(tdc->sreq_index);\r\nch_regs->src_addr = buf_addr;\r\nbreak;\r\ncase DMA_DEV_TO_MEM:\r\nadma_dir = ADMA_CH_CTRL_DIR_AHUB2MEM;\r\nburst_size = fls(tdc->sconfig.src_maxburst);\r\nch_regs->config = ADMA_CH_CONFIG_TRG_BUF(desc->num_periods - 1);\r\nch_regs->ctrl = ADMA_CH_CTRL_RX_REQ(tdc->sreq_index);\r\nch_regs->trg_addr = buf_addr;\r\nbreak;\r\ndefault:\r\ndev_err(tdc2dev(tdc), "DMA direction is not supported\n");\r\nreturn -EINVAL;\r\n}\r\nif (!burst_size || burst_size > ADMA_CH_CONFIG_BURST_16)\r\nburst_size = ADMA_CH_CONFIG_BURST_16;\r\nch_regs->ctrl |= ADMA_CH_CTRL_DIR(adma_dir) |\r\nADMA_CH_CTRL_MODE_CONTINUOUS |\r\nADMA_CH_CTRL_FLOWCTRL_EN;\r\nch_regs->config |= ADMA_CH_CONFIG_BURST_SIZE(burst_size);\r\nch_regs->config |= ADMA_CH_CONFIG_WEIGHT_FOR_WRR(1);\r\nch_regs->fifo_ctrl = ADMA_CH_FIFO_CTRL_DEFAULT;\r\nch_regs->tc = desc->period_len & ADMA_CH_TC_COUNT_MASK;\r\nreturn tegra_adma_request_alloc(tdc, direction);\r\n}\r\nstatic struct dma_async_tx_descriptor *tegra_adma_prep_dma_cyclic(\r\nstruct dma_chan *dc, dma_addr_t buf_addr, size_t buf_len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags)\r\n{\r\nstruct tegra_adma_chan *tdc = to_tegra_adma_chan(dc);\r\nstruct tegra_adma_desc *desc = NULL;\r\nif (!buf_len || !period_len || period_len > ADMA_CH_TC_COUNT_MASK) {\r\ndev_err(tdc2dev(tdc), "invalid buffer/period len\n");\r\nreturn NULL;\r\n}\r\nif (buf_len % period_len) {\r\ndev_err(tdc2dev(tdc), "buf_len not a multiple of period_len\n");\r\nreturn NULL;\r\n}\r\nif (!IS_ALIGNED(buf_addr, 4)) {\r\ndev_err(tdc2dev(tdc), "invalid buffer alignment\n");\r\nreturn NULL;\r\n}\r\ndesc = kzalloc(sizeof(*desc), GFP_NOWAIT);\r\nif (!desc)\r\nreturn NULL;\r\ndesc->buf_len = buf_len;\r\ndesc->period_len = period_len;\r\ndesc->num_periods = buf_len / period_len;\r\nif (tegra_adma_set_xfer_params(tdc, desc, buf_addr, direction)) {\r\nkfree(desc);\r\nreturn NULL;\r\n}\r\nreturn vchan_tx_prep(&tdc->vc, &desc->vd, flags);\r\n}\r\nstatic int tegra_adma_alloc_chan_resources(struct dma_chan *dc)\r\n{\r\nstruct tegra_adma_chan *tdc = to_tegra_adma_chan(dc);\r\nint ret;\r\nret = request_irq(tdc->irq, tegra_adma_isr, 0, dma_chan_name(dc), tdc);\r\nif (ret) {\r\ndev_err(tdc2dev(tdc), "failed to get interrupt for %s\n",\r\ndma_chan_name(dc));\r\nreturn ret;\r\n}\r\nret = pm_runtime_get_sync(tdc2dev(tdc));\r\nif (ret < 0) {\r\nfree_irq(tdc->irq, tdc);\r\nreturn ret;\r\n}\r\ndma_cookie_init(&tdc->vc.chan);\r\nreturn 0;\r\n}\r\nstatic void tegra_adma_free_chan_resources(struct dma_chan *dc)\r\n{\r\nstruct tegra_adma_chan *tdc = to_tegra_adma_chan(dc);\r\ntegra_adma_terminate_all(dc);\r\nvchan_free_chan_resources(&tdc->vc);\r\ntasklet_kill(&tdc->vc.task);\r\nfree_irq(tdc->irq, tdc);\r\npm_runtime_put(tdc2dev(tdc));\r\ntdc->sreq_index = 0;\r\ntdc->sreq_dir = DMA_TRANS_NONE;\r\n}\r\nstatic struct dma_chan *tegra_dma_of_xlate(struct of_phandle_args *dma_spec,\r\nstruct of_dma *ofdma)\r\n{\r\nstruct tegra_adma *tdma = ofdma->of_dma_data;\r\nstruct tegra_adma_chan *tdc;\r\nstruct dma_chan *chan;\r\nunsigned int sreq_index;\r\nif (dma_spec->args_count != 1)\r\nreturn NULL;\r\nsreq_index = dma_spec->args[0];\r\nif (sreq_index == 0) {\r\ndev_err(tdma->dev, "DMA request must not be 0\n");\r\nreturn NULL;\r\n}\r\nchan = dma_get_any_slave_channel(&tdma->dma_dev);\r\nif (!chan)\r\nreturn NULL;\r\ntdc = to_tegra_adma_chan(chan);\r\ntdc->sreq_index = sreq_index;\r\nreturn chan;\r\n}\r\nstatic int tegra_adma_runtime_suspend(struct device *dev)\r\n{\r\nstruct tegra_adma *tdma = dev_get_drvdata(dev);\r\ntdma->global_cmd = tdma_read(tdma, ADMA_GLOBAL_CMD);\r\nreturn pm_clk_suspend(dev);\r\n}\r\nstatic int tegra_adma_runtime_resume(struct device *dev)\r\n{\r\nstruct tegra_adma *tdma = dev_get_drvdata(dev);\r\nint ret;\r\nret = pm_clk_resume(dev);\r\nif (ret)\r\nreturn ret;\r\ntdma_write(tdma, ADMA_GLOBAL_CMD, tdma->global_cmd);\r\nreturn 0;\r\n}\r\nstatic int tegra_adma_probe(struct platform_device *pdev)\r\n{\r\nconst struct tegra_adma_chip_data *cdata;\r\nstruct tegra_adma *tdma;\r\nstruct resource *res;\r\nint ret, i;\r\ncdata = of_device_get_match_data(&pdev->dev);\r\nif (!cdata) {\r\ndev_err(&pdev->dev, "device match data not found\n");\r\nreturn -ENODEV;\r\n}\r\ntdma = devm_kzalloc(&pdev->dev, sizeof(*tdma) + cdata->nr_channels *\r\nsizeof(struct tegra_adma_chan), GFP_KERNEL);\r\nif (!tdma)\r\nreturn -ENOMEM;\r\ntdma->dev = &pdev->dev;\r\ntdma->nr_channels = cdata->nr_channels;\r\nplatform_set_drvdata(pdev, tdma);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\ntdma->base_addr = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(tdma->base_addr))\r\nreturn PTR_ERR(tdma->base_addr);\r\nret = pm_clk_create(&pdev->dev);\r\nif (ret)\r\nreturn ret;\r\nret = of_pm_clk_add_clk(&pdev->dev, "d_audio");\r\nif (ret)\r\ngoto clk_destroy;\r\npm_runtime_enable(&pdev->dev);\r\nret = pm_runtime_get_sync(&pdev->dev);\r\nif (ret < 0)\r\ngoto rpm_disable;\r\nret = tegra_adma_init(tdma);\r\nif (ret)\r\ngoto rpm_put;\r\nINIT_LIST_HEAD(&tdma->dma_dev.channels);\r\nfor (i = 0; i < tdma->nr_channels; i++) {\r\nstruct tegra_adma_chan *tdc = &tdma->channels[i];\r\ntdc->chan_addr = tdma->base_addr + ADMA_CH_REG_OFFSET(i);\r\ntdc->irq = of_irq_get(pdev->dev.of_node, i);\r\nif (tdc->irq < 0) {\r\nret = tdc->irq;\r\ngoto irq_dispose;\r\n}\r\nvchan_init(&tdc->vc, &tdma->dma_dev);\r\ntdc->vc.desc_free = tegra_adma_desc_free;\r\ntdc->tdma = tdma;\r\n}\r\ndma_cap_set(DMA_SLAVE, tdma->dma_dev.cap_mask);\r\ndma_cap_set(DMA_PRIVATE, tdma->dma_dev.cap_mask);\r\ndma_cap_set(DMA_CYCLIC, tdma->dma_dev.cap_mask);\r\ntdma->dma_dev.dev = &pdev->dev;\r\ntdma->dma_dev.device_alloc_chan_resources =\r\ntegra_adma_alloc_chan_resources;\r\ntdma->dma_dev.device_free_chan_resources =\r\ntegra_adma_free_chan_resources;\r\ntdma->dma_dev.device_issue_pending = tegra_adma_issue_pending;\r\ntdma->dma_dev.device_prep_dma_cyclic = tegra_adma_prep_dma_cyclic;\r\ntdma->dma_dev.device_config = tegra_adma_slave_config;\r\ntdma->dma_dev.device_tx_status = tegra_adma_tx_status;\r\ntdma->dma_dev.device_terminate_all = tegra_adma_terminate_all;\r\ntdma->dma_dev.src_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\ntdma->dma_dev.dst_addr_widths = BIT(DMA_SLAVE_BUSWIDTH_4_BYTES);\r\ntdma->dma_dev.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\r\ntdma->dma_dev.residue_granularity = DMA_RESIDUE_GRANULARITY_SEGMENT;\r\nret = dma_async_device_register(&tdma->dma_dev);\r\nif (ret < 0) {\r\ndev_err(&pdev->dev, "ADMA registration failed: %d\n", ret);\r\ngoto irq_dispose;\r\n}\r\nret = of_dma_controller_register(pdev->dev.of_node,\r\ntegra_dma_of_xlate, tdma);\r\nif (ret < 0) {\r\ndev_err(&pdev->dev, "ADMA OF registration failed %d\n", ret);\r\ngoto dma_remove;\r\n}\r\npm_runtime_put(&pdev->dev);\r\ndev_info(&pdev->dev, "Tegra210 ADMA driver registered %d channels\n",\r\ntdma->nr_channels);\r\nreturn 0;\r\ndma_remove:\r\ndma_async_device_unregister(&tdma->dma_dev);\r\nirq_dispose:\r\nwhile (--i >= 0)\r\nirq_dispose_mapping(tdma->channels[i].irq);\r\nrpm_put:\r\npm_runtime_put_sync(&pdev->dev);\r\nrpm_disable:\r\npm_runtime_disable(&pdev->dev);\r\nclk_destroy:\r\npm_clk_destroy(&pdev->dev);\r\nreturn ret;\r\n}\r\nstatic int tegra_adma_remove(struct platform_device *pdev)\r\n{\r\nstruct tegra_adma *tdma = platform_get_drvdata(pdev);\r\nint i;\r\ndma_async_device_unregister(&tdma->dma_dev);\r\nfor (i = 0; i < tdma->nr_channels; ++i)\r\nirq_dispose_mapping(tdma->channels[i].irq);\r\npm_runtime_put_sync(&pdev->dev);\r\npm_runtime_disable(&pdev->dev);\r\npm_clk_destroy(&pdev->dev);\r\nreturn 0;\r\n}\r\nstatic int tegra_adma_pm_suspend(struct device *dev)\r\n{\r\nreturn pm_runtime_suspended(dev) == false;\r\n}
