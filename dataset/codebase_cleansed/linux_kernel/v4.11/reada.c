static void __readahead_hook(struct btrfs_fs_info *fs_info,\r\nstruct reada_extent *re, struct extent_buffer *eb,\r\nint err)\r\n{\r\nint nritems;\r\nint i;\r\nu64 bytenr;\r\nu64 generation;\r\nstruct list_head list;\r\nspin_lock(&re->lock);\r\nlist_replace_init(&re->extctl, &list);\r\nre->scheduled = 0;\r\nspin_unlock(&re->lock);\r\nif (err)\r\ngoto cleanup;\r\nif (!btrfs_header_level(eb))\r\ngoto cleanup;\r\nnritems = btrfs_header_nritems(eb);\r\ngeneration = btrfs_header_generation(eb);\r\nfor (i = 0; i < nritems; i++) {\r\nstruct reada_extctl *rec;\r\nu64 n_gen;\r\nstruct btrfs_key key;\r\nstruct btrfs_key next_key;\r\nbtrfs_node_key_to_cpu(eb, &key, i);\r\nif (i + 1 < nritems)\r\nbtrfs_node_key_to_cpu(eb, &next_key, i + 1);\r\nelse\r\nnext_key = re->top;\r\nbytenr = btrfs_node_blockptr(eb, i);\r\nn_gen = btrfs_node_ptr_generation(eb, i);\r\nlist_for_each_entry(rec, &list, list) {\r\nstruct reada_control *rc = rec->rc;\r\n#ifdef DEBUG\r\nif (rec->generation != generation) {\r\nbtrfs_debug(fs_info,\r\n"generation mismatch for (%llu,%d,%llu) %llu != %llu",\r\nkey.objectid, key.type, key.offset,\r\nrec->generation, generation);\r\n}\r\n#endif\r\nif (rec->generation == generation &&\r\nbtrfs_comp_cpu_keys(&key, &rc->key_end) < 0 &&\r\nbtrfs_comp_cpu_keys(&next_key, &rc->key_start) > 0)\r\nreada_add_block(rc, bytenr, &next_key, n_gen);\r\n}\r\n}\r\ncleanup:\r\nwhile (!list_empty(&list)) {\r\nstruct reada_control *rc;\r\nstruct reada_extctl *rec;\r\nrec = list_first_entry(&list, struct reada_extctl, list);\r\nlist_del(&rec->list);\r\nrc = rec->rc;\r\nkfree(rec);\r\nkref_get(&rc->refcnt);\r\nif (atomic_dec_and_test(&rc->elems)) {\r\nkref_put(&rc->refcnt, reada_control_release);\r\nwake_up(&rc->wait);\r\n}\r\nkref_put(&rc->refcnt, reada_control_release);\r\nreada_extent_put(fs_info, re);\r\n}\r\nreturn;\r\n}\r\nint btree_readahead_hook(struct btrfs_fs_info *fs_info,\r\nstruct extent_buffer *eb, int err)\r\n{\r\nint ret = 0;\r\nstruct reada_extent *re;\r\nspin_lock(&fs_info->reada_lock);\r\nre = radix_tree_lookup(&fs_info->reada_tree,\r\neb->start >> PAGE_SHIFT);\r\nif (re)\r\nre->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nif (!re) {\r\nret = -1;\r\ngoto start_machine;\r\n}\r\n__readahead_hook(fs_info, re, eb, err);\r\nreada_extent_put(fs_info, re);\r\nstart_machine:\r\nreada_start_machine(fs_info);\r\nreturn ret;\r\n}\r\nstatic struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,\r\nstruct btrfs_device *dev, u64 logical,\r\nstruct btrfs_bio *bbio)\r\n{\r\nint ret;\r\nstruct reada_zone *zone;\r\nstruct btrfs_block_group_cache *cache = NULL;\r\nu64 start;\r\nu64 end;\r\nint i;\r\nzone = NULL;\r\nspin_lock(&fs_info->reada_lock);\r\nret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,\r\nlogical >> PAGE_SHIFT, 1);\r\nif (ret == 1 && logical >= zone->start && logical <= zone->end) {\r\nkref_get(&zone->refcnt);\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn zone;\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\ncache = btrfs_lookup_block_group(fs_info, logical);\r\nif (!cache)\r\nreturn NULL;\r\nstart = cache->key.objectid;\r\nend = start + cache->key.offset - 1;\r\nbtrfs_put_block_group(cache);\r\nzone = kzalloc(sizeof(*zone), GFP_KERNEL);\r\nif (!zone)\r\nreturn NULL;\r\nzone->start = start;\r\nzone->end = end;\r\nINIT_LIST_HEAD(&zone->list);\r\nspin_lock_init(&zone->lock);\r\nzone->locked = 0;\r\nkref_init(&zone->refcnt);\r\nzone->elems = 0;\r\nzone->device = dev;\r\nfor (i = 0; i < bbio->num_stripes; ++i) {\r\nzone->devs[i] = bbio->stripes[i].dev;\r\n}\r\nzone->ndevs = bbio->num_stripes;\r\nspin_lock(&fs_info->reada_lock);\r\nret = radix_tree_insert(&dev->reada_zones,\r\n(unsigned long)(zone->end >> PAGE_SHIFT),\r\nzone);\r\nif (ret == -EEXIST) {\r\nkfree(zone);\r\nret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,\r\nlogical >> PAGE_SHIFT, 1);\r\nif (ret == 1 && logical >= zone->start && logical <= zone->end)\r\nkref_get(&zone->refcnt);\r\nelse\r\nzone = NULL;\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn zone;\r\n}\r\nstatic struct reada_extent *reada_find_extent(struct btrfs_fs_info *fs_info,\r\nu64 logical,\r\nstruct btrfs_key *top)\r\n{\r\nint ret;\r\nstruct reada_extent *re = NULL;\r\nstruct reada_extent *re_exist = NULL;\r\nstruct btrfs_bio *bbio = NULL;\r\nstruct btrfs_device *dev;\r\nstruct btrfs_device *prev_dev;\r\nu32 blocksize;\r\nu64 length;\r\nint real_stripes;\r\nint nzones = 0;\r\nunsigned long index = logical >> PAGE_SHIFT;\r\nint dev_replace_is_ongoing;\r\nint have_zone = 0;\r\nspin_lock(&fs_info->reada_lock);\r\nre = radix_tree_lookup(&fs_info->reada_tree, index);\r\nif (re)\r\nre->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nif (re)\r\nreturn re;\r\nre = kzalloc(sizeof(*re), GFP_KERNEL);\r\nif (!re)\r\nreturn NULL;\r\nblocksize = fs_info->nodesize;\r\nre->logical = logical;\r\nre->top = *top;\r\nINIT_LIST_HEAD(&re->extctl);\r\nspin_lock_init(&re->lock);\r\nre->refcnt = 1;\r\nlength = blocksize;\r\nret = btrfs_map_block(fs_info, BTRFS_MAP_GET_READ_MIRRORS, logical,\r\n&length, &bbio, 0);\r\nif (ret || !bbio || length < blocksize)\r\ngoto error;\r\nif (bbio->num_stripes > BTRFS_MAX_MIRRORS) {\r\nbtrfs_err(fs_info,\r\n"readahead: more than %d copies not supported",\r\nBTRFS_MAX_MIRRORS);\r\ngoto error;\r\n}\r\nreal_stripes = bbio->num_stripes - bbio->num_tgtdevs;\r\nfor (nzones = 0; nzones < real_stripes; ++nzones) {\r\nstruct reada_zone *zone;\r\ndev = bbio->stripes[nzones].dev;\r\nif (!dev->bdev)\r\ncontinue;\r\nzone = reada_find_zone(fs_info, dev, logical, bbio);\r\nif (!zone)\r\ncontinue;\r\nre->zones[re->nzones++] = zone;\r\nspin_lock(&zone->lock);\r\nif (!zone->elems)\r\nkref_get(&zone->refcnt);\r\n++zone->elems;\r\nspin_unlock(&zone->lock);\r\nspin_lock(&fs_info->reada_lock);\r\nkref_put(&zone->refcnt, reada_zone_release);\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nif (re->nzones == 0) {\r\ngoto error;\r\n}\r\nbtrfs_dev_replace_lock(&fs_info->dev_replace, 0);\r\nspin_lock(&fs_info->reada_lock);\r\nret = radix_tree_insert(&fs_info->reada_tree, index, re);\r\nif (ret == -EEXIST) {\r\nre_exist = radix_tree_lookup(&fs_info->reada_tree, index);\r\nre_exist->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace, 0);\r\ngoto error;\r\n}\r\nif (ret) {\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace, 0);\r\ngoto error;\r\n}\r\nprev_dev = NULL;\r\ndev_replace_is_ongoing = btrfs_dev_replace_is_ongoing(\r\n&fs_info->dev_replace);\r\nfor (nzones = 0; nzones < re->nzones; ++nzones) {\r\ndev = re->zones[nzones]->device;\r\nif (dev == prev_dev) {\r\ncontinue;\r\n}\r\nif (!dev->bdev)\r\ncontinue;\r\nif (dev_replace_is_ongoing &&\r\ndev == fs_info->dev_replace.tgtdev) {\r\ncontinue;\r\n}\r\nprev_dev = dev;\r\nret = radix_tree_insert(&dev->reada_extents, index, re);\r\nif (ret) {\r\nwhile (--nzones >= 0) {\r\ndev = re->zones[nzones]->device;\r\nBUG_ON(dev == NULL);\r\nradix_tree_delete(&dev->reada_extents, index);\r\n}\r\nradix_tree_delete(&fs_info->reada_tree, index);\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace, 0);\r\ngoto error;\r\n}\r\nhave_zone = 1;\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace, 0);\r\nif (!have_zone)\r\ngoto error;\r\nbtrfs_put_bbio(bbio);\r\nreturn re;\r\nerror:\r\nfor (nzones = 0; nzones < re->nzones; ++nzones) {\r\nstruct reada_zone *zone;\r\nzone = re->zones[nzones];\r\nkref_get(&zone->refcnt);\r\nspin_lock(&zone->lock);\r\n--zone->elems;\r\nif (zone->elems == 0) {\r\nkref_put(&zone->refcnt, reada_zone_release);\r\n}\r\nspin_unlock(&zone->lock);\r\nspin_lock(&fs_info->reada_lock);\r\nkref_put(&zone->refcnt, reada_zone_release);\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nbtrfs_put_bbio(bbio);\r\nkfree(re);\r\nreturn re_exist;\r\n}\r\nstatic void reada_extent_put(struct btrfs_fs_info *fs_info,\r\nstruct reada_extent *re)\r\n{\r\nint i;\r\nunsigned long index = re->logical >> PAGE_SHIFT;\r\nspin_lock(&fs_info->reada_lock);\r\nif (--re->refcnt) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn;\r\n}\r\nradix_tree_delete(&fs_info->reada_tree, index);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nstruct reada_zone *zone = re->zones[i];\r\nradix_tree_delete(&zone->device->reada_extents, index);\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nstruct reada_zone *zone = re->zones[i];\r\nkref_get(&zone->refcnt);\r\nspin_lock(&zone->lock);\r\n--zone->elems;\r\nif (zone->elems == 0) {\r\nkref_put(&zone->refcnt, reada_zone_release);\r\n}\r\nspin_unlock(&zone->lock);\r\nspin_lock(&fs_info->reada_lock);\r\nkref_put(&zone->refcnt, reada_zone_release);\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nkfree(re);\r\n}\r\nstatic void reada_zone_release(struct kref *kref)\r\n{\r\nstruct reada_zone *zone = container_of(kref, struct reada_zone, refcnt);\r\nradix_tree_delete(&zone->device->reada_zones,\r\nzone->end >> PAGE_SHIFT);\r\nkfree(zone);\r\n}\r\nstatic void reada_control_release(struct kref *kref)\r\n{\r\nstruct reada_control *rc = container_of(kref, struct reada_control,\r\nrefcnt);\r\nkfree(rc);\r\n}\r\nstatic int reada_add_block(struct reada_control *rc, u64 logical,\r\nstruct btrfs_key *top, u64 generation)\r\n{\r\nstruct btrfs_fs_info *fs_info = rc->fs_info;\r\nstruct reada_extent *re;\r\nstruct reada_extctl *rec;\r\nre = reada_find_extent(fs_info, logical, top);\r\nif (!re)\r\nreturn -1;\r\nrec = kzalloc(sizeof(*rec), GFP_KERNEL);\r\nif (!rec) {\r\nreada_extent_put(fs_info, re);\r\nreturn -ENOMEM;\r\n}\r\nrec->rc = rc;\r\nrec->generation = generation;\r\natomic_inc(&rc->elems);\r\nspin_lock(&re->lock);\r\nlist_add_tail(&rec->list, &re->extctl);\r\nspin_unlock(&re->lock);\r\nreturn 0;\r\n}\r\nstatic void reada_peer_zones_set_lock(struct reada_zone *zone, int lock)\r\n{\r\nint i;\r\nunsigned long index = zone->end >> PAGE_SHIFT;\r\nfor (i = 0; i < zone->ndevs; ++i) {\r\nstruct reada_zone *peer;\r\npeer = radix_tree_lookup(&zone->devs[i]->reada_zones, index);\r\nif (peer && peer->device != zone->device)\r\npeer->locked = lock;\r\n}\r\n}\r\nstatic int reada_pick_zone(struct btrfs_device *dev)\r\n{\r\nstruct reada_zone *top_zone = NULL;\r\nstruct reada_zone *top_locked_zone = NULL;\r\nu64 top_elems = 0;\r\nu64 top_locked_elems = 0;\r\nunsigned long index = 0;\r\nint ret;\r\nif (dev->reada_curr_zone) {\r\nreada_peer_zones_set_lock(dev->reada_curr_zone, 0);\r\nkref_put(&dev->reada_curr_zone->refcnt, reada_zone_release);\r\ndev->reada_curr_zone = NULL;\r\n}\r\nwhile (1) {\r\nstruct reada_zone *zone;\r\nret = radix_tree_gang_lookup(&dev->reada_zones,\r\n(void **)&zone, index, 1);\r\nif (ret == 0)\r\nbreak;\r\nindex = (zone->end >> PAGE_SHIFT) + 1;\r\nif (zone->locked) {\r\nif (zone->elems > top_locked_elems) {\r\ntop_locked_elems = zone->elems;\r\ntop_locked_zone = zone;\r\n}\r\n} else {\r\nif (zone->elems > top_elems) {\r\ntop_elems = zone->elems;\r\ntop_zone = zone;\r\n}\r\n}\r\n}\r\nif (top_zone)\r\ndev->reada_curr_zone = top_zone;\r\nelse if (top_locked_zone)\r\ndev->reada_curr_zone = top_locked_zone;\r\nelse\r\nreturn 0;\r\ndev->reada_next = dev->reada_curr_zone->start;\r\nkref_get(&dev->reada_curr_zone->refcnt);\r\nreada_peer_zones_set_lock(dev->reada_curr_zone, 1);\r\nreturn 1;\r\n}\r\nstatic int reada_start_machine_dev(struct btrfs_fs_info *fs_info,\r\nstruct btrfs_device *dev)\r\n{\r\nstruct reada_extent *re = NULL;\r\nint mirror_num = 0;\r\nstruct extent_buffer *eb = NULL;\r\nu64 logical;\r\nint ret;\r\nint i;\r\nspin_lock(&fs_info->reada_lock);\r\nif (dev->reada_curr_zone == NULL) {\r\nret = reada_pick_zone(dev);\r\nif (!ret) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn 0;\r\n}\r\n}\r\nret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,\r\ndev->reada_next >> PAGE_SHIFT, 1);\r\nif (ret == 0 || re->logical > dev->reada_curr_zone->end) {\r\nret = reada_pick_zone(dev);\r\nif (!ret) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn 0;\r\n}\r\nre = NULL;\r\nret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,\r\ndev->reada_next >> PAGE_SHIFT, 1);\r\n}\r\nif (ret == 0) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn 0;\r\n}\r\ndev->reada_next = re->logical + fs_info->nodesize;\r\nre->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nspin_lock(&re->lock);\r\nif (re->scheduled || list_empty(&re->extctl)) {\r\nspin_unlock(&re->lock);\r\nreada_extent_put(fs_info, re);\r\nreturn 0;\r\n}\r\nre->scheduled = 1;\r\nspin_unlock(&re->lock);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nif (re->zones[i]->device == dev) {\r\nmirror_num = i + 1;\r\nbreak;\r\n}\r\n}\r\nlogical = re->logical;\r\natomic_inc(&dev->reada_in_flight);\r\nret = reada_tree_block_flagged(fs_info, logical, mirror_num, &eb);\r\nif (ret)\r\n__readahead_hook(fs_info, re, NULL, ret);\r\nelse if (eb)\r\n__readahead_hook(fs_info, re, eb, ret);\r\nif (eb)\r\nfree_extent_buffer(eb);\r\natomic_dec(&dev->reada_in_flight);\r\nreada_extent_put(fs_info, re);\r\nreturn 1;\r\n}\r\nstatic void reada_start_machine_worker(struct btrfs_work *work)\r\n{\r\nstruct reada_machine_work *rmw;\r\nstruct btrfs_fs_info *fs_info;\r\nint old_ioprio;\r\nrmw = container_of(work, struct reada_machine_work, work);\r\nfs_info = rmw->fs_info;\r\nkfree(rmw);\r\nold_ioprio = IOPRIO_PRIO_VALUE(task_nice_ioclass(current),\r\ntask_nice_ioprio(current));\r\nset_task_ioprio(current, BTRFS_IOPRIO_READA);\r\n__reada_start_machine(fs_info);\r\nset_task_ioprio(current, old_ioprio);\r\natomic_dec(&fs_info->reada_works_cnt);\r\n}\r\nstatic void __reada_start_machine(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_device *device;\r\nstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\r\nu64 enqueued;\r\nu64 total = 0;\r\nint i;\r\ndo {\r\nenqueued = 0;\r\nmutex_lock(&fs_devices->device_list_mutex);\r\nlist_for_each_entry(device, &fs_devices->devices, dev_list) {\r\nif (atomic_read(&device->reada_in_flight) <\r\nMAX_IN_FLIGHT)\r\nenqueued += reada_start_machine_dev(fs_info,\r\ndevice);\r\n}\r\nmutex_unlock(&fs_devices->device_list_mutex);\r\ntotal += enqueued;\r\n} while (enqueued && total < 10000);\r\nif (enqueued == 0)\r\nreturn;\r\nfor (i = 0; i < 2; ++i) {\r\nreada_start_machine(fs_info);\r\nif (atomic_read(&fs_info->reada_works_cnt) >\r\nBTRFS_MAX_MIRRORS * 2)\r\nbreak;\r\n}\r\n}\r\nstatic void reada_start_machine(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct reada_machine_work *rmw;\r\nrmw = kzalloc(sizeof(*rmw), GFP_KERNEL);\r\nif (!rmw) {\r\nBUG();\r\n}\r\nbtrfs_init_work(&rmw->work, btrfs_readahead_helper,\r\nreada_start_machine_worker, NULL, NULL);\r\nrmw->fs_info = fs_info;\r\nbtrfs_queue_work(fs_info->readahead_workers, &rmw->work);\r\natomic_inc(&fs_info->reada_works_cnt);\r\n}\r\nstatic void dump_devs(struct btrfs_fs_info *fs_info, int all)\r\n{\r\nstruct btrfs_device *device;\r\nstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\r\nunsigned long index;\r\nint ret;\r\nint i;\r\nint j;\r\nint cnt;\r\nspin_lock(&fs_info->reada_lock);\r\nlist_for_each_entry(device, &fs_devices->devices, dev_list) {\r\nbtrfs_debug(fs_info, "dev %lld has %d in flight", device->devid,\r\natomic_read(&device->reada_in_flight));\r\nindex = 0;\r\nwhile (1) {\r\nstruct reada_zone *zone;\r\nret = radix_tree_gang_lookup(&device->reada_zones,\r\n(void **)&zone, index, 1);\r\nif (ret == 0)\r\nbreak;\r\npr_debug(" zone %llu-%llu elems %llu locked %d devs",\r\nzone->start, zone->end, zone->elems,\r\nzone->locked);\r\nfor (j = 0; j < zone->ndevs; ++j) {\r\npr_cont(" %lld",\r\nzone->devs[j]->devid);\r\n}\r\nif (device->reada_curr_zone == zone)\r\npr_cont(" curr off %llu",\r\ndevice->reada_next - zone->start);\r\npr_cont("\n");\r\nindex = (zone->end >> PAGE_SHIFT) + 1;\r\n}\r\ncnt = 0;\r\nindex = 0;\r\nwhile (all) {\r\nstruct reada_extent *re = NULL;\r\nret = radix_tree_gang_lookup(&device->reada_extents,\r\n(void **)&re, index, 1);\r\nif (ret == 0)\r\nbreak;\r\npr_debug(" re: logical %llu size %u empty %d scheduled %d",\r\nre->logical, fs_info->nodesize,\r\nlist_empty(&re->extctl), re->scheduled);\r\nfor (i = 0; i < re->nzones; ++i) {\r\npr_cont(" zone %llu-%llu devs",\r\nre->zones[i]->start,\r\nre->zones[i]->end);\r\nfor (j = 0; j < re->zones[i]->ndevs; ++j) {\r\npr_cont(" %lld",\r\nre->zones[i]->devs[j]->devid);\r\n}\r\n}\r\npr_cont("\n");\r\nindex = (re->logical >> PAGE_SHIFT) + 1;\r\nif (++cnt > 15)\r\nbreak;\r\n}\r\n}\r\nindex = 0;\r\ncnt = 0;\r\nwhile (all) {\r\nstruct reada_extent *re = NULL;\r\nret = radix_tree_gang_lookup(&fs_info->reada_tree, (void **)&re,\r\nindex, 1);\r\nif (ret == 0)\r\nbreak;\r\nif (!re->scheduled) {\r\nindex = (re->logical >> PAGE_SHIFT) + 1;\r\ncontinue;\r\n}\r\npr_debug("re: logical %llu size %u list empty %d scheduled %d",\r\nre->logical, fs_info->nodesize,\r\nlist_empty(&re->extctl), re->scheduled);\r\nfor (i = 0; i < re->nzones; ++i) {\r\npr_cont(" zone %llu-%llu devs",\r\nre->zones[i]->start,\r\nre->zones[i]->end);\r\nfor (j = 0; j < re->zones[i]->ndevs; ++j) {\r\npr_cont(" %lld",\r\nre->zones[i]->devs[j]->devid);\r\n}\r\n}\r\npr_cont("\n");\r\nindex = (re->logical >> PAGE_SHIFT) + 1;\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nstruct reada_control *btrfs_reada_add(struct btrfs_root *root,\r\nstruct btrfs_key *key_start, struct btrfs_key *key_end)\r\n{\r\nstruct reada_control *rc;\r\nu64 start;\r\nu64 generation;\r\nint ret;\r\nstruct extent_buffer *node;\r\nstatic struct btrfs_key max_key = {\r\n.objectid = (u64)-1,\r\n.type = (u8)-1,\r\n.offset = (u64)-1\r\n};\r\nrc = kzalloc(sizeof(*rc), GFP_KERNEL);\r\nif (!rc)\r\nreturn ERR_PTR(-ENOMEM);\r\nrc->fs_info = root->fs_info;\r\nrc->key_start = *key_start;\r\nrc->key_end = *key_end;\r\natomic_set(&rc->elems, 0);\r\ninit_waitqueue_head(&rc->wait);\r\nkref_init(&rc->refcnt);\r\nkref_get(&rc->refcnt);\r\nnode = btrfs_root_node(root);\r\nstart = node->start;\r\ngeneration = btrfs_header_generation(node);\r\nfree_extent_buffer(node);\r\nret = reada_add_block(rc, start, &max_key, generation);\r\nif (ret) {\r\nkfree(rc);\r\nreturn ERR_PTR(ret);\r\n}\r\nreada_start_machine(root->fs_info);\r\nreturn rc;\r\n}\r\nint btrfs_reada_wait(void *handle)\r\n{\r\nstruct reada_control *rc = handle;\r\nstruct btrfs_fs_info *fs_info = rc->fs_info;\r\nwhile (atomic_read(&rc->elems)) {\r\nif (!atomic_read(&fs_info->reada_works_cnt))\r\nreada_start_machine(fs_info);\r\nwait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,\r\n5 * HZ);\r\ndump_devs(fs_info, atomic_read(&rc->elems) < 10 ? 1 : 0);\r\n}\r\ndump_devs(fs_info, atomic_read(&rc->elems) < 10 ? 1 : 0);\r\nkref_put(&rc->refcnt, reada_control_release);\r\nreturn 0;\r\n}\r\nint btrfs_reada_wait(void *handle)\r\n{\r\nstruct reada_control *rc = handle;\r\nstruct btrfs_fs_info *fs_info = rc->fs_info;\r\nwhile (atomic_read(&rc->elems)) {\r\nif (!atomic_read(&fs_info->reada_works_cnt))\r\nreada_start_machine(fs_info);\r\nwait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,\r\n(HZ + 9) / 10);\r\n}\r\nkref_put(&rc->refcnt, reada_control_release);\r\nreturn 0;\r\n}\r\nvoid btrfs_reada_detach(void *handle)\r\n{\r\nstruct reada_control *rc = handle;\r\nkref_put(&rc->refcnt, reada_control_release);\r\n}
