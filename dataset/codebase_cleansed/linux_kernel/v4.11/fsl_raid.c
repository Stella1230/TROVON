static dma_cookie_t fsl_re_tx_submit(struct dma_async_tx_descriptor *tx)\r\n{\r\nstruct fsl_re_desc *desc;\r\nstruct fsl_re_chan *re_chan;\r\ndma_cookie_t cookie;\r\nunsigned long flags;\r\ndesc = to_fsl_re_dma_desc(tx);\r\nre_chan = container_of(tx->chan, struct fsl_re_chan, chan);\r\nspin_lock_irqsave(&re_chan->desc_lock, flags);\r\ncookie = dma_cookie_assign(tx);\r\nlist_add_tail(&desc->node, &re_chan->submit_q);\r\nspin_unlock_irqrestore(&re_chan->desc_lock, flags);\r\nreturn cookie;\r\n}\r\nstatic void fsl_re_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nint avail;\r\nstruct fsl_re_desc *desc, *_desc;\r\nunsigned long flags;\r\nre_chan = container_of(chan, struct fsl_re_chan, chan);\r\nspin_lock_irqsave(&re_chan->desc_lock, flags);\r\navail = FSL_RE_SLOT_AVAIL(\r\nin_be32(&re_chan->jrregs->inbring_slot_avail));\r\nlist_for_each_entry_safe(desc, _desc, &re_chan->submit_q, node) {\r\nif (!avail)\r\nbreak;\r\nlist_move_tail(&desc->node, &re_chan->active_q);\r\nmemcpy(&re_chan->inb_ring_virt_addr[re_chan->inb_count],\r\n&desc->hwdesc, sizeof(struct fsl_re_hw_desc));\r\nre_chan->inb_count = (re_chan->inb_count + 1) &\r\nFSL_RE_RING_SIZE_MASK;\r\nout_be32(&re_chan->jrregs->inbring_add_job, FSL_RE_ADD_JOB(1));\r\navail--;\r\n}\r\nspin_unlock_irqrestore(&re_chan->desc_lock, flags);\r\n}\r\nstatic void fsl_re_desc_done(struct fsl_re_desc *desc)\r\n{\r\ndma_cookie_complete(&desc->async_tx);\r\ndma_descriptor_unmap(&desc->async_tx);\r\ndmaengine_desc_get_callback_invoke(&desc->async_tx, NULL);\r\n}\r\nstatic void fsl_re_cleanup_descs(struct fsl_re_chan *re_chan)\r\n{\r\nstruct fsl_re_desc *desc, *_desc;\r\nunsigned long flags;\r\nspin_lock_irqsave(&re_chan->desc_lock, flags);\r\nlist_for_each_entry_safe(desc, _desc, &re_chan->ack_q, node) {\r\nif (async_tx_test_ack(&desc->async_tx))\r\nlist_move_tail(&desc->node, &re_chan->free_q);\r\n}\r\nspin_unlock_irqrestore(&re_chan->desc_lock, flags);\r\nfsl_re_issue_pending(&re_chan->chan);\r\n}\r\nstatic void fsl_re_dequeue(unsigned long data)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nstruct fsl_re_desc *desc, *_desc;\r\nstruct fsl_re_hw_desc *hwdesc;\r\nunsigned long flags;\r\nunsigned int count, oub_count;\r\nint found;\r\nre_chan = dev_get_drvdata((struct device *)data);\r\nfsl_re_cleanup_descs(re_chan);\r\nspin_lock_irqsave(&re_chan->desc_lock, flags);\r\ncount = FSL_RE_SLOT_FULL(in_be32(&re_chan->jrregs->oubring_slot_full));\r\nwhile (count--) {\r\nfound = 0;\r\nhwdesc = &re_chan->oub_ring_virt_addr[re_chan->oub_count];\r\nlist_for_each_entry_safe(desc, _desc, &re_chan->active_q,\r\nnode) {\r\nif (desc->hwdesc.lbea32 == hwdesc->lbea32 &&\r\ndesc->hwdesc.addr_low == hwdesc->addr_low) {\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (found) {\r\nfsl_re_desc_done(desc);\r\nlist_move_tail(&desc->node, &re_chan->ack_q);\r\n} else {\r\ndev_err(re_chan->dev,\r\n"found hwdesc not in sw queue, discard it\n");\r\n}\r\noub_count = (re_chan->oub_count + 1) & FSL_RE_RING_SIZE_MASK;\r\nre_chan->oub_count = oub_count;\r\nout_be32(&re_chan->jrregs->oubring_job_rmvd,\r\nFSL_RE_RMVD_JOB(1));\r\n}\r\nspin_unlock_irqrestore(&re_chan->desc_lock, flags);\r\n}\r\nstatic irqreturn_t fsl_re_isr(int irq, void *data)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nu32 irqstate, status;\r\nre_chan = dev_get_drvdata((struct device *)data);\r\nirqstate = in_be32(&re_chan->jrregs->jr_interrupt_status);\r\nif (!irqstate)\r\nreturn IRQ_NONE;\r\nif (irqstate & FSL_RE_ERROR) {\r\nstatus = in_be32(&re_chan->jrregs->jr_status);\r\ndev_err(re_chan->dev, "chan error irqstate: %x, status: %x\n",\r\nirqstate, status);\r\n}\r\nout_be32(&re_chan->jrregs->jr_interrupt_status, FSL_RE_CLR_INTR);\r\ntasklet_schedule(&re_chan->irqtask);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic enum dma_status fsl_re_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie,\r\nstruct dma_tx_state *txstate)\r\n{\r\nreturn dma_cookie_status(chan, cookie, txstate);\r\n}\r\nstatic void fill_cfd_frame(struct fsl_re_cmpnd_frame *cf, u8 index,\r\nsize_t length, dma_addr_t addr, bool final)\r\n{\r\nu32 efrl = length & FSL_RE_CF_LENGTH_MASK;\r\nefrl |= final << FSL_RE_CF_FINAL_SHIFT;\r\ncf[index].efrl32 = efrl;\r\ncf[index].addr_high = upper_32_bits(addr);\r\ncf[index].addr_low = lower_32_bits(addr);\r\n}\r\nstatic struct fsl_re_desc *fsl_re_init_desc(struct fsl_re_chan *re_chan,\r\nstruct fsl_re_desc *desc,\r\nvoid *cf, dma_addr_t paddr)\r\n{\r\ndesc->re_chan = re_chan;\r\ndesc->async_tx.tx_submit = fsl_re_tx_submit;\r\ndma_async_tx_descriptor_init(&desc->async_tx, &re_chan->chan);\r\nINIT_LIST_HEAD(&desc->node);\r\ndesc->hwdesc.fmt32 = FSL_RE_FRAME_FORMAT << FSL_RE_HWDESC_FMT_SHIFT;\r\ndesc->hwdesc.lbea32 = upper_32_bits(paddr);\r\ndesc->hwdesc.addr_low = lower_32_bits(paddr);\r\ndesc->cf_addr = cf;\r\ndesc->cf_paddr = paddr;\r\ndesc->cdb_addr = (void *)(cf + FSL_RE_CF_DESC_SIZE);\r\ndesc->cdb_paddr = paddr + FSL_RE_CF_DESC_SIZE;\r\nreturn desc;\r\n}\r\nstatic struct fsl_re_desc *fsl_re_chan_alloc_desc(struct fsl_re_chan *re_chan,\r\nunsigned long flags)\r\n{\r\nstruct fsl_re_desc *desc = NULL;\r\nvoid *cf;\r\ndma_addr_t paddr;\r\nunsigned long lock_flag;\r\nfsl_re_cleanup_descs(re_chan);\r\nspin_lock_irqsave(&re_chan->desc_lock, lock_flag);\r\nif (!list_empty(&re_chan->free_q)) {\r\ndesc = list_first_entry(&re_chan->free_q,\r\nstruct fsl_re_desc, node);\r\nlist_del(&desc->node);\r\ndesc->async_tx.flags = flags;\r\n}\r\nspin_unlock_irqrestore(&re_chan->desc_lock, lock_flag);\r\nif (!desc) {\r\ndesc = kzalloc(sizeof(*desc), GFP_NOWAIT);\r\nif (!desc)\r\nreturn NULL;\r\ncf = dma_pool_alloc(re_chan->re_dev->cf_desc_pool, GFP_NOWAIT,\r\n&paddr);\r\nif (!cf) {\r\nkfree(desc);\r\nreturn NULL;\r\n}\r\ndesc = fsl_re_init_desc(re_chan, desc, cf, paddr);\r\ndesc->async_tx.flags = flags;\r\nspin_lock_irqsave(&re_chan->desc_lock, lock_flag);\r\nre_chan->alloc_count++;\r\nspin_unlock_irqrestore(&re_chan->desc_lock, lock_flag);\r\n}\r\nreturn desc;\r\n}\r\nstatic struct dma_async_tx_descriptor *fsl_re_prep_dma_genq(\r\nstruct dma_chan *chan, dma_addr_t dest, dma_addr_t *src,\r\nunsigned int src_cnt, const unsigned char *scf, size_t len,\r\nunsigned long flags)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nstruct fsl_re_desc *desc;\r\nstruct fsl_re_xor_cdb *xor;\r\nstruct fsl_re_cmpnd_frame *cf;\r\nu32 cdb;\r\nunsigned int i, j;\r\nunsigned int save_src_cnt = src_cnt;\r\nint cont_q = 0;\r\nre_chan = container_of(chan, struct fsl_re_chan, chan);\r\nif (len > FSL_RE_MAX_DATA_LEN) {\r\ndev_err(re_chan->dev, "genq tx length %zu, max length %d\n",\r\nlen, FSL_RE_MAX_DATA_LEN);\r\nreturn NULL;\r\n}\r\ndesc = fsl_re_chan_alloc_desc(re_chan, flags);\r\nif (desc <= 0)\r\nreturn NULL;\r\nif (scf && (flags & DMA_PREP_CONTINUE)) {\r\ncont_q = 1;\r\nsrc_cnt += 1;\r\n}\r\ncdb = FSL_RE_XOR_OPCODE << FSL_RE_CDB_OPCODE_SHIFT;\r\ncdb |= (src_cnt - 1) << FSL_RE_CDB_NRCS_SHIFT;\r\ncdb |= FSL_RE_BLOCK_SIZE << FSL_RE_CDB_BLKSIZE_SHIFT;\r\ncdb |= FSL_RE_INTR_ON_ERROR << FSL_RE_CDB_ERROR_SHIFT;\r\ncdb |= FSL_RE_DATA_DEP << FSL_RE_CDB_DEPEND_SHIFT;\r\nxor = desc->cdb_addr;\r\nxor->cdb32 = cdb;\r\nif (scf) {\r\nfor (i = 0; i < save_src_cnt; i++)\r\nxor->gfm[i] = scf[i];\r\nif (cont_q)\r\nxor->gfm[i++] = 1;\r\n} else {\r\nfor (i = 0; i < src_cnt; i++)\r\nxor->gfm[i] = 1;\r\n}\r\ncf = desc->cf_addr;\r\nfill_cfd_frame(cf, 0, sizeof(*xor), desc->cdb_paddr, 0);\r\nfill_cfd_frame(cf, 1, len, dest, 0);\r\nfor (i = 2, j = 0; j < save_src_cnt; i++, j++)\r\nfill_cfd_frame(cf, i, len, src[j], 0);\r\nif (cont_q)\r\nfill_cfd_frame(cf, i++, len, dest, 0);\r\ncf[i - 1].efrl32 |= 1 << FSL_RE_CF_FINAL_SHIFT;\r\nreturn &desc->async_tx;\r\n}\r\nstatic struct dma_async_tx_descriptor *fsl_re_prep_dma_xor(\r\nstruct dma_chan *chan, dma_addr_t dest, dma_addr_t *src,\r\nunsigned int src_cnt, size_t len, unsigned long flags)\r\n{\r\nreturn fsl_re_prep_dma_genq(chan, dest, src, src_cnt, NULL, len, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *fsl_re_prep_dma_pq(\r\nstruct dma_chan *chan, dma_addr_t *dest, dma_addr_t *src,\r\nunsigned int src_cnt, const unsigned char *scf, size_t len,\r\nunsigned long flags)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nstruct fsl_re_desc *desc;\r\nstruct fsl_re_pq_cdb *pq;\r\nstruct fsl_re_cmpnd_frame *cf;\r\nu32 cdb;\r\nu8 *p;\r\nint gfmq_len, i, j;\r\nunsigned int save_src_cnt = src_cnt;\r\nre_chan = container_of(chan, struct fsl_re_chan, chan);\r\nif (len > FSL_RE_MAX_DATA_LEN) {\r\ndev_err(re_chan->dev, "pq tx length is %zu, max length is %d\n",\r\nlen, FSL_RE_MAX_DATA_LEN);\r\nreturn NULL;\r\n}\r\nif (src_cnt == 1) {\r\nstruct dma_async_tx_descriptor *tx;\r\ndma_addr_t dma_src[2];\r\nunsigned char coef[2];\r\ndma_src[0] = *src;\r\ncoef[0] = *scf;\r\ndma_src[1] = *src;\r\ncoef[1] = 0;\r\ntx = fsl_re_prep_dma_genq(chan, dest[1], dma_src, 2, coef, len,\r\nflags);\r\nif (tx)\r\ndesc = to_fsl_re_dma_desc(tx);\r\nreturn tx;\r\n}\r\nif (flags & DMA_PREP_PQ_DISABLE_P)\r\nreturn fsl_re_prep_dma_genq(chan, dest[1], src, src_cnt,\r\nscf, len, flags);\r\nif (flags & DMA_PREP_CONTINUE)\r\nsrc_cnt += 3;\r\ndesc = fsl_re_chan_alloc_desc(re_chan, flags);\r\nif (desc <= 0)\r\nreturn NULL;\r\ncdb = FSL_RE_PQ_OPCODE << FSL_RE_CDB_OPCODE_SHIFT;\r\ncdb |= (src_cnt - 1) << FSL_RE_CDB_NRCS_SHIFT;\r\ncdb |= FSL_RE_BLOCK_SIZE << FSL_RE_CDB_BLKSIZE_SHIFT;\r\ncdb |= FSL_RE_BUFFER_OUTPUT << FSL_RE_CDB_BUFFER_SHIFT;\r\ncdb |= FSL_RE_DATA_DEP << FSL_RE_CDB_DEPEND_SHIFT;\r\npq = desc->cdb_addr;\r\npq->cdb32 = cdb;\r\np = pq->gfm_q1;\r\nfor (i = 0; i < src_cnt; i++)\r\np[i] = 1;\r\ngfmq_len = ALIGN(src_cnt, 4);\r\np += gfmq_len;\r\nfor (i = 0; i < src_cnt; i++)\r\np[i] = scf[i];\r\ncf = desc->cf_addr;\r\nfill_cfd_frame(cf, 0, sizeof(struct fsl_re_pq_cdb), desc->cdb_paddr, 0);\r\nfor (i = 1, j = 0; i < 3; i++, j++)\r\nfill_cfd_frame(cf, i, len, dest[j], 0);\r\nfor (i = 3, j = 0; j < save_src_cnt; i++, j++)\r\nfill_cfd_frame(cf, i, len, src[j], 0);\r\nif (flags & DMA_PREP_CONTINUE) {\r\nif (src_cnt - save_src_cnt == 3) {\r\np[save_src_cnt] = 0;\r\np[save_src_cnt + 1] = 0;\r\np[save_src_cnt + 2] = 1;\r\nfill_cfd_frame(cf, i++, len, dest[0], 0);\r\nfill_cfd_frame(cf, i++, len, dest[1], 0);\r\nfill_cfd_frame(cf, i++, len, dest[1], 0);\r\n} else {\r\ndev_err(re_chan->dev, "PQ tx continuation error!\n");\r\nreturn NULL;\r\n}\r\n}\r\ncf[i - 1].efrl32 |= 1 << FSL_RE_CF_FINAL_SHIFT;\r\nreturn &desc->async_tx;\r\n}\r\nstatic struct dma_async_tx_descriptor *fsl_re_prep_dma_memcpy(\r\nstruct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\r\nsize_t len, unsigned long flags)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nstruct fsl_re_desc *desc;\r\nsize_t length;\r\nstruct fsl_re_cmpnd_frame *cf;\r\nstruct fsl_re_move_cdb *move;\r\nu32 cdb;\r\nre_chan = container_of(chan, struct fsl_re_chan, chan);\r\nif (len > FSL_RE_MAX_DATA_LEN) {\r\ndev_err(re_chan->dev, "cp tx length is %zu, max length is %d\n",\r\nlen, FSL_RE_MAX_DATA_LEN);\r\nreturn NULL;\r\n}\r\ndesc = fsl_re_chan_alloc_desc(re_chan, flags);\r\nif (desc <= 0)\r\nreturn NULL;\r\ncdb = FSL_RE_MOVE_OPCODE << FSL_RE_CDB_OPCODE_SHIFT;\r\ncdb |= FSL_RE_BLOCK_SIZE << FSL_RE_CDB_BLKSIZE_SHIFT;\r\ncdb |= FSL_RE_INTR_ON_ERROR << FSL_RE_CDB_ERROR_SHIFT;\r\ncdb |= FSL_RE_DATA_DEP << FSL_RE_CDB_DEPEND_SHIFT;\r\nmove = desc->cdb_addr;\r\nmove->cdb32 = cdb;\r\ncf = desc->cf_addr;\r\nfill_cfd_frame(cf, 0, sizeof(*move), desc->cdb_paddr, 0);\r\nlength = min_t(size_t, len, FSL_RE_MAX_DATA_LEN);\r\nfill_cfd_frame(cf, 1, length, dest, 0);\r\nfill_cfd_frame(cf, 2, length, src, 1);\r\nreturn &desc->async_tx;\r\n}\r\nstatic int fsl_re_alloc_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nstruct fsl_re_desc *desc;\r\nvoid *cf;\r\ndma_addr_t paddr;\r\nint i;\r\nre_chan = container_of(chan, struct fsl_re_chan, chan);\r\nfor (i = 0; i < FSL_RE_MIN_DESCS; i++) {\r\ndesc = kzalloc(sizeof(*desc), GFP_KERNEL);\r\nif (!desc)\r\nbreak;\r\ncf = dma_pool_alloc(re_chan->re_dev->cf_desc_pool, GFP_KERNEL,\r\n&paddr);\r\nif (!cf) {\r\nkfree(desc);\r\nbreak;\r\n}\r\nINIT_LIST_HEAD(&desc->node);\r\nfsl_re_init_desc(re_chan, desc, cf, paddr);\r\nlist_add_tail(&desc->node, &re_chan->free_q);\r\nre_chan->alloc_count++;\r\n}\r\nreturn re_chan->alloc_count;\r\n}\r\nstatic void fsl_re_free_chan_resources(struct dma_chan *chan)\r\n{\r\nstruct fsl_re_chan *re_chan;\r\nstruct fsl_re_desc *desc;\r\nre_chan = container_of(chan, struct fsl_re_chan, chan);\r\nwhile (re_chan->alloc_count--) {\r\ndesc = list_first_entry(&re_chan->free_q,\r\nstruct fsl_re_desc,\r\nnode);\r\nlist_del(&desc->node);\r\ndma_pool_free(re_chan->re_dev->cf_desc_pool, desc->cf_addr,\r\ndesc->cf_paddr);\r\nkfree(desc);\r\n}\r\nif (!list_empty(&re_chan->free_q))\r\ndev_err(re_chan->dev, "chan resource cannot be cleaned!\n");\r\n}\r\nstatic int fsl_re_chan_probe(struct platform_device *ofdev,\r\nstruct device_node *np, u8 q, u32 off)\r\n{\r\nstruct device *dev, *chandev;\r\nstruct fsl_re_drv_private *re_priv;\r\nstruct fsl_re_chan *chan;\r\nstruct dma_device *dma_dev;\r\nu32 ptr;\r\nu32 status;\r\nint ret = 0, rc;\r\nstruct platform_device *chan_ofdev;\r\ndev = &ofdev->dev;\r\nre_priv = dev_get_drvdata(dev);\r\ndma_dev = &re_priv->dma_dev;\r\nchan = devm_kzalloc(dev, sizeof(*chan), GFP_KERNEL);\r\nif (!chan)\r\nreturn -ENOMEM;\r\nchan_ofdev = of_platform_device_create(np, NULL, dev);\r\nif (!chan_ofdev) {\r\ndev_err(dev, "Not able to create ofdev for jr %d\n", q);\r\nret = -EINVAL;\r\ngoto err_free;\r\n}\r\nrc = of_property_read_u32(np, "reg", &ptr);\r\nif (rc) {\r\ndev_err(dev, "Reg property not found in jr %d\n", q);\r\nret = -ENODEV;\r\ngoto err_free;\r\n}\r\nchan->jrregs = (struct fsl_re_chan_cfg *)((u8 *)re_priv->re_regs +\r\noff + ptr);\r\nchan->irq = irq_of_parse_and_map(np, 0);\r\nif (!chan->irq) {\r\ndev_err(dev, "No IRQ defined for JR %d\n", q);\r\nret = -ENODEV;\r\ngoto err_free;\r\n}\r\nsnprintf(chan->name, sizeof(chan->name), "re_jr%02d", q);\r\nchandev = &chan_ofdev->dev;\r\ntasklet_init(&chan->irqtask, fsl_re_dequeue, (unsigned long)chandev);\r\nret = request_irq(chan->irq, fsl_re_isr, 0, chan->name, chandev);\r\nif (ret) {\r\ndev_err(dev, "Unable to register interrupt for JR %d\n", q);\r\nret = -EINVAL;\r\ngoto err_free;\r\n}\r\nre_priv->re_jrs[q] = chan;\r\nchan->chan.device = dma_dev;\r\nchan->chan.private = chan;\r\nchan->dev = chandev;\r\nchan->re_dev = re_priv;\r\nspin_lock_init(&chan->desc_lock);\r\nINIT_LIST_HEAD(&chan->ack_q);\r\nINIT_LIST_HEAD(&chan->active_q);\r\nINIT_LIST_HEAD(&chan->submit_q);\r\nINIT_LIST_HEAD(&chan->free_q);\r\nchan->inb_ring_virt_addr = dma_pool_alloc(chan->re_dev->hw_desc_pool,\r\nGFP_KERNEL, &chan->inb_phys_addr);\r\nif (!chan->inb_ring_virt_addr) {\r\ndev_err(dev, "No dma memory for inb_ring_virt_addr\n");\r\nret = -ENOMEM;\r\ngoto err_free;\r\n}\r\nchan->oub_ring_virt_addr = dma_pool_alloc(chan->re_dev->hw_desc_pool,\r\nGFP_KERNEL, &chan->oub_phys_addr);\r\nif (!chan->oub_ring_virt_addr) {\r\ndev_err(dev, "No dma memory for oub_ring_virt_addr\n");\r\nret = -ENOMEM;\r\ngoto err_free_1;\r\n}\r\nout_be32(&chan->jrregs->inbring_base_h,\r\nchan->inb_phys_addr & FSL_RE_ADDR_BIT_MASK);\r\nout_be32(&chan->jrregs->oubring_base_h,\r\nchan->oub_phys_addr & FSL_RE_ADDR_BIT_MASK);\r\nout_be32(&chan->jrregs->inbring_base_l,\r\nchan->inb_phys_addr >> FSL_RE_ADDR_BIT_SHIFT);\r\nout_be32(&chan->jrregs->oubring_base_l,\r\nchan->oub_phys_addr >> FSL_RE_ADDR_BIT_SHIFT);\r\nout_be32(&chan->jrregs->inbring_size,\r\nFSL_RE_RING_SIZE << FSL_RE_RING_SIZE_SHIFT);\r\nout_be32(&chan->jrregs->oubring_size,\r\nFSL_RE_RING_SIZE << FSL_RE_RING_SIZE_SHIFT);\r\nstatus = in_be32(&chan->jrregs->jr_config_1) & FSL_RE_REG_LIODN_MASK;\r\nout_be32(&chan->jrregs->jr_config_1,\r\nFSL_RE_CFG1_CBSI | FSL_RE_CFG1_CBS0 | status);\r\ndev_set_drvdata(chandev, chan);\r\nout_be32(&chan->jrregs->jr_command, FSL_RE_ENABLE);\r\nreturn 0;\r\nerr_free_1:\r\ndma_pool_free(chan->re_dev->hw_desc_pool, chan->inb_ring_virt_addr,\r\nchan->inb_phys_addr);\r\nerr_free:\r\nreturn ret;\r\n}\r\nstatic int fsl_re_probe(struct platform_device *ofdev)\r\n{\r\nstruct fsl_re_drv_private *re_priv;\r\nstruct device_node *np;\r\nstruct device_node *child;\r\nu32 off;\r\nu8 ridx = 0;\r\nstruct dma_device *dma_dev;\r\nstruct resource *res;\r\nint rc;\r\nstruct device *dev = &ofdev->dev;\r\nre_priv = devm_kzalloc(dev, sizeof(*re_priv), GFP_KERNEL);\r\nif (!re_priv)\r\nreturn -ENOMEM;\r\nres = platform_get_resource(ofdev, IORESOURCE_MEM, 0);\r\nif (!res)\r\nreturn -ENODEV;\r\nre_priv->re_regs = devm_ioremap(dev, res->start, resource_size(res));\r\nif (!re_priv->re_regs)\r\nreturn -EBUSY;\r\nout_be32(&re_priv->re_regs->global_config, FSL_RE_NON_DPAA_MODE);\r\nout_be32(&re_priv->re_regs->galois_field_config, FSL_RE_GFM_POLY);\r\ndev_info(dev, "version %x, mode %x, gfp %x\n",\r\nin_be32(&re_priv->re_regs->re_version_id),\r\nin_be32(&re_priv->re_regs->global_config),\r\nin_be32(&re_priv->re_regs->galois_field_config));\r\ndma_dev = &re_priv->dma_dev;\r\ndma_dev->dev = dev;\r\nINIT_LIST_HEAD(&dma_dev->channels);\r\ndma_set_mask(dev, DMA_BIT_MASK(40));\r\ndma_dev->device_alloc_chan_resources = fsl_re_alloc_chan_resources;\r\ndma_dev->device_tx_status = fsl_re_tx_status;\r\ndma_dev->device_issue_pending = fsl_re_issue_pending;\r\ndma_dev->max_xor = FSL_RE_MAX_XOR_SRCS;\r\ndma_dev->device_prep_dma_xor = fsl_re_prep_dma_xor;\r\ndma_cap_set(DMA_XOR, dma_dev->cap_mask);\r\ndma_dev->max_pq = FSL_RE_MAX_PQ_SRCS;\r\ndma_dev->device_prep_dma_pq = fsl_re_prep_dma_pq;\r\ndma_cap_set(DMA_PQ, dma_dev->cap_mask);\r\ndma_dev->device_prep_dma_memcpy = fsl_re_prep_dma_memcpy;\r\ndma_cap_set(DMA_MEMCPY, dma_dev->cap_mask);\r\ndma_dev->device_free_chan_resources = fsl_re_free_chan_resources;\r\nre_priv->total_chans = 0;\r\nre_priv->cf_desc_pool = dmam_pool_create("fsl_re_cf_desc_pool", dev,\r\nFSL_RE_CF_CDB_SIZE,\r\nFSL_RE_CF_CDB_ALIGN, 0);\r\nif (!re_priv->cf_desc_pool) {\r\ndev_err(dev, "No memory for fsl re_cf desc pool\n");\r\nreturn -ENOMEM;\r\n}\r\nre_priv->hw_desc_pool = dmam_pool_create("fsl_re_hw_desc_pool", dev,\r\nsizeof(struct fsl_re_hw_desc) * FSL_RE_RING_SIZE,\r\nFSL_RE_FRAME_ALIGN, 0);\r\nif (!re_priv->hw_desc_pool) {\r\ndev_err(dev, "No memory for fsl re_hw desc pool\n");\r\nreturn -ENOMEM;\r\n}\r\ndev_set_drvdata(dev, re_priv);\r\nfor_each_compatible_node(np, NULL, "fsl,raideng-v1.0-job-queue") {\r\nrc = of_property_read_u32(np, "reg", &off);\r\nif (rc) {\r\ndev_err(dev, "Reg property not found in JQ node\n");\r\nof_node_put(np);\r\nreturn -ENODEV;\r\n}\r\nfor_each_child_of_node(np, child) {\r\nrc = of_device_is_compatible(child,\r\n"fsl,raideng-v1.0-job-ring");\r\nif (rc) {\r\nfsl_re_chan_probe(ofdev, child, ridx++, off);\r\nre_priv->total_chans++;\r\n}\r\n}\r\n}\r\ndma_async_device_register(dma_dev);\r\nreturn 0;\r\n}\r\nstatic void fsl_re_remove_chan(struct fsl_re_chan *chan)\r\n{\r\ntasklet_kill(&chan->irqtask);\r\ndma_pool_free(chan->re_dev->hw_desc_pool, chan->inb_ring_virt_addr,\r\nchan->inb_phys_addr);\r\ndma_pool_free(chan->re_dev->hw_desc_pool, chan->oub_ring_virt_addr,\r\nchan->oub_phys_addr);\r\n}\r\nstatic int fsl_re_remove(struct platform_device *ofdev)\r\n{\r\nstruct fsl_re_drv_private *re_priv;\r\nstruct device *dev;\r\nint i;\r\ndev = &ofdev->dev;\r\nre_priv = dev_get_drvdata(dev);\r\nfor (i = 0; i < re_priv->total_chans; i++)\r\nfsl_re_remove_chan(re_priv->re_jrs[i]);\r\ndma_async_device_unregister(&re_priv->dma_dev);\r\nreturn 0;\r\n}
