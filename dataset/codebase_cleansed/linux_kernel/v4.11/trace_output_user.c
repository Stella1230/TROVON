static int perf_event_mmap(int fd)\r\n{\r\nvoid *base;\r\nint mmap_size;\r\npage_size = getpagesize();\r\nmmap_size = page_size * (page_cnt + 1);\r\nbase = mmap(NULL, mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\r\nif (base == MAP_FAILED) {\r\nprintf("mmap err\n");\r\nreturn -1;\r\n}\r\nheader = base;\r\nreturn 0;\r\n}\r\nstatic int perf_event_poll(int fd)\r\n{\r\nstruct pollfd pfd = { .fd = fd, .events = POLLIN };\r\nreturn poll(&pfd, 1, 1000);\r\n}\r\nstatic void perf_event_read(print_fn fn)\r\n{\r\n__u64 data_tail = header->data_tail;\r\n__u64 data_head = header->data_head;\r\n__u64 buffer_size = page_cnt * page_size;\r\nvoid *base, *begin, *end;\r\nchar buf[256];\r\nasm volatile("" ::: "memory");\r\nif (data_head == data_tail)\r\nreturn;\r\nbase = ((char *)header) + page_size;\r\nbegin = base + data_tail % buffer_size;\r\nend = base + data_head % buffer_size;\r\nwhile (begin != end) {\r\nstruct perf_event_sample *e;\r\ne = begin;\r\nif (begin + e->header.size > base + buffer_size) {\r\nlong len = base + buffer_size - begin;\r\nassert(len < e->header.size);\r\nmemcpy(buf, begin, len);\r\nmemcpy(buf + len, base, e->header.size - len);\r\ne = (void *) buf;\r\nbegin = base + e->header.size - len;\r\n} else if (begin + e->header.size == base + buffer_size) {\r\nbegin = base;\r\n} else {\r\nbegin += e->header.size;\r\n}\r\nif (e->header.type == PERF_RECORD_SAMPLE) {\r\nfn(e->data, e->size);\r\n} else if (e->header.type == PERF_RECORD_LOST) {\r\nstruct {\r\nstruct perf_event_header header;\r\n__u64 id;\r\n__u64 lost;\r\n} *lost = (void *) e;\r\nprintf("lost %lld events\n", lost->lost);\r\n} else {\r\nprintf("unknown event type=%d size=%d\n",\r\ne->header.type, e->header.size);\r\n}\r\n}\r\n__sync_synchronize();\r\nheader->data_tail = data_head;\r\n}\r\nstatic __u64 time_get_ns(void)\r\n{\r\nstruct timespec ts;\r\nclock_gettime(CLOCK_MONOTONIC, &ts);\r\nreturn ts.tv_sec * 1000000000ull + ts.tv_nsec;\r\n}\r\nstatic void print_bpf_output(void *data, int size)\r\n{\r\nstatic __u64 cnt;\r\nstruct {\r\n__u64 pid;\r\n__u64 cookie;\r\n} *e = data;\r\nif (e->cookie != 0x12345678) {\r\nprintf("BUG pid %llx cookie %llx sized %d\n",\r\ne->pid, e->cookie, size);\r\nkill(0, SIGINT);\r\n}\r\ncnt++;\r\nif (cnt == MAX_CNT) {\r\nprintf("recv %lld events per sec\n",\r\nMAX_CNT * 1000000000ll / (time_get_ns() - start_time));\r\nkill(0, SIGINT);\r\n}\r\n}\r\nstatic void test_bpf_perf_event(void)\r\n{\r\nstruct perf_event_attr attr = {\r\n.sample_type = PERF_SAMPLE_RAW,\r\n.type = PERF_TYPE_SOFTWARE,\r\n.config = PERF_COUNT_SW_BPF_OUTPUT,\r\n};\r\nint key = 0;\r\npmu_fd = sys_perf_event_open(&attr, -1, 0, -1, 0);\r\nassert(pmu_fd >= 0);\r\nassert(bpf_map_update_elem(map_fd[0], &key, &pmu_fd, BPF_ANY) == 0);\r\nioctl(pmu_fd, PERF_EVENT_IOC_ENABLE, 0);\r\n}\r\nint main(int argc, char **argv)\r\n{\r\nchar filename[256];\r\nFILE *f;\r\nsnprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);\r\nif (load_bpf_file(filename)) {\r\nprintf("%s", bpf_log_buf);\r\nreturn 1;\r\n}\r\ntest_bpf_perf_event();\r\nif (perf_event_mmap(pmu_fd) < 0)\r\nreturn 1;\r\nf = popen("taskset 1 dd if=/dev/zero of=/dev/null", "r");\r\n(void) f;\r\nstart_time = time_get_ns();\r\nfor (;;) {\r\nperf_event_poll(pmu_fd);\r\nperf_event_read(print_bpf_output);\r\n}\r\nreturn 0;\r\n}
