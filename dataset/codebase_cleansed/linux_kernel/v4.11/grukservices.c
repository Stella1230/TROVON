static void gru_load_kernel_context(struct gru_blade_state *bs, int blade_id)\r\n{\r\nstruct gru_state *gru;\r\nstruct gru_thread_state *kgts;\r\nvoid *vaddr;\r\nint ctxnum, ncpus;\r\nup_read(&bs->bs_kgts_sema);\r\ndown_write(&bs->bs_kgts_sema);\r\nif (!bs->bs_kgts) {\r\ndo {\r\nbs->bs_kgts = gru_alloc_gts(NULL, 0, 0, 0, 0, 0);\r\nif (!IS_ERR(bs->bs_kgts))\r\nbreak;\r\nmsleep(1);\r\n} while (true);\r\nbs->bs_kgts->ts_user_blade_id = blade_id;\r\n}\r\nkgts = bs->bs_kgts;\r\nif (!kgts->ts_gru) {\r\nSTAT(load_kernel_context);\r\nncpus = uv_blade_nr_possible_cpus(blade_id);\r\nkgts->ts_cbr_au_count = GRU_CB_COUNT_TO_AU(\r\nGRU_NUM_KERNEL_CBR * ncpus + bs->bs_async_cbrs);\r\nkgts->ts_dsr_au_count = GRU_DS_BYTES_TO_AU(\r\nGRU_NUM_KERNEL_DSR_BYTES * ncpus +\r\nbs->bs_async_dsr_bytes);\r\nwhile (!gru_assign_gru_context(kgts)) {\r\nmsleep(1);\r\ngru_steal_context(kgts);\r\n}\r\ngru_load_context(kgts);\r\ngru = bs->bs_kgts->ts_gru;\r\nvaddr = gru->gs_gru_base_vaddr;\r\nctxnum = kgts->ts_ctxnum;\r\nbs->kernel_cb = get_gseg_base_address_cb(vaddr, ctxnum, 0);\r\nbs->kernel_dsr = get_gseg_base_address_ds(vaddr, ctxnum, 0);\r\n}\r\ndowngrade_write(&bs->bs_kgts_sema);\r\n}\r\nstatic int gru_free_kernel_contexts(void)\r\n{\r\nstruct gru_blade_state *bs;\r\nstruct gru_thread_state *kgts;\r\nint bid, ret = 0;\r\nfor (bid = 0; bid < GRU_MAX_BLADES; bid++) {\r\nbs = gru_base[bid];\r\nif (!bs)\r\ncontinue;\r\nif (down_write_trylock(&bs->bs_kgts_sema)) {\r\nkgts = bs->bs_kgts;\r\nif (kgts && kgts->ts_gru)\r\ngru_unload_context(kgts, 0);\r\nbs->bs_kgts = NULL;\r\nup_write(&bs->bs_kgts_sema);\r\nkfree(kgts);\r\n} else {\r\nret++;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic struct gru_blade_state *gru_lock_kernel_context(int blade_id)\r\n{\r\nstruct gru_blade_state *bs;\r\nint bid;\r\nSTAT(lock_kernel_context);\r\nagain:\r\nbid = blade_id < 0 ? uv_numa_blade_id() : blade_id;\r\nbs = gru_base[bid];\r\ndown_read(&bs->bs_kgts_sema);\r\nif (blade_id < 0 && bid != uv_numa_blade_id()) {\r\nup_read(&bs->bs_kgts_sema);\r\ngoto again;\r\n}\r\nif (!bs->bs_kgts || !bs->bs_kgts->ts_gru)\r\ngru_load_kernel_context(bs, bid);\r\nreturn bs;\r\n}\r\nstatic void gru_unlock_kernel_context(int blade_id)\r\n{\r\nstruct gru_blade_state *bs;\r\nbs = gru_base[blade_id];\r\nup_read(&bs->bs_kgts_sema);\r\nSTAT(unlock_kernel_context);\r\n}\r\nstatic int gru_get_cpu_resources(int dsr_bytes, void **cb, void **dsr)\r\n{\r\nstruct gru_blade_state *bs;\r\nint lcpu;\r\nBUG_ON(dsr_bytes > GRU_NUM_KERNEL_DSR_BYTES);\r\npreempt_disable();\r\nbs = gru_lock_kernel_context(-1);\r\nlcpu = uv_blade_processor_id();\r\n*cb = bs->kernel_cb + lcpu * GRU_HANDLE_STRIDE;\r\n*dsr = bs->kernel_dsr + lcpu * GRU_NUM_KERNEL_DSR_BYTES;\r\nreturn 0;\r\n}\r\nstatic void gru_free_cpu_resources(void *cb, void *dsr)\r\n{\r\ngru_unlock_kernel_context(uv_numa_blade_id());\r\npreempt_enable();\r\n}\r\nunsigned long gru_reserve_async_resources(int blade_id, int cbrs, int dsr_bytes,\r\nstruct completion *cmp)\r\n{\r\nstruct gru_blade_state *bs;\r\nstruct gru_thread_state *kgts;\r\nint ret = 0;\r\nbs = gru_base[blade_id];\r\ndown_write(&bs->bs_kgts_sema);\r\nif (bs->bs_async_dsr_bytes + bs->bs_async_cbrs)\r\ngoto done;\r\nbs->bs_async_dsr_bytes = dsr_bytes;\r\nbs->bs_async_cbrs = cbrs;\r\nbs->bs_async_wq = cmp;\r\nkgts = bs->bs_kgts;\r\nif (kgts && kgts->ts_gru)\r\ngru_unload_context(kgts, 0);\r\nret = ASYNC_BID_TO_HAN(blade_id);\r\ndone:\r\nup_write(&bs->bs_kgts_sema);\r\nreturn ret;\r\n}\r\nvoid gru_release_async_resources(unsigned long han)\r\n{\r\nstruct gru_blade_state *bs = ASYNC_HAN_TO_BS(han);\r\ndown_write(&bs->bs_kgts_sema);\r\nbs->bs_async_dsr_bytes = 0;\r\nbs->bs_async_cbrs = 0;\r\nbs->bs_async_wq = NULL;\r\nup_write(&bs->bs_kgts_sema);\r\n}\r\nvoid gru_wait_async_cbr(unsigned long han)\r\n{\r\nstruct gru_blade_state *bs = ASYNC_HAN_TO_BS(han);\r\nwait_for_completion(bs->bs_async_wq);\r\nmb();\r\n}\r\nvoid gru_lock_async_resource(unsigned long han, void **cb, void **dsr)\r\n{\r\nstruct gru_blade_state *bs = ASYNC_HAN_TO_BS(han);\r\nint blade_id = ASYNC_HAN_TO_BID(han);\r\nint ncpus;\r\ngru_lock_kernel_context(blade_id);\r\nncpus = uv_blade_nr_possible_cpus(blade_id);\r\nif (cb)\r\n*cb = bs->kernel_cb + ncpus * GRU_HANDLE_STRIDE;\r\nif (dsr)\r\n*dsr = bs->kernel_dsr + ncpus * GRU_NUM_KERNEL_DSR_BYTES;\r\n}\r\nvoid gru_unlock_async_resource(unsigned long han)\r\n{\r\nint blade_id = ASYNC_HAN_TO_BID(han);\r\ngru_unlock_kernel_context(blade_id);\r\n}\r\nint gru_get_cb_exception_detail(void *cb,\r\nstruct control_block_extended_exc_detail *excdet)\r\n{\r\nstruct gru_control_block_extended *cbe;\r\nstruct gru_thread_state *kgts = NULL;\r\nunsigned long off;\r\nint cbrnum, bid;\r\nfor_each_possible_blade(bid) {\r\nif (!gru_base[bid])\r\nbreak;\r\nkgts = gru_base[bid]->bs_kgts;\r\nif (!kgts || !kgts->ts_gru)\r\ncontinue;\r\noff = cb - kgts->ts_gru->gs_gru_base_vaddr;\r\nif (off < GRU_SIZE)\r\nbreak;\r\nkgts = NULL;\r\n}\r\nBUG_ON(!kgts);\r\ncbrnum = thread_cbr_number(kgts, get_cb_number(cb));\r\ncbe = get_cbe(GRUBASE(cb), cbrnum);\r\ngru_flush_cache(cbe);\r\nsync_core();\r\nexcdet->opc = cbe->opccpy;\r\nexcdet->exopc = cbe->exopccpy;\r\nexcdet->ecause = cbe->ecause;\r\nexcdet->exceptdet0 = cbe->idef1upd;\r\nexcdet->exceptdet1 = cbe->idef3upd;\r\ngru_flush_cache(cbe);\r\nreturn 0;\r\n}\r\nstatic char *gru_get_cb_exception_detail_str(int ret, void *cb,\r\nchar *buf, int size)\r\n{\r\nstruct gru_control_block_status *gen = (void *)cb;\r\nstruct control_block_extended_exc_detail excdet;\r\nif (ret > 0 && gen->istatus == CBS_EXCEPTION) {\r\ngru_get_cb_exception_detail(cb, &excdet);\r\nsnprintf(buf, size,\r\n"GRU:%d exception: cb %p, opc %d, exopc %d, ecause 0x%x,"\r\n"excdet0 0x%lx, excdet1 0x%x", smp_processor_id(),\r\ngen, excdet.opc, excdet.exopc, excdet.ecause,\r\nexcdet.exceptdet0, excdet.exceptdet1);\r\n} else {\r\nsnprintf(buf, size, "No exception");\r\n}\r\nreturn buf;\r\n}\r\nstatic int gru_wait_idle_or_exception(struct gru_control_block_status *gen)\r\n{\r\nwhile (gen->istatus >= CBS_ACTIVE) {\r\ncpu_relax();\r\nbarrier();\r\n}\r\nreturn gen->istatus;\r\n}\r\nstatic int gru_retry_exception(void *cb)\r\n{\r\nstruct gru_control_block_status *gen = (void *)cb;\r\nstruct control_block_extended_exc_detail excdet;\r\nint retry = EXCEPTION_RETRY_LIMIT;\r\nwhile (1) {\r\nif (gru_wait_idle_or_exception(gen) == CBS_IDLE)\r\nreturn CBS_IDLE;\r\nif (gru_get_cb_message_queue_substatus(cb))\r\nreturn CBS_EXCEPTION;\r\ngru_get_cb_exception_detail(cb, &excdet);\r\nif ((excdet.ecause & ~EXCEPTION_RETRY_BITS) ||\r\n(excdet.cbrexecstatus & CBR_EXS_ABORT_OCC))\r\nbreak;\r\nif (retry-- == 0)\r\nbreak;\r\ngen->icmd = 1;\r\ngru_flush_cache(gen);\r\n}\r\nreturn CBS_EXCEPTION;\r\n}\r\nint gru_check_status_proc(void *cb)\r\n{\r\nstruct gru_control_block_status *gen = (void *)cb;\r\nint ret;\r\nret = gen->istatus;\r\nif (ret == CBS_EXCEPTION)\r\nret = gru_retry_exception(cb);\r\nrmb();\r\nreturn ret;\r\n}\r\nint gru_wait_proc(void *cb)\r\n{\r\nstruct gru_control_block_status *gen = (void *)cb;\r\nint ret;\r\nret = gru_wait_idle_or_exception(gen);\r\nif (ret == CBS_EXCEPTION)\r\nret = gru_retry_exception(cb);\r\nrmb();\r\nreturn ret;\r\n}\r\nstatic void gru_abort(int ret, void *cb, char *str)\r\n{\r\nchar buf[GRU_EXC_STR_SIZE];\r\npanic("GRU FATAL ERROR: %s - %s\n", str,\r\ngru_get_cb_exception_detail_str(ret, cb, buf, sizeof(buf)));\r\n}\r\nvoid gru_wait_abort_proc(void *cb)\r\n{\r\nint ret;\r\nret = gru_wait_proc(cb);\r\nif (ret)\r\ngru_abort(ret, cb, "gru_wait_abort");\r\n}\r\nstatic inline int get_present2(void *p)\r\n{\r\nstruct message_header *mhdr = p + GRU_CACHE_LINE_BYTES;\r\nreturn mhdr->present;\r\n}\r\nstatic inline void restore_present2(void *p, int val)\r\n{\r\nstruct message_header *mhdr = p + GRU_CACHE_LINE_BYTES;\r\nmhdr->present = val;\r\n}\r\nint gru_create_message_queue(struct gru_message_queue_desc *mqd,\r\nvoid *p, unsigned int bytes, int nasid, int vector, int apicid)\r\n{\r\nstruct message_queue *mq = p;\r\nunsigned int qlines;\r\nqlines = bytes / GRU_CACHE_LINE_BYTES - 2;\r\nmemset(mq, 0, bytes);\r\nmq->start = &mq->data;\r\nmq->start2 = &mq->data + (qlines / 2 - 1) * GRU_CACHE_LINE_BYTES;\r\nmq->next = &mq->data;\r\nmq->limit = &mq->data + (qlines - 2) * GRU_CACHE_LINE_BYTES;\r\nmq->qlines = qlines;\r\nmq->hstatus[0] = 0;\r\nmq->hstatus[1] = 1;\r\nmq->head = gru_mesq_head(2, qlines / 2 + 1);\r\nmqd->mq = mq;\r\nmqd->mq_gpa = uv_gpa(mq);\r\nmqd->qlines = qlines;\r\nmqd->interrupt_pnode = nasid >> 1;\r\nmqd->interrupt_vector = vector;\r\nmqd->interrupt_apicid = apicid;\r\nreturn 0;\r\n}\r\nstatic int send_noop_message(void *cb, struct gru_message_queue_desc *mqd,\r\nvoid *mesg)\r\n{\r\nconst struct message_header noop_header = {\r\n.present = MQS_NOOP, .lines = 1};\r\nunsigned long m;\r\nint substatus, ret;\r\nstruct message_header save_mhdr, *mhdr = mesg;\r\nSTAT(mesq_noop);\r\nsave_mhdr = *mhdr;\r\n*mhdr = noop_header;\r\ngru_mesq(cb, mqd->mq_gpa, gru_get_tri(mhdr), 1, IMA);\r\nret = gru_wait(cb);\r\nif (ret) {\r\nsubstatus = gru_get_cb_message_queue_substatus(cb);\r\nswitch (substatus) {\r\ncase CBSS_NO_ERROR:\r\nSTAT(mesq_noop_unexpected_error);\r\nret = MQE_UNEXPECTED_CB_ERR;\r\nbreak;\r\ncase CBSS_LB_OVERFLOWED:\r\nSTAT(mesq_noop_lb_overflow);\r\nret = MQE_CONGESTION;\r\nbreak;\r\ncase CBSS_QLIMIT_REACHED:\r\nSTAT(mesq_noop_qlimit_reached);\r\nret = 0;\r\nbreak;\r\ncase CBSS_AMO_NACKED:\r\nSTAT(mesq_noop_amo_nacked);\r\nret = MQE_CONGESTION;\r\nbreak;\r\ncase CBSS_PUT_NACKED:\r\nSTAT(mesq_noop_put_nacked);\r\nm = mqd->mq_gpa + (gru_get_amo_value_head(cb) << 6);\r\ngru_vstore(cb, m, gru_get_tri(mesg), XTYPE_CL, 1, 1,\r\nIMA);\r\nif (gru_wait(cb) == CBS_IDLE)\r\nret = MQIE_AGAIN;\r\nelse\r\nret = MQE_UNEXPECTED_CB_ERR;\r\nbreak;\r\ncase CBSS_PAGE_OVERFLOW:\r\nSTAT(mesq_noop_page_overflow);\r\ndefault:\r\nBUG();\r\n}\r\n}\r\n*mhdr = save_mhdr;\r\nreturn ret;\r\n}\r\nstatic int send_message_queue_full(void *cb, struct gru_message_queue_desc *mqd,\r\nvoid *mesg, int lines)\r\n{\r\nunion gru_mesqhead mqh;\r\nunsigned int limit, head;\r\nunsigned long avalue;\r\nint half, qlines;\r\navalue = gru_get_amo_value(cb);\r\nhead = gru_get_amo_value_head(cb);\r\nlimit = gru_get_amo_value_limit(cb);\r\nqlines = mqd->qlines;\r\nhalf = (limit != qlines);\r\nif (half)\r\nmqh = gru_mesq_head(qlines / 2 + 1, qlines);\r\nelse\r\nmqh = gru_mesq_head(2, qlines / 2 + 1);\r\ngru_gamir(cb, EOP_IR_CLR, HSTATUS(mqd->mq_gpa, half), XTYPE_DW, IMA);\r\nif (gru_wait(cb) != CBS_IDLE)\r\ngoto cberr;\r\nif (!gru_get_amo_value(cb)) {\r\nSTAT(mesq_qf_locked);\r\nreturn MQE_QUEUE_FULL;\r\n}\r\nif (head != limit) {\r\nif (send_noop_message(cb, mqd, mesg)) {\r\ngru_gamir(cb, EOP_IR_INC, HSTATUS(mqd->mq_gpa, half),\r\nXTYPE_DW, IMA);\r\nif (gru_wait(cb) != CBS_IDLE)\r\ngoto cberr;\r\nSTAT(mesq_qf_noop_not_full);\r\nreturn MQIE_AGAIN;\r\n}\r\navalue++;\r\n}\r\ngru_gamer(cb, EOP_ERR_CSWAP, mqd->mq_gpa, XTYPE_DW, mqh.val, avalue,\r\nIMA);\r\nif (gru_wait(cb) != CBS_IDLE)\r\ngoto cberr;\r\nif (gru_get_amo_value(cb) != avalue) {\r\nSTAT(mesq_qf_switch_head_failed);\r\ngru_gamir(cb, EOP_IR_INC, HSTATUS(mqd->mq_gpa, half), XTYPE_DW,\r\nIMA);\r\nif (gru_wait(cb) != CBS_IDLE)\r\ngoto cberr;\r\n}\r\nreturn MQIE_AGAIN;\r\ncberr:\r\nSTAT(mesq_qf_unexpected_error);\r\nreturn MQE_UNEXPECTED_CB_ERR;\r\n}\r\nstatic int send_message_put_nacked(void *cb, struct gru_message_queue_desc *mqd,\r\nvoid *mesg, int lines)\r\n{\r\nunsigned long m;\r\nint ret, loops = 200;\r\nm = mqd->mq_gpa + (gru_get_amo_value_head(cb) << 6);\r\nif (lines == 2) {\r\ngru_vset(cb, m, 0, XTYPE_CL, lines, 1, IMA);\r\nif (gru_wait(cb) != CBS_IDLE)\r\nreturn MQE_UNEXPECTED_CB_ERR;\r\n}\r\ngru_vstore(cb, m, gru_get_tri(mesg), XTYPE_CL, lines, 1, IMA);\r\nif (gru_wait(cb) != CBS_IDLE)\r\nreturn MQE_UNEXPECTED_CB_ERR;\r\nif (!mqd->interrupt_vector)\r\nreturn MQE_OK;\r\ndo {\r\nret = send_noop_message(cb, mqd, mesg);\r\n} while ((ret == MQIE_AGAIN || ret == MQE_CONGESTION) && (loops-- > 0));\r\nif (ret == MQIE_AGAIN || ret == MQE_CONGESTION) {\r\nret = MQE_OK;\r\n}\r\nreturn ret;\r\n}\r\nstatic int send_message_failure(void *cb, struct gru_message_queue_desc *mqd,\r\nvoid *mesg, int lines)\r\n{\r\nint substatus, ret = 0;\r\nsubstatus = gru_get_cb_message_queue_substatus(cb);\r\nswitch (substatus) {\r\ncase CBSS_NO_ERROR:\r\nSTAT(mesq_send_unexpected_error);\r\nret = MQE_UNEXPECTED_CB_ERR;\r\nbreak;\r\ncase CBSS_LB_OVERFLOWED:\r\nSTAT(mesq_send_lb_overflow);\r\nret = MQE_CONGESTION;\r\nbreak;\r\ncase CBSS_QLIMIT_REACHED:\r\nSTAT(mesq_send_qlimit_reached);\r\nret = send_message_queue_full(cb, mqd, mesg, lines);\r\nbreak;\r\ncase CBSS_AMO_NACKED:\r\nSTAT(mesq_send_amo_nacked);\r\nret = MQE_CONGESTION;\r\nbreak;\r\ncase CBSS_PUT_NACKED:\r\nSTAT(mesq_send_put_nacked);\r\nret = send_message_put_nacked(cb, mqd, mesg, lines);\r\nbreak;\r\ncase CBSS_PAGE_OVERFLOW:\r\nSTAT(mesq_page_overflow);\r\ndefault:\r\nBUG();\r\n}\r\nreturn ret;\r\n}\r\nint gru_send_message_gpa(struct gru_message_queue_desc *mqd, void *mesg,\r\nunsigned int bytes)\r\n{\r\nstruct message_header *mhdr;\r\nvoid *cb;\r\nvoid *dsr;\r\nint istatus, clines, ret;\r\nSTAT(mesq_send);\r\nBUG_ON(bytes < sizeof(int) || bytes > 2 * GRU_CACHE_LINE_BYTES);\r\nclines = DIV_ROUND_UP(bytes, GRU_CACHE_LINE_BYTES);\r\nif (gru_get_cpu_resources(bytes, &cb, &dsr))\r\nreturn MQE_BUG_NO_RESOURCES;\r\nmemcpy(dsr, mesg, bytes);\r\nmhdr = dsr;\r\nmhdr->present = MQS_FULL;\r\nmhdr->lines = clines;\r\nif (clines == 2) {\r\nmhdr->present2 = get_present2(mhdr);\r\nrestore_present2(mhdr, MQS_FULL);\r\n}\r\ndo {\r\nret = MQE_OK;\r\ngru_mesq(cb, mqd->mq_gpa, gru_get_tri(mhdr), clines, IMA);\r\nistatus = gru_wait(cb);\r\nif (istatus != CBS_IDLE)\r\nret = send_message_failure(cb, mqd, dsr, clines);\r\n} while (ret == MQIE_AGAIN);\r\ngru_free_cpu_resources(cb, dsr);\r\nif (ret)\r\nSTAT(mesq_send_failed);\r\nreturn ret;\r\n}\r\nvoid gru_free_message(struct gru_message_queue_desc *mqd, void *mesg)\r\n{\r\nstruct message_queue *mq = mqd->mq;\r\nstruct message_header *mhdr = mq->next;\r\nvoid *next, *pnext;\r\nint half = -1;\r\nint lines = mhdr->lines;\r\nif (lines == 2)\r\nrestore_present2(mhdr, MQS_EMPTY);\r\nmhdr->present = MQS_EMPTY;\r\npnext = mq->next;\r\nnext = pnext + GRU_CACHE_LINE_BYTES * lines;\r\nif (next == mq->limit) {\r\nnext = mq->start;\r\nhalf = 1;\r\n} else if (pnext < mq->start2 && next >= mq->start2) {\r\nhalf = 0;\r\n}\r\nif (half >= 0)\r\nmq->hstatus[half] = 1;\r\nmq->next = next;\r\n}\r\nvoid *gru_get_next_message(struct gru_message_queue_desc *mqd)\r\n{\r\nstruct message_queue *mq = mqd->mq;\r\nstruct message_header *mhdr = mq->next;\r\nint present = mhdr->present;\r\nwhile (present == MQS_NOOP) {\r\ngru_free_message(mqd, mhdr);\r\nmhdr = mq->next;\r\npresent = mhdr->present;\r\n}\r\nif (present == MQS_FULL && mhdr->lines == 2 &&\r\nget_present2(mhdr) == MQS_EMPTY)\r\npresent = MQS_EMPTY;\r\nif (!present) {\r\nSTAT(mesq_receive_none);\r\nreturn NULL;\r\n}\r\nif (mhdr->lines == 2)\r\nrestore_present2(mhdr, mhdr->present2);\r\nSTAT(mesq_receive);\r\nreturn mhdr;\r\n}\r\nint gru_read_gpa(unsigned long *value, unsigned long gpa)\r\n{\r\nvoid *cb;\r\nvoid *dsr;\r\nint ret, iaa;\r\nSTAT(read_gpa);\r\nif (gru_get_cpu_resources(GRU_NUM_KERNEL_DSR_BYTES, &cb, &dsr))\r\nreturn MQE_BUG_NO_RESOURCES;\r\niaa = gpa >> 62;\r\ngru_vload_phys(cb, gpa, gru_get_tri(dsr), iaa, IMA);\r\nret = gru_wait(cb);\r\nif (ret == CBS_IDLE)\r\n*value = *(unsigned long *)dsr;\r\ngru_free_cpu_resources(cb, dsr);\r\nreturn ret;\r\n}\r\nint gru_copy_gpa(unsigned long dest_gpa, unsigned long src_gpa,\r\nunsigned int bytes)\r\n{\r\nvoid *cb;\r\nvoid *dsr;\r\nint ret;\r\nSTAT(copy_gpa);\r\nif (gru_get_cpu_resources(GRU_NUM_KERNEL_DSR_BYTES, &cb, &dsr))\r\nreturn MQE_BUG_NO_RESOURCES;\r\ngru_bcopy(cb, src_gpa, dest_gpa, gru_get_tri(dsr),\r\nXTYPE_B, bytes, GRU_NUM_KERNEL_DSR_CL, IMA);\r\nret = gru_wait(cb);\r\ngru_free_cpu_resources(cb, dsr);\r\nreturn ret;\r\n}\r\nstatic int quicktest0(unsigned long arg)\r\n{\r\nunsigned long word0;\r\nunsigned long word1;\r\nvoid *cb;\r\nvoid *dsr;\r\nunsigned long *p;\r\nint ret = -EIO;\r\nif (gru_get_cpu_resources(GRU_CACHE_LINE_BYTES, &cb, &dsr))\r\nreturn MQE_BUG_NO_RESOURCES;\r\np = dsr;\r\nword0 = MAGIC;\r\nword1 = 0;\r\ngru_vload(cb, uv_gpa(&word0), gru_get_tri(dsr), XTYPE_DW, 1, 1, IMA);\r\nif (gru_wait(cb) != CBS_IDLE) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest0: CBR failure 1\n", smp_processor_id());\r\ngoto done;\r\n}\r\nif (*p != MAGIC) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest0 bad magic 0x%lx\n", smp_processor_id(), *p);\r\ngoto done;\r\n}\r\ngru_vstore(cb, uv_gpa(&word1), gru_get_tri(dsr), XTYPE_DW, 1, 1, IMA);\r\nif (gru_wait(cb) != CBS_IDLE) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest0: CBR failure 2\n", smp_processor_id());\r\ngoto done;\r\n}\r\nif (word0 != word1 || word1 != MAGIC) {\r\nprintk(KERN_DEBUG\r\n"GRU:%d quicktest0 err: found 0x%lx, expected 0x%lx\n",\r\nsmp_processor_id(), word1, MAGIC);\r\ngoto done;\r\n}\r\nret = 0;\r\ndone:\r\ngru_free_cpu_resources(cb, dsr);\r\nreturn ret;\r\n}\r\nstatic int quicktest1(unsigned long arg)\r\n{\r\nstruct gru_message_queue_desc mqd;\r\nvoid *p, *mq;\r\nint i, ret = -EIO;\r\nchar mes[GRU_CACHE_LINE_BYTES], *m;\r\np = kmalloc(4096, 0);\r\nif (p == NULL)\r\nreturn -ENOMEM;\r\nmq = ALIGNUP(p, 1024);\r\nmemset(mes, 0xee, sizeof(mes));\r\ngru_create_message_queue(&mqd, mq, 8 * GRU_CACHE_LINE_BYTES, 0, 0, 0);\r\nfor (i = 0; i < 6; i++) {\r\nmes[8] = i;\r\ndo {\r\nret = gru_send_message_gpa(&mqd, mes, sizeof(mes));\r\n} while (ret == MQE_CONGESTION);\r\nif (ret)\r\nbreak;\r\n}\r\nif (ret != MQE_QUEUE_FULL || i != 4) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest1: unexpect status %d, i %d\n",\r\nsmp_processor_id(), ret, i);\r\ngoto done;\r\n}\r\nfor (i = 0; i < 6; i++) {\r\nm = gru_get_next_message(&mqd);\r\nif (!m || m[8] != i)\r\nbreak;\r\ngru_free_message(&mqd, m);\r\n}\r\nif (i != 4) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest2: bad message, i %d, m %p, m8 %d\n",\r\nsmp_processor_id(), i, m, m ? m[8] : -1);\r\ngoto done;\r\n}\r\nret = 0;\r\ndone:\r\nkfree(p);\r\nreturn ret;\r\n}\r\nstatic int quicktest2(unsigned long arg)\r\n{\r\nstatic DECLARE_COMPLETION(cmp);\r\nunsigned long han;\r\nint blade_id = 0;\r\nint numcb = 4;\r\nint ret = 0;\r\nunsigned long *buf;\r\nvoid *cb0, *cb;\r\nstruct gru_control_block_status *gen;\r\nint i, k, istatus, bytes;\r\nbytes = numcb * 4 * 8;\r\nbuf = kmalloc(bytes, GFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\nret = -EBUSY;\r\nhan = gru_reserve_async_resources(blade_id, numcb, 0, &cmp);\r\nif (!han)\r\ngoto done;\r\ngru_lock_async_resource(han, &cb0, NULL);\r\nmemset(buf, 0xee, bytes);\r\nfor (i = 0; i < numcb; i++)\r\ngru_vset(cb0 + i * GRU_HANDLE_STRIDE, uv_gpa(&buf[i * 4]), 0,\r\nXTYPE_DW, 4, 1, IMA_INTERRUPT);\r\nret = 0;\r\nk = numcb;\r\ndo {\r\ngru_wait_async_cbr(han);\r\nfor (i = 0; i < numcb; i++) {\r\ncb = cb0 + i * GRU_HANDLE_STRIDE;\r\nistatus = gru_check_status(cb);\r\nif (istatus != CBS_ACTIVE && istatus != CBS_CALL_OS)\r\nbreak;\r\n}\r\nif (i == numcb)\r\ncontinue;\r\nif (istatus != CBS_IDLE) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest2: cb %d, exception\n", smp_processor_id(), i);\r\nret = -EFAULT;\r\n} else if (buf[4 * i] || buf[4 * i + 1] || buf[4 * i + 2] ||\r\nbuf[4 * i + 3]) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest2:cb %d, buf 0x%lx, 0x%lx, 0x%lx, 0x%lx\n",\r\nsmp_processor_id(), i, buf[4 * i], buf[4 * i + 1], buf[4 * i + 2], buf[4 * i + 3]);\r\nret = -EIO;\r\n}\r\nk--;\r\ngen = cb;\r\ngen->istatus = CBS_CALL_OS;\r\n} while (k);\r\nBUG_ON(cmp.done);\r\ngru_unlock_async_resource(han);\r\ngru_release_async_resources(han);\r\ndone:\r\nkfree(buf);\r\nreturn ret;\r\n}\r\nstatic int quicktest3(unsigned long arg)\r\n{\r\nchar buf1[BUFSIZE], buf2[BUFSIZE];\r\nint ret = 0;\r\nmemset(buf2, 0, sizeof(buf2));\r\nmemset(buf1, get_cycles() & 255, sizeof(buf1));\r\ngru_copy_gpa(uv_gpa(buf2), uv_gpa(buf1), BUFSIZE);\r\nif (memcmp(buf1, buf2, BUFSIZE)) {\r\nprintk(KERN_DEBUG "GRU:%d quicktest3 error\n", smp_processor_id());\r\nret = -EIO;\r\n}\r\nreturn ret;\r\n}\r\nint gru_ktest(unsigned long arg)\r\n{\r\nint ret = -EINVAL;\r\nswitch (arg & 0xff) {\r\ncase 0:\r\nret = quicktest0(arg);\r\nbreak;\r\ncase 1:\r\nret = quicktest1(arg);\r\nbreak;\r\ncase 2:\r\nret = quicktest2(arg);\r\nbreak;\r\ncase 3:\r\nret = quicktest3(arg);\r\nbreak;\r\ncase 99:\r\nret = gru_free_kernel_contexts();\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nint gru_kservices_init(void)\r\n{\r\nreturn 0;\r\n}\r\nvoid gru_kservices_exit(void)\r\n{\r\nif (gru_free_kernel_contexts())\r\nBUG();\r\n}
