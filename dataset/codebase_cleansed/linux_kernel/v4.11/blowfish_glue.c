static inline void blowfish_enc_blk(struct bf_ctx *ctx, u8 *dst, const u8 *src)\r\n{\r\n__blowfish_enc_blk(ctx, dst, src, false);\r\n}\r\nstatic inline void blowfish_enc_blk_xor(struct bf_ctx *ctx, u8 *dst,\r\nconst u8 *src)\r\n{\r\n__blowfish_enc_blk(ctx, dst, src, true);\r\n}\r\nstatic inline void blowfish_enc_blk_4way(struct bf_ctx *ctx, u8 *dst,\r\nconst u8 *src)\r\n{\r\n__blowfish_enc_blk_4way(ctx, dst, src, false);\r\n}\r\nstatic inline void blowfish_enc_blk_xor_4way(struct bf_ctx *ctx, u8 *dst,\r\nconst u8 *src)\r\n{\r\n__blowfish_enc_blk_4way(ctx, dst, src, true);\r\n}\r\nstatic void blowfish_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\r\n{\r\nblowfish_enc_blk(crypto_tfm_ctx(tfm), dst, src);\r\n}\r\nstatic void blowfish_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\r\n{\r\nblowfish_dec_blk(crypto_tfm_ctx(tfm), dst, src);\r\n}\r\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\r\nvoid (*fn)(struct bf_ctx *, u8 *, const u8 *),\r\nvoid (*fn_4way)(struct bf_ctx *, u8 *, const u8 *))\r\n{\r\nstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = BF_BLOCK_SIZE;\r\nunsigned int nbytes;\r\nint err;\r\nerr = blkcipher_walk_virt(desc, walk);\r\nwhile ((nbytes = walk->nbytes)) {\r\nu8 *wsrc = walk->src.virt.addr;\r\nu8 *wdst = walk->dst.virt.addr;\r\nif (nbytes >= bsize * 4) {\r\ndo {\r\nfn_4way(ctx, wdst, wsrc);\r\nwsrc += bsize * 4;\r\nwdst += bsize * 4;\r\nnbytes -= bsize * 4;\r\n} while (nbytes >= bsize * 4);\r\nif (nbytes < bsize)\r\ngoto done;\r\n}\r\ndo {\r\nfn(ctx, wdst, wsrc);\r\nwsrc += bsize;\r\nwdst += bsize;\r\nnbytes -= bsize;\r\n} while (nbytes >= bsize);\r\ndone:\r\nerr = blkcipher_walk_done(desc, walk, nbytes);\r\n}\r\nreturn err;\r\n}\r\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nreturn ecb_crypt(desc, &walk, blowfish_enc_blk, blowfish_enc_blk_4way);\r\n}\r\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nreturn ecb_crypt(desc, &walk, blowfish_dec_blk, blowfish_dec_blk_4way);\r\n}\r\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\r\nstruct blkcipher_walk *walk)\r\n{\r\nstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = BF_BLOCK_SIZE;\r\nunsigned int nbytes = walk->nbytes;\r\nu64 *src = (u64 *)walk->src.virt.addr;\r\nu64 *dst = (u64 *)walk->dst.virt.addr;\r\nu64 *iv = (u64 *)walk->iv;\r\ndo {\r\n*dst = *src ^ *iv;\r\nblowfish_enc_blk(ctx, (u8 *)dst, (u8 *)dst);\r\niv = dst;\r\nsrc += 1;\r\ndst += 1;\r\nnbytes -= bsize;\r\n} while (nbytes >= bsize);\r\n*(u64 *)walk->iv = *iv;\r\nreturn nbytes;\r\n}\r\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nwhile ((nbytes = walk.nbytes)) {\r\nnbytes = __cbc_encrypt(desc, &walk);\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nreturn err;\r\n}\r\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\r\nstruct blkcipher_walk *walk)\r\n{\r\nstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = BF_BLOCK_SIZE;\r\nunsigned int nbytes = walk->nbytes;\r\nu64 *src = (u64 *)walk->src.virt.addr;\r\nu64 *dst = (u64 *)walk->dst.virt.addr;\r\nu64 ivs[4 - 1];\r\nu64 last_iv;\r\nsrc += nbytes / bsize - 1;\r\ndst += nbytes / bsize - 1;\r\nlast_iv = *src;\r\nif (nbytes >= bsize * 4) {\r\ndo {\r\nnbytes -= bsize * 4 - bsize;\r\nsrc -= 4 - 1;\r\ndst -= 4 - 1;\r\nivs[0] = src[0];\r\nivs[1] = src[1];\r\nivs[2] = src[2];\r\nblowfish_dec_blk_4way(ctx, (u8 *)dst, (u8 *)src);\r\ndst[1] ^= ivs[0];\r\ndst[2] ^= ivs[1];\r\ndst[3] ^= ivs[2];\r\nnbytes -= bsize;\r\nif (nbytes < bsize)\r\ngoto done;\r\n*dst ^= *(src - 1);\r\nsrc -= 1;\r\ndst -= 1;\r\n} while (nbytes >= bsize * 4);\r\n}\r\nfor (;;) {\r\nblowfish_dec_blk(ctx, (u8 *)dst, (u8 *)src);\r\nnbytes -= bsize;\r\nif (nbytes < bsize)\r\nbreak;\r\n*dst ^= *(src - 1);\r\nsrc -= 1;\r\ndst -= 1;\r\n}\r\ndone:\r\n*dst ^= *(u64 *)walk->iv;\r\n*(u64 *)walk->iv = last_iv;\r\nreturn nbytes;\r\n}\r\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nwhile ((nbytes = walk.nbytes)) {\r\nnbytes = __cbc_decrypt(desc, &walk);\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nreturn err;\r\n}\r\nstatic void ctr_crypt_final(struct bf_ctx *ctx, struct blkcipher_walk *walk)\r\n{\r\nu8 *ctrblk = walk->iv;\r\nu8 keystream[BF_BLOCK_SIZE];\r\nu8 *src = walk->src.virt.addr;\r\nu8 *dst = walk->dst.virt.addr;\r\nunsigned int nbytes = walk->nbytes;\r\nblowfish_enc_blk(ctx, keystream, ctrblk);\r\ncrypto_xor(keystream, src, nbytes);\r\nmemcpy(dst, keystream, nbytes);\r\ncrypto_inc(ctrblk, BF_BLOCK_SIZE);\r\n}\r\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\r\nstruct blkcipher_walk *walk)\r\n{\r\nstruct bf_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = BF_BLOCK_SIZE;\r\nunsigned int nbytes = walk->nbytes;\r\nu64 *src = (u64 *)walk->src.virt.addr;\r\nu64 *dst = (u64 *)walk->dst.virt.addr;\r\nu64 ctrblk = be64_to_cpu(*(__be64 *)walk->iv);\r\n__be64 ctrblocks[4];\r\nif (nbytes >= bsize * 4) {\r\ndo {\r\nif (dst != src) {\r\ndst[0] = src[0];\r\ndst[1] = src[1];\r\ndst[2] = src[2];\r\ndst[3] = src[3];\r\n}\r\nctrblocks[0] = cpu_to_be64(ctrblk++);\r\nctrblocks[1] = cpu_to_be64(ctrblk++);\r\nctrblocks[2] = cpu_to_be64(ctrblk++);\r\nctrblocks[3] = cpu_to_be64(ctrblk++);\r\nblowfish_enc_blk_xor_4way(ctx, (u8 *)dst,\r\n(u8 *)ctrblocks);\r\nsrc += 4;\r\ndst += 4;\r\n} while ((nbytes -= bsize * 4) >= bsize * 4);\r\nif (nbytes < bsize)\r\ngoto done;\r\n}\r\ndo {\r\nif (dst != src)\r\n*dst = *src;\r\nctrblocks[0] = cpu_to_be64(ctrblk++);\r\nblowfish_enc_blk_xor(ctx, (u8 *)dst, (u8 *)ctrblocks);\r\nsrc += 1;\r\ndst += 1;\r\n} while ((nbytes -= bsize) >= bsize);\r\ndone:\r\n*(__be64 *)walk->iv = cpu_to_be64(ctrblk);\r\nreturn nbytes;\r\n}\r\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt_block(desc, &walk, BF_BLOCK_SIZE);\r\nwhile ((nbytes = walk.nbytes) >= BF_BLOCK_SIZE) {\r\nnbytes = __ctr_crypt(desc, &walk);\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nif (walk.nbytes) {\r\nctr_crypt_final(crypto_blkcipher_ctx(desc->tfm), &walk);\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nreturn err;\r\n}\r\nstatic bool is_blacklisted_cpu(void)\r\n{\r\nif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\r\nreturn false;\r\nif (boot_cpu_data.x86 == 0x0f) {\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic int __init init(void)\r\n{\r\nif (!force && is_blacklisted_cpu()) {\r\nprintk(KERN_INFO\r\n"blowfish-x86_64: performance on this CPU "\r\n"would be suboptimal: disabling "\r\n"blowfish-x86_64.\n");\r\nreturn -ENODEV;\r\n}\r\nreturn crypto_register_algs(bf_algs, ARRAY_SIZE(bf_algs));\r\n}\r\nstatic void __exit fini(void)\r\n{\r\ncrypto_unregister_algs(bf_algs, ARRAY_SIZE(bf_algs));\r\n}
