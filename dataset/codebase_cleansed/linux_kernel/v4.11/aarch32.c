bool kvm_condition_valid32(const struct kvm_vcpu *vcpu)\r\n{\r\nunsigned long cpsr;\r\nu32 cpsr_cond;\r\nint cond;\r\nif (kvm_vcpu_get_hsr(vcpu) >> 30)\r\nreturn true;\r\ncond = kvm_vcpu_get_condition(vcpu);\r\nif (cond == 0xE)\r\nreturn true;\r\ncpsr = *vcpu_cpsr(vcpu);\r\nif (cond < 0) {\r\nunsigned long it;\r\nit = ((cpsr >> 8) & 0xFC) | ((cpsr >> 25) & 0x3);\r\nif (it == 0)\r\nreturn true;\r\ncond = (it >> 4);\r\n}\r\ncpsr_cond = cpsr >> 28;\r\nif (!((cc_map[cond] >> cpsr_cond) & 1))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void __hyp_text kvm_adjust_itstate(struct kvm_vcpu *vcpu)\r\n{\r\nunsigned long itbits, cond;\r\nunsigned long cpsr = *vcpu_cpsr(vcpu);\r\nbool is_arm = !(cpsr & COMPAT_PSR_T_BIT);\r\nif (is_arm || !(cpsr & COMPAT_PSR_IT_MASK))\r\nreturn;\r\ncond = (cpsr & 0xe000) >> 13;\r\nitbits = (cpsr & 0x1c00) >> (10 - 2);\r\nitbits |= (cpsr & (0x3 << 25)) >> 25;\r\nif ((itbits & 0x7) == 0)\r\nitbits = cond = 0;\r\nelse\r\nitbits = (itbits << 1) & 0x1f;\r\ncpsr &= ~COMPAT_PSR_IT_MASK;\r\ncpsr |= cond << 13;\r\ncpsr |= (itbits & 0x1c) << (10 - 2);\r\ncpsr |= (itbits & 0x3) << 25;\r\n*vcpu_cpsr(vcpu) = cpsr;\r\n}\r\nvoid __hyp_text kvm_skip_instr32(struct kvm_vcpu *vcpu, bool is_wide_instr)\r\n{\r\nbool is_thumb;\r\nis_thumb = !!(*vcpu_cpsr(vcpu) & COMPAT_PSR_T_BIT);\r\nif (is_thumb && !is_wide_instr)\r\n*vcpu_pc(vcpu) += 2;\r\nelse\r\n*vcpu_pc(vcpu) += 4;\r\nkvm_adjust_itstate(vcpu);\r\n}
