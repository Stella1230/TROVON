static void cpmac_dump_regs(struct net_device *dev)\r\n{\r\nint i;\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nfor (i = 0; i < CPMAC_REG_END; i += 4) {\r\nif (i % 16 == 0) {\r\nif (i)\r\nprintk("\n");\r\nprintk("%s: reg[%p]:", dev->name, priv->regs + i);\r\n}\r\nprintk(" %08x", cpmac_read(priv->regs, i));\r\n}\r\nprintk("\n");\r\n}\r\nstatic void cpmac_dump_desc(struct net_device *dev, struct cpmac_desc *desc)\r\n{\r\nint i;\r\nprintk("%s: desc[%p]:", dev->name, desc);\r\nfor (i = 0; i < sizeof(*desc) / 4; i++)\r\nprintk(" %08x", ((u32 *)desc)[i]);\r\nprintk("\n");\r\n}\r\nstatic void cpmac_dump_all_desc(struct net_device *dev)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nstruct cpmac_desc *dump = priv->rx_head;\r\ndo {\r\ncpmac_dump_desc(dev, dump);\r\ndump = dump->next;\r\n} while (dump != priv->rx_head);\r\n}\r\nstatic void cpmac_dump_skb(struct net_device *dev, struct sk_buff *skb)\r\n{\r\nint i;\r\nprintk("%s: skb 0x%p, len=%d\n", dev->name, skb, skb->len);\r\nfor (i = 0; i < skb->len; i++) {\r\nif (i % 16 == 0) {\r\nif (i)\r\nprintk("\n");\r\nprintk("%s: data[%p]:", dev->name, skb->data + i);\r\n}\r\nprintk(" %02x", ((u8 *)skb->data)[i]);\r\n}\r\nprintk("\n");\r\n}\r\nstatic int cpmac_mdio_read(struct mii_bus *bus, int phy_id, int reg)\r\n{\r\nu32 val;\r\nwhile (cpmac_read(bus->priv, CPMAC_MDIO_ACCESS(0)) & MDIO_BUSY)\r\ncpu_relax();\r\ncpmac_write(bus->priv, CPMAC_MDIO_ACCESS(0), MDIO_BUSY | MDIO_REG(reg) |\r\nMDIO_PHY(phy_id));\r\nwhile ((val = cpmac_read(bus->priv, CPMAC_MDIO_ACCESS(0))) & MDIO_BUSY)\r\ncpu_relax();\r\nreturn MDIO_DATA(val);\r\n}\r\nstatic int cpmac_mdio_write(struct mii_bus *bus, int phy_id,\r\nint reg, u16 val)\r\n{\r\nwhile (cpmac_read(bus->priv, CPMAC_MDIO_ACCESS(0)) & MDIO_BUSY)\r\ncpu_relax();\r\ncpmac_write(bus->priv, CPMAC_MDIO_ACCESS(0), MDIO_BUSY | MDIO_WRITE |\r\nMDIO_REG(reg) | MDIO_PHY(phy_id) | MDIO_DATA(val));\r\nreturn 0;\r\n}\r\nstatic int cpmac_mdio_reset(struct mii_bus *bus)\r\n{\r\nstruct clk *cpmac_clk;\r\ncpmac_clk = clk_get(&bus->dev, "cpmac");\r\nif (IS_ERR(cpmac_clk)) {\r\npr_err("unable to get cpmac clock\n");\r\nreturn -1;\r\n}\r\nar7_device_reset(AR7_RESET_BIT_MDIO);\r\ncpmac_write(bus->priv, CPMAC_MDIO_CONTROL, MDIOC_ENABLE |\r\nMDIOC_CLKDIV(clk_get_rate(cpmac_clk) / 2200000 - 1));\r\nreturn 0;\r\n}\r\nstatic void cpmac_set_multicast_list(struct net_device *dev)\r\n{\r\nstruct netdev_hw_addr *ha;\r\nu8 tmp;\r\nu32 mbp, bit, hash[2] = { 0, };\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nmbp = cpmac_read(priv->regs, CPMAC_MBP);\r\nif (dev->flags & IFF_PROMISC) {\r\ncpmac_write(priv->regs, CPMAC_MBP, (mbp & ~MBP_PROMISCCHAN(0)) |\r\nMBP_RXPROMISC);\r\n} else {\r\ncpmac_write(priv->regs, CPMAC_MBP, mbp & ~MBP_RXPROMISC);\r\nif (dev->flags & IFF_ALLMULTI) {\r\ncpmac_write(priv->regs, CPMAC_MAC_HASH_LO, 0xffffffff);\r\ncpmac_write(priv->regs, CPMAC_MAC_HASH_HI, 0xffffffff);\r\n} else {\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nbit = 0;\r\ntmp = ha->addr[0];\r\nbit ^= (tmp >> 2) ^ (tmp << 4);\r\ntmp = ha->addr[1];\r\nbit ^= (tmp >> 4) ^ (tmp << 2);\r\ntmp = ha->addr[2];\r\nbit ^= (tmp >> 6) ^ tmp;\r\ntmp = ha->addr[3];\r\nbit ^= (tmp >> 2) ^ (tmp << 4);\r\ntmp = ha->addr[4];\r\nbit ^= (tmp >> 4) ^ (tmp << 2);\r\ntmp = ha->addr[5];\r\nbit ^= (tmp >> 6) ^ tmp;\r\nbit &= 0x3f;\r\nhash[bit / 32] |= 1 << (bit % 32);\r\n}\r\ncpmac_write(priv->regs, CPMAC_MAC_HASH_LO, hash[0]);\r\ncpmac_write(priv->regs, CPMAC_MAC_HASH_HI, hash[1]);\r\n}\r\n}\r\n}\r\nstatic struct sk_buff *cpmac_rx_one(struct cpmac_priv *priv,\r\nstruct cpmac_desc *desc)\r\n{\r\nstruct sk_buff *skb, *result = NULL;\r\nif (unlikely(netif_msg_hw(priv)))\r\ncpmac_dump_desc(priv->dev, desc);\r\ncpmac_write(priv->regs, CPMAC_RX_ACK(0), (u32)desc->mapping);\r\nif (unlikely(!desc->datalen)) {\r\nif (netif_msg_rx_err(priv) && net_ratelimit())\r\nnetdev_warn(priv->dev, "rx: spurious interrupt\n");\r\nreturn NULL;\r\n}\r\nskb = netdev_alloc_skb_ip_align(priv->dev, CPMAC_SKB_SIZE);\r\nif (likely(skb)) {\r\nskb_put(desc->skb, desc->datalen);\r\ndesc->skb->protocol = eth_type_trans(desc->skb, priv->dev);\r\nskb_checksum_none_assert(desc->skb);\r\npriv->dev->stats.rx_packets++;\r\npriv->dev->stats.rx_bytes += desc->datalen;\r\nresult = desc->skb;\r\ndma_unmap_single(&priv->dev->dev, desc->data_mapping,\r\nCPMAC_SKB_SIZE, DMA_FROM_DEVICE);\r\ndesc->skb = skb;\r\ndesc->data_mapping = dma_map_single(&priv->dev->dev, skb->data,\r\nCPMAC_SKB_SIZE,\r\nDMA_FROM_DEVICE);\r\ndesc->hw_data = (u32)desc->data_mapping;\r\nif (unlikely(netif_msg_pktdata(priv))) {\r\nnetdev_dbg(priv->dev, "received packet:\n");\r\ncpmac_dump_skb(priv->dev, result);\r\n}\r\n} else {\r\nif (netif_msg_rx_err(priv) && net_ratelimit())\r\nnetdev_warn(priv->dev,\r\n"low on skbs, dropping packet\n");\r\npriv->dev->stats.rx_dropped++;\r\n}\r\ndesc->buflen = CPMAC_SKB_SIZE;\r\ndesc->dataflags = CPMAC_OWN;\r\nreturn result;\r\n}\r\nstatic int cpmac_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct sk_buff *skb;\r\nstruct cpmac_desc *desc, *restart;\r\nstruct cpmac_priv *priv = container_of(napi, struct cpmac_priv, napi);\r\nint received = 0, processed = 0;\r\nspin_lock(&priv->rx_lock);\r\nif (unlikely(!priv->rx_head)) {\r\nif (netif_msg_rx_err(priv) && net_ratelimit())\r\nnetdev_warn(priv->dev, "rx: polling, but no queue\n");\r\nspin_unlock(&priv->rx_lock);\r\nnapi_complete(napi);\r\nreturn 0;\r\n}\r\ndesc = priv->rx_head;\r\nrestart = NULL;\r\nwhile (((desc->dataflags & CPMAC_OWN) == 0) && (received < budget)) {\r\nprocessed++;\r\nif ((desc->dataflags & CPMAC_EOQ) != 0) {\r\nif (unlikely(restart)) {\r\nif (netif_msg_rx_err(priv))\r\nnetdev_err(priv->dev, "poll found a"\r\n" duplicate EOQ: %p and %p\n",\r\nrestart, desc);\r\ngoto fatal_error;\r\n}\r\nrestart = desc->next;\r\n}\r\nskb = cpmac_rx_one(priv, desc);\r\nif (likely(skb)) {\r\nnetif_receive_skb(skb);\r\nreceived++;\r\n}\r\ndesc = desc->next;\r\n}\r\nif (desc != priv->rx_head) {\r\ndesc->prev->hw_next = (u32)0;\r\npriv->rx_head->prev->hw_next = priv->rx_head->mapping;\r\n}\r\nif (!restart &&\r\n(priv->rx_head->prev->dataflags & (CPMAC_OWN|CPMAC_EOQ))\r\n== CPMAC_EOQ &&\r\n(priv->rx_head->dataflags & CPMAC_OWN) != 0) {\r\npriv->rx_head->prev->dataflags &= ~CPMAC_EOQ;\r\nrestart = priv->rx_head;\r\n}\r\nif (restart) {\r\npriv->dev->stats.rx_errors++;\r\npriv->dev->stats.rx_fifo_errors++;\r\nif (netif_msg_rx_err(priv) && net_ratelimit())\r\nnetdev_warn(priv->dev, "rx dma ring overrun\n");\r\nif (unlikely((restart->dataflags & CPMAC_OWN) == 0)) {\r\nif (netif_msg_drv(priv))\r\nnetdev_err(priv->dev, "cpmac_poll is trying "\r\n"to restart rx from a descriptor "\r\n"that's not free: %p\n", restart);\r\ngoto fatal_error;\r\n}\r\ncpmac_write(priv->regs, CPMAC_RX_PTR(0), restart->mapping);\r\n}\r\npriv->rx_head = desc;\r\nspin_unlock(&priv->rx_lock);\r\nif (unlikely(netif_msg_rx_status(priv)))\r\nnetdev_dbg(priv->dev, "poll processed %d packets\n", received);\r\nif (processed == 0) {\r\nnapi_complete(napi);\r\ncpmac_write(priv->regs, CPMAC_RX_INT_ENABLE, 1);\r\nreturn 0;\r\n}\r\nreturn 1;\r\nfatal_error:\r\nif (netif_msg_drv(priv)) {\r\nnetdev_err(priv->dev, "cpmac_poll is confused. "\r\n"Resetting hardware\n");\r\ncpmac_dump_all_desc(priv->dev);\r\nnetdev_dbg(priv->dev, "RX_PTR(0)=0x%08x RX_ACK(0)=0x%08x\n",\r\ncpmac_read(priv->regs, CPMAC_RX_PTR(0)),\r\ncpmac_read(priv->regs, CPMAC_RX_ACK(0)));\r\n}\r\nspin_unlock(&priv->rx_lock);\r\nnapi_complete(napi);\r\nnetif_tx_stop_all_queues(priv->dev);\r\nnapi_disable(&priv->napi);\r\natomic_inc(&priv->reset_pending);\r\ncpmac_hw_stop(priv->dev);\r\nif (!schedule_work(&priv->reset_work))\r\natomic_dec(&priv->reset_pending);\r\nreturn 0;\r\n}\r\nstatic int cpmac_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nint queue;\r\nunsigned int len;\r\nstruct cpmac_desc *desc;\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nif (unlikely(atomic_read(&priv->reset_pending)))\r\nreturn NETDEV_TX_BUSY;\r\nif (unlikely(skb_padto(skb, ETH_ZLEN)))\r\nreturn NETDEV_TX_OK;\r\nlen = max_t(unsigned int, skb->len, ETH_ZLEN);\r\nqueue = skb_get_queue_mapping(skb);\r\nnetif_stop_subqueue(dev, queue);\r\ndesc = &priv->desc_ring[queue];\r\nif (unlikely(desc->dataflags & CPMAC_OWN)) {\r\nif (netif_msg_tx_err(priv) && net_ratelimit())\r\nnetdev_warn(dev, "tx dma ring full\n");\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nspin_lock(&priv->lock);\r\nspin_unlock(&priv->lock);\r\ndesc->dataflags = CPMAC_SOP | CPMAC_EOP | CPMAC_OWN;\r\ndesc->skb = skb;\r\ndesc->data_mapping = dma_map_single(&dev->dev, skb->data, len,\r\nDMA_TO_DEVICE);\r\ndesc->hw_data = (u32)desc->data_mapping;\r\ndesc->datalen = len;\r\ndesc->buflen = len;\r\nif (unlikely(netif_msg_tx_queued(priv)))\r\nnetdev_dbg(dev, "sending 0x%p, len=%d\n", skb, skb->len);\r\nif (unlikely(netif_msg_hw(priv)))\r\ncpmac_dump_desc(dev, desc);\r\nif (unlikely(netif_msg_pktdata(priv)))\r\ncpmac_dump_skb(dev, skb);\r\ncpmac_write(priv->regs, CPMAC_TX_PTR(queue), (u32)desc->mapping);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void cpmac_end_xmit(struct net_device *dev, int queue)\r\n{\r\nstruct cpmac_desc *desc;\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\ndesc = &priv->desc_ring[queue];\r\ncpmac_write(priv->regs, CPMAC_TX_ACK(queue), (u32)desc->mapping);\r\nif (likely(desc->skb)) {\r\nspin_lock(&priv->lock);\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += desc->skb->len;\r\nspin_unlock(&priv->lock);\r\ndma_unmap_single(&dev->dev, desc->data_mapping, desc->skb->len,\r\nDMA_TO_DEVICE);\r\nif (unlikely(netif_msg_tx_done(priv)))\r\nnetdev_dbg(dev, "sent 0x%p, len=%d\n",\r\ndesc->skb, desc->skb->len);\r\ndev_kfree_skb_irq(desc->skb);\r\ndesc->skb = NULL;\r\nif (__netif_subqueue_stopped(dev, queue))\r\nnetif_wake_subqueue(dev, queue);\r\n} else {\r\nif (netif_msg_tx_err(priv) && net_ratelimit())\r\nnetdev_warn(dev, "end_xmit: spurious interrupt\n");\r\nif (__netif_subqueue_stopped(dev, queue))\r\nnetif_wake_subqueue(dev, queue);\r\n}\r\n}\r\nstatic void cpmac_hw_stop(struct net_device *dev)\r\n{\r\nint i;\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nstruct plat_cpmac_data *pdata = dev_get_platdata(&priv->pdev->dev);\r\nar7_device_reset(pdata->reset_bit);\r\ncpmac_write(priv->regs, CPMAC_RX_CONTROL,\r\ncpmac_read(priv->regs, CPMAC_RX_CONTROL) & ~1);\r\ncpmac_write(priv->regs, CPMAC_TX_CONTROL,\r\ncpmac_read(priv->regs, CPMAC_TX_CONTROL) & ~1);\r\nfor (i = 0; i < 8; i++) {\r\ncpmac_write(priv->regs, CPMAC_TX_PTR(i), 0);\r\ncpmac_write(priv->regs, CPMAC_RX_PTR(i), 0);\r\n}\r\ncpmac_write(priv->regs, CPMAC_UNICAST_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_RX_INT_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_TX_INT_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_MAC_INT_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_MAC_CONTROL,\r\ncpmac_read(priv->regs, CPMAC_MAC_CONTROL) & ~MAC_MII);\r\n}\r\nstatic void cpmac_hw_start(struct net_device *dev)\r\n{\r\nint i;\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nstruct plat_cpmac_data *pdata = dev_get_platdata(&priv->pdev->dev);\r\nar7_device_reset(pdata->reset_bit);\r\nfor (i = 0; i < 8; i++) {\r\ncpmac_write(priv->regs, CPMAC_TX_PTR(i), 0);\r\ncpmac_write(priv->regs, CPMAC_RX_PTR(i), 0);\r\n}\r\ncpmac_write(priv->regs, CPMAC_RX_PTR(0), priv->rx_head->mapping);\r\ncpmac_write(priv->regs, CPMAC_MBP, MBP_RXSHORT | MBP_RXBCAST |\r\nMBP_RXMCAST);\r\ncpmac_write(priv->regs, CPMAC_BUFFER_OFFSET, 0);\r\nfor (i = 0; i < 8; i++)\r\ncpmac_write(priv->regs, CPMAC_MAC_ADDR_LO(i), dev->dev_addr[5]);\r\ncpmac_write(priv->regs, CPMAC_MAC_ADDR_MID, dev->dev_addr[4]);\r\ncpmac_write(priv->regs, CPMAC_MAC_ADDR_HI, dev->dev_addr[0] |\r\n(dev->dev_addr[1] << 8) | (dev->dev_addr[2] << 16) |\r\n(dev->dev_addr[3] << 24));\r\ncpmac_write(priv->regs, CPMAC_MAX_LENGTH, CPMAC_SKB_SIZE);\r\ncpmac_write(priv->regs, CPMAC_UNICAST_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_RX_INT_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_TX_INT_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_MAC_INT_CLEAR, 0xff);\r\ncpmac_write(priv->regs, CPMAC_UNICAST_ENABLE, 1);\r\ncpmac_write(priv->regs, CPMAC_RX_INT_ENABLE, 1);\r\ncpmac_write(priv->regs, CPMAC_TX_INT_ENABLE, 0xff);\r\ncpmac_write(priv->regs, CPMAC_MAC_INT_ENABLE, 3);\r\ncpmac_write(priv->regs, CPMAC_RX_CONTROL,\r\ncpmac_read(priv->regs, CPMAC_RX_CONTROL) | 1);\r\ncpmac_write(priv->regs, CPMAC_TX_CONTROL,\r\ncpmac_read(priv->regs, CPMAC_TX_CONTROL) | 1);\r\ncpmac_write(priv->regs, CPMAC_MAC_CONTROL,\r\ncpmac_read(priv->regs, CPMAC_MAC_CONTROL) | MAC_MII |\r\nMAC_FDX);\r\n}\r\nstatic void cpmac_clear_rx(struct net_device *dev)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nstruct cpmac_desc *desc;\r\nint i;\r\nif (unlikely(!priv->rx_head))\r\nreturn;\r\ndesc = priv->rx_head;\r\nfor (i = 0; i < priv->ring_size; i++) {\r\nif ((desc->dataflags & CPMAC_OWN) == 0) {\r\nif (netif_msg_rx_err(priv) && net_ratelimit())\r\nnetdev_warn(dev, "packet dropped\n");\r\nif (unlikely(netif_msg_hw(priv)))\r\ncpmac_dump_desc(dev, desc);\r\ndesc->dataflags = CPMAC_OWN;\r\ndev->stats.rx_dropped++;\r\n}\r\ndesc->hw_next = desc->next->mapping;\r\ndesc = desc->next;\r\n}\r\npriv->rx_head->prev->hw_next = 0;\r\n}\r\nstatic void cpmac_clear_tx(struct net_device *dev)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nint i;\r\nif (unlikely(!priv->desc_ring))\r\nreturn;\r\nfor (i = 0; i < CPMAC_QUEUES; i++) {\r\npriv->desc_ring[i].dataflags = 0;\r\nif (priv->desc_ring[i].skb) {\r\ndev_kfree_skb_any(priv->desc_ring[i].skb);\r\npriv->desc_ring[i].skb = NULL;\r\n}\r\n}\r\n}\r\nstatic void cpmac_hw_error(struct work_struct *work)\r\n{\r\nstruct cpmac_priv *priv =\r\ncontainer_of(work, struct cpmac_priv, reset_work);\r\nspin_lock(&priv->rx_lock);\r\ncpmac_clear_rx(priv->dev);\r\nspin_unlock(&priv->rx_lock);\r\ncpmac_clear_tx(priv->dev);\r\ncpmac_hw_start(priv->dev);\r\nbarrier();\r\natomic_dec(&priv->reset_pending);\r\nnetif_tx_wake_all_queues(priv->dev);\r\ncpmac_write(priv->regs, CPMAC_MAC_INT_ENABLE, 3);\r\n}\r\nstatic void cpmac_check_status(struct net_device *dev)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nu32 macstatus = cpmac_read(priv->regs, CPMAC_MAC_STATUS);\r\nint rx_channel = (macstatus >> 8) & 7;\r\nint rx_code = (macstatus >> 12) & 15;\r\nint tx_channel = (macstatus >> 16) & 7;\r\nint tx_code = (macstatus >> 20) & 15;\r\nif (rx_code || tx_code) {\r\nif (netif_msg_drv(priv) && net_ratelimit()) {\r\nif (rx_code)\r\nnetdev_warn(dev, "host error %d on rx "\r\n"channel %d (macstatus %08x), resetting\n",\r\nrx_code, rx_channel, macstatus);\r\nif (tx_code)\r\nnetdev_warn(dev, "host error %d on tx "\r\n"channel %d (macstatus %08x), resetting\n",\r\ntx_code, tx_channel, macstatus);\r\n}\r\nnetif_tx_stop_all_queues(dev);\r\ncpmac_hw_stop(dev);\r\nif (schedule_work(&priv->reset_work))\r\natomic_inc(&priv->reset_pending);\r\nif (unlikely(netif_msg_hw(priv)))\r\ncpmac_dump_regs(dev);\r\n}\r\ncpmac_write(priv->regs, CPMAC_MAC_INT_CLEAR, 0xff);\r\n}\r\nstatic irqreturn_t cpmac_irq(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = dev_id;\r\nstruct cpmac_priv *priv;\r\nint queue;\r\nu32 status;\r\npriv = netdev_priv(dev);\r\nstatus = cpmac_read(priv->regs, CPMAC_MAC_INT_VECTOR);\r\nif (unlikely(netif_msg_intr(priv)))\r\nnetdev_dbg(dev, "interrupt status: 0x%08x\n", status);\r\nif (status & MAC_INT_TX)\r\ncpmac_end_xmit(dev, (status & 7));\r\nif (status & MAC_INT_RX) {\r\nqueue = (status >> 8) & 7;\r\nif (napi_schedule_prep(&priv->napi)) {\r\ncpmac_write(priv->regs, CPMAC_RX_INT_CLEAR, 1 << queue);\r\n__napi_schedule(&priv->napi);\r\n}\r\n}\r\ncpmac_write(priv->regs, CPMAC_MAC_EOI_VECTOR, 0);\r\nif (unlikely(status & (MAC_INT_HOST | MAC_INT_STATUS)))\r\ncpmac_check_status(dev);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void cpmac_tx_timeout(struct net_device *dev)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nspin_lock(&priv->lock);\r\ndev->stats.tx_errors++;\r\nspin_unlock(&priv->lock);\r\nif (netif_msg_tx_err(priv) && net_ratelimit())\r\nnetdev_warn(dev, "transmit timeout\n");\r\natomic_inc(&priv->reset_pending);\r\nbarrier();\r\ncpmac_clear_tx(dev);\r\nbarrier();\r\natomic_dec(&priv->reset_pending);\r\nnetif_tx_wake_all_queues(priv->dev);\r\n}\r\nstatic int cpmac_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nif (!(netif_running(dev)))\r\nreturn -EINVAL;\r\nif (!dev->phydev)\r\nreturn -EINVAL;\r\nreturn phy_mii_ioctl(dev->phydev, ifr, cmd);\r\n}\r\nstatic void cpmac_get_ringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *ring)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nring->rx_max_pending = 1024;\r\nring->rx_mini_max_pending = 1;\r\nring->rx_jumbo_max_pending = 1;\r\nring->tx_max_pending = 1;\r\nring->rx_pending = priv->ring_size;\r\nring->rx_mini_pending = 1;\r\nring->rx_jumbo_pending = 1;\r\nring->tx_pending = 1;\r\n}\r\nstatic int cpmac_set_ringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *ring)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nif (netif_running(dev))\r\nreturn -EBUSY;\r\npriv->ring_size = ring->rx_pending;\r\nreturn 0;\r\n}\r\nstatic void cpmac_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstrlcpy(info->driver, "cpmac", sizeof(info->driver));\r\nstrlcpy(info->version, CPMAC_VERSION, sizeof(info->version));\r\nsnprintf(info->bus_info, sizeof(info->bus_info), "%s", "cpmac");\r\n}\r\nstatic void cpmac_adjust_link(struct net_device *dev)\r\n{\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nint new_state = 0;\r\nspin_lock(&priv->lock);\r\nif (dev->phydev->link) {\r\nnetif_tx_start_all_queues(dev);\r\nif (dev->phydev->duplex != priv->oldduplex) {\r\nnew_state = 1;\r\npriv->oldduplex = dev->phydev->duplex;\r\n}\r\nif (dev->phydev->speed != priv->oldspeed) {\r\nnew_state = 1;\r\npriv->oldspeed = dev->phydev->speed;\r\n}\r\nif (!priv->oldlink) {\r\nnew_state = 1;\r\npriv->oldlink = 1;\r\n}\r\n} else if (priv->oldlink) {\r\nnew_state = 1;\r\npriv->oldlink = 0;\r\npriv->oldspeed = 0;\r\npriv->oldduplex = -1;\r\n}\r\nif (new_state && netif_msg_link(priv) && net_ratelimit())\r\nphy_print_status(dev->phydev);\r\nspin_unlock(&priv->lock);\r\n}\r\nstatic int cpmac_open(struct net_device *dev)\r\n{\r\nint i, size, res;\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nstruct resource *mem;\r\nstruct cpmac_desc *desc;\r\nstruct sk_buff *skb;\r\nmem = platform_get_resource_byname(priv->pdev, IORESOURCE_MEM, "regs");\r\nif (!request_mem_region(mem->start, resource_size(mem), dev->name)) {\r\nif (netif_msg_drv(priv))\r\nnetdev_err(dev, "failed to request registers\n");\r\nres = -ENXIO;\r\ngoto fail_reserve;\r\n}\r\npriv->regs = ioremap(mem->start, resource_size(mem));\r\nif (!priv->regs) {\r\nif (netif_msg_drv(priv))\r\nnetdev_err(dev, "failed to remap registers\n");\r\nres = -ENXIO;\r\ngoto fail_remap;\r\n}\r\nsize = priv->ring_size + CPMAC_QUEUES;\r\npriv->desc_ring = dma_alloc_coherent(&dev->dev,\r\nsizeof(struct cpmac_desc) * size,\r\n&priv->dma_ring,\r\nGFP_KERNEL);\r\nif (!priv->desc_ring) {\r\nres = -ENOMEM;\r\ngoto fail_alloc;\r\n}\r\nfor (i = 0; i < size; i++)\r\npriv->desc_ring[i].mapping = priv->dma_ring + sizeof(*desc) * i;\r\npriv->rx_head = &priv->desc_ring[CPMAC_QUEUES];\r\nfor (i = 0, desc = priv->rx_head; i < priv->ring_size; i++, desc++) {\r\nskb = netdev_alloc_skb_ip_align(dev, CPMAC_SKB_SIZE);\r\nif (unlikely(!skb)) {\r\nres = -ENOMEM;\r\ngoto fail_desc;\r\n}\r\ndesc->skb = skb;\r\ndesc->data_mapping = dma_map_single(&dev->dev, skb->data,\r\nCPMAC_SKB_SIZE,\r\nDMA_FROM_DEVICE);\r\ndesc->hw_data = (u32)desc->data_mapping;\r\ndesc->buflen = CPMAC_SKB_SIZE;\r\ndesc->dataflags = CPMAC_OWN;\r\ndesc->next = &priv->rx_head[(i + 1) % priv->ring_size];\r\ndesc->next->prev = desc;\r\ndesc->hw_next = (u32)desc->next->mapping;\r\n}\r\npriv->rx_head->prev->hw_next = (u32)0;\r\nres = request_irq(dev->irq, cpmac_irq, IRQF_SHARED, dev->name, dev);\r\nif (res) {\r\nif (netif_msg_drv(priv))\r\nnetdev_err(dev, "failed to obtain irq\n");\r\ngoto fail_irq;\r\n}\r\natomic_set(&priv->reset_pending, 0);\r\nINIT_WORK(&priv->reset_work, cpmac_hw_error);\r\ncpmac_hw_start(dev);\r\nnapi_enable(&priv->napi);\r\ndev->phydev->state = PHY_CHANGELINK;\r\nphy_start(dev->phydev);\r\nreturn 0;\r\nfail_irq:\r\nfail_desc:\r\nfor (i = 0; i < priv->ring_size; i++) {\r\nif (priv->rx_head[i].skb) {\r\ndma_unmap_single(&dev->dev,\r\npriv->rx_head[i].data_mapping,\r\nCPMAC_SKB_SIZE,\r\nDMA_FROM_DEVICE);\r\nkfree_skb(priv->rx_head[i].skb);\r\n}\r\n}\r\ndma_free_coherent(&dev->dev, sizeof(struct cpmac_desc) * size,\r\npriv->desc_ring, priv->dma_ring);\r\nfail_alloc:\r\niounmap(priv->regs);\r\nfail_remap:\r\nrelease_mem_region(mem->start, resource_size(mem));\r\nfail_reserve:\r\nreturn res;\r\n}\r\nstatic int cpmac_stop(struct net_device *dev)\r\n{\r\nint i;\r\nstruct cpmac_priv *priv = netdev_priv(dev);\r\nstruct resource *mem;\r\nnetif_tx_stop_all_queues(dev);\r\ncancel_work_sync(&priv->reset_work);\r\nnapi_disable(&priv->napi);\r\nphy_stop(dev->phydev);\r\ncpmac_hw_stop(dev);\r\nfor (i = 0; i < 8; i++)\r\ncpmac_write(priv->regs, CPMAC_TX_PTR(i), 0);\r\ncpmac_write(priv->regs, CPMAC_RX_PTR(0), 0);\r\ncpmac_write(priv->regs, CPMAC_MBP, 0);\r\nfree_irq(dev->irq, dev);\r\niounmap(priv->regs);\r\nmem = platform_get_resource_byname(priv->pdev, IORESOURCE_MEM, "regs");\r\nrelease_mem_region(mem->start, resource_size(mem));\r\npriv->rx_head = &priv->desc_ring[CPMAC_QUEUES];\r\nfor (i = 0; i < priv->ring_size; i++) {\r\nif (priv->rx_head[i].skb) {\r\ndma_unmap_single(&dev->dev,\r\npriv->rx_head[i].data_mapping,\r\nCPMAC_SKB_SIZE,\r\nDMA_FROM_DEVICE);\r\nkfree_skb(priv->rx_head[i].skb);\r\n}\r\n}\r\ndma_free_coherent(&dev->dev, sizeof(struct cpmac_desc) *\r\n(CPMAC_QUEUES + priv->ring_size),\r\npriv->desc_ring, priv->dma_ring);\r\nreturn 0;\r\n}\r\nstatic int cpmac_probe(struct platform_device *pdev)\r\n{\r\nint rc, phy_id;\r\nchar mdio_bus_id[MII_BUS_ID_SIZE];\r\nstruct resource *mem;\r\nstruct cpmac_priv *priv;\r\nstruct net_device *dev;\r\nstruct plat_cpmac_data *pdata;\r\nstruct phy_device *phydev = NULL;\r\npdata = dev_get_platdata(&pdev->dev);\r\nif (external_switch || dumb_switch) {\r\nstrncpy(mdio_bus_id, "fixed-0", MII_BUS_ID_SIZE);\r\nphy_id = pdev->id;\r\n} else {\r\nfor (phy_id = 0; phy_id < PHY_MAX_ADDR; phy_id++) {\r\nif (!(pdata->phy_mask & (1 << phy_id)))\r\ncontinue;\r\nif (!mdiobus_get_phy(cpmac_mii, phy_id))\r\ncontinue;\r\nstrncpy(mdio_bus_id, cpmac_mii->id, MII_BUS_ID_SIZE);\r\nbreak;\r\n}\r\n}\r\nif (phy_id == PHY_MAX_ADDR) {\r\ndev_err(&pdev->dev, "no PHY present, falling back "\r\n"to switch on MDIO bus 0\n");\r\nstrncpy(mdio_bus_id, "fixed-0", MII_BUS_ID_SIZE);\r\nphy_id = pdev->id;\r\n}\r\nmdio_bus_id[sizeof(mdio_bus_id) - 1] = '\0';\r\ndev = alloc_etherdev_mq(sizeof(*priv), CPMAC_QUEUES);\r\nif (!dev)\r\nreturn -ENOMEM;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nplatform_set_drvdata(pdev, dev);\r\npriv = netdev_priv(dev);\r\npriv->pdev = pdev;\r\nmem = platform_get_resource_byname(pdev, IORESOURCE_MEM, "regs");\r\nif (!mem) {\r\nrc = -ENODEV;\r\ngoto fail;\r\n}\r\ndev->irq = platform_get_irq_byname(pdev, "irq");\r\ndev->netdev_ops = &cpmac_netdev_ops;\r\ndev->ethtool_ops = &cpmac_ethtool_ops;\r\nnetif_napi_add(dev, &priv->napi, cpmac_poll, 64);\r\nspin_lock_init(&priv->lock);\r\nspin_lock_init(&priv->rx_lock);\r\npriv->dev = dev;\r\npriv->ring_size = 64;\r\npriv->msg_enable = netif_msg_init(debug_level, 0xff);\r\nmemcpy(dev->dev_addr, pdata->dev_addr, sizeof(pdata->dev_addr));\r\nsnprintf(priv->phy_name, MII_BUS_ID_SIZE, PHY_ID_FMT,\r\nmdio_bus_id, phy_id);\r\nphydev = phy_connect(dev, priv->phy_name, cpmac_adjust_link,\r\nPHY_INTERFACE_MODE_MII);\r\nif (IS_ERR(phydev)) {\r\nif (netif_msg_drv(priv))\r\ndev_err(&pdev->dev, "Could not attach to PHY\n");\r\nrc = PTR_ERR(phydev);\r\ngoto fail;\r\n}\r\nrc = register_netdev(dev);\r\nif (rc) {\r\ndev_err(&pdev->dev, "Could not register net device\n");\r\ngoto fail;\r\n}\r\nif (netif_msg_probe(priv)) {\r\ndev_info(&pdev->dev, "regs: %p, irq: %d, phy: %s, "\r\n"mac: %pM\n", (void *)mem->start, dev->irq,\r\npriv->phy_name, dev->dev_addr);\r\n}\r\nreturn 0;\r\nfail:\r\nfree_netdev(dev);\r\nreturn rc;\r\n}\r\nstatic int cpmac_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *dev = platform_get_drvdata(pdev);\r\nunregister_netdev(dev);\r\nfree_netdev(dev);\r\nreturn 0;\r\n}\r\nint cpmac_init(void)\r\n{\r\nu32 mask;\r\nint i, res;\r\ncpmac_mii = mdiobus_alloc();\r\nif (cpmac_mii == NULL)\r\nreturn -ENOMEM;\r\ncpmac_mii->name = "cpmac-mii";\r\ncpmac_mii->read = cpmac_mdio_read;\r\ncpmac_mii->write = cpmac_mdio_write;\r\ncpmac_mii->reset = cpmac_mdio_reset;\r\ncpmac_mii->priv = ioremap(AR7_REGS_MDIO, 256);\r\nif (!cpmac_mii->priv) {\r\npr_err("Can't ioremap mdio registers\n");\r\nres = -ENXIO;\r\ngoto fail_alloc;\r\n}\r\nar7_gpio_disable(26);\r\nar7_gpio_disable(27);\r\nar7_device_reset(AR7_RESET_BIT_CPMAC_LO);\r\nar7_device_reset(AR7_RESET_BIT_CPMAC_HI);\r\nar7_device_reset(AR7_RESET_BIT_EPHY);\r\ncpmac_mii->reset(cpmac_mii);\r\nfor (i = 0; i < 300; i++) {\r\nmask = cpmac_read(cpmac_mii->priv, CPMAC_MDIO_ALIVE);\r\nif (mask)\r\nbreak;\r\nelse\r\nmsleep(10);\r\n}\r\nmask &= 0x7fffffff;\r\nif (mask & (mask - 1)) {\r\nexternal_switch = 1;\r\nmask = 0;\r\n}\r\ncpmac_mii->phy_mask = ~(mask | 0x80000000);\r\nsnprintf(cpmac_mii->id, MII_BUS_ID_SIZE, "cpmac-1");\r\nres = mdiobus_register(cpmac_mii);\r\nif (res)\r\ngoto fail_mii;\r\nres = platform_driver_register(&cpmac_driver);\r\nif (res)\r\ngoto fail_cpmac;\r\nreturn 0;\r\nfail_cpmac:\r\nmdiobus_unregister(cpmac_mii);\r\nfail_mii:\r\niounmap(cpmac_mii->priv);\r\nfail_alloc:\r\nmdiobus_free(cpmac_mii);\r\nreturn res;\r\n}\r\nvoid cpmac_exit(void)\r\n{\r\nplatform_driver_unregister(&cpmac_driver);\r\nmdiobus_unregister(cpmac_mii);\r\niounmap(cpmac_mii->priv);\r\nmdiobus_free(cpmac_mii);\r\n}
