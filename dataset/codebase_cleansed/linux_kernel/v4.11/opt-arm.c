int arch_prepared_optinsn(struct arch_optimized_insn *optinsn)\r\n{\r\nreturn optinsn->insn != NULL;\r\n}\r\nint arch_check_optimized_kprobe(struct optimized_kprobe *op)\r\n{\r\nreturn 0;\r\n}\r\nstatic int can_optimize(struct kprobe *kp)\r\n{\r\nif (kp->ainsn.stack_space < 0)\r\nreturn 0;\r\nif (kp->ainsn.stack_space > 255 - sizeof(struct pt_regs))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic void\r\n__arch_remove_optimized_kprobe(struct optimized_kprobe *op, int dirty)\r\n{\r\nif (op->optinsn.insn) {\r\nfree_optinsn_slot(op->optinsn.insn, dirty);\r\nop->optinsn.insn = NULL;\r\n}\r\n}\r\nstatic void\r\noptimized_callback(struct optimized_kprobe *op, struct pt_regs *regs)\r\n{\r\nunsigned long flags;\r\nstruct kprobe *p = &op->kp;\r\nstruct kprobe_ctlblk *kcb = get_kprobe_ctlblk();\r\nregs->ARM_pc = (unsigned long)op->kp.addr;\r\nregs->ARM_ORIG_r0 = ~0UL;\r\nlocal_irq_save(flags);\r\nif (kprobe_running()) {\r\nkprobes_inc_nmissed_count(&op->kp);\r\n} else {\r\n__this_cpu_write(current_kprobe, &op->kp);\r\nkcb->kprobe_status = KPROBE_HIT_ACTIVE;\r\nopt_pre_handler(&op->kp, regs);\r\n__this_cpu_write(current_kprobe, NULL);\r\n}\r\nif (!p->ainsn.kprobe_direct_exec)\r\nop->kp.ainsn.insn_singlestep(p->opcode, &p->ainsn, regs);\r\nlocal_irq_restore(flags);\r\n}\r\nint arch_prepare_optimized_kprobe(struct optimized_kprobe *op, struct kprobe *orig)\r\n{\r\nkprobe_opcode_t *code;\r\nunsigned long rel_chk;\r\nunsigned long val;\r\nunsigned long stack_protect = sizeof(struct pt_regs);\r\nif (!can_optimize(orig))\r\nreturn -EILSEQ;\r\ncode = get_optinsn_slot();\r\nif (!code)\r\nreturn -ENOMEM;\r\nrel_chk = (unsigned long)((long)code -\r\n(long)orig->addr + 8) & 0xfe000003;\r\nif ((rel_chk != 0) && (rel_chk != 0xfe000000)) {\r\nfree_optinsn_slot(code, 0);\r\nreturn -ERANGE;\r\n}\r\nmemcpy(code, &optprobe_template_entry,\r\nTMPL_END_IDX * sizeof(kprobe_opcode_t));\r\nBUG_ON(orig->ainsn.stack_space < 0);\r\nstack_protect += orig->ainsn.stack_space;\r\nBUG_ON(stack_protect > 255);\r\ncode[TMPL_SUB_SP] = __opcode_to_mem_arm(0xe24dd000 | stack_protect);\r\ncode[TMPL_ADD_SP] = __opcode_to_mem_arm(0xe28d3000 | stack_protect);\r\nval = (unsigned long)op;\r\ncode[TMPL_VAL_IDX] = val;\r\nval = (unsigned long)optimized_callback;\r\ncode[TMPL_CALL_IDX] = val;\r\norig->ainsn.kprobe_direct_exec = false;\r\nif (can_kprobe_direct_exec(orig->ainsn.register_usage_flags)) {\r\nkprobe_opcode_t final_branch = arm_gen_branch(\r\n(unsigned long)(&code[TMPL_RESTORE_END]),\r\n(unsigned long)(op->kp.addr) + 4);\r\nif (final_branch != 0) {\r\ncode[TMPL_RESTORE_BEGIN] = __opcode_to_mem_arm(0xe89d7fff);\r\ncode[TMPL_RESTORE_ORIGN_INSN] = __opcode_to_mem_arm(orig->opcode);\r\ncode[TMPL_RESTORE_END] = __opcode_to_mem_arm(final_branch);\r\norig->ainsn.kprobe_direct_exec = true;\r\n}\r\n}\r\nflush_icache_range((unsigned long)code,\r\n(unsigned long)(&code[TMPL_END_IDX]));\r\nop->optinsn.insn = code;\r\nreturn 0;\r\n}\r\nvoid __kprobes arch_optimize_kprobes(struct list_head *oplist)\r\n{\r\nstruct optimized_kprobe *op, *tmp;\r\nlist_for_each_entry_safe(op, tmp, oplist, list) {\r\nunsigned long insn;\r\nWARN_ON(kprobe_disabled(&op->kp));\r\nmemcpy(op->optinsn.copied_insn, op->kp.addr,\r\nRELATIVEJUMP_SIZE);\r\ninsn = arm_gen_branch((unsigned long)op->kp.addr,\r\n(unsigned long)op->optinsn.insn);\r\nBUG_ON(insn == 0);\r\ninsn = (__mem_to_opcode_arm(\r\nop->optinsn.copied_insn[0]) & 0xf0000000) |\r\n(insn & 0x0fffffff);\r\nkprobes_remove_breakpoint(op->kp.addr, insn);\r\nlist_del_init(&op->list);\r\n}\r\n}\r\nvoid arch_unoptimize_kprobe(struct optimized_kprobe *op)\r\n{\r\narch_arm_kprobe(&op->kp);\r\n}\r\nvoid arch_unoptimize_kprobes(struct list_head *oplist,\r\nstruct list_head *done_list)\r\n{\r\nstruct optimized_kprobe *op, *tmp;\r\nlist_for_each_entry_safe(op, tmp, oplist, list) {\r\narch_unoptimize_kprobe(op);\r\nlist_move(&op->list, done_list);\r\n}\r\n}\r\nint arch_within_optimized_kprobe(struct optimized_kprobe *op,\r\nunsigned long addr)\r\n{\r\nreturn ((unsigned long)op->kp.addr <= addr &&\r\n(unsigned long)op->kp.addr + RELATIVEJUMP_SIZE > addr);\r\n}\r\nvoid arch_remove_optimized_kprobe(struct optimized_kprobe *op)\r\n{\r\n__arch_remove_optimized_kprobe(op, 1);\r\n}
