static struct rds_cong_map *rds_cong_tree_walk(__be32 addr,\r\nstruct rds_cong_map *insert)\r\n{\r\nstruct rb_node **p = &rds_cong_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct rds_cong_map *map;\r\nwhile (*p) {\r\nparent = *p;\r\nmap = rb_entry(parent, struct rds_cong_map, m_rb_node);\r\nif (addr < map->m_addr)\r\np = &(*p)->rb_left;\r\nelse if (addr > map->m_addr)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn map;\r\n}\r\nif (insert) {\r\nrb_link_node(&insert->m_rb_node, parent, p);\r\nrb_insert_color(&insert->m_rb_node, &rds_cong_tree);\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct rds_cong_map *rds_cong_from_addr(__be32 addr)\r\n{\r\nstruct rds_cong_map *map;\r\nstruct rds_cong_map *ret = NULL;\r\nunsigned long zp;\r\nunsigned long i;\r\nunsigned long flags;\r\nmap = kzalloc(sizeof(struct rds_cong_map), GFP_KERNEL);\r\nif (!map)\r\nreturn NULL;\r\nmap->m_addr = addr;\r\ninit_waitqueue_head(&map->m_waitq);\r\nINIT_LIST_HEAD(&map->m_conn_list);\r\nfor (i = 0; i < RDS_CONG_MAP_PAGES; i++) {\r\nzp = get_zeroed_page(GFP_KERNEL);\r\nif (zp == 0)\r\ngoto out;\r\nmap->m_page_addrs[i] = zp;\r\n}\r\nspin_lock_irqsave(&rds_cong_lock, flags);\r\nret = rds_cong_tree_walk(addr, map);\r\nspin_unlock_irqrestore(&rds_cong_lock, flags);\r\nif (!ret) {\r\nret = map;\r\nmap = NULL;\r\n}\r\nout:\r\nif (map) {\r\nfor (i = 0; i < RDS_CONG_MAP_PAGES && map->m_page_addrs[i]; i++)\r\nfree_page(map->m_page_addrs[i]);\r\nkfree(map);\r\n}\r\nrdsdebug("map %p for addr %x\n", ret, be32_to_cpu(addr));\r\nreturn ret;\r\n}\r\nvoid rds_cong_add_conn(struct rds_connection *conn)\r\n{\r\nunsigned long flags;\r\nrdsdebug("conn %p now on map %p\n", conn, conn->c_lcong);\r\nspin_lock_irqsave(&rds_cong_lock, flags);\r\nlist_add_tail(&conn->c_map_item, &conn->c_lcong->m_conn_list);\r\nspin_unlock_irqrestore(&rds_cong_lock, flags);\r\n}\r\nvoid rds_cong_remove_conn(struct rds_connection *conn)\r\n{\r\nunsigned long flags;\r\nrdsdebug("removing conn %p from map %p\n", conn, conn->c_lcong);\r\nspin_lock_irqsave(&rds_cong_lock, flags);\r\nlist_del_init(&conn->c_map_item);\r\nspin_unlock_irqrestore(&rds_cong_lock, flags);\r\n}\r\nint rds_cong_get_maps(struct rds_connection *conn)\r\n{\r\nconn->c_lcong = rds_cong_from_addr(conn->c_laddr);\r\nconn->c_fcong = rds_cong_from_addr(conn->c_faddr);\r\nif (!(conn->c_lcong && conn->c_fcong))\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid rds_cong_queue_updates(struct rds_cong_map *map)\r\n{\r\nstruct rds_connection *conn;\r\nunsigned long flags;\r\nspin_lock_irqsave(&rds_cong_lock, flags);\r\nlist_for_each_entry(conn, &map->m_conn_list, c_map_item) {\r\nif (!test_and_set_bit(0, &conn->c_map_queued)) {\r\nrds_stats_inc(s_cong_update_queued);\r\nqueue_delayed_work(rds_wq,\r\n&conn->c_path[0].cp_send_w, 0);\r\n}\r\n}\r\nspin_unlock_irqrestore(&rds_cong_lock, flags);\r\n}\r\nvoid rds_cong_map_updated(struct rds_cong_map *map, uint64_t portmask)\r\n{\r\nrdsdebug("waking map %p for %pI4\n",\r\nmap, &map->m_addr);\r\nrds_stats_inc(s_cong_update_received);\r\natomic_inc(&rds_cong_generation);\r\nif (waitqueue_active(&map->m_waitq))\r\nwake_up(&map->m_waitq);\r\nif (waitqueue_active(&rds_poll_waitq))\r\nwake_up_all(&rds_poll_waitq);\r\nif (portmask && !list_empty(&rds_cong_monitor)) {\r\nunsigned long flags;\r\nstruct rds_sock *rs;\r\nread_lock_irqsave(&rds_cong_monitor_lock, flags);\r\nlist_for_each_entry(rs, &rds_cong_monitor, rs_cong_list) {\r\nspin_lock(&rs->rs_lock);\r\nrs->rs_cong_notify |= (rs->rs_cong_mask & portmask);\r\nrs->rs_cong_mask &= ~portmask;\r\nspin_unlock(&rs->rs_lock);\r\nif (rs->rs_cong_notify)\r\nrds_wake_sk_sleep(rs);\r\n}\r\nread_unlock_irqrestore(&rds_cong_monitor_lock, flags);\r\n}\r\n}\r\nint rds_cong_updated_since(unsigned long *recent)\r\n{\r\nunsigned long gen = atomic_read(&rds_cong_generation);\r\nif (likely(*recent == gen))\r\nreturn 0;\r\n*recent = gen;\r\nreturn 1;\r\n}\r\nvoid rds_cong_set_bit(struct rds_cong_map *map, __be16 port)\r\n{\r\nunsigned long i;\r\nunsigned long off;\r\nrdsdebug("setting congestion for %pI4:%u in map %p\n",\r\n&map->m_addr, ntohs(port), map);\r\ni = be16_to_cpu(port) / RDS_CONG_MAP_PAGE_BITS;\r\noff = be16_to_cpu(port) % RDS_CONG_MAP_PAGE_BITS;\r\nset_bit_le(off, (void *)map->m_page_addrs[i]);\r\n}\r\nvoid rds_cong_clear_bit(struct rds_cong_map *map, __be16 port)\r\n{\r\nunsigned long i;\r\nunsigned long off;\r\nrdsdebug("clearing congestion for %pI4:%u in map %p\n",\r\n&map->m_addr, ntohs(port), map);\r\ni = be16_to_cpu(port) / RDS_CONG_MAP_PAGE_BITS;\r\noff = be16_to_cpu(port) % RDS_CONG_MAP_PAGE_BITS;\r\nclear_bit_le(off, (void *)map->m_page_addrs[i]);\r\n}\r\nstatic int rds_cong_test_bit(struct rds_cong_map *map, __be16 port)\r\n{\r\nunsigned long i;\r\nunsigned long off;\r\ni = be16_to_cpu(port) / RDS_CONG_MAP_PAGE_BITS;\r\noff = be16_to_cpu(port) % RDS_CONG_MAP_PAGE_BITS;\r\nreturn test_bit_le(off, (void *)map->m_page_addrs[i]);\r\n}\r\nvoid rds_cong_add_socket(struct rds_sock *rs)\r\n{\r\nunsigned long flags;\r\nwrite_lock_irqsave(&rds_cong_monitor_lock, flags);\r\nif (list_empty(&rs->rs_cong_list))\r\nlist_add(&rs->rs_cong_list, &rds_cong_monitor);\r\nwrite_unlock_irqrestore(&rds_cong_monitor_lock, flags);\r\n}\r\nvoid rds_cong_remove_socket(struct rds_sock *rs)\r\n{\r\nunsigned long flags;\r\nstruct rds_cong_map *map;\r\nwrite_lock_irqsave(&rds_cong_monitor_lock, flags);\r\nlist_del_init(&rs->rs_cong_list);\r\nwrite_unlock_irqrestore(&rds_cong_monitor_lock, flags);\r\nspin_lock_irqsave(&rds_cong_lock, flags);\r\nmap = rds_cong_tree_walk(rs->rs_bound_addr, NULL);\r\nspin_unlock_irqrestore(&rds_cong_lock, flags);\r\nif (map && rds_cong_test_bit(map, rs->rs_bound_port)) {\r\nrds_cong_clear_bit(map, rs->rs_bound_port);\r\nrds_cong_queue_updates(map);\r\n}\r\n}\r\nint rds_cong_wait(struct rds_cong_map *map, __be16 port, int nonblock,\r\nstruct rds_sock *rs)\r\n{\r\nif (!rds_cong_test_bit(map, port))\r\nreturn 0;\r\nif (nonblock) {\r\nif (rs && rs->rs_cong_monitor) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&rs->rs_lock, flags);\r\nrs->rs_cong_mask |= RDS_CONG_MONITOR_MASK(ntohs(port));\r\nspin_unlock_irqrestore(&rs->rs_lock, flags);\r\nif (!rds_cong_test_bit(map, port))\r\nreturn 0;\r\n}\r\nrds_stats_inc(s_cong_send_error);\r\nreturn -ENOBUFS;\r\n}\r\nrds_stats_inc(s_cong_send_blocked);\r\nrdsdebug("waiting on map %p for port %u\n", map, be16_to_cpu(port));\r\nreturn wait_event_interruptible(map->m_waitq,\r\n!rds_cong_test_bit(map, port));\r\n}\r\nvoid rds_cong_exit(void)\r\n{\r\nstruct rb_node *node;\r\nstruct rds_cong_map *map;\r\nunsigned long i;\r\nwhile ((node = rb_first(&rds_cong_tree))) {\r\nmap = rb_entry(node, struct rds_cong_map, m_rb_node);\r\nrdsdebug("freeing map %p\n", map);\r\nrb_erase(&map->m_rb_node, &rds_cong_tree);\r\nfor (i = 0; i < RDS_CONG_MAP_PAGES && map->m_page_addrs[i]; i++)\r\nfree_page(map->m_page_addrs[i]);\r\nkfree(map);\r\n}\r\n}\r\nstruct rds_message *rds_cong_update_alloc(struct rds_connection *conn)\r\n{\r\nstruct rds_cong_map *map = conn->c_lcong;\r\nstruct rds_message *rm;\r\nrm = rds_message_map_pages(map->m_page_addrs, RDS_CONG_MAP_BYTES);\r\nif (!IS_ERR(rm))\r\nrm->m_inc.i_hdr.h_flags = RDS_FLAG_CONG_BITMAP;\r\nreturn rm;\r\n}
