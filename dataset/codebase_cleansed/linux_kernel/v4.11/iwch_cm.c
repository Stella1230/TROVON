static void start_ep_timer(struct iwch_ep *ep)\r\n{\r\nPDBG("%s ep %p\n", __func__, ep);\r\nif (timer_pending(&ep->timer)) {\r\nPDBG("%s stopped / restarted timer ep %p\n", __func__, ep);\r\ndel_timer_sync(&ep->timer);\r\n} else\r\nget_ep(&ep->com);\r\nep->timer.expires = jiffies + ep_timeout_secs * HZ;\r\nep->timer.data = (unsigned long)ep;\r\nep->timer.function = ep_timeout;\r\nadd_timer(&ep->timer);\r\n}\r\nstatic void stop_ep_timer(struct iwch_ep *ep)\r\n{\r\nPDBG("%s ep %p\n", __func__, ep);\r\nif (!timer_pending(&ep->timer)) {\r\nWARN(1, "%s timer stopped when its not running! ep %p state %u\n",\r\n__func__, ep, ep->com.state);\r\nreturn;\r\n}\r\ndel_timer_sync(&ep->timer);\r\nput_ep(&ep->com);\r\n}\r\nstatic int iwch_l2t_send(struct t3cdev *tdev, struct sk_buff *skb, struct l2t_entry *l2e)\r\n{\r\nint error = 0;\r\nstruct cxio_rdev *rdev;\r\nrdev = (struct cxio_rdev *)tdev->ulp;\r\nif (cxio_fatal_error(rdev)) {\r\nkfree_skb(skb);\r\nreturn -EIO;\r\n}\r\nerror = l2t_send(tdev, skb, l2e);\r\nif (error < 0)\r\nkfree_skb(skb);\r\nreturn error < 0 ? error : 0;\r\n}\r\nint iwch_cxgb3_ofld_send(struct t3cdev *tdev, struct sk_buff *skb)\r\n{\r\nint error = 0;\r\nstruct cxio_rdev *rdev;\r\nrdev = (struct cxio_rdev *)tdev->ulp;\r\nif (cxio_fatal_error(rdev)) {\r\nkfree_skb(skb);\r\nreturn -EIO;\r\n}\r\nerror = cxgb3_ofld_send(tdev, skb);\r\nif (error < 0)\r\nkfree_skb(skb);\r\nreturn error < 0 ? error : 0;\r\n}\r\nstatic void release_tid(struct t3cdev *tdev, u32 hwtid, struct sk_buff *skb)\r\n{\r\nstruct cpl_tid_release *req;\r\nskb = get_skb(skb, sizeof *req, GFP_KERNEL);\r\nif (!skb)\r\nreturn;\r\nreq = (struct cpl_tid_release *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_TID_RELEASE, hwtid));\r\nskb->priority = CPL_PRIORITY_SETUP;\r\niwch_cxgb3_ofld_send(tdev, skb);\r\nreturn;\r\n}\r\nint iwch_quiesce_tid(struct iwch_ep *ep)\r\n{\r\nstruct cpl_set_tcb_field *req;\r\nstruct sk_buff *skb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nreq = (struct cpl_set_tcb_field *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nreq->wr.wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SET_TCB_FIELD, ep->hwtid));\r\nreq->reply = 0;\r\nreq->cpu_idx = 0;\r\nreq->word = htons(W_TCB_RX_QUIESCE);\r\nreq->mask = cpu_to_be64(1ULL << S_TCB_RX_QUIESCE);\r\nreq->val = cpu_to_be64(1 << S_TCB_RX_QUIESCE);\r\nskb->priority = CPL_PRIORITY_DATA;\r\nreturn iwch_cxgb3_ofld_send(ep->com.tdev, skb);\r\n}\r\nint iwch_resume_tid(struct iwch_ep *ep)\r\n{\r\nstruct cpl_set_tcb_field *req;\r\nstruct sk_buff *skb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nreq = (struct cpl_set_tcb_field *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nreq->wr.wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SET_TCB_FIELD, ep->hwtid));\r\nreq->reply = 0;\r\nreq->cpu_idx = 0;\r\nreq->word = htons(W_TCB_RX_QUIESCE);\r\nreq->mask = cpu_to_be64(1ULL << S_TCB_RX_QUIESCE);\r\nreq->val = 0;\r\nskb->priority = CPL_PRIORITY_DATA;\r\nreturn iwch_cxgb3_ofld_send(ep->com.tdev, skb);\r\n}\r\nstatic void set_emss(struct iwch_ep *ep, u16 opt)\r\n{\r\nPDBG("%s ep %p opt %u\n", __func__, ep, opt);\r\nep->emss = T3C_DATA(ep->com.tdev)->mtus[G_TCPOPT_MSS(opt)] - 40;\r\nif (G_TCPOPT_TSTAMP(opt))\r\nep->emss -= 12;\r\nif (ep->emss < 128)\r\nep->emss = 128;\r\nPDBG("emss=%d\n", ep->emss);\r\n}\r\nstatic enum iwch_ep_state state_read(struct iwch_ep_common *epc)\r\n{\r\nunsigned long flags;\r\nenum iwch_ep_state state;\r\nspin_lock_irqsave(&epc->lock, flags);\r\nstate = epc->state;\r\nspin_unlock_irqrestore(&epc->lock, flags);\r\nreturn state;\r\n}\r\nstatic void __state_set(struct iwch_ep_common *epc, enum iwch_ep_state new)\r\n{\r\nepc->state = new;\r\n}\r\nstatic void state_set(struct iwch_ep_common *epc, enum iwch_ep_state new)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&epc->lock, flags);\r\nPDBG("%s - %s -> %s\n", __func__, states[epc->state], states[new]);\r\n__state_set(epc, new);\r\nspin_unlock_irqrestore(&epc->lock, flags);\r\nreturn;\r\n}\r\nstatic void *alloc_ep(int size, gfp_t gfp)\r\n{\r\nstruct iwch_ep_common *epc;\r\nepc = kzalloc(size, gfp);\r\nif (epc) {\r\nkref_init(&epc->kref);\r\nspin_lock_init(&epc->lock);\r\ninit_waitqueue_head(&epc->waitq);\r\n}\r\nPDBG("%s alloc ep %p\n", __func__, epc);\r\nreturn epc;\r\n}\r\nvoid __free_ep(struct kref *kref)\r\n{\r\nstruct iwch_ep *ep;\r\nep = container_of(container_of(kref, struct iwch_ep_common, kref),\r\nstruct iwch_ep, com);\r\nPDBG("%s ep %p state %s\n", __func__, ep, states[state_read(&ep->com)]);\r\nif (test_bit(RELEASE_RESOURCES, &ep->com.flags)) {\r\ncxgb3_remove_tid(ep->com.tdev, (void *)ep, ep->hwtid);\r\ndst_release(ep->dst);\r\nl2t_release(ep->com.tdev, ep->l2t);\r\n}\r\nkfree(ep);\r\n}\r\nstatic void release_ep_resources(struct iwch_ep *ep)\r\n{\r\nPDBG("%s ep %p tid %d\n", __func__, ep, ep->hwtid);\r\nset_bit(RELEASE_RESOURCES, &ep->com.flags);\r\nput_ep(&ep->com);\r\n}\r\nstatic int status2errno(int status)\r\n{\r\nswitch (status) {\r\ncase CPL_ERR_NONE:\r\nreturn 0;\r\ncase CPL_ERR_CONN_RESET:\r\nreturn -ECONNRESET;\r\ncase CPL_ERR_ARP_MISS:\r\nreturn -EHOSTUNREACH;\r\ncase CPL_ERR_CONN_TIMEDOUT:\r\nreturn -ETIMEDOUT;\r\ncase CPL_ERR_TCAM_FULL:\r\nreturn -ENOMEM;\r\ncase CPL_ERR_CONN_EXIST:\r\nreturn -EADDRINUSE;\r\ndefault:\r\nreturn -EIO;\r\n}\r\n}\r\nstatic struct sk_buff *get_skb(struct sk_buff *skb, int len, gfp_t gfp)\r\n{\r\nif (skb && !skb_is_nonlinear(skb) && !skb_cloned(skb)) {\r\nskb_trim(skb, 0);\r\nskb_get(skb);\r\n} else {\r\nskb = alloc_skb(len, gfp);\r\n}\r\nreturn skb;\r\n}\r\nstatic struct rtable *find_route(struct t3cdev *dev, __be32 local_ip,\r\n__be32 peer_ip, __be16 local_port,\r\n__be16 peer_port, u8 tos)\r\n{\r\nstruct rtable *rt;\r\nstruct flowi4 fl4;\r\nrt = ip_route_output_ports(&init_net, &fl4, NULL, peer_ip, local_ip,\r\npeer_port, local_port, IPPROTO_TCP,\r\ntos, 0);\r\nif (IS_ERR(rt))\r\nreturn NULL;\r\nreturn rt;\r\n}\r\nstatic unsigned int find_best_mtu(const struct t3c_data *d, unsigned short mtu)\r\n{\r\nint i = 0;\r\nwhile (i < d->nmtus - 1 && d->mtus[i + 1] <= mtu)\r\n++i;\r\nreturn i;\r\n}\r\nstatic void arp_failure_discard(struct t3cdev *dev, struct sk_buff *skb)\r\n{\r\nPDBG("%s t3cdev %p\n", __func__, dev);\r\nkfree_skb(skb);\r\n}\r\nstatic void act_open_req_arp_failure(struct t3cdev *dev, struct sk_buff *skb)\r\n{\r\nprintk(KERN_ERR MOD "ARP failure during connect\n");\r\nkfree_skb(skb);\r\n}\r\nstatic void abort_arp_failure(struct t3cdev *dev, struct sk_buff *skb)\r\n{\r\nstruct cpl_abort_req *req = cplhdr(skb);\r\nPDBG("%s t3cdev %p\n", __func__, dev);\r\nreq->cmd = CPL_ABORT_NO_RST;\r\niwch_cxgb3_ofld_send(dev, skb);\r\n}\r\nstatic int send_halfclose(struct iwch_ep *ep, gfp_t gfp)\r\n{\r\nstruct cpl_close_con_req *req;\r\nstruct sk_buff *skb;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nskb = get_skb(NULL, sizeof(*req), gfp);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "%s - failed to alloc skb\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nskb->priority = CPL_PRIORITY_DATA;\r\nset_arp_failure_handler(skb, arp_failure_discard);\r\nreq = (struct cpl_close_con_req *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_CLOSE_CON));\r\nreq->wr.wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_CLOSE_CON_REQ, ep->hwtid));\r\nreturn iwch_l2t_send(ep->com.tdev, skb, ep->l2t);\r\n}\r\nstatic int send_abort(struct iwch_ep *ep, struct sk_buff *skb, gfp_t gfp)\r\n{\r\nstruct cpl_abort_req *req;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nskb = get_skb(skb, sizeof(*req), gfp);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "%s - failed to alloc skb.\n",\r\n__func__);\r\nreturn -ENOMEM;\r\n}\r\nskb->priority = CPL_PRIORITY_DATA;\r\nset_arp_failure_handler(skb, abort_arp_failure);\r\nreq = (struct cpl_abort_req *) skb_put(skb, sizeof(*req));\r\nmemset(req, 0, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_HOST_ABORT_CON_REQ));\r\nreq->wr.wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_ABORT_REQ, ep->hwtid));\r\nreq->cmd = CPL_ABORT_SEND_RST;\r\nreturn iwch_l2t_send(ep->com.tdev, skb, ep->l2t);\r\n}\r\nstatic int send_connect(struct iwch_ep *ep)\r\n{\r\nstruct cpl_act_open_req *req;\r\nstruct sk_buff *skb;\r\nu32 opt0h, opt0l, opt2;\r\nunsigned int mtu_idx;\r\nint wscale;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nskb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "%s - failed to alloc skb.\n",\r\n__func__);\r\nreturn -ENOMEM;\r\n}\r\nmtu_idx = find_best_mtu(T3C_DATA(ep->com.tdev), dst_mtu(ep->dst));\r\nwscale = compute_wscale(rcv_win);\r\nopt0h = V_NAGLE(0) |\r\nV_NO_CONG(nocong) |\r\nV_KEEP_ALIVE(1) |\r\nF_TCAM_BYPASS |\r\nV_WND_SCALE(wscale) |\r\nV_MSS_IDX(mtu_idx) |\r\nV_L2T_IDX(ep->l2t->idx) | V_TX_CHANNEL(ep->l2t->smt_idx);\r\nopt0l = V_TOS((ep->tos >> 2) & M_TOS) | V_RCV_BUFSIZ(rcv_win>>10);\r\nopt2 = F_RX_COALESCE_VALID | V_RX_COALESCE(0) | V_FLAVORS_VALID(1) |\r\nV_CONG_CONTROL_FLAVOR(cong_flavor);\r\nskb->priority = CPL_PRIORITY_SETUP;\r\nset_arp_failure_handler(skb, act_open_req_arp_failure);\r\nreq = (struct cpl_act_open_req *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_ACT_OPEN_REQ, ep->atid));\r\nreq->local_port = ep->com.local_addr.sin_port;\r\nreq->peer_port = ep->com.remote_addr.sin_port;\r\nreq->local_ip = ep->com.local_addr.sin_addr.s_addr;\r\nreq->peer_ip = ep->com.remote_addr.sin_addr.s_addr;\r\nreq->opt0h = htonl(opt0h);\r\nreq->opt0l = htonl(opt0l);\r\nreq->params = 0;\r\nreq->opt2 = htonl(opt2);\r\nreturn iwch_l2t_send(ep->com.tdev, skb, ep->l2t);\r\n}\r\nstatic void send_mpa_req(struct iwch_ep *ep, struct sk_buff *skb)\r\n{\r\nint mpalen;\r\nstruct tx_data_wr *req;\r\nstruct mpa_message *mpa;\r\nint len;\r\nPDBG("%s ep %p pd_len %d\n", __func__, ep, ep->plen);\r\nBUG_ON(skb_cloned(skb));\r\nmpalen = sizeof(*mpa) + ep->plen;\r\nif (skb->data + mpalen + sizeof(*req) > skb_end_pointer(skb)) {\r\nkfree_skb(skb);\r\nskb=alloc_skb(mpalen + sizeof(*req), GFP_KERNEL);\r\nif (!skb) {\r\nconnect_reply_upcall(ep, -ENOMEM);\r\nreturn;\r\n}\r\n}\r\nskb_trim(skb, 0);\r\nskb_reserve(skb, sizeof(*req));\r\nskb_put(skb, mpalen);\r\nskb->priority = CPL_PRIORITY_DATA;\r\nmpa = (struct mpa_message *) skb->data;\r\nmemset(mpa, 0, sizeof(*mpa));\r\nmemcpy(mpa->key, MPA_KEY_REQ, sizeof(mpa->key));\r\nmpa->flags = (crc_enabled ? MPA_CRC : 0) |\r\n(markers_enabled ? MPA_MARKERS : 0);\r\nmpa->private_data_size = htons(ep->plen);\r\nmpa->revision = mpa_rev;\r\nif (ep->plen)\r\nmemcpy(mpa->private_data, ep->mpa_pkt + sizeof(*mpa), ep->plen);\r\nskb_get(skb);\r\nset_arp_failure_handler(skb, arp_failure_discard);\r\nskb_reset_transport_header(skb);\r\nlen = skb->len;\r\nreq = (struct tx_data_wr *) skb_push(skb, sizeof(*req));\r\nreq->wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_TX_DATA)|F_WR_COMPL);\r\nreq->wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nreq->len = htonl(len);\r\nreq->param = htonl(V_TX_PORT(ep->l2t->smt_idx) |\r\nV_TX_SNDBUF(snd_win>>15));\r\nreq->flags = htonl(F_TX_INIT);\r\nreq->sndseq = htonl(ep->snd_seq);\r\nBUG_ON(ep->mpa_skb);\r\nep->mpa_skb = skb;\r\niwch_l2t_send(ep->com.tdev, skb, ep->l2t);\r\nstart_ep_timer(ep);\r\nstate_set(&ep->com, MPA_REQ_SENT);\r\nreturn;\r\n}\r\nstatic int send_mpa_reject(struct iwch_ep *ep, const void *pdata, u8 plen)\r\n{\r\nint mpalen;\r\nstruct tx_data_wr *req;\r\nstruct mpa_message *mpa;\r\nstruct sk_buff *skb;\r\nPDBG("%s ep %p plen %d\n", __func__, ep, plen);\r\nmpalen = sizeof(*mpa) + plen;\r\nskb = get_skb(NULL, mpalen + sizeof(*req), GFP_KERNEL);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "%s - cannot alloc skb!\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nskb_reserve(skb, sizeof(*req));\r\nmpa = (struct mpa_message *) skb_put(skb, mpalen);\r\nmemset(mpa, 0, sizeof(*mpa));\r\nmemcpy(mpa->key, MPA_KEY_REP, sizeof(mpa->key));\r\nmpa->flags = MPA_REJECT;\r\nmpa->revision = mpa_rev;\r\nmpa->private_data_size = htons(plen);\r\nif (plen)\r\nmemcpy(mpa->private_data, pdata, plen);\r\nskb_get(skb);\r\nskb->priority = CPL_PRIORITY_DATA;\r\nset_arp_failure_handler(skb, arp_failure_discard);\r\nskb_reset_transport_header(skb);\r\nreq = (struct tx_data_wr *) skb_push(skb, sizeof(*req));\r\nreq->wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_TX_DATA)|F_WR_COMPL);\r\nreq->wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nreq->len = htonl(mpalen);\r\nreq->param = htonl(V_TX_PORT(ep->l2t->smt_idx) |\r\nV_TX_SNDBUF(snd_win>>15));\r\nreq->flags = htonl(F_TX_INIT);\r\nreq->sndseq = htonl(ep->snd_seq);\r\nBUG_ON(ep->mpa_skb);\r\nep->mpa_skb = skb;\r\nreturn iwch_l2t_send(ep->com.tdev, skb, ep->l2t);\r\n}\r\nstatic int send_mpa_reply(struct iwch_ep *ep, const void *pdata, u8 plen)\r\n{\r\nint mpalen;\r\nstruct tx_data_wr *req;\r\nstruct mpa_message *mpa;\r\nint len;\r\nstruct sk_buff *skb;\r\nPDBG("%s ep %p plen %d\n", __func__, ep, plen);\r\nmpalen = sizeof(*mpa) + plen;\r\nskb = get_skb(NULL, mpalen + sizeof(*req), GFP_KERNEL);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "%s - cannot alloc skb!\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nskb->priority = CPL_PRIORITY_DATA;\r\nskb_reserve(skb, sizeof(*req));\r\nmpa = (struct mpa_message *) skb_put(skb, mpalen);\r\nmemset(mpa, 0, sizeof(*mpa));\r\nmemcpy(mpa->key, MPA_KEY_REP, sizeof(mpa->key));\r\nmpa->flags = (ep->mpa_attr.crc_enabled ? MPA_CRC : 0) |\r\n(markers_enabled ? MPA_MARKERS : 0);\r\nmpa->revision = mpa_rev;\r\nmpa->private_data_size = htons(plen);\r\nif (plen)\r\nmemcpy(mpa->private_data, pdata, plen);\r\nskb_get(skb);\r\nset_arp_failure_handler(skb, arp_failure_discard);\r\nskb_reset_transport_header(skb);\r\nlen = skb->len;\r\nreq = (struct tx_data_wr *) skb_push(skb, sizeof(*req));\r\nreq->wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_TX_DATA)|F_WR_COMPL);\r\nreq->wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nreq->len = htonl(len);\r\nreq->param = htonl(V_TX_PORT(ep->l2t->smt_idx) |\r\nV_TX_SNDBUF(snd_win>>15));\r\nreq->flags = htonl(F_TX_INIT);\r\nreq->sndseq = htonl(ep->snd_seq);\r\nep->mpa_skb = skb;\r\nstate_set(&ep->com, MPA_REP_SENT);\r\nreturn iwch_l2t_send(ep->com.tdev, skb, ep->l2t);\r\n}\r\nstatic int act_establish(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nstruct cpl_act_establish *req = cplhdr(skb);\r\nunsigned int tid = GET_TID(req);\r\nPDBG("%s ep %p tid %d\n", __func__, ep, tid);\r\ndst_confirm(ep->dst);\r\nep->hwtid = tid;\r\ncxgb3_insert_tid(ep->com.tdev, &t3c_client, ep, tid);\r\nep->snd_seq = ntohl(req->snd_isn);\r\nep->rcv_seq = ntohl(req->rcv_isn);\r\nset_emss(ep, ntohs(req->tcp_opt));\r\ncxgb3_free_atid(ep->com.tdev, ep->atid);\r\nsend_mpa_req(ep, skb);\r\nreturn 0;\r\n}\r\nstatic void abort_connection(struct iwch_ep *ep, struct sk_buff *skb, gfp_t gfp)\r\n{\r\nPDBG("%s ep %p\n", __FILE__, ep);\r\nstate_set(&ep->com, ABORTING);\r\nsend_abort(ep, skb, gfp);\r\n}\r\nstatic void close_complete_upcall(struct iwch_ep *ep)\r\n{\r\nstruct iw_cm_event event;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nmemset(&event, 0, sizeof(event));\r\nevent.event = IW_CM_EVENT_CLOSE;\r\nif (ep->com.cm_id) {\r\nPDBG("close complete delivered ep %p cm_id %p tid %d\n",\r\nep, ep->com.cm_id, ep->hwtid);\r\nep->com.cm_id->event_handler(ep->com.cm_id, &event);\r\nep->com.cm_id->rem_ref(ep->com.cm_id);\r\nep->com.cm_id = NULL;\r\nep->com.qp = NULL;\r\n}\r\n}\r\nstatic void peer_close_upcall(struct iwch_ep *ep)\r\n{\r\nstruct iw_cm_event event;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nmemset(&event, 0, sizeof(event));\r\nevent.event = IW_CM_EVENT_DISCONNECT;\r\nif (ep->com.cm_id) {\r\nPDBG("peer close delivered ep %p cm_id %p tid %d\n",\r\nep, ep->com.cm_id, ep->hwtid);\r\nep->com.cm_id->event_handler(ep->com.cm_id, &event);\r\n}\r\n}\r\nstatic void peer_abort_upcall(struct iwch_ep *ep)\r\n{\r\nstruct iw_cm_event event;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nmemset(&event, 0, sizeof(event));\r\nevent.event = IW_CM_EVENT_CLOSE;\r\nevent.status = -ECONNRESET;\r\nif (ep->com.cm_id) {\r\nPDBG("abort delivered ep %p cm_id %p tid %d\n", ep,\r\nep->com.cm_id, ep->hwtid);\r\nep->com.cm_id->event_handler(ep->com.cm_id, &event);\r\nep->com.cm_id->rem_ref(ep->com.cm_id);\r\nep->com.cm_id = NULL;\r\nep->com.qp = NULL;\r\n}\r\n}\r\nstatic void connect_reply_upcall(struct iwch_ep *ep, int status)\r\n{\r\nstruct iw_cm_event event;\r\nPDBG("%s ep %p status %d\n", __func__, ep, status);\r\nmemset(&event, 0, sizeof(event));\r\nevent.event = IW_CM_EVENT_CONNECT_REPLY;\r\nevent.status = status;\r\nmemcpy(&event.local_addr, &ep->com.local_addr,\r\nsizeof(ep->com.local_addr));\r\nmemcpy(&event.remote_addr, &ep->com.remote_addr,\r\nsizeof(ep->com.remote_addr));\r\nif ((status == 0) || (status == -ECONNREFUSED)) {\r\nevent.private_data_len = ep->plen;\r\nevent.private_data = ep->mpa_pkt + sizeof(struct mpa_message);\r\n}\r\nif (ep->com.cm_id) {\r\nPDBG("%s ep %p tid %d status %d\n", __func__, ep,\r\nep->hwtid, status);\r\nep->com.cm_id->event_handler(ep->com.cm_id, &event);\r\n}\r\nif (status < 0) {\r\nep->com.cm_id->rem_ref(ep->com.cm_id);\r\nep->com.cm_id = NULL;\r\nep->com.qp = NULL;\r\n}\r\n}\r\nstatic void connect_request_upcall(struct iwch_ep *ep)\r\n{\r\nstruct iw_cm_event event;\r\nPDBG("%s ep %p tid %d\n", __func__, ep, ep->hwtid);\r\nmemset(&event, 0, sizeof(event));\r\nevent.event = IW_CM_EVENT_CONNECT_REQUEST;\r\nmemcpy(&event.local_addr, &ep->com.local_addr,\r\nsizeof(ep->com.local_addr));\r\nmemcpy(&event.remote_addr, &ep->com.remote_addr,\r\nsizeof(ep->com.local_addr));\r\nevent.private_data_len = ep->plen;\r\nevent.private_data = ep->mpa_pkt + sizeof(struct mpa_message);\r\nevent.provider_data = ep;\r\nevent.ird = event.ord = 8;\r\nif (state_read(&ep->parent_ep->com) != DEAD) {\r\nget_ep(&ep->com);\r\nep->parent_ep->com.cm_id->event_handler(\r\nep->parent_ep->com.cm_id,\r\n&event);\r\n}\r\nput_ep(&ep->parent_ep->com);\r\nep->parent_ep = NULL;\r\n}\r\nstatic void established_upcall(struct iwch_ep *ep)\r\n{\r\nstruct iw_cm_event event;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nmemset(&event, 0, sizeof(event));\r\nevent.event = IW_CM_EVENT_ESTABLISHED;\r\nevent.ird = event.ord = 8;\r\nif (ep->com.cm_id) {\r\nPDBG("%s ep %p tid %d\n", __func__, ep, ep->hwtid);\r\nep->com.cm_id->event_handler(ep->com.cm_id, &event);\r\n}\r\n}\r\nstatic int update_rx_credits(struct iwch_ep *ep, u32 credits)\r\n{\r\nstruct cpl_rx_data_ack *req;\r\nstruct sk_buff *skb;\r\nPDBG("%s ep %p credits %u\n", __func__, ep, credits);\r\nskb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "update_rx_credits - cannot alloc skb!\n");\r\nreturn 0;\r\n}\r\nreq = (struct cpl_rx_data_ack *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_RX_DATA_ACK, ep->hwtid));\r\nreq->credit_dack = htonl(V_RX_CREDITS(credits) | V_RX_FORCE_ACK(1));\r\nskb->priority = CPL_PRIORITY_ACK;\r\niwch_cxgb3_ofld_send(ep->com.tdev, skb);\r\nreturn credits;\r\n}\r\nstatic void process_mpa_reply(struct iwch_ep *ep, struct sk_buff *skb)\r\n{\r\nstruct mpa_message *mpa;\r\nu16 plen;\r\nstruct iwch_qp_attributes attrs;\r\nenum iwch_qp_attr_mask mask;\r\nint err;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nstop_ep_timer(ep);\r\nif (state_read(&ep->com) != MPA_REQ_SENT)\r\nreturn;\r\nif (ep->mpa_pkt_len + skb->len > sizeof(ep->mpa_pkt)) {\r\nerr = -EINVAL;\r\ngoto err;\r\n}\r\nskb_copy_from_linear_data(skb, &(ep->mpa_pkt[ep->mpa_pkt_len]),\r\nskb->len);\r\nep->mpa_pkt_len += skb->len;\r\nif (ep->mpa_pkt_len < sizeof(*mpa))\r\nreturn;\r\nmpa = (struct mpa_message *) ep->mpa_pkt;\r\nif (mpa->revision != mpa_rev) {\r\nerr = -EPROTO;\r\ngoto err;\r\n}\r\nif (memcmp(mpa->key, MPA_KEY_REP, sizeof(mpa->key))) {\r\nerr = -EPROTO;\r\ngoto err;\r\n}\r\nplen = ntohs(mpa->private_data_size);\r\nif (plen > MPA_MAX_PRIVATE_DATA) {\r\nerr = -EPROTO;\r\ngoto err;\r\n}\r\nif (ep->mpa_pkt_len > (sizeof(*mpa) + plen)) {\r\nerr = -EPROTO;\r\ngoto err;\r\n}\r\nep->plen = (u8) plen;\r\nif (ep->mpa_pkt_len < (sizeof(*mpa) + plen))\r\nreturn;\r\nif (mpa->flags & MPA_REJECT) {\r\nerr = -ECONNREFUSED;\r\ngoto err;\r\n}\r\nstate_set(&ep->com, FPDU_MODE);\r\nep->mpa_attr.initiator = 1;\r\nep->mpa_attr.crc_enabled = (mpa->flags & MPA_CRC) | crc_enabled ? 1 : 0;\r\nep->mpa_attr.recv_marker_enabled = markers_enabled;\r\nep->mpa_attr.xmit_marker_enabled = mpa->flags & MPA_MARKERS ? 1 : 0;\r\nep->mpa_attr.version = mpa_rev;\r\nPDBG("%s - crc_enabled=%d, recv_marker_enabled=%d, "\r\n"xmit_marker_enabled=%d, version=%d\n", __func__,\r\nep->mpa_attr.crc_enabled, ep->mpa_attr.recv_marker_enabled,\r\nep->mpa_attr.xmit_marker_enabled, ep->mpa_attr.version);\r\nattrs.mpa_attr = ep->mpa_attr;\r\nattrs.max_ird = ep->ird;\r\nattrs.max_ord = ep->ord;\r\nattrs.llp_stream_handle = ep;\r\nattrs.next_state = IWCH_QP_STATE_RTS;\r\nmask = IWCH_QP_ATTR_NEXT_STATE |\r\nIWCH_QP_ATTR_LLP_STREAM_HANDLE | IWCH_QP_ATTR_MPA_ATTR |\r\nIWCH_QP_ATTR_MAX_IRD | IWCH_QP_ATTR_MAX_ORD;\r\nerr = iwch_modify_qp(ep->com.qp->rhp,\r\nep->com.qp, mask, &attrs, 1);\r\nif (err)\r\ngoto err;\r\nif (peer2peer && iwch_rqes_posted(ep->com.qp) == 0) {\r\niwch_post_zb_read(ep);\r\n}\r\ngoto out;\r\nerr:\r\nabort_connection(ep, skb, GFP_KERNEL);\r\nout:\r\nconnect_reply_upcall(ep, err);\r\nreturn;\r\n}\r\nstatic void process_mpa_request(struct iwch_ep *ep, struct sk_buff *skb)\r\n{\r\nstruct mpa_message *mpa;\r\nu16 plen;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nstop_ep_timer(ep);\r\nif (state_read(&ep->com) != MPA_REQ_WAIT)\r\nreturn;\r\nif (ep->mpa_pkt_len + skb->len > sizeof(ep->mpa_pkt)) {\r\nabort_connection(ep, skb, GFP_KERNEL);\r\nreturn;\r\n}\r\nPDBG("%s enter (%s line %u)\n", __func__, __FILE__, __LINE__);\r\nskb_copy_from_linear_data(skb, &(ep->mpa_pkt[ep->mpa_pkt_len]),\r\nskb->len);\r\nep->mpa_pkt_len += skb->len;\r\nif (ep->mpa_pkt_len < sizeof(*mpa))\r\nreturn;\r\nPDBG("%s enter (%s line %u)\n", __func__, __FILE__, __LINE__);\r\nmpa = (struct mpa_message *) ep->mpa_pkt;\r\nif (mpa->revision != mpa_rev) {\r\nabort_connection(ep, skb, GFP_KERNEL);\r\nreturn;\r\n}\r\nif (memcmp(mpa->key, MPA_KEY_REQ, sizeof(mpa->key))) {\r\nabort_connection(ep, skb, GFP_KERNEL);\r\nreturn;\r\n}\r\nplen = ntohs(mpa->private_data_size);\r\nif (plen > MPA_MAX_PRIVATE_DATA) {\r\nabort_connection(ep, skb, GFP_KERNEL);\r\nreturn;\r\n}\r\nif (ep->mpa_pkt_len > (sizeof(*mpa) + plen)) {\r\nabort_connection(ep, skb, GFP_KERNEL);\r\nreturn;\r\n}\r\nep->plen = (u8) plen;\r\nif (ep->mpa_pkt_len < (sizeof(*mpa) + plen))\r\nreturn;\r\nep->mpa_attr.initiator = 0;\r\nep->mpa_attr.crc_enabled = (mpa->flags & MPA_CRC) | crc_enabled ? 1 : 0;\r\nep->mpa_attr.recv_marker_enabled = markers_enabled;\r\nep->mpa_attr.xmit_marker_enabled = mpa->flags & MPA_MARKERS ? 1 : 0;\r\nep->mpa_attr.version = mpa_rev;\r\nPDBG("%s - crc_enabled=%d, recv_marker_enabled=%d, "\r\n"xmit_marker_enabled=%d, version=%d\n", __func__,\r\nep->mpa_attr.crc_enabled, ep->mpa_attr.recv_marker_enabled,\r\nep->mpa_attr.xmit_marker_enabled, ep->mpa_attr.version);\r\nstate_set(&ep->com, MPA_REQ_RCVD);\r\nconnect_request_upcall(ep);\r\nreturn;\r\n}\r\nstatic int rx_data(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nstruct cpl_rx_data *hdr = cplhdr(skb);\r\nunsigned int dlen = ntohs(hdr->len);\r\nPDBG("%s ep %p dlen %u\n", __func__, ep, dlen);\r\nskb_pull(skb, sizeof(*hdr));\r\nskb_trim(skb, dlen);\r\nep->rcv_seq += dlen;\r\nBUG_ON(ep->rcv_seq != (ntohl(hdr->seq) + dlen));\r\nswitch (state_read(&ep->com)) {\r\ncase MPA_REQ_SENT:\r\nprocess_mpa_reply(ep, skb);\r\nbreak;\r\ncase MPA_REQ_WAIT:\r\nprocess_mpa_request(ep, skb);\r\nbreak;\r\ncase MPA_REP_SENT:\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR MOD "%s Unexpected streaming data."\r\n" ep %p state %d tid %d\n",\r\n__func__, ep, state_read(&ep->com), ep->hwtid);\r\nbreak;\r\n}\r\nupdate_rx_credits(ep, dlen);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int tx_ack(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nstruct cpl_wr_ack *hdr = cplhdr(skb);\r\nunsigned int credits = ntohs(hdr->credits);\r\nunsigned long flags;\r\nint post_zb = 0;\r\nPDBG("%s ep %p credits %u\n", __func__, ep, credits);\r\nif (credits == 0) {\r\nPDBG("%s 0 credit ack ep %p state %u\n",\r\n__func__, ep, state_read(&ep->com));\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nspin_lock_irqsave(&ep->com.lock, flags);\r\nBUG_ON(credits != 1);\r\ndst_confirm(ep->dst);\r\nif (!ep->mpa_skb) {\r\nPDBG("%s rdma_init wr_ack ep %p state %u\n",\r\n__func__, ep, ep->com.state);\r\nif (ep->mpa_attr.initiator) {\r\nPDBG("%s initiator ep %p state %u\n",\r\n__func__, ep, ep->com.state);\r\nif (peer2peer && ep->com.state == FPDU_MODE)\r\npost_zb = 1;\r\n} else {\r\nPDBG("%s responder ep %p state %u\n",\r\n__func__, ep, ep->com.state);\r\nif (ep->com.state == MPA_REQ_RCVD) {\r\nep->com.rpl_done = 1;\r\nwake_up(&ep->com.waitq);\r\n}\r\n}\r\n} else {\r\nPDBG("%s lsm ack ep %p state %u freeing skb\n",\r\n__func__, ep, ep->com.state);\r\nkfree_skb(ep->mpa_skb);\r\nep->mpa_skb = NULL;\r\n}\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nif (post_zb)\r\niwch_post_zb_read(ep);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int abort_rpl(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nunsigned long flags;\r\nint release = 0;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nBUG_ON(!ep);\r\nif (!test_and_set_bit(ABORT_REQ_IN_PROGRESS, &ep->com.flags)) {\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nspin_lock_irqsave(&ep->com.lock, flags);\r\nswitch (ep->com.state) {\r\ncase ABORTING:\r\nclose_complete_upcall(ep);\r\n__state_set(&ep->com, DEAD);\r\nrelease = 1;\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "%s ep %p state %d\n",\r\n__func__, ep, ep->com.state);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nif (release)\r\nrelease_ep_resources(ep);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic inline int act_open_has_tid(int status)\r\n{\r\nreturn status != CPL_ERR_TCAM_FULL && status != CPL_ERR_CONN_EXIST &&\r\nstatus != CPL_ERR_ARP_MISS;\r\n}\r\nstatic int act_open_rpl(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nstruct cpl_act_open_rpl *rpl = cplhdr(skb);\r\nPDBG("%s ep %p status %u errno %d\n", __func__, ep, rpl->status,\r\nstatus2errno(rpl->status));\r\nconnect_reply_upcall(ep, status2errno(rpl->status));\r\nstate_set(&ep->com, DEAD);\r\nif (ep->com.tdev->type != T3A && act_open_has_tid(rpl->status))\r\nrelease_tid(ep->com.tdev, GET_TID(rpl), NULL);\r\ncxgb3_free_atid(ep->com.tdev, ep->atid);\r\ndst_release(ep->dst);\r\nl2t_release(ep->com.tdev, ep->l2t);\r\nput_ep(&ep->com);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int listen_start(struct iwch_listen_ep *ep)\r\n{\r\nstruct sk_buff *skb;\r\nstruct cpl_pass_open_req *req;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nskb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "t3c_listen_start failed to alloc skb!\n");\r\nreturn -ENOMEM;\r\n}\r\nreq = (struct cpl_pass_open_req *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_PASS_OPEN_REQ, ep->stid));\r\nreq->local_port = ep->com.local_addr.sin_port;\r\nreq->local_ip = ep->com.local_addr.sin_addr.s_addr;\r\nreq->peer_port = 0;\r\nreq->peer_ip = 0;\r\nreq->peer_netmask = 0;\r\nreq->opt0h = htonl(F_DELACK | F_TCAM_BYPASS);\r\nreq->opt0l = htonl(V_RCV_BUFSIZ(rcv_win>>10));\r\nreq->opt1 = htonl(V_CONN_POLICY(CPL_CONN_POLICY_ASK));\r\nskb->priority = 1;\r\nreturn iwch_cxgb3_ofld_send(ep->com.tdev, skb);\r\n}\r\nstatic int pass_open_rpl(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_listen_ep *ep = ctx;\r\nstruct cpl_pass_open_rpl *rpl = cplhdr(skb);\r\nPDBG("%s ep %p status %d error %d\n", __func__, ep,\r\nrpl->status, status2errno(rpl->status));\r\nep->com.rpl_err = status2errno(rpl->status);\r\nep->com.rpl_done = 1;\r\nwake_up(&ep->com.waitq);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int listen_stop(struct iwch_listen_ep *ep)\r\n{\r\nstruct sk_buff *skb;\r\nstruct cpl_close_listserv_req *req;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nskb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\r\nif (!skb) {\r\nprintk(KERN_ERR MOD "%s - failed to alloc skb\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nreq = (struct cpl_close_listserv_req *) skb_put(skb, sizeof(*req));\r\nreq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nreq->cpu_idx = 0;\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_CLOSE_LISTSRV_REQ, ep->stid));\r\nskb->priority = 1;\r\nreturn iwch_cxgb3_ofld_send(ep->com.tdev, skb);\r\n}\r\nstatic int close_listsrv_rpl(struct t3cdev *tdev, struct sk_buff *skb,\r\nvoid *ctx)\r\n{\r\nstruct iwch_listen_ep *ep = ctx;\r\nstruct cpl_close_listserv_rpl *rpl = cplhdr(skb);\r\nPDBG("%s ep %p\n", __func__, ep);\r\nep->com.rpl_err = status2errno(rpl->status);\r\nep->com.rpl_done = 1;\r\nwake_up(&ep->com.waitq);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic void accept_cr(struct iwch_ep *ep, __be32 peer_ip, struct sk_buff *skb)\r\n{\r\nstruct cpl_pass_accept_rpl *rpl;\r\nunsigned int mtu_idx;\r\nu32 opt0h, opt0l, opt2;\r\nint wscale;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nBUG_ON(skb_cloned(skb));\r\nskb_trim(skb, sizeof(*rpl));\r\nskb_get(skb);\r\nmtu_idx = find_best_mtu(T3C_DATA(ep->com.tdev), dst_mtu(ep->dst));\r\nwscale = compute_wscale(rcv_win);\r\nopt0h = V_NAGLE(0) |\r\nV_NO_CONG(nocong) |\r\nV_KEEP_ALIVE(1) |\r\nF_TCAM_BYPASS |\r\nV_WND_SCALE(wscale) |\r\nV_MSS_IDX(mtu_idx) |\r\nV_L2T_IDX(ep->l2t->idx) | V_TX_CHANNEL(ep->l2t->smt_idx);\r\nopt0l = V_TOS((ep->tos >> 2) & M_TOS) | V_RCV_BUFSIZ(rcv_win>>10);\r\nopt2 = F_RX_COALESCE_VALID | V_RX_COALESCE(0) | V_FLAVORS_VALID(1) |\r\nV_CONG_CONTROL_FLAVOR(cong_flavor);\r\nrpl = cplhdr(skb);\r\nrpl->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(rpl) = htonl(MK_OPCODE_TID(CPL_PASS_ACCEPT_RPL, ep->hwtid));\r\nrpl->peer_ip = peer_ip;\r\nrpl->opt0h = htonl(opt0h);\r\nrpl->opt0l_status = htonl(opt0l | CPL_PASS_OPEN_ACCEPT);\r\nrpl->opt2 = htonl(opt2);\r\nrpl->rsvd = rpl->opt2;\r\nskb->priority = CPL_PRIORITY_SETUP;\r\niwch_l2t_send(ep->com.tdev, skb, ep->l2t);\r\nreturn;\r\n}\r\nstatic void reject_cr(struct t3cdev *tdev, u32 hwtid, __be32 peer_ip,\r\nstruct sk_buff *skb)\r\n{\r\nPDBG("%s t3cdev %p tid %u peer_ip %x\n", __func__, tdev, hwtid,\r\npeer_ip);\r\nBUG_ON(skb_cloned(skb));\r\nskb_trim(skb, sizeof(struct cpl_tid_release));\r\nskb_get(skb);\r\nif (tdev->type != T3A)\r\nrelease_tid(tdev, hwtid, skb);\r\nelse {\r\nstruct cpl_pass_accept_rpl *rpl;\r\nrpl = cplhdr(skb);\r\nskb->priority = CPL_PRIORITY_SETUP;\r\nrpl->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\r\nOPCODE_TID(rpl) = htonl(MK_OPCODE_TID(CPL_PASS_ACCEPT_RPL,\r\nhwtid));\r\nrpl->peer_ip = peer_ip;\r\nrpl->opt0h = htonl(F_TCAM_BYPASS);\r\nrpl->opt0l_status = htonl(CPL_PASS_OPEN_REJECT);\r\nrpl->opt2 = 0;\r\nrpl->rsvd = rpl->opt2;\r\niwch_cxgb3_ofld_send(tdev, skb);\r\n}\r\n}\r\nstatic int pass_accept_req(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *child_ep, *parent_ep = ctx;\r\nstruct cpl_pass_accept_req *req = cplhdr(skb);\r\nunsigned int hwtid = GET_TID(req);\r\nstruct dst_entry *dst;\r\nstruct l2t_entry *l2t;\r\nstruct rtable *rt;\r\nstruct iff_mac tim;\r\nPDBG("%s parent ep %p tid %u\n", __func__, parent_ep, hwtid);\r\nif (state_read(&parent_ep->com) != LISTEN) {\r\nprintk(KERN_ERR "%s - listening ep not in LISTEN\n",\r\n__func__);\r\ngoto reject;\r\n}\r\ntim.mac_addr = req->dst_mac;\r\ntim.vlan_tag = ntohs(req->vlan_tag);\r\nif (tdev->ctl(tdev, GET_IFF_FROM_MAC, &tim) < 0 || !tim.dev) {\r\nprintk(KERN_ERR "%s bad dst mac %pM\n",\r\n__func__, req->dst_mac);\r\ngoto reject;\r\n}\r\nrt = find_route(tdev,\r\nreq->local_ip,\r\nreq->peer_ip,\r\nreq->local_port,\r\nreq->peer_port, G_PASS_OPEN_TOS(ntohl(req->tos_tid)));\r\nif (!rt) {\r\nprintk(KERN_ERR MOD "%s - failed to find dst entry!\n",\r\n__func__);\r\ngoto reject;\r\n}\r\ndst = &rt->dst;\r\nl2t = t3_l2t_get(tdev, dst, NULL, &req->peer_ip);\r\nif (!l2t) {\r\nprintk(KERN_ERR MOD "%s - failed to allocate l2t entry!\n",\r\n__func__);\r\ndst_release(dst);\r\ngoto reject;\r\n}\r\nchild_ep = alloc_ep(sizeof(*child_ep), GFP_KERNEL);\r\nif (!child_ep) {\r\nprintk(KERN_ERR MOD "%s - failed to allocate ep entry!\n",\r\n__func__);\r\nl2t_release(tdev, l2t);\r\ndst_release(dst);\r\ngoto reject;\r\n}\r\nstate_set(&child_ep->com, CONNECTING);\r\nchild_ep->com.tdev = tdev;\r\nchild_ep->com.cm_id = NULL;\r\nchild_ep->com.local_addr.sin_family = AF_INET;\r\nchild_ep->com.local_addr.sin_port = req->local_port;\r\nchild_ep->com.local_addr.sin_addr.s_addr = req->local_ip;\r\nchild_ep->com.remote_addr.sin_family = AF_INET;\r\nchild_ep->com.remote_addr.sin_port = req->peer_port;\r\nchild_ep->com.remote_addr.sin_addr.s_addr = req->peer_ip;\r\nget_ep(&parent_ep->com);\r\nchild_ep->parent_ep = parent_ep;\r\nchild_ep->tos = G_PASS_OPEN_TOS(ntohl(req->tos_tid));\r\nchild_ep->l2t = l2t;\r\nchild_ep->dst = dst;\r\nchild_ep->hwtid = hwtid;\r\ninit_timer(&child_ep->timer);\r\ncxgb3_insert_tid(tdev, &t3c_client, child_ep, hwtid);\r\naccept_cr(child_ep, req->peer_ip, skb);\r\ngoto out;\r\nreject:\r\nreject_cr(tdev, hwtid, req->peer_ip, skb);\r\nout:\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int pass_establish(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nstruct cpl_pass_establish *req = cplhdr(skb);\r\nPDBG("%s ep %p\n", __func__, ep);\r\nep->snd_seq = ntohl(req->snd_isn);\r\nep->rcv_seq = ntohl(req->rcv_isn);\r\nset_emss(ep, ntohs(req->tcp_opt));\r\ndst_confirm(ep->dst);\r\nstate_set(&ep->com, MPA_REQ_WAIT);\r\nstart_ep_timer(ep);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int peer_close(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nstruct iwch_qp_attributes attrs;\r\nunsigned long flags;\r\nint disconnect = 1;\r\nint release = 0;\r\nPDBG("%s ep %p\n", __func__, ep);\r\ndst_confirm(ep->dst);\r\nspin_lock_irqsave(&ep->com.lock, flags);\r\nswitch (ep->com.state) {\r\ncase MPA_REQ_WAIT:\r\n__state_set(&ep->com, CLOSING);\r\nbreak;\r\ncase MPA_REQ_SENT:\r\n__state_set(&ep->com, CLOSING);\r\nconnect_reply_upcall(ep, -ECONNRESET);\r\nbreak;\r\ncase MPA_REQ_RCVD:\r\n__state_set(&ep->com, CLOSING);\r\nep->com.rpl_done = 1;\r\nep->com.rpl_err = -ECONNRESET;\r\nPDBG("waking up ep %p\n", ep);\r\nwake_up(&ep->com.waitq);\r\nbreak;\r\ncase MPA_REP_SENT:\r\n__state_set(&ep->com, CLOSING);\r\nep->com.rpl_done = 1;\r\nep->com.rpl_err = -ECONNRESET;\r\nPDBG("waking up ep %p\n", ep);\r\nwake_up(&ep->com.waitq);\r\nbreak;\r\ncase FPDU_MODE:\r\nstart_ep_timer(ep);\r\n__state_set(&ep->com, CLOSING);\r\nattrs.next_state = IWCH_QP_STATE_CLOSING;\r\niwch_modify_qp(ep->com.qp->rhp, ep->com.qp,\r\nIWCH_QP_ATTR_NEXT_STATE, &attrs, 1);\r\npeer_close_upcall(ep);\r\nbreak;\r\ncase ABORTING:\r\ndisconnect = 0;\r\nbreak;\r\ncase CLOSING:\r\n__state_set(&ep->com, MORIBUND);\r\ndisconnect = 0;\r\nbreak;\r\ncase MORIBUND:\r\nstop_ep_timer(ep);\r\nif (ep->com.cm_id && ep->com.qp) {\r\nattrs.next_state = IWCH_QP_STATE_IDLE;\r\niwch_modify_qp(ep->com.qp->rhp, ep->com.qp,\r\nIWCH_QP_ATTR_NEXT_STATE, &attrs, 1);\r\n}\r\nclose_complete_upcall(ep);\r\n__state_set(&ep->com, DEAD);\r\nrelease = 1;\r\ndisconnect = 0;\r\nbreak;\r\ncase DEAD:\r\ndisconnect = 0;\r\nbreak;\r\ndefault:\r\nBUG_ON(1);\r\n}\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nif (disconnect)\r\niwch_ep_disconnect(ep, 0, GFP_KERNEL);\r\nif (release)\r\nrelease_ep_resources(ep);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int is_neg_adv_abort(unsigned int status)\r\n{\r\nreturn status == CPL_ERR_RTX_NEG_ADVICE ||\r\nstatus == CPL_ERR_PERSIST_NEG_ADVICE;\r\n}\r\nstatic int peer_abort(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct cpl_abort_req_rss *req = cplhdr(skb);\r\nstruct iwch_ep *ep = ctx;\r\nstruct cpl_abort_rpl *rpl;\r\nstruct sk_buff *rpl_skb;\r\nstruct iwch_qp_attributes attrs;\r\nint ret;\r\nint release = 0;\r\nunsigned long flags;\r\nif (is_neg_adv_abort(req->status)) {\r\nPDBG("%s neg_adv_abort ep %p tid %d\n", __func__, ep,\r\nep->hwtid);\r\nt3_l2t_send_event(ep->com.tdev, ep->l2t);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nif (!test_and_set_bit(PEER_ABORT_IN_PROGRESS, &ep->com.flags)) {\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nspin_lock_irqsave(&ep->com.lock, flags);\r\nPDBG("%s ep %p state %u\n", __func__, ep, ep->com.state);\r\nswitch (ep->com.state) {\r\ncase CONNECTING:\r\nbreak;\r\ncase MPA_REQ_WAIT:\r\nstop_ep_timer(ep);\r\nbreak;\r\ncase MPA_REQ_SENT:\r\nstop_ep_timer(ep);\r\nconnect_reply_upcall(ep, -ECONNRESET);\r\nbreak;\r\ncase MPA_REP_SENT:\r\nep->com.rpl_done = 1;\r\nep->com.rpl_err = -ECONNRESET;\r\nPDBG("waking up ep %p\n", ep);\r\nwake_up(&ep->com.waitq);\r\nbreak;\r\ncase MPA_REQ_RCVD:\r\nep->com.rpl_done = 1;\r\nep->com.rpl_err = -ECONNRESET;\r\nPDBG("waking up ep %p\n", ep);\r\nwake_up(&ep->com.waitq);\r\nbreak;\r\ncase MORIBUND:\r\ncase CLOSING:\r\nstop_ep_timer(ep);\r\ncase FPDU_MODE:\r\nif (ep->com.cm_id && ep->com.qp) {\r\nattrs.next_state = IWCH_QP_STATE_ERROR;\r\nret = iwch_modify_qp(ep->com.qp->rhp,\r\nep->com.qp, IWCH_QP_ATTR_NEXT_STATE,\r\n&attrs, 1);\r\nif (ret)\r\nprintk(KERN_ERR MOD\r\n"%s - qp <- error failed!\n",\r\n__func__);\r\n}\r\npeer_abort_upcall(ep);\r\nbreak;\r\ncase ABORTING:\r\nbreak;\r\ncase DEAD:\r\nPDBG("%s PEER_ABORT IN DEAD STATE!!!!\n", __func__);\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nreturn CPL_RET_BUF_DONE;\r\ndefault:\r\nBUG_ON(1);\r\nbreak;\r\n}\r\ndst_confirm(ep->dst);\r\nif (ep->com.state != ABORTING) {\r\n__state_set(&ep->com, DEAD);\r\nrelease = 1;\r\n}\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nrpl_skb = get_skb(skb, sizeof(*rpl), GFP_KERNEL);\r\nif (!rpl_skb) {\r\nprintk(KERN_ERR MOD "%s - cannot allocate skb!\n",\r\n__func__);\r\nrelease = 1;\r\ngoto out;\r\n}\r\nrpl_skb->priority = CPL_PRIORITY_DATA;\r\nrpl = (struct cpl_abort_rpl *) skb_put(rpl_skb, sizeof(*rpl));\r\nrpl->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_HOST_ABORT_CON_RPL));\r\nrpl->wr.wr_lo = htonl(V_WR_TID(ep->hwtid));\r\nOPCODE_TID(rpl) = htonl(MK_OPCODE_TID(CPL_ABORT_RPL, ep->hwtid));\r\nrpl->cmd = CPL_ABORT_NO_RST;\r\niwch_cxgb3_ofld_send(ep->com.tdev, rpl_skb);\r\nout:\r\nif (release)\r\nrelease_ep_resources(ep);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int close_con_rpl(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nstruct iwch_qp_attributes attrs;\r\nunsigned long flags;\r\nint release = 0;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nBUG_ON(!ep);\r\nspin_lock_irqsave(&ep->com.lock, flags);\r\nswitch (ep->com.state) {\r\ncase CLOSING:\r\n__state_set(&ep->com, MORIBUND);\r\nbreak;\r\ncase MORIBUND:\r\nstop_ep_timer(ep);\r\nif ((ep->com.cm_id) && (ep->com.qp)) {\r\nattrs.next_state = IWCH_QP_STATE_IDLE;\r\niwch_modify_qp(ep->com.qp->rhp,\r\nep->com.qp,\r\nIWCH_QP_ATTR_NEXT_STATE,\r\n&attrs, 1);\r\n}\r\nclose_complete_upcall(ep);\r\n__state_set(&ep->com, DEAD);\r\nrelease = 1;\r\nbreak;\r\ncase ABORTING:\r\ncase DEAD:\r\nbreak;\r\ndefault:\r\nBUG_ON(1);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nif (release)\r\nrelease_ep_resources(ep);\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int terminate(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nif (state_read(&ep->com) != FPDU_MODE)\r\nreturn CPL_RET_BUF_DONE;\r\nPDBG("%s ep %p\n", __func__, ep);\r\nskb_pull(skb, sizeof(struct cpl_rdma_terminate));\r\nPDBG("%s saving %d bytes of term msg\n", __func__, skb->len);\r\nskb_copy_from_linear_data(skb, ep->com.qp->attr.terminate_buffer,\r\nskb->len);\r\nep->com.qp->attr.terminate_msg_len = skb->len;\r\nep->com.qp->attr.is_terminate_local = 0;\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic int ec_status(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct cpl_rdma_ec_status *rep = cplhdr(skb);\r\nstruct iwch_ep *ep = ctx;\r\nPDBG("%s ep %p tid %u status %d\n", __func__, ep, ep->hwtid,\r\nrep->status);\r\nif (rep->status) {\r\nstruct iwch_qp_attributes attrs;\r\nprintk(KERN_ERR MOD "%s BAD CLOSE - Aborting tid %u\n",\r\n__func__, ep->hwtid);\r\nstop_ep_timer(ep);\r\nattrs.next_state = IWCH_QP_STATE_ERROR;\r\niwch_modify_qp(ep->com.qp->rhp,\r\nep->com.qp, IWCH_QP_ATTR_NEXT_STATE,\r\n&attrs, 1);\r\nabort_connection(ep, NULL, GFP_KERNEL);\r\n}\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nstatic void ep_timeout(unsigned long arg)\r\n{\r\nstruct iwch_ep *ep = (struct iwch_ep *)arg;\r\nstruct iwch_qp_attributes attrs;\r\nunsigned long flags;\r\nint abort = 1;\r\nspin_lock_irqsave(&ep->com.lock, flags);\r\nPDBG("%s ep %p tid %u state %d\n", __func__, ep, ep->hwtid,\r\nep->com.state);\r\nswitch (ep->com.state) {\r\ncase MPA_REQ_SENT:\r\n__state_set(&ep->com, ABORTING);\r\nconnect_reply_upcall(ep, -ETIMEDOUT);\r\nbreak;\r\ncase MPA_REQ_WAIT:\r\n__state_set(&ep->com, ABORTING);\r\nbreak;\r\ncase CLOSING:\r\ncase MORIBUND:\r\nif (ep->com.cm_id && ep->com.qp) {\r\nattrs.next_state = IWCH_QP_STATE_ERROR;\r\niwch_modify_qp(ep->com.qp->rhp,\r\nep->com.qp, IWCH_QP_ATTR_NEXT_STATE,\r\n&attrs, 1);\r\n}\r\n__state_set(&ep->com, ABORTING);\r\nbreak;\r\ndefault:\r\nWARN(1, "%s unexpected state ep %p state %u\n",\r\n__func__, ep, ep->com.state);\r\nabort = 0;\r\n}\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nif (abort)\r\nabort_connection(ep, NULL, GFP_ATOMIC);\r\nput_ep(&ep->com);\r\n}\r\nint iwch_reject_cr(struct iw_cm_id *cm_id, const void *pdata, u8 pdata_len)\r\n{\r\nint err;\r\nstruct iwch_ep *ep = to_ep(cm_id);\r\nPDBG("%s ep %p tid %u\n", __func__, ep, ep->hwtid);\r\nif (state_read(&ep->com) == DEAD) {\r\nput_ep(&ep->com);\r\nreturn -ECONNRESET;\r\n}\r\nBUG_ON(state_read(&ep->com) != MPA_REQ_RCVD);\r\nif (mpa_rev == 0)\r\nabort_connection(ep, NULL, GFP_KERNEL);\r\nelse {\r\nerr = send_mpa_reject(ep, pdata, pdata_len);\r\nerr = iwch_ep_disconnect(ep, 0, GFP_KERNEL);\r\n}\r\nput_ep(&ep->com);\r\nreturn 0;\r\n}\r\nint iwch_accept_cr(struct iw_cm_id *cm_id, struct iw_cm_conn_param *conn_param)\r\n{\r\nint err;\r\nstruct iwch_qp_attributes attrs;\r\nenum iwch_qp_attr_mask mask;\r\nstruct iwch_ep *ep = to_ep(cm_id);\r\nstruct iwch_dev *h = to_iwch_dev(cm_id->device);\r\nstruct iwch_qp *qp = get_qhp(h, conn_param->qpn);\r\nPDBG("%s ep %p tid %u\n", __func__, ep, ep->hwtid);\r\nif (state_read(&ep->com) == DEAD) {\r\nerr = -ECONNRESET;\r\ngoto err;\r\n}\r\nBUG_ON(state_read(&ep->com) != MPA_REQ_RCVD);\r\nBUG_ON(!qp);\r\nif ((conn_param->ord > qp->rhp->attr.max_rdma_read_qp_depth) ||\r\n(conn_param->ird > qp->rhp->attr.max_rdma_reads_per_qp)) {\r\nabort_connection(ep, NULL, GFP_KERNEL);\r\nerr = -EINVAL;\r\ngoto err;\r\n}\r\ncm_id->add_ref(cm_id);\r\nep->com.cm_id = cm_id;\r\nep->com.qp = qp;\r\nep->ird = conn_param->ird;\r\nep->ord = conn_param->ord;\r\nif (peer2peer && ep->ird == 0)\r\nep->ird = 1;\r\nPDBG("%s %d ird %d ord %d\n", __func__, __LINE__, ep->ird, ep->ord);\r\nattrs.mpa_attr = ep->mpa_attr;\r\nattrs.max_ird = ep->ird;\r\nattrs.max_ord = ep->ord;\r\nattrs.llp_stream_handle = ep;\r\nattrs.next_state = IWCH_QP_STATE_RTS;\r\nmask = IWCH_QP_ATTR_NEXT_STATE |\r\nIWCH_QP_ATTR_LLP_STREAM_HANDLE |\r\nIWCH_QP_ATTR_MPA_ATTR |\r\nIWCH_QP_ATTR_MAX_IRD |\r\nIWCH_QP_ATTR_MAX_ORD;\r\nerr = iwch_modify_qp(ep->com.qp->rhp,\r\nep->com.qp, mask, &attrs, 1);\r\nif (err)\r\ngoto err1;\r\nif (iwch_rqes_posted(qp)) {\r\nwait_event(ep->com.waitq, ep->com.rpl_done);\r\nerr = ep->com.rpl_err;\r\nif (err)\r\ngoto err1;\r\n}\r\nerr = send_mpa_reply(ep, conn_param->private_data,\r\nconn_param->private_data_len);\r\nif (err)\r\ngoto err1;\r\nstate_set(&ep->com, FPDU_MODE);\r\nestablished_upcall(ep);\r\nput_ep(&ep->com);\r\nreturn 0;\r\nerr1:\r\nep->com.cm_id = NULL;\r\nep->com.qp = NULL;\r\ncm_id->rem_ref(cm_id);\r\nerr:\r\nput_ep(&ep->com);\r\nreturn err;\r\n}\r\nstatic int is_loopback_dst(struct iw_cm_id *cm_id)\r\n{\r\nstruct net_device *dev;\r\nstruct sockaddr_in *raddr = (struct sockaddr_in *)&cm_id->m_remote_addr;\r\ndev = ip_dev_find(&init_net, raddr->sin_addr.s_addr);\r\nif (!dev)\r\nreturn 0;\r\ndev_put(dev);\r\nreturn 1;\r\n}\r\nint iwch_connect(struct iw_cm_id *cm_id, struct iw_cm_conn_param *conn_param)\r\n{\r\nstruct iwch_dev *h = to_iwch_dev(cm_id->device);\r\nstruct iwch_ep *ep;\r\nstruct rtable *rt;\r\nint err = 0;\r\nstruct sockaddr_in *laddr = (struct sockaddr_in *)&cm_id->m_local_addr;\r\nstruct sockaddr_in *raddr = (struct sockaddr_in *)&cm_id->m_remote_addr;\r\nif (cm_id->m_remote_addr.ss_family != PF_INET) {\r\nerr = -ENOSYS;\r\ngoto out;\r\n}\r\nif (is_loopback_dst(cm_id)) {\r\nerr = -ENOSYS;\r\ngoto out;\r\n}\r\nep = alloc_ep(sizeof(*ep), GFP_KERNEL);\r\nif (!ep) {\r\nprintk(KERN_ERR MOD "%s - cannot alloc ep.\n", __func__);\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\ninit_timer(&ep->timer);\r\nep->plen = conn_param->private_data_len;\r\nif (ep->plen)\r\nmemcpy(ep->mpa_pkt + sizeof(struct mpa_message),\r\nconn_param->private_data, ep->plen);\r\nep->ird = conn_param->ird;\r\nep->ord = conn_param->ord;\r\nif (peer2peer && ep->ord == 0)\r\nep->ord = 1;\r\nep->com.tdev = h->rdev.t3cdev_p;\r\ncm_id->add_ref(cm_id);\r\nep->com.cm_id = cm_id;\r\nep->com.qp = get_qhp(h, conn_param->qpn);\r\nBUG_ON(!ep->com.qp);\r\nPDBG("%s qpn 0x%x qp %p cm_id %p\n", __func__, conn_param->qpn,\r\nep->com.qp, cm_id);\r\nep->atid = cxgb3_alloc_atid(h->rdev.t3cdev_p, &t3c_client, ep);\r\nif (ep->atid == -1) {\r\nprintk(KERN_ERR MOD "%s - cannot alloc atid.\n", __func__);\r\nerr = -ENOMEM;\r\ngoto fail2;\r\n}\r\nrt = find_route(h->rdev.t3cdev_p, laddr->sin_addr.s_addr,\r\nraddr->sin_addr.s_addr, laddr->sin_port,\r\nraddr->sin_port, IPTOS_LOWDELAY);\r\nif (!rt) {\r\nprintk(KERN_ERR MOD "%s - cannot find route.\n", __func__);\r\nerr = -EHOSTUNREACH;\r\ngoto fail3;\r\n}\r\nep->dst = &rt->dst;\r\nep->l2t = t3_l2t_get(ep->com.tdev, ep->dst, NULL,\r\n&raddr->sin_addr.s_addr);\r\nif (!ep->l2t) {\r\nprintk(KERN_ERR MOD "%s - cannot alloc l2e.\n", __func__);\r\nerr = -ENOMEM;\r\ngoto fail4;\r\n}\r\nstate_set(&ep->com, CONNECTING);\r\nep->tos = IPTOS_LOWDELAY;\r\nmemcpy(&ep->com.local_addr, &cm_id->m_local_addr,\r\nsizeof(ep->com.local_addr));\r\nmemcpy(&ep->com.remote_addr, &cm_id->m_remote_addr,\r\nsizeof(ep->com.remote_addr));\r\nerr = send_connect(ep);\r\nif (!err)\r\ngoto out;\r\nl2t_release(h->rdev.t3cdev_p, ep->l2t);\r\nfail4:\r\ndst_release(ep->dst);\r\nfail3:\r\ncxgb3_free_atid(ep->com.tdev, ep->atid);\r\nfail2:\r\ncm_id->rem_ref(cm_id);\r\nput_ep(&ep->com);\r\nout:\r\nreturn err;\r\n}\r\nint iwch_create_listen(struct iw_cm_id *cm_id, int backlog)\r\n{\r\nint err = 0;\r\nstruct iwch_dev *h = to_iwch_dev(cm_id->device);\r\nstruct iwch_listen_ep *ep;\r\nmight_sleep();\r\nif (cm_id->m_local_addr.ss_family != PF_INET) {\r\nerr = -ENOSYS;\r\ngoto fail1;\r\n}\r\nep = alloc_ep(sizeof(*ep), GFP_KERNEL);\r\nif (!ep) {\r\nprintk(KERN_ERR MOD "%s - cannot alloc ep.\n", __func__);\r\nerr = -ENOMEM;\r\ngoto fail1;\r\n}\r\nPDBG("%s ep %p\n", __func__, ep);\r\nep->com.tdev = h->rdev.t3cdev_p;\r\ncm_id->add_ref(cm_id);\r\nep->com.cm_id = cm_id;\r\nep->backlog = backlog;\r\nmemcpy(&ep->com.local_addr, &cm_id->m_local_addr,\r\nsizeof(ep->com.local_addr));\r\nep->stid = cxgb3_alloc_stid(h->rdev.t3cdev_p, &t3c_client, ep);\r\nif (ep->stid == -1) {\r\nprintk(KERN_ERR MOD "%s - cannot alloc atid.\n", __func__);\r\nerr = -ENOMEM;\r\ngoto fail2;\r\n}\r\nstate_set(&ep->com, LISTEN);\r\nerr = listen_start(ep);\r\nif (err)\r\ngoto fail3;\r\nwait_event(ep->com.waitq, ep->com.rpl_done);\r\nerr = ep->com.rpl_err;\r\nif (!err) {\r\ncm_id->provider_data = ep;\r\ngoto out;\r\n}\r\nfail3:\r\ncxgb3_free_stid(ep->com.tdev, ep->stid);\r\nfail2:\r\ncm_id->rem_ref(cm_id);\r\nput_ep(&ep->com);\r\nfail1:\r\nout:\r\nreturn err;\r\n}\r\nint iwch_destroy_listen(struct iw_cm_id *cm_id)\r\n{\r\nint err;\r\nstruct iwch_listen_ep *ep = to_listen_ep(cm_id);\r\nPDBG("%s ep %p\n", __func__, ep);\r\nmight_sleep();\r\nstate_set(&ep->com, DEAD);\r\nep->com.rpl_done = 0;\r\nep->com.rpl_err = 0;\r\nerr = listen_stop(ep);\r\nif (err)\r\ngoto done;\r\nwait_event(ep->com.waitq, ep->com.rpl_done);\r\ncxgb3_free_stid(ep->com.tdev, ep->stid);\r\ndone:\r\nerr = ep->com.rpl_err;\r\ncm_id->rem_ref(cm_id);\r\nput_ep(&ep->com);\r\nreturn err;\r\n}\r\nint iwch_ep_disconnect(struct iwch_ep *ep, int abrupt, gfp_t gfp)\r\n{\r\nint ret=0;\r\nunsigned long flags;\r\nint close = 0;\r\nint fatal = 0;\r\nstruct t3cdev *tdev;\r\nstruct cxio_rdev *rdev;\r\nspin_lock_irqsave(&ep->com.lock, flags);\r\nPDBG("%s ep %p state %s, abrupt %d\n", __func__, ep,\r\nstates[ep->com.state], abrupt);\r\ntdev = (struct t3cdev *)ep->com.tdev;\r\nrdev = (struct cxio_rdev *)tdev->ulp;\r\nif (cxio_fatal_error(rdev)) {\r\nfatal = 1;\r\nclose_complete_upcall(ep);\r\nep->com.state = DEAD;\r\n}\r\nswitch (ep->com.state) {\r\ncase MPA_REQ_WAIT:\r\ncase MPA_REQ_SENT:\r\ncase MPA_REQ_RCVD:\r\ncase MPA_REP_SENT:\r\ncase FPDU_MODE:\r\nclose = 1;\r\nif (abrupt)\r\nep->com.state = ABORTING;\r\nelse {\r\nep->com.state = CLOSING;\r\nstart_ep_timer(ep);\r\n}\r\nset_bit(CLOSE_SENT, &ep->com.flags);\r\nbreak;\r\ncase CLOSING:\r\nif (!test_and_set_bit(CLOSE_SENT, &ep->com.flags)) {\r\nclose = 1;\r\nif (abrupt) {\r\nstop_ep_timer(ep);\r\nep->com.state = ABORTING;\r\n} else\r\nep->com.state = MORIBUND;\r\n}\r\nbreak;\r\ncase MORIBUND:\r\ncase ABORTING:\r\ncase DEAD:\r\nPDBG("%s ignoring disconnect ep %p state %u\n",\r\n__func__, ep, ep->com.state);\r\nbreak;\r\ndefault:\r\nBUG();\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&ep->com.lock, flags);\r\nif (close) {\r\nif (abrupt)\r\nret = send_abort(ep, NULL, gfp);\r\nelse\r\nret = send_halfclose(ep, gfp);\r\nif (ret)\r\nfatal = 1;\r\n}\r\nif (fatal)\r\nrelease_ep_resources(ep);\r\nreturn ret;\r\n}\r\nint iwch_ep_redirect(void *ctx, struct dst_entry *old, struct dst_entry *new,\r\nstruct l2t_entry *l2t)\r\n{\r\nstruct iwch_ep *ep = ctx;\r\nif (ep->dst != old)\r\nreturn 0;\r\nPDBG("%s ep %p redirect to dst %p l2t %p\n", __func__, ep, new,\r\nl2t);\r\ndst_hold(new);\r\nl2t_release(ep->com.tdev, ep->l2t);\r\nep->l2t = l2t;\r\ndst_release(old);\r\nep->dst = new;\r\nreturn 1;\r\n}\r\nstatic void process_work(struct work_struct *work)\r\n{\r\nstruct sk_buff *skb = NULL;\r\nvoid *ep;\r\nstruct t3cdev *tdev;\r\nint ret;\r\nwhile ((skb = skb_dequeue(&rxq))) {\r\nep = *((void **) (skb->cb));\r\ntdev = *((struct t3cdev **) (skb->cb + sizeof(void *)));\r\nret = work_handlers[G_OPCODE(ntohl((__force __be32)skb->csum))](tdev, skb, ep);\r\nif (ret & CPL_RET_BUF_DONE)\r\nkfree_skb(skb);\r\nput_ep((struct iwch_ep_common *)ep);\r\n}\r\n}\r\nstatic int sched(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct iwch_ep_common *epc = ctx;\r\nget_ep(epc);\r\n*((void **) skb->cb) = ctx;\r\n*((struct t3cdev **) (skb->cb + sizeof(void *))) = tdev;\r\nskb_queue_tail(&rxq, skb);\r\nqueue_work(workq, &skb_work);\r\nreturn 0;\r\n}\r\nstatic int set_tcb_rpl(struct t3cdev *tdev, struct sk_buff *skb, void *ctx)\r\n{\r\nstruct cpl_set_tcb_rpl *rpl = cplhdr(skb);\r\nif (rpl->status != CPL_ERR_NONE) {\r\nprintk(KERN_ERR MOD "Unexpected SET_TCB_RPL status %u "\r\n"for tid %u\n", rpl->status, GET_TID(rpl));\r\n}\r\nreturn CPL_RET_BUF_DONE;\r\n}\r\nint __init iwch_cm_init(void)\r\n{\r\nskb_queue_head_init(&rxq);\r\nworkq = alloc_ordered_workqueue("iw_cxgb3", WQ_MEM_RECLAIM);\r\nif (!workq)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid __exit iwch_cm_term(void)\r\n{\r\nflush_workqueue(workq);\r\ndestroy_workqueue(workq);\r\n}
