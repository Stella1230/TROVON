static struct host1x_syncpt_base *\r\nhost1x_syncpt_base_request(struct host1x *host)\r\n{\r\nstruct host1x_syncpt_base *bases = host->bases;\r\nunsigned int i;\r\nfor (i = 0; i < host->info->nb_bases; i++)\r\nif (!bases[i].requested)\r\nbreak;\r\nif (i >= host->info->nb_bases)\r\nreturn NULL;\r\nbases[i].requested = true;\r\nreturn &bases[i];\r\n}\r\nstatic void host1x_syncpt_base_free(struct host1x_syncpt_base *base)\r\n{\r\nif (base)\r\nbase->requested = false;\r\n}\r\nstatic struct host1x_syncpt *host1x_syncpt_alloc(struct host1x *host,\r\nstruct device *dev,\r\nunsigned long flags)\r\n{\r\nint i;\r\nstruct host1x_syncpt *sp = host->syncpt;\r\nchar *name;\r\nmutex_lock(&host->syncpt_mutex);\r\nfor (i = 0; i < host->info->nb_pts && sp->name; i++, sp++)\r\n;\r\nif (i >= host->info->nb_pts)\r\ngoto unlock;\r\nif (flags & HOST1X_SYNCPT_HAS_BASE) {\r\nsp->base = host1x_syncpt_base_request(host);\r\nif (!sp->base)\r\ngoto unlock;\r\n}\r\nname = kasprintf(GFP_KERNEL, "%02u-%s", sp->id,\r\ndev ? dev_name(dev) : NULL);\r\nif (!name)\r\ngoto free_base;\r\nsp->dev = dev;\r\nsp->name = name;\r\nif (flags & HOST1X_SYNCPT_CLIENT_MANAGED)\r\nsp->client_managed = true;\r\nelse\r\nsp->client_managed = false;\r\nmutex_unlock(&host->syncpt_mutex);\r\nreturn sp;\r\nfree_base:\r\nhost1x_syncpt_base_free(sp->base);\r\nsp->base = NULL;\r\nunlock:\r\nmutex_unlock(&host->syncpt_mutex);\r\nreturn NULL;\r\n}\r\nu32 host1x_syncpt_id(struct host1x_syncpt *sp)\r\n{\r\nreturn sp->id;\r\n}\r\nu32 host1x_syncpt_incr_max(struct host1x_syncpt *sp, u32 incrs)\r\n{\r\nreturn (u32)atomic_add_return(incrs, &sp->max_val);\r\n}\r\nvoid host1x_syncpt_restore(struct host1x *host)\r\n{\r\nstruct host1x_syncpt *sp_base = host->syncpt;\r\nunsigned int i;\r\nfor (i = 0; i < host1x_syncpt_nb_pts(host); i++)\r\nhost1x_hw_syncpt_restore(host, sp_base + i);\r\nfor (i = 0; i < host1x_syncpt_nb_bases(host); i++)\r\nhost1x_hw_syncpt_restore_wait_base(host, sp_base + i);\r\nwmb();\r\n}\r\nvoid host1x_syncpt_save(struct host1x *host)\r\n{\r\nstruct host1x_syncpt *sp_base = host->syncpt;\r\nunsigned int i;\r\nfor (i = 0; i < host1x_syncpt_nb_pts(host); i++) {\r\nif (host1x_syncpt_client_managed(sp_base + i))\r\nhost1x_hw_syncpt_load(host, sp_base + i);\r\nelse\r\nWARN_ON(!host1x_syncpt_idle(sp_base + i));\r\n}\r\nfor (i = 0; i < host1x_syncpt_nb_bases(host); i++)\r\nhost1x_hw_syncpt_load_wait_base(host, sp_base + i);\r\n}\r\nu32 host1x_syncpt_load(struct host1x_syncpt *sp)\r\n{\r\nu32 val;\r\nval = host1x_hw_syncpt_load(sp->host, sp);\r\ntrace_host1x_syncpt_load_min(sp->id, val);\r\nreturn val;\r\n}\r\nu32 host1x_syncpt_load_wait_base(struct host1x_syncpt *sp)\r\n{\r\nhost1x_hw_syncpt_load_wait_base(sp->host, sp);\r\nreturn sp->base_val;\r\n}\r\nint host1x_syncpt_incr(struct host1x_syncpt *sp)\r\n{\r\nreturn host1x_hw_syncpt_cpu_incr(sp->host, sp);\r\n}\r\nstatic bool syncpt_load_min_is_expired(struct host1x_syncpt *sp, u32 thresh)\r\n{\r\nhost1x_hw_syncpt_load(sp->host, sp);\r\nreturn host1x_syncpt_is_expired(sp, thresh);\r\n}\r\nint host1x_syncpt_wait(struct host1x_syncpt *sp, u32 thresh, long timeout,\r\nu32 *value)\r\n{\r\nDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\r\nvoid *ref;\r\nstruct host1x_waitlist *waiter;\r\nint err = 0, check_count = 0;\r\nu32 val;\r\nif (value)\r\n*value = 0;\r\nif (host1x_syncpt_is_expired(sp, thresh)) {\r\nif (value)\r\n*value = host1x_syncpt_load(sp);\r\nreturn 0;\r\n}\r\nval = host1x_hw_syncpt_load(sp->host, sp);\r\nif (host1x_syncpt_is_expired(sp, thresh)) {\r\nif (value)\r\n*value = val;\r\ngoto done;\r\n}\r\nif (!timeout) {\r\nerr = -EAGAIN;\r\ngoto done;\r\n}\r\nwaiter = kzalloc(sizeof(*waiter), GFP_KERNEL);\r\nif (!waiter) {\r\nerr = -ENOMEM;\r\ngoto done;\r\n}\r\nerr = host1x_intr_add_action(sp->host, sp->id, thresh,\r\nHOST1X_INTR_ACTION_WAKEUP_INTERRUPTIBLE,\r\n&wq, waiter, &ref);\r\nif (err)\r\ngoto done;\r\nerr = -EAGAIN;\r\nif (timeout < 0)\r\ntimeout = LONG_MAX;\r\nwhile (timeout) {\r\nlong check = min_t(long, SYNCPT_CHECK_PERIOD, timeout);\r\nint remain;\r\nremain = wait_event_interruptible_timeout(wq,\r\nsyncpt_load_min_is_expired(sp, thresh),\r\ncheck);\r\nif (remain > 0 || host1x_syncpt_is_expired(sp, thresh)) {\r\nif (value)\r\n*value = host1x_syncpt_load(sp);\r\nerr = 0;\r\nbreak;\r\n}\r\nif (remain < 0) {\r\nerr = remain;\r\nbreak;\r\n}\r\ntimeout -= check;\r\nif (timeout && check_count <= MAX_STUCK_CHECK_COUNT) {\r\ndev_warn(sp->host->dev,\r\n"%s: syncpoint id %u (%s) stuck waiting %d, timeout=%ld\n",\r\ncurrent->comm, sp->id, sp->name,\r\nthresh, timeout);\r\nhost1x_debug_dump_syncpts(sp->host);\r\nif (check_count == MAX_STUCK_CHECK_COUNT)\r\nhost1x_debug_dump(sp->host);\r\ncheck_count++;\r\n}\r\n}\r\nhost1x_intr_put_ref(sp->host, sp->id, ref);\r\ndone:\r\nreturn err;\r\n}\r\nbool host1x_syncpt_is_expired(struct host1x_syncpt *sp, u32 thresh)\r\n{\r\nu32 current_val;\r\nu32 future_val;\r\nsmp_rmb();\r\ncurrent_val = (u32)atomic_read(&sp->min_val);\r\nfuture_val = (u32)atomic_read(&sp->max_val);\r\nif (!host1x_syncpt_client_managed(sp))\r\nreturn future_val - thresh >= current_val - thresh;\r\nelse\r\nreturn (s32)(current_val - thresh) >= 0;\r\n}\r\nint host1x_syncpt_patch_wait(struct host1x_syncpt *sp, void *patch_addr)\r\n{\r\nreturn host1x_hw_syncpt_patch_wait(sp->host, sp, patch_addr);\r\n}\r\nint host1x_syncpt_init(struct host1x *host)\r\n{\r\nstruct host1x_syncpt_base *bases;\r\nstruct host1x_syncpt *syncpt;\r\nunsigned int i;\r\nsyncpt = devm_kcalloc(host->dev, host->info->nb_pts, sizeof(*syncpt),\r\nGFP_KERNEL);\r\nif (!syncpt)\r\nreturn -ENOMEM;\r\nbases = devm_kcalloc(host->dev, host->info->nb_bases, sizeof(*bases),\r\nGFP_KERNEL);\r\nif (!bases)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < host->info->nb_pts; i++) {\r\nsyncpt[i].id = i;\r\nsyncpt[i].host = host;\r\n}\r\nfor (i = 0; i < host->info->nb_bases; i++)\r\nbases[i].id = i;\r\nmutex_init(&host->syncpt_mutex);\r\nhost->syncpt = syncpt;\r\nhost->bases = bases;\r\nhost1x_syncpt_restore(host);\r\nhost->nop_sp = host1x_syncpt_alloc(host, NULL, 0);\r\nif (!host->nop_sp)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstruct host1x_syncpt *host1x_syncpt_request(struct device *dev,\r\nunsigned long flags)\r\n{\r\nstruct host1x *host = dev_get_drvdata(dev->parent);\r\nreturn host1x_syncpt_alloc(host, dev, flags);\r\n}\r\nvoid host1x_syncpt_free(struct host1x_syncpt *sp)\r\n{\r\nif (!sp)\r\nreturn;\r\nmutex_lock(&sp->host->syncpt_mutex);\r\nhost1x_syncpt_base_free(sp->base);\r\nkfree(sp->name);\r\nsp->base = NULL;\r\nsp->dev = NULL;\r\nsp->name = NULL;\r\nsp->client_managed = false;\r\nmutex_unlock(&sp->host->syncpt_mutex);\r\n}\r\nvoid host1x_syncpt_deinit(struct host1x *host)\r\n{\r\nstruct host1x_syncpt *sp = host->syncpt;\r\nunsigned int i;\r\nfor (i = 0; i < host->info->nb_pts; i++, sp++)\r\nkfree(sp->name);\r\n}\r\nu32 host1x_syncpt_read_max(struct host1x_syncpt *sp)\r\n{\r\nsmp_rmb();\r\nreturn (u32)atomic_read(&sp->max_val);\r\n}\r\nu32 host1x_syncpt_read_min(struct host1x_syncpt *sp)\r\n{\r\nsmp_rmb();\r\nreturn (u32)atomic_read(&sp->min_val);\r\n}\r\nu32 host1x_syncpt_read(struct host1x_syncpt *sp)\r\n{\r\nreturn host1x_syncpt_load(sp);\r\n}\r\nunsigned int host1x_syncpt_nb_pts(struct host1x *host)\r\n{\r\nreturn host->info->nb_pts;\r\n}\r\nunsigned int host1x_syncpt_nb_bases(struct host1x *host)\r\n{\r\nreturn host->info->nb_bases;\r\n}\r\nunsigned int host1x_syncpt_nb_mlocks(struct host1x *host)\r\n{\r\nreturn host->info->nb_mlocks;\r\n}\r\nstruct host1x_syncpt *host1x_syncpt_get(struct host1x *host, unsigned int id)\r\n{\r\nif (host->info->nb_pts < id)\r\nreturn NULL;\r\nreturn host->syncpt + id;\r\n}\r\nstruct host1x_syncpt_base *host1x_syncpt_get_base(struct host1x_syncpt *sp)\r\n{\r\nreturn sp ? sp->base : NULL;\r\n}\r\nu32 host1x_syncpt_base_id(struct host1x_syncpt_base *base)\r\n{\r\nreturn base->id;\r\n}
