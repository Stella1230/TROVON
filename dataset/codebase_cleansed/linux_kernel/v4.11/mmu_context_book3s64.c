int __init_new_context(void)\r\n{\r\nint index;\r\nint err;\r\nagain:\r\nif (!ida_pre_get(&mmu_context_ida, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nspin_lock(&mmu_context_lock);\r\nerr = ida_get_new_above(&mmu_context_ida, 1, &index);\r\nspin_unlock(&mmu_context_lock);\r\nif (err == -EAGAIN)\r\ngoto again;\r\nelse if (err)\r\nreturn err;\r\nif (index > MAX_USER_CONTEXT) {\r\nspin_lock(&mmu_context_lock);\r\nida_remove(&mmu_context_ida, index);\r\nspin_unlock(&mmu_context_lock);\r\nreturn -ENOMEM;\r\n}\r\nreturn index;\r\n}\r\nstatic int radix__init_new_context(struct mm_struct *mm, int index)\r\n{\r\nunsigned long rts_field;\r\nrts_field = radix__get_tree_size();\r\nprocess_tb[index].prtb0 = cpu_to_be64(rts_field | __pa(mm->pgd) | RADIX_PGD_INDEX_SIZE);\r\nreturn 0;\r\n}\r\nint init_new_context(struct task_struct *tsk, struct mm_struct *mm)\r\n{\r\nint index;\r\nindex = __init_new_context();\r\nif (index < 0)\r\nreturn index;\r\nif (radix_enabled()) {\r\nradix__init_new_context(mm, index);\r\n} else {\r\nif (mm->context.id == 0)\r\nslice_set_user_psize(mm, mmu_virtual_psize);\r\nsubpage_prot_init_new_context(mm);\r\n}\r\nmm->context.id = index;\r\n#ifdef CONFIG_PPC_ICSWX\r\nmm->context.cop_lockp = kmalloc(sizeof(spinlock_t), GFP_KERNEL);\r\nif (!mm->context.cop_lockp) {\r\n__destroy_context(index);\r\nsubpage_prot_free(mm);\r\nmm->context.id = MMU_NO_CONTEXT;\r\nreturn -ENOMEM;\r\n}\r\nspin_lock_init(mm->context.cop_lockp);\r\n#endif\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nmm->context.pte_frag = NULL;\r\n#endif\r\n#ifdef CONFIG_SPAPR_TCE_IOMMU\r\nmm_iommu_init(mm);\r\n#endif\r\nreturn 0;\r\n}\r\nvoid __destroy_context(int context_id)\r\n{\r\nspin_lock(&mmu_context_lock);\r\nida_remove(&mmu_context_ida, context_id);\r\nspin_unlock(&mmu_context_lock);\r\n}\r\nstatic void destroy_pagetable_page(struct mm_struct *mm)\r\n{\r\nint count;\r\nvoid *pte_frag;\r\nstruct page *page;\r\npte_frag = mm->context.pte_frag;\r\nif (!pte_frag)\r\nreturn;\r\npage = virt_to_page(pte_frag);\r\ncount = ((unsigned long)pte_frag & ~PAGE_MASK) >> PTE_FRAG_SIZE_SHIFT;\r\nif (page_ref_sub_and_test(page, PTE_FRAG_NR - count)) {\r\npgtable_page_dtor(page);\r\nfree_hot_cold_page(page, 0);\r\n}\r\n}\r\nstatic inline void destroy_pagetable_page(struct mm_struct *mm)\r\n{\r\nreturn;\r\n}\r\nvoid destroy_context(struct mm_struct *mm)\r\n{\r\n#ifdef CONFIG_SPAPR_TCE_IOMMU\r\nWARN_ON_ONCE(!list_empty(&mm->context.iommu_group_mem_list));\r\n#endif\r\n#ifdef CONFIG_PPC_ICSWX\r\ndrop_cop(mm->context.acop, mm);\r\nkfree(mm->context.cop_lockp);\r\nmm->context.cop_lockp = NULL;\r\n#endif\r\nif (radix_enabled())\r\nprocess_tb[mm->context.id].prtb1 = 0;\r\nelse\r\nsubpage_prot_free(mm);\r\ndestroy_pagetable_page(mm);\r\n__destroy_context(mm->context.id);\r\nmm->context.id = MMU_NO_CONTEXT;\r\n}\r\nvoid radix__switch_mmu_context(struct mm_struct *prev, struct mm_struct *next)\r\n{\r\nasm volatile("isync": : :"memory");\r\nmtspr(SPRN_PID, next->context.id);\r\nasm volatile("isync \n"\r\nPPC_SLBIA(0x7)\r\n: : :"memory");\r\n}
