static int vsp1_dl_body_init(struct vsp1_device *vsp1,\r\nstruct vsp1_dl_body *dlb, unsigned int num_entries,\r\nsize_t extra_size)\r\n{\r\nsize_t size = num_entries * sizeof(*dlb->entries) + extra_size;\r\ndlb->vsp1 = vsp1;\r\ndlb->size = size;\r\ndlb->entries = dma_alloc_wc(vsp1->dev, dlb->size, &dlb->dma,\r\nGFP_KERNEL);\r\nif (!dlb->entries)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic void vsp1_dl_body_cleanup(struct vsp1_dl_body *dlb)\r\n{\r\ndma_free_wc(dlb->vsp1->dev, dlb->size, dlb->entries, dlb->dma);\r\n}\r\nstruct vsp1_dl_body *vsp1_dl_fragment_alloc(struct vsp1_device *vsp1,\r\nunsigned int num_entries)\r\n{\r\nstruct vsp1_dl_body *dlb;\r\nint ret;\r\ndlb = kzalloc(sizeof(*dlb), GFP_KERNEL);\r\nif (!dlb)\r\nreturn NULL;\r\nret = vsp1_dl_body_init(vsp1, dlb, num_entries, 0);\r\nif (ret < 0) {\r\nkfree(dlb);\r\nreturn NULL;\r\n}\r\nreturn dlb;\r\n}\r\nvoid vsp1_dl_fragment_free(struct vsp1_dl_body *dlb)\r\n{\r\nif (!dlb)\r\nreturn;\r\nvsp1_dl_body_cleanup(dlb);\r\nkfree(dlb);\r\n}\r\nvoid vsp1_dl_fragment_write(struct vsp1_dl_body *dlb, u32 reg, u32 data)\r\n{\r\ndlb->entries[dlb->num_entries].addr = reg;\r\ndlb->entries[dlb->num_entries].data = data;\r\ndlb->num_entries++;\r\n}\r\nstatic struct vsp1_dl_list *vsp1_dl_list_alloc(struct vsp1_dl_manager *dlm)\r\n{\r\nstruct vsp1_dl_list *dl;\r\nsize_t header_size;\r\nint ret;\r\ndl = kzalloc(sizeof(*dl), GFP_KERNEL);\r\nif (!dl)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&dl->fragments);\r\ndl->dlm = dlm;\r\nheader_size = dlm->mode == VSP1_DL_MODE_HEADER\r\n? ALIGN(sizeof(struct vsp1_dl_header), 8)\r\n: 0;\r\nret = vsp1_dl_body_init(dlm->vsp1, &dl->body0, VSP1_DL_NUM_ENTRIES,\r\nheader_size);\r\nif (ret < 0) {\r\nkfree(dl);\r\nreturn NULL;\r\n}\r\nif (dlm->mode == VSP1_DL_MODE_HEADER) {\r\nsize_t header_offset = VSP1_DL_NUM_ENTRIES\r\n* sizeof(*dl->body0.entries);\r\ndl->header = ((void *)dl->body0.entries) + header_offset;\r\ndl->dma = dl->body0.dma + header_offset;\r\nmemset(dl->header, 0, sizeof(*dl->header));\r\ndl->header->lists[0].addr = dl->body0.dma;\r\n}\r\nreturn dl;\r\n}\r\nstatic void vsp1_dl_list_free(struct vsp1_dl_list *dl)\r\n{\r\nvsp1_dl_body_cleanup(&dl->body0);\r\nlist_splice_init(&dl->fragments, &dl->dlm->gc_fragments);\r\nkfree(dl);\r\n}\r\nstruct vsp1_dl_list *vsp1_dl_list_get(struct vsp1_dl_manager *dlm)\r\n{\r\nstruct vsp1_dl_list *dl = NULL;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dlm->lock, flags);\r\nif (!list_empty(&dlm->free)) {\r\ndl = list_first_entry(&dlm->free, struct vsp1_dl_list, list);\r\nlist_del(&dl->list);\r\nINIT_LIST_HEAD(&dl->chain);\r\n}\r\nspin_unlock_irqrestore(&dlm->lock, flags);\r\nreturn dl;\r\n}\r\nstatic void __vsp1_dl_list_put(struct vsp1_dl_list *dl)\r\n{\r\nstruct vsp1_dl_list *dl_child;\r\nif (!dl)\r\nreturn;\r\nif (dl->has_chain) {\r\nlist_for_each_entry(dl_child, &dl->chain, chain)\r\n__vsp1_dl_list_put(dl_child);\r\n}\r\ndl->has_chain = false;\r\nif (!list_empty(&dl->fragments)) {\r\nlist_splice_init(&dl->fragments, &dl->dlm->gc_fragments);\r\nschedule_work(&dl->dlm->gc_work);\r\n}\r\ndl->body0.num_entries = 0;\r\nlist_add_tail(&dl->list, &dl->dlm->free);\r\n}\r\nvoid vsp1_dl_list_put(struct vsp1_dl_list *dl)\r\n{\r\nunsigned long flags;\r\nif (!dl)\r\nreturn;\r\nspin_lock_irqsave(&dl->dlm->lock, flags);\r\n__vsp1_dl_list_put(dl);\r\nspin_unlock_irqrestore(&dl->dlm->lock, flags);\r\n}\r\nvoid vsp1_dl_list_write(struct vsp1_dl_list *dl, u32 reg, u32 data)\r\n{\r\nvsp1_dl_fragment_write(&dl->body0, reg, data);\r\n}\r\nint vsp1_dl_list_add_fragment(struct vsp1_dl_list *dl,\r\nstruct vsp1_dl_body *dlb)\r\n{\r\nif (dl->dlm->mode != VSP1_DL_MODE_HEADER)\r\nreturn -EINVAL;\r\nlist_add_tail(&dlb->list, &dl->fragments);\r\nreturn 0;\r\n}\r\nint vsp1_dl_list_add_chain(struct vsp1_dl_list *head,\r\nstruct vsp1_dl_list *dl)\r\n{\r\nif (head->dlm->mode != VSP1_DL_MODE_HEADER)\r\nreturn -EINVAL;\r\nhead->has_chain = true;\r\nlist_add_tail(&dl->chain, &head->chain);\r\nreturn 0;\r\n}\r\nstatic void vsp1_dl_list_fill_header(struct vsp1_dl_list *dl, bool is_last)\r\n{\r\nstruct vsp1_dl_header_list *hdr = dl->header->lists;\r\nstruct vsp1_dl_body *dlb;\r\nunsigned int num_lists = 0;\r\nhdr->num_bytes = dl->body0.num_entries\r\n* sizeof(*dl->header->lists);\r\nlist_for_each_entry(dlb, &dl->fragments, list) {\r\nnum_lists++;\r\nhdr++;\r\nhdr->addr = dlb->dma;\r\nhdr->num_bytes = dlb->num_entries\r\n* sizeof(*dl->header->lists);\r\n}\r\ndl->header->num_lists = num_lists;\r\nif (!list_empty(&dl->chain) && !is_last) {\r\nstruct vsp1_dl_list *next = list_next_entry(dl, chain);\r\ndl->header->next_header = next->dma;\r\ndl->header->flags = VSP1_DLH_AUTO_START;\r\n} else {\r\ndl->header->flags = VSP1_DLH_INT_ENABLE;\r\n}\r\n}\r\nvoid vsp1_dl_list_commit(struct vsp1_dl_list *dl)\r\n{\r\nstruct vsp1_dl_manager *dlm = dl->dlm;\r\nstruct vsp1_device *vsp1 = dlm->vsp1;\r\nunsigned long flags;\r\nbool update;\r\nspin_lock_irqsave(&dlm->lock, flags);\r\nif (dl->dlm->mode == VSP1_DL_MODE_HEADER) {\r\nstruct vsp1_dl_list *dl_child;\r\nvsp1_dl_list_fill_header(dl, list_empty(&dl->chain));\r\nlist_for_each_entry(dl_child, &dl->chain, chain) {\r\nbool last = list_is_last(&dl_child->chain, &dl->chain);\r\nvsp1_dl_list_fill_header(dl_child, last);\r\n}\r\nvsp1_write(vsp1, VI6_DL_HDR_ADDR(dlm->index), dl->dma);\r\ndlm->active = dl;\r\ngoto done;\r\n}\r\nupdate = !!(vsp1_read(vsp1, VI6_DL_BODY_SIZE) & VI6_DL_BODY_SIZE_UPD);\r\nif (update) {\r\n__vsp1_dl_list_put(dlm->pending);\r\ndlm->pending = dl;\r\ngoto done;\r\n}\r\nvsp1_write(vsp1, VI6_DL_HDR_ADDR(0), dl->body0.dma);\r\nvsp1_write(vsp1, VI6_DL_BODY_SIZE, VI6_DL_BODY_SIZE_UPD |\r\n(dl->body0.num_entries * sizeof(*dl->header->lists)));\r\n__vsp1_dl_list_put(dlm->queued);\r\ndlm->queued = dl;\r\ndone:\r\nspin_unlock_irqrestore(&dlm->lock, flags);\r\n}\r\nvoid vsp1_dlm_irq_display_start(struct vsp1_dl_manager *dlm)\r\n{\r\nspin_lock(&dlm->lock);\r\n__vsp1_dl_list_put(dlm->active);\r\ndlm->active = NULL;\r\nspin_unlock(&dlm->lock);\r\n}\r\nvoid vsp1_dlm_irq_frame_end(struct vsp1_dl_manager *dlm)\r\n{\r\nstruct vsp1_device *vsp1 = dlm->vsp1;\r\nspin_lock(&dlm->lock);\r\n__vsp1_dl_list_put(dlm->active);\r\ndlm->active = NULL;\r\nif (dlm->mode == VSP1_DL_MODE_HEADER)\r\ngoto done;\r\nif (vsp1_read(vsp1, VI6_DL_BODY_SIZE) & VI6_DL_BODY_SIZE_UPD)\r\ngoto done;\r\nif (dlm->queued) {\r\ndlm->active = dlm->queued;\r\ndlm->queued = NULL;\r\n}\r\nif (dlm->pending) {\r\nstruct vsp1_dl_list *dl = dlm->pending;\r\nvsp1_write(vsp1, VI6_DL_HDR_ADDR(0), dl->body0.dma);\r\nvsp1_write(vsp1, VI6_DL_BODY_SIZE, VI6_DL_BODY_SIZE_UPD |\r\n(dl->body0.num_entries *\r\nsizeof(*dl->header->lists)));\r\ndlm->queued = dl;\r\ndlm->pending = NULL;\r\n}\r\ndone:\r\nspin_unlock(&dlm->lock);\r\n}\r\nvoid vsp1_dlm_setup(struct vsp1_device *vsp1)\r\n{\r\nu32 ctrl = (256 << VI6_DL_CTRL_AR_WAIT_SHIFT)\r\n| VI6_DL_CTRL_DC2 | VI6_DL_CTRL_DC1 | VI6_DL_CTRL_DC0\r\n| VI6_DL_CTRL_DLE;\r\nif (vsp1->drm)\r\nctrl |= VI6_DL_CTRL_CFM0 | VI6_DL_CTRL_NH0;\r\nvsp1_write(vsp1, VI6_DL_CTRL, ctrl);\r\nvsp1_write(vsp1, VI6_DL_SWAP, VI6_DL_SWAP_LWS);\r\n}\r\nvoid vsp1_dlm_reset(struct vsp1_dl_manager *dlm)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&dlm->lock, flags);\r\n__vsp1_dl_list_put(dlm->active);\r\n__vsp1_dl_list_put(dlm->queued);\r\n__vsp1_dl_list_put(dlm->pending);\r\nspin_unlock_irqrestore(&dlm->lock, flags);\r\ndlm->active = NULL;\r\ndlm->queued = NULL;\r\ndlm->pending = NULL;\r\n}\r\nstatic void vsp1_dlm_fragments_free(struct vsp1_dl_manager *dlm)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&dlm->lock, flags);\r\nwhile (!list_empty(&dlm->gc_fragments)) {\r\nstruct vsp1_dl_body *dlb;\r\ndlb = list_first_entry(&dlm->gc_fragments, struct vsp1_dl_body,\r\nlist);\r\nlist_del(&dlb->list);\r\nspin_unlock_irqrestore(&dlm->lock, flags);\r\nvsp1_dl_fragment_free(dlb);\r\nspin_lock_irqsave(&dlm->lock, flags);\r\n}\r\nspin_unlock_irqrestore(&dlm->lock, flags);\r\n}\r\nstatic void vsp1_dlm_garbage_collect(struct work_struct *work)\r\n{\r\nstruct vsp1_dl_manager *dlm =\r\ncontainer_of(work, struct vsp1_dl_manager, gc_work);\r\nvsp1_dlm_fragments_free(dlm);\r\n}\r\nstruct vsp1_dl_manager *vsp1_dlm_create(struct vsp1_device *vsp1,\r\nunsigned int index,\r\nunsigned int prealloc)\r\n{\r\nstruct vsp1_dl_manager *dlm;\r\nunsigned int i;\r\ndlm = devm_kzalloc(vsp1->dev, sizeof(*dlm), GFP_KERNEL);\r\nif (!dlm)\r\nreturn NULL;\r\ndlm->index = index;\r\ndlm->mode = index == 0 && !vsp1->info->uapi\r\n? VSP1_DL_MODE_HEADERLESS : VSP1_DL_MODE_HEADER;\r\ndlm->vsp1 = vsp1;\r\nspin_lock_init(&dlm->lock);\r\nINIT_LIST_HEAD(&dlm->free);\r\nINIT_LIST_HEAD(&dlm->gc_fragments);\r\nINIT_WORK(&dlm->gc_work, vsp1_dlm_garbage_collect);\r\nfor (i = 0; i < prealloc; ++i) {\r\nstruct vsp1_dl_list *dl;\r\ndl = vsp1_dl_list_alloc(dlm);\r\nif (!dl)\r\nreturn NULL;\r\nlist_add_tail(&dl->list, &dlm->free);\r\n}\r\nreturn dlm;\r\n}\r\nvoid vsp1_dlm_destroy(struct vsp1_dl_manager *dlm)\r\n{\r\nstruct vsp1_dl_list *dl, *next;\r\nif (!dlm)\r\nreturn;\r\ncancel_work_sync(&dlm->gc_work);\r\nlist_for_each_entry_safe(dl, next, &dlm->free, list) {\r\nlist_del(&dl->list);\r\nvsp1_dl_list_free(dl);\r\n}\r\nvsp1_dlm_fragments_free(dlm);\r\n}
