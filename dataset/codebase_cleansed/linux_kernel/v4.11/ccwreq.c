int lpm_adjust(int lpm, int mask)\r\n{\r\nwhile (lpm && ((lpm & mask) == 0))\r\nlpm >>= 1;\r\nreturn lpm;\r\n}\r\nstatic u16 ccwreq_next_path(struct ccw_device *cdev)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nif (!req->singlepath) {\r\nreq->mask = 0;\r\ngoto out;\r\n}\r\nreq->retries = req->maxretries;\r\nreq->mask = lpm_adjust(req->mask >> 1, req->lpm);\r\nout:\r\nreturn req->mask;\r\n}\r\nstatic void ccwreq_stop(struct ccw_device *cdev, int rc)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nif (req->done)\r\nreturn;\r\nreq->done = 1;\r\nccw_device_set_timeout(cdev, 0);\r\nmemset(&cdev->private->irb, 0, sizeof(struct irb));\r\nif (rc && rc != -ENODEV && req->drc)\r\nrc = req->drc;\r\nreq->callback(cdev, req->data, rc);\r\n}\r\nstatic void ccwreq_do(struct ccw_device *cdev)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw1 *cp = req->cp;\r\nint rc = -EACCES;\r\nwhile (req->mask) {\r\nif (req->retries-- == 0) {\r\nccwreq_next_path(cdev);\r\ncontinue;\r\n}\r\nmemset(&cdev->private->irb, 0, sizeof(struct irb));\r\nrc = cio_start(sch, cp, (u8) req->mask);\r\nif (rc == 0) {\r\nccw_device_set_timeout(cdev, req->timeout);\r\nreturn;\r\n}\r\nif (rc == -ENODEV) {\r\nbreak;\r\n}\r\nif (rc == -EACCES) {\r\nccwreq_next_path(cdev);\r\ncontinue;\r\n}\r\nrc = cio_clear(sch);\r\nif (rc)\r\nbreak;\r\nreturn;\r\n}\r\nccwreq_stop(cdev, rc);\r\n}\r\nvoid ccw_request_start(struct ccw_device *cdev)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nif (req->singlepath) {\r\nreq->mask = 0x8080;\r\n} else\r\nreq->mask = req->lpm;\r\nreq->retries = req->maxretries;\r\nreq->mask = lpm_adjust(req->mask, req->lpm);\r\nreq->drc = 0;\r\nreq->done = 0;\r\nreq->cancel = 0;\r\nif (!req->mask)\r\ngoto out_nopath;\r\nccwreq_do(cdev);\r\nreturn;\r\nout_nopath:\r\nccwreq_stop(cdev, -EACCES);\r\n}\r\nint ccw_request_cancel(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nint rc;\r\nif (req->done)\r\nreturn 1;\r\nreq->cancel = 1;\r\nrc = cio_clear(sch);\r\nif (rc)\r\nccwreq_stop(cdev, rc);\r\nreturn 0;\r\n}\r\nstatic enum io_status ccwreq_status(struct ccw_device *cdev, struct irb *lcirb)\r\n{\r\nstruct irb *irb = &cdev->private->irb;\r\nstruct cmd_scsw *scsw = &irb->scsw.cmd;\r\nenum uc_todo todo;\r\nif (ccw_device_accumulate_and_sense(cdev, lcirb))\r\nreturn IO_RUNNING;\r\nif (scsw->fctl & (SCSW_FCTL_HALT_FUNC | SCSW_FCTL_CLEAR_FUNC))\r\nreturn IO_KILLED;\r\nif (scsw->cc == 3 || scsw->pno)\r\nreturn IO_PATH_ERROR;\r\nif (irb->esw.esw0.erw.cons) {\r\nCIO_TRACE_EVENT(2, "sensedata");\r\nCIO_HEX_EVENT(2, &cdev->private->dev_id,\r\nsizeof(struct ccw_dev_id));\r\nCIO_HEX_EVENT(2, &cdev->private->irb.ecw, SENSE_MAX_COUNT);\r\nif (irb->ecw[0] & SNS0_CMD_REJECT)\r\nreturn IO_REJECTED;\r\nif (cdev->drv && cdev->drv->uc_handler) {\r\ntodo = cdev->drv->uc_handler(cdev, lcirb);\r\nCIO_TRACE_EVENT(2, "uc_response");\r\nCIO_HEX_EVENT(2, &todo, sizeof(todo));\r\nswitch (todo) {\r\ncase UC_TODO_RETRY:\r\nreturn IO_STATUS_ERROR;\r\ncase UC_TODO_RETRY_ON_NEW_PATH:\r\nreturn IO_PATH_ERROR;\r\ncase UC_TODO_STOP:\r\nreturn IO_REJECTED;\r\ndefault:\r\nreturn IO_STATUS_ERROR;\r\n}\r\n}\r\nreturn IO_STATUS_ERROR;\r\n}\r\nif (scsw->cstat != 0)\r\nreturn IO_STATUS_ERROR;\r\nif (scsw->dstat & ~(DEV_STAT_CHN_END | DEV_STAT_DEV_END))\r\nreturn IO_STATUS_ERROR;\r\nif (!(scsw->dstat & DEV_STAT_DEV_END))\r\nreturn IO_RUNNING;\r\nif (scsw->cc == 1 && (scsw->stctl & SCSW_STCTL_ALERT_STATUS))\r\nreturn IO_STATUS_ERROR;\r\nreturn IO_DONE;\r\n}\r\nstatic void ccwreq_log_status(struct ccw_device *cdev, enum io_status status)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nstruct {\r\nstruct ccw_dev_id dev_id;\r\nu16 retries;\r\nu8 lpm;\r\nu8 status;\r\n} __attribute__ ((packed)) data;\r\ndata.dev_id = cdev->private->dev_id;\r\ndata.retries = req->retries;\r\ndata.lpm = (u8) req->mask;\r\ndata.status = (u8) status;\r\nCIO_TRACE_EVENT(2, "reqstat");\r\nCIO_HEX_EVENT(2, &data, sizeof(data));\r\n}\r\nvoid ccw_request_handler(struct ccw_device *cdev)\r\n{\r\nstruct irb *irb = this_cpu_ptr(&cio_irb);\r\nstruct ccw_request *req = &cdev->private->req;\r\nenum io_status status;\r\nint rc = -EOPNOTSUPP;\r\nstatus = ccwreq_status(cdev, irb);\r\nif (req->filter)\r\nstatus = req->filter(cdev, req->data, irb, status);\r\nif (status != IO_RUNNING)\r\nccw_device_set_timeout(cdev, 0);\r\nif (status != IO_DONE && status != IO_RUNNING)\r\nccwreq_log_status(cdev, status);\r\nswitch (status) {\r\ncase IO_DONE:\r\nbreak;\r\ncase IO_RUNNING:\r\nreturn;\r\ncase IO_REJECTED:\r\ngoto err;\r\ncase IO_PATH_ERROR:\r\ngoto out_next_path;\r\ncase IO_STATUS_ERROR:\r\ngoto out_restart;\r\ncase IO_KILLED:\r\nif (req->cancel) {\r\nrc = -EIO;\r\ngoto err;\r\n}\r\ngoto out_restart;\r\n}\r\nif (!req->check)\r\ngoto out;\r\nswitch (req->check(cdev, req->data)) {\r\ncase 0:\r\nbreak;\r\ncase -EAGAIN:\r\ngoto out_restart;\r\ncase -EACCES:\r\ngoto out_next_path;\r\ndefault:\r\ngoto err;\r\n}\r\nout:\r\nccwreq_stop(cdev, 0);\r\nreturn;\r\nout_next_path:\r\nif (!ccwreq_next_path(cdev)) {\r\nrc = -EACCES;\r\ngoto err;\r\n}\r\nout_restart:\r\nccwreq_do(cdev);\r\nreturn;\r\nerr:\r\nccwreq_stop(cdev, rc);\r\n}\r\nvoid ccw_request_timeout(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nint rc = -ENODEV, chp;\r\nif (cio_update_schib(sch))\r\ngoto err;\r\nfor (chp = 0; chp < 8; chp++) {\r\nif ((0x80 >> chp) & sch->schib.pmcw.lpum)\r\npr_warn("%s: No interrupt was received within %lus (CS=%02x, DS=%02x, CHPID=%x.%02x)\n",\r\ndev_name(&cdev->dev), req->timeout / HZ,\r\nscsw_cstat(&sch->schib.scsw),\r\nscsw_dstat(&sch->schib.scsw),\r\nsch->schid.cssid,\r\nsch->schib.pmcw.chpid[chp]);\r\n}\r\nif (!ccwreq_next_path(cdev)) {\r\nreq->drc = -ETIME;\r\n}\r\nrc = cio_clear(sch);\r\nif (rc)\r\ngoto err;\r\nreturn;\r\nerr:\r\nccwreq_stop(cdev, rc);\r\n}\r\nvoid ccw_request_notoper(struct ccw_device *cdev)\r\n{\r\nccwreq_stop(cdev, -ENODEV);\r\n}
