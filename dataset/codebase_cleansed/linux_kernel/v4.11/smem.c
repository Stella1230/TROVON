static struct smem_private_entry *\r\nphdr_to_last_private_entry(struct smem_partition_header *phdr)\r\n{\r\nvoid *p = phdr;\r\nreturn p + le32_to_cpu(phdr->offset_free_uncached);\r\n}\r\nstatic void *phdr_to_first_cached_entry(struct smem_partition_header *phdr)\r\n{\r\nvoid *p = phdr;\r\nreturn p + le32_to_cpu(phdr->offset_free_cached);\r\n}\r\nstatic struct smem_private_entry *\r\nphdr_to_first_private_entry(struct smem_partition_header *phdr)\r\n{\r\nvoid *p = phdr;\r\nreturn p + sizeof(*phdr);\r\n}\r\nstatic struct smem_private_entry *\r\nprivate_entry_next(struct smem_private_entry *e)\r\n{\r\nvoid *p = e;\r\nreturn p + sizeof(*e) + le16_to_cpu(e->padding_hdr) +\r\nle32_to_cpu(e->size);\r\n}\r\nstatic void *entry_to_item(struct smem_private_entry *e)\r\n{\r\nvoid *p = e;\r\nreturn p + sizeof(*e) + le16_to_cpu(e->padding_hdr);\r\n}\r\nstatic int qcom_smem_alloc_private(struct qcom_smem *smem,\r\nunsigned host,\r\nunsigned item,\r\nsize_t size)\r\n{\r\nstruct smem_partition_header *phdr;\r\nstruct smem_private_entry *hdr, *end;\r\nsize_t alloc_size;\r\nvoid *cached;\r\nphdr = smem->partitions[host];\r\nhdr = phdr_to_first_private_entry(phdr);\r\nend = phdr_to_last_private_entry(phdr);\r\ncached = phdr_to_first_cached_entry(phdr);\r\nwhile (hdr < end) {\r\nif (hdr->canary != SMEM_PRIVATE_CANARY) {\r\ndev_err(smem->dev,\r\n"Found invalid canary in host %d partition\n",\r\nhost);\r\nreturn -EINVAL;\r\n}\r\nif (le16_to_cpu(hdr->item) == item)\r\nreturn -EEXIST;\r\nhdr = private_entry_next(hdr);\r\n}\r\nalloc_size = sizeof(*hdr) + ALIGN(size, 8);\r\nif ((void *)hdr + alloc_size >= cached) {\r\ndev_err(smem->dev, "Out of memory\n");\r\nreturn -ENOSPC;\r\n}\r\nhdr->canary = SMEM_PRIVATE_CANARY;\r\nhdr->item = cpu_to_le16(item);\r\nhdr->size = cpu_to_le32(ALIGN(size, 8));\r\nhdr->padding_data = cpu_to_le16(le32_to_cpu(hdr->size) - size);\r\nhdr->padding_hdr = 0;\r\nwmb();\r\nle32_add_cpu(&phdr->offset_free_uncached, alloc_size);\r\nreturn 0;\r\n}\r\nstatic int qcom_smem_alloc_global(struct qcom_smem *smem,\r\nunsigned item,\r\nsize_t size)\r\n{\r\nstruct smem_header *header;\r\nstruct smem_global_entry *entry;\r\nif (WARN_ON(item >= SMEM_ITEM_COUNT))\r\nreturn -EINVAL;\r\nheader = smem->regions[0].virt_base;\r\nentry = &header->toc[item];\r\nif (entry->allocated)\r\nreturn -EEXIST;\r\nsize = ALIGN(size, 8);\r\nif (WARN_ON(size > le32_to_cpu(header->available)))\r\nreturn -ENOMEM;\r\nentry->offset = header->free_offset;\r\nentry->size = cpu_to_le32(size);\r\nwmb();\r\nentry->allocated = cpu_to_le32(1);\r\nle32_add_cpu(&header->free_offset, size);\r\nle32_add_cpu(&header->available, -size);\r\nreturn 0;\r\n}\r\nint qcom_smem_alloc(unsigned host, unsigned item, size_t size)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nif (!__smem)\r\nreturn -EPROBE_DEFER;\r\nif (item < SMEM_ITEM_LAST_FIXED) {\r\ndev_err(__smem->dev,\r\n"Rejecting allocation of static entry %d\n", item);\r\nreturn -EINVAL;\r\n}\r\nret = hwspin_lock_timeout_irqsave(__smem->hwlock,\r\nHWSPINLOCK_TIMEOUT,\r\n&flags);\r\nif (ret)\r\nreturn ret;\r\nif (host < SMEM_HOST_COUNT && __smem->partitions[host])\r\nret = qcom_smem_alloc_private(__smem, host, item, size);\r\nelse\r\nret = qcom_smem_alloc_global(__smem, item, size);\r\nhwspin_unlock_irqrestore(__smem->hwlock, &flags);\r\nreturn ret;\r\n}\r\nstatic void *qcom_smem_get_global(struct qcom_smem *smem,\r\nunsigned item,\r\nsize_t *size)\r\n{\r\nstruct smem_header *header;\r\nstruct smem_region *area;\r\nstruct smem_global_entry *entry;\r\nu32 aux_base;\r\nunsigned i;\r\nif (WARN_ON(item >= SMEM_ITEM_COUNT))\r\nreturn ERR_PTR(-EINVAL);\r\nheader = smem->regions[0].virt_base;\r\nentry = &header->toc[item];\r\nif (!entry->allocated)\r\nreturn ERR_PTR(-ENXIO);\r\naux_base = le32_to_cpu(entry->aux_base) & AUX_BASE_MASK;\r\nfor (i = 0; i < smem->num_regions; i++) {\r\narea = &smem->regions[i];\r\nif (area->aux_base == aux_base || !aux_base) {\r\nif (size != NULL)\r\n*size = le32_to_cpu(entry->size);\r\nreturn area->virt_base + le32_to_cpu(entry->offset);\r\n}\r\n}\r\nreturn ERR_PTR(-ENOENT);\r\n}\r\nstatic void *qcom_smem_get_private(struct qcom_smem *smem,\r\nunsigned host,\r\nunsigned item,\r\nsize_t *size)\r\n{\r\nstruct smem_partition_header *phdr;\r\nstruct smem_private_entry *e, *end;\r\nphdr = smem->partitions[host];\r\ne = phdr_to_first_private_entry(phdr);\r\nend = phdr_to_last_private_entry(phdr);\r\nwhile (e < end) {\r\nif (e->canary != SMEM_PRIVATE_CANARY) {\r\ndev_err(smem->dev,\r\n"Found invalid canary in host %d partition\n",\r\nhost);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nif (le16_to_cpu(e->item) == item) {\r\nif (size != NULL)\r\n*size = le32_to_cpu(e->size) -\r\nle16_to_cpu(e->padding_data);\r\nreturn entry_to_item(e);\r\n}\r\ne = private_entry_next(e);\r\n}\r\nreturn ERR_PTR(-ENOENT);\r\n}\r\nvoid *qcom_smem_get(unsigned host, unsigned item, size_t *size)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nvoid *ptr = ERR_PTR(-EPROBE_DEFER);\r\nif (!__smem)\r\nreturn ptr;\r\nret = hwspin_lock_timeout_irqsave(__smem->hwlock,\r\nHWSPINLOCK_TIMEOUT,\r\n&flags);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\nif (host < SMEM_HOST_COUNT && __smem->partitions[host])\r\nptr = qcom_smem_get_private(__smem, host, item, size);\r\nelse\r\nptr = qcom_smem_get_global(__smem, item, size);\r\nhwspin_unlock_irqrestore(__smem->hwlock, &flags);\r\nreturn ptr;\r\n}\r\nint qcom_smem_get_free_space(unsigned host)\r\n{\r\nstruct smem_partition_header *phdr;\r\nstruct smem_header *header;\r\nunsigned ret;\r\nif (!__smem)\r\nreturn -EPROBE_DEFER;\r\nif (host < SMEM_HOST_COUNT && __smem->partitions[host]) {\r\nphdr = __smem->partitions[host];\r\nret = le32_to_cpu(phdr->offset_free_cached) -\r\nle32_to_cpu(phdr->offset_free_uncached);\r\n} else {\r\nheader = __smem->regions[0].virt_base;\r\nret = le32_to_cpu(header->available);\r\n}\r\nreturn ret;\r\n}\r\nstatic int qcom_smem_get_sbl_version(struct qcom_smem *smem)\r\n{\r\n__le32 *versions;\r\nsize_t size;\r\nversions = qcom_smem_get_global(smem, SMEM_ITEM_VERSION, &size);\r\nif (IS_ERR(versions)) {\r\ndev_err(smem->dev, "Unable to read the version item\n");\r\nreturn -ENOENT;\r\n}\r\nif (size < sizeof(unsigned) * SMEM_MASTER_SBL_VERSION_INDEX) {\r\ndev_err(smem->dev, "Version item is too small\n");\r\nreturn -EINVAL;\r\n}\r\nreturn le32_to_cpu(versions[SMEM_MASTER_SBL_VERSION_INDEX]);\r\n}\r\nstatic int qcom_smem_enumerate_partitions(struct qcom_smem *smem,\r\nunsigned local_host)\r\n{\r\nstruct smem_partition_header *header;\r\nstruct smem_ptable_entry *entry;\r\nstruct smem_ptable *ptable;\r\nunsigned remote_host;\r\nu32 version, host0, host1;\r\nint i;\r\nptable = smem->regions[0].virt_base + smem->regions[0].size - SZ_4K;\r\nif (memcmp(ptable->magic, SMEM_PTABLE_MAGIC, sizeof(ptable->magic)))\r\nreturn 0;\r\nversion = le32_to_cpu(ptable->version);\r\nif (version != 1) {\r\ndev_err(smem->dev,\r\n"Unsupported partition header version %d\n", version);\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < le32_to_cpu(ptable->num_entries); i++) {\r\nentry = &ptable->entry[i];\r\nhost0 = le16_to_cpu(entry->host0);\r\nhost1 = le16_to_cpu(entry->host1);\r\nif (host0 != local_host && host1 != local_host)\r\ncontinue;\r\nif (!le32_to_cpu(entry->offset))\r\ncontinue;\r\nif (!le32_to_cpu(entry->size))\r\ncontinue;\r\nif (host0 == local_host)\r\nremote_host = host1;\r\nelse\r\nremote_host = host0;\r\nif (remote_host >= SMEM_HOST_COUNT) {\r\ndev_err(smem->dev,\r\n"Invalid remote host %d\n",\r\nremote_host);\r\nreturn -EINVAL;\r\n}\r\nif (smem->partitions[remote_host]) {\r\ndev_err(smem->dev,\r\n"Already found a partition for host %d\n",\r\nremote_host);\r\nreturn -EINVAL;\r\n}\r\nheader = smem->regions[0].virt_base + le32_to_cpu(entry->offset);\r\nhost0 = le16_to_cpu(header->host0);\r\nhost1 = le16_to_cpu(header->host1);\r\nif (memcmp(header->magic, SMEM_PART_MAGIC,\r\nsizeof(header->magic))) {\r\ndev_err(smem->dev,\r\n"Partition %d has invalid magic\n", i);\r\nreturn -EINVAL;\r\n}\r\nif (host0 != local_host && host1 != local_host) {\r\ndev_err(smem->dev,\r\n"Partition %d hosts are invalid\n", i);\r\nreturn -EINVAL;\r\n}\r\nif (host0 != remote_host && host1 != remote_host) {\r\ndev_err(smem->dev,\r\n"Partition %d hosts are invalid\n", i);\r\nreturn -EINVAL;\r\n}\r\nif (header->size != entry->size) {\r\ndev_err(smem->dev,\r\n"Partition %d has invalid size\n", i);\r\nreturn -EINVAL;\r\n}\r\nif (le32_to_cpu(header->offset_free_uncached) > le32_to_cpu(header->size)) {\r\ndev_err(smem->dev,\r\n"Partition %d has invalid free pointer\n", i);\r\nreturn -EINVAL;\r\n}\r\nsmem->partitions[remote_host] = header;\r\n}\r\nreturn 0;\r\n}\r\nstatic int qcom_smem_map_memory(struct qcom_smem *smem, struct device *dev,\r\nconst char *name, int i)\r\n{\r\nstruct device_node *np;\r\nstruct resource r;\r\nint ret;\r\nnp = of_parse_phandle(dev->of_node, name, 0);\r\nif (!np) {\r\ndev_err(dev, "No %s specified\n", name);\r\nreturn -EINVAL;\r\n}\r\nret = of_address_to_resource(np, 0, &r);\r\nof_node_put(np);\r\nif (ret)\r\nreturn ret;\r\nsmem->regions[i].aux_base = (u32)r.start;\r\nsmem->regions[i].size = resource_size(&r);\r\nsmem->regions[i].virt_base = devm_ioremap_wc(dev, r.start, resource_size(&r));\r\nif (!smem->regions[i].virt_base)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic int qcom_smem_probe(struct platform_device *pdev)\r\n{\r\nstruct smem_header *header;\r\nstruct qcom_smem *smem;\r\nsize_t array_size;\r\nint num_regions;\r\nint hwlock_id;\r\nu32 version;\r\nint ret;\r\nnum_regions = 1;\r\nif (of_find_property(pdev->dev.of_node, "qcom,rpm-msg-ram", NULL))\r\nnum_regions++;\r\narray_size = num_regions * sizeof(struct smem_region);\r\nsmem = devm_kzalloc(&pdev->dev, sizeof(*smem) + array_size, GFP_KERNEL);\r\nif (!smem)\r\nreturn -ENOMEM;\r\nsmem->dev = &pdev->dev;\r\nsmem->num_regions = num_regions;\r\nret = qcom_smem_map_memory(smem, &pdev->dev, "memory-region", 0);\r\nif (ret)\r\nreturn ret;\r\nif (num_regions > 1 && (ret = qcom_smem_map_memory(smem, &pdev->dev,\r\n"qcom,rpm-msg-ram", 1)))\r\nreturn ret;\r\nheader = smem->regions[0].virt_base;\r\nif (le32_to_cpu(header->initialized) != 1 ||\r\nle32_to_cpu(header->reserved)) {\r\ndev_err(&pdev->dev, "SMEM is not initialized by SBL\n");\r\nreturn -EINVAL;\r\n}\r\nversion = qcom_smem_get_sbl_version(smem);\r\nif (version >> 16 != SMEM_EXPECTED_VERSION) {\r\ndev_err(&pdev->dev, "Unsupported SMEM version 0x%x\n", version);\r\nreturn -EINVAL;\r\n}\r\nret = qcom_smem_enumerate_partitions(smem, SMEM_HOST_APPS);\r\nif (ret < 0)\r\nreturn ret;\r\nhwlock_id = of_hwspin_lock_get_id(pdev->dev.of_node, 0);\r\nif (hwlock_id < 0) {\r\nif (hwlock_id != -EPROBE_DEFER)\r\ndev_err(&pdev->dev, "failed to retrieve hwlock\n");\r\nreturn hwlock_id;\r\n}\r\nsmem->hwlock = hwspin_lock_request_specific(hwlock_id);\r\nif (!smem->hwlock)\r\nreturn -ENXIO;\r\n__smem = smem;\r\nreturn 0;\r\n}\r\nstatic int qcom_smem_remove(struct platform_device *pdev)\r\n{\r\nhwspin_lock_free(__smem->hwlock);\r\n__smem = NULL;\r\nreturn 0;\r\n}\r\nstatic int __init qcom_smem_init(void)\r\n{\r\nreturn platform_driver_register(&qcom_smem_driver);\r\n}\r\nstatic void __exit qcom_smem_exit(void)\r\n{\r\nplatform_driver_unregister(&qcom_smem_driver);\r\n}
