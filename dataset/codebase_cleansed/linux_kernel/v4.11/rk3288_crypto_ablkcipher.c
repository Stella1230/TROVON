static void rk_crypto_complete(struct rk_crypto_info *dev, int err)\r\n{\r\nif (dev->ablk_req->base.complete)\r\ndev->ablk_req->base.complete(&dev->ablk_req->base, err);\r\n}\r\nstatic int rk_handle_req(struct rk_crypto_info *dev,\r\nstruct ablkcipher_request *req)\r\n{\r\nunsigned long flags;\r\nint err;\r\nif (!IS_ALIGNED(req->nbytes, dev->align_size))\r\nreturn -EINVAL;\r\ndev->left_bytes = req->nbytes;\r\ndev->total = req->nbytes;\r\ndev->sg_src = req->src;\r\ndev->first = req->src;\r\ndev->nents = sg_nents(req->src);\r\ndev->sg_dst = req->dst;\r\ndev->aligned = 1;\r\ndev->ablk_req = req;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nerr = ablkcipher_enqueue_request(&dev->queue, req);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\ntasklet_schedule(&dev->crypto_tasklet);\r\nreturn err;\r\n}\r\nstatic int rk_aes_setkey(struct crypto_ablkcipher *cipher,\r\nconst u8 *key, unsigned int keylen)\r\n{\r\nstruct crypto_tfm *tfm = crypto_ablkcipher_tfm(cipher);\r\nstruct rk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);\r\nif (keylen != AES_KEYSIZE_128 && keylen != AES_KEYSIZE_192 &&\r\nkeylen != AES_KEYSIZE_256) {\r\ncrypto_ablkcipher_set_flags(cipher, CRYPTO_TFM_RES_BAD_KEY_LEN);\r\nreturn -EINVAL;\r\n}\r\nctx->keylen = keylen;\r\nmemcpy_toio(ctx->dev->reg + RK_CRYPTO_AES_KEY_0, key, keylen);\r\nreturn 0;\r\n}\r\nstatic int rk_tdes_setkey(struct crypto_ablkcipher *cipher,\r\nconst u8 *key, unsigned int keylen)\r\n{\r\nstruct crypto_tfm *tfm = crypto_ablkcipher_tfm(cipher);\r\nstruct rk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);\r\nu32 tmp[DES_EXPKEY_WORDS];\r\nif (keylen != DES_KEY_SIZE && keylen != DES3_EDE_KEY_SIZE) {\r\ncrypto_ablkcipher_set_flags(cipher, CRYPTO_TFM_RES_BAD_KEY_LEN);\r\nreturn -EINVAL;\r\n}\r\nif (keylen == DES_KEY_SIZE) {\r\nif (!des_ekey(tmp, key) &&\r\n(tfm->crt_flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\r\ntfm->crt_flags |= CRYPTO_TFM_RES_WEAK_KEY;\r\nreturn -EINVAL;\r\n}\r\n}\r\nctx->keylen = keylen;\r\nmemcpy_toio(ctx->dev->reg + RK_CRYPTO_TDES_KEY1_0, key, keylen);\r\nreturn 0;\r\n}\r\nstatic int rk_aes_ecb_encrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_AES_ECB_MODE;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_aes_ecb_decrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_AES_ECB_MODE | RK_CRYPTO_DEC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_aes_cbc_encrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_AES_CBC_MODE;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_aes_cbc_decrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_AES_CBC_MODE | RK_CRYPTO_DEC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des_ecb_encrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = 0;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des_ecb_decrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_DEC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des_cbc_encrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_TDES_CHAINMODE_CBC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des_cbc_decrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_TDES_CHAINMODE_CBC | RK_CRYPTO_DEC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des3_ede_ecb_encrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_TDES_SELECT;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des3_ede_ecb_decrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_TDES_SELECT | RK_CRYPTO_DEC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des3_ede_cbc_encrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_TDES_SELECT | RK_CRYPTO_TDES_CHAINMODE_CBC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic int rk_des3_ede_cbc_decrypt(struct ablkcipher_request *req)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct rk_crypto_info *dev = ctx->dev;\r\ndev->mode = RK_CRYPTO_TDES_SELECT | RK_CRYPTO_TDES_CHAINMODE_CBC |\r\nRK_CRYPTO_DEC;\r\nreturn rk_handle_req(dev, req);\r\n}\r\nstatic void rk_ablk_hw_init(struct rk_crypto_info *dev)\r\n{\r\nstruct crypto_ablkcipher *cipher =\r\ncrypto_ablkcipher_reqtfm(dev->ablk_req);\r\nstruct crypto_tfm *tfm = crypto_ablkcipher_tfm(cipher);\r\nstruct rk_cipher_ctx *ctx = crypto_ablkcipher_ctx(cipher);\r\nu32 ivsize, block, conf_reg = 0;\r\nblock = crypto_tfm_alg_blocksize(tfm);\r\nivsize = crypto_ablkcipher_ivsize(cipher);\r\nif (block == DES_BLOCK_SIZE) {\r\ndev->mode |= RK_CRYPTO_TDES_FIFO_MODE |\r\nRK_CRYPTO_TDES_BYTESWAP_KEY |\r\nRK_CRYPTO_TDES_BYTESWAP_IV;\r\nCRYPTO_WRITE(dev, RK_CRYPTO_TDES_CTRL, dev->mode);\r\nmemcpy_toio(dev->reg + RK_CRYPTO_TDES_IV_0,\r\ndev->ablk_req->info, ivsize);\r\nconf_reg = RK_CRYPTO_DESSEL;\r\n} else {\r\ndev->mode |= RK_CRYPTO_AES_FIFO_MODE |\r\nRK_CRYPTO_AES_KEY_CHANGE |\r\nRK_CRYPTO_AES_BYTESWAP_KEY |\r\nRK_CRYPTO_AES_BYTESWAP_IV;\r\nif (ctx->keylen == AES_KEYSIZE_192)\r\ndev->mode |= RK_CRYPTO_AES_192BIT_key;\r\nelse if (ctx->keylen == AES_KEYSIZE_256)\r\ndev->mode |= RK_CRYPTO_AES_256BIT_key;\r\nCRYPTO_WRITE(dev, RK_CRYPTO_AES_CTRL, dev->mode);\r\nmemcpy_toio(dev->reg + RK_CRYPTO_AES_IV_0,\r\ndev->ablk_req->info, ivsize);\r\n}\r\nconf_reg |= RK_CRYPTO_BYTESWAP_BTFIFO |\r\nRK_CRYPTO_BYTESWAP_BRFIFO;\r\nCRYPTO_WRITE(dev, RK_CRYPTO_CONF, conf_reg);\r\nCRYPTO_WRITE(dev, RK_CRYPTO_INTENA,\r\nRK_CRYPTO_BCDMA_ERR_ENA | RK_CRYPTO_BCDMA_DONE_ENA);\r\n}\r\nstatic void crypto_dma_start(struct rk_crypto_info *dev)\r\n{\r\nCRYPTO_WRITE(dev, RK_CRYPTO_BRDMAS, dev->addr_in);\r\nCRYPTO_WRITE(dev, RK_CRYPTO_BRDMAL, dev->count / 4);\r\nCRYPTO_WRITE(dev, RK_CRYPTO_BTDMAS, dev->addr_out);\r\nCRYPTO_WRITE(dev, RK_CRYPTO_CTRL, RK_CRYPTO_BLOCK_START |\r\n_SBF(RK_CRYPTO_BLOCK_START, 16));\r\n}\r\nstatic int rk_set_data_start(struct rk_crypto_info *dev)\r\n{\r\nint err;\r\nerr = dev->load_data(dev, dev->sg_src, dev->sg_dst);\r\nif (!err)\r\ncrypto_dma_start(dev);\r\nreturn err;\r\n}\r\nstatic int rk_ablk_start(struct rk_crypto_info *dev)\r\n{\r\nunsigned long flags;\r\nint err;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nrk_ablk_hw_init(dev);\r\nerr = rk_set_data_start(dev);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nreturn err;\r\n}\r\nstatic void rk_iv_copyback(struct rk_crypto_info *dev)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(dev->ablk_req);\r\nu32 ivsize = crypto_ablkcipher_ivsize(tfm);\r\nif (ivsize == DES_BLOCK_SIZE)\r\nmemcpy_fromio(dev->ablk_req->info,\r\ndev->reg + RK_CRYPTO_TDES_IV_0, ivsize);\r\nelse if (ivsize == AES_BLOCK_SIZE)\r\nmemcpy_fromio(dev->ablk_req->info,\r\ndev->reg + RK_CRYPTO_AES_IV_0, ivsize);\r\n}\r\nstatic int rk_ablk_rx(struct rk_crypto_info *dev)\r\n{\r\nint err = 0;\r\ndev->unload_data(dev);\r\nif (!dev->aligned) {\r\nif (!sg_pcopy_from_buffer(dev->ablk_req->dst, dev->nents,\r\ndev->addr_vir, dev->count,\r\ndev->total - dev->left_bytes -\r\ndev->count)) {\r\nerr = -EINVAL;\r\ngoto out_rx;\r\n}\r\n}\r\nif (dev->left_bytes) {\r\nif (dev->aligned) {\r\nif (sg_is_last(dev->sg_src)) {\r\ndev_err(dev->dev, "[%s:%d] Lack of data\n",\r\n__func__, __LINE__);\r\nerr = -ENOMEM;\r\ngoto out_rx;\r\n}\r\ndev->sg_src = sg_next(dev->sg_src);\r\ndev->sg_dst = sg_next(dev->sg_dst);\r\n}\r\nerr = rk_set_data_start(dev);\r\n} else {\r\nrk_iv_copyback(dev);\r\ndev->complete(dev, 0);\r\n}\r\nout_rx:\r\nreturn err;\r\n}\r\nstatic int rk_ablk_cra_init(struct crypto_tfm *tfm)\r\n{\r\nstruct rk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);\r\nstruct crypto_alg *alg = tfm->__crt_alg;\r\nstruct rk_crypto_tmp *algt;\r\nalgt = container_of(alg, struct rk_crypto_tmp, alg.crypto);\r\nctx->dev = algt->dev;\r\nctx->dev->align_size = crypto_tfm_alg_alignmask(tfm) + 1;\r\nctx->dev->start = rk_ablk_start;\r\nctx->dev->update = rk_ablk_rx;\r\nctx->dev->complete = rk_crypto_complete;\r\nctx->dev->addr_vir = (char *)__get_free_page(GFP_KERNEL);\r\nreturn ctx->dev->addr_vir ? ctx->dev->enable_clk(ctx->dev) : -ENOMEM;\r\n}\r\nstatic void rk_ablk_cra_exit(struct crypto_tfm *tfm)\r\n{\r\nstruct rk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);\r\nfree_page((unsigned long)ctx->dev->addr_vir);\r\nctx->dev->disable_clk(ctx->dev);\r\n}
