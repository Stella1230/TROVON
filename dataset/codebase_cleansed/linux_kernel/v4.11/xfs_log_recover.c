static inline int\r\nxlog_buf_bbcount_valid(\r\nstruct xlog *log,\r\nint bbcount)\r\n{\r\nreturn bbcount > 0 && bbcount <= log->l_logBBsize;\r\n}\r\nSTATIC xfs_buf_t *\r\nxlog_get_bp(\r\nstruct xlog *log,\r\nint nbblks)\r\n{\r\nstruct xfs_buf *bp;\r\nif (!xlog_buf_bbcount_valid(log, nbblks)) {\r\nxfs_warn(log->l_mp, "Invalid block length (0x%x) for buffer",\r\nnbblks);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_HIGH, log->l_mp);\r\nreturn NULL;\r\n}\r\nif (nbblks > 1 && log->l_sectBBsize > 1)\r\nnbblks += log->l_sectBBsize;\r\nnbblks = round_up(nbblks, log->l_sectBBsize);\r\nbp = xfs_buf_get_uncached(log->l_mp->m_logdev_targp, nbblks, 0);\r\nif (bp)\r\nxfs_buf_unlock(bp);\r\nreturn bp;\r\n}\r\nSTATIC void\r\nxlog_put_bp(\r\nxfs_buf_t *bp)\r\n{\r\nxfs_buf_free(bp);\r\n}\r\nSTATIC char *\r\nxlog_align(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp)\r\n{\r\nxfs_daddr_t offset = blk_no & ((xfs_daddr_t)log->l_sectBBsize - 1);\r\nASSERT(offset + nbblks <= bp->b_length);\r\nreturn bp->b_addr + BBTOB(offset);\r\n}\r\nSTATIC int\r\nxlog_bread_noalign(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp)\r\n{\r\nint error;\r\nif (!xlog_buf_bbcount_valid(log, nbblks)) {\r\nxfs_warn(log->l_mp, "Invalid block length (0x%x) for buffer",\r\nnbblks);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_HIGH, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nblk_no = round_down(blk_no, log->l_sectBBsize);\r\nnbblks = round_up(nbblks, log->l_sectBBsize);\r\nASSERT(nbblks > 0);\r\nASSERT(nbblks <= bp->b_length);\r\nXFS_BUF_SET_ADDR(bp, log->l_logBBstart + blk_no);\r\nbp->b_flags |= XBF_READ;\r\nbp->b_io_length = nbblks;\r\nbp->b_error = 0;\r\nerror = xfs_buf_submit_wait(bp);\r\nif (error && !XFS_FORCED_SHUTDOWN(log->l_mp))\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_bread(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp,\r\nchar **offset)\r\n{\r\nint error;\r\nerror = xlog_bread_noalign(log, blk_no, nbblks, bp);\r\nif (error)\r\nreturn error;\r\n*offset = xlog_align(log, blk_no, nbblks, bp);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_bread_offset(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp,\r\nchar *offset)\r\n{\r\nchar *orig_offset = bp->b_addr;\r\nint orig_len = BBTOB(bp->b_length);\r\nint error, error2;\r\nerror = xfs_buf_associate_memory(bp, offset, BBTOB(nbblks));\r\nif (error)\r\nreturn error;\r\nerror = xlog_bread_noalign(log, blk_no, nbblks, bp);\r\nerror2 = xfs_buf_associate_memory(bp, orig_offset, orig_len);\r\nif (error)\r\nreturn error;\r\nreturn error2;\r\n}\r\nSTATIC int\r\nxlog_bwrite(\r\nstruct xlog *log,\r\nxfs_daddr_t blk_no,\r\nint nbblks,\r\nstruct xfs_buf *bp)\r\n{\r\nint error;\r\nif (!xlog_buf_bbcount_valid(log, nbblks)) {\r\nxfs_warn(log->l_mp, "Invalid block length (0x%x) for buffer",\r\nnbblks);\r\nXFS_ERROR_REPORT(__func__, XFS_ERRLEVEL_HIGH, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nblk_no = round_down(blk_no, log->l_sectBBsize);\r\nnbblks = round_up(nbblks, log->l_sectBBsize);\r\nASSERT(nbblks > 0);\r\nASSERT(nbblks <= bp->b_length);\r\nXFS_BUF_SET_ADDR(bp, log->l_logBBstart + blk_no);\r\nxfs_buf_hold(bp);\r\nxfs_buf_lock(bp);\r\nbp->b_io_length = nbblks;\r\nbp->b_error = 0;\r\nerror = xfs_bwrite(bp);\r\nif (error)\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nxfs_buf_relse(bp);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_header_check_dump(\r\nxfs_mount_t *mp,\r\nxlog_rec_header_t *head)\r\n{\r\nxfs_debug(mp, "%s: SB : uuid = %pU, fmt = %d",\r\n__func__, &mp->m_sb.sb_uuid, XLOG_FMT);\r\nxfs_debug(mp, " log : uuid = %pU, fmt = %d",\r\n&head->h_fs_uuid, be32_to_cpu(head->h_fmt));\r\n}\r\nSTATIC int\r\nxlog_header_check_recover(\r\nxfs_mount_t *mp,\r\nxlog_rec_header_t *head)\r\n{\r\nASSERT(head->h_magicno == cpu_to_be32(XLOG_HEADER_MAGIC_NUM));\r\nif (unlikely(head->h_fmt != cpu_to_be32(XLOG_FMT))) {\r\nxfs_warn(mp,\r\n"dirty log written in incompatible format - can't recover");\r\nxlog_header_check_dump(mp, head);\r\nXFS_ERROR_REPORT("xlog_header_check_recover(1)",\r\nXFS_ERRLEVEL_HIGH, mp);\r\nreturn -EFSCORRUPTED;\r\n} else if (unlikely(!uuid_equal(&mp->m_sb.sb_uuid, &head->h_fs_uuid))) {\r\nxfs_warn(mp,\r\n"dirty log entry has mismatched uuid - can't recover");\r\nxlog_header_check_dump(mp, head);\r\nXFS_ERROR_REPORT("xlog_header_check_recover(2)",\r\nXFS_ERRLEVEL_HIGH, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_header_check_mount(\r\nxfs_mount_t *mp,\r\nxlog_rec_header_t *head)\r\n{\r\nASSERT(head->h_magicno == cpu_to_be32(XLOG_HEADER_MAGIC_NUM));\r\nif (uuid_is_nil(&head->h_fs_uuid)) {\r\nxfs_warn(mp, "nil uuid in log - IRIX style log");\r\n} else if (unlikely(!uuid_equal(&mp->m_sb.sb_uuid, &head->h_fs_uuid))) {\r\nxfs_warn(mp, "log has mismatched uuid - can't recover");\r\nxlog_header_check_dump(mp, head);\r\nXFS_ERROR_REPORT("xlog_header_check_mount",\r\nXFS_ERRLEVEL_HIGH, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxlog_recover_iodone(\r\nstruct xfs_buf *bp)\r\n{\r\nif (bp->b_error) {\r\nif (!XFS_FORCED_SHUTDOWN(bp->b_target->bt_mount)) {\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nxfs_force_shutdown(bp->b_target->bt_mount,\r\nSHUTDOWN_META_IO_ERROR);\r\n}\r\n}\r\nif (bp->b_fspriv)\r\nxfs_buf_item_relse(bp);\r\nASSERT(bp->b_fspriv == NULL);\r\nbp->b_iodone = NULL;\r\nxfs_buf_ioend(bp);\r\n}\r\nSTATIC int\r\nxlog_find_cycle_start(\r\nstruct xlog *log,\r\nstruct xfs_buf *bp,\r\nxfs_daddr_t first_blk,\r\nxfs_daddr_t *last_blk,\r\nuint cycle)\r\n{\r\nchar *offset;\r\nxfs_daddr_t mid_blk;\r\nxfs_daddr_t end_blk;\r\nuint mid_cycle;\r\nint error;\r\nend_blk = *last_blk;\r\nmid_blk = BLK_AVG(first_blk, end_blk);\r\nwhile (mid_blk != first_blk && mid_blk != end_blk) {\r\nerror = xlog_bread(log, mid_blk, 1, bp, &offset);\r\nif (error)\r\nreturn error;\r\nmid_cycle = xlog_get_cycle(offset);\r\nif (mid_cycle == cycle)\r\nend_blk = mid_blk;\r\nelse\r\nfirst_blk = mid_blk;\r\nmid_blk = BLK_AVG(first_blk, end_blk);\r\n}\r\nASSERT((mid_blk == first_blk && mid_blk+1 == end_blk) ||\r\n(mid_blk == end_blk && mid_blk-1 == first_blk));\r\n*last_blk = end_blk;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_find_verify_cycle(\r\nstruct xlog *log,\r\nxfs_daddr_t start_blk,\r\nint nbblks,\r\nuint stop_on_cycle_no,\r\nxfs_daddr_t *new_blk)\r\n{\r\nxfs_daddr_t i, j;\r\nuint cycle;\r\nxfs_buf_t *bp;\r\nxfs_daddr_t bufblks;\r\nchar *buf = NULL;\r\nint error = 0;\r\nbufblks = 1 << ffs(nbblks);\r\nwhile (bufblks > log->l_logBBsize)\r\nbufblks >>= 1;\r\nwhile (!(bp = xlog_get_bp(log, bufblks))) {\r\nbufblks >>= 1;\r\nif (bufblks < log->l_sectBBsize)\r\nreturn -ENOMEM;\r\n}\r\nfor (i = start_blk; i < start_blk + nbblks; i += bufblks) {\r\nint bcount;\r\nbcount = min(bufblks, (start_blk + nbblks - i));\r\nerror = xlog_bread(log, i, bcount, bp, &buf);\r\nif (error)\r\ngoto out;\r\nfor (j = 0; j < bcount; j++) {\r\ncycle = xlog_get_cycle(buf);\r\nif (cycle == stop_on_cycle_no) {\r\n*new_blk = i+j;\r\ngoto out;\r\n}\r\nbuf += BBSIZE;\r\n}\r\n}\r\n*new_blk = -1;\r\nout:\r\nxlog_put_bp(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_find_verify_log_record(\r\nstruct xlog *log,\r\nxfs_daddr_t start_blk,\r\nxfs_daddr_t *last_blk,\r\nint extra_bblks)\r\n{\r\nxfs_daddr_t i;\r\nxfs_buf_t *bp;\r\nchar *offset = NULL;\r\nxlog_rec_header_t *head = NULL;\r\nint error = 0;\r\nint smallmem = 0;\r\nint num_blks = *last_blk - start_blk;\r\nint xhdrs;\r\nASSERT(start_blk != 0 || *last_blk != start_blk);\r\nif (!(bp = xlog_get_bp(log, num_blks))) {\r\nif (!(bp = xlog_get_bp(log, 1)))\r\nreturn -ENOMEM;\r\nsmallmem = 1;\r\n} else {\r\nerror = xlog_bread(log, start_blk, num_blks, bp, &offset);\r\nif (error)\r\ngoto out;\r\noffset += ((num_blks - 1) << BBSHIFT);\r\n}\r\nfor (i = (*last_blk) - 1; i >= 0; i--) {\r\nif (i < start_blk) {\r\nxfs_warn(log->l_mp,\r\n"Log inconsistent (didn't find previous header)");\r\nASSERT(0);\r\nerror = -EIO;\r\ngoto out;\r\n}\r\nif (smallmem) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto out;\r\n}\r\nhead = (xlog_rec_header_t *)offset;\r\nif (head->h_magicno == cpu_to_be32(XLOG_HEADER_MAGIC_NUM))\r\nbreak;\r\nif (!smallmem)\r\noffset -= BBSIZE;\r\n}\r\nif (i == -1) {\r\nerror = 1;\r\ngoto out;\r\n}\r\nif ((error = xlog_header_check_mount(log->l_mp, head)))\r\ngoto out;\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nuint h_size = be32_to_cpu(head->h_size);\r\nxhdrs = h_size / XLOG_HEADER_CYCLE_SIZE;\r\nif (h_size % XLOG_HEADER_CYCLE_SIZE)\r\nxhdrs++;\r\n} else {\r\nxhdrs = 1;\r\n}\r\nif (*last_blk - i + extra_bblks !=\r\nBTOBB(be32_to_cpu(head->h_len)) + xhdrs)\r\n*last_blk = i;\r\nout:\r\nxlog_put_bp(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_find_head(\r\nstruct xlog *log,\r\nxfs_daddr_t *return_head_blk)\r\n{\r\nxfs_buf_t *bp;\r\nchar *offset;\r\nxfs_daddr_t new_blk, first_blk, start_blk, last_blk, head_blk;\r\nint num_scan_bblks;\r\nuint first_half_cycle, last_half_cycle;\r\nuint stop_on_cycle;\r\nint error, log_bbnum = log->l_logBBsize;\r\nerror = xlog_find_zeroed(log, &first_blk);\r\nif (error < 0) {\r\nxfs_warn(log->l_mp, "empty log check failed");\r\nreturn error;\r\n}\r\nif (error == 1) {\r\n*return_head_blk = first_blk;\r\nif (!first_blk) {\r\nxfs_warn(log->l_mp, "totally zeroed log");\r\n}\r\nreturn 0;\r\n}\r\nfirst_blk = 0;\r\nbp = xlog_get_bp(log, 1);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nerror = xlog_bread(log, 0, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nfirst_half_cycle = xlog_get_cycle(offset);\r\nlast_blk = head_blk = log_bbnum - 1;\r\nerror = xlog_bread(log, last_blk, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nlast_half_cycle = xlog_get_cycle(offset);\r\nASSERT(last_half_cycle != 0);\r\nif (first_half_cycle == last_half_cycle) {\r\nhead_blk = log_bbnum;\r\nstop_on_cycle = last_half_cycle - 1;\r\n} else {\r\nstop_on_cycle = last_half_cycle;\r\nif ((error = xlog_find_cycle_start(log, bp, first_blk,\r\n&head_blk, last_half_cycle)))\r\ngoto bp_err;\r\n}\r\nnum_scan_bblks = XLOG_TOTAL_REC_SHIFT(log);\r\nif (head_blk >= num_scan_bblks) {\r\nstart_blk = head_blk - num_scan_bblks;\r\nif ((error = xlog_find_verify_cycle(log,\r\nstart_blk, num_scan_bblks,\r\nstop_on_cycle, &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1)\r\nhead_blk = new_blk;\r\n} else {\r\nASSERT(head_blk <= INT_MAX &&\r\n(xfs_daddr_t) num_scan_bblks >= head_blk);\r\nstart_blk = log_bbnum - (num_scan_bblks - head_blk);\r\nif ((error = xlog_find_verify_cycle(log, start_blk,\r\nnum_scan_bblks - (int)head_blk,\r\n(stop_on_cycle - 1), &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1) {\r\nhead_blk = new_blk;\r\ngoto validate_head;\r\n}\r\nstart_blk = 0;\r\nASSERT(head_blk <= INT_MAX);\r\nif ((error = xlog_find_verify_cycle(log,\r\nstart_blk, (int)head_blk,\r\nstop_on_cycle, &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1)\r\nhead_blk = new_blk;\r\n}\r\nvalidate_head:\r\nnum_scan_bblks = XLOG_REC_SHIFT(log);\r\nif (head_blk >= num_scan_bblks) {\r\nstart_blk = head_blk - num_scan_bblks;\r\nerror = xlog_find_verify_log_record(log, start_blk, &head_blk, 0);\r\nif (error == 1)\r\nerror = -EIO;\r\nif (error)\r\ngoto bp_err;\r\n} else {\r\nstart_blk = 0;\r\nASSERT(head_blk <= INT_MAX);\r\nerror = xlog_find_verify_log_record(log, start_blk, &head_blk, 0);\r\nif (error < 0)\r\ngoto bp_err;\r\nif (error == 1) {\r\nstart_blk = log_bbnum - (num_scan_bblks - head_blk);\r\nnew_blk = log_bbnum;\r\nASSERT(start_blk <= INT_MAX &&\r\n(xfs_daddr_t) log_bbnum-start_blk >= 0);\r\nASSERT(head_blk <= INT_MAX);\r\nerror = xlog_find_verify_log_record(log, start_blk,\r\n&new_blk, (int)head_blk);\r\nif (error == 1)\r\nerror = -EIO;\r\nif (error)\r\ngoto bp_err;\r\nif (new_blk != log_bbnum)\r\nhead_blk = new_blk;\r\n} else if (error)\r\ngoto bp_err;\r\n}\r\nxlog_put_bp(bp);\r\nif (head_blk == log_bbnum)\r\n*return_head_blk = 0;\r\nelse\r\n*return_head_blk = head_blk;\r\nreturn 0;\r\nbp_err:\r\nxlog_put_bp(bp);\r\nif (error)\r\nxfs_warn(log->l_mp, "failed to find log head");\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_rseek_logrec_hdr(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk,\r\nint count,\r\nstruct xfs_buf *bp,\r\nxfs_daddr_t *rblk,\r\nstruct xlog_rec_header **rhead,\r\nbool *wrapped)\r\n{\r\nint i;\r\nint error;\r\nint found = 0;\r\nchar *offset = NULL;\r\nxfs_daddr_t end_blk;\r\n*wrapped = false;\r\nend_blk = head_blk > tail_blk ? tail_blk : 0;\r\nfor (i = (int) head_blk - 1; i >= end_blk; i--) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto out_error;\r\nif (*(__be32 *) offset == cpu_to_be32(XLOG_HEADER_MAGIC_NUM)) {\r\n*rblk = i;\r\n*rhead = (struct xlog_rec_header *) offset;\r\nif (++found == count)\r\nbreak;\r\n}\r\n}\r\nif (tail_blk >= head_blk && found != count) {\r\nfor (i = log->l_logBBsize - 1; i >= (int) tail_blk; i--) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto out_error;\r\nif (*(__be32 *)offset ==\r\ncpu_to_be32(XLOG_HEADER_MAGIC_NUM)) {\r\n*wrapped = true;\r\n*rblk = i;\r\n*rhead = (struct xlog_rec_header *) offset;\r\nif (++found == count)\r\nbreak;\r\n}\r\n}\r\n}\r\nreturn found;\r\nout_error:\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_seek_logrec_hdr(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk,\r\nint count,\r\nstruct xfs_buf *bp,\r\nxfs_daddr_t *rblk,\r\nstruct xlog_rec_header **rhead,\r\nbool *wrapped)\r\n{\r\nint i;\r\nint error;\r\nint found = 0;\r\nchar *offset = NULL;\r\nxfs_daddr_t end_blk;\r\n*wrapped = false;\r\nend_blk = head_blk > tail_blk ? head_blk : log->l_logBBsize - 1;\r\nfor (i = (int) tail_blk; i <= end_blk; i++) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto out_error;\r\nif (*(__be32 *) offset == cpu_to_be32(XLOG_HEADER_MAGIC_NUM)) {\r\n*rblk = i;\r\n*rhead = (struct xlog_rec_header *) offset;\r\nif (++found == count)\r\nbreak;\r\n}\r\n}\r\nif (tail_blk > head_blk && found != count) {\r\nfor (i = 0; i < (int) head_blk; i++) {\r\nerror = xlog_bread(log, i, 1, bp, &offset);\r\nif (error)\r\ngoto out_error;\r\nif (*(__be32 *)offset ==\r\ncpu_to_be32(XLOG_HEADER_MAGIC_NUM)) {\r\n*wrapped = true;\r\n*rblk = i;\r\n*rhead = (struct xlog_rec_header *) offset;\r\nif (++found == count)\r\nbreak;\r\n}\r\n}\r\n}\r\nreturn found;\r\nout_error:\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_verify_tail(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk)\r\n{\r\nstruct xlog_rec_header *thead;\r\nstruct xfs_buf *bp;\r\nxfs_daddr_t first_bad;\r\nint count;\r\nint error = 0;\r\nbool wrapped;\r\nxfs_daddr_t tmp_head;\r\nbp = xlog_get_bp(log, 1);\r\nif (!bp)\r\nreturn -ENOMEM;\r\ncount = xlog_seek_logrec_hdr(log, head_blk, tail_blk,\r\nXLOG_MAX_ICLOGS + 1, bp, &tmp_head, &thead,\r\n&wrapped);\r\nif (count < 0) {\r\nerror = count;\r\ngoto out;\r\n}\r\nif (count < XLOG_MAX_ICLOGS + 1)\r\ntmp_head = head_blk;\r\nerror = xlog_do_recovery_pass(log, tmp_head, tail_blk,\r\nXLOG_RECOVER_CRCPASS, &first_bad);\r\nout:\r\nxlog_put_bp(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_verify_head(\r\nstruct xlog *log,\r\nxfs_daddr_t *head_blk,\r\nxfs_daddr_t *tail_blk,\r\nstruct xfs_buf *bp,\r\nxfs_daddr_t *rhead_blk,\r\nstruct xlog_rec_header **rhead,\r\nbool *wrapped)\r\n{\r\nstruct xlog_rec_header *tmp_rhead;\r\nstruct xfs_buf *tmp_bp;\r\nxfs_daddr_t first_bad;\r\nxfs_daddr_t tmp_rhead_blk;\r\nint found;\r\nint error;\r\nbool tmp_wrapped;\r\ntmp_bp = xlog_get_bp(log, 1);\r\nif (!tmp_bp)\r\nreturn -ENOMEM;\r\nerror = xlog_rseek_logrec_hdr(log, *head_blk, *tail_blk,\r\nXLOG_MAX_ICLOGS, tmp_bp, &tmp_rhead_blk,\r\n&tmp_rhead, &tmp_wrapped);\r\nxlog_put_bp(tmp_bp);\r\nif (error < 0)\r\nreturn error;\r\nerror = xlog_do_recovery_pass(log, *head_blk, tmp_rhead_blk,\r\nXLOG_RECOVER_CRCPASS, &first_bad);\r\nif (error == -EFSBADCRC) {\r\nerror = 0;\r\nxfs_warn(log->l_mp,\r\n"Torn write (CRC failure) detected at log block 0x%llx. Truncating head block from 0x%llx.",\r\nfirst_bad, *head_blk);\r\nfound = xlog_rseek_logrec_hdr(log, first_bad, *tail_blk, 1, bp,\r\nrhead_blk, rhead, wrapped);\r\nif (found < 0)\r\nreturn found;\r\nif (found == 0)\r\nreturn -EIO;\r\n*head_blk = first_bad;\r\n*tail_blk = BLOCK_LSN(be64_to_cpu((*rhead)->h_tail_lsn));\r\nif (*head_blk == *tail_blk) {\r\nASSERT(0);\r\nreturn 0;\r\n}\r\nerror = xlog_verify_tail(log, *head_blk, *tail_blk);\r\n}\r\nreturn error;\r\n}\r\nstatic int\r\nxlog_check_unmount_rec(\r\nstruct xlog *log,\r\nxfs_daddr_t *head_blk,\r\nxfs_daddr_t *tail_blk,\r\nstruct xlog_rec_header *rhead,\r\nxfs_daddr_t rhead_blk,\r\nstruct xfs_buf *bp,\r\nbool *clean)\r\n{\r\nstruct xlog_op_header *op_head;\r\nxfs_daddr_t umount_data_blk;\r\nxfs_daddr_t after_umount_blk;\r\nint hblks;\r\nint error;\r\nchar *offset;\r\n*clean = false;\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nint h_size = be32_to_cpu(rhead->h_size);\r\nint h_version = be32_to_cpu(rhead->h_version);\r\nif ((h_version & XLOG_VERSION_2) &&\r\n(h_size > XLOG_HEADER_CYCLE_SIZE)) {\r\nhblks = h_size / XLOG_HEADER_CYCLE_SIZE;\r\nif (h_size % XLOG_HEADER_CYCLE_SIZE)\r\nhblks++;\r\n} else {\r\nhblks = 1;\r\n}\r\n} else {\r\nhblks = 1;\r\n}\r\nafter_umount_blk = rhead_blk + hblks + BTOBB(be32_to_cpu(rhead->h_len));\r\nafter_umount_blk = do_mod(after_umount_blk, log->l_logBBsize);\r\nif (*head_blk == after_umount_blk &&\r\nbe32_to_cpu(rhead->h_num_logops) == 1) {\r\numount_data_blk = rhead_blk + hblks;\r\numount_data_blk = do_mod(umount_data_blk, log->l_logBBsize);\r\nerror = xlog_bread(log, umount_data_blk, 1, bp, &offset);\r\nif (error)\r\nreturn error;\r\nop_head = (struct xlog_op_header *)offset;\r\nif (op_head->oh_flags & XLOG_UNMOUNT_TRANS) {\r\nxlog_assign_atomic_lsn(&log->l_tail_lsn,\r\nlog->l_curr_cycle, after_umount_blk);\r\nxlog_assign_atomic_lsn(&log->l_last_sync_lsn,\r\nlog->l_curr_cycle, after_umount_blk);\r\n*tail_blk = after_umount_blk;\r\n*clean = true;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nxlog_set_state(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nstruct xlog_rec_header *rhead,\r\nxfs_daddr_t rhead_blk,\r\nbool bump_cycle)\r\n{\r\nlog->l_prev_block = rhead_blk;\r\nlog->l_curr_block = (int)head_blk;\r\nlog->l_curr_cycle = be32_to_cpu(rhead->h_cycle);\r\nif (bump_cycle)\r\nlog->l_curr_cycle++;\r\natomic64_set(&log->l_tail_lsn, be64_to_cpu(rhead->h_tail_lsn));\r\natomic64_set(&log->l_last_sync_lsn, be64_to_cpu(rhead->h_lsn));\r\nxlog_assign_grant_head(&log->l_reserve_head.grant, log->l_curr_cycle,\r\nBBTOB(log->l_curr_block));\r\nxlog_assign_grant_head(&log->l_write_head.grant, log->l_curr_cycle,\r\nBBTOB(log->l_curr_block));\r\n}\r\nSTATIC int\r\nxlog_find_tail(\r\nstruct xlog *log,\r\nxfs_daddr_t *head_blk,\r\nxfs_daddr_t *tail_blk)\r\n{\r\nxlog_rec_header_t *rhead;\r\nchar *offset = NULL;\r\nxfs_buf_t *bp;\r\nint error;\r\nxfs_daddr_t rhead_blk;\r\nxfs_lsn_t tail_lsn;\r\nbool wrapped = false;\r\nbool clean = false;\r\nif ((error = xlog_find_head(log, head_blk)))\r\nreturn error;\r\nASSERT(*head_blk < INT_MAX);\r\nbp = xlog_get_bp(log, 1);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nif (*head_blk == 0) {\r\nerror = xlog_bread(log, 0, 1, bp, &offset);\r\nif (error)\r\ngoto done;\r\nif (xlog_get_cycle(offset) == 0) {\r\n*tail_blk = 0;\r\ngoto done;\r\n}\r\n}\r\nerror = xlog_rseek_logrec_hdr(log, *head_blk, *head_blk, 1, bp,\r\n&rhead_blk, &rhead, &wrapped);\r\nif (error < 0)\r\nreturn error;\r\nif (!error) {\r\nxfs_warn(log->l_mp, "%s: couldn't find sync record", __func__);\r\nreturn -EIO;\r\n}\r\n*tail_blk = BLOCK_LSN(be64_to_cpu(rhead->h_tail_lsn));\r\nxlog_set_state(log, *head_blk, rhead, rhead_blk, wrapped);\r\ntail_lsn = atomic64_read(&log->l_tail_lsn);\r\nerror = xlog_check_unmount_rec(log, head_blk, tail_blk, rhead,\r\nrhead_blk, bp, &clean);\r\nif (error)\r\ngoto done;\r\nif (!clean) {\r\nxfs_daddr_t orig_head = *head_blk;\r\nerror = xlog_verify_head(log, head_blk, tail_blk, bp,\r\n&rhead_blk, &rhead, &wrapped);\r\nif (error)\r\ngoto done;\r\nif (*head_blk != orig_head) {\r\nxlog_set_state(log, *head_blk, rhead, rhead_blk,\r\nwrapped);\r\ntail_lsn = atomic64_read(&log->l_tail_lsn);\r\nerror = xlog_check_unmount_rec(log, head_blk, tail_blk,\r\nrhead, rhead_blk, bp,\r\n&clean);\r\nif (error)\r\ngoto done;\r\n}\r\n}\r\nif (clean)\r\nlog->l_mp->m_flags |= XFS_MOUNT_WAS_CLEAN;\r\nif (!xfs_readonly_buftarg(log->l_mp->m_logdev_targp))\r\nerror = xlog_clear_stale_blocks(log, tail_lsn);\r\ndone:\r\nxlog_put_bp(bp);\r\nif (error)\r\nxfs_warn(log->l_mp, "failed to locate log tail");\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_find_zeroed(\r\nstruct xlog *log,\r\nxfs_daddr_t *blk_no)\r\n{\r\nxfs_buf_t *bp;\r\nchar *offset;\r\nuint first_cycle, last_cycle;\r\nxfs_daddr_t new_blk, last_blk, start_blk;\r\nxfs_daddr_t num_scan_bblks;\r\nint error, log_bbnum = log->l_logBBsize;\r\n*blk_no = 0;\r\nbp = xlog_get_bp(log, 1);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nerror = xlog_bread(log, 0, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nfirst_cycle = xlog_get_cycle(offset);\r\nif (first_cycle == 0) {\r\n*blk_no = 0;\r\nxlog_put_bp(bp);\r\nreturn 1;\r\n}\r\nerror = xlog_bread(log, log_bbnum-1, 1, bp, &offset);\r\nif (error)\r\ngoto bp_err;\r\nlast_cycle = xlog_get_cycle(offset);\r\nif (last_cycle != 0) {\r\nxlog_put_bp(bp);\r\nreturn 0;\r\n} else if (first_cycle != 1) {\r\nxfs_warn(log->l_mp,\r\n"Log inconsistent or not a log (last==0, first!=1)");\r\nerror = -EINVAL;\r\ngoto bp_err;\r\n}\r\nlast_blk = log_bbnum-1;\r\nif ((error = xlog_find_cycle_start(log, bp, 0, &last_blk, 0)))\r\ngoto bp_err;\r\nnum_scan_bblks = XLOG_TOTAL_REC_SHIFT(log);\r\nASSERT(num_scan_bblks <= INT_MAX);\r\nif (last_blk < num_scan_bblks)\r\nnum_scan_bblks = last_blk;\r\nstart_blk = last_blk - num_scan_bblks;\r\nif ((error = xlog_find_verify_cycle(log, start_blk,\r\n(int)num_scan_bblks, 0, &new_blk)))\r\ngoto bp_err;\r\nif (new_blk != -1)\r\nlast_blk = new_blk;\r\nerror = xlog_find_verify_log_record(log, start_blk, &last_blk, 0);\r\nif (error == 1)\r\nerror = -EIO;\r\nif (error)\r\ngoto bp_err;\r\n*blk_no = last_blk;\r\nbp_err:\r\nxlog_put_bp(bp);\r\nif (error)\r\nreturn error;\r\nreturn 1;\r\n}\r\nSTATIC void\r\nxlog_add_record(\r\nstruct xlog *log,\r\nchar *buf,\r\nint cycle,\r\nint block,\r\nint tail_cycle,\r\nint tail_block)\r\n{\r\nxlog_rec_header_t *recp = (xlog_rec_header_t *)buf;\r\nmemset(buf, 0, BBSIZE);\r\nrecp->h_magicno = cpu_to_be32(XLOG_HEADER_MAGIC_NUM);\r\nrecp->h_cycle = cpu_to_be32(cycle);\r\nrecp->h_version = cpu_to_be32(\r\nxfs_sb_version_haslogv2(&log->l_mp->m_sb) ? 2 : 1);\r\nrecp->h_lsn = cpu_to_be64(xlog_assign_lsn(cycle, block));\r\nrecp->h_tail_lsn = cpu_to_be64(xlog_assign_lsn(tail_cycle, tail_block));\r\nrecp->h_fmt = cpu_to_be32(XLOG_FMT);\r\nmemcpy(&recp->h_fs_uuid, &log->l_mp->m_sb.sb_uuid, sizeof(uuid_t));\r\n}\r\nSTATIC int\r\nxlog_write_log_records(\r\nstruct xlog *log,\r\nint cycle,\r\nint start_block,\r\nint blocks,\r\nint tail_cycle,\r\nint tail_block)\r\n{\r\nchar *offset;\r\nxfs_buf_t *bp;\r\nint balign, ealign;\r\nint sectbb = log->l_sectBBsize;\r\nint end_block = start_block + blocks;\r\nint bufblks;\r\nint error = 0;\r\nint i, j = 0;\r\nbufblks = 1 << ffs(blocks);\r\nwhile (bufblks > log->l_logBBsize)\r\nbufblks >>= 1;\r\nwhile (!(bp = xlog_get_bp(log, bufblks))) {\r\nbufblks >>= 1;\r\nif (bufblks < sectbb)\r\nreturn -ENOMEM;\r\n}\r\nbalign = round_down(start_block, sectbb);\r\nif (balign != start_block) {\r\nerror = xlog_bread_noalign(log, start_block, 1, bp);\r\nif (error)\r\ngoto out_put_bp;\r\nj = start_block - balign;\r\n}\r\nfor (i = start_block; i < end_block; i += bufblks) {\r\nint bcount, endcount;\r\nbcount = min(bufblks, end_block - start_block);\r\nendcount = bcount - j;\r\nealign = round_down(end_block, sectbb);\r\nif (j == 0 && (start_block + endcount > ealign)) {\r\noffset = bp->b_addr + BBTOB(ealign - start_block);\r\nerror = xlog_bread_offset(log, ealign, sectbb,\r\nbp, offset);\r\nif (error)\r\nbreak;\r\n}\r\noffset = xlog_align(log, start_block, endcount, bp);\r\nfor (; j < endcount; j++) {\r\nxlog_add_record(log, offset, cycle, i+j,\r\ntail_cycle, tail_block);\r\noffset += BBSIZE;\r\n}\r\nerror = xlog_bwrite(log, start_block, endcount, bp);\r\nif (error)\r\nbreak;\r\nstart_block += endcount;\r\nj = 0;\r\n}\r\nout_put_bp:\r\nxlog_put_bp(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_clear_stale_blocks(\r\nstruct xlog *log,\r\nxfs_lsn_t tail_lsn)\r\n{\r\nint tail_cycle, head_cycle;\r\nint tail_block, head_block;\r\nint tail_distance, max_distance;\r\nint distance;\r\nint error;\r\ntail_cycle = CYCLE_LSN(tail_lsn);\r\ntail_block = BLOCK_LSN(tail_lsn);\r\nhead_cycle = log->l_curr_cycle;\r\nhead_block = log->l_curr_block;\r\nif (head_cycle == tail_cycle) {\r\nif (unlikely(head_block < tail_block || head_block >= log->l_logBBsize)) {\r\nXFS_ERROR_REPORT("xlog_clear_stale_blocks(1)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\ntail_distance = tail_block + (log->l_logBBsize - head_block);\r\n} else {\r\nif (unlikely(head_block >= tail_block || head_cycle != (tail_cycle + 1))){\r\nXFS_ERROR_REPORT("xlog_clear_stale_blocks(2)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\ntail_distance = tail_block - head_block;\r\n}\r\nif (tail_distance <= 0) {\r\nASSERT(tail_distance == 0);\r\nreturn 0;\r\n}\r\nmax_distance = XLOG_TOTAL_REC_SHIFT(log);\r\nmax_distance = MIN(max_distance, tail_distance);\r\nif ((head_block + max_distance) <= log->l_logBBsize) {\r\nerror = xlog_write_log_records(log, (head_cycle - 1),\r\nhead_block, max_distance, tail_cycle,\r\ntail_block);\r\nif (error)\r\nreturn error;\r\n} else {\r\ndistance = log->l_logBBsize - head_block;\r\nerror = xlog_write_log_records(log, (head_cycle - 1),\r\nhead_block, distance, tail_cycle,\r\ntail_block);\r\nif (error)\r\nreturn error;\r\ndistance = max_distance - (log->l_logBBsize - head_block);\r\nerror = xlog_write_log_records(log, head_cycle, 0, distance,\r\ntail_cycle, tail_block);\r\nif (error)\r\nreturn error;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_reorder_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nint pass)\r\n{\r\nxlog_recover_item_t *item, *n;\r\nint error = 0;\r\nLIST_HEAD(sort_list);\r\nLIST_HEAD(cancel_list);\r\nLIST_HEAD(buffer_list);\r\nLIST_HEAD(inode_buffer_list);\r\nLIST_HEAD(inode_list);\r\nlist_splice_init(&trans->r_itemq, &sort_list);\r\nlist_for_each_entry_safe(item, n, &sort_list, ri_list) {\r\nxfs_buf_log_format_t *buf_f = item->ri_buf[0].i_addr;\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_ICREATE:\r\nlist_move_tail(&item->ri_list, &buffer_list);\r\nbreak;\r\ncase XFS_LI_BUF:\r\nif (buf_f->blf_flags & XFS_BLF_CANCEL) {\r\ntrace_xfs_log_recover_item_reorder_head(log,\r\ntrans, item, pass);\r\nlist_move(&item->ri_list, &cancel_list);\r\nbreak;\r\n}\r\nif (buf_f->blf_flags & XFS_BLF_INODE_BUF) {\r\nlist_move(&item->ri_list, &inode_buffer_list);\r\nbreak;\r\n}\r\nlist_move_tail(&item->ri_list, &buffer_list);\r\nbreak;\r\ncase XFS_LI_INODE:\r\ncase XFS_LI_DQUOT:\r\ncase XFS_LI_QUOTAOFF:\r\ncase XFS_LI_EFD:\r\ncase XFS_LI_EFI:\r\ncase XFS_LI_RUI:\r\ncase XFS_LI_RUD:\r\ncase XFS_LI_CUI:\r\ncase XFS_LI_CUD:\r\ncase XFS_LI_BUI:\r\ncase XFS_LI_BUD:\r\ntrace_xfs_log_recover_item_reorder_tail(log,\r\ntrans, item, pass);\r\nlist_move_tail(&item->ri_list, &inode_list);\r\nbreak;\r\ndefault:\r\nxfs_warn(log->l_mp,\r\n"%s: unrecognized type of log operation",\r\n__func__);\r\nASSERT(0);\r\nif (!list_empty(&sort_list))\r\nlist_splice_init(&sort_list, &trans->r_itemq);\r\nerror = -EIO;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nASSERT(list_empty(&sort_list));\r\nif (!list_empty(&buffer_list))\r\nlist_splice(&buffer_list, &trans->r_itemq);\r\nif (!list_empty(&inode_list))\r\nlist_splice_tail(&inode_list, &trans->r_itemq);\r\nif (!list_empty(&inode_buffer_list))\r\nlist_splice_tail(&inode_buffer_list, &trans->r_itemq);\r\nif (!list_empty(&cancel_list))\r\nlist_splice_tail(&cancel_list, &trans->r_itemq);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_buffer_pass1(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nxfs_buf_log_format_t *buf_f = item->ri_buf[0].i_addr;\r\nstruct list_head *bucket;\r\nstruct xfs_buf_cancel *bcp;\r\nif (!(buf_f->blf_flags & XFS_BLF_CANCEL)) {\r\ntrace_xfs_log_recover_buf_not_cancel(log, buf_f);\r\nreturn 0;\r\n}\r\nbucket = XLOG_BUF_CANCEL_BUCKET(log, buf_f->blf_blkno);\r\nlist_for_each_entry(bcp, bucket, bc_list) {\r\nif (bcp->bc_blkno == buf_f->blf_blkno &&\r\nbcp->bc_len == buf_f->blf_len) {\r\nbcp->bc_refcount++;\r\ntrace_xfs_log_recover_buf_cancel_ref_inc(log, buf_f);\r\nreturn 0;\r\n}\r\n}\r\nbcp = kmem_alloc(sizeof(struct xfs_buf_cancel), KM_SLEEP);\r\nbcp->bc_blkno = buf_f->blf_blkno;\r\nbcp->bc_len = buf_f->blf_len;\r\nbcp->bc_refcount = 1;\r\nlist_add_tail(&bcp->bc_list, bucket);\r\ntrace_xfs_log_recover_buf_cancel_add(log, buf_f);\r\nreturn 0;\r\n}\r\nSTATIC struct xfs_buf_cancel *\r\nxlog_peek_buffer_cancelled(\r\nstruct xlog *log,\r\nxfs_daddr_t blkno,\r\nuint len,\r\nunsigned short flags)\r\n{\r\nstruct list_head *bucket;\r\nstruct xfs_buf_cancel *bcp;\r\nif (!log->l_buf_cancel_table) {\r\nASSERT(!(flags & XFS_BLF_CANCEL));\r\nreturn NULL;\r\n}\r\nbucket = XLOG_BUF_CANCEL_BUCKET(log, blkno);\r\nlist_for_each_entry(bcp, bucket, bc_list) {\r\nif (bcp->bc_blkno == blkno && bcp->bc_len == len)\r\nreturn bcp;\r\n}\r\nASSERT(!(flags & XFS_BLF_CANCEL));\r\nreturn NULL;\r\n}\r\nSTATIC int\r\nxlog_check_buffer_cancelled(\r\nstruct xlog *log,\r\nxfs_daddr_t blkno,\r\nuint len,\r\nunsigned short flags)\r\n{\r\nstruct xfs_buf_cancel *bcp;\r\nbcp = xlog_peek_buffer_cancelled(log, blkno, len, flags);\r\nif (!bcp)\r\nreturn 0;\r\nif (flags & XFS_BLF_CANCEL) {\r\nif (--bcp->bc_refcount == 0) {\r\nlist_del(&bcp->bc_list);\r\nkmem_free(bcp);\r\n}\r\n}\r\nreturn 1;\r\n}\r\nSTATIC int\r\nxlog_recover_do_inode_buffer(\r\nstruct xfs_mount *mp,\r\nxlog_recover_item_t *item,\r\nstruct xfs_buf *bp,\r\nxfs_buf_log_format_t *buf_f)\r\n{\r\nint i;\r\nint item_index = 0;\r\nint bit = 0;\r\nint nbits = 0;\r\nint reg_buf_offset = 0;\r\nint reg_buf_bytes = 0;\r\nint next_unlinked_offset;\r\nint inodes_per_buf;\r\nxfs_agino_t *logged_nextp;\r\nxfs_agino_t *buffer_nextp;\r\ntrace_xfs_log_recover_buf_inode_buf(mp->m_log, buf_f);\r\nif (xfs_sb_version_hascrc(&mp->m_sb))\r\nbp->b_ops = &xfs_inode_buf_ops;\r\ninodes_per_buf = BBTOB(bp->b_io_length) >> mp->m_sb.sb_inodelog;\r\nfor (i = 0; i < inodes_per_buf; i++) {\r\nnext_unlinked_offset = (i * mp->m_sb.sb_inodesize) +\r\noffsetof(xfs_dinode_t, di_next_unlinked);\r\nwhile (next_unlinked_offset >=\r\n(reg_buf_offset + reg_buf_bytes)) {\r\nbit += nbits;\r\nbit = xfs_next_bit(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nif (bit == -1)\r\nreturn 0;\r\nnbits = xfs_contig_bits(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nASSERT(nbits > 0);\r\nreg_buf_offset = bit << XFS_BLF_SHIFT;\r\nreg_buf_bytes = nbits << XFS_BLF_SHIFT;\r\nitem_index++;\r\n}\r\nif (next_unlinked_offset < reg_buf_offset)\r\ncontinue;\r\nASSERT(item->ri_buf[item_index].i_addr != NULL);\r\nASSERT((item->ri_buf[item_index].i_len % XFS_BLF_CHUNK) == 0);\r\nASSERT((reg_buf_offset + reg_buf_bytes) <=\r\nBBTOB(bp->b_io_length));\r\nlogged_nextp = item->ri_buf[item_index].i_addr +\r\nnext_unlinked_offset - reg_buf_offset;\r\nif (unlikely(*logged_nextp == 0)) {\r\nxfs_alert(mp,\r\n"Bad inode buffer log record (ptr = 0x%p, bp = 0x%p). "\r\n"Trying to replay bad (0) inode di_next_unlinked field.",\r\nitem, bp);\r\nXFS_ERROR_REPORT("xlog_recover_do_inode_buf",\r\nXFS_ERRLEVEL_LOW, mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nbuffer_nextp = xfs_buf_offset(bp, next_unlinked_offset);\r\n*buffer_nextp = *logged_nextp;\r\nxfs_dinode_calc_crc(mp,\r\nxfs_buf_offset(bp, i * mp->m_sb.sb_inodesize));\r\n}\r\nreturn 0;\r\n}\r\nstatic xfs_lsn_t\r\nxlog_recover_get_buf_lsn(\r\nstruct xfs_mount *mp,\r\nstruct xfs_buf *bp)\r\n{\r\n__uint32_t magic32;\r\n__uint16_t magic16;\r\n__uint16_t magicda;\r\nvoid *blk = bp->b_addr;\r\nuuid_t *uuid;\r\nxfs_lsn_t lsn = -1;\r\nif (!xfs_sb_version_hascrc(&mp->m_sb))\r\ngoto recover_immediately;\r\nmagic32 = be32_to_cpu(*(__be32 *)blk);\r\nswitch (magic32) {\r\ncase XFS_ABTB_CRC_MAGIC:\r\ncase XFS_ABTC_CRC_MAGIC:\r\ncase XFS_ABTB_MAGIC:\r\ncase XFS_ABTC_MAGIC:\r\ncase XFS_RMAP_CRC_MAGIC:\r\ncase XFS_REFC_CRC_MAGIC:\r\ncase XFS_IBT_CRC_MAGIC:\r\ncase XFS_IBT_MAGIC: {\r\nstruct xfs_btree_block *btb = blk;\r\nlsn = be64_to_cpu(btb->bb_u.s.bb_lsn);\r\nuuid = &btb->bb_u.s.bb_uuid;\r\nbreak;\r\n}\r\ncase XFS_BMAP_CRC_MAGIC:\r\ncase XFS_BMAP_MAGIC: {\r\nstruct xfs_btree_block *btb = blk;\r\nlsn = be64_to_cpu(btb->bb_u.l.bb_lsn);\r\nuuid = &btb->bb_u.l.bb_uuid;\r\nbreak;\r\n}\r\ncase XFS_AGF_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_agf *)blk)->agf_lsn);\r\nuuid = &((struct xfs_agf *)blk)->agf_uuid;\r\nbreak;\r\ncase XFS_AGFL_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_agfl *)blk)->agfl_lsn);\r\nuuid = &((struct xfs_agfl *)blk)->agfl_uuid;\r\nbreak;\r\ncase XFS_AGI_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_agi *)blk)->agi_lsn);\r\nuuid = &((struct xfs_agi *)blk)->agi_uuid;\r\nbreak;\r\ncase XFS_SYMLINK_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_dsymlink_hdr *)blk)->sl_lsn);\r\nuuid = &((struct xfs_dsymlink_hdr *)blk)->sl_uuid;\r\nbreak;\r\ncase XFS_DIR3_BLOCK_MAGIC:\r\ncase XFS_DIR3_DATA_MAGIC:\r\ncase XFS_DIR3_FREE_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_dir3_blk_hdr *)blk)->lsn);\r\nuuid = &((struct xfs_dir3_blk_hdr *)blk)->uuid;\r\nbreak;\r\ncase XFS_ATTR3_RMT_MAGIC:\r\ngoto recover_immediately;\r\ncase XFS_SB_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_dsb *)blk)->sb_lsn);\r\nif (xfs_sb_version_hasmetauuid(&mp->m_sb))\r\nuuid = &((struct xfs_dsb *)blk)->sb_meta_uuid;\r\nelse\r\nuuid = &((struct xfs_dsb *)blk)->sb_uuid;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (lsn != (xfs_lsn_t)-1) {\r\nif (!uuid_equal(&mp->m_sb.sb_meta_uuid, uuid))\r\ngoto recover_immediately;\r\nreturn lsn;\r\n}\r\nmagicda = be16_to_cpu(((struct xfs_da_blkinfo *)blk)->magic);\r\nswitch (magicda) {\r\ncase XFS_DIR3_LEAF1_MAGIC:\r\ncase XFS_DIR3_LEAFN_MAGIC:\r\ncase XFS_DA3_NODE_MAGIC:\r\nlsn = be64_to_cpu(((struct xfs_da3_blkinfo *)blk)->lsn);\r\nuuid = &((struct xfs_da3_blkinfo *)blk)->uuid;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (lsn != (xfs_lsn_t)-1) {\r\nif (!uuid_equal(&mp->m_sb.sb_uuid, uuid))\r\ngoto recover_immediately;\r\nreturn lsn;\r\n}\r\nmagic16 = be16_to_cpu(*(__be16 *)blk);\r\nswitch (magic16) {\r\ncase XFS_DQUOT_MAGIC:\r\ncase XFS_DINODE_MAGIC:\r\ngoto recover_immediately;\r\ndefault:\r\nbreak;\r\n}\r\nrecover_immediately:\r\nreturn (xfs_lsn_t)-1;\r\n}\r\nstatic void\r\nxlog_recover_validate_buf_type(\r\nstruct xfs_mount *mp,\r\nstruct xfs_buf *bp,\r\nxfs_buf_log_format_t *buf_f,\r\nxfs_lsn_t current_lsn)\r\n{\r\nstruct xfs_da_blkinfo *info = bp->b_addr;\r\n__uint32_t magic32;\r\n__uint16_t magic16;\r\n__uint16_t magicda;\r\nchar *warnmsg = NULL;\r\nif (!xfs_sb_version_hascrc(&mp->m_sb))\r\nreturn;\r\nmagic32 = be32_to_cpu(*(__be32 *)bp->b_addr);\r\nmagic16 = be16_to_cpu(*(__be16*)bp->b_addr);\r\nmagicda = be16_to_cpu(info->magic);\r\nswitch (xfs_blft_from_flags(buf_f)) {\r\ncase XFS_BLFT_BTREE_BUF:\r\nswitch (magic32) {\r\ncase XFS_ABTB_CRC_MAGIC:\r\ncase XFS_ABTC_CRC_MAGIC:\r\ncase XFS_ABTB_MAGIC:\r\ncase XFS_ABTC_MAGIC:\r\nbp->b_ops = &xfs_allocbt_buf_ops;\r\nbreak;\r\ncase XFS_IBT_CRC_MAGIC:\r\ncase XFS_FIBT_CRC_MAGIC:\r\ncase XFS_IBT_MAGIC:\r\ncase XFS_FIBT_MAGIC:\r\nbp->b_ops = &xfs_inobt_buf_ops;\r\nbreak;\r\ncase XFS_BMAP_CRC_MAGIC:\r\ncase XFS_BMAP_MAGIC:\r\nbp->b_ops = &xfs_bmbt_buf_ops;\r\nbreak;\r\ncase XFS_RMAP_CRC_MAGIC:\r\nbp->b_ops = &xfs_rmapbt_buf_ops;\r\nbreak;\r\ncase XFS_REFC_CRC_MAGIC:\r\nbp->b_ops = &xfs_refcountbt_buf_ops;\r\nbreak;\r\ndefault:\r\nwarnmsg = "Bad btree block magic!";\r\nbreak;\r\n}\r\nbreak;\r\ncase XFS_BLFT_AGF_BUF:\r\nif (magic32 != XFS_AGF_MAGIC) {\r\nwarnmsg = "Bad AGF block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_agf_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_AGFL_BUF:\r\nif (magic32 != XFS_AGFL_MAGIC) {\r\nwarnmsg = "Bad AGFL block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_agfl_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_AGI_BUF:\r\nif (magic32 != XFS_AGI_MAGIC) {\r\nwarnmsg = "Bad AGI block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_agi_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_UDQUOT_BUF:\r\ncase XFS_BLFT_PDQUOT_BUF:\r\ncase XFS_BLFT_GDQUOT_BUF:\r\n#ifdef CONFIG_XFS_QUOTA\r\nif (magic16 != XFS_DQUOT_MAGIC) {\r\nwarnmsg = "Bad DQUOT block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dquot_buf_ops;\r\n#else\r\nxfs_alert(mp,\r\n"Trying to recover dquots without QUOTA support built in!");\r\nASSERT(0);\r\n#endif\r\nbreak;\r\ncase XFS_BLFT_DINO_BUF:\r\nif (magic16 != XFS_DINODE_MAGIC) {\r\nwarnmsg = "Bad INODE block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_inode_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_SYMLINK_BUF:\r\nif (magic32 != XFS_SYMLINK_MAGIC) {\r\nwarnmsg = "Bad symlink block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_symlink_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_BLOCK_BUF:\r\nif (magic32 != XFS_DIR2_BLOCK_MAGIC &&\r\nmagic32 != XFS_DIR3_BLOCK_MAGIC) {\r\nwarnmsg = "Bad dir block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_block_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_DATA_BUF:\r\nif (magic32 != XFS_DIR2_DATA_MAGIC &&\r\nmagic32 != XFS_DIR3_DATA_MAGIC) {\r\nwarnmsg = "Bad dir data magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_data_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_FREE_BUF:\r\nif (magic32 != XFS_DIR2_FREE_MAGIC &&\r\nmagic32 != XFS_DIR3_FREE_MAGIC) {\r\nwarnmsg = "Bad dir3 free magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_free_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_LEAF1_BUF:\r\nif (magicda != XFS_DIR2_LEAF1_MAGIC &&\r\nmagicda != XFS_DIR3_LEAF1_MAGIC) {\r\nwarnmsg = "Bad dir leaf1 magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_leaf1_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DIR_LEAFN_BUF:\r\nif (magicda != XFS_DIR2_LEAFN_MAGIC &&\r\nmagicda != XFS_DIR3_LEAFN_MAGIC) {\r\nwarnmsg = "Bad dir leafn magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_dir3_leafn_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_DA_NODE_BUF:\r\nif (magicda != XFS_DA_NODE_MAGIC &&\r\nmagicda != XFS_DA3_NODE_MAGIC) {\r\nwarnmsg = "Bad da node magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_da3_node_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_ATTR_LEAF_BUF:\r\nif (magicda != XFS_ATTR_LEAF_MAGIC &&\r\nmagicda != XFS_ATTR3_LEAF_MAGIC) {\r\nwarnmsg = "Bad attr leaf magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_attr3_leaf_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_ATTR_RMT_BUF:\r\nif (magic32 != XFS_ATTR3_RMT_MAGIC) {\r\nwarnmsg = "Bad attr remote magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_attr3_rmt_buf_ops;\r\nbreak;\r\ncase XFS_BLFT_SB_BUF:\r\nif (magic32 != XFS_SB_MAGIC) {\r\nwarnmsg = "Bad SB block magic!";\r\nbreak;\r\n}\r\nbp->b_ops = &xfs_sb_buf_ops;\r\nbreak;\r\n#ifdef CONFIG_XFS_RT\r\ncase XFS_BLFT_RTBITMAP_BUF:\r\ncase XFS_BLFT_RTSUMMARY_BUF:\r\nbp->b_ops = &xfs_rtbuf_ops;\r\nbreak;\r\n#endif\r\ndefault:\r\nxfs_warn(mp, "Unknown buffer type %d!",\r\nxfs_blft_from_flags(buf_f));\r\nbreak;\r\n}\r\nif (current_lsn == NULLCOMMITLSN)\r\nreturn;\r\nif (warnmsg) {\r\nxfs_warn(mp, warnmsg);\r\nASSERT(0);\r\n}\r\nif (bp->b_ops) {\r\nstruct xfs_buf_log_item *bip;\r\nASSERT(!bp->b_iodone || bp->b_iodone == xlog_recover_iodone);\r\nbp->b_iodone = xlog_recover_iodone;\r\nxfs_buf_item_init(bp, mp);\r\nbip = bp->b_fspriv;\r\nbip->bli_item.li_lsn = current_lsn;\r\n}\r\n}\r\nSTATIC void\r\nxlog_recover_do_reg_buffer(\r\nstruct xfs_mount *mp,\r\nxlog_recover_item_t *item,\r\nstruct xfs_buf *bp,\r\nxfs_buf_log_format_t *buf_f,\r\nxfs_lsn_t current_lsn)\r\n{\r\nint i;\r\nint bit;\r\nint nbits;\r\nint error;\r\ntrace_xfs_log_recover_buf_reg_buf(mp->m_log, buf_f);\r\nbit = 0;\r\ni = 1;\r\nwhile (1) {\r\nbit = xfs_next_bit(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nif (bit == -1)\r\nbreak;\r\nnbits = xfs_contig_bits(buf_f->blf_data_map,\r\nbuf_f->blf_map_size, bit);\r\nASSERT(nbits > 0);\r\nASSERT(item->ri_buf[i].i_addr != NULL);\r\nASSERT(item->ri_buf[i].i_len % XFS_BLF_CHUNK == 0);\r\nASSERT(BBTOB(bp->b_io_length) >=\r\n((uint)bit << XFS_BLF_SHIFT) + (nbits << XFS_BLF_SHIFT));\r\nif (item->ri_buf[i].i_len < (nbits << XFS_BLF_SHIFT))\r\nnbits = item->ri_buf[i].i_len >> XFS_BLF_SHIFT;\r\nerror = 0;\r\nif (buf_f->blf_flags &\r\n(XFS_BLF_UDQUOT_BUF|XFS_BLF_PDQUOT_BUF|XFS_BLF_GDQUOT_BUF)) {\r\nif (item->ri_buf[i].i_addr == NULL) {\r\nxfs_alert(mp,\r\n"XFS: NULL dquot in %s.", __func__);\r\ngoto next;\r\n}\r\nif (item->ri_buf[i].i_len < sizeof(xfs_disk_dquot_t)) {\r\nxfs_alert(mp,\r\n"XFS: dquot too small (%d) in %s.",\r\nitem->ri_buf[i].i_len, __func__);\r\ngoto next;\r\n}\r\nerror = xfs_dqcheck(mp, item->ri_buf[i].i_addr,\r\n-1, 0, XFS_QMOPT_DOWARN,\r\n"dquot_buf_recover");\r\nif (error)\r\ngoto next;\r\n}\r\nmemcpy(xfs_buf_offset(bp,\r\n(uint)bit << XFS_BLF_SHIFT),\r\nitem->ri_buf[i].i_addr,\r\nnbits<<XFS_BLF_SHIFT);\r\nnext:\r\ni++;\r\nbit += nbits;\r\n}\r\nASSERT(i == item->ri_total);\r\nxlog_recover_validate_buf_type(mp, bp, buf_f, current_lsn);\r\n}\r\nSTATIC bool\r\nxlog_recover_do_dquot_buffer(\r\nstruct xfs_mount *mp,\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item,\r\nstruct xfs_buf *bp,\r\nstruct xfs_buf_log_format *buf_f)\r\n{\r\nuint type;\r\ntrace_xfs_log_recover_buf_dquot_buf(log, buf_f);\r\nif (!mp->m_qflags)\r\nreturn false;\r\ntype = 0;\r\nif (buf_f->blf_flags & XFS_BLF_UDQUOT_BUF)\r\ntype |= XFS_DQ_USER;\r\nif (buf_f->blf_flags & XFS_BLF_PDQUOT_BUF)\r\ntype |= XFS_DQ_PROJ;\r\nif (buf_f->blf_flags & XFS_BLF_GDQUOT_BUF)\r\ntype |= XFS_DQ_GROUP;\r\nif (log->l_quotaoffs_flag & type)\r\nreturn false;\r\nxlog_recover_do_reg_buffer(mp, item, bp, buf_f, NULLCOMMITLSN);\r\nreturn true;\r\n}\r\nSTATIC int\r\nxlog_recover_buffer_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t current_lsn)\r\n{\r\nxfs_buf_log_format_t *buf_f = item->ri_buf[0].i_addr;\r\nxfs_mount_t *mp = log->l_mp;\r\nxfs_buf_t *bp;\r\nint error;\r\nuint buf_flags;\r\nxfs_lsn_t lsn;\r\nif (xlog_check_buffer_cancelled(log, buf_f->blf_blkno,\r\nbuf_f->blf_len, buf_f->blf_flags)) {\r\ntrace_xfs_log_recover_buf_cancel(log, buf_f);\r\nreturn 0;\r\n}\r\ntrace_xfs_log_recover_buf_recover(log, buf_f);\r\nbuf_flags = 0;\r\nif (buf_f->blf_flags & XFS_BLF_INODE_BUF)\r\nbuf_flags |= XBF_UNMAPPED;\r\nbp = xfs_buf_read(mp->m_ddev_targp, buf_f->blf_blkno, buf_f->blf_len,\r\nbuf_flags, NULL);\r\nif (!bp)\r\nreturn -ENOMEM;\r\nerror = bp->b_error;\r\nif (error) {\r\nxfs_buf_ioerror_alert(bp, "xlog_recover_do..(read#1)");\r\ngoto out_release;\r\n}\r\nlsn = xlog_recover_get_buf_lsn(mp, bp);\r\nif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\r\ntrace_xfs_log_recover_buf_skip(log, buf_f);\r\nxlog_recover_validate_buf_type(mp, bp, buf_f, NULLCOMMITLSN);\r\ngoto out_release;\r\n}\r\nif (buf_f->blf_flags & XFS_BLF_INODE_BUF) {\r\nerror = xlog_recover_do_inode_buffer(mp, item, bp, buf_f);\r\nif (error)\r\ngoto out_release;\r\n} else if (buf_f->blf_flags &\r\n(XFS_BLF_UDQUOT_BUF|XFS_BLF_PDQUOT_BUF|XFS_BLF_GDQUOT_BUF)) {\r\nbool dirty;\r\ndirty = xlog_recover_do_dquot_buffer(mp, log, item, bp, buf_f);\r\nif (!dirty)\r\ngoto out_release;\r\n} else {\r\nxlog_recover_do_reg_buffer(mp, item, bp, buf_f, current_lsn);\r\n}\r\nif (XFS_DINODE_MAGIC ==\r\nbe16_to_cpu(*((__be16 *)xfs_buf_offset(bp, 0))) &&\r\n(BBTOB(bp->b_io_length) != MAX(log->l_mp->m_sb.sb_blocksize,\r\n(__uint32_t)log->l_mp->m_inode_cluster_size))) {\r\nxfs_buf_stale(bp);\r\nerror = xfs_bwrite(bp);\r\n} else {\r\nASSERT(bp->b_target->bt_mount == mp);\r\nbp->b_iodone = xlog_recover_iodone;\r\nxfs_buf_delwri_queue(bp, buffer_list);\r\n}\r\nout_release:\r\nxfs_buf_relse(bp);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_recover_inode_owner_change(\r\nstruct xfs_mount *mp,\r\nstruct xfs_dinode *dip,\r\nstruct xfs_inode_log_format *in_f,\r\nstruct list_head *buffer_list)\r\n{\r\nstruct xfs_inode *ip;\r\nint error;\r\nASSERT(in_f->ilf_fields & (XFS_ILOG_DOWNER|XFS_ILOG_AOWNER));\r\nip = xfs_inode_alloc(mp, in_f->ilf_ino);\r\nif (!ip)\r\nreturn -ENOMEM;\r\nxfs_inode_from_disk(ip, dip);\r\nASSERT(ip->i_d.di_version >= 3);\r\nerror = xfs_iformat_fork(ip, dip);\r\nif (error)\r\ngoto out_free_ip;\r\nif (in_f->ilf_fields & XFS_ILOG_DOWNER) {\r\nASSERT(in_f->ilf_fields & XFS_ILOG_DBROOT);\r\nerror = xfs_bmbt_change_owner(NULL, ip, XFS_DATA_FORK,\r\nip->i_ino, buffer_list);\r\nif (error)\r\ngoto out_free_ip;\r\n}\r\nif (in_f->ilf_fields & XFS_ILOG_AOWNER) {\r\nASSERT(in_f->ilf_fields & XFS_ILOG_ABROOT);\r\nerror = xfs_bmbt_change_owner(NULL, ip, XFS_ATTR_FORK,\r\nip->i_ino, buffer_list);\r\nif (error)\r\ngoto out_free_ip;\r\n}\r\nout_free_ip:\r\nxfs_inode_free(ip);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_inode_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t current_lsn)\r\n{\r\nxfs_inode_log_format_t *in_f;\r\nxfs_mount_t *mp = log->l_mp;\r\nxfs_buf_t *bp;\r\nxfs_dinode_t *dip;\r\nint len;\r\nchar *src;\r\nchar *dest;\r\nint error;\r\nint attr_index;\r\nuint fields;\r\nstruct xfs_log_dinode *ldip;\r\nuint isize;\r\nint need_free = 0;\r\nif (item->ri_buf[0].i_len == sizeof(xfs_inode_log_format_t)) {\r\nin_f = item->ri_buf[0].i_addr;\r\n} else {\r\nin_f = kmem_alloc(sizeof(xfs_inode_log_format_t), KM_SLEEP);\r\nneed_free = 1;\r\nerror = xfs_inode_item_format_convert(&item->ri_buf[0], in_f);\r\nif (error)\r\ngoto error;\r\n}\r\nif (xlog_check_buffer_cancelled(log, in_f->ilf_blkno,\r\nin_f->ilf_len, 0)) {\r\nerror = 0;\r\ntrace_xfs_log_recover_inode_cancel(log, in_f);\r\ngoto error;\r\n}\r\ntrace_xfs_log_recover_inode_recover(log, in_f);\r\nbp = xfs_buf_read(mp->m_ddev_targp, in_f->ilf_blkno, in_f->ilf_len, 0,\r\n&xfs_inode_buf_ops);\r\nif (!bp) {\r\nerror = -ENOMEM;\r\ngoto error;\r\n}\r\nerror = bp->b_error;\r\nif (error) {\r\nxfs_buf_ioerror_alert(bp, "xlog_recover_do..(read#2)");\r\ngoto out_release;\r\n}\r\nASSERT(in_f->ilf_fields & XFS_ILOG_CORE);\r\ndip = xfs_buf_offset(bp, in_f->ilf_boffset);\r\nif (unlikely(dip->di_magic != cpu_to_be16(XFS_DINODE_MAGIC))) {\r\nxfs_alert(mp,\r\n"%s: Bad inode magic number, dip = 0x%p, dino bp = 0x%p, ino = %Ld",\r\n__func__, dip, bp, in_f->ilf_ino);\r\nXFS_ERROR_REPORT("xlog_recover_inode_pass2(1)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nldip = item->ri_buf[1].i_addr;\r\nif (unlikely(ldip->di_magic != XFS_DINODE_MAGIC)) {\r\nxfs_alert(mp,\r\n"%s: Bad inode log record, rec ptr 0x%p, ino %Ld",\r\n__func__, item, in_f->ilf_ino);\r\nXFS_ERROR_REPORT("xlog_recover_inode_pass2(2)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nif (dip->di_version >= 3) {\r\nxfs_lsn_t lsn = be64_to_cpu(dip->di_lsn);\r\nif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\r\ntrace_xfs_log_recover_inode_skip(log, in_f);\r\nerror = 0;\r\ngoto out_owner_change;\r\n}\r\n}\r\nif (!xfs_sb_version_hascrc(&mp->m_sb) &&\r\nldip->di_flushiter < be16_to_cpu(dip->di_flushiter)) {\r\nif (be16_to_cpu(dip->di_flushiter) == DI_MAX_FLUSH &&\r\nldip->di_flushiter < (DI_MAX_FLUSH >> 1)) {\r\n} else {\r\ntrace_xfs_log_recover_inode_skip(log, in_f);\r\nerror = 0;\r\ngoto out_release;\r\n}\r\n}\r\nldip->di_flushiter = 0;\r\nif (unlikely(S_ISREG(ldip->di_mode))) {\r\nif ((ldip->di_format != XFS_DINODE_FMT_EXTENTS) &&\r\n(ldip->di_format != XFS_DINODE_FMT_BTREE)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(3)",\r\nXFS_ERRLEVEL_LOW, mp, ldip);\r\nxfs_alert(mp,\r\n"%s: Bad regular inode log record, rec ptr 0x%p, "\r\n"ino ptr = 0x%p, ino bp = 0x%p, ino %Ld",\r\n__func__, item, dip, bp, in_f->ilf_ino);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\n} else if (unlikely(S_ISDIR(ldip->di_mode))) {\r\nif ((ldip->di_format != XFS_DINODE_FMT_EXTENTS) &&\r\n(ldip->di_format != XFS_DINODE_FMT_BTREE) &&\r\n(ldip->di_format != XFS_DINODE_FMT_LOCAL)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(4)",\r\nXFS_ERRLEVEL_LOW, mp, ldip);\r\nxfs_alert(mp,\r\n"%s: Bad dir inode log record, rec ptr 0x%p, "\r\n"ino ptr = 0x%p, ino bp = 0x%p, ino %Ld",\r\n__func__, item, dip, bp, in_f->ilf_ino);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\n}\r\nif (unlikely(ldip->di_nextents + ldip->di_anextents > ldip->di_nblocks)){\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(5)",\r\nXFS_ERRLEVEL_LOW, mp, ldip);\r\nxfs_alert(mp,\r\n"%s: Bad inode log record, rec ptr 0x%p, dino ptr 0x%p, "\r\n"dino bp 0x%p, ino %Ld, total extents = %d, nblocks = %Ld",\r\n__func__, item, dip, bp, in_f->ilf_ino,\r\nldip->di_nextents + ldip->di_anextents,\r\nldip->di_nblocks);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nif (unlikely(ldip->di_forkoff > mp->m_sb.sb_inodesize)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(6)",\r\nXFS_ERRLEVEL_LOW, mp, ldip);\r\nxfs_alert(mp,\r\n"%s: Bad inode log record, rec ptr 0x%p, dino ptr 0x%p, "\r\n"dino bp 0x%p, ino %Ld, forkoff 0x%x", __func__,\r\nitem, dip, bp, in_f->ilf_ino, ldip->di_forkoff);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nisize = xfs_log_dinode_size(ldip->di_version);\r\nif (unlikely(item->ri_buf[1].i_len > isize)) {\r\nXFS_CORRUPTION_ERROR("xlog_recover_inode_pass2(7)",\r\nXFS_ERRLEVEL_LOW, mp, ldip);\r\nxfs_alert(mp,\r\n"%s: Bad inode log record length %d, rec ptr 0x%p",\r\n__func__, item->ri_buf[1].i_len, item);\r\nerror = -EFSCORRUPTED;\r\ngoto out_release;\r\n}\r\nxfs_log_dinode_to_disk(ldip, dip);\r\nif (item->ri_buf[1].i_len > isize) {\r\nmemcpy((char *)dip + isize,\r\nitem->ri_buf[1].i_addr + isize,\r\nitem->ri_buf[1].i_len - isize);\r\n}\r\nfields = in_f->ilf_fields;\r\nswitch (fields & (XFS_ILOG_DEV | XFS_ILOG_UUID)) {\r\ncase XFS_ILOG_DEV:\r\nxfs_dinode_put_rdev(dip, in_f->ilf_u.ilfu_rdev);\r\nbreak;\r\ncase XFS_ILOG_UUID:\r\nmemcpy(XFS_DFORK_DPTR(dip),\r\n&in_f->ilf_u.ilfu_uuid,\r\nsizeof(uuid_t));\r\nbreak;\r\n}\r\nif (in_f->ilf_size == 2)\r\ngoto out_owner_change;\r\nlen = item->ri_buf[2].i_len;\r\nsrc = item->ri_buf[2].i_addr;\r\nASSERT(in_f->ilf_size <= 4);\r\nASSERT((in_f->ilf_size == 3) || (fields & XFS_ILOG_AFORK));\r\nASSERT(!(fields & XFS_ILOG_DFORK) ||\r\n(len == in_f->ilf_dsize));\r\nswitch (fields & XFS_ILOG_DFORK) {\r\ncase XFS_ILOG_DDATA:\r\ncase XFS_ILOG_DEXT:\r\nmemcpy(XFS_DFORK_DPTR(dip), src, len);\r\nbreak;\r\ncase XFS_ILOG_DBROOT:\r\nxfs_bmbt_to_bmdr(mp, (struct xfs_btree_block *)src, len,\r\n(xfs_bmdr_block_t *)XFS_DFORK_DPTR(dip),\r\nXFS_DFORK_DSIZE(dip, mp));\r\nbreak;\r\ndefault:\r\nASSERT((fields & XFS_ILOG_DFORK) == 0);\r\nbreak;\r\n}\r\nif (in_f->ilf_fields & XFS_ILOG_AFORK) {\r\nif (in_f->ilf_fields & XFS_ILOG_DFORK) {\r\nattr_index = 3;\r\n} else {\r\nattr_index = 2;\r\n}\r\nlen = item->ri_buf[attr_index].i_len;\r\nsrc = item->ri_buf[attr_index].i_addr;\r\nASSERT(len == in_f->ilf_asize);\r\nswitch (in_f->ilf_fields & XFS_ILOG_AFORK) {\r\ncase XFS_ILOG_ADATA:\r\ncase XFS_ILOG_AEXT:\r\ndest = XFS_DFORK_APTR(dip);\r\nASSERT(len <= XFS_DFORK_ASIZE(dip, mp));\r\nmemcpy(dest, src, len);\r\nbreak;\r\ncase XFS_ILOG_ABROOT:\r\ndest = XFS_DFORK_APTR(dip);\r\nxfs_bmbt_to_bmdr(mp, (struct xfs_btree_block *)src,\r\nlen, (xfs_bmdr_block_t*)dest,\r\nXFS_DFORK_ASIZE(dip, mp));\r\nbreak;\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: Invalid flag", __func__);\r\nASSERT(0);\r\nerror = -EIO;\r\ngoto out_release;\r\n}\r\n}\r\nout_owner_change:\r\nif (in_f->ilf_fields & (XFS_ILOG_DOWNER|XFS_ILOG_AOWNER))\r\nerror = xfs_recover_inode_owner_change(mp, dip, in_f,\r\nbuffer_list);\r\nxfs_dinode_calc_crc(log->l_mp, dip);\r\nASSERT(bp->b_target->bt_mount == mp);\r\nbp->b_iodone = xlog_recover_iodone;\r\nxfs_buf_delwri_queue(bp, buffer_list);\r\nout_release:\r\nxfs_buf_relse(bp);\r\nerror:\r\nif (need_free)\r\nkmem_free(in_f);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_quotaoff_pass1(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nxfs_qoff_logformat_t *qoff_f = item->ri_buf[0].i_addr;\r\nASSERT(qoff_f);\r\nif (qoff_f->qf_flags & XFS_UQUOTA_ACCT)\r\nlog->l_quotaoffs_flag |= XFS_DQ_USER;\r\nif (qoff_f->qf_flags & XFS_PQUOTA_ACCT)\r\nlog->l_quotaoffs_flag |= XFS_DQ_PROJ;\r\nif (qoff_f->qf_flags & XFS_GQUOTA_ACCT)\r\nlog->l_quotaoffs_flag |= XFS_DQ_GROUP;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_dquot_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t current_lsn)\r\n{\r\nxfs_mount_t *mp = log->l_mp;\r\nxfs_buf_t *bp;\r\nstruct xfs_disk_dquot *ddq, *recddq;\r\nint error;\r\nxfs_dq_logformat_t *dq_f;\r\nuint type;\r\nif (mp->m_qflags == 0)\r\nreturn 0;\r\nrecddq = item->ri_buf[1].i_addr;\r\nif (recddq == NULL) {\r\nxfs_alert(log->l_mp, "NULL dquot in %s.", __func__);\r\nreturn -EIO;\r\n}\r\nif (item->ri_buf[1].i_len < sizeof(xfs_disk_dquot_t)) {\r\nxfs_alert(log->l_mp, "dquot too small (%d) in %s.",\r\nitem->ri_buf[1].i_len, __func__);\r\nreturn -EIO;\r\n}\r\ntype = recddq->d_flags & (XFS_DQ_USER | XFS_DQ_PROJ | XFS_DQ_GROUP);\r\nASSERT(type);\r\nif (log->l_quotaoffs_flag & type)\r\nreturn 0;\r\ndq_f = item->ri_buf[0].i_addr;\r\nASSERT(dq_f);\r\nerror = xfs_dqcheck(mp, recddq, dq_f->qlf_id, 0, XFS_QMOPT_DOWARN,\r\n"xlog_recover_dquot_pass2 (log copy)");\r\nif (error)\r\nreturn -EIO;\r\nASSERT(dq_f->qlf_len == 1);\r\nerror = xfs_trans_read_buf(mp, NULL, mp->m_ddev_targp, dq_f->qlf_blkno,\r\nXFS_FSB_TO_BB(mp, dq_f->qlf_len), 0, &bp,\r\n&xfs_dquot_buf_ops);\r\nif (error)\r\nreturn error;\r\nASSERT(bp);\r\nddq = xfs_buf_offset(bp, dq_f->qlf_boffset);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nstruct xfs_dqblk *dqb = (struct xfs_dqblk *)ddq;\r\nxfs_lsn_t lsn = be64_to_cpu(dqb->dd_lsn);\r\nif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\r\ngoto out_release;\r\n}\r\n}\r\nmemcpy(ddq, recddq, item->ri_buf[1].i_len);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nxfs_update_cksum((char *)ddq, sizeof(struct xfs_dqblk),\r\nXFS_DQUOT_CRC_OFF);\r\n}\r\nASSERT(dq_f->qlf_size == 2);\r\nASSERT(bp->b_target->bt_mount == mp);\r\nbp->b_iodone = xlog_recover_iodone;\r\nxfs_buf_delwri_queue(bp, buffer_list);\r\nout_release:\r\nxfs_buf_relse(bp);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_efi_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t lsn)\r\n{\r\nint error;\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_efi_log_item *efip;\r\nstruct xfs_efi_log_format *efi_formatp;\r\nefi_formatp = item->ri_buf[0].i_addr;\r\nefip = xfs_efi_init(mp, efi_formatp->efi_nextents);\r\nerror = xfs_efi_copy_format(&item->ri_buf[0], &efip->efi_format);\r\nif (error) {\r\nxfs_efi_item_free(efip);\r\nreturn error;\r\n}\r\natomic_set(&efip->efi_next_extent, efi_formatp->efi_nextents);\r\nspin_lock(&log->l_ailp->xa_lock);\r\nxfs_trans_ail_update(log->l_ailp, &efip->efi_item, lsn);\r\nxfs_efi_release(efip);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_efd_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nxfs_efd_log_format_t *efd_formatp;\r\nxfs_efi_log_item_t *efip = NULL;\r\nxfs_log_item_t *lip;\r\n__uint64_t efi_id;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp = log->l_ailp;\r\nefd_formatp = item->ri_buf[0].i_addr;\r\nASSERT((item->ri_buf[0].i_len == (sizeof(xfs_efd_log_format_32_t) +\r\n((efd_formatp->efd_nextents - 1) * sizeof(xfs_extent_32_t)))) ||\r\n(item->ri_buf[0].i_len == (sizeof(xfs_efd_log_format_64_t) +\r\n((efd_formatp->efd_nextents - 1) * sizeof(xfs_extent_64_t)))));\r\nefi_id = efd_formatp->efd_efi_id;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nwhile (lip != NULL) {\r\nif (lip->li_type == XFS_LI_EFI) {\r\nefip = (xfs_efi_log_item_t *)lip;\r\nif (efip->efi_format.efi_id == efi_id) {\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_efi_release(efip);\r\nspin_lock(&ailp->xa_lock);\r\nbreak;\r\n}\r\n}\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_rui_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t lsn)\r\n{\r\nint error;\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_rui_log_item *ruip;\r\nstruct xfs_rui_log_format *rui_formatp;\r\nrui_formatp = item->ri_buf[0].i_addr;\r\nruip = xfs_rui_init(mp, rui_formatp->rui_nextents);\r\nerror = xfs_rui_copy_format(&item->ri_buf[0], &ruip->rui_format);\r\nif (error) {\r\nxfs_rui_item_free(ruip);\r\nreturn error;\r\n}\r\natomic_set(&ruip->rui_next_extent, rui_formatp->rui_nextents);\r\nspin_lock(&log->l_ailp->xa_lock);\r\nxfs_trans_ail_update(log->l_ailp, &ruip->rui_item, lsn);\r\nxfs_rui_release(ruip);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_rud_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_rud_log_format *rud_formatp;\r\nstruct xfs_rui_log_item *ruip = NULL;\r\nstruct xfs_log_item *lip;\r\n__uint64_t rui_id;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp = log->l_ailp;\r\nrud_formatp = item->ri_buf[0].i_addr;\r\nASSERT(item->ri_buf[0].i_len == sizeof(struct xfs_rud_log_format));\r\nrui_id = rud_formatp->rud_rui_id;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nwhile (lip != NULL) {\r\nif (lip->li_type == XFS_LI_RUI) {\r\nruip = (struct xfs_rui_log_item *)lip;\r\nif (ruip->rui_format.rui_id == rui_id) {\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_rui_release(ruip);\r\nspin_lock(&ailp->xa_lock);\r\nbreak;\r\n}\r\n}\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn 0;\r\n}\r\nstatic int\r\nxfs_cui_copy_format(\r\nstruct xfs_log_iovec *buf,\r\nstruct xfs_cui_log_format *dst_cui_fmt)\r\n{\r\nstruct xfs_cui_log_format *src_cui_fmt;\r\nuint len;\r\nsrc_cui_fmt = buf->i_addr;\r\nlen = xfs_cui_log_format_sizeof(src_cui_fmt->cui_nextents);\r\nif (buf->i_len == len) {\r\nmemcpy(dst_cui_fmt, src_cui_fmt, len);\r\nreturn 0;\r\n}\r\nreturn -EFSCORRUPTED;\r\n}\r\nSTATIC int\r\nxlog_recover_cui_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t lsn)\r\n{\r\nint error;\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_cui_log_item *cuip;\r\nstruct xfs_cui_log_format *cui_formatp;\r\ncui_formatp = item->ri_buf[0].i_addr;\r\ncuip = xfs_cui_init(mp, cui_formatp->cui_nextents);\r\nerror = xfs_cui_copy_format(&item->ri_buf[0], &cuip->cui_format);\r\nif (error) {\r\nxfs_cui_item_free(cuip);\r\nreturn error;\r\n}\r\natomic_set(&cuip->cui_next_extent, cui_formatp->cui_nextents);\r\nspin_lock(&log->l_ailp->xa_lock);\r\nxfs_trans_ail_update(log->l_ailp, &cuip->cui_item, lsn);\r\nxfs_cui_release(cuip);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_cud_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_cud_log_format *cud_formatp;\r\nstruct xfs_cui_log_item *cuip = NULL;\r\nstruct xfs_log_item *lip;\r\n__uint64_t cui_id;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp = log->l_ailp;\r\ncud_formatp = item->ri_buf[0].i_addr;\r\nif (item->ri_buf[0].i_len != sizeof(struct xfs_cud_log_format))\r\nreturn -EFSCORRUPTED;\r\ncui_id = cud_formatp->cud_cui_id;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nwhile (lip != NULL) {\r\nif (lip->li_type == XFS_LI_CUI) {\r\ncuip = (struct xfs_cui_log_item *)lip;\r\nif (cuip->cui_format.cui_id == cui_id) {\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_cui_release(cuip);\r\nspin_lock(&ailp->xa_lock);\r\nbreak;\r\n}\r\n}\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn 0;\r\n}\r\nstatic int\r\nxfs_bui_copy_format(\r\nstruct xfs_log_iovec *buf,\r\nstruct xfs_bui_log_format *dst_bui_fmt)\r\n{\r\nstruct xfs_bui_log_format *src_bui_fmt;\r\nuint len;\r\nsrc_bui_fmt = buf->i_addr;\r\nlen = xfs_bui_log_format_sizeof(src_bui_fmt->bui_nextents);\r\nif (buf->i_len == len) {\r\nmemcpy(dst_bui_fmt, src_bui_fmt, len);\r\nreturn 0;\r\n}\r\nreturn -EFSCORRUPTED;\r\n}\r\nSTATIC int\r\nxlog_recover_bui_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item,\r\nxfs_lsn_t lsn)\r\n{\r\nint error;\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_bui_log_item *buip;\r\nstruct xfs_bui_log_format *bui_formatp;\r\nbui_formatp = item->ri_buf[0].i_addr;\r\nif (bui_formatp->bui_nextents != XFS_BUI_MAX_FAST_EXTENTS)\r\nreturn -EFSCORRUPTED;\r\nbuip = xfs_bui_init(mp);\r\nerror = xfs_bui_copy_format(&item->ri_buf[0], &buip->bui_format);\r\nif (error) {\r\nxfs_bui_item_free(buip);\r\nreturn error;\r\n}\r\natomic_set(&buip->bui_next_extent, bui_formatp->bui_nextents);\r\nspin_lock(&log->l_ailp->xa_lock);\r\nxfs_trans_ail_update(log->l_ailp, &buip->bui_item, lsn);\r\nxfs_bui_release(buip);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_bud_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_bud_log_format *bud_formatp;\r\nstruct xfs_bui_log_item *buip = NULL;\r\nstruct xfs_log_item *lip;\r\n__uint64_t bui_id;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp = log->l_ailp;\r\nbud_formatp = item->ri_buf[0].i_addr;\r\nif (item->ri_buf[0].i_len != sizeof(struct xfs_bud_log_format))\r\nreturn -EFSCORRUPTED;\r\nbui_id = bud_formatp->bud_bui_id;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nwhile (lip != NULL) {\r\nif (lip->li_type == XFS_LI_BUI) {\r\nbuip = (struct xfs_bui_log_item *)lip;\r\nif (buip->bui_format.bui_id == bui_id) {\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_bui_release(buip);\r\nspin_lock(&ailp->xa_lock);\r\nbreak;\r\n}\r\n}\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_do_icreate_pass2(\r\nstruct xlog *log,\r\nstruct list_head *buffer_list,\r\nxlog_recover_item_t *item)\r\n{\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_icreate_log *icl;\r\nxfs_agnumber_t agno;\r\nxfs_agblock_t agbno;\r\nunsigned int count;\r\nunsigned int isize;\r\nxfs_agblock_t length;\r\nint blks_per_cluster;\r\nint bb_per_cluster;\r\nint cancel_count;\r\nint nbufs;\r\nint i;\r\nicl = (struct xfs_icreate_log *)item->ri_buf[0].i_addr;\r\nif (icl->icl_type != XFS_LI_ICREATE) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad type");\r\nreturn -EINVAL;\r\n}\r\nif (icl->icl_size != 1) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad icl size");\r\nreturn -EINVAL;\r\n}\r\nagno = be32_to_cpu(icl->icl_ag);\r\nif (agno >= mp->m_sb.sb_agcount) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad agno");\r\nreturn -EINVAL;\r\n}\r\nagbno = be32_to_cpu(icl->icl_agbno);\r\nif (!agbno || agbno == NULLAGBLOCK || agbno >= mp->m_sb.sb_agblocks) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad agbno");\r\nreturn -EINVAL;\r\n}\r\nisize = be32_to_cpu(icl->icl_isize);\r\nif (isize != mp->m_sb.sb_inodesize) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad isize");\r\nreturn -EINVAL;\r\n}\r\ncount = be32_to_cpu(icl->icl_count);\r\nif (!count) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad count");\r\nreturn -EINVAL;\r\n}\r\nlength = be32_to_cpu(icl->icl_length);\r\nif (!length || length >= mp->m_sb.sb_agblocks) {\r\nxfs_warn(log->l_mp, "xlog_recover_do_icreate_trans: bad length");\r\nreturn -EINVAL;\r\n}\r\nif (length != mp->m_ialloc_blks &&\r\nlength != mp->m_ialloc_min_blks) {\r\nxfs_warn(log->l_mp,\r\n"%s: unsupported chunk length", __FUNCTION__);\r\nreturn -EINVAL;\r\n}\r\nif ((count >> mp->m_sb.sb_inopblog) != length) {\r\nxfs_warn(log->l_mp,\r\n"%s: inconsistent inode count and chunk length",\r\n__FUNCTION__);\r\nreturn -EINVAL;\r\n}\r\nblks_per_cluster = xfs_icluster_size_fsb(mp);\r\nbb_per_cluster = XFS_FSB_TO_BB(mp, blks_per_cluster);\r\nnbufs = length / blks_per_cluster;\r\nfor (i = 0, cancel_count = 0; i < nbufs; i++) {\r\nxfs_daddr_t daddr;\r\ndaddr = XFS_AGB_TO_DADDR(mp, agno,\r\nagbno + i * blks_per_cluster);\r\nif (xlog_check_buffer_cancelled(log, daddr, bb_per_cluster, 0))\r\ncancel_count++;\r\n}\r\nASSERT(!cancel_count || cancel_count == nbufs);\r\nif (cancel_count) {\r\nif (cancel_count != nbufs)\r\nxfs_warn(mp,\r\n"WARNING: partial inode chunk cancellation, skipped icreate.");\r\ntrace_xfs_log_recover_icreate_cancel(log, icl);\r\nreturn 0;\r\n}\r\ntrace_xfs_log_recover_icreate_recover(log, icl);\r\nreturn xfs_ialloc_inode_init(mp, NULL, buffer_list, count, agno, agbno,\r\nlength, be32_to_cpu(icl->icl_gen));\r\n}\r\nSTATIC void\r\nxlog_recover_buffer_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_buf_log_format *buf_f = item->ri_buf[0].i_addr;\r\nstruct xfs_mount *mp = log->l_mp;\r\nif (xlog_peek_buffer_cancelled(log, buf_f->blf_blkno,\r\nbuf_f->blf_len, buf_f->blf_flags)) {\r\nreturn;\r\n}\r\nxfs_buf_readahead(mp->m_ddev_targp, buf_f->blf_blkno,\r\nbuf_f->blf_len, NULL);\r\n}\r\nSTATIC void\r\nxlog_recover_inode_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_inode_log_format ilf_buf;\r\nstruct xfs_inode_log_format *ilfp;\r\nstruct xfs_mount *mp = log->l_mp;\r\nint error;\r\nif (item->ri_buf[0].i_len == sizeof(struct xfs_inode_log_format)) {\r\nilfp = item->ri_buf[0].i_addr;\r\n} else {\r\nilfp = &ilf_buf;\r\nmemset(ilfp, 0, sizeof(*ilfp));\r\nerror = xfs_inode_item_format_convert(&item->ri_buf[0], ilfp);\r\nif (error)\r\nreturn;\r\n}\r\nif (xlog_peek_buffer_cancelled(log, ilfp->ilf_blkno, ilfp->ilf_len, 0))\r\nreturn;\r\nxfs_buf_readahead(mp->m_ddev_targp, ilfp->ilf_blkno,\r\nilfp->ilf_len, &xfs_inode_buf_ra_ops);\r\n}\r\nSTATIC void\r\nxlog_recover_dquot_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nstruct xfs_mount *mp = log->l_mp;\r\nstruct xfs_disk_dquot *recddq;\r\nstruct xfs_dq_logformat *dq_f;\r\nuint type;\r\nint len;\r\nif (mp->m_qflags == 0)\r\nreturn;\r\nrecddq = item->ri_buf[1].i_addr;\r\nif (recddq == NULL)\r\nreturn;\r\nif (item->ri_buf[1].i_len < sizeof(struct xfs_disk_dquot))\r\nreturn;\r\ntype = recddq->d_flags & (XFS_DQ_USER | XFS_DQ_PROJ | XFS_DQ_GROUP);\r\nASSERT(type);\r\nif (log->l_quotaoffs_flag & type)\r\nreturn;\r\ndq_f = item->ri_buf[0].i_addr;\r\nASSERT(dq_f);\r\nASSERT(dq_f->qlf_len == 1);\r\nlen = XFS_FSB_TO_BB(mp, dq_f->qlf_len);\r\nif (xlog_peek_buffer_cancelled(log, dq_f->qlf_blkno, len, 0))\r\nreturn;\r\nxfs_buf_readahead(mp->m_ddev_targp, dq_f->qlf_blkno, len,\r\n&xfs_dquot_buf_ra_ops);\r\n}\r\nSTATIC void\r\nxlog_recover_ra_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover_item *item)\r\n{\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_BUF:\r\nxlog_recover_buffer_ra_pass2(log, item);\r\nbreak;\r\ncase XFS_LI_INODE:\r\nxlog_recover_inode_ra_pass2(log, item);\r\nbreak;\r\ncase XFS_LI_DQUOT:\r\nxlog_recover_dquot_ra_pass2(log, item);\r\nbreak;\r\ncase XFS_LI_EFI:\r\ncase XFS_LI_EFD:\r\ncase XFS_LI_QUOTAOFF:\r\ncase XFS_LI_RUI:\r\ncase XFS_LI_RUD:\r\ncase XFS_LI_CUI:\r\ncase XFS_LI_CUD:\r\ncase XFS_LI_BUI:\r\ncase XFS_LI_BUD:\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nSTATIC int\r\nxlog_recover_commit_pass1(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nstruct xlog_recover_item *item)\r\n{\r\ntrace_xfs_log_recover_item_recover(log, trans, item, XLOG_RECOVER_PASS1);\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_BUF:\r\nreturn xlog_recover_buffer_pass1(log, item);\r\ncase XFS_LI_QUOTAOFF:\r\nreturn xlog_recover_quotaoff_pass1(log, item);\r\ncase XFS_LI_INODE:\r\ncase XFS_LI_EFI:\r\ncase XFS_LI_EFD:\r\ncase XFS_LI_DQUOT:\r\ncase XFS_LI_ICREATE:\r\ncase XFS_LI_RUI:\r\ncase XFS_LI_RUD:\r\ncase XFS_LI_CUI:\r\ncase XFS_LI_CUD:\r\ncase XFS_LI_BUI:\r\ncase XFS_LI_BUD:\r\nreturn 0;\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: invalid item type (%d)",\r\n__func__, ITEM_TYPE(item));\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\n}\r\nSTATIC int\r\nxlog_recover_commit_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nstruct list_head *buffer_list,\r\nstruct xlog_recover_item *item)\r\n{\r\ntrace_xfs_log_recover_item_recover(log, trans, item, XLOG_RECOVER_PASS2);\r\nswitch (ITEM_TYPE(item)) {\r\ncase XFS_LI_BUF:\r\nreturn xlog_recover_buffer_pass2(log, buffer_list, item,\r\ntrans->r_lsn);\r\ncase XFS_LI_INODE:\r\nreturn xlog_recover_inode_pass2(log, buffer_list, item,\r\ntrans->r_lsn);\r\ncase XFS_LI_EFI:\r\nreturn xlog_recover_efi_pass2(log, item, trans->r_lsn);\r\ncase XFS_LI_EFD:\r\nreturn xlog_recover_efd_pass2(log, item);\r\ncase XFS_LI_RUI:\r\nreturn xlog_recover_rui_pass2(log, item, trans->r_lsn);\r\ncase XFS_LI_RUD:\r\nreturn xlog_recover_rud_pass2(log, item);\r\ncase XFS_LI_CUI:\r\nreturn xlog_recover_cui_pass2(log, item, trans->r_lsn);\r\ncase XFS_LI_CUD:\r\nreturn xlog_recover_cud_pass2(log, item);\r\ncase XFS_LI_BUI:\r\nreturn xlog_recover_bui_pass2(log, item, trans->r_lsn);\r\ncase XFS_LI_BUD:\r\nreturn xlog_recover_bud_pass2(log, item);\r\ncase XFS_LI_DQUOT:\r\nreturn xlog_recover_dquot_pass2(log, buffer_list, item,\r\ntrans->r_lsn);\r\ncase XFS_LI_ICREATE:\r\nreturn xlog_recover_do_icreate_pass2(log, buffer_list, item);\r\ncase XFS_LI_QUOTAOFF:\r\nreturn 0;\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: invalid item type (%d)",\r\n__func__, ITEM_TYPE(item));\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\n}\r\nSTATIC int\r\nxlog_recover_items_pass2(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nstruct list_head *buffer_list,\r\nstruct list_head *item_list)\r\n{\r\nstruct xlog_recover_item *item;\r\nint error = 0;\r\nlist_for_each_entry(item, item_list, ri_list) {\r\nerror = xlog_recover_commit_pass2(log, trans,\r\nbuffer_list, item);\r\nif (error)\r\nreturn error;\r\n}\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_commit_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nint pass,\r\nstruct list_head *buffer_list)\r\n{\r\nint error = 0;\r\nint items_queued = 0;\r\nstruct xlog_recover_item *item;\r\nstruct xlog_recover_item *next;\r\nLIST_HEAD (ra_list);\r\nLIST_HEAD (done_list);\r\n#define XLOG_RECOVER_COMMIT_QUEUE_MAX 100\r\nhlist_del(&trans->r_list);\r\nerror = xlog_recover_reorder_trans(log, trans, pass);\r\nif (error)\r\nreturn error;\r\nlist_for_each_entry_safe(item, next, &trans->r_itemq, ri_list) {\r\nswitch (pass) {\r\ncase XLOG_RECOVER_PASS1:\r\nerror = xlog_recover_commit_pass1(log, trans, item);\r\nbreak;\r\ncase XLOG_RECOVER_PASS2:\r\nxlog_recover_ra_pass2(log, item);\r\nlist_move_tail(&item->ri_list, &ra_list);\r\nitems_queued++;\r\nif (items_queued >= XLOG_RECOVER_COMMIT_QUEUE_MAX) {\r\nerror = xlog_recover_items_pass2(log, trans,\r\nbuffer_list, &ra_list);\r\nlist_splice_tail_init(&ra_list, &done_list);\r\nitems_queued = 0;\r\n}\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\n}\r\nif (error)\r\ngoto out;\r\n}\r\nout:\r\nif (!list_empty(&ra_list)) {\r\nif (!error)\r\nerror = xlog_recover_items_pass2(log, trans,\r\nbuffer_list, &ra_list);\r\nlist_splice_tail_init(&ra_list, &done_list);\r\n}\r\nif (!list_empty(&done_list))\r\nlist_splice_init(&done_list, &trans->r_itemq);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_recover_add_item(\r\nstruct list_head *head)\r\n{\r\nxlog_recover_item_t *item;\r\nitem = kmem_zalloc(sizeof(xlog_recover_item_t), KM_SLEEP);\r\nINIT_LIST_HEAD(&item->ri_list);\r\nlist_add_tail(&item->ri_list, head);\r\n}\r\nSTATIC int\r\nxlog_recover_add_to_cont_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nchar *dp,\r\nint len)\r\n{\r\nxlog_recover_item_t *item;\r\nchar *ptr, *old_ptr;\r\nint old_len;\r\nif (list_empty(&trans->r_itemq)) {\r\nASSERT(len <= sizeof(struct xfs_trans_header));\r\nif (len > sizeof(struct xfs_trans_header)) {\r\nxfs_warn(log->l_mp, "%s: bad header length", __func__);\r\nreturn -EIO;\r\n}\r\nxlog_recover_add_item(&trans->r_itemq);\r\nptr = (char *)&trans->r_theader +\r\nsizeof(struct xfs_trans_header) - len;\r\nmemcpy(ptr, dp, len);\r\nreturn 0;\r\n}\r\nitem = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);\r\nold_ptr = item->ri_buf[item->ri_cnt-1].i_addr;\r\nold_len = item->ri_buf[item->ri_cnt-1].i_len;\r\nptr = kmem_realloc(old_ptr, len + old_len, KM_SLEEP);\r\nmemcpy(&ptr[old_len], dp, len);\r\nitem->ri_buf[item->ri_cnt-1].i_len += len;\r\nitem->ri_buf[item->ri_cnt-1].i_addr = ptr;\r\ntrace_xfs_log_recover_item_add_cont(log, trans, item, 0);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_add_to_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nchar *dp,\r\nint len)\r\n{\r\nxfs_inode_log_format_t *in_f;\r\nxlog_recover_item_t *item;\r\nchar *ptr;\r\nif (!len)\r\nreturn 0;\r\nif (list_empty(&trans->r_itemq)) {\r\nif (*(uint *)dp != XFS_TRANS_HEADER_MAGIC) {\r\nxfs_warn(log->l_mp, "%s: bad header magic number",\r\n__func__);\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\nif (len > sizeof(struct xfs_trans_header)) {\r\nxfs_warn(log->l_mp, "%s: bad header length", __func__);\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\nif (len == sizeof(struct xfs_trans_header))\r\nxlog_recover_add_item(&trans->r_itemq);\r\nmemcpy(&trans->r_theader, dp, len);\r\nreturn 0;\r\n}\r\nptr = kmem_alloc(len, KM_SLEEP);\r\nmemcpy(ptr, dp, len);\r\nin_f = (xfs_inode_log_format_t *)ptr;\r\nitem = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);\r\nif (item->ri_total != 0 &&\r\nitem->ri_total == item->ri_cnt) {\r\nxlog_recover_add_item(&trans->r_itemq);\r\nitem = list_entry(trans->r_itemq.prev,\r\nxlog_recover_item_t, ri_list);\r\n}\r\nif (item->ri_total == 0) {\r\nif (in_f->ilf_size == 0 ||\r\nin_f->ilf_size > XLOG_MAX_REGIONS_IN_ITEM) {\r\nxfs_warn(log->l_mp,\r\n"bad number of regions (%d) in inode log format",\r\nin_f->ilf_size);\r\nASSERT(0);\r\nkmem_free(ptr);\r\nreturn -EIO;\r\n}\r\nitem->ri_total = in_f->ilf_size;\r\nitem->ri_buf =\r\nkmem_zalloc(item->ri_total * sizeof(xfs_log_iovec_t),\r\nKM_SLEEP);\r\n}\r\nASSERT(item->ri_total > item->ri_cnt);\r\nitem->ri_buf[item->ri_cnt].i_addr = ptr;\r\nitem->ri_buf[item->ri_cnt].i_len = len;\r\nitem->ri_cnt++;\r\ntrace_xfs_log_recover_item_add(log, trans, item, 0);\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxlog_recover_free_trans(\r\nstruct xlog_recover *trans)\r\n{\r\nxlog_recover_item_t *item, *n;\r\nint i;\r\nlist_for_each_entry_safe(item, n, &trans->r_itemq, ri_list) {\r\nlist_del(&item->ri_list);\r\nfor (i = 0; i < item->ri_cnt; i++)\r\nkmem_free(item->ri_buf[i].i_addr);\r\nkmem_free(item->ri_buf);\r\nkmem_free(item);\r\n}\r\nkmem_free(trans);\r\n}\r\nSTATIC int\r\nxlog_recovery_process_trans(\r\nstruct xlog *log,\r\nstruct xlog_recover *trans,\r\nchar *dp,\r\nunsigned int len,\r\nunsigned int flags,\r\nint pass,\r\nstruct list_head *buffer_list)\r\n{\r\nint error = 0;\r\nbool freeit = false;\r\nflags &= ~XLOG_END_TRANS;\r\nif (flags & XLOG_WAS_CONT_TRANS)\r\nflags &= ~XLOG_CONTINUE_TRANS;\r\nswitch (flags) {\r\ncase 0:\r\ncase XLOG_CONTINUE_TRANS:\r\nerror = xlog_recover_add_to_trans(log, trans, dp, len);\r\nbreak;\r\ncase XLOG_WAS_CONT_TRANS:\r\nerror = xlog_recover_add_to_cont_trans(log, trans, dp, len);\r\nbreak;\r\ncase XLOG_COMMIT_TRANS:\r\nerror = xlog_recover_commit_trans(log, trans, pass,\r\nbuffer_list);\r\nfreeit = true;\r\nbreak;\r\ncase XLOG_UNMOUNT_TRANS:\r\nxfs_warn(log->l_mp, "%s: Unmount LR", __func__);\r\nfreeit = true;\r\nbreak;\r\ncase XLOG_START_TRANS:\r\ndefault:\r\nxfs_warn(log->l_mp, "%s: bad flag 0x%x", __func__, flags);\r\nASSERT(0);\r\nerror = -EIO;\r\nbreak;\r\n}\r\nif (error || freeit)\r\nxlog_recover_free_trans(trans);\r\nreturn error;\r\n}\r\nSTATIC struct xlog_recover *\r\nxlog_recover_ophdr_to_trans(\r\nstruct hlist_head rhash[],\r\nstruct xlog_rec_header *rhead,\r\nstruct xlog_op_header *ohead)\r\n{\r\nstruct xlog_recover *trans;\r\nxlog_tid_t tid;\r\nstruct hlist_head *rhp;\r\ntid = be32_to_cpu(ohead->oh_tid);\r\nrhp = &rhash[XLOG_RHASH(tid)];\r\nhlist_for_each_entry(trans, rhp, r_list) {\r\nif (trans->r_log_tid == tid)\r\nreturn trans;\r\n}\r\nif (!(ohead->oh_flags & XLOG_START_TRANS))\r\nreturn NULL;\r\nASSERT(be32_to_cpu(ohead->oh_len) == 0);\r\ntrans = kmem_zalloc(sizeof(struct xlog_recover), KM_SLEEP);\r\ntrans->r_log_tid = tid;\r\ntrans->r_lsn = be64_to_cpu(rhead->h_lsn);\r\nINIT_LIST_HEAD(&trans->r_itemq);\r\nINIT_HLIST_NODE(&trans->r_list);\r\nhlist_add_head(&trans->r_list, rhp);\r\nreturn NULL;\r\n}\r\nSTATIC int\r\nxlog_recover_process_ophdr(\r\nstruct xlog *log,\r\nstruct hlist_head rhash[],\r\nstruct xlog_rec_header *rhead,\r\nstruct xlog_op_header *ohead,\r\nchar *dp,\r\nchar *end,\r\nint pass,\r\nstruct list_head *buffer_list)\r\n{\r\nstruct xlog_recover *trans;\r\nunsigned int len;\r\nint error;\r\nif (ohead->oh_clientid != XFS_TRANSACTION &&\r\nohead->oh_clientid != XFS_LOG) {\r\nxfs_warn(log->l_mp, "%s: bad clientid 0x%x",\r\n__func__, ohead->oh_clientid);\r\nASSERT(0);\r\nreturn -EIO;\r\n}\r\nlen = be32_to_cpu(ohead->oh_len);\r\nif (dp + len > end) {\r\nxfs_warn(log->l_mp, "%s: bad length 0x%x", __func__, len);\r\nWARN_ON(1);\r\nreturn -EIO;\r\n}\r\ntrans = xlog_recover_ophdr_to_trans(rhash, rhead, ohead);\r\nif (!trans) {\r\nreturn 0;\r\n}\r\nif (log->l_recovery_lsn != trans->r_lsn &&\r\nohead->oh_flags & XLOG_COMMIT_TRANS) {\r\nerror = xfs_buf_delwri_submit(buffer_list);\r\nif (error)\r\nreturn error;\r\nlog->l_recovery_lsn = trans->r_lsn;\r\n}\r\nreturn xlog_recovery_process_trans(log, trans, dp, len,\r\nohead->oh_flags, pass, buffer_list);\r\n}\r\nSTATIC int\r\nxlog_recover_process_data(\r\nstruct xlog *log,\r\nstruct hlist_head rhash[],\r\nstruct xlog_rec_header *rhead,\r\nchar *dp,\r\nint pass,\r\nstruct list_head *buffer_list)\r\n{\r\nstruct xlog_op_header *ohead;\r\nchar *end;\r\nint num_logops;\r\nint error;\r\nend = dp + be32_to_cpu(rhead->h_len);\r\nnum_logops = be32_to_cpu(rhead->h_num_logops);\r\nif (xlog_header_check_recover(log->l_mp, rhead))\r\nreturn -EIO;\r\ntrace_xfs_log_recover_record(log, rhead, pass);\r\nwhile ((dp < end) && num_logops) {\r\nohead = (struct xlog_op_header *)dp;\r\ndp += sizeof(*ohead);\r\nASSERT(dp <= end);\r\nerror = xlog_recover_process_ophdr(log, rhash, rhead, ohead,\r\ndp, end, pass, buffer_list);\r\nif (error)\r\nreturn error;\r\ndp += be32_to_cpu(ohead->oh_len);\r\nnum_logops--;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_process_efi(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_efi_log_item *efip;\r\nint error;\r\nefip = container_of(lip, struct xfs_efi_log_item, efi_item);\r\nif (test_bit(XFS_EFI_RECOVERED, &efip->efi_flags))\r\nreturn 0;\r\nspin_unlock(&ailp->xa_lock);\r\nerror = xfs_efi_recover(mp, efip);\r\nspin_lock(&ailp->xa_lock);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_recover_cancel_efi(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_efi_log_item *efip;\r\nefip = container_of(lip, struct xfs_efi_log_item, efi_item);\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_efi_release(efip);\r\nspin_lock(&ailp->xa_lock);\r\n}\r\nSTATIC int\r\nxlog_recover_process_rui(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_rui_log_item *ruip;\r\nint error;\r\nruip = container_of(lip, struct xfs_rui_log_item, rui_item);\r\nif (test_bit(XFS_RUI_RECOVERED, &ruip->rui_flags))\r\nreturn 0;\r\nspin_unlock(&ailp->xa_lock);\r\nerror = xfs_rui_recover(mp, ruip);\r\nspin_lock(&ailp->xa_lock);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_recover_cancel_rui(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_rui_log_item *ruip;\r\nruip = container_of(lip, struct xfs_rui_log_item, rui_item);\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_rui_release(ruip);\r\nspin_lock(&ailp->xa_lock);\r\n}\r\nSTATIC int\r\nxlog_recover_process_cui(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_cui_log_item *cuip;\r\nint error;\r\ncuip = container_of(lip, struct xfs_cui_log_item, cui_item);\r\nif (test_bit(XFS_CUI_RECOVERED, &cuip->cui_flags))\r\nreturn 0;\r\nspin_unlock(&ailp->xa_lock);\r\nerror = xfs_cui_recover(mp, cuip);\r\nspin_lock(&ailp->xa_lock);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_recover_cancel_cui(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_cui_log_item *cuip;\r\ncuip = container_of(lip, struct xfs_cui_log_item, cui_item);\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_cui_release(cuip);\r\nspin_lock(&ailp->xa_lock);\r\n}\r\nSTATIC int\r\nxlog_recover_process_bui(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_bui_log_item *buip;\r\nint error;\r\nbuip = container_of(lip, struct xfs_bui_log_item, bui_item);\r\nif (test_bit(XFS_BUI_RECOVERED, &buip->bui_flags))\r\nreturn 0;\r\nspin_unlock(&ailp->xa_lock);\r\nerror = xfs_bui_recover(mp, buip);\r\nspin_lock(&ailp->xa_lock);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_recover_cancel_bui(\r\nstruct xfs_mount *mp,\r\nstruct xfs_ail *ailp,\r\nstruct xfs_log_item *lip)\r\n{\r\nstruct xfs_bui_log_item *buip;\r\nbuip = container_of(lip, struct xfs_bui_log_item, bui_item);\r\nspin_unlock(&ailp->xa_lock);\r\nxfs_bui_release(buip);\r\nspin_lock(&ailp->xa_lock);\r\n}\r\nstatic inline bool xlog_item_is_intent(struct xfs_log_item *lip)\r\n{\r\nswitch (lip->li_type) {\r\ncase XFS_LI_EFI:\r\ncase XFS_LI_RUI:\r\ncase XFS_LI_CUI:\r\ncase XFS_LI_BUI:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nSTATIC int\r\nxlog_recover_process_intents(\r\nstruct xlog *log)\r\n{\r\nstruct xfs_log_item *lip;\r\nint error = 0;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp;\r\nxfs_lsn_t last_lsn;\r\nailp = log->l_ailp;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nlast_lsn = xlog_assign_lsn(log->l_curr_cycle, log->l_curr_block);\r\nwhile (lip != NULL) {\r\nif (!xlog_item_is_intent(lip)) {\r\n#ifdef DEBUG\r\nfor (; lip; lip = xfs_trans_ail_cursor_next(ailp, &cur))\r\nASSERT(!xlog_item_is_intent(lip));\r\n#endif\r\nbreak;\r\n}\r\nASSERT(XFS_LSN_CMP(last_lsn, lip->li_lsn) >= 0);\r\nswitch (lip->li_type) {\r\ncase XFS_LI_EFI:\r\nerror = xlog_recover_process_efi(log->l_mp, ailp, lip);\r\nbreak;\r\ncase XFS_LI_RUI:\r\nerror = xlog_recover_process_rui(log->l_mp, ailp, lip);\r\nbreak;\r\ncase XFS_LI_CUI:\r\nerror = xlog_recover_process_cui(log->l_mp, ailp, lip);\r\nbreak;\r\ncase XFS_LI_BUI:\r\nerror = xlog_recover_process_bui(log->l_mp, ailp, lip);\r\nbreak;\r\n}\r\nif (error)\r\ngoto out;\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nout:\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_recover_cancel_intents(\r\nstruct xlog *log)\r\n{\r\nstruct xfs_log_item *lip;\r\nint error = 0;\r\nstruct xfs_ail_cursor cur;\r\nstruct xfs_ail *ailp;\r\nailp = log->l_ailp;\r\nspin_lock(&ailp->xa_lock);\r\nlip = xfs_trans_ail_cursor_first(ailp, &cur, 0);\r\nwhile (lip != NULL) {\r\nif (!xlog_item_is_intent(lip)) {\r\n#ifdef DEBUG\r\nfor (; lip; lip = xfs_trans_ail_cursor_next(ailp, &cur))\r\nASSERT(!xlog_item_is_intent(lip));\r\n#endif\r\nbreak;\r\n}\r\nswitch (lip->li_type) {\r\ncase XFS_LI_EFI:\r\nxlog_recover_cancel_efi(log->l_mp, ailp, lip);\r\nbreak;\r\ncase XFS_LI_RUI:\r\nxlog_recover_cancel_rui(log->l_mp, ailp, lip);\r\nbreak;\r\ncase XFS_LI_CUI:\r\nxlog_recover_cancel_cui(log->l_mp, ailp, lip);\r\nbreak;\r\ncase XFS_LI_BUI:\r\nxlog_recover_cancel_bui(log->l_mp, ailp, lip);\r\nbreak;\r\n}\r\nlip = xfs_trans_ail_cursor_next(ailp, &cur);\r\n}\r\nxfs_trans_ail_cursor_done(&cur);\r\nspin_unlock(&ailp->xa_lock);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxlog_recover_clear_agi_bucket(\r\nxfs_mount_t *mp,\r\nxfs_agnumber_t agno,\r\nint bucket)\r\n{\r\nxfs_trans_t *tp;\r\nxfs_agi_t *agi;\r\nxfs_buf_t *agibp;\r\nint offset;\r\nint error;\r\nerror = xfs_trans_alloc(mp, &M_RES(mp)->tr_clearagi, 0, 0, 0, &tp);\r\nif (error)\r\ngoto out_error;\r\nerror = xfs_read_agi(mp, tp, agno, &agibp);\r\nif (error)\r\ngoto out_abort;\r\nagi = XFS_BUF_TO_AGI(agibp);\r\nagi->agi_unlinked[bucket] = cpu_to_be32(NULLAGINO);\r\noffset = offsetof(xfs_agi_t, agi_unlinked) +\r\n(sizeof(xfs_agino_t) * bucket);\r\nxfs_trans_log_buf(tp, agibp, offset,\r\n(offset + sizeof(xfs_agino_t) - 1));\r\nerror = xfs_trans_commit(tp);\r\nif (error)\r\ngoto out_error;\r\nreturn;\r\nout_abort:\r\nxfs_trans_cancel(tp);\r\nout_error:\r\nxfs_warn(mp, "%s: failed to clear agi %d. Continuing.", __func__, agno);\r\nreturn;\r\n}\r\nSTATIC xfs_agino_t\r\nxlog_recover_process_one_iunlink(\r\nstruct xfs_mount *mp,\r\nxfs_agnumber_t agno,\r\nxfs_agino_t agino,\r\nint bucket)\r\n{\r\nstruct xfs_buf *ibp;\r\nstruct xfs_dinode *dip;\r\nstruct xfs_inode *ip;\r\nxfs_ino_t ino;\r\nint error;\r\nino = XFS_AGINO_TO_INO(mp, agno, agino);\r\nerror = xfs_iget(mp, NULL, ino, 0, 0, &ip);\r\nif (error)\r\ngoto fail;\r\nerror = xfs_imap_to_bp(mp, NULL, &ip->i_imap, &dip, &ibp, 0, 0);\r\nif (error)\r\ngoto fail_iput;\r\nxfs_iflags_clear(ip, XFS_IRECOVERY);\r\nASSERT(VFS_I(ip)->i_nlink == 0);\r\nASSERT(VFS_I(ip)->i_mode != 0);\r\nagino = be32_to_cpu(dip->di_next_unlinked);\r\nxfs_buf_relse(ibp);\r\nip->i_d.di_dmevmask = 0;\r\nIRELE(ip);\r\nreturn agino;\r\nfail_iput:\r\nIRELE(ip);\r\nfail:\r\nxlog_recover_clear_agi_bucket(mp, agno, bucket);\r\nreturn NULLAGINO;\r\n}\r\nSTATIC void\r\nxlog_recover_process_iunlinks(\r\nstruct xlog *log)\r\n{\r\nxfs_mount_t *mp;\r\nxfs_agnumber_t agno;\r\nxfs_agi_t *agi;\r\nxfs_buf_t *agibp;\r\nxfs_agino_t agino;\r\nint bucket;\r\nint error;\r\nuint mp_dmevmask;\r\nmp = log->l_mp;\r\nmp_dmevmask = mp->m_dmevmask;\r\nmp->m_dmevmask = 0;\r\nfor (agno = 0; agno < mp->m_sb.sb_agcount; agno++) {\r\nerror = xfs_read_agi(mp, NULL, agno, &agibp);\r\nif (error) {\r\ncontinue;\r\n}\r\nagi = XFS_BUF_TO_AGI(agibp);\r\nxfs_buf_unlock(agibp);\r\nfor (bucket = 0; bucket < XFS_AGI_UNLINKED_BUCKETS; bucket++) {\r\nagino = be32_to_cpu(agi->agi_unlinked[bucket]);\r\nwhile (agino != NULLAGINO) {\r\nagino = xlog_recover_process_one_iunlink(mp,\r\nagno, agino, bucket);\r\n}\r\n}\r\nxfs_buf_rele(agibp);\r\n}\r\nmp->m_dmevmask = mp_dmevmask;\r\n}\r\nSTATIC int\r\nxlog_unpack_data(\r\nstruct xlog_rec_header *rhead,\r\nchar *dp,\r\nstruct xlog *log)\r\n{\r\nint i, j, k;\r\nfor (i = 0; i < BTOBB(be32_to_cpu(rhead->h_len)) &&\r\ni < (XLOG_HEADER_CYCLE_SIZE / BBSIZE); i++) {\r\n*(__be32 *)dp = *(__be32 *)&rhead->h_cycle_data[i];\r\ndp += BBSIZE;\r\n}\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nxlog_in_core_2_t *xhdr = (xlog_in_core_2_t *)rhead;\r\nfor ( ; i < BTOBB(be32_to_cpu(rhead->h_len)); i++) {\r\nj = i / (XLOG_HEADER_CYCLE_SIZE / BBSIZE);\r\nk = i % (XLOG_HEADER_CYCLE_SIZE / BBSIZE);\r\n*(__be32 *)dp = xhdr[j].hic_xheader.xh_cycle_data[k];\r\ndp += BBSIZE;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_recover_process(\r\nstruct xlog *log,\r\nstruct hlist_head rhash[],\r\nstruct xlog_rec_header *rhead,\r\nchar *dp,\r\nint pass,\r\nstruct list_head *buffer_list)\r\n{\r\nint error;\r\n__le32 old_crc = rhead->h_crc;\r\n__le32 crc;\r\ncrc = xlog_cksum(log, rhead, dp, be32_to_cpu(rhead->h_len));\r\nif (pass == XLOG_RECOVER_CRCPASS) {\r\nif (old_crc && crc != old_crc)\r\nreturn -EFSBADCRC;\r\nreturn 0;\r\n}\r\nif (crc != old_crc) {\r\nif (old_crc || xfs_sb_version_hascrc(&log->l_mp->m_sb)) {\r\nxfs_alert(log->l_mp,\r\n"log record CRC mismatch: found 0x%x, expected 0x%x.",\r\nle32_to_cpu(old_crc),\r\nle32_to_cpu(crc));\r\nxfs_hex_dump(dp, 32);\r\n}\r\nif (xfs_sb_version_hascrc(&log->l_mp->m_sb))\r\nreturn -EFSCORRUPTED;\r\n}\r\nerror = xlog_unpack_data(rhead, dp, log);\r\nif (error)\r\nreturn error;\r\nreturn xlog_recover_process_data(log, rhash, rhead, dp, pass,\r\nbuffer_list);\r\n}\r\nSTATIC int\r\nxlog_valid_rec_header(\r\nstruct xlog *log,\r\nstruct xlog_rec_header *rhead,\r\nxfs_daddr_t blkno)\r\n{\r\nint hlen;\r\nif (unlikely(rhead->h_magicno != cpu_to_be32(XLOG_HEADER_MAGIC_NUM))) {\r\nXFS_ERROR_REPORT("xlog_valid_rec_header(1)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nif (unlikely(\r\n(!rhead->h_version ||\r\n(be32_to_cpu(rhead->h_version) & (~XLOG_VERSION_OKBITS))))) {\r\nxfs_warn(log->l_mp, "%s: unrecognised log version (%d).",\r\n__func__, be32_to_cpu(rhead->h_version));\r\nreturn -EIO;\r\n}\r\nhlen = be32_to_cpu(rhead->h_len);\r\nif (unlikely( hlen <= 0 || hlen > INT_MAX )) {\r\nXFS_ERROR_REPORT("xlog_valid_rec_header(2)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nif (unlikely( blkno > log->l_logBBsize || blkno > INT_MAX )) {\r\nXFS_ERROR_REPORT("xlog_valid_rec_header(3)",\r\nXFS_ERRLEVEL_LOW, log->l_mp);\r\nreturn -EFSCORRUPTED;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxlog_do_recovery_pass(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk,\r\nint pass,\r\nxfs_daddr_t *first_bad)\r\n{\r\nxlog_rec_header_t *rhead;\r\nxfs_daddr_t blk_no;\r\nxfs_daddr_t rhead_blk;\r\nchar *offset;\r\nxfs_buf_t *hbp, *dbp;\r\nint error = 0, h_size, h_len;\r\nint error2 = 0;\r\nint bblks, split_bblks;\r\nint hblks, split_hblks, wrapped_hblks;\r\nstruct hlist_head rhash[XLOG_RHASH_SIZE];\r\nLIST_HEAD (buffer_list);\r\nASSERT(head_blk != tail_blk);\r\nrhead_blk = 0;\r\nif (xfs_sb_version_haslogv2(&log->l_mp->m_sb)) {\r\nhbp = xlog_get_bp(log, 1);\r\nif (!hbp)\r\nreturn -ENOMEM;\r\nerror = xlog_bread(log, tail_blk, 1, hbp, &offset);\r\nif (error)\r\ngoto bread_err1;\r\nrhead = (xlog_rec_header_t *)offset;\r\nerror = xlog_valid_rec_header(log, rhead, tail_blk);\r\nif (error)\r\ngoto bread_err1;\r\nh_size = be32_to_cpu(rhead->h_size);\r\nh_len = be32_to_cpu(rhead->h_len);\r\nif (h_len > h_size) {\r\nif (h_len <= log->l_mp->m_logbsize &&\r\nbe32_to_cpu(rhead->h_num_logops) == 1) {\r\nxfs_warn(log->l_mp,\r\n"invalid iclog size (%d bytes), using lsunit (%d bytes)",\r\nh_size, log->l_mp->m_logbsize);\r\nh_size = log->l_mp->m_logbsize;\r\n} else\r\nreturn -EFSCORRUPTED;\r\n}\r\nif ((be32_to_cpu(rhead->h_version) & XLOG_VERSION_2) &&\r\n(h_size > XLOG_HEADER_CYCLE_SIZE)) {\r\nhblks = h_size / XLOG_HEADER_CYCLE_SIZE;\r\nif (h_size % XLOG_HEADER_CYCLE_SIZE)\r\nhblks++;\r\nxlog_put_bp(hbp);\r\nhbp = xlog_get_bp(log, hblks);\r\n} else {\r\nhblks = 1;\r\n}\r\n} else {\r\nASSERT(log->l_sectBBsize == 1);\r\nhblks = 1;\r\nhbp = xlog_get_bp(log, 1);\r\nh_size = XLOG_BIG_RECORD_BSIZE;\r\n}\r\nif (!hbp)\r\nreturn -ENOMEM;\r\ndbp = xlog_get_bp(log, BTOBB(h_size));\r\nif (!dbp) {\r\nxlog_put_bp(hbp);\r\nreturn -ENOMEM;\r\n}\r\nmemset(rhash, 0, sizeof(rhash));\r\nblk_no = rhead_blk = tail_blk;\r\nif (tail_blk > head_blk) {\r\nwhile (blk_no < log->l_logBBsize) {\r\noffset = hbp->b_addr;\r\nsplit_hblks = 0;\r\nwrapped_hblks = 0;\r\nif (blk_no + hblks <= log->l_logBBsize) {\r\nerror = xlog_bread(log, blk_no, hblks, hbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n} else {\r\nif (blk_no != log->l_logBBsize) {\r\nASSERT(blk_no <= INT_MAX);\r\nsplit_hblks = log->l_logBBsize - (int)blk_no;\r\nASSERT(split_hblks > 0);\r\nerror = xlog_bread(log, blk_no,\r\nsplit_hblks, hbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nwrapped_hblks = hblks - split_hblks;\r\nerror = xlog_bread_offset(log, 0,\r\nwrapped_hblks, hbp,\r\noffset + BBTOB(split_hblks));\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nrhead = (xlog_rec_header_t *)offset;\r\nerror = xlog_valid_rec_header(log, rhead,\r\nsplit_hblks ? blk_no : 0);\r\nif (error)\r\ngoto bread_err2;\r\nbblks = (int)BTOBB(be32_to_cpu(rhead->h_len));\r\nblk_no += hblks;\r\nif (blk_no + bblks <= log->l_logBBsize) {\r\nerror = xlog_bread(log, blk_no, bblks, dbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n} else {\r\noffset = dbp->b_addr;\r\nsplit_bblks = 0;\r\nif (blk_no != log->l_logBBsize) {\r\nASSERT(!wrapped_hblks);\r\nASSERT(blk_no <= INT_MAX);\r\nsplit_bblks =\r\nlog->l_logBBsize - (int)blk_no;\r\nASSERT(split_bblks > 0);\r\nerror = xlog_bread(log, blk_no,\r\nsplit_bblks, dbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nerror = xlog_bread_offset(log, 0,\r\nbblks - split_bblks, dbp,\r\noffset + BBTOB(split_bblks));\r\nif (error)\r\ngoto bread_err2;\r\n}\r\nerror = xlog_recover_process(log, rhash, rhead, offset,\r\npass, &buffer_list);\r\nif (error)\r\ngoto bread_err2;\r\nblk_no += bblks;\r\nrhead_blk = blk_no;\r\n}\r\nASSERT(blk_no >= log->l_logBBsize);\r\nblk_no -= log->l_logBBsize;\r\nrhead_blk = blk_no;\r\n}\r\nwhile (blk_no < head_blk) {\r\nerror = xlog_bread(log, blk_no, hblks, hbp, &offset);\r\nif (error)\r\ngoto bread_err2;\r\nrhead = (xlog_rec_header_t *)offset;\r\nerror = xlog_valid_rec_header(log, rhead, blk_no);\r\nif (error)\r\ngoto bread_err2;\r\nbblks = (int)BTOBB(be32_to_cpu(rhead->h_len));\r\nerror = xlog_bread(log, blk_no+hblks, bblks, dbp,\r\n&offset);\r\nif (error)\r\ngoto bread_err2;\r\nerror = xlog_recover_process(log, rhash, rhead, offset, pass,\r\n&buffer_list);\r\nif (error)\r\ngoto bread_err2;\r\nblk_no += bblks + hblks;\r\nrhead_blk = blk_no;\r\n}\r\nbread_err2:\r\nxlog_put_bp(dbp);\r\nbread_err1:\r\nxlog_put_bp(hbp);\r\nif (!list_empty(&buffer_list))\r\nerror2 = xfs_buf_delwri_submit(&buffer_list);\r\nif (error && first_bad)\r\n*first_bad = rhead_blk;\r\nreturn error ? error : error2;\r\n}\r\nSTATIC int\r\nxlog_do_log_recovery(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk)\r\n{\r\nint error, i;\r\nASSERT(head_blk != tail_blk);\r\nlog->l_buf_cancel_table = kmem_zalloc(XLOG_BC_TABLE_SIZE *\r\nsizeof(struct list_head),\r\nKM_SLEEP);\r\nfor (i = 0; i < XLOG_BC_TABLE_SIZE; i++)\r\nINIT_LIST_HEAD(&log->l_buf_cancel_table[i]);\r\nerror = xlog_do_recovery_pass(log, head_blk, tail_blk,\r\nXLOG_RECOVER_PASS1, NULL);\r\nif (error != 0) {\r\nkmem_free(log->l_buf_cancel_table);\r\nlog->l_buf_cancel_table = NULL;\r\nreturn error;\r\n}\r\nerror = xlog_do_recovery_pass(log, head_blk, tail_blk,\r\nXLOG_RECOVER_PASS2, NULL);\r\n#ifdef DEBUG\r\nif (!error) {\r\nint i;\r\nfor (i = 0; i < XLOG_BC_TABLE_SIZE; i++)\r\nASSERT(list_empty(&log->l_buf_cancel_table[i]));\r\n}\r\n#endif\r\nkmem_free(log->l_buf_cancel_table);\r\nlog->l_buf_cancel_table = NULL;\r\nreturn error;\r\n}\r\nSTATIC int\r\nxlog_do_recover(\r\nstruct xlog *log,\r\nxfs_daddr_t head_blk,\r\nxfs_daddr_t tail_blk)\r\n{\r\nstruct xfs_mount *mp = log->l_mp;\r\nint error;\r\nxfs_buf_t *bp;\r\nxfs_sb_t *sbp;\r\nerror = xlog_do_log_recovery(log, head_blk, tail_blk);\r\nif (error)\r\nreturn error;\r\nif (XFS_FORCED_SHUTDOWN(mp)) {\r\nreturn -EIO;\r\n}\r\nxlog_assign_tail_lsn(mp);\r\nbp = xfs_getsb(mp, 0);\r\nbp->b_flags &= ~(XBF_DONE | XBF_ASYNC);\r\nASSERT(!(bp->b_flags & XBF_WRITE));\r\nbp->b_flags |= XBF_READ;\r\nbp->b_ops = &xfs_sb_buf_ops;\r\nerror = xfs_buf_submit_wait(bp);\r\nif (error) {\r\nif (!XFS_FORCED_SHUTDOWN(mp)) {\r\nxfs_buf_ioerror_alert(bp, __func__);\r\nASSERT(0);\r\n}\r\nxfs_buf_relse(bp);\r\nreturn error;\r\n}\r\nsbp = &mp->m_sb;\r\nxfs_sb_from_disk(sbp, XFS_BUF_TO_SBP(bp));\r\nxfs_buf_relse(bp);\r\nxfs_reinit_percpu_counters(mp);\r\nerror = xfs_initialize_perag(mp, sbp->sb_agcount, &mp->m_maxagi);\r\nif (error) {\r\nxfs_warn(mp, "Failed post-recovery per-ag init: %d", error);\r\nreturn error;\r\n}\r\nmp->m_alloc_set_aside = xfs_alloc_set_aside(mp);\r\nxlog_recover_check_summary(log);\r\nlog->l_flags &= ~XLOG_ACTIVE_RECOVERY;\r\nreturn 0;\r\n}\r\nint\r\nxlog_recover(\r\nstruct xlog *log)\r\n{\r\nxfs_daddr_t head_blk, tail_blk;\r\nint error;\r\nerror = xlog_find_tail(log, &head_blk, &tail_blk);\r\nif (error)\r\nreturn error;\r\nif (xfs_sb_version_hascrc(&log->l_mp->m_sb) &&\r\n!xfs_log_check_lsn(log->l_mp, log->l_mp->m_sb.sb_lsn))\r\nreturn -EINVAL;\r\nif (tail_blk != head_blk) {\r\nif ((error = xfs_dev_is_read_only(log->l_mp, "recovery"))) {\r\nreturn error;\r\n}\r\nif (XFS_SB_VERSION_NUM(&log->l_mp->m_sb) == XFS_SB_VERSION_5 &&\r\nxfs_sb_has_incompat_log_feature(&log->l_mp->m_sb,\r\nXFS_SB_FEAT_INCOMPAT_LOG_UNKNOWN)) {\r\nxfs_warn(log->l_mp,\r\n"Superblock has unknown incompatible log features (0x%x) enabled.",\r\n(log->l_mp->m_sb.sb_features_log_incompat &\r\nXFS_SB_FEAT_INCOMPAT_LOG_UNKNOWN));\r\nxfs_warn(log->l_mp,\r\n"The log can not be fully and/or safely recovered by this kernel.");\r\nxfs_warn(log->l_mp,\r\n"Please recover the log on a kernel that supports the unknown features.");\r\nreturn -EINVAL;\r\n}\r\nif (xfs_globals.log_recovery_delay) {\r\nxfs_notice(log->l_mp,\r\n"Delaying log recovery for %d seconds.",\r\nxfs_globals.log_recovery_delay);\r\nmsleep(xfs_globals.log_recovery_delay * 1000);\r\n}\r\nxfs_notice(log->l_mp, "Starting recovery (logdev: %s)",\r\nlog->l_mp->m_logname ? log->l_mp->m_logname\r\n: "internal");\r\nerror = xlog_do_recover(log, head_blk, tail_blk);\r\nlog->l_flags |= XLOG_RECOVERY_NEEDED;\r\n}\r\nreturn error;\r\n}\r\nint\r\nxlog_recover_finish(\r\nstruct xlog *log)\r\n{\r\nif (log->l_flags & XLOG_RECOVERY_NEEDED) {\r\nint error;\r\nerror = xlog_recover_process_intents(log);\r\nif (error) {\r\nxfs_alert(log->l_mp, "Failed to recover intents");\r\nreturn error;\r\n}\r\nxfs_log_force(log->l_mp, XFS_LOG_SYNC);\r\nxlog_recover_process_iunlinks(log);\r\nxlog_recover_check_summary(log);\r\nxfs_notice(log->l_mp, "Ending recovery (logdev: %s)",\r\nlog->l_mp->m_logname ? log->l_mp->m_logname\r\n: "internal");\r\nlog->l_flags &= ~XLOG_RECOVERY_NEEDED;\r\n} else {\r\nxfs_info(log->l_mp, "Ending clean mount");\r\n}\r\nreturn 0;\r\n}\r\nint\r\nxlog_recover_cancel(\r\nstruct xlog *log)\r\n{\r\nint error = 0;\r\nif (log->l_flags & XLOG_RECOVERY_NEEDED)\r\nerror = xlog_recover_cancel_intents(log);\r\nreturn error;\r\n}\r\nvoid\r\nxlog_recover_check_summary(\r\nstruct xlog *log)\r\n{\r\nxfs_mount_t *mp;\r\nxfs_agf_t *agfp;\r\nxfs_buf_t *agfbp;\r\nxfs_buf_t *agibp;\r\nxfs_agnumber_t agno;\r\n__uint64_t freeblks;\r\n__uint64_t itotal;\r\n__uint64_t ifree;\r\nint error;\r\nmp = log->l_mp;\r\nfreeblks = 0LL;\r\nitotal = 0LL;\r\nifree = 0LL;\r\nfor (agno = 0; agno < mp->m_sb.sb_agcount; agno++) {\r\nerror = xfs_read_agf(mp, NULL, agno, 0, &agfbp);\r\nif (error) {\r\nxfs_alert(mp, "%s agf read failed agno %d error %d",\r\n__func__, agno, error);\r\n} else {\r\nagfp = XFS_BUF_TO_AGF(agfbp);\r\nfreeblks += be32_to_cpu(agfp->agf_freeblks) +\r\nbe32_to_cpu(agfp->agf_flcount);\r\nxfs_buf_relse(agfbp);\r\n}\r\nerror = xfs_read_agi(mp, NULL, agno, &agibp);\r\nif (error) {\r\nxfs_alert(mp, "%s agi read failed agno %d error %d",\r\n__func__, agno, error);\r\n} else {\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agibp);\r\nitotal += be32_to_cpu(agi->agi_count);\r\nifree += be32_to_cpu(agi->agi_freecount);\r\nxfs_buf_relse(agibp);\r\n}\r\n}\r\n}
