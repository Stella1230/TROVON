static bool ovs_must_notify(struct genl_family *family, struct genl_info *info,\r\nunsigned int group)\r\n{\r\nreturn info->nlhdr->nlmsg_flags & NLM_F_ECHO ||\r\ngenl_has_listeners(family, genl_info_net(info), group);\r\n}\r\nstatic void ovs_notify(struct genl_family *family,\r\nstruct sk_buff *skb, struct genl_info *info)\r\n{\r\ngenl_notify(family, skb, info, 0, GFP_KERNEL);\r\n}\r\nvoid ovs_lock(void)\r\n{\r\nmutex_lock(&ovs_mutex);\r\n}\r\nvoid ovs_unlock(void)\r\n{\r\nmutex_unlock(&ovs_mutex);\r\n}\r\nint lockdep_ovsl_is_held(void)\r\n{\r\nif (debug_locks)\r\nreturn lockdep_is_held(&ovs_mutex);\r\nelse\r\nreturn 1;\r\n}\r\nstatic struct datapath *get_dp_rcu(struct net *net, int dp_ifindex)\r\n{\r\nstruct net_device *dev = dev_get_by_index_rcu(net, dp_ifindex);\r\nif (dev) {\r\nstruct vport *vport = ovs_internal_dev_get_vport(dev);\r\nif (vport)\r\nreturn vport->dp;\r\n}\r\nreturn NULL;\r\n}\r\nstatic inline struct datapath *get_dp(struct net *net, int dp_ifindex)\r\n{\r\nstruct datapath *dp;\r\nWARN_ON_ONCE(!rcu_read_lock_held() && !lockdep_ovsl_is_held());\r\nrcu_read_lock();\r\ndp = get_dp_rcu(net, dp_ifindex);\r\nrcu_read_unlock();\r\nreturn dp;\r\n}\r\nconst char *ovs_dp_name(const struct datapath *dp)\r\n{\r\nstruct vport *vport = ovs_vport_ovsl_rcu(dp, OVSP_LOCAL);\r\nreturn ovs_vport_name(vport);\r\n}\r\nstatic int get_dpifindex(const struct datapath *dp)\r\n{\r\nstruct vport *local;\r\nint ifindex;\r\nrcu_read_lock();\r\nlocal = ovs_vport_rcu(dp, OVSP_LOCAL);\r\nif (local)\r\nifindex = local->dev->ifindex;\r\nelse\r\nifindex = 0;\r\nrcu_read_unlock();\r\nreturn ifindex;\r\n}\r\nstatic void destroy_dp_rcu(struct rcu_head *rcu)\r\n{\r\nstruct datapath *dp = container_of(rcu, struct datapath, rcu);\r\novs_flow_tbl_destroy(&dp->table);\r\nfree_percpu(dp->stats_percpu);\r\nkfree(dp->ports);\r\nkfree(dp);\r\n}\r\nstatic struct hlist_head *vport_hash_bucket(const struct datapath *dp,\r\nu16 port_no)\r\n{\r\nreturn &dp->ports[port_no & (DP_VPORT_HASH_BUCKETS - 1)];\r\n}\r\nstruct vport *ovs_lookup_vport(const struct datapath *dp, u16 port_no)\r\n{\r\nstruct vport *vport;\r\nstruct hlist_head *head;\r\nhead = vport_hash_bucket(dp, port_no);\r\nhlist_for_each_entry_rcu(vport, head, dp_hash_node) {\r\nif (vport->port_no == port_no)\r\nreturn vport;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct vport *new_vport(const struct vport_parms *parms)\r\n{\r\nstruct vport *vport;\r\nvport = ovs_vport_add(parms);\r\nif (!IS_ERR(vport)) {\r\nstruct datapath *dp = parms->dp;\r\nstruct hlist_head *head = vport_hash_bucket(dp, vport->port_no);\r\nhlist_add_head_rcu(&vport->dp_hash_node, head);\r\n}\r\nreturn vport;\r\n}\r\nvoid ovs_dp_detach_port(struct vport *p)\r\n{\r\nASSERT_OVSL();\r\nhlist_del_rcu(&p->dp_hash_node);\r\novs_vport_del(p);\r\n}\r\nvoid ovs_dp_process_packet(struct sk_buff *skb, struct sw_flow_key *key)\r\n{\r\nconst struct vport *p = OVS_CB(skb)->input_vport;\r\nstruct datapath *dp = p->dp;\r\nstruct sw_flow *flow;\r\nstruct sw_flow_actions *sf_acts;\r\nstruct dp_stats_percpu *stats;\r\nu64 *stats_counter;\r\nu32 n_mask_hit;\r\nstats = this_cpu_ptr(dp->stats_percpu);\r\nflow = ovs_flow_tbl_lookup_stats(&dp->table, key, &n_mask_hit);\r\nif (unlikely(!flow)) {\r\nstruct dp_upcall_info upcall;\r\nint error;\r\nmemset(&upcall, 0, sizeof(upcall));\r\nupcall.cmd = OVS_PACKET_CMD_MISS;\r\nupcall.portid = ovs_vport_find_upcall_portid(p, skb);\r\nupcall.mru = OVS_CB(skb)->mru;\r\nerror = ovs_dp_upcall(dp, skb, key, &upcall, 0);\r\nif (unlikely(error))\r\nkfree_skb(skb);\r\nelse\r\nconsume_skb(skb);\r\nstats_counter = &stats->n_missed;\r\ngoto out;\r\n}\r\novs_flow_stats_update(flow, key->tp.flags, skb);\r\nsf_acts = rcu_dereference(flow->sf_acts);\r\novs_execute_actions(dp, skb, sf_acts, key);\r\nstats_counter = &stats->n_hit;\r\nout:\r\nu64_stats_update_begin(&stats->syncp);\r\n(*stats_counter)++;\r\nstats->n_mask_hit += n_mask_hit;\r\nu64_stats_update_end(&stats->syncp);\r\n}\r\nint ovs_dp_upcall(struct datapath *dp, struct sk_buff *skb,\r\nconst struct sw_flow_key *key,\r\nconst struct dp_upcall_info *upcall_info,\r\nuint32_t cutlen)\r\n{\r\nstruct dp_stats_percpu *stats;\r\nint err;\r\nif (upcall_info->portid == 0) {\r\nerr = -ENOTCONN;\r\ngoto err;\r\n}\r\nif (!skb_is_gso(skb))\r\nerr = queue_userspace_packet(dp, skb, key, upcall_info, cutlen);\r\nelse\r\nerr = queue_gso_packets(dp, skb, key, upcall_info, cutlen);\r\nif (err)\r\ngoto err;\r\nreturn 0;\r\nerr:\r\nstats = this_cpu_ptr(dp->stats_percpu);\r\nu64_stats_update_begin(&stats->syncp);\r\nstats->n_lost++;\r\nu64_stats_update_end(&stats->syncp);\r\nreturn err;\r\n}\r\nstatic int queue_gso_packets(struct datapath *dp, struct sk_buff *skb,\r\nconst struct sw_flow_key *key,\r\nconst struct dp_upcall_info *upcall_info,\r\nuint32_t cutlen)\r\n{\r\nunsigned short gso_type = skb_shinfo(skb)->gso_type;\r\nstruct sw_flow_key later_key;\r\nstruct sk_buff *segs, *nskb;\r\nint err;\r\nBUILD_BUG_ON(sizeof(*OVS_CB(skb)) > SKB_SGO_CB_OFFSET);\r\nsegs = __skb_gso_segment(skb, NETIF_F_SG, false);\r\nif (IS_ERR(segs))\r\nreturn PTR_ERR(segs);\r\nif (segs == NULL)\r\nreturn -EINVAL;\r\nif (gso_type & SKB_GSO_UDP) {\r\nlater_key = *key;\r\nlater_key.ip.frag = OVS_FRAG_TYPE_LATER;\r\n}\r\nskb = segs;\r\ndo {\r\nif (gso_type & SKB_GSO_UDP && skb != segs)\r\nkey = &later_key;\r\nerr = queue_userspace_packet(dp, skb, key, upcall_info, cutlen);\r\nif (err)\r\nbreak;\r\n} while ((skb = skb->next));\r\nskb = segs;\r\ndo {\r\nnskb = skb->next;\r\nif (err)\r\nkfree_skb(skb);\r\nelse\r\nconsume_skb(skb);\r\n} while ((skb = nskb));\r\nreturn err;\r\n}\r\nstatic size_t upcall_msg_size(const struct dp_upcall_info *upcall_info,\r\nunsigned int hdrlen)\r\n{\r\nsize_t size = NLMSG_ALIGN(sizeof(struct ovs_header))\r\n+ nla_total_size(hdrlen)\r\n+ nla_total_size(ovs_key_attr_size())\r\n+ nla_total_size(sizeof(unsigned int));\r\nif (upcall_info->userdata)\r\nsize += NLA_ALIGN(upcall_info->userdata->nla_len);\r\nif (upcall_info->egress_tun_info)\r\nsize += nla_total_size(ovs_tun_key_attr_size());\r\nif (upcall_info->actions_len)\r\nsize += nla_total_size(upcall_info->actions_len);\r\nif (upcall_info->mru)\r\nsize += nla_total_size(sizeof(upcall_info->mru));\r\nreturn size;\r\n}\r\nstatic void pad_packet(struct datapath *dp, struct sk_buff *skb)\r\n{\r\nif (!(dp->user_features & OVS_DP_F_UNALIGNED)) {\r\nsize_t plen = NLA_ALIGN(skb->len) - skb->len;\r\nif (plen > 0)\r\nmemset(skb_put(skb, plen), 0, plen);\r\n}\r\n}\r\nstatic int queue_userspace_packet(struct datapath *dp, struct sk_buff *skb,\r\nconst struct sw_flow_key *key,\r\nconst struct dp_upcall_info *upcall_info,\r\nuint32_t cutlen)\r\n{\r\nstruct ovs_header *upcall;\r\nstruct sk_buff *nskb = NULL;\r\nstruct sk_buff *user_skb = NULL;\r\nstruct nlattr *nla;\r\nsize_t len;\r\nunsigned int hlen;\r\nint err, dp_ifindex;\r\ndp_ifindex = get_dpifindex(dp);\r\nif (!dp_ifindex)\r\nreturn -ENODEV;\r\nif (skb_vlan_tag_present(skb)) {\r\nnskb = skb_clone(skb, GFP_ATOMIC);\r\nif (!nskb)\r\nreturn -ENOMEM;\r\nnskb = __vlan_hwaccel_push_inside(nskb);\r\nif (!nskb)\r\nreturn -ENOMEM;\r\nskb = nskb;\r\n}\r\nif (nla_attr_size(skb->len) > USHRT_MAX) {\r\nerr = -EFBIG;\r\ngoto out;\r\n}\r\nif (skb->ip_summed == CHECKSUM_PARTIAL &&\r\n(err = skb_checksum_help(skb)))\r\ngoto out;\r\nif (dp->user_features & OVS_DP_F_UNALIGNED)\r\nhlen = skb_zerocopy_headlen(skb);\r\nelse\r\nhlen = skb->len;\r\nlen = upcall_msg_size(upcall_info, hlen - cutlen);\r\nuser_skb = genlmsg_new(len, GFP_ATOMIC);\r\nif (!user_skb) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nupcall = genlmsg_put(user_skb, 0, 0, &dp_packet_genl_family,\r\n0, upcall_info->cmd);\r\nupcall->dp_ifindex = dp_ifindex;\r\nerr = ovs_nla_put_key(key, key, OVS_PACKET_ATTR_KEY, false, user_skb);\r\nBUG_ON(err);\r\nif (upcall_info->userdata)\r\n__nla_put(user_skb, OVS_PACKET_ATTR_USERDATA,\r\nnla_len(upcall_info->userdata),\r\nnla_data(upcall_info->userdata));\r\nif (upcall_info->egress_tun_info) {\r\nnla = nla_nest_start(user_skb, OVS_PACKET_ATTR_EGRESS_TUN_KEY);\r\nerr = ovs_nla_put_tunnel_info(user_skb,\r\nupcall_info->egress_tun_info);\r\nBUG_ON(err);\r\nnla_nest_end(user_skb, nla);\r\n}\r\nif (upcall_info->actions_len) {\r\nnla = nla_nest_start(user_skb, OVS_PACKET_ATTR_ACTIONS);\r\nerr = ovs_nla_put_actions(upcall_info->actions,\r\nupcall_info->actions_len,\r\nuser_skb);\r\nif (!err)\r\nnla_nest_end(user_skb, nla);\r\nelse\r\nnla_nest_cancel(user_skb, nla);\r\n}\r\nif (upcall_info->mru) {\r\nif (nla_put_u16(user_skb, OVS_PACKET_ATTR_MRU,\r\nupcall_info->mru)) {\r\nerr = -ENOBUFS;\r\ngoto out;\r\n}\r\npad_packet(dp, user_skb);\r\n}\r\nif (cutlen > 0) {\r\nif (nla_put_u32(user_skb, OVS_PACKET_ATTR_LEN,\r\nskb->len)) {\r\nerr = -ENOBUFS;\r\ngoto out;\r\n}\r\npad_packet(dp, user_skb);\r\n}\r\nif (!(nla = nla_reserve(user_skb, OVS_PACKET_ATTR_PACKET, 0))) {\r\nerr = -ENOBUFS;\r\ngoto out;\r\n}\r\nnla->nla_len = nla_attr_size(skb->len - cutlen);\r\nerr = skb_zerocopy(user_skb, skb, skb->len - cutlen, hlen);\r\nif (err)\r\ngoto out;\r\npad_packet(dp, user_skb);\r\n((struct nlmsghdr *) user_skb->data)->nlmsg_len = user_skb->len;\r\nerr = genlmsg_unicast(ovs_dp_get_net(dp), user_skb, upcall_info->portid);\r\nuser_skb = NULL;\r\nout:\r\nif (err)\r\nskb_tx_error(skb);\r\nkfree_skb(user_skb);\r\nkfree_skb(nskb);\r\nreturn err;\r\n}\r\nstatic int ovs_packet_cmd_execute(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct ovs_header *ovs_header = info->userhdr;\r\nstruct net *net = sock_net(skb->sk);\r\nstruct nlattr **a = info->attrs;\r\nstruct sw_flow_actions *acts;\r\nstruct sk_buff *packet;\r\nstruct sw_flow *flow;\r\nstruct sw_flow_actions *sf_acts;\r\nstruct datapath *dp;\r\nstruct vport *input_vport;\r\nu16 mru = 0;\r\nint len;\r\nint err;\r\nbool log = !a[OVS_PACKET_ATTR_PROBE];\r\nerr = -EINVAL;\r\nif (!a[OVS_PACKET_ATTR_PACKET] || !a[OVS_PACKET_ATTR_KEY] ||\r\n!a[OVS_PACKET_ATTR_ACTIONS])\r\ngoto err;\r\nlen = nla_len(a[OVS_PACKET_ATTR_PACKET]);\r\npacket = __dev_alloc_skb(NET_IP_ALIGN + len, GFP_KERNEL);\r\nerr = -ENOMEM;\r\nif (!packet)\r\ngoto err;\r\nskb_reserve(packet, NET_IP_ALIGN);\r\nnla_memcpy(__skb_put(packet, len), a[OVS_PACKET_ATTR_PACKET], len);\r\nif (a[OVS_PACKET_ATTR_MRU]) {\r\nmru = nla_get_u16(a[OVS_PACKET_ATTR_MRU]);\r\npacket->ignore_df = 1;\r\n}\r\nOVS_CB(packet)->mru = mru;\r\nflow = ovs_flow_alloc();\r\nerr = PTR_ERR(flow);\r\nif (IS_ERR(flow))\r\ngoto err_kfree_skb;\r\nerr = ovs_flow_key_extract_userspace(net, a[OVS_PACKET_ATTR_KEY],\r\npacket, &flow->key, log);\r\nif (err)\r\ngoto err_flow_free;\r\nerr = ovs_nla_copy_actions(net, a[OVS_PACKET_ATTR_ACTIONS],\r\n&flow->key, &acts, log);\r\nif (err)\r\ngoto err_flow_free;\r\nrcu_assign_pointer(flow->sf_acts, acts);\r\npacket->priority = flow->key.phy.priority;\r\npacket->mark = flow->key.phy.skb_mark;\r\nrcu_read_lock();\r\ndp = get_dp_rcu(net, ovs_header->dp_ifindex);\r\nerr = -ENODEV;\r\nif (!dp)\r\ngoto err_unlock;\r\ninput_vport = ovs_vport_rcu(dp, flow->key.phy.in_port);\r\nif (!input_vport)\r\ninput_vport = ovs_vport_rcu(dp, OVSP_LOCAL);\r\nif (!input_vport)\r\ngoto err_unlock;\r\npacket->dev = input_vport->dev;\r\nOVS_CB(packet)->input_vport = input_vport;\r\nsf_acts = rcu_dereference(flow->sf_acts);\r\nlocal_bh_disable();\r\nerr = ovs_execute_actions(dp, packet, sf_acts, &flow->key);\r\nlocal_bh_enable();\r\nrcu_read_unlock();\r\novs_flow_free(flow, false);\r\nreturn err;\r\nerr_unlock:\r\nrcu_read_unlock();\r\nerr_flow_free:\r\novs_flow_free(flow, false);\r\nerr_kfree_skb:\r\nkfree_skb(packet);\r\nerr:\r\nreturn err;\r\n}\r\nstatic void get_dp_stats(const struct datapath *dp, struct ovs_dp_stats *stats,\r\nstruct ovs_dp_megaflow_stats *mega_stats)\r\n{\r\nint i;\r\nmemset(mega_stats, 0, sizeof(*mega_stats));\r\nstats->n_flows = ovs_flow_tbl_count(&dp->table);\r\nmega_stats->n_masks = ovs_flow_tbl_num_masks(&dp->table);\r\nstats->n_hit = stats->n_missed = stats->n_lost = 0;\r\nfor_each_possible_cpu(i) {\r\nconst struct dp_stats_percpu *percpu_stats;\r\nstruct dp_stats_percpu local_stats;\r\nunsigned int start;\r\npercpu_stats = per_cpu_ptr(dp->stats_percpu, i);\r\ndo {\r\nstart = u64_stats_fetch_begin_irq(&percpu_stats->syncp);\r\nlocal_stats = *percpu_stats;\r\n} while (u64_stats_fetch_retry_irq(&percpu_stats->syncp, start));\r\nstats->n_hit += local_stats.n_hit;\r\nstats->n_missed += local_stats.n_missed;\r\nstats->n_lost += local_stats.n_lost;\r\nmega_stats->n_mask_hit += local_stats.n_mask_hit;\r\n}\r\n}\r\nstatic bool should_fill_key(const struct sw_flow_id *sfid, uint32_t ufid_flags)\r\n{\r\nreturn ovs_identifier_is_ufid(sfid) &&\r\n!(ufid_flags & OVS_UFID_F_OMIT_KEY);\r\n}\r\nstatic bool should_fill_mask(uint32_t ufid_flags)\r\n{\r\nreturn !(ufid_flags & OVS_UFID_F_OMIT_MASK);\r\n}\r\nstatic bool should_fill_actions(uint32_t ufid_flags)\r\n{\r\nreturn !(ufid_flags & OVS_UFID_F_OMIT_ACTIONS);\r\n}\r\nstatic size_t ovs_flow_cmd_msg_size(const struct sw_flow_actions *acts,\r\nconst struct sw_flow_id *sfid,\r\nuint32_t ufid_flags)\r\n{\r\nsize_t len = NLMSG_ALIGN(sizeof(struct ovs_header));\r\nif (sfid && ovs_identifier_is_ufid(sfid))\r\nlen += nla_total_size(sfid->ufid_len);\r\nif (!sfid || should_fill_key(sfid, ufid_flags))\r\nlen += nla_total_size(ovs_key_attr_size());\r\nif (should_fill_mask(ufid_flags))\r\nlen += nla_total_size(ovs_key_attr_size());\r\nif (should_fill_actions(ufid_flags))\r\nlen += nla_total_size(acts->orig_len);\r\nreturn len\r\n+ nla_total_size_64bit(sizeof(struct ovs_flow_stats))\r\n+ nla_total_size(1)\r\n+ nla_total_size_64bit(8);\r\n}\r\nstatic int ovs_flow_cmd_fill_stats(const struct sw_flow *flow,\r\nstruct sk_buff *skb)\r\n{\r\nstruct ovs_flow_stats stats;\r\n__be16 tcp_flags;\r\nunsigned long used;\r\novs_flow_stats_get(flow, &stats, &used, &tcp_flags);\r\nif (used &&\r\nnla_put_u64_64bit(skb, OVS_FLOW_ATTR_USED, ovs_flow_used_time(used),\r\nOVS_FLOW_ATTR_PAD))\r\nreturn -EMSGSIZE;\r\nif (stats.n_packets &&\r\nnla_put_64bit(skb, OVS_FLOW_ATTR_STATS,\r\nsizeof(struct ovs_flow_stats), &stats,\r\nOVS_FLOW_ATTR_PAD))\r\nreturn -EMSGSIZE;\r\nif ((u8)ntohs(tcp_flags) &&\r\nnla_put_u8(skb, OVS_FLOW_ATTR_TCP_FLAGS, (u8)ntohs(tcp_flags)))\r\nreturn -EMSGSIZE;\r\nreturn 0;\r\n}\r\nstatic int ovs_flow_cmd_fill_actions(const struct sw_flow *flow,\r\nstruct sk_buff *skb, int skb_orig_len)\r\n{\r\nstruct nlattr *start;\r\nint err;\r\nstart = nla_nest_start(skb, OVS_FLOW_ATTR_ACTIONS);\r\nif (start) {\r\nconst struct sw_flow_actions *sf_acts;\r\nsf_acts = rcu_dereference_ovsl(flow->sf_acts);\r\nerr = ovs_nla_put_actions(sf_acts->actions,\r\nsf_acts->actions_len, skb);\r\nif (!err)\r\nnla_nest_end(skb, start);\r\nelse {\r\nif (skb_orig_len)\r\nreturn err;\r\nnla_nest_cancel(skb, start);\r\n}\r\n} else if (skb_orig_len) {\r\nreturn -EMSGSIZE;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ovs_flow_cmd_fill_info(const struct sw_flow *flow, int dp_ifindex,\r\nstruct sk_buff *skb, u32 portid,\r\nu32 seq, u32 flags, u8 cmd, u32 ufid_flags)\r\n{\r\nconst int skb_orig_len = skb->len;\r\nstruct ovs_header *ovs_header;\r\nint err;\r\novs_header = genlmsg_put(skb, portid, seq, &dp_flow_genl_family,\r\nflags, cmd);\r\nif (!ovs_header)\r\nreturn -EMSGSIZE;\r\novs_header->dp_ifindex = dp_ifindex;\r\nerr = ovs_nla_put_identifier(flow, skb);\r\nif (err)\r\ngoto error;\r\nif (should_fill_key(&flow->id, ufid_flags)) {\r\nerr = ovs_nla_put_masked_key(flow, skb);\r\nif (err)\r\ngoto error;\r\n}\r\nif (should_fill_mask(ufid_flags)) {\r\nerr = ovs_nla_put_mask(flow, skb);\r\nif (err)\r\ngoto error;\r\n}\r\nerr = ovs_flow_cmd_fill_stats(flow, skb);\r\nif (err)\r\ngoto error;\r\nif (should_fill_actions(ufid_flags)) {\r\nerr = ovs_flow_cmd_fill_actions(flow, skb, skb_orig_len);\r\nif (err)\r\ngoto error;\r\n}\r\ngenlmsg_end(skb, ovs_header);\r\nreturn 0;\r\nerror:\r\ngenlmsg_cancel(skb, ovs_header);\r\nreturn err;\r\n}\r\nstatic struct sk_buff *ovs_flow_cmd_alloc_info(const struct sw_flow_actions *acts,\r\nconst struct sw_flow_id *sfid,\r\nstruct genl_info *info,\r\nbool always,\r\nuint32_t ufid_flags)\r\n{\r\nstruct sk_buff *skb;\r\nsize_t len;\r\nif (!always && !ovs_must_notify(&dp_flow_genl_family, info, 0))\r\nreturn NULL;\r\nlen = ovs_flow_cmd_msg_size(acts, sfid, ufid_flags);\r\nskb = genlmsg_new(len, GFP_KERNEL);\r\nif (!skb)\r\nreturn ERR_PTR(-ENOMEM);\r\nreturn skb;\r\n}\r\nstatic struct sk_buff *ovs_flow_cmd_build_info(const struct sw_flow *flow,\r\nint dp_ifindex,\r\nstruct genl_info *info, u8 cmd,\r\nbool always, u32 ufid_flags)\r\n{\r\nstruct sk_buff *skb;\r\nint retval;\r\nskb = ovs_flow_cmd_alloc_info(ovsl_dereference(flow->sf_acts),\r\n&flow->id, info, always, ufid_flags);\r\nif (IS_ERR_OR_NULL(skb))\r\nreturn skb;\r\nretval = ovs_flow_cmd_fill_info(flow, dp_ifindex, skb,\r\ninfo->snd_portid, info->snd_seq, 0,\r\ncmd, ufid_flags);\r\nBUG_ON(retval < 0);\r\nreturn skb;\r\n}\r\nstatic int ovs_flow_cmd_new(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nstruct nlattr **a = info->attrs;\r\nstruct ovs_header *ovs_header = info->userhdr;\r\nstruct sw_flow *flow = NULL, *new_flow;\r\nstruct sw_flow_mask mask;\r\nstruct sk_buff *reply;\r\nstruct datapath *dp;\r\nstruct sw_flow_actions *acts;\r\nstruct sw_flow_match match;\r\nu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\r\nint error;\r\nbool log = !a[OVS_FLOW_ATTR_PROBE];\r\nerror = -EINVAL;\r\nif (!a[OVS_FLOW_ATTR_KEY]) {\r\nOVS_NLERR(log, "Flow key attr not present in new flow.");\r\ngoto error;\r\n}\r\nif (!a[OVS_FLOW_ATTR_ACTIONS]) {\r\nOVS_NLERR(log, "Flow actions attr not present in new flow.");\r\ngoto error;\r\n}\r\nnew_flow = ovs_flow_alloc();\r\nif (IS_ERR(new_flow)) {\r\nerror = PTR_ERR(new_flow);\r\ngoto error;\r\n}\r\novs_match_init(&match, &new_flow->key, false, &mask);\r\nerror = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY],\r\na[OVS_FLOW_ATTR_MASK], log);\r\nif (error)\r\ngoto err_kfree_flow;\r\nerror = ovs_nla_get_identifier(&new_flow->id, a[OVS_FLOW_ATTR_UFID],\r\n&new_flow->key, log);\r\nif (error)\r\ngoto err_kfree_flow;\r\nif (ovs_identifier_is_key(&new_flow->id))\r\nmatch.key = new_flow->id.unmasked_key;\r\novs_flow_mask_key(&new_flow->key, &new_flow->key, true, &mask);\r\nerror = ovs_nla_copy_actions(net, a[OVS_FLOW_ATTR_ACTIONS],\r\n&new_flow->key, &acts, log);\r\nif (error) {\r\nOVS_NLERR(log, "Flow actions may not be safe on all matching packets.");\r\ngoto err_kfree_flow;\r\n}\r\nreply = ovs_flow_cmd_alloc_info(acts, &new_flow->id, info, false,\r\nufid_flags);\r\nif (IS_ERR(reply)) {\r\nerror = PTR_ERR(reply);\r\ngoto err_kfree_acts;\r\n}\r\novs_lock();\r\ndp = get_dp(net, ovs_header->dp_ifindex);\r\nif (unlikely(!dp)) {\r\nerror = -ENODEV;\r\ngoto err_unlock_ovs;\r\n}\r\nif (ovs_identifier_is_ufid(&new_flow->id))\r\nflow = ovs_flow_tbl_lookup_ufid(&dp->table, &new_flow->id);\r\nif (!flow)\r\nflow = ovs_flow_tbl_lookup(&dp->table, &new_flow->key);\r\nif (likely(!flow)) {\r\nrcu_assign_pointer(new_flow->sf_acts, acts);\r\nerror = ovs_flow_tbl_insert(&dp->table, new_flow, &mask);\r\nif (unlikely(error)) {\r\nacts = NULL;\r\ngoto err_unlock_ovs;\r\n}\r\nif (unlikely(reply)) {\r\nerror = ovs_flow_cmd_fill_info(new_flow,\r\novs_header->dp_ifindex,\r\nreply, info->snd_portid,\r\ninfo->snd_seq, 0,\r\nOVS_FLOW_CMD_NEW,\r\nufid_flags);\r\nBUG_ON(error < 0);\r\n}\r\novs_unlock();\r\n} else {\r\nstruct sw_flow_actions *old_acts;\r\nif (unlikely(info->nlhdr->nlmsg_flags & (NLM_F_CREATE\r\n| NLM_F_EXCL))) {\r\nerror = -EEXIST;\r\ngoto err_unlock_ovs;\r\n}\r\nif (unlikely(!ovs_flow_cmp(flow, &match))) {\r\nif (ovs_identifier_is_key(&flow->id))\r\nflow = ovs_flow_tbl_lookup_exact(&dp->table,\r\n&match);\r\nelse\r\nflow = NULL;\r\nif (!flow) {\r\nerror = -ENOENT;\r\ngoto err_unlock_ovs;\r\n}\r\n}\r\nold_acts = ovsl_dereference(flow->sf_acts);\r\nrcu_assign_pointer(flow->sf_acts, acts);\r\nif (unlikely(reply)) {\r\nerror = ovs_flow_cmd_fill_info(flow,\r\novs_header->dp_ifindex,\r\nreply, info->snd_portid,\r\ninfo->snd_seq, 0,\r\nOVS_FLOW_CMD_NEW,\r\nufid_flags);\r\nBUG_ON(error < 0);\r\n}\r\novs_unlock();\r\novs_nla_free_flow_actions_rcu(old_acts);\r\novs_flow_free(new_flow, false);\r\n}\r\nif (reply)\r\novs_notify(&dp_flow_genl_family, reply, info);\r\nreturn 0;\r\nerr_unlock_ovs:\r\novs_unlock();\r\nkfree_skb(reply);\r\nerr_kfree_acts:\r\novs_nla_free_flow_actions(acts);\r\nerr_kfree_flow:\r\novs_flow_free(new_flow, false);\r\nerror:\r\nreturn error;\r\n}\r\nstatic struct sw_flow_actions *get_flow_actions(struct net *net,\r\nconst struct nlattr *a,\r\nconst struct sw_flow_key *key,\r\nconst struct sw_flow_mask *mask,\r\nbool log)\r\n{\r\nstruct sw_flow_actions *acts;\r\nstruct sw_flow_key masked_key;\r\nint error;\r\novs_flow_mask_key(&masked_key, key, true, mask);\r\nerror = ovs_nla_copy_actions(net, a, &masked_key, &acts, log);\r\nif (error) {\r\nOVS_NLERR(log,\r\n"Actions may not be safe on all matching packets");\r\nreturn ERR_PTR(error);\r\n}\r\nreturn acts;\r\n}\r\nstatic int ovs_flow_cmd_set(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nstruct nlattr **a = info->attrs;\r\nstruct ovs_header *ovs_header = info->userhdr;\r\nstruct sw_flow_key key;\r\nstruct sw_flow *flow;\r\nstruct sw_flow_mask mask;\r\nstruct sk_buff *reply = NULL;\r\nstruct datapath *dp;\r\nstruct sw_flow_actions *old_acts = NULL, *acts = NULL;\r\nstruct sw_flow_match match;\r\nstruct sw_flow_id sfid;\r\nu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\r\nint error = 0;\r\nbool log = !a[OVS_FLOW_ATTR_PROBE];\r\nbool ufid_present;\r\nufid_present = ovs_nla_get_ufid(&sfid, a[OVS_FLOW_ATTR_UFID], log);\r\nif (a[OVS_FLOW_ATTR_KEY]) {\r\novs_match_init(&match, &key, true, &mask);\r\nerror = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY],\r\na[OVS_FLOW_ATTR_MASK], log);\r\n} else if (!ufid_present) {\r\nOVS_NLERR(log,\r\n"Flow set message rejected, Key attribute missing.");\r\nerror = -EINVAL;\r\n}\r\nif (error)\r\ngoto error;\r\nif (a[OVS_FLOW_ATTR_ACTIONS]) {\r\nif (!a[OVS_FLOW_ATTR_KEY]) {\r\nOVS_NLERR(log,\r\n"Flow key attribute not present in set flow.");\r\nerror = -EINVAL;\r\ngoto error;\r\n}\r\nacts = get_flow_actions(net, a[OVS_FLOW_ATTR_ACTIONS], &key,\r\n&mask, log);\r\nif (IS_ERR(acts)) {\r\nerror = PTR_ERR(acts);\r\ngoto error;\r\n}\r\nreply = ovs_flow_cmd_alloc_info(acts, &sfid, info, false,\r\nufid_flags);\r\nif (IS_ERR(reply)) {\r\nerror = PTR_ERR(reply);\r\ngoto err_kfree_acts;\r\n}\r\n}\r\novs_lock();\r\ndp = get_dp(net, ovs_header->dp_ifindex);\r\nif (unlikely(!dp)) {\r\nerror = -ENODEV;\r\ngoto err_unlock_ovs;\r\n}\r\nif (ufid_present)\r\nflow = ovs_flow_tbl_lookup_ufid(&dp->table, &sfid);\r\nelse\r\nflow = ovs_flow_tbl_lookup_exact(&dp->table, &match);\r\nif (unlikely(!flow)) {\r\nerror = -ENOENT;\r\ngoto err_unlock_ovs;\r\n}\r\nif (likely(acts)) {\r\nold_acts = ovsl_dereference(flow->sf_acts);\r\nrcu_assign_pointer(flow->sf_acts, acts);\r\nif (unlikely(reply)) {\r\nerror = ovs_flow_cmd_fill_info(flow,\r\novs_header->dp_ifindex,\r\nreply, info->snd_portid,\r\ninfo->snd_seq, 0,\r\nOVS_FLOW_CMD_NEW,\r\nufid_flags);\r\nBUG_ON(error < 0);\r\n}\r\n} else {\r\nreply = ovs_flow_cmd_build_info(flow, ovs_header->dp_ifindex,\r\ninfo, OVS_FLOW_CMD_NEW, false,\r\nufid_flags);\r\nif (IS_ERR(reply)) {\r\nerror = PTR_ERR(reply);\r\ngoto err_unlock_ovs;\r\n}\r\n}\r\nif (a[OVS_FLOW_ATTR_CLEAR])\r\novs_flow_stats_clear(flow);\r\novs_unlock();\r\nif (reply)\r\novs_notify(&dp_flow_genl_family, reply, info);\r\nif (old_acts)\r\novs_nla_free_flow_actions_rcu(old_acts);\r\nreturn 0;\r\nerr_unlock_ovs:\r\novs_unlock();\r\nkfree_skb(reply);\r\nerr_kfree_acts:\r\novs_nla_free_flow_actions(acts);\r\nerror:\r\nreturn error;\r\n}\r\nstatic int ovs_flow_cmd_get(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct nlattr **a = info->attrs;\r\nstruct ovs_header *ovs_header = info->userhdr;\r\nstruct net *net = sock_net(skb->sk);\r\nstruct sw_flow_key key;\r\nstruct sk_buff *reply;\r\nstruct sw_flow *flow;\r\nstruct datapath *dp;\r\nstruct sw_flow_match match;\r\nstruct sw_flow_id ufid;\r\nu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\r\nint err = 0;\r\nbool log = !a[OVS_FLOW_ATTR_PROBE];\r\nbool ufid_present;\r\nufid_present = ovs_nla_get_ufid(&ufid, a[OVS_FLOW_ATTR_UFID], log);\r\nif (a[OVS_FLOW_ATTR_KEY]) {\r\novs_match_init(&match, &key, true, NULL);\r\nerr = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY], NULL,\r\nlog);\r\n} else if (!ufid_present) {\r\nOVS_NLERR(log,\r\n"Flow get message rejected, Key attribute missing.");\r\nerr = -EINVAL;\r\n}\r\nif (err)\r\nreturn err;\r\novs_lock();\r\ndp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);\r\nif (!dp) {\r\nerr = -ENODEV;\r\ngoto unlock;\r\n}\r\nif (ufid_present)\r\nflow = ovs_flow_tbl_lookup_ufid(&dp->table, &ufid);\r\nelse\r\nflow = ovs_flow_tbl_lookup_exact(&dp->table, &match);\r\nif (!flow) {\r\nerr = -ENOENT;\r\ngoto unlock;\r\n}\r\nreply = ovs_flow_cmd_build_info(flow, ovs_header->dp_ifindex, info,\r\nOVS_FLOW_CMD_NEW, true, ufid_flags);\r\nif (IS_ERR(reply)) {\r\nerr = PTR_ERR(reply);\r\ngoto unlock;\r\n}\r\novs_unlock();\r\nreturn genlmsg_reply(reply, info);\r\nunlock:\r\novs_unlock();\r\nreturn err;\r\n}\r\nstatic int ovs_flow_cmd_del(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct nlattr **a = info->attrs;\r\nstruct ovs_header *ovs_header = info->userhdr;\r\nstruct net *net = sock_net(skb->sk);\r\nstruct sw_flow_key key;\r\nstruct sk_buff *reply;\r\nstruct sw_flow *flow = NULL;\r\nstruct datapath *dp;\r\nstruct sw_flow_match match;\r\nstruct sw_flow_id ufid;\r\nu32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\r\nint err;\r\nbool log = !a[OVS_FLOW_ATTR_PROBE];\r\nbool ufid_present;\r\nufid_present = ovs_nla_get_ufid(&ufid, a[OVS_FLOW_ATTR_UFID], log);\r\nif (a[OVS_FLOW_ATTR_KEY]) {\r\novs_match_init(&match, &key, true, NULL);\r\nerr = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY],\r\nNULL, log);\r\nif (unlikely(err))\r\nreturn err;\r\n}\r\novs_lock();\r\ndp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);\r\nif (unlikely(!dp)) {\r\nerr = -ENODEV;\r\ngoto unlock;\r\n}\r\nif (unlikely(!a[OVS_FLOW_ATTR_KEY] && !ufid_present)) {\r\nerr = ovs_flow_tbl_flush(&dp->table);\r\ngoto unlock;\r\n}\r\nif (ufid_present)\r\nflow = ovs_flow_tbl_lookup_ufid(&dp->table, &ufid);\r\nelse\r\nflow = ovs_flow_tbl_lookup_exact(&dp->table, &match);\r\nif (unlikely(!flow)) {\r\nerr = -ENOENT;\r\ngoto unlock;\r\n}\r\novs_flow_tbl_remove(&dp->table, flow);\r\novs_unlock();\r\nreply = ovs_flow_cmd_alloc_info((const struct sw_flow_actions __force *) flow->sf_acts,\r\n&flow->id, info, false, ufid_flags);\r\nif (likely(reply)) {\r\nif (likely(!IS_ERR(reply))) {\r\nrcu_read_lock();\r\nerr = ovs_flow_cmd_fill_info(flow, ovs_header->dp_ifindex,\r\nreply, info->snd_portid,\r\ninfo->snd_seq, 0,\r\nOVS_FLOW_CMD_DEL,\r\nufid_flags);\r\nrcu_read_unlock();\r\nBUG_ON(err < 0);\r\novs_notify(&dp_flow_genl_family, reply, info);\r\n} else {\r\nnetlink_set_err(sock_net(skb->sk)->genl_sock, 0, 0, PTR_ERR(reply));\r\n}\r\n}\r\novs_flow_free(flow, true);\r\nreturn 0;\r\nunlock:\r\novs_unlock();\r\nreturn err;\r\n}\r\nstatic int ovs_flow_cmd_dump(struct sk_buff *skb, struct netlink_callback *cb)\r\n{\r\nstruct nlattr *a[__OVS_FLOW_ATTR_MAX];\r\nstruct ovs_header *ovs_header = genlmsg_data(nlmsg_data(cb->nlh));\r\nstruct table_instance *ti;\r\nstruct datapath *dp;\r\nu32 ufid_flags;\r\nint err;\r\nerr = genlmsg_parse(cb->nlh, &dp_flow_genl_family, a,\r\nOVS_FLOW_ATTR_MAX, flow_policy);\r\nif (err)\r\nreturn err;\r\nufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);\r\nrcu_read_lock();\r\ndp = get_dp_rcu(sock_net(skb->sk), ovs_header->dp_ifindex);\r\nif (!dp) {\r\nrcu_read_unlock();\r\nreturn -ENODEV;\r\n}\r\nti = rcu_dereference(dp->table.ti);\r\nfor (;;) {\r\nstruct sw_flow *flow;\r\nu32 bucket, obj;\r\nbucket = cb->args[0];\r\nobj = cb->args[1];\r\nflow = ovs_flow_tbl_dump_next(ti, &bucket, &obj);\r\nif (!flow)\r\nbreak;\r\nif (ovs_flow_cmd_fill_info(flow, ovs_header->dp_ifindex, skb,\r\nNETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq, NLM_F_MULTI,\r\nOVS_FLOW_CMD_NEW, ufid_flags) < 0)\r\nbreak;\r\ncb->args[0] = bucket;\r\ncb->args[1] = obj;\r\n}\r\nrcu_read_unlock();\r\nreturn skb->len;\r\n}\r\nstatic size_t ovs_dp_cmd_msg_size(void)\r\n{\r\nsize_t msgsize = NLMSG_ALIGN(sizeof(struct ovs_header));\r\nmsgsize += nla_total_size(IFNAMSIZ);\r\nmsgsize += nla_total_size_64bit(sizeof(struct ovs_dp_stats));\r\nmsgsize += nla_total_size_64bit(sizeof(struct ovs_dp_megaflow_stats));\r\nmsgsize += nla_total_size(sizeof(u32));\r\nreturn msgsize;\r\n}\r\nstatic int ovs_dp_cmd_fill_info(struct datapath *dp, struct sk_buff *skb,\r\nu32 portid, u32 seq, u32 flags, u8 cmd)\r\n{\r\nstruct ovs_header *ovs_header;\r\nstruct ovs_dp_stats dp_stats;\r\nstruct ovs_dp_megaflow_stats dp_megaflow_stats;\r\nint err;\r\novs_header = genlmsg_put(skb, portid, seq, &dp_datapath_genl_family,\r\nflags, cmd);\r\nif (!ovs_header)\r\ngoto error;\r\novs_header->dp_ifindex = get_dpifindex(dp);\r\nerr = nla_put_string(skb, OVS_DP_ATTR_NAME, ovs_dp_name(dp));\r\nif (err)\r\ngoto nla_put_failure;\r\nget_dp_stats(dp, &dp_stats, &dp_megaflow_stats);\r\nif (nla_put_64bit(skb, OVS_DP_ATTR_STATS, sizeof(struct ovs_dp_stats),\r\n&dp_stats, OVS_DP_ATTR_PAD))\r\ngoto nla_put_failure;\r\nif (nla_put_64bit(skb, OVS_DP_ATTR_MEGAFLOW_STATS,\r\nsizeof(struct ovs_dp_megaflow_stats),\r\n&dp_megaflow_stats, OVS_DP_ATTR_PAD))\r\ngoto nla_put_failure;\r\nif (nla_put_u32(skb, OVS_DP_ATTR_USER_FEATURES, dp->user_features))\r\ngoto nla_put_failure;\r\ngenlmsg_end(skb, ovs_header);\r\nreturn 0;\r\nnla_put_failure:\r\ngenlmsg_cancel(skb, ovs_header);\r\nerror:\r\nreturn -EMSGSIZE;\r\n}\r\nstatic struct sk_buff *ovs_dp_cmd_alloc_info(void)\r\n{\r\nreturn genlmsg_new(ovs_dp_cmd_msg_size(), GFP_KERNEL);\r\n}\r\nstatic struct datapath *lookup_datapath(struct net *net,\r\nconst struct ovs_header *ovs_header,\r\nstruct nlattr *a[OVS_DP_ATTR_MAX + 1])\r\n{\r\nstruct datapath *dp;\r\nif (!a[OVS_DP_ATTR_NAME])\r\ndp = get_dp(net, ovs_header->dp_ifindex);\r\nelse {\r\nstruct vport *vport;\r\nvport = ovs_vport_locate(net, nla_data(a[OVS_DP_ATTR_NAME]));\r\ndp = vport && vport->port_no == OVSP_LOCAL ? vport->dp : NULL;\r\n}\r\nreturn dp ? dp : ERR_PTR(-ENODEV);\r\n}\r\nstatic void ovs_dp_reset_user_features(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct datapath *dp;\r\ndp = lookup_datapath(sock_net(skb->sk), info->userhdr, info->attrs);\r\nif (IS_ERR(dp))\r\nreturn;\r\nWARN(dp->user_features, "Dropping previously announced user features\n");\r\ndp->user_features = 0;\r\n}\r\nstatic void ovs_dp_change(struct datapath *dp, struct nlattr *a[])\r\n{\r\nif (a[OVS_DP_ATTR_USER_FEATURES])\r\ndp->user_features = nla_get_u32(a[OVS_DP_ATTR_USER_FEATURES]);\r\n}\r\nstatic int ovs_dp_cmd_new(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct nlattr **a = info->attrs;\r\nstruct vport_parms parms;\r\nstruct sk_buff *reply;\r\nstruct datapath *dp;\r\nstruct vport *vport;\r\nstruct ovs_net *ovs_net;\r\nint err, i;\r\nerr = -EINVAL;\r\nif (!a[OVS_DP_ATTR_NAME] || !a[OVS_DP_ATTR_UPCALL_PID])\r\ngoto err;\r\nreply = ovs_dp_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\nerr = -ENOMEM;\r\ndp = kzalloc(sizeof(*dp), GFP_KERNEL);\r\nif (dp == NULL)\r\ngoto err_free_reply;\r\novs_dp_set_net(dp, sock_net(skb->sk));\r\nerr = ovs_flow_tbl_init(&dp->table);\r\nif (err)\r\ngoto err_free_dp;\r\ndp->stats_percpu = netdev_alloc_pcpu_stats(struct dp_stats_percpu);\r\nif (!dp->stats_percpu) {\r\nerr = -ENOMEM;\r\ngoto err_destroy_table;\r\n}\r\ndp->ports = kmalloc(DP_VPORT_HASH_BUCKETS * sizeof(struct hlist_head),\r\nGFP_KERNEL);\r\nif (!dp->ports) {\r\nerr = -ENOMEM;\r\ngoto err_destroy_percpu;\r\n}\r\nfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++)\r\nINIT_HLIST_HEAD(&dp->ports[i]);\r\nparms.name = nla_data(a[OVS_DP_ATTR_NAME]);\r\nparms.type = OVS_VPORT_TYPE_INTERNAL;\r\nparms.options = NULL;\r\nparms.dp = dp;\r\nparms.port_no = OVSP_LOCAL;\r\nparms.upcall_portids = a[OVS_DP_ATTR_UPCALL_PID];\r\novs_dp_change(dp, a);\r\novs_lock();\r\nvport = new_vport(&parms);\r\nif (IS_ERR(vport)) {\r\nerr = PTR_ERR(vport);\r\nif (err == -EBUSY)\r\nerr = -EEXIST;\r\nif (err == -EEXIST) {\r\nif (info->genlhdr->version < OVS_DP_VER_FEATURES)\r\novs_dp_reset_user_features(skb, info);\r\n}\r\ngoto err_destroy_ports_array;\r\n}\r\nerr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_DP_CMD_NEW);\r\nBUG_ON(err < 0);\r\novs_net = net_generic(ovs_dp_get_net(dp), ovs_net_id);\r\nlist_add_tail_rcu(&dp->list_node, &ovs_net->dps);\r\novs_unlock();\r\novs_notify(&dp_datapath_genl_family, reply, info);\r\nreturn 0;\r\nerr_destroy_ports_array:\r\novs_unlock();\r\nkfree(dp->ports);\r\nerr_destroy_percpu:\r\nfree_percpu(dp->stats_percpu);\r\nerr_destroy_table:\r\novs_flow_tbl_destroy(&dp->table);\r\nerr_free_dp:\r\nkfree(dp);\r\nerr_free_reply:\r\nkfree_skb(reply);\r\nerr:\r\nreturn err;\r\n}\r\nstatic void __dp_destroy(struct datapath *dp)\r\n{\r\nint i;\r\nfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {\r\nstruct vport *vport;\r\nstruct hlist_node *n;\r\nhlist_for_each_entry_safe(vport, n, &dp->ports[i], dp_hash_node)\r\nif (vport->port_no != OVSP_LOCAL)\r\novs_dp_detach_port(vport);\r\n}\r\nlist_del_rcu(&dp->list_node);\r\novs_dp_detach_port(ovs_vport_ovsl(dp, OVSP_LOCAL));\r\ncall_rcu(&dp->rcu, destroy_dp_rcu);\r\n}\r\nstatic int ovs_dp_cmd_del(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct sk_buff *reply;\r\nstruct datapath *dp;\r\nint err;\r\nreply = ovs_dp_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\novs_lock();\r\ndp = lookup_datapath(sock_net(skb->sk), info->userhdr, info->attrs);\r\nerr = PTR_ERR(dp);\r\nif (IS_ERR(dp))\r\ngoto err_unlock_free;\r\nerr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_DP_CMD_DEL);\r\nBUG_ON(err < 0);\r\n__dp_destroy(dp);\r\novs_unlock();\r\novs_notify(&dp_datapath_genl_family, reply, info);\r\nreturn 0;\r\nerr_unlock_free:\r\novs_unlock();\r\nkfree_skb(reply);\r\nreturn err;\r\n}\r\nstatic int ovs_dp_cmd_set(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct sk_buff *reply;\r\nstruct datapath *dp;\r\nint err;\r\nreply = ovs_dp_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\novs_lock();\r\ndp = lookup_datapath(sock_net(skb->sk), info->userhdr, info->attrs);\r\nerr = PTR_ERR(dp);\r\nif (IS_ERR(dp))\r\ngoto err_unlock_free;\r\novs_dp_change(dp, info->attrs);\r\nerr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_DP_CMD_NEW);\r\nBUG_ON(err < 0);\r\novs_unlock();\r\novs_notify(&dp_datapath_genl_family, reply, info);\r\nreturn 0;\r\nerr_unlock_free:\r\novs_unlock();\r\nkfree_skb(reply);\r\nreturn err;\r\n}\r\nstatic int ovs_dp_cmd_get(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct sk_buff *reply;\r\nstruct datapath *dp;\r\nint err;\r\nreply = ovs_dp_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\novs_lock();\r\ndp = lookup_datapath(sock_net(skb->sk), info->userhdr, info->attrs);\r\nif (IS_ERR(dp)) {\r\nerr = PTR_ERR(dp);\r\ngoto err_unlock_free;\r\n}\r\nerr = ovs_dp_cmd_fill_info(dp, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_DP_CMD_NEW);\r\nBUG_ON(err < 0);\r\novs_unlock();\r\nreturn genlmsg_reply(reply, info);\r\nerr_unlock_free:\r\novs_unlock();\r\nkfree_skb(reply);\r\nreturn err;\r\n}\r\nstatic int ovs_dp_cmd_dump(struct sk_buff *skb, struct netlink_callback *cb)\r\n{\r\nstruct ovs_net *ovs_net = net_generic(sock_net(skb->sk), ovs_net_id);\r\nstruct datapath *dp;\r\nint skip = cb->args[0];\r\nint i = 0;\r\novs_lock();\r\nlist_for_each_entry(dp, &ovs_net->dps, list_node) {\r\nif (i >= skip &&\r\novs_dp_cmd_fill_info(dp, skb, NETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq, NLM_F_MULTI,\r\nOVS_DP_CMD_NEW) < 0)\r\nbreak;\r\ni++;\r\n}\r\novs_unlock();\r\ncb->args[0] = i;\r\nreturn skb->len;\r\n}\r\nstatic int ovs_vport_cmd_fill_info(struct vport *vport, struct sk_buff *skb,\r\nu32 portid, u32 seq, u32 flags, u8 cmd)\r\n{\r\nstruct ovs_header *ovs_header;\r\nstruct ovs_vport_stats vport_stats;\r\nint err;\r\novs_header = genlmsg_put(skb, portid, seq, &dp_vport_genl_family,\r\nflags, cmd);\r\nif (!ovs_header)\r\nreturn -EMSGSIZE;\r\novs_header->dp_ifindex = get_dpifindex(vport->dp);\r\nif (nla_put_u32(skb, OVS_VPORT_ATTR_PORT_NO, vport->port_no) ||\r\nnla_put_u32(skb, OVS_VPORT_ATTR_TYPE, vport->ops->type) ||\r\nnla_put_string(skb, OVS_VPORT_ATTR_NAME,\r\novs_vport_name(vport)))\r\ngoto nla_put_failure;\r\novs_vport_get_stats(vport, &vport_stats);\r\nif (nla_put_64bit(skb, OVS_VPORT_ATTR_STATS,\r\nsizeof(struct ovs_vport_stats), &vport_stats,\r\nOVS_VPORT_ATTR_PAD))\r\ngoto nla_put_failure;\r\nif (ovs_vport_get_upcall_portids(vport, skb))\r\ngoto nla_put_failure;\r\nerr = ovs_vport_get_options(vport, skb);\r\nif (err == -EMSGSIZE)\r\ngoto error;\r\ngenlmsg_end(skb, ovs_header);\r\nreturn 0;\r\nnla_put_failure:\r\nerr = -EMSGSIZE;\r\nerror:\r\ngenlmsg_cancel(skb, ovs_header);\r\nreturn err;\r\n}\r\nstatic struct sk_buff *ovs_vport_cmd_alloc_info(void)\r\n{\r\nreturn nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\r\n}\r\nstruct sk_buff *ovs_vport_cmd_build_info(struct vport *vport, u32 portid,\r\nu32 seq, u8 cmd)\r\n{\r\nstruct sk_buff *skb;\r\nint retval;\r\nskb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_ATOMIC);\r\nif (!skb)\r\nreturn ERR_PTR(-ENOMEM);\r\nretval = ovs_vport_cmd_fill_info(vport, skb, portid, seq, 0, cmd);\r\nBUG_ON(retval < 0);\r\nreturn skb;\r\n}\r\nstatic struct vport *lookup_vport(struct net *net,\r\nconst struct ovs_header *ovs_header,\r\nstruct nlattr *a[OVS_VPORT_ATTR_MAX + 1])\r\n{\r\nstruct datapath *dp;\r\nstruct vport *vport;\r\nif (a[OVS_VPORT_ATTR_NAME]) {\r\nvport = ovs_vport_locate(net, nla_data(a[OVS_VPORT_ATTR_NAME]));\r\nif (!vport)\r\nreturn ERR_PTR(-ENODEV);\r\nif (ovs_header->dp_ifindex &&\r\novs_header->dp_ifindex != get_dpifindex(vport->dp))\r\nreturn ERR_PTR(-ENODEV);\r\nreturn vport;\r\n} else if (a[OVS_VPORT_ATTR_PORT_NO]) {\r\nu32 port_no = nla_get_u32(a[OVS_VPORT_ATTR_PORT_NO]);\r\nif (port_no >= DP_MAX_PORTS)\r\nreturn ERR_PTR(-EFBIG);\r\ndp = get_dp(net, ovs_header->dp_ifindex);\r\nif (!dp)\r\nreturn ERR_PTR(-ENODEV);\r\nvport = ovs_vport_ovsl_rcu(dp, port_no);\r\nif (!vport)\r\nreturn ERR_PTR(-ENODEV);\r\nreturn vport;\r\n} else\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nstatic void update_headroom(struct datapath *dp)\r\n{\r\nunsigned dev_headroom, max_headroom = 0;\r\nstruct net_device *dev;\r\nstruct vport *vport;\r\nint i;\r\nfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {\r\nhlist_for_each_entry_rcu(vport, &dp->ports[i], dp_hash_node) {\r\ndev = vport->dev;\r\ndev_headroom = netdev_get_fwd_headroom(dev);\r\nif (dev_headroom > max_headroom)\r\nmax_headroom = dev_headroom;\r\n}\r\n}\r\ndp->max_headroom = max_headroom;\r\nfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++)\r\nhlist_for_each_entry_rcu(vport, &dp->ports[i], dp_hash_node)\r\nnetdev_set_rx_headroom(vport->dev, max_headroom);\r\n}\r\nstatic int ovs_vport_cmd_new(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct nlattr **a = info->attrs;\r\nstruct ovs_header *ovs_header = info->userhdr;\r\nstruct vport_parms parms;\r\nstruct sk_buff *reply;\r\nstruct vport *vport;\r\nstruct datapath *dp;\r\nu32 port_no;\r\nint err;\r\nif (!a[OVS_VPORT_ATTR_NAME] || !a[OVS_VPORT_ATTR_TYPE] ||\r\n!a[OVS_VPORT_ATTR_UPCALL_PID])\r\nreturn -EINVAL;\r\nport_no = a[OVS_VPORT_ATTR_PORT_NO]\r\n? nla_get_u32(a[OVS_VPORT_ATTR_PORT_NO]) : 0;\r\nif (port_no >= DP_MAX_PORTS)\r\nreturn -EFBIG;\r\nreply = ovs_vport_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\novs_lock();\r\nrestart:\r\ndp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);\r\nerr = -ENODEV;\r\nif (!dp)\r\ngoto exit_unlock_free;\r\nif (port_no) {\r\nvport = ovs_vport_ovsl(dp, port_no);\r\nerr = -EBUSY;\r\nif (vport)\r\ngoto exit_unlock_free;\r\n} else {\r\nfor (port_no = 1; ; port_no++) {\r\nif (port_no >= DP_MAX_PORTS) {\r\nerr = -EFBIG;\r\ngoto exit_unlock_free;\r\n}\r\nvport = ovs_vport_ovsl(dp, port_no);\r\nif (!vport)\r\nbreak;\r\n}\r\n}\r\nparms.name = nla_data(a[OVS_VPORT_ATTR_NAME]);\r\nparms.type = nla_get_u32(a[OVS_VPORT_ATTR_TYPE]);\r\nparms.options = a[OVS_VPORT_ATTR_OPTIONS];\r\nparms.dp = dp;\r\nparms.port_no = port_no;\r\nparms.upcall_portids = a[OVS_VPORT_ATTR_UPCALL_PID];\r\nvport = new_vport(&parms);\r\nerr = PTR_ERR(vport);\r\nif (IS_ERR(vport)) {\r\nif (err == -EAGAIN)\r\ngoto restart;\r\ngoto exit_unlock_free;\r\n}\r\nerr = ovs_vport_cmd_fill_info(vport, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_VPORT_CMD_NEW);\r\nif (netdev_get_fwd_headroom(vport->dev) > dp->max_headroom)\r\nupdate_headroom(dp);\r\nelse\r\nnetdev_set_rx_headroom(vport->dev, dp->max_headroom);\r\nBUG_ON(err < 0);\r\novs_unlock();\r\novs_notify(&dp_vport_genl_family, reply, info);\r\nreturn 0;\r\nexit_unlock_free:\r\novs_unlock();\r\nkfree_skb(reply);\r\nreturn err;\r\n}\r\nstatic int ovs_vport_cmd_set(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct nlattr **a = info->attrs;\r\nstruct sk_buff *reply;\r\nstruct vport *vport;\r\nint err;\r\nreply = ovs_vport_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\novs_lock();\r\nvport = lookup_vport(sock_net(skb->sk), info->userhdr, a);\r\nerr = PTR_ERR(vport);\r\nif (IS_ERR(vport))\r\ngoto exit_unlock_free;\r\nif (a[OVS_VPORT_ATTR_TYPE] &&\r\nnla_get_u32(a[OVS_VPORT_ATTR_TYPE]) != vport->ops->type) {\r\nerr = -EINVAL;\r\ngoto exit_unlock_free;\r\n}\r\nif (a[OVS_VPORT_ATTR_OPTIONS]) {\r\nerr = ovs_vport_set_options(vport, a[OVS_VPORT_ATTR_OPTIONS]);\r\nif (err)\r\ngoto exit_unlock_free;\r\n}\r\nif (a[OVS_VPORT_ATTR_UPCALL_PID]) {\r\nstruct nlattr *ids = a[OVS_VPORT_ATTR_UPCALL_PID];\r\nerr = ovs_vport_set_upcall_portids(vport, ids);\r\nif (err)\r\ngoto exit_unlock_free;\r\n}\r\nerr = ovs_vport_cmd_fill_info(vport, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_VPORT_CMD_NEW);\r\nBUG_ON(err < 0);\r\novs_unlock();\r\novs_notify(&dp_vport_genl_family, reply, info);\r\nreturn 0;\r\nexit_unlock_free:\r\novs_unlock();\r\nkfree_skb(reply);\r\nreturn err;\r\n}\r\nstatic int ovs_vport_cmd_del(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nbool must_update_headroom = false;\r\nstruct nlattr **a = info->attrs;\r\nstruct sk_buff *reply;\r\nstruct datapath *dp;\r\nstruct vport *vport;\r\nint err;\r\nreply = ovs_vport_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\novs_lock();\r\nvport = lookup_vport(sock_net(skb->sk), info->userhdr, a);\r\nerr = PTR_ERR(vport);\r\nif (IS_ERR(vport))\r\ngoto exit_unlock_free;\r\nif (vport->port_no == OVSP_LOCAL) {\r\nerr = -EINVAL;\r\ngoto exit_unlock_free;\r\n}\r\nerr = ovs_vport_cmd_fill_info(vport, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_VPORT_CMD_DEL);\r\nBUG_ON(err < 0);\r\ndp = vport->dp;\r\nif (netdev_get_fwd_headroom(vport->dev) == dp->max_headroom)\r\nmust_update_headroom = true;\r\nnetdev_reset_rx_headroom(vport->dev);\r\novs_dp_detach_port(vport);\r\nif (must_update_headroom)\r\nupdate_headroom(dp);\r\novs_unlock();\r\novs_notify(&dp_vport_genl_family, reply, info);\r\nreturn 0;\r\nexit_unlock_free:\r\novs_unlock();\r\nkfree_skb(reply);\r\nreturn err;\r\n}\r\nstatic int ovs_vport_cmd_get(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct nlattr **a = info->attrs;\r\nstruct ovs_header *ovs_header = info->userhdr;\r\nstruct sk_buff *reply;\r\nstruct vport *vport;\r\nint err;\r\nreply = ovs_vport_cmd_alloc_info();\r\nif (!reply)\r\nreturn -ENOMEM;\r\nrcu_read_lock();\r\nvport = lookup_vport(sock_net(skb->sk), ovs_header, a);\r\nerr = PTR_ERR(vport);\r\nif (IS_ERR(vport))\r\ngoto exit_unlock_free;\r\nerr = ovs_vport_cmd_fill_info(vport, reply, info->snd_portid,\r\ninfo->snd_seq, 0, OVS_VPORT_CMD_NEW);\r\nBUG_ON(err < 0);\r\nrcu_read_unlock();\r\nreturn genlmsg_reply(reply, info);\r\nexit_unlock_free:\r\nrcu_read_unlock();\r\nkfree_skb(reply);\r\nreturn err;\r\n}\r\nstatic int ovs_vport_cmd_dump(struct sk_buff *skb, struct netlink_callback *cb)\r\n{\r\nstruct ovs_header *ovs_header = genlmsg_data(nlmsg_data(cb->nlh));\r\nstruct datapath *dp;\r\nint bucket = cb->args[0], skip = cb->args[1];\r\nint i, j = 0;\r\nrcu_read_lock();\r\ndp = get_dp_rcu(sock_net(skb->sk), ovs_header->dp_ifindex);\r\nif (!dp) {\r\nrcu_read_unlock();\r\nreturn -ENODEV;\r\n}\r\nfor (i = bucket; i < DP_VPORT_HASH_BUCKETS; i++) {\r\nstruct vport *vport;\r\nj = 0;\r\nhlist_for_each_entry_rcu(vport, &dp->ports[i], dp_hash_node) {\r\nif (j >= skip &&\r\novs_vport_cmd_fill_info(vport, skb,\r\nNETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq,\r\nNLM_F_MULTI,\r\nOVS_VPORT_CMD_NEW) < 0)\r\ngoto out;\r\nj++;\r\n}\r\nskip = 0;\r\n}\r\nout:\r\nrcu_read_unlock();\r\ncb->args[0] = i;\r\ncb->args[1] = j;\r\nreturn skb->len;\r\n}\r\nstatic void dp_unregister_genl(int n_families)\r\n{\r\nint i;\r\nfor (i = 0; i < n_families; i++)\r\ngenl_unregister_family(dp_genl_families[i]);\r\n}\r\nstatic int __init dp_register_genl(void)\r\n{\r\nint err;\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(dp_genl_families); i++) {\r\nerr = genl_register_family(dp_genl_families[i]);\r\nif (err)\r\ngoto error;\r\n}\r\nreturn 0;\r\nerror:\r\ndp_unregister_genl(i);\r\nreturn err;\r\n}\r\nstatic int __net_init ovs_init_net(struct net *net)\r\n{\r\nstruct ovs_net *ovs_net = net_generic(net, ovs_net_id);\r\nINIT_LIST_HEAD(&ovs_net->dps);\r\nINIT_WORK(&ovs_net->dp_notify_work, ovs_dp_notify_wq);\r\novs_ct_init(net);\r\nreturn 0;\r\n}\r\nstatic void __net_exit list_vports_from_net(struct net *net, struct net *dnet,\r\nstruct list_head *head)\r\n{\r\nstruct ovs_net *ovs_net = net_generic(net, ovs_net_id);\r\nstruct datapath *dp;\r\nlist_for_each_entry(dp, &ovs_net->dps, list_node) {\r\nint i;\r\nfor (i = 0; i < DP_VPORT_HASH_BUCKETS; i++) {\r\nstruct vport *vport;\r\nhlist_for_each_entry(vport, &dp->ports[i], dp_hash_node) {\r\nif (vport->ops->type != OVS_VPORT_TYPE_INTERNAL)\r\ncontinue;\r\nif (dev_net(vport->dev) == dnet)\r\nlist_add(&vport->detach_list, head);\r\n}\r\n}\r\n}\r\n}\r\nstatic void __net_exit ovs_exit_net(struct net *dnet)\r\n{\r\nstruct datapath *dp, *dp_next;\r\nstruct ovs_net *ovs_net = net_generic(dnet, ovs_net_id);\r\nstruct vport *vport, *vport_next;\r\nstruct net *net;\r\nLIST_HEAD(head);\r\novs_ct_exit(dnet);\r\novs_lock();\r\nlist_for_each_entry_safe(dp, dp_next, &ovs_net->dps, list_node)\r\n__dp_destroy(dp);\r\nrtnl_lock();\r\nfor_each_net(net)\r\nlist_vports_from_net(net, dnet, &head);\r\nrtnl_unlock();\r\nlist_for_each_entry_safe(vport, vport_next, &head, detach_list) {\r\nlist_del(&vport->detach_list);\r\novs_dp_detach_port(vport);\r\n}\r\novs_unlock();\r\ncancel_work_sync(&ovs_net->dp_notify_work);\r\n}\r\nstatic int __init dp_init(void)\r\n{\r\nint err;\r\nBUILD_BUG_ON(sizeof(struct ovs_skb_cb) > FIELD_SIZEOF(struct sk_buff, cb));\r\npr_info("Open vSwitch switching datapath\n");\r\nerr = action_fifos_init();\r\nif (err)\r\ngoto error;\r\nerr = ovs_internal_dev_rtnl_link_register();\r\nif (err)\r\ngoto error_action_fifos_exit;\r\nerr = ovs_flow_init();\r\nif (err)\r\ngoto error_unreg_rtnl_link;\r\nerr = ovs_vport_init();\r\nif (err)\r\ngoto error_flow_exit;\r\nerr = register_pernet_device(&ovs_net_ops);\r\nif (err)\r\ngoto error_vport_exit;\r\nerr = register_netdevice_notifier(&ovs_dp_device_notifier);\r\nif (err)\r\ngoto error_netns_exit;\r\nerr = ovs_netdev_init();\r\nif (err)\r\ngoto error_unreg_notifier;\r\nerr = dp_register_genl();\r\nif (err < 0)\r\ngoto error_unreg_netdev;\r\nreturn 0;\r\nerror_unreg_netdev:\r\novs_netdev_exit();\r\nerror_unreg_notifier:\r\nunregister_netdevice_notifier(&ovs_dp_device_notifier);\r\nerror_netns_exit:\r\nunregister_pernet_device(&ovs_net_ops);\r\nerror_vport_exit:\r\novs_vport_exit();\r\nerror_flow_exit:\r\novs_flow_exit();\r\nerror_unreg_rtnl_link:\r\novs_internal_dev_rtnl_link_unregister();\r\nerror_action_fifos_exit:\r\naction_fifos_exit();\r\nerror:\r\nreturn err;\r\n}\r\nstatic void dp_cleanup(void)\r\n{\r\ndp_unregister_genl(ARRAY_SIZE(dp_genl_families));\r\novs_netdev_exit();\r\nunregister_netdevice_notifier(&ovs_dp_device_notifier);\r\nunregister_pernet_device(&ovs_net_ops);\r\nrcu_barrier();\r\novs_vport_exit();\r\novs_flow_exit();\r\novs_internal_dev_rtnl_link_unregister();\r\naction_fifos_exit();\r\n}
