static inline void rng_unmap_buf(struct device *jrdev, struct buf_data *bd)\r\n{\r\nif (bd->addr)\r\ndma_unmap_single(jrdev, bd->addr, RN_BUF_SIZE,\r\nDMA_FROM_DEVICE);\r\n}\r\nstatic inline void rng_unmap_ctx(struct caam_rng_ctx *ctx)\r\n{\r\nstruct device *jrdev = ctx->jrdev;\r\nif (ctx->sh_desc_dma)\r\ndma_unmap_single(jrdev, ctx->sh_desc_dma,\r\ndesc_bytes(ctx->sh_desc), DMA_TO_DEVICE);\r\nrng_unmap_buf(jrdev, &ctx->bufs[0]);\r\nrng_unmap_buf(jrdev, &ctx->bufs[1]);\r\n}\r\nstatic void rng_done(struct device *jrdev, u32 *desc, u32 err, void *context)\r\n{\r\nstruct buf_data *bd;\r\nbd = container_of(desc, struct buf_data, hw_desc[0]);\r\nif (err)\r\ncaam_jr_strstatus(jrdev, err);\r\natomic_set(&bd->empty, BUF_NOT_EMPTY);\r\ncomplete(&bd->filled);\r\ndma_sync_single_for_cpu(jrdev, bd->addr, RN_BUF_SIZE, DMA_FROM_DEVICE);\r\n#ifdef DEBUG\r\nprint_hex_dump(KERN_ERR, "rng refreshed buf@: ",\r\nDUMP_PREFIX_ADDRESS, 16, 4, bd->buf, RN_BUF_SIZE, 1);\r\n#endif\r\n}\r\nstatic inline int submit_job(struct caam_rng_ctx *ctx, int to_current)\r\n{\r\nstruct buf_data *bd = &ctx->bufs[!(to_current ^ ctx->current_buf)];\r\nstruct device *jrdev = ctx->jrdev;\r\nu32 *desc = bd->hw_desc;\r\nint err;\r\ndev_dbg(jrdev, "submitting job %d\n", !(to_current ^ ctx->current_buf));\r\ninit_completion(&bd->filled);\r\nerr = caam_jr_enqueue(jrdev, desc, rng_done, ctx);\r\nif (err)\r\ncomplete(&bd->filled);\r\nelse\r\natomic_inc(&bd->empty);\r\nreturn err;\r\n}\r\nstatic int caam_read(struct hwrng *rng, void *data, size_t max, bool wait)\r\n{\r\nstruct caam_rng_ctx *ctx = rng_ctx;\r\nstruct buf_data *bd = &ctx->bufs[ctx->current_buf];\r\nint next_buf_idx, copied_idx;\r\nint err;\r\nif (atomic_read(&bd->empty)) {\r\nif (atomic_read(&bd->empty) == BUF_EMPTY) {\r\nerr = submit_job(ctx, 1);\r\nif (err)\r\nreturn 0;\r\n}\r\nif (!wait)\r\nreturn 0;\r\nif (atomic_read(&bd->empty))\r\nwait_for_completion(&bd->filled);\r\n}\r\nnext_buf_idx = ctx->cur_buf_idx + max;\r\ndev_dbg(ctx->jrdev, "%s: start reading at buffer %d, idx %d\n",\r\n__func__, ctx->current_buf, ctx->cur_buf_idx);\r\nif (next_buf_idx < RN_BUF_SIZE) {\r\nmemcpy(data, bd->buf + ctx->cur_buf_idx, max);\r\nctx->cur_buf_idx = next_buf_idx;\r\nreturn max;\r\n}\r\ncopied_idx = RN_BUF_SIZE - ctx->cur_buf_idx;\r\nmemcpy(data, bd->buf + ctx->cur_buf_idx, copied_idx);\r\nctx->cur_buf_idx = 0;\r\natomic_set(&bd->empty, BUF_EMPTY);\r\nsubmit_job(ctx, 1);\r\nctx->current_buf = !ctx->current_buf;\r\ndev_dbg(ctx->jrdev, "switched to buffer %d\n", ctx->current_buf);\r\nreturn copied_idx + caam_read(rng, data + copied_idx,\r\nmax - copied_idx, false);\r\n}\r\nstatic inline int rng_create_sh_desc(struct caam_rng_ctx *ctx)\r\n{\r\nstruct device *jrdev = ctx->jrdev;\r\nu32 *desc = ctx->sh_desc;\r\ninit_sh_desc(desc, HDR_SHARE_SERIAL);\r\nappend_operation(desc, OP_ALG_ALGSEL_RNG | OP_TYPE_CLASS1_ALG);\r\nappend_seq_fifo_store(desc, RN_BUF_SIZE, FIFOST_TYPE_RNGSTORE);\r\nctx->sh_desc_dma = dma_map_single(jrdev, desc, desc_bytes(desc),\r\nDMA_TO_DEVICE);\r\nif (dma_mapping_error(jrdev, ctx->sh_desc_dma)) {\r\ndev_err(jrdev, "unable to map shared descriptor\n");\r\nreturn -ENOMEM;\r\n}\r\n#ifdef DEBUG\r\nprint_hex_dump(KERN_ERR, "rng shdesc@: ", DUMP_PREFIX_ADDRESS, 16, 4,\r\ndesc, desc_bytes(desc), 1);\r\n#endif\r\nreturn 0;\r\n}\r\nstatic inline int rng_create_job_desc(struct caam_rng_ctx *ctx, int buf_id)\r\n{\r\nstruct device *jrdev = ctx->jrdev;\r\nstruct buf_data *bd = &ctx->bufs[buf_id];\r\nu32 *desc = bd->hw_desc;\r\nint sh_len = desc_len(ctx->sh_desc);\r\ninit_job_desc_shared(desc, ctx->sh_desc_dma, sh_len, HDR_SHARE_DEFER |\r\nHDR_REVERSE);\r\nbd->addr = dma_map_single(jrdev, bd->buf, RN_BUF_SIZE, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(jrdev, bd->addr)) {\r\ndev_err(jrdev, "unable to map dst\n");\r\nreturn -ENOMEM;\r\n}\r\nappend_seq_out_ptr_intlen(desc, bd->addr, RN_BUF_SIZE, 0);\r\n#ifdef DEBUG\r\nprint_hex_dump(KERN_ERR, "rng job desc@: ", DUMP_PREFIX_ADDRESS, 16, 4,\r\ndesc, desc_bytes(desc), 1);\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void caam_cleanup(struct hwrng *rng)\r\n{\r\nint i;\r\nstruct buf_data *bd;\r\nfor (i = 0; i < 2; i++) {\r\nbd = &rng_ctx->bufs[i];\r\nif (atomic_read(&bd->empty) == BUF_PENDING)\r\nwait_for_completion(&bd->filled);\r\n}\r\nrng_unmap_ctx(rng_ctx);\r\n}\r\nstatic int caam_init_buf(struct caam_rng_ctx *ctx, int buf_id)\r\n{\r\nstruct buf_data *bd = &ctx->bufs[buf_id];\r\nint err;\r\nerr = rng_create_job_desc(ctx, buf_id);\r\nif (err)\r\nreturn err;\r\natomic_set(&bd->empty, BUF_EMPTY);\r\nsubmit_job(ctx, buf_id == ctx->current_buf);\r\nwait_for_completion(&bd->filled);\r\nreturn 0;\r\n}\r\nstatic int caam_init_rng(struct caam_rng_ctx *ctx, struct device *jrdev)\r\n{\r\nint err;\r\nctx->jrdev = jrdev;\r\nerr = rng_create_sh_desc(ctx);\r\nif (err)\r\nreturn err;\r\nctx->current_buf = 0;\r\nctx->cur_buf_idx = 0;\r\nerr = caam_init_buf(ctx, 0);\r\nif (err)\r\nreturn err;\r\nerr = caam_init_buf(ctx, 1);\r\nif (err)\r\nreturn err;\r\nreturn 0;\r\n}\r\nstatic void __exit caam_rng_exit(void)\r\n{\r\ncaam_jr_free(rng_ctx->jrdev);\r\nhwrng_unregister(&caam_rng);\r\nkfree(rng_ctx);\r\n}\r\nstatic int __init caam_rng_init(void)\r\n{\r\nstruct device *dev;\r\nstruct device_node *dev_node;\r\nstruct platform_device *pdev;\r\nstruct device *ctrldev;\r\nstruct caam_drv_private *priv;\r\nint err;\r\ndev_node = of_find_compatible_node(NULL, NULL, "fsl,sec-v4.0");\r\nif (!dev_node) {\r\ndev_node = of_find_compatible_node(NULL, NULL, "fsl,sec4.0");\r\nif (!dev_node)\r\nreturn -ENODEV;\r\n}\r\npdev = of_find_device_by_node(dev_node);\r\nif (!pdev) {\r\nof_node_put(dev_node);\r\nreturn -ENODEV;\r\n}\r\nctrldev = &pdev->dev;\r\npriv = dev_get_drvdata(ctrldev);\r\nof_node_put(dev_node);\r\nif (!priv)\r\nreturn -ENODEV;\r\nif (!(rd_reg32(&priv->ctrl->perfmon.cha_num_ls) & CHA_ID_LS_RNG_MASK))\r\nreturn -ENODEV;\r\ndev = caam_jr_alloc();\r\nif (IS_ERR(dev)) {\r\npr_err("Job Ring Device allocation for transform failed\n");\r\nreturn PTR_ERR(dev);\r\n}\r\nrng_ctx = kmalloc(sizeof(*rng_ctx), GFP_DMA | GFP_KERNEL);\r\nif (!rng_ctx) {\r\nerr = -ENOMEM;\r\ngoto free_caam_alloc;\r\n}\r\nerr = caam_init_rng(rng_ctx, dev);\r\nif (err)\r\ngoto free_rng_ctx;\r\ndev_info(dev, "registering rng-caam\n");\r\nreturn hwrng_register(&caam_rng);\r\nfree_rng_ctx:\r\nkfree(rng_ctx);\r\nfree_caam_alloc:\r\ncaam_jr_free(dev);\r\nreturn err;\r\n}
