static unsigned int ip_tunnel_hash(__be32 key, __be32 remote)\r\n{\r\nreturn hash_32((__force u32)key ^ (__force u32)remote,\r\nIP_TNL_HASH_BITS);\r\n}\r\nstatic bool ip_tunnel_key_match(const struct ip_tunnel_parm *p,\r\n__be16 flags, __be32 key)\r\n{\r\nif (p->i_flags & TUNNEL_KEY) {\r\nif (flags & TUNNEL_KEY)\r\nreturn key == p->i_key;\r\nelse\r\nreturn false;\r\n} else\r\nreturn !(flags & TUNNEL_KEY);\r\n}\r\nstruct ip_tunnel *ip_tunnel_lookup(struct ip_tunnel_net *itn,\r\nint link, __be16 flags,\r\n__be32 remote, __be32 local,\r\n__be32 key)\r\n{\r\nunsigned int hash;\r\nstruct ip_tunnel *t, *cand = NULL;\r\nstruct hlist_head *head;\r\nhash = ip_tunnel_hash(key, remote);\r\nhead = &itn->tunnels[hash];\r\nhlist_for_each_entry_rcu(t, head, hash_node) {\r\nif (local != t->parms.iph.saddr ||\r\nremote != t->parms.iph.daddr ||\r\n!(t->dev->flags & IFF_UP))\r\ncontinue;\r\nif (!ip_tunnel_key_match(&t->parms, flags, key))\r\ncontinue;\r\nif (t->parms.link == link)\r\nreturn t;\r\nelse\r\ncand = t;\r\n}\r\nhlist_for_each_entry_rcu(t, head, hash_node) {\r\nif (remote != t->parms.iph.daddr ||\r\nt->parms.iph.saddr != 0 ||\r\n!(t->dev->flags & IFF_UP))\r\ncontinue;\r\nif (!ip_tunnel_key_match(&t->parms, flags, key))\r\ncontinue;\r\nif (t->parms.link == link)\r\nreturn t;\r\nelse if (!cand)\r\ncand = t;\r\n}\r\nhash = ip_tunnel_hash(key, 0);\r\nhead = &itn->tunnels[hash];\r\nhlist_for_each_entry_rcu(t, head, hash_node) {\r\nif ((local != t->parms.iph.saddr || t->parms.iph.daddr != 0) &&\r\n(local != t->parms.iph.daddr || !ipv4_is_multicast(local)))\r\ncontinue;\r\nif (!(t->dev->flags & IFF_UP))\r\ncontinue;\r\nif (!ip_tunnel_key_match(&t->parms, flags, key))\r\ncontinue;\r\nif (t->parms.link == link)\r\nreturn t;\r\nelse if (!cand)\r\ncand = t;\r\n}\r\nif (flags & TUNNEL_NO_KEY)\r\ngoto skip_key_lookup;\r\nhlist_for_each_entry_rcu(t, head, hash_node) {\r\nif (t->parms.i_key != key ||\r\nt->parms.iph.saddr != 0 ||\r\nt->parms.iph.daddr != 0 ||\r\n!(t->dev->flags & IFF_UP))\r\ncontinue;\r\nif (t->parms.link == link)\r\nreturn t;\r\nelse if (!cand)\r\ncand = t;\r\n}\r\nskip_key_lookup:\r\nif (cand)\r\nreturn cand;\r\nt = rcu_dereference(itn->collect_md_tun);\r\nif (t)\r\nreturn t;\r\nif (itn->fb_tunnel_dev && itn->fb_tunnel_dev->flags & IFF_UP)\r\nreturn netdev_priv(itn->fb_tunnel_dev);\r\nreturn NULL;\r\n}\r\nstatic struct hlist_head *ip_bucket(struct ip_tunnel_net *itn,\r\nstruct ip_tunnel_parm *parms)\r\n{\r\nunsigned int h;\r\n__be32 remote;\r\n__be32 i_key = parms->i_key;\r\nif (parms->iph.daddr && !ipv4_is_multicast(parms->iph.daddr))\r\nremote = parms->iph.daddr;\r\nelse\r\nremote = 0;\r\nif (!(parms->i_flags & TUNNEL_KEY) && (parms->i_flags & VTI_ISVTI))\r\ni_key = 0;\r\nh = ip_tunnel_hash(i_key, remote);\r\nreturn &itn->tunnels[h];\r\n}\r\nstatic void ip_tunnel_add(struct ip_tunnel_net *itn, struct ip_tunnel *t)\r\n{\r\nstruct hlist_head *head = ip_bucket(itn, &t->parms);\r\nif (t->collect_md)\r\nrcu_assign_pointer(itn->collect_md_tun, t);\r\nhlist_add_head_rcu(&t->hash_node, head);\r\n}\r\nstatic void ip_tunnel_del(struct ip_tunnel_net *itn, struct ip_tunnel *t)\r\n{\r\nif (t->collect_md)\r\nrcu_assign_pointer(itn->collect_md_tun, NULL);\r\nhlist_del_init_rcu(&t->hash_node);\r\n}\r\nstatic struct ip_tunnel *ip_tunnel_find(struct ip_tunnel_net *itn,\r\nstruct ip_tunnel_parm *parms,\r\nint type)\r\n{\r\n__be32 remote = parms->iph.daddr;\r\n__be32 local = parms->iph.saddr;\r\n__be32 key = parms->i_key;\r\n__be16 flags = parms->i_flags;\r\nint link = parms->link;\r\nstruct ip_tunnel *t = NULL;\r\nstruct hlist_head *head = ip_bucket(itn, parms);\r\nhlist_for_each_entry_rcu(t, head, hash_node) {\r\nif (local == t->parms.iph.saddr &&\r\nremote == t->parms.iph.daddr &&\r\nlink == t->parms.link &&\r\ntype == t->dev->type &&\r\nip_tunnel_key_match(&t->parms, flags, key))\r\nbreak;\r\n}\r\nreturn t;\r\n}\r\nstatic struct net_device *__ip_tunnel_create(struct net *net,\r\nconst struct rtnl_link_ops *ops,\r\nstruct ip_tunnel_parm *parms)\r\n{\r\nint err;\r\nstruct ip_tunnel *tunnel;\r\nstruct net_device *dev;\r\nchar name[IFNAMSIZ];\r\nif (parms->name[0])\r\nstrlcpy(name, parms->name, IFNAMSIZ);\r\nelse {\r\nif (strlen(ops->kind) > (IFNAMSIZ - 3)) {\r\nerr = -E2BIG;\r\ngoto failed;\r\n}\r\nstrlcpy(name, ops->kind, IFNAMSIZ);\r\nstrncat(name, "%d", 2);\r\n}\r\nASSERT_RTNL();\r\ndev = alloc_netdev(ops->priv_size, name, NET_NAME_UNKNOWN, ops->setup);\r\nif (!dev) {\r\nerr = -ENOMEM;\r\ngoto failed;\r\n}\r\ndev_net_set(dev, net);\r\ndev->rtnl_link_ops = ops;\r\ntunnel = netdev_priv(dev);\r\ntunnel->parms = *parms;\r\ntunnel->net = net;\r\nerr = register_netdevice(dev);\r\nif (err)\r\ngoto failed_free;\r\nreturn dev;\r\nfailed_free:\r\nfree_netdev(dev);\r\nfailed:\r\nreturn ERR_PTR(err);\r\n}\r\nstatic inline void init_tunnel_flow(struct flowi4 *fl4,\r\nint proto,\r\n__be32 daddr, __be32 saddr,\r\n__be32 key, __u8 tos, int oif)\r\n{\r\nmemset(fl4, 0, sizeof(*fl4));\r\nfl4->flowi4_oif = oif;\r\nfl4->daddr = daddr;\r\nfl4->saddr = saddr;\r\nfl4->flowi4_tos = tos;\r\nfl4->flowi4_proto = proto;\r\nfl4->fl4_gre_key = key;\r\n}\r\nstatic int ip_tunnel_bind_dev(struct net_device *dev)\r\n{\r\nstruct net_device *tdev = NULL;\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nconst struct iphdr *iph;\r\nint hlen = LL_MAX_HEADER;\r\nint mtu = ETH_DATA_LEN;\r\nint t_hlen = tunnel->hlen + sizeof(struct iphdr);\r\niph = &tunnel->parms.iph;\r\nif (iph->daddr) {\r\nstruct flowi4 fl4;\r\nstruct rtable *rt;\r\ninit_tunnel_flow(&fl4, iph->protocol, iph->daddr,\r\niph->saddr, tunnel->parms.o_key,\r\nRT_TOS(iph->tos), tunnel->parms.link);\r\nrt = ip_route_output_key(tunnel->net, &fl4);\r\nif (!IS_ERR(rt)) {\r\ntdev = rt->dst.dev;\r\nip_rt_put(rt);\r\n}\r\nif (dev->type != ARPHRD_ETHER)\r\ndev->flags |= IFF_POINTOPOINT;\r\ndst_cache_reset(&tunnel->dst_cache);\r\n}\r\nif (!tdev && tunnel->parms.link)\r\ntdev = __dev_get_by_index(tunnel->net, tunnel->parms.link);\r\nif (tdev) {\r\nhlen = tdev->hard_header_len + tdev->needed_headroom;\r\nmtu = tdev->mtu;\r\n}\r\ndev->needed_headroom = t_hlen + hlen;\r\nmtu -= (dev->hard_header_len + t_hlen);\r\nif (mtu < 68)\r\nmtu = 68;\r\nreturn mtu;\r\n}\r\nstatic struct ip_tunnel *ip_tunnel_create(struct net *net,\r\nstruct ip_tunnel_net *itn,\r\nstruct ip_tunnel_parm *parms)\r\n{\r\nstruct ip_tunnel *nt;\r\nstruct net_device *dev;\r\nint t_hlen;\r\nBUG_ON(!itn->fb_tunnel_dev);\r\ndev = __ip_tunnel_create(net, itn->fb_tunnel_dev->rtnl_link_ops, parms);\r\nif (IS_ERR(dev))\r\nreturn ERR_CAST(dev);\r\ndev->mtu = ip_tunnel_bind_dev(dev);\r\nnt = netdev_priv(dev);\r\nt_hlen = nt->hlen + sizeof(struct iphdr);\r\ndev->min_mtu = ETH_MIN_MTU;\r\ndev->max_mtu = 0xFFF8 - dev->hard_header_len - t_hlen;\r\nip_tunnel_add(itn, nt);\r\nreturn nt;\r\n}\r\nint ip_tunnel_rcv(struct ip_tunnel *tunnel, struct sk_buff *skb,\r\nconst struct tnl_ptk_info *tpi, struct metadata_dst *tun_dst,\r\nbool log_ecn_error)\r\n{\r\nstruct pcpu_sw_netstats *tstats;\r\nconst struct iphdr *iph = ip_hdr(skb);\r\nint err;\r\n#ifdef CONFIG_NET_IPGRE_BROADCAST\r\nif (ipv4_is_multicast(iph->daddr)) {\r\ntunnel->dev->stats.multicast++;\r\nskb->pkt_type = PACKET_BROADCAST;\r\n}\r\n#endif\r\nif ((!(tpi->flags&TUNNEL_CSUM) && (tunnel->parms.i_flags&TUNNEL_CSUM)) ||\r\n((tpi->flags&TUNNEL_CSUM) && !(tunnel->parms.i_flags&TUNNEL_CSUM))) {\r\ntunnel->dev->stats.rx_crc_errors++;\r\ntunnel->dev->stats.rx_errors++;\r\ngoto drop;\r\n}\r\nif (tunnel->parms.i_flags&TUNNEL_SEQ) {\r\nif (!(tpi->flags&TUNNEL_SEQ) ||\r\n(tunnel->i_seqno && (s32)(ntohl(tpi->seq) - tunnel->i_seqno) < 0)) {\r\ntunnel->dev->stats.rx_fifo_errors++;\r\ntunnel->dev->stats.rx_errors++;\r\ngoto drop;\r\n}\r\ntunnel->i_seqno = ntohl(tpi->seq) + 1;\r\n}\r\nskb_reset_network_header(skb);\r\nerr = IP_ECN_decapsulate(iph, skb);\r\nif (unlikely(err)) {\r\nif (log_ecn_error)\r\nnet_info_ratelimited("non-ECT from %pI4 with TOS=%#x\n",\r\n&iph->saddr, iph->tos);\r\nif (err > 1) {\r\n++tunnel->dev->stats.rx_frame_errors;\r\n++tunnel->dev->stats.rx_errors;\r\ngoto drop;\r\n}\r\n}\r\ntstats = this_cpu_ptr(tunnel->dev->tstats);\r\nu64_stats_update_begin(&tstats->syncp);\r\ntstats->rx_packets++;\r\ntstats->rx_bytes += skb->len;\r\nu64_stats_update_end(&tstats->syncp);\r\nskb_scrub_packet(skb, !net_eq(tunnel->net, dev_net(tunnel->dev)));\r\nif (tunnel->dev->type == ARPHRD_ETHER) {\r\nskb->protocol = eth_type_trans(skb, tunnel->dev);\r\nskb_postpull_rcsum(skb, eth_hdr(skb), ETH_HLEN);\r\n} else {\r\nskb->dev = tunnel->dev;\r\n}\r\nif (tun_dst)\r\nskb_dst_set(skb, (struct dst_entry *)tun_dst);\r\ngro_cells_receive(&tunnel->gro_cells, skb);\r\nreturn 0;\r\ndrop:\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nint ip_tunnel_encap_add_ops(const struct ip_tunnel_encap_ops *ops,\r\nunsigned int num)\r\n{\r\nif (num >= MAX_IPTUN_ENCAP_OPS)\r\nreturn -ERANGE;\r\nreturn !cmpxchg((const struct ip_tunnel_encap_ops **)\r\n&iptun_encaps[num],\r\nNULL, ops) ? 0 : -1;\r\n}\r\nint ip_tunnel_encap_del_ops(const struct ip_tunnel_encap_ops *ops,\r\nunsigned int num)\r\n{\r\nint ret;\r\nif (num >= MAX_IPTUN_ENCAP_OPS)\r\nreturn -ERANGE;\r\nret = (cmpxchg((const struct ip_tunnel_encap_ops **)\r\n&iptun_encaps[num],\r\nops, NULL) == ops) ? 0 : -1;\r\nsynchronize_net();\r\nreturn ret;\r\n}\r\nint ip_tunnel_encap_setup(struct ip_tunnel *t,\r\nstruct ip_tunnel_encap *ipencap)\r\n{\r\nint hlen;\r\nmemset(&t->encap, 0, sizeof(t->encap));\r\nhlen = ip_encap_hlen(ipencap);\r\nif (hlen < 0)\r\nreturn hlen;\r\nt->encap.type = ipencap->type;\r\nt->encap.sport = ipencap->sport;\r\nt->encap.dport = ipencap->dport;\r\nt->encap.flags = ipencap->flags;\r\nt->encap_hlen = hlen;\r\nt->hlen = t->encap_hlen + t->tun_hlen;\r\nreturn 0;\r\n}\r\nstatic int tnl_update_pmtu(struct net_device *dev, struct sk_buff *skb,\r\nstruct rtable *rt, __be16 df,\r\nconst struct iphdr *inner_iph)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nint pkt_size = skb->len - tunnel->hlen - dev->hard_header_len;\r\nint mtu;\r\nif (df)\r\nmtu = dst_mtu(&rt->dst) - dev->hard_header_len\r\n- sizeof(struct iphdr) - tunnel->hlen;\r\nelse\r\nmtu = skb_dst(skb) ? dst_mtu(skb_dst(skb)) : dev->mtu;\r\nif (skb_dst(skb))\r\nskb_dst(skb)->ops->update_pmtu(skb_dst(skb), NULL, skb, mtu);\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\nif (!skb_is_gso(skb) &&\r\n(inner_iph->frag_off & htons(IP_DF)) &&\r\nmtu < pkt_size) {\r\nmemset(IPCB(skb), 0, sizeof(*IPCB(skb)));\r\nicmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, htonl(mtu));\r\nreturn -E2BIG;\r\n}\r\n}\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nelse if (skb->protocol == htons(ETH_P_IPV6)) {\r\nstruct rt6_info *rt6 = (struct rt6_info *)skb_dst(skb);\r\nif (rt6 && mtu < dst_mtu(skb_dst(skb)) &&\r\nmtu >= IPV6_MIN_MTU) {\r\nif ((tunnel->parms.iph.daddr &&\r\n!ipv4_is_multicast(tunnel->parms.iph.daddr)) ||\r\nrt6->rt6i_dst.plen == 128) {\r\nrt6->rt6i_flags |= RTF_MODIFIED;\r\ndst_metric_set(skb_dst(skb), RTAX_MTU, mtu);\r\n}\r\n}\r\nif (!skb_is_gso(skb) && mtu >= IPV6_MIN_MTU &&\r\nmtu < pkt_size) {\r\nicmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu);\r\nreturn -E2BIG;\r\n}\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nvoid ip_md_tunnel_xmit(struct sk_buff *skb, struct net_device *dev, u8 proto)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nu32 headroom = sizeof(struct iphdr);\r\nstruct ip_tunnel_info *tun_info;\r\nconst struct ip_tunnel_key *key;\r\nconst struct iphdr *inner_iph;\r\nstruct rtable *rt;\r\nstruct flowi4 fl4;\r\n__be16 df = 0;\r\nu8 tos, ttl;\r\ntun_info = skb_tunnel_info(skb);\r\nif (unlikely(!tun_info || !(tun_info->mode & IP_TUNNEL_INFO_TX) ||\r\nip_tunnel_info_af(tun_info) != AF_INET))\r\ngoto tx_error;\r\nkey = &tun_info->key;\r\nmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\r\ninner_iph = (const struct iphdr *)skb_inner_network_header(skb);\r\ntos = key->tos;\r\nif (tos == 1) {\r\nif (skb->protocol == htons(ETH_P_IP))\r\ntos = inner_iph->tos;\r\nelse if (skb->protocol == htons(ETH_P_IPV6))\r\ntos = ipv6_get_dsfield((const struct ipv6hdr *)inner_iph);\r\n}\r\ninit_tunnel_flow(&fl4, proto, key->u.ipv4.dst, key->u.ipv4.src, 0,\r\nRT_TOS(tos), tunnel->parms.link);\r\nif (tunnel->encap.type != TUNNEL_ENCAP_NONE)\r\ngoto tx_error;\r\nrt = ip_route_output_key(tunnel->net, &fl4);\r\nif (IS_ERR(rt)) {\r\ndev->stats.tx_carrier_errors++;\r\ngoto tx_error;\r\n}\r\nif (rt->dst.dev == dev) {\r\nip_rt_put(rt);\r\ndev->stats.collisions++;\r\ngoto tx_error;\r\n}\r\ntos = ip_tunnel_ecn_encap(tos, inner_iph, skb);\r\nttl = key->ttl;\r\nif (ttl == 0) {\r\nif (skb->protocol == htons(ETH_P_IP))\r\nttl = inner_iph->ttl;\r\nelse if (skb->protocol == htons(ETH_P_IPV6))\r\nttl = ((const struct ipv6hdr *)inner_iph)->hop_limit;\r\nelse\r\nttl = ip4_dst_hoplimit(&rt->dst);\r\n}\r\nif (key->tun_flags & TUNNEL_DONT_FRAGMENT)\r\ndf = htons(IP_DF);\r\nelse if (skb->protocol == htons(ETH_P_IP))\r\ndf = inner_iph->frag_off & htons(IP_DF);\r\nheadroom += LL_RESERVED_SPACE(rt->dst.dev) + rt->dst.header_len;\r\nif (headroom > dev->needed_headroom)\r\ndev->needed_headroom = headroom;\r\nif (skb_cow_head(skb, dev->needed_headroom)) {\r\nip_rt_put(rt);\r\ngoto tx_dropped;\r\n}\r\niptunnel_xmit(NULL, rt, skb, fl4.saddr, fl4.daddr, proto, key->tos,\r\nkey->ttl, df, !net_eq(tunnel->net, dev_net(dev)));\r\nreturn;\r\ntx_error:\r\ndev->stats.tx_errors++;\r\ngoto kfree;\r\ntx_dropped:\r\ndev->stats.tx_dropped++;\r\nkfree:\r\nkfree_skb(skb);\r\n}\r\nvoid ip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,\r\nconst struct iphdr *tnl_params, u8 protocol)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nconst struct iphdr *inner_iph;\r\nstruct flowi4 fl4;\r\nu8 tos, ttl;\r\n__be16 df;\r\nstruct rtable *rt;\r\nunsigned int max_headroom;\r\n__be32 dst;\r\nbool connected;\r\ninner_iph = (const struct iphdr *)skb_inner_network_header(skb);\r\nconnected = (tunnel->parms.iph.daddr != 0);\r\nmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\r\ndst = tnl_params->daddr;\r\nif (dst == 0) {\r\nif (!skb_dst(skb)) {\r\ndev->stats.tx_fifo_errors++;\r\ngoto tx_error;\r\n}\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\nrt = skb_rtable(skb);\r\ndst = rt_nexthop(rt, inner_iph->daddr);\r\n}\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nelse if (skb->protocol == htons(ETH_P_IPV6)) {\r\nconst struct in6_addr *addr6;\r\nstruct neighbour *neigh;\r\nbool do_tx_error_icmp;\r\nint addr_type;\r\nneigh = dst_neigh_lookup(skb_dst(skb),\r\n&ipv6_hdr(skb)->daddr);\r\nif (!neigh)\r\ngoto tx_error;\r\naddr6 = (const struct in6_addr *)&neigh->primary_key;\r\naddr_type = ipv6_addr_type(addr6);\r\nif (addr_type == IPV6_ADDR_ANY) {\r\naddr6 = &ipv6_hdr(skb)->daddr;\r\naddr_type = ipv6_addr_type(addr6);\r\n}\r\nif ((addr_type & IPV6_ADDR_COMPATv4) == 0)\r\ndo_tx_error_icmp = true;\r\nelse {\r\ndo_tx_error_icmp = false;\r\ndst = addr6->s6_addr32[3];\r\n}\r\nneigh_release(neigh);\r\nif (do_tx_error_icmp)\r\ngoto tx_error_icmp;\r\n}\r\n#endif\r\nelse\r\ngoto tx_error;\r\nconnected = false;\r\n}\r\ntos = tnl_params->tos;\r\nif (tos & 0x1) {\r\ntos &= ~0x1;\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\ntos = inner_iph->tos;\r\nconnected = false;\r\n} else if (skb->protocol == htons(ETH_P_IPV6)) {\r\ntos = ipv6_get_dsfield((const struct ipv6hdr *)inner_iph);\r\nconnected = false;\r\n}\r\n}\r\ninit_tunnel_flow(&fl4, protocol, dst, tnl_params->saddr,\r\ntunnel->parms.o_key, RT_TOS(tos), tunnel->parms.link);\r\nif (ip_tunnel_encap(skb, tunnel, &protocol, &fl4) < 0)\r\ngoto tx_error;\r\nrt = connected ? dst_cache_get_ip4(&tunnel->dst_cache, &fl4.saddr) :\r\nNULL;\r\nif (!rt) {\r\nrt = ip_route_output_key(tunnel->net, &fl4);\r\nif (IS_ERR(rt)) {\r\ndev->stats.tx_carrier_errors++;\r\ngoto tx_error;\r\n}\r\nif (connected)\r\ndst_cache_set_ip4(&tunnel->dst_cache, &rt->dst,\r\nfl4.saddr);\r\n}\r\nif (rt->dst.dev == dev) {\r\nip_rt_put(rt);\r\ndev->stats.collisions++;\r\ngoto tx_error;\r\n}\r\nif (tnl_update_pmtu(dev, skb, rt, tnl_params->frag_off, inner_iph)) {\r\nip_rt_put(rt);\r\ngoto tx_error;\r\n}\r\nif (tunnel->err_count > 0) {\r\nif (time_before(jiffies,\r\ntunnel->err_time + IPTUNNEL_ERR_TIMEO)) {\r\ntunnel->err_count--;\r\ndst_link_failure(skb);\r\n} else\r\ntunnel->err_count = 0;\r\n}\r\ntos = ip_tunnel_ecn_encap(tos, inner_iph, skb);\r\nttl = tnl_params->ttl;\r\nif (ttl == 0) {\r\nif (skb->protocol == htons(ETH_P_IP))\r\nttl = inner_iph->ttl;\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nelse if (skb->protocol == htons(ETH_P_IPV6))\r\nttl = ((const struct ipv6hdr *)inner_iph)->hop_limit;\r\n#endif\r\nelse\r\nttl = ip4_dst_hoplimit(&rt->dst);\r\n}\r\ndf = tnl_params->frag_off;\r\nif (skb->protocol == htons(ETH_P_IP) && !tunnel->ignore_df)\r\ndf |= (inner_iph->frag_off&htons(IP_DF));\r\nmax_headroom = LL_RESERVED_SPACE(rt->dst.dev) + sizeof(struct iphdr)\r\n+ rt->dst.header_len + ip_encap_hlen(&tunnel->encap);\r\nif (max_headroom > dev->needed_headroom)\r\ndev->needed_headroom = max_headroom;\r\nif (skb_cow_head(skb, dev->needed_headroom)) {\r\nip_rt_put(rt);\r\ndev->stats.tx_dropped++;\r\nkfree_skb(skb);\r\nreturn;\r\n}\r\niptunnel_xmit(NULL, rt, skb, fl4.saddr, fl4.daddr, protocol, tos, ttl,\r\ndf, !net_eq(tunnel->net, dev_net(dev)));\r\nreturn;\r\n#if IS_ENABLED(CONFIG_IPV6)\r\ntx_error_icmp:\r\ndst_link_failure(skb);\r\n#endif\r\ntx_error:\r\ndev->stats.tx_errors++;\r\nkfree_skb(skb);\r\n}\r\nstatic void ip_tunnel_update(struct ip_tunnel_net *itn,\r\nstruct ip_tunnel *t,\r\nstruct net_device *dev,\r\nstruct ip_tunnel_parm *p,\r\nbool set_mtu)\r\n{\r\nip_tunnel_del(itn, t);\r\nt->parms.iph.saddr = p->iph.saddr;\r\nt->parms.iph.daddr = p->iph.daddr;\r\nt->parms.i_key = p->i_key;\r\nt->parms.o_key = p->o_key;\r\nif (dev->type != ARPHRD_ETHER) {\r\nmemcpy(dev->dev_addr, &p->iph.saddr, 4);\r\nmemcpy(dev->broadcast, &p->iph.daddr, 4);\r\n}\r\nip_tunnel_add(itn, t);\r\nt->parms.iph.ttl = p->iph.ttl;\r\nt->parms.iph.tos = p->iph.tos;\r\nt->parms.iph.frag_off = p->iph.frag_off;\r\nif (t->parms.link != p->link) {\r\nint mtu;\r\nt->parms.link = p->link;\r\nmtu = ip_tunnel_bind_dev(dev);\r\nif (set_mtu)\r\ndev->mtu = mtu;\r\n}\r\ndst_cache_reset(&t->dst_cache);\r\nnetdev_state_change(dev);\r\n}\r\nint ip_tunnel_ioctl(struct net_device *dev, struct ip_tunnel_parm *p, int cmd)\r\n{\r\nint err = 0;\r\nstruct ip_tunnel *t = netdev_priv(dev);\r\nstruct net *net = t->net;\r\nstruct ip_tunnel_net *itn = net_generic(net, t->ip_tnl_net_id);\r\nBUG_ON(!itn->fb_tunnel_dev);\r\nswitch (cmd) {\r\ncase SIOCGETTUNNEL:\r\nif (dev == itn->fb_tunnel_dev) {\r\nt = ip_tunnel_find(itn, p, itn->fb_tunnel_dev->type);\r\nif (!t)\r\nt = netdev_priv(dev);\r\n}\r\nmemcpy(p, &t->parms, sizeof(*p));\r\nbreak;\r\ncase SIOCADDTUNNEL:\r\ncase SIOCCHGTUNNEL:\r\nerr = -EPERM;\r\nif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\r\ngoto done;\r\nif (p->iph.ttl)\r\np->iph.frag_off |= htons(IP_DF);\r\nif (!(p->i_flags & VTI_ISVTI)) {\r\nif (!(p->i_flags & TUNNEL_KEY))\r\np->i_key = 0;\r\nif (!(p->o_flags & TUNNEL_KEY))\r\np->o_key = 0;\r\n}\r\nt = ip_tunnel_find(itn, p, itn->fb_tunnel_dev->type);\r\nif (cmd == SIOCADDTUNNEL) {\r\nif (!t) {\r\nt = ip_tunnel_create(net, itn, p);\r\nerr = PTR_ERR_OR_ZERO(t);\r\nbreak;\r\n}\r\nerr = -EEXIST;\r\nbreak;\r\n}\r\nif (dev != itn->fb_tunnel_dev && cmd == SIOCCHGTUNNEL) {\r\nif (t) {\r\nif (t->dev != dev) {\r\nerr = -EEXIST;\r\nbreak;\r\n}\r\n} else {\r\nunsigned int nflags = 0;\r\nif (ipv4_is_multicast(p->iph.daddr))\r\nnflags = IFF_BROADCAST;\r\nelse if (p->iph.daddr)\r\nnflags = IFF_POINTOPOINT;\r\nif ((dev->flags^nflags)&(IFF_POINTOPOINT|IFF_BROADCAST)) {\r\nerr = -EINVAL;\r\nbreak;\r\n}\r\nt = netdev_priv(dev);\r\n}\r\n}\r\nif (t) {\r\nerr = 0;\r\nip_tunnel_update(itn, t, dev, p, true);\r\n} else {\r\nerr = -ENOENT;\r\n}\r\nbreak;\r\ncase SIOCDELTUNNEL:\r\nerr = -EPERM;\r\nif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\r\ngoto done;\r\nif (dev == itn->fb_tunnel_dev) {\r\nerr = -ENOENT;\r\nt = ip_tunnel_find(itn, p, itn->fb_tunnel_dev->type);\r\nif (!t)\r\ngoto done;\r\nerr = -EPERM;\r\nif (t == netdev_priv(itn->fb_tunnel_dev))\r\ngoto done;\r\ndev = t->dev;\r\n}\r\nunregister_netdevice(dev);\r\nerr = 0;\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\n}\r\ndone:\r\nreturn err;\r\n}\r\nint __ip_tunnel_change_mtu(struct net_device *dev, int new_mtu, bool strict)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nint t_hlen = tunnel->hlen + sizeof(struct iphdr);\r\nint max_mtu = 0xFFF8 - dev->hard_header_len - t_hlen;\r\nif (new_mtu < ETH_MIN_MTU)\r\nreturn -EINVAL;\r\nif (new_mtu > max_mtu) {\r\nif (strict)\r\nreturn -EINVAL;\r\nnew_mtu = max_mtu;\r\n}\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nint ip_tunnel_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nreturn __ip_tunnel_change_mtu(dev, new_mtu, true);\r\n}\r\nstatic void ip_tunnel_dev_free(struct net_device *dev)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\ngro_cells_destroy(&tunnel->gro_cells);\r\ndst_cache_destroy(&tunnel->dst_cache);\r\nfree_percpu(dev->tstats);\r\nfree_netdev(dev);\r\n}\r\nvoid ip_tunnel_dellink(struct net_device *dev, struct list_head *head)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nstruct ip_tunnel_net *itn;\r\nitn = net_generic(tunnel->net, tunnel->ip_tnl_net_id);\r\nif (itn->fb_tunnel_dev != dev) {\r\nip_tunnel_del(itn, netdev_priv(dev));\r\nunregister_netdevice_queue(dev, head);\r\n}\r\n}\r\nstruct net *ip_tunnel_get_link_net(const struct net_device *dev)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nreturn tunnel->net;\r\n}\r\nint ip_tunnel_get_iflink(const struct net_device *dev)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nreturn tunnel->parms.link;\r\n}\r\nint ip_tunnel_init_net(struct net *net, unsigned int ip_tnl_net_id,\r\nstruct rtnl_link_ops *ops, char *devname)\r\n{\r\nstruct ip_tunnel_net *itn = net_generic(net, ip_tnl_net_id);\r\nstruct ip_tunnel_parm parms;\r\nunsigned int i;\r\nfor (i = 0; i < IP_TNL_HASH_SIZE; i++)\r\nINIT_HLIST_HEAD(&itn->tunnels[i]);\r\nif (!ops) {\r\nitn->fb_tunnel_dev = NULL;\r\nreturn 0;\r\n}\r\nmemset(&parms, 0, sizeof(parms));\r\nif (devname)\r\nstrlcpy(parms.name, devname, IFNAMSIZ);\r\nrtnl_lock();\r\nitn->fb_tunnel_dev = __ip_tunnel_create(net, ops, &parms);\r\nif (!IS_ERR(itn->fb_tunnel_dev)) {\r\nitn->fb_tunnel_dev->features |= NETIF_F_NETNS_LOCAL;\r\nitn->fb_tunnel_dev->mtu = ip_tunnel_bind_dev(itn->fb_tunnel_dev);\r\nip_tunnel_add(itn, netdev_priv(itn->fb_tunnel_dev));\r\n}\r\nrtnl_unlock();\r\nreturn PTR_ERR_OR_ZERO(itn->fb_tunnel_dev);\r\n}\r\nstatic void ip_tunnel_destroy(struct ip_tunnel_net *itn, struct list_head *head,\r\nstruct rtnl_link_ops *ops)\r\n{\r\nstruct net *net = dev_net(itn->fb_tunnel_dev);\r\nstruct net_device *dev, *aux;\r\nint h;\r\nfor_each_netdev_safe(net, dev, aux)\r\nif (dev->rtnl_link_ops == ops)\r\nunregister_netdevice_queue(dev, head);\r\nfor (h = 0; h < IP_TNL_HASH_SIZE; h++) {\r\nstruct ip_tunnel *t;\r\nstruct hlist_node *n;\r\nstruct hlist_head *thead = &itn->tunnels[h];\r\nhlist_for_each_entry_safe(t, n, thead, hash_node)\r\nif (!net_eq(dev_net(t->dev), net))\r\nunregister_netdevice_queue(t->dev, head);\r\n}\r\n}\r\nvoid ip_tunnel_delete_net(struct ip_tunnel_net *itn, struct rtnl_link_ops *ops)\r\n{\r\nLIST_HEAD(list);\r\nrtnl_lock();\r\nip_tunnel_destroy(itn, &list, ops);\r\nunregister_netdevice_many(&list);\r\nrtnl_unlock();\r\n}\r\nint ip_tunnel_newlink(struct net_device *dev, struct nlattr *tb[],\r\nstruct ip_tunnel_parm *p)\r\n{\r\nstruct ip_tunnel *nt;\r\nstruct net *net = dev_net(dev);\r\nstruct ip_tunnel_net *itn;\r\nint mtu;\r\nint err;\r\nnt = netdev_priv(dev);\r\nitn = net_generic(net, nt->ip_tnl_net_id);\r\nif (nt->collect_md) {\r\nif (rtnl_dereference(itn->collect_md_tun))\r\nreturn -EEXIST;\r\n} else {\r\nif (ip_tunnel_find(itn, p, dev->type))\r\nreturn -EEXIST;\r\n}\r\nnt->net = net;\r\nnt->parms = *p;\r\nerr = register_netdevice(dev);\r\nif (err)\r\ngoto out;\r\nif (dev->type == ARPHRD_ETHER && !tb[IFLA_ADDRESS])\r\neth_hw_addr_random(dev);\r\nmtu = ip_tunnel_bind_dev(dev);\r\nif (!tb[IFLA_MTU])\r\ndev->mtu = mtu;\r\nip_tunnel_add(itn, nt);\r\nout:\r\nreturn err;\r\n}\r\nint ip_tunnel_changelink(struct net_device *dev, struct nlattr *tb[],\r\nstruct ip_tunnel_parm *p)\r\n{\r\nstruct ip_tunnel *t;\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nstruct net *net = tunnel->net;\r\nstruct ip_tunnel_net *itn = net_generic(net, tunnel->ip_tnl_net_id);\r\nif (dev == itn->fb_tunnel_dev)\r\nreturn -EINVAL;\r\nt = ip_tunnel_find(itn, p, dev->type);\r\nif (t) {\r\nif (t->dev != dev)\r\nreturn -EEXIST;\r\n} else {\r\nt = tunnel;\r\nif (dev->type != ARPHRD_ETHER) {\r\nunsigned int nflags = 0;\r\nif (ipv4_is_multicast(p->iph.daddr))\r\nnflags = IFF_BROADCAST;\r\nelse if (p->iph.daddr)\r\nnflags = IFF_POINTOPOINT;\r\nif ((dev->flags ^ nflags) &\r\n(IFF_POINTOPOINT | IFF_BROADCAST))\r\nreturn -EINVAL;\r\n}\r\n}\r\nip_tunnel_update(itn, t, dev, p, !tb[IFLA_MTU]);\r\nreturn 0;\r\n}\r\nint ip_tunnel_init(struct net_device *dev)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nstruct iphdr *iph = &tunnel->parms.iph;\r\nint err;\r\ndev->destructor = ip_tunnel_dev_free;\r\ndev->tstats = netdev_alloc_pcpu_stats(struct pcpu_sw_netstats);\r\nif (!dev->tstats)\r\nreturn -ENOMEM;\r\nerr = dst_cache_init(&tunnel->dst_cache, GFP_KERNEL);\r\nif (err) {\r\nfree_percpu(dev->tstats);\r\nreturn err;\r\n}\r\nerr = gro_cells_init(&tunnel->gro_cells, dev);\r\nif (err) {\r\ndst_cache_destroy(&tunnel->dst_cache);\r\nfree_percpu(dev->tstats);\r\nreturn err;\r\n}\r\ntunnel->dev = dev;\r\ntunnel->net = dev_net(dev);\r\nstrcpy(tunnel->parms.name, dev->name);\r\niph->version = 4;\r\niph->ihl = 5;\r\nif (tunnel->collect_md) {\r\ndev->features |= NETIF_F_NETNS_LOCAL;\r\nnetif_keep_dst(dev);\r\n}\r\nreturn 0;\r\n}\r\nvoid ip_tunnel_uninit(struct net_device *dev)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\nstruct net *net = tunnel->net;\r\nstruct ip_tunnel_net *itn;\r\nitn = net_generic(net, tunnel->ip_tnl_net_id);\r\nif (itn->fb_tunnel_dev != dev)\r\nip_tunnel_del(itn, netdev_priv(dev));\r\ndst_cache_reset(&tunnel->dst_cache);\r\n}\r\nvoid ip_tunnel_setup(struct net_device *dev, unsigned int net_id)\r\n{\r\nstruct ip_tunnel *tunnel = netdev_priv(dev);\r\ntunnel->ip_tnl_net_id = net_id;\r\n}
