void *drbd_md_get_buffer(struct drbd_device *device, const char *intent)\r\n{\r\nint r;\r\nwait_event(device->misc_wait,\r\n(r = atomic_cmpxchg(&device->md_io.in_use, 0, 1)) == 0 ||\r\ndevice->state.disk <= D_FAILED);\r\nif (r)\r\nreturn NULL;\r\ndevice->md_io.current_use = intent;\r\ndevice->md_io.start_jif = jiffies;\r\ndevice->md_io.submit_jif = device->md_io.start_jif - 1;\r\nreturn page_address(device->md_io.page);\r\n}\r\nvoid drbd_md_put_buffer(struct drbd_device *device)\r\n{\r\nif (atomic_dec_and_test(&device->md_io.in_use))\r\nwake_up(&device->misc_wait);\r\n}\r\nvoid wait_until_done_or_force_detached(struct drbd_device *device, struct drbd_backing_dev *bdev,\r\nunsigned int *done)\r\n{\r\nlong dt;\r\nrcu_read_lock();\r\ndt = rcu_dereference(bdev->disk_conf)->disk_timeout;\r\nrcu_read_unlock();\r\ndt = dt * HZ / 10;\r\nif (dt == 0)\r\ndt = MAX_SCHEDULE_TIMEOUT;\r\ndt = wait_event_timeout(device->misc_wait,\r\n*done || test_bit(FORCE_DETACH, &device->flags), dt);\r\nif (dt == 0) {\r\ndrbd_err(device, "meta-data IO operation timed out\n");\r\ndrbd_chk_io_error(device, 1, DRBD_FORCE_DETACH);\r\n}\r\n}\r\nstatic int _drbd_md_sync_page_io(struct drbd_device *device,\r\nstruct drbd_backing_dev *bdev,\r\nsector_t sector, int op)\r\n{\r\nstruct bio *bio;\r\nconst int size = 4096;\r\nint err, op_flags = 0;\r\ndevice->md_io.done = 0;\r\ndevice->md_io.error = -ENODEV;\r\nif ((op == REQ_OP_WRITE) && !test_bit(MD_NO_FUA, &device->flags))\r\nop_flags |= REQ_FUA | REQ_PREFLUSH;\r\nop_flags |= REQ_SYNC;\r\nbio = bio_alloc_drbd(GFP_NOIO);\r\nbio->bi_bdev = bdev->md_bdev;\r\nbio->bi_iter.bi_sector = sector;\r\nerr = -EIO;\r\nif (bio_add_page(bio, device->md_io.page, size, 0) != size)\r\ngoto out;\r\nbio->bi_private = device;\r\nbio->bi_end_io = drbd_md_endio;\r\nbio_set_op_attrs(bio, op, op_flags);\r\nif (op != REQ_OP_WRITE && device->state.disk == D_DISKLESS && device->ldev == NULL)\r\n;\r\nelse if (!get_ldev_if_state(device, D_ATTACHING)) {\r\ndrbd_err(device, "ASSERT FAILED: get_ldev_if_state() == 1 in _drbd_md_sync_page_io()\n");\r\nerr = -ENODEV;\r\ngoto out;\r\n}\r\nbio_get(bio);\r\natomic_inc(&device->md_io.in_use);\r\ndevice->md_io.submit_jif = jiffies;\r\nif (drbd_insert_fault(device, (op == REQ_OP_WRITE) ? DRBD_FAULT_MD_WR : DRBD_FAULT_MD_RD))\r\nbio_io_error(bio);\r\nelse\r\nsubmit_bio(bio);\r\nwait_until_done_or_force_detached(device, bdev, &device->md_io.done);\r\nif (!bio->bi_error)\r\nerr = device->md_io.error;\r\nout:\r\nbio_put(bio);\r\nreturn err;\r\n}\r\nint drbd_md_sync_page_io(struct drbd_device *device, struct drbd_backing_dev *bdev,\r\nsector_t sector, int op)\r\n{\r\nint err;\r\nD_ASSERT(device, atomic_read(&device->md_io.in_use) == 1);\r\nBUG_ON(!bdev->md_bdev);\r\ndynamic_drbd_dbg(device, "meta_data io: %s [%d]:%s(,%llus,%s) %pS\n",\r\ncurrent->comm, current->pid, __func__,\r\n(unsigned long long)sector, (op == REQ_OP_WRITE) ? "WRITE" : "READ",\r\n(void*)_RET_IP_ );\r\nif (sector < drbd_md_first_sector(bdev) ||\r\nsector + 7 > drbd_md_last_sector(bdev))\r\ndrbd_alert(device, "%s [%d]:%s(,%llus,%s) out of range md access!\n",\r\ncurrent->comm, current->pid, __func__,\r\n(unsigned long long)sector,\r\n(op == REQ_OP_WRITE) ? "WRITE" : "READ");\r\nerr = _drbd_md_sync_page_io(device, bdev, sector, op);\r\nif (err) {\r\ndrbd_err(device, "drbd_md_sync_page_io(,%llus,%s) failed with error %d\n",\r\n(unsigned long long)sector,\r\n(op == REQ_OP_WRITE) ? "WRITE" : "READ", err);\r\n}\r\nreturn err;\r\n}\r\nstatic struct bm_extent *find_active_resync_extent(struct drbd_device *device, unsigned int enr)\r\n{\r\nstruct lc_element *tmp;\r\ntmp = lc_find(device->resync, enr/AL_EXT_PER_BM_SECT);\r\nif (unlikely(tmp != NULL)) {\r\nstruct bm_extent *bm_ext = lc_entry(tmp, struct bm_extent, lce);\r\nif (test_bit(BME_NO_WRITES, &bm_ext->flags))\r\nreturn bm_ext;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct lc_element *_al_get(struct drbd_device *device, unsigned int enr, bool nonblock)\r\n{\r\nstruct lc_element *al_ext;\r\nstruct bm_extent *bm_ext;\r\nint wake;\r\nspin_lock_irq(&device->al_lock);\r\nbm_ext = find_active_resync_extent(device, enr);\r\nif (bm_ext) {\r\nwake = !test_and_set_bit(BME_PRIORITY, &bm_ext->flags);\r\nspin_unlock_irq(&device->al_lock);\r\nif (wake)\r\nwake_up(&device->al_wait);\r\nreturn NULL;\r\n}\r\nif (nonblock)\r\nal_ext = lc_try_get(device->act_log, enr);\r\nelse\r\nal_ext = lc_get(device->act_log, enr);\r\nspin_unlock_irq(&device->al_lock);\r\nreturn al_ext;\r\n}\r\nbool drbd_al_begin_io_fastpath(struct drbd_device *device, struct drbd_interval *i)\r\n{\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nD_ASSERT(device, first <= last);\r\nD_ASSERT(device, atomic_read(&device->local_cnt) > 0);\r\nif (first != last)\r\nreturn false;\r\nreturn _al_get(device, first, true);\r\n}\r\nbool drbd_al_begin_io_prepare(struct drbd_device *device, struct drbd_interval *i)\r\n{\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nunsigned enr;\r\nbool need_transaction = false;\r\nD_ASSERT(device, first <= last);\r\nD_ASSERT(device, atomic_read(&device->local_cnt) > 0);\r\nfor (enr = first; enr <= last; enr++) {\r\nstruct lc_element *al_ext;\r\nwait_event(device->al_wait,\r\n(al_ext = _al_get(device, enr, false)) != NULL);\r\nif (al_ext->lc_number != enr)\r\nneed_transaction = true;\r\n}\r\nreturn need_transaction;\r\n}\r\nstatic unsigned int al_extent_to_bm_page(unsigned int al_enr)\r\n{\r\nreturn al_enr >>\r\n((PAGE_SHIFT + 3) -\r\n(AL_EXTENT_SHIFT - BM_BLOCK_SHIFT));\r\n}\r\nstatic sector_t al_tr_number_to_on_disk_sector(struct drbd_device *device)\r\n{\r\nconst unsigned int stripes = device->ldev->md.al_stripes;\r\nconst unsigned int stripe_size_4kB = device->ldev->md.al_stripe_size_4k;\r\nunsigned int t = device->al_tr_number % (device->ldev->md.al_size_4k);\r\nt = ((t % stripes) * stripe_size_4kB) + t/stripes;\r\nt *= 8;\r\nreturn device->ldev->md.md_offset + device->ldev->md.al_offset + t;\r\n}\r\nstatic int __al_write_transaction(struct drbd_device *device, struct al_transaction_on_disk *buffer)\r\n{\r\nstruct lc_element *e;\r\nsector_t sector;\r\nint i, mx;\r\nunsigned extent_nr;\r\nunsigned crc = 0;\r\nint err = 0;\r\nmemset(buffer, 0, sizeof(*buffer));\r\nbuffer->magic = cpu_to_be32(DRBD_AL_MAGIC);\r\nbuffer->tr_number = cpu_to_be32(device->al_tr_number);\r\ni = 0;\r\ndrbd_bm_reset_al_hints(device);\r\nspin_lock_irq(&device->al_lock);\r\nlist_for_each_entry(e, &device->act_log->to_be_changed, list) {\r\nif (i == AL_UPDATES_PER_TRANSACTION) {\r\ni++;\r\nbreak;\r\n}\r\nbuffer->update_slot_nr[i] = cpu_to_be16(e->lc_index);\r\nbuffer->update_extent_nr[i] = cpu_to_be32(e->lc_new_number);\r\nif (e->lc_number != LC_FREE)\r\ndrbd_bm_mark_for_writeout(device,\r\nal_extent_to_bm_page(e->lc_number));\r\ni++;\r\n}\r\nspin_unlock_irq(&device->al_lock);\r\nBUG_ON(i > AL_UPDATES_PER_TRANSACTION);\r\nbuffer->n_updates = cpu_to_be16(i);\r\nfor ( ; i < AL_UPDATES_PER_TRANSACTION; i++) {\r\nbuffer->update_slot_nr[i] = cpu_to_be16(-1);\r\nbuffer->update_extent_nr[i] = cpu_to_be32(LC_FREE);\r\n}\r\nbuffer->context_size = cpu_to_be16(device->act_log->nr_elements);\r\nbuffer->context_start_slot_nr = cpu_to_be16(device->al_tr_cycle);\r\nmx = min_t(int, AL_CONTEXT_PER_TRANSACTION,\r\ndevice->act_log->nr_elements - device->al_tr_cycle);\r\nfor (i = 0; i < mx; i++) {\r\nunsigned idx = device->al_tr_cycle + i;\r\nextent_nr = lc_element_by_index(device->act_log, idx)->lc_number;\r\nbuffer->context[i] = cpu_to_be32(extent_nr);\r\n}\r\nfor (; i < AL_CONTEXT_PER_TRANSACTION; i++)\r\nbuffer->context[i] = cpu_to_be32(LC_FREE);\r\ndevice->al_tr_cycle += AL_CONTEXT_PER_TRANSACTION;\r\nif (device->al_tr_cycle >= device->act_log->nr_elements)\r\ndevice->al_tr_cycle = 0;\r\nsector = al_tr_number_to_on_disk_sector(device);\r\ncrc = crc32c(0, buffer, 4096);\r\nbuffer->crc32c = cpu_to_be32(crc);\r\nif (drbd_bm_write_hinted(device))\r\nerr = -EIO;\r\nelse {\r\nbool write_al_updates;\r\nrcu_read_lock();\r\nwrite_al_updates = rcu_dereference(device->ldev->disk_conf)->al_updates;\r\nrcu_read_unlock();\r\nif (write_al_updates) {\r\nif (drbd_md_sync_page_io(device, device->ldev, sector, WRITE)) {\r\nerr = -EIO;\r\ndrbd_chk_io_error(device, 1, DRBD_META_IO_ERROR);\r\n} else {\r\ndevice->al_tr_number++;\r\ndevice->al_writ_cnt++;\r\n}\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic int al_write_transaction(struct drbd_device *device)\r\n{\r\nstruct al_transaction_on_disk *buffer;\r\nint err;\r\nif (!get_ldev(device)) {\r\ndrbd_err(device, "disk is %s, cannot start al transaction\n",\r\ndrbd_disk_str(device->state.disk));\r\nreturn -EIO;\r\n}\r\nif (device->state.disk < D_INCONSISTENT) {\r\ndrbd_err(device,\r\n"disk is %s, cannot write al transaction\n",\r\ndrbd_disk_str(device->state.disk));\r\nput_ldev(device);\r\nreturn -EIO;\r\n}\r\nbuffer = drbd_md_get_buffer(device, __func__);\r\nif (!buffer) {\r\ndrbd_err(device, "disk failed while waiting for md_io buffer\n");\r\nput_ldev(device);\r\nreturn -ENODEV;\r\n}\r\nerr = __al_write_transaction(device, buffer);\r\ndrbd_md_put_buffer(device);\r\nput_ldev(device);\r\nreturn err;\r\n}\r\nvoid drbd_al_begin_io_commit(struct drbd_device *device)\r\n{\r\nbool locked = false;\r\nwait_event(device->al_wait,\r\ndevice->act_log->pending_changes == 0 ||\r\n(locked = lc_try_lock_for_transaction(device->act_log)));\r\nif (locked) {\r\nif (device->act_log->pending_changes) {\r\nbool write_al_updates;\r\nrcu_read_lock();\r\nwrite_al_updates = rcu_dereference(device->ldev->disk_conf)->al_updates;\r\nrcu_read_unlock();\r\nif (write_al_updates)\r\nal_write_transaction(device);\r\nspin_lock_irq(&device->al_lock);\r\nlc_committed(device->act_log);\r\nspin_unlock_irq(&device->al_lock);\r\n}\r\nlc_unlock(device->act_log);\r\nwake_up(&device->al_wait);\r\n}\r\n}\r\nvoid drbd_al_begin_io(struct drbd_device *device, struct drbd_interval *i)\r\n{\r\nif (drbd_al_begin_io_prepare(device, i))\r\ndrbd_al_begin_io_commit(device);\r\n}\r\nint drbd_al_begin_io_nonblock(struct drbd_device *device, struct drbd_interval *i)\r\n{\r\nstruct lru_cache *al = device->act_log;\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nunsigned nr_al_extents;\r\nunsigned available_update_slots;\r\nunsigned enr;\r\nD_ASSERT(device, first <= last);\r\nnr_al_extents = 1 + last - first;\r\navailable_update_slots = min(al->nr_elements - al->used,\r\nal->max_pending_changes - al->pending_changes);\r\nif (available_update_slots < nr_al_extents) {\r\nif (!al->pending_changes)\r\n__set_bit(__LC_STARVING, &device->act_log->flags);\r\nreturn -ENOBUFS;\r\n}\r\nfor (enr = first; enr <= last; enr++) {\r\nstruct lc_element *tmp;\r\ntmp = lc_find(device->resync, enr/AL_EXT_PER_BM_SECT);\r\nif (unlikely(tmp != NULL)) {\r\nstruct bm_extent *bm_ext = lc_entry(tmp, struct bm_extent, lce);\r\nif (test_bit(BME_NO_WRITES, &bm_ext->flags)) {\r\nif (!test_and_set_bit(BME_PRIORITY, &bm_ext->flags))\r\nreturn -EBUSY;\r\nreturn -EWOULDBLOCK;\r\n}\r\n}\r\n}\r\nfor (enr = first; enr <= last; enr++) {\r\nstruct lc_element *al_ext;\r\nal_ext = lc_get_cumulative(device->act_log, enr);\r\nif (!al_ext)\r\ndrbd_info(device, "LOGIC BUG for enr=%u\n", enr);\r\n}\r\nreturn 0;\r\n}\r\nvoid drbd_al_complete_io(struct drbd_device *device, struct drbd_interval *i)\r\n{\r\nunsigned first = i->sector >> (AL_EXTENT_SHIFT-9);\r\nunsigned last = i->size == 0 ? first : (i->sector + (i->size >> 9) - 1) >> (AL_EXTENT_SHIFT-9);\r\nunsigned enr;\r\nstruct lc_element *extent;\r\nunsigned long flags;\r\nD_ASSERT(device, first <= last);\r\nspin_lock_irqsave(&device->al_lock, flags);\r\nfor (enr = first; enr <= last; enr++) {\r\nextent = lc_find(device->act_log, enr);\r\nif (!extent) {\r\ndrbd_err(device, "al_complete_io() called on inactive extent %u\n", enr);\r\ncontinue;\r\n}\r\nlc_put(device->act_log, extent);\r\n}\r\nspin_unlock_irqrestore(&device->al_lock, flags);\r\nwake_up(&device->al_wait);\r\n}\r\nstatic int _try_lc_del(struct drbd_device *device, struct lc_element *al_ext)\r\n{\r\nint rv;\r\nspin_lock_irq(&device->al_lock);\r\nrv = (al_ext->refcnt == 0);\r\nif (likely(rv))\r\nlc_del(device->act_log, al_ext);\r\nspin_unlock_irq(&device->al_lock);\r\nreturn rv;\r\n}\r\nvoid drbd_al_shrink(struct drbd_device *device)\r\n{\r\nstruct lc_element *al_ext;\r\nint i;\r\nD_ASSERT(device, test_bit(__LC_LOCKED, &device->act_log->flags));\r\nfor (i = 0; i < device->act_log->nr_elements; i++) {\r\nal_ext = lc_element_by_index(device->act_log, i);\r\nif (al_ext->lc_number == LC_FREE)\r\ncontinue;\r\nwait_event(device->al_wait, _try_lc_del(device, al_ext));\r\n}\r\nwake_up(&device->al_wait);\r\n}\r\nint drbd_al_initialize(struct drbd_device *device, void *buffer)\r\n{\r\nstruct al_transaction_on_disk *al = buffer;\r\nstruct drbd_md *md = &device->ldev->md;\r\nint al_size_4k = md->al_stripes * md->al_stripe_size_4k;\r\nint i;\r\n__al_write_transaction(device, al);\r\nspin_lock_irq(&device->al_lock);\r\nlc_committed(device->act_log);\r\nspin_unlock_irq(&device->al_lock);\r\nfor (i = 1; i < al_size_4k; i++) {\r\nint err = __al_write_transaction(device, al);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic bool update_rs_extent(struct drbd_device *device,\r\nunsigned int enr, int count,\r\nenum update_sync_bits_mode mode)\r\n{\r\nstruct lc_element *e;\r\nD_ASSERT(device, atomic_read(&device->local_cnt));\r\nif (mode == SET_OUT_OF_SYNC)\r\ne = lc_find(device->resync, enr);\r\nelse\r\ne = lc_get(device->resync, enr);\r\nif (e) {\r\nstruct bm_extent *ext = lc_entry(e, struct bm_extent, lce);\r\nif (ext->lce.lc_number == enr) {\r\nif (mode == SET_IN_SYNC)\r\next->rs_left -= count;\r\nelse if (mode == SET_OUT_OF_SYNC)\r\next->rs_left += count;\r\nelse\r\next->rs_failed += count;\r\nif (ext->rs_left < ext->rs_failed) {\r\ndrbd_warn(device, "BAD! enr=%u rs_left=%d "\r\n"rs_failed=%d count=%d cstate=%s\n",\r\next->lce.lc_number, ext->rs_left,\r\next->rs_failed, count,\r\ndrbd_conn_str(device->state.conn));\r\next->rs_left = drbd_bm_e_weight(device, enr);\r\n}\r\n} else {\r\nint rs_left = drbd_bm_e_weight(device, enr);\r\nif (ext->flags != 0) {\r\ndrbd_warn(device, "changing resync lce: %d[%u;%02lx]"\r\n" -> %d[%u;00]\n",\r\next->lce.lc_number, ext->rs_left,\r\next->flags, enr, rs_left);\r\next->flags = 0;\r\n}\r\nif (ext->rs_failed) {\r\ndrbd_warn(device, "Kicking resync_lru element enr=%u "\r\n"out with rs_failed=%d\n",\r\next->lce.lc_number, ext->rs_failed);\r\n}\r\next->rs_left = rs_left;\r\next->rs_failed = (mode == RECORD_RS_FAILED) ? count : 0;\r\nlc_committed(device->resync);\r\n}\r\nif (mode != SET_OUT_OF_SYNC)\r\nlc_put(device->resync, &ext->lce);\r\nif (ext->rs_left <= ext->rs_failed) {\r\next->rs_failed = 0;\r\nreturn true;\r\n}\r\n} else if (mode != SET_OUT_OF_SYNC) {\r\ndrbd_err(device, "lc_get() failed! locked=%d/%d flags=%lu\n",\r\ndevice->resync_locked,\r\ndevice->resync->nr_elements,\r\ndevice->resync->flags);\r\n}\r\nreturn false;\r\n}\r\nvoid drbd_advance_rs_marks(struct drbd_device *device, unsigned long still_to_go)\r\n{\r\nunsigned long now = jiffies;\r\nunsigned long last = device->rs_mark_time[device->rs_last_mark];\r\nint next = (device->rs_last_mark + 1) % DRBD_SYNC_MARKS;\r\nif (time_after_eq(now, last + DRBD_SYNC_MARK_STEP)) {\r\nif (device->rs_mark_left[device->rs_last_mark] != still_to_go &&\r\ndevice->state.conn != C_PAUSED_SYNC_T &&\r\ndevice->state.conn != C_PAUSED_SYNC_S) {\r\ndevice->rs_mark_time[next] = now;\r\ndevice->rs_mark_left[next] = still_to_go;\r\ndevice->rs_last_mark = next;\r\n}\r\n}\r\n}\r\nstatic bool lazy_bitmap_update_due(struct drbd_device *device)\r\n{\r\nreturn time_after(jiffies, device->rs_last_bcast + 2*HZ);\r\n}\r\nstatic void maybe_schedule_on_disk_bitmap_update(struct drbd_device *device, bool rs_done)\r\n{\r\nif (rs_done) {\r\nstruct drbd_connection *connection = first_peer_device(device)->connection;\r\nif (connection->agreed_pro_version <= 95 ||\r\nis_sync_target_state(device->state.conn))\r\nset_bit(RS_DONE, &device->flags);\r\n} else if (!lazy_bitmap_update_due(device))\r\nreturn;\r\ndrbd_device_post_work(device, RS_PROGRESS);\r\n}\r\nstatic int update_sync_bits(struct drbd_device *device,\r\nunsigned long sbnr, unsigned long ebnr,\r\nenum update_sync_bits_mode mode)\r\n{\r\nunsigned long flags;\r\nunsigned long count = 0;\r\nunsigned int cleared = 0;\r\nwhile (sbnr <= ebnr) {\r\nunsigned long tbnr = min(ebnr, sbnr | BM_BLOCKS_PER_BM_EXT_MASK);\r\nunsigned long c;\r\nif (mode == RECORD_RS_FAILED)\r\nc = drbd_bm_count_bits(device, sbnr, tbnr);\r\nelse if (mode == SET_IN_SYNC)\r\nc = drbd_bm_clear_bits(device, sbnr, tbnr);\r\nelse\r\nc = drbd_bm_set_bits(device, sbnr, tbnr);\r\nif (c) {\r\nspin_lock_irqsave(&device->al_lock, flags);\r\ncleared += update_rs_extent(device, BM_BIT_TO_EXT(sbnr), c, mode);\r\nspin_unlock_irqrestore(&device->al_lock, flags);\r\ncount += c;\r\n}\r\nsbnr = tbnr + 1;\r\n}\r\nif (count) {\r\nif (mode == SET_IN_SYNC) {\r\nunsigned long still_to_go = drbd_bm_total_weight(device);\r\nbool rs_is_done = (still_to_go <= device->rs_failed);\r\ndrbd_advance_rs_marks(device, still_to_go);\r\nif (cleared || rs_is_done)\r\nmaybe_schedule_on_disk_bitmap_update(device, rs_is_done);\r\n} else if (mode == RECORD_RS_FAILED)\r\ndevice->rs_failed += count;\r\nwake_up(&device->al_wait);\r\n}\r\nreturn count;\r\n}\r\nstatic bool plausible_request_size(int size)\r\n{\r\nreturn size > 0\r\n&& size <= DRBD_MAX_BATCH_BIO_SIZE\r\n&& IS_ALIGNED(size, 512);\r\n}\r\nint __drbd_change_sync(struct drbd_device *device, sector_t sector, int size,\r\nenum update_sync_bits_mode mode)\r\n{\r\nunsigned long sbnr, ebnr, lbnr;\r\nunsigned long count = 0;\r\nsector_t esector, nr_sectors;\r\nif ((mode == SET_OUT_OF_SYNC) && size == 0)\r\nreturn 0;\r\nif (!plausible_request_size(size)) {\r\ndrbd_err(device, "%s: sector=%llus size=%d nonsense!\n",\r\ndrbd_change_sync_fname[mode],\r\n(unsigned long long)sector, size);\r\nreturn 0;\r\n}\r\nif (!get_ldev(device))\r\nreturn 0;\r\nnr_sectors = drbd_get_capacity(device->this_bdev);\r\nesector = sector + (size >> 9) - 1;\r\nif (!expect(sector < nr_sectors))\r\ngoto out;\r\nif (!expect(esector < nr_sectors))\r\nesector = nr_sectors - 1;\r\nlbnr = BM_SECT_TO_BIT(nr_sectors-1);\r\nif (mode == SET_IN_SYNC) {\r\nif (unlikely(esector < BM_SECT_PER_BIT-1))\r\ngoto out;\r\nif (unlikely(esector == (nr_sectors-1)))\r\nebnr = lbnr;\r\nelse\r\nebnr = BM_SECT_TO_BIT(esector - (BM_SECT_PER_BIT-1));\r\nsbnr = BM_SECT_TO_BIT(sector + BM_SECT_PER_BIT-1);\r\n} else {\r\nsbnr = BM_SECT_TO_BIT(sector);\r\nebnr = BM_SECT_TO_BIT(esector);\r\n}\r\ncount = update_sync_bits(device, sbnr, ebnr, mode);\r\nout:\r\nput_ldev(device);\r\nreturn count;\r\n}\r\nstatic\r\nstruct bm_extent *_bme_get(struct drbd_device *device, unsigned int enr)\r\n{\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint wakeup = 0;\r\nunsigned long rs_flags;\r\nspin_lock_irq(&device->al_lock);\r\nif (device->resync_locked > device->resync->nr_elements/2) {\r\nspin_unlock_irq(&device->al_lock);\r\nreturn NULL;\r\n}\r\ne = lc_get(device->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nif (bm_ext->lce.lc_number != enr) {\r\nbm_ext->rs_left = drbd_bm_e_weight(device, enr);\r\nbm_ext->rs_failed = 0;\r\nlc_committed(device->resync);\r\nwakeup = 1;\r\n}\r\nif (bm_ext->lce.refcnt == 1)\r\ndevice->resync_locked++;\r\nset_bit(BME_NO_WRITES, &bm_ext->flags);\r\n}\r\nrs_flags = device->resync->flags;\r\nspin_unlock_irq(&device->al_lock);\r\nif (wakeup)\r\nwake_up(&device->al_wait);\r\nif (!bm_ext) {\r\nif (rs_flags & LC_STARVING)\r\ndrbd_warn(device, "Have to wait for element"\r\n" (resync LRU too small?)\n");\r\nBUG_ON(rs_flags & LC_LOCKED);\r\n}\r\nreturn bm_ext;\r\n}\r\nstatic int _is_in_al(struct drbd_device *device, unsigned int enr)\r\n{\r\nint rv;\r\nspin_lock_irq(&device->al_lock);\r\nrv = lc_is_used(device->act_log, enr);\r\nspin_unlock_irq(&device->al_lock);\r\nreturn rv;\r\n}\r\nint drbd_rs_begin_io(struct drbd_device *device, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nstruct bm_extent *bm_ext;\r\nint i, sig;\r\nbool sa;\r\nretry:\r\nsig = wait_event_interruptible(device->al_wait,\r\n(bm_ext = _bme_get(device, enr)));\r\nif (sig)\r\nreturn -EINTR;\r\nif (test_bit(BME_LOCKED, &bm_ext->flags))\r\nreturn 0;\r\nsa = drbd_rs_c_min_rate_throttle(device);\r\nfor (i = 0; i < AL_EXT_PER_BM_SECT; i++) {\r\nsig = wait_event_interruptible(device->al_wait,\r\n!_is_in_al(device, enr * AL_EXT_PER_BM_SECT + i) ||\r\n(sa && test_bit(BME_PRIORITY, &bm_ext->flags)));\r\nif (sig || (sa && test_bit(BME_PRIORITY, &bm_ext->flags))) {\r\nspin_lock_irq(&device->al_lock);\r\nif (lc_put(device->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\ndevice->resync_locked--;\r\nwake_up(&device->al_wait);\r\n}\r\nspin_unlock_irq(&device->al_lock);\r\nif (sig)\r\nreturn -EINTR;\r\nif (schedule_timeout_interruptible(HZ/10))\r\nreturn -EINTR;\r\ngoto retry;\r\n}\r\n}\r\nset_bit(BME_LOCKED, &bm_ext->flags);\r\nreturn 0;\r\n}\r\nint drbd_try_rs_begin_io(struct drbd_device *device, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nconst unsigned int al_enr = enr*AL_EXT_PER_BM_SECT;\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint i;\r\nbool throttle = drbd_rs_should_slow_down(device, sector, true);\r\nif (throttle && device->resync_wenr != enr)\r\nreturn -EAGAIN;\r\nspin_lock_irq(&device->al_lock);\r\nif (device->resync_wenr != LC_FREE && device->resync_wenr != enr) {\r\ne = lc_find(device->resync, device->resync_wenr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nD_ASSERT(device, !test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(device, test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nclear_bit(BME_NO_WRITES, &bm_ext->flags);\r\ndevice->resync_wenr = LC_FREE;\r\nif (lc_put(device->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\ndevice->resync_locked--;\r\n}\r\nwake_up(&device->al_wait);\r\n} else {\r\ndrbd_alert(device, "LOGIC BUG\n");\r\n}\r\n}\r\ne = lc_try_get(device->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nif (test_bit(BME_LOCKED, &bm_ext->flags))\r\ngoto proceed;\r\nif (!test_and_set_bit(BME_NO_WRITES, &bm_ext->flags)) {\r\ndevice->resync_locked++;\r\n} else {\r\nbm_ext->lce.refcnt--;\r\nD_ASSERT(device, bm_ext->lce.refcnt > 0);\r\n}\r\ngoto check_al;\r\n} else {\r\nif (device->resync_locked > device->resync->nr_elements-3)\r\ngoto try_again;\r\ne = lc_get(device->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (!bm_ext) {\r\nconst unsigned long rs_flags = device->resync->flags;\r\nif (rs_flags & LC_STARVING)\r\ndrbd_warn(device, "Have to wait for element"\r\n" (resync LRU too small?)\n");\r\nBUG_ON(rs_flags & LC_LOCKED);\r\ngoto try_again;\r\n}\r\nif (bm_ext->lce.lc_number != enr) {\r\nbm_ext->rs_left = drbd_bm_e_weight(device, enr);\r\nbm_ext->rs_failed = 0;\r\nlc_committed(device->resync);\r\nwake_up(&device->al_wait);\r\nD_ASSERT(device, test_bit(BME_LOCKED, &bm_ext->flags) == 0);\r\n}\r\nset_bit(BME_NO_WRITES, &bm_ext->flags);\r\nD_ASSERT(device, bm_ext->lce.refcnt == 1);\r\ndevice->resync_locked++;\r\ngoto check_al;\r\n}\r\ncheck_al:\r\nfor (i = 0; i < AL_EXT_PER_BM_SECT; i++) {\r\nif (lc_is_used(device->act_log, al_enr+i))\r\ngoto try_again;\r\n}\r\nset_bit(BME_LOCKED, &bm_ext->flags);\r\nproceed:\r\ndevice->resync_wenr = LC_FREE;\r\nspin_unlock_irq(&device->al_lock);\r\nreturn 0;\r\ntry_again:\r\nif (bm_ext) {\r\nif (throttle) {\r\nD_ASSERT(device, !test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(device, test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nclear_bit(BME_NO_WRITES, &bm_ext->flags);\r\ndevice->resync_wenr = LC_FREE;\r\nif (lc_put(device->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\ndevice->resync_locked--;\r\n}\r\nwake_up(&device->al_wait);\r\n} else\r\ndevice->resync_wenr = enr;\r\n}\r\nspin_unlock_irq(&device->al_lock);\r\nreturn -EAGAIN;\r\n}\r\nvoid drbd_rs_complete_io(struct drbd_device *device, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nunsigned long flags;\r\nspin_lock_irqsave(&device->al_lock, flags);\r\ne = lc_find(device->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (!bm_ext) {\r\nspin_unlock_irqrestore(&device->al_lock, flags);\r\nif (__ratelimit(&drbd_ratelimit_state))\r\ndrbd_err(device, "drbd_rs_complete_io() called, but extent not found\n");\r\nreturn;\r\n}\r\nif (bm_ext->lce.refcnt == 0) {\r\nspin_unlock_irqrestore(&device->al_lock, flags);\r\ndrbd_err(device, "drbd_rs_complete_io(,%llu [=%u]) called, "\r\n"but refcnt is 0!?\n",\r\n(unsigned long long)sector, enr);\r\nreturn;\r\n}\r\nif (lc_put(device->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\ndevice->resync_locked--;\r\nwake_up(&device->al_wait);\r\n}\r\nspin_unlock_irqrestore(&device->al_lock, flags);\r\n}\r\nvoid drbd_rs_cancel_all(struct drbd_device *device)\r\n{\r\nspin_lock_irq(&device->al_lock);\r\nif (get_ldev_if_state(device, D_FAILED)) {\r\nlc_reset(device->resync);\r\nput_ldev(device);\r\n}\r\ndevice->resync_locked = 0;\r\ndevice->resync_wenr = LC_FREE;\r\nspin_unlock_irq(&device->al_lock);\r\nwake_up(&device->al_wait);\r\n}\r\nint drbd_rs_del_all(struct drbd_device *device)\r\n{\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint i;\r\nspin_lock_irq(&device->al_lock);\r\nif (get_ldev_if_state(device, D_FAILED)) {\r\nfor (i = 0; i < device->resync->nr_elements; i++) {\r\ne = lc_element_by_index(device->resync, i);\r\nbm_ext = lc_entry(e, struct bm_extent, lce);\r\nif (bm_ext->lce.lc_number == LC_FREE)\r\ncontinue;\r\nif (bm_ext->lce.lc_number == device->resync_wenr) {\r\ndrbd_info(device, "dropping %u in drbd_rs_del_all, apparently"\r\n" got 'synced' by application io\n",\r\ndevice->resync_wenr);\r\nD_ASSERT(device, !test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(device, test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nclear_bit(BME_NO_WRITES, &bm_ext->flags);\r\ndevice->resync_wenr = LC_FREE;\r\nlc_put(device->resync, &bm_ext->lce);\r\n}\r\nif (bm_ext->lce.refcnt != 0) {\r\ndrbd_info(device, "Retrying drbd_rs_del_all() later. "\r\n"refcnt=%d\n", bm_ext->lce.refcnt);\r\nput_ldev(device);\r\nspin_unlock_irq(&device->al_lock);\r\nreturn -EAGAIN;\r\n}\r\nD_ASSERT(device, !test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(device, !test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nlc_del(device->resync, &bm_ext->lce);\r\n}\r\nD_ASSERT(device, device->resync->used == 0);\r\nput_ldev(device);\r\n}\r\nspin_unlock_irq(&device->al_lock);\r\nwake_up(&device->al_wait);\r\nreturn 0;\r\n}
