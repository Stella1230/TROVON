void tcp_rate_skb_sent(struct sock *sk, struct sk_buff *skb)\r\n{\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nif (!tp->packets_out) {\r\ntp->first_tx_mstamp = skb->skb_mstamp;\r\ntp->delivered_mstamp = skb->skb_mstamp;\r\n}\r\nTCP_SKB_CB(skb)->tx.first_tx_mstamp = tp->first_tx_mstamp;\r\nTCP_SKB_CB(skb)->tx.delivered_mstamp = tp->delivered_mstamp;\r\nTCP_SKB_CB(skb)->tx.delivered = tp->delivered;\r\nTCP_SKB_CB(skb)->tx.is_app_limited = tp->app_limited ? 1 : 0;\r\n}\r\nvoid tcp_rate_skb_delivered(struct sock *sk, struct sk_buff *skb,\r\nstruct rate_sample *rs)\r\n{\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nstruct tcp_skb_cb *scb = TCP_SKB_CB(skb);\r\nif (!scb->tx.delivered_mstamp.v64)\r\nreturn;\r\nif (!rs->prior_delivered ||\r\nafter(scb->tx.delivered, rs->prior_delivered)) {\r\nrs->prior_delivered = scb->tx.delivered;\r\nrs->prior_mstamp = scb->tx.delivered_mstamp;\r\nrs->is_app_limited = scb->tx.is_app_limited;\r\nrs->is_retrans = scb->sacked & TCPCB_RETRANS;\r\nrs->interval_us = skb_mstamp_us_delta(\r\n&skb->skb_mstamp,\r\n&scb->tx.first_tx_mstamp);\r\ntp->first_tx_mstamp = skb->skb_mstamp;\r\n}\r\nif (scb->sacked & TCPCB_SACKED_ACKED)\r\nscb->tx.delivered_mstamp.v64 = 0;\r\n}\r\nvoid tcp_rate_gen(struct sock *sk, u32 delivered, u32 lost,\r\nstruct skb_mstamp *now, struct rate_sample *rs)\r\n{\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nu32 snd_us, ack_us;\r\nif (tp->app_limited && after(tp->delivered, tp->app_limited))\r\ntp->app_limited = 0;\r\nif (delivered)\r\ntp->delivered_mstamp = *now;\r\nrs->acked_sacked = delivered;\r\nrs->losses = lost;\r\nif (!rs->prior_mstamp.v64) {\r\nrs->delivered = -1;\r\nrs->interval_us = -1;\r\nreturn;\r\n}\r\nrs->delivered = tp->delivered - rs->prior_delivered;\r\nsnd_us = rs->interval_us;\r\nack_us = skb_mstamp_us_delta(now, &rs->prior_mstamp);\r\nrs->interval_us = max(snd_us, ack_us);\r\nif (unlikely(rs->interval_us < tcp_min_rtt(tp))) {\r\nif (!rs->is_retrans)\r\npr_debug("tcp rate: %ld %d %u %u %u\n",\r\nrs->interval_us, rs->delivered,\r\ninet_csk(sk)->icsk_ca_state,\r\ntp->rx_opt.sack_ok, tcp_min_rtt(tp));\r\nrs->interval_us = -1;\r\nreturn;\r\n}\r\nif (!rs->is_app_limited ||\r\n((u64)rs->delivered * tp->rate_interval_us >=\r\n(u64)tp->rate_delivered * rs->interval_us)) {\r\ntp->rate_delivered = rs->delivered;\r\ntp->rate_interval_us = rs->interval_us;\r\ntp->rate_app_limited = rs->is_app_limited;\r\n}\r\n}\r\nvoid tcp_rate_check_app_limited(struct sock *sk)\r\n{\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\nif (\r\ntp->write_seq - tp->snd_nxt < tp->mss_cache &&\r\nsk_wmem_alloc_get(sk) < SKB_TRUESIZE(1) &&\r\ntcp_packets_in_flight(tp) < tp->snd_cwnd &&\r\ntp->lost_out <= tp->retrans_out)\r\ntp->app_limited =\r\n(tp->delivered + tcp_packets_in_flight(tp)) ? : 1;\r\n}
