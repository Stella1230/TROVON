static inline unsigned long sh_tmu_read(struct sh_tmu_channel *ch, int reg_nr)\r\n{\r\nunsigned long offs;\r\nif (reg_nr == TSTR) {\r\nswitch (ch->tmu->model) {\r\ncase SH_TMU_SH3:\r\nreturn ioread8(ch->tmu->mapbase + 2);\r\ncase SH_TMU:\r\nreturn ioread8(ch->tmu->mapbase + 4);\r\n}\r\n}\r\noffs = reg_nr << 2;\r\nif (reg_nr == TCR)\r\nreturn ioread16(ch->base + offs);\r\nelse\r\nreturn ioread32(ch->base + offs);\r\n}\r\nstatic inline void sh_tmu_write(struct sh_tmu_channel *ch, int reg_nr,\r\nunsigned long value)\r\n{\r\nunsigned long offs;\r\nif (reg_nr == TSTR) {\r\nswitch (ch->tmu->model) {\r\ncase SH_TMU_SH3:\r\nreturn iowrite8(value, ch->tmu->mapbase + 2);\r\ncase SH_TMU:\r\nreturn iowrite8(value, ch->tmu->mapbase + 4);\r\n}\r\n}\r\noffs = reg_nr << 2;\r\nif (reg_nr == TCR)\r\niowrite16(value, ch->base + offs);\r\nelse\r\niowrite32(value, ch->base + offs);\r\n}\r\nstatic void sh_tmu_start_stop_ch(struct sh_tmu_channel *ch, int start)\r\n{\r\nunsigned long flags, value;\r\nraw_spin_lock_irqsave(&ch->tmu->lock, flags);\r\nvalue = sh_tmu_read(ch, TSTR);\r\nif (start)\r\nvalue |= 1 << ch->index;\r\nelse\r\nvalue &= ~(1 << ch->index);\r\nsh_tmu_write(ch, TSTR, value);\r\nraw_spin_unlock_irqrestore(&ch->tmu->lock, flags);\r\n}\r\nstatic int __sh_tmu_enable(struct sh_tmu_channel *ch)\r\n{\r\nint ret;\r\nret = clk_enable(ch->tmu->clk);\r\nif (ret) {\r\ndev_err(&ch->tmu->pdev->dev, "ch%u: cannot enable clock\n",\r\nch->index);\r\nreturn ret;\r\n}\r\nsh_tmu_start_stop_ch(ch, 0);\r\nsh_tmu_write(ch, TCOR, 0xffffffff);\r\nsh_tmu_write(ch, TCNT, 0xffffffff);\r\nch->rate = clk_get_rate(ch->tmu->clk) / 4;\r\nsh_tmu_write(ch, TCR, TCR_TPSC_CLK4);\r\nsh_tmu_start_stop_ch(ch, 1);\r\nreturn 0;\r\n}\r\nstatic int sh_tmu_enable(struct sh_tmu_channel *ch)\r\n{\r\nif (ch->enable_count++ > 0)\r\nreturn 0;\r\npm_runtime_get_sync(&ch->tmu->pdev->dev);\r\ndev_pm_syscore_device(&ch->tmu->pdev->dev, true);\r\nreturn __sh_tmu_enable(ch);\r\n}\r\nstatic void __sh_tmu_disable(struct sh_tmu_channel *ch)\r\n{\r\nsh_tmu_start_stop_ch(ch, 0);\r\nsh_tmu_write(ch, TCR, TCR_TPSC_CLK4);\r\nclk_disable(ch->tmu->clk);\r\n}\r\nstatic void sh_tmu_disable(struct sh_tmu_channel *ch)\r\n{\r\nif (WARN_ON(ch->enable_count == 0))\r\nreturn;\r\nif (--ch->enable_count > 0)\r\nreturn;\r\n__sh_tmu_disable(ch);\r\ndev_pm_syscore_device(&ch->tmu->pdev->dev, false);\r\npm_runtime_put(&ch->tmu->pdev->dev);\r\n}\r\nstatic void sh_tmu_set_next(struct sh_tmu_channel *ch, unsigned long delta,\r\nint periodic)\r\n{\r\nsh_tmu_start_stop_ch(ch, 0);\r\nsh_tmu_read(ch, TCR);\r\nsh_tmu_write(ch, TCR, TCR_UNIE | TCR_TPSC_CLK4);\r\nif (periodic)\r\nsh_tmu_write(ch, TCOR, delta);\r\nelse\r\nsh_tmu_write(ch, TCOR, 0xffffffff);\r\nsh_tmu_write(ch, TCNT, delta);\r\nsh_tmu_start_stop_ch(ch, 1);\r\n}\r\nstatic irqreturn_t sh_tmu_interrupt(int irq, void *dev_id)\r\n{\r\nstruct sh_tmu_channel *ch = dev_id;\r\nif (clockevent_state_oneshot(&ch->ced))\r\nsh_tmu_write(ch, TCR, TCR_TPSC_CLK4);\r\nelse\r\nsh_tmu_write(ch, TCR, TCR_UNIE | TCR_TPSC_CLK4);\r\nch->ced.event_handler(&ch->ced);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic struct sh_tmu_channel *cs_to_sh_tmu(struct clocksource *cs)\r\n{\r\nreturn container_of(cs, struct sh_tmu_channel, cs);\r\n}\r\nstatic u64 sh_tmu_clocksource_read(struct clocksource *cs)\r\n{\r\nstruct sh_tmu_channel *ch = cs_to_sh_tmu(cs);\r\nreturn sh_tmu_read(ch, TCNT) ^ 0xffffffff;\r\n}\r\nstatic int sh_tmu_clocksource_enable(struct clocksource *cs)\r\n{\r\nstruct sh_tmu_channel *ch = cs_to_sh_tmu(cs);\r\nint ret;\r\nif (WARN_ON(ch->cs_enabled))\r\nreturn 0;\r\nret = sh_tmu_enable(ch);\r\nif (!ret) {\r\n__clocksource_update_freq_hz(cs, ch->rate);\r\nch->cs_enabled = true;\r\n}\r\nreturn ret;\r\n}\r\nstatic void sh_tmu_clocksource_disable(struct clocksource *cs)\r\n{\r\nstruct sh_tmu_channel *ch = cs_to_sh_tmu(cs);\r\nif (WARN_ON(!ch->cs_enabled))\r\nreturn;\r\nsh_tmu_disable(ch);\r\nch->cs_enabled = false;\r\n}\r\nstatic void sh_tmu_clocksource_suspend(struct clocksource *cs)\r\n{\r\nstruct sh_tmu_channel *ch = cs_to_sh_tmu(cs);\r\nif (!ch->cs_enabled)\r\nreturn;\r\nif (--ch->enable_count == 0) {\r\n__sh_tmu_disable(ch);\r\npm_genpd_syscore_poweroff(&ch->tmu->pdev->dev);\r\n}\r\n}\r\nstatic void sh_tmu_clocksource_resume(struct clocksource *cs)\r\n{\r\nstruct sh_tmu_channel *ch = cs_to_sh_tmu(cs);\r\nif (!ch->cs_enabled)\r\nreturn;\r\nif (ch->enable_count++ == 0) {\r\npm_genpd_syscore_poweron(&ch->tmu->pdev->dev);\r\n__sh_tmu_enable(ch);\r\n}\r\n}\r\nstatic int sh_tmu_register_clocksource(struct sh_tmu_channel *ch,\r\nconst char *name)\r\n{\r\nstruct clocksource *cs = &ch->cs;\r\ncs->name = name;\r\ncs->rating = 200;\r\ncs->read = sh_tmu_clocksource_read;\r\ncs->enable = sh_tmu_clocksource_enable;\r\ncs->disable = sh_tmu_clocksource_disable;\r\ncs->suspend = sh_tmu_clocksource_suspend;\r\ncs->resume = sh_tmu_clocksource_resume;\r\ncs->mask = CLOCKSOURCE_MASK(32);\r\ncs->flags = CLOCK_SOURCE_IS_CONTINUOUS;\r\ndev_info(&ch->tmu->pdev->dev, "ch%u: used as clock source\n",\r\nch->index);\r\nclocksource_register_hz(cs, 1);\r\nreturn 0;\r\n}\r\nstatic struct sh_tmu_channel *ced_to_sh_tmu(struct clock_event_device *ced)\r\n{\r\nreturn container_of(ced, struct sh_tmu_channel, ced);\r\n}\r\nstatic void sh_tmu_clock_event_start(struct sh_tmu_channel *ch, int periodic)\r\n{\r\nstruct clock_event_device *ced = &ch->ced;\r\nsh_tmu_enable(ch);\r\nclockevents_config(ced, ch->rate);\r\nif (periodic) {\r\nch->periodic = (ch->rate + HZ/2) / HZ;\r\nsh_tmu_set_next(ch, ch->periodic, 1);\r\n}\r\n}\r\nstatic int sh_tmu_clock_event_shutdown(struct clock_event_device *ced)\r\n{\r\nstruct sh_tmu_channel *ch = ced_to_sh_tmu(ced);\r\nif (clockevent_state_oneshot(ced) || clockevent_state_periodic(ced))\r\nsh_tmu_disable(ch);\r\nreturn 0;\r\n}\r\nstatic int sh_tmu_clock_event_set_state(struct clock_event_device *ced,\r\nint periodic)\r\n{\r\nstruct sh_tmu_channel *ch = ced_to_sh_tmu(ced);\r\nif (clockevent_state_oneshot(ced) || clockevent_state_periodic(ced))\r\nsh_tmu_disable(ch);\r\ndev_info(&ch->tmu->pdev->dev, "ch%u: used for %s clock events\n",\r\nch->index, periodic ? "periodic" : "oneshot");\r\nsh_tmu_clock_event_start(ch, periodic);\r\nreturn 0;\r\n}\r\nstatic int sh_tmu_clock_event_set_oneshot(struct clock_event_device *ced)\r\n{\r\nreturn sh_tmu_clock_event_set_state(ced, 0);\r\n}\r\nstatic int sh_tmu_clock_event_set_periodic(struct clock_event_device *ced)\r\n{\r\nreturn sh_tmu_clock_event_set_state(ced, 1);\r\n}\r\nstatic int sh_tmu_clock_event_next(unsigned long delta,\r\nstruct clock_event_device *ced)\r\n{\r\nstruct sh_tmu_channel *ch = ced_to_sh_tmu(ced);\r\nBUG_ON(!clockevent_state_oneshot(ced));\r\nsh_tmu_set_next(ch, delta, 0);\r\nreturn 0;\r\n}\r\nstatic void sh_tmu_clock_event_suspend(struct clock_event_device *ced)\r\n{\r\npm_genpd_syscore_poweroff(&ced_to_sh_tmu(ced)->tmu->pdev->dev);\r\n}\r\nstatic void sh_tmu_clock_event_resume(struct clock_event_device *ced)\r\n{\r\npm_genpd_syscore_poweron(&ced_to_sh_tmu(ced)->tmu->pdev->dev);\r\n}\r\nstatic void sh_tmu_register_clockevent(struct sh_tmu_channel *ch,\r\nconst char *name)\r\n{\r\nstruct clock_event_device *ced = &ch->ced;\r\nint ret;\r\nced->name = name;\r\nced->features = CLOCK_EVT_FEAT_PERIODIC;\r\nced->features |= CLOCK_EVT_FEAT_ONESHOT;\r\nced->rating = 200;\r\nced->cpumask = cpu_possible_mask;\r\nced->set_next_event = sh_tmu_clock_event_next;\r\nced->set_state_shutdown = sh_tmu_clock_event_shutdown;\r\nced->set_state_periodic = sh_tmu_clock_event_set_periodic;\r\nced->set_state_oneshot = sh_tmu_clock_event_set_oneshot;\r\nced->suspend = sh_tmu_clock_event_suspend;\r\nced->resume = sh_tmu_clock_event_resume;\r\ndev_info(&ch->tmu->pdev->dev, "ch%u: used for clock events\n",\r\nch->index);\r\nclockevents_config_and_register(ced, 1, 0x300, 0xffffffff);\r\nret = request_irq(ch->irq, sh_tmu_interrupt,\r\nIRQF_TIMER | IRQF_IRQPOLL | IRQF_NOBALANCING,\r\ndev_name(&ch->tmu->pdev->dev), ch);\r\nif (ret) {\r\ndev_err(&ch->tmu->pdev->dev, "ch%u: failed to request irq %d\n",\r\nch->index, ch->irq);\r\nreturn;\r\n}\r\n}\r\nstatic int sh_tmu_register(struct sh_tmu_channel *ch, const char *name,\r\nbool clockevent, bool clocksource)\r\n{\r\nif (clockevent) {\r\nch->tmu->has_clockevent = true;\r\nsh_tmu_register_clockevent(ch, name);\r\n} else if (clocksource) {\r\nch->tmu->has_clocksource = true;\r\nsh_tmu_register_clocksource(ch, name);\r\n}\r\nreturn 0;\r\n}\r\nstatic int sh_tmu_channel_setup(struct sh_tmu_channel *ch, unsigned int index,\r\nbool clockevent, bool clocksource,\r\nstruct sh_tmu_device *tmu)\r\n{\r\nif (!clockevent && !clocksource)\r\nreturn 0;\r\nch->tmu = tmu;\r\nch->index = index;\r\nif (tmu->model == SH_TMU_SH3)\r\nch->base = tmu->mapbase + 4 + ch->index * 12;\r\nelse\r\nch->base = tmu->mapbase + 8 + ch->index * 12;\r\nch->irq = platform_get_irq(tmu->pdev, index);\r\nif (ch->irq < 0) {\r\ndev_err(&tmu->pdev->dev, "ch%u: failed to get irq\n",\r\nch->index);\r\nreturn ch->irq;\r\n}\r\nch->cs_enabled = false;\r\nch->enable_count = 0;\r\nreturn sh_tmu_register(ch, dev_name(&tmu->pdev->dev),\r\nclockevent, clocksource);\r\n}\r\nstatic int sh_tmu_map_memory(struct sh_tmu_device *tmu)\r\n{\r\nstruct resource *res;\r\nres = platform_get_resource(tmu->pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(&tmu->pdev->dev, "failed to get I/O memory\n");\r\nreturn -ENXIO;\r\n}\r\ntmu->mapbase = ioremap_nocache(res->start, resource_size(res));\r\nif (tmu->mapbase == NULL)\r\nreturn -ENXIO;\r\nreturn 0;\r\n}\r\nstatic int sh_tmu_parse_dt(struct sh_tmu_device *tmu)\r\n{\r\nstruct device_node *np = tmu->pdev->dev.of_node;\r\ntmu->model = SH_TMU;\r\ntmu->num_channels = 3;\r\nof_property_read_u32(np, "#renesas,channels", &tmu->num_channels);\r\nif (tmu->num_channels != 2 && tmu->num_channels != 3) {\r\ndev_err(&tmu->pdev->dev, "invalid number of channels %u\n",\r\ntmu->num_channels);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int sh_tmu_setup(struct sh_tmu_device *tmu, struct platform_device *pdev)\r\n{\r\nunsigned int i;\r\nint ret;\r\ntmu->pdev = pdev;\r\nraw_spin_lock_init(&tmu->lock);\r\nif (IS_ENABLED(CONFIG_OF) && pdev->dev.of_node) {\r\nret = sh_tmu_parse_dt(tmu);\r\nif (ret < 0)\r\nreturn ret;\r\n} else if (pdev->dev.platform_data) {\r\nconst struct platform_device_id *id = pdev->id_entry;\r\nstruct sh_timer_config *cfg = pdev->dev.platform_data;\r\ntmu->model = id->driver_data;\r\ntmu->num_channels = hweight8(cfg->channels_mask);\r\n} else {\r\ndev_err(&tmu->pdev->dev, "missing platform data\n");\r\nreturn -ENXIO;\r\n}\r\ntmu->clk = clk_get(&tmu->pdev->dev, "fck");\r\nif (IS_ERR(tmu->clk)) {\r\ndev_err(&tmu->pdev->dev, "cannot get clock\n");\r\nreturn PTR_ERR(tmu->clk);\r\n}\r\nret = clk_prepare(tmu->clk);\r\nif (ret < 0)\r\ngoto err_clk_put;\r\nret = sh_tmu_map_memory(tmu);\r\nif (ret < 0) {\r\ndev_err(&tmu->pdev->dev, "failed to remap I/O memory\n");\r\ngoto err_clk_unprepare;\r\n}\r\ntmu->channels = kzalloc(sizeof(*tmu->channels) * tmu->num_channels,\r\nGFP_KERNEL);\r\nif (tmu->channels == NULL) {\r\nret = -ENOMEM;\r\ngoto err_unmap;\r\n}\r\nfor (i = 0; i < tmu->num_channels; ++i) {\r\nret = sh_tmu_channel_setup(&tmu->channels[i], i,\r\ni == 0, i == 1, tmu);\r\nif (ret < 0)\r\ngoto err_unmap;\r\n}\r\nplatform_set_drvdata(pdev, tmu);\r\nreturn 0;\r\nerr_unmap:\r\nkfree(tmu->channels);\r\niounmap(tmu->mapbase);\r\nerr_clk_unprepare:\r\nclk_unprepare(tmu->clk);\r\nerr_clk_put:\r\nclk_put(tmu->clk);\r\nreturn ret;\r\n}\r\nstatic int sh_tmu_probe(struct platform_device *pdev)\r\n{\r\nstruct sh_tmu_device *tmu = platform_get_drvdata(pdev);\r\nint ret;\r\nif (!is_early_platform_device(pdev)) {\r\npm_runtime_set_active(&pdev->dev);\r\npm_runtime_enable(&pdev->dev);\r\n}\r\nif (tmu) {\r\ndev_info(&pdev->dev, "kept as earlytimer\n");\r\ngoto out;\r\n}\r\ntmu = kzalloc(sizeof(*tmu), GFP_KERNEL);\r\nif (tmu == NULL)\r\nreturn -ENOMEM;\r\nret = sh_tmu_setup(tmu, pdev);\r\nif (ret) {\r\nkfree(tmu);\r\npm_runtime_idle(&pdev->dev);\r\nreturn ret;\r\n}\r\nif (is_early_platform_device(pdev))\r\nreturn 0;\r\nout:\r\nif (tmu->has_clockevent || tmu->has_clocksource)\r\npm_runtime_irq_safe(&pdev->dev);\r\nelse\r\npm_runtime_idle(&pdev->dev);\r\nreturn 0;\r\n}\r\nstatic int sh_tmu_remove(struct platform_device *pdev)\r\n{\r\nreturn -EBUSY;\r\n}\r\nstatic int __init sh_tmu_init(void)\r\n{\r\nreturn platform_driver_register(&sh_tmu_device_driver);\r\n}\r\nstatic void __exit sh_tmu_exit(void)\r\n{\r\nplatform_driver_unregister(&sh_tmu_device_driver);\r\n}
