static u32 crc32c_intel_le_hw_byte(u32 crc, unsigned char const *data, size_t length)\r\n{\r\nwhile (length--) {\r\n__asm__ __volatile__(\r\n".byte 0xf2, 0xf, 0x38, 0xf0, 0xf1"\r\n:"=S"(crc)\r\n:"0"(crc), "c"(*data)\r\n);\r\ndata++;\r\n}\r\nreturn crc;\r\n}\r\nstatic u32 __pure crc32c_intel_le_hw(u32 crc, unsigned char const *p, size_t len)\r\n{\r\nunsigned int iquotient = len / SCALE_F;\r\nunsigned int iremainder = len % SCALE_F;\r\nunsigned long *ptmp = (unsigned long *)p;\r\nwhile (iquotient--) {\r\n__asm__ __volatile__(\r\n".byte 0xf2, " REX_PRE "0xf, 0x38, 0xf1, 0xf1;"\r\n:"=S"(crc)\r\n:"0"(crc), "c"(*ptmp)\r\n);\r\nptmp++;\r\n}\r\nif (iremainder)\r\ncrc = crc32c_intel_le_hw_byte(crc, (unsigned char *)ptmp,\r\niremainder);\r\nreturn crc;\r\n}\r\nstatic int crc32c_intel_setkey(struct crypto_shash *hash, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nu32 *mctx = crypto_shash_ctx(hash);\r\nif (keylen != sizeof(u32)) {\r\ncrypto_shash_set_flags(hash, CRYPTO_TFM_RES_BAD_KEY_LEN);\r\nreturn -EINVAL;\r\n}\r\n*mctx = le32_to_cpup((__le32 *)key);\r\nreturn 0;\r\n}\r\nstatic int crc32c_intel_init(struct shash_desc *desc)\r\n{\r\nu32 *mctx = crypto_shash_ctx(desc->tfm);\r\nu32 *crcp = shash_desc_ctx(desc);\r\n*crcp = *mctx;\r\nreturn 0;\r\n}\r\nstatic int crc32c_intel_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nu32 *crcp = shash_desc_ctx(desc);\r\n*crcp = crc32c_intel_le_hw(*crcp, data, len);\r\nreturn 0;\r\n}\r\nstatic int __crc32c_intel_finup(u32 *crcp, const u8 *data, unsigned int len,\r\nu8 *out)\r\n{\r\n*(__le32 *)out = ~cpu_to_le32(crc32c_intel_le_hw(*crcp, data, len));\r\nreturn 0;\r\n}\r\nstatic int crc32c_intel_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn __crc32c_intel_finup(shash_desc_ctx(desc), data, len, out);\r\n}\r\nstatic int crc32c_intel_final(struct shash_desc *desc, u8 *out)\r\n{\r\nu32 *crcp = shash_desc_ctx(desc);\r\n*(__le32 *)out = ~cpu_to_le32p(crcp);\r\nreturn 0;\r\n}\r\nstatic int crc32c_intel_digest(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn __crc32c_intel_finup(crypto_shash_ctx(desc->tfm), data, len,\r\nout);\r\n}\r\nstatic int crc32c_intel_cra_init(struct crypto_tfm *tfm)\r\n{\r\nu32 *key = crypto_tfm_ctx(tfm);\r\n*key = ~0;\r\nreturn 0;\r\n}\r\nstatic int crc32c_pcl_intel_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nu32 *crcp = shash_desc_ctx(desc);\r\nif (len >= CRC32C_PCL_BREAKEVEN && irq_fpu_usable()) {\r\nkernel_fpu_begin();\r\n*crcp = crc_pcl(data, len, *crcp);\r\nkernel_fpu_end();\r\n} else\r\n*crcp = crc32c_intel_le_hw(*crcp, data, len);\r\nreturn 0;\r\n}\r\nstatic int __crc32c_pcl_intel_finup(u32 *crcp, const u8 *data, unsigned int len,\r\nu8 *out)\r\n{\r\nif (len >= CRC32C_PCL_BREAKEVEN && irq_fpu_usable()) {\r\nkernel_fpu_begin();\r\n*(__le32 *)out = ~cpu_to_le32(crc_pcl(data, len, *crcp));\r\nkernel_fpu_end();\r\n} else\r\n*(__le32 *)out =\r\n~cpu_to_le32(crc32c_intel_le_hw(*crcp, data, len));\r\nreturn 0;\r\n}\r\nstatic int crc32c_pcl_intel_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn __crc32c_pcl_intel_finup(shash_desc_ctx(desc), data, len, out);\r\n}\r\nstatic int crc32c_pcl_intel_digest(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nreturn __crc32c_pcl_intel_finup(crypto_shash_ctx(desc->tfm), data, len,\r\nout);\r\n}\r\nstatic int __init crc32c_intel_mod_init(void)\r\n{\r\nif (!x86_match_cpu(crc32c_cpu_id))\r\nreturn -ENODEV;\r\n#ifdef CONFIG_X86_64\r\nif (boot_cpu_has(X86_FEATURE_PCLMULQDQ)) {\r\nalg.update = crc32c_pcl_intel_update;\r\nalg.finup = crc32c_pcl_intel_finup;\r\nalg.digest = crc32c_pcl_intel_digest;\r\n}\r\n#endif\r\nreturn crypto_register_shash(&alg);\r\n}\r\nstatic void __exit crc32c_intel_mod_fini(void)\r\n{\r\ncrypto_unregister_shash(&alg);\r\n}
