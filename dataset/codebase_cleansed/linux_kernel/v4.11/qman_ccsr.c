static bool qm_ecir_is_dcp(const struct qm_ecir *p)\r\n{\r\nreturn p->info & BIT(29);\r\n}\r\nstatic int qm_ecir_get_pnum(const struct qm_ecir *p)\r\n{\r\nreturn (p->info >> 24) & 0x1f;\r\n}\r\nstatic int qm_ecir_get_fqid(const struct qm_ecir *p)\r\n{\r\nreturn p->info & (BIT(24) - 1);\r\n}\r\nstatic bool qm_ecir2_is_dcp(const struct qm_ecir2 *p)\r\n{\r\nreturn p->info & BIT(31);\r\n}\r\nstatic int qm_ecir2_get_pnum(const struct qm_ecir2 *p)\r\n{\r\nreturn p->info & (BIT(10) - 1);\r\n}\r\nstatic int qm_eadr_get_memid(const struct qm_eadr *p)\r\n{\r\nreturn (p->info >> 24) & 0xf;\r\n}\r\nstatic int qm_eadr_get_eadr(const struct qm_eadr *p)\r\n{\r\nreturn p->info & (BIT(12) - 1);\r\n}\r\nstatic int qm_eadr_v3_get_memid(const struct qm_eadr *p)\r\n{\r\nreturn (p->info >> 24) & 0x1f;\r\n}\r\nstatic int qm_eadr_v3_get_eadr(const struct qm_eadr *p)\r\n{\r\nreturn p->info & (BIT(16) - 1);\r\n}\r\nstatic inline u32 qm_ccsr_in(u32 offset)\r\n{\r\nreturn ioread32be(qm_ccsr_start + offset/4);\r\n}\r\nstatic inline void qm_ccsr_out(u32 offset, u32 val)\r\n{\r\niowrite32be(val, qm_ccsr_start + offset/4);\r\n}\r\nu32 qm_get_pools_sdqcr(void)\r\n{\r\nreturn qm_pools_sdqcr;\r\n}\r\nstatic void qm_set_dc(enum qm_dc_portal portal, int ed, u8 sernd)\r\n{\r\nDPAA_ASSERT(!ed || portal == qm_dc_portal_fman0 ||\r\nportal == qm_dc_portal_fman1);\r\nif ((qman_ip_rev & 0xFF00) >= QMAN_REV30)\r\nqm_ccsr_out(REG_DCP_CFG(portal),\r\n(ed ? 0x1000 : 0) | (sernd & 0x3ff));\r\nelse\r\nqm_ccsr_out(REG_DCP_CFG(portal),\r\n(ed ? 0x100 : 0) | (sernd & 0x1f));\r\n}\r\nstatic void qm_set_wq_scheduling(enum qm_wq_class wq_class,\r\nu8 cs_elev, u8 csw2, u8 csw3, u8 csw4,\r\nu8 csw5, u8 csw6, u8 csw7)\r\n{\r\nqm_ccsr_out(REG_WQ_CS_CFG(wq_class), ((cs_elev & 0xff) << 24) |\r\n((csw2 & 0x7) << 20) | ((csw3 & 0x7) << 16) |\r\n((csw4 & 0x7) << 12) | ((csw5 & 0x7) << 8) |\r\n((csw6 & 0x7) << 4) | (csw7 & 0x7));\r\n}\r\nstatic void qm_set_hid(void)\r\n{\r\nqm_ccsr_out(REG_HID_CFG, 0);\r\n}\r\nstatic void qm_set_corenet_initiator(void)\r\n{\r\nqm_ccsr_out(REG_CI_SCHED_CFG, QM_CI_SCHED_CFG_SRCCIV_EN |\r\n(QM_CI_SCHED_CFG_SRCCIV << 24) |\r\n(QM_CI_SCHED_CFG_SRQ_W << 8) |\r\n(QM_CI_SCHED_CFG_RW_W << 4) |\r\nQM_CI_SCHED_CFG_BMAN_W);\r\n}\r\nstatic void qm_get_version(u16 *id, u8 *major, u8 *minor)\r\n{\r\nu32 v = qm_ccsr_in(REG_IP_REV_1);\r\n*id = (v >> 16);\r\n*major = (v >> 8) & 0xff;\r\n*minor = v & 0xff;\r\n}\r\nstatic void qm_set_memory(enum qm_memory memory, u64 ba, u32 size)\r\n{\r\nu32 offset = (memory == qm_memory_fqd) ? REG_FQD_BARE : REG_PFDR_BARE;\r\nu32 exp = ilog2(size);\r\nDPAA_ASSERT((size >= 4096) && (size <= 1024*1024*1024) &&\r\nis_power_of_2(size));\r\nDPAA_ASSERT(!(ba & (size - 1)));\r\nqm_ccsr_out(offset, upper_32_bits(ba));\r\nqm_ccsr_out(offset + REG_offset_BAR, lower_32_bits(ba));\r\nqm_ccsr_out(offset + REG_offset_AR, PFDR_AR_EN | (exp - 1));\r\n}\r\nstatic void qm_set_pfdr_threshold(u32 th, u8 k)\r\n{\r\nqm_ccsr_out(REG_PFDR_FP_LWIT, th & 0xffffff);\r\nqm_ccsr_out(REG_PFDR_CFG, k);\r\n}\r\nstatic void qm_set_sfdr_threshold(u16 th)\r\n{\r\nqm_ccsr_out(REG_SFDR_CFG, th & 0x3ff);\r\n}\r\nstatic int qm_init_pfdr(struct device *dev, u32 pfdr_start, u32 num)\r\n{\r\nu8 rslt = MCR_get_rslt(qm_ccsr_in(REG_MCR));\r\nDPAA_ASSERT(pfdr_start && !(pfdr_start & 7) && !(num & 7) && num);\r\nif (!MCR_rslt_idle(rslt)) {\r\ndev_crit(dev, "QMAN_MCR isn't idle");\r\nWARN_ON(1);\r\n}\r\nqm_ccsr_out(REG_MCP(0), pfdr_start);\r\nqm_ccsr_out(REG_MCP(1), pfdr_start + num - 16);\r\ndma_wmb();\r\nqm_ccsr_out(REG_MCR, MCR_INIT_PFDR);\r\ndo {\r\nrslt = MCR_get_rslt(qm_ccsr_in(REG_MCR));\r\n} while (!MCR_rslt_idle(rslt));\r\nif (MCR_rslt_ok(rslt))\r\nreturn 0;\r\nif (MCR_rslt_eaccess(rslt))\r\nreturn -EACCES;\r\nif (MCR_rslt_inval(rslt))\r\nreturn -EINVAL;\r\ndev_crit(dev, "Unexpected result from MCR_INIT_PFDR: %02x\n", rslt);\r\nreturn -ENODEV;\r\n}\r\nstatic int qman_fqd(struct reserved_mem *rmem)\r\n{\r\nfqd_a = rmem->base;\r\nfqd_sz = rmem->size;\r\nWARN_ON(!(fqd_a && fqd_sz));\r\nreturn 0;\r\n}\r\nstatic int qman_pfdr(struct reserved_mem *rmem)\r\n{\r\npfdr_a = rmem->base;\r\npfdr_sz = rmem->size;\r\nWARN_ON(!(pfdr_a && pfdr_sz));\r\nreturn 0;\r\n}\r\nstatic unsigned int qm_get_fqid_maxcnt(void)\r\n{\r\nreturn fqd_sz / 64;\r\n}\r\nstatic int zero_priv_mem(struct device *dev, struct device_node *node,\r\nphys_addr_t addr, size_t sz)\r\n{\r\nvoid __iomem *tmpp = ioremap_prot(addr, sz, 0);\r\nif (!tmpp)\r\nreturn -ENOMEM;\r\nmemset_io(tmpp, 0, sz);\r\nflush_dcache_range((unsigned long)tmpp,\r\n(unsigned long)tmpp + sz);\r\niounmap(tmpp);\r\nreturn 0;\r\n}\r\nstatic void log_edata_bits(struct device *dev, u32 bit_count)\r\n{\r\nu32 i, j, mask = 0xffffffff;\r\ndev_warn(dev, "ErrInt, EDATA:\n");\r\ni = bit_count / 32;\r\nif (bit_count % 32) {\r\ni++;\r\nmask = ~(mask << bit_count % 32);\r\n}\r\nj = 16 - i;\r\ndev_warn(dev, " 0x%08x\n", qm_ccsr_in(REG_EDATA(j)) & mask);\r\nj++;\r\nfor (; j < 16; j++)\r\ndev_warn(dev, " 0x%08x\n", qm_ccsr_in(REG_EDATA(j)));\r\n}\r\nstatic void log_additional_error_info(struct device *dev, u32 isr_val,\r\nu32 ecsr_val)\r\n{\r\nstruct qm_ecir ecir_val;\r\nstruct qm_eadr eadr_val;\r\nint memid;\r\necir_val.info = qm_ccsr_in(REG_ECIR);\r\nif ((qman_ip_rev & 0xFF00) >= QMAN_REV30) {\r\nstruct qm_ecir2 ecir2_val;\r\necir2_val.info = qm_ccsr_in(REG_ECIR2);\r\nif (ecsr_val & PORTAL_ECSR_ERR) {\r\ndev_warn(dev, "ErrInt: %s id %d\n",\r\nqm_ecir2_is_dcp(&ecir2_val) ? "DCP" : "SWP",\r\nqm_ecir2_get_pnum(&ecir2_val));\r\n}\r\nif (ecsr_val & (FQID_ECSR_ERR | QM_EIRQ_IECE))\r\ndev_warn(dev, "ErrInt: ecir.fqid 0x%x\n",\r\nqm_ecir_get_fqid(&ecir_val));\r\nif (ecsr_val & (QM_EIRQ_SBEI|QM_EIRQ_MBEI)) {\r\neadr_val.info = qm_ccsr_in(REG_EADR);\r\nmemid = qm_eadr_v3_get_memid(&eadr_val);\r\ndev_warn(dev, "ErrInt: EADR Memory: %s, 0x%x\n",\r\nerror_mdata[memid].txt,\r\nerror_mdata[memid].addr_mask\r\n& qm_eadr_v3_get_eadr(&eadr_val));\r\nlog_edata_bits(dev, error_mdata[memid].bits);\r\n}\r\n} else {\r\nif (ecsr_val & PORTAL_ECSR_ERR) {\r\ndev_warn(dev, "ErrInt: %s id %d\n",\r\nqm_ecir_is_dcp(&ecir_val) ? "DCP" : "SWP",\r\nqm_ecir_get_pnum(&ecir_val));\r\n}\r\nif (ecsr_val & FQID_ECSR_ERR)\r\ndev_warn(dev, "ErrInt: ecir.fqid 0x%x\n",\r\nqm_ecir_get_fqid(&ecir_val));\r\nif (ecsr_val & (QM_EIRQ_SBEI|QM_EIRQ_MBEI)) {\r\neadr_val.info = qm_ccsr_in(REG_EADR);\r\nmemid = qm_eadr_get_memid(&eadr_val);\r\ndev_warn(dev, "ErrInt: EADR Memory: %s, 0x%x\n",\r\nerror_mdata[memid].txt,\r\nerror_mdata[memid].addr_mask\r\n& qm_eadr_get_eadr(&eadr_val));\r\nlog_edata_bits(dev, error_mdata[memid].bits);\r\n}\r\n}\r\n}\r\nstatic irqreturn_t qman_isr(int irq, void *ptr)\r\n{\r\nu32 isr_val, ier_val, ecsr_val, isr_mask, i;\r\nstruct device *dev = ptr;\r\nier_val = qm_ccsr_in(REG_ERR_IER);\r\nisr_val = qm_ccsr_in(REG_ERR_ISR);\r\necsr_val = qm_ccsr_in(REG_ECSR);\r\nisr_mask = isr_val & ier_val;\r\nif (!isr_mask)\r\nreturn IRQ_NONE;\r\nfor (i = 0; i < ARRAY_SIZE(qman_hwerr_txts); i++) {\r\nif (qman_hwerr_txts[i].mask & isr_mask) {\r\ndev_err_ratelimited(dev, "ErrInt: %s\n",\r\nqman_hwerr_txts[i].txt);\r\nif (qman_hwerr_txts[i].mask & ecsr_val) {\r\nlog_additional_error_info(dev, isr_mask,\r\necsr_val);\r\nqm_ccsr_out(REG_ECSR, ecsr_val);\r\n}\r\nif (qman_hwerr_txts[i].mask & QMAN_ERRS_TO_DISABLE) {\r\ndev_dbg(dev, "Disabling error 0x%x\n",\r\nqman_hwerr_txts[i].mask);\r\nier_val &= ~qman_hwerr_txts[i].mask;\r\nqm_ccsr_out(REG_ERR_IER, ier_val);\r\n}\r\n}\r\n}\r\nqm_ccsr_out(REG_ERR_ISR, isr_val);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int qman_init_ccsr(struct device *dev)\r\n{\r\nint i, err;\r\nqm_set_memory(qm_memory_fqd, fqd_a, fqd_sz);\r\nqm_set_memory(qm_memory_pfdr, pfdr_a, pfdr_sz);\r\nerr = qm_init_pfdr(dev, 8, pfdr_sz / 64 - 8);\r\nif (err)\r\nreturn err;\r\nqm_set_pfdr_threshold(512, 64);\r\nqm_set_sfdr_threshold(128);\r\nqm_ccsr_out(REG_ERR_ISR, QM_EIRQ_PEBI);\r\nqm_set_corenet_initiator();\r\nqm_set_hid();\r\nfor (i = qm_wq_first; i <= qm_wq_last; i++)\r\nqm_set_wq_scheduling(i, 0, 0, 0, 0, 0, 0, 0);\r\nqm_set_dc(qm_dc_portal_fman0, 1, 0);\r\nqm_set_dc(qm_dc_portal_fman1, 1, 0);\r\nreturn 0;\r\n}\r\nvoid qman_liodn_fixup(u16 channel)\r\n{\r\nstatic int done;\r\nstatic u32 liodn_offset;\r\nu32 before, after;\r\nint idx = channel - QM_CHANNEL_SWPORTAL0;\r\nif ((qman_ip_rev & 0xFF00) >= QMAN_REV30)\r\nbefore = qm_ccsr_in(REG_REV3_QCSP_LIO_CFG(idx));\r\nelse\r\nbefore = qm_ccsr_in(REG_QCSP_LIO_CFG(idx));\r\nif (!done) {\r\nliodn_offset = before & LIO_CFG_LIODN_MASK;\r\ndone = 1;\r\nreturn;\r\n}\r\nafter = (before & (~LIO_CFG_LIODN_MASK)) | liodn_offset;\r\nif ((qman_ip_rev & 0xFF00) >= QMAN_REV30)\r\nqm_ccsr_out(REG_REV3_QCSP_LIO_CFG(idx), after);\r\nelse\r\nqm_ccsr_out(REG_QCSP_LIO_CFG(idx), after);\r\n}\r\nvoid qman_set_sdest(u16 channel, unsigned int cpu_idx)\r\n{\r\nint idx = channel - QM_CHANNEL_SWPORTAL0;\r\nu32 before, after;\r\nif ((qman_ip_rev & 0xFF00) >= QMAN_REV30) {\r\nbefore = qm_ccsr_in(REG_REV3_QCSP_IO_CFG(idx));\r\ncpu_idx /= 2;\r\nafter = (before & (~IO_CFG_SDEST_MASK)) | (cpu_idx << 16);\r\nqm_ccsr_out(REG_REV3_QCSP_IO_CFG(idx), after);\r\n} else {\r\nbefore = qm_ccsr_in(REG_QCSP_IO_CFG(idx));\r\nafter = (before & (~IO_CFG_SDEST_MASK)) | (cpu_idx << 16);\r\nqm_ccsr_out(REG_QCSP_IO_CFG(idx), after);\r\n}\r\n}\r\nstatic int qman_resource_init(struct device *dev)\r\n{\r\nint pool_chan_num, cgrid_num;\r\nint ret, i;\r\nswitch (qman_ip_rev >> 8) {\r\ncase 1:\r\npool_chan_num = 15;\r\ncgrid_num = 256;\r\nbreak;\r\ncase 2:\r\npool_chan_num = 3;\r\ncgrid_num = 64;\r\nbreak;\r\ncase 3:\r\npool_chan_num = 15;\r\ncgrid_num = 256;\r\nbreak;\r\ndefault:\r\nreturn -ENODEV;\r\n}\r\nret = gen_pool_add(qm_qpalloc, qm_channel_pool1 | DPAA_GENALLOC_OFF,\r\npool_chan_num, -1);\r\nif (ret) {\r\ndev_err(dev, "Failed to seed pool channels (%d)\n", ret);\r\nreturn ret;\r\n}\r\nret = gen_pool_add(qm_cgralloc, DPAA_GENALLOC_OFF, cgrid_num, -1);\r\nif (ret) {\r\ndev_err(dev, "Failed to seed CGRID range (%d)\n", ret);\r\nreturn ret;\r\n}\r\nfor (i = 0; i < cgrid_num; i++)\r\nqm_pools_sdqcr |= QM_SDQCR_CHANNELS_POOL_CONV(i);\r\nret = gen_pool_add(qm_fqalloc, QM_FQID_RANGE_START | DPAA_GENALLOC_OFF,\r\nqm_get_fqid_maxcnt() - QM_FQID_RANGE_START, -1);\r\nif (ret) {\r\ndev_err(dev, "Failed to seed FQID range (%d)\n", ret);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int fsl_qman_probe(struct platform_device *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct device_node *node = dev->of_node;\r\nstruct resource *res;\r\nint ret, err_irq;\r\nu16 id;\r\nu8 major, minor;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(dev, "Can't get %s property 'IORESOURCE_MEM'\n",\r\nnode->full_name);\r\nreturn -ENXIO;\r\n}\r\nqm_ccsr_start = devm_ioremap(dev, res->start, resource_size(res));\r\nif (!qm_ccsr_start)\r\nreturn -ENXIO;\r\nqm_get_version(&id, &major, &minor);\r\nif (major == 1 && minor == 0) {\r\ndev_err(dev, "Rev1.0 on P4080 rev1 is not supported!\n");\r\nreturn -ENODEV;\r\n} else if (major == 1 && minor == 1)\r\nqman_ip_rev = QMAN_REV11;\r\nelse if (major == 1 && minor == 2)\r\nqman_ip_rev = QMAN_REV12;\r\nelse if (major == 2 && minor == 0)\r\nqman_ip_rev = QMAN_REV20;\r\nelse if (major == 3 && minor == 0)\r\nqman_ip_rev = QMAN_REV30;\r\nelse if (major == 3 && minor == 1)\r\nqman_ip_rev = QMAN_REV31;\r\nelse {\r\ndev_err(dev, "Unknown QMan version\n");\r\nreturn -ENODEV;\r\n}\r\nif ((qman_ip_rev & 0xff00) >= QMAN_REV30)\r\nqm_channel_pool1 = QMAN_CHANNEL_POOL1_REV3;\r\nret = zero_priv_mem(dev, node, fqd_a, fqd_sz);\r\nWARN_ON(ret);\r\nif (ret)\r\nreturn -ENODEV;\r\nret = qman_init_ccsr(dev);\r\nif (ret) {\r\ndev_err(dev, "CCSR setup failed\n");\r\nreturn ret;\r\n}\r\nerr_irq = platform_get_irq(pdev, 0);\r\nif (err_irq <= 0) {\r\ndev_info(dev, "Can't get %s property 'interrupts'\n",\r\nnode->full_name);\r\nreturn -ENODEV;\r\n}\r\nret = devm_request_irq(dev, err_irq, qman_isr, IRQF_SHARED, "qman-err",\r\ndev);\r\nif (ret) {\r\ndev_err(dev, "devm_request_irq() failed %d for '%s'\n",\r\nret, node->full_name);\r\nreturn ret;\r\n}\r\nqm_ccsr_out(REG_ERR_ISR, 0xffffffff);\r\nqm_ccsr_out(REG_ERR_IER, 0xffffffff);\r\nqm_fqalloc = devm_gen_pool_create(dev, 0, -1, "qman-fqalloc");\r\nif (IS_ERR(qm_fqalloc)) {\r\nret = PTR_ERR(qm_fqalloc);\r\ndev_err(dev, "qman-fqalloc pool init failed (%d)\n", ret);\r\nreturn ret;\r\n}\r\nqm_qpalloc = devm_gen_pool_create(dev, 0, -1, "qman-qpalloc");\r\nif (IS_ERR(qm_qpalloc)) {\r\nret = PTR_ERR(qm_qpalloc);\r\ndev_err(dev, "qman-qpalloc pool init failed (%d)\n", ret);\r\nreturn ret;\r\n}\r\nqm_cgralloc = devm_gen_pool_create(dev, 0, -1, "qman-cgralloc");\r\nif (IS_ERR(qm_cgralloc)) {\r\nret = PTR_ERR(qm_cgralloc);\r\ndev_err(dev, "qman-cgralloc pool init failed (%d)\n", ret);\r\nreturn ret;\r\n}\r\nret = qman_resource_init(dev);\r\nif (ret)\r\nreturn ret;\r\nret = qman_alloc_fq_table(qm_get_fqid_maxcnt());\r\nif (ret)\r\nreturn ret;\r\nret = qman_wq_alloc();\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}
