static int acenic_probe_one(struct pci_dev *pdev,\r\nconst struct pci_device_id *id)\r\n{\r\nstruct net_device *dev;\r\nstruct ace_private *ap;\r\nstatic int boards_found;\r\ndev = alloc_etherdev(sizeof(struct ace_private));\r\nif (dev == NULL)\r\nreturn -ENOMEM;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nap = netdev_priv(dev);\r\nap->pdev = pdev;\r\nap->name = pci_name(pdev);\r\ndev->features |= NETIF_F_SG | NETIF_F_IP_CSUM;\r\ndev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX;\r\ndev->watchdog_timeo = 5*HZ;\r\ndev->min_mtu = 0;\r\ndev->max_mtu = ACE_JUMBO_MTU;\r\ndev->netdev_ops = &ace_netdev_ops;\r\ndev->ethtool_ops = &ace_ethtool_ops;\r\nif (!boards_found)\r\nprintk(version);\r\nif (pci_enable_device(pdev))\r\ngoto fail_free_netdev;\r\npci_set_master(pdev);\r\npci_read_config_word(pdev, PCI_COMMAND, &ap->pci_command);\r\nif (!(ap->pci_command & PCI_COMMAND_MEMORY)) {\r\nprintk(KERN_INFO "%s: Enabling PCI Memory Mapped "\r\n"access - was not enabled by BIOS/Firmware\n",\r\nap->name);\r\nap->pci_command = ap->pci_command | PCI_COMMAND_MEMORY;\r\npci_write_config_word(ap->pdev, PCI_COMMAND,\r\nap->pci_command);\r\nwmb();\r\n}\r\npci_read_config_byte(pdev, PCI_LATENCY_TIMER, &ap->pci_latency);\r\nif (ap->pci_latency <= 0x40) {\r\nap->pci_latency = 0x40;\r\npci_write_config_byte(pdev, PCI_LATENCY_TIMER, ap->pci_latency);\r\n}\r\ndev->base_addr = pci_resource_start(pdev, 0);\r\nap->regs = ioremap(dev->base_addr, 0x4000);\r\nif (!ap->regs) {\r\nprintk(KERN_ERR "%s: Unable to map I/O register, "\r\n"AceNIC %i will be disabled.\n",\r\nap->name, boards_found);\r\ngoto fail_free_netdev;\r\n}\r\nswitch(pdev->vendor) {\r\ncase PCI_VENDOR_ID_ALTEON:\r\nif (pdev->device == PCI_DEVICE_ID_FARALLON_PN9100T) {\r\nprintk(KERN_INFO "%s: Farallon PN9100-T ",\r\nap->name);\r\n} else {\r\nprintk(KERN_INFO "%s: Alteon AceNIC ",\r\nap->name);\r\n}\r\nbreak;\r\ncase PCI_VENDOR_ID_3COM:\r\nprintk(KERN_INFO "%s: 3Com 3C985 ", ap->name);\r\nbreak;\r\ncase PCI_VENDOR_ID_NETGEAR:\r\nprintk(KERN_INFO "%s: NetGear GA620 ", ap->name);\r\nbreak;\r\ncase PCI_VENDOR_ID_DEC:\r\nif (pdev->device == PCI_DEVICE_ID_FARALLON_PN9000SX) {\r\nprintk(KERN_INFO "%s: Farallon PN9000-SX ",\r\nap->name);\r\nbreak;\r\n}\r\ncase PCI_VENDOR_ID_SGI:\r\nprintk(KERN_INFO "%s: SGI AceNIC ", ap->name);\r\nbreak;\r\ndefault:\r\nprintk(KERN_INFO "%s: Unknown AceNIC ", ap->name);\r\nbreak;\r\n}\r\nprintk("Gigabit Ethernet at 0x%08lx, ", dev->base_addr);\r\nprintk("irq %d\n", pdev->irq);\r\n#ifdef CONFIG_ACENIC_OMIT_TIGON_I\r\nif ((readl(&ap->regs->HostCtrl) >> 28) == 4) {\r\nprintk(KERN_ERR "%s: Driver compiled without Tigon I"\r\n" support - NIC disabled\n", dev->name);\r\ngoto fail_uninit;\r\n}\r\n#endif\r\nif (ace_allocate_descriptors(dev))\r\ngoto fail_free_netdev;\r\n#ifdef MODULE\r\nif (boards_found >= ACE_MAX_MOD_PARMS)\r\nap->board_idx = BOARD_IDX_OVERFLOW;\r\nelse\r\nap->board_idx = boards_found;\r\n#else\r\nap->board_idx = BOARD_IDX_STATIC;\r\n#endif\r\nif (ace_init(dev))\r\ngoto fail_free_netdev;\r\nif (register_netdev(dev)) {\r\nprintk(KERN_ERR "acenic: device registration failed\n");\r\ngoto fail_uninit;\r\n}\r\nap->name = dev->name;\r\nif (ap->pci_using_dac)\r\ndev->features |= NETIF_F_HIGHDMA;\r\npci_set_drvdata(pdev, dev);\r\nboards_found++;\r\nreturn 0;\r\nfail_uninit:\r\nace_init_cleanup(dev);\r\nfail_free_netdev:\r\nfree_netdev(dev);\r\nreturn -ENODEV;\r\n}\r\nstatic void acenic_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nshort i;\r\nunregister_netdev(dev);\r\nwritel(readl(&regs->CpuCtrl) | CPU_HALT, &regs->CpuCtrl);\r\nif (ap->version >= 2)\r\nwritel(readl(&regs->CpuBCtrl) | CPU_HALT, &regs->CpuBCtrl);\r\nwritel(1, &regs->Mb0Lo);\r\nreadl(&regs->CpuCtrl);\r\nace_sync_irq(dev->irq);\r\nfor (i = 0; i < RX_STD_RING_ENTRIES; i++) {\r\nstruct sk_buff *skb = ap->skb->rx_std_skbuff[i].skb;\r\nif (skb) {\r\nstruct ring_info *ringp;\r\ndma_addr_t mapping;\r\nringp = &ap->skb->rx_std_skbuff[i];\r\nmapping = dma_unmap_addr(ringp, mapping);\r\npci_unmap_page(ap->pdev, mapping,\r\nACE_STD_BUFSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nap->rx_std_ring[i].size = 0;\r\nap->skb->rx_std_skbuff[i].skb = NULL;\r\ndev_kfree_skb(skb);\r\n}\r\n}\r\nif (ap->version >= 2) {\r\nfor (i = 0; i < RX_MINI_RING_ENTRIES; i++) {\r\nstruct sk_buff *skb = ap->skb->rx_mini_skbuff[i].skb;\r\nif (skb) {\r\nstruct ring_info *ringp;\r\ndma_addr_t mapping;\r\nringp = &ap->skb->rx_mini_skbuff[i];\r\nmapping = dma_unmap_addr(ringp,mapping);\r\npci_unmap_page(ap->pdev, mapping,\r\nACE_MINI_BUFSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nap->rx_mini_ring[i].size = 0;\r\nap->skb->rx_mini_skbuff[i].skb = NULL;\r\ndev_kfree_skb(skb);\r\n}\r\n}\r\n}\r\nfor (i = 0; i < RX_JUMBO_RING_ENTRIES; i++) {\r\nstruct sk_buff *skb = ap->skb->rx_jumbo_skbuff[i].skb;\r\nif (skb) {\r\nstruct ring_info *ringp;\r\ndma_addr_t mapping;\r\nringp = &ap->skb->rx_jumbo_skbuff[i];\r\nmapping = dma_unmap_addr(ringp, mapping);\r\npci_unmap_page(ap->pdev, mapping,\r\nACE_JUMBO_BUFSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nap->rx_jumbo_ring[i].size = 0;\r\nap->skb->rx_jumbo_skbuff[i].skb = NULL;\r\ndev_kfree_skb(skb);\r\n}\r\n}\r\nace_init_cleanup(dev);\r\nfree_netdev(dev);\r\n}\r\nstatic void ace_free_descriptors(struct net_device *dev)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nint size;\r\nif (ap->rx_std_ring != NULL) {\r\nsize = (sizeof(struct rx_desc) *\r\n(RX_STD_RING_ENTRIES +\r\nRX_JUMBO_RING_ENTRIES +\r\nRX_MINI_RING_ENTRIES +\r\nRX_RETURN_RING_ENTRIES));\r\npci_free_consistent(ap->pdev, size, ap->rx_std_ring,\r\nap->rx_ring_base_dma);\r\nap->rx_std_ring = NULL;\r\nap->rx_jumbo_ring = NULL;\r\nap->rx_mini_ring = NULL;\r\nap->rx_return_ring = NULL;\r\n}\r\nif (ap->evt_ring != NULL) {\r\nsize = (sizeof(struct event) * EVT_RING_ENTRIES);\r\npci_free_consistent(ap->pdev, size, ap->evt_ring,\r\nap->evt_ring_dma);\r\nap->evt_ring = NULL;\r\n}\r\nif (ap->tx_ring != NULL && !ACE_IS_TIGON_I(ap)) {\r\nsize = (sizeof(struct tx_desc) * MAX_TX_RING_ENTRIES);\r\npci_free_consistent(ap->pdev, size, ap->tx_ring,\r\nap->tx_ring_dma);\r\n}\r\nap->tx_ring = NULL;\r\nif (ap->evt_prd != NULL) {\r\npci_free_consistent(ap->pdev, sizeof(u32),\r\n(void *)ap->evt_prd, ap->evt_prd_dma);\r\nap->evt_prd = NULL;\r\n}\r\nif (ap->rx_ret_prd != NULL) {\r\npci_free_consistent(ap->pdev, sizeof(u32),\r\n(void *)ap->rx_ret_prd,\r\nap->rx_ret_prd_dma);\r\nap->rx_ret_prd = NULL;\r\n}\r\nif (ap->tx_csm != NULL) {\r\npci_free_consistent(ap->pdev, sizeof(u32),\r\n(void *)ap->tx_csm, ap->tx_csm_dma);\r\nap->tx_csm = NULL;\r\n}\r\n}\r\nstatic int ace_allocate_descriptors(struct net_device *dev)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nint size;\r\nsize = (sizeof(struct rx_desc) *\r\n(RX_STD_RING_ENTRIES +\r\nRX_JUMBO_RING_ENTRIES +\r\nRX_MINI_RING_ENTRIES +\r\nRX_RETURN_RING_ENTRIES));\r\nap->rx_std_ring = pci_alloc_consistent(ap->pdev, size,\r\n&ap->rx_ring_base_dma);\r\nif (ap->rx_std_ring == NULL)\r\ngoto fail;\r\nap->rx_jumbo_ring = ap->rx_std_ring + RX_STD_RING_ENTRIES;\r\nap->rx_mini_ring = ap->rx_jumbo_ring + RX_JUMBO_RING_ENTRIES;\r\nap->rx_return_ring = ap->rx_mini_ring + RX_MINI_RING_ENTRIES;\r\nsize = (sizeof(struct event) * EVT_RING_ENTRIES);\r\nap->evt_ring = pci_alloc_consistent(ap->pdev, size, &ap->evt_ring_dma);\r\nif (ap->evt_ring == NULL)\r\ngoto fail;\r\nif (!ACE_IS_TIGON_I(ap)) {\r\nsize = (sizeof(struct tx_desc) * MAX_TX_RING_ENTRIES);\r\nap->tx_ring = pci_alloc_consistent(ap->pdev, size,\r\n&ap->tx_ring_dma);\r\nif (ap->tx_ring == NULL)\r\ngoto fail;\r\n}\r\nap->evt_prd = pci_alloc_consistent(ap->pdev, sizeof(u32),\r\n&ap->evt_prd_dma);\r\nif (ap->evt_prd == NULL)\r\ngoto fail;\r\nap->rx_ret_prd = pci_alloc_consistent(ap->pdev, sizeof(u32),\r\n&ap->rx_ret_prd_dma);\r\nif (ap->rx_ret_prd == NULL)\r\ngoto fail;\r\nap->tx_csm = pci_alloc_consistent(ap->pdev, sizeof(u32),\r\n&ap->tx_csm_dma);\r\nif (ap->tx_csm == NULL)\r\ngoto fail;\r\nreturn 0;\r\nfail:\r\nace_init_cleanup(dev);\r\nreturn 1;\r\n}\r\nstatic void ace_init_cleanup(struct net_device *dev)\r\n{\r\nstruct ace_private *ap;\r\nap = netdev_priv(dev);\r\nace_free_descriptors(dev);\r\nif (ap->info)\r\npci_free_consistent(ap->pdev, sizeof(struct ace_info),\r\nap->info, ap->info_dma);\r\nkfree(ap->skb);\r\nkfree(ap->trace_buf);\r\nif (dev->irq)\r\nfree_irq(dev->irq, dev);\r\niounmap(ap->regs);\r\n}\r\nstatic inline void ace_issue_cmd(struct ace_regs __iomem *regs, struct cmd *cmd)\r\n{\r\nu32 idx;\r\nidx = readl(&regs->CmdPrd);\r\nwritel(*(u32 *)(cmd), &regs->CmdRng[idx]);\r\nidx = (idx + 1) % CMD_RING_ENTRIES;\r\nwritel(idx, &regs->CmdPrd);\r\n}\r\nstatic int ace_init(struct net_device *dev)\r\n{\r\nstruct ace_private *ap;\r\nstruct ace_regs __iomem *regs;\r\nstruct ace_info *info = NULL;\r\nstruct pci_dev *pdev;\r\nunsigned long myjif;\r\nu64 tmp_ptr;\r\nu32 tig_ver, mac1, mac2, tmp, pci_state;\r\nint board_idx, ecode = 0;\r\nshort i;\r\nunsigned char cache_size;\r\nap = netdev_priv(dev);\r\nregs = ap->regs;\r\nboard_idx = ap->board_idx;\r\nwritel(HW_RESET | (HW_RESET << 24), &regs->HostCtrl);\r\nreadl(&regs->HostCtrl);\r\nudelay(5);\r\n#ifdef __BIG_ENDIAN\r\nwritel((WORD_SWAP | CLR_INT | ((WORD_SWAP | CLR_INT) << 24)),\r\n&regs->HostCtrl);\r\n#else\r\nwritel((CLR_INT | WORD_SWAP | ((CLR_INT | WORD_SWAP) << 24)),\r\n&regs->HostCtrl);\r\n#endif\r\nreadl(&regs->HostCtrl);\r\nwritel(readl(&regs->CpuCtrl) | CPU_HALT, &regs->CpuCtrl);\r\nreadl(&regs->CpuCtrl);\r\nwritel(0, &regs->Mb0Lo);\r\ntig_ver = readl(&regs->HostCtrl) >> 28;\r\nswitch(tig_ver){\r\n#ifndef CONFIG_ACENIC_OMIT_TIGON_I\r\ncase 4:\r\ncase 5:\r\nprintk(KERN_INFO " Tigon I (Rev. %i), Firmware: %i.%i.%i, ",\r\ntig_ver, ap->firmware_major, ap->firmware_minor,\r\nap->firmware_fix);\r\nwritel(0, &regs->LocalCtrl);\r\nap->version = 1;\r\nap->tx_ring_entries = TIGON_I_TX_RING_ENTRIES;\r\nbreak;\r\n#endif\r\ncase 6:\r\nprintk(KERN_INFO " Tigon II (Rev. %i), Firmware: %i.%i.%i, ",\r\ntig_ver, ap->firmware_major, ap->firmware_minor,\r\nap->firmware_fix);\r\nwritel(readl(&regs->CpuBCtrl) | CPU_HALT, &regs->CpuBCtrl);\r\nreadl(&regs->CpuBCtrl);\r\nwritel(SRAM_BANK_512K, &regs->LocalCtrl);\r\nwritel(SYNC_SRAM_TIMING, &regs->MiscCfg);\r\nap->version = 2;\r\nap->tx_ring_entries = MAX_TX_RING_ENTRIES;\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING " Unsupported Tigon version detected "\r\n"(%i)\n", tig_ver);\r\necode = -ENODEV;\r\ngoto init_error;\r\n}\r\n#ifdef __BIG_ENDIAN\r\nwritel(ACE_BYTE_SWAP_DMA | ACE_WARN | ACE_FATAL | ACE_BYTE_SWAP_BD |\r\nACE_WORD_SWAP_BD | ACE_NO_JUMBO_FRAG, &regs->ModeStat);\r\n#else\r\nwritel(ACE_BYTE_SWAP_DMA | ACE_WARN | ACE_FATAL |\r\nACE_WORD_SWAP_BD | ACE_NO_JUMBO_FRAG, &regs->ModeStat);\r\n#endif\r\nreadl(&regs->ModeStat);\r\nmac1 = 0;\r\nfor(i = 0; i < 4; i++) {\r\nint t;\r\nmac1 = mac1 << 8;\r\nt = read_eeprom_byte(dev, 0x8c+i);\r\nif (t < 0) {\r\necode = -EIO;\r\ngoto init_error;\r\n} else\r\nmac1 |= (t & 0xff);\r\n}\r\nmac2 = 0;\r\nfor(i = 4; i < 8; i++) {\r\nint t;\r\nmac2 = mac2 << 8;\r\nt = read_eeprom_byte(dev, 0x8c+i);\r\nif (t < 0) {\r\necode = -EIO;\r\ngoto init_error;\r\n} else\r\nmac2 |= (t & 0xff);\r\n}\r\nwritel(mac1, &regs->MacAddrHi);\r\nwritel(mac2, &regs->MacAddrLo);\r\ndev->dev_addr[0] = (mac1 >> 8) & 0xff;\r\ndev->dev_addr[1] = mac1 & 0xff;\r\ndev->dev_addr[2] = (mac2 >> 24) & 0xff;\r\ndev->dev_addr[3] = (mac2 >> 16) & 0xff;\r\ndev->dev_addr[4] = (mac2 >> 8) & 0xff;\r\ndev->dev_addr[5] = mac2 & 0xff;\r\nprintk("MAC: %pM\n", dev->dev_addr);\r\npdev = ap->pdev;\r\npci_read_config_byte(pdev, PCI_CACHE_LINE_SIZE, &cache_size);\r\ncache_size <<= 2;\r\nif (cache_size != SMP_CACHE_BYTES) {\r\nprintk(KERN_INFO " PCI cache line size set incorrectly "\r\n"(%i bytes) by BIOS/FW, ", cache_size);\r\nif (cache_size > SMP_CACHE_BYTES)\r\nprintk("expecting %i\n", SMP_CACHE_BYTES);\r\nelse {\r\nprintk("correcting to %i\n", SMP_CACHE_BYTES);\r\npci_write_config_byte(pdev, PCI_CACHE_LINE_SIZE,\r\nSMP_CACHE_BYTES >> 2);\r\n}\r\n}\r\npci_state = readl(&regs->PciState);\r\nprintk(KERN_INFO " PCI bus width: %i bits, speed: %iMHz, "\r\n"latency: %i clks\n",\r\n(pci_state & PCI_32BIT) ? 32 : 64,\r\n(pci_state & PCI_66MHZ) ? 66 : 33,\r\nap->pci_latency);\r\ntmp = READ_CMD_MEM | WRITE_CMD_MEM;\r\nif (ap->version >= 2) {\r\ntmp |= (MEM_READ_MULTIPLE | (pci_state & PCI_66MHZ));\r\nif (board_idx == BOARD_IDX_OVERFLOW ||\r\ndis_pci_mem_inval[board_idx]) {\r\nif (ap->pci_command & PCI_COMMAND_INVALIDATE) {\r\nap->pci_command &= ~PCI_COMMAND_INVALIDATE;\r\npci_write_config_word(pdev, PCI_COMMAND,\r\nap->pci_command);\r\nprintk(KERN_INFO " Disabling PCI memory "\r\n"write and invalidate\n");\r\n}\r\n} else if (ap->pci_command & PCI_COMMAND_INVALIDATE) {\r\nprintk(KERN_INFO " PCI memory write & invalidate "\r\n"enabled by BIOS, enabling counter measures\n");\r\nswitch(SMP_CACHE_BYTES) {\r\ncase 16:\r\ntmp |= DMA_WRITE_MAX_16;\r\nbreak;\r\ncase 32:\r\ntmp |= DMA_WRITE_MAX_32;\r\nbreak;\r\ncase 64:\r\ntmp |= DMA_WRITE_MAX_64;\r\nbreak;\r\ncase 128:\r\ntmp |= DMA_WRITE_MAX_128;\r\nbreak;\r\ndefault:\r\nprintk(KERN_INFO " Cache line size %i not "\r\n"supported, PCI write and invalidate "\r\n"disabled\n", SMP_CACHE_BYTES);\r\nap->pci_command &= ~PCI_COMMAND_INVALIDATE;\r\npci_write_config_word(pdev, PCI_COMMAND,\r\nap->pci_command);\r\n}\r\n}\r\n}\r\n#ifdef __sparc__\r\ntmp &= ~DMA_READ_WRITE_MASK;\r\ntmp |= DMA_READ_MAX_64;\r\ntmp |= DMA_WRITE_MAX_64;\r\n#endif\r\n#ifdef __alpha__\r\ntmp &= ~DMA_READ_WRITE_MASK;\r\ntmp |= DMA_READ_MAX_128;\r\ntmp |= DMA_WRITE_MAX_128;\r\n#endif\r\nwritel(tmp, &regs->PciState);\r\n#if 0\r\nif (!(ap->pci_command & PCI_COMMAND_FAST_BACK)) {\r\nprintk(KERN_INFO " Enabling PCI Fast Back to Back\n");\r\nap->pci_command |= PCI_COMMAND_FAST_BACK;\r\npci_write_config_word(pdev, PCI_COMMAND, ap->pci_command);\r\n}\r\n#endif\r\nif (!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {\r\nap->pci_using_dac = 1;\r\n} else if (!pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) {\r\nap->pci_using_dac = 0;\r\n} else {\r\necode = -ENODEV;\r\ngoto init_error;\r\n}\r\nif (!(info = pci_alloc_consistent(ap->pdev, sizeof(struct ace_info),\r\n&ap->info_dma))) {\r\necode = -EAGAIN;\r\ngoto init_error;\r\n}\r\nap->info = info;\r\nif (!(ap->skb = kmalloc(sizeof(struct ace_skb), GFP_KERNEL))) {\r\necode = -EAGAIN;\r\ngoto init_error;\r\n}\r\necode = request_irq(pdev->irq, ace_interrupt, IRQF_SHARED,\r\nDRV_NAME, dev);\r\nif (ecode) {\r\nprintk(KERN_WARNING "%s: Requested IRQ %d is busy\n",\r\nDRV_NAME, pdev->irq);\r\ngoto init_error;\r\n} else\r\ndev->irq = pdev->irq;\r\n#ifdef INDEX_DEBUG\r\nspin_lock_init(&ap->debug_lock);\r\nap->last_tx = ACE_TX_RING_ENTRIES(ap) - 1;\r\nap->last_std_rx = 0;\r\nap->last_mini_rx = 0;\r\n#endif\r\nmemset(ap->info, 0, sizeof(struct ace_info));\r\nmemset(ap->skb, 0, sizeof(struct ace_skb));\r\necode = ace_load_firmware(dev);\r\nif (ecode)\r\ngoto init_error;\r\nap->fw_running = 0;\r\ntmp_ptr = ap->info_dma;\r\nwritel(tmp_ptr >> 32, &regs->InfoPtrHi);\r\nwritel(tmp_ptr & 0xffffffff, &regs->InfoPtrLo);\r\nmemset(ap->evt_ring, 0, EVT_RING_ENTRIES * sizeof(struct event));\r\nset_aceaddr(&info->evt_ctrl.rngptr, ap->evt_ring_dma);\r\ninfo->evt_ctrl.flags = 0;\r\n*(ap->evt_prd) = 0;\r\nwmb();\r\nset_aceaddr(&info->evt_prd_ptr, ap->evt_prd_dma);\r\nwritel(0, &regs->EvtCsm);\r\nset_aceaddr(&info->cmd_ctrl.rngptr, 0x100);\r\ninfo->cmd_ctrl.flags = 0;\r\ninfo->cmd_ctrl.max_len = 0;\r\nfor (i = 0; i < CMD_RING_ENTRIES; i++)\r\nwritel(0, &regs->CmdRng[i]);\r\nwritel(0, &regs->CmdPrd);\r\nwritel(0, &regs->CmdCsm);\r\ntmp_ptr = ap->info_dma;\r\ntmp_ptr += (unsigned long) &(((struct ace_info *)0)->s.stats);\r\nset_aceaddr(&info->stats2_ptr, (dma_addr_t) tmp_ptr);\r\nset_aceaddr(&info->rx_std_ctrl.rngptr, ap->rx_ring_base_dma);\r\ninfo->rx_std_ctrl.max_len = ACE_STD_BUFSIZE;\r\ninfo->rx_std_ctrl.flags =\r\nRCB_FLG_TCP_UDP_SUM | RCB_FLG_NO_PSEUDO_HDR | RCB_FLG_VLAN_ASSIST;\r\nmemset(ap->rx_std_ring, 0,\r\nRX_STD_RING_ENTRIES * sizeof(struct rx_desc));\r\nfor (i = 0; i < RX_STD_RING_ENTRIES; i++)\r\nap->rx_std_ring[i].flags = BD_FLG_TCP_UDP_SUM;\r\nap->rx_std_skbprd = 0;\r\natomic_set(&ap->cur_rx_bufs, 0);\r\nset_aceaddr(&info->rx_jumbo_ctrl.rngptr,\r\n(ap->rx_ring_base_dma +\r\n(sizeof(struct rx_desc) * RX_STD_RING_ENTRIES)));\r\ninfo->rx_jumbo_ctrl.max_len = 0;\r\ninfo->rx_jumbo_ctrl.flags =\r\nRCB_FLG_TCP_UDP_SUM | RCB_FLG_NO_PSEUDO_HDR | RCB_FLG_VLAN_ASSIST;\r\nmemset(ap->rx_jumbo_ring, 0,\r\nRX_JUMBO_RING_ENTRIES * sizeof(struct rx_desc));\r\nfor (i = 0; i < RX_JUMBO_RING_ENTRIES; i++)\r\nap->rx_jumbo_ring[i].flags = BD_FLG_TCP_UDP_SUM | BD_FLG_JUMBO;\r\nap->rx_jumbo_skbprd = 0;\r\natomic_set(&ap->cur_jumbo_bufs, 0);\r\nmemset(ap->rx_mini_ring, 0,\r\nRX_MINI_RING_ENTRIES * sizeof(struct rx_desc));\r\nif (ap->version >= 2) {\r\nset_aceaddr(&info->rx_mini_ctrl.rngptr,\r\n(ap->rx_ring_base_dma +\r\n(sizeof(struct rx_desc) *\r\n(RX_STD_RING_ENTRIES +\r\nRX_JUMBO_RING_ENTRIES))));\r\ninfo->rx_mini_ctrl.max_len = ACE_MINI_SIZE;\r\ninfo->rx_mini_ctrl.flags =\r\nRCB_FLG_TCP_UDP_SUM|RCB_FLG_NO_PSEUDO_HDR|RCB_FLG_VLAN_ASSIST;\r\nfor (i = 0; i < RX_MINI_RING_ENTRIES; i++)\r\nap->rx_mini_ring[i].flags =\r\nBD_FLG_TCP_UDP_SUM | BD_FLG_MINI;\r\n} else {\r\nset_aceaddr(&info->rx_mini_ctrl.rngptr, 0);\r\ninfo->rx_mini_ctrl.flags = RCB_FLG_RNG_DISABLE;\r\ninfo->rx_mini_ctrl.max_len = 0;\r\n}\r\nap->rx_mini_skbprd = 0;\r\natomic_set(&ap->cur_mini_bufs, 0);\r\nset_aceaddr(&info->rx_return_ctrl.rngptr,\r\n(ap->rx_ring_base_dma +\r\n(sizeof(struct rx_desc) *\r\n(RX_STD_RING_ENTRIES +\r\nRX_JUMBO_RING_ENTRIES +\r\nRX_MINI_RING_ENTRIES))));\r\ninfo->rx_return_ctrl.flags = 0;\r\ninfo->rx_return_ctrl.max_len = RX_RETURN_RING_ENTRIES;\r\nmemset(ap->rx_return_ring, 0,\r\nRX_RETURN_RING_ENTRIES * sizeof(struct rx_desc));\r\nset_aceaddr(&info->rx_ret_prd_ptr, ap->rx_ret_prd_dma);\r\n*(ap->rx_ret_prd) = 0;\r\nwritel(TX_RING_BASE, &regs->WinBase);\r\nif (ACE_IS_TIGON_I(ap)) {\r\nap->tx_ring = (__force struct tx_desc *) regs->Window;\r\nfor (i = 0; i < (TIGON_I_TX_RING_ENTRIES\r\n* sizeof(struct tx_desc)) / sizeof(u32); i++)\r\nwritel(0, (__force void __iomem *)ap->tx_ring + i * 4);\r\nset_aceaddr(&info->tx_ctrl.rngptr, TX_RING_BASE);\r\n} else {\r\nmemset(ap->tx_ring, 0,\r\nMAX_TX_RING_ENTRIES * sizeof(struct tx_desc));\r\nset_aceaddr(&info->tx_ctrl.rngptr, ap->tx_ring_dma);\r\n}\r\ninfo->tx_ctrl.max_len = ACE_TX_RING_ENTRIES(ap);\r\ntmp = RCB_FLG_TCP_UDP_SUM | RCB_FLG_NO_PSEUDO_HDR | RCB_FLG_VLAN_ASSIST;\r\nif (!ACE_IS_TIGON_I(ap))\r\ntmp |= RCB_FLG_TX_HOST_RING;\r\n#if TX_COAL_INTS_ONLY\r\ntmp |= RCB_FLG_COAL_INT_ONLY;\r\n#endif\r\ninfo->tx_ctrl.flags = tmp;\r\nset_aceaddr(&info->tx_csm_ptr, ap->tx_csm_dma);\r\n#if 0\r\nwritel(DMA_THRESH_16W, &regs->DmaReadCfg);\r\nwritel(DMA_THRESH_16W, &regs->DmaWriteCfg);\r\n#else\r\nwritel(DMA_THRESH_8W, &regs->DmaReadCfg);\r\nwritel(DMA_THRESH_8W, &regs->DmaWriteCfg);\r\n#endif\r\nwritel(0, &regs->MaskInt);\r\nwritel(1, &regs->IfIdx);\r\n#if 0\r\nwritel(1, &regs->AssistState);\r\n#endif\r\nwritel(DEF_STAT, &regs->TuneStatTicks);\r\nwritel(DEF_TRACE, &regs->TuneTrace);\r\nace_set_rxtx_parms(dev, 0);\r\nif (board_idx == BOARD_IDX_OVERFLOW) {\r\nprintk(KERN_WARNING "%s: more than %i NICs detected, "\r\n"ignoring module parameters!\n",\r\nap->name, ACE_MAX_MOD_PARMS);\r\n} else if (board_idx >= 0) {\r\nif (tx_coal_tick[board_idx])\r\nwritel(tx_coal_tick[board_idx],\r\n&regs->TuneTxCoalTicks);\r\nif (max_tx_desc[board_idx])\r\nwritel(max_tx_desc[board_idx], &regs->TuneMaxTxDesc);\r\nif (rx_coal_tick[board_idx])\r\nwritel(rx_coal_tick[board_idx],\r\n&regs->TuneRxCoalTicks);\r\nif (max_rx_desc[board_idx])\r\nwritel(max_rx_desc[board_idx], &regs->TuneMaxRxDesc);\r\nif (trace[board_idx])\r\nwritel(trace[board_idx], &regs->TuneTrace);\r\nif ((tx_ratio[board_idx] > 0) && (tx_ratio[board_idx] < 64))\r\nwritel(tx_ratio[board_idx], &regs->TxBufRat);\r\n}\r\ntmp = LNK_ENABLE | LNK_FULL_DUPLEX | LNK_1000MB | LNK_100MB |\r\nLNK_10MB | LNK_RX_FLOW_CTL_Y | LNK_NEG_FCTL | LNK_NEGOTIATE;\r\nif(ap->version >= 2)\r\ntmp |= LNK_TX_FLOW_CTL_Y;\r\nif ((board_idx >= 0) && link_state[board_idx]) {\r\nint option = link_state[board_idx];\r\ntmp = LNK_ENABLE;\r\nif (option & 0x01) {\r\nprintk(KERN_INFO "%s: Setting half duplex link\n",\r\nap->name);\r\ntmp &= ~LNK_FULL_DUPLEX;\r\n}\r\nif (option & 0x02)\r\ntmp &= ~LNK_NEGOTIATE;\r\nif (option & 0x10)\r\ntmp |= LNK_10MB;\r\nif (option & 0x20)\r\ntmp |= LNK_100MB;\r\nif (option & 0x40)\r\ntmp |= LNK_1000MB;\r\nif ((option & 0x70) == 0) {\r\nprintk(KERN_WARNING "%s: No media speed specified, "\r\n"forcing auto negotiation\n", ap->name);\r\ntmp |= LNK_NEGOTIATE | LNK_1000MB |\r\nLNK_100MB | LNK_10MB;\r\n}\r\nif ((option & 0x100) == 0)\r\ntmp |= LNK_NEG_FCTL;\r\nelse\r\nprintk(KERN_INFO "%s: Disabling flow control "\r\n"negotiation\n", ap->name);\r\nif (option & 0x200)\r\ntmp |= LNK_RX_FLOW_CTL_Y;\r\nif ((option & 0x400) && (ap->version >= 2)) {\r\nprintk(KERN_INFO "%s: Enabling TX flow control\n",\r\nap->name);\r\ntmp |= LNK_TX_FLOW_CTL_Y;\r\n}\r\n}\r\nap->link = tmp;\r\nwritel(tmp, &regs->TuneLink);\r\nif (ap->version >= 2)\r\nwritel(tmp, &regs->TuneFastLink);\r\nwritel(ap->firmware_start, &regs->Pc);\r\nwritel(0, &regs->Mb0Lo);\r\nap->cur_rx = 0;\r\nap->tx_prd = *(ap->tx_csm) = ap->tx_ret_csm = 0;\r\nwmb();\r\nace_set_txprd(regs, ap, 0);\r\nwritel(0, &regs->RxRetCsm);\r\nwritel(1, &regs->AssistState);\r\nwritel(readl(&regs->CpuCtrl) & ~(CPU_HALT|CPU_TRACE), &regs->CpuCtrl);\r\nreadl(&regs->CpuCtrl);\r\nmyjif = jiffies + 3 * HZ;\r\nwhile (time_before(jiffies, myjif) && !ap->fw_running)\r\ncpu_relax();\r\nif (!ap->fw_running) {\r\nprintk(KERN_ERR "%s: Firmware NOT running!\n", ap->name);\r\nace_dump_trace(ap);\r\nwritel(readl(&regs->CpuCtrl) | CPU_HALT, &regs->CpuCtrl);\r\nreadl(&regs->CpuCtrl);\r\nif (ap->version >= 2)\r\nwritel(readl(&regs->CpuBCtrl) | CPU_HALT,\r\n&regs->CpuBCtrl);\r\nwritel(0, &regs->Mb0Lo);\r\nreadl(&regs->Mb0Lo);\r\necode = -EBUSY;\r\ngoto init_error;\r\n}\r\nif (!test_and_set_bit(0, &ap->std_refill_busy))\r\nace_load_std_rx_ring(dev, RX_RING_SIZE);\r\nelse\r\nprintk(KERN_ERR "%s: Someone is busy refilling the RX ring\n",\r\nap->name);\r\nif (ap->version >= 2) {\r\nif (!test_and_set_bit(0, &ap->mini_refill_busy))\r\nace_load_mini_rx_ring(dev, RX_MINI_SIZE);\r\nelse\r\nprintk(KERN_ERR "%s: Someone is busy refilling "\r\n"the RX mini ring\n", ap->name);\r\n}\r\nreturn 0;\r\ninit_error:\r\nace_init_cleanup(dev);\r\nreturn ecode;\r\n}\r\nstatic void ace_set_rxtx_parms(struct net_device *dev, int jumbo)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nint board_idx = ap->board_idx;\r\nif (board_idx >= 0) {\r\nif (!jumbo) {\r\nif (!tx_coal_tick[board_idx])\r\nwritel(DEF_TX_COAL, &regs->TuneTxCoalTicks);\r\nif (!max_tx_desc[board_idx])\r\nwritel(DEF_TX_MAX_DESC, &regs->TuneMaxTxDesc);\r\nif (!rx_coal_tick[board_idx])\r\nwritel(DEF_RX_COAL, &regs->TuneRxCoalTicks);\r\nif (!max_rx_desc[board_idx])\r\nwritel(DEF_RX_MAX_DESC, &regs->TuneMaxRxDesc);\r\nif (!tx_ratio[board_idx])\r\nwritel(DEF_TX_RATIO, &regs->TxBufRat);\r\n} else {\r\nif (!tx_coal_tick[board_idx])\r\nwritel(DEF_JUMBO_TX_COAL,\r\n&regs->TuneTxCoalTicks);\r\nif (!max_tx_desc[board_idx])\r\nwritel(DEF_JUMBO_TX_MAX_DESC,\r\n&regs->TuneMaxTxDesc);\r\nif (!rx_coal_tick[board_idx])\r\nwritel(DEF_JUMBO_RX_COAL,\r\n&regs->TuneRxCoalTicks);\r\nif (!max_rx_desc[board_idx])\r\nwritel(DEF_JUMBO_RX_MAX_DESC,\r\n&regs->TuneMaxRxDesc);\r\nif (!tx_ratio[board_idx])\r\nwritel(DEF_JUMBO_TX_RATIO, &regs->TxBufRat);\r\n}\r\n}\r\n}\r\nstatic void ace_watchdog(struct net_device *data)\r\n{\r\nstruct net_device *dev = data;\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nif (*ap->tx_csm != ap->tx_ret_csm) {\r\nprintk(KERN_WARNING "%s: Transmitter is stuck, %08x\n",\r\ndev->name, (unsigned int)readl(&regs->HostCtrl));\r\n} else {\r\nprintk(KERN_DEBUG "%s: BUG... transmitter died. Kicking it.\n",\r\ndev->name);\r\n#if 0\r\nnetif_wake_queue(dev);\r\n#endif\r\n}\r\n}\r\nstatic void ace_tasklet(unsigned long arg)\r\n{\r\nstruct net_device *dev = (struct net_device *) arg;\r\nstruct ace_private *ap = netdev_priv(dev);\r\nint cur_size;\r\ncur_size = atomic_read(&ap->cur_rx_bufs);\r\nif ((cur_size < RX_LOW_STD_THRES) &&\r\n!test_and_set_bit(0, &ap->std_refill_busy)) {\r\n#ifdef DEBUG\r\nprintk("refilling buffers (current %i)\n", cur_size);\r\n#endif\r\nace_load_std_rx_ring(dev, RX_RING_SIZE - cur_size);\r\n}\r\nif (ap->version >= 2) {\r\ncur_size = atomic_read(&ap->cur_mini_bufs);\r\nif ((cur_size < RX_LOW_MINI_THRES) &&\r\n!test_and_set_bit(0, &ap->mini_refill_busy)) {\r\n#ifdef DEBUG\r\nprintk("refilling mini buffers (current %i)\n",\r\ncur_size);\r\n#endif\r\nace_load_mini_rx_ring(dev, RX_MINI_SIZE - cur_size);\r\n}\r\n}\r\ncur_size = atomic_read(&ap->cur_jumbo_bufs);\r\nif (ap->jumbo && (cur_size < RX_LOW_JUMBO_THRES) &&\r\n!test_and_set_bit(0, &ap->jumbo_refill_busy)) {\r\n#ifdef DEBUG\r\nprintk("refilling jumbo buffers (current %i)\n", cur_size);\r\n#endif\r\nace_load_jumbo_rx_ring(dev, RX_JUMBO_SIZE - cur_size);\r\n}\r\nap->tasklet_pending = 0;\r\n}\r\nstatic void ace_dump_trace(struct ace_private *ap)\r\n{\r\n#if 0\r\nif (!ap->trace_buf)\r\nif (!(ap->trace_buf = kmalloc(ACE_TRACE_SIZE, GFP_KERNEL)))\r\nreturn;\r\n#endif\r\n}\r\nstatic void ace_load_std_rx_ring(struct net_device *dev, int nr_bufs)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nshort i, idx;\r\nprefetchw(&ap->cur_rx_bufs);\r\nidx = ap->rx_std_skbprd;\r\nfor (i = 0; i < nr_bufs; i++) {\r\nstruct sk_buff *skb;\r\nstruct rx_desc *rd;\r\ndma_addr_t mapping;\r\nskb = netdev_alloc_skb_ip_align(dev, ACE_STD_BUFSIZE);\r\nif (!skb)\r\nbreak;\r\nmapping = pci_map_page(ap->pdev, virt_to_page(skb->data),\r\noffset_in_page(skb->data),\r\nACE_STD_BUFSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nap->skb->rx_std_skbuff[idx].skb = skb;\r\ndma_unmap_addr_set(&ap->skb->rx_std_skbuff[idx],\r\nmapping, mapping);\r\nrd = &ap->rx_std_ring[idx];\r\nset_aceaddr(&rd->addr, mapping);\r\nrd->size = ACE_STD_BUFSIZE;\r\nrd->idx = idx;\r\nidx = (idx + 1) % RX_STD_RING_ENTRIES;\r\n}\r\nif (!i)\r\ngoto error_out;\r\natomic_add(i, &ap->cur_rx_bufs);\r\nap->rx_std_skbprd = idx;\r\nif (ACE_IS_TIGON_I(ap)) {\r\nstruct cmd cmd;\r\ncmd.evt = C_SET_RX_PRD_IDX;\r\ncmd.code = 0;\r\ncmd.idx = ap->rx_std_skbprd;\r\nace_issue_cmd(regs, &cmd);\r\n} else {\r\nwritel(idx, &regs->RxStdPrd);\r\nwmb();\r\n}\r\nout:\r\nclear_bit(0, &ap->std_refill_busy);\r\nreturn;\r\nerror_out:\r\nprintk(KERN_INFO "Out of memory when allocating "\r\n"standard receive buffers\n");\r\ngoto out;\r\n}\r\nstatic void ace_load_mini_rx_ring(struct net_device *dev, int nr_bufs)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nshort i, idx;\r\nprefetchw(&ap->cur_mini_bufs);\r\nidx = ap->rx_mini_skbprd;\r\nfor (i = 0; i < nr_bufs; i++) {\r\nstruct sk_buff *skb;\r\nstruct rx_desc *rd;\r\ndma_addr_t mapping;\r\nskb = netdev_alloc_skb_ip_align(dev, ACE_MINI_BUFSIZE);\r\nif (!skb)\r\nbreak;\r\nmapping = pci_map_page(ap->pdev, virt_to_page(skb->data),\r\noffset_in_page(skb->data),\r\nACE_MINI_BUFSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nap->skb->rx_mini_skbuff[idx].skb = skb;\r\ndma_unmap_addr_set(&ap->skb->rx_mini_skbuff[idx],\r\nmapping, mapping);\r\nrd = &ap->rx_mini_ring[idx];\r\nset_aceaddr(&rd->addr, mapping);\r\nrd->size = ACE_MINI_BUFSIZE;\r\nrd->idx = idx;\r\nidx = (idx + 1) % RX_MINI_RING_ENTRIES;\r\n}\r\nif (!i)\r\ngoto error_out;\r\natomic_add(i, &ap->cur_mini_bufs);\r\nap->rx_mini_skbprd = idx;\r\nwritel(idx, &regs->RxMiniPrd);\r\nwmb();\r\nout:\r\nclear_bit(0, &ap->mini_refill_busy);\r\nreturn;\r\nerror_out:\r\nprintk(KERN_INFO "Out of memory when allocating "\r\n"mini receive buffers\n");\r\ngoto out;\r\n}\r\nstatic void ace_load_jumbo_rx_ring(struct net_device *dev, int nr_bufs)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nshort i, idx;\r\nidx = ap->rx_jumbo_skbprd;\r\nfor (i = 0; i < nr_bufs; i++) {\r\nstruct sk_buff *skb;\r\nstruct rx_desc *rd;\r\ndma_addr_t mapping;\r\nskb = netdev_alloc_skb_ip_align(dev, ACE_JUMBO_BUFSIZE);\r\nif (!skb)\r\nbreak;\r\nmapping = pci_map_page(ap->pdev, virt_to_page(skb->data),\r\noffset_in_page(skb->data),\r\nACE_JUMBO_BUFSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nap->skb->rx_jumbo_skbuff[idx].skb = skb;\r\ndma_unmap_addr_set(&ap->skb->rx_jumbo_skbuff[idx],\r\nmapping, mapping);\r\nrd = &ap->rx_jumbo_ring[idx];\r\nset_aceaddr(&rd->addr, mapping);\r\nrd->size = ACE_JUMBO_BUFSIZE;\r\nrd->idx = idx;\r\nidx = (idx + 1) % RX_JUMBO_RING_ENTRIES;\r\n}\r\nif (!i)\r\ngoto error_out;\r\natomic_add(i, &ap->cur_jumbo_bufs);\r\nap->rx_jumbo_skbprd = idx;\r\nif (ACE_IS_TIGON_I(ap)) {\r\nstruct cmd cmd;\r\ncmd.evt = C_SET_RX_JUMBO_PRD_IDX;\r\ncmd.code = 0;\r\ncmd.idx = ap->rx_jumbo_skbprd;\r\nace_issue_cmd(regs, &cmd);\r\n} else {\r\nwritel(idx, &regs->RxJumboPrd);\r\nwmb();\r\n}\r\nout:\r\nclear_bit(0, &ap->jumbo_refill_busy);\r\nreturn;\r\nerror_out:\r\nif (net_ratelimit())\r\nprintk(KERN_INFO "Out of memory when allocating "\r\n"jumbo receive buffers\n");\r\ngoto out;\r\n}\r\nstatic u32 ace_handle_event(struct net_device *dev, u32 evtcsm, u32 evtprd)\r\n{\r\nstruct ace_private *ap;\r\nap = netdev_priv(dev);\r\nwhile (evtcsm != evtprd) {\r\nswitch (ap->evt_ring[evtcsm].evt) {\r\ncase E_FW_RUNNING:\r\nprintk(KERN_INFO "%s: Firmware up and running\n",\r\nap->name);\r\nap->fw_running = 1;\r\nwmb();\r\nbreak;\r\ncase E_STATS_UPDATED:\r\nbreak;\r\ncase E_LNK_STATE:\r\n{\r\nu16 code = ap->evt_ring[evtcsm].code;\r\nswitch (code) {\r\ncase E_C_LINK_UP:\r\n{\r\nu32 state = readl(&ap->regs->GigLnkState);\r\nprintk(KERN_WARNING "%s: Optical link UP "\r\n"(%s Duplex, Flow Control: %s%s)\n",\r\nap->name,\r\nstate & LNK_FULL_DUPLEX ? "Full":"Half",\r\nstate & LNK_TX_FLOW_CTL_Y ? "TX " : "",\r\nstate & LNK_RX_FLOW_CTL_Y ? "RX" : "");\r\nbreak;\r\n}\r\ncase E_C_LINK_DOWN:\r\nprintk(KERN_WARNING "%s: Optical link DOWN\n",\r\nap->name);\r\nbreak;\r\ncase E_C_LINK_10_100:\r\nprintk(KERN_WARNING "%s: 10/100BaseT link "\r\n"UP\n", ap->name);\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "%s: Unknown optical link "\r\n"state %02x\n", ap->name, code);\r\n}\r\nbreak;\r\n}\r\ncase E_ERROR:\r\nswitch(ap->evt_ring[evtcsm].code) {\r\ncase E_C_ERR_INVAL_CMD:\r\nprintk(KERN_ERR "%s: invalid command error\n",\r\nap->name);\r\nbreak;\r\ncase E_C_ERR_UNIMP_CMD:\r\nprintk(KERN_ERR "%s: unimplemented command "\r\n"error\n", ap->name);\r\nbreak;\r\ncase E_C_ERR_BAD_CFG:\r\nprintk(KERN_ERR "%s: bad config error\n",\r\nap->name);\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "%s: unknown error %02x\n",\r\nap->name, ap->evt_ring[evtcsm].code);\r\n}\r\nbreak;\r\ncase E_RESET_JUMBO_RNG:\r\n{\r\nint i;\r\nfor (i = 0; i < RX_JUMBO_RING_ENTRIES; i++) {\r\nif (ap->skb->rx_jumbo_skbuff[i].skb) {\r\nap->rx_jumbo_ring[i].size = 0;\r\nset_aceaddr(&ap->rx_jumbo_ring[i].addr, 0);\r\ndev_kfree_skb(ap->skb->rx_jumbo_skbuff[i].skb);\r\nap->skb->rx_jumbo_skbuff[i].skb = NULL;\r\n}\r\n}\r\nif (ACE_IS_TIGON_I(ap)) {\r\nstruct cmd cmd;\r\ncmd.evt = C_SET_RX_JUMBO_PRD_IDX;\r\ncmd.code = 0;\r\ncmd.idx = 0;\r\nace_issue_cmd(ap->regs, &cmd);\r\n} else {\r\nwritel(0, &((ap->regs)->RxJumboPrd));\r\nwmb();\r\n}\r\nap->jumbo = 0;\r\nap->rx_jumbo_skbprd = 0;\r\nprintk(KERN_INFO "%s: Jumbo ring flushed\n",\r\nap->name);\r\nclear_bit(0, &ap->jumbo_refill_busy);\r\nbreak;\r\n}\r\ndefault:\r\nprintk(KERN_ERR "%s: Unhandled event 0x%02x\n",\r\nap->name, ap->evt_ring[evtcsm].evt);\r\n}\r\nevtcsm = (evtcsm + 1) % EVT_RING_ENTRIES;\r\n}\r\nreturn evtcsm;\r\n}\r\nstatic void ace_rx_int(struct net_device *dev, u32 rxretprd, u32 rxretcsm)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nu32 idx;\r\nint mini_count = 0, std_count = 0;\r\nidx = rxretcsm;\r\nprefetchw(&ap->cur_rx_bufs);\r\nprefetchw(&ap->cur_mini_bufs);\r\nwhile (idx != rxretprd) {\r\nstruct ring_info *rip;\r\nstruct sk_buff *skb;\r\nstruct rx_desc *rxdesc, *retdesc;\r\nu32 skbidx;\r\nint bd_flags, desc_type, mapsize;\r\nu16 csum;\r\nif (idx == rxretcsm)\r\nrmb();\r\nretdesc = &ap->rx_return_ring[idx];\r\nskbidx = retdesc->idx;\r\nbd_flags = retdesc->flags;\r\ndesc_type = bd_flags & (BD_FLG_JUMBO | BD_FLG_MINI);\r\nswitch(desc_type) {\r\ncase 0:\r\nrip = &ap->skb->rx_std_skbuff[skbidx];\r\nmapsize = ACE_STD_BUFSIZE;\r\nrxdesc = &ap->rx_std_ring[skbidx];\r\nstd_count++;\r\nbreak;\r\ncase BD_FLG_JUMBO:\r\nrip = &ap->skb->rx_jumbo_skbuff[skbidx];\r\nmapsize = ACE_JUMBO_BUFSIZE;\r\nrxdesc = &ap->rx_jumbo_ring[skbidx];\r\natomic_dec(&ap->cur_jumbo_bufs);\r\nbreak;\r\ncase BD_FLG_MINI:\r\nrip = &ap->skb->rx_mini_skbuff[skbidx];\r\nmapsize = ACE_MINI_BUFSIZE;\r\nrxdesc = &ap->rx_mini_ring[skbidx];\r\nmini_count++;\r\nbreak;\r\ndefault:\r\nprintk(KERN_INFO "%s: unknown frame type (0x%02x) "\r\n"returned by NIC\n", dev->name,\r\nretdesc->flags);\r\ngoto error;\r\n}\r\nskb = rip->skb;\r\nrip->skb = NULL;\r\npci_unmap_page(ap->pdev,\r\ndma_unmap_addr(rip, mapping),\r\nmapsize,\r\nPCI_DMA_FROMDEVICE);\r\nskb_put(skb, retdesc->size);\r\ncsum = retdesc->tcp_udp_csum;\r\nskb->protocol = eth_type_trans(skb, dev);\r\nif (bd_flags & BD_FLG_TCP_UDP_SUM) {\r\nskb->csum = htons(csum);\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\n} else {\r\nskb_checksum_none_assert(skb);\r\n}\r\nif ((bd_flags & BD_FLG_VLAN_TAG))\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), retdesc->vlan);\r\nnetif_rx(skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += retdesc->size;\r\nidx = (idx + 1) % RX_RETURN_RING_ENTRIES;\r\n}\r\natomic_sub(std_count, &ap->cur_rx_bufs);\r\nif (!ACE_IS_TIGON_I(ap))\r\natomic_sub(mini_count, &ap->cur_mini_bufs);\r\nout:\r\nif (ACE_IS_TIGON_I(ap)) {\r\nwritel(idx, &ap->regs->RxRetCsm);\r\n}\r\nap->cur_rx = idx;\r\nreturn;\r\nerror:\r\nidx = rxretprd;\r\ngoto out;\r\n}\r\nstatic inline void ace_tx_int(struct net_device *dev,\r\nu32 txcsm, u32 idx)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\ndo {\r\nstruct sk_buff *skb;\r\nstruct tx_ring_info *info;\r\ninfo = ap->skb->tx_skbuff + idx;\r\nskb = info->skb;\r\nif (dma_unmap_len(info, maplen)) {\r\npci_unmap_page(ap->pdev, dma_unmap_addr(info, mapping),\r\ndma_unmap_len(info, maplen),\r\nPCI_DMA_TODEVICE);\r\ndma_unmap_len_set(info, maplen, 0);\r\n}\r\nif (skb) {\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += skb->len;\r\ndev_kfree_skb_irq(skb);\r\ninfo->skb = NULL;\r\n}\r\nidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\r\n} while (idx != txcsm);\r\nif (netif_queue_stopped(dev))\r\nnetif_wake_queue(dev);\r\nwmb();\r\nap->tx_ret_csm = txcsm;\r\n}\r\nstatic irqreturn_t ace_interrupt(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *)dev_id;\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nu32 idx;\r\nu32 txcsm, rxretcsm, rxretprd;\r\nu32 evtcsm, evtprd;\r\nif (!(readl(&regs->HostCtrl) & IN_INT))\r\nreturn IRQ_NONE;\r\nwritel(0, &regs->Mb0Lo);\r\nreadl(&regs->Mb0Lo);\r\nrxretprd = *ap->rx_ret_prd;\r\nrxretcsm = ap->cur_rx;\r\nif (rxretprd != rxretcsm)\r\nace_rx_int(dev, rxretprd, rxretcsm);\r\ntxcsm = *ap->tx_csm;\r\nidx = ap->tx_ret_csm;\r\nif (txcsm != idx) {\r\nif (!tx_ring_full(ap, txcsm, ap->tx_prd))\r\nace_tx_int(dev, txcsm, idx);\r\n}\r\nevtcsm = readl(&regs->EvtCsm);\r\nevtprd = *ap->evt_prd;\r\nif (evtcsm != evtprd) {\r\nevtcsm = ace_handle_event(dev, evtcsm, evtprd);\r\nwritel(evtcsm, &regs->EvtCsm);\r\n}\r\nif (netif_running(dev)) {\r\nint cur_size;\r\nint run_tasklet = 0;\r\ncur_size = atomic_read(&ap->cur_rx_bufs);\r\nif (cur_size < RX_LOW_STD_THRES) {\r\nif ((cur_size < RX_PANIC_STD_THRES) &&\r\n!test_and_set_bit(0, &ap->std_refill_busy)) {\r\n#ifdef DEBUG\r\nprintk("low on std buffers %i\n", cur_size);\r\n#endif\r\nace_load_std_rx_ring(dev,\r\nRX_RING_SIZE - cur_size);\r\n} else\r\nrun_tasklet = 1;\r\n}\r\nif (!ACE_IS_TIGON_I(ap)) {\r\ncur_size = atomic_read(&ap->cur_mini_bufs);\r\nif (cur_size < RX_LOW_MINI_THRES) {\r\nif ((cur_size < RX_PANIC_MINI_THRES) &&\r\n!test_and_set_bit(0,\r\n&ap->mini_refill_busy)) {\r\n#ifdef DEBUG\r\nprintk("low on mini buffers %i\n",\r\ncur_size);\r\n#endif\r\nace_load_mini_rx_ring(dev,\r\nRX_MINI_SIZE - cur_size);\r\n} else\r\nrun_tasklet = 1;\r\n}\r\n}\r\nif (ap->jumbo) {\r\ncur_size = atomic_read(&ap->cur_jumbo_bufs);\r\nif (cur_size < RX_LOW_JUMBO_THRES) {\r\nif ((cur_size < RX_PANIC_JUMBO_THRES) &&\r\n!test_and_set_bit(0,\r\n&ap->jumbo_refill_busy)){\r\n#ifdef DEBUG\r\nprintk("low on jumbo buffers %i\n",\r\ncur_size);\r\n#endif\r\nace_load_jumbo_rx_ring(dev,\r\nRX_JUMBO_SIZE - cur_size);\r\n} else\r\nrun_tasklet = 1;\r\n}\r\n}\r\nif (run_tasklet && !ap->tasklet_pending) {\r\nap->tasklet_pending = 1;\r\ntasklet_schedule(&ap->ace_tasklet);\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int ace_open(struct net_device *dev)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nstruct cmd cmd;\r\nif (!(ap->fw_running)) {\r\nprintk(KERN_WARNING "%s: Firmware not running!\n", dev->name);\r\nreturn -EBUSY;\r\n}\r\nwritel(dev->mtu + ETH_HLEN + 4, &regs->IfMtu);\r\ncmd.evt = C_CLEAR_STATS;\r\ncmd.code = 0;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\ncmd.evt = C_HOST_STATE;\r\ncmd.code = C_C_STACK_UP;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nif (ap->jumbo &&\r\n!test_and_set_bit(0, &ap->jumbo_refill_busy))\r\nace_load_jumbo_rx_ring(dev, RX_JUMBO_SIZE);\r\nif (dev->flags & IFF_PROMISC) {\r\ncmd.evt = C_SET_PROMISC_MODE;\r\ncmd.code = C_C_PROMISC_ENABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nap->promisc = 1;\r\n}else\r\nap->promisc = 0;\r\nap->mcast_all = 0;\r\n#if 0\r\ncmd.evt = C_LNK_NEGOTIATION;\r\ncmd.code = 0;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\n#endif\r\nnetif_start_queue(dev);\r\ntasklet_init(&ap->ace_tasklet, ace_tasklet, (unsigned long)dev);\r\nreturn 0;\r\n}\r\nstatic int ace_close(struct net_device *dev)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nstruct cmd cmd;\r\nunsigned long flags;\r\nshort i;\r\nnetif_stop_queue(dev);\r\nif (ap->promisc) {\r\ncmd.evt = C_SET_PROMISC_MODE;\r\ncmd.code = C_C_PROMISC_DISABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nap->promisc = 0;\r\n}\r\ncmd.evt = C_HOST_STATE;\r\ncmd.code = C_C_STACK_DOWN;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\ntasklet_kill(&ap->ace_tasklet);\r\nlocal_irq_save(flags);\r\nace_mask_irq(dev);\r\nfor (i = 0; i < ACE_TX_RING_ENTRIES(ap); i++) {\r\nstruct sk_buff *skb;\r\nstruct tx_ring_info *info;\r\ninfo = ap->skb->tx_skbuff + i;\r\nskb = info->skb;\r\nif (dma_unmap_len(info, maplen)) {\r\nif (ACE_IS_TIGON_I(ap)) {\r\nstruct tx_desc __iomem *tx;\r\ntx = (__force struct tx_desc __iomem *) &ap->tx_ring[i];\r\nwritel(0, &tx->addr.addrhi);\r\nwritel(0, &tx->addr.addrlo);\r\nwritel(0, &tx->flagsize);\r\n} else\r\nmemset(ap->tx_ring + i, 0,\r\nsizeof(struct tx_desc));\r\npci_unmap_page(ap->pdev, dma_unmap_addr(info, mapping),\r\ndma_unmap_len(info, maplen),\r\nPCI_DMA_TODEVICE);\r\ndma_unmap_len_set(info, maplen, 0);\r\n}\r\nif (skb) {\r\ndev_kfree_skb(skb);\r\ninfo->skb = NULL;\r\n}\r\n}\r\nif (ap->jumbo) {\r\ncmd.evt = C_RESET_JUMBO_RNG;\r\ncmd.code = 0;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\n}\r\nace_unmask_irq(dev);\r\nlocal_irq_restore(flags);\r\nreturn 0;\r\n}\r\nstatic inline dma_addr_t\r\nace_map_tx_skb(struct ace_private *ap, struct sk_buff *skb,\r\nstruct sk_buff *tail, u32 idx)\r\n{\r\ndma_addr_t mapping;\r\nstruct tx_ring_info *info;\r\nmapping = pci_map_page(ap->pdev, virt_to_page(skb->data),\r\noffset_in_page(skb->data),\r\nskb->len, PCI_DMA_TODEVICE);\r\ninfo = ap->skb->tx_skbuff + idx;\r\ninfo->skb = tail;\r\ndma_unmap_addr_set(info, mapping, mapping);\r\ndma_unmap_len_set(info, maplen, skb->len);\r\nreturn mapping;\r\n}\r\nstatic inline void\r\nace_load_tx_bd(struct ace_private *ap, struct tx_desc *desc, u64 addr,\r\nu32 flagsize, u32 vlan_tag)\r\n{\r\n#if !USE_TX_COAL_NOW\r\nflagsize &= ~BD_FLG_COAL_NOW;\r\n#endif\r\nif (ACE_IS_TIGON_I(ap)) {\r\nstruct tx_desc __iomem *io = (__force struct tx_desc __iomem *) desc;\r\nwritel(addr >> 32, &io->addr.addrhi);\r\nwritel(addr & 0xffffffff, &io->addr.addrlo);\r\nwritel(flagsize, &io->flagsize);\r\nwritel(vlan_tag, &io->vlanres);\r\n} else {\r\ndesc->addr.addrhi = addr >> 32;\r\ndesc->addr.addrlo = addr;\r\ndesc->flagsize = flagsize;\r\ndesc->vlanres = vlan_tag;\r\n}\r\n}\r\nstatic netdev_tx_t ace_start_xmit(struct sk_buff *skb,\r\nstruct net_device *dev)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nstruct tx_desc *desc;\r\nu32 idx, flagsize;\r\nunsigned long maxjiff = jiffies + 3*HZ;\r\nrestart:\r\nidx = ap->tx_prd;\r\nif (tx_ring_full(ap, ap->tx_ret_csm, idx))\r\ngoto overflow;\r\nif (!skb_shinfo(skb)->nr_frags) {\r\ndma_addr_t mapping;\r\nu32 vlan_tag = 0;\r\nmapping = ace_map_tx_skb(ap, skb, skb, idx);\r\nflagsize = (skb->len << 16) | (BD_FLG_END);\r\nif (skb->ip_summed == CHECKSUM_PARTIAL)\r\nflagsize |= BD_FLG_TCP_UDP_SUM;\r\nif (skb_vlan_tag_present(skb)) {\r\nflagsize |= BD_FLG_VLAN_TAG;\r\nvlan_tag = skb_vlan_tag_get(skb);\r\n}\r\ndesc = ap->tx_ring + idx;\r\nidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\r\nif (tx_ring_full(ap, ap->tx_ret_csm, idx))\r\nflagsize |= BD_FLG_COAL_NOW;\r\nace_load_tx_bd(ap, desc, mapping, flagsize, vlan_tag);\r\n} else {\r\ndma_addr_t mapping;\r\nu32 vlan_tag = 0;\r\nint i, len = 0;\r\nmapping = ace_map_tx_skb(ap, skb, NULL, idx);\r\nflagsize = (skb_headlen(skb) << 16);\r\nif (skb->ip_summed == CHECKSUM_PARTIAL)\r\nflagsize |= BD_FLG_TCP_UDP_SUM;\r\nif (skb_vlan_tag_present(skb)) {\r\nflagsize |= BD_FLG_VLAN_TAG;\r\nvlan_tag = skb_vlan_tag_get(skb);\r\n}\r\nace_load_tx_bd(ap, ap->tx_ring + idx, mapping, flagsize, vlan_tag);\r\nidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\nconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\r\nstruct tx_ring_info *info;\r\nlen += skb_frag_size(frag);\r\ninfo = ap->skb->tx_skbuff + idx;\r\ndesc = ap->tx_ring + idx;\r\nmapping = skb_frag_dma_map(&ap->pdev->dev, frag, 0,\r\nskb_frag_size(frag),\r\nDMA_TO_DEVICE);\r\nflagsize = skb_frag_size(frag) << 16;\r\nif (skb->ip_summed == CHECKSUM_PARTIAL)\r\nflagsize |= BD_FLG_TCP_UDP_SUM;\r\nidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\r\nif (i == skb_shinfo(skb)->nr_frags - 1) {\r\nflagsize |= BD_FLG_END;\r\nif (tx_ring_full(ap, ap->tx_ret_csm, idx))\r\nflagsize |= BD_FLG_COAL_NOW;\r\ninfo->skb = skb;\r\n} else {\r\ninfo->skb = NULL;\r\n}\r\ndma_unmap_addr_set(info, mapping, mapping);\r\ndma_unmap_len_set(info, maplen, skb_frag_size(frag));\r\nace_load_tx_bd(ap, desc, mapping, flagsize, vlan_tag);\r\n}\r\n}\r\nwmb();\r\nap->tx_prd = idx;\r\nace_set_txprd(regs, ap, idx);\r\nif (flagsize & BD_FLG_COAL_NOW) {\r\nnetif_stop_queue(dev);\r\nif (!tx_ring_full(ap, ap->tx_ret_csm, idx))\r\nnetif_wake_queue(dev);\r\n}\r\nreturn NETDEV_TX_OK;\r\noverflow:\r\nif (time_before(jiffies, maxjiff)) {\r\nbarrier();\r\ncpu_relax();\r\ngoto restart;\r\n}\r\nprintk(KERN_WARNING "%s: Transmit ring stuck full\n", dev->name);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nstatic int ace_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nwritel(new_mtu + ETH_HLEN + 4, &regs->IfMtu);\r\ndev->mtu = new_mtu;\r\nif (new_mtu > ACE_STD_MTU) {\r\nif (!(ap->jumbo)) {\r\nprintk(KERN_INFO "%s: Enabling Jumbo frame "\r\n"support\n", dev->name);\r\nap->jumbo = 1;\r\nif (!test_and_set_bit(0, &ap->jumbo_refill_busy))\r\nace_load_jumbo_rx_ring(dev, RX_JUMBO_SIZE);\r\nace_set_rxtx_parms(dev, 1);\r\n}\r\n} else {\r\nwhile (test_and_set_bit(0, &ap->jumbo_refill_busy));\r\nace_sync_irq(dev->irq);\r\nace_set_rxtx_parms(dev, 0);\r\nif (ap->jumbo) {\r\nstruct cmd cmd;\r\ncmd.evt = C_RESET_JUMBO_RNG;\r\ncmd.code = 0;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int ace_get_link_ksettings(struct net_device *dev,\r\nstruct ethtool_link_ksettings *cmd)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nu32 link;\r\nu32 supported;\r\nmemset(cmd, 0, sizeof(struct ethtool_link_ksettings));\r\nsupported = (SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full |\r\nSUPPORTED_100baseT_Half | SUPPORTED_100baseT_Full |\r\nSUPPORTED_1000baseT_Half | SUPPORTED_1000baseT_Full |\r\nSUPPORTED_Autoneg | SUPPORTED_FIBRE);\r\ncmd->base.port = PORT_FIBRE;\r\nlink = readl(&regs->GigLnkState);\r\nif (link & LNK_1000MB) {\r\ncmd->base.speed = SPEED_1000;\r\n} else {\r\nlink = readl(&regs->FastLnkState);\r\nif (link & LNK_100MB)\r\ncmd->base.speed = SPEED_100;\r\nelse if (link & LNK_10MB)\r\ncmd->base.speed = SPEED_10;\r\nelse\r\ncmd->base.speed = 0;\r\n}\r\nif (link & LNK_FULL_DUPLEX)\r\ncmd->base.duplex = DUPLEX_FULL;\r\nelse\r\ncmd->base.duplex = DUPLEX_HALF;\r\nif (link & LNK_NEGOTIATE)\r\ncmd->base.autoneg = AUTONEG_ENABLE;\r\nelse\r\ncmd->base.autoneg = AUTONEG_DISABLE;\r\n#if 0\r\necmd->trace = readl(&regs->TuneTrace);\r\necmd->txcoal = readl(&regs->TuneTxCoalTicks);\r\necmd->rxcoal = readl(&regs->TuneRxCoalTicks);\r\n#endif\r\nethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported,\r\nsupported);\r\nreturn 0;\r\n}\r\nstatic int ace_set_link_ksettings(struct net_device *dev,\r\nconst struct ethtool_link_ksettings *cmd)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nu32 link, speed;\r\nlink = readl(&regs->GigLnkState);\r\nif (link & LNK_1000MB)\r\nspeed = SPEED_1000;\r\nelse {\r\nlink = readl(&regs->FastLnkState);\r\nif (link & LNK_100MB)\r\nspeed = SPEED_100;\r\nelse if (link & LNK_10MB)\r\nspeed = SPEED_10;\r\nelse\r\nspeed = SPEED_100;\r\n}\r\nlink = LNK_ENABLE | LNK_1000MB | LNK_100MB | LNK_10MB |\r\nLNK_RX_FLOW_CTL_Y | LNK_NEG_FCTL;\r\nif (!ACE_IS_TIGON_I(ap))\r\nlink |= LNK_TX_FLOW_CTL_Y;\r\nif (cmd->base.autoneg == AUTONEG_ENABLE)\r\nlink |= LNK_NEGOTIATE;\r\nif (cmd->base.speed != speed) {\r\nlink &= ~(LNK_1000MB | LNK_100MB | LNK_10MB);\r\nswitch (cmd->base.speed) {\r\ncase SPEED_1000:\r\nlink |= LNK_1000MB;\r\nbreak;\r\ncase SPEED_100:\r\nlink |= LNK_100MB;\r\nbreak;\r\ncase SPEED_10:\r\nlink |= LNK_10MB;\r\nbreak;\r\n}\r\n}\r\nif (cmd->base.duplex == DUPLEX_FULL)\r\nlink |= LNK_FULL_DUPLEX;\r\nif (link != ap->link) {\r\nstruct cmd cmd;\r\nprintk(KERN_INFO "%s: Renegotiating link state\n",\r\ndev->name);\r\nap->link = link;\r\nwritel(link, &regs->TuneLink);\r\nif (!ACE_IS_TIGON_I(ap))\r\nwritel(link, &regs->TuneFastLink);\r\nwmb();\r\ncmd.evt = C_LNK_NEGOTIATION;\r\ncmd.code = 0;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\n}\r\nreturn 0;\r\n}\r\nstatic void ace_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstrlcpy(info->driver, "acenic", sizeof(info->driver));\r\nsnprintf(info->version, sizeof(info->version), "%i.%i.%i",\r\nap->firmware_major, ap->firmware_minor,\r\nap->firmware_fix);\r\nif (ap->pdev)\r\nstrlcpy(info->bus_info, pci_name(ap->pdev),\r\nsizeof(info->bus_info));\r\n}\r\nstatic int ace_set_mac_addr(struct net_device *dev, void *p)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nstruct sockaddr *addr=p;\r\nu8 *da;\r\nstruct cmd cmd;\r\nif(netif_running(dev))\r\nreturn -EBUSY;\r\nmemcpy(dev->dev_addr, addr->sa_data,dev->addr_len);\r\nda = (u8 *)dev->dev_addr;\r\nwritel(da[0] << 8 | da[1], &regs->MacAddrHi);\r\nwritel((da[2] << 24) | (da[3] << 16) | (da[4] << 8) | da[5],\r\n&regs->MacAddrLo);\r\ncmd.evt = C_SET_MAC_ADDR;\r\ncmd.code = 0;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nreturn 0;\r\n}\r\nstatic void ace_set_multicast_list(struct net_device *dev)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nstruct cmd cmd;\r\nif ((dev->flags & IFF_ALLMULTI) && !(ap->mcast_all)) {\r\ncmd.evt = C_SET_MULTICAST_MODE;\r\ncmd.code = C_C_MCAST_ENABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nap->mcast_all = 1;\r\n} else if (ap->mcast_all) {\r\ncmd.evt = C_SET_MULTICAST_MODE;\r\ncmd.code = C_C_MCAST_DISABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nap->mcast_all = 0;\r\n}\r\nif ((dev->flags & IFF_PROMISC) && !(ap->promisc)) {\r\ncmd.evt = C_SET_PROMISC_MODE;\r\ncmd.code = C_C_PROMISC_ENABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nap->promisc = 1;\r\n}else if (!(dev->flags & IFF_PROMISC) && (ap->promisc)) {\r\ncmd.evt = C_SET_PROMISC_MODE;\r\ncmd.code = C_C_PROMISC_DISABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\nap->promisc = 0;\r\n}\r\nif (!netdev_mc_empty(dev) && !ap->mcast_all) {\r\ncmd.evt = C_SET_MULTICAST_MODE;\r\ncmd.code = C_C_MCAST_ENABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\n}else if (!ap->mcast_all) {\r\ncmd.evt = C_SET_MULTICAST_MODE;\r\ncmd.code = C_C_MCAST_DISABLE;\r\ncmd.idx = 0;\r\nace_issue_cmd(regs, &cmd);\r\n}\r\n}\r\nstatic struct net_device_stats *ace_get_stats(struct net_device *dev)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_mac_stats __iomem *mac_stats =\r\n(struct ace_mac_stats __iomem *)ap->regs->Stats;\r\ndev->stats.rx_missed_errors = readl(&mac_stats->drop_space);\r\ndev->stats.multicast = readl(&mac_stats->kept_mc);\r\ndev->stats.collisions = readl(&mac_stats->coll);\r\nreturn &dev->stats;\r\n}\r\nstatic void ace_copy(struct ace_regs __iomem *regs, const __be32 *src,\r\nu32 dest, int size)\r\n{\r\nvoid __iomem *tdest;\r\nshort tsize, i;\r\nif (size <= 0)\r\nreturn;\r\nwhile (size > 0) {\r\ntsize = min_t(u32, ((~dest & (ACE_WINDOW_SIZE - 1)) + 1),\r\nmin_t(u32, size, ACE_WINDOW_SIZE));\r\ntdest = (void __iomem *) &regs->Window +\r\n(dest & (ACE_WINDOW_SIZE - 1));\r\nwritel(dest & ~(ACE_WINDOW_SIZE - 1), &regs->WinBase);\r\nfor (i = 0; i < (tsize / 4); i++) {\r\nwritel(be32_to_cpup(src), tdest);\r\nsrc++;\r\ntdest += 4;\r\ndest += 4;\r\nsize -= 4;\r\n}\r\n}\r\n}\r\nstatic void ace_clear(struct ace_regs __iomem *regs, u32 dest, int size)\r\n{\r\nvoid __iomem *tdest;\r\nshort tsize = 0, i;\r\nif (size <= 0)\r\nreturn;\r\nwhile (size > 0) {\r\ntsize = min_t(u32, ((~dest & (ACE_WINDOW_SIZE - 1)) + 1),\r\nmin_t(u32, size, ACE_WINDOW_SIZE));\r\ntdest = (void __iomem *) &regs->Window +\r\n(dest & (ACE_WINDOW_SIZE - 1));\r\nwritel(dest & ~(ACE_WINDOW_SIZE - 1), &regs->WinBase);\r\nfor (i = 0; i < (tsize / 4); i++) {\r\nwritel(0, tdest + i*4);\r\n}\r\ndest += tsize;\r\nsize -= tsize;\r\n}\r\n}\r\nstatic int ace_load_firmware(struct net_device *dev)\r\n{\r\nconst struct firmware *fw;\r\nconst char *fw_name = "acenic/tg2.bin";\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nconst __be32 *fw_data;\r\nu32 load_addr;\r\nint ret;\r\nif (!(readl(&regs->CpuCtrl) & CPU_HALTED)) {\r\nprintk(KERN_ERR "%s: trying to download firmware while the "\r\n"CPU is running!\n", ap->name);\r\nreturn -EFAULT;\r\n}\r\nif (ACE_IS_TIGON_I(ap))\r\nfw_name = "acenic/tg1.bin";\r\nret = request_firmware(&fw, fw_name, &ap->pdev->dev);\r\nif (ret) {\r\nprintk(KERN_ERR "%s: Failed to load firmware \"%s\"\n",\r\nap->name, fw_name);\r\nreturn ret;\r\n}\r\nfw_data = (void *)fw->data;\r\nap->firmware_major = fw->data[0];\r\nap->firmware_minor = fw->data[1];\r\nap->firmware_fix = fw->data[2];\r\nap->firmware_start = be32_to_cpu(fw_data[1]);\r\nif (ap->firmware_start < 0x4000 || ap->firmware_start >= 0x80000) {\r\nprintk(KERN_ERR "%s: bogus load address %08x in \"%s\"\n",\r\nap->name, ap->firmware_start, fw_name);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nload_addr = be32_to_cpu(fw_data[2]);\r\nif (load_addr < 0x4000 || load_addr >= 0x80000) {\r\nprintk(KERN_ERR "%s: bogus load address %08x in \"%s\"\n",\r\nap->name, load_addr, fw_name);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nace_clear(regs, 0x2000, 0x80000-0x2000);\r\nace_copy(regs, &fw_data[3], load_addr, fw->size-12);\r\nout:\r\nrelease_firmware(fw);\r\nreturn ret;\r\n}\r\nstatic void eeprom_start(struct ace_regs __iomem *regs)\r\n{\r\nu32 local;\r\nreadl(&regs->LocalCtrl);\r\nudelay(ACE_SHORT_DELAY);\r\nlocal = readl(&regs->LocalCtrl);\r\nlocal |= EEPROM_DATA_OUT | EEPROM_WRITE_ENABLE;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal |= EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal &= ~EEPROM_DATA_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal &= ~EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\n}\r\nstatic void eeprom_prep(struct ace_regs __iomem *regs, u8 magic)\r\n{\r\nshort i;\r\nu32 local;\r\nudelay(ACE_SHORT_DELAY);\r\nlocal = readl(&regs->LocalCtrl);\r\nlocal &= ~EEPROM_DATA_OUT;\r\nlocal |= EEPROM_WRITE_ENABLE;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nfor (i = 0; i < 8; i++, magic <<= 1) {\r\nudelay(ACE_SHORT_DELAY);\r\nif (magic & 0x80)\r\nlocal |= EEPROM_DATA_OUT;\r\nelse\r\nlocal &= ~EEPROM_DATA_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal |= EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal &= ~(EEPROM_CLK_OUT | EEPROM_DATA_OUT);\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\n}\r\n}\r\nstatic int eeprom_check_ack(struct ace_regs __iomem *regs)\r\n{\r\nint state;\r\nu32 local;\r\nlocal = readl(&regs->LocalCtrl);\r\nlocal &= ~EEPROM_WRITE_ENABLE;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_LONG_DELAY);\r\nlocal |= EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nstate = (readl(&regs->LocalCtrl) & EEPROM_DATA_IN) != 0;\r\nudelay(ACE_SHORT_DELAY);\r\nmb();\r\nwritel(readl(&regs->LocalCtrl) & ~EEPROM_CLK_OUT, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nreturn state;\r\n}\r\nstatic void eeprom_stop(struct ace_regs __iomem *regs)\r\n{\r\nu32 local;\r\nudelay(ACE_SHORT_DELAY);\r\nlocal = readl(&regs->LocalCtrl);\r\nlocal |= EEPROM_WRITE_ENABLE;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal &= ~EEPROM_DATA_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal |= EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nlocal |= EEPROM_DATA_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_LONG_DELAY);\r\nlocal &= ~EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nmb();\r\n}\r\nstatic int read_eeprom_byte(struct net_device *dev, unsigned long offset)\r\n{\r\nstruct ace_private *ap = netdev_priv(dev);\r\nstruct ace_regs __iomem *regs = ap->regs;\r\nunsigned long flags;\r\nu32 local;\r\nint result = 0;\r\nshort i;\r\nlocal_irq_save(flags);\r\neeprom_start(regs);\r\neeprom_prep(regs, EEPROM_WRITE_SELECT);\r\nif (eeprom_check_ack(regs)) {\r\nlocal_irq_restore(flags);\r\nprintk(KERN_ERR "%s: Unable to sync eeprom\n", ap->name);\r\nresult = -EIO;\r\ngoto eeprom_read_error;\r\n}\r\neeprom_prep(regs, (offset >> 8) & 0xff);\r\nif (eeprom_check_ack(regs)) {\r\nlocal_irq_restore(flags);\r\nprintk(KERN_ERR "%s: Unable to set address byte 0\n",\r\nap->name);\r\nresult = -EIO;\r\ngoto eeprom_read_error;\r\n}\r\neeprom_prep(regs, offset & 0xff);\r\nif (eeprom_check_ack(regs)) {\r\nlocal_irq_restore(flags);\r\nprintk(KERN_ERR "%s: Unable to set address byte 1\n",\r\nap->name);\r\nresult = -EIO;\r\ngoto eeprom_read_error;\r\n}\r\neeprom_start(regs);\r\neeprom_prep(regs, EEPROM_READ_SELECT);\r\nif (eeprom_check_ack(regs)) {\r\nlocal_irq_restore(flags);\r\nprintk(KERN_ERR "%s: Unable to set READ_SELECT\n",\r\nap->name);\r\nresult = -EIO;\r\ngoto eeprom_read_error;\r\n}\r\nfor (i = 0; i < 8; i++) {\r\nlocal = readl(&regs->LocalCtrl);\r\nlocal &= ~EEPROM_WRITE_ENABLE;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nudelay(ACE_LONG_DELAY);\r\nmb();\r\nlocal |= EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nresult = (result << 1) |\r\n((readl(&regs->LocalCtrl) & EEPROM_DATA_IN) != 0);\r\nudelay(ACE_SHORT_DELAY);\r\nmb();\r\nlocal = readl(&regs->LocalCtrl);\r\nlocal &= ~EEPROM_CLK_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nudelay(ACE_SHORT_DELAY);\r\nmb();\r\nif (i == 7) {\r\nlocal |= EEPROM_WRITE_ENABLE;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\n}\r\n}\r\nlocal |= EEPROM_DATA_OUT;\r\nwritel(local, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\nwritel(readl(&regs->LocalCtrl) | EEPROM_CLK_OUT, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nudelay(ACE_LONG_DELAY);\r\nwritel(readl(&regs->LocalCtrl) & ~EEPROM_CLK_OUT, &regs->LocalCtrl);\r\nreadl(&regs->LocalCtrl);\r\nmb();\r\nudelay(ACE_SHORT_DELAY);\r\neeprom_stop(regs);\r\nlocal_irq_restore(flags);\r\nout:\r\nreturn result;\r\neeprom_read_error:\r\nprintk(KERN_ERR "%s: Unable to read eeprom byte 0x%02lx\n",\r\nap->name, offset);\r\ngoto out;\r\n}
