static int clk_rpm_handoff(struct clk_rpm *r)\r\n{\r\nint ret;\r\nu32 value = INT_MAX;\r\nret = qcom_rpm_write(r->rpm, QCOM_RPM_ACTIVE_STATE,\r\nr->rpm_clk_id, &value, 1);\r\nif (ret)\r\nreturn ret;\r\nret = qcom_rpm_write(r->rpm, QCOM_RPM_SLEEP_STATE,\r\nr->rpm_clk_id, &value, 1);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nstatic int clk_rpm_set_rate_active(struct clk_rpm *r, unsigned long rate)\r\n{\r\nu32 value = DIV_ROUND_UP(rate, 1000);\r\nreturn qcom_rpm_write(r->rpm, QCOM_RPM_ACTIVE_STATE,\r\nr->rpm_clk_id, &value, 1);\r\n}\r\nstatic int clk_rpm_set_rate_sleep(struct clk_rpm *r, unsigned long rate)\r\n{\r\nu32 value = DIV_ROUND_UP(rate, 1000);\r\nreturn qcom_rpm_write(r->rpm, QCOM_RPM_SLEEP_STATE,\r\nr->rpm_clk_id, &value, 1);\r\n}\r\nstatic void to_active_sleep(struct clk_rpm *r, unsigned long rate,\r\nunsigned long *active, unsigned long *sleep)\r\n{\r\n*active = rate;\r\nif (r->active_only)\r\n*sleep = 0;\r\nelse\r\n*sleep = *active;\r\n}\r\nstatic int clk_rpm_prepare(struct clk_hw *hw)\r\n{\r\nstruct clk_rpm *r = to_clk_rpm(hw);\r\nstruct clk_rpm *peer = r->peer;\r\nunsigned long this_rate = 0, this_sleep_rate = 0;\r\nunsigned long peer_rate = 0, peer_sleep_rate = 0;\r\nunsigned long active_rate, sleep_rate;\r\nint ret = 0;\r\nmutex_lock(&rpm_clk_lock);\r\nif (!r->rate)\r\ngoto out;\r\nto_active_sleep(r, r->rate, &this_rate, &this_sleep_rate);\r\nif (peer->enabled)\r\nto_active_sleep(peer, peer->rate,\r\n&peer_rate, &peer_sleep_rate);\r\nactive_rate = max(this_rate, peer_rate);\r\nif (r->branch)\r\nactive_rate = !!active_rate;\r\nret = clk_rpm_set_rate_active(r, active_rate);\r\nif (ret)\r\ngoto out;\r\nsleep_rate = max(this_sleep_rate, peer_sleep_rate);\r\nif (r->branch)\r\nsleep_rate = !!sleep_rate;\r\nret = clk_rpm_set_rate_sleep(r, sleep_rate);\r\nif (ret)\r\nret = clk_rpm_set_rate_active(r, peer_rate);\r\nout:\r\nif (!ret)\r\nr->enabled = true;\r\nmutex_unlock(&rpm_clk_lock);\r\nreturn ret;\r\n}\r\nstatic void clk_rpm_unprepare(struct clk_hw *hw)\r\n{\r\nstruct clk_rpm *r = to_clk_rpm(hw);\r\nstruct clk_rpm *peer = r->peer;\r\nunsigned long peer_rate = 0, peer_sleep_rate = 0;\r\nunsigned long active_rate, sleep_rate;\r\nint ret;\r\nmutex_lock(&rpm_clk_lock);\r\nif (!r->rate)\r\ngoto out;\r\nif (peer->enabled)\r\nto_active_sleep(peer, peer->rate, &peer_rate,\r\n&peer_sleep_rate);\r\nactive_rate = r->branch ? !!peer_rate : peer_rate;\r\nret = clk_rpm_set_rate_active(r, active_rate);\r\nif (ret)\r\ngoto out;\r\nsleep_rate = r->branch ? !!peer_sleep_rate : peer_sleep_rate;\r\nret = clk_rpm_set_rate_sleep(r, sleep_rate);\r\nif (ret)\r\ngoto out;\r\nr->enabled = false;\r\nout:\r\nmutex_unlock(&rpm_clk_lock);\r\n}\r\nstatic int clk_rpm_set_rate(struct clk_hw *hw,\r\nunsigned long rate, unsigned long parent_rate)\r\n{\r\nstruct clk_rpm *r = to_clk_rpm(hw);\r\nstruct clk_rpm *peer = r->peer;\r\nunsigned long active_rate, sleep_rate;\r\nunsigned long this_rate = 0, this_sleep_rate = 0;\r\nunsigned long peer_rate = 0, peer_sleep_rate = 0;\r\nint ret = 0;\r\nmutex_lock(&rpm_clk_lock);\r\nif (!r->enabled)\r\ngoto out;\r\nto_active_sleep(r, rate, &this_rate, &this_sleep_rate);\r\nif (peer->enabled)\r\nto_active_sleep(peer, peer->rate,\r\n&peer_rate, &peer_sleep_rate);\r\nactive_rate = max(this_rate, peer_rate);\r\nret = clk_rpm_set_rate_active(r, active_rate);\r\nif (ret)\r\ngoto out;\r\nsleep_rate = max(this_sleep_rate, peer_sleep_rate);\r\nret = clk_rpm_set_rate_sleep(r, sleep_rate);\r\nif (ret)\r\ngoto out;\r\nr->rate = rate;\r\nout:\r\nmutex_unlock(&rpm_clk_lock);\r\nreturn ret;\r\n}\r\nstatic long clk_rpm_round_rate(struct clk_hw *hw, unsigned long rate,\r\nunsigned long *parent_rate)\r\n{\r\nreturn rate;\r\n}\r\nstatic unsigned long clk_rpm_recalc_rate(struct clk_hw *hw,\r\nunsigned long parent_rate)\r\n{\r\nstruct clk_rpm *r = to_clk_rpm(hw);\r\nreturn r->rate;\r\n}\r\nstatic struct clk_hw *qcom_rpm_clk_hw_get(struct of_phandle_args *clkspec,\r\nvoid *data)\r\n{\r\nstruct rpm_cc *rcc = data;\r\nunsigned int idx = clkspec->args[0];\r\nif (idx >= rcc->num_clks) {\r\npr_err("%s: invalid index %u\n", __func__, idx);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nreturn rcc->clks[idx] ? &rcc->clks[idx]->hw : ERR_PTR(-ENOENT);\r\n}\r\nstatic int rpm_clk_probe(struct platform_device *pdev)\r\n{\r\nstruct rpm_cc *rcc;\r\nint ret;\r\nsize_t num_clks, i;\r\nstruct qcom_rpm *rpm;\r\nstruct clk_rpm **rpm_clks;\r\nconst struct rpm_clk_desc *desc;\r\nrpm = dev_get_drvdata(pdev->dev.parent);\r\nif (!rpm) {\r\ndev_err(&pdev->dev, "Unable to retrieve handle to RPM\n");\r\nreturn -ENODEV;\r\n}\r\ndesc = of_device_get_match_data(&pdev->dev);\r\nif (!desc)\r\nreturn -EINVAL;\r\nrpm_clks = desc->clks;\r\nnum_clks = desc->num_clks;\r\nrcc = devm_kzalloc(&pdev->dev, sizeof(*rcc), GFP_KERNEL);\r\nif (!rcc)\r\nreturn -ENOMEM;\r\nrcc->clks = rpm_clks;\r\nrcc->num_clks = num_clks;\r\nfor (i = 0; i < num_clks; i++) {\r\nif (!rpm_clks[i])\r\ncontinue;\r\nrpm_clks[i]->rpm = rpm;\r\nret = clk_rpm_handoff(rpm_clks[i]);\r\nif (ret)\r\ngoto err;\r\n}\r\nfor (i = 0; i < num_clks; i++) {\r\nif (!rpm_clks[i])\r\ncontinue;\r\nret = devm_clk_hw_register(&pdev->dev, &rpm_clks[i]->hw);\r\nif (ret)\r\ngoto err;\r\n}\r\nret = of_clk_add_hw_provider(pdev->dev.of_node, qcom_rpm_clk_hw_get,\r\nrcc);\r\nif (ret)\r\ngoto err;\r\nreturn 0;\r\nerr:\r\ndev_err(&pdev->dev, "Error registering RPM Clock driver (%d)\n", ret);\r\nreturn ret;\r\n}\r\nstatic int rpm_clk_remove(struct platform_device *pdev)\r\n{\r\nof_clk_del_provider(pdev->dev.of_node);\r\nreturn 0;\r\n}\r\nstatic int __init rpm_clk_init(void)\r\n{\r\nreturn platform_driver_register(&rpm_clk_driver);\r\n}\r\nstatic void __exit rpm_clk_exit(void)\r\n{\r\nplatform_driver_unregister(&rpm_clk_driver);\r\n}
