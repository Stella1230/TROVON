struct ceph_monmap *ceph_monmap_decode(void *p, void *end)\r\n{\r\nstruct ceph_monmap *m = NULL;\r\nint i, err = -EINVAL;\r\nstruct ceph_fsid fsid;\r\nu32 epoch, num_mon;\r\nu16 version;\r\nu32 len;\r\nceph_decode_32_safe(&p, end, len, bad);\r\nceph_decode_need(&p, end, len, bad);\r\ndout("monmap_decode %p %p len %d\n", p, end, (int)(end-p));\r\nceph_decode_16_safe(&p, end, version, bad);\r\nceph_decode_need(&p, end, sizeof(fsid) + 2*sizeof(u32), bad);\r\nceph_decode_copy(&p, &fsid, sizeof(fsid));\r\nepoch = ceph_decode_32(&p);\r\nnum_mon = ceph_decode_32(&p);\r\nceph_decode_need(&p, end, num_mon*sizeof(m->mon_inst[0]), bad);\r\nif (num_mon >= CEPH_MAX_MON)\r\ngoto bad;\r\nm = kmalloc(sizeof(*m) + sizeof(m->mon_inst[0])*num_mon, GFP_NOFS);\r\nif (m == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nm->fsid = fsid;\r\nm->epoch = epoch;\r\nm->num_mon = num_mon;\r\nceph_decode_copy(&p, m->mon_inst, num_mon*sizeof(m->mon_inst[0]));\r\nfor (i = 0; i < num_mon; i++)\r\nceph_decode_addr(&m->mon_inst[i].addr);\r\ndout("monmap_decode epoch %d, num_mon %d\n", m->epoch,\r\nm->num_mon);\r\nfor (i = 0; i < m->num_mon; i++)\r\ndout("monmap_decode mon%d is %s\n", i,\r\nceph_pr_addr(&m->mon_inst[i].addr.in_addr));\r\nreturn m;\r\nbad:\r\ndout("monmap_decode failed with %d\n", err);\r\nkfree(m);\r\nreturn ERR_PTR(err);\r\n}\r\nint ceph_monmap_contains(struct ceph_monmap *m, struct ceph_entity_addr *addr)\r\n{\r\nint i;\r\nfor (i = 0; i < m->num_mon; i++)\r\nif (memcmp(addr, &m->mon_inst[i].addr, sizeof(*addr)) == 0)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void __send_prepared_auth_request(struct ceph_mon_client *monc, int len)\r\n{\r\nmonc->pending_auth = 1;\r\nmonc->m_auth->front.iov_len = len;\r\nmonc->m_auth->hdr.front_len = cpu_to_le32(len);\r\nceph_msg_revoke(monc->m_auth);\r\nceph_msg_get(monc->m_auth);\r\nceph_con_send(&monc->con, monc->m_auth);\r\n}\r\nstatic void __close_session(struct ceph_mon_client *monc)\r\n{\r\ndout("__close_session closing mon%d\n", monc->cur_mon);\r\nceph_msg_revoke(monc->m_auth);\r\nceph_msg_revoke_incoming(monc->m_auth_reply);\r\nceph_msg_revoke(monc->m_subscribe);\r\nceph_msg_revoke_incoming(monc->m_subscribe_ack);\r\nceph_con_close(&monc->con);\r\nmonc->pending_auth = 0;\r\nceph_auth_reset(monc->auth);\r\n}\r\nstatic void pick_new_mon(struct ceph_mon_client *monc)\r\n{\r\nint old_mon = monc->cur_mon;\r\nBUG_ON(monc->monmap->num_mon < 1);\r\nif (monc->monmap->num_mon == 1) {\r\nmonc->cur_mon = 0;\r\n} else {\r\nint max = monc->monmap->num_mon;\r\nint o = -1;\r\nint n;\r\nif (monc->cur_mon >= 0) {\r\nif (monc->cur_mon < monc->monmap->num_mon)\r\no = monc->cur_mon;\r\nif (o >= 0)\r\nmax--;\r\n}\r\nn = prandom_u32() % max;\r\nif (o >= 0 && n >= o)\r\nn++;\r\nmonc->cur_mon = n;\r\n}\r\ndout("%s mon%d -> mon%d out of %d mons\n", __func__, old_mon,\r\nmonc->cur_mon, monc->monmap->num_mon);\r\n}\r\nstatic void __open_session(struct ceph_mon_client *monc)\r\n{\r\nint ret;\r\npick_new_mon(monc);\r\nmonc->hunting = true;\r\nif (monc->had_a_connection) {\r\nmonc->hunt_mult *= CEPH_MONC_HUNT_BACKOFF;\r\nif (monc->hunt_mult > CEPH_MONC_HUNT_MAX_MULT)\r\nmonc->hunt_mult = CEPH_MONC_HUNT_MAX_MULT;\r\n}\r\nmonc->sub_renew_after = jiffies;\r\nmonc->sub_renew_sent = 0;\r\ndout("%s opening mon%d\n", __func__, monc->cur_mon);\r\nceph_con_open(&monc->con, CEPH_ENTITY_TYPE_MON, monc->cur_mon,\r\n&monc->monmap->mon_inst[monc->cur_mon].addr);\r\nceph_con_keepalive(&monc->con);\r\nret = ceph_auth_build_hello(monc->auth,\r\nmonc->m_auth->front.iov_base,\r\nmonc->m_auth->front_alloc_len);\r\nBUG_ON(ret <= 0);\r\n__send_prepared_auth_request(monc, ret);\r\n}\r\nstatic void reopen_session(struct ceph_mon_client *monc)\r\n{\r\nif (!monc->hunting)\r\npr_info("mon%d %s session lost, hunting for new mon\n",\r\nmonc->cur_mon, ceph_pr_addr(&monc->con.peer_addr.in_addr));\r\n__close_session(monc);\r\n__open_session(monc);\r\n}\r\nstatic void __schedule_delayed(struct ceph_mon_client *monc)\r\n{\r\nunsigned long delay;\r\nif (monc->hunting)\r\ndelay = CEPH_MONC_HUNT_INTERVAL * monc->hunt_mult;\r\nelse\r\ndelay = CEPH_MONC_PING_INTERVAL;\r\ndout("__schedule_delayed after %lu\n", delay);\r\nmod_delayed_work(system_wq, &monc->delayed_work,\r\nround_jiffies_relative(delay));\r\n}\r\nstatic void __send_subscribe(struct ceph_mon_client *monc)\r\n{\r\nstruct ceph_msg *msg = monc->m_subscribe;\r\nvoid *p = msg->front.iov_base;\r\nvoid *const end = p + msg->front_alloc_len;\r\nint num = 0;\r\nint i;\r\ndout("%s sent %lu\n", __func__, monc->sub_renew_sent);\r\nBUG_ON(monc->cur_mon < 0);\r\nif (!monc->sub_renew_sent)\r\nmonc->sub_renew_sent = jiffies | 1;\r\nmsg->hdr.version = cpu_to_le16(2);\r\nfor (i = 0; i < ARRAY_SIZE(monc->subs); i++) {\r\nif (monc->subs[i].want)\r\nnum++;\r\n}\r\nBUG_ON(num < 1);\r\nceph_encode_32(&p, num);\r\nfor (i = 0; i < ARRAY_SIZE(monc->subs); i++) {\r\nchar buf[32];\r\nint len;\r\nif (!monc->subs[i].want)\r\ncontinue;\r\nlen = sprintf(buf, "%s", ceph_sub_str[i]);\r\nif (i == CEPH_SUB_MDSMAP &&\r\nmonc->fs_cluster_id != CEPH_FS_CLUSTER_ID_NONE)\r\nlen += sprintf(buf + len, ".%d", monc->fs_cluster_id);\r\ndout("%s %s start %llu flags 0x%x\n", __func__, buf,\r\nle64_to_cpu(monc->subs[i].item.start),\r\nmonc->subs[i].item.flags);\r\nceph_encode_string(&p, end, buf, len);\r\nmemcpy(p, &monc->subs[i].item, sizeof(monc->subs[i].item));\r\np += sizeof(monc->subs[i].item);\r\n}\r\nBUG_ON(p > end);\r\nmsg->front.iov_len = p - msg->front.iov_base;\r\nmsg->hdr.front_len = cpu_to_le32(msg->front.iov_len);\r\nceph_msg_revoke(msg);\r\nceph_con_send(&monc->con, ceph_msg_get(msg));\r\n}\r\nstatic void handle_subscribe_ack(struct ceph_mon_client *monc,\r\nstruct ceph_msg *msg)\r\n{\r\nunsigned int seconds;\r\nstruct ceph_mon_subscribe_ack *h = msg->front.iov_base;\r\nif (msg->front.iov_len < sizeof(*h))\r\ngoto bad;\r\nseconds = le32_to_cpu(h->duration);\r\nmutex_lock(&monc->mutex);\r\nif (monc->sub_renew_sent) {\r\nmonc->sub_renew_after = monc->sub_renew_sent +\r\n(seconds >> 1) * HZ - 1;\r\ndout("%s sent %lu duration %d renew after %lu\n", __func__,\r\nmonc->sub_renew_sent, seconds, monc->sub_renew_after);\r\nmonc->sub_renew_sent = 0;\r\n} else {\r\ndout("%s sent %lu renew after %lu, ignoring\n", __func__,\r\nmonc->sub_renew_sent, monc->sub_renew_after);\r\n}\r\nmutex_unlock(&monc->mutex);\r\nreturn;\r\nbad:\r\npr_err("got corrupt subscribe-ack msg\n");\r\nceph_msg_dump(msg);\r\n}\r\nstatic bool __ceph_monc_want_map(struct ceph_mon_client *monc, int sub,\r\nu32 epoch, bool continuous)\r\n{\r\n__le64 start = cpu_to_le64(epoch);\r\nu8 flags = !continuous ? CEPH_SUBSCRIBE_ONETIME : 0;\r\ndout("%s %s epoch %u continuous %d\n", __func__, ceph_sub_str[sub],\r\nepoch, continuous);\r\nif (monc->subs[sub].want &&\r\nmonc->subs[sub].item.start == start &&\r\nmonc->subs[sub].item.flags == flags)\r\nreturn false;\r\nmonc->subs[sub].item.start = start;\r\nmonc->subs[sub].item.flags = flags;\r\nmonc->subs[sub].want = true;\r\nreturn true;\r\n}\r\nbool ceph_monc_want_map(struct ceph_mon_client *monc, int sub, u32 epoch,\r\nbool continuous)\r\n{\r\nbool need_request;\r\nmutex_lock(&monc->mutex);\r\nneed_request = __ceph_monc_want_map(monc, sub, epoch, continuous);\r\nmutex_unlock(&monc->mutex);\r\nreturn need_request;\r\n}\r\nstatic void __ceph_monc_got_map(struct ceph_mon_client *monc, int sub,\r\nu32 epoch)\r\n{\r\ndout("%s %s epoch %u\n", __func__, ceph_sub_str[sub], epoch);\r\nif (monc->subs[sub].want) {\r\nif (monc->subs[sub].item.flags & CEPH_SUBSCRIBE_ONETIME)\r\nmonc->subs[sub].want = false;\r\nelse\r\nmonc->subs[sub].item.start = cpu_to_le64(epoch + 1);\r\n}\r\nmonc->subs[sub].have = epoch;\r\n}\r\nvoid ceph_monc_got_map(struct ceph_mon_client *monc, int sub, u32 epoch)\r\n{\r\nmutex_lock(&monc->mutex);\r\n__ceph_monc_got_map(monc, sub, epoch);\r\nmutex_unlock(&monc->mutex);\r\n}\r\nvoid ceph_monc_renew_subs(struct ceph_mon_client *monc)\r\n{\r\nmutex_lock(&monc->mutex);\r\n__send_subscribe(monc);\r\nmutex_unlock(&monc->mutex);\r\n}\r\nint ceph_monc_wait_osdmap(struct ceph_mon_client *monc, u32 epoch,\r\nunsigned long timeout)\r\n{\r\nunsigned long started = jiffies;\r\nlong ret;\r\nmutex_lock(&monc->mutex);\r\nwhile (monc->subs[CEPH_SUB_OSDMAP].have < epoch) {\r\nmutex_unlock(&monc->mutex);\r\nif (timeout && time_after_eq(jiffies, started + timeout))\r\nreturn -ETIMEDOUT;\r\nret = wait_event_interruptible_timeout(monc->client->auth_wq,\r\nmonc->subs[CEPH_SUB_OSDMAP].have >= epoch,\r\nceph_timeout_jiffies(timeout));\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&monc->mutex);\r\n}\r\nmutex_unlock(&monc->mutex);\r\nreturn 0;\r\n}\r\nint ceph_monc_open_session(struct ceph_mon_client *monc)\r\n{\r\nmutex_lock(&monc->mutex);\r\n__ceph_monc_want_map(monc, CEPH_SUB_MONMAP, 0, true);\r\n__ceph_monc_want_map(monc, CEPH_SUB_OSDMAP, 0, false);\r\n__open_session(monc);\r\n__schedule_delayed(monc);\r\nmutex_unlock(&monc->mutex);\r\nreturn 0;\r\n}\r\nstatic void ceph_monc_handle_map(struct ceph_mon_client *monc,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct ceph_client *client = monc->client;\r\nstruct ceph_monmap *monmap = NULL, *old = monc->monmap;\r\nvoid *p, *end;\r\nmutex_lock(&monc->mutex);\r\ndout("handle_monmap\n");\r\np = msg->front.iov_base;\r\nend = p + msg->front.iov_len;\r\nmonmap = ceph_monmap_decode(p, end);\r\nif (IS_ERR(monmap)) {\r\npr_err("problem decoding monmap, %d\n",\r\n(int)PTR_ERR(monmap));\r\ngoto out;\r\n}\r\nif (ceph_check_fsid(monc->client, &monmap->fsid) < 0) {\r\nkfree(monmap);\r\ngoto out;\r\n}\r\nclient->monc.monmap = monmap;\r\nkfree(old);\r\n__ceph_monc_got_map(monc, CEPH_SUB_MONMAP, monc->monmap->epoch);\r\nclient->have_fsid = true;\r\nout:\r\nmutex_unlock(&monc->mutex);\r\nwake_up_all(&client->auth_wq);\r\n}\r\nstatic void release_generic_request(struct kref *kref)\r\n{\r\nstruct ceph_mon_generic_request *req =\r\ncontainer_of(kref, struct ceph_mon_generic_request, kref);\r\ndout("%s greq %p request %p reply %p\n", __func__, req, req->request,\r\nreq->reply);\r\nWARN_ON(!RB_EMPTY_NODE(&req->node));\r\nif (req->reply)\r\nceph_msg_put(req->reply);\r\nif (req->request)\r\nceph_msg_put(req->request);\r\nkfree(req);\r\n}\r\nstatic void put_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\nif (req)\r\nkref_put(&req->kref, release_generic_request);\r\n}\r\nstatic void get_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\nkref_get(&req->kref);\r\n}\r\nstatic struct ceph_mon_generic_request *\r\nalloc_generic_request(struct ceph_mon_client *monc, gfp_t gfp)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nreq = kzalloc(sizeof(*req), gfp);\r\nif (!req)\r\nreturn NULL;\r\nreq->monc = monc;\r\nkref_init(&req->kref);\r\nRB_CLEAR_NODE(&req->node);\r\ninit_completion(&req->completion);\r\ndout("%s greq %p\n", __func__, req);\r\nreturn req;\r\n}\r\nstatic void register_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\nstruct ceph_mon_client *monc = req->monc;\r\nWARN_ON(req->tid);\r\nget_generic_request(req);\r\nreq->tid = ++monc->last_tid;\r\ninsert_generic_request(&monc->generic_request_tree, req);\r\n}\r\nstatic void send_generic_request(struct ceph_mon_client *monc,\r\nstruct ceph_mon_generic_request *req)\r\n{\r\nWARN_ON(!req->tid);\r\ndout("%s greq %p tid %llu\n", __func__, req, req->tid);\r\nreq->request->hdr.tid = cpu_to_le64(req->tid);\r\nceph_con_send(&monc->con, ceph_msg_get(req->request));\r\n}\r\nstatic void __finish_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\nstruct ceph_mon_client *monc = req->monc;\r\ndout("%s greq %p tid %llu\n", __func__, req, req->tid);\r\nerase_generic_request(&monc->generic_request_tree, req);\r\nceph_msg_revoke(req->request);\r\nceph_msg_revoke_incoming(req->reply);\r\n}\r\nstatic void finish_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\n__finish_generic_request(req);\r\nput_generic_request(req);\r\n}\r\nstatic void complete_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\nif (req->complete_cb)\r\nreq->complete_cb(req);\r\nelse\r\ncomplete_all(&req->completion);\r\nput_generic_request(req);\r\n}\r\nstatic void cancel_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\nstruct ceph_mon_client *monc = req->monc;\r\nstruct ceph_mon_generic_request *lookup_req;\r\ndout("%s greq %p tid %llu\n", __func__, req, req->tid);\r\nmutex_lock(&monc->mutex);\r\nlookup_req = lookup_generic_request(&monc->generic_request_tree,\r\nreq->tid);\r\nif (lookup_req) {\r\nWARN_ON(lookup_req != req);\r\nfinish_generic_request(req);\r\n}\r\nmutex_unlock(&monc->mutex);\r\n}\r\nstatic int wait_generic_request(struct ceph_mon_generic_request *req)\r\n{\r\nint ret;\r\ndout("%s greq %p tid %llu\n", __func__, req, req->tid);\r\nret = wait_for_completion_interruptible(&req->completion);\r\nif (ret)\r\ncancel_generic_request(req);\r\nelse\r\nret = req->result;\r\nreturn ret;\r\n}\r\nstatic struct ceph_msg *get_generic_reply(struct ceph_connection *con,\r\nstruct ceph_msg_header *hdr,\r\nint *skip)\r\n{\r\nstruct ceph_mon_client *monc = con->private;\r\nstruct ceph_mon_generic_request *req;\r\nu64 tid = le64_to_cpu(hdr->tid);\r\nstruct ceph_msg *m;\r\nmutex_lock(&monc->mutex);\r\nreq = lookup_generic_request(&monc->generic_request_tree, tid);\r\nif (!req) {\r\ndout("get_generic_reply %lld dne\n", tid);\r\n*skip = 1;\r\nm = NULL;\r\n} else {\r\ndout("get_generic_reply %lld got %p\n", tid, req->reply);\r\n*skip = 0;\r\nm = ceph_msg_get(req->reply);\r\n}\r\nmutex_unlock(&monc->mutex);\r\nreturn m;\r\n}\r\nstatic void handle_statfs_reply(struct ceph_mon_client *monc,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nstruct ceph_mon_statfs_reply *reply = msg->front.iov_base;\r\nu64 tid = le64_to_cpu(msg->hdr.tid);\r\ndout("%s msg %p tid %llu\n", __func__, msg, tid);\r\nif (msg->front.iov_len != sizeof(*reply))\r\ngoto bad;\r\nmutex_lock(&monc->mutex);\r\nreq = lookup_generic_request(&monc->generic_request_tree, tid);\r\nif (!req) {\r\nmutex_unlock(&monc->mutex);\r\nreturn;\r\n}\r\nreq->result = 0;\r\n*req->u.st = reply->st;\r\n__finish_generic_request(req);\r\nmutex_unlock(&monc->mutex);\r\ncomplete_generic_request(req);\r\nreturn;\r\nbad:\r\npr_err("corrupt statfs reply, tid %llu\n", tid);\r\nceph_msg_dump(msg);\r\n}\r\nint ceph_monc_do_statfs(struct ceph_mon_client *monc, struct ceph_statfs *buf)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nstruct ceph_mon_statfs *h;\r\nint ret = -ENOMEM;\r\nreq = alloc_generic_request(monc, GFP_NOFS);\r\nif (!req)\r\ngoto out;\r\nreq->request = ceph_msg_new(CEPH_MSG_STATFS, sizeof(*h), GFP_NOFS,\r\ntrue);\r\nif (!req->request)\r\ngoto out;\r\nreq->reply = ceph_msg_new(CEPH_MSG_STATFS_REPLY, 64, GFP_NOFS, true);\r\nif (!req->reply)\r\ngoto out;\r\nreq->u.st = buf;\r\nmutex_lock(&monc->mutex);\r\nregister_generic_request(req);\r\nh = req->request->front.iov_base;\r\nh->monhdr.have_version = 0;\r\nh->monhdr.session_mon = cpu_to_le16(-1);\r\nh->monhdr.session_mon_tid = 0;\r\nh->fsid = monc->monmap->fsid;\r\nsend_generic_request(monc, req);\r\nmutex_unlock(&monc->mutex);\r\nret = wait_generic_request(req);\r\nout:\r\nput_generic_request(req);\r\nreturn ret;\r\n}\r\nstatic void handle_get_version_reply(struct ceph_mon_client *monc,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nu64 tid = le64_to_cpu(msg->hdr.tid);\r\nvoid *p = msg->front.iov_base;\r\nvoid *end = p + msg->front_alloc_len;\r\nu64 handle;\r\ndout("%s msg %p tid %llu\n", __func__, msg, tid);\r\nceph_decode_need(&p, end, 2*sizeof(u64), bad);\r\nhandle = ceph_decode_64(&p);\r\nif (tid != 0 && tid != handle)\r\ngoto bad;\r\nmutex_lock(&monc->mutex);\r\nreq = lookup_generic_request(&monc->generic_request_tree, handle);\r\nif (!req) {\r\nmutex_unlock(&monc->mutex);\r\nreturn;\r\n}\r\nreq->result = 0;\r\nreq->u.newest = ceph_decode_64(&p);\r\n__finish_generic_request(req);\r\nmutex_unlock(&monc->mutex);\r\ncomplete_generic_request(req);\r\nreturn;\r\nbad:\r\npr_err("corrupt mon_get_version reply, tid %llu\n", tid);\r\nceph_msg_dump(msg);\r\n}\r\nstatic struct ceph_mon_generic_request *\r\n__ceph_monc_get_version(struct ceph_mon_client *monc, const char *what,\r\nceph_monc_callback_t cb, u64 private_data)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nreq = alloc_generic_request(monc, GFP_NOIO);\r\nif (!req)\r\ngoto err_put_req;\r\nreq->request = ceph_msg_new(CEPH_MSG_MON_GET_VERSION,\r\nsizeof(u64) + sizeof(u32) + strlen(what),\r\nGFP_NOIO, true);\r\nif (!req->request)\r\ngoto err_put_req;\r\nreq->reply = ceph_msg_new(CEPH_MSG_MON_GET_VERSION_REPLY, 32, GFP_NOIO,\r\ntrue);\r\nif (!req->reply)\r\ngoto err_put_req;\r\nreq->complete_cb = cb;\r\nreq->private_data = private_data;\r\nmutex_lock(&monc->mutex);\r\nregister_generic_request(req);\r\n{\r\nvoid *p = req->request->front.iov_base;\r\nvoid *const end = p + req->request->front_alloc_len;\r\nceph_encode_64(&p, req->tid);\r\nceph_encode_string(&p, end, what, strlen(what));\r\nWARN_ON(p != end);\r\n}\r\nsend_generic_request(monc, req);\r\nmutex_unlock(&monc->mutex);\r\nreturn req;\r\nerr_put_req:\r\nput_generic_request(req);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nint ceph_monc_get_version(struct ceph_mon_client *monc, const char *what,\r\nu64 *newest)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nint ret;\r\nreq = __ceph_monc_get_version(monc, what, NULL, 0);\r\nif (IS_ERR(req))\r\nreturn PTR_ERR(req);\r\nret = wait_generic_request(req);\r\nif (!ret)\r\n*newest = req->u.newest;\r\nput_generic_request(req);\r\nreturn ret;\r\n}\r\nint ceph_monc_get_version_async(struct ceph_mon_client *monc, const char *what,\r\nceph_monc_callback_t cb, u64 private_data)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nreq = __ceph_monc_get_version(monc, what, cb, private_data);\r\nif (IS_ERR(req))\r\nreturn PTR_ERR(req);\r\nput_generic_request(req);\r\nreturn 0;\r\n}\r\nstatic void handle_command_ack(struct ceph_mon_client *monc,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nvoid *p = msg->front.iov_base;\r\nvoid *const end = p + msg->front_alloc_len;\r\nu64 tid = le64_to_cpu(msg->hdr.tid);\r\ndout("%s msg %p tid %llu\n", __func__, msg, tid);\r\nceph_decode_need(&p, end, sizeof(struct ceph_mon_request_header) +\r\nsizeof(u32), bad);\r\np += sizeof(struct ceph_mon_request_header);\r\nmutex_lock(&monc->mutex);\r\nreq = lookup_generic_request(&monc->generic_request_tree, tid);\r\nif (!req) {\r\nmutex_unlock(&monc->mutex);\r\nreturn;\r\n}\r\nreq->result = ceph_decode_32(&p);\r\n__finish_generic_request(req);\r\nmutex_unlock(&monc->mutex);\r\ncomplete_generic_request(req);\r\nreturn;\r\nbad:\r\npr_err("corrupt mon_command ack, tid %llu\n", tid);\r\nceph_msg_dump(msg);\r\n}\r\nint ceph_monc_blacklist_add(struct ceph_mon_client *monc,\r\nstruct ceph_entity_addr *client_addr)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nstruct ceph_mon_command *h;\r\nint ret = -ENOMEM;\r\nint len;\r\nreq = alloc_generic_request(monc, GFP_NOIO);\r\nif (!req)\r\ngoto out;\r\nreq->request = ceph_msg_new(CEPH_MSG_MON_COMMAND, 256, GFP_NOIO, true);\r\nif (!req->request)\r\ngoto out;\r\nreq->reply = ceph_msg_new(CEPH_MSG_MON_COMMAND_ACK, 512, GFP_NOIO,\r\ntrue);\r\nif (!req->reply)\r\ngoto out;\r\nmutex_lock(&monc->mutex);\r\nregister_generic_request(req);\r\nh = req->request->front.iov_base;\r\nh->monhdr.have_version = 0;\r\nh->monhdr.session_mon = cpu_to_le16(-1);\r\nh->monhdr.session_mon_tid = 0;\r\nh->fsid = monc->monmap->fsid;\r\nh->num_strs = cpu_to_le32(1);\r\nlen = sprintf(h->str, "{ \"prefix\": \"osd blacklist\", \\r\n\"blacklistop\": \"add\", \\r\n\"addr\": \"%pISpc/%u\" }",\r\n&client_addr->in_addr, le32_to_cpu(client_addr->nonce));\r\nh->str_len = cpu_to_le32(len);\r\nsend_generic_request(monc, req);\r\nmutex_unlock(&monc->mutex);\r\nret = wait_generic_request(req);\r\nout:\r\nput_generic_request(req);\r\nreturn ret;\r\n}\r\nstatic void __resend_generic_request(struct ceph_mon_client *monc)\r\n{\r\nstruct ceph_mon_generic_request *req;\r\nstruct rb_node *p;\r\nfor (p = rb_first(&monc->generic_request_tree); p; p = rb_next(p)) {\r\nreq = rb_entry(p, struct ceph_mon_generic_request, node);\r\nceph_msg_revoke(req->request);\r\nceph_msg_revoke_incoming(req->reply);\r\nceph_con_send(&monc->con, ceph_msg_get(req->request));\r\n}\r\n}\r\nstatic void delayed_work(struct work_struct *work)\r\n{\r\nstruct ceph_mon_client *monc =\r\ncontainer_of(work, struct ceph_mon_client, delayed_work.work);\r\ndout("monc delayed_work\n");\r\nmutex_lock(&monc->mutex);\r\nif (monc->hunting) {\r\ndout("%s continuing hunt\n", __func__);\r\nreopen_session(monc);\r\n} else {\r\nint is_auth = ceph_auth_is_authenticated(monc->auth);\r\nif (ceph_con_keepalive_expired(&monc->con,\r\nCEPH_MONC_PING_TIMEOUT)) {\r\ndout("monc keepalive timeout\n");\r\nis_auth = 0;\r\nreopen_session(monc);\r\n}\r\nif (!monc->hunting) {\r\nceph_con_keepalive(&monc->con);\r\n__validate_auth(monc);\r\n}\r\nif (is_auth) {\r\nunsigned long now = jiffies;\r\ndout("%s renew subs? now %lu renew after %lu\n",\r\n__func__, now, monc->sub_renew_after);\r\nif (time_after_eq(now, monc->sub_renew_after))\r\n__send_subscribe(monc);\r\n}\r\n}\r\n__schedule_delayed(monc);\r\nmutex_unlock(&monc->mutex);\r\n}\r\nstatic int build_initial_monmap(struct ceph_mon_client *monc)\r\n{\r\nstruct ceph_options *opt = monc->client->options;\r\nstruct ceph_entity_addr *mon_addr = opt->mon_addr;\r\nint num_mon = opt->num_mon;\r\nint i;\r\nmonc->monmap = kzalloc(sizeof(*monc->monmap) +\r\nnum_mon*sizeof(monc->monmap->mon_inst[0]),\r\nGFP_KERNEL);\r\nif (!monc->monmap)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < num_mon; i++) {\r\nmonc->monmap->mon_inst[i].addr = mon_addr[i];\r\nmonc->monmap->mon_inst[i].addr.nonce = 0;\r\nmonc->monmap->mon_inst[i].name.type =\r\nCEPH_ENTITY_TYPE_MON;\r\nmonc->monmap->mon_inst[i].name.num = cpu_to_le64(i);\r\n}\r\nmonc->monmap->num_mon = num_mon;\r\nreturn 0;\r\n}\r\nint ceph_monc_init(struct ceph_mon_client *monc, struct ceph_client *cl)\r\n{\r\nint err = 0;\r\ndout("init\n");\r\nmemset(monc, 0, sizeof(*monc));\r\nmonc->client = cl;\r\nmonc->monmap = NULL;\r\nmutex_init(&monc->mutex);\r\nerr = build_initial_monmap(monc);\r\nif (err)\r\ngoto out;\r\nmonc->auth = ceph_auth_init(cl->options->name,\r\ncl->options->key);\r\nif (IS_ERR(monc->auth)) {\r\nerr = PTR_ERR(monc->auth);\r\ngoto out_monmap;\r\n}\r\nmonc->auth->want_keys =\r\nCEPH_ENTITY_TYPE_AUTH | CEPH_ENTITY_TYPE_MON |\r\nCEPH_ENTITY_TYPE_OSD | CEPH_ENTITY_TYPE_MDS;\r\nerr = -ENOMEM;\r\nmonc->m_subscribe_ack = ceph_msg_new(CEPH_MSG_MON_SUBSCRIBE_ACK,\r\nsizeof(struct ceph_mon_subscribe_ack),\r\nGFP_KERNEL, true);\r\nif (!monc->m_subscribe_ack)\r\ngoto out_auth;\r\nmonc->m_subscribe = ceph_msg_new(CEPH_MSG_MON_SUBSCRIBE, 128,\r\nGFP_KERNEL, true);\r\nif (!monc->m_subscribe)\r\ngoto out_subscribe_ack;\r\nmonc->m_auth_reply = ceph_msg_new(CEPH_MSG_AUTH_REPLY, 4096,\r\nGFP_KERNEL, true);\r\nif (!monc->m_auth_reply)\r\ngoto out_subscribe;\r\nmonc->m_auth = ceph_msg_new(CEPH_MSG_AUTH, 4096, GFP_KERNEL, true);\r\nmonc->pending_auth = 0;\r\nif (!monc->m_auth)\r\ngoto out_auth_reply;\r\nceph_con_init(&monc->con, monc, &mon_con_ops,\r\n&monc->client->msgr);\r\nmonc->cur_mon = -1;\r\nmonc->had_a_connection = false;\r\nmonc->hunt_mult = 1;\r\nINIT_DELAYED_WORK(&monc->delayed_work, delayed_work);\r\nmonc->generic_request_tree = RB_ROOT;\r\nmonc->last_tid = 0;\r\nmonc->fs_cluster_id = CEPH_FS_CLUSTER_ID_NONE;\r\nreturn 0;\r\nout_auth_reply:\r\nceph_msg_put(monc->m_auth_reply);\r\nout_subscribe:\r\nceph_msg_put(monc->m_subscribe);\r\nout_subscribe_ack:\r\nceph_msg_put(monc->m_subscribe_ack);\r\nout_auth:\r\nceph_auth_destroy(monc->auth);\r\nout_monmap:\r\nkfree(monc->monmap);\r\nout:\r\nreturn err;\r\n}\r\nvoid ceph_monc_stop(struct ceph_mon_client *monc)\r\n{\r\ndout("stop\n");\r\ncancel_delayed_work_sync(&monc->delayed_work);\r\nmutex_lock(&monc->mutex);\r\n__close_session(monc);\r\nmonc->cur_mon = -1;\r\nmutex_unlock(&monc->mutex);\r\nceph_msgr_flush();\r\nceph_auth_destroy(monc->auth);\r\nWARN_ON(!RB_EMPTY_ROOT(&monc->generic_request_tree));\r\nceph_msg_put(monc->m_auth);\r\nceph_msg_put(monc->m_auth_reply);\r\nceph_msg_put(monc->m_subscribe);\r\nceph_msg_put(monc->m_subscribe_ack);\r\nkfree(monc->monmap);\r\n}\r\nstatic void finish_hunting(struct ceph_mon_client *monc)\r\n{\r\nif (monc->hunting) {\r\ndout("%s found mon%d\n", __func__, monc->cur_mon);\r\nmonc->hunting = false;\r\nmonc->had_a_connection = true;\r\nmonc->hunt_mult /= 2;\r\nif (monc->hunt_mult < 1)\r\nmonc->hunt_mult = 1;\r\n}\r\n}\r\nstatic void handle_auth_reply(struct ceph_mon_client *monc,\r\nstruct ceph_msg *msg)\r\n{\r\nint ret;\r\nint was_auth = 0;\r\nmutex_lock(&monc->mutex);\r\nwas_auth = ceph_auth_is_authenticated(monc->auth);\r\nmonc->pending_auth = 0;\r\nret = ceph_handle_auth_reply(monc->auth, msg->front.iov_base,\r\nmsg->front.iov_len,\r\nmonc->m_auth->front.iov_base,\r\nmonc->m_auth->front_alloc_len);\r\nif (ret > 0) {\r\n__send_prepared_auth_request(monc, ret);\r\ngoto out;\r\n}\r\nfinish_hunting(monc);\r\nif (ret < 0) {\r\nmonc->client->auth_err = ret;\r\n} else if (!was_auth && ceph_auth_is_authenticated(monc->auth)) {\r\ndout("authenticated, starting session\n");\r\nmonc->client->msgr.inst.name.type = CEPH_ENTITY_TYPE_CLIENT;\r\nmonc->client->msgr.inst.name.num =\r\ncpu_to_le64(monc->auth->global_id);\r\n__send_subscribe(monc);\r\n__resend_generic_request(monc);\r\npr_info("mon%d %s session established\n", monc->cur_mon,\r\nceph_pr_addr(&monc->con.peer_addr.in_addr));\r\n}\r\nout:\r\nmutex_unlock(&monc->mutex);\r\nif (monc->client->auth_err < 0)\r\nwake_up_all(&monc->client->auth_wq);\r\n}\r\nstatic int __validate_auth(struct ceph_mon_client *monc)\r\n{\r\nint ret;\r\nif (monc->pending_auth)\r\nreturn 0;\r\nret = ceph_build_auth(monc->auth, monc->m_auth->front.iov_base,\r\nmonc->m_auth->front_alloc_len);\r\nif (ret <= 0)\r\nreturn ret;\r\n__send_prepared_auth_request(monc, ret);\r\nreturn 0;\r\n}\r\nint ceph_monc_validate_auth(struct ceph_mon_client *monc)\r\n{\r\nint ret;\r\nmutex_lock(&monc->mutex);\r\nret = __validate_auth(monc);\r\nmutex_unlock(&monc->mutex);\r\nreturn ret;\r\n}\r\nstatic void dispatch(struct ceph_connection *con, struct ceph_msg *msg)\r\n{\r\nstruct ceph_mon_client *monc = con->private;\r\nint type = le16_to_cpu(msg->hdr.type);\r\nif (!monc)\r\nreturn;\r\nswitch (type) {\r\ncase CEPH_MSG_AUTH_REPLY:\r\nhandle_auth_reply(monc, msg);\r\nbreak;\r\ncase CEPH_MSG_MON_SUBSCRIBE_ACK:\r\nhandle_subscribe_ack(monc, msg);\r\nbreak;\r\ncase CEPH_MSG_STATFS_REPLY:\r\nhandle_statfs_reply(monc, msg);\r\nbreak;\r\ncase CEPH_MSG_MON_GET_VERSION_REPLY:\r\nhandle_get_version_reply(monc, msg);\r\nbreak;\r\ncase CEPH_MSG_MON_COMMAND_ACK:\r\nhandle_command_ack(monc, msg);\r\nbreak;\r\ncase CEPH_MSG_MON_MAP:\r\nceph_monc_handle_map(monc, msg);\r\nbreak;\r\ncase CEPH_MSG_OSD_MAP:\r\nceph_osdc_handle_map(&monc->client->osdc, msg);\r\nbreak;\r\ndefault:\r\nif (monc->client->extra_mon_dispatch &&\r\nmonc->client->extra_mon_dispatch(monc->client, msg) == 0)\r\nbreak;\r\npr_err("received unknown message type %d %s\n", type,\r\nceph_msg_type_name(type));\r\n}\r\nceph_msg_put(msg);\r\n}\r\nstatic struct ceph_msg *mon_alloc_msg(struct ceph_connection *con,\r\nstruct ceph_msg_header *hdr,\r\nint *skip)\r\n{\r\nstruct ceph_mon_client *monc = con->private;\r\nint type = le16_to_cpu(hdr->type);\r\nint front_len = le32_to_cpu(hdr->front_len);\r\nstruct ceph_msg *m = NULL;\r\n*skip = 0;\r\nswitch (type) {\r\ncase CEPH_MSG_MON_SUBSCRIBE_ACK:\r\nm = ceph_msg_get(monc->m_subscribe_ack);\r\nbreak;\r\ncase CEPH_MSG_STATFS_REPLY:\r\ncase CEPH_MSG_MON_COMMAND_ACK:\r\nreturn get_generic_reply(con, hdr, skip);\r\ncase CEPH_MSG_AUTH_REPLY:\r\nm = ceph_msg_get(monc->m_auth_reply);\r\nbreak;\r\ncase CEPH_MSG_MON_GET_VERSION_REPLY:\r\nif (le64_to_cpu(hdr->tid) != 0)\r\nreturn get_generic_reply(con, hdr, skip);\r\ncase CEPH_MSG_MON_MAP:\r\ncase CEPH_MSG_MDS_MAP:\r\ncase CEPH_MSG_OSD_MAP:\r\ncase CEPH_MSG_FS_MAP_USER:\r\nm = ceph_msg_new(type, front_len, GFP_NOFS, false);\r\nif (!m)\r\nreturn NULL;\r\nbreak;\r\n}\r\nif (!m) {\r\npr_info("alloc_msg unknown type %d\n", type);\r\n*skip = 1;\r\n} else if (front_len > m->front_alloc_len) {\r\npr_warn("mon_alloc_msg front %d > prealloc %d (%u#%llu)\n",\r\nfront_len, m->front_alloc_len,\r\n(unsigned int)con->peer_name.type,\r\nle64_to_cpu(con->peer_name.num));\r\nceph_msg_put(m);\r\nm = ceph_msg_new(type, front_len, GFP_NOFS, false);\r\n}\r\nreturn m;\r\n}\r\nstatic void mon_fault(struct ceph_connection *con)\r\n{\r\nstruct ceph_mon_client *monc = con->private;\r\nmutex_lock(&monc->mutex);\r\ndout("%s mon%d\n", __func__, monc->cur_mon);\r\nif (monc->cur_mon >= 0) {\r\nif (!monc->hunting) {\r\ndout("%s hunting for new mon\n", __func__);\r\nreopen_session(monc);\r\n__schedule_delayed(monc);\r\n} else {\r\ndout("%s already hunting\n", __func__);\r\n}\r\n}\r\nmutex_unlock(&monc->mutex);\r\n}\r\nstatic struct ceph_connection *con_get(struct ceph_connection *con)\r\n{\r\nreturn con;\r\n}\r\nstatic void con_put(struct ceph_connection *con)\r\n{\r\n}
