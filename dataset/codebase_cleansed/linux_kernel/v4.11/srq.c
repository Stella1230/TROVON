void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type)\r\n{\r\nstruct mlx5_srq_table *table = &dev->priv.srq_table;\r\nstruct mlx5_core_srq *srq;\r\nspin_lock(&table->lock);\r\nsrq = radix_tree_lookup(&table->tree, srqn);\r\nif (srq)\r\natomic_inc(&srq->refcount);\r\nspin_unlock(&table->lock);\r\nif (!srq) {\r\nmlx5_core_warn(dev, "Async event for bogus SRQ 0x%08x\n", srqn);\r\nreturn;\r\n}\r\nsrq->event(srq, event_type);\r\nif (atomic_dec_and_test(&srq->refcount))\r\ncomplete(&srq->free);\r\n}\r\nstatic int get_pas_size(struct mlx5_srq_attr *in)\r\n{\r\nu32 log_page_size = in->log_page_size + 12;\r\nu32 log_srq_size = in->log_size;\r\nu32 log_rq_stride = in->wqe_shift;\r\nu32 page_offset = in->page_offset;\r\nu32 po_quanta = 1 << (log_page_size - 6);\r\nu32 rq_sz = 1 << (log_srq_size + 4 + log_rq_stride);\r\nu32 page_size = 1 << log_page_size;\r\nu32 rq_sz_po = rq_sz + (page_offset * po_quanta);\r\nu32 rq_num_pas = (rq_sz_po + page_size - 1) / page_size;\r\nreturn rq_num_pas * sizeof(u64);\r\n}\r\nstatic void set_wq(void *wq, struct mlx5_srq_attr *in)\r\n{\r\nMLX5_SET(wq, wq, wq_signature, !!(in->flags\r\n& MLX5_SRQ_FLAG_WQ_SIG));\r\nMLX5_SET(wq, wq, log_wq_pg_sz, in->log_page_size);\r\nMLX5_SET(wq, wq, log_wq_stride, in->wqe_shift + 4);\r\nMLX5_SET(wq, wq, log_wq_sz, in->log_size);\r\nMLX5_SET(wq, wq, page_offset, in->page_offset);\r\nMLX5_SET(wq, wq, lwm, in->lwm);\r\nMLX5_SET(wq, wq, pd, in->pd);\r\nMLX5_SET64(wq, wq, dbr_addr, in->db_record);\r\n}\r\nstatic void set_srqc(void *srqc, struct mlx5_srq_attr *in)\r\n{\r\nMLX5_SET(srqc, srqc, wq_signature, !!(in->flags\r\n& MLX5_SRQ_FLAG_WQ_SIG));\r\nMLX5_SET(srqc, srqc, log_page_size, in->log_page_size);\r\nMLX5_SET(srqc, srqc, log_rq_stride, in->wqe_shift);\r\nMLX5_SET(srqc, srqc, log_srq_size, in->log_size);\r\nMLX5_SET(srqc, srqc, page_offset, in->page_offset);\r\nMLX5_SET(srqc, srqc, lwm, in->lwm);\r\nMLX5_SET(srqc, srqc, pd, in->pd);\r\nMLX5_SET64(srqc, srqc, dbr_addr, in->db_record);\r\nMLX5_SET(srqc, srqc, xrcd, in->xrcd);\r\nMLX5_SET(srqc, srqc, cqn, in->cqn);\r\n}\r\nstatic void get_wq(void *wq, struct mlx5_srq_attr *in)\r\n{\r\nif (MLX5_GET(wq, wq, wq_signature))\r\nin->flags &= MLX5_SRQ_FLAG_WQ_SIG;\r\nin->log_page_size = MLX5_GET(wq, wq, log_wq_pg_sz);\r\nin->wqe_shift = MLX5_GET(wq, wq, log_wq_stride) - 4;\r\nin->log_size = MLX5_GET(wq, wq, log_wq_sz);\r\nin->page_offset = MLX5_GET(wq, wq, page_offset);\r\nin->lwm = MLX5_GET(wq, wq, lwm);\r\nin->pd = MLX5_GET(wq, wq, pd);\r\nin->db_record = MLX5_GET64(wq, wq, dbr_addr);\r\n}\r\nstatic void get_srqc(void *srqc, struct mlx5_srq_attr *in)\r\n{\r\nif (MLX5_GET(srqc, srqc, wq_signature))\r\nin->flags &= MLX5_SRQ_FLAG_WQ_SIG;\r\nin->log_page_size = MLX5_GET(srqc, srqc, log_page_size);\r\nin->wqe_shift = MLX5_GET(srqc, srqc, log_rq_stride);\r\nin->log_size = MLX5_GET(srqc, srqc, log_srq_size);\r\nin->page_offset = MLX5_GET(srqc, srqc, page_offset);\r\nin->lwm = MLX5_GET(srqc, srqc, lwm);\r\nin->pd = MLX5_GET(srqc, srqc, pd);\r\nin->db_record = MLX5_GET64(srqc, srqc, dbr_addr);\r\n}\r\nstruct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn)\r\n{\r\nstruct mlx5_srq_table *table = &dev->priv.srq_table;\r\nstruct mlx5_core_srq *srq;\r\nspin_lock(&table->lock);\r\nsrq = radix_tree_lookup(&table->tree, srqn);\r\nif (srq)\r\natomic_inc(&srq->refcount);\r\nspin_unlock(&table->lock);\r\nreturn srq;\r\n}\r\nstatic int create_srq_cmd(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *in)\r\n{\r\nu32 create_out[MLX5_ST_SZ_DW(create_srq_out)] = {0};\r\nvoid *create_in;\r\nvoid *srqc;\r\nvoid *pas;\r\nint pas_size;\r\nint inlen;\r\nint err;\r\npas_size = get_pas_size(in);\r\ninlen = MLX5_ST_SZ_BYTES(create_srq_in) + pas_size;\r\ncreate_in = mlx5_vzalloc(inlen);\r\nif (!create_in)\r\nreturn -ENOMEM;\r\nsrqc = MLX5_ADDR_OF(create_srq_in, create_in, srq_context_entry);\r\npas = MLX5_ADDR_OF(create_srq_in, create_in, pas);\r\nset_srqc(srqc, in);\r\nmemcpy(pas, in->pas, pas_size);\r\nMLX5_SET(create_srq_in, create_in, opcode,\r\nMLX5_CMD_OP_CREATE_SRQ);\r\nerr = mlx5_cmd_exec(dev, create_in, inlen, create_out,\r\nsizeof(create_out));\r\nkvfree(create_in);\r\nif (!err)\r\nsrq->srqn = MLX5_GET(create_srq_out, create_out, srqn);\r\nreturn err;\r\n}\r\nstatic int destroy_srq_cmd(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq)\r\n{\r\nu32 srq_in[MLX5_ST_SZ_DW(destroy_srq_in)] = {0};\r\nu32 srq_out[MLX5_ST_SZ_DW(destroy_srq_out)] = {0};\r\nMLX5_SET(destroy_srq_in, srq_in, opcode,\r\nMLX5_CMD_OP_DESTROY_SRQ);\r\nMLX5_SET(destroy_srq_in, srq_in, srqn, srq->srqn);\r\nreturn mlx5_cmd_exec(dev, srq_in, sizeof(srq_in),\r\nsrq_out, sizeof(srq_out));\r\n}\r\nstatic int arm_srq_cmd(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nu16 lwm, int is_srq)\r\n{\r\nu32 srq_in[MLX5_ST_SZ_DW(arm_xrc_srq_in)] = {0};\r\nu32 srq_out[MLX5_ST_SZ_DW(arm_xrc_srq_out)] = {0};\r\nMLX5_SET(arm_xrc_srq_in, srq_in, opcode, MLX5_CMD_OP_ARM_XRC_SRQ);\r\nMLX5_SET(arm_xrc_srq_in, srq_in, xrc_srqn, srq->srqn);\r\nMLX5_SET(arm_xrc_srq_in, srq_in, lwm, lwm);\r\nreturn mlx5_cmd_exec(dev, srq_in, sizeof(srq_in),\r\nsrq_out, sizeof(srq_out));\r\n}\r\nstatic int query_srq_cmd(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *out)\r\n{\r\nu32 srq_in[MLX5_ST_SZ_DW(query_srq_in)] = {0};\r\nu32 *srq_out;\r\nvoid *srqc;\r\nint err;\r\nsrq_out = mlx5_vzalloc(MLX5_ST_SZ_BYTES(query_srq_out));\r\nif (!srq_out)\r\nreturn -ENOMEM;\r\nMLX5_SET(query_srq_in, srq_in, opcode,\r\nMLX5_CMD_OP_QUERY_SRQ);\r\nMLX5_SET(query_srq_in, srq_in, srqn, srq->srqn);\r\nerr = mlx5_cmd_exec(dev, srq_in, sizeof(srq_in),\r\nsrq_out, MLX5_ST_SZ_BYTES(query_srq_out));\r\nif (err)\r\ngoto out;\r\nsrqc = MLX5_ADDR_OF(query_srq_out, srq_out, srq_context_entry);\r\nget_srqc(srqc, out);\r\nif (MLX5_GET(srqc, srqc, state) != MLX5_SRQC_STATE_GOOD)\r\nout->flags |= MLX5_SRQ_FLAG_ERR;\r\nout:\r\nkvfree(srq_out);\r\nreturn err;\r\n}\r\nstatic int create_xrc_srq_cmd(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *in)\r\n{\r\nu32 create_out[MLX5_ST_SZ_DW(create_xrc_srq_out)];\r\nvoid *create_in;\r\nvoid *xrc_srqc;\r\nvoid *pas;\r\nint pas_size;\r\nint inlen;\r\nint err;\r\npas_size = get_pas_size(in);\r\ninlen = MLX5_ST_SZ_BYTES(create_xrc_srq_in) + pas_size;\r\ncreate_in = mlx5_vzalloc(inlen);\r\nif (!create_in)\r\nreturn -ENOMEM;\r\nxrc_srqc = MLX5_ADDR_OF(create_xrc_srq_in, create_in,\r\nxrc_srq_context_entry);\r\npas = MLX5_ADDR_OF(create_xrc_srq_in, create_in, pas);\r\nset_srqc(xrc_srqc, in);\r\nMLX5_SET(xrc_srqc, xrc_srqc, user_index, in->user_index);\r\nmemcpy(pas, in->pas, pas_size);\r\nMLX5_SET(create_xrc_srq_in, create_in, opcode,\r\nMLX5_CMD_OP_CREATE_XRC_SRQ);\r\nmemset(create_out, 0, sizeof(create_out));\r\nerr = mlx5_cmd_exec(dev, create_in, inlen, create_out,\r\nsizeof(create_out));\r\nif (err)\r\ngoto out;\r\nsrq->srqn = MLX5_GET(create_xrc_srq_out, create_out, xrc_srqn);\r\nout:\r\nkvfree(create_in);\r\nreturn err;\r\n}\r\nstatic int destroy_xrc_srq_cmd(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq)\r\n{\r\nu32 xrcsrq_in[MLX5_ST_SZ_DW(destroy_xrc_srq_in)] = {0};\r\nu32 xrcsrq_out[MLX5_ST_SZ_DW(destroy_xrc_srq_out)] = {0};\r\nMLX5_SET(destroy_xrc_srq_in, xrcsrq_in, opcode,\r\nMLX5_CMD_OP_DESTROY_XRC_SRQ);\r\nMLX5_SET(destroy_xrc_srq_in, xrcsrq_in, xrc_srqn, srq->srqn);\r\nreturn mlx5_cmd_exec(dev, xrcsrq_in, sizeof(xrcsrq_in),\r\nxrcsrq_out, sizeof(xrcsrq_out));\r\n}\r\nstatic int arm_xrc_srq_cmd(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq, u16 lwm)\r\n{\r\nu32 xrcsrq_in[MLX5_ST_SZ_DW(arm_xrc_srq_in)] = {0};\r\nu32 xrcsrq_out[MLX5_ST_SZ_DW(arm_xrc_srq_out)] = {0};\r\nMLX5_SET(arm_xrc_srq_in, xrcsrq_in, opcode, MLX5_CMD_OP_ARM_XRC_SRQ);\r\nMLX5_SET(arm_xrc_srq_in, xrcsrq_in, op_mod, MLX5_ARM_XRC_SRQ_IN_OP_MOD_XRC_SRQ);\r\nMLX5_SET(arm_xrc_srq_in, xrcsrq_in, xrc_srqn, srq->srqn);\r\nMLX5_SET(arm_xrc_srq_in, xrcsrq_in, lwm, lwm);\r\nreturn mlx5_cmd_exec(dev, xrcsrq_in, sizeof(xrcsrq_in),\r\nxrcsrq_out, sizeof(xrcsrq_out));\r\n}\r\nstatic int query_xrc_srq_cmd(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *out)\r\n{\r\nu32 xrcsrq_in[MLX5_ST_SZ_DW(query_xrc_srq_in)];\r\nu32 *xrcsrq_out;\r\nvoid *xrc_srqc;\r\nint err;\r\nxrcsrq_out = mlx5_vzalloc(MLX5_ST_SZ_BYTES(query_xrc_srq_out));\r\nif (!xrcsrq_out)\r\nreturn -ENOMEM;\r\nmemset(xrcsrq_in, 0, sizeof(xrcsrq_in));\r\nMLX5_SET(query_xrc_srq_in, xrcsrq_in, opcode,\r\nMLX5_CMD_OP_QUERY_XRC_SRQ);\r\nMLX5_SET(query_xrc_srq_in, xrcsrq_in, xrc_srqn, srq->srqn);\r\nerr = mlx5_cmd_exec(dev, xrcsrq_in, sizeof(xrcsrq_in), xrcsrq_out,\r\nMLX5_ST_SZ_BYTES(query_xrc_srq_out));\r\nif (err)\r\ngoto out;\r\nxrc_srqc = MLX5_ADDR_OF(query_xrc_srq_out, xrcsrq_out,\r\nxrc_srq_context_entry);\r\nget_srqc(xrc_srqc, out);\r\nif (MLX5_GET(xrc_srqc, xrc_srqc, state) != MLX5_XRC_SRQC_STATE_GOOD)\r\nout->flags |= MLX5_SRQ_FLAG_ERR;\r\nout:\r\nkvfree(xrcsrq_out);\r\nreturn err;\r\n}\r\nstatic int create_rmp_cmd(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *in)\r\n{\r\nvoid *create_in;\r\nvoid *rmpc;\r\nvoid *wq;\r\nint pas_size;\r\nint inlen;\r\nint err;\r\npas_size = get_pas_size(in);\r\ninlen = MLX5_ST_SZ_BYTES(create_rmp_in) + pas_size;\r\ncreate_in = mlx5_vzalloc(inlen);\r\nif (!create_in)\r\nreturn -ENOMEM;\r\nrmpc = MLX5_ADDR_OF(create_rmp_in, create_in, ctx);\r\nwq = MLX5_ADDR_OF(rmpc, rmpc, wq);\r\nMLX5_SET(rmpc, rmpc, state, MLX5_RMPC_STATE_RDY);\r\nset_wq(wq, in);\r\nmemcpy(MLX5_ADDR_OF(rmpc, rmpc, wq.pas), in->pas, pas_size);\r\nerr = mlx5_core_create_rmp(dev, create_in, inlen, &srq->srqn);\r\nkvfree(create_in);\r\nreturn err;\r\n}\r\nstatic int destroy_rmp_cmd(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq)\r\n{\r\nreturn mlx5_core_destroy_rmp(dev, srq->srqn);\r\n}\r\nstatic int arm_rmp_cmd(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq,\r\nu16 lwm)\r\n{\r\nvoid *in;\r\nvoid *rmpc;\r\nvoid *wq;\r\nvoid *bitmask;\r\nint err;\r\nin = mlx5_vzalloc(MLX5_ST_SZ_BYTES(modify_rmp_in));\r\nif (!in)\r\nreturn -ENOMEM;\r\nrmpc = MLX5_ADDR_OF(modify_rmp_in, in, ctx);\r\nbitmask = MLX5_ADDR_OF(modify_rmp_in, in, bitmask);\r\nwq = MLX5_ADDR_OF(rmpc, rmpc, wq);\r\nMLX5_SET(modify_rmp_in, in, rmp_state, MLX5_RMPC_STATE_RDY);\r\nMLX5_SET(modify_rmp_in, in, rmpn, srq->srqn);\r\nMLX5_SET(wq, wq, lwm, lwm);\r\nMLX5_SET(rmp_bitmask, bitmask, lwm, 1);\r\nMLX5_SET(rmpc, rmpc, state, MLX5_RMPC_STATE_RDY);\r\nerr = mlx5_core_modify_rmp(dev, in, MLX5_ST_SZ_BYTES(modify_rmp_in));\r\nkvfree(in);\r\nreturn err;\r\n}\r\nstatic int query_rmp_cmd(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *out)\r\n{\r\nu32 *rmp_out;\r\nvoid *rmpc;\r\nint err;\r\nrmp_out = mlx5_vzalloc(MLX5_ST_SZ_BYTES(query_rmp_out));\r\nif (!rmp_out)\r\nreturn -ENOMEM;\r\nerr = mlx5_core_query_rmp(dev, srq->srqn, rmp_out);\r\nif (err)\r\ngoto out;\r\nrmpc = MLX5_ADDR_OF(query_rmp_out, rmp_out, rmp_context);\r\nget_wq(MLX5_ADDR_OF(rmpc, rmpc, wq), out);\r\nif (MLX5_GET(rmpc, rmpc, state) != MLX5_RMPC_STATE_RDY)\r\nout->flags |= MLX5_SRQ_FLAG_ERR;\r\nout:\r\nkvfree(rmp_out);\r\nreturn err;\r\n}\r\nstatic int create_srq_split(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *in)\r\n{\r\nif (!dev->issi)\r\nreturn create_srq_cmd(dev, srq, in);\r\nelse if (srq->common.res == MLX5_RES_XSRQ)\r\nreturn create_xrc_srq_cmd(dev, srq, in);\r\nelse\r\nreturn create_rmp_cmd(dev, srq, in);\r\n}\r\nstatic int destroy_srq_split(struct mlx5_core_dev *dev,\r\nstruct mlx5_core_srq *srq)\r\n{\r\nif (!dev->issi)\r\nreturn destroy_srq_cmd(dev, srq);\r\nelse if (srq->common.res == MLX5_RES_XSRQ)\r\nreturn destroy_xrc_srq_cmd(dev, srq);\r\nelse\r\nreturn destroy_rmp_cmd(dev, srq);\r\n}\r\nint mlx5_core_create_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *in)\r\n{\r\nint err;\r\nstruct mlx5_srq_table *table = &dev->priv.srq_table;\r\nif (in->type == IB_SRQT_XRC)\r\nsrq->common.res = MLX5_RES_XSRQ;\r\nelse\r\nsrq->common.res = MLX5_RES_SRQ;\r\nerr = create_srq_split(dev, srq, in);\r\nif (err)\r\nreturn err;\r\natomic_set(&srq->refcount, 1);\r\ninit_completion(&srq->free);\r\nspin_lock_irq(&table->lock);\r\nerr = radix_tree_insert(&table->tree, srq->srqn, srq);\r\nspin_unlock_irq(&table->lock);\r\nif (err) {\r\nmlx5_core_warn(dev, "err %d, srqn 0x%x\n", err, srq->srqn);\r\ngoto err_destroy_srq_split;\r\n}\r\nreturn 0;\r\nerr_destroy_srq_split:\r\ndestroy_srq_split(dev, srq);\r\nreturn err;\r\n}\r\nint mlx5_core_destroy_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq)\r\n{\r\nstruct mlx5_srq_table *table = &dev->priv.srq_table;\r\nstruct mlx5_core_srq *tmp;\r\nint err;\r\nspin_lock_irq(&table->lock);\r\ntmp = radix_tree_delete(&table->tree, srq->srqn);\r\nspin_unlock_irq(&table->lock);\r\nif (!tmp) {\r\nmlx5_core_warn(dev, "srq 0x%x not found in tree\n", srq->srqn);\r\nreturn -EINVAL;\r\n}\r\nif (tmp != srq) {\r\nmlx5_core_warn(dev, "corruption on srqn 0x%x\n", srq->srqn);\r\nreturn -EINVAL;\r\n}\r\nerr = destroy_srq_split(dev, srq);\r\nif (err)\r\nreturn err;\r\nif (atomic_dec_and_test(&srq->refcount))\r\ncomplete(&srq->free);\r\nwait_for_completion(&srq->free);\r\nreturn 0;\r\n}\r\nint mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nstruct mlx5_srq_attr *out)\r\n{\r\nif (!dev->issi)\r\nreturn query_srq_cmd(dev, srq, out);\r\nelse if (srq->common.res == MLX5_RES_XSRQ)\r\nreturn query_xrc_srq_cmd(dev, srq, out);\r\nelse\r\nreturn query_rmp_cmd(dev, srq, out);\r\n}\r\nint mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,\r\nu16 lwm, int is_srq)\r\n{\r\nif (!dev->issi)\r\nreturn arm_srq_cmd(dev, srq, lwm, is_srq);\r\nelse if (srq->common.res == MLX5_RES_XSRQ)\r\nreturn arm_xrc_srq_cmd(dev, srq, lwm);\r\nelse\r\nreturn arm_rmp_cmd(dev, srq, lwm);\r\n}\r\nvoid mlx5_init_srq_table(struct mlx5_core_dev *dev)\r\n{\r\nstruct mlx5_srq_table *table = &dev->priv.srq_table;\r\nmemset(table, 0, sizeof(*table));\r\nspin_lock_init(&table->lock);\r\nINIT_RADIX_TREE(&table->tree, GFP_ATOMIC);\r\n}\r\nvoid mlx5_cleanup_srq_table(struct mlx5_core_dev *dev)\r\n{\r\n}
