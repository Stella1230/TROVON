static struct s390_domain *to_s390_domain(struct iommu_domain *dom)\r\n{\r\nreturn container_of(dom, struct s390_domain, domain);\r\n}\r\nstatic bool s390_iommu_capable(enum iommu_cap cap)\r\n{\r\nswitch (cap) {\r\ncase IOMMU_CAP_CACHE_COHERENCY:\r\nreturn true;\r\ncase IOMMU_CAP_INTR_REMAP:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nstatic struct iommu_domain *s390_domain_alloc(unsigned domain_type)\r\n{\r\nstruct s390_domain *s390_domain;\r\nif (domain_type != IOMMU_DOMAIN_UNMANAGED)\r\nreturn NULL;\r\ns390_domain = kzalloc(sizeof(*s390_domain), GFP_KERNEL);\r\nif (!s390_domain)\r\nreturn NULL;\r\ns390_domain->dma_table = dma_alloc_cpu_table();\r\nif (!s390_domain->dma_table) {\r\nkfree(s390_domain);\r\nreturn NULL;\r\n}\r\nspin_lock_init(&s390_domain->dma_table_lock);\r\nspin_lock_init(&s390_domain->list_lock);\r\nINIT_LIST_HEAD(&s390_domain->devices);\r\nreturn &s390_domain->domain;\r\n}\r\nstatic void s390_domain_free(struct iommu_domain *domain)\r\n{\r\nstruct s390_domain *s390_domain = to_s390_domain(domain);\r\ndma_cleanup_tables(s390_domain->dma_table);\r\nkfree(s390_domain);\r\n}\r\nstatic int s390_iommu_attach_device(struct iommu_domain *domain,\r\nstruct device *dev)\r\n{\r\nstruct s390_domain *s390_domain = to_s390_domain(domain);\r\nstruct zpci_dev *zdev = to_pci_dev(dev)->sysdata;\r\nstruct s390_domain_device *domain_device;\r\nunsigned long flags;\r\nint rc;\r\nif (!zdev)\r\nreturn -ENODEV;\r\ndomain_device = kzalloc(sizeof(*domain_device), GFP_KERNEL);\r\nif (!domain_device)\r\nreturn -ENOMEM;\r\nif (zdev->dma_table)\r\nzpci_dma_exit_device(zdev);\r\nzdev->dma_table = s390_domain->dma_table;\r\nrc = zpci_register_ioat(zdev, 0, zdev->start_dma, zdev->end_dma,\r\n(u64) zdev->dma_table);\r\nif (rc)\r\ngoto out_restore;\r\nspin_lock_irqsave(&s390_domain->list_lock, flags);\r\nif (list_empty(&s390_domain->devices)) {\r\ndomain->geometry.aperture_start = zdev->start_dma;\r\ndomain->geometry.aperture_end = zdev->end_dma;\r\ndomain->geometry.force_aperture = true;\r\n} else if (domain->geometry.aperture_start != zdev->start_dma ||\r\ndomain->geometry.aperture_end != zdev->end_dma) {\r\nrc = -EINVAL;\r\nspin_unlock_irqrestore(&s390_domain->list_lock, flags);\r\ngoto out_restore;\r\n}\r\ndomain_device->zdev = zdev;\r\nzdev->s390_domain = s390_domain;\r\nlist_add(&domain_device->list, &s390_domain->devices);\r\nspin_unlock_irqrestore(&s390_domain->list_lock, flags);\r\nreturn 0;\r\nout_restore:\r\nzpci_dma_init_device(zdev);\r\nkfree(domain_device);\r\nreturn rc;\r\n}\r\nstatic void s390_iommu_detach_device(struct iommu_domain *domain,\r\nstruct device *dev)\r\n{\r\nstruct s390_domain *s390_domain = to_s390_domain(domain);\r\nstruct zpci_dev *zdev = to_pci_dev(dev)->sysdata;\r\nstruct s390_domain_device *domain_device, *tmp;\r\nunsigned long flags;\r\nint found = 0;\r\nif (!zdev)\r\nreturn;\r\nspin_lock_irqsave(&s390_domain->list_lock, flags);\r\nlist_for_each_entry_safe(domain_device, tmp, &s390_domain->devices,\r\nlist) {\r\nif (domain_device->zdev == zdev) {\r\nlist_del(&domain_device->list);\r\nkfree(domain_device);\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nspin_unlock_irqrestore(&s390_domain->list_lock, flags);\r\nif (found) {\r\nzdev->s390_domain = NULL;\r\nzpci_unregister_ioat(zdev, 0);\r\nzpci_dma_init_device(zdev);\r\n}\r\n}\r\nstatic int s390_iommu_add_device(struct device *dev)\r\n{\r\nstruct iommu_group *group;\r\nint rc;\r\ngroup = iommu_group_get(dev);\r\nif (!group) {\r\ngroup = iommu_group_alloc();\r\nif (IS_ERR(group))\r\nreturn PTR_ERR(group);\r\n}\r\nrc = iommu_group_add_device(group, dev);\r\niommu_group_put(group);\r\nreturn rc;\r\n}\r\nstatic void s390_iommu_remove_device(struct device *dev)\r\n{\r\nstruct zpci_dev *zdev = to_pci_dev(dev)->sysdata;\r\nstruct iommu_domain *domain;\r\nif (zdev && zdev->s390_domain) {\r\ndomain = iommu_get_domain_for_dev(dev);\r\nif (domain)\r\ns390_iommu_detach_device(domain, dev);\r\n}\r\niommu_group_remove_device(dev);\r\n}\r\nstatic int s390_iommu_update_trans(struct s390_domain *s390_domain,\r\nunsigned long pa, dma_addr_t dma_addr,\r\nsize_t size, int flags)\r\n{\r\nstruct s390_domain_device *domain_device;\r\nu8 *page_addr = (u8 *) (pa & PAGE_MASK);\r\ndma_addr_t start_dma_addr = dma_addr;\r\nunsigned long irq_flags, nr_pages, i;\r\nunsigned long *entry;\r\nint rc = 0;\r\nif (dma_addr < s390_domain->domain.geometry.aperture_start ||\r\ndma_addr + size > s390_domain->domain.geometry.aperture_end)\r\nreturn -EINVAL;\r\nnr_pages = PAGE_ALIGN(size) >> PAGE_SHIFT;\r\nif (!nr_pages)\r\nreturn 0;\r\nspin_lock_irqsave(&s390_domain->dma_table_lock, irq_flags);\r\nfor (i = 0; i < nr_pages; i++) {\r\nentry = dma_walk_cpu_trans(s390_domain->dma_table, dma_addr);\r\nif (!entry) {\r\nrc = -ENOMEM;\r\ngoto undo_cpu_trans;\r\n}\r\ndma_update_cpu_trans(entry, page_addr, flags);\r\npage_addr += PAGE_SIZE;\r\ndma_addr += PAGE_SIZE;\r\n}\r\nspin_lock(&s390_domain->list_lock);\r\nlist_for_each_entry(domain_device, &s390_domain->devices, list) {\r\nrc = zpci_refresh_trans((u64) domain_device->zdev->fh << 32,\r\nstart_dma_addr, nr_pages * PAGE_SIZE);\r\nif (rc)\r\nbreak;\r\n}\r\nspin_unlock(&s390_domain->list_lock);\r\nundo_cpu_trans:\r\nif (rc && ((flags & ZPCI_PTE_VALID_MASK) == ZPCI_PTE_VALID)) {\r\nflags = ZPCI_PTE_INVALID;\r\nwhile (i-- > 0) {\r\npage_addr -= PAGE_SIZE;\r\ndma_addr -= PAGE_SIZE;\r\nentry = dma_walk_cpu_trans(s390_domain->dma_table,\r\ndma_addr);\r\nif (!entry)\r\nbreak;\r\ndma_update_cpu_trans(entry, page_addr, flags);\r\n}\r\n}\r\nspin_unlock_irqrestore(&s390_domain->dma_table_lock, irq_flags);\r\nreturn rc;\r\n}\r\nstatic int s390_iommu_map(struct iommu_domain *domain, unsigned long iova,\r\nphys_addr_t paddr, size_t size, int prot)\r\n{\r\nstruct s390_domain *s390_domain = to_s390_domain(domain);\r\nint flags = ZPCI_PTE_VALID, rc = 0;\r\nif (!(prot & IOMMU_READ))\r\nreturn -EINVAL;\r\nif (!(prot & IOMMU_WRITE))\r\nflags |= ZPCI_TABLE_PROTECTED;\r\nrc = s390_iommu_update_trans(s390_domain, (unsigned long) paddr, iova,\r\nsize, flags);\r\nreturn rc;\r\n}\r\nstatic phys_addr_t s390_iommu_iova_to_phys(struct iommu_domain *domain,\r\ndma_addr_t iova)\r\n{\r\nstruct s390_domain *s390_domain = to_s390_domain(domain);\r\nunsigned long *sto, *pto, *rto, flags;\r\nunsigned int rtx, sx, px;\r\nphys_addr_t phys = 0;\r\nif (iova < domain->geometry.aperture_start ||\r\niova > domain->geometry.aperture_end)\r\nreturn 0;\r\nrtx = calc_rtx(iova);\r\nsx = calc_sx(iova);\r\npx = calc_px(iova);\r\nrto = s390_domain->dma_table;\r\nspin_lock_irqsave(&s390_domain->dma_table_lock, flags);\r\nif (rto && reg_entry_isvalid(rto[rtx])) {\r\nsto = get_rt_sto(rto[rtx]);\r\nif (sto && reg_entry_isvalid(sto[sx])) {\r\npto = get_st_pto(sto[sx]);\r\nif (pto && pt_entry_isvalid(pto[px]))\r\nphys = pto[px] & ZPCI_PTE_ADDR_MASK;\r\n}\r\n}\r\nspin_unlock_irqrestore(&s390_domain->dma_table_lock, flags);\r\nreturn phys;\r\n}\r\nstatic size_t s390_iommu_unmap(struct iommu_domain *domain,\r\nunsigned long iova, size_t size)\r\n{\r\nstruct s390_domain *s390_domain = to_s390_domain(domain);\r\nint flags = ZPCI_PTE_INVALID;\r\nphys_addr_t paddr;\r\nint rc;\r\npaddr = s390_iommu_iova_to_phys(domain, iova);\r\nif (!paddr)\r\nreturn 0;\r\nrc = s390_iommu_update_trans(s390_domain, (unsigned long) paddr, iova,\r\nsize, flags);\r\nif (rc)\r\nreturn 0;\r\nreturn size;\r\n}\r\nstatic int __init s390_iommu_init(void)\r\n{\r\nreturn bus_set_iommu(&pci_bus_type, &s390_iommu_ops);\r\n}
