static int mxs_dcp_start_dma(struct dcp_async_ctx *actx)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nconst int chan = actx->chan;\r\nuint32_t stat;\r\nunsigned long ret;\r\nstruct dcp_dma_desc *desc = &sdcp->coh->desc[actx->chan];\r\ndma_addr_t desc_phys = dma_map_single(sdcp->dev, desc, sizeof(*desc),\r\nDMA_TO_DEVICE);\r\nreinit_completion(&sdcp->completion[chan]);\r\nwritel(0xffffffff, sdcp->base + MXS_DCP_CH_N_STAT_CLR(chan));\r\nwritel(desc_phys, sdcp->base + MXS_DCP_CH_N_CMDPTR(chan));\r\nwritel(1, sdcp->base + MXS_DCP_CH_N_SEMA(chan));\r\nret = wait_for_completion_timeout(&sdcp->completion[chan],\r\nmsecs_to_jiffies(1000));\r\nif (!ret) {\r\ndev_err(sdcp->dev, "Channel %i timeout (DCP_STAT=0x%08x)\n",\r\nchan, readl(sdcp->base + MXS_DCP_STAT));\r\nreturn -ETIMEDOUT;\r\n}\r\nstat = readl(sdcp->base + MXS_DCP_CH_N_STAT(chan));\r\nif (stat & 0xff) {\r\ndev_err(sdcp->dev, "Channel %i error (CH_STAT=0x%08x)\n",\r\nchan, stat);\r\nreturn -EINVAL;\r\n}\r\ndma_unmap_single(sdcp->dev, desc_phys, sizeof(*desc), DMA_TO_DEVICE);\r\nreturn 0;\r\n}\r\nstatic int mxs_dcp_run_aes(struct dcp_async_ctx *actx,\r\nstruct ablkcipher_request *req, int init)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nstruct dcp_dma_desc *desc = &sdcp->coh->desc[actx->chan];\r\nstruct dcp_aes_req_ctx *rctx = ablkcipher_request_ctx(req);\r\nint ret;\r\ndma_addr_t key_phys = dma_map_single(sdcp->dev, sdcp->coh->aes_key,\r\n2 * AES_KEYSIZE_128,\r\nDMA_TO_DEVICE);\r\ndma_addr_t src_phys = dma_map_single(sdcp->dev, sdcp->coh->aes_in_buf,\r\nDCP_BUF_SZ, DMA_TO_DEVICE);\r\ndma_addr_t dst_phys = dma_map_single(sdcp->dev, sdcp->coh->aes_out_buf,\r\nDCP_BUF_SZ, DMA_FROM_DEVICE);\r\ndesc->control0 = MXS_DCP_CONTROL0_DECR_SEMAPHORE |\r\nMXS_DCP_CONTROL0_INTERRUPT |\r\nMXS_DCP_CONTROL0_ENABLE_CIPHER;\r\ndesc->control0 |= MXS_DCP_CONTROL0_PAYLOAD_KEY;\r\nif (rctx->enc)\r\ndesc->control0 |= MXS_DCP_CONTROL0_CIPHER_ENCRYPT;\r\nif (init)\r\ndesc->control0 |= MXS_DCP_CONTROL0_CIPHER_INIT;\r\ndesc->control1 = MXS_DCP_CONTROL1_CIPHER_SELECT_AES128;\r\nif (rctx->ecb)\r\ndesc->control1 |= MXS_DCP_CONTROL1_CIPHER_MODE_ECB;\r\nelse\r\ndesc->control1 |= MXS_DCP_CONTROL1_CIPHER_MODE_CBC;\r\ndesc->next_cmd_addr = 0;\r\ndesc->source = src_phys;\r\ndesc->destination = dst_phys;\r\ndesc->size = actx->fill;\r\ndesc->payload = key_phys;\r\ndesc->status = 0;\r\nret = mxs_dcp_start_dma(actx);\r\ndma_unmap_single(sdcp->dev, key_phys, 2 * AES_KEYSIZE_128,\r\nDMA_TO_DEVICE);\r\ndma_unmap_single(sdcp->dev, src_phys, DCP_BUF_SZ, DMA_TO_DEVICE);\r\ndma_unmap_single(sdcp->dev, dst_phys, DCP_BUF_SZ, DMA_FROM_DEVICE);\r\nreturn ret;\r\n}\r\nstatic int mxs_dcp_aes_block_crypt(struct crypto_async_request *arq)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nstruct ablkcipher_request *req = ablkcipher_request_cast(arq);\r\nstruct dcp_async_ctx *actx = crypto_tfm_ctx(arq->tfm);\r\nstruct dcp_aes_req_ctx *rctx = ablkcipher_request_ctx(req);\r\nstruct scatterlist *dst = req->dst;\r\nstruct scatterlist *src = req->src;\r\nconst int nents = sg_nents(req->src);\r\nconst int out_off = DCP_BUF_SZ;\r\nuint8_t *in_buf = sdcp->coh->aes_in_buf;\r\nuint8_t *out_buf = sdcp->coh->aes_out_buf;\r\nuint8_t *out_tmp, *src_buf, *dst_buf = NULL;\r\nuint32_t dst_off = 0;\r\nuint8_t *key = sdcp->coh->aes_key;\r\nint ret = 0;\r\nint split = 0;\r\nunsigned int i, len, clen, rem = 0;\r\nint init = 0;\r\nactx->fill = 0;\r\nmemcpy(key, actx->key, actx->key_len);\r\nif (!rctx->ecb) {\r\nmemcpy(key + AES_KEYSIZE_128, req->info, AES_KEYSIZE_128);\r\ninit = 1;\r\n} else {\r\nmemset(key + AES_KEYSIZE_128, 0, AES_KEYSIZE_128);\r\n}\r\nfor_each_sg(req->src, src, nents, i) {\r\nsrc_buf = sg_virt(src);\r\nlen = sg_dma_len(src);\r\ndo {\r\nif (actx->fill + len > out_off)\r\nclen = out_off - actx->fill;\r\nelse\r\nclen = len;\r\nmemcpy(in_buf + actx->fill, src_buf, clen);\r\nlen -= clen;\r\nsrc_buf += clen;\r\nactx->fill += clen;\r\nif (actx->fill == out_off || sg_is_last(src)) {\r\nret = mxs_dcp_run_aes(actx, req, init);\r\nif (ret)\r\nreturn ret;\r\ninit = 0;\r\nout_tmp = out_buf;\r\nwhile (dst && actx->fill) {\r\nif (!split) {\r\ndst_buf = sg_virt(dst);\r\ndst_off = 0;\r\n}\r\nrem = min(sg_dma_len(dst) - dst_off,\r\nactx->fill);\r\nmemcpy(dst_buf + dst_off, out_tmp, rem);\r\nout_tmp += rem;\r\ndst_off += rem;\r\nactx->fill -= rem;\r\nif (dst_off == sg_dma_len(dst)) {\r\ndst = sg_next(dst);\r\nsplit = 0;\r\n} else {\r\nsplit = 1;\r\n}\r\n}\r\n}\r\n} while (len);\r\n}\r\nreturn ret;\r\n}\r\nstatic int dcp_chan_thread_aes(void *data)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nconst int chan = DCP_CHAN_CRYPTO;\r\nstruct crypto_async_request *backlog;\r\nstruct crypto_async_request *arq;\r\nint ret;\r\ndo {\r\n__set_current_state(TASK_INTERRUPTIBLE);\r\nmutex_lock(&sdcp->mutex[chan]);\r\nbacklog = crypto_get_backlog(&sdcp->queue[chan]);\r\narq = crypto_dequeue_request(&sdcp->queue[chan]);\r\nmutex_unlock(&sdcp->mutex[chan]);\r\nif (backlog)\r\nbacklog->complete(backlog, -EINPROGRESS);\r\nif (arq) {\r\nret = mxs_dcp_aes_block_crypt(arq);\r\narq->complete(arq, ret);\r\ncontinue;\r\n}\r\nschedule();\r\n} while (!kthread_should_stop());\r\nreturn 0;\r\n}\r\nstatic int mxs_dcp_block_fallback(struct ablkcipher_request *req, int enc)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct dcp_async_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nSKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);\r\nint ret;\r\nskcipher_request_set_tfm(subreq, ctx->fallback);\r\nskcipher_request_set_callback(subreq, req->base.flags, NULL, NULL);\r\nskcipher_request_set_crypt(subreq, req->src, req->dst,\r\nreq->nbytes, req->info);\r\nif (enc)\r\nret = crypto_skcipher_encrypt(subreq);\r\nelse\r\nret = crypto_skcipher_decrypt(subreq);\r\nskcipher_request_zero(subreq);\r\nreturn ret;\r\n}\r\nstatic int mxs_dcp_aes_enqueue(struct ablkcipher_request *req, int enc, int ecb)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nstruct crypto_async_request *arq = &req->base;\r\nstruct dcp_async_ctx *actx = crypto_tfm_ctx(arq->tfm);\r\nstruct dcp_aes_req_ctx *rctx = ablkcipher_request_ctx(req);\r\nint ret;\r\nif (unlikely(actx->key_len != AES_KEYSIZE_128))\r\nreturn mxs_dcp_block_fallback(req, enc);\r\nrctx->enc = enc;\r\nrctx->ecb = ecb;\r\nactx->chan = DCP_CHAN_CRYPTO;\r\nmutex_lock(&sdcp->mutex[actx->chan]);\r\nret = crypto_enqueue_request(&sdcp->queue[actx->chan], &req->base);\r\nmutex_unlock(&sdcp->mutex[actx->chan]);\r\nwake_up_process(sdcp->thread[actx->chan]);\r\nreturn -EINPROGRESS;\r\n}\r\nstatic int mxs_dcp_aes_ecb_decrypt(struct ablkcipher_request *req)\r\n{\r\nreturn mxs_dcp_aes_enqueue(req, 0, 1);\r\n}\r\nstatic int mxs_dcp_aes_ecb_encrypt(struct ablkcipher_request *req)\r\n{\r\nreturn mxs_dcp_aes_enqueue(req, 1, 1);\r\n}\r\nstatic int mxs_dcp_aes_cbc_decrypt(struct ablkcipher_request *req)\r\n{\r\nreturn mxs_dcp_aes_enqueue(req, 0, 0);\r\n}\r\nstatic int mxs_dcp_aes_cbc_encrypt(struct ablkcipher_request *req)\r\n{\r\nreturn mxs_dcp_aes_enqueue(req, 1, 0);\r\n}\r\nstatic int mxs_dcp_aes_setkey(struct crypto_ablkcipher *tfm, const u8 *key,\r\nunsigned int len)\r\n{\r\nstruct dcp_async_ctx *actx = crypto_ablkcipher_ctx(tfm);\r\nunsigned int ret;\r\nactx->key_len = len;\r\nif (len == AES_KEYSIZE_128) {\r\nmemcpy(actx->key, key, len);\r\nreturn 0;\r\n}\r\ncrypto_skcipher_clear_flags(actx->fallback, CRYPTO_TFM_REQ_MASK);\r\ncrypto_skcipher_set_flags(actx->fallback,\r\ntfm->base.crt_flags & CRYPTO_TFM_REQ_MASK);\r\nret = crypto_skcipher_setkey(actx->fallback, key, len);\r\nif (!ret)\r\nreturn 0;\r\ntfm->base.crt_flags &= ~CRYPTO_TFM_RES_MASK;\r\ntfm->base.crt_flags |= crypto_skcipher_get_flags(actx->fallback) &\r\nCRYPTO_TFM_RES_MASK;\r\nreturn ret;\r\n}\r\nstatic int mxs_dcp_aes_fallback_init(struct crypto_tfm *tfm)\r\n{\r\nconst char *name = crypto_tfm_alg_name(tfm);\r\nconst uint32_t flags = CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK;\r\nstruct dcp_async_ctx *actx = crypto_tfm_ctx(tfm);\r\nstruct crypto_skcipher *blk;\r\nblk = crypto_alloc_skcipher(name, 0, flags);\r\nif (IS_ERR(blk))\r\nreturn PTR_ERR(blk);\r\nactx->fallback = blk;\r\ntfm->crt_ablkcipher.reqsize = sizeof(struct dcp_aes_req_ctx);\r\nreturn 0;\r\n}\r\nstatic void mxs_dcp_aes_fallback_exit(struct crypto_tfm *tfm)\r\n{\r\nstruct dcp_async_ctx *actx = crypto_tfm_ctx(tfm);\r\ncrypto_free_skcipher(actx->fallback);\r\n}\r\nstatic int mxs_dcp_run_sha(struct ahash_request *req)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nint ret;\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct dcp_async_ctx *actx = crypto_ahash_ctx(tfm);\r\nstruct dcp_sha_req_ctx *rctx = ahash_request_ctx(req);\r\nstruct hash_alg_common *halg = crypto_hash_alg_common(tfm);\r\nstruct dcp_dma_desc *desc = &sdcp->coh->desc[actx->chan];\r\ndma_addr_t digest_phys = 0;\r\ndma_addr_t buf_phys = dma_map_single(sdcp->dev, sdcp->coh->sha_in_buf,\r\nDCP_BUF_SZ, DMA_TO_DEVICE);\r\ndesc->control0 = MXS_DCP_CONTROL0_DECR_SEMAPHORE |\r\nMXS_DCP_CONTROL0_INTERRUPT |\r\nMXS_DCP_CONTROL0_ENABLE_HASH;\r\nif (rctx->init)\r\ndesc->control0 |= MXS_DCP_CONTROL0_HASH_INIT;\r\ndesc->control1 = actx->alg;\r\ndesc->next_cmd_addr = 0;\r\ndesc->source = buf_phys;\r\ndesc->destination = 0;\r\ndesc->size = actx->fill;\r\ndesc->payload = 0;\r\ndesc->status = 0;\r\nif (rctx->fini) {\r\ndigest_phys = dma_map_single(sdcp->dev, req->result,\r\nhalg->digestsize, DMA_FROM_DEVICE);\r\ndesc->control0 |= MXS_DCP_CONTROL0_HASH_TERM;\r\ndesc->payload = digest_phys;\r\n}\r\nret = mxs_dcp_start_dma(actx);\r\nif (rctx->fini)\r\ndma_unmap_single(sdcp->dev, digest_phys, halg->digestsize,\r\nDMA_FROM_DEVICE);\r\ndma_unmap_single(sdcp->dev, buf_phys, DCP_BUF_SZ, DMA_TO_DEVICE);\r\nreturn ret;\r\n}\r\nstatic int dcp_sha_req_to_buf(struct crypto_async_request *arq)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nstruct ahash_request *req = ahash_request_cast(arq);\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct dcp_async_ctx *actx = crypto_ahash_ctx(tfm);\r\nstruct dcp_sha_req_ctx *rctx = ahash_request_ctx(req);\r\nstruct hash_alg_common *halg = crypto_hash_alg_common(tfm);\r\nconst int nents = sg_nents(req->src);\r\nuint8_t *in_buf = sdcp->coh->sha_in_buf;\r\nuint8_t *src_buf;\r\nstruct scatterlist *src;\r\nunsigned int i, len, clen;\r\nint ret;\r\nint fin = rctx->fini;\r\nif (fin)\r\nrctx->fini = 0;\r\nfor_each_sg(req->src, src, nents, i) {\r\nsrc_buf = sg_virt(src);\r\nlen = sg_dma_len(src);\r\ndo {\r\nif (actx->fill + len > DCP_BUF_SZ)\r\nclen = DCP_BUF_SZ - actx->fill;\r\nelse\r\nclen = len;\r\nmemcpy(in_buf + actx->fill, src_buf, clen);\r\nlen -= clen;\r\nsrc_buf += clen;\r\nactx->fill += clen;\r\nif (len && actx->fill == DCP_BUF_SZ) {\r\nret = mxs_dcp_run_sha(req);\r\nif (ret)\r\nreturn ret;\r\nactx->fill = 0;\r\nrctx->init = 0;\r\n}\r\n} while (len);\r\n}\r\nif (fin) {\r\nrctx->fini = 1;\r\nif (!req->result)\r\nreturn -EINVAL;\r\nret = mxs_dcp_run_sha(req);\r\nif (ret)\r\nreturn ret;\r\nactx->fill = 0;\r\nfor (i = 0; i < halg->digestsize / 2; i++) {\r\nswap(req->result[i],\r\nreq->result[halg->digestsize - i - 1]);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int dcp_chan_thread_sha(void *data)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nconst int chan = DCP_CHAN_HASH_SHA;\r\nstruct crypto_async_request *backlog;\r\nstruct crypto_async_request *arq;\r\nstruct dcp_sha_req_ctx *rctx;\r\nstruct ahash_request *req;\r\nint ret, fini;\r\ndo {\r\n__set_current_state(TASK_INTERRUPTIBLE);\r\nmutex_lock(&sdcp->mutex[chan]);\r\nbacklog = crypto_get_backlog(&sdcp->queue[chan]);\r\narq = crypto_dequeue_request(&sdcp->queue[chan]);\r\nmutex_unlock(&sdcp->mutex[chan]);\r\nif (backlog)\r\nbacklog->complete(backlog, -EINPROGRESS);\r\nif (arq) {\r\nreq = ahash_request_cast(arq);\r\nrctx = ahash_request_ctx(req);\r\nret = dcp_sha_req_to_buf(arq);\r\nfini = rctx->fini;\r\narq->complete(arq, ret);\r\nif (!fini)\r\ncontinue;\r\n}\r\nschedule();\r\n} while (!kthread_should_stop());\r\nreturn 0;\r\n}\r\nstatic int dcp_sha_init(struct ahash_request *req)\r\n{\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct dcp_async_ctx *actx = crypto_ahash_ctx(tfm);\r\nstruct hash_alg_common *halg = crypto_hash_alg_common(tfm);\r\nmemset(actx, 0, sizeof(*actx));\r\nif (strcmp(halg->base.cra_name, "sha1") == 0)\r\nactx->alg = MXS_DCP_CONTROL1_HASH_SELECT_SHA1;\r\nelse\r\nactx->alg = MXS_DCP_CONTROL1_HASH_SELECT_SHA256;\r\nactx->fill = 0;\r\nactx->hot = 0;\r\nactx->chan = DCP_CHAN_HASH_SHA;\r\nmutex_init(&actx->mutex);\r\nreturn 0;\r\n}\r\nstatic int dcp_sha_update_fx(struct ahash_request *req, int fini)\r\n{\r\nstruct dcp *sdcp = global_sdcp;\r\nstruct dcp_sha_req_ctx *rctx = ahash_request_ctx(req);\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct dcp_async_ctx *actx = crypto_ahash_ctx(tfm);\r\nint ret;\r\nif (!req->nbytes && !fini)\r\nreturn 0;\r\nmutex_lock(&actx->mutex);\r\nrctx->fini = fini;\r\nif (!actx->hot) {\r\nactx->hot = 1;\r\nrctx->init = 1;\r\n}\r\nmutex_lock(&sdcp->mutex[actx->chan]);\r\nret = crypto_enqueue_request(&sdcp->queue[actx->chan], &req->base);\r\nmutex_unlock(&sdcp->mutex[actx->chan]);\r\nwake_up_process(sdcp->thread[actx->chan]);\r\nmutex_unlock(&actx->mutex);\r\nreturn -EINPROGRESS;\r\n}\r\nstatic int dcp_sha_update(struct ahash_request *req)\r\n{\r\nreturn dcp_sha_update_fx(req, 0);\r\n}\r\nstatic int dcp_sha_final(struct ahash_request *req)\r\n{\r\nahash_request_set_crypt(req, NULL, req->result, 0);\r\nreq->nbytes = 0;\r\nreturn dcp_sha_update_fx(req, 1);\r\n}\r\nstatic int dcp_sha_finup(struct ahash_request *req)\r\n{\r\nreturn dcp_sha_update_fx(req, 1);\r\n}\r\nstatic int dcp_sha_digest(struct ahash_request *req)\r\n{\r\nint ret;\r\nret = dcp_sha_init(req);\r\nif (ret)\r\nreturn ret;\r\nreturn dcp_sha_finup(req);\r\n}\r\nstatic int dcp_sha_cra_init(struct crypto_tfm *tfm)\r\n{\r\ncrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\r\nsizeof(struct dcp_sha_req_ctx));\r\nreturn 0;\r\n}\r\nstatic void dcp_sha_cra_exit(struct crypto_tfm *tfm)\r\n{\r\n}\r\nstatic irqreturn_t mxs_dcp_irq(int irq, void *context)\r\n{\r\nstruct dcp *sdcp = context;\r\nuint32_t stat;\r\nint i;\r\nstat = readl(sdcp->base + MXS_DCP_STAT);\r\nstat &= MXS_DCP_STAT_IRQ_MASK;\r\nif (!stat)\r\nreturn IRQ_NONE;\r\nwritel(stat, sdcp->base + MXS_DCP_STAT_CLR);\r\nfor (i = 0; i < DCP_MAX_CHANS; i++)\r\nif (stat & (1 << i))\r\ncomplete(&sdcp->completion[i]);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int mxs_dcp_probe(struct platform_device *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct dcp *sdcp = NULL;\r\nint i, ret;\r\nstruct resource *iores;\r\nint dcp_vmi_irq, dcp_irq;\r\nif (global_sdcp) {\r\ndev_err(dev, "Only one DCP instance allowed!\n");\r\nreturn -ENODEV;\r\n}\r\niores = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\ndcp_vmi_irq = platform_get_irq(pdev, 0);\r\nif (dcp_vmi_irq < 0)\r\nreturn dcp_vmi_irq;\r\ndcp_irq = platform_get_irq(pdev, 1);\r\nif (dcp_irq < 0)\r\nreturn dcp_irq;\r\nsdcp = devm_kzalloc(dev, sizeof(*sdcp), GFP_KERNEL);\r\nif (!sdcp)\r\nreturn -ENOMEM;\r\nsdcp->dev = dev;\r\nsdcp->base = devm_ioremap_resource(dev, iores);\r\nif (IS_ERR(sdcp->base))\r\nreturn PTR_ERR(sdcp->base);\r\nret = devm_request_irq(dev, dcp_vmi_irq, mxs_dcp_irq, 0,\r\n"dcp-vmi-irq", sdcp);\r\nif (ret) {\r\ndev_err(dev, "Failed to claim DCP VMI IRQ!\n");\r\nreturn ret;\r\n}\r\nret = devm_request_irq(dev, dcp_irq, mxs_dcp_irq, 0,\r\n"dcp-irq", sdcp);\r\nif (ret) {\r\ndev_err(dev, "Failed to claim DCP IRQ!\n");\r\nreturn ret;\r\n}\r\nsdcp->coh = devm_kzalloc(dev, sizeof(*sdcp->coh) + DCP_ALIGNMENT,\r\nGFP_KERNEL);\r\nif (!sdcp->coh)\r\nreturn -ENOMEM;\r\nsdcp->coh = PTR_ALIGN(sdcp->coh, DCP_ALIGNMENT);\r\nret = stmp_reset_block(sdcp->base);\r\nif (ret)\r\nreturn ret;\r\nwritel(MXS_DCP_CTRL_GATHER_RESIDUAL_WRITES |\r\nMXS_DCP_CTRL_ENABLE_CONTEXT_CACHING | 0xf,\r\nsdcp->base + MXS_DCP_CTRL);\r\nwritel(MXS_DCP_CHANNELCTRL_ENABLE_CHANNEL_MASK,\r\nsdcp->base + MXS_DCP_CHANNELCTRL);\r\nwritel(0xffff0000, sdcp->base + MXS_DCP_CONTEXT);\r\nfor (i = 0; i < DCP_MAX_CHANS; i++)\r\nwritel(0xffffffff, sdcp->base + MXS_DCP_CH_N_STAT_CLR(i));\r\nwritel(0xffffffff, sdcp->base + MXS_DCP_STAT_CLR);\r\nglobal_sdcp = sdcp;\r\nplatform_set_drvdata(pdev, sdcp);\r\nfor (i = 0; i < DCP_MAX_CHANS; i++) {\r\nmutex_init(&sdcp->mutex[i]);\r\ninit_completion(&sdcp->completion[i]);\r\ncrypto_init_queue(&sdcp->queue[i], 50);\r\n}\r\nsdcp->thread[DCP_CHAN_HASH_SHA] = kthread_run(dcp_chan_thread_sha,\r\nNULL, "mxs_dcp_chan/sha");\r\nif (IS_ERR(sdcp->thread[DCP_CHAN_HASH_SHA])) {\r\ndev_err(dev, "Error starting SHA thread!\n");\r\nreturn PTR_ERR(sdcp->thread[DCP_CHAN_HASH_SHA]);\r\n}\r\nsdcp->thread[DCP_CHAN_CRYPTO] = kthread_run(dcp_chan_thread_aes,\r\nNULL, "mxs_dcp_chan/aes");\r\nif (IS_ERR(sdcp->thread[DCP_CHAN_CRYPTO])) {\r\ndev_err(dev, "Error starting SHA thread!\n");\r\nret = PTR_ERR(sdcp->thread[DCP_CHAN_CRYPTO]);\r\ngoto err_destroy_sha_thread;\r\n}\r\nsdcp->caps = readl(sdcp->base + MXS_DCP_CAPABILITY1);\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_AES128) {\r\nret = crypto_register_algs(dcp_aes_algs,\r\nARRAY_SIZE(dcp_aes_algs));\r\nif (ret) {\r\ndev_err(dev, "Failed to register AES crypto!\n");\r\ngoto err_destroy_aes_thread;\r\n}\r\n}\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_SHA1) {\r\nret = crypto_register_ahash(&dcp_sha1_alg);\r\nif (ret) {\r\ndev_err(dev, "Failed to register %s hash!\n",\r\ndcp_sha1_alg.halg.base.cra_name);\r\ngoto err_unregister_aes;\r\n}\r\n}\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_SHA256) {\r\nret = crypto_register_ahash(&dcp_sha256_alg);\r\nif (ret) {\r\ndev_err(dev, "Failed to register %s hash!\n",\r\ndcp_sha256_alg.halg.base.cra_name);\r\ngoto err_unregister_sha1;\r\n}\r\n}\r\nreturn 0;\r\nerr_unregister_sha1:\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_SHA1)\r\ncrypto_unregister_ahash(&dcp_sha1_alg);\r\nerr_unregister_aes:\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_AES128)\r\ncrypto_unregister_algs(dcp_aes_algs, ARRAY_SIZE(dcp_aes_algs));\r\nerr_destroy_aes_thread:\r\nkthread_stop(sdcp->thread[DCP_CHAN_CRYPTO]);\r\nerr_destroy_sha_thread:\r\nkthread_stop(sdcp->thread[DCP_CHAN_HASH_SHA]);\r\nreturn ret;\r\n}\r\nstatic int mxs_dcp_remove(struct platform_device *pdev)\r\n{\r\nstruct dcp *sdcp = platform_get_drvdata(pdev);\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_SHA256)\r\ncrypto_unregister_ahash(&dcp_sha256_alg);\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_SHA1)\r\ncrypto_unregister_ahash(&dcp_sha1_alg);\r\nif (sdcp->caps & MXS_DCP_CAPABILITY1_AES128)\r\ncrypto_unregister_algs(dcp_aes_algs, ARRAY_SIZE(dcp_aes_algs));\r\nkthread_stop(sdcp->thread[DCP_CHAN_HASH_SHA]);\r\nkthread_stop(sdcp->thread[DCP_CHAN_CRYPTO]);\r\nplatform_set_drvdata(pdev, NULL);\r\nglobal_sdcp = NULL;\r\nreturn 0;\r\n}
