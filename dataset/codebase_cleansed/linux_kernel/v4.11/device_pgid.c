static void verify_done(struct ccw_device *cdev, int rc)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_dev_id *id = &cdev->private->dev_id;\r\nint mpath = cdev->private->flags.mpath;\r\nint pgroup = cdev->private->flags.pgroup;\r\nif (rc)\r\ngoto out;\r\nif (sch->config.mp != mpath) {\r\nsch->config.mp = mpath;\r\nrc = cio_commit_config(sch);\r\n}\r\nout:\r\nCIO_MSG_EVENT(2, "vrfy: device 0.%x.%04x: rc=%d pgroup=%d mpath=%d "\r\n"vpm=%02x\n", id->ssid, id->devno, rc, pgroup, mpath,\r\nsch->vpm);\r\nccw_device_verify_done(cdev, rc);\r\n}\r\nstatic void nop_build_cp(struct ccw_device *cdev)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nstruct ccw1 *cp = cdev->private->iccws;\r\ncp->cmd_code = CCW_CMD_NOOP;\r\ncp->cda = 0;\r\ncp->count = 0;\r\ncp->flags = CCW_FLAG_SLI;\r\nreq->cp = cp;\r\n}\r\nstatic void nop_do(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nreq->lpm = lpm_adjust(req->lpm, sch->schib.pmcw.pam & sch->opm &\r\n~cdev->private->path_noirq_mask);\r\nif (!req->lpm)\r\ngoto out_nopath;\r\nnop_build_cp(cdev);\r\nccw_request_start(cdev);\r\nreturn;\r\nout_nopath:\r\nverify_done(cdev, sch->vpm ? 0 : -EACCES);\r\n}\r\nstatic enum io_status nop_filter(struct ccw_device *cdev, void *data,\r\nstruct irb *irb, enum io_status status)\r\n{\r\nif (status == IO_STATUS_ERROR && irb->scsw.cmd.cstat == 0)\r\nreturn IO_DONE;\r\nreturn status;\r\n}\r\nstatic void nop_callback(struct ccw_device *cdev, void *data, int rc)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nswitch (rc) {\r\ncase 0:\r\nsch->vpm |= req->lpm;\r\nbreak;\r\ncase -ETIME:\r\ncdev->private->path_noirq_mask |= req->lpm;\r\nbreak;\r\ncase -EACCES:\r\ncdev->private->path_notoper_mask |= req->lpm;\r\nbreak;\r\ndefault:\r\ngoto err;\r\n}\r\nreq->lpm >>= 1;\r\nnop_do(cdev);\r\nreturn;\r\nerr:\r\nverify_done(cdev, rc);\r\n}\r\nstatic void spid_build_cp(struct ccw_device *cdev, u8 fn)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nstruct ccw1 *cp = cdev->private->iccws;\r\nint i = pathmask_to_pos(req->lpm);\r\nstruct pgid *pgid = &cdev->private->pgid[i];\r\npgid->inf.fc = fn;\r\ncp->cmd_code = CCW_CMD_SET_PGID;\r\ncp->cda = (u32) (addr_t) pgid;\r\ncp->count = sizeof(*pgid);\r\ncp->flags = CCW_FLAG_SLI;\r\nreq->cp = cp;\r\n}\r\nstatic void pgid_wipeout_callback(struct ccw_device *cdev, void *data, int rc)\r\n{\r\nif (rc) {\r\nverify_done(cdev, rc);\r\nreturn;\r\n}\r\ncdev->private->flags.pgid_unknown = 0;\r\nverify_start(cdev);\r\n}\r\nstatic void pgid_wipeout_start(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_dev_id *id = &cdev->private->dev_id;\r\nstruct ccw_request *req = &cdev->private->req;\r\nu8 fn;\r\nCIO_MSG_EVENT(2, "wipe: device 0.%x.%04x: pvm=%02x nim=%02x\n",\r\nid->ssid, id->devno, cdev->private->pgid_valid_mask,\r\ncdev->private->path_noirq_mask);\r\nmemset(req, 0, sizeof(*req));\r\nreq->timeout = PGID_TIMEOUT;\r\nreq->maxretries = PGID_RETRIES;\r\nreq->lpm = sch->schib.pmcw.pam;\r\nreq->callback = pgid_wipeout_callback;\r\nfn = SPID_FUNC_DISBAND;\r\nif (cdev->private->flags.mpath)\r\nfn |= SPID_FUNC_MULTI_PATH;\r\nspid_build_cp(cdev, fn);\r\nccw_request_start(cdev);\r\n}\r\nstatic void spid_do(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nu8 fn;\r\nreq->lpm = lpm_adjust(req->lpm, cdev->private->pgid_todo_mask);\r\nif (!req->lpm)\r\ngoto out_nopath;\r\nif (req->lpm & sch->opm)\r\nfn = SPID_FUNC_ESTABLISH;\r\nelse\r\nfn = SPID_FUNC_RESIGN;\r\nif (cdev->private->flags.mpath)\r\nfn |= SPID_FUNC_MULTI_PATH;\r\nspid_build_cp(cdev, fn);\r\nccw_request_start(cdev);\r\nreturn;\r\nout_nopath:\r\nif (cdev->private->flags.pgid_unknown) {\r\npgid_wipeout_start(cdev);\r\nreturn;\r\n}\r\nverify_done(cdev, sch->vpm ? 0 : -EACCES);\r\n}\r\nstatic void spid_callback(struct ccw_device *cdev, void *data, int rc)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nswitch (rc) {\r\ncase 0:\r\nsch->vpm |= req->lpm & sch->opm;\r\nbreak;\r\ncase -ETIME:\r\ncdev->private->flags.pgid_unknown = 1;\r\ncdev->private->path_noirq_mask |= req->lpm;\r\nbreak;\r\ncase -EACCES:\r\ncdev->private->path_notoper_mask |= req->lpm;\r\nbreak;\r\ncase -EOPNOTSUPP:\r\nif (cdev->private->flags.mpath) {\r\ncdev->private->flags.mpath = 0;\r\ngoto out_restart;\r\n}\r\ncdev->private->flags.pgroup = 0;\r\ngoto out_restart;\r\ndefault:\r\ngoto err;\r\n}\r\nreq->lpm >>= 1;\r\nspid_do(cdev);\r\nreturn;\r\nout_restart:\r\nverify_start(cdev);\r\nreturn;\r\nerr:\r\nverify_done(cdev, rc);\r\n}\r\nstatic void spid_start(struct ccw_device *cdev)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nmemset(req, 0, sizeof(*req));\r\nreq->timeout = PGID_TIMEOUT;\r\nreq->maxretries = PGID_RETRIES;\r\nreq->lpm = 0x80;\r\nreq->singlepath = 1;\r\nreq->callback = spid_callback;\r\nspid_do(cdev);\r\n}\r\nstatic int pgid_is_reset(struct pgid *p)\r\n{\r\nchar *c;\r\nfor (c = (char *)p + 1; c < (char *)(p + 1); c++) {\r\nif (*c != 0)\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic int pgid_cmp(struct pgid *p1, struct pgid *p2)\r\n{\r\nreturn memcmp((char *) p1 + 1, (char *) p2 + 1,\r\nsizeof(struct pgid) - 1);\r\n}\r\nstatic void pgid_analyze(struct ccw_device *cdev, struct pgid **p,\r\nint *mismatch, u8 *reserved, u8 *reset)\r\n{\r\nstruct pgid *pgid = &cdev->private->pgid[0];\r\nstruct pgid *first = NULL;\r\nint lpm;\r\nint i;\r\n*mismatch = 0;\r\n*reserved = 0;\r\n*reset = 0;\r\nfor (i = 0, lpm = 0x80; i < 8; i++, pgid++, lpm >>= 1) {\r\nif ((cdev->private->pgid_valid_mask & lpm) == 0)\r\ncontinue;\r\nif (pgid->inf.ps.state2 == SNID_STATE2_RESVD_ELSE)\r\n*reserved |= lpm;\r\nif (pgid_is_reset(pgid)) {\r\n*reset |= lpm;\r\ncontinue;\r\n}\r\nif (!first) {\r\nfirst = pgid;\r\ncontinue;\r\n}\r\nif (pgid_cmp(pgid, first) != 0)\r\n*mismatch = 1;\r\n}\r\nif (!first)\r\nfirst = &channel_subsystems[0]->global_pgid;\r\n*p = first;\r\n}\r\nstatic u8 pgid_to_donepm(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct pgid *pgid;\r\nint i;\r\nint lpm;\r\nu8 donepm = 0;\r\nfor (i = 0; i < 8; i++) {\r\nlpm = 0x80 >> i;\r\nif ((cdev->private->pgid_valid_mask & lpm) == 0)\r\ncontinue;\r\npgid = &cdev->private->pgid[i];\r\nif (sch->opm & lpm) {\r\nif (pgid->inf.ps.state1 != SNID_STATE1_GROUPED)\r\ncontinue;\r\n} else {\r\nif (pgid->inf.ps.state1 != SNID_STATE1_UNGROUPED)\r\ncontinue;\r\n}\r\nif (cdev->private->flags.mpath) {\r\nif (pgid->inf.ps.state3 != SNID_STATE3_MULTI_PATH)\r\ncontinue;\r\n} else {\r\nif (pgid->inf.ps.state3 != SNID_STATE3_SINGLE_PATH)\r\ncontinue;\r\n}\r\ndonepm |= lpm;\r\n}\r\nreturn donepm;\r\n}\r\nstatic void pgid_fill(struct ccw_device *cdev, struct pgid *pgid)\r\n{\r\nint i;\r\nfor (i = 0; i < 8; i++)\r\nmemcpy(&cdev->private->pgid[i], pgid, sizeof(struct pgid));\r\n}\r\nstatic void snid_done(struct ccw_device *cdev, int rc)\r\n{\r\nstruct ccw_dev_id *id = &cdev->private->dev_id;\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct pgid *pgid;\r\nint mismatch = 0;\r\nu8 reserved = 0;\r\nu8 reset = 0;\r\nu8 donepm;\r\nif (rc)\r\ngoto out;\r\npgid_analyze(cdev, &pgid, &mismatch, &reserved, &reset);\r\nif (reserved == cdev->private->pgid_valid_mask)\r\nrc = -EUSERS;\r\nelse if (mismatch)\r\nrc = -EOPNOTSUPP;\r\nelse {\r\ndonepm = pgid_to_donepm(cdev);\r\nsch->vpm = donepm & sch->opm;\r\ncdev->private->pgid_reset_mask |= reset;\r\ncdev->private->pgid_todo_mask &=\r\n~(donepm | cdev->private->path_noirq_mask);\r\npgid_fill(cdev, pgid);\r\n}\r\nout:\r\nCIO_MSG_EVENT(2, "snid: device 0.%x.%04x: rc=%d pvm=%02x vpm=%02x "\r\n"todo=%02x mism=%d rsvd=%02x reset=%02x\n", id->ssid,\r\nid->devno, rc, cdev->private->pgid_valid_mask, sch->vpm,\r\ncdev->private->pgid_todo_mask, mismatch, reserved, reset);\r\nswitch (rc) {\r\ncase 0:\r\nif (cdev->private->flags.pgid_unknown) {\r\npgid_wipeout_start(cdev);\r\nreturn;\r\n}\r\nif (cdev->private->pgid_todo_mask == 0) {\r\nverify_done(cdev, sch->vpm == 0 ? -EACCES : 0);\r\nreturn;\r\n}\r\nspid_start(cdev);\r\nbreak;\r\ncase -EOPNOTSUPP:\r\ncdev->private->flags.pgroup = 0;\r\ncdev->private->flags.mpath = 0;\r\nverify_start(cdev);\r\nbreak;\r\ndefault:\r\nverify_done(cdev, rc);\r\n}\r\n}\r\nstatic void snid_build_cp(struct ccw_device *cdev)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nstruct ccw1 *cp = cdev->private->iccws;\r\nint i = pathmask_to_pos(req->lpm);\r\ncp->cmd_code = CCW_CMD_SENSE_PGID;\r\ncp->cda = (u32) (addr_t) &cdev->private->pgid[i];\r\ncp->count = sizeof(struct pgid);\r\ncp->flags = CCW_FLAG_SLI;\r\nreq->cp = cp;\r\n}\r\nstatic void snid_do(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nint ret;\r\nreq->lpm = lpm_adjust(req->lpm, sch->schib.pmcw.pam &\r\n~cdev->private->path_noirq_mask);\r\nif (!req->lpm)\r\ngoto out_nopath;\r\nsnid_build_cp(cdev);\r\nccw_request_start(cdev);\r\nreturn;\r\nout_nopath:\r\nif (cdev->private->pgid_valid_mask)\r\nret = 0;\r\nelse if (cdev->private->path_noirq_mask)\r\nret = -ETIME;\r\nelse\r\nret = -EACCES;\r\nsnid_done(cdev, ret);\r\n}\r\nstatic void snid_callback(struct ccw_device *cdev, void *data, int rc)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nswitch (rc) {\r\ncase 0:\r\ncdev->private->pgid_valid_mask |= req->lpm;\r\nbreak;\r\ncase -ETIME:\r\ncdev->private->flags.pgid_unknown = 1;\r\ncdev->private->path_noirq_mask |= req->lpm;\r\nbreak;\r\ncase -EACCES:\r\ncdev->private->path_notoper_mask |= req->lpm;\r\nbreak;\r\ndefault:\r\ngoto err;\r\n}\r\nreq->lpm >>= 1;\r\nsnid_do(cdev);\r\nreturn;\r\nerr:\r\nsnid_done(cdev, rc);\r\n}\r\nstatic void verify_start(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nstruct ccw_dev_id *devid = &cdev->private->dev_id;\r\nsch->vpm = 0;\r\nsch->lpm = sch->schib.pmcw.pam;\r\nmemset(cdev->private->pgid, 0, sizeof(cdev->private->pgid));\r\ncdev->private->pgid_valid_mask = 0;\r\ncdev->private->pgid_todo_mask = sch->schib.pmcw.pam;\r\ncdev->private->path_notoper_mask = 0;\r\nmemset(req, 0, sizeof(*req));\r\nreq->timeout = PGID_TIMEOUT;\r\nreq->maxretries = PGID_RETRIES;\r\nreq->lpm = 0x80;\r\nreq->singlepath = 1;\r\nif (cdev->private->flags.pgroup) {\r\nCIO_TRACE_EVENT(4, "snid");\r\nCIO_HEX_EVENT(4, devid, sizeof(*devid));\r\nreq->callback = snid_callback;\r\nsnid_do(cdev);\r\n} else {\r\nCIO_TRACE_EVENT(4, "nop");\r\nCIO_HEX_EVENT(4, devid, sizeof(*devid));\r\nreq->filter = nop_filter;\r\nreq->callback = nop_callback;\r\nnop_do(cdev);\r\n}\r\n}\r\nvoid ccw_device_verify_start(struct ccw_device *cdev)\r\n{\r\nCIO_TRACE_EVENT(4, "vrfy");\r\nCIO_HEX_EVENT(4, &cdev->private->dev_id, sizeof(cdev->private->dev_id));\r\ncdev->private->flags.pgroup = cdev->private->options.pgroup;\r\ncdev->private->flags.mpath = cdev->private->options.mpath;\r\ncdev->private->flags.doverify = 0;\r\ncdev->private->path_noirq_mask = 0;\r\nverify_start(cdev);\r\n}\r\nstatic void disband_callback(struct ccw_device *cdev, void *data, int rc)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_dev_id *id = &cdev->private->dev_id;\r\nif (rc)\r\ngoto out;\r\ncdev->private->flags.mpath = 0;\r\nif (sch->config.mp) {\r\nsch->config.mp = 0;\r\nrc = cio_commit_config(sch);\r\n}\r\nout:\r\nCIO_MSG_EVENT(0, "disb: device 0.%x.%04x: rc=%d\n", id->ssid, id->devno,\r\nrc);\r\nccw_device_disband_done(cdev, rc);\r\n}\r\nvoid ccw_device_disband_start(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nu8 fn;\r\nCIO_TRACE_EVENT(4, "disb");\r\nCIO_HEX_EVENT(4, &cdev->private->dev_id, sizeof(cdev->private->dev_id));\r\nmemset(req, 0, sizeof(*req));\r\nreq->timeout = PGID_TIMEOUT;\r\nreq->maxretries = PGID_RETRIES;\r\nreq->lpm = sch->schib.pmcw.pam & sch->opm;\r\nreq->singlepath = 1;\r\nreq->callback = disband_callback;\r\nfn = SPID_FUNC_DISBAND;\r\nif (cdev->private->flags.mpath)\r\nfn |= SPID_FUNC_MULTI_PATH;\r\nspid_build_cp(cdev, fn);\r\nccw_request_start(cdev);\r\n}\r\nstatic void stlck_build_cp(struct ccw_device *cdev, void *buf1, void *buf2)\r\n{\r\nstruct ccw_request *req = &cdev->private->req;\r\nstruct ccw1 *cp = cdev->private->iccws;\r\ncp[0].cmd_code = CCW_CMD_STLCK;\r\ncp[0].cda = (u32) (addr_t) buf1;\r\ncp[0].count = 32;\r\ncp[0].flags = CCW_FLAG_CC;\r\ncp[1].cmd_code = CCW_CMD_RELEASE;\r\ncp[1].cda = (u32) (addr_t) buf2;\r\ncp[1].count = 32;\r\ncp[1].flags = 0;\r\nreq->cp = cp;\r\n}\r\nstatic void stlck_callback(struct ccw_device *cdev, void *data, int rc)\r\n{\r\nstruct stlck_data *sdata = data;\r\nsdata->rc = rc;\r\ncomplete(&sdata->done);\r\n}\r\nstatic void ccw_device_stlck_start(struct ccw_device *cdev, void *data,\r\nvoid *buf1, void *buf2)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct ccw_request *req = &cdev->private->req;\r\nCIO_TRACE_EVENT(4, "stlck");\r\nCIO_HEX_EVENT(4, &cdev->private->dev_id, sizeof(cdev->private->dev_id));\r\nmemset(req, 0, sizeof(*req));\r\nreq->timeout = PGID_TIMEOUT;\r\nreq->maxretries = PGID_RETRIES;\r\nreq->lpm = sch->schib.pmcw.pam & sch->opm;\r\nreq->data = data;\r\nreq->callback = stlck_callback;\r\nstlck_build_cp(cdev, buf1, buf2);\r\nccw_request_start(cdev);\r\n}\r\nint ccw_device_stlck(struct ccw_device *cdev)\r\n{\r\nstruct subchannel *sch = to_subchannel(cdev->dev.parent);\r\nstruct stlck_data data;\r\nu8 *buffer;\r\nint rc;\r\nif (cdev->drv) {\r\nif (!cdev->private->options.force)\r\nreturn -EINVAL;\r\n}\r\nbuffer = kzalloc(64, GFP_DMA | GFP_KERNEL);\r\nif (!buffer)\r\nreturn -ENOMEM;\r\ninit_completion(&data.done);\r\ndata.rc = -EIO;\r\nspin_lock_irq(sch->lock);\r\nrc = cio_enable_subchannel(sch, (u32) (addr_t) sch);\r\nif (rc)\r\ngoto out_unlock;\r\ncdev->private->state = DEV_STATE_STEAL_LOCK;\r\nccw_device_stlck_start(cdev, &data, &buffer[0], &buffer[32]);\r\nspin_unlock_irq(sch->lock);\r\nif (wait_for_completion_interruptible(&data.done)) {\r\nspin_lock_irq(sch->lock);\r\nccw_request_cancel(cdev);\r\nspin_unlock_irq(sch->lock);\r\nwait_for_completion(&data.done);\r\n}\r\nrc = data.rc;\r\nspin_lock_irq(sch->lock);\r\ncio_disable_subchannel(sch);\r\ncdev->private->state = DEV_STATE_BOXED;\r\nout_unlock:\r\nspin_unlock_irq(sch->lock);\r\nkfree(buffer);\r\nreturn rc;\r\n}
