static void pie_params_init(struct pie_params *params)\r\n{\r\nparams->alpha = 2;\r\nparams->beta = 20;\r\nparams->tupdate = usecs_to_jiffies(30 * USEC_PER_MSEC);\r\nparams->limit = 1000;\r\nparams->target = PSCHED_NS2TICKS(20 * NSEC_PER_MSEC);\r\nparams->ecn = false;\r\nparams->bytemode = false;\r\n}\r\nstatic void pie_vars_init(struct pie_vars *vars)\r\n{\r\nvars->dq_count = DQCOUNT_INVALID;\r\nvars->avg_dq_rate = 0;\r\nvars->burst_time = PSCHED_NS2TICKS(100 * NSEC_PER_MSEC);\r\n}\r\nstatic bool drop_early(struct Qdisc *sch, u32 packet_size)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nu32 rnd;\r\nu32 local_prob = q->vars.prob;\r\nu32 mtu = psched_mtu(qdisc_dev(sch));\r\nif (q->vars.burst_time > 0)\r\nreturn false;\r\nif ((q->vars.qdelay < q->params.target / 2)\r\n&& (q->vars.prob < MAX_PROB / 5))\r\nreturn false;\r\nif (sch->qstats.backlog < 2 * mtu)\r\nreturn false;\r\nif (q->params.bytemode && packet_size <= mtu)\r\nlocal_prob = (local_prob / mtu) * packet_size;\r\nelse\r\nlocal_prob = q->vars.prob;\r\nrnd = prandom_u32();\r\nif (rnd < local_prob)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic int pie_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch,\r\nstruct sk_buff **to_free)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nbool enqueue = false;\r\nif (unlikely(qdisc_qlen(sch) >= sch->limit)) {\r\nq->stats.overlimit++;\r\ngoto out;\r\n}\r\nif (!drop_early(sch, skb->len)) {\r\nenqueue = true;\r\n} else if (q->params.ecn && (q->vars.prob <= MAX_PROB / 10) &&\r\nINET_ECN_set_ce(skb)) {\r\nq->stats.ecn_mark++;\r\nenqueue = true;\r\n}\r\nif (enqueue) {\r\nq->stats.packets_in++;\r\nif (qdisc_qlen(sch) > q->stats.maxq)\r\nq->stats.maxq = qdisc_qlen(sch);\r\nreturn qdisc_enqueue_tail(skb, sch);\r\n}\r\nout:\r\nq->stats.dropped++;\r\nreturn qdisc_drop(skb, sch, to_free);\r\n}\r\nstatic int pie_change(struct Qdisc *sch, struct nlattr *opt)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nstruct nlattr *tb[TCA_PIE_MAX + 1];\r\nunsigned int qlen, dropped = 0;\r\nint err;\r\nif (!opt)\r\nreturn -EINVAL;\r\nerr = nla_parse_nested(tb, TCA_PIE_MAX, opt, pie_policy);\r\nif (err < 0)\r\nreturn err;\r\nsch_tree_lock(sch);\r\nif (tb[TCA_PIE_TARGET]) {\r\nu32 target = nla_get_u32(tb[TCA_PIE_TARGET]);\r\nq->params.target = PSCHED_NS2TICKS((u64)target * NSEC_PER_USEC);\r\n}\r\nif (tb[TCA_PIE_TUPDATE])\r\nq->params.tupdate = usecs_to_jiffies(nla_get_u32(tb[TCA_PIE_TUPDATE]));\r\nif (tb[TCA_PIE_LIMIT]) {\r\nu32 limit = nla_get_u32(tb[TCA_PIE_LIMIT]);\r\nq->params.limit = limit;\r\nsch->limit = limit;\r\n}\r\nif (tb[TCA_PIE_ALPHA])\r\nq->params.alpha = nla_get_u32(tb[TCA_PIE_ALPHA]);\r\nif (tb[TCA_PIE_BETA])\r\nq->params.beta = nla_get_u32(tb[TCA_PIE_BETA]);\r\nif (tb[TCA_PIE_ECN])\r\nq->params.ecn = nla_get_u32(tb[TCA_PIE_ECN]);\r\nif (tb[TCA_PIE_BYTEMODE])\r\nq->params.bytemode = nla_get_u32(tb[TCA_PIE_BYTEMODE]);\r\nqlen = sch->q.qlen;\r\nwhile (sch->q.qlen > sch->limit) {\r\nstruct sk_buff *skb = __qdisc_dequeue_head(&sch->q);\r\ndropped += qdisc_pkt_len(skb);\r\nqdisc_qstats_backlog_dec(sch, skb);\r\nrtnl_qdisc_drop(skb, sch);\r\n}\r\nqdisc_tree_reduce_backlog(sch, qlen - sch->q.qlen, dropped);\r\nsch_tree_unlock(sch);\r\nreturn 0;\r\n}\r\nstatic void pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nint qlen = sch->qstats.backlog;\r\nif (qlen >= QUEUE_THRESHOLD && q->vars.dq_count == DQCOUNT_INVALID) {\r\nq->vars.dq_tstamp = psched_get_time();\r\nq->vars.dq_count = 0;\r\n}\r\nif (q->vars.dq_count != DQCOUNT_INVALID) {\r\nq->vars.dq_count += skb->len;\r\nif (q->vars.dq_count >= QUEUE_THRESHOLD) {\r\npsched_time_t now = psched_get_time();\r\nu32 dtime = now - q->vars.dq_tstamp;\r\nu32 count = q->vars.dq_count << PIE_SCALE;\r\nif (dtime == 0)\r\nreturn;\r\ncount = count / dtime;\r\nif (q->vars.avg_dq_rate == 0)\r\nq->vars.avg_dq_rate = count;\r\nelse\r\nq->vars.avg_dq_rate =\r\n(q->vars.avg_dq_rate -\r\n(q->vars.avg_dq_rate >> 3)) + (count >> 3);\r\nif (qlen < QUEUE_THRESHOLD)\r\nq->vars.dq_count = DQCOUNT_INVALID;\r\nelse {\r\nq->vars.dq_count = 0;\r\nq->vars.dq_tstamp = psched_get_time();\r\n}\r\nif (q->vars.burst_time > 0) {\r\nif (q->vars.burst_time > dtime)\r\nq->vars.burst_time -= dtime;\r\nelse\r\nq->vars.burst_time = 0;\r\n}\r\n}\r\n}\r\n}\r\nstatic void calculate_probability(struct Qdisc *sch)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nu32 qlen = sch->qstats.backlog;\r\npsched_time_t qdelay = 0;\r\npsched_time_t qdelay_old = q->vars.qdelay;\r\ns32 delta = 0;\r\nu32 oldprob;\r\nu32 alpha, beta;\r\nbool update_prob = true;\r\nq->vars.qdelay_old = q->vars.qdelay;\r\nif (q->vars.avg_dq_rate > 0)\r\nqdelay = (qlen << PIE_SCALE) / q->vars.avg_dq_rate;\r\nelse\r\nqdelay = 0;\r\nif (qdelay == 0 && qlen != 0)\r\nupdate_prob = false;\r\nif (q->vars.prob < MAX_PROB / 100) {\r\nalpha =\r\n(q->params.alpha * (MAX_PROB / PSCHED_TICKS_PER_SEC)) >> 7;\r\nbeta =\r\n(q->params.beta * (MAX_PROB / PSCHED_TICKS_PER_SEC)) >> 7;\r\n} else if (q->vars.prob < MAX_PROB / 10) {\r\nalpha =\r\n(q->params.alpha * (MAX_PROB / PSCHED_TICKS_PER_SEC)) >> 5;\r\nbeta =\r\n(q->params.beta * (MAX_PROB / PSCHED_TICKS_PER_SEC)) >> 5;\r\n} else {\r\nalpha =\r\n(q->params.alpha * (MAX_PROB / PSCHED_TICKS_PER_SEC)) >> 4;\r\nbeta =\r\n(q->params.beta * (MAX_PROB / PSCHED_TICKS_PER_SEC)) >> 4;\r\n}\r\ndelta += alpha * ((qdelay - q->params.target));\r\ndelta += beta * ((qdelay - qdelay_old));\r\noldprob = q->vars.prob;\r\nif (delta > (s32) (MAX_PROB / (100 / 2)) &&\r\nq->vars.prob >= MAX_PROB / 10)\r\ndelta = (MAX_PROB / 100) * 2;\r\nif (qdelay > (PSCHED_NS2TICKS(250 * NSEC_PER_MSEC)))\r\ndelta += MAX_PROB / (100 / 2);\r\nq->vars.prob += delta;\r\nif (delta > 0) {\r\nif (q->vars.prob < oldprob) {\r\nq->vars.prob = MAX_PROB;\r\nupdate_prob = false;\r\n}\r\n} else {\r\nif (q->vars.prob > oldprob)\r\nq->vars.prob = 0;\r\n}\r\nif ((qdelay == 0) && (qdelay_old == 0) && update_prob)\r\nq->vars.prob = (q->vars.prob * 98) / 100;\r\nq->vars.qdelay = qdelay;\r\nq->vars.qlen_old = qlen;\r\nif ((q->vars.qdelay < q->params.target / 2) &&\r\n(q->vars.qdelay_old < q->params.target / 2) &&\r\n(q->vars.prob == 0) &&\r\n(q->vars.avg_dq_rate > 0))\r\npie_vars_init(&q->vars);\r\n}\r\nstatic void pie_timer(unsigned long arg)\r\n{\r\nstruct Qdisc *sch = (struct Qdisc *)arg;\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nspinlock_t *root_lock = qdisc_lock(qdisc_root_sleeping(sch));\r\nspin_lock(root_lock);\r\ncalculate_probability(sch);\r\nif (q->params.tupdate)\r\nmod_timer(&q->adapt_timer, jiffies + q->params.tupdate);\r\nspin_unlock(root_lock);\r\n}\r\nstatic int pie_init(struct Qdisc *sch, struct nlattr *opt)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\npie_params_init(&q->params);\r\npie_vars_init(&q->vars);\r\nsch->limit = q->params.limit;\r\nsetup_timer(&q->adapt_timer, pie_timer, (unsigned long)sch);\r\nif (opt) {\r\nint err = pie_change(sch, opt);\r\nif (err)\r\nreturn err;\r\n}\r\nmod_timer(&q->adapt_timer, jiffies + HZ / 2);\r\nreturn 0;\r\n}\r\nstatic int pie_dump(struct Qdisc *sch, struct sk_buff *skb)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nstruct nlattr *opts;\r\nopts = nla_nest_start(skb, TCA_OPTIONS);\r\nif (opts == NULL)\r\ngoto nla_put_failure;\r\nif (nla_put_u32(skb, TCA_PIE_TARGET,\r\n((u32) PSCHED_TICKS2NS(q->params.target)) /\r\nNSEC_PER_USEC) ||\r\nnla_put_u32(skb, TCA_PIE_LIMIT, sch->limit) ||\r\nnla_put_u32(skb, TCA_PIE_TUPDATE, jiffies_to_usecs(q->params.tupdate)) ||\r\nnla_put_u32(skb, TCA_PIE_ALPHA, q->params.alpha) ||\r\nnla_put_u32(skb, TCA_PIE_BETA, q->params.beta) ||\r\nnla_put_u32(skb, TCA_PIE_ECN, q->params.ecn) ||\r\nnla_put_u32(skb, TCA_PIE_BYTEMODE, q->params.bytemode))\r\ngoto nla_put_failure;\r\nreturn nla_nest_end(skb, opts);\r\nnla_put_failure:\r\nnla_nest_cancel(skb, opts);\r\nreturn -1;\r\n}\r\nstatic int pie_dump_stats(struct Qdisc *sch, struct gnet_dump *d)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nstruct tc_pie_xstats st = {\r\n.prob = q->vars.prob,\r\n.delay = ((u32) PSCHED_TICKS2NS(q->vars.qdelay)) /\r\nNSEC_PER_USEC,\r\n.avg_dq_rate = q->vars.avg_dq_rate *\r\n(PSCHED_TICKS_PER_SEC) >> PIE_SCALE,\r\n.packets_in = q->stats.packets_in,\r\n.overlimit = q->stats.overlimit,\r\n.maxq = q->stats.maxq,\r\n.dropped = q->stats.dropped,\r\n.ecn_mark = q->stats.ecn_mark,\r\n};\r\nreturn gnet_stats_copy_app(d, &st, sizeof(st));\r\n}\r\nstatic struct sk_buff *pie_qdisc_dequeue(struct Qdisc *sch)\r\n{\r\nstruct sk_buff *skb;\r\nskb = qdisc_dequeue_head(sch);\r\nif (!skb)\r\nreturn NULL;\r\npie_process_dequeue(sch, skb);\r\nreturn skb;\r\n}\r\nstatic void pie_reset(struct Qdisc *sch)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nqdisc_reset_queue(sch);\r\npie_vars_init(&q->vars);\r\n}\r\nstatic void pie_destroy(struct Qdisc *sch)\r\n{\r\nstruct pie_sched_data *q = qdisc_priv(sch);\r\nq->params.tupdate = 0;\r\ndel_timer_sync(&q->adapt_timer);\r\n}\r\nstatic int __init pie_module_init(void)\r\n{\r\nreturn register_qdisc(&pie_qdisc_ops);\r\n}\r\nstatic void __exit pie_module_exit(void)\r\n{\r\nunregister_qdisc(&pie_qdisc_ops);\r\n}
