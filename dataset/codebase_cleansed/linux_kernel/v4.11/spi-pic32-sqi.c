static inline void pic32_setbits(void __iomem *reg, u32 set)\r\n{\r\nwritel(readl(reg) | set, reg);\r\n}\r\nstatic inline void pic32_clrbits(void __iomem *reg, u32 clr)\r\n{\r\nwritel(readl(reg) & ~clr, reg);\r\n}\r\nstatic int pic32_sqi_set_clk_rate(struct pic32_sqi *sqi, u32 sck)\r\n{\r\nu32 val, div;\r\ndiv = clk_get_rate(sqi->base_clk) / (2 * sck);\r\ndiv &= PESQI_CLKDIV;\r\nval = readl(sqi->regs + PESQI_CLK_CTRL_REG);\r\nval &= ~(PESQI_CLK_STABLE | (PESQI_CLKDIV << PESQI_CLKDIV_SHIFT));\r\nval |= div << PESQI_CLKDIV_SHIFT;\r\nwritel(val, sqi->regs + PESQI_CLK_CTRL_REG);\r\nreturn readl_poll_timeout(sqi->regs + PESQI_CLK_CTRL_REG, val,\r\nval & PESQI_CLK_STABLE, 1, 5000);\r\n}\r\nstatic inline void pic32_sqi_enable_int(struct pic32_sqi *sqi)\r\n{\r\nu32 mask = PESQI_DMAERR | PESQI_BDDONE | PESQI_PKTCOMP;\r\nwritel(mask, sqi->regs + PESQI_INT_ENABLE_REG);\r\nwritel(mask, sqi->regs + PESQI_INT_SIGEN_REG);\r\n}\r\nstatic inline void pic32_sqi_disable_int(struct pic32_sqi *sqi)\r\n{\r\nwritel(0, sqi->regs + PESQI_INT_ENABLE_REG);\r\nwritel(0, sqi->regs + PESQI_INT_SIGEN_REG);\r\n}\r\nstatic irqreturn_t pic32_sqi_isr(int irq, void *dev_id)\r\n{\r\nstruct pic32_sqi *sqi = dev_id;\r\nu32 enable, status;\r\nenable = readl(sqi->regs + PESQI_INT_ENABLE_REG);\r\nstatus = readl(sqi->regs + PESQI_INT_STAT_REG);\r\nif (!status)\r\nreturn IRQ_NONE;\r\nif (status & PESQI_DMAERR) {\r\nenable = 0;\r\ngoto irq_done;\r\n}\r\nif (status & PESQI_TXTHR)\r\nenable &= ~(PESQI_TXTHR | PESQI_TXFULL | PESQI_TXEMPTY);\r\nif (status & PESQI_RXTHR)\r\nenable &= ~(PESQI_RXTHR | PESQI_RXFULL | PESQI_RXEMPTY);\r\nif (status & PESQI_BDDONE)\r\nenable &= ~PESQI_BDDONE;\r\nif (status & PESQI_PKTCOMP) {\r\nenable = 0;\r\ncomplete(&sqi->xfer_done);\r\n}\r\nirq_done:\r\nwritel(enable, sqi->regs + PESQI_INT_ENABLE_REG);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic struct ring_desc *ring_desc_get(struct pic32_sqi *sqi)\r\n{\r\nstruct ring_desc *rdesc;\r\nif (list_empty(&sqi->bd_list_free))\r\nreturn NULL;\r\nrdesc = list_first_entry(&sqi->bd_list_free, struct ring_desc, list);\r\nlist_move_tail(&rdesc->list, &sqi->bd_list_used);\r\nreturn rdesc;\r\n}\r\nstatic void ring_desc_put(struct pic32_sqi *sqi, struct ring_desc *rdesc)\r\n{\r\nlist_move(&rdesc->list, &sqi->bd_list_free);\r\n}\r\nstatic int pic32_sqi_one_transfer(struct pic32_sqi *sqi,\r\nstruct spi_message *mesg,\r\nstruct spi_transfer *xfer)\r\n{\r\nstruct spi_device *spi = mesg->spi;\r\nstruct scatterlist *sg, *sgl;\r\nstruct ring_desc *rdesc;\r\nstruct buf_desc *bd;\r\nint nents, i;\r\nu32 bd_ctrl;\r\nu32 nbits;\r\nbd_ctrl = spi->chip_select << BD_DEVSEL_SHIFT;\r\nif (xfer->rx_buf) {\r\nbd_ctrl |= BD_DATA_RECV;\r\nnbits = xfer->rx_nbits;\r\nsgl = xfer->rx_sg.sgl;\r\nnents = xfer->rx_sg.nents;\r\n} else {\r\nnbits = xfer->tx_nbits;\r\nsgl = xfer->tx_sg.sgl;\r\nnents = xfer->tx_sg.nents;\r\n}\r\nif (nbits & SPI_NBITS_QUAD)\r\nbd_ctrl |= BD_QUAD;\r\nelse if (nbits & SPI_NBITS_DUAL)\r\nbd_ctrl |= BD_DUAL;\r\nif (spi->mode & SPI_LSB_FIRST)\r\nbd_ctrl |= BD_LSBF;\r\nbd_ctrl |= BD_EN;\r\nfor_each_sg(sgl, sg, nents, i) {\r\nrdesc = ring_desc_get(sqi);\r\nif (!rdesc)\r\nbreak;\r\nbd = rdesc->bd;\r\nrdesc->xfer_len = sg_dma_len(sg);\r\nbd->bd_ctrl = bd_ctrl;\r\nbd->bd_ctrl |= rdesc->xfer_len;\r\nbd->bd_status = 0;\r\nbd->bd_addr = sg->dma_address;\r\n}\r\nreturn 0;\r\n}\r\nstatic int pic32_sqi_prepare_hardware(struct spi_master *master)\r\n{\r\nstruct pic32_sqi *sqi = spi_master_get_devdata(master);\r\npic32_setbits(sqi->regs + PESQI_CONF_REG, PESQI_EN);\r\npic32_setbits(sqi->regs + PESQI_CLK_CTRL_REG, PESQI_CLK_EN);\r\nreturn 0;\r\n}\r\nstatic bool pic32_sqi_can_dma(struct spi_master *master,\r\nstruct spi_device *spi,\r\nstruct spi_transfer *x)\r\n{\r\nreturn true;\r\n}\r\nstatic int pic32_sqi_one_message(struct spi_master *master,\r\nstruct spi_message *msg)\r\n{\r\nstruct spi_device *spi = msg->spi;\r\nstruct ring_desc *rdesc, *next;\r\nstruct spi_transfer *xfer;\r\nstruct pic32_sqi *sqi;\r\nint ret = 0, mode;\r\nunsigned long timeout;\r\nu32 val;\r\nsqi = spi_master_get_devdata(master);\r\nreinit_completion(&sqi->xfer_done);\r\nmsg->actual_length = 0;\r\nif (sqi->cur_spi != spi) {\r\nif (sqi->cur_speed != spi->max_speed_hz) {\r\nsqi->cur_speed = spi->max_speed_hz;\r\nret = pic32_sqi_set_clk_rate(sqi, spi->max_speed_hz);\r\nif (ret)\r\ndev_warn(&spi->dev, "set_clk, %d\n", ret);\r\n}\r\nmode = spi->mode & (SPI_MODE_3 | SPI_LSB_FIRST);\r\nif (sqi->cur_mode != mode) {\r\nval = readl(sqi->regs + PESQI_CONF_REG);\r\nval &= ~(PESQI_CPOL | PESQI_CPHA | PESQI_LSBF);\r\nif (mode & SPI_CPOL)\r\nval |= PESQI_CPOL;\r\nif (mode & SPI_LSB_FIRST)\r\nval |= PESQI_LSBF;\r\nval |= PESQI_CPHA;\r\nwritel(val, sqi->regs + PESQI_CONF_REG);\r\nsqi->cur_mode = mode;\r\n}\r\nsqi->cur_spi = spi;\r\n}\r\nlist_for_each_entry(xfer, &msg->transfers, transfer_list) {\r\nret = pic32_sqi_one_transfer(sqi, msg, xfer);\r\nif (ret) {\r\ndev_err(&spi->dev, "xfer %p err\n", xfer);\r\ngoto xfer_out;\r\n}\r\n}\r\nrdesc = list_last_entry(&sqi->bd_list_used, struct ring_desc, list);\r\nrdesc->bd->bd_ctrl |= BD_LAST | BD_CS_DEASSERT |\r\nBD_LIFM | BD_PKT_INT_EN;\r\nrdesc = list_first_entry(&sqi->bd_list_used, struct ring_desc, list);\r\nwritel(rdesc->bd_dma, sqi->regs + PESQI_BD_BASE_ADDR_REG);\r\npic32_sqi_enable_int(sqi);\r\nval = PESQI_DMA_EN | PESQI_POLL_EN | PESQI_BDP_START;\r\nwritel(val, sqi->regs + PESQI_BD_CTRL_REG);\r\ntimeout = wait_for_completion_timeout(&sqi->xfer_done, 5 * HZ);\r\nif (timeout == 0) {\r\ndev_err(&sqi->master->dev, "wait timedout/interrupted\n");\r\nret = -ETIMEDOUT;\r\nmsg->status = ret;\r\n} else {\r\nmsg->status = 0;\r\nret = 0;\r\n}\r\nwritel(0, sqi->regs + PESQI_BD_CTRL_REG);\r\npic32_sqi_disable_int(sqi);\r\nxfer_out:\r\nlist_for_each_entry_safe_reverse(rdesc, next,\r\n&sqi->bd_list_used, list) {\r\nmsg->actual_length += rdesc->xfer_len;\r\nring_desc_put(sqi, rdesc);\r\n}\r\nspi_finalize_current_message(spi->master);\r\nreturn ret;\r\n}\r\nstatic int pic32_sqi_unprepare_hardware(struct spi_master *master)\r\n{\r\nstruct pic32_sqi *sqi = spi_master_get_devdata(master);\r\npic32_clrbits(sqi->regs + PESQI_CLK_CTRL_REG, PESQI_CLK_EN);\r\npic32_clrbits(sqi->regs + PESQI_CONF_REG, PESQI_EN);\r\nreturn 0;\r\n}\r\nstatic int ring_desc_ring_alloc(struct pic32_sqi *sqi)\r\n{\r\nstruct ring_desc *rdesc;\r\nstruct buf_desc *bd;\r\nint i;\r\nsqi->bd = dma_zalloc_coherent(&sqi->master->dev,\r\nsizeof(*bd) * PESQI_BD_COUNT,\r\n&sqi->bd_dma, GFP_DMA32);\r\nif (!sqi->bd) {\r\ndev_err(&sqi->master->dev, "failed allocating dma buffer\n");\r\nreturn -ENOMEM;\r\n}\r\nsqi->ring = kcalloc(PESQI_BD_COUNT, sizeof(*rdesc), GFP_KERNEL);\r\nif (!sqi->ring) {\r\ndma_free_coherent(&sqi->master->dev,\r\nsizeof(*bd) * PESQI_BD_COUNT,\r\nsqi->bd, sqi->bd_dma);\r\nreturn -ENOMEM;\r\n}\r\nbd = (struct buf_desc *)sqi->bd;\r\nINIT_LIST_HEAD(&sqi->bd_list_free);\r\nINIT_LIST_HEAD(&sqi->bd_list_used);\r\nfor (i = 0, rdesc = sqi->ring; i < PESQI_BD_COUNT; i++, rdesc++) {\r\nINIT_LIST_HEAD(&rdesc->list);\r\nrdesc->bd = &bd[i];\r\nrdesc->bd_dma = sqi->bd_dma + (void *)&bd[i] - (void *)bd;\r\nlist_add_tail(&rdesc->list, &sqi->bd_list_free);\r\n}\r\nfor (i = 0, rdesc = sqi->ring; i < PESQI_BD_COUNT - 1; i++)\r\nbd[i].bd_nextp = rdesc[i + 1].bd_dma;\r\nbd[PESQI_BD_COUNT - 1].bd_nextp = 0;\r\nreturn 0;\r\n}\r\nstatic void ring_desc_ring_free(struct pic32_sqi *sqi)\r\n{\r\ndma_free_coherent(&sqi->master->dev,\r\nsizeof(struct buf_desc) * PESQI_BD_COUNT,\r\nsqi->bd, sqi->bd_dma);\r\nkfree(sqi->ring);\r\n}\r\nstatic void pic32_sqi_hw_init(struct pic32_sqi *sqi)\r\n{\r\nunsigned long flags;\r\nu32 val;\r\nlocal_irq_save(flags);\r\nwritel(PESQI_SOFT_RESET, sqi->regs + PESQI_CONF_REG);\r\nreadl_poll_timeout_atomic(sqi->regs + PESQI_CONF_REG, val,\r\n!(val & PESQI_SOFT_RESET), 1, 5000);\r\npic32_sqi_disable_int(sqi);\r\nlocal_irq_restore(flags);\r\nval = readl(sqi->regs + PESQI_CMD_THRES_REG);\r\nval &= ~(PESQI_TXTHR_MASK << PESQI_TXTHR_SHIFT);\r\nval &= ~(PESQI_RXTHR_MASK << PESQI_RXTHR_SHIFT);\r\nval |= (1U << PESQI_TXTHR_SHIFT) | (1U << PESQI_RXTHR_SHIFT);\r\nwritel(val, sqi->regs + PESQI_CMD_THRES_REG);\r\nval = readl(sqi->regs + PESQI_INT_THRES_REG);\r\nval &= ~(PESQI_TXTHR_MASK << PESQI_TXTHR_SHIFT);\r\nval &= ~(PESQI_RXTHR_MASK << PESQI_RXTHR_SHIFT);\r\nval |= (1U << PESQI_TXTHR_SHIFT) | (1U << PESQI_RXTHR_SHIFT);\r\nwritel(val, sqi->regs + PESQI_INT_THRES_REG);\r\nval = readl(sqi->regs + PESQI_CONF_REG);\r\nval &= ~PESQI_MODE;\r\nval |= PESQI_MODE_DMA << PESQI_MODE_SHIFT;\r\nwritel(val, sqi->regs + PESQI_CONF_REG);\r\nval |= PESQI_QUAD_LANE << PESQI_LANES_SHIFT;\r\nval |= PESQI_BURST_EN;\r\nval |= 3U << PESQI_CSEN_SHIFT;\r\nwritel(val, sqi->regs + PESQI_CONF_REG);\r\nwritel(0, sqi->regs + PESQI_BD_POLL_CTRL_REG);\r\nsqi->cur_speed = 0;\r\nsqi->cur_mode = -1;\r\n}\r\nstatic int pic32_sqi_probe(struct platform_device *pdev)\r\n{\r\nstruct spi_master *master;\r\nstruct pic32_sqi *sqi;\r\nstruct resource *reg;\r\nint ret;\r\nmaster = spi_alloc_master(&pdev->dev, sizeof(*sqi));\r\nif (!master)\r\nreturn -ENOMEM;\r\nsqi = spi_master_get_devdata(master);\r\nsqi->master = master;\r\nreg = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nsqi->regs = devm_ioremap_resource(&pdev->dev, reg);\r\nif (IS_ERR(sqi->regs)) {\r\nret = PTR_ERR(sqi->regs);\r\ngoto err_free_master;\r\n}\r\nsqi->irq = platform_get_irq(pdev, 0);\r\nif (sqi->irq < 0) {\r\ndev_err(&pdev->dev, "no irq found\n");\r\nret = sqi->irq;\r\ngoto err_free_master;\r\n}\r\nsqi->sys_clk = devm_clk_get(&pdev->dev, "reg_ck");\r\nif (IS_ERR(sqi->sys_clk)) {\r\nret = PTR_ERR(sqi->sys_clk);\r\ndev_err(&pdev->dev, "no sys_clk ?\n");\r\ngoto err_free_master;\r\n}\r\nsqi->base_clk = devm_clk_get(&pdev->dev, "spi_ck");\r\nif (IS_ERR(sqi->base_clk)) {\r\nret = PTR_ERR(sqi->base_clk);\r\ndev_err(&pdev->dev, "no base clk ?\n");\r\ngoto err_free_master;\r\n}\r\nret = clk_prepare_enable(sqi->sys_clk);\r\nif (ret) {\r\ndev_err(&pdev->dev, "sys clk enable failed\n");\r\ngoto err_free_master;\r\n}\r\nret = clk_prepare_enable(sqi->base_clk);\r\nif (ret) {\r\ndev_err(&pdev->dev, "base clk enable failed\n");\r\nclk_disable_unprepare(sqi->sys_clk);\r\ngoto err_free_master;\r\n}\r\ninit_completion(&sqi->xfer_done);\r\npic32_sqi_hw_init(sqi);\r\nret = ring_desc_ring_alloc(sqi);\r\nif (ret) {\r\ndev_err(&pdev->dev, "ring alloc failed\n");\r\ngoto err_disable_clk;\r\n}\r\nret = request_irq(sqi->irq, pic32_sqi_isr, 0,\r\ndev_name(&pdev->dev), sqi);\r\nif (ret < 0) {\r\ndev_err(&pdev->dev, "request_irq(%d), failed\n", sqi->irq);\r\ngoto err_free_ring;\r\n}\r\nmaster->num_chipselect = 2;\r\nmaster->max_speed_hz = clk_get_rate(sqi->base_clk);\r\nmaster->dma_alignment = 32;\r\nmaster->max_dma_len = PESQI_BD_BUF_LEN_MAX;\r\nmaster->dev.of_node = of_node_get(pdev->dev.of_node);\r\nmaster->mode_bits = SPI_MODE_3 | SPI_MODE_0 | SPI_TX_DUAL |\r\nSPI_RX_DUAL | SPI_TX_QUAD | SPI_RX_QUAD;\r\nmaster->flags = SPI_MASTER_HALF_DUPLEX;\r\nmaster->can_dma = pic32_sqi_can_dma;\r\nmaster->bits_per_word_mask = SPI_BPW_RANGE_MASK(8, 32);\r\nmaster->transfer_one_message = pic32_sqi_one_message;\r\nmaster->prepare_transfer_hardware = pic32_sqi_prepare_hardware;\r\nmaster->unprepare_transfer_hardware = pic32_sqi_unprepare_hardware;\r\nret = devm_spi_register_master(&pdev->dev, master);\r\nif (ret) {\r\ndev_err(&master->dev, "failed registering spi master\n");\r\nfree_irq(sqi->irq, sqi);\r\ngoto err_free_ring;\r\n}\r\nplatform_set_drvdata(pdev, sqi);\r\nreturn 0;\r\nerr_free_ring:\r\nring_desc_ring_free(sqi);\r\nerr_disable_clk:\r\nclk_disable_unprepare(sqi->base_clk);\r\nclk_disable_unprepare(sqi->sys_clk);\r\nerr_free_master:\r\nspi_master_put(master);\r\nreturn ret;\r\n}\r\nstatic int pic32_sqi_remove(struct platform_device *pdev)\r\n{\r\nstruct pic32_sqi *sqi = platform_get_drvdata(pdev);\r\nfree_irq(sqi->irq, sqi);\r\nring_desc_ring_free(sqi);\r\nclk_disable_unprepare(sqi->base_clk);\r\nclk_disable_unprepare(sqi->sys_clk);\r\nreturn 0;\r\n}
