static void dce_virtual_vblank_wait(struct amdgpu_device *adev, int crtc)\r\n{\r\nreturn;\r\n}\r\nstatic u32 dce_virtual_vblank_get_counter(struct amdgpu_device *adev, int crtc)\r\n{\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_page_flip(struct amdgpu_device *adev,\r\nint crtc_id, u64 crtc_base, bool async)\r\n{\r\nreturn;\r\n}\r\nstatic int dce_virtual_crtc_get_scanoutpos(struct amdgpu_device *adev, int crtc,\r\nu32 *vbl, u32 *position)\r\n{\r\n*vbl = 0;\r\n*position = 0;\r\nreturn -EINVAL;\r\n}\r\nstatic bool dce_virtual_hpd_sense(struct amdgpu_device *adev,\r\nenum amdgpu_hpd_id hpd)\r\n{\r\nreturn true;\r\n}\r\nstatic void dce_virtual_hpd_set_polarity(struct amdgpu_device *adev,\r\nenum amdgpu_hpd_id hpd)\r\n{\r\nreturn;\r\n}\r\nstatic u32 dce_virtual_hpd_get_gpio_reg(struct amdgpu_device *adev)\r\n{\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_stop_mc_access(struct amdgpu_device *adev,\r\nstruct amdgpu_mode_mc_save *save)\r\n{\r\nswitch (adev->asic_type) {\r\n#ifdef CONFIG_DRM_AMDGPU_SI\r\ncase CHIP_TAHITI:\r\ncase CHIP_PITCAIRN:\r\ncase CHIP_VERDE:\r\ncase CHIP_OLAND:\r\ndce_v6_0_disable_dce(adev);\r\nbreak;\r\n#endif\r\n#ifdef CONFIG_DRM_AMDGPU_CIK\r\ncase CHIP_BONAIRE:\r\ncase CHIP_HAWAII:\r\ncase CHIP_KAVERI:\r\ncase CHIP_KABINI:\r\ncase CHIP_MULLINS:\r\ndce_v8_0_disable_dce(adev);\r\nbreak;\r\n#endif\r\ncase CHIP_FIJI:\r\ncase CHIP_TONGA:\r\ndce_v10_0_disable_dce(adev);\r\nbreak;\r\ncase CHIP_CARRIZO:\r\ncase CHIP_STONEY:\r\ncase CHIP_POLARIS11:\r\ncase CHIP_POLARIS10:\r\ndce_v11_0_disable_dce(adev);\r\nbreak;\r\ncase CHIP_TOPAZ:\r\n#ifdef CONFIG_DRM_AMDGPU_SI\r\ncase CHIP_HAINAN:\r\n#endif\r\nreturn;\r\ndefault:\r\nDRM_ERROR("Virtual display unsupported ASIC type: 0x%X\n", adev->asic_type);\r\n}\r\nreturn;\r\n}\r\nstatic void dce_virtual_resume_mc_access(struct amdgpu_device *adev,\r\nstruct amdgpu_mode_mc_save *save)\r\n{\r\nreturn;\r\n}\r\nstatic void dce_virtual_set_vga_render_state(struct amdgpu_device *adev,\r\nbool render)\r\n{\r\nreturn;\r\n}\r\nstatic void dce_virtual_bandwidth_update(struct amdgpu_device *adev)\r\n{\r\nreturn;\r\n}\r\nstatic int dce_virtual_crtc_gamma_set(struct drm_crtc *crtc, u16 *red,\r\nu16 *green, u16 *blue, uint32_t size)\r\n{\r\nstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\r\nint i;\r\nfor (i = 0; i < size; i++) {\r\namdgpu_crtc->lut_r[i] = red[i] >> 6;\r\namdgpu_crtc->lut_g[i] = green[i] >> 6;\r\namdgpu_crtc->lut_b[i] = blue[i] >> 6;\r\n}\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_crtc_destroy(struct drm_crtc *crtc)\r\n{\r\nstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\r\ndrm_crtc_cleanup(crtc);\r\nkfree(amdgpu_crtc);\r\n}\r\nstatic void dce_virtual_crtc_dpms(struct drm_crtc *crtc, int mode)\r\n{\r\nstruct drm_device *dev = crtc->dev;\r\nstruct amdgpu_device *adev = dev->dev_private;\r\nstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\r\nunsigned type;\r\nswitch (mode) {\r\ncase DRM_MODE_DPMS_ON:\r\namdgpu_crtc->enabled = true;\r\ntype = amdgpu_crtc_idx_to_irq_type(adev, amdgpu_crtc->crtc_id);\r\namdgpu_irq_update(adev, &adev->crtc_irq, type);\r\ndrm_crtc_vblank_on(crtc);\r\nbreak;\r\ncase DRM_MODE_DPMS_STANDBY:\r\ncase DRM_MODE_DPMS_SUSPEND:\r\ncase DRM_MODE_DPMS_OFF:\r\ndrm_crtc_vblank_off(crtc);\r\namdgpu_crtc->enabled = false;\r\nbreak;\r\n}\r\n}\r\nstatic void dce_virtual_crtc_prepare(struct drm_crtc *crtc)\r\n{\r\ndce_virtual_crtc_dpms(crtc, DRM_MODE_DPMS_OFF);\r\n}\r\nstatic void dce_virtual_crtc_commit(struct drm_crtc *crtc)\r\n{\r\ndce_virtual_crtc_dpms(crtc, DRM_MODE_DPMS_ON);\r\n}\r\nstatic void dce_virtual_crtc_disable(struct drm_crtc *crtc)\r\n{\r\nstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\r\ndce_virtual_crtc_dpms(crtc, DRM_MODE_DPMS_OFF);\r\nif (crtc->primary->fb) {\r\nint r;\r\nstruct amdgpu_framebuffer *amdgpu_fb;\r\nstruct amdgpu_bo *abo;\r\namdgpu_fb = to_amdgpu_framebuffer(crtc->primary->fb);\r\nabo = gem_to_amdgpu_bo(amdgpu_fb->obj);\r\nr = amdgpu_bo_reserve(abo, false);\r\nif (unlikely(r))\r\nDRM_ERROR("failed to reserve abo before unpin\n");\r\nelse {\r\namdgpu_bo_unpin(abo);\r\namdgpu_bo_unreserve(abo);\r\n}\r\n}\r\namdgpu_crtc->pll_id = ATOM_PPLL_INVALID;\r\namdgpu_crtc->encoder = NULL;\r\namdgpu_crtc->connector = NULL;\r\n}\r\nstatic int dce_virtual_crtc_mode_set(struct drm_crtc *crtc,\r\nstruct drm_display_mode *mode,\r\nstruct drm_display_mode *adjusted_mode,\r\nint x, int y, struct drm_framebuffer *old_fb)\r\n{\r\nstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\r\namdgpu_crtc->hw_mode = *adjusted_mode;\r\nreturn 0;\r\n}\r\nstatic bool dce_virtual_crtc_mode_fixup(struct drm_crtc *crtc,\r\nconst struct drm_display_mode *mode,\r\nstruct drm_display_mode *adjusted_mode)\r\n{\r\nreturn true;\r\n}\r\nstatic int dce_virtual_crtc_set_base(struct drm_crtc *crtc, int x, int y,\r\nstruct drm_framebuffer *old_fb)\r\n{\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_crtc_load_lut(struct drm_crtc *crtc)\r\n{\r\nreturn;\r\n}\r\nstatic int dce_virtual_crtc_set_base_atomic(struct drm_crtc *crtc,\r\nstruct drm_framebuffer *fb,\r\nint x, int y, enum mode_set_atomic state)\r\n{\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_crtc_init(struct amdgpu_device *adev, int index)\r\n{\r\nstruct amdgpu_crtc *amdgpu_crtc;\r\nint i;\r\namdgpu_crtc = kzalloc(sizeof(struct amdgpu_crtc) +\r\n(AMDGPUFB_CONN_LIMIT * sizeof(struct drm_connector *)), GFP_KERNEL);\r\nif (amdgpu_crtc == NULL)\r\nreturn -ENOMEM;\r\ndrm_crtc_init(adev->ddev, &amdgpu_crtc->base, &dce_virtual_crtc_funcs);\r\ndrm_mode_crtc_set_gamma_size(&amdgpu_crtc->base, 256);\r\namdgpu_crtc->crtc_id = index;\r\nadev->mode_info.crtcs[index] = amdgpu_crtc;\r\nfor (i = 0; i < 256; i++) {\r\namdgpu_crtc->lut_r[i] = i << 2;\r\namdgpu_crtc->lut_g[i] = i << 2;\r\namdgpu_crtc->lut_b[i] = i << 2;\r\n}\r\namdgpu_crtc->pll_id = ATOM_PPLL_INVALID;\r\namdgpu_crtc->encoder = NULL;\r\namdgpu_crtc->connector = NULL;\r\namdgpu_crtc->vsync_timer_enabled = AMDGPU_IRQ_STATE_DISABLE;\r\ndrm_crtc_helper_add(&amdgpu_crtc->base, &dce_virtual_crtc_helper_funcs);\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_early_init(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\ndce_virtual_set_display_funcs(adev);\r\ndce_virtual_set_irq_funcs(adev);\r\nadev->mode_info.num_hpd = 1;\r\nadev->mode_info.num_dig = 1;\r\nreturn 0;\r\n}\r\nstatic struct drm_encoder *\r\ndce_virtual_encoder(struct drm_connector *connector)\r\n{\r\nint enc_id = connector->encoder_ids[0];\r\nstruct drm_encoder *encoder;\r\nint i;\r\nfor (i = 0; i < DRM_CONNECTOR_MAX_ENCODER; i++) {\r\nif (connector->encoder_ids[i] == 0)\r\nbreak;\r\nencoder = drm_encoder_find(connector->dev, connector->encoder_ids[i]);\r\nif (!encoder)\r\ncontinue;\r\nif (encoder->encoder_type == DRM_MODE_ENCODER_VIRTUAL)\r\nreturn encoder;\r\n}\r\nif (enc_id)\r\nreturn drm_encoder_find(connector->dev, enc_id);\r\nreturn NULL;\r\n}\r\nstatic int dce_virtual_get_modes(struct drm_connector *connector)\r\n{\r\nstruct drm_device *dev = connector->dev;\r\nstruct drm_display_mode *mode = NULL;\r\nunsigned i;\r\nstatic const struct mode_size {\r\nint w;\r\nint h;\r\n} common_modes[17] = {\r\n{ 640, 480},\r\n{ 720, 480},\r\n{ 800, 600},\r\n{ 848, 480},\r\n{1024, 768},\r\n{1152, 768},\r\n{1280, 720},\r\n{1280, 800},\r\n{1280, 854},\r\n{1280, 960},\r\n{1280, 1024},\r\n{1440, 900},\r\n{1400, 1050},\r\n{1680, 1050},\r\n{1600, 1200},\r\n{1920, 1080},\r\n{1920, 1200}\r\n};\r\nfor (i = 0; i < 17; i++) {\r\nmode = drm_cvt_mode(dev, common_modes[i].w, common_modes[i].h, 60, false, false, false);\r\ndrm_mode_probed_add(connector, mode);\r\n}\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_mode_valid(struct drm_connector *connector,\r\nstruct drm_display_mode *mode)\r\n{\r\nreturn MODE_OK;\r\n}\r\nstatic int\r\ndce_virtual_dpms(struct drm_connector *connector, int mode)\r\n{\r\nreturn 0;\r\n}\r\nstatic int\r\ndce_virtual_set_property(struct drm_connector *connector,\r\nstruct drm_property *property,\r\nuint64_t val)\r\n{\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_destroy(struct drm_connector *connector)\r\n{\r\ndrm_connector_unregister(connector);\r\ndrm_connector_cleanup(connector);\r\nkfree(connector);\r\n}\r\nstatic void dce_virtual_force(struct drm_connector *connector)\r\n{\r\nreturn;\r\n}\r\nstatic int dce_virtual_sw_init(void *handle)\r\n{\r\nint r, i;\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nr = amdgpu_irq_add_id(adev, 229, &adev->crtc_irq);\r\nif (r)\r\nreturn r;\r\nadev->ddev->max_vblank_count = 0;\r\nadev->ddev->mode_config.funcs = &amdgpu_mode_funcs;\r\nadev->ddev->mode_config.max_width = 16384;\r\nadev->ddev->mode_config.max_height = 16384;\r\nadev->ddev->mode_config.preferred_depth = 24;\r\nadev->ddev->mode_config.prefer_shadow = 1;\r\nadev->ddev->mode_config.fb_base = adev->mc.aper_base;\r\nr = amdgpu_modeset_create_props(adev);\r\nif (r)\r\nreturn r;\r\nadev->ddev->mode_config.max_width = 16384;\r\nadev->ddev->mode_config.max_height = 16384;\r\nfor (i = 0; i < adev->mode_info.num_crtc; i++) {\r\nr = dce_virtual_crtc_init(adev, i);\r\nif (r)\r\nreturn r;\r\nr = dce_virtual_connector_encoder_init(adev, i);\r\nif (r)\r\nreturn r;\r\n}\r\ndrm_kms_helper_poll_init(adev->ddev);\r\nadev->mode_info.mode_config_initialized = true;\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_sw_fini(void *handle)\r\n{\r\nstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\r\nkfree(adev->mode_info.bios_hardcoded_edid);\r\ndrm_kms_helper_poll_fini(adev->ddev);\r\ndrm_mode_config_cleanup(adev->ddev);\r\nadev->mode_info.mode_config_initialized = false;\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_hw_init(void *handle)\r\n{\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_hw_fini(void *handle)\r\n{\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_suspend(void *handle)\r\n{\r\nreturn dce_virtual_hw_fini(handle);\r\n}\r\nstatic int dce_virtual_resume(void *handle)\r\n{\r\nreturn dce_virtual_hw_init(handle);\r\n}\r\nstatic bool dce_virtual_is_idle(void *handle)\r\n{\r\nreturn true;\r\n}\r\nstatic int dce_virtual_wait_for_idle(void *handle)\r\n{\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_soft_reset(void *handle)\r\n{\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_set_clockgating_state(void *handle,\r\nenum amd_clockgating_state state)\r\n{\r\nreturn 0;\r\n}\r\nstatic int dce_virtual_set_powergating_state(void *handle,\r\nenum amd_powergating_state state)\r\n{\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_encoder_prepare(struct drm_encoder *encoder)\r\n{\r\nreturn;\r\n}\r\nstatic void dce_virtual_encoder_commit(struct drm_encoder *encoder)\r\n{\r\nreturn;\r\n}\r\nstatic void\r\ndce_virtual_encoder_mode_set(struct drm_encoder *encoder,\r\nstruct drm_display_mode *mode,\r\nstruct drm_display_mode *adjusted_mode)\r\n{\r\nreturn;\r\n}\r\nstatic void dce_virtual_encoder_disable(struct drm_encoder *encoder)\r\n{\r\nreturn;\r\n}\r\nstatic void\r\ndce_virtual_encoder_dpms(struct drm_encoder *encoder, int mode)\r\n{\r\nreturn;\r\n}\r\nstatic bool dce_virtual_encoder_mode_fixup(struct drm_encoder *encoder,\r\nconst struct drm_display_mode *mode,\r\nstruct drm_display_mode *adjusted_mode)\r\n{\r\nreturn true;\r\n}\r\nstatic void dce_virtual_encoder_destroy(struct drm_encoder *encoder)\r\n{\r\ndrm_encoder_cleanup(encoder);\r\nkfree(encoder);\r\n}\r\nstatic int dce_virtual_connector_encoder_init(struct amdgpu_device *adev,\r\nint index)\r\n{\r\nstruct drm_encoder *encoder;\r\nstruct drm_connector *connector;\r\nencoder = kzalloc(sizeof(struct drm_encoder), GFP_KERNEL);\r\nif (!encoder)\r\nreturn -ENOMEM;\r\nencoder->possible_crtcs = 1 << index;\r\ndrm_encoder_init(adev->ddev, encoder, &dce_virtual_encoder_funcs,\r\nDRM_MODE_ENCODER_VIRTUAL, NULL);\r\ndrm_encoder_helper_add(encoder, &dce_virtual_encoder_helper_funcs);\r\nconnector = kzalloc(sizeof(struct drm_connector), GFP_KERNEL);\r\nif (!connector) {\r\nkfree(encoder);\r\nreturn -ENOMEM;\r\n}\r\ndrm_connector_init(adev->ddev, connector, &dce_virtual_connector_funcs,\r\nDRM_MODE_CONNECTOR_VIRTUAL);\r\ndrm_connector_helper_add(connector, &dce_virtual_connector_helper_funcs);\r\nconnector->display_info.subpixel_order = SubPixelHorizontalRGB;\r\nconnector->interlace_allowed = false;\r\nconnector->doublescan_allowed = false;\r\ndrm_connector_register(connector);\r\ndrm_mode_connector_attach_encoder(connector, encoder);\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_set_display_funcs(struct amdgpu_device *adev)\r\n{\r\nif (adev->mode_info.funcs == NULL)\r\nadev->mode_info.funcs = &dce_virtual_display_funcs;\r\n}\r\nstatic int dce_virtual_pageflip(struct amdgpu_device *adev,\r\nunsigned crtc_id)\r\n{\r\nunsigned long flags;\r\nstruct amdgpu_crtc *amdgpu_crtc;\r\nstruct amdgpu_flip_work *works;\r\namdgpu_crtc = adev->mode_info.crtcs[crtc_id];\r\nif (crtc_id >= adev->mode_info.num_crtc) {\r\nDRM_ERROR("invalid pageflip crtc %d\n", crtc_id);\r\nreturn -EINVAL;\r\n}\r\nif (amdgpu_crtc == NULL)\r\nreturn 0;\r\nspin_lock_irqsave(&adev->ddev->event_lock, flags);\r\nworks = amdgpu_crtc->pflip_works;\r\nif (amdgpu_crtc->pflip_status != AMDGPU_FLIP_SUBMITTED) {\r\nDRM_DEBUG_DRIVER("amdgpu_crtc->pflip_status = %d != "\r\n"AMDGPU_FLIP_SUBMITTED(%d)\n",\r\namdgpu_crtc->pflip_status,\r\nAMDGPU_FLIP_SUBMITTED);\r\nspin_unlock_irqrestore(&adev->ddev->event_lock, flags);\r\nreturn 0;\r\n}\r\namdgpu_crtc->pflip_status = AMDGPU_FLIP_NONE;\r\namdgpu_crtc->pflip_works = NULL;\r\nif (works->event)\r\ndrm_crtc_send_vblank_event(&amdgpu_crtc->base, works->event);\r\nspin_unlock_irqrestore(&adev->ddev->event_lock, flags);\r\ndrm_crtc_vblank_put(&amdgpu_crtc->base);\r\nschedule_work(&works->unpin_work);\r\nreturn 0;\r\n}\r\nstatic enum hrtimer_restart dce_virtual_vblank_timer_handle(struct hrtimer *vblank_timer)\r\n{\r\nstruct amdgpu_crtc *amdgpu_crtc = container_of(vblank_timer,\r\nstruct amdgpu_crtc, vblank_timer);\r\nstruct drm_device *ddev = amdgpu_crtc->base.dev;\r\nstruct amdgpu_device *adev = ddev->dev_private;\r\ndrm_handle_vblank(ddev, amdgpu_crtc->crtc_id);\r\ndce_virtual_pageflip(adev, amdgpu_crtc->crtc_id);\r\nhrtimer_start(vblank_timer, DCE_VIRTUAL_VBLANK_PERIOD,\r\nHRTIMER_MODE_REL);\r\nreturn HRTIMER_NORESTART;\r\n}\r\nstatic void dce_virtual_set_crtc_vblank_interrupt_state(struct amdgpu_device *adev,\r\nint crtc,\r\nenum amdgpu_interrupt_state state)\r\n{\r\nif (crtc >= adev->mode_info.num_crtc) {\r\nDRM_DEBUG("invalid crtc %d\n", crtc);\r\nreturn;\r\n}\r\nif (state && !adev->mode_info.crtcs[crtc]->vsync_timer_enabled) {\r\nDRM_DEBUG("Enable software vsync timer\n");\r\nhrtimer_init(&adev->mode_info.crtcs[crtc]->vblank_timer,\r\nCLOCK_MONOTONIC, HRTIMER_MODE_REL);\r\nhrtimer_set_expires(&adev->mode_info.crtcs[crtc]->vblank_timer,\r\nDCE_VIRTUAL_VBLANK_PERIOD);\r\nadev->mode_info.crtcs[crtc]->vblank_timer.function =\r\ndce_virtual_vblank_timer_handle;\r\nhrtimer_start(&adev->mode_info.crtcs[crtc]->vblank_timer,\r\nDCE_VIRTUAL_VBLANK_PERIOD, HRTIMER_MODE_REL);\r\n} else if (!state && adev->mode_info.crtcs[crtc]->vsync_timer_enabled) {\r\nDRM_DEBUG("Disable software vsync timer\n");\r\nhrtimer_cancel(&adev->mode_info.crtcs[crtc]->vblank_timer);\r\n}\r\nadev->mode_info.crtcs[crtc]->vsync_timer_enabled = state;\r\nDRM_DEBUG("[FM]set crtc %d vblank interrupt state %d\n", crtc, state);\r\n}\r\nstatic int dce_virtual_set_crtc_irq_state(struct amdgpu_device *adev,\r\nstruct amdgpu_irq_src *source,\r\nunsigned type,\r\nenum amdgpu_interrupt_state state)\r\n{\r\nif (type > AMDGPU_CRTC_IRQ_VBLANK6)\r\nreturn -EINVAL;\r\ndce_virtual_set_crtc_vblank_interrupt_state(adev, type, state);\r\nreturn 0;\r\n}\r\nstatic void dce_virtual_set_irq_funcs(struct amdgpu_device *adev)\r\n{\r\nadev->crtc_irq.num_types = AMDGPU_CRTC_IRQ_LAST;\r\nadev->crtc_irq.funcs = &dce_virtual_crtc_irq_funcs;\r\n}
