static bool msm_gem_shrinker_lock(struct drm_device *dev, bool *unlock)\r\n{\r\nswitch (mutex_trylock_recursive(&dev->struct_mutex)) {\r\ncase MUTEX_TRYLOCK_FAILED:\r\nreturn false;\r\ncase MUTEX_TRYLOCK_SUCCESS:\r\n*unlock = true;\r\nreturn true;\r\ncase MUTEX_TRYLOCK_RECURSIVE:\r\n*unlock = false;\r\nreturn true;\r\n}\r\nBUG();\r\n}\r\nstatic unsigned long\r\nmsm_gem_shrinker_count(struct shrinker *shrinker, struct shrink_control *sc)\r\n{\r\nstruct msm_drm_private *priv =\r\ncontainer_of(shrinker, struct msm_drm_private, shrinker);\r\nstruct drm_device *dev = priv->dev;\r\nstruct msm_gem_object *msm_obj;\r\nunsigned long count = 0;\r\nbool unlock;\r\nif (!msm_gem_shrinker_lock(dev, &unlock))\r\nreturn 0;\r\nlist_for_each_entry(msm_obj, &priv->inactive_list, mm_list) {\r\nif (is_purgeable(msm_obj))\r\ncount += msm_obj->base.size >> PAGE_SHIFT;\r\n}\r\nif (unlock)\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn count;\r\n}\r\nstatic unsigned long\r\nmsm_gem_shrinker_scan(struct shrinker *shrinker, struct shrink_control *sc)\r\n{\r\nstruct msm_drm_private *priv =\r\ncontainer_of(shrinker, struct msm_drm_private, shrinker);\r\nstruct drm_device *dev = priv->dev;\r\nstruct msm_gem_object *msm_obj;\r\nunsigned long freed = 0;\r\nbool unlock;\r\nif (!msm_gem_shrinker_lock(dev, &unlock))\r\nreturn SHRINK_STOP;\r\nlist_for_each_entry(msm_obj, &priv->inactive_list, mm_list) {\r\nif (freed >= sc->nr_to_scan)\r\nbreak;\r\nif (is_purgeable(msm_obj)) {\r\nmsm_gem_purge(&msm_obj->base);\r\nfreed += msm_obj->base.size >> PAGE_SHIFT;\r\n}\r\n}\r\nif (unlock)\r\nmutex_unlock(&dev->struct_mutex);\r\nif (freed > 0)\r\npr_info_ratelimited("Purging %lu bytes\n", freed << PAGE_SHIFT);\r\nreturn freed;\r\n}\r\nstatic int\r\nmsm_gem_shrinker_vmap(struct notifier_block *nb, unsigned long event, void *ptr)\r\n{\r\nstruct msm_drm_private *priv =\r\ncontainer_of(nb, struct msm_drm_private, vmap_notifier);\r\nstruct drm_device *dev = priv->dev;\r\nstruct msm_gem_object *msm_obj;\r\nunsigned unmapped = 0;\r\nbool unlock;\r\nif (!msm_gem_shrinker_lock(dev, &unlock))\r\nreturn NOTIFY_DONE;\r\nlist_for_each_entry(msm_obj, &priv->inactive_list, mm_list) {\r\nif (is_vunmapable(msm_obj)) {\r\nmsm_gem_vunmap(&msm_obj->base);\r\nif (++unmapped >= 15)\r\nbreak;\r\n}\r\n}\r\nif (unlock)\r\nmutex_unlock(&dev->struct_mutex);\r\n*(unsigned long *)ptr += unmapped;\r\nif (unmapped > 0)\r\npr_info_ratelimited("Purging %u vmaps\n", unmapped);\r\nreturn NOTIFY_DONE;\r\n}\r\nvoid msm_gem_shrinker_init(struct drm_device *dev)\r\n{\r\nstruct msm_drm_private *priv = dev->dev_private;\r\npriv->shrinker.count_objects = msm_gem_shrinker_count;\r\npriv->shrinker.scan_objects = msm_gem_shrinker_scan;\r\npriv->shrinker.seeks = DEFAULT_SEEKS;\r\nWARN_ON(register_shrinker(&priv->shrinker));\r\npriv->vmap_notifier.notifier_call = msm_gem_shrinker_vmap;\r\nWARN_ON(register_vmap_purge_notifier(&priv->vmap_notifier));\r\n}\r\nvoid msm_gem_shrinker_cleanup(struct drm_device *dev)\r\n{\r\nstruct msm_drm_private *priv = dev->dev_private;\r\nif (priv->shrinker.nr_deferred) {\r\nWARN_ON(unregister_vmap_purge_notifier(&priv->vmap_notifier));\r\nunregister_shrinker(&priv->shrinker);\r\n}\r\n}
