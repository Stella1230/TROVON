static int ccp_get_msix_irqs(struct ccp_device *ccp)\r\n{\r\nstruct ccp_pci *ccp_pci = ccp->dev_specific;\r\nstruct device *dev = ccp->dev;\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct msix_entry msix_entry[MSIX_VECTORS];\r\nunsigned int name_len = sizeof(ccp_pci->msix[0].name) - 1;\r\nint v, ret;\r\nfor (v = 0; v < ARRAY_SIZE(msix_entry); v++)\r\nmsix_entry[v].entry = v;\r\nret = pci_enable_msix_range(pdev, msix_entry, 1, v);\r\nif (ret < 0)\r\nreturn ret;\r\nccp_pci->msix_count = ret;\r\nfor (v = 0; v < ccp_pci->msix_count; v++) {\r\nsnprintf(ccp_pci->msix[v].name, name_len, "%s-%u",\r\nccp->name, v);\r\nccp_pci->msix[v].vector = msix_entry[v].vector;\r\nret = request_irq(ccp_pci->msix[v].vector,\r\nccp->vdata->perform->irqhandler,\r\n0, ccp_pci->msix[v].name, dev);\r\nif (ret) {\r\ndev_notice(dev, "unable to allocate MSI-X IRQ (%d)\n",\r\nret);\r\ngoto e_irq;\r\n}\r\n}\r\nreturn 0;\r\ne_irq:\r\nwhile (v--)\r\nfree_irq(ccp_pci->msix[v].vector, dev);\r\npci_disable_msix(pdev);\r\nccp_pci->msix_count = 0;\r\nreturn ret;\r\n}\r\nstatic int ccp_get_msi_irq(struct ccp_device *ccp)\r\n{\r\nstruct device *dev = ccp->dev;\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nint ret;\r\nret = pci_enable_msi(pdev);\r\nif (ret)\r\nreturn ret;\r\nccp->irq = pdev->irq;\r\nret = request_irq(ccp->irq, ccp->vdata->perform->irqhandler, 0,\r\nccp->name, dev);\r\nif (ret) {\r\ndev_notice(dev, "unable to allocate MSI IRQ (%d)\n", ret);\r\ngoto e_msi;\r\n}\r\nreturn 0;\r\ne_msi:\r\npci_disable_msi(pdev);\r\nreturn ret;\r\n}\r\nstatic int ccp_get_irqs(struct ccp_device *ccp)\r\n{\r\nstruct device *dev = ccp->dev;\r\nint ret;\r\nret = ccp_get_msix_irqs(ccp);\r\nif (!ret)\r\nreturn 0;\r\ndev_notice(dev, "could not enable MSI-X (%d), trying MSI\n", ret);\r\nret = ccp_get_msi_irq(ccp);\r\nif (!ret)\r\nreturn 0;\r\ndev_notice(dev, "could not enable MSI (%d)\n", ret);\r\nreturn ret;\r\n}\r\nstatic void ccp_free_irqs(struct ccp_device *ccp)\r\n{\r\nstruct ccp_pci *ccp_pci = ccp->dev_specific;\r\nstruct device *dev = ccp->dev;\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nif (ccp_pci->msix_count) {\r\nwhile (ccp_pci->msix_count--)\r\nfree_irq(ccp_pci->msix[ccp_pci->msix_count].vector,\r\ndev);\r\npci_disable_msix(pdev);\r\n} else if (ccp->irq) {\r\nfree_irq(ccp->irq, dev);\r\npci_disable_msi(pdev);\r\n}\r\nccp->irq = 0;\r\n}\r\nstatic int ccp_find_mmio_area(struct ccp_device *ccp)\r\n{\r\nstruct device *dev = ccp->dev;\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nresource_size_t io_len;\r\nunsigned long io_flags;\r\nio_flags = pci_resource_flags(pdev, ccp->vdata->bar);\r\nio_len = pci_resource_len(pdev, ccp->vdata->bar);\r\nif ((io_flags & IORESOURCE_MEM) &&\r\n(io_len >= (ccp->vdata->offset + 0x800)))\r\nreturn ccp->vdata->bar;\r\nreturn -EIO;\r\n}\r\nstatic int ccp_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nstruct ccp_device *ccp;\r\nstruct ccp_pci *ccp_pci;\r\nstruct device *dev = &pdev->dev;\r\nunsigned int bar;\r\nint ret;\r\nret = -ENOMEM;\r\nccp = ccp_alloc_struct(dev);\r\nif (!ccp)\r\ngoto e_err;\r\nccp_pci = devm_kzalloc(dev, sizeof(*ccp_pci), GFP_KERNEL);\r\nif (!ccp_pci)\r\ngoto e_err;\r\nccp->dev_specific = ccp_pci;\r\nccp->vdata = (struct ccp_vdata *)id->driver_data;\r\nif (!ccp->vdata || !ccp->vdata->version) {\r\nret = -ENODEV;\r\ndev_err(dev, "missing driver data\n");\r\ngoto e_err;\r\n}\r\nccp->get_irq = ccp_get_irqs;\r\nccp->free_irq = ccp_free_irqs;\r\nret = pci_request_regions(pdev, "ccp");\r\nif (ret) {\r\ndev_err(dev, "pci_request_regions failed (%d)\n", ret);\r\ngoto e_err;\r\n}\r\nret = pci_enable_device(pdev);\r\nif (ret) {\r\ndev_err(dev, "pci_enable_device failed (%d)\n", ret);\r\ngoto e_regions;\r\n}\r\npci_set_master(pdev);\r\nret = ccp_find_mmio_area(ccp);\r\nif (ret < 0)\r\ngoto e_device;\r\nbar = ret;\r\nret = -EIO;\r\nccp->io_map = pci_iomap(pdev, bar, 0);\r\nif (!ccp->io_map) {\r\ndev_err(dev, "pci_iomap failed\n");\r\ngoto e_device;\r\n}\r\nccp->io_regs = ccp->io_map + ccp->vdata->offset;\r\nret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(48));\r\nif (ret) {\r\nret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));\r\nif (ret) {\r\ndev_err(dev, "dma_set_mask_and_coherent failed (%d)\n",\r\nret);\r\ngoto e_iomap;\r\n}\r\n}\r\ndev_set_drvdata(dev, ccp);\r\nif (ccp->vdata->setup)\r\nccp->vdata->setup(ccp);\r\nret = ccp->vdata->perform->init(ccp);\r\nif (ret)\r\ngoto e_iomap;\r\ndev_notice(dev, "enabled\n");\r\nreturn 0;\r\ne_iomap:\r\npci_iounmap(pdev, ccp->io_map);\r\ne_device:\r\npci_disable_device(pdev);\r\ne_regions:\r\npci_release_regions(pdev);\r\ne_err:\r\ndev_notice(dev, "initialization failed\n");\r\nreturn ret;\r\n}\r\nstatic void ccp_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct ccp_device *ccp = dev_get_drvdata(dev);\r\nif (!ccp)\r\nreturn;\r\nccp->vdata->perform->destroy(ccp);\r\npci_iounmap(pdev, ccp->io_map);\r\npci_disable_device(pdev);\r\npci_release_regions(pdev);\r\ndev_notice(dev, "disabled\n");\r\n}\r\nstatic int ccp_pci_suspend(struct pci_dev *pdev, pm_message_t state)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct ccp_device *ccp = dev_get_drvdata(dev);\r\nunsigned long flags;\r\nunsigned int i;\r\nspin_lock_irqsave(&ccp->cmd_lock, flags);\r\nccp->suspending = 1;\r\nfor (i = 0; i < ccp->cmd_q_count; i++)\r\nwake_up_process(ccp->cmd_q[i].kthread);\r\nspin_unlock_irqrestore(&ccp->cmd_lock, flags);\r\nwhile (!ccp_queues_suspended(ccp))\r\nwait_event_interruptible(ccp->suspend_queue,\r\nccp_queues_suspended(ccp));\r\nreturn 0;\r\n}\r\nstatic int ccp_pci_resume(struct pci_dev *pdev)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct ccp_device *ccp = dev_get_drvdata(dev);\r\nunsigned long flags;\r\nunsigned int i;\r\nspin_lock_irqsave(&ccp->cmd_lock, flags);\r\nccp->suspending = 0;\r\nfor (i = 0; i < ccp->cmd_q_count; i++) {\r\nccp->cmd_q[i].suspended = 0;\r\nwake_up_process(ccp->cmd_q[i].kthread);\r\n}\r\nspin_unlock_irqrestore(&ccp->cmd_lock, flags);\r\nreturn 0;\r\n}\r\nint ccp_pci_init(void)\r\n{\r\nreturn pci_register_driver(&ccp_pci_driver);\r\n}\r\nvoid ccp_pci_exit(void)\r\n{\r\npci_unregister_driver(&ccp_pci_driver);\r\n}
