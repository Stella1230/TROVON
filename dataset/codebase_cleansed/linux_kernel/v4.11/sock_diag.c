static u64 sock_gen_cookie(struct sock *sk)\r\n{\r\nwhile (1) {\r\nu64 res = atomic64_read(&sk->sk_cookie);\r\nif (res)\r\nreturn res;\r\nres = atomic64_inc_return(&sock_net(sk)->cookie_gen);\r\natomic64_cmpxchg(&sk->sk_cookie, 0, res);\r\n}\r\n}\r\nint sock_diag_check_cookie(struct sock *sk, const __u32 *cookie)\r\n{\r\nu64 res;\r\nif (cookie[0] == INET_DIAG_NOCOOKIE && cookie[1] == INET_DIAG_NOCOOKIE)\r\nreturn 0;\r\nres = sock_gen_cookie(sk);\r\nif ((u32)res != cookie[0] || (u32)(res >> 32) != cookie[1])\r\nreturn -ESTALE;\r\nreturn 0;\r\n}\r\nvoid sock_diag_save_cookie(struct sock *sk, __u32 *cookie)\r\n{\r\nu64 res = sock_gen_cookie(sk);\r\ncookie[0] = (u32)res;\r\ncookie[1] = (u32)(res >> 32);\r\n}\r\nint sock_diag_put_meminfo(struct sock *sk, struct sk_buff *skb, int attrtype)\r\n{\r\nu32 mem[SK_MEMINFO_VARS];\r\nmem[SK_MEMINFO_RMEM_ALLOC] = sk_rmem_alloc_get(sk);\r\nmem[SK_MEMINFO_RCVBUF] = sk->sk_rcvbuf;\r\nmem[SK_MEMINFO_WMEM_ALLOC] = sk_wmem_alloc_get(sk);\r\nmem[SK_MEMINFO_SNDBUF] = sk->sk_sndbuf;\r\nmem[SK_MEMINFO_FWD_ALLOC] = sk->sk_forward_alloc;\r\nmem[SK_MEMINFO_WMEM_QUEUED] = sk->sk_wmem_queued;\r\nmem[SK_MEMINFO_OPTMEM] = atomic_read(&sk->sk_omem_alloc);\r\nmem[SK_MEMINFO_BACKLOG] = sk->sk_backlog.len;\r\nmem[SK_MEMINFO_DROPS] = atomic_read(&sk->sk_drops);\r\nreturn nla_put(skb, attrtype, sizeof(mem), &mem);\r\n}\r\nint sock_diag_put_filterinfo(bool may_report_filterinfo, struct sock *sk,\r\nstruct sk_buff *skb, int attrtype)\r\n{\r\nstruct sock_fprog_kern *fprog;\r\nstruct sk_filter *filter;\r\nstruct nlattr *attr;\r\nunsigned int flen;\r\nint err = 0;\r\nif (!may_report_filterinfo) {\r\nnla_reserve(skb, attrtype, 0);\r\nreturn 0;\r\n}\r\nrcu_read_lock();\r\nfilter = rcu_dereference(sk->sk_filter);\r\nif (!filter)\r\ngoto out;\r\nfprog = filter->prog->orig_prog;\r\nif (!fprog)\r\ngoto out;\r\nflen = bpf_classic_proglen(fprog);\r\nattr = nla_reserve(skb, attrtype, flen);\r\nif (attr == NULL) {\r\nerr = -EMSGSIZE;\r\ngoto out;\r\n}\r\nmemcpy(nla_data(attr), fprog->filter, flen);\r\nout:\r\nrcu_read_unlock();\r\nreturn err;\r\n}\r\nstatic size_t sock_diag_nlmsg_size(void)\r\n{\r\nreturn NLMSG_ALIGN(sizeof(struct inet_diag_msg)\r\n+ nla_total_size(sizeof(u8))\r\n+ nla_total_size_64bit(sizeof(struct tcp_info)));\r\n}\r\nstatic void sock_diag_broadcast_destroy_work(struct work_struct *work)\r\n{\r\nstruct broadcast_sk *bsk =\r\ncontainer_of(work, struct broadcast_sk, work);\r\nstruct sock *sk = bsk->sk;\r\nconst struct sock_diag_handler *hndl;\r\nstruct sk_buff *skb;\r\nconst enum sknetlink_groups group = sock_diag_destroy_group(sk);\r\nint err = -1;\r\nWARN_ON(group == SKNLGRP_NONE);\r\nskb = nlmsg_new(sock_diag_nlmsg_size(), GFP_KERNEL);\r\nif (!skb)\r\ngoto out;\r\nmutex_lock(&sock_diag_table_mutex);\r\nhndl = sock_diag_handlers[sk->sk_family];\r\nif (hndl && hndl->get_info)\r\nerr = hndl->get_info(skb, sk);\r\nmutex_unlock(&sock_diag_table_mutex);\r\nif (!err)\r\nnlmsg_multicast(sock_net(sk)->diag_nlsk, skb, 0, group,\r\nGFP_KERNEL);\r\nelse\r\nkfree_skb(skb);\r\nout:\r\nsk_destruct(sk);\r\nkfree(bsk);\r\n}\r\nvoid sock_diag_broadcast_destroy(struct sock *sk)\r\n{\r\nstruct broadcast_sk *bsk =\r\nkmalloc(sizeof(struct broadcast_sk), GFP_ATOMIC);\r\nif (!bsk)\r\nreturn sk_destruct(sk);\r\nbsk->sk = sk;\r\nINIT_WORK(&bsk->work, sock_diag_broadcast_destroy_work);\r\nqueue_work(broadcast_wq, &bsk->work);\r\n}\r\nvoid sock_diag_register_inet_compat(int (*fn)(struct sk_buff *skb, struct nlmsghdr *nlh))\r\n{\r\nmutex_lock(&sock_diag_table_mutex);\r\ninet_rcv_compat = fn;\r\nmutex_unlock(&sock_diag_table_mutex);\r\n}\r\nvoid sock_diag_unregister_inet_compat(int (*fn)(struct sk_buff *skb, struct nlmsghdr *nlh))\r\n{\r\nmutex_lock(&sock_diag_table_mutex);\r\ninet_rcv_compat = NULL;\r\nmutex_unlock(&sock_diag_table_mutex);\r\n}\r\nint sock_diag_register(const struct sock_diag_handler *hndl)\r\n{\r\nint err = 0;\r\nif (hndl->family >= AF_MAX)\r\nreturn -EINVAL;\r\nmutex_lock(&sock_diag_table_mutex);\r\nif (sock_diag_handlers[hndl->family])\r\nerr = -EBUSY;\r\nelse\r\nsock_diag_handlers[hndl->family] = hndl;\r\nmutex_unlock(&sock_diag_table_mutex);\r\nreturn err;\r\n}\r\nvoid sock_diag_unregister(const struct sock_diag_handler *hnld)\r\n{\r\nint family = hnld->family;\r\nif (family >= AF_MAX)\r\nreturn;\r\nmutex_lock(&sock_diag_table_mutex);\r\nBUG_ON(sock_diag_handlers[family] != hnld);\r\nsock_diag_handlers[family] = NULL;\r\nmutex_unlock(&sock_diag_table_mutex);\r\n}\r\nstatic int __sock_diag_cmd(struct sk_buff *skb, struct nlmsghdr *nlh)\r\n{\r\nint err;\r\nstruct sock_diag_req *req = nlmsg_data(nlh);\r\nconst struct sock_diag_handler *hndl;\r\nif (nlmsg_len(nlh) < sizeof(*req))\r\nreturn -EINVAL;\r\nif (req->sdiag_family >= AF_MAX)\r\nreturn -EINVAL;\r\nif (sock_diag_handlers[req->sdiag_family] == NULL)\r\nrequest_module("net-pf-%d-proto-%d-type-%d", PF_NETLINK,\r\nNETLINK_SOCK_DIAG, req->sdiag_family);\r\nmutex_lock(&sock_diag_table_mutex);\r\nhndl = sock_diag_handlers[req->sdiag_family];\r\nif (hndl == NULL)\r\nerr = -ENOENT;\r\nelse if (nlh->nlmsg_type == SOCK_DIAG_BY_FAMILY)\r\nerr = hndl->dump(skb, nlh);\r\nelse if (nlh->nlmsg_type == SOCK_DESTROY && hndl->destroy)\r\nerr = hndl->destroy(skb, nlh);\r\nelse\r\nerr = -EOPNOTSUPP;\r\nmutex_unlock(&sock_diag_table_mutex);\r\nreturn err;\r\n}\r\nstatic int sock_diag_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)\r\n{\r\nint ret;\r\nswitch (nlh->nlmsg_type) {\r\ncase TCPDIAG_GETSOCK:\r\ncase DCCPDIAG_GETSOCK:\r\nif (inet_rcv_compat == NULL)\r\nrequest_module("net-pf-%d-proto-%d-type-%d", PF_NETLINK,\r\nNETLINK_SOCK_DIAG, AF_INET);\r\nmutex_lock(&sock_diag_table_mutex);\r\nif (inet_rcv_compat != NULL)\r\nret = inet_rcv_compat(skb, nlh);\r\nelse\r\nret = -EOPNOTSUPP;\r\nmutex_unlock(&sock_diag_table_mutex);\r\nreturn ret;\r\ncase SOCK_DIAG_BY_FAMILY:\r\ncase SOCK_DESTROY:\r\nreturn __sock_diag_cmd(skb, nlh);\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic void sock_diag_rcv(struct sk_buff *skb)\r\n{\r\nmutex_lock(&sock_diag_mutex);\r\nnetlink_rcv_skb(skb, &sock_diag_rcv_msg);\r\nmutex_unlock(&sock_diag_mutex);\r\n}\r\nstatic int sock_diag_bind(struct net *net, int group)\r\n{\r\nswitch (group) {\r\ncase SKNLGRP_INET_TCP_DESTROY:\r\ncase SKNLGRP_INET_UDP_DESTROY:\r\nif (!sock_diag_handlers[AF_INET])\r\nrequest_module("net-pf-%d-proto-%d-type-%d", PF_NETLINK,\r\nNETLINK_SOCK_DIAG, AF_INET);\r\nbreak;\r\ncase SKNLGRP_INET6_TCP_DESTROY:\r\ncase SKNLGRP_INET6_UDP_DESTROY:\r\nif (!sock_diag_handlers[AF_INET6])\r\nrequest_module("net-pf-%d-proto-%d-type-%d", PF_NETLINK,\r\nNETLINK_SOCK_DIAG, AF_INET);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nint sock_diag_destroy(struct sock *sk, int err)\r\n{\r\nif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (!sk->sk_prot->diag_destroy)\r\nreturn -EOPNOTSUPP;\r\nreturn sk->sk_prot->diag_destroy(sk, err);\r\n}\r\nstatic int __net_init diag_net_init(struct net *net)\r\n{\r\nstruct netlink_kernel_cfg cfg = {\r\n.groups = SKNLGRP_MAX,\r\n.input = sock_diag_rcv,\r\n.bind = sock_diag_bind,\r\n.flags = NL_CFG_F_NONROOT_RECV,\r\n};\r\nnet->diag_nlsk = netlink_kernel_create(net, NETLINK_SOCK_DIAG, &cfg);\r\nreturn net->diag_nlsk == NULL ? -ENOMEM : 0;\r\n}\r\nstatic void __net_exit diag_net_exit(struct net *net)\r\n{\r\nnetlink_kernel_release(net->diag_nlsk);\r\nnet->diag_nlsk = NULL;\r\n}\r\nstatic int __init sock_diag_init(void)\r\n{\r\nbroadcast_wq = alloc_workqueue("sock_diag_events", 0, 0);\r\nBUG_ON(!broadcast_wq);\r\nreturn register_pernet_subsys(&diag_net_ops);\r\n}
