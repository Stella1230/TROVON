static inline u32 nand_readreg(struct brcmnand_controller *ctrl, u32 offs)\r\n{\r\nreturn brcmnand_readl(ctrl->nand_base + offs);\r\n}\r\nstatic inline void nand_writereg(struct brcmnand_controller *ctrl, u32 offs,\r\nu32 val)\r\n{\r\nbrcmnand_writel(val, ctrl->nand_base + offs);\r\n}\r\nstatic int brcmnand_revision_init(struct brcmnand_controller *ctrl)\r\n{\r\nstatic const unsigned int block_sizes_v6[] = { 8, 16, 128, 256, 512, 1024, 2048, 0 };\r\nstatic const unsigned int block_sizes_v4[] = { 16, 128, 8, 512, 256, 1024, 2048, 0 };\r\nstatic const unsigned int page_sizes[] = { 512, 2048, 4096, 8192, 0 };\r\nctrl->nand_version = nand_readreg(ctrl, 0) & 0xffff;\r\nif (ctrl->nand_version < 0x0400) {\r\ndev_err(ctrl->dev, "version %#x not supported\n",\r\nctrl->nand_version);\r\nreturn -ENODEV;\r\n}\r\nif (ctrl->nand_version >= 0x0702)\r\nctrl->reg_offsets = brcmnand_regs_v72;\r\nelse if (ctrl->nand_version >= 0x0701)\r\nctrl->reg_offsets = brcmnand_regs_v71;\r\nelse if (ctrl->nand_version >= 0x0600)\r\nctrl->reg_offsets = brcmnand_regs_v60;\r\nelse if (ctrl->nand_version >= 0x0500)\r\nctrl->reg_offsets = brcmnand_regs_v50;\r\nelse if (ctrl->nand_version >= 0x0400)\r\nctrl->reg_offsets = brcmnand_regs_v40;\r\nif (ctrl->nand_version >= 0x0701)\r\nctrl->reg_spacing = 0x14;\r\nelse\r\nctrl->reg_spacing = 0x10;\r\nif (ctrl->nand_version >= 0x0701) {\r\nctrl->cs_offsets = brcmnand_cs_offsets_v71;\r\n} else {\r\nctrl->cs_offsets = brcmnand_cs_offsets;\r\nif (ctrl->nand_version <= 0x0500)\r\nctrl->cs0_offsets = brcmnand_cs_offsets_cs0;\r\n}\r\nif (ctrl->nand_version >= 0x0701) {\r\nctrl->max_page_size = 16 * 1024;\r\nctrl->max_block_size = 2 * 1024 * 1024;\r\n} else {\r\nctrl->page_sizes = page_sizes;\r\nif (ctrl->nand_version >= 0x0600)\r\nctrl->block_sizes = block_sizes_v6;\r\nelse\r\nctrl->block_sizes = block_sizes_v4;\r\nif (ctrl->nand_version < 0x0400) {\r\nctrl->max_page_size = 4096;\r\nctrl->max_block_size = 512 * 1024;\r\n}\r\n}\r\nif (ctrl->nand_version >= 0x0702)\r\nctrl->max_oob = 128;\r\nelse if (ctrl->nand_version >= 0x0600)\r\nctrl->max_oob = 64;\r\nelse if (ctrl->nand_version >= 0x0500)\r\nctrl->max_oob = 32;\r\nelse\r\nctrl->max_oob = 16;\r\nif (ctrl->nand_version >= 0x0600 && ctrl->nand_version != 0x0601)\r\nctrl->features |= BRCMNAND_HAS_PREFETCH;\r\nif (ctrl->nand_version >= 0x0700)\r\nctrl->features |= BRCMNAND_HAS_CACHE_MODE;\r\nif (ctrl->nand_version >= 0x0500)\r\nctrl->features |= BRCMNAND_HAS_1K_SECTORS;\r\nif (ctrl->nand_version >= 0x0700)\r\nctrl->features |= BRCMNAND_HAS_WP;\r\nelse if (of_property_read_bool(ctrl->dev->of_node, "brcm,nand-has-wp"))\r\nctrl->features |= BRCMNAND_HAS_WP;\r\nreturn 0;\r\n}\r\nstatic inline u32 brcmnand_read_reg(struct brcmnand_controller *ctrl,\r\nenum brcmnand_reg reg)\r\n{\r\nu16 offs = ctrl->reg_offsets[reg];\r\nif (offs)\r\nreturn nand_readreg(ctrl, offs);\r\nelse\r\nreturn 0;\r\n}\r\nstatic inline void brcmnand_write_reg(struct brcmnand_controller *ctrl,\r\nenum brcmnand_reg reg, u32 val)\r\n{\r\nu16 offs = ctrl->reg_offsets[reg];\r\nif (offs)\r\nnand_writereg(ctrl, offs, val);\r\n}\r\nstatic inline void brcmnand_rmw_reg(struct brcmnand_controller *ctrl,\r\nenum brcmnand_reg reg, u32 mask, unsigned\r\nint shift, u32 val)\r\n{\r\nu32 tmp = brcmnand_read_reg(ctrl, reg);\r\ntmp &= ~mask;\r\ntmp |= val << shift;\r\nbrcmnand_write_reg(ctrl, reg, tmp);\r\n}\r\nstatic inline u32 brcmnand_read_fc(struct brcmnand_controller *ctrl, int word)\r\n{\r\nreturn __raw_readl(ctrl->nand_fc + word * 4);\r\n}\r\nstatic inline void brcmnand_write_fc(struct brcmnand_controller *ctrl,\r\nint word, u32 val)\r\n{\r\n__raw_writel(val, ctrl->nand_fc + word * 4);\r\n}\r\nstatic inline u16 brcmnand_cs_offset(struct brcmnand_controller *ctrl, int cs,\r\nenum brcmnand_cs_reg reg)\r\n{\r\nu16 offs_cs0 = ctrl->reg_offsets[BRCMNAND_CS0_BASE];\r\nu16 offs_cs1 = ctrl->reg_offsets[BRCMNAND_CS1_BASE];\r\nu8 cs_offs;\r\nif (cs == 0 && ctrl->cs0_offsets)\r\ncs_offs = ctrl->cs0_offsets[reg];\r\nelse\r\ncs_offs = ctrl->cs_offsets[reg];\r\nif (cs && offs_cs1)\r\nreturn offs_cs1 + (cs - 1) * ctrl->reg_spacing + cs_offs;\r\nreturn offs_cs0 + cs * ctrl->reg_spacing + cs_offs;\r\n}\r\nstatic inline u32 brcmnand_count_corrected(struct brcmnand_controller *ctrl)\r\n{\r\nif (ctrl->nand_version < 0x0600)\r\nreturn 1;\r\nreturn brcmnand_read_reg(ctrl, BRCMNAND_CORR_COUNT);\r\n}\r\nstatic void brcmnand_wr_corr_thresh(struct brcmnand_host *host, u8 val)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nunsigned int shift = 0, bits;\r\nenum brcmnand_reg reg = BRCMNAND_CORR_THRESHOLD;\r\nint cs = host->cs;\r\nif (ctrl->nand_version >= 0x0702)\r\nbits = 7;\r\nelse if (ctrl->nand_version >= 0x0600)\r\nbits = 6;\r\nelse if (ctrl->nand_version >= 0x0500)\r\nbits = 5;\r\nelse\r\nbits = 4;\r\nif (ctrl->nand_version >= 0x0702) {\r\nif (cs >= 4)\r\nreg = BRCMNAND_CORR_THRESHOLD_EXT;\r\nshift = (cs % 4) * bits;\r\n} else if (ctrl->nand_version >= 0x0600) {\r\nif (cs >= 5)\r\nreg = BRCMNAND_CORR_THRESHOLD_EXT;\r\nshift = (cs % 5) * bits;\r\n}\r\nbrcmnand_rmw_reg(ctrl, reg, (bits - 1) << shift, shift, val);\r\n}\r\nstatic inline int brcmnand_cmd_shift(struct brcmnand_controller *ctrl)\r\n{\r\nif (ctrl->nand_version < 0x0602)\r\nreturn 24;\r\nreturn 0;\r\n}\r\nstatic inline u32 brcmnand_spare_area_mask(struct brcmnand_controller *ctrl)\r\n{\r\nif (ctrl->nand_version >= 0x0702)\r\nreturn GENMASK(7, 0);\r\nelse if (ctrl->nand_version >= 0x0600)\r\nreturn GENMASK(6, 0);\r\nelse\r\nreturn GENMASK(5, 0);\r\n}\r\nstatic inline u32 brcmnand_ecc_level_mask(struct brcmnand_controller *ctrl)\r\n{\r\nu32 mask = (ctrl->nand_version >= 0x0600) ? 0x1f : 0x0f;\r\nmask <<= NAND_ACC_CONTROL_ECC_SHIFT;\r\nif (ctrl->nand_version >= 0x0702)\r\nmask |= 0x7 << NAND_ACC_CONTROL_ECC_EXT_SHIFT;\r\nreturn mask;\r\n}\r\nstatic void brcmnand_set_ecc_enabled(struct brcmnand_host *host, int en)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nu16 offs = brcmnand_cs_offset(ctrl, host->cs, BRCMNAND_CS_ACC_CONTROL);\r\nu32 acc_control = nand_readreg(ctrl, offs);\r\nu32 ecc_flags = ACC_CONTROL_WR_ECC | ACC_CONTROL_RD_ECC;\r\nif (en) {\r\nacc_control |= ecc_flags;\r\nacc_control |= host->hwcfg.ecc_level\r\n<< NAND_ACC_CONTROL_ECC_SHIFT;\r\n} else {\r\nacc_control &= ~ecc_flags;\r\nacc_control &= ~brcmnand_ecc_level_mask(ctrl);\r\n}\r\nnand_writereg(ctrl, offs, acc_control);\r\n}\r\nstatic inline int brcmnand_sector_1k_shift(struct brcmnand_controller *ctrl)\r\n{\r\nif (ctrl->nand_version >= 0x0702)\r\nreturn 9;\r\nelse if (ctrl->nand_version >= 0x0600)\r\nreturn 7;\r\nelse if (ctrl->nand_version >= 0x0500)\r\nreturn 6;\r\nelse\r\nreturn -1;\r\n}\r\nstatic int brcmnand_get_sector_size_1k(struct brcmnand_host *host)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nint shift = brcmnand_sector_1k_shift(ctrl);\r\nu16 acc_control_offs = brcmnand_cs_offset(ctrl, host->cs,\r\nBRCMNAND_CS_ACC_CONTROL);\r\nif (shift < 0)\r\nreturn 0;\r\nreturn (nand_readreg(ctrl, acc_control_offs) >> shift) & 0x1;\r\n}\r\nstatic void brcmnand_set_sector_size_1k(struct brcmnand_host *host, int val)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nint shift = brcmnand_sector_1k_shift(ctrl);\r\nu16 acc_control_offs = brcmnand_cs_offset(ctrl, host->cs,\r\nBRCMNAND_CS_ACC_CONTROL);\r\nu32 tmp;\r\nif (shift < 0)\r\nreturn;\r\ntmp = nand_readreg(ctrl, acc_control_offs);\r\ntmp &= ~(1 << shift);\r\ntmp |= (!!val) << shift;\r\nnand_writereg(ctrl, acc_control_offs, tmp);\r\n}\r\nstatic inline void brcmnand_set_wp(struct brcmnand_controller *ctrl, bool en)\r\n{\r\nu32 val = en ? CS_SELECT_NAND_WP : 0;\r\nbrcmnand_rmw_reg(ctrl, BRCMNAND_CS_SELECT, CS_SELECT_NAND_WP, 0, val);\r\n}\r\nstatic inline bool has_flash_dma(struct brcmnand_controller *ctrl)\r\n{\r\nreturn ctrl->flash_dma_base;\r\n}\r\nstatic inline bool flash_dma_buf_ok(const void *buf)\r\n{\r\nreturn buf && !is_vmalloc_addr(buf) &&\r\nlikely(IS_ALIGNED((uintptr_t)buf, 4));\r\n}\r\nstatic inline void flash_dma_writel(struct brcmnand_controller *ctrl, u8 offs,\r\nu32 val)\r\n{\r\nbrcmnand_writel(val, ctrl->flash_dma_base + offs);\r\n}\r\nstatic inline u32 flash_dma_readl(struct brcmnand_controller *ctrl, u8 offs)\r\n{\r\nreturn brcmnand_readl(ctrl->flash_dma_base + offs);\r\n}\r\nstatic inline bool is_hamming_ecc(struct brcmnand_controller *ctrl,\r\nstruct brcmnand_cfg *cfg)\r\n{\r\nif (ctrl->nand_version <= 0x0701)\r\nreturn cfg->sector_size_1k == 0 && cfg->spare_area_size == 16 &&\r\ncfg->ecc_level == 15;\r\nelse\r\nreturn cfg->sector_size_1k == 0 && ((cfg->spare_area_size == 16 &&\r\ncfg->ecc_level == 15) ||\r\n(cfg->spare_area_size == 28 && cfg->ecc_level == 16));\r\n}\r\nstatic int brcmnand_hamming_ooblayout_ecc(struct mtd_info *mtd, int section,\r\nstruct mtd_oob_region *oobregion)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_cfg *cfg = &host->hwcfg;\r\nint sas = cfg->spare_area_size << cfg->sector_size_1k;\r\nint sectors = cfg->page_size / (512 << cfg->sector_size_1k);\r\nif (section >= sectors)\r\nreturn -ERANGE;\r\noobregion->offset = (section * sas) + 6;\r\noobregion->length = 3;\r\nreturn 0;\r\n}\r\nstatic int brcmnand_hamming_ooblayout_free(struct mtd_info *mtd, int section,\r\nstruct mtd_oob_region *oobregion)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_cfg *cfg = &host->hwcfg;\r\nint sas = cfg->spare_area_size << cfg->sector_size_1k;\r\nint sectors = cfg->page_size / (512 << cfg->sector_size_1k);\r\nif (section >= sectors * 2)\r\nreturn -ERANGE;\r\noobregion->offset = (section / 2) * sas;\r\nif (section & 1) {\r\noobregion->offset += 9;\r\noobregion->length = 7;\r\n} else {\r\noobregion->length = 6;\r\nif (!section) {\r\nif (cfg->page_size > 512)\r\noobregion->offset++;\r\noobregion->length--;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int brcmnand_bch_ooblayout_ecc(struct mtd_info *mtd, int section,\r\nstruct mtd_oob_region *oobregion)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_cfg *cfg = &host->hwcfg;\r\nint sas = cfg->spare_area_size << cfg->sector_size_1k;\r\nint sectors = cfg->page_size / (512 << cfg->sector_size_1k);\r\nif (section >= sectors)\r\nreturn -ERANGE;\r\noobregion->offset = (section * (sas + 1)) - chip->ecc.bytes;\r\noobregion->length = chip->ecc.bytes;\r\nreturn 0;\r\n}\r\nstatic int brcmnand_bch_ooblayout_free_lp(struct mtd_info *mtd, int section,\r\nstruct mtd_oob_region *oobregion)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_cfg *cfg = &host->hwcfg;\r\nint sas = cfg->spare_area_size << cfg->sector_size_1k;\r\nint sectors = cfg->page_size / (512 << cfg->sector_size_1k);\r\nif (section >= sectors)\r\nreturn -ERANGE;\r\nif (sas <= chip->ecc.bytes)\r\nreturn 0;\r\noobregion->offset = section * sas;\r\noobregion->length = sas - chip->ecc.bytes;\r\nif (!section) {\r\noobregion->offset++;\r\noobregion->length--;\r\n}\r\nreturn 0;\r\n}\r\nstatic int brcmnand_bch_ooblayout_free_sp(struct mtd_info *mtd, int section,\r\nstruct mtd_oob_region *oobregion)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_cfg *cfg = &host->hwcfg;\r\nint sas = cfg->spare_area_size << cfg->sector_size_1k;\r\nif (section > 1 || sas - chip->ecc.bytes < 6 ||\r\n(section && sas - chip->ecc.bytes == 6))\r\nreturn -ERANGE;\r\nif (!section) {\r\noobregion->offset = 0;\r\noobregion->length = 5;\r\n} else {\r\noobregion->offset = 6;\r\noobregion->length = sas - chip->ecc.bytes - 6;\r\n}\r\nreturn 0;\r\n}\r\nstatic int brcmstb_choose_ecc_layout(struct brcmnand_host *host)\r\n{\r\nstruct brcmnand_cfg *p = &host->hwcfg;\r\nstruct mtd_info *mtd = nand_to_mtd(&host->chip);\r\nstruct nand_ecc_ctrl *ecc = &host->chip.ecc;\r\nunsigned int ecc_level = p->ecc_level;\r\nint sas = p->spare_area_size << p->sector_size_1k;\r\nint sectors = p->page_size / (512 << p->sector_size_1k);\r\nif (p->sector_size_1k)\r\necc_level <<= 1;\r\nif (is_hamming_ecc(host->ctrl, p)) {\r\necc->bytes = 3 * sectors;\r\nmtd_set_ooblayout(mtd, &brcmnand_hamming_ooblayout_ops);\r\nreturn 0;\r\n}\r\necc->bytes = DIV_ROUND_UP(ecc_level * 14, 8);\r\nif (p->page_size == 512)\r\nmtd_set_ooblayout(mtd, &brcmnand_bch_sp_ooblayout_ops);\r\nelse\r\nmtd_set_ooblayout(mtd, &brcmnand_bch_lp_ooblayout_ops);\r\nif (ecc->bytes >= sas) {\r\ndev_err(&host->pdev->dev,\r\n"error: ECC too large for OOB (ECC bytes %d, spare sector %d)\n",\r\necc->bytes, sas);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void brcmnand_wp(struct mtd_info *mtd, int wp)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nif ((ctrl->features & BRCMNAND_HAS_WP) && wp_on == 1) {\r\nstatic int old_wp = -1;\r\nif (old_wp != wp) {\r\ndev_dbg(ctrl->dev, "WP %s\n", wp ? "on" : "off");\r\nold_wp = wp;\r\n}\r\nbrcmnand_set_wp(ctrl, wp);\r\n}\r\n}\r\nstatic inline u8 oob_reg_read(struct brcmnand_controller *ctrl, u32 offs)\r\n{\r\nu16 offset0, offset10, reg_offs;\r\noffset0 = ctrl->reg_offsets[BRCMNAND_OOB_READ_BASE];\r\noffset10 = ctrl->reg_offsets[BRCMNAND_OOB_READ_10_BASE];\r\nif (offs >= ctrl->max_oob)\r\nreturn 0x77;\r\nif (offs >= 16 && offset10)\r\nreg_offs = offset10 + ((offs - 0x10) & ~0x03);\r\nelse\r\nreg_offs = offset0 + (offs & ~0x03);\r\nreturn nand_readreg(ctrl, reg_offs) >> (24 - ((offs & 0x03) << 3));\r\n}\r\nstatic inline void oob_reg_write(struct brcmnand_controller *ctrl, u32 offs,\r\nu32 data)\r\n{\r\nu16 offset0, offset10, reg_offs;\r\noffset0 = ctrl->reg_offsets[BRCMNAND_OOB_WRITE_BASE];\r\noffset10 = ctrl->reg_offsets[BRCMNAND_OOB_WRITE_10_BASE];\r\nif (offs >= ctrl->max_oob)\r\nreturn;\r\nif (offs >= 16 && offset10)\r\nreg_offs = offset10 + ((offs - 0x10) & ~0x03);\r\nelse\r\nreg_offs = offset0 + (offs & ~0x03);\r\nnand_writereg(ctrl, reg_offs, data);\r\n}\r\nstatic int read_oob_from_regs(struct brcmnand_controller *ctrl, int i, u8 *oob,\r\nint sas, int sector_1k)\r\n{\r\nint tbytes = sas << sector_1k;\r\nint j;\r\nif (sector_1k && (i & 0x01))\r\ntbytes = max(0, tbytes - (int)ctrl->max_oob);\r\ntbytes = min_t(int, tbytes, ctrl->max_oob);\r\nfor (j = 0; j < tbytes; j++)\r\noob[j] = oob_reg_read(ctrl, j);\r\nreturn tbytes;\r\n}\r\nstatic int write_oob_to_regs(struct brcmnand_controller *ctrl, int i,\r\nconst u8 *oob, int sas, int sector_1k)\r\n{\r\nint tbytes = sas << sector_1k;\r\nint j;\r\nif (sector_1k && (i & 0x01))\r\ntbytes = max(0, tbytes - (int)ctrl->max_oob);\r\ntbytes = min_t(int, tbytes, ctrl->max_oob);\r\nfor (j = 0; j < tbytes; j += 4)\r\noob_reg_write(ctrl, j,\r\n(oob[j + 0] << 24) |\r\n(oob[j + 1] << 16) |\r\n(oob[j + 2] << 8) |\r\n(oob[j + 3] << 0));\r\nreturn tbytes;\r\n}\r\nstatic irqreturn_t brcmnand_ctlrdy_irq(int irq, void *data)\r\n{\r\nstruct brcmnand_controller *ctrl = data;\r\nif (ctrl->dma_pending)\r\nreturn IRQ_HANDLED;\r\ncomplete(&ctrl->done);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t brcmnand_irq(int irq, void *data)\r\n{\r\nstruct brcmnand_controller *ctrl = data;\r\nif (ctrl->soc->ctlrdy_ack(ctrl->soc))\r\nreturn brcmnand_ctlrdy_irq(irq, data);\r\nreturn IRQ_NONE;\r\n}\r\nstatic irqreturn_t brcmnand_dma_irq(int irq, void *data)\r\n{\r\nstruct brcmnand_controller *ctrl = data;\r\ncomplete(&ctrl->dma_done);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void brcmnand_send_cmd(struct brcmnand_host *host, int cmd)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nu32 intfc;\r\ndev_dbg(ctrl->dev, "send native cmd %d addr_lo 0x%x\n", cmd,\r\nbrcmnand_read_reg(ctrl, BRCMNAND_CMD_ADDRESS));\r\nBUG_ON(ctrl->cmd_pending != 0);\r\nctrl->cmd_pending = cmd;\r\nintfc = brcmnand_read_reg(ctrl, BRCMNAND_INTFC_STATUS);\r\nWARN_ON(!(intfc & INTFC_CTLR_READY));\r\nmb();\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CMD_START,\r\ncmd << brcmnand_cmd_shift(ctrl));\r\n}\r\nstatic void brcmnand_cmd_ctrl(struct mtd_info *mtd, int dat,\r\nunsigned int ctrl)\r\n{\r\n}\r\nstatic int brcmnand_waitfunc(struct mtd_info *mtd, struct nand_chip *this)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nunsigned long timeo = msecs_to_jiffies(100);\r\ndev_dbg(ctrl->dev, "wait on native cmd %d\n", ctrl->cmd_pending);\r\nif (ctrl->cmd_pending &&\r\nwait_for_completion_timeout(&ctrl->done, timeo) <= 0) {\r\nu32 cmd = brcmnand_read_reg(ctrl, BRCMNAND_CMD_START)\r\n>> brcmnand_cmd_shift(ctrl);\r\ndev_err_ratelimited(ctrl->dev,\r\n"timeout waiting for command %#02x\n", cmd);\r\ndev_err_ratelimited(ctrl->dev, "intfc status %08x\n",\r\nbrcmnand_read_reg(ctrl, BRCMNAND_INTFC_STATUS));\r\n}\r\nctrl->cmd_pending = 0;\r\nreturn brcmnand_read_reg(ctrl, BRCMNAND_INTFC_STATUS) &\r\nINTFC_FLASH_STATUS;\r\n}\r\nstatic int brcmnand_low_level_op(struct brcmnand_host *host,\r\nenum brcmnand_llop_type type, u32 data,\r\nbool last_op)\r\n{\r\nstruct mtd_info *mtd = nand_to_mtd(&host->chip);\r\nstruct nand_chip *chip = &host->chip;\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nu32 tmp;\r\ntmp = data & LLOP_DATA_MASK;\r\nswitch (type) {\r\ncase LL_OP_CMD:\r\ntmp |= LLOP_WE | LLOP_CLE;\r\nbreak;\r\ncase LL_OP_ADDR:\r\ntmp |= LLOP_WE | LLOP_ALE;\r\nbreak;\r\ncase LL_OP_WR:\r\ntmp |= LLOP_WE;\r\nbreak;\r\ncase LL_OP_RD:\r\ntmp |= LLOP_RE;\r\nbreak;\r\n}\r\nif (last_op)\r\ntmp |= LLOP_RETURN_IDLE;\r\ndev_dbg(ctrl->dev, "ll_op cmd %#x\n", tmp);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_LL_OP, tmp);\r\n(void)brcmnand_read_reg(ctrl, BRCMNAND_LL_OP);\r\nbrcmnand_send_cmd(host, CMD_LOW_LEVEL_OP);\r\nreturn brcmnand_waitfunc(mtd, chip);\r\n}\r\nstatic void brcmnand_cmdfunc(struct mtd_info *mtd, unsigned command,\r\nint column, int page_addr)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nu64 addr = (u64)page_addr << chip->page_shift;\r\nint native_cmd = 0;\r\nif (command == NAND_CMD_READID || command == NAND_CMD_PARAM ||\r\ncommand == NAND_CMD_RNDOUT)\r\naddr = (u64)column;\r\nelse if (page_addr < 0)\r\naddr = 0;\r\ndev_dbg(ctrl->dev, "cmd 0x%x addr 0x%llx\n", command,\r\n(unsigned long long)addr);\r\nhost->last_cmd = command;\r\nhost->last_byte = 0;\r\nhost->last_addr = addr;\r\nswitch (command) {\r\ncase NAND_CMD_RESET:\r\nnative_cmd = CMD_FLASH_RESET;\r\nbreak;\r\ncase NAND_CMD_STATUS:\r\nnative_cmd = CMD_STATUS_READ;\r\nbreak;\r\ncase NAND_CMD_READID:\r\nnative_cmd = CMD_DEVICE_ID_READ;\r\nbreak;\r\ncase NAND_CMD_READOOB:\r\nnative_cmd = CMD_SPARE_AREA_READ;\r\nbreak;\r\ncase NAND_CMD_ERASE1:\r\nnative_cmd = CMD_BLOCK_ERASE;\r\nbrcmnand_wp(mtd, 0);\r\nbreak;\r\ncase NAND_CMD_PARAM:\r\nnative_cmd = CMD_PARAMETER_READ;\r\nbreak;\r\ncase NAND_CMD_SET_FEATURES:\r\ncase NAND_CMD_GET_FEATURES:\r\nbrcmnand_low_level_op(host, LL_OP_CMD, command, false);\r\nbrcmnand_low_level_op(host, LL_OP_ADDR, column, false);\r\nbreak;\r\ncase NAND_CMD_RNDOUT:\r\nnative_cmd = CMD_PARAMETER_CHANGE_COL;\r\naddr &= ~((u64)(FC_BYTES - 1));\r\nif (brcmnand_get_sector_size_1k(host)) {\r\nhost->hwcfg.sector_size_1k =\r\nbrcmnand_get_sector_size_1k(host);\r\nbrcmnand_set_sector_size_1k(host, 0);\r\n}\r\nbreak;\r\n}\r\nif (!native_cmd)\r\nreturn;\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CMD_EXT_ADDRESS,\r\n(host->cs << 16) | ((addr >> 32) & 0xffff));\r\n(void)brcmnand_read_reg(ctrl, BRCMNAND_CMD_EXT_ADDRESS);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CMD_ADDRESS, lower_32_bits(addr));\r\n(void)brcmnand_read_reg(ctrl, BRCMNAND_CMD_ADDRESS);\r\nbrcmnand_send_cmd(host, native_cmd);\r\nbrcmnand_waitfunc(mtd, chip);\r\nif (native_cmd == CMD_PARAMETER_READ ||\r\nnative_cmd == CMD_PARAMETER_CHANGE_COL) {\r\nu32 *flash_cache = (u32 *)ctrl->flash_cache;\r\nint i;\r\nbrcmnand_soc_data_bus_prepare(ctrl->soc, true);\r\nfor (i = 0; i < FC_WORDS; i++)\r\nflash_cache[i] = be32_to_cpu(brcmnand_read_fc(ctrl, i));\r\nbrcmnand_soc_data_bus_unprepare(ctrl->soc, true);\r\nif (host->hwcfg.sector_size_1k)\r\nbrcmnand_set_sector_size_1k(host,\r\nhost->hwcfg.sector_size_1k);\r\n}\r\nif (command == NAND_CMD_ERASE1)\r\nbrcmnand_wp(mtd, 1);\r\n}\r\nstatic uint8_t brcmnand_read_byte(struct mtd_info *mtd)\r\n{\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nuint8_t ret = 0;\r\nint addr, offs;\r\nswitch (host->last_cmd) {\r\ncase NAND_CMD_READID:\r\nif (host->last_byte < 4)\r\nret = brcmnand_read_reg(ctrl, BRCMNAND_ID) >>\r\n(24 - (host->last_byte << 3));\r\nelse if (host->last_byte < 8)\r\nret = brcmnand_read_reg(ctrl, BRCMNAND_ID_EXT) >>\r\n(56 - (host->last_byte << 3));\r\nbreak;\r\ncase NAND_CMD_READOOB:\r\nret = oob_reg_read(ctrl, host->last_byte);\r\nbreak;\r\ncase NAND_CMD_STATUS:\r\nret = brcmnand_read_reg(ctrl, BRCMNAND_INTFC_STATUS) &\r\nINTFC_FLASH_STATUS;\r\nif (wp_on)\r\nret |= NAND_STATUS_WP;\r\nbreak;\r\ncase NAND_CMD_PARAM:\r\ncase NAND_CMD_RNDOUT:\r\naddr = host->last_addr + host->last_byte;\r\noffs = addr & (FC_BYTES - 1);\r\nif (host->last_byte > 0 && offs == 0)\r\nchip->cmdfunc(mtd, NAND_CMD_RNDOUT, addr, -1);\r\nret = ctrl->flash_cache[offs];\r\nbreak;\r\ncase NAND_CMD_GET_FEATURES:\r\nif (host->last_byte >= ONFI_SUBFEATURE_PARAM_LEN) {\r\nret = 0;\r\n} else {\r\nbool last = host->last_byte ==\r\nONFI_SUBFEATURE_PARAM_LEN - 1;\r\nbrcmnand_low_level_op(host, LL_OP_RD, 0, last);\r\nret = brcmnand_read_reg(ctrl, BRCMNAND_LL_RDATA) & 0xff;\r\n}\r\n}\r\ndev_dbg(ctrl->dev, "read byte = 0x%02x\n", ret);\r\nhost->last_byte++;\r\nreturn ret;\r\n}\r\nstatic void brcmnand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)\r\n{\r\nint i;\r\nfor (i = 0; i < len; i++, buf++)\r\n*buf = brcmnand_read_byte(mtd);\r\n}\r\nstatic void brcmnand_write_buf(struct mtd_info *mtd, const uint8_t *buf,\r\nint len)\r\n{\r\nint i;\r\nstruct nand_chip *chip = mtd_to_nand(mtd);\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nswitch (host->last_cmd) {\r\ncase NAND_CMD_SET_FEATURES:\r\nfor (i = 0; i < len; i++)\r\nbrcmnand_low_level_op(host, LL_OP_WR, buf[i],\r\n(i + 1) == len);\r\nbreak;\r\ndefault:\r\nBUG();\r\nbreak;\r\n}\r\n}\r\nstatic int brcmnand_fill_dma_desc(struct brcmnand_host *host,\r\nstruct brcm_nand_dma_desc *desc, u64 addr,\r\ndma_addr_t buf, u32 len, u8 dma_cmd,\r\nbool begin, bool end,\r\ndma_addr_t next_desc)\r\n{\r\nmemset(desc, 0, sizeof(*desc));\r\ndesc->next_desc = lower_32_bits(next_desc);\r\ndesc->next_desc_ext = upper_32_bits(next_desc);\r\ndesc->cmd_irq = (dma_cmd << 24) |\r\n(end ? (0x03 << 8) : 0) |\r\n(!!begin) | ((!!end) << 1);\r\n#ifdef CONFIG_CPU_BIG_ENDIAN\r\ndesc->cmd_irq |= 0x01 << 12;\r\n#endif\r\ndesc->dram_addr = lower_32_bits(buf);\r\ndesc->dram_addr_ext = upper_32_bits(buf);\r\ndesc->tfr_len = len;\r\ndesc->total_len = len;\r\ndesc->flash_addr = lower_32_bits(addr);\r\ndesc->flash_addr_ext = upper_32_bits(addr);\r\ndesc->cs = host->cs;\r\ndesc->status_valid = 0x01;\r\nreturn 0;\r\n}\r\nstatic void brcmnand_dma_run(struct brcmnand_host *host, dma_addr_t desc)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nunsigned long timeo = msecs_to_jiffies(100);\r\nflash_dma_writel(ctrl, FLASH_DMA_FIRST_DESC, lower_32_bits(desc));\r\n(void)flash_dma_readl(ctrl, FLASH_DMA_FIRST_DESC);\r\nflash_dma_writel(ctrl, FLASH_DMA_FIRST_DESC_EXT, upper_32_bits(desc));\r\n(void)flash_dma_readl(ctrl, FLASH_DMA_FIRST_DESC_EXT);\r\nctrl->dma_pending = true;\r\nmb();\r\nflash_dma_writel(ctrl, FLASH_DMA_CTRL, 0x03);\r\nif (wait_for_completion_timeout(&ctrl->dma_done, timeo) <= 0) {\r\ndev_err(ctrl->dev,\r\n"timeout waiting for DMA; status %#x, error status %#x\n",\r\nflash_dma_readl(ctrl, FLASH_DMA_STATUS),\r\nflash_dma_readl(ctrl, FLASH_DMA_ERROR_STATUS));\r\n}\r\nctrl->dma_pending = false;\r\nflash_dma_writel(ctrl, FLASH_DMA_CTRL, 0);\r\n}\r\nstatic int brcmnand_dma_trans(struct brcmnand_host *host, u64 addr, u32 *buf,\r\nu32 len, u8 dma_cmd)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\ndma_addr_t buf_pa;\r\nint dir = dma_cmd == CMD_PAGE_READ ? DMA_FROM_DEVICE : DMA_TO_DEVICE;\r\nbuf_pa = dma_map_single(ctrl->dev, buf, len, dir);\r\nif (dma_mapping_error(ctrl->dev, buf_pa)) {\r\ndev_err(ctrl->dev, "unable to map buffer for DMA\n");\r\nreturn -ENOMEM;\r\n}\r\nbrcmnand_fill_dma_desc(host, ctrl->dma_desc, addr, buf_pa, len,\r\ndma_cmd, true, true, 0);\r\nbrcmnand_dma_run(host, ctrl->dma_pa);\r\ndma_unmap_single(ctrl->dev, buf_pa, len, dir);\r\nif (ctrl->dma_desc->status_valid & FLASH_DMA_ECC_ERROR)\r\nreturn -EBADMSG;\r\nelse if (ctrl->dma_desc->status_valid & FLASH_DMA_CORR_ERROR)\r\nreturn -EUCLEAN;\r\nreturn 0;\r\n}\r\nstatic int brcmnand_read_by_pio(struct mtd_info *mtd, struct nand_chip *chip,\r\nu64 addr, unsigned int trans, u32 *buf,\r\nu8 *oob, u64 *err_addr)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nint i, j, ret = 0;\r\nbrcmnand_write_reg(ctrl, BRCMNAND_UNCORR_ADDR, 0);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CORR_ADDR, 0);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_UNCORR_EXT_ADDR, 0);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CORR_EXT_ADDR, 0);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CMD_EXT_ADDRESS,\r\n(host->cs << 16) | ((addr >> 32) & 0xffff));\r\n(void)brcmnand_read_reg(ctrl, BRCMNAND_CMD_EXT_ADDRESS);\r\nfor (i = 0; i < trans; i++, addr += FC_BYTES) {\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CMD_ADDRESS,\r\nlower_32_bits(addr));\r\n(void)brcmnand_read_reg(ctrl, BRCMNAND_CMD_ADDRESS);\r\nbrcmnand_send_cmd(host, CMD_PAGE_READ);\r\nbrcmnand_waitfunc(mtd, chip);\r\nif (likely(buf)) {\r\nbrcmnand_soc_data_bus_prepare(ctrl->soc, false);\r\nfor (j = 0; j < FC_WORDS; j++, buf++)\r\n*buf = brcmnand_read_fc(ctrl, j);\r\nbrcmnand_soc_data_bus_unprepare(ctrl->soc, false);\r\n}\r\nif (oob)\r\noob += read_oob_from_regs(ctrl, i, oob,\r\nmtd->oobsize / trans,\r\nhost->hwcfg.sector_size_1k);\r\nif (!ret) {\r\n*err_addr = brcmnand_read_reg(ctrl,\r\nBRCMNAND_UNCORR_ADDR) |\r\n((u64)(brcmnand_read_reg(ctrl,\r\nBRCMNAND_UNCORR_EXT_ADDR)\r\n& 0xffff) << 32);\r\nif (*err_addr)\r\nret = -EBADMSG;\r\n}\r\nif (!ret) {\r\n*err_addr = brcmnand_read_reg(ctrl,\r\nBRCMNAND_CORR_ADDR) |\r\n((u64)(brcmnand_read_reg(ctrl,\r\nBRCMNAND_CORR_EXT_ADDR)\r\n& 0xffff) << 32);\r\nif (*err_addr)\r\nret = -EUCLEAN;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int brcmstb_nand_verify_erased_page(struct mtd_info *mtd,\r\nstruct nand_chip *chip, void *buf, u64 addr)\r\n{\r\nint i, sas;\r\nvoid *oob = chip->oob_poi;\r\nint bitflips = 0;\r\nint page = addr >> chip->page_shift;\r\nint ret;\r\nif (!buf) {\r\nbuf = chip->buffers->databuf;\r\nchip->pagebuf = -1;\r\n}\r\nsas = mtd->oobsize / chip->ecc.steps;\r\nchip->cmdfunc(mtd, NAND_CMD_READ0, 0x00, page);\r\nret = chip->ecc.read_page_raw(mtd, chip, buf, true, page);\r\nif (ret)\r\nreturn ret;\r\nfor (i = 0; i < chip->ecc.steps; i++, oob += sas) {\r\nret = nand_check_erased_ecc_chunk(buf, chip->ecc.size,\r\noob, sas, NULL, 0,\r\nchip->ecc.strength);\r\nif (ret < 0)\r\nreturn ret;\r\nbitflips = max(bitflips, ret);\r\n}\r\nreturn bitflips;\r\n}\r\nstatic int brcmnand_read(struct mtd_info *mtd, struct nand_chip *chip,\r\nu64 addr, unsigned int trans, u32 *buf, u8 *oob)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nu64 err_addr = 0;\r\nint err;\r\nbool retry = true;\r\ndev_dbg(ctrl->dev, "read %llx -> %p\n", (unsigned long long)addr, buf);\r\ntry_dmaread:\r\nbrcmnand_write_reg(ctrl, BRCMNAND_UNCORR_COUNT, 0);\r\nif (has_flash_dma(ctrl) && !oob && flash_dma_buf_ok(buf)) {\r\nerr = brcmnand_dma_trans(host, addr, buf, trans * FC_BYTES,\r\nCMD_PAGE_READ);\r\nif (err) {\r\nif (mtd_is_bitflip_or_eccerr(err))\r\nerr_addr = addr;\r\nelse\r\nreturn -EIO;\r\n}\r\n} else {\r\nif (oob)\r\nmemset(oob, 0x99, mtd->oobsize);\r\nerr = brcmnand_read_by_pio(mtd, chip, addr, trans, buf,\r\noob, &err_addr);\r\n}\r\nif (mtd_is_eccerr(err)) {\r\nif ((ctrl->nand_version == 0x0700) ||\r\n(ctrl->nand_version == 0x0701)) {\r\nif (retry) {\r\nretry = false;\r\ngoto try_dmaread;\r\n}\r\n}\r\nif (ctrl->nand_version < 0x0702) {\r\nerr = brcmstb_nand_verify_erased_page(mtd, chip, buf,\r\naddr);\r\nif (err > 0)\r\nreturn err;\r\n}\r\ndev_dbg(ctrl->dev, "uncorrectable error at 0x%llx\n",\r\n(unsigned long long)err_addr);\r\nmtd->ecc_stats.failed++;\r\nreturn 0;\r\n}\r\nif (mtd_is_bitflip(err)) {\r\nunsigned int corrected = brcmnand_count_corrected(ctrl);\r\ndev_dbg(ctrl->dev, "corrected error at 0x%llx\n",\r\n(unsigned long long)err_addr);\r\nmtd->ecc_stats.corrected += corrected;\r\nreturn max(mtd->bitflip_threshold, corrected);\r\n}\r\nreturn 0;\r\n}\r\nstatic int brcmnand_read_page(struct mtd_info *mtd, struct nand_chip *chip,\r\nuint8_t *buf, int oob_required, int page)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nu8 *oob = oob_required ? (u8 *)chip->oob_poi : NULL;\r\nreturn brcmnand_read(mtd, chip, host->last_addr,\r\nmtd->writesize >> FC_SHIFT, (u32 *)buf, oob);\r\n}\r\nstatic int brcmnand_read_page_raw(struct mtd_info *mtd, struct nand_chip *chip,\r\nuint8_t *buf, int oob_required, int page)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nu8 *oob = oob_required ? (u8 *)chip->oob_poi : NULL;\r\nint ret;\r\nbrcmnand_set_ecc_enabled(host, 0);\r\nret = brcmnand_read(mtd, chip, host->last_addr,\r\nmtd->writesize >> FC_SHIFT, (u32 *)buf, oob);\r\nbrcmnand_set_ecc_enabled(host, 1);\r\nreturn ret;\r\n}\r\nstatic int brcmnand_read_oob(struct mtd_info *mtd, struct nand_chip *chip,\r\nint page)\r\n{\r\nreturn brcmnand_read(mtd, chip, (u64)page << chip->page_shift,\r\nmtd->writesize >> FC_SHIFT,\r\nNULL, (u8 *)chip->oob_poi);\r\n}\r\nstatic int brcmnand_read_oob_raw(struct mtd_info *mtd, struct nand_chip *chip,\r\nint page)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nbrcmnand_set_ecc_enabled(host, 0);\r\nbrcmnand_read(mtd, chip, (u64)page << chip->page_shift,\r\nmtd->writesize >> FC_SHIFT,\r\nNULL, (u8 *)chip->oob_poi);\r\nbrcmnand_set_ecc_enabled(host, 1);\r\nreturn 0;\r\n}\r\nstatic int brcmnand_write(struct mtd_info *mtd, struct nand_chip *chip,\r\nu64 addr, const u32 *buf, u8 *oob)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nunsigned int i, j, trans = mtd->writesize >> FC_SHIFT;\r\nint status, ret = 0;\r\ndev_dbg(ctrl->dev, "write %llx <- %p\n", (unsigned long long)addr, buf);\r\nif (unlikely((unsigned long)buf & 0x03)) {\r\ndev_warn(ctrl->dev, "unaligned buffer: %p\n", buf);\r\nbuf = (u32 *)((unsigned long)buf & ~0x03);\r\n}\r\nbrcmnand_wp(mtd, 0);\r\nfor (i = 0; i < ctrl->max_oob; i += 4)\r\noob_reg_write(ctrl, i, 0xffffffff);\r\nif (has_flash_dma(ctrl) && !oob && flash_dma_buf_ok(buf)) {\r\nif (brcmnand_dma_trans(host, addr, (u32 *)buf,\r\nmtd->writesize, CMD_PROGRAM_PAGE))\r\nret = -EIO;\r\ngoto out;\r\n}\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CMD_EXT_ADDRESS,\r\n(host->cs << 16) | ((addr >> 32) & 0xffff));\r\n(void)brcmnand_read_reg(ctrl, BRCMNAND_CMD_EXT_ADDRESS);\r\nfor (i = 0; i < trans; i++, addr += FC_BYTES) {\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CMD_ADDRESS,\r\nlower_32_bits(addr));\r\n(void)brcmnand_read_reg(ctrl, BRCMNAND_CMD_ADDRESS);\r\nif (buf) {\r\nbrcmnand_soc_data_bus_prepare(ctrl->soc, false);\r\nfor (j = 0; j < FC_WORDS; j++, buf++)\r\nbrcmnand_write_fc(ctrl, j, *buf);\r\nbrcmnand_soc_data_bus_unprepare(ctrl->soc, false);\r\n} else if (oob) {\r\nfor (j = 0; j < FC_WORDS; j++)\r\nbrcmnand_write_fc(ctrl, j, 0xffffffff);\r\n}\r\nif (oob) {\r\noob += write_oob_to_regs(ctrl, i, oob,\r\nmtd->oobsize / trans,\r\nhost->hwcfg.sector_size_1k);\r\n}\r\nbrcmnand_send_cmd(host, CMD_PROGRAM_PAGE);\r\nstatus = brcmnand_waitfunc(mtd, chip);\r\nif (status & NAND_STATUS_FAIL) {\r\ndev_info(ctrl->dev, "program failed at %llx\n",\r\n(unsigned long long)addr);\r\nret = -EIO;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nbrcmnand_wp(mtd, 1);\r\nreturn ret;\r\n}\r\nstatic int brcmnand_write_page(struct mtd_info *mtd, struct nand_chip *chip,\r\nconst uint8_t *buf, int oob_required, int page)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nvoid *oob = oob_required ? chip->oob_poi : NULL;\r\nbrcmnand_write(mtd, chip, host->last_addr, (const u32 *)buf, oob);\r\nreturn 0;\r\n}\r\nstatic int brcmnand_write_page_raw(struct mtd_info *mtd,\r\nstruct nand_chip *chip, const uint8_t *buf,\r\nint oob_required, int page)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nvoid *oob = oob_required ? chip->oob_poi : NULL;\r\nbrcmnand_set_ecc_enabled(host, 0);\r\nbrcmnand_write(mtd, chip, host->last_addr, (const u32 *)buf, oob);\r\nbrcmnand_set_ecc_enabled(host, 1);\r\nreturn 0;\r\n}\r\nstatic int brcmnand_write_oob(struct mtd_info *mtd, struct nand_chip *chip,\r\nint page)\r\n{\r\nreturn brcmnand_write(mtd, chip, (u64)page << chip->page_shift,\r\nNULL, chip->oob_poi);\r\n}\r\nstatic int brcmnand_write_oob_raw(struct mtd_info *mtd, struct nand_chip *chip,\r\nint page)\r\n{\r\nstruct brcmnand_host *host = nand_get_controller_data(chip);\r\nint ret;\r\nbrcmnand_set_ecc_enabled(host, 0);\r\nret = brcmnand_write(mtd, chip, (u64)page << chip->page_shift, NULL,\r\n(u8 *)chip->oob_poi);\r\nbrcmnand_set_ecc_enabled(host, 1);\r\nreturn ret;\r\n}\r\nstatic int brcmnand_set_cfg(struct brcmnand_host *host,\r\nstruct brcmnand_cfg *cfg)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nstruct nand_chip *chip = &host->chip;\r\nu16 cfg_offs = brcmnand_cs_offset(ctrl, host->cs, BRCMNAND_CS_CFG);\r\nu16 cfg_ext_offs = brcmnand_cs_offset(ctrl, host->cs,\r\nBRCMNAND_CS_CFG_EXT);\r\nu16 acc_control_offs = brcmnand_cs_offset(ctrl, host->cs,\r\nBRCMNAND_CS_ACC_CONTROL);\r\nu8 block_size = 0, page_size = 0, device_size = 0;\r\nu32 tmp;\r\nif (ctrl->block_sizes) {\r\nint i, found;\r\nfor (i = 0, found = 0; ctrl->block_sizes[i]; i++)\r\nif (ctrl->block_sizes[i] * 1024 == cfg->block_size) {\r\nblock_size = i;\r\nfound = 1;\r\n}\r\nif (!found) {\r\ndev_warn(ctrl->dev, "invalid block size %u\n",\r\ncfg->block_size);\r\nreturn -EINVAL;\r\n}\r\n} else {\r\nblock_size = ffs(cfg->block_size) - ffs(BRCMNAND_MIN_BLOCKSIZE);\r\n}\r\nif (cfg->block_size < BRCMNAND_MIN_BLOCKSIZE || (ctrl->max_block_size &&\r\ncfg->block_size > ctrl->max_block_size)) {\r\ndev_warn(ctrl->dev, "invalid block size %u\n",\r\ncfg->block_size);\r\nblock_size = 0;\r\n}\r\nif (ctrl->page_sizes) {\r\nint i, found;\r\nfor (i = 0, found = 0; ctrl->page_sizes[i]; i++)\r\nif (ctrl->page_sizes[i] == cfg->page_size) {\r\npage_size = i;\r\nfound = 1;\r\n}\r\nif (!found) {\r\ndev_warn(ctrl->dev, "invalid page size %u\n",\r\ncfg->page_size);\r\nreturn -EINVAL;\r\n}\r\n} else {\r\npage_size = ffs(cfg->page_size) - ffs(BRCMNAND_MIN_PAGESIZE);\r\n}\r\nif (cfg->page_size < BRCMNAND_MIN_PAGESIZE || (ctrl->max_page_size &&\r\ncfg->page_size > ctrl->max_page_size)) {\r\ndev_warn(ctrl->dev, "invalid page size %u\n", cfg->page_size);\r\nreturn -EINVAL;\r\n}\r\nif (fls64(cfg->device_size) < fls64(BRCMNAND_MIN_DEVSIZE)) {\r\ndev_warn(ctrl->dev, "invalid device size 0x%llx\n",\r\n(unsigned long long)cfg->device_size);\r\nreturn -EINVAL;\r\n}\r\ndevice_size = fls64(cfg->device_size) - fls64(BRCMNAND_MIN_DEVSIZE);\r\ntmp = (cfg->blk_adr_bytes << CFG_BLK_ADR_BYTES_SHIFT) |\r\n(cfg->col_adr_bytes << CFG_COL_ADR_BYTES_SHIFT) |\r\n(cfg->ful_adr_bytes << CFG_FUL_ADR_BYTES_SHIFT) |\r\n(!!(cfg->device_width == 16) << CFG_BUS_WIDTH_SHIFT) |\r\n(device_size << CFG_DEVICE_SIZE_SHIFT);\r\nif (cfg_offs == cfg_ext_offs) {\r\ntmp |= (page_size << CFG_PAGE_SIZE_SHIFT) |\r\n(block_size << CFG_BLK_SIZE_SHIFT);\r\nnand_writereg(ctrl, cfg_offs, tmp);\r\n} else {\r\nnand_writereg(ctrl, cfg_offs, tmp);\r\ntmp = (page_size << CFG_EXT_PAGE_SIZE_SHIFT) |\r\n(block_size << CFG_EXT_BLK_SIZE_SHIFT);\r\nnand_writereg(ctrl, cfg_ext_offs, tmp);\r\n}\r\ntmp = nand_readreg(ctrl, acc_control_offs);\r\ntmp &= ~brcmnand_ecc_level_mask(ctrl);\r\ntmp |= cfg->ecc_level << NAND_ACC_CONTROL_ECC_SHIFT;\r\ntmp &= ~brcmnand_spare_area_mask(ctrl);\r\ntmp |= cfg->spare_area_size;\r\nnand_writereg(ctrl, acc_control_offs, tmp);\r\nbrcmnand_set_sector_size_1k(host, cfg->sector_size_1k);\r\nbrcmnand_wr_corr_thresh(host, DIV_ROUND_UP(chip->ecc.strength * 3, 4));\r\nreturn 0;\r\n}\r\nstatic void brcmnand_print_cfg(struct brcmnand_host *host,\r\nchar *buf, struct brcmnand_cfg *cfg)\r\n{\r\nbuf += sprintf(buf,\r\n"%lluMiB total, %uKiB blocks, %u%s pages, %uB OOB, %u-bit",\r\n(unsigned long long)cfg->device_size >> 20,\r\ncfg->block_size >> 10,\r\ncfg->page_size >= 1024 ? cfg->page_size >> 10 : cfg->page_size,\r\ncfg->page_size >= 1024 ? "KiB" : "B",\r\ncfg->spare_area_size, cfg->device_width);\r\nif (is_hamming_ecc(host->ctrl, cfg))\r\nsprintf(buf, ", Hamming ECC");\r\nelse if (cfg->sector_size_1k)\r\nsprintf(buf, ", BCH-%u (1KiB sector)", cfg->ecc_level << 1);\r\nelse\r\nsprintf(buf, ", BCH-%u", cfg->ecc_level);\r\n}\r\nstatic inline int get_blk_adr_bytes(u64 size, u32 writesize)\r\n{\r\nreturn ALIGN(ilog2(size) - ilog2(writesize), 8) >> 3;\r\n}\r\nstatic int brcmnand_setup_dev(struct brcmnand_host *host)\r\n{\r\nstruct mtd_info *mtd = nand_to_mtd(&host->chip);\r\nstruct nand_chip *chip = &host->chip;\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nstruct brcmnand_cfg *cfg = &host->hwcfg;\r\nchar msg[128];\r\nu32 offs, tmp, oob_sector;\r\nint ret;\r\nmemset(cfg, 0, sizeof(*cfg));\r\nret = of_property_read_u32(nand_get_flash_node(chip),\r\n"brcm,nand-oob-sector-size",\r\n&oob_sector);\r\nif (ret) {\r\ncfg->spare_area_size = mtd->oobsize /\r\n(mtd->writesize >> FC_SHIFT);\r\n} else {\r\ncfg->spare_area_size = oob_sector;\r\n}\r\nif (cfg->spare_area_size > ctrl->max_oob)\r\ncfg->spare_area_size = ctrl->max_oob;\r\nmtd->oobsize = cfg->spare_area_size * (mtd->writesize >> FC_SHIFT);\r\ncfg->device_size = mtd->size;\r\ncfg->block_size = mtd->erasesize;\r\ncfg->page_size = mtd->writesize;\r\ncfg->device_width = (chip->options & NAND_BUSWIDTH_16) ? 16 : 8;\r\ncfg->col_adr_bytes = 2;\r\ncfg->blk_adr_bytes = get_blk_adr_bytes(mtd->size, mtd->writesize);\r\nif (chip->ecc.mode != NAND_ECC_HW) {\r\ndev_err(ctrl->dev, "only HW ECC supported; selected: %d\n",\r\nchip->ecc.mode);\r\nreturn -EINVAL;\r\n}\r\nif (chip->ecc.algo == NAND_ECC_UNKNOWN) {\r\nif (chip->ecc.strength == 1 && chip->ecc.size == 512)\r\nchip->ecc.algo = NAND_ECC_HAMMING;\r\nelse\r\nchip->ecc.algo = NAND_ECC_BCH;\r\n}\r\nif (chip->ecc.algo == NAND_ECC_HAMMING && (chip->ecc.strength != 1 ||\r\nchip->ecc.size != 512)) {\r\ndev_err(ctrl->dev, "invalid Hamming params: %d bits per %d bytes\n",\r\nchip->ecc.strength, chip->ecc.size);\r\nreturn -EINVAL;\r\n}\r\nswitch (chip->ecc.size) {\r\ncase 512:\r\nif (chip->ecc.algo == NAND_ECC_HAMMING)\r\ncfg->ecc_level = 15;\r\nelse\r\ncfg->ecc_level = chip->ecc.strength;\r\ncfg->sector_size_1k = 0;\r\nbreak;\r\ncase 1024:\r\nif (!(ctrl->features & BRCMNAND_HAS_1K_SECTORS)) {\r\ndev_err(ctrl->dev, "1KB sectors not supported\n");\r\nreturn -EINVAL;\r\n}\r\nif (chip->ecc.strength & 0x1) {\r\ndev_err(ctrl->dev,\r\n"odd ECC not supported with 1KB sectors\n");\r\nreturn -EINVAL;\r\n}\r\ncfg->ecc_level = chip->ecc.strength >> 1;\r\ncfg->sector_size_1k = 1;\r\nbreak;\r\ndefault:\r\ndev_err(ctrl->dev, "unsupported ECC size: %d\n",\r\nchip->ecc.size);\r\nreturn -EINVAL;\r\n}\r\ncfg->ful_adr_bytes = cfg->blk_adr_bytes;\r\nif (mtd->writesize > 512)\r\ncfg->ful_adr_bytes += cfg->col_adr_bytes;\r\nelse\r\ncfg->ful_adr_bytes += 1;\r\nret = brcmnand_set_cfg(host, cfg);\r\nif (ret)\r\nreturn ret;\r\nbrcmnand_set_ecc_enabled(host, 1);\r\nbrcmnand_print_cfg(host, msg, cfg);\r\ndev_info(ctrl->dev, "detected %s\n", msg);\r\noffs = brcmnand_cs_offset(ctrl, host->cs, BRCMNAND_CS_ACC_CONTROL);\r\ntmp = nand_readreg(ctrl, offs);\r\ntmp &= ~ACC_CONTROL_PARTIAL_PAGE;\r\ntmp &= ~ACC_CONTROL_RD_ERASED;\r\nif (ctrl->nand_version >= 0x0702)\r\ntmp |= ACC_CONTROL_RD_ERASED;\r\ntmp &= ~ACC_CONTROL_FAST_PGM_RDIN;\r\nif (ctrl->features & BRCMNAND_HAS_PREFETCH) {\r\nif (has_flash_dma(ctrl))\r\ntmp &= ~ACC_CONTROL_PREFETCH;\r\nelse\r\ntmp |= ACC_CONTROL_PREFETCH;\r\n}\r\nnand_writereg(ctrl, offs, tmp);\r\nreturn 0;\r\n}\r\nstatic int brcmnand_init_cs(struct brcmnand_host *host, struct device_node *dn)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nstruct platform_device *pdev = host->pdev;\r\nstruct mtd_info *mtd;\r\nstruct nand_chip *chip;\r\nint ret;\r\nu16 cfg_offs;\r\nret = of_property_read_u32(dn, "reg", &host->cs);\r\nif (ret) {\r\ndev_err(&pdev->dev, "can't get chip-select\n");\r\nreturn -ENXIO;\r\n}\r\nmtd = nand_to_mtd(&host->chip);\r\nchip = &host->chip;\r\nnand_set_flash_node(chip, dn);\r\nnand_set_controller_data(chip, host);\r\nmtd->name = devm_kasprintf(&pdev->dev, GFP_KERNEL, "brcmnand.%d",\r\nhost->cs);\r\nmtd->owner = THIS_MODULE;\r\nmtd->dev.parent = &pdev->dev;\r\nchip->IO_ADDR_R = (void __iomem *)0xdeadbeef;\r\nchip->IO_ADDR_W = (void __iomem *)0xdeadbeef;\r\nchip->cmd_ctrl = brcmnand_cmd_ctrl;\r\nchip->cmdfunc = brcmnand_cmdfunc;\r\nchip->waitfunc = brcmnand_waitfunc;\r\nchip->read_byte = brcmnand_read_byte;\r\nchip->read_buf = brcmnand_read_buf;\r\nchip->write_buf = brcmnand_write_buf;\r\nchip->ecc.mode = NAND_ECC_HW;\r\nchip->ecc.read_page = brcmnand_read_page;\r\nchip->ecc.write_page = brcmnand_write_page;\r\nchip->ecc.read_page_raw = brcmnand_read_page_raw;\r\nchip->ecc.write_page_raw = brcmnand_write_page_raw;\r\nchip->ecc.write_oob_raw = brcmnand_write_oob_raw;\r\nchip->ecc.read_oob_raw = brcmnand_read_oob_raw;\r\nchip->ecc.read_oob = brcmnand_read_oob;\r\nchip->ecc.write_oob = brcmnand_write_oob;\r\nchip->controller = &ctrl->controller;\r\ncfg_offs = brcmnand_cs_offset(ctrl, host->cs, BRCMNAND_CS_CFG);\r\nnand_writereg(ctrl, cfg_offs,\r\nnand_readreg(ctrl, cfg_offs) & ~CFG_BUS_WIDTH);\r\nret = nand_scan_ident(mtd, 1, NULL);\r\nif (ret)\r\nreturn ret;\r\nchip->options |= NAND_NO_SUBPAGE_WRITE;\r\nchip->options |= NAND_USE_BOUNCE_BUFFER;\r\nif (chip->bbt_options & NAND_BBT_USE_FLASH)\r\nchip->bbt_options |= NAND_BBT_NO_OOB;\r\nif (brcmnand_setup_dev(host))\r\nreturn -ENXIO;\r\nchip->ecc.size = host->hwcfg.sector_size_1k ? 1024 : 512;\r\nmtd->bitflip_threshold = 1;\r\nret = brcmstb_choose_ecc_layout(host);\r\nif (ret)\r\nreturn ret;\r\nret = nand_scan_tail(mtd);\r\nif (ret)\r\nreturn ret;\r\nreturn mtd_device_register(mtd, NULL, 0);\r\n}\r\nstatic void brcmnand_save_restore_cs_config(struct brcmnand_host *host,\r\nint restore)\r\n{\r\nstruct brcmnand_controller *ctrl = host->ctrl;\r\nu16 cfg_offs = brcmnand_cs_offset(ctrl, host->cs, BRCMNAND_CS_CFG);\r\nu16 cfg_ext_offs = brcmnand_cs_offset(ctrl, host->cs,\r\nBRCMNAND_CS_CFG_EXT);\r\nu16 acc_control_offs = brcmnand_cs_offset(ctrl, host->cs,\r\nBRCMNAND_CS_ACC_CONTROL);\r\nu16 t1_offs = brcmnand_cs_offset(ctrl, host->cs, BRCMNAND_CS_TIMING1);\r\nu16 t2_offs = brcmnand_cs_offset(ctrl, host->cs, BRCMNAND_CS_TIMING2);\r\nif (restore) {\r\nnand_writereg(ctrl, cfg_offs, host->hwcfg.config);\r\nif (cfg_offs != cfg_ext_offs)\r\nnand_writereg(ctrl, cfg_ext_offs,\r\nhost->hwcfg.config_ext);\r\nnand_writereg(ctrl, acc_control_offs, host->hwcfg.acc_control);\r\nnand_writereg(ctrl, t1_offs, host->hwcfg.timing_1);\r\nnand_writereg(ctrl, t2_offs, host->hwcfg.timing_2);\r\n} else {\r\nhost->hwcfg.config = nand_readreg(ctrl, cfg_offs);\r\nif (cfg_offs != cfg_ext_offs)\r\nhost->hwcfg.config_ext =\r\nnand_readreg(ctrl, cfg_ext_offs);\r\nhost->hwcfg.acc_control = nand_readreg(ctrl, acc_control_offs);\r\nhost->hwcfg.timing_1 = nand_readreg(ctrl, t1_offs);\r\nhost->hwcfg.timing_2 = nand_readreg(ctrl, t2_offs);\r\n}\r\n}\r\nstatic int brcmnand_suspend(struct device *dev)\r\n{\r\nstruct brcmnand_controller *ctrl = dev_get_drvdata(dev);\r\nstruct brcmnand_host *host;\r\nlist_for_each_entry(host, &ctrl->host_list, node)\r\nbrcmnand_save_restore_cs_config(host, 0);\r\nctrl->nand_cs_nand_select = brcmnand_read_reg(ctrl, BRCMNAND_CS_SELECT);\r\nctrl->nand_cs_nand_xor = brcmnand_read_reg(ctrl, BRCMNAND_CS_XOR);\r\nctrl->corr_stat_threshold =\r\nbrcmnand_read_reg(ctrl, BRCMNAND_CORR_THRESHOLD);\r\nif (has_flash_dma(ctrl))\r\nctrl->flash_dma_mode = flash_dma_readl(ctrl, FLASH_DMA_MODE);\r\nreturn 0;\r\n}\r\nstatic int brcmnand_resume(struct device *dev)\r\n{\r\nstruct brcmnand_controller *ctrl = dev_get_drvdata(dev);\r\nstruct brcmnand_host *host;\r\nif (has_flash_dma(ctrl)) {\r\nflash_dma_writel(ctrl, FLASH_DMA_MODE, ctrl->flash_dma_mode);\r\nflash_dma_writel(ctrl, FLASH_DMA_ERROR_STATUS, 0);\r\n}\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CS_SELECT, ctrl->nand_cs_nand_select);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CS_XOR, ctrl->nand_cs_nand_xor);\r\nbrcmnand_write_reg(ctrl, BRCMNAND_CORR_THRESHOLD,\r\nctrl->corr_stat_threshold);\r\nif (ctrl->soc) {\r\nctrl->soc->ctlrdy_ack(ctrl->soc);\r\nctrl->soc->ctlrdy_set_enabled(ctrl->soc, true);\r\n}\r\nlist_for_each_entry(host, &ctrl->host_list, node) {\r\nstruct nand_chip *chip = &host->chip;\r\nstruct mtd_info *mtd = nand_to_mtd(chip);\r\nbrcmnand_save_restore_cs_config(host, 1);\r\nchip->cmdfunc(mtd, NAND_CMD_RESET, -1, -1);\r\n}\r\nreturn 0;\r\n}\r\nint brcmnand_probe(struct platform_device *pdev, struct brcmnand_soc *soc)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct device_node *dn = dev->of_node, *child;\r\nstruct brcmnand_controller *ctrl;\r\nstruct resource *res;\r\nint ret;\r\nif (!dn)\r\nreturn -ENODEV;\r\nif (!of_match_node(brcmnand_of_match, dn))\r\nreturn -ENODEV;\r\nctrl = devm_kzalloc(dev, sizeof(*ctrl), GFP_KERNEL);\r\nif (!ctrl)\r\nreturn -ENOMEM;\r\ndev_set_drvdata(dev, ctrl);\r\nctrl->dev = dev;\r\ninit_completion(&ctrl->done);\r\ninit_completion(&ctrl->dma_done);\r\nnand_hw_control_init(&ctrl->controller);\r\nINIT_LIST_HEAD(&ctrl->host_list);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nctrl->nand_base = devm_ioremap_resource(dev, res);\r\nif (IS_ERR(ctrl->nand_base))\r\nreturn PTR_ERR(ctrl->nand_base);\r\nctrl->clk = devm_clk_get(dev, "nand");\r\nif (!IS_ERR(ctrl->clk)) {\r\nret = clk_prepare_enable(ctrl->clk);\r\nif (ret)\r\nreturn ret;\r\n} else {\r\nret = PTR_ERR(ctrl->clk);\r\nif (ret == -EPROBE_DEFER)\r\nreturn ret;\r\nctrl->clk = NULL;\r\n}\r\nret = brcmnand_revision_init(ctrl);\r\nif (ret)\r\ngoto err;\r\nres = platform_get_resource_byname(pdev, IORESOURCE_MEM, "nand-cache");\r\nif (res) {\r\nctrl->nand_fc = devm_ioremap_resource(dev, res);\r\nif (IS_ERR(ctrl->nand_fc)) {\r\nret = PTR_ERR(ctrl->nand_fc);\r\ngoto err;\r\n}\r\n} else {\r\nctrl->nand_fc = ctrl->nand_base +\r\nctrl->reg_offsets[BRCMNAND_FC_BASE];\r\n}\r\nres = platform_get_resource_byname(pdev, IORESOURCE_MEM, "flash-dma");\r\nif (res) {\r\nctrl->flash_dma_base = devm_ioremap_resource(dev, res);\r\nif (IS_ERR(ctrl->flash_dma_base)) {\r\nret = PTR_ERR(ctrl->flash_dma_base);\r\ngoto err;\r\n}\r\nflash_dma_writel(ctrl, FLASH_DMA_MODE, 1);\r\nflash_dma_writel(ctrl, FLASH_DMA_ERROR_STATUS, 0);\r\nctrl->dma_desc = dmam_alloc_coherent(dev,\r\nsizeof(*ctrl->dma_desc),\r\n&ctrl->dma_pa, GFP_KERNEL);\r\nif (!ctrl->dma_desc) {\r\nret = -ENOMEM;\r\ngoto err;\r\n}\r\nctrl->dma_irq = platform_get_irq(pdev, 1);\r\nif ((int)ctrl->dma_irq < 0) {\r\ndev_err(dev, "missing FLASH_DMA IRQ\n");\r\nret = -ENODEV;\r\ngoto err;\r\n}\r\nret = devm_request_irq(dev, ctrl->dma_irq,\r\nbrcmnand_dma_irq, 0, DRV_NAME,\r\nctrl);\r\nif (ret < 0) {\r\ndev_err(dev, "can't allocate IRQ %d: error %d\n",\r\nctrl->dma_irq, ret);\r\ngoto err;\r\n}\r\ndev_info(dev, "enabling FLASH_DMA\n");\r\n}\r\nbrcmnand_rmw_reg(ctrl, BRCMNAND_CS_SELECT,\r\nCS_SELECT_AUTO_DEVICE_ID_CFG | 0xff, 0, 0);\r\nbrcmnand_rmw_reg(ctrl, BRCMNAND_CS_XOR, 0xff, 0, 0);\r\nif (ctrl->features & BRCMNAND_HAS_WP) {\r\nif (wp_on == 2)\r\nbrcmnand_set_wp(ctrl, false);\r\n} else {\r\nwp_on = 0;\r\n}\r\nctrl->irq = platform_get_irq(pdev, 0);\r\nif ((int)ctrl->irq < 0) {\r\ndev_err(dev, "no IRQ defined\n");\r\nret = -ENODEV;\r\ngoto err;\r\n}\r\nif (soc) {\r\nctrl->soc = soc;\r\nret = devm_request_irq(dev, ctrl->irq, brcmnand_irq, 0,\r\nDRV_NAME, ctrl);\r\nctrl->soc->ctlrdy_ack(ctrl->soc);\r\nctrl->soc->ctlrdy_set_enabled(ctrl->soc, true);\r\n} else {\r\nret = devm_request_irq(dev, ctrl->irq, brcmnand_ctlrdy_irq, 0,\r\nDRV_NAME, ctrl);\r\n}\r\nif (ret < 0) {\r\ndev_err(dev, "can't allocate IRQ %d: error %d\n",\r\nctrl->irq, ret);\r\ngoto err;\r\n}\r\nfor_each_available_child_of_node(dn, child) {\r\nif (of_device_is_compatible(child, "brcm,nandcs")) {\r\nstruct brcmnand_host *host;\r\nhost = devm_kzalloc(dev, sizeof(*host), GFP_KERNEL);\r\nif (!host) {\r\nof_node_put(child);\r\nret = -ENOMEM;\r\ngoto err;\r\n}\r\nhost->pdev = pdev;\r\nhost->ctrl = ctrl;\r\nret = brcmnand_init_cs(host, child);\r\nif (ret) {\r\ndevm_kfree(dev, host);\r\ncontinue;\r\n}\r\nlist_add_tail(&host->node, &ctrl->host_list);\r\n}\r\n}\r\nif (list_empty(&ctrl->host_list)) {\r\nret = -ENODEV;\r\ngoto err;\r\n}\r\nreturn 0;\r\nerr:\r\nclk_disable_unprepare(ctrl->clk);\r\nreturn ret;\r\n}\r\nint brcmnand_remove(struct platform_device *pdev)\r\n{\r\nstruct brcmnand_controller *ctrl = dev_get_drvdata(&pdev->dev);\r\nstruct brcmnand_host *host;\r\nlist_for_each_entry(host, &ctrl->host_list, node)\r\nnand_release(nand_to_mtd(&host->chip));\r\nclk_disable_unprepare(ctrl->clk);\r\ndev_set_drvdata(&pdev->dev, NULL);\r\nreturn 0;\r\n}
