static ktime_t mmdc_pmu_timer_period(void)\r\n{\r\nreturn ns_to_ktime((u64)mmdc_pmu_poll_period_us * 1000);\r\n}\r\nstatic ssize_t mmdc_pmu_cpumask_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = dev_get_drvdata(dev);\r\nreturn cpumap_print_to_pagebuf(true, buf, &pmu_mmdc->cpu);\r\n}\r\nstatic u32 mmdc_pmu_read_counter(struct mmdc_pmu *pmu_mmdc, int cfg)\r\n{\r\nvoid __iomem *mmdc_base, *reg;\r\nmmdc_base = pmu_mmdc->mmdc_base;\r\nswitch (cfg) {\r\ncase TOTAL_CYCLES:\r\nreg = mmdc_base + MMDC_MADPSR0;\r\nbreak;\r\ncase BUSY_CYCLES:\r\nreg = mmdc_base + MMDC_MADPSR1;\r\nbreak;\r\ncase READ_ACCESSES:\r\nreg = mmdc_base + MMDC_MADPSR2;\r\nbreak;\r\ncase WRITE_ACCESSES:\r\nreg = mmdc_base + MMDC_MADPSR3;\r\nbreak;\r\ncase READ_BYTES:\r\nreg = mmdc_base + MMDC_MADPSR4;\r\nbreak;\r\ncase WRITE_BYTES:\r\nreg = mmdc_base + MMDC_MADPSR5;\r\nbreak;\r\ndefault:\r\nreturn WARN_ONCE(1,\r\n"invalid configuration %d for mmdc counter", cfg);\r\n}\r\nreturn readl(reg);\r\n}\r\nstatic int mmdc_pmu_offline_cpu(unsigned int cpu, struct hlist_node *node)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = hlist_entry_safe(node, struct mmdc_pmu, node);\r\nint target;\r\nif (!cpumask_test_and_clear_cpu(cpu, &pmu_mmdc->cpu))\r\nreturn 0;\r\ntarget = cpumask_any_but(cpu_online_mask, cpu);\r\nif (target >= nr_cpu_ids)\r\nreturn 0;\r\nperf_pmu_migrate_context(&pmu_mmdc->pmu, cpu, target);\r\ncpumask_set_cpu(target, &pmu_mmdc->cpu);\r\nreturn 0;\r\n}\r\nstatic bool mmdc_pmu_group_event_is_valid(struct perf_event *event,\r\nstruct pmu *pmu,\r\nunsigned long *used_counters)\r\n{\r\nint cfg = event->attr.config;\r\nif (is_software_event(event))\r\nreturn true;\r\nif (event->pmu != pmu)\r\nreturn false;\r\nreturn !test_and_set_bit(cfg, used_counters);\r\n}\r\nstatic bool mmdc_pmu_group_is_valid(struct perf_event *event)\r\n{\r\nstruct pmu *pmu = event->pmu;\r\nstruct perf_event *leader = event->group_leader;\r\nstruct perf_event *sibling;\r\nunsigned long counter_mask = 0;\r\nset_bit(leader->attr.config, &counter_mask);\r\nif (event != leader) {\r\nif (!mmdc_pmu_group_event_is_valid(event, pmu, &counter_mask))\r\nreturn false;\r\n}\r\nlist_for_each_entry(sibling, &leader->sibling_list, group_entry) {\r\nif (!mmdc_pmu_group_event_is_valid(sibling, pmu, &counter_mask))\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic int mmdc_pmu_event_init(struct perf_event *event)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = to_mmdc_pmu(event->pmu);\r\nint cfg = event->attr.config;\r\nif (event->attr.type != event->pmu->type)\r\nreturn -ENOENT;\r\nif (is_sampling_event(event) || event->attach_state & PERF_ATTACH_TASK)\r\nreturn -EOPNOTSUPP;\r\nif (event->cpu < 0) {\r\ndev_warn(pmu_mmdc->dev, "Can't provide per-task data!\n");\r\nreturn -EOPNOTSUPP;\r\n}\r\nif (event->attr.exclude_user ||\r\nevent->attr.exclude_kernel ||\r\nevent->attr.exclude_hv ||\r\nevent->attr.exclude_idle ||\r\nevent->attr.exclude_host ||\r\nevent->attr.exclude_guest ||\r\nevent->attr.sample_period)\r\nreturn -EINVAL;\r\nif (cfg < 0 || cfg >= MMDC_NUM_COUNTERS)\r\nreturn -EINVAL;\r\nif (!mmdc_pmu_group_is_valid(event))\r\nreturn -EINVAL;\r\nevent->cpu = cpumask_first(&pmu_mmdc->cpu);\r\nreturn 0;\r\n}\r\nstatic void mmdc_pmu_event_update(struct perf_event *event)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = to_mmdc_pmu(event->pmu);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nu64 delta, prev_raw_count, new_raw_count;\r\ndo {\r\nprev_raw_count = local64_read(&hwc->prev_count);\r\nnew_raw_count = mmdc_pmu_read_counter(pmu_mmdc,\r\nevent->attr.config);\r\n} while (local64_cmpxchg(&hwc->prev_count, prev_raw_count,\r\nnew_raw_count) != prev_raw_count);\r\ndelta = (new_raw_count - prev_raw_count) & 0xFFFFFFFF;\r\nlocal64_add(delta, &event->count);\r\n}\r\nstatic void mmdc_pmu_event_start(struct perf_event *event, int flags)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = to_mmdc_pmu(event->pmu);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nvoid __iomem *mmdc_base, *reg;\r\nu32 val;\r\nmmdc_base = pmu_mmdc->mmdc_base;\r\nreg = mmdc_base + MMDC_MADPCR0;\r\nhrtimer_start(&pmu_mmdc->hrtimer, mmdc_pmu_timer_period(),\r\nHRTIMER_MODE_REL_PINNED);\r\nlocal64_set(&hwc->prev_count, 0);\r\nwritel(DBG_RST, reg);\r\nval = DBG_EN;\r\nif (pmu_mmdc->devtype_data->flags & MMDC_FLAG_PROFILE_SEL)\r\nval |= PROFILE_SEL;\r\nwritel(val, reg);\r\n}\r\nstatic int mmdc_pmu_event_add(struct perf_event *event, int flags)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = to_mmdc_pmu(event->pmu);\r\nstruct hw_perf_event *hwc = &event->hw;\r\nint cfg = event->attr.config;\r\nif (flags & PERF_EF_START)\r\nmmdc_pmu_event_start(event, flags);\r\nif (pmu_mmdc->mmdc_events[cfg] != NULL)\r\nreturn -EAGAIN;\r\npmu_mmdc->mmdc_events[cfg] = event;\r\npmu_mmdc->active_events++;\r\nlocal64_set(&hwc->prev_count, mmdc_pmu_read_counter(pmu_mmdc, cfg));\r\nreturn 0;\r\n}\r\nstatic void mmdc_pmu_event_stop(struct perf_event *event, int flags)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = to_mmdc_pmu(event->pmu);\r\nvoid __iomem *mmdc_base, *reg;\r\nmmdc_base = pmu_mmdc->mmdc_base;\r\nreg = mmdc_base + MMDC_MADPCR0;\r\nwritel(PRF_FRZ, reg);\r\nmmdc_pmu_event_update(event);\r\n}\r\nstatic void mmdc_pmu_event_del(struct perf_event *event, int flags)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = to_mmdc_pmu(event->pmu);\r\nint cfg = event->attr.config;\r\npmu_mmdc->mmdc_events[cfg] = NULL;\r\npmu_mmdc->active_events--;\r\nif (pmu_mmdc->active_events == 0)\r\nhrtimer_cancel(&pmu_mmdc->hrtimer);\r\nmmdc_pmu_event_stop(event, PERF_EF_UPDATE);\r\n}\r\nstatic void mmdc_pmu_overflow_handler(struct mmdc_pmu *pmu_mmdc)\r\n{\r\nint i;\r\nfor (i = 0; i < MMDC_NUM_COUNTERS; i++) {\r\nstruct perf_event *event = pmu_mmdc->mmdc_events[i];\r\nif (event)\r\nmmdc_pmu_event_update(event);\r\n}\r\n}\r\nstatic enum hrtimer_restart mmdc_pmu_timer_handler(struct hrtimer *hrtimer)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = container_of(hrtimer, struct mmdc_pmu,\r\nhrtimer);\r\nmmdc_pmu_overflow_handler(pmu_mmdc);\r\nhrtimer_forward_now(hrtimer, mmdc_pmu_timer_period());\r\nreturn HRTIMER_RESTART;\r\n}\r\nstatic int mmdc_pmu_init(struct mmdc_pmu *pmu_mmdc,\r\nvoid __iomem *mmdc_base, struct device *dev)\r\n{\r\nint mmdc_num;\r\n*pmu_mmdc = (struct mmdc_pmu) {\r\n.pmu = (struct pmu) {\r\n.task_ctx_nr = perf_invalid_context,\r\n.attr_groups = attr_groups,\r\n.event_init = mmdc_pmu_event_init,\r\n.add = mmdc_pmu_event_add,\r\n.del = mmdc_pmu_event_del,\r\n.start = mmdc_pmu_event_start,\r\n.stop = mmdc_pmu_event_stop,\r\n.read = mmdc_pmu_event_update,\r\n},\r\n.mmdc_base = mmdc_base,\r\n.dev = dev,\r\n.active_events = 0,\r\n};\r\nmmdc_num = ida_simple_get(&mmdc_ida, 0, 0, GFP_KERNEL);\r\nreturn mmdc_num;\r\n}\r\nstatic int imx_mmdc_remove(struct platform_device *pdev)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc = platform_get_drvdata(pdev);\r\ncpuhp_state_remove_instance_nocalls(cpuhp_mmdc_state, &pmu_mmdc->node);\r\nperf_pmu_unregister(&pmu_mmdc->pmu);\r\nkfree(pmu_mmdc);\r\nreturn 0;\r\n}\r\nstatic int imx_mmdc_perf_init(struct platform_device *pdev, void __iomem *mmdc_base)\r\n{\r\nstruct mmdc_pmu *pmu_mmdc;\r\nchar *name;\r\nint mmdc_num;\r\nint ret;\r\nconst struct of_device_id *of_id =\r\nof_match_device(imx_mmdc_dt_ids, &pdev->dev);\r\npmu_mmdc = kzalloc(sizeof(*pmu_mmdc), GFP_KERNEL);\r\nif (!pmu_mmdc) {\r\npr_err("failed to allocate PMU device!\n");\r\nreturn -ENOMEM;\r\n}\r\nif (!cpuhp_mmdc_state) {\r\nret = cpuhp_setup_state_multi(CPUHP_AP_ONLINE_DYN,\r\n"perf/arm/mmdc:online", NULL,\r\nmmdc_pmu_offline_cpu);\r\nif (ret < 0) {\r\npr_err("cpuhp_setup_state_multi failed\n");\r\ngoto pmu_free;\r\n}\r\ncpuhp_mmdc_state = ret;\r\n}\r\nmmdc_num = mmdc_pmu_init(pmu_mmdc, mmdc_base, &pdev->dev);\r\nif (mmdc_num == 0)\r\nname = "mmdc";\r\nelse\r\nname = devm_kasprintf(&pdev->dev,\r\nGFP_KERNEL, "mmdc%d", mmdc_num);\r\npmu_mmdc->devtype_data = (struct fsl_mmdc_devtype_data *)of_id->data;\r\nhrtimer_init(&pmu_mmdc->hrtimer, CLOCK_MONOTONIC,\r\nHRTIMER_MODE_REL);\r\npmu_mmdc->hrtimer.function = mmdc_pmu_timer_handler;\r\ncpumask_set_cpu(raw_smp_processor_id(), &pmu_mmdc->cpu);\r\ncpuhp_state_add_instance_nocalls(cpuhp_mmdc_state, &pmu_mmdc->node);\r\nret = perf_pmu_register(&(pmu_mmdc->pmu), name, -1);\r\nif (ret)\r\ngoto pmu_register_err;\r\nplatform_set_drvdata(pdev, pmu_mmdc);\r\nreturn 0;\r\npmu_register_err:\r\npr_warn("MMDC Perf PMU failed (%d), disabled\n", ret);\r\ncpuhp_state_remove_instance_nocalls(cpuhp_mmdc_state, &pmu_mmdc->node);\r\nhrtimer_cancel(&pmu_mmdc->hrtimer);\r\npmu_free:\r\nkfree(pmu_mmdc);\r\nreturn ret;\r\n}\r\nstatic int imx_mmdc_probe(struct platform_device *pdev)\r\n{\r\nstruct device_node *np = pdev->dev.of_node;\r\nvoid __iomem *mmdc_base, *reg;\r\nu32 val;\r\nint timeout = 0x400;\r\nmmdc_base = of_iomap(np, 0);\r\nWARN_ON(!mmdc_base);\r\nreg = mmdc_base + MMDC_MDMISC;\r\nval = readl_relaxed(reg);\r\nddr_type = (val & BM_MMDC_MDMISC_DDR_TYPE) >>\r\nBP_MMDC_MDMISC_DDR_TYPE;\r\nreg = mmdc_base + MMDC_MAPSR;\r\nval = readl_relaxed(reg);\r\nval &= ~(1 << BP_MMDC_MAPSR_PSD);\r\nwritel_relaxed(val, reg);\r\nwhile (!(readl_relaxed(reg) & 1 << BP_MMDC_MAPSR_PSS) && --timeout)\r\ncpu_relax();\r\nif (unlikely(!timeout)) {\r\npr_warn("%s: failed to enable automatic power saving\n",\r\n__func__);\r\nreturn -EBUSY;\r\n}\r\nreturn imx_mmdc_perf_init(pdev, mmdc_base);\r\n}\r\nint imx_mmdc_get_ddr_type(void)\r\n{\r\nreturn ddr_type;\r\n}\r\nstatic int __init imx_mmdc_init(void)\r\n{\r\nreturn platform_driver_register(&imx_mmdc_driver);\r\n}
