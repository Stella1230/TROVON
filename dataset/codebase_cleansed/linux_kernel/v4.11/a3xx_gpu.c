static bool a3xx_me_init(struct msm_gpu *gpu)\r\n{\r\nstruct msm_ringbuffer *ring = gpu->rb;\r\nOUT_PKT3(ring, CP_ME_INIT, 17);\r\nOUT_RING(ring, 0x000003f7);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000080);\r\nOUT_RING(ring, 0x00000100);\r\nOUT_RING(ring, 0x00000180);\r\nOUT_RING(ring, 0x00006600);\r\nOUT_RING(ring, 0x00000150);\r\nOUT_RING(ring, 0x0000014e);\r\nOUT_RING(ring, 0x00000154);\r\nOUT_RING(ring, 0x00000001);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\ngpu->funcs->flush(gpu);\r\nreturn gpu->funcs->idle(gpu);\r\n}\r\nstatic int a3xx_hw_init(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a3xx_gpu *a3xx_gpu = to_a3xx_gpu(adreno_gpu);\r\nuint32_t *ptr, len;\r\nint i, ret;\r\nDBG("%s", gpu->name);\r\nif (adreno_is_a305(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_DDR_OUT_MAX_BURST, 0x0000303);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_GATE_OFF_WRREQ_EN, 0x0000ff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ARB_CTL, 0x00000030);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO_EN, 0x0000003c);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO, 0x003c003c);\r\n} else if (adreno_is_a306(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_ROUND_ROBIN_QOS_ARB, 0x0003);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_RD_LIM_CONF0, 0x0000000a);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_WR_LIM_CONF0, 0x0000000a);\r\n} else if (adreno_is_a320(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_RD_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_DDR_OUT_MAX_BURST, 0x0000303);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF0, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF1, 0x10101010);\r\ngpu_write(gpu, REG_A3XX_VBIF_GATE_OFF_WRREQ_EN, 0x0000ff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ARB_CTL, 0x00000030);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO_EN, 0x0000003c);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO, 0x003c003c);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT, 0x000000ff);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT_CONF, 0x000000a4);\r\n} else if (adreno_is_a330v2(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT, 0x0001003f);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT_CONF, 0x000000a4);\r\ngpu_write(gpu, REG_A3XX_VBIF_GATE_OFF_WRREQ_EN, 0x00003f);\r\ngpu_write(gpu, REG_A3XX_VBIF_DDR_OUT_MAX_BURST, 0x0000303);\r\ngpu_write(gpu, REG_A3XX_VBIF_ROUND_ROBIN_QOS_ARB, 0x0003);\r\n} else if (adreno_is_a330(adreno_gpu)) {\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_RD_LIM_CONF1, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_RD_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_WR_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_DDR_OUT_MAX_BURST, 0x0000303);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_IN_WR_LIM_CONF1, 0x18181818);\r\ngpu_write(gpu, REG_A3XX_VBIF_GATE_OFF_WRREQ_EN, 0x00003f);\r\ngpu_write(gpu, REG_A3XX_VBIF_ARB_CTL, 0x00000030);\r\ngpu_write(gpu, REG_A3XX_VBIF_ROUND_ROBIN_QOS_ARB, 0x0001);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO_EN, 0x0000003f);\r\ngpu_write(gpu, REG_A3XX_VBIF_OUT_AXI_AOOO, 0x003f003f);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT, 0x0001003f);\r\ngpu_write(gpu, REG_A3XX_VBIF_ABIT_SORT_CONF, 0x000000a4);\r\ngpu_write(gpu, REG_A3XX_VBIF_CLKON, 0x00000001);\r\n} else {\r\nBUG();\r\n}\r\ngpu_write(gpu, REG_A3XX_RBBM_GPU_BUSY_MASKED, 0xffffffff);\r\ngpu_write(gpu, REG_A3XX_RBBM_SP_HYST_CNT, 0x10);\r\ngpu_write(gpu, REG_A3XX_RBBM_WAIT_IDLE_CLOCKS_CTL, 0x10);\r\ngpu_write(gpu, REG_A3XX_RBBM_AHB_CTL0, 0x00000001);\r\ngpu_write(gpu, REG_A3XX_RBBM_AHB_CTL1, 0xa6ffffff);\r\ngpu_write(gpu, REG_A3XX_RBBM_RBBM_CTL, 0x00030000);\r\ngpu_write(gpu, REG_A3XX_RBBM_INTERFACE_HANG_INT_CTL, 0x00010fff);\r\ngpu_write(gpu, REG_A3XX_UCHE_CACHE_MODE_CONTROL_REG, 0x00000001);\r\nif (adreno_is_a306(adreno_gpu))\r\ngpu_write(gpu, REG_A3XX_RBBM_CLOCK_CTL, 0xaaaaaaaa);\r\nelse if (adreno_is_a320(adreno_gpu))\r\ngpu_write(gpu, REG_A3XX_RBBM_CLOCK_CTL, 0xbfffffff);\r\nelse if (adreno_is_a330v2(adreno_gpu))\r\ngpu_write(gpu, REG_A3XX_RBBM_CLOCK_CTL, 0xaaaaaaaa);\r\nelse if (adreno_is_a330(adreno_gpu))\r\ngpu_write(gpu, REG_A3XX_RBBM_CLOCK_CTL, 0xbffcffff);\r\nif (adreno_is_a330v2(adreno_gpu))\r\ngpu_write(gpu, REG_A3XX_RBBM_GPR0_CTL, 0x05515455);\r\nelse if (adreno_is_a330(adreno_gpu))\r\ngpu_write(gpu, REG_A3XX_RBBM_GPR0_CTL, 0x00000000);\r\nif (a3xx_gpu->ocmem_hdl) {\r\ngpu_write(gpu, REG_A3XX_RB_GMEM_BASE_ADDR,\r\n(unsigned int)(a3xx_gpu->ocmem_base >> 14));\r\n}\r\ngpu_write(gpu, REG_A3XX_RBBM_PERFCTR_CTL, 0x01);\r\nfor (i = 0; i < gpu->num_perfcntrs; i++) {\r\nconst struct msm_gpu_perfcntr *perfcntr = &gpu->perfcntrs[i];\r\ngpu_write(gpu, perfcntr->select_reg, perfcntr->select_val);\r\n}\r\ngpu_write(gpu, REG_A3XX_RBBM_INT_0_MASK, A3XX_INT0_MASK);\r\nret = adreno_hw_init(gpu);\r\nif (ret)\r\nreturn ret;\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT_CTRL, 0x00000007);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(0), 0x63000040);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(1), 0x62000080);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(2), 0x600000cc);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(3), 0x60000108);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(4), 0x64000140);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(5), 0x66000400);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(6), 0x65000700);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(7), 0x610007d8);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(8), 0x620007e0);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(9), 0x61001178);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(10), 0x64001180);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(11), 0x60003300);\r\ngpu_write(gpu, REG_A3XX_CP_PROTECT(12), 0x6b00c000);\r\nptr = (uint32_t *)(adreno_gpu->pm4->data);\r\nlen = adreno_gpu->pm4->size / 4;\r\nDBG("loading PM4 ucode version: %x", ptr[1]);\r\ngpu_write(gpu, REG_AXXX_CP_DEBUG,\r\nAXXX_CP_DEBUG_DYNAMIC_CLK_DISABLE |\r\nAXXX_CP_DEBUG_MIU_128BIT_WRITE_ENABLE);\r\ngpu_write(gpu, REG_AXXX_CP_ME_RAM_WADDR, 0);\r\nfor (i = 1; i < len; i++)\r\ngpu_write(gpu, REG_AXXX_CP_ME_RAM_DATA, ptr[i]);\r\nptr = (uint32_t *)(adreno_gpu->pfp->data);\r\nlen = adreno_gpu->pfp->size / 4;\r\nDBG("loading PFP ucode version: %x", ptr[5]);\r\ngpu_write(gpu, REG_A3XX_CP_PFP_UCODE_ADDR, 0);\r\nfor (i = 1; i < len; i++)\r\ngpu_write(gpu, REG_A3XX_CP_PFP_UCODE_DATA, ptr[i]);\r\nif (adreno_is_a305(adreno_gpu) || adreno_is_a306(adreno_gpu) ||\r\nadreno_is_a320(adreno_gpu)) {\r\ngpu_write(gpu, REG_AXXX_CP_QUEUE_THRESHOLDS,\r\nAXXX_CP_QUEUE_THRESHOLDS_CSQ_IB1_START(2) |\r\nAXXX_CP_QUEUE_THRESHOLDS_CSQ_IB2_START(6) |\r\nAXXX_CP_QUEUE_THRESHOLDS_CSQ_ST_START(14));\r\n} else if (adreno_is_a330(adreno_gpu)) {\r\ngpu_write(gpu, REG_AXXX_CP_QUEUE_THRESHOLDS, 0x003e2008);\r\n}\r\ngpu_write(gpu, REG_AXXX_CP_ME_CNTL, 0);\r\nreturn a3xx_me_init(gpu) ? 0 : -EINVAL;\r\n}\r\nstatic void a3xx_recover(struct msm_gpu *gpu)\r\n{\r\nint i;\r\nadreno_dump_info(gpu);\r\nfor (i = 0; i < 8; i++) {\r\nprintk("CP_SCRATCH_REG%d: %u\n", i,\r\ngpu_read(gpu, REG_AXXX_CP_SCRATCH_REG0 + i));\r\n}\r\nif (hang_debug)\r\na3xx_dump(gpu);\r\ngpu_write(gpu, REG_A3XX_RBBM_SW_RESET_CMD, 1);\r\ngpu_read(gpu, REG_A3XX_RBBM_SW_RESET_CMD);\r\ngpu_write(gpu, REG_A3XX_RBBM_SW_RESET_CMD, 0);\r\nadreno_recover(gpu);\r\n}\r\nstatic void a3xx_destroy(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a3xx_gpu *a3xx_gpu = to_a3xx_gpu(adreno_gpu);\r\nDBG("%s", gpu->name);\r\nadreno_gpu_cleanup(adreno_gpu);\r\n#ifdef CONFIG_MSM_OCMEM\r\nif (a3xx_gpu->ocmem_base)\r\nocmem_free(OCMEM_GRAPHICS, a3xx_gpu->ocmem_hdl);\r\n#endif\r\nkfree(a3xx_gpu);\r\n}\r\nstatic bool a3xx_idle(struct msm_gpu *gpu)\r\n{\r\nif (!adreno_idle(gpu))\r\nreturn false;\r\nif (spin_until(!(gpu_read(gpu, REG_A3XX_RBBM_STATUS) &\r\nA3XX_RBBM_STATUS_GPU_BUSY))) {\r\nDRM_ERROR("%s: timeout waiting for GPU to idle!\n", gpu->name);\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic irqreturn_t a3xx_irq(struct msm_gpu *gpu)\r\n{\r\nuint32_t status;\r\nstatus = gpu_read(gpu, REG_A3XX_RBBM_INT_0_STATUS);\r\nDBG("%s: %08x", gpu->name, status);\r\ngpu_write(gpu, REG_A3XX_RBBM_INT_CLEAR_CMD, status);\r\nmsm_gpu_retire(gpu);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void a3xx_show(struct msm_gpu *gpu, struct seq_file *m)\r\n{\r\ngpu->funcs->pm_resume(gpu);\r\nseq_printf(m, "status: %08x\n",\r\ngpu_read(gpu, REG_A3XX_RBBM_STATUS));\r\ngpu->funcs->pm_suspend(gpu);\r\nadreno_show(gpu, m);\r\n}\r\nstatic void a3xx_dump(struct msm_gpu *gpu)\r\n{\r\nprintk("status: %08x\n",\r\ngpu_read(gpu, REG_A3XX_RBBM_STATUS));\r\nadreno_dump(gpu);\r\n}\r\nstruct msm_gpu *a3xx_gpu_init(struct drm_device *dev)\r\n{\r\nstruct a3xx_gpu *a3xx_gpu = NULL;\r\nstruct adreno_gpu *adreno_gpu;\r\nstruct msm_gpu *gpu;\r\nstruct msm_drm_private *priv = dev->dev_private;\r\nstruct platform_device *pdev = priv->gpu_pdev;\r\nint ret;\r\nif (!pdev) {\r\ndev_err(dev->dev, "no a3xx device\n");\r\nret = -ENXIO;\r\ngoto fail;\r\n}\r\na3xx_gpu = kzalloc(sizeof(*a3xx_gpu), GFP_KERNEL);\r\nif (!a3xx_gpu) {\r\nret = -ENOMEM;\r\ngoto fail;\r\n}\r\nadreno_gpu = &a3xx_gpu->base;\r\ngpu = &adreno_gpu->base;\r\na3xx_gpu->pdev = pdev;\r\ngpu->perfcntrs = perfcntrs;\r\ngpu->num_perfcntrs = ARRAY_SIZE(perfcntrs);\r\nadreno_gpu->registers = a3xx_registers;\r\nadreno_gpu->reg_offsets = a3xx_register_offsets;\r\nret = adreno_gpu_init(dev, pdev, adreno_gpu, &funcs);\r\nif (ret)\r\ngoto fail;\r\nif (adreno_is_a330(adreno_gpu)) {\r\n#ifdef CONFIG_MSM_OCMEM\r\nstruct ocmem_buf *ocmem_hdl =\r\nocmem_allocate(OCMEM_GRAPHICS, adreno_gpu->gmem);\r\na3xx_gpu->ocmem_hdl = ocmem_hdl;\r\na3xx_gpu->ocmem_base = ocmem_hdl->addr;\r\nadreno_gpu->gmem = ocmem_hdl->len;\r\nDBG("using %dK of OCMEM at 0x%08x", adreno_gpu->gmem / 1024,\r\na3xx_gpu->ocmem_base);\r\n#endif\r\n}\r\nif (!gpu->aspace) {\r\ndev_err(dev->dev, "No memory protection without IOMMU\n");\r\nret = -ENXIO;\r\ngoto fail;\r\n}\r\nreturn gpu;\r\nfail:\r\nif (a3xx_gpu)\r\na3xx_destroy(&a3xx_gpu->base.base);\r\nreturn ERR_PTR(ret);\r\n}
