static void rd_write(struct msm_rd_state *rd, const void *buf, int sz)\r\n{\r\nstruct circ_buf *fifo = &rd->fifo;\r\nconst char *ptr = buf;\r\nwhile (sz > 0) {\r\nchar *fptr = &fifo->buf[fifo->head];\r\nint n;\r\nwait_event(rd->fifo_event, circ_space(&rd->fifo) > 0);\r\nn = min(sz, circ_space_to_end(&rd->fifo));\r\nmemcpy(fptr, ptr, n);\r\nfifo->head = (fifo->head + n) & (BUF_SZ - 1);\r\nsz -= n;\r\nptr += n;\r\nwake_up_all(&rd->fifo_event);\r\n}\r\n}\r\nstatic void rd_write_section(struct msm_rd_state *rd,\r\nenum rd_sect_type type, const void *buf, int sz)\r\n{\r\nrd_write(rd, &type, 4);\r\nrd_write(rd, &sz, 4);\r\nrd_write(rd, buf, sz);\r\n}\r\nstatic ssize_t rd_read(struct file *file, char __user *buf,\r\nsize_t sz, loff_t *ppos)\r\n{\r\nstruct msm_rd_state *rd = file->private_data;\r\nstruct circ_buf *fifo = &rd->fifo;\r\nconst char *fptr = &fifo->buf[fifo->tail];\r\nint n = 0, ret = 0;\r\nmutex_lock(&rd->read_lock);\r\nret = wait_event_interruptible(rd->fifo_event,\r\ncirc_count(&rd->fifo) > 0);\r\nif (ret)\r\ngoto out;\r\nn = min_t(int, sz, circ_count_to_end(&rd->fifo));\r\nif (copy_to_user(buf, fptr, n)) {\r\nret = -EFAULT;\r\ngoto out;\r\n}\r\nfifo->tail = (fifo->tail + n) & (BUF_SZ - 1);\r\n*ppos += n;\r\nwake_up_all(&rd->fifo_event);\r\nout:\r\nmutex_unlock(&rd->read_lock);\r\nif (ret)\r\nreturn ret;\r\nreturn n;\r\n}\r\nstatic int rd_open(struct inode *inode, struct file *file)\r\n{\r\nstruct msm_rd_state *rd = inode->i_private;\r\nstruct drm_device *dev = rd->dev;\r\nstruct msm_drm_private *priv = dev->dev_private;\r\nstruct msm_gpu *gpu = priv->gpu;\r\nuint64_t val;\r\nuint32_t gpu_id;\r\nint ret = 0;\r\nmutex_lock(&dev->struct_mutex);\r\nif (rd->open || !gpu) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nfile->private_data = rd;\r\nrd->open = true;\r\ngpu->funcs->get_param(gpu, MSM_PARAM_GPU_ID, &val);\r\ngpu_id = val;\r\nrd_write_section(rd, RD_GPU_ID, &gpu_id, sizeof(gpu_id));\r\nout:\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn ret;\r\n}\r\nstatic int rd_release(struct inode *inode, struct file *file)\r\n{\r\nstruct msm_rd_state *rd = inode->i_private;\r\nrd->open = false;\r\nreturn 0;\r\n}\r\nint msm_rd_debugfs_init(struct drm_minor *minor)\r\n{\r\nstruct msm_drm_private *priv = minor->dev->dev_private;\r\nstruct msm_rd_state *rd;\r\nif (priv->rd)\r\nreturn 0;\r\nrd = kzalloc(sizeof(*rd), GFP_KERNEL);\r\nif (!rd)\r\nreturn -ENOMEM;\r\nrd->dev = minor->dev;\r\nrd->fifo.buf = rd->buf;\r\nmutex_init(&rd->read_lock);\r\npriv->rd = rd;\r\ninit_waitqueue_head(&rd->fifo_event);\r\nrd->node = kzalloc(sizeof(*rd->node), GFP_KERNEL);\r\nif (!rd->node)\r\ngoto fail;\r\nrd->ent = debugfs_create_file("rd", S_IFREG | S_IRUGO,\r\nminor->debugfs_root, rd, &rd_debugfs_fops);\r\nif (!rd->ent) {\r\nDRM_ERROR("Cannot create /sys/kernel/debug/dri/%pd/rd\n",\r\nminor->debugfs_root);\r\ngoto fail;\r\n}\r\nrd->node->minor = minor;\r\nrd->node->dent = rd->ent;\r\nrd->node->info_ent = NULL;\r\nmutex_lock(&minor->debugfs_lock);\r\nlist_add(&rd->node->list, &minor->debugfs_list);\r\nmutex_unlock(&minor->debugfs_lock);\r\nreturn 0;\r\nfail:\r\nmsm_rd_debugfs_cleanup(minor);\r\nreturn -1;\r\n}\r\nvoid msm_rd_debugfs_cleanup(struct drm_minor *minor)\r\n{\r\nstruct msm_drm_private *priv = minor->dev->dev_private;\r\nstruct msm_rd_state *rd = priv->rd;\r\nif (!rd)\r\nreturn;\r\npriv->rd = NULL;\r\ndebugfs_remove(rd->ent);\r\nif (rd->node) {\r\nmutex_lock(&minor->debugfs_lock);\r\nlist_del(&rd->node->list);\r\nmutex_unlock(&minor->debugfs_lock);\r\nkfree(rd->node);\r\n}\r\nmutex_destroy(&rd->read_lock);\r\nkfree(rd);\r\n}\r\nstatic void snapshot_buf(struct msm_rd_state *rd,\r\nstruct msm_gem_submit *submit, int idx,\r\nuint64_t iova, uint32_t size)\r\n{\r\nstruct msm_gem_object *obj = submit->bos[idx].obj;\r\nconst char *buf;\r\nbuf = msm_gem_get_vaddr_locked(&obj->base);\r\nif (IS_ERR(buf))\r\nreturn;\r\nif (iova) {\r\nbuf += iova - submit->bos[idx].iova;\r\n} else {\r\niova = submit->bos[idx].iova;\r\nsize = obj->base.size;\r\n}\r\nrd_write_section(rd, RD_GPUADDR,\r\n(uint32_t[3]){ iova, size, iova >> 32 }, 12);\r\nrd_write_section(rd, RD_BUFFER_CONTENTS, buf, size);\r\nmsm_gem_put_vaddr_locked(&obj->base);\r\n}\r\nvoid msm_rd_dump_submit(struct msm_gem_submit *submit)\r\n{\r\nstruct drm_device *dev = submit->dev;\r\nstruct msm_drm_private *priv = dev->dev_private;\r\nstruct msm_rd_state *rd = priv->rd;\r\nchar msg[128];\r\nint i, n;\r\nif (!rd->open)\r\nreturn;\r\nWARN_ON(!mutex_is_locked(&dev->struct_mutex));\r\nn = snprintf(msg, sizeof(msg), "%.*s/%d: fence=%u",\r\nTASK_COMM_LEN, current->comm, task_pid_nr(current),\r\nsubmit->fence->seqno);\r\nrd_write_section(rd, RD_CMD, msg, ALIGN(n, 4));\r\nif (rd_full) {\r\nfor (i = 0; i < submit->nr_bos; i++) {\r\nif (submit->bos[i].flags & MSM_SUBMIT_BO_WRITE)\r\ncontinue;\r\nsnapshot_buf(rd, submit, i, 0, 0);\r\n}\r\n}\r\nfor (i = 0; i < submit->nr_cmds; i++) {\r\nuint32_t iova = submit->cmd[i].iova;\r\nuint32_t szd = submit->cmd[i].size;\r\nif (!rd_full) {\r\nsnapshot_buf(rd, submit, submit->cmd[i].idx,\r\nsubmit->cmd[i].iova, szd * 4);\r\n}\r\nswitch (submit->cmd[i].type) {\r\ncase MSM_SUBMIT_CMD_IB_TARGET_BUF:\r\nbreak;\r\ncase MSM_SUBMIT_CMD_CTX_RESTORE_BUF:\r\ncase MSM_SUBMIT_CMD_BUF:\r\nrd_write_section(rd, RD_CMDSTREAM_ADDR,\r\n(uint32_t[2]){ iova, szd }, 8);\r\nbreak;\r\n}\r\n}\r\n}
