static u64 notrace nomadik_read_sched_clock(void)\r\n{\r\nif (unlikely(!mtu_base))\r\nreturn 0;\r\nreturn -readl(mtu_base + MTU_VAL(0));\r\n}\r\nstatic unsigned long nmdk_timer_read_current_timer(void)\r\n{\r\nreturn ~readl_relaxed(mtu_base + MTU_VAL(0));\r\n}\r\nstatic int nmdk_clkevt_next(unsigned long evt, struct clock_event_device *ev)\r\n{\r\nwritel(1 << 1, mtu_base + MTU_IMSC);\r\nwritel(evt, mtu_base + MTU_LR(1));\r\nwritel(MTU_CRn_ONESHOT | clk_prescale |\r\nMTU_CRn_32BITS | MTU_CRn_ENA,\r\nmtu_base + MTU_CR(1));\r\nreturn 0;\r\n}\r\nstatic void nmdk_clkevt_reset(void)\r\n{\r\nif (clkevt_periodic) {\r\nwritel(nmdk_cycle, mtu_base + MTU_LR(1));\r\nwritel(nmdk_cycle, mtu_base + MTU_BGLR(1));\r\nwritel(MTU_CRn_PERIODIC | clk_prescale |\r\nMTU_CRn_32BITS | MTU_CRn_ENA,\r\nmtu_base + MTU_CR(1));\r\nwritel(1 << 1, mtu_base + MTU_IMSC);\r\n} else {\r\n(void) nmdk_clkevt_next(nmdk_cycle, NULL);\r\n}\r\n}\r\nstatic int nmdk_clkevt_shutdown(struct clock_event_device *evt)\r\n{\r\nwritel(0, mtu_base + MTU_IMSC);\r\nwritel(0, mtu_base + MTU_CR(1));\r\nwritel(0xffffffff, mtu_base + MTU_LR(1));\r\nreturn 0;\r\n}\r\nstatic int nmdk_clkevt_set_oneshot(struct clock_event_device *evt)\r\n{\r\nclkevt_periodic = false;\r\nreturn 0;\r\n}\r\nstatic int nmdk_clkevt_set_periodic(struct clock_event_device *evt)\r\n{\r\nclkevt_periodic = true;\r\nnmdk_clkevt_reset();\r\nreturn 0;\r\n}\r\nstatic void nmdk_clksrc_reset(void)\r\n{\r\nwritel(0, mtu_base + MTU_CR(0));\r\nwritel(nmdk_cycle, mtu_base + MTU_LR(0));\r\nwritel(nmdk_cycle, mtu_base + MTU_BGLR(0));\r\nwritel(clk_prescale | MTU_CRn_32BITS | MTU_CRn_ENA,\r\nmtu_base + MTU_CR(0));\r\n}\r\nstatic void nmdk_clkevt_resume(struct clock_event_device *cedev)\r\n{\r\nnmdk_clkevt_reset();\r\nnmdk_clksrc_reset();\r\n}\r\nstatic irqreturn_t nmdk_timer_interrupt(int irq, void *dev_id)\r\n{\r\nstruct clock_event_device *evdev = dev_id;\r\nwritel(1 << 1, mtu_base + MTU_ICR);\r\nevdev->event_handler(evdev);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int __init nmdk_timer_init(void __iomem *base, int irq,\r\nstruct clk *pclk, struct clk *clk)\r\n{\r\nunsigned long rate;\r\nint ret;\r\nmtu_base = base;\r\nBUG_ON(clk_prepare_enable(pclk));\r\nBUG_ON(clk_prepare_enable(clk));\r\nrate = clk_get_rate(clk);\r\nif (rate > 32000000) {\r\nrate /= 16;\r\nclk_prescale = MTU_CRn_PRESCALE_16;\r\n} else {\r\nclk_prescale = MTU_CRn_PRESCALE_1;\r\n}\r\nnmdk_cycle = DIV_ROUND_CLOSEST(rate, HZ);\r\nnmdk_clksrc_reset();\r\nret = clocksource_mmio_init(mtu_base + MTU_VAL(0), "mtu_0",\r\nrate, 200, 32, clocksource_mmio_readl_down);\r\nif (ret) {\r\npr_err("timer: failed to initialize clock source %s\n", "mtu_0");\r\nreturn ret;\r\n}\r\n#ifdef CONFIG_CLKSRC_NOMADIK_MTU_SCHED_CLOCK\r\nsched_clock_register(nomadik_read_sched_clock, 32, rate);\r\n#endif\r\nsetup_irq(irq, &nmdk_timer_irq);\r\nnmdk_clkevt.cpumask = cpumask_of(0);\r\nnmdk_clkevt.irq = irq;\r\nclockevents_config_and_register(&nmdk_clkevt, rate, 2, 0xffffffffU);\r\nmtu_delay_timer.read_current_timer = &nmdk_timer_read_current_timer;\r\nmtu_delay_timer.freq = rate;\r\nregister_current_timer_delay(&mtu_delay_timer);\r\nreturn 0;\r\n}\r\nstatic int __init nmdk_timer_of_init(struct device_node *node)\r\n{\r\nstruct clk *pclk;\r\nstruct clk *clk;\r\nvoid __iomem *base;\r\nint irq;\r\nbase = of_iomap(node, 0);\r\nif (!base) {\r\npr_err("Can't remap registers");\r\nreturn -ENXIO;\r\n}\r\npclk = of_clk_get_by_name(node, "apb_pclk");\r\nif (IS_ERR(pclk)) {\r\npr_err("could not get apb_pclk");\r\nreturn PTR_ERR(pclk);\r\n}\r\nclk = of_clk_get_by_name(node, "timclk");\r\nif (IS_ERR(clk)) {\r\npr_err("could not get timclk");\r\nreturn PTR_ERR(clk);\r\n}\r\nirq = irq_of_parse_and_map(node, 0);\r\nif (irq <= 0) {\r\npr_err("Can't parse IRQ");\r\nreturn -EINVAL;\r\n}\r\nreturn nmdk_timer_init(base, irq, pclk, clk);\r\n}
