static inline void ib_sa_disable_local_svc(struct ib_sa_query *query)\r\n{\r\nquery->flags &= ~IB_SA_ENABLE_LOCAL_SERVICE;\r\n}\r\nstatic inline int ib_sa_query_cancelled(struct ib_sa_query *query)\r\n{\r\nreturn (query->flags & IB_SA_CANCEL);\r\n}\r\nstatic void ib_nl_set_path_rec_attrs(struct sk_buff *skb,\r\nstruct ib_sa_query *query)\r\n{\r\nstruct ib_sa_path_rec *sa_rec = query->mad_buf->context[1];\r\nstruct ib_sa_mad *mad = query->mad_buf->mad;\r\nib_sa_comp_mask comp_mask = mad->sa_hdr.comp_mask;\r\nu16 val16;\r\nu64 val64;\r\nstruct rdma_ls_resolve_header *header;\r\nquery->mad_buf->context[1] = NULL;\r\nheader = (struct rdma_ls_resolve_header *)\r\nskb_put(skb, NLMSG_ALIGN(sizeof(*header)));\r\nmemcpy(header->device_name, query->port->agent->device->name,\r\nLS_DEVICE_NAME_MAX);\r\nheader->port_num = query->port->port_num;\r\nif ((comp_mask & IB_SA_PATH_REC_REVERSIBLE) &&\r\nsa_rec->reversible != 0)\r\nquery->path_use = LS_RESOLVE_PATH_USE_GMP;\r\nelse\r\nquery->path_use = LS_RESOLVE_PATH_USE_UNIDIRECTIONAL;\r\nheader->path_use = query->path_use;\r\nif (comp_mask & IB_SA_PATH_REC_SERVICE_ID) {\r\nval64 = be64_to_cpu(sa_rec->service_id);\r\nnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_SERVICE_ID,\r\nsizeof(val64), &val64);\r\n}\r\nif (comp_mask & IB_SA_PATH_REC_DGID)\r\nnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_DGID,\r\nsizeof(sa_rec->dgid), &sa_rec->dgid);\r\nif (comp_mask & IB_SA_PATH_REC_SGID)\r\nnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_SGID,\r\nsizeof(sa_rec->sgid), &sa_rec->sgid);\r\nif (comp_mask & IB_SA_PATH_REC_TRAFFIC_CLASS)\r\nnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_TCLASS,\r\nsizeof(sa_rec->traffic_class), &sa_rec->traffic_class);\r\nif (comp_mask & IB_SA_PATH_REC_PKEY) {\r\nval16 = be16_to_cpu(sa_rec->pkey);\r\nnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_PKEY,\r\nsizeof(val16), &val16);\r\n}\r\nif (comp_mask & IB_SA_PATH_REC_QOS_CLASS) {\r\nval16 = be16_to_cpu(sa_rec->qos_class);\r\nnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_QOS_CLASS,\r\nsizeof(val16), &val16);\r\n}\r\n}\r\nstatic int ib_nl_get_path_rec_attrs_len(ib_sa_comp_mask comp_mask)\r\n{\r\nint len = 0;\r\nif (comp_mask & IB_SA_PATH_REC_SERVICE_ID)\r\nlen += nla_total_size(sizeof(u64));\r\nif (comp_mask & IB_SA_PATH_REC_DGID)\r\nlen += nla_total_size(sizeof(struct rdma_nla_ls_gid));\r\nif (comp_mask & IB_SA_PATH_REC_SGID)\r\nlen += nla_total_size(sizeof(struct rdma_nla_ls_gid));\r\nif (comp_mask & IB_SA_PATH_REC_TRAFFIC_CLASS)\r\nlen += nla_total_size(sizeof(u8));\r\nif (comp_mask & IB_SA_PATH_REC_PKEY)\r\nlen += nla_total_size(sizeof(u16));\r\nif (comp_mask & IB_SA_PATH_REC_QOS_CLASS)\r\nlen += nla_total_size(sizeof(u16));\r\nif (WARN_ON(len == 0))\r\nreturn len;\r\nlen += NLMSG_ALIGN(sizeof(struct rdma_ls_resolve_header));\r\nreturn len;\r\n}\r\nstatic int ib_nl_send_msg(struct ib_sa_query *query, gfp_t gfp_mask)\r\n{\r\nstruct sk_buff *skb = NULL;\r\nstruct nlmsghdr *nlh;\r\nvoid *data;\r\nint ret = 0;\r\nstruct ib_sa_mad *mad;\r\nint len;\r\nmad = query->mad_buf->mad;\r\nlen = ib_nl_get_path_rec_attrs_len(mad->sa_hdr.comp_mask);\r\nif (len <= 0)\r\nreturn -EMSGSIZE;\r\nskb = nlmsg_new(len, gfp_mask);\r\nif (!skb)\r\nreturn -ENOMEM;\r\ndata = ibnl_put_msg(skb, &nlh, query->seq, 0, RDMA_NL_LS,\r\nRDMA_NL_LS_OP_RESOLVE, NLM_F_REQUEST);\r\nif (!data) {\r\nnlmsg_free(skb);\r\nreturn -EMSGSIZE;\r\n}\r\nib_nl_set_path_rec_attrs(skb, query);\r\nnlmsg_end(skb, nlh);\r\nret = ibnl_multicast(skb, nlh, RDMA_NL_GROUP_LS, gfp_mask);\r\nif (!ret)\r\nret = len;\r\nelse\r\nret = 0;\r\nreturn ret;\r\n}\r\nstatic int ib_nl_make_request(struct ib_sa_query *query, gfp_t gfp_mask)\r\n{\r\nunsigned long flags;\r\nunsigned long delay;\r\nint ret;\r\nINIT_LIST_HEAD(&query->list);\r\nquery->seq = (u32)atomic_inc_return(&ib_nl_sa_request_seq);\r\nspin_lock_irqsave(&ib_nl_request_lock, flags);\r\ndelay = msecs_to_jiffies(sa_local_svc_timeout_ms);\r\nquery->timeout = delay + jiffies;\r\nlist_add_tail(&query->list, &ib_nl_request_list);\r\nif (ib_nl_request_list.next == &query->list)\r\nqueue_delayed_work(ib_nl_wq, &ib_nl_timed_work, delay);\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\nret = ib_nl_send_msg(query, gfp_mask);\r\nif (ret <= 0) {\r\nret = -EIO;\r\nspin_lock_irqsave(&ib_nl_request_lock, flags);\r\nlist_del(&query->list);\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\n} else {\r\nret = 0;\r\n}\r\nreturn ret;\r\n}\r\nstatic int ib_nl_cancel_request(struct ib_sa_query *query)\r\n{\r\nunsigned long flags;\r\nstruct ib_sa_query *wait_query;\r\nint found = 0;\r\nspin_lock_irqsave(&ib_nl_request_lock, flags);\r\nlist_for_each_entry(wait_query, &ib_nl_request_list, list) {\r\nif (query == wait_query) {\r\nquery->flags |= IB_SA_CANCEL;\r\nquery->timeout = jiffies;\r\nlist_move(&query->list, &ib_nl_request_list);\r\nfound = 1;\r\nmod_delayed_work(ib_nl_wq, &ib_nl_timed_work, 1);\r\nbreak;\r\n}\r\n}\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\nreturn found;\r\n}\r\nstatic void ib_nl_process_good_resolve_rsp(struct ib_sa_query *query,\r\nconst struct nlmsghdr *nlh)\r\n{\r\nstruct ib_mad_send_wc mad_send_wc;\r\nstruct ib_sa_mad *mad = NULL;\r\nconst struct nlattr *head, *curr;\r\nstruct ib_path_rec_data *rec;\r\nint len, rem;\r\nu32 mask = 0;\r\nint status = -EIO;\r\nif (query->callback) {\r\nhead = (const struct nlattr *) nlmsg_data(nlh);\r\nlen = nlmsg_len(nlh);\r\nswitch (query->path_use) {\r\ncase LS_RESOLVE_PATH_USE_UNIDIRECTIONAL:\r\nmask = IB_PATH_PRIMARY | IB_PATH_OUTBOUND;\r\nbreak;\r\ncase LS_RESOLVE_PATH_USE_ALL:\r\ncase LS_RESOLVE_PATH_USE_GMP:\r\ndefault:\r\nmask = IB_PATH_PRIMARY | IB_PATH_GMP |\r\nIB_PATH_BIDIRECTIONAL;\r\nbreak;\r\n}\r\nnla_for_each_attr(curr, head, len, rem) {\r\nif (curr->nla_type == LS_NLA_TYPE_PATH_RECORD) {\r\nrec = nla_data(curr);\r\nif ((rec->flags & mask) == mask) {\r\nmad = query->mad_buf->mad;\r\nmad->mad_hdr.method |=\r\nIB_MGMT_METHOD_RESP;\r\nmemcpy(mad->data, rec->path_rec,\r\nsizeof(rec->path_rec));\r\nstatus = 0;\r\nbreak;\r\n}\r\n}\r\n}\r\nquery->callback(query, status, mad);\r\n}\r\nmad_send_wc.send_buf = query->mad_buf;\r\nmad_send_wc.status = IB_WC_SUCCESS;\r\nsend_handler(query->mad_buf->mad_agent, &mad_send_wc);\r\n}\r\nstatic void ib_nl_request_timeout(struct work_struct *work)\r\n{\r\nunsigned long flags;\r\nstruct ib_sa_query *query;\r\nunsigned long delay;\r\nstruct ib_mad_send_wc mad_send_wc;\r\nint ret;\r\nspin_lock_irqsave(&ib_nl_request_lock, flags);\r\nwhile (!list_empty(&ib_nl_request_list)) {\r\nquery = list_entry(ib_nl_request_list.next,\r\nstruct ib_sa_query, list);\r\nif (time_after(query->timeout, jiffies)) {\r\ndelay = query->timeout - jiffies;\r\nif ((long)delay <= 0)\r\ndelay = 1;\r\nqueue_delayed_work(ib_nl_wq, &ib_nl_timed_work, delay);\r\nbreak;\r\n}\r\nlist_del(&query->list);\r\nib_sa_disable_local_svc(query);\r\nif (ib_sa_query_cancelled(query))\r\nret = -1;\r\nelse\r\nret = ib_post_send_mad(query->mad_buf, NULL);\r\nif (ret) {\r\nmad_send_wc.send_buf = query->mad_buf;\r\nmad_send_wc.status = IB_WC_WR_FLUSH_ERR;\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\nsend_handler(query->port->agent, &mad_send_wc);\r\nspin_lock_irqsave(&ib_nl_request_lock, flags);\r\n}\r\n}\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\n}\r\nint ib_nl_handle_set_timeout(struct sk_buff *skb,\r\nstruct netlink_callback *cb)\r\n{\r\nconst struct nlmsghdr *nlh = (struct nlmsghdr *)cb->nlh;\r\nint timeout, delta, abs_delta;\r\nconst struct nlattr *attr;\r\nunsigned long flags;\r\nstruct ib_sa_query *query;\r\nlong delay = 0;\r\nstruct nlattr *tb[LS_NLA_TYPE_MAX];\r\nint ret;\r\nif (!(nlh->nlmsg_flags & NLM_F_REQUEST) ||\r\n!(NETLINK_CB(skb).sk) ||\r\n!netlink_capable(skb, CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nret = nla_parse(tb, LS_NLA_TYPE_MAX - 1, nlmsg_data(nlh),\r\nnlmsg_len(nlh), ib_nl_policy);\r\nattr = (const struct nlattr *)tb[LS_NLA_TYPE_TIMEOUT];\r\nif (ret || !attr)\r\ngoto settimeout_out;\r\ntimeout = *(int *) nla_data(attr);\r\nif (timeout < IB_SA_LOCAL_SVC_TIMEOUT_MIN)\r\ntimeout = IB_SA_LOCAL_SVC_TIMEOUT_MIN;\r\nif (timeout > IB_SA_LOCAL_SVC_TIMEOUT_MAX)\r\ntimeout = IB_SA_LOCAL_SVC_TIMEOUT_MAX;\r\ndelta = timeout - sa_local_svc_timeout_ms;\r\nif (delta < 0)\r\nabs_delta = -delta;\r\nelse\r\nabs_delta = delta;\r\nif (delta != 0) {\r\nspin_lock_irqsave(&ib_nl_request_lock, flags);\r\nsa_local_svc_timeout_ms = timeout;\r\nlist_for_each_entry(query, &ib_nl_request_list, list) {\r\nif (delta < 0 && abs_delta > query->timeout)\r\nquery->timeout = 0;\r\nelse\r\nquery->timeout += delta;\r\nif (!delay) {\r\ndelay = query->timeout - jiffies;\r\nif (delay <= 0)\r\ndelay = 1;\r\n}\r\n}\r\nif (delay)\r\nmod_delayed_work(ib_nl_wq, &ib_nl_timed_work,\r\n(unsigned long)delay);\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\n}\r\nsettimeout_out:\r\nreturn skb->len;\r\n}\r\nstatic inline int ib_nl_is_good_resolve_resp(const struct nlmsghdr *nlh)\r\n{\r\nstruct nlattr *tb[LS_NLA_TYPE_MAX];\r\nint ret;\r\nif (nlh->nlmsg_flags & RDMA_NL_LS_F_ERR)\r\nreturn 0;\r\nret = nla_parse(tb, LS_NLA_TYPE_MAX - 1, nlmsg_data(nlh),\r\nnlmsg_len(nlh), ib_nl_policy);\r\nif (ret)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nint ib_nl_handle_resolve_resp(struct sk_buff *skb,\r\nstruct netlink_callback *cb)\r\n{\r\nconst struct nlmsghdr *nlh = (struct nlmsghdr *)cb->nlh;\r\nunsigned long flags;\r\nstruct ib_sa_query *query;\r\nstruct ib_mad_send_buf *send_buf;\r\nstruct ib_mad_send_wc mad_send_wc;\r\nint found = 0;\r\nint ret;\r\nif ((nlh->nlmsg_flags & NLM_F_REQUEST) ||\r\n!(NETLINK_CB(skb).sk) ||\r\n!netlink_capable(skb, CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nspin_lock_irqsave(&ib_nl_request_lock, flags);\r\nlist_for_each_entry(query, &ib_nl_request_list, list) {\r\nif (nlh->nlmsg_seq == query->seq) {\r\nfound = !ib_sa_query_cancelled(query);\r\nif (found)\r\nlist_del(&query->list);\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\ngoto resp_out;\r\n}\r\nsend_buf = query->mad_buf;\r\nif (!ib_nl_is_good_resolve_resp(nlh)) {\r\nib_sa_disable_local_svc(query);\r\nret = ib_post_send_mad(query->mad_buf, NULL);\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\nif (ret) {\r\nmad_send_wc.send_buf = send_buf;\r\nmad_send_wc.status = IB_WC_GENERAL_ERR;\r\nsend_handler(query->port->agent, &mad_send_wc);\r\n}\r\n} else {\r\nspin_unlock_irqrestore(&ib_nl_request_lock, flags);\r\nib_nl_process_good_resolve_rsp(query, nlh);\r\n}\r\nresp_out:\r\nreturn skb->len;\r\n}\r\nstatic void free_sm_ah(struct kref *kref)\r\n{\r\nstruct ib_sa_sm_ah *sm_ah = container_of(kref, struct ib_sa_sm_ah, ref);\r\nib_destroy_ah(sm_ah->ah);\r\nkfree(sm_ah);\r\n}\r\nstatic void update_sm_ah(struct work_struct *work)\r\n{\r\nstruct ib_sa_port *port =\r\ncontainer_of(work, struct ib_sa_port, update_task);\r\nstruct ib_sa_sm_ah *new_ah;\r\nstruct ib_port_attr port_attr;\r\nstruct ib_ah_attr ah_attr;\r\nif (ib_query_port(port->agent->device, port->port_num, &port_attr)) {\r\npr_warn("Couldn't query port\n");\r\nreturn;\r\n}\r\nnew_ah = kmalloc(sizeof *new_ah, GFP_KERNEL);\r\nif (!new_ah) {\r\nreturn;\r\n}\r\nkref_init(&new_ah->ref);\r\nnew_ah->src_path_mask = (1 << port_attr.lmc) - 1;\r\nnew_ah->pkey_index = 0;\r\nif (ib_find_pkey(port->agent->device, port->port_num,\r\nIB_DEFAULT_PKEY_FULL, &new_ah->pkey_index))\r\npr_err("Couldn't find index for default PKey\n");\r\nmemset(&ah_attr, 0, sizeof ah_attr);\r\nah_attr.dlid = port_attr.sm_lid;\r\nah_attr.sl = port_attr.sm_sl;\r\nah_attr.port_num = port->port_num;\r\nif (port_attr.grh_required) {\r\nah_attr.ah_flags = IB_AH_GRH;\r\nah_attr.grh.dgid.global.subnet_prefix = cpu_to_be64(port_attr.subnet_prefix);\r\nah_attr.grh.dgid.global.interface_id = cpu_to_be64(IB_SA_WELL_KNOWN_GUID);\r\n}\r\nnew_ah->ah = ib_create_ah(port->agent->qp->pd, &ah_attr);\r\nif (IS_ERR(new_ah->ah)) {\r\npr_warn("Couldn't create new SM AH\n");\r\nkfree(new_ah);\r\nreturn;\r\n}\r\nspin_lock_irq(&port->ah_lock);\r\nif (port->sm_ah)\r\nkref_put(&port->sm_ah->ref, free_sm_ah);\r\nport->sm_ah = new_ah;\r\nspin_unlock_irq(&port->ah_lock);\r\n}\r\nstatic void ib_sa_event(struct ib_event_handler *handler, struct ib_event *event)\r\n{\r\nif (event->event == IB_EVENT_PORT_ERR ||\r\nevent->event == IB_EVENT_PORT_ACTIVE ||\r\nevent->event == IB_EVENT_LID_CHANGE ||\r\nevent->event == IB_EVENT_PKEY_CHANGE ||\r\nevent->event == IB_EVENT_SM_CHANGE ||\r\nevent->event == IB_EVENT_CLIENT_REREGISTER) {\r\nunsigned long flags;\r\nstruct ib_sa_device *sa_dev =\r\ncontainer_of(handler, typeof(*sa_dev), event_handler);\r\nstruct ib_sa_port *port =\r\n&sa_dev->port[event->element.port_num - sa_dev->start_port];\r\nif (!rdma_cap_ib_sa(handler->device, port->port_num))\r\nreturn;\r\nspin_lock_irqsave(&port->ah_lock, flags);\r\nif (port->sm_ah)\r\nkref_put(&port->sm_ah->ref, free_sm_ah);\r\nport->sm_ah = NULL;\r\nspin_unlock_irqrestore(&port->ah_lock, flags);\r\nif (event->event == IB_EVENT_SM_CHANGE ||\r\nevent->event == IB_EVENT_CLIENT_REREGISTER ||\r\nevent->event == IB_EVENT_LID_CHANGE) {\r\nspin_lock_irqsave(&port->classport_lock, flags);\r\nport->classport_info.valid = false;\r\nspin_unlock_irqrestore(&port->classport_lock, flags);\r\n}\r\nqueue_work(ib_wq, &sa_dev->port[event->element.port_num -\r\nsa_dev->start_port].update_task);\r\n}\r\n}\r\nvoid ib_sa_register_client(struct ib_sa_client *client)\r\n{\r\natomic_set(&client->users, 1);\r\ninit_completion(&client->comp);\r\n}\r\nvoid ib_sa_unregister_client(struct ib_sa_client *client)\r\n{\r\nib_sa_client_put(client);\r\nwait_for_completion(&client->comp);\r\n}\r\nvoid ib_sa_cancel_query(int id, struct ib_sa_query *query)\r\n{\r\nunsigned long flags;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_mad_send_buf *mad_buf;\r\nspin_lock_irqsave(&idr_lock, flags);\r\nif (idr_find(&query_idr, id) != query) {\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nreturn;\r\n}\r\nagent = query->port->agent;\r\nmad_buf = query->mad_buf;\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nif (!ib_nl_cancel_request(query))\r\nib_cancel_mad(agent, mad_buf);\r\n}\r\nstatic u8 get_src_path_mask(struct ib_device *device, u8 port_num)\r\n{\r\nstruct ib_sa_device *sa_dev;\r\nstruct ib_sa_port *port;\r\nunsigned long flags;\r\nu8 src_path_mask;\r\nsa_dev = ib_get_client_data(device, &sa_client);\r\nif (!sa_dev)\r\nreturn 0x7f;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nspin_lock_irqsave(&port->ah_lock, flags);\r\nsrc_path_mask = port->sm_ah ? port->sm_ah->src_path_mask : 0x7f;\r\nspin_unlock_irqrestore(&port->ah_lock, flags);\r\nreturn src_path_mask;\r\n}\r\nint ib_init_ah_from_path(struct ib_device *device, u8 port_num,\r\nstruct ib_sa_path_rec *rec, struct ib_ah_attr *ah_attr)\r\n{\r\nint ret;\r\nu16 gid_index;\r\nint use_roce;\r\nstruct net_device *ndev = NULL;\r\nmemset(ah_attr, 0, sizeof *ah_attr);\r\nah_attr->dlid = be16_to_cpu(rec->dlid);\r\nah_attr->sl = rec->sl;\r\nah_attr->src_path_bits = be16_to_cpu(rec->slid) &\r\nget_src_path_mask(device, port_num);\r\nah_attr->port_num = port_num;\r\nah_attr->static_rate = rec->rate;\r\nuse_roce = rdma_cap_eth_ah(device, port_num);\r\nif (use_roce) {\r\nstruct net_device *idev;\r\nstruct net_device *resolved_dev;\r\nstruct rdma_dev_addr dev_addr = {.bound_dev_if = rec->ifindex,\r\n.net = rec->net ? rec->net :\r\n&init_net};\r\nunion {\r\nstruct sockaddr _sockaddr;\r\nstruct sockaddr_in _sockaddr_in;\r\nstruct sockaddr_in6 _sockaddr_in6;\r\n} sgid_addr, dgid_addr;\r\nif (!device->get_netdev)\r\nreturn -EOPNOTSUPP;\r\nrdma_gid2ip(&sgid_addr._sockaddr, &rec->sgid);\r\nrdma_gid2ip(&dgid_addr._sockaddr, &rec->dgid);\r\nret = rdma_resolve_ip_route(&sgid_addr._sockaddr,\r\n&dgid_addr._sockaddr, &dev_addr);\r\nif (ret)\r\nreturn ret;\r\nif ((dev_addr.network == RDMA_NETWORK_IPV4 ||\r\ndev_addr.network == RDMA_NETWORK_IPV6) &&\r\nrec->gid_type != IB_GID_TYPE_ROCE_UDP_ENCAP)\r\nreturn -EINVAL;\r\nidev = device->get_netdev(device, port_num);\r\nif (!idev)\r\nreturn -ENODEV;\r\nresolved_dev = dev_get_by_index(dev_addr.net,\r\ndev_addr.bound_dev_if);\r\nif (resolved_dev->flags & IFF_LOOPBACK) {\r\ndev_put(resolved_dev);\r\nresolved_dev = idev;\r\ndev_hold(resolved_dev);\r\n}\r\nndev = ib_get_ndev_from_path(rec);\r\nrcu_read_lock();\r\nif ((ndev && ndev != resolved_dev) ||\r\n(resolved_dev != idev &&\r\n!rdma_is_upper_dev_rcu(idev, resolved_dev)))\r\nret = -EHOSTUNREACH;\r\nrcu_read_unlock();\r\ndev_put(idev);\r\ndev_put(resolved_dev);\r\nif (ret) {\r\nif (ndev)\r\ndev_put(ndev);\r\nreturn ret;\r\n}\r\n}\r\nif (rec->hop_limit > 0 || use_roce) {\r\nah_attr->ah_flags = IB_AH_GRH;\r\nah_attr->grh.dgid = rec->dgid;\r\nret = ib_find_cached_gid_by_port(device, &rec->sgid,\r\nrec->gid_type, port_num, ndev,\r\n&gid_index);\r\nif (ret) {\r\nif (ndev)\r\ndev_put(ndev);\r\nreturn ret;\r\n}\r\nah_attr->grh.sgid_index = gid_index;\r\nah_attr->grh.flow_label = be32_to_cpu(rec->flow_label);\r\nah_attr->grh.hop_limit = rec->hop_limit;\r\nah_attr->grh.traffic_class = rec->traffic_class;\r\nif (ndev)\r\ndev_put(ndev);\r\n}\r\nif (use_roce)\r\nmemcpy(ah_attr->dmac, rec->dmac, ETH_ALEN);\r\nreturn 0;\r\n}\r\nstatic int alloc_mad(struct ib_sa_query *query, gfp_t gfp_mask)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&query->port->ah_lock, flags);\r\nif (!query->port->sm_ah) {\r\nspin_unlock_irqrestore(&query->port->ah_lock, flags);\r\nreturn -EAGAIN;\r\n}\r\nkref_get(&query->port->sm_ah->ref);\r\nquery->sm_ah = query->port->sm_ah;\r\nspin_unlock_irqrestore(&query->port->ah_lock, flags);\r\nquery->mad_buf = ib_create_send_mad(query->port->agent, 1,\r\nquery->sm_ah->pkey_index,\r\n0, IB_MGMT_SA_HDR, IB_MGMT_SA_DATA,\r\ngfp_mask,\r\nIB_MGMT_BASE_VERSION);\r\nif (IS_ERR(query->mad_buf)) {\r\nkref_put(&query->sm_ah->ref, free_sm_ah);\r\nreturn -ENOMEM;\r\n}\r\nquery->mad_buf->ah = query->sm_ah->ah;\r\nreturn 0;\r\n}\r\nstatic void free_mad(struct ib_sa_query *query)\r\n{\r\nib_free_send_mad(query->mad_buf);\r\nkref_put(&query->sm_ah->ref, free_sm_ah);\r\n}\r\nstatic void init_mad(struct ib_sa_mad *mad, struct ib_mad_agent *agent)\r\n{\r\nunsigned long flags;\r\nmemset(mad, 0, sizeof *mad);\r\nmad->mad_hdr.base_version = IB_MGMT_BASE_VERSION;\r\nmad->mad_hdr.mgmt_class = IB_MGMT_CLASS_SUBN_ADM;\r\nmad->mad_hdr.class_version = IB_SA_CLASS_VERSION;\r\nspin_lock_irqsave(&tid_lock, flags);\r\nmad->mad_hdr.tid =\r\ncpu_to_be64(((u64) agent->hi_tid) << 32 | tid++);\r\nspin_unlock_irqrestore(&tid_lock, flags);\r\n}\r\nstatic int send_mad(struct ib_sa_query *query, int timeout_ms, gfp_t gfp_mask)\r\n{\r\nbool preload = gfpflags_allow_blocking(gfp_mask);\r\nunsigned long flags;\r\nint ret, id;\r\nif (preload)\r\nidr_preload(gfp_mask);\r\nspin_lock_irqsave(&idr_lock, flags);\r\nid = idr_alloc(&query_idr, query, 0, 0, GFP_NOWAIT);\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nif (preload)\r\nidr_preload_end();\r\nif (id < 0)\r\nreturn id;\r\nquery->mad_buf->timeout_ms = timeout_ms;\r\nquery->mad_buf->context[0] = query;\r\nquery->id = id;\r\nif (query->flags & IB_SA_ENABLE_LOCAL_SERVICE) {\r\nif (!ibnl_chk_listeners(RDMA_NL_GROUP_LS)) {\r\nif (!ib_nl_make_request(query, gfp_mask))\r\nreturn id;\r\n}\r\nib_sa_disable_local_svc(query);\r\n}\r\nret = ib_post_send_mad(query->mad_buf, NULL);\r\nif (ret) {\r\nspin_lock_irqsave(&idr_lock, flags);\r\nidr_remove(&query_idr, id);\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\n}\r\nreturn ret ? ret : id;\r\n}\r\nvoid ib_sa_unpack_path(void *attribute, struct ib_sa_path_rec *rec)\r\n{\r\nib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table), attribute, rec);\r\n}\r\nvoid ib_sa_pack_path(struct ib_sa_path_rec *rec, void *attribute)\r\n{\r\nib_pack(path_rec_table, ARRAY_SIZE(path_rec_table), rec, attribute);\r\n}\r\nstatic void ib_sa_path_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_path_query *query =\r\ncontainer_of(sa_query, struct ib_sa_path_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_path_rec rec;\r\nib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table),\r\nmad->data, &rec);\r\nrec.net = NULL;\r\nrec.ifindex = 0;\r\nrec.gid_type = IB_GID_TYPE_IB;\r\neth_zero_addr(rec.dmac);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_path_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_path_query, sa_query));\r\n}\r\nint ib_sa_path_rec_get(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num,\r\nstruct ib_sa_path_rec *rec,\r\nib_sa_comp_mask comp_mask,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_path_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_path_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nquery = kzalloc(sizeof(*query), gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_path_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_path_rec_release;\r\nmad->mad_hdr.method = IB_MGMT_METHOD_GET;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_PATH_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(path_rec_table, ARRAY_SIZE(path_rec_table), rec, mad->data);\r\n*sa_query = &query->sa_query;\r\nquery->sa_query.flags |= IB_SA_ENABLE_LOCAL_SERVICE;\r\nquery->sa_query.mad_buf->context[1] = rec;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void ib_sa_service_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_service_query *query =\r\ncontainer_of(sa_query, struct ib_sa_service_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_service_rec rec;\r\nib_unpack(service_rec_table, ARRAY_SIZE(service_rec_table),\r\nmad->data, &rec);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_service_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_service_query, sa_query));\r\n}\r\nint ib_sa_service_rec_query(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num, u8 method,\r\nstruct ib_sa_service_rec *rec,\r\nib_sa_comp_mask comp_mask,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_service_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_service_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nif (method != IB_MGMT_METHOD_GET &&\r\nmethod != IB_MGMT_METHOD_SET &&\r\nmethod != IB_SA_METHOD_DELETE)\r\nreturn -EINVAL;\r\nquery = kzalloc(sizeof(*query), gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_service_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_service_rec_release;\r\nmad->mad_hdr.method = method;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_SERVICE_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(service_rec_table, ARRAY_SIZE(service_rec_table),\r\nrec, mad->data);\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void ib_sa_mcmember_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_mcmember_query *query =\r\ncontainer_of(sa_query, struct ib_sa_mcmember_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_mcmember_rec rec;\r\nib_unpack(mcmember_rec_table, ARRAY_SIZE(mcmember_rec_table),\r\nmad->data, &rec);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_mcmember_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_mcmember_query, sa_query));\r\n}\r\nint ib_sa_mcmember_rec_query(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num,\r\nu8 method,\r\nstruct ib_sa_mcmember_rec *rec,\r\nib_sa_comp_mask comp_mask,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_mcmember_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_mcmember_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nquery = kzalloc(sizeof(*query), gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_mcmember_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_mcmember_rec_release;\r\nmad->mad_hdr.method = method;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_MC_MEMBER_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(mcmember_rec_table, ARRAY_SIZE(mcmember_rec_table),\r\nrec, mad->data);\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void ib_sa_guidinfo_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nstruct ib_sa_guidinfo_query *query =\r\ncontainer_of(sa_query, struct ib_sa_guidinfo_query, sa_query);\r\nif (mad) {\r\nstruct ib_sa_guidinfo_rec rec;\r\nib_unpack(guidinfo_rec_table, ARRAY_SIZE(guidinfo_rec_table),\r\nmad->data, &rec);\r\nquery->callback(status, &rec, query->context);\r\n} else\r\nquery->callback(status, NULL, query->context);\r\n}\r\nstatic void ib_sa_guidinfo_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_guidinfo_query, sa_query));\r\n}\r\nint ib_sa_guid_info_rec_query(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num,\r\nstruct ib_sa_guidinfo_rec *rec,\r\nib_sa_comp_mask comp_mask, u8 method,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_sa_guidinfo_rec *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_guidinfo_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nint ret;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nif (method != IB_MGMT_METHOD_GET &&\r\nmethod != IB_MGMT_METHOD_SET &&\r\nmethod != IB_SA_METHOD_DELETE) {\r\nreturn -EINVAL;\r\n}\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nquery = kzalloc(sizeof(*query), gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_guidinfo_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_guidinfo_rec_release;\r\nmad->mad_hdr.method = method;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_GUID_INFO_REC);\r\nmad->sa_hdr.comp_mask = comp_mask;\r\nib_pack(guidinfo_rec_table, ARRAY_SIZE(guidinfo_rec_table), rec,\r\nmad->data);\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void ib_sa_classport_info_rec_callback(struct ib_sa_query *sa_query,\r\nint status,\r\nstruct ib_sa_mad *mad)\r\n{\r\nunsigned long flags;\r\nstruct ib_sa_classport_info_query *query =\r\ncontainer_of(sa_query, struct ib_sa_classport_info_query, sa_query);\r\nif (mad) {\r\nstruct ib_class_port_info rec;\r\nib_unpack(classport_info_rec_table,\r\nARRAY_SIZE(classport_info_rec_table),\r\nmad->data, &rec);\r\nspin_lock_irqsave(&sa_query->port->classport_lock, flags);\r\nif (!status && !sa_query->port->classport_info.valid) {\r\nmemcpy(&sa_query->port->classport_info.data, &rec,\r\nsizeof(sa_query->port->classport_info.data));\r\nsa_query->port->classport_info.valid = true;\r\n}\r\nspin_unlock_irqrestore(&sa_query->port->classport_lock, flags);\r\nquery->callback(status, &rec, query->context);\r\n} else {\r\nquery->callback(status, NULL, query->context);\r\n}\r\n}\r\nstatic void ib_sa_portclass_info_rec_release(struct ib_sa_query *sa_query)\r\n{\r\nkfree(container_of(sa_query, struct ib_sa_classport_info_query,\r\nsa_query));\r\n}\r\nint ib_sa_classport_info_rec_query(struct ib_sa_client *client,\r\nstruct ib_device *device, u8 port_num,\r\nint timeout_ms, gfp_t gfp_mask,\r\nvoid (*callback)(int status,\r\nstruct ib_class_port_info *resp,\r\nvoid *context),\r\nvoid *context,\r\nstruct ib_sa_query **sa_query)\r\n{\r\nstruct ib_sa_classport_info_query *query;\r\nstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\r\nstruct ib_sa_port *port;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_sa_mad *mad;\r\nstruct ib_class_port_info cached_class_port_info;\r\nint ret;\r\nunsigned long flags;\r\nif (!sa_dev)\r\nreturn -ENODEV;\r\nport = &sa_dev->port[port_num - sa_dev->start_port];\r\nagent = port->agent;\r\nspin_lock_irqsave(&port->classport_lock, flags);\r\nif (port->classport_info.valid && callback) {\r\nmemcpy(&cached_class_port_info, &port->classport_info.data,\r\nsizeof(cached_class_port_info));\r\nspin_unlock_irqrestore(&port->classport_lock, flags);\r\ncallback(0, &cached_class_port_info, context);\r\nreturn 0;\r\n}\r\nspin_unlock_irqrestore(&port->classport_lock, flags);\r\nquery = kzalloc(sizeof(*query), gfp_mask);\r\nif (!query)\r\nreturn -ENOMEM;\r\nquery->sa_query.port = port;\r\nret = alloc_mad(&query->sa_query, gfp_mask);\r\nif (ret)\r\ngoto err1;\r\nib_sa_client_get(client);\r\nquery->sa_query.client = client;\r\nquery->callback = callback;\r\nquery->context = context;\r\nmad = query->sa_query.mad_buf->mad;\r\ninit_mad(mad, agent);\r\nquery->sa_query.callback = callback ? ib_sa_classport_info_rec_callback : NULL;\r\nquery->sa_query.release = ib_sa_portclass_info_rec_release;\r\nmad->mad_hdr.method = IB_MGMT_METHOD_GET;\r\nmad->mad_hdr.attr_id = cpu_to_be16(IB_SA_ATTR_CLASS_PORTINFO);\r\nmad->sa_hdr.comp_mask = 0;\r\n*sa_query = &query->sa_query;\r\nret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\r\nif (ret < 0)\r\ngoto err2;\r\nreturn ret;\r\nerr2:\r\n*sa_query = NULL;\r\nib_sa_client_put(query->sa_query.client);\r\nfree_mad(&query->sa_query);\r\nerr1:\r\nkfree(query);\r\nreturn ret;\r\n}\r\nstatic void send_handler(struct ib_mad_agent *agent,\r\nstruct ib_mad_send_wc *mad_send_wc)\r\n{\r\nstruct ib_sa_query *query = mad_send_wc->send_buf->context[0];\r\nunsigned long flags;\r\nif (query->callback)\r\nswitch (mad_send_wc->status) {\r\ncase IB_WC_SUCCESS:\r\nbreak;\r\ncase IB_WC_RESP_TIMEOUT_ERR:\r\nquery->callback(query, -ETIMEDOUT, NULL);\r\nbreak;\r\ncase IB_WC_WR_FLUSH_ERR:\r\nquery->callback(query, -EINTR, NULL);\r\nbreak;\r\ndefault:\r\nquery->callback(query, -EIO, NULL);\r\nbreak;\r\n}\r\nspin_lock_irqsave(&idr_lock, flags);\r\nidr_remove(&query_idr, query->id);\r\nspin_unlock_irqrestore(&idr_lock, flags);\r\nfree_mad(query);\r\nib_sa_client_put(query->client);\r\nquery->release(query);\r\n}\r\nstatic void recv_handler(struct ib_mad_agent *mad_agent,\r\nstruct ib_mad_send_buf *send_buf,\r\nstruct ib_mad_recv_wc *mad_recv_wc)\r\n{\r\nstruct ib_sa_query *query;\r\nif (!send_buf)\r\nreturn;\r\nquery = send_buf->context[0];\r\nif (query->callback) {\r\nif (mad_recv_wc->wc->status == IB_WC_SUCCESS)\r\nquery->callback(query,\r\nmad_recv_wc->recv_buf.mad->mad_hdr.status ?\r\n-EINVAL : 0,\r\n(struct ib_sa_mad *) mad_recv_wc->recv_buf.mad);\r\nelse\r\nquery->callback(query, -EIO, NULL);\r\n}\r\nib_free_recv_mad(mad_recv_wc);\r\n}\r\nstatic void ib_sa_add_one(struct ib_device *device)\r\n{\r\nstruct ib_sa_device *sa_dev;\r\nint s, e, i;\r\nint count = 0;\r\ns = rdma_start_port(device);\r\ne = rdma_end_port(device);\r\nsa_dev = kzalloc(sizeof *sa_dev +\r\n(e - s + 1) * sizeof (struct ib_sa_port),\r\nGFP_KERNEL);\r\nif (!sa_dev)\r\nreturn;\r\nsa_dev->start_port = s;\r\nsa_dev->end_port = e;\r\nfor (i = 0; i <= e - s; ++i) {\r\nspin_lock_init(&sa_dev->port[i].ah_lock);\r\nif (!rdma_cap_ib_sa(device, i + 1))\r\ncontinue;\r\nsa_dev->port[i].sm_ah = NULL;\r\nsa_dev->port[i].port_num = i + s;\r\nspin_lock_init(&sa_dev->port[i].classport_lock);\r\nsa_dev->port[i].classport_info.valid = false;\r\nsa_dev->port[i].agent =\r\nib_register_mad_agent(device, i + s, IB_QPT_GSI,\r\nNULL, 0, send_handler,\r\nrecv_handler, sa_dev, 0);\r\nif (IS_ERR(sa_dev->port[i].agent))\r\ngoto err;\r\nINIT_WORK(&sa_dev->port[i].update_task, update_sm_ah);\r\ncount++;\r\n}\r\nif (!count)\r\ngoto free;\r\nib_set_client_data(device, &sa_client, sa_dev);\r\nINIT_IB_EVENT_HANDLER(&sa_dev->event_handler, device, ib_sa_event);\r\nif (ib_register_event_handler(&sa_dev->event_handler))\r\ngoto err;\r\nfor (i = 0; i <= e - s; ++i) {\r\nif (rdma_cap_ib_sa(device, i + 1))\r\nupdate_sm_ah(&sa_dev->port[i].update_task);\r\n}\r\nreturn;\r\nerr:\r\nwhile (--i >= 0) {\r\nif (rdma_cap_ib_sa(device, i + 1))\r\nib_unregister_mad_agent(sa_dev->port[i].agent);\r\n}\r\nfree:\r\nkfree(sa_dev);\r\nreturn;\r\n}\r\nstatic void ib_sa_remove_one(struct ib_device *device, void *client_data)\r\n{\r\nstruct ib_sa_device *sa_dev = client_data;\r\nint i;\r\nif (!sa_dev)\r\nreturn;\r\nib_unregister_event_handler(&sa_dev->event_handler);\r\nflush_workqueue(ib_wq);\r\nfor (i = 0; i <= sa_dev->end_port - sa_dev->start_port; ++i) {\r\nif (rdma_cap_ib_sa(device, i + 1)) {\r\nib_unregister_mad_agent(sa_dev->port[i].agent);\r\nif (sa_dev->port[i].sm_ah)\r\nkref_put(&sa_dev->port[i].sm_ah->ref, free_sm_ah);\r\n}\r\n}\r\nkfree(sa_dev);\r\n}\r\nint ib_sa_init(void)\r\n{\r\nint ret;\r\nget_random_bytes(&tid, sizeof tid);\r\natomic_set(&ib_nl_sa_request_seq, 0);\r\nret = ib_register_client(&sa_client);\r\nif (ret) {\r\npr_err("Couldn't register ib_sa client\n");\r\ngoto err1;\r\n}\r\nret = mcast_init();\r\nif (ret) {\r\npr_err("Couldn't initialize multicast handling\n");\r\ngoto err2;\r\n}\r\nib_nl_wq = alloc_ordered_workqueue("ib_nl_sa_wq", WQ_MEM_RECLAIM);\r\nif (!ib_nl_wq) {\r\nret = -ENOMEM;\r\ngoto err3;\r\n}\r\nINIT_DELAYED_WORK(&ib_nl_timed_work, ib_nl_request_timeout);\r\nreturn 0;\r\nerr3:\r\nmcast_cleanup();\r\nerr2:\r\nib_unregister_client(&sa_client);\r\nerr1:\r\nreturn ret;\r\n}\r\nvoid ib_sa_cleanup(void)\r\n{\r\ncancel_delayed_work(&ib_nl_timed_work);\r\nflush_workqueue(ib_nl_wq);\r\ndestroy_workqueue(ib_nl_wq);\r\nmcast_cleanup();\r\nib_unregister_client(&sa_client);\r\nidr_destroy(&query_idr);\r\n}
