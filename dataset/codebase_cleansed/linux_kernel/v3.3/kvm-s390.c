int kvm_arch_hardware_enable(void *garbage)\r\n{\r\nreturn 0;\r\n}\r\nvoid kvm_arch_hardware_disable(void *garbage)\r\n{\r\n}\r\nint kvm_arch_hardware_setup(void)\r\n{\r\nreturn 0;\r\n}\r\nvoid kvm_arch_hardware_unsetup(void)\r\n{\r\n}\r\nvoid kvm_arch_check_processor_compat(void *rtn)\r\n{\r\n}\r\nint kvm_arch_init(void *opaque)\r\n{\r\nreturn 0;\r\n}\r\nvoid kvm_arch_exit(void)\r\n{\r\n}\r\nlong kvm_arch_dev_ioctl(struct file *filp,\r\nunsigned int ioctl, unsigned long arg)\r\n{\r\nif (ioctl == KVM_S390_ENABLE_SIE)\r\nreturn s390_enable_sie();\r\nreturn -EINVAL;\r\n}\r\nint kvm_dev_ioctl_check_extension(long ext)\r\n{\r\nint r;\r\nswitch (ext) {\r\ncase KVM_CAP_S390_PSW:\r\ncase KVM_CAP_S390_GMAP:\r\ncase KVM_CAP_SYNC_MMU:\r\nr = 1;\r\nbreak;\r\ndefault:\r\nr = 0;\r\n}\r\nreturn r;\r\n}\r\nint kvm_vm_ioctl_get_dirty_log(struct kvm *kvm,\r\nstruct kvm_dirty_log *log)\r\n{\r\nreturn 0;\r\n}\r\nlong kvm_arch_vm_ioctl(struct file *filp,\r\nunsigned int ioctl, unsigned long arg)\r\n{\r\nstruct kvm *kvm = filp->private_data;\r\nvoid __user *argp = (void __user *)arg;\r\nint r;\r\nswitch (ioctl) {\r\ncase KVM_S390_INTERRUPT: {\r\nstruct kvm_s390_interrupt s390int;\r\nr = -EFAULT;\r\nif (copy_from_user(&s390int, argp, sizeof(s390int)))\r\nbreak;\r\nr = kvm_s390_inject_vm(kvm, &s390int);\r\nbreak;\r\n}\r\ndefault:\r\nr = -ENOTTY;\r\n}\r\nreturn r;\r\n}\r\nint kvm_arch_init_vm(struct kvm *kvm)\r\n{\r\nint rc;\r\nchar debug_name[16];\r\nrc = s390_enable_sie();\r\nif (rc)\r\ngoto out_err;\r\nrc = -ENOMEM;\r\nkvm->arch.sca = (struct sca_block *) get_zeroed_page(GFP_KERNEL);\r\nif (!kvm->arch.sca)\r\ngoto out_err;\r\nsprintf(debug_name, "kvm-%u", current->pid);\r\nkvm->arch.dbf = debug_register(debug_name, 8, 2, 8 * sizeof(long));\r\nif (!kvm->arch.dbf)\r\ngoto out_nodbf;\r\nspin_lock_init(&kvm->arch.float_int.lock);\r\nINIT_LIST_HEAD(&kvm->arch.float_int.list);\r\ndebug_register_view(kvm->arch.dbf, &debug_sprintf_view);\r\nVM_EVENT(kvm, 3, "%s", "vm created");\r\nkvm->arch.gmap = gmap_alloc(current->mm);\r\nif (!kvm->arch.gmap)\r\ngoto out_nogmap;\r\nreturn 0;\r\nout_nogmap:\r\ndebug_unregister(kvm->arch.dbf);\r\nout_nodbf:\r\nfree_page((unsigned long)(kvm->arch.sca));\r\nout_err:\r\nreturn rc;\r\n}\r\nvoid kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)\r\n{\r\nVCPU_EVENT(vcpu, 3, "%s", "free cpu");\r\nclear_bit(63 - vcpu->vcpu_id, (unsigned long *) &vcpu->kvm->arch.sca->mcn);\r\nif (vcpu->kvm->arch.sca->cpu[vcpu->vcpu_id].sda ==\r\n(__u64) vcpu->arch.sie_block)\r\nvcpu->kvm->arch.sca->cpu[vcpu->vcpu_id].sda = 0;\r\nsmp_mb();\r\nfree_page((unsigned long)(vcpu->arch.sie_block));\r\nkvm_vcpu_uninit(vcpu);\r\nkfree(vcpu);\r\n}\r\nstatic void kvm_free_vcpus(struct kvm *kvm)\r\n{\r\nunsigned int i;\r\nstruct kvm_vcpu *vcpu;\r\nkvm_for_each_vcpu(i, vcpu, kvm)\r\nkvm_arch_vcpu_destroy(vcpu);\r\nmutex_lock(&kvm->lock);\r\nfor (i = 0; i < atomic_read(&kvm->online_vcpus); i++)\r\nkvm->vcpus[i] = NULL;\r\natomic_set(&kvm->online_vcpus, 0);\r\nmutex_unlock(&kvm->lock);\r\n}\r\nvoid kvm_arch_sync_events(struct kvm *kvm)\r\n{\r\n}\r\nvoid kvm_arch_destroy_vm(struct kvm *kvm)\r\n{\r\nkvm_free_vcpus(kvm);\r\nfree_page((unsigned long)(kvm->arch.sca));\r\ndebug_unregister(kvm->arch.dbf);\r\ngmap_free(kvm->arch.gmap);\r\n}\r\nint kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)\r\n{\r\nvcpu->arch.gmap = vcpu->kvm->arch.gmap;\r\nreturn 0;\r\n}\r\nvoid kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu)\r\n{\r\n}\r\nvoid kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)\r\n{\r\nsave_fp_regs(&vcpu->arch.host_fpregs);\r\nsave_access_regs(vcpu->arch.host_acrs);\r\nvcpu->arch.guest_fpregs.fpc &= FPC_VALID_MASK;\r\nrestore_fp_regs(&vcpu->arch.guest_fpregs);\r\nrestore_access_regs(vcpu->arch.guest_acrs);\r\ngmap_enable(vcpu->arch.gmap);\r\natomic_set_mask(CPUSTAT_RUNNING, &vcpu->arch.sie_block->cpuflags);\r\n}\r\nvoid kvm_arch_vcpu_put(struct kvm_vcpu *vcpu)\r\n{\r\natomic_clear_mask(CPUSTAT_RUNNING, &vcpu->arch.sie_block->cpuflags);\r\ngmap_disable(vcpu->arch.gmap);\r\nsave_fp_regs(&vcpu->arch.guest_fpregs);\r\nsave_access_regs(vcpu->arch.guest_acrs);\r\nrestore_fp_regs(&vcpu->arch.host_fpregs);\r\nrestore_access_regs(vcpu->arch.host_acrs);\r\n}\r\nstatic void kvm_s390_vcpu_initial_reset(struct kvm_vcpu *vcpu)\r\n{\r\nvcpu->arch.sie_block->gpsw.mask = 0UL;\r\nvcpu->arch.sie_block->gpsw.addr = 0UL;\r\nvcpu->arch.sie_block->prefix = 0UL;\r\nvcpu->arch.sie_block->ihcpu = 0xffff;\r\nvcpu->arch.sie_block->cputm = 0UL;\r\nvcpu->arch.sie_block->ckc = 0UL;\r\nvcpu->arch.sie_block->todpr = 0;\r\nmemset(vcpu->arch.sie_block->gcr, 0, 16 * sizeof(__u64));\r\nvcpu->arch.sie_block->gcr[0] = 0xE0UL;\r\nvcpu->arch.sie_block->gcr[14] = 0xC2000000UL;\r\nvcpu->arch.guest_fpregs.fpc = 0;\r\nasm volatile("lfpc %0" : : "Q" (vcpu->arch.guest_fpregs.fpc));\r\nvcpu->arch.sie_block->gbea = 1;\r\n}\r\nint kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)\r\n{\r\natomic_set(&vcpu->arch.sie_block->cpuflags, CPUSTAT_ZARCH |\r\nCPUSTAT_SM |\r\nCPUSTAT_STOPPED);\r\nvcpu->arch.sie_block->ecb = 6;\r\nvcpu->arch.sie_block->eca = 0xC1002001U;\r\nvcpu->arch.sie_block->fac = (int) (long) facilities;\r\nhrtimer_init(&vcpu->arch.ckc_timer, CLOCK_REALTIME, HRTIMER_MODE_ABS);\r\ntasklet_init(&vcpu->arch.tasklet, kvm_s390_tasklet,\r\n(unsigned long) vcpu);\r\nvcpu->arch.ckc_timer.function = kvm_s390_idle_wakeup;\r\nget_cpu_id(&vcpu->arch.cpu_id);\r\nvcpu->arch.cpu_id.version = 0xff;\r\nreturn 0;\r\n}\r\nstruct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,\r\nunsigned int id)\r\n{\r\nstruct kvm_vcpu *vcpu;\r\nint rc = -EINVAL;\r\nif (id >= KVM_MAX_VCPUS)\r\ngoto out;\r\nrc = -ENOMEM;\r\nvcpu = kzalloc(sizeof(struct kvm_vcpu), GFP_KERNEL);\r\nif (!vcpu)\r\ngoto out;\r\nvcpu->arch.sie_block = (struct kvm_s390_sie_block *)\r\nget_zeroed_page(GFP_KERNEL);\r\nif (!vcpu->arch.sie_block)\r\ngoto out_free_cpu;\r\nvcpu->arch.sie_block->icpua = id;\r\nBUG_ON(!kvm->arch.sca);\r\nif (!kvm->arch.sca->cpu[id].sda)\r\nkvm->arch.sca->cpu[id].sda = (__u64) vcpu->arch.sie_block;\r\nvcpu->arch.sie_block->scaoh = (__u32)(((__u64)kvm->arch.sca) >> 32);\r\nvcpu->arch.sie_block->scaol = (__u32)(__u64)kvm->arch.sca;\r\nset_bit(63 - id, (unsigned long *) &kvm->arch.sca->mcn);\r\nspin_lock_init(&vcpu->arch.local_int.lock);\r\nINIT_LIST_HEAD(&vcpu->arch.local_int.list);\r\nvcpu->arch.local_int.float_int = &kvm->arch.float_int;\r\nspin_lock(&kvm->arch.float_int.lock);\r\nkvm->arch.float_int.local_int[id] = &vcpu->arch.local_int;\r\ninit_waitqueue_head(&vcpu->arch.local_int.wq);\r\nvcpu->arch.local_int.cpuflags = &vcpu->arch.sie_block->cpuflags;\r\nspin_unlock(&kvm->arch.float_int.lock);\r\nrc = kvm_vcpu_init(vcpu, kvm, id);\r\nif (rc)\r\ngoto out_free_sie_block;\r\nVM_EVENT(kvm, 3, "create cpu %d at %p, sie block at %p", id, vcpu,\r\nvcpu->arch.sie_block);\r\nreturn vcpu;\r\nout_free_sie_block:\r\nfree_page((unsigned long)(vcpu->arch.sie_block));\r\nout_free_cpu:\r\nkfree(vcpu);\r\nout:\r\nreturn ERR_PTR(rc);\r\n}\r\nint kvm_arch_vcpu_runnable(struct kvm_vcpu *vcpu)\r\n{\r\nBUG();\r\nreturn 0;\r\n}\r\nstatic int kvm_arch_vcpu_ioctl_initial_reset(struct kvm_vcpu *vcpu)\r\n{\r\nkvm_s390_vcpu_initial_reset(vcpu);\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)\r\n{\r\nmemcpy(&vcpu->arch.guest_gprs, &regs->gprs, sizeof(regs->gprs));\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_get_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs)\r\n{\r\nmemcpy(&regs->gprs, &vcpu->arch.guest_gprs, sizeof(regs->gprs));\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_sregs(struct kvm_vcpu *vcpu,\r\nstruct kvm_sregs *sregs)\r\n{\r\nmemcpy(&vcpu->arch.guest_acrs, &sregs->acrs, sizeof(sregs->acrs));\r\nmemcpy(&vcpu->arch.sie_block->gcr, &sregs->crs, sizeof(sregs->crs));\r\nrestore_access_regs(vcpu->arch.guest_acrs);\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_get_sregs(struct kvm_vcpu *vcpu,\r\nstruct kvm_sregs *sregs)\r\n{\r\nmemcpy(&sregs->acrs, &vcpu->arch.guest_acrs, sizeof(sregs->acrs));\r\nmemcpy(&sregs->crs, &vcpu->arch.sie_block->gcr, sizeof(sregs->crs));\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_fpu(struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)\r\n{\r\nmemcpy(&vcpu->arch.guest_fpregs.fprs, &fpu->fprs, sizeof(fpu->fprs));\r\nvcpu->arch.guest_fpregs.fpc = fpu->fpc;\r\nrestore_fp_regs(&vcpu->arch.guest_fpregs);\r\nreturn 0;\r\n}\r\nint kvm_arch_vcpu_ioctl_get_fpu(struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)\r\n{\r\nmemcpy(&fpu->fprs, &vcpu->arch.guest_fpregs.fprs, sizeof(fpu->fprs));\r\nfpu->fpc = vcpu->arch.guest_fpregs.fpc;\r\nreturn 0;\r\n}\r\nstatic int kvm_arch_vcpu_ioctl_set_initial_psw(struct kvm_vcpu *vcpu, psw_t psw)\r\n{\r\nint rc = 0;\r\nif (!(atomic_read(&vcpu->arch.sie_block->cpuflags) & CPUSTAT_STOPPED))\r\nrc = -EBUSY;\r\nelse {\r\nvcpu->run->psw_mask = psw.mask;\r\nvcpu->run->psw_addr = psw.addr;\r\n}\r\nreturn rc;\r\n}\r\nint kvm_arch_vcpu_ioctl_translate(struct kvm_vcpu *vcpu,\r\nstruct kvm_translation *tr)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_guest_debug(struct kvm_vcpu *vcpu,\r\nstruct kvm_guest_debug *dbg)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint kvm_arch_vcpu_ioctl_get_mpstate(struct kvm_vcpu *vcpu,\r\nstruct kvm_mp_state *mp_state)\r\n{\r\nreturn -EINVAL;\r\n}\r\nint kvm_arch_vcpu_ioctl_set_mpstate(struct kvm_vcpu *vcpu,\r\nstruct kvm_mp_state *mp_state)\r\n{\r\nreturn -EINVAL;\r\n}\r\nstatic void __vcpu_run(struct kvm_vcpu *vcpu)\r\n{\r\nmemcpy(&vcpu->arch.sie_block->gg14, &vcpu->arch.guest_gprs[14], 16);\r\nif (need_resched())\r\nschedule();\r\nif (test_thread_flag(TIF_MCCK_PENDING))\r\ns390_handle_mcck();\r\nkvm_s390_deliver_pending_interrupts(vcpu);\r\nvcpu->arch.sie_block->icptcode = 0;\r\nlocal_irq_disable();\r\nkvm_guest_enter();\r\nlocal_irq_enable();\r\nVCPU_EVENT(vcpu, 6, "entering sie flags %x",\r\natomic_read(&vcpu->arch.sie_block->cpuflags));\r\nif (sie64a(vcpu->arch.sie_block, vcpu->arch.guest_gprs)) {\r\nVCPU_EVENT(vcpu, 3, "%s", "fault in sie instruction");\r\nkvm_s390_inject_program_int(vcpu, PGM_ADDRESSING);\r\n}\r\nVCPU_EVENT(vcpu, 6, "exit sie icptcode %d",\r\nvcpu->arch.sie_block->icptcode);\r\nlocal_irq_disable();\r\nkvm_guest_exit();\r\nlocal_irq_enable();\r\nmemcpy(&vcpu->arch.guest_gprs[14], &vcpu->arch.sie_block->gg14, 16);\r\n}\r\nint kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run)\r\n{\r\nint rc;\r\nsigset_t sigsaved;\r\nrerun_vcpu:\r\nif (vcpu->sigset_active)\r\nsigprocmask(SIG_SETMASK, &vcpu->sigset, &sigsaved);\r\natomic_clear_mask(CPUSTAT_STOPPED, &vcpu->arch.sie_block->cpuflags);\r\nBUG_ON(vcpu->kvm->arch.float_int.local_int[vcpu->vcpu_id] == NULL);\r\nswitch (kvm_run->exit_reason) {\r\ncase KVM_EXIT_S390_SIEIC:\r\ncase KVM_EXIT_UNKNOWN:\r\ncase KVM_EXIT_INTR:\r\ncase KVM_EXIT_S390_RESET:\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nvcpu->arch.sie_block->gpsw.mask = kvm_run->psw_mask;\r\nvcpu->arch.sie_block->gpsw.addr = kvm_run->psw_addr;\r\nmight_fault();\r\ndo {\r\n__vcpu_run(vcpu);\r\nrc = kvm_handle_sie_intercept(vcpu);\r\n} while (!signal_pending(current) && !rc);\r\nif (rc == SIE_INTERCEPT_RERUNVCPU)\r\ngoto rerun_vcpu;\r\nif (signal_pending(current) && !rc) {\r\nkvm_run->exit_reason = KVM_EXIT_INTR;\r\nrc = -EINTR;\r\n}\r\nif (rc == -EOPNOTSUPP) {\r\nkvm_run->exit_reason = KVM_EXIT_S390_SIEIC;\r\nkvm_run->s390_sieic.icptcode = vcpu->arch.sie_block->icptcode;\r\nkvm_run->s390_sieic.ipa = vcpu->arch.sie_block->ipa;\r\nkvm_run->s390_sieic.ipb = vcpu->arch.sie_block->ipb;\r\nrc = 0;\r\n}\r\nif (rc == -EREMOTE) {\r\nrc = 0;\r\n}\r\nkvm_run->psw_mask = vcpu->arch.sie_block->gpsw.mask;\r\nkvm_run->psw_addr = vcpu->arch.sie_block->gpsw.addr;\r\nif (vcpu->sigset_active)\r\nsigprocmask(SIG_SETMASK, &sigsaved, NULL);\r\nvcpu->stat.exit_userspace++;\r\nreturn rc;\r\n}\r\nstatic int __guestcopy(struct kvm_vcpu *vcpu, u64 guestdest, void *from,\r\nunsigned long n, int prefix)\r\n{\r\nif (prefix)\r\nreturn copy_to_guest(vcpu, guestdest, from, n);\r\nelse\r\nreturn copy_to_guest_absolute(vcpu, guestdest, from, n);\r\n}\r\nint kvm_s390_vcpu_store_status(struct kvm_vcpu *vcpu, unsigned long addr)\r\n{\r\nunsigned char archmode = 1;\r\nint prefix;\r\nif (addr == KVM_S390_STORE_STATUS_NOADDR) {\r\nif (copy_to_guest_absolute(vcpu, 163ul, &archmode, 1))\r\nreturn -EFAULT;\r\naddr = SAVE_AREA_BASE;\r\nprefix = 0;\r\n} else if (addr == KVM_S390_STORE_STATUS_PREFIXED) {\r\nif (copy_to_guest(vcpu, 163ul, &archmode, 1))\r\nreturn -EFAULT;\r\naddr = SAVE_AREA_BASE;\r\nprefix = 1;\r\n} else\r\nprefix = 0;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, fp_regs),\r\nvcpu->arch.guest_fpregs.fprs, 128, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, gp_regs),\r\nvcpu->arch.guest_gprs, 128, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, psw),\r\n&vcpu->arch.sie_block->gpsw, 16, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, pref_reg),\r\n&vcpu->arch.sie_block->prefix, 4, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu,\r\naddr + offsetof(struct save_area, fp_ctrl_reg),\r\n&vcpu->arch.guest_fpregs.fpc, 4, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, tod_reg),\r\n&vcpu->arch.sie_block->todpr, 4, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, timer),\r\n&vcpu->arch.sie_block->cputm, 8, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, clk_cmp),\r\n&vcpu->arch.sie_block->ckc, 8, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu, addr + offsetof(struct save_area, acc_regs),\r\n&vcpu->arch.guest_acrs, 64, prefix))\r\nreturn -EFAULT;\r\nif (__guestcopy(vcpu,\r\naddr + offsetof(struct save_area, ctrl_regs),\r\n&vcpu->arch.sie_block->gcr, 128, prefix))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nlong kvm_arch_vcpu_ioctl(struct file *filp,\r\nunsigned int ioctl, unsigned long arg)\r\n{\r\nstruct kvm_vcpu *vcpu = filp->private_data;\r\nvoid __user *argp = (void __user *)arg;\r\nlong r;\r\nswitch (ioctl) {\r\ncase KVM_S390_INTERRUPT: {\r\nstruct kvm_s390_interrupt s390int;\r\nr = -EFAULT;\r\nif (copy_from_user(&s390int, argp, sizeof(s390int)))\r\nbreak;\r\nr = kvm_s390_inject_vcpu(vcpu, &s390int);\r\nbreak;\r\n}\r\ncase KVM_S390_STORE_STATUS:\r\nr = kvm_s390_vcpu_store_status(vcpu, arg);\r\nbreak;\r\ncase KVM_S390_SET_INITIAL_PSW: {\r\npsw_t psw;\r\nr = -EFAULT;\r\nif (copy_from_user(&psw, argp, sizeof(psw)))\r\nbreak;\r\nr = kvm_arch_vcpu_ioctl_set_initial_psw(vcpu, psw);\r\nbreak;\r\n}\r\ncase KVM_S390_INITIAL_RESET:\r\nr = kvm_arch_vcpu_ioctl_initial_reset(vcpu);\r\nbreak;\r\ndefault:\r\nr = -EINVAL;\r\n}\r\nreturn r;\r\n}\r\nint kvm_arch_prepare_memory_region(struct kvm *kvm,\r\nstruct kvm_memory_slot *memslot,\r\nstruct kvm_memory_slot old,\r\nstruct kvm_userspace_memory_region *mem,\r\nint user_alloc)\r\n{\r\nif (mem->slot)\r\nreturn -EINVAL;\r\nif (mem->guest_phys_addr)\r\nreturn -EINVAL;\r\nif (mem->userspace_addr & 0xffffful)\r\nreturn -EINVAL;\r\nif (mem->memory_size & 0xffffful)\r\nreturn -EINVAL;\r\nif (!user_alloc)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nvoid kvm_arch_commit_memory_region(struct kvm *kvm,\r\nstruct kvm_userspace_memory_region *mem,\r\nstruct kvm_memory_slot old,\r\nint user_alloc)\r\n{\r\nint rc;\r\nrc = gmap_map_segment(kvm->arch.gmap, mem->userspace_addr,\r\nmem->guest_phys_addr, mem->memory_size);\r\nif (rc)\r\nprintk(KERN_WARNING "kvm-s390: failed to commit memory region\n");\r\nreturn;\r\n}\r\nvoid kvm_arch_flush_shadow(struct kvm *kvm)\r\n{\r\n}\r\nstatic int __init kvm_s390_init(void)\r\n{\r\nint ret;\r\nret = kvm_init(NULL, sizeof(struct kvm_vcpu), 0, THIS_MODULE);\r\nif (ret)\r\nreturn ret;\r\nfacilities = (unsigned long long *) get_zeroed_page(GFP_KERNEL|GFP_DMA);\r\nif (!facilities) {\r\nkvm_exit();\r\nreturn -ENOMEM;\r\n}\r\nmemcpy(facilities, S390_lowcore.stfle_fac_list, 16);\r\nfacilities[0] &= 0xff00fff3f47c0000ULL;\r\nfacilities[1] &= 0x201c000000000000ULL;\r\nreturn 0;\r\n}\r\nstatic void __exit kvm_s390_exit(void)\r\n{\r\nfree_page((unsigned long) facilities);\r\nkvm_exit();\r\n}
