static unsigned int limit_uint(unsigned int value)\r\n{\r\nreturn min_t(unsigned int, value, INT_MAX);\r\n}\r\nint ehca_query_device(struct ib_device *ibdev, struct ib_device_attr *props)\r\n{\r\nint i, ret = 0;\r\nstruct ehca_shca *shca = container_of(ibdev, struct ehca_shca,\r\nib_device);\r\nstruct hipz_query_hca *rblock;\r\nstatic const u32 cap_mapping[] = {\r\nIB_DEVICE_RESIZE_MAX_WR, HCA_CAP_WQE_RESIZE,\r\nIB_DEVICE_BAD_PKEY_CNTR, HCA_CAP_BAD_P_KEY_CTR,\r\nIB_DEVICE_BAD_QKEY_CNTR, HCA_CAP_Q_KEY_VIOL_CTR,\r\nIB_DEVICE_RAW_MULTI, HCA_CAP_RAW_PACKET_MCAST,\r\nIB_DEVICE_AUTO_PATH_MIG, HCA_CAP_AUTO_PATH_MIG,\r\nIB_DEVICE_CHANGE_PHY_PORT, HCA_CAP_SQD_RTS_PORT_CHANGE,\r\nIB_DEVICE_UD_AV_PORT_ENFORCE, HCA_CAP_AH_PORT_NR_CHECK,\r\nIB_DEVICE_CURR_QP_STATE_MOD, HCA_CAP_CUR_QP_STATE_MOD,\r\nIB_DEVICE_SHUTDOWN_PORT, HCA_CAP_SHUTDOWN_PORT,\r\nIB_DEVICE_INIT_TYPE, HCA_CAP_INIT_TYPE,\r\nIB_DEVICE_PORT_ACTIVE_EVENT, HCA_CAP_PORT_ACTIVE_EVENT,\r\n};\r\nrblock = ehca_alloc_fw_ctrlblock(GFP_KERNEL);\r\nif (!rblock) {\r\nehca_err(&shca->ib_device, "Can't allocate rblock memory.");\r\nreturn -ENOMEM;\r\n}\r\nif (hipz_h_query_hca(shca->ipz_hca_handle, rblock) != H_SUCCESS) {\r\nehca_err(&shca->ib_device, "Can't query device properties");\r\nret = -EINVAL;\r\ngoto query_device1;\r\n}\r\nmemset(props, 0, sizeof(struct ib_device_attr));\r\nprops->page_size_cap = shca->hca_cap_mr_pgsize;\r\nprops->fw_ver = rblock->hw_ver;\r\nprops->max_mr_size = rblock->max_mr_size;\r\nprops->vendor_id = rblock->vendor_id >> 8;\r\nprops->vendor_part_id = rblock->vendor_part_id >> 16;\r\nprops->hw_ver = rblock->hw_ver;\r\nprops->max_qp = limit_uint(rblock->max_qp);\r\nprops->max_qp_wr = limit_uint(rblock->max_wqes_wq);\r\nprops->max_sge = limit_uint(rblock->max_sge);\r\nprops->max_sge_rd = limit_uint(rblock->max_sge_rd);\r\nprops->max_cq = limit_uint(rblock->max_cq);\r\nprops->max_cqe = limit_uint(rblock->max_cqe);\r\nprops->max_mr = limit_uint(rblock->max_mr);\r\nprops->max_mw = limit_uint(rblock->max_mw);\r\nprops->max_pd = limit_uint(rblock->max_pd);\r\nprops->max_ah = limit_uint(rblock->max_ah);\r\nprops->max_ee = limit_uint(rblock->max_rd_ee_context);\r\nprops->max_rdd = limit_uint(rblock->max_rd_domain);\r\nprops->max_fmr = limit_uint(rblock->max_mr);\r\nprops->max_qp_rd_atom = limit_uint(rblock->max_rr_qp);\r\nprops->max_ee_rd_atom = limit_uint(rblock->max_rr_ee_context);\r\nprops->max_res_rd_atom = limit_uint(rblock->max_rr_hca);\r\nprops->max_qp_init_rd_atom = limit_uint(rblock->max_act_wqs_qp);\r\nprops->max_ee_init_rd_atom = limit_uint(rblock->max_act_wqs_ee_context);\r\nif (EHCA_BMASK_GET(HCA_CAP_SRQ, shca->hca_cap)) {\r\nprops->max_srq = limit_uint(props->max_qp);\r\nprops->max_srq_wr = limit_uint(props->max_qp_wr);\r\nprops->max_srq_sge = 3;\r\n}\r\nprops->max_pkeys = 16;\r\nprops->local_ca_ack_delay = rblock->local_ca_ack_delay ?\r\nmin_t(u8, rblock->local_ca_ack_delay, 255) : 12;\r\nprops->max_raw_ipv6_qp = limit_uint(rblock->max_raw_ipv6_qp);\r\nprops->max_raw_ethy_qp = limit_uint(rblock->max_raw_ethy_qp);\r\nprops->max_mcast_grp = limit_uint(rblock->max_mcast_grp);\r\nprops->max_mcast_qp_attach = limit_uint(rblock->max_mcast_qp_attach);\r\nprops->max_total_mcast_qp_attach\r\n= limit_uint(rblock->max_total_mcast_qp_attach);\r\nprops->device_cap_flags = IB_DEVICE_SYS_IMAGE_GUID |\r\nIB_DEVICE_RC_RNR_NAK_GEN | IB_DEVICE_N_NOTIFY_CQ;\r\nfor (i = 0; i < ARRAY_SIZE(cap_mapping); i += 2)\r\nif (rblock->hca_cap_indicators & cap_mapping[i + 1])\r\nprops->device_cap_flags |= cap_mapping[i];\r\nquery_device1:\r\nehca_free_fw_ctrlblock(rblock);\r\nreturn ret;\r\n}\r\nstatic enum ib_mtu map_mtu(struct ehca_shca *shca, u32 fw_mtu)\r\n{\r\nswitch (fw_mtu) {\r\ncase 0x1:\r\nreturn IB_MTU_256;\r\ncase 0x2:\r\nreturn IB_MTU_512;\r\ncase 0x3:\r\nreturn IB_MTU_1024;\r\ncase 0x4:\r\nreturn IB_MTU_2048;\r\ncase 0x5:\r\nreturn IB_MTU_4096;\r\ndefault:\r\nehca_err(&shca->ib_device, "Unknown MTU size: %x.",\r\nfw_mtu);\r\nreturn 0;\r\n}\r\n}\r\nstatic u8 map_number_of_vls(struct ehca_shca *shca, u32 vl_cap)\r\n{\r\nswitch (vl_cap) {\r\ncase 0x1:\r\nreturn 1;\r\ncase 0x2:\r\nreturn 2;\r\ncase 0x3:\r\nreturn 4;\r\ncase 0x4:\r\nreturn 8;\r\ncase 0x5:\r\nreturn 15;\r\ndefault:\r\nehca_err(&shca->ib_device, "invalid Vl Capability: %x.",\r\nvl_cap);\r\nreturn 0;\r\n}\r\n}\r\nint ehca_query_port(struct ib_device *ibdev,\r\nu8 port, struct ib_port_attr *props)\r\n{\r\nint ret = 0;\r\nu64 h_ret;\r\nstruct ehca_shca *shca = container_of(ibdev, struct ehca_shca,\r\nib_device);\r\nstruct hipz_query_port *rblock;\r\nrblock = ehca_alloc_fw_ctrlblock(GFP_KERNEL);\r\nif (!rblock) {\r\nehca_err(&shca->ib_device, "Can't allocate rblock memory.");\r\nreturn -ENOMEM;\r\n}\r\nh_ret = hipz_h_query_port(shca->ipz_hca_handle, port, rblock);\r\nif (h_ret != H_SUCCESS) {\r\nehca_err(&shca->ib_device, "Can't query port properties");\r\nret = -EINVAL;\r\ngoto query_port1;\r\n}\r\nmemset(props, 0, sizeof(struct ib_port_attr));\r\nprops->active_mtu = props->max_mtu = map_mtu(shca, rblock->max_mtu);\r\nprops->port_cap_flags = rblock->capability_mask;\r\nprops->gid_tbl_len = rblock->gid_tbl_len;\r\nif (rblock->max_msg_sz)\r\nprops->max_msg_sz = rblock->max_msg_sz;\r\nelse\r\nprops->max_msg_sz = 0x1 << 31;\r\nprops->bad_pkey_cntr = rblock->bad_pkey_cntr;\r\nprops->qkey_viol_cntr = rblock->qkey_viol_cntr;\r\nprops->pkey_tbl_len = rblock->pkey_tbl_len;\r\nprops->lid = rblock->lid;\r\nprops->sm_lid = rblock->sm_lid;\r\nprops->lmc = rblock->lmc;\r\nprops->sm_sl = rblock->sm_sl;\r\nprops->subnet_timeout = rblock->subnet_timeout;\r\nprops->init_type_reply = rblock->init_type_reply;\r\nprops->max_vl_num = map_number_of_vls(shca, rblock->vl_cap);\r\nif (rblock->state && rblock->phys_width) {\r\nprops->phys_state = rblock->phys_pstate;\r\nprops->state = rblock->phys_state;\r\nprops->active_width = rblock->phys_width;\r\nprops->active_speed = rblock->phys_speed;\r\n} else {\r\nprops->phys_state = 5;\r\nprops->state = rblock->state;\r\nprops->active_width = IB_WIDTH_12X;\r\nprops->active_speed = 0x1;\r\n}\r\nquery_port1:\r\nehca_free_fw_ctrlblock(rblock);\r\nreturn ret;\r\n}\r\nint ehca_query_sma_attr(struct ehca_shca *shca,\r\nu8 port, struct ehca_sma_attr *attr)\r\n{\r\nint ret = 0;\r\nu64 h_ret;\r\nstruct hipz_query_port *rblock;\r\nrblock = ehca_alloc_fw_ctrlblock(GFP_ATOMIC);\r\nif (!rblock) {\r\nehca_err(&shca->ib_device, "Can't allocate rblock memory.");\r\nreturn -ENOMEM;\r\n}\r\nh_ret = hipz_h_query_port(shca->ipz_hca_handle, port, rblock);\r\nif (h_ret != H_SUCCESS) {\r\nehca_err(&shca->ib_device, "Can't query port properties");\r\nret = -EINVAL;\r\ngoto query_sma_attr1;\r\n}\r\nmemset(attr, 0, sizeof(struct ehca_sma_attr));\r\nattr->lid = rblock->lid;\r\nattr->lmc = rblock->lmc;\r\nattr->sm_sl = rblock->sm_sl;\r\nattr->sm_lid = rblock->sm_lid;\r\nattr->pkey_tbl_len = rblock->pkey_tbl_len;\r\nmemcpy(attr->pkeys, rblock->pkey_entries, sizeof(attr->pkeys));\r\nquery_sma_attr1:\r\nehca_free_fw_ctrlblock(rblock);\r\nreturn ret;\r\n}\r\nint ehca_query_pkey(struct ib_device *ibdev, u8 port, u16 index, u16 *pkey)\r\n{\r\nint ret = 0;\r\nu64 h_ret;\r\nstruct ehca_shca *shca;\r\nstruct hipz_query_port *rblock;\r\nshca = container_of(ibdev, struct ehca_shca, ib_device);\r\nif (index > 16) {\r\nehca_err(&shca->ib_device, "Invalid index: %x.", index);\r\nreturn -EINVAL;\r\n}\r\nrblock = ehca_alloc_fw_ctrlblock(GFP_KERNEL);\r\nif (!rblock) {\r\nehca_err(&shca->ib_device, "Can't allocate rblock memory.");\r\nreturn -ENOMEM;\r\n}\r\nh_ret = hipz_h_query_port(shca->ipz_hca_handle, port, rblock);\r\nif (h_ret != H_SUCCESS) {\r\nehca_err(&shca->ib_device, "Can't query port properties");\r\nret = -EINVAL;\r\ngoto query_pkey1;\r\n}\r\nmemcpy(pkey, &rblock->pkey_entries + index, sizeof(u16));\r\nquery_pkey1:\r\nehca_free_fw_ctrlblock(rblock);\r\nreturn ret;\r\n}\r\nint ehca_query_gid(struct ib_device *ibdev, u8 port,\r\nint index, union ib_gid *gid)\r\n{\r\nint ret = 0;\r\nu64 h_ret;\r\nstruct ehca_shca *shca = container_of(ibdev, struct ehca_shca,\r\nib_device);\r\nstruct hipz_query_port *rblock;\r\nif (index < 0 || index > 255) {\r\nehca_err(&shca->ib_device, "Invalid index: %x.", index);\r\nreturn -EINVAL;\r\n}\r\nrblock = ehca_alloc_fw_ctrlblock(GFP_KERNEL);\r\nif (!rblock) {\r\nehca_err(&shca->ib_device, "Can't allocate rblock memory.");\r\nreturn -ENOMEM;\r\n}\r\nh_ret = hipz_h_query_port(shca->ipz_hca_handle, port, rblock);\r\nif (h_ret != H_SUCCESS) {\r\nehca_err(&shca->ib_device, "Can't query port properties");\r\nret = -EINVAL;\r\ngoto query_gid1;\r\n}\r\nmemcpy(&gid->raw[0], &rblock->gid_prefix, sizeof(u64));\r\nmemcpy(&gid->raw[8], &rblock->guid_entries[index], sizeof(u64));\r\nquery_gid1:\r\nehca_free_fw_ctrlblock(rblock);\r\nreturn ret;\r\n}\r\nint ehca_modify_port(struct ib_device *ibdev,\r\nu8 port, int port_modify_mask,\r\nstruct ib_port_modify *props)\r\n{\r\nint ret = 0;\r\nstruct ehca_shca *shca;\r\nstruct hipz_query_port *rblock;\r\nu32 cap;\r\nu64 hret;\r\nshca = container_of(ibdev, struct ehca_shca, ib_device);\r\nif ((props->set_port_cap_mask | props->clr_port_cap_mask)\r\n& ~allowed_port_caps) {\r\nehca_err(&shca->ib_device, "Non-changeable bits set in masks "\r\n"set=%x clr=%x allowed=%x", props->set_port_cap_mask,\r\nprops->clr_port_cap_mask, allowed_port_caps);\r\nreturn -EINVAL;\r\n}\r\nif (mutex_lock_interruptible(&shca->modify_mutex))\r\nreturn -ERESTARTSYS;\r\nrblock = ehca_alloc_fw_ctrlblock(GFP_KERNEL);\r\nif (!rblock) {\r\nehca_err(&shca->ib_device, "Can't allocate rblock memory.");\r\nret = -ENOMEM;\r\ngoto modify_port1;\r\n}\r\nhret = hipz_h_query_port(shca->ipz_hca_handle, port, rblock);\r\nif (hret != H_SUCCESS) {\r\nehca_err(&shca->ib_device, "Can't query port properties");\r\nret = -EINVAL;\r\ngoto modify_port2;\r\n}\r\ncap = (rblock->capability_mask | props->set_port_cap_mask)\r\n& ~props->clr_port_cap_mask;\r\nhret = hipz_h_modify_port(shca->ipz_hca_handle, port,\r\ncap, props->init_type, port_modify_mask);\r\nif (hret != H_SUCCESS) {\r\nehca_err(&shca->ib_device, "Modify port failed h_ret=%lli",\r\nhret);\r\nret = -EINVAL;\r\n}\r\nmodify_port2:\r\nehca_free_fw_ctrlblock(rblock);\r\nmodify_port1:\r\nmutex_unlock(&shca->modify_mutex);\r\nreturn ret;\r\n}
