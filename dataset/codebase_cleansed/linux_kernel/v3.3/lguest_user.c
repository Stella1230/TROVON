bool send_notify_to_eventfd(struct lg_cpu *cpu)\r\n{\r\nunsigned int i;\r\nstruct lg_eventfd_map *map;\r\nrcu_read_lock();\r\nmap = rcu_dereference(cpu->lg->eventfds);\r\nfor (i = 0; i < map->num; i++) {\r\nif (map->map[i].addr == cpu->pending_notify) {\r\neventfd_signal(map->map[i].event, 1);\r\ncpu->pending_notify = 0;\r\nbreak;\r\n}\r\n}\r\nrcu_read_unlock();\r\nreturn cpu->pending_notify == 0;\r\n}\r\nstatic int add_eventfd(struct lguest *lg, unsigned long addr, int fd)\r\n{\r\nstruct lg_eventfd_map *new, *old = lg->eventfds;\r\nif (!addr)\r\nreturn -EINVAL;\r\nnew = kmalloc(sizeof(*new) + sizeof(new->map[0]) * (old->num + 1),\r\nGFP_KERNEL);\r\nif (!new)\r\nreturn -ENOMEM;\r\nmemcpy(new->map, old->map, sizeof(old->map[0]) * old->num);\r\nnew->num = old->num;\r\nnew->map[new->num].addr = addr;\r\nnew->map[new->num].event = eventfd_ctx_fdget(fd);\r\nif (IS_ERR(new->map[new->num].event)) {\r\nint err = PTR_ERR(new->map[new->num].event);\r\nkfree(new);\r\nreturn err;\r\n}\r\nnew->num++;\r\nrcu_assign_pointer(lg->eventfds, new);\r\nsynchronize_rcu();\r\nkfree(old);\r\nreturn 0;\r\n}\r\nstatic int attach_eventfd(struct lguest *lg, const unsigned long __user *input)\r\n{\r\nunsigned long addr, fd;\r\nint err;\r\nif (get_user(addr, input) != 0)\r\nreturn -EFAULT;\r\ninput++;\r\nif (get_user(fd, input) != 0)\r\nreturn -EFAULT;\r\nmutex_lock(&lguest_lock);\r\nerr = add_eventfd(lg, addr, fd);\r\nmutex_unlock(&lguest_lock);\r\nreturn err;\r\n}\r\nstatic int user_send_irq(struct lg_cpu *cpu, const unsigned long __user *input)\r\n{\r\nunsigned long irq;\r\nif (get_user(irq, input) != 0)\r\nreturn -EFAULT;\r\nif (irq >= LGUEST_IRQS)\r\nreturn -EINVAL;\r\nset_interrupt(cpu, irq);\r\nreturn 0;\r\n}\r\nstatic ssize_t read(struct file *file, char __user *user, size_t size,loff_t*o)\r\n{\r\nstruct lguest *lg = file->private_data;\r\nstruct lg_cpu *cpu;\r\nunsigned int cpu_id = *o;\r\nif (!lg)\r\nreturn -EINVAL;\r\nif (cpu_id >= lg->nr_cpus)\r\nreturn -EINVAL;\r\ncpu = &lg->cpus[cpu_id];\r\nif (current != cpu->tsk)\r\nreturn -EPERM;\r\nif (lg->dead) {\r\nsize_t len;\r\nif (IS_ERR(lg->dead))\r\nreturn PTR_ERR(lg->dead);\r\nlen = min(size, strlen(lg->dead)+1);\r\nif (copy_to_user(user, lg->dead, len) != 0)\r\nreturn -EFAULT;\r\nreturn len;\r\n}\r\nif (cpu->pending_notify)\r\ncpu->pending_notify = 0;\r\nreturn run_guest(cpu, (unsigned long __user *)user);\r\n}\r\nstatic int lg_cpu_start(struct lg_cpu *cpu, unsigned id, unsigned long start_ip)\r\n{\r\nif (id >= ARRAY_SIZE(cpu->lg->cpus))\r\nreturn -EINVAL;\r\ncpu->id = id;\r\ncpu->lg = container_of((cpu - id), struct lguest, cpus[0]);\r\ncpu->lg->nr_cpus++;\r\ninit_clockdev(cpu);\r\ncpu->regs_page = get_zeroed_page(GFP_KERNEL);\r\nif (!cpu->regs_page)\r\nreturn -ENOMEM;\r\ncpu->regs = (void *)cpu->regs_page + PAGE_SIZE - sizeof(*cpu->regs);\r\nlguest_arch_setup_regs(cpu, start_ip);\r\ncpu->tsk = current;\r\ncpu->mm = get_task_mm(cpu->tsk);\r\ncpu->last_pages = NULL;\r\nreturn 0;\r\n}\r\nstatic int initialize(struct file *file, const unsigned long __user *input)\r\n{\r\nstruct lguest *lg;\r\nint err;\r\nunsigned long args[3];\r\nmutex_lock(&lguest_lock);\r\nif (file->private_data) {\r\nerr = -EBUSY;\r\ngoto unlock;\r\n}\r\nif (copy_from_user(args, input, sizeof(args)) != 0) {\r\nerr = -EFAULT;\r\ngoto unlock;\r\n}\r\nlg = kzalloc(sizeof(*lg), GFP_KERNEL);\r\nif (!lg) {\r\nerr = -ENOMEM;\r\ngoto unlock;\r\n}\r\nlg->eventfds = kmalloc(sizeof(*lg->eventfds), GFP_KERNEL);\r\nif (!lg->eventfds) {\r\nerr = -ENOMEM;\r\ngoto free_lg;\r\n}\r\nlg->eventfds->num = 0;\r\nlg->mem_base = (void __user *)args[0];\r\nlg->pfn_limit = args[1];\r\nerr = lg_cpu_start(&lg->cpus[0], 0, args[2]);\r\nif (err)\r\ngoto free_eventfds;\r\nerr = init_guest_pagetable(lg);\r\nif (err)\r\ngoto free_regs;\r\nfile->private_data = lg;\r\nmutex_unlock(&lguest_lock);\r\nreturn sizeof(args);\r\nfree_regs:\r\nfree_page(lg->cpus[0].regs_page);\r\nfree_eventfds:\r\nkfree(lg->eventfds);\r\nfree_lg:\r\nkfree(lg);\r\nunlock:\r\nmutex_unlock(&lguest_lock);\r\nreturn err;\r\n}\r\nstatic ssize_t write(struct file *file, const char __user *in,\r\nsize_t size, loff_t *off)\r\n{\r\nstruct lguest *lg = file->private_data;\r\nconst unsigned long __user *input = (const unsigned long __user *)in;\r\nunsigned long req;\r\nstruct lg_cpu *uninitialized_var(cpu);\r\nunsigned int cpu_id = *off;\r\nif (get_user(req, input) != 0)\r\nreturn -EFAULT;\r\ninput++;\r\nif (req != LHREQ_INITIALIZE) {\r\nif (!lg || (cpu_id >= lg->nr_cpus))\r\nreturn -EINVAL;\r\ncpu = &lg->cpus[cpu_id];\r\nif (lg->dead)\r\nreturn -ENOENT;\r\n}\r\nswitch (req) {\r\ncase LHREQ_INITIALIZE:\r\nreturn initialize(file, input);\r\ncase LHREQ_IRQ:\r\nreturn user_send_irq(cpu, input);\r\ncase LHREQ_EVENTFD:\r\nreturn attach_eventfd(lg, input);\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int close(struct inode *inode, struct file *file)\r\n{\r\nstruct lguest *lg = file->private_data;\r\nunsigned int i;\r\nif (!lg)\r\nreturn 0;\r\nmutex_lock(&lguest_lock);\r\nfree_guest_pagetable(lg);\r\nfor (i = 0; i < lg->nr_cpus; i++) {\r\nhrtimer_cancel(&lg->cpus[i].hrt);\r\nfree_page(lg->cpus[i].regs_page);\r\nmmput(lg->cpus[i].mm);\r\n}\r\nfor (i = 0; i < lg->eventfds->num; i++)\r\neventfd_ctx_put(lg->eventfds->map[i].event);\r\nkfree(lg->eventfds);\r\nif (!IS_ERR(lg->dead))\r\nkfree(lg->dead);\r\nkfree(lg);\r\nmutex_unlock(&lguest_lock);\r\nreturn 0;\r\n}\r\nint __init lguest_device_init(void)\r\n{\r\nreturn misc_register(&lguest_dev);\r\n}\r\nvoid __exit lguest_device_remove(void)\r\n{\r\nmisc_deregister(&lguest_dev);\r\n}
