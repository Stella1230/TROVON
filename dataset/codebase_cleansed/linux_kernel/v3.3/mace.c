static int __devinit mace_probe(struct macio_dev *mdev, const struct of_device_id *match)\r\n{\r\nstruct device_node *mace = macio_get_of_node(mdev);\r\nstruct net_device *dev;\r\nstruct mace_data *mp;\r\nconst unsigned char *addr;\r\nint j, rev, rc = -EBUSY;\r\nif (macio_resource_count(mdev) != 3 || macio_irq_count(mdev) != 3) {\r\nprintk(KERN_ERR "can't use MACE %s: need 3 addrs and 3 irqs\n",\r\nmace->full_name);\r\nreturn -ENODEV;\r\n}\r\naddr = of_get_property(mace, "mac-address", NULL);\r\nif (addr == NULL) {\r\naddr = of_get_property(mace, "local-mac-address", NULL);\r\nif (addr == NULL) {\r\nprintk(KERN_ERR "Can't get mac-address for MACE %s\n",\r\nmace->full_name);\r\nreturn -ENODEV;\r\n}\r\n}\r\nif (dummy_buf == NULL) {\r\ndummy_buf = kmalloc(RX_BUFLEN+2, GFP_KERNEL);\r\nif (dummy_buf == NULL) {\r\nprintk(KERN_ERR "MACE: couldn't allocate dummy buffer\n");\r\nreturn -ENOMEM;\r\n}\r\n}\r\nif (macio_request_resources(mdev, "mace")) {\r\nprintk(KERN_ERR "MACE: can't request IO resources !\n");\r\nreturn -EBUSY;\r\n}\r\ndev = alloc_etherdev(PRIV_BYTES);\r\nif (!dev) {\r\nprintk(KERN_ERR "MACE: can't allocate ethernet device !\n");\r\nrc = -ENOMEM;\r\ngoto err_release;\r\n}\r\nSET_NETDEV_DEV(dev, &mdev->ofdev.dev);\r\nmp = netdev_priv(dev);\r\nmp->mdev = mdev;\r\nmacio_set_drvdata(mdev, dev);\r\ndev->base_addr = macio_resource_start(mdev, 0);\r\nmp->mace = ioremap(dev->base_addr, 0x1000);\r\nif (mp->mace == NULL) {\r\nprintk(KERN_ERR "MACE: can't map IO resources !\n");\r\nrc = -ENOMEM;\r\ngoto err_free;\r\n}\r\ndev->irq = macio_irq(mdev, 0);\r\nrev = addr[0] == 0 && addr[1] == 0xA0;\r\nfor (j = 0; j < 6; ++j) {\r\ndev->dev_addr[j] = rev ? bitrev8(addr[j]): addr[j];\r\n}\r\nmp->chipid = (in_8(&mp->mace->chipid_hi) << 8) |\r\nin_8(&mp->mace->chipid_lo);\r\nmp = netdev_priv(dev);\r\nmp->maccc = ENXMT | ENRCV;\r\nmp->tx_dma = ioremap(macio_resource_start(mdev, 1), 0x1000);\r\nif (mp->tx_dma == NULL) {\r\nprintk(KERN_ERR "MACE: can't map TX DMA resources !\n");\r\nrc = -ENOMEM;\r\ngoto err_unmap_io;\r\n}\r\nmp->tx_dma_intr = macio_irq(mdev, 1);\r\nmp->rx_dma = ioremap(macio_resource_start(mdev, 2), 0x1000);\r\nif (mp->rx_dma == NULL) {\r\nprintk(KERN_ERR "MACE: can't map RX DMA resources !\n");\r\nrc = -ENOMEM;\r\ngoto err_unmap_tx_dma;\r\n}\r\nmp->rx_dma_intr = macio_irq(mdev, 2);\r\nmp->tx_cmds = (volatile struct dbdma_cmd *) DBDMA_ALIGN(mp + 1);\r\nmp->rx_cmds = mp->tx_cmds + NCMDS_TX * N_TX_RING + 1;\r\nmemset((char *) mp->tx_cmds, 0,\r\n(NCMDS_TX*N_TX_RING + N_RX_RING + 2) * sizeof(struct dbdma_cmd));\r\ninit_timer(&mp->tx_timeout);\r\nspin_lock_init(&mp->lock);\r\nmp->timeout_active = 0;\r\nif (port_aaui >= 0)\r\nmp->port_aaui = port_aaui;\r\nelse {\r\nif (of_machine_is_compatible("AAPL,ShinerESB"))\r\nmp->port_aaui = 1;\r\nelse {\r\n#ifdef CONFIG_MACE_AAUI_PORT\r\nmp->port_aaui = 1;\r\n#else\r\nmp->port_aaui = 0;\r\n#endif\r\n}\r\n}\r\ndev->netdev_ops = &mace_netdev_ops;\r\nmace_reset(dev);\r\nrc = request_irq(dev->irq, mace_interrupt, 0, "MACE", dev);\r\nif (rc) {\r\nprintk(KERN_ERR "MACE: can't get irq %d\n", dev->irq);\r\ngoto err_unmap_rx_dma;\r\n}\r\nrc = request_irq(mp->tx_dma_intr, mace_txdma_intr, 0, "MACE-txdma", dev);\r\nif (rc) {\r\nprintk(KERN_ERR "MACE: can't get irq %d\n", mp->tx_dma_intr);\r\ngoto err_free_irq;\r\n}\r\nrc = request_irq(mp->rx_dma_intr, mace_rxdma_intr, 0, "MACE-rxdma", dev);\r\nif (rc) {\r\nprintk(KERN_ERR "MACE: can't get irq %d\n", mp->rx_dma_intr);\r\ngoto err_free_tx_irq;\r\n}\r\nrc = register_netdev(dev);\r\nif (rc) {\r\nprintk(KERN_ERR "MACE: Cannot register net device, aborting.\n");\r\ngoto err_free_rx_irq;\r\n}\r\nprintk(KERN_INFO "%s: MACE at %pM, chip revision %d.%d\n",\r\ndev->name, dev->dev_addr,\r\nmp->chipid >> 8, mp->chipid & 0xff);\r\nreturn 0;\r\nerr_free_rx_irq:\r\nfree_irq(macio_irq(mdev, 2), dev);\r\nerr_free_tx_irq:\r\nfree_irq(macio_irq(mdev, 1), dev);\r\nerr_free_irq:\r\nfree_irq(macio_irq(mdev, 0), dev);\r\nerr_unmap_rx_dma:\r\niounmap(mp->rx_dma);\r\nerr_unmap_tx_dma:\r\niounmap(mp->tx_dma);\r\nerr_unmap_io:\r\niounmap(mp->mace);\r\nerr_free:\r\nfree_netdev(dev);\r\nerr_release:\r\nmacio_release_resources(mdev);\r\nreturn rc;\r\n}\r\nstatic int __devexit mace_remove(struct macio_dev *mdev)\r\n{\r\nstruct net_device *dev = macio_get_drvdata(mdev);\r\nstruct mace_data *mp;\r\nBUG_ON(dev == NULL);\r\nmacio_set_drvdata(mdev, NULL);\r\nmp = netdev_priv(dev);\r\nunregister_netdev(dev);\r\nfree_irq(dev->irq, dev);\r\nfree_irq(mp->tx_dma_intr, dev);\r\nfree_irq(mp->rx_dma_intr, dev);\r\niounmap(mp->rx_dma);\r\niounmap(mp->tx_dma);\r\niounmap(mp->mace);\r\nfree_netdev(dev);\r\nmacio_release_resources(mdev);\r\nreturn 0;\r\n}\r\nstatic void dbdma_reset(volatile struct dbdma_regs __iomem *dma)\r\n{\r\nint i;\r\nout_le32(&dma->control, (WAKE|FLUSH|PAUSE|RUN) << 16);\r\nfor (i = 200; i > 0; --i)\r\nif (ld_le32(&dma->control) & RUN)\r\nudelay(1);\r\n}\r\nstatic void mace_reset(struct net_device *dev)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nint i;\r\ni = 200;\r\nwhile (--i) {\r\nout_8(&mb->biucc, SWRST);\r\nif (in_8(&mb->biucc) & SWRST) {\r\nudelay(10);\r\ncontinue;\r\n}\r\nbreak;\r\n}\r\nif (!i) {\r\nprintk(KERN_ERR "mace: cannot reset chip!\n");\r\nreturn;\r\n}\r\nout_8(&mb->imr, 0xff);\r\ni = in_8(&mb->ir);\r\nout_8(&mb->maccc, 0);\r\nout_8(&mb->biucc, XMTSP_64);\r\nout_8(&mb->utr, RTRD);\r\nout_8(&mb->fifocc, RCVFW_32 | XMTFW_16 | XMTFWU | RCVFWU | XMTBRST);\r\nout_8(&mb->xmtfc, AUTO_PAD_XMIT);\r\nout_8(&mb->rcvfc, 0);\r\n__mace_set_address(dev, dev->dev_addr);\r\nif (mp->chipid == BROKEN_ADDRCHG_REV)\r\nout_8(&mb->iac, LOGADDR);\r\nelse {\r\nout_8(&mb->iac, ADDRCHG | LOGADDR);\r\nwhile ((in_8(&mb->iac) & ADDRCHG) != 0)\r\n;\r\n}\r\nfor (i = 0; i < 8; ++i)\r\nout_8(&mb->ladrf, 0);\r\nif (mp->chipid != BROKEN_ADDRCHG_REV)\r\nout_8(&mb->iac, 0);\r\nif (mp->port_aaui)\r\nout_8(&mb->plscc, PORTSEL_AUI + ENPLSIO);\r\nelse\r\nout_8(&mb->plscc, PORTSEL_GPSI + ENPLSIO);\r\n}\r\nstatic void __mace_set_address(struct net_device *dev, void *addr)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nunsigned char *p = addr;\r\nint i;\r\nif (mp->chipid == BROKEN_ADDRCHG_REV)\r\nout_8(&mb->iac, PHYADDR);\r\nelse {\r\nout_8(&mb->iac, ADDRCHG | PHYADDR);\r\nwhile ((in_8(&mb->iac) & ADDRCHG) != 0)\r\n;\r\n}\r\nfor (i = 0; i < 6; ++i)\r\nout_8(&mb->padr, dev->dev_addr[i] = p[i]);\r\nif (mp->chipid != BROKEN_ADDRCHG_REV)\r\nout_8(&mb->iac, 0);\r\n}\r\nstatic int mace_set_address(struct net_device *dev, void *addr)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mp->lock, flags);\r\n__mace_set_address(dev, addr);\r\nout_8(&mb->maccc, mp->maccc);\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\nreturn 0;\r\n}\r\nstatic inline void mace_clean_rings(struct mace_data *mp)\r\n{\r\nint i;\r\nfor (i = 0; i < N_RX_RING; ++i) {\r\nif (mp->rx_bufs[i] != NULL) {\r\ndev_kfree_skb(mp->rx_bufs[i]);\r\nmp->rx_bufs[i] = NULL;\r\n}\r\n}\r\nfor (i = mp->tx_empty; i != mp->tx_fill; ) {\r\ndev_kfree_skb(mp->tx_bufs[i]);\r\nif (++i >= N_TX_RING)\r\ni = 0;\r\n}\r\n}\r\nstatic int mace_open(struct net_device *dev)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nvolatile struct dbdma_regs __iomem *rd = mp->rx_dma;\r\nvolatile struct dbdma_regs __iomem *td = mp->tx_dma;\r\nvolatile struct dbdma_cmd *cp;\r\nint i;\r\nstruct sk_buff *skb;\r\nunsigned char *data;\r\nmace_reset(dev);\r\nmace_clean_rings(mp);\r\nmemset((char *)mp->rx_cmds, 0, N_RX_RING * sizeof(struct dbdma_cmd));\r\ncp = mp->rx_cmds;\r\nfor (i = 0; i < N_RX_RING - 1; ++i) {\r\nskb = dev_alloc_skb(RX_BUFLEN + 2);\r\nif (!skb) {\r\ndata = dummy_buf;\r\n} else {\r\nskb_reserve(skb, 2);\r\ndata = skb->data;\r\n}\r\nmp->rx_bufs[i] = skb;\r\nst_le16(&cp->req_count, RX_BUFLEN);\r\nst_le16(&cp->command, INPUT_LAST + INTR_ALWAYS);\r\nst_le32(&cp->phy_addr, virt_to_bus(data));\r\ncp->xfer_status = 0;\r\n++cp;\r\n}\r\nmp->rx_bufs[i] = NULL;\r\nst_le16(&cp->command, DBDMA_STOP);\r\nmp->rx_fill = i;\r\nmp->rx_empty = 0;\r\n++cp;\r\nst_le16(&cp->command, DBDMA_NOP + BR_ALWAYS);\r\nst_le32(&cp->cmd_dep, virt_to_bus(mp->rx_cmds));\r\nout_le32(&rd->control, (RUN|PAUSE|FLUSH|WAKE) << 16);\r\nout_le32(&rd->cmdptr, virt_to_bus(mp->rx_cmds));\r\nout_le32(&rd->control, (RUN << 16) | RUN);\r\ncp = mp->tx_cmds + NCMDS_TX * N_TX_RING;\r\nst_le16(&cp->command, DBDMA_NOP + BR_ALWAYS);\r\nst_le32(&cp->cmd_dep, virt_to_bus(mp->tx_cmds));\r\nout_le32(&td->control, (RUN|PAUSE|FLUSH|WAKE) << 16);\r\nout_le32(&td->cmdptr, virt_to_bus(mp->tx_cmds));\r\nmp->tx_fill = 0;\r\nmp->tx_empty = 0;\r\nmp->tx_fullup = 0;\r\nmp->tx_active = 0;\r\nmp->tx_bad_runt = 0;\r\nout_8(&mb->maccc, mp->maccc);\r\nout_8(&mb->imr, RCVINT);\r\nreturn 0;\r\n}\r\nstatic int mace_close(struct net_device *dev)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nvolatile struct dbdma_regs __iomem *rd = mp->rx_dma;\r\nvolatile struct dbdma_regs __iomem *td = mp->tx_dma;\r\nout_8(&mb->maccc, 0);\r\nout_8(&mb->imr, 0xff);\r\nst_le32(&rd->control, (RUN|PAUSE|FLUSH|WAKE) << 16);\r\nst_le32(&td->control, (RUN|PAUSE|FLUSH|WAKE) << 16);\r\nmace_clean_rings(mp);\r\nreturn 0;\r\n}\r\nstatic inline void mace_set_timeout(struct net_device *dev)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nif (mp->timeout_active)\r\ndel_timer(&mp->tx_timeout);\r\nmp->tx_timeout.expires = jiffies + TX_TIMEOUT;\r\nmp->tx_timeout.function = mace_tx_timeout;\r\nmp->tx_timeout.data = (unsigned long) dev;\r\nadd_timer(&mp->tx_timeout);\r\nmp->timeout_active = 1;\r\n}\r\nstatic int mace_xmit_start(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *td = mp->tx_dma;\r\nvolatile struct dbdma_cmd *cp, *np;\r\nunsigned long flags;\r\nint fill, next, len;\r\nspin_lock_irqsave(&mp->lock, flags);\r\nfill = mp->tx_fill;\r\nnext = fill + 1;\r\nif (next >= N_TX_RING)\r\nnext = 0;\r\nif (next == mp->tx_empty) {\r\nnetif_stop_queue(dev);\r\nmp->tx_fullup = 1;\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\nlen = skb->len;\r\nif (len > ETH_FRAME_LEN) {\r\nprintk(KERN_DEBUG "mace: xmit frame too long (%d)\n", len);\r\nlen = ETH_FRAME_LEN;\r\n}\r\nmp->tx_bufs[fill] = skb;\r\ncp = mp->tx_cmds + NCMDS_TX * fill;\r\nst_le16(&cp->req_count, len);\r\nst_le32(&cp->phy_addr, virt_to_bus(skb->data));\r\nnp = mp->tx_cmds + NCMDS_TX * next;\r\nout_le16(&np->command, DBDMA_STOP);\r\nspin_lock_irqsave(&mp->lock, flags);\r\nmp->tx_fill = next;\r\nif (!mp->tx_bad_runt && mp->tx_active < MAX_TX_ACTIVE) {\r\nout_le16(&cp->xfer_status, 0);\r\nout_le16(&cp->command, OUTPUT_LAST);\r\nout_le32(&td->control, ((RUN|WAKE) << 16) + (RUN|WAKE));\r\n++mp->tx_active;\r\nmace_set_timeout(dev);\r\n}\r\nif (++next >= N_TX_RING)\r\nnext = 0;\r\nif (next == mp->tx_empty)\r\nnetif_stop_queue(dev);\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void mace_set_multicast(struct net_device *dev)\r\n{\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nint i;\r\nu32 crc;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mp->lock, flags);\r\nmp->maccc &= ~PROM;\r\nif (dev->flags & IFF_PROMISC) {\r\nmp->maccc |= PROM;\r\n} else {\r\nunsigned char multicast_filter[8];\r\nstruct netdev_hw_addr *ha;\r\nif (dev->flags & IFF_ALLMULTI) {\r\nfor (i = 0; i < 8; i++)\r\nmulticast_filter[i] = 0xff;\r\n} else {\r\nfor (i = 0; i < 8; i++)\r\nmulticast_filter[i] = 0;\r\nnetdev_for_each_mc_addr(ha, dev) {\r\ncrc = ether_crc_le(6, ha->addr);\r\ni = crc >> 26;\r\nmulticast_filter[i >> 3] |= 1 << (i & 7);\r\n}\r\n}\r\n#if 0\r\nprintk("Multicast filter :");\r\nfor (i = 0; i < 8; i++)\r\nprintk("%02x ", multicast_filter[i]);\r\nprintk("\n");\r\n#endif\r\nif (mp->chipid == BROKEN_ADDRCHG_REV)\r\nout_8(&mb->iac, LOGADDR);\r\nelse {\r\nout_8(&mb->iac, ADDRCHG | LOGADDR);\r\nwhile ((in_8(&mb->iac) & ADDRCHG) != 0)\r\n;\r\n}\r\nfor (i = 0; i < 8; ++i)\r\nout_8(&mb->ladrf, multicast_filter[i]);\r\nif (mp->chipid != BROKEN_ADDRCHG_REV)\r\nout_8(&mb->iac, 0);\r\n}\r\nout_8(&mb->maccc, mp->maccc);\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\n}\r\nstatic void mace_handle_misc_intrs(struct mace_data *mp, int intr, struct net_device *dev)\r\n{\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nstatic int mace_babbles, mace_jabbers;\r\nif (intr & MPCO)\r\ndev->stats.rx_missed_errors += 256;\r\ndev->stats.rx_missed_errors += in_8(&mb->mpc);\r\nif (intr & RNTPCO)\r\ndev->stats.rx_length_errors += 256;\r\ndev->stats.rx_length_errors += in_8(&mb->rntpc);\r\nif (intr & CERR)\r\n++dev->stats.tx_heartbeat_errors;\r\nif (intr & BABBLE)\r\nif (mace_babbles++ < 4)\r\nprintk(KERN_DEBUG "mace: babbling transmitter\n");\r\nif (intr & JABBER)\r\nif (mace_jabbers++ < 4)\r\nprintk(KERN_DEBUG "mace: jabbering transceiver\n");\r\n}\r\nstatic irqreturn_t mace_interrupt(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *) dev_id;\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nvolatile struct dbdma_regs __iomem *td = mp->tx_dma;\r\nvolatile struct dbdma_cmd *cp;\r\nint intr, fs, i, stat, x;\r\nint xcount, dstat;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mp->lock, flags);\r\nintr = in_8(&mb->ir);\r\nin_8(&mb->xmtrc);\r\nmace_handle_misc_intrs(mp, intr, dev);\r\ni = mp->tx_empty;\r\nwhile (in_8(&mb->pr) & XMTSV) {\r\ndel_timer(&mp->tx_timeout);\r\nmp->timeout_active = 0;\r\nintr = in_8(&mb->ir);\r\nif (intr != 0)\r\nmace_handle_misc_intrs(mp, intr, dev);\r\nif (mp->tx_bad_runt) {\r\nfs = in_8(&mb->xmtfs);\r\nmp->tx_bad_runt = 0;\r\nout_8(&mb->xmtfc, AUTO_PAD_XMIT);\r\ncontinue;\r\n}\r\ndstat = ld_le32(&td->status);\r\nout_le32(&td->control, RUN << 16);\r\nxcount = (in_8(&mb->fifofc) >> XMTFC_SH) & XMTFC_MASK;\r\nif (xcount == 0 || (dstat & DEAD)) {\r\nout_8(&mb->xmtfc, DXMTFCS);\r\n}\r\nfs = in_8(&mb->xmtfs);\r\nif ((fs & XMTSV) == 0) {\r\nprintk(KERN_ERR "mace: xmtfs not valid! (fs=%x xc=%d ds=%x)\n",\r\nfs, xcount, dstat);\r\nmace_reset(dev);\r\n}\r\ncp = mp->tx_cmds + NCMDS_TX * i;\r\nstat = ld_le16(&cp->xfer_status);\r\nif ((fs & (UFLO|LCOL|LCAR|RTRY)) || (dstat & DEAD) || xcount == 0) {\r\nudelay(1);\r\nx = (in_8(&mb->fifofc) >> XMTFC_SH) & XMTFC_MASK;\r\nif (x != 0) {\r\nmp->tx_bad_runt = 1;\r\nmace_set_timeout(dev);\r\n} else {\r\nout_8(&mb->maccc, in_8(&mb->maccc) & ~ENXMT);\r\nout_8(&mb->fifocc, in_8(&mb->fifocc) | XMTFWU);\r\nudelay(1);\r\nout_8(&mb->maccc, in_8(&mb->maccc) | ENXMT);\r\nout_8(&mb->xmtfc, AUTO_PAD_XMIT);\r\n}\r\n}\r\nif (i == mp->tx_fill) {\r\nprintk(KERN_DEBUG "mace: tx ring ran out? (fs=%x xc=%d ds=%x)\n",\r\nfs, xcount, dstat);\r\ncontinue;\r\n}\r\nif (fs & (UFLO|LCOL|LCAR|RTRY)) {\r\n++dev->stats.tx_errors;\r\nif (fs & LCAR)\r\n++dev->stats.tx_carrier_errors;\r\nif (fs & (UFLO|LCOL|RTRY))\r\n++dev->stats.tx_aborted_errors;\r\n} else {\r\ndev->stats.tx_bytes += mp->tx_bufs[i]->len;\r\n++dev->stats.tx_packets;\r\n}\r\ndev_kfree_skb_irq(mp->tx_bufs[i]);\r\n--mp->tx_active;\r\nif (++i >= N_TX_RING)\r\ni = 0;\r\n#if 0\r\nmace_last_fs = fs;\r\nmace_last_xcount = xcount;\r\n#endif\r\n}\r\nif (i != mp->tx_empty) {\r\nmp->tx_fullup = 0;\r\nnetif_wake_queue(dev);\r\n}\r\nmp->tx_empty = i;\r\ni += mp->tx_active;\r\nif (i >= N_TX_RING)\r\ni -= N_TX_RING;\r\nif (!mp->tx_bad_runt && i != mp->tx_fill && mp->tx_active < MAX_TX_ACTIVE) {\r\ndo {\r\ncp = mp->tx_cmds + NCMDS_TX * i;\r\nout_le16(&cp->xfer_status, 0);\r\nout_le16(&cp->command, OUTPUT_LAST);\r\n++mp->tx_active;\r\nif (++i >= N_TX_RING)\r\ni = 0;\r\n} while (i != mp->tx_fill && mp->tx_active < MAX_TX_ACTIVE);\r\nout_le32(&td->control, ((RUN|WAKE) << 16) + (RUN|WAKE));\r\nmace_set_timeout(dev);\r\n}\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void mace_tx_timeout(unsigned long data)\r\n{\r\nstruct net_device *dev = (struct net_device *) data;\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct mace __iomem *mb = mp->mace;\r\nvolatile struct dbdma_regs __iomem *td = mp->tx_dma;\r\nvolatile struct dbdma_regs __iomem *rd = mp->rx_dma;\r\nvolatile struct dbdma_cmd *cp;\r\nunsigned long flags;\r\nint i;\r\nspin_lock_irqsave(&mp->lock, flags);\r\nmp->timeout_active = 0;\r\nif (mp->tx_active == 0 && !mp->tx_bad_runt)\r\ngoto out;\r\nmace_handle_misc_intrs(mp, in_8(&mb->ir), dev);\r\ncp = mp->tx_cmds + NCMDS_TX * mp->tx_empty;\r\nout_8(&mb->maccc, 0);\r\nprintk(KERN_ERR "mace: transmit timeout - resetting\n");\r\ndbdma_reset(td);\r\nmace_reset(dev);\r\ncp = bus_to_virt(ld_le32(&rd->cmdptr));\r\ndbdma_reset(rd);\r\nout_le16(&cp->xfer_status, 0);\r\nout_le32(&rd->cmdptr, virt_to_bus(cp));\r\nout_le32(&rd->control, (RUN << 16) | RUN);\r\ni = mp->tx_empty;\r\nmp->tx_active = 0;\r\n++dev->stats.tx_errors;\r\nif (mp->tx_bad_runt) {\r\nmp->tx_bad_runt = 0;\r\n} else if (i != mp->tx_fill) {\r\ndev_kfree_skb(mp->tx_bufs[i]);\r\nif (++i >= N_TX_RING)\r\ni = 0;\r\nmp->tx_empty = i;\r\n}\r\nmp->tx_fullup = 0;\r\nnetif_wake_queue(dev);\r\nif (i != mp->tx_fill) {\r\ncp = mp->tx_cmds + NCMDS_TX * i;\r\nout_le16(&cp->xfer_status, 0);\r\nout_le16(&cp->command, OUTPUT_LAST);\r\nout_le32(&td->cmdptr, virt_to_bus(cp));\r\nout_le32(&td->control, (RUN << 16) | RUN);\r\n++mp->tx_active;\r\nmace_set_timeout(dev);\r\n}\r\nout_8(&mb->imr, RCVINT);\r\nout_8(&mb->maccc, mp->maccc);\r\nout:\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\n}\r\nstatic irqreturn_t mace_txdma_intr(int irq, void *dev_id)\r\n{\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t mace_rxdma_intr(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *) dev_id;\r\nstruct mace_data *mp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *rd = mp->rx_dma;\r\nvolatile struct dbdma_cmd *cp, *np;\r\nint i, nb, stat, next;\r\nstruct sk_buff *skb;\r\nunsigned frame_status;\r\nstatic int mace_lost_status;\r\nunsigned char *data;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mp->lock, flags);\r\nfor (i = mp->rx_empty; i != mp->rx_fill; ) {\r\ncp = mp->rx_cmds + i;\r\nstat = ld_le16(&cp->xfer_status);\r\nif ((stat & ACTIVE) == 0) {\r\nnext = i + 1;\r\nif (next >= N_RX_RING)\r\nnext = 0;\r\nnp = mp->rx_cmds + next;\r\nif (next != mp->rx_fill &&\r\n(ld_le16(&np->xfer_status) & ACTIVE) != 0) {\r\nprintk(KERN_DEBUG "mace: lost a status word\n");\r\n++mace_lost_status;\r\n} else\r\nbreak;\r\n}\r\nnb = ld_le16(&cp->req_count) - ld_le16(&cp->res_count);\r\nout_le16(&cp->command, DBDMA_STOP);\r\nskb = mp->rx_bufs[i];\r\nif (!skb) {\r\n++dev->stats.rx_dropped;\r\n} else if (nb > 8) {\r\ndata = skb->data;\r\nframe_status = (data[nb-3] << 8) + data[nb-4];\r\nif (frame_status & (RS_OFLO|RS_CLSN|RS_FRAMERR|RS_FCSERR)) {\r\n++dev->stats.rx_errors;\r\nif (frame_status & RS_OFLO)\r\n++dev->stats.rx_over_errors;\r\nif (frame_status & RS_FRAMERR)\r\n++dev->stats.rx_frame_errors;\r\nif (frame_status & RS_FCSERR)\r\n++dev->stats.rx_crc_errors;\r\n} else {\r\nif (*(unsigned short *)(data+12) < 1536)\r\nnb -= 4;\r\nelse\r\nnb -= 8;\r\nskb_put(skb, nb);\r\nskb->protocol = eth_type_trans(skb, dev);\r\ndev->stats.rx_bytes += skb->len;\r\nnetif_rx(skb);\r\nmp->rx_bufs[i] = NULL;\r\n++dev->stats.rx_packets;\r\n}\r\n} else {\r\n++dev->stats.rx_errors;\r\n++dev->stats.rx_length_errors;\r\n}\r\nif (++i >= N_RX_RING)\r\ni = 0;\r\n}\r\nmp->rx_empty = i;\r\ni = mp->rx_fill;\r\nfor (;;) {\r\nnext = i + 1;\r\nif (next >= N_RX_RING)\r\nnext = 0;\r\nif (next == mp->rx_empty)\r\nbreak;\r\ncp = mp->rx_cmds + i;\r\nskb = mp->rx_bufs[i];\r\nif (!skb) {\r\nskb = dev_alloc_skb(RX_BUFLEN + 2);\r\nif (skb) {\r\nskb_reserve(skb, 2);\r\nmp->rx_bufs[i] = skb;\r\n}\r\n}\r\nst_le16(&cp->req_count, RX_BUFLEN);\r\ndata = skb? skb->data: dummy_buf;\r\nst_le32(&cp->phy_addr, virt_to_bus(data));\r\nout_le16(&cp->xfer_status, 0);\r\nout_le16(&cp->command, INPUT_LAST + INTR_ALWAYS);\r\n#if 0\r\nif ((ld_le32(&rd->status) & ACTIVE) != 0) {\r\nout_le32(&rd->control, (PAUSE << 16) | PAUSE);\r\nwhile ((in_le32(&rd->status) & ACTIVE) != 0)\r\n;\r\n}\r\n#endif\r\ni = next;\r\n}\r\nif (i != mp->rx_fill) {\r\nout_le32(&rd->control, ((RUN|WAKE) << 16) | (RUN|WAKE));\r\nmp->rx_fill = i;\r\n}\r\nspin_unlock_irqrestore(&mp->lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int __init mace_init(void)\r\n{\r\nreturn macio_register_driver(&mace_driver);\r\n}\r\nstatic void __exit mace_cleanup(void)\r\n{\r\nmacio_unregister_driver(&mace_driver);\r\nkfree(dummy_buf);\r\ndummy_buf = NULL;\r\n}
