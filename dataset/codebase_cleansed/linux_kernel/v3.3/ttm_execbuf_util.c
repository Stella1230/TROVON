static void ttm_eu_backoff_reservation_locked(struct list_head *list)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nlist_for_each_entry(entry, list, head) {\r\nstruct ttm_buffer_object *bo = entry->bo;\r\nif (!entry->reserved)\r\ncontinue;\r\nif (entry->removed) {\r\nttm_bo_add_to_lru(bo);\r\nentry->removed = false;\r\n}\r\nentry->reserved = false;\r\natomic_set(&bo->reserved, 0);\r\nwake_up_all(&bo->event_queue);\r\n}\r\n}\r\nstatic void ttm_eu_del_from_lru_locked(struct list_head *list)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nlist_for_each_entry(entry, list, head) {\r\nstruct ttm_buffer_object *bo = entry->bo;\r\nif (!entry->reserved)\r\ncontinue;\r\nif (!entry->removed) {\r\nentry->put_count = ttm_bo_del_from_lru(bo);\r\nentry->removed = true;\r\n}\r\n}\r\n}\r\nstatic void ttm_eu_list_ref_sub(struct list_head *list)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nlist_for_each_entry(entry, list, head) {\r\nstruct ttm_buffer_object *bo = entry->bo;\r\nif (entry->put_count) {\r\nttm_bo_list_ref_sub(bo, entry->put_count, true);\r\nentry->put_count = 0;\r\n}\r\n}\r\n}\r\nstatic int ttm_eu_wait_unreserved_locked(struct list_head *list,\r\nstruct ttm_buffer_object *bo)\r\n{\r\nstruct ttm_bo_global *glob = bo->glob;\r\nint ret;\r\nttm_eu_del_from_lru_locked(list);\r\nspin_unlock(&glob->lru_lock);\r\nret = ttm_bo_wait_unreserved(bo, true);\r\nspin_lock(&glob->lru_lock);\r\nif (unlikely(ret != 0))\r\nttm_eu_backoff_reservation_locked(list);\r\nreturn ret;\r\n}\r\nvoid ttm_eu_backoff_reservation(struct list_head *list)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nstruct ttm_bo_global *glob;\r\nif (list_empty(list))\r\nreturn;\r\nentry = list_first_entry(list, struct ttm_validate_buffer, head);\r\nglob = entry->bo->glob;\r\nspin_lock(&glob->lru_lock);\r\nttm_eu_backoff_reservation_locked(list);\r\nspin_unlock(&glob->lru_lock);\r\n}\r\nint ttm_eu_reserve_buffers(struct list_head *list)\r\n{\r\nstruct ttm_bo_global *glob;\r\nstruct ttm_validate_buffer *entry;\r\nint ret;\r\nuint32_t val_seq;\r\nif (list_empty(list))\r\nreturn 0;\r\nlist_for_each_entry(entry, list, head) {\r\nentry->reserved = false;\r\nentry->put_count = 0;\r\nentry->removed = false;\r\n}\r\nentry = list_first_entry(list, struct ttm_validate_buffer, head);\r\nglob = entry->bo->glob;\r\nretry:\r\nspin_lock(&glob->lru_lock);\r\nval_seq = entry->bo->bdev->val_seq++;\r\nlist_for_each_entry(entry, list, head) {\r\nstruct ttm_buffer_object *bo = entry->bo;\r\nretry_this_bo:\r\nret = ttm_bo_reserve_locked(bo, true, true, true, val_seq);\r\nswitch (ret) {\r\ncase 0:\r\nbreak;\r\ncase -EBUSY:\r\nret = ttm_eu_wait_unreserved_locked(list, bo);\r\nif (unlikely(ret != 0)) {\r\nspin_unlock(&glob->lru_lock);\r\nttm_eu_list_ref_sub(list);\r\nreturn ret;\r\n}\r\ngoto retry_this_bo;\r\ncase -EAGAIN:\r\nttm_eu_backoff_reservation_locked(list);\r\nspin_unlock(&glob->lru_lock);\r\nttm_eu_list_ref_sub(list);\r\nret = ttm_bo_wait_unreserved(bo, true);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\ngoto retry;\r\ndefault:\r\nttm_eu_backoff_reservation_locked(list);\r\nspin_unlock(&glob->lru_lock);\r\nttm_eu_list_ref_sub(list);\r\nreturn ret;\r\n}\r\nentry->reserved = true;\r\nif (unlikely(atomic_read(&bo->cpu_writers) > 0)) {\r\nttm_eu_backoff_reservation_locked(list);\r\nspin_unlock(&glob->lru_lock);\r\nttm_eu_list_ref_sub(list);\r\nret = ttm_bo_wait_cpu(bo, false);\r\nif (ret)\r\nreturn ret;\r\ngoto retry;\r\n}\r\n}\r\nttm_eu_del_from_lru_locked(list);\r\nspin_unlock(&glob->lru_lock);\r\nttm_eu_list_ref_sub(list);\r\nreturn 0;\r\n}\r\nvoid ttm_eu_fence_buffer_objects(struct list_head *list, void *sync_obj)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nstruct ttm_buffer_object *bo;\r\nstruct ttm_bo_global *glob;\r\nstruct ttm_bo_device *bdev;\r\nstruct ttm_bo_driver *driver;\r\nif (list_empty(list))\r\nreturn;\r\nbo = list_first_entry(list, struct ttm_validate_buffer, head)->bo;\r\nbdev = bo->bdev;\r\ndriver = bdev->driver;\r\nglob = bo->glob;\r\nspin_lock(&bdev->fence_lock);\r\nspin_lock(&glob->lru_lock);\r\nlist_for_each_entry(entry, list, head) {\r\nbo = entry->bo;\r\nentry->old_sync_obj = bo->sync_obj;\r\nbo->sync_obj = driver->sync_obj_ref(sync_obj);\r\nbo->sync_obj_arg = entry->new_sync_obj_arg;\r\nttm_bo_unreserve_locked(bo);\r\nentry->reserved = false;\r\n}\r\nspin_unlock(&glob->lru_lock);\r\nspin_unlock(&bdev->fence_lock);\r\nlist_for_each_entry(entry, list, head) {\r\nif (entry->old_sync_obj)\r\ndriver->sync_obj_unref(&entry->old_sync_obj);\r\n}\r\n}
