static int ep93xx_mdio_read(struct net_device *dev, int phy_id, int reg)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nint data;\r\nint i;\r\nwrl(ep, REG_MIICMD, REG_MIICMD_READ | (phy_id << 5) | reg);\r\nfor (i = 0; i < 10; i++) {\r\nif ((rdl(ep, REG_MIISTS) & REG_MIISTS_BUSY) == 0)\r\nbreak;\r\nmsleep(1);\r\n}\r\nif (i == 10) {\r\npr_info("mdio read timed out\n");\r\ndata = 0xffff;\r\n} else {\r\ndata = rdl(ep, REG_MIIDATA);\r\n}\r\nreturn data;\r\n}\r\nstatic void ep93xx_mdio_write(struct net_device *dev, int phy_id, int reg, int data)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nint i;\r\nwrl(ep, REG_MIIDATA, data);\r\nwrl(ep, REG_MIICMD, REG_MIICMD_WRITE | (phy_id << 5) | reg);\r\nfor (i = 0; i < 10; i++) {\r\nif ((rdl(ep, REG_MIISTS) & REG_MIISTS_BUSY) == 0)\r\nbreak;\r\nmsleep(1);\r\n}\r\nif (i == 10)\r\npr_info("mdio write timed out\n");\r\n}\r\nstatic int ep93xx_rx(struct net_device *dev, int processed, int budget)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nwhile (processed < budget) {\r\nint entry;\r\nstruct ep93xx_rstat *rstat;\r\nu32 rstat0;\r\nu32 rstat1;\r\nint length;\r\nstruct sk_buff *skb;\r\nentry = ep->rx_pointer;\r\nrstat = ep->descs->rstat + entry;\r\nrstat0 = rstat->rstat0;\r\nrstat1 = rstat->rstat1;\r\nif (!(rstat0 & RSTAT0_RFP) || !(rstat1 & RSTAT1_RFP))\r\nbreak;\r\nrstat->rstat0 = 0;\r\nrstat->rstat1 = 0;\r\nif (!(rstat0 & RSTAT0_EOF))\r\npr_crit("not end-of-frame %.8x %.8x\n", rstat0, rstat1);\r\nif (!(rstat0 & RSTAT0_EOB))\r\npr_crit("not end-of-buffer %.8x %.8x\n", rstat0, rstat1);\r\nif ((rstat1 & RSTAT1_BUFFER_INDEX) >> 16 != entry)\r\npr_crit("entry mismatch %.8x %.8x\n", rstat0, rstat1);\r\nif (!(rstat0 & RSTAT0_RWE)) {\r\ndev->stats.rx_errors++;\r\nif (rstat0 & RSTAT0_OE)\r\ndev->stats.rx_fifo_errors++;\r\nif (rstat0 & RSTAT0_FE)\r\ndev->stats.rx_frame_errors++;\r\nif (rstat0 & (RSTAT0_RUNT | RSTAT0_EDATA))\r\ndev->stats.rx_length_errors++;\r\nif (rstat0 & RSTAT0_CRCE)\r\ndev->stats.rx_crc_errors++;\r\ngoto err;\r\n}\r\nlength = rstat1 & RSTAT1_FRAME_LENGTH;\r\nif (length > MAX_PKT_SIZE) {\r\npr_notice("invalid length %.8x %.8x\n", rstat0, rstat1);\r\ngoto err;\r\n}\r\nif (rstat0 & RSTAT0_CRCI)\r\nlength -= 4;\r\nskb = dev_alloc_skb(length + 2);\r\nif (likely(skb != NULL)) {\r\nstruct ep93xx_rdesc *rxd = &ep->descs->rdesc[entry];\r\nskb_reserve(skb, 2);\r\ndma_sync_single_for_cpu(dev->dev.parent, rxd->buf_addr,\r\nlength, DMA_FROM_DEVICE);\r\nskb_copy_to_linear_data(skb, ep->rx_buf[entry], length);\r\ndma_sync_single_for_device(dev->dev.parent,\r\nrxd->buf_addr, length,\r\nDMA_FROM_DEVICE);\r\nskb_put(skb, length);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_receive_skb(skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += length;\r\n} else {\r\ndev->stats.rx_dropped++;\r\n}\r\nerr:\r\nep->rx_pointer = (entry + 1) & (RX_QUEUE_ENTRIES - 1);\r\nprocessed++;\r\n}\r\nreturn processed;\r\n}\r\nstatic int ep93xx_have_more_rx(struct ep93xx_priv *ep)\r\n{\r\nstruct ep93xx_rstat *rstat = ep->descs->rstat + ep->rx_pointer;\r\nreturn !!((rstat->rstat0 & RSTAT0_RFP) && (rstat->rstat1 & RSTAT1_RFP));\r\n}\r\nstatic int ep93xx_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct ep93xx_priv *ep = container_of(napi, struct ep93xx_priv, napi);\r\nstruct net_device *dev = ep->dev;\r\nint rx = 0;\r\npoll_some_more:\r\nrx = ep93xx_rx(dev, rx, budget);\r\nif (rx < budget) {\r\nint more = 0;\r\nspin_lock_irq(&ep->rx_lock);\r\n__napi_complete(napi);\r\nwrl(ep, REG_INTEN, REG_INTEN_TX | REG_INTEN_RX);\r\nif (ep93xx_have_more_rx(ep)) {\r\nwrl(ep, REG_INTEN, REG_INTEN_TX);\r\nwrl(ep, REG_INTSTSP, REG_INTSTS_RX);\r\nmore = 1;\r\n}\r\nspin_unlock_irq(&ep->rx_lock);\r\nif (more && napi_reschedule(napi))\r\ngoto poll_some_more;\r\n}\r\nif (rx) {\r\nwrw(ep, REG_RXDENQ, rx);\r\nwrw(ep, REG_RXSTSENQ, rx);\r\n}\r\nreturn rx;\r\n}\r\nstatic int ep93xx_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nstruct ep93xx_tdesc *txd;\r\nint entry;\r\nif (unlikely(skb->len > MAX_PKT_SIZE)) {\r\ndev->stats.tx_dropped++;\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nentry = ep->tx_pointer;\r\nep->tx_pointer = (ep->tx_pointer + 1) & (TX_QUEUE_ENTRIES - 1);\r\ntxd = &ep->descs->tdesc[entry];\r\ntxd->tdesc1 = TDESC1_EOF | (entry << 16) | (skb->len & 0xfff);\r\ndma_sync_single_for_cpu(dev->dev.parent, txd->buf_addr, skb->len,\r\nDMA_TO_DEVICE);\r\nskb_copy_and_csum_dev(skb, ep->tx_buf[entry]);\r\ndma_sync_single_for_device(dev->dev.parent, txd->buf_addr, skb->len,\r\nDMA_TO_DEVICE);\r\ndev_kfree_skb(skb);\r\nspin_lock_irq(&ep->tx_pending_lock);\r\nep->tx_pending++;\r\nif (ep->tx_pending == TX_QUEUE_ENTRIES)\r\nnetif_stop_queue(dev);\r\nspin_unlock_irq(&ep->tx_pending_lock);\r\nwrl(ep, REG_TXDENQ, 1);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void ep93xx_tx_complete(struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nint wake;\r\nwake = 0;\r\nspin_lock(&ep->tx_pending_lock);\r\nwhile (1) {\r\nint entry;\r\nstruct ep93xx_tstat *tstat;\r\nu32 tstat0;\r\nentry = ep->tx_clean_pointer;\r\ntstat = ep->descs->tstat + entry;\r\ntstat0 = tstat->tstat0;\r\nif (!(tstat0 & TSTAT0_TXFP))\r\nbreak;\r\ntstat->tstat0 = 0;\r\nif (tstat0 & TSTAT0_FA)\r\npr_crit("frame aborted %.8x\n", tstat0);\r\nif ((tstat0 & TSTAT0_BUFFER_INDEX) != entry)\r\npr_crit("entry mismatch %.8x\n", tstat0);\r\nif (tstat0 & TSTAT0_TXWE) {\r\nint length = ep->descs->tdesc[entry].tdesc1 & 0xfff;\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += length;\r\n} else {\r\ndev->stats.tx_errors++;\r\n}\r\nif (tstat0 & TSTAT0_OW)\r\ndev->stats.tx_window_errors++;\r\nif (tstat0 & TSTAT0_TXU)\r\ndev->stats.tx_fifo_errors++;\r\ndev->stats.collisions += (tstat0 >> 16) & 0x1f;\r\nep->tx_clean_pointer = (entry + 1) & (TX_QUEUE_ENTRIES - 1);\r\nif (ep->tx_pending == TX_QUEUE_ENTRIES)\r\nwake = 1;\r\nep->tx_pending--;\r\n}\r\nspin_unlock(&ep->tx_pending_lock);\r\nif (wake)\r\nnetif_wake_queue(dev);\r\n}\r\nstatic irqreturn_t ep93xx_irq(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = dev_id;\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nu32 status;\r\nstatus = rdl(ep, REG_INTSTSC);\r\nif (status == 0)\r\nreturn IRQ_NONE;\r\nif (status & REG_INTSTS_RX) {\r\nspin_lock(&ep->rx_lock);\r\nif (likely(napi_schedule_prep(&ep->napi))) {\r\nwrl(ep, REG_INTEN, REG_INTEN_TX);\r\n__napi_schedule(&ep->napi);\r\n}\r\nspin_unlock(&ep->rx_lock);\r\n}\r\nif (status & REG_INTSTS_TX)\r\nep93xx_tx_complete(dev);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void ep93xx_free_buffers(struct ep93xx_priv *ep)\r\n{\r\nstruct device *dev = ep->dev->dev.parent;\r\nint i;\r\nfor (i = 0; i < RX_QUEUE_ENTRIES; i++) {\r\ndma_addr_t d;\r\nd = ep->descs->rdesc[i].buf_addr;\r\nif (d)\r\ndma_unmap_single(dev, d, PKT_BUF_SIZE, DMA_FROM_DEVICE);\r\nif (ep->rx_buf[i] != NULL)\r\nkfree(ep->rx_buf[i]);\r\n}\r\nfor (i = 0; i < TX_QUEUE_ENTRIES; i++) {\r\ndma_addr_t d;\r\nd = ep->descs->tdesc[i].buf_addr;\r\nif (d)\r\ndma_unmap_single(dev, d, PKT_BUF_SIZE, DMA_TO_DEVICE);\r\nif (ep->tx_buf[i] != NULL)\r\nkfree(ep->tx_buf[i]);\r\n}\r\ndma_free_coherent(dev, sizeof(struct ep93xx_descs), ep->descs,\r\nep->descs_dma_addr);\r\n}\r\nstatic int ep93xx_alloc_buffers(struct ep93xx_priv *ep)\r\n{\r\nstruct device *dev = ep->dev->dev.parent;\r\nint i;\r\nep->descs = dma_alloc_coherent(dev, sizeof(struct ep93xx_descs),\r\n&ep->descs_dma_addr, GFP_KERNEL);\r\nif (ep->descs == NULL)\r\nreturn 1;\r\nfor (i = 0; i < RX_QUEUE_ENTRIES; i++) {\r\nvoid *buf;\r\ndma_addr_t d;\r\nbuf = kmalloc(PKT_BUF_SIZE, GFP_KERNEL);\r\nif (buf == NULL)\r\ngoto err;\r\nd = dma_map_single(dev, buf, PKT_BUF_SIZE, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(dev, d)) {\r\nkfree(buf);\r\ngoto err;\r\n}\r\nep->rx_buf[i] = buf;\r\nep->descs->rdesc[i].buf_addr = d;\r\nep->descs->rdesc[i].rdesc1 = (i << 16) | PKT_BUF_SIZE;\r\n}\r\nfor (i = 0; i < TX_QUEUE_ENTRIES; i++) {\r\nvoid *buf;\r\ndma_addr_t d;\r\nbuf = kmalloc(PKT_BUF_SIZE, GFP_KERNEL);\r\nif (buf == NULL)\r\ngoto err;\r\nd = dma_map_single(dev, buf, PKT_BUF_SIZE, DMA_TO_DEVICE);\r\nif (dma_mapping_error(dev, d)) {\r\nkfree(buf);\r\ngoto err;\r\n}\r\nep->tx_buf[i] = buf;\r\nep->descs->tdesc[i].buf_addr = d;\r\n}\r\nreturn 0;\r\nerr:\r\nep93xx_free_buffers(ep);\r\nreturn 1;\r\n}\r\nstatic int ep93xx_start_hw(struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nunsigned long addr;\r\nint i;\r\nwrl(ep, REG_SELFCTL, REG_SELFCTL_RESET);\r\nfor (i = 0; i < 10; i++) {\r\nif ((rdl(ep, REG_SELFCTL) & REG_SELFCTL_RESET) == 0)\r\nbreak;\r\nmsleep(1);\r\n}\r\nif (i == 10) {\r\npr_crit("hw failed to reset\n");\r\nreturn 1;\r\n}\r\nwrl(ep, REG_SELFCTL, ((ep->mdc_divisor - 1) << 9));\r\nif ((ep93xx_mdio_read(dev, ep->mii.phy_id, MII_BMSR) & 0x0040) != 0)\r\nwrl(ep, REG_SELFCTL, ((ep->mdc_divisor - 1) << 9) | (1 << 8));\r\naddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, rdesc);\r\nwrl(ep, REG_RXDQBADD, addr);\r\nwrl(ep, REG_RXDCURADD, addr);\r\nwrw(ep, REG_RXDQBLEN, RX_QUEUE_ENTRIES * sizeof(struct ep93xx_rdesc));\r\naddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, rstat);\r\nwrl(ep, REG_RXSTSQBADD, addr);\r\nwrl(ep, REG_RXSTSQCURADD, addr);\r\nwrw(ep, REG_RXSTSQBLEN, RX_QUEUE_ENTRIES * sizeof(struct ep93xx_rstat));\r\naddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, tdesc);\r\nwrl(ep, REG_TXDQBADD, addr);\r\nwrl(ep, REG_TXDQCURADD, addr);\r\nwrw(ep, REG_TXDQBLEN, TX_QUEUE_ENTRIES * sizeof(struct ep93xx_tdesc));\r\naddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, tstat);\r\nwrl(ep, REG_TXSTSQBADD, addr);\r\nwrl(ep, REG_TXSTSQCURADD, addr);\r\nwrw(ep, REG_TXSTSQBLEN, TX_QUEUE_ENTRIES * sizeof(struct ep93xx_tstat));\r\nwrl(ep, REG_BMCTL, REG_BMCTL_ENABLE_TX | REG_BMCTL_ENABLE_RX);\r\nwrl(ep, REG_INTEN, REG_INTEN_TX | REG_INTEN_RX);\r\nwrl(ep, REG_GIINTMSK, 0);\r\nfor (i = 0; i < 10; i++) {\r\nif ((rdl(ep, REG_BMSTS) & REG_BMSTS_RX_ACTIVE) != 0)\r\nbreak;\r\nmsleep(1);\r\n}\r\nif (i == 10) {\r\npr_crit("hw failed to start\n");\r\nreturn 1;\r\n}\r\nwrl(ep, REG_RXDENQ, RX_QUEUE_ENTRIES);\r\nwrl(ep, REG_RXSTSENQ, RX_QUEUE_ENTRIES);\r\nwrb(ep, REG_INDAD0, dev->dev_addr[0]);\r\nwrb(ep, REG_INDAD1, dev->dev_addr[1]);\r\nwrb(ep, REG_INDAD2, dev->dev_addr[2]);\r\nwrb(ep, REG_INDAD3, dev->dev_addr[3]);\r\nwrb(ep, REG_INDAD4, dev->dev_addr[4]);\r\nwrb(ep, REG_INDAD5, dev->dev_addr[5]);\r\nwrl(ep, REG_AFP, 0);\r\nwrl(ep, REG_MAXFRMLEN, (MAX_PKT_SIZE << 16) | MAX_PKT_SIZE);\r\nwrl(ep, REG_RXCTL, REG_RXCTL_DEFAULT);\r\nwrl(ep, REG_TXCTL, REG_TXCTL_ENABLE);\r\nreturn 0;\r\n}\r\nstatic void ep93xx_stop_hw(struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nint i;\r\nwrl(ep, REG_SELFCTL, REG_SELFCTL_RESET);\r\nfor (i = 0; i < 10; i++) {\r\nif ((rdl(ep, REG_SELFCTL) & REG_SELFCTL_RESET) == 0)\r\nbreak;\r\nmsleep(1);\r\n}\r\nif (i == 10)\r\npr_crit("hw failed to reset\n");\r\n}\r\nstatic int ep93xx_open(struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nint err;\r\nif (ep93xx_alloc_buffers(ep))\r\nreturn -ENOMEM;\r\nnapi_enable(&ep->napi);\r\nif (ep93xx_start_hw(dev)) {\r\nnapi_disable(&ep->napi);\r\nep93xx_free_buffers(ep);\r\nreturn -EIO;\r\n}\r\nspin_lock_init(&ep->rx_lock);\r\nep->rx_pointer = 0;\r\nep->tx_clean_pointer = 0;\r\nep->tx_pointer = 0;\r\nspin_lock_init(&ep->tx_pending_lock);\r\nep->tx_pending = 0;\r\nerr = request_irq(ep->irq, ep93xx_irq, IRQF_SHARED, dev->name, dev);\r\nif (err) {\r\nnapi_disable(&ep->napi);\r\nep93xx_stop_hw(dev);\r\nep93xx_free_buffers(ep);\r\nreturn err;\r\n}\r\nwrl(ep, REG_GIINTMSK, REG_GIINTMSK_ENABLE);\r\nnetif_start_queue(dev);\r\nreturn 0;\r\n}\r\nstatic int ep93xx_close(struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nnapi_disable(&ep->napi);\r\nnetif_stop_queue(dev);\r\nwrl(ep, REG_GIINTMSK, 0);\r\nfree_irq(ep->irq, dev);\r\nep93xx_stop_hw(dev);\r\nep93xx_free_buffers(ep);\r\nreturn 0;\r\n}\r\nstatic int ep93xx_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nstruct mii_ioctl_data *data = if_mii(ifr);\r\nreturn generic_mii_ioctl(&ep->mii, data, cmd, NULL);\r\n}\r\nstatic void ep93xx_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstrcpy(info->driver, DRV_MODULE_NAME);\r\nstrcpy(info->version, DRV_MODULE_VERSION);\r\n}\r\nstatic int ep93xx_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nreturn mii_ethtool_gset(&ep->mii, cmd);\r\n}\r\nstatic int ep93xx_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nreturn mii_ethtool_sset(&ep->mii, cmd);\r\n}\r\nstatic int ep93xx_nway_reset(struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nreturn mii_nway_restart(&ep->mii);\r\n}\r\nstatic u32 ep93xx_get_link(struct net_device *dev)\r\n{\r\nstruct ep93xx_priv *ep = netdev_priv(dev);\r\nreturn mii_link_ok(&ep->mii);\r\n}\r\nstatic struct net_device *ep93xx_dev_alloc(struct ep93xx_eth_data *data)\r\n{\r\nstruct net_device *dev;\r\ndev = alloc_etherdev(sizeof(struct ep93xx_priv));\r\nif (dev == NULL)\r\nreturn NULL;\r\nmemcpy(dev->dev_addr, data->dev_addr, ETH_ALEN);\r\ndev->ethtool_ops = &ep93xx_ethtool_ops;\r\ndev->netdev_ops = &ep93xx_netdev_ops;\r\ndev->features |= NETIF_F_SG | NETIF_F_HW_CSUM;\r\nreturn dev;\r\n}\r\nstatic int ep93xx_eth_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *dev;\r\nstruct ep93xx_priv *ep;\r\ndev = platform_get_drvdata(pdev);\r\nif (dev == NULL)\r\nreturn 0;\r\nplatform_set_drvdata(pdev, NULL);\r\nep = netdev_priv(dev);\r\nunregister_netdev(dev);\r\nep93xx_free_buffers(ep);\r\nif (ep->base_addr != NULL)\r\niounmap(ep->base_addr);\r\nif (ep->res != NULL) {\r\nrelease_resource(ep->res);\r\nkfree(ep->res);\r\n}\r\nfree_netdev(dev);\r\nreturn 0;\r\n}\r\nstatic int ep93xx_eth_probe(struct platform_device *pdev)\r\n{\r\nstruct ep93xx_eth_data *data;\r\nstruct net_device *dev;\r\nstruct ep93xx_priv *ep;\r\nstruct resource *mem;\r\nint irq;\r\nint err;\r\nif (pdev == NULL)\r\nreturn -ENODEV;\r\ndata = pdev->dev.platform_data;\r\nmem = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nirq = platform_get_irq(pdev, 0);\r\nif (!mem || irq < 0)\r\nreturn -ENXIO;\r\ndev = ep93xx_dev_alloc(data);\r\nif (dev == NULL) {\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\nep = netdev_priv(dev);\r\nep->dev = dev;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nnetif_napi_add(dev, &ep->napi, ep93xx_poll, 64);\r\nplatform_set_drvdata(pdev, dev);\r\nep->res = request_mem_region(mem->start, resource_size(mem),\r\ndev_name(&pdev->dev));\r\nif (ep->res == NULL) {\r\ndev_err(&pdev->dev, "Could not reserve memory region\n");\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\nep->base_addr = ioremap(mem->start, resource_size(mem));\r\nif (ep->base_addr == NULL) {\r\ndev_err(&pdev->dev, "Failed to ioremap ethernet registers\n");\r\nerr = -EIO;\r\ngoto err_out;\r\n}\r\nep->irq = irq;\r\nep->mii.phy_id = data->phy_id;\r\nep->mii.phy_id_mask = 0x1f;\r\nep->mii.reg_num_mask = 0x1f;\r\nep->mii.dev = dev;\r\nep->mii.mdio_read = ep93xx_mdio_read;\r\nep->mii.mdio_write = ep93xx_mdio_write;\r\nep->mdc_divisor = 40;\r\nif (is_zero_ether_addr(dev->dev_addr))\r\nrandom_ether_addr(dev->dev_addr);\r\nerr = register_netdev(dev);\r\nif (err) {\r\ndev_err(&pdev->dev, "Failed to register netdev\n");\r\ngoto err_out;\r\n}\r\nprintk(KERN_INFO "%s: ep93xx on-chip ethernet, IRQ %d, %pM\n",\r\ndev->name, ep->irq, dev->dev_addr);\r\nreturn 0;\r\nerr_out:\r\nep93xx_eth_remove(pdev);\r\nreturn err;\r\n}\r\nstatic int __init ep93xx_eth_init_module(void)\r\n{\r\nprintk(KERN_INFO DRV_MODULE_NAME " version " DRV_MODULE_VERSION " loading\n");\r\nreturn platform_driver_register(&ep93xx_eth_driver);\r\n}\r\nstatic void __exit ep93xx_eth_cleanup_module(void)\r\n{\r\nplatform_driver_unregister(&ep93xx_eth_driver);\r\n}
