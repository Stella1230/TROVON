void\r\nnvc0_vm_map_pgt(struct nouveau_gpuobj *pgd, u32 index,\r\nstruct nouveau_gpuobj *pgt[2])\r\n{\r\nu32 pde[2] = { 0, 0 };\r\nif (pgt[0])\r\npde[1] = 0x00000001 | (pgt[0]->vinst >> 8);\r\nif (pgt[1])\r\npde[0] = 0x00000001 | (pgt[1]->vinst >> 8);\r\nnv_wo32(pgd, (index * 8) + 0, pde[0]);\r\nnv_wo32(pgd, (index * 8) + 4, pde[1]);\r\n}\r\nstatic inline u64\r\nnvc0_vm_addr(struct nouveau_vma *vma, u64 phys, u32 memtype, u32 target)\r\n{\r\nphys >>= 8;\r\nphys |= 0x00000001;\r\nif (vma->access & NV_MEM_ACCESS_SYS)\r\nphys |= 0x00000002;\r\nphys |= ((u64)target << 32);\r\nphys |= ((u64)memtype << 36);\r\nreturn phys;\r\n}\r\nvoid\r\nnvc0_vm_map(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,\r\nstruct nouveau_mem *mem, u32 pte, u32 cnt, u64 phys, u64 delta)\r\n{\r\nu32 next = 1 << (vma->node->type - 8);\r\nphys = nvc0_vm_addr(vma, phys, mem->memtype, 0);\r\npte <<= 3;\r\nwhile (cnt--) {\r\nnv_wo32(pgt, pte + 0, lower_32_bits(phys));\r\nnv_wo32(pgt, pte + 4, upper_32_bits(phys));\r\nphys += next;\r\npte += 8;\r\n}\r\n}\r\nvoid\r\nnvc0_vm_map_sg(struct nouveau_vma *vma, struct nouveau_gpuobj *pgt,\r\nstruct nouveau_mem *mem, u32 pte, u32 cnt, dma_addr_t *list)\r\n{\r\npte <<= 3;\r\nwhile (cnt--) {\r\nu64 phys = nvc0_vm_addr(vma, *list++, mem->memtype, 5);\r\nnv_wo32(pgt, pte + 0, lower_32_bits(phys));\r\nnv_wo32(pgt, pte + 4, upper_32_bits(phys));\r\npte += 8;\r\n}\r\n}\r\nvoid\r\nnvc0_vm_unmap(struct nouveau_gpuobj *pgt, u32 pte, u32 cnt)\r\n{\r\npte <<= 3;\r\nwhile (cnt--) {\r\nnv_wo32(pgt, pte + 0, 0x00000000);\r\nnv_wo32(pgt, pte + 4, 0x00000000);\r\npte += 8;\r\n}\r\n}\r\nvoid\r\nnvc0_vm_flush(struct nouveau_vm *vm)\r\n{\r\nstruct drm_nouveau_private *dev_priv = vm->dev->dev_private;\r\nstruct nouveau_instmem_engine *pinstmem = &dev_priv->engine.instmem;\r\nstruct drm_device *dev = vm->dev;\r\nstruct nouveau_vm_pgd *vpgd;\r\nunsigned long flags;\r\nu32 engine;\r\nengine = 1;\r\nif (vm == dev_priv->bar1_vm || vm == dev_priv->bar3_vm)\r\nengine |= 4;\r\npinstmem->flush(vm->dev);\r\nspin_lock_irqsave(&dev_priv->vm_lock, flags);\r\nlist_for_each_entry(vpgd, &vm->pgd_list, head) {\r\nif (!nv_wait_ne(dev, 0x100c80, 0x00ff0000, 0x00000000)) {\r\nNV_ERROR(dev, "vm timeout 0: 0x%08x %d\n",\r\nnv_rd32(dev, 0x100c80), engine);\r\n}\r\nnv_wr32(dev, 0x100cb8, vpgd->obj->vinst >> 8);\r\nnv_wr32(dev, 0x100cbc, 0x80000000 | engine);\r\nif (!nv_wait(dev, 0x100c80, 0x00008000, 0x00008000)) {\r\nNV_ERROR(dev, "vm timeout 1: 0x%08x %d\n",\r\nnv_rd32(dev, 0x100c80), engine);\r\n}\r\n}\r\nspin_unlock_irqrestore(&dev_priv->vm_lock, flags);\r\n}
