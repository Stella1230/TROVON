static int cipso_v4_bitmap_walk(const unsigned char *bitmap,\r\nu32 bitmap_len,\r\nu32 offset,\r\nu8 state)\r\n{\r\nu32 bit_spot;\r\nu32 byte_offset;\r\nunsigned char bitmask;\r\nunsigned char byte;\r\nbyte_offset = offset / 8;\r\nbyte = bitmap[byte_offset];\r\nbit_spot = offset;\r\nbitmask = 0x80 >> (offset % 8);\r\nwhile (bit_spot < bitmap_len) {\r\nif ((state && (byte & bitmask) == bitmask) ||\r\n(state == 0 && (byte & bitmask) == 0))\r\nreturn bit_spot;\r\nbit_spot++;\r\nbitmask >>= 1;\r\nif (bitmask == 0) {\r\nbyte = bitmap[++byte_offset];\r\nbitmask = 0x80;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nstatic void cipso_v4_bitmap_setbit(unsigned char *bitmap,\r\nu32 bit,\r\nu8 state)\r\n{\r\nu32 byte_spot;\r\nu8 bitmask;\r\nbyte_spot = bit / 8;\r\nbitmask = 0x80 >> (bit % 8);\r\nif (state)\r\nbitmap[byte_spot] |= bitmask;\r\nelse\r\nbitmap[byte_spot] &= ~bitmask;\r\n}\r\nstatic void cipso_v4_cache_entry_free(struct cipso_v4_map_cache_entry *entry)\r\n{\r\nif (entry->lsm_data)\r\nnetlbl_secattr_cache_free(entry->lsm_data);\r\nkfree(entry->key);\r\nkfree(entry);\r\n}\r\nstatic u32 cipso_v4_map_cache_hash(const unsigned char *key, u32 key_len)\r\n{\r\nreturn jhash(key, key_len, 0);\r\n}\r\nstatic int cipso_v4_cache_init(void)\r\n{\r\nu32 iter;\r\ncipso_v4_cache = kcalloc(CIPSO_V4_CACHE_BUCKETS,\r\nsizeof(struct cipso_v4_map_cache_bkt),\r\nGFP_KERNEL);\r\nif (cipso_v4_cache == NULL)\r\nreturn -ENOMEM;\r\nfor (iter = 0; iter < CIPSO_V4_CACHE_BUCKETS; iter++) {\r\nspin_lock_init(&cipso_v4_cache[iter].lock);\r\ncipso_v4_cache[iter].size = 0;\r\nINIT_LIST_HEAD(&cipso_v4_cache[iter].list);\r\n}\r\nreturn 0;\r\n}\r\nvoid cipso_v4_cache_invalidate(void)\r\n{\r\nstruct cipso_v4_map_cache_entry *entry, *tmp_entry;\r\nu32 iter;\r\nfor (iter = 0; iter < CIPSO_V4_CACHE_BUCKETS; iter++) {\r\nspin_lock_bh(&cipso_v4_cache[iter].lock);\r\nlist_for_each_entry_safe(entry,\r\ntmp_entry,\r\n&cipso_v4_cache[iter].list, list) {\r\nlist_del(&entry->list);\r\ncipso_v4_cache_entry_free(entry);\r\n}\r\ncipso_v4_cache[iter].size = 0;\r\nspin_unlock_bh(&cipso_v4_cache[iter].lock);\r\n}\r\n}\r\nstatic int cipso_v4_cache_check(const unsigned char *key,\r\nu32 key_len,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nu32 bkt;\r\nstruct cipso_v4_map_cache_entry *entry;\r\nstruct cipso_v4_map_cache_entry *prev_entry = NULL;\r\nu32 hash;\r\nif (!cipso_v4_cache_enabled)\r\nreturn -ENOENT;\r\nhash = cipso_v4_map_cache_hash(key, key_len);\r\nbkt = hash & (CIPSO_V4_CACHE_BUCKETS - 1);\r\nspin_lock_bh(&cipso_v4_cache[bkt].lock);\r\nlist_for_each_entry(entry, &cipso_v4_cache[bkt].list, list) {\r\nif (entry->hash == hash &&\r\nentry->key_len == key_len &&\r\nmemcmp(entry->key, key, key_len) == 0) {\r\nentry->activity += 1;\r\natomic_inc(&entry->lsm_data->refcount);\r\nsecattr->cache = entry->lsm_data;\r\nsecattr->flags |= NETLBL_SECATTR_CACHE;\r\nsecattr->type = NETLBL_NLTYPE_CIPSOV4;\r\nif (prev_entry == NULL) {\r\nspin_unlock_bh(&cipso_v4_cache[bkt].lock);\r\nreturn 0;\r\n}\r\nif (prev_entry->activity > 0)\r\nprev_entry->activity -= 1;\r\nif (entry->activity > prev_entry->activity &&\r\nentry->activity - prev_entry->activity >\r\nCIPSO_V4_CACHE_REORDERLIMIT) {\r\n__list_del(entry->list.prev, entry->list.next);\r\n__list_add(&entry->list,\r\nprev_entry->list.prev,\r\n&prev_entry->list);\r\n}\r\nspin_unlock_bh(&cipso_v4_cache[bkt].lock);\r\nreturn 0;\r\n}\r\nprev_entry = entry;\r\n}\r\nspin_unlock_bh(&cipso_v4_cache[bkt].lock);\r\nreturn -ENOENT;\r\n}\r\nint cipso_v4_cache_add(const struct sk_buff *skb,\r\nconst struct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val = -EPERM;\r\nu32 bkt;\r\nstruct cipso_v4_map_cache_entry *entry = NULL;\r\nstruct cipso_v4_map_cache_entry *old_entry = NULL;\r\nunsigned char *cipso_ptr;\r\nu32 cipso_ptr_len;\r\nif (!cipso_v4_cache_enabled || cipso_v4_cache_bucketsize <= 0)\r\nreturn 0;\r\ncipso_ptr = CIPSO_V4_OPTPTR(skb);\r\ncipso_ptr_len = cipso_ptr[1];\r\nentry = kzalloc(sizeof(*entry), GFP_ATOMIC);\r\nif (entry == NULL)\r\nreturn -ENOMEM;\r\nentry->key = kmemdup(cipso_ptr, cipso_ptr_len, GFP_ATOMIC);\r\nif (entry->key == NULL) {\r\nret_val = -ENOMEM;\r\ngoto cache_add_failure;\r\n}\r\nentry->key_len = cipso_ptr_len;\r\nentry->hash = cipso_v4_map_cache_hash(cipso_ptr, cipso_ptr_len);\r\natomic_inc(&secattr->cache->refcount);\r\nentry->lsm_data = secattr->cache;\r\nbkt = entry->hash & (CIPSO_V4_CACHE_BUCKETS - 1);\r\nspin_lock_bh(&cipso_v4_cache[bkt].lock);\r\nif (cipso_v4_cache[bkt].size < cipso_v4_cache_bucketsize) {\r\nlist_add(&entry->list, &cipso_v4_cache[bkt].list);\r\ncipso_v4_cache[bkt].size += 1;\r\n} else {\r\nold_entry = list_entry(cipso_v4_cache[bkt].list.prev,\r\nstruct cipso_v4_map_cache_entry, list);\r\nlist_del(&old_entry->list);\r\nlist_add(&entry->list, &cipso_v4_cache[bkt].list);\r\ncipso_v4_cache_entry_free(old_entry);\r\n}\r\nspin_unlock_bh(&cipso_v4_cache[bkt].lock);\r\nreturn 0;\r\ncache_add_failure:\r\nif (entry)\r\ncipso_v4_cache_entry_free(entry);\r\nreturn ret_val;\r\n}\r\nstatic struct cipso_v4_doi *cipso_v4_doi_search(u32 doi)\r\n{\r\nstruct cipso_v4_doi *iter;\r\nlist_for_each_entry_rcu(iter, &cipso_v4_doi_list, list)\r\nif (iter->doi == doi && atomic_read(&iter->refcount))\r\nreturn iter;\r\nreturn NULL;\r\n}\r\nint cipso_v4_doi_add(struct cipso_v4_doi *doi_def,\r\nstruct netlbl_audit *audit_info)\r\n{\r\nint ret_val = -EINVAL;\r\nu32 iter;\r\nu32 doi;\r\nu32 doi_type;\r\nstruct audit_buffer *audit_buf;\r\ndoi = doi_def->doi;\r\ndoi_type = doi_def->type;\r\nif (doi_def->doi == CIPSO_V4_DOI_UNKNOWN)\r\ngoto doi_add_return;\r\nfor (iter = 0; iter < CIPSO_V4_TAG_MAXCNT; iter++) {\r\nswitch (doi_def->tags[iter]) {\r\ncase CIPSO_V4_TAG_RBITMAP:\r\nbreak;\r\ncase CIPSO_V4_TAG_RANGE:\r\ncase CIPSO_V4_TAG_ENUM:\r\nif (doi_def->type != CIPSO_V4_MAP_PASS)\r\ngoto doi_add_return;\r\nbreak;\r\ncase CIPSO_V4_TAG_LOCAL:\r\nif (doi_def->type != CIPSO_V4_MAP_LOCAL)\r\ngoto doi_add_return;\r\nbreak;\r\ncase CIPSO_V4_TAG_INVALID:\r\nif (iter == 0)\r\ngoto doi_add_return;\r\nbreak;\r\ndefault:\r\ngoto doi_add_return;\r\n}\r\n}\r\natomic_set(&doi_def->refcount, 1);\r\nspin_lock(&cipso_v4_doi_list_lock);\r\nif (cipso_v4_doi_search(doi_def->doi) != NULL) {\r\nspin_unlock(&cipso_v4_doi_list_lock);\r\nret_val = -EEXIST;\r\ngoto doi_add_return;\r\n}\r\nlist_add_tail_rcu(&doi_def->list, &cipso_v4_doi_list);\r\nspin_unlock(&cipso_v4_doi_list_lock);\r\nret_val = 0;\r\ndoi_add_return:\r\naudit_buf = netlbl_audit_start(AUDIT_MAC_CIPSOV4_ADD, audit_info);\r\nif (audit_buf != NULL) {\r\nconst char *type_str;\r\nswitch (doi_type) {\r\ncase CIPSO_V4_MAP_TRANS:\r\ntype_str = "trans";\r\nbreak;\r\ncase CIPSO_V4_MAP_PASS:\r\ntype_str = "pass";\r\nbreak;\r\ncase CIPSO_V4_MAP_LOCAL:\r\ntype_str = "local";\r\nbreak;\r\ndefault:\r\ntype_str = "(unknown)";\r\n}\r\naudit_log_format(audit_buf,\r\n" cipso_doi=%u cipso_type=%s res=%u",\r\ndoi, type_str, ret_val == 0 ? 1 : 0);\r\naudit_log_end(audit_buf);\r\n}\r\nreturn ret_val;\r\n}\r\nvoid cipso_v4_doi_free(struct cipso_v4_doi *doi_def)\r\n{\r\nif (doi_def == NULL)\r\nreturn;\r\nswitch (doi_def->type) {\r\ncase CIPSO_V4_MAP_TRANS:\r\nkfree(doi_def->map.std->lvl.cipso);\r\nkfree(doi_def->map.std->lvl.local);\r\nkfree(doi_def->map.std->cat.cipso);\r\nkfree(doi_def->map.std->cat.local);\r\nbreak;\r\n}\r\nkfree(doi_def);\r\n}\r\nstatic void cipso_v4_doi_free_rcu(struct rcu_head *entry)\r\n{\r\nstruct cipso_v4_doi *doi_def;\r\ndoi_def = container_of(entry, struct cipso_v4_doi, rcu);\r\ncipso_v4_doi_free(doi_def);\r\n}\r\nint cipso_v4_doi_remove(u32 doi, struct netlbl_audit *audit_info)\r\n{\r\nint ret_val;\r\nstruct cipso_v4_doi *doi_def;\r\nstruct audit_buffer *audit_buf;\r\nspin_lock(&cipso_v4_doi_list_lock);\r\ndoi_def = cipso_v4_doi_search(doi);\r\nif (doi_def == NULL) {\r\nspin_unlock(&cipso_v4_doi_list_lock);\r\nret_val = -ENOENT;\r\ngoto doi_remove_return;\r\n}\r\nif (!atomic_dec_and_test(&doi_def->refcount)) {\r\nspin_unlock(&cipso_v4_doi_list_lock);\r\nret_val = -EBUSY;\r\ngoto doi_remove_return;\r\n}\r\nlist_del_rcu(&doi_def->list);\r\nspin_unlock(&cipso_v4_doi_list_lock);\r\ncipso_v4_cache_invalidate();\r\ncall_rcu(&doi_def->rcu, cipso_v4_doi_free_rcu);\r\nret_val = 0;\r\ndoi_remove_return:\r\naudit_buf = netlbl_audit_start(AUDIT_MAC_CIPSOV4_DEL, audit_info);\r\nif (audit_buf != NULL) {\r\naudit_log_format(audit_buf,\r\n" cipso_doi=%u res=%u",\r\ndoi, ret_val == 0 ? 1 : 0);\r\naudit_log_end(audit_buf);\r\n}\r\nreturn ret_val;\r\n}\r\nstruct cipso_v4_doi *cipso_v4_doi_getdef(u32 doi)\r\n{\r\nstruct cipso_v4_doi *doi_def;\r\nrcu_read_lock();\r\ndoi_def = cipso_v4_doi_search(doi);\r\nif (doi_def == NULL)\r\ngoto doi_getdef_return;\r\nif (!atomic_inc_not_zero(&doi_def->refcount))\r\ndoi_def = NULL;\r\ndoi_getdef_return:\r\nrcu_read_unlock();\r\nreturn doi_def;\r\n}\r\nvoid cipso_v4_doi_putdef(struct cipso_v4_doi *doi_def)\r\n{\r\nif (doi_def == NULL)\r\nreturn;\r\nif (!atomic_dec_and_test(&doi_def->refcount))\r\nreturn;\r\nspin_lock(&cipso_v4_doi_list_lock);\r\nlist_del_rcu(&doi_def->list);\r\nspin_unlock(&cipso_v4_doi_list_lock);\r\ncipso_v4_cache_invalidate();\r\ncall_rcu(&doi_def->rcu, cipso_v4_doi_free_rcu);\r\n}\r\nint cipso_v4_doi_walk(u32 *skip_cnt,\r\nint (*callback) (struct cipso_v4_doi *doi_def, void *arg),\r\nvoid *cb_arg)\r\n{\r\nint ret_val = -ENOENT;\r\nu32 doi_cnt = 0;\r\nstruct cipso_v4_doi *iter_doi;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(iter_doi, &cipso_v4_doi_list, list)\r\nif (atomic_read(&iter_doi->refcount) > 0) {\r\nif (doi_cnt++ < *skip_cnt)\r\ncontinue;\r\nret_val = callback(iter_doi, cb_arg);\r\nif (ret_val < 0) {\r\ndoi_cnt--;\r\ngoto doi_walk_return;\r\n}\r\n}\r\ndoi_walk_return:\r\nrcu_read_unlock();\r\n*skip_cnt = doi_cnt;\r\nreturn ret_val;\r\n}\r\nstatic int cipso_v4_map_lvl_valid(const struct cipso_v4_doi *doi_def, u8 level)\r\n{\r\nswitch (doi_def->type) {\r\ncase CIPSO_V4_MAP_PASS:\r\nreturn 0;\r\ncase CIPSO_V4_MAP_TRANS:\r\nif (doi_def->map.std->lvl.cipso[level] < CIPSO_V4_INV_LVL)\r\nreturn 0;\r\nbreak;\r\n}\r\nreturn -EFAULT;\r\n}\r\nstatic int cipso_v4_map_lvl_hton(const struct cipso_v4_doi *doi_def,\r\nu32 host_lvl,\r\nu32 *net_lvl)\r\n{\r\nswitch (doi_def->type) {\r\ncase CIPSO_V4_MAP_PASS:\r\n*net_lvl = host_lvl;\r\nreturn 0;\r\ncase CIPSO_V4_MAP_TRANS:\r\nif (host_lvl < doi_def->map.std->lvl.local_size &&\r\ndoi_def->map.std->lvl.local[host_lvl] < CIPSO_V4_INV_LVL) {\r\n*net_lvl = doi_def->map.std->lvl.local[host_lvl];\r\nreturn 0;\r\n}\r\nreturn -EPERM;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int cipso_v4_map_lvl_ntoh(const struct cipso_v4_doi *doi_def,\r\nu32 net_lvl,\r\nu32 *host_lvl)\r\n{\r\nstruct cipso_v4_std_map_tbl *map_tbl;\r\nswitch (doi_def->type) {\r\ncase CIPSO_V4_MAP_PASS:\r\n*host_lvl = net_lvl;\r\nreturn 0;\r\ncase CIPSO_V4_MAP_TRANS:\r\nmap_tbl = doi_def->map.std;\r\nif (net_lvl < map_tbl->lvl.cipso_size &&\r\nmap_tbl->lvl.cipso[net_lvl] < CIPSO_V4_INV_LVL) {\r\n*host_lvl = doi_def->map.std->lvl.cipso[net_lvl];\r\nreturn 0;\r\n}\r\nreturn -EPERM;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int cipso_v4_map_cat_rbm_valid(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *bitmap,\r\nu32 bitmap_len)\r\n{\r\nint cat = -1;\r\nu32 bitmap_len_bits = bitmap_len * 8;\r\nu32 cipso_cat_size;\r\nu32 *cipso_array;\r\nswitch (doi_def->type) {\r\ncase CIPSO_V4_MAP_PASS:\r\nreturn 0;\r\ncase CIPSO_V4_MAP_TRANS:\r\ncipso_cat_size = doi_def->map.std->cat.cipso_size;\r\ncipso_array = doi_def->map.std->cat.cipso;\r\nfor (;;) {\r\ncat = cipso_v4_bitmap_walk(bitmap,\r\nbitmap_len_bits,\r\ncat + 1,\r\n1);\r\nif (cat < 0)\r\nbreak;\r\nif (cat >= cipso_cat_size ||\r\ncipso_array[cat] >= CIPSO_V4_INV_CAT)\r\nreturn -EFAULT;\r\n}\r\nif (cat == -1)\r\nreturn 0;\r\nbreak;\r\n}\r\nreturn -EFAULT;\r\n}\r\nstatic int cipso_v4_map_cat_rbm_hton(const struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr,\r\nunsigned char *net_cat,\r\nu32 net_cat_len)\r\n{\r\nint host_spot = -1;\r\nu32 net_spot = CIPSO_V4_INV_CAT;\r\nu32 net_spot_max = 0;\r\nu32 net_clen_bits = net_cat_len * 8;\r\nu32 host_cat_size = 0;\r\nu32 *host_cat_array = NULL;\r\nif (doi_def->type == CIPSO_V4_MAP_TRANS) {\r\nhost_cat_size = doi_def->map.std->cat.local_size;\r\nhost_cat_array = doi_def->map.std->cat.local;\r\n}\r\nfor (;;) {\r\nhost_spot = netlbl_secattr_catmap_walk(secattr->attr.mls.cat,\r\nhost_spot + 1);\r\nif (host_spot < 0)\r\nbreak;\r\nswitch (doi_def->type) {\r\ncase CIPSO_V4_MAP_PASS:\r\nnet_spot = host_spot;\r\nbreak;\r\ncase CIPSO_V4_MAP_TRANS:\r\nif (host_spot >= host_cat_size)\r\nreturn -EPERM;\r\nnet_spot = host_cat_array[host_spot];\r\nif (net_spot >= CIPSO_V4_INV_CAT)\r\nreturn -EPERM;\r\nbreak;\r\n}\r\nif (net_spot >= net_clen_bits)\r\nreturn -ENOSPC;\r\ncipso_v4_bitmap_setbit(net_cat, net_spot, 1);\r\nif (net_spot > net_spot_max)\r\nnet_spot_max = net_spot;\r\n}\r\nif (++net_spot_max % 8)\r\nreturn net_spot_max / 8 + 1;\r\nreturn net_spot_max / 8;\r\n}\r\nstatic int cipso_v4_map_cat_rbm_ntoh(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *net_cat,\r\nu32 net_cat_len,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nint net_spot = -1;\r\nu32 host_spot = CIPSO_V4_INV_CAT;\r\nu32 net_clen_bits = net_cat_len * 8;\r\nu32 net_cat_size = 0;\r\nu32 *net_cat_array = NULL;\r\nif (doi_def->type == CIPSO_V4_MAP_TRANS) {\r\nnet_cat_size = doi_def->map.std->cat.cipso_size;\r\nnet_cat_array = doi_def->map.std->cat.cipso;\r\n}\r\nfor (;;) {\r\nnet_spot = cipso_v4_bitmap_walk(net_cat,\r\nnet_clen_bits,\r\nnet_spot + 1,\r\n1);\r\nif (net_spot < 0) {\r\nif (net_spot == -2)\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nswitch (doi_def->type) {\r\ncase CIPSO_V4_MAP_PASS:\r\nhost_spot = net_spot;\r\nbreak;\r\ncase CIPSO_V4_MAP_TRANS:\r\nif (net_spot >= net_cat_size)\r\nreturn -EPERM;\r\nhost_spot = net_cat_array[net_spot];\r\nif (host_spot >= CIPSO_V4_INV_CAT)\r\nreturn -EPERM;\r\nbreak;\r\n}\r\nret_val = netlbl_secattr_catmap_setbit(secattr->attr.mls.cat,\r\nhost_spot,\r\nGFP_ATOMIC);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int cipso_v4_map_cat_enum_valid(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *enumcat,\r\nu32 enumcat_len)\r\n{\r\nu16 cat;\r\nint cat_prev = -1;\r\nu32 iter;\r\nif (doi_def->type != CIPSO_V4_MAP_PASS || enumcat_len & 0x01)\r\nreturn -EFAULT;\r\nfor (iter = 0; iter < enumcat_len; iter += 2) {\r\ncat = get_unaligned_be16(&enumcat[iter]);\r\nif (cat <= cat_prev)\r\nreturn -EFAULT;\r\ncat_prev = cat;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cipso_v4_map_cat_enum_hton(const struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr,\r\nunsigned char *net_cat,\r\nu32 net_cat_len)\r\n{\r\nint cat = -1;\r\nu32 cat_iter = 0;\r\nfor (;;) {\r\ncat = netlbl_secattr_catmap_walk(secattr->attr.mls.cat,\r\ncat + 1);\r\nif (cat < 0)\r\nbreak;\r\nif ((cat_iter + 2) > net_cat_len)\r\nreturn -ENOSPC;\r\n*((__be16 *)&net_cat[cat_iter]) = htons(cat);\r\ncat_iter += 2;\r\n}\r\nreturn cat_iter;\r\n}\r\nstatic int cipso_v4_map_cat_enum_ntoh(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *net_cat,\r\nu32 net_cat_len,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nu32 iter;\r\nfor (iter = 0; iter < net_cat_len; iter += 2) {\r\nret_val = netlbl_secattr_catmap_setbit(secattr->attr.mls.cat,\r\nget_unaligned_be16(&net_cat[iter]),\r\nGFP_ATOMIC);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cipso_v4_map_cat_rng_valid(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *rngcat,\r\nu32 rngcat_len)\r\n{\r\nu16 cat_high;\r\nu16 cat_low;\r\nu32 cat_prev = CIPSO_V4_MAX_REM_CATS + 1;\r\nu32 iter;\r\nif (doi_def->type != CIPSO_V4_MAP_PASS || rngcat_len & 0x01)\r\nreturn -EFAULT;\r\nfor (iter = 0; iter < rngcat_len; iter += 4) {\r\ncat_high = get_unaligned_be16(&rngcat[iter]);\r\nif ((iter + 4) <= rngcat_len)\r\ncat_low = get_unaligned_be16(&rngcat[iter + 2]);\r\nelse\r\ncat_low = 0;\r\nif (cat_high > cat_prev)\r\nreturn -EFAULT;\r\ncat_prev = cat_low;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cipso_v4_map_cat_rng_hton(const struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr,\r\nunsigned char *net_cat,\r\nu32 net_cat_len)\r\n{\r\nint iter = -1;\r\nu16 array[CIPSO_V4_TAG_RNG_CAT_MAX * 2];\r\nu32 array_cnt = 0;\r\nu32 cat_size = 0;\r\nif (net_cat_len >\r\n(CIPSO_V4_OPT_LEN_MAX - CIPSO_V4_HDR_LEN - CIPSO_V4_TAG_RNG_BLEN))\r\nreturn -ENOSPC;\r\nfor (;;) {\r\niter = netlbl_secattr_catmap_walk(secattr->attr.mls.cat,\r\niter + 1);\r\nif (iter < 0)\r\nbreak;\r\ncat_size += (iter == 0 ? 0 : sizeof(u16));\r\nif (cat_size > net_cat_len)\r\nreturn -ENOSPC;\r\narray[array_cnt++] = iter;\r\niter = netlbl_secattr_catmap_walk_rng(secattr->attr.mls.cat,\r\niter);\r\nif (iter < 0)\r\nreturn -EFAULT;\r\ncat_size += sizeof(u16);\r\nif (cat_size > net_cat_len)\r\nreturn -ENOSPC;\r\narray[array_cnt++] = iter;\r\n}\r\nfor (iter = 0; array_cnt > 0;) {\r\n*((__be16 *)&net_cat[iter]) = htons(array[--array_cnt]);\r\niter += 2;\r\narray_cnt--;\r\nif (array[array_cnt] != 0) {\r\n*((__be16 *)&net_cat[iter]) = htons(array[array_cnt]);\r\niter += 2;\r\n}\r\n}\r\nreturn cat_size;\r\n}\r\nstatic int cipso_v4_map_cat_rng_ntoh(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *net_cat,\r\nu32 net_cat_len,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nu32 net_iter;\r\nu16 cat_low;\r\nu16 cat_high;\r\nfor (net_iter = 0; net_iter < net_cat_len; net_iter += 4) {\r\ncat_high = get_unaligned_be16(&net_cat[net_iter]);\r\nif ((net_iter + 4) <= net_cat_len)\r\ncat_low = get_unaligned_be16(&net_cat[net_iter + 2]);\r\nelse\r\ncat_low = 0;\r\nret_val = netlbl_secattr_catmap_setrng(secattr->attr.mls.cat,\r\ncat_low,\r\ncat_high,\r\nGFP_ATOMIC);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\n}\r\nreturn 0;\r\n}\r\nstatic void cipso_v4_gentag_hdr(const struct cipso_v4_doi *doi_def,\r\nunsigned char *buf,\r\nu32 len)\r\n{\r\nbuf[0] = IPOPT_CIPSO;\r\nbuf[1] = CIPSO_V4_HDR_LEN + len;\r\n*(__be32 *)&buf[2] = htonl(doi_def->doi);\r\n}\r\nstatic int cipso_v4_gentag_rbm(const struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr,\r\nunsigned char *buffer,\r\nu32 buffer_len)\r\n{\r\nint ret_val;\r\nu32 tag_len;\r\nu32 level;\r\nif ((secattr->flags & NETLBL_SECATTR_MLS_LVL) == 0)\r\nreturn -EPERM;\r\nret_val = cipso_v4_map_lvl_hton(doi_def,\r\nsecattr->attr.mls.lvl,\r\n&level);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\nif (secattr->flags & NETLBL_SECATTR_MLS_CAT) {\r\nret_val = cipso_v4_map_cat_rbm_hton(doi_def,\r\nsecattr,\r\n&buffer[4],\r\nbuffer_len - 4);\r\nif (ret_val < 0)\r\nreturn ret_val;\r\nif (cipso_v4_rbm_optfmt && ret_val > 0 && ret_val <= 10)\r\ntag_len = 14;\r\nelse\r\ntag_len = 4 + ret_val;\r\n} else\r\ntag_len = 4;\r\nbuffer[0] = CIPSO_V4_TAG_RBITMAP;\r\nbuffer[1] = tag_len;\r\nbuffer[3] = level;\r\nreturn tag_len;\r\n}\r\nstatic int cipso_v4_parsetag_rbm(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *tag,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nu8 tag_len = tag[1];\r\nu32 level;\r\nret_val = cipso_v4_map_lvl_ntoh(doi_def, tag[3], &level);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\nsecattr->attr.mls.lvl = level;\r\nsecattr->flags |= NETLBL_SECATTR_MLS_LVL;\r\nif (tag_len > 4) {\r\nsecattr->attr.mls.cat =\r\nnetlbl_secattr_catmap_alloc(GFP_ATOMIC);\r\nif (secattr->attr.mls.cat == NULL)\r\nreturn -ENOMEM;\r\nret_val = cipso_v4_map_cat_rbm_ntoh(doi_def,\r\n&tag[4],\r\ntag_len - 4,\r\nsecattr);\r\nif (ret_val != 0) {\r\nnetlbl_secattr_catmap_free(secattr->attr.mls.cat);\r\nreturn ret_val;\r\n}\r\nsecattr->flags |= NETLBL_SECATTR_MLS_CAT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cipso_v4_gentag_enum(const struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr,\r\nunsigned char *buffer,\r\nu32 buffer_len)\r\n{\r\nint ret_val;\r\nu32 tag_len;\r\nu32 level;\r\nif (!(secattr->flags & NETLBL_SECATTR_MLS_LVL))\r\nreturn -EPERM;\r\nret_val = cipso_v4_map_lvl_hton(doi_def,\r\nsecattr->attr.mls.lvl,\r\n&level);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\nif (secattr->flags & NETLBL_SECATTR_MLS_CAT) {\r\nret_val = cipso_v4_map_cat_enum_hton(doi_def,\r\nsecattr,\r\n&buffer[4],\r\nbuffer_len - 4);\r\nif (ret_val < 0)\r\nreturn ret_val;\r\ntag_len = 4 + ret_val;\r\n} else\r\ntag_len = 4;\r\nbuffer[0] = CIPSO_V4_TAG_ENUM;\r\nbuffer[1] = tag_len;\r\nbuffer[3] = level;\r\nreturn tag_len;\r\n}\r\nstatic int cipso_v4_parsetag_enum(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *tag,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nu8 tag_len = tag[1];\r\nu32 level;\r\nret_val = cipso_v4_map_lvl_ntoh(doi_def, tag[3], &level);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\nsecattr->attr.mls.lvl = level;\r\nsecattr->flags |= NETLBL_SECATTR_MLS_LVL;\r\nif (tag_len > 4) {\r\nsecattr->attr.mls.cat =\r\nnetlbl_secattr_catmap_alloc(GFP_ATOMIC);\r\nif (secattr->attr.mls.cat == NULL)\r\nreturn -ENOMEM;\r\nret_val = cipso_v4_map_cat_enum_ntoh(doi_def,\r\n&tag[4],\r\ntag_len - 4,\r\nsecattr);\r\nif (ret_val != 0) {\r\nnetlbl_secattr_catmap_free(secattr->attr.mls.cat);\r\nreturn ret_val;\r\n}\r\nsecattr->flags |= NETLBL_SECATTR_MLS_CAT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cipso_v4_gentag_rng(const struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr,\r\nunsigned char *buffer,\r\nu32 buffer_len)\r\n{\r\nint ret_val;\r\nu32 tag_len;\r\nu32 level;\r\nif (!(secattr->flags & NETLBL_SECATTR_MLS_LVL))\r\nreturn -EPERM;\r\nret_val = cipso_v4_map_lvl_hton(doi_def,\r\nsecattr->attr.mls.lvl,\r\n&level);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\nif (secattr->flags & NETLBL_SECATTR_MLS_CAT) {\r\nret_val = cipso_v4_map_cat_rng_hton(doi_def,\r\nsecattr,\r\n&buffer[4],\r\nbuffer_len - 4);\r\nif (ret_val < 0)\r\nreturn ret_val;\r\ntag_len = 4 + ret_val;\r\n} else\r\ntag_len = 4;\r\nbuffer[0] = CIPSO_V4_TAG_RANGE;\r\nbuffer[1] = tag_len;\r\nbuffer[3] = level;\r\nreturn tag_len;\r\n}\r\nstatic int cipso_v4_parsetag_rng(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *tag,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nu8 tag_len = tag[1];\r\nu32 level;\r\nret_val = cipso_v4_map_lvl_ntoh(doi_def, tag[3], &level);\r\nif (ret_val != 0)\r\nreturn ret_val;\r\nsecattr->attr.mls.lvl = level;\r\nsecattr->flags |= NETLBL_SECATTR_MLS_LVL;\r\nif (tag_len > 4) {\r\nsecattr->attr.mls.cat =\r\nnetlbl_secattr_catmap_alloc(GFP_ATOMIC);\r\nif (secattr->attr.mls.cat == NULL)\r\nreturn -ENOMEM;\r\nret_val = cipso_v4_map_cat_rng_ntoh(doi_def,\r\n&tag[4],\r\ntag_len - 4,\r\nsecattr);\r\nif (ret_val != 0) {\r\nnetlbl_secattr_catmap_free(secattr->attr.mls.cat);\r\nreturn ret_val;\r\n}\r\nsecattr->flags |= NETLBL_SECATTR_MLS_CAT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int cipso_v4_gentag_loc(const struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr,\r\nunsigned char *buffer,\r\nu32 buffer_len)\r\n{\r\nif (!(secattr->flags & NETLBL_SECATTR_SECID))\r\nreturn -EPERM;\r\nbuffer[0] = CIPSO_V4_TAG_LOCAL;\r\nbuffer[1] = CIPSO_V4_TAG_LOC_BLEN;\r\n*(u32 *)&buffer[2] = secattr->attr.secid;\r\nreturn CIPSO_V4_TAG_LOC_BLEN;\r\n}\r\nstatic int cipso_v4_parsetag_loc(const struct cipso_v4_doi *doi_def,\r\nconst unsigned char *tag,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nsecattr->attr.secid = *(u32 *)&tag[2];\r\nsecattr->flags |= NETLBL_SECATTR_SECID;\r\nreturn 0;\r\n}\r\nint cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)\r\n{\r\nunsigned char *opt = *option;\r\nunsigned char *tag;\r\nunsigned char opt_iter;\r\nunsigned char err_offset = 0;\r\nu8 opt_len;\r\nu8 tag_len;\r\nstruct cipso_v4_doi *doi_def = NULL;\r\nu32 tag_iter;\r\nopt_len = opt[1];\r\nif (opt_len < 8) {\r\nerr_offset = 1;\r\ngoto validate_return;\r\n}\r\nrcu_read_lock();\r\ndoi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));\r\nif (doi_def == NULL) {\r\nerr_offset = 2;\r\ngoto validate_return_locked;\r\n}\r\nopt_iter = CIPSO_V4_HDR_LEN;\r\ntag = opt + opt_iter;\r\nwhile (opt_iter < opt_len) {\r\nfor (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];)\r\nif (doi_def->tags[tag_iter] == CIPSO_V4_TAG_INVALID ||\r\n++tag_iter == CIPSO_V4_TAG_MAXCNT) {\r\nerr_offset = opt_iter;\r\ngoto validate_return_locked;\r\n}\r\ntag_len = tag[1];\r\nif (tag_len > (opt_len - opt_iter)) {\r\nerr_offset = opt_iter + 1;\r\ngoto validate_return_locked;\r\n}\r\nswitch (tag[0]) {\r\ncase CIPSO_V4_TAG_RBITMAP:\r\nif (tag_len < CIPSO_V4_TAG_RBM_BLEN) {\r\nerr_offset = opt_iter + 1;\r\ngoto validate_return_locked;\r\n}\r\nif (cipso_v4_rbm_strictvalid) {\r\nif (cipso_v4_map_lvl_valid(doi_def,\r\ntag[3]) < 0) {\r\nerr_offset = opt_iter + 3;\r\ngoto validate_return_locked;\r\n}\r\nif (tag_len > CIPSO_V4_TAG_RBM_BLEN &&\r\ncipso_v4_map_cat_rbm_valid(doi_def,\r\n&tag[4],\r\ntag_len - 4) < 0) {\r\nerr_offset = opt_iter + 4;\r\ngoto validate_return_locked;\r\n}\r\n}\r\nbreak;\r\ncase CIPSO_V4_TAG_ENUM:\r\nif (tag_len < CIPSO_V4_TAG_ENUM_BLEN) {\r\nerr_offset = opt_iter + 1;\r\ngoto validate_return_locked;\r\n}\r\nif (cipso_v4_map_lvl_valid(doi_def,\r\ntag[3]) < 0) {\r\nerr_offset = opt_iter + 3;\r\ngoto validate_return_locked;\r\n}\r\nif (tag_len > CIPSO_V4_TAG_ENUM_BLEN &&\r\ncipso_v4_map_cat_enum_valid(doi_def,\r\n&tag[4],\r\ntag_len - 4) < 0) {\r\nerr_offset = opt_iter + 4;\r\ngoto validate_return_locked;\r\n}\r\nbreak;\r\ncase CIPSO_V4_TAG_RANGE:\r\nif (tag_len < CIPSO_V4_TAG_RNG_BLEN) {\r\nerr_offset = opt_iter + 1;\r\ngoto validate_return_locked;\r\n}\r\nif (cipso_v4_map_lvl_valid(doi_def,\r\ntag[3]) < 0) {\r\nerr_offset = opt_iter + 3;\r\ngoto validate_return_locked;\r\n}\r\nif (tag_len > CIPSO_V4_TAG_RNG_BLEN &&\r\ncipso_v4_map_cat_rng_valid(doi_def,\r\n&tag[4],\r\ntag_len - 4) < 0) {\r\nerr_offset = opt_iter + 4;\r\ngoto validate_return_locked;\r\n}\r\nbreak;\r\ncase CIPSO_V4_TAG_LOCAL:\r\nif (!(skb->dev->flags & IFF_LOOPBACK)) {\r\nerr_offset = opt_iter;\r\ngoto validate_return_locked;\r\n}\r\nif (tag_len != CIPSO_V4_TAG_LOC_BLEN) {\r\nerr_offset = opt_iter + 1;\r\ngoto validate_return_locked;\r\n}\r\nbreak;\r\ndefault:\r\nerr_offset = opt_iter;\r\ngoto validate_return_locked;\r\n}\r\ntag += tag_len;\r\nopt_iter += tag_len;\r\n}\r\nvalidate_return_locked:\r\nrcu_read_unlock();\r\nvalidate_return:\r\n*option = opt + err_offset;\r\nreturn err_offset;\r\n}\r\nvoid cipso_v4_error(struct sk_buff *skb, int error, u32 gateway)\r\n{\r\nif (ip_hdr(skb)->protocol == IPPROTO_ICMP || error != -EACCES)\r\nreturn;\r\nif (gateway)\r\nicmp_send(skb, ICMP_DEST_UNREACH, ICMP_NET_ANO, 0);\r\nelse\r\nicmp_send(skb, ICMP_DEST_UNREACH, ICMP_HOST_ANO, 0);\r\n}\r\nstatic int cipso_v4_genopt(unsigned char *buf, u32 buf_len,\r\nconst struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nu32 iter;\r\nif (buf_len <= CIPSO_V4_HDR_LEN)\r\nreturn -ENOSPC;\r\niter = 0;\r\ndo {\r\nmemset(buf, 0, buf_len);\r\nswitch (doi_def->tags[iter]) {\r\ncase CIPSO_V4_TAG_RBITMAP:\r\nret_val = cipso_v4_gentag_rbm(doi_def,\r\nsecattr,\r\n&buf[CIPSO_V4_HDR_LEN],\r\nbuf_len - CIPSO_V4_HDR_LEN);\r\nbreak;\r\ncase CIPSO_V4_TAG_ENUM:\r\nret_val = cipso_v4_gentag_enum(doi_def,\r\nsecattr,\r\n&buf[CIPSO_V4_HDR_LEN],\r\nbuf_len - CIPSO_V4_HDR_LEN);\r\nbreak;\r\ncase CIPSO_V4_TAG_RANGE:\r\nret_val = cipso_v4_gentag_rng(doi_def,\r\nsecattr,\r\n&buf[CIPSO_V4_HDR_LEN],\r\nbuf_len - CIPSO_V4_HDR_LEN);\r\nbreak;\r\ncase CIPSO_V4_TAG_LOCAL:\r\nret_val = cipso_v4_gentag_loc(doi_def,\r\nsecattr,\r\n&buf[CIPSO_V4_HDR_LEN],\r\nbuf_len - CIPSO_V4_HDR_LEN);\r\nbreak;\r\ndefault:\r\nreturn -EPERM;\r\n}\r\niter++;\r\n} while (ret_val < 0 &&\r\niter < CIPSO_V4_TAG_MAXCNT &&\r\ndoi_def->tags[iter] != CIPSO_V4_TAG_INVALID);\r\nif (ret_val < 0)\r\nreturn ret_val;\r\ncipso_v4_gentag_hdr(doi_def, buf, ret_val);\r\nreturn CIPSO_V4_HDR_LEN + ret_val;\r\n}\r\nstatic void opt_kfree_rcu(struct rcu_head *head)\r\n{\r\nkfree(container_of(head, struct ip_options_rcu, rcu));\r\n}\r\nint cipso_v4_sock_setattr(struct sock *sk,\r\nconst struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val = -EPERM;\r\nunsigned char *buf = NULL;\r\nu32 buf_len;\r\nu32 opt_len;\r\nstruct ip_options_rcu *old, *opt = NULL;\r\nstruct inet_sock *sk_inet;\r\nstruct inet_connection_sock *sk_conn;\r\nif (sk == NULL)\r\nreturn 0;\r\nbuf_len = CIPSO_V4_OPT_LEN_MAX;\r\nbuf = kmalloc(buf_len, GFP_ATOMIC);\r\nif (buf == NULL) {\r\nret_val = -ENOMEM;\r\ngoto socket_setattr_failure;\r\n}\r\nret_val = cipso_v4_genopt(buf, buf_len, doi_def, secattr);\r\nif (ret_val < 0)\r\ngoto socket_setattr_failure;\r\nbuf_len = ret_val;\r\nopt_len = (buf_len + 3) & ~3;\r\nopt = kzalloc(sizeof(*opt) + opt_len, GFP_ATOMIC);\r\nif (opt == NULL) {\r\nret_val = -ENOMEM;\r\ngoto socket_setattr_failure;\r\n}\r\nmemcpy(opt->opt.__data, buf, buf_len);\r\nopt->opt.optlen = opt_len;\r\nopt->opt.cipso = sizeof(struct iphdr);\r\nkfree(buf);\r\nbuf = NULL;\r\nsk_inet = inet_sk(sk);\r\nold = rcu_dereference_protected(sk_inet->inet_opt, sock_owned_by_user(sk));\r\nif (sk_inet->is_icsk) {\r\nsk_conn = inet_csk(sk);\r\nif (old)\r\nsk_conn->icsk_ext_hdr_len -= old->opt.optlen;\r\nsk_conn->icsk_ext_hdr_len += opt->opt.optlen;\r\nsk_conn->icsk_sync_mss(sk, sk_conn->icsk_pmtu_cookie);\r\n}\r\nrcu_assign_pointer(sk_inet->inet_opt, opt);\r\nif (old)\r\ncall_rcu(&old->rcu, opt_kfree_rcu);\r\nreturn 0;\r\nsocket_setattr_failure:\r\nkfree(buf);\r\nkfree(opt);\r\nreturn ret_val;\r\n}\r\nint cipso_v4_req_setattr(struct request_sock *req,\r\nconst struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val = -EPERM;\r\nunsigned char *buf = NULL;\r\nu32 buf_len;\r\nu32 opt_len;\r\nstruct ip_options_rcu *opt = NULL;\r\nstruct inet_request_sock *req_inet;\r\nbuf_len = CIPSO_V4_OPT_LEN_MAX;\r\nbuf = kmalloc(buf_len, GFP_ATOMIC);\r\nif (buf == NULL) {\r\nret_val = -ENOMEM;\r\ngoto req_setattr_failure;\r\n}\r\nret_val = cipso_v4_genopt(buf, buf_len, doi_def, secattr);\r\nif (ret_val < 0)\r\ngoto req_setattr_failure;\r\nbuf_len = ret_val;\r\nopt_len = (buf_len + 3) & ~3;\r\nopt = kzalloc(sizeof(*opt) + opt_len, GFP_ATOMIC);\r\nif (opt == NULL) {\r\nret_val = -ENOMEM;\r\ngoto req_setattr_failure;\r\n}\r\nmemcpy(opt->opt.__data, buf, buf_len);\r\nopt->opt.optlen = opt_len;\r\nopt->opt.cipso = sizeof(struct iphdr);\r\nkfree(buf);\r\nbuf = NULL;\r\nreq_inet = inet_rsk(req);\r\nopt = xchg(&req_inet->opt, opt);\r\nif (opt)\r\ncall_rcu(&opt->rcu, opt_kfree_rcu);\r\nreturn 0;\r\nreq_setattr_failure:\r\nkfree(buf);\r\nkfree(opt);\r\nreturn ret_val;\r\n}\r\nstatic int cipso_v4_delopt(struct ip_options_rcu **opt_ptr)\r\n{\r\nint hdr_delta = 0;\r\nstruct ip_options_rcu *opt = *opt_ptr;\r\nif (opt->opt.srr || opt->opt.rr || opt->opt.ts || opt->opt.router_alert) {\r\nu8 cipso_len;\r\nu8 cipso_off;\r\nunsigned char *cipso_ptr;\r\nint iter;\r\nint optlen_new;\r\ncipso_off = opt->opt.cipso - sizeof(struct iphdr);\r\ncipso_ptr = &opt->opt.__data[cipso_off];\r\ncipso_len = cipso_ptr[1];\r\nif (opt->opt.srr > opt->opt.cipso)\r\nopt->opt.srr -= cipso_len;\r\nif (opt->opt.rr > opt->opt.cipso)\r\nopt->opt.rr -= cipso_len;\r\nif (opt->opt.ts > opt->opt.cipso)\r\nopt->opt.ts -= cipso_len;\r\nif (opt->opt.router_alert > opt->opt.cipso)\r\nopt->opt.router_alert -= cipso_len;\r\nopt->opt.cipso = 0;\r\nmemmove(cipso_ptr, cipso_ptr + cipso_len,\r\nopt->opt.optlen - cipso_off - cipso_len);\r\niter = 0;\r\noptlen_new = 0;\r\nwhile (iter < opt->opt.optlen)\r\nif (opt->opt.__data[iter] != IPOPT_NOP) {\r\niter += opt->opt.__data[iter + 1];\r\noptlen_new = iter;\r\n} else\r\niter++;\r\nhdr_delta = opt->opt.optlen;\r\nopt->opt.optlen = (optlen_new + 3) & ~3;\r\nhdr_delta -= opt->opt.optlen;\r\n} else {\r\n*opt_ptr = NULL;\r\nhdr_delta = opt->opt.optlen;\r\ncall_rcu(&opt->rcu, opt_kfree_rcu);\r\n}\r\nreturn hdr_delta;\r\n}\r\nvoid cipso_v4_sock_delattr(struct sock *sk)\r\n{\r\nint hdr_delta;\r\nstruct ip_options_rcu *opt;\r\nstruct inet_sock *sk_inet;\r\nsk_inet = inet_sk(sk);\r\nopt = rcu_dereference_protected(sk_inet->inet_opt, 1);\r\nif (opt == NULL || opt->opt.cipso == 0)\r\nreturn;\r\nhdr_delta = cipso_v4_delopt(&sk_inet->inet_opt);\r\nif (sk_inet->is_icsk && hdr_delta > 0) {\r\nstruct inet_connection_sock *sk_conn = inet_csk(sk);\r\nsk_conn->icsk_ext_hdr_len -= hdr_delta;\r\nsk_conn->icsk_sync_mss(sk, sk_conn->icsk_pmtu_cookie);\r\n}\r\n}\r\nvoid cipso_v4_req_delattr(struct request_sock *req)\r\n{\r\nstruct ip_options_rcu *opt;\r\nstruct inet_request_sock *req_inet;\r\nreq_inet = inet_rsk(req);\r\nopt = req_inet->opt;\r\nif (opt == NULL || opt->opt.cipso == 0)\r\nreturn;\r\ncipso_v4_delopt(&req_inet->opt);\r\n}\r\nstatic int cipso_v4_getattr(const unsigned char *cipso,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val = -ENOMSG;\r\nu32 doi;\r\nstruct cipso_v4_doi *doi_def;\r\nif (cipso_v4_cache_check(cipso, cipso[1], secattr) == 0)\r\nreturn 0;\r\ndoi = get_unaligned_be32(&cipso[2]);\r\nrcu_read_lock();\r\ndoi_def = cipso_v4_doi_search(doi);\r\nif (doi_def == NULL)\r\ngoto getattr_return;\r\nswitch (cipso[6]) {\r\ncase CIPSO_V4_TAG_RBITMAP:\r\nret_val = cipso_v4_parsetag_rbm(doi_def, &cipso[6], secattr);\r\nbreak;\r\ncase CIPSO_V4_TAG_ENUM:\r\nret_val = cipso_v4_parsetag_enum(doi_def, &cipso[6], secattr);\r\nbreak;\r\ncase CIPSO_V4_TAG_RANGE:\r\nret_val = cipso_v4_parsetag_rng(doi_def, &cipso[6], secattr);\r\nbreak;\r\ncase CIPSO_V4_TAG_LOCAL:\r\nret_val = cipso_v4_parsetag_loc(doi_def, &cipso[6], secattr);\r\nbreak;\r\n}\r\nif (ret_val == 0)\r\nsecattr->type = NETLBL_NLTYPE_CIPSOV4;\r\ngetattr_return:\r\nrcu_read_unlock();\r\nreturn ret_val;\r\n}\r\nint cipso_v4_sock_getattr(struct sock *sk, struct netlbl_lsm_secattr *secattr)\r\n{\r\nstruct ip_options_rcu *opt;\r\nint res = -ENOMSG;\r\nrcu_read_lock();\r\nopt = rcu_dereference(inet_sk(sk)->inet_opt);\r\nif (opt && opt->opt.cipso)\r\nres = cipso_v4_getattr(opt->opt.__data +\r\nopt->opt.cipso -\r\nsizeof(struct iphdr),\r\nsecattr);\r\nrcu_read_unlock();\r\nreturn res;\r\n}\r\nint cipso_v4_skbuff_setattr(struct sk_buff *skb,\r\nconst struct cipso_v4_doi *doi_def,\r\nconst struct netlbl_lsm_secattr *secattr)\r\n{\r\nint ret_val;\r\nstruct iphdr *iph;\r\nstruct ip_options *opt = &IPCB(skb)->opt;\r\nunsigned char buf[CIPSO_V4_OPT_LEN_MAX];\r\nu32 buf_len = CIPSO_V4_OPT_LEN_MAX;\r\nu32 opt_len;\r\nint len_delta;\r\nret_val = cipso_v4_genopt(buf, buf_len, doi_def, secattr);\r\nif (ret_val < 0)\r\nreturn ret_val;\r\nbuf_len = ret_val;\r\nopt_len = (buf_len + 3) & ~3;\r\nlen_delta = opt_len - opt->optlen;\r\nret_val = skb_cow(skb, skb_headroom(skb) + len_delta);\r\nif (ret_val < 0)\r\nreturn ret_val;\r\nif (len_delta > 0) {\r\niph = ip_hdr(skb);\r\nskb_push(skb, len_delta);\r\nmemmove((char *)iph - len_delta, iph, iph->ihl << 2);\r\nskb_reset_network_header(skb);\r\niph = ip_hdr(skb);\r\n} else if (len_delta < 0) {\r\niph = ip_hdr(skb);\r\nmemset(iph + 1, IPOPT_NOP, opt->optlen);\r\n} else\r\niph = ip_hdr(skb);\r\nif (opt->optlen > 0)\r\nmemset(opt, 0, sizeof(*opt));\r\nopt->optlen = opt_len;\r\nopt->cipso = sizeof(struct iphdr);\r\nopt->is_changed = 1;\r\nmemcpy(iph + 1, buf, buf_len);\r\nif (opt_len > buf_len)\r\nmemset((char *)(iph + 1) + buf_len, 0, opt_len - buf_len);\r\nif (len_delta != 0) {\r\niph->ihl = 5 + (opt_len >> 2);\r\niph->tot_len = htons(skb->len);\r\n}\r\nip_send_check(iph);\r\nreturn 0;\r\n}\r\nint cipso_v4_skbuff_delattr(struct sk_buff *skb)\r\n{\r\nint ret_val;\r\nstruct iphdr *iph;\r\nstruct ip_options *opt = &IPCB(skb)->opt;\r\nunsigned char *cipso_ptr;\r\nif (opt->cipso == 0)\r\nreturn 0;\r\nret_val = skb_cow(skb, skb_headroom(skb));\r\nif (ret_val < 0)\r\nreturn ret_val;\r\niph = ip_hdr(skb);\r\ncipso_ptr = (unsigned char *)iph + opt->cipso;\r\nmemset(cipso_ptr, IPOPT_NOOP, cipso_ptr[1]);\r\nopt->cipso = 0;\r\nopt->is_changed = 1;\r\nip_send_check(iph);\r\nreturn 0;\r\n}\r\nint cipso_v4_skbuff_getattr(const struct sk_buff *skb,\r\nstruct netlbl_lsm_secattr *secattr)\r\n{\r\nreturn cipso_v4_getattr(CIPSO_V4_OPTPTR(skb), secattr);\r\n}\r\nstatic int __init cipso_v4_init(void)\r\n{\r\nint ret_val;\r\nret_val = cipso_v4_cache_init();\r\nif (ret_val != 0)\r\npanic("Failed to initialize the CIPSO/IPv4 cache (%d)\n",\r\nret_val);\r\nreturn 0;\r\n}
