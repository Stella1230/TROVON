inline void __do_tlb_refill(unsigned long address,\r\nunsigned long long is_text_not_data, pte_t *pte)\r\n{\r\nunsigned long long ptel;\r\nunsigned long long pteh=0;\r\nstruct tlb_info *tlbp;\r\nunsigned long long next;\r\nptel = pte_val(*pte);\r\npteh = neff_sign_extend(address & MMU_VPN_MASK);\r\npteh |= get_asid() << PTEH_ASID_SHIFT;\r\npteh |= PTEH_VALID;\r\nptel &= _PAGE_FLAGS_HARDWARE_MASK;\r\ntlbp = is_text_not_data ? &(cpu_data->itlb) : &(cpu_data->dtlb);\r\nnext = tlbp->next;\r\n__flush_tlb_slot(next);\r\nasm volatile ("putcfg %0,1,%2\n\n\t"\r\n"putcfg %0,0,%1\n"\r\n: : "r" (next), "r" (pteh), "r" (ptel) );\r\nnext += TLB_STEP;\r\nif (next > tlbp->last) next = tlbp->first;\r\ntlbp->next = next;\r\n}\r\nstatic int handle_vmalloc_fault(struct mm_struct *mm,\r\nunsigned long protection_flags,\r\nunsigned long long textaccess,\r\nunsigned long address)\r\n{\r\npgd_t *dir;\r\npud_t *pud;\r\npmd_t *pmd;\r\nstatic pte_t *pte;\r\npte_t entry;\r\ndir = pgd_offset_k(address);\r\npud = pud_offset(dir, address);\r\nif (pud_none_or_clear_bad(pud))\r\nreturn 0;\r\npmd = pmd_offset(pud, address);\r\nif (pmd_none_or_clear_bad(pmd))\r\nreturn 0;\r\npte = pte_offset_kernel(pmd, address);\r\nentry = *pte;\r\nif (pte_none(entry) || !pte_present(entry))\r\nreturn 0;\r\nif ((pte_val(entry) & protection_flags) != protection_flags)\r\nreturn 0;\r\n__do_tlb_refill(address, textaccess, pte);\r\nreturn 1;\r\n}\r\nstatic int handle_tlbmiss(struct mm_struct *mm,\r\nunsigned long long protection_flags,\r\nunsigned long long textaccess,\r\nunsigned long address)\r\n{\r\npgd_t *dir;\r\npud_t *pud;\r\npmd_t *pmd;\r\npte_t *pte;\r\npte_t entry;\r\nif (address >= (unsigned long) TASK_SIZE)\r\nreturn 0;\r\ndir = pgd_offset(mm, address);\r\nif (pgd_none(*dir) || !pgd_present(*dir))\r\nreturn 0;\r\nif (!pgd_present(*dir))\r\nreturn 0;\r\npud = pud_offset(dir, address);\r\nif (pud_none(*pud) || !pud_present(*pud))\r\nreturn 0;\r\npmd = pmd_offset(pud, address);\r\nif (pmd_none(*pmd) || !pmd_present(*pmd))\r\nreturn 0;\r\npte = pte_offset_kernel(pmd, address);\r\nentry = *pte;\r\nif (pte_none(entry) || !pte_present(entry))\r\nreturn 0;\r\nif ((pte_val(entry) & protection_flags) != protection_flags)\r\nreturn 0;\r\n__do_tlb_refill(address, textaccess, pte);\r\nreturn 1;\r\n}\r\nasmlinkage int do_fast_page_fault(unsigned long long ssr_md,\r\nunsigned long long expevt,\r\nunsigned long address)\r\n{\r\nstruct task_struct *tsk;\r\nstruct mm_struct *mm;\r\nunsigned long long textaccess;\r\nunsigned long long protection_flags;\r\nunsigned long long index;\r\nunsigned long long expevt4;\r\nexpevt4 = (expevt >> 4);\r\nindex = expevt4 ^ (expevt4 >> 5);\r\nindex &= 7;\r\nprotection_flags = expevt_lookup_table.protection_flags[index];\r\ntextaccess = expevt_lookup_table.is_text_access[index];\r\ntsk = current;\r\nmm = tsk->mm;\r\nif ((address >= VMALLOC_START && address < VMALLOC_END) ||\r\n(address >= IOBASE_VADDR && address < IOBASE_END)) {\r\nif (ssr_md)\r\nif (handle_vmalloc_fault(mm, protection_flags,\r\ntextaccess, address))\r\nreturn 1;\r\n} else if (!in_interrupt() && mm) {\r\nif (handle_tlbmiss(mm, protection_flags, textaccess, address))\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}
