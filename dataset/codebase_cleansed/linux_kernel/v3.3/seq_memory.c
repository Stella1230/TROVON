static inline int snd_seq_pool_available(struct snd_seq_pool *pool)\r\n{\r\nreturn pool->total_elements - atomic_read(&pool->counter);\r\n}\r\nstatic inline int snd_seq_output_ok(struct snd_seq_pool *pool)\r\n{\r\nreturn snd_seq_pool_available(pool) >= pool->room;\r\n}\r\nstatic int get_var_len(const struct snd_seq_event *event)\r\n{\r\nif ((event->flags & SNDRV_SEQ_EVENT_LENGTH_MASK) != SNDRV_SEQ_EVENT_LENGTH_VARIABLE)\r\nreturn -EINVAL;\r\nreturn event->data.ext.len & ~SNDRV_SEQ_EXT_MASK;\r\n}\r\nint snd_seq_dump_var_event(const struct snd_seq_event *event,\r\nsnd_seq_dump_func_t func, void *private_data)\r\n{\r\nint len, err;\r\nstruct snd_seq_event_cell *cell;\r\nif ((len = get_var_len(event)) <= 0)\r\nreturn len;\r\nif (event->data.ext.len & SNDRV_SEQ_EXT_USRPTR) {\r\nchar buf[32];\r\nchar __user *curptr = (char __force __user *)event->data.ext.ptr;\r\nwhile (len > 0) {\r\nint size = sizeof(buf);\r\nif (len < size)\r\nsize = len;\r\nif (copy_from_user(buf, curptr, size))\r\nreturn -EFAULT;\r\nerr = func(private_data, buf, size);\r\nif (err < 0)\r\nreturn err;\r\ncurptr += size;\r\nlen -= size;\r\n}\r\nreturn 0;\r\n} if (! (event->data.ext.len & SNDRV_SEQ_EXT_CHAINED)) {\r\nreturn func(private_data, event->data.ext.ptr, len);\r\n}\r\ncell = (struct snd_seq_event_cell *)event->data.ext.ptr;\r\nfor (; len > 0 && cell; cell = cell->next) {\r\nint size = sizeof(struct snd_seq_event);\r\nif (len < size)\r\nsize = len;\r\nerr = func(private_data, &cell->event, size);\r\nif (err < 0)\r\nreturn err;\r\nlen -= size;\r\n}\r\nreturn 0;\r\n}\r\nstatic int seq_copy_in_kernel(char **bufptr, const void *src, int size)\r\n{\r\nmemcpy(*bufptr, src, size);\r\n*bufptr += size;\r\nreturn 0;\r\n}\r\nstatic int seq_copy_in_user(char __user **bufptr, const void *src, int size)\r\n{\r\nif (copy_to_user(*bufptr, src, size))\r\nreturn -EFAULT;\r\n*bufptr += size;\r\nreturn 0;\r\n}\r\nint snd_seq_expand_var_event(const struct snd_seq_event *event, int count, char *buf,\r\nint in_kernel, int size_aligned)\r\n{\r\nint len, newlen;\r\nint err;\r\nif ((len = get_var_len(event)) < 0)\r\nreturn len;\r\nnewlen = len;\r\nif (size_aligned > 0)\r\nnewlen = roundup(len, size_aligned);\r\nif (count < newlen)\r\nreturn -EAGAIN;\r\nif (event->data.ext.len & SNDRV_SEQ_EXT_USRPTR) {\r\nif (! in_kernel)\r\nreturn -EINVAL;\r\nif (copy_from_user(buf, (void __force __user *)event->data.ext.ptr, len))\r\nreturn -EFAULT;\r\nreturn newlen;\r\n}\r\nerr = snd_seq_dump_var_event(event,\r\nin_kernel ? (snd_seq_dump_func_t)seq_copy_in_kernel :\r\n(snd_seq_dump_func_t)seq_copy_in_user,\r\n&buf);\r\nreturn err < 0 ? err : newlen;\r\n}\r\nstatic inline void free_cell(struct snd_seq_pool *pool,\r\nstruct snd_seq_event_cell *cell)\r\n{\r\ncell->next = pool->free;\r\npool->free = cell;\r\natomic_dec(&pool->counter);\r\n}\r\nvoid snd_seq_cell_free(struct snd_seq_event_cell * cell)\r\n{\r\nunsigned long flags;\r\nstruct snd_seq_pool *pool;\r\nif (snd_BUG_ON(!cell))\r\nreturn;\r\npool = cell->pool;\r\nif (snd_BUG_ON(!pool))\r\nreturn;\r\nspin_lock_irqsave(&pool->lock, flags);\r\nfree_cell(pool, cell);\r\nif (snd_seq_ev_is_variable(&cell->event)) {\r\nif (cell->event.data.ext.len & SNDRV_SEQ_EXT_CHAINED) {\r\nstruct snd_seq_event_cell *curp, *nextptr;\r\ncurp = cell->event.data.ext.ptr;\r\nfor (; curp; curp = nextptr) {\r\nnextptr = curp->next;\r\ncurp->next = pool->free;\r\nfree_cell(pool, curp);\r\n}\r\n}\r\n}\r\nif (waitqueue_active(&pool->output_sleep)) {\r\nif (snd_seq_output_ok(pool))\r\nwake_up(&pool->output_sleep);\r\n}\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\n}\r\nstatic int snd_seq_cell_alloc(struct snd_seq_pool *pool,\r\nstruct snd_seq_event_cell **cellp,\r\nint nonblock, struct file *file)\r\n{\r\nstruct snd_seq_event_cell *cell;\r\nunsigned long flags;\r\nint err = -EAGAIN;\r\nwait_queue_t wait;\r\nif (pool == NULL)\r\nreturn -EINVAL;\r\n*cellp = NULL;\r\ninit_waitqueue_entry(&wait, current);\r\nspin_lock_irqsave(&pool->lock, flags);\r\nif (pool->ptr == NULL) {\r\nsnd_printd("seq: pool is not initialized\n");\r\nerr = -EINVAL;\r\ngoto __error;\r\n}\r\nwhile (pool->free == NULL && ! nonblock && ! pool->closing) {\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nadd_wait_queue(&pool->output_sleep, &wait);\r\nspin_unlock_irq(&pool->lock);\r\nschedule();\r\nspin_lock_irq(&pool->lock);\r\nremove_wait_queue(&pool->output_sleep, &wait);\r\nif (signal_pending(current)) {\r\nerr = -ERESTARTSYS;\r\ngoto __error;\r\n}\r\n}\r\nif (pool->closing) {\r\nerr = -ENOMEM;\r\ngoto __error;\r\n}\r\ncell = pool->free;\r\nif (cell) {\r\nint used;\r\npool->free = cell->next;\r\natomic_inc(&pool->counter);\r\nused = atomic_read(&pool->counter);\r\nif (pool->max_used < used)\r\npool->max_used = used;\r\npool->event_alloc_success++;\r\ncell->next = NULL;\r\nerr = 0;\r\n} else\r\npool->event_alloc_failures++;\r\n*cellp = cell;\r\n__error:\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nreturn err;\r\n}\r\nint snd_seq_event_dup(struct snd_seq_pool *pool, struct snd_seq_event *event,\r\nstruct snd_seq_event_cell **cellp, int nonblock,\r\nstruct file *file)\r\n{\r\nint ncells, err;\r\nunsigned int extlen;\r\nstruct snd_seq_event_cell *cell;\r\n*cellp = NULL;\r\nncells = 0;\r\nextlen = 0;\r\nif (snd_seq_ev_is_variable(event)) {\r\nextlen = event->data.ext.len & ~SNDRV_SEQ_EXT_MASK;\r\nncells = (extlen + sizeof(struct snd_seq_event) - 1) / sizeof(struct snd_seq_event);\r\n}\r\nif (ncells >= pool->total_elements)\r\nreturn -ENOMEM;\r\nerr = snd_seq_cell_alloc(pool, &cell, nonblock, file);\r\nif (err < 0)\r\nreturn err;\r\ncell->event = *event;\r\nif (snd_seq_ev_is_variable(event)) {\r\nint len = extlen;\r\nint is_chained = event->data.ext.len & SNDRV_SEQ_EXT_CHAINED;\r\nint is_usrptr = event->data.ext.len & SNDRV_SEQ_EXT_USRPTR;\r\nstruct snd_seq_event_cell *src, *tmp, *tail;\r\nchar *buf;\r\ncell->event.data.ext.len = extlen | SNDRV_SEQ_EXT_CHAINED;\r\ncell->event.data.ext.ptr = NULL;\r\nsrc = (struct snd_seq_event_cell *)event->data.ext.ptr;\r\nbuf = (char *)event->data.ext.ptr;\r\ntail = NULL;\r\nwhile (ncells-- > 0) {\r\nint size = sizeof(struct snd_seq_event);\r\nif (len < size)\r\nsize = len;\r\nerr = snd_seq_cell_alloc(pool, &tmp, nonblock, file);\r\nif (err < 0)\r\ngoto __error;\r\nif (cell->event.data.ext.ptr == NULL)\r\ncell->event.data.ext.ptr = tmp;\r\nif (tail)\r\ntail->next = tmp;\r\ntail = tmp;\r\nif (is_chained && src) {\r\ntmp->event = src->event;\r\nsrc = src->next;\r\n} else if (is_usrptr) {\r\nif (copy_from_user(&tmp->event, (char __force __user *)buf, size)) {\r\nerr = -EFAULT;\r\ngoto __error;\r\n}\r\n} else {\r\nmemcpy(&tmp->event, buf, size);\r\n}\r\nbuf += size;\r\nlen -= size;\r\n}\r\n}\r\n*cellp = cell;\r\nreturn 0;\r\n__error:\r\nsnd_seq_cell_free(cell);\r\nreturn err;\r\n}\r\nint snd_seq_pool_poll_wait(struct snd_seq_pool *pool, struct file *file,\r\npoll_table *wait)\r\n{\r\npoll_wait(file, &pool->output_sleep, wait);\r\nreturn snd_seq_output_ok(pool);\r\n}\r\nint snd_seq_pool_init(struct snd_seq_pool *pool)\r\n{\r\nint cell;\r\nstruct snd_seq_event_cell *cellptr;\r\nunsigned long flags;\r\nif (snd_BUG_ON(!pool))\r\nreturn -EINVAL;\r\nif (pool->ptr)\r\nreturn 0;\r\npool->ptr = vmalloc(sizeof(struct snd_seq_event_cell) * pool->size);\r\nif (pool->ptr == NULL) {\r\nsnd_printd("seq: malloc for sequencer events failed\n");\r\nreturn -ENOMEM;\r\n}\r\nspin_lock_irqsave(&pool->lock, flags);\r\npool->free = NULL;\r\nfor (cell = 0; cell < pool->size; cell++) {\r\ncellptr = pool->ptr + cell;\r\ncellptr->pool = pool;\r\ncellptr->next = pool->free;\r\npool->free = cellptr;\r\n}\r\npool->room = (pool->size + 1) / 2;\r\npool->max_used = 0;\r\npool->total_elements = pool->size;\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nreturn 0;\r\n}\r\nint snd_seq_pool_done(struct snd_seq_pool *pool)\r\n{\r\nunsigned long flags;\r\nstruct snd_seq_event_cell *ptr;\r\nint max_count = 5 * HZ;\r\nif (snd_BUG_ON(!pool))\r\nreturn -EINVAL;\r\nspin_lock_irqsave(&pool->lock, flags);\r\npool->closing = 1;\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nif (waitqueue_active(&pool->output_sleep))\r\nwake_up(&pool->output_sleep);\r\nwhile (atomic_read(&pool->counter) > 0) {\r\nif (max_count == 0) {\r\nsnd_printk(KERN_WARNING "snd_seq_pool_done timeout: %d cells remain\n", atomic_read(&pool->counter));\r\nbreak;\r\n}\r\nschedule_timeout_uninterruptible(1);\r\nmax_count--;\r\n}\r\nspin_lock_irqsave(&pool->lock, flags);\r\nptr = pool->ptr;\r\npool->ptr = NULL;\r\npool->free = NULL;\r\npool->total_elements = 0;\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nvfree(ptr);\r\nspin_lock_irqsave(&pool->lock, flags);\r\npool->closing = 0;\r\nspin_unlock_irqrestore(&pool->lock, flags);\r\nreturn 0;\r\n}\r\nstruct snd_seq_pool *snd_seq_pool_new(int poolsize)\r\n{\r\nstruct snd_seq_pool *pool;\r\npool = kzalloc(sizeof(*pool), GFP_KERNEL);\r\nif (pool == NULL) {\r\nsnd_printd("seq: malloc failed for pool\n");\r\nreturn NULL;\r\n}\r\nspin_lock_init(&pool->lock);\r\npool->ptr = NULL;\r\npool->free = NULL;\r\npool->total_elements = 0;\r\natomic_set(&pool->counter, 0);\r\npool->closing = 0;\r\ninit_waitqueue_head(&pool->output_sleep);\r\npool->size = poolsize;\r\npool->max_used = 0;\r\nreturn pool;\r\n}\r\nint snd_seq_pool_delete(struct snd_seq_pool **ppool)\r\n{\r\nstruct snd_seq_pool *pool = *ppool;\r\n*ppool = NULL;\r\nif (pool == NULL)\r\nreturn 0;\r\nsnd_seq_pool_done(pool);\r\nkfree(pool);\r\nreturn 0;\r\n}\r\nint __init snd_sequencer_memory_init(void)\r\n{\r\nreturn 0;\r\n}\r\nvoid __exit snd_sequencer_memory_done(void)\r\n{\r\n}\r\nvoid snd_seq_info_pool(struct snd_info_buffer *buffer,\r\nstruct snd_seq_pool *pool, char *space)\r\n{\r\nif (pool == NULL)\r\nreturn;\r\nsnd_iprintf(buffer, "%sPool size : %d\n", space, pool->total_elements);\r\nsnd_iprintf(buffer, "%sCells in use : %d\n", space, atomic_read(&pool->counter));\r\nsnd_iprintf(buffer, "%sPeak cells in use : %d\n", space, pool->max_used);\r\nsnd_iprintf(buffer, "%sAlloc success : %d\n", space, pool->event_alloc_success);\r\nsnd_iprintf(buffer, "%sAlloc failures : %d\n", space, pool->event_alloc_failures);\r\n}
