static inline int notify_page_fault(struct pt_regs *regs, int trap)\r\n{\r\nint ret = 0;\r\nif (kprobes_built_in() && !user_mode(regs)) {\r\npreempt_disable();\r\nif (kprobe_running() && kprobe_fault_handler(regs, trap))\r\nret = 1;\r\npreempt_enable();\r\n}\r\nreturn ret;\r\n}\r\nstatic inline pmd_t *vmalloc_sync_one(pgd_t *pgd, unsigned long address)\r\n{\r\nunsigned index = pgd_index(address);\r\npgd_t *pgd_k;\r\npud_t *pud, *pud_k;\r\npmd_t *pmd, *pmd_k;\r\npgd += index;\r\npgd_k = init_mm.pgd + index;\r\nif (!pgd_present(*pgd_k))\r\nreturn NULL;\r\npud = pud_offset(pgd, address);\r\npud_k = pud_offset(pgd_k, address);\r\nif (!pud_present(*pud_k))\r\nreturn NULL;\r\nif (!pud_present(*pud))\r\nset_pud(pud, *pud_k);\r\npmd = pmd_offset(pud, address);\r\npmd_k = pmd_offset(pud_k, address);\r\nif (!pmd_present(*pmd_k))\r\nreturn NULL;\r\nif (!pmd_present(*pmd))\r\nset_pmd(pmd, *pmd_k);\r\nelse {\r\nBUG_ON(pmd_page(*pmd) != pmd_page(*pmd_k));\r\nreturn NULL;\r\n}\r\nreturn pmd_k;\r\n}\r\nstatic noinline int vmalloc_fault(unsigned long address)\r\n{\r\npgd_t *pgd_k;\r\npmd_t *pmd_k;\r\npte_t *pte_k;\r\nif (!(address >= VMALLOC_START && address < P3_ADDR_MAX))\r\nreturn -1;\r\npgd_k = get_TTB();\r\npmd_k = vmalloc_sync_one(pgd_k, address);\r\nif (!pmd_k)\r\nreturn -1;\r\npte_k = pte_offset_kernel(pmd_k, address);\r\nif (!pte_present(*pte_k))\r\nreturn -1;\r\nreturn 0;\r\n}\r\nstatic int fault_in_kernel_space(unsigned long address)\r\n{\r\nreturn address >= TASK_SIZE;\r\n}\r\nasmlinkage void __kprobes do_page_fault(struct pt_regs *regs,\r\nunsigned long writeaccess,\r\nunsigned long address)\r\n{\r\nunsigned long vec;\r\nstruct task_struct *tsk;\r\nstruct mm_struct *mm;\r\nstruct vm_area_struct * vma;\r\nint si_code;\r\nint fault;\r\nsiginfo_t info;\r\ntsk = current;\r\nmm = tsk->mm;\r\nsi_code = SEGV_MAPERR;\r\nvec = lookup_exception_vector();\r\nif (unlikely(fault_in_kernel_space(address))) {\r\nif (vmalloc_fault(address) >= 0)\r\nreturn;\r\nif (notify_page_fault(regs, vec))\r\nreturn;\r\ngoto bad_area_nosemaphore;\r\n}\r\nif (unlikely(notify_page_fault(regs, vec)))\r\nreturn;\r\nif ((regs->sr & SR_IMASK) != SR_IMASK)\r\nlocal_irq_enable();\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);\r\nif (in_atomic() || !mm)\r\ngoto no_context;\r\ndown_read(&mm->mmap_sem);\r\nvma = find_vma(mm, address);\r\nif (!vma)\r\ngoto bad_area;\r\nif (vma->vm_start <= address)\r\ngoto good_area;\r\nif (!(vma->vm_flags & VM_GROWSDOWN))\r\ngoto bad_area;\r\nif (expand_stack(vma, address))\r\ngoto bad_area;\r\ngood_area:\r\nsi_code = SEGV_ACCERR;\r\nif (writeaccess) {\r\nif (!(vma->vm_flags & VM_WRITE))\r\ngoto bad_area;\r\n} else {\r\nif (!(vma->vm_flags & (VM_READ | VM_EXEC | VM_WRITE)))\r\ngoto bad_area;\r\n}\r\nfault = handle_mm_fault(mm, vma, address, writeaccess ? FAULT_FLAG_WRITE : 0);\r\nif (unlikely(fault & VM_FAULT_ERROR)) {\r\nif (fault & VM_FAULT_OOM)\r\ngoto out_of_memory;\r\nelse if (fault & VM_FAULT_SIGBUS)\r\ngoto do_sigbus;\r\nBUG();\r\n}\r\nif (fault & VM_FAULT_MAJOR) {\r\ntsk->maj_flt++;\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1,\r\nregs, address);\r\n} else {\r\ntsk->min_flt++;\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1,\r\nregs, address);\r\n}\r\nup_read(&mm->mmap_sem);\r\nreturn;\r\nbad_area:\r\nup_read(&mm->mmap_sem);\r\nbad_area_nosemaphore:\r\nif (user_mode(regs)) {\r\ninfo.si_signo = SIGSEGV;\r\ninfo.si_errno = 0;\r\ninfo.si_code = si_code;\r\ninfo.si_addr = (void *) address;\r\nforce_sig_info(SIGSEGV, &info, tsk);\r\nreturn;\r\n}\r\nno_context:\r\nif (fixup_exception(regs))\r\nreturn;\r\nif (handle_trapped_io(regs, address))\r\nreturn;\r\nbust_spinlocks(1);\r\nif (oops_may_print()) {\r\nunsigned long page;\r\nif (address < PAGE_SIZE)\r\nprintk(KERN_ALERT "Unable to handle kernel NULL "\r\n"pointer dereference");\r\nelse\r\nprintk(KERN_ALERT "Unable to handle kernel paging "\r\n"request");\r\nprintk(" at virtual address %08lx\n", address);\r\nprintk(KERN_ALERT "pc = %08lx\n", regs->pc);\r\npage = (unsigned long)get_TTB();\r\nif (page) {\r\npage = ((__typeof__(page) *)page)[address >> PGDIR_SHIFT];\r\nprintk(KERN_ALERT "*pde = %08lx\n", page);\r\nif (page & _PAGE_PRESENT) {\r\npage &= PAGE_MASK;\r\naddress &= 0x003ff000;\r\npage = ((__typeof__(page) *)\r\n__va(page))[address >>\r\nPAGE_SHIFT];\r\nprintk(KERN_ALERT "*pte = %08lx\n", page);\r\n}\r\n}\r\n}\r\ndie("Oops", regs, writeaccess);\r\nbust_spinlocks(0);\r\ndo_exit(SIGKILL);\r\nout_of_memory:\r\nup_read(&mm->mmap_sem);\r\nif (!user_mode(regs))\r\ngoto no_context;\r\npagefault_out_of_memory();\r\nreturn;\r\ndo_sigbus:\r\nup_read(&mm->mmap_sem);\r\ninfo.si_signo = SIGBUS;\r\ninfo.si_errno = 0;\r\ninfo.si_code = BUS_ADRERR;\r\ninfo.si_addr = (void *)address;\r\nforce_sig_info(SIGBUS, &info, tsk);\r\nif (!user_mode(regs))\r\ngoto no_context;\r\n}\r\nasmlinkage int __kprobes\r\nhandle_tlbmiss(struct pt_regs *regs, unsigned long writeaccess,\r\nunsigned long address)\r\n{\r\npgd_t *pgd;\r\npud_t *pud;\r\npmd_t *pmd;\r\npte_t *pte;\r\npte_t entry;\r\nif (address >= P3SEG && address < P3_ADDR_MAX) {\r\npgd = pgd_offset_k(address);\r\n} else {\r\nif (unlikely(address >= TASK_SIZE || !current->mm))\r\nreturn 1;\r\npgd = pgd_offset(current->mm, address);\r\n}\r\npud = pud_offset(pgd, address);\r\nif (pud_none_or_clear_bad(pud))\r\nreturn 1;\r\npmd = pmd_offset(pud, address);\r\nif (pmd_none_or_clear_bad(pmd))\r\nreturn 1;\r\npte = pte_offset_kernel(pmd, address);\r\nentry = *pte;\r\nif (unlikely(pte_none(entry) || pte_not_present(entry)))\r\nreturn 1;\r\nif (unlikely(writeaccess && !pte_write(entry)))\r\nreturn 1;\r\nif (writeaccess)\r\nentry = pte_mkdirty(entry);\r\nentry = pte_mkyoung(entry);\r\nset_pte(pte, entry);\r\n#if defined(CONFIG_CPU_SH4) && !defined(CONFIG_SMP)\r\nif (writeaccess == 2)\r\nlocal_flush_tlb_one(get_asid(), address & PAGE_MASK);\r\n#endif\r\nupdate_mmu_cache(NULL, address, pte);\r\nreturn 0;\r\n}
