char *ceph_osdmap_state_str(char *str, int len, int state)\r\n{\r\nint flag = 0;\r\nif (!len)\r\ngoto done;\r\n*str = '\0';\r\nif (state) {\r\nif (state & CEPH_OSD_EXISTS) {\r\nsnprintf(str, len, "exists");\r\nflag = 1;\r\n}\r\nif (state & CEPH_OSD_UP) {\r\nsnprintf(str, len, "%s%s%s", str, (flag ? ", " : ""),\r\n"up");\r\nflag = 1;\r\n}\r\n} else {\r\nsnprintf(str, len, "doesn't exist");\r\n}\r\ndone:\r\nreturn str;\r\n}\r\nstatic int calc_bits_of(unsigned t)\r\n{\r\nint b = 0;\r\nwhile (t) {\r\nt = t >> 1;\r\nb++;\r\n}\r\nreturn b;\r\n}\r\nstatic void calc_pg_masks(struct ceph_pg_pool_info *pi)\r\n{\r\npi->pg_num_mask = (1 << calc_bits_of(le32_to_cpu(pi->v.pg_num)-1)) - 1;\r\npi->pgp_num_mask =\r\n(1 << calc_bits_of(le32_to_cpu(pi->v.pgp_num)-1)) - 1;\r\npi->lpg_num_mask =\r\n(1 << calc_bits_of(le32_to_cpu(pi->v.lpg_num)-1)) - 1;\r\npi->lpgp_num_mask =\r\n(1 << calc_bits_of(le32_to_cpu(pi->v.lpgp_num)-1)) - 1;\r\n}\r\nstatic int crush_decode_uniform_bucket(void **p, void *end,\r\nstruct crush_bucket_uniform *b)\r\n{\r\ndout("crush_decode_uniform_bucket %p to %p\n", *p, end);\r\nceph_decode_need(p, end, (1+b->h.size) * sizeof(u32), bad);\r\nb->item_weight = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_list_bucket(void **p, void *end,\r\nstruct crush_bucket_list *b)\r\n{\r\nint j;\r\ndout("crush_decode_list_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nb->sum_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->sum_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++) {\r\nb->item_weights[j] = ceph_decode_32(p);\r\nb->sum_weights[j] = ceph_decode_32(p);\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_tree_bucket(void **p, void *end,\r\nstruct crush_bucket_tree *b)\r\n{\r\nint j;\r\ndout("crush_decode_tree_bucket %p to %p\n", *p, end);\r\nceph_decode_32_safe(p, end, b->num_nodes, bad);\r\nb->node_weights = kcalloc(b->num_nodes, sizeof(u32), GFP_NOFS);\r\nif (b->node_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, b->num_nodes * sizeof(u32), bad);\r\nfor (j = 0; j < b->num_nodes; j++)\r\nb->node_weights[j] = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_straw_bucket(void **p, void *end,\r\nstruct crush_bucket_straw *b)\r\n{\r\nint j;\r\ndout("crush_decode_straw_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nb->straws = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->straws == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++) {\r\nb->item_weights[j] = ceph_decode_32(p);\r\nb->straws[j] = ceph_decode_32(p);\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic struct crush_map *crush_decode(void *pbyval, void *end)\r\n{\r\nstruct crush_map *c;\r\nint err = -EINVAL;\r\nint i, j;\r\nvoid **p = &pbyval;\r\nvoid *start = pbyval;\r\nu32 magic;\r\ndout("crush_decode %p to %p len %d\n", *p, end, (int)(end - *p));\r\nc = kzalloc(sizeof(*c), GFP_NOFS);\r\nif (c == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nceph_decode_need(p, end, 4*sizeof(u32), bad);\r\nmagic = ceph_decode_32(p);\r\nif (magic != CRUSH_MAGIC) {\r\npr_err("crush_decode magic %x != current %x\n",\r\n(unsigned)magic, (unsigned)CRUSH_MAGIC);\r\ngoto bad;\r\n}\r\nc->max_buckets = ceph_decode_32(p);\r\nc->max_rules = ceph_decode_32(p);\r\nc->max_devices = ceph_decode_32(p);\r\nc->device_parents = kcalloc(c->max_devices, sizeof(u32), GFP_NOFS);\r\nif (c->device_parents == NULL)\r\ngoto badmem;\r\nc->bucket_parents = kcalloc(c->max_buckets, sizeof(u32), GFP_NOFS);\r\nif (c->bucket_parents == NULL)\r\ngoto badmem;\r\nc->buckets = kcalloc(c->max_buckets, sizeof(*c->buckets), GFP_NOFS);\r\nif (c->buckets == NULL)\r\ngoto badmem;\r\nc->rules = kcalloc(c->max_rules, sizeof(*c->rules), GFP_NOFS);\r\nif (c->rules == NULL)\r\ngoto badmem;\r\nfor (i = 0; i < c->max_buckets; i++) {\r\nint size = 0;\r\nu32 alg;\r\nstruct crush_bucket *b;\r\nceph_decode_32_safe(p, end, alg, bad);\r\nif (alg == 0) {\r\nc->buckets[i] = NULL;\r\ncontinue;\r\n}\r\ndout("crush_decode bucket %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nswitch (alg) {\r\ncase CRUSH_BUCKET_UNIFORM:\r\nsize = sizeof(struct crush_bucket_uniform);\r\nbreak;\r\ncase CRUSH_BUCKET_LIST:\r\nsize = sizeof(struct crush_bucket_list);\r\nbreak;\r\ncase CRUSH_BUCKET_TREE:\r\nsize = sizeof(struct crush_bucket_tree);\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW:\r\nsize = sizeof(struct crush_bucket_straw);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto bad;\r\n}\r\nBUG_ON(size == 0);\r\nb = c->buckets[i] = kzalloc(size, GFP_NOFS);\r\nif (b == NULL)\r\ngoto badmem;\r\nceph_decode_need(p, end, 4*sizeof(u32), bad);\r\nb->id = ceph_decode_32(p);\r\nb->type = ceph_decode_16(p);\r\nb->alg = ceph_decode_8(p);\r\nb->hash = ceph_decode_8(p);\r\nb->weight = ceph_decode_32(p);\r\nb->size = ceph_decode_32(p);\r\ndout("crush_decode bucket size %d off %x %p to %p\n",\r\nb->size, (int)(*p-start), *p, end);\r\nb->items = kcalloc(b->size, sizeof(__s32), GFP_NOFS);\r\nif (b->items == NULL)\r\ngoto badmem;\r\nb->perm = kcalloc(b->size, sizeof(u32), GFP_NOFS);\r\nif (b->perm == NULL)\r\ngoto badmem;\r\nb->perm_n = 0;\r\nceph_decode_need(p, end, b->size*sizeof(u32), bad);\r\nfor (j = 0; j < b->size; j++)\r\nb->items[j] = ceph_decode_32(p);\r\nswitch (b->alg) {\r\ncase CRUSH_BUCKET_UNIFORM:\r\nerr = crush_decode_uniform_bucket(p, end,\r\n(struct crush_bucket_uniform *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_LIST:\r\nerr = crush_decode_list_bucket(p, end,\r\n(struct crush_bucket_list *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_TREE:\r\nerr = crush_decode_tree_bucket(p, end,\r\n(struct crush_bucket_tree *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW:\r\nerr = crush_decode_straw_bucket(p, end,\r\n(struct crush_bucket_straw *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\n}\r\n}\r\ndout("rule vec is %p\n", c->rules);\r\nfor (i = 0; i < c->max_rules; i++) {\r\nu32 yes;\r\nstruct crush_rule *r;\r\nceph_decode_32_safe(p, end, yes, bad);\r\nif (!yes) {\r\ndout("crush_decode NO rule %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nc->rules[i] = NULL;\r\ncontinue;\r\n}\r\ndout("crush_decode rule %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nceph_decode_32_safe(p, end, yes, bad);\r\n#if BITS_PER_LONG == 32\r\nerr = -EINVAL;\r\nif (yes > ULONG_MAX / sizeof(struct crush_rule_step))\r\ngoto bad;\r\n#endif\r\nr = c->rules[i] = kmalloc(sizeof(*r) +\r\nyes*sizeof(struct crush_rule_step),\r\nGFP_NOFS);\r\nif (r == NULL)\r\ngoto badmem;\r\ndout(" rule %d is at %p\n", i, r);\r\nr->len = yes;\r\nceph_decode_copy_safe(p, end, &r->mask, 4, bad);\r\nceph_decode_need(p, end, r->len*3*sizeof(u32), bad);\r\nfor (j = 0; j < r->len; j++) {\r\nr->steps[j].op = ceph_decode_32(p);\r\nr->steps[j].arg1 = ceph_decode_32(p);\r\nr->steps[j].arg2 = ceph_decode_32(p);\r\n}\r\n}\r\ndout("crush_decode success\n");\r\nreturn c;\r\nbadmem:\r\nerr = -ENOMEM;\r\nbad:\r\ndout("crush_decode fail %d\n", err);\r\ncrush_destroy(c);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic int pgid_cmp(struct ceph_pg l, struct ceph_pg r)\r\n{\r\nu64 a = *(u64 *)&l;\r\nu64 b = *(u64 *)&r;\r\nif (a < b)\r\nreturn -1;\r\nif (a > b)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int __insert_pg_mapping(struct ceph_pg_mapping *new,\r\nstruct rb_root *root)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_pg_mapping *pg = NULL;\r\nint c;\r\ndout("__insert_pg_mapping %llx %p\n", *(u64 *)&new->pgid, new);\r\nwhile (*p) {\r\nparent = *p;\r\npg = rb_entry(parent, struct ceph_pg_mapping, node);\r\nc = pgid_cmp(new->pgid, pg->pgid);\r\nif (c < 0)\r\np = &(*p)->rb_left;\r\nelse if (c > 0)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, root);\r\nreturn 0;\r\n}\r\nstatic struct ceph_pg_mapping *__lookup_pg_mapping(struct rb_root *root,\r\nstruct ceph_pg pgid)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct ceph_pg_mapping *pg;\r\nint c;\r\nwhile (n) {\r\npg = rb_entry(n, struct ceph_pg_mapping, node);\r\nc = pgid_cmp(pgid, pg->pgid);\r\nif (c < 0) {\r\nn = n->rb_left;\r\n} else if (c > 0) {\r\nn = n->rb_right;\r\n} else {\r\ndout("__lookup_pg_mapping %llx got %p\n",\r\n*(u64 *)&pgid, pg);\r\nreturn pg;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic int __remove_pg_mapping(struct rb_root *root, struct ceph_pg pgid)\r\n{\r\nstruct ceph_pg_mapping *pg = __lookup_pg_mapping(root, pgid);\r\nif (pg) {\r\ndout("__remove_pg_mapping %llx %p\n", *(u64 *)&pgid, pg);\r\nrb_erase(&pg->node, root);\r\nkfree(pg);\r\nreturn 0;\r\n}\r\ndout("__remove_pg_mapping %llx dne\n", *(u64 *)&pgid);\r\nreturn -ENOENT;\r\n}\r\nstatic int __insert_pg_pool(struct rb_root *root, struct ceph_pg_pool_info *new)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_pg_pool_info *pi = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\npi = rb_entry(parent, struct ceph_pg_pool_info, node);\r\nif (new->id < pi->id)\r\np = &(*p)->rb_left;\r\nelse if (new->id > pi->id)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, root);\r\nreturn 0;\r\n}\r\nstatic struct ceph_pg_pool_info *__lookup_pg_pool(struct rb_root *root, int id)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nstruct rb_node *n = root->rb_node;\r\nwhile (n) {\r\npi = rb_entry(n, struct ceph_pg_pool_info, node);\r\nif (id < pi->id)\r\nn = n->rb_left;\r\nelse if (id > pi->id)\r\nn = n->rb_right;\r\nelse\r\nreturn pi;\r\n}\r\nreturn NULL;\r\n}\r\nint ceph_pg_poolid_by_name(struct ceph_osdmap *map, const char *name)\r\n{\r\nstruct rb_node *rbp;\r\nfor (rbp = rb_first(&map->pg_pools); rbp; rbp = rb_next(rbp)) {\r\nstruct ceph_pg_pool_info *pi =\r\nrb_entry(rbp, struct ceph_pg_pool_info, node);\r\nif (pi->name && strcmp(pi->name, name) == 0)\r\nreturn pi->id;\r\n}\r\nreturn -ENOENT;\r\n}\r\nstatic void __remove_pg_pool(struct rb_root *root, struct ceph_pg_pool_info *pi)\r\n{\r\nrb_erase(&pi->node, root);\r\nkfree(pi->name);\r\nkfree(pi);\r\n}\r\nstatic int __decode_pool(void **p, void *end, struct ceph_pg_pool_info *pi)\r\n{\r\nunsigned n, m;\r\nceph_decode_copy(p, &pi->v, sizeof(pi->v));\r\ncalc_pg_masks(pi);\r\nn = le32_to_cpu(pi->v.num_snaps);\r\nwhile (n--) {\r\nceph_decode_need(p, end, sizeof(u64) + 1 + sizeof(u64) +\r\nsizeof(struct ceph_timespec), bad);\r\n*p += sizeof(u64) +\r\n1 + sizeof(u64) +\r\nsizeof(struct ceph_timespec);\r\nm = ceph_decode_32(p);\r\n*p += m;\r\n}\r\n*p += le32_to_cpu(pi->v.num_removed_snap_intervals) * sizeof(u64) * 2;\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int __decode_pool_names(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nu32 num, len, pool;\r\nceph_decode_32_safe(p, end, num, bad);\r\ndout(" %d pool names\n", num);\r\nwhile (num--) {\r\nceph_decode_32_safe(p, end, pool, bad);\r\nceph_decode_32_safe(p, end, len, bad);\r\ndout(" pool %d len %d\n", pool, len);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (pi) {\r\nkfree(pi->name);\r\npi->name = kmalloc(len + 1, GFP_NOFS);\r\nif (pi->name) {\r\nmemcpy(pi->name, *p, len);\r\npi->name[len] = '\0';\r\ndout(" name is %s\n", pi->name);\r\n}\r\n}\r\n*p += len;\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nvoid ceph_osdmap_destroy(struct ceph_osdmap *map)\r\n{\r\ndout("osdmap_destroy %p\n", map);\r\nif (map->crush)\r\ncrush_destroy(map->crush);\r\nwhile (!RB_EMPTY_ROOT(&map->pg_temp)) {\r\nstruct ceph_pg_mapping *pg =\r\nrb_entry(rb_first(&map->pg_temp),\r\nstruct ceph_pg_mapping, node);\r\nrb_erase(&pg->node, &map->pg_temp);\r\nkfree(pg);\r\n}\r\nwhile (!RB_EMPTY_ROOT(&map->pg_pools)) {\r\nstruct ceph_pg_pool_info *pi =\r\nrb_entry(rb_first(&map->pg_pools),\r\nstruct ceph_pg_pool_info, node);\r\n__remove_pg_pool(&map->pg_pools, pi);\r\n}\r\nkfree(map->osd_state);\r\nkfree(map->osd_weight);\r\nkfree(map->osd_addr);\r\nkfree(map);\r\n}\r\nstatic int osdmap_set_max_osd(struct ceph_osdmap *map, int max)\r\n{\r\nu8 *state;\r\nstruct ceph_entity_addr *addr;\r\nu32 *weight;\r\nstate = kcalloc(max, sizeof(*state), GFP_NOFS);\r\naddr = kcalloc(max, sizeof(*addr), GFP_NOFS);\r\nweight = kcalloc(max, sizeof(*weight), GFP_NOFS);\r\nif (state == NULL || addr == NULL || weight == NULL) {\r\nkfree(state);\r\nkfree(addr);\r\nkfree(weight);\r\nreturn -ENOMEM;\r\n}\r\nif (map->osd_state) {\r\nmemcpy(state, map->osd_state, map->max_osd*sizeof(*state));\r\nmemcpy(addr, map->osd_addr, map->max_osd*sizeof(*addr));\r\nmemcpy(weight, map->osd_weight, map->max_osd*sizeof(*weight));\r\nkfree(map->osd_state);\r\nkfree(map->osd_addr);\r\nkfree(map->osd_weight);\r\n}\r\nmap->osd_state = state;\r\nmap->osd_weight = weight;\r\nmap->osd_addr = addr;\r\nmap->max_osd = max;\r\nreturn 0;\r\n}\r\nstruct ceph_osdmap *osdmap_decode(void **p, void *end)\r\n{\r\nstruct ceph_osdmap *map;\r\nu16 version;\r\nu32 len, max, i;\r\nu8 ev;\r\nint err = -EINVAL;\r\nvoid *start = *p;\r\nstruct ceph_pg_pool_info *pi;\r\ndout("osdmap_decode %p to %p len %d\n", *p, end, (int)(end - *p));\r\nmap = kzalloc(sizeof(*map), GFP_NOFS);\r\nif (map == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nmap->pg_temp = RB_ROOT;\r\nceph_decode_16_safe(p, end, version, bad);\r\nif (version > CEPH_OSDMAP_VERSION) {\r\npr_warning("got unknown v %d > %d of osdmap\n", version,\r\nCEPH_OSDMAP_VERSION);\r\ngoto bad;\r\n}\r\nceph_decode_need(p, end, 2*sizeof(u64)+6*sizeof(u32), bad);\r\nceph_decode_copy(p, &map->fsid, sizeof(map->fsid));\r\nmap->epoch = ceph_decode_32(p);\r\nceph_decode_copy(p, &map->created, sizeof(map->created));\r\nceph_decode_copy(p, &map->modified, sizeof(map->modified));\r\nceph_decode_32_safe(p, end, max, bad);\r\nwhile (max--) {\r\nceph_decode_need(p, end, 4 + 1 + sizeof(pi->v), bad);\r\npi = kzalloc(sizeof(*pi), GFP_NOFS);\r\nif (!pi)\r\ngoto bad;\r\npi->id = ceph_decode_32(p);\r\nev = ceph_decode_8(p);\r\nif (ev > CEPH_PG_POOL_VERSION) {\r\npr_warning("got unknown v %d > %d of ceph_pg_pool\n",\r\nev, CEPH_PG_POOL_VERSION);\r\nkfree(pi);\r\ngoto bad;\r\n}\r\nerr = __decode_pool(p, end, pi);\r\nif (err < 0) {\r\nkfree(pi);\r\ngoto bad;\r\n}\r\n__insert_pg_pool(&map->pg_pools, pi);\r\n}\r\nif (version >= 5 && __decode_pool_names(p, end, map) < 0)\r\ngoto bad;\r\nceph_decode_32_safe(p, end, map->pool_max, bad);\r\nceph_decode_32_safe(p, end, map->flags, bad);\r\nmax = ceph_decode_32(p);\r\nerr = osdmap_set_max_osd(map, max);\r\nif (err < 0)\r\ngoto bad;\r\ndout("osdmap_decode max_osd = %d\n", map->max_osd);\r\nerr = -EINVAL;\r\nceph_decode_need(p, end, 3*sizeof(u32) +\r\nmap->max_osd*(1 + sizeof(*map->osd_weight) +\r\nsizeof(*map->osd_addr)), bad);\r\n*p += 4;\r\nceph_decode_copy(p, map->osd_state, map->max_osd);\r\n*p += 4;\r\nfor (i = 0; i < map->max_osd; i++)\r\nmap->osd_weight[i] = ceph_decode_32(p);\r\n*p += 4;\r\nceph_decode_copy(p, map->osd_addr, map->max_osd*sizeof(*map->osd_addr));\r\nfor (i = 0; i < map->max_osd; i++)\r\nceph_decode_addr(&map->osd_addr[i]);\r\nceph_decode_32_safe(p, end, len, bad);\r\nfor (i = 0; i < len; i++) {\r\nint n, j;\r\nstruct ceph_pg pgid;\r\nstruct ceph_pg_mapping *pg;\r\nceph_decode_need(p, end, sizeof(u32) + sizeof(u64), bad);\r\nceph_decode_copy(p, &pgid, sizeof(pgid));\r\nn = ceph_decode_32(p);\r\nceph_decode_need(p, end, n * sizeof(u32), bad);\r\nerr = -ENOMEM;\r\npg = kmalloc(sizeof(*pg) + n*sizeof(u32), GFP_NOFS);\r\nif (!pg)\r\ngoto bad;\r\npg->pgid = pgid;\r\npg->len = n;\r\nfor (j = 0; j < n; j++)\r\npg->osds[j] = ceph_decode_32(p);\r\nerr = __insert_pg_mapping(pg, &map->pg_temp);\r\nif (err)\r\ngoto bad;\r\ndout(" added pg_temp %llx len %d\n", *(u64 *)&pgid, len);\r\n}\r\nceph_decode_32_safe(p, end, len, bad);\r\ndout("osdmap_decode crush len %d from off 0x%x\n", len,\r\n(int)(*p - start));\r\nceph_decode_need(p, end, len, bad);\r\nmap->crush = crush_decode(*p, end);\r\n*p += len;\r\nif (IS_ERR(map->crush)) {\r\nerr = PTR_ERR(map->crush);\r\nmap->crush = NULL;\r\ngoto bad;\r\n}\r\n*p = end;\r\ndout("osdmap_decode done %p %p\n", *p, end);\r\nreturn map;\r\nbad:\r\ndout("osdmap_decode fail\n");\r\nceph_osdmap_destroy(map);\r\nreturn ERR_PTR(err);\r\n}\r\nstruct ceph_osdmap *osdmap_apply_incremental(void **p, void *end,\r\nstruct ceph_osdmap *map,\r\nstruct ceph_messenger *msgr)\r\n{\r\nstruct crush_map *newcrush = NULL;\r\nstruct ceph_fsid fsid;\r\nu32 epoch = 0;\r\nstruct ceph_timespec modified;\r\nu32 len, pool;\r\n__s32 new_pool_max, new_flags, max;\r\nvoid *start = *p;\r\nint err = -EINVAL;\r\nu16 version;\r\nceph_decode_16_safe(p, end, version, bad);\r\nif (version > CEPH_OSDMAP_INC_VERSION) {\r\npr_warning("got unknown v %d > %d of inc osdmap\n", version,\r\nCEPH_OSDMAP_INC_VERSION);\r\ngoto bad;\r\n}\r\nceph_decode_need(p, end, sizeof(fsid)+sizeof(modified)+2*sizeof(u32),\r\nbad);\r\nceph_decode_copy(p, &fsid, sizeof(fsid));\r\nepoch = ceph_decode_32(p);\r\nBUG_ON(epoch != map->epoch+1);\r\nceph_decode_copy(p, &modified, sizeof(modified));\r\nnew_pool_max = ceph_decode_32(p);\r\nnew_flags = ceph_decode_32(p);\r\nceph_decode_32_safe(p, end, len, bad);\r\nif (len > 0) {\r\ndout("apply_incremental full map len %d, %p to %p\n",\r\nlen, *p, end);\r\nreturn osdmap_decode(p, min(*p+len, end));\r\n}\r\nceph_decode_32_safe(p, end, len, bad);\r\nif (len > 0) {\r\ndout("apply_incremental new crush map len %d, %p to %p\n",\r\nlen, *p, end);\r\nnewcrush = crush_decode(*p, min(*p+len, end));\r\nif (IS_ERR(newcrush))\r\nreturn ERR_CAST(newcrush);\r\n*p += len;\r\n}\r\nif (new_flags >= 0)\r\nmap->flags = new_flags;\r\nif (new_pool_max >= 0)\r\nmap->pool_max = new_pool_max;\r\nceph_decode_need(p, end, 5*sizeof(u32), bad);\r\nmax = ceph_decode_32(p);\r\nif (max >= 0) {\r\nerr = osdmap_set_max_osd(map, max);\r\nif (err < 0)\r\ngoto bad;\r\n}\r\nmap->epoch++;\r\nmap->modified = modified;\r\nif (newcrush) {\r\nif (map->crush)\r\ncrush_destroy(map->crush);\r\nmap->crush = newcrush;\r\nnewcrush = NULL;\r\n}\r\nceph_decode_32_safe(p, end, len, bad);\r\nwhile (len--) {\r\n__u8 ev;\r\nstruct ceph_pg_pool_info *pi;\r\nceph_decode_32_safe(p, end, pool, bad);\r\nceph_decode_need(p, end, 1 + sizeof(pi->v), bad);\r\nev = ceph_decode_8(p);\r\nif (ev > CEPH_PG_POOL_VERSION) {\r\npr_warning("got unknown v %d > %d of ceph_pg_pool\n",\r\nev, CEPH_PG_POOL_VERSION);\r\ngoto bad;\r\n}\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (!pi) {\r\npi = kzalloc(sizeof(*pi), GFP_NOFS);\r\nif (!pi) {\r\nerr = -ENOMEM;\r\ngoto bad;\r\n}\r\npi->id = pool;\r\n__insert_pg_pool(&map->pg_pools, pi);\r\n}\r\nerr = __decode_pool(p, end, pi);\r\nif (err < 0)\r\ngoto bad;\r\n}\r\nif (version >= 5 && __decode_pool_names(p, end, map) < 0)\r\ngoto bad;\r\nceph_decode_32_safe(p, end, len, bad);\r\nwhile (len--) {\r\nstruct ceph_pg_pool_info *pi;\r\nceph_decode_32_safe(p, end, pool, bad);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (pi)\r\n__remove_pg_pool(&map->pg_pools, pi);\r\n}\r\nerr = -EINVAL;\r\nceph_decode_32_safe(p, end, len, bad);\r\nwhile (len--) {\r\nu32 osd;\r\nstruct ceph_entity_addr addr;\r\nceph_decode_32_safe(p, end, osd, bad);\r\nceph_decode_copy_safe(p, end, &addr, sizeof(addr), bad);\r\nceph_decode_addr(&addr);\r\npr_info("osd%d up\n", osd);\r\nBUG_ON(osd >= map->max_osd);\r\nmap->osd_state[osd] |= CEPH_OSD_UP;\r\nmap->osd_addr[osd] = addr;\r\n}\r\nceph_decode_32_safe(p, end, len, bad);\r\nwhile (len--) {\r\nu32 osd;\r\nu8 xorstate;\r\nceph_decode_32_safe(p, end, osd, bad);\r\nxorstate = **(u8 **)p;\r\n(*p)++;\r\nif (xorstate == 0)\r\nxorstate = CEPH_OSD_UP;\r\nif (xorstate & CEPH_OSD_UP)\r\npr_info("osd%d down\n", osd);\r\nif (osd < map->max_osd)\r\nmap->osd_state[osd] ^= xorstate;\r\n}\r\nceph_decode_32_safe(p, end, len, bad);\r\nwhile (len--) {\r\nu32 osd, off;\r\nceph_decode_need(p, end, sizeof(u32)*2, bad);\r\nosd = ceph_decode_32(p);\r\noff = ceph_decode_32(p);\r\npr_info("osd%d weight 0x%x %s\n", osd, off,\r\noff == CEPH_OSD_IN ? "(in)" :\r\n(off == CEPH_OSD_OUT ? "(out)" : ""));\r\nif (osd < map->max_osd)\r\nmap->osd_weight[osd] = off;\r\n}\r\nceph_decode_32_safe(p, end, len, bad);\r\nwhile (len--) {\r\nstruct ceph_pg_mapping *pg;\r\nint j;\r\nstruct ceph_pg pgid;\r\nu32 pglen;\r\nceph_decode_need(p, end, sizeof(u64) + sizeof(u32), bad);\r\nceph_decode_copy(p, &pgid, sizeof(pgid));\r\npglen = ceph_decode_32(p);\r\nif (pglen) {\r\nceph_decode_need(p, end, pglen*sizeof(u32), bad);\r\npg = kmalloc(sizeof(*pg) + sizeof(u32)*pglen, GFP_NOFS);\r\nif (!pg) {\r\nerr = -ENOMEM;\r\ngoto bad;\r\n}\r\npg->pgid = pgid;\r\npg->len = pglen;\r\nfor (j = 0; j < pglen; j++)\r\npg->osds[j] = ceph_decode_32(p);\r\nerr = __insert_pg_mapping(pg, &map->pg_temp);\r\nif (err) {\r\nkfree(pg);\r\ngoto bad;\r\n}\r\ndout(" added pg_temp %llx len %d\n", *(u64 *)&pgid,\r\npglen);\r\n} else {\r\n__remove_pg_mapping(&map->pg_temp, pgid);\r\n}\r\n}\r\n*p = end;\r\nreturn map;\r\nbad:\r\npr_err("corrupt inc osdmap epoch %d off %d (%p of %p-%p)\n",\r\nepoch, (int)(*p - start), *p, start, end);\r\nprint_hex_dump(KERN_DEBUG, "osdmap: ",\r\nDUMP_PREFIX_OFFSET, 16, 1,\r\nstart, end - start, true);\r\nif (newcrush)\r\ncrush_destroy(newcrush);\r\nreturn ERR_PTR(err);\r\n}\r\nvoid ceph_calc_file_object_mapping(struct ceph_file_layout *layout,\r\nu64 off, u64 *plen,\r\nu64 *ono,\r\nu64 *oxoff, u64 *oxlen)\r\n{\r\nu32 osize = le32_to_cpu(layout->fl_object_size);\r\nu32 su = le32_to_cpu(layout->fl_stripe_unit);\r\nu32 sc = le32_to_cpu(layout->fl_stripe_count);\r\nu32 bl, stripeno, stripepos, objsetno;\r\nu32 su_per_object;\r\nu64 t, su_offset;\r\ndout("mapping %llu~%llu osize %u fl_su %u\n", off, *plen,\r\nosize, su);\r\nsu_per_object = osize / su;\r\ndout("osize %u / su %u = su_per_object %u\n", osize, su,\r\nsu_per_object);\r\nBUG_ON((su & ~PAGE_MASK) != 0);\r\nt = off;\r\ndo_div(t, su);\r\nbl = t;\r\ndout("off %llu / su %u = bl %u\n", off, su, bl);\r\nstripeno = bl / sc;\r\nstripepos = bl % sc;\r\nobjsetno = stripeno / su_per_object;\r\n*ono = objsetno * sc + stripepos;\r\ndout("objset %u * sc %u = ono %u\n", objsetno, sc, (unsigned)*ono);\r\nt = off;\r\nsu_offset = do_div(t, su);\r\n*oxoff = su_offset + (stripeno % su_per_object) * su;\r\n*oxlen = min_t(u64, *plen, su - su_offset);\r\n*plen = *oxlen;\r\ndout(" obj extent %llu~%llu\n", *oxoff, *oxlen);\r\n}\r\nint ceph_calc_object_layout(struct ceph_object_layout *ol,\r\nconst char *oid,\r\nstruct ceph_file_layout *fl,\r\nstruct ceph_osdmap *osdmap)\r\n{\r\nunsigned num, num_mask;\r\nstruct ceph_pg pgid;\r\ns32 preferred = (s32)le32_to_cpu(fl->fl_pg_preferred);\r\nint poolid = le32_to_cpu(fl->fl_pg_pool);\r\nstruct ceph_pg_pool_info *pool;\r\nunsigned ps;\r\nBUG_ON(!osdmap);\r\npool = __lookup_pg_pool(&osdmap->pg_pools, poolid);\r\nif (!pool)\r\nreturn -EIO;\r\nps = ceph_str_hash(pool->v.object_hash, oid, strlen(oid));\r\nif (preferred >= 0) {\r\nps += preferred;\r\nnum = le32_to_cpu(pool->v.lpg_num);\r\nnum_mask = pool->lpg_num_mask;\r\n} else {\r\nnum = le32_to_cpu(pool->v.pg_num);\r\nnum_mask = pool->pg_num_mask;\r\n}\r\npgid.ps = cpu_to_le16(ps);\r\npgid.preferred = cpu_to_le16(preferred);\r\npgid.pool = fl->fl_pg_pool;\r\nif (preferred >= 0)\r\ndout("calc_object_layout '%s' pgid %d.%xp%d\n", oid, poolid, ps,\r\n(int)preferred);\r\nelse\r\ndout("calc_object_layout '%s' pgid %d.%x\n", oid, poolid, ps);\r\nol->ol_pgid = pgid;\r\nol->ol_stripe_unit = fl->fl_object_stripe_unit;\r\nreturn 0;\r\n}\r\nstatic int *calc_pg_raw(struct ceph_osdmap *osdmap, struct ceph_pg pgid,\r\nint *osds, int *num)\r\n{\r\nstruct ceph_pg_mapping *pg;\r\nstruct ceph_pg_pool_info *pool;\r\nint ruleno;\r\nunsigned poolid, ps, pps, t;\r\nint preferred;\r\npoolid = le32_to_cpu(pgid.pool);\r\nps = le16_to_cpu(pgid.ps);\r\npreferred = (s16)le16_to_cpu(pgid.preferred);\r\npool = __lookup_pg_pool(&osdmap->pg_pools, poolid);\r\nif (!pool)\r\nreturn NULL;\r\nif (preferred >= 0)\r\nt = ceph_stable_mod(ps, le32_to_cpu(pool->v.lpg_num),\r\npool->lpgp_num_mask);\r\nelse\r\nt = ceph_stable_mod(ps, le32_to_cpu(pool->v.pg_num),\r\npool->pgp_num_mask);\r\npgid.ps = cpu_to_le16(t);\r\npg = __lookup_pg_mapping(&osdmap->pg_temp, pgid);\r\nif (pg) {\r\n*num = pg->len;\r\nreturn pg->osds;\r\n}\r\nruleno = crush_find_rule(osdmap->crush, pool->v.crush_ruleset,\r\npool->v.type, pool->v.size);\r\nif (ruleno < 0) {\r\npr_err("no crush rule pool %d ruleset %d type %d size %d\n",\r\npoolid, pool->v.crush_ruleset, pool->v.type,\r\npool->v.size);\r\nreturn NULL;\r\n}\r\nif (preferred >= osdmap->max_osd ||\r\npreferred >= osdmap->crush->max_devices)\r\npreferred = -1;\r\nif (preferred >= 0)\r\npps = ceph_stable_mod(ps,\r\nle32_to_cpu(pool->v.lpgp_num),\r\npool->lpgp_num_mask);\r\nelse\r\npps = ceph_stable_mod(ps,\r\nle32_to_cpu(pool->v.pgp_num),\r\npool->pgp_num_mask);\r\npps += poolid;\r\n*num = crush_do_rule(osdmap->crush, ruleno, pps, osds,\r\nmin_t(int, pool->v.size, *num),\r\npreferred, osdmap->osd_weight);\r\nreturn osds;\r\n}\r\nint ceph_calc_pg_acting(struct ceph_osdmap *osdmap, struct ceph_pg pgid,\r\nint *acting)\r\n{\r\nint rawosds[CEPH_PG_MAX_SIZE], *osds;\r\nint i, o, num = CEPH_PG_MAX_SIZE;\r\nosds = calc_pg_raw(osdmap, pgid, rawosds, &num);\r\nif (!osds)\r\nreturn -1;\r\no = 0;\r\nfor (i = 0; i < num; i++)\r\nif (ceph_osd_is_up(osdmap, osds[i]))\r\nacting[o++] = osds[i];\r\nreturn o;\r\n}\r\nint ceph_calc_pg_primary(struct ceph_osdmap *osdmap, struct ceph_pg pgid)\r\n{\r\nint rawosds[CEPH_PG_MAX_SIZE], *osds;\r\nint i, num = CEPH_PG_MAX_SIZE;\r\nosds = calc_pg_raw(osdmap, pgid, rawosds, &num);\r\nif (!osds)\r\nreturn -1;\r\nfor (i = 0; i < num; i++)\r\nif (ceph_osd_is_up(osdmap, osds[i]))\r\nreturn osds[i];\r\nreturn -1;\r\n}
