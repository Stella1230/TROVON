static int disabled_by_idle_boot_param(void)\r\n{\r\nreturn boot_option_idle_override == IDLE_POLL ||\r\nboot_option_idle_override == IDLE_FORCE_MWAIT ||\r\nboot_option_idle_override == IDLE_HALT;\r\n}\r\nstatic int set_max_cstate(const struct dmi_system_id *id)\r\n{\r\nif (max_cstate > ACPI_PROCESSOR_MAX_POWER)\r\nreturn 0;\r\nprintk(KERN_NOTICE PREFIX "%s detected - limiting to C%ld max_cstate."\r\n" Override with \"processor.max_cstate=%d\"\n", id->ident,\r\n(long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);\r\nmax_cstate = (long)id->driver_data;\r\nreturn 0;\r\n}\r\nstatic void acpi_safe_halt(void)\r\n{\r\ncurrent_thread_info()->status &= ~TS_POLLING;\r\nsmp_mb();\r\nif (!need_resched()) {\r\nsafe_halt();\r\nlocal_irq_disable();\r\n}\r\ncurrent_thread_info()->status |= TS_POLLING;\r\n}\r\nstatic void lapic_timer_check_state(int state, struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx)\r\n{\r\nstruct acpi_processor_power *pwr = &pr->power;\r\nu8 type = local_apic_timer_c2_ok ? ACPI_STATE_C3 : ACPI_STATE_C2;\r\nif (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))\r\nreturn;\r\nif (amd_e400_c1e_detected)\r\ntype = ACPI_STATE_C1;\r\nif (pwr->timer_broadcast_on_state < state)\r\nreturn;\r\nif (cx->type >= type)\r\npr->power.timer_broadcast_on_state = state;\r\n}\r\nstatic void __lapic_timer_propagate_broadcast(void *arg)\r\n{\r\nstruct acpi_processor *pr = (struct acpi_processor *) arg;\r\nunsigned long reason;\r\nreason = pr->power.timer_broadcast_on_state < INT_MAX ?\r\nCLOCK_EVT_NOTIFY_BROADCAST_ON : CLOCK_EVT_NOTIFY_BROADCAST_OFF;\r\nclockevents_notify(reason, &pr->id);\r\n}\r\nstatic void lapic_timer_propagate_broadcast(struct acpi_processor *pr)\r\n{\r\nsmp_call_function_single(pr->id, __lapic_timer_propagate_broadcast,\r\n(void *)pr, 1);\r\n}\r\nstatic void lapic_timer_state_broadcast(struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx,\r\nint broadcast)\r\n{\r\nint state = cx - pr->power.states;\r\nif (state >= pr->power.timer_broadcast_on_state) {\r\nunsigned long reason;\r\nreason = broadcast ? CLOCK_EVT_NOTIFY_BROADCAST_ENTER :\r\nCLOCK_EVT_NOTIFY_BROADCAST_EXIT;\r\nclockevents_notify(reason, &pr->id);\r\n}\r\n}\r\nstatic void lapic_timer_check_state(int state, struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cstate) { }\r\nstatic void lapic_timer_propagate_broadcast(struct acpi_processor *pr) { }\r\nstatic void lapic_timer_state_broadcast(struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx,\r\nint broadcast)\r\n{\r\n}\r\nstatic void acpi_idle_bm_rld_save(void)\r\n{\r\nacpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &saved_bm_rld);\r\n}\r\nstatic void acpi_idle_bm_rld_restore(void)\r\n{\r\nu32 resumed_bm_rld;\r\nacpi_read_bit_register(ACPI_BITREG_BUS_MASTER_RLD, &resumed_bm_rld);\r\nif (resumed_bm_rld != saved_bm_rld)\r\nacpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, saved_bm_rld);\r\n}\r\nint acpi_processor_suspend(struct acpi_device * device, pm_message_t state)\r\n{\r\nacpi_idle_bm_rld_save();\r\nreturn 0;\r\n}\r\nint acpi_processor_resume(struct acpi_device * device)\r\n{\r\nacpi_idle_bm_rld_restore();\r\nreturn 0;\r\n}\r\nstatic void tsc_check_state(int state)\r\n{\r\nswitch (boot_cpu_data.x86_vendor) {\r\ncase X86_VENDOR_AMD:\r\ncase X86_VENDOR_INTEL:\r\nif (boot_cpu_has(X86_FEATURE_NONSTOP_TSC))\r\nreturn;\r\ndefault:\r\nif (state > ACPI_STATE_C1)\r\nmark_tsc_unstable("TSC halts in idle");\r\n}\r\n}\r\nstatic void tsc_check_state(int state) { return; }\r\nstatic int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)\r\n{\r\nif (!pr)\r\nreturn -EINVAL;\r\nif (!pr->pblk)\r\nreturn -ENODEV;\r\npr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;\r\npr->power.states[ACPI_STATE_C3].type = ACPI_STATE_C3;\r\n#ifndef CONFIG_HOTPLUG_CPU\r\nif ((num_online_cpus() > 1) &&\r\n!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))\r\nreturn -ENODEV;\r\n#endif\r\npr->power.states[ACPI_STATE_C2].address = pr->pblk + 4;\r\npr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;\r\npr->power.states[ACPI_STATE_C2].latency = acpi_gbl_FADT.C2latency;\r\npr->power.states[ACPI_STATE_C3].latency = acpi_gbl_FADT.C3latency;\r\nif (acpi_gbl_FADT.C2latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C2 latency too large [%d]\n", acpi_gbl_FADT.C2latency));\r\npr->power.states[ACPI_STATE_C2].address = 0;\r\n}\r\nif (acpi_gbl_FADT.C3latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 latency too large [%d]\n", acpi_gbl_FADT.C3latency));\r\npr->power.states[ACPI_STATE_C3].address = 0;\r\n}\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"lvl2[0x%08x] lvl3[0x%08x]\n",\r\npr->power.states[ACPI_STATE_C2].address,\r\npr->power.states[ACPI_STATE_C3].address));\r\nreturn 0;\r\n}\r\nstatic int acpi_processor_get_power_info_default(struct acpi_processor *pr)\r\n{\r\nif (!pr->power.states[ACPI_STATE_C1].valid) {\r\npr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;\r\npr->power.states[ACPI_STATE_C1].valid = 1;\r\npr->power.states[ACPI_STATE_C1].entry_method = ACPI_CSTATE_HALT;\r\n}\r\npr->power.states[ACPI_STATE_C0].valid = 1;\r\nreturn 0;\r\n}\r\nstatic int acpi_processor_get_power_info_cst(struct acpi_processor *pr)\r\n{\r\nacpi_status status = 0;\r\nu64 count;\r\nint current_count;\r\nint i;\r\nstruct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };\r\nunion acpi_object *cst;\r\nif (nocst)\r\nreturn -ENODEV;\r\ncurrent_count = 0;\r\nstatus = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);\r\nif (ACPI_FAILURE(status)) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _CST, giving up\n"));\r\nreturn -ENODEV;\r\n}\r\ncst = buffer.pointer;\r\nif (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {\r\nprintk(KERN_ERR PREFIX "not enough elements in _CST\n");\r\nstatus = -EFAULT;\r\ngoto end;\r\n}\r\ncount = cst->package.elements[0].integer.value;\r\nif (count < 1 || count != cst->package.count - 1) {\r\nprintk(KERN_ERR PREFIX "count given by _CST is not valid\n");\r\nstatus = -EFAULT;\r\ngoto end;\r\n}\r\npr->flags.has_cst = 1;\r\nfor (i = 1; i <= count; i++) {\r\nunion acpi_object *element;\r\nunion acpi_object *obj;\r\nstruct acpi_power_register *reg;\r\nstruct acpi_processor_cx cx;\r\nmemset(&cx, 0, sizeof(cx));\r\nelement = &(cst->package.elements[i]);\r\nif (element->type != ACPI_TYPE_PACKAGE)\r\ncontinue;\r\nif (element->package.count != 4)\r\ncontinue;\r\nobj = &(element->package.elements[0]);\r\nif (obj->type != ACPI_TYPE_BUFFER)\r\ncontinue;\r\nreg = (struct acpi_power_register *)obj->buffer.pointer;\r\nif (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO &&\r\n(reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE))\r\ncontinue;\r\nobj = &(element->package.elements[1]);\r\nif (obj->type != ACPI_TYPE_INTEGER)\r\ncontinue;\r\ncx.type = obj->integer.value;\r\nif (i == 1 && cx.type != ACPI_STATE_C1)\r\ncurrent_count++;\r\ncx.address = reg->address;\r\ncx.index = current_count + 1;\r\ncx.entry_method = ACPI_CSTATE_SYSTEMIO;\r\nif (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) {\r\nif (acpi_processor_ffh_cstate_probe\r\n(pr->id, &cx, reg) == 0) {\r\ncx.entry_method = ACPI_CSTATE_FFH;\r\n} else if (cx.type == ACPI_STATE_C1) {\r\ncx.entry_method = ACPI_CSTATE_HALT;\r\nsnprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");\r\n} else {\r\ncontinue;\r\n}\r\nif (cx.type == ACPI_STATE_C1 &&\r\n(boot_option_idle_override == IDLE_NOMWAIT)) {\r\ncx.entry_method = ACPI_CSTATE_HALT;\r\nsnprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");\r\n}\r\n} else {\r\nsnprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI IOPORT 0x%x",\r\ncx.address);\r\n}\r\nif (cx.type == ACPI_STATE_C1) {\r\ncx.valid = 1;\r\n}\r\nobj = &(element->package.elements[2]);\r\nif (obj->type != ACPI_TYPE_INTEGER)\r\ncontinue;\r\ncx.latency = obj->integer.value;\r\nobj = &(element->package.elements[3]);\r\nif (obj->type != ACPI_TYPE_INTEGER)\r\ncontinue;\r\ncx.power = obj->integer.value;\r\ncurrent_count++;\r\nmemcpy(&(pr->power.states[current_count]), &cx, sizeof(cx));\r\nif (current_count >= (ACPI_PROCESSOR_MAX_POWER - 1)) {\r\nprintk(KERN_WARNING\r\n"Limiting number of power states to max (%d)\n",\r\nACPI_PROCESSOR_MAX_POWER);\r\nprintk(KERN_WARNING\r\n"Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");\r\nbreak;\r\n}\r\n}\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO, "Found %d power states\n",\r\ncurrent_count));\r\nif (current_count < 2)\r\nstatus = -EFAULT;\r\nend:\r\nkfree(buffer.pointer);\r\nreturn status;\r\n}\r\nstatic void acpi_processor_power_verify_c3(struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx)\r\n{\r\nstatic int bm_check_flag = -1;\r\nstatic int bm_control_flag = -1;\r\nif (!cx->address)\r\nreturn;\r\nelse if (errata.piix4.fdma) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 not supported on PIIX4 with Type-F DMA\n"));\r\nreturn;\r\n}\r\nif (bm_check_flag == -1) {\r\nacpi_processor_power_init_bm_check(&(pr->flags), pr->id);\r\nbm_check_flag = pr->flags.bm_check;\r\nbm_control_flag = pr->flags.bm_control;\r\n} else {\r\npr->flags.bm_check = bm_check_flag;\r\npr->flags.bm_control = bm_control_flag;\r\n}\r\nif (pr->flags.bm_check) {\r\nif (!pr->flags.bm_control) {\r\nif (pr->flags.has_cst != 1) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 support requires BM control\n"));\r\nreturn;\r\n} else {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 support without BM control\n"));\r\n}\r\n}\r\n} else {\r\nif (!(acpi_gbl_FADT.flags & ACPI_FADT_WBINVD)) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"Cache invalidation should work properly"\r\n" for C3 to be enabled on SMP systems\n"));\r\nreturn;\r\n}\r\n}\r\ncx->valid = 1;\r\ncx->latency_ticks = cx->latency;\r\nacpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, 1);\r\nreturn;\r\n}\r\nstatic int acpi_processor_power_verify(struct acpi_processor *pr)\r\n{\r\nunsigned int i;\r\nunsigned int working = 0;\r\npr->power.timer_broadcast_on_state = INT_MAX;\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\r\nstruct acpi_processor_cx *cx = &pr->power.states[i];\r\nswitch (cx->type) {\r\ncase ACPI_STATE_C1:\r\ncx->valid = 1;\r\nbreak;\r\ncase ACPI_STATE_C2:\r\nif (!cx->address)\r\nbreak;\r\ncx->valid = 1;\r\ncx->latency_ticks = cx->latency;\r\nbreak;\r\ncase ACPI_STATE_C3:\r\nacpi_processor_power_verify_c3(pr, cx);\r\nbreak;\r\n}\r\nif (!cx->valid)\r\ncontinue;\r\nlapic_timer_check_state(i, pr, cx);\r\ntsc_check_state(cx->type);\r\nworking++;\r\n}\r\nlapic_timer_propagate_broadcast(pr);\r\nreturn (working);\r\n}\r\nstatic int acpi_processor_get_power_info(struct acpi_processor *pr)\r\n{\r\nunsigned int i;\r\nint result;\r\nmemset(pr->power.states, 0, sizeof(pr->power.states));\r\nresult = acpi_processor_get_power_info_cst(pr);\r\nif (result == -ENODEV)\r\nresult = acpi_processor_get_power_info_fadt(pr);\r\nif (result)\r\nreturn result;\r\nacpi_processor_get_power_info_default(pr);\r\npr->power.count = acpi_processor_power_verify(pr);\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {\r\nif (pr->power.states[i].valid) {\r\npr->power.count = i;\r\nif (pr->power.states[i].type >= ACPI_STATE_C2)\r\npr->flags.power = 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int acpi_idle_bm_check(void)\r\n{\r\nu32 bm_status = 0;\r\nif (bm_check_disable)\r\nreturn 0;\r\nacpi_read_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);\r\nif (bm_status)\r\nacpi_write_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);\r\nelse if (errata.piix4.bmisx) {\r\nif ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)\r\n|| (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))\r\nbm_status = 1;\r\n}\r\nreturn bm_status;\r\n}\r\nstatic inline void acpi_idle_do_entry(struct acpi_processor_cx *cx)\r\n{\r\nstop_critical_timings();\r\nif (cx->entry_method == ACPI_CSTATE_FFH) {\r\nacpi_processor_ffh_cstate_enter(cx);\r\n} else if (cx->entry_method == ACPI_CSTATE_HALT) {\r\nacpi_safe_halt();\r\n} else {\r\ninb(cx->address);\r\ninl(acpi_gbl_FADT.xpm_timer_block.address);\r\n}\r\nstart_critical_timings();\r\n}\r\nstatic int acpi_idle_enter_c1(struct cpuidle_device *dev,\r\nstruct cpuidle_driver *drv, int index)\r\n{\r\nktime_t kt1, kt2;\r\ns64 idle_time;\r\nstruct acpi_processor *pr;\r\nstruct cpuidle_state_usage *state_usage = &dev->states_usage[index];\r\nstruct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);\r\npr = __this_cpu_read(processors);\r\ndev->last_residency = 0;\r\nif (unlikely(!pr))\r\nreturn -EINVAL;\r\nlocal_irq_disable();\r\nlapic_timer_state_broadcast(pr, cx, 1);\r\nkt1 = ktime_get_real();\r\nacpi_idle_do_entry(cx);\r\nkt2 = ktime_get_real();\r\nidle_time = ktime_to_us(ktime_sub(kt2, kt1));\r\ndev->last_residency = (int)idle_time;\r\nlocal_irq_enable();\r\ncx->usage++;\r\nlapic_timer_state_broadcast(pr, cx, 0);\r\nreturn index;\r\n}\r\nstatic int acpi_idle_enter_simple(struct cpuidle_device *dev,\r\nstruct cpuidle_driver *drv, int index)\r\n{\r\nstruct acpi_processor *pr;\r\nstruct cpuidle_state_usage *state_usage = &dev->states_usage[index];\r\nstruct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);\r\nktime_t kt1, kt2;\r\ns64 idle_time_ns;\r\ns64 idle_time;\r\npr = __this_cpu_read(processors);\r\ndev->last_residency = 0;\r\nif (unlikely(!pr))\r\nreturn -EINVAL;\r\nlocal_irq_disable();\r\nif (cx->entry_method != ACPI_CSTATE_FFH) {\r\ncurrent_thread_info()->status &= ~TS_POLLING;\r\nsmp_mb();\r\nif (unlikely(need_resched())) {\r\ncurrent_thread_info()->status |= TS_POLLING;\r\nlocal_irq_enable();\r\nreturn -EINVAL;\r\n}\r\n}\r\nlapic_timer_state_broadcast(pr, cx, 1);\r\nif (cx->type == ACPI_STATE_C3)\r\nACPI_FLUSH_CPU_CACHE();\r\nkt1 = ktime_get_real();\r\nsched_clock_idle_sleep_event();\r\nacpi_idle_do_entry(cx);\r\nkt2 = ktime_get_real();\r\nidle_time_ns = ktime_to_ns(ktime_sub(kt2, kt1));\r\nidle_time = idle_time_ns;\r\ndo_div(idle_time, NSEC_PER_USEC);\r\ndev->last_residency = (int)idle_time;\r\nsched_clock_idle_wakeup_event(idle_time_ns);\r\nlocal_irq_enable();\r\nif (cx->entry_method != ACPI_CSTATE_FFH)\r\ncurrent_thread_info()->status |= TS_POLLING;\r\ncx->usage++;\r\nlapic_timer_state_broadcast(pr, cx, 0);\r\ncx->time += idle_time;\r\nreturn index;\r\n}\r\nstatic int acpi_idle_enter_bm(struct cpuidle_device *dev,\r\nstruct cpuidle_driver *drv, int index)\r\n{\r\nstruct acpi_processor *pr;\r\nstruct cpuidle_state_usage *state_usage = &dev->states_usage[index];\r\nstruct acpi_processor_cx *cx = cpuidle_get_statedata(state_usage);\r\nktime_t kt1, kt2;\r\ns64 idle_time_ns;\r\ns64 idle_time;\r\npr = __this_cpu_read(processors);\r\ndev->last_residency = 0;\r\nif (unlikely(!pr))\r\nreturn -EINVAL;\r\nif (!cx->bm_sts_skip && acpi_idle_bm_check()) {\r\nif (drv->safe_state_index >= 0) {\r\nreturn drv->states[drv->safe_state_index].enter(dev,\r\ndrv, drv->safe_state_index);\r\n} else {\r\nlocal_irq_disable();\r\nacpi_safe_halt();\r\nlocal_irq_enable();\r\nreturn -EINVAL;\r\n}\r\n}\r\nlocal_irq_disable();\r\nif (cx->entry_method != ACPI_CSTATE_FFH) {\r\ncurrent_thread_info()->status &= ~TS_POLLING;\r\nsmp_mb();\r\nif (unlikely(need_resched())) {\r\ncurrent_thread_info()->status |= TS_POLLING;\r\nlocal_irq_enable();\r\nreturn -EINVAL;\r\n}\r\n}\r\nacpi_unlazy_tlb(smp_processor_id());\r\nsched_clock_idle_sleep_event();\r\nlapic_timer_state_broadcast(pr, cx, 1);\r\nkt1 = ktime_get_real();\r\nif (pr->flags.bm_check && pr->flags.bm_control) {\r\nraw_spin_lock(&c3_lock);\r\nc3_cpu_count++;\r\nif (c3_cpu_count == num_online_cpus())\r\nacpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 1);\r\nraw_spin_unlock(&c3_lock);\r\n} else if (!pr->flags.bm_check) {\r\nACPI_FLUSH_CPU_CACHE();\r\n}\r\nacpi_idle_do_entry(cx);\r\nif (pr->flags.bm_check && pr->flags.bm_control) {\r\nraw_spin_lock(&c3_lock);\r\nacpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 0);\r\nc3_cpu_count--;\r\nraw_spin_unlock(&c3_lock);\r\n}\r\nkt2 = ktime_get_real();\r\nidle_time_ns = ktime_to_ns(ktime_sub(kt2, kt1));\r\nidle_time = idle_time_ns;\r\ndo_div(idle_time, NSEC_PER_USEC);\r\ndev->last_residency = (int)idle_time;\r\nsched_clock_idle_wakeup_event(idle_time_ns);\r\nlocal_irq_enable();\r\nif (cx->entry_method != ACPI_CSTATE_FFH)\r\ncurrent_thread_info()->status |= TS_POLLING;\r\ncx->usage++;\r\nlapic_timer_state_broadcast(pr, cx, 0);\r\ncx->time += idle_time;\r\nreturn index;\r\n}\r\nstatic int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr)\r\n{\r\nint i, count = CPUIDLE_DRIVER_STATE_START;\r\nstruct acpi_processor_cx *cx;\r\nstruct cpuidle_state_usage *state_usage;\r\nstruct cpuidle_device *dev = &pr->power.dev;\r\nif (!pr->flags.power_setup_done)\r\nreturn -EINVAL;\r\nif (pr->flags.power == 0) {\r\nreturn -EINVAL;\r\n}\r\ndev->cpu = pr->id;\r\nif (max_cstate == 0)\r\nmax_cstate = 1;\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\r\ncx = &pr->power.states[i];\r\nstate_usage = &dev->states_usage[count];\r\nif (!cx->valid)\r\ncontinue;\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nif ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&\r\n!pr->flags.has_cst &&\r\n!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))\r\ncontinue;\r\n#endif\r\ncpuidle_set_statedata(state_usage, cx);\r\ncount++;\r\nif (count == CPUIDLE_STATE_MAX)\r\nbreak;\r\n}\r\ndev->state_count = count;\r\nif (!count)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)\r\n{\r\nint i, count = CPUIDLE_DRIVER_STATE_START;\r\nstruct acpi_processor_cx *cx;\r\nstruct cpuidle_state *state;\r\nstruct cpuidle_driver *drv = &acpi_idle_driver;\r\nif (!pr->flags.power_setup_done)\r\nreturn -EINVAL;\r\nif (pr->flags.power == 0)\r\nreturn -EINVAL;\r\ndrv->safe_state_index = -1;\r\nfor (i = 0; i < CPUIDLE_STATE_MAX; i++) {\r\ndrv->states[i].name[0] = '\0';\r\ndrv->states[i].desc[0] = '\0';\r\n}\r\nif (max_cstate == 0)\r\nmax_cstate = 1;\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\r\ncx = &pr->power.states[i];\r\nif (!cx->valid)\r\ncontinue;\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nif ((cx->type != ACPI_STATE_C1) && (num_online_cpus() > 1) &&\r\n!pr->flags.has_cst &&\r\n!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))\r\ncontinue;\r\n#endif\r\nstate = &drv->states[count];\r\nsnprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);\r\nstrncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);\r\nstate->exit_latency = cx->latency;\r\nstate->target_residency = cx->latency * latency_factor;\r\nstate->flags = 0;\r\nswitch (cx->type) {\r\ncase ACPI_STATE_C1:\r\nif (cx->entry_method == ACPI_CSTATE_FFH)\r\nstate->flags |= CPUIDLE_FLAG_TIME_VALID;\r\nstate->enter = acpi_idle_enter_c1;\r\ndrv->safe_state_index = count;\r\nbreak;\r\ncase ACPI_STATE_C2:\r\nstate->flags |= CPUIDLE_FLAG_TIME_VALID;\r\nstate->enter = acpi_idle_enter_simple;\r\ndrv->safe_state_index = count;\r\nbreak;\r\ncase ACPI_STATE_C3:\r\nstate->flags |= CPUIDLE_FLAG_TIME_VALID;\r\nstate->enter = pr->flags.bm_check ?\r\nacpi_idle_enter_bm :\r\nacpi_idle_enter_simple;\r\nbreak;\r\n}\r\ncount++;\r\nif (count == CPUIDLE_STATE_MAX)\r\nbreak;\r\n}\r\ndrv->state_count = count;\r\nif (!count)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nint acpi_processor_hotplug(struct acpi_processor *pr)\r\n{\r\nint ret = 0;\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (!pr)\r\nreturn -EINVAL;\r\nif (nocst) {\r\nreturn -ENODEV;\r\n}\r\nif (!pr->flags.power_setup_done)\r\nreturn -ENODEV;\r\ncpuidle_pause_and_lock();\r\ncpuidle_disable_device(&pr->power.dev);\r\nacpi_processor_get_power_info(pr);\r\nif (pr->flags.power) {\r\nacpi_processor_setup_cpuidle_cx(pr);\r\nret = cpuidle_enable_device(&pr->power.dev);\r\n}\r\ncpuidle_resume_and_unlock();\r\nreturn ret;\r\n}\r\nint acpi_processor_cst_has_changed(struct acpi_processor *pr)\r\n{\r\nint cpu;\r\nstruct acpi_processor *_pr;\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (!pr)\r\nreturn -EINVAL;\r\nif (nocst)\r\nreturn -ENODEV;\r\nif (!pr->flags.power_setup_done)\r\nreturn -ENODEV;\r\nif (smp_processor_id() == 0 &&\r\ncpuidle_get_driver() == &acpi_idle_driver) {\r\ncpuidle_pause_and_lock();\r\nget_online_cpus();\r\nfor_each_online_cpu(cpu) {\r\n_pr = per_cpu(processors, cpu);\r\nif (!_pr || !_pr->flags.power_setup_done)\r\ncontinue;\r\ncpuidle_disable_device(&_pr->power.dev);\r\n}\r\nacpi_processor_setup_cpuidle_states(pr);\r\nfor_each_online_cpu(cpu) {\r\n_pr = per_cpu(processors, cpu);\r\nif (!_pr || !_pr->flags.power_setup_done)\r\ncontinue;\r\nacpi_processor_get_power_info(_pr);\r\nif (_pr->flags.power) {\r\nacpi_processor_setup_cpuidle_cx(_pr);\r\ncpuidle_enable_device(&_pr->power.dev);\r\n}\r\n}\r\nput_online_cpus();\r\ncpuidle_resume_and_unlock();\r\n}\r\nreturn 0;\r\n}\r\nint __cpuinit acpi_processor_power_init(struct acpi_processor *pr,\r\nstruct acpi_device *device)\r\n{\r\nacpi_status status = 0;\r\nint retval;\r\nstatic int first_run;\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (!first_run) {\r\ndmi_check_system(processor_power_dmi_table);\r\nmax_cstate = acpi_processor_cstate_check(max_cstate);\r\nif (max_cstate < ACPI_C_STATES_MAX)\r\nprintk(KERN_NOTICE\r\n"ACPI: processor limited to max C-state %d\n",\r\nmax_cstate);\r\nfirst_run++;\r\n}\r\nif (!pr)\r\nreturn -EINVAL;\r\nif (acpi_gbl_FADT.cst_control && !nocst) {\r\nstatus =\r\nacpi_os_write_port(acpi_gbl_FADT.smi_command, acpi_gbl_FADT.cst_control, 8);\r\nif (ACPI_FAILURE(status)) {\r\nACPI_EXCEPTION((AE_INFO, status,\r\n"Notifying BIOS of _CST ability failed"));\r\n}\r\n}\r\nacpi_processor_get_power_info(pr);\r\npr->flags.power_setup_done = 1;\r\nif (pr->flags.power) {\r\nif (!acpi_processor_registered) {\r\nacpi_processor_setup_cpuidle_states(pr);\r\nretval = cpuidle_register_driver(&acpi_idle_driver);\r\nif (retval)\r\nreturn retval;\r\nprintk(KERN_DEBUG "ACPI: %s registered with cpuidle\n",\r\nacpi_idle_driver.name);\r\n}\r\nacpi_processor_setup_cpuidle_cx(pr);\r\nretval = cpuidle_register_device(&pr->power.dev);\r\nif (retval) {\r\nif (acpi_processor_registered == 0)\r\ncpuidle_unregister_driver(&acpi_idle_driver);\r\nreturn retval;\r\n}\r\nacpi_processor_registered++;\r\n}\r\nreturn 0;\r\n}\r\nint acpi_processor_power_exit(struct acpi_processor *pr,\r\nstruct acpi_device *device)\r\n{\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (pr->flags.power) {\r\ncpuidle_unregister_device(&pr->power.dev);\r\nacpi_processor_registered--;\r\nif (acpi_processor_registered == 0)\r\ncpuidle_unregister_driver(&acpi_idle_driver);\r\n}\r\npr->flags.power_setup_done = 0;\r\nreturn 0;\r\n}
