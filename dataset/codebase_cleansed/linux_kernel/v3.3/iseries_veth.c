static inline void veth_stack_push(struct veth_lpar_connection *cnx,\r\nstruct veth_msg *msg)\r\n{\r\nmsg->next = cnx->msg_stack_head;\r\ncnx->msg_stack_head = msg;\r\n}\r\nstatic inline struct veth_msg *veth_stack_pop(struct veth_lpar_connection *cnx)\r\n{\r\nstruct veth_msg *msg;\r\nmsg = cnx->msg_stack_head;\r\nif (msg)\r\ncnx->msg_stack_head = cnx->msg_stack_head->next;\r\nreturn msg;\r\n}\r\nstatic inline int veth_stack_is_empty(struct veth_lpar_connection *cnx)\r\n{\r\nreturn cnx->msg_stack_head == NULL;\r\n}\r\nstatic inline HvLpEvent_Rc\r\nveth_signalevent(struct veth_lpar_connection *cnx, u16 subtype,\r\nHvLpEvent_AckInd ackind, HvLpEvent_AckType acktype,\r\nu64 token,\r\nu64 data1, u64 data2, u64 data3, u64 data4, u64 data5)\r\n{\r\nreturn HvCallEvent_signalLpEventFast(cnx->remote_lp,\r\nHvLpEvent_Type_VirtualLan,\r\nsubtype, ackind, acktype,\r\ncnx->src_inst,\r\ncnx->dst_inst,\r\ntoken, data1, data2, data3,\r\ndata4, data5);\r\n}\r\nstatic inline HvLpEvent_Rc veth_signaldata(struct veth_lpar_connection *cnx,\r\nu16 subtype, u64 token, void *data)\r\n{\r\nu64 *p = (u64 *) data;\r\nreturn veth_signalevent(cnx, subtype, HvLpEvent_AckInd_NoAck,\r\nHvLpEvent_AckType_ImmediateAck,\r\ntoken, p[0], p[1], p[2], p[3], p[4]);\r\n}\r\nstatic void veth_complete_allocation(void *parm, int number)\r\n{\r\nstruct veth_allocation *vc = (struct veth_allocation *)parm;\r\nvc->num = number;\r\ncomplete(&vc->c);\r\n}\r\nstatic int veth_allocate_events(HvLpIndex rlp, int number)\r\n{\r\nstruct veth_allocation vc =\r\n{ COMPLETION_INITIALIZER_ONSTACK(vc.c), 0 };\r\nmf_allocate_lp_events(rlp, HvLpEvent_Type_VirtualLan,\r\nsizeof(struct veth_lpevent), number,\r\n&veth_complete_allocation, &vc);\r\nwait_for_completion(&vc.c);\r\nreturn vc.num;\r\n}\r\nstatic ssize_t veth_cnx_attribute_show(struct kobject *kobj,\r\nstruct attribute *attr, char *buf)\r\n{\r\nstruct veth_cnx_attribute *cnx_attr;\r\nstruct veth_lpar_connection *cnx;\r\ncnx_attr = container_of(attr, struct veth_cnx_attribute, attr);\r\ncnx = container_of(kobj, struct veth_lpar_connection, kobject);\r\nif (!cnx_attr->show)\r\nreturn -EIO;\r\nreturn cnx_attr->show(cnx, buf);\r\n}\r\nstatic ssize_t veth_port_attribute_show(struct kobject *kobj,\r\nstruct attribute *attr, char *buf)\r\n{\r\nstruct veth_port_attribute *port_attr;\r\nstruct veth_port *port;\r\nport_attr = container_of(attr, struct veth_port_attribute, attr);\r\nport = container_of(kobj, struct veth_port, kobject);\r\nif (!port_attr->show)\r\nreturn -EIO;\r\nreturn port_attr->show(port, buf);\r\n}\r\nstatic inline void veth_kick_statemachine(struct veth_lpar_connection *cnx)\r\n{\r\nschedule_delayed_work(&cnx->statemachine_wq, 0);\r\n}\r\nstatic void veth_take_cap(struct veth_lpar_connection *cnx,\r\nstruct veth_lpevent *event)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cnx->lock, flags);\r\ncnx->dst_inst =\r\nHvCallEvent_getTargetLpInstanceId(cnx->remote_lp,\r\nHvLpEvent_Type_VirtualLan);\r\nif (cnx->state & VETH_STATE_GOTCAPS) {\r\nveth_error("Received a second capabilities from LPAR %d.\n",\r\ncnx->remote_lp);\r\nevent->base_event.xRc = HvLpEvent_Rc_BufferNotAvailable;\r\nHvCallEvent_ackLpEvent((struct HvLpEvent *) event);\r\n} else {\r\nmemcpy(&cnx->cap_event, event, sizeof(cnx->cap_event));\r\ncnx->state |= VETH_STATE_GOTCAPS;\r\nveth_kick_statemachine(cnx);\r\n}\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\n}\r\nstatic void veth_take_cap_ack(struct veth_lpar_connection *cnx,\r\nstruct veth_lpevent *event)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cnx->lock, flags);\r\nif (cnx->state & VETH_STATE_GOTCAPACK) {\r\nveth_error("Received a second capabilities ack from LPAR %d.\n",\r\ncnx->remote_lp);\r\n} else {\r\nmemcpy(&cnx->cap_ack_event, event,\r\nsizeof(cnx->cap_ack_event));\r\ncnx->state |= VETH_STATE_GOTCAPACK;\r\nveth_kick_statemachine(cnx);\r\n}\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\n}\r\nstatic void veth_take_monitor_ack(struct veth_lpar_connection *cnx,\r\nstruct veth_lpevent *event)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cnx->lock, flags);\r\nveth_debug("cnx %d: lost connection.\n", cnx->remote_lp);\r\nif (! (cnx->state & VETH_STATE_SHUTDOWN)) {\r\ncnx->state |= VETH_STATE_RESET;\r\nveth_kick_statemachine(cnx);\r\n}\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\n}\r\nstatic void veth_handle_ack(struct veth_lpevent *event)\r\n{\r\nHvLpIndex rlp = event->base_event.xTargetLp;\r\nstruct veth_lpar_connection *cnx = veth_cnx[rlp];\r\nBUG_ON(! cnx);\r\nswitch (event->base_event.xSubtype) {\r\ncase VETH_EVENT_CAP:\r\nveth_take_cap_ack(cnx, event);\r\nbreak;\r\ncase VETH_EVENT_MONITOR:\r\nveth_take_monitor_ack(cnx, event);\r\nbreak;\r\ndefault:\r\nveth_error("Unknown ack type %d from LPAR %d.\n",\r\nevent->base_event.xSubtype, rlp);\r\n}\r\n}\r\nstatic void veth_handle_int(struct veth_lpevent *event)\r\n{\r\nHvLpIndex rlp = event->base_event.xSourceLp;\r\nstruct veth_lpar_connection *cnx = veth_cnx[rlp];\r\nunsigned long flags;\r\nint i, acked = 0;\r\nBUG_ON(! cnx);\r\nswitch (event->base_event.xSubtype) {\r\ncase VETH_EVENT_CAP:\r\nveth_take_cap(cnx, event);\r\nbreak;\r\ncase VETH_EVENT_MONITOR:\r\nbreak;\r\ncase VETH_EVENT_FRAMES_ACK:\r\nspin_lock_irqsave(&cnx->lock, flags);\r\nfor (i = 0; i < VETH_MAX_ACKS_PER_MSG; ++i) {\r\nu16 msgnum = event->u.frames_ack_data.token[i];\r\nif (msgnum < VETH_NUMBUFFERS) {\r\nveth_recycle_msg(cnx, cnx->msgs + msgnum);\r\ncnx->outstanding_tx--;\r\nacked++;\r\n}\r\n}\r\nif (acked > 0) {\r\ncnx->last_contact = jiffies;\r\nveth_wake_queues(cnx);\r\n}\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\nbreak;\r\ncase VETH_EVENT_FRAMES:\r\nveth_receive(cnx, event);\r\nbreak;\r\ndefault:\r\nveth_error("Unknown interrupt type %d from LPAR %d.\n",\r\nevent->base_event.xSubtype, rlp);\r\n}\r\n}\r\nstatic void veth_handle_event(struct HvLpEvent *event)\r\n{\r\nstruct veth_lpevent *veth_event = (struct veth_lpevent *)event;\r\nif (hvlpevent_is_ack(event))\r\nveth_handle_ack(veth_event);\r\nelse\r\nveth_handle_int(veth_event);\r\n}\r\nstatic int veth_process_caps(struct veth_lpar_connection *cnx)\r\n{\r\nstruct veth_cap_data *remote_caps = &cnx->remote_caps;\r\nint num_acks_needed;\r\ncnx->ack_timeout = remote_caps->ack_timeout * HZ / 1000000;\r\nif ( (remote_caps->num_buffers == 0) ||\r\n(remote_caps->ack_threshold > VETH_MAX_ACKS_PER_MSG) ||\r\n(remote_caps->ack_threshold == 0) ||\r\n(cnx->ack_timeout == 0) ) {\r\nveth_error("Received incompatible capabilities from LPAR %d.\n",\r\ncnx->remote_lp);\r\nreturn HvLpEvent_Rc_InvalidSubtypeData;\r\n}\r\nnum_acks_needed = (remote_caps->num_buffers\r\n/ remote_caps->ack_threshold) + 1;\r\nif (cnx->num_ack_events < num_acks_needed) {\r\nint num;\r\nnum = veth_allocate_events(cnx->remote_lp,\r\nnum_acks_needed-cnx->num_ack_events);\r\nif (num > 0)\r\ncnx->num_ack_events += num;\r\nif (cnx->num_ack_events < num_acks_needed) {\r\nveth_error("Couldn't allocate enough ack events "\r\n"for LPAR %d.\n", cnx->remote_lp);\r\nreturn HvLpEvent_Rc_BufferNotAvailable;\r\n}\r\n}\r\nreturn HvLpEvent_Rc_Good;\r\n}\r\nstatic void veth_statemachine(struct work_struct *work)\r\n{\r\nstruct veth_lpar_connection *cnx =\r\ncontainer_of(work, struct veth_lpar_connection,\r\nstatemachine_wq.work);\r\nint rlp = cnx->remote_lp;\r\nint rc;\r\nspin_lock_irq(&cnx->lock);\r\nrestart:\r\nif (cnx->state & VETH_STATE_RESET) {\r\nif (cnx->state & VETH_STATE_OPEN)\r\nHvCallEvent_closeLpEventPath(cnx->remote_lp,\r\nHvLpEvent_Type_VirtualLan);\r\nmemset(&cnx->pending_acks, 0xff, sizeof (cnx->pending_acks));\r\ncnx->num_pending_acks = 0;\r\ncnx->state &= ~(VETH_STATE_RESET | VETH_STATE_SENTMON\r\n| VETH_STATE_OPEN | VETH_STATE_SENTCAPS\r\n| VETH_STATE_GOTCAPACK | VETH_STATE_GOTCAPS\r\n| VETH_STATE_SENTCAPACK | VETH_STATE_READY);\r\nif (cnx->msgs) {\r\nint i;\r\nfor (i = 0; i < VETH_NUMBUFFERS; ++i)\r\nveth_recycle_msg(cnx, cnx->msgs + i);\r\n}\r\ncnx->outstanding_tx = 0;\r\nveth_wake_queues(cnx);\r\nspin_unlock_irq(&cnx->lock);\r\ndel_timer_sync(&cnx->ack_timer);\r\ndel_timer_sync(&cnx->reset_timer);\r\nspin_lock_irq(&cnx->lock);\r\nif (cnx->state & VETH_STATE_RESET)\r\ngoto restart;\r\nif (! (cnx->state & VETH_STATE_SHUTDOWN)) {\r\nschedule_delayed_work(&cnx->statemachine_wq, 5 * HZ);\r\ngoto out;\r\n}\r\n}\r\nif (cnx->state & VETH_STATE_SHUTDOWN)\r\ngoto out;\r\nif ( !(cnx->state & VETH_STATE_OPEN) ) {\r\nif (! cnx->msgs || (cnx->num_events < (2 + VETH_NUMBUFFERS)) )\r\ngoto cant_cope;\r\nHvCallEvent_openLpEventPath(rlp, HvLpEvent_Type_VirtualLan);\r\ncnx->src_inst =\r\nHvCallEvent_getSourceLpInstanceId(rlp,\r\nHvLpEvent_Type_VirtualLan);\r\ncnx->dst_inst =\r\nHvCallEvent_getTargetLpInstanceId(rlp,\r\nHvLpEvent_Type_VirtualLan);\r\ncnx->state |= VETH_STATE_OPEN;\r\n}\r\nif ( (cnx->state & VETH_STATE_OPEN) &&\r\n!(cnx->state & VETH_STATE_SENTMON) ) {\r\nrc = veth_signalevent(cnx, VETH_EVENT_MONITOR,\r\nHvLpEvent_AckInd_DoAck,\r\nHvLpEvent_AckType_DeferredAck,\r\n0, 0, 0, 0, 0, 0);\r\nif (rc == HvLpEvent_Rc_Good) {\r\ncnx->state |= VETH_STATE_SENTMON;\r\n} else {\r\nif ( (rc != HvLpEvent_Rc_PartitionDead) &&\r\n(rc != HvLpEvent_Rc_PathClosed) )\r\nveth_error("Error sending monitor to LPAR %d, "\r\n"rc = %d\n", rlp, rc);\r\ngoto out;\r\n}\r\n}\r\nif ( (cnx->state & VETH_STATE_OPEN) &&\r\n!(cnx->state & VETH_STATE_SENTCAPS)) {\r\nu64 *rawcap = (u64 *)&cnx->local_caps;\r\nrc = veth_signalevent(cnx, VETH_EVENT_CAP,\r\nHvLpEvent_AckInd_DoAck,\r\nHvLpEvent_AckType_ImmediateAck,\r\n0, rawcap[0], rawcap[1], rawcap[2],\r\nrawcap[3], rawcap[4]);\r\nif (rc == HvLpEvent_Rc_Good) {\r\ncnx->state |= VETH_STATE_SENTCAPS;\r\n} else {\r\nif ( (rc != HvLpEvent_Rc_PartitionDead) &&\r\n(rc != HvLpEvent_Rc_PathClosed) )\r\nveth_error("Error sending caps to LPAR %d, "\r\n"rc = %d\n", rlp, rc);\r\ngoto out;\r\n}\r\n}\r\nif ((cnx->state & VETH_STATE_GOTCAPS) &&\r\n!(cnx->state & VETH_STATE_SENTCAPACK)) {\r\nstruct veth_cap_data *remote_caps = &cnx->remote_caps;\r\nmemcpy(remote_caps, &cnx->cap_event.u.caps_data,\r\nsizeof(*remote_caps));\r\nspin_unlock_irq(&cnx->lock);\r\nrc = veth_process_caps(cnx);\r\nspin_lock_irq(&cnx->lock);\r\nif (cnx->state & (VETH_STATE_RESET|VETH_STATE_SHUTDOWN))\r\ngoto restart;\r\ncnx->cap_event.base_event.xRc = rc;\r\nHvCallEvent_ackLpEvent((struct HvLpEvent *)&cnx->cap_event);\r\nif (rc == HvLpEvent_Rc_Good)\r\ncnx->state |= VETH_STATE_SENTCAPACK;\r\nelse\r\ngoto cant_cope;\r\n}\r\nif ((cnx->state & VETH_STATE_GOTCAPACK) &&\r\n(cnx->state & VETH_STATE_GOTCAPS) &&\r\n!(cnx->state & VETH_STATE_READY)) {\r\nif (cnx->cap_ack_event.base_event.xRc == HvLpEvent_Rc_Good) {\r\ncnx->ack_timer.expires = jiffies + cnx->ack_timeout;\r\nadd_timer(&cnx->ack_timer);\r\ncnx->state |= VETH_STATE_READY;\r\n} else {\r\nveth_error("Caps rejected by LPAR %d, rc = %d\n",\r\nrlp, cnx->cap_ack_event.base_event.xRc);\r\ngoto cant_cope;\r\n}\r\n}\r\nout:\r\nspin_unlock_irq(&cnx->lock);\r\nreturn;\r\ncant_cope:\r\nveth_error("Unrecoverable error on connection to LPAR %d, shutting down"\r\n" (state = 0x%04lx)\n", rlp, cnx->state);\r\ncnx->state |= VETH_STATE_SHUTDOWN;\r\nspin_unlock_irq(&cnx->lock);\r\n}\r\nstatic int veth_init_connection(u8 rlp)\r\n{\r\nstruct veth_lpar_connection *cnx;\r\nstruct veth_msg *msgs;\r\nint i;\r\nif ( (rlp == this_lp) ||\r\n! HvLpConfig_doLpsCommunicateOnVirtualLan(this_lp, rlp) )\r\nreturn 0;\r\ncnx = kzalloc(sizeof(*cnx), GFP_KERNEL);\r\nif (! cnx)\r\nreturn -ENOMEM;\r\ncnx->remote_lp = rlp;\r\nspin_lock_init(&cnx->lock);\r\nINIT_DELAYED_WORK(&cnx->statemachine_wq, veth_statemachine);\r\ninit_timer(&cnx->ack_timer);\r\ncnx->ack_timer.function = veth_timed_ack;\r\ncnx->ack_timer.data = (unsigned long) cnx;\r\ninit_timer(&cnx->reset_timer);\r\ncnx->reset_timer.function = veth_timed_reset;\r\ncnx->reset_timer.data = (unsigned long) cnx;\r\ncnx->reset_timeout = 5 * HZ * (VETH_ACKTIMEOUT / 1000000);\r\nmemset(&cnx->pending_acks, 0xff, sizeof (cnx->pending_acks));\r\nveth_cnx[rlp] = cnx;\r\nkobject_init(&cnx->kobject, &veth_lpar_connection_ktype);\r\nmsgs = kcalloc(VETH_NUMBUFFERS, sizeof(struct veth_msg), GFP_KERNEL);\r\nif (! msgs) {\r\nveth_error("Can't allocate buffers for LPAR %d.\n", rlp);\r\nreturn -ENOMEM;\r\n}\r\ncnx->msgs = msgs;\r\nfor (i = 0; i < VETH_NUMBUFFERS; i++) {\r\nmsgs[i].token = i;\r\nveth_stack_push(cnx, msgs + i);\r\n}\r\ncnx->num_events = veth_allocate_events(rlp, 2 + VETH_NUMBUFFERS);\r\nif (cnx->num_events < (2 + VETH_NUMBUFFERS)) {\r\nveth_error("Can't allocate enough events for LPAR %d.\n", rlp);\r\nreturn -ENOMEM;\r\n}\r\ncnx->local_caps.num_buffers = VETH_NUMBUFFERS;\r\ncnx->local_caps.ack_threshold = ACK_THRESHOLD;\r\ncnx->local_caps.ack_timeout = VETH_ACKTIMEOUT;\r\nreturn 0;\r\n}\r\nstatic void veth_stop_connection(struct veth_lpar_connection *cnx)\r\n{\r\nif (!cnx)\r\nreturn;\r\nspin_lock_irq(&cnx->lock);\r\ncnx->state |= VETH_STATE_RESET | VETH_STATE_SHUTDOWN;\r\nveth_kick_statemachine(cnx);\r\nspin_unlock_irq(&cnx->lock);\r\nflush_delayed_work_sync(&cnx->statemachine_wq);\r\n}\r\nstatic void veth_destroy_connection(struct veth_lpar_connection *cnx)\r\n{\r\nif (!cnx)\r\nreturn;\r\nif (cnx->num_events > 0)\r\nmf_deallocate_lp_events(cnx->remote_lp,\r\nHvLpEvent_Type_VirtualLan,\r\ncnx->num_events,\r\nNULL, NULL);\r\nif (cnx->num_ack_events > 0)\r\nmf_deallocate_lp_events(cnx->remote_lp,\r\nHvLpEvent_Type_VirtualLan,\r\ncnx->num_ack_events,\r\nNULL, NULL);\r\nkfree(cnx->msgs);\r\nveth_cnx[cnx->remote_lp] = NULL;\r\nkfree(cnx);\r\n}\r\nstatic void veth_release_connection(struct kobject *kobj)\r\n{\r\nstruct veth_lpar_connection *cnx;\r\ncnx = container_of(kobj, struct veth_lpar_connection, kobject);\r\nveth_stop_connection(cnx);\r\nveth_destroy_connection(cnx);\r\n}\r\nstatic int veth_open(struct net_device *dev)\r\n{\r\nnetif_start_queue(dev);\r\nreturn 0;\r\n}\r\nstatic int veth_close(struct net_device *dev)\r\n{\r\nnetif_stop_queue(dev);\r\nreturn 0;\r\n}\r\nstatic int veth_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nif ((new_mtu < 68) || (new_mtu > VETH_MAX_MTU))\r\nreturn -EINVAL;\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nstatic void veth_set_multicast_list(struct net_device *dev)\r\n{\r\nstruct veth_port *port = netdev_priv(dev);\r\nunsigned long flags;\r\nwrite_lock_irqsave(&port->mcast_gate, flags);\r\nif ((dev->flags & IFF_PROMISC) || (dev->flags & IFF_ALLMULTI) ||\r\n(netdev_mc_count(dev) > VETH_MAX_MCAST)) {\r\nport->promiscuous = 1;\r\n} else {\r\nstruct netdev_hw_addr *ha;\r\nport->promiscuous = 0;\r\nport->num_mcast = 0;\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nu8 *addr = ha->addr;\r\nu64 xaddr = 0;\r\nmemcpy(&xaddr, addr, ETH_ALEN);\r\nport->mcast_addr[port->num_mcast] = xaddr;\r\nport->num_mcast++;\r\n}\r\n}\r\nwrite_unlock_irqrestore(&port->mcast_gate, flags);\r\n}\r\nstatic void veth_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstrncpy(info->driver, DRV_NAME, sizeof(info->driver) - 1);\r\ninfo->driver[sizeof(info->driver) - 1] = '\0';\r\nstrncpy(info->version, DRV_VERSION, sizeof(info->version) - 1);\r\ninfo->version[sizeof(info->version) - 1] = '\0';\r\n}\r\nstatic int veth_get_settings(struct net_device *dev, struct ethtool_cmd *ecmd)\r\n{\r\necmd->supported = (SUPPORTED_1000baseT_Full\r\n| SUPPORTED_Autoneg | SUPPORTED_FIBRE);\r\necmd->advertising = (SUPPORTED_1000baseT_Full\r\n| SUPPORTED_Autoneg | SUPPORTED_FIBRE);\r\necmd->port = PORT_FIBRE;\r\necmd->transceiver = XCVR_INTERNAL;\r\necmd->phy_address = 0;\r\necmd->speed = SPEED_1000;\r\necmd->duplex = DUPLEX_FULL;\r\necmd->autoneg = AUTONEG_ENABLE;\r\necmd->maxtxpkt = 120;\r\necmd->maxrxpkt = 120;\r\nreturn 0;\r\n}\r\nstatic struct net_device *veth_probe_one(int vlan,\r\nstruct vio_dev *vio_dev)\r\n{\r\nstruct net_device *dev;\r\nstruct veth_port *port;\r\nstruct device *vdev = &vio_dev->dev;\r\nint i, rc;\r\nconst unsigned char *mac_addr;\r\nmac_addr = vio_get_attribute(vio_dev, "local-mac-address", NULL);\r\nif (mac_addr == NULL)\r\nmac_addr = vio_get_attribute(vio_dev, "mac-address", NULL);\r\nif (mac_addr == NULL) {\r\nveth_error("Unable to fetch MAC address from device tree.\n");\r\nreturn NULL;\r\n}\r\ndev = alloc_etherdev(sizeof (struct veth_port));\r\nif (! dev) {\r\nveth_error("Unable to allocate net_device structure!\n");\r\nreturn NULL;\r\n}\r\nport = netdev_priv(dev);\r\nspin_lock_init(&port->queue_lock);\r\nrwlock_init(&port->mcast_gate);\r\nport->stopped_map = 0;\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; i++) {\r\nHvLpVirtualLanIndexMap map;\r\nif (i == this_lp)\r\ncontinue;\r\nmap = HvLpConfig_getVirtualLanIndexMapForLp(i);\r\nif (map & (0x8000 >> vlan))\r\nport->lpar_map |= (1 << i);\r\n}\r\nport->dev = vdev;\r\nmemcpy(dev->dev_addr, mac_addr, ETH_ALEN);\r\ndev->mtu = VETH_MAX_MTU;\r\nmemcpy(&port->mac_addr, mac_addr, ETH_ALEN);\r\ndev->netdev_ops = &veth_netdev_ops;\r\nSET_ETHTOOL_OPS(dev, &ops);\r\nSET_NETDEV_DEV(dev, vdev);\r\nrc = register_netdev(dev);\r\nif (rc != 0) {\r\nveth_error("Failed registering net device for vlan%d.\n", vlan);\r\nfree_netdev(dev);\r\nreturn NULL;\r\n}\r\nkobject_init(&port->kobject, &veth_port_ktype);\r\nif (0 != kobject_add(&port->kobject, &dev->dev.kobj, "veth_port"))\r\nveth_error("Failed adding port for %s to sysfs.\n", dev->name);\r\nveth_info("%s attached to iSeries vlan %d (LPAR map = 0x%.4X)\n",\r\ndev->name, vlan, port->lpar_map);\r\nreturn dev;\r\n}\r\nstatic int veth_transmit_to_one(struct sk_buff *skb, HvLpIndex rlp,\r\nstruct net_device *dev)\r\n{\r\nstruct veth_lpar_connection *cnx = veth_cnx[rlp];\r\nstruct veth_port *port = netdev_priv(dev);\r\nHvLpEvent_Rc rc;\r\nstruct veth_msg *msg = NULL;\r\nunsigned long flags;\r\nif (! cnx)\r\nreturn 0;\r\nspin_lock_irqsave(&cnx->lock, flags);\r\nif (! (cnx->state & VETH_STATE_READY))\r\ngoto no_error;\r\nif ((skb->len - ETH_HLEN) > VETH_MAX_MTU)\r\ngoto drop;\r\nmsg = veth_stack_pop(cnx);\r\nif (! msg)\r\ngoto drop;\r\nmsg->in_use = 1;\r\nmsg->skb = skb_get(skb);\r\nmsg->data.addr[0] = dma_map_single(port->dev, skb->data,\r\nskb->len, DMA_TO_DEVICE);\r\nif (dma_mapping_error(port->dev, msg->data.addr[0]))\r\ngoto recycle_and_drop;\r\nmsg->dev = port->dev;\r\nmsg->data.len[0] = skb->len;\r\nmsg->data.eofmask = 1 << VETH_EOF_SHIFT;\r\nrc = veth_signaldata(cnx, VETH_EVENT_FRAMES, msg->token, &msg->data);\r\nif (rc != HvLpEvent_Rc_Good)\r\ngoto recycle_and_drop;\r\nif (0 == cnx->outstanding_tx)\r\nmod_timer(&cnx->reset_timer, jiffies + cnx->reset_timeout);\r\ncnx->last_contact = jiffies;\r\ncnx->outstanding_tx++;\r\nif (veth_stack_is_empty(cnx))\r\nveth_stop_queues(cnx);\r\nno_error:\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\nreturn 0;\r\nrecycle_and_drop:\r\nveth_recycle_msg(cnx, msg);\r\ndrop:\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\nreturn 1;\r\n}\r\nstatic void veth_transmit_to_many(struct sk_buff *skb,\r\nHvLpIndexMap lpmask,\r\nstruct net_device *dev)\r\n{\r\nint i, success, error;\r\nsuccess = error = 0;\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; i++) {\r\nif ((lpmask & (1 << i)) == 0)\r\ncontinue;\r\nif (veth_transmit_to_one(skb, i, dev))\r\nerror = 1;\r\nelse\r\nsuccess = 1;\r\n}\r\nif (error)\r\ndev->stats.tx_errors++;\r\nif (success) {\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += skb->len;\r\n}\r\n}\r\nstatic int veth_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nunsigned char *frame = skb->data;\r\nstruct veth_port *port = netdev_priv(dev);\r\nHvLpIndexMap lpmask;\r\nif (is_unicast_ether_addr(frame)) {\r\nHvLpIndex rlp = frame[5];\r\nif ( ! ((1 << rlp) & port->lpar_map) ) {\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nlpmask = 1 << rlp;\r\n} else {\r\nlpmask = port->lpar_map;\r\n}\r\nveth_transmit_to_many(skb, lpmask, dev);\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void veth_recycle_msg(struct veth_lpar_connection *cnx,\r\nstruct veth_msg *msg)\r\n{\r\nu32 dma_address, dma_length;\r\nif (msg->in_use) {\r\nmsg->in_use = 0;\r\ndma_address = msg->data.addr[0];\r\ndma_length = msg->data.len[0];\r\nif (!dma_mapping_error(msg->dev, dma_address))\r\ndma_unmap_single(msg->dev, dma_address, dma_length,\r\nDMA_TO_DEVICE);\r\nif (msg->skb) {\r\ndev_kfree_skb_any(msg->skb);\r\nmsg->skb = NULL;\r\n}\r\nmemset(&msg->data, 0, sizeof(msg->data));\r\nveth_stack_push(cnx, msg);\r\n} else if (cnx->state & VETH_STATE_OPEN) {\r\nveth_error("Non-pending frame (# %d) acked by LPAR %d.\n",\r\ncnx->remote_lp, msg->token);\r\n}\r\n}\r\nstatic void veth_wake_queues(struct veth_lpar_connection *cnx)\r\n{\r\nint i;\r\nfor (i = 0; i < HVMAXARCHITECTEDVIRTUALLANS; i++) {\r\nstruct net_device *dev = veth_dev[i];\r\nstruct veth_port *port;\r\nunsigned long flags;\r\nif (! dev)\r\ncontinue;\r\nport = netdev_priv(dev);\r\nif (! (port->lpar_map & (1<<cnx->remote_lp)))\r\ncontinue;\r\nspin_lock_irqsave(&port->queue_lock, flags);\r\nport->stopped_map &= ~(1 << cnx->remote_lp);\r\nif (0 == port->stopped_map && netif_queue_stopped(dev)) {\r\nveth_debug("cnx %d: woke queue for %s.\n",\r\ncnx->remote_lp, dev->name);\r\nnetif_wake_queue(dev);\r\n}\r\nspin_unlock_irqrestore(&port->queue_lock, flags);\r\n}\r\n}\r\nstatic void veth_stop_queues(struct veth_lpar_connection *cnx)\r\n{\r\nint i;\r\nfor (i = 0; i < HVMAXARCHITECTEDVIRTUALLANS; i++) {\r\nstruct net_device *dev = veth_dev[i];\r\nstruct veth_port *port;\r\nif (! dev)\r\ncontinue;\r\nport = netdev_priv(dev);\r\nif (! (port->lpar_map & (1 << cnx->remote_lp)))\r\ncontinue;\r\nspin_lock(&port->queue_lock);\r\nnetif_stop_queue(dev);\r\nport->stopped_map |= (1 << cnx->remote_lp);\r\nveth_debug("cnx %d: stopped queue for %s, map = 0x%x.\n",\r\ncnx->remote_lp, dev->name, port->stopped_map);\r\nspin_unlock(&port->queue_lock);\r\n}\r\n}\r\nstatic void veth_timed_reset(unsigned long ptr)\r\n{\r\nstruct veth_lpar_connection *cnx = (struct veth_lpar_connection *)ptr;\r\nunsigned long trigger_time, flags;\r\nspin_lock_irqsave(&cnx->lock, flags);\r\nif (cnx->outstanding_tx > 0) {\r\ntrigger_time = cnx->last_contact + cnx->reset_timeout;\r\nif (trigger_time < jiffies) {\r\ncnx->state |= VETH_STATE_RESET;\r\nveth_kick_statemachine(cnx);\r\nveth_error("%d packets not acked by LPAR %d within %d "\r\n"seconds, resetting.\n",\r\ncnx->outstanding_tx, cnx->remote_lp,\r\ncnx->reset_timeout / HZ);\r\n} else {\r\ntrigger_time = jiffies + cnx->reset_timeout;\r\nmod_timer(&cnx->reset_timer, trigger_time);\r\n}\r\n}\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\n}\r\nstatic inline int veth_frame_wanted(struct veth_port *port, u64 mac_addr)\r\n{\r\nint wanted = 0;\r\nint i;\r\nunsigned long flags;\r\nif ( (mac_addr == port->mac_addr) || (mac_addr == 0xffffffffffff0000) )\r\nreturn 1;\r\nread_lock_irqsave(&port->mcast_gate, flags);\r\nif (port->promiscuous) {\r\nwanted = 1;\r\ngoto out;\r\n}\r\nfor (i = 0; i < port->num_mcast; ++i) {\r\nif (port->mcast_addr[i] == mac_addr) {\r\nwanted = 1;\r\nbreak;\r\n}\r\n}\r\nout:\r\nread_unlock_irqrestore(&port->mcast_gate, flags);\r\nreturn wanted;\r\n}\r\nstatic inline void veth_build_dma_list(struct dma_chunk *list,\r\nunsigned char *p, unsigned long length)\r\n{\r\nunsigned long done;\r\nint i = 1;\r\nlist[0].addr = iseries_hv_addr(p);\r\nlist[0].size = min(length,\r\nPAGE_SIZE - ((unsigned long)p & ~PAGE_MASK));\r\ndone = list[0].size;\r\nwhile (done < length) {\r\nlist[i].addr = iseries_hv_addr(p + done);\r\nlist[i].size = min(length-done, PAGE_SIZE);\r\ndone += list[i].size;\r\ni++;\r\n}\r\n}\r\nstatic void veth_flush_acks(struct veth_lpar_connection *cnx)\r\n{\r\nHvLpEvent_Rc rc;\r\nrc = veth_signaldata(cnx, VETH_EVENT_FRAMES_ACK,\r\n0, &cnx->pending_acks);\r\nif (rc != HvLpEvent_Rc_Good)\r\nveth_error("Failed acking frames from LPAR %d, rc = %d\n",\r\ncnx->remote_lp, (int)rc);\r\ncnx->num_pending_acks = 0;\r\nmemset(&cnx->pending_acks, 0xff, sizeof(cnx->pending_acks));\r\n}\r\nstatic void veth_receive(struct veth_lpar_connection *cnx,\r\nstruct veth_lpevent *event)\r\n{\r\nstruct veth_frames_data *senddata = &event->u.frames_data;\r\nint startchunk = 0;\r\nint nchunks;\r\nunsigned long flags;\r\nHvLpDma_Rc rc;\r\ndo {\r\nu16 length = 0;\r\nstruct sk_buff *skb;\r\nstruct dma_chunk local_list[VETH_MAX_PAGES_PER_FRAME];\r\nstruct dma_chunk remote_list[VETH_MAX_FRAMES_PER_MSG];\r\nu64 dest;\r\nHvLpVirtualLanIndex vlan;\r\nstruct net_device *dev;\r\nstruct veth_port *port;\r\nmemset(local_list, 0, sizeof(local_list));\r\nmemset(remote_list, 0, sizeof(remote_list));\r\nif (senddata->addr[startchunk] == 0)\r\nbreak;\r\nif (! (senddata->eofmask >> (startchunk + VETH_EOF_SHIFT))) {\r\nveth_error("Missing EOF fragment in event "\r\n"eofmask = 0x%x startchunk = %d\n",\r\n(unsigned)senddata->eofmask,\r\nstartchunk);\r\nbreak;\r\n}\r\nnchunks = 0;\r\ndo {\r\nremote_list[nchunks].addr =\r\n(u64) senddata->addr[startchunk+nchunks] << 32;\r\nremote_list[nchunks].size =\r\nsenddata->len[startchunk+nchunks];\r\nlength += remote_list[nchunks].size;\r\n} while (! (senddata->eofmask &\r\n(1 << (VETH_EOF_SHIFT + startchunk + nchunks++))));\r\nif ((length - ETH_HLEN) > VETH_MAX_MTU) {\r\nveth_error("Received oversize frame from LPAR %d "\r\n"(length = %d)\n",\r\ncnx->remote_lp, length);\r\ncontinue;\r\n}\r\nskb = alloc_skb(length, GFP_ATOMIC);\r\nif (!skb)\r\ncontinue;\r\nveth_build_dma_list(local_list, skb->data, length);\r\nrc = HvCallEvent_dmaBufList(HvLpEvent_Type_VirtualLan,\r\nevent->base_event.xSourceLp,\r\nHvLpDma_Direction_RemoteToLocal,\r\ncnx->src_inst,\r\ncnx->dst_inst,\r\nHvLpDma_AddressType_RealAddress,\r\nHvLpDma_AddressType_TceIndex,\r\niseries_hv_addr(&local_list),\r\niseries_hv_addr(&remote_list),\r\nlength);\r\nif (rc != HvLpDma_Rc_Good) {\r\ndev_kfree_skb_irq(skb);\r\ncontinue;\r\n}\r\nvlan = skb->data[9];\r\ndev = veth_dev[vlan];\r\nif (! dev) {\r\ndev_kfree_skb_irq(skb);\r\ncontinue;\r\n}\r\nport = netdev_priv(dev);\r\ndest = *((u64 *) skb->data) & 0xFFFFFFFFFFFF0000;\r\nif ((vlan > HVMAXARCHITECTEDVIRTUALLANS) || !port) {\r\ndev_kfree_skb_irq(skb);\r\ncontinue;\r\n}\r\nif (! veth_frame_wanted(port, dest)) {\r\ndev_kfree_skb_irq(skb);\r\ncontinue;\r\n}\r\nskb_put(skb, length);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nskb_checksum_none_assert(skb);\r\nnetif_rx(skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += length;\r\n} while (startchunk += nchunks, startchunk < VETH_MAX_FRAMES_PER_MSG);\r\nspin_lock_irqsave(&cnx->lock, flags);\r\nBUG_ON(cnx->num_pending_acks > VETH_MAX_ACKS_PER_MSG);\r\ncnx->pending_acks[cnx->num_pending_acks++] =\r\nevent->base_event.xCorrelationToken;\r\nif ( (cnx->num_pending_acks >= cnx->remote_caps.ack_threshold) ||\r\n(cnx->num_pending_acks >= VETH_MAX_ACKS_PER_MSG) )\r\nveth_flush_acks(cnx);\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\n}\r\nstatic void veth_timed_ack(unsigned long ptr)\r\n{\r\nstruct veth_lpar_connection *cnx = (struct veth_lpar_connection *) ptr;\r\nunsigned long flags;\r\nspin_lock_irqsave(&cnx->lock, flags);\r\nif (cnx->num_pending_acks > 0)\r\nveth_flush_acks(cnx);\r\ncnx->ack_timer.expires = jiffies + cnx->ack_timeout;\r\nadd_timer(&cnx->ack_timer);\r\nspin_unlock_irqrestore(&cnx->lock, flags);\r\n}\r\nstatic int veth_remove(struct vio_dev *vdev)\r\n{\r\nstruct veth_lpar_connection *cnx;\r\nstruct net_device *dev;\r\nstruct veth_port *port;\r\nint i;\r\ndev = veth_dev[vdev->unit_address];\r\nif (! dev)\r\nreturn 0;\r\nport = netdev_priv(dev);\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; i++) {\r\ncnx = veth_cnx[i];\r\nif (cnx && (port->lpar_map & (1 << i))) {\r\nkobject_put(&cnx->kobject);\r\n}\r\n}\r\nveth_dev[vdev->unit_address] = NULL;\r\nkobject_del(&port->kobject);\r\nkobject_put(&port->kobject);\r\nunregister_netdev(dev);\r\nfree_netdev(dev);\r\nreturn 0;\r\n}\r\nstatic int veth_probe(struct vio_dev *vdev, const struct vio_device_id *id)\r\n{\r\nint i = vdev->unit_address;\r\nstruct net_device *dev;\r\nstruct veth_port *port;\r\ndev = veth_probe_one(i, vdev);\r\nif (dev == NULL) {\r\nveth_remove(vdev);\r\nreturn 1;\r\n}\r\nveth_dev[i] = dev;\r\nport = netdev_priv(dev);\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; i++) {\r\nstruct veth_lpar_connection *cnx;\r\nif (! (port->lpar_map & (1 << i)))\r\ncontinue;\r\ncnx = veth_cnx[i];\r\nif (!cnx)\r\ncontinue;\r\nkobject_get(&cnx->kobject);\r\nveth_kick_statemachine(cnx);\r\n}\r\nreturn 0;\r\n}\r\nstatic void __exit veth_module_cleanup(void)\r\n{\r\nint i;\r\nstruct veth_lpar_connection *cnx;\r\nHvLpEvent_unregisterHandler(HvLpEvent_Type_VirtualLan);\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {\r\ncnx = veth_cnx[i];\r\nif (!cnx)\r\ncontinue;\r\ncancel_delayed_work_sync(&cnx->statemachine_wq);\r\nkobject_del(&cnx->kobject);\r\nkobject_put(&cnx->kobject);\r\n}\r\nvio_unregister_driver(&veth_driver);\r\n}\r\nstatic int __init veth_module_init(void)\r\n{\r\nint i;\r\nint rc;\r\nif (!firmware_has_feature(FW_FEATURE_ISERIES))\r\nreturn -ENODEV;\r\nthis_lp = HvLpConfig_getLpIndex_outline();\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {\r\nrc = veth_init_connection(i);\r\nif (rc != 0)\r\ngoto error;\r\n}\r\nHvLpEvent_registerHandler(HvLpEvent_Type_VirtualLan,\r\n&veth_handle_event);\r\nrc = vio_register_driver(&veth_driver);\r\nif (rc != 0)\r\ngoto error;\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {\r\nstruct kobject *kobj;\r\nif (!veth_cnx[i])\r\ncontinue;\r\nkobj = &veth_cnx[i]->kobject;\r\nif (0 != driver_add_kobj(&veth_driver.driver, kobj,\r\n"cnx%.2d", veth_cnx[i]->remote_lp))\r\nveth_error("cnx %d: Failed adding to sysfs.\n", i);\r\n}\r\nreturn 0;\r\nerror:\r\nfor (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {\r\nveth_destroy_connection(veth_cnx[i]);\r\n}\r\nreturn rc;\r\n}
