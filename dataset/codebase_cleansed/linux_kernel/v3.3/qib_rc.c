static u32 restart_sge(struct qib_sge_state *ss, struct qib_swqe *wqe,\r\nu32 psn, u32 pmtu)\r\n{\r\nu32 len;\r\nlen = ((psn - wqe->psn) & QIB_PSN_MASK) * pmtu;\r\nss->sge = wqe->sg_list[0];\r\nss->sg_list = wqe->sg_list + 1;\r\nss->num_sge = wqe->wr.num_sge;\r\nss->total_len = wqe->length;\r\nqib_skip_sge(ss, len, 0);\r\nreturn wqe->length - len;\r\n}\r\nstatic void start_timer(struct qib_qp *qp)\r\n{\r\nqp->s_flags |= QIB_S_TIMER;\r\nqp->s_timer.function = rc_timeout;\r\nqp->s_timer.expires = jiffies + qp->timeout_jiffies;\r\nadd_timer(&qp->s_timer);\r\n}\r\nstatic int qib_make_rc_ack(struct qib_ibdev *dev, struct qib_qp *qp,\r\nstruct qib_other_headers *ohdr, u32 pmtu)\r\n{\r\nstruct qib_ack_entry *e;\r\nu32 hwords;\r\nu32 len;\r\nu32 bth0;\r\nu32 bth2;\r\nif (!(ib_qib_state_ops[qp->state] & QIB_PROCESS_RECV_OK))\r\ngoto bail;\r\nhwords = 5;\r\nswitch (qp->s_ack_state) {\r\ncase OP(RDMA_READ_RESPONSE_LAST):\r\ncase OP(RDMA_READ_RESPONSE_ONLY):\r\ne = &qp->s_ack_queue[qp->s_tail_ack_queue];\r\nif (e->rdma_sge.mr) {\r\natomic_dec(&e->rdma_sge.mr->refcount);\r\ne->rdma_sge.mr = NULL;\r\n}\r\ncase OP(ATOMIC_ACKNOWLEDGE):\r\nif (++qp->s_tail_ack_queue > QIB_MAX_RDMA_ATOMIC)\r\nqp->s_tail_ack_queue = 0;\r\ncase OP(SEND_ONLY):\r\ncase OP(ACKNOWLEDGE):\r\nif (qp->r_head_ack_queue == qp->s_tail_ack_queue) {\r\nif (qp->s_flags & QIB_S_ACK_PENDING)\r\ngoto normal;\r\ngoto bail;\r\n}\r\ne = &qp->s_ack_queue[qp->s_tail_ack_queue];\r\nif (e->opcode == OP(RDMA_READ_REQUEST)) {\r\nlen = e->rdma_sge.sge_length;\r\nif (len && !e->rdma_sge.mr) {\r\nqp->s_tail_ack_queue = qp->r_head_ack_queue;\r\ngoto bail;\r\n}\r\nqp->s_rdma_mr = e->rdma_sge.mr;\r\nif (qp->s_rdma_mr)\r\natomic_inc(&qp->s_rdma_mr->refcount);\r\nqp->s_ack_rdma_sge.sge = e->rdma_sge;\r\nqp->s_ack_rdma_sge.num_sge = 1;\r\nqp->s_cur_sge = &qp->s_ack_rdma_sge;\r\nif (len > pmtu) {\r\nlen = pmtu;\r\nqp->s_ack_state = OP(RDMA_READ_RESPONSE_FIRST);\r\n} else {\r\nqp->s_ack_state = OP(RDMA_READ_RESPONSE_ONLY);\r\ne->sent = 1;\r\n}\r\nohdr->u.aeth = qib_compute_aeth(qp);\r\nhwords++;\r\nqp->s_ack_rdma_psn = e->psn;\r\nbth2 = qp->s_ack_rdma_psn++ & QIB_PSN_MASK;\r\n} else {\r\nqp->s_cur_sge = NULL;\r\nlen = 0;\r\nqp->s_ack_state = OP(ATOMIC_ACKNOWLEDGE);\r\nohdr->u.at.aeth = qib_compute_aeth(qp);\r\nohdr->u.at.atomic_ack_eth[0] =\r\ncpu_to_be32(e->atomic_data >> 32);\r\nohdr->u.at.atomic_ack_eth[1] =\r\ncpu_to_be32(e->atomic_data);\r\nhwords += sizeof(ohdr->u.at) / sizeof(u32);\r\nbth2 = e->psn & QIB_PSN_MASK;\r\ne->sent = 1;\r\n}\r\nbth0 = qp->s_ack_state << 24;\r\nbreak;\r\ncase OP(RDMA_READ_RESPONSE_FIRST):\r\nqp->s_ack_state = OP(RDMA_READ_RESPONSE_MIDDLE);\r\ncase OP(RDMA_READ_RESPONSE_MIDDLE):\r\nqp->s_cur_sge = &qp->s_ack_rdma_sge;\r\nqp->s_rdma_mr = qp->s_ack_rdma_sge.sge.mr;\r\nif (qp->s_rdma_mr)\r\natomic_inc(&qp->s_rdma_mr->refcount);\r\nlen = qp->s_ack_rdma_sge.sge.sge_length;\r\nif (len > pmtu)\r\nlen = pmtu;\r\nelse {\r\nohdr->u.aeth = qib_compute_aeth(qp);\r\nhwords++;\r\nqp->s_ack_state = OP(RDMA_READ_RESPONSE_LAST);\r\ne = &qp->s_ack_queue[qp->s_tail_ack_queue];\r\ne->sent = 1;\r\n}\r\nbth0 = qp->s_ack_state << 24;\r\nbth2 = qp->s_ack_rdma_psn++ & QIB_PSN_MASK;\r\nbreak;\r\ndefault:\r\nnormal:\r\nqp->s_ack_state = OP(SEND_ONLY);\r\nqp->s_flags &= ~QIB_S_ACK_PENDING;\r\nqp->s_cur_sge = NULL;\r\nif (qp->s_nak_state)\r\nohdr->u.aeth =\r\ncpu_to_be32((qp->r_msn & QIB_MSN_MASK) |\r\n(qp->s_nak_state <<\r\nQIB_AETH_CREDIT_SHIFT));\r\nelse\r\nohdr->u.aeth = qib_compute_aeth(qp);\r\nhwords++;\r\nlen = 0;\r\nbth0 = OP(ACKNOWLEDGE) << 24;\r\nbth2 = qp->s_ack_psn & QIB_PSN_MASK;\r\n}\r\nqp->s_rdma_ack_cnt++;\r\nqp->s_hdrwords = hwords;\r\nqp->s_cur_size = len;\r\nqib_make_ruc_header(qp, ohdr, bth0, bth2);\r\nreturn 1;\r\nbail:\r\nqp->s_ack_state = OP(ACKNOWLEDGE);\r\nqp->s_flags &= ~(QIB_S_RESP_PENDING | QIB_S_ACK_PENDING);\r\nreturn 0;\r\n}\r\nint qib_make_rc_req(struct qib_qp *qp)\r\n{\r\nstruct qib_ibdev *dev = to_idev(qp->ibqp.device);\r\nstruct qib_other_headers *ohdr;\r\nstruct qib_sge_state *ss;\r\nstruct qib_swqe *wqe;\r\nu32 hwords;\r\nu32 len;\r\nu32 bth0;\r\nu32 bth2;\r\nu32 pmtu = qp->pmtu;\r\nchar newreq;\r\nunsigned long flags;\r\nint ret = 0;\r\nint delta;\r\nohdr = &qp->s_hdr.u.oth;\r\nif (qp->remote_ah_attr.ah_flags & IB_AH_GRH)\r\nohdr = &qp->s_hdr.u.l.oth;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif ((qp->s_flags & QIB_S_RESP_PENDING) &&\r\nqib_make_rc_ack(dev, qp, ohdr, pmtu))\r\ngoto done;\r\nif (!(ib_qib_state_ops[qp->state] & QIB_PROCESS_SEND_OK)) {\r\nif (!(ib_qib_state_ops[qp->state] & QIB_FLUSH_SEND))\r\ngoto bail;\r\nif (qp->s_last == qp->s_head)\r\ngoto bail;\r\nif (atomic_read(&qp->s_dma_busy)) {\r\nqp->s_flags |= QIB_S_WAIT_DMA;\r\ngoto bail;\r\n}\r\nwqe = get_swqe_ptr(qp, qp->s_last);\r\nqib_send_complete(qp, wqe, qp->s_last != qp->s_acked ?\r\nIB_WC_SUCCESS : IB_WC_WR_FLUSH_ERR);\r\ngoto done;\r\n}\r\nif (qp->s_flags & (QIB_S_WAIT_RNR | QIB_S_WAIT_ACK))\r\ngoto bail;\r\nif (qib_cmp24(qp->s_psn, qp->s_sending_hpsn) <= 0) {\r\nif (qib_cmp24(qp->s_sending_psn, qp->s_sending_hpsn) <= 0) {\r\nqp->s_flags |= QIB_S_WAIT_PSN;\r\ngoto bail;\r\n}\r\nqp->s_sending_psn = qp->s_psn;\r\nqp->s_sending_hpsn = qp->s_psn - 1;\r\n}\r\nhwords = 5;\r\nbth0 = 0;\r\nwqe = get_swqe_ptr(qp, qp->s_cur);\r\nswitch (qp->s_state) {\r\ndefault:\r\nif (!(ib_qib_state_ops[qp->state] & QIB_PROCESS_NEXT_SEND_OK))\r\ngoto bail;\r\nnewreq = 0;\r\nif (qp->s_cur == qp->s_tail) {\r\nif (qp->s_tail == qp->s_head)\r\ngoto bail;\r\nif ((wqe->wr.send_flags & IB_SEND_FENCE) &&\r\nqp->s_num_rd_atomic) {\r\nqp->s_flags |= QIB_S_WAIT_FENCE;\r\ngoto bail;\r\n}\r\nwqe->psn = qp->s_next_psn;\r\nnewreq = 1;\r\n}\r\nlen = wqe->length;\r\nss = &qp->s_sge;\r\nbth2 = qp->s_psn & QIB_PSN_MASK;\r\nswitch (wqe->wr.opcode) {\r\ncase IB_WR_SEND:\r\ncase IB_WR_SEND_WITH_IMM:\r\nif (!(qp->s_flags & QIB_S_UNLIMITED_CREDIT) &&\r\nqib_cmp24(wqe->ssn, qp->s_lsn + 1) > 0) {\r\nqp->s_flags |= QIB_S_WAIT_SSN_CREDIT;\r\ngoto bail;\r\n}\r\nwqe->lpsn = wqe->psn;\r\nif (len > pmtu) {\r\nwqe->lpsn += (len - 1) / pmtu;\r\nqp->s_state = OP(SEND_FIRST);\r\nlen = pmtu;\r\nbreak;\r\n}\r\nif (wqe->wr.opcode == IB_WR_SEND)\r\nqp->s_state = OP(SEND_ONLY);\r\nelse {\r\nqp->s_state = OP(SEND_ONLY_WITH_IMMEDIATE);\r\nohdr->u.imm_data = wqe->wr.ex.imm_data;\r\nhwords += 1;\r\n}\r\nif (wqe->wr.send_flags & IB_SEND_SOLICITED)\r\nbth0 |= IB_BTH_SOLICITED;\r\nbth2 |= IB_BTH_REQ_ACK;\r\nif (++qp->s_cur == qp->s_size)\r\nqp->s_cur = 0;\r\nbreak;\r\ncase IB_WR_RDMA_WRITE:\r\nif (newreq && !(qp->s_flags & QIB_S_UNLIMITED_CREDIT))\r\nqp->s_lsn++;\r\ncase IB_WR_RDMA_WRITE_WITH_IMM:\r\nif (!(qp->s_flags & QIB_S_UNLIMITED_CREDIT) &&\r\nqib_cmp24(wqe->ssn, qp->s_lsn + 1) > 0) {\r\nqp->s_flags |= QIB_S_WAIT_SSN_CREDIT;\r\ngoto bail;\r\n}\r\nohdr->u.rc.reth.vaddr =\r\ncpu_to_be64(wqe->wr.wr.rdma.remote_addr);\r\nohdr->u.rc.reth.rkey =\r\ncpu_to_be32(wqe->wr.wr.rdma.rkey);\r\nohdr->u.rc.reth.length = cpu_to_be32(len);\r\nhwords += sizeof(struct ib_reth) / sizeof(u32);\r\nwqe->lpsn = wqe->psn;\r\nif (len > pmtu) {\r\nwqe->lpsn += (len - 1) / pmtu;\r\nqp->s_state = OP(RDMA_WRITE_FIRST);\r\nlen = pmtu;\r\nbreak;\r\n}\r\nif (wqe->wr.opcode == IB_WR_RDMA_WRITE)\r\nqp->s_state = OP(RDMA_WRITE_ONLY);\r\nelse {\r\nqp->s_state =\r\nOP(RDMA_WRITE_ONLY_WITH_IMMEDIATE);\r\nohdr->u.rc.imm_data = wqe->wr.ex.imm_data;\r\nhwords += 1;\r\nif (wqe->wr.send_flags & IB_SEND_SOLICITED)\r\nbth0 |= IB_BTH_SOLICITED;\r\n}\r\nbth2 |= IB_BTH_REQ_ACK;\r\nif (++qp->s_cur == qp->s_size)\r\nqp->s_cur = 0;\r\nbreak;\r\ncase IB_WR_RDMA_READ:\r\nif (newreq) {\r\nif (qp->s_num_rd_atomic >=\r\nqp->s_max_rd_atomic) {\r\nqp->s_flags |= QIB_S_WAIT_RDMAR;\r\ngoto bail;\r\n}\r\nqp->s_num_rd_atomic++;\r\nif (!(qp->s_flags & QIB_S_UNLIMITED_CREDIT))\r\nqp->s_lsn++;\r\nif (len > pmtu)\r\nqp->s_next_psn += (len - 1) / pmtu;\r\nwqe->lpsn = qp->s_next_psn++;\r\n}\r\nohdr->u.rc.reth.vaddr =\r\ncpu_to_be64(wqe->wr.wr.rdma.remote_addr);\r\nohdr->u.rc.reth.rkey =\r\ncpu_to_be32(wqe->wr.wr.rdma.rkey);\r\nohdr->u.rc.reth.length = cpu_to_be32(len);\r\nqp->s_state = OP(RDMA_READ_REQUEST);\r\nhwords += sizeof(ohdr->u.rc.reth) / sizeof(u32);\r\nss = NULL;\r\nlen = 0;\r\nbth2 |= IB_BTH_REQ_ACK;\r\nif (++qp->s_cur == qp->s_size)\r\nqp->s_cur = 0;\r\nbreak;\r\ncase IB_WR_ATOMIC_CMP_AND_SWP:\r\ncase IB_WR_ATOMIC_FETCH_AND_ADD:\r\nif (newreq) {\r\nif (qp->s_num_rd_atomic >=\r\nqp->s_max_rd_atomic) {\r\nqp->s_flags |= QIB_S_WAIT_RDMAR;\r\ngoto bail;\r\n}\r\nqp->s_num_rd_atomic++;\r\nif (!(qp->s_flags & QIB_S_UNLIMITED_CREDIT))\r\nqp->s_lsn++;\r\nwqe->lpsn = wqe->psn;\r\n}\r\nif (wqe->wr.opcode == IB_WR_ATOMIC_CMP_AND_SWP) {\r\nqp->s_state = OP(COMPARE_SWAP);\r\nohdr->u.atomic_eth.swap_data = cpu_to_be64(\r\nwqe->wr.wr.atomic.swap);\r\nohdr->u.atomic_eth.compare_data = cpu_to_be64(\r\nwqe->wr.wr.atomic.compare_add);\r\n} else {\r\nqp->s_state = OP(FETCH_ADD);\r\nohdr->u.atomic_eth.swap_data = cpu_to_be64(\r\nwqe->wr.wr.atomic.compare_add);\r\nohdr->u.atomic_eth.compare_data = 0;\r\n}\r\nohdr->u.atomic_eth.vaddr[0] = cpu_to_be32(\r\nwqe->wr.wr.atomic.remote_addr >> 32);\r\nohdr->u.atomic_eth.vaddr[1] = cpu_to_be32(\r\nwqe->wr.wr.atomic.remote_addr);\r\nohdr->u.atomic_eth.rkey = cpu_to_be32(\r\nwqe->wr.wr.atomic.rkey);\r\nhwords += sizeof(struct ib_atomic_eth) / sizeof(u32);\r\nss = NULL;\r\nlen = 0;\r\nbth2 |= IB_BTH_REQ_ACK;\r\nif (++qp->s_cur == qp->s_size)\r\nqp->s_cur = 0;\r\nbreak;\r\ndefault:\r\ngoto bail;\r\n}\r\nqp->s_sge.sge = wqe->sg_list[0];\r\nqp->s_sge.sg_list = wqe->sg_list + 1;\r\nqp->s_sge.num_sge = wqe->wr.num_sge;\r\nqp->s_sge.total_len = wqe->length;\r\nqp->s_len = wqe->length;\r\nif (newreq) {\r\nqp->s_tail++;\r\nif (qp->s_tail >= qp->s_size)\r\nqp->s_tail = 0;\r\n}\r\nif (wqe->wr.opcode == IB_WR_RDMA_READ)\r\nqp->s_psn = wqe->lpsn + 1;\r\nelse {\r\nqp->s_psn++;\r\nif (qib_cmp24(qp->s_psn, qp->s_next_psn) > 0)\r\nqp->s_next_psn = qp->s_psn;\r\n}\r\nbreak;\r\ncase OP(RDMA_READ_RESPONSE_FIRST):\r\nqp->s_len = restart_sge(&qp->s_sge, wqe, qp->s_psn, pmtu);\r\ncase OP(SEND_FIRST):\r\nqp->s_state = OP(SEND_MIDDLE);\r\ncase OP(SEND_MIDDLE):\r\nbth2 = qp->s_psn++ & QIB_PSN_MASK;\r\nif (qib_cmp24(qp->s_psn, qp->s_next_psn) > 0)\r\nqp->s_next_psn = qp->s_psn;\r\nss = &qp->s_sge;\r\nlen = qp->s_len;\r\nif (len > pmtu) {\r\nlen = pmtu;\r\nbreak;\r\n}\r\nif (wqe->wr.opcode == IB_WR_SEND)\r\nqp->s_state = OP(SEND_LAST);\r\nelse {\r\nqp->s_state = OP(SEND_LAST_WITH_IMMEDIATE);\r\nohdr->u.imm_data = wqe->wr.ex.imm_data;\r\nhwords += 1;\r\n}\r\nif (wqe->wr.send_flags & IB_SEND_SOLICITED)\r\nbth0 |= IB_BTH_SOLICITED;\r\nbth2 |= IB_BTH_REQ_ACK;\r\nqp->s_cur++;\r\nif (qp->s_cur >= qp->s_size)\r\nqp->s_cur = 0;\r\nbreak;\r\ncase OP(RDMA_READ_RESPONSE_LAST):\r\nqp->s_len = restart_sge(&qp->s_sge, wqe, qp->s_psn, pmtu);\r\ncase OP(RDMA_WRITE_FIRST):\r\nqp->s_state = OP(RDMA_WRITE_MIDDLE);\r\ncase OP(RDMA_WRITE_MIDDLE):\r\nbth2 = qp->s_psn++ & QIB_PSN_MASK;\r\nif (qib_cmp24(qp->s_psn, qp->s_next_psn) > 0)\r\nqp->s_next_psn = qp->s_psn;\r\nss = &qp->s_sge;\r\nlen = qp->s_len;\r\nif (len > pmtu) {\r\nlen = pmtu;\r\nbreak;\r\n}\r\nif (wqe->wr.opcode == IB_WR_RDMA_WRITE)\r\nqp->s_state = OP(RDMA_WRITE_LAST);\r\nelse {\r\nqp->s_state = OP(RDMA_WRITE_LAST_WITH_IMMEDIATE);\r\nohdr->u.imm_data = wqe->wr.ex.imm_data;\r\nhwords += 1;\r\nif (wqe->wr.send_flags & IB_SEND_SOLICITED)\r\nbth0 |= IB_BTH_SOLICITED;\r\n}\r\nbth2 |= IB_BTH_REQ_ACK;\r\nqp->s_cur++;\r\nif (qp->s_cur >= qp->s_size)\r\nqp->s_cur = 0;\r\nbreak;\r\ncase OP(RDMA_READ_RESPONSE_MIDDLE):\r\nlen = ((qp->s_psn - wqe->psn) & QIB_PSN_MASK) * pmtu;\r\nohdr->u.rc.reth.vaddr =\r\ncpu_to_be64(wqe->wr.wr.rdma.remote_addr + len);\r\nohdr->u.rc.reth.rkey =\r\ncpu_to_be32(wqe->wr.wr.rdma.rkey);\r\nohdr->u.rc.reth.length = cpu_to_be32(wqe->length - len);\r\nqp->s_state = OP(RDMA_READ_REQUEST);\r\nhwords += sizeof(ohdr->u.rc.reth) / sizeof(u32);\r\nbth2 = (qp->s_psn & QIB_PSN_MASK) | IB_BTH_REQ_ACK;\r\nqp->s_psn = wqe->lpsn + 1;\r\nss = NULL;\r\nlen = 0;\r\nqp->s_cur++;\r\nif (qp->s_cur == qp->s_size)\r\nqp->s_cur = 0;\r\nbreak;\r\n}\r\nqp->s_sending_hpsn = bth2;\r\ndelta = (((int) bth2 - (int) wqe->psn) << 8) >> 8;\r\nif (delta && delta % QIB_PSN_CREDIT == 0)\r\nbth2 |= IB_BTH_REQ_ACK;\r\nif (qp->s_flags & QIB_S_SEND_ONE) {\r\nqp->s_flags &= ~QIB_S_SEND_ONE;\r\nqp->s_flags |= QIB_S_WAIT_ACK;\r\nbth2 |= IB_BTH_REQ_ACK;\r\n}\r\nqp->s_len -= len;\r\nqp->s_hdrwords = hwords;\r\nqp->s_cur_sge = ss;\r\nqp->s_cur_size = len;\r\nqib_make_ruc_header(qp, ohdr, bth0 | (qp->s_state << 24), bth2);\r\ndone:\r\nret = 1;\r\ngoto unlock;\r\nbail:\r\nqp->s_flags &= ~QIB_S_BUSY;\r\nunlock:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nreturn ret;\r\n}\r\nvoid qib_send_rc_ack(struct qib_qp *qp)\r\n{\r\nstruct qib_devdata *dd = dd_from_ibdev(qp->ibqp.device);\r\nstruct qib_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);\r\nstruct qib_pportdata *ppd = ppd_from_ibp(ibp);\r\nu64 pbc;\r\nu16 lrh0;\r\nu32 bth0;\r\nu32 hwords;\r\nu32 pbufn;\r\nu32 __iomem *piobuf;\r\nstruct qib_ib_header hdr;\r\nstruct qib_other_headers *ohdr;\r\nu32 control;\r\nunsigned long flags;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif (!(ib_qib_state_ops[qp->state] & QIB_PROCESS_RECV_OK))\r\ngoto unlock;\r\nif ((qp->s_flags & QIB_S_RESP_PENDING) || qp->s_rdma_ack_cnt)\r\ngoto queue_ack;\r\nohdr = &hdr.u.oth;\r\nlrh0 = QIB_LRH_BTH;\r\nhwords = 6;\r\nif (unlikely(qp->remote_ah_attr.ah_flags & IB_AH_GRH)) {\r\nhwords += qib_make_grh(ibp, &hdr.u.l.grh,\r\n&qp->remote_ah_attr.grh, hwords, 0);\r\nohdr = &hdr.u.l.oth;\r\nlrh0 = QIB_LRH_GRH;\r\n}\r\nbth0 = qib_get_pkey(ibp, qp->s_pkey_index) | (OP(ACKNOWLEDGE) << 24);\r\nif (qp->s_mig_state == IB_MIG_MIGRATED)\r\nbth0 |= IB_BTH_MIG_REQ;\r\nif (qp->r_nak_state)\r\nohdr->u.aeth = cpu_to_be32((qp->r_msn & QIB_MSN_MASK) |\r\n(qp->r_nak_state <<\r\nQIB_AETH_CREDIT_SHIFT));\r\nelse\r\nohdr->u.aeth = qib_compute_aeth(qp);\r\nlrh0 |= ibp->sl_to_vl[qp->remote_ah_attr.sl] << 12 |\r\nqp->remote_ah_attr.sl << 4;\r\nhdr.lrh[0] = cpu_to_be16(lrh0);\r\nhdr.lrh[1] = cpu_to_be16(qp->remote_ah_attr.dlid);\r\nhdr.lrh[2] = cpu_to_be16(hwords + SIZE_OF_CRC);\r\nhdr.lrh[3] = cpu_to_be16(ppd->lid | qp->remote_ah_attr.src_path_bits);\r\nohdr->bth[0] = cpu_to_be32(bth0);\r\nohdr->bth[1] = cpu_to_be32(qp->remote_qpn);\r\nohdr->bth[2] = cpu_to_be32(qp->r_ack_psn & QIB_PSN_MASK);\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nif (!(ppd->lflags & QIBL_LINKACTIVE))\r\ngoto done;\r\ncontrol = dd->f_setpbc_control(ppd, hwords + SIZE_OF_CRC,\r\nqp->s_srate, lrh0 >> 12);\r\npbc = ((u64) control << 32) | (hwords + 1);\r\npiobuf = dd->f_getsendbuf(ppd, pbc, &pbufn);\r\nif (!piobuf) {\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\ngoto queue_ack;\r\n}\r\nwriteq(pbc, piobuf);\r\nif (dd->flags & QIB_PIO_FLUSH_WC) {\r\nu32 *hdrp = (u32 *) &hdr;\r\nqib_flush_wc();\r\nqib_pio_copy(piobuf + 2, hdrp, hwords - 1);\r\nqib_flush_wc();\r\n__raw_writel(hdrp[hwords - 1], piobuf + hwords + 1);\r\n} else\r\nqib_pio_copy(piobuf + 2, (u32 *) &hdr, hwords);\r\nif (dd->flags & QIB_USE_SPCL_TRIG) {\r\nu32 spcl_off = (pbufn >= dd->piobcnt2k) ? 2047 : 1023;\r\nqib_flush_wc();\r\n__raw_writel(0xaebecede, piobuf + spcl_off);\r\n}\r\nqib_flush_wc();\r\nqib_sendbuf_done(dd, pbufn);\r\nibp->n_unicast_xmit++;\r\ngoto done;\r\nqueue_ack:\r\nif (ib_qib_state_ops[qp->state] & QIB_PROCESS_RECV_OK) {\r\nibp->n_rc_qacks++;\r\nqp->s_flags |= QIB_S_ACK_PENDING | QIB_S_RESP_PENDING;\r\nqp->s_nak_state = qp->r_nak_state;\r\nqp->s_ack_psn = qp->r_ack_psn;\r\nqib_schedule_send(qp);\r\n}\r\nunlock:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\ndone:\r\nreturn;\r\n}\r\nstatic void reset_psn(struct qib_qp *qp, u32 psn)\r\n{\r\nu32 n = qp->s_acked;\r\nstruct qib_swqe *wqe = get_swqe_ptr(qp, n);\r\nu32 opcode;\r\nqp->s_cur = n;\r\nif (qib_cmp24(psn, wqe->psn) <= 0) {\r\nqp->s_state = OP(SEND_LAST);\r\ngoto done;\r\n}\r\nopcode = wqe->wr.opcode;\r\nfor (;;) {\r\nint diff;\r\nif (++n == qp->s_size)\r\nn = 0;\r\nif (n == qp->s_tail)\r\nbreak;\r\nwqe = get_swqe_ptr(qp, n);\r\ndiff = qib_cmp24(psn, wqe->psn);\r\nif (diff < 0)\r\nbreak;\r\nqp->s_cur = n;\r\nif (diff == 0) {\r\nqp->s_state = OP(SEND_LAST);\r\ngoto done;\r\n}\r\nopcode = wqe->wr.opcode;\r\n}\r\nswitch (opcode) {\r\ncase IB_WR_SEND:\r\ncase IB_WR_SEND_WITH_IMM:\r\nqp->s_state = OP(RDMA_READ_RESPONSE_FIRST);\r\nbreak;\r\ncase IB_WR_RDMA_WRITE:\r\ncase IB_WR_RDMA_WRITE_WITH_IMM:\r\nqp->s_state = OP(RDMA_READ_RESPONSE_LAST);\r\nbreak;\r\ncase IB_WR_RDMA_READ:\r\nqp->s_state = OP(RDMA_READ_RESPONSE_MIDDLE);\r\nbreak;\r\ndefault:\r\nqp->s_state = OP(SEND_LAST);\r\n}\r\ndone:\r\nqp->s_psn = psn;\r\nif ((qib_cmp24(qp->s_psn, qp->s_sending_hpsn) <= 0) &&\r\n(qib_cmp24(qp->s_sending_psn, qp->s_sending_hpsn) <= 0))\r\nqp->s_flags |= QIB_S_WAIT_PSN;\r\n}\r\nstatic void qib_restart_rc(struct qib_qp *qp, u32 psn, int wait)\r\n{\r\nstruct qib_swqe *wqe = get_swqe_ptr(qp, qp->s_acked);\r\nstruct qib_ibport *ibp;\r\nif (qp->s_retry == 0) {\r\nif (qp->s_mig_state == IB_MIG_ARMED) {\r\nqib_migrate_qp(qp);\r\nqp->s_retry = qp->s_retry_cnt;\r\n} else if (qp->s_last == qp->s_acked) {\r\nqib_send_complete(qp, wqe, IB_WC_RETRY_EXC_ERR);\r\nqib_error_qp(qp, IB_WC_WR_FLUSH_ERR);\r\nreturn;\r\n} else\r\nreturn;\r\n} else\r\nqp->s_retry--;\r\nibp = to_iport(qp->ibqp.device, qp->port_num);\r\nif (wqe->wr.opcode == IB_WR_RDMA_READ)\r\nibp->n_rc_resends++;\r\nelse\r\nibp->n_rc_resends += (qp->s_psn - psn) & QIB_PSN_MASK;\r\nqp->s_flags &= ~(QIB_S_WAIT_FENCE | QIB_S_WAIT_RDMAR |\r\nQIB_S_WAIT_SSN_CREDIT | QIB_S_WAIT_PSN |\r\nQIB_S_WAIT_ACK);\r\nif (wait)\r\nqp->s_flags |= QIB_S_SEND_ONE;\r\nreset_psn(qp, psn);\r\n}\r\nstatic void rc_timeout(unsigned long arg)\r\n{\r\nstruct qib_qp *qp = (struct qib_qp *)arg;\r\nstruct qib_ibport *ibp;\r\nunsigned long flags;\r\nspin_lock_irqsave(&qp->r_lock, flags);\r\nspin_lock(&qp->s_lock);\r\nif (qp->s_flags & QIB_S_TIMER) {\r\nibp = to_iport(qp->ibqp.device, qp->port_num);\r\nibp->n_rc_timeouts++;\r\nqp->s_flags &= ~QIB_S_TIMER;\r\ndel_timer(&qp->s_timer);\r\nqib_restart_rc(qp, qp->s_last_psn + 1, 1);\r\nqib_schedule_send(qp);\r\n}\r\nspin_unlock(&qp->s_lock);\r\nspin_unlock_irqrestore(&qp->r_lock, flags);\r\n}\r\nvoid qib_rc_rnr_retry(unsigned long arg)\r\n{\r\nstruct qib_qp *qp = (struct qib_qp *)arg;\r\nunsigned long flags;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif (qp->s_flags & QIB_S_WAIT_RNR) {\r\nqp->s_flags &= ~QIB_S_WAIT_RNR;\r\ndel_timer(&qp->s_timer);\r\nqib_schedule_send(qp);\r\n}\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\n}\r\nstatic void reset_sending_psn(struct qib_qp *qp, u32 psn)\r\n{\r\nstruct qib_swqe *wqe;\r\nu32 n = qp->s_last;\r\nfor (;;) {\r\nwqe = get_swqe_ptr(qp, n);\r\nif (qib_cmp24(psn, wqe->lpsn) <= 0) {\r\nif (wqe->wr.opcode == IB_WR_RDMA_READ)\r\nqp->s_sending_psn = wqe->lpsn + 1;\r\nelse\r\nqp->s_sending_psn = psn + 1;\r\nbreak;\r\n}\r\nif (++n == qp->s_size)\r\nn = 0;\r\nif (n == qp->s_tail)\r\nbreak;\r\n}\r\n}\r\nvoid qib_rc_send_complete(struct qib_qp *qp, struct qib_ib_header *hdr)\r\n{\r\nstruct qib_other_headers *ohdr;\r\nstruct qib_swqe *wqe;\r\nstruct ib_wc wc;\r\nunsigned i;\r\nu32 opcode;\r\nu32 psn;\r\nif (!(ib_qib_state_ops[qp->state] & QIB_PROCESS_OR_FLUSH_SEND))\r\nreturn;\r\nif ((be16_to_cpu(hdr->lrh[0]) & 3) == QIB_LRH_BTH)\r\nohdr = &hdr->u.oth;\r\nelse\r\nohdr = &hdr->u.l.oth;\r\nopcode = be32_to_cpu(ohdr->bth[0]) >> 24;\r\nif (opcode >= OP(RDMA_READ_RESPONSE_FIRST) &&\r\nopcode <= OP(ATOMIC_ACKNOWLEDGE)) {\r\nWARN_ON(!qp->s_rdma_ack_cnt);\r\nqp->s_rdma_ack_cnt--;\r\nreturn;\r\n}\r\npsn = be32_to_cpu(ohdr->bth[2]);\r\nreset_sending_psn(qp, psn);\r\nif ((psn & IB_BTH_REQ_ACK) && qp->s_acked != qp->s_tail &&\r\n!(qp->s_flags & (QIB_S_TIMER | QIB_S_WAIT_RNR | QIB_S_WAIT_PSN)) &&\r\n(ib_qib_state_ops[qp->state] & QIB_PROCESS_RECV_OK))\r\nstart_timer(qp);\r\nwhile (qp->s_last != qp->s_acked) {\r\nwqe = get_swqe_ptr(qp, qp->s_last);\r\nif (qib_cmp24(wqe->lpsn, qp->s_sending_psn) >= 0 &&\r\nqib_cmp24(qp->s_sending_psn, qp->s_sending_hpsn) <= 0)\r\nbreak;\r\nfor (i = 0; i < wqe->wr.num_sge; i++) {\r\nstruct qib_sge *sge = &wqe->sg_list[i];\r\natomic_dec(&sge->mr->refcount);\r\n}\r\nif (!(qp->s_flags & QIB_S_SIGNAL_REQ_WR) ||\r\n(wqe->wr.send_flags & IB_SEND_SIGNALED)) {\r\nmemset(&wc, 0, sizeof wc);\r\nwc.wr_id = wqe->wr.wr_id;\r\nwc.status = IB_WC_SUCCESS;\r\nwc.opcode = ib_qib_wc_opcode[wqe->wr.opcode];\r\nwc.byte_len = wqe->length;\r\nwc.qp = &qp->ibqp;\r\nqib_cq_enter(to_icq(qp->ibqp.send_cq), &wc, 0);\r\n}\r\nif (++qp->s_last >= qp->s_size)\r\nqp->s_last = 0;\r\n}\r\nif (qp->s_flags & QIB_S_WAIT_PSN &&\r\nqib_cmp24(qp->s_sending_psn, qp->s_sending_hpsn) > 0) {\r\nqp->s_flags &= ~QIB_S_WAIT_PSN;\r\nqp->s_sending_psn = qp->s_psn;\r\nqp->s_sending_hpsn = qp->s_psn - 1;\r\nqib_schedule_send(qp);\r\n}\r\n}\r\nstatic inline void update_last_psn(struct qib_qp *qp, u32 psn)\r\n{\r\nqp->s_last_psn = psn;\r\n}\r\nstatic struct qib_swqe *do_rc_completion(struct qib_qp *qp,\r\nstruct qib_swqe *wqe,\r\nstruct qib_ibport *ibp)\r\n{\r\nstruct ib_wc wc;\r\nunsigned i;\r\nif (qib_cmp24(wqe->lpsn, qp->s_sending_psn) < 0 ||\r\nqib_cmp24(qp->s_sending_psn, qp->s_sending_hpsn) > 0) {\r\nfor (i = 0; i < wqe->wr.num_sge; i++) {\r\nstruct qib_sge *sge = &wqe->sg_list[i];\r\natomic_dec(&sge->mr->refcount);\r\n}\r\nif (!(qp->s_flags & QIB_S_SIGNAL_REQ_WR) ||\r\n(wqe->wr.send_flags & IB_SEND_SIGNALED)) {\r\nmemset(&wc, 0, sizeof wc);\r\nwc.wr_id = wqe->wr.wr_id;\r\nwc.status = IB_WC_SUCCESS;\r\nwc.opcode = ib_qib_wc_opcode[wqe->wr.opcode];\r\nwc.byte_len = wqe->length;\r\nwc.qp = &qp->ibqp;\r\nqib_cq_enter(to_icq(qp->ibqp.send_cq), &wc, 0);\r\n}\r\nif (++qp->s_last >= qp->s_size)\r\nqp->s_last = 0;\r\n} else\r\nibp->n_rc_delayed_comp++;\r\nqp->s_retry = qp->s_retry_cnt;\r\nupdate_last_psn(qp, wqe->lpsn);\r\nif (qp->s_acked == qp->s_cur) {\r\nif (++qp->s_cur >= qp->s_size)\r\nqp->s_cur = 0;\r\nqp->s_acked = qp->s_cur;\r\nwqe = get_swqe_ptr(qp, qp->s_cur);\r\nif (qp->s_acked != qp->s_tail) {\r\nqp->s_state = OP(SEND_LAST);\r\nqp->s_psn = wqe->psn;\r\n}\r\n} else {\r\nif (++qp->s_acked >= qp->s_size)\r\nqp->s_acked = 0;\r\nif (qp->state == IB_QPS_SQD && qp->s_acked == qp->s_cur)\r\nqp->s_draining = 0;\r\nwqe = get_swqe_ptr(qp, qp->s_acked);\r\n}\r\nreturn wqe;\r\n}\r\nstatic int do_rc_ack(struct qib_qp *qp, u32 aeth, u32 psn, int opcode,\r\nu64 val, struct qib_ctxtdata *rcd)\r\n{\r\nstruct qib_ibport *ibp;\r\nenum ib_wc_status status;\r\nstruct qib_swqe *wqe;\r\nint ret = 0;\r\nu32 ack_psn;\r\nint diff;\r\nif (qp->s_flags & (QIB_S_TIMER | QIB_S_WAIT_RNR)) {\r\nqp->s_flags &= ~(QIB_S_TIMER | QIB_S_WAIT_RNR);\r\ndel_timer(&qp->s_timer);\r\n}\r\nack_psn = psn;\r\nif (aeth >> 29)\r\nack_psn--;\r\nwqe = get_swqe_ptr(qp, qp->s_acked);\r\nibp = to_iport(qp->ibqp.device, qp->port_num);\r\nwhile ((diff = qib_cmp24(ack_psn, wqe->lpsn)) >= 0) {\r\nif (wqe->wr.opcode == IB_WR_RDMA_READ &&\r\nopcode == OP(RDMA_READ_RESPONSE_ONLY) &&\r\ndiff == 0) {\r\nret = 1;\r\ngoto bail;\r\n}\r\nif ((wqe->wr.opcode == IB_WR_RDMA_READ &&\r\n(opcode != OP(RDMA_READ_RESPONSE_LAST) || diff != 0)) ||\r\n((wqe->wr.opcode == IB_WR_ATOMIC_CMP_AND_SWP ||\r\nwqe->wr.opcode == IB_WR_ATOMIC_FETCH_AND_ADD) &&\r\n(opcode != OP(ATOMIC_ACKNOWLEDGE) || diff != 0))) {\r\nif (!(qp->r_flags & QIB_R_RDMAR_SEQ)) {\r\nqp->r_flags |= QIB_R_RDMAR_SEQ;\r\nqib_restart_rc(qp, qp->s_last_psn + 1, 0);\r\nif (list_empty(&qp->rspwait)) {\r\nqp->r_flags |= QIB_R_RSP_SEND;\r\natomic_inc(&qp->refcount);\r\nlist_add_tail(&qp->rspwait,\r\n&rcd->qp_wait_list);\r\n}\r\n}\r\ngoto bail;\r\n}\r\nif (wqe->wr.opcode == IB_WR_ATOMIC_CMP_AND_SWP ||\r\nwqe->wr.opcode == IB_WR_ATOMIC_FETCH_AND_ADD) {\r\nu64 *vaddr = wqe->sg_list[0].vaddr;\r\n*vaddr = val;\r\n}\r\nif (qp->s_num_rd_atomic &&\r\n(wqe->wr.opcode == IB_WR_RDMA_READ ||\r\nwqe->wr.opcode == IB_WR_ATOMIC_CMP_AND_SWP ||\r\nwqe->wr.opcode == IB_WR_ATOMIC_FETCH_AND_ADD)) {\r\nqp->s_num_rd_atomic--;\r\nif ((qp->s_flags & QIB_S_WAIT_FENCE) &&\r\n!qp->s_num_rd_atomic) {\r\nqp->s_flags &= ~(QIB_S_WAIT_FENCE |\r\nQIB_S_WAIT_ACK);\r\nqib_schedule_send(qp);\r\n} else if (qp->s_flags & QIB_S_WAIT_RDMAR) {\r\nqp->s_flags &= ~(QIB_S_WAIT_RDMAR |\r\nQIB_S_WAIT_ACK);\r\nqib_schedule_send(qp);\r\n}\r\n}\r\nwqe = do_rc_completion(qp, wqe, ibp);\r\nif (qp->s_acked == qp->s_tail)\r\nbreak;\r\n}\r\nswitch (aeth >> 29) {\r\ncase 0:\r\nibp->n_rc_acks++;\r\nif (qp->s_acked != qp->s_tail) {\r\nstart_timer(qp);\r\nif (qib_cmp24(qp->s_psn, psn) <= 0)\r\nreset_psn(qp, psn + 1);\r\n} else if (qib_cmp24(qp->s_psn, psn) <= 0) {\r\nqp->s_state = OP(SEND_LAST);\r\nqp->s_psn = psn + 1;\r\n}\r\nif (qp->s_flags & QIB_S_WAIT_ACK) {\r\nqp->s_flags &= ~QIB_S_WAIT_ACK;\r\nqib_schedule_send(qp);\r\n}\r\nqib_get_credit(qp, aeth);\r\nqp->s_rnr_retry = qp->s_rnr_retry_cnt;\r\nqp->s_retry = qp->s_retry_cnt;\r\nupdate_last_psn(qp, psn);\r\nret = 1;\r\ngoto bail;\r\ncase 1:\r\nibp->n_rnr_naks++;\r\nif (qp->s_acked == qp->s_tail)\r\ngoto bail;\r\nif (qp->s_flags & QIB_S_WAIT_RNR)\r\ngoto bail;\r\nif (qp->s_rnr_retry == 0) {\r\nstatus = IB_WC_RNR_RETRY_EXC_ERR;\r\ngoto class_b;\r\n}\r\nif (qp->s_rnr_retry_cnt < 7)\r\nqp->s_rnr_retry--;\r\nupdate_last_psn(qp, psn - 1);\r\nibp->n_rc_resends += (qp->s_psn - psn) & QIB_PSN_MASK;\r\nreset_psn(qp, psn);\r\nqp->s_flags &= ~(QIB_S_WAIT_SSN_CREDIT | QIB_S_WAIT_ACK);\r\nqp->s_flags |= QIB_S_WAIT_RNR;\r\nqp->s_timer.function = qib_rc_rnr_retry;\r\nqp->s_timer.expires = jiffies + usecs_to_jiffies(\r\nib_qib_rnr_table[(aeth >> QIB_AETH_CREDIT_SHIFT) &\r\nQIB_AETH_CREDIT_MASK]);\r\nadd_timer(&qp->s_timer);\r\ngoto bail;\r\ncase 3:\r\nif (qp->s_acked == qp->s_tail)\r\ngoto bail;\r\nupdate_last_psn(qp, psn - 1);\r\nswitch ((aeth >> QIB_AETH_CREDIT_SHIFT) &\r\nQIB_AETH_CREDIT_MASK) {\r\ncase 0:\r\nibp->n_seq_naks++;\r\nqib_restart_rc(qp, psn, 0);\r\nqib_schedule_send(qp);\r\nbreak;\r\ncase 1:\r\nstatus = IB_WC_REM_INV_REQ_ERR;\r\nibp->n_other_naks++;\r\ngoto class_b;\r\ncase 2:\r\nstatus = IB_WC_REM_ACCESS_ERR;\r\nibp->n_other_naks++;\r\ngoto class_b;\r\ncase 3:\r\nstatus = IB_WC_REM_OP_ERR;\r\nibp->n_other_naks++;\r\nclass_b:\r\nif (qp->s_last == qp->s_acked) {\r\nqib_send_complete(qp, wqe, status);\r\nqib_error_qp(qp, IB_WC_WR_FLUSH_ERR);\r\n}\r\nbreak;\r\ndefault:\r\ngoto reserved;\r\n}\r\nqp->s_retry = qp->s_retry_cnt;\r\nqp->s_rnr_retry = qp->s_rnr_retry_cnt;\r\ngoto bail;\r\ndefault:\r\nreserved:\r\ngoto bail;\r\n}\r\nbail:\r\nreturn ret;\r\n}\r\nstatic void rdma_seq_err(struct qib_qp *qp, struct qib_ibport *ibp, u32 psn,\r\nstruct qib_ctxtdata *rcd)\r\n{\r\nstruct qib_swqe *wqe;\r\nif (qp->s_flags & (QIB_S_TIMER | QIB_S_WAIT_RNR)) {\r\nqp->s_flags &= ~(QIB_S_TIMER | QIB_S_WAIT_RNR);\r\ndel_timer(&qp->s_timer);\r\n}\r\nwqe = get_swqe_ptr(qp, qp->s_acked);\r\nwhile (qib_cmp24(psn, wqe->lpsn) > 0) {\r\nif (wqe->wr.opcode == IB_WR_RDMA_READ ||\r\nwqe->wr.opcode == IB_WR_ATOMIC_CMP_AND_SWP ||\r\nwqe->wr.opcode == IB_WR_ATOMIC_FETCH_AND_ADD)\r\nbreak;\r\nwqe = do_rc_completion(qp, wqe, ibp);\r\n}\r\nibp->n_rdma_seq++;\r\nqp->r_flags |= QIB_R_RDMAR_SEQ;\r\nqib_restart_rc(qp, qp->s_last_psn + 1, 0);\r\nif (list_empty(&qp->rspwait)) {\r\nqp->r_flags |= QIB_R_RSP_SEND;\r\natomic_inc(&qp->refcount);\r\nlist_add_tail(&qp->rspwait, &rcd->qp_wait_list);\r\n}\r\n}\r\nstatic void qib_rc_rcv_resp(struct qib_ibport *ibp,\r\nstruct qib_other_headers *ohdr,\r\nvoid *data, u32 tlen,\r\nstruct qib_qp *qp,\r\nu32 opcode,\r\nu32 psn, u32 hdrsize, u32 pmtu,\r\nstruct qib_ctxtdata *rcd)\r\n{\r\nstruct qib_swqe *wqe;\r\nstruct qib_pportdata *ppd = ppd_from_ibp(ibp);\r\nenum ib_wc_status status;\r\nunsigned long flags;\r\nint diff;\r\nu32 pad;\r\nu32 aeth;\r\nu64 val;\r\nif (opcode != OP(RDMA_READ_RESPONSE_MIDDLE)) {\r\nif ((qib_cmp24(psn, qp->s_sending_psn) >= 0) &&\r\n(qib_cmp24(qp->s_sending_psn, qp->s_sending_hpsn) <= 0)) {\r\nif (!(qp->s_flags & QIB_S_BUSY)) {\r\nspin_lock_irqsave(&ppd->sdma_lock, flags);\r\nqib_sdma_make_progress(ppd);\r\nspin_unlock_irqrestore(&ppd->sdma_lock, flags);\r\n}\r\n}\r\n}\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif (!(ib_qib_state_ops[qp->state] & QIB_PROCESS_RECV_OK))\r\ngoto ack_done;\r\nif (qib_cmp24(psn, qp->s_next_psn) >= 0)\r\ngoto ack_done;\r\ndiff = qib_cmp24(psn, qp->s_last_psn);\r\nif (unlikely(diff <= 0)) {\r\nif (diff == 0 && opcode == OP(ACKNOWLEDGE)) {\r\naeth = be32_to_cpu(ohdr->u.aeth);\r\nif ((aeth >> 29) == 0)\r\nqib_get_credit(qp, aeth);\r\n}\r\ngoto ack_done;\r\n}\r\nif (qp->r_flags & QIB_R_RDMAR_SEQ) {\r\nif (qib_cmp24(psn, qp->s_last_psn + 1) != 0)\r\ngoto ack_done;\r\nqp->r_flags &= ~QIB_R_RDMAR_SEQ;\r\n}\r\nif (unlikely(qp->s_acked == qp->s_tail))\r\ngoto ack_done;\r\nwqe = get_swqe_ptr(qp, qp->s_acked);\r\nstatus = IB_WC_SUCCESS;\r\nswitch (opcode) {\r\ncase OP(ACKNOWLEDGE):\r\ncase OP(ATOMIC_ACKNOWLEDGE):\r\ncase OP(RDMA_READ_RESPONSE_FIRST):\r\naeth = be32_to_cpu(ohdr->u.aeth);\r\nif (opcode == OP(ATOMIC_ACKNOWLEDGE)) {\r\n__be32 *p = ohdr->u.at.atomic_ack_eth;\r\nval = ((u64) be32_to_cpu(p[0]) << 32) |\r\nbe32_to_cpu(p[1]);\r\n} else\r\nval = 0;\r\nif (!do_rc_ack(qp, aeth, psn, opcode, val, rcd) ||\r\nopcode != OP(RDMA_READ_RESPONSE_FIRST))\r\ngoto ack_done;\r\nhdrsize += 4;\r\nwqe = get_swqe_ptr(qp, qp->s_acked);\r\nif (unlikely(wqe->wr.opcode != IB_WR_RDMA_READ))\r\ngoto ack_op_err;\r\nqp->s_rdma_read_len = restart_sge(&qp->s_rdma_read_sge,\r\nwqe, psn, pmtu);\r\ngoto read_middle;\r\ncase OP(RDMA_READ_RESPONSE_MIDDLE):\r\nif (unlikely(qib_cmp24(psn, qp->s_last_psn + 1)))\r\ngoto ack_seq_err;\r\nif (unlikely(wqe->wr.opcode != IB_WR_RDMA_READ))\r\ngoto ack_op_err;\r\nread_middle:\r\nif (unlikely(tlen != (hdrsize + pmtu + 4)))\r\ngoto ack_len_err;\r\nif (unlikely(pmtu >= qp->s_rdma_read_len))\r\ngoto ack_len_err;\r\nqp->s_flags |= QIB_S_TIMER;\r\nmod_timer(&qp->s_timer, jiffies + qp->timeout_jiffies);\r\nif (qp->s_flags & QIB_S_WAIT_ACK) {\r\nqp->s_flags &= ~QIB_S_WAIT_ACK;\r\nqib_schedule_send(qp);\r\n}\r\nif (opcode == OP(RDMA_READ_RESPONSE_MIDDLE))\r\nqp->s_retry = qp->s_retry_cnt;\r\nqp->s_rdma_read_len -= pmtu;\r\nupdate_last_psn(qp, psn);\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nqib_copy_sge(&qp->s_rdma_read_sge, data, pmtu, 0);\r\ngoto bail;\r\ncase OP(RDMA_READ_RESPONSE_ONLY):\r\naeth = be32_to_cpu(ohdr->u.aeth);\r\nif (!do_rc_ack(qp, aeth, psn, opcode, 0, rcd))\r\ngoto ack_done;\r\npad = (be32_to_cpu(ohdr->bth[0]) >> 20) & 3;\r\nif (unlikely(tlen < (hdrsize + pad + 8)))\r\ngoto ack_len_err;\r\nwqe = get_swqe_ptr(qp, qp->s_acked);\r\nqp->s_rdma_read_len = restart_sge(&qp->s_rdma_read_sge,\r\nwqe, psn, pmtu);\r\ngoto read_last;\r\ncase OP(RDMA_READ_RESPONSE_LAST):\r\nif (unlikely(qib_cmp24(psn, qp->s_last_psn + 1)))\r\ngoto ack_seq_err;\r\nif (unlikely(wqe->wr.opcode != IB_WR_RDMA_READ))\r\ngoto ack_op_err;\r\npad = (be32_to_cpu(ohdr->bth[0]) >> 20) & 3;\r\nif (unlikely(tlen <= (hdrsize + pad + 8)))\r\ngoto ack_len_err;\r\nread_last:\r\ntlen -= hdrsize + pad + 8;\r\nif (unlikely(tlen != qp->s_rdma_read_len))\r\ngoto ack_len_err;\r\naeth = be32_to_cpu(ohdr->u.aeth);\r\nqib_copy_sge(&qp->s_rdma_read_sge, data, tlen, 0);\r\nWARN_ON(qp->s_rdma_read_sge.num_sge);\r\n(void) do_rc_ack(qp, aeth, psn,\r\nOP(RDMA_READ_RESPONSE_LAST), 0, rcd);\r\ngoto ack_done;\r\n}\r\nack_op_err:\r\nstatus = IB_WC_LOC_QP_OP_ERR;\r\ngoto ack_err;\r\nack_seq_err:\r\nrdma_seq_err(qp, ibp, psn, rcd);\r\ngoto ack_done;\r\nack_len_err:\r\nstatus = IB_WC_LOC_LEN_ERR;\r\nack_err:\r\nif (qp->s_last == qp->s_acked) {\r\nqib_send_complete(qp, wqe, status);\r\nqib_error_qp(qp, IB_WC_WR_FLUSH_ERR);\r\n}\r\nack_done:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nbail:\r\nreturn;\r\n}\r\nstatic int qib_rc_rcv_error(struct qib_other_headers *ohdr,\r\nvoid *data,\r\nstruct qib_qp *qp,\r\nu32 opcode,\r\nu32 psn,\r\nint diff,\r\nstruct qib_ctxtdata *rcd)\r\n{\r\nstruct qib_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);\r\nstruct qib_ack_entry *e;\r\nunsigned long flags;\r\nu8 i, prev;\r\nint old_req;\r\nif (diff > 0) {\r\nif (!qp->r_nak_state) {\r\nibp->n_rc_seqnak++;\r\nqp->r_nak_state = IB_NAK_PSN_ERROR;\r\nqp->r_ack_psn = qp->r_psn;\r\nif (list_empty(&qp->rspwait)) {\r\nqp->r_flags |= QIB_R_RSP_NAK;\r\natomic_inc(&qp->refcount);\r\nlist_add_tail(&qp->rspwait, &rcd->qp_wait_list);\r\n}\r\n}\r\ngoto done;\r\n}\r\ne = NULL;\r\nold_req = 1;\r\nibp->n_rc_dupreq++;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nfor (i = qp->r_head_ack_queue; ; i = prev) {\r\nif (i == qp->s_tail_ack_queue)\r\nold_req = 0;\r\nif (i)\r\nprev = i - 1;\r\nelse\r\nprev = QIB_MAX_RDMA_ATOMIC;\r\nif (prev == qp->r_head_ack_queue) {\r\ne = NULL;\r\nbreak;\r\n}\r\ne = &qp->s_ack_queue[prev];\r\nif (!e->opcode) {\r\ne = NULL;\r\nbreak;\r\n}\r\nif (qib_cmp24(psn, e->psn) >= 0) {\r\nif (prev == qp->s_tail_ack_queue &&\r\nqib_cmp24(psn, e->lpsn) <= 0)\r\nold_req = 0;\r\nbreak;\r\n}\r\n}\r\nswitch (opcode) {\r\ncase OP(RDMA_READ_REQUEST): {\r\nstruct ib_reth *reth;\r\nu32 offset;\r\nu32 len;\r\nif (!e || e->opcode != OP(RDMA_READ_REQUEST))\r\ngoto unlock_done;\r\nreth = &ohdr->u.rc.reth;\r\noffset = ((psn - e->psn) & QIB_PSN_MASK) *\r\nqp->pmtu;\r\nlen = be32_to_cpu(reth->length);\r\nif (unlikely(offset + len != e->rdma_sge.sge_length))\r\ngoto unlock_done;\r\nif (e->rdma_sge.mr) {\r\natomic_dec(&e->rdma_sge.mr->refcount);\r\ne->rdma_sge.mr = NULL;\r\n}\r\nif (len != 0) {\r\nu32 rkey = be32_to_cpu(reth->rkey);\r\nu64 vaddr = be64_to_cpu(reth->vaddr);\r\nint ok;\r\nok = qib_rkey_ok(qp, &e->rdma_sge, len, vaddr, rkey,\r\nIB_ACCESS_REMOTE_READ);\r\nif (unlikely(!ok))\r\ngoto unlock_done;\r\n} else {\r\ne->rdma_sge.vaddr = NULL;\r\ne->rdma_sge.length = 0;\r\ne->rdma_sge.sge_length = 0;\r\n}\r\ne->psn = psn;\r\nif (old_req)\r\ngoto unlock_done;\r\nqp->s_tail_ack_queue = prev;\r\nbreak;\r\n}\r\ncase OP(COMPARE_SWAP):\r\ncase OP(FETCH_ADD): {\r\nif (!e || e->opcode != (u8) opcode || old_req)\r\ngoto unlock_done;\r\nqp->s_tail_ack_queue = prev;\r\nbreak;\r\n}\r\ndefault:\r\nif (!(psn & IB_BTH_REQ_ACK) || old_req)\r\ngoto unlock_done;\r\nif (i == qp->r_head_ack_queue) {\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nqp->r_nak_state = 0;\r\nqp->r_ack_psn = qp->r_psn - 1;\r\ngoto send_ack;\r\n}\r\nif (!(qp->s_flags & QIB_S_RESP_PENDING)) {\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nqp->r_nak_state = 0;\r\nqp->r_ack_psn = qp->s_ack_queue[i].psn - 1;\r\ngoto send_ack;\r\n}\r\nqp->s_tail_ack_queue = i;\r\nbreak;\r\n}\r\nqp->s_ack_state = OP(ACKNOWLEDGE);\r\nqp->s_flags |= QIB_S_RESP_PENDING;\r\nqp->r_nak_state = 0;\r\nqib_schedule_send(qp);\r\nunlock_done:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\ndone:\r\nreturn 1;\r\nsend_ack:\r\nreturn 0;\r\n}\r\nvoid qib_rc_error(struct qib_qp *qp, enum ib_wc_status err)\r\n{\r\nunsigned long flags;\r\nint lastwqe;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nlastwqe = qib_error_qp(qp, err);\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nif (lastwqe) {\r\nstruct ib_event ev;\r\nev.device = qp->ibqp.device;\r\nev.element.qp = &qp->ibqp;\r\nev.event = IB_EVENT_QP_LAST_WQE_REACHED;\r\nqp->ibqp.event_handler(&ev, qp->ibqp.qp_context);\r\n}\r\n}\r\nstatic inline void qib_update_ack_queue(struct qib_qp *qp, unsigned n)\r\n{\r\nunsigned next;\r\nnext = n + 1;\r\nif (next > QIB_MAX_RDMA_ATOMIC)\r\nnext = 0;\r\nqp->s_tail_ack_queue = next;\r\nqp->s_ack_state = OP(ACKNOWLEDGE);\r\n}\r\nvoid qib_rc_rcv(struct qib_ctxtdata *rcd, struct qib_ib_header *hdr,\r\nint has_grh, void *data, u32 tlen, struct qib_qp *qp)\r\n{\r\nstruct qib_ibport *ibp = &rcd->ppd->ibport_data;\r\nstruct qib_other_headers *ohdr;\r\nu32 opcode;\r\nu32 hdrsize;\r\nu32 psn;\r\nu32 pad;\r\nstruct ib_wc wc;\r\nu32 pmtu = qp->pmtu;\r\nint diff;\r\nstruct ib_reth *reth;\r\nunsigned long flags;\r\nint ret;\r\nif (!has_grh) {\r\nohdr = &hdr->u.oth;\r\nhdrsize = 8 + 12;\r\n} else {\r\nohdr = &hdr->u.l.oth;\r\nhdrsize = 8 + 40 + 12;\r\n}\r\nopcode = be32_to_cpu(ohdr->bth[0]);\r\nif (qib_ruc_check_hdr(ibp, hdr, has_grh, qp, opcode))\r\nreturn;\r\npsn = be32_to_cpu(ohdr->bth[2]);\r\nopcode >>= 24;\r\nif (opcode >= OP(RDMA_READ_RESPONSE_FIRST) &&\r\nopcode <= OP(ATOMIC_ACKNOWLEDGE)) {\r\nqib_rc_rcv_resp(ibp, ohdr, data, tlen, qp, opcode, psn,\r\nhdrsize, pmtu, rcd);\r\nreturn;\r\n}\r\ndiff = qib_cmp24(psn, qp->r_psn);\r\nif (unlikely(diff)) {\r\nif (qib_rc_rcv_error(ohdr, data, qp, opcode, psn, diff, rcd))\r\nreturn;\r\ngoto send_ack;\r\n}\r\nswitch (qp->r_state) {\r\ncase OP(SEND_FIRST):\r\ncase OP(SEND_MIDDLE):\r\nif (opcode == OP(SEND_MIDDLE) ||\r\nopcode == OP(SEND_LAST) ||\r\nopcode == OP(SEND_LAST_WITH_IMMEDIATE))\r\nbreak;\r\ngoto nack_inv;\r\ncase OP(RDMA_WRITE_FIRST):\r\ncase OP(RDMA_WRITE_MIDDLE):\r\nif (opcode == OP(RDMA_WRITE_MIDDLE) ||\r\nopcode == OP(RDMA_WRITE_LAST) ||\r\nopcode == OP(RDMA_WRITE_LAST_WITH_IMMEDIATE))\r\nbreak;\r\ngoto nack_inv;\r\ndefault:\r\nif (opcode == OP(SEND_MIDDLE) ||\r\nopcode == OP(SEND_LAST) ||\r\nopcode == OP(SEND_LAST_WITH_IMMEDIATE) ||\r\nopcode == OP(RDMA_WRITE_MIDDLE) ||\r\nopcode == OP(RDMA_WRITE_LAST) ||\r\nopcode == OP(RDMA_WRITE_LAST_WITH_IMMEDIATE))\r\ngoto nack_inv;\r\nbreak;\r\n}\r\nif (qp->state == IB_QPS_RTR && !(qp->r_flags & QIB_R_COMM_EST)) {\r\nqp->r_flags |= QIB_R_COMM_EST;\r\nif (qp->ibqp.event_handler) {\r\nstruct ib_event ev;\r\nev.device = qp->ibqp.device;\r\nev.element.qp = &qp->ibqp;\r\nev.event = IB_EVENT_COMM_EST;\r\nqp->ibqp.event_handler(&ev, qp->ibqp.qp_context);\r\n}\r\n}\r\nswitch (opcode) {\r\ncase OP(SEND_FIRST):\r\nret = qib_get_rwqe(qp, 0);\r\nif (ret < 0)\r\ngoto nack_op_err;\r\nif (!ret)\r\ngoto rnr_nak;\r\nqp->r_rcv_len = 0;\r\ncase OP(SEND_MIDDLE):\r\ncase OP(RDMA_WRITE_MIDDLE):\r\nsend_middle:\r\nif (unlikely(tlen != (hdrsize + pmtu + 4)))\r\ngoto nack_inv;\r\nqp->r_rcv_len += pmtu;\r\nif (unlikely(qp->r_rcv_len > qp->r_len))\r\ngoto nack_inv;\r\nqib_copy_sge(&qp->r_sge, data, pmtu, 1);\r\nbreak;\r\ncase OP(RDMA_WRITE_LAST_WITH_IMMEDIATE):\r\nret = qib_get_rwqe(qp, 1);\r\nif (ret < 0)\r\ngoto nack_op_err;\r\nif (!ret)\r\ngoto rnr_nak;\r\ngoto send_last_imm;\r\ncase OP(SEND_ONLY):\r\ncase OP(SEND_ONLY_WITH_IMMEDIATE):\r\nret = qib_get_rwqe(qp, 0);\r\nif (ret < 0)\r\ngoto nack_op_err;\r\nif (!ret)\r\ngoto rnr_nak;\r\nqp->r_rcv_len = 0;\r\nif (opcode == OP(SEND_ONLY))\r\ngoto no_immediate_data;\r\ncase OP(SEND_LAST_WITH_IMMEDIATE):\r\nsend_last_imm:\r\nwc.ex.imm_data = ohdr->u.imm_data;\r\nhdrsize += 4;\r\nwc.wc_flags = IB_WC_WITH_IMM;\r\ngoto send_last;\r\ncase OP(SEND_LAST):\r\ncase OP(RDMA_WRITE_LAST):\r\nno_immediate_data:\r\nwc.wc_flags = 0;\r\nwc.ex.imm_data = 0;\r\nsend_last:\r\npad = (be32_to_cpu(ohdr->bth[0]) >> 20) & 3;\r\nif (unlikely(tlen < (hdrsize + pad + 4)))\r\ngoto nack_inv;\r\ntlen -= (hdrsize + pad + 4);\r\nwc.byte_len = tlen + qp->r_rcv_len;\r\nif (unlikely(wc.byte_len > qp->r_len))\r\ngoto nack_inv;\r\nqib_copy_sge(&qp->r_sge, data, tlen, 1);\r\nwhile (qp->r_sge.num_sge) {\r\natomic_dec(&qp->r_sge.sge.mr->refcount);\r\nif (--qp->r_sge.num_sge)\r\nqp->r_sge.sge = *qp->r_sge.sg_list++;\r\n}\r\nqp->r_msn++;\r\nif (!test_and_clear_bit(QIB_R_WRID_VALID, &qp->r_aflags))\r\nbreak;\r\nwc.wr_id = qp->r_wr_id;\r\nwc.status = IB_WC_SUCCESS;\r\nif (opcode == OP(RDMA_WRITE_LAST_WITH_IMMEDIATE) ||\r\nopcode == OP(RDMA_WRITE_ONLY_WITH_IMMEDIATE))\r\nwc.opcode = IB_WC_RECV_RDMA_WITH_IMM;\r\nelse\r\nwc.opcode = IB_WC_RECV;\r\nwc.qp = &qp->ibqp;\r\nwc.src_qp = qp->remote_qpn;\r\nwc.slid = qp->remote_ah_attr.dlid;\r\nwc.sl = qp->remote_ah_attr.sl;\r\nwc.vendor_err = 0;\r\nwc.pkey_index = 0;\r\nwc.dlid_path_bits = 0;\r\nwc.port_num = 0;\r\nwc.csum_ok = 0;\r\nqib_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,\r\n(ohdr->bth[0] &\r\ncpu_to_be32(IB_BTH_SOLICITED)) != 0);\r\nbreak;\r\ncase OP(RDMA_WRITE_FIRST):\r\ncase OP(RDMA_WRITE_ONLY):\r\ncase OP(RDMA_WRITE_ONLY_WITH_IMMEDIATE):\r\nif (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_WRITE)))\r\ngoto nack_inv;\r\nreth = &ohdr->u.rc.reth;\r\nhdrsize += sizeof(*reth);\r\nqp->r_len = be32_to_cpu(reth->length);\r\nqp->r_rcv_len = 0;\r\nqp->r_sge.sg_list = NULL;\r\nif (qp->r_len != 0) {\r\nu32 rkey = be32_to_cpu(reth->rkey);\r\nu64 vaddr = be64_to_cpu(reth->vaddr);\r\nint ok;\r\nok = qib_rkey_ok(qp, &qp->r_sge.sge, qp->r_len, vaddr,\r\nrkey, IB_ACCESS_REMOTE_WRITE);\r\nif (unlikely(!ok))\r\ngoto nack_acc;\r\nqp->r_sge.num_sge = 1;\r\n} else {\r\nqp->r_sge.num_sge = 0;\r\nqp->r_sge.sge.mr = NULL;\r\nqp->r_sge.sge.vaddr = NULL;\r\nqp->r_sge.sge.length = 0;\r\nqp->r_sge.sge.sge_length = 0;\r\n}\r\nif (opcode == OP(RDMA_WRITE_FIRST))\r\ngoto send_middle;\r\nelse if (opcode == OP(RDMA_WRITE_ONLY))\r\ngoto no_immediate_data;\r\nret = qib_get_rwqe(qp, 1);\r\nif (ret < 0)\r\ngoto nack_op_err;\r\nif (!ret)\r\ngoto rnr_nak;\r\nwc.ex.imm_data = ohdr->u.rc.imm_data;\r\nhdrsize += 4;\r\nwc.wc_flags = IB_WC_WITH_IMM;\r\ngoto send_last;\r\ncase OP(RDMA_READ_REQUEST): {\r\nstruct qib_ack_entry *e;\r\nu32 len;\r\nu8 next;\r\nif (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_READ)))\r\ngoto nack_inv;\r\nnext = qp->r_head_ack_queue + 1;\r\nif (next > QIB_MAX_RDMA_ATOMIC)\r\nnext = 0;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif (unlikely(next == qp->s_tail_ack_queue)) {\r\nif (!qp->s_ack_queue[next].sent)\r\ngoto nack_inv_unlck;\r\nqib_update_ack_queue(qp, next);\r\n}\r\ne = &qp->s_ack_queue[qp->r_head_ack_queue];\r\nif (e->opcode == OP(RDMA_READ_REQUEST) && e->rdma_sge.mr) {\r\natomic_dec(&e->rdma_sge.mr->refcount);\r\ne->rdma_sge.mr = NULL;\r\n}\r\nreth = &ohdr->u.rc.reth;\r\nlen = be32_to_cpu(reth->length);\r\nif (len) {\r\nu32 rkey = be32_to_cpu(reth->rkey);\r\nu64 vaddr = be64_to_cpu(reth->vaddr);\r\nint ok;\r\nok = qib_rkey_ok(qp, &e->rdma_sge, len, vaddr,\r\nrkey, IB_ACCESS_REMOTE_READ);\r\nif (unlikely(!ok))\r\ngoto nack_acc_unlck;\r\nif (len > pmtu)\r\nqp->r_psn += (len - 1) / pmtu;\r\n} else {\r\ne->rdma_sge.mr = NULL;\r\ne->rdma_sge.vaddr = NULL;\r\ne->rdma_sge.length = 0;\r\ne->rdma_sge.sge_length = 0;\r\n}\r\ne->opcode = opcode;\r\ne->sent = 0;\r\ne->psn = psn;\r\ne->lpsn = qp->r_psn;\r\nqp->r_msn++;\r\nqp->r_psn++;\r\nqp->r_state = opcode;\r\nqp->r_nak_state = 0;\r\nqp->r_head_ack_queue = next;\r\nqp->s_flags |= QIB_S_RESP_PENDING;\r\nqib_schedule_send(qp);\r\ngoto sunlock;\r\n}\r\ncase OP(COMPARE_SWAP):\r\ncase OP(FETCH_ADD): {\r\nstruct ib_atomic_eth *ateth;\r\nstruct qib_ack_entry *e;\r\nu64 vaddr;\r\natomic64_t *maddr;\r\nu64 sdata;\r\nu32 rkey;\r\nu8 next;\r\nif (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_ATOMIC)))\r\ngoto nack_inv;\r\nnext = qp->r_head_ack_queue + 1;\r\nif (next > QIB_MAX_RDMA_ATOMIC)\r\nnext = 0;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif (unlikely(next == qp->s_tail_ack_queue)) {\r\nif (!qp->s_ack_queue[next].sent)\r\ngoto nack_inv_unlck;\r\nqib_update_ack_queue(qp, next);\r\n}\r\ne = &qp->s_ack_queue[qp->r_head_ack_queue];\r\nif (e->opcode == OP(RDMA_READ_REQUEST) && e->rdma_sge.mr) {\r\natomic_dec(&e->rdma_sge.mr->refcount);\r\ne->rdma_sge.mr = NULL;\r\n}\r\nateth = &ohdr->u.atomic_eth;\r\nvaddr = ((u64) be32_to_cpu(ateth->vaddr[0]) << 32) |\r\nbe32_to_cpu(ateth->vaddr[1]);\r\nif (unlikely(vaddr & (sizeof(u64) - 1)))\r\ngoto nack_inv_unlck;\r\nrkey = be32_to_cpu(ateth->rkey);\r\nif (unlikely(!qib_rkey_ok(qp, &qp->r_sge.sge, sizeof(u64),\r\nvaddr, rkey,\r\nIB_ACCESS_REMOTE_ATOMIC)))\r\ngoto nack_acc_unlck;\r\nmaddr = (atomic64_t *) qp->r_sge.sge.vaddr;\r\nsdata = be64_to_cpu(ateth->swap_data);\r\ne->atomic_data = (opcode == OP(FETCH_ADD)) ?\r\n(u64) atomic64_add_return(sdata, maddr) - sdata :\r\n(u64) cmpxchg((u64 *) qp->r_sge.sge.vaddr,\r\nbe64_to_cpu(ateth->compare_data),\r\nsdata);\r\natomic_dec(&qp->r_sge.sge.mr->refcount);\r\nqp->r_sge.num_sge = 0;\r\ne->opcode = opcode;\r\ne->sent = 0;\r\ne->psn = psn;\r\ne->lpsn = psn;\r\nqp->r_msn++;\r\nqp->r_psn++;\r\nqp->r_state = opcode;\r\nqp->r_nak_state = 0;\r\nqp->r_head_ack_queue = next;\r\nqp->s_flags |= QIB_S_RESP_PENDING;\r\nqib_schedule_send(qp);\r\ngoto sunlock;\r\n}\r\ndefault:\r\ngoto nack_inv;\r\n}\r\nqp->r_psn++;\r\nqp->r_state = opcode;\r\nqp->r_ack_psn = psn;\r\nqp->r_nak_state = 0;\r\nif (psn & (1 << 31))\r\ngoto send_ack;\r\nreturn;\r\nrnr_nak:\r\nqp->r_nak_state = IB_RNR_NAK | qp->r_min_rnr_timer;\r\nqp->r_ack_psn = qp->r_psn;\r\nif (list_empty(&qp->rspwait)) {\r\nqp->r_flags |= QIB_R_RSP_NAK;\r\natomic_inc(&qp->refcount);\r\nlist_add_tail(&qp->rspwait, &rcd->qp_wait_list);\r\n}\r\nreturn;\r\nnack_op_err:\r\nqib_rc_error(qp, IB_WC_LOC_QP_OP_ERR);\r\nqp->r_nak_state = IB_NAK_REMOTE_OPERATIONAL_ERROR;\r\nqp->r_ack_psn = qp->r_psn;\r\nif (list_empty(&qp->rspwait)) {\r\nqp->r_flags |= QIB_R_RSP_NAK;\r\natomic_inc(&qp->refcount);\r\nlist_add_tail(&qp->rspwait, &rcd->qp_wait_list);\r\n}\r\nreturn;\r\nnack_inv_unlck:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nnack_inv:\r\nqib_rc_error(qp, IB_WC_LOC_QP_OP_ERR);\r\nqp->r_nak_state = IB_NAK_INVALID_REQUEST;\r\nqp->r_ack_psn = qp->r_psn;\r\nif (list_empty(&qp->rspwait)) {\r\nqp->r_flags |= QIB_R_RSP_NAK;\r\natomic_inc(&qp->refcount);\r\nlist_add_tail(&qp->rspwait, &rcd->qp_wait_list);\r\n}\r\nreturn;\r\nnack_acc_unlck:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nnack_acc:\r\nqib_rc_error(qp, IB_WC_LOC_PROT_ERR);\r\nqp->r_nak_state = IB_NAK_REMOTE_ACCESS_ERROR;\r\nqp->r_ack_psn = qp->r_psn;\r\nsend_ack:\r\nqib_send_rc_ack(qp);\r\nreturn;\r\nsunlock:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\n}
