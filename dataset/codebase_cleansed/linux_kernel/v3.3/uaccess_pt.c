static inline pte_t *follow_table(struct mm_struct *mm, unsigned long addr)\r\n{\r\npgd_t *pgd;\r\npud_t *pud;\r\npmd_t *pmd;\r\npgd = pgd_offset(mm, addr);\r\nif (pgd_none(*pgd) || unlikely(pgd_bad(*pgd)))\r\nreturn (pte_t *) 0x3a;\r\npud = pud_offset(pgd, addr);\r\nif (pud_none(*pud) || unlikely(pud_bad(*pud)))\r\nreturn (pte_t *) 0x3b;\r\npmd = pmd_offset(pud, addr);\r\nif (pmd_none(*pmd) || unlikely(pmd_bad(*pmd)))\r\nreturn (pte_t *) 0x10;\r\nreturn pte_offset_map(pmd, addr);\r\n}\r\nstatic __always_inline size_t __user_copy_pt(unsigned long uaddr, void *kptr,\r\nsize_t n, int write_user)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long offset, pfn, done, size;\r\npte_t *pte;\r\nvoid *from, *to;\r\ndone = 0;\r\nretry:\r\nspin_lock(&mm->page_table_lock);\r\ndo {\r\npte = follow_table(mm, uaddr);\r\nif ((unsigned long) pte < 0x1000)\r\ngoto fault;\r\nif (!pte_present(*pte)) {\r\npte = (pte_t *) 0x11;\r\ngoto fault;\r\n} else if (write_user && !pte_write(*pte)) {\r\npte = (pte_t *) 0x04;\r\ngoto fault;\r\n}\r\npfn = pte_pfn(*pte);\r\noffset = uaddr & (PAGE_SIZE - 1);\r\nsize = min(n - done, PAGE_SIZE - offset);\r\nif (write_user) {\r\nto = (void *)((pfn << PAGE_SHIFT) + offset);\r\nfrom = kptr + done;\r\n} else {\r\nfrom = (void *)((pfn << PAGE_SHIFT) + offset);\r\nto = kptr + done;\r\n}\r\nmemcpy(to, from, size);\r\ndone += size;\r\nuaddr += size;\r\n} while (done < n);\r\nspin_unlock(&mm->page_table_lock);\r\nreturn n - done;\r\nfault:\r\nspin_unlock(&mm->page_table_lock);\r\nif (__handle_fault(uaddr, (unsigned long) pte, write_user))\r\nreturn n - done;\r\ngoto retry;\r\n}\r\nstatic __always_inline unsigned long __dat_user_addr(unsigned long uaddr)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long pfn;\r\npte_t *pte;\r\nint rc;\r\nretry:\r\npte = follow_table(mm, uaddr);\r\nif ((unsigned long) pte < 0x1000)\r\ngoto fault;\r\nif (!pte_present(*pte)) {\r\npte = (pte_t *) 0x11;\r\ngoto fault;\r\n}\r\npfn = pte_pfn(*pte);\r\nreturn (pfn << PAGE_SHIFT) + (uaddr & (PAGE_SIZE - 1));\r\nfault:\r\nspin_unlock(&mm->page_table_lock);\r\nrc = __handle_fault(uaddr, (unsigned long) pte, 0);\r\nspin_lock(&mm->page_table_lock);\r\nif (!rc)\r\ngoto retry;\r\nreturn 0;\r\n}\r\nsize_t copy_from_user_pt(size_t n, const void __user *from, void *to)\r\n{\r\nsize_t rc;\r\nif (segment_eq(get_fs(), KERNEL_DS)) {\r\nmemcpy(to, (void __kernel __force *) from, n);\r\nreturn 0;\r\n}\r\nrc = __user_copy_pt((unsigned long) from, to, n, 0);\r\nif (unlikely(rc))\r\nmemset(to + n - rc, 0, rc);\r\nreturn rc;\r\n}\r\nsize_t copy_to_user_pt(size_t n, void __user *to, const void *from)\r\n{\r\nif (segment_eq(get_fs(), KERNEL_DS)) {\r\nmemcpy((void __kernel __force *) to, from, n);\r\nreturn 0;\r\n}\r\nreturn __user_copy_pt((unsigned long) to, (void *) from, n, 1);\r\n}\r\nstatic size_t clear_user_pt(size_t n, void __user *to)\r\n{\r\nlong done, size, ret;\r\nif (segment_eq(get_fs(), KERNEL_DS)) {\r\nmemset((void __kernel __force *) to, 0, n);\r\nreturn 0;\r\n}\r\ndone = 0;\r\ndo {\r\nif (n - done > PAGE_SIZE)\r\nsize = PAGE_SIZE;\r\nelse\r\nsize = n - done;\r\nret = __user_copy_pt((unsigned long) to + done,\r\n&empty_zero_page, size, 1);\r\ndone += size;\r\nif (ret)\r\nreturn ret + n - done;\r\n} while (done < n);\r\nreturn 0;\r\n}\r\nstatic size_t strnlen_user_pt(size_t count, const char __user *src)\r\n{\r\nchar *addr;\r\nunsigned long uaddr = (unsigned long) src;\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long offset, pfn, done, len;\r\npte_t *pte;\r\nsize_t len_str;\r\nif (segment_eq(get_fs(), KERNEL_DS))\r\nreturn strnlen((const char __kernel __force *) src, count) + 1;\r\ndone = 0;\r\nretry:\r\nspin_lock(&mm->page_table_lock);\r\ndo {\r\npte = follow_table(mm, uaddr);\r\nif ((unsigned long) pte < 0x1000)\r\ngoto fault;\r\nif (!pte_present(*pte)) {\r\npte = (pte_t *) 0x11;\r\ngoto fault;\r\n}\r\npfn = pte_pfn(*pte);\r\noffset = uaddr & (PAGE_SIZE-1);\r\naddr = (char *)(pfn << PAGE_SHIFT) + offset;\r\nlen = min(count - done, PAGE_SIZE - offset);\r\nlen_str = strnlen(addr, len);\r\ndone += len_str;\r\nuaddr += len_str;\r\n} while ((len_str == len) && (done < count));\r\nspin_unlock(&mm->page_table_lock);\r\nreturn done + 1;\r\nfault:\r\nspin_unlock(&mm->page_table_lock);\r\nif (__handle_fault(uaddr, (unsigned long) pte, 0))\r\nreturn 0;\r\ngoto retry;\r\n}\r\nstatic size_t strncpy_from_user_pt(size_t count, const char __user *src,\r\nchar *dst)\r\n{\r\nsize_t n = strnlen_user_pt(count, src);\r\nif (!n)\r\nreturn -EFAULT;\r\nif (n > count)\r\nn = count;\r\nif (segment_eq(get_fs(), KERNEL_DS)) {\r\nmemcpy(dst, (const char __kernel __force *) src, n);\r\nif (dst[n-1] == '\0')\r\nreturn n-1;\r\nelse\r\nreturn n;\r\n}\r\nif (__user_copy_pt((unsigned long) src, dst, n, 0))\r\nreturn -EFAULT;\r\nif (dst[n-1] == '\0')\r\nreturn n-1;\r\nelse\r\nreturn n;\r\n}\r\nstatic size_t copy_in_user_pt(size_t n, void __user *to,\r\nconst void __user *from)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long offset_from, offset_to, offset_max, pfn_from, pfn_to,\r\nuaddr, done, size, error_code;\r\nunsigned long uaddr_from = (unsigned long) from;\r\nunsigned long uaddr_to = (unsigned long) to;\r\npte_t *pte_from, *pte_to;\r\nint write_user;\r\nif (segment_eq(get_fs(), KERNEL_DS)) {\r\nmemcpy((void __force *) to, (void __force *) from, n);\r\nreturn 0;\r\n}\r\ndone = 0;\r\nretry:\r\nspin_lock(&mm->page_table_lock);\r\ndo {\r\nwrite_user = 0;\r\nuaddr = uaddr_from;\r\npte_from = follow_table(mm, uaddr_from);\r\nerror_code = (unsigned long) pte_from;\r\nif (error_code < 0x1000)\r\ngoto fault;\r\nif (!pte_present(*pte_from)) {\r\nerror_code = 0x11;\r\ngoto fault;\r\n}\r\nwrite_user = 1;\r\nuaddr = uaddr_to;\r\npte_to = follow_table(mm, uaddr_to);\r\nerror_code = (unsigned long) pte_to;\r\nif (error_code < 0x1000)\r\ngoto fault;\r\nif (!pte_present(*pte_to)) {\r\nerror_code = 0x11;\r\ngoto fault;\r\n} else if (!pte_write(*pte_to)) {\r\nerror_code = 0x04;\r\ngoto fault;\r\n}\r\npfn_from = pte_pfn(*pte_from);\r\npfn_to = pte_pfn(*pte_to);\r\noffset_from = uaddr_from & (PAGE_SIZE-1);\r\noffset_to = uaddr_from & (PAGE_SIZE-1);\r\noffset_max = max(offset_from, offset_to);\r\nsize = min(n - done, PAGE_SIZE - offset_max);\r\nmemcpy((void *)(pfn_to << PAGE_SHIFT) + offset_to,\r\n(void *)(pfn_from << PAGE_SHIFT) + offset_from, size);\r\ndone += size;\r\nuaddr_from += size;\r\nuaddr_to += size;\r\n} while (done < n);\r\nspin_unlock(&mm->page_table_lock);\r\nreturn n - done;\r\nfault:\r\nspin_unlock(&mm->page_table_lock);\r\nif (__handle_fault(uaddr, error_code, write_user))\r\nreturn n - done;\r\ngoto retry;\r\n}\r\nstatic int __futex_atomic_op_pt(int op, u32 __user *uaddr, int oparg, int *old)\r\n{\r\nint oldval = 0, newval, ret;\r\nswitch (op) {\r\ncase FUTEX_OP_SET:\r\n__futex_atomic_op("lr %2,%5\n",\r\nret, oldval, newval, uaddr, oparg);\r\nbreak;\r\ncase FUTEX_OP_ADD:\r\n__futex_atomic_op("lr %2,%1\nar %2,%5\n",\r\nret, oldval, newval, uaddr, oparg);\r\nbreak;\r\ncase FUTEX_OP_OR:\r\n__futex_atomic_op("lr %2,%1\nor %2,%5\n",\r\nret, oldval, newval, uaddr, oparg);\r\nbreak;\r\ncase FUTEX_OP_ANDN:\r\n__futex_atomic_op("lr %2,%1\nnr %2,%5\n",\r\nret, oldval, newval, uaddr, oparg);\r\nbreak;\r\ncase FUTEX_OP_XOR:\r\n__futex_atomic_op("lr %2,%1\nxr %2,%5\n",\r\nret, oldval, newval, uaddr, oparg);\r\nbreak;\r\ndefault:\r\nret = -ENOSYS;\r\n}\r\nif (ret == 0)\r\n*old = oldval;\r\nreturn ret;\r\n}\r\nint futex_atomic_op_pt(int op, u32 __user *uaddr, int oparg, int *old)\r\n{\r\nint ret;\r\nif (segment_eq(get_fs(), KERNEL_DS))\r\nreturn __futex_atomic_op_pt(op, uaddr, oparg, old);\r\nspin_lock(&current->mm->page_table_lock);\r\nuaddr = (u32 __force __user *)\r\n__dat_user_addr((__force unsigned long) uaddr);\r\nif (!uaddr) {\r\nspin_unlock(&current->mm->page_table_lock);\r\nreturn -EFAULT;\r\n}\r\nget_page(virt_to_page(uaddr));\r\nspin_unlock(&current->mm->page_table_lock);\r\nret = __futex_atomic_op_pt(op, uaddr, oparg, old);\r\nput_page(virt_to_page(uaddr));\r\nreturn ret;\r\n}\r\nstatic int __futex_atomic_cmpxchg_pt(u32 *uval, u32 __user *uaddr,\r\nu32 oldval, u32 newval)\r\n{\r\nint ret;\r\nasm volatile("0: cs %1,%4,0(%5)\n"\r\n"1: la %0,0\n"\r\n"2:\n"\r\nEX_TABLE(0b,2b) EX_TABLE(1b,2b)\r\n: "=d" (ret), "+d" (oldval), "=m" (*uaddr)\r\n: "0" (-EFAULT), "d" (newval), "a" (uaddr), "m" (*uaddr)\r\n: "cc", "memory" );\r\n*uval = oldval;\r\nreturn ret;\r\n}\r\nint futex_atomic_cmpxchg_pt(u32 *uval, u32 __user *uaddr,\r\nu32 oldval, u32 newval)\r\n{\r\nint ret;\r\nif (segment_eq(get_fs(), KERNEL_DS))\r\nreturn __futex_atomic_cmpxchg_pt(uval, uaddr, oldval, newval);\r\nspin_lock(&current->mm->page_table_lock);\r\nuaddr = (u32 __force __user *)\r\n__dat_user_addr((__force unsigned long) uaddr);\r\nif (!uaddr) {\r\nspin_unlock(&current->mm->page_table_lock);\r\nreturn -EFAULT;\r\n}\r\nget_page(virt_to_page(uaddr));\r\nspin_unlock(&current->mm->page_table_lock);\r\nret = __futex_atomic_cmpxchg_pt(uval, uaddr, oldval, newval);\r\nput_page(virt_to_page(uaddr));\r\nreturn ret;\r\n}
