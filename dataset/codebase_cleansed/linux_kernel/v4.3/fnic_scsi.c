const char *fnic_state_to_str(unsigned int state)\r\n{\r\nif (state >= ARRAY_SIZE(fnic_state_str) || !fnic_state_str[state])\r\nreturn "unknown";\r\nreturn fnic_state_str[state];\r\n}\r\nstatic const char *fnic_ioreq_state_to_str(unsigned int state)\r\n{\r\nif (state >= ARRAY_SIZE(fnic_ioreq_state_str) ||\r\n!fnic_ioreq_state_str[state])\r\nreturn "unknown";\r\nreturn fnic_ioreq_state_str[state];\r\n}\r\nstatic const char *fnic_fcpio_status_to_str(unsigned int status)\r\n{\r\nif (status >= ARRAY_SIZE(fcpio_status_str) || !fcpio_status_str[status])\r\nreturn "unknown";\r\nreturn fcpio_status_str[status];\r\n}\r\nstatic inline spinlock_t *fnic_io_lock_hash(struct fnic *fnic,\r\nstruct scsi_cmnd *sc)\r\n{\r\nu32 hash = sc->request->tag & (FNIC_IO_LOCKS - 1);\r\nreturn &fnic->io_req_lock[hash];\r\n}\r\nstatic inline spinlock_t *fnic_io_lock_tag(struct fnic *fnic,\r\nint tag)\r\n{\r\nreturn &fnic->io_req_lock[tag & (FNIC_IO_LOCKS - 1)];\r\n}\r\nstatic void fnic_release_ioreq_buf(struct fnic *fnic,\r\nstruct fnic_io_req *io_req,\r\nstruct scsi_cmnd *sc)\r\n{\r\nif (io_req->sgl_list_pa)\r\npci_unmap_single(fnic->pdev, io_req->sgl_list_pa,\r\nsizeof(io_req->sgl_list[0]) * io_req->sgl_cnt,\r\nPCI_DMA_TODEVICE);\r\nscsi_dma_unmap(sc);\r\nif (io_req->sgl_cnt)\r\nmempool_free(io_req->sgl_list_alloc,\r\nfnic->io_sgl_pool[io_req->sgl_type]);\r\nif (io_req->sense_buf_pa)\r\npci_unmap_single(fnic->pdev, io_req->sense_buf_pa,\r\nSCSI_SENSE_BUFFERSIZE, PCI_DMA_FROMDEVICE);\r\n}\r\nstatic int free_wq_copy_descs(struct fnic *fnic, struct vnic_wq_copy *wq)\r\n{\r\nif (!fnic->fw_ack_recd[0])\r\nreturn 1;\r\nif (wq->to_clean_index <= fnic->fw_ack_index[0])\r\nwq->ring.desc_avail += (fnic->fw_ack_index[0]\r\n- wq->to_clean_index + 1);\r\nelse\r\nwq->ring.desc_avail += (wq->ring.desc_count\r\n- wq->to_clean_index\r\n+ fnic->fw_ack_index[0] + 1);\r\nwq->to_clean_index =\r\n(fnic->fw_ack_index[0] + 1) % wq->ring.desc_count;\r\nfnic->fw_ack_recd[0] = 0;\r\nreturn 0;\r\n}\r\nvoid\r\n__fnic_set_state_flags(struct fnic *fnic, unsigned long st_flags,\r\nunsigned long clearbits)\r\n{\r\nstruct Scsi_Host *host = fnic->lport->host;\r\nint sh_locked = spin_is_locked(host->host_lock);\r\nunsigned long flags = 0;\r\nif (!sh_locked)\r\nspin_lock_irqsave(host->host_lock, flags);\r\nif (clearbits)\r\nfnic->state_flags &= ~st_flags;\r\nelse\r\nfnic->state_flags |= st_flags;\r\nif (!sh_locked)\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nreturn;\r\n}\r\nint fnic_fw_reset_handler(struct fnic *fnic)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nint ret = 0;\r\nunsigned long flags;\r\nfnic_set_state_flags(fnic, FNIC_FLAGS_FWRESET);\r\nskb_queue_purge(&fnic->frame_queue);\r\nskb_queue_purge(&fnic->tx_queue);\r\nwhile (atomic_read(&fnic->in_flight))\r\nschedule_timeout(msecs_to_jiffies(1));\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq))\r\nret = -EAGAIN;\r\nelse {\r\nfnic_queue_wq_copy_desc_fw_reset(wq, SCSI_NO_TAG);\r\natomic64_inc(&fnic->fnic_stats.fw_stats.active_fw_reqs);\r\nif (atomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs) >\r\natomic64_read(&fnic->fnic_stats.fw_stats.max_fw_reqs))\r\natomic64_set(&fnic->fnic_stats.fw_stats.max_fw_reqs,\r\natomic64_read(\r\n&fnic->fnic_stats.fw_stats.active_fw_reqs));\r\n}\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\nif (!ret) {\r\natomic64_inc(&fnic->fnic_stats.reset_stats.fw_resets);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Issued fw reset\n");\r\n} else {\r\nfnic_clear_state_flags(fnic, FNIC_FLAGS_FWRESET);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Failed to issue fw reset\n");\r\n}\r\nreturn ret;\r\n}\r\nint fnic_flogi_reg_handler(struct fnic *fnic, u32 fc_id)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nenum fcpio_flogi_reg_format_type format;\r\nstruct fc_lport *lp = fnic->lport;\r\nu8 gw_mac[ETH_ALEN];\r\nint ret = 0;\r\nunsigned long flags;\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq)) {\r\nret = -EAGAIN;\r\ngoto flogi_reg_ioreq_end;\r\n}\r\nif (fnic->ctlr.map_dest) {\r\nmemset(gw_mac, 0xff, ETH_ALEN);\r\nformat = FCPIO_FLOGI_REG_DEF_DEST;\r\n} else {\r\nmemcpy(gw_mac, fnic->ctlr.dest_addr, ETH_ALEN);\r\nformat = FCPIO_FLOGI_REG_GW_DEST;\r\n}\r\nif ((fnic->config.flags & VFCF_FIP_CAPABLE) && !fnic->ctlr.map_dest) {\r\nfnic_queue_wq_copy_desc_fip_reg(wq, SCSI_NO_TAG,\r\nfc_id, gw_mac,\r\nfnic->data_src_addr,\r\nlp->r_a_tov, lp->e_d_tov);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"FLOGI FIP reg issued fcid %x src %pM dest %pM\n",\r\nfc_id, fnic->data_src_addr, gw_mac);\r\n} else {\r\nfnic_queue_wq_copy_desc_flogi_reg(wq, SCSI_NO_TAG,\r\nformat, fc_id, gw_mac);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"FLOGI reg issued fcid %x map %d dest %pM\n",\r\nfc_id, fnic->ctlr.map_dest, gw_mac);\r\n}\r\natomic64_inc(&fnic->fnic_stats.fw_stats.active_fw_reqs);\r\nif (atomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs) >\r\natomic64_read(&fnic->fnic_stats.fw_stats.max_fw_reqs))\r\natomic64_set(&fnic->fnic_stats.fw_stats.max_fw_reqs,\r\natomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs));\r\nflogi_reg_ioreq_end:\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\nreturn ret;\r\n}\r\nstatic inline int fnic_queue_wq_copy_desc(struct fnic *fnic,\r\nstruct vnic_wq_copy *wq,\r\nstruct fnic_io_req *io_req,\r\nstruct scsi_cmnd *sc,\r\nint sg_count)\r\n{\r\nstruct scatterlist *sg;\r\nstruct fc_rport *rport = starget_to_rport(scsi_target(sc->device));\r\nstruct fc_rport_libfc_priv *rp = rport->dd_data;\r\nstruct host_sg_desc *desc;\r\nstruct misc_stats *misc_stats = &fnic->fnic_stats.misc_stats;\r\nunsigned int i;\r\nunsigned long intr_flags;\r\nint flags;\r\nu8 exch_flags;\r\nstruct scsi_lun fc_lun;\r\nif (sg_count) {\r\ndesc = io_req->sgl_list;\r\nfor_each_sg(scsi_sglist(sc), sg, sg_count, i) {\r\ndesc->addr = cpu_to_le64(sg_dma_address(sg));\r\ndesc->len = cpu_to_le32(sg_dma_len(sg));\r\ndesc->_resvd = 0;\r\ndesc++;\r\n}\r\nio_req->sgl_list_pa = pci_map_single\r\n(fnic->pdev,\r\nio_req->sgl_list,\r\nsizeof(io_req->sgl_list[0]) * sg_count,\r\nPCI_DMA_TODEVICE);\r\n}\r\nio_req->sense_buf_pa = pci_map_single(fnic->pdev,\r\nsc->sense_buffer,\r\nSCSI_SENSE_BUFFERSIZE,\r\nPCI_DMA_FROMDEVICE);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], intr_flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (unlikely(!vnic_wq_copy_desc_avail(wq))) {\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], intr_flags);\r\nFNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,\r\n"fnic_queue_wq_copy_desc failure - no descriptors\n");\r\natomic64_inc(&misc_stats->io_cpwq_alloc_failures);\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\n}\r\nflags = 0;\r\nif (sc->sc_data_direction == DMA_FROM_DEVICE)\r\nflags = FCPIO_ICMND_RDDATA;\r\nelse if (sc->sc_data_direction == DMA_TO_DEVICE)\r\nflags = FCPIO_ICMND_WRDATA;\r\nexch_flags = 0;\r\nif ((fnic->config.flags & VFCF_FCP_SEQ_LVL_ERR) &&\r\n(rp->flags & FC_RP_FLAGS_RETRY))\r\nexch_flags |= FCPIO_ICMND_SRFLAG_RETRY;\r\nfnic_queue_wq_copy_desc_icmnd_16(wq, sc->request->tag,\r\n0, exch_flags, io_req->sgl_cnt,\r\nSCSI_SENSE_BUFFERSIZE,\r\nio_req->sgl_list_pa,\r\nio_req->sense_buf_pa,\r\n0,\r\nFCPIO_ICMND_PTA_SIMPLE,\r\nflags,\r\nsc->cmnd, sc->cmd_len,\r\nscsi_bufflen(sc),\r\nfc_lun.scsi_lun, io_req->port_id,\r\nrport->maxframe_size, rp->r_a_tov,\r\nrp->e_d_tov);\r\natomic64_inc(&fnic->fnic_stats.fw_stats.active_fw_reqs);\r\nif (atomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs) >\r\natomic64_read(&fnic->fnic_stats.fw_stats.max_fw_reqs))\r\natomic64_set(&fnic->fnic_stats.fw_stats.max_fw_reqs,\r\natomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs));\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], intr_flags);\r\nreturn 0;\r\n}\r\nstatic int fnic_queuecommand_lck(struct scsi_cmnd *sc, void (*done)(struct scsi_cmnd *))\r\n{\r\nstruct fc_lport *lp = shost_priv(sc->device->host);\r\nstruct fc_rport *rport;\r\nstruct fnic_io_req *io_req = NULL;\r\nstruct fnic *fnic = lport_priv(lp);\r\nstruct fnic_stats *fnic_stats = &fnic->fnic_stats;\r\nstruct vnic_wq_copy *wq;\r\nint ret;\r\nu64 cmd_trace;\r\nint sg_count = 0;\r\nunsigned long flags = 0;\r\nunsigned long ptr;\r\nstruct fc_rport_priv *rdata;\r\nspinlock_t *io_lock = NULL;\r\nint io_lock_acquired = 0;\r\nif (unlikely(fnic_chk_state_flags_locked(fnic, FNIC_FLAGS_IO_BLOCKED)))\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\nrport = starget_to_rport(scsi_target(sc->device));\r\nret = fc_remote_port_chkready(rport);\r\nif (ret) {\r\natomic64_inc(&fnic_stats->misc_stats.rport_not_ready);\r\nsc->result = ret;\r\ndone(sc);\r\nreturn 0;\r\n}\r\nrdata = lp->tt.rport_lookup(lp, rport->port_id);\r\nif (!rdata || (rdata->rp_state == RPORT_ST_DELETE)) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"returning IO as rport is removed\n");\r\natomic64_inc(&fnic_stats->misc_stats.rport_not_ready);\r\nsc->result = DID_NO_CONNECT;\r\ndone(sc);\r\nreturn 0;\r\n}\r\nif (lp->state != LPORT_ST_READY || !(lp->link_up))\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\natomic_inc(&fnic->in_flight);\r\nspin_unlock(lp->host->host_lock);\r\nCMD_STATE(sc) = FNIC_IOREQ_NOT_INITED;\r\nCMD_FLAGS(sc) = FNIC_NO_FLAGS;\r\nio_req = mempool_alloc(fnic->io_req_pool, GFP_ATOMIC);\r\nif (!io_req) {\r\natomic64_inc(&fnic_stats->io_stats.alloc_failures);\r\nret = SCSI_MLQUEUE_HOST_BUSY;\r\ngoto out;\r\n}\r\nmemset(io_req, 0, sizeof(*io_req));\r\nsg_count = scsi_dma_map(sc);\r\nif (sg_count < 0) {\r\nFNIC_TRACE(fnic_queuecommand, sc->device->host->host_no,\r\nsc->request->tag, sc, 0, sc->cmnd[0],\r\nsg_count, CMD_STATE(sc));\r\nmempool_free(io_req, fnic->io_req_pool);\r\ngoto out;\r\n}\r\nio_req->sgl_cnt = sg_count;\r\nio_req->sgl_type = FNIC_SGL_CACHE_DFLT;\r\nif (sg_count > FNIC_DFLT_SG_DESC_CNT)\r\nio_req->sgl_type = FNIC_SGL_CACHE_MAX;\r\nif (sg_count) {\r\nio_req->sgl_list =\r\nmempool_alloc(fnic->io_sgl_pool[io_req->sgl_type],\r\nGFP_ATOMIC);\r\nif (!io_req->sgl_list) {\r\natomic64_inc(&fnic_stats->io_stats.alloc_failures);\r\nret = SCSI_MLQUEUE_HOST_BUSY;\r\nscsi_dma_unmap(sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\ngoto out;\r\n}\r\nio_req->sgl_list_alloc = io_req->sgl_list;\r\nptr = (unsigned long) io_req->sgl_list;\r\nif (ptr % FNIC_SG_DESC_ALIGN) {\r\nio_req->sgl_list = (struct host_sg_desc *)\r\n(((unsigned long) ptr\r\n+ FNIC_SG_DESC_ALIGN - 1)\r\n& ~(FNIC_SG_DESC_ALIGN - 1));\r\n}\r\n}\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_lock_acquired = 1;\r\nio_req->port_id = rport->port_id;\r\nio_req->start_time = jiffies;\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_PENDING;\r\nCMD_SP(sc) = (char *)io_req;\r\nCMD_FLAGS(sc) |= FNIC_IO_INITIALIZED;\r\nsc->scsi_done = done;\r\nwq = &fnic->wq_copy[0];\r\nret = fnic_queue_wq_copy_desc(fnic, wq, io_req, sc, sg_count);\r\nif (ret) {\r\nFNIC_TRACE(fnic_queuecommand, sc->device->host->host_no,\r\nsc->request->tag, sc, 0, 0, 0,\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nCMD_SP(sc) = NULL;\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_COMPLETE;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (io_req) {\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\n}\r\natomic_dec(&fnic->in_flight);\r\nspin_lock(lp->host->host_lock);\r\nreturn ret;\r\n} else {\r\natomic64_inc(&fnic_stats->io_stats.active_ios);\r\natomic64_inc(&fnic_stats->io_stats.num_ios);\r\nif (atomic64_read(&fnic_stats->io_stats.active_ios) >\r\natomic64_read(&fnic_stats->io_stats.max_active_ios))\r\natomic64_set(&fnic_stats->io_stats.max_active_ios,\r\natomic64_read(&fnic_stats->io_stats.active_ios));\r\nCMD_FLAGS(sc) |= FNIC_IO_ISSUED;\r\n}\r\nout:\r\ncmd_trace = ((u64)sc->cmnd[0] << 56 | (u64)sc->cmnd[7] << 40 |\r\n(u64)sc->cmnd[8] << 32 | (u64)sc->cmnd[2] << 24 |\r\n(u64)sc->cmnd[3] << 16 | (u64)sc->cmnd[4] << 8 |\r\nsc->cmnd[5]);\r\nFNIC_TRACE(fnic_queuecommand, sc->device->host->host_no,\r\nsc->request->tag, sc, io_req,\r\nsg_count, cmd_trace,\r\n(((u64)CMD_FLAGS(sc) >> 32) | CMD_STATE(sc)));\r\nif (io_lock_acquired)\r\nspin_unlock_irqrestore(io_lock, flags);\r\natomic_dec(&fnic->in_flight);\r\nspin_lock(lp->host->host_lock);\r\nreturn ret;\r\n}\r\nstatic int fnic_fcpio_fw_reset_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nint ret = 0;\r\nunsigned long flags;\r\nstruct reset_stats *reset_stats = &fnic->fnic_stats.reset_stats;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\natomic64_inc(&reset_stats->fw_reset_completions);\r\nfnic_cleanup_io(fnic, SCSI_NO_TAG);\r\natomic64_set(&fnic->fnic_stats.fw_stats.active_fw_reqs, 0);\r\natomic64_set(&fnic->fnic_stats.io_stats.active_ios, 0);\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE) {\r\nif (!hdr_status) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"reset cmpl success\n");\r\nfnic->state = FNIC_IN_ETH_MODE;\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic fw_reset : failed %s\n",\r\nfnic_fcpio_status_to_str(hdr_status));\r\nfnic->state = FNIC_IN_FC_MODE;\r\natomic64_inc(&reset_stats->fw_reset_failures);\r\nret = -1;\r\n}\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"Unexpected state %s while processing"\r\n" reset cmpl\n", fnic_state_to_str(fnic->state));\r\natomic64_inc(&reset_stats->fw_reset_failures);\r\nret = -1;\r\n}\r\nif (fnic->remove_wait)\r\ncomplete(fnic->remove_wait);\r\nif (fnic->remove_wait || ret) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nskb_queue_purge(&fnic->tx_queue);\r\ngoto reset_cmpl_handler_end;\r\n}\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nfnic_flush_tx(fnic);\r\nreset_cmpl_handler_end:\r\nfnic_clear_state_flags(fnic, FNIC_FLAGS_FWRESET);\r\nreturn ret;\r\n}\r\nstatic int fnic_fcpio_flogi_reg_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nint ret = 0;\r\nunsigned long flags;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_ETH_TRANS_FC_MODE) {\r\nif (!hdr_status) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"flog reg succeeded\n");\r\nfnic->state = FNIC_IN_FC_MODE;\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic flogi reg :failed %s\n",\r\nfnic_fcpio_status_to_str(hdr_status));\r\nfnic->state = FNIC_IN_ETH_MODE;\r\nret = -1;\r\n}\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Unexpected fnic state %s while"\r\n" processing flogi reg completion\n",\r\nfnic_state_to_str(fnic->state));\r\nret = -1;\r\n}\r\nif (!ret) {\r\nif (fnic->stop_rx_link_events) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\ngoto reg_cmpl_handler_end;\r\n}\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nfnic_flush_tx(fnic);\r\nqueue_work(fnic_event_queue, &fnic->frame_work);\r\n} else {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\nreg_cmpl_handler_end:\r\nreturn ret;\r\n}\r\nstatic inline int is_ack_index_in_range(struct vnic_wq_copy *wq,\r\nu16 request_out)\r\n{\r\nif (wq->to_clean_index <= wq->to_use_index) {\r\nif (request_out < wq->to_clean_index ||\r\nrequest_out >= wq->to_use_index)\r\nreturn 0;\r\n} else {\r\nif (request_out < wq->to_clean_index &&\r\nrequest_out >= wq->to_use_index)\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic inline void fnic_fcpio_ack_handler(struct fnic *fnic,\r\nunsigned int cq_index,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nstruct vnic_wq_copy *wq;\r\nu16 request_out = desc->u.ack.request_out;\r\nunsigned long flags;\r\nu64 *ox_id_tag = (u64 *)(void *)desc;\r\nwq = &fnic->wq_copy[cq_index - fnic->raw_wq_count - fnic->rq_count];\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nfnic->fnic_stats.misc_stats.last_ack_time = jiffies;\r\nif (is_ack_index_in_range(wq, request_out)) {\r\nfnic->fw_ack_index[0] = request_out;\r\nfnic->fw_ack_recd[0] = 1;\r\n} else\r\natomic64_inc(\r\n&fnic->fnic_stats.misc_stats.ack_index_out_of_range);\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\nFNIC_TRACE(fnic_fcpio_ack_handler,\r\nfnic->lport->host->host_no, 0, 0, ox_id_tag[2], ox_id_tag[3],\r\nox_id_tag[4], ox_id_tag[5]);\r\n}\r\nstatic void fnic_fcpio_icmnd_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nu32 id;\r\nu64 xfer_len = 0;\r\nstruct fcpio_icmnd_cmpl *icmnd_cmpl;\r\nstruct fnic_io_req *io_req;\r\nstruct scsi_cmnd *sc;\r\nstruct fnic_stats *fnic_stats = &fnic->fnic_stats;\r\nunsigned long flags;\r\nspinlock_t *io_lock;\r\nu64 cmd_trace;\r\nunsigned long start_time;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\nfcpio_tag_id_dec(&tag, &id);\r\nicmnd_cmpl = &desc->u.icmnd_cmpl;\r\nif (id >= fnic->fnic_max_tag_id) {\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"Tag out of range tag %x hdr status = %s\n",\r\nid, fnic_fcpio_status_to_str(hdr_status));\r\nreturn;\r\n}\r\nsc = scsi_host_find_tag(fnic->lport->host, id);\r\nWARN_ON_ONCE(!sc);\r\nif (!sc) {\r\natomic64_inc(&fnic_stats->io_stats.sc_null);\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"icmnd_cmpl sc is null - "\r\n"hdr status = %s tag = 0x%x desc = 0x%p\n",\r\nfnic_fcpio_status_to_str(hdr_status), id, desc);\r\nFNIC_TRACE(fnic_fcpio_icmnd_cmpl_handler,\r\nfnic->lport->host->host_no, id,\r\n((u64)icmnd_cmpl->_resvd0[1] << 16 |\r\n(u64)icmnd_cmpl->_resvd0[0]),\r\n((u64)hdr_status << 16 |\r\n(u64)icmnd_cmpl->scsi_status << 8 |\r\n(u64)icmnd_cmpl->flags), desc,\r\n(u64)icmnd_cmpl->residual, 0);\r\nreturn;\r\n}\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nWARN_ON_ONCE(!io_req);\r\nif (!io_req) {\r\natomic64_inc(&fnic_stats->io_stats.ioreq_null);\r\nCMD_FLAGS(sc) |= FNIC_IO_REQ_NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"icmnd_cmpl io_req is null - "\r\n"hdr status = %s tag = 0x%x sc 0x%p\n",\r\nfnic_fcpio_status_to_str(hdr_status), id, sc);\r\nreturn;\r\n}\r\nstart_time = io_req->start_time;\r\nio_req->io_completed = 1;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_IO_ABTS_PENDING;\r\nswitch (hdr_status) {\r\ncase FCPIO_SUCCESS:\r\nCMD_FLAGS(sc) |= FNIC_IO_DONE;\r\nFNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,\r\n"icmnd_cmpl ABTS pending hdr status = %s "\r\n"sc 0x%p scsi_status %x residual %d\n",\r\nfnic_fcpio_status_to_str(hdr_status), sc,\r\nicmnd_cmpl->scsi_status,\r\nicmnd_cmpl->residual);\r\nbreak;\r\ncase FCPIO_ABORTED:\r\nCMD_FLAGS(sc) |= FNIC_IO_ABORTED;\r\nbreak;\r\ndefault:\r\nFNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,\r\n"icmnd_cmpl abts pending "\r\n"hdr status = %s tag = 0x%x sc = 0x%p\n",\r\nfnic_fcpio_status_to_str(hdr_status),\r\nid, sc);\r\nbreak;\r\n}\r\nreturn;\r\n}\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_COMPLETE;\r\nicmnd_cmpl = &desc->u.icmnd_cmpl;\r\nswitch (hdr_status) {\r\ncase FCPIO_SUCCESS:\r\nsc->result = (DID_OK << 16) | icmnd_cmpl->scsi_status;\r\nxfer_len = scsi_bufflen(sc);\r\nscsi_set_resid(sc, icmnd_cmpl->residual);\r\nif (icmnd_cmpl->flags & FCPIO_ICMND_CMPL_RESID_UNDER)\r\nxfer_len -= icmnd_cmpl->residual;\r\nif (icmnd_cmpl->scsi_status == SAM_STAT_TASK_SET_FULL)\r\natomic64_inc(&fnic_stats->misc_stats.queue_fulls);\r\nbreak;\r\ncase FCPIO_TIMEOUT:\r\natomic64_inc(&fnic_stats->misc_stats.fcpio_timeout);\r\nsc->result = (DID_TIME_OUT << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_ABORTED:\r\natomic64_inc(&fnic_stats->misc_stats.fcpio_aborted);\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_DATA_CNT_MISMATCH:\r\natomic64_inc(&fnic_stats->misc_stats.data_count_mismatch);\r\nscsi_set_resid(sc, icmnd_cmpl->residual);\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_OUT_OF_RESOURCE:\r\natomic64_inc(&fnic_stats->fw_stats.fw_out_of_resources);\r\nsc->result = (DID_REQUEUE << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_IO_NOT_FOUND:\r\natomic64_inc(&fnic_stats->io_stats.io_not_found);\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_SGL_INVALID:\r\natomic64_inc(&fnic_stats->misc_stats.sgl_invalid);\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_FW_ERR:\r\natomic64_inc(&fnic_stats->fw_stats.io_fw_errs);\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_MSS_INVALID:\r\natomic64_inc(&fnic_stats->misc_stats.mss_invalid);\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\ncase FCPIO_INVALID_HEADER:\r\ncase FCPIO_INVALID_PARAM:\r\ncase FCPIO_REQ_NOT_SUPPORTED:\r\ndefault:\r\nshost_printk(KERN_ERR, fnic->lport->host, "hdr status = %s\n",\r\nfnic_fcpio_status_to_str(hdr_status));\r\nsc->result = (DID_ERROR << 16) | icmnd_cmpl->scsi_status;\r\nbreak;\r\n}\r\nif (hdr_status != FCPIO_SUCCESS) {\r\natomic64_inc(&fnic_stats->io_stats.io_failures);\r\nshost_printk(KERN_ERR, fnic->lport->host, "hdr status = %s\n",\r\nfnic_fcpio_status_to_str(hdr_status));\r\n}\r\nCMD_SP(sc) = NULL;\r\nCMD_FLAGS(sc) |= FNIC_IO_DONE;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\ncmd_trace = ((u64)hdr_status << 56) |\r\n(u64)icmnd_cmpl->scsi_status << 48 |\r\n(u64)icmnd_cmpl->flags << 40 | (u64)sc->cmnd[0] << 32 |\r\n(u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |\r\n(u64)sc->cmnd[4] << 8 | sc->cmnd[5];\r\nFNIC_TRACE(fnic_fcpio_icmnd_cmpl_handler,\r\nsc->device->host->host_no, id, sc,\r\n((u64)icmnd_cmpl->_resvd0[1] << 56 |\r\n(u64)icmnd_cmpl->_resvd0[0] << 48 |\r\njiffies_to_msecs(jiffies - start_time)),\r\ndesc, cmd_trace,\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nif (sc->sc_data_direction == DMA_FROM_DEVICE) {\r\nfnic->lport->host_stats.fcp_input_requests++;\r\nfnic->fcp_input_bytes += xfer_len;\r\n} else if (sc->sc_data_direction == DMA_TO_DEVICE) {\r\nfnic->lport->host_stats.fcp_output_requests++;\r\nfnic->fcp_output_bytes += xfer_len;\r\n} else\r\nfnic->lport->host_stats.fcp_control_requests++;\r\natomic64_dec(&fnic_stats->io_stats.active_ios);\r\nif (atomic64_read(&fnic->io_cmpl_skip))\r\natomic64_dec(&fnic->io_cmpl_skip);\r\nelse\r\natomic64_inc(&fnic_stats->io_stats.io_completions);\r\nif (sc->scsi_done)\r\nsc->scsi_done(sc);\r\n}\r\nstatic void fnic_fcpio_itmf_cmpl_handler(struct fnic *fnic,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nu8 type;\r\nu8 hdr_status;\r\nstruct fcpio_tag tag;\r\nu32 id;\r\nstruct scsi_cmnd *sc;\r\nstruct fnic_io_req *io_req;\r\nstruct fnic_stats *fnic_stats = &fnic->fnic_stats;\r\nstruct abort_stats *abts_stats = &fnic->fnic_stats.abts_stats;\r\nstruct terminate_stats *term_stats = &fnic->fnic_stats.term_stats;\r\nstruct misc_stats *misc_stats = &fnic->fnic_stats.misc_stats;\r\nunsigned long flags;\r\nspinlock_t *io_lock;\r\nunsigned long start_time;\r\nfcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);\r\nfcpio_tag_id_dec(&tag, &id);\r\nif ((id & FNIC_TAG_MASK) >= fnic->fnic_max_tag_id) {\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"Tag out of range tag %x hdr status = %s\n",\r\nid, fnic_fcpio_status_to_str(hdr_status));\r\nreturn;\r\n}\r\nsc = scsi_host_find_tag(fnic->lport->host, id & FNIC_TAG_MASK);\r\nWARN_ON_ONCE(!sc);\r\nif (!sc) {\r\natomic64_inc(&fnic_stats->io_stats.sc_null);\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"itmf_cmpl sc is null - hdr status = %s tag = 0x%x\n",\r\nfnic_fcpio_status_to_str(hdr_status), id);\r\nreturn;\r\n}\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nWARN_ON_ONCE(!io_req);\r\nif (!io_req) {\r\natomic64_inc(&fnic_stats->io_stats.ioreq_null);\r\nspin_unlock_irqrestore(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_IO_ABT_TERM_REQ_NULL;\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"itmf_cmpl io_req is null - "\r\n"hdr status = %s tag = 0x%x sc 0x%p\n",\r\nfnic_fcpio_status_to_str(hdr_status), id, sc);\r\nreturn;\r\n}\r\nstart_time = io_req->start_time;\r\nif ((id & FNIC_TAG_ABORT) && (id & FNIC_TAG_DEV_RST)) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"dev reset abts cmpl recd. id %x status %s\n",\r\nid, fnic_fcpio_status_to_str(hdr_status));\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_COMPLETE;\r\nCMD_ABTS_STATUS(sc) = hdr_status;\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_DONE;\r\nif (io_req->abts_done)\r\ncomplete(io_req->abts_done);\r\nspin_unlock_irqrestore(io_lock, flags);\r\n} else if (id & FNIC_TAG_ABORT) {\r\nswitch (hdr_status) {\r\ncase FCPIO_SUCCESS:\r\nbreak;\r\ncase FCPIO_TIMEOUT:\r\nif (CMD_FLAGS(sc) & FNIC_IO_ABTS_ISSUED)\r\natomic64_inc(&abts_stats->abort_fw_timeouts);\r\nelse\r\natomic64_inc(\r\n&term_stats->terminate_fw_timeouts);\r\nbreak;\r\ncase FCPIO_IO_NOT_FOUND:\r\nif (CMD_FLAGS(sc) & FNIC_IO_ABTS_ISSUED)\r\natomic64_inc(&abts_stats->abort_io_not_found);\r\nelse\r\natomic64_inc(\r\n&term_stats->terminate_io_not_found);\r\nbreak;\r\ndefault:\r\nif (CMD_FLAGS(sc) & FNIC_IO_ABTS_ISSUED)\r\natomic64_inc(&abts_stats->abort_failures);\r\nelse\r\natomic64_inc(\r\n&term_stats->terminate_failures);\r\nbreak;\r\n}\r\nif (CMD_STATE(sc) != FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nreturn;\r\n}\r\nCMD_ABTS_STATUS(sc) = hdr_status;\r\nCMD_FLAGS(sc) |= FNIC_IO_ABT_TERM_DONE;\r\natomic64_dec(&fnic_stats->io_stats.active_ios);\r\nif (atomic64_read(&fnic->io_cmpl_skip))\r\natomic64_dec(&fnic->io_cmpl_skip);\r\nelse\r\natomic64_inc(&fnic_stats->io_stats.io_completions);\r\nif (!(CMD_FLAGS(sc) & (FNIC_IO_ABORTED | FNIC_IO_DONE)))\r\natomic64_inc(&misc_stats->no_icmnd_itmf_cmpls);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"abts cmpl recd. id %d status %s\n",\r\n(int)(id & FNIC_TAG_MASK),\r\nfnic_fcpio_status_to_str(hdr_status));\r\nif (io_req->abts_done) {\r\ncomplete(io_req->abts_done);\r\nspin_unlock_irqrestore(io_lock, flags);\r\n} else {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"abts cmpl, completing IO\n");\r\nCMD_SP(sc) = NULL;\r\nsc->result = (DID_ERROR << 16);\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\nif (sc->scsi_done) {\r\nFNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,\r\nsc->device->host->host_no, id,\r\nsc,\r\njiffies_to_msecs(jiffies - start_time),\r\ndesc,\r\n(((u64)hdr_status << 40) |\r\n(u64)sc->cmnd[0] << 32 |\r\n(u64)sc->cmnd[2] << 24 |\r\n(u64)sc->cmnd[3] << 16 |\r\n(u64)sc->cmnd[4] << 8 | sc->cmnd[5]),\r\n(((u64)CMD_FLAGS(sc) << 32) |\r\nCMD_STATE(sc)));\r\nsc->scsi_done(sc);\r\n}\r\n}\r\n} else if (id & FNIC_TAG_DEV_RST) {\r\nCMD_LR_STATUS(sc) = hdr_status;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_ABTS_PENDING;\r\nFNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,\r\nsc->device->host->host_no, id, sc,\r\njiffies_to_msecs(jiffies - start_time),\r\ndesc, 0,\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Terminate pending "\r\n"dev reset cmpl recd. id %d status %s\n",\r\n(int)(id & FNIC_TAG_MASK),\r\nfnic_fcpio_status_to_str(hdr_status));\r\nreturn;\r\n}\r\nif (CMD_FLAGS(sc) & FNIC_DEV_RST_TIMED_OUT) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nFNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,\r\nsc->device->host->host_no, id, sc,\r\njiffies_to_msecs(jiffies - start_time),\r\ndesc, 0,\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"dev reset cmpl recd after time out. "\r\n"id %d status %s\n",\r\n(int)(id & FNIC_TAG_MASK),\r\nfnic_fcpio_status_to_str(hdr_status));\r\nreturn;\r\n}\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_COMPLETE;\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_DONE;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"dev reset cmpl recd. id %d status %s\n",\r\n(int)(id & FNIC_TAG_MASK),\r\nfnic_fcpio_status_to_str(hdr_status));\r\nif (io_req->dr_done)\r\ncomplete(io_req->dr_done);\r\nspin_unlock_irqrestore(io_lock, flags);\r\n} else {\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"Unexpected itmf io state %s tag %x\n",\r\nfnic_ioreq_state_to_str(CMD_STATE(sc)), id);\r\nspin_unlock_irqrestore(io_lock, flags);\r\n}\r\n}\r\nstatic int fnic_fcpio_cmpl_handler(struct vnic_dev *vdev,\r\nunsigned int cq_index,\r\nstruct fcpio_fw_req *desc)\r\n{\r\nstruct fnic *fnic = vnic_dev_priv(vdev);\r\nswitch (desc->hdr.type) {\r\ncase FCPIO_ICMND_CMPL:\r\ncase FCPIO_ITMF_CMPL:\r\ncase FCPIO_FLOGI_REG_CMPL:\r\ncase FCPIO_FLOGI_FIP_REG_CMPL:\r\ncase FCPIO_RESET_CMPL:\r\natomic64_dec(&fnic->fnic_stats.fw_stats.active_fw_reqs);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nswitch (desc->hdr.type) {\r\ncase FCPIO_ACK:\r\nfnic_fcpio_ack_handler(fnic, cq_index, desc);\r\nbreak;\r\ncase FCPIO_ICMND_CMPL:\r\nfnic_fcpio_icmnd_cmpl_handler(fnic, desc);\r\nbreak;\r\ncase FCPIO_ITMF_CMPL:\r\nfnic_fcpio_itmf_cmpl_handler(fnic, desc);\r\nbreak;\r\ncase FCPIO_FLOGI_REG_CMPL:\r\ncase FCPIO_FLOGI_FIP_REG_CMPL:\r\nfnic_fcpio_flogi_reg_cmpl_handler(fnic, desc);\r\nbreak;\r\ncase FCPIO_RESET_CMPL:\r\nfnic_fcpio_fw_reset_cmpl_handler(fnic, desc);\r\nbreak;\r\ndefault:\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"firmware completion type %d\n",\r\ndesc->hdr.type);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nint fnic_wq_copy_cmpl_handler(struct fnic *fnic, int copy_work_to_do)\r\n{\r\nunsigned int wq_work_done = 0;\r\nunsigned int i, cq_index;\r\nunsigned int cur_work_done;\r\nfor (i = 0; i < fnic->wq_copy_count; i++) {\r\ncq_index = i + fnic->raw_wq_count + fnic->rq_count;\r\ncur_work_done = vnic_cq_copy_service(&fnic->cq[cq_index],\r\nfnic_fcpio_cmpl_handler,\r\ncopy_work_to_do);\r\nwq_work_done += cur_work_done;\r\n}\r\nreturn wq_work_done;\r\n}\r\nstatic void fnic_cleanup_io(struct fnic *fnic, int exclude_id)\r\n{\r\nint i;\r\nstruct fnic_io_req *io_req;\r\nunsigned long flags = 0;\r\nstruct scsi_cmnd *sc;\r\nspinlock_t *io_lock;\r\nunsigned long start_time = 0;\r\nstruct fnic_stats *fnic_stats = &fnic->fnic_stats;\r\nfor (i = 0; i < fnic->fnic_max_tag_id; i++) {\r\nif (i == exclude_id)\r\ncontinue;\r\nio_lock = fnic_io_lock_tag(fnic, i);\r\nspin_lock_irqsave(io_lock, flags);\r\nsc = scsi_host_find_tag(fnic->lport->host, i);\r\nif (!sc) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif ((CMD_FLAGS(sc) & FNIC_DEVICE_RESET) &&\r\n!(CMD_FLAGS(sc) & FNIC_DEV_RST_DONE)) {\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_DONE;\r\nif (io_req && io_req->dr_done)\r\ncomplete(io_req->dr_done);\r\nelse if (io_req && io_req->abts_done)\r\ncomplete(io_req->abts_done);\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n} else if (CMD_FLAGS(sc) & FNIC_DEVICE_RESET) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto cleanup_scsi_cmd;\r\n}\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nstart_time = io_req->start_time;\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\ncleanup_scsi_cmd:\r\nsc->result = DID_TRANSPORT_DISRUPTED << 16;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"%s: sc duration = %lu DID_TRANSPORT_DISRUPTED\n",\r\n__func__, (jiffies - start_time));\r\nif (atomic64_read(&fnic->io_cmpl_skip))\r\natomic64_dec(&fnic->io_cmpl_skip);\r\nelse\r\natomic64_inc(&fnic_stats->io_stats.io_completions);\r\nif (sc->scsi_done) {\r\nFNIC_TRACE(fnic_cleanup_io,\r\nsc->device->host->host_no, i, sc,\r\njiffies_to_msecs(jiffies - start_time),\r\n0, ((u64)sc->cmnd[0] << 32 |\r\n(u64)sc->cmnd[2] << 24 |\r\n(u64)sc->cmnd[3] << 16 |\r\n(u64)sc->cmnd[4] << 8 | sc->cmnd[5]),\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nsc->scsi_done(sc);\r\n}\r\n}\r\n}\r\nvoid fnic_wq_copy_cleanup_handler(struct vnic_wq_copy *wq,\r\nstruct fcpio_host_req *desc)\r\n{\r\nu32 id;\r\nstruct fnic *fnic = vnic_dev_priv(wq->vdev);\r\nstruct fnic_io_req *io_req;\r\nstruct scsi_cmnd *sc;\r\nunsigned long flags;\r\nspinlock_t *io_lock;\r\nunsigned long start_time = 0;\r\nfcpio_tag_id_dec(&desc->hdr.tag, &id);\r\nid &= FNIC_TAG_MASK;\r\nif (id >= fnic->fnic_max_tag_id)\r\nreturn;\r\nsc = scsi_host_find_tag(fnic->lport->host, id);\r\nif (!sc)\r\nreturn;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto wq_copy_cleanup_scsi_cmd;\r\n}\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nstart_time = io_req->start_time;\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\nwq_copy_cleanup_scsi_cmd:\r\nsc->result = DID_NO_CONNECT << 16;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host, "wq_copy_cleanup_handler:"\r\n" DID_NO_CONNECT\n");\r\nif (sc->scsi_done) {\r\nFNIC_TRACE(fnic_wq_copy_cleanup_handler,\r\nsc->device->host->host_no, id, sc,\r\njiffies_to_msecs(jiffies - start_time),\r\n0, ((u64)sc->cmnd[0] << 32 |\r\n(u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |\r\n(u64)sc->cmnd[4] << 8 | sc->cmnd[5]),\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nsc->scsi_done(sc);\r\n}\r\n}\r\nstatic inline int fnic_queue_abort_io_req(struct fnic *fnic, int tag,\r\nu32 task_req, u8 *fc_lun,\r\nstruct fnic_io_req *io_req)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nstruct Scsi_Host *host = fnic->lport->host;\r\nstruct misc_stats *misc_stats = &fnic->fnic_stats.misc_stats;\r\nunsigned long flags;\r\nspin_lock_irqsave(host->host_lock, flags);\r\nif (unlikely(fnic_chk_state_flags_locked(fnic,\r\nFNIC_FLAGS_IO_BLOCKED))) {\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nreturn 1;\r\n} else\r\natomic_inc(&fnic->in_flight);\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq)) {\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\natomic_dec(&fnic->in_flight);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_queue_abort_io_req: failure: no descriptors\n");\r\natomic64_inc(&misc_stats->abts_cpwq_alloc_failures);\r\nreturn 1;\r\n}\r\nfnic_queue_wq_copy_desc_itmf(wq, tag | FNIC_TAG_ABORT,\r\n0, task_req, tag, fc_lun, io_req->port_id,\r\nfnic->config.ra_tov, fnic->config.ed_tov);\r\natomic64_inc(&fnic->fnic_stats.fw_stats.active_fw_reqs);\r\nif (atomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs) >\r\natomic64_read(&fnic->fnic_stats.fw_stats.max_fw_reqs))\r\natomic64_set(&fnic->fnic_stats.fw_stats.max_fw_reqs,\r\natomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs));\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);\r\natomic_dec(&fnic->in_flight);\r\nreturn 0;\r\n}\r\nstatic void fnic_rport_exch_reset(struct fnic *fnic, u32 port_id)\r\n{\r\nint tag;\r\nint abt_tag;\r\nint term_cnt = 0;\r\nstruct fnic_io_req *io_req;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nstruct scsi_cmnd *sc;\r\nstruct reset_stats *reset_stats = &fnic->fnic_stats.reset_stats;\r\nstruct terminate_stats *term_stats = &fnic->fnic_stats.term_stats;\r\nstruct scsi_lun fc_lun;\r\nenum fnic_ioreq_state old_ioreq_state;\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic_rport_exch_reset called portid 0x%06x\n",\r\nport_id);\r\nif (fnic->in_remove)\r\nreturn;\r\nfor (tag = 0; tag < fnic->fnic_max_tag_id; tag++) {\r\nabt_tag = tag;\r\nio_lock = fnic_io_lock_tag(fnic, tag);\r\nspin_lock_irqsave(io_lock, flags);\r\nsc = scsi_host_find_tag(fnic->lport->host, tag);\r\nif (!sc) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req || io_req->port_id != port_id) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif ((CMD_FLAGS(sc) & FNIC_DEVICE_RESET) &&\r\n(!(CMD_FLAGS(sc) & FNIC_DEV_RST_ISSUED))) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_rport_exch_reset dev rst not pending sc 0x%p\n",\r\nsc);\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (io_req->abts_done) {\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"fnic_rport_exch_reset: io_req->abts_done is set "\r\n"state is %s\n",\r\nfnic_ioreq_state_to_str(CMD_STATE(sc)));\r\n}\r\nif (!(CMD_FLAGS(sc) & FNIC_IO_ISSUED)) {\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"rport_exch_reset "\r\n"IO not yet issued %p tag 0x%x flags "\r\n"%x state %d\n",\r\nsc, tag, CMD_FLAGS(sc), CMD_STATE(sc));\r\n}\r\nold_ioreq_state = CMD_STATE(sc);\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nif (CMD_FLAGS(sc) & FNIC_DEVICE_RESET) {\r\natomic64_inc(&reset_stats->device_reset_terminates);\r\nabt_tag = (tag | FNIC_TAG_DEV_RST);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_rport_exch_reset dev rst sc 0x%p\n",\r\nsc);\r\n}\r\nBUG_ON(io_req->abts_done);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_rport_reset_exch: Issuing abts\n");\r\nspin_unlock_irqrestore(io_lock, flags);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, abt_tag,\r\nFCPIO_ITMF_ABT_TASK_TERM,\r\nfc_lun.scsi_lun, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)\r\nCMD_STATE(sc) = old_ioreq_state;\r\nspin_unlock_irqrestore(io_lock, flags);\r\n} else {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_FLAGS(sc) & FNIC_DEVICE_RESET)\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_TERM_ISSUED;\r\nelse\r\nCMD_FLAGS(sc) |= FNIC_IO_INTERNAL_TERM_ISSUED;\r\nspin_unlock_irqrestore(io_lock, flags);\r\natomic64_inc(&term_stats->terminates);\r\nterm_cnt++;\r\n}\r\n}\r\nif (term_cnt > atomic64_read(&term_stats->max_terminates))\r\natomic64_set(&term_stats->max_terminates, term_cnt);\r\n}\r\nvoid fnic_terminate_rport_io(struct fc_rport *rport)\r\n{\r\nint tag;\r\nint abt_tag;\r\nint term_cnt = 0;\r\nstruct fnic_io_req *io_req;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nstruct scsi_cmnd *sc;\r\nstruct scsi_lun fc_lun;\r\nstruct fc_rport_libfc_priv *rdata;\r\nstruct fc_lport *lport;\r\nstruct fnic *fnic;\r\nstruct fc_rport *cmd_rport;\r\nstruct reset_stats *reset_stats;\r\nstruct terminate_stats *term_stats;\r\nenum fnic_ioreq_state old_ioreq_state;\r\nif (!rport) {\r\nprintk(KERN_ERR "fnic_terminate_rport_io: rport is NULL\n");\r\nreturn;\r\n}\r\nrdata = rport->dd_data;\r\nif (!rdata) {\r\nprintk(KERN_ERR "fnic_terminate_rport_io: rdata is NULL\n");\r\nreturn;\r\n}\r\nlport = rdata->local_port;\r\nif (!lport) {\r\nprintk(KERN_ERR "fnic_terminate_rport_io: lport is NULL\n");\r\nreturn;\r\n}\r\nfnic = lport_priv(lport);\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host, "fnic_terminate_rport_io called"\r\n" wwpn 0x%llx, wwnn0x%llx, rport 0x%p, portid 0x%06x\n",\r\nrport->port_name, rport->node_name, rport,\r\nrport->port_id);\r\nif (fnic->in_remove)\r\nreturn;\r\nreset_stats = &fnic->fnic_stats.reset_stats;\r\nterm_stats = &fnic->fnic_stats.term_stats;\r\nfor (tag = 0; tag < fnic->fnic_max_tag_id; tag++) {\r\nabt_tag = tag;\r\nio_lock = fnic_io_lock_tag(fnic, tag);\r\nspin_lock_irqsave(io_lock, flags);\r\nsc = scsi_host_find_tag(fnic->lport->host, tag);\r\nif (!sc) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\ncmd_rport = starget_to_rport(scsi_target(sc->device));\r\nif (rport != cmd_rport) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req || rport != cmd_rport) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif ((CMD_FLAGS(sc) & FNIC_DEVICE_RESET) &&\r\n(!(CMD_FLAGS(sc) & FNIC_DEV_RST_ISSUED))) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_terminate_rport_io dev rst not pending sc 0x%p\n",\r\nsc);\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (io_req->abts_done) {\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"fnic_terminate_rport_io: io_req->abts_done is set "\r\n"state is %s\n",\r\nfnic_ioreq_state_to_str(CMD_STATE(sc)));\r\n}\r\nif (!(CMD_FLAGS(sc) & FNIC_IO_ISSUED)) {\r\nFNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,\r\n"fnic_terminate_rport_io "\r\n"IO not yet issued %p tag 0x%x flags "\r\n"%x state %d\n",\r\nsc, tag, CMD_FLAGS(sc), CMD_STATE(sc));\r\n}\r\nold_ioreq_state = CMD_STATE(sc);\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nif (CMD_FLAGS(sc) & FNIC_DEVICE_RESET) {\r\natomic64_inc(&reset_stats->device_reset_terminates);\r\nabt_tag = (tag | FNIC_TAG_DEV_RST);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_terminate_rport_io dev rst sc 0x%p\n", sc);\r\n}\r\nBUG_ON(io_req->abts_done);\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"fnic_terminate_rport_io: Issuing abts\n");\r\nspin_unlock_irqrestore(io_lock, flags);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, abt_tag,\r\nFCPIO_ITMF_ABT_TASK_TERM,\r\nfc_lun.scsi_lun, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)\r\nCMD_STATE(sc) = old_ioreq_state;\r\nspin_unlock_irqrestore(io_lock, flags);\r\n} else {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_FLAGS(sc) & FNIC_DEVICE_RESET)\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_TERM_ISSUED;\r\nelse\r\nCMD_FLAGS(sc) |= FNIC_IO_INTERNAL_TERM_ISSUED;\r\nspin_unlock_irqrestore(io_lock, flags);\r\natomic64_inc(&term_stats->terminates);\r\nterm_cnt++;\r\n}\r\n}\r\nif (term_cnt > atomic64_read(&term_stats->max_terminates))\r\natomic64_set(&term_stats->max_terminates, term_cnt);\r\n}\r\nint fnic_abort_cmd(struct scsi_cmnd *sc)\r\n{\r\nstruct fc_lport *lp;\r\nstruct fnic *fnic;\r\nstruct fnic_io_req *io_req = NULL;\r\nstruct fc_rport *rport;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nunsigned long start_time = 0;\r\nint ret = SUCCESS;\r\nu32 task_req = 0;\r\nstruct scsi_lun fc_lun;\r\nstruct fnic_stats *fnic_stats;\r\nstruct abort_stats *abts_stats;\r\nstruct terminate_stats *term_stats;\r\nenum fnic_ioreq_state old_ioreq_state;\r\nint tag;\r\nDECLARE_COMPLETION_ONSTACK(tm_done);\r\nfc_block_scsi_eh(sc);\r\nlp = shost_priv(sc->device->host);\r\nfnic = lport_priv(lp);\r\nfnic_stats = &fnic->fnic_stats;\r\nabts_stats = &fnic->fnic_stats.abts_stats;\r\nterm_stats = &fnic->fnic_stats.term_stats;\r\nrport = starget_to_rport(scsi_target(sc->device));\r\ntag = sc->request->tag;\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"Abort Cmd called FCID 0x%x, LUN 0x%llx TAG %x flags %x\n",\r\nrport->port_id, sc->device->lun, tag, CMD_FLAGS(sc));\r\nCMD_FLAGS(sc) = FNIC_NO_FLAGS;\r\nif (lp->state != LPORT_ST_READY || !(lp->link_up)) {\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto fnic_abort_cmd_end;\r\n}\r\nio_req->abts_done = &tm_done;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto wait_pending;\r\n}\r\nold_ioreq_state = CMD_STATE(sc);\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (fc_remote_port_chkready(rport) == 0)\r\ntask_req = FCPIO_ITMF_ABT_TASK;\r\nelse {\r\natomic64_inc(&fnic_stats->misc_stats.rport_not_ready);\r\ntask_req = FCPIO_ITMF_ABT_TASK_TERM;\r\n}\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, sc->request->tag, task_req,\r\nfc_lun.scsi_lun, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)\r\nCMD_STATE(sc) = old_ioreq_state;\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nio_req->abts_done = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nif (task_req == FCPIO_ITMF_ABT_TASK) {\r\nCMD_FLAGS(sc) |= FNIC_IO_ABTS_ISSUED;\r\natomic64_inc(&fnic_stats->abts_stats.aborts);\r\n} else {\r\nCMD_FLAGS(sc) |= FNIC_IO_TERM_ISSUED;\r\natomic64_inc(&fnic_stats->term_stats.terminates);\r\n}\r\nwait_pending:\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies\r\n(2 * fnic->config.ra_tov +\r\nfnic->config.ed_tov));\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\natomic64_inc(&fnic_stats->io_stats.ioreq_null);\r\nspin_unlock_irqrestore(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_IO_ABT_TERM_REQ_NULL;\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nio_req->abts_done = NULL;\r\nif (CMD_ABTS_STATUS(sc) == FCPIO_INVALID_CODE) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (task_req == FCPIO_ITMF_ABT_TASK) {\r\natomic64_inc(&abts_stats->abort_drv_timeouts);\r\n} else {\r\natomic64_inc(&term_stats->terminate_drv_timeouts);\r\n}\r\nCMD_FLAGS(sc) |= FNIC_IO_ABT_TERM_TIMED_OUT;\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nif (!(CMD_FLAGS(sc) & (FNIC_IO_ABORTED | FNIC_IO_DONE))) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Issuing Host reset due to out of order IO\n");\r\nif (fnic_host_reset(sc) == FAILED) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_host_reset failed.\n");\r\n}\r\nret = FAILED;\r\ngoto fnic_abort_cmd_end;\r\n}\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_COMPLETE;\r\nif (CMD_ABTS_STATUS(sc) != FCPIO_SUCCESS)\r\nret = FAILED;\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nstart_time = io_req->start_time;\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\nfnic_abort_cmd_end:\r\nFNIC_TRACE(fnic_abort_cmd, sc->device->host->host_no,\r\nsc->request->tag, sc,\r\njiffies_to_msecs(jiffies - start_time),\r\n0, ((u64)sc->cmnd[0] << 32 |\r\n(u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |\r\n(u64)sc->cmnd[4] << 8 | sc->cmnd[5]),\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Returning from abort cmd type %x %s\n", task_req,\r\n(ret == SUCCESS) ?\r\n"SUCCESS" : "FAILED");\r\nreturn ret;\r\n}\r\nstatic inline int fnic_queue_dr_io_req(struct fnic *fnic,\r\nstruct scsi_cmnd *sc,\r\nstruct fnic_io_req *io_req)\r\n{\r\nstruct vnic_wq_copy *wq = &fnic->wq_copy[0];\r\nstruct Scsi_Host *host = fnic->lport->host;\r\nstruct misc_stats *misc_stats = &fnic->fnic_stats.misc_stats;\r\nstruct scsi_lun fc_lun;\r\nint ret = 0;\r\nunsigned long intr_flags;\r\nspin_lock_irqsave(host->host_lock, intr_flags);\r\nif (unlikely(fnic_chk_state_flags_locked(fnic,\r\nFNIC_FLAGS_IO_BLOCKED))) {\r\nspin_unlock_irqrestore(host->host_lock, intr_flags);\r\nreturn FAILED;\r\n} else\r\natomic_inc(&fnic->in_flight);\r\nspin_unlock_irqrestore(host->host_lock, intr_flags);\r\nspin_lock_irqsave(&fnic->wq_copy_lock[0], intr_flags);\r\nif (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])\r\nfree_wq_copy_descs(fnic, wq);\r\nif (!vnic_wq_copy_desc_avail(wq)) {\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"queue_dr_io_req failure - no descriptors\n");\r\natomic64_inc(&misc_stats->devrst_cpwq_alloc_failures);\r\nret = -EAGAIN;\r\ngoto lr_io_req_end;\r\n}\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nfnic_queue_wq_copy_desc_itmf(wq, sc->request->tag | FNIC_TAG_DEV_RST,\r\n0, FCPIO_ITMF_LUN_RESET, SCSI_NO_TAG,\r\nfc_lun.scsi_lun, io_req->port_id,\r\nfnic->config.ra_tov, fnic->config.ed_tov);\r\natomic64_inc(&fnic->fnic_stats.fw_stats.active_fw_reqs);\r\nif (atomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs) >\r\natomic64_read(&fnic->fnic_stats.fw_stats.max_fw_reqs))\r\natomic64_set(&fnic->fnic_stats.fw_stats.max_fw_reqs,\r\natomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs));\r\nlr_io_req_end:\r\nspin_unlock_irqrestore(&fnic->wq_copy_lock[0], intr_flags);\r\natomic_dec(&fnic->in_flight);\r\nreturn ret;\r\n}\r\nstatic int fnic_clean_pending_aborts(struct fnic *fnic,\r\nstruct scsi_cmnd *lr_sc)\r\n{\r\nint tag, abt_tag;\r\nstruct fnic_io_req *io_req;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nint ret = 0;\r\nstruct scsi_cmnd *sc;\r\nstruct scsi_lun fc_lun;\r\nstruct scsi_device *lun_dev = lr_sc->device;\r\nDECLARE_COMPLETION_ONSTACK(tm_done);\r\nenum fnic_ioreq_state old_ioreq_state;\r\nfor (tag = 0; tag < fnic->fnic_max_tag_id; tag++) {\r\nio_lock = fnic_io_lock_tag(fnic, tag);\r\nspin_lock_irqsave(io_lock, flags);\r\nsc = scsi_host_find_tag(fnic->lport->host, tag);\r\nif (!sc || sc == lr_sc || sc->device != lun_dev) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req || sc->device != lun_dev) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Found IO in %s on lun\n",\r\nfnic_ioreq_state_to_str(CMD_STATE(sc)));\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif ((CMD_FLAGS(sc) & FNIC_DEVICE_RESET) &&\r\n(!(CMD_FLAGS(sc) & FNIC_DEV_RST_ISSUED))) {\r\nFNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,\r\n"%s dev rst not pending sc 0x%p\n", __func__,\r\nsc);\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nif (io_req->abts_done)\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"%s: io_req->abts_done is set state is %s\n",\r\n__func__, fnic_ioreq_state_to_str(CMD_STATE(sc)));\r\nold_ioreq_state = CMD_STATE(sc);\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nBUG_ON(io_req->abts_done);\r\nabt_tag = tag;\r\nif (CMD_FLAGS(sc) & FNIC_DEVICE_RESET) {\r\nabt_tag |= FNIC_TAG_DEV_RST;\r\nFNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,\r\n"%s: dev rst sc 0x%p\n", __func__, sc);\r\n}\r\nCMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;\r\nio_req->abts_done = &tm_done;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nif (fnic_queue_abort_io_req(fnic, abt_tag,\r\nFCPIO_ITMF_ABT_TASK_TERM,\r\nfc_lun.scsi_lun, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nio_req->abts_done = NULL;\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)\r\nCMD_STATE(sc) = old_ioreq_state;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nret = 1;\r\ngoto clean_pending_aborts_end;\r\n} else {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_FLAGS(sc) & FNIC_DEVICE_RESET)\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_TERM_ISSUED;\r\nspin_unlock_irqrestore(io_lock, flags);\r\n}\r\nCMD_FLAGS(sc) |= FNIC_IO_INTERNAL_TERM_ISSUED;\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies\r\n(fnic->config.ed_tov));\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_IO_ABT_TERM_REQ_NULL;\r\ncontinue;\r\n}\r\nio_req->abts_done = NULL;\r\nif (CMD_ABTS_STATUS(sc) == FCPIO_INVALID_CODE) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_IO_ABT_TERM_DONE;\r\nret = 1;\r\ngoto clean_pending_aborts_end;\r\n}\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_COMPLETE;\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\n}\r\nschedule_timeout(msecs_to_jiffies(2 * fnic->config.ed_tov));\r\nif (fnic_is_abts_pending(fnic, lr_sc))\r\nret = FAILED;\r\nclean_pending_aborts_end:\r\nreturn ret;\r\n}\r\nstatic inline int\r\nfnic_scsi_host_start_tag(struct fnic *fnic, struct scsi_cmnd *sc)\r\n{\r\nstruct blk_queue_tag *bqt = fnic->lport->host->bqt;\r\nint tag, ret = SCSI_NO_TAG;\r\nBUG_ON(!bqt);\r\nif (!bqt) {\r\npr_err("Tags are not supported\n");\r\ngoto end;\r\n}\r\ndo {\r\ntag = find_next_zero_bit(bqt->tag_map, bqt->max_depth, 1);\r\nif (tag >= bqt->max_depth) {\r\npr_err("Tag allocation failure\n");\r\ngoto end;\r\n}\r\n} while (test_and_set_bit(tag, bqt->tag_map));\r\nbqt->tag_index[tag] = sc->request;\r\nsc->request->tag = tag;\r\nsc->tag = tag;\r\nif (!sc->request->special)\r\nsc->request->special = sc;\r\nret = tag;\r\nend:\r\nreturn ret;\r\n}\r\nstatic inline void\r\nfnic_scsi_host_end_tag(struct fnic *fnic, struct scsi_cmnd *sc)\r\n{\r\nstruct blk_queue_tag *bqt = fnic->lport->host->bqt;\r\nint tag = sc->request->tag;\r\nif (tag == SCSI_NO_TAG)\r\nreturn;\r\nBUG_ON(!bqt || !bqt->tag_index[tag]);\r\nif (!bqt)\r\nreturn;\r\nbqt->tag_index[tag] = NULL;\r\nclear_bit(tag, bqt->tag_map);\r\nreturn;\r\n}\r\nint fnic_device_reset(struct scsi_cmnd *sc)\r\n{\r\nstruct fc_lport *lp;\r\nstruct fnic *fnic;\r\nstruct fnic_io_req *io_req = NULL;\r\nstruct fc_rport *rport;\r\nint status;\r\nint ret = FAILED;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nunsigned long start_time = 0;\r\nstruct scsi_lun fc_lun;\r\nstruct fnic_stats *fnic_stats;\r\nstruct reset_stats *reset_stats;\r\nint tag = 0;\r\nDECLARE_COMPLETION_ONSTACK(tm_done);\r\nint tag_gen_flag = 0;\r\nfc_block_scsi_eh(sc);\r\nlp = shost_priv(sc->device->host);\r\nfnic = lport_priv(lp);\r\nfnic_stats = &fnic->fnic_stats;\r\nreset_stats = &fnic->fnic_stats.reset_stats;\r\natomic64_inc(&reset_stats->device_resets);\r\nrport = starget_to_rport(scsi_target(sc->device));\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Device reset called FCID 0x%x, LUN 0x%llx sc 0x%p\n",\r\nrport->port_id, sc->device->lun, sc);\r\nif (lp->state != LPORT_ST_READY || !(lp->link_up))\r\ngoto fnic_device_reset_end;\r\nif (fc_remote_port_chkready(rport)) {\r\natomic64_inc(&fnic_stats->misc_stats.rport_not_ready);\r\ngoto fnic_device_reset_end;\r\n}\r\nCMD_FLAGS(sc) = FNIC_DEVICE_RESET;\r\ntag = sc->request->tag;\r\nif (unlikely(tag < 0)) {\r\nif (shost_use_blk_mq(sc->device->host))\r\ngoto fnic_device_reset_end;\r\ntag = fnic_scsi_host_start_tag(fnic, sc);\r\nif (unlikely(tag == SCSI_NO_TAG))\r\ngoto fnic_device_reset_end;\r\ntag_gen_flag = 1;\r\n}\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nio_req = mempool_alloc(fnic->io_req_pool, GFP_ATOMIC);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ngoto fnic_device_reset_end;\r\n}\r\nmemset(io_req, 0, sizeof(*io_req));\r\nio_req->port_id = rport->port_id;\r\nCMD_SP(sc) = (char *)io_req;\r\n}\r\nio_req->dr_done = &tm_done;\r\nCMD_STATE(sc) = FNIC_IOREQ_CMD_PENDING;\r\nCMD_LR_STATUS(sc) = FCPIO_INVALID_CODE;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host, "TAG %x\n", tag);\r\nif (fnic_queue_dr_io_req(fnic, sc, io_req)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nio_req->dr_done = NULL;\r\ngoto fnic_device_reset_clean;\r\n}\r\nspin_lock_irqsave(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_ISSUED;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies(FNIC_LUN_RESET_TIMEOUT));\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"io_req is null tag 0x%x sc 0x%p\n", tag, sc);\r\ngoto fnic_device_reset_end;\r\n}\r\nio_req->dr_done = NULL;\r\nstatus = CMD_LR_STATUS(sc);\r\nif (status == FCPIO_INVALID_CODE) {\r\natomic64_inc(&reset_stats->device_reset_timeouts);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Device reset timed out\n");\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_TIMED_OUT;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nint_to_scsilun(sc->device->lun, &fc_lun);\r\nwhile (1) {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (CMD_FLAGS(sc) & FNIC_DEV_RST_TERM_ISSUED) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (fnic_queue_abort_io_req(fnic,\r\ntag | FNIC_TAG_DEV_RST,\r\nFCPIO_ITMF_ABT_TASK_TERM,\r\nfc_lun.scsi_lun, io_req)) {\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies(FNIC_ABT_TERM_DELAY_TIMEOUT));\r\n} else {\r\nspin_lock_irqsave(io_lock, flags);\r\nCMD_FLAGS(sc) |= FNIC_DEV_RST_TERM_ISSUED;\r\nCMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;\r\nio_req->abts_done = &tm_done;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Abort and terminate issued on Device reset "\r\n"tag 0x%x sc 0x%p\n", tag, sc);\r\nbreak;\r\n}\r\n}\r\nwhile (1) {\r\nspin_lock_irqsave(io_lock, flags);\r\nif (!(CMD_FLAGS(sc) & FNIC_DEV_RST_DONE)) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\nwait_for_completion_timeout(&tm_done,\r\nmsecs_to_jiffies(FNIC_LUN_RESET_TIMEOUT));\r\nbreak;\r\n} else {\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nio_req->abts_done = NULL;\r\ngoto fnic_device_reset_clean;\r\n}\r\n}\r\n} else {\r\nspin_unlock_irqrestore(io_lock, flags);\r\n}\r\nif (status != FCPIO_SUCCESS) {\r\nspin_lock_irqsave(io_lock, flags);\r\nFNIC_SCSI_DBG(KERN_DEBUG,\r\nfnic->lport->host,\r\n"Device reset completed - failed\n");\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\ngoto fnic_device_reset_clean;\r\n}\r\nif (fnic_clean_pending_aborts(fnic, sc)) {\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Device reset failed"\r\n" since could not abort all IOs\n");\r\ngoto fnic_device_reset_clean;\r\n}\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (io_req)\r\nret = SUCCESS;\r\nfnic_device_reset_clean:\r\nif (io_req)\r\nCMD_SP(sc) = NULL;\r\nspin_unlock_irqrestore(io_lock, flags);\r\nif (io_req) {\r\nstart_time = io_req->start_time;\r\nfnic_release_ioreq_buf(fnic, io_req, sc);\r\nmempool_free(io_req, fnic->io_req_pool);\r\n}\r\nfnic_device_reset_end:\r\nFNIC_TRACE(fnic_device_reset, sc->device->host->host_no,\r\nsc->request->tag, sc,\r\njiffies_to_msecs(jiffies - start_time),\r\n0, ((u64)sc->cmnd[0] << 32 |\r\n(u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |\r\n(u64)sc->cmnd[4] << 8 | sc->cmnd[5]),\r\n(((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));\r\nif (unlikely(tag_gen_flag))\r\nfnic_scsi_host_end_tag(fnic, sc);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Returning from device reset %s\n",\r\n(ret == SUCCESS) ?\r\n"SUCCESS" : "FAILED");\r\nif (ret == FAILED)\r\natomic64_inc(&reset_stats->device_reset_failures);\r\nreturn ret;\r\n}\r\nint fnic_reset(struct Scsi_Host *shost)\r\n{\r\nstruct fc_lport *lp;\r\nstruct fnic *fnic;\r\nint ret = 0;\r\nstruct reset_stats *reset_stats;\r\nlp = shost_priv(shost);\r\nfnic = lport_priv(lp);\r\nreset_stats = &fnic->fnic_stats.reset_stats;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_reset called\n");\r\natomic64_inc(&reset_stats->fnic_resets);\r\nret = lp->tt.lport_reset(lp);\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Returning from fnic reset %s\n",\r\n(ret == 0) ?\r\n"SUCCESS" : "FAILED");\r\nif (ret == 0)\r\natomic64_inc(&reset_stats->fnic_reset_completions);\r\nelse\r\natomic64_inc(&reset_stats->fnic_reset_failures);\r\nreturn ret;\r\n}\r\nint fnic_host_reset(struct scsi_cmnd *sc)\r\n{\r\nint ret;\r\nunsigned long wait_host_tmo;\r\nstruct Scsi_Host *shost = sc->device->host;\r\nstruct fc_lport *lp = shost_priv(shost);\r\nret = (fnic_reset(shost) == 0) ? SUCCESS : FAILED;\r\nif (ret == SUCCESS) {\r\nwait_host_tmo = jiffies + FNIC_HOST_RESET_SETTLE_TIME * HZ;\r\nret = FAILED;\r\nwhile (time_before(jiffies, wait_host_tmo)) {\r\nif ((lp->state == LPORT_ST_READY) &&\r\n(lp->link_up)) {\r\nret = SUCCESS;\r\nbreak;\r\n}\r\nssleep(1);\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid fnic_scsi_abort_io(struct fc_lport *lp)\r\n{\r\nint err = 0;\r\nunsigned long flags;\r\nenum fnic_state old_state;\r\nstruct fnic *fnic = lport_priv(lp);\r\nDECLARE_COMPLETION_ONSTACK(remove_wait);\r\nretry_fw_reset:\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (unlikely(fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nschedule_timeout(msecs_to_jiffies(100));\r\ngoto retry_fw_reset;\r\n}\r\nfnic->remove_wait = &remove_wait;\r\nold_state = fnic->state;\r\nfnic->state = FNIC_IN_FC_TRANS_ETH_MODE;\r\nfnic_update_mac_locked(fnic, fnic->ctlr.ctl_src_addr);\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nerr = fnic_fw_reset_handler(fnic);\r\nif (err) {\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)\r\nfnic->state = old_state;\r\nfnic->remove_wait = NULL;\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nreturn;\r\n}\r\nwait_for_completion_timeout(&remove_wait,\r\nmsecs_to_jiffies(FNIC_RMDEVICE_TIMEOUT));\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nfnic->remove_wait = NULL;\r\nFNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,\r\n"fnic_scsi_abort_io %s\n",\r\n(fnic->state == FNIC_IN_ETH_MODE) ?\r\n"SUCCESS" : "FAILED");\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\nvoid fnic_scsi_cleanup(struct fc_lport *lp)\r\n{\r\nunsigned long flags;\r\nenum fnic_state old_state;\r\nstruct fnic *fnic = lport_priv(lp);\r\nretry_fw_reset:\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (unlikely(fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nschedule_timeout(msecs_to_jiffies(100));\r\ngoto retry_fw_reset;\r\n}\r\nold_state = fnic->state;\r\nfnic->state = FNIC_IN_FC_TRANS_ETH_MODE;\r\nfnic_update_mac_locked(fnic, fnic->ctlr.ctl_src_addr);\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nif (fnic_fw_reset_handler(fnic)) {\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)\r\nfnic->state = old_state;\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\n}\r\nvoid fnic_empty_scsi_cleanup(struct fc_lport *lp)\r\n{\r\n}\r\nvoid fnic_exch_mgr_reset(struct fc_lport *lp, u32 sid, u32 did)\r\n{\r\nstruct fnic *fnic = lport_priv(lp);\r\nif (sid)\r\ngoto call_fc_exch_mgr_reset;\r\nif (did) {\r\nfnic_rport_exch_reset(fnic, did);\r\ngoto call_fc_exch_mgr_reset;\r\n}\r\nif (!fnic->in_remove)\r\nfnic_scsi_cleanup(lp);\r\nelse\r\nfnic_scsi_abort_io(lp);\r\ncall_fc_exch_mgr_reset:\r\nfc_exch_mgr_reset(lp, sid, did);\r\n}\r\nint fnic_is_abts_pending(struct fnic *fnic, struct scsi_cmnd *lr_sc)\r\n{\r\nint tag;\r\nstruct fnic_io_req *io_req;\r\nspinlock_t *io_lock;\r\nunsigned long flags;\r\nint ret = 0;\r\nstruct scsi_cmnd *sc;\r\nstruct scsi_device *lun_dev = NULL;\r\nif (lr_sc)\r\nlun_dev = lr_sc->device;\r\nfor (tag = 0; tag < fnic->fnic_max_tag_id; tag++) {\r\nsc = scsi_host_find_tag(fnic->lport->host, tag);\r\nif (!sc || (lr_sc && (sc->device != lun_dev || sc == lr_sc)))\r\ncontinue;\r\nio_lock = fnic_io_lock_hash(fnic, sc);\r\nspin_lock_irqsave(io_lock, flags);\r\nio_req = (struct fnic_io_req *)CMD_SP(sc);\r\nif (!io_req || sc->device != lun_dev) {\r\nspin_unlock_irqrestore(io_lock, flags);\r\ncontinue;\r\n}\r\nFNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,\r\n"Found IO in %s on lun\n",\r\nfnic_ioreq_state_to_str(CMD_STATE(sc)));\r\nif (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)\r\nret = 1;\r\nspin_unlock_irqrestore(io_lock, flags);\r\n}\r\nreturn ret;\r\n}
