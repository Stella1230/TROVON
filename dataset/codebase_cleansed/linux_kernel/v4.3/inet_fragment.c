static unsigned int\r\ninet_frag_hashfn(const struct inet_frags *f, const struct inet_frag_queue *q)\r\n{\r\nreturn f->hashfn(q) & (INETFRAGS_HASHSZ - 1);\r\n}\r\nstatic bool inet_frag_may_rebuild(struct inet_frags *f)\r\n{\r\nreturn time_after(jiffies,\r\nf->last_rebuild_jiffies + INETFRAGS_MIN_REBUILD_INTERVAL);\r\n}\r\nstatic void inet_frag_secret_rebuild(struct inet_frags *f)\r\n{\r\nint i;\r\nwrite_seqlock_bh(&f->rnd_seqlock);\r\nif (!inet_frag_may_rebuild(f))\r\ngoto out;\r\nget_random_bytes(&f->rnd, sizeof(u32));\r\nfor (i = 0; i < INETFRAGS_HASHSZ; i++) {\r\nstruct inet_frag_bucket *hb;\r\nstruct inet_frag_queue *q;\r\nstruct hlist_node *n;\r\nhb = &f->hash[i];\r\nspin_lock(&hb->chain_lock);\r\nhlist_for_each_entry_safe(q, n, &hb->chain, list) {\r\nunsigned int hval = inet_frag_hashfn(f, q);\r\nif (hval != i) {\r\nstruct inet_frag_bucket *hb_dest;\r\nhlist_del(&q->list);\r\nhb_dest = &f->hash[hval];\r\nspin_lock_nested(&hb_dest->chain_lock,\r\nSINGLE_DEPTH_NESTING);\r\nhlist_add_head(&q->list, &hb_dest->chain);\r\nspin_unlock(&hb_dest->chain_lock);\r\n}\r\n}\r\nspin_unlock(&hb->chain_lock);\r\n}\r\nf->rebuild = false;\r\nf->last_rebuild_jiffies = jiffies;\r\nout:\r\nwrite_sequnlock_bh(&f->rnd_seqlock);\r\n}\r\nstatic bool inet_fragq_should_evict(const struct inet_frag_queue *q)\r\n{\r\nreturn q->net->low_thresh == 0 ||\r\nfrag_mem_limit(q->net) >= q->net->low_thresh;\r\n}\r\nstatic unsigned int\r\ninet_evict_bucket(struct inet_frags *f, struct inet_frag_bucket *hb)\r\n{\r\nstruct inet_frag_queue *fq;\r\nstruct hlist_node *n;\r\nunsigned int evicted = 0;\r\nHLIST_HEAD(expired);\r\nspin_lock(&hb->chain_lock);\r\nhlist_for_each_entry_safe(fq, n, &hb->chain, list) {\r\nif (!inet_fragq_should_evict(fq))\r\ncontinue;\r\nif (!del_timer(&fq->timer))\r\ncontinue;\r\nhlist_add_head(&fq->list_evictor, &expired);\r\n++evicted;\r\n}\r\nspin_unlock(&hb->chain_lock);\r\nhlist_for_each_entry_safe(fq, n, &expired, list_evictor)\r\nf->frag_expire((unsigned long) fq);\r\nreturn evicted;\r\n}\r\nstatic void inet_frag_worker(struct work_struct *work)\r\n{\r\nunsigned int budget = INETFRAGS_EVICT_BUCKETS;\r\nunsigned int i, evicted = 0;\r\nstruct inet_frags *f;\r\nf = container_of(work, struct inet_frags, frags_work);\r\nBUILD_BUG_ON(INETFRAGS_EVICT_BUCKETS >= INETFRAGS_HASHSZ);\r\nlocal_bh_disable();\r\nfor (i = ACCESS_ONCE(f->next_bucket); budget; --budget) {\r\nevicted += inet_evict_bucket(f, &f->hash[i]);\r\ni = (i + 1) & (INETFRAGS_HASHSZ - 1);\r\nif (evicted > INETFRAGS_EVICT_MAX)\r\nbreak;\r\n}\r\nf->next_bucket = i;\r\nlocal_bh_enable();\r\nif (f->rebuild && inet_frag_may_rebuild(f))\r\ninet_frag_secret_rebuild(f);\r\n}\r\nstatic void inet_frag_schedule_worker(struct inet_frags *f)\r\n{\r\nif (unlikely(!work_pending(&f->frags_work)))\r\nschedule_work(&f->frags_work);\r\n}\r\nint inet_frags_init(struct inet_frags *f)\r\n{\r\nint i;\r\nINIT_WORK(&f->frags_work, inet_frag_worker);\r\nfor (i = 0; i < INETFRAGS_HASHSZ; i++) {\r\nstruct inet_frag_bucket *hb = &f->hash[i];\r\nspin_lock_init(&hb->chain_lock);\r\nINIT_HLIST_HEAD(&hb->chain);\r\n}\r\nseqlock_init(&f->rnd_seqlock);\r\nf->last_rebuild_jiffies = 0;\r\nf->frags_cachep = kmem_cache_create(f->frags_cache_name, f->qsize, 0, 0,\r\nNULL);\r\nif (!f->frags_cachep)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid inet_frags_init_net(struct netns_frags *nf)\r\n{\r\ninit_frag_mem_limit(nf);\r\n}\r\nvoid inet_frags_fini(struct inet_frags *f)\r\n{\r\ncancel_work_sync(&f->frags_work);\r\nkmem_cache_destroy(f->frags_cachep);\r\n}\r\nvoid inet_frags_exit_net(struct netns_frags *nf, struct inet_frags *f)\r\n{\r\nunsigned int seq;\r\nint i;\r\nnf->low_thresh = 0;\r\nevict_again:\r\nlocal_bh_disable();\r\nseq = read_seqbegin(&f->rnd_seqlock);\r\nfor (i = 0; i < INETFRAGS_HASHSZ ; i++)\r\ninet_evict_bucket(f, &f->hash[i]);\r\nlocal_bh_enable();\r\ncond_resched();\r\nif (read_seqretry(&f->rnd_seqlock, seq) ||\r\npercpu_counter_sum(&nf->mem))\r\ngoto evict_again;\r\npercpu_counter_destroy(&nf->mem);\r\n}\r\nstatic struct inet_frag_bucket *\r\nget_frag_bucket_locked(struct inet_frag_queue *fq, struct inet_frags *f)\r\n__acquires(hb->chain_lock)\r\n{\r\nstruct inet_frag_bucket *hb;\r\nunsigned int seq, hash;\r\nrestart:\r\nseq = read_seqbegin(&f->rnd_seqlock);\r\nhash = inet_frag_hashfn(f, fq);\r\nhb = &f->hash[hash];\r\nspin_lock(&hb->chain_lock);\r\nif (read_seqretry(&f->rnd_seqlock, seq)) {\r\nspin_unlock(&hb->chain_lock);\r\ngoto restart;\r\n}\r\nreturn hb;\r\n}\r\nstatic inline void fq_unlink(struct inet_frag_queue *fq, struct inet_frags *f)\r\n{\r\nstruct inet_frag_bucket *hb;\r\nhb = get_frag_bucket_locked(fq, f);\r\nhlist_del(&fq->list);\r\nfq->flags |= INET_FRAG_COMPLETE;\r\nspin_unlock(&hb->chain_lock);\r\n}\r\nvoid inet_frag_kill(struct inet_frag_queue *fq, struct inet_frags *f)\r\n{\r\nif (del_timer(&fq->timer))\r\natomic_dec(&fq->refcnt);\r\nif (!(fq->flags & INET_FRAG_COMPLETE)) {\r\nfq_unlink(fq, f);\r\natomic_dec(&fq->refcnt);\r\n}\r\n}\r\nstatic inline void frag_kfree_skb(struct netns_frags *nf, struct inet_frags *f,\r\nstruct sk_buff *skb)\r\n{\r\nif (f->skb_free)\r\nf->skb_free(skb);\r\nkfree_skb(skb);\r\n}\r\nvoid inet_frag_destroy(struct inet_frag_queue *q, struct inet_frags *f)\r\n{\r\nstruct sk_buff *fp;\r\nstruct netns_frags *nf;\r\nunsigned int sum, sum_truesize = 0;\r\nWARN_ON(!(q->flags & INET_FRAG_COMPLETE));\r\nWARN_ON(del_timer(&q->timer) != 0);\r\nfp = q->fragments;\r\nnf = q->net;\r\nwhile (fp) {\r\nstruct sk_buff *xp = fp->next;\r\nsum_truesize += fp->truesize;\r\nfrag_kfree_skb(nf, f, fp);\r\nfp = xp;\r\n}\r\nsum = sum_truesize + f->qsize;\r\nif (f->destructor)\r\nf->destructor(q);\r\nkmem_cache_free(f->frags_cachep, q);\r\nsub_frag_mem_limit(nf, sum);\r\n}\r\nstatic struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf,\r\nstruct inet_frag_queue *qp_in,\r\nstruct inet_frags *f,\r\nvoid *arg)\r\n{\r\nstruct inet_frag_bucket *hb = get_frag_bucket_locked(qp_in, f);\r\nstruct inet_frag_queue *qp;\r\n#ifdef CONFIG_SMP\r\nhlist_for_each_entry(qp, &hb->chain, list) {\r\nif (qp->net == nf && f->match(qp, arg)) {\r\natomic_inc(&qp->refcnt);\r\nspin_unlock(&hb->chain_lock);\r\nqp_in->flags |= INET_FRAG_COMPLETE;\r\ninet_frag_put(qp_in, f);\r\nreturn qp;\r\n}\r\n}\r\n#endif\r\nqp = qp_in;\r\nif (!mod_timer(&qp->timer, jiffies + nf->timeout))\r\natomic_inc(&qp->refcnt);\r\natomic_inc(&qp->refcnt);\r\nhlist_add_head(&qp->list, &hb->chain);\r\nspin_unlock(&hb->chain_lock);\r\nreturn qp;\r\n}\r\nstatic struct inet_frag_queue *inet_frag_alloc(struct netns_frags *nf,\r\nstruct inet_frags *f,\r\nvoid *arg)\r\n{\r\nstruct inet_frag_queue *q;\r\nif (frag_mem_limit(nf) > nf->high_thresh) {\r\ninet_frag_schedule_worker(f);\r\nreturn NULL;\r\n}\r\nq = kmem_cache_zalloc(f->frags_cachep, GFP_ATOMIC);\r\nif (!q)\r\nreturn NULL;\r\nq->net = nf;\r\nf->constructor(q, arg);\r\nadd_frag_mem_limit(nf, f->qsize);\r\nsetup_timer(&q->timer, f->frag_expire, (unsigned long)q);\r\nspin_lock_init(&q->lock);\r\natomic_set(&q->refcnt, 1);\r\nreturn q;\r\n}\r\nstatic struct inet_frag_queue *inet_frag_create(struct netns_frags *nf,\r\nstruct inet_frags *f,\r\nvoid *arg)\r\n{\r\nstruct inet_frag_queue *q;\r\nq = inet_frag_alloc(nf, f, arg);\r\nif (!q)\r\nreturn NULL;\r\nreturn inet_frag_intern(nf, q, f, arg);\r\n}\r\nstruct inet_frag_queue *inet_frag_find(struct netns_frags *nf,\r\nstruct inet_frags *f, void *key,\r\nunsigned int hash)\r\n{\r\nstruct inet_frag_bucket *hb;\r\nstruct inet_frag_queue *q;\r\nint depth = 0;\r\nif (frag_mem_limit(nf) > nf->low_thresh)\r\ninet_frag_schedule_worker(f);\r\nhash &= (INETFRAGS_HASHSZ - 1);\r\nhb = &f->hash[hash];\r\nspin_lock(&hb->chain_lock);\r\nhlist_for_each_entry(q, &hb->chain, list) {\r\nif (q->net == nf && f->match(q, key)) {\r\natomic_inc(&q->refcnt);\r\nspin_unlock(&hb->chain_lock);\r\nreturn q;\r\n}\r\ndepth++;\r\n}\r\nspin_unlock(&hb->chain_lock);\r\nif (depth <= INETFRAGS_MAXDEPTH)\r\nreturn inet_frag_create(nf, f, key);\r\nif (inet_frag_may_rebuild(f)) {\r\nif (!f->rebuild)\r\nf->rebuild = true;\r\ninet_frag_schedule_worker(f);\r\n}\r\nreturn ERR_PTR(-ENOBUFS);\r\n}\r\nvoid inet_frag_maybe_warn_overflow(struct inet_frag_queue *q,\r\nconst char *prefix)\r\n{\r\nstatic const char msg[] = "inet_frag_find: Fragment hash bucket"\r\n" list length grew over limit " __stringify(INETFRAGS_MAXDEPTH)\r\n". Dropping fragment.\n";\r\nif (PTR_ERR(q) == -ENOBUFS)\r\nnet_dbg_ratelimited("%s%s", prefix, msg);\r\n}
