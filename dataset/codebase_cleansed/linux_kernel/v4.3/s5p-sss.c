static inline struct samsung_aes_variant *find_s5p_sss_version\r\n(struct platform_device *pdev)\r\n{\r\nif (IS_ENABLED(CONFIG_OF) && (pdev->dev.of_node)) {\r\nconst struct of_device_id *match;\r\nmatch = of_match_node(s5p_sss_dt_match,\r\npdev->dev.of_node);\r\nreturn (struct samsung_aes_variant *)match->data;\r\n}\r\nreturn (struct samsung_aes_variant *)\r\nplatform_get_device_id(pdev)->driver_data;\r\n}\r\nstatic void s5p_set_dma_indata(struct s5p_aes_dev *dev, struct scatterlist *sg)\r\n{\r\nSSS_WRITE(dev, FCBRDMAS, sg_dma_address(sg));\r\nSSS_WRITE(dev, FCBRDMAL, sg_dma_len(sg));\r\n}\r\nstatic void s5p_set_dma_outdata(struct s5p_aes_dev *dev, struct scatterlist *sg)\r\n{\r\nSSS_WRITE(dev, FCBTDMAS, sg_dma_address(sg));\r\nSSS_WRITE(dev, FCBTDMAL, sg_dma_len(sg));\r\n}\r\nstatic void s5p_aes_complete(struct s5p_aes_dev *dev, int err)\r\n{\r\ndev->req->base.complete(&dev->req->base, err);\r\ndev->busy = false;\r\n}\r\nstatic void s5p_unset_outdata(struct s5p_aes_dev *dev)\r\n{\r\ndma_unmap_sg(dev->dev, dev->sg_dst, 1, DMA_FROM_DEVICE);\r\n}\r\nstatic void s5p_unset_indata(struct s5p_aes_dev *dev)\r\n{\r\ndma_unmap_sg(dev->dev, dev->sg_src, 1, DMA_TO_DEVICE);\r\n}\r\nstatic int s5p_set_outdata(struct s5p_aes_dev *dev, struct scatterlist *sg)\r\n{\r\nint err;\r\nif (!IS_ALIGNED(sg_dma_len(sg), AES_BLOCK_SIZE)) {\r\nerr = -EINVAL;\r\ngoto exit;\r\n}\r\nif (!sg_dma_len(sg)) {\r\nerr = -EINVAL;\r\ngoto exit;\r\n}\r\nerr = dma_map_sg(dev->dev, sg, 1, DMA_FROM_DEVICE);\r\nif (!err) {\r\nerr = -ENOMEM;\r\ngoto exit;\r\n}\r\ndev->sg_dst = sg;\r\nerr = 0;\r\nexit:\r\nreturn err;\r\n}\r\nstatic int s5p_set_indata(struct s5p_aes_dev *dev, struct scatterlist *sg)\r\n{\r\nint err;\r\nif (!IS_ALIGNED(sg_dma_len(sg), AES_BLOCK_SIZE)) {\r\nerr = -EINVAL;\r\ngoto exit;\r\n}\r\nif (!sg_dma_len(sg)) {\r\nerr = -EINVAL;\r\ngoto exit;\r\n}\r\nerr = dma_map_sg(dev->dev, sg, 1, DMA_TO_DEVICE);\r\nif (!err) {\r\nerr = -ENOMEM;\r\ngoto exit;\r\n}\r\ndev->sg_src = sg;\r\nerr = 0;\r\nexit:\r\nreturn err;\r\n}\r\nstatic void s5p_aes_tx(struct s5p_aes_dev *dev)\r\n{\r\nint err = 0;\r\ns5p_unset_outdata(dev);\r\nif (!sg_is_last(dev->sg_dst)) {\r\nerr = s5p_set_outdata(dev, sg_next(dev->sg_dst));\r\nif (err) {\r\ns5p_aes_complete(dev, err);\r\nreturn;\r\n}\r\ns5p_set_dma_outdata(dev, dev->sg_dst);\r\n} else {\r\ns5p_aes_complete(dev, err);\r\ndev->busy = true;\r\ntasklet_schedule(&dev->tasklet);\r\n}\r\n}\r\nstatic void s5p_aes_rx(struct s5p_aes_dev *dev)\r\n{\r\nint err;\r\ns5p_unset_indata(dev);\r\nif (!sg_is_last(dev->sg_src)) {\r\nerr = s5p_set_indata(dev, sg_next(dev->sg_src));\r\nif (err) {\r\ns5p_aes_complete(dev, err);\r\nreturn;\r\n}\r\ns5p_set_dma_indata(dev, dev->sg_src);\r\n}\r\n}\r\nstatic irqreturn_t s5p_aes_interrupt(int irq, void *dev_id)\r\n{\r\nstruct platform_device *pdev = dev_id;\r\nstruct s5p_aes_dev *dev = platform_get_drvdata(pdev);\r\nuint32_t status;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nif (irq == dev->irq_fc) {\r\nstatus = SSS_READ(dev, FCINTSTAT);\r\nif (status & SSS_FCINTSTAT_BRDMAINT)\r\ns5p_aes_rx(dev);\r\nif (status & SSS_FCINTSTAT_BTDMAINT)\r\ns5p_aes_tx(dev);\r\nSSS_WRITE(dev, FCINTPEND, status);\r\n}\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void s5p_set_aes(struct s5p_aes_dev *dev,\r\nuint8_t *key, uint8_t *iv, unsigned int keylen)\r\n{\r\nvoid __iomem *keystart;\r\nif (iv)\r\nmemcpy(dev->aes_ioaddr + SSS_REG_AES_IV_DATA(0), iv, 0x10);\r\nif (keylen == AES_KEYSIZE_256)\r\nkeystart = dev->aes_ioaddr + SSS_REG_AES_KEY_DATA(0);\r\nelse if (keylen == AES_KEYSIZE_192)\r\nkeystart = dev->aes_ioaddr + SSS_REG_AES_KEY_DATA(2);\r\nelse\r\nkeystart = dev->aes_ioaddr + SSS_REG_AES_KEY_DATA(4);\r\nmemcpy(keystart, key, keylen);\r\n}\r\nstatic void s5p_aes_crypt_start(struct s5p_aes_dev *dev, unsigned long mode)\r\n{\r\nstruct ablkcipher_request *req = dev->req;\r\nuint32_t aes_control;\r\nint err;\r\nunsigned long flags;\r\naes_control = SSS_AES_KEY_CHANGE_MODE;\r\nif (mode & FLAGS_AES_DECRYPT)\r\naes_control |= SSS_AES_MODE_DECRYPT;\r\nif ((mode & FLAGS_AES_MODE_MASK) == FLAGS_AES_CBC)\r\naes_control |= SSS_AES_CHAIN_MODE_CBC;\r\nelse if ((mode & FLAGS_AES_MODE_MASK) == FLAGS_AES_CTR)\r\naes_control |= SSS_AES_CHAIN_MODE_CTR;\r\nif (dev->ctx->keylen == AES_KEYSIZE_192)\r\naes_control |= SSS_AES_KEY_SIZE_192;\r\nelse if (dev->ctx->keylen == AES_KEYSIZE_256)\r\naes_control |= SSS_AES_KEY_SIZE_256;\r\naes_control |= SSS_AES_FIFO_MODE;\r\naes_control |= SSS_AES_BYTESWAP_DI\r\n| SSS_AES_BYTESWAP_DO\r\n| SSS_AES_BYTESWAP_IV\r\n| SSS_AES_BYTESWAP_KEY\r\n| SSS_AES_BYTESWAP_CNT;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nSSS_WRITE(dev, FCINTENCLR,\r\nSSS_FCINTENCLR_BTDMAINTENCLR | SSS_FCINTENCLR_BRDMAINTENCLR);\r\nSSS_WRITE(dev, FCFIFOCTRL, 0x00);\r\nerr = s5p_set_indata(dev, req->src);\r\nif (err)\r\ngoto indata_error;\r\nerr = s5p_set_outdata(dev, req->dst);\r\nif (err)\r\ngoto outdata_error;\r\nSSS_AES_WRITE(dev, AES_CONTROL, aes_control);\r\ns5p_set_aes(dev, dev->ctx->aes_key, req->info, dev->ctx->keylen);\r\ns5p_set_dma_indata(dev, req->src);\r\ns5p_set_dma_outdata(dev, req->dst);\r\nSSS_WRITE(dev, FCINTENSET,\r\nSSS_FCINTENSET_BTDMAINTENSET | SSS_FCINTENSET_BRDMAINTENSET);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nreturn;\r\noutdata_error:\r\ns5p_unset_indata(dev);\r\nindata_error:\r\ns5p_aes_complete(dev, err);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\n}\r\nstatic void s5p_tasklet_cb(unsigned long data)\r\n{\r\nstruct s5p_aes_dev *dev = (struct s5p_aes_dev *)data;\r\nstruct crypto_async_request *async_req, *backlog;\r\nstruct s5p_aes_reqctx *reqctx;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nbacklog = crypto_get_backlog(&dev->queue);\r\nasync_req = crypto_dequeue_request(&dev->queue);\r\nif (!async_req) {\r\ndev->busy = false;\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nreturn;\r\n}\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nif (backlog)\r\nbacklog->complete(backlog, -EINPROGRESS);\r\ndev->req = ablkcipher_request_cast(async_req);\r\ndev->ctx = crypto_tfm_ctx(dev->req->base.tfm);\r\nreqctx = ablkcipher_request_ctx(dev->req);\r\ns5p_aes_crypt_start(dev, reqctx->mode);\r\n}\r\nstatic int s5p_aes_handle_req(struct s5p_aes_dev *dev,\r\nstruct ablkcipher_request *req)\r\n{\r\nunsigned long flags;\r\nint err;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nerr = ablkcipher_enqueue_request(&dev->queue, req);\r\nif (dev->busy) {\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\ngoto exit;\r\n}\r\ndev->busy = true;\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\ntasklet_schedule(&dev->tasklet);\r\nexit:\r\nreturn err;\r\n}\r\nstatic int s5p_aes_crypt(struct ablkcipher_request *req, unsigned long mode)\r\n{\r\nstruct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);\r\nstruct s5p_aes_ctx *ctx = crypto_ablkcipher_ctx(tfm);\r\nstruct s5p_aes_reqctx *reqctx = ablkcipher_request_ctx(req);\r\nstruct s5p_aes_dev *dev = ctx->dev;\r\nif (!IS_ALIGNED(req->nbytes, AES_BLOCK_SIZE)) {\r\npr_err("request size is not exact amount of AES blocks\n");\r\nreturn -EINVAL;\r\n}\r\nreqctx->mode = mode;\r\nreturn s5p_aes_handle_req(dev, req);\r\n}\r\nstatic int s5p_aes_setkey(struct crypto_ablkcipher *cipher,\r\nconst uint8_t *key, unsigned int keylen)\r\n{\r\nstruct crypto_tfm *tfm = crypto_ablkcipher_tfm(cipher);\r\nstruct s5p_aes_ctx *ctx = crypto_tfm_ctx(tfm);\r\nif (keylen != AES_KEYSIZE_128 &&\r\nkeylen != AES_KEYSIZE_192 &&\r\nkeylen != AES_KEYSIZE_256)\r\nreturn -EINVAL;\r\nmemcpy(ctx->aes_key, key, keylen);\r\nctx->keylen = keylen;\r\nreturn 0;\r\n}\r\nstatic int s5p_aes_ecb_encrypt(struct ablkcipher_request *req)\r\n{\r\nreturn s5p_aes_crypt(req, 0);\r\n}\r\nstatic int s5p_aes_ecb_decrypt(struct ablkcipher_request *req)\r\n{\r\nreturn s5p_aes_crypt(req, FLAGS_AES_DECRYPT);\r\n}\r\nstatic int s5p_aes_cbc_encrypt(struct ablkcipher_request *req)\r\n{\r\nreturn s5p_aes_crypt(req, FLAGS_AES_CBC);\r\n}\r\nstatic int s5p_aes_cbc_decrypt(struct ablkcipher_request *req)\r\n{\r\nreturn s5p_aes_crypt(req, FLAGS_AES_DECRYPT | FLAGS_AES_CBC);\r\n}\r\nstatic int s5p_aes_cra_init(struct crypto_tfm *tfm)\r\n{\r\nstruct s5p_aes_ctx *ctx = crypto_tfm_ctx(tfm);\r\nctx->dev = s5p_dev;\r\ntfm->crt_ablkcipher.reqsize = sizeof(struct s5p_aes_reqctx);\r\nreturn 0;\r\n}\r\nstatic int s5p_aes_probe(struct platform_device *pdev)\r\n{\r\nint i, j, err = -ENODEV;\r\nstruct s5p_aes_dev *pdata;\r\nstruct device *dev = &pdev->dev;\r\nstruct resource *res;\r\nstruct samsung_aes_variant *variant;\r\nif (s5p_dev)\r\nreturn -EEXIST;\r\npdata = devm_kzalloc(dev, sizeof(*pdata), GFP_KERNEL);\r\nif (!pdata)\r\nreturn -ENOMEM;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\npdata->ioaddr = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(pdata->ioaddr))\r\nreturn PTR_ERR(pdata->ioaddr);\r\nvariant = find_s5p_sss_version(pdev);\r\npdata->clk = devm_clk_get(dev, "secss");\r\nif (IS_ERR(pdata->clk)) {\r\ndev_err(dev, "failed to find secss clock source\n");\r\nreturn -ENOENT;\r\n}\r\nerr = clk_prepare_enable(pdata->clk);\r\nif (err < 0) {\r\ndev_err(dev, "Enabling SSS clk failed, err %d\n", err);\r\nreturn err;\r\n}\r\nspin_lock_init(&pdata->lock);\r\npdata->aes_ioaddr = pdata->ioaddr + variant->aes_offset;\r\npdata->irq_fc = platform_get_irq(pdev, 0);\r\nif (pdata->irq_fc < 0) {\r\nerr = pdata->irq_fc;\r\ndev_warn(dev, "feed control interrupt is not available.\n");\r\ngoto err_irq;\r\n}\r\nerr = devm_request_irq(dev, pdata->irq_fc, s5p_aes_interrupt,\r\nIRQF_SHARED, pdev->name, pdev);\r\nif (err < 0) {\r\ndev_warn(dev, "feed control interrupt is not available.\n");\r\ngoto err_irq;\r\n}\r\nif (variant->has_hash_irq) {\r\npdata->irq_hash = platform_get_irq(pdev, 1);\r\nif (pdata->irq_hash < 0) {\r\nerr = pdata->irq_hash;\r\ndev_warn(dev, "hash interrupt is not available.\n");\r\ngoto err_irq;\r\n}\r\nerr = devm_request_irq(dev, pdata->irq_hash, s5p_aes_interrupt,\r\nIRQF_SHARED, pdev->name, pdev);\r\nif (err < 0) {\r\ndev_warn(dev, "hash interrupt is not available.\n");\r\ngoto err_irq;\r\n}\r\n}\r\npdata->busy = false;\r\npdata->variant = variant;\r\npdata->dev = dev;\r\nplatform_set_drvdata(pdev, pdata);\r\ns5p_dev = pdata;\r\ntasklet_init(&pdata->tasklet, s5p_tasklet_cb, (unsigned long)pdata);\r\ncrypto_init_queue(&pdata->queue, CRYPTO_QUEUE_LEN);\r\nfor (i = 0; i < ARRAY_SIZE(algs); i++) {\r\nerr = crypto_register_alg(&algs[i]);\r\nif (err)\r\ngoto err_algs;\r\n}\r\npr_info("s5p-sss driver registered\n");\r\nreturn 0;\r\nerr_algs:\r\ndev_err(dev, "can't register '%s': %d\n", algs[i].cra_name, err);\r\nfor (j = 0; j < i; j++)\r\ncrypto_unregister_alg(&algs[j]);\r\ntasklet_kill(&pdata->tasklet);\r\nerr_irq:\r\nclk_disable_unprepare(pdata->clk);\r\ns5p_dev = NULL;\r\nreturn err;\r\n}\r\nstatic int s5p_aes_remove(struct platform_device *pdev)\r\n{\r\nstruct s5p_aes_dev *pdata = platform_get_drvdata(pdev);\r\nint i;\r\nif (!pdata)\r\nreturn -ENODEV;\r\nfor (i = 0; i < ARRAY_SIZE(algs); i++)\r\ncrypto_unregister_alg(&algs[i]);\r\ntasklet_kill(&pdata->tasklet);\r\nclk_disable_unprepare(pdata->clk);\r\ns5p_dev = NULL;\r\nreturn 0;\r\n}
