static int insert_alloc_stat(unsigned long call_site, unsigned long ptr,\r\nint bytes_req, int bytes_alloc, int cpu)\r\n{\r\nstruct rb_node **node = &root_alloc_stat.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct alloc_stat *data = NULL;\r\nwhile (*node) {\r\nparent = *node;\r\ndata = rb_entry(*node, struct alloc_stat, node);\r\nif (ptr > data->ptr)\r\nnode = &(*node)->rb_right;\r\nelse if (ptr < data->ptr)\r\nnode = &(*node)->rb_left;\r\nelse\r\nbreak;\r\n}\r\nif (data && data->ptr == ptr) {\r\ndata->hit++;\r\ndata->bytes_req += bytes_req;\r\ndata->bytes_alloc += bytes_alloc;\r\n} else {\r\ndata = malloc(sizeof(*data));\r\nif (!data) {\r\npr_err("%s: malloc failed\n", __func__);\r\nreturn -1;\r\n}\r\ndata->ptr = ptr;\r\ndata->pingpong = 0;\r\ndata->hit = 1;\r\ndata->bytes_req = bytes_req;\r\ndata->bytes_alloc = bytes_alloc;\r\nrb_link_node(&data->node, parent, node);\r\nrb_insert_color(&data->node, &root_alloc_stat);\r\n}\r\ndata->call_site = call_site;\r\ndata->alloc_cpu = cpu;\r\nreturn 0;\r\n}\r\nstatic int insert_caller_stat(unsigned long call_site,\r\nint bytes_req, int bytes_alloc)\r\n{\r\nstruct rb_node **node = &root_caller_stat.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct alloc_stat *data = NULL;\r\nwhile (*node) {\r\nparent = *node;\r\ndata = rb_entry(*node, struct alloc_stat, node);\r\nif (call_site > data->call_site)\r\nnode = &(*node)->rb_right;\r\nelse if (call_site < data->call_site)\r\nnode = &(*node)->rb_left;\r\nelse\r\nbreak;\r\n}\r\nif (data && data->call_site == call_site) {\r\ndata->hit++;\r\ndata->bytes_req += bytes_req;\r\ndata->bytes_alloc += bytes_alloc;\r\n} else {\r\ndata = malloc(sizeof(*data));\r\nif (!data) {\r\npr_err("%s: malloc failed\n", __func__);\r\nreturn -1;\r\n}\r\ndata->call_site = call_site;\r\ndata->pingpong = 0;\r\ndata->hit = 1;\r\ndata->bytes_req = bytes_req;\r\ndata->bytes_alloc = bytes_alloc;\r\nrb_link_node(&data->node, parent, node);\r\nrb_insert_color(&data->node, &root_caller_stat);\r\n}\r\nreturn 0;\r\n}\r\nstatic int perf_evsel__process_alloc_event(struct perf_evsel *evsel,\r\nstruct perf_sample *sample)\r\n{\r\nunsigned long ptr = perf_evsel__intval(evsel, sample, "ptr"),\r\ncall_site = perf_evsel__intval(evsel, sample, "call_site");\r\nint bytes_req = perf_evsel__intval(evsel, sample, "bytes_req"),\r\nbytes_alloc = perf_evsel__intval(evsel, sample, "bytes_alloc");\r\nif (insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, sample->cpu) ||\r\ninsert_caller_stat(call_site, bytes_req, bytes_alloc))\r\nreturn -1;\r\ntotal_requested += bytes_req;\r\ntotal_allocated += bytes_alloc;\r\nnr_allocs++;\r\nreturn 0;\r\n}\r\nstatic int perf_evsel__process_alloc_node_event(struct perf_evsel *evsel,\r\nstruct perf_sample *sample)\r\n{\r\nint ret = perf_evsel__process_alloc_event(evsel, sample);\r\nif (!ret) {\r\nint node1 = cpu__get_node(sample->cpu),\r\nnode2 = perf_evsel__intval(evsel, sample, "node");\r\nif (node1 != node2)\r\nnr_cross_allocs++;\r\n}\r\nreturn ret;\r\n}\r\nstatic struct alloc_stat *search_alloc_stat(unsigned long ptr,\r\nunsigned long call_site,\r\nstruct rb_root *root,\r\nsort_fn_t sort_fn)\r\n{\r\nstruct rb_node *node = root->rb_node;\r\nstruct alloc_stat key = { .ptr = ptr, .call_site = call_site };\r\nwhile (node) {\r\nstruct alloc_stat *data;\r\nint cmp;\r\ndata = rb_entry(node, struct alloc_stat, node);\r\ncmp = sort_fn(&key, data);\r\nif (cmp < 0)\r\nnode = node->rb_left;\r\nelse if (cmp > 0)\r\nnode = node->rb_right;\r\nelse\r\nreturn data;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int perf_evsel__process_free_event(struct perf_evsel *evsel,\r\nstruct perf_sample *sample)\r\n{\r\nunsigned long ptr = perf_evsel__intval(evsel, sample, "ptr");\r\nstruct alloc_stat *s_alloc, *s_caller;\r\ns_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);\r\nif (!s_alloc)\r\nreturn 0;\r\nif ((short)sample->cpu != s_alloc->alloc_cpu) {\r\ns_alloc->pingpong++;\r\ns_caller = search_alloc_stat(0, s_alloc->call_site,\r\n&root_caller_stat,\r\nslab_callsite_cmp);\r\nif (!s_caller)\r\nreturn -1;\r\ns_caller->pingpong++;\r\n}\r\ns_alloc->alloc_cpu = -1;\r\nreturn 0;\r\n}\r\nstatic int funcmp(const void *a, const void *b)\r\n{\r\nconst struct alloc_func *fa = a;\r\nconst struct alloc_func *fb = b;\r\nif (fa->start > fb->start)\r\nreturn 1;\r\nelse\r\nreturn -1;\r\n}\r\nstatic int callcmp(const void *a, const void *b)\r\n{\r\nconst struct alloc_func *fa = a;\r\nconst struct alloc_func *fb = b;\r\nif (fb->start <= fa->start && fa->end < fb->end)\r\nreturn 0;\r\nif (fa->start > fb->start)\r\nreturn 1;\r\nelse\r\nreturn -1;\r\n}\r\nstatic int build_alloc_func_list(void)\r\n{\r\nint ret;\r\nstruct map *kernel_map;\r\nstruct symbol *sym;\r\nstruct rb_node *node;\r\nstruct alloc_func *func;\r\nstruct machine *machine = &kmem_session->machines.host;\r\nregex_t alloc_func_regex;\r\nconst char pattern[] = "^_?_?(alloc|get_free|get_zeroed)_pages?";\r\nret = regcomp(&alloc_func_regex, pattern, REG_EXTENDED);\r\nif (ret) {\r\nchar err[BUFSIZ];\r\nregerror(ret, &alloc_func_regex, err, sizeof(err));\r\npr_err("Invalid regex: %s\n%s", pattern, err);\r\nreturn -EINVAL;\r\n}\r\nkernel_map = machine->vmlinux_maps[MAP__FUNCTION];\r\nif (map__load(kernel_map, NULL) < 0) {\r\npr_err("cannot load kernel map\n");\r\nreturn -ENOENT;\r\n}\r\nmap__for_each_symbol(kernel_map, sym, node) {\r\nif (regexec(&alloc_func_regex, sym->name, 0, NULL, 0))\r\ncontinue;\r\nfunc = realloc(alloc_func_list,\r\n(nr_alloc_funcs + 1) * sizeof(*func));\r\nif (func == NULL)\r\nreturn -ENOMEM;\r\npr_debug("alloc func: %s\n", sym->name);\r\nfunc[nr_alloc_funcs].start = sym->start;\r\nfunc[nr_alloc_funcs].end = sym->end;\r\nfunc[nr_alloc_funcs].name = sym->name;\r\nalloc_func_list = func;\r\nnr_alloc_funcs++;\r\n}\r\nqsort(alloc_func_list, nr_alloc_funcs, sizeof(*func), funcmp);\r\nregfree(&alloc_func_regex);\r\nreturn 0;\r\n}\r\nstatic u64 find_callsite(struct perf_evsel *evsel, struct perf_sample *sample)\r\n{\r\nstruct addr_location al;\r\nstruct machine *machine = &kmem_session->machines.host;\r\nstruct callchain_cursor_node *node;\r\nif (alloc_func_list == NULL) {\r\nif (build_alloc_func_list() < 0)\r\ngoto out;\r\n}\r\nal.thread = machine__findnew_thread(machine, sample->pid, sample->tid);\r\nsample__resolve_callchain(sample, NULL, evsel, &al, 16);\r\ncallchain_cursor_commit(&callchain_cursor);\r\nwhile (true) {\r\nstruct alloc_func key, *caller;\r\nu64 addr;\r\nnode = callchain_cursor_current(&callchain_cursor);\r\nif (node == NULL)\r\nbreak;\r\nkey.start = key.end = node->ip;\r\ncaller = bsearch(&key, alloc_func_list, nr_alloc_funcs,\r\nsizeof(key), callcmp);\r\nif (!caller) {\r\nif (node->map)\r\naddr = map__unmap_ip(node->map, node->ip);\r\nelse\r\naddr = node->ip;\r\nreturn addr;\r\n} else\r\npr_debug3("skipping alloc function: %s\n", caller->name);\r\ncallchain_cursor_advance(&callchain_cursor);\r\n}\r\nout:\r\npr_debug2("unknown callsite: %"PRIx64 "\n", sample->ip);\r\nreturn sample->ip;\r\n}\r\nstatic struct page_stat *\r\n__page_stat__findnew_page(struct page_stat *pstat, bool create)\r\n{\r\nstruct rb_node **node = &page_live_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct page_stat *data;\r\nwhile (*node) {\r\ns64 cmp;\r\nparent = *node;\r\ndata = rb_entry(*node, struct page_stat, node);\r\ncmp = data->page - pstat->page;\r\nif (cmp < 0)\r\nnode = &parent->rb_left;\r\nelse if (cmp > 0)\r\nnode = &parent->rb_right;\r\nelse\r\nreturn data;\r\n}\r\nif (!create)\r\nreturn NULL;\r\ndata = zalloc(sizeof(*data));\r\nif (data != NULL) {\r\ndata->page = pstat->page;\r\ndata->order = pstat->order;\r\ndata->gfp_flags = pstat->gfp_flags;\r\ndata->migrate_type = pstat->migrate_type;\r\nrb_link_node(&data->node, parent, node);\r\nrb_insert_color(&data->node, &page_live_tree);\r\n}\r\nreturn data;\r\n}\r\nstatic struct page_stat *page_stat__find_page(struct page_stat *pstat)\r\n{\r\nreturn __page_stat__findnew_page(pstat, false);\r\n}\r\nstatic struct page_stat *page_stat__findnew_page(struct page_stat *pstat)\r\n{\r\nreturn __page_stat__findnew_page(pstat, true);\r\n}\r\nstatic struct page_stat *\r\n__page_stat__findnew_alloc(struct page_stat *pstat, bool create)\r\n{\r\nstruct rb_node **node = &page_alloc_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct page_stat *data;\r\nstruct sort_dimension *sort;\r\nwhile (*node) {\r\nint cmp = 0;\r\nparent = *node;\r\ndata = rb_entry(*node, struct page_stat, node);\r\nlist_for_each_entry(sort, &page_alloc_sort_input, list) {\r\ncmp = sort->cmp(pstat, data);\r\nif (cmp)\r\nbreak;\r\n}\r\nif (cmp < 0)\r\nnode = &parent->rb_left;\r\nelse if (cmp > 0)\r\nnode = &parent->rb_right;\r\nelse\r\nreturn data;\r\n}\r\nif (!create)\r\nreturn NULL;\r\ndata = zalloc(sizeof(*data));\r\nif (data != NULL) {\r\ndata->page = pstat->page;\r\ndata->order = pstat->order;\r\ndata->gfp_flags = pstat->gfp_flags;\r\ndata->migrate_type = pstat->migrate_type;\r\nrb_link_node(&data->node, parent, node);\r\nrb_insert_color(&data->node, &page_alloc_tree);\r\n}\r\nreturn data;\r\n}\r\nstatic struct page_stat *page_stat__find_alloc(struct page_stat *pstat)\r\n{\r\nreturn __page_stat__findnew_alloc(pstat, false);\r\n}\r\nstatic struct page_stat *page_stat__findnew_alloc(struct page_stat *pstat)\r\n{\r\nreturn __page_stat__findnew_alloc(pstat, true);\r\n}\r\nstatic struct page_stat *\r\n__page_stat__findnew_caller(struct page_stat *pstat, bool create)\r\n{\r\nstruct rb_node **node = &page_caller_tree.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct page_stat *data;\r\nstruct sort_dimension *sort;\r\nwhile (*node) {\r\nint cmp = 0;\r\nparent = *node;\r\ndata = rb_entry(*node, struct page_stat, node);\r\nlist_for_each_entry(sort, &page_caller_sort_input, list) {\r\ncmp = sort->cmp(pstat, data);\r\nif (cmp)\r\nbreak;\r\n}\r\nif (cmp < 0)\r\nnode = &parent->rb_left;\r\nelse if (cmp > 0)\r\nnode = &parent->rb_right;\r\nelse\r\nreturn data;\r\n}\r\nif (!create)\r\nreturn NULL;\r\ndata = zalloc(sizeof(*data));\r\nif (data != NULL) {\r\ndata->callsite = pstat->callsite;\r\ndata->order = pstat->order;\r\ndata->gfp_flags = pstat->gfp_flags;\r\ndata->migrate_type = pstat->migrate_type;\r\nrb_link_node(&data->node, parent, node);\r\nrb_insert_color(&data->node, &page_caller_tree);\r\n}\r\nreturn data;\r\n}\r\nstatic struct page_stat *page_stat__find_caller(struct page_stat *pstat)\r\n{\r\nreturn __page_stat__findnew_caller(pstat, false);\r\n}\r\nstatic struct page_stat *page_stat__findnew_caller(struct page_stat *pstat)\r\n{\r\nreturn __page_stat__findnew_caller(pstat, true);\r\n}\r\nstatic bool valid_page(u64 pfn_or_page)\r\n{\r\nif (use_pfn && pfn_or_page == -1UL)\r\nreturn false;\r\nif (!use_pfn && pfn_or_page == 0)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int gfpcmp(const void *a, const void *b)\r\n{\r\nconst struct gfp_flag *fa = a;\r\nconst struct gfp_flag *fb = b;\r\nreturn fa->flags - fb->flags;\r\n}\r\nstatic char *compact_gfp_flags(char *gfp_flags)\r\n{\r\nchar *orig_flags = strdup(gfp_flags);\r\nchar *new_flags = NULL;\r\nchar *str, *pos = NULL;\r\nsize_t len = 0;\r\nif (orig_flags == NULL)\r\nreturn NULL;\r\nstr = strtok_r(orig_flags, "|", &pos);\r\nwhile (str) {\r\nsize_t i;\r\nchar *new;\r\nconst char *cpt;\r\nfor (i = 0; i < ARRAY_SIZE(gfp_compact_table); i++) {\r\nif (strcmp(gfp_compact_table[i].original, str))\r\ncontinue;\r\ncpt = gfp_compact_table[i].compact;\r\nnew = realloc(new_flags, len + strlen(cpt) + 2);\r\nif (new == NULL) {\r\nfree(new_flags);\r\nreturn NULL;\r\n}\r\nnew_flags = new;\r\nif (!len) {\r\nstrcpy(new_flags, cpt);\r\n} else {\r\nstrcat(new_flags, "|");\r\nstrcat(new_flags, cpt);\r\nlen++;\r\n}\r\nlen += strlen(cpt);\r\n}\r\nstr = strtok_r(NULL, "|", &pos);\r\n}\r\nif (max_gfp_len < len)\r\nmax_gfp_len = len;\r\nfree(orig_flags);\r\nreturn new_flags;\r\n}\r\nstatic char *compact_gfp_string(unsigned long gfp_flags)\r\n{\r\nstruct gfp_flag key = {\r\n.flags = gfp_flags,\r\n};\r\nstruct gfp_flag *gfp;\r\ngfp = bsearch(&key, gfps, nr_gfps, sizeof(*gfps), gfpcmp);\r\nif (gfp)\r\nreturn gfp->compact_str;\r\nreturn NULL;\r\n}\r\nstatic int parse_gfp_flags(struct perf_evsel *evsel, struct perf_sample *sample,\r\nunsigned int gfp_flags)\r\n{\r\nstruct pevent_record record = {\r\n.cpu = sample->cpu,\r\n.data = sample->raw_data,\r\n.size = sample->raw_size,\r\n};\r\nstruct trace_seq seq;\r\nchar *str, *pos = NULL;\r\nif (nr_gfps) {\r\nstruct gfp_flag key = {\r\n.flags = gfp_flags,\r\n};\r\nif (bsearch(&key, gfps, nr_gfps, sizeof(*gfps), gfpcmp))\r\nreturn 0;\r\n}\r\ntrace_seq_init(&seq);\r\npevent_event_info(&seq, evsel->tp_format, &record);\r\nstr = strtok_r(seq.buffer, " ", &pos);\r\nwhile (str) {\r\nif (!strncmp(str, "gfp_flags=", 10)) {\r\nstruct gfp_flag *new;\r\nnew = realloc(gfps, (nr_gfps + 1) * sizeof(*gfps));\r\nif (new == NULL)\r\nreturn -ENOMEM;\r\ngfps = new;\r\nnew += nr_gfps++;\r\nnew->flags = gfp_flags;\r\nnew->human_readable = strdup(str + 10);\r\nnew->compact_str = compact_gfp_flags(str + 10);\r\nif (!new->human_readable || !new->compact_str)\r\nreturn -ENOMEM;\r\nqsort(gfps, nr_gfps, sizeof(*gfps), gfpcmp);\r\n}\r\nstr = strtok_r(NULL, " ", &pos);\r\n}\r\ntrace_seq_destroy(&seq);\r\nreturn 0;\r\n}\r\nstatic int perf_evsel__process_page_alloc_event(struct perf_evsel *evsel,\r\nstruct perf_sample *sample)\r\n{\r\nu64 page;\r\nunsigned int order = perf_evsel__intval(evsel, sample, "order");\r\nunsigned int gfp_flags = perf_evsel__intval(evsel, sample, "gfp_flags");\r\nunsigned int migrate_type = perf_evsel__intval(evsel, sample,\r\n"migratetype");\r\nu64 bytes = kmem_page_size << order;\r\nu64 callsite;\r\nstruct page_stat *pstat;\r\nstruct page_stat this = {\r\n.order = order,\r\n.gfp_flags = gfp_flags,\r\n.migrate_type = migrate_type,\r\n};\r\nif (use_pfn)\r\npage = perf_evsel__intval(evsel, sample, "pfn");\r\nelse\r\npage = perf_evsel__intval(evsel, sample, "page");\r\nnr_page_allocs++;\r\ntotal_page_alloc_bytes += bytes;\r\nif (!valid_page(page)) {\r\nnr_page_fails++;\r\ntotal_page_fail_bytes += bytes;\r\nreturn 0;\r\n}\r\nif (parse_gfp_flags(evsel, sample, gfp_flags) < 0)\r\nreturn -1;\r\ncallsite = find_callsite(evsel, sample);\r\nthis.page = page;\r\npstat = page_stat__findnew_page(&this);\r\nif (pstat == NULL)\r\nreturn -ENOMEM;\r\npstat->nr_alloc++;\r\npstat->alloc_bytes += bytes;\r\npstat->callsite = callsite;\r\nif (!live_page) {\r\npstat = page_stat__findnew_alloc(&this);\r\nif (pstat == NULL)\r\nreturn -ENOMEM;\r\npstat->nr_alloc++;\r\npstat->alloc_bytes += bytes;\r\npstat->callsite = callsite;\r\n}\r\nthis.callsite = callsite;\r\npstat = page_stat__findnew_caller(&this);\r\nif (pstat == NULL)\r\nreturn -ENOMEM;\r\npstat->nr_alloc++;\r\npstat->alloc_bytes += bytes;\r\norder_stats[order][migrate_type]++;\r\nreturn 0;\r\n}\r\nstatic int perf_evsel__process_page_free_event(struct perf_evsel *evsel,\r\nstruct perf_sample *sample)\r\n{\r\nu64 page;\r\nunsigned int order = perf_evsel__intval(evsel, sample, "order");\r\nu64 bytes = kmem_page_size << order;\r\nstruct page_stat *pstat;\r\nstruct page_stat this = {\r\n.order = order,\r\n};\r\nif (use_pfn)\r\npage = perf_evsel__intval(evsel, sample, "pfn");\r\nelse\r\npage = perf_evsel__intval(evsel, sample, "page");\r\nnr_page_frees++;\r\ntotal_page_free_bytes += bytes;\r\nthis.page = page;\r\npstat = page_stat__find_page(&this);\r\nif (pstat == NULL) {\r\npr_debug2("missing free at page %"PRIx64" (order: %d)\n",\r\npage, order);\r\nnr_page_nomatch++;\r\ntotal_page_nomatch_bytes += bytes;\r\nreturn 0;\r\n}\r\nthis.gfp_flags = pstat->gfp_flags;\r\nthis.migrate_type = pstat->migrate_type;\r\nthis.callsite = pstat->callsite;\r\nrb_erase(&pstat->node, &page_live_tree);\r\nfree(pstat);\r\nif (live_page) {\r\norder_stats[this.order][this.migrate_type]--;\r\n} else {\r\npstat = page_stat__find_alloc(&this);\r\nif (pstat == NULL)\r\nreturn -ENOMEM;\r\npstat->nr_free++;\r\npstat->free_bytes += bytes;\r\n}\r\npstat = page_stat__find_caller(&this);\r\nif (pstat == NULL)\r\nreturn -ENOENT;\r\npstat->nr_free++;\r\npstat->free_bytes += bytes;\r\nif (live_page) {\r\npstat->nr_alloc--;\r\npstat->alloc_bytes -= bytes;\r\nif (pstat->nr_alloc == 0) {\r\nrb_erase(&pstat->node, &page_caller_tree);\r\nfree(pstat);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int process_sample_event(struct perf_tool *tool __maybe_unused,\r\nunion perf_event *event,\r\nstruct perf_sample *sample,\r\nstruct perf_evsel *evsel,\r\nstruct machine *machine)\r\n{\r\nint err = 0;\r\nstruct thread *thread = machine__findnew_thread(machine, sample->pid,\r\nsample->tid);\r\nif (thread == NULL) {\r\npr_debug("problem processing %d event, skipping it.\n",\r\nevent->header.type);\r\nreturn -1;\r\n}\r\ndump_printf(" ... thread: %s:%d\n", thread__comm_str(thread), thread->tid);\r\nif (evsel->handler != NULL) {\r\ntracepoint_handler f = evsel->handler;\r\nerr = f(evsel, sample);\r\n}\r\nthread__put(thread);\r\nreturn err;\r\n}\r\nstatic double fragmentation(unsigned long n_req, unsigned long n_alloc)\r\n{\r\nif (n_alloc == 0)\r\nreturn 0.0;\r\nelse\r\nreturn 100.0 - (100.0 * n_req / n_alloc);\r\n}\r\nstatic void __print_slab_result(struct rb_root *root,\r\nstruct perf_session *session,\r\nint n_lines, int is_caller)\r\n{\r\nstruct rb_node *next;\r\nstruct machine *machine = &session->machines.host;\r\nprintf("%.105s\n", graph_dotted_line);\r\nprintf(" %-34s |", is_caller ? "Callsite": "Alloc Ptr");\r\nprintf(" Total_alloc/Per | Total_req/Per | Hit | Ping-pong | Frag\n");\r\nprintf("%.105s\n", graph_dotted_line);\r\nnext = rb_first(root);\r\nwhile (next && n_lines--) {\r\nstruct alloc_stat *data = rb_entry(next, struct alloc_stat,\r\nnode);\r\nstruct symbol *sym = NULL;\r\nstruct map *map;\r\nchar buf[BUFSIZ];\r\nu64 addr;\r\nif (is_caller) {\r\naddr = data->call_site;\r\nif (!raw_ip)\r\nsym = machine__find_kernel_function(machine, addr, &map, NULL);\r\n} else\r\naddr = data->ptr;\r\nif (sym != NULL)\r\nsnprintf(buf, sizeof(buf), "%s+%" PRIx64 "", sym->name,\r\naddr - map->unmap_ip(map, sym->start));\r\nelse\r\nsnprintf(buf, sizeof(buf), "%#" PRIx64 "", addr);\r\nprintf(" %-34s |", buf);\r\nprintf(" %9llu/%-5lu | %9llu/%-5lu | %8lu | %9lu | %6.3f%%\n",\r\n(unsigned long long)data->bytes_alloc,\r\n(unsigned long)data->bytes_alloc / data->hit,\r\n(unsigned long long)data->bytes_req,\r\n(unsigned long)data->bytes_req / data->hit,\r\n(unsigned long)data->hit,\r\n(unsigned long)data->pingpong,\r\nfragmentation(data->bytes_req, data->bytes_alloc));\r\nnext = rb_next(next);\r\n}\r\nif (n_lines == -1)\r\nprintf(" ... | ... | ... | ... | ... | ... \n");\r\nprintf("%.105s\n", graph_dotted_line);\r\n}\r\nstatic void __print_page_alloc_result(struct perf_session *session, int n_lines)\r\n{\r\nstruct rb_node *next = rb_first(&page_alloc_sorted);\r\nstruct machine *machine = &session->machines.host;\r\nconst char *format;\r\nint gfp_len = max(strlen("GFP flags"), max_gfp_len);\r\nprintf("\n%.105s\n", graph_dotted_line);\r\nprintf(" %-16s | %5s alloc (KB) | Hits | Order | Mig.type | %-*s | Callsite\n",\r\nuse_pfn ? "PFN" : "Page", live_page ? "Live" : "Total",\r\ngfp_len, "GFP flags");\r\nprintf("%.105s\n", graph_dotted_line);\r\nif (use_pfn)\r\nformat = " %16llu | %'16llu | %'9d | %5d | %8s | %-*s | %s\n";\r\nelse\r\nformat = " %016llx | %'16llu | %'9d | %5d | %8s | %-*s | %s\n";\r\nwhile (next && n_lines--) {\r\nstruct page_stat *data;\r\nstruct symbol *sym;\r\nstruct map *map;\r\nchar buf[32];\r\nchar *caller = buf;\r\ndata = rb_entry(next, struct page_stat, node);\r\nsym = machine__find_kernel_function(machine, data->callsite,\r\n&map, NULL);\r\nif (sym && sym->name)\r\ncaller = sym->name;\r\nelse\r\nscnprintf(buf, sizeof(buf), "%"PRIx64, data->callsite);\r\nprintf(format, (unsigned long long)data->page,\r\n(unsigned long long)data->alloc_bytes / 1024,\r\ndata->nr_alloc, data->order,\r\nmigrate_type_str[data->migrate_type],\r\ngfp_len, compact_gfp_string(data->gfp_flags), caller);\r\nnext = rb_next(next);\r\n}\r\nif (n_lines == -1) {\r\nprintf(" ... | ... | ... | ... | ... | %-*s | ...\n",\r\ngfp_len, "...");\r\n}\r\nprintf("%.105s\n", graph_dotted_line);\r\n}\r\nstatic void __print_page_caller_result(struct perf_session *session, int n_lines)\r\n{\r\nstruct rb_node *next = rb_first(&page_caller_sorted);\r\nstruct machine *machine = &session->machines.host;\r\nint gfp_len = max(strlen("GFP flags"), max_gfp_len);\r\nprintf("\n%.105s\n", graph_dotted_line);\r\nprintf(" %5s alloc (KB) | Hits | Order | Mig.type | %-*s | Callsite\n",\r\nlive_page ? "Live" : "Total", gfp_len, "GFP flags");\r\nprintf("%.105s\n", graph_dotted_line);\r\nwhile (next && n_lines--) {\r\nstruct page_stat *data;\r\nstruct symbol *sym;\r\nstruct map *map;\r\nchar buf[32];\r\nchar *caller = buf;\r\ndata = rb_entry(next, struct page_stat, node);\r\nsym = machine__find_kernel_function(machine, data->callsite,\r\n&map, NULL);\r\nif (sym && sym->name)\r\ncaller = sym->name;\r\nelse\r\nscnprintf(buf, sizeof(buf), "%"PRIx64, data->callsite);\r\nprintf(" %'16llu | %'9d | %5d | %8s | %-*s | %s\n",\r\n(unsigned long long)data->alloc_bytes / 1024,\r\ndata->nr_alloc, data->order,\r\nmigrate_type_str[data->migrate_type],\r\ngfp_len, compact_gfp_string(data->gfp_flags), caller);\r\nnext = rb_next(next);\r\n}\r\nif (n_lines == -1) {\r\nprintf(" ... | ... | ... | ... | %-*s | ...\n",\r\ngfp_len, "...");\r\n}\r\nprintf("%.105s\n", graph_dotted_line);\r\n}\r\nstatic void print_gfp_flags(void)\r\n{\r\nint i;\r\nprintf("#\n");\r\nprintf("# GFP flags\n");\r\nprintf("# ---------\n");\r\nfor (i = 0; i < nr_gfps; i++) {\r\nprintf("# %08x: %*s: %s\n", gfps[i].flags,\r\n(int) max_gfp_len, gfps[i].compact_str,\r\ngfps[i].human_readable);\r\n}\r\n}\r\nstatic void print_slab_summary(void)\r\n{\r\nprintf("\nSUMMARY (SLAB allocator)");\r\nprintf("\n========================\n");\r\nprintf("Total bytes requested: %'lu\n", total_requested);\r\nprintf("Total bytes allocated: %'lu\n", total_allocated);\r\nprintf("Total bytes wasted on internal fragmentation: %'lu\n",\r\ntotal_allocated - total_requested);\r\nprintf("Internal fragmentation: %f%%\n",\r\nfragmentation(total_requested, total_allocated));\r\nprintf("Cross CPU allocations: %'lu/%'lu\n", nr_cross_allocs, nr_allocs);\r\n}\r\nstatic void print_page_summary(void)\r\n{\r\nint o, m;\r\nu64 nr_alloc_freed = nr_page_frees - nr_page_nomatch;\r\nu64 total_alloc_freed_bytes = total_page_free_bytes - total_page_nomatch_bytes;\r\nprintf("\nSUMMARY (page allocator)");\r\nprintf("\n========================\n");\r\nprintf("%-30s: %'16lu [ %'16"PRIu64" KB ]\n", "Total allocation requests",\r\nnr_page_allocs, total_page_alloc_bytes / 1024);\r\nprintf("%-30s: %'16lu [ %'16"PRIu64" KB ]\n", "Total free requests",\r\nnr_page_frees, total_page_free_bytes / 1024);\r\nprintf("\n");\r\nprintf("%-30s: %'16"PRIu64" [ %'16"PRIu64" KB ]\n", "Total alloc+freed requests",\r\nnr_alloc_freed, (total_alloc_freed_bytes) / 1024);\r\nprintf("%-30s: %'16"PRIu64" [ %'16"PRIu64" KB ]\n", "Total alloc-only requests",\r\nnr_page_allocs - nr_alloc_freed,\r\n(total_page_alloc_bytes - total_alloc_freed_bytes) / 1024);\r\nprintf("%-30s: %'16lu [ %'16"PRIu64" KB ]\n", "Total free-only requests",\r\nnr_page_nomatch, total_page_nomatch_bytes / 1024);\r\nprintf("\n");\r\nprintf("%-30s: %'16lu [ %'16"PRIu64" KB ]\n", "Total allocation failures",\r\nnr_page_fails, total_page_fail_bytes / 1024);\r\nprintf("\n");\r\nprintf("%5s %12s %12s %12s %12s %12s\n", "Order", "Unmovable",\r\n"Reclaimable", "Movable", "Reserved", "CMA/Isolated");\r\nprintf("%.5s %.12s %.12s %.12s %.12s %.12s\n", graph_dotted_line,\r\ngraph_dotted_line, graph_dotted_line, graph_dotted_line,\r\ngraph_dotted_line, graph_dotted_line);\r\nfor (o = 0; o < MAX_PAGE_ORDER; o++) {\r\nprintf("%5d", o);\r\nfor (m = 0; m < MAX_MIGRATE_TYPES - 1; m++) {\r\nif (order_stats[o][m])\r\nprintf(" %'12d", order_stats[o][m]);\r\nelse\r\nprintf(" %12c", '.');\r\n}\r\nprintf("\n");\r\n}\r\n}\r\nstatic void print_slab_result(struct perf_session *session)\r\n{\r\nif (caller_flag)\r\n__print_slab_result(&root_caller_sorted, session, caller_lines, 1);\r\nif (alloc_flag)\r\n__print_slab_result(&root_alloc_sorted, session, alloc_lines, 0);\r\nprint_slab_summary();\r\n}\r\nstatic void print_page_result(struct perf_session *session)\r\n{\r\nif (caller_flag || alloc_flag)\r\nprint_gfp_flags();\r\nif (caller_flag)\r\n__print_page_caller_result(session, caller_lines);\r\nif (alloc_flag)\r\n__print_page_alloc_result(session, alloc_lines);\r\nprint_page_summary();\r\n}\r\nstatic void print_result(struct perf_session *session)\r\n{\r\nif (kmem_slab)\r\nprint_slab_result(session);\r\nif (kmem_page)\r\nprint_page_result(session);\r\n}\r\nstatic void sort_slab_insert(struct rb_root *root, struct alloc_stat *data,\r\nstruct list_head *sort_list)\r\n{\r\nstruct rb_node **new = &(root->rb_node);\r\nstruct rb_node *parent = NULL;\r\nstruct sort_dimension *sort;\r\nwhile (*new) {\r\nstruct alloc_stat *this;\r\nint cmp = 0;\r\nthis = rb_entry(*new, struct alloc_stat, node);\r\nparent = *new;\r\nlist_for_each_entry(sort, sort_list, list) {\r\ncmp = sort->cmp(data, this);\r\nif (cmp)\r\nbreak;\r\n}\r\nif (cmp > 0)\r\nnew = &((*new)->rb_left);\r\nelse\r\nnew = &((*new)->rb_right);\r\n}\r\nrb_link_node(&data->node, parent, new);\r\nrb_insert_color(&data->node, root);\r\n}\r\nstatic void __sort_slab_result(struct rb_root *root, struct rb_root *root_sorted,\r\nstruct list_head *sort_list)\r\n{\r\nstruct rb_node *node;\r\nstruct alloc_stat *data;\r\nfor (;;) {\r\nnode = rb_first(root);\r\nif (!node)\r\nbreak;\r\nrb_erase(node, root);\r\ndata = rb_entry(node, struct alloc_stat, node);\r\nsort_slab_insert(root_sorted, data, sort_list);\r\n}\r\n}\r\nstatic void sort_page_insert(struct rb_root *root, struct page_stat *data,\r\nstruct list_head *sort_list)\r\n{\r\nstruct rb_node **new = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct sort_dimension *sort;\r\nwhile (*new) {\r\nstruct page_stat *this;\r\nint cmp = 0;\r\nthis = rb_entry(*new, struct page_stat, node);\r\nparent = *new;\r\nlist_for_each_entry(sort, sort_list, list) {\r\ncmp = sort->cmp(data, this);\r\nif (cmp)\r\nbreak;\r\n}\r\nif (cmp > 0)\r\nnew = &parent->rb_left;\r\nelse\r\nnew = &parent->rb_right;\r\n}\r\nrb_link_node(&data->node, parent, new);\r\nrb_insert_color(&data->node, root);\r\n}\r\nstatic void __sort_page_result(struct rb_root *root, struct rb_root *root_sorted,\r\nstruct list_head *sort_list)\r\n{\r\nstruct rb_node *node;\r\nstruct page_stat *data;\r\nfor (;;) {\r\nnode = rb_first(root);\r\nif (!node)\r\nbreak;\r\nrb_erase(node, root);\r\ndata = rb_entry(node, struct page_stat, node);\r\nsort_page_insert(root_sorted, data, sort_list);\r\n}\r\n}\r\nstatic void sort_result(void)\r\n{\r\nif (kmem_slab) {\r\n__sort_slab_result(&root_alloc_stat, &root_alloc_sorted,\r\n&slab_alloc_sort);\r\n__sort_slab_result(&root_caller_stat, &root_caller_sorted,\r\n&slab_caller_sort);\r\n}\r\nif (kmem_page) {\r\nif (live_page)\r\n__sort_page_result(&page_live_tree, &page_alloc_sorted,\r\n&page_alloc_sort);\r\nelse\r\n__sort_page_result(&page_alloc_tree, &page_alloc_sorted,\r\n&page_alloc_sort);\r\n__sort_page_result(&page_caller_tree, &page_caller_sorted,\r\n&page_caller_sort);\r\n}\r\n}\r\nstatic int __cmd_kmem(struct perf_session *session)\r\n{\r\nint err = -EINVAL;\r\nstruct perf_evsel *evsel;\r\nconst struct perf_evsel_str_handler kmem_tracepoints[] = {\r\n{ "kmem:kmalloc", perf_evsel__process_alloc_event, },\r\n{ "kmem:kmem_cache_alloc", perf_evsel__process_alloc_event, },\r\n{ "kmem:kmalloc_node", perf_evsel__process_alloc_node_event, },\r\n{ "kmem:kmem_cache_alloc_node", perf_evsel__process_alloc_node_event, },\r\n{ "kmem:kfree", perf_evsel__process_free_event, },\r\n{ "kmem:kmem_cache_free", perf_evsel__process_free_event, },\r\n{ "kmem:mm_page_alloc", perf_evsel__process_page_alloc_event, },\r\n{ "kmem:mm_page_free", perf_evsel__process_page_free_event, },\r\n};\r\nif (!perf_session__has_traces(session, "kmem record"))\r\ngoto out;\r\nif (perf_session__set_tracepoints_handlers(session, kmem_tracepoints)) {\r\npr_err("Initializing perf session tracepoint handlers failed\n");\r\ngoto out;\r\n}\r\nevlist__for_each(session->evlist, evsel) {\r\nif (!strcmp(perf_evsel__name(evsel), "kmem:mm_page_alloc") &&\r\nperf_evsel__field(evsel, "pfn")) {\r\nuse_pfn = true;\r\nbreak;\r\n}\r\n}\r\nsetup_pager();\r\nerr = perf_session__process_events(session);\r\nif (err != 0) {\r\npr_err("error during process events: %d\n", err);\r\ngoto out;\r\n}\r\nsort_result();\r\nprint_result(session);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ptr_cmp(void *a, void *b)\r\n{\r\nstruct alloc_stat *l = a;\r\nstruct alloc_stat *r = b;\r\nif (l->ptr < r->ptr)\r\nreturn -1;\r\nelse if (l->ptr > r->ptr)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int slab_callsite_cmp(void *a, void *b)\r\n{\r\nstruct alloc_stat *l = a;\r\nstruct alloc_stat *r = b;\r\nif (l->call_site < r->call_site)\r\nreturn -1;\r\nelse if (l->call_site > r->call_site)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int hit_cmp(void *a, void *b)\r\n{\r\nstruct alloc_stat *l = a;\r\nstruct alloc_stat *r = b;\r\nif (l->hit < r->hit)\r\nreturn -1;\r\nelse if (l->hit > r->hit)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int bytes_cmp(void *a, void *b)\r\n{\r\nstruct alloc_stat *l = a;\r\nstruct alloc_stat *r = b;\r\nif (l->bytes_alloc < r->bytes_alloc)\r\nreturn -1;\r\nelse if (l->bytes_alloc > r->bytes_alloc)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int frag_cmp(void *a, void *b)\r\n{\r\ndouble x, y;\r\nstruct alloc_stat *l = a;\r\nstruct alloc_stat *r = b;\r\nx = fragmentation(l->bytes_req, l->bytes_alloc);\r\ny = fragmentation(r->bytes_req, r->bytes_alloc);\r\nif (x < y)\r\nreturn -1;\r\nelse if (x > y)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int pingpong_cmp(void *a, void *b)\r\n{\r\nstruct alloc_stat *l = a;\r\nstruct alloc_stat *r = b;\r\nif (l->pingpong < r->pingpong)\r\nreturn -1;\r\nelse if (l->pingpong > r->pingpong)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int page_cmp(void *a, void *b)\r\n{\r\nstruct page_stat *l = a;\r\nstruct page_stat *r = b;\r\nif (l->page < r->page)\r\nreturn -1;\r\nelse if (l->page > r->page)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int page_callsite_cmp(void *a, void *b)\r\n{\r\nstruct page_stat *l = a;\r\nstruct page_stat *r = b;\r\nif (l->callsite < r->callsite)\r\nreturn -1;\r\nelse if (l->callsite > r->callsite)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int page_hit_cmp(void *a, void *b)\r\n{\r\nstruct page_stat *l = a;\r\nstruct page_stat *r = b;\r\nif (l->nr_alloc < r->nr_alloc)\r\nreturn -1;\r\nelse if (l->nr_alloc > r->nr_alloc)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int page_bytes_cmp(void *a, void *b)\r\n{\r\nstruct page_stat *l = a;\r\nstruct page_stat *r = b;\r\nif (l->alloc_bytes < r->alloc_bytes)\r\nreturn -1;\r\nelse if (l->alloc_bytes > r->alloc_bytes)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int page_order_cmp(void *a, void *b)\r\n{\r\nstruct page_stat *l = a;\r\nstruct page_stat *r = b;\r\nif (l->order < r->order)\r\nreturn -1;\r\nelse if (l->order > r->order)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int migrate_type_cmp(void *a, void *b)\r\n{\r\nstruct page_stat *l = a;\r\nstruct page_stat *r = b;\r\nif (l->migrate_type == -1U)\r\nreturn 0;\r\nif (l->migrate_type < r->migrate_type)\r\nreturn -1;\r\nelse if (l->migrate_type > r->migrate_type)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int gfp_flags_cmp(void *a, void *b)\r\n{\r\nstruct page_stat *l = a;\r\nstruct page_stat *r = b;\r\nif (l->gfp_flags == -1U)\r\nreturn 0;\r\nif (l->gfp_flags < r->gfp_flags)\r\nreturn -1;\r\nelse if (l->gfp_flags > r->gfp_flags)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int slab_sort_dimension__add(const char *tok, struct list_head *list)\r\n{\r\nstruct sort_dimension *sort;\r\nint i;\r\nfor (i = 0; i < (int)ARRAY_SIZE(slab_sorts); i++) {\r\nif (!strcmp(slab_sorts[i]->name, tok)) {\r\nsort = memdup(slab_sorts[i], sizeof(*slab_sorts[i]));\r\nif (!sort) {\r\npr_err("%s: memdup failed\n", __func__);\r\nreturn -1;\r\n}\r\nlist_add_tail(&sort->list, list);\r\nreturn 0;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nstatic int page_sort_dimension__add(const char *tok, struct list_head *list)\r\n{\r\nstruct sort_dimension *sort;\r\nint i;\r\nfor (i = 0; i < (int)ARRAY_SIZE(page_sorts); i++) {\r\nif (!strcmp(page_sorts[i]->name, tok)) {\r\nsort = memdup(page_sorts[i], sizeof(*page_sorts[i]));\r\nif (!sort) {\r\npr_err("%s: memdup failed\n", __func__);\r\nreturn -1;\r\n}\r\nlist_add_tail(&sort->list, list);\r\nreturn 0;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nstatic int setup_slab_sorting(struct list_head *sort_list, const char *arg)\r\n{\r\nchar *tok;\r\nchar *str = strdup(arg);\r\nchar *pos = str;\r\nif (!str) {\r\npr_err("%s: strdup failed\n", __func__);\r\nreturn -1;\r\n}\r\nwhile (true) {\r\ntok = strsep(&pos, ",");\r\nif (!tok)\r\nbreak;\r\nif (slab_sort_dimension__add(tok, sort_list) < 0) {\r\nerror("Unknown slab --sort key: '%s'", tok);\r\nfree(str);\r\nreturn -1;\r\n}\r\n}\r\nfree(str);\r\nreturn 0;\r\n}\r\nstatic int setup_page_sorting(struct list_head *sort_list, const char *arg)\r\n{\r\nchar *tok;\r\nchar *str = strdup(arg);\r\nchar *pos = str;\r\nif (!str) {\r\npr_err("%s: strdup failed\n", __func__);\r\nreturn -1;\r\n}\r\nwhile (true) {\r\ntok = strsep(&pos, ",");\r\nif (!tok)\r\nbreak;\r\nif (page_sort_dimension__add(tok, sort_list) < 0) {\r\nerror("Unknown page --sort key: '%s'", tok);\r\nfree(str);\r\nreturn -1;\r\n}\r\n}\r\nfree(str);\r\nreturn 0;\r\n}\r\nstatic int parse_sort_opt(const struct option *opt __maybe_unused,\r\nconst char *arg, int unset __maybe_unused)\r\n{\r\nif (!arg)\r\nreturn -1;\r\nif (kmem_page > kmem_slab ||\r\n(kmem_page == 0 && kmem_slab == 0 && kmem_default == KMEM_PAGE)) {\r\nif (caller_flag > alloc_flag)\r\nreturn setup_page_sorting(&page_caller_sort, arg);\r\nelse\r\nreturn setup_page_sorting(&page_alloc_sort, arg);\r\n} else {\r\nif (caller_flag > alloc_flag)\r\nreturn setup_slab_sorting(&slab_caller_sort, arg);\r\nelse\r\nreturn setup_slab_sorting(&slab_alloc_sort, arg);\r\n}\r\nreturn 0;\r\n}\r\nstatic int parse_caller_opt(const struct option *opt __maybe_unused,\r\nconst char *arg __maybe_unused,\r\nint unset __maybe_unused)\r\n{\r\ncaller_flag = (alloc_flag + 1);\r\nreturn 0;\r\n}\r\nstatic int parse_alloc_opt(const struct option *opt __maybe_unused,\r\nconst char *arg __maybe_unused,\r\nint unset __maybe_unused)\r\n{\r\nalloc_flag = (caller_flag + 1);\r\nreturn 0;\r\n}\r\nstatic int parse_slab_opt(const struct option *opt __maybe_unused,\r\nconst char *arg __maybe_unused,\r\nint unset __maybe_unused)\r\n{\r\nkmem_slab = (kmem_page + 1);\r\nreturn 0;\r\n}\r\nstatic int parse_page_opt(const struct option *opt __maybe_unused,\r\nconst char *arg __maybe_unused,\r\nint unset __maybe_unused)\r\n{\r\nkmem_page = (kmem_slab + 1);\r\nreturn 0;\r\n}\r\nstatic int parse_line_opt(const struct option *opt __maybe_unused,\r\nconst char *arg, int unset __maybe_unused)\r\n{\r\nint lines;\r\nif (!arg)\r\nreturn -1;\r\nlines = strtoul(arg, NULL, 10);\r\nif (caller_flag > alloc_flag)\r\ncaller_lines = lines;\r\nelse\r\nalloc_lines = lines;\r\nreturn 0;\r\n}\r\nstatic int __cmd_record(int argc, const char **argv)\r\n{\r\nconst char * const record_args[] = {\r\n"record", "-a", "-R", "-c", "1",\r\n};\r\nconst char * const slab_events[] = {\r\n"-e", "kmem:kmalloc",\r\n"-e", "kmem:kmalloc_node",\r\n"-e", "kmem:kfree",\r\n"-e", "kmem:kmem_cache_alloc",\r\n"-e", "kmem:kmem_cache_alloc_node",\r\n"-e", "kmem:kmem_cache_free",\r\n};\r\nconst char * const page_events[] = {\r\n"-e", "kmem:mm_page_alloc",\r\n"-e", "kmem:mm_page_free",\r\n};\r\nunsigned int rec_argc, i, j;\r\nconst char **rec_argv;\r\nrec_argc = ARRAY_SIZE(record_args) + argc - 1;\r\nif (kmem_slab)\r\nrec_argc += ARRAY_SIZE(slab_events);\r\nif (kmem_page)\r\nrec_argc += ARRAY_SIZE(page_events) + 1;\r\nrec_argv = calloc(rec_argc + 1, sizeof(char *));\r\nif (rec_argv == NULL)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < ARRAY_SIZE(record_args); i++)\r\nrec_argv[i] = strdup(record_args[i]);\r\nif (kmem_slab) {\r\nfor (j = 0; j < ARRAY_SIZE(slab_events); j++, i++)\r\nrec_argv[i] = strdup(slab_events[j]);\r\n}\r\nif (kmem_page) {\r\nrec_argv[i++] = strdup("-g");\r\nfor (j = 0; j < ARRAY_SIZE(page_events); j++, i++)\r\nrec_argv[i] = strdup(page_events[j]);\r\n}\r\nfor (j = 1; j < (unsigned int)argc; j++, i++)\r\nrec_argv[i] = argv[j];\r\nreturn cmd_record(i, rec_argv, NULL);\r\n}\r\nstatic int kmem_config(const char *var, const char *value, void *cb)\r\n{\r\nif (!strcmp(var, "kmem.default")) {\r\nif (!strcmp(value, "slab"))\r\nkmem_default = KMEM_SLAB;\r\nelse if (!strcmp(value, "page"))\r\nkmem_default = KMEM_PAGE;\r\nelse\r\npr_err("invalid default value ('slab' or 'page' required): %s\n",\r\nvalue);\r\nreturn 0;\r\n}\r\nreturn perf_default_config(var, value, cb);\r\n}\r\nint cmd_kmem(int argc, const char **argv, const char *prefix __maybe_unused)\r\n{\r\nconst char * const default_slab_sort = "frag,hit,bytes";\r\nconst char * const default_page_sort = "bytes,hit";\r\nstruct perf_data_file file = {\r\n.mode = PERF_DATA_MODE_READ,\r\n};\r\nconst struct option kmem_options[] = {\r\nOPT_STRING('i', "input", &input_name, "file", "input file name"),\r\nOPT_INCR('v', "verbose", &verbose,\r\n"be more verbose (show symbol address, etc)"),\r\nOPT_CALLBACK_NOOPT(0, "caller", NULL, NULL,\r\n"show per-callsite statistics", parse_caller_opt),\r\nOPT_CALLBACK_NOOPT(0, "alloc", NULL, NULL,\r\n"show per-allocation statistics", parse_alloc_opt),\r\nOPT_CALLBACK('s', "sort", NULL, "key[,key2...]",\r\n"sort by keys: ptr, callsite, bytes, hit, pingpong, frag, "\r\n"page, order, migtype, gfp", parse_sort_opt),\r\nOPT_CALLBACK('l', "line", NULL, "num", "show n lines", parse_line_opt),\r\nOPT_BOOLEAN(0, "raw-ip", &raw_ip, "show raw ip instead of symbol"),\r\nOPT_BOOLEAN('f', "force", &file.force, "don't complain, do it"),\r\nOPT_CALLBACK_NOOPT(0, "slab", NULL, NULL, "Analyze slab allocator",\r\nparse_slab_opt),\r\nOPT_CALLBACK_NOOPT(0, "page", NULL, NULL, "Analyze page allocator",\r\nparse_page_opt),\r\nOPT_BOOLEAN(0, "live", &live_page, "Show live page stat"),\r\nOPT_END()\r\n};\r\nconst char *const kmem_subcommands[] = { "record", "stat", NULL };\r\nconst char *kmem_usage[] = {\r\nNULL,\r\nNULL\r\n};\r\nstruct perf_session *session;\r\nint ret = -1;\r\nconst char errmsg[] = "No %s allocation events found. Have you run 'perf kmem record --%s'?\n";\r\nperf_config(kmem_config, NULL);\r\nargc = parse_options_subcommand(argc, argv, kmem_options,\r\nkmem_subcommands, kmem_usage, 0);\r\nif (!argc)\r\nusage_with_options(kmem_usage, kmem_options);\r\nif (kmem_slab == 0 && kmem_page == 0) {\r\nif (kmem_default == KMEM_SLAB)\r\nkmem_slab = 1;\r\nelse\r\nkmem_page = 1;\r\n}\r\nif (!strncmp(argv[0], "rec", 3)) {\r\nsymbol__init(NULL);\r\nreturn __cmd_record(argc, argv);\r\n}\r\nfile.path = input_name;\r\nkmem_session = session = perf_session__new(&file, false, &perf_kmem);\r\nif (session == NULL)\r\nreturn -1;\r\nif (kmem_slab) {\r\nif (!perf_evlist__find_tracepoint_by_name(session->evlist,\r\n"kmem:kmalloc")) {\r\npr_err(errmsg, "slab", "slab");\r\ngoto out_delete;\r\n}\r\n}\r\nif (kmem_page) {\r\nstruct perf_evsel *evsel;\r\nevsel = perf_evlist__find_tracepoint_by_name(session->evlist,\r\n"kmem:mm_page_alloc");\r\nif (evsel == NULL) {\r\npr_err(errmsg, "page", "page");\r\ngoto out_delete;\r\n}\r\nkmem_page_size = pevent_get_page_size(evsel->tp_format->pevent);\r\nsymbol_conf.use_callchain = true;\r\n}\r\nsymbol__init(&session->header.env);\r\nif (!strcmp(argv[0], "stat")) {\r\nsetlocale(LC_ALL, "");\r\nif (cpu__setup_cpunode_map())\r\ngoto out_delete;\r\nif (list_empty(&slab_caller_sort))\r\nsetup_slab_sorting(&slab_caller_sort, default_slab_sort);\r\nif (list_empty(&slab_alloc_sort))\r\nsetup_slab_sorting(&slab_alloc_sort, default_slab_sort);\r\nif (list_empty(&page_caller_sort))\r\nsetup_page_sorting(&page_caller_sort, default_page_sort);\r\nif (list_empty(&page_alloc_sort))\r\nsetup_page_sorting(&page_alloc_sort, default_page_sort);\r\nif (kmem_page) {\r\nsetup_page_sorting(&page_alloc_sort_input,\r\n"page,order,migtype,gfp");\r\nsetup_page_sorting(&page_caller_sort_input,\r\n"callsite,order,migtype,gfp");\r\n}\r\nret = __cmd_kmem(session);\r\n} else\r\nusage_with_options(kmem_usage, kmem_options);\r\nout_delete:\r\nperf_session__delete(session);\r\nreturn ret;\r\n}
