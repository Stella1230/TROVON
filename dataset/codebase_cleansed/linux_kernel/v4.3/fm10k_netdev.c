int fm10k_setup_tx_resources(struct fm10k_ring *tx_ring)\r\n{\r\nstruct device *dev = tx_ring->dev;\r\nint size;\r\nsize = sizeof(struct fm10k_tx_buffer) * tx_ring->count;\r\ntx_ring->tx_buffer = vzalloc(size);\r\nif (!tx_ring->tx_buffer)\r\ngoto err;\r\nu64_stats_init(&tx_ring->syncp);\r\ntx_ring->size = tx_ring->count * sizeof(struct fm10k_tx_desc);\r\ntx_ring->size = ALIGN(tx_ring->size, 4096);\r\ntx_ring->desc = dma_alloc_coherent(dev, tx_ring->size,\r\n&tx_ring->dma, GFP_KERNEL);\r\nif (!tx_ring->desc)\r\ngoto err;\r\nreturn 0;\r\nerr:\r\nvfree(tx_ring->tx_buffer);\r\ntx_ring->tx_buffer = NULL;\r\nreturn -ENOMEM;\r\n}\r\nstatic int fm10k_setup_all_tx_resources(struct fm10k_intfc *interface)\r\n{\r\nint i, err = 0;\r\nfor (i = 0; i < interface->num_tx_queues; i++) {\r\nerr = fm10k_setup_tx_resources(interface->tx_ring[i]);\r\nif (!err)\r\ncontinue;\r\nnetif_err(interface, probe, interface->netdev,\r\n"Allocation for Tx Queue %u failed\n", i);\r\ngoto err_setup_tx;\r\n}\r\nreturn 0;\r\nerr_setup_tx:\r\nwhile (i--)\r\nfm10k_free_tx_resources(interface->tx_ring[i]);\r\nreturn err;\r\n}\r\nint fm10k_setup_rx_resources(struct fm10k_ring *rx_ring)\r\n{\r\nstruct device *dev = rx_ring->dev;\r\nint size;\r\nsize = sizeof(struct fm10k_rx_buffer) * rx_ring->count;\r\nrx_ring->rx_buffer = vzalloc(size);\r\nif (!rx_ring->rx_buffer)\r\ngoto err;\r\nu64_stats_init(&rx_ring->syncp);\r\nrx_ring->size = rx_ring->count * sizeof(union fm10k_rx_desc);\r\nrx_ring->size = ALIGN(rx_ring->size, 4096);\r\nrx_ring->desc = dma_alloc_coherent(dev, rx_ring->size,\r\n&rx_ring->dma, GFP_KERNEL);\r\nif (!rx_ring->desc)\r\ngoto err;\r\nreturn 0;\r\nerr:\r\nvfree(rx_ring->rx_buffer);\r\nrx_ring->rx_buffer = NULL;\r\nreturn -ENOMEM;\r\n}\r\nstatic int fm10k_setup_all_rx_resources(struct fm10k_intfc *interface)\r\n{\r\nint i, err = 0;\r\nfor (i = 0; i < interface->num_rx_queues; i++) {\r\nerr = fm10k_setup_rx_resources(interface->rx_ring[i]);\r\nif (!err)\r\ncontinue;\r\nnetif_err(interface, probe, interface->netdev,\r\n"Allocation for Rx Queue %u failed\n", i);\r\ngoto err_setup_rx;\r\n}\r\nreturn 0;\r\nerr_setup_rx:\r\nwhile (i--)\r\nfm10k_free_rx_resources(interface->rx_ring[i]);\r\nreturn err;\r\n}\r\nvoid fm10k_unmap_and_free_tx_resource(struct fm10k_ring *ring,\r\nstruct fm10k_tx_buffer *tx_buffer)\r\n{\r\nif (tx_buffer->skb) {\r\ndev_kfree_skb_any(tx_buffer->skb);\r\nif (dma_unmap_len(tx_buffer, len))\r\ndma_unmap_single(ring->dev,\r\ndma_unmap_addr(tx_buffer, dma),\r\ndma_unmap_len(tx_buffer, len),\r\nDMA_TO_DEVICE);\r\n} else if (dma_unmap_len(tx_buffer, len)) {\r\ndma_unmap_page(ring->dev,\r\ndma_unmap_addr(tx_buffer, dma),\r\ndma_unmap_len(tx_buffer, len),\r\nDMA_TO_DEVICE);\r\n}\r\ntx_buffer->next_to_watch = NULL;\r\ntx_buffer->skb = NULL;\r\ndma_unmap_len_set(tx_buffer, len, 0);\r\n}\r\nstatic void fm10k_clean_tx_ring(struct fm10k_ring *tx_ring)\r\n{\r\nstruct fm10k_tx_buffer *tx_buffer;\r\nunsigned long size;\r\nu16 i;\r\nif (!tx_ring->tx_buffer)\r\nreturn;\r\nfor (i = 0; i < tx_ring->count; i++) {\r\ntx_buffer = &tx_ring->tx_buffer[i];\r\nfm10k_unmap_and_free_tx_resource(tx_ring, tx_buffer);\r\n}\r\nnetdev_tx_reset_queue(txring_txq(tx_ring));\r\nsize = sizeof(struct fm10k_tx_buffer) * tx_ring->count;\r\nmemset(tx_ring->tx_buffer, 0, size);\r\nmemset(tx_ring->desc, 0, tx_ring->size);\r\n}\r\nvoid fm10k_free_tx_resources(struct fm10k_ring *tx_ring)\r\n{\r\nfm10k_clean_tx_ring(tx_ring);\r\nvfree(tx_ring->tx_buffer);\r\ntx_ring->tx_buffer = NULL;\r\nif (!tx_ring->desc)\r\nreturn;\r\ndma_free_coherent(tx_ring->dev, tx_ring->size,\r\ntx_ring->desc, tx_ring->dma);\r\ntx_ring->desc = NULL;\r\n}\r\nvoid fm10k_clean_all_tx_rings(struct fm10k_intfc *interface)\r\n{\r\nint i;\r\nfor (i = 0; i < interface->num_tx_queues; i++)\r\nfm10k_clean_tx_ring(interface->tx_ring[i]);\r\nskb_queue_purge(&interface->ts_tx_skb_queue);\r\n}\r\nstatic void fm10k_free_all_tx_resources(struct fm10k_intfc *interface)\r\n{\r\nint i = interface->num_tx_queues;\r\nwhile (i--)\r\nfm10k_free_tx_resources(interface->tx_ring[i]);\r\n}\r\nstatic void fm10k_clean_rx_ring(struct fm10k_ring *rx_ring)\r\n{\r\nunsigned long size;\r\nu16 i;\r\nif (!rx_ring->rx_buffer)\r\nreturn;\r\nif (rx_ring->skb)\r\ndev_kfree_skb(rx_ring->skb);\r\nrx_ring->skb = NULL;\r\nfor (i = 0; i < rx_ring->count; i++) {\r\nstruct fm10k_rx_buffer *buffer = &rx_ring->rx_buffer[i];\r\nif (!buffer->page)\r\ncontinue;\r\ndma_unmap_page(rx_ring->dev, buffer->dma,\r\nPAGE_SIZE, DMA_FROM_DEVICE);\r\n__free_page(buffer->page);\r\nbuffer->page = NULL;\r\n}\r\nsize = sizeof(struct fm10k_rx_buffer) * rx_ring->count;\r\nmemset(rx_ring->rx_buffer, 0, size);\r\nmemset(rx_ring->desc, 0, rx_ring->size);\r\nrx_ring->next_to_alloc = 0;\r\nrx_ring->next_to_clean = 0;\r\nrx_ring->next_to_use = 0;\r\n}\r\nvoid fm10k_free_rx_resources(struct fm10k_ring *rx_ring)\r\n{\r\nfm10k_clean_rx_ring(rx_ring);\r\nvfree(rx_ring->rx_buffer);\r\nrx_ring->rx_buffer = NULL;\r\nif (!rx_ring->desc)\r\nreturn;\r\ndma_free_coherent(rx_ring->dev, rx_ring->size,\r\nrx_ring->desc, rx_ring->dma);\r\nrx_ring->desc = NULL;\r\n}\r\nvoid fm10k_clean_all_rx_rings(struct fm10k_intfc *interface)\r\n{\r\nint i;\r\nfor (i = 0; i < interface->num_rx_queues; i++)\r\nfm10k_clean_rx_ring(interface->rx_ring[i]);\r\n}\r\nstatic void fm10k_free_all_rx_resources(struct fm10k_intfc *interface)\r\n{\r\nint i = interface->num_rx_queues;\r\nwhile (i--)\r\nfm10k_free_rx_resources(interface->rx_ring[i]);\r\n}\r\nstatic void fm10k_request_glort_range(struct fm10k_intfc *interface)\r\n{\r\nstruct fm10k_hw *hw = &interface->hw;\r\nu16 mask = (~hw->mac.dglort_map) >> FM10K_DGLORTMAP_MASK_SHIFT;\r\ninterface->glort = hw->mac.dglort_map & FM10K_DGLORTMAP_NONE;\r\ninterface->glort_count = 0;\r\nif (hw->mac.dglort_map == FM10K_DGLORTMAP_NONE)\r\nreturn;\r\nif (mask <= hw->iov.total_vfs) {\r\ninterface->glort_count = 1;\r\ninterface->glort += mask;\r\n} else if (mask < 64) {\r\ninterface->glort_count = (mask + 1) / 2;\r\ninterface->glort += interface->glort_count;\r\n} else {\r\ninterface->glort_count = mask - 63;\r\ninterface->glort += 64;\r\n}\r\n}\r\nstatic void fm10k_del_vxlan_port_all(struct fm10k_intfc *interface)\r\n{\r\nstruct fm10k_vxlan_port *vxlan_port;\r\nvxlan_port = list_first_entry_or_null(&interface->vxlan_port,\r\nstruct fm10k_vxlan_port, list);\r\nwhile (vxlan_port) {\r\nlist_del(&vxlan_port->list);\r\nkfree(vxlan_port);\r\nvxlan_port = list_first_entry_or_null(&interface->vxlan_port,\r\nstruct fm10k_vxlan_port,\r\nlist);\r\n}\r\n}\r\nstatic void fm10k_restore_vxlan_port(struct fm10k_intfc *interface)\r\n{\r\nstruct fm10k_hw *hw = &interface->hw;\r\nstruct fm10k_vxlan_port *vxlan_port;\r\nif (hw->mac.type != fm10k_mac_pf)\r\nreturn;\r\nvxlan_port = list_first_entry_or_null(&interface->vxlan_port,\r\nstruct fm10k_vxlan_port, list);\r\nfm10k_write_reg(hw, FM10K_TUNNEL_CFG,\r\n(vxlan_port ? ntohs(vxlan_port->port) : 0) |\r\n(ETH_P_TEB << FM10K_TUNNEL_CFG_NVGRE_SHIFT));\r\n}\r\nstatic void fm10k_add_vxlan_port(struct net_device *dev,\r\nsa_family_t sa_family, __be16 port) {\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_vxlan_port *vxlan_port;\r\nif (interface->hw.mac.type != fm10k_mac_pf)\r\nreturn;\r\nfm10k_vxlan_port_for_each(vxlan_port, interface) {\r\nif ((vxlan_port->port == port) &&\r\n(vxlan_port->sa_family == sa_family)) {\r\nlist_del(&vxlan_port->list);\r\ngoto insert_tail;\r\n}\r\n}\r\nvxlan_port = kmalloc(sizeof(*vxlan_port), GFP_ATOMIC);\r\nif (!vxlan_port)\r\nreturn;\r\nvxlan_port->port = port;\r\nvxlan_port->sa_family = sa_family;\r\ninsert_tail:\r\nlist_add_tail(&vxlan_port->list, &interface->vxlan_port);\r\nfm10k_restore_vxlan_port(interface);\r\n}\r\nstatic void fm10k_del_vxlan_port(struct net_device *dev,\r\nsa_family_t sa_family, __be16 port) {\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_vxlan_port *vxlan_port;\r\nif (interface->hw.mac.type != fm10k_mac_pf)\r\nreturn;\r\nfm10k_vxlan_port_for_each(vxlan_port, interface) {\r\nif ((vxlan_port->port == port) &&\r\n(vxlan_port->sa_family == sa_family)) {\r\nlist_del(&vxlan_port->list);\r\nkfree(vxlan_port);\r\nbreak;\r\n}\r\n}\r\nfm10k_restore_vxlan_port(interface);\r\n}\r\nint fm10k_open(struct net_device *netdev)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(netdev);\r\nint err;\r\nerr = fm10k_setup_all_tx_resources(interface);\r\nif (err)\r\ngoto err_setup_tx;\r\nerr = fm10k_setup_all_rx_resources(interface);\r\nif (err)\r\ngoto err_setup_rx;\r\nerr = fm10k_qv_request_irq(interface);\r\nif (err)\r\ngoto err_req_irq;\r\nfm10k_request_glort_range(interface);\r\nerr = netif_set_real_num_tx_queues(netdev,\r\ninterface->num_tx_queues);\r\nif (err)\r\ngoto err_set_queues;\r\nerr = netif_set_real_num_rx_queues(netdev,\r\ninterface->num_rx_queues);\r\nif (err)\r\ngoto err_set_queues;\r\n#if IS_ENABLED(CONFIG_FM10K_VXLAN)\r\nvxlan_get_rx_port(netdev);\r\n#endif\r\nfm10k_up(interface);\r\nreturn 0;\r\nerr_set_queues:\r\nfm10k_qv_free_irq(interface);\r\nerr_req_irq:\r\nfm10k_free_all_rx_resources(interface);\r\nerr_setup_rx:\r\nfm10k_free_all_tx_resources(interface);\r\nerr_setup_tx:\r\nreturn err;\r\n}\r\nint fm10k_close(struct net_device *netdev)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(netdev);\r\nfm10k_down(interface);\r\nfm10k_qv_free_irq(interface);\r\nfm10k_del_vxlan_port_all(interface);\r\nfm10k_free_all_tx_resources(interface);\r\nfm10k_free_all_rx_resources(interface);\r\nreturn 0;\r\n}\r\nstatic netdev_tx_t fm10k_xmit_frame(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nunsigned int r_idx = skb->queue_mapping;\r\nint err;\r\nif ((skb->protocol == htons(ETH_P_8021Q)) &&\r\n!skb_vlan_tag_present(skb)) {\r\nstruct vlan_hdr *vhdr;\r\n__be16 proto;\r\nskb = skb_share_check(skb, GFP_ATOMIC);\r\nif (!skb)\r\nreturn NETDEV_TX_OK;\r\nif (unlikely(!pskb_may_pull(skb, VLAN_ETH_HLEN)))\r\nreturn NETDEV_TX_OK;\r\nerr = skb_cow_head(skb, 0);\r\nif (err)\r\nreturn NETDEV_TX_OK;\r\nvhdr = (struct vlan_hdr *)(skb->data + ETH_HLEN);\r\n__vlan_hwaccel_put_tag(skb,\r\nhtons(ETH_P_8021Q),\r\nntohs(vhdr->h_vlan_TCI));\r\nproto = vhdr->h_vlan_encapsulated_proto;\r\nskb->protocol = (ntohs(proto) >= 1536) ? proto :\r\nhtons(ETH_P_802_2);\r\nmemmove(skb->data + VLAN_HLEN, skb->data, 12);\r\n__skb_pull(skb, VLAN_HLEN);\r\nskb_reset_mac_header(skb);\r\n}\r\nif (unlikely(skb->len < 17)) {\r\nint pad_len = 17 - skb->len;\r\nif (skb_pad(skb, pad_len))\r\nreturn NETDEV_TX_OK;\r\n__skb_put(skb, pad_len);\r\n}\r\nif (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP))\r\nfm10k_ts_tx_enqueue(interface, skb);\r\nif (r_idx >= interface->num_tx_queues)\r\nr_idx %= interface->num_tx_queues;\r\nerr = fm10k_xmit_frame_ring(skb, interface->tx_ring[r_idx]);\r\nreturn err;\r\n}\r\nstatic int fm10k_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nif (new_mtu < 68 || new_mtu > FM10K_MAX_JUMBO_FRAME_SIZE)\r\nreturn -EINVAL;\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nstatic void fm10k_tx_timeout(struct net_device *netdev)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(netdev);\r\nbool real_tx_hang = false;\r\nint i;\r\n#define TX_TIMEO_LIMIT 16000\r\nfor (i = 0; i < interface->num_tx_queues; i++) {\r\nstruct fm10k_ring *tx_ring = interface->tx_ring[i];\r\nif (check_for_tx_hang(tx_ring) && fm10k_check_tx_hang(tx_ring))\r\nreal_tx_hang = true;\r\n}\r\nif (real_tx_hang) {\r\nfm10k_tx_timeout_reset(interface);\r\n} else {\r\nnetif_info(interface, drv, netdev,\r\n"Fake Tx hang detected with timeout of %d seconds\n",\r\nnetdev->watchdog_timeo/HZ);\r\nif (netdev->watchdog_timeo < TX_TIMEO_LIMIT)\r\nnetdev->watchdog_timeo *= 2;\r\n}\r\n}\r\nstatic int fm10k_uc_vlan_unsync(struct net_device *netdev,\r\nconst unsigned char *uc_addr)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(netdev);\r\nstruct fm10k_hw *hw = &interface->hw;\r\nu16 glort = interface->glort;\r\nu16 vid = interface->vid;\r\nbool set = !!(vid / VLAN_N_VID);\r\nint err;\r\nvid &= VLAN_N_VID - 1;\r\nerr = hw->mac.ops.update_uc_addr(hw, glort, uc_addr, vid, set, 0);\r\nif (err)\r\nreturn err;\r\nreturn 1;\r\n}\r\nstatic int fm10k_mc_vlan_unsync(struct net_device *netdev,\r\nconst unsigned char *mc_addr)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(netdev);\r\nstruct fm10k_hw *hw = &interface->hw;\r\nu16 glort = interface->glort;\r\nu16 vid = interface->vid;\r\nbool set = !!(vid / VLAN_N_VID);\r\nint err;\r\nvid &= VLAN_N_VID - 1;\r\nerr = hw->mac.ops.update_mc_addr(hw, glort, mc_addr, vid, set);\r\nif (err)\r\nreturn err;\r\nreturn 1;\r\n}\r\nstatic int fm10k_update_vid(struct net_device *netdev, u16 vid, bool set)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(netdev);\r\nstruct fm10k_hw *hw = &interface->hw;\r\ns32 err;\r\nif (!vid)\r\nreturn 0;\r\nif (vid >= VLAN_N_VID)\r\nreturn -EINVAL;\r\nif (hw->mac.vlan_override)\r\nreturn -EACCES;\r\nset_bit(vid, interface->active_vlans);\r\nif (!set)\r\nclear_bit(vid, interface->active_vlans);\r\nif (vid == hw->mac.default_vid)\r\nreturn 0;\r\nfm10k_mbx_lock(interface);\r\nif (!(netdev->flags & IFF_PROMISC)) {\r\nerr = hw->mac.ops.update_vlan(hw, vid, 0, set);\r\nif (err)\r\ngoto err_out;\r\n}\r\nerr = hw->mac.ops.update_uc_addr(hw, interface->glort, hw->mac.addr,\r\nvid, set, 0);\r\nif (err)\r\ngoto err_out;\r\ninterface->vid = vid + (set ? VLAN_N_VID : 0);\r\n__dev_uc_unsync(netdev, fm10k_uc_vlan_unsync);\r\n__dev_mc_unsync(netdev, fm10k_mc_vlan_unsync);\r\nerr_out:\r\nfm10k_mbx_unlock(interface);\r\nreturn err;\r\n}\r\nstatic int fm10k_vlan_rx_add_vid(struct net_device *netdev,\r\n__always_unused __be16 proto, u16 vid)\r\n{\r\nreturn fm10k_update_vid(netdev, vid, true);\r\n}\r\nstatic int fm10k_vlan_rx_kill_vid(struct net_device *netdev,\r\n__always_unused __be16 proto, u16 vid)\r\n{\r\nreturn fm10k_update_vid(netdev, vid, false);\r\n}\r\nstatic u16 fm10k_find_next_vlan(struct fm10k_intfc *interface, u16 vid)\r\n{\r\nstruct fm10k_hw *hw = &interface->hw;\r\nu16 default_vid = hw->mac.default_vid;\r\nu16 vid_limit = vid < default_vid ? default_vid : VLAN_N_VID;\r\nvid = find_next_bit(interface->active_vlans, vid_limit, ++vid);\r\nreturn vid;\r\n}\r\nstatic void fm10k_clear_unused_vlans(struct fm10k_intfc *interface)\r\n{\r\nstruct fm10k_hw *hw = &interface->hw;\r\nu32 vid, prev_vid;\r\nfor (vid = 0, prev_vid = 0;\r\nprev_vid < VLAN_N_VID;\r\nprev_vid = vid + 1, vid = fm10k_find_next_vlan(interface, vid)) {\r\nif (prev_vid == vid)\r\ncontinue;\r\nprev_vid += (vid - prev_vid - 1) << FM10K_VLAN_LENGTH_SHIFT;\r\nhw->mac.ops.update_vlan(hw, prev_vid, 0, false);\r\n}\r\n}\r\nstatic int __fm10k_uc_sync(struct net_device *dev,\r\nconst unsigned char *addr, bool sync)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_hw *hw = &interface->hw;\r\nu16 vid, glort = interface->glort;\r\ns32 err;\r\nif (!is_valid_ether_addr(addr))\r\nreturn -EADDRNOTAVAIL;\r\nfor (vid = hw->mac.default_vid ? fm10k_find_next_vlan(interface, 0) : 0;\r\nvid < VLAN_N_VID;\r\nvid = fm10k_find_next_vlan(interface, vid)) {\r\nerr = hw->mac.ops.update_uc_addr(hw, glort, addr,\r\nvid, sync, 0);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic int fm10k_uc_sync(struct net_device *dev,\r\nconst unsigned char *addr)\r\n{\r\nreturn __fm10k_uc_sync(dev, addr, true);\r\n}\r\nstatic int fm10k_uc_unsync(struct net_device *dev,\r\nconst unsigned char *addr)\r\n{\r\nreturn __fm10k_uc_sync(dev, addr, false);\r\n}\r\nstatic int fm10k_set_mac(struct net_device *dev, void *p)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_hw *hw = &interface->hw;\r\nstruct sockaddr *addr = p;\r\ns32 err = 0;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nif (dev->flags & IFF_UP) {\r\nfm10k_mbx_lock(interface);\r\nerr = fm10k_uc_sync(dev, addr->sa_data);\r\nif (!err)\r\nfm10k_uc_unsync(dev, hw->mac.addr);\r\nfm10k_mbx_unlock(interface);\r\n}\r\nif (!err) {\r\nether_addr_copy(dev->dev_addr, addr->sa_data);\r\nether_addr_copy(hw->mac.addr, addr->sa_data);\r\ndev->addr_assign_type &= ~NET_ADDR_RANDOM;\r\n}\r\nreturn err ? -EAGAIN : 0;\r\n}\r\nstatic int __fm10k_mc_sync(struct net_device *dev,\r\nconst unsigned char *addr, bool sync)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_hw *hw = &interface->hw;\r\nu16 vid, glort = interface->glort;\r\nfor (vid = hw->mac.default_vid ? fm10k_find_next_vlan(interface, 0) : 0;\r\nvid < VLAN_N_VID;\r\nvid = fm10k_find_next_vlan(interface, vid)) {\r\nhw->mac.ops.update_mc_addr(hw, glort, addr, vid, sync);\r\n}\r\nreturn 0;\r\n}\r\nstatic int fm10k_mc_sync(struct net_device *dev,\r\nconst unsigned char *addr)\r\n{\r\nreturn __fm10k_mc_sync(dev, addr, true);\r\n}\r\nstatic int fm10k_mc_unsync(struct net_device *dev,\r\nconst unsigned char *addr)\r\n{\r\nreturn __fm10k_mc_sync(dev, addr, false);\r\n}\r\nstatic void fm10k_set_rx_mode(struct net_device *dev)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_hw *hw = &interface->hw;\r\nint xcast_mode;\r\nif (!(dev->flags & IFF_UP))\r\nreturn;\r\nxcast_mode = (dev->flags & IFF_PROMISC) ? FM10K_XCAST_MODE_PROMISC :\r\n(dev->flags & IFF_ALLMULTI) ? FM10K_XCAST_MODE_ALLMULTI :\r\n(dev->flags & (IFF_BROADCAST | IFF_MULTICAST)) ?\r\nFM10K_XCAST_MODE_MULTI : FM10K_XCAST_MODE_NONE;\r\nfm10k_mbx_lock(interface);\r\nif (interface->xcast_mode != xcast_mode) {\r\nif (xcast_mode == FM10K_XCAST_MODE_PROMISC)\r\nhw->mac.ops.update_vlan(hw, FM10K_VLAN_ALL, 0, true);\r\nif (interface->xcast_mode == FM10K_XCAST_MODE_PROMISC)\r\nfm10k_clear_unused_vlans(interface);\r\nhw->mac.ops.update_xcast_mode(hw, interface->glort, xcast_mode);\r\ninterface->xcast_mode = xcast_mode;\r\n}\r\nif (xcast_mode != FM10K_XCAST_MODE_PROMISC) {\r\n__dev_uc_sync(dev, fm10k_uc_sync, fm10k_uc_unsync);\r\nif (xcast_mode != FM10K_XCAST_MODE_ALLMULTI)\r\n__dev_mc_sync(dev, fm10k_mc_sync, fm10k_mc_unsync);\r\n}\r\nfm10k_mbx_unlock(interface);\r\n}\r\nvoid fm10k_restore_rx_state(struct fm10k_intfc *interface)\r\n{\r\nstruct net_device *netdev = interface->netdev;\r\nstruct fm10k_hw *hw = &interface->hw;\r\nint xcast_mode;\r\nu16 vid, glort;\r\nif (hw->mac.type == fm10k_mac_vf) {\r\nif (is_valid_ether_addr(hw->mac.perm_addr)) {\r\nether_addr_copy(hw->mac.addr, hw->mac.perm_addr);\r\nether_addr_copy(netdev->perm_addr, hw->mac.perm_addr);\r\nether_addr_copy(netdev->dev_addr, hw->mac.perm_addr);\r\nnetdev->addr_assign_type &= ~NET_ADDR_RANDOM;\r\n}\r\nif (hw->mac.vlan_override)\r\nnetdev->features &= ~NETIF_F_HW_VLAN_CTAG_RX;\r\nelse\r\nnetdev->features |= NETIF_F_HW_VLAN_CTAG_RX;\r\n}\r\nglort = interface->glort;\r\nif (netdev->flags & IFF_PROMISC)\r\nxcast_mode = FM10K_XCAST_MODE_PROMISC;\r\nelse if (netdev->flags & IFF_ALLMULTI)\r\nxcast_mode = FM10K_XCAST_MODE_ALLMULTI;\r\nelse if (netdev->flags & (IFF_BROADCAST | IFF_MULTICAST))\r\nxcast_mode = FM10K_XCAST_MODE_MULTI;\r\nelse\r\nxcast_mode = FM10K_XCAST_MODE_NONE;\r\nfm10k_mbx_lock(interface);\r\nhw->mac.ops.update_lport_state(hw, glort, interface->glort_count, true);\r\nhw->mac.ops.update_vlan(hw, FM10K_VLAN_ALL, 0,\r\nxcast_mode == FM10K_XCAST_MODE_PROMISC);\r\nhw->mac.ops.update_vlan(hw, 0, 0, true);\r\nfor (vid = hw->mac.default_vid ? fm10k_find_next_vlan(interface, 0) : 0;\r\nvid < VLAN_N_VID;\r\nvid = fm10k_find_next_vlan(interface, vid)) {\r\nhw->mac.ops.update_vlan(hw, vid, 0, true);\r\nhw->mac.ops.update_uc_addr(hw, glort, hw->mac.addr,\r\nvid, true, 0);\r\n}\r\nhw->mac.ops.update_xcast_mode(hw, glort, xcast_mode);\r\nif (xcast_mode != FM10K_XCAST_MODE_PROMISC) {\r\n__dev_uc_sync(netdev, fm10k_uc_sync, fm10k_uc_unsync);\r\nif (xcast_mode != FM10K_XCAST_MODE_ALLMULTI)\r\n__dev_mc_sync(netdev, fm10k_mc_sync, fm10k_mc_unsync);\r\n}\r\nfm10k_mbx_unlock(interface);\r\ninterface->xcast_mode = xcast_mode;\r\nfm10k_restore_vxlan_port(interface);\r\n}\r\nvoid fm10k_reset_rx_state(struct fm10k_intfc *interface)\r\n{\r\nstruct net_device *netdev = interface->netdev;\r\nstruct fm10k_hw *hw = &interface->hw;\r\nfm10k_mbx_lock(interface);\r\nhw->mac.ops.update_lport_state(hw, interface->glort,\r\ninterface->glort_count, false);\r\nfm10k_mbx_unlock(interface);\r\ninterface->xcast_mode = FM10K_XCAST_MODE_NONE;\r\n__dev_uc_unsync(netdev, NULL);\r\n__dev_mc_unsync(netdev, NULL);\r\n}\r\nstatic struct rtnl_link_stats64 *fm10k_get_stats64(struct net_device *netdev,\r\nstruct rtnl_link_stats64 *stats)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(netdev);\r\nstruct fm10k_ring *ring;\r\nunsigned int start, i;\r\nu64 bytes, packets;\r\nrcu_read_lock();\r\nfor (i = 0; i < interface->num_rx_queues; i++) {\r\nring = ACCESS_ONCE(interface->rx_ring[i]);\r\nif (!ring)\r\ncontinue;\r\ndo {\r\nstart = u64_stats_fetch_begin_irq(&ring->syncp);\r\npackets = ring->stats.packets;\r\nbytes = ring->stats.bytes;\r\n} while (u64_stats_fetch_retry_irq(&ring->syncp, start));\r\nstats->rx_packets += packets;\r\nstats->rx_bytes += bytes;\r\n}\r\nfor (i = 0; i < interface->num_tx_queues; i++) {\r\nring = ACCESS_ONCE(interface->tx_ring[i]);\r\nif (!ring)\r\ncontinue;\r\ndo {\r\nstart = u64_stats_fetch_begin_irq(&ring->syncp);\r\npackets = ring->stats.packets;\r\nbytes = ring->stats.bytes;\r\n} while (u64_stats_fetch_retry_irq(&ring->syncp, start));\r\nstats->tx_packets += packets;\r\nstats->tx_bytes += bytes;\r\n}\r\nrcu_read_unlock();\r\nstats->rx_missed_errors = netdev->stats.rx_missed_errors;\r\nreturn stats;\r\n}\r\nint fm10k_setup_tc(struct net_device *dev, u8 tc)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nif (tc && (interface->hw.mac.type != fm10k_mac_pf))\r\nreturn -EINVAL;\r\nif (tc > 8)\r\nreturn -EINVAL;\r\nif (netif_running(dev))\r\nfm10k_close(dev);\r\nfm10k_mbx_free_irq(interface);\r\nfm10k_clear_queueing_scheme(interface);\r\nnetdev_reset_tc(dev);\r\nnetdev_set_num_tc(dev, tc);\r\nfm10k_init_queueing_scheme(interface);\r\nfm10k_mbx_request_irq(interface);\r\nif (netif_running(dev))\r\nfm10k_open(dev);\r\ninterface->flags |= FM10K_FLAG_SWPRI_CONFIG;\r\nreturn 0;\r\n}\r\nstatic int fm10k_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\r\n{\r\nswitch (cmd) {\r\ncase SIOCGHWTSTAMP:\r\nreturn fm10k_get_ts_config(netdev, ifr);\r\ncase SIOCSHWTSTAMP:\r\nreturn fm10k_set_ts_config(netdev, ifr);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void fm10k_assign_l2_accel(struct fm10k_intfc *interface,\r\nstruct fm10k_l2_accel *l2_accel)\r\n{\r\nstruct fm10k_ring *ring;\r\nint i;\r\nfor (i = 0; i < interface->num_rx_queues; i++) {\r\nring = interface->rx_ring[i];\r\nrcu_assign_pointer(ring->l2_accel, l2_accel);\r\n}\r\ninterface->l2_accel = l2_accel;\r\n}\r\nstatic void *fm10k_dfwd_add_station(struct net_device *dev,\r\nstruct net_device *sdev)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_l2_accel *l2_accel = interface->l2_accel;\r\nstruct fm10k_l2_accel *old_l2_accel = NULL;\r\nstruct fm10k_dglort_cfg dglort = { 0 };\r\nstruct fm10k_hw *hw = &interface->hw;\r\nint size = 0, i;\r\nu16 glort;\r\nif (!l2_accel) {\r\nif (interface->glort_count < 7)\r\nreturn ERR_PTR(-EBUSY);\r\nsize = offsetof(struct fm10k_l2_accel, macvlan[7]);\r\nl2_accel = kzalloc(size, GFP_KERNEL);\r\nif (!l2_accel)\r\nreturn ERR_PTR(-ENOMEM);\r\nl2_accel->size = 7;\r\nl2_accel->dglort = interface->glort;\r\nfm10k_assign_l2_accel(interface, l2_accel);\r\n} else if ((l2_accel->count == FM10K_MAX_STATIONS) ||\r\n(l2_accel->count == (interface->glort_count - 1))) {\r\nreturn ERR_PTR(-EBUSY);\r\n} else if (l2_accel->count == l2_accel->size) {\r\nold_l2_accel = l2_accel;\r\nsize = offsetof(struct fm10k_l2_accel,\r\nmacvlan[(l2_accel->size * 2) + 1]);\r\nl2_accel = kzalloc(size, GFP_KERNEL);\r\nif (!l2_accel)\r\nreturn ERR_PTR(-ENOMEM);\r\nmemcpy(l2_accel, old_l2_accel,\r\noffsetof(struct fm10k_l2_accel,\r\nmacvlan[old_l2_accel->size]));\r\nl2_accel->size = (old_l2_accel->size * 2) + 1;\r\nfm10k_assign_l2_accel(interface, l2_accel);\r\nkfree_rcu(old_l2_accel, rcu);\r\n}\r\nfor (i = 0; i < l2_accel->size; i++) {\r\nif (!l2_accel->macvlan[i])\r\nbreak;\r\n}\r\nl2_accel->macvlan[i] = sdev;\r\nl2_accel->count++;\r\ndglort.idx = fm10k_dglort_pf_rss;\r\ndglort.inner_rss = 1;\r\ndglort.rss_l = fls(interface->ring_feature[RING_F_RSS].mask);\r\ndglort.pc_l = fls(interface->ring_feature[RING_F_QOS].mask);\r\ndglort.glort = interface->glort;\r\ndglort.shared_l = fls(l2_accel->size);\r\nhw->mac.ops.configure_dglort_map(hw, &dglort);\r\nfm10k_mbx_lock(interface);\r\nglort = l2_accel->dglort + 1 + i;\r\nhw->mac.ops.update_xcast_mode(hw, glort, FM10K_XCAST_MODE_MULTI);\r\nhw->mac.ops.update_uc_addr(hw, glort, sdev->dev_addr, 0, true, 0);\r\nfm10k_mbx_unlock(interface);\r\nreturn sdev;\r\n}\r\nstatic void fm10k_dfwd_del_station(struct net_device *dev, void *priv)\r\n{\r\nstruct fm10k_intfc *interface = netdev_priv(dev);\r\nstruct fm10k_l2_accel *l2_accel = ACCESS_ONCE(interface->l2_accel);\r\nstruct fm10k_dglort_cfg dglort = { 0 };\r\nstruct fm10k_hw *hw = &interface->hw;\r\nstruct net_device *sdev = priv;\r\nint i;\r\nu16 glort;\r\nif (!l2_accel)\r\nreturn;\r\nfor (i = 0; i < l2_accel->size; i++) {\r\nif (l2_accel->macvlan[i] == sdev)\r\nbreak;\r\n}\r\nif (i == l2_accel->size)\r\nreturn;\r\nfm10k_mbx_lock(interface);\r\nglort = l2_accel->dglort + 1 + i;\r\nhw->mac.ops.update_xcast_mode(hw, glort, FM10K_XCAST_MODE_NONE);\r\nhw->mac.ops.update_uc_addr(hw, glort, sdev->dev_addr, 0, false, 0);\r\nfm10k_mbx_unlock(interface);\r\nl2_accel->macvlan[i] = NULL;\r\nl2_accel->count--;\r\ndglort.idx = fm10k_dglort_pf_rss;\r\ndglort.inner_rss = 1;\r\ndglort.rss_l = fls(interface->ring_feature[RING_F_RSS].mask);\r\ndglort.pc_l = fls(interface->ring_feature[RING_F_QOS].mask);\r\ndglort.glort = interface->glort;\r\ndglort.shared_l = fls(l2_accel->size);\r\nhw->mac.ops.configure_dglort_map(hw, &dglort);\r\nif (l2_accel->count == 0) {\r\nfm10k_assign_l2_accel(interface, NULL);\r\nkfree_rcu(l2_accel, rcu);\r\n}\r\n}\r\nstatic netdev_features_t fm10k_features_check(struct sk_buff *skb,\r\nstruct net_device *dev,\r\nnetdev_features_t features)\r\n{\r\nif (!skb->encapsulation || fm10k_tx_encap_offload(skb))\r\nreturn features;\r\nreturn features & ~(NETIF_F_ALL_CSUM | NETIF_F_GSO_MASK);\r\n}\r\nstruct net_device *fm10k_alloc_netdev(void)\r\n{\r\nstruct fm10k_intfc *interface;\r\nstruct net_device *dev;\r\ndev = alloc_etherdev_mq(sizeof(struct fm10k_intfc), MAX_QUEUES);\r\nif (!dev)\r\nreturn NULL;\r\ndev->netdev_ops = &fm10k_netdev_ops;\r\nfm10k_set_ethtool_ops(dev);\r\ninterface = netdev_priv(dev);\r\ninterface->msg_enable = (1 << DEFAULT_DEBUG_LEVEL_SHIFT) - 1;\r\ndev->features |= NETIF_F_IP_CSUM |\r\nNETIF_F_IPV6_CSUM |\r\nNETIF_F_SG |\r\nNETIF_F_TSO |\r\nNETIF_F_TSO6 |\r\nNETIF_F_TSO_ECN |\r\nNETIF_F_GSO_UDP_TUNNEL |\r\nNETIF_F_RXHASH |\r\nNETIF_F_RXCSUM;\r\ndev->hw_features |= dev->features;\r\ndev->hw_features |= NETIF_F_HW_L2FW_DOFFLOAD;\r\ndev->vlan_features |= dev->features;\r\ndev->hw_enc_features |= NETIF_F_IP_CSUM |\r\nNETIF_F_TSO |\r\nNETIF_F_TSO6 |\r\nNETIF_F_TSO_ECN |\r\nNETIF_F_GSO_UDP_TUNNEL |\r\nNETIF_F_IPV6_CSUM;\r\ndev->features |= NETIF_F_HW_VLAN_CTAG_TX |\r\nNETIF_F_HW_VLAN_CTAG_RX |\r\nNETIF_F_HW_VLAN_CTAG_FILTER;\r\ndev->priv_flags |= IFF_UNICAST_FLT;\r\nreturn dev;\r\n}
