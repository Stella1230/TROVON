static int armada_gem_vm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct armada_gem_object *obj = drm_to_armada_gem(vma->vm_private_data);\r\nunsigned long addr = (unsigned long)vmf->virtual_address;\r\nunsigned long pfn = obj->phys_addr >> PAGE_SHIFT;\r\nint ret;\r\npfn += (addr - vma->vm_start) >> PAGE_SHIFT;\r\nret = vm_insert_pfn(vma, addr, pfn);\r\nswitch (ret) {\r\ncase 0:\r\ncase -EBUSY:\r\nreturn VM_FAULT_NOPAGE;\r\ncase -ENOMEM:\r\nreturn VM_FAULT_OOM;\r\ndefault:\r\nreturn VM_FAULT_SIGBUS;\r\n}\r\n}\r\nstatic size_t roundup_gem_size(size_t size)\r\n{\r\nreturn roundup(size, PAGE_SIZE);\r\n}\r\nvoid armada_gem_free_object(struct drm_gem_object *obj)\r\n{\r\nstruct armada_gem_object *dobj = drm_to_armada_gem(obj);\r\nDRM_DEBUG_DRIVER("release obj %p\n", dobj);\r\ndrm_gem_free_mmap_offset(&dobj->obj);\r\nif (dobj->page) {\r\nunsigned int order = get_order(dobj->obj.size);\r\n__free_pages(dobj->page, order);\r\n} else if (dobj->linear) {\r\ndrm_mm_remove_node(dobj->linear);\r\nkfree(dobj->linear);\r\nif (dobj->addr)\r\niounmap(dobj->addr);\r\n}\r\nif (dobj->obj.import_attach) {\r\nif (dobj->sgt)\r\ndma_buf_unmap_attachment(dobj->obj.import_attach,\r\ndobj->sgt, DMA_TO_DEVICE);\r\ndrm_prime_gem_destroy(&dobj->obj, NULL);\r\n}\r\ndrm_gem_object_release(&dobj->obj);\r\nkfree(dobj);\r\n}\r\nint\r\narmada_gem_linear_back(struct drm_device *dev, struct armada_gem_object *obj)\r\n{\r\nstruct armada_private *priv = dev->dev_private;\r\nsize_t size = obj->obj.size;\r\nif (obj->page || obj->linear)\r\nreturn 0;\r\nif (size <= 8192) {\r\nunsigned int order = get_order(size);\r\nstruct page *p = alloc_pages(GFP_KERNEL, order);\r\nif (p) {\r\nobj->addr = page_address(p);\r\nobj->phys_addr = page_to_phys(p);\r\nobj->page = p;\r\nmemset(obj->addr, 0, PAGE_ALIGN(size));\r\n}\r\n}\r\nif (!obj->page) {\r\nstruct drm_mm_node *node;\r\nunsigned align = min_t(unsigned, size, SZ_2M);\r\nvoid __iomem *ptr;\r\nint ret;\r\nnode = kzalloc(sizeof(*node), GFP_KERNEL);\r\nif (!node)\r\nreturn -ENOSPC;\r\nmutex_lock(&dev->struct_mutex);\r\nret = drm_mm_insert_node(&priv->linear, node, size, align,\r\nDRM_MM_SEARCH_DEFAULT);\r\nmutex_unlock(&dev->struct_mutex);\r\nif (ret) {\r\nkfree(node);\r\nreturn ret;\r\n}\r\nobj->linear = node;\r\nptr = ioremap_wc(obj->linear->start, size);\r\nif (!ptr) {\r\nmutex_lock(&dev->struct_mutex);\r\ndrm_mm_remove_node(obj->linear);\r\nmutex_unlock(&dev->struct_mutex);\r\nkfree(obj->linear);\r\nobj->linear = NULL;\r\nreturn -ENOMEM;\r\n}\r\nmemset_io(ptr, 0, size);\r\niounmap(ptr);\r\nobj->phys_addr = obj->linear->start;\r\nobj->dev_addr = obj->linear->start;\r\n}\r\nDRM_DEBUG_DRIVER("obj %p phys %#llx dev %#llx\n", obj,\r\n(unsigned long long)obj->phys_addr,\r\n(unsigned long long)obj->dev_addr);\r\nreturn 0;\r\n}\r\nvoid *\r\narmada_gem_map_object(struct drm_device *dev, struct armada_gem_object *dobj)\r\n{\r\nif (!dobj->addr && dobj->linear)\r\ndobj->addr = ioremap_wc(dobj->phys_addr, dobj->obj.size);\r\nreturn dobj->addr;\r\n}\r\nstruct armada_gem_object *\r\narmada_gem_alloc_private_object(struct drm_device *dev, size_t size)\r\n{\r\nstruct armada_gem_object *obj;\r\nsize = roundup_gem_size(size);\r\nobj = kzalloc(sizeof(*obj), GFP_KERNEL);\r\nif (!obj)\r\nreturn NULL;\r\ndrm_gem_private_object_init(dev, &obj->obj, size);\r\nobj->dev_addr = DMA_ERROR_CODE;\r\nDRM_DEBUG_DRIVER("alloc private obj %p size %zu\n", obj, size);\r\nreturn obj;\r\n}\r\nstruct armada_gem_object *armada_gem_alloc_object(struct drm_device *dev,\r\nsize_t size)\r\n{\r\nstruct armada_gem_object *obj;\r\nstruct address_space *mapping;\r\nsize = roundup_gem_size(size);\r\nobj = kzalloc(sizeof(*obj), GFP_KERNEL);\r\nif (!obj)\r\nreturn NULL;\r\nif (drm_gem_object_init(dev, &obj->obj, size)) {\r\nkfree(obj);\r\nreturn NULL;\r\n}\r\nobj->dev_addr = DMA_ERROR_CODE;\r\nmapping = file_inode(obj->obj.filp)->i_mapping;\r\nmapping_set_gfp_mask(mapping, GFP_HIGHUSER | __GFP_RECLAIMABLE);\r\nDRM_DEBUG_DRIVER("alloc obj %p size %zu\n", obj, size);\r\nreturn obj;\r\n}\r\nint armada_gem_dumb_create(struct drm_file *file, struct drm_device *dev,\r\nstruct drm_mode_create_dumb *args)\r\n{\r\nstruct armada_gem_object *dobj;\r\nu32 handle;\r\nsize_t size;\r\nint ret;\r\nargs->pitch = armada_pitch(args->width, args->bpp);\r\nargs->size = size = args->pitch * args->height;\r\ndobj = armada_gem_alloc_private_object(dev, size);\r\nif (dobj == NULL)\r\nreturn -ENOMEM;\r\nret = armada_gem_linear_back(dev, dobj);\r\nif (ret)\r\ngoto err;\r\nret = drm_gem_handle_create(file, &dobj->obj, &handle);\r\nif (ret)\r\ngoto err;\r\nargs->handle = handle;\r\nDRM_DEBUG_DRIVER("obj %p size %zu handle %#x\n", dobj, size, handle);\r\nerr:\r\ndrm_gem_object_unreference_unlocked(&dobj->obj);\r\nreturn ret;\r\n}\r\nint armada_gem_dumb_map_offset(struct drm_file *file, struct drm_device *dev,\r\nuint32_t handle, uint64_t *offset)\r\n{\r\nstruct armada_gem_object *obj;\r\nint ret = 0;\r\nmutex_lock(&dev->struct_mutex);\r\nobj = armada_gem_object_lookup(dev, file, handle);\r\nif (!obj) {\r\nDRM_ERROR("failed to lookup gem object\n");\r\nret = -EINVAL;\r\ngoto err_unlock;\r\n}\r\nif (obj->obj.import_attach) {\r\nret = -EINVAL;\r\ngoto err_unlock;\r\n}\r\nret = drm_gem_create_mmap_offset(&obj->obj);\r\nif (ret == 0) {\r\n*offset = drm_vma_node_offset_addr(&obj->obj.vma_node);\r\nDRM_DEBUG_DRIVER("handle %#x offset %llx\n", handle, *offset);\r\n}\r\ndrm_gem_object_unreference(&obj->obj);\r\nerr_unlock:\r\nmutex_unlock(&dev->struct_mutex);\r\nreturn ret;\r\n}\r\nint armada_gem_dumb_destroy(struct drm_file *file, struct drm_device *dev,\r\nuint32_t handle)\r\n{\r\nreturn drm_gem_handle_delete(file, handle);\r\n}\r\nint armada_gem_create_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_armada_gem_create *args = data;\r\nstruct armada_gem_object *dobj;\r\nsize_t size;\r\nu32 handle;\r\nint ret;\r\nif (args->size == 0)\r\nreturn -ENOMEM;\r\nsize = args->size;\r\ndobj = armada_gem_alloc_object(dev, size);\r\nif (dobj == NULL)\r\nreturn -ENOMEM;\r\nret = drm_gem_handle_create(file, &dobj->obj, &handle);\r\nif (ret)\r\ngoto err;\r\nargs->handle = handle;\r\nDRM_DEBUG_DRIVER("obj %p size %zu handle %#x\n", dobj, size, handle);\r\nerr:\r\ndrm_gem_object_unreference_unlocked(&dobj->obj);\r\nreturn ret;\r\n}\r\nint armada_gem_mmap_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_armada_gem_mmap *args = data;\r\nstruct armada_gem_object *dobj;\r\nunsigned long addr;\r\ndobj = armada_gem_object_lookup(dev, file, args->handle);\r\nif (dobj == NULL)\r\nreturn -ENOENT;\r\nif (!dobj->obj.filp) {\r\ndrm_gem_object_unreference(&dobj->obj);\r\nreturn -EINVAL;\r\n}\r\naddr = vm_mmap(dobj->obj.filp, 0, args->size, PROT_READ | PROT_WRITE,\r\nMAP_SHARED, args->offset);\r\ndrm_gem_object_unreference(&dobj->obj);\r\nif (IS_ERR_VALUE(addr))\r\nreturn addr;\r\nargs->addr = addr;\r\nreturn 0;\r\n}\r\nint armada_gem_pwrite_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file)\r\n{\r\nstruct drm_armada_gem_pwrite *args = data;\r\nstruct armada_gem_object *dobj;\r\nchar __user *ptr;\r\nint ret;\r\nDRM_DEBUG_DRIVER("handle %u off %u size %u ptr 0x%llx\n",\r\nargs->handle, args->offset, args->size, args->ptr);\r\nif (args->size == 0)\r\nreturn 0;\r\nptr = (char __user *)(uintptr_t)args->ptr;\r\nif (!access_ok(VERIFY_READ, ptr, args->size))\r\nreturn -EFAULT;\r\nret = fault_in_multipages_readable(ptr, args->size);\r\nif (ret)\r\nreturn ret;\r\ndobj = armada_gem_object_lookup(dev, file, args->handle);\r\nif (dobj == NULL)\r\nreturn -ENOENT;\r\nif (!dobj->addr)\r\nreturn -EINVAL;\r\nif (args->offset > dobj->obj.size ||\r\nargs->size > dobj->obj.size - args->offset) {\r\nDRM_ERROR("invalid size: object size %u\n", dobj->obj.size);\r\nret = -EINVAL;\r\ngoto unref;\r\n}\r\nif (copy_from_user(dobj->addr + args->offset, ptr, args->size)) {\r\nret = -EFAULT;\r\n} else if (dobj->update) {\r\ndobj->update(dobj->update_data);\r\nret = 0;\r\n}\r\nunref:\r\ndrm_gem_object_unreference_unlocked(&dobj->obj);\r\nreturn ret;\r\n}\r\nstruct sg_table *\r\narmada_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,\r\nenum dma_data_direction dir)\r\n{\r\nstruct drm_gem_object *obj = attach->dmabuf->priv;\r\nstruct armada_gem_object *dobj = drm_to_armada_gem(obj);\r\nstruct scatterlist *sg;\r\nstruct sg_table *sgt;\r\nint i, num;\r\nsgt = kmalloc(sizeof(*sgt), GFP_KERNEL);\r\nif (!sgt)\r\nreturn NULL;\r\nif (dobj->obj.filp) {\r\nstruct address_space *mapping;\r\nint count;\r\ncount = dobj->obj.size / PAGE_SIZE;\r\nif (sg_alloc_table(sgt, count, GFP_KERNEL))\r\ngoto free_sgt;\r\nmapping = file_inode(dobj->obj.filp)->i_mapping;\r\nfor_each_sg(sgt->sgl, sg, count, i) {\r\nstruct page *page;\r\npage = shmem_read_mapping_page(mapping, i);\r\nif (IS_ERR(page)) {\r\nnum = i;\r\ngoto release;\r\n}\r\nsg_set_page(sg, page, PAGE_SIZE, 0);\r\n}\r\nif (dma_map_sg(attach->dev, sgt->sgl, sgt->nents, dir) == 0) {\r\nnum = sgt->nents;\r\ngoto release;\r\n}\r\n} else if (dobj->page) {\r\nif (sg_alloc_table(sgt, 1, GFP_KERNEL))\r\ngoto free_sgt;\r\nsg_set_page(sgt->sgl, dobj->page, dobj->obj.size, 0);\r\nif (dma_map_sg(attach->dev, sgt->sgl, sgt->nents, dir) == 0)\r\ngoto free_table;\r\n} else if (dobj->linear) {\r\nif (sg_alloc_table(sgt, 1, GFP_KERNEL))\r\ngoto free_sgt;\r\nsg_dma_address(sgt->sgl) = dobj->dev_addr;\r\nsg_dma_len(sgt->sgl) = dobj->obj.size;\r\n} else {\r\ngoto free_sgt;\r\n}\r\nreturn sgt;\r\nrelease:\r\nfor_each_sg(sgt->sgl, sg, num, i)\r\npage_cache_release(sg_page(sg));\r\nfree_table:\r\nsg_free_table(sgt);\r\nfree_sgt:\r\nkfree(sgt);\r\nreturn NULL;\r\n}\r\nstatic void armada_gem_prime_unmap_dma_buf(struct dma_buf_attachment *attach,\r\nstruct sg_table *sgt, enum dma_data_direction dir)\r\n{\r\nstruct drm_gem_object *obj = attach->dmabuf->priv;\r\nstruct armada_gem_object *dobj = drm_to_armada_gem(obj);\r\nint i;\r\nif (!dobj->linear)\r\ndma_unmap_sg(attach->dev, sgt->sgl, sgt->nents, dir);\r\nif (dobj->obj.filp) {\r\nstruct scatterlist *sg;\r\nfor_each_sg(sgt->sgl, sg, sgt->nents, i)\r\npage_cache_release(sg_page(sg));\r\n}\r\nsg_free_table(sgt);\r\nkfree(sgt);\r\n}\r\nstatic void *armada_gem_dmabuf_no_kmap(struct dma_buf *buf, unsigned long n)\r\n{\r\nreturn NULL;\r\n}\r\nstatic void\r\narmada_gem_dmabuf_no_kunmap(struct dma_buf *buf, unsigned long n, void *addr)\r\n{\r\n}\r\nstatic int\r\narmada_gem_dmabuf_mmap(struct dma_buf *buf, struct vm_area_struct *vma)\r\n{\r\nreturn -EINVAL;\r\n}\r\nstruct dma_buf *\r\narmada_gem_prime_export(struct drm_device *dev, struct drm_gem_object *obj,\r\nint flags)\r\n{\r\nDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\r\nexp_info.ops = &armada_gem_prime_dmabuf_ops;\r\nexp_info.size = obj->size;\r\nexp_info.flags = O_RDWR;\r\nexp_info.priv = obj;\r\nreturn dma_buf_export(&exp_info);\r\n}\r\nstruct drm_gem_object *\r\narmada_gem_prime_import(struct drm_device *dev, struct dma_buf *buf)\r\n{\r\nstruct dma_buf_attachment *attach;\r\nstruct armada_gem_object *dobj;\r\nif (buf->ops == &armada_gem_prime_dmabuf_ops) {\r\nstruct drm_gem_object *obj = buf->priv;\r\nif (obj->dev == dev) {\r\ndrm_gem_object_reference(obj);\r\nreturn obj;\r\n}\r\n}\r\nattach = dma_buf_attach(buf, dev->dev);\r\nif (IS_ERR(attach))\r\nreturn ERR_CAST(attach);\r\ndobj = armada_gem_alloc_private_object(dev, buf->size);\r\nif (!dobj) {\r\ndma_buf_detach(buf, attach);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\ndobj->obj.import_attach = attach;\r\nget_dma_buf(buf);\r\nreturn &dobj->obj;\r\n}\r\nint armada_gem_map_import(struct armada_gem_object *dobj)\r\n{\r\nint ret;\r\ndobj->sgt = dma_buf_map_attachment(dobj->obj.import_attach,\r\nDMA_TO_DEVICE);\r\nif (!dobj->sgt) {\r\nDRM_ERROR("dma_buf_map_attachment() returned NULL\n");\r\nreturn -EINVAL;\r\n}\r\nif (IS_ERR(dobj->sgt)) {\r\nret = PTR_ERR(dobj->sgt);\r\ndobj->sgt = NULL;\r\nDRM_ERROR("dma_buf_map_attachment() error: %d\n", ret);\r\nreturn ret;\r\n}\r\nif (dobj->sgt->nents > 1) {\r\nDRM_ERROR("dma_buf_map_attachment() returned an (unsupported) scattered list\n");\r\nreturn -EINVAL;\r\n}\r\nif (sg_dma_len(dobj->sgt->sgl) < dobj->obj.size) {\r\nDRM_ERROR("dma_buf_map_attachment() returned a small buffer\n");\r\nreturn -EINVAL;\r\n}\r\ndobj->dev_addr = sg_dma_address(dobj->sgt->sgl);\r\nreturn 0;\r\n}
