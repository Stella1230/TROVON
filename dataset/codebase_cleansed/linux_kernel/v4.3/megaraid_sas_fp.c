u32 mega_mod64(u64 dividend, u32 divisor)\r\n{\r\nu64 d;\r\nu32 remainder;\r\nif (!divisor)\r\nprintk(KERN_ERR "megasas : DIVISOR is zero, in div fn\n");\r\nd = dividend;\r\nremainder = do_div(d, divisor);\r\nreturn remainder;\r\n}\r\nu64 mega_div64_32(uint64_t dividend, uint32_t divisor)\r\n{\r\nu32 remainder;\r\nu64 d;\r\nif (!divisor)\r\nprintk(KERN_ERR "megasas : DIVISOR is zero in mod fn\n");\r\nd = dividend;\r\nremainder = do_div(d, divisor);\r\nreturn d;\r\n}\r\nstruct MR_LD_RAID *MR_LdRaidGet(u32 ld, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn &map->raidMap.ldSpanMap[ld].ldRaid;\r\n}\r\nstatic struct MR_SPAN_BLOCK_INFO *MR_LdSpanInfoGet(u32 ld,\r\nstruct MR_DRV_RAID_MAP_ALL\r\n*map)\r\n{\r\nreturn &map->raidMap.ldSpanMap[ld].spanBlock[0];\r\n}\r\nstatic u8 MR_LdDataArmGet(u32 ld, u32 armIdx, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn map->raidMap.ldSpanMap[ld].dataArmMap[armIdx];\r\n}\r\nu16 MR_ArPdGet(u32 ar, u32 arm, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn le16_to_cpu(map->raidMap.arMapInfo[ar].pd[arm]);\r\n}\r\nu16 MR_LdSpanArrayGet(u32 ld, u32 span, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn le16_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].span.arrayRef);\r\n}\r\n__le16 MR_PdDevHandleGet(u32 pd, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn map->raidMap.devHndlInfo[pd].curDevHdl;\r\n}\r\nu16 MR_GetLDTgtId(u32 ld, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn le16_to_cpu(map->raidMap.ldSpanMap[ld].ldRaid.targetId);\r\n}\r\nu8 MR_TargetIdToLdGet(u32 ldTgtId, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn map->raidMap.ldTgtIdToLd[ldTgtId];\r\n}\r\nstatic struct MR_LD_SPAN *MR_LdSpanPtrGet(u32 ld, u32 span,\r\nstruct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nreturn &map->raidMap.ldSpanMap[ld].spanBlock[span].span;\r\n}\r\nvoid MR_PopulateDrvRaidMap(struct megasas_instance *instance)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_FW_RAID_MAP_ALL *fw_map_old = NULL;\r\nstruct MR_FW_RAID_MAP *pFwRaidMap = NULL;\r\nint i;\r\nu16 ld_count;\r\nstruct MR_DRV_RAID_MAP_ALL *drv_map =\r\nfusion->ld_drv_map[(instance->map_id & 1)];\r\nstruct MR_DRV_RAID_MAP *pDrvRaidMap = &drv_map->raidMap;\r\nif (instance->supportmax256vd) {\r\nmemcpy(fusion->ld_drv_map[instance->map_id & 1],\r\nfusion->ld_map[instance->map_id & 1],\r\nfusion->current_map_sz);\r\npDrvRaidMap->totalSize =\r\ncpu_to_le32(sizeof(struct MR_FW_RAID_MAP_EXT));\r\n} else {\r\nfw_map_old = (struct MR_FW_RAID_MAP_ALL *)\r\nfusion->ld_map[(instance->map_id & 1)];\r\npFwRaidMap = &fw_map_old->raidMap;\r\nld_count = (u16)le32_to_cpu(pFwRaidMap->ldCount);\r\n#if VD_EXT_DEBUG\r\nfor (i = 0; i < ld_count; i++) {\r\ndev_dbg(&instance->pdev->dev, "(%d) :Index 0x%x "\r\n"Target Id 0x%x Seq Num 0x%x Size 0/%llx\n",\r\ninstance->unique_id, i,\r\nfw_map_old->raidMap.ldSpanMap[i].ldRaid.targetId,\r\nfw_map_old->raidMap.ldSpanMap[i].ldRaid.seqNum,\r\nfw_map_old->raidMap.ldSpanMap[i].ldRaid.size);\r\n}\r\n#endif\r\nmemset(drv_map, 0, fusion->drv_map_sz);\r\npDrvRaidMap->totalSize = pFwRaidMap->totalSize;\r\npDrvRaidMap->ldCount = (__le16)cpu_to_le16(ld_count);\r\npDrvRaidMap->fpPdIoTimeoutSec = pFwRaidMap->fpPdIoTimeoutSec;\r\nfor (i = 0; i < MAX_RAIDMAP_LOGICAL_DRIVES + MAX_RAIDMAP_VIEWS; i++)\r\npDrvRaidMap->ldTgtIdToLd[i] =\r\n(u8)pFwRaidMap->ldTgtIdToLd[i];\r\nfor (i = (MAX_RAIDMAP_LOGICAL_DRIVES + MAX_RAIDMAP_VIEWS);\r\ni < MAX_LOGICAL_DRIVES_EXT; i++)\r\npDrvRaidMap->ldTgtIdToLd[i] = 0xff;\r\nfor (i = 0; i < ld_count; i++) {\r\npDrvRaidMap->ldSpanMap[i] = pFwRaidMap->ldSpanMap[i];\r\n#if VD_EXT_DEBUG\r\ndev_dbg(&instance->pdev->dev,\r\n"pFwRaidMap->ldSpanMap[%d].ldRaid.targetId 0x%x "\r\n"pFwRaidMap->ldSpanMap[%d].ldRaid.seqNum 0x%x "\r\n"size 0x%x\n", i, i,\r\npFwRaidMap->ldSpanMap[i].ldRaid.targetId,\r\npFwRaidMap->ldSpanMap[i].ldRaid.seqNum,\r\n(u32)pFwRaidMap->ldSpanMap[i].ldRaid.rowSize);\r\ndev_dbg(&instance->pdev->dev,\r\n"pDrvRaidMap->ldSpanMap[%d].ldRaid.targetId 0x%x "\r\n"pDrvRaidMap->ldSpanMap[%d].ldRaid.seqNum 0x%x "\r\n"size 0x%x\n", i, i,\r\npDrvRaidMap->ldSpanMap[i].ldRaid.targetId,\r\npDrvRaidMap->ldSpanMap[i].ldRaid.seqNum,\r\n(u32)pDrvRaidMap->ldSpanMap[i].ldRaid.rowSize);\r\ndev_dbg(&instance->pdev->dev, "Driver raid map all %p "\r\n"raid map %p LD RAID MAP %p/%p\n", drv_map,\r\npDrvRaidMap, &pFwRaidMap->ldSpanMap[i].ldRaid,\r\n&pDrvRaidMap->ldSpanMap[i].ldRaid);\r\n#endif\r\n}\r\nmemcpy(pDrvRaidMap->arMapInfo, pFwRaidMap->arMapInfo,\r\nsizeof(struct MR_ARRAY_INFO) * MAX_RAIDMAP_ARRAYS);\r\nmemcpy(pDrvRaidMap->devHndlInfo, pFwRaidMap->devHndlInfo,\r\nsizeof(struct MR_DEV_HANDLE_INFO) *\r\nMAX_RAIDMAP_PHYSICAL_DEVICES);\r\n}\r\n}\r\nu8 MR_ValidateMapInfo(struct megasas_instance *instance)\r\n{\r\nstruct fusion_context *fusion;\r\nstruct MR_DRV_RAID_MAP_ALL *drv_map;\r\nstruct MR_DRV_RAID_MAP *pDrvRaidMap;\r\nstruct LD_LOAD_BALANCE_INFO *lbInfo;\r\nPLD_SPAN_INFO ldSpanInfo;\r\nstruct MR_LD_RAID *raid;\r\nu16 ldCount, num_lds;\r\nu16 ld;\r\nu32 expected_size;\r\nMR_PopulateDrvRaidMap(instance);\r\nfusion = instance->ctrl_context;\r\ndrv_map = fusion->ld_drv_map[(instance->map_id & 1)];\r\npDrvRaidMap = &drv_map->raidMap;\r\nlbInfo = fusion->load_balance_info;\r\nldSpanInfo = fusion->log_to_span;\r\nif (instance->supportmax256vd)\r\nexpected_size = sizeof(struct MR_FW_RAID_MAP_EXT);\r\nelse\r\nexpected_size =\r\n(sizeof(struct MR_FW_RAID_MAP) - sizeof(struct MR_LD_SPAN_MAP) +\r\n(sizeof(struct MR_LD_SPAN_MAP) * le16_to_cpu(pDrvRaidMap->ldCount)));\r\nif (le32_to_cpu(pDrvRaidMap->totalSize) != expected_size) {\r\ndev_err(&instance->pdev->dev, "map info structure size 0x%x is not matching with ld count\n",\r\n(unsigned int) expected_size);\r\ndev_err(&instance->pdev->dev, "megasas: span map %x, pDrvRaidMap->totalSize : %x\n",\r\n(unsigned int)sizeof(struct MR_LD_SPAN_MAP),\r\nle32_to_cpu(pDrvRaidMap->totalSize));\r\nreturn 0;\r\n}\r\nif (instance->UnevenSpanSupport)\r\nmr_update_span_set(drv_map, ldSpanInfo);\r\nmr_update_load_balance_params(drv_map, lbInfo);\r\nnum_lds = le16_to_cpu(drv_map->raidMap.ldCount);\r\nfor (ldCount = 0; ldCount < num_lds; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, drv_map);\r\nraid = MR_LdRaidGet(ld, drv_map);\r\nle32_to_cpus((u32 *)&raid->capability);\r\n}\r\nreturn 1;\r\n}\r\nu32 MR_GetSpanBlock(u32 ld, u64 row, u64 *span_blk,\r\nstruct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_SPAN_BLOCK_INFO *pSpanBlock = MR_LdSpanInfoGet(ld, map);\r\nstruct MR_QUAD_ELEMENT *quad;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 span, j;\r\nfor (span = 0; span < raid->spanDepth; span++, pSpanBlock++) {\r\nfor (j = 0; j < le32_to_cpu(pSpanBlock->block_span_info.noElements); j++) {\r\nquad = &pSpanBlock->block_span_info.quad[j];\r\nif (le32_to_cpu(quad->diff) == 0)\r\nreturn SPAN_INVALID;\r\nif (le64_to_cpu(quad->logStart) <= row && row <=\r\nle64_to_cpu(quad->logEnd) && (mega_mod64(row - le64_to_cpu(quad->logStart),\r\nle32_to_cpu(quad->diff))) == 0) {\r\nif (span_blk != NULL) {\r\nu64 blk, debugBlk;\r\nblk = mega_div64_32((row-le64_to_cpu(quad->logStart)), le32_to_cpu(quad->diff));\r\ndebugBlk = blk;\r\nblk = (blk + le64_to_cpu(quad->offsetInSpan)) << raid->stripeShift;\r\n*span_blk = blk;\r\n}\r\nreturn span;\r\n}\r\n}\r\n}\r\nreturn SPAN_INVALID;\r\n}\r\nstatic int getSpanInfo(struct MR_DRV_RAID_MAP_ALL *map,\r\nPLD_SPAN_INFO ldSpanInfo)\r\n{\r\nu8 span;\r\nu32 element;\r\nstruct MR_LD_RAID *raid;\r\nLD_SPAN_SET *span_set;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nint ldCount;\r\nu16 ld;\r\nfor (ldCount = 0; ldCount < MAX_LOGICAL_DRIVES_EXT; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, map);\r\nif (ld >= (MAX_LOGICAL_DRIVES_EXT - 1))\r\ncontinue;\r\nraid = MR_LdRaidGet(ld, map);\r\ndev_dbg(&instance->pdev->dev, "LD %x: span_depth=%x\n",\r\nld, raid->spanDepth);\r\nfor (span = 0; span < raid->spanDepth; span++)\r\ndev_dbg(&instance->pdev->dev, "Span=%x,"\r\n" number of quads=%x\n", span,\r\nle32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements));\r\nfor (element = 0; element < MAX_QUAD_DEPTH; element++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[element]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\ndev_dbg(&instance->pdev->dev, "Span Set %x:"\r\n"width=%x, diff=%x\n", element,\r\n(unsigned int)span_set->span_row_data_width,\r\n(unsigned int)span_set->diff);\r\ndev_dbg(&instance->pdev->dev, "logical LBA"\r\n"start=0x%08lx, end=0x%08lx\n",\r\n(long unsigned int)span_set->log_start_lba,\r\n(long unsigned int)span_set->log_end_lba);\r\ndev_dbg(&instance->pdev->dev, "span row start=0x%08lx,"\r\n" end=0x%08lx\n",\r\n(long unsigned int)span_set->span_row_start,\r\n(long unsigned int)span_set->span_row_end);\r\ndev_dbg(&instance->pdev->dev, "data row start=0x%08lx,"\r\n" end=0x%08lx\n",\r\n(long unsigned int)span_set->data_row_start,\r\n(long unsigned int)span_set->data_row_end);\r\ndev_dbg(&instance->pdev->dev, "data strip start=0x%08lx,"\r\n" end=0x%08lx\n",\r\n(long unsigned int)span_set->data_strip_start,\r\n(long unsigned int)span_set->data_strip_end);\r\nfor (span = 0; span < raid->spanDepth; span++) {\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >=\r\nelement + 1) {\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].block_span_info.\r\nquad[element];\r\ndev_dbg(&instance->pdev->dev, "Span=%x,"\r\n"Quad=%x, diff=%x\n", span,\r\nelement, le32_to_cpu(quad->diff));\r\ndev_dbg(&instance->pdev->dev,\r\n"offset_in_span=0x%08lx\n",\r\n(long unsigned int)le64_to_cpu(quad->offsetInSpan));\r\ndev_dbg(&instance->pdev->dev,\r\n"logical start=0x%08lx, end=0x%08lx\n",\r\n(long unsigned int)le64_to_cpu(quad->logStart),\r\n(long unsigned int)le64_to_cpu(quad->logEnd));\r\n}\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nu32 mr_spanset_get_span_block(struct megasas_instance *instance,\r\nu32 ld, u64 row, u64 *span_blk, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nu32 span, info;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nfor (info = 0; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (row > span_set->data_row_end)\r\ncontinue;\r\nfor (span = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >= info+1) {\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].\r\nblock_span_info.quad[info];\r\nif (le32_to_cpu(quad->diff) == 0)\r\nreturn SPAN_INVALID;\r\nif (le64_to_cpu(quad->logStart) <= row &&\r\nrow <= le64_to_cpu(quad->logEnd) &&\r\n(mega_mod64(row - le64_to_cpu(quad->logStart),\r\nle32_to_cpu(quad->diff))) == 0) {\r\nif (span_blk != NULL) {\r\nu64 blk;\r\nblk = mega_div64_32\r\n((row - le64_to_cpu(quad->logStart)),\r\nle32_to_cpu(quad->diff));\r\nblk = (blk + le64_to_cpu(quad->offsetInSpan))\r\n<< raid->stripeShift;\r\n*span_blk = blk;\r\n}\r\nreturn span;\r\n}\r\n}\r\n}\r\nreturn SPAN_INVALID;\r\n}\r\nstatic u64 get_row_from_strip(struct megasas_instance *instance,\r\nu32 ld, u64 strip, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nu32 info, strip_offset, span, span_offset;\r\nu64 span_set_Strip, span_set_Row, retval;\r\nfor (info = 0; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (strip > span_set->data_strip_end)\r\ncontinue;\r\nspan_set_Strip = strip - span_set->data_strip_start;\r\nstrip_offset = mega_mod64(span_set_Strip,\r\nspan_set->span_row_data_width);\r\nspan_set_Row = mega_div64_32(span_set_Strip,\r\nspan_set->span_row_data_width) * span_set->diff;\r\nfor (span = 0, span_offset = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >= info+1) {\r\nif (strip_offset >=\r\nspan_set->strip_offset[span])\r\nspan_offset++;\r\nelse\r\nbreak;\r\n}\r\n#if SPAN_DEBUG\r\ndev_info(&instance->pdev->dev, "Strip 0x%llx,"\r\n"span_set_Strip 0x%llx, span_set_Row 0x%llx"\r\n"data width 0x%llx span offset 0x%x\n", strip,\r\n(unsigned long long)span_set_Strip,\r\n(unsigned long long)span_set_Row,\r\n(unsigned long long)span_set->span_row_data_width,\r\nspan_offset);\r\ndev_info(&instance->pdev->dev, "For strip 0x%llx"\r\n"row is 0x%llx\n", strip,\r\n(unsigned long long) span_set->data_row_start +\r\n(unsigned long long) span_set_Row + (span_offset - 1));\r\n#endif\r\nretval = (span_set->data_row_start + span_set_Row +\r\n(span_offset - 1));\r\nreturn retval;\r\n}\r\nreturn -1LLU;\r\n}\r\nstatic u64 get_strip_from_row(struct megasas_instance *instance,\r\nu32 ld, u64 row, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nu32 span, info;\r\nu64 strip;\r\nfor (info = 0; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (row > span_set->data_row_end)\r\ncontinue;\r\nfor (span = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >= info+1) {\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].block_span_info.quad[info];\r\nif (le64_to_cpu(quad->logStart) <= row &&\r\nrow <= le64_to_cpu(quad->logEnd) &&\r\nmega_mod64((row - le64_to_cpu(quad->logStart)),\r\nle32_to_cpu(quad->diff)) == 0) {\r\nstrip = mega_div64_32\r\n(((row - span_set->data_row_start)\r\n- le64_to_cpu(quad->logStart)),\r\nle32_to_cpu(quad->diff));\r\nstrip *= span_set->span_row_data_width;\r\nstrip += span_set->data_strip_start;\r\nstrip += span_set->strip_offset[span];\r\nreturn strip;\r\n}\r\n}\r\n}\r\ndev_err(&instance->pdev->dev, "get_strip_from_row"\r\n"returns invalid strip for ld=%x, row=%lx\n",\r\nld, (long unsigned int)row);\r\nreturn -1;\r\n}\r\nstatic u32 get_arm_from_strip(struct megasas_instance *instance,\r\nu32 ld, u64 strip, struct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nu32 info, strip_offset, span, span_offset, retval;\r\nfor (info = 0 ; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (strip > span_set->data_strip_end)\r\ncontinue;\r\nstrip_offset = (uint)mega_mod64\r\n((strip - span_set->data_strip_start),\r\nspan_set->span_row_data_width);\r\nfor (span = 0, span_offset = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >= info+1) {\r\nif (strip_offset >=\r\nspan_set->strip_offset[span])\r\nspan_offset =\r\nspan_set->strip_offset[span];\r\nelse\r\nbreak;\r\n}\r\n#if SPAN_DEBUG\r\ndev_info(&instance->pdev->dev, "get_arm_from_strip:"\r\n"for ld=0x%x strip=0x%lx arm is 0x%x\n", ld,\r\n(long unsigned int)strip, (strip_offset - span_offset));\r\n#endif\r\nretval = (strip_offset - span_offset);\r\nreturn retval;\r\n}\r\ndev_err(&instance->pdev->dev, "get_arm_from_strip"\r\n"returns invalid arm for ld=%x strip=%lx\n",\r\nld, (long unsigned int)strip);\r\nreturn -1;\r\n}\r\nu8 get_arm(struct megasas_instance *instance, u32 ld, u8 span, u64 stripe,\r\nstruct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 arm = 0;\r\nswitch (raid->level) {\r\ncase 0:\r\ncase 5:\r\ncase 6:\r\narm = mega_mod64(stripe, SPAN_ROW_SIZE(map, ld, span));\r\nbreak;\r\ncase 1:\r\narm = get_arm_from_strip(instance, ld, stripe, map);\r\nif (arm != -1U)\r\narm *= 2;\r\nbreak;\r\n}\r\nreturn arm;\r\n}\r\nstatic u8 mr_spanset_get_phy_params(struct megasas_instance *instance, u32 ld,\r\nu64 stripRow, u16 stripRef, struct IO_REQUEST_INFO *io_info,\r\nstruct RAID_CONTEXT *pRAID_Context,\r\nstruct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 pd, arRef;\r\nu8 physArm, span;\r\nu64 row;\r\nu8 retval = TRUE;\r\nu8 do_invader = 0;\r\nu64 *pdBlock = &io_info->pdBlock;\r\n__le16 *pDevHandle = &io_info->devHandle;\r\nu32 logArm, rowMod, armQ, arm;\r\nif ((instance->pdev->device == PCI_DEVICE_ID_LSI_INVADER ||\r\ninstance->pdev->device == PCI_DEVICE_ID_LSI_FURY))\r\ndo_invader = 1;\r\nrow = io_info->start_row;\r\nspan = io_info->start_span;\r\nif (raid->level == 6) {\r\nlogArm = get_arm_from_strip(instance, ld, stripRow, map);\r\nif (logArm == -1U)\r\nreturn FALSE;\r\nrowMod = mega_mod64(row, SPAN_ROW_SIZE(map, ld, span));\r\narmQ = SPAN_ROW_SIZE(map, ld, span) - 1 - rowMod;\r\narm = armQ + 1 + logArm;\r\nif (arm >= SPAN_ROW_SIZE(map, ld, span))\r\narm -= SPAN_ROW_SIZE(map, ld, span);\r\nphysArm = (u8)arm;\r\n} else\r\nphysArm = get_arm(instance, ld, span, stripRow, map);\r\nif (physArm == 0xFF)\r\nreturn FALSE;\r\narRef = MR_LdSpanArrayGet(ld, span, map);\r\npd = MR_ArPdGet(arRef, physArm, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\nelse {\r\n*pDevHandle = cpu_to_le16(MR_PD_INVALID);\r\nif ((raid->level >= 5) &&\r\n(!do_invader || (do_invader &&\r\n(raid->regTypeReqOnRead != REGION_TYPE_UNUSED))))\r\npRAID_Context->regLockFlags = REGION_TYPE_EXCLUSIVE;\r\nelse if (raid->level == 1) {\r\npd = MR_ArPdGet(arRef, physArm + 1, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\n}\r\n}\r\n*pdBlock += stripRef + le64_to_cpu(MR_LdSpanPtrGet(ld, span, map)->startBlk);\r\npRAID_Context->spanArm = (span << RAID_CTX_SPANARM_SPAN_SHIFT) |\r\nphysArm;\r\nio_info->span_arm = pRAID_Context->spanArm;\r\nreturn retval;\r\n}\r\nu8 MR_GetPhyParams(struct megasas_instance *instance, u32 ld, u64 stripRow,\r\nu16 stripRef, struct IO_REQUEST_INFO *io_info,\r\nstruct RAID_CONTEXT *pRAID_Context,\r\nstruct MR_DRV_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 pd, arRef;\r\nu8 physArm, span;\r\nu64 row;\r\nu8 retval = TRUE;\r\nu8 do_invader = 0;\r\nu64 *pdBlock = &io_info->pdBlock;\r\n__le16 *pDevHandle = &io_info->devHandle;\r\nif ((instance->pdev->device == PCI_DEVICE_ID_LSI_INVADER ||\r\ninstance->pdev->device == PCI_DEVICE_ID_LSI_FURY))\r\ndo_invader = 1;\r\nrow = mega_div64_32(stripRow, raid->rowDataSize);\r\nif (raid->level == 6) {\r\nu32 logArm = mega_mod64(stripRow, raid->rowDataSize);\r\nu32 rowMod, armQ, arm;\r\nif (raid->rowSize == 0)\r\nreturn FALSE;\r\nrowMod = mega_mod64(row, raid->rowSize);\r\narmQ = raid->rowSize-1-rowMod;\r\narm = armQ+1+logArm;\r\nif (arm >= raid->rowSize)\r\narm -= raid->rowSize;\r\nphysArm = (u8)arm;\r\n} else {\r\nif (raid->modFactor == 0)\r\nreturn FALSE;\r\nphysArm = MR_LdDataArmGet(ld, mega_mod64(stripRow,\r\nraid->modFactor),\r\nmap);\r\n}\r\nif (raid->spanDepth == 1) {\r\nspan = 0;\r\n*pdBlock = row << raid->stripeShift;\r\n} else {\r\nspan = (u8)MR_GetSpanBlock(ld, row, pdBlock, map);\r\nif (span == SPAN_INVALID)\r\nreturn FALSE;\r\n}\r\narRef = MR_LdSpanArrayGet(ld, span, map);\r\npd = MR_ArPdGet(arRef, physArm, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\nelse {\r\n*pDevHandle = cpu_to_le16(MR_PD_INVALID);\r\nif ((raid->level >= 5) &&\r\n(!do_invader || (do_invader &&\r\n(raid->regTypeReqOnRead != REGION_TYPE_UNUSED))))\r\npRAID_Context->regLockFlags = REGION_TYPE_EXCLUSIVE;\r\nelse if (raid->level == 1) {\r\npd = MR_ArPdGet(arRef, physArm + 1, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\n}\r\n}\r\n*pdBlock += stripRef + le64_to_cpu(MR_LdSpanPtrGet(ld, span, map)->startBlk);\r\npRAID_Context->spanArm = (span << RAID_CTX_SPANARM_SPAN_SHIFT) |\r\nphysArm;\r\nio_info->span_arm = pRAID_Context->spanArm;\r\nreturn retval;\r\n}\r\nu8\r\nMR_BuildRaidContext(struct megasas_instance *instance,\r\nstruct IO_REQUEST_INFO *io_info,\r\nstruct RAID_CONTEXT *pRAID_Context,\r\nstruct MR_DRV_RAID_MAP_ALL *map, u8 **raidLUN)\r\n{\r\nstruct MR_LD_RAID *raid;\r\nu32 ld, stripSize, stripe_mask;\r\nu64 endLba, endStrip, endRow, start_row, start_strip;\r\nu64 regStart;\r\nu32 regSize;\r\nu8 num_strips, numRows;\r\nu16 ref_in_start_stripe, ref_in_end_stripe;\r\nu64 ldStartBlock;\r\nu32 numBlocks, ldTgtId;\r\nu8 isRead;\r\nu8 retval = 0;\r\nu8 startlba_span = SPAN_INVALID;\r\nu64 *pdBlock = &io_info->pdBlock;\r\nldStartBlock = io_info->ldStartBlock;\r\nnumBlocks = io_info->numBlocks;\r\nldTgtId = io_info->ldTgtId;\r\nisRead = io_info->isRead;\r\nio_info->IoforUnevenSpan = 0;\r\nio_info->start_span = SPAN_INVALID;\r\nld = MR_TargetIdToLdGet(ldTgtId, map);\r\nraid = MR_LdRaidGet(ld, map);\r\nif (raid->rowDataSize == 0) {\r\nif (MR_LdSpanPtrGet(ld, 0, map)->spanRowDataSize == 0)\r\nreturn FALSE;\r\nelse if (instance->UnevenSpanSupport) {\r\nio_info->IoforUnevenSpan = 1;\r\n} else {\r\ndev_info(&instance->pdev->dev,\r\n"raid->rowDataSize is 0, but has SPAN[0]"\r\n"rowDataSize = 0x%0x,"\r\n"but there is _NO_ UnevenSpanSupport\n",\r\nMR_LdSpanPtrGet(ld, 0, map)->spanRowDataSize);\r\nreturn FALSE;\r\n}\r\n}\r\nstripSize = 1 << raid->stripeShift;\r\nstripe_mask = stripSize-1;\r\nstart_strip = ldStartBlock >> raid->stripeShift;\r\nref_in_start_stripe = (u16)(ldStartBlock & stripe_mask);\r\nendLba = ldStartBlock + numBlocks - 1;\r\nref_in_end_stripe = (u16)(endLba & stripe_mask);\r\nendStrip = endLba >> raid->stripeShift;\r\nnum_strips = (u8)(endStrip - start_strip + 1);\r\nif (io_info->IoforUnevenSpan) {\r\nstart_row = get_row_from_strip(instance, ld, start_strip, map);\r\nendRow = get_row_from_strip(instance, ld, endStrip, map);\r\nif (start_row == -1ULL || endRow == -1ULL) {\r\ndev_info(&instance->pdev->dev, "return from %s %d."\r\n"Send IO w/o region lock.\n",\r\n__func__, __LINE__);\r\nreturn FALSE;\r\n}\r\nif (raid->spanDepth == 1) {\r\nstartlba_span = 0;\r\n*pdBlock = start_row << raid->stripeShift;\r\n} else\r\nstartlba_span = (u8)mr_spanset_get_span_block(instance,\r\nld, start_row, pdBlock, map);\r\nif (startlba_span == SPAN_INVALID) {\r\ndev_info(&instance->pdev->dev, "return from %s %d"\r\n"for row 0x%llx,start strip %llx"\r\n"endSrip %llx\n", __func__, __LINE__,\r\n(unsigned long long)start_row,\r\n(unsigned long long)start_strip,\r\n(unsigned long long)endStrip);\r\nreturn FALSE;\r\n}\r\nio_info->start_span = startlba_span;\r\nio_info->start_row = start_row;\r\n#if SPAN_DEBUG\r\ndev_dbg(&instance->pdev->dev, "Check Span number from %s %d"\r\n"for row 0x%llx, start strip 0x%llx end strip 0x%llx"\r\n" span 0x%x\n", __func__, __LINE__,\r\n(unsigned long long)start_row,\r\n(unsigned long long)start_strip,\r\n(unsigned long long)endStrip, startlba_span);\r\ndev_dbg(&instance->pdev->dev, "start_row 0x%llx endRow 0x%llx"\r\n"Start span 0x%x\n", (unsigned long long)start_row,\r\n(unsigned long long)endRow, startlba_span);\r\n#endif\r\n} else {\r\nstart_row = mega_div64_32(start_strip, raid->rowDataSize);\r\nendRow = mega_div64_32(endStrip, raid->rowDataSize);\r\n}\r\nnumRows = (u8)(endRow - start_row + 1);\r\nregStart = start_row << raid->stripeShift;\r\nregSize = stripSize;\r\nif (raid->capability.fpCapable) {\r\nif (isRead)\r\nio_info->fpOkForIo = (raid->capability.fpReadCapable &&\r\n((num_strips == 1) ||\r\nraid->capability.\r\nfpReadAcrossStripe));\r\nelse\r\nio_info->fpOkForIo = (raid->capability.fpWriteCapable &&\r\n((num_strips == 1) ||\r\nraid->capability.\r\nfpWriteAcrossStripe));\r\n} else\r\nio_info->fpOkForIo = FALSE;\r\nif (numRows == 1) {\r\nif (num_strips == 1) {\r\nregStart += ref_in_start_stripe;\r\nregSize = numBlocks;\r\n}\r\n} else if (io_info->IoforUnevenSpan == 0) {\r\nif (start_strip == (start_row + 1) * raid->rowDataSize - 1) {\r\nregStart += ref_in_start_stripe;\r\nregSize = stripSize - ref_in_start_stripe;\r\n}\r\nif (numRows > 2)\r\nregSize += (numRows-2) << raid->stripeShift;\r\nif (endStrip == endRow*raid->rowDataSize)\r\nregSize += ref_in_end_stripe+1;\r\nelse\r\nregSize += stripSize;\r\n} else {\r\nif (start_strip == (get_strip_from_row(instance, ld, start_row, map) +\r\nSPAN_ROW_DATA_SIZE(map, ld, startlba_span) - 1)) {\r\nregStart += ref_in_start_stripe;\r\nregSize = stripSize - ref_in_start_stripe;\r\n}\r\nif (numRows > 2)\r\nregSize += (numRows-2) << raid->stripeShift;\r\nif (endStrip == get_strip_from_row(instance, ld, endRow, map))\r\nregSize += ref_in_end_stripe + 1;\r\nelse\r\nregSize += stripSize;\r\n}\r\npRAID_Context->timeoutValue =\r\ncpu_to_le16(raid->fpIoTimeoutForLd ?\r\nraid->fpIoTimeoutForLd :\r\nmap->raidMap.fpPdIoTimeoutSec);\r\nif ((instance->pdev->device == PCI_DEVICE_ID_LSI_INVADER) ||\r\n(instance->pdev->device == PCI_DEVICE_ID_LSI_FURY))\r\npRAID_Context->regLockFlags = (isRead) ?\r\nraid->regTypeReqOnRead : raid->regTypeReqOnWrite;\r\nelse\r\npRAID_Context->regLockFlags = (isRead) ?\r\nREGION_TYPE_SHARED_READ : raid->regTypeReqOnWrite;\r\npRAID_Context->VirtualDiskTgtId = raid->targetId;\r\npRAID_Context->regLockRowLBA = cpu_to_le64(regStart);\r\npRAID_Context->regLockLength = cpu_to_le32(regSize);\r\npRAID_Context->configSeqNum = raid->seqNum;\r\n*raidLUN = raid->LUN;\r\nif (io_info->fpOkForIo) {\r\nretval = io_info->IoforUnevenSpan ?\r\nmr_spanset_get_phy_params(instance, ld,\r\nstart_strip, ref_in_start_stripe,\r\nio_info, pRAID_Context, map) :\r\nMR_GetPhyParams(instance, ld, start_strip,\r\nref_in_start_stripe, io_info,\r\npRAID_Context, map);\r\nif (io_info->devHandle == cpu_to_le16(MR_PD_INVALID))\r\nio_info->fpOkForIo = FALSE;\r\nreturn retval;\r\n} else if (isRead) {\r\nuint stripIdx;\r\nfor (stripIdx = 0; stripIdx < num_strips; stripIdx++) {\r\nretval = io_info->IoforUnevenSpan ?\r\nmr_spanset_get_phy_params(instance, ld,\r\nstart_strip + stripIdx,\r\nref_in_start_stripe, io_info,\r\npRAID_Context, map) :\r\nMR_GetPhyParams(instance, ld,\r\nstart_strip + stripIdx, ref_in_start_stripe,\r\nio_info, pRAID_Context, map);\r\nif (!retval)\r\nreturn TRUE;\r\n}\r\n}\r\n#if SPAN_DEBUG\r\nif (io_info->IoforUnevenSpan)\r\nget_arm_from_strip(instance, ld, start_strip, map);\r\n#endif\r\nreturn TRUE;\r\n}\r\nvoid mr_update_span_set(struct MR_DRV_RAID_MAP_ALL *map,\r\nPLD_SPAN_INFO ldSpanInfo)\r\n{\r\nu8 span, count;\r\nu32 element, span_row_width;\r\nu64 span_row;\r\nstruct MR_LD_RAID *raid;\r\nLD_SPAN_SET *span_set, *span_set_prev;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nint ldCount;\r\nu16 ld;\r\nfor (ldCount = 0; ldCount < MAX_LOGICAL_DRIVES_EXT; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, map);\r\nif (ld >= (MAX_LOGICAL_DRIVES_EXT - 1))\r\ncontinue;\r\nraid = MR_LdRaidGet(ld, map);\r\nfor (element = 0; element < MAX_QUAD_DEPTH; element++) {\r\nfor (span = 0; span < raid->spanDepth; span++) {\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) <\r\nelement + 1)\r\ncontinue;\r\nspan_set = &(ldSpanInfo[ld].span_set[element]);\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].block_span_info.\r\nquad[element];\r\nspan_set->diff = le32_to_cpu(quad->diff);\r\nfor (count = 0, span_row_width = 0;\r\ncount < raid->spanDepth; count++) {\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].\r\nspanBlock[count].\r\nblock_span_info.\r\nnoElements) >= element + 1) {\r\nspan_set->strip_offset[count] =\r\nspan_row_width;\r\nspan_row_width +=\r\nMR_LdSpanPtrGet\r\n(ld, count, map)->spanRowDataSize;\r\nprintk(KERN_INFO "megasas:"\r\n"span %x rowDataSize %x\n",\r\ncount, MR_LdSpanPtrGet\r\n(ld, count, map)->spanRowDataSize);\r\n}\r\n}\r\nspan_set->span_row_data_width = span_row_width;\r\nspan_row = mega_div64_32(((le64_to_cpu(quad->logEnd) -\r\nle64_to_cpu(quad->logStart)) + le32_to_cpu(quad->diff)),\r\nle32_to_cpu(quad->diff));\r\nif (element == 0) {\r\nspan_set->log_start_lba = 0;\r\nspan_set->log_end_lba =\r\n((span_row << raid->stripeShift)\r\n* span_row_width) - 1;\r\nspan_set->span_row_start = 0;\r\nspan_set->span_row_end = span_row - 1;\r\nspan_set->data_strip_start = 0;\r\nspan_set->data_strip_end =\r\n(span_row * span_row_width) - 1;\r\nspan_set->data_row_start = 0;\r\nspan_set->data_row_end =\r\n(span_row * le32_to_cpu(quad->diff)) - 1;\r\n} else {\r\nspan_set_prev = &(ldSpanInfo[ld].\r\nspan_set[element - 1]);\r\nspan_set->log_start_lba =\r\nspan_set_prev->log_end_lba + 1;\r\nspan_set->log_end_lba =\r\nspan_set->log_start_lba +\r\n((span_row << raid->stripeShift)\r\n* span_row_width) - 1;\r\nspan_set->span_row_start =\r\nspan_set_prev->span_row_end + 1;\r\nspan_set->span_row_end =\r\nspan_set->span_row_start + span_row - 1;\r\nspan_set->data_strip_start =\r\nspan_set_prev->data_strip_end + 1;\r\nspan_set->data_strip_end =\r\nspan_set->data_strip_start +\r\n(span_row * span_row_width) - 1;\r\nspan_set->data_row_start =\r\nspan_set_prev->data_row_end + 1;\r\nspan_set->data_row_end =\r\nspan_set->data_row_start +\r\n(span_row * le32_to_cpu(quad->diff)) - 1;\r\n}\r\nbreak;\r\n}\r\nif (span == raid->spanDepth)\r\nbreak;\r\n}\r\n}\r\n#if SPAN_DEBUG\r\ngetSpanInfo(map, ldSpanInfo);\r\n#endif\r\n}\r\nvoid mr_update_load_balance_params(struct MR_DRV_RAID_MAP_ALL *drv_map,\r\nstruct LD_LOAD_BALANCE_INFO *lbInfo)\r\n{\r\nint ldCount;\r\nu16 ld;\r\nstruct MR_LD_RAID *raid;\r\nif (lb_pending_cmds > 128 || lb_pending_cmds < 1)\r\nlb_pending_cmds = LB_PENDING_CMDS_DEFAULT;\r\nfor (ldCount = 0; ldCount < MAX_LOGICAL_DRIVES_EXT; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, drv_map);\r\nif (ld >= MAX_LOGICAL_DRIVES_EXT) {\r\nlbInfo[ldCount].loadBalanceFlag = 0;\r\ncontinue;\r\n}\r\nraid = MR_LdRaidGet(ld, drv_map);\r\nif ((raid->level != 1) ||\r\n(raid->ldState != MR_LD_STATE_OPTIMAL)) {\r\nlbInfo[ldCount].loadBalanceFlag = 0;\r\ncontinue;\r\n}\r\nlbInfo[ldCount].loadBalanceFlag = 1;\r\n}\r\n}\r\nu8 megasas_get_best_arm_pd(struct megasas_instance *instance,\r\nstruct LD_LOAD_BALANCE_INFO *lbInfo, struct IO_REQUEST_INFO *io_info)\r\n{\r\nstruct fusion_context *fusion;\r\nstruct MR_LD_RAID *raid;\r\nstruct MR_DRV_RAID_MAP_ALL *drv_map;\r\nu16 pend0, pend1, ld;\r\nu64 diff0, diff1;\r\nu8 bestArm, pd0, pd1, span, arm;\r\nu32 arRef, span_row_size;\r\nu64 block = io_info->ldStartBlock;\r\nu32 count = io_info->numBlocks;\r\nspan = ((io_info->span_arm & RAID_CTX_SPANARM_SPAN_MASK)\r\n>> RAID_CTX_SPANARM_SPAN_SHIFT);\r\narm = (io_info->span_arm & RAID_CTX_SPANARM_ARM_MASK);\r\nfusion = instance->ctrl_context;\r\ndrv_map = fusion->ld_drv_map[(instance->map_id & 1)];\r\nld = MR_TargetIdToLdGet(io_info->ldTgtId, drv_map);\r\nraid = MR_LdRaidGet(ld, drv_map);\r\nspan_row_size = instance->UnevenSpanSupport ?\r\nSPAN_ROW_SIZE(drv_map, ld, span) : raid->rowSize;\r\narRef = MR_LdSpanArrayGet(ld, span, drv_map);\r\npd0 = MR_ArPdGet(arRef, arm, drv_map);\r\npd1 = MR_ArPdGet(arRef, (arm + 1) >= span_row_size ?\r\n(arm + 1 - span_row_size) : arm + 1, drv_map);\r\npend0 = atomic_read(&lbInfo->scsi_pending_cmds[pd0]);\r\npend1 = atomic_read(&lbInfo->scsi_pending_cmds[pd1]);\r\ndiff0 = ABS_DIFF(block, lbInfo->last_accessed_block[pd0]);\r\ndiff1 = ABS_DIFF(block, lbInfo->last_accessed_block[pd1]);\r\nbestArm = (diff0 <= diff1 ? arm : arm ^ 1);\r\nif ((bestArm == arm && pend0 > pend1 + lb_pending_cmds) ||\r\n(bestArm != arm && pend1 > pend0 + lb_pending_cmds))\r\nbestArm ^= 1;\r\nio_info->pd_after_lb = (bestArm == arm) ? pd0 : pd1;\r\nlbInfo->last_accessed_block[io_info->pd_after_lb] = block + count - 1;\r\nio_info->span_arm = (span << RAID_CTX_SPANARM_SPAN_SHIFT) | bestArm;\r\n#if SPAN_DEBUG\r\nif (arm != bestArm)\r\ndev_dbg(&instance->pdev->dev, "LSI Debug R1 Load balance "\r\n"occur - span 0x%x arm 0x%x bestArm 0x%x "\r\n"io_info->span_arm 0x%x\n",\r\nspan, arm, bestArm, io_info->span_arm);\r\n#endif\r\nreturn io_info->pd_after_lb;\r\n}\r\n__le16 get_updated_dev_handle(struct megasas_instance *instance,\r\nstruct LD_LOAD_BALANCE_INFO *lbInfo, struct IO_REQUEST_INFO *io_info)\r\n{\r\nu8 arm_pd;\r\n__le16 devHandle;\r\nstruct fusion_context *fusion;\r\nstruct MR_DRV_RAID_MAP_ALL *drv_map;\r\nfusion = instance->ctrl_context;\r\ndrv_map = fusion->ld_drv_map[(instance->map_id & 1)];\r\narm_pd = megasas_get_best_arm_pd(instance, lbInfo, io_info);\r\ndevHandle = MR_PdDevHandleGet(arm_pd, drv_map);\r\natomic_inc(&lbInfo->scsi_pending_cmds[arm_pd]);\r\nreturn devHandle;\r\n}
