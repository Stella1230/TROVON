u32 r600_rcu_rreg(struct radeon_device *rdev, u32 reg)\r\n{\r\nunsigned long flags;\r\nu32 r;\r\nspin_lock_irqsave(&rdev->rcu_idx_lock, flags);\r\nWREG32(R600_RCU_INDEX, ((reg) & 0x1fff));\r\nr = RREG32(R600_RCU_DATA);\r\nspin_unlock_irqrestore(&rdev->rcu_idx_lock, flags);\r\nreturn r;\r\n}\r\nvoid r600_rcu_wreg(struct radeon_device *rdev, u32 reg, u32 v)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&rdev->rcu_idx_lock, flags);\r\nWREG32(R600_RCU_INDEX, ((reg) & 0x1fff));\r\nWREG32(R600_RCU_DATA, (v));\r\nspin_unlock_irqrestore(&rdev->rcu_idx_lock, flags);\r\n}\r\nu32 r600_uvd_ctx_rreg(struct radeon_device *rdev, u32 reg)\r\n{\r\nunsigned long flags;\r\nu32 r;\r\nspin_lock_irqsave(&rdev->uvd_idx_lock, flags);\r\nWREG32(R600_UVD_CTX_INDEX, ((reg) & 0x1ff));\r\nr = RREG32(R600_UVD_CTX_DATA);\r\nspin_unlock_irqrestore(&rdev->uvd_idx_lock, flags);\r\nreturn r;\r\n}\r\nvoid r600_uvd_ctx_wreg(struct radeon_device *rdev, u32 reg, u32 v)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&rdev->uvd_idx_lock, flags);\r\nWREG32(R600_UVD_CTX_INDEX, ((reg) & 0x1ff));\r\nWREG32(R600_UVD_CTX_DATA, (v));\r\nspin_unlock_irqrestore(&rdev->uvd_idx_lock, flags);\r\n}\r\nint r600_get_allowed_info_register(struct radeon_device *rdev,\r\nu32 reg, u32 *val)\r\n{\r\nswitch (reg) {\r\ncase GRBM_STATUS:\r\ncase GRBM_STATUS2:\r\ncase R_000E50_SRBM_STATUS:\r\ncase DMA_STATUS_REG:\r\ncase UVD_STATUS:\r\n*val = RREG32(reg);\r\nreturn 0;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nu32 r600_get_xclk(struct radeon_device *rdev)\r\n{\r\nreturn rdev->clock.spll.reference_freq;\r\n}\r\nint r600_set_uvd_clocks(struct radeon_device *rdev, u32 vclk, u32 dclk)\r\n{\r\nunsigned fb_div = 0, ref_div, vclk_div = 0, dclk_div = 0;\r\nint r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nVCLK_SRC_SEL(1) | DCLK_SRC_SEL(1),\r\n~(VCLK_SRC_SEL_MASK | DCLK_SRC_SEL_MASK));\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_BYPASS_EN_MASK, ~(\r\nUPLL_RESET_MASK | UPLL_SLEEP_MASK | UPLL_CTLREQ_MASK));\r\nif (rdev->family >= CHIP_RS780)\r\nWREG32_P(GFX_MACRO_BYPASS_CNTL, UPLL_BYPASS_CNTL,\r\n~UPLL_BYPASS_CNTL);\r\nif (!vclk || !dclk) {\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_SLEEP_MASK, ~UPLL_SLEEP_MASK);\r\nreturn 0;\r\n}\r\nif (rdev->clock.spll.reference_freq == 10000)\r\nref_div = 34;\r\nelse\r\nref_div = 4;\r\nr = radeon_uvd_calc_upll_dividers(rdev, vclk, dclk, 50000, 160000,\r\nref_div + 1, 0xFFF, 2, 30, ~0,\r\n&fb_div, &vclk_div, &dclk_div);\r\nif (r)\r\nreturn r;\r\nif (rdev->family >= CHIP_RV670 && rdev->family < CHIP_RS780)\r\nfb_div >>= 1;\r\nelse\r\nfb_div |= 1;\r\nr = radeon_uvd_send_upll_ctlreq(rdev, CG_UPLL_FUNC_CNTL);\r\nif (r)\r\nreturn r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_RESET_MASK, ~UPLL_RESET_MASK);\r\nif (rdev->family >= CHIP_RS780)\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_REFCLK_SRC_SEL_MASK,\r\n~UPLL_REFCLK_SRC_SEL_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL,\r\nUPLL_FB_DIV(fb_div) |\r\nUPLL_REF_DIV(ref_div),\r\n~(UPLL_FB_DIV_MASK | UPLL_REF_DIV_MASK));\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nUPLL_SW_HILEN(vclk_div >> 1) |\r\nUPLL_SW_LOLEN((vclk_div >> 1) + (vclk_div & 1)) |\r\nUPLL_SW_HILEN2(dclk_div >> 1) |\r\nUPLL_SW_LOLEN2((dclk_div >> 1) + (dclk_div & 1)) |\r\nUPLL_DIVEN_MASK | UPLL_DIVEN2_MASK,\r\n~UPLL_SW_MASK);\r\nmdelay(15);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_RESET_MASK);\r\nmdelay(15);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_BYPASS_EN_MASK);\r\nif (rdev->family >= CHIP_RS780)\r\nWREG32_P(GFX_MACRO_BYPASS_CNTL, 0, ~UPLL_BYPASS_CNTL);\r\nr = radeon_uvd_send_upll_ctlreq(rdev, CG_UPLL_FUNC_CNTL);\r\nif (r)\r\nreturn r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nVCLK_SRC_SEL(2) | DCLK_SRC_SEL(2),\r\n~(VCLK_SRC_SEL_MASK | DCLK_SRC_SEL_MASK));\r\nmdelay(100);\r\nreturn 0;\r\n}\r\nvoid dce3_program_fmt(struct drm_encoder *encoder)\r\n{\r\nstruct drm_device *dev = encoder->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nstruct radeon_encoder *radeon_encoder = to_radeon_encoder(encoder);\r\nstruct radeon_crtc *radeon_crtc = to_radeon_crtc(encoder->crtc);\r\nstruct drm_connector *connector = radeon_get_connector_for_encoder(encoder);\r\nint bpc = 0;\r\nu32 tmp = 0;\r\nenum radeon_connector_dither dither = RADEON_FMT_DITHER_DISABLE;\r\nif (connector) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nbpc = radeon_get_monitor_bpc(connector);\r\ndither = radeon_connector->dither;\r\n}\r\nif (radeon_encoder->devices & ATOM_DEVICE_LCD_SUPPORT)\r\nreturn;\r\nif ((radeon_encoder->encoder_id == ENCODER_OBJECT_ID_INTERNAL_KLDSCP_DAC1) ||\r\n(radeon_encoder->encoder_id == ENCODER_OBJECT_ID_INTERNAL_KLDSCP_DAC2))\r\nreturn;\r\nif (bpc == 0)\r\nreturn;\r\nswitch (bpc) {\r\ncase 6:\r\nif (dither == RADEON_FMT_DITHER_ENABLE)\r\ntmp |= FMT_SPATIAL_DITHER_EN;\r\nelse\r\ntmp |= FMT_TRUNCATE_EN;\r\nbreak;\r\ncase 8:\r\nif (dither == RADEON_FMT_DITHER_ENABLE)\r\ntmp |= (FMT_SPATIAL_DITHER_EN | FMT_SPATIAL_DITHER_DEPTH);\r\nelse\r\ntmp |= (FMT_TRUNCATE_EN | FMT_TRUNCATE_DEPTH);\r\nbreak;\r\ncase 10:\r\ndefault:\r\nbreak;\r\n}\r\nWREG32(FMT_BIT_DEPTH_CONTROL + radeon_crtc->crtc_offset, tmp);\r\n}\r\nint rv6xx_get_temp(struct radeon_device *rdev)\r\n{\r\nu32 temp = (RREG32(CG_THERMAL_STATUS) & ASIC_T_MASK) >>\r\nASIC_T_SHIFT;\r\nint actual_temp = temp & 0xff;\r\nif (temp & 0x100)\r\nactual_temp -= 256;\r\nreturn actual_temp * 1000;\r\n}\r\nvoid r600_pm_get_dynpm_state(struct radeon_device *rdev)\r\n{\r\nint i;\r\nrdev->pm.dynpm_can_upclock = true;\r\nrdev->pm.dynpm_can_downclock = true;\r\nif ((rdev->flags & RADEON_IS_IGP) || (rdev->family == CHIP_R600)) {\r\nint min_power_state_index = 0;\r\nif (rdev->pm.num_power_states > 2)\r\nmin_power_state_index = 1;\r\nswitch (rdev->pm.dynpm_planned_action) {\r\ncase DYNPM_ACTION_MINIMUM:\r\nrdev->pm.requested_power_state_index = min_power_state_index;\r\nrdev->pm.requested_clock_mode_index = 0;\r\nrdev->pm.dynpm_can_downclock = false;\r\nbreak;\r\ncase DYNPM_ACTION_DOWNCLOCK:\r\nif (rdev->pm.current_power_state_index == min_power_state_index) {\r\nrdev->pm.requested_power_state_index = rdev->pm.current_power_state_index;\r\nrdev->pm.dynpm_can_downclock = false;\r\n} else {\r\nif (rdev->pm.active_crtc_count > 1) {\r\nfor (i = 0; i < rdev->pm.num_power_states; i++) {\r\nif (rdev->pm.power_state[i].flags & RADEON_PM_STATE_SINGLE_DISPLAY_ONLY)\r\ncontinue;\r\nelse if (i >= rdev->pm.current_power_state_index) {\r\nrdev->pm.requested_power_state_index =\r\nrdev->pm.current_power_state_index;\r\nbreak;\r\n} else {\r\nrdev->pm.requested_power_state_index = i;\r\nbreak;\r\n}\r\n}\r\n} else {\r\nif (rdev->pm.current_power_state_index == 0)\r\nrdev->pm.requested_power_state_index =\r\nrdev->pm.num_power_states - 1;\r\nelse\r\nrdev->pm.requested_power_state_index =\r\nrdev->pm.current_power_state_index - 1;\r\n}\r\n}\r\nrdev->pm.requested_clock_mode_index = 0;\r\nif ((rdev->pm.active_crtc_count > 0) &&\r\n(rdev->pm.power_state[rdev->pm.requested_power_state_index].\r\nclock_info[rdev->pm.requested_clock_mode_index].flags &\r\nRADEON_PM_MODE_NO_DISPLAY)) {\r\nrdev->pm.requested_power_state_index++;\r\n}\r\nbreak;\r\ncase DYNPM_ACTION_UPCLOCK:\r\nif (rdev->pm.current_power_state_index == (rdev->pm.num_power_states - 1)) {\r\nrdev->pm.requested_power_state_index = rdev->pm.current_power_state_index;\r\nrdev->pm.dynpm_can_upclock = false;\r\n} else {\r\nif (rdev->pm.active_crtc_count > 1) {\r\nfor (i = (rdev->pm.num_power_states - 1); i >= 0; i--) {\r\nif (rdev->pm.power_state[i].flags & RADEON_PM_STATE_SINGLE_DISPLAY_ONLY)\r\ncontinue;\r\nelse if (i <= rdev->pm.current_power_state_index) {\r\nrdev->pm.requested_power_state_index =\r\nrdev->pm.current_power_state_index;\r\nbreak;\r\n} else {\r\nrdev->pm.requested_power_state_index = i;\r\nbreak;\r\n}\r\n}\r\n} else\r\nrdev->pm.requested_power_state_index =\r\nrdev->pm.current_power_state_index + 1;\r\n}\r\nrdev->pm.requested_clock_mode_index = 0;\r\nbreak;\r\ncase DYNPM_ACTION_DEFAULT:\r\nrdev->pm.requested_power_state_index = rdev->pm.default_power_state_index;\r\nrdev->pm.requested_clock_mode_index = 0;\r\nrdev->pm.dynpm_can_upclock = false;\r\nbreak;\r\ncase DYNPM_ACTION_NONE:\r\ndefault:\r\nDRM_ERROR("Requested mode for not defined action\n");\r\nreturn;\r\n}\r\n} else {\r\nif (rdev->pm.active_crtc_count > 1) {\r\nrdev->pm.requested_power_state_index = -1;\r\nfor (i = 1; i < rdev->pm.num_power_states; i++) {\r\nif (rdev->pm.power_state[i].flags & RADEON_PM_STATE_SINGLE_DISPLAY_ONLY)\r\ncontinue;\r\nelse if ((rdev->pm.power_state[i].type == POWER_STATE_TYPE_PERFORMANCE) ||\r\n(rdev->pm.power_state[i].type == POWER_STATE_TYPE_BATTERY)) {\r\nrdev->pm.requested_power_state_index = i;\r\nbreak;\r\n}\r\n}\r\nif (rdev->pm.requested_power_state_index == -1)\r\nrdev->pm.requested_power_state_index = 0;\r\n} else\r\nrdev->pm.requested_power_state_index = 1;\r\nswitch (rdev->pm.dynpm_planned_action) {\r\ncase DYNPM_ACTION_MINIMUM:\r\nrdev->pm.requested_clock_mode_index = 0;\r\nrdev->pm.dynpm_can_downclock = false;\r\nbreak;\r\ncase DYNPM_ACTION_DOWNCLOCK:\r\nif (rdev->pm.requested_power_state_index == rdev->pm.current_power_state_index) {\r\nif (rdev->pm.current_clock_mode_index == 0) {\r\nrdev->pm.requested_clock_mode_index = 0;\r\nrdev->pm.dynpm_can_downclock = false;\r\n} else\r\nrdev->pm.requested_clock_mode_index =\r\nrdev->pm.current_clock_mode_index - 1;\r\n} else {\r\nrdev->pm.requested_clock_mode_index = 0;\r\nrdev->pm.dynpm_can_downclock = false;\r\n}\r\nif ((rdev->pm.active_crtc_count > 0) &&\r\n(rdev->pm.power_state[rdev->pm.requested_power_state_index].\r\nclock_info[rdev->pm.requested_clock_mode_index].flags &\r\nRADEON_PM_MODE_NO_DISPLAY)) {\r\nrdev->pm.requested_clock_mode_index++;\r\n}\r\nbreak;\r\ncase DYNPM_ACTION_UPCLOCK:\r\nif (rdev->pm.requested_power_state_index == rdev->pm.current_power_state_index) {\r\nif (rdev->pm.current_clock_mode_index ==\r\n(rdev->pm.power_state[rdev->pm.requested_power_state_index].num_clock_modes - 1)) {\r\nrdev->pm.requested_clock_mode_index = rdev->pm.current_clock_mode_index;\r\nrdev->pm.dynpm_can_upclock = false;\r\n} else\r\nrdev->pm.requested_clock_mode_index =\r\nrdev->pm.current_clock_mode_index + 1;\r\n} else {\r\nrdev->pm.requested_clock_mode_index =\r\nrdev->pm.power_state[rdev->pm.requested_power_state_index].num_clock_modes - 1;\r\nrdev->pm.dynpm_can_upclock = false;\r\n}\r\nbreak;\r\ncase DYNPM_ACTION_DEFAULT:\r\nrdev->pm.requested_power_state_index = rdev->pm.default_power_state_index;\r\nrdev->pm.requested_clock_mode_index = 0;\r\nrdev->pm.dynpm_can_upclock = false;\r\nbreak;\r\ncase DYNPM_ACTION_NONE:\r\ndefault:\r\nDRM_ERROR("Requested mode for not defined action\n");\r\nreturn;\r\n}\r\n}\r\nDRM_DEBUG_DRIVER("Requested: e: %d m: %d p: %d\n",\r\nrdev->pm.power_state[rdev->pm.requested_power_state_index].\r\nclock_info[rdev->pm.requested_clock_mode_index].sclk,\r\nrdev->pm.power_state[rdev->pm.requested_power_state_index].\r\nclock_info[rdev->pm.requested_clock_mode_index].mclk,\r\nrdev->pm.power_state[rdev->pm.requested_power_state_index].\r\npcie_lanes);\r\n}\r\nvoid rs780_pm_init_profile(struct radeon_device *rdev)\r\n{\r\nif (rdev->pm.num_power_states == 2) {\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 0;\r\n} else if (rdev->pm.num_power_states == 3) {\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 0;\r\n} else {\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = 3;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = 3;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 0;\r\n}\r\n}\r\nvoid r600_pm_init_profile(struct radeon_device *rdev)\r\n{\r\nint idx;\r\nif (rdev->family == CHIP_R600) {\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 0;\r\n} else {\r\nif (rdev->pm.num_power_states < 4) {\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 2;\r\n} else {\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 2;\r\nif (rdev->flags & RADEON_IS_MOBILITY)\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_BATTERY, 0);\r\nelse\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_PERFORMANCE, 0);\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 1;\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_PERFORMANCE, 0);\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 2;\r\nif (rdev->flags & RADEON_IS_MOBILITY)\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_BATTERY, 1);\r\nelse\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_PERFORMANCE, 1);\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 1;\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_PERFORMANCE, 1);\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 2;\r\n}\r\n}\r\n}\r\nvoid r600_pm_misc(struct radeon_device *rdev)\r\n{\r\nint req_ps_idx = rdev->pm.requested_power_state_index;\r\nint req_cm_idx = rdev->pm.requested_clock_mode_index;\r\nstruct radeon_power_state *ps = &rdev->pm.power_state[req_ps_idx];\r\nstruct radeon_voltage *voltage = &ps->clock_info[req_cm_idx].voltage;\r\nif ((voltage->type == VOLTAGE_SW) && voltage->voltage) {\r\nif (voltage->voltage == 0xff01)\r\nreturn;\r\nif (voltage->voltage != rdev->pm.current_vddc) {\r\nradeon_atom_set_voltage(rdev, voltage->voltage, SET_VOLTAGE_TYPE_ASIC_VDDC);\r\nrdev->pm.current_vddc = voltage->voltage;\r\nDRM_DEBUG_DRIVER("Setting: v: %d\n", voltage->voltage);\r\n}\r\n}\r\n}\r\nbool r600_gui_idle(struct radeon_device *rdev)\r\n{\r\nif (RREG32(GRBM_STATUS) & GUI_ACTIVE)\r\nreturn false;\r\nelse\r\nreturn true;\r\n}\r\nbool r600_hpd_sense(struct radeon_device *rdev, enum radeon_hpd_id hpd)\r\n{\r\nbool connected = false;\r\nif (ASIC_IS_DCE3(rdev)) {\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\nif (RREG32(DC_HPD1_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_2:\r\nif (RREG32(DC_HPD2_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_3:\r\nif (RREG32(DC_HPD3_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_4:\r\nif (RREG32(DC_HPD4_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_5:\r\nif (RREG32(DC_HPD5_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_6:\r\nif (RREG32(DC_HPD6_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n} else {\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\nif (RREG32(DC_HOT_PLUG_DETECT1_INT_STATUS) & DC_HOT_PLUG_DETECTx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_2:\r\nif (RREG32(DC_HOT_PLUG_DETECT2_INT_STATUS) & DC_HOT_PLUG_DETECTx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_3:\r\nif (RREG32(DC_HOT_PLUG_DETECT3_INT_STATUS) & DC_HOT_PLUG_DETECTx_SENSE)\r\nconnected = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nreturn connected;\r\n}\r\nvoid r600_hpd_set_polarity(struct radeon_device *rdev,\r\nenum radeon_hpd_id hpd)\r\n{\r\nu32 tmp;\r\nbool connected = r600_hpd_sense(rdev, hpd);\r\nif (ASIC_IS_DCE3(rdev)) {\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\ntmp = RREG32(DC_HPD1_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD1_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_2:\r\ntmp = RREG32(DC_HPD2_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD2_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_3:\r\ntmp = RREG32(DC_HPD3_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD3_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_4:\r\ntmp = RREG32(DC_HPD4_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD4_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_5:\r\ntmp = RREG32(DC_HPD5_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD5_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_6:\r\ntmp = RREG32(DC_HPD6_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD6_INT_CONTROL, tmp);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n} else {\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\ntmp = RREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nWREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_2:\r\ntmp = RREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nWREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_3:\r\ntmp = RREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nWREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL, tmp);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\n}\r\nvoid r600_hpd_init(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *dev = rdev->ddev;\r\nstruct drm_connector *connector;\r\nunsigned enable = 0;\r\nlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nif (connector->connector_type == DRM_MODE_CONNECTOR_eDP ||\r\nconnector->connector_type == DRM_MODE_CONNECTOR_LVDS) {\r\ncontinue;\r\n}\r\nif (ASIC_IS_DCE3(rdev)) {\r\nu32 tmp = DC_HPDx_CONNECTION_TIMER(0x9c4) | DC_HPDx_RX_INT_TIMER(0xfa);\r\nif (ASIC_IS_DCE32(rdev))\r\ntmp |= DC_HPDx_EN;\r\nswitch (radeon_connector->hpd.hpd) {\r\ncase RADEON_HPD_1:\r\nWREG32(DC_HPD1_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_2:\r\nWREG32(DC_HPD2_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_3:\r\nWREG32(DC_HPD3_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_4:\r\nWREG32(DC_HPD4_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_5:\r\nWREG32(DC_HPD5_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_6:\r\nWREG32(DC_HPD6_CONTROL, tmp);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n} else {\r\nswitch (radeon_connector->hpd.hpd) {\r\ncase RADEON_HPD_1:\r\nWREG32(DC_HOT_PLUG_DETECT1_CONTROL, DC_HOT_PLUG_DETECTx_EN);\r\nbreak;\r\ncase RADEON_HPD_2:\r\nWREG32(DC_HOT_PLUG_DETECT2_CONTROL, DC_HOT_PLUG_DETECTx_EN);\r\nbreak;\r\ncase RADEON_HPD_3:\r\nWREG32(DC_HOT_PLUG_DETECT3_CONTROL, DC_HOT_PLUG_DETECTx_EN);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nenable |= 1 << radeon_connector->hpd.hpd;\r\nradeon_hpd_set_polarity(rdev, radeon_connector->hpd.hpd);\r\n}\r\nradeon_irq_kms_enable_hpd(rdev, enable);\r\n}\r\nvoid r600_hpd_fini(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *dev = rdev->ddev;\r\nstruct drm_connector *connector;\r\nunsigned disable = 0;\r\nlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nif (ASIC_IS_DCE3(rdev)) {\r\nswitch (radeon_connector->hpd.hpd) {\r\ncase RADEON_HPD_1:\r\nWREG32(DC_HPD1_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_2:\r\nWREG32(DC_HPD2_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_3:\r\nWREG32(DC_HPD3_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_4:\r\nWREG32(DC_HPD4_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_5:\r\nWREG32(DC_HPD5_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_6:\r\nWREG32(DC_HPD6_CONTROL, 0);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n} else {\r\nswitch (radeon_connector->hpd.hpd) {\r\ncase RADEON_HPD_1:\r\nWREG32(DC_HOT_PLUG_DETECT1_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_2:\r\nWREG32(DC_HOT_PLUG_DETECT2_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_3:\r\nWREG32(DC_HOT_PLUG_DETECT3_CONTROL, 0);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\ndisable |= 1 << radeon_connector->hpd.hpd;\r\n}\r\nradeon_irq_kms_disable_hpd(rdev, disable);\r\n}\r\nvoid r600_pcie_gart_tlb_flush(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nu32 tmp;\r\nif ((rdev->family >= CHIP_RV770) && (rdev->family <= CHIP_RV740) &&\r\n!(rdev->flags & RADEON_IS_AGP)) {\r\nvoid __iomem *ptr = (void *)rdev->gart.ptr;\r\nu32 tmp;\r\nWREG32(HDP_DEBUG1, 0);\r\ntmp = readl((void __iomem *)ptr);\r\n} else\r\nWREG32(R_005480_HDP_MEM_COHERENCY_FLUSH_CNTL, 0x1);\r\nWREG32(VM_CONTEXT0_INVALIDATION_LOW_ADDR, rdev->mc.gtt_start >> 12);\r\nWREG32(VM_CONTEXT0_INVALIDATION_HIGH_ADDR, (rdev->mc.gtt_end - 1) >> 12);\r\nWREG32(VM_CONTEXT0_REQUEST_RESPONSE, REQUEST_TYPE(1));\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(VM_CONTEXT0_REQUEST_RESPONSE);\r\ntmp = (tmp & RESPONSE_TYPE_MASK) >> RESPONSE_TYPE_SHIFT;\r\nif (tmp == 2) {\r\nprintk(KERN_WARNING "[drm] r600 flush TLB failed\n");\r\nreturn;\r\n}\r\nif (tmp) {\r\nreturn;\r\n}\r\nudelay(1);\r\n}\r\n}\r\nint r600_pcie_gart_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->gart.robj) {\r\nWARN(1, "R600 PCIE GART already initialized\n");\r\nreturn 0;\r\n}\r\nr = radeon_gart_init(rdev);\r\nif (r)\r\nreturn r;\r\nrdev->gart.table_size = rdev->gart.num_gpu_pages * 8;\r\nreturn radeon_gart_table_vram_alloc(rdev);\r\n}\r\nstatic int r600_pcie_gart_enable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint r, i;\r\nif (rdev->gart.robj == NULL) {\r\ndev_err(rdev->dev, "No VRAM object for PCIE GART.\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_gart_table_vram_pin(rdev);\r\nif (r)\r\nreturn r;\r\nWREG32(VM_L2_CNTL, ENABLE_L2_CACHE | ENABLE_L2_FRAGMENT_PROCESSING |\r\nENABLE_L2_PTE_CACHE_LRU_UPDATE_BY_WRITE |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT_0(0) | BANK_SELECT_1(1));\r\ntmp = ENABLE_L1_TLB | ENABLE_L1_FRAGMENT_PROCESSING |\r\nSYSTEM_ACCESS_MODE_NOT_IN_SYS |\r\nEFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5) |\r\nENABLE_WAIT_L2_QUERY;\r\nWREG32(MC_VM_L1_TLB_MCB_RD_SYS_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_SYS_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_HDP_CNTL, tmp | ENABLE_L1_STRICT_ORDERING);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_HDP_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_RD_A_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_WR_A_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_RD_B_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_WR_B_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_GFX_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_GFX_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_PDMA_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_PDMA_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_UVD_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_UVD_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_SEM_CNTL, tmp | ENABLE_SEMAPHORE_MODE);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_SEM_CNTL, tmp | ENABLE_SEMAPHORE_MODE);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_START_ADDR, rdev->mc.gtt_start >> 12);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_END_ADDR, rdev->mc.gtt_end >> 12);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_BASE_ADDR, rdev->gart.table_addr >> 12);\r\nWREG32(VM_CONTEXT0_CNTL, ENABLE_CONTEXT | PAGE_TABLE_DEPTH(0) |\r\nRANGE_PROTECTION_FAULT_ENABLE_DEFAULT);\r\nWREG32(VM_CONTEXT0_PROTECTION_FAULT_DEFAULT_ADDR,\r\n(u32)(rdev->dummy_page.addr >> 12));\r\nfor (i = 1; i < 7; i++)\r\nWREG32(VM_CONTEXT0_CNTL + (i * 4), 0);\r\nr600_pcie_gart_tlb_flush(rdev);\r\nDRM_INFO("PCIE GART of %uM enabled (table at 0x%016llX).\n",\r\n(unsigned)(rdev->mc.gtt_size >> 20),\r\n(unsigned long long)rdev->gart.table_addr);\r\nrdev->gart.ready = true;\r\nreturn 0;\r\n}\r\nstatic void r600_pcie_gart_disable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint i;\r\nfor (i = 0; i < 7; i++)\r\nWREG32(VM_CONTEXT0_CNTL + (i * 4), 0);\r\nWREG32(VM_L2_CNTL, ENABLE_L2_FRAGMENT_PROCESSING |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL3, BANK_SELECT_0(0) | BANK_SELECT_1(1));\r\ntmp = EFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5) |\r\nENABLE_WAIT_L2_QUERY;\r\nWREG32(MC_VM_L1_TLB_MCD_RD_A_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_WR_A_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_RD_B_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_WR_B_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_GFX_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_GFX_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_PDMA_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_PDMA_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_SEM_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_SEM_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_SYS_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_SYS_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_HDP_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_HDP_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_UVD_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_UVD_CNTL, tmp);\r\nradeon_gart_table_vram_unpin(rdev);\r\n}\r\nstatic void r600_pcie_gart_fini(struct radeon_device *rdev)\r\n{\r\nradeon_gart_fini(rdev);\r\nr600_pcie_gart_disable(rdev);\r\nradeon_gart_table_vram_free(rdev);\r\n}\r\nstatic void r600_agp_enable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint i;\r\nWREG32(VM_L2_CNTL, ENABLE_L2_CACHE | ENABLE_L2_FRAGMENT_PROCESSING |\r\nENABLE_L2_PTE_CACHE_LRU_UPDATE_BY_WRITE |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT_0(0) | BANK_SELECT_1(1));\r\ntmp = ENABLE_L1_TLB | ENABLE_L1_FRAGMENT_PROCESSING |\r\nSYSTEM_ACCESS_MODE_NOT_IN_SYS |\r\nEFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5) |\r\nENABLE_WAIT_L2_QUERY;\r\nWREG32(MC_VM_L1_TLB_MCB_RD_SYS_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_SYS_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_HDP_CNTL, tmp | ENABLE_L1_STRICT_ORDERING);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_HDP_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_RD_A_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_WR_A_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_RD_B_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCD_WR_B_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_GFX_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_GFX_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_PDMA_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_PDMA_CNTL, tmp);\r\nWREG32(MC_VM_L1_TLB_MCB_RD_SEM_CNTL, tmp | ENABLE_SEMAPHORE_MODE);\r\nWREG32(MC_VM_L1_TLB_MCB_WR_SEM_CNTL, tmp | ENABLE_SEMAPHORE_MODE);\r\nfor (i = 0; i < 7; i++)\r\nWREG32(VM_CONTEXT0_CNTL + (i * 4), 0);\r\n}\r\nint r600_mc_wait_for_idle(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nu32 tmp;\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(R_000E50_SRBM_STATUS) & 0x3F00;\r\nif (!tmp)\r\nreturn 0;\r\nudelay(1);\r\n}\r\nreturn -1;\r\n}\r\nuint32_t rs780_mc_rreg(struct radeon_device *rdev, uint32_t reg)\r\n{\r\nunsigned long flags;\r\nuint32_t r;\r\nspin_lock_irqsave(&rdev->mc_idx_lock, flags);\r\nWREG32(R_0028F8_MC_INDEX, S_0028F8_MC_IND_ADDR(reg));\r\nr = RREG32(R_0028FC_MC_DATA);\r\nWREG32(R_0028F8_MC_INDEX, ~C_0028F8_MC_IND_ADDR);\r\nspin_unlock_irqrestore(&rdev->mc_idx_lock, flags);\r\nreturn r;\r\n}\r\nvoid rs780_mc_wreg(struct radeon_device *rdev, uint32_t reg, uint32_t v)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&rdev->mc_idx_lock, flags);\r\nWREG32(R_0028F8_MC_INDEX, S_0028F8_MC_IND_ADDR(reg) |\r\nS_0028F8_MC_IND_WR_EN(1));\r\nWREG32(R_0028FC_MC_DATA, v);\r\nWREG32(R_0028F8_MC_INDEX, 0x7F);\r\nspin_unlock_irqrestore(&rdev->mc_idx_lock, flags);\r\n}\r\nstatic void r600_mc_program(struct radeon_device *rdev)\r\n{\r\nstruct rv515_mc_save save;\r\nu32 tmp;\r\nint i, j;\r\nfor (i = 0, j = 0; i < 32; i++, j += 0x18) {\r\nWREG32((0x2c14 + j), 0x00000000);\r\nWREG32((0x2c18 + j), 0x00000000);\r\nWREG32((0x2c1c + j), 0x00000000);\r\nWREG32((0x2c20 + j), 0x00000000);\r\nWREG32((0x2c24 + j), 0x00000000);\r\n}\r\nWREG32(HDP_REG_COHERENCY_FLUSH_CNTL, 0);\r\nrv515_mc_stop(rdev, &save);\r\nif (r600_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nWREG32(VGA_HDP_CONTROL, VGA_MEMORY_DISABLE);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nif (rdev->mc.vram_start < rdev->mc.gtt_start) {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.vram_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.gtt_end >> 12);\r\n} else {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.gtt_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.vram_end >> 12);\r\n}\r\n} else {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR, rdev->mc.vram_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR, rdev->mc.vram_end >> 12);\r\n}\r\nWREG32(MC_VM_SYSTEM_APERTURE_DEFAULT_ADDR, rdev->vram_scratch.gpu_addr >> 12);\r\ntmp = ((rdev->mc.vram_end >> 24) & 0xFFFF) << 16;\r\ntmp |= ((rdev->mc.vram_start >> 24) & 0xFFFF);\r\nWREG32(MC_VM_FB_LOCATION, tmp);\r\nWREG32(HDP_NONSURFACE_BASE, (rdev->mc.vram_start >> 8));\r\nWREG32(HDP_NONSURFACE_INFO, (2 << 7));\r\nWREG32(HDP_NONSURFACE_SIZE, 0x3FFFFFFF);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nWREG32(MC_VM_AGP_TOP, rdev->mc.gtt_end >> 22);\r\nWREG32(MC_VM_AGP_BOT, rdev->mc.gtt_start >> 22);\r\nWREG32(MC_VM_AGP_BASE, rdev->mc.agp_base >> 22);\r\n} else {\r\nWREG32(MC_VM_AGP_BASE, 0);\r\nWREG32(MC_VM_AGP_TOP, 0x0FFFFFFF);\r\nWREG32(MC_VM_AGP_BOT, 0x0FFFFFFF);\r\n}\r\nif (r600_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nrv515_mc_resume(rdev, &save);\r\nrv515_vga_render_disable(rdev);\r\n}\r\nstatic void r600_vram_gtt_location(struct radeon_device *rdev, struct radeon_mc *mc)\r\n{\r\nu64 size_bf, size_af;\r\nif (mc->mc_vram_size > 0xE0000000) {\r\ndev_warn(rdev->dev, "limiting VRAM\n");\r\nmc->real_vram_size = 0xE0000000;\r\nmc->mc_vram_size = 0xE0000000;\r\n}\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nsize_bf = mc->gtt_start;\r\nsize_af = mc->mc_mask - mc->gtt_end;\r\nif (size_bf > size_af) {\r\nif (mc->mc_vram_size > size_bf) {\r\ndev_warn(rdev->dev, "limiting VRAM\n");\r\nmc->real_vram_size = size_bf;\r\nmc->mc_vram_size = size_bf;\r\n}\r\nmc->vram_start = mc->gtt_start - mc->mc_vram_size;\r\n} else {\r\nif (mc->mc_vram_size > size_af) {\r\ndev_warn(rdev->dev, "limiting VRAM\n");\r\nmc->real_vram_size = size_af;\r\nmc->mc_vram_size = size_af;\r\n}\r\nmc->vram_start = mc->gtt_end + 1;\r\n}\r\nmc->vram_end = mc->vram_start + mc->mc_vram_size - 1;\r\ndev_info(rdev->dev, "VRAM: %lluM 0x%08llX - 0x%08llX (%lluM used)\n",\r\nmc->mc_vram_size >> 20, mc->vram_start,\r\nmc->vram_end, mc->real_vram_size >> 20);\r\n} else {\r\nu64 base = 0;\r\nif (rdev->flags & RADEON_IS_IGP) {\r\nbase = RREG32(MC_VM_FB_LOCATION) & 0xFFFF;\r\nbase <<= 24;\r\n}\r\nradeon_vram_location(rdev, &rdev->mc, base);\r\nrdev->mc.gtt_base_align = 0;\r\nradeon_gtt_location(rdev, mc);\r\n}\r\n}\r\nstatic int r600_mc_init(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint chansize, numchan;\r\nuint32_t h_addr, l_addr;\r\nunsigned long long k8_addr;\r\nrdev->mc.vram_is_ddr = true;\r\ntmp = RREG32(RAMCFG);\r\nif (tmp & CHANSIZE_OVERRIDE) {\r\nchansize = 16;\r\n} else if (tmp & CHANSIZE_MASK) {\r\nchansize = 64;\r\n} else {\r\nchansize = 32;\r\n}\r\ntmp = RREG32(CHMAP);\r\nswitch ((tmp & NOOFCHAN_MASK) >> NOOFCHAN_SHIFT) {\r\ncase 0:\r\ndefault:\r\nnumchan = 1;\r\nbreak;\r\ncase 1:\r\nnumchan = 2;\r\nbreak;\r\ncase 2:\r\nnumchan = 4;\r\nbreak;\r\ncase 3:\r\nnumchan = 8;\r\nbreak;\r\n}\r\nrdev->mc.vram_width = numchan * chansize;\r\nrdev->mc.aper_base = pci_resource_start(rdev->pdev, 0);\r\nrdev->mc.aper_size = pci_resource_len(rdev->pdev, 0);\r\nrdev->mc.mc_vram_size = RREG32(CONFIG_MEMSIZE);\r\nrdev->mc.real_vram_size = RREG32(CONFIG_MEMSIZE);\r\nrdev->mc.visible_vram_size = rdev->mc.aper_size;\r\nr600_vram_gtt_location(rdev, &rdev->mc);\r\nif (rdev->flags & RADEON_IS_IGP) {\r\nrs690_pm_info(rdev);\r\nrdev->mc.igp_sideport_enabled = radeon_atombios_sideport_present(rdev);\r\nif (rdev->family == CHIP_RS780 || rdev->family == CHIP_RS880) {\r\nrdev->fastfb_working = false;\r\nh_addr = G_000012_K8_ADDR_EXT(RREG32_MC(R_000012_MC_MISC_UMA_CNTL));\r\nl_addr = RREG32_MC(R_000011_K8_FB_LOCATION);\r\nk8_addr = ((unsigned long long)h_addr) << 32 | l_addr;\r\n#if defined(CONFIG_X86_32) && !defined(CONFIG_X86_PAE)\r\nif (k8_addr + rdev->mc.visible_vram_size < 0x100000000ULL)\r\n#endif\r\n{\r\nif (rdev->mc.igp_sideport_enabled == false && radeon_fastfb == 1) {\r\nDRM_INFO("Direct mapping: aper base at 0x%llx, replaced by direct mapping base 0x%llx.\n",\r\n(unsigned long long)rdev->mc.aper_base, k8_addr);\r\nrdev->mc.aper_base = (resource_size_t)k8_addr;\r\nrdev->fastfb_working = true;\r\n}\r\n}\r\n}\r\n}\r\nradeon_update_bandwidth_info(rdev);\r\nreturn 0;\r\n}\r\nint r600_vram_scratch_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->vram_scratch.robj == NULL) {\r\nr = radeon_bo_create(rdev, RADEON_GPU_PAGE_SIZE,\r\nPAGE_SIZE, true, RADEON_GEM_DOMAIN_VRAM,\r\n0, NULL, NULL, &rdev->vram_scratch.robj);\r\nif (r) {\r\nreturn r;\r\n}\r\n}\r\nr = radeon_bo_reserve(rdev->vram_scratch.robj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_pin(rdev->vram_scratch.robj,\r\nRADEON_GEM_DOMAIN_VRAM, &rdev->vram_scratch.gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(rdev->vram_scratch.robj);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(rdev->vram_scratch.robj,\r\n(void **)&rdev->vram_scratch.ptr);\r\nif (r)\r\nradeon_bo_unpin(rdev->vram_scratch.robj);\r\nradeon_bo_unreserve(rdev->vram_scratch.robj);\r\nreturn r;\r\n}\r\nvoid r600_vram_scratch_fini(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->vram_scratch.robj == NULL) {\r\nreturn;\r\n}\r\nr = radeon_bo_reserve(rdev->vram_scratch.robj, false);\r\nif (likely(r == 0)) {\r\nradeon_bo_kunmap(rdev->vram_scratch.robj);\r\nradeon_bo_unpin(rdev->vram_scratch.robj);\r\nradeon_bo_unreserve(rdev->vram_scratch.robj);\r\n}\r\nradeon_bo_unref(&rdev->vram_scratch.robj);\r\n}\r\nvoid r600_set_bios_scratch_engine_hung(struct radeon_device *rdev, bool hung)\r\n{\r\nu32 tmp = RREG32(R600_BIOS_3_SCRATCH);\r\nif (hung)\r\ntmp |= ATOM_S3_ASIC_GUI_ENGINE_HUNG;\r\nelse\r\ntmp &= ~ATOM_S3_ASIC_GUI_ENGINE_HUNG;\r\nWREG32(R600_BIOS_3_SCRATCH, tmp);\r\n}\r\nstatic void r600_print_gpu_status_regs(struct radeon_device *rdev)\r\n{\r\ndev_info(rdev->dev, " R_008010_GRBM_STATUS = 0x%08X\n",\r\nRREG32(R_008010_GRBM_STATUS));\r\ndev_info(rdev->dev, " R_008014_GRBM_STATUS2 = 0x%08X\n",\r\nRREG32(R_008014_GRBM_STATUS2));\r\ndev_info(rdev->dev, " R_000E50_SRBM_STATUS = 0x%08X\n",\r\nRREG32(R_000E50_SRBM_STATUS));\r\ndev_info(rdev->dev, " R_008674_CP_STALLED_STAT1 = 0x%08X\n",\r\nRREG32(CP_STALLED_STAT1));\r\ndev_info(rdev->dev, " R_008678_CP_STALLED_STAT2 = 0x%08X\n",\r\nRREG32(CP_STALLED_STAT2));\r\ndev_info(rdev->dev, " R_00867C_CP_BUSY_STAT = 0x%08X\n",\r\nRREG32(CP_BUSY_STAT));\r\ndev_info(rdev->dev, " R_008680_CP_STAT = 0x%08X\n",\r\nRREG32(CP_STAT));\r\ndev_info(rdev->dev, " R_00D034_DMA_STATUS_REG = 0x%08X\n",\r\nRREG32(DMA_STATUS_REG));\r\n}\r\nstatic bool r600_is_display_hung(struct radeon_device *rdev)\r\n{\r\nu32 crtc_hung = 0;\r\nu32 crtc_status[2];\r\nu32 i, j, tmp;\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (RREG32(AVIVO_D1CRTC_CONTROL + crtc_offsets[i]) & AVIVO_CRTC_EN) {\r\ncrtc_status[i] = RREG32(AVIVO_D1CRTC_STATUS_HV_COUNT + crtc_offsets[i]);\r\ncrtc_hung |= (1 << i);\r\n}\r\n}\r\nfor (j = 0; j < 10; j++) {\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (crtc_hung & (1 << i)) {\r\ntmp = RREG32(AVIVO_D1CRTC_STATUS_HV_COUNT + crtc_offsets[i]);\r\nif (tmp != crtc_status[i])\r\ncrtc_hung &= ~(1 << i);\r\n}\r\n}\r\nif (crtc_hung == 0)\r\nreturn false;\r\nudelay(100);\r\n}\r\nreturn true;\r\n}\r\nu32 r600_gpu_check_soft_reset(struct radeon_device *rdev)\r\n{\r\nu32 reset_mask = 0;\r\nu32 tmp;\r\ntmp = RREG32(R_008010_GRBM_STATUS);\r\nif (rdev->family >= CHIP_RV770) {\r\nif (G_008010_PA_BUSY(tmp) | G_008010_SC_BUSY(tmp) |\r\nG_008010_SH_BUSY(tmp) | G_008010_SX_BUSY(tmp) |\r\nG_008010_TA_BUSY(tmp) | G_008010_VGT_BUSY(tmp) |\r\nG_008010_DB03_BUSY(tmp) | G_008010_CB03_BUSY(tmp) |\r\nG_008010_SPI03_BUSY(tmp) | G_008010_VGT_BUSY_NO_DMA(tmp))\r\nreset_mask |= RADEON_RESET_GFX;\r\n} else {\r\nif (G_008010_PA_BUSY(tmp) | G_008010_SC_BUSY(tmp) |\r\nG_008010_SH_BUSY(tmp) | G_008010_SX_BUSY(tmp) |\r\nG_008010_TA03_BUSY(tmp) | G_008010_VGT_BUSY(tmp) |\r\nG_008010_DB03_BUSY(tmp) | G_008010_CB03_BUSY(tmp) |\r\nG_008010_SPI03_BUSY(tmp) | G_008010_VGT_BUSY_NO_DMA(tmp))\r\nreset_mask |= RADEON_RESET_GFX;\r\n}\r\nif (G_008010_CF_RQ_PENDING(tmp) | G_008010_PF_RQ_PENDING(tmp) |\r\nG_008010_CP_BUSY(tmp) | G_008010_CP_COHERENCY_BUSY(tmp))\r\nreset_mask |= RADEON_RESET_CP;\r\nif (G_008010_GRBM_EE_BUSY(tmp))\r\nreset_mask |= RADEON_RESET_GRBM | RADEON_RESET_GFX | RADEON_RESET_CP;\r\ntmp = RREG32(DMA_STATUS_REG);\r\nif (!(tmp & DMA_IDLE))\r\nreset_mask |= RADEON_RESET_DMA;\r\ntmp = RREG32(R_000E50_SRBM_STATUS);\r\nif (G_000E50_RLC_RQ_PENDING(tmp) | G_000E50_RLC_BUSY(tmp))\r\nreset_mask |= RADEON_RESET_RLC;\r\nif (G_000E50_IH_BUSY(tmp))\r\nreset_mask |= RADEON_RESET_IH;\r\nif (G_000E50_SEM_BUSY(tmp))\r\nreset_mask |= RADEON_RESET_SEM;\r\nif (G_000E50_GRBM_RQ_PENDING(tmp))\r\nreset_mask |= RADEON_RESET_GRBM;\r\nif (G_000E50_VMC_BUSY(tmp))\r\nreset_mask |= RADEON_RESET_VMC;\r\nif (G_000E50_MCB_BUSY(tmp) | G_000E50_MCDZ_BUSY(tmp) |\r\nG_000E50_MCDY_BUSY(tmp) | G_000E50_MCDX_BUSY(tmp) |\r\nG_000E50_MCDW_BUSY(tmp))\r\nreset_mask |= RADEON_RESET_MC;\r\nif (r600_is_display_hung(rdev))\r\nreset_mask |= RADEON_RESET_DISPLAY;\r\nif (reset_mask & RADEON_RESET_MC) {\r\nDRM_DEBUG("MC busy: 0x%08X, clearing.\n", reset_mask);\r\nreset_mask &= ~RADEON_RESET_MC;\r\n}\r\nreturn reset_mask;\r\n}\r\nstatic void r600_gpu_soft_reset(struct radeon_device *rdev, u32 reset_mask)\r\n{\r\nstruct rv515_mc_save save;\r\nu32 grbm_soft_reset = 0, srbm_soft_reset = 0;\r\nu32 tmp;\r\nif (reset_mask == 0)\r\nreturn;\r\ndev_info(rdev->dev, "GPU softreset: 0x%08X\n", reset_mask);\r\nr600_print_gpu_status_regs(rdev);\r\nif (rdev->family >= CHIP_RV770)\r\nWREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1) | S_0086D8_CP_PFP_HALT(1));\r\nelse\r\nWREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1));\r\nWREG32(RLC_CNTL, 0);\r\nif (reset_mask & RADEON_RESET_DMA) {\r\ntmp = RREG32(DMA_RB_CNTL);\r\ntmp &= ~DMA_RB_ENABLE;\r\nWREG32(DMA_RB_CNTL, tmp);\r\n}\r\nmdelay(50);\r\nrv515_mc_stop(rdev, &save);\r\nif (r600_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nif (reset_mask & (RADEON_RESET_GFX | RADEON_RESET_COMPUTE)) {\r\nif (rdev->family >= CHIP_RV770)\r\ngrbm_soft_reset |= S_008020_SOFT_RESET_DB(1) |\r\nS_008020_SOFT_RESET_CB(1) |\r\nS_008020_SOFT_RESET_PA(1) |\r\nS_008020_SOFT_RESET_SC(1) |\r\nS_008020_SOFT_RESET_SPI(1) |\r\nS_008020_SOFT_RESET_SX(1) |\r\nS_008020_SOFT_RESET_SH(1) |\r\nS_008020_SOFT_RESET_TC(1) |\r\nS_008020_SOFT_RESET_TA(1) |\r\nS_008020_SOFT_RESET_VC(1) |\r\nS_008020_SOFT_RESET_VGT(1);\r\nelse\r\ngrbm_soft_reset |= S_008020_SOFT_RESET_CR(1) |\r\nS_008020_SOFT_RESET_DB(1) |\r\nS_008020_SOFT_RESET_CB(1) |\r\nS_008020_SOFT_RESET_PA(1) |\r\nS_008020_SOFT_RESET_SC(1) |\r\nS_008020_SOFT_RESET_SMX(1) |\r\nS_008020_SOFT_RESET_SPI(1) |\r\nS_008020_SOFT_RESET_SX(1) |\r\nS_008020_SOFT_RESET_SH(1) |\r\nS_008020_SOFT_RESET_TC(1) |\r\nS_008020_SOFT_RESET_TA(1) |\r\nS_008020_SOFT_RESET_VC(1) |\r\nS_008020_SOFT_RESET_VGT(1);\r\n}\r\nif (reset_mask & RADEON_RESET_CP) {\r\ngrbm_soft_reset |= S_008020_SOFT_RESET_CP(1) |\r\nS_008020_SOFT_RESET_VGT(1);\r\nsrbm_soft_reset |= S_000E60_SOFT_RESET_GRBM(1);\r\n}\r\nif (reset_mask & RADEON_RESET_DMA) {\r\nif (rdev->family >= CHIP_RV770)\r\nsrbm_soft_reset |= RV770_SOFT_RESET_DMA;\r\nelse\r\nsrbm_soft_reset |= SOFT_RESET_DMA;\r\n}\r\nif (reset_mask & RADEON_RESET_RLC)\r\nsrbm_soft_reset |= S_000E60_SOFT_RESET_RLC(1);\r\nif (reset_mask & RADEON_RESET_SEM)\r\nsrbm_soft_reset |= S_000E60_SOFT_RESET_SEM(1);\r\nif (reset_mask & RADEON_RESET_IH)\r\nsrbm_soft_reset |= S_000E60_SOFT_RESET_IH(1);\r\nif (reset_mask & RADEON_RESET_GRBM)\r\nsrbm_soft_reset |= S_000E60_SOFT_RESET_GRBM(1);\r\nif (!(rdev->flags & RADEON_IS_IGP)) {\r\nif (reset_mask & RADEON_RESET_MC)\r\nsrbm_soft_reset |= S_000E60_SOFT_RESET_MC(1);\r\n}\r\nif (reset_mask & RADEON_RESET_VMC)\r\nsrbm_soft_reset |= S_000E60_SOFT_RESET_VMC(1);\r\nif (grbm_soft_reset) {\r\ntmp = RREG32(R_008020_GRBM_SOFT_RESET);\r\ntmp |= grbm_soft_reset;\r\ndev_info(rdev->dev, "R_008020_GRBM_SOFT_RESET=0x%08X\n", tmp);\r\nWREG32(R_008020_GRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(R_008020_GRBM_SOFT_RESET);\r\nudelay(50);\r\ntmp &= ~grbm_soft_reset;\r\nWREG32(R_008020_GRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(R_008020_GRBM_SOFT_RESET);\r\n}\r\nif (srbm_soft_reset) {\r\ntmp = RREG32(SRBM_SOFT_RESET);\r\ntmp |= srbm_soft_reset;\r\ndev_info(rdev->dev, "SRBM_SOFT_RESET=0x%08X\n", tmp);\r\nWREG32(SRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(SRBM_SOFT_RESET);\r\nudelay(50);\r\ntmp &= ~srbm_soft_reset;\r\nWREG32(SRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(SRBM_SOFT_RESET);\r\n}\r\nmdelay(1);\r\nrv515_mc_resume(rdev, &save);\r\nudelay(50);\r\nr600_print_gpu_status_regs(rdev);\r\n}\r\nstatic void r600_gpu_pci_config_reset(struct radeon_device *rdev)\r\n{\r\nstruct rv515_mc_save save;\r\nu32 tmp, i;\r\ndev_info(rdev->dev, "GPU pci config reset\n");\r\nif (rdev->family >= CHIP_RV770)\r\nWREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1) | S_0086D8_CP_PFP_HALT(1));\r\nelse\r\nWREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1));\r\nWREG32(RLC_CNTL, 0);\r\ntmp = RREG32(DMA_RB_CNTL);\r\ntmp &= ~DMA_RB_ENABLE;\r\nWREG32(DMA_RB_CNTL, tmp);\r\nmdelay(50);\r\nif (rdev->family >= CHIP_RV770)\r\nrv770_set_clk_bypass_mode(rdev);\r\npci_clear_master(rdev->pdev);\r\nrv515_mc_stop(rdev, &save);\r\nif (r600_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\ntmp = RREG32(BUS_CNTL);\r\ntmp |= VGA_COHE_SPEC_TIMER_DIS;\r\nWREG32(BUS_CNTL, tmp);\r\ntmp = RREG32(BIF_SCRATCH0);\r\nradeon_pci_config_reset(rdev);\r\nmdelay(1);\r\ntmp = SOFT_RESET_BIF;\r\nWREG32(SRBM_SOFT_RESET, tmp);\r\nmdelay(1);\r\nWREG32(SRBM_SOFT_RESET, 0);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\nif (RREG32(CONFIG_MEMSIZE) != 0xffffffff)\r\nbreak;\r\nudelay(1);\r\n}\r\n}\r\nint r600_asic_reset(struct radeon_device *rdev)\r\n{\r\nu32 reset_mask;\r\nreset_mask = r600_gpu_check_soft_reset(rdev);\r\nif (reset_mask)\r\nr600_set_bios_scratch_engine_hung(rdev, true);\r\nr600_gpu_soft_reset(rdev, reset_mask);\r\nreset_mask = r600_gpu_check_soft_reset(rdev);\r\nif (reset_mask && radeon_hard_reset)\r\nr600_gpu_pci_config_reset(rdev);\r\nreset_mask = r600_gpu_check_soft_reset(rdev);\r\nif (!reset_mask)\r\nr600_set_bios_scratch_engine_hung(rdev, false);\r\nreturn 0;\r\n}\r\nbool r600_gfx_is_lockup(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nu32 reset_mask = r600_gpu_check_soft_reset(rdev);\r\nif (!(reset_mask & (RADEON_RESET_GFX |\r\nRADEON_RESET_COMPUTE |\r\nRADEON_RESET_CP))) {\r\nradeon_ring_lockup_update(rdev, ring);\r\nreturn false;\r\n}\r\nreturn radeon_ring_test_lockup(rdev, ring);\r\n}\r\nu32 r6xx_remap_render_backend(struct radeon_device *rdev,\r\nu32 tiling_pipe_num,\r\nu32 max_rb_num,\r\nu32 total_max_rb_num,\r\nu32 disabled_rb_mask)\r\n{\r\nu32 rendering_pipe_num, rb_num_width, req_rb_num;\r\nu32 pipe_rb_ratio, pipe_rb_remain, tmp;\r\nu32 data = 0, mask = 1 << (max_rb_num - 1);\r\nunsigned i, j;\r\ntmp = disabled_rb_mask | ((0xff << max_rb_num) & 0xff);\r\nif ((tmp & 0xff) != 0xff)\r\ndisabled_rb_mask = tmp;\r\nrendering_pipe_num = 1 << tiling_pipe_num;\r\nreq_rb_num = total_max_rb_num - r600_count_pipe_bits(disabled_rb_mask);\r\nBUG_ON(rendering_pipe_num < req_rb_num);\r\npipe_rb_ratio = rendering_pipe_num / req_rb_num;\r\npipe_rb_remain = rendering_pipe_num - pipe_rb_ratio * req_rb_num;\r\nif (rdev->family <= CHIP_RV740) {\r\nrb_num_width = 2;\r\n} else {\r\nrb_num_width = 4;\r\n}\r\nfor (i = 0; i < max_rb_num; i++) {\r\nif (!(mask & disabled_rb_mask)) {\r\nfor (j = 0; j < pipe_rb_ratio; j++) {\r\ndata <<= rb_num_width;\r\ndata |= max_rb_num - i - 1;\r\n}\r\nif (pipe_rb_remain) {\r\ndata <<= rb_num_width;\r\ndata |= max_rb_num - i - 1;\r\npipe_rb_remain--;\r\n}\r\n}\r\nmask >>= 1;\r\n}\r\nreturn data;\r\n}\r\nint r600_count_pipe_bits(uint32_t val)\r\n{\r\nreturn hweight32(val);\r\n}\r\nstatic void r600_gpu_init(struct radeon_device *rdev)\r\n{\r\nu32 tiling_config;\r\nu32 ramcfg;\r\nu32 cc_gc_shader_pipe_config;\r\nu32 tmp;\r\nint i, j;\r\nu32 sq_config;\r\nu32 sq_gpr_resource_mgmt_1 = 0;\r\nu32 sq_gpr_resource_mgmt_2 = 0;\r\nu32 sq_thread_resource_mgmt = 0;\r\nu32 sq_stack_resource_mgmt_1 = 0;\r\nu32 sq_stack_resource_mgmt_2 = 0;\r\nu32 disabled_rb_mask;\r\nrdev->config.r600.tiling_group_size = 256;\r\nswitch (rdev->family) {\r\ncase CHIP_R600:\r\nrdev->config.r600.max_pipes = 4;\r\nrdev->config.r600.max_tile_pipes = 8;\r\nrdev->config.r600.max_simds = 4;\r\nrdev->config.r600.max_backends = 4;\r\nrdev->config.r600.max_gprs = 256;\r\nrdev->config.r600.max_threads = 192;\r\nrdev->config.r600.max_stack_entries = 256;\r\nrdev->config.r600.max_hw_contexts = 8;\r\nrdev->config.r600.max_gs_threads = 16;\r\nrdev->config.r600.sx_max_export_size = 128;\r\nrdev->config.r600.sx_max_export_pos_size = 16;\r\nrdev->config.r600.sx_max_export_smx_size = 128;\r\nrdev->config.r600.sq_num_cf_insts = 2;\r\nbreak;\r\ncase CHIP_RV630:\r\ncase CHIP_RV635:\r\nrdev->config.r600.max_pipes = 2;\r\nrdev->config.r600.max_tile_pipes = 2;\r\nrdev->config.r600.max_simds = 3;\r\nrdev->config.r600.max_backends = 1;\r\nrdev->config.r600.max_gprs = 128;\r\nrdev->config.r600.max_threads = 192;\r\nrdev->config.r600.max_stack_entries = 128;\r\nrdev->config.r600.max_hw_contexts = 8;\r\nrdev->config.r600.max_gs_threads = 4;\r\nrdev->config.r600.sx_max_export_size = 128;\r\nrdev->config.r600.sx_max_export_pos_size = 16;\r\nrdev->config.r600.sx_max_export_smx_size = 128;\r\nrdev->config.r600.sq_num_cf_insts = 2;\r\nbreak;\r\ncase CHIP_RV610:\r\ncase CHIP_RV620:\r\ncase CHIP_RS780:\r\ncase CHIP_RS880:\r\nrdev->config.r600.max_pipes = 1;\r\nrdev->config.r600.max_tile_pipes = 1;\r\nrdev->config.r600.max_simds = 2;\r\nrdev->config.r600.max_backends = 1;\r\nrdev->config.r600.max_gprs = 128;\r\nrdev->config.r600.max_threads = 192;\r\nrdev->config.r600.max_stack_entries = 128;\r\nrdev->config.r600.max_hw_contexts = 4;\r\nrdev->config.r600.max_gs_threads = 4;\r\nrdev->config.r600.sx_max_export_size = 128;\r\nrdev->config.r600.sx_max_export_pos_size = 16;\r\nrdev->config.r600.sx_max_export_smx_size = 128;\r\nrdev->config.r600.sq_num_cf_insts = 1;\r\nbreak;\r\ncase CHIP_RV670:\r\nrdev->config.r600.max_pipes = 4;\r\nrdev->config.r600.max_tile_pipes = 4;\r\nrdev->config.r600.max_simds = 4;\r\nrdev->config.r600.max_backends = 4;\r\nrdev->config.r600.max_gprs = 192;\r\nrdev->config.r600.max_threads = 192;\r\nrdev->config.r600.max_stack_entries = 256;\r\nrdev->config.r600.max_hw_contexts = 8;\r\nrdev->config.r600.max_gs_threads = 16;\r\nrdev->config.r600.sx_max_export_size = 128;\r\nrdev->config.r600.sx_max_export_pos_size = 16;\r\nrdev->config.r600.sx_max_export_smx_size = 128;\r\nrdev->config.r600.sq_num_cf_insts = 2;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nfor (i = 0, j = 0; i < 32; i++, j += 0x18) {\r\nWREG32((0x2c14 + j), 0x00000000);\r\nWREG32((0x2c18 + j), 0x00000000);\r\nWREG32((0x2c1c + j), 0x00000000);\r\nWREG32((0x2c20 + j), 0x00000000);\r\nWREG32((0x2c24 + j), 0x00000000);\r\n}\r\nWREG32(GRBM_CNTL, GRBM_READ_TIMEOUT(0xff));\r\ntiling_config = 0;\r\nramcfg = RREG32(RAMCFG);\r\nswitch (rdev->config.r600.max_tile_pipes) {\r\ncase 1:\r\ntiling_config |= PIPE_TILING(0);\r\nbreak;\r\ncase 2:\r\ntiling_config |= PIPE_TILING(1);\r\nbreak;\r\ncase 4:\r\ntiling_config |= PIPE_TILING(2);\r\nbreak;\r\ncase 8:\r\ntiling_config |= PIPE_TILING(3);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nrdev->config.r600.tiling_npipes = rdev->config.r600.max_tile_pipes;\r\nrdev->config.r600.tiling_nbanks = 4 << ((ramcfg & NOOFBANK_MASK) >> NOOFBANK_SHIFT);\r\ntiling_config |= BANK_TILING((ramcfg & NOOFBANK_MASK) >> NOOFBANK_SHIFT);\r\ntiling_config |= GROUP_SIZE((ramcfg & BURSTLENGTH_MASK) >> BURSTLENGTH_SHIFT);\r\ntmp = (ramcfg & NOOFROWS_MASK) >> NOOFROWS_SHIFT;\r\nif (tmp > 3) {\r\ntiling_config |= ROW_TILING(3);\r\ntiling_config |= SAMPLE_SPLIT(3);\r\n} else {\r\ntiling_config |= ROW_TILING(tmp);\r\ntiling_config |= SAMPLE_SPLIT(tmp);\r\n}\r\ntiling_config |= BANK_SWAPS(1);\r\ncc_gc_shader_pipe_config = RREG32(CC_GC_SHADER_PIPE_CONFIG) & 0x00ffff00;\r\ntmp = rdev->config.r600.max_simds -\r\nr600_count_pipe_bits((cc_gc_shader_pipe_config >> 16) & R6XX_MAX_SIMDS_MASK);\r\nrdev->config.r600.active_simds = tmp;\r\ndisabled_rb_mask = (RREG32(CC_RB_BACKEND_DISABLE) >> 16) & R6XX_MAX_BACKENDS_MASK;\r\ntmp = 0;\r\nfor (i = 0; i < rdev->config.r600.max_backends; i++)\r\ntmp |= (1 << i);\r\nif ((disabled_rb_mask & tmp) == tmp) {\r\nfor (i = 0; i < rdev->config.r600.max_backends; i++)\r\ndisabled_rb_mask &= ~(1 << i);\r\n}\r\ntmp = (tiling_config & PIPE_TILING__MASK) >> PIPE_TILING__SHIFT;\r\ntmp = r6xx_remap_render_backend(rdev, tmp, rdev->config.r600.max_backends,\r\nR6XX_MAX_BACKENDS, disabled_rb_mask);\r\ntiling_config |= tmp << 16;\r\nrdev->config.r600.backend_map = tmp;\r\nrdev->config.r600.tile_config = tiling_config;\r\nWREG32(GB_TILING_CONFIG, tiling_config);\r\nWREG32(DCP_TILING_CONFIG, tiling_config & 0xffff);\r\nWREG32(HDP_TILING_CONFIG, tiling_config & 0xffff);\r\nWREG32(DMA_TILING_CONFIG, tiling_config & 0xffff);\r\ntmp = R6XX_MAX_PIPES - r600_count_pipe_bits((cc_gc_shader_pipe_config & INACTIVE_QD_PIPES_MASK) >> 8);\r\nWREG32(VGT_OUT_DEALLOC_CNTL, (tmp * 4) & DEALLOC_DIST_MASK);\r\nWREG32(VGT_VERTEX_REUSE_BLOCK_CNTL, ((tmp * 4) - 2) & VTX_REUSE_DEPTH_MASK);\r\nWREG32(CP_QUEUE_THRESHOLDS, (ROQ_IB1_START(0x16) | ROQ_IB2_START(0x2b)));\r\nWREG32(CP_MEQ_THRESHOLDS, (MEQ_END(0x40) | ROQ_END(0x40)));\r\nWREG32(TA_CNTL_AUX, (DISABLE_CUBE_ANISO | SYNC_GRADIENT |\r\nSYNC_WALKER | SYNC_ALIGNER));\r\nif (rdev->family == CHIP_RV670)\r\nWREG32(ARB_GDEC_RD_CNTL, 0x00000021);\r\ntmp = RREG32(SX_DEBUG_1);\r\ntmp |= SMX_EVENT_RELEASE;\r\nif ((rdev->family > CHIP_R600))\r\ntmp |= ENABLE_NEW_SMX_ADDRESS;\r\nWREG32(SX_DEBUG_1, tmp);\r\nif (((rdev->family) == CHIP_R600) ||\r\n((rdev->family) == CHIP_RV630) ||\r\n((rdev->family) == CHIP_RV610) ||\r\n((rdev->family) == CHIP_RV620) ||\r\n((rdev->family) == CHIP_RS780) ||\r\n((rdev->family) == CHIP_RS880)) {\r\nWREG32(DB_DEBUG, PREZ_MUST_WAIT_FOR_POSTZ_DONE);\r\n} else {\r\nWREG32(DB_DEBUG, 0);\r\n}\r\nWREG32(DB_WATERMARKS, (DEPTH_FREE(4) | DEPTH_CACHELINE_FREE(16) |\r\nDEPTH_FLUSH(16) | DEPTH_PENDING_FREE(4)));\r\nWREG32(PA_SC_MULTI_CHIP_CNTL, 0);\r\nWREG32(VGT_NUM_INSTANCES, 0);\r\nWREG32(SPI_CONFIG_CNTL, GPR_WRITE_PRIORITY(0));\r\nWREG32(SPI_CONFIG_CNTL_1, VTX_DONE_DELAY(0));\r\ntmp = RREG32(SQ_MS_FIFO_SIZES);\r\nif (((rdev->family) == CHIP_RV610) ||\r\n((rdev->family) == CHIP_RV620) ||\r\n((rdev->family) == CHIP_RS780) ||\r\n((rdev->family) == CHIP_RS880)) {\r\ntmp = (CACHE_FIFO_SIZE(0xa) |\r\nFETCH_FIFO_HIWATER(0xa) |\r\nDONE_FIFO_HIWATER(0xe0) |\r\nALU_UPDATE_FIFO_HIWATER(0x8));\r\n} else if (((rdev->family) == CHIP_R600) ||\r\n((rdev->family) == CHIP_RV630)) {\r\ntmp &= ~DONE_FIFO_HIWATER(0xff);\r\ntmp |= DONE_FIFO_HIWATER(0x4);\r\n}\r\nWREG32(SQ_MS_FIFO_SIZES, tmp);\r\nsq_config = RREG32(SQ_CONFIG);\r\nsq_config &= ~(PS_PRIO(3) |\r\nVS_PRIO(3) |\r\nGS_PRIO(3) |\r\nES_PRIO(3));\r\nsq_config |= (DX9_CONSTS |\r\nVC_ENABLE |\r\nPS_PRIO(0) |\r\nVS_PRIO(1) |\r\nGS_PRIO(2) |\r\nES_PRIO(3));\r\nif ((rdev->family) == CHIP_R600) {\r\nsq_gpr_resource_mgmt_1 = (NUM_PS_GPRS(124) |\r\nNUM_VS_GPRS(124) |\r\nNUM_CLAUSE_TEMP_GPRS(4));\r\nsq_gpr_resource_mgmt_2 = (NUM_GS_GPRS(0) |\r\nNUM_ES_GPRS(0));\r\nsq_thread_resource_mgmt = (NUM_PS_THREADS(136) |\r\nNUM_VS_THREADS(48) |\r\nNUM_GS_THREADS(4) |\r\nNUM_ES_THREADS(4));\r\nsq_stack_resource_mgmt_1 = (NUM_PS_STACK_ENTRIES(128) |\r\nNUM_VS_STACK_ENTRIES(128));\r\nsq_stack_resource_mgmt_2 = (NUM_GS_STACK_ENTRIES(0) |\r\nNUM_ES_STACK_ENTRIES(0));\r\n} else if (((rdev->family) == CHIP_RV610) ||\r\n((rdev->family) == CHIP_RV620) ||\r\n((rdev->family) == CHIP_RS780) ||\r\n((rdev->family) == CHIP_RS880)) {\r\nsq_config &= ~VC_ENABLE;\r\nsq_gpr_resource_mgmt_1 = (NUM_PS_GPRS(44) |\r\nNUM_VS_GPRS(44) |\r\nNUM_CLAUSE_TEMP_GPRS(2));\r\nsq_gpr_resource_mgmt_2 = (NUM_GS_GPRS(17) |\r\nNUM_ES_GPRS(17));\r\nsq_thread_resource_mgmt = (NUM_PS_THREADS(79) |\r\nNUM_VS_THREADS(78) |\r\nNUM_GS_THREADS(4) |\r\nNUM_ES_THREADS(31));\r\nsq_stack_resource_mgmt_1 = (NUM_PS_STACK_ENTRIES(40) |\r\nNUM_VS_STACK_ENTRIES(40));\r\nsq_stack_resource_mgmt_2 = (NUM_GS_STACK_ENTRIES(32) |\r\nNUM_ES_STACK_ENTRIES(16));\r\n} else if (((rdev->family) == CHIP_RV630) ||\r\n((rdev->family) == CHIP_RV635)) {\r\nsq_gpr_resource_mgmt_1 = (NUM_PS_GPRS(44) |\r\nNUM_VS_GPRS(44) |\r\nNUM_CLAUSE_TEMP_GPRS(2));\r\nsq_gpr_resource_mgmt_2 = (NUM_GS_GPRS(18) |\r\nNUM_ES_GPRS(18));\r\nsq_thread_resource_mgmt = (NUM_PS_THREADS(79) |\r\nNUM_VS_THREADS(78) |\r\nNUM_GS_THREADS(4) |\r\nNUM_ES_THREADS(31));\r\nsq_stack_resource_mgmt_1 = (NUM_PS_STACK_ENTRIES(40) |\r\nNUM_VS_STACK_ENTRIES(40));\r\nsq_stack_resource_mgmt_2 = (NUM_GS_STACK_ENTRIES(32) |\r\nNUM_ES_STACK_ENTRIES(16));\r\n} else if ((rdev->family) == CHIP_RV670) {\r\nsq_gpr_resource_mgmt_1 = (NUM_PS_GPRS(44) |\r\nNUM_VS_GPRS(44) |\r\nNUM_CLAUSE_TEMP_GPRS(2));\r\nsq_gpr_resource_mgmt_2 = (NUM_GS_GPRS(17) |\r\nNUM_ES_GPRS(17));\r\nsq_thread_resource_mgmt = (NUM_PS_THREADS(79) |\r\nNUM_VS_THREADS(78) |\r\nNUM_GS_THREADS(4) |\r\nNUM_ES_THREADS(31));\r\nsq_stack_resource_mgmt_1 = (NUM_PS_STACK_ENTRIES(64) |\r\nNUM_VS_STACK_ENTRIES(64));\r\nsq_stack_resource_mgmt_2 = (NUM_GS_STACK_ENTRIES(64) |\r\nNUM_ES_STACK_ENTRIES(64));\r\n}\r\nWREG32(SQ_CONFIG, sq_config);\r\nWREG32(SQ_GPR_RESOURCE_MGMT_1, sq_gpr_resource_mgmt_1);\r\nWREG32(SQ_GPR_RESOURCE_MGMT_2, sq_gpr_resource_mgmt_2);\r\nWREG32(SQ_THREAD_RESOURCE_MGMT, sq_thread_resource_mgmt);\r\nWREG32(SQ_STACK_RESOURCE_MGMT_1, sq_stack_resource_mgmt_1);\r\nWREG32(SQ_STACK_RESOURCE_MGMT_2, sq_stack_resource_mgmt_2);\r\nif (((rdev->family) == CHIP_RV610) ||\r\n((rdev->family) == CHIP_RV620) ||\r\n((rdev->family) == CHIP_RS780) ||\r\n((rdev->family) == CHIP_RS880)) {\r\nWREG32(VGT_CACHE_INVALIDATION, CACHE_INVALIDATION(TC_ONLY));\r\n} else {\r\nWREG32(VGT_CACHE_INVALIDATION, CACHE_INVALIDATION(VC_AND_TC));\r\n}\r\nWREG32(PA_SC_AA_SAMPLE_LOCS_2S, (S0_X(0xc) | S0_Y(0x4) |\r\nS1_X(0x4) | S1_Y(0xc)));\r\nWREG32(PA_SC_AA_SAMPLE_LOCS_4S, (S0_X(0xe) | S0_Y(0xe) |\r\nS1_X(0x2) | S1_Y(0x2) |\r\nS2_X(0xa) | S2_Y(0x6) |\r\nS3_X(0x6) | S3_Y(0xa)));\r\nWREG32(PA_SC_AA_SAMPLE_LOCS_8S_WD0, (S0_X(0xe) | S0_Y(0xb) |\r\nS1_X(0x4) | S1_Y(0xc) |\r\nS2_X(0x1) | S2_Y(0x6) |\r\nS3_X(0xa) | S3_Y(0xe)));\r\nWREG32(PA_SC_AA_SAMPLE_LOCS_8S_WD1, (S4_X(0x6) | S4_Y(0x1) |\r\nS5_X(0x0) | S5_Y(0x0) |\r\nS6_X(0xb) | S6_Y(0x4) |\r\nS7_X(0x7) | S7_Y(0x8)));\r\nWREG32(VGT_STRMOUT_EN, 0);\r\ntmp = rdev->config.r600.max_pipes * 16;\r\nswitch (rdev->family) {\r\ncase CHIP_RV610:\r\ncase CHIP_RV620:\r\ncase CHIP_RS780:\r\ncase CHIP_RS880:\r\ntmp += 32;\r\nbreak;\r\ncase CHIP_RV670:\r\ntmp += 128;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (tmp > 256) {\r\ntmp = 256;\r\n}\r\nWREG32(VGT_ES_PER_GS, 128);\r\nWREG32(VGT_GS_PER_ES, tmp);\r\nWREG32(VGT_GS_PER_VS, 2);\r\nWREG32(VGT_GS_VERTEX_REUSE, 16);\r\nWREG32(PA_SC_LINE_STIPPLE_STATE, 0);\r\nWREG32(VGT_STRMOUT_EN, 0);\r\nWREG32(SX_MISC, 0);\r\nWREG32(PA_SC_MODE_CNTL, 0);\r\nWREG32(PA_SC_AA_CONFIG, 0);\r\nWREG32(PA_SC_LINE_STIPPLE, 0);\r\nWREG32(SPI_INPUT_Z, 0);\r\nWREG32(SPI_PS_IN_CONTROL_0, NUM_INTERP(2));\r\nWREG32(CB_COLOR7_FRAG, 0);\r\nWREG32(CB_COLOR0_BASE, 0);\r\nWREG32(CB_COLOR1_BASE, 0);\r\nWREG32(CB_COLOR2_BASE, 0);\r\nWREG32(CB_COLOR3_BASE, 0);\r\nWREG32(CB_COLOR4_BASE, 0);\r\nWREG32(CB_COLOR5_BASE, 0);\r\nWREG32(CB_COLOR6_BASE, 0);\r\nWREG32(CB_COLOR7_BASE, 0);\r\nWREG32(CB_COLOR7_FRAG, 0);\r\nswitch (rdev->family) {\r\ncase CHIP_RV610:\r\ncase CHIP_RV620:\r\ncase CHIP_RS780:\r\ncase CHIP_RS880:\r\ntmp = TC_L2_SIZE(8);\r\nbreak;\r\ncase CHIP_RV630:\r\ncase CHIP_RV635:\r\ntmp = TC_L2_SIZE(4);\r\nbreak;\r\ncase CHIP_R600:\r\ntmp = TC_L2_SIZE(0) | L2_DISABLE_LATE_HIT;\r\nbreak;\r\ndefault:\r\ntmp = TC_L2_SIZE(0);\r\nbreak;\r\n}\r\nWREG32(TC_CNTL, tmp);\r\ntmp = RREG32(HDP_HOST_PATH_CNTL);\r\nWREG32(HDP_HOST_PATH_CNTL, tmp);\r\ntmp = RREG32(ARB_POP);\r\ntmp |= ENABLE_TC128;\r\nWREG32(ARB_POP, tmp);\r\nWREG32(PA_SC_MULTI_CHIP_CNTL, 0);\r\nWREG32(PA_CL_ENHANCE, (CLIP_VTX_REORDER_ENA |\r\nNUM_CLIP_SEQ(3)));\r\nWREG32(PA_SC_ENHANCE, FORCE_EOV_MAX_CLK_CNT(4095));\r\nWREG32(VC_ENHANCE, 0);\r\n}\r\nu32 r600_pciep_rreg(struct radeon_device *rdev, u32 reg)\r\n{\r\nunsigned long flags;\r\nu32 r;\r\nspin_lock_irqsave(&rdev->pciep_idx_lock, flags);\r\nWREG32(PCIE_PORT_INDEX, ((reg) & 0xff));\r\n(void)RREG32(PCIE_PORT_INDEX);\r\nr = RREG32(PCIE_PORT_DATA);\r\nspin_unlock_irqrestore(&rdev->pciep_idx_lock, flags);\r\nreturn r;\r\n}\r\nvoid r600_pciep_wreg(struct radeon_device *rdev, u32 reg, u32 v)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&rdev->pciep_idx_lock, flags);\r\nWREG32(PCIE_PORT_INDEX, ((reg) & 0xff));\r\n(void)RREG32(PCIE_PORT_INDEX);\r\nWREG32(PCIE_PORT_DATA, (v));\r\n(void)RREG32(PCIE_PORT_DATA);\r\nspin_unlock_irqrestore(&rdev->pciep_idx_lock, flags);\r\n}\r\nvoid r600_cp_stop(struct radeon_device *rdev)\r\n{\r\nif (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);\r\nWREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1));\r\nWREG32(SCRATCH_UMSK, 0);\r\nrdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;\r\n}\r\nint r600_init_microcode(struct radeon_device *rdev)\r\n{\r\nconst char *chip_name;\r\nconst char *rlc_chip_name;\r\nconst char *smc_chip_name = "RV770";\r\nsize_t pfp_req_size, me_req_size, rlc_req_size, smc_req_size = 0;\r\nchar fw_name[30];\r\nint err;\r\nDRM_DEBUG("\n");\r\nswitch (rdev->family) {\r\ncase CHIP_R600:\r\nchip_name = "R600";\r\nrlc_chip_name = "R600";\r\nbreak;\r\ncase CHIP_RV610:\r\nchip_name = "RV610";\r\nrlc_chip_name = "R600";\r\nbreak;\r\ncase CHIP_RV630:\r\nchip_name = "RV630";\r\nrlc_chip_name = "R600";\r\nbreak;\r\ncase CHIP_RV620:\r\nchip_name = "RV620";\r\nrlc_chip_name = "R600";\r\nbreak;\r\ncase CHIP_RV635:\r\nchip_name = "RV635";\r\nrlc_chip_name = "R600";\r\nbreak;\r\ncase CHIP_RV670:\r\nchip_name = "RV670";\r\nrlc_chip_name = "R600";\r\nbreak;\r\ncase CHIP_RS780:\r\ncase CHIP_RS880:\r\nchip_name = "RS780";\r\nrlc_chip_name = "R600";\r\nbreak;\r\ncase CHIP_RV770:\r\nchip_name = "RV770";\r\nrlc_chip_name = "R700";\r\nsmc_chip_name = "RV770";\r\nsmc_req_size = ALIGN(RV770_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_RV730:\r\nchip_name = "RV730";\r\nrlc_chip_name = "R700";\r\nsmc_chip_name = "RV730";\r\nsmc_req_size = ALIGN(RV730_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_RV710:\r\nchip_name = "RV710";\r\nrlc_chip_name = "R700";\r\nsmc_chip_name = "RV710";\r\nsmc_req_size = ALIGN(RV710_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_RV740:\r\nchip_name = "RV730";\r\nrlc_chip_name = "R700";\r\nsmc_chip_name = "RV740";\r\nsmc_req_size = ALIGN(RV740_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_CEDAR:\r\nchip_name = "CEDAR";\r\nrlc_chip_name = "CEDAR";\r\nsmc_chip_name = "CEDAR";\r\nsmc_req_size = ALIGN(CEDAR_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_REDWOOD:\r\nchip_name = "REDWOOD";\r\nrlc_chip_name = "REDWOOD";\r\nsmc_chip_name = "REDWOOD";\r\nsmc_req_size = ALIGN(REDWOOD_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_JUNIPER:\r\nchip_name = "JUNIPER";\r\nrlc_chip_name = "JUNIPER";\r\nsmc_chip_name = "JUNIPER";\r\nsmc_req_size = ALIGN(JUNIPER_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_CYPRESS:\r\ncase CHIP_HEMLOCK:\r\nchip_name = "CYPRESS";\r\nrlc_chip_name = "CYPRESS";\r\nsmc_chip_name = "CYPRESS";\r\nsmc_req_size = ALIGN(CYPRESS_SMC_UCODE_SIZE, 4);\r\nbreak;\r\ncase CHIP_PALM:\r\nchip_name = "PALM";\r\nrlc_chip_name = "SUMO";\r\nbreak;\r\ncase CHIP_SUMO:\r\nchip_name = "SUMO";\r\nrlc_chip_name = "SUMO";\r\nbreak;\r\ncase CHIP_SUMO2:\r\nchip_name = "SUMO2";\r\nrlc_chip_name = "SUMO";\r\nbreak;\r\ndefault: BUG();\r\n}\r\nif (rdev->family >= CHIP_CEDAR) {\r\npfp_req_size = EVERGREEN_PFP_UCODE_SIZE * 4;\r\nme_req_size = EVERGREEN_PM4_UCODE_SIZE * 4;\r\nrlc_req_size = EVERGREEN_RLC_UCODE_SIZE * 4;\r\n} else if (rdev->family >= CHIP_RV770) {\r\npfp_req_size = R700_PFP_UCODE_SIZE * 4;\r\nme_req_size = R700_PM4_UCODE_SIZE * 4;\r\nrlc_req_size = R700_RLC_UCODE_SIZE * 4;\r\n} else {\r\npfp_req_size = R600_PFP_UCODE_SIZE * 4;\r\nme_req_size = R600_PM4_UCODE_SIZE * 12;\r\nrlc_req_size = R600_RLC_UCODE_SIZE * 4;\r\n}\r\nDRM_INFO("Loading %s Microcode\n", chip_name);\r\nsnprintf(fw_name, sizeof(fw_name), "radeon/%s_pfp.bin", chip_name);\r\nerr = request_firmware(&rdev->pfp_fw, fw_name, rdev->dev);\r\nif (err)\r\ngoto out;\r\nif (rdev->pfp_fw->size != pfp_req_size) {\r\nprintk(KERN_ERR\r\n"r600_cp: Bogus length %zu in firmware \"%s\"\n",\r\nrdev->pfp_fw->size, fw_name);\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\nsnprintf(fw_name, sizeof(fw_name), "radeon/%s_me.bin", chip_name);\r\nerr = request_firmware(&rdev->me_fw, fw_name, rdev->dev);\r\nif (err)\r\ngoto out;\r\nif (rdev->me_fw->size != me_req_size) {\r\nprintk(KERN_ERR\r\n"r600_cp: Bogus length %zu in firmware \"%s\"\n",\r\nrdev->me_fw->size, fw_name);\r\nerr = -EINVAL;\r\n}\r\nsnprintf(fw_name, sizeof(fw_name), "radeon/%s_rlc.bin", rlc_chip_name);\r\nerr = request_firmware(&rdev->rlc_fw, fw_name, rdev->dev);\r\nif (err)\r\ngoto out;\r\nif (rdev->rlc_fw->size != rlc_req_size) {\r\nprintk(KERN_ERR\r\n"r600_rlc: Bogus length %zu in firmware \"%s\"\n",\r\nrdev->rlc_fw->size, fw_name);\r\nerr = -EINVAL;\r\n}\r\nif ((rdev->family >= CHIP_RV770) && (rdev->family <= CHIP_HEMLOCK)) {\r\nsnprintf(fw_name, sizeof(fw_name), "radeon/%s_smc.bin", smc_chip_name);\r\nerr = request_firmware(&rdev->smc_fw, fw_name, rdev->dev);\r\nif (err) {\r\nprintk(KERN_ERR\r\n"smc: error loading firmware \"%s\"\n",\r\nfw_name);\r\nrelease_firmware(rdev->smc_fw);\r\nrdev->smc_fw = NULL;\r\nerr = 0;\r\n} else if (rdev->smc_fw->size != smc_req_size) {\r\nprintk(KERN_ERR\r\n"smc: Bogus length %zu in firmware \"%s\"\n",\r\nrdev->smc_fw->size, fw_name);\r\nerr = -EINVAL;\r\n}\r\n}\r\nout:\r\nif (err) {\r\nif (err != -EINVAL)\r\nprintk(KERN_ERR\r\n"r600_cp: Failed to load firmware \"%s\"\n",\r\nfw_name);\r\nrelease_firmware(rdev->pfp_fw);\r\nrdev->pfp_fw = NULL;\r\nrelease_firmware(rdev->me_fw);\r\nrdev->me_fw = NULL;\r\nrelease_firmware(rdev->rlc_fw);\r\nrdev->rlc_fw = NULL;\r\nrelease_firmware(rdev->smc_fw);\r\nrdev->smc_fw = NULL;\r\n}\r\nreturn err;\r\n}\r\nu32 r600_gfx_get_rptr(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nu32 rptr;\r\nif (rdev->wb.enabled)\r\nrptr = rdev->wb.wb[ring->rptr_offs/4];\r\nelse\r\nrptr = RREG32(R600_CP_RB_RPTR);\r\nreturn rptr;\r\n}\r\nu32 r600_gfx_get_wptr(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nu32 wptr;\r\nwptr = RREG32(R600_CP_RB_WPTR);\r\nreturn wptr;\r\n}\r\nvoid r600_gfx_set_wptr(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nWREG32(R600_CP_RB_WPTR, ring->wptr);\r\n(void)RREG32(R600_CP_RB_WPTR);\r\n}\r\nstatic int r600_cp_load_microcode(struct radeon_device *rdev)\r\n{\r\nconst __be32 *fw_data;\r\nint i;\r\nif (!rdev->me_fw || !rdev->pfp_fw)\r\nreturn -EINVAL;\r\nr600_cp_stop(rdev);\r\nWREG32(CP_RB_CNTL,\r\n#ifdef __BIG_ENDIAN\r\nBUF_SWAP_32BIT |\r\n#endif\r\nRB_NO_UPDATE | RB_BLKSZ(15) | RB_BUFSZ(3));\r\nWREG32(GRBM_SOFT_RESET, SOFT_RESET_CP);\r\nRREG32(GRBM_SOFT_RESET);\r\nmdelay(15);\r\nWREG32(GRBM_SOFT_RESET, 0);\r\nWREG32(CP_ME_RAM_WADDR, 0);\r\nfw_data = (const __be32 *)rdev->me_fw->data;\r\nWREG32(CP_ME_RAM_WADDR, 0);\r\nfor (i = 0; i < R600_PM4_UCODE_SIZE * 3; i++)\r\nWREG32(CP_ME_RAM_DATA,\r\nbe32_to_cpup(fw_data++));\r\nfw_data = (const __be32 *)rdev->pfp_fw->data;\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nfor (i = 0; i < R600_PFP_UCODE_SIZE; i++)\r\nWREG32(CP_PFP_UCODE_DATA,\r\nbe32_to_cpup(fw_data++));\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nWREG32(CP_ME_RAM_WADDR, 0);\r\nWREG32(CP_ME_RAM_RADDR, 0);\r\nreturn 0;\r\n}\r\nint r600_cp_start(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nint r;\r\nuint32_t cp_me;\r\nr = radeon_ring_lock(rdev, ring, 7);\r\nif (r) {\r\nDRM_ERROR("radeon: cp failed to lock ring (%d).\n", r);\r\nreturn r;\r\n}\r\nradeon_ring_write(ring, PACKET3(PACKET3_ME_INITIALIZE, 5));\r\nradeon_ring_write(ring, 0x1);\r\nif (rdev->family >= CHIP_RV770) {\r\nradeon_ring_write(ring, 0x0);\r\nradeon_ring_write(ring, rdev->config.rv770.max_hw_contexts - 1);\r\n} else {\r\nradeon_ring_write(ring, 0x3);\r\nradeon_ring_write(ring, rdev->config.r600.max_hw_contexts - 1);\r\n}\r\nradeon_ring_write(ring, PACKET3_ME_INITIALIZE_DEVICE_ID(1));\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\ncp_me = 0xff;\r\nWREG32(R_0086D8_CP_ME_CNTL, cp_me);\r\nreturn 0;\r\n}\r\nint r600_cp_resume(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nu32 tmp;\r\nu32 rb_bufsz;\r\nint r;\r\nWREG32(GRBM_SOFT_RESET, SOFT_RESET_CP);\r\nRREG32(GRBM_SOFT_RESET);\r\nmdelay(15);\r\nWREG32(GRBM_SOFT_RESET, 0);\r\nrb_bufsz = order_base_2(ring->ring_size / 8);\r\ntmp = (order_base_2(RADEON_GPU_PAGE_SIZE/8) << 8) | rb_bufsz;\r\n#ifdef __BIG_ENDIAN\r\ntmp |= BUF_SWAP_32BIT;\r\n#endif\r\nWREG32(CP_RB_CNTL, tmp);\r\nWREG32(CP_SEM_WAIT_TIMER, 0x0);\r\nWREG32(CP_RB_WPTR_DELAY, 0);\r\nWREG32(CP_RB_CNTL, tmp | RB_RPTR_WR_ENA);\r\nWREG32(CP_RB_RPTR_WR, 0);\r\nring->wptr = 0;\r\nWREG32(CP_RB_WPTR, ring->wptr);\r\nWREG32(CP_RB_RPTR_ADDR,\r\n((rdev->wb.gpu_addr + RADEON_WB_CP_RPTR_OFFSET) & 0xFFFFFFFC));\r\nWREG32(CP_RB_RPTR_ADDR_HI, upper_32_bits(rdev->wb.gpu_addr + RADEON_WB_CP_RPTR_OFFSET) & 0xFF);\r\nWREG32(SCRATCH_ADDR, ((rdev->wb.gpu_addr + RADEON_WB_SCRATCH_OFFSET) >> 8) & 0xFFFFFFFF);\r\nif (rdev->wb.enabled)\r\nWREG32(SCRATCH_UMSK, 0xff);\r\nelse {\r\ntmp |= RB_NO_UPDATE;\r\nWREG32(SCRATCH_UMSK, 0);\r\n}\r\nmdelay(1);\r\nWREG32(CP_RB_CNTL, tmp);\r\nWREG32(CP_RB_BASE, ring->gpu_addr >> 8);\r\nWREG32(CP_DEBUG, (1 << 27) | (1 << 28));\r\nr600_cp_start(rdev);\r\nring->ready = true;\r\nr = radeon_ring_test(rdev, RADEON_RING_TYPE_GFX_INDEX, ring);\r\nif (r) {\r\nring->ready = false;\r\nreturn r;\r\n}\r\nif (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);\r\nreturn 0;\r\n}\r\nvoid r600_ring_init(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ring_size)\r\n{\r\nu32 rb_bufsz;\r\nint r;\r\nrb_bufsz = order_base_2(ring_size / 8);\r\nring_size = (1 << (rb_bufsz + 1)) * 4;\r\nring->ring_size = ring_size;\r\nring->align_mask = 16 - 1;\r\nif (radeon_ring_supports_scratch_reg(rdev, ring)) {\r\nr = radeon_scratch_get(rdev, &ring->rptr_save_reg);\r\nif (r) {\r\nDRM_ERROR("failed to get scratch reg for rptr save (%d).\n", r);\r\nring->rptr_save_reg = 0;\r\n}\r\n}\r\n}\r\nvoid r600_cp_fini(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nr600_cp_stop(rdev);\r\nradeon_ring_fini(rdev, ring);\r\nradeon_scratch_free(rdev, ring->rptr_save_reg);\r\n}\r\nvoid r600_scratch_init(struct radeon_device *rdev)\r\n{\r\nint i;\r\nrdev->scratch.num_reg = 7;\r\nrdev->scratch.reg_base = SCRATCH_REG0;\r\nfor (i = 0; i < rdev->scratch.num_reg; i++) {\r\nrdev->scratch.free[i] = true;\r\nrdev->scratch.reg[i] = rdev->scratch.reg_base + (i * 4);\r\n}\r\n}\r\nint r600_ring_test(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nuint32_t scratch;\r\nuint32_t tmp = 0;\r\nunsigned i;\r\nint r;\r\nr = radeon_scratch_get(rdev, &scratch);\r\nif (r) {\r\nDRM_ERROR("radeon: cp failed to get scratch reg (%d).\n", r);\r\nreturn r;\r\n}\r\nWREG32(scratch, 0xCAFEDEAD);\r\nr = radeon_ring_lock(rdev, ring, 3);\r\nif (r) {\r\nDRM_ERROR("radeon: cp failed to lock ring %d (%d).\n", ring->idx, r);\r\nradeon_scratch_free(rdev, scratch);\r\nreturn r;\r\n}\r\nradeon_ring_write(ring, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(ring, ((scratch - PACKET3_SET_CONFIG_REG_OFFSET) >> 2));\r\nradeon_ring_write(ring, 0xDEADBEEF);\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(scratch);\r\nif (tmp == 0xDEADBEEF)\r\nbreak;\r\nDRM_UDELAY(1);\r\n}\r\nif (i < rdev->usec_timeout) {\r\nDRM_INFO("ring test on %d succeeded in %d usecs\n", ring->idx, i);\r\n} else {\r\nDRM_ERROR("radeon: ring %d test failed (scratch(0x%04X)=0x%08X)\n",\r\nring->idx, scratch, tmp);\r\nr = -EINVAL;\r\n}\r\nradeon_scratch_free(rdev, scratch);\r\nreturn r;\r\n}\r\nvoid r600_fence_ring_emit(struct radeon_device *rdev,\r\nstruct radeon_fence *fence)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[fence->ring];\r\nu32 cp_coher_cntl = PACKET3_TC_ACTION_ENA | PACKET3_VC_ACTION_ENA |\r\nPACKET3_SH_ACTION_ENA;\r\nif (rdev->family >= CHIP_RV770)\r\ncp_coher_cntl |= PACKET3_FULL_CACHE_ENA;\r\nif (rdev->wb.use_event) {\r\nu64 addr = rdev->fence_drv[fence->ring].gpu_addr;\r\nradeon_ring_write(ring, PACKET3(PACKET3_SURFACE_SYNC, 3));\r\nradeon_ring_write(ring, cp_coher_cntl);\r\nradeon_ring_write(ring, 0xFFFFFFFF);\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_write(ring, 10);\r\nradeon_ring_write(ring, PACKET3(PACKET3_EVENT_WRITE_EOP, 4));\r\nradeon_ring_write(ring, EVENT_TYPE(CACHE_FLUSH_AND_INV_EVENT_TS) | EVENT_INDEX(5));\r\nradeon_ring_write(ring, lower_32_bits(addr));\r\nradeon_ring_write(ring, (upper_32_bits(addr) & 0xff) | DATA_SEL(1) | INT_SEL(2));\r\nradeon_ring_write(ring, fence->seq);\r\nradeon_ring_write(ring, 0);\r\n} else {\r\nradeon_ring_write(ring, PACKET3(PACKET3_SURFACE_SYNC, 3));\r\nradeon_ring_write(ring, cp_coher_cntl);\r\nradeon_ring_write(ring, 0xFFFFFFFF);\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_write(ring, 10);\r\nradeon_ring_write(ring, PACKET3(PACKET3_EVENT_WRITE, 0));\r\nradeon_ring_write(ring, EVENT_TYPE(CACHE_FLUSH_AND_INV_EVENT) | EVENT_INDEX(0));\r\nradeon_ring_write(ring, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(ring, (WAIT_UNTIL - PACKET3_SET_CONFIG_REG_OFFSET) >> 2);\r\nradeon_ring_write(ring, WAIT_3D_IDLE_bit | WAIT_3D_IDLECLEAN_bit);\r\nradeon_ring_write(ring, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(ring, ((rdev->fence_drv[fence->ring].scratch_reg - PACKET3_SET_CONFIG_REG_OFFSET) >> 2));\r\nradeon_ring_write(ring, fence->seq);\r\nradeon_ring_write(ring, PACKET0(CP_INT_STATUS, 0));\r\nradeon_ring_write(ring, RB_INT_STAT);\r\n}\r\n}\r\nbool r600_semaphore_ring_emit(struct radeon_device *rdev,\r\nstruct radeon_ring *ring,\r\nstruct radeon_semaphore *semaphore,\r\nbool emit_wait)\r\n{\r\nuint64_t addr = semaphore->gpu_addr;\r\nunsigned sel = emit_wait ? PACKET3_SEM_SEL_WAIT : PACKET3_SEM_SEL_SIGNAL;\r\nif (rdev->family < CHIP_CAYMAN)\r\nsel |= PACKET3_SEM_WAIT_ON_SIGNAL;\r\nradeon_ring_write(ring, PACKET3(PACKET3_MEM_SEMAPHORE, 1));\r\nradeon_ring_write(ring, lower_32_bits(addr));\r\nradeon_ring_write(ring, (upper_32_bits(addr) & 0xff) | sel);\r\nif (emit_wait && (rdev->family >= CHIP_CEDAR)) {\r\nradeon_ring_write(ring, PACKET3(PACKET3_PFP_SYNC_ME, 0));\r\nradeon_ring_write(ring, 0x0);\r\n}\r\nreturn true;\r\n}\r\nstruct radeon_fence *r600_copy_cpdma(struct radeon_device *rdev,\r\nuint64_t src_offset, uint64_t dst_offset,\r\nunsigned num_gpu_pages,\r\nstruct reservation_object *resv)\r\n{\r\nstruct radeon_fence *fence;\r\nstruct radeon_sync sync;\r\nint ring_index = rdev->asic->copy.blit_ring_index;\r\nstruct radeon_ring *ring = &rdev->ring[ring_index];\r\nu32 size_in_bytes, cur_size_in_bytes, tmp;\r\nint i, num_loops;\r\nint r = 0;\r\nradeon_sync_create(&sync);\r\nsize_in_bytes = (num_gpu_pages << RADEON_GPU_PAGE_SHIFT);\r\nnum_loops = DIV_ROUND_UP(size_in_bytes, 0x1fffff);\r\nr = radeon_ring_lock(rdev, ring, num_loops * 6 + 24);\r\nif (r) {\r\nDRM_ERROR("radeon: moving bo (%d).\n", r);\r\nradeon_sync_free(rdev, &sync, NULL);\r\nreturn ERR_PTR(r);\r\n}\r\nradeon_sync_resv(rdev, &sync, resv, false);\r\nradeon_sync_rings(rdev, &sync, ring->idx);\r\nradeon_ring_write(ring, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(ring, (WAIT_UNTIL - PACKET3_SET_CONFIG_REG_OFFSET) >> 2);\r\nradeon_ring_write(ring, WAIT_3D_IDLE_bit);\r\nfor (i = 0; i < num_loops; i++) {\r\ncur_size_in_bytes = size_in_bytes;\r\nif (cur_size_in_bytes > 0x1fffff)\r\ncur_size_in_bytes = 0x1fffff;\r\nsize_in_bytes -= cur_size_in_bytes;\r\ntmp = upper_32_bits(src_offset) & 0xff;\r\nif (size_in_bytes == 0)\r\ntmp |= PACKET3_CP_DMA_CP_SYNC;\r\nradeon_ring_write(ring, PACKET3(PACKET3_CP_DMA, 4));\r\nradeon_ring_write(ring, lower_32_bits(src_offset));\r\nradeon_ring_write(ring, tmp);\r\nradeon_ring_write(ring, lower_32_bits(dst_offset));\r\nradeon_ring_write(ring, upper_32_bits(dst_offset) & 0xff);\r\nradeon_ring_write(ring, cur_size_in_bytes);\r\nsrc_offset += cur_size_in_bytes;\r\ndst_offset += cur_size_in_bytes;\r\n}\r\nradeon_ring_write(ring, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(ring, (WAIT_UNTIL - PACKET3_SET_CONFIG_REG_OFFSET) >> 2);\r\nradeon_ring_write(ring, WAIT_CP_DMA_IDLE_bit);\r\nr = radeon_fence_emit(rdev, &fence, ring->idx);\r\nif (r) {\r\nradeon_ring_unlock_undo(rdev, ring);\r\nradeon_sync_free(rdev, &sync, NULL);\r\nreturn ERR_PTR(r);\r\n}\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\nradeon_sync_free(rdev, &sync, fence);\r\nreturn fence;\r\n}\r\nint r600_set_surface_reg(struct radeon_device *rdev, int reg,\r\nuint32_t tiling_flags, uint32_t pitch,\r\nuint32_t offset, uint32_t obj_size)\r\n{\r\nreturn 0;\r\n}\r\nvoid r600_clear_surface_reg(struct radeon_device *rdev, int reg)\r\n{\r\n}\r\nstatic int r600_startup(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring;\r\nint r;\r\nr600_pcie_gen2_enable(rdev);\r\nr = r600_vram_scratch_init(rdev);\r\nif (r)\r\nreturn r;\r\nr600_mc_program(rdev);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nr600_agp_enable(rdev);\r\n} else {\r\nr = r600_pcie_gart_enable(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nr600_gpu_init(rdev);\r\nr = radeon_wb_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_fence_driver_start_ring(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing CP fences (%d).\n", r);\r\nreturn r;\r\n}\r\nif (rdev->has_uvd) {\r\nr = uvd_v1_0_resume(rdev);\r\nif (!r) {\r\nr = radeon_fence_driver_start_ring(rdev, R600_RING_TYPE_UVD_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing UVD fences (%d).\n", r);\r\n}\r\n}\r\nif (r)\r\nrdev->ring[R600_RING_TYPE_UVD_INDEX].ring_size = 0;\r\n}\r\nif (!rdev->irq.installed) {\r\nr = radeon_irq_kms_init(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nr = r600_irq_init(rdev);\r\nif (r) {\r\nDRM_ERROR("radeon: IH init failed (%d).\n", r);\r\nradeon_irq_kms_fini(rdev);\r\nreturn r;\r\n}\r\nr600_irq_set(rdev);\r\nring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,\r\nRADEON_CP_PACKET2);\r\nif (r)\r\nreturn r;\r\nr = r600_cp_load_microcode(rdev);\r\nif (r)\r\nreturn r;\r\nr = r600_cp_resume(rdev);\r\nif (r)\r\nreturn r;\r\nif (rdev->has_uvd) {\r\nring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];\r\nif (ring->ring_size) {\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, 0,\r\nRADEON_CP_PACKET2);\r\nif (!r)\r\nr = uvd_v1_0_init(rdev);\r\nif (r)\r\nDRM_ERROR("radeon: failed initializing UVD (%d).\n", r);\r\n}\r\n}\r\nr = radeon_ib_pool_init(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "IB initialization failed (%d).\n", r);\r\nreturn r;\r\n}\r\nr = radeon_audio_init(rdev);\r\nif (r) {\r\nDRM_ERROR("radeon: audio init failed\n");\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nvoid r600_vga_set_state(struct radeon_device *rdev, bool state)\r\n{\r\nuint32_t temp;\r\ntemp = RREG32(CONFIG_CNTL);\r\nif (state == false) {\r\ntemp &= ~(1<<0);\r\ntemp |= (1<<1);\r\n} else {\r\ntemp &= ~(1<<1);\r\n}\r\nWREG32(CONFIG_CNTL, temp);\r\n}\r\nint r600_resume(struct radeon_device *rdev)\r\n{\r\nint r;\r\natom_asic_init(rdev->mode_info.atom_context);\r\nif (rdev->pm.pm_method == PM_METHOD_DPM)\r\nradeon_pm_resume(rdev);\r\nrdev->accel_working = true;\r\nr = r600_startup(rdev);\r\nif (r) {\r\nDRM_ERROR("r600 startup failed on resume\n");\r\nrdev->accel_working = false;\r\nreturn r;\r\n}\r\nreturn r;\r\n}\r\nint r600_suspend(struct radeon_device *rdev)\r\n{\r\nradeon_pm_suspend(rdev);\r\nradeon_audio_fini(rdev);\r\nr600_cp_stop(rdev);\r\nif (rdev->has_uvd) {\r\nuvd_v1_0_fini(rdev);\r\nradeon_uvd_suspend(rdev);\r\n}\r\nr600_irq_suspend(rdev);\r\nradeon_wb_disable(rdev);\r\nr600_pcie_gart_disable(rdev);\r\nreturn 0;\r\n}\r\nint r600_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (r600_debugfs_mc_info_init(rdev)) {\r\nDRM_ERROR("Failed to register debugfs file for mc !\n");\r\n}\r\nif (!radeon_get_bios(rdev)) {\r\nif (ASIC_IS_AVIVO(rdev))\r\nreturn -EINVAL;\r\n}\r\nif (!rdev->is_atom_bios) {\r\ndev_err(rdev->dev, "Expecting atombios for R600 GPU\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_atombios_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (!radeon_card_posted(rdev)) {\r\nif (!rdev->bios) {\r\ndev_err(rdev->dev, "Card not posted and no BIOS - ignoring\n");\r\nreturn -EINVAL;\r\n}\r\nDRM_INFO("GPU not posted. posting now...\n");\r\natom_asic_init(rdev->mode_info.atom_context);\r\n}\r\nr600_scratch_init(rdev);\r\nradeon_surface_init(rdev);\r\nradeon_get_clock_info(rdev->ddev);\r\nr = radeon_fence_driver_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nr = radeon_agp_init(rdev);\r\nif (r)\r\nradeon_agp_disable(rdev);\r\n}\r\nr = r600_mc_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_bo_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (!rdev->me_fw || !rdev->pfp_fw || !rdev->rlc_fw) {\r\nr = r600_init_microcode(rdev);\r\nif (r) {\r\nDRM_ERROR("Failed to load firmware!\n");\r\nreturn r;\r\n}\r\n}\r\nradeon_pm_init(rdev);\r\nrdev->ring[RADEON_RING_TYPE_GFX_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX], 1024 * 1024);\r\nif (rdev->has_uvd) {\r\nr = radeon_uvd_init(rdev);\r\nif (!r) {\r\nrdev->ring[R600_RING_TYPE_UVD_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[R600_RING_TYPE_UVD_INDEX], 4096);\r\n}\r\n}\r\nrdev->ih.ring_obj = NULL;\r\nr600_ih_ring_init(rdev, 64 * 1024);\r\nr = r600_pcie_gart_init(rdev);\r\nif (r)\r\nreturn r;\r\nrdev->accel_working = true;\r\nr = r600_startup(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "disabling GPU acceleration\n");\r\nr600_cp_fini(rdev);\r\nr600_irq_fini(rdev);\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nr600_pcie_gart_fini(rdev);\r\nrdev->accel_working = false;\r\n}\r\nreturn 0;\r\n}\r\nvoid r600_fini(struct radeon_device *rdev)\r\n{\r\nradeon_pm_fini(rdev);\r\nradeon_audio_fini(rdev);\r\nr600_cp_fini(rdev);\r\nr600_irq_fini(rdev);\r\nif (rdev->has_uvd) {\r\nuvd_v1_0_fini(rdev);\r\nradeon_uvd_fini(rdev);\r\n}\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nr600_pcie_gart_fini(rdev);\r\nr600_vram_scratch_fini(rdev);\r\nradeon_agp_fini(rdev);\r\nradeon_gem_fini(rdev);\r\nradeon_fence_driver_fini(rdev);\r\nradeon_bo_fini(rdev);\r\nradeon_atombios_fini(rdev);\r\nkfree(rdev->bios);\r\nrdev->bios = NULL;\r\n}\r\nvoid r600_ring_ib_execute(struct radeon_device *rdev, struct radeon_ib *ib)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[ib->ring];\r\nu32 next_rptr;\r\nif (ring->rptr_save_reg) {\r\nnext_rptr = ring->wptr + 3 + 4;\r\nradeon_ring_write(ring, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(ring, ((ring->rptr_save_reg -\r\nPACKET3_SET_CONFIG_REG_OFFSET) >> 2));\r\nradeon_ring_write(ring, next_rptr);\r\n} else if (rdev->wb.enabled) {\r\nnext_rptr = ring->wptr + 5 + 4;\r\nradeon_ring_write(ring, PACKET3(PACKET3_MEM_WRITE, 3));\r\nradeon_ring_write(ring, ring->next_rptr_gpu_addr & 0xfffffffc);\r\nradeon_ring_write(ring, (upper_32_bits(ring->next_rptr_gpu_addr) & 0xff) | (1 << 18));\r\nradeon_ring_write(ring, next_rptr);\r\nradeon_ring_write(ring, 0);\r\n}\r\nradeon_ring_write(ring, PACKET3(PACKET3_INDIRECT_BUFFER, 2));\r\nradeon_ring_write(ring,\r\n#ifdef __BIG_ENDIAN\r\n(2 << 0) |\r\n#endif\r\n(ib->gpu_addr & 0xFFFFFFFC));\r\nradeon_ring_write(ring, upper_32_bits(ib->gpu_addr) & 0xFF);\r\nradeon_ring_write(ring, ib->length_dw);\r\n}\r\nint r600_ib_test(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nstruct radeon_ib ib;\r\nuint32_t scratch;\r\nuint32_t tmp = 0;\r\nunsigned i;\r\nint r;\r\nr = radeon_scratch_get(rdev, &scratch);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to get scratch reg (%d).\n", r);\r\nreturn r;\r\n}\r\nWREG32(scratch, 0xCAFEDEAD);\r\nr = radeon_ib_get(rdev, ring->idx, &ib, NULL, 256);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to get ib (%d).\n", r);\r\ngoto free_scratch;\r\n}\r\nib.ptr[0] = PACKET3(PACKET3_SET_CONFIG_REG, 1);\r\nib.ptr[1] = ((scratch - PACKET3_SET_CONFIG_REG_OFFSET) >> 2);\r\nib.ptr[2] = 0xDEADBEEF;\r\nib.length_dw = 3;\r\nr = radeon_ib_schedule(rdev, &ib, NULL, false);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to schedule ib (%d).\n", r);\r\ngoto free_ib;\r\n}\r\nr = radeon_fence_wait(ib.fence, false);\r\nif (r) {\r\nDRM_ERROR("radeon: fence wait failed (%d).\n", r);\r\ngoto free_ib;\r\n}\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(scratch);\r\nif (tmp == 0xDEADBEEF)\r\nbreak;\r\nDRM_UDELAY(1);\r\n}\r\nif (i < rdev->usec_timeout) {\r\nDRM_INFO("ib test on ring %d succeeded in %u usecs\n", ib.fence->ring, i);\r\n} else {\r\nDRM_ERROR("radeon: ib test failed (scratch(0x%04X)=0x%08X)\n",\r\nscratch, tmp);\r\nr = -EINVAL;\r\n}\r\nfree_ib:\r\nradeon_ib_free(rdev, &ib);\r\nfree_scratch:\r\nradeon_scratch_free(rdev, scratch);\r\nreturn r;\r\n}\r\nvoid r600_ih_ring_init(struct radeon_device *rdev, unsigned ring_size)\r\n{\r\nu32 rb_bufsz;\r\nrb_bufsz = order_base_2(ring_size / 4);\r\nring_size = (1 << rb_bufsz) * 4;\r\nrdev->ih.ring_size = ring_size;\r\nrdev->ih.ptr_mask = rdev->ih.ring_size - 1;\r\nrdev->ih.rptr = 0;\r\n}\r\nint r600_ih_ring_alloc(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->ih.ring_obj == NULL) {\r\nr = radeon_bo_create(rdev, rdev->ih.ring_size,\r\nPAGE_SIZE, true,\r\nRADEON_GEM_DOMAIN_GTT, 0,\r\nNULL, NULL, &rdev->ih.ring_obj);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to create ih ring buffer (%d).\n", r);\r\nreturn r;\r\n}\r\nr = radeon_bo_reserve(rdev->ih.ring_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_pin(rdev->ih.ring_obj,\r\nRADEON_GEM_DOMAIN_GTT,\r\n&rdev->ih.gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(rdev->ih.ring_obj);\r\nDRM_ERROR("radeon: failed to pin ih ring buffer (%d).\n", r);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(rdev->ih.ring_obj,\r\n(void **)&rdev->ih.ring);\r\nradeon_bo_unreserve(rdev->ih.ring_obj);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to map ih ring buffer (%d).\n", r);\r\nreturn r;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid r600_ih_ring_fini(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->ih.ring_obj) {\r\nr = radeon_bo_reserve(rdev->ih.ring_obj, false);\r\nif (likely(r == 0)) {\r\nradeon_bo_kunmap(rdev->ih.ring_obj);\r\nradeon_bo_unpin(rdev->ih.ring_obj);\r\nradeon_bo_unreserve(rdev->ih.ring_obj);\r\n}\r\nradeon_bo_unref(&rdev->ih.ring_obj);\r\nrdev->ih.ring = NULL;\r\nrdev->ih.ring_obj = NULL;\r\n}\r\n}\r\nvoid r600_rlc_stop(struct radeon_device *rdev)\r\n{\r\nif ((rdev->family >= CHIP_RV770) &&\r\n(rdev->family <= CHIP_RV740)) {\r\nWREG32(SRBM_SOFT_RESET, SOFT_RESET_RLC);\r\nRREG32(SRBM_SOFT_RESET);\r\nmdelay(15);\r\nWREG32(SRBM_SOFT_RESET, 0);\r\nRREG32(SRBM_SOFT_RESET);\r\n}\r\nWREG32(RLC_CNTL, 0);\r\n}\r\nstatic void r600_rlc_start(struct radeon_device *rdev)\r\n{\r\nWREG32(RLC_CNTL, RLC_ENABLE);\r\n}\r\nstatic int r600_rlc_resume(struct radeon_device *rdev)\r\n{\r\nu32 i;\r\nconst __be32 *fw_data;\r\nif (!rdev->rlc_fw)\r\nreturn -EINVAL;\r\nr600_rlc_stop(rdev);\r\nWREG32(RLC_HB_CNTL, 0);\r\nWREG32(RLC_HB_BASE, 0);\r\nWREG32(RLC_HB_RPTR, 0);\r\nWREG32(RLC_HB_WPTR, 0);\r\nWREG32(RLC_HB_WPTR_LSB_ADDR, 0);\r\nWREG32(RLC_HB_WPTR_MSB_ADDR, 0);\r\nWREG32(RLC_MC_CNTL, 0);\r\nWREG32(RLC_UCODE_CNTL, 0);\r\nfw_data = (const __be32 *)rdev->rlc_fw->data;\r\nif (rdev->family >= CHIP_RV770) {\r\nfor (i = 0; i < R700_RLC_UCODE_SIZE; i++) {\r\nWREG32(RLC_UCODE_ADDR, i);\r\nWREG32(RLC_UCODE_DATA, be32_to_cpup(fw_data++));\r\n}\r\n} else {\r\nfor (i = 0; i < R600_RLC_UCODE_SIZE; i++) {\r\nWREG32(RLC_UCODE_ADDR, i);\r\nWREG32(RLC_UCODE_DATA, be32_to_cpup(fw_data++));\r\n}\r\n}\r\nWREG32(RLC_UCODE_ADDR, 0);\r\nr600_rlc_start(rdev);\r\nreturn 0;\r\n}\r\nstatic void r600_enable_interrupts(struct radeon_device *rdev)\r\n{\r\nu32 ih_cntl = RREG32(IH_CNTL);\r\nu32 ih_rb_cntl = RREG32(IH_RB_CNTL);\r\nih_cntl |= ENABLE_INTR;\r\nih_rb_cntl |= IH_RB_ENABLE;\r\nWREG32(IH_CNTL, ih_cntl);\r\nWREG32(IH_RB_CNTL, ih_rb_cntl);\r\nrdev->ih.enabled = true;\r\n}\r\nvoid r600_disable_interrupts(struct radeon_device *rdev)\r\n{\r\nu32 ih_rb_cntl = RREG32(IH_RB_CNTL);\r\nu32 ih_cntl = RREG32(IH_CNTL);\r\nih_rb_cntl &= ~IH_RB_ENABLE;\r\nih_cntl &= ~ENABLE_INTR;\r\nWREG32(IH_RB_CNTL, ih_rb_cntl);\r\nWREG32(IH_CNTL, ih_cntl);\r\nWREG32(IH_RB_RPTR, 0);\r\nWREG32(IH_RB_WPTR, 0);\r\nrdev->ih.enabled = false;\r\nrdev->ih.rptr = 0;\r\n}\r\nstatic void r600_disable_interrupt_state(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nWREG32(CP_INT_CNTL, CNTX_BUSY_INT_ENABLE | CNTX_EMPTY_INT_ENABLE);\r\ntmp = RREG32(DMA_CNTL) & ~TRAP_ENABLE;\r\nWREG32(DMA_CNTL, tmp);\r\nWREG32(GRBM_INT_CNTL, 0);\r\nWREG32(DxMODE_INT_MASK, 0);\r\nWREG32(D1GRPH_INTERRUPT_CONTROL, 0);\r\nWREG32(D2GRPH_INTERRUPT_CONTROL, 0);\r\nif (ASIC_IS_DCE3(rdev)) {\r\nWREG32(DCE3_DACA_AUTODETECT_INT_CONTROL, 0);\r\nWREG32(DCE3_DACB_AUTODETECT_INT_CONTROL, 0);\r\ntmp = RREG32(DC_HPD1_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD1_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD2_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD2_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD3_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD3_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD4_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD4_INT_CONTROL, tmp);\r\nif (ASIC_IS_DCE32(rdev)) {\r\ntmp = RREG32(DC_HPD5_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD5_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD6_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD6_INT_CONTROL, tmp);\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET0) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET0, tmp);\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET1) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET1, tmp);\r\n} else {\r\ntmp = RREG32(HDMI0_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nWREG32(HDMI0_AUDIO_PACKET_CONTROL, tmp);\r\ntmp = RREG32(DCE3_HDMI1_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nWREG32(DCE3_HDMI1_AUDIO_PACKET_CONTROL, tmp);\r\n}\r\n} else {\r\nWREG32(DACA_AUTODETECT_INT_CONTROL, 0);\r\nWREG32(DACB_AUTODETECT_INT_CONTROL, 0);\r\ntmp = RREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL) & DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nWREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL) & DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nWREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL) & DC_HOT_PLUG_DETECTx_INT_POLARITY;\r\nWREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL, tmp);\r\ntmp = RREG32(HDMI0_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nWREG32(HDMI0_AUDIO_PACKET_CONTROL, tmp);\r\ntmp = RREG32(HDMI1_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nWREG32(HDMI1_AUDIO_PACKET_CONTROL, tmp);\r\n}\r\n}\r\nint r600_irq_init(struct radeon_device *rdev)\r\n{\r\nint ret = 0;\r\nint rb_bufsz;\r\nu32 interrupt_cntl, ih_cntl, ih_rb_cntl;\r\nret = r600_ih_ring_alloc(rdev);\r\nif (ret)\r\nreturn ret;\r\nr600_disable_interrupts(rdev);\r\nif (rdev->family >= CHIP_CEDAR)\r\nret = evergreen_rlc_resume(rdev);\r\nelse\r\nret = r600_rlc_resume(rdev);\r\nif (ret) {\r\nr600_ih_ring_fini(rdev);\r\nreturn ret;\r\n}\r\nWREG32(INTERRUPT_CNTL2, rdev->ih.gpu_addr >> 8);\r\ninterrupt_cntl = RREG32(INTERRUPT_CNTL);\r\ninterrupt_cntl &= ~IH_DUMMY_RD_OVERRIDE;\r\ninterrupt_cntl &= ~IH_REQ_NONSNOOP_EN;\r\nWREG32(INTERRUPT_CNTL, interrupt_cntl);\r\nWREG32(IH_RB_BASE, rdev->ih.gpu_addr >> 8);\r\nrb_bufsz = order_base_2(rdev->ih.ring_size / 4);\r\nih_rb_cntl = (IH_WPTR_OVERFLOW_ENABLE |\r\nIH_WPTR_OVERFLOW_CLEAR |\r\n(rb_bufsz << 1));\r\nif (rdev->wb.enabled)\r\nih_rb_cntl |= IH_WPTR_WRITEBACK_ENABLE;\r\nWREG32(IH_RB_WPTR_ADDR_LO, (rdev->wb.gpu_addr + R600_WB_IH_WPTR_OFFSET) & 0xFFFFFFFC);\r\nWREG32(IH_RB_WPTR_ADDR_HI, upper_32_bits(rdev->wb.gpu_addr + R600_WB_IH_WPTR_OFFSET) & 0xFF);\r\nWREG32(IH_RB_CNTL, ih_rb_cntl);\r\nWREG32(IH_RB_RPTR, 0);\r\nWREG32(IH_RB_WPTR, 0);\r\nih_cntl = MC_WRREQ_CREDIT(0x10) | MC_WR_CLEAN_CNT(0x10);\r\nif (rdev->msi_enabled)\r\nih_cntl |= RPTR_REARM;\r\nWREG32(IH_CNTL, ih_cntl);\r\nif (rdev->family >= CHIP_CEDAR)\r\nevergreen_disable_interrupt_state(rdev);\r\nelse\r\nr600_disable_interrupt_state(rdev);\r\npci_set_master(rdev->pdev);\r\nr600_enable_interrupts(rdev);\r\nreturn ret;\r\n}\r\nvoid r600_irq_suspend(struct radeon_device *rdev)\r\n{\r\nr600_irq_disable(rdev);\r\nr600_rlc_stop(rdev);\r\n}\r\nvoid r600_irq_fini(struct radeon_device *rdev)\r\n{\r\nr600_irq_suspend(rdev);\r\nr600_ih_ring_fini(rdev);\r\n}\r\nint r600_irq_set(struct radeon_device *rdev)\r\n{\r\nu32 cp_int_cntl = CNTX_BUSY_INT_ENABLE | CNTX_EMPTY_INT_ENABLE;\r\nu32 mode_int = 0;\r\nu32 hpd1, hpd2, hpd3, hpd4 = 0, hpd5 = 0, hpd6 = 0;\r\nu32 grbm_int_cntl = 0;\r\nu32 hdmi0, hdmi1;\r\nu32 dma_cntl;\r\nu32 thermal_int = 0;\r\nif (!rdev->irq.installed) {\r\nWARN(1, "Can't enable IRQ/MSI because no handler is installed\n");\r\nreturn -EINVAL;\r\n}\r\nif (!rdev->ih.enabled) {\r\nr600_disable_interrupts(rdev);\r\nr600_disable_interrupt_state(rdev);\r\nreturn 0;\r\n}\r\nif (ASIC_IS_DCE3(rdev)) {\r\nhpd1 = RREG32(DC_HPD1_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd2 = RREG32(DC_HPD2_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd3 = RREG32(DC_HPD3_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd4 = RREG32(DC_HPD4_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nif (ASIC_IS_DCE32(rdev)) {\r\nhpd5 = RREG32(DC_HPD5_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd6 = RREG32(DC_HPD6_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhdmi0 = RREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET0) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\nhdmi1 = RREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET1) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\n} else {\r\nhdmi0 = RREG32(HDMI0_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nhdmi1 = RREG32(DCE3_HDMI1_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\n}\r\n} else {\r\nhpd1 = RREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd2 = RREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd3 = RREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhdmi0 = RREG32(HDMI0_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\nhdmi1 = RREG32(HDMI1_AUDIO_PACKET_CONTROL) & ~HDMI0_AZ_FORMAT_WTRIG_MASK;\r\n}\r\ndma_cntl = RREG32(DMA_CNTL) & ~TRAP_ENABLE;\r\nif ((rdev->family > CHIP_R600) && (rdev->family < CHIP_RV770)) {\r\nthermal_int = RREG32(CG_THERMAL_INT) &\r\n~(THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW);\r\n} else if (rdev->family >= CHIP_RV770) {\r\nthermal_int = RREG32(RV770_CG_THERMAL_INT) &\r\n~(THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW);\r\n}\r\nif (rdev->irq.dpm_thermal) {\r\nDRM_DEBUG("dpm thermal\n");\r\nthermal_int |= THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW;\r\n}\r\nif (atomic_read(&rdev->irq.ring_int[RADEON_RING_TYPE_GFX_INDEX])) {\r\nDRM_DEBUG("r600_irq_set: sw int\n");\r\ncp_int_cntl |= RB_INT_ENABLE;\r\ncp_int_cntl |= TIME_STAMP_INT_ENABLE;\r\n}\r\nif (atomic_read(&rdev->irq.ring_int[R600_RING_TYPE_DMA_INDEX])) {\r\nDRM_DEBUG("r600_irq_set: sw int dma\n");\r\ndma_cntl |= TRAP_ENABLE;\r\n}\r\nif (rdev->irq.crtc_vblank_int[0] ||\r\natomic_read(&rdev->irq.pflip[0])) {\r\nDRM_DEBUG("r600_irq_set: vblank 0\n");\r\nmode_int |= D1MODE_VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.crtc_vblank_int[1] ||\r\natomic_read(&rdev->irq.pflip[1])) {\r\nDRM_DEBUG("r600_irq_set: vblank 1\n");\r\nmode_int |= D2MODE_VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.hpd[0]) {\r\nDRM_DEBUG("r600_irq_set: hpd 1\n");\r\nhpd1 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[1]) {\r\nDRM_DEBUG("r600_irq_set: hpd 2\n");\r\nhpd2 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[2]) {\r\nDRM_DEBUG("r600_irq_set: hpd 3\n");\r\nhpd3 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[3]) {\r\nDRM_DEBUG("r600_irq_set: hpd 4\n");\r\nhpd4 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[4]) {\r\nDRM_DEBUG("r600_irq_set: hpd 5\n");\r\nhpd5 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[5]) {\r\nDRM_DEBUG("r600_irq_set: hpd 6\n");\r\nhpd6 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.afmt[0]) {\r\nDRM_DEBUG("r600_irq_set: hdmi 0\n");\r\nhdmi0 |= HDMI0_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nif (rdev->irq.afmt[1]) {\r\nDRM_DEBUG("r600_irq_set: hdmi 0\n");\r\nhdmi1 |= HDMI0_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nWREG32(CP_INT_CNTL, cp_int_cntl);\r\nWREG32(DMA_CNTL, dma_cntl);\r\nWREG32(DxMODE_INT_MASK, mode_int);\r\nWREG32(D1GRPH_INTERRUPT_CONTROL, DxGRPH_PFLIP_INT_MASK);\r\nWREG32(D2GRPH_INTERRUPT_CONTROL, DxGRPH_PFLIP_INT_MASK);\r\nWREG32(GRBM_INT_CNTL, grbm_int_cntl);\r\nif (ASIC_IS_DCE3(rdev)) {\r\nWREG32(DC_HPD1_INT_CONTROL, hpd1);\r\nWREG32(DC_HPD2_INT_CONTROL, hpd2);\r\nWREG32(DC_HPD3_INT_CONTROL, hpd3);\r\nWREG32(DC_HPD4_INT_CONTROL, hpd4);\r\nif (ASIC_IS_DCE32(rdev)) {\r\nWREG32(DC_HPD5_INT_CONTROL, hpd5);\r\nWREG32(DC_HPD6_INT_CONTROL, hpd6);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET0, hdmi0);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET1, hdmi1);\r\n} else {\r\nWREG32(HDMI0_AUDIO_PACKET_CONTROL, hdmi0);\r\nWREG32(DCE3_HDMI1_AUDIO_PACKET_CONTROL, hdmi1);\r\n}\r\n} else {\r\nWREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL, hpd1);\r\nWREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL, hpd2);\r\nWREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL, hpd3);\r\nWREG32(HDMI0_AUDIO_PACKET_CONTROL, hdmi0);\r\nWREG32(HDMI1_AUDIO_PACKET_CONTROL, hdmi1);\r\n}\r\nif ((rdev->family > CHIP_R600) && (rdev->family < CHIP_RV770)) {\r\nWREG32(CG_THERMAL_INT, thermal_int);\r\n} else if (rdev->family >= CHIP_RV770) {\r\nWREG32(RV770_CG_THERMAL_INT, thermal_int);\r\n}\r\nRREG32(R_000E50_SRBM_STATUS);\r\nreturn 0;\r\n}\r\nstatic void r600_irq_ack(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nif (ASIC_IS_DCE3(rdev)) {\r\nrdev->irq.stat_regs.r600.disp_int = RREG32(DCE3_DISP_INTERRUPT_STATUS);\r\nrdev->irq.stat_regs.r600.disp_int_cont = RREG32(DCE3_DISP_INTERRUPT_STATUS_CONTINUE);\r\nrdev->irq.stat_regs.r600.disp_int_cont2 = RREG32(DCE3_DISP_INTERRUPT_STATUS_CONTINUE2);\r\nif (ASIC_IS_DCE32(rdev)) {\r\nrdev->irq.stat_regs.r600.hdmi0_status = RREG32(AFMT_STATUS + DCE3_HDMI_OFFSET0);\r\nrdev->irq.stat_regs.r600.hdmi1_status = RREG32(AFMT_STATUS + DCE3_HDMI_OFFSET1);\r\n} else {\r\nrdev->irq.stat_regs.r600.hdmi0_status = RREG32(HDMI0_STATUS);\r\nrdev->irq.stat_regs.r600.hdmi1_status = RREG32(DCE3_HDMI1_STATUS);\r\n}\r\n} else {\r\nrdev->irq.stat_regs.r600.disp_int = RREG32(DISP_INTERRUPT_STATUS);\r\nrdev->irq.stat_regs.r600.disp_int_cont = RREG32(DISP_INTERRUPT_STATUS_CONTINUE);\r\nrdev->irq.stat_regs.r600.disp_int_cont2 = 0;\r\nrdev->irq.stat_regs.r600.hdmi0_status = RREG32(HDMI0_STATUS);\r\nrdev->irq.stat_regs.r600.hdmi1_status = RREG32(HDMI1_STATUS);\r\n}\r\nrdev->irq.stat_regs.r600.d1grph_int = RREG32(D1GRPH_INTERRUPT_STATUS);\r\nrdev->irq.stat_regs.r600.d2grph_int = RREG32(D2GRPH_INTERRUPT_STATUS);\r\nif (rdev->irq.stat_regs.r600.d1grph_int & DxGRPH_PFLIP_INT_OCCURRED)\r\nWREG32(D1GRPH_INTERRUPT_STATUS, DxGRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.r600.d2grph_int & DxGRPH_PFLIP_INT_OCCURRED)\r\nWREG32(D2GRPH_INTERRUPT_STATUS, DxGRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.r600.disp_int & LB_D1_VBLANK_INTERRUPT)\r\nWREG32(D1MODE_VBLANK_STATUS, DxMODE_VBLANK_ACK);\r\nif (rdev->irq.stat_regs.r600.disp_int & LB_D1_VLINE_INTERRUPT)\r\nWREG32(D1MODE_VLINE_STATUS, DxMODE_VLINE_ACK);\r\nif (rdev->irq.stat_regs.r600.disp_int & LB_D2_VBLANK_INTERRUPT)\r\nWREG32(D2MODE_VBLANK_STATUS, DxMODE_VBLANK_ACK);\r\nif (rdev->irq.stat_regs.r600.disp_int & LB_D2_VLINE_INTERRUPT)\r\nWREG32(D2MODE_VLINE_STATUS, DxMODE_VLINE_ACK);\r\nif (rdev->irq.stat_regs.r600.disp_int & DC_HPD1_INTERRUPT) {\r\nif (ASIC_IS_DCE3(rdev)) {\r\ntmp = RREG32(DC_HPD1_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD1_INT_CONTROL, tmp);\r\n} else {\r\ntmp = RREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HOT_PLUG_DETECT1_INT_CONTROL, tmp);\r\n}\r\n}\r\nif (rdev->irq.stat_regs.r600.disp_int & DC_HPD2_INTERRUPT) {\r\nif (ASIC_IS_DCE3(rdev)) {\r\ntmp = RREG32(DC_HPD2_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD2_INT_CONTROL, tmp);\r\n} else {\r\ntmp = RREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HOT_PLUG_DETECT2_INT_CONTROL, tmp);\r\n}\r\n}\r\nif (rdev->irq.stat_regs.r600.disp_int_cont & DC_HPD3_INTERRUPT) {\r\nif (ASIC_IS_DCE3(rdev)) {\r\ntmp = RREG32(DC_HPD3_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD3_INT_CONTROL, tmp);\r\n} else {\r\ntmp = RREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HOT_PLUG_DETECT3_INT_CONTROL, tmp);\r\n}\r\n}\r\nif (rdev->irq.stat_regs.r600.disp_int_cont & DC_HPD4_INTERRUPT) {\r\ntmp = RREG32(DC_HPD4_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD4_INT_CONTROL, tmp);\r\n}\r\nif (ASIC_IS_DCE32(rdev)) {\r\nif (rdev->irq.stat_regs.r600.disp_int_cont2 & DC_HPD5_INTERRUPT) {\r\ntmp = RREG32(DC_HPD5_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD5_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.r600.disp_int_cont2 & DC_HPD6_INTERRUPT) {\r\ntmp = RREG32(DC_HPD5_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD6_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.r600.hdmi0_status & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET0);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET0, tmp);\r\n}\r\nif (rdev->irq.stat_regs.r600.hdmi1_status & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET1);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + DCE3_HDMI_OFFSET1, tmp);\r\n}\r\n} else {\r\nif (rdev->irq.stat_regs.r600.hdmi0_status & HDMI0_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(HDMI0_AUDIO_PACKET_CONTROL);\r\ntmp |= HDMI0_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(HDMI0_AUDIO_PACKET_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.r600.hdmi1_status & HDMI0_AZ_FORMAT_WTRIG) {\r\nif (ASIC_IS_DCE3(rdev)) {\r\ntmp = RREG32(DCE3_HDMI1_AUDIO_PACKET_CONTROL);\r\ntmp |= HDMI0_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(DCE3_HDMI1_AUDIO_PACKET_CONTROL, tmp);\r\n} else {\r\ntmp = RREG32(HDMI1_AUDIO_PACKET_CONTROL);\r\ntmp |= HDMI0_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(HDMI1_AUDIO_PACKET_CONTROL, tmp);\r\n}\r\n}\r\n}\r\n}\r\nvoid r600_irq_disable(struct radeon_device *rdev)\r\n{\r\nr600_disable_interrupts(rdev);\r\nmdelay(1);\r\nr600_irq_ack(rdev);\r\nr600_disable_interrupt_state(rdev);\r\n}\r\nstatic u32 r600_get_ih_wptr(struct radeon_device *rdev)\r\n{\r\nu32 wptr, tmp;\r\nif (rdev->wb.enabled)\r\nwptr = le32_to_cpu(rdev->wb.wb[R600_WB_IH_WPTR_OFFSET/4]);\r\nelse\r\nwptr = RREG32(IH_RB_WPTR);\r\nif (wptr & RB_OVERFLOW) {\r\nwptr &= ~RB_OVERFLOW;\r\ndev_warn(rdev->dev, "IH ring buffer overflow (0x%08X, 0x%08X, 0x%08X)\n",\r\nwptr, rdev->ih.rptr, (wptr + 16) & rdev->ih.ptr_mask);\r\nrdev->ih.rptr = (wptr + 16) & rdev->ih.ptr_mask;\r\ntmp = RREG32(IH_RB_CNTL);\r\ntmp |= IH_WPTR_OVERFLOW_CLEAR;\r\nWREG32(IH_RB_CNTL, tmp);\r\n}\r\nreturn (wptr & rdev->ih.ptr_mask);\r\n}\r\nint r600_irq_process(struct radeon_device *rdev)\r\n{\r\nu32 wptr;\r\nu32 rptr;\r\nu32 src_id, src_data;\r\nu32 ring_index;\r\nbool queue_hotplug = false;\r\nbool queue_hdmi = false;\r\nbool queue_thermal = false;\r\nif (!rdev->ih.enabled || rdev->shutdown)\r\nreturn IRQ_NONE;\r\nif (!rdev->msi_enabled)\r\nRREG32(IH_RB_WPTR);\r\nwptr = r600_get_ih_wptr(rdev);\r\nrestart_ih:\r\nif (atomic_xchg(&rdev->ih.lock, 1))\r\nreturn IRQ_NONE;\r\nrptr = rdev->ih.rptr;\r\nDRM_DEBUG("r600_irq_process start: rptr %d, wptr %d\n", rptr, wptr);\r\nrmb();\r\nr600_irq_ack(rdev);\r\nwhile (rptr != wptr) {\r\nring_index = rptr / 4;\r\nsrc_id = le32_to_cpu(rdev->ih.ring[ring_index]) & 0xff;\r\nsrc_data = le32_to_cpu(rdev->ih.ring[ring_index + 1]) & 0xfffffff;\r\nswitch (src_id) {\r\ncase 1:\r\nswitch (src_data) {\r\ncase 0:\r\nif (!(rdev->irq.stat_regs.r600.disp_int & LB_D1_VBLANK_INTERRUPT))\r\nDRM_DEBUG("IH: D1 vblank - IH event w/o asserted irq bit?\n");\r\nif (rdev->irq.crtc_vblank_int[0]) {\r\ndrm_handle_vblank(rdev->ddev, 0);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[0]))\r\nradeon_crtc_handle_vblank(rdev, 0);\r\nrdev->irq.stat_regs.r600.disp_int &= ~LB_D1_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D1 vblank\n");\r\nbreak;\r\ncase 1:\r\nif (!(rdev->irq.stat_regs.r600.disp_int & LB_D1_VLINE_INTERRUPT))\r\nDRM_DEBUG("IH: D1 vline - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int &= ~LB_D1_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D1 vline\n");\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 5:\r\nswitch (src_data) {\r\ncase 0:\r\nif (!(rdev->irq.stat_regs.r600.disp_int & LB_D2_VBLANK_INTERRUPT))\r\nDRM_DEBUG("IH: D2 vblank - IH event w/o asserted irq bit?\n");\r\nif (rdev->irq.crtc_vblank_int[1]) {\r\ndrm_handle_vblank(rdev->ddev, 1);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[1]))\r\nradeon_crtc_handle_vblank(rdev, 1);\r\nrdev->irq.stat_regs.r600.disp_int &= ~LB_D2_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D2 vblank\n");\r\nbreak;\r\ncase 1:\r\nif (!(rdev->irq.stat_regs.r600.disp_int & LB_D2_VLINE_INTERRUPT))\r\nDRM_DEBUG("IH: D2 vline - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int &= ~LB_D2_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D2 vline\n");\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 9:\r\nDRM_DEBUG("IH: D1 flip\n");\r\nif (radeon_use_pflipirq > 0)\r\nradeon_crtc_handle_flip(rdev, 0);\r\nbreak;\r\ncase 11:\r\nDRM_DEBUG("IH: D2 flip\n");\r\nif (radeon_use_pflipirq > 0)\r\nradeon_crtc_handle_flip(rdev, 1);\r\nbreak;\r\ncase 19:\r\nswitch (src_data) {\r\ncase 0:\r\nif (!(rdev->irq.stat_regs.r600.disp_int & DC_HPD1_INTERRUPT))\r\nDRM_DEBUG("IH: HPD1 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int &= ~DC_HPD1_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD1\n");\r\nbreak;\r\ncase 1:\r\nif (!(rdev->irq.stat_regs.r600.disp_int & DC_HPD2_INTERRUPT))\r\nDRM_DEBUG("IH: HPD2 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int &= ~DC_HPD2_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD2\n");\r\nbreak;\r\ncase 4:\r\nif (!(rdev->irq.stat_regs.r600.disp_int_cont & DC_HPD3_INTERRUPT))\r\nDRM_DEBUG("IH: HPD3 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int_cont &= ~DC_HPD3_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD3\n");\r\nbreak;\r\ncase 5:\r\nif (!(rdev->irq.stat_regs.r600.disp_int_cont & DC_HPD4_INTERRUPT))\r\nDRM_DEBUG("IH: HPD4 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int_cont &= ~DC_HPD4_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD4\n");\r\nbreak;\r\ncase 10:\r\nif (!(rdev->irq.stat_regs.r600.disp_int_cont2 & DC_HPD5_INTERRUPT))\r\nDRM_DEBUG("IH: HPD5 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int_cont2 &= ~DC_HPD5_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD5\n");\r\nbreak;\r\ncase 12:\r\nif (!(rdev->irq.stat_regs.r600.disp_int_cont2 & DC_HPD6_INTERRUPT))\r\nDRM_DEBUG("IH: HPD6 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.disp_int_cont2 &= ~DC_HPD6_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD6\n");\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 21:\r\nswitch (src_data) {\r\ncase 4:\r\nif (!(rdev->irq.stat_regs.r600.hdmi0_status & HDMI0_AZ_FORMAT_WTRIG))\r\nDRM_DEBUG("IH: HDMI0 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.hdmi0_status &= ~HDMI0_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI0\n");\r\nbreak;\r\ncase 5:\r\nif (!(rdev->irq.stat_regs.r600.hdmi1_status & HDMI0_AZ_FORMAT_WTRIG))\r\nDRM_DEBUG("IH: HDMI1 - IH event w/o asserted irq bit?\n");\r\nrdev->irq.stat_regs.r600.hdmi1_status &= ~HDMI0_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI1\n");\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 124:\r\nDRM_DEBUG("IH: UVD int: 0x%08x\n", src_data);\r\nradeon_fence_process(rdev, R600_RING_TYPE_UVD_INDEX);\r\nbreak;\r\ncase 176:\r\ncase 177:\r\ncase 178:\r\nDRM_DEBUG("IH: CP int: 0x%08x\n", src_data);\r\nradeon_fence_process(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nbreak;\r\ncase 181:\r\nDRM_DEBUG("IH: CP EOP\n");\r\nradeon_fence_process(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nbreak;\r\ncase 224:\r\nDRM_DEBUG("IH: DMA trap\n");\r\nradeon_fence_process(rdev, R600_RING_TYPE_DMA_INDEX);\r\nbreak;\r\ncase 230:\r\nDRM_DEBUG("IH: thermal low to high\n");\r\nrdev->pm.dpm.thermal.high_to_low = false;\r\nqueue_thermal = true;\r\nbreak;\r\ncase 231:\r\nDRM_DEBUG("IH: thermal high to low\n");\r\nrdev->pm.dpm.thermal.high_to_low = true;\r\nqueue_thermal = true;\r\nbreak;\r\ncase 233:\r\nDRM_DEBUG("IH: GUI idle\n");\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nrptr += 16;\r\nrptr &= rdev->ih.ptr_mask;\r\nWREG32(IH_RB_RPTR, rptr);\r\n}\r\nif (queue_hotplug)\r\nschedule_work(&rdev->hotplug_work);\r\nif (queue_hdmi)\r\nschedule_work(&rdev->audio_work);\r\nif (queue_thermal && rdev->pm.dpm_enabled)\r\nschedule_work(&rdev->pm.dpm.thermal.work);\r\nrdev->ih.rptr = rptr;\r\natomic_set(&rdev->ih.lock, 0);\r\nwptr = r600_get_ih_wptr(rdev);\r\nif (wptr != rptr)\r\ngoto restart_ih;\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int r600_debugfs_mc_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nDREG32_SYS(m, rdev, R_000E50_SRBM_STATUS);\r\nDREG32_SYS(m, rdev, VM_L2_STATUS);\r\nreturn 0;\r\n}\r\nint r600_debugfs_mc_info_init(struct radeon_device *rdev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nreturn radeon_debugfs_add_files(rdev, r600_mc_info_list, ARRAY_SIZE(r600_mc_info_list));\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nvoid r600_mmio_hdp_flush(struct radeon_device *rdev)\r\n{\r\nif ((rdev->family >= CHIP_RV770) && (rdev->family <= CHIP_RV740) &&\r\nrdev->vram_scratch.ptr && !(rdev->flags & RADEON_IS_AGP)) {\r\nvoid __iomem *ptr = (void *)rdev->vram_scratch.ptr;\r\nu32 tmp;\r\nWREG32(HDP_DEBUG1, 0);\r\ntmp = readl((void __iomem *)ptr);\r\n} else\r\nWREG32(R_005480_HDP_MEM_COHERENCY_FLUSH_CNTL, 0x1);\r\n}\r\nvoid r600_set_pcie_lanes(struct radeon_device *rdev, int lanes)\r\n{\r\nu32 link_width_cntl, mask;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nreturn;\r\nif (!(rdev->flags & RADEON_IS_PCIE))\r\nreturn;\r\nif (ASIC_IS_X2(rdev))\r\nreturn;\r\nradeon_gui_idle(rdev);\r\nswitch (lanes) {\r\ncase 0:\r\nmask = RADEON_PCIE_LC_LINK_WIDTH_X0;\r\nbreak;\r\ncase 1:\r\nmask = RADEON_PCIE_LC_LINK_WIDTH_X1;\r\nbreak;\r\ncase 2:\r\nmask = RADEON_PCIE_LC_LINK_WIDTH_X2;\r\nbreak;\r\ncase 4:\r\nmask = RADEON_PCIE_LC_LINK_WIDTH_X4;\r\nbreak;\r\ncase 8:\r\nmask = RADEON_PCIE_LC_LINK_WIDTH_X8;\r\nbreak;\r\ncase 12:\r\nmask = RADEON_PCIE_LC_LINK_WIDTH_X12;\r\nbreak;\r\ncase 16:\r\nmask = RADEON_PCIE_LC_LINK_WIDTH_X16;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("invalid pcie lane request: %d\n", lanes);\r\nreturn;\r\n}\r\nlink_width_cntl = RREG32_PCIE_PORT(RADEON_PCIE_LC_LINK_WIDTH_CNTL);\r\nlink_width_cntl &= ~RADEON_PCIE_LC_LINK_WIDTH_MASK;\r\nlink_width_cntl |= mask << RADEON_PCIE_LC_LINK_WIDTH_SHIFT;\r\nlink_width_cntl |= (RADEON_PCIE_LC_RECONFIG_NOW |\r\nR600_PCIE_LC_RECONFIG_ARC_MISSING_ESCAPE);\r\nWREG32_PCIE_PORT(RADEON_PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n}\r\nint r600_get_pcie_lanes(struct radeon_device *rdev)\r\n{\r\nu32 link_width_cntl;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nreturn 0;\r\nif (!(rdev->flags & RADEON_IS_PCIE))\r\nreturn 0;\r\nif (ASIC_IS_X2(rdev))\r\nreturn 0;\r\nradeon_gui_idle(rdev);\r\nlink_width_cntl = RREG32_PCIE_PORT(RADEON_PCIE_LC_LINK_WIDTH_CNTL);\r\nswitch ((link_width_cntl & RADEON_PCIE_LC_LINK_WIDTH_RD_MASK) >> RADEON_PCIE_LC_LINK_WIDTH_RD_SHIFT) {\r\ncase RADEON_PCIE_LC_LINK_WIDTH_X1:\r\nreturn 1;\r\ncase RADEON_PCIE_LC_LINK_WIDTH_X2:\r\nreturn 2;\r\ncase RADEON_PCIE_LC_LINK_WIDTH_X4:\r\nreturn 4;\r\ncase RADEON_PCIE_LC_LINK_WIDTH_X8:\r\nreturn 8;\r\ncase RADEON_PCIE_LC_LINK_WIDTH_X12:\r\nreturn 12;\r\ncase RADEON_PCIE_LC_LINK_WIDTH_X0:\r\ncase RADEON_PCIE_LC_LINK_WIDTH_X16:\r\ndefault:\r\nreturn 16;\r\n}\r\n}\r\nstatic void r600_pcie_gen2_enable(struct radeon_device *rdev)\r\n{\r\nu32 link_width_cntl, lanes, speed_cntl, training_cntl, tmp;\r\nu16 link_cntl2;\r\nif (radeon_pcie_gen2 == 0)\r\nreturn;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nreturn;\r\nif (!(rdev->flags & RADEON_IS_PCIE))\r\nreturn;\r\nif (ASIC_IS_X2(rdev))\r\nreturn;\r\nif (rdev->family <= CHIP_R600)\r\nreturn;\r\nif ((rdev->pdev->bus->max_bus_speed != PCIE_SPEED_5_0GT) &&\r\n(rdev->pdev->bus->max_bus_speed != PCIE_SPEED_8_0GT))\r\nreturn;\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nif (speed_cntl & LC_CURRENT_DATA_RATE) {\r\nDRM_INFO("PCIE gen 2 link speeds already enabled\n");\r\nreturn;\r\n}\r\nDRM_INFO("enabling PCIE gen 2 link speeds, disable with radeon.pcie_gen2=0\n");\r\nif ((rdev->family == CHIP_RV670) ||\r\n(rdev->family == CHIP_RV620) ||\r\n(rdev->family == CHIP_RV635)) {\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nlink_width_cntl &= ~LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nif (link_width_cntl & LC_RENEGOTIATION_SUPPORT) {\r\nlanes = (link_width_cntl & LC_LINK_WIDTH_RD_MASK) >> LC_LINK_WIDTH_RD_SHIFT;\r\nlink_width_cntl &= ~(LC_LINK_WIDTH_MASK |\r\nLC_RECONFIG_ARC_MISSING_ESCAPE);\r\nlink_width_cntl |= lanes | LC_RECONFIG_NOW | LC_RENEGOTIATE_EN;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n} else {\r\nlink_width_cntl |= LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n}\r\n}\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nif ((speed_cntl & LC_OTHER_SIDE_EVER_SENT_GEN2) &&\r\n(speed_cntl & LC_OTHER_SIDE_SUPPORTS_GEN2)) {\r\nif ((rdev->family == CHIP_RV670) ||\r\n(rdev->family == CHIP_RV620) ||\r\n(rdev->family == CHIP_RV635)) {\r\nWREG32(MM_CFGREGS_CNTL, 0x8);\r\nlink_cntl2 = RREG32(0x4088);\r\nWREG32(MM_CFGREGS_CNTL, 0);\r\nif (link_cntl2 & SELECTABLE_DEEMPHASIS)\r\nreturn;\r\n}\r\nspeed_cntl &= ~LC_SPEED_CHANGE_ATTEMPTS_ALLOWED_MASK;\r\nspeed_cntl |= (0x3 << LC_SPEED_CHANGE_ATTEMPTS_ALLOWED_SHIFT);\r\nspeed_cntl &= ~LC_VOLTAGE_TIMER_SEL_MASK;\r\nspeed_cntl &= ~LC_FORCE_DIS_HW_SPEED_CHANGE;\r\nspeed_cntl |= LC_FORCE_EN_HW_SPEED_CHANGE;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\ntmp = RREG32(0x541c);\r\nWREG32(0x541c, tmp | 0x8);\r\nWREG32(MM_CFGREGS_CNTL, MM_WR_TO_CFG_EN);\r\nlink_cntl2 = RREG16(0x4088);\r\nlink_cntl2 &= ~TARGET_LINK_SPEED_MASK;\r\nlink_cntl2 |= 0x2;\r\nWREG16(0x4088, link_cntl2);\r\nWREG32(MM_CFGREGS_CNTL, 0);\r\nif ((rdev->family == CHIP_RV670) ||\r\n(rdev->family == CHIP_RV620) ||\r\n(rdev->family == CHIP_RV635)) {\r\ntraining_cntl = RREG32_PCIE_PORT(PCIE_LC_TRAINING_CNTL);\r\ntraining_cntl &= ~LC_POINT_7_PLUS_EN;\r\nWREG32_PCIE_PORT(PCIE_LC_TRAINING_CNTL, training_cntl);\r\n} else {\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl &= ~LC_TARGET_LINK_SPEED_OVERRIDE_EN;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\n}\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl |= LC_GEN2_EN_STRAP;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\n} else {\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nif (1)\r\nlink_width_cntl |= LC_UPCONFIGURE_DIS;\r\nelse\r\nlink_width_cntl &= ~LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n}\r\n}\r\nuint64_t r600_get_gpu_clock_counter(struct radeon_device *rdev)\r\n{\r\nuint64_t clock;\r\nmutex_lock(&rdev->gpu_clock_mutex);\r\nWREG32(RLC_CAPTURE_GPU_CLOCK_COUNT, 1);\r\nclock = (uint64_t)RREG32(RLC_GPU_CLOCK_COUNT_LSB) |\r\n((uint64_t)RREG32(RLC_GPU_CLOCK_COUNT_MSB) << 32ULL);\r\nmutex_unlock(&rdev->gpu_clock_mutex);\r\nreturn clock;\r\n}
