static inline unsigned int edma_read(unsigned ctlr, int offset)\r\n{\r\nreturn (unsigned int)__raw_readl(edmacc_regs_base[ctlr] + offset);\r\n}\r\nstatic inline void edma_write(unsigned ctlr, int offset, int val)\r\n{\r\n__raw_writel(val, edmacc_regs_base[ctlr] + offset);\r\n}\r\nstatic inline void edma_modify(unsigned ctlr, int offset, unsigned and,\r\nunsigned or)\r\n{\r\nunsigned val = edma_read(ctlr, offset);\r\nval &= and;\r\nval |= or;\r\nedma_write(ctlr, offset, val);\r\n}\r\nstatic inline void edma_and(unsigned ctlr, int offset, unsigned and)\r\n{\r\nunsigned val = edma_read(ctlr, offset);\r\nval &= and;\r\nedma_write(ctlr, offset, val);\r\n}\r\nstatic inline void edma_or(unsigned ctlr, int offset, unsigned or)\r\n{\r\nunsigned val = edma_read(ctlr, offset);\r\nval |= or;\r\nedma_write(ctlr, offset, val);\r\n}\r\nstatic inline unsigned int edma_read_array(unsigned ctlr, int offset, int i)\r\n{\r\nreturn edma_read(ctlr, offset + (i << 2));\r\n}\r\nstatic inline void edma_write_array(unsigned ctlr, int offset, int i,\r\nunsigned val)\r\n{\r\nedma_write(ctlr, offset + (i << 2), val);\r\n}\r\nstatic inline void edma_modify_array(unsigned ctlr, int offset, int i,\r\nunsigned and, unsigned or)\r\n{\r\nedma_modify(ctlr, offset + (i << 2), and, or);\r\n}\r\nstatic inline void edma_or_array(unsigned ctlr, int offset, int i, unsigned or)\r\n{\r\nedma_or(ctlr, offset + (i << 2), or);\r\n}\r\nstatic inline void edma_or_array2(unsigned ctlr, int offset, int i, int j,\r\nunsigned or)\r\n{\r\nedma_or(ctlr, offset + ((i*2 + j) << 2), or);\r\n}\r\nstatic inline void edma_write_array2(unsigned ctlr, int offset, int i, int j,\r\nunsigned val)\r\n{\r\nedma_write(ctlr, offset + ((i*2 + j) << 2), val);\r\n}\r\nstatic inline unsigned int edma_shadow0_read(unsigned ctlr, int offset)\r\n{\r\nreturn edma_read(ctlr, EDMA_SHADOW0 + offset);\r\n}\r\nstatic inline unsigned int edma_shadow0_read_array(unsigned ctlr, int offset,\r\nint i)\r\n{\r\nreturn edma_read(ctlr, EDMA_SHADOW0 + offset + (i << 2));\r\n}\r\nstatic inline void edma_shadow0_write(unsigned ctlr, int offset, unsigned val)\r\n{\r\nedma_write(ctlr, EDMA_SHADOW0 + offset, val);\r\n}\r\nstatic inline void edma_shadow0_write_array(unsigned ctlr, int offset, int i,\r\nunsigned val)\r\n{\r\nedma_write(ctlr, EDMA_SHADOW0 + offset + (i << 2), val);\r\n}\r\nstatic inline unsigned int edma_parm_read(unsigned ctlr, int offset,\r\nint param_no)\r\n{\r\nreturn edma_read(ctlr, EDMA_PARM + offset + (param_no << 5));\r\n}\r\nstatic inline void edma_parm_write(unsigned ctlr, int offset, int param_no,\r\nunsigned val)\r\n{\r\nedma_write(ctlr, EDMA_PARM + offset + (param_no << 5), val);\r\n}\r\nstatic inline void edma_parm_modify(unsigned ctlr, int offset, int param_no,\r\nunsigned and, unsigned or)\r\n{\r\nedma_modify(ctlr, EDMA_PARM + offset + (param_no << 5), and, or);\r\n}\r\nstatic inline void edma_parm_and(unsigned ctlr, int offset, int param_no,\r\nunsigned and)\r\n{\r\nedma_and(ctlr, EDMA_PARM + offset + (param_no << 5), and);\r\n}\r\nstatic inline void edma_parm_or(unsigned ctlr, int offset, int param_no,\r\nunsigned or)\r\n{\r\nedma_or(ctlr, EDMA_PARM + offset + (param_no << 5), or);\r\n}\r\nstatic inline void set_bits(int offset, int len, unsigned long *p)\r\n{\r\nfor (; len > 0; len--)\r\nset_bit(offset + (len - 1), p);\r\n}\r\nstatic inline void clear_bits(int offset, int len, unsigned long *p)\r\n{\r\nfor (; len > 0; len--)\r\nclear_bit(offset + (len - 1), p);\r\n}\r\nstatic void map_dmach_queue(unsigned ctlr, unsigned ch_no,\r\nenum dma_event_q queue_no)\r\n{\r\nint bit = (ch_no & 0x7) * 4;\r\nif (queue_no == EVENTQ_DEFAULT)\r\nqueue_no = edma_cc[ctlr]->default_queue;\r\nqueue_no &= 7;\r\nedma_modify_array(ctlr, EDMA_DMAQNUM, (ch_no >> 3),\r\n~(0x7 << bit), queue_no << bit);\r\n}\r\nstatic void assign_priority_to_queue(unsigned ctlr, int queue_no,\r\nint priority)\r\n{\r\nint bit = queue_no * 4;\r\nedma_modify(ctlr, EDMA_QUEPRI, ~(0x7 << bit),\r\n((priority & 0x7) << bit));\r\n}\r\nstatic void map_dmach_param(unsigned ctlr)\r\n{\r\nint i;\r\nfor (i = 0; i < EDMA_MAX_DMACH; i++)\r\nedma_write_array(ctlr, EDMA_DCHMAP , i , (i << 5));\r\n}\r\nstatic inline void\r\nsetup_dma_interrupt(unsigned lch,\r\nvoid (*callback)(unsigned channel, u16 ch_status, void *data),\r\nvoid *data)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(lch);\r\nlch = EDMA_CHAN_SLOT(lch);\r\nif (!callback)\r\nedma_shadow0_write_array(ctlr, SH_IECR, lch >> 5,\r\nBIT(lch & 0x1f));\r\nedma_cc[ctlr]->intr_data[lch].callback = callback;\r\nedma_cc[ctlr]->intr_data[lch].data = data;\r\nif (callback) {\r\nedma_shadow0_write_array(ctlr, SH_ICR, lch >> 5,\r\nBIT(lch & 0x1f));\r\nedma_shadow0_write_array(ctlr, SH_IESR, lch >> 5,\r\nBIT(lch & 0x1f));\r\n}\r\n}\r\nstatic int irq2ctlr(int irq)\r\n{\r\nif (irq >= edma_cc[0]->irq_res_start && irq <= edma_cc[0]->irq_res_end)\r\nreturn 0;\r\nelse if (irq >= edma_cc[1]->irq_res_start &&\r\nirq <= edma_cc[1]->irq_res_end)\r\nreturn 1;\r\nreturn -1;\r\n}\r\nstatic irqreturn_t dma_irq_handler(int irq, void *data)\r\n{\r\nint ctlr;\r\nu32 sh_ier;\r\nu32 sh_ipr;\r\nu32 bank;\r\nctlr = irq2ctlr(irq);\r\nif (ctlr < 0)\r\nreturn IRQ_NONE;\r\ndev_dbg(data, "dma_irq_handler\n");\r\nsh_ipr = edma_shadow0_read_array(ctlr, SH_IPR, 0);\r\nif (!sh_ipr) {\r\nsh_ipr = edma_shadow0_read_array(ctlr, SH_IPR, 1);\r\nif (!sh_ipr)\r\nreturn IRQ_NONE;\r\nsh_ier = edma_shadow0_read_array(ctlr, SH_IER, 1);\r\nbank = 1;\r\n} else {\r\nsh_ier = edma_shadow0_read_array(ctlr, SH_IER, 0);\r\nbank = 0;\r\n}\r\ndo {\r\nu32 slot;\r\nu32 channel;\r\ndev_dbg(data, "IPR%d %08x\n", bank, sh_ipr);\r\nslot = __ffs(sh_ipr);\r\nsh_ipr &= ~(BIT(slot));\r\nif (sh_ier & BIT(slot)) {\r\nchannel = (bank << 5) | slot;\r\nedma_shadow0_write_array(ctlr, SH_ICR, bank,\r\nBIT(slot));\r\nif (edma_cc[ctlr]->intr_data[channel].callback)\r\nedma_cc[ctlr]->intr_data[channel].callback(\r\nchannel, EDMA_DMA_COMPLETE,\r\nedma_cc[ctlr]->intr_data[channel].data);\r\n}\r\n} while (sh_ipr);\r\nedma_shadow0_write(ctlr, SH_IEVAL, 1);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t dma_ccerr_handler(int irq, void *data)\r\n{\r\nint i;\r\nint ctlr;\r\nunsigned int cnt = 0;\r\nctlr = irq2ctlr(irq);\r\nif (ctlr < 0)\r\nreturn IRQ_NONE;\r\ndev_dbg(data, "dma_ccerr_handler\n");\r\nif ((edma_read_array(ctlr, EDMA_EMR, 0) == 0) &&\r\n(edma_read_array(ctlr, EDMA_EMR, 1) == 0) &&\r\n(edma_read(ctlr, EDMA_QEMR) == 0) &&\r\n(edma_read(ctlr, EDMA_CCERR) == 0))\r\nreturn IRQ_NONE;\r\nwhile (1) {\r\nint j = -1;\r\nif (edma_read_array(ctlr, EDMA_EMR, 0))\r\nj = 0;\r\nelse if (edma_read_array(ctlr, EDMA_EMR, 1))\r\nj = 1;\r\nif (j >= 0) {\r\ndev_dbg(data, "EMR%d %08x\n", j,\r\nedma_read_array(ctlr, EDMA_EMR, j));\r\nfor (i = 0; i < 32; i++) {\r\nint k = (j << 5) + i;\r\nif (edma_read_array(ctlr, EDMA_EMR, j) &\r\nBIT(i)) {\r\nedma_write_array(ctlr, EDMA_EMCR, j,\r\nBIT(i));\r\nedma_shadow0_write_array(ctlr, SH_SECR,\r\nj, BIT(i));\r\nif (edma_cc[ctlr]->intr_data[k].\r\ncallback) {\r\nedma_cc[ctlr]->intr_data[k].\r\ncallback(k,\r\nEDMA_DMA_CC_ERROR,\r\nedma_cc[ctlr]->intr_data\r\n[k].data);\r\n}\r\n}\r\n}\r\n} else if (edma_read(ctlr, EDMA_QEMR)) {\r\ndev_dbg(data, "QEMR %02x\n",\r\nedma_read(ctlr, EDMA_QEMR));\r\nfor (i = 0; i < 8; i++) {\r\nif (edma_read(ctlr, EDMA_QEMR) & BIT(i)) {\r\nedma_write(ctlr, EDMA_QEMCR, BIT(i));\r\nedma_shadow0_write(ctlr, SH_QSECR,\r\nBIT(i));\r\n}\r\n}\r\n} else if (edma_read(ctlr, EDMA_CCERR)) {\r\ndev_dbg(data, "CCERR %08x\n",\r\nedma_read(ctlr, EDMA_CCERR));\r\nfor (i = 0; i < 8; i++) {\r\nif (edma_read(ctlr, EDMA_CCERR) & BIT(i)) {\r\nedma_write(ctlr, EDMA_CCERRCLR, BIT(i));\r\n}\r\n}\r\n}\r\nif ((edma_read_array(ctlr, EDMA_EMR, 0) == 0) &&\r\n(edma_read_array(ctlr, EDMA_EMR, 1) == 0) &&\r\n(edma_read(ctlr, EDMA_QEMR) == 0) &&\r\n(edma_read(ctlr, EDMA_CCERR) == 0))\r\nbreak;\r\ncnt++;\r\nif (cnt > 10)\r\nbreak;\r\n}\r\nedma_write(ctlr, EDMA_EEVAL, 1);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int reserve_contiguous_slots(int ctlr, unsigned int id,\r\nunsigned int num_slots,\r\nunsigned int start_slot)\r\n{\r\nint i, j;\r\nunsigned int count = num_slots;\r\nint stop_slot = start_slot;\r\nDECLARE_BITMAP(tmp_inuse, EDMA_MAX_PARAMENTRY);\r\nfor (i = start_slot; i < edma_cc[ctlr]->num_slots; ++i) {\r\nj = EDMA_CHAN_SLOT(i);\r\nif (!test_and_set_bit(j, edma_cc[ctlr]->edma_inuse)) {\r\nif (count == num_slots)\r\nstop_slot = i;\r\ncount--;\r\nset_bit(j, tmp_inuse);\r\nif (count == 0)\r\nbreak;\r\n} else {\r\nclear_bit(j, tmp_inuse);\r\nif (id == EDMA_CONT_PARAMS_FIXED_EXACT) {\r\nstop_slot = i;\r\nbreak;\r\n} else {\r\ncount = num_slots;\r\n}\r\n}\r\n}\r\nif (i == edma_cc[ctlr]->num_slots)\r\nstop_slot = i;\r\nj = start_slot;\r\nfor_each_set_bit_from(j, tmp_inuse, stop_slot)\r\nclear_bit(j, edma_cc[ctlr]->edma_inuse);\r\nif (count)\r\nreturn -EBUSY;\r\nfor (j = i - num_slots + 1; j <= i; ++j)\r\nmemcpy_toio(edmacc_regs_base[ctlr] + PARM_OFFSET(j),\r\n&dummy_paramset, PARM_SIZE);\r\nreturn EDMA_CTLR_CHAN(ctlr, i - num_slots + 1);\r\n}\r\nstatic int prepare_unused_channel_list(struct device *dev, void *data)\r\n{\r\nstruct platform_device *pdev = to_platform_device(dev);\r\nint i, count, ctlr;\r\nstruct of_phandle_args dma_spec;\r\nif (dev->of_node) {\r\ncount = of_property_count_strings(dev->of_node, "dma-names");\r\nif (count < 0)\r\nreturn 0;\r\nfor (i = 0; i < count; i++) {\r\nif (of_parse_phandle_with_args(dev->of_node, "dmas",\r\n"#dma-cells", i,\r\n&dma_spec))\r\ncontinue;\r\nif (!of_match_node(edma_of_ids, dma_spec.np)) {\r\nof_node_put(dma_spec.np);\r\ncontinue;\r\n}\r\nclear_bit(EDMA_CHAN_SLOT(dma_spec.args[0]),\r\nedma_cc[0]->edma_unused);\r\nof_node_put(dma_spec.np);\r\n}\r\nreturn 0;\r\n}\r\nfor (i = 0; i < pdev->num_resources; i++) {\r\nif ((pdev->resource[i].flags & IORESOURCE_DMA) &&\r\n(int)pdev->resource[i].start >= 0) {\r\nctlr = EDMA_CTLR(pdev->resource[i].start);\r\nclear_bit(EDMA_CHAN_SLOT(pdev->resource[i].start),\r\nedma_cc[ctlr]->edma_unused);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint edma_alloc_channel(int channel,\r\nvoid (*callback)(unsigned channel, u16 ch_status, void *data),\r\nvoid *data,\r\nenum dma_event_q eventq_no)\r\n{\r\nunsigned i, done = 0, ctlr = 0;\r\nint ret = 0;\r\nif (!unused_chan_list_done) {\r\nret = bus_for_each_dev(&platform_bus_type, NULL, NULL,\r\nprepare_unused_channel_list);\r\nif (ret < 0)\r\nreturn ret;\r\nunused_chan_list_done = true;\r\n}\r\nif (channel >= 0) {\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\n}\r\nif (channel < 0) {\r\nfor (i = 0; i < arch_num_cc; i++) {\r\nchannel = 0;\r\nfor (;;) {\r\nchannel = find_next_bit(edma_cc[i]->edma_unused,\r\nedma_cc[i]->num_channels,\r\nchannel);\r\nif (channel == edma_cc[i]->num_channels)\r\nbreak;\r\nif (!test_and_set_bit(channel,\r\nedma_cc[i]->edma_inuse)) {\r\ndone = 1;\r\nctlr = i;\r\nbreak;\r\n}\r\nchannel++;\r\n}\r\nif (done)\r\nbreak;\r\n}\r\nif (!done)\r\nreturn -ENOMEM;\r\n} else if (channel >= edma_cc[ctlr]->num_channels) {\r\nreturn -EINVAL;\r\n} else if (test_and_set_bit(channel, edma_cc[ctlr]->edma_inuse)) {\r\nreturn -EBUSY;\r\n}\r\nedma_or_array2(ctlr, EDMA_DRAE, 0, channel >> 5, BIT(channel & 0x1f));\r\nedma_stop(EDMA_CTLR_CHAN(ctlr, channel));\r\nmemcpy_toio(edmacc_regs_base[ctlr] + PARM_OFFSET(channel),\r\n&dummy_paramset, PARM_SIZE);\r\nif (callback)\r\nsetup_dma_interrupt(EDMA_CTLR_CHAN(ctlr, channel),\r\ncallback, data);\r\nmap_dmach_queue(ctlr, channel, eventq_no);\r\nreturn EDMA_CTLR_CHAN(ctlr, channel);\r\n}\r\nvoid edma_free_channel(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel >= edma_cc[ctlr]->num_channels)\r\nreturn;\r\nsetup_dma_interrupt(channel, NULL, NULL);\r\nmemcpy_toio(edmacc_regs_base[ctlr] + PARM_OFFSET(channel),\r\n&dummy_paramset, PARM_SIZE);\r\nclear_bit(channel, edma_cc[ctlr]->edma_inuse);\r\n}\r\nint edma_alloc_slot(unsigned ctlr, int slot)\r\n{\r\nif (!edma_cc[ctlr])\r\nreturn -EINVAL;\r\nif (slot >= 0)\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < 0) {\r\nslot = edma_cc[ctlr]->num_channels;\r\nfor (;;) {\r\nslot = find_next_zero_bit(edma_cc[ctlr]->edma_inuse,\r\nedma_cc[ctlr]->num_slots, slot);\r\nif (slot == edma_cc[ctlr]->num_slots)\r\nreturn -ENOMEM;\r\nif (!test_and_set_bit(slot, edma_cc[ctlr]->edma_inuse))\r\nbreak;\r\n}\r\n} else if (slot < edma_cc[ctlr]->num_channels ||\r\nslot >= edma_cc[ctlr]->num_slots) {\r\nreturn -EINVAL;\r\n} else if (test_and_set_bit(slot, edma_cc[ctlr]->edma_inuse)) {\r\nreturn -EBUSY;\r\n}\r\nmemcpy_toio(edmacc_regs_base[ctlr] + PARM_OFFSET(slot),\r\n&dummy_paramset, PARM_SIZE);\r\nreturn EDMA_CTLR_CHAN(ctlr, slot);\r\n}\r\nvoid edma_free_slot(unsigned slot)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < edma_cc[ctlr]->num_channels ||\r\nslot >= edma_cc[ctlr]->num_slots)\r\nreturn;\r\nmemcpy_toio(edmacc_regs_base[ctlr] + PARM_OFFSET(slot),\r\n&dummy_paramset, PARM_SIZE);\r\nclear_bit(slot, edma_cc[ctlr]->edma_inuse);\r\n}\r\nint edma_alloc_cont_slots(unsigned ctlr, unsigned int id, int slot, int count)\r\n{\r\nif ((id != EDMA_CONT_PARAMS_ANY) &&\r\n(slot < edma_cc[ctlr]->num_channels ||\r\nslot >= edma_cc[ctlr]->num_slots))\r\nreturn -EINVAL;\r\nif (count < 1 || count >\r\n(edma_cc[ctlr]->num_slots - edma_cc[ctlr]->num_channels))\r\nreturn -EINVAL;\r\nswitch (id) {\r\ncase EDMA_CONT_PARAMS_ANY:\r\nreturn reserve_contiguous_slots(ctlr, id, count,\r\nedma_cc[ctlr]->num_channels);\r\ncase EDMA_CONT_PARAMS_FIXED_EXACT:\r\ncase EDMA_CONT_PARAMS_FIXED_NOT_EXACT:\r\nreturn reserve_contiguous_slots(ctlr, id, count, slot);\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nint edma_free_cont_slots(unsigned slot, int count)\r\n{\r\nunsigned ctlr, slot_to_free;\r\nint i;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < edma_cc[ctlr]->num_channels ||\r\nslot >= edma_cc[ctlr]->num_slots ||\r\ncount < 1)\r\nreturn -EINVAL;\r\nfor (i = slot; i < slot + count; ++i) {\r\nctlr = EDMA_CTLR(i);\r\nslot_to_free = EDMA_CHAN_SLOT(i);\r\nmemcpy_toio(edmacc_regs_base[ctlr] + PARM_OFFSET(slot_to_free),\r\n&dummy_paramset, PARM_SIZE);\r\nclear_bit(slot_to_free, edma_cc[ctlr]->edma_inuse);\r\n}\r\nreturn 0;\r\n}\r\nvoid edma_set_src(unsigned slot, dma_addr_t src_port,\r\nenum address_mode mode, enum fifo_width width)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < edma_cc[ctlr]->num_slots) {\r\nunsigned int i = edma_parm_read(ctlr, PARM_OPT, slot);\r\nif (mode) {\r\ni = (i & ~(EDMA_FWID)) | (SAM | ((width & 0x7) << 8));\r\n} else {\r\ni &= ~SAM;\r\n}\r\nedma_parm_write(ctlr, PARM_OPT, slot, i);\r\nedma_parm_write(ctlr, PARM_SRC, slot, src_port);\r\n}\r\n}\r\nvoid edma_set_dest(unsigned slot, dma_addr_t dest_port,\r\nenum address_mode mode, enum fifo_width width)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < edma_cc[ctlr]->num_slots) {\r\nunsigned int i = edma_parm_read(ctlr, PARM_OPT, slot);\r\nif (mode) {\r\ni = (i & ~(EDMA_FWID)) | (DAM | ((width & 0x7) << 8));\r\n} else {\r\ni &= ~DAM;\r\n}\r\nedma_parm_write(ctlr, PARM_OPT, slot, i);\r\nedma_parm_write(ctlr, PARM_DST, slot, dest_port);\r\n}\r\n}\r\ndma_addr_t edma_get_position(unsigned slot, bool dst)\r\n{\r\nu32 offs, ctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\noffs = PARM_OFFSET(slot);\r\noffs += dst ? PARM_DST : PARM_SRC;\r\nreturn edma_read(ctlr, offs);\r\n}\r\nvoid edma_set_src_index(unsigned slot, s16 src_bidx, s16 src_cidx)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < edma_cc[ctlr]->num_slots) {\r\nedma_parm_modify(ctlr, PARM_SRC_DST_BIDX, slot,\r\n0xffff0000, src_bidx);\r\nedma_parm_modify(ctlr, PARM_SRC_DST_CIDX, slot,\r\n0xffff0000, src_cidx);\r\n}\r\n}\r\nvoid edma_set_dest_index(unsigned slot, s16 dest_bidx, s16 dest_cidx)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < edma_cc[ctlr]->num_slots) {\r\nedma_parm_modify(ctlr, PARM_SRC_DST_BIDX, slot,\r\n0x0000ffff, dest_bidx << 16);\r\nedma_parm_modify(ctlr, PARM_SRC_DST_CIDX, slot,\r\n0x0000ffff, dest_cidx << 16);\r\n}\r\n}\r\nvoid edma_set_transfer_params(unsigned slot,\r\nu16 acnt, u16 bcnt, u16 ccnt,\r\nu16 bcnt_rld, enum sync_dimension sync_mode)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot < edma_cc[ctlr]->num_slots) {\r\nedma_parm_modify(ctlr, PARM_LINK_BCNTRLD, slot,\r\n0x0000ffff, bcnt_rld << 16);\r\nif (sync_mode == ASYNC)\r\nedma_parm_and(ctlr, PARM_OPT, slot, ~SYNCDIM);\r\nelse\r\nedma_parm_or(ctlr, PARM_OPT, slot, SYNCDIM);\r\nedma_parm_write(ctlr, PARM_A_B_CNT, slot, (bcnt << 16) | acnt);\r\nedma_parm_write(ctlr, PARM_CCNT, slot, ccnt);\r\n}\r\n}\r\nvoid edma_link(unsigned from, unsigned to)\r\n{\r\nunsigned ctlr_from, ctlr_to;\r\nctlr_from = EDMA_CTLR(from);\r\nfrom = EDMA_CHAN_SLOT(from);\r\nctlr_to = EDMA_CTLR(to);\r\nto = EDMA_CHAN_SLOT(to);\r\nif (from >= edma_cc[ctlr_from]->num_slots)\r\nreturn;\r\nif (to >= edma_cc[ctlr_to]->num_slots)\r\nreturn;\r\nedma_parm_modify(ctlr_from, PARM_LINK_BCNTRLD, from, 0xffff0000,\r\nPARM_OFFSET(to));\r\n}\r\nvoid edma_unlink(unsigned from)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(from);\r\nfrom = EDMA_CHAN_SLOT(from);\r\nif (from >= edma_cc[ctlr]->num_slots)\r\nreturn;\r\nedma_parm_or(ctlr, PARM_LINK_BCNTRLD, from, 0xffff);\r\n}\r\nvoid edma_write_slot(unsigned slot, const struct edmacc_param *param)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot >= edma_cc[ctlr]->num_slots)\r\nreturn;\r\nmemcpy_toio(edmacc_regs_base[ctlr] + PARM_OFFSET(slot), param,\r\nPARM_SIZE);\r\n}\r\nvoid edma_read_slot(unsigned slot, struct edmacc_param *param)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(slot);\r\nslot = EDMA_CHAN_SLOT(slot);\r\nif (slot >= edma_cc[ctlr]->num_slots)\r\nreturn;\r\nmemcpy_fromio(param, edmacc_regs_base[ctlr] + PARM_OFFSET(slot),\r\nPARM_SIZE);\r\n}\r\nvoid edma_pause(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel < edma_cc[ctlr]->num_channels) {\r\nunsigned int mask = BIT(channel & 0x1f);\r\nedma_shadow0_write_array(ctlr, SH_EECR, channel >> 5, mask);\r\n}\r\n}\r\nvoid edma_resume(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel < edma_cc[ctlr]->num_channels) {\r\nunsigned int mask = BIT(channel & 0x1f);\r\nedma_shadow0_write_array(ctlr, SH_EESR, channel >> 5, mask);\r\n}\r\n}\r\nint edma_trigger_channel(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nunsigned int mask;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nmask = BIT(channel & 0x1f);\r\nedma_shadow0_write_array(ctlr, SH_ESR, (channel >> 5), mask);\r\npr_debug("EDMA: ESR%d %08x\n", (channel >> 5),\r\nedma_shadow0_read_array(ctlr, SH_ESR, (channel >> 5)));\r\nreturn 0;\r\n}\r\nint edma_start(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel < edma_cc[ctlr]->num_channels) {\r\nint j = channel >> 5;\r\nunsigned int mask = BIT(channel & 0x1f);\r\nif (test_bit(channel, edma_cc[ctlr]->edma_unused)) {\r\npr_debug("EDMA: ESR%d %08x\n", j,\r\nedma_shadow0_read_array(ctlr, SH_ESR, j));\r\nedma_shadow0_write_array(ctlr, SH_ESR, j, mask);\r\nreturn 0;\r\n}\r\npr_debug("EDMA: ER%d %08x\n", j,\r\nedma_shadow0_read_array(ctlr, SH_ER, j));\r\nedma_write_array(ctlr, EDMA_ECR, j, mask);\r\nedma_write_array(ctlr, EDMA_EMCR, j, mask);\r\nedma_shadow0_write_array(ctlr, SH_SECR, j, mask);\r\nedma_shadow0_write_array(ctlr, SH_EESR, j, mask);\r\npr_debug("EDMA: EER%d %08x\n", j,\r\nedma_shadow0_read_array(ctlr, SH_EER, j));\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nvoid edma_stop(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel < edma_cc[ctlr]->num_channels) {\r\nint j = channel >> 5;\r\nunsigned int mask = BIT(channel & 0x1f);\r\nedma_shadow0_write_array(ctlr, SH_EECR, j, mask);\r\nedma_shadow0_write_array(ctlr, SH_ECR, j, mask);\r\nedma_shadow0_write_array(ctlr, SH_SECR, j, mask);\r\nedma_write_array(ctlr, EDMA_EMCR, j, mask);\r\nedma_shadow0_write_array(ctlr, SH_ICR, j, mask);\r\npr_debug("EDMA: EER%d %08x\n", j,\r\nedma_shadow0_read_array(ctlr, SH_EER, j));\r\n}\r\n}\r\nvoid edma_clean_channel(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel < edma_cc[ctlr]->num_channels) {\r\nint j = (channel >> 5);\r\nunsigned int mask = BIT(channel & 0x1f);\r\npr_debug("EDMA: EMR%d %08x\n", j,\r\nedma_read_array(ctlr, EDMA_EMR, j));\r\nedma_shadow0_write_array(ctlr, SH_ECR, j, mask);\r\nedma_write_array(ctlr, EDMA_EMCR, j, mask);\r\nedma_shadow0_write_array(ctlr, SH_SECR, j, mask);\r\nedma_write(ctlr, EDMA_CCERRCLR, BIT(16) | BIT(1) | BIT(0));\r\n}\r\n}\r\nvoid edma_clear_event(unsigned channel)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel >= edma_cc[ctlr]->num_channels)\r\nreturn;\r\nif (channel < 32)\r\nedma_write(ctlr, EDMA_ECR, BIT(channel));\r\nelse\r\nedma_write(ctlr, EDMA_ECRH, BIT(channel - 32));\r\n}\r\nvoid edma_assign_channel_eventq(unsigned channel, enum dma_event_q eventq_no)\r\n{\r\nunsigned ctlr;\r\nctlr = EDMA_CTLR(channel);\r\nchannel = EDMA_CHAN_SLOT(channel);\r\nif (channel >= edma_cc[ctlr]->num_channels)\r\nreturn;\r\nif (eventq_no == EVENTQ_DEFAULT)\r\neventq_no = edma_cc[ctlr]->default_queue;\r\nif (eventq_no >= edma_cc[ctlr]->num_tc)\r\nreturn;\r\nmap_dmach_queue(ctlr, channel, eventq_no);\r\n}\r\nstatic int edma_setup_from_hw(struct device *dev, struct edma_soc_info *pdata,\r\nstruct edma *edma_cc, int cc_id)\r\n{\r\nint i;\r\nu32 value, cccfg;\r\ns8 (*queue_priority_map)[2];\r\ncccfg = edma_read(cc_id, EDMA_CCCFG);\r\nvalue = GET_NUM_REGN(cccfg);\r\nedma_cc->num_region = BIT(value);\r\nvalue = GET_NUM_DMACH(cccfg);\r\nedma_cc->num_channels = BIT(value + 1);\r\nvalue = GET_NUM_PAENTRY(cccfg);\r\nedma_cc->num_slots = BIT(value + 4);\r\nvalue = GET_NUM_EVQUE(cccfg);\r\nedma_cc->num_tc = value + 1;\r\ndev_dbg(dev, "eDMA3 CC%d HW configuration (cccfg: 0x%08x):\n", cc_id,\r\ncccfg);\r\ndev_dbg(dev, "num_region: %u\n", edma_cc->num_region);\r\ndev_dbg(dev, "num_channel: %u\n", edma_cc->num_channels);\r\ndev_dbg(dev, "num_slot: %u\n", edma_cc->num_slots);\r\ndev_dbg(dev, "num_tc: %u\n", edma_cc->num_tc);\r\nif (pdata->queue_priority_mapping)\r\nreturn 0;\r\nqueue_priority_map = devm_kzalloc(dev,\r\n(edma_cc->num_tc + 1) * sizeof(s8),\r\nGFP_KERNEL);\r\nif (!queue_priority_map)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < edma_cc->num_tc; i++) {\r\nqueue_priority_map[i][0] = i;\r\nqueue_priority_map[i][1] = i;\r\n}\r\nqueue_priority_map[i][0] = -1;\r\nqueue_priority_map[i][1] = -1;\r\npdata->queue_priority_mapping = queue_priority_map;\r\npdata->default_queue = i - 1;\r\nreturn 0;\r\n}\r\nstatic int edma_xbar_event_map(struct device *dev, struct device_node *node,\r\nstruct edma_soc_info *pdata, size_t sz)\r\n{\r\nconst char pname[] = "ti,edma-xbar-event-map";\r\nstruct resource res;\r\nvoid __iomem *xbar;\r\ns16 (*xbar_chans)[2];\r\nsize_t nelm = sz / sizeof(s16);\r\nu32 shift, offset, mux;\r\nint ret, i;\r\nxbar_chans = devm_kzalloc(dev, (nelm + 2) * sizeof(s16), GFP_KERNEL);\r\nif (!xbar_chans)\r\nreturn -ENOMEM;\r\nret = of_address_to_resource(node, 1, &res);\r\nif (ret)\r\nreturn -ENOMEM;\r\nxbar = devm_ioremap(dev, res.start, resource_size(&res));\r\nif (!xbar)\r\nreturn -ENOMEM;\r\nret = of_property_read_u16_array(node, pname, (u16 *)xbar_chans, nelm);\r\nif (ret)\r\nreturn -EIO;\r\nnelm >>= 1;\r\nxbar_chans[nelm][0] = xbar_chans[nelm][1] = -1;\r\nfor (i = 0; i < nelm; i++) {\r\nshift = (xbar_chans[i][1] & 0x03) << 3;\r\noffset = xbar_chans[i][1] & 0xfffffffc;\r\nmux = readl(xbar + offset);\r\nmux &= ~(0xff << shift);\r\nmux |= xbar_chans[i][0] << shift;\r\nwritel(mux, (xbar + offset));\r\n}\r\npdata->xbar_chans = (const s16 (*)[2]) xbar_chans;\r\nreturn 0;\r\n}\r\nstatic int edma_of_parse_dt(struct device *dev,\r\nstruct device_node *node,\r\nstruct edma_soc_info *pdata)\r\n{\r\nint ret = 0;\r\nstruct property *prop;\r\nsize_t sz;\r\nstruct edma_rsv_info *rsv_info;\r\nrsv_info = devm_kzalloc(dev, sizeof(struct edma_rsv_info), GFP_KERNEL);\r\nif (!rsv_info)\r\nreturn -ENOMEM;\r\npdata->rsv = rsv_info;\r\nprop = of_find_property(node, "ti,edma-xbar-event-map", &sz);\r\nif (prop)\r\nret = edma_xbar_event_map(dev, node, pdata, sz);\r\nreturn ret;\r\n}\r\nstatic struct edma_soc_info *edma_setup_info_from_dt(struct device *dev,\r\nstruct device_node *node)\r\n{\r\nstruct edma_soc_info *info;\r\nint ret;\r\ninfo = devm_kzalloc(dev, sizeof(struct edma_soc_info), GFP_KERNEL);\r\nif (!info)\r\nreturn ERR_PTR(-ENOMEM);\r\nret = edma_of_parse_dt(dev, node, info);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\ndma_cap_set(DMA_SLAVE, edma_filter_info.dma_cap);\r\ndma_cap_set(DMA_CYCLIC, edma_filter_info.dma_cap);\r\nof_dma_controller_register(dev->of_node, of_dma_simple_xlate,\r\n&edma_filter_info);\r\nreturn info;\r\n}\r\nstatic struct edma_soc_info *edma_setup_info_from_dt(struct device *dev,\r\nstruct device_node *node)\r\n{\r\nreturn ERR_PTR(-ENOSYS);\r\n}\r\nstatic int edma_probe(struct platform_device *pdev)\r\n{\r\nstruct edma_soc_info **info = pdev->dev.platform_data;\r\nstruct edma_soc_info *ninfo[EDMA_MAX_CC] = {NULL};\r\ns8 (*queue_priority_mapping)[2];\r\nint i, j, off, ln, found = 0;\r\nint status = -1;\r\nconst s16 (*rsv_chans)[2];\r\nconst s16 (*rsv_slots)[2];\r\nconst s16 (*xbar_chans)[2];\r\nint irq[EDMA_MAX_CC] = {0, 0};\r\nint err_irq[EDMA_MAX_CC] = {0, 0};\r\nstruct resource *r[EDMA_MAX_CC] = {NULL};\r\nstruct resource res[EDMA_MAX_CC];\r\nchar res_name[10];\r\nstruct device_node *node = pdev->dev.of_node;\r\nstruct device *dev = &pdev->dev;\r\nint ret;\r\nstruct platform_device_info edma_dev_info = {\r\n.name = "edma-dma-engine",\r\n.dma_mask = DMA_BIT_MASK(32),\r\n.parent = &pdev->dev,\r\n};\r\nif (node) {\r\nif (arch_num_cc) {\r\ndev_err(dev, "only one EDMA instance is supported via DT\n");\r\nreturn -ENODEV;\r\n}\r\nninfo[0] = edma_setup_info_from_dt(dev, node);\r\nif (IS_ERR(ninfo[0])) {\r\ndev_err(dev, "failed to get DT data\n");\r\nreturn PTR_ERR(ninfo[0]);\r\n}\r\ninfo = ninfo;\r\n}\r\nif (!info)\r\nreturn -ENODEV;\r\npm_runtime_enable(dev);\r\nret = pm_runtime_get_sync(dev);\r\nif (ret < 0) {\r\ndev_err(dev, "pm_runtime_get_sync() failed\n");\r\nreturn ret;\r\n}\r\nfor (j = 0; j < EDMA_MAX_CC; j++) {\r\nif (!info[j]) {\r\nif (!found)\r\nreturn -ENODEV;\r\nbreak;\r\n}\r\nif (node) {\r\nret = of_address_to_resource(node, j, &res[j]);\r\nif (!ret)\r\nr[j] = &res[j];\r\n} else {\r\nsprintf(res_name, "edma_cc%d", j);\r\nr[j] = platform_get_resource_byname(pdev,\r\nIORESOURCE_MEM,\r\nres_name);\r\n}\r\nif (!r[j]) {\r\nif (found)\r\nbreak;\r\nelse\r\nreturn -ENODEV;\r\n} else {\r\nfound = 1;\r\n}\r\nedmacc_regs_base[j] = devm_ioremap_resource(&pdev->dev, r[j]);\r\nif (IS_ERR(edmacc_regs_base[j]))\r\nreturn PTR_ERR(edmacc_regs_base[j]);\r\nedma_cc[j] = devm_kzalloc(&pdev->dev, sizeof(struct edma),\r\nGFP_KERNEL);\r\nif (!edma_cc[j])\r\nreturn -ENOMEM;\r\nret = edma_setup_from_hw(dev, info[j], edma_cc[j], j);\r\nif (ret)\r\nreturn ret;\r\nedma_cc[j]->default_queue = info[j]->default_queue;\r\ndev_dbg(&pdev->dev, "DMA REG BASE ADDR=%p\n",\r\nedmacc_regs_base[j]);\r\nfor (i = 0; i < edma_cc[j]->num_slots; i++)\r\nmemcpy_toio(edmacc_regs_base[j] + PARM_OFFSET(i),\r\n&dummy_paramset, PARM_SIZE);\r\nmemset(edma_cc[j]->edma_unused, 0xff,\r\nsizeof(edma_cc[j]->edma_unused));\r\nif (info[j]->rsv) {\r\nrsv_chans = info[j]->rsv->rsv_chans;\r\nif (rsv_chans) {\r\nfor (i = 0; rsv_chans[i][0] != -1; i++) {\r\noff = rsv_chans[i][0];\r\nln = rsv_chans[i][1];\r\nclear_bits(off, ln,\r\nedma_cc[j]->edma_unused);\r\n}\r\n}\r\nrsv_slots = info[j]->rsv->rsv_slots;\r\nif (rsv_slots) {\r\nfor (i = 0; rsv_slots[i][0] != -1; i++) {\r\noff = rsv_slots[i][0];\r\nln = rsv_slots[i][1];\r\nset_bits(off, ln,\r\nedma_cc[j]->edma_inuse);\r\n}\r\n}\r\n}\r\nxbar_chans = info[j]->xbar_chans;\r\nif (xbar_chans) {\r\nfor (i = 0; xbar_chans[i][1] != -1; i++) {\r\noff = xbar_chans[i][1];\r\nclear_bits(off, 1,\r\nedma_cc[j]->edma_unused);\r\n}\r\n}\r\nif (node) {\r\nirq[j] = irq_of_parse_and_map(node, 0);\r\nerr_irq[j] = irq_of_parse_and_map(node, 2);\r\n} else {\r\nchar irq_name[10];\r\nsprintf(irq_name, "edma%d", j);\r\nirq[j] = platform_get_irq_byname(pdev, irq_name);\r\nsprintf(irq_name, "edma%d_err", j);\r\nerr_irq[j] = platform_get_irq_byname(pdev, irq_name);\r\n}\r\nedma_cc[j]->irq_res_start = irq[j];\r\nedma_cc[j]->irq_res_end = err_irq[j];\r\nstatus = devm_request_irq(dev, irq[j], dma_irq_handler, 0,\r\n"edma", dev);\r\nif (status < 0) {\r\ndev_dbg(&pdev->dev,\r\n"devm_request_irq %d failed --> %d\n",\r\nirq[j], status);\r\nreturn status;\r\n}\r\nstatus = devm_request_irq(dev, err_irq[j], dma_ccerr_handler, 0,\r\n"edma_error", dev);\r\nif (status < 0) {\r\ndev_dbg(&pdev->dev,\r\n"devm_request_irq %d failed --> %d\n",\r\nerr_irq[j], status);\r\nreturn status;\r\n}\r\nfor (i = 0; i < edma_cc[j]->num_channels; i++)\r\nmap_dmach_queue(j, i, info[j]->default_queue);\r\nqueue_priority_mapping = info[j]->queue_priority_mapping;\r\nfor (i = 0; queue_priority_mapping[i][0] != -1; i++)\r\nassign_priority_to_queue(j,\r\nqueue_priority_mapping[i][0],\r\nqueue_priority_mapping[i][1]);\r\nif (edma_read(j, EDMA_CCCFG) & CHMAP_EXIST)\r\nmap_dmach_param(j);\r\nfor (i = 0; i < edma_cc[j]->num_region; i++) {\r\nedma_write_array2(j, EDMA_DRAE, i, 0, 0x0);\r\nedma_write_array2(j, EDMA_DRAE, i, 1, 0x0);\r\nedma_write_array(j, EDMA_QRAE, i, 0x0);\r\n}\r\nedma_cc[j]->info = info[j];\r\narch_num_cc++;\r\nedma_dev_info.id = j;\r\nplatform_device_register_full(&edma_dev_info);\r\n}\r\nreturn 0;\r\n}\r\nstatic int edma_pm_resume(struct device *dev)\r\n{\r\nint i, j;\r\nfor (j = 0; j < arch_num_cc; j++) {\r\nstruct edma *cc = edma_cc[j];\r\ns8 (*queue_priority_mapping)[2];\r\nqueue_priority_mapping = cc->info->queue_priority_mapping;\r\nfor (i = 0; queue_priority_mapping[i][0] != -1; i++)\r\nassign_priority_to_queue(j,\r\nqueue_priority_mapping[i][0],\r\nqueue_priority_mapping[i][1]);\r\nif (edma_read(j, EDMA_CCCFG) & CHMAP_EXIST)\r\nmap_dmach_param(j);\r\nfor (i = 0; i < cc->num_channels; i++) {\r\nif (test_bit(i, cc->edma_inuse)) {\r\nedma_or_array2(j, EDMA_DRAE, 0, i >> 5,\r\nBIT(i & 0x1f));\r\nsetup_dma_interrupt(i,\r\ncc->intr_data[i].callback,\r\ncc->intr_data[i].data);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init edma_init(void)\r\n{\r\nreturn platform_driver_probe(&edma_driver, edma_probe);\r\n}
