static inline u32 axienet_dma_in32(struct axienet_local *lp, off_t reg)\r\n{\r\nreturn in_be32(lp->dma_regs + reg);\r\n}\r\nstatic inline void axienet_dma_out32(struct axienet_local *lp,\r\noff_t reg, u32 value)\r\n{\r\nout_be32((lp->dma_regs + reg), value);\r\n}\r\nstatic void axienet_dma_bd_release(struct net_device *ndev)\r\n{\r\nint i;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nfor (i = 0; i < RX_BD_NUM; i++) {\r\ndma_unmap_single(ndev->dev.parent, lp->rx_bd_v[i].phys,\r\nlp->max_frm_size, DMA_FROM_DEVICE);\r\ndev_kfree_skb((struct sk_buff *)\r\n(lp->rx_bd_v[i].sw_id_offset));\r\n}\r\nif (lp->rx_bd_v) {\r\ndma_free_coherent(ndev->dev.parent,\r\nsizeof(*lp->rx_bd_v) * RX_BD_NUM,\r\nlp->rx_bd_v,\r\nlp->rx_bd_p);\r\n}\r\nif (lp->tx_bd_v) {\r\ndma_free_coherent(ndev->dev.parent,\r\nsizeof(*lp->tx_bd_v) * TX_BD_NUM,\r\nlp->tx_bd_v,\r\nlp->tx_bd_p);\r\n}\r\n}\r\nstatic int axienet_dma_bd_init(struct net_device *ndev)\r\n{\r\nu32 cr;\r\nint i;\r\nstruct sk_buff *skb;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nlp->tx_bd_ci = 0;\r\nlp->tx_bd_tail = 0;\r\nlp->rx_bd_ci = 0;\r\nlp->tx_bd_v = dma_zalloc_coherent(ndev->dev.parent,\r\nsizeof(*lp->tx_bd_v) * TX_BD_NUM,\r\n&lp->tx_bd_p, GFP_KERNEL);\r\nif (!lp->tx_bd_v)\r\ngoto out;\r\nlp->rx_bd_v = dma_zalloc_coherent(ndev->dev.parent,\r\nsizeof(*lp->rx_bd_v) * RX_BD_NUM,\r\n&lp->rx_bd_p, GFP_KERNEL);\r\nif (!lp->rx_bd_v)\r\ngoto out;\r\nfor (i = 0; i < TX_BD_NUM; i++) {\r\nlp->tx_bd_v[i].next = lp->tx_bd_p +\r\nsizeof(*lp->tx_bd_v) *\r\n((i + 1) % TX_BD_NUM);\r\n}\r\nfor (i = 0; i < RX_BD_NUM; i++) {\r\nlp->rx_bd_v[i].next = lp->rx_bd_p +\r\nsizeof(*lp->rx_bd_v) *\r\n((i + 1) % RX_BD_NUM);\r\nskb = netdev_alloc_skb_ip_align(ndev, lp->max_frm_size);\r\nif (!skb)\r\ngoto out;\r\nlp->rx_bd_v[i].sw_id_offset = (u32) skb;\r\nlp->rx_bd_v[i].phys = dma_map_single(ndev->dev.parent,\r\nskb->data,\r\nlp->max_frm_size,\r\nDMA_FROM_DEVICE);\r\nlp->rx_bd_v[i].cntrl = lp->max_frm_size;\r\n}\r\ncr = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\ncr = ((cr & ~XAXIDMA_COALESCE_MASK) |\r\n((lp->coalesce_count_rx) << XAXIDMA_COALESCE_SHIFT));\r\ncr = ((cr & ~XAXIDMA_DELAY_MASK) |\r\n(XAXIDMA_DFT_RX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\r\ncr |= XAXIDMA_IRQ_ALL_MASK;\r\naxienet_dma_out32(lp, XAXIDMA_RX_CR_OFFSET, cr);\r\ncr = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\ncr = (((cr & ~XAXIDMA_COALESCE_MASK)) |\r\n((lp->coalesce_count_tx) << XAXIDMA_COALESCE_SHIFT));\r\ncr = (((cr & ~XAXIDMA_DELAY_MASK)) |\r\n(XAXIDMA_DFT_TX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\r\ncr |= XAXIDMA_IRQ_ALL_MASK;\r\naxienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET, cr);\r\naxienet_dma_out32(lp, XAXIDMA_RX_CDESC_OFFSET, lp->rx_bd_p);\r\ncr = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\naxienet_dma_out32(lp, XAXIDMA_RX_CR_OFFSET,\r\ncr | XAXIDMA_CR_RUNSTOP_MASK);\r\naxienet_dma_out32(lp, XAXIDMA_RX_TDESC_OFFSET, lp->rx_bd_p +\r\n(sizeof(*lp->rx_bd_v) * (RX_BD_NUM - 1)));\r\naxienet_dma_out32(lp, XAXIDMA_TX_CDESC_OFFSET, lp->tx_bd_p);\r\ncr = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\naxienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET,\r\ncr | XAXIDMA_CR_RUNSTOP_MASK);\r\nreturn 0;\r\nout:\r\naxienet_dma_bd_release(ndev);\r\nreturn -ENOMEM;\r\n}\r\nstatic void axienet_set_mac_address(struct net_device *ndev, void *address)\r\n{\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nif (address)\r\nmemcpy(ndev->dev_addr, address, ETH_ALEN);\r\nif (!is_valid_ether_addr(ndev->dev_addr))\r\neth_random_addr(ndev->dev_addr);\r\naxienet_iow(lp, XAE_UAW0_OFFSET,\r\n(ndev->dev_addr[0]) |\r\n(ndev->dev_addr[1] << 8) |\r\n(ndev->dev_addr[2] << 16) |\r\n(ndev->dev_addr[3] << 24));\r\naxienet_iow(lp, XAE_UAW1_OFFSET,\r\n(((axienet_ior(lp, XAE_UAW1_OFFSET)) &\r\n~XAE_UAW1_UNICASTADDR_MASK) |\r\n(ndev->dev_addr[4] |\r\n(ndev->dev_addr[5] << 8))));\r\n}\r\nstatic int netdev_set_mac_address(struct net_device *ndev, void *p)\r\n{\r\nstruct sockaddr *addr = p;\r\naxienet_set_mac_address(ndev, addr->sa_data);\r\nreturn 0;\r\n}\r\nstatic void axienet_set_multicast_list(struct net_device *ndev)\r\n{\r\nint i;\r\nu32 reg, af0reg, af1reg;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nif (ndev->flags & (IFF_ALLMULTI | IFF_PROMISC) ||\r\nnetdev_mc_count(ndev) > XAE_MULTICAST_CAM_TABLE_NUM) {\r\nndev->flags |= IFF_PROMISC;\r\nreg = axienet_ior(lp, XAE_FMI_OFFSET);\r\nreg |= XAE_FMI_PM_MASK;\r\naxienet_iow(lp, XAE_FMI_OFFSET, reg);\r\ndev_info(&ndev->dev, "Promiscuous mode enabled.\n");\r\n} else if (!netdev_mc_empty(ndev)) {\r\nstruct netdev_hw_addr *ha;\r\ni = 0;\r\nnetdev_for_each_mc_addr(ha, ndev) {\r\nif (i >= XAE_MULTICAST_CAM_TABLE_NUM)\r\nbreak;\r\naf0reg = (ha->addr[0]);\r\naf0reg |= (ha->addr[1] << 8);\r\naf0reg |= (ha->addr[2] << 16);\r\naf0reg |= (ha->addr[3] << 24);\r\naf1reg = (ha->addr[4]);\r\naf1reg |= (ha->addr[5] << 8);\r\nreg = axienet_ior(lp, XAE_FMI_OFFSET) & 0xFFFFFF00;\r\nreg |= i;\r\naxienet_iow(lp, XAE_FMI_OFFSET, reg);\r\naxienet_iow(lp, XAE_AF0_OFFSET, af0reg);\r\naxienet_iow(lp, XAE_AF1_OFFSET, af1reg);\r\ni++;\r\n}\r\n} else {\r\nreg = axienet_ior(lp, XAE_FMI_OFFSET);\r\nreg &= ~XAE_FMI_PM_MASK;\r\naxienet_iow(lp, XAE_FMI_OFFSET, reg);\r\nfor (i = 0; i < XAE_MULTICAST_CAM_TABLE_NUM; i++) {\r\nreg = axienet_ior(lp, XAE_FMI_OFFSET) & 0xFFFFFF00;\r\nreg |= i;\r\naxienet_iow(lp, XAE_FMI_OFFSET, reg);\r\naxienet_iow(lp, XAE_AF0_OFFSET, 0);\r\naxienet_iow(lp, XAE_AF1_OFFSET, 0);\r\n}\r\ndev_info(&ndev->dev, "Promiscuous mode disabled.\n");\r\n}\r\n}\r\nstatic void axienet_setoptions(struct net_device *ndev, u32 options)\r\n{\r\nint reg;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstruct axienet_option *tp = &axienet_options[0];\r\nwhile (tp->opt) {\r\nreg = ((axienet_ior(lp, tp->reg)) & ~(tp->m_or));\r\nif (options & tp->opt)\r\nreg |= tp->m_or;\r\naxienet_iow(lp, tp->reg, reg);\r\ntp++;\r\n}\r\nlp->options |= options;\r\n}\r\nstatic void __axienet_device_reset(struct axienet_local *lp,\r\nstruct device *dev, off_t offset)\r\n{\r\nu32 timeout;\r\naxienet_dma_out32(lp, offset, XAXIDMA_CR_RESET_MASK);\r\ntimeout = DELAY_OF_ONE_MILLISEC;\r\nwhile (axienet_dma_in32(lp, offset) & XAXIDMA_CR_RESET_MASK) {\r\nudelay(1);\r\nif (--timeout == 0) {\r\nnetdev_err(lp->ndev, "%s: DMA reset timeout!\n",\r\n__func__);\r\nbreak;\r\n}\r\n}\r\n}\r\nstatic void axienet_device_reset(struct net_device *ndev)\r\n{\r\nu32 axienet_status;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\n__axienet_device_reset(lp, &ndev->dev, XAXIDMA_TX_CR_OFFSET);\r\n__axienet_device_reset(lp, &ndev->dev, XAXIDMA_RX_CR_OFFSET);\r\nlp->max_frm_size = XAE_MAX_VLAN_FRAME_SIZE;\r\nlp->options |= XAE_OPTION_VLAN;\r\nlp->options &= (~XAE_OPTION_JUMBO);\r\nif ((ndev->mtu > XAE_MTU) &&\r\n(ndev->mtu <= XAE_JUMBO_MTU)) {\r\nlp->max_frm_size = ndev->mtu + VLAN_ETH_HLEN +\r\nXAE_TRL_SIZE;\r\nif (lp->max_frm_size <= lp->rxmem)\r\nlp->options |= XAE_OPTION_JUMBO;\r\n}\r\nif (axienet_dma_bd_init(ndev)) {\r\nnetdev_err(ndev, "%s: descriptor allocation failed\n",\r\n__func__);\r\n}\r\naxienet_status = axienet_ior(lp, XAE_RCW1_OFFSET);\r\naxienet_status &= ~XAE_RCW1_RX_MASK;\r\naxienet_iow(lp, XAE_RCW1_OFFSET, axienet_status);\r\naxienet_status = axienet_ior(lp, XAE_IP_OFFSET);\r\nif (axienet_status & XAE_INT_RXRJECT_MASK)\r\naxienet_iow(lp, XAE_IS_OFFSET, XAE_INT_RXRJECT_MASK);\r\naxienet_iow(lp, XAE_FCC_OFFSET, XAE_FCC_FCRX_MASK);\r\naxienet_setoptions(ndev, lp->options &\r\n~(XAE_OPTION_TXEN | XAE_OPTION_RXEN));\r\naxienet_set_mac_address(ndev, NULL);\r\naxienet_set_multicast_list(ndev);\r\naxienet_setoptions(ndev, lp->options);\r\nndev->trans_start = jiffies;\r\n}\r\nstatic void axienet_adjust_link(struct net_device *ndev)\r\n{\r\nu32 emmc_reg;\r\nu32 link_state;\r\nu32 setspeed = 1;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstruct phy_device *phy = lp->phy_dev;\r\nlink_state = phy->speed | (phy->duplex << 1) | phy->link;\r\nif (lp->last_link != link_state) {\r\nif ((phy->speed == SPEED_10) || (phy->speed == SPEED_100)) {\r\nif (lp->phy_type == XAE_PHY_TYPE_1000BASE_X)\r\nsetspeed = 0;\r\n} else {\r\nif ((phy->speed == SPEED_1000) &&\r\n(lp->phy_type == XAE_PHY_TYPE_MII))\r\nsetspeed = 0;\r\n}\r\nif (setspeed == 1) {\r\nemmc_reg = axienet_ior(lp, XAE_EMMC_OFFSET);\r\nemmc_reg &= ~XAE_EMMC_LINKSPEED_MASK;\r\nswitch (phy->speed) {\r\ncase SPEED_1000:\r\nemmc_reg |= XAE_EMMC_LINKSPD_1000;\r\nbreak;\r\ncase SPEED_100:\r\nemmc_reg |= XAE_EMMC_LINKSPD_100;\r\nbreak;\r\ncase SPEED_10:\r\nemmc_reg |= XAE_EMMC_LINKSPD_10;\r\nbreak;\r\ndefault:\r\ndev_err(&ndev->dev, "Speed other than 10, 100 "\r\n"or 1Gbps is not supported\n");\r\nbreak;\r\n}\r\naxienet_iow(lp, XAE_EMMC_OFFSET, emmc_reg);\r\nlp->last_link = link_state;\r\nphy_print_status(phy);\r\n} else {\r\nnetdev_err(ndev,\r\n"Error setting Axi Ethernet mac speed\n");\r\n}\r\n}\r\n}\r\nstatic void axienet_start_xmit_done(struct net_device *ndev)\r\n{\r\nu32 size = 0;\r\nu32 packets = 0;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstruct axidma_bd *cur_p;\r\nunsigned int status = 0;\r\ncur_p = &lp->tx_bd_v[lp->tx_bd_ci];\r\nstatus = cur_p->status;\r\nwhile (status & XAXIDMA_BD_STS_COMPLETE_MASK) {\r\ndma_unmap_single(ndev->dev.parent, cur_p->phys,\r\n(cur_p->cntrl & XAXIDMA_BD_CTRL_LENGTH_MASK),\r\nDMA_TO_DEVICE);\r\nif (cur_p->app4)\r\ndev_kfree_skb_irq((struct sk_buff *)cur_p->app4);\r\ncur_p->app0 = 0;\r\ncur_p->app1 = 0;\r\ncur_p->app2 = 0;\r\ncur_p->app4 = 0;\r\ncur_p->status = 0;\r\nsize += status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;\r\npackets++;\r\n++lp->tx_bd_ci;\r\nlp->tx_bd_ci %= TX_BD_NUM;\r\ncur_p = &lp->tx_bd_v[lp->tx_bd_ci];\r\nstatus = cur_p->status;\r\n}\r\nndev->stats.tx_packets += packets;\r\nndev->stats.tx_bytes += size;\r\nnetif_wake_queue(ndev);\r\n}\r\nstatic inline int axienet_check_tx_bd_space(struct axienet_local *lp,\r\nint num_frag)\r\n{\r\nstruct axidma_bd *cur_p;\r\ncur_p = &lp->tx_bd_v[(lp->tx_bd_tail + num_frag) % TX_BD_NUM];\r\nif (cur_p->status & XAXIDMA_BD_STS_ALL_MASK)\r\nreturn NETDEV_TX_BUSY;\r\nreturn 0;\r\n}\r\nstatic int axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)\r\n{\r\nu32 ii;\r\nu32 num_frag;\r\nu32 csum_start_off;\r\nu32 csum_index_off;\r\nskb_frag_t *frag;\r\ndma_addr_t tail_p;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstruct axidma_bd *cur_p;\r\nnum_frag = skb_shinfo(skb)->nr_frags;\r\ncur_p = &lp->tx_bd_v[lp->tx_bd_tail];\r\nif (axienet_check_tx_bd_space(lp, num_frag)) {\r\nif (!netif_queue_stopped(ndev))\r\nnetif_stop_queue(ndev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nif (lp->features & XAE_FEATURE_FULL_TX_CSUM) {\r\ncur_p->app0 |= 2;\r\n} else if (lp->features & XAE_FEATURE_PARTIAL_RX_CSUM) {\r\ncsum_start_off = skb_transport_offset(skb);\r\ncsum_index_off = csum_start_off + skb->csum_offset;\r\ncur_p->app0 |= 1;\r\ncur_p->app1 = (csum_start_off << 16) | csum_index_off;\r\n}\r\n} else if (skb->ip_summed == CHECKSUM_UNNECESSARY) {\r\ncur_p->app0 |= 2;\r\n}\r\ncur_p->cntrl = skb_headlen(skb) | XAXIDMA_BD_CTRL_TXSOF_MASK;\r\ncur_p->phys = dma_map_single(ndev->dev.parent, skb->data,\r\nskb_headlen(skb), DMA_TO_DEVICE);\r\nfor (ii = 0; ii < num_frag; ii++) {\r\n++lp->tx_bd_tail;\r\nlp->tx_bd_tail %= TX_BD_NUM;\r\ncur_p = &lp->tx_bd_v[lp->tx_bd_tail];\r\nfrag = &skb_shinfo(skb)->frags[ii];\r\ncur_p->phys = dma_map_single(ndev->dev.parent,\r\nskb_frag_address(frag),\r\nskb_frag_size(frag),\r\nDMA_TO_DEVICE);\r\ncur_p->cntrl = skb_frag_size(frag);\r\n}\r\ncur_p->cntrl |= XAXIDMA_BD_CTRL_TXEOF_MASK;\r\ncur_p->app4 = (unsigned long)skb;\r\ntail_p = lp->tx_bd_p + sizeof(*lp->tx_bd_v) * lp->tx_bd_tail;\r\naxienet_dma_out32(lp, XAXIDMA_TX_TDESC_OFFSET, tail_p);\r\n++lp->tx_bd_tail;\r\nlp->tx_bd_tail %= TX_BD_NUM;\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void axienet_recv(struct net_device *ndev)\r\n{\r\nu32 length;\r\nu32 csumstatus;\r\nu32 size = 0;\r\nu32 packets = 0;\r\ndma_addr_t tail_p = 0;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstruct sk_buff *skb, *new_skb;\r\nstruct axidma_bd *cur_p;\r\ncur_p = &lp->rx_bd_v[lp->rx_bd_ci];\r\nwhile ((cur_p->status & XAXIDMA_BD_STS_COMPLETE_MASK)) {\r\ntail_p = lp->rx_bd_p + sizeof(*lp->rx_bd_v) * lp->rx_bd_ci;\r\nskb = (struct sk_buff *) (cur_p->sw_id_offset);\r\nlength = cur_p->app4 & 0x0000FFFF;\r\ndma_unmap_single(ndev->dev.parent, cur_p->phys,\r\nlp->max_frm_size,\r\nDMA_FROM_DEVICE);\r\nskb_put(skb, length);\r\nskb->protocol = eth_type_trans(skb, ndev);\r\nskb->ip_summed = CHECKSUM_NONE;\r\nif (lp->features & XAE_FEATURE_FULL_RX_CSUM) {\r\ncsumstatus = (cur_p->app2 &\r\nXAE_FULL_CSUM_STATUS_MASK) >> 3;\r\nif ((csumstatus == XAE_IP_TCP_CSUM_VALIDATED) ||\r\n(csumstatus == XAE_IP_UDP_CSUM_VALIDATED)) {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\n}\r\n} else if ((lp->features & XAE_FEATURE_PARTIAL_RX_CSUM) != 0 &&\r\nskb->protocol == htons(ETH_P_IP) &&\r\nskb->len > 64) {\r\nskb->csum = be32_to_cpu(cur_p->app3 & 0xFFFF);\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\n}\r\nnetif_rx(skb);\r\nsize += length;\r\npackets++;\r\nnew_skb = netdev_alloc_skb_ip_align(ndev, lp->max_frm_size);\r\nif (!new_skb)\r\nreturn;\r\ncur_p->phys = dma_map_single(ndev->dev.parent, new_skb->data,\r\nlp->max_frm_size,\r\nDMA_FROM_DEVICE);\r\ncur_p->cntrl = lp->max_frm_size;\r\ncur_p->status = 0;\r\ncur_p->sw_id_offset = (u32) new_skb;\r\n++lp->rx_bd_ci;\r\nlp->rx_bd_ci %= RX_BD_NUM;\r\ncur_p = &lp->rx_bd_v[lp->rx_bd_ci];\r\n}\r\nndev->stats.rx_packets += packets;\r\nndev->stats.rx_bytes += size;\r\nif (tail_p)\r\naxienet_dma_out32(lp, XAXIDMA_RX_TDESC_OFFSET, tail_p);\r\n}\r\nstatic irqreturn_t axienet_tx_irq(int irq, void *_ndev)\r\n{\r\nu32 cr;\r\nunsigned int status;\r\nstruct net_device *ndev = _ndev;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstatus = axienet_dma_in32(lp, XAXIDMA_TX_SR_OFFSET);\r\nif (status & (XAXIDMA_IRQ_IOC_MASK | XAXIDMA_IRQ_DELAY_MASK)) {\r\naxienet_dma_out32(lp, XAXIDMA_TX_SR_OFFSET, status);\r\naxienet_start_xmit_done(lp->ndev);\r\ngoto out;\r\n}\r\nif (!(status & XAXIDMA_IRQ_ALL_MASK))\r\ndev_err(&ndev->dev, "No interrupts asserted in Tx path");\r\nif (status & XAXIDMA_IRQ_ERROR_MASK) {\r\ndev_err(&ndev->dev, "DMA Tx error 0x%x\n", status);\r\ndev_err(&ndev->dev, "Current BD is at: 0x%x\n",\r\n(lp->tx_bd_v[lp->tx_bd_ci]).phys);\r\ncr = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\ncr &= (~XAXIDMA_IRQ_ALL_MASK);\r\naxienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET, cr);\r\ncr = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\ncr &= (~XAXIDMA_IRQ_ALL_MASK);\r\naxienet_dma_out32(lp, XAXIDMA_RX_CR_OFFSET, cr);\r\ntasklet_schedule(&lp->dma_err_tasklet);\r\naxienet_dma_out32(lp, XAXIDMA_TX_SR_OFFSET, status);\r\n}\r\nout:\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t axienet_rx_irq(int irq, void *_ndev)\r\n{\r\nu32 cr;\r\nunsigned int status;\r\nstruct net_device *ndev = _ndev;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstatus = axienet_dma_in32(lp, XAXIDMA_RX_SR_OFFSET);\r\nif (status & (XAXIDMA_IRQ_IOC_MASK | XAXIDMA_IRQ_DELAY_MASK)) {\r\naxienet_dma_out32(lp, XAXIDMA_RX_SR_OFFSET, status);\r\naxienet_recv(lp->ndev);\r\ngoto out;\r\n}\r\nif (!(status & XAXIDMA_IRQ_ALL_MASK))\r\ndev_err(&ndev->dev, "No interrupts asserted in Rx path");\r\nif (status & XAXIDMA_IRQ_ERROR_MASK) {\r\ndev_err(&ndev->dev, "DMA Rx error 0x%x\n", status);\r\ndev_err(&ndev->dev, "Current BD is at: 0x%x\n",\r\n(lp->rx_bd_v[lp->rx_bd_ci]).phys);\r\ncr = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\ncr &= (~XAXIDMA_IRQ_ALL_MASK);\r\naxienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET, cr);\r\ncr = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\ncr &= (~XAXIDMA_IRQ_ALL_MASK);\r\naxienet_dma_out32(lp, XAXIDMA_RX_CR_OFFSET, cr);\r\ntasklet_schedule(&lp->dma_err_tasklet);\r\naxienet_dma_out32(lp, XAXIDMA_RX_SR_OFFSET, status);\r\n}\r\nout:\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int axienet_open(struct net_device *ndev)\r\n{\r\nint ret, mdio_mcreg;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\ndev_dbg(&ndev->dev, "axienet_open()\n");\r\nmdio_mcreg = axienet_ior(lp, XAE_MDIO_MC_OFFSET);\r\nret = axienet_mdio_wait_until_ready(lp);\r\nif (ret < 0)\r\nreturn ret;\r\naxienet_iow(lp, XAE_MDIO_MC_OFFSET,\r\n(mdio_mcreg & (~XAE_MDIO_MC_MDIOEN_MASK)));\r\naxienet_device_reset(ndev);\r\naxienet_iow(lp, XAE_MDIO_MC_OFFSET, mdio_mcreg);\r\nret = axienet_mdio_wait_until_ready(lp);\r\nif (ret < 0)\r\nreturn ret;\r\nif (lp->phy_node) {\r\nif (lp->phy_type == XAE_PHY_TYPE_GMII) {\r\nlp->phy_dev = of_phy_connect(lp->ndev, lp->phy_node,\r\naxienet_adjust_link, 0,\r\nPHY_INTERFACE_MODE_GMII);\r\n} else if (lp->phy_type == XAE_PHY_TYPE_RGMII_2_0) {\r\nlp->phy_dev = of_phy_connect(lp->ndev, lp->phy_node,\r\naxienet_adjust_link, 0,\r\nPHY_INTERFACE_MODE_RGMII_ID);\r\n}\r\nif (!lp->phy_dev)\r\ndev_err(lp->dev, "of_phy_connect() failed\n");\r\nelse\r\nphy_start(lp->phy_dev);\r\n}\r\ntasklet_init(&lp->dma_err_tasklet, axienet_dma_err_handler,\r\n(unsigned long) lp);\r\nret = request_irq(lp->tx_irq, axienet_tx_irq, 0, ndev->name, ndev);\r\nif (ret)\r\ngoto err_tx_irq;\r\nret = request_irq(lp->rx_irq, axienet_rx_irq, 0, ndev->name, ndev);\r\nif (ret)\r\ngoto err_rx_irq;\r\nreturn 0;\r\nerr_rx_irq:\r\nfree_irq(lp->tx_irq, ndev);\r\nerr_tx_irq:\r\nif (lp->phy_dev)\r\nphy_disconnect(lp->phy_dev);\r\nlp->phy_dev = NULL;\r\ntasklet_kill(&lp->dma_err_tasklet);\r\ndev_err(lp->dev, "request_irq() failed\n");\r\nreturn ret;\r\n}\r\nstatic int axienet_stop(struct net_device *ndev)\r\n{\r\nu32 cr;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\ndev_dbg(&ndev->dev, "axienet_close()\n");\r\ncr = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\naxienet_dma_out32(lp, XAXIDMA_RX_CR_OFFSET,\r\ncr & (~XAXIDMA_CR_RUNSTOP_MASK));\r\ncr = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\naxienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET,\r\ncr & (~XAXIDMA_CR_RUNSTOP_MASK));\r\naxienet_setoptions(ndev, lp->options &\r\n~(XAE_OPTION_TXEN | XAE_OPTION_RXEN));\r\ntasklet_kill(&lp->dma_err_tasklet);\r\nfree_irq(lp->tx_irq, ndev);\r\nfree_irq(lp->rx_irq, ndev);\r\nif (lp->phy_dev)\r\nphy_disconnect(lp->phy_dev);\r\nlp->phy_dev = NULL;\r\naxienet_dma_bd_release(ndev);\r\nreturn 0;\r\n}\r\nstatic int axienet_change_mtu(struct net_device *ndev, int new_mtu)\r\n{\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nif (netif_running(ndev))\r\nreturn -EBUSY;\r\nif ((new_mtu + VLAN_ETH_HLEN +\r\nXAE_TRL_SIZE) > lp->rxmem)\r\nreturn -EINVAL;\r\nif ((new_mtu > XAE_JUMBO_MTU) || (new_mtu < 64))\r\nreturn -EINVAL;\r\nndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nstatic void axienet_poll_controller(struct net_device *ndev)\r\n{\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\ndisable_irq(lp->tx_irq);\r\ndisable_irq(lp->rx_irq);\r\naxienet_rx_irq(lp->tx_irq, ndev);\r\naxienet_tx_irq(lp->rx_irq, ndev);\r\nenable_irq(lp->tx_irq);\r\nenable_irq(lp->rx_irq);\r\n}\r\nstatic int axienet_ethtools_get_settings(struct net_device *ndev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstruct phy_device *phydev = lp->phy_dev;\r\nif (!phydev)\r\nreturn -ENODEV;\r\nreturn phy_ethtool_gset(phydev, ecmd);\r\n}\r\nstatic int axienet_ethtools_set_settings(struct net_device *ndev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nstruct phy_device *phydev = lp->phy_dev;\r\nif (!phydev)\r\nreturn -ENODEV;\r\nreturn phy_ethtool_sset(phydev, ecmd);\r\n}\r\nstatic void axienet_ethtools_get_drvinfo(struct net_device *ndev,\r\nstruct ethtool_drvinfo *ed)\r\n{\r\nstrlcpy(ed->driver, DRIVER_NAME, sizeof(ed->driver));\r\nstrlcpy(ed->version, DRIVER_VERSION, sizeof(ed->version));\r\ned->regdump_len = sizeof(u32) * AXIENET_REGS_N;\r\n}\r\nstatic int axienet_ethtools_get_regs_len(struct net_device *ndev)\r\n{\r\nreturn sizeof(u32) * AXIENET_REGS_N;\r\n}\r\nstatic void axienet_ethtools_get_regs(struct net_device *ndev,\r\nstruct ethtool_regs *regs, void *ret)\r\n{\r\nu32 *data = (u32 *) ret;\r\nsize_t len = sizeof(u32) * AXIENET_REGS_N;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nregs->version = 0;\r\nregs->len = len;\r\nmemset(data, 0, len);\r\ndata[0] = axienet_ior(lp, XAE_RAF_OFFSET);\r\ndata[1] = axienet_ior(lp, XAE_TPF_OFFSET);\r\ndata[2] = axienet_ior(lp, XAE_IFGP_OFFSET);\r\ndata[3] = axienet_ior(lp, XAE_IS_OFFSET);\r\ndata[4] = axienet_ior(lp, XAE_IP_OFFSET);\r\ndata[5] = axienet_ior(lp, XAE_IE_OFFSET);\r\ndata[6] = axienet_ior(lp, XAE_TTAG_OFFSET);\r\ndata[7] = axienet_ior(lp, XAE_RTAG_OFFSET);\r\ndata[8] = axienet_ior(lp, XAE_UAWL_OFFSET);\r\ndata[9] = axienet_ior(lp, XAE_UAWU_OFFSET);\r\ndata[10] = axienet_ior(lp, XAE_TPID0_OFFSET);\r\ndata[11] = axienet_ior(lp, XAE_TPID1_OFFSET);\r\ndata[12] = axienet_ior(lp, XAE_PPST_OFFSET);\r\ndata[13] = axienet_ior(lp, XAE_RCW0_OFFSET);\r\ndata[14] = axienet_ior(lp, XAE_RCW1_OFFSET);\r\ndata[15] = axienet_ior(lp, XAE_TC_OFFSET);\r\ndata[16] = axienet_ior(lp, XAE_FCC_OFFSET);\r\ndata[17] = axienet_ior(lp, XAE_EMMC_OFFSET);\r\ndata[18] = axienet_ior(lp, XAE_PHYC_OFFSET);\r\ndata[19] = axienet_ior(lp, XAE_MDIO_MC_OFFSET);\r\ndata[20] = axienet_ior(lp, XAE_MDIO_MCR_OFFSET);\r\ndata[21] = axienet_ior(lp, XAE_MDIO_MWD_OFFSET);\r\ndata[22] = axienet_ior(lp, XAE_MDIO_MRD_OFFSET);\r\ndata[23] = axienet_ior(lp, XAE_MDIO_MIS_OFFSET);\r\ndata[24] = axienet_ior(lp, XAE_MDIO_MIP_OFFSET);\r\ndata[25] = axienet_ior(lp, XAE_MDIO_MIE_OFFSET);\r\ndata[26] = axienet_ior(lp, XAE_MDIO_MIC_OFFSET);\r\ndata[27] = axienet_ior(lp, XAE_UAW0_OFFSET);\r\ndata[28] = axienet_ior(lp, XAE_UAW1_OFFSET);\r\ndata[29] = axienet_ior(lp, XAE_FMI_OFFSET);\r\ndata[30] = axienet_ior(lp, XAE_AF0_OFFSET);\r\ndata[31] = axienet_ior(lp, XAE_AF1_OFFSET);\r\n}\r\nstatic void\r\naxienet_ethtools_get_pauseparam(struct net_device *ndev,\r\nstruct ethtool_pauseparam *epauseparm)\r\n{\r\nu32 regval;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nepauseparm->autoneg = 0;\r\nregval = axienet_ior(lp, XAE_FCC_OFFSET);\r\nepauseparm->tx_pause = regval & XAE_FCC_FCTX_MASK;\r\nepauseparm->rx_pause = regval & XAE_FCC_FCRX_MASK;\r\n}\r\nstatic int\r\naxienet_ethtools_set_pauseparam(struct net_device *ndev,\r\nstruct ethtool_pauseparam *epauseparm)\r\n{\r\nu32 regval = 0;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nif (netif_running(ndev)) {\r\nnetdev_err(ndev,\r\n"Please stop netif before applying configuration\n");\r\nreturn -EFAULT;\r\n}\r\nregval = axienet_ior(lp, XAE_FCC_OFFSET);\r\nif (epauseparm->tx_pause)\r\nregval |= XAE_FCC_FCTX_MASK;\r\nelse\r\nregval &= ~XAE_FCC_FCTX_MASK;\r\nif (epauseparm->rx_pause)\r\nregval |= XAE_FCC_FCRX_MASK;\r\nelse\r\nregval &= ~XAE_FCC_FCRX_MASK;\r\naxienet_iow(lp, XAE_FCC_OFFSET, regval);\r\nreturn 0;\r\n}\r\nstatic int axienet_ethtools_get_coalesce(struct net_device *ndev,\r\nstruct ethtool_coalesce *ecoalesce)\r\n{\r\nu32 regval = 0;\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nregval = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\necoalesce->rx_max_coalesced_frames = (regval & XAXIDMA_COALESCE_MASK)\r\n>> XAXIDMA_COALESCE_SHIFT;\r\nregval = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\necoalesce->tx_max_coalesced_frames = (regval & XAXIDMA_COALESCE_MASK)\r\n>> XAXIDMA_COALESCE_SHIFT;\r\nreturn 0;\r\n}\r\nstatic int axienet_ethtools_set_coalesce(struct net_device *ndev,\r\nstruct ethtool_coalesce *ecoalesce)\r\n{\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\nif (netif_running(ndev)) {\r\nnetdev_err(ndev,\r\n"Please stop netif before applying configuration\n");\r\nreturn -EFAULT;\r\n}\r\nif ((ecoalesce->rx_coalesce_usecs) ||\r\n(ecoalesce->rx_coalesce_usecs_irq) ||\r\n(ecoalesce->rx_max_coalesced_frames_irq) ||\r\n(ecoalesce->tx_coalesce_usecs) ||\r\n(ecoalesce->tx_coalesce_usecs_irq) ||\r\n(ecoalesce->tx_max_coalesced_frames_irq) ||\r\n(ecoalesce->stats_block_coalesce_usecs) ||\r\n(ecoalesce->use_adaptive_rx_coalesce) ||\r\n(ecoalesce->use_adaptive_tx_coalesce) ||\r\n(ecoalesce->pkt_rate_low) ||\r\n(ecoalesce->rx_coalesce_usecs_low) ||\r\n(ecoalesce->rx_max_coalesced_frames_low) ||\r\n(ecoalesce->tx_coalesce_usecs_low) ||\r\n(ecoalesce->tx_max_coalesced_frames_low) ||\r\n(ecoalesce->pkt_rate_high) ||\r\n(ecoalesce->rx_coalesce_usecs_high) ||\r\n(ecoalesce->rx_max_coalesced_frames_high) ||\r\n(ecoalesce->tx_coalesce_usecs_high) ||\r\n(ecoalesce->tx_max_coalesced_frames_high) ||\r\n(ecoalesce->rate_sample_interval))\r\nreturn -EOPNOTSUPP;\r\nif (ecoalesce->rx_max_coalesced_frames)\r\nlp->coalesce_count_rx = ecoalesce->rx_max_coalesced_frames;\r\nif (ecoalesce->tx_max_coalesced_frames)\r\nlp->coalesce_count_tx = ecoalesce->tx_max_coalesced_frames;\r\nreturn 0;\r\n}\r\nstatic void axienet_dma_err_handler(unsigned long data)\r\n{\r\nu32 axienet_status;\r\nu32 cr, i;\r\nint mdio_mcreg;\r\nstruct axienet_local *lp = (struct axienet_local *) data;\r\nstruct net_device *ndev = lp->ndev;\r\nstruct axidma_bd *cur_p;\r\naxienet_setoptions(ndev, lp->options &\r\n~(XAE_OPTION_TXEN | XAE_OPTION_RXEN));\r\nmdio_mcreg = axienet_ior(lp, XAE_MDIO_MC_OFFSET);\r\naxienet_mdio_wait_until_ready(lp);\r\naxienet_iow(lp, XAE_MDIO_MC_OFFSET, (mdio_mcreg &\r\n~XAE_MDIO_MC_MDIOEN_MASK));\r\n__axienet_device_reset(lp, &ndev->dev, XAXIDMA_TX_CR_OFFSET);\r\n__axienet_device_reset(lp, &ndev->dev, XAXIDMA_RX_CR_OFFSET);\r\naxienet_iow(lp, XAE_MDIO_MC_OFFSET, mdio_mcreg);\r\naxienet_mdio_wait_until_ready(lp);\r\nfor (i = 0; i < TX_BD_NUM; i++) {\r\ncur_p = &lp->tx_bd_v[i];\r\nif (cur_p->phys)\r\ndma_unmap_single(ndev->dev.parent, cur_p->phys,\r\n(cur_p->cntrl &\r\nXAXIDMA_BD_CTRL_LENGTH_MASK),\r\nDMA_TO_DEVICE);\r\nif (cur_p->app4)\r\ndev_kfree_skb_irq((struct sk_buff *) cur_p->app4);\r\ncur_p->phys = 0;\r\ncur_p->cntrl = 0;\r\ncur_p->status = 0;\r\ncur_p->app0 = 0;\r\ncur_p->app1 = 0;\r\ncur_p->app2 = 0;\r\ncur_p->app3 = 0;\r\ncur_p->app4 = 0;\r\ncur_p->sw_id_offset = 0;\r\n}\r\nfor (i = 0; i < RX_BD_NUM; i++) {\r\ncur_p = &lp->rx_bd_v[i];\r\ncur_p->status = 0;\r\ncur_p->app0 = 0;\r\ncur_p->app1 = 0;\r\ncur_p->app2 = 0;\r\ncur_p->app3 = 0;\r\ncur_p->app4 = 0;\r\n}\r\nlp->tx_bd_ci = 0;\r\nlp->tx_bd_tail = 0;\r\nlp->rx_bd_ci = 0;\r\ncr = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\ncr = ((cr & ~XAXIDMA_COALESCE_MASK) |\r\n(XAXIDMA_DFT_RX_THRESHOLD << XAXIDMA_COALESCE_SHIFT));\r\ncr = ((cr & ~XAXIDMA_DELAY_MASK) |\r\n(XAXIDMA_DFT_RX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\r\ncr |= XAXIDMA_IRQ_ALL_MASK;\r\naxienet_dma_out32(lp, XAXIDMA_RX_CR_OFFSET, cr);\r\ncr = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\ncr = (((cr & ~XAXIDMA_COALESCE_MASK)) |\r\n(XAXIDMA_DFT_TX_THRESHOLD << XAXIDMA_COALESCE_SHIFT));\r\ncr = (((cr & ~XAXIDMA_DELAY_MASK)) |\r\n(XAXIDMA_DFT_TX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\r\ncr |= XAXIDMA_IRQ_ALL_MASK;\r\naxienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET, cr);\r\naxienet_dma_out32(lp, XAXIDMA_RX_CDESC_OFFSET, lp->rx_bd_p);\r\ncr = axienet_dma_in32(lp, XAXIDMA_RX_CR_OFFSET);\r\naxienet_dma_out32(lp, XAXIDMA_RX_CR_OFFSET,\r\ncr | XAXIDMA_CR_RUNSTOP_MASK);\r\naxienet_dma_out32(lp, XAXIDMA_RX_TDESC_OFFSET, lp->rx_bd_p +\r\n(sizeof(*lp->rx_bd_v) * (RX_BD_NUM - 1)));\r\naxienet_dma_out32(lp, XAXIDMA_TX_CDESC_OFFSET, lp->tx_bd_p);\r\ncr = axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET);\r\naxienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET,\r\ncr | XAXIDMA_CR_RUNSTOP_MASK);\r\naxienet_status = axienet_ior(lp, XAE_RCW1_OFFSET);\r\naxienet_status &= ~XAE_RCW1_RX_MASK;\r\naxienet_iow(lp, XAE_RCW1_OFFSET, axienet_status);\r\naxienet_status = axienet_ior(lp, XAE_IP_OFFSET);\r\nif (axienet_status & XAE_INT_RXRJECT_MASK)\r\naxienet_iow(lp, XAE_IS_OFFSET, XAE_INT_RXRJECT_MASK);\r\naxienet_iow(lp, XAE_FCC_OFFSET, XAE_FCC_FCRX_MASK);\r\naxienet_setoptions(ndev, lp->options &\r\n~(XAE_OPTION_TXEN | XAE_OPTION_RXEN));\r\naxienet_set_mac_address(ndev, NULL);\r\naxienet_set_multicast_list(ndev);\r\naxienet_setoptions(ndev, lp->options);\r\n}\r\nstatic int axienet_probe(struct platform_device *pdev)\r\n{\r\nint ret;\r\nstruct device_node *np;\r\nstruct axienet_local *lp;\r\nstruct net_device *ndev;\r\nu8 mac_addr[6];\r\nstruct resource *ethres, dmares;\r\nu32 value;\r\nndev = alloc_etherdev(sizeof(*lp));\r\nif (!ndev)\r\nreturn -ENOMEM;\r\nplatform_set_drvdata(pdev, ndev);\r\nSET_NETDEV_DEV(ndev, &pdev->dev);\r\nndev->flags &= ~IFF_MULTICAST;\r\nndev->features = NETIF_F_SG;\r\nndev->netdev_ops = &axienet_netdev_ops;\r\nndev->ethtool_ops = &axienet_ethtool_ops;\r\nlp = netdev_priv(ndev);\r\nlp->ndev = ndev;\r\nlp->dev = &pdev->dev;\r\nlp->options = XAE_OPTION_DEFAULTS;\r\nethres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nlp->regs = devm_ioremap_resource(&pdev->dev, ethres);\r\nif (IS_ERR(lp->regs)) {\r\ndev_err(&pdev->dev, "could not map Axi Ethernet regs.\n");\r\nret = PTR_ERR(lp->regs);\r\ngoto free_netdev;\r\n}\r\nlp->features = 0;\r\nret = of_property_read_u32(pdev->dev.of_node, "xlnx,txcsum", &value);\r\nif (!ret) {\r\nswitch (value) {\r\ncase 1:\r\nlp->csum_offload_on_tx_path =\r\nXAE_FEATURE_PARTIAL_TX_CSUM;\r\nlp->features |= XAE_FEATURE_PARTIAL_TX_CSUM;\r\nndev->features |= NETIF_F_IP_CSUM;\r\nbreak;\r\ncase 2:\r\nlp->csum_offload_on_tx_path =\r\nXAE_FEATURE_FULL_TX_CSUM;\r\nlp->features |= XAE_FEATURE_FULL_TX_CSUM;\r\nndev->features |= NETIF_F_IP_CSUM;\r\nbreak;\r\ndefault:\r\nlp->csum_offload_on_tx_path = XAE_NO_CSUM_OFFLOAD;\r\n}\r\n}\r\nret = of_property_read_u32(pdev->dev.of_node, "xlnx,rxcsum", &value);\r\nif (!ret) {\r\nswitch (value) {\r\ncase 1:\r\nlp->csum_offload_on_rx_path =\r\nXAE_FEATURE_PARTIAL_RX_CSUM;\r\nlp->features |= XAE_FEATURE_PARTIAL_RX_CSUM;\r\nbreak;\r\ncase 2:\r\nlp->csum_offload_on_rx_path =\r\nXAE_FEATURE_FULL_RX_CSUM;\r\nlp->features |= XAE_FEATURE_FULL_RX_CSUM;\r\nbreak;\r\ndefault:\r\nlp->csum_offload_on_rx_path = XAE_NO_CSUM_OFFLOAD;\r\n}\r\n}\r\nof_property_read_u32(pdev->dev.of_node, "xlnx,rxmem", &lp->rxmem);\r\nof_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &lp->phy_type);\r\nnp = of_parse_phandle(pdev->dev.of_node, "axistream-connected", 0);\r\nif (IS_ERR(np)) {\r\ndev_err(&pdev->dev, "could not find DMA node\n");\r\nret = PTR_ERR(np);\r\ngoto free_netdev;\r\n}\r\nret = of_address_to_resource(np, 0, &dmares);\r\nif (ret) {\r\ndev_err(&pdev->dev, "unable to get DMA resource\n");\r\ngoto free_netdev;\r\n}\r\nlp->dma_regs = devm_ioremap_resource(&pdev->dev, &dmares);\r\nif (IS_ERR(lp->dma_regs)) {\r\ndev_err(&pdev->dev, "could not map DMA regs\n");\r\nret = PTR_ERR(lp->dma_regs);\r\ngoto free_netdev;\r\n}\r\nlp->rx_irq = irq_of_parse_and_map(np, 1);\r\nlp->tx_irq = irq_of_parse_and_map(np, 0);\r\nof_node_put(np);\r\nif ((lp->rx_irq <= 0) || (lp->tx_irq <= 0)) {\r\ndev_err(&pdev->dev, "could not determine irqs\n");\r\nret = -ENOMEM;\r\ngoto free_netdev;\r\n}\r\nret = of_property_read_u8_array(pdev->dev.of_node,\r\n"local-mac-address", mac_addr, 6);\r\nif (ret) {\r\ndev_err(&pdev->dev, "could not find MAC address\n");\r\ngoto free_netdev;\r\n}\r\naxienet_set_mac_address(ndev, (void *)mac_addr);\r\nlp->coalesce_count_rx = XAXIDMA_DFT_RX_THRESHOLD;\r\nlp->coalesce_count_tx = XAXIDMA_DFT_TX_THRESHOLD;\r\nlp->phy_node = of_parse_phandle(pdev->dev.of_node, "phy-handle", 0);\r\nif (lp->phy_node) {\r\nret = axienet_mdio_setup(lp, pdev->dev.of_node);\r\nif (ret)\r\ndev_warn(&pdev->dev, "error registering MDIO bus\n");\r\n}\r\nret = register_netdev(lp->ndev);\r\nif (ret) {\r\ndev_err(lp->dev, "register_netdev() error (%i)\n", ret);\r\ngoto free_netdev;\r\n}\r\nreturn 0;\r\nfree_netdev:\r\nfree_netdev(ndev);\r\nreturn ret;\r\n}\r\nstatic int axienet_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *ndev = platform_get_drvdata(pdev);\r\nstruct axienet_local *lp = netdev_priv(ndev);\r\naxienet_mdio_teardown(lp);\r\nunregister_netdev(ndev);\r\nof_node_put(lp->phy_node);\r\nlp->phy_node = NULL;\r\nfree_netdev(ndev);\r\nreturn 0;\r\n}
