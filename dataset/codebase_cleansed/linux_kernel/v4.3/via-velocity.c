static void velocity_set_power_state(struct velocity_info *vptr, char state)\r\n{\r\nvoid *addr = vptr->mac_regs;\r\nif (vptr->pdev)\r\npci_set_power_state(vptr->pdev, state);\r\nelse\r\nwriteb(state, addr + 0x154);\r\n}\r\nstatic void mac_get_cam_mask(struct mac_regs __iomem *regs, u8 *mask)\r\n{\r\nint i;\r\nBYTE_REG_BITS_SET(CAMCR_PS_CAM_MASK, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\nwriteb(0, &regs->CAMADDR);\r\nfor (i = 0; i < 8; i++)\r\n*mask++ = readb(&(regs->MARCAM[i]));\r\nwriteb(0, &regs->CAMADDR);\r\nBYTE_REG_BITS_SET(CAMCR_PS_MAR, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\n}\r\nstatic void mac_set_cam_mask(struct mac_regs __iomem *regs, u8 *mask)\r\n{\r\nint i;\r\nBYTE_REG_BITS_SET(CAMCR_PS_CAM_MASK, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\nwriteb(CAMADDR_CAMEN, &regs->CAMADDR);\r\nfor (i = 0; i < 8; i++)\r\nwriteb(*mask++, &(regs->MARCAM[i]));\r\nwriteb(0, &regs->CAMADDR);\r\nBYTE_REG_BITS_SET(CAMCR_PS_MAR, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\n}\r\nstatic void mac_set_vlan_cam_mask(struct mac_regs __iomem *regs, u8 *mask)\r\n{\r\nint i;\r\nBYTE_REG_BITS_SET(CAMCR_PS_CAM_MASK, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\nwriteb(CAMADDR_CAMEN | CAMADDR_VCAMSL, &regs->CAMADDR);\r\nfor (i = 0; i < 8; i++)\r\nwriteb(*mask++, &(regs->MARCAM[i]));\r\nwriteb(0, &regs->CAMADDR);\r\nBYTE_REG_BITS_SET(CAMCR_PS_MAR, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\n}\r\nstatic void mac_set_cam(struct mac_regs __iomem *regs, int idx, const u8 *addr)\r\n{\r\nint i;\r\nBYTE_REG_BITS_SET(CAMCR_PS_CAM_DATA, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\nidx &= (64 - 1);\r\nwriteb(CAMADDR_CAMEN | idx, &regs->CAMADDR);\r\nfor (i = 0; i < 6; i++)\r\nwriteb(*addr++, &(regs->MARCAM[i]));\r\nBYTE_REG_BITS_ON(CAMCR_CAMWR, &regs->CAMCR);\r\nudelay(10);\r\nwriteb(0, &regs->CAMADDR);\r\nBYTE_REG_BITS_SET(CAMCR_PS_MAR, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\n}\r\nstatic void mac_set_vlan_cam(struct mac_regs __iomem *regs, int idx,\r\nconst u8 *addr)\r\n{\r\nBYTE_REG_BITS_SET(CAMCR_PS_CAM_DATA, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\nidx &= (64 - 1);\r\nwriteb(CAMADDR_CAMEN | CAMADDR_VCAMSL | idx, &regs->CAMADDR);\r\nwritew(*((u16 *) addr), &regs->MARCAM[0]);\r\nBYTE_REG_BITS_ON(CAMCR_CAMWR, &regs->CAMCR);\r\nudelay(10);\r\nwriteb(0, &regs->CAMADDR);\r\nBYTE_REG_BITS_SET(CAMCR_PS_MAR, CAMCR_PS1 | CAMCR_PS0, &regs->CAMCR);\r\n}\r\nstatic void mac_wol_reset(struct mac_regs __iomem *regs)\r\n{\r\nBYTE_REG_BITS_OFF(STICKHW_SWPTAG, &regs->STICKHW);\r\nBYTE_REG_BITS_OFF((STICKHW_DS1 | STICKHW_DS0), &regs->STICKHW);\r\nBYTE_REG_BITS_OFF(CHIPGCR_FCGMII, &regs->CHIPGCR);\r\nBYTE_REG_BITS_OFF(CHIPGCR_FCMODE, &regs->CHIPGCR);\r\nwriteb(WOLCFG_PMEOVR, &regs->WOLCFGClr);\r\nwritew(0xFFFF, &regs->WOLCRClr);\r\nwritew(0xFFFF, &regs->WOLSRClr);\r\n}\r\nstatic const char *get_chip_name(enum chip_type chip_id)\r\n{\r\nint i;\r\nfor (i = 0; chip_info_table[i].name != NULL; i++)\r\nif (chip_info_table[i].chip_id == chip_id)\r\nbreak;\r\nreturn chip_info_table[i].name;\r\n}\r\nstatic void velocity_set_int_opt(int *opt, int val, int min, int max, int def,\r\nchar *name, const char *devname)\r\n{\r\nif (val == -1)\r\n*opt = def;\r\nelse if (val < min || val > max) {\r\nVELOCITY_PRT(MSG_LEVEL_INFO, KERN_NOTICE "%s: the value of parameter %s is invalid, the valid range is (%d-%d)\n",\r\ndevname, name, min, max);\r\n*opt = def;\r\n} else {\r\nVELOCITY_PRT(MSG_LEVEL_INFO, KERN_INFO "%s: set value of parameter %s to %d\n",\r\ndevname, name, val);\r\n*opt = val;\r\n}\r\n}\r\nstatic void velocity_set_bool_opt(u32 *opt, int val, int def, u32 flag,\r\nchar *name, const char *devname)\r\n{\r\n(*opt) &= (~flag);\r\nif (val == -1)\r\n*opt |= (def ? flag : 0);\r\nelse if (val < 0 || val > 1) {\r\nprintk(KERN_NOTICE "%s: the value of parameter %s is invalid, the valid range is (0-1)\n",\r\ndevname, name);\r\n*opt |= (def ? flag : 0);\r\n} else {\r\nprintk(KERN_INFO "%s: set parameter %s to %s\n",\r\ndevname, name, val ? "TRUE" : "FALSE");\r\n*opt |= (val ? flag : 0);\r\n}\r\n}\r\nstatic void velocity_get_options(struct velocity_opt *opts, int index,\r\nconst char *devname)\r\n{\r\nvelocity_set_int_opt(&opts->rx_thresh, rx_thresh[index], RX_THRESH_MIN, RX_THRESH_MAX, RX_THRESH_DEF, "rx_thresh", devname);\r\nvelocity_set_int_opt(&opts->DMA_length, DMA_length[index], DMA_LENGTH_MIN, DMA_LENGTH_MAX, DMA_LENGTH_DEF, "DMA_length", devname);\r\nvelocity_set_int_opt(&opts->numrx, RxDescriptors[index], RX_DESC_MIN, RX_DESC_MAX, RX_DESC_DEF, "RxDescriptors", devname);\r\nvelocity_set_int_opt(&opts->numtx, TxDescriptors[index], TX_DESC_MIN, TX_DESC_MAX, TX_DESC_DEF, "TxDescriptors", devname);\r\nvelocity_set_int_opt(&opts->flow_cntl, flow_control[index], FLOW_CNTL_MIN, FLOW_CNTL_MAX, FLOW_CNTL_DEF, "flow_control", devname);\r\nvelocity_set_bool_opt(&opts->flags, IP_byte_align[index], IP_ALIG_DEF, VELOCITY_FLAGS_IP_ALIGN, "IP_byte_align", devname);\r\nvelocity_set_bool_opt(&opts->flags, ValPktLen[index], VAL_PKT_LEN_DEF, VELOCITY_FLAGS_VAL_PKT_LEN, "ValPktLen", devname);\r\nvelocity_set_int_opt((int *) &opts->spd_dpx, speed_duplex[index], MED_LNK_MIN, MED_LNK_MAX, MED_LNK_DEF, "Media link mode", devname);\r\nvelocity_set_int_opt(&opts->wol_opts, wol_opts[index], WOL_OPT_MIN, WOL_OPT_MAX, WOL_OPT_DEF, "Wake On Lan options", devname);\r\nopts->numrx = (opts->numrx & ~3);\r\n}\r\nstatic void velocity_init_cam_filter(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nunsigned int vid, i = 0;\r\nWORD_REG_BITS_SET(MCFG_PQEN, MCFG_RTGOPT, &regs->MCFG);\r\nWORD_REG_BITS_ON(MCFG_VIDFR, &regs->MCFG);\r\nmemset(vptr->vCAMmask, 0, sizeof(u8) * 8);\r\nmemset(vptr->mCAMmask, 0, sizeof(u8) * 8);\r\nmac_set_vlan_cam_mask(regs, vptr->vCAMmask);\r\nmac_set_cam_mask(regs, vptr->mCAMmask);\r\nfor_each_set_bit(vid, vptr->active_vlans, VLAN_N_VID) {\r\nmac_set_vlan_cam(regs, i, (u8 *) &vid);\r\nvptr->vCAMmask[i / 8] |= 0x1 << (i % 8);\r\nif (++i >= VCAM_SIZE)\r\nbreak;\r\n}\r\nmac_set_vlan_cam_mask(regs, vptr->vCAMmask);\r\n}\r\nstatic int velocity_vlan_rx_add_vid(struct net_device *dev,\r\n__be16 proto, u16 vid)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nspin_lock_irq(&vptr->lock);\r\nset_bit(vid, vptr->active_vlans);\r\nvelocity_init_cam_filter(vptr);\r\nspin_unlock_irq(&vptr->lock);\r\nreturn 0;\r\n}\r\nstatic int velocity_vlan_rx_kill_vid(struct net_device *dev,\r\n__be16 proto, u16 vid)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nspin_lock_irq(&vptr->lock);\r\nclear_bit(vid, vptr->active_vlans);\r\nvelocity_init_cam_filter(vptr);\r\nspin_unlock_irq(&vptr->lock);\r\nreturn 0;\r\n}\r\nstatic void velocity_init_rx_ring_indexes(struct velocity_info *vptr)\r\n{\r\nvptr->rx.dirty = vptr->rx.filled = vptr->rx.curr = 0;\r\n}\r\nstatic void velocity_rx_reset(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nint i;\r\nvelocity_init_rx_ring_indexes(vptr);\r\nfor (i = 0; i < vptr->options.numrx; ++i)\r\nvptr->rx.ring[i].rdesc0.len |= OWNED_BY_NIC;\r\nwritew(vptr->options.numrx, &regs->RBRDU);\r\nwritel(vptr->rx.pool_dma, &regs->RDBaseLo);\r\nwritew(0, &regs->RDIdx);\r\nwritew(vptr->options.numrx - 1, &regs->RDCSize);\r\n}\r\nstatic u32 velocity_get_opt_media_mode(struct velocity_info *vptr)\r\n{\r\nu32 status = 0;\r\nswitch (vptr->options.spd_dpx) {\r\ncase SPD_DPX_AUTO:\r\nstatus = VELOCITY_AUTONEG_ENABLE;\r\nbreak;\r\ncase SPD_DPX_100_FULL:\r\nstatus = VELOCITY_SPEED_100 | VELOCITY_DUPLEX_FULL;\r\nbreak;\r\ncase SPD_DPX_10_FULL:\r\nstatus = VELOCITY_SPEED_10 | VELOCITY_DUPLEX_FULL;\r\nbreak;\r\ncase SPD_DPX_100_HALF:\r\nstatus = VELOCITY_SPEED_100;\r\nbreak;\r\ncase SPD_DPX_10_HALF:\r\nstatus = VELOCITY_SPEED_10;\r\nbreak;\r\ncase SPD_DPX_1000_FULL:\r\nstatus = VELOCITY_SPEED_1000 | VELOCITY_DUPLEX_FULL;\r\nbreak;\r\n}\r\nvptr->mii_status = status;\r\nreturn status;\r\n}\r\nstatic void safe_disable_mii_autopoll(struct mac_regs __iomem *regs)\r\n{\r\nu16 ww;\r\nwriteb(0, &regs->MIICR);\r\nfor (ww = 0; ww < W_MAX_TIMEOUT; ww++) {\r\nudelay(1);\r\nif (BYTE_REG_BITS_IS_ON(MIISR_MIDLE, &regs->MIISR))\r\nbreak;\r\n}\r\n}\r\nstatic void enable_mii_autopoll(struct mac_regs __iomem *regs)\r\n{\r\nint ii;\r\nwriteb(0, &(regs->MIICR));\r\nwriteb(MIIADR_SWMPL, &regs->MIIADR);\r\nfor (ii = 0; ii < W_MAX_TIMEOUT; ii++) {\r\nudelay(1);\r\nif (BYTE_REG_BITS_IS_ON(MIISR_MIDLE, &regs->MIISR))\r\nbreak;\r\n}\r\nwriteb(MIICR_MAUTO, &regs->MIICR);\r\nfor (ii = 0; ii < W_MAX_TIMEOUT; ii++) {\r\nudelay(1);\r\nif (!BYTE_REG_BITS_IS_ON(MIISR_MIDLE, &regs->MIISR))\r\nbreak;\r\n}\r\n}\r\nstatic int velocity_mii_read(struct mac_regs __iomem *regs, u8 index, u16 *data)\r\n{\r\nu16 ww;\r\nsafe_disable_mii_autopoll(regs);\r\nwriteb(index, &regs->MIIADR);\r\nBYTE_REG_BITS_ON(MIICR_RCMD, &regs->MIICR);\r\nfor (ww = 0; ww < W_MAX_TIMEOUT; ww++) {\r\nif (!(readb(&regs->MIICR) & MIICR_RCMD))\r\nbreak;\r\n}\r\n*data = readw(&regs->MIIDATA);\r\nenable_mii_autopoll(regs);\r\nif (ww == W_MAX_TIMEOUT)\r\nreturn -ETIMEDOUT;\r\nreturn 0;\r\n}\r\nstatic u32 mii_check_media_mode(struct mac_regs __iomem *regs)\r\n{\r\nu32 status = 0;\r\nu16 ANAR;\r\nif (!MII_REG_BITS_IS_ON(BMSR_LSTATUS, MII_BMSR, regs))\r\nstatus |= VELOCITY_LINK_FAIL;\r\nif (MII_REG_BITS_IS_ON(ADVERTISE_1000FULL, MII_CTRL1000, regs))\r\nstatus |= VELOCITY_SPEED_1000 | VELOCITY_DUPLEX_FULL;\r\nelse if (MII_REG_BITS_IS_ON(ADVERTISE_1000HALF, MII_CTRL1000, regs))\r\nstatus |= (VELOCITY_SPEED_1000);\r\nelse {\r\nvelocity_mii_read(regs, MII_ADVERTISE, &ANAR);\r\nif (ANAR & ADVERTISE_100FULL)\r\nstatus |= (VELOCITY_SPEED_100 | VELOCITY_DUPLEX_FULL);\r\nelse if (ANAR & ADVERTISE_100HALF)\r\nstatus |= VELOCITY_SPEED_100;\r\nelse if (ANAR & ADVERTISE_10FULL)\r\nstatus |= (VELOCITY_SPEED_10 | VELOCITY_DUPLEX_FULL);\r\nelse\r\nstatus |= (VELOCITY_SPEED_10);\r\n}\r\nif (MII_REG_BITS_IS_ON(BMCR_ANENABLE, MII_BMCR, regs)) {\r\nvelocity_mii_read(regs, MII_ADVERTISE, &ANAR);\r\nif ((ANAR & (ADVERTISE_100FULL | ADVERTISE_100HALF | ADVERTISE_10FULL | ADVERTISE_10HALF))\r\n== (ADVERTISE_100FULL | ADVERTISE_100HALF | ADVERTISE_10FULL | ADVERTISE_10HALF)) {\r\nif (MII_REG_BITS_IS_ON(ADVERTISE_1000HALF | ADVERTISE_1000FULL, MII_CTRL1000, regs))\r\nstatus |= VELOCITY_AUTONEG_ENABLE;\r\n}\r\n}\r\nreturn status;\r\n}\r\nstatic int velocity_mii_write(struct mac_regs __iomem *regs, u8 mii_addr, u16 data)\r\n{\r\nu16 ww;\r\nsafe_disable_mii_autopoll(regs);\r\nwriteb(mii_addr, &regs->MIIADR);\r\nwritew(data, &regs->MIIDATA);\r\nBYTE_REG_BITS_ON(MIICR_WCMD, &regs->MIICR);\r\nfor (ww = 0; ww < W_MAX_TIMEOUT; ww++) {\r\nudelay(5);\r\nif (!(readb(&regs->MIICR) & MIICR_WCMD))\r\nbreak;\r\n}\r\nenable_mii_autopoll(regs);\r\nif (ww == W_MAX_TIMEOUT)\r\nreturn -ETIMEDOUT;\r\nreturn 0;\r\n}\r\nstatic void set_mii_flow_control(struct velocity_info *vptr)\r\n{\r\nswitch (vptr->options.flow_cntl) {\r\ncase FLOW_CNTL_TX:\r\nMII_REG_BITS_OFF(ADVERTISE_PAUSE_CAP, MII_ADVERTISE, vptr->mac_regs);\r\nMII_REG_BITS_ON(ADVERTISE_PAUSE_ASYM, MII_ADVERTISE, vptr->mac_regs);\r\nbreak;\r\ncase FLOW_CNTL_RX:\r\nMII_REG_BITS_ON(ADVERTISE_PAUSE_CAP, MII_ADVERTISE, vptr->mac_regs);\r\nMII_REG_BITS_ON(ADVERTISE_PAUSE_ASYM, MII_ADVERTISE, vptr->mac_regs);\r\nbreak;\r\ncase FLOW_CNTL_TX_RX:\r\nMII_REG_BITS_ON(ADVERTISE_PAUSE_CAP, MII_ADVERTISE, vptr->mac_regs);\r\nMII_REG_BITS_OFF(ADVERTISE_PAUSE_ASYM, MII_ADVERTISE, vptr->mac_regs);\r\nbreak;\r\ncase FLOW_CNTL_DISABLE:\r\nMII_REG_BITS_OFF(ADVERTISE_PAUSE_CAP, MII_ADVERTISE, vptr->mac_regs);\r\nMII_REG_BITS_OFF(ADVERTISE_PAUSE_ASYM, MII_ADVERTISE, vptr->mac_regs);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic void mii_set_auto_on(struct velocity_info *vptr)\r\n{\r\nif (MII_REG_BITS_IS_ON(BMCR_ANENABLE, MII_BMCR, vptr->mac_regs))\r\nMII_REG_BITS_ON(BMCR_ANRESTART, MII_BMCR, vptr->mac_regs);\r\nelse\r\nMII_REG_BITS_ON(BMCR_ANENABLE, MII_BMCR, vptr->mac_regs);\r\n}\r\nstatic u32 check_connection_type(struct mac_regs __iomem *regs)\r\n{\r\nu32 status = 0;\r\nu8 PHYSR0;\r\nu16 ANAR;\r\nPHYSR0 = readb(&regs->PHYSR0);\r\nif (PHYSR0 & PHYSR0_FDPX)\r\nstatus |= VELOCITY_DUPLEX_FULL;\r\nif (PHYSR0 & PHYSR0_SPDG)\r\nstatus |= VELOCITY_SPEED_1000;\r\nelse if (PHYSR0 & PHYSR0_SPD10)\r\nstatus |= VELOCITY_SPEED_10;\r\nelse\r\nstatus |= VELOCITY_SPEED_100;\r\nif (MII_REG_BITS_IS_ON(BMCR_ANENABLE, MII_BMCR, regs)) {\r\nvelocity_mii_read(regs, MII_ADVERTISE, &ANAR);\r\nif ((ANAR & (ADVERTISE_100FULL | ADVERTISE_100HALF | ADVERTISE_10FULL | ADVERTISE_10HALF))\r\n== (ADVERTISE_100FULL | ADVERTISE_100HALF | ADVERTISE_10FULL | ADVERTISE_10HALF)) {\r\nif (MII_REG_BITS_IS_ON(ADVERTISE_1000HALF | ADVERTISE_1000FULL, MII_CTRL1000, regs))\r\nstatus |= VELOCITY_AUTONEG_ENABLE;\r\n}\r\n}\r\nreturn status;\r\n}\r\nstatic int velocity_set_media_mode(struct velocity_info *vptr, u32 mii_status)\r\n{\r\nu32 curr_status;\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nvptr->mii_status = mii_check_media_mode(vptr->mac_regs);\r\ncurr_status = vptr->mii_status & (~VELOCITY_LINK_FAIL);\r\nset_mii_flow_control(vptr);\r\nif (PHYID_GET_PHY_ID(vptr->phy_id) == PHYID_CICADA_CS8201)\r\nMII_REG_BITS_ON(AUXCR_MDPPS, MII_NCONFIG, vptr->mac_regs);\r\nif (mii_status & VELOCITY_AUTONEG_ENABLE) {\r\nVELOCITY_PRT(MSG_LEVEL_INFO, "Velocity is AUTO mode\n");\r\nBYTE_REG_BITS_OFF(CHIPGCR_FCMODE, &regs->CHIPGCR);\r\nMII_REG_BITS_ON(ADVERTISE_100FULL | ADVERTISE_100HALF | ADVERTISE_10FULL | ADVERTISE_10HALF, MII_ADVERTISE, vptr->mac_regs);\r\nMII_REG_BITS_ON(ADVERTISE_1000FULL | ADVERTISE_1000HALF, MII_CTRL1000, vptr->mac_regs);\r\nMII_REG_BITS_ON(BMCR_SPEED1000, MII_BMCR, vptr->mac_regs);\r\nmii_set_auto_on(vptr);\r\n} else {\r\nu16 CTRL1000;\r\nu16 ANAR;\r\nu8 CHIPGCR;\r\nBYTE_REG_BITS_ON(CHIPGCR_FCMODE, &regs->CHIPGCR);\r\nCHIPGCR = readb(&regs->CHIPGCR);\r\nif (mii_status & VELOCITY_SPEED_1000)\r\nCHIPGCR |= CHIPGCR_FCGMII;\r\nelse\r\nCHIPGCR &= ~CHIPGCR_FCGMII;\r\nif (mii_status & VELOCITY_DUPLEX_FULL) {\r\nCHIPGCR |= CHIPGCR_FCFDX;\r\nwriteb(CHIPGCR, &regs->CHIPGCR);\r\nVELOCITY_PRT(MSG_LEVEL_INFO, "set Velocity to forced full mode\n");\r\nif (vptr->rev_id < REV_ID_VT3216_A0)\r\nBYTE_REG_BITS_OFF(TCR_TB2BDIS, &regs->TCR);\r\n} else {\r\nCHIPGCR &= ~CHIPGCR_FCFDX;\r\nVELOCITY_PRT(MSG_LEVEL_INFO, "set Velocity to forced half mode\n");\r\nwriteb(CHIPGCR, &regs->CHIPGCR);\r\nif (vptr->rev_id < REV_ID_VT3216_A0)\r\nBYTE_REG_BITS_ON(TCR_TB2BDIS, &regs->TCR);\r\n}\r\nvelocity_mii_read(vptr->mac_regs, MII_CTRL1000, &CTRL1000);\r\nCTRL1000 &= ~(ADVERTISE_1000FULL | ADVERTISE_1000HALF);\r\nif ((mii_status & VELOCITY_SPEED_1000) &&\r\n(mii_status & VELOCITY_DUPLEX_FULL)) {\r\nCTRL1000 |= ADVERTISE_1000FULL;\r\n}\r\nvelocity_mii_write(vptr->mac_regs, MII_CTRL1000, CTRL1000);\r\nif (!(mii_status & VELOCITY_DUPLEX_FULL) && (mii_status & VELOCITY_SPEED_10))\r\nBYTE_REG_BITS_OFF(TESTCFG_HBDIS, &regs->TESTCFG);\r\nelse\r\nBYTE_REG_BITS_ON(TESTCFG_HBDIS, &regs->TESTCFG);\r\nvelocity_mii_read(vptr->mac_regs, MII_ADVERTISE, &ANAR);\r\nANAR &= (~(ADVERTISE_100FULL | ADVERTISE_100HALF | ADVERTISE_10FULL | ADVERTISE_10HALF));\r\nif (mii_status & VELOCITY_SPEED_100) {\r\nif (mii_status & VELOCITY_DUPLEX_FULL)\r\nANAR |= ADVERTISE_100FULL;\r\nelse\r\nANAR |= ADVERTISE_100HALF;\r\n} else if (mii_status & VELOCITY_SPEED_10) {\r\nif (mii_status & VELOCITY_DUPLEX_FULL)\r\nANAR |= ADVERTISE_10FULL;\r\nelse\r\nANAR |= ADVERTISE_10HALF;\r\n}\r\nvelocity_mii_write(vptr->mac_regs, MII_ADVERTISE, ANAR);\r\nmii_set_auto_on(vptr);\r\n}\r\nreturn VELOCITY_LINK_CHANGE;\r\n}\r\nstatic void velocity_print_link_status(struct velocity_info *vptr)\r\n{\r\nif (vptr->mii_status & VELOCITY_LINK_FAIL) {\r\nVELOCITY_PRT(MSG_LEVEL_INFO, KERN_NOTICE "%s: failed to detect cable link\n", vptr->netdev->name);\r\n} else if (vptr->options.spd_dpx == SPD_DPX_AUTO) {\r\nVELOCITY_PRT(MSG_LEVEL_INFO, KERN_NOTICE "%s: Link auto-negotiation", vptr->netdev->name);\r\nif (vptr->mii_status & VELOCITY_SPEED_1000)\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 1000M bps");\r\nelse if (vptr->mii_status & VELOCITY_SPEED_100)\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 100M bps");\r\nelse\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 10M bps");\r\nif (vptr->mii_status & VELOCITY_DUPLEX_FULL)\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " full duplex\n");\r\nelse\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " half duplex\n");\r\n} else {\r\nVELOCITY_PRT(MSG_LEVEL_INFO, KERN_NOTICE "%s: Link forced", vptr->netdev->name);\r\nswitch (vptr->options.spd_dpx) {\r\ncase SPD_DPX_1000_FULL:\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 1000M bps full duplex\n");\r\nbreak;\r\ncase SPD_DPX_100_HALF:\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 100M bps half duplex\n");\r\nbreak;\r\ncase SPD_DPX_100_FULL:\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 100M bps full duplex\n");\r\nbreak;\r\ncase SPD_DPX_10_HALF:\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 10M bps half duplex\n");\r\nbreak;\r\ncase SPD_DPX_10_FULL:\r\nVELOCITY_PRT(MSG_LEVEL_INFO, " speed 10M bps full duplex\n");\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\n}\r\nstatic void enable_flow_control_ability(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nswitch (vptr->options.flow_cntl) {\r\ncase FLOW_CNTL_DEFAULT:\r\nif (BYTE_REG_BITS_IS_ON(PHYSR0_RXFLC, &regs->PHYSR0))\r\nwritel(CR0_FDXRFCEN, &regs->CR0Set);\r\nelse\r\nwritel(CR0_FDXRFCEN, &regs->CR0Clr);\r\nif (BYTE_REG_BITS_IS_ON(PHYSR0_TXFLC, &regs->PHYSR0))\r\nwritel(CR0_FDXTFCEN, &regs->CR0Set);\r\nelse\r\nwritel(CR0_FDXTFCEN, &regs->CR0Clr);\r\nbreak;\r\ncase FLOW_CNTL_TX:\r\nwritel(CR0_FDXTFCEN, &regs->CR0Set);\r\nwritel(CR0_FDXRFCEN, &regs->CR0Clr);\r\nbreak;\r\ncase FLOW_CNTL_RX:\r\nwritel(CR0_FDXRFCEN, &regs->CR0Set);\r\nwritel(CR0_FDXTFCEN, &regs->CR0Clr);\r\nbreak;\r\ncase FLOW_CNTL_TX_RX:\r\nwritel(CR0_FDXTFCEN, &regs->CR0Set);\r\nwritel(CR0_FDXRFCEN, &regs->CR0Set);\r\nbreak;\r\ncase FLOW_CNTL_DISABLE:\r\nwritel(CR0_FDXRFCEN, &regs->CR0Clr);\r\nwritel(CR0_FDXTFCEN, &regs->CR0Clr);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic int velocity_soft_reset(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nint i = 0;\r\nwritel(CR0_SFRST, &regs->CR0Set);\r\nfor (i = 0; i < W_MAX_TIMEOUT; i++) {\r\nudelay(5);\r\nif (!DWORD_REG_BITS_IS_ON(CR0_SFRST, &regs->CR0Set))\r\nbreak;\r\n}\r\nif (i == W_MAX_TIMEOUT) {\r\nwritel(CR0_FORSRST, &regs->CR0Set);\r\nmdelay(2);\r\n}\r\nreturn 0;\r\n}\r\nstatic void velocity_set_multi(struct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nu8 rx_mode;\r\nint i;\r\nstruct netdev_hw_addr *ha;\r\nif (dev->flags & IFF_PROMISC) {\r\nwritel(0xffffffff, &regs->MARCAM[0]);\r\nwritel(0xffffffff, &regs->MARCAM[4]);\r\nrx_mode = (RCR_AM | RCR_AB | RCR_PROM);\r\n} else if ((netdev_mc_count(dev) > vptr->multicast_limit) ||\r\n(dev->flags & IFF_ALLMULTI)) {\r\nwritel(0xffffffff, &regs->MARCAM[0]);\r\nwritel(0xffffffff, &regs->MARCAM[4]);\r\nrx_mode = (RCR_AM | RCR_AB);\r\n} else {\r\nint offset = MCAM_SIZE - vptr->multicast_limit;\r\nmac_get_cam_mask(regs, vptr->mCAMmask);\r\ni = 0;\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nmac_set_cam(regs, i + offset, ha->addr);\r\nvptr->mCAMmask[(offset + i) / 8] |= 1 << ((offset + i) & 7);\r\ni++;\r\n}\r\nmac_set_cam_mask(regs, vptr->mCAMmask);\r\nrx_mode = RCR_AM | RCR_AB | RCR_AP;\r\n}\r\nif (dev->mtu > 1500)\r\nrx_mode |= RCR_AL;\r\nBYTE_REG_BITS_ON(rx_mode, &regs->RCR);\r\n}\r\nstatic void mii_init(struct velocity_info *vptr, u32 mii_status)\r\n{\r\nu16 BMCR;\r\nswitch (PHYID_GET_PHY_ID(vptr->phy_id)) {\r\ncase PHYID_ICPLUS_IP101A:\r\nMII_REG_BITS_ON((ADVERTISE_PAUSE_ASYM | ADVERTISE_PAUSE_CAP),\r\nMII_ADVERTISE, vptr->mac_regs);\r\nif (vptr->mii_status & VELOCITY_DUPLEX_FULL)\r\nMII_REG_BITS_ON(TCSR_ECHODIS, MII_SREVISION,\r\nvptr->mac_regs);\r\nelse\r\nMII_REG_BITS_OFF(TCSR_ECHODIS, MII_SREVISION,\r\nvptr->mac_regs);\r\nMII_REG_BITS_ON(PLED_LALBE, MII_TPISTATUS, vptr->mac_regs);\r\nbreak;\r\ncase PHYID_CICADA_CS8201:\r\nMII_REG_BITS_OFF((ADVERTISE_PAUSE_ASYM | ADVERTISE_PAUSE_CAP), MII_ADVERTISE, vptr->mac_regs);\r\nif (vptr->mii_status & VELOCITY_DUPLEX_FULL)\r\nMII_REG_BITS_ON(TCSR_ECHODIS, MII_SREVISION, vptr->mac_regs);\r\nelse\r\nMII_REG_BITS_OFF(TCSR_ECHODIS, MII_SREVISION, vptr->mac_regs);\r\nMII_REG_BITS_ON(PLED_LALBE, MII_TPISTATUS, vptr->mac_regs);\r\nbreak;\r\ncase PHYID_VT3216_32BIT:\r\ncase PHYID_VT3216_64BIT:\r\nMII_REG_BITS_ON((ADVERTISE_PAUSE_ASYM | ADVERTISE_PAUSE_CAP), MII_ADVERTISE, vptr->mac_regs);\r\nif (vptr->mii_status & VELOCITY_DUPLEX_FULL)\r\nMII_REG_BITS_ON(TCSR_ECHODIS, MII_SREVISION, vptr->mac_regs);\r\nelse\r\nMII_REG_BITS_OFF(TCSR_ECHODIS, MII_SREVISION, vptr->mac_regs);\r\nbreak;\r\ncase PHYID_MARVELL_1000:\r\ncase PHYID_MARVELL_1000S:\r\nMII_REG_BITS_ON(PSCR_ACRSTX, MII_REG_PSCR, vptr->mac_regs);\r\nMII_REG_BITS_ON((ADVERTISE_PAUSE_ASYM | ADVERTISE_PAUSE_CAP), MII_ADVERTISE, vptr->mac_regs);\r\nbreak;\r\ndefault:\r\n;\r\n}\r\nvelocity_mii_read(vptr->mac_regs, MII_BMCR, &BMCR);\r\nif (BMCR & BMCR_ISOLATE) {\r\nBMCR &= ~BMCR_ISOLATE;\r\nvelocity_mii_write(vptr->mac_regs, MII_BMCR, BMCR);\r\n}\r\n}\r\nstatic void setup_queue_timers(struct velocity_info *vptr)\r\n{\r\nif (vptr->rev_id >= REV_ID_VT3216_A0) {\r\nu8 txqueue_timer = 0;\r\nu8 rxqueue_timer = 0;\r\nif (vptr->mii_status & (VELOCITY_SPEED_1000 |\r\nVELOCITY_SPEED_100)) {\r\ntxqueue_timer = vptr->options.txqueue_timer;\r\nrxqueue_timer = vptr->options.rxqueue_timer;\r\n}\r\nwriteb(txqueue_timer, &vptr->mac_regs->TQETMR);\r\nwriteb(rxqueue_timer, &vptr->mac_regs->RQETMR);\r\n}\r\n}\r\nstatic void setup_adaptive_interrupts(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nu16 tx_intsup = vptr->options.tx_intsup;\r\nu16 rx_intsup = vptr->options.rx_intsup;\r\nvptr->int_mask = INT_MASK_DEF;\r\nwriteb(CAMCR_PS0, &regs->CAMCR);\r\nif (tx_intsup != 0) {\r\nvptr->int_mask &= ~(ISR_PTXI | ISR_PTX0I | ISR_PTX1I |\r\nISR_PTX2I | ISR_PTX3I);\r\nwritew(tx_intsup, &regs->ISRCTL);\r\n} else\r\nwritew(ISRCTL_TSUPDIS, &regs->ISRCTL);\r\nwriteb(CAMCR_PS1, &regs->CAMCR);\r\nif (rx_intsup != 0) {\r\nvptr->int_mask &= ~ISR_PRXI;\r\nwritew(rx_intsup, &regs->ISRCTL);\r\n} else\r\nwritew(ISRCTL_RSUPDIS, &regs->ISRCTL);\r\nwriteb(0, &regs->CAMCR);\r\n}\r\nstatic void velocity_init_registers(struct velocity_info *vptr,\r\nenum velocity_init_type type)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nstruct net_device *netdev = vptr->netdev;\r\nint i, mii_status;\r\nmac_wol_reset(regs);\r\nswitch (type) {\r\ncase VELOCITY_INIT_RESET:\r\ncase VELOCITY_INIT_WOL:\r\nnetif_stop_queue(netdev);\r\nvelocity_rx_reset(vptr);\r\nmac_rx_queue_run(regs);\r\nmac_rx_queue_wake(regs);\r\nmii_status = velocity_get_opt_media_mode(vptr);\r\nif (velocity_set_media_mode(vptr, mii_status) != VELOCITY_LINK_CHANGE) {\r\nvelocity_print_link_status(vptr);\r\nif (!(vptr->mii_status & VELOCITY_LINK_FAIL))\r\nnetif_wake_queue(netdev);\r\n}\r\nenable_flow_control_ability(vptr);\r\nmac_clear_isr(regs);\r\nwritel(CR0_STOP, &regs->CR0Clr);\r\nwritel((CR0_DPOLL | CR0_TXON | CR0_RXON | CR0_STRT),\r\n&regs->CR0Set);\r\nbreak;\r\ncase VELOCITY_INIT_COLD:\r\ndefault:\r\nvelocity_soft_reset(vptr);\r\nmdelay(5);\r\nif (!vptr->no_eeprom) {\r\nmac_eeprom_reload(regs);\r\nfor (i = 0; i < 6; i++)\r\nwriteb(netdev->dev_addr[i], regs->PAR + i);\r\n}\r\nBYTE_REG_BITS_OFF(CFGA_PACPI, &(regs->CFGA));\r\nmac_set_rx_thresh(regs, vptr->options.rx_thresh);\r\nmac_set_dma_length(regs, vptr->options.DMA_length);\r\nwriteb(WOLCFG_SAM | WOLCFG_SAB, &regs->WOLCFGSet);\r\nBYTE_REG_BITS_SET(CFGB_OFSET, (CFGB_CRANDOM | CFGB_CAP | CFGB_MBA | CFGB_BAKOPT), &regs->CFGB);\r\nvelocity_init_cam_filter(vptr);\r\nvelocity_set_multi(netdev);\r\nenable_mii_autopoll(regs);\r\nsetup_adaptive_interrupts(vptr);\r\nwritel(vptr->rx.pool_dma, &regs->RDBaseLo);\r\nwritew(vptr->options.numrx - 1, &regs->RDCSize);\r\nmac_rx_queue_run(regs);\r\nmac_rx_queue_wake(regs);\r\nwritew(vptr->options.numtx - 1, &regs->TDCSize);\r\nfor (i = 0; i < vptr->tx.numq; i++) {\r\nwritel(vptr->tx.pool_dma[i], &regs->TDBaseLo[i]);\r\nmac_tx_queue_run(regs, i);\r\n}\r\ninit_flow_control_register(vptr);\r\nwritel(CR0_STOP, &regs->CR0Clr);\r\nwritel((CR0_DPOLL | CR0_TXON | CR0_RXON | CR0_STRT), &regs->CR0Set);\r\nmii_status = velocity_get_opt_media_mode(vptr);\r\nnetif_stop_queue(netdev);\r\nmii_init(vptr, mii_status);\r\nif (velocity_set_media_mode(vptr, mii_status) != VELOCITY_LINK_CHANGE) {\r\nvelocity_print_link_status(vptr);\r\nif (!(vptr->mii_status & VELOCITY_LINK_FAIL))\r\nnetif_wake_queue(netdev);\r\n}\r\nenable_flow_control_ability(vptr);\r\nmac_hw_mibs_init(regs);\r\nmac_write_int_mask(vptr->int_mask, regs);\r\nmac_clear_isr(regs);\r\n}\r\n}\r\nstatic void velocity_give_many_rx_descs(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nint avail, dirty, unusable;\r\nif (vptr->rx.filled < 4)\r\nreturn;\r\nwmb();\r\nunusable = vptr->rx.filled & 0x0003;\r\ndirty = vptr->rx.dirty - unusable;\r\nfor (avail = vptr->rx.filled & 0xfffc; avail; avail--) {\r\ndirty = (dirty > 0) ? dirty - 1 : vptr->options.numrx - 1;\r\nvptr->rx.ring[dirty].rdesc0.len |= OWNED_BY_NIC;\r\n}\r\nwritew(vptr->rx.filled & 0xfffc, &regs->RBRDU);\r\nvptr->rx.filled = unusable;\r\n}\r\nstatic int velocity_init_dma_rings(struct velocity_info *vptr)\r\n{\r\nstruct velocity_opt *opt = &vptr->options;\r\nconst unsigned int rx_ring_size = opt->numrx * sizeof(struct rx_desc);\r\nconst unsigned int tx_ring_size = opt->numtx * sizeof(struct tx_desc);\r\ndma_addr_t pool_dma;\r\nvoid *pool;\r\nunsigned int i;\r\npool = dma_alloc_coherent(vptr->dev, tx_ring_size * vptr->tx.numq +\r\nrx_ring_size, &pool_dma, GFP_ATOMIC);\r\nif (!pool) {\r\ndev_err(vptr->dev, "%s : DMA memory allocation failed.\n",\r\nvptr->netdev->name);\r\nreturn -ENOMEM;\r\n}\r\nvptr->rx.ring = pool;\r\nvptr->rx.pool_dma = pool_dma;\r\npool += rx_ring_size;\r\npool_dma += rx_ring_size;\r\nfor (i = 0; i < vptr->tx.numq; i++) {\r\nvptr->tx.rings[i] = pool;\r\nvptr->tx.pool_dma[i] = pool_dma;\r\npool += tx_ring_size;\r\npool_dma += tx_ring_size;\r\n}\r\nreturn 0;\r\n}\r\nstatic void velocity_set_rxbufsize(struct velocity_info *vptr, int mtu)\r\n{\r\nvptr->rx.buf_sz = (mtu <= ETH_DATA_LEN) ? PKT_BUF_SZ : mtu + 32;\r\n}\r\nstatic int velocity_alloc_rx_buf(struct velocity_info *vptr, int idx)\r\n{\r\nstruct rx_desc *rd = &(vptr->rx.ring[idx]);\r\nstruct velocity_rd_info *rd_info = &(vptr->rx.info[idx]);\r\nrd_info->skb = netdev_alloc_skb(vptr->netdev, vptr->rx.buf_sz + 64);\r\nif (rd_info->skb == NULL)\r\nreturn -ENOMEM;\r\nskb_reserve(rd_info->skb,\r\n64 - ((unsigned long) rd_info->skb->data & 63));\r\nrd_info->skb_dma = dma_map_single(vptr->dev, rd_info->skb->data,\r\nvptr->rx.buf_sz, DMA_FROM_DEVICE);\r\n*((u32 *) & (rd->rdesc0)) = 0;\r\nrd->size = cpu_to_le16(vptr->rx.buf_sz) | RX_INTEN;\r\nrd->pa_low = cpu_to_le32(rd_info->skb_dma);\r\nrd->pa_high = 0;\r\nreturn 0;\r\n}\r\nstatic int velocity_rx_refill(struct velocity_info *vptr)\r\n{\r\nint dirty = vptr->rx.dirty, done = 0;\r\ndo {\r\nstruct rx_desc *rd = vptr->rx.ring + dirty;\r\nif (rd->rdesc0.len & OWNED_BY_NIC)\r\nbreak;\r\nif (!vptr->rx.info[dirty].skb) {\r\nif (velocity_alloc_rx_buf(vptr, dirty) < 0)\r\nbreak;\r\n}\r\ndone++;\r\ndirty = (dirty < vptr->options.numrx - 1) ? dirty + 1 : 0;\r\n} while (dirty != vptr->rx.curr);\r\nif (done) {\r\nvptr->rx.dirty = dirty;\r\nvptr->rx.filled += done;\r\n}\r\nreturn done;\r\n}\r\nstatic void velocity_free_rd_ring(struct velocity_info *vptr)\r\n{\r\nint i;\r\nif (vptr->rx.info == NULL)\r\nreturn;\r\nfor (i = 0; i < vptr->options.numrx; i++) {\r\nstruct velocity_rd_info *rd_info = &(vptr->rx.info[i]);\r\nstruct rx_desc *rd = vptr->rx.ring + i;\r\nmemset(rd, 0, sizeof(*rd));\r\nif (!rd_info->skb)\r\ncontinue;\r\ndma_unmap_single(vptr->dev, rd_info->skb_dma, vptr->rx.buf_sz,\r\nDMA_FROM_DEVICE);\r\nrd_info->skb_dma = 0;\r\ndev_kfree_skb(rd_info->skb);\r\nrd_info->skb = NULL;\r\n}\r\nkfree(vptr->rx.info);\r\nvptr->rx.info = NULL;\r\n}\r\nstatic int velocity_init_rd_ring(struct velocity_info *vptr)\r\n{\r\nint ret = -ENOMEM;\r\nvptr->rx.info = kcalloc(vptr->options.numrx,\r\nsizeof(struct velocity_rd_info), GFP_KERNEL);\r\nif (!vptr->rx.info)\r\ngoto out;\r\nvelocity_init_rx_ring_indexes(vptr);\r\nif (velocity_rx_refill(vptr) != vptr->options.numrx) {\r\nVELOCITY_PRT(MSG_LEVEL_ERR, KERN_ERR\r\n"%s: failed to allocate RX buffer.\n", vptr->netdev->name);\r\nvelocity_free_rd_ring(vptr);\r\ngoto out;\r\n}\r\nret = 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic int velocity_init_td_ring(struct velocity_info *vptr)\r\n{\r\nint j;\r\nfor (j = 0; j < vptr->tx.numq; j++) {\r\nvptr->tx.infos[j] = kcalloc(vptr->options.numtx,\r\nsizeof(struct velocity_td_info),\r\nGFP_KERNEL);\r\nif (!vptr->tx.infos[j]) {\r\nwhile (--j >= 0)\r\nkfree(vptr->tx.infos[j]);\r\nreturn -ENOMEM;\r\n}\r\nvptr->tx.tail[j] = vptr->tx.curr[j] = vptr->tx.used[j] = 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic void velocity_free_dma_rings(struct velocity_info *vptr)\r\n{\r\nconst int size = vptr->options.numrx * sizeof(struct rx_desc) +\r\nvptr->options.numtx * sizeof(struct tx_desc) * vptr->tx.numq;\r\ndma_free_coherent(vptr->dev, size, vptr->rx.ring, vptr->rx.pool_dma);\r\n}\r\nstatic int velocity_init_rings(struct velocity_info *vptr, int mtu)\r\n{\r\nint ret;\r\nvelocity_set_rxbufsize(vptr, mtu);\r\nret = velocity_init_dma_rings(vptr);\r\nif (ret < 0)\r\ngoto out;\r\nret = velocity_init_rd_ring(vptr);\r\nif (ret < 0)\r\ngoto err_free_dma_rings_0;\r\nret = velocity_init_td_ring(vptr);\r\nif (ret < 0)\r\ngoto err_free_rd_ring_1;\r\nout:\r\nreturn ret;\r\nerr_free_rd_ring_1:\r\nvelocity_free_rd_ring(vptr);\r\nerr_free_dma_rings_0:\r\nvelocity_free_dma_rings(vptr);\r\ngoto out;\r\n}\r\nstatic void velocity_free_tx_buf(struct velocity_info *vptr,\r\nstruct velocity_td_info *tdinfo, struct tx_desc *td)\r\n{\r\nstruct sk_buff *skb = tdinfo->skb;\r\nif (tdinfo->skb_dma) {\r\nint i;\r\nfor (i = 0; i < tdinfo->nskb_dma; i++) {\r\nsize_t pktlen = max_t(size_t, skb->len, ETH_ZLEN);\r\nif (skb_shinfo(skb)->nr_frags > 0)\r\npktlen = max_t(size_t, pktlen,\r\ntd->td_buf[i].size & ~TD_QUEUE);\r\ndma_unmap_single(vptr->dev, tdinfo->skb_dma[i],\r\nle16_to_cpu(pktlen), DMA_TO_DEVICE);\r\n}\r\n}\r\ndev_kfree_skb_irq(skb);\r\ntdinfo->skb = NULL;\r\n}\r\nstatic void velocity_free_td_ring_entry(struct velocity_info *vptr,\r\nint q, int n)\r\n{\r\nstruct velocity_td_info *td_info = &(vptr->tx.infos[q][n]);\r\nint i;\r\nif (td_info == NULL)\r\nreturn;\r\nif (td_info->skb) {\r\nfor (i = 0; i < td_info->nskb_dma; i++) {\r\nif (td_info->skb_dma[i]) {\r\ndma_unmap_single(vptr->dev, td_info->skb_dma[i],\r\ntd_info->skb->len, DMA_TO_DEVICE);\r\ntd_info->skb_dma[i] = 0;\r\n}\r\n}\r\ndev_kfree_skb(td_info->skb);\r\ntd_info->skb = NULL;\r\n}\r\n}\r\nstatic void velocity_free_td_ring(struct velocity_info *vptr)\r\n{\r\nint i, j;\r\nfor (j = 0; j < vptr->tx.numq; j++) {\r\nif (vptr->tx.infos[j] == NULL)\r\ncontinue;\r\nfor (i = 0; i < vptr->options.numtx; i++)\r\nvelocity_free_td_ring_entry(vptr, j, i);\r\nkfree(vptr->tx.infos[j]);\r\nvptr->tx.infos[j] = NULL;\r\n}\r\n}\r\nstatic void velocity_free_rings(struct velocity_info *vptr)\r\n{\r\nvelocity_free_td_ring(vptr);\r\nvelocity_free_rd_ring(vptr);\r\nvelocity_free_dma_rings(vptr);\r\n}\r\nstatic void velocity_error(struct velocity_info *vptr, int status)\r\n{\r\nif (status & ISR_TXSTLI) {\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nprintk(KERN_ERR "TD structure error TDindex=%hx\n", readw(&regs->TDIdx[0]));\r\nBYTE_REG_BITS_ON(TXESR_TDSTR, &regs->TXESR);\r\nwritew(TRDCSR_RUN, &regs->TDCSRClr);\r\nnetif_stop_queue(vptr->netdev);\r\n}\r\nif (status & ISR_SRCI) {\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nint linked;\r\nif (vptr->options.spd_dpx == SPD_DPX_AUTO) {\r\nvptr->mii_status = check_connection_type(regs);\r\nif (vptr->rev_id < REV_ID_VT3216_A0) {\r\nif (vptr->mii_status & VELOCITY_DUPLEX_FULL)\r\nBYTE_REG_BITS_ON(TCR_TB2BDIS, &regs->TCR);\r\nelse\r\nBYTE_REG_BITS_OFF(TCR_TB2BDIS, &regs->TCR);\r\n}\r\nif (!(vptr->mii_status & VELOCITY_DUPLEX_FULL) && (vptr->mii_status & VELOCITY_SPEED_10))\r\nBYTE_REG_BITS_OFF(TESTCFG_HBDIS, &regs->TESTCFG);\r\nelse\r\nBYTE_REG_BITS_ON(TESTCFG_HBDIS, &regs->TESTCFG);\r\nsetup_queue_timers(vptr);\r\n}\r\nlinked = readb(&regs->PHYSR0) & PHYSR0_LINKGD;\r\nif (linked) {\r\nvptr->mii_status &= ~VELOCITY_LINK_FAIL;\r\nnetif_carrier_on(vptr->netdev);\r\n} else {\r\nvptr->mii_status |= VELOCITY_LINK_FAIL;\r\nnetif_carrier_off(vptr->netdev);\r\n}\r\nvelocity_print_link_status(vptr);\r\nenable_flow_control_ability(vptr);\r\nenable_mii_autopoll(regs);\r\nif (vptr->mii_status & VELOCITY_LINK_FAIL)\r\nnetif_stop_queue(vptr->netdev);\r\nelse\r\nnetif_wake_queue(vptr->netdev);\r\n}\r\nif (status & ISR_MIBFI)\r\nvelocity_update_hw_mibs(vptr);\r\nif (status & ISR_LSTEI)\r\nmac_rx_queue_wake(vptr->mac_regs);\r\n}\r\nstatic int velocity_tx_srv(struct velocity_info *vptr)\r\n{\r\nstruct tx_desc *td;\r\nint qnum;\r\nint full = 0;\r\nint idx;\r\nint works = 0;\r\nstruct velocity_td_info *tdinfo;\r\nstruct net_device_stats *stats = &vptr->netdev->stats;\r\nfor (qnum = 0; qnum < vptr->tx.numq; qnum++) {\r\nfor (idx = vptr->tx.tail[qnum]; vptr->tx.used[qnum] > 0;\r\nidx = (idx + 1) % vptr->options.numtx) {\r\ntd = &(vptr->tx.rings[qnum][idx]);\r\ntdinfo = &(vptr->tx.infos[qnum][idx]);\r\nif (td->tdesc0.len & OWNED_BY_NIC)\r\nbreak;\r\nif ((works++ > 15))\r\nbreak;\r\nif (td->tdesc0.TSR & TSR0_TERR) {\r\nstats->tx_errors++;\r\nstats->tx_dropped++;\r\nif (td->tdesc0.TSR & TSR0_CDH)\r\nstats->tx_heartbeat_errors++;\r\nif (td->tdesc0.TSR & TSR0_CRS)\r\nstats->tx_carrier_errors++;\r\nif (td->tdesc0.TSR & TSR0_ABT)\r\nstats->tx_aborted_errors++;\r\nif (td->tdesc0.TSR & TSR0_OWC)\r\nstats->tx_window_errors++;\r\n} else {\r\nstats->tx_packets++;\r\nstats->tx_bytes += tdinfo->skb->len;\r\n}\r\nvelocity_free_tx_buf(vptr, tdinfo, td);\r\nvptr->tx.used[qnum]--;\r\n}\r\nvptr->tx.tail[qnum] = idx;\r\nif (AVAIL_TD(vptr, qnum) < 1)\r\nfull = 1;\r\n}\r\nif (netif_queue_stopped(vptr->netdev) && (full == 0) &&\r\n(!(vptr->mii_status & VELOCITY_LINK_FAIL))) {\r\nnetif_wake_queue(vptr->netdev);\r\n}\r\nreturn works;\r\n}\r\nstatic inline void velocity_rx_csum(struct rx_desc *rd, struct sk_buff *skb)\r\n{\r\nskb_checksum_none_assert(skb);\r\nif (rd->rdesc1.CSM & CSM_IPKT) {\r\nif (rd->rdesc1.CSM & CSM_IPOK) {\r\nif ((rd->rdesc1.CSM & CSM_TCPKT) ||\r\n(rd->rdesc1.CSM & CSM_UDPKT)) {\r\nif (!(rd->rdesc1.CSM & CSM_TUPOK))\r\nreturn;\r\n}\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\n}\r\n}\r\n}\r\nstatic int velocity_rx_copy(struct sk_buff **rx_skb, int pkt_size,\r\nstruct velocity_info *vptr)\r\n{\r\nint ret = -1;\r\nif (pkt_size < rx_copybreak) {\r\nstruct sk_buff *new_skb;\r\nnew_skb = netdev_alloc_skb_ip_align(vptr->netdev, pkt_size);\r\nif (new_skb) {\r\nnew_skb->ip_summed = rx_skb[0]->ip_summed;\r\nskb_copy_from_linear_data(*rx_skb, new_skb->data, pkt_size);\r\n*rx_skb = new_skb;\r\nret = 0;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic inline void velocity_iph_realign(struct velocity_info *vptr,\r\nstruct sk_buff *skb, int pkt_size)\r\n{\r\nif (vptr->flags & VELOCITY_FLAGS_IP_ALIGN) {\r\nmemmove(skb->data + 2, skb->data, pkt_size);\r\nskb_reserve(skb, 2);\r\n}\r\n}\r\nstatic int velocity_receive_frame(struct velocity_info *vptr, int idx)\r\n{\r\nstruct net_device_stats *stats = &vptr->netdev->stats;\r\nstruct velocity_rd_info *rd_info = &(vptr->rx.info[idx]);\r\nstruct rx_desc *rd = &(vptr->rx.ring[idx]);\r\nint pkt_len = le16_to_cpu(rd->rdesc0.len) & 0x3fff;\r\nstruct sk_buff *skb;\r\nif (rd->rdesc0.RSR & (RSR_STP | RSR_EDP)) {\r\nVELOCITY_PRT(MSG_LEVEL_VERBOSE, KERN_ERR " %s : the received frame spans multiple RDs.\n", vptr->netdev->name);\r\nstats->rx_length_errors++;\r\nreturn -EINVAL;\r\n}\r\nif (rd->rdesc0.RSR & RSR_MAR)\r\nstats->multicast++;\r\nskb = rd_info->skb;\r\ndma_sync_single_for_cpu(vptr->dev, rd_info->skb_dma,\r\nvptr->rx.buf_sz, DMA_FROM_DEVICE);\r\nif (vptr->flags & VELOCITY_FLAGS_VAL_PKT_LEN) {\r\nif (rd->rdesc0.RSR & RSR_RL) {\r\nstats->rx_length_errors++;\r\nreturn -EINVAL;\r\n}\r\n}\r\nvelocity_rx_csum(rd, skb);\r\nif (velocity_rx_copy(&skb, pkt_len, vptr) < 0) {\r\nvelocity_iph_realign(vptr, skb, pkt_len);\r\nrd_info->skb = NULL;\r\ndma_unmap_single(vptr->dev, rd_info->skb_dma, vptr->rx.buf_sz,\r\nDMA_FROM_DEVICE);\r\n} else {\r\ndma_sync_single_for_device(vptr->dev, rd_info->skb_dma,\r\nvptr->rx.buf_sz, DMA_FROM_DEVICE);\r\n}\r\nskb_put(skb, pkt_len - 4);\r\nskb->protocol = eth_type_trans(skb, vptr->netdev);\r\nif (rd->rdesc0.RSR & RSR_DETAG) {\r\nu16 vid = swab16(le16_to_cpu(rd->rdesc1.PQTAG));\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\r\n}\r\nnetif_receive_skb(skb);\r\nstats->rx_bytes += pkt_len;\r\nstats->rx_packets++;\r\nreturn 0;\r\n}\r\nstatic int velocity_rx_srv(struct velocity_info *vptr, int budget_left)\r\n{\r\nstruct net_device_stats *stats = &vptr->netdev->stats;\r\nint rd_curr = vptr->rx.curr;\r\nint works = 0;\r\nwhile (works < budget_left) {\r\nstruct rx_desc *rd = vptr->rx.ring + rd_curr;\r\nif (!vptr->rx.info[rd_curr].skb)\r\nbreak;\r\nif (rd->rdesc0.len & OWNED_BY_NIC)\r\nbreak;\r\nrmb();\r\nif (rd->rdesc0.RSR & (RSR_RXOK | RSR_CE | RSR_RL)) {\r\nif (velocity_receive_frame(vptr, rd_curr) < 0)\r\nstats->rx_dropped++;\r\n} else {\r\nif (rd->rdesc0.RSR & RSR_CRC)\r\nstats->rx_crc_errors++;\r\nif (rd->rdesc0.RSR & RSR_FAE)\r\nstats->rx_frame_errors++;\r\nstats->rx_dropped++;\r\n}\r\nrd->size |= RX_INTEN;\r\nrd_curr++;\r\nif (rd_curr >= vptr->options.numrx)\r\nrd_curr = 0;\r\nworks++;\r\n}\r\nvptr->rx.curr = rd_curr;\r\nif ((works > 0) && (velocity_rx_refill(vptr) > 0))\r\nvelocity_give_many_rx_descs(vptr);\r\nVAR_USED(stats);\r\nreturn works;\r\n}\r\nstatic int velocity_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct velocity_info *vptr = container_of(napi,\r\nstruct velocity_info, napi);\r\nunsigned int rx_done;\r\nunsigned long flags;\r\nrx_done = velocity_rx_srv(vptr, budget);\r\nspin_lock_irqsave(&vptr->lock, flags);\r\nvelocity_tx_srv(vptr);\r\nif (rx_done < budget) {\r\nnapi_complete(napi);\r\nmac_enable_int(vptr->mac_regs);\r\n}\r\nspin_unlock_irqrestore(&vptr->lock, flags);\r\nreturn rx_done;\r\n}\r\nstatic irqreturn_t velocity_intr(int irq, void *dev_instance)\r\n{\r\nstruct net_device *dev = dev_instance;\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nu32 isr_status;\r\nspin_lock(&vptr->lock);\r\nisr_status = mac_read_isr(vptr->mac_regs);\r\nif (isr_status == 0) {\r\nspin_unlock(&vptr->lock);\r\nreturn IRQ_NONE;\r\n}\r\nmac_write_isr(vptr->mac_regs, isr_status);\r\nif (likely(napi_schedule_prep(&vptr->napi))) {\r\nmac_disable_int(vptr->mac_regs);\r\n__napi_schedule(&vptr->napi);\r\n}\r\nif (isr_status & (~(ISR_PRXI | ISR_PPRXI | ISR_PTXI | ISR_PPTXI)))\r\nvelocity_error(vptr, isr_status);\r\nspin_unlock(&vptr->lock);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int velocity_open(struct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nint ret;\r\nret = velocity_init_rings(vptr, dev->mtu);\r\nif (ret < 0)\r\ngoto out;\r\nvelocity_set_power_state(vptr, PCI_D0);\r\nvelocity_init_registers(vptr, VELOCITY_INIT_COLD);\r\nret = request_irq(dev->irq, velocity_intr, IRQF_SHARED,\r\ndev->name, dev);\r\nif (ret < 0) {\r\nvelocity_set_power_state(vptr, PCI_D3hot);\r\nvelocity_free_rings(vptr);\r\ngoto out;\r\n}\r\nvelocity_give_many_rx_descs(vptr);\r\nmac_enable_int(vptr->mac_regs);\r\nnetif_start_queue(dev);\r\nnapi_enable(&vptr->napi);\r\nvptr->flags |= VELOCITY_FLAGS_OPENED;\r\nout:\r\nreturn ret;\r\n}\r\nstatic void velocity_shutdown(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nmac_disable_int(regs);\r\nwritel(CR0_STOP, &regs->CR0Set);\r\nwritew(0xFFFF, &regs->TDCSRClr);\r\nwriteb(0xFF, &regs->RDCSRClr);\r\nsafe_disable_mii_autopoll(regs);\r\nmac_clear_isr(regs);\r\n}\r\nstatic int velocity_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nint ret = 0;\r\nif ((new_mtu < VELOCITY_MIN_MTU) || new_mtu > (VELOCITY_MAX_MTU)) {\r\nVELOCITY_PRT(MSG_LEVEL_ERR, KERN_NOTICE "%s: Invalid MTU.\n",\r\nvptr->netdev->name);\r\nret = -EINVAL;\r\ngoto out_0;\r\n}\r\nif (!netif_running(dev)) {\r\ndev->mtu = new_mtu;\r\ngoto out_0;\r\n}\r\nif (dev->mtu != new_mtu) {\r\nstruct velocity_info *tmp_vptr;\r\nunsigned long flags;\r\nstruct rx_info rx;\r\nstruct tx_info tx;\r\ntmp_vptr = kzalloc(sizeof(*tmp_vptr), GFP_KERNEL);\r\nif (!tmp_vptr) {\r\nret = -ENOMEM;\r\ngoto out_0;\r\n}\r\ntmp_vptr->netdev = dev;\r\ntmp_vptr->pdev = vptr->pdev;\r\ntmp_vptr->dev = vptr->dev;\r\ntmp_vptr->options = vptr->options;\r\ntmp_vptr->tx.numq = vptr->tx.numq;\r\nret = velocity_init_rings(tmp_vptr, new_mtu);\r\nif (ret < 0)\r\ngoto out_free_tmp_vptr_1;\r\nnapi_disable(&vptr->napi);\r\nspin_lock_irqsave(&vptr->lock, flags);\r\nnetif_stop_queue(dev);\r\nvelocity_shutdown(vptr);\r\nrx = vptr->rx;\r\ntx = vptr->tx;\r\nvptr->rx = tmp_vptr->rx;\r\nvptr->tx = tmp_vptr->tx;\r\ntmp_vptr->rx = rx;\r\ntmp_vptr->tx = tx;\r\ndev->mtu = new_mtu;\r\nvelocity_init_registers(vptr, VELOCITY_INIT_COLD);\r\nvelocity_give_many_rx_descs(vptr);\r\nnapi_enable(&vptr->napi);\r\nmac_enable_int(vptr->mac_regs);\r\nnetif_start_queue(dev);\r\nspin_unlock_irqrestore(&vptr->lock, flags);\r\nvelocity_free_rings(tmp_vptr);\r\nout_free_tmp_vptr_1:\r\nkfree(tmp_vptr);\r\n}\r\nout_0:\r\nreturn ret;\r\n}\r\nstatic void velocity_poll_controller(struct net_device *dev)\r\n{\r\ndisable_irq(dev->irq);\r\nvelocity_intr(dev->irq, dev);\r\nenable_irq(dev->irq);\r\n}\r\nstatic int velocity_mii_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nunsigned long flags;\r\nstruct mii_ioctl_data *miidata = if_mii(ifr);\r\nint err;\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\nmiidata->phy_id = readb(&regs->MIIADR) & 0x1f;\r\nbreak;\r\ncase SIOCGMIIREG:\r\nif (velocity_mii_read(vptr->mac_regs, miidata->reg_num & 0x1f, &(miidata->val_out)) < 0)\r\nreturn -ETIMEDOUT;\r\nbreak;\r\ncase SIOCSMIIREG:\r\nspin_lock_irqsave(&vptr->lock, flags);\r\nerr = velocity_mii_write(vptr->mac_regs, miidata->reg_num & 0x1f, miidata->val_in);\r\nspin_unlock_irqrestore(&vptr->lock, flags);\r\ncheck_connection_type(vptr->mac_regs);\r\nif (err)\r\nreturn err;\r\nbreak;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\nreturn 0;\r\n}\r\nstatic int velocity_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nint ret;\r\nif (!netif_running(dev))\r\nvelocity_set_power_state(vptr, PCI_D0);\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\ncase SIOCGMIIREG:\r\ncase SIOCSMIIREG:\r\nret = velocity_mii_ioctl(dev, rq, cmd);\r\nbreak;\r\ndefault:\r\nret = -EOPNOTSUPP;\r\n}\r\nif (!netif_running(dev))\r\nvelocity_set_power_state(vptr, PCI_D3hot);\r\nreturn ret;\r\n}\r\nstatic struct net_device_stats *velocity_get_stats(struct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nif (!netif_running(dev))\r\nreturn &dev->stats;\r\nspin_lock_irq(&vptr->lock);\r\nvelocity_update_hw_mibs(vptr);\r\nspin_unlock_irq(&vptr->lock);\r\ndev->stats.rx_packets = vptr->mib_counter[HW_MIB_ifRxAllPkts];\r\ndev->stats.rx_errors = vptr->mib_counter[HW_MIB_ifRxErrorPkts];\r\ndev->stats.rx_length_errors = vptr->mib_counter[HW_MIB_ifInRangeLengthErrors];\r\ndev->stats.collisions = vptr->mib_counter[HW_MIB_ifTxEtherCollisions];\r\ndev->stats.rx_crc_errors = vptr->mib_counter[HW_MIB_ifRxPktCRCE];\r\nreturn &dev->stats;\r\n}\r\nstatic int velocity_close(struct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nnapi_disable(&vptr->napi);\r\nnetif_stop_queue(dev);\r\nvelocity_shutdown(vptr);\r\nif (vptr->flags & VELOCITY_FLAGS_WOL_ENABLED)\r\nvelocity_get_ip(vptr);\r\nfree_irq(dev->irq, dev);\r\nvelocity_free_rings(vptr);\r\nvptr->flags &= (~VELOCITY_FLAGS_OPENED);\r\nreturn 0;\r\n}\r\nstatic netdev_tx_t velocity_xmit(struct sk_buff *skb,\r\nstruct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nint qnum = 0;\r\nstruct tx_desc *td_ptr;\r\nstruct velocity_td_info *tdinfo;\r\nunsigned long flags;\r\nint pktlen;\r\nint index, prev;\r\nint i = 0;\r\nif (skb_padto(skb, ETH_ZLEN))\r\ngoto out;\r\nif (skb_shinfo(skb)->nr_frags > 6 && __skb_linearize(skb)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\npktlen = skb_shinfo(skb)->nr_frags == 0 ?\r\nmax_t(unsigned int, skb->len, ETH_ZLEN) :\r\nskb_headlen(skb);\r\nspin_lock_irqsave(&vptr->lock, flags);\r\nindex = vptr->tx.curr[qnum];\r\ntd_ptr = &(vptr->tx.rings[qnum][index]);\r\ntdinfo = &(vptr->tx.infos[qnum][index]);\r\ntd_ptr->tdesc1.TCR = TCR0_TIC;\r\ntd_ptr->td_buf[0].size &= ~TD_QUEUE;\r\ntdinfo->skb = skb;\r\ntdinfo->skb_dma[0] = dma_map_single(vptr->dev, skb->data, pktlen,\r\nDMA_TO_DEVICE);\r\ntd_ptr->tdesc0.len = cpu_to_le16(pktlen);\r\ntd_ptr->td_buf[0].pa_low = cpu_to_le32(tdinfo->skb_dma[0]);\r\ntd_ptr->td_buf[0].pa_high = 0;\r\ntd_ptr->td_buf[0].size = cpu_to_le16(pktlen);\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\nconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\r\ntdinfo->skb_dma[i + 1] = skb_frag_dma_map(vptr->dev,\r\nfrag, 0,\r\nskb_frag_size(frag),\r\nDMA_TO_DEVICE);\r\ntd_ptr->td_buf[i + 1].pa_low = cpu_to_le32(tdinfo->skb_dma[i + 1]);\r\ntd_ptr->td_buf[i + 1].pa_high = 0;\r\ntd_ptr->td_buf[i + 1].size = cpu_to_le16(skb_frag_size(frag));\r\n}\r\ntdinfo->nskb_dma = i + 1;\r\ntd_ptr->tdesc1.cmd = TCPLS_NORMAL + (tdinfo->nskb_dma + 1) * 16;\r\nif (skb_vlan_tag_present(skb)) {\r\ntd_ptr->tdesc1.vlan = cpu_to_le16(skb_vlan_tag_get(skb));\r\ntd_ptr->tdesc1.TCR |= TCR0_VETAG;\r\n}\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nconst struct iphdr *ip = ip_hdr(skb);\r\nif (ip->protocol == IPPROTO_TCP)\r\ntd_ptr->tdesc1.TCR |= TCR0_TCPCK;\r\nelse if (ip->protocol == IPPROTO_UDP)\r\ntd_ptr->tdesc1.TCR |= (TCR0_UDPCK);\r\ntd_ptr->tdesc1.TCR |= TCR0_IPCK;\r\n}\r\nprev = index - 1;\r\nif (prev < 0)\r\nprev = vptr->options.numtx - 1;\r\ntd_ptr->tdesc0.len |= OWNED_BY_NIC;\r\nvptr->tx.used[qnum]++;\r\nvptr->tx.curr[qnum] = (index + 1) % vptr->options.numtx;\r\nif (AVAIL_TD(vptr, qnum) < 1)\r\nnetif_stop_queue(dev);\r\ntd_ptr = &(vptr->tx.rings[qnum][prev]);\r\ntd_ptr->td_buf[0].size |= TD_QUEUE;\r\nmac_tx_queue_wake(vptr->mac_regs, qnum);\r\nspin_unlock_irqrestore(&vptr->lock, flags);\r\nout:\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void velocity_init_info(struct velocity_info *vptr,\r\nconst struct velocity_info_tbl *info)\r\n{\r\nvptr->chip_id = info->chip_id;\r\nvptr->tx.numq = info->txqueue;\r\nvptr->multicast_limit = MCAM_SIZE;\r\nspin_lock_init(&vptr->lock);\r\n}\r\nstatic int velocity_get_pci_info(struct velocity_info *vptr)\r\n{\r\nstruct pci_dev *pdev = vptr->pdev;\r\npci_set_master(pdev);\r\nvptr->ioaddr = pci_resource_start(pdev, 0);\r\nvptr->memaddr = pci_resource_start(pdev, 1);\r\nif (!(pci_resource_flags(pdev, 0) & IORESOURCE_IO)) {\r\ndev_err(&pdev->dev,\r\n"region #0 is not an I/O resource, aborting.\n");\r\nreturn -EINVAL;\r\n}\r\nif ((pci_resource_flags(pdev, 1) & IORESOURCE_IO)) {\r\ndev_err(&pdev->dev,\r\n"region #1 is an I/O resource, aborting.\n");\r\nreturn -EINVAL;\r\n}\r\nif (pci_resource_len(pdev, 1) < VELOCITY_IO_SIZE) {\r\ndev_err(&pdev->dev, "region #1 is too small.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int velocity_get_platform_info(struct velocity_info *vptr)\r\n{\r\nstruct resource res;\r\nint ret;\r\nif (of_get_property(vptr->dev->of_node, "no-eeprom", NULL))\r\nvptr->no_eeprom = 1;\r\nret = of_address_to_resource(vptr->dev->of_node, 0, &res);\r\nif (ret) {\r\ndev_err(vptr->dev, "unable to find memory address\n");\r\nreturn ret;\r\n}\r\nvptr->memaddr = res.start;\r\nif (resource_size(&res) < VELOCITY_IO_SIZE) {\r\ndev_err(vptr->dev, "memory region is too small.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void velocity_print_info(struct velocity_info *vptr)\r\n{\r\nstruct net_device *dev = vptr->netdev;\r\nprintk(KERN_INFO "%s: %s\n", dev->name, get_chip_name(vptr->chip_id));\r\nprintk(KERN_INFO "%s: Ethernet Address: %pM\n",\r\ndev->name, dev->dev_addr);\r\n}\r\nstatic u32 velocity_get_link(struct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nreturn BYTE_REG_BITS_IS_ON(PHYSR0_LINKGD, &regs->PHYSR0) ? 1 : 0;\r\n}\r\nstatic int velocity_probe(struct device *dev, int irq,\r\nconst struct velocity_info_tbl *info,\r\nenum velocity_bus_type bustype)\r\n{\r\nstatic int first = 1;\r\nstruct net_device *netdev;\r\nint i;\r\nconst char *drv_string;\r\nstruct velocity_info *vptr;\r\nstruct mac_regs __iomem *regs;\r\nint ret = -ENOMEM;\r\nif (velocity_nics >= MAX_UNITS) {\r\ndev_notice(dev, "already found %d NICs.\n", velocity_nics);\r\nreturn -ENODEV;\r\n}\r\nnetdev = alloc_etherdev(sizeof(struct velocity_info));\r\nif (!netdev)\r\ngoto out;\r\nSET_NETDEV_DEV(netdev, dev);\r\nvptr = netdev_priv(netdev);\r\nif (first) {\r\nprintk(KERN_INFO "%s Ver. %s\n",\r\nVELOCITY_FULL_DRV_NAM, VELOCITY_VERSION);\r\nprintk(KERN_INFO "Copyright (c) 2002, 2003 VIA Networking Technologies, Inc.\n");\r\nprintk(KERN_INFO "Copyright (c) 2004 Red Hat Inc.\n");\r\nfirst = 0;\r\n}\r\nnetdev->irq = irq;\r\nvptr->netdev = netdev;\r\nvptr->dev = dev;\r\nvelocity_init_info(vptr, info);\r\nif (bustype == BUS_PCI) {\r\nvptr->pdev = to_pci_dev(dev);\r\nret = velocity_get_pci_info(vptr);\r\nif (ret < 0)\r\ngoto err_free_dev;\r\n} else {\r\nvptr->pdev = NULL;\r\nret = velocity_get_platform_info(vptr);\r\nif (ret < 0)\r\ngoto err_free_dev;\r\n}\r\nregs = ioremap(vptr->memaddr, VELOCITY_IO_SIZE);\r\nif (regs == NULL) {\r\nret = -EIO;\r\ngoto err_free_dev;\r\n}\r\nvptr->mac_regs = regs;\r\nvptr->rev_id = readb(&regs->rev_id);\r\nmac_wol_reset(regs);\r\nfor (i = 0; i < 6; i++)\r\nnetdev->dev_addr[i] = readb(&regs->PAR[i]);\r\ndrv_string = dev_driver_string(dev);\r\nvelocity_get_options(&vptr->options, velocity_nics, drv_string);\r\nvptr->options.flags &= info->flags;\r\nvptr->flags = vptr->options.flags | (info->flags & 0xFF000000UL);\r\nvptr->wol_opts = vptr->options.wol_opts;\r\nvptr->flags |= VELOCITY_FLAGS_WOL_ENABLED;\r\nvptr->phy_id = MII_GET_PHY_ID(vptr->mac_regs);\r\nnetdev->netdev_ops = &velocity_netdev_ops;\r\nnetdev->ethtool_ops = &velocity_ethtool_ops;\r\nnetif_napi_add(netdev, &vptr->napi, velocity_poll,\r\nVELOCITY_NAPI_WEIGHT);\r\nnetdev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG |\r\nNETIF_F_HW_VLAN_CTAG_TX;\r\nnetdev->features |= NETIF_F_HW_VLAN_CTAG_TX |\r\nNETIF_F_HW_VLAN_CTAG_FILTER | NETIF_F_HW_VLAN_CTAG_RX |\r\nNETIF_F_IP_CSUM;\r\nret = register_netdev(netdev);\r\nif (ret < 0)\r\ngoto err_iounmap;\r\nif (!velocity_get_link(netdev)) {\r\nnetif_carrier_off(netdev);\r\nvptr->mii_status |= VELOCITY_LINK_FAIL;\r\n}\r\nvelocity_print_info(vptr);\r\ndev_set_drvdata(vptr->dev, netdev);\r\nvelocity_set_power_state(vptr, PCI_D3hot);\r\nvelocity_nics++;\r\nout:\r\nreturn ret;\r\nerr_iounmap:\r\nnetif_napi_del(&vptr->napi);\r\niounmap(regs);\r\nerr_free_dev:\r\nfree_netdev(netdev);\r\ngoto out;\r\n}\r\nstatic int velocity_remove(struct device *dev)\r\n{\r\nstruct net_device *netdev = dev_get_drvdata(dev);\r\nstruct velocity_info *vptr = netdev_priv(netdev);\r\nunregister_netdev(netdev);\r\nnetif_napi_del(&vptr->napi);\r\niounmap(vptr->mac_regs);\r\nfree_netdev(netdev);\r\nvelocity_nics--;\r\nreturn 0;\r\n}\r\nstatic int velocity_pci_probe(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nconst struct velocity_info_tbl *info =\r\n&chip_info_table[ent->driver_data];\r\nint ret;\r\nret = pci_enable_device(pdev);\r\nif (ret < 0)\r\nreturn ret;\r\nret = pci_request_regions(pdev, VELOCITY_NAME);\r\nif (ret < 0) {\r\ndev_err(&pdev->dev, "No PCI resources.\n");\r\ngoto fail1;\r\n}\r\nret = velocity_probe(&pdev->dev, pdev->irq, info, BUS_PCI);\r\nif (ret == 0)\r\nreturn 0;\r\npci_release_regions(pdev);\r\nfail1:\r\npci_disable_device(pdev);\r\nreturn ret;\r\n}\r\nstatic void velocity_pci_remove(struct pci_dev *pdev)\r\n{\r\nvelocity_remove(&pdev->dev);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int velocity_platform_probe(struct platform_device *pdev)\r\n{\r\nconst struct of_device_id *of_id;\r\nconst struct velocity_info_tbl *info;\r\nint irq;\r\nof_id = of_match_device(velocity_of_ids, &pdev->dev);\r\nif (!of_id)\r\nreturn -EINVAL;\r\ninfo = of_id->data;\r\nirq = irq_of_parse_and_map(pdev->dev.of_node, 0);\r\nif (!irq)\r\nreturn -EINVAL;\r\nreturn velocity_probe(&pdev->dev, irq, info, BUS_PLATFORM);\r\n}\r\nstatic int velocity_platform_remove(struct platform_device *pdev)\r\n{\r\nvelocity_remove(&pdev->dev);\r\nreturn 0;\r\n}\r\nstatic u16 wol_calc_crc(int size, u8 *pattern, u8 *mask_pattern)\r\n{\r\nu16 crc = 0xFFFF;\r\nu8 mask;\r\nint i, j;\r\nfor (i = 0; i < size; i++) {\r\nmask = mask_pattern[i];\r\nif (mask == 0x00)\r\ncontinue;\r\nfor (j = 0; j < 8; j++) {\r\nif ((mask & 0x01) == 0) {\r\nmask >>= 1;\r\ncontinue;\r\n}\r\nmask >>= 1;\r\ncrc = crc_ccitt(crc, &(pattern[i * 8 + j]), 1);\r\n}\r\n}\r\ncrc = ~crc;\r\nreturn bitrev32(crc) >> 16;\r\n}\r\nstatic int velocity_set_wol(struct velocity_info *vptr)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nenum speed_opt spd_dpx = vptr->options.spd_dpx;\r\nstatic u8 buf[256];\r\nint i;\r\nstatic u32 mask_pattern[2][4] = {\r\n{0x00203000, 0x000003C0, 0x00000000, 0x0000000},\r\n{0xfffff000, 0xffffffff, 0xffffffff, 0x000ffff}\r\n};\r\nwritew(0xFFFF, &regs->WOLCRClr);\r\nwriteb(WOLCFG_SAB | WOLCFG_SAM, &regs->WOLCFGSet);\r\nwritew(WOLCR_MAGIC_EN, &regs->WOLCRSet);\r\nif (vptr->wol_opts & VELOCITY_WOL_UCAST)\r\nwritew(WOLCR_UNICAST_EN, &regs->WOLCRSet);\r\nif (vptr->wol_opts & VELOCITY_WOL_ARP) {\r\nstruct arp_packet *arp = (struct arp_packet *) buf;\r\nu16 crc;\r\nmemset(buf, 0, sizeof(struct arp_packet) + 7);\r\nfor (i = 0; i < 4; i++)\r\nwritel(mask_pattern[0][i], &regs->ByteMask[0][i]);\r\narp->type = htons(ETH_P_ARP);\r\narp->ar_op = htons(1);\r\nmemcpy(arp->ar_tip, vptr->ip_addr, 4);\r\ncrc = wol_calc_crc((sizeof(struct arp_packet) + 7) / 8, buf,\r\n(u8 *) & mask_pattern[0][0]);\r\nwritew(crc, &regs->PatternCRC[0]);\r\nwritew(WOLCR_ARP_EN, &regs->WOLCRSet);\r\n}\r\nBYTE_REG_BITS_ON(PWCFG_WOLTYPE, &regs->PWCFGSet);\r\nBYTE_REG_BITS_ON(PWCFG_LEGACY_WOLEN, &regs->PWCFGSet);\r\nwritew(0x0FFF, &regs->WOLSRClr);\r\nif (spd_dpx == SPD_DPX_1000_FULL)\r\ngoto mac_done;\r\nif (spd_dpx != SPD_DPX_AUTO)\r\ngoto advertise_done;\r\nif (vptr->mii_status & VELOCITY_AUTONEG_ENABLE) {\r\nif (PHYID_GET_PHY_ID(vptr->phy_id) == PHYID_CICADA_CS8201)\r\nMII_REG_BITS_ON(AUXCR_MDPPS, MII_NCONFIG, vptr->mac_regs);\r\nMII_REG_BITS_OFF(ADVERTISE_1000FULL | ADVERTISE_1000HALF, MII_CTRL1000, vptr->mac_regs);\r\n}\r\nif (vptr->mii_status & VELOCITY_SPEED_1000)\r\nMII_REG_BITS_ON(BMCR_ANRESTART, MII_BMCR, vptr->mac_regs);\r\nadvertise_done:\r\nBYTE_REG_BITS_ON(CHIPGCR_FCMODE, &regs->CHIPGCR);\r\n{\r\nu8 GCR;\r\nGCR = readb(&regs->CHIPGCR);\r\nGCR = (GCR & ~CHIPGCR_FCGMII) | CHIPGCR_FCFDX;\r\nwriteb(GCR, &regs->CHIPGCR);\r\n}\r\nmac_done:\r\nBYTE_REG_BITS_OFF(ISR_PWEI, &regs->ISR);\r\nBYTE_REG_BITS_ON(STICKHW_SWPTAG, &regs->STICKHW);\r\nBYTE_REG_BITS_ON((STICKHW_DS1 | STICKHW_DS0), &regs->STICKHW);\r\nreturn 0;\r\n}\r\nstatic void velocity_save_context(struct velocity_info *vptr, struct velocity_context *context)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nu16 i;\r\nu8 __iomem *ptr = (u8 __iomem *)regs;\r\nfor (i = MAC_REG_PAR; i < MAC_REG_CR0_CLR; i += 4)\r\n*((u32 *) (context->mac_reg + i)) = readl(ptr + i);\r\nfor (i = MAC_REG_MAR; i < MAC_REG_TDCSR_CLR; i += 4)\r\n*((u32 *) (context->mac_reg + i)) = readl(ptr + i);\r\nfor (i = MAC_REG_RDBASE_LO; i < MAC_REG_FIFO_TEST0; i += 4)\r\n*((u32 *) (context->mac_reg + i)) = readl(ptr + i);\r\n}\r\nstatic int velocity_suspend(struct device *dev)\r\n{\r\nstruct net_device *netdev = dev_get_drvdata(dev);\r\nstruct velocity_info *vptr = netdev_priv(netdev);\r\nunsigned long flags;\r\nif (!netif_running(vptr->netdev))\r\nreturn 0;\r\nnetif_device_detach(vptr->netdev);\r\nspin_lock_irqsave(&vptr->lock, flags);\r\nif (vptr->pdev)\r\npci_save_state(vptr->pdev);\r\nif (vptr->flags & VELOCITY_FLAGS_WOL_ENABLED) {\r\nvelocity_get_ip(vptr);\r\nvelocity_save_context(vptr, &vptr->context);\r\nvelocity_shutdown(vptr);\r\nvelocity_set_wol(vptr);\r\nif (vptr->pdev)\r\npci_enable_wake(vptr->pdev, PCI_D3hot, 1);\r\nvelocity_set_power_state(vptr, PCI_D3hot);\r\n} else {\r\nvelocity_save_context(vptr, &vptr->context);\r\nvelocity_shutdown(vptr);\r\nif (vptr->pdev)\r\npci_disable_device(vptr->pdev);\r\nvelocity_set_power_state(vptr, PCI_D3hot);\r\n}\r\nspin_unlock_irqrestore(&vptr->lock, flags);\r\nreturn 0;\r\n}\r\nstatic void velocity_restore_context(struct velocity_info *vptr, struct velocity_context *context)\r\n{\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nint i;\r\nu8 __iomem *ptr = (u8 __iomem *)regs;\r\nfor (i = MAC_REG_PAR; i < MAC_REG_CR0_SET; i += 4)\r\nwritel(*((u32 *) (context->mac_reg + i)), ptr + i);\r\nfor (i = MAC_REG_CR1_SET; i < MAC_REG_CR0_CLR; i++) {\r\nwriteb(~(*((u8 *) (context->mac_reg + i))), ptr + i + 4);\r\nwriteb(*((u8 *) (context->mac_reg + i)), ptr + i);\r\n}\r\nfor (i = MAC_REG_MAR; i < MAC_REG_IMR; i += 4)\r\nwritel(*((u32 *) (context->mac_reg + i)), ptr + i);\r\nfor (i = MAC_REG_RDBASE_LO; i < MAC_REG_FIFO_TEST0; i += 4)\r\nwritel(*((u32 *) (context->mac_reg + i)), ptr + i);\r\nfor (i = MAC_REG_TDCSR_SET; i <= MAC_REG_RDCSR_SET; i++)\r\nwriteb(*((u8 *) (context->mac_reg + i)), ptr + i);\r\n}\r\nstatic int velocity_resume(struct device *dev)\r\n{\r\nstruct net_device *netdev = dev_get_drvdata(dev);\r\nstruct velocity_info *vptr = netdev_priv(netdev);\r\nunsigned long flags;\r\nint i;\r\nif (!netif_running(vptr->netdev))\r\nreturn 0;\r\nvelocity_set_power_state(vptr, PCI_D0);\r\nif (vptr->pdev) {\r\npci_enable_wake(vptr->pdev, PCI_D0, 0);\r\npci_restore_state(vptr->pdev);\r\n}\r\nmac_wol_reset(vptr->mac_regs);\r\nspin_lock_irqsave(&vptr->lock, flags);\r\nvelocity_restore_context(vptr, &vptr->context);\r\nvelocity_init_registers(vptr, VELOCITY_INIT_WOL);\r\nmac_disable_int(vptr->mac_regs);\r\nvelocity_tx_srv(vptr);\r\nfor (i = 0; i < vptr->tx.numq; i++) {\r\nif (vptr->tx.used[i])\r\nmac_tx_queue_wake(vptr->mac_regs, i);\r\n}\r\nmac_enable_int(vptr->mac_regs);\r\nspin_unlock_irqrestore(&vptr->lock, flags);\r\nnetif_device_attach(vptr->netdev);\r\nreturn 0;\r\n}\r\nstatic int velocity_ethtool_up(struct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nif (!netif_running(dev))\r\nvelocity_set_power_state(vptr, PCI_D0);\r\nreturn 0;\r\n}\r\nstatic void velocity_ethtool_down(struct net_device *dev)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nif (!netif_running(dev))\r\nvelocity_set_power_state(vptr, PCI_D3hot);\r\n}\r\nstatic int velocity_get_settings(struct net_device *dev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nstruct mac_regs __iomem *regs = vptr->mac_regs;\r\nu32 status;\r\nstatus = check_connection_type(vptr->mac_regs);\r\ncmd->supported = SUPPORTED_TP |\r\nSUPPORTED_Autoneg |\r\nSUPPORTED_10baseT_Half |\r\nSUPPORTED_10baseT_Full |\r\nSUPPORTED_100baseT_Half |\r\nSUPPORTED_100baseT_Full |\r\nSUPPORTED_1000baseT_Half |\r\nSUPPORTED_1000baseT_Full;\r\ncmd->advertising = ADVERTISED_TP | ADVERTISED_Autoneg;\r\nif (vptr->options.spd_dpx == SPD_DPX_AUTO) {\r\ncmd->advertising |=\r\nADVERTISED_10baseT_Half |\r\nADVERTISED_10baseT_Full |\r\nADVERTISED_100baseT_Half |\r\nADVERTISED_100baseT_Full |\r\nADVERTISED_1000baseT_Half |\r\nADVERTISED_1000baseT_Full;\r\n} else {\r\nswitch (vptr->options.spd_dpx) {\r\ncase SPD_DPX_1000_FULL:\r\ncmd->advertising |= ADVERTISED_1000baseT_Full;\r\nbreak;\r\ncase SPD_DPX_100_HALF:\r\ncmd->advertising |= ADVERTISED_100baseT_Half;\r\nbreak;\r\ncase SPD_DPX_100_FULL:\r\ncmd->advertising |= ADVERTISED_100baseT_Full;\r\nbreak;\r\ncase SPD_DPX_10_HALF:\r\ncmd->advertising |= ADVERTISED_10baseT_Half;\r\nbreak;\r\ncase SPD_DPX_10_FULL:\r\ncmd->advertising |= ADVERTISED_10baseT_Full;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nif (status & VELOCITY_SPEED_1000)\r\nethtool_cmd_speed_set(cmd, SPEED_1000);\r\nelse if (status & VELOCITY_SPEED_100)\r\nethtool_cmd_speed_set(cmd, SPEED_100);\r\nelse\r\nethtool_cmd_speed_set(cmd, SPEED_10);\r\ncmd->autoneg = (status & VELOCITY_AUTONEG_ENABLE) ? AUTONEG_ENABLE : AUTONEG_DISABLE;\r\ncmd->port = PORT_TP;\r\ncmd->transceiver = XCVR_INTERNAL;\r\ncmd->phy_address = readb(&regs->MIIADR) & 0x1F;\r\nif (status & VELOCITY_DUPLEX_FULL)\r\ncmd->duplex = DUPLEX_FULL;\r\nelse\r\ncmd->duplex = DUPLEX_HALF;\r\nreturn 0;\r\n}\r\nstatic int velocity_set_settings(struct net_device *dev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nu32 speed = ethtool_cmd_speed(cmd);\r\nu32 curr_status;\r\nu32 new_status = 0;\r\nint ret = 0;\r\ncurr_status = check_connection_type(vptr->mac_regs);\r\ncurr_status &= (~VELOCITY_LINK_FAIL);\r\nnew_status |= ((cmd->autoneg) ? VELOCITY_AUTONEG_ENABLE : 0);\r\nnew_status |= ((speed == SPEED_1000) ? VELOCITY_SPEED_1000 : 0);\r\nnew_status |= ((speed == SPEED_100) ? VELOCITY_SPEED_100 : 0);\r\nnew_status |= ((speed == SPEED_10) ? VELOCITY_SPEED_10 : 0);\r\nnew_status |= ((cmd->duplex == DUPLEX_FULL) ? VELOCITY_DUPLEX_FULL : 0);\r\nif ((new_status & VELOCITY_AUTONEG_ENABLE) &&\r\n(new_status != (curr_status | VELOCITY_AUTONEG_ENABLE))) {\r\nret = -EINVAL;\r\n} else {\r\nenum speed_opt spd_dpx;\r\nif (new_status & VELOCITY_AUTONEG_ENABLE)\r\nspd_dpx = SPD_DPX_AUTO;\r\nelse if ((new_status & VELOCITY_SPEED_1000) &&\r\n(new_status & VELOCITY_DUPLEX_FULL)) {\r\nspd_dpx = SPD_DPX_1000_FULL;\r\n} else if (new_status & VELOCITY_SPEED_100)\r\nspd_dpx = (new_status & VELOCITY_DUPLEX_FULL) ?\r\nSPD_DPX_100_FULL : SPD_DPX_100_HALF;\r\nelse if (new_status & VELOCITY_SPEED_10)\r\nspd_dpx = (new_status & VELOCITY_DUPLEX_FULL) ?\r\nSPD_DPX_10_FULL : SPD_DPX_10_HALF;\r\nelse\r\nreturn -EOPNOTSUPP;\r\nvptr->options.spd_dpx = spd_dpx;\r\nvelocity_set_media_mode(vptr, new_status);\r\n}\r\nreturn ret;\r\n}\r\nstatic void velocity_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nstrlcpy(info->driver, VELOCITY_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, VELOCITY_VERSION, sizeof(info->version));\r\nif (vptr->pdev)\r\nstrlcpy(info->bus_info, pci_name(vptr->pdev),\r\nsizeof(info->bus_info));\r\nelse\r\nstrlcpy(info->bus_info, "platform", sizeof(info->bus_info));\r\n}\r\nstatic void velocity_ethtool_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nwol->supported = WAKE_PHY | WAKE_MAGIC | WAKE_UCAST | WAKE_ARP;\r\nwol->wolopts |= WAKE_MAGIC;\r\nif (vptr->wol_opts & VELOCITY_WOL_UCAST)\r\nwol->wolopts |= WAKE_UCAST;\r\nif (vptr->wol_opts & VELOCITY_WOL_ARP)\r\nwol->wolopts |= WAKE_ARP;\r\nmemcpy(&wol->sopass, vptr->wol_passwd, 6);\r\n}\r\nstatic int velocity_ethtool_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nif (!(wol->wolopts & (WAKE_PHY | WAKE_MAGIC | WAKE_UCAST | WAKE_ARP)))\r\nreturn -EFAULT;\r\nvptr->wol_opts = VELOCITY_WOL_MAGIC;\r\nif (wol->wolopts & WAKE_MAGIC) {\r\nvptr->wol_opts |= VELOCITY_WOL_MAGIC;\r\nvptr->flags |= VELOCITY_FLAGS_WOL_ENABLED;\r\n}\r\nif (wol->wolopts & WAKE_UCAST) {\r\nvptr->wol_opts |= VELOCITY_WOL_UCAST;\r\nvptr->flags |= VELOCITY_FLAGS_WOL_ENABLED;\r\n}\r\nif (wol->wolopts & WAKE_ARP) {\r\nvptr->wol_opts |= VELOCITY_WOL_ARP;\r\nvptr->flags |= VELOCITY_FLAGS_WOL_ENABLED;\r\n}\r\nmemcpy(vptr->wol_passwd, wol->sopass, 6);\r\nreturn 0;\r\n}\r\nstatic u32 velocity_get_msglevel(struct net_device *dev)\r\n{\r\nreturn msglevel;\r\n}\r\nstatic void velocity_set_msglevel(struct net_device *dev, u32 value)\r\n{\r\nmsglevel = value;\r\n}\r\nstatic int get_pending_timer_val(int val)\r\n{\r\nint mult_bits = val >> 6;\r\nint mult = 1;\r\nswitch (mult_bits)\r\n{\r\ncase 1:\r\nmult = 4; break;\r\ncase 2:\r\nmult = 16; break;\r\ncase 3:\r\nmult = 64; break;\r\ncase 0:\r\ndefault:\r\nbreak;\r\n}\r\nreturn (val & 0x3f) * mult;\r\n}\r\nstatic void set_pending_timer_val(int *val, u32 us)\r\n{\r\nu8 mult = 0;\r\nu8 shift = 0;\r\nif (us >= 0x3f) {\r\nmult = 1;\r\nshift = 2;\r\n}\r\nif (us >= 0x3f * 4) {\r\nmult = 2;\r\nshift = 4;\r\n}\r\nif (us >= 0x3f * 16) {\r\nmult = 3;\r\nshift = 6;\r\n}\r\n*val = (mult << 6) | ((us >> shift) & 0x3f);\r\n}\r\nstatic int velocity_get_coalesce(struct net_device *dev,\r\nstruct ethtool_coalesce *ecmd)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\necmd->tx_max_coalesced_frames = vptr->options.tx_intsup;\r\necmd->rx_max_coalesced_frames = vptr->options.rx_intsup;\r\necmd->rx_coalesce_usecs = get_pending_timer_val(vptr->options.rxqueue_timer);\r\necmd->tx_coalesce_usecs = get_pending_timer_val(vptr->options.txqueue_timer);\r\nreturn 0;\r\n}\r\nstatic int velocity_set_coalesce(struct net_device *dev,\r\nstruct ethtool_coalesce *ecmd)\r\n{\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nint max_us = 0x3f * 64;\r\nunsigned long flags;\r\nif (ecmd->tx_coalesce_usecs > max_us)\r\nreturn -EINVAL;\r\nif (ecmd->rx_coalesce_usecs > max_us)\r\nreturn -EINVAL;\r\nif (ecmd->tx_max_coalesced_frames > 0xff)\r\nreturn -EINVAL;\r\nif (ecmd->rx_max_coalesced_frames > 0xff)\r\nreturn -EINVAL;\r\nvptr->options.rx_intsup = ecmd->rx_max_coalesced_frames;\r\nvptr->options.tx_intsup = ecmd->tx_max_coalesced_frames;\r\nset_pending_timer_val(&vptr->options.rxqueue_timer,\r\necmd->rx_coalesce_usecs);\r\nset_pending_timer_val(&vptr->options.txqueue_timer,\r\necmd->tx_coalesce_usecs);\r\nspin_lock_irqsave(&vptr->lock, flags);\r\nmac_disable_int(vptr->mac_regs);\r\nsetup_adaptive_interrupts(vptr);\r\nsetup_queue_timers(vptr);\r\nmac_write_int_mask(vptr->int_mask, vptr->mac_regs);\r\nmac_clear_isr(vptr->mac_regs);\r\nmac_enable_int(vptr->mac_regs);\r\nspin_unlock_irqrestore(&vptr->lock, flags);\r\nreturn 0;\r\n}\r\nstatic void velocity_get_strings(struct net_device *dev, u32 sset, u8 *data)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nmemcpy(data, *velocity_gstrings, sizeof(velocity_gstrings));\r\nbreak;\r\n}\r\n}\r\nstatic int velocity_get_sset_count(struct net_device *dev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn ARRAY_SIZE(velocity_gstrings);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void velocity_get_ethtool_stats(struct net_device *dev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nif (netif_running(dev)) {\r\nstruct velocity_info *vptr = netdev_priv(dev);\r\nu32 *p = vptr->mib_counter;\r\nint i;\r\nspin_lock_irq(&vptr->lock);\r\nvelocity_update_hw_mibs(vptr);\r\nspin_unlock_irq(&vptr->lock);\r\nfor (i = 0; i < ARRAY_SIZE(velocity_gstrings); i++)\r\n*data++ = *p++;\r\n}\r\n}\r\nstatic int velocity_netdev_event(struct notifier_block *nb, unsigned long notification, void *ptr)\r\n{\r\nstruct in_ifaddr *ifa = ptr;\r\nstruct net_device *dev = ifa->ifa_dev->dev;\r\nif (dev_net(dev) == &init_net &&\r\ndev->netdev_ops == &velocity_netdev_ops)\r\nvelocity_get_ip(netdev_priv(dev));\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic void velocity_register_notifier(void)\r\n{\r\nregister_inetaddr_notifier(&velocity_inetaddr_notifier);\r\n}\r\nstatic void velocity_unregister_notifier(void)\r\n{\r\nunregister_inetaddr_notifier(&velocity_inetaddr_notifier);\r\n}\r\nstatic int __init velocity_init_module(void)\r\n{\r\nint ret_pci, ret_platform;\r\nvelocity_register_notifier();\r\nret_pci = pci_register_driver(&velocity_pci_driver);\r\nret_platform = platform_driver_register(&velocity_platform_driver);\r\nif ((ret_pci < 0) && (ret_platform < 0)) {\r\nvelocity_unregister_notifier();\r\nreturn ret_pci;\r\n}\r\nreturn 0;\r\n}\r\nstatic void __exit velocity_cleanup_module(void)\r\n{\r\nvelocity_unregister_notifier();\r\npci_unregister_driver(&velocity_pci_driver);\r\nplatform_driver_unregister(&velocity_platform_driver);\r\n}
