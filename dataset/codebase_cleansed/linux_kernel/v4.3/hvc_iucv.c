static struct hvc_iucv_private *hvc_iucv_get_private(uint32_t num)\r\n{\r\nif ((num < HVC_IUCV_MAGIC) || (num - HVC_IUCV_MAGIC > hvc_iucv_devices))\r\nreturn NULL;\r\nreturn hvc_iucv_table[num - HVC_IUCV_MAGIC];\r\n}\r\nstatic struct iucv_tty_buffer *alloc_tty_buffer(size_t size, gfp_t flags)\r\n{\r\nstruct iucv_tty_buffer *bufp;\r\nbufp = mempool_alloc(hvc_iucv_mempool, flags);\r\nif (!bufp)\r\nreturn NULL;\r\nmemset(bufp, 0, sizeof(*bufp));\r\nif (size > 0) {\r\nbufp->msg.length = MSG_SIZE(size);\r\nbufp->mbuf = kmalloc(bufp->msg.length, flags | GFP_DMA);\r\nif (!bufp->mbuf) {\r\nmempool_free(bufp, hvc_iucv_mempool);\r\nreturn NULL;\r\n}\r\nbufp->mbuf->version = MSG_VERSION;\r\nbufp->mbuf->type = MSG_TYPE_DATA;\r\nbufp->mbuf->datalen = (u16) size;\r\n}\r\nreturn bufp;\r\n}\r\nstatic void destroy_tty_buffer(struct iucv_tty_buffer *bufp)\r\n{\r\nkfree(bufp->mbuf);\r\nmempool_free(bufp, hvc_iucv_mempool);\r\n}\r\nstatic void destroy_tty_buffer_list(struct list_head *list)\r\n{\r\nstruct iucv_tty_buffer *ent, *next;\r\nlist_for_each_entry_safe(ent, next, list, list) {\r\nlist_del(&ent->list);\r\ndestroy_tty_buffer(ent);\r\n}\r\n}\r\nstatic int hvc_iucv_write(struct hvc_iucv_private *priv,\r\nchar *buf, int count, int *has_more_data)\r\n{\r\nstruct iucv_tty_buffer *rb;\r\nint written;\r\nint rc;\r\nif (priv->iucv_state == IUCV_DISCONN)\r\nreturn 0;\r\nif (priv->iucv_state == IUCV_SEVERED)\r\nreturn -EPIPE;\r\nif (list_empty(&priv->tty_inqueue))\r\nreturn 0;\r\nrb = list_first_entry(&priv->tty_inqueue, struct iucv_tty_buffer, list);\r\nwritten = 0;\r\nif (!rb->mbuf) {\r\nrb->mbuf = kmalloc(rb->msg.length, GFP_ATOMIC | GFP_DMA);\r\nif (!rb->mbuf)\r\nreturn -ENOMEM;\r\nrc = __iucv_message_receive(priv->path, &rb->msg, 0,\r\nrb->mbuf, rb->msg.length, NULL);\r\nswitch (rc) {\r\ncase 0:\r\nbreak;\r\ncase 2:\r\ncase 9:\r\nbreak;\r\ndefault:\r\nwritten = -EIO;\r\n}\r\nif (rc || (rb->mbuf->version != MSG_VERSION) ||\r\n(rb->msg.length != MSG_SIZE(rb->mbuf->datalen)))\r\ngoto out_remove_buffer;\r\n}\r\nswitch (rb->mbuf->type) {\r\ncase MSG_TYPE_DATA:\r\nwritten = min_t(int, rb->mbuf->datalen - rb->offset, count);\r\nmemcpy(buf, rb->mbuf->data + rb->offset, written);\r\nif (written < (rb->mbuf->datalen - rb->offset)) {\r\nrb->offset += written;\r\n*has_more_data = 1;\r\ngoto out_written;\r\n}\r\nbreak;\r\ncase MSG_TYPE_WINSIZE:\r\nif (rb->mbuf->datalen != sizeof(struct winsize))\r\nbreak;\r\n__hvc_resize(priv->hvc, *((struct winsize *) rb->mbuf->data));\r\nbreak;\r\ncase MSG_TYPE_ERROR:\r\ncase MSG_TYPE_TERMENV:\r\ncase MSG_TYPE_TERMIOS:\r\nbreak;\r\n}\r\nout_remove_buffer:\r\nlist_del(&rb->list);\r\ndestroy_tty_buffer(rb);\r\n*has_more_data = !list_empty(&priv->tty_inqueue);\r\nout_written:\r\nreturn written;\r\n}\r\nstatic int hvc_iucv_get_chars(uint32_t vtermno, char *buf, int count)\r\n{\r\nstruct hvc_iucv_private *priv = hvc_iucv_get_private(vtermno);\r\nint written;\r\nint has_more_data;\r\nif (count <= 0)\r\nreturn 0;\r\nif (!priv)\r\nreturn -ENODEV;\r\nspin_lock(&priv->lock);\r\nhas_more_data = 0;\r\nwritten = hvc_iucv_write(priv, buf, count, &has_more_data);\r\nspin_unlock(&priv->lock);\r\nif (has_more_data)\r\nhvc_kick();\r\nreturn written;\r\n}\r\nstatic int hvc_iucv_queue(struct hvc_iucv_private *priv, const char *buf,\r\nint count)\r\n{\r\nsize_t len;\r\nif (priv->iucv_state == IUCV_DISCONN)\r\nreturn count;\r\nif (priv->iucv_state == IUCV_SEVERED)\r\nreturn -EPIPE;\r\nlen = min_t(size_t, count, SNDBUF_SIZE - priv->sndbuf_len);\r\nif (!len)\r\nreturn 0;\r\nmemcpy(priv->sndbuf + priv->sndbuf_len, buf, len);\r\npriv->sndbuf_len += len;\r\nif (priv->iucv_state == IUCV_CONNECTED)\r\nschedule_delayed_work(&priv->sndbuf_work, QUEUE_SNDBUF_DELAY);\r\nreturn len;\r\n}\r\nstatic int hvc_iucv_send(struct hvc_iucv_private *priv)\r\n{\r\nstruct iucv_tty_buffer *sb;\r\nint rc, len;\r\nif (priv->iucv_state == IUCV_SEVERED)\r\nreturn -EPIPE;\r\nif (priv->iucv_state == IUCV_DISCONN)\r\nreturn -EIO;\r\nif (!priv->sndbuf_len)\r\nreturn 0;\r\nsb = alloc_tty_buffer(priv->sndbuf_len, GFP_ATOMIC);\r\nif (!sb)\r\nreturn -ENOMEM;\r\nmemcpy(sb->mbuf->data, priv->sndbuf, priv->sndbuf_len);\r\nsb->mbuf->datalen = (u16) priv->sndbuf_len;\r\nsb->msg.length = MSG_SIZE(sb->mbuf->datalen);\r\nlist_add_tail(&sb->list, &priv->tty_outqueue);\r\nrc = __iucv_message_send(priv->path, &sb->msg, 0, 0,\r\n(void *) sb->mbuf, sb->msg.length);\r\nif (rc) {\r\nlist_del(&sb->list);\r\ndestroy_tty_buffer(sb);\r\n}\r\nlen = priv->sndbuf_len;\r\npriv->sndbuf_len = 0;\r\nreturn len;\r\n}\r\nstatic void hvc_iucv_sndbuf_work(struct work_struct *work)\r\n{\r\nstruct hvc_iucv_private *priv;\r\npriv = container_of(work, struct hvc_iucv_private, sndbuf_work.work);\r\nif (!priv)\r\nreturn;\r\nspin_lock_bh(&priv->lock);\r\nhvc_iucv_send(priv);\r\nspin_unlock_bh(&priv->lock);\r\n}\r\nstatic int hvc_iucv_put_chars(uint32_t vtermno, const char *buf, int count)\r\n{\r\nstruct hvc_iucv_private *priv = hvc_iucv_get_private(vtermno);\r\nint queued;\r\nif (count <= 0)\r\nreturn 0;\r\nif (!priv)\r\nreturn -ENODEV;\r\nspin_lock(&priv->lock);\r\nqueued = hvc_iucv_queue(priv, buf, count);\r\nspin_unlock(&priv->lock);\r\nreturn queued;\r\n}\r\nstatic int hvc_iucv_notifier_add(struct hvc_struct *hp, int id)\r\n{\r\nstruct hvc_iucv_private *priv;\r\npriv = hvc_iucv_get_private(id);\r\nif (!priv)\r\nreturn 0;\r\nspin_lock_bh(&priv->lock);\r\npriv->tty_state = TTY_OPENED;\r\nspin_unlock_bh(&priv->lock);\r\nreturn 0;\r\n}\r\nstatic void hvc_iucv_cleanup(struct hvc_iucv_private *priv)\r\n{\r\ndestroy_tty_buffer_list(&priv->tty_outqueue);\r\ndestroy_tty_buffer_list(&priv->tty_inqueue);\r\npriv->tty_state = TTY_CLOSED;\r\npriv->iucv_state = IUCV_DISCONN;\r\npriv->sndbuf_len = 0;\r\n}\r\nstatic inline int tty_outqueue_empty(struct hvc_iucv_private *priv)\r\n{\r\nint rc;\r\nspin_lock_bh(&priv->lock);\r\nrc = list_empty(&priv->tty_outqueue);\r\nspin_unlock_bh(&priv->lock);\r\nreturn rc;\r\n}\r\nstatic void flush_sndbuf_sync(struct hvc_iucv_private *priv)\r\n{\r\nint sync_wait;\r\ncancel_delayed_work_sync(&priv->sndbuf_work);\r\nspin_lock_bh(&priv->lock);\r\nhvc_iucv_send(priv);\r\nsync_wait = !list_empty(&priv->tty_outqueue);\r\nspin_unlock_bh(&priv->lock);\r\nif (sync_wait)\r\nwait_event_timeout(priv->sndbuf_waitq,\r\ntty_outqueue_empty(priv), HZ/10);\r\n}\r\nstatic void hvc_iucv_hangup(struct hvc_iucv_private *priv)\r\n{\r\nstruct iucv_path *path;\r\npath = NULL;\r\nspin_lock(&priv->lock);\r\nif (priv->iucv_state == IUCV_CONNECTED) {\r\npath = priv->path;\r\npriv->path = NULL;\r\npriv->iucv_state = IUCV_SEVERED;\r\nif (priv->tty_state == TTY_CLOSED)\r\nhvc_iucv_cleanup(priv);\r\nelse\r\nif (priv->is_console) {\r\nhvc_iucv_cleanup(priv);\r\npriv->tty_state = TTY_OPENED;\r\n} else\r\nhvc_kick();\r\n}\r\nspin_unlock(&priv->lock);\r\nif (path) {\r\niucv_path_sever(path, NULL);\r\niucv_path_free(path);\r\n}\r\n}\r\nstatic void hvc_iucv_notifier_hangup(struct hvc_struct *hp, int id)\r\n{\r\nstruct hvc_iucv_private *priv;\r\npriv = hvc_iucv_get_private(id);\r\nif (!priv)\r\nreturn;\r\nflush_sndbuf_sync(priv);\r\nspin_lock_bh(&priv->lock);\r\npriv->tty_state = TTY_CLOSED;\r\nif (priv->iucv_state == IUCV_SEVERED)\r\nhvc_iucv_cleanup(priv);\r\nspin_unlock_bh(&priv->lock);\r\n}\r\nstatic void hvc_iucv_dtr_rts(struct hvc_struct *hp, int raise)\r\n{\r\nstruct hvc_iucv_private *priv;\r\nstruct iucv_path *path;\r\nif (raise)\r\nreturn;\r\npriv = hvc_iucv_get_private(hp->vtermno);\r\nif (!priv)\r\nreturn;\r\nflush_sndbuf_sync(priv);\r\nspin_lock_bh(&priv->lock);\r\npath = priv->path;\r\npriv->path = NULL;\r\npriv->iucv_state = IUCV_DISCONN;\r\nspin_unlock_bh(&priv->lock);\r\nif (path) {\r\niucv_path_sever(path, NULL);\r\niucv_path_free(path);\r\n}\r\n}\r\nstatic void hvc_iucv_notifier_del(struct hvc_struct *hp, int id)\r\n{\r\nstruct hvc_iucv_private *priv;\r\npriv = hvc_iucv_get_private(id);\r\nif (!priv)\r\nreturn;\r\nflush_sndbuf_sync(priv);\r\nspin_lock_bh(&priv->lock);\r\ndestroy_tty_buffer_list(&priv->tty_outqueue);\r\ndestroy_tty_buffer_list(&priv->tty_inqueue);\r\npriv->tty_state = TTY_CLOSED;\r\npriv->sndbuf_len = 0;\r\nspin_unlock_bh(&priv->lock);\r\n}\r\nstatic int hvc_iucv_filter_connreq(u8 ipvmid[8])\r\n{\r\nconst char *wildcard, *filter_entry;\r\nsize_t i, len;\r\nif (!hvc_iucv_filter_size)\r\nreturn 0;\r\nfor (i = 0; i < hvc_iucv_filter_size; i++) {\r\nfilter_entry = hvc_iucv_filter + (8 * i);\r\nwildcard = strnchr(filter_entry, 8, FILTER_WILDCARD_CHAR);\r\nlen = (wildcard) ? wildcard - filter_entry : 8;\r\nif (0 == memcmp(ipvmid, filter_entry, len))\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic int hvc_iucv_path_pending(struct iucv_path *path,\r\nu8 ipvmid[8], u8 ipuser[16])\r\n{\r\nstruct hvc_iucv_private *priv, *tmp;\r\nu8 wildcard[9] = "lnxhvc ";\r\nint i, rc, find_unused;\r\nu8 nuser_data[16];\r\nu8 vm_user_id[9];\r\nASCEBC(wildcard, sizeof(wildcard));\r\nfind_unused = !memcmp(wildcard, ipuser, 8);\r\npriv = NULL;\r\nfor (i = 0; i < hvc_iucv_devices; i++) {\r\ntmp = hvc_iucv_table[i];\r\nif (!tmp)\r\ncontinue;\r\nif (find_unused) {\r\nspin_lock(&tmp->lock);\r\nif (tmp->iucv_state == IUCV_DISCONN)\r\npriv = tmp;\r\nspin_unlock(&tmp->lock);\r\n} else if (!memcmp(tmp->srv_name, ipuser, 8))\r\npriv = tmp;\r\nif (priv)\r\nbreak;\r\n}\r\nif (!priv)\r\nreturn -ENODEV;\r\nread_lock(&hvc_iucv_filter_lock);\r\nrc = hvc_iucv_filter_connreq(ipvmid);\r\nread_unlock(&hvc_iucv_filter_lock);\r\nif (rc) {\r\niucv_path_sever(path, ipuser);\r\niucv_path_free(path);\r\nmemcpy(vm_user_id, ipvmid, 8);\r\nvm_user_id[8] = 0;\r\npr_info("A connection request from z/VM user ID %s "\r\n"was refused\n", vm_user_id);\r\nreturn 0;\r\n}\r\nspin_lock(&priv->lock);\r\nif (priv->iucv_state != IUCV_DISCONN) {\r\niucv_path_sever(path, ipuser);\r\niucv_path_free(path);\r\ngoto out_path_handled;\r\n}\r\nmemcpy(nuser_data, ipuser + 8, 8);\r\nmemcpy(nuser_data + 8, ipuser, 8);\r\npath->msglim = 0xffff;\r\npath->flags &= ~IUCV_IPRMDATA;\r\nrc = iucv_path_accept(path, &hvc_iucv_handler, nuser_data, priv);\r\nif (rc) {\r\niucv_path_sever(path, ipuser);\r\niucv_path_free(path);\r\ngoto out_path_handled;\r\n}\r\npriv->path = path;\r\npriv->iucv_state = IUCV_CONNECTED;\r\nmemcpy(priv->info_path, ipvmid, 8);\r\nmemcpy(priv->info_path + 8, ipuser + 8, 8);\r\nschedule_delayed_work(&priv->sndbuf_work, 5);\r\nout_path_handled:\r\nspin_unlock(&priv->lock);\r\nreturn 0;\r\n}\r\nstatic void hvc_iucv_path_severed(struct iucv_path *path, u8 ipuser[16])\r\n{\r\nstruct hvc_iucv_private *priv = path->private;\r\nhvc_iucv_hangup(priv);\r\n}\r\nstatic void hvc_iucv_msg_pending(struct iucv_path *path,\r\nstruct iucv_message *msg)\r\n{\r\nstruct hvc_iucv_private *priv = path->private;\r\nstruct iucv_tty_buffer *rb;\r\nif (msg->length > MSG_SIZE(MSG_MAX_DATALEN)) {\r\niucv_message_reject(path, msg);\r\nreturn;\r\n}\r\nspin_lock(&priv->lock);\r\nif (priv->tty_state == TTY_CLOSED) {\r\niucv_message_reject(path, msg);\r\ngoto unlock_return;\r\n}\r\nrb = alloc_tty_buffer(0, GFP_ATOMIC);\r\nif (!rb) {\r\niucv_message_reject(path, msg);\r\ngoto unlock_return;\r\n}\r\nrb->msg = *msg;\r\nlist_add_tail(&rb->list, &priv->tty_inqueue);\r\nhvc_kick();\r\nunlock_return:\r\nspin_unlock(&priv->lock);\r\n}\r\nstatic void hvc_iucv_msg_complete(struct iucv_path *path,\r\nstruct iucv_message *msg)\r\n{\r\nstruct hvc_iucv_private *priv = path->private;\r\nstruct iucv_tty_buffer *ent, *next;\r\nLIST_HEAD(list_remove);\r\nspin_lock(&priv->lock);\r\nlist_for_each_entry_safe(ent, next, &priv->tty_outqueue, list)\r\nif (ent->msg.id == msg->id) {\r\nlist_move(&ent->list, &list_remove);\r\nbreak;\r\n}\r\nwake_up(&priv->sndbuf_waitq);\r\nspin_unlock(&priv->lock);\r\ndestroy_tty_buffer_list(&list_remove);\r\n}\r\nstatic int hvc_iucv_pm_freeze(struct device *dev)\r\n{\r\nstruct hvc_iucv_private *priv = dev_get_drvdata(dev);\r\nlocal_bh_disable();\r\nhvc_iucv_hangup(priv);\r\nlocal_bh_enable();\r\nreturn 0;\r\n}\r\nstatic int hvc_iucv_pm_restore_thaw(struct device *dev)\r\n{\r\nhvc_kick();\r\nreturn 0;\r\n}\r\nstatic ssize_t hvc_iucv_dev_termid_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct hvc_iucv_private *priv = dev_get_drvdata(dev);\r\nsize_t len;\r\nlen = sizeof(priv->srv_name);\r\nmemcpy(buf, priv->srv_name, len);\r\nEBCASC(buf, len);\r\nbuf[len++] = '\n';\r\nreturn len;\r\n}\r\nstatic ssize_t hvc_iucv_dev_state_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct hvc_iucv_private *priv = dev_get_drvdata(dev);\r\nreturn sprintf(buf, "%u:%u\n", priv->iucv_state, priv->tty_state);\r\n}\r\nstatic ssize_t hvc_iucv_dev_peer_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct hvc_iucv_private *priv = dev_get_drvdata(dev);\r\nchar vmid[9], ipuser[9];\r\nmemset(vmid, 0, sizeof(vmid));\r\nmemset(ipuser, 0, sizeof(ipuser));\r\nspin_lock_bh(&priv->lock);\r\nif (priv->iucv_state == IUCV_CONNECTED) {\r\nmemcpy(vmid, priv->info_path, 8);\r\nmemcpy(ipuser, priv->info_path + 8, 8);\r\n}\r\nspin_unlock_bh(&priv->lock);\r\nEBCASC(ipuser, 8);\r\nreturn sprintf(buf, "%s:%s\n", vmid, ipuser);\r\n}\r\nstatic int __init hvc_iucv_alloc(int id, unsigned int is_console)\r\n{\r\nstruct hvc_iucv_private *priv;\r\nchar name[9];\r\nint rc;\r\npriv = kzalloc(sizeof(struct hvc_iucv_private), GFP_KERNEL);\r\nif (!priv)\r\nreturn -ENOMEM;\r\nspin_lock_init(&priv->lock);\r\nINIT_LIST_HEAD(&priv->tty_outqueue);\r\nINIT_LIST_HEAD(&priv->tty_inqueue);\r\nINIT_DELAYED_WORK(&priv->sndbuf_work, hvc_iucv_sndbuf_work);\r\ninit_waitqueue_head(&priv->sndbuf_waitq);\r\npriv->sndbuf = (void *) get_zeroed_page(GFP_KERNEL);\r\nif (!priv->sndbuf) {\r\nkfree(priv);\r\nreturn -ENOMEM;\r\n}\r\npriv->is_console = is_console;\r\npriv->hvc = hvc_alloc(HVC_IUCV_MAGIC + id,\r\nHVC_IUCV_MAGIC + id, &hvc_iucv_ops, 256);\r\nif (IS_ERR(priv->hvc)) {\r\nrc = PTR_ERR(priv->hvc);\r\ngoto out_error_hvc;\r\n}\r\npriv->hvc->irq_requested = 1;\r\nsnprintf(name, 9, "lnxhvc%-2d", id);\r\nmemcpy(priv->srv_name, name, 8);\r\nASCEBC(priv->srv_name, 8);\r\npriv->dev = kzalloc(sizeof(*priv->dev), GFP_KERNEL);\r\nif (!priv->dev) {\r\nrc = -ENOMEM;\r\ngoto out_error_dev;\r\n}\r\ndev_set_name(priv->dev, "hvc_iucv%d", id);\r\ndev_set_drvdata(priv->dev, priv);\r\npriv->dev->bus = &iucv_bus;\r\npriv->dev->parent = iucv_root;\r\npriv->dev->driver = &hvc_iucv_driver;\r\npriv->dev->groups = hvc_iucv_dev_attr_groups;\r\npriv->dev->release = (void (*)(struct device *)) kfree;\r\nrc = device_register(priv->dev);\r\nif (rc) {\r\nput_device(priv->dev);\r\ngoto out_error_dev;\r\n}\r\nhvc_iucv_table[id] = priv;\r\nreturn 0;\r\nout_error_dev:\r\nhvc_remove(priv->hvc);\r\nout_error_hvc:\r\nfree_page((unsigned long) priv->sndbuf);\r\nkfree(priv);\r\nreturn rc;\r\n}\r\nstatic void __init hvc_iucv_destroy(struct hvc_iucv_private *priv)\r\n{\r\nhvc_remove(priv->hvc);\r\ndevice_unregister(priv->dev);\r\nfree_page((unsigned long) priv->sndbuf);\r\nkfree(priv);\r\n}\r\nstatic const char *hvc_iucv_parse_filter(const char *filter, char *dest)\r\n{\r\nconst char *nextdelim, *residual;\r\nsize_t len;\r\nnextdelim = strchr(filter, ',');\r\nif (nextdelim) {\r\nlen = nextdelim - filter;\r\nresidual = nextdelim + 1;\r\n} else {\r\nlen = strlen(filter);\r\nresidual = filter + len;\r\n}\r\nif (len == 0)\r\nreturn ERR_PTR(-EINVAL);\r\nif (filter[len - 1] == '\n')\r\nlen--;\r\nif (len == 1 && *filter == FILTER_WILDCARD_CHAR)\r\nreturn ERR_PTR(-EINVAL);\r\nif (len > 8)\r\nreturn ERR_PTR(-EINVAL);\r\nmemset(dest, ' ', 8);\r\nwhile (len--)\r\ndest[len] = toupper(filter[len]);\r\nreturn residual;\r\n}\r\nstatic int hvc_iucv_setup_filter(const char *val)\r\n{\r\nconst char *residual;\r\nint err;\r\nsize_t size, count;\r\nvoid *array, *old_filter;\r\ncount = strlen(val);\r\nif (count == 0 || (count == 1 && val[0] == '\n')) {\r\nsize = 0;\r\narray = NULL;\r\ngoto out_replace_filter;\r\n}\r\nsize = 1;\r\nresidual = val;\r\nwhile ((residual = strchr(residual, ',')) != NULL) {\r\nresidual++;\r\nsize++;\r\n}\r\nif (size > MAX_VMID_FILTER)\r\nreturn -ENOSPC;\r\narray = kzalloc(size * 8, GFP_KERNEL);\r\nif (!array)\r\nreturn -ENOMEM;\r\ncount = size;\r\nresidual = val;\r\nwhile (*residual && count) {\r\nresidual = hvc_iucv_parse_filter(residual,\r\narray + ((size - count) * 8));\r\nif (IS_ERR(residual)) {\r\nerr = PTR_ERR(residual);\r\nkfree(array);\r\ngoto out_err;\r\n}\r\ncount--;\r\n}\r\nout_replace_filter:\r\nwrite_lock_bh(&hvc_iucv_filter_lock);\r\nold_filter = hvc_iucv_filter;\r\nhvc_iucv_filter_size = size;\r\nhvc_iucv_filter = array;\r\nwrite_unlock_bh(&hvc_iucv_filter_lock);\r\nkfree(old_filter);\r\nerr = 0;\r\nout_err:\r\nreturn err;\r\n}\r\nstatic int param_set_vmidfilter(const char *val, const struct kernel_param *kp)\r\n{\r\nint rc;\r\nif (!MACHINE_IS_VM || !hvc_iucv_devices)\r\nreturn -ENODEV;\r\nif (!val)\r\nreturn -EINVAL;\r\nrc = 0;\r\nif (slab_is_available())\r\nrc = hvc_iucv_setup_filter(val);\r\nelse\r\nhvc_iucv_filter_string = val;\r\nreturn rc;\r\n}\r\nstatic int param_get_vmidfilter(char *buffer, const struct kernel_param *kp)\r\n{\r\nint rc;\r\nsize_t index, len;\r\nvoid *start, *end;\r\nif (!MACHINE_IS_VM || !hvc_iucv_devices)\r\nreturn -ENODEV;\r\nrc = 0;\r\nread_lock_bh(&hvc_iucv_filter_lock);\r\nfor (index = 0; index < hvc_iucv_filter_size; index++) {\r\nstart = hvc_iucv_filter + (8 * index);\r\nend = memchr(start, ' ', 8);\r\nlen = (end) ? end - start : 8;\r\nmemcpy(buffer + rc, start, len);\r\nrc += len;\r\nbuffer[rc++] = ',';\r\n}\r\nread_unlock_bh(&hvc_iucv_filter_lock);\r\nif (rc)\r\nbuffer[--rc] = '\0';\r\nreturn rc;\r\n}\r\nstatic int __init hvc_iucv_init(void)\r\n{\r\nint rc;\r\nunsigned int i;\r\nif (!hvc_iucv_devices)\r\nreturn -ENODEV;\r\nif (!MACHINE_IS_VM) {\r\npr_notice("The z/VM IUCV HVC device driver cannot "\r\n"be used without z/VM\n");\r\nrc = -ENODEV;\r\ngoto out_error;\r\n}\r\nif (hvc_iucv_devices > MAX_HVC_IUCV_LINES) {\r\npr_err("%lu is not a valid value for the hvc_iucv= "\r\n"kernel parameter\n", hvc_iucv_devices);\r\nrc = -EINVAL;\r\ngoto out_error;\r\n}\r\nrc = driver_register(&hvc_iucv_driver);\r\nif (rc)\r\ngoto out_error;\r\nif (hvc_iucv_filter_string) {\r\nrc = hvc_iucv_setup_filter(hvc_iucv_filter_string);\r\nswitch (rc) {\r\ncase 0:\r\nbreak;\r\ncase -ENOMEM:\r\npr_err("Allocating memory failed with "\r\n"reason code=%d\n", 3);\r\ngoto out_error;\r\ncase -EINVAL:\r\npr_err("hvc_iucv_allow= does not specify a valid "\r\n"z/VM user ID list\n");\r\ngoto out_error;\r\ncase -ENOSPC:\r\npr_err("hvc_iucv_allow= specifies too many "\r\n"z/VM user IDs\n");\r\ngoto out_error;\r\ndefault:\r\ngoto out_error;\r\n}\r\n}\r\nhvc_iucv_buffer_cache = kmem_cache_create(KMSG_COMPONENT,\r\nsizeof(struct iucv_tty_buffer),\r\n0, 0, NULL);\r\nif (!hvc_iucv_buffer_cache) {\r\npr_err("Allocating memory failed with reason code=%d\n", 1);\r\nrc = -ENOMEM;\r\ngoto out_error;\r\n}\r\nhvc_iucv_mempool = mempool_create_slab_pool(MEMPOOL_MIN_NR,\r\nhvc_iucv_buffer_cache);\r\nif (!hvc_iucv_mempool) {\r\npr_err("Allocating memory failed with reason code=%d\n", 2);\r\nkmem_cache_destroy(hvc_iucv_buffer_cache);\r\nrc = -ENOMEM;\r\ngoto out_error;\r\n}\r\nrc = hvc_instantiate(HVC_IUCV_MAGIC, IUCV_HVC_CON_IDX, &hvc_iucv_ops);\r\nif (rc) {\r\npr_err("Registering HVC terminal device as "\r\n"Linux console failed\n");\r\ngoto out_error_memory;\r\n}\r\nfor (i = 0; i < hvc_iucv_devices; i++) {\r\nrc = hvc_iucv_alloc(i, (i == IUCV_HVC_CON_IDX) ? 1 : 0);\r\nif (rc) {\r\npr_err("Creating a new HVC terminal device "\r\n"failed with error code=%d\n", rc);\r\ngoto out_error_hvc;\r\n}\r\n}\r\nrc = iucv_register(&hvc_iucv_handler, 0);\r\nif (rc) {\r\npr_err("Registering IUCV handlers failed with error code=%d\n",\r\nrc);\r\ngoto out_error_hvc;\r\n}\r\nreturn 0;\r\nout_error_hvc:\r\nfor (i = 0; i < hvc_iucv_devices; i++)\r\nif (hvc_iucv_table[i])\r\nhvc_iucv_destroy(hvc_iucv_table[i]);\r\nout_error_memory:\r\nmempool_destroy(hvc_iucv_mempool);\r\nkmem_cache_destroy(hvc_iucv_buffer_cache);\r\nout_error:\r\nkfree(hvc_iucv_filter);\r\nhvc_iucv_devices = 0;\r\nreturn rc;\r\n}\r\nstatic int __init hvc_iucv_config(char *val)\r\n{\r\nreturn kstrtoul(val, 10, &hvc_iucv_devices);\r\n}
