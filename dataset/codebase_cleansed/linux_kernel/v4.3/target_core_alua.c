sense_reason_t\r\ntarget_emulate_report_referrals(struct se_cmd *cmd)\r\n{\r\nstruct se_device *dev = cmd->se_dev;\r\nstruct t10_alua_lba_map *map;\r\nstruct t10_alua_lba_map_member *map_mem;\r\nunsigned char *buf;\r\nu32 rd_len = 0, off;\r\nif (cmd->data_length < 4) {\r\npr_warn("REPORT REFERRALS allocation length %u too"\r\n" small\n", cmd->data_length);\r\nreturn TCM_INVALID_CDB_FIELD;\r\n}\r\nbuf = transport_kmap_data_sg(cmd);\r\nif (!buf)\r\nreturn TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;\r\noff = 4;\r\nspin_lock(&dev->t10_alua.lba_map_lock);\r\nif (list_empty(&dev->t10_alua.lba_map_list)) {\r\nspin_unlock(&dev->t10_alua.lba_map_lock);\r\ntransport_kunmap_data_sg(cmd);\r\nreturn TCM_UNSUPPORTED_SCSI_OPCODE;\r\n}\r\nlist_for_each_entry(map, &dev->t10_alua.lba_map_list,\r\nlba_map_list) {\r\nint desc_num = off + 3;\r\nint pg_num;\r\noff += 4;\r\nif (cmd->data_length > off)\r\nput_unaligned_be64(map->lba_map_first_lba, &buf[off]);\r\noff += 8;\r\nif (cmd->data_length > off)\r\nput_unaligned_be64(map->lba_map_last_lba, &buf[off]);\r\noff += 8;\r\nrd_len += 20;\r\npg_num = 0;\r\nlist_for_each_entry(map_mem, &map->lba_map_mem_list,\r\nlba_map_mem_list) {\r\nint alua_state = map_mem->lba_map_mem_alua_state;\r\nint alua_pg_id = map_mem->lba_map_mem_alua_pg_id;\r\nif (cmd->data_length > off)\r\nbuf[off] = alua_state & 0x0f;\r\noff += 2;\r\nif (cmd->data_length > off)\r\nbuf[off] = (alua_pg_id >> 8) & 0xff;\r\noff++;\r\nif (cmd->data_length > off)\r\nbuf[off] = (alua_pg_id & 0xff);\r\noff++;\r\nrd_len += 4;\r\npg_num++;\r\n}\r\nif (cmd->data_length > desc_num)\r\nbuf[desc_num] = pg_num;\r\n}\r\nspin_unlock(&dev->t10_alua.lba_map_lock);\r\nput_unaligned_be16(rd_len, &buf[2]);\r\ntransport_kunmap_data_sg(cmd);\r\ntarget_complete_cmd(cmd, GOOD);\r\nreturn 0;\r\n}\r\nsense_reason_t\r\ntarget_emulate_report_target_port_groups(struct se_cmd *cmd)\r\n{\r\nstruct se_device *dev = cmd->se_dev;\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nstruct se_lun *lun;\r\nunsigned char *buf;\r\nu32 rd_len = 0, off;\r\nint ext_hdr = (cmd->t_task_cdb[1] & 0x20);\r\nif (ext_hdr != 0)\r\noff = 8;\r\nelse\r\noff = 4;\r\nif (cmd->data_length < off) {\r\npr_warn("REPORT TARGET PORT GROUPS allocation length %u too"\r\n" small for %s header\n", cmd->data_length,\r\n(ext_hdr) ? "extended" : "normal");\r\nreturn TCM_INVALID_CDB_FIELD;\r\n}\r\nbuf = transport_kmap_data_sg(cmd);\r\nif (!buf)\r\nreturn TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\nlist_for_each_entry(tg_pt_gp, &dev->t10_alua.tg_pt_gps_list,\r\ntg_pt_gp_list) {\r\nif ((off + 8 + (tg_pt_gp->tg_pt_gp_members * 4)) >\r\ncmd->data_length) {\r\nrd_len += 8 + (tg_pt_gp->tg_pt_gp_members * 4);\r\ncontinue;\r\n}\r\nif (tg_pt_gp->tg_pt_gp_pref)\r\nbuf[off] = 0x80;\r\nbuf[off++] |= (atomic_read(\r\n&tg_pt_gp->tg_pt_gp_alua_access_state) & 0xff);\r\nbuf[off++] |= tg_pt_gp->tg_pt_gp_alua_supported_states;\r\nbuf[off++] = ((tg_pt_gp->tg_pt_gp_id >> 8) & 0xff);\r\nbuf[off++] = (tg_pt_gp->tg_pt_gp_id & 0xff);\r\noff++;\r\nbuf[off++] = (tg_pt_gp->tg_pt_gp_alua_access_status & 0xff);\r\nbuf[off++] = 0x00;\r\nbuf[off++] = (tg_pt_gp->tg_pt_gp_members & 0xff);\r\nrd_len += 8;\r\nspin_lock(&tg_pt_gp->tg_pt_gp_lock);\r\nlist_for_each_entry(lun, &tg_pt_gp->tg_pt_gp_lun_list,\r\nlun_tg_pt_gp_link) {\r\noff += 2;\r\nbuf[off++] = ((lun->lun_rtpi >> 8) & 0xff);\r\nbuf[off++] = (lun->lun_rtpi & 0xff);\r\nrd_len += 4;\r\n}\r\nspin_unlock(&tg_pt_gp->tg_pt_gp_lock);\r\n}\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nput_unaligned_be32(rd_len, &buf[0]);\r\nif (ext_hdr != 0) {\r\nbuf[4] = 0x10;\r\nspin_lock(&cmd->se_lun->lun_tg_pt_gp_lock);\r\ntg_pt_gp = cmd->se_lun->lun_tg_pt_gp;\r\nif (tg_pt_gp)\r\nbuf[5] = tg_pt_gp->tg_pt_gp_implicit_trans_secs;\r\nspin_unlock(&cmd->se_lun->lun_tg_pt_gp_lock);\r\n}\r\ntransport_kunmap_data_sg(cmd);\r\ntarget_complete_cmd(cmd, GOOD);\r\nreturn 0;\r\n}\r\nsense_reason_t\r\ntarget_emulate_set_target_port_groups(struct se_cmd *cmd)\r\n{\r\nstruct se_device *dev = cmd->se_dev;\r\nstruct se_lun *l_lun = cmd->se_lun;\r\nstruct se_node_acl *nacl = cmd->se_sess->se_node_acl;\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp = NULL, *l_tg_pt_gp;\r\nunsigned char *buf;\r\nunsigned char *ptr;\r\nsense_reason_t rc = TCM_NO_SENSE;\r\nu32 len = 4;\r\nint alua_access_state, primary = 0, valid_states;\r\nu16 tg_pt_id, rtpi;\r\nif (cmd->data_length < 4) {\r\npr_warn("SET TARGET PORT GROUPS parameter list length %u too"\r\n" small\n", cmd->data_length);\r\nreturn TCM_INVALID_PARAMETER_LIST;\r\n}\r\nbuf = transport_kmap_data_sg(cmd);\r\nif (!buf)\r\nreturn TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;\r\nspin_lock(&l_lun->lun_tg_pt_gp_lock);\r\nl_tg_pt_gp = l_lun->lun_tg_pt_gp;\r\nif (!l_tg_pt_gp) {\r\nspin_unlock(&l_lun->lun_tg_pt_gp_lock);\r\npr_err("Unable to access l_lun->tg_pt_gp\n");\r\nrc = TCM_UNSUPPORTED_SCSI_OPCODE;\r\ngoto out;\r\n}\r\nif (!(l_tg_pt_gp->tg_pt_gp_alua_access_type & TPGS_EXPLICIT_ALUA)) {\r\nspin_unlock(&l_lun->lun_tg_pt_gp_lock);\r\npr_debug("Unable to process SET_TARGET_PORT_GROUPS"\r\n" while TPGS_EXPLICIT_ALUA is disabled\n");\r\nrc = TCM_UNSUPPORTED_SCSI_OPCODE;\r\ngoto out;\r\n}\r\nvalid_states = l_tg_pt_gp->tg_pt_gp_alua_supported_states;\r\nspin_unlock(&l_lun->lun_tg_pt_gp_lock);\r\nptr = &buf[4];\r\nwhile (len < cmd->data_length) {\r\nbool found = false;\r\nalua_access_state = (ptr[0] & 0x0f);\r\nrc = core_alua_check_transition(alua_access_state,\r\nvalid_states, &primary);\r\nif (rc) {\r\ngoto out;\r\n}\r\nif (primary) {\r\ntg_pt_id = get_unaligned_be16(ptr + 2);\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\nlist_for_each_entry(tg_pt_gp,\r\n&dev->t10_alua.tg_pt_gps_list,\r\ntg_pt_gp_list) {\r\nif (!tg_pt_gp->tg_pt_gp_valid_id)\r\ncontinue;\r\nif (tg_pt_id != tg_pt_gp->tg_pt_gp_id)\r\ncontinue;\r\natomic_inc_mb(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nif (!core_alua_do_port_transition(tg_pt_gp,\r\ndev, l_lun, nacl,\r\nalua_access_state, 1))\r\nfound = true;\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\natomic_dec_mb(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nbreak;\r\n}\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\n} else {\r\nstruct se_lun *lun;\r\nrtpi = get_unaligned_be16(ptr + 2);\r\nspin_lock(&dev->se_port_lock);\r\nlist_for_each_entry(lun, &dev->dev_sep_list,\r\nlun_dev_link) {\r\nif (lun->lun_rtpi != rtpi)\r\ncontinue;\r\nspin_unlock(&dev->se_port_lock);\r\nif (!core_alua_set_tg_pt_secondary_state(\r\nlun, 1, 1))\r\nfound = true;\r\nspin_lock(&dev->se_port_lock);\r\nbreak;\r\n}\r\nspin_unlock(&dev->se_port_lock);\r\n}\r\nif (!found) {\r\nrc = TCM_INVALID_PARAMETER_LIST;\r\ngoto out;\r\n}\r\nptr += 4;\r\nlen += 4;\r\n}\r\nout:\r\ntransport_kunmap_data_sg(cmd);\r\nif (!rc)\r\ntarget_complete_cmd(cmd, GOOD);\r\nreturn rc;\r\n}\r\nstatic inline void set_ascq(struct se_cmd *cmd, u8 alua_ascq)\r\n{\r\npr_debug("[%s]: ALUA TG Port not available, "\r\n"SenseKey: NOT_READY, ASC/ASCQ: "\r\n"0x04/0x%02x\n",\r\ncmd->se_tfo->get_fabric_name(), alua_ascq);\r\ncmd->scsi_asc = 0x04;\r\ncmd->scsi_ascq = alua_ascq;\r\n}\r\nstatic inline void core_alua_state_nonoptimized(\r\nstruct se_cmd *cmd,\r\nunsigned char *cdb,\r\nint nonop_delay_msecs)\r\n{\r\ncmd->se_cmd_flags |= SCF_ALUA_NON_OPTIMIZED;\r\ncmd->alua_nonop_delay = nonop_delay_msecs;\r\n}\r\nstatic inline int core_alua_state_lba_dependent(\r\nstruct se_cmd *cmd,\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nstruct se_device *dev = cmd->se_dev;\r\nu64 segment_size, segment_mult, sectors, lba;\r\nif (!(cmd->se_cmd_flags & SCF_SCSI_DATA_CDB))\r\nreturn 0;\r\nspin_lock(&dev->t10_alua.lba_map_lock);\r\nsegment_size = dev->t10_alua.lba_map_segment_size;\r\nsegment_mult = dev->t10_alua.lba_map_segment_multiplier;\r\nsectors = cmd->data_length / dev->dev_attrib.block_size;\r\nlba = cmd->t_task_lba;\r\nwhile (lba < cmd->t_task_lba + sectors) {\r\nstruct t10_alua_lba_map *cur_map = NULL, *map;\r\nstruct t10_alua_lba_map_member *map_mem;\r\nlist_for_each_entry(map, &dev->t10_alua.lba_map_list,\r\nlba_map_list) {\r\nu64 start_lba, last_lba;\r\nu64 first_lba = map->lba_map_first_lba;\r\nif (segment_mult) {\r\nu64 tmp = lba;\r\nstart_lba = do_div(tmp, segment_size * segment_mult);\r\nlast_lba = first_lba + segment_size - 1;\r\nif (start_lba >= first_lba &&\r\nstart_lba <= last_lba) {\r\nlba += segment_size;\r\ncur_map = map;\r\nbreak;\r\n}\r\n} else {\r\nlast_lba = map->lba_map_last_lba;\r\nif (lba >= first_lba && lba <= last_lba) {\r\nlba = last_lba + 1;\r\ncur_map = map;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (!cur_map) {\r\nspin_unlock(&dev->t10_alua.lba_map_lock);\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_UNAVAILABLE);\r\nreturn 1;\r\n}\r\nlist_for_each_entry(map_mem, &cur_map->lba_map_mem_list,\r\nlba_map_mem_list) {\r\nif (map_mem->lba_map_mem_alua_pg_id !=\r\ntg_pt_gp->tg_pt_gp_id)\r\ncontinue;\r\nswitch(map_mem->lba_map_mem_alua_state) {\r\ncase ALUA_ACCESS_STATE_STANDBY:\r\nspin_unlock(&dev->t10_alua.lba_map_lock);\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_STANDBY);\r\nreturn 1;\r\ncase ALUA_ACCESS_STATE_UNAVAILABLE:\r\nspin_unlock(&dev->t10_alua.lba_map_lock);\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_UNAVAILABLE);\r\nreturn 1;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\n}\r\nspin_unlock(&dev->t10_alua.lba_map_lock);\r\nreturn 0;\r\n}\r\nstatic inline int core_alua_state_standby(\r\nstruct se_cmd *cmd,\r\nunsigned char *cdb)\r\n{\r\nswitch (cdb[0]) {\r\ncase INQUIRY:\r\ncase LOG_SELECT:\r\ncase LOG_SENSE:\r\ncase MODE_SELECT:\r\ncase MODE_SENSE:\r\ncase REPORT_LUNS:\r\ncase RECEIVE_DIAGNOSTIC:\r\ncase SEND_DIAGNOSTIC:\r\ncase READ_CAPACITY:\r\nreturn 0;\r\ncase SERVICE_ACTION_IN_16:\r\nswitch (cdb[1] & 0x1f) {\r\ncase SAI_READ_CAPACITY_16:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_STANDBY);\r\nreturn 1;\r\n}\r\ncase MAINTENANCE_IN:\r\nswitch (cdb[1] & 0x1f) {\r\ncase MI_REPORT_TARGET_PGS:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_STANDBY);\r\nreturn 1;\r\n}\r\ncase MAINTENANCE_OUT:\r\nswitch (cdb[1]) {\r\ncase MO_SET_TARGET_PGS:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_STANDBY);\r\nreturn 1;\r\n}\r\ncase REQUEST_SENSE:\r\ncase PERSISTENT_RESERVE_IN:\r\ncase PERSISTENT_RESERVE_OUT:\r\ncase READ_BUFFER:\r\ncase WRITE_BUFFER:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_STANDBY);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline int core_alua_state_unavailable(\r\nstruct se_cmd *cmd,\r\nunsigned char *cdb)\r\n{\r\nswitch (cdb[0]) {\r\ncase INQUIRY:\r\ncase REPORT_LUNS:\r\nreturn 0;\r\ncase MAINTENANCE_IN:\r\nswitch (cdb[1] & 0x1f) {\r\ncase MI_REPORT_TARGET_PGS:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_UNAVAILABLE);\r\nreturn 1;\r\n}\r\ncase MAINTENANCE_OUT:\r\nswitch (cdb[1]) {\r\ncase MO_SET_TARGET_PGS:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_UNAVAILABLE);\r\nreturn 1;\r\n}\r\ncase REQUEST_SENSE:\r\ncase READ_BUFFER:\r\ncase WRITE_BUFFER:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_TG_PT_UNAVAILABLE);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline int core_alua_state_transition(\r\nstruct se_cmd *cmd,\r\nunsigned char *cdb)\r\n{\r\nswitch (cdb[0]) {\r\ncase INQUIRY:\r\ncase REPORT_LUNS:\r\nreturn 0;\r\ncase MAINTENANCE_IN:\r\nswitch (cdb[1] & 0x1f) {\r\ncase MI_REPORT_TARGET_PGS:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_STATE_TRANSITION);\r\nreturn 1;\r\n}\r\ncase REQUEST_SENSE:\r\ncase READ_BUFFER:\r\ncase WRITE_BUFFER:\r\nreturn 0;\r\ndefault:\r\nset_ascq(cmd, ASCQ_04H_ALUA_STATE_TRANSITION);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nsense_reason_t\r\ntarget_alua_state_check(struct se_cmd *cmd)\r\n{\r\nstruct se_device *dev = cmd->se_dev;\r\nunsigned char *cdb = cmd->t_task_cdb;\r\nstruct se_lun *lun = cmd->se_lun;\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nint out_alua_state, nonop_delay_msecs;\r\nif (dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE)\r\nreturn 0;\r\nif (dev->transport->transport_flags & TRANSPORT_FLAG_PASSTHROUGH)\r\nreturn 0;\r\nif (atomic_read(&lun->lun_tg_pt_secondary_offline)) {\r\npr_debug("ALUA: Got secondary offline status for local"\r\n" target port\n");\r\nset_ascq(cmd, ASCQ_04H_ALUA_OFFLINE);\r\nreturn TCM_CHECK_CONDITION_NOT_READY;\r\n}\r\nif (!lun->lun_tg_pt_gp)\r\nreturn 0;\r\nspin_lock(&lun->lun_tg_pt_gp_lock);\r\ntg_pt_gp = lun->lun_tg_pt_gp;\r\nout_alua_state = atomic_read(&tg_pt_gp->tg_pt_gp_alua_access_state);\r\nnonop_delay_msecs = tg_pt_gp->tg_pt_gp_nonop_delay_msecs;\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\nif (out_alua_state == ALUA_ACCESS_STATE_ACTIVE_OPTIMIZED)\r\nreturn 0;\r\nswitch (out_alua_state) {\r\ncase ALUA_ACCESS_STATE_ACTIVE_NON_OPTIMIZED:\r\ncore_alua_state_nonoptimized(cmd, cdb, nonop_delay_msecs);\r\nbreak;\r\ncase ALUA_ACCESS_STATE_STANDBY:\r\nif (core_alua_state_standby(cmd, cdb))\r\nreturn TCM_CHECK_CONDITION_NOT_READY;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_UNAVAILABLE:\r\nif (core_alua_state_unavailable(cmd, cdb))\r\nreturn TCM_CHECK_CONDITION_NOT_READY;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_TRANSITION:\r\nif (core_alua_state_transition(cmd, cdb))\r\nreturn TCM_CHECK_CONDITION_NOT_READY;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_LBA_DEPENDENT:\r\nif (core_alua_state_lba_dependent(cmd, tg_pt_gp))\r\nreturn TCM_CHECK_CONDITION_NOT_READY;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_OFFLINE:\r\ndefault:\r\npr_err("Unknown ALUA access state: 0x%02x\n",\r\nout_alua_state);\r\nreturn TCM_INVALID_CDB_FIELD;\r\n}\r\nreturn 0;\r\n}\r\nstatic sense_reason_t\r\ncore_alua_check_transition(int state, int valid, int *primary)\r\n{\r\nswitch (state) {\r\ncase ALUA_ACCESS_STATE_ACTIVE_OPTIMIZED:\r\nif (!(valid & ALUA_AO_SUP))\r\ngoto not_supported;\r\n*primary = 1;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_ACTIVE_NON_OPTIMIZED:\r\nif (!(valid & ALUA_AN_SUP))\r\ngoto not_supported;\r\n*primary = 1;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_STANDBY:\r\nif (!(valid & ALUA_S_SUP))\r\ngoto not_supported;\r\n*primary = 1;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_UNAVAILABLE:\r\nif (!(valid & ALUA_U_SUP))\r\ngoto not_supported;\r\n*primary = 1;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_LBA_DEPENDENT:\r\nif (!(valid & ALUA_LBD_SUP))\r\ngoto not_supported;\r\n*primary = 1;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_OFFLINE:\r\nif (!(valid & ALUA_O_SUP))\r\ngoto not_supported;\r\n*primary = 0;\r\nbreak;\r\ncase ALUA_ACCESS_STATE_TRANSITION:\r\ngoto not_supported;\r\ndefault:\r\npr_err("Unknown ALUA access state: 0x%02x\n", state);\r\nreturn TCM_INVALID_PARAMETER_LIST;\r\n}\r\nreturn 0;\r\nnot_supported:\r\npr_err("ALUA access state %s not supported",\r\ncore_alua_dump_state(state));\r\nreturn TCM_INVALID_PARAMETER_LIST;\r\n}\r\nstatic char *core_alua_dump_state(int state)\r\n{\r\nswitch (state) {\r\ncase ALUA_ACCESS_STATE_ACTIVE_OPTIMIZED:\r\nreturn "Active/Optimized";\r\ncase ALUA_ACCESS_STATE_ACTIVE_NON_OPTIMIZED:\r\nreturn "Active/NonOptimized";\r\ncase ALUA_ACCESS_STATE_LBA_DEPENDENT:\r\nreturn "LBA Dependent";\r\ncase ALUA_ACCESS_STATE_STANDBY:\r\nreturn "Standby";\r\ncase ALUA_ACCESS_STATE_UNAVAILABLE:\r\nreturn "Unavailable";\r\ncase ALUA_ACCESS_STATE_OFFLINE:\r\nreturn "Offline";\r\ncase ALUA_ACCESS_STATE_TRANSITION:\r\nreturn "Transitioning";\r\ndefault:\r\nreturn "Unknown";\r\n}\r\nreturn NULL;\r\n}\r\nchar *core_alua_dump_status(int status)\r\n{\r\nswitch (status) {\r\ncase ALUA_STATUS_NONE:\r\nreturn "None";\r\ncase ALUA_STATUS_ALTERED_BY_EXPLICIT_STPG:\r\nreturn "Altered by Explicit STPG";\r\ncase ALUA_STATUS_ALTERED_BY_IMPLICIT_ALUA:\r\nreturn "Altered by Implicit ALUA";\r\ndefault:\r\nreturn "Unknown";\r\n}\r\nreturn NULL;\r\n}\r\nint core_alua_check_nonop_delay(\r\nstruct se_cmd *cmd)\r\n{\r\nif (!(cmd->se_cmd_flags & SCF_ALUA_NON_OPTIMIZED))\r\nreturn 0;\r\nif (in_interrupt())\r\nreturn 0;\r\nif (!cmd->alua_nonop_delay)\r\nreturn 0;\r\nmsleep_interruptible(cmd->alua_nonop_delay);\r\nreturn 0;\r\n}\r\nstatic int core_alua_write_tpg_metadata(\r\nconst char *path,\r\nunsigned char *md_buf,\r\nu32 md_buf_len)\r\n{\r\nstruct file *file = filp_open(path, O_RDWR | O_CREAT | O_TRUNC, 0600);\r\nint ret;\r\nif (IS_ERR(file)) {\r\npr_err("filp_open(%s) for ALUA metadata failed\n", path);\r\nreturn -ENODEV;\r\n}\r\nret = kernel_write(file, md_buf, md_buf_len, 0);\r\nif (ret < 0)\r\npr_err("Error writing ALUA metadata file: %s\n", path);\r\nfput(file);\r\nreturn (ret < 0) ? -EIO : 0;\r\n}\r\nstatic int core_alua_update_tpg_primary_metadata(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nunsigned char *md_buf;\r\nstruct t10_wwn *wwn = &tg_pt_gp->tg_pt_gp_dev->t10_wwn;\r\nchar path[ALUA_METADATA_PATH_LEN];\r\nint len, rc;\r\nmd_buf = kzalloc(ALUA_MD_BUF_LEN, GFP_KERNEL);\r\nif (!md_buf) {\r\npr_err("Unable to allocate buf for ALUA metadata\n");\r\nreturn -ENOMEM;\r\n}\r\nmemset(path, 0, ALUA_METADATA_PATH_LEN);\r\nlen = snprintf(md_buf, ALUA_MD_BUF_LEN,\r\n"tg_pt_gp_id=%hu\n"\r\n"alua_access_state=0x%02x\n"\r\n"alua_access_status=0x%02x\n",\r\ntg_pt_gp->tg_pt_gp_id,\r\ntg_pt_gp->tg_pt_gp_alua_pending_state,\r\ntg_pt_gp->tg_pt_gp_alua_access_status);\r\nsnprintf(path, ALUA_METADATA_PATH_LEN,\r\n"/var/target/alua/tpgs_%s/%s", &wwn->unit_serial[0],\r\nconfig_item_name(&tg_pt_gp->tg_pt_gp_group.cg_item));\r\nrc = core_alua_write_tpg_metadata(path, md_buf, len);\r\nkfree(md_buf);\r\nreturn rc;\r\n}\r\nstatic void core_alua_queue_state_change_ua(struct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nstruct se_dev_entry *se_deve;\r\nstruct se_lun *lun;\r\nstruct se_lun_acl *lacl;\r\nspin_lock(&tg_pt_gp->tg_pt_gp_lock);\r\nlist_for_each_entry(lun, &tg_pt_gp->tg_pt_gp_lun_list,\r\nlun_tg_pt_gp_link) {\r\nif (!percpu_ref_tryget_live(&lun->lun_ref))\r\ncontinue;\r\nspin_unlock(&tg_pt_gp->tg_pt_gp_lock);\r\nspin_lock(&lun->lun_deve_lock);\r\nlist_for_each_entry(se_deve, &lun->lun_deve_list, lun_link) {\r\nlacl = rcu_dereference_check(se_deve->se_lun_acl,\r\nlockdep_is_held(&lun->lun_deve_lock));\r\nif ((tg_pt_gp->tg_pt_gp_alua_access_status ==\r\nALUA_STATUS_ALTERED_BY_EXPLICIT_STPG) &&\r\n(tg_pt_gp->tg_pt_gp_alua_lun != NULL) &&\r\n(tg_pt_gp->tg_pt_gp_alua_lun == lun))\r\ncontinue;\r\nif (lacl && (tg_pt_gp->tg_pt_gp_alua_nacl != NULL) &&\r\n(tg_pt_gp->tg_pt_gp_alua_nacl == lacl->se_lun_nacl))\r\ncontinue;\r\ncore_scsi3_ua_allocate(se_deve, 0x2A,\r\nASCQ_2AH_ASYMMETRIC_ACCESS_STATE_CHANGED);\r\n}\r\nspin_unlock(&lun->lun_deve_lock);\r\nspin_lock(&tg_pt_gp->tg_pt_gp_lock);\r\npercpu_ref_put(&lun->lun_ref);\r\n}\r\nspin_unlock(&tg_pt_gp->tg_pt_gp_lock);\r\n}\r\nstatic void core_alua_do_transition_tg_pt_work(struct work_struct *work)\r\n{\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp = container_of(work,\r\nstruct t10_alua_tg_pt_gp, tg_pt_gp_transition_work.work);\r\nstruct se_device *dev = tg_pt_gp->tg_pt_gp_dev;\r\nbool explicit = (tg_pt_gp->tg_pt_gp_alua_access_status ==\r\nALUA_STATUS_ALTERED_BY_EXPLICIT_STPG);\r\nif (tg_pt_gp->tg_pt_gp_write_metadata) {\r\nmutex_lock(&tg_pt_gp->tg_pt_gp_md_mutex);\r\ncore_alua_update_tpg_primary_metadata(tg_pt_gp);\r\nmutex_unlock(&tg_pt_gp->tg_pt_gp_md_mutex);\r\n}\r\natomic_set(&tg_pt_gp->tg_pt_gp_alua_access_state,\r\ntg_pt_gp->tg_pt_gp_alua_pending_state);\r\npr_debug("Successful %s ALUA transition TG PT Group: %s ID: %hu"\r\n" from primary access state %s to %s\n", (explicit) ? "explicit" :\r\n"implicit", config_item_name(&tg_pt_gp->tg_pt_gp_group.cg_item),\r\ntg_pt_gp->tg_pt_gp_id,\r\ncore_alua_dump_state(tg_pt_gp->tg_pt_gp_alua_previous_state),\r\ncore_alua_dump_state(tg_pt_gp->tg_pt_gp_alua_pending_state));\r\ncore_alua_queue_state_change_ua(tg_pt_gp);\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\natomic_dec(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nif (tg_pt_gp->tg_pt_gp_transition_complete)\r\ncomplete(tg_pt_gp->tg_pt_gp_transition_complete);\r\n}\r\nstatic int core_alua_do_transition_tg_pt(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nint new_state,\r\nint explicit)\r\n{\r\nstruct se_device *dev = tg_pt_gp->tg_pt_gp_dev;\r\nDECLARE_COMPLETION_ONSTACK(wait);\r\nif (atomic_read(&tg_pt_gp->tg_pt_gp_alua_access_state) == new_state)\r\nreturn 0;\r\nif (new_state == ALUA_ACCESS_STATE_TRANSITION)\r\nreturn -EAGAIN;\r\nif (!explicit && tg_pt_gp->tg_pt_gp_implicit_trans_secs &&\r\natomic_read(&tg_pt_gp->tg_pt_gp_alua_access_state) ==\r\nALUA_ACCESS_STATE_TRANSITION) {\r\ntg_pt_gp->tg_pt_gp_alua_pending_state = new_state;\r\ntg_pt_gp->tg_pt_gp_transition_complete = &wait;\r\nflush_delayed_work(&tg_pt_gp->tg_pt_gp_transition_work);\r\nwait_for_completion(&wait);\r\ntg_pt_gp->tg_pt_gp_transition_complete = NULL;\r\nreturn 0;\r\n}\r\ntg_pt_gp->tg_pt_gp_alua_previous_state =\r\natomic_read(&tg_pt_gp->tg_pt_gp_alua_access_state);\r\ntg_pt_gp->tg_pt_gp_alua_pending_state = new_state;\r\natomic_set(&tg_pt_gp->tg_pt_gp_alua_access_state,\r\nALUA_ACCESS_STATE_TRANSITION);\r\ntg_pt_gp->tg_pt_gp_alua_access_status = (explicit) ?\r\nALUA_STATUS_ALTERED_BY_EXPLICIT_STPG :\r\nALUA_STATUS_ALTERED_BY_IMPLICIT_ALUA;\r\ncore_alua_queue_state_change_ua(tg_pt_gp);\r\nif (tg_pt_gp->tg_pt_gp_trans_delay_msecs != 0)\r\nmsleep_interruptible(tg_pt_gp->tg_pt_gp_trans_delay_msecs);\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\natomic_inc(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nif (!explicit && tg_pt_gp->tg_pt_gp_implicit_trans_secs) {\r\nunsigned long transition_tmo;\r\ntransition_tmo = tg_pt_gp->tg_pt_gp_implicit_trans_secs * HZ;\r\nqueue_delayed_work(tg_pt_gp->tg_pt_gp_dev->tmr_wq,\r\n&tg_pt_gp->tg_pt_gp_transition_work,\r\ntransition_tmo);\r\n} else {\r\ntg_pt_gp->tg_pt_gp_transition_complete = &wait;\r\nqueue_delayed_work(tg_pt_gp->tg_pt_gp_dev->tmr_wq,\r\n&tg_pt_gp->tg_pt_gp_transition_work, 0);\r\nwait_for_completion(&wait);\r\ntg_pt_gp->tg_pt_gp_transition_complete = NULL;\r\n}\r\nreturn 0;\r\n}\r\nint core_alua_do_port_transition(\r\nstruct t10_alua_tg_pt_gp *l_tg_pt_gp,\r\nstruct se_device *l_dev,\r\nstruct se_lun *l_lun,\r\nstruct se_node_acl *l_nacl,\r\nint new_state,\r\nint explicit)\r\n{\r\nstruct se_device *dev;\r\nstruct t10_alua_lu_gp *lu_gp;\r\nstruct t10_alua_lu_gp_member *lu_gp_mem, *local_lu_gp_mem;\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nint primary, valid_states, rc = 0;\r\nvalid_states = l_tg_pt_gp->tg_pt_gp_alua_supported_states;\r\nif (core_alua_check_transition(new_state, valid_states, &primary) != 0)\r\nreturn -EINVAL;\r\nlocal_lu_gp_mem = l_dev->dev_alua_lu_gp_mem;\r\nspin_lock(&local_lu_gp_mem->lu_gp_mem_lock);\r\nlu_gp = local_lu_gp_mem->lu_gp;\r\natomic_inc(&lu_gp->lu_gp_ref_cnt);\r\nspin_unlock(&local_lu_gp_mem->lu_gp_mem_lock);\r\nif (!lu_gp->lu_gp_id) {\r\nl_tg_pt_gp->tg_pt_gp_alua_lun = l_lun;\r\nl_tg_pt_gp->tg_pt_gp_alua_nacl = l_nacl;\r\nrc = core_alua_do_transition_tg_pt(l_tg_pt_gp,\r\nnew_state, explicit);\r\natomic_dec_mb(&lu_gp->lu_gp_ref_cnt);\r\nreturn rc;\r\n}\r\nspin_lock(&lu_gp->lu_gp_lock);\r\nlist_for_each_entry(lu_gp_mem, &lu_gp->lu_gp_mem_list,\r\nlu_gp_mem_list) {\r\ndev = lu_gp_mem->lu_gp_mem_dev;\r\natomic_inc_mb(&lu_gp_mem->lu_gp_mem_ref_cnt);\r\nspin_unlock(&lu_gp->lu_gp_lock);\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\nlist_for_each_entry(tg_pt_gp,\r\n&dev->t10_alua.tg_pt_gps_list,\r\ntg_pt_gp_list) {\r\nif (!tg_pt_gp->tg_pt_gp_valid_id)\r\ncontinue;\r\nif (l_tg_pt_gp->tg_pt_gp_id != tg_pt_gp->tg_pt_gp_id)\r\ncontinue;\r\nif (l_tg_pt_gp == tg_pt_gp) {\r\ntg_pt_gp->tg_pt_gp_alua_lun = l_lun;\r\ntg_pt_gp->tg_pt_gp_alua_nacl = l_nacl;\r\n} else {\r\ntg_pt_gp->tg_pt_gp_alua_lun = NULL;\r\ntg_pt_gp->tg_pt_gp_alua_nacl = NULL;\r\n}\r\natomic_inc_mb(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nrc = core_alua_do_transition_tg_pt(tg_pt_gp,\r\nnew_state, explicit);\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\natomic_dec_mb(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nif (rc)\r\nbreak;\r\n}\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nspin_lock(&lu_gp->lu_gp_lock);\r\natomic_dec_mb(&lu_gp_mem->lu_gp_mem_ref_cnt);\r\n}\r\nspin_unlock(&lu_gp->lu_gp_lock);\r\nif (!rc) {\r\npr_debug("Successfully processed LU Group: %s all ALUA TG PT"\r\n" Group IDs: %hu %s transition to primary state: %s\n",\r\nconfig_item_name(&lu_gp->lu_gp_group.cg_item),\r\nl_tg_pt_gp->tg_pt_gp_id,\r\n(explicit) ? "explicit" : "implicit",\r\ncore_alua_dump_state(new_state));\r\n}\r\natomic_dec_mb(&lu_gp->lu_gp_ref_cnt);\r\nreturn rc;\r\n}\r\nstatic int core_alua_update_tpg_secondary_metadata(struct se_lun *lun)\r\n{\r\nstruct se_portal_group *se_tpg = lun->lun_tpg;\r\nunsigned char *md_buf;\r\nchar path[ALUA_METADATA_PATH_LEN], wwn[ALUA_SECONDARY_METADATA_WWN_LEN];\r\nint len, rc;\r\nmutex_lock(&lun->lun_tg_pt_md_mutex);\r\nmd_buf = kzalloc(ALUA_MD_BUF_LEN, GFP_KERNEL);\r\nif (!md_buf) {\r\npr_err("Unable to allocate buf for ALUA metadata\n");\r\nrc = -ENOMEM;\r\ngoto out_unlock;\r\n}\r\nmemset(path, 0, ALUA_METADATA_PATH_LEN);\r\nmemset(wwn, 0, ALUA_SECONDARY_METADATA_WWN_LEN);\r\nlen = snprintf(wwn, ALUA_SECONDARY_METADATA_WWN_LEN, "%s",\r\nse_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg));\r\nif (se_tpg->se_tpg_tfo->tpg_get_tag != NULL)\r\nsnprintf(wwn+len, ALUA_SECONDARY_METADATA_WWN_LEN-len, "+%hu",\r\nse_tpg->se_tpg_tfo->tpg_get_tag(se_tpg));\r\nlen = snprintf(md_buf, ALUA_MD_BUF_LEN, "alua_tg_pt_offline=%d\n"\r\n"alua_tg_pt_status=0x%02x\n",\r\natomic_read(&lun->lun_tg_pt_secondary_offline),\r\nlun->lun_tg_pt_secondary_stat);\r\nsnprintf(path, ALUA_METADATA_PATH_LEN, "/var/target/alua/%s/%s/lun_%llu",\r\nse_tpg->se_tpg_tfo->get_fabric_name(), wwn,\r\nlun->unpacked_lun);\r\nrc = core_alua_write_tpg_metadata(path, md_buf, len);\r\nkfree(md_buf);\r\nout_unlock:\r\nmutex_unlock(&lun->lun_tg_pt_md_mutex);\r\nreturn rc;\r\n}\r\nstatic int core_alua_set_tg_pt_secondary_state(\r\nstruct se_lun *lun,\r\nint explicit,\r\nint offline)\r\n{\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nint trans_delay_msecs;\r\nspin_lock(&lun->lun_tg_pt_gp_lock);\r\ntg_pt_gp = lun->lun_tg_pt_gp;\r\nif (!tg_pt_gp) {\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\npr_err("Unable to complete secondary state"\r\n" transition\n");\r\nreturn -EINVAL;\r\n}\r\ntrans_delay_msecs = tg_pt_gp->tg_pt_gp_trans_delay_msecs;\r\nif (offline)\r\natomic_set(&lun->lun_tg_pt_secondary_offline, 1);\r\nelse\r\natomic_set(&lun->lun_tg_pt_secondary_offline, 0);\r\nlun->lun_tg_pt_secondary_stat = (explicit) ?\r\nALUA_STATUS_ALTERED_BY_EXPLICIT_STPG :\r\nALUA_STATUS_ALTERED_BY_IMPLICIT_ALUA;\r\npr_debug("Successful %s ALUA transition TG PT Group: %s ID: %hu"\r\n" to secondary access state: %s\n", (explicit) ? "explicit" :\r\n"implicit", config_item_name(&tg_pt_gp->tg_pt_gp_group.cg_item),\r\ntg_pt_gp->tg_pt_gp_id, (offline) ? "OFFLINE" : "ONLINE");\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\nif (trans_delay_msecs != 0)\r\nmsleep_interruptible(trans_delay_msecs);\r\nif (lun->lun_tg_pt_secondary_write_md)\r\ncore_alua_update_tpg_secondary_metadata(lun);\r\nreturn 0;\r\n}\r\nstruct t10_alua_lba_map *\r\ncore_alua_allocate_lba_map(struct list_head *list,\r\nu64 first_lba, u64 last_lba)\r\n{\r\nstruct t10_alua_lba_map *lba_map;\r\nlba_map = kmem_cache_zalloc(t10_alua_lba_map_cache, GFP_KERNEL);\r\nif (!lba_map) {\r\npr_err("Unable to allocate struct t10_alua_lba_map\n");\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nINIT_LIST_HEAD(&lba_map->lba_map_mem_list);\r\nlba_map->lba_map_first_lba = first_lba;\r\nlba_map->lba_map_last_lba = last_lba;\r\nlist_add_tail(&lba_map->lba_map_list, list);\r\nreturn lba_map;\r\n}\r\nint\r\ncore_alua_allocate_lba_map_mem(struct t10_alua_lba_map *lba_map,\r\nint pg_id, int state)\r\n{\r\nstruct t10_alua_lba_map_member *lba_map_mem;\r\nlist_for_each_entry(lba_map_mem, &lba_map->lba_map_mem_list,\r\nlba_map_mem_list) {\r\nif (lba_map_mem->lba_map_mem_alua_pg_id == pg_id) {\r\npr_err("Duplicate pg_id %d in lba_map\n", pg_id);\r\nreturn -EINVAL;\r\n}\r\n}\r\nlba_map_mem = kmem_cache_zalloc(t10_alua_lba_map_mem_cache, GFP_KERNEL);\r\nif (!lba_map_mem) {\r\npr_err("Unable to allocate struct t10_alua_lba_map_mem\n");\r\nreturn -ENOMEM;\r\n}\r\nlba_map_mem->lba_map_mem_alua_state = state;\r\nlba_map_mem->lba_map_mem_alua_pg_id = pg_id;\r\nlist_add_tail(&lba_map_mem->lba_map_mem_list,\r\n&lba_map->lba_map_mem_list);\r\nreturn 0;\r\n}\r\nvoid\r\ncore_alua_free_lba_map(struct list_head *lba_list)\r\n{\r\nstruct t10_alua_lba_map *lba_map, *lba_map_tmp;\r\nstruct t10_alua_lba_map_member *lba_map_mem, *lba_map_mem_tmp;\r\nlist_for_each_entry_safe(lba_map, lba_map_tmp, lba_list,\r\nlba_map_list) {\r\nlist_for_each_entry_safe(lba_map_mem, lba_map_mem_tmp,\r\n&lba_map->lba_map_mem_list,\r\nlba_map_mem_list) {\r\nlist_del(&lba_map_mem->lba_map_mem_list);\r\nkmem_cache_free(t10_alua_lba_map_mem_cache,\r\nlba_map_mem);\r\n}\r\nlist_del(&lba_map->lba_map_list);\r\nkmem_cache_free(t10_alua_lba_map_cache, lba_map);\r\n}\r\n}\r\nvoid\r\ncore_alua_set_lba_map(struct se_device *dev, struct list_head *lba_map_list,\r\nint segment_size, int segment_mult)\r\n{\r\nstruct list_head old_lba_map_list;\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nint activate = 0, supported;\r\nINIT_LIST_HEAD(&old_lba_map_list);\r\nspin_lock(&dev->t10_alua.lba_map_lock);\r\ndev->t10_alua.lba_map_segment_size = segment_size;\r\ndev->t10_alua.lba_map_segment_multiplier = segment_mult;\r\nlist_splice_init(&dev->t10_alua.lba_map_list, &old_lba_map_list);\r\nif (lba_map_list) {\r\nlist_splice_init(lba_map_list, &dev->t10_alua.lba_map_list);\r\nactivate = 1;\r\n}\r\nspin_unlock(&dev->t10_alua.lba_map_lock);\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\nlist_for_each_entry(tg_pt_gp, &dev->t10_alua.tg_pt_gps_list,\r\ntg_pt_gp_list) {\r\nif (!tg_pt_gp->tg_pt_gp_valid_id)\r\ncontinue;\r\nsupported = tg_pt_gp->tg_pt_gp_alua_supported_states;\r\nif (activate)\r\nsupported |= ALUA_LBD_SUP;\r\nelse\r\nsupported &= ~ALUA_LBD_SUP;\r\ntg_pt_gp->tg_pt_gp_alua_supported_states = supported;\r\n}\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\ncore_alua_free_lba_map(&old_lba_map_list);\r\n}\r\nstruct t10_alua_lu_gp *\r\ncore_alua_allocate_lu_gp(const char *name, int def_group)\r\n{\r\nstruct t10_alua_lu_gp *lu_gp;\r\nlu_gp = kmem_cache_zalloc(t10_alua_lu_gp_cache, GFP_KERNEL);\r\nif (!lu_gp) {\r\npr_err("Unable to allocate struct t10_alua_lu_gp\n");\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nINIT_LIST_HEAD(&lu_gp->lu_gp_node);\r\nINIT_LIST_HEAD(&lu_gp->lu_gp_mem_list);\r\nspin_lock_init(&lu_gp->lu_gp_lock);\r\natomic_set(&lu_gp->lu_gp_ref_cnt, 0);\r\nif (def_group) {\r\nlu_gp->lu_gp_id = alua_lu_gps_counter++;\r\nlu_gp->lu_gp_valid_id = 1;\r\nalua_lu_gps_count++;\r\n}\r\nreturn lu_gp;\r\n}\r\nint core_alua_set_lu_gp_id(struct t10_alua_lu_gp *lu_gp, u16 lu_gp_id)\r\n{\r\nstruct t10_alua_lu_gp *lu_gp_tmp;\r\nu16 lu_gp_id_tmp;\r\nif (lu_gp->lu_gp_valid_id) {\r\npr_warn("ALUA LU Group already has a valid ID,"\r\n" ignoring request\n");\r\nreturn -EINVAL;\r\n}\r\nspin_lock(&lu_gps_lock);\r\nif (alua_lu_gps_count == 0x0000ffff) {\r\npr_err("Maximum ALUA alua_lu_gps_count:"\r\n" 0x0000ffff reached\n");\r\nspin_unlock(&lu_gps_lock);\r\nkmem_cache_free(t10_alua_lu_gp_cache, lu_gp);\r\nreturn -ENOSPC;\r\n}\r\nagain:\r\nlu_gp_id_tmp = (lu_gp_id != 0) ? lu_gp_id :\r\nalua_lu_gps_counter++;\r\nlist_for_each_entry(lu_gp_tmp, &lu_gps_list, lu_gp_node) {\r\nif (lu_gp_tmp->lu_gp_id == lu_gp_id_tmp) {\r\nif (!lu_gp_id)\r\ngoto again;\r\npr_warn("ALUA Logical Unit Group ID: %hu"\r\n" already exists, ignoring request\n",\r\nlu_gp_id);\r\nspin_unlock(&lu_gps_lock);\r\nreturn -EINVAL;\r\n}\r\n}\r\nlu_gp->lu_gp_id = lu_gp_id_tmp;\r\nlu_gp->lu_gp_valid_id = 1;\r\nlist_add_tail(&lu_gp->lu_gp_node, &lu_gps_list);\r\nalua_lu_gps_count++;\r\nspin_unlock(&lu_gps_lock);\r\nreturn 0;\r\n}\r\nstatic struct t10_alua_lu_gp_member *\r\ncore_alua_allocate_lu_gp_mem(struct se_device *dev)\r\n{\r\nstruct t10_alua_lu_gp_member *lu_gp_mem;\r\nlu_gp_mem = kmem_cache_zalloc(t10_alua_lu_gp_mem_cache, GFP_KERNEL);\r\nif (!lu_gp_mem) {\r\npr_err("Unable to allocate struct t10_alua_lu_gp_member\n");\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nINIT_LIST_HEAD(&lu_gp_mem->lu_gp_mem_list);\r\nspin_lock_init(&lu_gp_mem->lu_gp_mem_lock);\r\natomic_set(&lu_gp_mem->lu_gp_mem_ref_cnt, 0);\r\nlu_gp_mem->lu_gp_mem_dev = dev;\r\ndev->dev_alua_lu_gp_mem = lu_gp_mem;\r\nreturn lu_gp_mem;\r\n}\r\nvoid core_alua_free_lu_gp(struct t10_alua_lu_gp *lu_gp)\r\n{\r\nstruct t10_alua_lu_gp_member *lu_gp_mem, *lu_gp_mem_tmp;\r\nspin_lock(&lu_gps_lock);\r\nlist_del(&lu_gp->lu_gp_node);\r\nalua_lu_gps_count--;\r\nspin_unlock(&lu_gps_lock);\r\nwhile (atomic_read(&lu_gp->lu_gp_ref_cnt))\r\ncpu_relax();\r\nspin_lock(&lu_gp->lu_gp_lock);\r\nlist_for_each_entry_safe(lu_gp_mem, lu_gp_mem_tmp,\r\n&lu_gp->lu_gp_mem_list, lu_gp_mem_list) {\r\nif (lu_gp_mem->lu_gp_assoc) {\r\nlist_del(&lu_gp_mem->lu_gp_mem_list);\r\nlu_gp->lu_gp_members--;\r\nlu_gp_mem->lu_gp_assoc = 0;\r\n}\r\nspin_unlock(&lu_gp->lu_gp_lock);\r\nspin_lock(&lu_gp_mem->lu_gp_mem_lock);\r\nif (lu_gp != default_lu_gp)\r\n__core_alua_attach_lu_gp_mem(lu_gp_mem,\r\ndefault_lu_gp);\r\nelse\r\nlu_gp_mem->lu_gp = NULL;\r\nspin_unlock(&lu_gp_mem->lu_gp_mem_lock);\r\nspin_lock(&lu_gp->lu_gp_lock);\r\n}\r\nspin_unlock(&lu_gp->lu_gp_lock);\r\nkmem_cache_free(t10_alua_lu_gp_cache, lu_gp);\r\n}\r\nvoid core_alua_free_lu_gp_mem(struct se_device *dev)\r\n{\r\nstruct t10_alua_lu_gp *lu_gp;\r\nstruct t10_alua_lu_gp_member *lu_gp_mem;\r\nlu_gp_mem = dev->dev_alua_lu_gp_mem;\r\nif (!lu_gp_mem)\r\nreturn;\r\nwhile (atomic_read(&lu_gp_mem->lu_gp_mem_ref_cnt))\r\ncpu_relax();\r\nspin_lock(&lu_gp_mem->lu_gp_mem_lock);\r\nlu_gp = lu_gp_mem->lu_gp;\r\nif (lu_gp) {\r\nspin_lock(&lu_gp->lu_gp_lock);\r\nif (lu_gp_mem->lu_gp_assoc) {\r\nlist_del(&lu_gp_mem->lu_gp_mem_list);\r\nlu_gp->lu_gp_members--;\r\nlu_gp_mem->lu_gp_assoc = 0;\r\n}\r\nspin_unlock(&lu_gp->lu_gp_lock);\r\nlu_gp_mem->lu_gp = NULL;\r\n}\r\nspin_unlock(&lu_gp_mem->lu_gp_mem_lock);\r\nkmem_cache_free(t10_alua_lu_gp_mem_cache, lu_gp_mem);\r\n}\r\nstruct t10_alua_lu_gp *core_alua_get_lu_gp_by_name(const char *name)\r\n{\r\nstruct t10_alua_lu_gp *lu_gp;\r\nstruct config_item *ci;\r\nspin_lock(&lu_gps_lock);\r\nlist_for_each_entry(lu_gp, &lu_gps_list, lu_gp_node) {\r\nif (!lu_gp->lu_gp_valid_id)\r\ncontinue;\r\nci = &lu_gp->lu_gp_group.cg_item;\r\nif (!strcmp(config_item_name(ci), name)) {\r\natomic_inc(&lu_gp->lu_gp_ref_cnt);\r\nspin_unlock(&lu_gps_lock);\r\nreturn lu_gp;\r\n}\r\n}\r\nspin_unlock(&lu_gps_lock);\r\nreturn NULL;\r\n}\r\nvoid core_alua_put_lu_gp_from_name(struct t10_alua_lu_gp *lu_gp)\r\n{\r\nspin_lock(&lu_gps_lock);\r\natomic_dec(&lu_gp->lu_gp_ref_cnt);\r\nspin_unlock(&lu_gps_lock);\r\n}\r\nvoid __core_alua_attach_lu_gp_mem(\r\nstruct t10_alua_lu_gp_member *lu_gp_mem,\r\nstruct t10_alua_lu_gp *lu_gp)\r\n{\r\nspin_lock(&lu_gp->lu_gp_lock);\r\nlu_gp_mem->lu_gp = lu_gp;\r\nlu_gp_mem->lu_gp_assoc = 1;\r\nlist_add_tail(&lu_gp_mem->lu_gp_mem_list, &lu_gp->lu_gp_mem_list);\r\nlu_gp->lu_gp_members++;\r\nspin_unlock(&lu_gp->lu_gp_lock);\r\n}\r\nvoid __core_alua_drop_lu_gp_mem(\r\nstruct t10_alua_lu_gp_member *lu_gp_mem,\r\nstruct t10_alua_lu_gp *lu_gp)\r\n{\r\nspin_lock(&lu_gp->lu_gp_lock);\r\nlist_del(&lu_gp_mem->lu_gp_mem_list);\r\nlu_gp_mem->lu_gp = NULL;\r\nlu_gp_mem->lu_gp_assoc = 0;\r\nlu_gp->lu_gp_members--;\r\nspin_unlock(&lu_gp->lu_gp_lock);\r\n}\r\nstruct t10_alua_tg_pt_gp *core_alua_allocate_tg_pt_gp(struct se_device *dev,\r\nconst char *name, int def_group)\r\n{\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\ntg_pt_gp = kmem_cache_zalloc(t10_alua_tg_pt_gp_cache, GFP_KERNEL);\r\nif (!tg_pt_gp) {\r\npr_err("Unable to allocate struct t10_alua_tg_pt_gp\n");\r\nreturn NULL;\r\n}\r\nINIT_LIST_HEAD(&tg_pt_gp->tg_pt_gp_list);\r\nINIT_LIST_HEAD(&tg_pt_gp->tg_pt_gp_lun_list);\r\nmutex_init(&tg_pt_gp->tg_pt_gp_md_mutex);\r\nspin_lock_init(&tg_pt_gp->tg_pt_gp_lock);\r\natomic_set(&tg_pt_gp->tg_pt_gp_ref_cnt, 0);\r\nINIT_DELAYED_WORK(&tg_pt_gp->tg_pt_gp_transition_work,\r\ncore_alua_do_transition_tg_pt_work);\r\ntg_pt_gp->tg_pt_gp_dev = dev;\r\natomic_set(&tg_pt_gp->tg_pt_gp_alua_access_state,\r\nALUA_ACCESS_STATE_ACTIVE_OPTIMIZED);\r\ntg_pt_gp->tg_pt_gp_alua_access_type =\r\nTPGS_EXPLICIT_ALUA | TPGS_IMPLICIT_ALUA;\r\ntg_pt_gp->tg_pt_gp_nonop_delay_msecs = ALUA_DEFAULT_NONOP_DELAY_MSECS;\r\ntg_pt_gp->tg_pt_gp_trans_delay_msecs = ALUA_DEFAULT_TRANS_DELAY_MSECS;\r\ntg_pt_gp->tg_pt_gp_implicit_trans_secs = ALUA_DEFAULT_IMPLICIT_TRANS_SECS;\r\ntg_pt_gp->tg_pt_gp_alua_supported_states =\r\nALUA_T_SUP | ALUA_O_SUP |\r\nALUA_U_SUP | ALUA_S_SUP | ALUA_AN_SUP | ALUA_AO_SUP;\r\nif (def_group) {\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\ntg_pt_gp->tg_pt_gp_id =\r\ndev->t10_alua.alua_tg_pt_gps_counter++;\r\ntg_pt_gp->tg_pt_gp_valid_id = 1;\r\ndev->t10_alua.alua_tg_pt_gps_count++;\r\nlist_add_tail(&tg_pt_gp->tg_pt_gp_list,\r\n&dev->t10_alua.tg_pt_gps_list);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\n}\r\nreturn tg_pt_gp;\r\n}\r\nint core_alua_set_tg_pt_gp_id(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nu16 tg_pt_gp_id)\r\n{\r\nstruct se_device *dev = tg_pt_gp->tg_pt_gp_dev;\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp_tmp;\r\nu16 tg_pt_gp_id_tmp;\r\nif (tg_pt_gp->tg_pt_gp_valid_id) {\r\npr_warn("ALUA TG PT Group already has a valid ID,"\r\n" ignoring request\n");\r\nreturn -EINVAL;\r\n}\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\nif (dev->t10_alua.alua_tg_pt_gps_count == 0x0000ffff) {\r\npr_err("Maximum ALUA alua_tg_pt_gps_count:"\r\n" 0x0000ffff reached\n");\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nkmem_cache_free(t10_alua_tg_pt_gp_cache, tg_pt_gp);\r\nreturn -ENOSPC;\r\n}\r\nagain:\r\ntg_pt_gp_id_tmp = (tg_pt_gp_id != 0) ? tg_pt_gp_id :\r\ndev->t10_alua.alua_tg_pt_gps_counter++;\r\nlist_for_each_entry(tg_pt_gp_tmp, &dev->t10_alua.tg_pt_gps_list,\r\ntg_pt_gp_list) {\r\nif (tg_pt_gp_tmp->tg_pt_gp_id == tg_pt_gp_id_tmp) {\r\nif (!tg_pt_gp_id)\r\ngoto again;\r\npr_err("ALUA Target Port Group ID: %hu already"\r\n" exists, ignoring request\n", tg_pt_gp_id);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nreturn -EINVAL;\r\n}\r\n}\r\ntg_pt_gp->tg_pt_gp_id = tg_pt_gp_id_tmp;\r\ntg_pt_gp->tg_pt_gp_valid_id = 1;\r\nlist_add_tail(&tg_pt_gp->tg_pt_gp_list,\r\n&dev->t10_alua.tg_pt_gps_list);\r\ndev->t10_alua.alua_tg_pt_gps_count++;\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nreturn 0;\r\n}\r\nvoid core_alua_free_tg_pt_gp(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nstruct se_device *dev = tg_pt_gp->tg_pt_gp_dev;\r\nstruct se_lun *lun, *next;\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\nlist_del(&tg_pt_gp->tg_pt_gp_list);\r\ndev->t10_alua.alua_tg_pt_gps_counter--;\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nflush_delayed_work(&tg_pt_gp->tg_pt_gp_transition_work);\r\nwhile (atomic_read(&tg_pt_gp->tg_pt_gp_ref_cnt))\r\ncpu_relax();\r\nspin_lock(&tg_pt_gp->tg_pt_gp_lock);\r\nlist_for_each_entry_safe(lun, next,\r\n&tg_pt_gp->tg_pt_gp_lun_list, lun_tg_pt_gp_link) {\r\nlist_del_init(&lun->lun_tg_pt_gp_link);\r\ntg_pt_gp->tg_pt_gp_members--;\r\nspin_unlock(&tg_pt_gp->tg_pt_gp_lock);\r\nspin_lock(&lun->lun_tg_pt_gp_lock);\r\nif (tg_pt_gp != dev->t10_alua.default_tg_pt_gp) {\r\n__target_attach_tg_pt_gp(lun,\r\ndev->t10_alua.default_tg_pt_gp);\r\n} else\r\nlun->lun_tg_pt_gp = NULL;\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\nspin_lock(&tg_pt_gp->tg_pt_gp_lock);\r\n}\r\nspin_unlock(&tg_pt_gp->tg_pt_gp_lock);\r\nkmem_cache_free(t10_alua_tg_pt_gp_cache, tg_pt_gp);\r\n}\r\nstatic struct t10_alua_tg_pt_gp *core_alua_get_tg_pt_gp_by_name(\r\nstruct se_device *dev, const char *name)\r\n{\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nstruct config_item *ci;\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\nlist_for_each_entry(tg_pt_gp, &dev->t10_alua.tg_pt_gps_list,\r\ntg_pt_gp_list) {\r\nif (!tg_pt_gp->tg_pt_gp_valid_id)\r\ncontinue;\r\nci = &tg_pt_gp->tg_pt_gp_group.cg_item;\r\nif (!strcmp(config_item_name(ci), name)) {\r\natomic_inc(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nreturn tg_pt_gp;\r\n}\r\n}\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\nreturn NULL;\r\n}\r\nstatic void core_alua_put_tg_pt_gp_from_name(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nstruct se_device *dev = tg_pt_gp->tg_pt_gp_dev;\r\nspin_lock(&dev->t10_alua.tg_pt_gps_lock);\r\natomic_dec(&tg_pt_gp->tg_pt_gp_ref_cnt);\r\nspin_unlock(&dev->t10_alua.tg_pt_gps_lock);\r\n}\r\nstatic void __target_attach_tg_pt_gp(struct se_lun *lun,\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nstruct se_dev_entry *se_deve;\r\nassert_spin_locked(&lun->lun_tg_pt_gp_lock);\r\nspin_lock(&tg_pt_gp->tg_pt_gp_lock);\r\nlun->lun_tg_pt_gp = tg_pt_gp;\r\nlist_add_tail(&lun->lun_tg_pt_gp_link, &tg_pt_gp->tg_pt_gp_lun_list);\r\ntg_pt_gp->tg_pt_gp_members++;\r\nspin_lock(&lun->lun_deve_lock);\r\nlist_for_each_entry(se_deve, &lun->lun_deve_list, lun_link)\r\ncore_scsi3_ua_allocate(se_deve, 0x3f,\r\nASCQ_3FH_INQUIRY_DATA_HAS_CHANGED);\r\nspin_unlock(&lun->lun_deve_lock);\r\nspin_unlock(&tg_pt_gp->tg_pt_gp_lock);\r\n}\r\nvoid target_attach_tg_pt_gp(struct se_lun *lun,\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nspin_lock(&lun->lun_tg_pt_gp_lock);\r\n__target_attach_tg_pt_gp(lun, tg_pt_gp);\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\n}\r\nstatic void __target_detach_tg_pt_gp(struct se_lun *lun,\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp)\r\n{\r\nassert_spin_locked(&lun->lun_tg_pt_gp_lock);\r\nspin_lock(&tg_pt_gp->tg_pt_gp_lock);\r\nlist_del_init(&lun->lun_tg_pt_gp_link);\r\ntg_pt_gp->tg_pt_gp_members--;\r\nspin_unlock(&tg_pt_gp->tg_pt_gp_lock);\r\nlun->lun_tg_pt_gp = NULL;\r\n}\r\nvoid target_detach_tg_pt_gp(struct se_lun *lun)\r\n{\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nspin_lock(&lun->lun_tg_pt_gp_lock);\r\ntg_pt_gp = lun->lun_tg_pt_gp;\r\nif (tg_pt_gp)\r\n__target_detach_tg_pt_gp(lun, tg_pt_gp);\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\n}\r\nssize_t core_alua_show_tg_pt_gp_info(struct se_lun *lun, char *page)\r\n{\r\nstruct config_item *tg_pt_ci;\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp;\r\nssize_t len = 0;\r\nspin_lock(&lun->lun_tg_pt_gp_lock);\r\ntg_pt_gp = lun->lun_tg_pt_gp;\r\nif (tg_pt_gp) {\r\ntg_pt_ci = &tg_pt_gp->tg_pt_gp_group.cg_item;\r\nlen += sprintf(page, "TG Port Alias: %s\nTG Port Group ID:"\r\n" %hu\nTG Port Primary Access State: %s\nTG Port "\r\n"Primary Access Status: %s\nTG Port Secondary Access"\r\n" State: %s\nTG Port Secondary Access Status: %s\n",\r\nconfig_item_name(tg_pt_ci), tg_pt_gp->tg_pt_gp_id,\r\ncore_alua_dump_state(atomic_read(\r\n&tg_pt_gp->tg_pt_gp_alua_access_state)),\r\ncore_alua_dump_status(\r\ntg_pt_gp->tg_pt_gp_alua_access_status),\r\natomic_read(&lun->lun_tg_pt_secondary_offline) ?\r\n"Offline" : "None",\r\ncore_alua_dump_status(lun->lun_tg_pt_secondary_stat));\r\n}\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\nreturn len;\r\n}\r\nssize_t core_alua_store_tg_pt_gp_info(\r\nstruct se_lun *lun,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nstruct se_portal_group *tpg = lun->lun_tpg;\r\nstruct se_device *dev = rcu_dereference_raw(lun->lun_se_dev);\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp = NULL, *tg_pt_gp_new = NULL;\r\nunsigned char buf[TG_PT_GROUP_NAME_BUF];\r\nint move = 0;\r\nif (dev->transport->transport_flags & TRANSPORT_FLAG_PASSTHROUGH ||\r\n(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))\r\nreturn -ENODEV;\r\nif (count > TG_PT_GROUP_NAME_BUF) {\r\npr_err("ALUA Target Port Group alias too large!\n");\r\nreturn -EINVAL;\r\n}\r\nmemset(buf, 0, TG_PT_GROUP_NAME_BUF);\r\nmemcpy(buf, page, count);\r\nif (strcmp(strstrip(buf), "NULL")) {\r\ntg_pt_gp_new = core_alua_get_tg_pt_gp_by_name(dev,\r\nstrstrip(buf));\r\nif (!tg_pt_gp_new)\r\nreturn -ENODEV;\r\n}\r\nspin_lock(&lun->lun_tg_pt_gp_lock);\r\ntg_pt_gp = lun->lun_tg_pt_gp;\r\nif (tg_pt_gp) {\r\nif (!tg_pt_gp_new) {\r\npr_debug("Target_Core_ConfigFS: Moving"\r\n" %s/tpgt_%hu/%s from ALUA Target Port Group:"\r\n" alua/%s, ID: %hu back to"\r\n" default_tg_pt_gp\n",\r\ntpg->se_tpg_tfo->tpg_get_wwn(tpg),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg),\r\nconfig_item_name(&lun->lun_group.cg_item),\r\nconfig_item_name(\r\n&tg_pt_gp->tg_pt_gp_group.cg_item),\r\ntg_pt_gp->tg_pt_gp_id);\r\n__target_detach_tg_pt_gp(lun, tg_pt_gp);\r\n__target_attach_tg_pt_gp(lun,\r\ndev->t10_alua.default_tg_pt_gp);\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\nreturn count;\r\n}\r\n__target_detach_tg_pt_gp(lun, tg_pt_gp);\r\nmove = 1;\r\n}\r\n__target_attach_tg_pt_gp(lun, tg_pt_gp_new);\r\nspin_unlock(&lun->lun_tg_pt_gp_lock);\r\npr_debug("Target_Core_ConfigFS: %s %s/tpgt_%hu/%s to ALUA"\r\n" Target Port Group: alua/%s, ID: %hu\n", (move) ?\r\n"Moving" : "Adding", tpg->se_tpg_tfo->tpg_get_wwn(tpg),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg),\r\nconfig_item_name(&lun->lun_group.cg_item),\r\nconfig_item_name(&tg_pt_gp_new->tg_pt_gp_group.cg_item),\r\ntg_pt_gp_new->tg_pt_gp_id);\r\ncore_alua_put_tg_pt_gp_from_name(tg_pt_gp_new);\r\nreturn count;\r\n}\r\nssize_t core_alua_show_access_type(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nchar *page)\r\n{\r\nif ((tg_pt_gp->tg_pt_gp_alua_access_type & TPGS_EXPLICIT_ALUA) &&\r\n(tg_pt_gp->tg_pt_gp_alua_access_type & TPGS_IMPLICIT_ALUA))\r\nreturn sprintf(page, "Implicit and Explicit\n");\r\nelse if (tg_pt_gp->tg_pt_gp_alua_access_type & TPGS_IMPLICIT_ALUA)\r\nreturn sprintf(page, "Implicit\n");\r\nelse if (tg_pt_gp->tg_pt_gp_alua_access_type & TPGS_EXPLICIT_ALUA)\r\nreturn sprintf(page, "Explicit\n");\r\nelse\r\nreturn sprintf(page, "None\n");\r\n}\r\nssize_t core_alua_store_access_type(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nunsigned long tmp;\r\nint ret;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract alua_access_type\n");\r\nreturn ret;\r\n}\r\nif ((tmp != 0) && (tmp != 1) && (tmp != 2) && (tmp != 3)) {\r\npr_err("Illegal value for alua_access_type:"\r\n" %lu\n", tmp);\r\nreturn -EINVAL;\r\n}\r\nif (tmp == 3)\r\ntg_pt_gp->tg_pt_gp_alua_access_type =\r\nTPGS_IMPLICIT_ALUA | TPGS_EXPLICIT_ALUA;\r\nelse if (tmp == 2)\r\ntg_pt_gp->tg_pt_gp_alua_access_type = TPGS_EXPLICIT_ALUA;\r\nelse if (tmp == 1)\r\ntg_pt_gp->tg_pt_gp_alua_access_type = TPGS_IMPLICIT_ALUA;\r\nelse\r\ntg_pt_gp->tg_pt_gp_alua_access_type = 0;\r\nreturn count;\r\n}\r\nssize_t core_alua_show_nonop_delay_msecs(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nchar *page)\r\n{\r\nreturn sprintf(page, "%d\n", tg_pt_gp->tg_pt_gp_nonop_delay_msecs);\r\n}\r\nssize_t core_alua_store_nonop_delay_msecs(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nunsigned long tmp;\r\nint ret;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract nonop_delay_msecs\n");\r\nreturn ret;\r\n}\r\nif (tmp > ALUA_MAX_NONOP_DELAY_MSECS) {\r\npr_err("Passed nonop_delay_msecs: %lu, exceeds"\r\n" ALUA_MAX_NONOP_DELAY_MSECS: %d\n", tmp,\r\nALUA_MAX_NONOP_DELAY_MSECS);\r\nreturn -EINVAL;\r\n}\r\ntg_pt_gp->tg_pt_gp_nonop_delay_msecs = (int)tmp;\r\nreturn count;\r\n}\r\nssize_t core_alua_show_trans_delay_msecs(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nchar *page)\r\n{\r\nreturn sprintf(page, "%d\n", tg_pt_gp->tg_pt_gp_trans_delay_msecs);\r\n}\r\nssize_t core_alua_store_trans_delay_msecs(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nunsigned long tmp;\r\nint ret;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract trans_delay_msecs\n");\r\nreturn ret;\r\n}\r\nif (tmp > ALUA_MAX_TRANS_DELAY_MSECS) {\r\npr_err("Passed trans_delay_msecs: %lu, exceeds"\r\n" ALUA_MAX_TRANS_DELAY_MSECS: %d\n", tmp,\r\nALUA_MAX_TRANS_DELAY_MSECS);\r\nreturn -EINVAL;\r\n}\r\ntg_pt_gp->tg_pt_gp_trans_delay_msecs = (int)tmp;\r\nreturn count;\r\n}\r\nssize_t core_alua_show_implicit_trans_secs(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nchar *page)\r\n{\r\nreturn sprintf(page, "%d\n", tg_pt_gp->tg_pt_gp_implicit_trans_secs);\r\n}\r\nssize_t core_alua_store_implicit_trans_secs(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nunsigned long tmp;\r\nint ret;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract implicit_trans_secs\n");\r\nreturn ret;\r\n}\r\nif (tmp > ALUA_MAX_IMPLICIT_TRANS_SECS) {\r\npr_err("Passed implicit_trans_secs: %lu, exceeds"\r\n" ALUA_MAX_IMPLICIT_TRANS_SECS: %d\n", tmp,\r\nALUA_MAX_IMPLICIT_TRANS_SECS);\r\nreturn -EINVAL;\r\n}\r\ntg_pt_gp->tg_pt_gp_implicit_trans_secs = (int)tmp;\r\nreturn count;\r\n}\r\nssize_t core_alua_show_preferred_bit(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nchar *page)\r\n{\r\nreturn sprintf(page, "%d\n", tg_pt_gp->tg_pt_gp_pref);\r\n}\r\nssize_t core_alua_store_preferred_bit(\r\nstruct t10_alua_tg_pt_gp *tg_pt_gp,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nunsigned long tmp;\r\nint ret;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract preferred ALUA value\n");\r\nreturn ret;\r\n}\r\nif ((tmp != 0) && (tmp != 1)) {\r\npr_err("Illegal value for preferred ALUA: %lu\n", tmp);\r\nreturn -EINVAL;\r\n}\r\ntg_pt_gp->tg_pt_gp_pref = (int)tmp;\r\nreturn count;\r\n}\r\nssize_t core_alua_show_offline_bit(struct se_lun *lun, char *page)\r\n{\r\nreturn sprintf(page, "%d\n",\r\natomic_read(&lun->lun_tg_pt_secondary_offline));\r\n}\r\nssize_t core_alua_store_offline_bit(\r\nstruct se_lun *lun,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nstruct se_device *dev = rcu_dereference_raw(lun->lun_se_dev);\r\nunsigned long tmp;\r\nint ret;\r\nif (dev->transport->transport_flags & TRANSPORT_FLAG_PASSTHROUGH ||\r\n(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))\r\nreturn -ENODEV;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract alua_tg_pt_offline value\n");\r\nreturn ret;\r\n}\r\nif ((tmp != 0) && (tmp != 1)) {\r\npr_err("Illegal value for alua_tg_pt_offline: %lu\n",\r\ntmp);\r\nreturn -EINVAL;\r\n}\r\nret = core_alua_set_tg_pt_secondary_state(lun, 0, (int)tmp);\r\nif (ret < 0)\r\nreturn -EINVAL;\r\nreturn count;\r\n}\r\nssize_t core_alua_show_secondary_status(\r\nstruct se_lun *lun,\r\nchar *page)\r\n{\r\nreturn sprintf(page, "%d\n", lun->lun_tg_pt_secondary_stat);\r\n}\r\nssize_t core_alua_store_secondary_status(\r\nstruct se_lun *lun,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nunsigned long tmp;\r\nint ret;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract alua_tg_pt_status\n");\r\nreturn ret;\r\n}\r\nif ((tmp != ALUA_STATUS_NONE) &&\r\n(tmp != ALUA_STATUS_ALTERED_BY_EXPLICIT_STPG) &&\r\n(tmp != ALUA_STATUS_ALTERED_BY_IMPLICIT_ALUA)) {\r\npr_err("Illegal value for alua_tg_pt_status: %lu\n",\r\ntmp);\r\nreturn -EINVAL;\r\n}\r\nlun->lun_tg_pt_secondary_stat = (int)tmp;\r\nreturn count;\r\n}\r\nssize_t core_alua_show_secondary_write_metadata(\r\nstruct se_lun *lun,\r\nchar *page)\r\n{\r\nreturn sprintf(page, "%d\n", lun->lun_tg_pt_secondary_write_md);\r\n}\r\nssize_t core_alua_store_secondary_write_metadata(\r\nstruct se_lun *lun,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nunsigned long tmp;\r\nint ret;\r\nret = kstrtoul(page, 0, &tmp);\r\nif (ret < 0) {\r\npr_err("Unable to extract alua_tg_pt_write_md\n");\r\nreturn ret;\r\n}\r\nif ((tmp != 0) && (tmp != 1)) {\r\npr_err("Illegal value for alua_tg_pt_write_md:"\r\n" %lu\n", tmp);\r\nreturn -EINVAL;\r\n}\r\nlun->lun_tg_pt_secondary_write_md = (int)tmp;\r\nreturn count;\r\n}\r\nint core_setup_alua(struct se_device *dev)\r\n{\r\nif (!(dev->transport->transport_flags & TRANSPORT_FLAG_PASSTHROUGH) &&\r\n!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE)) {\r\nstruct t10_alua_lu_gp_member *lu_gp_mem;\r\nlu_gp_mem = core_alua_allocate_lu_gp_mem(dev);\r\nif (IS_ERR(lu_gp_mem))\r\nreturn PTR_ERR(lu_gp_mem);\r\nspin_lock(&lu_gp_mem->lu_gp_mem_lock);\r\n__core_alua_attach_lu_gp_mem(lu_gp_mem,\r\ndefault_lu_gp);\r\nspin_unlock(&lu_gp_mem->lu_gp_mem_lock);\r\npr_debug("%s: Adding to default ALUA LU Group:"\r\n" core/alua/lu_gps/default_lu_gp\n",\r\ndev->transport->name);\r\n}\r\nreturn 0;\r\n}
