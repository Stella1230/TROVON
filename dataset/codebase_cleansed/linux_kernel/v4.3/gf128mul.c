static void gf128mul_x_lle(be128 *r, const be128 *x)\r\n{\r\nu64 a = be64_to_cpu(x->a);\r\nu64 b = be64_to_cpu(x->b);\r\nu64 _tt = gf128mul_table_lle[(b << 7) & 0xff];\r\nr->b = cpu_to_be64((b >> 1) | (a << 63));\r\nr->a = cpu_to_be64((a >> 1) ^ (_tt << 48));\r\n}\r\nstatic void gf128mul_x_bbe(be128 *r, const be128 *x)\r\n{\r\nu64 a = be64_to_cpu(x->a);\r\nu64 b = be64_to_cpu(x->b);\r\nu64 _tt = gf128mul_table_bbe[a >> 63];\r\nr->a = cpu_to_be64((a << 1) | (b >> 63));\r\nr->b = cpu_to_be64((b << 1) ^ _tt);\r\n}\r\nvoid gf128mul_x_ble(be128 *r, const be128 *x)\r\n{\r\nu64 a = le64_to_cpu(x->a);\r\nu64 b = le64_to_cpu(x->b);\r\nu64 _tt = gf128mul_table_bbe[b >> 63];\r\nr->a = cpu_to_le64((a << 1) ^ _tt);\r\nr->b = cpu_to_le64((b << 1) | (a >> 63));\r\n}\r\nstatic void gf128mul_x8_lle(be128 *x)\r\n{\r\nu64 a = be64_to_cpu(x->a);\r\nu64 b = be64_to_cpu(x->b);\r\nu64 _tt = gf128mul_table_lle[b & 0xff];\r\nx->b = cpu_to_be64((b >> 8) | (a << 56));\r\nx->a = cpu_to_be64((a >> 8) ^ (_tt << 48));\r\n}\r\nstatic void gf128mul_x8_bbe(be128 *x)\r\n{\r\nu64 a = be64_to_cpu(x->a);\r\nu64 b = be64_to_cpu(x->b);\r\nu64 _tt = gf128mul_table_bbe[a >> 56];\r\nx->a = cpu_to_be64((a << 8) | (b >> 56));\r\nx->b = cpu_to_be64((b << 8) ^ _tt);\r\n}\r\nvoid gf128mul_lle(be128 *r, const be128 *b)\r\n{\r\nbe128 p[8];\r\nint i;\r\np[0] = *r;\r\nfor (i = 0; i < 7; ++i)\r\ngf128mul_x_lle(&p[i + 1], &p[i]);\r\nmemset(r, 0, sizeof(*r));\r\nfor (i = 0;;) {\r\nu8 ch = ((u8 *)b)[15 - i];\r\nif (ch & 0x80)\r\nbe128_xor(r, r, &p[0]);\r\nif (ch & 0x40)\r\nbe128_xor(r, r, &p[1]);\r\nif (ch & 0x20)\r\nbe128_xor(r, r, &p[2]);\r\nif (ch & 0x10)\r\nbe128_xor(r, r, &p[3]);\r\nif (ch & 0x08)\r\nbe128_xor(r, r, &p[4]);\r\nif (ch & 0x04)\r\nbe128_xor(r, r, &p[5]);\r\nif (ch & 0x02)\r\nbe128_xor(r, r, &p[6]);\r\nif (ch & 0x01)\r\nbe128_xor(r, r, &p[7]);\r\nif (++i >= 16)\r\nbreak;\r\ngf128mul_x8_lle(r);\r\n}\r\n}\r\nvoid gf128mul_bbe(be128 *r, const be128 *b)\r\n{\r\nbe128 p[8];\r\nint i;\r\np[0] = *r;\r\nfor (i = 0; i < 7; ++i)\r\ngf128mul_x_bbe(&p[i + 1], &p[i]);\r\nmemset(r, 0, sizeof(*r));\r\nfor (i = 0;;) {\r\nu8 ch = ((u8 *)b)[i];\r\nif (ch & 0x80)\r\nbe128_xor(r, r, &p[7]);\r\nif (ch & 0x40)\r\nbe128_xor(r, r, &p[6]);\r\nif (ch & 0x20)\r\nbe128_xor(r, r, &p[5]);\r\nif (ch & 0x10)\r\nbe128_xor(r, r, &p[4]);\r\nif (ch & 0x08)\r\nbe128_xor(r, r, &p[3]);\r\nif (ch & 0x04)\r\nbe128_xor(r, r, &p[2]);\r\nif (ch & 0x02)\r\nbe128_xor(r, r, &p[1]);\r\nif (ch & 0x01)\r\nbe128_xor(r, r, &p[0]);\r\nif (++i >= 16)\r\nbreak;\r\ngf128mul_x8_bbe(r);\r\n}\r\n}\r\nstruct gf128mul_64k *gf128mul_init_64k_lle(const be128 *g)\r\n{\r\nstruct gf128mul_64k *t;\r\nint i, j, k;\r\nt = kzalloc(sizeof(*t), GFP_KERNEL);\r\nif (!t)\r\ngoto out;\r\nfor (i = 0; i < 16; i++) {\r\nt->t[i] = kzalloc(sizeof(*t->t[i]), GFP_KERNEL);\r\nif (!t->t[i]) {\r\ngf128mul_free_64k(t);\r\nt = NULL;\r\ngoto out;\r\n}\r\n}\r\nt->t[0]->t[128] = *g;\r\nfor (j = 64; j > 0; j >>= 1)\r\ngf128mul_x_lle(&t->t[0]->t[j], &t->t[0]->t[j + j]);\r\nfor (i = 0;;) {\r\nfor (j = 2; j < 256; j += j)\r\nfor (k = 1; k < j; ++k)\r\nbe128_xor(&t->t[i]->t[j + k],\r\n&t->t[i]->t[j], &t->t[i]->t[k]);\r\nif (++i >= 16)\r\nbreak;\r\nfor (j = 128; j > 0; j >>= 1) {\r\nt->t[i]->t[j] = t->t[i - 1]->t[j];\r\ngf128mul_x8_lle(&t->t[i]->t[j]);\r\n}\r\n}\r\nout:\r\nreturn t;\r\n}\r\nstruct gf128mul_64k *gf128mul_init_64k_bbe(const be128 *g)\r\n{\r\nstruct gf128mul_64k *t;\r\nint i, j, k;\r\nt = kzalloc(sizeof(*t), GFP_KERNEL);\r\nif (!t)\r\ngoto out;\r\nfor (i = 0; i < 16; i++) {\r\nt->t[i] = kzalloc(sizeof(*t->t[i]), GFP_KERNEL);\r\nif (!t->t[i]) {\r\ngf128mul_free_64k(t);\r\nt = NULL;\r\ngoto out;\r\n}\r\n}\r\nt->t[0]->t[1] = *g;\r\nfor (j = 1; j <= 64; j <<= 1)\r\ngf128mul_x_bbe(&t->t[0]->t[j + j], &t->t[0]->t[j]);\r\nfor (i = 0;;) {\r\nfor (j = 2; j < 256; j += j)\r\nfor (k = 1; k < j; ++k)\r\nbe128_xor(&t->t[i]->t[j + k],\r\n&t->t[i]->t[j], &t->t[i]->t[k]);\r\nif (++i >= 16)\r\nbreak;\r\nfor (j = 128; j > 0; j >>= 1) {\r\nt->t[i]->t[j] = t->t[i - 1]->t[j];\r\ngf128mul_x8_bbe(&t->t[i]->t[j]);\r\n}\r\n}\r\nout:\r\nreturn t;\r\n}\r\nvoid gf128mul_free_64k(struct gf128mul_64k *t)\r\n{\r\nint i;\r\nfor (i = 0; i < 16; i++)\r\nkfree(t->t[i]);\r\nkfree(t);\r\n}\r\nvoid gf128mul_64k_lle(be128 *a, struct gf128mul_64k *t)\r\n{\r\nu8 *ap = (u8 *)a;\r\nbe128 r[1];\r\nint i;\r\n*r = t->t[0]->t[ap[0]];\r\nfor (i = 1; i < 16; ++i)\r\nbe128_xor(r, r, &t->t[i]->t[ap[i]]);\r\n*a = *r;\r\n}\r\nvoid gf128mul_64k_bbe(be128 *a, struct gf128mul_64k *t)\r\n{\r\nu8 *ap = (u8 *)a;\r\nbe128 r[1];\r\nint i;\r\n*r = t->t[0]->t[ap[15]];\r\nfor (i = 1; i < 16; ++i)\r\nbe128_xor(r, r, &t->t[i]->t[ap[15 - i]]);\r\n*a = *r;\r\n}\r\nstruct gf128mul_4k *gf128mul_init_4k_lle(const be128 *g)\r\n{\r\nstruct gf128mul_4k *t;\r\nint j, k;\r\nt = kzalloc(sizeof(*t), GFP_KERNEL);\r\nif (!t)\r\ngoto out;\r\nt->t[128] = *g;\r\nfor (j = 64; j > 0; j >>= 1)\r\ngf128mul_x_lle(&t->t[j], &t->t[j+j]);\r\nfor (j = 2; j < 256; j += j)\r\nfor (k = 1; k < j; ++k)\r\nbe128_xor(&t->t[j + k], &t->t[j], &t->t[k]);\r\nout:\r\nreturn t;\r\n}\r\nstruct gf128mul_4k *gf128mul_init_4k_bbe(const be128 *g)\r\n{\r\nstruct gf128mul_4k *t;\r\nint j, k;\r\nt = kzalloc(sizeof(*t), GFP_KERNEL);\r\nif (!t)\r\ngoto out;\r\nt->t[1] = *g;\r\nfor (j = 1; j <= 64; j <<= 1)\r\ngf128mul_x_bbe(&t->t[j + j], &t->t[j]);\r\nfor (j = 2; j < 256; j += j)\r\nfor (k = 1; k < j; ++k)\r\nbe128_xor(&t->t[j + k], &t->t[j], &t->t[k]);\r\nout:\r\nreturn t;\r\n}\r\nvoid gf128mul_4k_lle(be128 *a, struct gf128mul_4k *t)\r\n{\r\nu8 *ap = (u8 *)a;\r\nbe128 r[1];\r\nint i = 15;\r\n*r = t->t[ap[15]];\r\nwhile (i--) {\r\ngf128mul_x8_lle(r);\r\nbe128_xor(r, r, &t->t[ap[i]]);\r\n}\r\n*a = *r;\r\n}\r\nvoid gf128mul_4k_bbe(be128 *a, struct gf128mul_4k *t)\r\n{\r\nu8 *ap = (u8 *)a;\r\nbe128 r[1];\r\nint i = 0;\r\n*r = t->t[ap[0]];\r\nwhile (++i < 16) {\r\ngf128mul_x8_bbe(r);\r\nbe128_xor(r, r, &t->t[ap[i]]);\r\n}\r\n*a = *r;\r\n}
