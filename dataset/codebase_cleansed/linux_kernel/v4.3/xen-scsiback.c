static void scsiback_get(struct vscsibk_info *info)\r\n{\r\natomic_inc(&info->nr_unreplied_reqs);\r\n}\r\nstatic void scsiback_put(struct vscsibk_info *info)\r\n{\r\nif (atomic_dec_and_test(&info->nr_unreplied_reqs))\r\nwake_up(&info->waiting_to_free);\r\n}\r\nstatic void put_free_pages(struct page **page, int num)\r\n{\r\nunsigned long flags;\r\nint i = free_pages_num + num, n = num;\r\nif (num == 0)\r\nreturn;\r\nif (i > scsiback_max_buffer_pages) {\r\nn = min(num, i - scsiback_max_buffer_pages);\r\ngnttab_free_pages(n, page + num - n);\r\nn = num - n;\r\n}\r\nspin_lock_irqsave(&free_pages_lock, flags);\r\nfor (i = 0; i < n; i++)\r\nlist_add(&page[i]->lru, &scsiback_free_pages);\r\nfree_pages_num += n;\r\nspin_unlock_irqrestore(&free_pages_lock, flags);\r\n}\r\nstatic int get_free_page(struct page **page)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&free_pages_lock, flags);\r\nif (list_empty(&scsiback_free_pages)) {\r\nspin_unlock_irqrestore(&free_pages_lock, flags);\r\nreturn gnttab_alloc_pages(1, page);\r\n}\r\npage[0] = list_first_entry(&scsiback_free_pages, struct page, lru);\r\nlist_del(&page[0]->lru);\r\nfree_pages_num--;\r\nspin_unlock_irqrestore(&free_pages_lock, flags);\r\nreturn 0;\r\n}\r\nstatic unsigned long vaddr_page(struct page *page)\r\n{\r\nunsigned long pfn = page_to_pfn(page);\r\nreturn (unsigned long)pfn_to_kaddr(pfn);\r\n}\r\nstatic unsigned long vaddr(struct vscsibk_pend *req, int seg)\r\n{\r\nreturn vaddr_page(req->pages[seg]);\r\n}\r\nstatic void scsiback_print_status(char *sense_buffer, int errors,\r\nstruct vscsibk_pend *pending_req)\r\n{\r\nstruct scsiback_tpg *tpg = pending_req->v2p->tpg;\r\npr_err("[%s:%d] cmnd[0]=%02x -> st=%02x msg=%02x host=%02x drv=%02x\n",\r\ntpg->tport->tport_name, pending_req->v2p->lun,\r\npending_req->cmnd[0], status_byte(errors), msg_byte(errors),\r\nhost_byte(errors), driver_byte(errors));\r\n}\r\nstatic void scsiback_fast_flush_area(struct vscsibk_pend *req)\r\n{\r\nstruct gnttab_unmap_grant_ref unmap[VSCSI_GRANT_BATCH];\r\nstruct page *pages[VSCSI_GRANT_BATCH];\r\nunsigned int i, invcount = 0;\r\ngrant_handle_t handle;\r\nint err;\r\nkfree(req->sgl);\r\nreq->sgl = NULL;\r\nreq->n_sg = 0;\r\nif (!req->n_grants)\r\nreturn;\r\nfor (i = 0; i < req->n_grants; i++) {\r\nhandle = req->grant_handles[i];\r\nif (handle == SCSIBACK_INVALID_HANDLE)\r\ncontinue;\r\ngnttab_set_unmap_op(&unmap[invcount], vaddr(req, i),\r\nGNTMAP_host_map, handle);\r\nreq->grant_handles[i] = SCSIBACK_INVALID_HANDLE;\r\npages[invcount] = req->pages[i];\r\nput_page(pages[invcount]);\r\ninvcount++;\r\nif (invcount < VSCSI_GRANT_BATCH)\r\ncontinue;\r\nerr = gnttab_unmap_refs(unmap, NULL, pages, invcount);\r\nBUG_ON(err);\r\ninvcount = 0;\r\n}\r\nif (invcount) {\r\nerr = gnttab_unmap_refs(unmap, NULL, pages, invcount);\r\nBUG_ON(err);\r\n}\r\nput_free_pages(req->pages, req->n_grants);\r\nreq->n_grants = 0;\r\n}\r\nstatic void scsiback_free_translation_entry(struct kref *kref)\r\n{\r\nstruct v2p_entry *entry = container_of(kref, struct v2p_entry, kref);\r\nstruct scsiback_tpg *tpg = entry->tpg;\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\ntpg->tv_tpg_fe_count--;\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nkfree(entry);\r\n}\r\nstatic void scsiback_do_resp_with_sense(char *sense_buffer, int32_t result,\r\nuint32_t resid, struct vscsibk_pend *pending_req)\r\n{\r\nstruct vscsiif_response *ring_res;\r\nstruct vscsibk_info *info = pending_req->info;\r\nint notify;\r\nstruct scsi_sense_hdr sshdr;\r\nunsigned long flags;\r\nunsigned len;\r\nspin_lock_irqsave(&info->ring_lock, flags);\r\nring_res = RING_GET_RESPONSE(&info->ring, info->ring.rsp_prod_pvt);\r\ninfo->ring.rsp_prod_pvt++;\r\nring_res->rslt = result;\r\nring_res->rqid = pending_req->rqid;\r\nif (sense_buffer != NULL &&\r\nscsi_normalize_sense(sense_buffer, VSCSIIF_SENSE_BUFFERSIZE,\r\n&sshdr)) {\r\nlen = min_t(unsigned, 8 + sense_buffer[7],\r\nVSCSIIF_SENSE_BUFFERSIZE);\r\nmemcpy(ring_res->sense_buffer, sense_buffer, len);\r\nring_res->sense_len = len;\r\n} else {\r\nring_res->sense_len = 0;\r\n}\r\nring_res->residual_len = resid;\r\nRING_PUSH_RESPONSES_AND_CHECK_NOTIFY(&info->ring, notify);\r\nspin_unlock_irqrestore(&info->ring_lock, flags);\r\nif (notify)\r\nnotify_remote_via_irq(info->irq);\r\nif (pending_req->v2p)\r\nkref_put(&pending_req->v2p->kref,\r\nscsiback_free_translation_entry);\r\n}\r\nstatic void scsiback_cmd_done(struct vscsibk_pend *pending_req)\r\n{\r\nstruct vscsibk_info *info = pending_req->info;\r\nunsigned char *sense_buffer;\r\nunsigned int resid;\r\nint errors;\r\nsense_buffer = pending_req->sense_buffer;\r\nresid = pending_req->se_cmd.residual_count;\r\nerrors = pending_req->result;\r\nif (errors && log_print_stat)\r\nscsiback_print_status(sense_buffer, errors, pending_req);\r\nscsiback_fast_flush_area(pending_req);\r\nscsiback_do_resp_with_sense(sense_buffer, errors, resid, pending_req);\r\nscsiback_put(info);\r\n}\r\nstatic void scsiback_cmd_exec(struct vscsibk_pend *pending_req)\r\n{\r\nstruct se_cmd *se_cmd = &pending_req->se_cmd;\r\nstruct se_session *sess = pending_req->v2p->tpg->tpg_nexus->tvn_se_sess;\r\nint rc;\r\nmemset(pending_req->sense_buffer, 0, VSCSIIF_SENSE_BUFFERSIZE);\r\nmemset(se_cmd, 0, sizeof(*se_cmd));\r\nscsiback_get(pending_req->info);\r\nse_cmd->tag = pending_req->rqid;\r\nrc = target_submit_cmd_map_sgls(se_cmd, sess, pending_req->cmnd,\r\npending_req->sense_buffer, pending_req->v2p->lun,\r\npending_req->data_len, 0,\r\npending_req->sc_data_direction, 0,\r\npending_req->sgl, pending_req->n_sg,\r\nNULL, 0, NULL, 0);\r\nif (rc < 0) {\r\ntransport_send_check_condition_and_sense(se_cmd,\r\nTCM_LOGICAL_UNIT_COMMUNICATION_FAILURE, 0);\r\ntransport_generic_free_cmd(se_cmd, 0);\r\n}\r\n}\r\nstatic int scsiback_gnttab_data_map_batch(struct gnttab_map_grant_ref *map,\r\nstruct page **pg, grant_handle_t *grant, int cnt)\r\n{\r\nint err, i;\r\nif (!cnt)\r\nreturn 0;\r\nerr = gnttab_map_refs(map, NULL, pg, cnt);\r\nBUG_ON(err);\r\nfor (i = 0; i < cnt; i++) {\r\nif (unlikely(map[i].status != GNTST_okay)) {\r\npr_err("invalid buffer -- could not remap it\n");\r\nmap[i].handle = SCSIBACK_INVALID_HANDLE;\r\nerr = -ENOMEM;\r\n} else {\r\nget_page(pg[i]);\r\n}\r\ngrant[i] = map[i].handle;\r\n}\r\nreturn err;\r\n}\r\nstatic int scsiback_gnttab_data_map_list(struct vscsibk_pend *pending_req,\r\nstruct scsiif_request_segment *seg, struct page **pg,\r\ngrant_handle_t *grant, int cnt, u32 flags)\r\n{\r\nint mapcount = 0, i, err = 0;\r\nstruct gnttab_map_grant_ref map[VSCSI_GRANT_BATCH];\r\nstruct vscsibk_info *info = pending_req->info;\r\nfor (i = 0; i < cnt; i++) {\r\nif (get_free_page(pg + mapcount)) {\r\nput_free_pages(pg, mapcount);\r\npr_err("no grant page\n");\r\nreturn -ENOMEM;\r\n}\r\ngnttab_set_map_op(&map[mapcount], vaddr_page(pg[mapcount]),\r\nflags, seg[i].gref, info->domid);\r\nmapcount++;\r\nif (mapcount < VSCSI_GRANT_BATCH)\r\ncontinue;\r\nerr = scsiback_gnttab_data_map_batch(map, pg, grant, mapcount);\r\npg += mapcount;\r\ngrant += mapcount;\r\npending_req->n_grants += mapcount;\r\nif (err)\r\nreturn err;\r\nmapcount = 0;\r\n}\r\nerr = scsiback_gnttab_data_map_batch(map, pg, grant, mapcount);\r\npending_req->n_grants += mapcount;\r\nreturn err;\r\n}\r\nstatic int scsiback_gnttab_data_map(struct vscsiif_request *ring_req,\r\nstruct vscsibk_pend *pending_req)\r\n{\r\nu32 flags;\r\nint i, err, n_segs, i_seg = 0;\r\nstruct page **pg;\r\nstruct scsiif_request_segment *seg;\r\nunsigned long end_seg = 0;\r\nunsigned int nr_segments = (unsigned int)ring_req->nr_segments;\r\nunsigned int nr_sgl = 0;\r\nstruct scatterlist *sg;\r\ngrant_handle_t *grant;\r\npending_req->n_sg = 0;\r\npending_req->n_grants = 0;\r\npending_req->data_len = 0;\r\nnr_segments &= ~VSCSIIF_SG_GRANT;\r\nif (!nr_segments)\r\nreturn 0;\r\nif (nr_segments > VSCSIIF_SG_TABLESIZE) {\r\npr_debug("invalid parameter nr_seg = %d\n",\r\nring_req->nr_segments);\r\nreturn -EINVAL;\r\n}\r\nif (ring_req->nr_segments & VSCSIIF_SG_GRANT) {\r\nerr = scsiback_gnttab_data_map_list(pending_req, ring_req->seg,\r\npending_req->pages, pending_req->grant_handles,\r\nnr_segments, GNTMAP_host_map | GNTMAP_readonly);\r\nif (err)\r\nreturn err;\r\nnr_sgl = nr_segments;\r\nnr_segments = 0;\r\nfor (i = 0; i < nr_sgl; i++) {\r\nn_segs = ring_req->seg[i].length /\r\nsizeof(struct scsiif_request_segment);\r\nif ((unsigned)ring_req->seg[i].offset +\r\n(unsigned)ring_req->seg[i].length > PAGE_SIZE ||\r\nn_segs * sizeof(struct scsiif_request_segment) !=\r\nring_req->seg[i].length)\r\nreturn -EINVAL;\r\nnr_segments += n_segs;\r\n}\r\nif (nr_segments > SG_ALL) {\r\npr_debug("invalid nr_seg = %d\n", nr_segments);\r\nreturn -EINVAL;\r\n}\r\n}\r\npending_req->sgl = kmalloc_array(nr_segments,\r\nsizeof(struct scatterlist), GFP_KERNEL);\r\nif (!pending_req->sgl)\r\nreturn -ENOMEM;\r\nsg_init_table(pending_req->sgl, nr_segments);\r\npending_req->n_sg = nr_segments;\r\nflags = GNTMAP_host_map;\r\nif (pending_req->sc_data_direction == DMA_TO_DEVICE)\r\nflags |= GNTMAP_readonly;\r\npg = pending_req->pages + nr_sgl;\r\ngrant = pending_req->grant_handles + nr_sgl;\r\nif (!nr_sgl) {\r\nseg = ring_req->seg;\r\nerr = scsiback_gnttab_data_map_list(pending_req, seg,\r\npg, grant, nr_segments, flags);\r\nif (err)\r\nreturn err;\r\n} else {\r\nfor (i = 0; i < nr_sgl; i++) {\r\nseg = (struct scsiif_request_segment *)(\r\nvaddr(pending_req, i) + ring_req->seg[i].offset);\r\nn_segs = ring_req->seg[i].length /\r\nsizeof(struct scsiif_request_segment);\r\nerr = scsiback_gnttab_data_map_list(pending_req, seg,\r\npg, grant, n_segs, flags);\r\nif (err)\r\nreturn err;\r\npg += n_segs;\r\ngrant += n_segs;\r\n}\r\nend_seg = vaddr(pending_req, 0) + ring_req->seg[0].offset;\r\nseg = (struct scsiif_request_segment *)end_seg;\r\nend_seg += ring_req->seg[0].length;\r\npg = pending_req->pages + nr_sgl;\r\n}\r\nfor_each_sg(pending_req->sgl, sg, nr_segments, i) {\r\nsg_set_page(sg, pg[i], seg->length, seg->offset);\r\npending_req->data_len += seg->length;\r\nseg++;\r\nif (nr_sgl && (unsigned long)seg >= end_seg) {\r\ni_seg++;\r\nend_seg = vaddr(pending_req, i_seg) +\r\nring_req->seg[i_seg].offset;\r\nseg = (struct scsiif_request_segment *)end_seg;\r\nend_seg += ring_req->seg[i_seg].length;\r\n}\r\nif (sg->offset >= PAGE_SIZE ||\r\nsg->length > PAGE_SIZE ||\r\nsg->offset + sg->length > PAGE_SIZE)\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void scsiback_disconnect(struct vscsibk_info *info)\r\n{\r\nwait_event(info->waiting_to_free,\r\natomic_read(&info->nr_unreplied_reqs) == 0);\r\nunbind_from_irqhandler(info->irq, info);\r\ninfo->irq = 0;\r\nxenbus_unmap_ring_vfree(info->dev, info->ring.sring);\r\n}\r\nstatic void scsiback_device_action(struct vscsibk_pend *pending_req,\r\nenum tcm_tmreq_table act, int tag)\r\n{\r\nint rc, err = FAILED;\r\nstruct scsiback_tpg *tpg = pending_req->v2p->tpg;\r\nstruct se_cmd *se_cmd = &pending_req->se_cmd;\r\nstruct scsiback_tmr *tmr;\r\ntmr = kzalloc(sizeof(struct scsiback_tmr), GFP_KERNEL);\r\nif (!tmr)\r\ngoto out;\r\ninit_waitqueue_head(&tmr->tmr_wait);\r\ntransport_init_se_cmd(se_cmd, tpg->se_tpg.se_tpg_tfo,\r\ntpg->tpg_nexus->tvn_se_sess, 0, DMA_NONE, TCM_SIMPLE_TAG,\r\n&pending_req->sense_buffer[0]);\r\nrc = core_tmr_alloc_req(se_cmd, tmr, act, GFP_KERNEL);\r\nif (rc < 0)\r\ngoto out;\r\nse_cmd->se_tmr_req->ref_task_tag = tag;\r\nif (transport_lookup_tmr_lun(se_cmd, pending_req->v2p->lun) < 0)\r\ngoto out;\r\ntransport_generic_handle_tmr(se_cmd);\r\nwait_event(tmr->tmr_wait, atomic_read(&tmr->tmr_complete));\r\nerr = (se_cmd->se_tmr_req->response == TMR_FUNCTION_COMPLETE) ?\r\nSUCCESS : FAILED;\r\nout:\r\nif (tmr) {\r\ntransport_generic_free_cmd(&pending_req->se_cmd, 1);\r\nkfree(tmr);\r\n}\r\nscsiback_do_resp_with_sense(NULL, err, 0, pending_req);\r\nkmem_cache_free(scsiback_cachep, pending_req);\r\n}\r\nstatic struct v2p_entry *scsiback_do_translation(struct vscsibk_info *info,\r\nstruct ids_tuple *v)\r\n{\r\nstruct v2p_entry *entry;\r\nstruct list_head *head = &(info->v2p_entry_lists);\r\nunsigned long flags;\r\nspin_lock_irqsave(&info->v2p_lock, flags);\r\nlist_for_each_entry(entry, head, l) {\r\nif ((entry->v.chn == v->chn) &&\r\n(entry->v.tgt == v->tgt) &&\r\n(entry->v.lun == v->lun)) {\r\nkref_get(&entry->kref);\r\ngoto out;\r\n}\r\n}\r\nentry = NULL;\r\nout:\r\nspin_unlock_irqrestore(&info->v2p_lock, flags);\r\nreturn entry;\r\n}\r\nstatic int prepare_pending_reqs(struct vscsibk_info *info,\r\nstruct vscsiif_request *ring_req,\r\nstruct vscsibk_pend *pending_req)\r\n{\r\nstruct v2p_entry *v2p;\r\nstruct ids_tuple vir;\r\npending_req->rqid = ring_req->rqid;\r\npending_req->info = info;\r\nvir.chn = ring_req->channel;\r\nvir.tgt = ring_req->id;\r\nvir.lun = ring_req->lun;\r\nv2p = scsiback_do_translation(info, &vir);\r\nif (!v2p) {\r\npending_req->v2p = NULL;\r\npr_debug("the v2p of (chn:%d, tgt:%d, lun:%d) doesn't exist.\n",\r\nvir.chn, vir.tgt, vir.lun);\r\nreturn -ENODEV;\r\n}\r\npending_req->v2p = v2p;\r\npending_req->sc_data_direction = ring_req->sc_data_direction;\r\nif ((pending_req->sc_data_direction != DMA_BIDIRECTIONAL) &&\r\n(pending_req->sc_data_direction != DMA_TO_DEVICE) &&\r\n(pending_req->sc_data_direction != DMA_FROM_DEVICE) &&\r\n(pending_req->sc_data_direction != DMA_NONE)) {\r\npr_debug("invalid parameter data_dir = %d\n",\r\npending_req->sc_data_direction);\r\nreturn -EINVAL;\r\n}\r\npending_req->cmd_len = ring_req->cmd_len;\r\nif (pending_req->cmd_len > VSCSIIF_MAX_COMMAND_SIZE) {\r\npr_debug("invalid parameter cmd_len = %d\n",\r\npending_req->cmd_len);\r\nreturn -EINVAL;\r\n}\r\nmemcpy(pending_req->cmnd, ring_req->cmnd, pending_req->cmd_len);\r\nreturn 0;\r\n}\r\nstatic int scsiback_do_cmd_fn(struct vscsibk_info *info)\r\n{\r\nstruct vscsiif_back_ring *ring = &info->ring;\r\nstruct vscsiif_request ring_req;\r\nstruct vscsibk_pend *pending_req;\r\nRING_IDX rc, rp;\r\nint err, more_to_do;\r\nuint32_t result;\r\nrc = ring->req_cons;\r\nrp = ring->sring->req_prod;\r\nrmb();\r\nif (RING_REQUEST_PROD_OVERFLOW(ring, rp)) {\r\nrc = ring->rsp_prod_pvt;\r\npr_warn("Dom%d provided bogus ring requests (%#x - %#x = %u). Halting ring processing\n",\r\ninfo->domid, rp, rc, rp - rc);\r\ninfo->ring_error = 1;\r\nreturn 0;\r\n}\r\nwhile ((rc != rp)) {\r\nif (RING_REQUEST_CONS_OVERFLOW(ring, rc))\r\nbreak;\r\npending_req = kmem_cache_alloc(scsiback_cachep, GFP_KERNEL);\r\nif (!pending_req)\r\nreturn 1;\r\nring_req = *RING_GET_REQUEST(ring, rc);\r\nring->req_cons = ++rc;\r\nerr = prepare_pending_reqs(info, &ring_req, pending_req);\r\nif (err) {\r\nswitch (err) {\r\ncase -ENODEV:\r\nresult = DID_NO_CONNECT;\r\nbreak;\r\ndefault:\r\nresult = DRIVER_ERROR;\r\nbreak;\r\n}\r\nscsiback_do_resp_with_sense(NULL, result << 24, 0,\r\npending_req);\r\nkmem_cache_free(scsiback_cachep, pending_req);\r\nreturn 1;\r\n}\r\nswitch (ring_req.act) {\r\ncase VSCSIIF_ACT_SCSI_CDB:\r\nif (scsiback_gnttab_data_map(&ring_req, pending_req)) {\r\nscsiback_fast_flush_area(pending_req);\r\nscsiback_do_resp_with_sense(NULL,\r\nDRIVER_ERROR << 24, 0, pending_req);\r\nkmem_cache_free(scsiback_cachep, pending_req);\r\n} else {\r\nscsiback_cmd_exec(pending_req);\r\n}\r\nbreak;\r\ncase VSCSIIF_ACT_SCSI_ABORT:\r\nscsiback_device_action(pending_req, TMR_ABORT_TASK,\r\nring_req.ref_rqid);\r\nbreak;\r\ncase VSCSIIF_ACT_SCSI_RESET:\r\nscsiback_device_action(pending_req, TMR_LUN_RESET, 0);\r\nbreak;\r\ndefault:\r\npr_err_ratelimited("invalid request\n");\r\nscsiback_do_resp_with_sense(NULL, DRIVER_ERROR << 24,\r\n0, pending_req);\r\nkmem_cache_free(scsiback_cachep, pending_req);\r\nbreak;\r\n}\r\ncond_resched();\r\n}\r\nRING_FINAL_CHECK_FOR_REQUESTS(&info->ring, more_to_do);\r\nreturn more_to_do;\r\n}\r\nstatic irqreturn_t scsiback_irq_fn(int irq, void *dev_id)\r\n{\r\nstruct vscsibk_info *info = dev_id;\r\nif (info->ring_error)\r\nreturn IRQ_HANDLED;\r\nwhile (scsiback_do_cmd_fn(info))\r\ncond_resched();\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int scsiback_init_sring(struct vscsibk_info *info, grant_ref_t ring_ref,\r\nevtchn_port_t evtchn)\r\n{\r\nvoid *area;\r\nstruct vscsiif_sring *sring;\r\nint err;\r\nif (info->irq)\r\nreturn -1;\r\nerr = xenbus_map_ring_valloc(info->dev, &ring_ref, 1, &area);\r\nif (err)\r\nreturn err;\r\nsring = (struct vscsiif_sring *)area;\r\nBACK_RING_INIT(&info->ring, sring, PAGE_SIZE);\r\nerr = bind_interdomain_evtchn_to_irq(info->domid, evtchn);\r\nif (err < 0)\r\ngoto unmap_page;\r\ninfo->irq = err;\r\nerr = request_threaded_irq(info->irq, NULL, scsiback_irq_fn,\r\nIRQF_ONESHOT, "vscsiif-backend", info);\r\nif (err)\r\ngoto free_irq;\r\nreturn 0;\r\nfree_irq:\r\nunbind_from_irqhandler(info->irq, info);\r\ninfo->irq = 0;\r\nunmap_page:\r\nxenbus_unmap_ring_vfree(info->dev, area);\r\nreturn err;\r\n}\r\nstatic int scsiback_map(struct vscsibk_info *info)\r\n{\r\nstruct xenbus_device *dev = info->dev;\r\nunsigned int ring_ref, evtchn;\r\nint err;\r\nerr = xenbus_gather(XBT_NIL, dev->otherend,\r\n"ring-ref", "%u", &ring_ref,\r\n"event-channel", "%u", &evtchn, NULL);\r\nif (err) {\r\nxenbus_dev_fatal(dev, err, "reading %s ring", dev->otherend);\r\nreturn err;\r\n}\r\nreturn scsiback_init_sring(info, ring_ref, evtchn);\r\n}\r\nstatic int scsiback_add_translation_entry(struct vscsibk_info *info,\r\nchar *phy, struct ids_tuple *v)\r\n{\r\nint err = 0;\r\nstruct v2p_entry *entry;\r\nstruct v2p_entry *new;\r\nstruct list_head *head = &(info->v2p_entry_lists);\r\nunsigned long flags;\r\nchar *lunp;\r\nunsigned long long unpacked_lun;\r\nstruct se_lun *se_lun;\r\nstruct scsiback_tpg *tpg_entry, *tpg = NULL;\r\nchar *error = "doesn't exist";\r\nlunp = strrchr(phy, ':');\r\nif (!lunp) {\r\npr_err("illegal format of physical device %s\n", phy);\r\nreturn -EINVAL;\r\n}\r\n*lunp = 0;\r\nlunp++;\r\nerr = kstrtoull(lunp, 10, &unpacked_lun);\r\nif (err < 0) {\r\npr_err("lun number not valid: %s\n", lunp);\r\nreturn err;\r\n}\r\nmutex_lock(&scsiback_mutex);\r\nlist_for_each_entry(tpg_entry, &scsiback_list, tv_tpg_list) {\r\nif (!strcmp(phy, tpg_entry->tport->tport_name) ||\r\n!strcmp(phy, tpg_entry->param_alias)) {\r\nmutex_lock(&tpg_entry->se_tpg.tpg_lun_mutex);\r\nhlist_for_each_entry(se_lun, &tpg_entry->se_tpg.tpg_lun_hlist, link) {\r\nif (se_lun->unpacked_lun == unpacked_lun) {\r\nif (!tpg_entry->tpg_nexus)\r\nerror = "nexus undefined";\r\nelse\r\ntpg = tpg_entry;\r\nbreak;\r\n}\r\n}\r\nmutex_unlock(&tpg_entry->se_tpg.tpg_lun_mutex);\r\nbreak;\r\n}\r\n}\r\nif (tpg) {\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\ntpg->tv_tpg_fe_count++;\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\n}\r\nmutex_unlock(&scsiback_mutex);\r\nif (!tpg) {\r\npr_err("%s:%llu %s\n", phy, unpacked_lun, error);\r\nreturn -ENODEV;\r\n}\r\nnew = kmalloc(sizeof(struct v2p_entry), GFP_KERNEL);\r\nif (new == NULL) {\r\nerr = -ENOMEM;\r\ngoto out_free;\r\n}\r\nspin_lock_irqsave(&info->v2p_lock, flags);\r\nlist_for_each_entry(entry, head, l) {\r\nif ((entry->v.chn == v->chn) &&\r\n(entry->v.tgt == v->tgt) &&\r\n(entry->v.lun == v->lun)) {\r\npr_warn("Virtual ID is already used. Assignment was not performed.\n");\r\nerr = -EEXIST;\r\ngoto out;\r\n}\r\n}\r\nkref_init(&new->kref);\r\nnew->v = *v;\r\nnew->tpg = tpg;\r\nnew->lun = unpacked_lun;\r\nlist_add_tail(&new->l, head);\r\nout:\r\nspin_unlock_irqrestore(&info->v2p_lock, flags);\r\nout_free:\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\ntpg->tv_tpg_fe_count--;\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nif (err)\r\nkfree(new);\r\nreturn err;\r\n}\r\nstatic void __scsiback_del_translation_entry(struct v2p_entry *entry)\r\n{\r\nlist_del(&entry->l);\r\nkref_put(&entry->kref, scsiback_free_translation_entry);\r\n}\r\nstatic int scsiback_del_translation_entry(struct vscsibk_info *info,\r\nstruct ids_tuple *v)\r\n{\r\nstruct v2p_entry *entry;\r\nstruct list_head *head = &(info->v2p_entry_lists);\r\nunsigned long flags;\r\nspin_lock_irqsave(&info->v2p_lock, flags);\r\nlist_for_each_entry(entry, head, l) {\r\nif ((entry->v.chn == v->chn) &&\r\n(entry->v.tgt == v->tgt) &&\r\n(entry->v.lun == v->lun)) {\r\ngoto found;\r\n}\r\n}\r\nspin_unlock_irqrestore(&info->v2p_lock, flags);\r\nreturn 1;\r\nfound:\r\n__scsiback_del_translation_entry(entry);\r\nspin_unlock_irqrestore(&info->v2p_lock, flags);\r\nreturn 0;\r\n}\r\nstatic void scsiback_do_add_lun(struct vscsibk_info *info, const char *state,\r\nchar *phy, struct ids_tuple *vir, int try)\r\n{\r\nif (!scsiback_add_translation_entry(info, phy, vir)) {\r\nif (xenbus_printf(XBT_NIL, info->dev->nodename, state,\r\n"%d", XenbusStateInitialised)) {\r\npr_err("xenbus_printf error %s\n", state);\r\nscsiback_del_translation_entry(info, vir);\r\n}\r\n} else if (!try) {\r\nxenbus_printf(XBT_NIL, info->dev->nodename, state,\r\n"%d", XenbusStateClosed);\r\n}\r\n}\r\nstatic void scsiback_do_del_lun(struct vscsibk_info *info, const char *state,\r\nstruct ids_tuple *vir)\r\n{\r\nif (!scsiback_del_translation_entry(info, vir)) {\r\nif (xenbus_printf(XBT_NIL, info->dev->nodename, state,\r\n"%d", XenbusStateClosed))\r\npr_err("xenbus_printf error %s\n", state);\r\n}\r\n}\r\nstatic void scsiback_do_1lun_hotplug(struct vscsibk_info *info, int op,\r\nchar *ent)\r\n{\r\nint err;\r\nstruct ids_tuple vir;\r\nchar *val;\r\nint device_state;\r\nchar phy[VSCSI_NAMELEN];\r\nchar str[64];\r\nchar state[64];\r\nstruct xenbus_device *dev = info->dev;\r\nsnprintf(state, sizeof(state), "vscsi-devs/%s/state", ent);\r\nerr = xenbus_scanf(XBT_NIL, dev->nodename, state, "%u", &device_state);\r\nif (XENBUS_EXIST_ERR(err))\r\nreturn;\r\nsnprintf(str, sizeof(str), "vscsi-devs/%s/p-dev", ent);\r\nval = xenbus_read(XBT_NIL, dev->nodename, str, NULL);\r\nif (IS_ERR(val)) {\r\nxenbus_printf(XBT_NIL, dev->nodename, state,\r\n"%d", XenbusStateClosed);\r\nreturn;\r\n}\r\nstrlcpy(phy, val, VSCSI_NAMELEN);\r\nkfree(val);\r\nsnprintf(str, sizeof(str), "vscsi-devs/%s/v-dev", ent);\r\nerr = xenbus_scanf(XBT_NIL, dev->nodename, str, "%u:%u:%u:%u",\r\n&vir.hst, &vir.chn, &vir.tgt, &vir.lun);\r\nif (XENBUS_EXIST_ERR(err)) {\r\nxenbus_printf(XBT_NIL, dev->nodename, state,\r\n"%d", XenbusStateClosed);\r\nreturn;\r\n}\r\nswitch (op) {\r\ncase VSCSIBACK_OP_ADD_OR_DEL_LUN:\r\nswitch (device_state) {\r\ncase XenbusStateInitialising:\r\nscsiback_do_add_lun(info, state, phy, &vir, 0);\r\nbreak;\r\ncase XenbusStateConnected:\r\nscsiback_do_add_lun(info, state, phy, &vir, 1);\r\nbreak;\r\ncase XenbusStateClosing:\r\nscsiback_do_del_lun(info, state, &vir);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nbreak;\r\ncase VSCSIBACK_OP_UPDATEDEV_STATE:\r\nif (device_state == XenbusStateInitialised) {\r\nif (xenbus_printf(XBT_NIL, dev->nodename, state,\r\n"%d", XenbusStateConnected)) {\r\npr_err("xenbus_printf error %s\n", str);\r\nscsiback_del_translation_entry(info, &vir);\r\nxenbus_printf(XBT_NIL, dev->nodename, state,\r\n"%d", XenbusStateClosed);\r\n}\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic void scsiback_do_lun_hotplug(struct vscsibk_info *info, int op)\r\n{\r\nint i;\r\nchar **dir;\r\nunsigned int ndir = 0;\r\ndir = xenbus_directory(XBT_NIL, info->dev->nodename, "vscsi-devs",\r\n&ndir);\r\nif (IS_ERR(dir))\r\nreturn;\r\nfor (i = 0; i < ndir; i++)\r\nscsiback_do_1lun_hotplug(info, op, dir[i]);\r\nkfree(dir);\r\n}\r\nstatic void scsiback_frontend_changed(struct xenbus_device *dev,\r\nenum xenbus_state frontend_state)\r\n{\r\nstruct vscsibk_info *info = dev_get_drvdata(&dev->dev);\r\nswitch (frontend_state) {\r\ncase XenbusStateInitialising:\r\nbreak;\r\ncase XenbusStateInitialised:\r\nif (scsiback_map(info))\r\nbreak;\r\nscsiback_do_lun_hotplug(info, VSCSIBACK_OP_ADD_OR_DEL_LUN);\r\nxenbus_switch_state(dev, XenbusStateConnected);\r\nbreak;\r\ncase XenbusStateConnected:\r\nscsiback_do_lun_hotplug(info, VSCSIBACK_OP_UPDATEDEV_STATE);\r\nif (dev->state == XenbusStateConnected)\r\nbreak;\r\nxenbus_switch_state(dev, XenbusStateConnected);\r\nbreak;\r\ncase XenbusStateClosing:\r\nif (info->irq)\r\nscsiback_disconnect(info);\r\nxenbus_switch_state(dev, XenbusStateClosing);\r\nbreak;\r\ncase XenbusStateClosed:\r\nxenbus_switch_state(dev, XenbusStateClosed);\r\nif (xenbus_dev_is_online(dev))\r\nbreak;\r\ncase XenbusStateUnknown:\r\ndevice_unregister(&dev->dev);\r\nbreak;\r\ncase XenbusStateReconfiguring:\r\nscsiback_do_lun_hotplug(info, VSCSIBACK_OP_ADD_OR_DEL_LUN);\r\nxenbus_switch_state(dev, XenbusStateReconfigured);\r\nbreak;\r\ndefault:\r\nxenbus_dev_fatal(dev, -EINVAL, "saw state %d at frontend",\r\nfrontend_state);\r\nbreak;\r\n}\r\n}\r\nstatic void scsiback_release_translation_entry(struct vscsibk_info *info)\r\n{\r\nstruct v2p_entry *entry, *tmp;\r\nstruct list_head *head = &(info->v2p_entry_lists);\r\nunsigned long flags;\r\nspin_lock_irqsave(&info->v2p_lock, flags);\r\nlist_for_each_entry_safe(entry, tmp, head, l)\r\n__scsiback_del_translation_entry(entry);\r\nspin_unlock_irqrestore(&info->v2p_lock, flags);\r\n}\r\nstatic int scsiback_remove(struct xenbus_device *dev)\r\n{\r\nstruct vscsibk_info *info = dev_get_drvdata(&dev->dev);\r\nif (info->irq)\r\nscsiback_disconnect(info);\r\nscsiback_release_translation_entry(info);\r\ndev_set_drvdata(&dev->dev, NULL);\r\nreturn 0;\r\n}\r\nstatic int scsiback_probe(struct xenbus_device *dev,\r\nconst struct xenbus_device_id *id)\r\n{\r\nint err;\r\nstruct vscsibk_info *info = kzalloc(sizeof(struct vscsibk_info),\r\nGFP_KERNEL);\r\npr_debug("%s %p %d\n", __func__, dev, dev->otherend_id);\r\nif (!info) {\r\nxenbus_dev_fatal(dev, -ENOMEM, "allocating backend structure");\r\nreturn -ENOMEM;\r\n}\r\ninfo->dev = dev;\r\ndev_set_drvdata(&dev->dev, info);\r\ninfo->domid = dev->otherend_id;\r\nspin_lock_init(&info->ring_lock);\r\ninfo->ring_error = 0;\r\natomic_set(&info->nr_unreplied_reqs, 0);\r\ninit_waitqueue_head(&info->waiting_to_free);\r\ninfo->dev = dev;\r\ninfo->irq = 0;\r\nINIT_LIST_HEAD(&info->v2p_entry_lists);\r\nspin_lock_init(&info->v2p_lock);\r\nerr = xenbus_printf(XBT_NIL, dev->nodename, "feature-sg-grant", "%u",\r\nSG_ALL);\r\nif (err)\r\nxenbus_dev_error(dev, err, "writing feature-sg-grant");\r\nerr = xenbus_switch_state(dev, XenbusStateInitWait);\r\nif (err)\r\ngoto fail;\r\nreturn 0;\r\nfail:\r\npr_warn("%s failed\n", __func__);\r\nscsiback_remove(dev);\r\nreturn err;\r\n}\r\nstatic char *scsiback_dump_proto_id(struct scsiback_tport *tport)\r\n{\r\nswitch (tport->tport_proto_id) {\r\ncase SCSI_PROTOCOL_SAS:\r\nreturn "SAS";\r\ncase SCSI_PROTOCOL_FCP:\r\nreturn "FCP";\r\ncase SCSI_PROTOCOL_ISCSI:\r\nreturn "iSCSI";\r\ndefault:\r\nbreak;\r\n}\r\nreturn "Unknown";\r\n}\r\nstatic char *scsiback_get_fabric_wwn(struct se_portal_group *se_tpg)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg,\r\nstruct scsiback_tpg, se_tpg);\r\nstruct scsiback_tport *tport = tpg->tport;\r\nreturn &tport->tport_name[0];\r\n}\r\nstatic u16 scsiback_get_tag(struct se_portal_group *se_tpg)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg,\r\nstruct scsiback_tpg, se_tpg);\r\nreturn tpg->tport_tpgt;\r\n}\r\nstatic struct se_wwn *\r\nscsiback_make_tport(struct target_fabric_configfs *tf,\r\nstruct config_group *group,\r\nconst char *name)\r\n{\r\nstruct scsiback_tport *tport;\r\nchar *ptr;\r\nu64 wwpn = 0;\r\nint off = 0;\r\ntport = kzalloc(sizeof(struct scsiback_tport), GFP_KERNEL);\r\nif (!tport)\r\nreturn ERR_PTR(-ENOMEM);\r\ntport->tport_wwpn = wwpn;\r\nptr = strstr(name, "naa.");\r\nif (ptr) {\r\ntport->tport_proto_id = SCSI_PROTOCOL_SAS;\r\ngoto check_len;\r\n}\r\nptr = strstr(name, "fc.");\r\nif (ptr) {\r\ntport->tport_proto_id = SCSI_PROTOCOL_FCP;\r\noff = 3;\r\ngoto check_len;\r\n}\r\nptr = strstr(name, "iqn.");\r\nif (ptr) {\r\ntport->tport_proto_id = SCSI_PROTOCOL_ISCSI;\r\ngoto check_len;\r\n}\r\npr_err("Unable to locate prefix for emulated Target Port: %s\n", name);\r\nkfree(tport);\r\nreturn ERR_PTR(-EINVAL);\r\ncheck_len:\r\nif (strlen(name) >= VSCSI_NAMELEN) {\r\npr_err("Emulated %s Address: %s, exceeds max: %d\n", name,\r\nscsiback_dump_proto_id(tport), VSCSI_NAMELEN);\r\nkfree(tport);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nsnprintf(&tport->tport_name[0], VSCSI_NAMELEN, "%s", &name[off]);\r\npr_debug("Allocated emulated Target %s Address: %s\n",\r\nscsiback_dump_proto_id(tport), name);\r\nreturn &tport->tport_wwn;\r\n}\r\nstatic void scsiback_drop_tport(struct se_wwn *wwn)\r\n{\r\nstruct scsiback_tport *tport = container_of(wwn,\r\nstruct scsiback_tport, tport_wwn);\r\npr_debug("Deallocating emulated Target %s Address: %s\n",\r\nscsiback_dump_proto_id(tport), tport->tport_name);\r\nkfree(tport);\r\n}\r\nstatic u32 scsiback_tpg_get_inst_index(struct se_portal_group *se_tpg)\r\n{\r\nreturn 1;\r\n}\r\nstatic int scsiback_check_stop_free(struct se_cmd *se_cmd)\r\n{\r\nif (se_cmd->se_cmd_flags & SCF_SCSI_TMR_CDB)\r\nreturn 0;\r\ntransport_generic_free_cmd(se_cmd, 0);\r\nreturn 1;\r\n}\r\nstatic void scsiback_release_cmd(struct se_cmd *se_cmd)\r\n{\r\nstruct vscsibk_pend *pending_req = container_of(se_cmd,\r\nstruct vscsibk_pend, se_cmd);\r\nkmem_cache_free(scsiback_cachep, pending_req);\r\n}\r\nstatic int scsiback_shutdown_session(struct se_session *se_sess)\r\n{\r\nreturn 0;\r\n}\r\nstatic void scsiback_close_session(struct se_session *se_sess)\r\n{\r\n}\r\nstatic u32 scsiback_sess_get_index(struct se_session *se_sess)\r\n{\r\nreturn 0;\r\n}\r\nstatic int scsiback_write_pending(struct se_cmd *se_cmd)\r\n{\r\ntarget_execute_cmd(se_cmd);\r\nreturn 0;\r\n}\r\nstatic int scsiback_write_pending_status(struct se_cmd *se_cmd)\r\n{\r\nreturn 0;\r\n}\r\nstatic void scsiback_set_default_node_attrs(struct se_node_acl *nacl)\r\n{\r\n}\r\nstatic int scsiback_get_cmd_state(struct se_cmd *se_cmd)\r\n{\r\nreturn 0;\r\n}\r\nstatic int scsiback_queue_data_in(struct se_cmd *se_cmd)\r\n{\r\nstruct vscsibk_pend *pending_req = container_of(se_cmd,\r\nstruct vscsibk_pend, se_cmd);\r\npending_req->result = SAM_STAT_GOOD;\r\nscsiback_cmd_done(pending_req);\r\nreturn 0;\r\n}\r\nstatic int scsiback_queue_status(struct se_cmd *se_cmd)\r\n{\r\nstruct vscsibk_pend *pending_req = container_of(se_cmd,\r\nstruct vscsibk_pend, se_cmd);\r\nif (se_cmd->sense_buffer &&\r\n((se_cmd->se_cmd_flags & SCF_TRANSPORT_TASK_SENSE) ||\r\n(se_cmd->se_cmd_flags & SCF_EMULATED_TASK_SENSE)))\r\npending_req->result = (DRIVER_SENSE << 24) |\r\nSAM_STAT_CHECK_CONDITION;\r\nelse\r\npending_req->result = se_cmd->scsi_status;\r\nscsiback_cmd_done(pending_req);\r\nreturn 0;\r\n}\r\nstatic void scsiback_queue_tm_rsp(struct se_cmd *se_cmd)\r\n{\r\nstruct se_tmr_req *se_tmr = se_cmd->se_tmr_req;\r\nstruct scsiback_tmr *tmr = se_tmr->fabric_tmr_ptr;\r\natomic_set(&tmr->tmr_complete, 1);\r\nwake_up(&tmr->tmr_wait);\r\n}\r\nstatic void scsiback_aborted_task(struct se_cmd *se_cmd)\r\n{\r\n}\r\nstatic ssize_t scsiback_tpg_param_show_alias(struct se_portal_group *se_tpg,\r\nchar *page)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg, struct scsiback_tpg,\r\nse_tpg);\r\nssize_t rb;\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\nrb = snprintf(page, PAGE_SIZE, "%s\n", tpg->param_alias);\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn rb;\r\n}\r\nstatic ssize_t scsiback_tpg_param_store_alias(struct se_portal_group *se_tpg,\r\nconst char *page, size_t count)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg, struct scsiback_tpg,\r\nse_tpg);\r\nint len;\r\nif (strlen(page) >= VSCSI_NAMELEN) {\r\npr_err("param alias: %s, exceeds max: %d\n", page,\r\nVSCSI_NAMELEN);\r\nreturn -EINVAL;\r\n}\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\nlen = snprintf(tpg->param_alias, VSCSI_NAMELEN, "%s", page);\r\nif (tpg->param_alias[len - 1] == '\n')\r\ntpg->param_alias[len - 1] = '\0';\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn count;\r\n}\r\nstatic int scsiback_make_nexus(struct scsiback_tpg *tpg,\r\nconst char *name)\r\n{\r\nstruct se_portal_group *se_tpg;\r\nstruct se_session *se_sess;\r\nstruct scsiback_nexus *tv_nexus;\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\nif (tpg->tpg_nexus) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\npr_debug("tpg->tpg_nexus already exists\n");\r\nreturn -EEXIST;\r\n}\r\nse_tpg = &tpg->se_tpg;\r\ntv_nexus = kzalloc(sizeof(struct scsiback_nexus), GFP_KERNEL);\r\nif (!tv_nexus) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn -ENOMEM;\r\n}\r\ntv_nexus->tvn_se_sess = transport_init_session(TARGET_PROT_NORMAL);\r\nif (IS_ERR(tv_nexus->tvn_se_sess)) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nkfree(tv_nexus);\r\nreturn -ENOMEM;\r\n}\r\nse_sess = tv_nexus->tvn_se_sess;\r\ntv_nexus->tvn_se_sess->se_node_acl = core_tpg_check_initiator_node_acl(\r\nse_tpg, (unsigned char *)name);\r\nif (!tv_nexus->tvn_se_sess->se_node_acl) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\npr_debug("core_tpg_check_initiator_node_acl() failed for %s\n",\r\nname);\r\ngoto out;\r\n}\r\ntransport_register_session(se_tpg, tv_nexus->tvn_se_sess->se_node_acl,\r\ntv_nexus->tvn_se_sess, tv_nexus);\r\ntpg->tpg_nexus = tv_nexus;\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn 0;\r\nout:\r\ntransport_free_session(se_sess);\r\nkfree(tv_nexus);\r\nreturn -ENOMEM;\r\n}\r\nstatic int scsiback_drop_nexus(struct scsiback_tpg *tpg)\r\n{\r\nstruct se_session *se_sess;\r\nstruct scsiback_nexus *tv_nexus;\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\ntv_nexus = tpg->tpg_nexus;\r\nif (!tv_nexus) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn -ENODEV;\r\n}\r\nse_sess = tv_nexus->tvn_se_sess;\r\nif (!se_sess) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn -ENODEV;\r\n}\r\nif (tpg->tv_tpg_port_count != 0) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\npr_err("Unable to remove xen-pvscsi I_T Nexus with active TPG port count: %d\n",\r\ntpg->tv_tpg_port_count);\r\nreturn -EBUSY;\r\n}\r\nif (tpg->tv_tpg_fe_count != 0) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\npr_err("Unable to remove xen-pvscsi I_T Nexus with active TPG frontend count: %d\n",\r\ntpg->tv_tpg_fe_count);\r\nreturn -EBUSY;\r\n}\r\npr_debug("Removing I_T Nexus to emulated %s Initiator Port: %s\n",\r\nscsiback_dump_proto_id(tpg->tport),\r\ntv_nexus->tvn_se_sess->se_node_acl->initiatorname);\r\ntransport_deregister_session(tv_nexus->tvn_se_sess);\r\ntpg->tpg_nexus = NULL;\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nkfree(tv_nexus);\r\nreturn 0;\r\n}\r\nstatic ssize_t scsiback_tpg_show_nexus(struct se_portal_group *se_tpg,\r\nchar *page)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg,\r\nstruct scsiback_tpg, se_tpg);\r\nstruct scsiback_nexus *tv_nexus;\r\nssize_t ret;\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\ntv_nexus = tpg->tpg_nexus;\r\nif (!tv_nexus) {\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn -ENODEV;\r\n}\r\nret = snprintf(page, PAGE_SIZE, "%s\n",\r\ntv_nexus->tvn_se_sess->se_node_acl->initiatorname);\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn ret;\r\n}\r\nstatic ssize_t scsiback_tpg_store_nexus(struct se_portal_group *se_tpg,\r\nconst char *page,\r\nsize_t count)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg,\r\nstruct scsiback_tpg, se_tpg);\r\nstruct scsiback_tport *tport_wwn = tpg->tport;\r\nunsigned char i_port[VSCSI_NAMELEN], *ptr, *port_ptr;\r\nint ret;\r\nif (!strncmp(page, "NULL", 4)) {\r\nret = scsiback_drop_nexus(tpg);\r\nreturn (!ret) ? count : ret;\r\n}\r\nif (strlen(page) >= VSCSI_NAMELEN) {\r\npr_err("Emulated NAA Sas Address: %s, exceeds max: %d\n",\r\npage, VSCSI_NAMELEN);\r\nreturn -EINVAL;\r\n}\r\nsnprintf(&i_port[0], VSCSI_NAMELEN, "%s", page);\r\nptr = strstr(i_port, "naa.");\r\nif (ptr) {\r\nif (tport_wwn->tport_proto_id != SCSI_PROTOCOL_SAS) {\r\npr_err("Passed SAS Initiator Port %s does not match target port protoid: %s\n",\r\ni_port, scsiback_dump_proto_id(tport_wwn));\r\nreturn -EINVAL;\r\n}\r\nport_ptr = &i_port[0];\r\ngoto check_newline;\r\n}\r\nptr = strstr(i_port, "fc.");\r\nif (ptr) {\r\nif (tport_wwn->tport_proto_id != SCSI_PROTOCOL_FCP) {\r\npr_err("Passed FCP Initiator Port %s does not match target port protoid: %s\n",\r\ni_port, scsiback_dump_proto_id(tport_wwn));\r\nreturn -EINVAL;\r\n}\r\nport_ptr = &i_port[3];\r\ngoto check_newline;\r\n}\r\nptr = strstr(i_port, "iqn.");\r\nif (ptr) {\r\nif (tport_wwn->tport_proto_id != SCSI_PROTOCOL_ISCSI) {\r\npr_err("Passed iSCSI Initiator Port %s does not match target port protoid: %s\n",\r\ni_port, scsiback_dump_proto_id(tport_wwn));\r\nreturn -EINVAL;\r\n}\r\nport_ptr = &i_port[0];\r\ngoto check_newline;\r\n}\r\npr_err("Unable to locate prefix for emulated Initiator Port: %s\n",\r\ni_port);\r\nreturn -EINVAL;\r\ncheck_newline:\r\nif (i_port[strlen(i_port) - 1] == '\n')\r\ni_port[strlen(i_port) - 1] = '\0';\r\nret = scsiback_make_nexus(tpg, port_ptr);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn count;\r\n}\r\nstatic ssize_t\r\nscsiback_wwn_show_attr_version(struct target_fabric_configfs *tf,\r\nchar *page)\r\n{\r\nreturn sprintf(page, "xen-pvscsi fabric module %s on %s/%s on "\r\nUTS_RELEASE"\n",\r\nVSCSI_VERSION, utsname()->sysname, utsname()->machine);\r\n}\r\nstatic char *scsiback_get_fabric_name(void)\r\n{\r\nreturn "xen-pvscsi";\r\n}\r\nstatic int scsiback_port_link(struct se_portal_group *se_tpg,\r\nstruct se_lun *lun)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg,\r\nstruct scsiback_tpg, se_tpg);\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\ntpg->tv_tpg_port_count++;\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\nreturn 0;\r\n}\r\nstatic void scsiback_port_unlink(struct se_portal_group *se_tpg,\r\nstruct se_lun *lun)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg,\r\nstruct scsiback_tpg, se_tpg);\r\nmutex_lock(&tpg->tv_tpg_mutex);\r\ntpg->tv_tpg_port_count--;\r\nmutex_unlock(&tpg->tv_tpg_mutex);\r\n}\r\nstatic struct se_portal_group *\r\nscsiback_make_tpg(struct se_wwn *wwn,\r\nstruct config_group *group,\r\nconst char *name)\r\n{\r\nstruct scsiback_tport *tport = container_of(wwn,\r\nstruct scsiback_tport, tport_wwn);\r\nstruct scsiback_tpg *tpg;\r\nu16 tpgt;\r\nint ret;\r\nif (strstr(name, "tpgt_") != name)\r\nreturn ERR_PTR(-EINVAL);\r\nret = kstrtou16(name + 5, 10, &tpgt);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\ntpg = kzalloc(sizeof(struct scsiback_tpg), GFP_KERNEL);\r\nif (!tpg)\r\nreturn ERR_PTR(-ENOMEM);\r\nmutex_init(&tpg->tv_tpg_mutex);\r\nINIT_LIST_HEAD(&tpg->tv_tpg_list);\r\nINIT_LIST_HEAD(&tpg->info_list);\r\ntpg->tport = tport;\r\ntpg->tport_tpgt = tpgt;\r\nret = core_tpg_register(wwn, &tpg->se_tpg, tport->tport_proto_id);\r\nif (ret < 0) {\r\nkfree(tpg);\r\nreturn NULL;\r\n}\r\nmutex_lock(&scsiback_mutex);\r\nlist_add_tail(&tpg->tv_tpg_list, &scsiback_list);\r\nmutex_unlock(&scsiback_mutex);\r\nreturn &tpg->se_tpg;\r\n}\r\nstatic void scsiback_drop_tpg(struct se_portal_group *se_tpg)\r\n{\r\nstruct scsiback_tpg *tpg = container_of(se_tpg,\r\nstruct scsiback_tpg, se_tpg);\r\nmutex_lock(&scsiback_mutex);\r\nlist_del(&tpg->tv_tpg_list);\r\nmutex_unlock(&scsiback_mutex);\r\nscsiback_drop_nexus(tpg);\r\ncore_tpg_deregister(se_tpg);\r\nkfree(tpg);\r\n}\r\nstatic int scsiback_check_true(struct se_portal_group *se_tpg)\r\n{\r\nreturn 1;\r\n}\r\nstatic int scsiback_check_false(struct se_portal_group *se_tpg)\r\n{\r\nreturn 0;\r\n}\r\nstatic void scsiback_init_pend(void *p)\r\n{\r\nstruct vscsibk_pend *pend = p;\r\nint i;\r\nmemset(pend, 0, sizeof(*pend));\r\nfor (i = 0; i < VSCSI_MAX_GRANTS; i++)\r\npend->grant_handles[i] = SCSIBACK_INVALID_HANDLE;\r\n}\r\nstatic int __init scsiback_init(void)\r\n{\r\nint ret;\r\nif (!xen_domain())\r\nreturn -ENODEV;\r\npr_debug("xen-pvscsi: fabric module %s on %s/%s on "UTS_RELEASE"\n",\r\nVSCSI_VERSION, utsname()->sysname, utsname()->machine);\r\nscsiback_cachep = kmem_cache_create("vscsiif_cache",\r\nsizeof(struct vscsibk_pend), 0, 0, scsiback_init_pend);\r\nif (!scsiback_cachep)\r\nreturn -ENOMEM;\r\nret = xenbus_register_backend(&scsiback_driver);\r\nif (ret)\r\ngoto out_cache_destroy;\r\nret = target_register_template(&scsiback_ops);\r\nif (ret)\r\ngoto out_unregister_xenbus;\r\nreturn 0;\r\nout_unregister_xenbus:\r\nxenbus_unregister_driver(&scsiback_driver);\r\nout_cache_destroy:\r\nkmem_cache_destroy(scsiback_cachep);\r\npr_err("%s: error %d\n", __func__, ret);\r\nreturn ret;\r\n}\r\nstatic void __exit scsiback_exit(void)\r\n{\r\nstruct page *page;\r\nwhile (free_pages_num) {\r\nif (get_free_page(&page))\r\nBUG();\r\ngnttab_free_pages(1, &page);\r\n}\r\ntarget_unregister_template(&scsiback_ops);\r\nxenbus_unregister_driver(&scsiback_driver);\r\nkmem_cache_destroy(scsiback_cachep);\r\n}
