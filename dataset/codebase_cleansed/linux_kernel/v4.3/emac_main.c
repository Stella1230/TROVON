static inline int arc_emac_tx_avail(struct arc_emac_priv *priv)\r\n{\r\nreturn (priv->txbd_dirty + TX_BD_NUM - priv->txbd_curr - 1) % TX_BD_NUM;\r\n}\r\nstatic void arc_emac_adjust_link(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nstruct phy_device *phy_dev = priv->phy_dev;\r\nunsigned int reg, state_changed = 0;\r\nif (priv->link != phy_dev->link) {\r\npriv->link = phy_dev->link;\r\nstate_changed = 1;\r\n}\r\nif (priv->speed != phy_dev->speed) {\r\npriv->speed = phy_dev->speed;\r\nstate_changed = 1;\r\nif (priv->set_mac_speed)\r\npriv->set_mac_speed(priv, priv->speed);\r\n}\r\nif (priv->duplex != phy_dev->duplex) {\r\nreg = arc_reg_get(priv, R_CTRL);\r\nif (DUPLEX_FULL == phy_dev->duplex)\r\nreg |= ENFL_MASK;\r\nelse\r\nreg &= ~ENFL_MASK;\r\narc_reg_set(priv, R_CTRL, reg);\r\npriv->duplex = phy_dev->duplex;\r\nstate_changed = 1;\r\n}\r\nif (state_changed)\r\nphy_print_status(phy_dev);\r\n}\r\nstatic int arc_emac_get_settings(struct net_device *ndev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nreturn phy_ethtool_gset(priv->phy_dev, cmd);\r\n}\r\nstatic int arc_emac_set_settings(struct net_device *ndev,\r\nstruct ethtool_cmd *cmd)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nreturn phy_ethtool_sset(priv->phy_dev, cmd);\r\n}\r\nstatic void arc_emac_get_drvinfo(struct net_device *ndev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nstrlcpy(info->driver, priv->drv_name, sizeof(info->driver));\r\nstrlcpy(info->version, priv->drv_version, sizeof(info->version));\r\n}\r\nstatic void arc_emac_tx_clean(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nstruct net_device_stats *stats = &ndev->stats;\r\nunsigned int i;\r\nfor (i = 0; i < TX_BD_NUM; i++) {\r\nunsigned int *txbd_dirty = &priv->txbd_dirty;\r\nstruct arc_emac_bd *txbd = &priv->txbd[*txbd_dirty];\r\nstruct buffer_state *tx_buff = &priv->tx_buff[*txbd_dirty];\r\nstruct sk_buff *skb = tx_buff->skb;\r\nunsigned int info = le32_to_cpu(txbd->info);\r\nif ((info & FOR_EMAC) || !txbd->data)\r\nbreak;\r\nif (unlikely(info & (DROP | DEFR | LTCL | UFLO))) {\r\nstats->tx_errors++;\r\nstats->tx_dropped++;\r\nif (info & DEFR)\r\nstats->tx_carrier_errors++;\r\nif (info & LTCL)\r\nstats->collisions++;\r\nif (info & UFLO)\r\nstats->tx_fifo_errors++;\r\n} else if (likely(info & FIRST_OR_LAST_MASK)) {\r\nstats->tx_packets++;\r\nstats->tx_bytes += skb->len;\r\n}\r\ndma_unmap_single(&ndev->dev, dma_unmap_addr(tx_buff, addr),\r\ndma_unmap_len(tx_buff, len), DMA_TO_DEVICE);\r\ndev_kfree_skb_irq(skb);\r\ntxbd->data = 0;\r\ntxbd->info = 0;\r\n*txbd_dirty = (*txbd_dirty + 1) % TX_BD_NUM;\r\n}\r\nsmp_mb();\r\nif (netif_queue_stopped(ndev) && arc_emac_tx_avail(priv))\r\nnetif_wake_queue(ndev);\r\n}\r\nstatic int arc_emac_rx(struct net_device *ndev, int budget)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nunsigned int work_done;\r\nfor (work_done = 0; work_done < budget; work_done++) {\r\nunsigned int *last_rx_bd = &priv->last_rx_bd;\r\nstruct net_device_stats *stats = &ndev->stats;\r\nstruct buffer_state *rx_buff = &priv->rx_buff[*last_rx_bd];\r\nstruct arc_emac_bd *rxbd = &priv->rxbd[*last_rx_bd];\r\nunsigned int pktlen, info = le32_to_cpu(rxbd->info);\r\nstruct sk_buff *skb;\r\ndma_addr_t addr;\r\nif (unlikely((info & OWN_MASK) == FOR_EMAC))\r\nbreak;\r\n*last_rx_bd = (*last_rx_bd + 1) % RX_BD_NUM;\r\nif (unlikely((info & FIRST_OR_LAST_MASK) !=\r\nFIRST_OR_LAST_MASK)) {\r\nif (net_ratelimit())\r\nnetdev_err(ndev, "incomplete packet received\n");\r\nrxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\r\nstats->rx_errors++;\r\nstats->rx_length_errors++;\r\ncontinue;\r\n}\r\npktlen = info & LEN_MASK;\r\nstats->rx_packets++;\r\nstats->rx_bytes += pktlen;\r\nskb = rx_buff->skb;\r\nskb_put(skb, pktlen);\r\nskb->dev = ndev;\r\nskb->protocol = eth_type_trans(skb, ndev);\r\ndma_unmap_single(&ndev->dev, dma_unmap_addr(rx_buff, addr),\r\ndma_unmap_len(rx_buff, len), DMA_FROM_DEVICE);\r\nrx_buff->skb = netdev_alloc_skb_ip_align(ndev,\r\nEMAC_BUFFER_SIZE);\r\nif (unlikely(!rx_buff->skb)) {\r\nstats->rx_errors++;\r\nstats->rx_dropped++;\r\ncontinue;\r\n}\r\nnetif_receive_skb(skb);\r\naddr = dma_map_single(&ndev->dev, (void *)rx_buff->skb->data,\r\nEMAC_BUFFER_SIZE, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(&ndev->dev, addr)) {\r\nif (net_ratelimit())\r\nnetdev_err(ndev, "cannot dma map\n");\r\ndev_kfree_skb(rx_buff->skb);\r\nstats->rx_errors++;\r\ncontinue;\r\n}\r\ndma_unmap_addr_set(rx_buff, addr, addr);\r\ndma_unmap_len_set(rx_buff, len, EMAC_BUFFER_SIZE);\r\nrxbd->data = cpu_to_le32(addr);\r\nwmb();\r\nrxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\r\n}\r\nreturn work_done;\r\n}\r\nstatic int arc_emac_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct net_device *ndev = napi->dev;\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nunsigned int work_done;\r\narc_emac_tx_clean(ndev);\r\nwork_done = arc_emac_rx(ndev, budget);\r\nif (work_done < budget) {\r\nnapi_complete(napi);\r\narc_reg_or(priv, R_ENABLE, RXINT_MASK | TXINT_MASK);\r\n}\r\nreturn work_done;\r\n}\r\nstatic irqreturn_t arc_emac_intr(int irq, void *dev_instance)\r\n{\r\nstruct net_device *ndev = dev_instance;\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nstruct net_device_stats *stats = &ndev->stats;\r\nunsigned int status;\r\nstatus = arc_reg_get(priv, R_STATUS);\r\nstatus &= ~MDIO_MASK;\r\narc_reg_set(priv, R_STATUS, status);\r\nif (status & (RXINT_MASK | TXINT_MASK)) {\r\nif (likely(napi_schedule_prep(&priv->napi))) {\r\narc_reg_clr(priv, R_ENABLE, RXINT_MASK | TXINT_MASK);\r\n__napi_schedule(&priv->napi);\r\n}\r\n}\r\nif (status & ERR_MASK) {\r\nif (status & MSER_MASK) {\r\nstats->rx_missed_errors += 0x100;\r\nstats->rx_errors += 0x100;\r\n}\r\nif (status & RXCR_MASK) {\r\nstats->rx_crc_errors += 0x100;\r\nstats->rx_errors += 0x100;\r\n}\r\nif (status & RXFR_MASK) {\r\nstats->rx_frame_errors += 0x100;\r\nstats->rx_errors += 0x100;\r\n}\r\nif (status & RXFL_MASK) {\r\nstats->rx_over_errors += 0x100;\r\nstats->rx_errors += 0x100;\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void arc_emac_poll_controller(struct net_device *dev)\r\n{\r\ndisable_irq(dev->irq);\r\narc_emac_intr(dev->irq, dev);\r\nenable_irq(dev->irq);\r\n}\r\nstatic int arc_emac_open(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nstruct phy_device *phy_dev = priv->phy_dev;\r\nint i;\r\nphy_dev->autoneg = AUTONEG_ENABLE;\r\nphy_dev->speed = 0;\r\nphy_dev->duplex = 0;\r\nphy_dev->advertising &= phy_dev->supported;\r\npriv->last_rx_bd = 0;\r\nfor (i = 0; i < RX_BD_NUM; i++) {\r\ndma_addr_t addr;\r\nunsigned int *last_rx_bd = &priv->last_rx_bd;\r\nstruct arc_emac_bd *rxbd = &priv->rxbd[*last_rx_bd];\r\nstruct buffer_state *rx_buff = &priv->rx_buff[*last_rx_bd];\r\nrx_buff->skb = netdev_alloc_skb_ip_align(ndev,\r\nEMAC_BUFFER_SIZE);\r\nif (unlikely(!rx_buff->skb))\r\nreturn -ENOMEM;\r\naddr = dma_map_single(&ndev->dev, (void *)rx_buff->skb->data,\r\nEMAC_BUFFER_SIZE, DMA_FROM_DEVICE);\r\nif (dma_mapping_error(&ndev->dev, addr)) {\r\nnetdev_err(ndev, "cannot dma map\n");\r\ndev_kfree_skb(rx_buff->skb);\r\nreturn -ENOMEM;\r\n}\r\ndma_unmap_addr_set(rx_buff, addr, addr);\r\ndma_unmap_len_set(rx_buff, len, EMAC_BUFFER_SIZE);\r\nrxbd->data = cpu_to_le32(addr);\r\nwmb();\r\nrxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\r\n*last_rx_bd = (*last_rx_bd + 1) % RX_BD_NUM;\r\n}\r\nmemset(priv->txbd, 0, TX_RING_SZ);\r\narc_reg_set(priv, R_LAFL, 0);\r\narc_reg_set(priv, R_LAFH, 0);\r\narc_reg_set(priv, R_RX_RING, (unsigned int)priv->rxbd_dma);\r\narc_reg_set(priv, R_TX_RING, (unsigned int)priv->txbd_dma);\r\narc_reg_set(priv, R_ENABLE, RXINT_MASK | TXINT_MASK | ERR_MASK);\r\narc_reg_set(priv, R_CTRL,\r\n(RX_BD_NUM << 24) |\r\n(TX_BD_NUM << 16) |\r\nTXRN_MASK | RXRN_MASK);\r\nnapi_enable(&priv->napi);\r\narc_reg_or(priv, R_CTRL, EN_MASK);\r\nphy_start_aneg(priv->phy_dev);\r\nnetif_start_queue(ndev);\r\nreturn 0;\r\n}\r\nstatic void arc_emac_set_rx_mode(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nif (ndev->flags & IFF_PROMISC) {\r\narc_reg_or(priv, R_CTRL, PROM_MASK);\r\n} else {\r\narc_reg_clr(priv, R_CTRL, PROM_MASK);\r\nif (ndev->flags & IFF_ALLMULTI) {\r\narc_reg_set(priv, R_LAFL, ~0);\r\narc_reg_set(priv, R_LAFH, ~0);\r\n} else {\r\nstruct netdev_hw_addr *ha;\r\nunsigned int filter[2] = { 0, 0 };\r\nint bit;\r\nnetdev_for_each_mc_addr(ha, ndev) {\r\nbit = ether_crc_le(ETH_ALEN, ha->addr) >> 26;\r\nfilter[bit >> 5] |= 1 << (bit & 31);\r\n}\r\narc_reg_set(priv, R_LAFL, filter[0]);\r\narc_reg_set(priv, R_LAFH, filter[1]);\r\n}\r\n}\r\n}\r\nstatic int arc_emac_stop(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nnapi_disable(&priv->napi);\r\nnetif_stop_queue(ndev);\r\narc_reg_clr(priv, R_ENABLE, RXINT_MASK | TXINT_MASK | ERR_MASK);\r\narc_reg_clr(priv, R_CTRL, EN_MASK);\r\nreturn 0;\r\n}\r\nstatic struct net_device_stats *arc_emac_stats(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nstruct net_device_stats *stats = &ndev->stats;\r\nunsigned long miss, rxerr;\r\nu8 rxcrc, rxfram, rxoflow;\r\nrxerr = arc_reg_get(priv, R_RXERR);\r\nmiss = arc_reg_get(priv, R_MISS);\r\nrxcrc = rxerr;\r\nrxfram = rxerr >> 8;\r\nrxoflow = rxerr >> 16;\r\nstats->rx_errors += miss;\r\nstats->rx_errors += rxcrc + rxfram + rxoflow;\r\nstats->rx_over_errors += rxoflow;\r\nstats->rx_frame_errors += rxfram;\r\nstats->rx_crc_errors += rxcrc;\r\nstats->rx_missed_errors += miss;\r\nreturn stats;\r\n}\r\nstatic int arc_emac_tx(struct sk_buff *skb, struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nunsigned int len, *txbd_curr = &priv->txbd_curr;\r\nstruct net_device_stats *stats = &ndev->stats;\r\n__le32 *info = &priv->txbd[*txbd_curr].info;\r\ndma_addr_t addr;\r\nif (skb_padto(skb, ETH_ZLEN))\r\nreturn NETDEV_TX_OK;\r\nlen = max_t(unsigned int, ETH_ZLEN, skb->len);\r\nif (unlikely(!arc_emac_tx_avail(priv))) {\r\nnetif_stop_queue(ndev);\r\nnetdev_err(ndev, "BUG! Tx Ring full when queue awake!\n");\r\nreturn NETDEV_TX_BUSY;\r\n}\r\naddr = dma_map_single(&ndev->dev, (void *)skb->data, len,\r\nDMA_TO_DEVICE);\r\nif (unlikely(dma_mapping_error(&ndev->dev, addr))) {\r\nstats->tx_dropped++;\r\nstats->tx_errors++;\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\ndma_unmap_addr_set(&priv->tx_buff[*txbd_curr], addr, addr);\r\ndma_unmap_len_set(&priv->tx_buff[*txbd_curr], len, len);\r\npriv->tx_buff[*txbd_curr].skb = skb;\r\npriv->txbd[*txbd_curr].data = cpu_to_le32(addr);\r\nwmb();\r\nskb_tx_timestamp(skb);\r\n*info = cpu_to_le32(FOR_EMAC | FIRST_OR_LAST_MASK | len);\r\n*txbd_curr = (*txbd_curr + 1) % TX_BD_NUM;\r\nsmp_mb();\r\nif (!arc_emac_tx_avail(priv)) {\r\nnetif_stop_queue(ndev);\r\nsmp_mb();\r\nif (arc_emac_tx_avail(priv))\r\nnetif_start_queue(ndev);\r\n}\r\narc_reg_set(priv, R_STATUS, TXPL_MASK);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void arc_emac_set_address_internal(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nunsigned int addr_low, addr_hi;\r\naddr_low = le32_to_cpu(*(__le32 *) &ndev->dev_addr[0]);\r\naddr_hi = le16_to_cpu(*(__le16 *) &ndev->dev_addr[4]);\r\narc_reg_set(priv, R_ADDRL, addr_low);\r\narc_reg_set(priv, R_ADDRH, addr_hi);\r\n}\r\nstatic int arc_emac_set_address(struct net_device *ndev, void *p)\r\n{\r\nstruct sockaddr *addr = p;\r\nif (netif_running(ndev))\r\nreturn -EBUSY;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(ndev->dev_addr, addr->sa_data, ndev->addr_len);\r\narc_emac_set_address_internal(ndev);\r\nreturn 0;\r\n}\r\nint arc_emac_probe(struct net_device *ndev, int interface)\r\n{\r\nstruct device *dev = ndev->dev.parent;\r\nstruct resource res_regs;\r\nstruct device_node *phy_node;\r\nstruct arc_emac_priv *priv;\r\nconst char *mac_addr;\r\nunsigned int id, clock_frequency, irq;\r\nint err;\r\nphy_node = of_parse_phandle(dev->of_node, "phy", 0);\r\nif (!phy_node) {\r\ndev_err(dev, "failed to retrieve phy description from device tree\n");\r\nreturn -ENODEV;\r\n}\r\nerr = of_address_to_resource(dev->of_node, 0, &res_regs);\r\nif (err) {\r\ndev_err(dev, "failed to retrieve registers base from device tree\n");\r\nreturn -ENODEV;\r\n}\r\nirq = irq_of_parse_and_map(dev->of_node, 0);\r\nif (!irq) {\r\ndev_err(dev, "failed to retrieve <irq> value from device tree\n");\r\nreturn -ENODEV;\r\n}\r\nndev->netdev_ops = &arc_emac_netdev_ops;\r\nndev->ethtool_ops = &arc_emac_ethtool_ops;\r\nndev->watchdog_timeo = TX_TIMEOUT;\r\nndev->flags &= ~IFF_MULTICAST;\r\npriv = netdev_priv(ndev);\r\npriv->dev = dev;\r\npriv->regs = devm_ioremap_resource(dev, &res_regs);\r\nif (IS_ERR(priv->regs)) {\r\nreturn PTR_ERR(priv->regs);\r\n}\r\ndev_dbg(dev, "Registers base address is 0x%p\n", priv->regs);\r\nif (priv->clk) {\r\nerr = clk_prepare_enable(priv->clk);\r\nif (err) {\r\ndev_err(dev, "failed to enable clock\n");\r\nreturn err;\r\n}\r\nclock_frequency = clk_get_rate(priv->clk);\r\n} else {\r\nif (of_property_read_u32(dev->of_node, "clock-frequency",\r\n&clock_frequency)) {\r\ndev_err(dev, "failed to retrieve <clock-frequency> from device tree\n");\r\nreturn -EINVAL;\r\n}\r\n}\r\nid = arc_reg_get(priv, R_ID);\r\nif (!(id == 0x0005fd02 || id == 0x0007fd02)) {\r\ndev_err(dev, "ARC EMAC not detected, id=0x%x\n", id);\r\nerr = -ENODEV;\r\ngoto out_clken;\r\n}\r\ndev_info(dev, "ARC EMAC detected with id: 0x%x\n", id);\r\narc_reg_set(priv, R_POLLRATE, clock_frequency / 1000000);\r\nndev->irq = irq;\r\ndev_info(dev, "IRQ is %d\n", ndev->irq);\r\nerr = devm_request_irq(dev, ndev->irq, arc_emac_intr, 0,\r\nndev->name, ndev);\r\nif (err) {\r\ndev_err(dev, "could not allocate IRQ\n");\r\ngoto out_clken;\r\n}\r\nmac_addr = of_get_mac_address(dev->of_node);\r\nif (mac_addr)\r\nmemcpy(ndev->dev_addr, mac_addr, ETH_ALEN);\r\nelse\r\neth_hw_addr_random(ndev);\r\narc_emac_set_address_internal(ndev);\r\ndev_info(dev, "MAC address is now %pM\n", ndev->dev_addr);\r\npriv->rxbd = dmam_alloc_coherent(dev, RX_RING_SZ + TX_RING_SZ,\r\n&priv->rxbd_dma, GFP_KERNEL);\r\nif (!priv->rxbd) {\r\ndev_err(dev, "failed to allocate data buffers\n");\r\nerr = -ENOMEM;\r\ngoto out_clken;\r\n}\r\npriv->txbd = priv->rxbd + RX_BD_NUM;\r\npriv->txbd_dma = priv->rxbd_dma + RX_RING_SZ;\r\ndev_dbg(dev, "EMAC Device addr: Rx Ring [0x%x], Tx Ring[%x]\n",\r\n(unsigned int)priv->rxbd_dma, (unsigned int)priv->txbd_dma);\r\nerr = arc_mdio_probe(priv);\r\nif (err) {\r\ndev_err(dev, "failed to probe MII bus\n");\r\ngoto out_clken;\r\n}\r\npriv->phy_dev = of_phy_connect(ndev, phy_node, arc_emac_adjust_link, 0,\r\ninterface);\r\nif (!priv->phy_dev) {\r\ndev_err(dev, "of_phy_connect() failed\n");\r\nerr = -ENODEV;\r\ngoto out_mdio;\r\n}\r\ndev_info(dev, "connected to %s phy with id 0x%x\n",\r\npriv->phy_dev->drv->name, priv->phy_dev->phy_id);\r\nnetif_napi_add(ndev, &priv->napi, arc_emac_poll, ARC_EMAC_NAPI_WEIGHT);\r\nerr = register_netdev(ndev);\r\nif (err) {\r\ndev_err(dev, "failed to register network device\n");\r\ngoto out_netif_api;\r\n}\r\nreturn 0;\r\nout_netif_api:\r\nnetif_napi_del(&priv->napi);\r\nphy_disconnect(priv->phy_dev);\r\npriv->phy_dev = NULL;\r\nout_mdio:\r\narc_mdio_remove(priv);\r\nout_clken:\r\nif (priv->clk)\r\nclk_disable_unprepare(priv->clk);\r\nreturn err;\r\n}\r\nint arc_emac_remove(struct net_device *ndev)\r\n{\r\nstruct arc_emac_priv *priv = netdev_priv(ndev);\r\nphy_disconnect(priv->phy_dev);\r\npriv->phy_dev = NULL;\r\narc_mdio_remove(priv);\r\nunregister_netdev(ndev);\r\nnetif_napi_del(&priv->napi);\r\nif (!IS_ERR(priv->clk)) {\r\nclk_disable_unprepare(priv->clk);\r\n}\r\nreturn 0;\r\n}
