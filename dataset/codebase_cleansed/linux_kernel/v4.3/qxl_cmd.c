void qxl_ring_free(struct qxl_ring *ring)\r\n{\r\nkfree(ring);\r\n}\r\nvoid qxl_ring_init_hdr(struct qxl_ring *ring)\r\n{\r\nring->ring->header.notify_on_prod = ring->n_elements;\r\n}\r\nstruct qxl_ring *\r\nqxl_ring_create(struct qxl_ring_header *header,\r\nint element_size,\r\nint n_elements,\r\nint prod_notify,\r\nbool set_prod_notify,\r\nwait_queue_head_t *push_event)\r\n{\r\nstruct qxl_ring *ring;\r\nring = kmalloc(sizeof(*ring), GFP_KERNEL);\r\nif (!ring)\r\nreturn NULL;\r\nring->ring = (struct ring *)header;\r\nring->element_size = element_size;\r\nring->n_elements = n_elements;\r\nring->prod_notify = prod_notify;\r\nring->push_event = push_event;\r\nif (set_prod_notify)\r\nqxl_ring_init_hdr(ring);\r\nspin_lock_init(&ring->lock);\r\nreturn ring;\r\n}\r\nstatic int qxl_check_header(struct qxl_ring *ring)\r\n{\r\nint ret;\r\nstruct qxl_ring_header *header = &(ring->ring->header);\r\nunsigned long flags;\r\nspin_lock_irqsave(&ring->lock, flags);\r\nret = header->prod - header->cons < header->num_items;\r\nif (ret == 0)\r\nheader->notify_on_cons = header->cons + 1;\r\nspin_unlock_irqrestore(&ring->lock, flags);\r\nreturn ret;\r\n}\r\nint qxl_check_idle(struct qxl_ring *ring)\r\n{\r\nint ret;\r\nstruct qxl_ring_header *header = &(ring->ring->header);\r\nunsigned long flags;\r\nspin_lock_irqsave(&ring->lock, flags);\r\nret = header->prod == header->cons;\r\nspin_unlock_irqrestore(&ring->lock, flags);\r\nreturn ret;\r\n}\r\nint qxl_ring_push(struct qxl_ring *ring,\r\nconst void *new_elt, bool interruptible)\r\n{\r\nstruct qxl_ring_header *header = &(ring->ring->header);\r\nuint8_t *elt;\r\nint idx, ret;\r\nunsigned long flags;\r\nspin_lock_irqsave(&ring->lock, flags);\r\nif (header->prod - header->cons == header->num_items) {\r\nheader->notify_on_cons = header->cons + 1;\r\nmb();\r\nspin_unlock_irqrestore(&ring->lock, flags);\r\nif (!drm_can_sleep()) {\r\nwhile (!qxl_check_header(ring))\r\nudelay(1);\r\n} else {\r\nif (interruptible) {\r\nret = wait_event_interruptible(*ring->push_event,\r\nqxl_check_header(ring));\r\nif (ret)\r\nreturn ret;\r\n} else {\r\nwait_event(*ring->push_event,\r\nqxl_check_header(ring));\r\n}\r\n}\r\nspin_lock_irqsave(&ring->lock, flags);\r\n}\r\nidx = header->prod & (ring->n_elements - 1);\r\nelt = ring->ring->elements + idx * ring->element_size;\r\nmemcpy((void *)elt, new_elt, ring->element_size);\r\nheader->prod++;\r\nmb();\r\nif (header->prod == header->notify_on_prod)\r\noutb(0, ring->prod_notify);\r\nspin_unlock_irqrestore(&ring->lock, flags);\r\nreturn 0;\r\n}\r\nstatic bool qxl_ring_pop(struct qxl_ring *ring,\r\nvoid *element)\r\n{\r\nvolatile struct qxl_ring_header *header = &(ring->ring->header);\r\nvolatile uint8_t *ring_elt;\r\nint idx;\r\nunsigned long flags;\r\nspin_lock_irqsave(&ring->lock, flags);\r\nif (header->cons == header->prod) {\r\nheader->notify_on_prod = header->cons + 1;\r\nspin_unlock_irqrestore(&ring->lock, flags);\r\nreturn false;\r\n}\r\nidx = header->cons & (ring->n_elements - 1);\r\nring_elt = ring->ring->elements + idx * ring->element_size;\r\nmemcpy(element, (void *)ring_elt, ring->element_size);\r\nheader->cons++;\r\nspin_unlock_irqrestore(&ring->lock, flags);\r\nreturn true;\r\n}\r\nint\r\nqxl_push_command_ring_release(struct qxl_device *qdev, struct qxl_release *release,\r\nuint32_t type, bool interruptible)\r\n{\r\nstruct qxl_command cmd;\r\nstruct qxl_bo_list *entry = list_first_entry(&release->bos, struct qxl_bo_list, tv.head);\r\ncmd.type = type;\r\ncmd.data = qxl_bo_physical_address(qdev, to_qxl_bo(entry->tv.bo), release->release_offset);\r\nreturn qxl_ring_push(qdev->command_ring, &cmd, interruptible);\r\n}\r\nint\r\nqxl_push_cursor_ring_release(struct qxl_device *qdev, struct qxl_release *release,\r\nuint32_t type, bool interruptible)\r\n{\r\nstruct qxl_command cmd;\r\nstruct qxl_bo_list *entry = list_first_entry(&release->bos, struct qxl_bo_list, tv.head);\r\ncmd.type = type;\r\ncmd.data = qxl_bo_physical_address(qdev, to_qxl_bo(entry->tv.bo), release->release_offset);\r\nreturn qxl_ring_push(qdev->cursor_ring, &cmd, interruptible);\r\n}\r\nbool qxl_queue_garbage_collect(struct qxl_device *qdev, bool flush)\r\n{\r\nif (!qxl_check_idle(qdev->release_ring)) {\r\nqueue_work(qdev->gc_queue, &qdev->gc_work);\r\nif (flush)\r\nflush_work(&qdev->gc_work);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nint qxl_garbage_collect(struct qxl_device *qdev)\r\n{\r\nstruct qxl_release *release;\r\nuint64_t id, next_id;\r\nint i = 0;\r\nunion qxl_release_info *info;\r\nwhile (qxl_ring_pop(qdev->release_ring, &id)) {\r\nQXL_INFO(qdev, "popped %lld\n", id);\r\nwhile (id) {\r\nrelease = qxl_release_from_id_locked(qdev, id);\r\nif (release == NULL)\r\nbreak;\r\ninfo = qxl_release_map(qdev, release);\r\nnext_id = info->next;\r\nqxl_release_unmap(qdev, release, info);\r\nQXL_INFO(qdev, "popped %lld, next %lld\n", id,\r\nnext_id);\r\nswitch (release->type) {\r\ncase QXL_RELEASE_DRAWABLE:\r\ncase QXL_RELEASE_SURFACE_CMD:\r\ncase QXL_RELEASE_CURSOR_CMD:\r\nbreak;\r\ndefault:\r\nDRM_ERROR("unexpected release type\n");\r\nbreak;\r\n}\r\nid = next_id;\r\nqxl_release_free(qdev, release);\r\n++i;\r\n}\r\n}\r\nQXL_INFO(qdev, "%s: %d\n", __func__, i);\r\nreturn i;\r\n}\r\nint qxl_alloc_bo_reserved(struct qxl_device *qdev,\r\nstruct qxl_release *release,\r\nunsigned long size,\r\nstruct qxl_bo **_bo)\r\n{\r\nstruct qxl_bo *bo;\r\nint ret;\r\nret = qxl_bo_create(qdev, size, false ,\r\nfalse, QXL_GEM_DOMAIN_VRAM, NULL, &bo);\r\nif (ret) {\r\nDRM_ERROR("failed to allocate VRAM BO\n");\r\nreturn ret;\r\n}\r\nret = qxl_release_list_add(release, bo);\r\nif (ret)\r\ngoto out_unref;\r\n*_bo = bo;\r\nreturn 0;\r\nout_unref:\r\nqxl_bo_unref(&bo);\r\nreturn ret;\r\n}\r\nstatic int wait_for_io_cmd_user(struct qxl_device *qdev, uint8_t val, long port, bool intr)\r\n{\r\nint irq_num;\r\nlong addr = qdev->io_base + port;\r\nint ret;\r\nmutex_lock(&qdev->async_io_mutex);\r\nirq_num = atomic_read(&qdev->irq_received_io_cmd);\r\nif (qdev->last_sent_io_cmd > irq_num) {\r\nif (intr)\r\nret = wait_event_interruptible_timeout(qdev->io_cmd_event,\r\natomic_read(&qdev->irq_received_io_cmd) > irq_num, 5*HZ);\r\nelse\r\nret = wait_event_timeout(qdev->io_cmd_event,\r\natomic_read(&qdev->irq_received_io_cmd) > irq_num, 5*HZ);\r\nif (ret <= 0)\r\ngoto out;\r\nirq_num = atomic_read(&qdev->irq_received_io_cmd);\r\n}\r\noutb(val, addr);\r\nqdev->last_sent_io_cmd = irq_num + 1;\r\nif (intr)\r\nret = wait_event_interruptible_timeout(qdev->io_cmd_event,\r\natomic_read(&qdev->irq_received_io_cmd) > irq_num, 5*HZ);\r\nelse\r\nret = wait_event_timeout(qdev->io_cmd_event,\r\natomic_read(&qdev->irq_received_io_cmd) > irq_num, 5*HZ);\r\nout:\r\nif (ret > 0)\r\nret = 0;\r\nmutex_unlock(&qdev->async_io_mutex);\r\nreturn ret;\r\n}\r\nstatic void wait_for_io_cmd(struct qxl_device *qdev, uint8_t val, long port)\r\n{\r\nint ret;\r\nrestart:\r\nret = wait_for_io_cmd_user(qdev, val, port, false);\r\nif (ret == -ERESTARTSYS)\r\ngoto restart;\r\n}\r\nint qxl_io_update_area(struct qxl_device *qdev, struct qxl_bo *surf,\r\nconst struct qxl_rect *area)\r\n{\r\nint surface_id;\r\nuint32_t surface_width, surface_height;\r\nint ret;\r\nif (!surf->hw_surf_alloc)\r\nDRM_ERROR("got io update area with no hw surface\n");\r\nif (surf->is_primary)\r\nsurface_id = 0;\r\nelse\r\nsurface_id = surf->surface_id;\r\nsurface_width = surf->surf.width;\r\nsurface_height = surf->surf.height;\r\nif (area->left < 0 || area->top < 0 ||\r\narea->right > surface_width || area->bottom > surface_height) {\r\nqxl_io_log(qdev, "%s: not doing area update for "\r\n"%d, (%d,%d,%d,%d) (%d,%d)\n", __func__, surface_id, area->left,\r\narea->top, area->right, area->bottom, surface_width, surface_height);\r\nreturn -EINVAL;\r\n}\r\nmutex_lock(&qdev->update_area_mutex);\r\nqdev->ram_header->update_area = *area;\r\nqdev->ram_header->update_surface = surface_id;\r\nret = wait_for_io_cmd_user(qdev, 0, QXL_IO_UPDATE_AREA_ASYNC, true);\r\nmutex_unlock(&qdev->update_area_mutex);\r\nreturn ret;\r\n}\r\nvoid qxl_io_notify_oom(struct qxl_device *qdev)\r\n{\r\noutb(0, qdev->io_base + QXL_IO_NOTIFY_OOM);\r\n}\r\nvoid qxl_io_flush_release(struct qxl_device *qdev)\r\n{\r\noutb(0, qdev->io_base + QXL_IO_FLUSH_RELEASE);\r\n}\r\nvoid qxl_io_flush_surfaces(struct qxl_device *qdev)\r\n{\r\nwait_for_io_cmd(qdev, 0, QXL_IO_FLUSH_SURFACES_ASYNC);\r\n}\r\nvoid qxl_io_destroy_primary(struct qxl_device *qdev)\r\n{\r\nwait_for_io_cmd(qdev, 0, QXL_IO_DESTROY_PRIMARY_ASYNC);\r\n}\r\nvoid qxl_io_create_primary(struct qxl_device *qdev,\r\nunsigned offset, struct qxl_bo *bo)\r\n{\r\nstruct qxl_surface_create *create;\r\nQXL_INFO(qdev, "%s: qdev %p, ram_header %p\n", __func__, qdev,\r\nqdev->ram_header);\r\ncreate = &qdev->ram_header->create_surface;\r\ncreate->format = bo->surf.format;\r\ncreate->width = bo->surf.width;\r\ncreate->height = bo->surf.height;\r\ncreate->stride = bo->surf.stride;\r\ncreate->mem = qxl_bo_physical_address(qdev, bo, offset);\r\nQXL_INFO(qdev, "%s: mem = %llx, from %p\n", __func__, create->mem,\r\nbo->kptr);\r\ncreate->flags = QXL_SURF_FLAG_KEEP_DATA;\r\ncreate->type = QXL_SURF_TYPE_PRIMARY;\r\nwait_for_io_cmd(qdev, 0, QXL_IO_CREATE_PRIMARY_ASYNC);\r\n}\r\nvoid qxl_io_memslot_add(struct qxl_device *qdev, uint8_t id)\r\n{\r\nQXL_INFO(qdev, "qxl_memslot_add %d\n", id);\r\nwait_for_io_cmd(qdev, id, QXL_IO_MEMSLOT_ADD_ASYNC);\r\n}\r\nvoid qxl_io_log(struct qxl_device *qdev, const char *fmt, ...)\r\n{\r\nva_list args;\r\nva_start(args, fmt);\r\nvsnprintf(qdev->ram_header->log_buf, QXL_LOG_BUF_SIZE, fmt, args);\r\nva_end(args);\r\noutb(0, qdev->io_base + QXL_IO_LOG);\r\n}\r\nvoid qxl_io_reset(struct qxl_device *qdev)\r\n{\r\noutb(0, qdev->io_base + QXL_IO_RESET);\r\n}\r\nvoid qxl_io_monitors_config(struct qxl_device *qdev)\r\n{\r\nqxl_io_log(qdev, "%s: %d [%dx%d+%d+%d]\n", __func__,\r\nqdev->monitors_config ?\r\nqdev->monitors_config->count : -1,\r\nqdev->monitors_config && qdev->monitors_config->count ?\r\nqdev->monitors_config->heads[0].width : -1,\r\nqdev->monitors_config && qdev->monitors_config->count ?\r\nqdev->monitors_config->heads[0].height : -1,\r\nqdev->monitors_config && qdev->monitors_config->count ?\r\nqdev->monitors_config->heads[0].x : -1,\r\nqdev->monitors_config && qdev->monitors_config->count ?\r\nqdev->monitors_config->heads[0].y : -1\r\n);\r\nwait_for_io_cmd(qdev, 0, QXL_IO_MONITORS_CONFIG_ASYNC);\r\n}\r\nint qxl_surface_id_alloc(struct qxl_device *qdev,\r\nstruct qxl_bo *surf)\r\n{\r\nuint32_t handle;\r\nint idr_ret;\r\nint count = 0;\r\nagain:\r\nidr_preload(GFP_ATOMIC);\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nidr_ret = idr_alloc(&qdev->surf_id_idr, NULL, 1, 0, GFP_NOWAIT);\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\nidr_preload_end();\r\nif (idr_ret < 0)\r\nreturn idr_ret;\r\nhandle = idr_ret;\r\nif (handle >= qdev->rom->n_surfaces) {\r\ncount++;\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nidr_remove(&qdev->surf_id_idr, handle);\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\nqxl_reap_surface_id(qdev, 2);\r\ngoto again;\r\n}\r\nsurf->surface_id = handle;\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nqdev->last_alloced_surf_id = handle;\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\nreturn 0;\r\n}\r\nvoid qxl_surface_id_dealloc(struct qxl_device *qdev,\r\nuint32_t surface_id)\r\n{\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nidr_remove(&qdev->surf_id_idr, surface_id);\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\n}\r\nint qxl_hw_surface_alloc(struct qxl_device *qdev,\r\nstruct qxl_bo *surf,\r\nstruct ttm_mem_reg *new_mem)\r\n{\r\nstruct qxl_surface_cmd *cmd;\r\nstruct qxl_release *release;\r\nint ret;\r\nif (surf->hw_surf_alloc)\r\nreturn 0;\r\nret = qxl_alloc_surface_release_reserved(qdev, QXL_SURFACE_CMD_CREATE,\r\nNULL,\r\n&release);\r\nif (ret)\r\nreturn ret;\r\nret = qxl_release_reserve_list(release, true);\r\nif (ret)\r\nreturn ret;\r\ncmd = (struct qxl_surface_cmd *)qxl_release_map(qdev, release);\r\ncmd->type = QXL_SURFACE_CMD_CREATE;\r\ncmd->flags = QXL_SURF_FLAG_KEEP_DATA;\r\ncmd->u.surface_create.format = surf->surf.format;\r\ncmd->u.surface_create.width = surf->surf.width;\r\ncmd->u.surface_create.height = surf->surf.height;\r\ncmd->u.surface_create.stride = surf->surf.stride;\r\nif (new_mem) {\r\nint slot_id = surf->type == QXL_GEM_DOMAIN_VRAM ? qdev->main_mem_slot : qdev->surfaces_mem_slot;\r\nstruct qxl_memslot *slot = &(qdev->mem_slots[slot_id]);\r\ncmd->u.surface_create.data = slot->high_bits;\r\ncmd->u.surface_create.data |= (new_mem->start << PAGE_SHIFT) + surf->tbo.bdev->man[new_mem->mem_type].gpu_offset;\r\n} else\r\ncmd->u.surface_create.data = qxl_bo_physical_address(qdev, surf, 0);\r\ncmd->surface_id = surf->surface_id;\r\nqxl_release_unmap(qdev, release, &cmd->release_info);\r\nsurf->surf_create = release;\r\nqxl_push_command_ring_release(qdev, release, QXL_CMD_SURFACE, false);\r\nqxl_release_fence_buffer_objects(release);\r\nsurf->hw_surf_alloc = true;\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nidr_replace(&qdev->surf_id_idr, surf, surf->surface_id);\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\nreturn 0;\r\n}\r\nint qxl_hw_surface_dealloc(struct qxl_device *qdev,\r\nstruct qxl_bo *surf)\r\n{\r\nstruct qxl_surface_cmd *cmd;\r\nstruct qxl_release *release;\r\nint ret;\r\nint id;\r\nif (!surf->hw_surf_alloc)\r\nreturn 0;\r\nret = qxl_alloc_surface_release_reserved(qdev, QXL_SURFACE_CMD_DESTROY,\r\nsurf->surf_create,\r\n&release);\r\nif (ret)\r\nreturn ret;\r\nsurf->surf_create = NULL;\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nidr_replace(&qdev->surf_id_idr, NULL, surf->surface_id);\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\nsurf->hw_surf_alloc = false;\r\nid = surf->surface_id;\r\nsurf->surface_id = 0;\r\nrelease->surface_release_id = id;\r\ncmd = (struct qxl_surface_cmd *)qxl_release_map(qdev, release);\r\ncmd->type = QXL_SURFACE_CMD_DESTROY;\r\ncmd->surface_id = id;\r\nqxl_release_unmap(qdev, release, &cmd->release_info);\r\nqxl_push_command_ring_release(qdev, release, QXL_CMD_SURFACE, false);\r\nqxl_release_fence_buffer_objects(release);\r\nreturn 0;\r\n}\r\nint qxl_update_surface(struct qxl_device *qdev, struct qxl_bo *surf)\r\n{\r\nstruct qxl_rect rect;\r\nint ret;\r\nrect.left = 0;\r\nrect.right = surf->surf.width;\r\nrect.top = 0;\r\nrect.bottom = surf->surf.height;\r\nretry:\r\nret = qxl_io_update_area(qdev, surf, &rect);\r\nif (ret == -ERESTARTSYS)\r\ngoto retry;\r\nreturn ret;\r\n}\r\nstatic void qxl_surface_evict_locked(struct qxl_device *qdev, struct qxl_bo *surf, bool do_update_area)\r\n{\r\nif (do_update_area)\r\nqxl_update_surface(qdev, surf);\r\nqxl_hw_surface_dealloc(qdev, surf);\r\n}\r\nvoid qxl_surface_evict(struct qxl_device *qdev, struct qxl_bo *surf, bool do_update_area)\r\n{\r\nmutex_lock(&qdev->surf_evict_mutex);\r\nqxl_surface_evict_locked(qdev, surf, do_update_area);\r\nmutex_unlock(&qdev->surf_evict_mutex);\r\n}\r\nstatic int qxl_reap_surf(struct qxl_device *qdev, struct qxl_bo *surf, bool stall)\r\n{\r\nint ret;\r\nret = qxl_bo_reserve(surf, false);\r\nif (ret)\r\nreturn ret;\r\nif (stall)\r\nmutex_unlock(&qdev->surf_evict_mutex);\r\nret = ttm_bo_wait(&surf->tbo, true, true, !stall);\r\nif (stall)\r\nmutex_lock(&qdev->surf_evict_mutex);\r\nif (ret) {\r\nqxl_bo_unreserve(surf);\r\nreturn ret;\r\n}\r\nqxl_surface_evict_locked(qdev, surf, true);\r\nqxl_bo_unreserve(surf);\r\nreturn 0;\r\n}\r\nstatic int qxl_reap_surface_id(struct qxl_device *qdev, int max_to_reap)\r\n{\r\nint num_reaped = 0;\r\nint i, ret;\r\nbool stall = false;\r\nint start = 0;\r\nmutex_lock(&qdev->surf_evict_mutex);\r\nagain:\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nstart = qdev->last_alloced_surf_id + 1;\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\nfor (i = start; i < start + qdev->rom->n_surfaces; i++) {\r\nvoid *objptr;\r\nint surfid = i % qdev->rom->n_surfaces;\r\nspin_lock(&qdev->surf_id_idr_lock);\r\nobjptr = idr_find(&qdev->surf_id_idr, surfid);\r\nspin_unlock(&qdev->surf_id_idr_lock);\r\nif (!objptr)\r\ncontinue;\r\nret = qxl_reap_surf(qdev, objptr, stall);\r\nif (ret == 0)\r\nnum_reaped++;\r\nif (num_reaped >= max_to_reap)\r\nbreak;\r\n}\r\nif (num_reaped == 0 && stall == false) {\r\nstall = true;\r\ngoto again;\r\n}\r\nmutex_unlock(&qdev->surf_evict_mutex);\r\nif (num_reaped) {\r\nusleep_range(500, 1000);\r\nqxl_queue_garbage_collect(qdev, true);\r\n}\r\nreturn 0;\r\n}
