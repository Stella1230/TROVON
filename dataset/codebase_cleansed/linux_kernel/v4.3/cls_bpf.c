static int cls_bpf_classify(struct sk_buff *skb, const struct tcf_proto *tp,\r\nstruct tcf_result *res)\r\n{\r\nstruct cls_bpf_head *head = rcu_dereference_bh(tp->root);\r\nstruct cls_bpf_prog *prog;\r\n#ifdef CONFIG_NET_CLS_ACT\r\nbool at_ingress = G_TC_AT(skb->tc_verd) & AT_INGRESS;\r\n#else\r\nbool at_ingress = false;\r\n#endif\r\nint ret = -1;\r\nif (unlikely(!skb_mac_header_was_set(skb)))\r\nreturn -1;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(prog, &head->plist, link) {\r\nint filter_res;\r\nif (at_ingress) {\r\n__skb_push(skb, skb->mac_len);\r\nfilter_res = BPF_PROG_RUN(prog->filter, skb);\r\n__skb_pull(skb, skb->mac_len);\r\n} else {\r\nfilter_res = BPF_PROG_RUN(prog->filter, skb);\r\n}\r\nif (filter_res == 0)\r\ncontinue;\r\n*res = prog->res;\r\nif (filter_res != -1)\r\nres->classid = filter_res;\r\nret = tcf_exts_exec(skb, &prog->exts, res);\r\nif (ret < 0)\r\ncontinue;\r\nbreak;\r\n}\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nstatic bool cls_bpf_is_ebpf(const struct cls_bpf_prog *prog)\r\n{\r\nreturn !prog->bpf_ops;\r\n}\r\nstatic int cls_bpf_init(struct tcf_proto *tp)\r\n{\r\nstruct cls_bpf_head *head;\r\nhead = kzalloc(sizeof(*head), GFP_KERNEL);\r\nif (head == NULL)\r\nreturn -ENOBUFS;\r\nINIT_LIST_HEAD_RCU(&head->plist);\r\nrcu_assign_pointer(tp->root, head);\r\nreturn 0;\r\n}\r\nstatic void cls_bpf_delete_prog(struct tcf_proto *tp, struct cls_bpf_prog *prog)\r\n{\r\ntcf_exts_destroy(&prog->exts);\r\nif (cls_bpf_is_ebpf(prog))\r\nbpf_prog_put(prog->filter);\r\nelse\r\nbpf_prog_destroy(prog->filter);\r\nkfree(prog->bpf_name);\r\nkfree(prog->bpf_ops);\r\nkfree(prog);\r\n}\r\nstatic void __cls_bpf_delete_prog(struct rcu_head *rcu)\r\n{\r\nstruct cls_bpf_prog *prog = container_of(rcu, struct cls_bpf_prog, rcu);\r\ncls_bpf_delete_prog(prog->tp, prog);\r\n}\r\nstatic int cls_bpf_delete(struct tcf_proto *tp, unsigned long arg)\r\n{\r\nstruct cls_bpf_prog *prog = (struct cls_bpf_prog *) arg;\r\nlist_del_rcu(&prog->link);\r\ntcf_unbind_filter(tp, &prog->res);\r\ncall_rcu(&prog->rcu, __cls_bpf_delete_prog);\r\nreturn 0;\r\n}\r\nstatic bool cls_bpf_destroy(struct tcf_proto *tp, bool force)\r\n{\r\nstruct cls_bpf_head *head = rtnl_dereference(tp->root);\r\nstruct cls_bpf_prog *prog, *tmp;\r\nif (!force && !list_empty(&head->plist))\r\nreturn false;\r\nlist_for_each_entry_safe(prog, tmp, &head->plist, link) {\r\nlist_del_rcu(&prog->link);\r\ntcf_unbind_filter(tp, &prog->res);\r\ncall_rcu(&prog->rcu, __cls_bpf_delete_prog);\r\n}\r\nRCU_INIT_POINTER(tp->root, NULL);\r\nkfree_rcu(head, rcu);\r\nreturn true;\r\n}\r\nstatic unsigned long cls_bpf_get(struct tcf_proto *tp, u32 handle)\r\n{\r\nstruct cls_bpf_head *head = rtnl_dereference(tp->root);\r\nstruct cls_bpf_prog *prog;\r\nunsigned long ret = 0UL;\r\nif (head == NULL)\r\nreturn 0UL;\r\nlist_for_each_entry(prog, &head->plist, link) {\r\nif (prog->handle == handle) {\r\nret = (unsigned long) prog;\r\nbreak;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int cls_bpf_prog_from_ops(struct nlattr **tb,\r\nstruct cls_bpf_prog *prog, u32 classid)\r\n{\r\nstruct sock_filter *bpf_ops;\r\nstruct sock_fprog_kern fprog_tmp;\r\nstruct bpf_prog *fp;\r\nu16 bpf_size, bpf_num_ops;\r\nint ret;\r\nbpf_num_ops = nla_get_u16(tb[TCA_BPF_OPS_LEN]);\r\nif (bpf_num_ops > BPF_MAXINSNS || bpf_num_ops == 0)\r\nreturn -EINVAL;\r\nbpf_size = bpf_num_ops * sizeof(*bpf_ops);\r\nif (bpf_size != nla_len(tb[TCA_BPF_OPS]))\r\nreturn -EINVAL;\r\nbpf_ops = kzalloc(bpf_size, GFP_KERNEL);\r\nif (bpf_ops == NULL)\r\nreturn -ENOMEM;\r\nmemcpy(bpf_ops, nla_data(tb[TCA_BPF_OPS]), bpf_size);\r\nfprog_tmp.len = bpf_num_ops;\r\nfprog_tmp.filter = bpf_ops;\r\nret = bpf_prog_create(&fp, &fprog_tmp);\r\nif (ret < 0) {\r\nkfree(bpf_ops);\r\nreturn ret;\r\n}\r\nprog->bpf_ops = bpf_ops;\r\nprog->bpf_num_ops = bpf_num_ops;\r\nprog->bpf_name = NULL;\r\nprog->filter = fp;\r\nprog->res.classid = classid;\r\nreturn 0;\r\n}\r\nstatic int cls_bpf_prog_from_efd(struct nlattr **tb,\r\nstruct cls_bpf_prog *prog, u32 classid)\r\n{\r\nstruct bpf_prog *fp;\r\nchar *name = NULL;\r\nu32 bpf_fd;\r\nbpf_fd = nla_get_u32(tb[TCA_BPF_FD]);\r\nfp = bpf_prog_get(bpf_fd);\r\nif (IS_ERR(fp))\r\nreturn PTR_ERR(fp);\r\nif (fp->type != BPF_PROG_TYPE_SCHED_CLS) {\r\nbpf_prog_put(fp);\r\nreturn -EINVAL;\r\n}\r\nif (tb[TCA_BPF_NAME]) {\r\nname = kmemdup(nla_data(tb[TCA_BPF_NAME]),\r\nnla_len(tb[TCA_BPF_NAME]),\r\nGFP_KERNEL);\r\nif (!name) {\r\nbpf_prog_put(fp);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nprog->bpf_ops = NULL;\r\nprog->bpf_fd = bpf_fd;\r\nprog->bpf_name = name;\r\nprog->filter = fp;\r\nprog->res.classid = classid;\r\nreturn 0;\r\n}\r\nstatic int cls_bpf_modify_existing(struct net *net, struct tcf_proto *tp,\r\nstruct cls_bpf_prog *prog,\r\nunsigned long base, struct nlattr **tb,\r\nstruct nlattr *est, bool ovr)\r\n{\r\nstruct tcf_exts exts;\r\nbool is_bpf, is_ebpf;\r\nu32 classid;\r\nint ret;\r\nis_bpf = tb[TCA_BPF_OPS_LEN] && tb[TCA_BPF_OPS];\r\nis_ebpf = tb[TCA_BPF_FD];\r\nif ((!is_bpf && !is_ebpf) || (is_bpf && is_ebpf) ||\r\n!tb[TCA_BPF_CLASSID])\r\nreturn -EINVAL;\r\ntcf_exts_init(&exts, TCA_BPF_ACT, TCA_BPF_POLICE);\r\nret = tcf_exts_validate(net, tp, tb, est, &exts, ovr);\r\nif (ret < 0)\r\nreturn ret;\r\nclassid = nla_get_u32(tb[TCA_BPF_CLASSID]);\r\nret = is_bpf ? cls_bpf_prog_from_ops(tb, prog, classid) :\r\ncls_bpf_prog_from_efd(tb, prog, classid);\r\nif (ret < 0) {\r\ntcf_exts_destroy(&exts);\r\nreturn ret;\r\n}\r\ntcf_bind_filter(tp, &prog->res, base);\r\ntcf_exts_change(tp, &prog->exts, &exts);\r\nreturn 0;\r\n}\r\nstatic u32 cls_bpf_grab_new_handle(struct tcf_proto *tp,\r\nstruct cls_bpf_head *head)\r\n{\r\nunsigned int i = 0x80000000;\r\nu32 handle;\r\ndo {\r\nif (++head->hgen == 0x7FFFFFFF)\r\nhead->hgen = 1;\r\n} while (--i > 0 && cls_bpf_get(tp, head->hgen));\r\nif (unlikely(i == 0)) {\r\npr_err("Insufficient number of handles\n");\r\nhandle = 0;\r\n} else {\r\nhandle = head->hgen;\r\n}\r\nreturn handle;\r\n}\r\nstatic int cls_bpf_change(struct net *net, struct sk_buff *in_skb,\r\nstruct tcf_proto *tp, unsigned long base,\r\nu32 handle, struct nlattr **tca,\r\nunsigned long *arg, bool ovr)\r\n{\r\nstruct cls_bpf_head *head = rtnl_dereference(tp->root);\r\nstruct cls_bpf_prog *oldprog = (struct cls_bpf_prog *) *arg;\r\nstruct nlattr *tb[TCA_BPF_MAX + 1];\r\nstruct cls_bpf_prog *prog;\r\nint ret;\r\nif (tca[TCA_OPTIONS] == NULL)\r\nreturn -EINVAL;\r\nret = nla_parse_nested(tb, TCA_BPF_MAX, tca[TCA_OPTIONS], bpf_policy);\r\nif (ret < 0)\r\nreturn ret;\r\nprog = kzalloc(sizeof(*prog), GFP_KERNEL);\r\nif (!prog)\r\nreturn -ENOBUFS;\r\ntcf_exts_init(&prog->exts, TCA_BPF_ACT, TCA_BPF_POLICE);\r\nif (oldprog) {\r\nif (handle && oldprog->handle != handle) {\r\nret = -EINVAL;\r\ngoto errout;\r\n}\r\n}\r\nif (handle == 0)\r\nprog->handle = cls_bpf_grab_new_handle(tp, head);\r\nelse\r\nprog->handle = handle;\r\nif (prog->handle == 0) {\r\nret = -EINVAL;\r\ngoto errout;\r\n}\r\nret = cls_bpf_modify_existing(net, tp, prog, base, tb, tca[TCA_RATE], ovr);\r\nif (ret < 0)\r\ngoto errout;\r\nif (oldprog) {\r\nlist_replace_rcu(&oldprog->link, &prog->link);\r\ntcf_unbind_filter(tp, &oldprog->res);\r\ncall_rcu(&oldprog->rcu, __cls_bpf_delete_prog);\r\n} else {\r\nlist_add_rcu(&prog->link, &head->plist);\r\n}\r\n*arg = (unsigned long) prog;\r\nreturn 0;\r\nerrout:\r\nkfree(prog);\r\nreturn ret;\r\n}\r\nstatic int cls_bpf_dump_bpf_info(const struct cls_bpf_prog *prog,\r\nstruct sk_buff *skb)\r\n{\r\nstruct nlattr *nla;\r\nif (nla_put_u16(skb, TCA_BPF_OPS_LEN, prog->bpf_num_ops))\r\nreturn -EMSGSIZE;\r\nnla = nla_reserve(skb, TCA_BPF_OPS, prog->bpf_num_ops *\r\nsizeof(struct sock_filter));\r\nif (nla == NULL)\r\nreturn -EMSGSIZE;\r\nmemcpy(nla_data(nla), prog->bpf_ops, nla_len(nla));\r\nreturn 0;\r\n}\r\nstatic int cls_bpf_dump_ebpf_info(const struct cls_bpf_prog *prog,\r\nstruct sk_buff *skb)\r\n{\r\nif (nla_put_u32(skb, TCA_BPF_FD, prog->bpf_fd))\r\nreturn -EMSGSIZE;\r\nif (prog->bpf_name &&\r\nnla_put_string(skb, TCA_BPF_NAME, prog->bpf_name))\r\nreturn -EMSGSIZE;\r\nreturn 0;\r\n}\r\nstatic int cls_bpf_dump(struct net *net, struct tcf_proto *tp, unsigned long fh,\r\nstruct sk_buff *skb, struct tcmsg *tm)\r\n{\r\nstruct cls_bpf_prog *prog = (struct cls_bpf_prog *) fh;\r\nstruct nlattr *nest;\r\nint ret;\r\nif (prog == NULL)\r\nreturn skb->len;\r\ntm->tcm_handle = prog->handle;\r\nnest = nla_nest_start(skb, TCA_OPTIONS);\r\nif (nest == NULL)\r\ngoto nla_put_failure;\r\nif (nla_put_u32(skb, TCA_BPF_CLASSID, prog->res.classid))\r\ngoto nla_put_failure;\r\nif (cls_bpf_is_ebpf(prog))\r\nret = cls_bpf_dump_ebpf_info(prog, skb);\r\nelse\r\nret = cls_bpf_dump_bpf_info(prog, skb);\r\nif (ret)\r\ngoto nla_put_failure;\r\nif (tcf_exts_dump(skb, &prog->exts) < 0)\r\ngoto nla_put_failure;\r\nnla_nest_end(skb, nest);\r\nif (tcf_exts_dump_stats(skb, &prog->exts) < 0)\r\ngoto nla_put_failure;\r\nreturn skb->len;\r\nnla_put_failure:\r\nnla_nest_cancel(skb, nest);\r\nreturn -1;\r\n}\r\nstatic void cls_bpf_walk(struct tcf_proto *tp, struct tcf_walker *arg)\r\n{\r\nstruct cls_bpf_head *head = rtnl_dereference(tp->root);\r\nstruct cls_bpf_prog *prog;\r\nlist_for_each_entry(prog, &head->plist, link) {\r\nif (arg->count < arg->skip)\r\ngoto skip;\r\nif (arg->fn(tp, (unsigned long) prog, arg) < 0) {\r\narg->stop = 1;\r\nbreak;\r\n}\r\nskip:\r\narg->count++;\r\n}\r\n}\r\nstatic int __init cls_bpf_init_mod(void)\r\n{\r\nreturn register_tcf_proto_ops(&cls_bpf_ops);\r\n}\r\nstatic void __exit cls_bpf_exit_mod(void)\r\n{\r\nunregister_tcf_proto_ops(&cls_bpf_ops);\r\n}
