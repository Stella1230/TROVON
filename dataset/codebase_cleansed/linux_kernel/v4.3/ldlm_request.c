static void interrupted_completion_wait(void *data)\r\n{\r\n}\r\nint ldlm_expired_completion_wait(void *data)\r\n{\r\nstruct lock_wait_data *lwd = data;\r\nstruct ldlm_lock *lock = lwd->lwd_lock;\r\nstruct obd_import *imp;\r\nstruct obd_device *obd;\r\nif (lock->l_conn_export == NULL) {\r\nstatic unsigned long next_dump, last_dump;\r\nLCONSOLE_WARN("lock timed out (enqueued at "CFS_TIME_T", "\r\nCFS_DURATION_T"s ago)\n",\r\nlock->l_last_activity,\r\ncfs_time_sub(get_seconds(),\r\nlock->l_last_activity));\r\nLDLM_DEBUG(lock, "lock timed out (enqueued at " CFS_TIME_T ", " CFS_DURATION_T "s ago); not entering recovery in server code, just going back to sleep",\r\nlock->l_last_activity,\r\ncfs_time_sub(get_seconds(),\r\nlock->l_last_activity));\r\nif (cfs_time_after(cfs_time_current(), next_dump)) {\r\nlast_dump = next_dump;\r\nnext_dump = cfs_time_shift(300);\r\nldlm_namespace_dump(D_DLMTRACE,\r\nldlm_lock_to_ns(lock));\r\nif (last_dump == 0)\r\nlibcfs_debug_dumplog();\r\n}\r\nreturn 0;\r\n}\r\nobd = lock->l_conn_export->exp_obd;\r\nimp = obd->u.cli.cl_import;\r\nptlrpc_fail_import(imp, lwd->lwd_conn_cnt);\r\nLDLM_ERROR(lock, "lock timed out (enqueued at "CFS_TIME_T", "\r\nCFS_DURATION_T"s ago), entering recovery for %s@%s",\r\nlock->l_last_activity,\r\ncfs_time_sub(get_seconds(), lock->l_last_activity),\r\nobd2cli_tgt(obd), imp->imp_connection->c_remote_uuid.uuid);\r\nreturn 0;\r\n}\r\nint ldlm_get_enq_timeout(struct ldlm_lock *lock)\r\n{\r\nint timeout = at_get(ldlm_lock_to_ns_at(lock));\r\nif (AT_OFF)\r\nreturn obd_timeout / 2;\r\ntimeout = min_t(int, at_max, timeout + (timeout >> 1));\r\nreturn max(timeout, ldlm_enqueue_min);\r\n}\r\nstatic int ldlm_completion_tail(struct ldlm_lock *lock)\r\n{\r\nlong delay;\r\nint result;\r\nif (lock->l_flags & (LDLM_FL_DESTROYED | LDLM_FL_FAILED)) {\r\nLDLM_DEBUG(lock, "client-side enqueue: destroyed");\r\nresult = -EIO;\r\n} else {\r\ndelay = cfs_time_sub(get_seconds(),\r\nlock->l_last_activity);\r\nLDLM_DEBUG(lock, "client-side enqueue: granted after "\r\nCFS_DURATION_T"s", delay);\r\nat_measured(ldlm_lock_to_ns_at(lock),\r\ndelay);\r\nresult = 0;\r\n}\r\nreturn result;\r\n}\r\nint ldlm_completion_ast_async(struct ldlm_lock *lock, __u64 flags, void *data)\r\n{\r\nif (flags == LDLM_FL_WAIT_NOREPROC) {\r\nLDLM_DEBUG(lock, "client-side enqueue waiting on pending lock");\r\nreturn 0;\r\n}\r\nif (!(flags & (LDLM_FL_BLOCK_WAIT | LDLM_FL_BLOCK_GRANTED |\r\nLDLM_FL_BLOCK_CONV))) {\r\nwake_up(&lock->l_waitq);\r\nreturn ldlm_completion_tail(lock);\r\n}\r\nLDLM_DEBUG(lock, "client-side enqueue returned a blocked lock, going forward");\r\nldlm_reprocess_all(lock->l_resource);\r\nreturn 0;\r\n}\r\nint ldlm_completion_ast(struct ldlm_lock *lock, __u64 flags, void *data)\r\n{\r\nstruct lock_wait_data lwd;\r\nstruct obd_device *obd;\r\nstruct obd_import *imp = NULL;\r\nstruct l_wait_info lwi;\r\n__u32 timeout;\r\nint rc = 0;\r\nif (flags == LDLM_FL_WAIT_NOREPROC) {\r\nLDLM_DEBUG(lock, "client-side enqueue waiting on pending lock");\r\ngoto noreproc;\r\n}\r\nif (!(flags & (LDLM_FL_BLOCK_WAIT | LDLM_FL_BLOCK_GRANTED |\r\nLDLM_FL_BLOCK_CONV))) {\r\nwake_up(&lock->l_waitq);\r\nreturn 0;\r\n}\r\nLDLM_DEBUG(lock, "client-side enqueue returned a blocked lock, sleeping");\r\nnoreproc:\r\nobd = class_exp2obd(lock->l_conn_export);\r\nif (obd != NULL)\r\nimp = obd->u.cli.cl_import;\r\ntimeout = ldlm_get_enq_timeout(lock) * 2;\r\nlwd.lwd_lock = lock;\r\nif (lock->l_flags & LDLM_FL_NO_TIMEOUT) {\r\nLDLM_DEBUG(lock, "waiting indefinitely because of NO_TIMEOUT");\r\nlwi = LWI_INTR(interrupted_completion_wait, &lwd);\r\n} else {\r\nlwi = LWI_TIMEOUT_INTR(cfs_time_seconds(timeout),\r\nldlm_expired_completion_wait,\r\ninterrupted_completion_wait, &lwd);\r\n}\r\nif (imp != NULL) {\r\nspin_lock(&imp->imp_lock);\r\nlwd.lwd_conn_cnt = imp->imp_conn_cnt;\r\nspin_unlock(&imp->imp_lock);\r\n}\r\nif (ns_is_client(ldlm_lock_to_ns(lock)) &&\r\nOBD_FAIL_CHECK_RESET(OBD_FAIL_LDLM_INTR_CP_AST,\r\nOBD_FAIL_LDLM_CP_BL_RACE | OBD_FAIL_ONCE)) {\r\nlock->l_flags |= LDLM_FL_FAIL_LOC;\r\nrc = -EINTR;\r\n} else {\r\nrc = l_wait_event(lock->l_waitq,\r\nis_granted_or_cancelled(lock), &lwi);\r\n}\r\nif (rc) {\r\nLDLM_DEBUG(lock, "client-side enqueue waking up: failed (%d)",\r\nrc);\r\nreturn rc;\r\n}\r\nreturn ldlm_completion_tail(lock);\r\n}\r\nint ldlm_blocking_ast_nocheck(struct ldlm_lock *lock)\r\n{\r\nint do_ast;\r\nlock->l_flags |= LDLM_FL_CBPENDING;\r\ndo_ast = !lock->l_readers && !lock->l_writers;\r\nunlock_res_and_lock(lock);\r\nif (do_ast) {\r\nstruct lustre_handle lockh;\r\nint rc;\r\nLDLM_DEBUG(lock, "already unused, calling ldlm_cli_cancel");\r\nldlm_lock2handle(lock, &lockh);\r\nrc = ldlm_cli_cancel(&lockh, LCF_ASYNC);\r\nif (rc < 0)\r\nCERROR("ldlm_cli_cancel: %d\n", rc);\r\n} else {\r\nLDLM_DEBUG(lock, "Lock still has references, will be cancelled later");\r\n}\r\nreturn 0;\r\n}\r\nint ldlm_blocking_ast(struct ldlm_lock *lock, struct ldlm_lock_desc *desc,\r\nvoid *data, int flag)\r\n{\r\nif (flag == LDLM_CB_CANCELING) {\r\nreturn 0;\r\n}\r\nlock_res_and_lock(lock);\r\nif (lock->l_blocking_ast != ldlm_blocking_ast) {\r\nunlock_res_and_lock(lock);\r\nreturn 0;\r\n}\r\nreturn ldlm_blocking_ast_nocheck(lock);\r\n}\r\nint ldlm_glimpse_ast(struct ldlm_lock *lock, void *reqp)\r\n{\r\nreturn -ELDLM_NO_LOCK_DATA;\r\n}\r\nint ldlm_cli_enqueue_local(struct ldlm_namespace *ns,\r\nconst struct ldlm_res_id *res_id,\r\nldlm_type_t type, ldlm_policy_data_t *policy,\r\nldlm_mode_t mode, __u64 *flags,\r\nldlm_blocking_callback blocking,\r\nldlm_completion_callback completion,\r\nldlm_glimpse_callback glimpse,\r\nvoid *data, __u32 lvb_len, enum lvb_type lvb_type,\r\nconst __u64 *client_cookie,\r\nstruct lustre_handle *lockh)\r\n{\r\nstruct ldlm_lock *lock;\r\nint err;\r\nconst struct ldlm_callback_suite cbs = { .lcs_completion = completion,\r\n.lcs_blocking = blocking,\r\n.lcs_glimpse = glimpse,\r\n};\r\nLASSERT(!(*flags & LDLM_FL_REPLAY));\r\nif (unlikely(ns_is_client(ns))) {\r\nCERROR("Trying to enqueue local lock in a shadow namespace\n");\r\nLBUG();\r\n}\r\nlock = ldlm_lock_create(ns, res_id, type, mode, &cbs, data, lvb_len,\r\nlvb_type);\r\nif (unlikely(!lock)) {\r\nerr = -ENOMEM;\r\ngoto out_nolock;\r\n}\r\nldlm_lock2handle(lock, lockh);\r\nldlm_lock_addref_internal_nolock(lock, mode);\r\nlock->l_flags |= LDLM_FL_LOCAL;\r\nif (*flags & LDLM_FL_ATOMIC_CB)\r\nlock->l_flags |= LDLM_FL_ATOMIC_CB;\r\nif (policy != NULL)\r\nlock->l_policy_data = *policy;\r\nif (client_cookie != NULL)\r\nlock->l_client_cookie = *client_cookie;\r\nif (type == LDLM_EXTENT)\r\nlock->l_req_extent = policy->l_extent;\r\nerr = ldlm_lock_enqueue(ns, &lock, policy, flags);\r\nif (unlikely(err != ELDLM_OK))\r\ngoto out;\r\nif (policy != NULL)\r\n*policy = lock->l_policy_data;\r\nif (lock->l_completion_ast)\r\nlock->l_completion_ast(lock, *flags, NULL);\r\nLDLM_DEBUG(lock, "client-side local enqueue handler, new lock created");\r\nout:\r\nLDLM_LOCK_RELEASE(lock);\r\nout_nolock:\r\nreturn err;\r\n}\r\nstatic void failed_lock_cleanup(struct ldlm_namespace *ns,\r\nstruct ldlm_lock *lock, int mode)\r\n{\r\nint need_cancel = 0;\r\nlock_res_and_lock(lock);\r\nif ((lock->l_req_mode != lock->l_granted_mode) &&\r\n!(lock->l_flags & LDLM_FL_FAILED)) {\r\nlock->l_flags |= LDLM_FL_LOCAL_ONLY | LDLM_FL_FAILED |\r\nLDLM_FL_ATOMIC_CB | LDLM_FL_CBPENDING;\r\nneed_cancel = 1;\r\n}\r\nunlock_res_and_lock(lock);\r\nif (need_cancel)\r\nLDLM_DEBUG(lock,\r\n"setting FL_LOCAL_ONLY | LDLM_FL_FAILED | LDLM_FL_ATOMIC_CB | LDLM_FL_CBPENDING");\r\nelse\r\nLDLM_DEBUG(lock, "lock was granted or failed in race");\r\nldlm_lock_decref_internal(lock, mode);\r\nif (lock->l_resource->lr_type == LDLM_FLOCK) {\r\nlock_res_and_lock(lock);\r\nldlm_resource_unlink_lock(lock);\r\nldlm_lock_destroy_nolock(lock);\r\nunlock_res_and_lock(lock);\r\n}\r\n}\r\nint ldlm_cli_enqueue_fini(struct obd_export *exp, struct ptlrpc_request *req,\r\nldlm_type_t type, __u8 with_policy, ldlm_mode_t mode,\r\n__u64 *flags, void *lvb, __u32 lvb_len,\r\nstruct lustre_handle *lockh, int rc)\r\n{\r\nstruct ldlm_namespace *ns = exp->exp_obd->obd_namespace;\r\nint is_replay = *flags & LDLM_FL_REPLAY;\r\nstruct ldlm_lock *lock;\r\nstruct ldlm_reply *reply;\r\nint cleanup_phase = 1;\r\nint size = 0;\r\nlock = ldlm_handle2lock(lockh);\r\nif (!lock) {\r\nLASSERT(type == LDLM_FLOCK);\r\nreturn -ENOLCK;\r\n}\r\nLASSERTF(ergo(lvb_len != 0, lvb_len == lock->l_lvb_len),\r\n"lvb_len = %d, l_lvb_len = %d\n", lvb_len, lock->l_lvb_len);\r\nif (rc != ELDLM_OK) {\r\nLASSERT(!is_replay);\r\nLDLM_DEBUG(lock, "client-side enqueue END (%s)",\r\nrc == ELDLM_LOCK_ABORTED ? "ABORTED" : "FAILED");\r\nif (rc != ELDLM_LOCK_ABORTED)\r\ngoto cleanup;\r\n}\r\nreply = req_capsule_server_get(&req->rq_pill, &RMF_DLM_REP);\r\nif (reply == NULL) {\r\nrc = -EPROTO;\r\ngoto cleanup;\r\n}\r\nif (lvb_len != 0) {\r\nLASSERT(lvb != NULL);\r\nsize = req_capsule_get_size(&req->rq_pill, &RMF_DLM_LVB,\r\nRCL_SERVER);\r\nif (size < 0) {\r\nLDLM_ERROR(lock, "Fail to get lvb_len, rc = %d", size);\r\nrc = size;\r\ngoto cleanup;\r\n} else if (unlikely(size > lvb_len)) {\r\nLDLM_ERROR(lock, "Replied LVB is larger than expectation, expected = %d, replied = %d",\r\nlvb_len, size);\r\nrc = -EINVAL;\r\ngoto cleanup;\r\n}\r\n}\r\nif (rc == ELDLM_LOCK_ABORTED) {\r\nif (lvb_len != 0)\r\nrc = ldlm_fill_lvb(lock, &req->rq_pill, RCL_SERVER,\r\nlvb, size);\r\nif (rc == 0)\r\nrc = ELDLM_LOCK_ABORTED;\r\ngoto cleanup;\r\n}\r\ncleanup_phase = 0;\r\nlock_res_and_lock(lock);\r\nif (exp->exp_lock_hash) {\r\ncfs_hash_rehash_key(exp->exp_lock_hash,\r\n&lock->l_remote_handle,\r\n&reply->lock_handle,\r\n&lock->l_exp_hash);\r\n} else {\r\nlock->l_remote_handle = reply->lock_handle;\r\n}\r\n*flags = ldlm_flags_from_wire(reply->lock_flags);\r\nlock->l_flags |= ldlm_flags_from_wire(reply->lock_flags &\r\nLDLM_INHERIT_FLAGS);\r\nlock->l_flags |= ldlm_flags_from_wire(reply->lock_flags &\r\nLDLM_FL_NO_TIMEOUT);\r\nunlock_res_and_lock(lock);\r\nCDEBUG(D_INFO, "local: %p, remote cookie: %#llx, flags: 0x%llx\n",\r\nlock, reply->lock_handle.cookie, *flags);\r\nif ((*flags) & LDLM_FL_LOCK_CHANGED) {\r\nint newmode = reply->lock_desc.l_req_mode;\r\nLASSERT(!is_replay);\r\nif (newmode && newmode != lock->l_req_mode) {\r\nLDLM_DEBUG(lock, "server returned different mode %s",\r\nldlm_lockname[newmode]);\r\nlock->l_req_mode = newmode;\r\n}\r\nif (!ldlm_res_eq(&reply->lock_desc.l_resource.lr_name,\r\n&lock->l_resource->lr_name)) {\r\nCDEBUG(D_INFO, "remote intent success, locking "DLDLMRES\r\n" instead of "DLDLMRES"\n",\r\nPLDLMRES(&reply->lock_desc.l_resource),\r\nPLDLMRES(lock->l_resource));\r\nrc = ldlm_lock_change_resource(ns, lock,\r\n&reply->lock_desc.l_resource.lr_name);\r\nif (rc || lock->l_resource == NULL) {\r\nrc = -ENOMEM;\r\ngoto cleanup;\r\n}\r\nLDLM_DEBUG(lock, "client-side enqueue, new resource");\r\n}\r\nif (with_policy)\r\nif (!(type == LDLM_IBITS &&\r\n!(exp_connect_flags(exp) & OBD_CONNECT_IBITS)))\r\nldlm_convert_policy_to_local(exp,\r\nlock->l_resource->lr_type,\r\n&reply->lock_desc.l_policy_data,\r\n&lock->l_policy_data);\r\nif (type != LDLM_PLAIN)\r\nLDLM_DEBUG(lock,\r\n"client-side enqueue, new policy data");\r\n}\r\nif ((*flags) & LDLM_FL_AST_SENT ||\r\n(LIBLUSTRE_CLIENT && type == LDLM_EXTENT)) {\r\nlock_res_and_lock(lock);\r\nlock->l_flags |= LDLM_FL_CBPENDING | LDLM_FL_BL_AST;\r\nunlock_res_and_lock(lock);\r\nLDLM_DEBUG(lock, "enqueue reply includes blocking AST");\r\n}\r\nif (lvb_len != 0) {\r\nlock_res_and_lock(lock);\r\nif (lock->l_req_mode != lock->l_granted_mode)\r\nrc = ldlm_fill_lvb(lock, &req->rq_pill, RCL_SERVER,\r\nlock->l_lvb_data, size);\r\nunlock_res_and_lock(lock);\r\nif (rc < 0) {\r\ncleanup_phase = 1;\r\ngoto cleanup;\r\n}\r\n}\r\nif (!is_replay) {\r\nrc = ldlm_lock_enqueue(ns, &lock, NULL, flags);\r\nif (lock->l_completion_ast != NULL) {\r\nint err = lock->l_completion_ast(lock, *flags, NULL);\r\nif (!rc)\r\nrc = err;\r\nif (rc)\r\ncleanup_phase = 1;\r\n}\r\n}\r\nif (lvb_len && lvb != NULL) {\r\nmemcpy(lvb, lock->l_lvb_data, lvb_len);\r\n}\r\nLDLM_DEBUG(lock, "client-side enqueue END");\r\ncleanup:\r\nif (cleanup_phase == 1 && rc)\r\nfailed_lock_cleanup(ns, lock, mode);\r\nLDLM_LOCK_PUT(lock);\r\nLDLM_LOCK_RELEASE(lock);\r\nreturn rc;\r\n}\r\nstatic inline int ldlm_req_handles_avail(int req_size, int off)\r\n{\r\nint avail;\r\navail = min_t(int, LDLM_MAXREQSIZE, PAGE_CACHE_SIZE - 512) - req_size;\r\nif (likely(avail >= 0))\r\navail /= (int)sizeof(struct lustre_handle);\r\nelse\r\navail = 0;\r\navail += LDLM_LOCKREQ_HANDLES - off;\r\nreturn avail;\r\n}\r\nstatic inline int ldlm_capsule_handles_avail(struct req_capsule *pill,\r\nenum req_location loc,\r\nint off)\r\n{\r\nint size = req_capsule_msg_size(pill, loc);\r\nreturn ldlm_req_handles_avail(size, off);\r\n}\r\nstatic inline int ldlm_format_handles_avail(struct obd_import *imp,\r\nconst struct req_format *fmt,\r\nenum req_location loc, int off)\r\n{\r\nint size = req_capsule_fmt_size(imp->imp_msg_magic, fmt, loc);\r\nreturn ldlm_req_handles_avail(size, off);\r\n}\r\nint ldlm_prep_elc_req(struct obd_export *exp, struct ptlrpc_request *req,\r\nint version, int opc, int canceloff,\r\nstruct list_head *cancels, int count)\r\n{\r\nstruct ldlm_namespace *ns = exp->exp_obd->obd_namespace;\r\nstruct req_capsule *pill = &req->rq_pill;\r\nstruct ldlm_request *dlm = NULL;\r\nint flags, avail, to_free, pack = 0;\r\nLIST_HEAD(head);\r\nint rc;\r\nif (cancels == NULL)\r\ncancels = &head;\r\nif (ns_connect_cancelset(ns)) {\r\nreq_capsule_filled_sizes(pill, RCL_CLIENT);\r\navail = ldlm_capsule_handles_avail(pill, RCL_CLIENT, canceloff);\r\nflags = ns_connect_lru_resize(ns) ?\r\nLDLM_CANCEL_LRUR : LDLM_CANCEL_AGED;\r\nto_free = !ns_connect_lru_resize(ns) &&\r\nopc == LDLM_ENQUEUE ? 1 : 0;\r\nif (avail > count)\r\ncount += ldlm_cancel_lru_local(ns, cancels, to_free,\r\navail - count, 0, flags);\r\nif (avail > count)\r\npack = count;\r\nelse\r\npack = avail;\r\nreq_capsule_set_size(pill, &RMF_DLM_REQ, RCL_CLIENT,\r\nldlm_request_bufsize(pack, opc));\r\n}\r\nrc = ptlrpc_request_pack(req, version, opc);\r\nif (rc) {\r\nldlm_lock_list_put(cancels, l_bl_ast, count);\r\nreturn rc;\r\n}\r\nif (ns_connect_cancelset(ns)) {\r\nif (canceloff) {\r\ndlm = req_capsule_client_get(pill, &RMF_DLM_REQ);\r\nLASSERT(dlm);\r\ndlm->lock_count = canceloff;\r\n}\r\nldlm_cli_cancel_list(cancels, pack, req, 0);\r\nldlm_cli_cancel_list(cancels, count - pack, NULL, 0);\r\n} else {\r\nldlm_lock_list_put(cancels, l_bl_ast, count);\r\n}\r\nreturn 0;\r\n}\r\nint ldlm_prep_enqueue_req(struct obd_export *exp, struct ptlrpc_request *req,\r\nstruct list_head *cancels, int count)\r\n{\r\nreturn ldlm_prep_elc_req(exp, req, LUSTRE_DLM_VERSION, LDLM_ENQUEUE,\r\nLDLM_ENQUEUE_CANCEL_OFF, cancels, count);\r\n}\r\nstruct ptlrpc_request *ldlm_enqueue_pack(struct obd_export *exp, int lvb_len)\r\n{\r\nstruct ptlrpc_request *req;\r\nint rc;\r\nreq = ptlrpc_request_alloc(class_exp2cliimp(exp), &RQF_LDLM_ENQUEUE);\r\nif (req == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nrc = ldlm_prep_enqueue_req(exp, req, NULL, 0);\r\nif (rc) {\r\nptlrpc_request_free(req);\r\nreturn ERR_PTR(rc);\r\n}\r\nreq_capsule_set_size(&req->rq_pill, &RMF_DLM_LVB, RCL_SERVER, lvb_len);\r\nptlrpc_request_set_replen(req);\r\nreturn req;\r\n}\r\nint ldlm_cli_enqueue(struct obd_export *exp, struct ptlrpc_request **reqp,\r\nstruct ldlm_enqueue_info *einfo,\r\nconst struct ldlm_res_id *res_id,\r\nldlm_policy_data_t const *policy, __u64 *flags,\r\nvoid *lvb, __u32 lvb_len, enum lvb_type lvb_type,\r\nstruct lustre_handle *lockh, int async)\r\n{\r\nstruct ldlm_namespace *ns;\r\nstruct ldlm_lock *lock;\r\nstruct ldlm_request *body;\r\nint is_replay = *flags & LDLM_FL_REPLAY;\r\nint req_passed_in = 1;\r\nint rc, err;\r\nstruct ptlrpc_request *req;\r\nLASSERT(exp != NULL);\r\nns = exp->exp_obd->obd_namespace;\r\nif (is_replay) {\r\nlock = ldlm_handle2lock_long(lockh, 0);\r\nLASSERT(lock != NULL);\r\nLDLM_DEBUG(lock, "client-side enqueue START");\r\nLASSERT(exp == lock->l_conn_export);\r\n} else {\r\nconst struct ldlm_callback_suite cbs = {\r\n.lcs_completion = einfo->ei_cb_cp,\r\n.lcs_blocking = einfo->ei_cb_bl,\r\n.lcs_glimpse = einfo->ei_cb_gl\r\n};\r\nlock = ldlm_lock_create(ns, res_id, einfo->ei_type,\r\neinfo->ei_mode, &cbs, einfo->ei_cbdata,\r\nlvb_len, lvb_type);\r\nif (lock == NULL)\r\nreturn -ENOMEM;\r\nldlm_lock_addref_internal(lock, einfo->ei_mode);\r\nldlm_lock2handle(lock, lockh);\r\nif (policy != NULL)\r\nlock->l_policy_data = *policy;\r\nif (einfo->ei_type == LDLM_EXTENT)\r\nlock->l_req_extent = policy->l_extent;\r\nLDLM_DEBUG(lock, "client-side enqueue START, flags %llx\n",\r\n*flags);\r\n}\r\nlock->l_conn_export = exp;\r\nlock->l_export = NULL;\r\nlock->l_blocking_ast = einfo->ei_cb_bl;\r\nlock->l_flags |= (*flags & (LDLM_FL_NO_LRU | LDLM_FL_EXCL));\r\nif (reqp == NULL || *reqp == NULL) {\r\nreq = ptlrpc_request_alloc_pack(class_exp2cliimp(exp),\r\n&RQF_LDLM_ENQUEUE,\r\nLUSTRE_DLM_VERSION,\r\nLDLM_ENQUEUE);\r\nif (req == NULL) {\r\nfailed_lock_cleanup(ns, lock, einfo->ei_mode);\r\nLDLM_LOCK_RELEASE(lock);\r\nreturn -ENOMEM;\r\n}\r\nreq_passed_in = 0;\r\nif (reqp)\r\n*reqp = req;\r\n} else {\r\nint len;\r\nreq = *reqp;\r\nlen = req_capsule_get_size(&req->rq_pill, &RMF_DLM_REQ,\r\nRCL_CLIENT);\r\nLASSERTF(len >= sizeof(*body), "buflen[%d] = %d, not %d\n",\r\nDLM_LOCKREQ_OFF, len, (int)sizeof(*body));\r\n}\r\nbody = req_capsule_client_get(&req->rq_pill, &RMF_DLM_REQ);\r\nldlm_lock2desc(lock, &body->lock_desc);\r\nbody->lock_flags = ldlm_flags_to_wire(*flags);\r\nbody->lock_handle[0] = *lockh;\r\nif (!req_passed_in) {\r\nif (lvb_len > 0)\r\nreq_capsule_extend(&req->rq_pill,\r\n&RQF_LDLM_ENQUEUE_LVB);\r\nreq_capsule_set_size(&req->rq_pill, &RMF_DLM_LVB, RCL_SERVER,\r\nlvb_len);\r\nptlrpc_request_set_replen(req);\r\n}\r\nLASSERT(ergo(LIBLUSTRE_CLIENT, einfo->ei_type != LDLM_EXTENT ||\r\npolicy->l_extent.end == OBD_OBJECT_EOF));\r\nif (async) {\r\nLASSERT(reqp != NULL);\r\nreturn 0;\r\n}\r\nLDLM_DEBUG(lock, "sending request");\r\nrc = ptlrpc_queue_wait(req);\r\nerr = ldlm_cli_enqueue_fini(exp, req, einfo->ei_type, policy ? 1 : 0,\r\neinfo->ei_mode, flags, lvb, lvb_len,\r\nlockh, rc);\r\nif (err == -ENOLCK)\r\nLDLM_LOCK_RELEASE(lock);\r\nelse\r\nrc = err;\r\nif (!req_passed_in && req != NULL) {\r\nptlrpc_req_finished(req);\r\nif (reqp)\r\n*reqp = NULL;\r\n}\r\nreturn rc;\r\n}\r\nstatic int ldlm_cli_convert_local(struct ldlm_lock *lock, int new_mode,\r\n__u32 *flags)\r\n{\r\nstruct ldlm_resource *res;\r\nint rc;\r\nif (ns_is_client(ldlm_lock_to_ns(lock))) {\r\nCERROR("Trying to cancel local lock\n");\r\nLBUG();\r\n}\r\nLDLM_DEBUG(lock, "client-side local convert");\r\nres = ldlm_lock_convert(lock, new_mode, flags);\r\nif (res) {\r\nldlm_reprocess_all(res);\r\nrc = 0;\r\n} else {\r\nrc = LUSTRE_EDEADLK;\r\n}\r\nLDLM_DEBUG(lock, "client-side local convert handler END");\r\nLDLM_LOCK_PUT(lock);\r\nreturn rc;\r\n}\r\nint ldlm_cli_convert(struct lustre_handle *lockh, int new_mode, __u32 *flags)\r\n{\r\nstruct ldlm_request *body;\r\nstruct ldlm_reply *reply;\r\nstruct ldlm_lock *lock;\r\nstruct ldlm_resource *res;\r\nstruct ptlrpc_request *req;\r\nint rc;\r\nlock = ldlm_handle2lock(lockh);\r\nif (!lock) {\r\nLBUG();\r\nreturn -EINVAL;\r\n}\r\n*flags = 0;\r\nif (lock->l_conn_export == NULL)\r\nreturn ldlm_cli_convert_local(lock, new_mode, flags);\r\nLDLM_DEBUG(lock, "client-side convert");\r\nreq = ptlrpc_request_alloc_pack(class_exp2cliimp(lock->l_conn_export),\r\n&RQF_LDLM_CONVERT, LUSTRE_DLM_VERSION,\r\nLDLM_CONVERT);\r\nif (req == NULL) {\r\nLDLM_LOCK_PUT(lock);\r\nreturn -ENOMEM;\r\n}\r\nbody = req_capsule_client_get(&req->rq_pill, &RMF_DLM_REQ);\r\nbody->lock_handle[0] = lock->l_remote_handle;\r\nbody->lock_desc.l_req_mode = new_mode;\r\nbody->lock_flags = ldlm_flags_to_wire(*flags);\r\nptlrpc_request_set_replen(req);\r\nrc = ptlrpc_queue_wait(req);\r\nif (rc != ELDLM_OK)\r\ngoto out;\r\nreply = req_capsule_server_get(&req->rq_pill, &RMF_DLM_REP);\r\nif (reply == NULL) {\r\nrc = -EPROTO;\r\ngoto out;\r\n}\r\nif (req->rq_status) {\r\nrc = req->rq_status;\r\ngoto out;\r\n}\r\nres = ldlm_lock_convert(lock, new_mode, &reply->lock_flags);\r\nif (res != NULL) {\r\nldlm_reprocess_all(res);\r\nif (lock->l_completion_ast) {\r\nrc = lock->l_completion_ast(lock, LDLM_FL_WAIT_NOREPROC,\r\nNULL);\r\nif (rc)\r\ngoto out;\r\n}\r\n} else {\r\nrc = LUSTRE_EDEADLK;\r\n}\r\nout:\r\nLDLM_LOCK_PUT(lock);\r\nptlrpc_req_finished(req);\r\nreturn rc;\r\n}\r\nstatic __u64 ldlm_cli_cancel_local(struct ldlm_lock *lock)\r\n{\r\n__u64 rc = LDLM_FL_LOCAL_ONLY;\r\nif (lock->l_conn_export) {\r\nbool local_only;\r\nLDLM_DEBUG(lock, "client-side cancel");\r\nlock_res_and_lock(lock);\r\nlock->l_flags |= LDLM_FL_CBPENDING;\r\nlocal_only = !!(lock->l_flags &\r\n(LDLM_FL_LOCAL_ONLY|LDLM_FL_CANCEL_ON_BLOCK));\r\nldlm_cancel_callback(lock);\r\nrc = (lock->l_flags & LDLM_FL_BL_AST) ?\r\nLDLM_FL_BL_AST : LDLM_FL_CANCELING;\r\nunlock_res_and_lock(lock);\r\nif (local_only) {\r\nCDEBUG(D_DLMTRACE, "not sending request (at caller's instruction)\n");\r\nrc = LDLM_FL_LOCAL_ONLY;\r\n}\r\nldlm_lock_cancel(lock);\r\n} else {\r\nif (ns_is_client(ldlm_lock_to_ns(lock))) {\r\nLDLM_ERROR(lock, "Trying to cancel local lock");\r\nLBUG();\r\n}\r\nLDLM_DEBUG(lock, "server-side local cancel");\r\nldlm_lock_cancel(lock);\r\nldlm_reprocess_all(lock->l_resource);\r\n}\r\nreturn rc;\r\n}\r\nstatic void ldlm_cancel_pack(struct ptlrpc_request *req,\r\nstruct list_head *head, int count)\r\n{\r\nstruct ldlm_request *dlm;\r\nstruct ldlm_lock *lock;\r\nint max, packed = 0;\r\ndlm = req_capsule_client_get(&req->rq_pill, &RMF_DLM_REQ);\r\nLASSERT(dlm != NULL);\r\nmax = req_capsule_get_size(&req->rq_pill, &RMF_DLM_REQ, RCL_CLIENT) -\r\nsizeof(struct ldlm_request);\r\nmax /= sizeof(struct lustre_handle);\r\nmax += LDLM_LOCKREQ_HANDLES;\r\nLASSERT(max >= dlm->lock_count + count);\r\nlist_for_each_entry(lock, head, l_bl_ast) {\r\nif (!count--)\r\nbreak;\r\nLASSERT(lock->l_conn_export);\r\nLDLM_DEBUG(lock, "packing");\r\ndlm->lock_handle[dlm->lock_count++] = lock->l_remote_handle;\r\npacked++;\r\n}\r\nCDEBUG(D_DLMTRACE, "%d locks packed\n", packed);\r\n}\r\nint ldlm_cli_cancel_req(struct obd_export *exp, struct list_head *cancels,\r\nint count, ldlm_cancel_flags_t flags)\r\n{\r\nstruct ptlrpc_request *req = NULL;\r\nstruct obd_import *imp;\r\nint free, sent = 0;\r\nint rc = 0;\r\nLASSERT(exp != NULL);\r\nLASSERT(count > 0);\r\nCFS_FAIL_TIMEOUT(OBD_FAIL_LDLM_PAUSE_CANCEL, cfs_fail_val);\r\nif (CFS_FAIL_CHECK(OBD_FAIL_LDLM_CANCEL_RACE))\r\nreturn count;\r\nfree = ldlm_format_handles_avail(class_exp2cliimp(exp),\r\n&RQF_LDLM_CANCEL, RCL_CLIENT, 0);\r\nif (count > free)\r\ncount = free;\r\nwhile (1) {\r\nimp = class_exp2cliimp(exp);\r\nif (imp == NULL || imp->imp_invalid) {\r\nCDEBUG(D_DLMTRACE,\r\n"skipping cancel on invalid import %p\n", imp);\r\nreturn count;\r\n}\r\nreq = ptlrpc_request_alloc(imp, &RQF_LDLM_CANCEL);\r\nif (req == NULL) {\r\nrc = -ENOMEM;\r\ngoto out;\r\n}\r\nreq_capsule_filled_sizes(&req->rq_pill, RCL_CLIENT);\r\nreq_capsule_set_size(&req->rq_pill, &RMF_DLM_REQ, RCL_CLIENT,\r\nldlm_request_bufsize(count, LDLM_CANCEL));\r\nrc = ptlrpc_request_pack(req, LUSTRE_DLM_VERSION, LDLM_CANCEL);\r\nif (rc) {\r\nptlrpc_request_free(req);\r\ngoto out;\r\n}\r\nreq->rq_request_portal = LDLM_CANCEL_REQUEST_PORTAL;\r\nreq->rq_reply_portal = LDLM_CANCEL_REPLY_PORTAL;\r\nptlrpc_at_set_req_timeout(req);\r\nldlm_cancel_pack(req, cancels, count);\r\nptlrpc_request_set_replen(req);\r\nif (flags & LCF_ASYNC) {\r\nptlrpcd_add_req(req, PDL_POLICY_LOCAL, -1);\r\nsent = count;\r\ngoto out;\r\n} else {\r\nrc = ptlrpc_queue_wait(req);\r\n}\r\nif (rc == LUSTRE_ESTALE) {\r\nCDEBUG(D_DLMTRACE, "client/server (nid %s) out of sync -- not fatal\n",\r\nlibcfs_nid2str(req->rq_import->\r\nimp_connection->c_peer.nid));\r\nrc = 0;\r\n} else if (rc == -ETIMEDOUT &&\r\nreq->rq_import_generation == imp->imp_generation) {\r\nptlrpc_req_finished(req);\r\ncontinue;\r\n} else if (rc != ELDLM_OK) {\r\nCDEBUG_LIMIT(rc == -ESHUTDOWN ? D_DLMTRACE : D_ERROR,\r\n"Got rc %d from cancel RPC: canceling anyway\n",\r\nrc);\r\nbreak;\r\n}\r\nsent = count;\r\nbreak;\r\n}\r\nptlrpc_req_finished(req);\r\nout:\r\nreturn sent ? sent : rc;\r\n}\r\nstatic inline struct ldlm_pool *ldlm_imp2pl(struct obd_import *imp)\r\n{\r\nLASSERT(imp != NULL);\r\nreturn &imp->imp_obd->obd_namespace->ns_pool;\r\n}\r\nint ldlm_cli_update_pool(struct ptlrpc_request *req)\r\n{\r\nstruct obd_device *obd;\r\n__u64 new_slv;\r\n__u32 new_limit;\r\nif (unlikely(!req->rq_import || !req->rq_import->imp_obd ||\r\n!imp_connect_lru_resize(req->rq_import))) {\r\nreturn 0;\r\n}\r\nif (lustre_msg_get_slv(req->rq_repmsg) == 0 ||\r\nlustre_msg_get_limit(req->rq_repmsg) == 0) {\r\nDEBUG_REQ(D_HA, req,\r\n"Zero SLV or Limit found (SLV: %llu, Limit: %u)",\r\nlustre_msg_get_slv(req->rq_repmsg),\r\nlustre_msg_get_limit(req->rq_repmsg));\r\nreturn 0;\r\n}\r\nnew_limit = lustre_msg_get_limit(req->rq_repmsg);\r\nnew_slv = lustre_msg_get_slv(req->rq_repmsg);\r\nobd = req->rq_import->imp_obd;\r\nwrite_lock(&obd->obd_pool_lock);\r\nobd->obd_pool_slv = new_slv;\r\nobd->obd_pool_limit = new_limit;\r\nwrite_unlock(&obd->obd_pool_lock);\r\nreturn 0;\r\n}\r\nint ldlm_cli_cancel(struct lustre_handle *lockh,\r\nldlm_cancel_flags_t cancel_flags)\r\n{\r\nstruct obd_export *exp;\r\nint avail, flags, count = 1;\r\n__u64 rc = 0;\r\nstruct ldlm_namespace *ns;\r\nstruct ldlm_lock *lock;\r\nLIST_HEAD(cancels);\r\nlock = ldlm_handle2lock_long(lockh, LDLM_FL_CANCELING);\r\nif (lock == NULL) {\r\nLDLM_DEBUG_NOLOCK("lock is already being destroyed\n");\r\nreturn 0;\r\n}\r\nrc = ldlm_cli_cancel_local(lock);\r\nif (rc == LDLM_FL_LOCAL_ONLY || cancel_flags & LCF_LOCAL) {\r\nLDLM_LOCK_RELEASE(lock);\r\nreturn 0;\r\n}\r\nLASSERT(list_empty(&lock->l_bl_ast));\r\nlist_add(&lock->l_bl_ast, &cancels);\r\nexp = lock->l_conn_export;\r\nif (exp_connect_cancelset(exp)) {\r\navail = ldlm_format_handles_avail(class_exp2cliimp(exp),\r\n&RQF_LDLM_CANCEL,\r\nRCL_CLIENT, 0);\r\nLASSERT(avail > 0);\r\nns = ldlm_lock_to_ns(lock);\r\nflags = ns_connect_lru_resize(ns) ?\r\nLDLM_CANCEL_LRUR : LDLM_CANCEL_AGED;\r\ncount += ldlm_cancel_lru_local(ns, &cancels, 0, avail - 1,\r\nLCF_BL_AST, flags);\r\n}\r\nldlm_cli_cancel_list(&cancels, count, NULL, cancel_flags);\r\nreturn 0;\r\n}\r\nint ldlm_cli_cancel_list_local(struct list_head *cancels, int count,\r\nldlm_cancel_flags_t flags)\r\n{\r\nLIST_HEAD(head);\r\nstruct ldlm_lock *lock, *next;\r\nint left = 0, bl_ast = 0;\r\n__u64 rc;\r\nleft = count;\r\nlist_for_each_entry_safe(lock, next, cancels, l_bl_ast) {\r\nif (left-- == 0)\r\nbreak;\r\nif (flags & LCF_LOCAL) {\r\nrc = LDLM_FL_LOCAL_ONLY;\r\nldlm_lock_cancel(lock);\r\n} else {\r\nrc = ldlm_cli_cancel_local(lock);\r\n}\r\nif (!(flags & LCF_BL_AST) && (rc == LDLM_FL_BL_AST)) {\r\nLDLM_DEBUG(lock, "Cancel lock separately");\r\nlist_del_init(&lock->l_bl_ast);\r\nlist_add(&lock->l_bl_ast, &head);\r\nbl_ast++;\r\ncontinue;\r\n}\r\nif (rc == LDLM_FL_LOCAL_ONLY) {\r\nlist_del_init(&lock->l_bl_ast);\r\nLDLM_LOCK_RELEASE(lock);\r\ncount--;\r\n}\r\n}\r\nif (bl_ast > 0) {\r\ncount -= bl_ast;\r\nldlm_cli_cancel_list(&head, bl_ast, NULL, 0);\r\n}\r\nreturn count;\r\n}\r\nstatic ldlm_policy_res_t ldlm_cancel_no_wait_policy(struct ldlm_namespace *ns,\r\nstruct ldlm_lock *lock,\r\nint unused, int added,\r\nint count)\r\n{\r\nldlm_policy_res_t result = LDLM_POLICY_CANCEL_LOCK;\r\nldlm_cancel_for_recovery cb = ns->ns_cancel_for_recovery;\r\nlock_res_and_lock(lock);\r\nswitch (lock->l_resource->lr_type) {\r\ncase LDLM_EXTENT:\r\ncase LDLM_IBITS:\r\nif (cb && cb(lock))\r\nbreak;\r\ndefault:\r\nresult = LDLM_POLICY_SKIP_LOCK;\r\nlock->l_flags |= LDLM_FL_SKIPPED;\r\nbreak;\r\n}\r\nunlock_res_and_lock(lock);\r\nreturn result;\r\n}\r\nstatic ldlm_policy_res_t ldlm_cancel_lrur_policy(struct ldlm_namespace *ns,\r\nstruct ldlm_lock *lock,\r\nint unused, int added,\r\nint count)\r\n{\r\nunsigned long cur = cfs_time_current();\r\nstruct ldlm_pool *pl = &ns->ns_pool;\r\n__u64 slv, lvf, lv;\r\nunsigned long la;\r\nif (count && added >= count)\r\nreturn LDLM_POLICY_KEEP_LOCK;\r\nslv = ldlm_pool_get_slv(pl);\r\nlvf = ldlm_pool_get_lvf(pl);\r\nla = cfs_duration_sec(cfs_time_sub(cur,\r\nlock->l_last_used));\r\nlv = lvf * la * unused;\r\nldlm_pool_set_clv(pl, lv);\r\nreturn (slv == 0 || lv < slv) ?\r\nLDLM_POLICY_KEEP_LOCK : LDLM_POLICY_CANCEL_LOCK;\r\n}\r\nstatic ldlm_policy_res_t ldlm_cancel_passed_policy(struct ldlm_namespace *ns,\r\nstruct ldlm_lock *lock,\r\nint unused, int added,\r\nint count)\r\n{\r\nreturn (added >= count) ?\r\nLDLM_POLICY_KEEP_LOCK : LDLM_POLICY_CANCEL_LOCK;\r\n}\r\nstatic ldlm_policy_res_t ldlm_cancel_aged_policy(struct ldlm_namespace *ns,\r\nstruct ldlm_lock *lock,\r\nint unused, int added,\r\nint count)\r\n{\r\nreturn ((added >= count) &&\r\ntime_before(cfs_time_current(),\r\ncfs_time_add(lock->l_last_used, ns->ns_max_age))) ?\r\nLDLM_POLICY_KEEP_LOCK : LDLM_POLICY_CANCEL_LOCK;\r\n}\r\nstatic ldlm_policy_res_t ldlm_cancel_default_policy(struct ldlm_namespace *ns,\r\nstruct ldlm_lock *lock,\r\nint unused, int added,\r\nint count)\r\n{\r\nreturn (added >= count) ?\r\nLDLM_POLICY_KEEP_LOCK : LDLM_POLICY_CANCEL_LOCK;\r\n}\r\nstatic ldlm_cancel_lru_policy_t\r\nldlm_cancel_lru_policy(struct ldlm_namespace *ns, int flags)\r\n{\r\nif (flags & LDLM_CANCEL_NO_WAIT)\r\nreturn ldlm_cancel_no_wait_policy;\r\nif (ns_connect_lru_resize(ns)) {\r\nif (flags & LDLM_CANCEL_SHRINK)\r\nreturn ldlm_cancel_passed_policy;\r\nelse if (flags & LDLM_CANCEL_LRUR)\r\nreturn ldlm_cancel_lrur_policy;\r\nelse if (flags & LDLM_CANCEL_PASSED)\r\nreturn ldlm_cancel_passed_policy;\r\n} else {\r\nif (flags & LDLM_CANCEL_AGED)\r\nreturn ldlm_cancel_aged_policy;\r\n}\r\nreturn ldlm_cancel_default_policy;\r\n}\r\nstatic int ldlm_prepare_lru_list(struct ldlm_namespace *ns,\r\nstruct list_head *cancels, int count, int max,\r\nint flags)\r\n{\r\nldlm_cancel_lru_policy_t pf;\r\nstruct ldlm_lock *lock, *next;\r\nint added = 0, unused, remained;\r\nspin_lock(&ns->ns_lock);\r\nunused = ns->ns_nr_unused;\r\nremained = unused;\r\nif (!ns_connect_lru_resize(ns))\r\ncount += unused - ns->ns_max_unused;\r\npf = ldlm_cancel_lru_policy(ns, flags);\r\nLASSERT(pf != NULL);\r\nwhile (!list_empty(&ns->ns_unused_list)) {\r\nldlm_policy_res_t result;\r\nif (remained-- <= 0)\r\nbreak;\r\nif (max && added >= max)\r\nbreak;\r\nlist_for_each_entry_safe(lock, next, &ns->ns_unused_list,\r\nl_lru) {\r\nLASSERT(!(lock->l_flags & LDLM_FL_BL_AST));\r\nif (flags & LDLM_CANCEL_NO_WAIT &&\r\nlock->l_flags & LDLM_FL_SKIPPED)\r\ncontinue;\r\nif (!(lock->l_flags & LDLM_FL_CANCELING))\r\nbreak;\r\nldlm_lock_remove_from_lru_nolock(lock);\r\n}\r\nif (&lock->l_lru == &ns->ns_unused_list)\r\nbreak;\r\nLDLM_LOCK_GET(lock);\r\nspin_unlock(&ns->ns_lock);\r\nlu_ref_add(&lock->l_reference, __func__, current);\r\nresult = pf(ns, lock, unused, added, count);\r\nif (result == LDLM_POLICY_KEEP_LOCK) {\r\nlu_ref_del(&lock->l_reference,\r\n__func__, current);\r\nLDLM_LOCK_RELEASE(lock);\r\nspin_lock(&ns->ns_lock);\r\nbreak;\r\n}\r\nif (result == LDLM_POLICY_SKIP_LOCK) {\r\nlu_ref_del(&lock->l_reference,\r\n__func__, current);\r\nLDLM_LOCK_RELEASE(lock);\r\nspin_lock(&ns->ns_lock);\r\ncontinue;\r\n}\r\nlock_res_and_lock(lock);\r\nif ((lock->l_flags & LDLM_FL_CANCELING) ||\r\n(ldlm_lock_remove_from_lru(lock) == 0)) {\r\nunlock_res_and_lock(lock);\r\nlu_ref_del(&lock->l_reference,\r\n__func__, current);\r\nLDLM_LOCK_RELEASE(lock);\r\nspin_lock(&ns->ns_lock);\r\ncontinue;\r\n}\r\nLASSERT(!lock->l_readers && !lock->l_writers);\r\nlock->l_flags &= ~LDLM_FL_CANCEL_ON_BLOCK;\r\nlock->l_flags |= LDLM_FL_CBPENDING | LDLM_FL_CANCELING;\r\nLASSERT(list_empty(&lock->l_bl_ast));\r\nlist_add(&lock->l_bl_ast, cancels);\r\nunlock_res_and_lock(lock);\r\nlu_ref_del(&lock->l_reference, __func__, current);\r\nspin_lock(&ns->ns_lock);\r\nadded++;\r\nunused--;\r\n}\r\nspin_unlock(&ns->ns_lock);\r\nreturn added;\r\n}\r\nint ldlm_cancel_lru_local(struct ldlm_namespace *ns, struct list_head *cancels,\r\nint count, int max, ldlm_cancel_flags_t cancel_flags,\r\nint flags)\r\n{\r\nint added;\r\nadded = ldlm_prepare_lru_list(ns, cancels, count, max, flags);\r\nif (added <= 0)\r\nreturn added;\r\nreturn ldlm_cli_cancel_list_local(cancels, added, cancel_flags);\r\n}\r\nint ldlm_cancel_lru(struct ldlm_namespace *ns, int nr,\r\nldlm_cancel_flags_t cancel_flags,\r\nint flags)\r\n{\r\nLIST_HEAD(cancels);\r\nint count, rc;\r\ncount = ldlm_prepare_lru_list(ns, &cancels, nr, 0, flags);\r\nrc = ldlm_bl_to_thread_list(ns, NULL, &cancels, count, cancel_flags);\r\nif (rc == 0)\r\nreturn count;\r\nreturn 0;\r\n}\r\nint ldlm_cancel_resource_local(struct ldlm_resource *res,\r\nstruct list_head *cancels,\r\nldlm_policy_data_t *policy,\r\nldlm_mode_t mode, __u64 lock_flags,\r\nldlm_cancel_flags_t cancel_flags, void *opaque)\r\n{\r\nstruct ldlm_lock *lock;\r\nint count = 0;\r\nlock_res(res);\r\nlist_for_each_entry(lock, &res->lr_granted, l_res_link) {\r\nif (opaque != NULL && lock->l_ast_data != opaque) {\r\nLDLM_ERROR(lock, "data %p doesn't match opaque %p",\r\nlock->l_ast_data, opaque);\r\ncontinue;\r\n}\r\nif (lock->l_readers || lock->l_writers)\r\ncontinue;\r\nif (lock->l_flags & LDLM_FL_BL_AST ||\r\nlock->l_flags & LDLM_FL_CANCELING)\r\ncontinue;\r\nif (lockmode_compat(lock->l_granted_mode, mode))\r\ncontinue;\r\nif (policy && (lock->l_resource->lr_type == LDLM_IBITS) &&\r\n!(lock->l_policy_data.l_inodebits.bits &\r\npolicy->l_inodebits.bits))\r\ncontinue;\r\nlock->l_flags |= LDLM_FL_CBPENDING | LDLM_FL_CANCELING |\r\nlock_flags;\r\nLASSERT(list_empty(&lock->l_bl_ast));\r\nlist_add(&lock->l_bl_ast, cancels);\r\nLDLM_LOCK_GET(lock);\r\ncount++;\r\n}\r\nunlock_res(res);\r\nreturn ldlm_cli_cancel_list_local(cancels, count, cancel_flags);\r\n}\r\nint ldlm_cli_cancel_list(struct list_head *cancels, int count,\r\nstruct ptlrpc_request *req, ldlm_cancel_flags_t flags)\r\n{\r\nstruct ldlm_lock *lock;\r\nint res = 0;\r\nif (list_empty(cancels) || count == 0)\r\nreturn 0;\r\nwhile (count > 0) {\r\nLASSERT(!list_empty(cancels));\r\nlock = list_entry(cancels->next, struct ldlm_lock,\r\nl_bl_ast);\r\nLASSERT(lock->l_conn_export);\r\nif (exp_connect_cancelset(lock->l_conn_export)) {\r\nres = count;\r\nif (req)\r\nldlm_cancel_pack(req, cancels, count);\r\nelse\r\nres = ldlm_cli_cancel_req(lock->l_conn_export,\r\ncancels, count,\r\nflags);\r\n} else {\r\nres = ldlm_cli_cancel_req(lock->l_conn_export,\r\ncancels, 1, flags);\r\n}\r\nif (res < 0) {\r\nCDEBUG_LIMIT(res == -ESHUTDOWN ? D_DLMTRACE : D_ERROR,\r\n"ldlm_cli_cancel_list: %d\n", res);\r\nres = count;\r\n}\r\ncount -= res;\r\nldlm_lock_list_put(cancels, l_bl_ast, res);\r\n}\r\nLASSERT(count == 0);\r\nreturn 0;\r\n}\r\nint ldlm_cli_cancel_unused_resource(struct ldlm_namespace *ns,\r\nconst struct ldlm_res_id *res_id,\r\nldlm_policy_data_t *policy,\r\nldlm_mode_t mode,\r\nldlm_cancel_flags_t flags,\r\nvoid *opaque)\r\n{\r\nstruct ldlm_resource *res;\r\nLIST_HEAD(cancels);\r\nint count;\r\nint rc;\r\nres = ldlm_resource_get(ns, NULL, res_id, 0, 0);\r\nif (res == NULL) {\r\nCDEBUG(D_INFO, "No resource %llu\n", res_id->name[0]);\r\nreturn 0;\r\n}\r\nLDLM_RESOURCE_ADDREF(res);\r\ncount = ldlm_cancel_resource_local(res, &cancels, policy, mode,\r\n0, flags | LCF_BL_AST, opaque);\r\nrc = ldlm_cli_cancel_list(&cancels, count, NULL, flags);\r\nif (rc != ELDLM_OK)\r\nCERROR("canceling unused lock "DLDLMRES": rc = %d\n",\r\nPLDLMRES(res), rc);\r\nLDLM_RESOURCE_DELREF(res);\r\nldlm_resource_putref(res);\r\nreturn 0;\r\n}\r\nstatic int ldlm_cli_hash_cancel_unused(struct cfs_hash *hs,\r\nstruct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode, void *arg)\r\n{\r\nstruct ldlm_resource *res = cfs_hash_object(hs, hnode);\r\nstruct ldlm_cli_cancel_arg *lc = arg;\r\nldlm_cli_cancel_unused_resource(ldlm_res_to_ns(res), &res->lr_name,\r\nNULL, LCK_MINMODE,\r\nlc->lc_flags, lc->lc_opaque);\r\nreturn 0;\r\n}\r\nint ldlm_cli_cancel_unused(struct ldlm_namespace *ns,\r\nconst struct ldlm_res_id *res_id,\r\nldlm_cancel_flags_t flags, void *opaque)\r\n{\r\nstruct ldlm_cli_cancel_arg arg = {\r\n.lc_flags = flags,\r\n.lc_opaque = opaque,\r\n};\r\nif (ns == NULL)\r\nreturn ELDLM_OK;\r\nif (res_id != NULL) {\r\nreturn ldlm_cli_cancel_unused_resource(ns, res_id, NULL,\r\nLCK_MINMODE, flags,\r\nopaque);\r\n} else {\r\ncfs_hash_for_each_nolock(ns->ns_rs_hash,\r\nldlm_cli_hash_cancel_unused, &arg);\r\nreturn ELDLM_OK;\r\n}\r\n}\r\nint ldlm_resource_foreach(struct ldlm_resource *res, ldlm_iterator_t iter,\r\nvoid *closure)\r\n{\r\nstruct list_head *tmp, *next;\r\nstruct ldlm_lock *lock;\r\nint rc = LDLM_ITER_CONTINUE;\r\nif (!res)\r\nreturn LDLM_ITER_CONTINUE;\r\nlock_res(res);\r\nlist_for_each_safe(tmp, next, &res->lr_granted) {\r\nlock = list_entry(tmp, struct ldlm_lock, l_res_link);\r\nif (iter(lock, closure) == LDLM_ITER_STOP) {\r\nrc = LDLM_ITER_STOP;\r\ngoto out;\r\n}\r\n}\r\nlist_for_each_safe(tmp, next, &res->lr_converting) {\r\nlock = list_entry(tmp, struct ldlm_lock, l_res_link);\r\nif (iter(lock, closure) == LDLM_ITER_STOP) {\r\nrc = LDLM_ITER_STOP;\r\ngoto out;\r\n}\r\n}\r\nlist_for_each_safe(tmp, next, &res->lr_waiting) {\r\nlock = list_entry(tmp, struct ldlm_lock, l_res_link);\r\nif (iter(lock, closure) == LDLM_ITER_STOP) {\r\nrc = LDLM_ITER_STOP;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nunlock_res(res);\r\nreturn rc;\r\n}\r\nstatic int ldlm_iter_helper(struct ldlm_lock *lock, void *closure)\r\n{\r\nstruct iter_helper_data *helper = closure;\r\nreturn helper->iter(lock, helper->closure);\r\n}\r\nstatic int ldlm_res_iter_helper(struct cfs_hash *hs, struct cfs_hash_bd *bd,\r\nstruct hlist_node *hnode, void *arg)\r\n{\r\nstruct ldlm_resource *res = cfs_hash_object(hs, hnode);\r\nreturn ldlm_resource_foreach(res, ldlm_iter_helper, arg) ==\r\nLDLM_ITER_STOP;\r\n}\r\nvoid ldlm_namespace_foreach(struct ldlm_namespace *ns,\r\nldlm_iterator_t iter, void *closure)\r\n{\r\nstruct iter_helper_data helper = {\r\n.iter = iter,\r\n.closure = closure,\r\n};\r\ncfs_hash_for_each_nolock(ns->ns_rs_hash,\r\nldlm_res_iter_helper, &helper);\r\n}\r\nint ldlm_resource_iterate(struct ldlm_namespace *ns,\r\nconst struct ldlm_res_id *res_id,\r\nldlm_iterator_t iter, void *data)\r\n{\r\nstruct ldlm_resource *res;\r\nint rc;\r\nif (ns == NULL) {\r\nCERROR("must pass in namespace\n");\r\nLBUG();\r\n}\r\nres = ldlm_resource_get(ns, NULL, res_id, 0, 0);\r\nif (res == NULL)\r\nreturn 0;\r\nLDLM_RESOURCE_ADDREF(res);\r\nrc = ldlm_resource_foreach(res, iter, data);\r\nLDLM_RESOURCE_DELREF(res);\r\nldlm_resource_putref(res);\r\nreturn rc;\r\n}\r\nstatic int ldlm_chain_lock_for_replay(struct ldlm_lock *lock, void *closure)\r\n{\r\nstruct list_head *list = closure;\r\nLASSERTF(list_empty(&lock->l_pending_chain),\r\n"lock %p next %p prev %p\n",\r\nlock, &lock->l_pending_chain.next,\r\n&lock->l_pending_chain.prev);\r\nif (!(lock->l_flags & (LDLM_FL_FAILED|LDLM_FL_CANCELING))) {\r\nlist_add(&lock->l_pending_chain, list);\r\nLDLM_LOCK_GET(lock);\r\n}\r\nreturn LDLM_ITER_CONTINUE;\r\n}\r\nstatic int replay_lock_interpret(const struct lu_env *env,\r\nstruct ptlrpc_request *req,\r\nstruct ldlm_async_args *aa, int rc)\r\n{\r\nstruct ldlm_lock *lock;\r\nstruct ldlm_reply *reply;\r\nstruct obd_export *exp;\r\natomic_dec(&req->rq_import->imp_replay_inflight);\r\nif (rc != ELDLM_OK)\r\ngoto out;\r\nreply = req_capsule_server_get(&req->rq_pill, &RMF_DLM_REP);\r\nif (reply == NULL) {\r\nrc = -EPROTO;\r\ngoto out;\r\n}\r\nlock = ldlm_handle2lock(&aa->lock_handle);\r\nif (!lock) {\r\nCERROR("received replay ack for unknown local cookie %#llx remote cookie %#llx from server %s id %s\n",\r\naa->lock_handle.cookie, reply->lock_handle.cookie,\r\nreq->rq_export->exp_client_uuid.uuid,\r\nlibcfs_id2str(req->rq_peer));\r\nrc = -ESTALE;\r\ngoto out;\r\n}\r\nexp = req->rq_export;\r\nif (exp && exp->exp_lock_hash) {\r\ncfs_hash_rehash_key(exp->exp_lock_hash,\r\n&lock->l_remote_handle,\r\n&reply->lock_handle,\r\n&lock->l_exp_hash);\r\n} else {\r\nlock->l_remote_handle = reply->lock_handle;\r\n}\r\nLDLM_DEBUG(lock, "replayed lock:");\r\nptlrpc_import_recovery_state_machine(req->rq_import);\r\nLDLM_LOCK_PUT(lock);\r\nout:\r\nif (rc != ELDLM_OK)\r\nptlrpc_connect_import(req->rq_import);\r\nreturn rc;\r\n}\r\nstatic int replay_one_lock(struct obd_import *imp, struct ldlm_lock *lock)\r\n{\r\nstruct ptlrpc_request *req;\r\nstruct ldlm_async_args *aa;\r\nstruct ldlm_request *body;\r\nint flags;\r\nif (lock->l_flags & LDLM_FL_CANCELING) {\r\nLDLM_DEBUG(lock, "Not replaying canceled lock:");\r\nreturn 0;\r\n}\r\nif (lock->l_flags & LDLM_FL_CANCEL_ON_BLOCK) {\r\nLDLM_DEBUG(lock, "Not replaying reply-less lock:");\r\nldlm_lock_cancel(lock);\r\nreturn 0;\r\n}\r\nif (lock->l_granted_mode == lock->l_req_mode)\r\nflags = LDLM_FL_REPLAY | LDLM_FL_BLOCK_GRANTED;\r\nelse if (lock->l_granted_mode)\r\nflags = LDLM_FL_REPLAY | LDLM_FL_BLOCK_CONV;\r\nelse if (!list_empty(&lock->l_res_link))\r\nflags = LDLM_FL_REPLAY | LDLM_FL_BLOCK_WAIT;\r\nelse\r\nflags = LDLM_FL_REPLAY;\r\nreq = ptlrpc_request_alloc_pack(imp, &RQF_LDLM_ENQUEUE,\r\nLUSTRE_DLM_VERSION, LDLM_ENQUEUE);\r\nif (req == NULL)\r\nreturn -ENOMEM;\r\nreq->rq_send_state = LUSTRE_IMP_REPLAY_LOCKS;\r\nbody = req_capsule_client_get(&req->rq_pill, &RMF_DLM_REQ);\r\nldlm_lock2desc(lock, &body->lock_desc);\r\nbody->lock_flags = ldlm_flags_to_wire(flags);\r\nldlm_lock2handle(lock, &body->lock_handle[0]);\r\nif (lock->l_lvb_len > 0)\r\nreq_capsule_extend(&req->rq_pill, &RQF_LDLM_ENQUEUE_LVB);\r\nreq_capsule_set_size(&req->rq_pill, &RMF_DLM_LVB, RCL_SERVER,\r\nlock->l_lvb_len);\r\nptlrpc_request_set_replen(req);\r\nlustre_msg_set_flags(req->rq_reqmsg, MSG_REQ_REPLAY_DONE);\r\nLDLM_DEBUG(lock, "replaying lock:");\r\natomic_inc(&req->rq_import->imp_replay_inflight);\r\nCLASSERT(sizeof(*aa) <= sizeof(req->rq_async_args));\r\naa = ptlrpc_req_async_args(req);\r\naa->lock_handle = body->lock_handle[0];\r\nreq->rq_interpret_reply = (ptlrpc_interpterer_t)replay_lock_interpret;\r\nptlrpcd_add_req(req, PDL_POLICY_LOCAL, -1);\r\nreturn 0;\r\n}\r\nstatic void ldlm_cancel_unused_locks_for_replay(struct ldlm_namespace *ns)\r\n{\r\nint canceled;\r\nLIST_HEAD(cancels);\r\nCDEBUG(D_DLMTRACE, "Dropping as many unused locks as possible before replay for namespace %s (%d)\n",\r\nldlm_ns_name(ns), ns->ns_nr_unused);\r\ncanceled = ldlm_cancel_lru_local(ns, &cancels, ns->ns_nr_unused, 0,\r\nLCF_LOCAL, LDLM_CANCEL_NO_WAIT);\r\nCDEBUG(D_DLMTRACE, "Canceled %d unused locks from namespace %s\n",\r\ncanceled, ldlm_ns_name(ns));\r\n}\r\nint ldlm_replay_locks(struct obd_import *imp)\r\n{\r\nstruct ldlm_namespace *ns = imp->imp_obd->obd_namespace;\r\nLIST_HEAD(list);\r\nstruct ldlm_lock *lock, *next;\r\nint rc = 0;\r\nLASSERT(atomic_read(&imp->imp_replay_inflight) == 0);\r\nif (imp->imp_vbr_failed)\r\nreturn 0;\r\natomic_inc(&imp->imp_replay_inflight);\r\nif (ldlm_cancel_unused_locks_before_replay)\r\nldlm_cancel_unused_locks_for_replay(ns);\r\nldlm_namespace_foreach(ns, ldlm_chain_lock_for_replay, &list);\r\nlist_for_each_entry_safe(lock, next, &list, l_pending_chain) {\r\nlist_del_init(&lock->l_pending_chain);\r\nif (rc) {\r\nLDLM_LOCK_RELEASE(lock);\r\ncontinue;\r\n}\r\nrc = replay_one_lock(imp, lock);\r\nLDLM_LOCK_RELEASE(lock);\r\n}\r\natomic_dec(&imp->imp_replay_inflight);\r\nreturn rc;\r\n}
