static IOCB_t *\r\nlpfc_get_iocb_from_iocbq(struct lpfc_iocbq *iocbq)\r\n{\r\nreturn &iocbq->iocb;\r\n}\r\nstatic uint32_t\r\nlpfc_sli4_wq_put(struct lpfc_queue *q, union lpfc_wqe *wqe)\r\n{\r\nunion lpfc_wqe *temp_wqe;\r\nstruct lpfc_register doorbell;\r\nuint32_t host_index;\r\nuint32_t idx;\r\nif (unlikely(!q))\r\nreturn -ENOMEM;\r\ntemp_wqe = q->qe[q->host_index].wqe;\r\nidx = ((q->host_index + 1) % q->entry_count);\r\nif (idx == q->hba_index) {\r\nq->WQ_overflow++;\r\nreturn -ENOMEM;\r\n}\r\nq->WQ_posted++;\r\nif (!((q->host_index + 1) % q->entry_repost))\r\nbf_set(wqe_wqec, &wqe->generic.wqe_com, 1);\r\nif (q->phba->sli3_options & LPFC_SLI4_PHWQ_ENABLED)\r\nbf_set(wqe_wqid, &wqe->generic.wqe_com, q->queue_id);\r\nlpfc_sli_pcimem_bcopy(wqe, temp_wqe, q->entry_size);\r\nhost_index = q->host_index;\r\nq->host_index = idx;\r\ndoorbell.word0 = 0;\r\nif (q->db_format == LPFC_DB_LIST_FORMAT) {\r\nbf_set(lpfc_wq_db_list_fm_num_posted, &doorbell, 1);\r\nbf_set(lpfc_wq_db_list_fm_index, &doorbell, host_index);\r\nbf_set(lpfc_wq_db_list_fm_id, &doorbell, q->queue_id);\r\n} else if (q->db_format == LPFC_DB_RING_FORMAT) {\r\nbf_set(lpfc_wq_db_ring_fm_num_posted, &doorbell, 1);\r\nbf_set(lpfc_wq_db_ring_fm_id, &doorbell, q->queue_id);\r\n} else {\r\nreturn -EINVAL;\r\n}\r\nwritel(doorbell.word0, q->db_regaddr);\r\nreturn 0;\r\n}\r\nstatic uint32_t\r\nlpfc_sli4_wq_release(struct lpfc_queue *q, uint32_t index)\r\n{\r\nuint32_t released = 0;\r\nif (unlikely(!q))\r\nreturn 0;\r\nif (q->hba_index == index)\r\nreturn 0;\r\ndo {\r\nq->hba_index = ((q->hba_index + 1) % q->entry_count);\r\nreleased++;\r\n} while (q->hba_index != index);\r\nreturn released;\r\n}\r\nstatic uint32_t\r\nlpfc_sli4_mq_put(struct lpfc_queue *q, struct lpfc_mqe *mqe)\r\n{\r\nstruct lpfc_mqe *temp_mqe;\r\nstruct lpfc_register doorbell;\r\nif (unlikely(!q))\r\nreturn -ENOMEM;\r\ntemp_mqe = q->qe[q->host_index].mqe;\r\nif (((q->host_index + 1) % q->entry_count) == q->hba_index)\r\nreturn -ENOMEM;\r\nlpfc_sli_pcimem_bcopy(mqe, temp_mqe, q->entry_size);\r\nq->phba->mbox = (MAILBOX_t *)temp_mqe;\r\nq->host_index = ((q->host_index + 1) % q->entry_count);\r\ndoorbell.word0 = 0;\r\nbf_set(lpfc_mq_doorbell_num_posted, &doorbell, 1);\r\nbf_set(lpfc_mq_doorbell_id, &doorbell, q->queue_id);\r\nwritel(doorbell.word0, q->phba->sli4_hba.MQDBregaddr);\r\nreturn 0;\r\n}\r\nstatic uint32_t\r\nlpfc_sli4_mq_release(struct lpfc_queue *q)\r\n{\r\nif (unlikely(!q))\r\nreturn 0;\r\nq->phba->mbox = NULL;\r\nq->hba_index = ((q->hba_index + 1) % q->entry_count);\r\nreturn 1;\r\n}\r\nstatic struct lpfc_eqe *\r\nlpfc_sli4_eq_get(struct lpfc_queue *q)\r\n{\r\nstruct lpfc_eqe *eqe;\r\nuint32_t idx;\r\nif (unlikely(!q))\r\nreturn NULL;\r\neqe = q->qe[q->hba_index].eqe;\r\nif (!bf_get_le32(lpfc_eqe_valid, eqe))\r\nreturn NULL;\r\nidx = ((q->hba_index + 1) % q->entry_count);\r\nif (idx == q->host_index)\r\nreturn NULL;\r\nq->hba_index = idx;\r\nmb();\r\nreturn eqe;\r\n}\r\nstatic inline void\r\nlpfc_sli4_eq_clr_intr(struct lpfc_queue *q)\r\n{\r\nstruct lpfc_register doorbell;\r\ndoorbell.word0 = 0;\r\nbf_set(lpfc_eqcq_doorbell_eqci, &doorbell, 1);\r\nbf_set(lpfc_eqcq_doorbell_qt, &doorbell, LPFC_QUEUE_TYPE_EVENT);\r\nbf_set(lpfc_eqcq_doorbell_eqid_hi, &doorbell,\r\n(q->queue_id >> LPFC_EQID_HI_FIELD_SHIFT));\r\nbf_set(lpfc_eqcq_doorbell_eqid_lo, &doorbell, q->queue_id);\r\nwritel(doorbell.word0, q->phba->sli4_hba.EQCQDBregaddr);\r\n}\r\nuint32_t\r\nlpfc_sli4_eq_release(struct lpfc_queue *q, bool arm)\r\n{\r\nuint32_t released = 0;\r\nstruct lpfc_eqe *temp_eqe;\r\nstruct lpfc_register doorbell;\r\nif (unlikely(!q))\r\nreturn 0;\r\nwhile (q->hba_index != q->host_index) {\r\ntemp_eqe = q->qe[q->host_index].eqe;\r\nbf_set_le32(lpfc_eqe_valid, temp_eqe, 0);\r\nreleased++;\r\nq->host_index = ((q->host_index + 1) % q->entry_count);\r\n}\r\nif (unlikely(released == 0 && !arm))\r\nreturn 0;\r\ndoorbell.word0 = 0;\r\nif (arm) {\r\nbf_set(lpfc_eqcq_doorbell_arm, &doorbell, 1);\r\nbf_set(lpfc_eqcq_doorbell_eqci, &doorbell, 1);\r\n}\r\nbf_set(lpfc_eqcq_doorbell_num_released, &doorbell, released);\r\nbf_set(lpfc_eqcq_doorbell_qt, &doorbell, LPFC_QUEUE_TYPE_EVENT);\r\nbf_set(lpfc_eqcq_doorbell_eqid_hi, &doorbell,\r\n(q->queue_id >> LPFC_EQID_HI_FIELD_SHIFT));\r\nbf_set(lpfc_eqcq_doorbell_eqid_lo, &doorbell, q->queue_id);\r\nwritel(doorbell.word0, q->phba->sli4_hba.EQCQDBregaddr);\r\nif ((q->phba->intr_type == INTx) && (arm == LPFC_QUEUE_REARM))\r\nreadl(q->phba->sli4_hba.EQCQDBregaddr);\r\nreturn released;\r\n}\r\nstatic struct lpfc_cqe *\r\nlpfc_sli4_cq_get(struct lpfc_queue *q)\r\n{\r\nstruct lpfc_cqe *cqe;\r\nuint32_t idx;\r\nif (unlikely(!q))\r\nreturn NULL;\r\nif (!bf_get_le32(lpfc_cqe_valid, q->qe[q->hba_index].cqe))\r\nreturn NULL;\r\nidx = ((q->hba_index + 1) % q->entry_count);\r\nif (idx == q->host_index)\r\nreturn NULL;\r\ncqe = q->qe[q->hba_index].cqe;\r\nq->hba_index = idx;\r\nmb();\r\nreturn cqe;\r\n}\r\nuint32_t\r\nlpfc_sli4_cq_release(struct lpfc_queue *q, bool arm)\r\n{\r\nuint32_t released = 0;\r\nstruct lpfc_cqe *temp_qe;\r\nstruct lpfc_register doorbell;\r\nif (unlikely(!q))\r\nreturn 0;\r\nwhile (q->hba_index != q->host_index) {\r\ntemp_qe = q->qe[q->host_index].cqe;\r\nbf_set_le32(lpfc_cqe_valid, temp_qe, 0);\r\nreleased++;\r\nq->host_index = ((q->host_index + 1) % q->entry_count);\r\n}\r\nif (unlikely(released == 0 && !arm))\r\nreturn 0;\r\ndoorbell.word0 = 0;\r\nif (arm)\r\nbf_set(lpfc_eqcq_doorbell_arm, &doorbell, 1);\r\nbf_set(lpfc_eqcq_doorbell_num_released, &doorbell, released);\r\nbf_set(lpfc_eqcq_doorbell_qt, &doorbell, LPFC_QUEUE_TYPE_COMPLETION);\r\nbf_set(lpfc_eqcq_doorbell_cqid_hi, &doorbell,\r\n(q->queue_id >> LPFC_CQID_HI_FIELD_SHIFT));\r\nbf_set(lpfc_eqcq_doorbell_cqid_lo, &doorbell, q->queue_id);\r\nwritel(doorbell.word0, q->phba->sli4_hba.EQCQDBregaddr);\r\nreturn released;\r\n}\r\nstatic int\r\nlpfc_sli4_rq_put(struct lpfc_queue *hq, struct lpfc_queue *dq,\r\nstruct lpfc_rqe *hrqe, struct lpfc_rqe *drqe)\r\n{\r\nstruct lpfc_rqe *temp_hrqe;\r\nstruct lpfc_rqe *temp_drqe;\r\nstruct lpfc_register doorbell;\r\nint put_index;\r\nif (unlikely(!hq) || unlikely(!dq))\r\nreturn -ENOMEM;\r\nput_index = hq->host_index;\r\ntemp_hrqe = hq->qe[hq->host_index].rqe;\r\ntemp_drqe = dq->qe[dq->host_index].rqe;\r\nif (hq->type != LPFC_HRQ || dq->type != LPFC_DRQ)\r\nreturn -EINVAL;\r\nif (hq->host_index != dq->host_index)\r\nreturn -EINVAL;\r\nif (((hq->host_index + 1) % hq->entry_count) == hq->hba_index)\r\nreturn -EBUSY;\r\nlpfc_sli_pcimem_bcopy(hrqe, temp_hrqe, hq->entry_size);\r\nlpfc_sli_pcimem_bcopy(drqe, temp_drqe, dq->entry_size);\r\nhq->host_index = ((hq->host_index + 1) % hq->entry_count);\r\ndq->host_index = ((dq->host_index + 1) % dq->entry_count);\r\nif (!(hq->host_index % hq->entry_repost)) {\r\ndoorbell.word0 = 0;\r\nif (hq->db_format == LPFC_DB_RING_FORMAT) {\r\nbf_set(lpfc_rq_db_ring_fm_num_posted, &doorbell,\r\nhq->entry_repost);\r\nbf_set(lpfc_rq_db_ring_fm_id, &doorbell, hq->queue_id);\r\n} else if (hq->db_format == LPFC_DB_LIST_FORMAT) {\r\nbf_set(lpfc_rq_db_list_fm_num_posted, &doorbell,\r\nhq->entry_repost);\r\nbf_set(lpfc_rq_db_list_fm_index, &doorbell,\r\nhq->host_index);\r\nbf_set(lpfc_rq_db_list_fm_id, &doorbell, hq->queue_id);\r\n} else {\r\nreturn -EINVAL;\r\n}\r\nwritel(doorbell.word0, hq->db_regaddr);\r\n}\r\nreturn put_index;\r\n}\r\nstatic uint32_t\r\nlpfc_sli4_rq_release(struct lpfc_queue *hq, struct lpfc_queue *dq)\r\n{\r\nif (unlikely(!hq) || unlikely(!dq))\r\nreturn 0;\r\nif ((hq->type != LPFC_HRQ) || (dq->type != LPFC_DRQ))\r\nreturn 0;\r\nhq->hba_index = ((hq->hba_index + 1) % hq->entry_count);\r\ndq->hba_index = ((dq->hba_index + 1) % dq->entry_count);\r\nreturn 1;\r\n}\r\nstatic inline IOCB_t *\r\nlpfc_cmd_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nreturn (IOCB_t *) (((char *) pring->sli.sli3.cmdringaddr) +\r\npring->sli.sli3.cmdidx * phba->iocb_cmd_size);\r\n}\r\nstatic inline IOCB_t *\r\nlpfc_resp_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nreturn (IOCB_t *) (((char *) pring->sli.sli3.rspringaddr) +\r\npring->sli.sli3.rspidx * phba->iocb_rsp_size);\r\n}\r\nstruct lpfc_iocbq *\r\n__lpfc_sli_get_iocbq(struct lpfc_hba *phba)\r\n{\r\nstruct list_head *lpfc_iocb_list = &phba->lpfc_iocb_list;\r\nstruct lpfc_iocbq * iocbq = NULL;\r\nlist_remove_head(lpfc_iocb_list, iocbq, struct lpfc_iocbq, list);\r\nif (iocbq)\r\nphba->iocb_cnt++;\r\nif (phba->iocb_cnt > phba->iocb_max)\r\nphba->iocb_max = phba->iocb_cnt;\r\nreturn iocbq;\r\n}\r\nstatic struct lpfc_sglq *\r\n__lpfc_clear_active_sglq(struct lpfc_hba *phba, uint16_t xritag)\r\n{\r\nstruct lpfc_sglq *sglq;\r\nsglq = phba->sli4_hba.lpfc_sglq_active_list[xritag];\r\nphba->sli4_hba.lpfc_sglq_active_list[xritag] = NULL;\r\nreturn sglq;\r\n}\r\nstruct lpfc_sglq *\r\n__lpfc_get_active_sglq(struct lpfc_hba *phba, uint16_t xritag)\r\n{\r\nstruct lpfc_sglq *sglq;\r\nsglq = phba->sli4_hba.lpfc_sglq_active_list[xritag];\r\nreturn sglq;\r\n}\r\nvoid\r\nlpfc_clr_rrq_active(struct lpfc_hba *phba,\r\nuint16_t xritag,\r\nstruct lpfc_node_rrq *rrq)\r\n{\r\nstruct lpfc_nodelist *ndlp = NULL;\r\nif ((rrq->vport) && NLP_CHK_NODE_ACT(rrq->ndlp))\r\nndlp = lpfc_findnode_did(rrq->vport, rrq->nlp_DID);\r\nif ((!ndlp) && rrq->ndlp)\r\nndlp = rrq->ndlp;\r\nif (!ndlp)\r\ngoto out;\r\nif (test_and_clear_bit(xritag, ndlp->active_rrqs_xri_bitmap)) {\r\nrrq->send_rrq = 0;\r\nrrq->xritag = 0;\r\nrrq->rrq_stop_time = 0;\r\n}\r\nout:\r\nmempool_free(rrq, phba->rrq_pool);\r\n}\r\nvoid\r\nlpfc_handle_rrq_active(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_node_rrq *rrq;\r\nstruct lpfc_node_rrq *nextrrq;\r\nunsigned long next_time;\r\nunsigned long iflags;\r\nLIST_HEAD(send_rrq);\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nphba->hba_flag &= ~HBA_RRQ_ACTIVE;\r\nnext_time = jiffies + msecs_to_jiffies(1000 * (phba->fc_ratov + 1));\r\nlist_for_each_entry_safe(rrq, nextrrq,\r\n&phba->active_rrq_list, list) {\r\nif (time_after(jiffies, rrq->rrq_stop_time))\r\nlist_move(&rrq->list, &send_rrq);\r\nelse if (time_before(rrq->rrq_stop_time, next_time))\r\nnext_time = rrq->rrq_stop_time;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nif ((!list_empty(&phba->active_rrq_list)) &&\r\n(!(phba->pport->load_flag & FC_UNLOADING)))\r\nmod_timer(&phba->rrq_tmr, next_time);\r\nlist_for_each_entry_safe(rrq, nextrrq, &send_rrq, list) {\r\nlist_del(&rrq->list);\r\nif (!rrq->send_rrq)\r\nlpfc_clr_rrq_active(phba, rrq->xritag, rrq);\r\nelse if (lpfc_send_rrq(phba, rrq)) {\r\nlpfc_clr_rrq_active(phba, rrq->xritag,\r\nrrq);\r\n}\r\n}\r\n}\r\nstruct lpfc_node_rrq *\r\nlpfc_get_active_rrq(struct lpfc_vport *vport, uint16_t xri, uint32_t did)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_node_rrq *rrq;\r\nstruct lpfc_node_rrq *nextrrq;\r\nunsigned long iflags;\r\nif (phba->sli_rev != LPFC_SLI_REV4)\r\nreturn NULL;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nlist_for_each_entry_safe(rrq, nextrrq, &phba->active_rrq_list, list) {\r\nif (rrq->vport == vport && rrq->xritag == xri &&\r\nrrq->nlp_DID == did){\r\nlist_del(&rrq->list);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn rrq;\r\n}\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn NULL;\r\n}\r\nvoid\r\nlpfc_cleanup_vports_rrqs(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_node_rrq *rrq;\r\nstruct lpfc_node_rrq *nextrrq;\r\nunsigned long iflags;\r\nLIST_HEAD(rrq_list);\r\nif (phba->sli_rev != LPFC_SLI_REV4)\r\nreturn;\r\nif (!ndlp) {\r\nlpfc_sli4_vport_delete_els_xri_aborted(vport);\r\nlpfc_sli4_vport_delete_fcp_xri_aborted(vport);\r\n}\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nlist_for_each_entry_safe(rrq, nextrrq, &phba->active_rrq_list, list)\r\nif ((rrq->vport == vport) && (!ndlp || rrq->ndlp == ndlp))\r\nlist_move(&rrq->list, &rrq_list);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nlist_for_each_entry_safe(rrq, nextrrq, &rrq_list, list) {\r\nlist_del(&rrq->list);\r\nlpfc_clr_rrq_active(phba, rrq->xritag, rrq);\r\n}\r\n}\r\nint\r\nlpfc_test_rrq_active(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp,\r\nuint16_t xritag)\r\n{\r\nif (!ndlp)\r\nreturn 0;\r\nif (!ndlp->active_rrqs_xri_bitmap)\r\nreturn 0;\r\nif (test_bit(xritag, ndlp->active_rrqs_xri_bitmap))\r\nreturn 1;\r\nelse\r\nreturn 0;\r\n}\r\nint\r\nlpfc_set_rrq_active(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp,\r\nuint16_t xritag, uint16_t rxid, uint16_t send_rrq)\r\n{\r\nunsigned long iflags;\r\nstruct lpfc_node_rrq *rrq;\r\nint empty;\r\nif (!ndlp)\r\nreturn -EINVAL;\r\nif (!phba->cfg_enable_rrq)\r\nreturn -EINVAL;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nif (phba->pport->load_flag & FC_UNLOADING) {\r\nphba->hba_flag &= ~HBA_RRQ_ACTIVE;\r\ngoto out;\r\n}\r\nif (NLP_CHK_FREE_REQ(ndlp))\r\ngoto out;\r\nif (ndlp->vport && (ndlp->vport->load_flag & FC_UNLOADING))\r\ngoto out;\r\nif (!ndlp->active_rrqs_xri_bitmap)\r\ngoto out;\r\nif (test_and_set_bit(xritag, ndlp->active_rrqs_xri_bitmap))\r\ngoto out;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nrrq = mempool_alloc(phba->rrq_pool, GFP_KERNEL);\r\nif (!rrq) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"3155 Unable to allocate RRQ xri:0x%x rxid:0x%x"\r\n" DID:0x%x Send:%d\n",\r\nxritag, rxid, ndlp->nlp_DID, send_rrq);\r\nreturn -EINVAL;\r\n}\r\nif (phba->cfg_enable_rrq == 1)\r\nrrq->send_rrq = send_rrq;\r\nelse\r\nrrq->send_rrq = 0;\r\nrrq->xritag = xritag;\r\nrrq->rrq_stop_time = jiffies +\r\nmsecs_to_jiffies(1000 * (phba->fc_ratov + 1));\r\nrrq->ndlp = ndlp;\r\nrrq->nlp_DID = ndlp->nlp_DID;\r\nrrq->vport = ndlp->vport;\r\nrrq->rxid = rxid;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nempty = list_empty(&phba->active_rrq_list);\r\nlist_add_tail(&rrq->list, &phba->active_rrq_list);\r\nphba->hba_flag |= HBA_RRQ_ACTIVE;\r\nif (empty)\r\nlpfc_worker_wake_up(phba);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn 0;\r\nout:\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"2921 Can't set rrq active xri:0x%x rxid:0x%x"\r\n" DID:0x%x Send:%d\n",\r\nxritag, rxid, ndlp->nlp_DID, send_rrq);\r\nreturn -EINVAL;\r\n}\r\nstatic struct lpfc_sglq *\r\n__lpfc_sli_get_sglq(struct lpfc_hba *phba, struct lpfc_iocbq *piocbq)\r\n{\r\nstruct list_head *lpfc_sgl_list = &phba->sli4_hba.lpfc_sgl_list;\r\nstruct lpfc_sglq *sglq = NULL;\r\nstruct lpfc_sglq *start_sglq = NULL;\r\nstruct lpfc_scsi_buf *lpfc_cmd;\r\nstruct lpfc_nodelist *ndlp;\r\nint found = 0;\r\nif (piocbq->iocb_flag & LPFC_IO_FCP) {\r\nlpfc_cmd = (struct lpfc_scsi_buf *) piocbq->context1;\r\nndlp = lpfc_cmd->rdata->pnode;\r\n} else if ((piocbq->iocb.ulpCommand == CMD_GEN_REQUEST64_CR) &&\r\n!(piocbq->iocb_flag & LPFC_IO_LIBDFC)) {\r\nndlp = piocbq->context_un.ndlp;\r\n} else if (piocbq->iocb_flag & LPFC_IO_LIBDFC) {\r\nif (piocbq->iocb_flag & LPFC_IO_LOOPBACK)\r\nndlp = NULL;\r\nelse\r\nndlp = piocbq->context_un.ndlp;\r\n} else {\r\nndlp = piocbq->context1;\r\n}\r\nlist_remove_head(lpfc_sgl_list, sglq, struct lpfc_sglq, list);\r\nstart_sglq = sglq;\r\nwhile (!found) {\r\nif (!sglq)\r\nreturn NULL;\r\nif (lpfc_test_rrq_active(phba, ndlp, sglq->sli4_lxritag)) {\r\nlist_add_tail(&sglq->list, lpfc_sgl_list);\r\nsglq = NULL;\r\nlist_remove_head(lpfc_sgl_list, sglq,\r\nstruct lpfc_sglq, list);\r\nif (sglq == start_sglq) {\r\nsglq = NULL;\r\nbreak;\r\n} else\r\ncontinue;\r\n}\r\nsglq->ndlp = ndlp;\r\nfound = 1;\r\nphba->sli4_hba.lpfc_sglq_active_list[sglq->sli4_lxritag] = sglq;\r\nsglq->state = SGL_ALLOCATED;\r\n}\r\nreturn sglq;\r\n}\r\nstruct lpfc_iocbq *\r\nlpfc_sli_get_iocbq(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_iocbq * iocbq = NULL;\r\nunsigned long iflags;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\niocbq = __lpfc_sli_get_iocbq(phba);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn iocbq;\r\n}\r\nstatic void\r\n__lpfc_sli_release_iocbq_s4(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\r\n{\r\nstruct lpfc_sglq *sglq;\r\nsize_t start_clean = offsetof(struct lpfc_iocbq, iocb);\r\nunsigned long iflag = 0;\r\nstruct lpfc_sli_ring *pring = &phba->sli.ring[LPFC_ELS_RING];\r\nif (iocbq->sli4_xritag == NO_XRI)\r\nsglq = NULL;\r\nelse\r\nsglq = __lpfc_clear_active_sglq(phba, iocbq->sli4_lxritag);\r\nif (sglq) {\r\nif ((iocbq->iocb_flag & LPFC_EXCHANGE_BUSY) &&\r\n(sglq->state != SGL_XRI_ABORTED)) {\r\nspin_lock_irqsave(&phba->sli4_hba.abts_sgl_list_lock,\r\niflag);\r\nlist_add(&sglq->list,\r\n&phba->sli4_hba.lpfc_abts_els_sgl_list);\r\nspin_unlock_irqrestore(\r\n&phba->sli4_hba.abts_sgl_list_lock, iflag);\r\n} else {\r\nspin_lock_irqsave(&pring->ring_lock, iflag);\r\nsglq->state = SGL_FREED;\r\nsglq->ndlp = NULL;\r\nlist_add_tail(&sglq->list,\r\n&phba->sli4_hba.lpfc_sgl_list);\r\nspin_unlock_irqrestore(&pring->ring_lock, iflag);\r\nif (!list_empty(&pring->txq))\r\nlpfc_worker_wake_up(phba);\r\n}\r\n}\r\nmemset((char *)iocbq + start_clean, 0, sizeof(*iocbq) - start_clean);\r\niocbq->sli4_lxritag = NO_XRI;\r\niocbq->sli4_xritag = NO_XRI;\r\nlist_add_tail(&iocbq->list, &phba->lpfc_iocb_list);\r\n}\r\nstatic void\r\n__lpfc_sli_release_iocbq_s3(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\r\n{\r\nsize_t start_clean = offsetof(struct lpfc_iocbq, iocb);\r\nmemset((char*)iocbq + start_clean, 0, sizeof(*iocbq) - start_clean);\r\niocbq->sli4_xritag = NO_XRI;\r\nlist_add_tail(&iocbq->list, &phba->lpfc_iocb_list);\r\n}\r\nstatic void\r\n__lpfc_sli_release_iocbq(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\r\n{\r\nphba->__lpfc_sli_release_iocbq(phba, iocbq);\r\nphba->iocb_cnt--;\r\n}\r\nvoid\r\nlpfc_sli_release_iocbq(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\r\n{\r\nunsigned long iflags;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\n__lpfc_sli_release_iocbq(phba, iocbq);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\n}\r\nvoid\r\nlpfc_sli_cancel_iocbs(struct lpfc_hba *phba, struct list_head *iocblist,\r\nuint32_t ulpstatus, uint32_t ulpWord4)\r\n{\r\nstruct lpfc_iocbq *piocb;\r\nwhile (!list_empty(iocblist)) {\r\nlist_remove_head(iocblist, piocb, struct lpfc_iocbq, list);\r\nif (!piocb->iocb_cmpl)\r\nlpfc_sli_release_iocbq(phba, piocb);\r\nelse {\r\npiocb->iocb.ulpStatus = ulpstatus;\r\npiocb->iocb.un.ulpWord[4] = ulpWord4;\r\n(piocb->iocb_cmpl) (phba, piocb, piocb);\r\n}\r\n}\r\nreturn;\r\n}\r\nstatic lpfc_iocb_type\r\nlpfc_sli_iocb_cmd_type(uint8_t iocb_cmnd)\r\n{\r\nlpfc_iocb_type type = LPFC_UNKNOWN_IOCB;\r\nif (iocb_cmnd > CMD_MAX_IOCB_CMD)\r\nreturn 0;\r\nswitch (iocb_cmnd) {\r\ncase CMD_XMIT_SEQUENCE_CR:\r\ncase CMD_XMIT_SEQUENCE_CX:\r\ncase CMD_XMIT_BCAST_CN:\r\ncase CMD_XMIT_BCAST_CX:\r\ncase CMD_ELS_REQUEST_CR:\r\ncase CMD_ELS_REQUEST_CX:\r\ncase CMD_CREATE_XRI_CR:\r\ncase CMD_CREATE_XRI_CX:\r\ncase CMD_GET_RPI_CN:\r\ncase CMD_XMIT_ELS_RSP_CX:\r\ncase CMD_GET_RPI_CR:\r\ncase CMD_FCP_IWRITE_CR:\r\ncase CMD_FCP_IWRITE_CX:\r\ncase CMD_FCP_IREAD_CR:\r\ncase CMD_FCP_IREAD_CX:\r\ncase CMD_FCP_ICMND_CR:\r\ncase CMD_FCP_ICMND_CX:\r\ncase CMD_FCP_TSEND_CX:\r\ncase CMD_FCP_TRSP_CX:\r\ncase CMD_FCP_TRECEIVE_CX:\r\ncase CMD_FCP_AUTO_TRSP_CX:\r\ncase CMD_ADAPTER_MSG:\r\ncase CMD_ADAPTER_DUMP:\r\ncase CMD_XMIT_SEQUENCE64_CR:\r\ncase CMD_XMIT_SEQUENCE64_CX:\r\ncase CMD_XMIT_BCAST64_CN:\r\ncase CMD_XMIT_BCAST64_CX:\r\ncase CMD_ELS_REQUEST64_CR:\r\ncase CMD_ELS_REQUEST64_CX:\r\ncase CMD_FCP_IWRITE64_CR:\r\ncase CMD_FCP_IWRITE64_CX:\r\ncase CMD_FCP_IREAD64_CR:\r\ncase CMD_FCP_IREAD64_CX:\r\ncase CMD_FCP_ICMND64_CR:\r\ncase CMD_FCP_ICMND64_CX:\r\ncase CMD_FCP_TSEND64_CX:\r\ncase CMD_FCP_TRSP64_CX:\r\ncase CMD_FCP_TRECEIVE64_CX:\r\ncase CMD_GEN_REQUEST64_CR:\r\ncase CMD_GEN_REQUEST64_CX:\r\ncase CMD_XMIT_ELS_RSP64_CX:\r\ncase DSSCMD_IWRITE64_CR:\r\ncase DSSCMD_IWRITE64_CX:\r\ncase DSSCMD_IREAD64_CR:\r\ncase DSSCMD_IREAD64_CX:\r\ntype = LPFC_SOL_IOCB;\r\nbreak;\r\ncase CMD_ABORT_XRI_CN:\r\ncase CMD_ABORT_XRI_CX:\r\ncase CMD_CLOSE_XRI_CN:\r\ncase CMD_CLOSE_XRI_CX:\r\ncase CMD_XRI_ABORTED_CX:\r\ncase CMD_ABORT_MXRI64_CN:\r\ncase CMD_XMIT_BLS_RSP64_CX:\r\ntype = LPFC_ABORT_IOCB;\r\nbreak;\r\ncase CMD_RCV_SEQUENCE_CX:\r\ncase CMD_RCV_ELS_REQ_CX:\r\ncase CMD_RCV_SEQUENCE64_CX:\r\ncase CMD_RCV_ELS_REQ64_CX:\r\ncase CMD_ASYNC_STATUS:\r\ncase CMD_IOCB_RCV_SEQ64_CX:\r\ncase CMD_IOCB_RCV_ELS64_CX:\r\ncase CMD_IOCB_RCV_CONT64_CX:\r\ncase CMD_IOCB_RET_XRI64_CX:\r\ntype = LPFC_UNSOL_IOCB;\r\nbreak;\r\ncase CMD_IOCB_XMIT_MSEQ64_CR:\r\ncase CMD_IOCB_XMIT_MSEQ64_CX:\r\ncase CMD_IOCB_RCV_SEQ_LIST64_CX:\r\ncase CMD_IOCB_RCV_ELS_LIST64_CX:\r\ncase CMD_IOCB_CLOSE_EXTENDED_CN:\r\ncase CMD_IOCB_ABORT_EXTENDED_CN:\r\ncase CMD_IOCB_RET_HBQE64_CN:\r\ncase CMD_IOCB_FCP_IBIDIR64_CR:\r\ncase CMD_IOCB_FCP_IBIDIR64_CX:\r\ncase CMD_IOCB_FCP_ITASKMGT64_CX:\r\ncase CMD_IOCB_LOGENTRY_CN:\r\ncase CMD_IOCB_LOGENTRY_ASYNC_CN:\r\nprintk("%s - Unhandled SLI-3 Command x%x\n",\r\n__func__, iocb_cmnd);\r\ntype = LPFC_UNKNOWN_IOCB;\r\nbreak;\r\ndefault:\r\ntype = LPFC_UNKNOWN_IOCB;\r\nbreak;\r\n}\r\nreturn type;\r\n}\r\nstatic int\r\nlpfc_sli_ring_map(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nLPFC_MBOXQ_t *pmb;\r\nMAILBOX_t *pmbox;\r\nint i, rc, ret = 0;\r\npmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!pmb)\r\nreturn -ENOMEM;\r\npmbox = &pmb->u.mb;\r\nphba->link_state = LPFC_INIT_MBX_CMDS;\r\nfor (i = 0; i < psli->num_rings; i++) {\r\nlpfc_config_ring(phba, i, pmb);\r\nrc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0446 Adapter failed to init (%d), "\r\n"mbxCmd x%x CFG_RING, mbxStatus x%x, "\r\n"ring %d\n",\r\nrc, pmbox->mbxCommand,\r\npmbox->mbxStatus, i);\r\nphba->link_state = LPFC_HBA_ERROR;\r\nret = -ENXIO;\r\nbreak;\r\n}\r\n}\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn ret;\r\n}\r\nstatic int\r\nlpfc_sli_ringtxcmpl_put(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *piocb)\r\n{\r\nlist_add_tail(&piocb->list, &pring->txcmplq);\r\npiocb->iocb_flag |= LPFC_IO_ON_TXCMPLQ;\r\nif ((unlikely(pring->ringno == LPFC_ELS_RING)) &&\r\n(piocb->iocb.ulpCommand != CMD_ABORT_XRI_CN) &&\r\n(piocb->iocb.ulpCommand != CMD_CLOSE_XRI_CN) &&\r\n(!(piocb->vport->load_flag & FC_UNLOADING))) {\r\nif (!piocb->vport)\r\nBUG();\r\nelse\r\nmod_timer(&piocb->vport->els_tmofunc,\r\njiffies +\r\nmsecs_to_jiffies(1000 * (phba->fc_ratov << 1)));\r\n}\r\nreturn 0;\r\n}\r\nstruct lpfc_iocbq *\r\nlpfc_sli_ringtx_get(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nstruct lpfc_iocbq *cmd_iocb;\r\nlist_remove_head((&pring->txq), cmd_iocb, struct lpfc_iocbq, list);\r\nreturn cmd_iocb;\r\n}\r\nstatic IOCB_t *\r\nlpfc_sli_next_iocb_slot (struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nstruct lpfc_pgp *pgp = &phba->port_gp[pring->ringno];\r\nuint32_t max_cmd_idx = pring->sli.sli3.numCiocb;\r\nif ((pring->sli.sli3.next_cmdidx == pring->sli.sli3.cmdidx) &&\r\n(++pring->sli.sli3.next_cmdidx >= max_cmd_idx))\r\npring->sli.sli3.next_cmdidx = 0;\r\nif (unlikely(pring->sli.sli3.local_getidx ==\r\npring->sli.sli3.next_cmdidx)) {\r\npring->sli.sli3.local_getidx = le32_to_cpu(pgp->cmdGetInx);\r\nif (unlikely(pring->sli.sli3.local_getidx >= max_cmd_idx)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0315 Ring %d issue: portCmdGet %d "\r\n"is bigger than cmd ring %d\n",\r\npring->ringno,\r\npring->sli.sli3.local_getidx,\r\nmax_cmd_idx);\r\nphba->link_state = LPFC_HBA_ERROR;\r\nphba->work_ha |= HA_ERATT;\r\nphba->work_hs = HS_FFER3;\r\nlpfc_worker_wake_up(phba);\r\nreturn NULL;\r\n}\r\nif (pring->sli.sli3.local_getidx == pring->sli.sli3.next_cmdidx)\r\nreturn NULL;\r\n}\r\nreturn lpfc_cmd_iocb(phba, pring);\r\n}\r\nuint16_t\r\nlpfc_sli_next_iotag(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq)\r\n{\r\nstruct lpfc_iocbq **new_arr;\r\nstruct lpfc_iocbq **old_arr;\r\nsize_t new_len;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nuint16_t iotag;\r\nspin_lock_irq(&phba->hbalock);\r\niotag = psli->last_iotag;\r\nif(++iotag < psli->iocbq_lookup_len) {\r\npsli->last_iotag = iotag;\r\npsli->iocbq_lookup[iotag] = iocbq;\r\nspin_unlock_irq(&phba->hbalock);\r\niocbq->iotag = iotag;\r\nreturn iotag;\r\n} else if (psli->iocbq_lookup_len < (0xffff\r\n- LPFC_IOCBQ_LOOKUP_INCREMENT)) {\r\nnew_len = psli->iocbq_lookup_len + LPFC_IOCBQ_LOOKUP_INCREMENT;\r\nspin_unlock_irq(&phba->hbalock);\r\nnew_arr = kzalloc(new_len * sizeof (struct lpfc_iocbq *),\r\nGFP_KERNEL);\r\nif (new_arr) {\r\nspin_lock_irq(&phba->hbalock);\r\nold_arr = psli->iocbq_lookup;\r\nif (new_len <= psli->iocbq_lookup_len) {\r\nkfree(new_arr);\r\niotag = psli->last_iotag;\r\nif(++iotag < psli->iocbq_lookup_len) {\r\npsli->last_iotag = iotag;\r\npsli->iocbq_lookup[iotag] = iocbq;\r\nspin_unlock_irq(&phba->hbalock);\r\niocbq->iotag = iotag;\r\nreturn iotag;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 0;\r\n}\r\nif (psli->iocbq_lookup)\r\nmemcpy(new_arr, old_arr,\r\n((psli->last_iotag + 1) *\r\nsizeof (struct lpfc_iocbq *)));\r\npsli->iocbq_lookup = new_arr;\r\npsli->iocbq_lookup_len = new_len;\r\npsli->last_iotag = iotag;\r\npsli->iocbq_lookup[iotag] = iocbq;\r\nspin_unlock_irq(&phba->hbalock);\r\niocbq->iotag = iotag;\r\nkfree(old_arr);\r\nreturn iotag;\r\n}\r\n} else\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0318 Failed to allocate IOTAG.last IOTAG is %d\n",\r\npsli->last_iotag);\r\nreturn 0;\r\n}\r\nstatic void\r\nlpfc_sli_submit_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nIOCB_t *iocb, struct lpfc_iocbq *nextiocb)\r\n{\r\nnextiocb->iocb.ulpIoTag = (nextiocb->iocb_cmpl) ? nextiocb->iotag : 0;\r\nif (pring->ringno == LPFC_ELS_RING) {\r\nlpfc_debugfs_slow_ring_trc(phba,\r\n"IOCB cmd ring: wd4:x%08x wd6:x%08x wd7:x%08x",\r\n*(((uint32_t *) &nextiocb->iocb) + 4),\r\n*(((uint32_t *) &nextiocb->iocb) + 6),\r\n*(((uint32_t *) &nextiocb->iocb) + 7));\r\n}\r\nlpfc_sli_pcimem_bcopy(&nextiocb->iocb, iocb, phba->iocb_cmd_size);\r\nwmb();\r\npring->stats.iocb_cmd++;\r\nif (nextiocb->iocb_cmpl)\r\nlpfc_sli_ringtxcmpl_put(phba, pring, nextiocb);\r\nelse\r\n__lpfc_sli_release_iocbq(phba, nextiocb);\r\npring->sli.sli3.cmdidx = pring->sli.sli3.next_cmdidx;\r\nwritel(pring->sli.sli3.cmdidx, &phba->host_gp[pring->ringno].cmdPutInx);\r\n}\r\nstatic void\r\nlpfc_sli_update_full_ring(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nint ringno = pring->ringno;\r\npring->flag |= LPFC_CALL_RING_AVAILABLE;\r\nwmb();\r\nwritel((CA_R0ATT|CA_R0CE_REQ) << (ringno*4), phba->CAregaddr);\r\nreadl(phba->CAregaddr);\r\npring->stats.iocb_cmd_full++;\r\n}\r\nstatic void\r\nlpfc_sli_update_ring(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nint ringno = pring->ringno;\r\nif (!(phba->sli3_options & LPFC_SLI3_CRP_ENABLED)) {\r\nwmb();\r\nwritel(CA_R0ATT << (ringno * 4), phba->CAregaddr);\r\nreadl(phba->CAregaddr);\r\n}\r\n}\r\nstatic void\r\nlpfc_sli_resume_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nIOCB_t *iocb;\r\nstruct lpfc_iocbq *nextiocb;\r\nif (lpfc_is_link_up(phba) &&\r\n(!list_empty(&pring->txq)) &&\r\n(pring->ringno != phba->sli.fcp_ring ||\r\nphba->sli.sli_flag & LPFC_PROCESS_LA)) {\r\nwhile ((iocb = lpfc_sli_next_iocb_slot(phba, pring)) &&\r\n(nextiocb = lpfc_sli_ringtx_get(phba, pring)))\r\nlpfc_sli_submit_iocb(phba, pring, iocb, nextiocb);\r\nif (iocb)\r\nlpfc_sli_update_ring(phba, pring);\r\nelse\r\nlpfc_sli_update_full_ring(phba, pring);\r\n}\r\nreturn;\r\n}\r\nstatic struct lpfc_hbq_entry *\r\nlpfc_sli_next_hbq_slot(struct lpfc_hba *phba, uint32_t hbqno)\r\n{\r\nstruct hbq_s *hbqp = &phba->hbqs[hbqno];\r\nif (hbqp->next_hbqPutIdx == hbqp->hbqPutIdx &&\r\n++hbqp->next_hbqPutIdx >= hbqp->entry_count)\r\nhbqp->next_hbqPutIdx = 0;\r\nif (unlikely(hbqp->local_hbqGetIdx == hbqp->next_hbqPutIdx)) {\r\nuint32_t raw_index = phba->hbq_get[hbqno];\r\nuint32_t getidx = le32_to_cpu(raw_index);\r\nhbqp->local_hbqGetIdx = getidx;\r\nif (unlikely(hbqp->local_hbqGetIdx >= hbqp->entry_count)) {\r\nlpfc_printf_log(phba, KERN_ERR,\r\nLOG_SLI | LOG_VPORT,\r\n"1802 HBQ %d: local_hbqGetIdx "\r\n"%u is > than hbqp->entry_count %u\n",\r\nhbqno, hbqp->local_hbqGetIdx,\r\nhbqp->entry_count);\r\nphba->link_state = LPFC_HBA_ERROR;\r\nreturn NULL;\r\n}\r\nif (hbqp->local_hbqGetIdx == hbqp->next_hbqPutIdx)\r\nreturn NULL;\r\n}\r\nreturn (struct lpfc_hbq_entry *) phba->hbqs[hbqno].hbq_virt +\r\nhbqp->hbqPutIdx;\r\n}\r\nvoid\r\nlpfc_sli_hbqbuf_free_all(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_dmabuf *dmabuf, *next_dmabuf;\r\nstruct hbq_dmabuf *hbq_buf;\r\nunsigned long flags;\r\nint i, hbq_count;\r\nuint32_t hbqno;\r\nhbq_count = lpfc_sli_hbq_count();\r\nspin_lock_irqsave(&phba->hbalock, flags);\r\nfor (i = 0; i < hbq_count; ++i) {\r\nlist_for_each_entry_safe(dmabuf, next_dmabuf,\r\n&phba->hbqs[i].hbq_buffer_list, list) {\r\nhbq_buf = container_of(dmabuf, struct hbq_dmabuf, dbuf);\r\nlist_del(&hbq_buf->dbuf.list);\r\n(phba->hbqs[i].hbq_free_buffer)(phba, hbq_buf);\r\n}\r\nphba->hbqs[i].buffer_count = 0;\r\n}\r\nlist_for_each_entry_safe(dmabuf, next_dmabuf, &phba->rb_pend_list,\r\nlist) {\r\nhbq_buf = container_of(dmabuf, struct hbq_dmabuf, dbuf);\r\nlist_del(&hbq_buf->dbuf.list);\r\nif (hbq_buf->tag == -1) {\r\n(phba->hbqs[LPFC_ELS_HBQ].hbq_free_buffer)\r\n(phba, hbq_buf);\r\n} else {\r\nhbqno = hbq_buf->tag >> 16;\r\nif (hbqno >= LPFC_MAX_HBQS)\r\n(phba->hbqs[LPFC_ELS_HBQ].hbq_free_buffer)\r\n(phba, hbq_buf);\r\nelse\r\n(phba->hbqs[hbqno].hbq_free_buffer)(phba,\r\nhbq_buf);\r\n}\r\n}\r\nphba->hbq_in_use = 0;\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\n}\r\nstatic int\r\nlpfc_sli_hbq_to_firmware(struct lpfc_hba *phba, uint32_t hbqno,\r\nstruct hbq_dmabuf *hbq_buf)\r\n{\r\nreturn phba->lpfc_sli_hbq_to_firmware(phba, hbqno, hbq_buf);\r\n}\r\nstatic int\r\nlpfc_sli_hbq_to_firmware_s3(struct lpfc_hba *phba, uint32_t hbqno,\r\nstruct hbq_dmabuf *hbq_buf)\r\n{\r\nstruct lpfc_hbq_entry *hbqe;\r\ndma_addr_t physaddr = hbq_buf->dbuf.phys;\r\nhbqe = lpfc_sli_next_hbq_slot(phba, hbqno);\r\nif (hbqe) {\r\nstruct hbq_s *hbqp = &phba->hbqs[hbqno];\r\nhbqe->bde.addrHigh = le32_to_cpu(putPaddrHigh(physaddr));\r\nhbqe->bde.addrLow = le32_to_cpu(putPaddrLow(physaddr));\r\nhbqe->bde.tus.f.bdeSize = hbq_buf->size;\r\nhbqe->bde.tus.f.bdeFlags = 0;\r\nhbqe->bde.tus.w = le32_to_cpu(hbqe->bde.tus.w);\r\nhbqe->buffer_tag = le32_to_cpu(hbq_buf->tag);\r\nhbqp->hbqPutIdx = hbqp->next_hbqPutIdx;\r\nwritel(hbqp->hbqPutIdx, phba->hbq_put + hbqno);\r\nreadl(phba->hbq_put + hbqno);\r\nlist_add_tail(&hbq_buf->dbuf.list, &hbqp->hbq_buffer_list);\r\nreturn 0;\r\n} else\r\nreturn -ENOMEM;\r\n}\r\nstatic int\r\nlpfc_sli_hbq_to_firmware_s4(struct lpfc_hba *phba, uint32_t hbqno,\r\nstruct hbq_dmabuf *hbq_buf)\r\n{\r\nint rc;\r\nstruct lpfc_rqe hrqe;\r\nstruct lpfc_rqe drqe;\r\nhrqe.address_lo = putPaddrLow(hbq_buf->hbuf.phys);\r\nhrqe.address_hi = putPaddrHigh(hbq_buf->hbuf.phys);\r\ndrqe.address_lo = putPaddrLow(hbq_buf->dbuf.phys);\r\ndrqe.address_hi = putPaddrHigh(hbq_buf->dbuf.phys);\r\nrc = lpfc_sli4_rq_put(phba->sli4_hba.hdr_rq, phba->sli4_hba.dat_rq,\r\n&hrqe, &drqe);\r\nif (rc < 0)\r\nreturn rc;\r\nhbq_buf->tag = rc;\r\nlist_add_tail(&hbq_buf->dbuf.list, &phba->hbqs[hbqno].hbq_buffer_list);\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_sli_hbqbuf_fill_hbqs(struct lpfc_hba *phba, uint32_t hbqno, uint32_t count)\r\n{\r\nuint32_t i, posted = 0;\r\nunsigned long flags;\r\nstruct hbq_dmabuf *hbq_buffer;\r\nLIST_HEAD(hbq_buf_list);\r\nif (!phba->hbqs[hbqno].hbq_alloc_buffer)\r\nreturn 0;\r\nif ((phba->hbqs[hbqno].buffer_count + count) >\r\nlpfc_hbq_defs[hbqno]->entry_count)\r\ncount = lpfc_hbq_defs[hbqno]->entry_count -\r\nphba->hbqs[hbqno].buffer_count;\r\nif (!count)\r\nreturn 0;\r\nfor (i = 0; i < count; i++) {\r\nhbq_buffer = (phba->hbqs[hbqno].hbq_alloc_buffer)(phba);\r\nif (!hbq_buffer)\r\nbreak;\r\nlist_add_tail(&hbq_buffer->dbuf.list, &hbq_buf_list);\r\n}\r\nspin_lock_irqsave(&phba->hbalock, flags);\r\nif (!phba->hbq_in_use)\r\ngoto err;\r\nwhile (!list_empty(&hbq_buf_list)) {\r\nlist_remove_head(&hbq_buf_list, hbq_buffer, struct hbq_dmabuf,\r\ndbuf.list);\r\nhbq_buffer->tag = (phba->hbqs[hbqno].buffer_count |\r\n(hbqno << 16));\r\nif (!lpfc_sli_hbq_to_firmware(phba, hbqno, hbq_buffer)) {\r\nphba->hbqs[hbqno].buffer_count++;\r\nposted++;\r\n} else\r\n(phba->hbqs[hbqno].hbq_free_buffer)(phba, hbq_buffer);\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nreturn posted;\r\nerr:\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nwhile (!list_empty(&hbq_buf_list)) {\r\nlist_remove_head(&hbq_buf_list, hbq_buffer, struct hbq_dmabuf,\r\ndbuf.list);\r\n(phba->hbqs[hbqno].hbq_free_buffer)(phba, hbq_buffer);\r\n}\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli_hbqbuf_add_hbqs(struct lpfc_hba *phba, uint32_t qno)\r\n{\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nreturn 0;\r\nelse\r\nreturn lpfc_sli_hbqbuf_fill_hbqs(phba, qno,\r\nlpfc_hbq_defs[qno]->add_count);\r\n}\r\nstatic int\r\nlpfc_sli_hbqbuf_init_hbqs(struct lpfc_hba *phba, uint32_t qno)\r\n{\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nreturn lpfc_sli_hbqbuf_fill_hbqs(phba, qno,\r\nlpfc_hbq_defs[qno]->entry_count);\r\nelse\r\nreturn lpfc_sli_hbqbuf_fill_hbqs(phba, qno,\r\nlpfc_hbq_defs[qno]->init_count);\r\n}\r\nstatic struct hbq_dmabuf *\r\nlpfc_sli_hbqbuf_get(struct list_head *rb_list)\r\n{\r\nstruct lpfc_dmabuf *d_buf;\r\nlist_remove_head(rb_list, d_buf, struct lpfc_dmabuf, list);\r\nif (!d_buf)\r\nreturn NULL;\r\nreturn container_of(d_buf, struct hbq_dmabuf, dbuf);\r\n}\r\nstatic struct hbq_dmabuf *\r\nlpfc_sli_hbqbuf_find(struct lpfc_hba *phba, uint32_t tag)\r\n{\r\nstruct lpfc_dmabuf *d_buf;\r\nstruct hbq_dmabuf *hbq_buf;\r\nuint32_t hbqno;\r\nhbqno = tag >> 16;\r\nif (hbqno >= LPFC_MAX_HBQS)\r\nreturn NULL;\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry(d_buf, &phba->hbqs[hbqno].hbq_buffer_list, list) {\r\nhbq_buf = container_of(d_buf, struct hbq_dmabuf, dbuf);\r\nif (hbq_buf->tag == tag) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn hbq_buf;\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI | LOG_VPORT,\r\n"1803 Bad hbq tag. Data: x%x x%x\n",\r\ntag, phba->hbqs[tag >> 16].buffer_count);\r\nreturn NULL;\r\n}\r\nvoid\r\nlpfc_sli_free_hbq(struct lpfc_hba *phba, struct hbq_dmabuf *hbq_buffer)\r\n{\r\nuint32_t hbqno;\r\nif (hbq_buffer) {\r\nhbqno = hbq_buffer->tag >> 16;\r\nif (lpfc_sli_hbq_to_firmware(phba, hbqno, hbq_buffer))\r\n(phba->hbqs[hbqno].hbq_free_buffer)(phba, hbq_buffer);\r\n}\r\n}\r\nstatic int\r\nlpfc_sli_chk_mbx_command(uint8_t mbxCommand)\r\n{\r\nuint8_t ret;\r\nswitch (mbxCommand) {\r\ncase MBX_LOAD_SM:\r\ncase MBX_READ_NV:\r\ncase MBX_WRITE_NV:\r\ncase MBX_WRITE_VPARMS:\r\ncase MBX_RUN_BIU_DIAG:\r\ncase MBX_INIT_LINK:\r\ncase MBX_DOWN_LINK:\r\ncase MBX_CONFIG_LINK:\r\ncase MBX_CONFIG_RING:\r\ncase MBX_RESET_RING:\r\ncase MBX_READ_CONFIG:\r\ncase MBX_READ_RCONFIG:\r\ncase MBX_READ_SPARM:\r\ncase MBX_READ_STATUS:\r\ncase MBX_READ_RPI:\r\ncase MBX_READ_XRI:\r\ncase MBX_READ_REV:\r\ncase MBX_READ_LNK_STAT:\r\ncase MBX_REG_LOGIN:\r\ncase MBX_UNREG_LOGIN:\r\ncase MBX_CLEAR_LA:\r\ncase MBX_DUMP_MEMORY:\r\ncase MBX_DUMP_CONTEXT:\r\ncase MBX_RUN_DIAGS:\r\ncase MBX_RESTART:\r\ncase MBX_UPDATE_CFG:\r\ncase MBX_DOWN_LOAD:\r\ncase MBX_DEL_LD_ENTRY:\r\ncase MBX_RUN_PROGRAM:\r\ncase MBX_SET_MASK:\r\ncase MBX_SET_VARIABLE:\r\ncase MBX_UNREG_D_ID:\r\ncase MBX_KILL_BOARD:\r\ncase MBX_CONFIG_FARP:\r\ncase MBX_BEACON:\r\ncase MBX_LOAD_AREA:\r\ncase MBX_RUN_BIU_DIAG64:\r\ncase MBX_CONFIG_PORT:\r\ncase MBX_READ_SPARM64:\r\ncase MBX_READ_RPI64:\r\ncase MBX_REG_LOGIN64:\r\ncase MBX_READ_TOPOLOGY:\r\ncase MBX_WRITE_WWN:\r\ncase MBX_SET_DEBUG:\r\ncase MBX_LOAD_EXP_ROM:\r\ncase MBX_ASYNCEVT_ENABLE:\r\ncase MBX_REG_VPI:\r\ncase MBX_UNREG_VPI:\r\ncase MBX_HEARTBEAT:\r\ncase MBX_PORT_CAPABILITIES:\r\ncase MBX_PORT_IOV_CONTROL:\r\ncase MBX_SLI4_CONFIG:\r\ncase MBX_SLI4_REQ_FTRS:\r\ncase MBX_REG_FCFI:\r\ncase MBX_UNREG_FCFI:\r\ncase MBX_REG_VFI:\r\ncase MBX_UNREG_VFI:\r\ncase MBX_INIT_VPI:\r\ncase MBX_INIT_VFI:\r\ncase MBX_RESUME_RPI:\r\ncase MBX_READ_EVENT_LOG_STATUS:\r\ncase MBX_READ_EVENT_LOG:\r\ncase MBX_SECURITY_MGMT:\r\ncase MBX_AUTH_PORT:\r\ncase MBX_ACCESS_VDATA:\r\nret = mbxCommand;\r\nbreak;\r\ndefault:\r\nret = MBX_SHUTDOWN;\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nvoid\r\nlpfc_sli_wake_mbox_wait(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmboxq)\r\n{\r\nwait_queue_head_t *pdone_q;\r\nunsigned long drvr_flag;\r\npmboxq->mbox_flag |= LPFC_MBX_WAKE;\r\nspin_lock_irqsave(&phba->hbalock, drvr_flag);\r\npdone_q = (wait_queue_head_t *) pmboxq->context1;\r\nif (pdone_q)\r\nwake_up_interruptible(pdone_q);\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_sli_def_mbox_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct lpfc_dmabuf *mp;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct Scsi_Host *shost;\r\nuint16_t rpi, vpi;\r\nint rc;\r\nmp = (struct lpfc_dmabuf *) (pmb->context1);\r\nif (mp) {\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\n}\r\nif (!(phba->pport->load_flag & FC_UNLOADING) &&\r\npmb->u.mb.mbxCommand == MBX_REG_LOGIN64 &&\r\n!pmb->u.mb.mbxStatus) {\r\nrpi = pmb->u.mb.un.varWords[0];\r\nvpi = pmb->u.mb.un.varRegLogin.vpi;\r\nlpfc_unreg_login(phba, vpi, rpi, pmb);\r\npmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nrc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\r\nif (rc != MBX_NOT_FINISHED)\r\nreturn;\r\n}\r\nif ((pmb->u.mb.mbxCommand == MBX_REG_VPI) &&\r\n!(phba->pport->load_flag & FC_UNLOADING) &&\r\n!pmb->u.mb.mbxStatus) {\r\nshost = lpfc_shost_from_vport(vport);\r\nspin_lock_irq(shost->host_lock);\r\nvport->vpi_state |= LPFC_VPI_REGISTERED;\r\nvport->fc_flag &= ~FC_VPORT_NEEDS_REG_VPI;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nif (pmb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\r\nndlp = (struct lpfc_nodelist *)pmb->context2;\r\nlpfc_nlp_put(ndlp);\r\npmb->context2 = NULL;\r\n}\r\nif ((pmb->u.mb.mbxCommand == MBX_INIT_LINK) &&\r\n(pmb->u.mb.mbxStatus == MBXERR_SEC_NO_PERMISSION))\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"2860 SLI authentication is required "\r\n"for INIT_LINK but has not done yet\n");\r\nif (bf_get(lpfc_mqe_command, &pmb->u.mqe) == MBX_SLI4_CONFIG)\r\nlpfc_sli4_mbox_cmd_free(phba, pmb);\r\nelse\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\n}\r\nvoid\r\nlpfc_sli4_unreg_rpi_cmpl_clr(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct lpfc_nodelist *ndlp;\r\nndlp = pmb->context1;\r\nif (pmb->u.mb.mbxCommand == MBX_UNREG_LOGIN) {\r\nif (phba->sli_rev == LPFC_SLI_REV4 &&\r\n(bf_get(lpfc_sli_intf_if_type,\r\n&phba->sli4_hba.sli_intf) ==\r\nLPFC_SLI_INTF_IF_TYPE_2)) {\r\nif (ndlp) {\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_SLI,\r\n"0010 UNREG_LOGIN vpi:%x "\r\n"rpi:%x DID:%x map:%x %p\n",\r\nvport->vpi, ndlp->nlp_rpi,\r\nndlp->nlp_DID,\r\nndlp->nlp_usg_map, ndlp);\r\nndlp->nlp_flag &= ~NLP_LOGO_ACC;\r\nlpfc_nlp_put(ndlp);\r\n}\r\n}\r\n}\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\n}\r\nint\r\nlpfc_sli_handle_mb_event(struct lpfc_hba *phba)\r\n{\r\nMAILBOX_t *pmbox;\r\nLPFC_MBOXQ_t *pmb;\r\nint rc;\r\nLIST_HEAD(cmplq);\r\nphba->sli.slistat.mbox_event++;\r\nspin_lock_irq(&phba->hbalock);\r\nlist_splice_init(&phba->sli.mboxq_cmpl, &cmplq);\r\nspin_unlock_irq(&phba->hbalock);\r\ndo {\r\nlist_remove_head(&cmplq, pmb, LPFC_MBOXQ_t, list);\r\nif (pmb == NULL)\r\nbreak;\r\npmbox = &pmb->u.mb;\r\nif (pmbox->mbxCommand != MBX_HEARTBEAT) {\r\nif (pmb->vport) {\r\nlpfc_debugfs_disc_trc(pmb->vport,\r\nLPFC_DISC_TRC_MBOX_VPORT,\r\n"MBOX cmpl vport: cmd:x%x mb:x%x x%x",\r\n(uint32_t)pmbox->mbxCommand,\r\npmbox->un.varWords[0],\r\npmbox->un.varWords[1]);\r\n}\r\nelse {\r\nlpfc_debugfs_disc_trc(phba->pport,\r\nLPFC_DISC_TRC_MBOX,\r\n"MBOX cmpl: cmd:x%x mb:x%x x%x",\r\n(uint32_t)pmbox->mbxCommand,\r\npmbox->un.varWords[0],\r\npmbox->un.varWords[1]);\r\n}\r\n}\r\nif (lpfc_sli_chk_mbx_command(pmbox->mbxCommand) ==\r\nMBX_SHUTDOWN) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):0323 Unknown Mailbox command "\r\n"x%x (x%x/x%x) Cmpl\n",\r\npmb->vport ? pmb->vport->vpi : 0,\r\npmbox->mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba,\r\npmb),\r\nlpfc_sli_config_mbox_opcode_get(phba,\r\npmb));\r\nphba->link_state = LPFC_HBA_ERROR;\r\nphba->work_hs = HS_FFER3;\r\nlpfc_handle_eratt(phba);\r\ncontinue;\r\n}\r\nif (pmbox->mbxStatus) {\r\nphba->sli.slistat.mbox_stat_err++;\r\nif (pmbox->mbxStatus == MBXERR_NO_RESOURCES) {\r\nlpfc_printf_log(phba, KERN_INFO,\r\nLOG_MBOX | LOG_SLI,\r\n"(%d):0305 Mbox cmd cmpl "\r\n"error - RETRYing Data: x%x "\r\n"(x%x/x%x) x%x x%x x%x\n",\r\npmb->vport ? pmb->vport->vpi : 0,\r\npmbox->mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba,\r\npmb),\r\nlpfc_sli_config_mbox_opcode_get(phba,\r\npmb),\r\npmbox->mbxStatus,\r\npmbox->un.varWords[0],\r\npmb->vport->port_state);\r\npmbox->mbxStatus = 0;\r\npmbox->mbxOwner = OWN_HOST;\r\nrc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\r\nif (rc != MBX_NOT_FINISHED)\r\ncontinue;\r\n}\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):0307 Mailbox cmd x%x (x%x/x%x) Cmpl x%p "\r\n"Data: x%x x%x x%x x%x x%x x%x x%x x%x x%x "\r\n"x%x x%x x%x\n",\r\npmb->vport ? pmb->vport->vpi : 0,\r\npmbox->mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba, pmb),\r\nlpfc_sli_config_mbox_opcode_get(phba, pmb),\r\npmb->mbox_cmpl,\r\n*((uint32_t *) pmbox),\r\npmbox->un.varWords[0],\r\npmbox->un.varWords[1],\r\npmbox->un.varWords[2],\r\npmbox->un.varWords[3],\r\npmbox->un.varWords[4],\r\npmbox->un.varWords[5],\r\npmbox->un.varWords[6],\r\npmbox->un.varWords[7],\r\npmbox->un.varWords[8],\r\npmbox->un.varWords[9],\r\npmbox->un.varWords[10]);\r\nif (pmb->mbox_cmpl)\r\npmb->mbox_cmpl(phba,pmb);\r\n} while (1);\r\nreturn 0;\r\n}\r\nstatic struct lpfc_dmabuf *\r\nlpfc_sli_get_buff(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring,\r\nuint32_t tag)\r\n{\r\nstruct hbq_dmabuf *hbq_entry;\r\nif (tag & QUE_BUFTAG_BIT)\r\nreturn lpfc_sli_ring_taggedbuf_get(phba, pring, tag);\r\nhbq_entry = lpfc_sli_hbqbuf_find(phba, tag);\r\nif (!hbq_entry)\r\nreturn NULL;\r\nreturn &hbq_entry->dbuf;\r\n}\r\nstatic int\r\nlpfc_complete_unsol_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *saveq, uint32_t fch_r_ctl,\r\nuint32_t fch_type)\r\n{\r\nint i;\r\nif (pring->prt[0].profile) {\r\nif (pring->prt[0].lpfc_sli_rcv_unsol_event)\r\n(pring->prt[0].lpfc_sli_rcv_unsol_event) (phba, pring,\r\nsaveq);\r\nreturn 1;\r\n}\r\nfor (i = 0; i < pring->num_mask; i++) {\r\nif ((pring->prt[i].rctl == fch_r_ctl) &&\r\n(pring->prt[i].type == fch_type)) {\r\nif (pring->prt[i].lpfc_sli_rcv_unsol_event)\r\n(pring->prt[i].lpfc_sli_rcv_unsol_event)\r\n(phba, pring, saveq);\r\nreturn 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_sli_process_unsol_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *saveq)\r\n{\r\nIOCB_t * irsp;\r\nWORD5 * w5p;\r\nuint32_t Rctl, Type;\r\nstruct lpfc_iocbq *iocbq;\r\nstruct lpfc_dmabuf *dmzbuf;\r\nirsp = &(saveq->iocb);\r\nif (irsp->ulpCommand == CMD_ASYNC_STATUS) {\r\nif (pring->lpfc_sli_rcv_async_status)\r\npring->lpfc_sli_rcv_async_status(phba, pring, saveq);\r\nelse\r\nlpfc_printf_log(phba,\r\nKERN_WARNING,\r\nLOG_SLI,\r\n"0316 Ring %d handler: unexpected "\r\n"ASYNC_STATUS iocb received evt_code "\r\n"0x%x\n",\r\npring->ringno,\r\nirsp->un.asyncstat.evt_code);\r\nreturn 1;\r\n}\r\nif ((irsp->ulpCommand == CMD_IOCB_RET_XRI64_CX) &&\r\n(phba->sli3_options & LPFC_SLI3_HBQ_ENABLED)) {\r\nif (irsp->ulpBdeCount > 0) {\r\ndmzbuf = lpfc_sli_get_buff(phba, pring,\r\nirsp->un.ulpWord[3]);\r\nlpfc_in_buf_free(phba, dmzbuf);\r\n}\r\nif (irsp->ulpBdeCount > 1) {\r\ndmzbuf = lpfc_sli_get_buff(phba, pring,\r\nirsp->unsli3.sli3Words[3]);\r\nlpfc_in_buf_free(phba, dmzbuf);\r\n}\r\nif (irsp->ulpBdeCount > 2) {\r\ndmzbuf = lpfc_sli_get_buff(phba, pring,\r\nirsp->unsli3.sli3Words[7]);\r\nlpfc_in_buf_free(phba, dmzbuf);\r\n}\r\nreturn 1;\r\n}\r\nif (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED) {\r\nif (irsp->ulpBdeCount != 0) {\r\nsaveq->context2 = lpfc_sli_get_buff(phba, pring,\r\nirsp->un.ulpWord[3]);\r\nif (!saveq->context2)\r\nlpfc_printf_log(phba,\r\nKERN_ERR,\r\nLOG_SLI,\r\n"0341 Ring %d Cannot find buffer for "\r\n"an unsolicited iocb. tag 0x%x\n",\r\npring->ringno,\r\nirsp->un.ulpWord[3]);\r\n}\r\nif (irsp->ulpBdeCount == 2) {\r\nsaveq->context3 = lpfc_sli_get_buff(phba, pring,\r\nirsp->unsli3.sli3Words[7]);\r\nif (!saveq->context3)\r\nlpfc_printf_log(phba,\r\nKERN_ERR,\r\nLOG_SLI,\r\n"0342 Ring %d Cannot find buffer for an"\r\n" unsolicited iocb. tag 0x%x\n",\r\npring->ringno,\r\nirsp->unsli3.sli3Words[7]);\r\n}\r\nlist_for_each_entry(iocbq, &saveq->list, list) {\r\nirsp = &(iocbq->iocb);\r\nif (irsp->ulpBdeCount != 0) {\r\niocbq->context2 = lpfc_sli_get_buff(phba, pring,\r\nirsp->un.ulpWord[3]);\r\nif (!iocbq->context2)\r\nlpfc_printf_log(phba,\r\nKERN_ERR,\r\nLOG_SLI,\r\n"0343 Ring %d Cannot find "\r\n"buffer for an unsolicited iocb"\r\n". tag 0x%x\n", pring->ringno,\r\nirsp->un.ulpWord[3]);\r\n}\r\nif (irsp->ulpBdeCount == 2) {\r\niocbq->context3 = lpfc_sli_get_buff(phba, pring,\r\nirsp->unsli3.sli3Words[7]);\r\nif (!iocbq->context3)\r\nlpfc_printf_log(phba,\r\nKERN_ERR,\r\nLOG_SLI,\r\n"0344 Ring %d Cannot find "\r\n"buffer for an unsolicited "\r\n"iocb. tag 0x%x\n",\r\npring->ringno,\r\nirsp->unsli3.sli3Words[7]);\r\n}\r\n}\r\n}\r\nif (irsp->ulpBdeCount != 0 &&\r\n(irsp->ulpCommand == CMD_IOCB_RCV_CONT64_CX ||\r\nirsp->ulpStatus == IOSTAT_INTERMED_RSP)) {\r\nint found = 0;\r\nlist_for_each_entry(iocbq, &pring->iocb_continue_saveq, clist) {\r\nif (iocbq->iocb.unsli3.rcvsli3.ox_id ==\r\nsaveq->iocb.unsli3.rcvsli3.ox_id) {\r\nlist_add_tail(&saveq->list, &iocbq->list);\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\nif (!found)\r\nlist_add_tail(&saveq->clist,\r\n&pring->iocb_continue_saveq);\r\nif (saveq->iocb.ulpStatus != IOSTAT_INTERMED_RSP) {\r\nlist_del_init(&iocbq->clist);\r\nsaveq = iocbq;\r\nirsp = &(saveq->iocb);\r\n} else\r\nreturn 0;\r\n}\r\nif ((irsp->ulpCommand == CMD_RCV_ELS_REQ64_CX) ||\r\n(irsp->ulpCommand == CMD_RCV_ELS_REQ_CX) ||\r\n(irsp->ulpCommand == CMD_IOCB_RCV_ELS64_CX)) {\r\nRctl = FC_RCTL_ELS_REQ;\r\nType = FC_TYPE_ELS;\r\n} else {\r\nw5p = (WORD5 *)&(saveq->iocb.un.ulpWord[5]);\r\nRctl = w5p->hcsw.Rctl;\r\nType = w5p->hcsw.Type;\r\nif ((Rctl == 0) && (pring->ringno == LPFC_ELS_RING) &&\r\n(irsp->ulpCommand == CMD_RCV_SEQUENCE64_CX ||\r\nirsp->ulpCommand == CMD_IOCB_RCV_SEQ64_CX)) {\r\nRctl = FC_RCTL_ELS_REQ;\r\nType = FC_TYPE_ELS;\r\nw5p->hcsw.Rctl = Rctl;\r\nw5p->hcsw.Type = Type;\r\n}\r\n}\r\nif (!lpfc_complete_unsol_iocb(phba, pring, saveq, Rctl, Type))\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0313 Ring %d handler: unexpected Rctl x%x "\r\n"Type x%x received\n",\r\npring->ringno, Rctl, Type);\r\nreturn 1;\r\n}\r\nstatic struct lpfc_iocbq *\r\nlpfc_sli_iocbq_lookup(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *prspiocb)\r\n{\r\nstruct lpfc_iocbq *cmd_iocb = NULL;\r\nuint16_t iotag;\r\niotag = prspiocb->iocb.ulpIoTag;\r\nif (iotag != 0 && iotag <= phba->sli.last_iotag) {\r\ncmd_iocb = phba->sli.iocbq_lookup[iotag];\r\nlist_del_init(&cmd_iocb->list);\r\nif (cmd_iocb->iocb_flag & LPFC_IO_ON_TXCMPLQ) {\r\ncmd_iocb->iocb_flag &= ~LPFC_IO_ON_TXCMPLQ;\r\n}\r\nreturn cmd_iocb;\r\n}\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0317 iotag x%x is out off "\r\n"range: max iotag x%x wd0 x%x\n",\r\niotag, phba->sli.last_iotag,\r\n*(((uint32_t *) &prspiocb->iocb) + 7));\r\nreturn NULL;\r\n}\r\nstatic struct lpfc_iocbq *\r\nlpfc_sli_iocbq_lookup_by_tag(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring, uint16_t iotag)\r\n{\r\nstruct lpfc_iocbq *cmd_iocb;\r\nif (iotag != 0 && iotag <= phba->sli.last_iotag) {\r\ncmd_iocb = phba->sli.iocbq_lookup[iotag];\r\nif (cmd_iocb->iocb_flag & LPFC_IO_ON_TXCMPLQ) {\r\nlist_del_init(&cmd_iocb->list);\r\ncmd_iocb->iocb_flag &= ~LPFC_IO_ON_TXCMPLQ;\r\nreturn cmd_iocb;\r\n}\r\n}\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0372 iotag x%x is out off range: max iotag (x%x)\n",\r\niotag, phba->sli.last_iotag);\r\nreturn NULL;\r\n}\r\nstatic int\r\nlpfc_sli_process_sol_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *saveq)\r\n{\r\nstruct lpfc_iocbq *cmdiocbp;\r\nint rc = 1;\r\nunsigned long iflag;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\ncmdiocbp = lpfc_sli_iocbq_lookup(phba, pring, saveq);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nif (cmdiocbp) {\r\nif (cmdiocbp->iocb_cmpl) {\r\nif (saveq->iocb.ulpStatus &&\r\n(pring->ringno == LPFC_ELS_RING) &&\r\n(cmdiocbp->iocb.ulpCommand ==\r\nCMD_ELS_REQUEST64_CR))\r\nlpfc_send_els_failure_event(phba,\r\ncmdiocbp, saveq);\r\nif (pring->ringno == LPFC_ELS_RING) {\r\nif ((phba->sli_rev < LPFC_SLI_REV4) &&\r\n(cmdiocbp->iocb_flag &\r\nLPFC_DRIVER_ABORTED)) {\r\nspin_lock_irqsave(&phba->hbalock,\r\niflag);\r\ncmdiocbp->iocb_flag &=\r\n~LPFC_DRIVER_ABORTED;\r\nspin_unlock_irqrestore(&phba->hbalock,\r\niflag);\r\nsaveq->iocb.ulpStatus =\r\nIOSTAT_LOCAL_REJECT;\r\nsaveq->iocb.un.ulpWord[4] =\r\nIOERR_SLI_ABORTED;\r\nspin_lock_irqsave(&phba->hbalock,\r\niflag);\r\nsaveq->iocb_flag |= LPFC_DELAY_MEM_FREE;\r\nspin_unlock_irqrestore(&phba->hbalock,\r\niflag);\r\n}\r\nif (phba->sli_rev == LPFC_SLI_REV4) {\r\nif (saveq->iocb_flag &\r\nLPFC_EXCHANGE_BUSY) {\r\nspin_lock_irqsave(\r\n&phba->hbalock, iflag);\r\ncmdiocbp->iocb_flag |=\r\nLPFC_EXCHANGE_BUSY;\r\nspin_unlock_irqrestore(\r\n&phba->hbalock, iflag);\r\n}\r\nif (cmdiocbp->iocb_flag &\r\nLPFC_DRIVER_ABORTED) {\r\nspin_lock_irqsave(\r\n&phba->hbalock, iflag);\r\ncmdiocbp->iocb_flag &=\r\n~LPFC_DRIVER_ABORTED;\r\nspin_unlock_irqrestore(\r\n&phba->hbalock, iflag);\r\ncmdiocbp->iocb.ulpStatus =\r\nIOSTAT_LOCAL_REJECT;\r\ncmdiocbp->iocb.un.ulpWord[4] =\r\nIOERR_ABORT_REQUESTED;\r\nsaveq->iocb.ulpStatus =\r\nIOSTAT_LOCAL_REJECT;\r\nsaveq->iocb.un.ulpWord[4] =\r\nIOERR_SLI_ABORTED;\r\nspin_lock_irqsave(\r\n&phba->hbalock, iflag);\r\nsaveq->iocb_flag |=\r\nLPFC_DELAY_MEM_FREE;\r\nspin_unlock_irqrestore(\r\n&phba->hbalock, iflag);\r\n}\r\n}\r\n}\r\n(cmdiocbp->iocb_cmpl) (phba, cmdiocbp, saveq);\r\n} else\r\nlpfc_sli_release_iocbq(phba, cmdiocbp);\r\n} else {\r\nif (pring->ringno != LPFC_ELS_RING) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0322 Ring %d handler: "\r\n"unexpected completion IoTag x%x "\r\n"Data: x%x x%x x%x x%x\n",\r\npring->ringno,\r\nsaveq->iocb.ulpIoTag,\r\nsaveq->iocb.ulpStatus,\r\nsaveq->iocb.un.ulpWord[4],\r\nsaveq->iocb.ulpCommand,\r\nsaveq->iocb.ulpContext);\r\n}\r\n}\r\nreturn rc;\r\n}\r\nstatic void\r\nlpfc_sli_rsp_pointers_error(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nstruct lpfc_pgp *pgp = &phba->port_gp[pring->ringno];\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0312 Ring %d handler: portRspPut %d "\r\n"is bigger than rsp ring %d\n",\r\npring->ringno, le32_to_cpu(pgp->rspPutInx),\r\npring->sli.sli3.numRiocb);\r\nphba->link_state = LPFC_HBA_ERROR;\r\nphba->work_ha |= HA_ERATT;\r\nphba->work_hs = HS_FFER3;\r\nlpfc_worker_wake_up(phba);\r\nreturn;\r\n}\r\nvoid lpfc_poll_eratt(unsigned long ptr)\r\n{\r\nstruct lpfc_hba *phba;\r\nuint32_t eratt = 0;\r\nuint64_t sli_intr, cnt;\r\nphba = (struct lpfc_hba *)ptr;\r\nsli_intr = phba->sli.slistat.sli_intr;\r\nif (phba->sli.slistat.sli_prev_intr > sli_intr)\r\ncnt = (((uint64_t)(-1) - phba->sli.slistat.sli_prev_intr) +\r\nsli_intr);\r\nelse\r\ncnt = (sli_intr - phba->sli.slistat.sli_prev_intr);\r\ndo_div(cnt, LPFC_ERATT_POLL_INTERVAL);\r\nphba->sli.slistat.sli_ips = cnt;\r\nphba->sli.slistat.sli_prev_intr = sli_intr;\r\neratt = lpfc_sli_check_eratt(phba);\r\nif (eratt)\r\nlpfc_worker_wake_up(phba);\r\nelse\r\nmod_timer(&phba->eratt_poll,\r\njiffies +\r\nmsecs_to_jiffies(1000 * LPFC_ERATT_POLL_INTERVAL));\r\nreturn;\r\n}\r\nint\r\nlpfc_sli_handle_fast_ring_event(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring, uint32_t mask)\r\n{\r\nstruct lpfc_pgp *pgp = &phba->port_gp[pring->ringno];\r\nIOCB_t *irsp = NULL;\r\nIOCB_t *entry = NULL;\r\nstruct lpfc_iocbq *cmdiocbq = NULL;\r\nstruct lpfc_iocbq rspiocbq;\r\nuint32_t status;\r\nuint32_t portRspPut, portRspMax;\r\nint rc = 1;\r\nlpfc_iocb_type type;\r\nunsigned long iflag;\r\nuint32_t rsp_cmpl = 0;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\npring->stats.iocb_event++;\r\nportRspMax = pring->sli.sli3.numRiocb;\r\nportRspPut = le32_to_cpu(pgp->rspPutInx);\r\nif (unlikely(portRspPut >= portRspMax)) {\r\nlpfc_sli_rsp_pointers_error(phba, pring);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn 1;\r\n}\r\nif (phba->fcp_ring_in_use) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn 1;\r\n} else\r\nphba->fcp_ring_in_use = 1;\r\nrmb();\r\nwhile (pring->sli.sli3.rspidx != portRspPut) {\r\nentry = lpfc_resp_iocb(phba, pring);\r\nphba->last_completion_time = jiffies;\r\nif (++pring->sli.sli3.rspidx >= portRspMax)\r\npring->sli.sli3.rspidx = 0;\r\nlpfc_sli_pcimem_bcopy((uint32_t *) entry,\r\n(uint32_t *) &rspiocbq.iocb,\r\nphba->iocb_rsp_size);\r\nINIT_LIST_HEAD(&(rspiocbq.list));\r\nirsp = &rspiocbq.iocb;\r\ntype = lpfc_sli_iocb_cmd_type(irsp->ulpCommand & CMD_IOCB_MASK);\r\npring->stats.iocb_rsp++;\r\nrsp_cmpl++;\r\nif (unlikely(irsp->ulpStatus)) {\r\nif ((irsp->ulpStatus == IOSTAT_LOCAL_REJECT) &&\r\n((irsp->un.ulpWord[4] & IOERR_PARAM_MASK) ==\r\nIOERR_NO_RESOURCES)) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nphba->lpfc_rampdown_queue_depth(phba);\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\n}\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0336 Rsp Ring %d error: IOCB Data: "\r\n"x%x x%x x%x x%x x%x x%x x%x x%x\n",\r\npring->ringno,\r\nirsp->un.ulpWord[0],\r\nirsp->un.ulpWord[1],\r\nirsp->un.ulpWord[2],\r\nirsp->un.ulpWord[3],\r\nirsp->un.ulpWord[4],\r\nirsp->un.ulpWord[5],\r\n*(uint32_t *)&irsp->un1,\r\n*((uint32_t *)&irsp->un1 + 1));\r\n}\r\nswitch (type) {\r\ncase LPFC_ABORT_IOCB:\r\ncase LPFC_SOL_IOCB:\r\nif (unlikely(irsp->ulpCommand == CMD_XRI_ABORTED_CX)) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0333 IOCB cmd 0x%x"\r\n" processed. Skipping"\r\n" completion\n",\r\nirsp->ulpCommand);\r\nbreak;\r\n}\r\ncmdiocbq = lpfc_sli_iocbq_lookup(phba, pring,\r\n&rspiocbq);\r\nif (unlikely(!cmdiocbq))\r\nbreak;\r\nif (cmdiocbq->iocb_flag & LPFC_DRIVER_ABORTED)\r\ncmdiocbq->iocb_flag &= ~LPFC_DRIVER_ABORTED;\r\nif (cmdiocbq->iocb_cmpl) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\n(cmdiocbq->iocb_cmpl)(phba, cmdiocbq,\r\n&rspiocbq);\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\n}\r\nbreak;\r\ncase LPFC_UNSOL_IOCB:\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nlpfc_sli_process_unsol_iocb(phba, pring, &rspiocbq);\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nbreak;\r\ndefault:\r\nif (irsp->ulpCommand == CMD_ADAPTER_MSG) {\r\nchar adaptermsg[LPFC_MAX_ADPTMSG];\r\nmemset(adaptermsg, 0, LPFC_MAX_ADPTMSG);\r\nmemcpy(&adaptermsg[0], (uint8_t *) irsp,\r\nMAX_MSG_DATA);\r\ndev_warn(&((phba->pcidev)->dev),\r\n"lpfc%d: %s\n",\r\nphba->brd_no, adaptermsg);\r\n} else {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0334 Unknown IOCB command "\r\n"Data: x%x, x%x x%x x%x x%x\n",\r\ntype, irsp->ulpCommand,\r\nirsp->ulpStatus,\r\nirsp->ulpIoTag,\r\nirsp->ulpContext);\r\n}\r\nbreak;\r\n}\r\nwritel(pring->sli.sli3.rspidx,\r\n&phba->host_gp[pring->ringno].rspGetInx);\r\nif (pring->sli.sli3.rspidx == portRspPut)\r\nportRspPut = le32_to_cpu(pgp->rspPutInx);\r\n}\r\nif ((rsp_cmpl > 0) && (mask & HA_R0RE_REQ)) {\r\npring->stats.iocb_rsp_full++;\r\nstatus = ((CA_R0ATT | CA_R0RE_RSP) << (pring->ringno * 4));\r\nwritel(status, phba->CAregaddr);\r\nreadl(phba->CAregaddr);\r\n}\r\nif ((mask & HA_R0CE_RSP) && (pring->flag & LPFC_CALL_RING_AVAILABLE)) {\r\npring->flag &= ~LPFC_CALL_RING_AVAILABLE;\r\npring->stats.iocb_cmd_empty++;\r\npring->sli.sli3.local_getidx = le32_to_cpu(pgp->cmdGetInx);\r\nlpfc_sli_resume_iocb(phba, pring);\r\nif ((pring->lpfc_sli_cmd_available))\r\n(pring->lpfc_sli_cmd_available) (phba, pring);\r\n}\r\nphba->fcp_ring_in_use = 0;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn rc;\r\n}\r\nstatic struct lpfc_iocbq *\r\nlpfc_sli_sp_handle_rspiocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *rspiocbp)\r\n{\r\nstruct lpfc_iocbq *saveq;\r\nstruct lpfc_iocbq *cmdiocbp;\r\nstruct lpfc_iocbq *next_iocb;\r\nIOCB_t *irsp = NULL;\r\nuint32_t free_saveq;\r\nuint8_t iocb_cmd_type;\r\nlpfc_iocb_type type;\r\nunsigned long iflag;\r\nint rc;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nlist_add_tail(&rspiocbp->list, &(pring->iocb_continueq));\r\npring->iocb_continueq_cnt++;\r\nirsp = &rspiocbp->iocb;\r\nif (irsp->ulpLe) {\r\nfree_saveq = 1;\r\nsaveq = list_get_first(&pring->iocb_continueq,\r\nstruct lpfc_iocbq, list);\r\nirsp = &(saveq->iocb);\r\nlist_del_init(&pring->iocb_continueq);\r\npring->iocb_continueq_cnt = 0;\r\npring->stats.iocb_rsp++;\r\nif ((irsp->ulpStatus == IOSTAT_LOCAL_REJECT) &&\r\n((irsp->un.ulpWord[4] & IOERR_PARAM_MASK) ==\r\nIOERR_NO_RESOURCES)) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nphba->lpfc_rampdown_queue_depth(phba);\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\n}\r\nif (irsp->ulpStatus) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0328 Rsp Ring %d error: "\r\n"IOCB Data: "\r\n"x%x x%x x%x x%x "\r\n"x%x x%x x%x x%x "\r\n"x%x x%x x%x x%x "\r\n"x%x x%x x%x x%x\n",\r\npring->ringno,\r\nirsp->un.ulpWord[0],\r\nirsp->un.ulpWord[1],\r\nirsp->un.ulpWord[2],\r\nirsp->un.ulpWord[3],\r\nirsp->un.ulpWord[4],\r\nirsp->un.ulpWord[5],\r\n*(((uint32_t *) irsp) + 6),\r\n*(((uint32_t *) irsp) + 7),\r\n*(((uint32_t *) irsp) + 8),\r\n*(((uint32_t *) irsp) + 9),\r\n*(((uint32_t *) irsp) + 10),\r\n*(((uint32_t *) irsp) + 11),\r\n*(((uint32_t *) irsp) + 12),\r\n*(((uint32_t *) irsp) + 13),\r\n*(((uint32_t *) irsp) + 14),\r\n*(((uint32_t *) irsp) + 15));\r\n}\r\niocb_cmd_type = irsp->ulpCommand & CMD_IOCB_MASK;\r\ntype = lpfc_sli_iocb_cmd_type(iocb_cmd_type);\r\nswitch (type) {\r\ncase LPFC_SOL_IOCB:\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nrc = lpfc_sli_process_sol_iocb(phba, pring, saveq);\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nbreak;\r\ncase LPFC_UNSOL_IOCB:\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nrc = lpfc_sli_process_unsol_iocb(phba, pring, saveq);\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (!rc)\r\nfree_saveq = 0;\r\nbreak;\r\ncase LPFC_ABORT_IOCB:\r\ncmdiocbp = NULL;\r\nif (irsp->ulpCommand != CMD_XRI_ABORTED_CX)\r\ncmdiocbp = lpfc_sli_iocbq_lookup(phba, pring,\r\nsaveq);\r\nif (cmdiocbp) {\r\nif (cmdiocbp->iocb_cmpl) {\r\nspin_unlock_irqrestore(&phba->hbalock,\r\niflag);\r\n(cmdiocbp->iocb_cmpl)(phba, cmdiocbp,\r\nsaveq);\r\nspin_lock_irqsave(&phba->hbalock,\r\niflag);\r\n} else\r\n__lpfc_sli_release_iocbq(phba,\r\ncmdiocbp);\r\n}\r\nbreak;\r\ncase LPFC_UNKNOWN_IOCB:\r\nif (irsp->ulpCommand == CMD_ADAPTER_MSG) {\r\nchar adaptermsg[LPFC_MAX_ADPTMSG];\r\nmemset(adaptermsg, 0, LPFC_MAX_ADPTMSG);\r\nmemcpy(&adaptermsg[0], (uint8_t *)irsp,\r\nMAX_MSG_DATA);\r\ndev_warn(&((phba->pcidev)->dev),\r\n"lpfc%d: %s\n",\r\nphba->brd_no, adaptermsg);\r\n} else {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0335 Unknown IOCB "\r\n"command Data: x%x "\r\n"x%x x%x x%x\n",\r\nirsp->ulpCommand,\r\nirsp->ulpStatus,\r\nirsp->ulpIoTag,\r\nirsp->ulpContext);\r\n}\r\nbreak;\r\n}\r\nif (free_saveq) {\r\nlist_for_each_entry_safe(rspiocbp, next_iocb,\r\n&saveq->list, list) {\r\nlist_del_init(&rspiocbp->list);\r\n__lpfc_sli_release_iocbq(phba, rspiocbp);\r\n}\r\n__lpfc_sli_release_iocbq(phba, saveq);\r\n}\r\nrspiocbp = NULL;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn rspiocbp;\r\n}\r\nvoid\r\nlpfc_sli_handle_slow_ring_event(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring, uint32_t mask)\r\n{\r\nphba->lpfc_sli_handle_slow_ring_event(phba, pring, mask);\r\n}\r\nstatic void\r\nlpfc_sli_handle_slow_ring_event_s3(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring, uint32_t mask)\r\n{\r\nstruct lpfc_pgp *pgp;\r\nIOCB_t *entry;\r\nIOCB_t *irsp = NULL;\r\nstruct lpfc_iocbq *rspiocbp = NULL;\r\nuint32_t portRspPut, portRspMax;\r\nunsigned long iflag;\r\nuint32_t status;\r\npgp = &phba->port_gp[pring->ringno];\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\npring->stats.iocb_event++;\r\nportRspMax = pring->sli.sli3.numRiocb;\r\nportRspPut = le32_to_cpu(pgp->rspPutInx);\r\nif (portRspPut >= portRspMax) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0303 Ring %d handler: portRspPut %d "\r\n"is bigger than rsp ring %d\n",\r\npring->ringno, portRspPut, portRspMax);\r\nphba->link_state = LPFC_HBA_ERROR;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nphba->work_hs = HS_FFER3;\r\nlpfc_handle_eratt(phba);\r\nreturn;\r\n}\r\nrmb();\r\nwhile (pring->sli.sli3.rspidx != portRspPut) {\r\nentry = lpfc_resp_iocb(phba, pring);\r\nphba->last_completion_time = jiffies;\r\nrspiocbp = __lpfc_sli_get_iocbq(phba);\r\nif (rspiocbp == NULL) {\r\nprintk(KERN_ERR "%s: out of buffers! Failing "\r\n"completion.\n", __func__);\r\nbreak;\r\n}\r\nlpfc_sli_pcimem_bcopy(entry, &rspiocbp->iocb,\r\nphba->iocb_rsp_size);\r\nirsp = &rspiocbp->iocb;\r\nif (++pring->sli.sli3.rspidx >= portRspMax)\r\npring->sli.sli3.rspidx = 0;\r\nif (pring->ringno == LPFC_ELS_RING) {\r\nlpfc_debugfs_slow_ring_trc(phba,\r\n"IOCB rsp ring: wd4:x%08x wd6:x%08x wd7:x%08x",\r\n*(((uint32_t *) irsp) + 4),\r\n*(((uint32_t *) irsp) + 6),\r\n*(((uint32_t *) irsp) + 7));\r\n}\r\nwritel(pring->sli.sli3.rspidx,\r\n&phba->host_gp[pring->ringno].rspGetInx);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nrspiocbp = lpfc_sli_sp_handle_rspiocb(phba, pring, rspiocbp);\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (pring->sli.sli3.rspidx == portRspPut) {\r\nportRspPut = le32_to_cpu(pgp->rspPutInx);\r\n}\r\n}\r\nif ((rspiocbp != NULL) && (mask & HA_R0RE_REQ)) {\r\npring->stats.iocb_rsp_full++;\r\nstatus = ((CA_R0ATT | CA_R0RE_RSP) << (pring->ringno * 4));\r\nwritel(status, phba->CAregaddr);\r\nreadl(phba->CAregaddr);\r\n}\r\nif ((mask & HA_R0CE_RSP) && (pring->flag & LPFC_CALL_RING_AVAILABLE)) {\r\npring->flag &= ~LPFC_CALL_RING_AVAILABLE;\r\npring->stats.iocb_cmd_empty++;\r\npring->sli.sli3.local_getidx = le32_to_cpu(pgp->cmdGetInx);\r\nlpfc_sli_resume_iocb(phba, pring);\r\nif ((pring->lpfc_sli_cmd_available))\r\n(pring->lpfc_sli_cmd_available) (phba, pring);\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_sli_handle_slow_ring_event_s4(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring, uint32_t mask)\r\n{\r\nstruct lpfc_iocbq *irspiocbq;\r\nstruct hbq_dmabuf *dmabuf;\r\nstruct lpfc_cq_event *cq_event;\r\nunsigned long iflag;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nphba->hba_flag &= ~HBA_SP_QUEUE_EVT;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nwhile (!list_empty(&phba->sli4_hba.sp_queue_event)) {\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nlist_remove_head(&phba->sli4_hba.sp_queue_event,\r\ncq_event, struct lpfc_cq_event, list);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nswitch (bf_get(lpfc_wcqe_c_code, &cq_event->cqe.wcqe_cmpl)) {\r\ncase CQE_CODE_COMPL_WQE:\r\nirspiocbq = container_of(cq_event, struct lpfc_iocbq,\r\ncq_event);\r\nirspiocbq = lpfc_sli4_els_wcqe_to_rspiocbq(phba,\r\nirspiocbq);\r\nif (irspiocbq)\r\nlpfc_sli_sp_handle_rspiocb(phba, pring,\r\nirspiocbq);\r\nbreak;\r\ncase CQE_CODE_RECEIVE:\r\ncase CQE_CODE_RECEIVE_V1:\r\ndmabuf = container_of(cq_event, struct hbq_dmabuf,\r\ncq_event);\r\nlpfc_sli4_handle_received_buffer(phba, dmabuf);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\n}\r\nvoid\r\nlpfc_sli_abort_iocb_ring(struct lpfc_hba *phba, struct lpfc_sli_ring *pring)\r\n{\r\nLIST_HEAD(completions);\r\nstruct lpfc_iocbq *iocb, *next_iocb;\r\nif (pring->ringno == LPFC_ELS_RING) {\r\nlpfc_fabric_abort_hba(phba);\r\n}\r\nif (phba->sli_rev >= LPFC_SLI_REV4) {\r\nspin_lock_irq(&pring->ring_lock);\r\nlist_splice_init(&pring->txq, &completions);\r\npring->txq_cnt = 0;\r\nspin_unlock_irq(&pring->ring_lock);\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(iocb, next_iocb, &pring->txcmplq, list)\r\nlpfc_sli_issue_abort_iotag(phba, pring, iocb);\r\nspin_unlock_irq(&phba->hbalock);\r\n} else {\r\nspin_lock_irq(&phba->hbalock);\r\nlist_splice_init(&pring->txq, &completions);\r\npring->txq_cnt = 0;\r\nlist_for_each_entry_safe(iocb, next_iocb, &pring->txcmplq, list)\r\nlpfc_sli_issue_abort_iotag(phba, pring, iocb);\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_ABORTED);\r\n}\r\nvoid\r\nlpfc_sli_abort_fcp_rings(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_sli_ring *pring;\r\nuint32_t i;\r\nif (phba->sli_rev >= LPFC_SLI_REV4) {\r\nfor (i = 0; i < phba->cfg_fcp_io_channel; i++) {\r\npring = &psli->ring[i + MAX_SLI3_CONFIGURED_RINGS];\r\nlpfc_sli_abort_iocb_ring(phba, pring);\r\n}\r\n} else {\r\npring = &psli->ring[psli->fcp_ring];\r\nlpfc_sli_abort_iocb_ring(phba, pring);\r\n}\r\n}\r\nvoid\r\nlpfc_sli_flush_fcp_rings(struct lpfc_hba *phba)\r\n{\r\nLIST_HEAD(txq);\r\nLIST_HEAD(txcmplq);\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_sli_ring *pring;\r\nuint32_t i;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag |= HBA_FCP_IOQ_FLUSH;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (phba->sli_rev >= LPFC_SLI_REV4) {\r\nfor (i = 0; i < phba->cfg_fcp_io_channel; i++) {\r\npring = &psli->ring[i + MAX_SLI3_CONFIGURED_RINGS];\r\nspin_lock_irq(&pring->ring_lock);\r\nlist_splice_init(&pring->txq, &txq);\r\nlist_splice_init(&pring->txcmplq, &txcmplq);\r\npring->txq_cnt = 0;\r\npring->txcmplq_cnt = 0;\r\nspin_unlock_irq(&pring->ring_lock);\r\nlpfc_sli_cancel_iocbs(phba, &txq,\r\nIOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_DOWN);\r\nlpfc_sli_cancel_iocbs(phba, &txcmplq,\r\nIOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_DOWN);\r\n}\r\n} else {\r\npring = &psli->ring[psli->fcp_ring];\r\nspin_lock_irq(&phba->hbalock);\r\nlist_splice_init(&pring->txq, &txq);\r\nlist_splice_init(&pring->txcmplq, &txcmplq);\r\npring->txq_cnt = 0;\r\npring->txcmplq_cnt = 0;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli_cancel_iocbs(phba, &txq, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_DOWN);\r\nlpfc_sli_cancel_iocbs(phba, &txcmplq, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_DOWN);\r\n}\r\n}\r\nstatic int\r\nlpfc_sli_brdready_s3(struct lpfc_hba *phba, uint32_t mask)\r\n{\r\nuint32_t status;\r\nint i = 0;\r\nint retval = 0;\r\nif (lpfc_readl(phba->HSregaddr, &status))\r\nreturn 1;\r\nwhile (((status & mask) != mask) &&\r\n!(status & HS_FFERM) &&\r\ni++ < 20) {\r\nif (i <= 5)\r\nmsleep(10);\r\nelse if (i <= 10)\r\nmsleep(500);\r\nelse\r\nmsleep(2500);\r\nif (i == 15) {\r\nphba->pport->port_state = LPFC_VPORT_UNKNOWN;\r\nlpfc_sli_brdrestart(phba);\r\n}\r\nif (lpfc_readl(phba->HSregaddr, &status)) {\r\nretval = 1;\r\nbreak;\r\n}\r\n}\r\nif ((status & HS_FFERM) || (i >= 20)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2751 Adapter failed to restart, "\r\n"status reg x%x, FW Data: A8 x%x AC x%x\n",\r\nstatus,\r\nreadl(phba->MBslimaddr + 0xa8),\r\nreadl(phba->MBslimaddr + 0xac));\r\nphba->link_state = LPFC_HBA_ERROR;\r\nretval = 1;\r\n}\r\nreturn retval;\r\n}\r\nstatic int\r\nlpfc_sli_brdready_s4(struct lpfc_hba *phba, uint32_t mask)\r\n{\r\nuint32_t status;\r\nint retval = 0;\r\nstatus = lpfc_sli4_post_status_check(phba);\r\nif (status) {\r\nphba->pport->port_state = LPFC_VPORT_UNKNOWN;\r\nlpfc_sli_brdrestart(phba);\r\nstatus = lpfc_sli4_post_status_check(phba);\r\n}\r\nif (status) {\r\nphba->link_state = LPFC_HBA_ERROR;\r\nretval = 1;\r\n} else\r\nphba->sli4_hba.intr_enable = 0;\r\nreturn retval;\r\n}\r\nint\r\nlpfc_sli_brdready(struct lpfc_hba *phba, uint32_t mask)\r\n{\r\nreturn phba->lpfc_sli_brdready(phba, mask);\r\n}\r\nvoid lpfc_reset_barrier(struct lpfc_hba *phba)\r\n{\r\nuint32_t __iomem *resp_buf;\r\nuint32_t __iomem *mbox_buf;\r\nvolatile uint32_t mbox;\r\nuint32_t hc_copy, ha_copy, resp_data;\r\nint i;\r\nuint8_t hdrtype;\r\npci_read_config_byte(phba->pcidev, PCI_HEADER_TYPE, &hdrtype);\r\nif (hdrtype != 0x80 ||\r\n(FC_JEDEC_ID(phba->vpd.rev.biuRev) != HELIOS_JEDEC_ID &&\r\nFC_JEDEC_ID(phba->vpd.rev.biuRev) != THOR_JEDEC_ID))\r\nreturn;\r\nresp_buf = phba->MBslimaddr;\r\nif (lpfc_readl(phba->HCregaddr, &hc_copy))\r\nreturn;\r\nwritel((hc_copy & ~HC_ERINT_ENA), phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\nphba->link_flag |= LS_IGNORE_ERATT;\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy))\r\nreturn;\r\nif (ha_copy & HA_ERATT) {\r\nwritel(HA_ERATT, phba->HAregaddr);\r\nphba->pport->stopped = 1;\r\n}\r\nmbox = 0;\r\n((MAILBOX_t *)&mbox)->mbxCommand = MBX_KILL_BOARD;\r\n((MAILBOX_t *)&mbox)->mbxOwner = OWN_CHIP;\r\nwritel(BARRIER_TEST_PATTERN, (resp_buf + 1));\r\nmbox_buf = phba->MBslimaddr;\r\nwritel(mbox, mbox_buf);\r\nfor (i = 0; i < 50; i++) {\r\nif (lpfc_readl((resp_buf + 1), &resp_data))\r\nreturn;\r\nif (resp_data != ~(BARRIER_TEST_PATTERN))\r\nmdelay(1);\r\nelse\r\nbreak;\r\n}\r\nresp_data = 0;\r\nif (lpfc_readl((resp_buf + 1), &resp_data))\r\nreturn;\r\nif (resp_data != ~(BARRIER_TEST_PATTERN)) {\r\nif (phba->sli.sli_flag & LPFC_SLI_ACTIVE ||\r\nphba->pport->stopped)\r\ngoto restore_hc;\r\nelse\r\ngoto clear_errat;\r\n}\r\n((MAILBOX_t *)&mbox)->mbxOwner = OWN_HOST;\r\nresp_data = 0;\r\nfor (i = 0; i < 500; i++) {\r\nif (lpfc_readl(resp_buf, &resp_data))\r\nreturn;\r\nif (resp_data != mbox)\r\nmdelay(1);\r\nelse\r\nbreak;\r\n}\r\nclear_errat:\r\nwhile (++i < 500) {\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy))\r\nreturn;\r\nif (!(ha_copy & HA_ERATT))\r\nmdelay(1);\r\nelse\r\nbreak;\r\n}\r\nif (readl(phba->HAregaddr) & HA_ERATT) {\r\nwritel(HA_ERATT, phba->HAregaddr);\r\nphba->pport->stopped = 1;\r\n}\r\nrestore_hc:\r\nphba->link_flag &= ~LS_IGNORE_ERATT;\r\nwritel(hc_copy, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n}\r\nint\r\nlpfc_sli_brdkill(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli;\r\nLPFC_MBOXQ_t *pmb;\r\nuint32_t status;\r\nuint32_t ha_copy;\r\nint retval;\r\nint i = 0;\r\npsli = &phba->sli;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0329 Kill HBA Data: x%x x%x\n",\r\nphba->pport->port_state, psli->sli_flag);\r\npmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!pmb)\r\nreturn 1;\r\nspin_lock_irq(&phba->hbalock);\r\nif (lpfc_readl(phba->HCregaddr, &status)) {\r\nspin_unlock_irq(&phba->hbalock);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn 1;\r\n}\r\nstatus &= ~HC_ERINT_ENA;\r\nwritel(status, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\nphba->link_flag |= LS_IGNORE_ERATT;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_kill_board(phba, pmb);\r\npmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nretval = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\r\nif (retval != MBX_SUCCESS) {\r\nif (retval != MBX_BUSY)\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2752 KILL_BOARD command failed retval %d\n",\r\nretval);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->link_flag &= ~LS_IGNORE_ERATT;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 1;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag &= ~LPFC_SLI_ACTIVE;\r\nspin_unlock_irq(&phba->hbalock);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy))\r\nreturn 1;\r\nwhile ((i++ < 30) && !(ha_copy & HA_ERATT)) {\r\nmdelay(100);\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy))\r\nreturn 1;\r\n}\r\ndel_timer_sync(&psli->mbox_tmo);\r\nif (ha_copy & HA_ERATT) {\r\nwritel(HA_ERATT, phba->HAregaddr);\r\nphba->pport->stopped = 1;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\npsli->mbox_active = NULL;\r\nphba->link_flag &= ~LS_IGNORE_ERATT;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_hba_down_post(phba);\r\nphba->link_state = LPFC_HBA_ERROR;\r\nreturn ha_copy & HA_ERATT ? 0 : 1;\r\n}\r\nint\r\nlpfc_sli_brdreset(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli;\r\nstruct lpfc_sli_ring *pring;\r\nuint16_t cfg_value;\r\nint i;\r\npsli = &phba->sli;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0325 Reset HBA Data: x%x x%x\n",\r\nphba->pport->port_state, psli->sli_flag);\r\nphba->fc_eventTag = 0;\r\nphba->link_events = 0;\r\nphba->pport->fc_myDID = 0;\r\nphba->pport->fc_prevDID = 0;\r\npci_read_config_word(phba->pcidev, PCI_COMMAND, &cfg_value);\r\npci_write_config_word(phba->pcidev, PCI_COMMAND,\r\n(cfg_value &\r\n~(PCI_COMMAND_PARITY | PCI_COMMAND_SERR)));\r\npsli->sli_flag &= ~(LPFC_SLI_ACTIVE | LPFC_PROCESS_LA);\r\nwritel(HC_INITFF, phba->HCregaddr);\r\nmdelay(1);\r\nreadl(phba->HCregaddr);\r\nwritel(0, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\npci_write_config_word(phba->pcidev, PCI_COMMAND, cfg_value);\r\nfor (i = 0; i < psli->num_rings; i++) {\r\npring = &psli->ring[i];\r\npring->flag = 0;\r\npring->sli.sli3.rspidx = 0;\r\npring->sli.sli3.next_cmdidx = 0;\r\npring->sli.sli3.local_getidx = 0;\r\npring->sli.sli3.cmdidx = 0;\r\npring->missbufcnt = 0;\r\n}\r\nphba->link_state = LPFC_WARM_START;\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli4_brdreset(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nuint16_t cfg_value;\r\nint rc = 0;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0295 Reset HBA Data: x%x x%x x%x\n",\r\nphba->pport->port_state, psli->sli_flag,\r\nphba->hba_flag);\r\nphba->fc_eventTag = 0;\r\nphba->link_events = 0;\r\nphba->pport->fc_myDID = 0;\r\nphba->pport->fc_prevDID = 0;\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag &= ~(LPFC_PROCESS_LA);\r\nphba->fcf.fcf_flag = 0;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (phba->hba_flag & HBA_FW_DUMP_OP) {\r\nphba->hba_flag &= ~HBA_FW_DUMP_OP;\r\nreturn rc;\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"0389 Performing PCI function reset!\n");\r\npci_read_config_word(phba->pcidev, PCI_COMMAND, &cfg_value);\r\npci_write_config_word(phba->pcidev, PCI_COMMAND, (cfg_value &\r\n~(PCI_COMMAND_PARITY | PCI_COMMAND_SERR)));\r\nrc = lpfc_pci_function_reset(phba);\r\nlpfc_sli4_queue_destroy(phba);\r\npci_write_config_word(phba->pcidev, PCI_COMMAND, cfg_value);\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli_brdrestart_s3(struct lpfc_hba *phba)\r\n{\r\nMAILBOX_t *mb;\r\nstruct lpfc_sli *psli;\r\nvolatile uint32_t word0;\r\nvoid __iomem *to_slim;\r\nuint32_t hba_aer_enabled;\r\nspin_lock_irq(&phba->hbalock);\r\nhba_aer_enabled = phba->hba_flag & HBA_AER_ENABLED;\r\npsli = &phba->sli;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0337 Restart HBA Data: x%x x%x\n",\r\nphba->pport->port_state, psli->sli_flag);\r\nword0 = 0;\r\nmb = (MAILBOX_t *) &word0;\r\nmb->mbxCommand = MBX_RESTART;\r\nmb->mbxHc = 1;\r\nlpfc_reset_barrier(phba);\r\nto_slim = phba->MBslimaddr;\r\nwritel(*(uint32_t *) mb, to_slim);\r\nreadl(to_slim);\r\nif (phba->pport->port_state)\r\nword0 = 1;\r\nelse\r\nword0 = 0;\r\nto_slim = phba->MBslimaddr + sizeof (uint32_t);\r\nwritel(*(uint32_t *) mb, to_slim);\r\nreadl(to_slim);\r\nlpfc_sli_brdreset(phba);\r\nphba->pport->stopped = 0;\r\nphba->link_state = LPFC_INIT_START;\r\nphba->hba_flag = 0;\r\nspin_unlock_irq(&phba->hbalock);\r\nmemset(&psli->lnk_stat_offsets, 0, sizeof(psli->lnk_stat_offsets));\r\npsli->stats_start = get_seconds();\r\nmdelay(100);\r\nif (hba_aer_enabled)\r\npci_disable_pcie_error_reporting(phba->pcidev);\r\nlpfc_hba_down_post(phba);\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_sli_brdrestart_s4(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nuint32_t hba_aer_enabled;\r\nint rc;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0296 Restart HBA Data: x%x x%x\n",\r\nphba->pport->port_state, psli->sli_flag);\r\nhba_aer_enabled = phba->hba_flag & HBA_AER_ENABLED;\r\nrc = lpfc_sli4_brdreset(phba);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->pport->stopped = 0;\r\nphba->link_state = LPFC_INIT_START;\r\nphba->hba_flag = 0;\r\nspin_unlock_irq(&phba->hbalock);\r\nmemset(&psli->lnk_stat_offsets, 0, sizeof(psli->lnk_stat_offsets));\r\npsli->stats_start = get_seconds();\r\nif (hba_aer_enabled)\r\npci_disable_pcie_error_reporting(phba->pcidev);\r\nlpfc_hba_down_post(phba);\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli_brdrestart(struct lpfc_hba *phba)\r\n{\r\nreturn phba->lpfc_sli_brdrestart(phba);\r\n}\r\nstatic int\r\nlpfc_sli_chipset_init(struct lpfc_hba *phba)\r\n{\r\nuint32_t status, i = 0;\r\nif (lpfc_readl(phba->HSregaddr, &status))\r\nreturn -EIO;\r\ni = 0;\r\nwhile ((status & (HS_FFRDY | HS_MBRDY)) != (HS_FFRDY | HS_MBRDY)) {\r\nif (i++ >= 200) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0436 Adapter failed to init, "\r\n"timeout, status reg x%x, "\r\n"FW Data: A8 x%x AC x%x\n", status,\r\nreadl(phba->MBslimaddr + 0xa8),\r\nreadl(phba->MBslimaddr + 0xac));\r\nphba->link_state = LPFC_HBA_ERROR;\r\nreturn -ETIMEDOUT;\r\n}\r\nif (status & HS_FFERM) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0437 Adapter failed to init, "\r\n"chipset, status reg x%x, "\r\n"FW Data: A8 x%x AC x%x\n", status,\r\nreadl(phba->MBslimaddr + 0xa8),\r\nreadl(phba->MBslimaddr + 0xac));\r\nphba->link_state = LPFC_HBA_ERROR;\r\nreturn -EIO;\r\n}\r\nif (i <= 10)\r\nmsleep(10);\r\nelse if (i <= 100)\r\nmsleep(100);\r\nelse\r\nmsleep(1000);\r\nif (i == 150) {\r\nphba->pport->port_state = LPFC_VPORT_UNKNOWN;\r\nlpfc_sli_brdrestart(phba);\r\n}\r\nif (lpfc_readl(phba->HSregaddr, &status))\r\nreturn -EIO;\r\n}\r\nif (status & HS_FFERM) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0438 Adapter failed to init, chipset, "\r\n"status reg x%x, "\r\n"FW Data: A8 x%x AC x%x\n", status,\r\nreadl(phba->MBslimaddr + 0xa8),\r\nreadl(phba->MBslimaddr + 0xac));\r\nphba->link_state = LPFC_HBA_ERROR;\r\nreturn -EIO;\r\n}\r\nwritel(0, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\nwritel(0xffffffff, phba->HAregaddr);\r\nreadl(phba->HAregaddr);\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli_hbq_count(void)\r\n{\r\nreturn ARRAY_SIZE(lpfc_hbq_defs);\r\n}\r\nstatic int\r\nlpfc_sli_hbq_entry_count(void)\r\n{\r\nint hbq_count = lpfc_sli_hbq_count();\r\nint count = 0;\r\nint i;\r\nfor (i = 0; i < hbq_count; ++i)\r\ncount += lpfc_hbq_defs[i]->entry_count;\r\nreturn count;\r\n}\r\nint\r\nlpfc_sli_hbq_size(void)\r\n{\r\nreturn lpfc_sli_hbq_entry_count() * sizeof(struct lpfc_hbq_entry);\r\n}\r\nstatic int\r\nlpfc_sli_hbq_setup(struct lpfc_hba *phba)\r\n{\r\nint hbq_count = lpfc_sli_hbq_count();\r\nLPFC_MBOXQ_t *pmb;\r\nMAILBOX_t *pmbox;\r\nuint32_t hbqno;\r\nuint32_t hbq_entry_index;\r\npmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!pmb)\r\nreturn -ENOMEM;\r\npmbox = &pmb->u.mb;\r\nphba->link_state = LPFC_INIT_MBX_CMDS;\r\nphba->hbq_in_use = 1;\r\nhbq_entry_index = 0;\r\nfor (hbqno = 0; hbqno < hbq_count; ++hbqno) {\r\nphba->hbqs[hbqno].next_hbqPutIdx = 0;\r\nphba->hbqs[hbqno].hbqPutIdx = 0;\r\nphba->hbqs[hbqno].local_hbqGetIdx = 0;\r\nphba->hbqs[hbqno].entry_count =\r\nlpfc_hbq_defs[hbqno]->entry_count;\r\nlpfc_config_hbq(phba, hbqno, lpfc_hbq_defs[hbqno],\r\nhbq_entry_index, pmb);\r\nhbq_entry_index += phba->hbqs[hbqno].entry_count;\r\nif (lpfc_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_ERR,\r\nLOG_SLI | LOG_VPORT,\r\n"1805 Adapter failed to init. "\r\n"Data: x%x x%x x%x\n",\r\npmbox->mbxCommand,\r\npmbox->mbxStatus, hbqno);\r\nphba->link_state = LPFC_HBA_ERROR;\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn -ENXIO;\r\n}\r\n}\r\nphba->hbq_count = hbq_count;\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nfor (hbqno = 0; hbqno < hbq_count; ++hbqno)\r\nlpfc_sli_hbqbuf_init_hbqs(phba, hbqno);\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_sli4_rb_setup(struct lpfc_hba *phba)\r\n{\r\nphba->hbq_in_use = 1;\r\nphba->hbqs[0].entry_count = lpfc_hbq_defs[0]->entry_count;\r\nphba->hbq_count = 1;\r\nlpfc_sli_hbqbuf_init_hbqs(phba, 0);\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli_config_port(struct lpfc_hba *phba, int sli_mode)\r\n{\r\nLPFC_MBOXQ_t *pmb;\r\nuint32_t resetcount = 0, rc = 0, done = 0;\r\npmb = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!pmb) {\r\nphba->link_state = LPFC_HBA_ERROR;\r\nreturn -ENOMEM;\r\n}\r\nphba->sli_rev = sli_mode;\r\nwhile (resetcount < 2 && !done) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli.sli_flag |= LPFC_SLI_MBOX_ACTIVE;\r\nspin_unlock_irq(&phba->hbalock);\r\nphba->pport->port_state = LPFC_VPORT_UNKNOWN;\r\nlpfc_sli_brdrestart(phba);\r\nrc = lpfc_sli_chipset_init(phba);\r\nif (rc)\r\nbreak;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nspin_unlock_irq(&phba->hbalock);\r\nresetcount++;\r\nrc = lpfc_config_port_prep(phba);\r\nif (rc == -ERESTART) {\r\nphba->link_state = LPFC_LINK_UNKNOWN;\r\ncontinue;\r\n} else if (rc)\r\nbreak;\r\nphba->link_state = LPFC_INIT_MBX_CMDS;\r\nlpfc_config_port(phba, pmb);\r\nrc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\r\nphba->sli3_options &= ~(LPFC_SLI3_NPIV_ENABLED |\r\nLPFC_SLI3_HBQ_ENABLED |\r\nLPFC_SLI3_CRP_ENABLED |\r\nLPFC_SLI3_BG_ENABLED |\r\nLPFC_SLI3_DSS_ENABLED);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0442 Adapter failed to init, mbxCmd x%x "\r\n"CONFIG_PORT, mbxStatus x%x Data: x%x\n",\r\npmb->u.mb.mbxCommand, pmb->u.mb.mbxStatus, 0);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli.sli_flag &= ~LPFC_SLI_ACTIVE;\r\nspin_unlock_irq(&phba->hbalock);\r\nrc = -ENXIO;\r\n} else {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli.sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\r\nspin_unlock_irq(&phba->hbalock);\r\ndone = 1;\r\nif ((pmb->u.mb.un.varCfgPort.casabt == 1) &&\r\n(pmb->u.mb.un.varCfgPort.gasabt == 0))\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\r\n"3110 Port did not grant ASABT\n");\r\n}\r\n}\r\nif (!done) {\r\nrc = -EINVAL;\r\ngoto do_prep_failed;\r\n}\r\nif (pmb->u.mb.un.varCfgPort.sli_mode == 3) {\r\nif (!pmb->u.mb.un.varCfgPort.cMA) {\r\nrc = -ENXIO;\r\ngoto do_prep_failed;\r\n}\r\nif (phba->max_vpi && pmb->u.mb.un.varCfgPort.gmv) {\r\nphba->sli3_options |= LPFC_SLI3_NPIV_ENABLED;\r\nphba->max_vpi = pmb->u.mb.un.varCfgPort.max_vpi;\r\nphba->max_vports = (phba->max_vpi > phba->max_vports) ?\r\nphba->max_vpi : phba->max_vports;\r\n} else\r\nphba->max_vpi = 0;\r\nphba->fips_level = 0;\r\nphba->fips_spec_rev = 0;\r\nif (pmb->u.mb.un.varCfgPort.gdss) {\r\nphba->sli3_options |= LPFC_SLI3_DSS_ENABLED;\r\nphba->fips_level = pmb->u.mb.un.varCfgPort.fips_level;\r\nphba->fips_spec_rev = pmb->u.mb.un.varCfgPort.fips_rev;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"2850 Security Crypto Active. FIPS x%d "\r\n"(Spec Rev: x%d)",\r\nphba->fips_level, phba->fips_spec_rev);\r\n}\r\nif (pmb->u.mb.un.varCfgPort.sec_err) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2856 Config Port Security Crypto "\r\n"Error: x%x ",\r\npmb->u.mb.un.varCfgPort.sec_err);\r\n}\r\nif (pmb->u.mb.un.varCfgPort.gerbm)\r\nphba->sli3_options |= LPFC_SLI3_HBQ_ENABLED;\r\nif (pmb->u.mb.un.varCfgPort.gcrp)\r\nphba->sli3_options |= LPFC_SLI3_CRP_ENABLED;\r\nphba->hbq_get = phba->mbox->us.s3_pgp.hbq_get;\r\nphba->port_gp = phba->mbox->us.s3_pgp.port;\r\nif (phba->cfg_enable_bg) {\r\nif (pmb->u.mb.un.varCfgPort.gbg)\r\nphba->sli3_options |= LPFC_SLI3_BG_ENABLED;\r\nelse\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0443 Adapter did not grant "\r\n"BlockGuard\n");\r\n}\r\n} else {\r\nphba->hbq_get = NULL;\r\nphba->port_gp = phba->mbox->us.s2.port;\r\nphba->max_vpi = 0;\r\n}\r\ndo_prep_failed:\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli_hba_setup(struct lpfc_hba *phba)\r\n{\r\nuint32_t rc;\r\nint mode = 3, i;\r\nint longs;\r\nswitch (lpfc_sli_mode) {\r\ncase 2:\r\nif (phba->cfg_enable_npiv) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_VPORT,\r\n"1824 NPIV enabled: Override lpfc_sli_mode "\r\n"parameter (%d) to auto (0).\n",\r\nlpfc_sli_mode);\r\nbreak;\r\n}\r\nmode = 2;\r\nbreak;\r\ncase 0:\r\ncase 3:\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_VPORT,\r\n"1819 Unrecognized lpfc_sli_mode "\r\n"parameter: %d.\n", lpfc_sli_mode);\r\nbreak;\r\n}\r\nrc = lpfc_sli_config_port(phba, mode);\r\nif (rc && lpfc_sli_mode == 3)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_VPORT,\r\n"1820 Unable to select SLI-3. "\r\n"Not supported by adapter.\n");\r\nif (rc && mode != 2)\r\nrc = lpfc_sli_config_port(phba, 2);\r\nif (rc)\r\ngoto lpfc_sli_hba_setup_error;\r\nif (phba->cfg_aer_support == 1 && !(phba->hba_flag & HBA_AER_ENABLED)) {\r\nrc = pci_enable_pcie_error_reporting(phba->pcidev);\r\nif (!rc) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"2709 This device supports "\r\n"Advanced Error Reporting (AER)\n");\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag |= HBA_AER_ENABLED;\r\nspin_unlock_irq(&phba->hbalock);\r\n} else {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"2708 This device does not support "\r\n"Advanced Error Reporting (AER): %d\n",\r\nrc);\r\nphba->cfg_aer_support = 0;\r\n}\r\n}\r\nif (phba->sli_rev == 3) {\r\nphba->iocb_cmd_size = SLI3_IOCB_CMD_SIZE;\r\nphba->iocb_rsp_size = SLI3_IOCB_RSP_SIZE;\r\n} else {\r\nphba->iocb_cmd_size = SLI2_IOCB_CMD_SIZE;\r\nphba->iocb_rsp_size = SLI2_IOCB_RSP_SIZE;\r\nphba->sli3_options = 0;\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"0444 Firmware in SLI %x mode. Max_vpi %d\n",\r\nphba->sli_rev, phba->max_vpi);\r\nrc = lpfc_sli_ring_map(phba);\r\nif (rc)\r\ngoto lpfc_sli_hba_setup_error;\r\nif (phba->sli_rev == LPFC_SLI_REV3) {\r\nif ((phba->vpi_bmask == NULL) && (phba->vpi_ids == NULL)) {\r\nlongs = (phba->max_vpi + BITS_PER_LONG) / BITS_PER_LONG;\r\nphba->vpi_bmask = kzalloc(longs * sizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (!phba->vpi_bmask) {\r\nrc = -ENOMEM;\r\ngoto lpfc_sli_hba_setup_error;\r\n}\r\nphba->vpi_ids = kzalloc(\r\n(phba->max_vpi+1) * sizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (!phba->vpi_ids) {\r\nkfree(phba->vpi_bmask);\r\nrc = -ENOMEM;\r\ngoto lpfc_sli_hba_setup_error;\r\n}\r\nfor (i = 0; i < phba->max_vpi; i++)\r\nphba->vpi_ids[i] = i;\r\n}\r\n}\r\nif (phba->sli3_options & LPFC_SLI3_HBQ_ENABLED) {\r\nrc = lpfc_sli_hbq_setup(phba);\r\nif (rc)\r\ngoto lpfc_sli_hba_setup_error;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli.sli_flag |= LPFC_PROCESS_LA;\r\nspin_unlock_irq(&phba->hbalock);\r\nrc = lpfc_config_port_post(phba);\r\nif (rc)\r\ngoto lpfc_sli_hba_setup_error;\r\nreturn rc;\r\nlpfc_sli_hba_setup_error:\r\nphba->link_state = LPFC_HBA_ERROR;\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0445 Firmware initialization failed\n");\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli4_read_fcoe_params(struct lpfc_hba *phba)\r\n{\r\nLPFC_MBOXQ_t *mboxq;\r\nstruct lpfc_dmabuf *mp;\r\nstruct lpfc_mqe *mqe;\r\nuint32_t data_length;\r\nint rc;\r\nphba->valid_vlan = 0;\r\nphba->fc_map[0] = LPFC_FCOE_FCF_MAP0;\r\nphba->fc_map[1] = LPFC_FCOE_FCF_MAP1;\r\nphba->fc_map[2] = LPFC_FCOE_FCF_MAP2;\r\nmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq)\r\nreturn -ENOMEM;\r\nmqe = &mboxq->u.mqe;\r\nif (lpfc_sli4_dump_cfg_rg23(phba, mboxq)) {\r\nrc = -ENOMEM;\r\ngoto out_free_mboxq;\r\n}\r\nmp = (struct lpfc_dmabuf *) mboxq->context1;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):2571 Mailbox cmd x%x Status x%x "\r\n"Data: x%x x%x x%x x%x x%x x%x x%x x%x x%x "\r\n"x%x x%x x%x x%x x%x x%x x%x x%x x%x "\r\n"CQ: x%x x%x x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nbf_get(lpfc_mqe_command, mqe),\r\nbf_get(lpfc_mqe_status, mqe),\r\nmqe->un.mb_words[0], mqe->un.mb_words[1],\r\nmqe->un.mb_words[2], mqe->un.mb_words[3],\r\nmqe->un.mb_words[4], mqe->un.mb_words[5],\r\nmqe->un.mb_words[6], mqe->un.mb_words[7],\r\nmqe->un.mb_words[8], mqe->un.mb_words[9],\r\nmqe->un.mb_words[10], mqe->un.mb_words[11],\r\nmqe->un.mb_words[12], mqe->un.mb_words[13],\r\nmqe->un.mb_words[14], mqe->un.mb_words[15],\r\nmqe->un.mb_words[16], mqe->un.mb_words[50],\r\nmboxq->mcqe.word0,\r\nmboxq->mcqe.mcqe_tag0, mboxq->mcqe.mcqe_tag1,\r\nmboxq->mcqe.trailer);\r\nif (rc) {\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nrc = -EIO;\r\ngoto out_free_mboxq;\r\n}\r\ndata_length = mqe->un.mb_words[5];\r\nif (data_length > DMP_RGN23_SIZE) {\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nrc = -EIO;\r\ngoto out_free_mboxq;\r\n}\r\nlpfc_parse_fcoe_conf(phba, mp->virt, data_length);\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nrc = 0;\r\nout_free_mboxq:\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli4_read_rev(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq,\r\nuint8_t *vpd, uint32_t *vpd_size)\r\n{\r\nint rc = 0;\r\nuint32_t dma_size;\r\nstruct lpfc_dmabuf *dmabuf;\r\nstruct lpfc_mqe *mqe;\r\ndmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\r\nif (!dmabuf)\r\nreturn -ENOMEM;\r\ndma_size = *vpd_size;\r\ndmabuf->virt = dma_zalloc_coherent(&phba->pcidev->dev, dma_size,\r\n&dmabuf->phys, GFP_KERNEL);\r\nif (!dmabuf->virt) {\r\nkfree(dmabuf);\r\nreturn -ENOMEM;\r\n}\r\nlpfc_read_rev(phba, mboxq);\r\nmqe = &mboxq->u.mqe;\r\nmqe->un.read_rev.vpd_paddr_high = putPaddrHigh(dmabuf->phys);\r\nmqe->un.read_rev.vpd_paddr_low = putPaddrLow(dmabuf->phys);\r\nmqe->un.read_rev.word1 &= 0x0000FFFF;\r\nbf_set(lpfc_mbx_rd_rev_vpd, &mqe->un.read_rev, 1);\r\nbf_set(lpfc_mbx_rd_rev_avail_len, &mqe->un.read_rev, dma_size);\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nif (rc) {\r\ndma_free_coherent(&phba->pcidev->dev, dma_size,\r\ndmabuf->virt, dmabuf->phys);\r\nkfree(dmabuf);\r\nreturn -EIO;\r\n}\r\nif (mqe->un.read_rev.avail_vpd_len < *vpd_size)\r\n*vpd_size = mqe->un.read_rev.avail_vpd_len;\r\nmemcpy(vpd, dmabuf->virt, *vpd_size);\r\ndma_free_coherent(&phba->pcidev->dev, dma_size,\r\ndmabuf->virt, dmabuf->phys);\r\nkfree(dmabuf);\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_sli4_retrieve_pport_name(struct lpfc_hba *phba)\r\n{\r\nLPFC_MBOXQ_t *mboxq;\r\nstruct lpfc_mbx_get_cntl_attributes *mbx_cntl_attr;\r\nstruct lpfc_controller_attribute *cntl_attr;\r\nstruct lpfc_mbx_get_port_name *get_port_name;\r\nvoid *virtaddr = NULL;\r\nuint32_t alloclen, reqlen;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nchar cport_name = 0;\r\nint rc;\r\nphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_INVAL;\r\nphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_NON;\r\nmboxq = (LPFC_MBOXQ_t *)mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq)\r\nreturn -ENOMEM;\r\nphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_INVAL;\r\nlpfc_sli4_read_config(phba);\r\nif (phba->sli4_hba.lnk_info.lnk_dv == LPFC_LNK_DAT_VAL)\r\ngoto retrieve_ppname;\r\nreqlen = sizeof(struct lpfc_mbx_get_cntl_attributes);\r\nalloclen = lpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_GET_CNTL_ATTRIBUTES, reqlen,\r\nLPFC_SLI4_MBX_NEMBED);\r\nif (alloclen < reqlen) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"3084 Allocated DMA memory size (%d) is "\r\n"less than the requested DMA memory size "\r\n"(%d)\n", alloclen, reqlen);\r\nrc = -ENOMEM;\r\ngoto out_free_mboxq;\r\n}\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nvirtaddr = mboxq->sge_array->addr[0];\r\nmbx_cntl_attr = (struct lpfc_mbx_get_cntl_attributes *)virtaddr;\r\nshdr = &mbx_cntl_attr->cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"3085 Mailbox x%x (x%x/x%x) failed, "\r\n"rc:x%x, status:x%x, add_status:x%x\n",\r\nbf_get(lpfc_mqe_command, &mboxq->u.mqe),\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\nrc, shdr_status, shdr_add_status);\r\nrc = -ENXIO;\r\ngoto out_free_mboxq;\r\n}\r\ncntl_attr = &mbx_cntl_attr->cntl_attr;\r\nphba->sli4_hba.lnk_info.lnk_dv = LPFC_LNK_DAT_VAL;\r\nphba->sli4_hba.lnk_info.lnk_tp =\r\nbf_get(lpfc_cntl_attr_lnk_type, cntl_attr);\r\nphba->sli4_hba.lnk_info.lnk_no =\r\nbf_get(lpfc_cntl_attr_lnk_numb, cntl_attr);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"3086 lnk_type:%d, lnk_numb:%d\n",\r\nphba->sli4_hba.lnk_info.lnk_tp,\r\nphba->sli4_hba.lnk_info.lnk_no);\r\nretrieve_ppname:\r\nlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_GET_PORT_NAME,\r\nsizeof(struct lpfc_mbx_get_port_name) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr),\r\nLPFC_SLI4_MBX_EMBED);\r\nget_port_name = &mboxq->u.mqe.un.get_port_name;\r\nshdr = (union lpfc_sli4_cfg_shdr *)&get_port_name->header.cfg_shdr;\r\nbf_set(lpfc_mbox_hdr_version, &shdr->request, LPFC_OPCODE_VERSION_1);\r\nbf_set(lpfc_mbx_get_port_name_lnk_type, &get_port_name->u.request,\r\nphba->sli4_hba.lnk_info.lnk_tp);\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"3087 Mailbox x%x (x%x/x%x) failed: "\r\n"rc:x%x, status:x%x, add_status:x%x\n",\r\nbf_get(lpfc_mqe_command, &mboxq->u.mqe),\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\nrc, shdr_status, shdr_add_status);\r\nrc = -ENXIO;\r\ngoto out_free_mboxq;\r\n}\r\nswitch (phba->sli4_hba.lnk_info.lnk_no) {\r\ncase LPFC_LINK_NUMBER_0:\r\ncport_name = bf_get(lpfc_mbx_get_port_name_name0,\r\n&get_port_name->u.response);\r\nphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\r\nbreak;\r\ncase LPFC_LINK_NUMBER_1:\r\ncport_name = bf_get(lpfc_mbx_get_port_name_name1,\r\n&get_port_name->u.response);\r\nphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\r\nbreak;\r\ncase LPFC_LINK_NUMBER_2:\r\ncport_name = bf_get(lpfc_mbx_get_port_name_name2,\r\n&get_port_name->u.response);\r\nphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\r\nbreak;\r\ncase LPFC_LINK_NUMBER_3:\r\ncport_name = bf_get(lpfc_mbx_get_port_name_name3,\r\n&get_port_name->u.response);\r\nphba->sli4_hba.pport_name_sta = LPFC_SLI4_PPNAME_GET;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (phba->sli4_hba.pport_name_sta == LPFC_SLI4_PPNAME_GET) {\r\nphba->Port[0] = cport_name;\r\nphba->Port[1] = '\0';\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"3091 SLI get port name: %s\n", phba->Port);\r\n}\r\nout_free_mboxq:\r\nif (rc != MBX_TIMEOUT) {\r\nif (bf_get(lpfc_mqe_command, &mboxq->u.mqe) == MBX_SLI4_CONFIG)\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nelse\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\n}\r\nreturn rc;\r\n}\r\nstatic void\r\nlpfc_sli4_arm_cqeq_intr(struct lpfc_hba *phba)\r\n{\r\nint fcp_eqidx;\r\nlpfc_sli4_cq_release(phba->sli4_hba.mbx_cq, LPFC_QUEUE_REARM);\r\nlpfc_sli4_cq_release(phba->sli4_hba.els_cq, LPFC_QUEUE_REARM);\r\nfcp_eqidx = 0;\r\nif (phba->sli4_hba.fcp_cq) {\r\ndo {\r\nlpfc_sli4_cq_release(phba->sli4_hba.fcp_cq[fcp_eqidx],\r\nLPFC_QUEUE_REARM);\r\n} while (++fcp_eqidx < phba->cfg_fcp_io_channel);\r\n}\r\nif (phba->cfg_fof)\r\nlpfc_sli4_cq_release(phba->sli4_hba.oas_cq, LPFC_QUEUE_REARM);\r\nif (phba->sli4_hba.hba_eq) {\r\nfor (fcp_eqidx = 0; fcp_eqidx < phba->cfg_fcp_io_channel;\r\nfcp_eqidx++)\r\nlpfc_sli4_eq_release(phba->sli4_hba.hba_eq[fcp_eqidx],\r\nLPFC_QUEUE_REARM);\r\n}\r\nif (phba->cfg_fof)\r\nlpfc_sli4_eq_release(phba->sli4_hba.fof_eq, LPFC_QUEUE_REARM);\r\n}\r\nint\r\nlpfc_sli4_get_avail_extnt_rsrc(struct lpfc_hba *phba, uint16_t type,\r\nuint16_t *extnt_count, uint16_t *extnt_size)\r\n{\r\nint rc = 0;\r\nuint32_t length;\r\nuint32_t mbox_tmo;\r\nstruct lpfc_mbx_get_rsrc_extent_info *rsrc_info;\r\nLPFC_MBOXQ_t *mbox;\r\nmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_get_rsrc_extent_info) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_GET_RSRC_EXTENT_INFO,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nrc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, 0, type,\r\nLPFC_SLI4_MBX_EMBED);\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto err_exit;\r\n}\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto err_exit;\r\n}\r\nrsrc_info = &mbox->u.mqe.un.rsrc_extent_info;\r\nif (bf_get(lpfc_mbox_hdr_status,\r\n&rsrc_info->header.cfg_shdr.response)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_INIT,\r\n"2930 Failed to get resource extents "\r\n"Status 0x%x Add'l Status 0x%x\n",\r\nbf_get(lpfc_mbox_hdr_status,\r\n&rsrc_info->header.cfg_shdr.response),\r\nbf_get(lpfc_mbox_hdr_add_status,\r\n&rsrc_info->header.cfg_shdr.response));\r\nrc = -EIO;\r\ngoto err_exit;\r\n}\r\n*extnt_count = bf_get(lpfc_mbx_get_rsrc_extent_info_cnt,\r\n&rsrc_info->u.rsp);\r\n*extnt_size = bf_get(lpfc_mbx_get_rsrc_extent_info_size,\r\n&rsrc_info->u.rsp);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"3162 Retrieved extents type-%d from port: count:%d, "\r\n"size:%d\n", type, *extnt_count, *extnt_size);\r\nerr_exit:\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli4_chk_avail_extnt_rsrc(struct lpfc_hba *phba, uint16_t type)\r\n{\r\nuint16_t curr_ext_cnt, rsrc_ext_cnt;\r\nuint16_t size_diff, rsrc_ext_size;\r\nint rc = 0;\r\nstruct lpfc_rsrc_blks *rsrc_entry;\r\nstruct list_head *rsrc_blk_list = NULL;\r\nsize_diff = 0;\r\ncurr_ext_cnt = 0;\r\nrc = lpfc_sli4_get_avail_extnt_rsrc(phba, type,\r\n&rsrc_ext_cnt,\r\n&rsrc_ext_size);\r\nif (unlikely(rc))\r\nreturn -EIO;\r\nswitch (type) {\r\ncase LPFC_RSC_TYPE_FCOE_RPI:\r\nrsrc_blk_list = &phba->sli4_hba.lpfc_rpi_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_VPI:\r\nrsrc_blk_list = &phba->lpfc_vpi_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_XRI:\r\nrsrc_blk_list = &phba->sli4_hba.lpfc_xri_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_VFI:\r\nrsrc_blk_list = &phba->sli4_hba.lpfc_vfi_blk_list;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nlist_for_each_entry(rsrc_entry, rsrc_blk_list, list) {\r\ncurr_ext_cnt++;\r\nif (rsrc_entry->rsrc_size != rsrc_ext_size)\r\nsize_diff++;\r\n}\r\nif (curr_ext_cnt != rsrc_ext_cnt || size_diff != 0)\r\nrc = 1;\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli4_cfg_post_extnts(struct lpfc_hba *phba, uint16_t extnt_cnt,\r\nuint16_t type, bool *emb, LPFC_MBOXQ_t *mbox)\r\n{\r\nint rc = 0;\r\nuint32_t req_len;\r\nuint32_t emb_len;\r\nuint32_t alloc_len, mbox_tmo;\r\nreq_len = extnt_cnt * sizeof(uint16_t);\r\nemb_len = sizeof(MAILBOX_t) - sizeof(struct mbox_header) -\r\nsizeof(uint32_t);\r\n*emb = LPFC_SLI4_MBX_EMBED;\r\nif (req_len > emb_len) {\r\nreq_len = extnt_cnt * sizeof(uint16_t) +\r\nsizeof(union lpfc_sli4_cfg_shdr) +\r\nsizeof(uint32_t);\r\n*emb = LPFC_SLI4_MBX_NEMBED;\r\n}\r\nalloc_len = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_ALLOC_RSRC_EXTENT,\r\nreq_len, *emb);\r\nif (alloc_len < req_len) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2982 Allocated DMA memory size (x%x) is "\r\n"less than the requested DMA memory "\r\n"size (x%x)\n", alloc_len, req_len);\r\nreturn -ENOMEM;\r\n}\r\nrc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, extnt_cnt, type, *emb);\r\nif (unlikely(rc))\r\nreturn -EIO;\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nif (unlikely(rc))\r\nrc = -EIO;\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli4_alloc_extent(struct lpfc_hba *phba, uint16_t type)\r\n{\r\nbool emb = false;\r\nuint16_t rsrc_id_cnt, rsrc_cnt, rsrc_size;\r\nuint16_t rsrc_id, rsrc_start, j, k;\r\nuint16_t *ids;\r\nint i, rc;\r\nunsigned long longs;\r\nunsigned long *bmask;\r\nstruct lpfc_rsrc_blks *rsrc_blks;\r\nLPFC_MBOXQ_t *mbox;\r\nuint32_t length;\r\nstruct lpfc_id_range *id_array = NULL;\r\nvoid *virtaddr = NULL;\r\nstruct lpfc_mbx_nembed_rsrc_extent *n_rsrc;\r\nstruct lpfc_mbx_alloc_rsrc_extents *rsrc_ext;\r\nstruct list_head *ext_blk_list;\r\nrc = lpfc_sli4_get_avail_extnt_rsrc(phba, type,\r\n&rsrc_cnt,\r\n&rsrc_size);\r\nif (unlikely(rc))\r\nreturn -EIO;\r\nif ((rsrc_cnt == 0) || (rsrc_size == 0)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_INIT,\r\n"3009 No available Resource Extents "\r\n"for resource type 0x%x: Count: 0x%x, "\r\n"Size 0x%x\n", type, rsrc_cnt,\r\nrsrc_size);\r\nreturn -ENOMEM;\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_INIT | LOG_SLI,\r\n"2903 Post resource extents type-0x%x: "\r\n"count:%d, size %d\n", type, rsrc_cnt, rsrc_size);\r\nmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nrc = lpfc_sli4_cfg_post_extnts(phba, rsrc_cnt, type, &emb, mbox);\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto err_exit;\r\n}\r\nif (emb == LPFC_SLI4_MBX_EMBED) {\r\nrsrc_ext = &mbox->u.mqe.un.alloc_rsrc_extents;\r\nid_array = &rsrc_ext->u.rsp.id[0];\r\nrsrc_cnt = bf_get(lpfc_mbx_rsrc_cnt, &rsrc_ext->u.rsp);\r\n} else {\r\nvirtaddr = mbox->sge_array->addr[0];\r\nn_rsrc = (struct lpfc_mbx_nembed_rsrc_extent *) virtaddr;\r\nrsrc_cnt = bf_get(lpfc_mbx_rsrc_cnt, n_rsrc);\r\nid_array = &n_rsrc->id;\r\n}\r\nlongs = ((rsrc_cnt * rsrc_size) + BITS_PER_LONG - 1) / BITS_PER_LONG;\r\nrsrc_id_cnt = rsrc_cnt * rsrc_size;\r\nlength = sizeof(struct lpfc_rsrc_blks);\r\nswitch (type) {\r\ncase LPFC_RSC_TYPE_FCOE_RPI:\r\nphba->sli4_hba.rpi_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.rpi_bmask)) {\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nphba->sli4_hba.rpi_ids = kzalloc(rsrc_id_cnt *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.rpi_ids)) {\r\nkfree(phba->sli4_hba.rpi_bmask);\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nphba->sli4_hba.next_rpi = rsrc_id_cnt;\r\nbmask = phba->sli4_hba.rpi_bmask;\r\nids = phba->sli4_hba.rpi_ids;\r\next_blk_list = &phba->sli4_hba.lpfc_rpi_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_VPI:\r\nphba->vpi_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->vpi_bmask)) {\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nphba->vpi_ids = kzalloc(rsrc_id_cnt *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->vpi_ids)) {\r\nkfree(phba->vpi_bmask);\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nbmask = phba->vpi_bmask;\r\nids = phba->vpi_ids;\r\next_blk_list = &phba->lpfc_vpi_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_XRI:\r\nphba->sli4_hba.xri_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.xri_bmask)) {\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nphba->sli4_hba.max_cfg_param.xri_used = 0;\r\nphba->sli4_hba.xri_ids = kzalloc(rsrc_id_cnt *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.xri_ids)) {\r\nkfree(phba->sli4_hba.xri_bmask);\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nbmask = phba->sli4_hba.xri_bmask;\r\nids = phba->sli4_hba.xri_ids;\r\next_blk_list = &phba->sli4_hba.lpfc_xri_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_VFI:\r\nphba->sli4_hba.vfi_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.vfi_bmask)) {\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nphba->sli4_hba.vfi_ids = kzalloc(rsrc_id_cnt *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.vfi_ids)) {\r\nkfree(phba->sli4_hba.vfi_bmask);\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nbmask = phba->sli4_hba.vfi_bmask;\r\nids = phba->sli4_hba.vfi_ids;\r\next_blk_list = &phba->sli4_hba.lpfc_vfi_blk_list;\r\nbreak;\r\ndefault:\r\nid_array = NULL;\r\nbmask = NULL;\r\nids = NULL;\r\next_blk_list = NULL;\r\ngoto err_exit;\r\n}\r\nfor (i = 0, j = 0, k = 0; i < rsrc_cnt; i++) {\r\nif ((i % 2) == 0)\r\nrsrc_id = bf_get(lpfc_mbx_rsrc_id_word4_0,\r\n&id_array[k]);\r\nelse\r\nrsrc_id = bf_get(lpfc_mbx_rsrc_id_word4_1,\r\n&id_array[k]);\r\nrsrc_blks = kzalloc(length, GFP_KERNEL);\r\nif (unlikely(!rsrc_blks)) {\r\nrc = -ENOMEM;\r\nkfree(bmask);\r\nkfree(ids);\r\ngoto err_exit;\r\n}\r\nrsrc_blks->rsrc_start = rsrc_id;\r\nrsrc_blks->rsrc_size = rsrc_size;\r\nlist_add_tail(&rsrc_blks->list, ext_blk_list);\r\nrsrc_start = rsrc_id;\r\nif ((type == LPFC_RSC_TYPE_FCOE_XRI) && (j == 0))\r\nphba->sli4_hba.scsi_xri_start = rsrc_start +\r\nlpfc_sli4_get_els_iocb_cnt(phba);\r\nwhile (rsrc_id < (rsrc_start + rsrc_size)) {\r\nids[j] = rsrc_id;\r\nrsrc_id++;\r\nj++;\r\n}\r\nif ((i % 2) == 1)\r\nk++;\r\n}\r\nerr_exit:\r\nlpfc_sli4_mbox_cmd_free(phba, mbox);\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli4_dealloc_extent(struct lpfc_hba *phba, uint16_t type)\r\n{\r\nint rc;\r\nuint32_t length, mbox_tmo = 0;\r\nLPFC_MBOXQ_t *mbox;\r\nstruct lpfc_mbx_dealloc_rsrc_extents *dealloc_rsrc;\r\nstruct lpfc_rsrc_blks *rsrc_blk, *rsrc_blk_next;\r\nmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_dealloc_rsrc_extents) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_DEALLOC_RSRC_EXTENT,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nrc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, 0, type,\r\nLPFC_SLI4_MBX_EMBED);\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto out_free_mbox;\r\n}\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto out_free_mbox;\r\n}\r\ndealloc_rsrc = &mbox->u.mqe.un.dealloc_rsrc_extents;\r\nif (bf_get(lpfc_mbox_hdr_status,\r\n&dealloc_rsrc->header.cfg_shdr.response)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_INIT,\r\n"2919 Failed to release resource extents "\r\n"for type %d - Status 0x%x Add'l Status 0x%x. "\r\n"Resource memory not released.\n",\r\ntype,\r\nbf_get(lpfc_mbox_hdr_status,\r\n&dealloc_rsrc->header.cfg_shdr.response),\r\nbf_get(lpfc_mbox_hdr_add_status,\r\n&dealloc_rsrc->header.cfg_shdr.response));\r\nrc = -EIO;\r\ngoto out_free_mbox;\r\n}\r\nswitch (type) {\r\ncase LPFC_RSC_TYPE_FCOE_VPI:\r\nkfree(phba->vpi_bmask);\r\nkfree(phba->vpi_ids);\r\nbf_set(lpfc_vpi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\r\nlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\r\n&phba->lpfc_vpi_blk_list, list) {\r\nlist_del_init(&rsrc_blk->list);\r\nkfree(rsrc_blk);\r\n}\r\nphba->sli4_hba.max_cfg_param.vpi_used = 0;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_XRI:\r\nkfree(phba->sli4_hba.xri_bmask);\r\nkfree(phba->sli4_hba.xri_ids);\r\nlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\r\n&phba->sli4_hba.lpfc_xri_blk_list, list) {\r\nlist_del_init(&rsrc_blk->list);\r\nkfree(rsrc_blk);\r\n}\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_VFI:\r\nkfree(phba->sli4_hba.vfi_bmask);\r\nkfree(phba->sli4_hba.vfi_ids);\r\nbf_set(lpfc_vfi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\r\nlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\r\n&phba->sli4_hba.lpfc_vfi_blk_list, list) {\r\nlist_del_init(&rsrc_blk->list);\r\nkfree(rsrc_blk);\r\n}\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_RPI:\r\nlist_for_each_entry_safe(rsrc_blk, rsrc_blk_next,\r\n&phba->sli4_hba.lpfc_rpi_blk_list, list) {\r\nlist_del_init(&rsrc_blk->list);\r\nkfree(rsrc_blk);\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\r\nout_free_mbox:\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli4_alloc_resource_identifiers(struct lpfc_hba *phba)\r\n{\r\nint i, rc, error = 0;\r\nuint16_t count, base;\r\nunsigned long longs;\r\nif (!phba->sli4_hba.rpi_hdrs_in_use)\r\nphba->sli4_hba.next_rpi = phba->sli4_hba.max_cfg_param.max_rpi;\r\nif (phba->sli4_hba.extents_in_use) {\r\nif (bf_get(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags) ==\r\nLPFC_IDX_RSRC_RDY) {\r\nrc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\r\nLPFC_RSC_TYPE_FCOE_VFI);\r\nif (rc != 0)\r\nerror++;\r\nrc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\r\nLPFC_RSC_TYPE_FCOE_VPI);\r\nif (rc != 0)\r\nerror++;\r\nrc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\r\nLPFC_RSC_TYPE_FCOE_XRI);\r\nif (rc != 0)\r\nerror++;\r\nrc = lpfc_sli4_chk_avail_extnt_rsrc(phba,\r\nLPFC_RSC_TYPE_FCOE_RPI);\r\nif (rc != 0)\r\nerror++;\r\nif (error) {\r\nlpfc_printf_log(phba, KERN_INFO,\r\nLOG_MBOX | LOG_INIT,\r\n"2931 Detected extent resource "\r\n"change. Reallocating all "\r\n"extents.\n");\r\nrc = lpfc_sli4_dealloc_extent(phba,\r\nLPFC_RSC_TYPE_FCOE_VFI);\r\nrc = lpfc_sli4_dealloc_extent(phba,\r\nLPFC_RSC_TYPE_FCOE_VPI);\r\nrc = lpfc_sli4_dealloc_extent(phba,\r\nLPFC_RSC_TYPE_FCOE_XRI);\r\nrc = lpfc_sli4_dealloc_extent(phba,\r\nLPFC_RSC_TYPE_FCOE_RPI);\r\n} else\r\nreturn 0;\r\n}\r\nrc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_VFI);\r\nif (unlikely(rc))\r\ngoto err_exit;\r\nrc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_VPI);\r\nif (unlikely(rc))\r\ngoto err_exit;\r\nrc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_RPI);\r\nif (unlikely(rc))\r\ngoto err_exit;\r\nrc = lpfc_sli4_alloc_extent(phba, LPFC_RSC_TYPE_FCOE_XRI);\r\nif (unlikely(rc))\r\ngoto err_exit;\r\nbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags,\r\nLPFC_IDX_RSRC_RDY);\r\nreturn rc;\r\n} else {\r\nif (bf_get(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags) ==\r\nLPFC_IDX_RSRC_RDY) {\r\nlpfc_sli4_dealloc_resource_identifiers(phba);\r\nlpfc_sli4_remove_rpis(phba);\r\n}\r\ncount = phba->sli4_hba.max_cfg_param.max_rpi;\r\nif (count <= 0) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"3279 Invalid provisioning of "\r\n"rpi:%d\n", count);\r\nrc = -EINVAL;\r\ngoto err_exit;\r\n}\r\nbase = phba->sli4_hba.max_cfg_param.rpi_base;\r\nlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\r\nphba->sli4_hba.rpi_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.rpi_bmask)) {\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nphba->sli4_hba.rpi_ids = kzalloc(count *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.rpi_ids)) {\r\nrc = -ENOMEM;\r\ngoto free_rpi_bmask;\r\n}\r\nfor (i = 0; i < count; i++)\r\nphba->sli4_hba.rpi_ids[i] = base + i;\r\ncount = phba->sli4_hba.max_cfg_param.max_vpi;\r\nif (count <= 0) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"3280 Invalid provisioning of "\r\n"vpi:%d\n", count);\r\nrc = -EINVAL;\r\ngoto free_rpi_ids;\r\n}\r\nbase = phba->sli4_hba.max_cfg_param.vpi_base;\r\nlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\r\nphba->vpi_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->vpi_bmask)) {\r\nrc = -ENOMEM;\r\ngoto free_rpi_ids;\r\n}\r\nphba->vpi_ids = kzalloc(count *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->vpi_ids)) {\r\nrc = -ENOMEM;\r\ngoto free_vpi_bmask;\r\n}\r\nfor (i = 0; i < count; i++)\r\nphba->vpi_ids[i] = base + i;\r\ncount = phba->sli4_hba.max_cfg_param.max_xri;\r\nif (count <= 0) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"3281 Invalid provisioning of "\r\n"xri:%d\n", count);\r\nrc = -EINVAL;\r\ngoto free_vpi_ids;\r\n}\r\nbase = phba->sli4_hba.max_cfg_param.xri_base;\r\nlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\r\nphba->sli4_hba.xri_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.xri_bmask)) {\r\nrc = -ENOMEM;\r\ngoto free_vpi_ids;\r\n}\r\nphba->sli4_hba.max_cfg_param.xri_used = 0;\r\nphba->sli4_hba.xri_ids = kzalloc(count *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.xri_ids)) {\r\nrc = -ENOMEM;\r\ngoto free_xri_bmask;\r\n}\r\nfor (i = 0; i < count; i++)\r\nphba->sli4_hba.xri_ids[i] = base + i;\r\ncount = phba->sli4_hba.max_cfg_param.max_vfi;\r\nif (count <= 0) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"3282 Invalid provisioning of "\r\n"vfi:%d\n", count);\r\nrc = -EINVAL;\r\ngoto free_xri_ids;\r\n}\r\nbase = phba->sli4_hba.max_cfg_param.vfi_base;\r\nlongs = (count + BITS_PER_LONG - 1) / BITS_PER_LONG;\r\nphba->sli4_hba.vfi_bmask = kzalloc(longs *\r\nsizeof(unsigned long),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.vfi_bmask)) {\r\nrc = -ENOMEM;\r\ngoto free_xri_ids;\r\n}\r\nphba->sli4_hba.vfi_ids = kzalloc(count *\r\nsizeof(uint16_t),\r\nGFP_KERNEL);\r\nif (unlikely(!phba->sli4_hba.vfi_ids)) {\r\nrc = -ENOMEM;\r\ngoto free_vfi_bmask;\r\n}\r\nfor (i = 0; i < count; i++)\r\nphba->sli4_hba.vfi_ids[i] = base + i;\r\nbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags,\r\nLPFC_IDX_RSRC_RDY);\r\nreturn 0;\r\n}\r\nfree_vfi_bmask:\r\nkfree(phba->sli4_hba.vfi_bmask);\r\nfree_xri_ids:\r\nkfree(phba->sli4_hba.xri_ids);\r\nfree_xri_bmask:\r\nkfree(phba->sli4_hba.xri_bmask);\r\nfree_vpi_ids:\r\nkfree(phba->vpi_ids);\r\nfree_vpi_bmask:\r\nkfree(phba->vpi_bmask);\r\nfree_rpi_ids:\r\nkfree(phba->sli4_hba.rpi_ids);\r\nfree_rpi_bmask:\r\nkfree(phba->sli4_hba.rpi_bmask);\r\nerr_exit:\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli4_dealloc_resource_identifiers(struct lpfc_hba *phba)\r\n{\r\nif (phba->sli4_hba.extents_in_use) {\r\nlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_VPI);\r\nlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_RPI);\r\nlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_XRI);\r\nlpfc_sli4_dealloc_extent(phba, LPFC_RSC_TYPE_FCOE_VFI);\r\n} else {\r\nkfree(phba->vpi_bmask);\r\nphba->sli4_hba.max_cfg_param.vpi_used = 0;\r\nkfree(phba->vpi_ids);\r\nbf_set(lpfc_vpi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\r\nkfree(phba->sli4_hba.xri_bmask);\r\nkfree(phba->sli4_hba.xri_ids);\r\nkfree(phba->sli4_hba.vfi_bmask);\r\nkfree(phba->sli4_hba.vfi_ids);\r\nbf_set(lpfc_vfi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\r\nbf_set(lpfc_idx_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\r\n}\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli4_get_allocated_extnts(struct lpfc_hba *phba, uint16_t type,\r\nuint16_t *extnt_cnt, uint16_t *extnt_size)\r\n{\r\nbool emb;\r\nint rc = 0;\r\nuint16_t curr_blks = 0;\r\nuint32_t req_len, emb_len;\r\nuint32_t alloc_len, mbox_tmo;\r\nstruct list_head *blk_list_head;\r\nstruct lpfc_rsrc_blks *rsrc_blk;\r\nLPFC_MBOXQ_t *mbox;\r\nvoid *virtaddr = NULL;\r\nstruct lpfc_mbx_nembed_rsrc_extent *n_rsrc;\r\nstruct lpfc_mbx_alloc_rsrc_extents *rsrc_ext;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nswitch (type) {\r\ncase LPFC_RSC_TYPE_FCOE_VPI:\r\nblk_list_head = &phba->lpfc_vpi_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_XRI:\r\nblk_list_head = &phba->sli4_hba.lpfc_xri_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_VFI:\r\nblk_list_head = &phba->sli4_hba.lpfc_vfi_blk_list;\r\nbreak;\r\ncase LPFC_RSC_TYPE_FCOE_RPI:\r\nblk_list_head = &phba->sli4_hba.lpfc_rpi_blk_list;\r\nbreak;\r\ndefault:\r\nreturn -EIO;\r\n}\r\nlist_for_each_entry(rsrc_blk, blk_list_head, list) {\r\nif (curr_blks == 0) {\r\n*extnt_size = rsrc_blk->rsrc_size;\r\n}\r\ncurr_blks++;\r\n}\r\nemb_len = sizeof(MAILBOX_t) - sizeof(struct mbox_header) -\r\nsizeof(uint32_t);\r\nemb = LPFC_SLI4_MBX_EMBED;\r\nreq_len = emb_len;\r\nif (req_len > emb_len) {\r\nreq_len = curr_blks * sizeof(uint16_t) +\r\nsizeof(union lpfc_sli4_cfg_shdr) +\r\nsizeof(uint32_t);\r\nemb = LPFC_SLI4_MBX_NEMBED;\r\n}\r\nmbox = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nmemset(mbox, 0, sizeof(LPFC_MBOXQ_t));\r\nalloc_len = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_GET_ALLOC_RSRC_EXTENT,\r\nreq_len, emb);\r\nif (alloc_len < req_len) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2983 Allocated DMA memory size (x%x) is "\r\n"less than the requested DMA memory "\r\n"size (x%x)\n", alloc_len, req_len);\r\nrc = -ENOMEM;\r\ngoto err_exit;\r\n}\r\nrc = lpfc_sli4_mbox_rsrc_extent(phba, mbox, curr_blks, type, emb);\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto err_exit;\r\n}\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto err_exit;\r\n}\r\nif (emb == LPFC_SLI4_MBX_EMBED) {\r\nrsrc_ext = &mbox->u.mqe.un.alloc_rsrc_extents;\r\nshdr = &rsrc_ext->header.cfg_shdr;\r\n*extnt_cnt = bf_get(lpfc_mbx_rsrc_cnt, &rsrc_ext->u.rsp);\r\n} else {\r\nvirtaddr = mbox->sge_array->addr[0];\r\nn_rsrc = (struct lpfc_mbx_nembed_rsrc_extent *) virtaddr;\r\nshdr = &n_rsrc->cfg_shdr;\r\n*extnt_cnt = bf_get(lpfc_mbx_rsrc_cnt, n_rsrc);\r\n}\r\nif (bf_get(lpfc_mbox_hdr_status, &shdr->response)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_INIT,\r\n"2984 Failed to read allocated resources "\r\n"for type %d - Status 0x%x Add'l Status 0x%x.\n",\r\ntype,\r\nbf_get(lpfc_mbox_hdr_status, &shdr->response),\r\nbf_get(lpfc_mbox_hdr_add_status, &shdr->response));\r\nrc = -EIO;\r\ngoto err_exit;\r\n}\r\nerr_exit:\r\nlpfc_sli4_mbox_cmd_free(phba, mbox);\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli4_repost_els_sgl_list(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sglq *sglq_entry = NULL;\r\nstruct lpfc_sglq *sglq_entry_next = NULL;\r\nstruct lpfc_sglq *sglq_entry_first = NULL;\r\nint status, total_cnt, post_cnt = 0, num_posted = 0, block_cnt = 0;\r\nint last_xritag = NO_XRI;\r\nstruct lpfc_sli_ring *pring;\r\nLIST_HEAD(prep_sgl_list);\r\nLIST_HEAD(blck_sgl_list);\r\nLIST_HEAD(allc_sgl_list);\r\nLIST_HEAD(post_sgl_list);\r\nLIST_HEAD(free_sgl_list);\r\npring = &phba->sli.ring[LPFC_ELS_RING];\r\nspin_lock_irq(&phba->hbalock);\r\nspin_lock(&pring->ring_lock);\r\nlist_splice_init(&phba->sli4_hba.lpfc_sgl_list, &allc_sgl_list);\r\nspin_unlock(&pring->ring_lock);\r\nspin_unlock_irq(&phba->hbalock);\r\ntotal_cnt = phba->sli4_hba.els_xri_cnt;\r\nlist_for_each_entry_safe(sglq_entry, sglq_entry_next,\r\n&allc_sgl_list, list) {\r\nlist_del_init(&sglq_entry->list);\r\nblock_cnt++;\r\nif ((last_xritag != NO_XRI) &&\r\n(sglq_entry->sli4_xritag != last_xritag + 1)) {\r\nlist_splice_init(&prep_sgl_list, &blck_sgl_list);\r\npost_cnt = block_cnt - 1;\r\nlist_add_tail(&sglq_entry->list, &prep_sgl_list);\r\nblock_cnt = 1;\r\n} else {\r\nlist_add_tail(&sglq_entry->list, &prep_sgl_list);\r\nif (block_cnt == LPFC_NEMBED_MBOX_SGL_CNT) {\r\nlist_splice_init(&prep_sgl_list,\r\n&blck_sgl_list);\r\npost_cnt = block_cnt;\r\nblock_cnt = 0;\r\n}\r\n}\r\nnum_posted++;\r\nlast_xritag = sglq_entry->sli4_xritag;\r\nif (num_posted == phba->sli4_hba.els_xri_cnt) {\r\nif (post_cnt == 0) {\r\nlist_splice_init(&prep_sgl_list,\r\n&blck_sgl_list);\r\npost_cnt = block_cnt;\r\n} else if (block_cnt == 1) {\r\nstatus = lpfc_sli4_post_sgl(phba,\r\nsglq_entry->phys, 0,\r\nsglq_entry->sli4_xritag);\r\nif (!status) {\r\nlist_add_tail(&sglq_entry->list,\r\n&post_sgl_list);\r\n} else {\r\nlpfc_printf_log(phba, KERN_WARNING,\r\nLOG_SLI,\r\n"3159 Failed to post els "\r\n"sgl, xritag:x%x\n",\r\nsglq_entry->sli4_xritag);\r\nlist_add_tail(&sglq_entry->list,\r\n&free_sgl_list);\r\ntotal_cnt--;\r\n}\r\n}\r\n}\r\nif (post_cnt == 0)\r\ncontinue;\r\nstatus = lpfc_sli4_post_els_sgl_list(phba, &blck_sgl_list,\r\npost_cnt);\r\nif (!status) {\r\nlist_splice_init(&blck_sgl_list, &post_sgl_list);\r\n} else {\r\nsglq_entry_first = list_first_entry(&blck_sgl_list,\r\nstruct lpfc_sglq,\r\nlist);\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"3160 Failed to post els sgl-list, "\r\n"xritag:x%x-x%x\n",\r\nsglq_entry_first->sli4_xritag,\r\n(sglq_entry_first->sli4_xritag +\r\npost_cnt - 1));\r\nlist_splice_init(&blck_sgl_list, &free_sgl_list);\r\ntotal_cnt -= post_cnt;\r\n}\r\nif (block_cnt == 0)\r\nlast_xritag = NO_XRI;\r\npost_cnt = 0;\r\n}\r\nphba->sli4_hba.els_xri_cnt = total_cnt;\r\nlpfc_free_sgl_list(phba, &free_sgl_list);\r\nif (!list_empty(&post_sgl_list)) {\r\nspin_lock_irq(&phba->hbalock);\r\nspin_lock(&pring->ring_lock);\r\nlist_splice_init(&post_sgl_list,\r\n&phba->sli4_hba.lpfc_sgl_list);\r\nspin_unlock(&pring->ring_lock);\r\nspin_unlock_irq(&phba->hbalock);\r\n} else {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"3161 Failure to post els sgl to port.\n");\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli4_hba_setup(struct lpfc_hba *phba)\r\n{\r\nint rc;\r\nLPFC_MBOXQ_t *mboxq;\r\nstruct lpfc_mqe *mqe;\r\nuint8_t *vpd;\r\nuint32_t vpd_size;\r\nuint32_t ftr_rsp = 0;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(phba->pport);\r\nstruct lpfc_vport *vport = phba->pport;\r\nstruct lpfc_dmabuf *mp;\r\nrc = lpfc_pci_function_reset(phba);\r\nif (unlikely(rc))\r\nreturn -ENODEV;\r\nrc = lpfc_sli4_post_status_check(phba);\r\nif (unlikely(rc))\r\nreturn -ENODEV;\r\nelse {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli.sli_flag |= LPFC_SLI_ACTIVE;\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq)\r\nreturn -ENOMEM;\r\nvpd_size = SLI4_PAGE_SIZE;\r\nvpd = kzalloc(vpd_size, GFP_KERNEL);\r\nif (!vpd) {\r\nrc = -ENOMEM;\r\ngoto out_free_mbox;\r\n}\r\nrc = lpfc_sli4_read_rev(phba, mboxq, vpd, &vpd_size);\r\nif (unlikely(rc)) {\r\nkfree(vpd);\r\ngoto out_free_mbox;\r\n}\r\nmqe = &mboxq->u.mqe;\r\nphba->sli_rev = bf_get(lpfc_mbx_rd_rev_sli_lvl, &mqe->un.read_rev);\r\nif (bf_get(lpfc_mbx_rd_rev_fcoe, &mqe->un.read_rev))\r\nphba->hba_flag |= HBA_FCOE_MODE;\r\nelse\r\nphba->hba_flag &= ~HBA_FCOE_MODE;\r\nif (bf_get(lpfc_mbx_rd_rev_cee_ver, &mqe->un.read_rev) ==\r\nLPFC_DCBX_CEE_MODE)\r\nphba->hba_flag |= HBA_FIP_SUPPORT;\r\nelse\r\nphba->hba_flag &= ~HBA_FIP_SUPPORT;\r\nphba->hba_flag &= ~HBA_FCP_IOQ_FLUSH;\r\nif (phba->sli_rev != LPFC_SLI_REV4) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0376 READ_REV Error. SLI Level %d "\r\n"FCoE enabled %d\n",\r\nphba->sli_rev, phba->hba_flag & HBA_FCOE_MODE);\r\nrc = -EIO;\r\nkfree(vpd);\r\ngoto out_free_mbox;\r\n}\r\nif (phba->hba_flag & HBA_FCOE_MODE &&\r\nlpfc_sli4_read_fcoe_params(phba))\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_INIT,\r\n"2570 Failed to read FCoE parameters\n");\r\nrc = lpfc_sli4_retrieve_pport_name(phba);\r\nif (!rc)\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"3080 Successful retrieving SLI4 device "\r\n"physical port name: %s.\n", phba->Port);\r\nrc = lpfc_parse_vpd(phba, vpd, vpd_size);\r\nif (unlikely(!rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0377 Error %d parsing vpd. "\r\n"Using defaults.\n", rc);\r\nrc = 0;\r\n}\r\nkfree(vpd);\r\nphba->vpd.rev.biuRev = mqe->un.read_rev.first_hw_rev;\r\nphba->vpd.rev.smRev = mqe->un.read_rev.second_hw_rev;\r\nphba->vpd.rev.endecRev = mqe->un.read_rev.third_hw_rev;\r\nphba->vpd.rev.fcphHigh = bf_get(lpfc_mbx_rd_rev_fcph_high,\r\n&mqe->un.read_rev);\r\nphba->vpd.rev.fcphLow = bf_get(lpfc_mbx_rd_rev_fcph_low,\r\n&mqe->un.read_rev);\r\nphba->vpd.rev.feaLevelHigh = bf_get(lpfc_mbx_rd_rev_ftr_lvl_high,\r\n&mqe->un.read_rev);\r\nphba->vpd.rev.feaLevelLow = bf_get(lpfc_mbx_rd_rev_ftr_lvl_low,\r\n&mqe->un.read_rev);\r\nphba->vpd.rev.sli1FwRev = mqe->un.read_rev.fw_id_rev;\r\nmemcpy(phba->vpd.rev.sli1FwName, mqe->un.read_rev.fw_name, 16);\r\nphba->vpd.rev.sli2FwRev = mqe->un.read_rev.ulp_fw_id_rev;\r\nmemcpy(phba->vpd.rev.sli2FwName, mqe->un.read_rev.ulp_fw_name, 16);\r\nphba->vpd.rev.opFwRev = mqe->un.read_rev.fw_id_rev;\r\nmemcpy(phba->vpd.rev.opFwName, mqe->un.read_rev.fw_name, 16);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):0380 READ_REV Status x%x "\r\n"fw_rev:%s fcphHi:%x fcphLo:%x flHi:%x flLo:%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nbf_get(lpfc_mqe_status, mqe),\r\nphba->vpd.rev.opFwName,\r\nphba->vpd.rev.fcphHigh, phba->vpd.rev.fcphLow,\r\nphba->vpd.rev.feaLevelHigh, phba->vpd.rev.feaLevelLow);\r\nrc = (phba->sli4_hba.max_cfg_param.max_xri >> 3);\r\nif (phba->pport->cfg_lun_queue_depth > rc) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\r\n"3362 LUN queue depth changed from %d to %d\n",\r\nphba->pport->cfg_lun_queue_depth, rc);\r\nphba->pport->cfg_lun_queue_depth = rc;\r\n}\r\nlpfc_request_features(phba, mboxq);\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nif (unlikely(rc)) {\r\nrc = -EIO;\r\ngoto out_free_mbox;\r\n}\r\nif (!(bf_get(lpfc_mbx_rq_ftr_rsp_fcpi, &mqe->un.req_ftrs))) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\r\n"0378 No support for fcpi mode.\n");\r\nftr_rsp++;\r\n}\r\nif (bf_get(lpfc_mbx_rq_ftr_rsp_perfh, &mqe->un.req_ftrs))\r\nphba->sli3_options |= LPFC_SLI4_PERFH_ENABLED;\r\nelse\r\nphba->sli3_options &= ~LPFC_SLI4_PERFH_ENABLED;\r\nphba->sli3_options &= ~LPFC_SLI3_BG_ENABLED;\r\nif (phba->cfg_enable_bg) {\r\nif (bf_get(lpfc_mbx_rq_ftr_rsp_dif, &mqe->un.req_ftrs))\r\nphba->sli3_options |= LPFC_SLI3_BG_ENABLED;\r\nelse\r\nftr_rsp++;\r\n}\r\nif (phba->max_vpi && phba->cfg_enable_npiv &&\r\n!(bf_get(lpfc_mbx_rq_ftr_rsp_npiv, &mqe->un.req_ftrs)))\r\nftr_rsp++;\r\nif (ftr_rsp) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\r\n"0379 Feature Mismatch Data: x%08x %08x "\r\n"x%x x%x x%x\n", mqe->un.req_ftrs.word2,\r\nmqe->un.req_ftrs.word3, phba->cfg_enable_bg,\r\nphba->cfg_enable_npiv, phba->max_vpi);\r\nif (!(bf_get(lpfc_mbx_rq_ftr_rsp_dif, &mqe->un.req_ftrs)))\r\nphba->cfg_enable_bg = 0;\r\nif (!(bf_get(lpfc_mbx_rq_ftr_rsp_npiv, &mqe->un.req_ftrs)))\r\nphba->cfg_enable_npiv = 0;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli3_options |= (LPFC_SLI3_NPIV_ENABLED | LPFC_SLI3_HBQ_ENABLED);\r\nspin_unlock_irq(&phba->hbalock);\r\nrc = lpfc_sli4_alloc_resource_identifiers(phba);\r\nif (rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"2920 Failed to alloc Resource IDs "\r\n"rc = x%x\n", rc);\r\ngoto out_free_mbox;\r\n}\r\nrc = lpfc_read_sparam(phba, mboxq, vport->vpi);\r\nif (rc) {\r\nphba->link_state = LPFC_HBA_ERROR;\r\nrc = -ENOMEM;\r\ngoto out_free_mbox;\r\n}\r\nmboxq->vport = vport;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nmp = (struct lpfc_dmabuf *) mboxq->context1;\r\nif (rc == MBX_SUCCESS) {\r\nmemcpy(&vport->fc_sparam, mp->virt, sizeof(struct serv_parm));\r\nrc = 0;\r\n}\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmboxq->context1 = NULL;\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0382 READ_SPARAM command failed "\r\n"status %d, mbxStatus x%x\n",\r\nrc, bf_get(lpfc_mqe_status, mqe));\r\nphba->link_state = LPFC_HBA_ERROR;\r\nrc = -EIO;\r\ngoto out_free_mbox;\r\n}\r\nlpfc_update_vport_wwn(vport);\r\nfc_host_node_name(shost) = wwn_to_u64(vport->fc_nodename.u.wwn);\r\nfc_host_port_name(shost) = wwn_to_u64(vport->fc_portname.u.wwn);\r\nrc = lpfc_sli4_xri_sgl_update(phba);\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"1400 Failed to update xri-sgl size and "\r\n"mapping: %d\n", rc);\r\ngoto out_free_mbox;\r\n}\r\nrc = lpfc_sli4_repost_els_sgl_list(phba);\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0582 Error %d during els sgl post "\r\n"operation\n", rc);\r\nrc = -ENODEV;\r\ngoto out_free_mbox;\r\n}\r\nrc = lpfc_sli4_repost_scsi_sgl_list(phba);\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0383 Error %d during scsi sgl post "\r\n"operation\n", rc);\r\nrc = -ENODEV;\r\ngoto out_free_mbox;\r\n}\r\nrc = lpfc_sli4_post_all_rpi_hdrs(phba);\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0393 Error %d during rpi post operation\n",\r\nrc);\r\nrc = -ENODEV;\r\ngoto out_free_mbox;\r\n}\r\nlpfc_sli4_node_prep(phba);\r\nrc = lpfc_sli4_queue_create(phba);\r\nif (rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3089 Failed to allocate queues\n");\r\nrc = -ENODEV;\r\ngoto out_stop_timers;\r\n}\r\nrc = lpfc_sli4_queue_setup(phba);\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0381 Error %d during queue setup.\n ", rc);\r\ngoto out_destroy_queue;\r\n}\r\nlpfc_sli4_arm_cqeq_intr(phba);\r\nphba->sli4_hba.intr_enable = 1;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->sli.sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_rb_setup(phba);\r\nphba->fcf.fcf_flag = 0;\r\nphba->fcf.current_rec.flag = 0;\r\nmod_timer(&vport->els_tmofunc,\r\njiffies + msecs_to_jiffies(1000 * (phba->fc_ratov * 2)));\r\nmod_timer(&phba->hb_tmofunc,\r\njiffies + msecs_to_jiffies(1000 * LPFC_HB_MBOX_INTERVAL));\r\nphba->hb_outstanding = 0;\r\nphba->last_completion_time = jiffies;\r\nmod_timer(&phba->eratt_poll,\r\njiffies + msecs_to_jiffies(1000 * LPFC_ERATT_POLL_INTERVAL));\r\nif (phba->cfg_aer_support == 1 && !(phba->hba_flag & HBA_AER_ENABLED)) {\r\nrc = pci_enable_pcie_error_reporting(phba->pcidev);\r\nif (!rc) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"2829 This device supports "\r\n"Advanced Error Reporting (AER)\n");\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag |= HBA_AER_ENABLED;\r\nspin_unlock_irq(&phba->hbalock);\r\n} else {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"2830 This device does not support "\r\n"Advanced Error Reporting (AER)\n");\r\nphba->cfg_aer_support = 0;\r\n}\r\nrc = 0;\r\n}\r\nif (!(phba->hba_flag & HBA_FCOE_MODE)) {\r\nlpfc_reg_fcfi(phba, mboxq);\r\nmboxq->vport = phba->pport;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nif (rc != MBX_SUCCESS)\r\ngoto out_unset_queue;\r\nrc = 0;\r\nphba->fcf.fcfi = bf_get(lpfc_reg_fcfi_fcfi,\r\n&mboxq->u.mqe.un.reg_fcfi);\r\nlpfc_sli_read_link_ste(phba);\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\nphba->link_state = LPFC_LINK_DOWN;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (!(phba->hba_flag & HBA_FCOE_MODE) &&\r\n(phba->hba_flag & LINK_DISABLED)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_SLI,\r\n"3103 Adapter Link is disabled.\n");\r\nlpfc_down_link(phba, mboxq);\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_SLI,\r\n"3104 Adapter failed to issue "\r\n"DOWN_LINK mbox cmd, rc:x%x\n", rc);\r\ngoto out_unset_queue;\r\n}\r\n} else if (phba->cfg_suppress_link_up == LPFC_INITIALIZE_LINK) {\r\nif (!(phba->link_flag & LS_LOOPBACK_MODE)) {\r\nrc = phba->lpfc_hba_init_link(phba, MBX_NOWAIT);\r\nif (rc)\r\ngoto out_unset_queue;\r\n}\r\n}\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn rc;\r\nout_unset_queue:\r\nlpfc_sli4_queue_unset(phba);\r\nout_destroy_queue:\r\nlpfc_sli4_queue_destroy(phba);\r\nout_stop_timers:\r\nlpfc_stop_hba_timers(phba);\r\nout_free_mbox:\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn rc;\r\n}\r\nvoid\r\nlpfc_mbox_timeout(unsigned long ptr)\r\n{\r\nstruct lpfc_hba *phba = (struct lpfc_hba *) ptr;\r\nunsigned long iflag;\r\nuint32_t tmo_posted;\r\nspin_lock_irqsave(&phba->pport->work_port_lock, iflag);\r\ntmo_posted = phba->pport->work_port_events & WORKER_MBOX_TMO;\r\nif (!tmo_posted)\r\nphba->pport->work_port_events |= WORKER_MBOX_TMO;\r\nspin_unlock_irqrestore(&phba->pport->work_port_lock, iflag);\r\nif (!tmo_posted)\r\nlpfc_worker_wake_up(phba);\r\nreturn;\r\n}\r\nbool\r\nlpfc_sli4_mbox_completions_pending(struct lpfc_hba *phba)\r\n{\r\nuint32_t idx;\r\nstruct lpfc_queue *mcq;\r\nstruct lpfc_mcqe *mcqe;\r\nbool pending_completions = false;\r\nif (unlikely(!phba) || (phba->sli_rev != LPFC_SLI_REV4))\r\nreturn false;\r\nmcq = phba->sli4_hba.mbx_cq;\r\nidx = mcq->hba_index;\r\nwhile (bf_get_le32(lpfc_cqe_valid, mcq->qe[idx].cqe)) {\r\nmcqe = (struct lpfc_mcqe *)mcq->qe[idx].cqe;\r\nif (bf_get_le32(lpfc_trailer_completed, mcqe) &&\r\n(!bf_get_le32(lpfc_trailer_async, mcqe))) {\r\npending_completions = true;\r\nbreak;\r\n}\r\nidx = (idx + 1) % mcq->entry_count;\r\nif (mcq->hba_index == idx)\r\nbreak;\r\n}\r\nreturn pending_completions;\r\n}\r\nbool\r\nlpfc_sli4_process_missed_mbox_completions(struct lpfc_hba *phba)\r\n{\r\nuint32_t eqidx;\r\nstruct lpfc_queue *fpeq = NULL;\r\nstruct lpfc_eqe *eqe;\r\nbool mbox_pending;\r\nif (unlikely(!phba) || (phba->sli_rev != LPFC_SLI_REV4))\r\nreturn false;\r\nif (phba->sli4_hba.hba_eq)\r\nfor (eqidx = 0; eqidx < phba->cfg_fcp_io_channel; eqidx++)\r\nif (phba->sli4_hba.hba_eq[eqidx]->queue_id ==\r\nphba->sli4_hba.mbx_cq->assoc_qid) {\r\nfpeq = phba->sli4_hba.hba_eq[eqidx];\r\nbreak;\r\n}\r\nif (!fpeq)\r\nreturn false;\r\nlpfc_sli4_eq_clr_intr(fpeq);\r\nmbox_pending = lpfc_sli4_mbox_completions_pending(phba);\r\nif (mbox_pending)\r\nwhile ((eqe = lpfc_sli4_eq_get(fpeq))) {\r\nlpfc_sli4_hba_handle_eqe(phba, eqe, eqidx);\r\nfpeq->EQ_processed++;\r\n}\r\nlpfc_sli4_eq_release(fpeq, LPFC_QUEUE_REARM);\r\nreturn mbox_pending;\r\n}\r\nvoid\r\nlpfc_mbox_timeout_handler(struct lpfc_hba *phba)\r\n{\r\nLPFC_MBOXQ_t *pmbox = phba->sli.mbox_active;\r\nMAILBOX_t *mb = NULL;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nif (lpfc_sli4_process_missed_mbox_completions(phba))\r\nreturn;\r\nif (pmbox != NULL)\r\nmb = &pmbox->u.mb;\r\nspin_lock_irq(&phba->hbalock);\r\nif (pmbox == NULL) {\r\nlpfc_printf_log(phba, KERN_WARNING,\r\nLOG_MBOX | LOG_SLI,\r\n"0353 Active Mailbox cleared - mailbox timeout "\r\n"exiting\n");\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0310 Mailbox command x%x timeout Data: x%x x%x x%p\n",\r\nmb->mbxCommand,\r\nphba->pport->port_state,\r\nphba->sli.sli_flag,\r\nphba->sli.mbox_active);\r\nspin_unlock_irq(&phba->hbalock);\r\nspin_lock_irq(&phba->pport->work_port_lock);\r\nphba->pport->work_port_events &= ~WORKER_MBOX_TMO;\r\nspin_unlock_irq(&phba->pport->work_port_lock);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->link_state = LPFC_LINK_UNKNOWN;\r\npsli->sli_flag &= ~LPFC_SLI_ACTIVE;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli_abort_fcp_rings(phba);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0345 Resetting board due to mailbox timeout\n");\r\nlpfc_reset_hba(phba);\r\n}\r\nstatic int\r\nlpfc_sli_issue_mbox_s3(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmbox,\r\nuint32_t flag)\r\n{\r\nMAILBOX_t *mbx;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nuint32_t status, evtctr;\r\nuint32_t ha_copy, hc_copy;\r\nint i;\r\nunsigned long timeout;\r\nunsigned long drvr_flag = 0;\r\nuint32_t word0, ldata;\r\nvoid __iomem *to_slim;\r\nint processing_queue = 0;\r\nspin_lock_irqsave(&phba->hbalock, drvr_flag);\r\nif (!pmbox) {\r\nphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nif (unlikely(psli->sli_flag & LPFC_SLI_ASYNC_MBX_BLK)) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nreturn MBX_SUCCESS;\r\n}\r\nprocessing_queue = 1;\r\npmbox = lpfc_mbox_get(phba);\r\nif (!pmbox) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nreturn MBX_SUCCESS;\r\n}\r\n}\r\nif (pmbox->mbox_cmpl && pmbox->mbox_cmpl != lpfc_sli_def_mbox_cmpl &&\r\npmbox->mbox_cmpl != lpfc_sli_wake_mbox_wait) {\r\nif(!pmbox->vport) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nlpfc_printf_log(phba, KERN_ERR,\r\nLOG_MBOX | LOG_VPORT,\r\n"1806 Mbox x%x failed. No vport\n",\r\npmbox->u.mb.mbxCommand);\r\ndump_stack();\r\ngoto out_not_finished;\r\n}\r\n}\r\nif (unlikely(pci_channel_offline(phba->pcidev))) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\ngoto out_not_finished;\r\n}\r\nif (unlikely(phba->hba_flag & DEFER_ERATT)) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\ngoto out_not_finished;\r\n}\r\npsli = &phba->sli;\r\nmbx = &pmbox->u.mb;\r\nstatus = MBX_SUCCESS;\r\nif (phba->link_state == LPFC_HBA_ERROR) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):0311 Mailbox command x%x cannot "\r\n"issue Data: x%x x%x\n",\r\npmbox->vport ? pmbox->vport->vpi : 0,\r\npmbox->u.mb.mbxCommand, psli->sli_flag, flag);\r\ngoto out_not_finished;\r\n}\r\nif (mbx->mbxCommand != MBX_KILL_BOARD && flag & MBX_NOWAIT) {\r\nif (lpfc_readl(phba->HCregaddr, &hc_copy) ||\r\n!(hc_copy & HC_MBINT_ENA)) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2528 Mailbox command x%x cannot "\r\n"issue Data: x%x x%x\n",\r\npmbox->vport ? pmbox->vport->vpi : 0,\r\npmbox->u.mb.mbxCommand, psli->sli_flag, flag);\r\ngoto out_not_finished;\r\n}\r\n}\r\nif (psli->sli_flag & LPFC_SLI_MBOX_ACTIVE) {\r\nif (flag & MBX_POLL) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2529 Mailbox command x%x "\r\n"cannot issue Data: x%x x%x\n",\r\npmbox->vport ? pmbox->vport->vpi : 0,\r\npmbox->u.mb.mbxCommand,\r\npsli->sli_flag, flag);\r\ngoto out_not_finished;\r\n}\r\nif (!(psli->sli_flag & LPFC_SLI_ACTIVE)) {\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2530 Mailbox command x%x "\r\n"cannot issue Data: x%x x%x\n",\r\npmbox->vport ? pmbox->vport->vpi : 0,\r\npmbox->u.mb.mbxCommand,\r\npsli->sli_flag, flag);\r\ngoto out_not_finished;\r\n}\r\nlpfc_mbox_put(phba, pmbox);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):0308 Mbox cmd issue - BUSY Data: "\r\n"x%x x%x x%x x%x\n",\r\npmbox->vport ? pmbox->vport->vpi : 0xffffff,\r\nmbx->mbxCommand, phba->pport->port_state,\r\npsli->sli_flag, flag);\r\npsli->slistat.mbox_busy++;\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nif (pmbox->vport) {\r\nlpfc_debugfs_disc_trc(pmbox->vport,\r\nLPFC_DISC_TRC_MBOX_VPORT,\r\n"MBOX Bsy vport: cmd:x%x mb:x%x x%x",\r\n(uint32_t)mbx->mbxCommand,\r\nmbx->un.varWords[0], mbx->un.varWords[1]);\r\n}\r\nelse {\r\nlpfc_debugfs_disc_trc(phba->pport,\r\nLPFC_DISC_TRC_MBOX,\r\n"MBOX Bsy: cmd:x%x mb:x%x x%x",\r\n(uint32_t)mbx->mbxCommand,\r\nmbx->un.varWords[0], mbx->un.varWords[1]);\r\n}\r\nreturn MBX_BUSY;\r\n}\r\npsli->sli_flag |= LPFC_SLI_MBOX_ACTIVE;\r\nif (flag != MBX_POLL) {\r\nif (!(psli->sli_flag & LPFC_SLI_ACTIVE) &&\r\n(mbx->mbxCommand != MBX_KILL_BOARD)) {\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2531 Mailbox command x%x "\r\n"cannot issue Data: x%x x%x\n",\r\npmbox->vport ? pmbox->vport->vpi : 0,\r\npmbox->u.mb.mbxCommand,\r\npsli->sli_flag, flag);\r\ngoto out_not_finished;\r\n}\r\ntimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba, pmbox) *\r\n1000);\r\nmod_timer(&psli->mbox_tmo, jiffies + timeout);\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):0309 Mailbox cmd x%x issue Data: x%x x%x "\r\n"x%x\n",\r\npmbox->vport ? pmbox->vport->vpi : 0,\r\nmbx->mbxCommand, phba->pport->port_state,\r\npsli->sli_flag, flag);\r\nif (mbx->mbxCommand != MBX_HEARTBEAT) {\r\nif (pmbox->vport) {\r\nlpfc_debugfs_disc_trc(pmbox->vport,\r\nLPFC_DISC_TRC_MBOX_VPORT,\r\n"MBOX Send vport: cmd:x%x mb:x%x x%x",\r\n(uint32_t)mbx->mbxCommand,\r\nmbx->un.varWords[0], mbx->un.varWords[1]);\r\n}\r\nelse {\r\nlpfc_debugfs_disc_trc(phba->pport,\r\nLPFC_DISC_TRC_MBOX,\r\n"MBOX Send: cmd:x%x mb:x%x x%x",\r\n(uint32_t)mbx->mbxCommand,\r\nmbx->un.varWords[0], mbx->un.varWords[1]);\r\n}\r\n}\r\npsli->slistat.mbox_cmd++;\r\nevtctr = psli->slistat.mbox_event;\r\nmbx->mbxOwner = OWN_CHIP;\r\nif (psli->sli_flag & LPFC_SLI_ACTIVE) {\r\nif (pmbox->in_ext_byte_len || pmbox->out_ext_byte_len) {\r\n*(((uint32_t *)mbx) + pmbox->mbox_offset_word)\r\n= (uint8_t *)phba->mbox_ext\r\n- (uint8_t *)phba->mbox;\r\n}\r\nif (pmbox->in_ext_byte_len && pmbox->context2) {\r\nlpfc_sli_pcimem_bcopy(pmbox->context2,\r\n(uint8_t *)phba->mbox_ext,\r\npmbox->in_ext_byte_len);\r\n}\r\nlpfc_sli_pcimem_bcopy(mbx, phba->mbox, MAILBOX_CMD_SIZE);\r\n} else {\r\nif (pmbox->in_ext_byte_len || pmbox->out_ext_byte_len)\r\n*(((uint32_t *)mbx) + pmbox->mbox_offset_word)\r\n= MAILBOX_HBA_EXT_OFFSET;\r\nif (pmbox->in_ext_byte_len && pmbox->context2) {\r\nlpfc_memcpy_to_slim(phba->MBslimaddr +\r\nMAILBOX_HBA_EXT_OFFSET,\r\npmbox->context2, pmbox->in_ext_byte_len);\r\n}\r\nif (mbx->mbxCommand == MBX_CONFIG_PORT) {\r\nlpfc_sli_pcimem_bcopy(mbx, phba->mbox, MAILBOX_CMD_SIZE);\r\n}\r\nto_slim = phba->MBslimaddr + sizeof (uint32_t);\r\nlpfc_memcpy_to_slim(to_slim, &mbx->un.varWords[0],\r\nMAILBOX_CMD_SIZE - sizeof (uint32_t));\r\nldata = *((uint32_t *)mbx);\r\nto_slim = phba->MBslimaddr;\r\nwritel(ldata, to_slim);\r\nreadl(to_slim);\r\nif (mbx->mbxCommand == MBX_CONFIG_PORT) {\r\npsli->sli_flag |= LPFC_SLI_ACTIVE;\r\n}\r\n}\r\nwmb();\r\nswitch (flag) {\r\ncase MBX_NOWAIT:\r\npsli->mbox_active = pmbox;\r\nwritel(CA_MBATT, phba->CAregaddr);\r\nreadl(phba->CAregaddr);\r\nbreak;\r\ncase MBX_POLL:\r\npsli->mbox_active = NULL;\r\nwritel(CA_MBATT, phba->CAregaddr);\r\nreadl(phba->CAregaddr);\r\nif (psli->sli_flag & LPFC_SLI_ACTIVE) {\r\nword0 = *((uint32_t *)phba->mbox);\r\nword0 = le32_to_cpu(word0);\r\n} else {\r\nif (lpfc_readl(phba->MBslimaddr, &word0)) {\r\nspin_unlock_irqrestore(&phba->hbalock,\r\ndrvr_flag);\r\ngoto out_not_finished;\r\n}\r\n}\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy)) {\r\nspin_unlock_irqrestore(&phba->hbalock,\r\ndrvr_flag);\r\ngoto out_not_finished;\r\n}\r\ntimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba, pmbox) *\r\n1000) + jiffies;\r\ni = 0;\r\nwhile (((word0 & OWN_CHIP) == OWN_CHIP) ||\r\n(!(ha_copy & HA_MBATT) &&\r\n(phba->link_state > LPFC_WARM_START))) {\r\nif (time_after(jiffies, timeout)) {\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nspin_unlock_irqrestore(&phba->hbalock,\r\ndrvr_flag);\r\ngoto out_not_finished;\r\n}\r\nif (((word0 & OWN_CHIP) != OWN_CHIP)\r\n&& (evtctr != psli->slistat.mbox_event))\r\nbreak;\r\nif (i++ > 10) {\r\nspin_unlock_irqrestore(&phba->hbalock,\r\ndrvr_flag);\r\nmsleep(1);\r\nspin_lock_irqsave(&phba->hbalock, drvr_flag);\r\n}\r\nif (psli->sli_flag & LPFC_SLI_ACTIVE) {\r\nword0 = *((uint32_t *)phba->mbox);\r\nword0 = le32_to_cpu(word0);\r\nif (mbx->mbxCommand == MBX_CONFIG_PORT) {\r\nMAILBOX_t *slimmb;\r\nuint32_t slimword0;\r\nslimword0 = readl(phba->MBslimaddr);\r\nslimmb = (MAILBOX_t *) & slimword0;\r\nif (((slimword0 & OWN_CHIP) != OWN_CHIP)\r\n&& slimmb->mbxStatus) {\r\npsli->sli_flag &=\r\n~LPFC_SLI_ACTIVE;\r\nword0 = slimword0;\r\n}\r\n}\r\n} else {\r\nword0 = readl(phba->MBslimaddr);\r\n}\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy)) {\r\nspin_unlock_irqrestore(&phba->hbalock,\r\ndrvr_flag);\r\ngoto out_not_finished;\r\n}\r\n}\r\nif (psli->sli_flag & LPFC_SLI_ACTIVE) {\r\nlpfc_sli_pcimem_bcopy(phba->mbox, mbx, MAILBOX_CMD_SIZE);\r\nif (pmbox->out_ext_byte_len && pmbox->context2) {\r\nlpfc_sli_pcimem_bcopy(phba->mbox_ext,\r\npmbox->context2,\r\npmbox->out_ext_byte_len);\r\n}\r\n} else {\r\nlpfc_memcpy_from_slim(mbx, phba->MBslimaddr,\r\nMAILBOX_CMD_SIZE);\r\nif (pmbox->out_ext_byte_len && pmbox->context2) {\r\nlpfc_memcpy_from_slim(pmbox->context2,\r\nphba->MBslimaddr +\r\nMAILBOX_HBA_EXT_OFFSET,\r\npmbox->out_ext_byte_len);\r\n}\r\n}\r\nwritel(HA_MBATT, phba->HAregaddr);\r\nreadl(phba->HAregaddr);\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nstatus = mbx->mbxStatus;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, drvr_flag);\r\nreturn status;\r\nout_not_finished:\r\nif (processing_queue) {\r\npmbox->u.mb.mbxStatus = MBX_NOT_FINISHED;\r\nlpfc_mbox_cmpl_put(phba, pmbox);\r\n}\r\nreturn MBX_NOT_FINISHED;\r\n}\r\nstatic int\r\nlpfc_sli4_async_mbox_block(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nint rc = 0;\r\nunsigned long timeout = 0;\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag |= LPFC_SLI_ASYNC_MBX_BLK;\r\nif (phba->sli.mbox_active)\r\ntimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba,\r\nphba->sli.mbox_active) *\r\n1000) + jiffies;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (timeout)\r\nlpfc_sli4_process_missed_mbox_completions(phba);\r\nwhile (phba->sli.mbox_active) {\r\nmsleep(2);\r\nif (time_after(jiffies, timeout)) {\r\nrc = 1;\r\nbreak;\r\n}\r\n}\r\nif (rc) {\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nreturn rc;\r\n}\r\nstatic void\r\nlpfc_sli4_async_mbox_unblock(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nspin_lock_irq(&phba->hbalock);\r\nif (!(psli->sli_flag & LPFC_SLI_ASYNC_MBX_BLK)) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\npsli->sli_flag &= ~LPFC_SLI_ASYNC_MBX_BLK;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_worker_wake_up(phba);\r\n}\r\nstatic int\r\nlpfc_sli4_wait_bmbx_ready(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nuint32_t db_ready;\r\nunsigned long timeout;\r\nstruct lpfc_register bmbx_reg;\r\ntimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba, mboxq)\r\n* 1000) + jiffies;\r\ndo {\r\nbmbx_reg.word0 = readl(phba->sli4_hba.BMBXregaddr);\r\ndb_ready = bf_get(lpfc_bmbx_rdy, &bmbx_reg);\r\nif (!db_ready)\r\nmsleep(2);\r\nif (time_after(jiffies, timeout))\r\nreturn MBXERR_ERROR;\r\n} while (!db_ready);\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_sli4_post_sync_mbox(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nint rc = MBX_SUCCESS;\r\nunsigned long iflag;\r\nuint32_t mcqe_status;\r\nuint32_t mbx_cmnd;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_mqe *mb = &mboxq->u.mqe;\r\nstruct lpfc_bmbx_create *mbox_rgn;\r\nstruct dma_address *dma_address;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (psli->sli_flag & LPFC_SLI_MBOX_ACTIVE) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2532 Mailbox command x%x (x%x/x%x) "\r\n"cannot issue Data: x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nmboxq->u.mb.mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\npsli->sli_flag, MBX_POLL);\r\nreturn MBXERR_ERROR;\r\n}\r\npsli->sli_flag |= LPFC_SLI_MBOX_ACTIVE;\r\nphba->sli.mbox_active = mboxq;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nrc = lpfc_sli4_wait_bmbx_ready(phba, mboxq);\r\nif (rc)\r\ngoto exit;\r\nmbx_cmnd = bf_get(lpfc_mqe_command, mb);\r\nmemset(phba->sli4_hba.bmbx.avirt, 0, sizeof(struct lpfc_bmbx_create));\r\nlpfc_sli_pcimem_bcopy(mb, phba->sli4_hba.bmbx.avirt,\r\nsizeof(struct lpfc_mqe));\r\ndma_address = &phba->sli4_hba.bmbx.dma_address;\r\nwritel(dma_address->addr_hi, phba->sli4_hba.BMBXregaddr);\r\nrc = lpfc_sli4_wait_bmbx_ready(phba, mboxq);\r\nif (rc)\r\ngoto exit;\r\nwritel(dma_address->addr_lo, phba->sli4_hba.BMBXregaddr);\r\nrc = lpfc_sli4_wait_bmbx_ready(phba, mboxq);\r\nif (rc)\r\ngoto exit;\r\nlpfc_sli_pcimem_bcopy(phba->sli4_hba.bmbx.avirt, mb,\r\nsizeof(struct lpfc_mqe));\r\nmbox_rgn = (struct lpfc_bmbx_create *) phba->sli4_hba.bmbx.avirt;\r\nlpfc_sli_pcimem_bcopy(&mbox_rgn->mcqe, &mboxq->mcqe,\r\nsizeof(struct lpfc_mcqe));\r\nmcqe_status = bf_get(lpfc_mcqe_status, &mbox_rgn->mcqe);\r\nif (mcqe_status != MB_CQE_STATUS_SUCCESS) {\r\nif (bf_get(lpfc_mqe_status, mb) == MBX_SUCCESS)\r\nbf_set(lpfc_mqe_status, mb,\r\n(LPFC_MBX_ERROR_RANGE | mcqe_status));\r\nrc = MBXERR_ERROR;\r\n} else\r\nlpfc_sli4_swap_str(phba, mboxq);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):0356 Mailbox cmd x%x (x%x/x%x) Status x%x "\r\n"Data: x%x x%x x%x x%x x%x x%x x%x x%x x%x x%x x%x"\r\n" x%x x%x CQ: x%x x%x x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0, mbx_cmnd,\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\nbf_get(lpfc_mqe_status, mb),\r\nmb->un.mb_words[0], mb->un.mb_words[1],\r\nmb->un.mb_words[2], mb->un.mb_words[3],\r\nmb->un.mb_words[4], mb->un.mb_words[5],\r\nmb->un.mb_words[6], mb->un.mb_words[7],\r\nmb->un.mb_words[8], mb->un.mb_words[9],\r\nmb->un.mb_words[10], mb->un.mb_words[11],\r\nmb->un.mb_words[12], mboxq->mcqe.word0,\r\nmboxq->mcqe.mcqe_tag0, mboxq->mcqe.mcqe_tag1,\r\nmboxq->mcqe.trailer);\r\nexit:\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nphba->sli.mbox_active = NULL;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_sli_issue_mbox_s4(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq,\r\nuint32_t flag)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nunsigned long iflags;\r\nint rc;\r\nlpfc_idiag_mbxacc_dump_issue_mbox(phba, &mboxq->u.mb);\r\nrc = lpfc_mbox_dev_check(phba);\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2544 Mailbox command x%x (x%x/x%x) "\r\n"cannot issue Data: x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nmboxq->u.mb.mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\npsli->sli_flag, flag);\r\ngoto out_not_finished;\r\n}\r\nif (!phba->sli4_hba.intr_enable) {\r\nif (flag == MBX_POLL)\r\nrc = lpfc_sli4_post_sync_mbox(phba, mboxq);\r\nelse\r\nrc = -EIO;\r\nif (rc != MBX_SUCCESS)\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\r\n"(%d):2541 Mailbox command x%x "\r\n"(x%x/x%x) failure: "\r\n"mqe_sta: x%x mcqe_sta: x%x/x%x "\r\n"Data: x%x x%x\n,",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nmboxq->u.mb.mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba,\r\nmboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba,\r\nmboxq),\r\nbf_get(lpfc_mqe_status, &mboxq->u.mqe),\r\nbf_get(lpfc_mcqe_status, &mboxq->mcqe),\r\nbf_get(lpfc_mcqe_ext_status,\r\n&mboxq->mcqe),\r\npsli->sli_flag, flag);\r\nreturn rc;\r\n} else if (flag == MBX_POLL) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_MBOX | LOG_SLI,\r\n"(%d):2542 Try to issue mailbox command "\r\n"x%x (x%x/x%x) synchronously ahead of async"\r\n"mailbox command queue: x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nmboxq->u.mb.mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\npsli->sli_flag, flag);\r\nrc = lpfc_sli4_async_mbox_block(phba);\r\nif (!rc) {\r\nrc = lpfc_sli4_post_sync_mbox(phba, mboxq);\r\nif (rc != MBX_SUCCESS)\r\nlpfc_printf_log(phba, KERN_WARNING,\r\nLOG_MBOX | LOG_SLI,\r\n"(%d):2597 Sync Mailbox command "\r\n"x%x (x%x/x%x) failure: "\r\n"mqe_sta: x%x mcqe_sta: x%x/x%x "\r\n"Data: x%x x%x\n,",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nmboxq->u.mb.mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba,\r\nmboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba,\r\nmboxq),\r\nbf_get(lpfc_mqe_status, &mboxq->u.mqe),\r\nbf_get(lpfc_mcqe_status, &mboxq->mcqe),\r\nbf_get(lpfc_mcqe_ext_status,\r\n&mboxq->mcqe),\r\npsli->sli_flag, flag);\r\nlpfc_sli4_async_mbox_unblock(phba);\r\n}\r\nreturn rc;\r\n}\r\nrc = lpfc_mbox_cmd_check(phba, mboxq);\r\nif (rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2543 Mailbox command x%x (x%x/x%x) "\r\n"cannot issue Data: x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nmboxq->u.mb.mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\npsli->sli_flag, flag);\r\ngoto out_not_finished;\r\n}\r\npsli->slistat.mbox_busy++;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nlpfc_mbox_put(phba, mboxq);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):0354 Mbox cmd issue - Enqueue Data: "\r\n"x%x (x%x/x%x) x%x x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0xffffff,\r\nbf_get(lpfc_mqe_command, &mboxq->u.mqe),\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\nphba->pport->port_state,\r\npsli->sli_flag, MBX_NOWAIT);\r\nlpfc_worker_wake_up(phba);\r\nreturn MBX_BUSY;\r\nout_not_finished:\r\nreturn MBX_NOT_FINISHED;\r\n}\r\nint\r\nlpfc_sli4_post_async_mbox(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nLPFC_MBOXQ_t *mboxq;\r\nint rc = MBX_SUCCESS;\r\nunsigned long iflags;\r\nstruct lpfc_mqe *mqe;\r\nuint32_t mbx_cmnd;\r\nif (unlikely(!phba->sli4_hba.intr_enable))\r\nreturn MBX_NOT_FINISHED;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nif (unlikely(psli->sli_flag & LPFC_SLI_ASYNC_MBX_BLK)) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn MBX_NOT_FINISHED;\r\n}\r\nif (psli->sli_flag & LPFC_SLI_MBOX_ACTIVE) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn MBX_NOT_FINISHED;\r\n}\r\nif (unlikely(phba->sli.mbox_active)) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"0384 There is pending active mailbox cmd\n");\r\nreturn MBX_NOT_FINISHED;\r\n}\r\npsli->sli_flag |= LPFC_SLI_MBOX_ACTIVE;\r\nmboxq = lpfc_mbox_get(phba);\r\nif (!mboxq) {\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn MBX_SUCCESS;\r\n}\r\nphba->sli.mbox_active = mboxq;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nrc = lpfc_mbox_dev_check(phba);\r\nif (unlikely(rc))\r\ngoto out_not_finished;\r\nmqe = &mboxq->u.mqe;\r\nmbx_cmnd = bf_get(lpfc_mqe_command, mqe);\r\nmod_timer(&psli->mbox_tmo, (jiffies +\r\nmsecs_to_jiffies(1000 * lpfc_mbox_tmo_val(phba, mboxq))));\r\nlpfc_printf_log(phba, KERN_INFO, LOG_MBOX | LOG_SLI,\r\n"(%d):0355 Mailbox cmd x%x (x%x/x%x) issue Data: "\r\n"x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0, mbx_cmnd,\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\nphba->pport->port_state, psli->sli_flag);\r\nif (mbx_cmnd != MBX_HEARTBEAT) {\r\nif (mboxq->vport) {\r\nlpfc_debugfs_disc_trc(mboxq->vport,\r\nLPFC_DISC_TRC_MBOX_VPORT,\r\n"MBOX Send vport: cmd:x%x mb:x%x x%x",\r\nmbx_cmnd, mqe->un.mb_words[0],\r\nmqe->un.mb_words[1]);\r\n} else {\r\nlpfc_debugfs_disc_trc(phba->pport,\r\nLPFC_DISC_TRC_MBOX,\r\n"MBOX Send: cmd:x%x mb:x%x x%x",\r\nmbx_cmnd, mqe->un.mb_words[0],\r\nmqe->un.mb_words[1]);\r\n}\r\n}\r\npsli->slistat.mbox_cmd++;\r\nrc = lpfc_sli4_mq_put(phba->sli4_hba.mbx_wq, mqe);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX | LOG_SLI,\r\n"(%d):2533 Mailbox command x%x (x%x/x%x) "\r\n"cannot issue Data: x%x x%x\n",\r\nmboxq->vport ? mboxq->vport->vpi : 0,\r\nmboxq->u.mb.mbxCommand,\r\nlpfc_sli_config_mbox_subsys_get(phba, mboxq),\r\nlpfc_sli_config_mbox_opcode_get(phba, mboxq),\r\npsli->sli_flag, MBX_NOWAIT);\r\ngoto out_not_finished;\r\n}\r\nreturn rc;\r\nout_not_finished:\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nif (phba->sli.mbox_active) {\r\nmboxq->u.mb.mbxStatus = MBX_NOT_FINISHED;\r\n__lpfc_mbox_cmpl_put(phba, mboxq);\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nphba->sli.mbox_active = NULL;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn MBX_NOT_FINISHED;\r\n}\r\nint\r\nlpfc_sli_issue_mbox(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmbox, uint32_t flag)\r\n{\r\nreturn phba->lpfc_sli_issue_mbox(phba, pmbox, flag);\r\n}\r\nint\r\nlpfc_mbox_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\r\n{\r\nswitch (dev_grp) {\r\ncase LPFC_PCI_DEV_LP:\r\nphba->lpfc_sli_issue_mbox = lpfc_sli_issue_mbox_s3;\r\nphba->lpfc_sli_handle_slow_ring_event =\r\nlpfc_sli_handle_slow_ring_event_s3;\r\nphba->lpfc_sli_hbq_to_firmware = lpfc_sli_hbq_to_firmware_s3;\r\nphba->lpfc_sli_brdrestart = lpfc_sli_brdrestart_s3;\r\nphba->lpfc_sli_brdready = lpfc_sli_brdready_s3;\r\nbreak;\r\ncase LPFC_PCI_DEV_OC:\r\nphba->lpfc_sli_issue_mbox = lpfc_sli_issue_mbox_s4;\r\nphba->lpfc_sli_handle_slow_ring_event =\r\nlpfc_sli_handle_slow_ring_event_s4;\r\nphba->lpfc_sli_hbq_to_firmware = lpfc_sli_hbq_to_firmware_s4;\r\nphba->lpfc_sli_brdrestart = lpfc_sli_brdrestart_s4;\r\nphba->lpfc_sli_brdready = lpfc_sli_brdready_s4;\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"1420 Invalid HBA PCI-device group: 0x%x\n",\r\ndev_grp);\r\nreturn -ENODEV;\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\n__lpfc_sli_ringtx_put(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *piocb)\r\n{\r\nlist_add_tail(&piocb->list, &pring->txq);\r\n}\r\nstatic struct lpfc_iocbq *\r\nlpfc_sli_next_iocb(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq **piocb)\r\n{\r\nstruct lpfc_iocbq * nextiocb;\r\nnextiocb = lpfc_sli_ringtx_get(phba, pring);\r\nif (!nextiocb) {\r\nnextiocb = *piocb;\r\n*piocb = NULL;\r\n}\r\nreturn nextiocb;\r\n}\r\nstatic int\r\n__lpfc_sli_issue_iocb_s3(struct lpfc_hba *phba, uint32_t ring_number,\r\nstruct lpfc_iocbq *piocb, uint32_t flag)\r\n{\r\nstruct lpfc_iocbq *nextiocb;\r\nIOCB_t *iocb;\r\nstruct lpfc_sli_ring *pring = &phba->sli.ring[ring_number];\r\nif (piocb->iocb_cmpl && (!piocb->vport) &&\r\n(piocb->iocb.ulpCommand != CMD_ABORT_XRI_CN) &&\r\n(piocb->iocb.ulpCommand != CMD_CLOSE_XRI_CN)) {\r\nlpfc_printf_log(phba, KERN_ERR,\r\nLOG_SLI | LOG_VPORT,\r\n"1807 IOCB x%x failed. No vport\n",\r\npiocb->iocb.ulpCommand);\r\ndump_stack();\r\nreturn IOCB_ERROR;\r\n}\r\nif (unlikely(pci_channel_offline(phba->pcidev)))\r\nreturn IOCB_ERROR;\r\nif (unlikely(phba->hba_flag & DEFER_ERATT))\r\nreturn IOCB_ERROR;\r\nif (unlikely(phba->link_state < LPFC_LINK_DOWN))\r\nreturn IOCB_ERROR;\r\nif (unlikely(pring->flag & LPFC_STOP_IOCB_EVENT))\r\ngoto iocb_busy;\r\nif (unlikely(phba->link_state == LPFC_LINK_DOWN)) {\r\nswitch (piocb->iocb.ulpCommand) {\r\ncase CMD_GEN_REQUEST64_CR:\r\ncase CMD_GEN_REQUEST64_CX:\r\nif (!(phba->sli.sli_flag & LPFC_MENLO_MAINT) ||\r\n(piocb->iocb.un.genreq64.w5.hcsw.Rctl !=\r\nFC_RCTL_DD_UNSOL_CMD) ||\r\n(piocb->iocb.un.genreq64.w5.hcsw.Type !=\r\nMENLO_TRANSPORT_TYPE))\r\ngoto iocb_busy;\r\nbreak;\r\ncase CMD_QUE_RING_BUF_CN:\r\ncase CMD_QUE_RING_BUF64_CN:\r\nif (piocb->iocb_cmpl)\r\npiocb->iocb_cmpl = NULL;\r\ncase CMD_CREATE_XRI_CR:\r\ncase CMD_CLOSE_XRI_CN:\r\ncase CMD_CLOSE_XRI_CX:\r\nbreak;\r\ndefault:\r\ngoto iocb_busy;\r\n}\r\n} else if (unlikely(pring->ringno == phba->sli.fcp_ring &&\r\n!(phba->sli.sli_flag & LPFC_PROCESS_LA))) {\r\ngoto iocb_busy;\r\n}\r\nwhile ((iocb = lpfc_sli_next_iocb_slot(phba, pring)) &&\r\n(nextiocb = lpfc_sli_next_iocb(phba, pring, &piocb)))\r\nlpfc_sli_submit_iocb(phba, pring, iocb, nextiocb);\r\nif (iocb)\r\nlpfc_sli_update_ring(phba, pring);\r\nelse\r\nlpfc_sli_update_full_ring(phba, pring);\r\nif (!piocb)\r\nreturn IOCB_SUCCESS;\r\ngoto out_busy;\r\niocb_busy:\r\npring->stats.iocb_cmd_delay++;\r\nout_busy:\r\nif (!(flag & SLI_IOCB_RET_IOCB)) {\r\n__lpfc_sli_ringtx_put(phba, pring, piocb);\r\nreturn IOCB_SUCCESS;\r\n}\r\nreturn IOCB_BUSY;\r\n}\r\nstatic uint16_t\r\nlpfc_sli4_bpl2sgl(struct lpfc_hba *phba, struct lpfc_iocbq *piocbq,\r\nstruct lpfc_sglq *sglq)\r\n{\r\nuint16_t xritag = NO_XRI;\r\nstruct ulp_bde64 *bpl = NULL;\r\nstruct ulp_bde64 bde;\r\nstruct sli4_sge *sgl = NULL;\r\nstruct lpfc_dmabuf *dmabuf;\r\nIOCB_t *icmd;\r\nint numBdes = 0;\r\nint i = 0;\r\nuint32_t offset = 0;\r\nint inbound = 0;\r\nif (!piocbq || !sglq)\r\nreturn xritag;\r\nsgl = (struct sli4_sge *)sglq->sgl;\r\nicmd = &piocbq->iocb;\r\nif (icmd->ulpCommand == CMD_XMIT_BLS_RSP64_CX)\r\nreturn sglq->sli4_xritag;\r\nif (icmd->un.genreq64.bdl.bdeFlags == BUFF_TYPE_BLP_64) {\r\nnumBdes = icmd->un.genreq64.bdl.bdeSize /\r\nsizeof(struct ulp_bde64);\r\nif (piocbq->context3)\r\ndmabuf = (struct lpfc_dmabuf *)piocbq->context3;\r\nelse\r\nreturn xritag;\r\nbpl = (struct ulp_bde64 *)dmabuf->virt;\r\nif (!bpl)\r\nreturn xritag;\r\nfor (i = 0; i < numBdes; i++) {\r\nsgl->addr_hi = bpl->addrHigh;\r\nsgl->addr_lo = bpl->addrLow;\r\nsgl->word2 = le32_to_cpu(sgl->word2);\r\nif ((i+1) == numBdes)\r\nbf_set(lpfc_sli4_sge_last, sgl, 1);\r\nelse\r\nbf_set(lpfc_sli4_sge_last, sgl, 0);\r\nbde.tus.w = le32_to_cpu(bpl->tus.w);\r\nsgl->sge_len = cpu_to_le32(bde.tus.f.bdeSize);\r\nif (piocbq->iocb.ulpCommand == CMD_GEN_REQUEST64_CR) {\r\nif (bpl->tus.f.bdeFlags == BUFF_TYPE_BDE_64I)\r\ninbound++;\r\nif (inbound == 1)\r\noffset = 0;\r\nbf_set(lpfc_sli4_sge_offset, sgl, offset);\r\nbf_set(lpfc_sli4_sge_type, sgl,\r\nLPFC_SGE_TYPE_DATA);\r\noffset += bde.tus.f.bdeSize;\r\n}\r\nsgl->word2 = cpu_to_le32(sgl->word2);\r\nbpl++;\r\nsgl++;\r\n}\r\n} else if (icmd->un.genreq64.bdl.bdeFlags == BUFF_TYPE_BDE_64) {\r\nsgl->addr_hi =\r\ncpu_to_le32(icmd->un.genreq64.bdl.addrHigh);\r\nsgl->addr_lo =\r\ncpu_to_le32(icmd->un.genreq64.bdl.addrLow);\r\nsgl->word2 = le32_to_cpu(sgl->word2);\r\nbf_set(lpfc_sli4_sge_last, sgl, 1);\r\nsgl->word2 = cpu_to_le32(sgl->word2);\r\nsgl->sge_len =\r\ncpu_to_le32(icmd->un.genreq64.bdl.bdeSize);\r\n}\r\nreturn sglq->sli4_xritag;\r\n}\r\nstatic int\r\nlpfc_sli4_iocb2wqe(struct lpfc_hba *phba, struct lpfc_iocbq *iocbq,\r\nunion lpfc_wqe *wqe)\r\n{\r\nuint32_t xmit_len = 0, total_len = 0;\r\nuint8_t ct = 0;\r\nuint32_t fip;\r\nuint32_t abort_tag;\r\nuint8_t command_type = ELS_COMMAND_NON_FIP;\r\nuint8_t cmnd;\r\nuint16_t xritag;\r\nuint16_t abrt_iotag;\r\nstruct lpfc_iocbq *abrtiocbq;\r\nstruct ulp_bde64 *bpl = NULL;\r\nuint32_t els_id = LPFC_ELS_ID_DEFAULT;\r\nint numBdes, i;\r\nstruct ulp_bde64 bde;\r\nstruct lpfc_nodelist *ndlp;\r\nuint32_t *pcmd;\r\nuint32_t if_type;\r\nfip = phba->hba_flag & HBA_FIP_SUPPORT;\r\nif (iocbq->iocb_flag & LPFC_IO_FCP)\r\ncommand_type = FCP_COMMAND;\r\nelse if (fip && (iocbq->iocb_flag & LPFC_FIP_ELS_ID_MASK))\r\ncommand_type = ELS_COMMAND_FIP;\r\nelse\r\ncommand_type = ELS_COMMAND_NON_FIP;\r\nmemcpy(wqe, &iocbq->iocb, sizeof(union lpfc_wqe));\r\nabort_tag = (uint32_t) iocbq->iotag;\r\nxritag = iocbq->sli4_xritag;\r\nwqe->generic.wqe_com.word7 = 0;\r\nwqe->generic.wqe_com.word10 = 0;\r\nif (iocbq->iocb.un.genreq64.bdl.bdeFlags == BUFF_TYPE_BLP_64) {\r\nnumBdes = iocbq->iocb.un.genreq64.bdl.bdeSize /\r\nsizeof(struct ulp_bde64);\r\nbpl = (struct ulp_bde64 *)\r\n((struct lpfc_dmabuf *)iocbq->context3)->virt;\r\nif (!bpl)\r\nreturn IOCB_ERROR;\r\nwqe->generic.bde.addrHigh = le32_to_cpu(bpl->addrHigh);\r\nwqe->generic.bde.addrLow = le32_to_cpu(bpl->addrLow);\r\nwqe->generic.bde.tus.w = le32_to_cpu(bpl->tus.w);\r\nxmit_len = wqe->generic.bde.tus.f.bdeSize;\r\ntotal_len = 0;\r\nfor (i = 0; i < numBdes; i++) {\r\nbde.tus.w = le32_to_cpu(bpl[i].tus.w);\r\ntotal_len += bde.tus.f.bdeSize;\r\n}\r\n} else\r\nxmit_len = iocbq->iocb.un.fcpi64.bdl.bdeSize;\r\niocbq->iocb.ulpIoTag = iocbq->iotag;\r\ncmnd = iocbq->iocb.ulpCommand;\r\nswitch (iocbq->iocb.ulpCommand) {\r\ncase CMD_ELS_REQUEST64_CR:\r\nif (iocbq->iocb_flag & LPFC_IO_LIBDFC)\r\nndlp = iocbq->context_un.ndlp;\r\nelse\r\nndlp = (struct lpfc_nodelist *)iocbq->context1;\r\nif (!iocbq->iocb.ulpLe) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2007 Only Limited Edition cmd Format"\r\n" supported 0x%x\n",\r\niocbq->iocb.ulpCommand);\r\nreturn IOCB_ERROR;\r\n}\r\nwqe->els_req.payload_len = xmit_len;\r\nbf_set(wqe_tmo, &wqe->els_req.wqe_com,\r\niocbq->iocb.ulpTimeout);\r\nbf_set(els_req64_vf, &wqe->els_req, 0);\r\nbf_set(els_req64_vfid, &wqe->els_req, 0);\r\nct = ((iocbq->iocb.ulpCt_h << 1) | iocbq->iocb.ulpCt_l);\r\nbf_set(wqe_ctxt_tag, &wqe->els_req.wqe_com,\r\niocbq->iocb.ulpContext);\r\nbf_set(wqe_ct, &wqe->els_req.wqe_com, ct);\r\nbf_set(wqe_pu, &wqe->els_req.wqe_com, 0);\r\nif (command_type == ELS_COMMAND_FIP)\r\nels_id = ((iocbq->iocb_flag & LPFC_FIP_ELS_ID_MASK)\r\n>> LPFC_FIP_ELS_ID_SHIFT);\r\npcmd = (uint32_t *) (((struct lpfc_dmabuf *)\r\niocbq->context2)->virt);\r\nif_type = bf_get(lpfc_sli_intf_if_type,\r\n&phba->sli4_hba.sli_intf);\r\nif (if_type == LPFC_SLI_INTF_IF_TYPE_2) {\r\nif (pcmd && (*pcmd == ELS_CMD_FLOGI ||\r\n*pcmd == ELS_CMD_SCR ||\r\n*pcmd == ELS_CMD_FDISC ||\r\n*pcmd == ELS_CMD_LOGO ||\r\n*pcmd == ELS_CMD_PLOGI)) {\r\nbf_set(els_req64_sp, &wqe->els_req, 1);\r\nbf_set(els_req64_sid, &wqe->els_req,\r\niocbq->vport->fc_myDID);\r\nif ((*pcmd == ELS_CMD_FLOGI) &&\r\n!(phba->fc_topology ==\r\nLPFC_TOPOLOGY_LOOP))\r\nbf_set(els_req64_sid, &wqe->els_req, 0);\r\nbf_set(wqe_ct, &wqe->els_req.wqe_com, 1);\r\nbf_set(wqe_ctxt_tag, &wqe->els_req.wqe_com,\r\nphba->vpi_ids[iocbq->vport->vpi]);\r\n} else if (pcmd && iocbq->context1) {\r\nbf_set(wqe_ct, &wqe->els_req.wqe_com, 0);\r\nbf_set(wqe_ctxt_tag, &wqe->els_req.wqe_com,\r\nphba->sli4_hba.rpi_ids[ndlp->nlp_rpi]);\r\n}\r\n}\r\nbf_set(wqe_temp_rpi, &wqe->els_req.wqe_com,\r\nphba->sli4_hba.rpi_ids[ndlp->nlp_rpi]);\r\nbf_set(wqe_els_id, &wqe->els_req.wqe_com, els_id);\r\nbf_set(wqe_dbde, &wqe->els_req.wqe_com, 1);\r\nbf_set(wqe_iod, &wqe->els_req.wqe_com, LPFC_WQE_IOD_READ);\r\nbf_set(wqe_qosd, &wqe->els_req.wqe_com, 1);\r\nbf_set(wqe_lenloc, &wqe->els_req.wqe_com, LPFC_WQE_LENLOC_NONE);\r\nbf_set(wqe_ebde_cnt, &wqe->els_req.wqe_com, 0);\r\nwqe->els_req.max_response_payload_len = total_len - xmit_len;\r\nbreak;\r\ncase CMD_XMIT_SEQUENCE64_CX:\r\nbf_set(wqe_ctxt_tag, &wqe->xmit_sequence.wqe_com,\r\niocbq->iocb.un.ulpWord[3]);\r\nbf_set(wqe_rcvoxid, &wqe->xmit_sequence.wqe_com,\r\niocbq->iocb.unsli3.rcvsli3.ox_id);\r\nxmit_len = total_len;\r\ncmnd = CMD_XMIT_SEQUENCE64_CR;\r\nif (phba->link_flag & LS_LOOPBACK_MODE)\r\nbf_set(wqe_xo, &wqe->xmit_sequence.wge_ctl, 1);\r\ncase CMD_XMIT_SEQUENCE64_CR:\r\nwqe->xmit_sequence.rsvd3 = 0;\r\nbf_set(wqe_pu, &wqe->xmit_sequence.wqe_com, 0);\r\nbf_set(wqe_dbde, &wqe->xmit_sequence.wqe_com, 1);\r\nbf_set(wqe_iod, &wqe->xmit_sequence.wqe_com,\r\nLPFC_WQE_IOD_WRITE);\r\nbf_set(wqe_lenloc, &wqe->xmit_sequence.wqe_com,\r\nLPFC_WQE_LENLOC_WORD12);\r\nbf_set(wqe_ebde_cnt, &wqe->xmit_sequence.wqe_com, 0);\r\nwqe->xmit_sequence.xmit_len = xmit_len;\r\ncommand_type = OTHER_COMMAND;\r\nbreak;\r\ncase CMD_XMIT_BCAST64_CN:\r\nwqe->xmit_bcast64.seq_payload_len = xmit_len;\r\nbf_set(wqe_ct, &wqe->xmit_bcast64.wqe_com,\r\n((iocbq->iocb.ulpCt_h << 1) | iocbq->iocb.ulpCt_l));\r\nbf_set(wqe_dbde, &wqe->xmit_bcast64.wqe_com, 1);\r\nbf_set(wqe_iod, &wqe->xmit_bcast64.wqe_com, LPFC_WQE_IOD_WRITE);\r\nbf_set(wqe_lenloc, &wqe->xmit_bcast64.wqe_com,\r\nLPFC_WQE_LENLOC_WORD3);\r\nbf_set(wqe_ebde_cnt, &wqe->xmit_bcast64.wqe_com, 0);\r\nbreak;\r\ncase CMD_FCP_IWRITE64_CR:\r\ncommand_type = FCP_COMMAND_DATA_OUT;\r\nbf_set(payload_offset_len, &wqe->fcp_iwrite,\r\nxmit_len + sizeof(struct fcp_rsp));\r\nbf_set(cmd_buff_len, &wqe->fcp_iwrite,\r\n0);\r\nbf_set(wqe_erp, &wqe->fcp_iwrite.wqe_com,\r\niocbq->iocb.ulpFCP2Rcvy);\r\nbf_set(wqe_lnk, &wqe->fcp_iwrite.wqe_com, iocbq->iocb.ulpXS);\r\nbf_set(wqe_xc, &wqe->fcp_iwrite.wqe_com, 0);\r\nbf_set(wqe_iod, &wqe->fcp_iwrite.wqe_com, LPFC_WQE_IOD_WRITE);\r\nbf_set(wqe_lenloc, &wqe->fcp_iwrite.wqe_com,\r\nLPFC_WQE_LENLOC_WORD4);\r\nbf_set(wqe_ebde_cnt, &wqe->fcp_iwrite.wqe_com, 0);\r\nbf_set(wqe_pu, &wqe->fcp_iwrite.wqe_com, iocbq->iocb.ulpPU);\r\nbf_set(wqe_dbde, &wqe->fcp_iwrite.wqe_com, 1);\r\nif (iocbq->iocb_flag & LPFC_IO_OAS) {\r\nbf_set(wqe_oas, &wqe->fcp_iwrite.wqe_com, 1);\r\nif (phba->cfg_XLanePriority) {\r\nbf_set(wqe_ccpe, &wqe->fcp_iwrite.wqe_com, 1);\r\nbf_set(wqe_ccp, &wqe->fcp_iwrite.wqe_com,\r\n(phba->cfg_XLanePriority << 1));\r\n}\r\n}\r\nbreak;\r\ncase CMD_FCP_IREAD64_CR:\r\nbf_set(payload_offset_len, &wqe->fcp_iread,\r\nxmit_len + sizeof(struct fcp_rsp));\r\nbf_set(cmd_buff_len, &wqe->fcp_iread,\r\n0);\r\nbf_set(wqe_erp, &wqe->fcp_iread.wqe_com,\r\niocbq->iocb.ulpFCP2Rcvy);\r\nbf_set(wqe_lnk, &wqe->fcp_iread.wqe_com, iocbq->iocb.ulpXS);\r\nbf_set(wqe_xc, &wqe->fcp_iread.wqe_com, 0);\r\nbf_set(wqe_iod, &wqe->fcp_iread.wqe_com, LPFC_WQE_IOD_READ);\r\nbf_set(wqe_lenloc, &wqe->fcp_iread.wqe_com,\r\nLPFC_WQE_LENLOC_WORD4);\r\nbf_set(wqe_ebde_cnt, &wqe->fcp_iread.wqe_com, 0);\r\nbf_set(wqe_pu, &wqe->fcp_iread.wqe_com, iocbq->iocb.ulpPU);\r\nbf_set(wqe_dbde, &wqe->fcp_iread.wqe_com, 1);\r\nif (iocbq->iocb_flag & LPFC_IO_OAS) {\r\nbf_set(wqe_oas, &wqe->fcp_iread.wqe_com, 1);\r\nif (phba->cfg_XLanePriority) {\r\nbf_set(wqe_ccpe, &wqe->fcp_iread.wqe_com, 1);\r\nbf_set(wqe_ccp, &wqe->fcp_iread.wqe_com,\r\n(phba->cfg_XLanePriority << 1));\r\n}\r\n}\r\nbreak;\r\ncase CMD_FCP_ICMND64_CR:\r\nbf_set(payload_offset_len, &wqe->fcp_icmd,\r\nxmit_len + sizeof(struct fcp_rsp));\r\nbf_set(cmd_buff_len, &wqe->fcp_icmd,\r\n0);\r\nbf_set(wqe_pu, &wqe->fcp_icmd.wqe_com, 0);\r\nbf_set(wqe_xc, &wqe->fcp_icmd.wqe_com, 0);\r\nbf_set(wqe_dbde, &wqe->fcp_icmd.wqe_com, 1);\r\nbf_set(wqe_iod, &wqe->fcp_icmd.wqe_com, LPFC_WQE_IOD_WRITE);\r\nbf_set(wqe_qosd, &wqe->fcp_icmd.wqe_com, 1);\r\nbf_set(wqe_lenloc, &wqe->fcp_icmd.wqe_com,\r\nLPFC_WQE_LENLOC_NONE);\r\nbf_set(wqe_ebde_cnt, &wqe->fcp_icmd.wqe_com, 0);\r\nbf_set(wqe_erp, &wqe->fcp_icmd.wqe_com,\r\niocbq->iocb.ulpFCP2Rcvy);\r\nif (iocbq->iocb_flag & LPFC_IO_OAS) {\r\nbf_set(wqe_oas, &wqe->fcp_icmd.wqe_com, 1);\r\nif (phba->cfg_XLanePriority) {\r\nbf_set(wqe_ccpe, &wqe->fcp_icmd.wqe_com, 1);\r\nbf_set(wqe_ccp, &wqe->fcp_icmd.wqe_com,\r\n(phba->cfg_XLanePriority << 1));\r\n}\r\n}\r\nbreak;\r\ncase CMD_GEN_REQUEST64_CR:\r\nxmit_len = 0;\r\nnumBdes = iocbq->iocb.un.genreq64.bdl.bdeSize /\r\nsizeof(struct ulp_bde64);\r\nfor (i = 0; i < numBdes; i++) {\r\nbde.tus.w = le32_to_cpu(bpl[i].tus.w);\r\nif (bde.tus.f.bdeFlags != BUFF_TYPE_BDE_64)\r\nbreak;\r\nxmit_len += bde.tus.f.bdeSize;\r\n}\r\nwqe->gen_req.request_payload_len = xmit_len;\r\nif (iocbq->iocb.ulpCt_h || iocbq->iocb.ulpCt_l) {\r\nct = ((iocbq->iocb.ulpCt_h << 1) | iocbq->iocb.ulpCt_l);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2015 Invalid CT %x command 0x%x\n",\r\nct, iocbq->iocb.ulpCommand);\r\nreturn IOCB_ERROR;\r\n}\r\nbf_set(wqe_ct, &wqe->gen_req.wqe_com, 0);\r\nbf_set(wqe_tmo, &wqe->gen_req.wqe_com, iocbq->iocb.ulpTimeout);\r\nbf_set(wqe_pu, &wqe->gen_req.wqe_com, iocbq->iocb.ulpPU);\r\nbf_set(wqe_dbde, &wqe->gen_req.wqe_com, 1);\r\nbf_set(wqe_iod, &wqe->gen_req.wqe_com, LPFC_WQE_IOD_READ);\r\nbf_set(wqe_qosd, &wqe->gen_req.wqe_com, 1);\r\nbf_set(wqe_lenloc, &wqe->gen_req.wqe_com, LPFC_WQE_LENLOC_NONE);\r\nbf_set(wqe_ebde_cnt, &wqe->gen_req.wqe_com, 0);\r\nwqe->gen_req.max_response_payload_len = total_len - xmit_len;\r\ncommand_type = OTHER_COMMAND;\r\nbreak;\r\ncase CMD_XMIT_ELS_RSP64_CX:\r\nndlp = (struct lpfc_nodelist *)iocbq->context1;\r\nwqe->xmit_els_rsp.response_payload_len = xmit_len;\r\nwqe->xmit_els_rsp.word4 = 0;\r\nbf_set(wqe_els_did, &wqe->xmit_els_rsp.wqe_dest,\r\niocbq->iocb.un.xseq64.xmit_els_remoteID);\r\nif_type = bf_get(lpfc_sli_intf_if_type,\r\n&phba->sli4_hba.sli_intf);\r\nif (if_type == LPFC_SLI_INTF_IF_TYPE_2) {\r\nif (iocbq->vport->fc_flag & FC_PT2PT) {\r\nbf_set(els_rsp64_sp, &wqe->xmit_els_rsp, 1);\r\nbf_set(els_rsp64_sid, &wqe->xmit_els_rsp,\r\niocbq->vport->fc_myDID);\r\nif (iocbq->vport->fc_myDID == Fabric_DID) {\r\nbf_set(wqe_els_did,\r\n&wqe->xmit_els_rsp.wqe_dest, 0);\r\n}\r\n}\r\n}\r\nbf_set(wqe_ct, &wqe->xmit_els_rsp.wqe_com,\r\n((iocbq->iocb.ulpCt_h << 1) | iocbq->iocb.ulpCt_l));\r\nbf_set(wqe_pu, &wqe->xmit_els_rsp.wqe_com, iocbq->iocb.ulpPU);\r\nbf_set(wqe_rcvoxid, &wqe->xmit_els_rsp.wqe_com,\r\niocbq->iocb.unsli3.rcvsli3.ox_id);\r\nif (!iocbq->iocb.ulpCt_h && iocbq->iocb.ulpCt_l)\r\nbf_set(wqe_ctxt_tag, &wqe->xmit_els_rsp.wqe_com,\r\nphba->vpi_ids[iocbq->vport->vpi]);\r\nbf_set(wqe_dbde, &wqe->xmit_els_rsp.wqe_com, 1);\r\nbf_set(wqe_iod, &wqe->xmit_els_rsp.wqe_com, LPFC_WQE_IOD_WRITE);\r\nbf_set(wqe_qosd, &wqe->xmit_els_rsp.wqe_com, 1);\r\nbf_set(wqe_lenloc, &wqe->xmit_els_rsp.wqe_com,\r\nLPFC_WQE_LENLOC_WORD3);\r\nbf_set(wqe_ebde_cnt, &wqe->xmit_els_rsp.wqe_com, 0);\r\nbf_set(wqe_rsp_temp_rpi, &wqe->xmit_els_rsp,\r\nphba->sli4_hba.rpi_ids[ndlp->nlp_rpi]);\r\npcmd = (uint32_t *) (((struct lpfc_dmabuf *)\r\niocbq->context2)->virt);\r\nif (phba->fc_topology == LPFC_TOPOLOGY_LOOP) {\r\nbf_set(els_rsp64_sp, &wqe->xmit_els_rsp, 1);\r\nbf_set(els_rsp64_sid, &wqe->xmit_els_rsp,\r\niocbq->vport->fc_myDID);\r\nbf_set(wqe_ct, &wqe->xmit_els_rsp.wqe_com, 1);\r\nbf_set(wqe_ctxt_tag, &wqe->xmit_els_rsp.wqe_com,\r\nphba->vpi_ids[phba->pport->vpi]);\r\n}\r\ncommand_type = OTHER_COMMAND;\r\nbreak;\r\ncase CMD_CLOSE_XRI_CN:\r\ncase CMD_ABORT_XRI_CN:\r\ncase CMD_ABORT_XRI_CX:\r\nabrt_iotag = iocbq->iocb.un.acxri.abortContextTag;\r\nif (abrt_iotag != 0 && abrt_iotag <= phba->sli.last_iotag) {\r\nabrtiocbq = phba->sli.iocbq_lookup[abrt_iotag];\r\nfip = abrtiocbq->iocb_flag & LPFC_FIP_ELS_ID_MASK;\r\n} else\r\nfip = 0;\r\nif ((iocbq->iocb.ulpCommand == CMD_CLOSE_XRI_CN) || fip)\r\nbf_set(abort_cmd_ia, &wqe->abort_cmd, 1);\r\nelse\r\nbf_set(abort_cmd_ia, &wqe->abort_cmd, 0);\r\nbf_set(abort_cmd_criteria, &wqe->abort_cmd, T_XRI_TAG);\r\nwqe->abort_cmd.rsrvd5 = 0;\r\nbf_set(wqe_ct, &wqe->abort_cmd.wqe_com,\r\n((iocbq->iocb.ulpCt_h << 1) | iocbq->iocb.ulpCt_l));\r\nabort_tag = iocbq->iocb.un.acxri.abortIoTag;\r\nbf_set(wqe_cmnd, &wqe->abort_cmd.wqe_com, CMD_ABORT_XRI_CX);\r\nbf_set(wqe_qosd, &wqe->abort_cmd.wqe_com, 1);\r\nbf_set(wqe_lenloc, &wqe->abort_cmd.wqe_com,\r\nLPFC_WQE_LENLOC_NONE);\r\ncmnd = CMD_ABORT_XRI_CX;\r\ncommand_type = OTHER_COMMAND;\r\nxritag = 0;\r\nbreak;\r\ncase CMD_XMIT_BLS_RSP64_CX:\r\nndlp = (struct lpfc_nodelist *)iocbq->context1;\r\nmemset(wqe, 0, sizeof(union lpfc_wqe));\r\nbf_set(xmit_bls_rsp64_oxid, &wqe->xmit_bls_rsp,\r\nbf_get(lpfc_abts_oxid, &iocbq->iocb.un.bls_rsp));\r\nif (bf_get(lpfc_abts_orig, &iocbq->iocb.un.bls_rsp) ==\r\nLPFC_ABTS_UNSOL_INT) {\r\nbf_set(xmit_bls_rsp64_rxid, &wqe->xmit_bls_rsp,\r\niocbq->sli4_xritag);\r\n} else {\r\nbf_set(xmit_bls_rsp64_rxid, &wqe->xmit_bls_rsp,\r\nbf_get(lpfc_abts_rxid, &iocbq->iocb.un.bls_rsp));\r\n}\r\nbf_set(xmit_bls_rsp64_seqcnthi, &wqe->xmit_bls_rsp, 0xffff);\r\nbf_set(wqe_xmit_bls_pt, &wqe->xmit_bls_rsp.wqe_dest, 0x1);\r\nbf_set(wqe_els_did, &wqe->xmit_bls_rsp.wqe_dest,\r\nndlp->nlp_DID);\r\nbf_set(xmit_bls_rsp64_temprpi, &wqe->xmit_bls_rsp,\r\niocbq->iocb.ulpContext);\r\nbf_set(wqe_ct, &wqe->xmit_bls_rsp.wqe_com, 1);\r\nbf_set(wqe_ctxt_tag, &wqe->xmit_bls_rsp.wqe_com,\r\nphba->vpi_ids[phba->pport->vpi]);\r\nbf_set(wqe_qosd, &wqe->xmit_bls_rsp.wqe_com, 1);\r\nbf_set(wqe_lenloc, &wqe->xmit_bls_rsp.wqe_com,\r\nLPFC_WQE_LENLOC_NONE);\r\ncommand_type = OTHER_COMMAND;\r\nif (iocbq->iocb.un.xseq64.w5.hcsw.Rctl == FC_RCTL_BA_RJT) {\r\nbf_set(xmit_bls_rsp64_rjt_vspec, &wqe->xmit_bls_rsp,\r\nbf_get(lpfc_vndr_code, &iocbq->iocb.un.bls_rsp));\r\nbf_set(xmit_bls_rsp64_rjt_expc, &wqe->xmit_bls_rsp,\r\nbf_get(lpfc_rsn_expln, &iocbq->iocb.un.bls_rsp));\r\nbf_set(xmit_bls_rsp64_rjt_rsnc, &wqe->xmit_bls_rsp,\r\nbf_get(lpfc_rsn_code, &iocbq->iocb.un.bls_rsp));\r\n}\r\nbreak;\r\ncase CMD_XRI_ABORTED_CX:\r\ncase CMD_CREATE_XRI_CR:\r\ncase CMD_IOCB_FCP_IBIDIR64_CR:\r\ncase CMD_FCP_TSEND64_CX:\r\ncase CMD_FCP_TRSP64_CX:\r\ncase CMD_FCP_AUTO_TRSP_CX:\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2014 Invalid command 0x%x\n",\r\niocbq->iocb.ulpCommand);\r\nreturn IOCB_ERROR;\r\nbreak;\r\n}\r\nif (iocbq->iocb_flag & LPFC_IO_DIF_PASS)\r\nbf_set(wqe_dif, &wqe->generic.wqe_com, LPFC_WQE_DIF_PASSTHRU);\r\nelse if (iocbq->iocb_flag & LPFC_IO_DIF_STRIP)\r\nbf_set(wqe_dif, &wqe->generic.wqe_com, LPFC_WQE_DIF_STRIP);\r\nelse if (iocbq->iocb_flag & LPFC_IO_DIF_INSERT)\r\nbf_set(wqe_dif, &wqe->generic.wqe_com, LPFC_WQE_DIF_INSERT);\r\niocbq->iocb_flag &= ~(LPFC_IO_DIF_PASS | LPFC_IO_DIF_STRIP |\r\nLPFC_IO_DIF_INSERT);\r\nbf_set(wqe_xri_tag, &wqe->generic.wqe_com, xritag);\r\nbf_set(wqe_reqtag, &wqe->generic.wqe_com, iocbq->iotag);\r\nwqe->generic.wqe_com.abort_tag = abort_tag;\r\nbf_set(wqe_cmd_type, &wqe->generic.wqe_com, command_type);\r\nbf_set(wqe_cmnd, &wqe->generic.wqe_com, cmnd);\r\nbf_set(wqe_class, &wqe->generic.wqe_com, iocbq->iocb.ulpClass);\r\nbf_set(wqe_cqid, &wqe->generic.wqe_com, LPFC_WQE_CQ_ID_DEFAULT);\r\nreturn 0;\r\n}\r\nstatic int\r\n__lpfc_sli_issue_iocb_s4(struct lpfc_hba *phba, uint32_t ring_number,\r\nstruct lpfc_iocbq *piocb, uint32_t flag)\r\n{\r\nstruct lpfc_sglq *sglq;\r\nunion lpfc_wqe wqe;\r\nstruct lpfc_queue *wq;\r\nstruct lpfc_sli_ring *pring = &phba->sli.ring[ring_number];\r\nif (piocb->sli4_xritag == NO_XRI) {\r\nif (piocb->iocb.ulpCommand == CMD_ABORT_XRI_CN ||\r\npiocb->iocb.ulpCommand == CMD_CLOSE_XRI_CN)\r\nsglq = NULL;\r\nelse {\r\nif (!list_empty(&pring->txq)) {\r\nif (!(flag & SLI_IOCB_RET_IOCB)) {\r\n__lpfc_sli_ringtx_put(phba,\r\npring, piocb);\r\nreturn IOCB_SUCCESS;\r\n} else {\r\nreturn IOCB_BUSY;\r\n}\r\n} else {\r\nsglq = __lpfc_sli_get_sglq(phba, piocb);\r\nif (!sglq) {\r\nif (!(flag & SLI_IOCB_RET_IOCB)) {\r\n__lpfc_sli_ringtx_put(phba,\r\npring,\r\npiocb);\r\nreturn IOCB_SUCCESS;\r\n} else\r\nreturn IOCB_BUSY;\r\n}\r\n}\r\n}\r\n} else if (piocb->iocb_flag & LPFC_IO_FCP) {\r\nsglq = NULL;\r\n} else {\r\nsglq = __lpfc_get_active_sglq(phba, piocb->sli4_lxritag);\r\nif (!sglq)\r\nreturn IOCB_ERROR;\r\n}\r\nif (sglq) {\r\npiocb->sli4_lxritag = sglq->sli4_lxritag;\r\npiocb->sli4_xritag = sglq->sli4_xritag;\r\nif (NO_XRI == lpfc_sli4_bpl2sgl(phba, piocb, sglq))\r\nreturn IOCB_ERROR;\r\n}\r\nif (lpfc_sli4_iocb2wqe(phba, piocb, &wqe))\r\nreturn IOCB_ERROR;\r\nif ((piocb->iocb_flag & LPFC_IO_FCP) ||\r\n(piocb->iocb_flag & LPFC_USE_FCPWQIDX)) {\r\nif (!phba->cfg_fof || (!(piocb->iocb_flag & LPFC_IO_OAS))) {\r\nwq = phba->sli4_hba.fcp_wq[piocb->fcp_wqidx];\r\n} else {\r\nwq = phba->sli4_hba.oas_wq;\r\n}\r\nif (lpfc_sli4_wq_put(wq, &wqe))\r\nreturn IOCB_ERROR;\r\n} else {\r\nif (unlikely(!phba->sli4_hba.els_wq))\r\nreturn IOCB_ERROR;\r\nif (lpfc_sli4_wq_put(phba->sli4_hba.els_wq, &wqe))\r\nreturn IOCB_ERROR;\r\n}\r\nlpfc_sli_ringtxcmpl_put(phba, pring, piocb);\r\nreturn 0;\r\n}\r\nint\r\n__lpfc_sli_issue_iocb(struct lpfc_hba *phba, uint32_t ring_number,\r\nstruct lpfc_iocbq *piocb, uint32_t flag)\r\n{\r\nreturn phba->__lpfc_sli_issue_iocb(phba, ring_number, piocb, flag);\r\n}\r\nint\r\nlpfc_sli_api_table_setup(struct lpfc_hba *phba, uint8_t dev_grp)\r\n{\r\nswitch (dev_grp) {\r\ncase LPFC_PCI_DEV_LP:\r\nphba->__lpfc_sli_issue_iocb = __lpfc_sli_issue_iocb_s3;\r\nphba->__lpfc_sli_release_iocbq = __lpfc_sli_release_iocbq_s3;\r\nbreak;\r\ncase LPFC_PCI_DEV_OC:\r\nphba->__lpfc_sli_issue_iocb = __lpfc_sli_issue_iocb_s4;\r\nphba->__lpfc_sli_release_iocbq = __lpfc_sli_release_iocbq_s4;\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"1419 Invalid HBA PCI-device group: 0x%x\n",\r\ndev_grp);\r\nreturn -ENODEV;\r\nbreak;\r\n}\r\nphba->lpfc_get_iocb_from_iocbq = lpfc_get_iocb_from_iocbq;\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli_calc_ring(struct lpfc_hba *phba, uint32_t ring_number,\r\nstruct lpfc_iocbq *piocb)\r\n{\r\nif (phba->sli_rev < LPFC_SLI_REV4)\r\nreturn ring_number;\r\nif (piocb->iocb_flag & (LPFC_IO_FCP | LPFC_USE_FCPWQIDX)) {\r\nif (!(phba->cfg_fof) ||\r\n(!(piocb->iocb_flag & LPFC_IO_FOF))) {\r\nif (unlikely(!phba->sli4_hba.fcp_wq))\r\nreturn LPFC_HBA_ERROR;\r\nif (!(piocb->iocb_flag & LPFC_USE_FCPWQIDX))\r\npiocb->fcp_wqidx =\r\nlpfc_sli4_scmd_to_wqidx_distr(phba,\r\npiocb->context1);\r\nring_number = MAX_SLI3_CONFIGURED_RINGS +\r\npiocb->fcp_wqidx;\r\n} else {\r\nif (unlikely(!phba->sli4_hba.oas_wq))\r\nreturn LPFC_HBA_ERROR;\r\npiocb->fcp_wqidx = 0;\r\nring_number = LPFC_FCP_OAS_RING;\r\n}\r\n}\r\nreturn ring_number;\r\n}\r\nint\r\nlpfc_sli_issue_iocb(struct lpfc_hba *phba, uint32_t ring_number,\r\nstruct lpfc_iocbq *piocb, uint32_t flag)\r\n{\r\nstruct lpfc_fcp_eq_hdl *fcp_eq_hdl;\r\nstruct lpfc_sli_ring *pring;\r\nstruct lpfc_queue *fpeq;\r\nstruct lpfc_eqe *eqe;\r\nunsigned long iflags;\r\nint rc, idx;\r\nif (phba->sli_rev == LPFC_SLI_REV4) {\r\nring_number = lpfc_sli_calc_ring(phba, ring_number, piocb);\r\nif (unlikely(ring_number == LPFC_HBA_ERROR))\r\nreturn IOCB_ERROR;\r\nidx = piocb->fcp_wqidx;\r\npring = &phba->sli.ring[ring_number];\r\nspin_lock_irqsave(&pring->ring_lock, iflags);\r\nrc = __lpfc_sli_issue_iocb(phba, ring_number, piocb, flag);\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\nif (lpfc_fcp_look_ahead && (piocb->iocb_flag & LPFC_IO_FCP)) {\r\nfcp_eq_hdl = &phba->sli4_hba.fcp_eq_hdl[idx];\r\nif (atomic_dec_and_test(&fcp_eq_hdl->\r\nfcp_eq_in_use)) {\r\nfpeq = phba->sli4_hba.hba_eq[idx];\r\nlpfc_sli4_eq_clr_intr(fpeq);\r\nwhile ((eqe = lpfc_sli4_eq_get(fpeq))) {\r\nlpfc_sli4_hba_handle_eqe(phba,\r\neqe, idx);\r\nfpeq->EQ_processed++;\r\n}\r\nlpfc_sli4_eq_release(fpeq,\r\nLPFC_QUEUE_REARM);\r\n}\r\natomic_inc(&fcp_eq_hdl->fcp_eq_in_use);\r\n}\r\n} else {\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nrc = __lpfc_sli_issue_iocb(phba, ring_number, piocb, flag);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\n}\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_extra_ring_setup( struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli;\r\nstruct lpfc_sli_ring *pring;\r\npsli = &phba->sli;\r\npring = &psli->ring[psli->fcp_ring];\r\npring->sli.sli3.numCiocb -= SLI2_IOCB_CMD_R1XTRA_ENTRIES;\r\npring->sli.sli3.numRiocb -= SLI2_IOCB_RSP_R1XTRA_ENTRIES;\r\npring->sli.sli3.numCiocb -= SLI2_IOCB_CMD_R3XTRA_ENTRIES;\r\npring->sli.sli3.numRiocb -= SLI2_IOCB_RSP_R3XTRA_ENTRIES;\r\npring = &psli->ring[psli->extra_ring];\r\npring->sli.sli3.numCiocb += SLI2_IOCB_CMD_R1XTRA_ENTRIES;\r\npring->sli.sli3.numRiocb += SLI2_IOCB_RSP_R1XTRA_ENTRIES;\r\npring->sli.sli3.numCiocb += SLI2_IOCB_CMD_R3XTRA_ENTRIES;\r\npring->sli.sli3.numRiocb += SLI2_IOCB_RSP_R3XTRA_ENTRIES;\r\npring->iotag_max = 4096;\r\npring->num_mask = 1;\r\npring->prt[0].profile = 0;\r\npring->prt[0].rctl = phba->cfg_multi_ring_rctl;\r\npring->prt[0].type = phba->cfg_multi_ring_type;\r\npring->prt[0].lpfc_sli_rcv_unsol_event = NULL;\r\nreturn 0;\r\n}\r\nstatic void\r\nlpfc_sli_abts_err_handler(struct lpfc_hba *phba,\r\nstruct lpfc_iocbq *iocbq)\r\n{\r\nstruct lpfc_nodelist *ndlp = NULL;\r\nuint16_t rpi = 0, vpi = 0;\r\nstruct lpfc_vport *vport = NULL;\r\nvpi = iocbq->iocb.un.asyncstat.sub_ctxt_tag;\r\nrpi = iocbq->iocb.ulpContext;\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"3092 Port generated ABTS async event "\r\n"on vpi %d rpi %d status 0x%x\n",\r\nvpi, rpi, iocbq->iocb.ulpStatus);\r\nvport = lpfc_find_vport_by_vpid(phba, vpi);\r\nif (!vport)\r\ngoto err_exit;\r\nndlp = lpfc_findnode_rpi(vport, rpi);\r\nif (!ndlp || !NLP_CHK_NODE_ACT(ndlp))\r\ngoto err_exit;\r\nif (iocbq->iocb.ulpStatus == IOSTAT_LOCAL_REJECT)\r\nlpfc_sli_abts_recover_port(vport, ndlp);\r\nreturn;\r\nerr_exit:\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"3095 Event Context not found, no "\r\n"action on vpi %d rpi %d status 0x%x, reason 0x%x\n",\r\niocbq->iocb.ulpContext, iocbq->iocb.ulpStatus,\r\nvpi, rpi);\r\n}\r\nvoid\r\nlpfc_sli4_abts_err_handler(struct lpfc_hba *phba,\r\nstruct lpfc_nodelist *ndlp,\r\nstruct sli4_wcqe_xri_aborted *axri)\r\n{\r\nstruct lpfc_vport *vport;\r\nuint32_t ext_status = 0;\r\nif (!ndlp || !NLP_CHK_NODE_ACT(ndlp)) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"3115 Node Context not found, driver "\r\n"ignoring abts err event\n");\r\nreturn;\r\n}\r\nvport = ndlp->vport;\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"3116 Port generated FCP XRI ABORT event on "\r\n"vpi %d rpi %d xri x%x status 0x%x parameter x%x\n",\r\nndlp->vport->vpi, phba->sli4_hba.rpi_ids[ndlp->nlp_rpi],\r\nbf_get(lpfc_wcqe_xa_xri, axri),\r\nbf_get(lpfc_wcqe_xa_status, axri),\r\naxri->parameter);\r\next_status = axri->parameter & IOERR_PARAM_MASK;\r\nif ((bf_get(lpfc_wcqe_xa_status, axri) == IOSTAT_LOCAL_REJECT) &&\r\n((ext_status == IOERR_SEQUENCE_TIMEOUT) || (ext_status == 0)))\r\nlpfc_sli_abts_recover_port(vport, ndlp);\r\n}\r\nstatic void\r\nlpfc_sli_async_event_handler(struct lpfc_hba * phba,\r\nstruct lpfc_sli_ring * pring, struct lpfc_iocbq * iocbq)\r\n{\r\nIOCB_t *icmd;\r\nuint16_t evt_code;\r\nstruct temp_event temp_event_data;\r\nstruct Scsi_Host *shost;\r\nuint32_t *iocb_w;\r\nicmd = &iocbq->iocb;\r\nevt_code = icmd->un.asyncstat.evt_code;\r\nswitch (evt_code) {\r\ncase ASYNC_TEMP_WARN:\r\ncase ASYNC_TEMP_SAFE:\r\ntemp_event_data.data = (uint32_t) icmd->ulpContext;\r\ntemp_event_data.event_type = FC_REG_TEMPERATURE_EVENT;\r\nif (evt_code == ASYNC_TEMP_WARN) {\r\ntemp_event_data.event_code = LPFC_THRESHOLD_TEMP;\r\nlpfc_printf_log(phba, KERN_ERR, LOG_TEMP,\r\n"0347 Adapter is very hot, please take "\r\n"corrective action. temperature : %d Celsius\n",\r\n(uint32_t) icmd->ulpContext);\r\n} else {\r\ntemp_event_data.event_code = LPFC_NORMAL_TEMP;\r\nlpfc_printf_log(phba, KERN_ERR, LOG_TEMP,\r\n"0340 Adapter temperature is OK now. "\r\n"temperature : %d Celsius\n",\r\n(uint32_t) icmd->ulpContext);\r\n}\r\nshost = lpfc_shost_from_vport(phba->pport);\r\nfc_host_post_vendor_event(shost, fc_get_event_number(),\r\nsizeof(temp_event_data), (char *) &temp_event_data,\r\nLPFC_NL_VENDOR_ID);\r\nbreak;\r\ncase ASYNC_STATUS_CN:\r\nlpfc_sli_abts_err_handler(phba, iocbq);\r\nbreak;\r\ndefault:\r\niocb_w = (uint32_t *) icmd;\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0346 Ring %d handler: unexpected ASYNC_STATUS"\r\n" evt_code 0x%x\n"\r\n"W0 0x%08x W1 0x%08x W2 0x%08x W3 0x%08x\n"\r\n"W4 0x%08x W5 0x%08x W6 0x%08x W7 0x%08x\n"\r\n"W8 0x%08x W9 0x%08x W10 0x%08x W11 0x%08x\n"\r\n"W12 0x%08x W13 0x%08x W14 0x%08x W15 0x%08x\n",\r\npring->ringno, icmd->un.asyncstat.evt_code,\r\niocb_w[0], iocb_w[1], iocb_w[2], iocb_w[3],\r\niocb_w[4], iocb_w[5], iocb_w[6], iocb_w[7],\r\niocb_w[8], iocb_w[9], iocb_w[10], iocb_w[11],\r\niocb_w[12], iocb_w[13], iocb_w[14], iocb_w[15]);\r\nbreak;\r\n}\r\n}\r\nint\r\nlpfc_sli_setup(struct lpfc_hba *phba)\r\n{\r\nint i, totiocbsize = 0;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_sli_ring *pring;\r\npsli->num_rings = MAX_SLI3_CONFIGURED_RINGS;\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\npsli->num_rings += phba->cfg_fcp_io_channel;\r\npsli->sli_flag = 0;\r\npsli->fcp_ring = LPFC_FCP_RING;\r\npsli->next_ring = LPFC_FCP_NEXT_RING;\r\npsli->extra_ring = LPFC_EXTRA_RING;\r\npsli->iocbq_lookup = NULL;\r\npsli->iocbq_lookup_len = 0;\r\npsli->last_iotag = 0;\r\nfor (i = 0; i < psli->num_rings; i++) {\r\npring = &psli->ring[i];\r\nswitch (i) {\r\ncase LPFC_FCP_RING:\r\npring->sli.sli3.numCiocb = SLI2_IOCB_CMD_R0_ENTRIES;\r\npring->sli.sli3.numRiocb = SLI2_IOCB_RSP_R0_ENTRIES;\r\npring->sli.sli3.numCiocb +=\r\nSLI2_IOCB_CMD_R1XTRA_ENTRIES;\r\npring->sli.sli3.numRiocb +=\r\nSLI2_IOCB_RSP_R1XTRA_ENTRIES;\r\npring->sli.sli3.numCiocb +=\r\nSLI2_IOCB_CMD_R3XTRA_ENTRIES;\r\npring->sli.sli3.numRiocb +=\r\nSLI2_IOCB_RSP_R3XTRA_ENTRIES;\r\npring->sli.sli3.sizeCiocb = (phba->sli_rev == 3) ?\r\nSLI3_IOCB_CMD_SIZE :\r\nSLI2_IOCB_CMD_SIZE;\r\npring->sli.sli3.sizeRiocb = (phba->sli_rev == 3) ?\r\nSLI3_IOCB_RSP_SIZE :\r\nSLI2_IOCB_RSP_SIZE;\r\npring->iotag_ctr = 0;\r\npring->iotag_max =\r\n(phba->cfg_hba_queue_depth * 2);\r\npring->fast_iotag = pring->iotag_max;\r\npring->num_mask = 0;\r\nbreak;\r\ncase LPFC_EXTRA_RING:\r\npring->sli.sli3.numCiocb = SLI2_IOCB_CMD_R1_ENTRIES;\r\npring->sli.sli3.numRiocb = SLI2_IOCB_RSP_R1_ENTRIES;\r\npring->sli.sli3.sizeCiocb = (phba->sli_rev == 3) ?\r\nSLI3_IOCB_CMD_SIZE :\r\nSLI2_IOCB_CMD_SIZE;\r\npring->sli.sli3.sizeRiocb = (phba->sli_rev == 3) ?\r\nSLI3_IOCB_RSP_SIZE :\r\nSLI2_IOCB_RSP_SIZE;\r\npring->iotag_max = phba->cfg_hba_queue_depth;\r\npring->num_mask = 0;\r\nbreak;\r\ncase LPFC_ELS_RING:\r\npring->sli.sli3.numCiocb = SLI2_IOCB_CMD_R2_ENTRIES;\r\npring->sli.sli3.numRiocb = SLI2_IOCB_RSP_R2_ENTRIES;\r\npring->sli.sli3.sizeCiocb = (phba->sli_rev == 3) ?\r\nSLI3_IOCB_CMD_SIZE :\r\nSLI2_IOCB_CMD_SIZE;\r\npring->sli.sli3.sizeRiocb = (phba->sli_rev == 3) ?\r\nSLI3_IOCB_RSP_SIZE :\r\nSLI2_IOCB_RSP_SIZE;\r\npring->fast_iotag = 0;\r\npring->iotag_ctr = 0;\r\npring->iotag_max = 4096;\r\npring->lpfc_sli_rcv_async_status =\r\nlpfc_sli_async_event_handler;\r\npring->num_mask = LPFC_MAX_RING_MASK;\r\npring->prt[0].profile = 0;\r\npring->prt[0].rctl = FC_RCTL_ELS_REQ;\r\npring->prt[0].type = FC_TYPE_ELS;\r\npring->prt[0].lpfc_sli_rcv_unsol_event =\r\nlpfc_els_unsol_event;\r\npring->prt[1].profile = 0;\r\npring->prt[1].rctl = FC_RCTL_ELS_REP;\r\npring->prt[1].type = FC_TYPE_ELS;\r\npring->prt[1].lpfc_sli_rcv_unsol_event =\r\nlpfc_els_unsol_event;\r\npring->prt[2].profile = 0;\r\npring->prt[2].rctl = FC_RCTL_DD_UNSOL_CTL;\r\npring->prt[2].type = FC_TYPE_CT;\r\npring->prt[2].lpfc_sli_rcv_unsol_event =\r\nlpfc_ct_unsol_event;\r\npring->prt[3].profile = 0;\r\npring->prt[3].rctl = FC_RCTL_DD_SOL_CTL;\r\npring->prt[3].type = FC_TYPE_CT;\r\npring->prt[3].lpfc_sli_rcv_unsol_event =\r\nlpfc_ct_unsol_event;\r\nbreak;\r\n}\r\ntotiocbsize += (pring->sli.sli3.numCiocb *\r\npring->sli.sli3.sizeCiocb) +\r\n(pring->sli.sli3.numRiocb * pring->sli.sli3.sizeRiocb);\r\n}\r\nif (totiocbsize > MAX_SLIM_IOCB_SIZE) {\r\nprintk(KERN_ERR "%d:0462 Too many cmd / rsp ring entries in "\r\n"SLI2 SLIM Data: x%x x%lx\n",\r\nphba->brd_no, totiocbsize,\r\n(unsigned long) MAX_SLIM_IOCB_SIZE);\r\n}\r\nif (phba->cfg_multi_ring_support == 2)\r\nlpfc_extra_ring_setup(phba);\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli_queue_setup(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli;\r\nstruct lpfc_sli_ring *pring;\r\nint i;\r\npsli = &phba->sli;\r\nspin_lock_irq(&phba->hbalock);\r\nINIT_LIST_HEAD(&psli->mboxq);\r\nINIT_LIST_HEAD(&psli->mboxq_cmpl);\r\nfor (i = 0; i < psli->num_rings; i++) {\r\npring = &psli->ring[i];\r\npring->ringno = i;\r\npring->sli.sli3.next_cmdidx = 0;\r\npring->sli.sli3.local_getidx = 0;\r\npring->sli.sli3.cmdidx = 0;\r\npring->flag = 0;\r\nINIT_LIST_HEAD(&pring->txq);\r\nINIT_LIST_HEAD(&pring->txcmplq);\r\nINIT_LIST_HEAD(&pring->iocb_continueq);\r\nINIT_LIST_HEAD(&pring->iocb_continue_saveq);\r\nINIT_LIST_HEAD(&pring->postbufq);\r\nspin_lock_init(&pring->ring_lock);\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 1;\r\n}\r\nstatic void\r\nlpfc_sli_mbox_sys_flush(struct lpfc_hba *phba)\r\n{\r\nLIST_HEAD(completions);\r\nstruct lpfc_sli *psli = &phba->sli;\r\nLPFC_MBOXQ_t *pmb;\r\nunsigned long iflag;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nlist_splice_init(&phba->sli.mboxq, &completions);\r\nif (psli->mbox_active) {\r\nlist_add_tail(&psli->mbox_active->list, &completions);\r\npsli->mbox_active = NULL;\r\npsli->sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\n}\r\nlist_splice_init(&phba->sli.mboxq_cmpl, &completions);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nwhile (!list_empty(&completions)) {\r\nlist_remove_head(&completions, pmb, LPFC_MBOXQ_t, list);\r\npmb->u.mb.mbxStatus = MBX_NOT_FINISHED;\r\nif (pmb->mbox_cmpl)\r\npmb->mbox_cmpl(phba, pmb);\r\n}\r\n}\r\nint\r\nlpfc_sli_host_down(struct lpfc_vport *vport)\r\n{\r\nLIST_HEAD(completions);\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_sli_ring *pring;\r\nstruct lpfc_iocbq *iocb, *next_iocb;\r\nint i;\r\nunsigned long flags = 0;\r\nuint16_t prev_pring_flag;\r\nlpfc_cleanup_discovery_resources(vport);\r\nspin_lock_irqsave(&phba->hbalock, flags);\r\nfor (i = 0; i < psli->num_rings; i++) {\r\npring = &psli->ring[i];\r\nprev_pring_flag = pring->flag;\r\nif (pring->ringno == LPFC_ELS_RING) {\r\npring->flag |= LPFC_DEFERRED_RING_EVENT;\r\nset_bit(LPFC_DATA_READY, &phba->data_flags);\r\n}\r\nlist_for_each_entry_safe(iocb, next_iocb, &pring->txq, list) {\r\nif (iocb->vport != vport)\r\ncontinue;\r\nlist_move_tail(&iocb->list, &completions);\r\n}\r\nlist_for_each_entry_safe(iocb, next_iocb, &pring->txcmplq,\r\nlist) {\r\nif (iocb->vport != vport)\r\ncontinue;\r\nlpfc_sli_issue_abort_iotag(phba, pring, iocb);\r\n}\r\npring->flag = prev_pring_flag;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_DOWN);\r\nreturn 1;\r\n}\r\nint\r\nlpfc_sli_hba_down(struct lpfc_hba *phba)\r\n{\r\nLIST_HEAD(completions);\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_sli_ring *pring;\r\nstruct lpfc_dmabuf *buf_ptr;\r\nunsigned long flags = 0;\r\nint i;\r\nlpfc_sli_mbox_sys_shutdown(phba, LPFC_MBX_WAIT);\r\nlpfc_hba_down_prep(phba);\r\nlpfc_fabric_abort_hba(phba);\r\nspin_lock_irqsave(&phba->hbalock, flags);\r\nfor (i = 0; i < psli->num_rings; i++) {\r\npring = &psli->ring[i];\r\nif (pring->ringno == LPFC_ELS_RING) {\r\npring->flag |= LPFC_DEFERRED_RING_EVENT;\r\nset_bit(LPFC_DATA_READY, &phba->data_flags);\r\n}\r\nlist_splice_init(&pring->txq, &completions);\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_DOWN);\r\nspin_lock_irqsave(&phba->hbalock, flags);\r\nlist_splice_init(&phba->elsbuf, &completions);\r\nphba->elsbuf_cnt = 0;\r\nphba->elsbuf_prev_cnt = 0;\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nwhile (!list_empty(&completions)) {\r\nlist_remove_head(&completions, buf_ptr,\r\nstruct lpfc_dmabuf, list);\r\nlpfc_mbuf_free(phba, buf_ptr->virt, buf_ptr->phys);\r\nkfree(buf_ptr);\r\n}\r\ndel_timer_sync(&psli->mbox_tmo);\r\nspin_lock_irqsave(&phba->pport->work_port_lock, flags);\r\nphba->pport->work_port_events &= ~WORKER_MBOX_TMO;\r\nspin_unlock_irqrestore(&phba->pport->work_port_lock, flags);\r\nreturn 1;\r\n}\r\nvoid\r\nlpfc_sli_pcimem_bcopy(void *srcp, void *destp, uint32_t cnt)\r\n{\r\nuint32_t *src = srcp;\r\nuint32_t *dest = destp;\r\nuint32_t ldata;\r\nint i;\r\nfor (i = 0; i < (int)cnt; i += sizeof (uint32_t)) {\r\nldata = *src;\r\nldata = le32_to_cpu(ldata);\r\n*dest = ldata;\r\nsrc++;\r\ndest++;\r\n}\r\n}\r\nvoid\r\nlpfc_sli_bemem_bcopy(void *srcp, void *destp, uint32_t cnt)\r\n{\r\nuint32_t *src = srcp;\r\nuint32_t *dest = destp;\r\nuint32_t ldata;\r\nint i;\r\nfor (i = 0; i < (int)cnt; i += sizeof(uint32_t)) {\r\nldata = *src;\r\nldata = be32_to_cpu(ldata);\r\n*dest = ldata;\r\nsrc++;\r\ndest++;\r\n}\r\n}\r\nint\r\nlpfc_sli_ringpostbuf_put(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_dmabuf *mp)\r\n{\r\nspin_lock_irq(&phba->hbalock);\r\nlist_add_tail(&mp->list, &pring->postbufq);\r\npring->postbufq_cnt++;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 0;\r\n}\r\nuint32_t\r\nlpfc_sli_get_buffer_tag(struct lpfc_hba *phba)\r\n{\r\nspin_lock_irq(&phba->hbalock);\r\nphba->buffer_tag_count++;\r\nphba->buffer_tag_count |= QUE_BUFTAG_BIT;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn phba->buffer_tag_count;\r\n}\r\nstruct lpfc_dmabuf *\r\nlpfc_sli_ring_taggedbuf_get(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nuint32_t tag)\r\n{\r\nstruct lpfc_dmabuf *mp, *next_mp;\r\nstruct list_head *slp = &pring->postbufq;\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(mp, next_mp, &pring->postbufq, list) {\r\nif (mp->buffer_tag == tag) {\r\nlist_del_init(&mp->list);\r\npring->postbufq_cnt--;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn mp;\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0402 Cannot find virtual addr for buffer tag on "\r\n"ring %d Data x%lx x%p x%p x%x\n",\r\npring->ringno, (unsigned long) tag,\r\nslp->next, slp->prev, pring->postbufq_cnt);\r\nreturn NULL;\r\n}\r\nstruct lpfc_dmabuf *\r\nlpfc_sli_ringpostbuf_get(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\ndma_addr_t phys)\r\n{\r\nstruct lpfc_dmabuf *mp, *next_mp;\r\nstruct list_head *slp = &pring->postbufq;\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(mp, next_mp, &pring->postbufq, list) {\r\nif (mp->phys == phys) {\r\nlist_del_init(&mp->list);\r\npring->postbufq_cnt--;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn mp;\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0410 Cannot find virtual addr for mapped buf on "\r\n"ring %d Data x%llx x%p x%p x%x\n",\r\npring->ringno, (unsigned long long)phys,\r\nslp->next, slp->prev, pring->postbufq_cnt);\r\nreturn NULL;\r\n}\r\nstatic void\r\nlpfc_sli_abort_els_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\r\nstruct lpfc_iocbq *rspiocb)\r\n{\r\nIOCB_t *irsp = &rspiocb->iocb;\r\nuint16_t abort_iotag, abort_context;\r\nstruct lpfc_iocbq *abort_iocb = NULL;\r\nif (irsp->ulpStatus) {\r\nabort_context = cmdiocb->iocb.un.acxri.abortContextTag;\r\nabort_iotag = cmdiocb->iocb.un.acxri.abortIoTag;\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->sli_rev < LPFC_SLI_REV4) {\r\nif (abort_iotag != 0 &&\r\nabort_iotag <= phba->sli.last_iotag)\r\nabort_iocb =\r\nphba->sli.iocbq_lookup[abort_iotag];\r\n} else\r\nabort_iocb = phba->sli.iocbq_lookup[abort_context];\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_ELS | LOG_SLI,\r\n"0327 Cannot abort els iocb %p "\r\n"with tag %x context %x, abort status %x, "\r\n"abort code %x\n",\r\nabort_iocb, abort_iotag, abort_context,\r\nirsp->ulpStatus, irsp->un.ulpWord[4]);\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nlpfc_sli_release_iocbq(phba, cmdiocb);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_ignore_els_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\r\nstruct lpfc_iocbq *rspiocb)\r\n{\r\nIOCB_t *irsp = &rspiocb->iocb;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_ELS,\r\n"0139 Ignoring ELS cmd tag x%x completion Data: "\r\n"x%x x%x x%x\n",\r\nirsp->ulpIoTag, irsp->ulpStatus,\r\nirsp->un.ulpWord[4], irsp->ulpTimeout);\r\nif (cmdiocb->iocb.ulpCommand == CMD_GEN_REQUEST64_CR)\r\nlpfc_ct_free_iocb(phba, cmdiocb);\r\nelse\r\nlpfc_els_free_iocb(phba, cmdiocb);\r\nreturn;\r\n}\r\nstatic int\r\nlpfc_sli_abort_iotag_issue(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *cmdiocb)\r\n{\r\nstruct lpfc_vport *vport = cmdiocb->vport;\r\nstruct lpfc_iocbq *abtsiocbp;\r\nIOCB_t *icmd = NULL;\r\nIOCB_t *iabt = NULL;\r\nint ring_number;\r\nint retval;\r\nunsigned long iflags;\r\nicmd = &cmdiocb->iocb;\r\nif (icmd->ulpCommand == CMD_ABORT_XRI_CN ||\r\nicmd->ulpCommand == CMD_CLOSE_XRI_CN ||\r\n(cmdiocb->iocb_flag & LPFC_DRIVER_ABORTED) != 0)\r\nreturn 0;\r\nabtsiocbp = __lpfc_sli_get_iocbq(phba);\r\nif (abtsiocbp == NULL)\r\nreturn 0;\r\ncmdiocb->iocb_flag |= LPFC_DRIVER_ABORTED;\r\niabt = &abtsiocbp->iocb;\r\niabt->un.acxri.abortType = ABORT_TYPE_ABTS;\r\niabt->un.acxri.abortContextTag = icmd->ulpContext;\r\nif (phba->sli_rev == LPFC_SLI_REV4) {\r\niabt->un.acxri.abortIoTag = cmdiocb->sli4_xritag;\r\niabt->un.acxri.abortContextTag = cmdiocb->iotag;\r\n}\r\nelse\r\niabt->un.acxri.abortIoTag = icmd->ulpIoTag;\r\niabt->ulpLe = 1;\r\niabt->ulpClass = icmd->ulpClass;\r\nabtsiocbp->fcp_wqidx = cmdiocb->fcp_wqidx;\r\nif (cmdiocb->iocb_flag & LPFC_IO_FCP)\r\nabtsiocbp->iocb_flag |= LPFC_USE_FCPWQIDX;\r\nif (cmdiocb->iocb_flag & LPFC_IO_FOF)\r\nabtsiocbp->iocb_flag |= LPFC_IO_FOF;\r\nif (phba->link_state >= LPFC_LINK_UP)\r\niabt->ulpCommand = CMD_ABORT_XRI_CN;\r\nelse\r\niabt->ulpCommand = CMD_CLOSE_XRI_CN;\r\nabtsiocbp->iocb_cmpl = lpfc_sli_abort_els_cmpl;\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_SLI,\r\n"0339 Abort xri x%x, original iotag x%x, "\r\n"abort cmd iotag x%x\n",\r\niabt->un.acxri.abortIoTag,\r\niabt->un.acxri.abortContextTag,\r\nabtsiocbp->iotag);\r\nif (phba->sli_rev == LPFC_SLI_REV4) {\r\nring_number =\r\nlpfc_sli_calc_ring(phba, pring->ringno, abtsiocbp);\r\nif (unlikely(ring_number == LPFC_HBA_ERROR))\r\nreturn 0;\r\npring = &phba->sli.ring[ring_number];\r\nspin_lock_irqsave(&pring->ring_lock, iflags);\r\nretval = __lpfc_sli_issue_iocb(phba, pring->ringno,\r\nabtsiocbp, 0);\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\n} else {\r\nretval = __lpfc_sli_issue_iocb(phba, pring->ringno,\r\nabtsiocbp, 0);\r\n}\r\nif (retval)\r\n__lpfc_sli_release_iocbq(phba, abtsiocbp);\r\nreturn retval;\r\n}\r\nint\r\nlpfc_sli_issue_abort_iotag(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *cmdiocb)\r\n{\r\nstruct lpfc_vport *vport = cmdiocb->vport;\r\nint retval = IOCB_ERROR;\r\nIOCB_t *icmd = NULL;\r\nicmd = &cmdiocb->iocb;\r\nif (icmd->ulpCommand == CMD_ABORT_XRI_CN ||\r\nicmd->ulpCommand == CMD_CLOSE_XRI_CN ||\r\n(cmdiocb->iocb_flag & LPFC_DRIVER_ABORTED) != 0)\r\nreturn 0;\r\nif ((vport->load_flag & FC_UNLOADING) &&\r\n(pring->ringno == LPFC_ELS_RING)) {\r\nif (cmdiocb->iocb_flag & LPFC_IO_FABRIC)\r\ncmdiocb->fabric_iocb_cmpl = lpfc_ignore_els_cmpl;\r\nelse\r\ncmdiocb->iocb_cmpl = lpfc_ignore_els_cmpl;\r\ngoto abort_iotag_exit;\r\n}\r\nretval = lpfc_sli_abort_iotag_issue(phba, pring, cmdiocb);\r\nabort_iotag_exit:\r\nreturn retval;\r\n}\r\nvoid\r\nlpfc_sli_hba_iocb_abort(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_sli_ring *pring;\r\nint i;\r\nfor (i = 0; i < psli->num_rings; i++) {\r\npring = &psli->ring[i];\r\nlpfc_sli_abort_iocb_ring(phba, pring);\r\n}\r\n}\r\nstatic int\r\nlpfc_sli_validate_fcp_iocb(struct lpfc_iocbq *iocbq, struct lpfc_vport *vport,\r\nuint16_t tgt_id, uint64_t lun_id,\r\nlpfc_ctx_cmd ctx_cmd)\r\n{\r\nstruct lpfc_scsi_buf *lpfc_cmd;\r\nint rc = 1;\r\nif (!(iocbq->iocb_flag & LPFC_IO_FCP))\r\nreturn rc;\r\nif (iocbq->vport != vport)\r\nreturn rc;\r\nlpfc_cmd = container_of(iocbq, struct lpfc_scsi_buf, cur_iocbq);\r\nif (lpfc_cmd->pCmd == NULL)\r\nreturn rc;\r\nswitch (ctx_cmd) {\r\ncase LPFC_CTX_LUN:\r\nif ((lpfc_cmd->rdata->pnode) &&\r\n(lpfc_cmd->rdata->pnode->nlp_sid == tgt_id) &&\r\n(scsilun_to_int(&lpfc_cmd->fcp_cmnd->fcp_lun) == lun_id))\r\nrc = 0;\r\nbreak;\r\ncase LPFC_CTX_TGT:\r\nif ((lpfc_cmd->rdata->pnode) &&\r\n(lpfc_cmd->rdata->pnode->nlp_sid == tgt_id))\r\nrc = 0;\r\nbreak;\r\ncase LPFC_CTX_HOST:\r\nrc = 0;\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "%s: Unknown context cmd type, value %d\n",\r\n__func__, ctx_cmd);\r\nbreak;\r\n}\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli_sum_iocb(struct lpfc_vport *vport, uint16_t tgt_id, uint64_t lun_id,\r\nlpfc_ctx_cmd ctx_cmd)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_iocbq *iocbq;\r\nint sum, i;\r\nfor (i = 1, sum = 0; i <= phba->sli.last_iotag; i++) {\r\niocbq = phba->sli.iocbq_lookup[i];\r\nif (lpfc_sli_validate_fcp_iocb (iocbq, vport, tgt_id, lun_id,\r\nctx_cmd) == 0)\r\nsum++;\r\n}\r\nreturn sum;\r\n}\r\nvoid\r\nlpfc_sli_abort_fcp_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,\r\nstruct lpfc_iocbq *rspiocb)\r\n{\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"3096 ABORT_XRI_CN completing on rpi x%x "\r\n"original iotag x%x, abort cmd iotag x%x "\r\n"status 0x%x, reason 0x%x\n",\r\ncmdiocb->iocb.un.acxri.abortContextTag,\r\ncmdiocb->iocb.un.acxri.abortIoTag,\r\ncmdiocb->iotag, rspiocb->iocb.ulpStatus,\r\nrspiocb->iocb.un.ulpWord[4]);\r\nlpfc_sli_release_iocbq(phba, cmdiocb);\r\nreturn;\r\n}\r\nint\r\nlpfc_sli_abort_iocb(struct lpfc_vport *vport, struct lpfc_sli_ring *pring,\r\nuint16_t tgt_id, uint64_t lun_id, lpfc_ctx_cmd abort_cmd)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_iocbq *iocbq;\r\nstruct lpfc_iocbq *abtsiocb;\r\nIOCB_t *cmd = NULL;\r\nint errcnt = 0, ret_val = 0;\r\nint i;\r\nfor (i = 1; i <= phba->sli.last_iotag; i++) {\r\niocbq = phba->sli.iocbq_lookup[i];\r\nif (lpfc_sli_validate_fcp_iocb(iocbq, vport, tgt_id, lun_id,\r\nabort_cmd) != 0)\r\ncontinue;\r\nif (iocbq->iocb_flag & LPFC_DRIVER_ABORTED)\r\ncontinue;\r\nabtsiocb = lpfc_sli_get_iocbq(phba);\r\nif (abtsiocb == NULL) {\r\nerrcnt++;\r\ncontinue;\r\n}\r\niocbq->iocb_flag |= LPFC_DRIVER_ABORTED;\r\ncmd = &iocbq->iocb;\r\nabtsiocb->iocb.un.acxri.abortType = ABORT_TYPE_ABTS;\r\nabtsiocb->iocb.un.acxri.abortContextTag = cmd->ulpContext;\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nabtsiocb->iocb.un.acxri.abortIoTag = iocbq->sli4_xritag;\r\nelse\r\nabtsiocb->iocb.un.acxri.abortIoTag = cmd->ulpIoTag;\r\nabtsiocb->iocb.ulpLe = 1;\r\nabtsiocb->iocb.ulpClass = cmd->ulpClass;\r\nabtsiocb->vport = vport;\r\nabtsiocb->fcp_wqidx = iocbq->fcp_wqidx;\r\nif (iocbq->iocb_flag & LPFC_IO_FCP)\r\nabtsiocb->iocb_flag |= LPFC_USE_FCPWQIDX;\r\nif (iocbq->iocb_flag & LPFC_IO_FOF)\r\nabtsiocb->iocb_flag |= LPFC_IO_FOF;\r\nif (lpfc_is_link_up(phba))\r\nabtsiocb->iocb.ulpCommand = CMD_ABORT_XRI_CN;\r\nelse\r\nabtsiocb->iocb.ulpCommand = CMD_CLOSE_XRI_CN;\r\nabtsiocb->iocb_cmpl = lpfc_sli_abort_fcp_cmpl;\r\nret_val = lpfc_sli_issue_iocb(phba, pring->ringno,\r\nabtsiocb, 0);\r\nif (ret_val == IOCB_ERROR) {\r\nlpfc_sli_release_iocbq(phba, abtsiocb);\r\nerrcnt++;\r\ncontinue;\r\n}\r\n}\r\nreturn errcnt;\r\n}\r\nint\r\nlpfc_sli_abort_taskmgmt(struct lpfc_vport *vport, struct lpfc_sli_ring *pring,\r\nuint16_t tgt_id, uint64_t lun_id, lpfc_ctx_cmd cmd)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_scsi_buf *lpfc_cmd;\r\nstruct lpfc_iocbq *abtsiocbq;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct lpfc_iocbq *iocbq;\r\nIOCB_t *icmd;\r\nint sum, i, ret_val;\r\nunsigned long iflags;\r\nstruct lpfc_sli_ring *pring_s4;\r\nuint32_t ring_number;\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->hba_flag & HBA_FCP_IOQ_FLUSH) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 0;\r\n}\r\nsum = 0;\r\nfor (i = 1; i <= phba->sli.last_iotag; i++) {\r\niocbq = phba->sli.iocbq_lookup[i];\r\nif (lpfc_sli_validate_fcp_iocb(iocbq, vport, tgt_id, lun_id,\r\ncmd) != 0)\r\ncontinue;\r\nif (iocbq->iocb_flag & LPFC_DRIVER_ABORTED)\r\ncontinue;\r\nabtsiocbq = __lpfc_sli_get_iocbq(phba);\r\nif (abtsiocbq == NULL)\r\ncontinue;\r\nicmd = &iocbq->iocb;\r\nabtsiocbq->iocb.un.acxri.abortType = ABORT_TYPE_ABTS;\r\nabtsiocbq->iocb.un.acxri.abortContextTag = icmd->ulpContext;\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nabtsiocbq->iocb.un.acxri.abortIoTag =\r\niocbq->sli4_xritag;\r\nelse\r\nabtsiocbq->iocb.un.acxri.abortIoTag = icmd->ulpIoTag;\r\nabtsiocbq->iocb.ulpLe = 1;\r\nabtsiocbq->iocb.ulpClass = icmd->ulpClass;\r\nabtsiocbq->vport = vport;\r\nabtsiocbq->fcp_wqidx = iocbq->fcp_wqidx;\r\nif (iocbq->iocb_flag & LPFC_IO_FCP)\r\nabtsiocbq->iocb_flag |= LPFC_USE_FCPWQIDX;\r\nif (iocbq->iocb_flag & LPFC_IO_FOF)\r\nabtsiocbq->iocb_flag |= LPFC_IO_FOF;\r\nlpfc_cmd = container_of(iocbq, struct lpfc_scsi_buf, cur_iocbq);\r\nndlp = lpfc_cmd->rdata->pnode;\r\nif (lpfc_is_link_up(phba) &&\r\n(ndlp && ndlp->nlp_state == NLP_STE_MAPPED_NODE))\r\nabtsiocbq->iocb.ulpCommand = CMD_ABORT_XRI_CN;\r\nelse\r\nabtsiocbq->iocb.ulpCommand = CMD_CLOSE_XRI_CN;\r\nabtsiocbq->iocb_cmpl = lpfc_sli_abort_fcp_cmpl;\r\niocbq->iocb_flag |= LPFC_DRIVER_ABORTED;\r\nif (phba->sli_rev == LPFC_SLI_REV4) {\r\nring_number = MAX_SLI3_CONFIGURED_RINGS +\r\niocbq->fcp_wqidx;\r\npring_s4 = &phba->sli.ring[ring_number];\r\nspin_lock_irqsave(&pring_s4->ring_lock, iflags);\r\nret_val = __lpfc_sli_issue_iocb(phba, pring_s4->ringno,\r\nabtsiocbq, 0);\r\nspin_unlock_irqrestore(&pring_s4->ring_lock, iflags);\r\n} else {\r\nret_val = __lpfc_sli_issue_iocb(phba, pring->ringno,\r\nabtsiocbq, 0);\r\n}\r\nif (ret_val == IOCB_ERROR)\r\n__lpfc_sli_release_iocbq(phba, abtsiocbq);\r\nelse\r\nsum++;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn sum;\r\n}\r\nstatic void\r\nlpfc_sli_wake_iocb_wait(struct lpfc_hba *phba,\r\nstruct lpfc_iocbq *cmdiocbq,\r\nstruct lpfc_iocbq *rspiocbq)\r\n{\r\nwait_queue_head_t *pdone_q;\r\nunsigned long iflags;\r\nstruct lpfc_scsi_buf *lpfc_cmd;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nif (cmdiocbq->iocb_flag & LPFC_IO_WAKE_TMO) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\ncmdiocbq->iocb_cmpl = cmdiocbq->wait_iocb_cmpl;\r\ncmdiocbq->wait_iocb_cmpl = NULL;\r\nif (cmdiocbq->iocb_cmpl)\r\n(cmdiocbq->iocb_cmpl)(phba, cmdiocbq, NULL);\r\nelse\r\nlpfc_sli_release_iocbq(phba, cmdiocbq);\r\nreturn;\r\n}\r\ncmdiocbq->iocb_flag |= LPFC_IO_WAKE;\r\nif (cmdiocbq->context2 && rspiocbq)\r\nmemcpy(&((struct lpfc_iocbq *)cmdiocbq->context2)->iocb,\r\n&rspiocbq->iocb, sizeof(IOCB_t));\r\nif ((cmdiocbq->iocb_flag & LPFC_IO_FCP) &&\r\n!(cmdiocbq->iocb_flag & LPFC_IO_LIBDFC)) {\r\nlpfc_cmd = container_of(cmdiocbq, struct lpfc_scsi_buf,\r\ncur_iocbq);\r\nlpfc_cmd->exch_busy = rspiocbq->iocb_flag & LPFC_EXCHANGE_BUSY;\r\n}\r\npdone_q = cmdiocbq->context_un.wait_queue;\r\nif (pdone_q)\r\nwake_up(pdone_q);\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn;\r\n}\r\nstatic int\r\nlpfc_chk_iocb_flg(struct lpfc_hba *phba,\r\nstruct lpfc_iocbq *piocbq, uint32_t flag)\r\n{\r\nunsigned long iflags;\r\nint ret;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nret = piocbq->iocb_flag & flag;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn ret;\r\n}\r\nint\r\nlpfc_sli_issue_iocb_wait(struct lpfc_hba *phba,\r\nuint32_t ring_number,\r\nstruct lpfc_iocbq *piocb,\r\nstruct lpfc_iocbq *prspiocbq,\r\nuint32_t timeout)\r\n{\r\nDECLARE_WAIT_QUEUE_HEAD_ONSTACK(done_q);\r\nlong timeleft, timeout_req = 0;\r\nint retval = IOCB_SUCCESS;\r\nuint32_t creg_val;\r\nstruct lpfc_iocbq *iocb;\r\nint txq_cnt = 0;\r\nint txcmplq_cnt = 0;\r\nstruct lpfc_sli_ring *pring = &phba->sli.ring[LPFC_ELS_RING];\r\nunsigned long iflags;\r\nbool iocb_completed = true;\r\nif (prspiocbq) {\r\nif (piocb->context2)\r\nreturn IOCB_ERROR;\r\npiocb->context2 = prspiocbq;\r\n}\r\npiocb->wait_iocb_cmpl = piocb->iocb_cmpl;\r\npiocb->iocb_cmpl = lpfc_sli_wake_iocb_wait;\r\npiocb->context_un.wait_queue = &done_q;\r\npiocb->iocb_flag &= ~(LPFC_IO_WAKE | LPFC_IO_WAKE_TMO);\r\nif (phba->cfg_poll & DISABLE_FCP_RING_INT) {\r\nif (lpfc_readl(phba->HCregaddr, &creg_val))\r\nreturn IOCB_ERROR;\r\ncreg_val |= (HC_R0INT_ENA << LPFC_FCP_RING);\r\nwritel(creg_val, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n}\r\nretval = lpfc_sli_issue_iocb(phba, ring_number, piocb,\r\nSLI_IOCB_RET_IOCB);\r\nif (retval == IOCB_SUCCESS) {\r\ntimeout_req = msecs_to_jiffies(timeout * 1000);\r\ntimeleft = wait_event_timeout(done_q,\r\nlpfc_chk_iocb_flg(phba, piocb, LPFC_IO_WAKE),\r\ntimeout_req);\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nif (!(piocb->iocb_flag & LPFC_IO_WAKE)) {\r\niocb_completed = false;\r\npiocb->iocb_flag |= LPFC_IO_WAKE_TMO;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nif (iocb_completed) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0331 IOCB wake signaled\n");\r\n} else if (timeleft == 0) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0338 IOCB wait timeout error - no "\r\n"wake response Data x%x\n", timeout);\r\nretval = IOCB_TIMEDOUT;\r\n} else {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0330 IOCB wake NOT set, "\r\n"Data x%x x%lx\n",\r\ntimeout, (timeleft / jiffies));\r\nretval = IOCB_TIMEDOUT;\r\n}\r\n} else if (retval == IOCB_BUSY) {\r\nif (phba->cfg_log_verbose & LOG_SLI) {\r\nlist_for_each_entry(iocb, &pring->txq, list) {\r\ntxq_cnt++;\r\n}\r\nlist_for_each_entry(iocb, &pring->txcmplq, list) {\r\ntxcmplq_cnt++;\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"2818 Max IOCBs %d txq cnt %d txcmplq cnt %d\n",\r\nphba->iocb_cnt, txq_cnt, txcmplq_cnt);\r\n}\r\nreturn retval;\r\n} else {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0332 IOCB wait issue failed, Data x%x\n",\r\nretval);\r\nretval = IOCB_ERROR;\r\n}\r\nif (phba->cfg_poll & DISABLE_FCP_RING_INT) {\r\nif (lpfc_readl(phba->HCregaddr, &creg_val))\r\nreturn IOCB_ERROR;\r\ncreg_val &= ~(HC_R0INT_ENA << LPFC_FCP_RING);\r\nwritel(creg_val, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n}\r\nif (prspiocbq)\r\npiocb->context2 = NULL;\r\npiocb->context_un.wait_queue = NULL;\r\npiocb->iocb_cmpl = NULL;\r\nreturn retval;\r\n}\r\nint\r\nlpfc_sli_issue_mbox_wait(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmboxq,\r\nuint32_t timeout)\r\n{\r\nDECLARE_WAIT_QUEUE_HEAD_ONSTACK(done_q);\r\nMAILBOX_t *mb = NULL;\r\nint retval;\r\nunsigned long flag;\r\nif (pmboxq->context1)\r\nmb = (MAILBOX_t *)pmboxq->context1;\r\npmboxq->mbox_flag &= ~LPFC_MBX_WAKE;\r\npmboxq->mbox_cmpl = lpfc_sli_wake_mbox_wait;\r\npmboxq->context1 = &done_q;\r\nretval = lpfc_sli_issue_mbox(phba, pmboxq, MBX_NOWAIT);\r\nif (retval == MBX_BUSY || retval == MBX_SUCCESS) {\r\nwait_event_interruptible_timeout(done_q,\r\npmboxq->mbox_flag & LPFC_MBX_WAKE,\r\nmsecs_to_jiffies(timeout * 1000));\r\nspin_lock_irqsave(&phba->hbalock, flag);\r\npmboxq->context1 = (uint8_t *)mb;\r\nif (pmboxq->mbox_flag & LPFC_MBX_WAKE) {\r\nretval = MBX_SUCCESS;\r\n} else {\r\nretval = MBX_TIMEOUT;\r\npmboxq->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, flag);\r\n} else {\r\npmboxq->context1 = (uint8_t *)mb;\r\n}\r\nreturn retval;\r\n}\r\nvoid\r\nlpfc_sli_mbox_sys_shutdown(struct lpfc_hba *phba, int mbx_action)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nunsigned long timeout;\r\nif (mbx_action == LPFC_MBX_NO_WAIT) {\r\nmsleep(100);\r\nlpfc_sli_mbox_sys_flush(phba);\r\nreturn;\r\n}\r\ntimeout = msecs_to_jiffies(LPFC_MBOX_TMO * 1000) + jiffies;\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag |= LPFC_SLI_ASYNC_MBX_BLK;\r\nif (psli->sli_flag & LPFC_SLI_ACTIVE) {\r\nif (phba->sli.mbox_active)\r\ntimeout = msecs_to_jiffies(lpfc_mbox_tmo_val(phba,\r\nphba->sli.mbox_active) *\r\n1000) + jiffies;\r\nspin_unlock_irq(&phba->hbalock);\r\nwhile (phba->sli.mbox_active) {\r\nmsleep(2);\r\nif (time_after(jiffies, timeout))\r\nbreak;\r\n}\r\n} else\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli_mbox_sys_flush(phba);\r\n}\r\nstatic int\r\nlpfc_sli_eratt_read(struct lpfc_hba *phba)\r\n{\r\nuint32_t ha_copy;\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy))\r\ngoto unplug_err;\r\nif (ha_copy & HA_ERATT) {\r\nif (lpfc_sli_read_hs(phba))\r\ngoto unplug_err;\r\nif ((HS_FFER1 & phba->work_hs) &&\r\n((HS_FFER2 | HS_FFER3 | HS_FFER4 | HS_FFER5 |\r\nHS_FFER6 | HS_FFER7 | HS_FFER8) & phba->work_hs)) {\r\nphba->hba_flag |= DEFER_ERATT;\r\nwritel(0, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n}\r\nphba->work_ha |= HA_ERATT;\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\nreturn 1;\r\n}\r\nreturn 0;\r\nunplug_err:\r\nphba->work_hs |= UNPLUG_ERR;\r\nphba->work_ha |= HA_ERATT;\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\nreturn 1;\r\n}\r\nstatic int\r\nlpfc_sli4_eratt_read(struct lpfc_hba *phba)\r\n{\r\nuint32_t uerr_sta_hi, uerr_sta_lo;\r\nuint32_t if_type, portsmphr;\r\nstruct lpfc_register portstat_reg;\r\nif_type = bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf);\r\nswitch (if_type) {\r\ncase LPFC_SLI_INTF_IF_TYPE_0:\r\nif (lpfc_readl(phba->sli4_hba.u.if_type0.UERRLOregaddr,\r\n&uerr_sta_lo) ||\r\nlpfc_readl(phba->sli4_hba.u.if_type0.UERRHIregaddr,\r\n&uerr_sta_hi)) {\r\nphba->work_hs |= UNPLUG_ERR;\r\nphba->work_ha |= HA_ERATT;\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\nreturn 1;\r\n}\r\nif ((~phba->sli4_hba.ue_mask_lo & uerr_sta_lo) ||\r\n(~phba->sli4_hba.ue_mask_hi & uerr_sta_hi)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"1423 HBA Unrecoverable error: "\r\n"uerr_lo_reg=0x%x, uerr_hi_reg=0x%x, "\r\n"ue_mask_lo_reg=0x%x, "\r\n"ue_mask_hi_reg=0x%x\n",\r\nuerr_sta_lo, uerr_sta_hi,\r\nphba->sli4_hba.ue_mask_lo,\r\nphba->sli4_hba.ue_mask_hi);\r\nphba->work_status[0] = uerr_sta_lo;\r\nphba->work_status[1] = uerr_sta_hi;\r\nphba->work_ha |= HA_ERATT;\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\nreturn 1;\r\n}\r\nbreak;\r\ncase LPFC_SLI_INTF_IF_TYPE_2:\r\nif (lpfc_readl(phba->sli4_hba.u.if_type2.STATUSregaddr,\r\n&portstat_reg.word0) ||\r\nlpfc_readl(phba->sli4_hba.PSMPHRregaddr,\r\n&portsmphr)){\r\nphba->work_hs |= UNPLUG_ERR;\r\nphba->work_ha |= HA_ERATT;\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\nreturn 1;\r\n}\r\nif (bf_get(lpfc_sliport_status_err, &portstat_reg)) {\r\nphba->work_status[0] =\r\nreadl(phba->sli4_hba.u.if_type2.ERR1regaddr);\r\nphba->work_status[1] =\r\nreadl(phba->sli4_hba.u.if_type2.ERR2regaddr);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2885 Port Status Event: "\r\n"port status reg 0x%x, "\r\n"port smphr reg 0x%x, "\r\n"error 1=0x%x, error 2=0x%x\n",\r\nportstat_reg.word0,\r\nportsmphr,\r\nphba->work_status[0],\r\nphba->work_status[1]);\r\nphba->work_ha |= HA_ERATT;\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\nreturn 1;\r\n}\r\nbreak;\r\ncase LPFC_SLI_INTF_IF_TYPE_1:\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2886 HBA Error Attention on unsupported "\r\n"if type %d.", if_type);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli_check_eratt(struct lpfc_hba *phba)\r\n{\r\nuint32_t ha_copy;\r\nif (phba->link_flag & LS_IGNORE_ERATT)\r\nreturn 0;\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->hba_flag & HBA_ERATT_HANDLED) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 0;\r\n}\r\nif (unlikely(phba->hba_flag & DEFER_ERATT)) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 0;\r\n}\r\nif (unlikely(pci_channel_offline(phba->pcidev))) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn 0;\r\n}\r\nswitch (phba->sli_rev) {\r\ncase LPFC_SLI_REV2:\r\ncase LPFC_SLI_REV3:\r\nha_copy = lpfc_sli_eratt_read(phba);\r\nbreak;\r\ncase LPFC_SLI_REV4:\r\nha_copy = lpfc_sli4_eratt_read(phba);\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0299 Invalid SLI revision (%d)\n",\r\nphba->sli_rev);\r\nha_copy = 0;\r\nbreak;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn ha_copy;\r\n}\r\nstatic inline int\r\nlpfc_intr_state_check(struct lpfc_hba *phba)\r\n{\r\nif (unlikely(pci_channel_offline(phba->pcidev)))\r\nreturn -EIO;\r\nphba->sli.slistat.sli_intr++;\r\nif (unlikely(phba->link_state < LPFC_LINK_DOWN))\r\nreturn -EIO;\r\nreturn 0;\r\n}\r\nirqreturn_t\r\nlpfc_sli_sp_intr_handler(int irq, void *dev_id)\r\n{\r\nstruct lpfc_hba *phba;\r\nuint32_t ha_copy, hc_copy;\r\nuint32_t work_ha_copy;\r\nunsigned long status;\r\nunsigned long iflag;\r\nuint32_t control;\r\nMAILBOX_t *mbox, *pmbox;\r\nstruct lpfc_vport *vport;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct lpfc_dmabuf *mp;\r\nLPFC_MBOXQ_t *pmb;\r\nint rc;\r\nphba = (struct lpfc_hba *)dev_id;\r\nif (unlikely(!phba))\r\nreturn IRQ_NONE;\r\nif (phba->intr_type == MSIX) {\r\nif (lpfc_intr_state_check(phba))\r\nreturn IRQ_NONE;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy))\r\ngoto unplug_error;\r\nif (phba->link_flag & LS_IGNORE_ERATT)\r\nha_copy &= ~HA_ERATT;\r\nif (ha_copy & HA_ERATT) {\r\nif (phba->hba_flag & HBA_ERATT_HANDLED)\r\nha_copy &= ~HA_ERATT;\r\nelse\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\n}\r\nif (unlikely(phba->hba_flag & DEFER_ERATT)) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn IRQ_NONE;\r\n}\r\nif (lpfc_readl(phba->HCregaddr, &hc_copy))\r\ngoto unplug_error;\r\nwritel(hc_copy & ~(HC_MBINT_ENA | HC_R2INT_ENA |\r\nHC_LAINT_ENA | HC_ERINT_ENA),\r\nphba->HCregaddr);\r\nwritel((ha_copy & (HA_MBATT | HA_R2_CLR_MSK)),\r\nphba->HAregaddr);\r\nwritel(hc_copy, phba->HCregaddr);\r\nreadl(phba->HAregaddr);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\n} else\r\nha_copy = phba->ha_copy;\r\nwork_ha_copy = ha_copy & phba->work_ha_mask;\r\nif (work_ha_copy) {\r\nif (work_ha_copy & HA_LATT) {\r\nif (phba->sli.sli_flag & LPFC_PROCESS_LA) {\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nphba->sli.sli_flag &= ~LPFC_PROCESS_LA;\r\nif (lpfc_readl(phba->HCregaddr, &control))\r\ngoto unplug_error;\r\ncontrol &= ~HC_LAINT_ENA;\r\nwritel(control, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\n}\r\nelse\r\nwork_ha_copy &= ~HA_LATT;\r\n}\r\nif (work_ha_copy & ~(HA_ERATT | HA_MBATT | HA_LATT)) {\r\nstatus = (work_ha_copy &\r\n(HA_RXMASK << (4*LPFC_ELS_RING)));\r\nstatus >>= (4*LPFC_ELS_RING);\r\nif (status & HA_RXMASK) {\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (lpfc_readl(phba->HCregaddr, &control))\r\ngoto unplug_error;\r\nlpfc_debugfs_slow_ring_trc(phba,\r\n"ISR slow ring: ctl:x%x stat:x%x isrcnt:x%x",\r\ncontrol, status,\r\n(uint32_t)phba->sli.slistat.sli_intr);\r\nif (control & (HC_R0INT_ENA << LPFC_ELS_RING)) {\r\nlpfc_debugfs_slow_ring_trc(phba,\r\n"ISR Disable ring:"\r\n"pwork:x%x hawork:x%x wait:x%x",\r\nphba->work_ha, work_ha_copy,\r\n(uint32_t)((unsigned long)\r\n&phba->work_waitq));\r\ncontrol &=\r\n~(HC_R0INT_ENA << LPFC_ELS_RING);\r\nwritel(control, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n}\r\nelse {\r\nlpfc_debugfs_slow_ring_trc(phba,\r\n"ISR slow ring: pwork:"\r\n"x%x hawork:x%x wait:x%x",\r\nphba->work_ha, work_ha_copy,\r\n(uint32_t)((unsigned long)\r\n&phba->work_waitq));\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\n}\r\n}\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (work_ha_copy & HA_ERATT) {\r\nif (lpfc_sli_read_hs(phba))\r\ngoto unplug_error;\r\nif ((HS_FFER1 & phba->work_hs) &&\r\n((HS_FFER2 | HS_FFER3 | HS_FFER4 | HS_FFER5 |\r\nHS_FFER6 | HS_FFER7 | HS_FFER8) &\r\nphba->work_hs)) {\r\nphba->hba_flag |= DEFER_ERATT;\r\nwritel(0, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n}\r\n}\r\nif ((work_ha_copy & HA_MBATT) && (phba->sli.mbox_active)) {\r\npmb = phba->sli.mbox_active;\r\npmbox = &pmb->u.mb;\r\nmbox = phba->mbox;\r\nvport = pmb->vport;\r\nlpfc_sli_pcimem_bcopy(mbox, pmbox, sizeof(uint32_t));\r\nif (pmbox->mbxOwner != OWN_HOST) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX |\r\nLOG_SLI,\r\n"(%d):0304 Stray Mailbox "\r\n"Interrupt mbxCommand x%x "\r\n"mbxStatus x%x\n",\r\n(vport ? vport->vpi : 0),\r\npmbox->mbxCommand,\r\npmbox->mbxStatus);\r\nwork_ha_copy &= ~HA_MBATT;\r\n} else {\r\nphba->sli.mbox_active = NULL;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nphba->last_completion_time = jiffies;\r\ndel_timer(&phba->sli.mbox_tmo);\r\nif (pmb->mbox_cmpl) {\r\nlpfc_sli_pcimem_bcopy(mbox, pmbox,\r\nMAILBOX_CMD_SIZE);\r\nif (pmb->out_ext_byte_len &&\r\npmb->context2)\r\nlpfc_sli_pcimem_bcopy(\r\nphba->mbox_ext,\r\npmb->context2,\r\npmb->out_ext_byte_len);\r\n}\r\nif (pmb->mbox_flag & LPFC_MBX_IMED_UNREG) {\r\npmb->mbox_flag &= ~LPFC_MBX_IMED_UNREG;\r\nlpfc_debugfs_disc_trc(vport,\r\nLPFC_DISC_TRC_MBOX_VPORT,\r\n"MBOX dflt rpi: : "\r\n"status:x%x rpi:x%x",\r\n(uint32_t)pmbox->mbxStatus,\r\npmbox->un.varWords[0], 0);\r\nif (!pmbox->mbxStatus) {\r\nmp = (struct lpfc_dmabuf *)\r\n(pmb->context1);\r\nndlp = (struct lpfc_nodelist *)\r\npmb->context2;\r\nlpfc_unreg_login(phba,\r\nvport->vpi,\r\npmbox->un.varWords[0],\r\npmb);\r\npmb->mbox_cmpl =\r\nlpfc_mbx_cmpl_dflt_rpi;\r\npmb->context1 = mp;\r\npmb->context2 = ndlp;\r\npmb->vport = vport;\r\nrc = lpfc_sli_issue_mbox(phba,\r\npmb,\r\nMBX_NOWAIT);\r\nif (rc != MBX_BUSY)\r\nlpfc_printf_log(phba,\r\nKERN_ERR,\r\nLOG_MBOX | LOG_SLI,\r\n"0350 rc should have"\r\n"been MBX_BUSY\n");\r\nif (rc != MBX_NOT_FINISHED)\r\ngoto send_current_mbox;\r\n}\r\n}\r\nspin_lock_irqsave(\r\n&phba->pport->work_port_lock,\r\niflag);\r\nphba->pport->work_port_events &=\r\n~WORKER_MBOX_TMO;\r\nspin_unlock_irqrestore(\r\n&phba->pport->work_port_lock,\r\niflag);\r\nlpfc_mbox_cmpl_put(phba, pmb);\r\n}\r\n} else\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nif ((work_ha_copy & HA_MBATT) &&\r\n(phba->sli.mbox_active == NULL)) {\r\nsend_current_mbox:\r\ndo {\r\nrc = lpfc_sli_issue_mbox(phba, NULL,\r\nMBX_NOWAIT);\r\n} while (rc == MBX_NOT_FINISHED);\r\nif (rc != MBX_SUCCESS)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX |\r\nLOG_SLI, "0349 rc should be "\r\n"MBX_SUCCESS\n");\r\n}\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nphba->work_ha |= work_ha_copy;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nlpfc_worker_wake_up(phba);\r\n}\r\nreturn IRQ_HANDLED;\r\nunplug_error:\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn IRQ_HANDLED;\r\n}\r\nirqreturn_t\r\nlpfc_sli_fp_intr_handler(int irq, void *dev_id)\r\n{\r\nstruct lpfc_hba *phba;\r\nuint32_t ha_copy;\r\nunsigned long status;\r\nunsigned long iflag;\r\nphba = (struct lpfc_hba *) dev_id;\r\nif (unlikely(!phba))\r\nreturn IRQ_NONE;\r\nif (phba->intr_type == MSIX) {\r\nif (lpfc_intr_state_check(phba))\r\nreturn IRQ_NONE;\r\nif (lpfc_readl(phba->HAregaddr, &ha_copy))\r\nreturn IRQ_HANDLED;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (unlikely(phba->hba_flag & DEFER_ERATT)) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn IRQ_NONE;\r\n}\r\nwritel((ha_copy & (HA_R0_CLR_MSK | HA_R1_CLR_MSK)),\r\nphba->HAregaddr);\r\nreadl(phba->HAregaddr);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\n} else\r\nha_copy = phba->ha_copy;\r\nha_copy &= ~(phba->work_ha_mask);\r\nstatus = (ha_copy & (HA_RXMASK << (4*LPFC_FCP_RING)));\r\nstatus >>= (4*LPFC_FCP_RING);\r\nif (status & HA_RXMASK)\r\nlpfc_sli_handle_fast_ring_event(phba,\r\n&phba->sli.ring[LPFC_FCP_RING],\r\nstatus);\r\nif (phba->cfg_multi_ring_support == 2) {\r\nstatus = (ha_copy & (HA_RXMASK << (4*LPFC_EXTRA_RING)));\r\nstatus >>= (4*LPFC_EXTRA_RING);\r\nif (status & HA_RXMASK) {\r\nlpfc_sli_handle_fast_ring_event(phba,\r\n&phba->sli.ring[LPFC_EXTRA_RING],\r\nstatus);\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nirqreturn_t\r\nlpfc_sli_intr_handler(int irq, void *dev_id)\r\n{\r\nstruct lpfc_hba *phba;\r\nirqreturn_t sp_irq_rc, fp_irq_rc;\r\nunsigned long status1, status2;\r\nuint32_t hc_copy;\r\nphba = (struct lpfc_hba *) dev_id;\r\nif (unlikely(!phba))\r\nreturn IRQ_NONE;\r\nif (lpfc_intr_state_check(phba))\r\nreturn IRQ_NONE;\r\nspin_lock(&phba->hbalock);\r\nif (lpfc_readl(phba->HAregaddr, &phba->ha_copy)) {\r\nspin_unlock(&phba->hbalock);\r\nreturn IRQ_HANDLED;\r\n}\r\nif (unlikely(!phba->ha_copy)) {\r\nspin_unlock(&phba->hbalock);\r\nreturn IRQ_NONE;\r\n} else if (phba->ha_copy & HA_ERATT) {\r\nif (phba->hba_flag & HBA_ERATT_HANDLED)\r\nphba->ha_copy &= ~HA_ERATT;\r\nelse\r\nphba->hba_flag |= HBA_ERATT_HANDLED;\r\n}\r\nif (unlikely(phba->hba_flag & DEFER_ERATT)) {\r\nspin_unlock(&phba->hbalock);\r\nreturn IRQ_NONE;\r\n}\r\nif (lpfc_readl(phba->HCregaddr, &hc_copy)) {\r\nspin_unlock(&phba->hbalock);\r\nreturn IRQ_HANDLED;\r\n}\r\nwritel(hc_copy & ~(HC_MBINT_ENA | HC_R0INT_ENA | HC_R1INT_ENA\r\n| HC_R2INT_ENA | HC_LAINT_ENA | HC_ERINT_ENA),\r\nphba->HCregaddr);\r\nwritel((phba->ha_copy & ~(HA_LATT | HA_ERATT)), phba->HAregaddr);\r\nwritel(hc_copy, phba->HCregaddr);\r\nreadl(phba->HAregaddr);\r\nspin_unlock(&phba->hbalock);\r\nstatus1 = phba->ha_copy & (HA_MBATT | HA_LATT | HA_ERATT);\r\nstatus2 = (phba->ha_copy & (HA_RXMASK << (4*LPFC_ELS_RING)));\r\nstatus2 >>= (4*LPFC_ELS_RING);\r\nif (status1 || (status2 & HA_RXMASK))\r\nsp_irq_rc = lpfc_sli_sp_intr_handler(irq, dev_id);\r\nelse\r\nsp_irq_rc = IRQ_NONE;\r\nstatus1 = (phba->ha_copy & (HA_RXMASK << (4*LPFC_FCP_RING)));\r\nstatus1 >>= (4*LPFC_FCP_RING);\r\nif (phba->cfg_multi_ring_support == 2) {\r\nstatus2 = (phba->ha_copy & (HA_RXMASK << (4*LPFC_EXTRA_RING)));\r\nstatus2 >>= (4*LPFC_EXTRA_RING);\r\n} else\r\nstatus2 = 0;\r\nif ((status1 & HA_RXMASK) || (status2 & HA_RXMASK))\r\nfp_irq_rc = lpfc_sli_fp_intr_handler(irq, dev_id);\r\nelse\r\nfp_irq_rc = IRQ_NONE;\r\nreturn (sp_irq_rc == IRQ_HANDLED) ? sp_irq_rc : fp_irq_rc;\r\n}\r\nvoid lpfc_sli4_fcp_xri_abort_event_proc(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_cq_event *cq_event;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~FCP_XRI_ABORT_EVENT;\r\nspin_unlock_irq(&phba->hbalock);\r\nwhile (!list_empty(&phba->sli4_hba.sp_fcp_xri_aborted_work_queue)) {\r\nspin_lock_irq(&phba->hbalock);\r\nlist_remove_head(&phba->sli4_hba.sp_fcp_xri_aborted_work_queue,\r\ncq_event, struct lpfc_cq_event, list);\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_fcp_xri_aborted(phba, &cq_event->cqe.wcqe_axri);\r\nlpfc_sli4_cq_event_release(phba, cq_event);\r\n}\r\n}\r\nvoid lpfc_sli4_els_xri_abort_event_proc(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_cq_event *cq_event;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~ELS_XRI_ABORT_EVENT;\r\nspin_unlock_irq(&phba->hbalock);\r\nwhile (!list_empty(&phba->sli4_hba.sp_els_xri_aborted_work_queue)) {\r\nspin_lock_irq(&phba->hbalock);\r\nlist_remove_head(&phba->sli4_hba.sp_els_xri_aborted_work_queue,\r\ncq_event, struct lpfc_cq_event, list);\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_els_xri_aborted(phba, &cq_event->cqe.wcqe_axri);\r\nlpfc_sli4_cq_event_release(phba, cq_event);\r\n}\r\n}\r\nstatic void\r\nlpfc_sli4_iocb_param_transfer(struct lpfc_hba *phba,\r\nstruct lpfc_iocbq *pIocbIn,\r\nstruct lpfc_iocbq *pIocbOut,\r\nstruct lpfc_wcqe_complete *wcqe)\r\n{\r\nint numBdes, i;\r\nunsigned long iflags;\r\nuint32_t status, max_response;\r\nstruct lpfc_dmabuf *dmabuf;\r\nstruct ulp_bde64 *bpl, bde;\r\nsize_t offset = offsetof(struct lpfc_iocbq, iocb);\r\nmemcpy((char *)pIocbIn + offset, (char *)pIocbOut + offset,\r\nsizeof(struct lpfc_iocbq) - offset);\r\nstatus = bf_get(lpfc_wcqe_c_status, wcqe);\r\npIocbIn->iocb.ulpStatus = (status & LPFC_IOCB_STATUS_MASK);\r\nif (pIocbOut->iocb_flag & LPFC_IO_FCP)\r\nif (pIocbIn->iocb.ulpStatus == IOSTAT_FCP_RSP_ERROR)\r\npIocbIn->iocb.un.fcpi.fcpi_parm =\r\npIocbOut->iocb.un.fcpi.fcpi_parm -\r\nwcqe->total_data_placed;\r\nelse\r\npIocbIn->iocb.un.ulpWord[4] = wcqe->parameter;\r\nelse {\r\npIocbIn->iocb.un.ulpWord[4] = wcqe->parameter;\r\nswitch (pIocbOut->iocb.ulpCommand) {\r\ncase CMD_ELS_REQUEST64_CR:\r\ndmabuf = (struct lpfc_dmabuf *)pIocbOut->context3;\r\nbpl = (struct ulp_bde64 *)dmabuf->virt;\r\nbde.tus.w = le32_to_cpu(bpl[1].tus.w);\r\nmax_response = bde.tus.f.bdeSize;\r\nbreak;\r\ncase CMD_GEN_REQUEST64_CR:\r\nmax_response = 0;\r\nif (!pIocbOut->context3)\r\nbreak;\r\nnumBdes = pIocbOut->iocb.un.genreq64.bdl.bdeSize/\r\nsizeof(struct ulp_bde64);\r\ndmabuf = (struct lpfc_dmabuf *)pIocbOut->context3;\r\nbpl = (struct ulp_bde64 *)dmabuf->virt;\r\nfor (i = 0; i < numBdes; i++) {\r\nbde.tus.w = le32_to_cpu(bpl[i].tus.w);\r\nif (bde.tus.f.bdeFlags != BUFF_TYPE_BDE_64)\r\nmax_response += bde.tus.f.bdeSize;\r\n}\r\nbreak;\r\ndefault:\r\nmax_response = wcqe->total_data_placed;\r\nbreak;\r\n}\r\nif (max_response < wcqe->total_data_placed)\r\npIocbIn->iocb.un.genreq64.bdl.bdeSize = max_response;\r\nelse\r\npIocbIn->iocb.un.genreq64.bdl.bdeSize =\r\nwcqe->total_data_placed;\r\n}\r\nif (status == CQE_STATUS_DI_ERROR) {\r\npIocbIn->iocb.ulpStatus = IOSTAT_LOCAL_REJECT;\r\nif (bf_get(lpfc_wcqe_c_bg_edir, wcqe))\r\npIocbIn->iocb.un.ulpWord[4] = IOERR_RX_DMA_FAILED;\r\nelse\r\npIocbIn->iocb.un.ulpWord[4] = IOERR_TX_DMA_FAILED;\r\npIocbIn->iocb.unsli3.sli3_bg.bgstat = 0;\r\nif (bf_get(lpfc_wcqe_c_bg_ge, wcqe))\r\npIocbIn->iocb.unsli3.sli3_bg.bgstat |=\r\nBGS_GUARD_ERR_MASK;\r\nif (bf_get(lpfc_wcqe_c_bg_ae, wcqe))\r\npIocbIn->iocb.unsli3.sli3_bg.bgstat |=\r\nBGS_APPTAG_ERR_MASK;\r\nif (bf_get(lpfc_wcqe_c_bg_re, wcqe))\r\npIocbIn->iocb.unsli3.sli3_bg.bgstat |=\r\nBGS_REFTAG_ERR_MASK;\r\nif (bf_get(lpfc_wcqe_c_bg_tdpv, wcqe)) {\r\npIocbIn->iocb.unsli3.sli3_bg.bgstat |=\r\nBGS_HI_WATER_MARK_PRESENT_MASK;\r\npIocbIn->iocb.unsli3.sli3_bg.bghm =\r\nwcqe->total_data_placed;\r\n}\r\nif (!pIocbIn->iocb.unsli3.sli3_bg.bgstat)\r\npIocbIn->iocb.unsli3.sli3_bg.bgstat |=\r\n(BGS_REFTAG_ERR_MASK | BGS_APPTAG_ERR_MASK |\r\nBGS_GUARD_ERR_MASK);\r\n}\r\nif (bf_get(lpfc_wcqe_c_xb, wcqe)) {\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\npIocbIn->iocb_flag |= LPFC_EXCHANGE_BUSY;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\n}\r\n}\r\nstatic struct lpfc_iocbq *\r\nlpfc_sli4_els_wcqe_to_rspiocbq(struct lpfc_hba *phba,\r\nstruct lpfc_iocbq *irspiocbq)\r\n{\r\nstruct lpfc_sli_ring *pring = &phba->sli.ring[LPFC_ELS_RING];\r\nstruct lpfc_iocbq *cmdiocbq;\r\nstruct lpfc_wcqe_complete *wcqe;\r\nunsigned long iflags;\r\nwcqe = &irspiocbq->cq_event.cqe.wcqe_cmpl;\r\nspin_lock_irqsave(&pring->ring_lock, iflags);\r\npring->stats.iocb_event++;\r\ncmdiocbq = lpfc_sli_iocbq_lookup_by_tag(phba, pring,\r\nbf_get(lpfc_wcqe_c_request_tag, wcqe));\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\nif (unlikely(!cmdiocbq)) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0386 ELS complete with no corresponding "\r\n"cmdiocb: iotag (%d)\n",\r\nbf_get(lpfc_wcqe_c_request_tag, wcqe));\r\nlpfc_sli_release_iocbq(phba, irspiocbq);\r\nreturn NULL;\r\n}\r\nlpfc_sli4_iocb_param_transfer(phba, irspiocbq, cmdiocbq, wcqe);\r\nreturn irspiocbq;\r\n}\r\nstatic bool\r\nlpfc_sli4_sp_handle_async_event(struct lpfc_hba *phba, struct lpfc_mcqe *mcqe)\r\n{\r\nstruct lpfc_cq_event *cq_event;\r\nunsigned long iflags;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0392 Async Event: word0:x%x, word1:x%x, "\r\n"word2:x%x, word3:x%x\n", mcqe->word0,\r\nmcqe->mcqe_tag0, mcqe->mcqe_tag1, mcqe->trailer);\r\ncq_event = lpfc_sli4_cq_event_alloc(phba);\r\nif (!cq_event) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0394 Failed to allocate CQ_EVENT entry\n");\r\nreturn false;\r\n}\r\nmemcpy(&cq_event->cqe, mcqe, sizeof(struct lpfc_mcqe));\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nlist_add_tail(&cq_event->list, &phba->sli4_hba.sp_asynce_work_queue);\r\nphba->hba_flag |= ASYNC_EVENT;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn true;\r\n}\r\nstatic bool\r\nlpfc_sli4_sp_handle_mbox_event(struct lpfc_hba *phba, struct lpfc_mcqe *mcqe)\r\n{\r\nuint32_t mcqe_status;\r\nMAILBOX_t *mbox, *pmbox;\r\nstruct lpfc_mqe *mqe;\r\nstruct lpfc_vport *vport;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct lpfc_dmabuf *mp;\r\nunsigned long iflags;\r\nLPFC_MBOXQ_t *pmb;\r\nbool workposted = false;\r\nint rc;\r\nif (!bf_get(lpfc_trailer_completed, mcqe))\r\ngoto out_no_mqe_complete;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\npmb = phba->sli.mbox_active;\r\nif (unlikely(!pmb)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX,\r\n"1832 No pending MBOX command to handle\n");\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\ngoto out_no_mqe_complete;\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nmqe = &pmb->u.mqe;\r\npmbox = (MAILBOX_t *)&pmb->u.mqe;\r\nmbox = phba->mbox;\r\nvport = pmb->vport;\r\nphba->last_completion_time = jiffies;\r\ndel_timer(&phba->sli.mbox_tmo);\r\nif (pmb->mbox_cmpl && mbox)\r\nlpfc_sli_pcimem_bcopy(mbox, mqe, sizeof(struct lpfc_mqe));\r\nmcqe_status = bf_get(lpfc_mcqe_status, mcqe);\r\nif (mcqe_status != MB_CQE_STATUS_SUCCESS) {\r\nif (bf_get(lpfc_mqe_status, mqe) == MBX_SUCCESS)\r\nbf_set(lpfc_mqe_status, mqe,\r\n(LPFC_MBX_ERROR_RANGE | mcqe_status));\r\n}\r\nif (pmb->mbox_flag & LPFC_MBX_IMED_UNREG) {\r\npmb->mbox_flag &= ~LPFC_MBX_IMED_UNREG;\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_MBOX_VPORT,\r\n"MBOX dflt rpi: status:x%x rpi:x%x",\r\nmcqe_status,\r\npmbox->un.varWords[0], 0);\r\nif (mcqe_status == MB_CQE_STATUS_SUCCESS) {\r\nmp = (struct lpfc_dmabuf *)(pmb->context1);\r\nndlp = (struct lpfc_nodelist *)pmb->context2;\r\nlpfc_unreg_login(phba, vport->vpi,\r\npmbox->un.varWords[0], pmb);\r\npmb->mbox_cmpl = lpfc_mbx_cmpl_dflt_rpi;\r\npmb->context1 = mp;\r\npmb->context2 = ndlp;\r\npmb->vport = vport;\r\nrc = lpfc_sli_issue_mbox(phba, pmb, MBX_NOWAIT);\r\nif (rc != MBX_BUSY)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX |\r\nLOG_SLI, "0385 rc should "\r\n"have been MBX_BUSY\n");\r\nif (rc != MBX_NOT_FINISHED)\r\ngoto send_current_mbox;\r\n}\r\n}\r\nspin_lock_irqsave(&phba->pport->work_port_lock, iflags);\r\nphba->pport->work_port_events &= ~WORKER_MBOX_TMO;\r\nspin_unlock_irqrestore(&phba->pport->work_port_lock, iflags);\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\n__lpfc_mbox_cmpl_put(phba, pmb);\r\nphba->work_ha |= HA_MBATT;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nworkposted = true;\r\nsend_current_mbox:\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nphba->sli.sli_flag &= ~LPFC_SLI_MBOX_ACTIVE;\r\nphba->sli.mbox_active = NULL;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nlpfc_worker_wake_up(phba);\r\nout_no_mqe_complete:\r\nif (bf_get(lpfc_trailer_consumed, mcqe))\r\nlpfc_sli4_mq_release(phba->sli4_hba.mbx_wq);\r\nreturn workposted;\r\n}\r\nstatic bool\r\nlpfc_sli4_sp_handle_mcqe(struct lpfc_hba *phba, struct lpfc_cqe *cqe)\r\n{\r\nstruct lpfc_mcqe mcqe;\r\nbool workposted;\r\nlpfc_sli_pcimem_bcopy(cqe, &mcqe, sizeof(struct lpfc_mcqe));\r\nif (!bf_get(lpfc_trailer_async, &mcqe))\r\nworkposted = lpfc_sli4_sp_handle_mbox_event(phba, &mcqe);\r\nelse\r\nworkposted = lpfc_sli4_sp_handle_async_event(phba, &mcqe);\r\nreturn workposted;\r\n}\r\nstatic bool\r\nlpfc_sli4_sp_handle_els_wcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\r\nstruct lpfc_wcqe_complete *wcqe)\r\n{\r\nstruct lpfc_iocbq *irspiocbq;\r\nunsigned long iflags;\r\nstruct lpfc_sli_ring *pring = cq->pring;\r\nint txq_cnt = 0;\r\nint txcmplq_cnt = 0;\r\nint fcp_txcmplq_cnt = 0;\r\nirspiocbq = lpfc_sli_get_iocbq(phba);\r\nif (!irspiocbq) {\r\nif (!list_empty(&pring->txq))\r\ntxq_cnt++;\r\nif (!list_empty(&pring->txcmplq))\r\ntxcmplq_cnt++;\r\nif (!list_empty(&phba->sli.ring[LPFC_FCP_RING].txcmplq))\r\nfcp_txcmplq_cnt++;\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0387 NO IOCBQ data: txq_cnt=%d iocb_cnt=%d "\r\n"fcp_txcmplq_cnt=%d, els_txcmplq_cnt=%d\n",\r\ntxq_cnt, phba->iocb_cnt,\r\nfcp_txcmplq_cnt,\r\ntxcmplq_cnt);\r\nreturn false;\r\n}\r\nmemcpy(&irspiocbq->cq_event.cqe.wcqe_cmpl, wcqe, sizeof(*wcqe));\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nlist_add_tail(&irspiocbq->cq_event.list,\r\n&phba->sli4_hba.sp_queue_event);\r\nphba->hba_flag |= HBA_SP_QUEUE_EVT;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nreturn true;\r\n}\r\nstatic void\r\nlpfc_sli4_sp_handle_rel_wcqe(struct lpfc_hba *phba,\r\nstruct lpfc_wcqe_release *wcqe)\r\n{\r\nif (unlikely(!phba->sli4_hba.els_wq))\r\nreturn;\r\nif (bf_get(lpfc_wcqe_r_wq_id, wcqe) == phba->sli4_hba.els_wq->queue_id)\r\nlpfc_sli4_wq_release(phba->sli4_hba.els_wq,\r\nbf_get(lpfc_wcqe_r_wqe_index, wcqe));\r\nelse\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"2579 Slow-path wqe consume event carries "\r\n"miss-matched qid: wcqe-qid=x%x, sp-qid=x%x\n",\r\nbf_get(lpfc_wcqe_r_wqe_index, wcqe),\r\nphba->sli4_hba.els_wq->queue_id);\r\n}\r\nstatic bool\r\nlpfc_sli4_sp_handle_abort_xri_wcqe(struct lpfc_hba *phba,\r\nstruct lpfc_queue *cq,\r\nstruct sli4_wcqe_xri_aborted *wcqe)\r\n{\r\nbool workposted = false;\r\nstruct lpfc_cq_event *cq_event;\r\nunsigned long iflags;\r\ncq_event = lpfc_sli4_cq_event_alloc(phba);\r\nif (!cq_event) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0602 Failed to allocate CQ_EVENT entry\n");\r\nreturn false;\r\n}\r\nmemcpy(&cq_event->cqe, wcqe, sizeof(struct sli4_wcqe_xri_aborted));\r\nswitch (cq->subtype) {\r\ncase LPFC_FCP:\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nlist_add_tail(&cq_event->list,\r\n&phba->sli4_hba.sp_fcp_xri_aborted_work_queue);\r\nphba->hba_flag |= FCP_XRI_ABORT_EVENT;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nworkposted = true;\r\nbreak;\r\ncase LPFC_ELS:\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nlist_add_tail(&cq_event->list,\r\n&phba->sli4_hba.sp_els_xri_aborted_work_queue);\r\nphba->hba_flag |= ELS_XRI_ABORT_EVENT;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nworkposted = true;\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0603 Invalid work queue CQE subtype (x%x)\n",\r\ncq->subtype);\r\nworkposted = false;\r\nbreak;\r\n}\r\nreturn workposted;\r\n}\r\nstatic bool\r\nlpfc_sli4_sp_handle_rcqe(struct lpfc_hba *phba, struct lpfc_rcqe *rcqe)\r\n{\r\nbool workposted = false;\r\nstruct lpfc_queue *hrq = phba->sli4_hba.hdr_rq;\r\nstruct lpfc_queue *drq = phba->sli4_hba.dat_rq;\r\nstruct hbq_dmabuf *dma_buf;\r\nuint32_t status, rq_id;\r\nunsigned long iflags;\r\nif (unlikely(!hrq) || unlikely(!drq))\r\nreturn workposted;\r\nif (bf_get(lpfc_cqe_code, rcqe) == CQE_CODE_RECEIVE_V1)\r\nrq_id = bf_get(lpfc_rcqe_rq_id_v1, rcqe);\r\nelse\r\nrq_id = bf_get(lpfc_rcqe_rq_id, rcqe);\r\nif (rq_id != hrq->queue_id)\r\ngoto out;\r\nstatus = bf_get(lpfc_rcqe_status, rcqe);\r\nswitch (status) {\r\ncase FC_STATUS_RQ_BUF_LEN_EXCEEDED:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2537 Receive Frame Truncated!!\n");\r\nhrq->RQ_buf_trunc++;\r\ncase FC_STATUS_RQ_SUCCESS:\r\nlpfc_sli4_rq_release(hrq, drq);\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\ndma_buf = lpfc_sli_hbqbuf_get(&phba->hbqs[0].hbq_buffer_list);\r\nif (!dma_buf) {\r\nhrq->RQ_no_buf_found++;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\ngoto out;\r\n}\r\nhrq->RQ_rcv_buf++;\r\nmemcpy(&dma_buf->cq_event.cqe.rcqe_cmpl, rcqe, sizeof(*rcqe));\r\nlist_add_tail(&dma_buf->cq_event.list,\r\n&phba->sli4_hba.sp_queue_event);\r\nphba->hba_flag |= HBA_SP_QUEUE_EVT;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nworkposted = true;\r\nbreak;\r\ncase FC_STATUS_INSUFF_BUF_NEED_BUF:\r\ncase FC_STATUS_INSUFF_BUF_FRM_DISC:\r\nhrq->RQ_no_posted_buf++;\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\nphba->hba_flag |= HBA_POST_RECEIVE_BUFFER;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\nworkposted = true;\r\nbreak;\r\n}\r\nout:\r\nreturn workposted;\r\n}\r\nstatic bool\r\nlpfc_sli4_sp_handle_cqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\r\nstruct lpfc_cqe *cqe)\r\n{\r\nstruct lpfc_cqe cqevt;\r\nbool workposted = false;\r\nlpfc_sli_pcimem_bcopy(cqe, &cqevt, sizeof(struct lpfc_cqe));\r\nswitch (bf_get(lpfc_cqe_code, &cqevt)) {\r\ncase CQE_CODE_COMPL_WQE:\r\nphba->last_completion_time = jiffies;\r\nworkposted = lpfc_sli4_sp_handle_els_wcqe(phba, cq,\r\n(struct lpfc_wcqe_complete *)&cqevt);\r\nbreak;\r\ncase CQE_CODE_RELEASE_WQE:\r\nlpfc_sli4_sp_handle_rel_wcqe(phba,\r\n(struct lpfc_wcqe_release *)&cqevt);\r\nbreak;\r\ncase CQE_CODE_XRI_ABORTED:\r\nphba->last_completion_time = jiffies;\r\nworkposted = lpfc_sli4_sp_handle_abort_xri_wcqe(phba, cq,\r\n(struct sli4_wcqe_xri_aborted *)&cqevt);\r\nbreak;\r\ncase CQE_CODE_RECEIVE:\r\ncase CQE_CODE_RECEIVE_V1:\r\nphba->last_completion_time = jiffies;\r\nworkposted = lpfc_sli4_sp_handle_rcqe(phba,\r\n(struct lpfc_rcqe *)&cqevt);\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0388 Not a valid WCQE code: x%x\n",\r\nbf_get(lpfc_cqe_code, &cqevt));\r\nbreak;\r\n}\r\nreturn workposted;\r\n}\r\nstatic void\r\nlpfc_sli4_sp_handle_eqe(struct lpfc_hba *phba, struct lpfc_eqe *eqe,\r\nstruct lpfc_queue *speq)\r\n{\r\nstruct lpfc_queue *cq = NULL, *childq;\r\nstruct lpfc_cqe *cqe;\r\nbool workposted = false;\r\nint ecount = 0;\r\nuint16_t cqid;\r\ncqid = bf_get_le32(lpfc_eqe_resource_id, eqe);\r\nlist_for_each_entry(childq, &speq->child_list, list) {\r\nif (childq->queue_id == cqid) {\r\ncq = childq;\r\nbreak;\r\n}\r\n}\r\nif (unlikely(!cq)) {\r\nif (phba->sli.sli_flag & LPFC_SLI_ACTIVE)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0365 Slow-path CQ identifier "\r\n"(%d) does not exist\n", cqid);\r\nreturn;\r\n}\r\nswitch (cq->type) {\r\ncase LPFC_MCQ:\r\nwhile ((cqe = lpfc_sli4_cq_get(cq))) {\r\nworkposted |= lpfc_sli4_sp_handle_mcqe(phba, cqe);\r\nif (!(++ecount % cq->entry_repost))\r\nlpfc_sli4_cq_release(cq, LPFC_QUEUE_NOARM);\r\ncq->CQ_mbox++;\r\n}\r\nbreak;\r\ncase LPFC_WCQ:\r\nwhile ((cqe = lpfc_sli4_cq_get(cq))) {\r\nif (cq->subtype == LPFC_FCP)\r\nworkposted |= lpfc_sli4_fp_handle_wcqe(phba, cq,\r\ncqe);\r\nelse\r\nworkposted |= lpfc_sli4_sp_handle_cqe(phba, cq,\r\ncqe);\r\nif (!(++ecount % cq->entry_repost))\r\nlpfc_sli4_cq_release(cq, LPFC_QUEUE_NOARM);\r\n}\r\nif (ecount > cq->CQ_max_cqe)\r\ncq->CQ_max_cqe = ecount;\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0370 Invalid completion queue type (%d)\n",\r\ncq->type);\r\nreturn;\r\n}\r\nif (unlikely(ecount == 0))\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0371 No entry from the CQ: identifier "\r\n"(x%x), type (%d)\n", cq->queue_id, cq->type);\r\nlpfc_sli4_cq_release(cq, LPFC_QUEUE_REARM);\r\nif (workposted)\r\nlpfc_worker_wake_up(phba);\r\n}\r\nstatic void\r\nlpfc_sli4_fp_handle_fcp_wcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\r\nstruct lpfc_wcqe_complete *wcqe)\r\n{\r\nstruct lpfc_sli_ring *pring = cq->pring;\r\nstruct lpfc_iocbq *cmdiocbq;\r\nstruct lpfc_iocbq irspiocbq;\r\nunsigned long iflags;\r\nif (unlikely(bf_get(lpfc_wcqe_c_status, wcqe))) {\r\nif (((bf_get(lpfc_wcqe_c_status, wcqe) ==\r\nIOSTAT_LOCAL_REJECT)) &&\r\n((wcqe->parameter & IOERR_PARAM_MASK) ==\r\nIOERR_NO_RESOURCES))\r\nphba->lpfc_rampdown_queue_depth(phba);\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0373 FCP complete error: status=x%x, "\r\n"hw_status=x%x, total_data_specified=%d, "\r\n"parameter=x%x, word3=x%x\n",\r\nbf_get(lpfc_wcqe_c_status, wcqe),\r\nbf_get(lpfc_wcqe_c_hw_status, wcqe),\r\nwcqe->total_data_placed, wcqe->parameter,\r\nwcqe->word3);\r\n}\r\nspin_lock_irqsave(&pring->ring_lock, iflags);\r\npring->stats.iocb_event++;\r\ncmdiocbq = lpfc_sli_iocbq_lookup_by_tag(phba, pring,\r\nbf_get(lpfc_wcqe_c_request_tag, wcqe));\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\nif (unlikely(!cmdiocbq)) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0374 FCP complete with no corresponding "\r\n"cmdiocb: iotag (%d)\n",\r\nbf_get(lpfc_wcqe_c_request_tag, wcqe));\r\nreturn;\r\n}\r\nif (unlikely(!cmdiocbq->iocb_cmpl)) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0375 FCP cmdiocb not callback function "\r\n"iotag: (%d)\n",\r\nbf_get(lpfc_wcqe_c_request_tag, wcqe));\r\nreturn;\r\n}\r\nlpfc_sli4_iocb_param_transfer(phba, &irspiocbq, cmdiocbq, wcqe);\r\nif (cmdiocbq->iocb_flag & LPFC_DRIVER_ABORTED) {\r\nspin_lock_irqsave(&phba->hbalock, iflags);\r\ncmdiocbq->iocb_flag &= ~LPFC_DRIVER_ABORTED;\r\nspin_unlock_irqrestore(&phba->hbalock, iflags);\r\n}\r\n(cmdiocbq->iocb_cmpl)(phba, cmdiocbq, &irspiocbq);\r\n}\r\nstatic void\r\nlpfc_sli4_fp_handle_rel_wcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\r\nstruct lpfc_wcqe_release *wcqe)\r\n{\r\nstruct lpfc_queue *childwq;\r\nbool wqid_matched = false;\r\nuint16_t fcp_wqid;\r\nfcp_wqid = bf_get(lpfc_wcqe_r_wq_id, wcqe);\r\nlist_for_each_entry(childwq, &cq->child_list, list) {\r\nif (childwq->queue_id == fcp_wqid) {\r\nlpfc_sli4_wq_release(childwq,\r\nbf_get(lpfc_wcqe_r_wqe_index, wcqe));\r\nwqid_matched = true;\r\nbreak;\r\n}\r\n}\r\nif (wqid_matched != true)\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"2580 Fast-path wqe consume event carries "\r\n"miss-matched qid: wcqe-qid=x%x\n", fcp_wqid);\r\n}\r\nstatic int\r\nlpfc_sli4_fp_handle_wcqe(struct lpfc_hba *phba, struct lpfc_queue *cq,\r\nstruct lpfc_cqe *cqe)\r\n{\r\nstruct lpfc_wcqe_release wcqe;\r\nbool workposted = false;\r\nlpfc_sli_pcimem_bcopy(cqe, &wcqe, sizeof(struct lpfc_cqe));\r\nswitch (bf_get(lpfc_wcqe_c_code, &wcqe)) {\r\ncase CQE_CODE_COMPL_WQE:\r\ncq->CQ_wq++;\r\nphba->last_completion_time = jiffies;\r\nlpfc_sli4_fp_handle_fcp_wcqe(phba, cq,\r\n(struct lpfc_wcqe_complete *)&wcqe);\r\nbreak;\r\ncase CQE_CODE_RELEASE_WQE:\r\ncq->CQ_release_wqe++;\r\nlpfc_sli4_fp_handle_rel_wcqe(phba, cq,\r\n(struct lpfc_wcqe_release *)&wcqe);\r\nbreak;\r\ncase CQE_CODE_XRI_ABORTED:\r\ncq->CQ_xri_aborted++;\r\nphba->last_completion_time = jiffies;\r\nworkposted = lpfc_sli4_sp_handle_abort_xri_wcqe(phba, cq,\r\n(struct sli4_wcqe_xri_aborted *)&wcqe);\r\nbreak;\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0144 Not a valid WCQE code: x%x\n",\r\nbf_get(lpfc_wcqe_c_code, &wcqe));\r\nbreak;\r\n}\r\nreturn workposted;\r\n}\r\nstatic void\r\nlpfc_sli4_hba_handle_eqe(struct lpfc_hba *phba, struct lpfc_eqe *eqe,\r\nuint32_t qidx)\r\n{\r\nstruct lpfc_queue *cq;\r\nstruct lpfc_cqe *cqe;\r\nbool workposted = false;\r\nuint16_t cqid;\r\nint ecount = 0;\r\nif (unlikely(bf_get_le32(lpfc_eqe_major_code, eqe) != 0)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0366 Not a valid completion "\r\n"event: majorcode=x%x, minorcode=x%x\n",\r\nbf_get_le32(lpfc_eqe_major_code, eqe),\r\nbf_get_le32(lpfc_eqe_minor_code, eqe));\r\nreturn;\r\n}\r\ncqid = bf_get_le32(lpfc_eqe_resource_id, eqe);\r\nif (unlikely(cqid != phba->sli4_hba.fcp_cq_map[qidx])) {\r\nlpfc_sli4_sp_handle_eqe(phba, eqe,\r\nphba->sli4_hba.hba_eq[qidx]);\r\nreturn;\r\n}\r\nif (unlikely(!phba->sli4_hba.fcp_cq)) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"3146 Fast-path completion queues "\r\n"does not exist\n");\r\nreturn;\r\n}\r\ncq = phba->sli4_hba.fcp_cq[qidx];\r\nif (unlikely(!cq)) {\r\nif (phba->sli.sli_flag & LPFC_SLI_ACTIVE)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0367 Fast-path completion queue "\r\n"(%d) does not exist\n", qidx);\r\nreturn;\r\n}\r\nif (unlikely(cqid != cq->queue_id)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0368 Miss-matched fast-path completion "\r\n"queue identifier: eqcqid=%d, fcpcqid=%d\n",\r\ncqid, cq->queue_id);\r\nreturn;\r\n}\r\nwhile ((cqe = lpfc_sli4_cq_get(cq))) {\r\nworkposted |= lpfc_sli4_fp_handle_wcqe(phba, cq, cqe);\r\nif (!(++ecount % cq->entry_repost))\r\nlpfc_sli4_cq_release(cq, LPFC_QUEUE_NOARM);\r\n}\r\nif (ecount > cq->CQ_max_cqe)\r\ncq->CQ_max_cqe = ecount;\r\nif (unlikely(ecount == 0))\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0369 No entry from fast-path completion "\r\n"queue fcpcqid=%d\n", cq->queue_id);\r\nlpfc_sli4_cq_release(cq, LPFC_QUEUE_REARM);\r\nif (workposted)\r\nlpfc_worker_wake_up(phba);\r\n}\r\nstatic void\r\nlpfc_sli4_eq_flush(struct lpfc_hba *phba, struct lpfc_queue *eq)\r\n{\r\nstruct lpfc_eqe *eqe;\r\nwhile ((eqe = lpfc_sli4_eq_get(eq)))\r\n;\r\nlpfc_sli4_eq_release(eq, LPFC_QUEUE_REARM);\r\n}\r\nstatic void\r\nlpfc_sli4_fof_handle_eqe(struct lpfc_hba *phba, struct lpfc_eqe *eqe)\r\n{\r\nstruct lpfc_queue *cq;\r\nstruct lpfc_cqe *cqe;\r\nbool workposted = false;\r\nuint16_t cqid;\r\nint ecount = 0;\r\nif (unlikely(bf_get_le32(lpfc_eqe_major_code, eqe) != 0)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"9147 Not a valid completion "\r\n"event: majorcode=x%x, minorcode=x%x\n",\r\nbf_get_le32(lpfc_eqe_major_code, eqe),\r\nbf_get_le32(lpfc_eqe_minor_code, eqe));\r\nreturn;\r\n}\r\ncqid = bf_get_le32(lpfc_eqe_resource_id, eqe);\r\ncq = phba->sli4_hba.oas_cq;\r\nif (unlikely(!cq)) {\r\nif (phba->sli.sli_flag & LPFC_SLI_ACTIVE)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"9148 OAS completion queue "\r\n"does not exist\n");\r\nreturn;\r\n}\r\nif (unlikely(cqid != cq->queue_id)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"9149 Miss-matched fast-path compl "\r\n"queue id: eqcqid=%d, fcpcqid=%d\n",\r\ncqid, cq->queue_id);\r\nreturn;\r\n}\r\nwhile ((cqe = lpfc_sli4_cq_get(cq))) {\r\nworkposted |= lpfc_sli4_fp_handle_wcqe(phba, cq, cqe);\r\nif (!(++ecount % cq->entry_repost))\r\nlpfc_sli4_cq_release(cq, LPFC_QUEUE_NOARM);\r\n}\r\nif (ecount > cq->CQ_max_cqe)\r\ncq->CQ_max_cqe = ecount;\r\nif (unlikely(ecount == 0))\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"9153 No entry from fast-path completion "\r\n"queue fcpcqid=%d\n", cq->queue_id);\r\nlpfc_sli4_cq_release(cq, LPFC_QUEUE_REARM);\r\nif (workposted)\r\nlpfc_worker_wake_up(phba);\r\n}\r\nirqreturn_t\r\nlpfc_sli4_fof_intr_handler(int irq, void *dev_id)\r\n{\r\nstruct lpfc_hba *phba;\r\nstruct lpfc_fcp_eq_hdl *fcp_eq_hdl;\r\nstruct lpfc_queue *eq;\r\nstruct lpfc_eqe *eqe;\r\nunsigned long iflag;\r\nint ecount = 0;\r\nuint32_t eqidx;\r\nfcp_eq_hdl = (struct lpfc_fcp_eq_hdl *)dev_id;\r\nphba = fcp_eq_hdl->phba;\r\neqidx = fcp_eq_hdl->idx;\r\nif (unlikely(!phba))\r\nreturn IRQ_NONE;\r\neq = phba->sli4_hba.fof_eq;\r\nif (unlikely(!eq))\r\nreturn IRQ_NONE;\r\nif (unlikely(lpfc_intr_state_check(phba))) {\r\neq->EQ_badstate++;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (phba->link_state < LPFC_LINK_DOWN)\r\nlpfc_sli4_eq_flush(phba, eq);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn IRQ_NONE;\r\n}\r\nwhile ((eqe = lpfc_sli4_eq_get(eq))) {\r\nlpfc_sli4_fof_handle_eqe(phba, eqe);\r\nif (!(++ecount % eq->entry_repost))\r\nlpfc_sli4_eq_release(eq, LPFC_QUEUE_NOARM);\r\neq->EQ_processed++;\r\n}\r\nif (ecount > eq->EQ_max_eqe)\r\neq->EQ_max_eqe = ecount;\r\nif (unlikely(ecount == 0)) {\r\neq->EQ_no_entry++;\r\nif (phba->intr_type == MSIX)\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"9145 MSI-X interrupt with no EQE\n");\r\nelse {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"9146 ISR interrupt with no EQE\n");\r\nreturn IRQ_NONE;\r\n}\r\n}\r\nlpfc_sli4_eq_release(eq, LPFC_QUEUE_REARM);\r\nreturn IRQ_HANDLED;\r\n}\r\nirqreturn_t\r\nlpfc_sli4_hba_intr_handler(int irq, void *dev_id)\r\n{\r\nstruct lpfc_hba *phba;\r\nstruct lpfc_fcp_eq_hdl *fcp_eq_hdl;\r\nstruct lpfc_queue *fpeq;\r\nstruct lpfc_eqe *eqe;\r\nunsigned long iflag;\r\nint ecount = 0;\r\nint fcp_eqidx;\r\nfcp_eq_hdl = (struct lpfc_fcp_eq_hdl *)dev_id;\r\nphba = fcp_eq_hdl->phba;\r\nfcp_eqidx = fcp_eq_hdl->idx;\r\nif (unlikely(!phba))\r\nreturn IRQ_NONE;\r\nif (unlikely(!phba->sli4_hba.hba_eq))\r\nreturn IRQ_NONE;\r\nfpeq = phba->sli4_hba.hba_eq[fcp_eqidx];\r\nif (unlikely(!fpeq))\r\nreturn IRQ_NONE;\r\nif (lpfc_fcp_look_ahead) {\r\nif (atomic_dec_and_test(&fcp_eq_hdl->fcp_eq_in_use))\r\nlpfc_sli4_eq_clr_intr(fpeq);\r\nelse {\r\natomic_inc(&fcp_eq_hdl->fcp_eq_in_use);\r\nreturn IRQ_NONE;\r\n}\r\n}\r\nif (unlikely(lpfc_intr_state_check(phba))) {\r\nfpeq->EQ_badstate++;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nif (phba->link_state < LPFC_LINK_DOWN)\r\nlpfc_sli4_eq_flush(phba, fpeq);\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nif (lpfc_fcp_look_ahead)\r\natomic_inc(&fcp_eq_hdl->fcp_eq_in_use);\r\nreturn IRQ_NONE;\r\n}\r\nwhile ((eqe = lpfc_sli4_eq_get(fpeq))) {\r\nif (eqe == NULL)\r\nbreak;\r\nlpfc_sli4_hba_handle_eqe(phba, eqe, fcp_eqidx);\r\nif (!(++ecount % fpeq->entry_repost))\r\nlpfc_sli4_eq_release(fpeq, LPFC_QUEUE_NOARM);\r\nfpeq->EQ_processed++;\r\n}\r\nif (ecount > fpeq->EQ_max_eqe)\r\nfpeq->EQ_max_eqe = ecount;\r\nlpfc_sli4_eq_release(fpeq, LPFC_QUEUE_REARM);\r\nif (unlikely(ecount == 0)) {\r\nfpeq->EQ_no_entry++;\r\nif (lpfc_fcp_look_ahead) {\r\natomic_inc(&fcp_eq_hdl->fcp_eq_in_use);\r\nreturn IRQ_NONE;\r\n}\r\nif (phba->intr_type == MSIX)\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"0358 MSI-X interrupt with no EQE\n");\r\nelse\r\nreturn IRQ_NONE;\r\n}\r\nif (lpfc_fcp_look_ahead)\r\natomic_inc(&fcp_eq_hdl->fcp_eq_in_use);\r\nreturn IRQ_HANDLED;\r\n}\r\nirqreturn_t\r\nlpfc_sli4_intr_handler(int irq, void *dev_id)\r\n{\r\nstruct lpfc_hba *phba;\r\nirqreturn_t hba_irq_rc;\r\nbool hba_handled = false;\r\nint fcp_eqidx;\r\nphba = (struct lpfc_hba *)dev_id;\r\nif (unlikely(!phba))\r\nreturn IRQ_NONE;\r\nfor (fcp_eqidx = 0; fcp_eqidx < phba->cfg_fcp_io_channel; fcp_eqidx++) {\r\nhba_irq_rc = lpfc_sli4_hba_intr_handler(irq,\r\n&phba->sli4_hba.fcp_eq_hdl[fcp_eqidx]);\r\nif (hba_irq_rc == IRQ_HANDLED)\r\nhba_handled |= true;\r\n}\r\nif (phba->cfg_fof) {\r\nhba_irq_rc = lpfc_sli4_fof_intr_handler(irq,\r\n&phba->sli4_hba.fcp_eq_hdl[0]);\r\nif (hba_irq_rc == IRQ_HANDLED)\r\nhba_handled |= true;\r\n}\r\nreturn (hba_handled == true) ? IRQ_HANDLED : IRQ_NONE;\r\n}\r\nvoid\r\nlpfc_sli4_queue_free(struct lpfc_queue *queue)\r\n{\r\nstruct lpfc_dmabuf *dmabuf;\r\nif (!queue)\r\nreturn;\r\nwhile (!list_empty(&queue->page_list)) {\r\nlist_remove_head(&queue->page_list, dmabuf, struct lpfc_dmabuf,\r\nlist);\r\ndma_free_coherent(&queue->phba->pcidev->dev, SLI4_PAGE_SIZE,\r\ndmabuf->virt, dmabuf->phys);\r\nkfree(dmabuf);\r\n}\r\nkfree(queue);\r\nreturn;\r\n}\r\nstruct lpfc_queue *\r\nlpfc_sli4_queue_alloc(struct lpfc_hba *phba, uint32_t entry_size,\r\nuint32_t entry_count)\r\n{\r\nstruct lpfc_queue *queue;\r\nstruct lpfc_dmabuf *dmabuf;\r\nint x, total_qe_count;\r\nvoid *dma_pointer;\r\nuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\r\nif (!phba->sli4_hba.pc_sli4_params.supported)\r\nhw_page_size = SLI4_PAGE_SIZE;\r\nqueue = kzalloc(sizeof(struct lpfc_queue) +\r\n(sizeof(union sli4_qe) * entry_count), GFP_KERNEL);\r\nif (!queue)\r\nreturn NULL;\r\nqueue->page_count = (ALIGN(entry_size * entry_count,\r\nhw_page_size))/hw_page_size;\r\nINIT_LIST_HEAD(&queue->list);\r\nINIT_LIST_HEAD(&queue->page_list);\r\nINIT_LIST_HEAD(&queue->child_list);\r\nfor (x = 0, total_qe_count = 0; x < queue->page_count; x++) {\r\ndmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);\r\nif (!dmabuf)\r\ngoto out_fail;\r\ndmabuf->virt = dma_zalloc_coherent(&phba->pcidev->dev,\r\nhw_page_size, &dmabuf->phys,\r\nGFP_KERNEL);\r\nif (!dmabuf->virt) {\r\nkfree(dmabuf);\r\ngoto out_fail;\r\n}\r\ndmabuf->buffer_tag = x;\r\nlist_add_tail(&dmabuf->list, &queue->page_list);\r\ndma_pointer = dmabuf->virt;\r\nfor (; total_qe_count < entry_count &&\r\ndma_pointer < (hw_page_size + dmabuf->virt);\r\ntotal_qe_count++, dma_pointer += entry_size) {\r\nqueue->qe[total_qe_count].address = dma_pointer;\r\n}\r\n}\r\nqueue->entry_size = entry_size;\r\nqueue->entry_count = entry_count;\r\nqueue->entry_repost = (entry_count >> 3);\r\nif (queue->entry_repost < LPFC_QUEUE_MIN_REPOST)\r\nqueue->entry_repost = LPFC_QUEUE_MIN_REPOST;\r\nqueue->phba = phba;\r\nreturn queue;\r\nout_fail:\r\nlpfc_sli4_queue_free(queue);\r\nreturn NULL;\r\n}\r\nstatic void __iomem *\r\nlpfc_dual_chute_pci_bar_map(struct lpfc_hba *phba, uint16_t pci_barset)\r\n{\r\nstruct pci_dev *pdev;\r\nif (!phba->pcidev)\r\nreturn NULL;\r\nelse\r\npdev = phba->pcidev;\r\nswitch (pci_barset) {\r\ncase WQ_PCI_BAR_0_AND_1:\r\nreturn phba->pci_bar0_memmap_p;\r\ncase WQ_PCI_BAR_2_AND_3:\r\nreturn phba->pci_bar2_memmap_p;\r\ncase WQ_PCI_BAR_4_AND_5:\r\nreturn phba->pci_bar4_memmap_p;\r\ndefault:\r\nbreak;\r\n}\r\nreturn NULL;\r\n}\r\nint\r\nlpfc_modify_fcp_eq_delay(struct lpfc_hba *phba, uint32_t startq)\r\n{\r\nstruct lpfc_mbx_modify_eq_delay *eq_delay;\r\nLPFC_MBOXQ_t *mbox;\r\nstruct lpfc_queue *eq;\r\nint cnt, rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nuint32_t result;\r\nint fcp_eqidx;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nuint16_t dmult;\r\nif (startq >= phba->cfg_fcp_io_channel)\r\nreturn 0;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_modify_eq_delay) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_MODIFY_EQ_DELAY,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\neq_delay = &mbox->u.mqe.un.eq_delay;\r\nresult = phba->cfg_fcp_imax / phba->cfg_fcp_io_channel;\r\nif (result > LPFC_DMULT_CONST)\r\ndmult = 0;\r\nelse\r\ndmult = LPFC_DMULT_CONST/result - 1;\r\ncnt = 0;\r\nfor (fcp_eqidx = startq; fcp_eqidx < phba->cfg_fcp_io_channel;\r\nfcp_eqidx++) {\r\neq = phba->sli4_hba.hba_eq[fcp_eqidx];\r\nif (!eq)\r\ncontinue;\r\neq_delay->u.request.eq[cnt].eq_id = eq->queue_id;\r\neq_delay->u.request.eq[cnt].phase = 0;\r\neq_delay->u.request.eq[cnt].delay_multi = dmult;\r\ncnt++;\r\nif (cnt >= LPFC_MAX_EQ_DELAY)\r\nbreak;\r\n}\r\neq_delay->u.request.num_eq = cnt;\r\nmbox->vport = phba->pport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nmbox->context1 = NULL;\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *) &eq_delay->header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2512 MODIFY_EQ_DELAY mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\n}\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_eq_create(struct lpfc_hba *phba, struct lpfc_queue *eq, uint32_t imax)\r\n{\r\nstruct lpfc_mbx_eq_create *eq_create;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nstruct lpfc_dmabuf *dmabuf;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nuint16_t dmult;\r\nuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\r\nif (!eq)\r\nreturn -ENODEV;\r\nif (!phba->sli4_hba.pc_sli4_params.supported)\r\nhw_page_size = SLI4_PAGE_SIZE;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_eq_create) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_EQ_CREATE,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\neq_create = &mbox->u.mqe.un.eq_create;\r\nbf_set(lpfc_mbx_eq_create_num_pages, &eq_create->u.request,\r\neq->page_count);\r\nbf_set(lpfc_eq_context_size, &eq_create->u.request.context,\r\nLPFC_EQE_SIZE);\r\nbf_set(lpfc_eq_context_valid, &eq_create->u.request.context, 1);\r\ndmult = 0;\r\nbf_set(lpfc_eq_context_delay_multi, &eq_create->u.request.context,\r\ndmult);\r\nswitch (eq->entry_count) {\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0360 Unsupported EQ count. (%d)\n",\r\neq->entry_count);\r\nif (eq->entry_count < 256)\r\nreturn -EINVAL;\r\ncase 256:\r\nbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\r\nLPFC_EQ_CNT_256);\r\nbreak;\r\ncase 512:\r\nbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\r\nLPFC_EQ_CNT_512);\r\nbreak;\r\ncase 1024:\r\nbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\r\nLPFC_EQ_CNT_1024);\r\nbreak;\r\ncase 2048:\r\nbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\r\nLPFC_EQ_CNT_2048);\r\nbreak;\r\ncase 4096:\r\nbf_set(lpfc_eq_context_count, &eq_create->u.request.context,\r\nLPFC_EQ_CNT_4096);\r\nbreak;\r\n}\r\nlist_for_each_entry(dmabuf, &eq->page_list, list) {\r\nmemset(dmabuf->virt, 0, hw_page_size);\r\neq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\r\nputPaddrLow(dmabuf->phys);\r\neq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\r\nputPaddrHigh(dmabuf->phys);\r\n}\r\nmbox->vport = phba->pport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nmbox->context1 = NULL;\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *) &eq_create->header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2500 EQ_CREATE mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\n}\r\neq->type = LPFC_EQ;\r\neq->subtype = LPFC_NONE;\r\neq->queue_id = bf_get(lpfc_mbx_eq_create_q_id, &eq_create->u.response);\r\nif (eq->queue_id == 0xFFFF)\r\nstatus = -ENXIO;\r\neq->host_index = 0;\r\neq->hba_index = 0;\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_cq_create(struct lpfc_hba *phba, struct lpfc_queue *cq,\r\nstruct lpfc_queue *eq, uint32_t type, uint32_t subtype)\r\n{\r\nstruct lpfc_mbx_cq_create *cq_create;\r\nstruct lpfc_dmabuf *dmabuf;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\r\nif (!cq || !eq)\r\nreturn -ENODEV;\r\nif (!phba->sli4_hba.pc_sli4_params.supported)\r\nhw_page_size = SLI4_PAGE_SIZE;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_cq_create) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_CQ_CREATE,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\ncq_create = &mbox->u.mqe.un.cq_create;\r\nshdr = (union lpfc_sli4_cfg_shdr *) &cq_create->header.cfg_shdr;\r\nbf_set(lpfc_mbx_cq_create_num_pages, &cq_create->u.request,\r\ncq->page_count);\r\nbf_set(lpfc_cq_context_event, &cq_create->u.request.context, 1);\r\nbf_set(lpfc_cq_context_valid, &cq_create->u.request.context, 1);\r\nbf_set(lpfc_mbox_hdr_version, &shdr->request,\r\nphba->sli4_hba.pc_sli4_params.cqv);\r\nif (phba->sli4_hba.pc_sli4_params.cqv == LPFC_Q_CREATE_VERSION_2) {\r\nbf_set(lpfc_mbx_cq_create_page_size, &cq_create->u.request, 1);\r\nbf_set(lpfc_cq_eq_id_2, &cq_create->u.request.context,\r\neq->queue_id);\r\n} else {\r\nbf_set(lpfc_cq_eq_id, &cq_create->u.request.context,\r\neq->queue_id);\r\n}\r\nswitch (cq->entry_count) {\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0361 Unsupported CQ count. (%d)\n",\r\ncq->entry_count);\r\nif (cq->entry_count < 256) {\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\ncase 256:\r\nbf_set(lpfc_cq_context_count, &cq_create->u.request.context,\r\nLPFC_CQ_CNT_256);\r\nbreak;\r\ncase 512:\r\nbf_set(lpfc_cq_context_count, &cq_create->u.request.context,\r\nLPFC_CQ_CNT_512);\r\nbreak;\r\ncase 1024:\r\nbf_set(lpfc_cq_context_count, &cq_create->u.request.context,\r\nLPFC_CQ_CNT_1024);\r\nbreak;\r\n}\r\nlist_for_each_entry(dmabuf, &cq->page_list, list) {\r\nmemset(dmabuf->virt, 0, hw_page_size);\r\ncq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\r\nputPaddrLow(dmabuf->phys);\r\ncq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\r\nputPaddrHigh(dmabuf->phys);\r\n}\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2501 CQ_CREATE mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\ncq->queue_id = bf_get(lpfc_mbx_cq_create_q_id, &cq_create->u.response);\r\nif (cq->queue_id == 0xFFFF) {\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\nlist_add_tail(&cq->list, &eq->child_list);\r\ncq->type = type;\r\ncq->subtype = subtype;\r\ncq->queue_id = bf_get(lpfc_mbx_cq_create_q_id, &cq_create->u.response);\r\ncq->assoc_qid = eq->queue_id;\r\ncq->host_index = 0;\r\ncq->hba_index = 0;\r\nout:\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nstatic void\r\nlpfc_mq_create_fb_init(struct lpfc_hba *phba, struct lpfc_queue *mq,\r\nLPFC_MBOXQ_t *mbox, struct lpfc_queue *cq)\r\n{\r\nstruct lpfc_mbx_mq_create *mq_create;\r\nstruct lpfc_dmabuf *dmabuf;\r\nint length;\r\nlength = (sizeof(struct lpfc_mbx_mq_create) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_MQ_CREATE,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nmq_create = &mbox->u.mqe.un.mq_create;\r\nbf_set(lpfc_mbx_mq_create_num_pages, &mq_create->u.request,\r\nmq->page_count);\r\nbf_set(lpfc_mq_context_cq_id, &mq_create->u.request.context,\r\ncq->queue_id);\r\nbf_set(lpfc_mq_context_valid, &mq_create->u.request.context, 1);\r\nswitch (mq->entry_count) {\r\ncase 16:\r\nbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\r\nLPFC_MQ_RING_SIZE_16);\r\nbreak;\r\ncase 32:\r\nbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\r\nLPFC_MQ_RING_SIZE_32);\r\nbreak;\r\ncase 64:\r\nbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\r\nLPFC_MQ_RING_SIZE_64);\r\nbreak;\r\ncase 128:\r\nbf_set(lpfc_mq_context_ring_size, &mq_create->u.request.context,\r\nLPFC_MQ_RING_SIZE_128);\r\nbreak;\r\n}\r\nlist_for_each_entry(dmabuf, &mq->page_list, list) {\r\nmq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\r\nputPaddrLow(dmabuf->phys);\r\nmq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\r\nputPaddrHigh(dmabuf->phys);\r\n}\r\n}\r\nint32_t\r\nlpfc_mq_create(struct lpfc_hba *phba, struct lpfc_queue *mq,\r\nstruct lpfc_queue *cq, uint32_t subtype)\r\n{\r\nstruct lpfc_mbx_mq_create *mq_create;\r\nstruct lpfc_mbx_mq_create_ext *mq_create_ext;\r\nstruct lpfc_dmabuf *dmabuf;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\r\nif (!mq || !cq)\r\nreturn -ENODEV;\r\nif (!phba->sli4_hba.pc_sli4_params.supported)\r\nhw_page_size = SLI4_PAGE_SIZE;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_mq_create_ext) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_MQ_CREATE_EXT,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nmq_create_ext = &mbox->u.mqe.un.mq_create_ext;\r\nshdr = (union lpfc_sli4_cfg_shdr *) &mq_create_ext->header.cfg_shdr;\r\nbf_set(lpfc_mbx_mq_create_ext_num_pages,\r\n&mq_create_ext->u.request, mq->page_count);\r\nbf_set(lpfc_mbx_mq_create_ext_async_evt_link,\r\n&mq_create_ext->u.request, 1);\r\nbf_set(lpfc_mbx_mq_create_ext_async_evt_fip,\r\n&mq_create_ext->u.request, 1);\r\nbf_set(lpfc_mbx_mq_create_ext_async_evt_group5,\r\n&mq_create_ext->u.request, 1);\r\nbf_set(lpfc_mbx_mq_create_ext_async_evt_fc,\r\n&mq_create_ext->u.request, 1);\r\nbf_set(lpfc_mbx_mq_create_ext_async_evt_sli,\r\n&mq_create_ext->u.request, 1);\r\nbf_set(lpfc_mq_context_valid, &mq_create_ext->u.request.context, 1);\r\nbf_set(lpfc_mbox_hdr_version, &shdr->request,\r\nphba->sli4_hba.pc_sli4_params.mqv);\r\nif (phba->sli4_hba.pc_sli4_params.mqv == LPFC_Q_CREATE_VERSION_1)\r\nbf_set(lpfc_mbx_mq_create_ext_cq_id, &mq_create_ext->u.request,\r\ncq->queue_id);\r\nelse\r\nbf_set(lpfc_mq_context_cq_id, &mq_create_ext->u.request.context,\r\ncq->queue_id);\r\nswitch (mq->entry_count) {\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0362 Unsupported MQ count. (%d)\n",\r\nmq->entry_count);\r\nif (mq->entry_count < 16) {\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\ncase 16:\r\nbf_set(lpfc_mq_context_ring_size,\r\n&mq_create_ext->u.request.context,\r\nLPFC_MQ_RING_SIZE_16);\r\nbreak;\r\ncase 32:\r\nbf_set(lpfc_mq_context_ring_size,\r\n&mq_create_ext->u.request.context,\r\nLPFC_MQ_RING_SIZE_32);\r\nbreak;\r\ncase 64:\r\nbf_set(lpfc_mq_context_ring_size,\r\n&mq_create_ext->u.request.context,\r\nLPFC_MQ_RING_SIZE_64);\r\nbreak;\r\ncase 128:\r\nbf_set(lpfc_mq_context_ring_size,\r\n&mq_create_ext->u.request.context,\r\nLPFC_MQ_RING_SIZE_128);\r\nbreak;\r\n}\r\nlist_for_each_entry(dmabuf, &mq->page_list, list) {\r\nmemset(dmabuf->virt, 0, hw_page_size);\r\nmq_create_ext->u.request.page[dmabuf->buffer_tag].addr_lo =\r\nputPaddrLow(dmabuf->phys);\r\nmq_create_ext->u.request.page[dmabuf->buffer_tag].addr_hi =\r\nputPaddrHigh(dmabuf->phys);\r\n}\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nmq->queue_id = bf_get(lpfc_mbx_mq_create_q_id,\r\n&mq_create_ext->u.response);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"2795 MQ_CREATE_EXT failed with "\r\n"status x%x. Failback to MQ_CREATE.\n",\r\nrc);\r\nlpfc_mq_create_fb_init(phba, mq, mbox, cq);\r\nmq_create = &mbox->u.mqe.un.mq_create;\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *) &mq_create->header.cfg_shdr;\r\nmq->queue_id = bf_get(lpfc_mbx_mq_create_q_id,\r\n&mq_create->u.response);\r\n}\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2502 MQ_CREATE mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\nif (mq->queue_id == 0xFFFF) {\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\nmq->type = LPFC_MQ;\r\nmq->assoc_qid = cq->queue_id;\r\nmq->subtype = subtype;\r\nmq->host_index = 0;\r\nmq->hba_index = 0;\r\nlist_add_tail(&mq->list, &cq->child_list);\r\nout:\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_wq_create(struct lpfc_hba *phba, struct lpfc_queue *wq,\r\nstruct lpfc_queue *cq, uint32_t subtype)\r\n{\r\nstruct lpfc_mbx_wq_create *wq_create;\r\nstruct lpfc_dmabuf *dmabuf;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\r\nstruct dma_address *page;\r\nvoid __iomem *bar_memmap_p;\r\nuint32_t db_offset;\r\nuint16_t pci_barset;\r\nif (!wq || !cq)\r\nreturn -ENODEV;\r\nif (!phba->sli4_hba.pc_sli4_params.supported)\r\nhw_page_size = SLI4_PAGE_SIZE;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_wq_create) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_WQ_CREATE,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nwq_create = &mbox->u.mqe.un.wq_create;\r\nshdr = (union lpfc_sli4_cfg_shdr *) &wq_create->header.cfg_shdr;\r\nbf_set(lpfc_mbx_wq_create_num_pages, &wq_create->u.request,\r\nwq->page_count);\r\nbf_set(lpfc_mbx_wq_create_cq_id, &wq_create->u.request,\r\ncq->queue_id);\r\nbf_set(lpfc_mbox_hdr_version, &shdr->request,\r\nphba->sli4_hba.pc_sli4_params.wqv);\r\nswitch (phba->sli4_hba.pc_sli4_params.wqv) {\r\ncase LPFC_Q_CREATE_VERSION_0:\r\nswitch (wq->entry_size) {\r\ndefault:\r\ncase 64:\r\npage = wq_create->u.request.page;\r\nbreak;\r\ncase 128:\r\nif (!(phba->sli4_hba.pc_sli4_params.wqsize &\r\nLPFC_WQ_SZ128_SUPPORT)) {\r\nstatus = -ERANGE;\r\ngoto out;\r\n}\r\nbf_set(lpfc_mbox_hdr_version, &shdr->request,\r\nLPFC_Q_CREATE_VERSION_1);\r\nbf_set(lpfc_mbx_wq_create_wqe_count,\r\n&wq_create->u.request_1, wq->entry_count);\r\nbf_set(lpfc_mbx_wq_create_wqe_size,\r\n&wq_create->u.request_1,\r\nLPFC_WQ_WQE_SIZE_128);\r\nbf_set(lpfc_mbx_wq_create_page_size,\r\n&wq_create->u.request_1,\r\n(PAGE_SIZE/SLI4_PAGE_SIZE));\r\npage = wq_create->u.request_1.page;\r\nbreak;\r\n}\r\nbreak;\r\ncase LPFC_Q_CREATE_VERSION_1:\r\nbf_set(lpfc_mbx_wq_create_wqe_count, &wq_create->u.request_1,\r\nwq->entry_count);\r\nswitch (wq->entry_size) {\r\ndefault:\r\ncase 64:\r\nbf_set(lpfc_mbx_wq_create_wqe_size,\r\n&wq_create->u.request_1,\r\nLPFC_WQ_WQE_SIZE_64);\r\nbreak;\r\ncase 128:\r\nif (!(phba->sli4_hba.pc_sli4_params.wqsize &\r\nLPFC_WQ_SZ128_SUPPORT)) {\r\nstatus = -ERANGE;\r\ngoto out;\r\n}\r\nbf_set(lpfc_mbx_wq_create_wqe_size,\r\n&wq_create->u.request_1,\r\nLPFC_WQ_WQE_SIZE_128);\r\nbreak;\r\n}\r\nbf_set(lpfc_mbx_wq_create_page_size, &wq_create->u.request_1,\r\n(PAGE_SIZE/SLI4_PAGE_SIZE));\r\npage = wq_create->u.request_1.page;\r\nbreak;\r\ndefault:\r\nstatus = -ERANGE;\r\ngoto out;\r\n}\r\nlist_for_each_entry(dmabuf, &wq->page_list, list) {\r\nmemset(dmabuf->virt, 0, hw_page_size);\r\npage[dmabuf->buffer_tag].addr_lo = putPaddrLow(dmabuf->phys);\r\npage[dmabuf->buffer_tag].addr_hi = putPaddrHigh(dmabuf->phys);\r\n}\r\nif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE)\r\nbf_set(lpfc_mbx_wq_create_dua, &wq_create->u.request, 1);\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2503 WQ_CREATE mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\nwq->queue_id = bf_get(lpfc_mbx_wq_create_q_id, &wq_create->u.response);\r\nif (wq->queue_id == 0xFFFF) {\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\nif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE) {\r\nwq->db_format = bf_get(lpfc_mbx_wq_create_db_format,\r\n&wq_create->u.response);\r\nif ((wq->db_format != LPFC_DB_LIST_FORMAT) &&\r\n(wq->db_format != LPFC_DB_RING_FORMAT)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3265 WQ[%d] doorbell format not "\r\n"supported: x%x\n", wq->queue_id,\r\nwq->db_format);\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\npci_barset = bf_get(lpfc_mbx_wq_create_bar_set,\r\n&wq_create->u.response);\r\nbar_memmap_p = lpfc_dual_chute_pci_bar_map(phba, pci_barset);\r\nif (!bar_memmap_p) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3263 WQ[%d] failed to memmap pci "\r\n"barset:x%x\n", wq->queue_id,\r\npci_barset);\r\nstatus = -ENOMEM;\r\ngoto out;\r\n}\r\ndb_offset = wq_create->u.response.doorbell_offset;\r\nif ((db_offset != LPFC_ULP0_WQ_DOORBELL) &&\r\n(db_offset != LPFC_ULP1_WQ_DOORBELL)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3252 WQ[%d] doorbell offset not "\r\n"supported: x%x\n", wq->queue_id,\r\ndb_offset);\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\nwq->db_regaddr = bar_memmap_p + db_offset;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"3264 WQ[%d]: barset:x%x, offset:x%x, "\r\n"format:x%x\n", wq->queue_id, pci_barset,\r\ndb_offset, wq->db_format);\r\n} else {\r\nwq->db_format = LPFC_DB_LIST_FORMAT;\r\nwq->db_regaddr = phba->sli4_hba.WQDBregaddr;\r\n}\r\nwq->type = LPFC_WQ;\r\nwq->assoc_qid = cq->queue_id;\r\nwq->subtype = subtype;\r\nwq->host_index = 0;\r\nwq->hba_index = 0;\r\nwq->entry_repost = LPFC_RELEASE_NOTIFICATION_INTERVAL;\r\nlist_add_tail(&wq->list, &cq->child_list);\r\nout:\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nvoid\r\nlpfc_rq_adjust_repost(struct lpfc_hba *phba, struct lpfc_queue *rq, int qno)\r\n{\r\nuint32_t cnt;\r\nif (!rq)\r\nreturn;\r\ncnt = lpfc_hbq_defs[qno]->entry_count;\r\ncnt = (cnt >> 3);\r\nif (cnt < LPFC_QUEUE_MIN_REPOST)\r\ncnt = LPFC_QUEUE_MIN_REPOST;\r\nrq->entry_repost = cnt;\r\n}\r\nint\r\nlpfc_rq_create(struct lpfc_hba *phba, struct lpfc_queue *hrq,\r\nstruct lpfc_queue *drq, struct lpfc_queue *cq, uint32_t subtype)\r\n{\r\nstruct lpfc_mbx_rq_create *rq_create;\r\nstruct lpfc_dmabuf *dmabuf;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nuint32_t hw_page_size = phba->sli4_hba.pc_sli4_params.if_page_sz;\r\nvoid __iomem *bar_memmap_p;\r\nuint32_t db_offset;\r\nuint16_t pci_barset;\r\nif (!hrq || !drq || !cq)\r\nreturn -ENODEV;\r\nif (!phba->sli4_hba.pc_sli4_params.supported)\r\nhw_page_size = SLI4_PAGE_SIZE;\r\nif (hrq->entry_count != drq->entry_count)\r\nreturn -EINVAL;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_rq_create) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_RQ_CREATE,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nrq_create = &mbox->u.mqe.un.rq_create;\r\nshdr = (union lpfc_sli4_cfg_shdr *) &rq_create->header.cfg_shdr;\r\nbf_set(lpfc_mbox_hdr_version, &shdr->request,\r\nphba->sli4_hba.pc_sli4_params.rqv);\r\nif (phba->sli4_hba.pc_sli4_params.rqv == LPFC_Q_CREATE_VERSION_1) {\r\nbf_set(lpfc_rq_context_rqe_count_1,\r\n&rq_create->u.request.context,\r\nhrq->entry_count);\r\nrq_create->u.request.context.buffer_size = LPFC_HDR_BUF_SIZE;\r\nbf_set(lpfc_rq_context_rqe_size,\r\n&rq_create->u.request.context,\r\nLPFC_RQE_SIZE_8);\r\nbf_set(lpfc_rq_context_page_size,\r\n&rq_create->u.request.context,\r\n(PAGE_SIZE/SLI4_PAGE_SIZE));\r\n} else {\r\nswitch (hrq->entry_count) {\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2535 Unsupported RQ count. (%d)\n",\r\nhrq->entry_count);\r\nif (hrq->entry_count < 512) {\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\ncase 512:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_512);\r\nbreak;\r\ncase 1024:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_1024);\r\nbreak;\r\ncase 2048:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_2048);\r\nbreak;\r\ncase 4096:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_4096);\r\nbreak;\r\n}\r\nbf_set(lpfc_rq_context_buf_size, &rq_create->u.request.context,\r\nLPFC_HDR_BUF_SIZE);\r\n}\r\nbf_set(lpfc_rq_context_cq_id, &rq_create->u.request.context,\r\ncq->queue_id);\r\nbf_set(lpfc_mbx_rq_create_num_pages, &rq_create->u.request,\r\nhrq->page_count);\r\nlist_for_each_entry(dmabuf, &hrq->page_list, list) {\r\nmemset(dmabuf->virt, 0, hw_page_size);\r\nrq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\r\nputPaddrLow(dmabuf->phys);\r\nrq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\r\nputPaddrHigh(dmabuf->phys);\r\n}\r\nif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE)\r\nbf_set(lpfc_mbx_rq_create_dua, &rq_create->u.request, 1);\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2504 RQ_CREATE mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\nhrq->queue_id = bf_get(lpfc_mbx_rq_create_q_id, &rq_create->u.response);\r\nif (hrq->queue_id == 0xFFFF) {\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\nif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE) {\r\nhrq->db_format = bf_get(lpfc_mbx_rq_create_db_format,\r\n&rq_create->u.response);\r\nif ((hrq->db_format != LPFC_DB_LIST_FORMAT) &&\r\n(hrq->db_format != LPFC_DB_RING_FORMAT)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3262 RQ [%d] doorbell format not "\r\n"supported: x%x\n", hrq->queue_id,\r\nhrq->db_format);\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\npci_barset = bf_get(lpfc_mbx_rq_create_bar_set,\r\n&rq_create->u.response);\r\nbar_memmap_p = lpfc_dual_chute_pci_bar_map(phba, pci_barset);\r\nif (!bar_memmap_p) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3269 RQ[%d] failed to memmap pci "\r\n"barset:x%x\n", hrq->queue_id,\r\npci_barset);\r\nstatus = -ENOMEM;\r\ngoto out;\r\n}\r\ndb_offset = rq_create->u.response.doorbell_offset;\r\nif ((db_offset != LPFC_ULP0_RQ_DOORBELL) &&\r\n(db_offset != LPFC_ULP1_RQ_DOORBELL)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3270 RQ[%d] doorbell offset not "\r\n"supported: x%x\n", hrq->queue_id,\r\ndb_offset);\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\nhrq->db_regaddr = bar_memmap_p + db_offset;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"3266 RQ[qid:%d]: barset:x%x, offset:x%x, "\r\n"format:x%x\n", hrq->queue_id, pci_barset,\r\ndb_offset, hrq->db_format);\r\n} else {\r\nhrq->db_format = LPFC_DB_RING_FORMAT;\r\nhrq->db_regaddr = phba->sli4_hba.RQDBregaddr;\r\n}\r\nhrq->type = LPFC_HRQ;\r\nhrq->assoc_qid = cq->queue_id;\r\nhrq->subtype = subtype;\r\nhrq->host_index = 0;\r\nhrq->hba_index = 0;\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_RQ_CREATE,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nbf_set(lpfc_mbox_hdr_version, &shdr->request,\r\nphba->sli4_hba.pc_sli4_params.rqv);\r\nif (phba->sli4_hba.pc_sli4_params.rqv == LPFC_Q_CREATE_VERSION_1) {\r\nbf_set(lpfc_rq_context_rqe_count_1,\r\n&rq_create->u.request.context, hrq->entry_count);\r\nrq_create->u.request.context.buffer_size = LPFC_DATA_BUF_SIZE;\r\nbf_set(lpfc_rq_context_rqe_size, &rq_create->u.request.context,\r\nLPFC_RQE_SIZE_8);\r\nbf_set(lpfc_rq_context_page_size, &rq_create->u.request.context,\r\n(PAGE_SIZE/SLI4_PAGE_SIZE));\r\n} else {\r\nswitch (drq->entry_count) {\r\ndefault:\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2536 Unsupported RQ count. (%d)\n",\r\ndrq->entry_count);\r\nif (drq->entry_count < 512) {\r\nstatus = -EINVAL;\r\ngoto out;\r\n}\r\ncase 512:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_512);\r\nbreak;\r\ncase 1024:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_1024);\r\nbreak;\r\ncase 2048:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_2048);\r\nbreak;\r\ncase 4096:\r\nbf_set(lpfc_rq_context_rqe_count,\r\n&rq_create->u.request.context,\r\nLPFC_RQ_RING_SIZE_4096);\r\nbreak;\r\n}\r\nbf_set(lpfc_rq_context_buf_size, &rq_create->u.request.context,\r\nLPFC_DATA_BUF_SIZE);\r\n}\r\nbf_set(lpfc_rq_context_cq_id, &rq_create->u.request.context,\r\ncq->queue_id);\r\nbf_set(lpfc_mbx_rq_create_num_pages, &rq_create->u.request,\r\ndrq->page_count);\r\nlist_for_each_entry(dmabuf, &drq->page_list, list) {\r\nrq_create->u.request.page[dmabuf->buffer_tag].addr_lo =\r\nputPaddrLow(dmabuf->phys);\r\nrq_create->u.request.page[dmabuf->buffer_tag].addr_hi =\r\nputPaddrHigh(dmabuf->phys);\r\n}\r\nif (phba->sli4_hba.fw_func_mode & LPFC_DUA_MODE)\r\nbf_set(lpfc_mbx_rq_create_dua, &rq_create->u.request, 1);\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *) &rq_create->header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\ndrq->queue_id = bf_get(lpfc_mbx_rq_create_q_id, &rq_create->u.response);\r\nif (drq->queue_id == 0xFFFF) {\r\nstatus = -ENXIO;\r\ngoto out;\r\n}\r\ndrq->type = LPFC_DRQ;\r\ndrq->assoc_qid = cq->queue_id;\r\ndrq->subtype = subtype;\r\ndrq->host_index = 0;\r\ndrq->hba_index = 0;\r\nlist_add_tail(&hrq->list, &cq->child_list);\r\nlist_add_tail(&drq->list, &cq->child_list);\r\nout:\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_eq_destroy(struct lpfc_hba *phba, struct lpfc_queue *eq)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nif (!eq)\r\nreturn -ENODEV;\r\nmbox = mempool_alloc(eq->phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_eq_destroy) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_EQ_DESTROY,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nbf_set(lpfc_mbx_eq_destroy_q_id, &mbox->u.mqe.un.eq_destroy.u.request,\r\neq->queue_id);\r\nmbox->vport = eq->phba->pport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nrc = lpfc_sli_issue_mbox(eq->phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *)\r\n&mbox->u.mqe.un.eq_destroy.header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2505 EQ_DESTROY mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\n}\r\nlist_del_init(&eq->list);\r\nmempool_free(mbox, eq->phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_cq_destroy(struct lpfc_hba *phba, struct lpfc_queue *cq)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nif (!cq)\r\nreturn -ENODEV;\r\nmbox = mempool_alloc(cq->phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_cq_destroy) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_CQ_DESTROY,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nbf_set(lpfc_mbx_cq_destroy_q_id, &mbox->u.mqe.un.cq_destroy.u.request,\r\ncq->queue_id);\r\nmbox->vport = cq->phba->pport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nrc = lpfc_sli_issue_mbox(cq->phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *)\r\n&mbox->u.mqe.un.wq_create.header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2506 CQ_DESTROY mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\n}\r\nlist_del_init(&cq->list);\r\nmempool_free(mbox, cq->phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_mq_destroy(struct lpfc_hba *phba, struct lpfc_queue *mq)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nif (!mq)\r\nreturn -ENODEV;\r\nmbox = mempool_alloc(mq->phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_mq_destroy) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_MQ_DESTROY,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nbf_set(lpfc_mbx_mq_destroy_q_id, &mbox->u.mqe.un.mq_destroy.u.request,\r\nmq->queue_id);\r\nmbox->vport = mq->phba->pport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nrc = lpfc_sli_issue_mbox(mq->phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *)\r\n&mbox->u.mqe.un.mq_destroy.header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2507 MQ_DESTROY mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\n}\r\nlist_del_init(&mq->list);\r\nmempool_free(mbox, mq->phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_wq_destroy(struct lpfc_hba *phba, struct lpfc_queue *wq)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nif (!wq)\r\nreturn -ENODEV;\r\nmbox = mempool_alloc(wq->phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_wq_destroy) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_WQ_DESTROY,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nbf_set(lpfc_mbx_wq_destroy_q_id, &mbox->u.mqe.un.wq_destroy.u.request,\r\nwq->queue_id);\r\nmbox->vport = wq->phba->pport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nrc = lpfc_sli_issue_mbox(wq->phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *)\r\n&mbox->u.mqe.un.wq_destroy.header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2508 WQ_DESTROY mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\n}\r\nlist_del_init(&wq->list);\r\nmempool_free(mbox, wq->phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_rq_destroy(struct lpfc_hba *phba, struct lpfc_queue *hrq,\r\nstruct lpfc_queue *drq)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nint rc, length, status = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nif (!hrq || !drq)\r\nreturn -ENODEV;\r\nmbox = mempool_alloc(hrq->phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlength = (sizeof(struct lpfc_mbx_rq_destroy) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_RQ_DESTROY,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nbf_set(lpfc_mbx_rq_destroy_q_id, &mbox->u.mqe.un.rq_destroy.u.request,\r\nhrq->queue_id);\r\nmbox->vport = hrq->phba->pport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nrc = lpfc_sli_issue_mbox(hrq->phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *)\r\n&mbox->u.mqe.un.rq_destroy.header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2509 RQ_DESTROY mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nif (rc != MBX_TIMEOUT)\r\nmempool_free(mbox, hrq->phba->mbox_mem_pool);\r\nreturn -ENXIO;\r\n}\r\nbf_set(lpfc_mbx_rq_destroy_q_id, &mbox->u.mqe.un.rq_destroy.u.request,\r\ndrq->queue_id);\r\nrc = lpfc_sli_issue_mbox(drq->phba, mbox, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *)\r\n&mbox->u.mqe.un.rq_destroy.header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2510 RQ_DESTROY mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nstatus = -ENXIO;\r\n}\r\nlist_del_init(&hrq->list);\r\nlist_del_init(&drq->list);\r\nmempool_free(mbox, hrq->phba->mbox_mem_pool);\r\nreturn status;\r\n}\r\nint\r\nlpfc_sli4_post_sgl(struct lpfc_hba *phba,\r\ndma_addr_t pdma_phys_addr0,\r\ndma_addr_t pdma_phys_addr1,\r\nuint16_t xritag)\r\n{\r\nstruct lpfc_mbx_post_sgl_pages *post_sgl_pages;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc;\r\nuint32_t shdr_status, shdr_add_status;\r\nuint32_t mbox_tmo;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nif (xritag == NO_XRI) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"0364 Invalid param:\n");\r\nreturn -EINVAL;\r\n}\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_POST_SGL_PAGES,\r\nsizeof(struct lpfc_mbx_post_sgl_pages) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr), LPFC_SLI4_MBX_EMBED);\r\npost_sgl_pages = (struct lpfc_mbx_post_sgl_pages *)\r\n&mbox->u.mqe.un.post_sgl_pages;\r\nbf_set(lpfc_post_sgl_pages_xri, post_sgl_pages, xritag);\r\nbf_set(lpfc_post_sgl_pages_xricnt, post_sgl_pages, 1);\r\npost_sgl_pages->sgl_pg_pairs[0].sgl_pg0_addr_lo =\r\ncpu_to_le32(putPaddrLow(pdma_phys_addr0));\r\npost_sgl_pages->sgl_pg_pairs[0].sgl_pg0_addr_hi =\r\ncpu_to_le32(putPaddrHigh(pdma_phys_addr0));\r\npost_sgl_pages->sgl_pg_pairs[0].sgl_pg1_addr_lo =\r\ncpu_to_le32(putPaddrLow(pdma_phys_addr1));\r\npost_sgl_pages->sgl_pg_pairs[0].sgl_pg1_addr_hi =\r\ncpu_to_le32(putPaddrHigh(pdma_phys_addr1));\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nshdr = (union lpfc_sli4_cfg_shdr *) &post_sgl_pages->header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (rc != MBX_TIMEOUT)\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2511 POST_SGL mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\n}\r\nreturn 0;\r\n}\r\nstatic uint16_t\r\nlpfc_sli4_alloc_xri(struct lpfc_hba *phba)\r\n{\r\nunsigned long xri;\r\nspin_lock_irq(&phba->hbalock);\r\nxri = find_next_zero_bit(phba->sli4_hba.xri_bmask,\r\nphba->sli4_hba.max_cfg_param.max_xri, 0);\r\nif (xri >= phba->sli4_hba.max_cfg_param.max_xri) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn NO_XRI;\r\n} else {\r\nset_bit(xri, phba->sli4_hba.xri_bmask);\r\nphba->sli4_hba.max_cfg_param.xri_used++;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn xri;\r\n}\r\nstatic void\r\n__lpfc_sli4_free_xri(struct lpfc_hba *phba, int xri)\r\n{\r\nif (test_and_clear_bit(xri, phba->sli4_hba.xri_bmask)) {\r\nphba->sli4_hba.max_cfg_param.xri_used--;\r\n}\r\n}\r\nvoid\r\nlpfc_sli4_free_xri(struct lpfc_hba *phba, int xri)\r\n{\r\nspin_lock_irq(&phba->hbalock);\r\n__lpfc_sli4_free_xri(phba, xri);\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nuint16_t\r\nlpfc_sli4_next_xritag(struct lpfc_hba *phba)\r\n{\r\nuint16_t xri_index;\r\nxri_index = lpfc_sli4_alloc_xri(phba);\r\nif (xri_index == NO_XRI)\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"2004 Failed to allocate XRI.last XRITAG is %d"\r\n" Max XRI is %d, Used XRI is %d\n",\r\nxri_index,\r\nphba->sli4_hba.max_cfg_param.max_xri,\r\nphba->sli4_hba.max_cfg_param.xri_used);\r\nreturn xri_index;\r\n}\r\nstatic int\r\nlpfc_sli4_post_els_sgl_list(struct lpfc_hba *phba,\r\nstruct list_head *post_sgl_list,\r\nint post_cnt)\r\n{\r\nstruct lpfc_sglq *sglq_entry = NULL, *sglq_next = NULL;\r\nstruct lpfc_mbx_post_uembed_sgl_page1 *sgl;\r\nstruct sgl_page_pairs *sgl_pg_pairs;\r\nvoid *viraddr;\r\nLPFC_MBOXQ_t *mbox;\r\nuint32_t reqlen, alloclen, pg_pairs;\r\nuint32_t mbox_tmo;\r\nuint16_t xritag_start = 0;\r\nint rc = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nreqlen = phba->sli4_hba.els_xri_cnt * sizeof(struct sgl_page_pairs) +\r\nsizeof(union lpfc_sli4_cfg_shdr) + sizeof(uint32_t);\r\nif (reqlen > SLI4_PAGE_SIZE) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\r\n"2559 Block sgl registration required DMA "\r\n"size (%d) great than a page\n", reqlen);\r\nreturn -ENOMEM;\r\n}\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nalloclen = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_POST_SGL_PAGES, reqlen,\r\nLPFC_SLI4_MBX_NEMBED);\r\nif (alloclen < reqlen) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0285 Allocated DMA memory size (%d) is "\r\n"less than the requested DMA memory "\r\n"size (%d)\n", alloclen, reqlen);\r\nlpfc_sli4_mbox_cmd_free(phba, mbox);\r\nreturn -ENOMEM;\r\n}\r\nviraddr = mbox->sge_array->addr[0];\r\nsgl = (struct lpfc_mbx_post_uembed_sgl_page1 *)viraddr;\r\nsgl_pg_pairs = &sgl->sgl_pg_pairs;\r\npg_pairs = 0;\r\nlist_for_each_entry_safe(sglq_entry, sglq_next, post_sgl_list, list) {\r\nsgl_pg_pairs->sgl_pg0_addr_lo =\r\ncpu_to_le32(putPaddrLow(sglq_entry->phys));\r\nsgl_pg_pairs->sgl_pg0_addr_hi =\r\ncpu_to_le32(putPaddrHigh(sglq_entry->phys));\r\nsgl_pg_pairs->sgl_pg1_addr_lo =\r\ncpu_to_le32(putPaddrLow(0));\r\nsgl_pg_pairs->sgl_pg1_addr_hi =\r\ncpu_to_le32(putPaddrHigh(0));\r\nif (pg_pairs == 0)\r\nxritag_start = sglq_entry->sli4_xritag;\r\nsgl_pg_pairs++;\r\npg_pairs++;\r\n}\r\nbf_set(lpfc_post_sgl_pages_xri, sgl, xritag_start);\r\nbf_set(lpfc_post_sgl_pages_xricnt, sgl, phba->sli4_hba.els_xri_cnt);\r\nsgl->word0 = cpu_to_le32(sgl->word0);\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nshdr = (union lpfc_sli4_cfg_shdr *) &sgl->cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (rc != MBX_TIMEOUT)\r\nlpfc_sli4_mbox_cmd_free(phba, mbox);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2513 POST_SGL_BLOCK mailbox command failed "\r\n"status x%x add_status x%x mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nrc = -ENXIO;\r\n}\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli4_post_scsi_sgl_block(struct lpfc_hba *phba,\r\nstruct list_head *sblist,\r\nint count)\r\n{\r\nstruct lpfc_scsi_buf *psb;\r\nstruct lpfc_mbx_post_uembed_sgl_page1 *sgl;\r\nstruct sgl_page_pairs *sgl_pg_pairs;\r\nvoid *viraddr;\r\nLPFC_MBOXQ_t *mbox;\r\nuint32_t reqlen, alloclen, pg_pairs;\r\nuint32_t mbox_tmo;\r\nuint16_t xritag_start = 0;\r\nint rc = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\ndma_addr_t pdma_phys_bpl1;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nreqlen = count * sizeof(struct sgl_page_pairs) +\r\nsizeof(union lpfc_sli4_cfg_shdr) + sizeof(uint32_t);\r\nif (reqlen > SLI4_PAGE_SIZE) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\r\n"0217 Block sgl registration required DMA "\r\n"size (%d) great than a page\n", reqlen);\r\nreturn -ENOMEM;\r\n}\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0283 Failed to allocate mbox cmd memory\n");\r\nreturn -ENOMEM;\r\n}\r\nalloclen = lpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_POST_SGL_PAGES, reqlen,\r\nLPFC_SLI4_MBX_NEMBED);\r\nif (alloclen < reqlen) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2561 Allocated DMA memory size (%d) is "\r\n"less than the requested DMA memory "\r\n"size (%d)\n", alloclen, reqlen);\r\nlpfc_sli4_mbox_cmd_free(phba, mbox);\r\nreturn -ENOMEM;\r\n}\r\nviraddr = mbox->sge_array->addr[0];\r\nsgl = (struct lpfc_mbx_post_uembed_sgl_page1 *)viraddr;\r\nsgl_pg_pairs = &sgl->sgl_pg_pairs;\r\npg_pairs = 0;\r\nlist_for_each_entry(psb, sblist, list) {\r\nsgl_pg_pairs->sgl_pg0_addr_lo =\r\ncpu_to_le32(putPaddrLow(psb->dma_phys_bpl));\r\nsgl_pg_pairs->sgl_pg0_addr_hi =\r\ncpu_to_le32(putPaddrHigh(psb->dma_phys_bpl));\r\nif (phba->cfg_sg_dma_buf_size > SGL_PAGE_SIZE)\r\npdma_phys_bpl1 = psb->dma_phys_bpl + SGL_PAGE_SIZE;\r\nelse\r\npdma_phys_bpl1 = 0;\r\nsgl_pg_pairs->sgl_pg1_addr_lo =\r\ncpu_to_le32(putPaddrLow(pdma_phys_bpl1));\r\nsgl_pg_pairs->sgl_pg1_addr_hi =\r\ncpu_to_le32(putPaddrHigh(pdma_phys_bpl1));\r\nif (pg_pairs == 0)\r\nxritag_start = psb->cur_iocbq.sli4_xritag;\r\nsgl_pg_pairs++;\r\npg_pairs++;\r\n}\r\nbf_set(lpfc_post_sgl_pages_xri, sgl, xritag_start);\r\nbf_set(lpfc_post_sgl_pages_xricnt, sgl, pg_pairs);\r\nsgl->word0 = cpu_to_le32(sgl->word0);\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nshdr = (union lpfc_sli4_cfg_shdr *) &sgl->cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (rc != MBX_TIMEOUT)\r\nlpfc_sli4_mbox_cmd_free(phba, mbox);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2564 POST_SGL_BLOCK mailbox command failed "\r\n"status x%x add_status x%x mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nrc = -ENXIO;\r\n}\r\nreturn rc;\r\n}\r\nstatic int\r\nlpfc_fc_frame_check(struct lpfc_hba *phba, struct fc_frame_header *fc_hdr)\r\n{\r\nstatic char *rctl_names[] = FC_RCTL_NAMES_INIT;\r\nchar *type_names[] = FC_TYPE_NAMES_INIT;\r\nstruct fc_vft_header *fc_vft_hdr;\r\nuint32_t *header = (uint32_t *) fc_hdr;\r\nswitch (fc_hdr->fh_r_ctl) {\r\ncase FC_RCTL_DD_UNCAT:\r\ncase FC_RCTL_DD_SOL_DATA:\r\ncase FC_RCTL_DD_UNSOL_CTL:\r\ncase FC_RCTL_DD_SOL_CTL:\r\ncase FC_RCTL_DD_UNSOL_DATA:\r\ncase FC_RCTL_DD_DATA_DESC:\r\ncase FC_RCTL_DD_UNSOL_CMD:\r\ncase FC_RCTL_DD_CMD_STATUS:\r\ncase FC_RCTL_ELS_REQ:\r\ncase FC_RCTL_ELS_REP:\r\ncase FC_RCTL_ELS4_REQ:\r\ncase FC_RCTL_ELS4_REP:\r\ncase FC_RCTL_BA_NOP:\r\ncase FC_RCTL_BA_ABTS:\r\ncase FC_RCTL_BA_RMC:\r\ncase FC_RCTL_BA_ACC:\r\ncase FC_RCTL_BA_RJT:\r\ncase FC_RCTL_BA_PRMT:\r\ncase FC_RCTL_ACK_1:\r\ncase FC_RCTL_ACK_0:\r\ncase FC_RCTL_P_RJT:\r\ncase FC_RCTL_F_RJT:\r\ncase FC_RCTL_P_BSY:\r\ncase FC_RCTL_F_BSY:\r\ncase FC_RCTL_F_BSYL:\r\ncase FC_RCTL_LCR:\r\ncase FC_RCTL_END:\r\nbreak;\r\ncase FC_RCTL_VFTH:\r\nfc_vft_hdr = (struct fc_vft_header *)fc_hdr;\r\nfc_hdr = &((struct fc_frame_header *)fc_vft_hdr)[1];\r\nreturn lpfc_fc_frame_check(phba, fc_hdr);\r\ndefault:\r\ngoto drop;\r\n}\r\nswitch (fc_hdr->fh_type) {\r\ncase FC_TYPE_BLS:\r\ncase FC_TYPE_ELS:\r\ncase FC_TYPE_FCP:\r\ncase FC_TYPE_CT:\r\nbreak;\r\ncase FC_TYPE_IP:\r\ncase FC_TYPE_ILS:\r\ndefault:\r\ngoto drop;\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_ELS,\r\n"2538 Received frame rctl:%s (x%x), type:%s (x%x), "\r\n"frame Data:%08x %08x %08x %08x %08x %08x %08x\n",\r\nrctl_names[fc_hdr->fh_r_ctl], fc_hdr->fh_r_ctl,\r\ntype_names[fc_hdr->fh_type], fc_hdr->fh_type,\r\nbe32_to_cpu(header[0]), be32_to_cpu(header[1]),\r\nbe32_to_cpu(header[2]), be32_to_cpu(header[3]),\r\nbe32_to_cpu(header[4]), be32_to_cpu(header[5]),\r\nbe32_to_cpu(header[6]));\r\nreturn 0;\r\ndrop:\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_ELS,\r\n"2539 Dropped frame rctl:%s type:%s\n",\r\nrctl_names[fc_hdr->fh_r_ctl],\r\ntype_names[fc_hdr->fh_type]);\r\nreturn 1;\r\n}\r\nstatic uint32_t\r\nlpfc_fc_hdr_get_vfi(struct fc_frame_header *fc_hdr)\r\n{\r\nstruct fc_vft_header *fc_vft_hdr = (struct fc_vft_header *)fc_hdr;\r\nif (fc_hdr->fh_r_ctl != FC_RCTL_VFTH)\r\nreturn 0;\r\nreturn bf_get(fc_vft_hdr_vf_id, fc_vft_hdr);\r\n}\r\nstatic struct lpfc_vport *\r\nlpfc_fc_frame_to_vport(struct lpfc_hba *phba, struct fc_frame_header *fc_hdr,\r\nuint16_t fcfi)\r\n{\r\nstruct lpfc_vport **vports;\r\nstruct lpfc_vport *vport = NULL;\r\nint i;\r\nuint32_t did = (fc_hdr->fh_d_id[0] << 16 |\r\nfc_hdr->fh_d_id[1] << 8 |\r\nfc_hdr->fh_d_id[2]);\r\nif (did == Fabric_DID)\r\nreturn phba->pport;\r\nif ((phba->pport->fc_flag & FC_PT2PT) &&\r\n!(phba->link_state == LPFC_HBA_READY))\r\nreturn phba->pport;\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (vports != NULL)\r\nfor (i = 0; i <= phba->max_vpi && vports[i] != NULL; i++) {\r\nif (phba->fcf.fcfi == fcfi &&\r\nvports[i]->vfi == lpfc_fc_hdr_get_vfi(fc_hdr) &&\r\nvports[i]->fc_myDID == did) {\r\nvport = vports[i];\r\nbreak;\r\n}\r\n}\r\nlpfc_destroy_vport_work_array(phba, vports);\r\nreturn vport;\r\n}\r\nstatic void\r\nlpfc_update_rcv_time_stamp(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_dmabuf *h_buf;\r\nstruct hbq_dmabuf *dmabuf = NULL;\r\nh_buf = list_get_first(&vport->rcv_buffer_list,\r\nstruct lpfc_dmabuf, list);\r\nif (!h_buf)\r\nreturn;\r\ndmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\r\nvport->rcv_buffer_time_stamp = dmabuf->time_stamp;\r\n}\r\nvoid\r\nlpfc_cleanup_rcv_buffers(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_dmabuf *h_buf, *hnext;\r\nstruct lpfc_dmabuf *d_buf, *dnext;\r\nstruct hbq_dmabuf *dmabuf = NULL;\r\nlist_for_each_entry_safe(h_buf, hnext, &vport->rcv_buffer_list, list) {\r\ndmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\r\nlist_del_init(&dmabuf->hbuf.list);\r\nlist_for_each_entry_safe(d_buf, dnext,\r\n&dmabuf->dbuf.list, list) {\r\nlist_del_init(&d_buf->list);\r\nlpfc_in_buf_free(vport->phba, d_buf);\r\n}\r\nlpfc_in_buf_free(vport->phba, &dmabuf->dbuf);\r\n}\r\n}\r\nvoid\r\nlpfc_rcv_seq_check_edtov(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_dmabuf *h_buf, *hnext;\r\nstruct lpfc_dmabuf *d_buf, *dnext;\r\nstruct hbq_dmabuf *dmabuf = NULL;\r\nunsigned long timeout;\r\nint abort_count = 0;\r\ntimeout = (msecs_to_jiffies(vport->phba->fc_edtov) +\r\nvport->rcv_buffer_time_stamp);\r\nif (list_empty(&vport->rcv_buffer_list) ||\r\ntime_before(jiffies, timeout))\r\nreturn;\r\nlist_for_each_entry_safe(h_buf, hnext, &vport->rcv_buffer_list, list) {\r\ndmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\r\ntimeout = (msecs_to_jiffies(vport->phba->fc_edtov) +\r\ndmabuf->time_stamp);\r\nif (time_before(jiffies, timeout))\r\nbreak;\r\nabort_count++;\r\nlist_del_init(&dmabuf->hbuf.list);\r\nlist_for_each_entry_safe(d_buf, dnext,\r\n&dmabuf->dbuf.list, list) {\r\nlist_del_init(&d_buf->list);\r\nlpfc_in_buf_free(vport->phba, d_buf);\r\n}\r\nlpfc_in_buf_free(vport->phba, &dmabuf->dbuf);\r\n}\r\nif (abort_count)\r\nlpfc_update_rcv_time_stamp(vport);\r\n}\r\nstatic struct hbq_dmabuf *\r\nlpfc_fc_frame_add(struct lpfc_vport *vport, struct hbq_dmabuf *dmabuf)\r\n{\r\nstruct fc_frame_header *new_hdr;\r\nstruct fc_frame_header *temp_hdr;\r\nstruct lpfc_dmabuf *d_buf;\r\nstruct lpfc_dmabuf *h_buf;\r\nstruct hbq_dmabuf *seq_dmabuf = NULL;\r\nstruct hbq_dmabuf *temp_dmabuf = NULL;\r\nINIT_LIST_HEAD(&dmabuf->dbuf.list);\r\ndmabuf->time_stamp = jiffies;\r\nnew_hdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\r\nlist_for_each_entry(h_buf, &vport->rcv_buffer_list, list) {\r\ntemp_hdr = (struct fc_frame_header *)h_buf->virt;\r\nif ((temp_hdr->fh_seq_id != new_hdr->fh_seq_id) ||\r\n(temp_hdr->fh_ox_id != new_hdr->fh_ox_id) ||\r\n(memcmp(&temp_hdr->fh_s_id, &new_hdr->fh_s_id, 3)))\r\ncontinue;\r\nseq_dmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\r\nbreak;\r\n}\r\nif (!seq_dmabuf) {\r\nlist_add_tail(&dmabuf->hbuf.list, &vport->rcv_buffer_list);\r\nlpfc_update_rcv_time_stamp(vport);\r\nreturn dmabuf;\r\n}\r\ntemp_hdr = seq_dmabuf->hbuf.virt;\r\nif (be16_to_cpu(new_hdr->fh_seq_cnt) <\r\nbe16_to_cpu(temp_hdr->fh_seq_cnt)) {\r\nlist_del_init(&seq_dmabuf->hbuf.list);\r\nlist_add_tail(&dmabuf->hbuf.list, &vport->rcv_buffer_list);\r\nlist_add_tail(&dmabuf->dbuf.list, &seq_dmabuf->dbuf.list);\r\nlpfc_update_rcv_time_stamp(vport);\r\nreturn dmabuf;\r\n}\r\nlist_move_tail(&seq_dmabuf->hbuf.list, &vport->rcv_buffer_list);\r\nseq_dmabuf->time_stamp = jiffies;\r\nlpfc_update_rcv_time_stamp(vport);\r\nif (list_empty(&seq_dmabuf->dbuf.list)) {\r\ntemp_hdr = dmabuf->hbuf.virt;\r\nlist_add_tail(&dmabuf->dbuf.list, &seq_dmabuf->dbuf.list);\r\nreturn seq_dmabuf;\r\n}\r\nlist_for_each_entry_reverse(d_buf, &seq_dmabuf->dbuf.list, list) {\r\ntemp_dmabuf = container_of(d_buf, struct hbq_dmabuf, dbuf);\r\ntemp_hdr = (struct fc_frame_header *)temp_dmabuf->hbuf.virt;\r\nif (be16_to_cpu(new_hdr->fh_seq_cnt) >\r\nbe16_to_cpu(temp_hdr->fh_seq_cnt)) {\r\nlist_add(&dmabuf->dbuf.list, &temp_dmabuf->dbuf.list);\r\nreturn seq_dmabuf;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic bool\r\nlpfc_sli4_abort_partial_seq(struct lpfc_vport *vport,\r\nstruct hbq_dmabuf *dmabuf)\r\n{\r\nstruct fc_frame_header *new_hdr;\r\nstruct fc_frame_header *temp_hdr;\r\nstruct lpfc_dmabuf *d_buf, *n_buf, *h_buf;\r\nstruct hbq_dmabuf *seq_dmabuf = NULL;\r\nINIT_LIST_HEAD(&dmabuf->dbuf.list);\r\nINIT_LIST_HEAD(&dmabuf->hbuf.list);\r\nnew_hdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\r\nlist_for_each_entry(h_buf, &vport->rcv_buffer_list, list) {\r\ntemp_hdr = (struct fc_frame_header *)h_buf->virt;\r\nif ((temp_hdr->fh_seq_id != new_hdr->fh_seq_id) ||\r\n(temp_hdr->fh_ox_id != new_hdr->fh_ox_id) ||\r\n(memcmp(&temp_hdr->fh_s_id, &new_hdr->fh_s_id, 3)))\r\ncontinue;\r\nseq_dmabuf = container_of(h_buf, struct hbq_dmabuf, hbuf);\r\nbreak;\r\n}\r\nif (seq_dmabuf) {\r\nlist_for_each_entry_safe(d_buf, n_buf,\r\n&seq_dmabuf->dbuf.list, list) {\r\nlist_del_init(&d_buf->list);\r\nlpfc_in_buf_free(vport->phba, d_buf);\r\n}\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic bool\r\nlpfc_sli4_abort_ulp_seq(struct lpfc_vport *vport, struct hbq_dmabuf *dmabuf)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nint handled;\r\nif (phba->sli_rev < LPFC_SLI_REV4)\r\nreturn false;\r\nhandled = lpfc_ct_handle_unsol_abort(phba, dmabuf);\r\nif (handled)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void\r\nlpfc_sli4_seq_abort_rsp_cmpl(struct lpfc_hba *phba,\r\nstruct lpfc_iocbq *cmd_iocbq,\r\nstruct lpfc_iocbq *rsp_iocbq)\r\n{\r\nstruct lpfc_nodelist *ndlp;\r\nif (cmd_iocbq) {\r\nndlp = (struct lpfc_nodelist *)cmd_iocbq->context1;\r\nlpfc_nlp_put(ndlp);\r\nlpfc_nlp_not_used(ndlp);\r\nlpfc_sli_release_iocbq(phba, cmd_iocbq);\r\n}\r\nif (rsp_iocbq && rsp_iocbq->iocb.ulpStatus)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"3154 BLS ABORT RSP failed, data: x%x/x%x\n",\r\nrsp_iocbq->iocb.ulpStatus,\r\nrsp_iocbq->iocb.un.ulpWord[4]);\r\n}\r\nuint16_t\r\nlpfc_sli4_xri_inrange(struct lpfc_hba *phba,\r\nuint16_t xri)\r\n{\r\nuint16_t i;\r\nfor (i = 0; i < phba->sli4_hba.max_cfg_param.max_xri; i++) {\r\nif (xri == phba->sli4_hba.xri_ids[i])\r\nreturn i;\r\n}\r\nreturn NO_XRI;\r\n}\r\nstatic void\r\nlpfc_sli4_seq_abort_rsp(struct lpfc_vport *vport,\r\nstruct fc_frame_header *fc_hdr, bool aborted)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_iocbq *ctiocb = NULL;\r\nstruct lpfc_nodelist *ndlp;\r\nuint16_t oxid, rxid, xri, lxri;\r\nuint32_t sid, fctl;\r\nIOCB_t *icmd;\r\nint rc;\r\nif (!lpfc_is_link_up(phba))\r\nreturn;\r\nsid = sli4_sid_from_fc_hdr(fc_hdr);\r\noxid = be16_to_cpu(fc_hdr->fh_ox_id);\r\nrxid = be16_to_cpu(fc_hdr->fh_rx_id);\r\nndlp = lpfc_findnode_did(vport, sid);\r\nif (!ndlp) {\r\nndlp = mempool_alloc(phba->nlp_mem_pool, GFP_KERNEL);\r\nif (!ndlp) {\r\nlpfc_printf_vlog(vport, KERN_WARNING, LOG_ELS,\r\n"1268 Failed to allocate ndlp for "\r\n"oxid:x%x SID:x%x\n", oxid, sid);\r\nreturn;\r\n}\r\nlpfc_nlp_init(vport, ndlp, sid);\r\nlpfc_enqueue_node(vport, ndlp);\r\n} else if (!NLP_CHK_NODE_ACT(ndlp)) {\r\nndlp = lpfc_enable_node(vport, ndlp, NLP_STE_UNUSED_NODE);\r\nif (!ndlp) {\r\nlpfc_printf_vlog(vport, KERN_WARNING, LOG_ELS,\r\n"3275 Failed to active ndlp found "\r\n"for oxid:x%x SID:x%x\n", oxid, sid);\r\nreturn;\r\n}\r\n}\r\nctiocb = lpfc_sli_get_iocbq(phba);\r\nif (!ctiocb)\r\nreturn;\r\nfctl = sli4_fctl_from_fc_hdr(fc_hdr);\r\nicmd = &ctiocb->iocb;\r\nicmd->un.xseq64.bdl.bdeSize = 0;\r\nicmd->un.xseq64.bdl.ulpIoTag32 = 0;\r\nicmd->un.xseq64.w5.hcsw.Dfctl = 0;\r\nicmd->un.xseq64.w5.hcsw.Rctl = FC_RCTL_BA_ACC;\r\nicmd->un.xseq64.w5.hcsw.Type = FC_TYPE_BLS;\r\nicmd->ulpCommand = CMD_XMIT_BLS_RSP64_CX;\r\nicmd->ulpBdeCount = 0;\r\nicmd->ulpLe = 1;\r\nicmd->ulpClass = CLASS3;\r\nicmd->ulpContext = phba->sli4_hba.rpi_ids[ndlp->nlp_rpi];\r\nctiocb->context1 = lpfc_nlp_get(ndlp);\r\nctiocb->iocb_cmpl = NULL;\r\nctiocb->vport = phba->pport;\r\nctiocb->iocb_cmpl = lpfc_sli4_seq_abort_rsp_cmpl;\r\nctiocb->sli4_lxritag = NO_XRI;\r\nctiocb->sli4_xritag = NO_XRI;\r\nif (fctl & FC_FC_EX_CTX)\r\nxri = oxid;\r\nelse\r\nxri = rxid;\r\nlxri = lpfc_sli4_xri_inrange(phba, xri);\r\nif (lxri != NO_XRI)\r\nlpfc_set_rrq_active(phba, ndlp, lxri,\r\n(xri == oxid) ? rxid : oxid, 0);\r\nif ((fctl & FC_FC_EX_CTX) &&\r\n(lxri > lpfc_sli4_get_els_iocb_cnt(phba))) {\r\nicmd->un.xseq64.w5.hcsw.Rctl = FC_RCTL_BA_RJT;\r\nbf_set(lpfc_vndr_code, &icmd->un.bls_rsp, 0);\r\nbf_set(lpfc_rsn_expln, &icmd->un.bls_rsp, FC_BA_RJT_INV_XID);\r\nbf_set(lpfc_rsn_code, &icmd->un.bls_rsp, FC_BA_RJT_UNABLE);\r\n}\r\nif (aborted == false) {\r\nicmd->un.xseq64.w5.hcsw.Rctl = FC_RCTL_BA_RJT;\r\nbf_set(lpfc_vndr_code, &icmd->un.bls_rsp, 0);\r\nbf_set(lpfc_rsn_expln, &icmd->un.bls_rsp, FC_BA_RJT_INV_XID);\r\nbf_set(lpfc_rsn_code, &icmd->un.bls_rsp, FC_BA_RJT_UNABLE);\r\n}\r\nif (fctl & FC_FC_EX_CTX) {\r\nbf_set(lpfc_abts_orig, &icmd->un.bls_rsp, LPFC_ABTS_UNSOL_RSP);\r\n} else {\r\nbf_set(lpfc_abts_orig, &icmd->un.bls_rsp, LPFC_ABTS_UNSOL_INT);\r\n}\r\nbf_set(lpfc_abts_rxid, &icmd->un.bls_rsp, rxid);\r\nbf_set(lpfc_abts_oxid, &icmd->un.bls_rsp, oxid);\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_ELS,\r\n"1200 Send BLS cmd x%x on oxid x%x Data: x%x\n",\r\nicmd->un.xseq64.w5.hcsw.Rctl, oxid, phba->link_state);\r\nrc = lpfc_sli_issue_iocb(phba, LPFC_ELS_RING, ctiocb, 0);\r\nif (rc == IOCB_ERROR) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_ELS,\r\n"2925 Failed to issue CT ABTS RSP x%x on "\r\n"xri x%x, Data x%x\n",\r\nicmd->un.xseq64.w5.hcsw.Rctl, oxid,\r\nphba->link_state);\r\nlpfc_nlp_put(ndlp);\r\nctiocb->context1 = NULL;\r\nlpfc_sli_release_iocbq(phba, ctiocb);\r\n}\r\n}\r\nstatic void\r\nlpfc_sli4_handle_unsol_abort(struct lpfc_vport *vport,\r\nstruct hbq_dmabuf *dmabuf)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct fc_frame_header fc_hdr;\r\nuint32_t fctl;\r\nbool aborted;\r\nmemcpy(&fc_hdr, dmabuf->hbuf.virt, sizeof(struct fc_frame_header));\r\nfctl = sli4_fctl_from_fc_hdr(&fc_hdr);\r\nif (fctl & FC_FC_EX_CTX) {\r\naborted = true;\r\n} else {\r\naborted = lpfc_sli4_abort_partial_seq(vport, dmabuf);\r\nif (aborted == false)\r\naborted = lpfc_sli4_abort_ulp_seq(vport, dmabuf);\r\n}\r\nlpfc_in_buf_free(phba, &dmabuf->dbuf);\r\nlpfc_sli4_seq_abort_rsp(vport, &fc_hdr, aborted);\r\n}\r\nstatic int\r\nlpfc_seq_complete(struct hbq_dmabuf *dmabuf)\r\n{\r\nstruct fc_frame_header *hdr;\r\nstruct lpfc_dmabuf *d_buf;\r\nstruct hbq_dmabuf *seq_dmabuf;\r\nuint32_t fctl;\r\nint seq_count = 0;\r\nhdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\r\nif (hdr->fh_seq_cnt != seq_count)\r\nreturn 0;\r\nfctl = (hdr->fh_f_ctl[0] << 16 |\r\nhdr->fh_f_ctl[1] << 8 |\r\nhdr->fh_f_ctl[2]);\r\nif (fctl & FC_FC_END_SEQ)\r\nreturn 1;\r\nlist_for_each_entry(d_buf, &dmabuf->dbuf.list, list) {\r\nseq_dmabuf = container_of(d_buf, struct hbq_dmabuf, dbuf);\r\nhdr = (struct fc_frame_header *)seq_dmabuf->hbuf.virt;\r\nif (++seq_count != be16_to_cpu(hdr->fh_seq_cnt))\r\nreturn 0;\r\nfctl = (hdr->fh_f_ctl[0] << 16 |\r\nhdr->fh_f_ctl[1] << 8 |\r\nhdr->fh_f_ctl[2]);\r\nif (fctl & FC_FC_END_SEQ)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct lpfc_iocbq *\r\nlpfc_prep_seq(struct lpfc_vport *vport, struct hbq_dmabuf *seq_dmabuf)\r\n{\r\nstruct hbq_dmabuf *hbq_buf;\r\nstruct lpfc_dmabuf *d_buf, *n_buf;\r\nstruct lpfc_iocbq *first_iocbq, *iocbq;\r\nstruct fc_frame_header *fc_hdr;\r\nuint32_t sid;\r\nuint32_t len, tot_len;\r\nstruct ulp_bde64 *pbde;\r\nfc_hdr = (struct fc_frame_header *)seq_dmabuf->hbuf.virt;\r\nlist_del_init(&seq_dmabuf->hbuf.list);\r\nlpfc_update_rcv_time_stamp(vport);\r\nsid = sli4_sid_from_fc_hdr(fc_hdr);\r\ntot_len = 0;\r\nfirst_iocbq = lpfc_sli_get_iocbq(vport->phba);\r\nif (first_iocbq) {\r\nfirst_iocbq->iocb.unsli3.rcvsli3.acc_len = 0;\r\nfirst_iocbq->iocb.ulpStatus = IOSTAT_SUCCESS;\r\nif (sli4_type_from_fc_hdr(fc_hdr) == FC_TYPE_ELS) {\r\nfirst_iocbq->iocb.ulpCommand = CMD_IOCB_RCV_ELS64_CX;\r\nfirst_iocbq->iocb.un.rcvels.parmRo =\r\nsli4_did_from_fc_hdr(fc_hdr);\r\nfirst_iocbq->iocb.ulpPU = PARM_NPIV_DID;\r\n} else\r\nfirst_iocbq->iocb.ulpCommand = CMD_IOCB_RCV_SEQ64_CX;\r\nfirst_iocbq->iocb.ulpContext = NO_XRI;\r\nfirst_iocbq->iocb.unsli3.rcvsli3.ox_id =\r\nbe16_to_cpu(fc_hdr->fh_ox_id);\r\nfirst_iocbq->iocb.unsli3.rcvsli3.vpi =\r\nvport->phba->vpi_ids[vport->vpi];\r\ntot_len = bf_get(lpfc_rcqe_length,\r\n&seq_dmabuf->cq_event.cqe.rcqe_cmpl);\r\nfirst_iocbq->context2 = &seq_dmabuf->dbuf;\r\nfirst_iocbq->context3 = NULL;\r\nfirst_iocbq->iocb.ulpBdeCount = 1;\r\nif (tot_len > LPFC_DATA_BUF_SIZE)\r\nfirst_iocbq->iocb.un.cont64[0].tus.f.bdeSize =\r\nLPFC_DATA_BUF_SIZE;\r\nelse\r\nfirst_iocbq->iocb.un.cont64[0].tus.f.bdeSize = tot_len;\r\nfirst_iocbq->iocb.un.rcvels.remoteID = sid;\r\nfirst_iocbq->iocb.unsli3.rcvsli3.acc_len = tot_len;\r\n}\r\niocbq = first_iocbq;\r\nlist_for_each_entry_safe(d_buf, n_buf, &seq_dmabuf->dbuf.list, list) {\r\nif (!iocbq) {\r\nlpfc_in_buf_free(vport->phba, d_buf);\r\ncontinue;\r\n}\r\nif (!iocbq->context3) {\r\niocbq->context3 = d_buf;\r\niocbq->iocb.ulpBdeCount++;\r\nhbq_buf = container_of(d_buf, struct hbq_dmabuf, dbuf);\r\nlen = bf_get(lpfc_rcqe_length,\r\n&hbq_buf->cq_event.cqe.rcqe_cmpl);\r\npbde = (struct ulp_bde64 *)\r\n&iocbq->iocb.unsli3.sli3Words[4];\r\nif (len > LPFC_DATA_BUF_SIZE)\r\npbde->tus.f.bdeSize = LPFC_DATA_BUF_SIZE;\r\nelse\r\npbde->tus.f.bdeSize = len;\r\niocbq->iocb.unsli3.rcvsli3.acc_len += len;\r\ntot_len += len;\r\n} else {\r\niocbq = lpfc_sli_get_iocbq(vport->phba);\r\nif (!iocbq) {\r\nif (first_iocbq) {\r\nfirst_iocbq->iocb.ulpStatus =\r\nIOSTAT_FCP_RSP_ERROR;\r\nfirst_iocbq->iocb.un.ulpWord[4] =\r\nIOERR_NO_RESOURCES;\r\n}\r\nlpfc_in_buf_free(vport->phba, d_buf);\r\ncontinue;\r\n}\r\nhbq_buf = container_of(d_buf, struct hbq_dmabuf, dbuf);\r\nlen = bf_get(lpfc_rcqe_length,\r\n&hbq_buf->cq_event.cqe.rcqe_cmpl);\r\niocbq->context2 = d_buf;\r\niocbq->context3 = NULL;\r\niocbq->iocb.ulpBdeCount = 1;\r\nif (len > LPFC_DATA_BUF_SIZE)\r\niocbq->iocb.un.cont64[0].tus.f.bdeSize =\r\nLPFC_DATA_BUF_SIZE;\r\nelse\r\niocbq->iocb.un.cont64[0].tus.f.bdeSize = len;\r\ntot_len += len;\r\niocbq->iocb.unsli3.rcvsli3.acc_len = tot_len;\r\niocbq->iocb.un.rcvels.remoteID = sid;\r\nlist_add_tail(&iocbq->list, &first_iocbq->list);\r\n}\r\n}\r\nreturn first_iocbq;\r\n}\r\nstatic void\r\nlpfc_sli4_send_seq_to_ulp(struct lpfc_vport *vport,\r\nstruct hbq_dmabuf *seq_dmabuf)\r\n{\r\nstruct fc_frame_header *fc_hdr;\r\nstruct lpfc_iocbq *iocbq, *curr_iocb, *next_iocb;\r\nstruct lpfc_hba *phba = vport->phba;\r\nfc_hdr = (struct fc_frame_header *)seq_dmabuf->hbuf.virt;\r\niocbq = lpfc_prep_seq(vport, seq_dmabuf);\r\nif (!iocbq) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2707 Ring %d handler: Failed to allocate "\r\n"iocb Rctl x%x Type x%x received\n",\r\nLPFC_ELS_RING,\r\nfc_hdr->fh_r_ctl, fc_hdr->fh_type);\r\nreturn;\r\n}\r\nif (!lpfc_complete_unsol_iocb(phba,\r\n&phba->sli.ring[LPFC_ELS_RING],\r\niocbq, fc_hdr->fh_r_ctl,\r\nfc_hdr->fh_type))\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2540 Ring %d handler: unexpected Rctl "\r\n"x%x Type x%x received\n",\r\nLPFC_ELS_RING,\r\nfc_hdr->fh_r_ctl, fc_hdr->fh_type);\r\nlist_for_each_entry_safe(curr_iocb, next_iocb,\r\n&iocbq->list, list) {\r\nlist_del_init(&curr_iocb->list);\r\nlpfc_sli_release_iocbq(phba, curr_iocb);\r\n}\r\nlpfc_sli_release_iocbq(phba, iocbq);\r\n}\r\nvoid\r\nlpfc_sli4_handle_received_buffer(struct lpfc_hba *phba,\r\nstruct hbq_dmabuf *dmabuf)\r\n{\r\nstruct hbq_dmabuf *seq_dmabuf;\r\nstruct fc_frame_header *fc_hdr;\r\nstruct lpfc_vport *vport;\r\nuint32_t fcfi;\r\nuint32_t did;\r\nfc_hdr = (struct fc_frame_header *)dmabuf->hbuf.virt;\r\nif (lpfc_fc_frame_check(phba, fc_hdr)) {\r\nlpfc_in_buf_free(phba, &dmabuf->dbuf);\r\nreturn;\r\n}\r\nif ((bf_get(lpfc_cqe_code,\r\n&dmabuf->cq_event.cqe.rcqe_cmpl) == CQE_CODE_RECEIVE_V1))\r\nfcfi = bf_get(lpfc_rcqe_fcf_id_v1,\r\n&dmabuf->cq_event.cqe.rcqe_cmpl);\r\nelse\r\nfcfi = bf_get(lpfc_rcqe_fcf_id,\r\n&dmabuf->cq_event.cqe.rcqe_cmpl);\r\nvport = lpfc_fc_frame_to_vport(phba, fc_hdr, fcfi);\r\nif (!vport) {\r\nlpfc_in_buf_free(phba, &dmabuf->dbuf);\r\nreturn;\r\n}\r\ndid = sli4_did_from_fc_hdr(fc_hdr);\r\nif (!(vport->vpi_state & LPFC_VPI_REGISTERED) &&\r\n(did != Fabric_DID)) {\r\nif (!(vport->fc_flag & FC_PT2PT) ||\r\n(phba->link_state == LPFC_HBA_READY)) {\r\nlpfc_in_buf_free(phba, &dmabuf->dbuf);\r\nreturn;\r\n}\r\n}\r\nif (fc_hdr->fh_r_ctl == FC_RCTL_BA_ABTS) {\r\nlpfc_sli4_handle_unsol_abort(vport, dmabuf);\r\nreturn;\r\n}\r\nseq_dmabuf = lpfc_fc_frame_add(vport, dmabuf);\r\nif (!seq_dmabuf) {\r\nlpfc_in_buf_free(phba, &dmabuf->dbuf);\r\nreturn;\r\n}\r\nif (!lpfc_seq_complete(seq_dmabuf))\r\nreturn;\r\nlpfc_sli4_send_seq_to_ulp(vport, seq_dmabuf);\r\n}\r\nint\r\nlpfc_sli4_post_all_rpi_hdrs(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_rpi_hdr *rpi_page;\r\nuint32_t rc = 0;\r\nuint16_t lrpi = 0;\r\nif (!phba->sli4_hba.rpi_hdrs_in_use)\r\ngoto exit;\r\nif (phba->sli4_hba.extents_in_use)\r\nreturn -EIO;\r\nlist_for_each_entry(rpi_page, &phba->sli4_hba.lpfc_rpi_hdr_list, list) {\r\nif (bf_get(lpfc_rpi_rsrc_rdy, &phba->sli4_hba.sli4_flags) !=\r\nLPFC_RPI_RSRC_RDY)\r\nrpi_page->start_rpi = phba->sli4_hba.rpi_ids[lrpi];\r\nrc = lpfc_sli4_post_rpi_hdr(phba, rpi_page);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2008 Error %d posting all rpi "\r\n"headers\n", rc);\r\nrc = -EIO;\r\nbreak;\r\n}\r\n}\r\nexit:\r\nbf_set(lpfc_rpi_rsrc_rdy, &phba->sli4_hba.sli4_flags,\r\nLPFC_RPI_RSRC_RDY);\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli4_post_rpi_hdr(struct lpfc_hba *phba, struct lpfc_rpi_hdr *rpi_page)\r\n{\r\nLPFC_MBOXQ_t *mboxq;\r\nstruct lpfc_mbx_post_hdr_tmpl *hdr_tmpl;\r\nuint32_t rc = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nif (!phba->sli4_hba.rpi_hdrs_in_use)\r\nreturn rc;\r\nif (phba->sli4_hba.extents_in_use)\r\nreturn -EIO;\r\nmboxq = (LPFC_MBOXQ_t *) mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2001 Unable to allocate memory for issuing "\r\n"SLI_CONFIG_SPECIAL mailbox command\n");\r\nreturn -ENOMEM;\r\n}\r\nhdr_tmpl = &mboxq->u.mqe.un.hdr_tmpl;\r\nlpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_POST_HDR_TEMPLATE,\r\nsizeof(struct lpfc_mbx_post_hdr_tmpl) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr),\r\nLPFC_SLI4_MBX_EMBED);\r\nbf_set(lpfc_mbx_post_hdr_tmpl_rpi_offset, hdr_tmpl,\r\nrpi_page->start_rpi);\r\nbf_set(lpfc_mbx_post_hdr_tmpl_page_cnt,\r\nhdr_tmpl, rpi_page->page_count);\r\nhdr_tmpl->rpi_paddr_lo = putPaddrLow(rpi_page->dmabuf->phys);\r\nhdr_tmpl->rpi_paddr_hi = putPaddrHigh(rpi_page->dmabuf->phys);\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nshdr = (union lpfc_sli4_cfg_shdr *) &hdr_tmpl->header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (rc != MBX_TIMEOUT)\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2514 POST_RPI_HDR mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nrc = -ENXIO;\r\n}\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli4_alloc_rpi(struct lpfc_hba *phba)\r\n{\r\nunsigned long rpi;\r\nuint16_t max_rpi, rpi_limit;\r\nuint16_t rpi_remaining, lrpi = 0;\r\nstruct lpfc_rpi_hdr *rpi_hdr;\r\nunsigned long iflag;\r\nspin_lock_irqsave(&phba->hbalock, iflag);\r\nmax_rpi = phba->sli4_hba.max_cfg_param.max_rpi;\r\nrpi_limit = phba->sli4_hba.next_rpi;\r\nrpi = find_next_zero_bit(phba->sli4_hba.rpi_bmask, rpi_limit, 0);\r\nif (rpi >= rpi_limit)\r\nrpi = LPFC_RPI_ALLOC_ERROR;\r\nelse {\r\nset_bit(rpi, phba->sli4_hba.rpi_bmask);\r\nphba->sli4_hba.max_cfg_param.rpi_used++;\r\nphba->sli4_hba.rpi_count++;\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_SLI,\r\n"0001 rpi:%x max:%x lim:%x\n",\r\n(int) rpi, max_rpi, rpi_limit);\r\nif ((rpi == LPFC_RPI_ALLOC_ERROR) &&\r\n(phba->sli4_hba.rpi_count >= max_rpi)) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn rpi;\r\n}\r\nif (!phba->sli4_hba.rpi_hdrs_in_use) {\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nreturn rpi;\r\n}\r\nrpi_remaining = phba->sli4_hba.next_rpi - phba->sli4_hba.rpi_count;\r\nspin_unlock_irqrestore(&phba->hbalock, iflag);\r\nif (rpi_remaining < LPFC_RPI_LOW_WATER_MARK) {\r\nrpi_hdr = lpfc_sli4_create_rpi_hdr(phba);\r\nif (!rpi_hdr) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2002 Error Could not grow rpi "\r\n"count\n");\r\n} else {\r\nlrpi = rpi_hdr->start_rpi;\r\nrpi_hdr->start_rpi = phba->sli4_hba.rpi_ids[lrpi];\r\nlpfc_sli4_post_rpi_hdr(phba, rpi_hdr);\r\n}\r\n}\r\nreturn rpi;\r\n}\r\nstatic void\r\n__lpfc_sli4_free_rpi(struct lpfc_hba *phba, int rpi)\r\n{\r\nif (test_and_clear_bit(rpi, phba->sli4_hba.rpi_bmask)) {\r\nphba->sli4_hba.rpi_count--;\r\nphba->sli4_hba.max_cfg_param.rpi_used--;\r\n}\r\n}\r\nvoid\r\nlpfc_sli4_free_rpi(struct lpfc_hba *phba, int rpi)\r\n{\r\nspin_lock_irq(&phba->hbalock);\r\n__lpfc_sli4_free_rpi(phba, rpi);\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nvoid\r\nlpfc_sli4_remove_rpis(struct lpfc_hba *phba)\r\n{\r\nkfree(phba->sli4_hba.rpi_bmask);\r\nkfree(phba->sli4_hba.rpi_ids);\r\nbf_set(lpfc_rpi_rsrc_rdy, &phba->sli4_hba.sli4_flags, 0);\r\n}\r\nint\r\nlpfc_sli4_resume_rpi(struct lpfc_nodelist *ndlp,\r\nvoid (*cmpl)(struct lpfc_hba *, LPFC_MBOXQ_t *), void *arg)\r\n{\r\nLPFC_MBOXQ_t *mboxq;\r\nstruct lpfc_hba *phba = ndlp->phba;\r\nint rc;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq)\r\nreturn -ENOMEM;\r\nlpfc_resume_rpi(mboxq, ndlp);\r\nif (cmpl) {\r\nmboxq->mbox_cmpl = cmpl;\r\nmboxq->context1 = arg;\r\nmboxq->context2 = ndlp;\r\n} else\r\nmboxq->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nmboxq->vport = ndlp->vport;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2010 Resume RPI Mailbox failed "\r\n"status %d, mbxStatus x%x\n", rc,\r\nbf_get(lpfc_mqe_status, &mboxq->u.mqe));\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nlpfc_sli4_init_vpi(struct lpfc_vport *vport)\r\n{\r\nLPFC_MBOXQ_t *mboxq;\r\nint rc = 0;\r\nint retval = MBX_SUCCESS;\r\nuint32_t mbox_tmo;\r\nstruct lpfc_hba *phba = vport->phba;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq)\r\nreturn -ENOMEM;\r\nlpfc_init_vpi(phba, mboxq, vport->vpi);\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mboxq);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mboxq, mbox_tmo);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_SLI,\r\n"2022 INIT VPI Mailbox failed "\r\n"status %d, mbxStatus x%x\n", rc,\r\nbf_get(lpfc_mqe_status, &mboxq->u.mqe));\r\nretval = -EIO;\r\n}\r\nif (rc != MBX_TIMEOUT)\r\nmempool_free(mboxq, vport->phba->mbox_mem_pool);\r\nreturn retval;\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_add_fcf_record(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nvoid *virt_addr;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nuint32_t shdr_status, shdr_add_status;\r\nvirt_addr = mboxq->sge_array->addr[0];\r\nshdr = (union lpfc_sli4_cfg_shdr *) virt_addr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif ((shdr_status || shdr_add_status) &&\r\n(shdr_status != STATUS_FCF_IN_USE))\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2558 ADD_FCF_RECORD mailbox failed with "\r\n"status x%x add_status x%x\n",\r\nshdr_status, shdr_add_status);\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\n}\r\nint\r\nlpfc_sli4_add_fcf_record(struct lpfc_hba *phba, struct fcf_record *fcf_record)\r\n{\r\nint rc = 0;\r\nLPFC_MBOXQ_t *mboxq;\r\nuint8_t *bytep;\r\nvoid *virt_addr;\r\ndma_addr_t phys_addr;\r\nstruct lpfc_mbx_sge sge;\r\nuint32_t alloc_len, req_len;\r\nuint32_t fcfindex;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2009 Failed to allocate mbox for ADD_FCF cmd\n");\r\nreturn -ENOMEM;\r\n}\r\nreq_len = sizeof(struct fcf_record) + sizeof(union lpfc_sli4_cfg_shdr) +\r\nsizeof(uint32_t);\r\nalloc_len = lpfc_sli4_config(phba, mboxq, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_ADD_FCF,\r\nreq_len, LPFC_SLI4_MBX_NEMBED);\r\nif (alloc_len < req_len) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2523 Allocated DMA memory size (x%x) is "\r\n"less than the requested DMA memory "\r\n"size (x%x)\n", alloc_len, req_len);\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nreturn -ENOMEM;\r\n}\r\nlpfc_sli4_mbx_sge_get(mboxq, 0, &sge);\r\nphys_addr = getPaddr(sge.pa_hi, sge.pa_lo);\r\nvirt_addr = mboxq->sge_array->addr[0];\r\nfcfindex = bf_get(lpfc_fcf_record_fcf_index, fcf_record);\r\nbytep = virt_addr + sizeof(union lpfc_sli4_cfg_shdr);\r\nlpfc_sli_pcimem_bcopy(&fcfindex, bytep, sizeof(uint32_t));\r\nbytep += sizeof(uint32_t);\r\nlpfc_sli_pcimem_bcopy(fcf_record, bytep, sizeof(struct fcf_record));\r\nmboxq->vport = phba->pport;\r\nmboxq->mbox_cmpl = lpfc_mbx_cmpl_add_fcf_record;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2515 ADD_FCF_RECORD mailbox failed with "\r\n"status 0x%x\n", rc);\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nrc = -EIO;\r\n} else\r\nrc = 0;\r\nreturn rc;\r\n}\r\nvoid\r\nlpfc_sli4_build_dflt_fcf_record(struct lpfc_hba *phba,\r\nstruct fcf_record *fcf_record,\r\nuint16_t fcf_index)\r\n{\r\nmemset(fcf_record, 0, sizeof(struct fcf_record));\r\nfcf_record->max_rcv_size = LPFC_FCOE_MAX_RCV_SIZE;\r\nfcf_record->fka_adv_period = LPFC_FCOE_FKA_ADV_PER;\r\nfcf_record->fip_priority = LPFC_FCOE_FIP_PRIORITY;\r\nbf_set(lpfc_fcf_record_mac_0, fcf_record, phba->fc_map[0]);\r\nbf_set(lpfc_fcf_record_mac_1, fcf_record, phba->fc_map[1]);\r\nbf_set(lpfc_fcf_record_mac_2, fcf_record, phba->fc_map[2]);\r\nbf_set(lpfc_fcf_record_mac_3, fcf_record, LPFC_FCOE_FCF_MAC3);\r\nbf_set(lpfc_fcf_record_mac_4, fcf_record, LPFC_FCOE_FCF_MAC4);\r\nbf_set(lpfc_fcf_record_mac_5, fcf_record, LPFC_FCOE_FCF_MAC5);\r\nbf_set(lpfc_fcf_record_fc_map_0, fcf_record, phba->fc_map[0]);\r\nbf_set(lpfc_fcf_record_fc_map_1, fcf_record, phba->fc_map[1]);\r\nbf_set(lpfc_fcf_record_fc_map_2, fcf_record, phba->fc_map[2]);\r\nbf_set(lpfc_fcf_record_fcf_valid, fcf_record, 1);\r\nbf_set(lpfc_fcf_record_fcf_avail, fcf_record, 1);\r\nbf_set(lpfc_fcf_record_fcf_index, fcf_record, fcf_index);\r\nbf_set(lpfc_fcf_record_mac_addr_prov, fcf_record,\r\nLPFC_FCF_FPMA | LPFC_FCF_SPMA);\r\nif (phba->valid_vlan) {\r\nfcf_record->vlan_bitmap[phba->vlan_id / 8]\r\n= 1 << (phba->vlan_id % 8);\r\n}\r\n}\r\nint\r\nlpfc_sli4_fcf_scan_read_fcf_rec(struct lpfc_hba *phba, uint16_t fcf_index)\r\n{\r\nint rc = 0, error;\r\nLPFC_MBOXQ_t *mboxq;\r\nphba->fcoe_eventtag_at_fcf_scan = phba->fcoe_eventtag;\r\nphba->fcoe_cvl_eventtag_attn = phba->fcoe_cvl_eventtag;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2000 Failed to allocate mbox for "\r\n"READ_FCF cmd\n");\r\nerror = -ENOMEM;\r\ngoto fail_fcf_scan;\r\n}\r\nrc = lpfc_sli4_mbx_read_fcf_rec(phba, mboxq, fcf_index);\r\nif (rc) {\r\nerror = -EINVAL;\r\ngoto fail_fcf_scan;\r\n}\r\nmboxq->vport = phba->pport;\r\nmboxq->mbox_cmpl = lpfc_mbx_cmpl_fcf_scan_read_fcf_rec;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag |= FCF_TS_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED)\r\nerror = -EIO;\r\nelse {\r\nif (fcf_index == LPFC_FCOE_FCF_GET_FIRST)\r\nphba->fcf.eligible_fcf_cnt = 0;\r\nerror = 0;\r\n}\r\nfail_fcf_scan:\r\nif (error) {\r\nif (mboxq)\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~FCF_TS_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nreturn error;\r\n}\r\nint\r\nlpfc_sli4_fcf_rr_read_fcf_rec(struct lpfc_hba *phba, uint16_t fcf_index)\r\n{\r\nint rc = 0, error;\r\nLPFC_MBOXQ_t *mboxq;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP | LOG_INIT,\r\n"2763 Failed to allocate mbox for "\r\n"READ_FCF cmd\n");\r\nerror = -ENOMEM;\r\ngoto fail_fcf_read;\r\n}\r\nrc = lpfc_sli4_mbx_read_fcf_rec(phba, mboxq, fcf_index);\r\nif (rc) {\r\nerror = -EINVAL;\r\ngoto fail_fcf_read;\r\n}\r\nmboxq->vport = phba->pport;\r\nmboxq->mbox_cmpl = lpfc_mbx_cmpl_fcf_rr_read_fcf_rec;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED)\r\nerror = -EIO;\r\nelse\r\nerror = 0;\r\nfail_fcf_read:\r\nif (error && mboxq)\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nreturn error;\r\n}\r\nint\r\nlpfc_sli4_read_fcf_rec(struct lpfc_hba *phba, uint16_t fcf_index)\r\n{\r\nint rc = 0, error;\r\nLPFC_MBOXQ_t *mboxq;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP | LOG_INIT,\r\n"2758 Failed to allocate mbox for "\r\n"READ_FCF cmd\n");\r\nerror = -ENOMEM;\r\ngoto fail_fcf_read;\r\n}\r\nrc = lpfc_sli4_mbx_read_fcf_rec(phba, mboxq, fcf_index);\r\nif (rc) {\r\nerror = -EINVAL;\r\ngoto fail_fcf_read;\r\n}\r\nmboxq->vport = phba->pport;\r\nmboxq->mbox_cmpl = lpfc_mbx_cmpl_read_fcf_rec;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED)\r\nerror = -EIO;\r\nelse\r\nerror = 0;\r\nfail_fcf_read:\r\nif (error && mboxq)\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nreturn error;\r\n}\r\nstatic int\r\nlpfc_check_next_fcf_pri_level(struct lpfc_hba *phba)\r\n{\r\nuint16_t next_fcf_pri;\r\nuint16_t last_index;\r\nstruct lpfc_fcf_pri *fcf_pri;\r\nint rc;\r\nint ret = 0;\r\nlast_index = find_first_bit(phba->fcf.fcf_rr_bmask,\r\nLPFC_SLI4_FCF_TBL_INDX_MAX);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"3060 Last IDX %d\n", last_index);\r\nspin_lock_irq(&phba->hbalock);\r\nif (list_empty(&phba->fcf.fcf_pri_list) ||\r\nlist_is_singular(&phba->fcf.fcf_pri_list)) {\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"3061 Last IDX %d\n", last_index);\r\nreturn 0;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nnext_fcf_pri = 0;\r\nmemset(phba->fcf.fcf_rr_bmask, 0,\r\nsizeof(*phba->fcf.fcf_rr_bmask));\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry(fcf_pri, &phba->fcf.fcf_pri_list, list) {\r\nif (fcf_pri->fcf_rec.flag & LPFC_FCF_FLOGI_FAILED)\r\ncontinue;\r\nif (!next_fcf_pri)\r\nnext_fcf_pri = fcf_pri->fcf_rec.priority;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (fcf_pri->fcf_rec.priority == next_fcf_pri) {\r\nrc = lpfc_sli4_fcf_rr_index_set(phba,\r\nfcf_pri->fcf_rec.fcf_index);\r\nif (rc)\r\nreturn 0;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\n}\r\nif (!next_fcf_pri && !list_empty(&phba->fcf.fcf_pri_list)) {\r\nlist_for_each_entry(fcf_pri, &phba->fcf.fcf_pri_list, list) {\r\nfcf_pri->fcf_rec.flag &= ~LPFC_FCF_FLOGI_FAILED;\r\nif (!next_fcf_pri)\r\nnext_fcf_pri = fcf_pri->fcf_rec.priority;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (fcf_pri->fcf_rec.priority == next_fcf_pri) {\r\nrc = lpfc_sli4_fcf_rr_index_set(phba,\r\nfcf_pri->fcf_rec.fcf_index);\r\nif (rc)\r\nreturn 0;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\n}\r\n} else\r\nret = 1;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn ret;\r\n}\r\nuint16_t\r\nlpfc_sli4_fcf_rr_next_index_get(struct lpfc_hba *phba)\r\n{\r\nuint16_t next_fcf_index;\r\ninitial_priority:\r\nnext_fcf_index = phba->fcf.current_rec.fcf_indx;\r\nnext_priority:\r\nnext_fcf_index = (next_fcf_index + 1) % LPFC_SLI4_FCF_TBL_INDX_MAX;\r\nnext_fcf_index = find_next_bit(phba->fcf.fcf_rr_bmask,\r\nLPFC_SLI4_FCF_TBL_INDX_MAX,\r\nnext_fcf_index);\r\nif (next_fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX) {\r\nnext_fcf_index = find_next_bit(phba->fcf.fcf_rr_bmask,\r\nLPFC_SLI4_FCF_TBL_INDX_MAX, 0);\r\n}\r\nif (next_fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX ||\r\nnext_fcf_index == phba->fcf.current_rec.fcf_indx) {\r\nif (lpfc_check_next_fcf_pri_level(phba))\r\ngoto initial_priority;\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_FIP,\r\n"2844 No roundrobin failover FCF available\n");\r\nif (next_fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX)\r\nreturn LPFC_FCOE_FCF_NEXT_NONE;\r\nelse {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_FIP,\r\n"3063 Only FCF available idx %d, flag %x\n",\r\nnext_fcf_index,\r\nphba->fcf.fcf_pri[next_fcf_index].fcf_rec.flag);\r\nreturn next_fcf_index;\r\n}\r\n}\r\nif (next_fcf_index < LPFC_SLI4_FCF_TBL_INDX_MAX &&\r\nphba->fcf.fcf_pri[next_fcf_index].fcf_rec.flag &\r\nLPFC_FCF_FLOGI_FAILED)\r\ngoto next_priority;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2845 Get next roundrobin failover FCF (x%x)\n",\r\nnext_fcf_index);\r\nreturn next_fcf_index;\r\n}\r\nint\r\nlpfc_sli4_fcf_rr_index_set(struct lpfc_hba *phba, uint16_t fcf_index)\r\n{\r\nif (fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2610 FCF (x%x) reached driver's book "\r\n"keeping dimension:x%x\n",\r\nfcf_index, LPFC_SLI4_FCF_TBL_INDX_MAX);\r\nreturn -EINVAL;\r\n}\r\nset_bit(fcf_index, phba->fcf.fcf_rr_bmask);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2790 Set FCF (x%x) to roundrobin FCF failover "\r\n"bmask\n", fcf_index);\r\nreturn 0;\r\n}\r\nvoid\r\nlpfc_sli4_fcf_rr_index_clear(struct lpfc_hba *phba, uint16_t fcf_index)\r\n{\r\nstruct lpfc_fcf_pri *fcf_pri, *fcf_pri_next;\r\nif (fcf_index >= LPFC_SLI4_FCF_TBL_INDX_MAX) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2762 FCF (x%x) reached driver's book "\r\n"keeping dimension:x%x\n",\r\nfcf_index, LPFC_SLI4_FCF_TBL_INDX_MAX);\r\nreturn;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(fcf_pri, fcf_pri_next, &phba->fcf.fcf_pri_list,\r\nlist) {\r\nif (fcf_pri->fcf_rec.fcf_index == fcf_index) {\r\nlist_del_init(&fcf_pri->list);\r\nbreak;\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nclear_bit(fcf_index, phba->fcf.fcf_rr_bmask);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2791 Clear FCF (x%x) from roundrobin failover "\r\n"bmask\n", fcf_index);\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_redisc_fcf_table(struct lpfc_hba *phba, LPFC_MBOXQ_t *mbox)\r\n{\r\nstruct lpfc_mbx_redisc_fcf_tbl *redisc_fcf;\r\nuint32_t shdr_status, shdr_add_status;\r\nredisc_fcf = &mbox->u.mqe.un.redisc_fcf_tbl;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status,\r\n&redisc_fcf->header.cfg_shdr.response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status,\r\n&redisc_fcf->header.cfg_shdr.response);\r\nif (shdr_status || shdr_add_status) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2746 Requesting for FCF rediscovery failed "\r\n"status x%x add_status x%x\n",\r\nshdr_status, shdr_add_status);\r\nif (phba->fcf.fcf_flag & FCF_ACVL_DISC) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_ACVL_DISC;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_retry_pport_discovery(phba);\r\n} else {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_DEAD_DISC;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_fcf_dead_failthrough(phba);\r\n}\r\n} else {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2775 Start FCF rediscover quiescent timer\n");\r\nlpfc_fcf_redisc_wait_start_timer(phba);\r\n}\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\n}\r\nint\r\nlpfc_sli4_redisc_fcf_table(struct lpfc_hba *phba)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nstruct lpfc_mbx_redisc_fcf_tbl *redisc_fcf;\r\nint rc, length;\r\nlpfc_cancel_all_vport_retry_delay_timer(phba);\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2745 Failed to allocate mbox for "\r\n"requesting FCF rediscover.\n");\r\nreturn -ENOMEM;\r\n}\r\nlength = (sizeof(struct lpfc_mbx_redisc_fcf_tbl) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr));\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_FCOE,\r\nLPFC_MBOX_OPCODE_FCOE_REDISCOVER_FCF,\r\nlength, LPFC_SLI4_MBX_EMBED);\r\nredisc_fcf = &mbox->u.mqe.un.redisc_fcf_tbl;\r\nbf_set(lpfc_mbx_redisc_fcf_count, redisc_fcf, 0);\r\nmbox->vport = phba->pport;\r\nmbox->mbox_cmpl = lpfc_mbx_cmpl_redisc_fcf_table;\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nlpfc_sli4_fcf_dead_failthrough(struct lpfc_hba *phba)\r\n{\r\nuint32_t link_state;\r\nlink_state = phba->link_state;\r\nlpfc_linkdown(phba);\r\nphba->link_state = link_state;\r\nlpfc_unregister_unused_fcf(phba);\r\n}\r\nstatic uint32_t\r\nlpfc_sli_get_config_region23(struct lpfc_hba *phba, char *rgn23_data)\r\n{\r\nLPFC_MBOXQ_t *pmb = NULL;\r\nMAILBOX_t *mb;\r\nuint32_t offset = 0;\r\nint rc;\r\nif (!rgn23_data)\r\nreturn 0;\r\npmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!pmb) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2600 failed to allocate mailbox memory\n");\r\nreturn 0;\r\n}\r\nmb = &pmb->u.mb;\r\ndo {\r\nlpfc_dump_mem(phba, pmb, offset, DMP_REGION_23);\r\nrc = lpfc_sli_issue_mbox(phba, pmb, MBX_POLL);\r\nif (rc != MBX_SUCCESS) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"2601 failed to read config "\r\n"region 23, rc 0x%x Status 0x%x\n",\r\nrc, mb->mbxStatus);\r\nmb->un.varDmp.word_cnt = 0;\r\n}\r\nif (mb->un.varDmp.word_cnt == 0)\r\nbreak;\r\nif (mb->un.varDmp.word_cnt > DMP_RGN23_SIZE - offset)\r\nmb->un.varDmp.word_cnt = DMP_RGN23_SIZE - offset;\r\nlpfc_sli_pcimem_bcopy(((uint8_t *)mb) + DMP_RSP_OFFSET,\r\nrgn23_data + offset,\r\nmb->un.varDmp.word_cnt);\r\noffset += mb->un.varDmp.word_cnt;\r\n} while (mb->un.varDmp.word_cnt && offset < DMP_RGN23_SIZE);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn offset;\r\n}\r\nstatic uint32_t\r\nlpfc_sli4_get_config_region23(struct lpfc_hba *phba, char *rgn23_data)\r\n{\r\nLPFC_MBOXQ_t *mboxq = NULL;\r\nstruct lpfc_dmabuf *mp = NULL;\r\nstruct lpfc_mqe *mqe;\r\nuint32_t data_length = 0;\r\nint rc;\r\nif (!rgn23_data)\r\nreturn 0;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3105 failed to allocate mailbox memory\n");\r\nreturn 0;\r\n}\r\nif (lpfc_sli4_dump_cfg_rg23(phba, mboxq))\r\ngoto out;\r\nmqe = &mboxq->u.mqe;\r\nmp = (struct lpfc_dmabuf *) mboxq->context1;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_POLL);\r\nif (rc)\r\ngoto out;\r\ndata_length = mqe->un.mb_words[5];\r\nif (data_length == 0)\r\ngoto out;\r\nif (data_length > DMP_RGN23_SIZE) {\r\ndata_length = 0;\r\ngoto out;\r\n}\r\nlpfc_sli_pcimem_bcopy((char *)mp->virt, rgn23_data, data_length);\r\nout:\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nif (mp) {\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\n}\r\nreturn data_length;\r\n}\r\nvoid\r\nlpfc_sli_read_link_ste(struct lpfc_hba *phba)\r\n{\r\nuint8_t *rgn23_data = NULL;\r\nuint32_t if_type, data_size, sub_tlv_len, tlv_offset;\r\nuint32_t offset = 0;\r\nrgn23_data = kzalloc(DMP_RGN23_SIZE, GFP_KERNEL);\r\nif (!rgn23_data)\r\ngoto out;\r\nif (phba->sli_rev < LPFC_SLI_REV4)\r\ndata_size = lpfc_sli_get_config_region23(phba, rgn23_data);\r\nelse {\r\nif_type = bf_get(lpfc_sli_intf_if_type,\r\n&phba->sli4_hba.sli_intf);\r\nif (if_type == LPFC_SLI_INTF_IF_TYPE_0)\r\ngoto out;\r\ndata_size = lpfc_sli4_get_config_region23(phba, rgn23_data);\r\n}\r\nif (!data_size)\r\ngoto out;\r\nif (memcmp(&rgn23_data[offset], LPFC_REGION23_SIGNATURE, 4)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2619 Config region 23 has bad signature\n");\r\ngoto out;\r\n}\r\noffset += 4;\r\nif (rgn23_data[offset] != LPFC_REGION23_VERSION) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2620 Config region 23 has bad version\n");\r\ngoto out;\r\n}\r\noffset += 4;\r\nwhile (offset < data_size) {\r\nif (rgn23_data[offset] == LPFC_REGION23_LAST_REC)\r\nbreak;\r\nif ((rgn23_data[offset] != DRIVER_SPECIFIC_TYPE) ||\r\n(rgn23_data[offset + 2] != LINUX_DRIVER_ID) ||\r\n(rgn23_data[offset + 3] != 0)) {\r\noffset += rgn23_data[offset + 1] * 4 + 4;\r\ncontinue;\r\n}\r\nsub_tlv_len = rgn23_data[offset + 1] * 4;\r\noffset += 4;\r\ntlv_offset = 0;\r\nwhile ((offset < data_size) &&\r\n(tlv_offset < sub_tlv_len)) {\r\nif (rgn23_data[offset] == LPFC_REGION23_LAST_REC) {\r\noffset += 4;\r\ntlv_offset += 4;\r\nbreak;\r\n}\r\nif (rgn23_data[offset] != PORT_STE_TYPE) {\r\noffset += rgn23_data[offset + 1] * 4 + 4;\r\ntlv_offset += rgn23_data[offset + 1] * 4 + 4;\r\ncontinue;\r\n}\r\nif (!rgn23_data[offset + 2])\r\nphba->hba_flag |= LINK_DISABLED;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nkfree(rgn23_data);\r\nreturn;\r\n}\r\nint\r\nlpfc_wr_object(struct lpfc_hba *phba, struct list_head *dmabuf_list,\r\nuint32_t size, uint32_t *offset)\r\n{\r\nstruct lpfc_mbx_wr_object *wr_object;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc = 0, i = 0;\r\nuint32_t shdr_status, shdr_add_status;\r\nuint32_t mbox_tmo;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nstruct lpfc_dmabuf *dmabuf;\r\nuint32_t written = 0;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn -ENOMEM;\r\nlpfc_sli4_config(phba, mbox, LPFC_MBOX_SUBSYSTEM_COMMON,\r\nLPFC_MBOX_OPCODE_WRITE_OBJECT,\r\nsizeof(struct lpfc_mbx_wr_object) -\r\nsizeof(struct lpfc_sli4_cfg_mhdr), LPFC_SLI4_MBX_EMBED);\r\nwr_object = (struct lpfc_mbx_wr_object *)&mbox->u.mqe.un.wr_object;\r\nwr_object->u.request.write_offset = *offset;\r\nsprintf((uint8_t *)wr_object->u.request.object_name, "/");\r\nwr_object->u.request.object_name[0] =\r\ncpu_to_le32(wr_object->u.request.object_name[0]);\r\nbf_set(lpfc_wr_object_eof, &wr_object->u.request, 0);\r\nlist_for_each_entry(dmabuf, dmabuf_list, list) {\r\nif (i >= LPFC_MBX_WR_CONFIG_MAX_BDE || written >= size)\r\nbreak;\r\nwr_object->u.request.bde[i].addrLow = putPaddrLow(dmabuf->phys);\r\nwr_object->u.request.bde[i].addrHigh =\r\nputPaddrHigh(dmabuf->phys);\r\nif (written + SLI4_PAGE_SIZE >= size) {\r\nwr_object->u.request.bde[i].tus.f.bdeSize =\r\n(size - written);\r\nwritten += (size - written);\r\nbf_set(lpfc_wr_object_eof, &wr_object->u.request, 1);\r\n} else {\r\nwr_object->u.request.bde[i].tus.f.bdeSize =\r\nSLI4_PAGE_SIZE;\r\nwritten += SLI4_PAGE_SIZE;\r\n}\r\ni++;\r\n}\r\nwr_object->u.request.bde_count = i;\r\nbf_set(lpfc_wr_object_write_length, &wr_object->u.request, written);\r\nif (!phba->sli4_hba.intr_enable)\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_POLL);\r\nelse {\r\nmbox_tmo = lpfc_mbox_tmo_val(phba, mbox);\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, mbox_tmo);\r\n}\r\nshdr = (union lpfc_sli4_cfg_shdr *) &wr_object->header.cfg_shdr;\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (rc != MBX_TIMEOUT)\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nif (shdr_status || shdr_add_status || rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"3025 Write Object mailbox failed with "\r\n"status x%x add_status x%x, mbx status x%x\n",\r\nshdr_status, shdr_add_status, rc);\r\nrc = -ENXIO;\r\n} else\r\n*offset += wr_object->u.response.actual_write_length;\r\nreturn rc;\r\n}\r\nvoid\r\nlpfc_cleanup_pending_mbox(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nLPFC_MBOXQ_t *mb, *nextmb;\r\nstruct lpfc_dmabuf *mp;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct lpfc_nodelist *act_mbx_ndlp = NULL;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nLIST_HEAD(mbox_cmd_list);\r\nuint8_t restart_loop;\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(mb, nextmb, &phba->sli.mboxq, list) {\r\nif (mb->vport != vport)\r\ncontinue;\r\nif ((mb->u.mb.mbxCommand != MBX_REG_LOGIN64) &&\r\n(mb->u.mb.mbxCommand != MBX_REG_VPI))\r\ncontinue;\r\nlist_del(&mb->list);\r\nlist_add_tail(&mb->list, &mbox_cmd_list);\r\n}\r\nmb = phba->sli.mbox_active;\r\nif (mb && (mb->vport == vport)) {\r\nif ((mb->u.mb.mbxCommand == MBX_REG_LOGIN64) ||\r\n(mb->u.mb.mbxCommand == MBX_REG_VPI))\r\nmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nif (mb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\r\nact_mbx_ndlp = (struct lpfc_nodelist *)mb->context2;\r\nact_mbx_ndlp = lpfc_nlp_get(act_mbx_ndlp);\r\nmb->mbox_flag |= LPFC_MBX_IMED_UNREG;\r\n}\r\n}\r\ndo {\r\nrestart_loop = 0;\r\nlist_for_each_entry(mb, &phba->sli.mboxq_cmpl, list) {\r\nif ((mb->vport != vport) ||\r\n(mb->mbox_flag & LPFC_MBX_IMED_UNREG))\r\ncontinue;\r\nif ((mb->u.mb.mbxCommand != MBX_REG_LOGIN64) &&\r\n(mb->u.mb.mbxCommand != MBX_REG_VPI))\r\ncontinue;\r\nmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nif (mb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\r\nndlp = (struct lpfc_nodelist *)mb->context2;\r\nmb->mbox_flag |= LPFC_MBX_IMED_UNREG;\r\nrestart_loop = 1;\r\nspin_unlock_irq(&phba->hbalock);\r\nspin_lock(shost->host_lock);\r\nndlp->nlp_flag &= ~NLP_IGNR_REG_CMPL;\r\nspin_unlock(shost->host_lock);\r\nspin_lock_irq(&phba->hbalock);\r\nbreak;\r\n}\r\n}\r\n} while (restart_loop);\r\nspin_unlock_irq(&phba->hbalock);\r\nwhile (!list_empty(&mbox_cmd_list)) {\r\nlist_remove_head(&mbox_cmd_list, mb, LPFC_MBOXQ_t, list);\r\nif (mb->u.mb.mbxCommand == MBX_REG_LOGIN64) {\r\nmp = (struct lpfc_dmabuf *) (mb->context1);\r\nif (mp) {\r\n__lpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\n}\r\nndlp = (struct lpfc_nodelist *) mb->context2;\r\nmb->context2 = NULL;\r\nif (ndlp) {\r\nspin_lock(shost->host_lock);\r\nndlp->nlp_flag &= ~NLP_IGNR_REG_CMPL;\r\nspin_unlock(shost->host_lock);\r\nlpfc_nlp_put(ndlp);\r\n}\r\n}\r\nmempool_free(mb, phba->mbox_mem_pool);\r\n}\r\nif (act_mbx_ndlp) {\r\nspin_lock(shost->host_lock);\r\nact_mbx_ndlp->nlp_flag &= ~NLP_IGNR_REG_CMPL;\r\nspin_unlock(shost->host_lock);\r\nlpfc_nlp_put(act_mbx_ndlp);\r\n}\r\n}\r\nuint32_t\r\nlpfc_drain_txq(struct lpfc_hba *phba)\r\n{\r\nLIST_HEAD(completions);\r\nstruct lpfc_sli_ring *pring = &phba->sli.ring[LPFC_ELS_RING];\r\nstruct lpfc_iocbq *piocbq = NULL;\r\nunsigned long iflags = 0;\r\nchar *fail_msg = NULL;\r\nstruct lpfc_sglq *sglq;\r\nunion lpfc_wqe wqe;\r\nuint32_t txq_cnt = 0;\r\nspin_lock_irqsave(&pring->ring_lock, iflags);\r\nlist_for_each_entry(piocbq, &pring->txq, list) {\r\ntxq_cnt++;\r\n}\r\nif (txq_cnt > pring->txq_max)\r\npring->txq_max = txq_cnt;\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\nwhile (!list_empty(&pring->txq)) {\r\nspin_lock_irqsave(&pring->ring_lock, iflags);\r\npiocbq = lpfc_sli_ringtx_get(phba, pring);\r\nif (!piocbq) {\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2823 txq empty and txq_cnt is %d\n ",\r\ntxq_cnt);\r\nbreak;\r\n}\r\nsglq = __lpfc_sli_get_sglq(phba, piocbq);\r\nif (!sglq) {\r\n__lpfc_sli_ringtx_put(phba, pring, piocbq);\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\nbreak;\r\n}\r\ntxq_cnt--;\r\npiocbq->sli4_lxritag = sglq->sli4_lxritag;\r\npiocbq->sli4_xritag = sglq->sli4_xritag;\r\nif (NO_XRI == lpfc_sli4_bpl2sgl(phba, piocbq, sglq))\r\nfail_msg = "to convert bpl to sgl";\r\nelse if (lpfc_sli4_iocb2wqe(phba, piocbq, &wqe))\r\nfail_msg = "to convert iocb to wqe";\r\nelse if (lpfc_sli4_wq_put(phba->sli4_hba.els_wq, &wqe))\r\nfail_msg = " - Wq is full";\r\nelse\r\nlpfc_sli_ringtxcmpl_put(phba, pring, piocbq);\r\nif (fail_msg) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2822 IOCB failed %s iotag 0x%x "\r\n"xri 0x%x\n",\r\nfail_msg,\r\npiocbq->iotag, piocbq->sli4_xritag);\r\nlist_add_tail(&piocbq->list, &completions);\r\n}\r\nspin_unlock_irqrestore(&pring->ring_lock, iflags);\r\n}\r\nlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_ABORTED);\r\nreturn txq_cnt;\r\n}
