int generic_ide_suspend(struct device *dev, pm_message_t mesg)\r\n{\r\nide_drive_t *drive = to_ide_device(dev);\r\nide_drive_t *pair = ide_get_pair_dev(drive);\r\nide_hwif_t *hwif = drive->hwif;\r\nstruct request *rq;\r\nstruct ide_pm_state rqpm;\r\nint ret;\r\nif (ide_port_acpi(hwif)) {\r\nif ((drive->dn & 1) == 0 || pair == NULL)\r\nide_acpi_get_timing(hwif);\r\n}\r\nmemset(&rqpm, 0, sizeof(rqpm));\r\nrq = blk_get_request(drive->queue, READ, __GFP_WAIT);\r\nrq->cmd_type = REQ_TYPE_ATA_PM_SUSPEND;\r\nrq->special = &rqpm;\r\nrqpm.pm_step = IDE_PM_START_SUSPEND;\r\nif (mesg.event == PM_EVENT_PRETHAW)\r\nmesg.event = PM_EVENT_FREEZE;\r\nrqpm.pm_state = mesg.event;\r\nret = blk_execute_rq(drive->queue, NULL, rq, 0);\r\nblk_put_request(rq);\r\nif (ret == 0 && ide_port_acpi(hwif)) {\r\nif ((drive->dn & 1) || pair == NULL)\r\nide_acpi_set_state(hwif, 0);\r\n}\r\nreturn ret;\r\n}\r\nstatic void ide_end_sync_rq(struct request *rq, int error)\r\n{\r\ncomplete(rq->end_io_data);\r\n}\r\nstatic int ide_pm_execute_rq(struct request *rq)\r\n{\r\nstruct request_queue *q = rq->q;\r\nDECLARE_COMPLETION_ONSTACK(wait);\r\nrq->end_io_data = &wait;\r\nrq->end_io = ide_end_sync_rq;\r\nspin_lock_irq(q->queue_lock);\r\nif (unlikely(blk_queue_dying(q))) {\r\nrq->cmd_flags |= REQ_QUIET;\r\nrq->errors = -ENXIO;\r\n__blk_end_request_all(rq, rq->errors);\r\nspin_unlock_irq(q->queue_lock);\r\nreturn -ENXIO;\r\n}\r\n__elv_add_request(q, rq, ELEVATOR_INSERT_FRONT);\r\n__blk_run_queue_uncond(q);\r\nspin_unlock_irq(q->queue_lock);\r\nwait_for_completion_io(&wait);\r\nreturn rq->errors ? -EIO : 0;\r\n}\r\nint generic_ide_resume(struct device *dev)\r\n{\r\nide_drive_t *drive = to_ide_device(dev);\r\nide_drive_t *pair = ide_get_pair_dev(drive);\r\nide_hwif_t *hwif = drive->hwif;\r\nstruct request *rq;\r\nstruct ide_pm_state rqpm;\r\nint err;\r\nif (ide_port_acpi(hwif)) {\r\nif ((drive->dn & 1) == 0 || pair == NULL) {\r\nide_acpi_set_state(hwif, 1);\r\nide_acpi_push_timing(hwif);\r\n}\r\nide_acpi_exec_tfs(drive);\r\n}\r\nmemset(&rqpm, 0, sizeof(rqpm));\r\nrq = blk_get_request(drive->queue, READ, __GFP_WAIT);\r\nrq->cmd_type = REQ_TYPE_ATA_PM_RESUME;\r\nrq->cmd_flags |= REQ_PREEMPT;\r\nrq->special = &rqpm;\r\nrqpm.pm_step = IDE_PM_START_RESUME;\r\nrqpm.pm_state = PM_EVENT_ON;\r\nerr = ide_pm_execute_rq(rq);\r\nblk_put_request(rq);\r\nif (err == 0 && dev->driver) {\r\nstruct ide_driver *drv = to_ide_driver(dev->driver);\r\nif (drv->resume)\r\ndrv->resume(drive);\r\n}\r\nreturn err;\r\n}\r\nvoid ide_complete_power_step(ide_drive_t *drive, struct request *rq)\r\n{\r\nstruct ide_pm_state *pm = rq->special;\r\n#ifdef DEBUG_PM\r\nprintk(KERN_INFO "%s: complete_power_step(step: %d)\n",\r\ndrive->name, pm->pm_step);\r\n#endif\r\nif (drive->media != ide_disk)\r\nreturn;\r\nswitch (pm->pm_step) {\r\ncase IDE_PM_FLUSH_CACHE:\r\nif (pm->pm_state == PM_EVENT_FREEZE)\r\npm->pm_step = IDE_PM_COMPLETED;\r\nelse\r\npm->pm_step = IDE_PM_STANDBY;\r\nbreak;\r\ncase IDE_PM_STANDBY:\r\npm->pm_step = IDE_PM_COMPLETED;\r\nbreak;\r\ncase IDE_PM_RESTORE_PIO:\r\npm->pm_step = IDE_PM_IDLE;\r\nbreak;\r\ncase IDE_PM_IDLE:\r\npm->pm_step = IDE_PM_RESTORE_DMA;\r\nbreak;\r\n}\r\n}\r\nide_startstop_t ide_start_power_step(ide_drive_t *drive, struct request *rq)\r\n{\r\nstruct ide_pm_state *pm = rq->special;\r\nstruct ide_cmd cmd = { };\r\nswitch (pm->pm_step) {\r\ncase IDE_PM_FLUSH_CACHE:\r\nif (drive->media != ide_disk)\r\nbreak;\r\nif (ata_id_flush_enabled(drive->id) == 0 ||\r\n(drive->dev_flags & IDE_DFLAG_WCACHE) == 0) {\r\nide_complete_power_step(drive, rq);\r\nreturn ide_stopped;\r\n}\r\nif (ata_id_flush_ext_enabled(drive->id))\r\ncmd.tf.command = ATA_CMD_FLUSH_EXT;\r\nelse\r\ncmd.tf.command = ATA_CMD_FLUSH;\r\ngoto out_do_tf;\r\ncase IDE_PM_STANDBY:\r\ncmd.tf.command = ATA_CMD_STANDBYNOW1;\r\ngoto out_do_tf;\r\ncase IDE_PM_RESTORE_PIO:\r\nide_set_max_pio(drive);\r\nif (drive->media != ide_disk)\r\npm->pm_step = IDE_PM_RESTORE_DMA;\r\nelse\r\nide_complete_power_step(drive, rq);\r\nreturn ide_stopped;\r\ncase IDE_PM_IDLE:\r\ncmd.tf.command = ATA_CMD_IDLEIMMEDIATE;\r\ngoto out_do_tf;\r\ncase IDE_PM_RESTORE_DMA:\r\nif (drive->hwif->dma_ops == NULL)\r\nbreak;\r\nide_set_dma(drive);\r\nbreak;\r\n}\r\npm->pm_step = IDE_PM_COMPLETED;\r\nreturn ide_stopped;\r\nout_do_tf:\r\ncmd.valid.out.tf = IDE_VALID_OUT_TF | IDE_VALID_DEVICE;\r\ncmd.valid.in.tf = IDE_VALID_IN_TF | IDE_VALID_DEVICE;\r\ncmd.protocol = ATA_PROT_NODATA;\r\nreturn do_rw_taskfile(drive, &cmd);\r\n}\r\nvoid ide_complete_pm_rq(ide_drive_t *drive, struct request *rq)\r\n{\r\nstruct request_queue *q = drive->queue;\r\nstruct ide_pm_state *pm = rq->special;\r\nunsigned long flags;\r\nide_complete_power_step(drive, rq);\r\nif (pm->pm_step != IDE_PM_COMPLETED)\r\nreturn;\r\n#ifdef DEBUG_PM\r\nprintk("%s: completing PM request, %s\n", drive->name,\r\n(rq->cmd_type == REQ_TYPE_ATA_PM_SUSPEND) ? "suspend" : "resume");\r\n#endif\r\nspin_lock_irqsave(q->queue_lock, flags);\r\nif (rq->cmd_type == REQ_TYPE_ATA_PM_SUSPEND)\r\nblk_stop_queue(q);\r\nelse\r\ndrive->dev_flags &= ~IDE_DFLAG_BLOCKED;\r\nspin_unlock_irqrestore(q->queue_lock, flags);\r\ndrive->hwif->rq = NULL;\r\nif (blk_end_request(rq, 0, 0))\r\nBUG();\r\n}\r\nvoid ide_check_pm_state(ide_drive_t *drive, struct request *rq)\r\n{\r\nstruct ide_pm_state *pm = rq->special;\r\nif (rq->cmd_type == REQ_TYPE_ATA_PM_SUSPEND &&\r\npm->pm_step == IDE_PM_START_SUSPEND)\r\ndrive->dev_flags |= IDE_DFLAG_BLOCKED;\r\nelse if (rq->cmd_type == REQ_TYPE_ATA_PM_RESUME &&\r\npm->pm_step == IDE_PM_START_RESUME) {\r\nide_hwif_t *hwif = drive->hwif;\r\nconst struct ide_tp_ops *tp_ops = hwif->tp_ops;\r\nstruct request_queue *q = drive->queue;\r\nunsigned long flags;\r\nint rc;\r\n#ifdef DEBUG_PM\r\nprintk("%s: Wakeup request inited, waiting for !BSY...\n", drive->name);\r\n#endif\r\nrc = ide_wait_not_busy(hwif, 35000);\r\nif (rc)\r\nprintk(KERN_WARNING "%s: bus not ready on wakeup\n", drive->name);\r\ntp_ops->dev_select(drive);\r\ntp_ops->write_devctl(hwif, ATA_DEVCTL_OBS);\r\nrc = ide_wait_not_busy(hwif, 100000);\r\nif (rc)\r\nprintk(KERN_WARNING "%s: drive not ready on wakeup\n", drive->name);\r\nspin_lock_irqsave(q->queue_lock, flags);\r\nblk_start_queue(q);\r\nspin_unlock_irqrestore(q->queue_lock, flags);\r\n}\r\n}
