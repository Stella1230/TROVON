static struct lov_sublock_env *lov_sublock_env_get(const struct lu_env *env,\r\nstruct cl_lock *parent,\r\nstruct lov_lock_sub *lls)\r\n{\r\nstruct lov_sublock_env *subenv;\r\nstruct lov_io *lio = lov_env_io(env);\r\nstruct cl_io *io = lio->lis_cl.cis_io;\r\nstruct lov_io_sub *sub;\r\nsubenv = &lov_env_session(env)->ls_subenv;\r\nif (!io || !cl_object_same(io->ci_obj, parent->cll_descr.cld_obj)) {\r\nsubenv->lse_env = env;\r\nsubenv->lse_io = io;\r\nsubenv->lse_sub = NULL;\r\n} else {\r\nsub = lov_sub_get(env, lio, lls->sub_stripe);\r\nif (!IS_ERR(sub)) {\r\nsubenv->lse_env = sub->sub_env;\r\nsubenv->lse_io = sub->sub_io;\r\nsubenv->lse_sub = sub;\r\n} else {\r\nsubenv = (void *)sub;\r\n}\r\n}\r\nreturn subenv;\r\n}\r\nstatic void lov_sublock_env_put(struct lov_sublock_env *subenv)\r\n{\r\nif (subenv && subenv->lse_sub)\r\nlov_sub_put(subenv->lse_sub);\r\n}\r\nstatic void lov_sublock_adopt(const struct lu_env *env, struct lov_lock *lck,\r\nstruct cl_lock *sublock, int idx,\r\nstruct lov_lock_link *link)\r\n{\r\nstruct lovsub_lock *lsl;\r\nstruct cl_lock *parent = lck->lls_cl.cls_lock;\r\nint rc;\r\nLASSERT(cl_lock_is_mutexed(parent));\r\nLASSERT(cl_lock_is_mutexed(sublock));\r\nlsl = cl2sub_lock(sublock);\r\nLASSERT(lov_lock_link_find(env, lck, lsl) == NULL);\r\nLASSERT(idx < lck->lls_nr);\r\nlck->lls_sub[idx].sub_lock = lsl;\r\nlck->lls_nr_filled++;\r\nLASSERT(lck->lls_nr_filled <= lck->lls_nr);\r\nlist_add_tail(&link->lll_list, &lsl->lss_parents);\r\nlink->lll_idx = idx;\r\nlink->lll_super = lck;\r\ncl_lock_get(parent);\r\nlu_ref_add(&parent->cll_reference, "lov-child", sublock);\r\nlck->lls_sub[idx].sub_flags |= LSF_HELD;\r\ncl_lock_user_add(env, sublock);\r\nrc = lov_sublock_modify(env, lck, lsl, &sublock->cll_descr, idx);\r\nLASSERT(rc == 0);\r\n}\r\nstatic struct cl_lock *lov_sublock_alloc(const struct lu_env *env,\r\nconst struct cl_io *io,\r\nstruct lov_lock *lck,\r\nint idx, struct lov_lock_link **out)\r\n{\r\nstruct cl_lock *sublock;\r\nstruct cl_lock *parent;\r\nstruct lov_lock_link *link;\r\nLASSERT(idx < lck->lls_nr);\r\nOBD_SLAB_ALLOC_PTR_GFP(link, lov_lock_link_kmem, GFP_NOFS);\r\nif (link != NULL) {\r\nstruct lov_sublock_env *subenv;\r\nstruct lov_lock_sub *lls;\r\nstruct cl_lock_descr *descr;\r\nparent = lck->lls_cl.cls_lock;\r\nlls = &lck->lls_sub[idx];\r\ndescr = &lls->sub_got;\r\nsubenv = lov_sublock_env_get(env, parent, lls);\r\nif (!IS_ERR(subenv)) {\r\nsublock = cl_lock_hold(subenv->lse_env, subenv->lse_io,\r\ndescr, "lov-parent", parent);\r\nlov_sublock_env_put(subenv);\r\n} else {\r\nsublock = (void *)subenv;\r\n}\r\nif (!IS_ERR(sublock))\r\n*out = link;\r\nelse\r\nOBD_SLAB_FREE_PTR(link, lov_lock_link_kmem);\r\n} else\r\nsublock = ERR_PTR(-ENOMEM);\r\nreturn sublock;\r\n}\r\nstatic void lov_sublock_unlock(const struct lu_env *env,\r\nstruct lovsub_lock *lsl,\r\nstruct cl_lock_closure *closure,\r\nstruct lov_sublock_env *subenv)\r\n{\r\nlov_sublock_env_put(subenv);\r\nlsl->lss_active = NULL;\r\ncl_lock_disclosure(env, closure);\r\n}\r\nstatic int lov_sublock_lock(const struct lu_env *env,\r\nstruct lov_lock *lck,\r\nstruct lov_lock_sub *lls,\r\nstruct cl_lock_closure *closure,\r\nstruct lov_sublock_env **lsep)\r\n{\r\nstruct lovsub_lock *sublock;\r\nstruct cl_lock *child;\r\nint result = 0;\r\nLASSERT(list_empty(&closure->clc_list));\r\nsublock = lls->sub_lock;\r\nchild = sublock->lss_cl.cls_lock;\r\nresult = cl_lock_closure_build(env, child, closure);\r\nif (result == 0) {\r\nstruct cl_lock *parent = closure->clc_origin;\r\nLASSERT(cl_lock_is_mutexed(child));\r\nsublock->lss_active = parent;\r\nif (unlikely((child->cll_state == CLS_FREEING) ||\r\n(child->cll_flags & CLF_CANCELLED))) {\r\nstruct lov_lock_link *link;\r\nLASSERT(!(lls->sub_flags & LSF_HELD));\r\nlink = lov_lock_link_find(env, lck, sublock);\r\nLASSERT(link != NULL);\r\nlov_lock_unlink(env, link, sublock);\r\nlov_sublock_unlock(env, sublock, closure, NULL);\r\nlck->lls_cancel_race = 1;\r\nresult = CLO_REPEAT;\r\n} else if (lsep) {\r\nstruct lov_sublock_env *subenv;\r\nsubenv = lov_sublock_env_get(env, parent, lls);\r\nif (IS_ERR(subenv)) {\r\nlov_sublock_unlock(env, sublock,\r\nclosure, NULL);\r\nresult = PTR_ERR(subenv);\r\n} else {\r\n*lsep = subenv;\r\n}\r\n}\r\n}\r\nreturn result;\r\n}\r\nstatic int lov_subresult(int result, int rc)\r\n{\r\nint result_rank;\r\nint rc_rank;\r\nLASSERTF(result <= 0 || result == CLO_REPEAT || result == CLO_WAIT,\r\n"result = %d", result);\r\nLASSERTF(rc <= 0 || rc == CLO_REPEAT || rc == CLO_WAIT,\r\n"rc = %d\n", rc);\r\nCLASSERT(CLO_WAIT < CLO_REPEAT);\r\nresult_rank = result < 0 ? 1 + CLO_REPEAT : result;\r\nrc_rank = rc < 0 ? 1 + CLO_REPEAT : rc;\r\nif (result_rank < rc_rank)\r\nresult = rc;\r\nreturn result;\r\n}\r\nstatic int lov_lock_sub_init(const struct lu_env *env,\r\nstruct lov_lock *lck, const struct cl_io *io)\r\n{\r\nint result = 0;\r\nint i;\r\nint nr;\r\nu64 start;\r\nu64 end;\r\nu64 file_start;\r\nu64 file_end;\r\nstruct lov_object *loo = cl2lov(lck->lls_cl.cls_obj);\r\nstruct lov_layout_raid0 *r0 = lov_r0(loo);\r\nstruct cl_lock *parent = lck->lls_cl.cls_lock;\r\nlck->lls_orig = parent->cll_descr;\r\nfile_start = cl_offset(lov2cl(loo), parent->cll_descr.cld_start);\r\nfile_end = cl_offset(lov2cl(loo), parent->cll_descr.cld_end + 1) - 1;\r\nfor (i = 0, nr = 0; i < r0->lo_nr; i++) {\r\nif (likely(r0->lo_sub[i] != NULL) &&\r\nlov_stripe_intersects(loo->lo_lsm, i,\r\nfile_start, file_end, &start, &end))\r\nnr++;\r\n}\r\nLASSERT(nr > 0);\r\nlck->lls_sub = libcfs_kvzalloc(nr * sizeof(lck->lls_sub[0]), GFP_NOFS);\r\nif (lck->lls_sub == NULL)\r\nreturn -ENOMEM;\r\nlck->lls_nr = nr;\r\nfor (i = 0, nr = 0; i < r0->lo_nr; ++i) {\r\nif (likely(r0->lo_sub[i] != NULL) &&\r\nlov_stripe_intersects(loo->lo_lsm, i,\r\nfile_start, file_end, &start, &end)) {\r\nstruct cl_lock_descr *descr;\r\ndescr = &lck->lls_sub[nr].sub_descr;\r\nLASSERT(descr->cld_obj == NULL);\r\ndescr->cld_obj = lovsub2cl(r0->lo_sub[i]);\r\ndescr->cld_start = cl_index(descr->cld_obj, start);\r\ndescr->cld_end = cl_index(descr->cld_obj, end);\r\ndescr->cld_mode = parent->cll_descr.cld_mode;\r\ndescr->cld_gid = parent->cll_descr.cld_gid;\r\ndescr->cld_enq_flags = parent->cll_descr.cld_enq_flags;\r\nlck->lls_sub[nr].sub_got = *descr;\r\nlck->lls_sub[nr].sub_stripe = i;\r\nnr++;\r\n}\r\n}\r\nLASSERT(nr == lck->lls_nr);\r\nreturn result;\r\n}\r\nstatic int lov_sublock_release(const struct lu_env *env, struct lov_lock *lck,\r\nint i, int deluser, int rc)\r\n{\r\nstruct cl_lock *parent = lck->lls_cl.cls_lock;\r\nLASSERT(cl_lock_is_mutexed(parent));\r\nif (lck->lls_sub[i].sub_flags & LSF_HELD) {\r\nstruct cl_lock *sublock;\r\nint dying;\r\nLASSERT(lck->lls_sub[i].sub_lock != NULL);\r\nsublock = lck->lls_sub[i].sub_lock->lss_cl.cls_lock;\r\nLASSERT(cl_lock_is_mutexed(sublock));\r\nlck->lls_sub[i].sub_flags &= ~LSF_HELD;\r\nif (deluser)\r\ncl_lock_user_del(env, sublock);\r\ndying = (sublock->cll_descr.cld_mode == CLM_PHANTOM ||\r\nsublock->cll_descr.cld_mode == CLM_GROUP ||\r\n(sublock->cll_flags & (CLF_CANCELPEND|CLF_DOOMED))) &&\r\nsublock->cll_holds == 1;\r\nif (dying)\r\ncl_lock_mutex_put(env, parent);\r\ncl_lock_unhold(env, sublock, "lov-parent", parent);\r\nif (dying) {\r\ncl_lock_mutex_get(env, parent);\r\nrc = lov_subresult(rc, CLO_REPEAT);\r\n}\r\n}\r\nreturn rc;\r\n}\r\nstatic void lov_sublock_hold(const struct lu_env *env, struct lov_lock *lck,\r\nint i)\r\n{\r\nstruct cl_lock *parent = lck->lls_cl.cls_lock;\r\nLASSERT(cl_lock_is_mutexed(parent));\r\nif (!(lck->lls_sub[i].sub_flags & LSF_HELD)) {\r\nstruct cl_lock *sublock;\r\nLASSERT(lck->lls_sub[i].sub_lock != NULL);\r\nsublock = lck->lls_sub[i].sub_lock->lss_cl.cls_lock;\r\nLASSERT(cl_lock_is_mutexed(sublock));\r\nLASSERT(sublock->cll_state != CLS_FREEING);\r\nlck->lls_sub[i].sub_flags |= LSF_HELD;\r\ncl_lock_get_trust(sublock);\r\ncl_lock_hold_add(env, sublock, "lov-parent", parent);\r\ncl_lock_user_add(env, sublock);\r\ncl_lock_put(env, sublock);\r\n}\r\n}\r\nstatic void lov_lock_fini(const struct lu_env *env,\r\nstruct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck;\r\nint i;\r\nlck = cl2lov_lock(slice);\r\nLASSERT(lck->lls_nr_filled == 0);\r\nif (lck->lls_sub != NULL) {\r\nfor (i = 0; i < lck->lls_nr; ++i)\r\nLASSERT(lck->lls_sub[i].sub_lock == NULL);\r\nkvfree(lck->lls_sub);\r\n}\r\nOBD_SLAB_FREE_PTR(lck, lov_lock_kmem);\r\n}\r\nstatic int lov_lock_enqueue_wait(const struct lu_env *env,\r\nstruct lov_lock *lck,\r\nstruct cl_lock *sublock)\r\n{\r\nstruct cl_lock *lock = lck->lls_cl.cls_lock;\r\nint result;\r\nLASSERT(cl_lock_is_mutexed(lock));\r\ncl_lock_mutex_put(env, lock);\r\nresult = cl_lock_enqueue_wait(env, sublock, 0);\r\ncl_lock_mutex_get(env, lock);\r\nreturn result ?: CLO_REPEAT;\r\n}\r\nstatic int lov_lock_enqueue_one(const struct lu_env *env, struct lov_lock *lck,\r\nstruct cl_lock *sublock,\r\nstruct cl_io *io, __u32 enqflags, int last)\r\n{\r\nint result;\r\nresult = cl_enqueue_try(env, sublock, io, enqflags);\r\nif ((sublock->cll_state == CLS_ENQUEUED) && !(enqflags & CEF_AGL)) {\r\nresult = cl_wait_try(env, sublock);\r\nif (result == CLO_REENQUEUED)\r\nresult = CLO_WAIT;\r\n}\r\nif ((result == CLO_WAIT) && (sublock->cll_state <= CLS_HELD) &&\r\n(enqflags & CEF_ASYNC) && (!last || (enqflags & CEF_AGL)))\r\nresult = 0;\r\nreturn result;\r\n}\r\nstatic int lov_sublock_fill(const struct lu_env *env, struct cl_lock *parent,\r\nstruct cl_io *io, struct lov_lock *lck, int idx)\r\n{\r\nstruct lov_lock_link *link = NULL;\r\nstruct cl_lock *sublock;\r\nint result;\r\nLASSERT(parent->cll_depth == 1);\r\ncl_lock_mutex_put(env, parent);\r\nsublock = lov_sublock_alloc(env, io, lck, idx, &link);\r\nif (!IS_ERR(sublock))\r\ncl_lock_mutex_get(env, sublock);\r\ncl_lock_mutex_get(env, parent);\r\nif (!IS_ERR(sublock)) {\r\ncl_lock_get_trust(sublock);\r\nif (parent->cll_state == CLS_QUEUING &&\r\nlck->lls_sub[idx].sub_lock == NULL) {\r\nlov_sublock_adopt(env, lck, sublock, idx, link);\r\n} else {\r\nOBD_SLAB_FREE_PTR(link, lov_lock_link_kmem);\r\ncl_lock_mutex_put(env, parent);\r\ncl_lock_unhold(env, sublock, "lov-parent", parent);\r\ncl_lock_mutex_get(env, parent);\r\n}\r\ncl_lock_mutex_put(env, sublock);\r\ncl_lock_put(env, sublock);\r\nresult = CLO_REPEAT;\r\n} else\r\nresult = PTR_ERR(sublock);\r\nreturn result;\r\n}\r\nstatic int lov_lock_enqueue(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nstruct cl_io *io, __u32 enqflags)\r\n{\r\nstruct cl_lock *lock = slice->cls_lock;\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nstruct cl_lock_closure *closure = lov_closure_get(env, lock);\r\nint i;\r\nint result;\r\nenum cl_lock_state minstate;\r\nfor (result = 0, minstate = CLS_FREEING, i = 0; i < lck->lls_nr; ++i) {\r\nint rc;\r\nstruct lovsub_lock *sub;\r\nstruct lov_lock_sub *lls;\r\nstruct cl_lock *sublock;\r\nstruct lov_sublock_env *subenv;\r\nif (lock->cll_state != CLS_QUEUING) {\r\nLASSERT(i > 0 && result != 0);\r\nbreak;\r\n}\r\nlls = &lck->lls_sub[i];\r\nsub = lls->sub_lock;\r\nif (sub == NULL) {\r\nresult = lov_sublock_fill(env, lock, io, lck, i);\r\nbreak;\r\n}\r\nsublock = sub->lss_cl.cls_lock;\r\nrc = lov_sublock_lock(env, lck, lls, closure, &subenv);\r\nif (rc == 0) {\r\nlov_sublock_hold(env, lck, i);\r\nrc = lov_lock_enqueue_one(subenv->lse_env, lck, sublock,\r\nsubenv->lse_io, enqflags,\r\ni == lck->lls_nr - 1);\r\nminstate = min(minstate, sublock->cll_state);\r\nif (rc == CLO_WAIT) {\r\nswitch (sublock->cll_state) {\r\ncase CLS_QUEUING:\r\ncl_lock_mutex_get(env, sublock);\r\nlov_sublock_unlock(env, sub, closure,\r\nsubenv);\r\nrc = lov_lock_enqueue_wait(env, lck,\r\nsublock);\r\nbreak;\r\ncase CLS_CACHED:\r\ncl_lock_get(sublock);\r\ncl_lock_mutex_get(env, sublock);\r\nlov_sublock_unlock(env, sub, closure,\r\nsubenv);\r\nrc = lov_sublock_release(env, lck, i,\r\n1, rc);\r\ncl_lock_mutex_put(env, sublock);\r\ncl_lock_put(env, sublock);\r\nbreak;\r\ndefault:\r\nlov_sublock_unlock(env, sub, closure,\r\nsubenv);\r\nbreak;\r\n}\r\n} else {\r\nLASSERT(sublock->cll_conflict == NULL);\r\nlov_sublock_unlock(env, sub, closure, subenv);\r\n}\r\n}\r\nresult = lov_subresult(result, rc);\r\nif (result != 0)\r\nbreak;\r\n}\r\ncl_lock_closure_fini(closure);\r\nreturn result ?: minstate >= CLS_ENQUEUED ? 0 : CLO_WAIT;\r\n}\r\nstatic int lov_lock_unuse(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nstruct cl_lock_closure *closure = lov_closure_get(env, slice->cls_lock);\r\nint i;\r\nint result;\r\nfor (result = 0, i = 0; i < lck->lls_nr; ++i) {\r\nint rc;\r\nstruct lovsub_lock *sub;\r\nstruct cl_lock *sublock;\r\nstruct lov_lock_sub *lls;\r\nstruct lov_sublock_env *subenv;\r\nLASSERT(slice->cls_lock->cll_state == CLS_INTRANSIT);\r\nlls = &lck->lls_sub[i];\r\nsub = lls->sub_lock;\r\nif (sub == NULL)\r\ncontinue;\r\nsublock = sub->lss_cl.cls_lock;\r\nrc = lov_sublock_lock(env, lck, lls, closure, &subenv);\r\nif (rc == 0) {\r\nif (lls->sub_flags & LSF_HELD) {\r\nLASSERT(sublock->cll_state == CLS_HELD ||\r\nsublock->cll_state == CLS_ENQUEUED);\r\nrc = cl_unuse_try(subenv->lse_env, sublock);\r\nrc = lov_sublock_release(env, lck, i, 0, rc);\r\n}\r\nlov_sublock_unlock(env, sub, closure, subenv);\r\n}\r\nresult = lov_subresult(result, rc);\r\n}\r\nif (result == 0 && lck->lls_cancel_race) {\r\nlck->lls_cancel_race = 0;\r\nresult = -ESTALE;\r\n}\r\ncl_lock_closure_fini(closure);\r\nreturn result;\r\n}\r\nstatic void lov_lock_cancel(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nstruct cl_lock_closure *closure = lov_closure_get(env, slice->cls_lock);\r\nint i;\r\nint result;\r\nfor (result = 0, i = 0; i < lck->lls_nr; ++i) {\r\nint rc;\r\nstruct lovsub_lock *sub;\r\nstruct cl_lock *sublock;\r\nstruct lov_lock_sub *lls;\r\nstruct lov_sublock_env *subenv;\r\nlls = &lck->lls_sub[i];\r\nsub = lls->sub_lock;\r\nif (sub == NULL)\r\ncontinue;\r\nsublock = sub->lss_cl.cls_lock;\r\nrc = lov_sublock_lock(env, lck, lls, closure, &subenv);\r\nif (rc == 0) {\r\nif (!(lls->sub_flags & LSF_HELD)) {\r\nlov_sublock_unlock(env, sub, closure, subenv);\r\ncontinue;\r\n}\r\nswitch (sublock->cll_state) {\r\ncase CLS_HELD:\r\nrc = cl_unuse_try(subenv->lse_env, sublock);\r\nlov_sublock_release(env, lck, i, 0, 0);\r\nbreak;\r\ndefault:\r\nlov_sublock_release(env, lck, i, 1, 0);\r\nbreak;\r\n}\r\nlov_sublock_unlock(env, sub, closure, subenv);\r\n}\r\nif (rc == CLO_REPEAT) {\r\n--i;\r\ncontinue;\r\n}\r\nresult = lov_subresult(result, rc);\r\n}\r\nif (result)\r\nCL_LOCK_DEBUG(D_ERROR, env, slice->cls_lock,\r\n"lov_lock_cancel fails with %d.\n", result);\r\ncl_lock_closure_fini(closure);\r\n}\r\nstatic int lov_lock_wait(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nstruct cl_lock_closure *closure = lov_closure_get(env, slice->cls_lock);\r\nenum cl_lock_state minstate;\r\nint reenqueued;\r\nint result;\r\nint i;\r\nagain:\r\nfor (result = 0, minstate = CLS_FREEING, i = 0, reenqueued = 0;\r\ni < lck->lls_nr; ++i) {\r\nint rc;\r\nstruct lovsub_lock *sub;\r\nstruct cl_lock *sublock;\r\nstruct lov_lock_sub *lls;\r\nstruct lov_sublock_env *subenv;\r\nlls = &lck->lls_sub[i];\r\nsub = lls->sub_lock;\r\nLASSERT(sub != NULL);\r\nsublock = sub->lss_cl.cls_lock;\r\nrc = lov_sublock_lock(env, lck, lls, closure, &subenv);\r\nif (rc == 0) {\r\nLASSERT(sublock->cll_state >= CLS_ENQUEUED);\r\nif (sublock->cll_state < CLS_HELD)\r\nrc = cl_wait_try(env, sublock);\r\nminstate = min(minstate, sublock->cll_state);\r\nlov_sublock_unlock(env, sub, closure, subenv);\r\n}\r\nif (rc == CLO_REENQUEUED) {\r\nreenqueued++;\r\nrc = 0;\r\n}\r\nresult = lov_subresult(result, rc);\r\nif (result != 0)\r\nbreak;\r\n}\r\nif (result == 0 && reenqueued != 0)\r\ngoto again;\r\ncl_lock_closure_fini(closure);\r\nreturn result ?: minstate >= CLS_HELD ? 0 : CLO_WAIT;\r\n}\r\nstatic int lov_lock_use(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nstruct cl_lock_closure *closure = lov_closure_get(env, slice->cls_lock);\r\nint result;\r\nint i;\r\nLASSERT(slice->cls_lock->cll_state == CLS_INTRANSIT);\r\nfor (result = 0, i = 0; i < lck->lls_nr; ++i) {\r\nint rc;\r\nstruct lovsub_lock *sub;\r\nstruct cl_lock *sublock;\r\nstruct lov_lock_sub *lls;\r\nstruct lov_sublock_env *subenv;\r\nLASSERT(slice->cls_lock->cll_state == CLS_INTRANSIT);\r\nlls = &lck->lls_sub[i];\r\nsub = lls->sub_lock;\r\nif (sub == NULL) {\r\nresult = -ESTALE;\r\nbreak;\r\n}\r\nsublock = sub->lss_cl.cls_lock;\r\nrc = lov_sublock_lock(env, lck, lls, closure, &subenv);\r\nif (rc == 0) {\r\nLASSERT(sublock->cll_state != CLS_FREEING);\r\nlov_sublock_hold(env, lck, i);\r\nif (sublock->cll_state == CLS_CACHED) {\r\nrc = cl_use_try(subenv->lse_env, sublock, 0);\r\nif (rc != 0)\r\nrc = lov_sublock_release(env, lck,\r\ni, 1, rc);\r\n} else if (sublock->cll_state == CLS_NEW) {\r\nresult = -ESTALE;\r\nlov_sublock_release(env, lck, i, 1, result);\r\n}\r\nlov_sublock_unlock(env, sub, closure, subenv);\r\n}\r\nresult = lov_subresult(result, rc);\r\nif (result != 0)\r\nbreak;\r\n}\r\nif (lck->lls_cancel_race) {\r\nlck->lls_cancel_race = 0;\r\nLASSERT(result != 0);\r\nresult = -ESTALE;\r\n}\r\ncl_lock_closure_fini(closure);\r\nreturn result;\r\n}\r\nstatic int lov_lock_stripe_is_matching(const struct lu_env *env,\r\nstruct lov_object *lov, int stripe,\r\nconst struct cl_lock_descr *child,\r\nconst struct cl_lock_descr *descr)\r\n{\r\nstruct lov_stripe_md *lsm = lov->lo_lsm;\r\nu64 start;\r\nu64 end;\r\nint result;\r\nif (lov_r0(lov)->lo_nr == 1)\r\nreturn cl_lock_ext_match(child, descr);\r\nstart = cl_offset(&lov->lo_cl, descr->cld_start);\r\nend = cl_offset(&lov->lo_cl, descr->cld_end + 1) - 1;\r\nresult = 0;\r\nif (end - start <= lsm->lsm_stripe_size) {\r\nint idx;\r\nidx = lov_stripe_number(lsm, start);\r\nif (idx == stripe ||\r\nunlikely(lov_r0(lov)->lo_sub[idx] == NULL)) {\r\nidx = lov_stripe_number(lsm, end);\r\nif (idx == stripe ||\r\nunlikely(lov_r0(lov)->lo_sub[idx] == NULL))\r\nresult = 1;\r\n}\r\n}\r\nif (result != 0) {\r\nstruct cl_lock_descr *subd = &lov_env_info(env)->lti_ldescr;\r\nu64 sub_start;\r\nu64 sub_end;\r\nsubd->cld_obj = NULL;\r\nsubd->cld_mode = descr->cld_mode;\r\nsubd->cld_gid = descr->cld_gid;\r\nresult = lov_stripe_intersects(lsm, stripe, start, end,\r\n&sub_start, &sub_end);\r\nLASSERT(result);\r\nsubd->cld_start = cl_index(child->cld_obj, sub_start);\r\nsubd->cld_end = cl_index(child->cld_obj, sub_end);\r\nresult = cl_lock_ext_match(child, subd);\r\n}\r\nreturn result;\r\n}\r\nstatic int lov_lock_fits_into(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nconst struct cl_lock_descr *need,\r\nconst struct cl_io *io)\r\n{\r\nstruct lov_lock *lov = cl2lov_lock(slice);\r\nstruct lov_object *obj = cl2lov(slice->cls_obj);\r\nint result;\r\nLASSERT(cl_object_same(need->cld_obj, slice->cls_obj));\r\nLASSERT(lov->lls_nr > 0);\r\nif (need->cld_enq_flags != lov->lls_orig.cld_enq_flags)\r\nreturn 0;\r\nif (need->cld_mode == CLM_GROUP)\r\nresult = cl_lock_ext_match(&lov->lls_orig, need);\r\nelse if (lov->lls_nr == 1) {\r\nstruct cl_lock_descr *got = &lov->lls_sub[0].sub_got;\r\nresult = lov_lock_stripe_is_matching(env,\r\ncl2lov(slice->cls_obj),\r\nlov->lls_sub[0].sub_stripe,\r\ngot, need);\r\n} else if (io->ci_type != CIT_SETATTR && io->ci_type != CIT_MISC &&\r\n!cl_io_is_append(io) && need->cld_mode != CLM_PHANTOM)\r\nresult = 0;\r\nelse\r\nresult = cl_lock_ext_match(&lov->lls_orig, need);\r\nCDEBUG(D_DLMTRACE, DDESCR"/"DDESCR" %d %d/%d: %d\n",\r\nPDESCR(&lov->lls_orig), PDESCR(&lov->lls_sub[0].sub_got),\r\nlov->lls_sub[0].sub_stripe, lov->lls_nr, lov_r0(obj)->lo_nr,\r\nresult);\r\nreturn result;\r\n}\r\nvoid lov_lock_unlink(const struct lu_env *env,\r\nstruct lov_lock_link *link, struct lovsub_lock *sub)\r\n{\r\nstruct lov_lock *lck = link->lll_super;\r\nstruct cl_lock *parent = lck->lls_cl.cls_lock;\r\nLASSERT(cl_lock_is_mutexed(parent));\r\nLASSERT(cl_lock_is_mutexed(sub->lss_cl.cls_lock));\r\nlist_del_init(&link->lll_list);\r\nLASSERT(lck->lls_sub[link->lll_idx].sub_lock == sub);\r\nlck->lls_sub[link->lll_idx].sub_lock = NULL;\r\nLASSERT(lck->lls_nr_filled > 0);\r\nlck->lls_nr_filled--;\r\nlu_ref_del(&parent->cll_reference, "lov-child", sub->lss_cl.cls_lock);\r\ncl_lock_put(env, parent);\r\nOBD_SLAB_FREE_PTR(link, lov_lock_link_kmem);\r\n}\r\nstruct lov_lock_link *lov_lock_link_find(const struct lu_env *env,\r\nstruct lov_lock *lck,\r\nstruct lovsub_lock *sub)\r\n{\r\nstruct lov_lock_link *scan;\r\nLASSERT(cl_lock_is_mutexed(sub->lss_cl.cls_lock));\r\nlist_for_each_entry(scan, &sub->lss_parents, lll_list) {\r\nif (scan->lll_super == lck)\r\nreturn scan;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void lov_lock_delete(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nstruct cl_lock_closure *closure = lov_closure_get(env, slice->cls_lock);\r\nstruct lov_lock_link *link;\r\nint rc;\r\nint i;\r\nLASSERT(slice->cls_lock->cll_state == CLS_FREEING);\r\nfor (i = 0; i < lck->lls_nr; ++i) {\r\nstruct lov_lock_sub *lls = &lck->lls_sub[i];\r\nstruct lovsub_lock *lsl = lls->sub_lock;\r\nif (lsl == NULL)\r\ncontinue;\r\nrc = lov_sublock_lock(env, lck, lls, closure, NULL);\r\nif (rc == CLO_REPEAT) {\r\n--i;\r\ncontinue;\r\n}\r\nLASSERT(rc == 0);\r\nLASSERT(lsl->lss_cl.cls_lock->cll_state < CLS_FREEING);\r\nif (lls->sub_flags & LSF_HELD)\r\nlov_sublock_release(env, lck, i, 1, 0);\r\nlink = lov_lock_link_find(env, lck, lsl);\r\nLASSERT(link != NULL);\r\nlov_lock_unlink(env, link, lsl);\r\nLASSERT(lck->lls_sub[i].sub_lock == NULL);\r\nlov_sublock_unlock(env, lsl, closure, NULL);\r\n}\r\ncl_lock_closure_fini(closure);\r\n}\r\nstatic int lov_lock_print(const struct lu_env *env, void *cookie,\r\nlu_printer_t p, const struct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nint i;\r\n(*p)(env, cookie, "%d\n", lck->lls_nr);\r\nfor (i = 0; i < lck->lls_nr; ++i) {\r\nstruct lov_lock_sub *sub;\r\nsub = &lck->lls_sub[i];\r\n(*p)(env, cookie, " %d %x: ", i, sub->sub_flags);\r\nif (sub->sub_lock != NULL)\r\ncl_lock_print(env, cookie, p,\r\nsub->sub_lock->lss_cl.cls_lock);\r\nelse\r\n(*p)(env, cookie, "---\n");\r\n}\r\nreturn 0;\r\n}\r\nint lov_lock_init_raid0(const struct lu_env *env, struct cl_object *obj,\r\nstruct cl_lock *lock, const struct cl_io *io)\r\n{\r\nstruct lov_lock *lck;\r\nint result;\r\nOBD_SLAB_ALLOC_PTR_GFP(lck, lov_lock_kmem, GFP_NOFS);\r\nif (lck != NULL) {\r\ncl_lock_slice_add(lock, &lck->lls_cl, obj, &lov_lock_ops);\r\nresult = lov_lock_sub_init(env, lck, io);\r\n} else\r\nresult = -ENOMEM;\r\nreturn result;\r\n}\r\nstatic void lov_empty_lock_fini(const struct lu_env *env,\r\nstruct cl_lock_slice *slice)\r\n{\r\nstruct lov_lock *lck = cl2lov_lock(slice);\r\nOBD_SLAB_FREE_PTR(lck, lov_lock_kmem);\r\n}\r\nstatic int lov_empty_lock_print(const struct lu_env *env, void *cookie,\r\nlu_printer_t p, const struct cl_lock_slice *slice)\r\n{\r\n(*p)(env, cookie, "empty\n");\r\nreturn 0;\r\n}\r\nint lov_lock_init_empty(const struct lu_env *env, struct cl_object *obj,\r\nstruct cl_lock *lock, const struct cl_io *io)\r\n{\r\nstruct lov_lock *lck;\r\nint result = -ENOMEM;\r\nOBD_SLAB_ALLOC_PTR_GFP(lck, lov_lock_kmem, GFP_NOFS);\r\nif (lck != NULL) {\r\ncl_lock_slice_add(lock, &lck->lls_cl, obj, &lov_empty_lock_ops);\r\nlck->lls_orig = lock->cll_descr;\r\nresult = 0;\r\n}\r\nreturn result;\r\n}\r\nstatic struct cl_lock_closure *lov_closure_get(const struct lu_env *env,\r\nstruct cl_lock *parent)\r\n{\r\nstruct cl_lock_closure *closure;\r\nclosure = &lov_env_info(env)->lti_closure;\r\nLASSERT(list_empty(&closure->clc_list));\r\ncl_lock_closure_init(env, closure, parent, 1);\r\nreturn closure;\r\n}
