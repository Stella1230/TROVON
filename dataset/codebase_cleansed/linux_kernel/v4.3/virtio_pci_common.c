void vp_synchronize_vectors(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nint i;\r\nif (vp_dev->intx_enabled)\r\nsynchronize_irq(vp_dev->pci_dev->irq);\r\nfor (i = 0; i < vp_dev->msix_vectors; ++i)\r\nsynchronize_irq(vp_dev->msix_entries[i].vector);\r\n}\r\nbool vp_notify(struct virtqueue *vq)\r\n{\r\niowrite16(vq->index, (void __iomem *)vq->priv);\r\nreturn true;\r\n}\r\nstatic irqreturn_t vp_config_changed(int irq, void *opaque)\r\n{\r\nstruct virtio_pci_device *vp_dev = opaque;\r\nvirtio_config_changed(&vp_dev->vdev);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t vp_vring_interrupt(int irq, void *opaque)\r\n{\r\nstruct virtio_pci_device *vp_dev = opaque;\r\nstruct virtio_pci_vq_info *info;\r\nirqreturn_t ret = IRQ_NONE;\r\nunsigned long flags;\r\nspin_lock_irqsave(&vp_dev->lock, flags);\r\nlist_for_each_entry(info, &vp_dev->virtqueues, node) {\r\nif (vring_interrupt(irq, info->vq) == IRQ_HANDLED)\r\nret = IRQ_HANDLED;\r\n}\r\nspin_unlock_irqrestore(&vp_dev->lock, flags);\r\nreturn ret;\r\n}\r\nstatic irqreturn_t vp_interrupt(int irq, void *opaque)\r\n{\r\nstruct virtio_pci_device *vp_dev = opaque;\r\nu8 isr;\r\nisr = ioread8(vp_dev->isr);\r\nif (!isr)\r\nreturn IRQ_NONE;\r\nif (isr & VIRTIO_PCI_ISR_CONFIG)\r\nvp_config_changed(irq, opaque);\r\nreturn vp_vring_interrupt(irq, opaque);\r\n}\r\nstatic void vp_free_vectors(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nint i;\r\nif (vp_dev->intx_enabled) {\r\nfree_irq(vp_dev->pci_dev->irq, vp_dev);\r\nvp_dev->intx_enabled = 0;\r\n}\r\nfor (i = 0; i < vp_dev->msix_used_vectors; ++i)\r\nfree_irq(vp_dev->msix_entries[i].vector, vp_dev);\r\nfor (i = 0; i < vp_dev->msix_vectors; i++)\r\nif (vp_dev->msix_affinity_masks[i])\r\nfree_cpumask_var(vp_dev->msix_affinity_masks[i]);\r\nif (vp_dev->msix_enabled) {\r\nvp_dev->config_vector(vp_dev, VIRTIO_MSI_NO_VECTOR);\r\npci_disable_msix(vp_dev->pci_dev);\r\nvp_dev->msix_enabled = 0;\r\n}\r\nvp_dev->msix_vectors = 0;\r\nvp_dev->msix_used_vectors = 0;\r\nkfree(vp_dev->msix_names);\r\nvp_dev->msix_names = NULL;\r\nkfree(vp_dev->msix_entries);\r\nvp_dev->msix_entries = NULL;\r\nkfree(vp_dev->msix_affinity_masks);\r\nvp_dev->msix_affinity_masks = NULL;\r\n}\r\nstatic int vp_request_msix_vectors(struct virtio_device *vdev, int nvectors,\r\nbool per_vq_vectors)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nconst char *name = dev_name(&vp_dev->vdev.dev);\r\nunsigned i, v;\r\nint err = -ENOMEM;\r\nvp_dev->msix_vectors = nvectors;\r\nvp_dev->msix_entries = kmalloc(nvectors * sizeof *vp_dev->msix_entries,\r\nGFP_KERNEL);\r\nif (!vp_dev->msix_entries)\r\ngoto error;\r\nvp_dev->msix_names = kmalloc(nvectors * sizeof *vp_dev->msix_names,\r\nGFP_KERNEL);\r\nif (!vp_dev->msix_names)\r\ngoto error;\r\nvp_dev->msix_affinity_masks\r\n= kzalloc(nvectors * sizeof *vp_dev->msix_affinity_masks,\r\nGFP_KERNEL);\r\nif (!vp_dev->msix_affinity_masks)\r\ngoto error;\r\nfor (i = 0; i < nvectors; ++i)\r\nif (!alloc_cpumask_var(&vp_dev->msix_affinity_masks[i],\r\nGFP_KERNEL))\r\ngoto error;\r\nfor (i = 0; i < nvectors; ++i)\r\nvp_dev->msix_entries[i].entry = i;\r\nerr = pci_enable_msix_exact(vp_dev->pci_dev,\r\nvp_dev->msix_entries, nvectors);\r\nif (err)\r\ngoto error;\r\nvp_dev->msix_enabled = 1;\r\nv = vp_dev->msix_used_vectors;\r\nsnprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,\r\n"%s-config", name);\r\nerr = request_irq(vp_dev->msix_entries[v].vector,\r\nvp_config_changed, 0, vp_dev->msix_names[v],\r\nvp_dev);\r\nif (err)\r\ngoto error;\r\n++vp_dev->msix_used_vectors;\r\nv = vp_dev->config_vector(vp_dev, v);\r\nif (v == VIRTIO_MSI_NO_VECTOR) {\r\nerr = -EBUSY;\r\ngoto error;\r\n}\r\nif (!per_vq_vectors) {\r\nv = vp_dev->msix_used_vectors;\r\nsnprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,\r\n"%s-virtqueues", name);\r\nerr = request_irq(vp_dev->msix_entries[v].vector,\r\nvp_vring_interrupt, 0, vp_dev->msix_names[v],\r\nvp_dev);\r\nif (err)\r\ngoto error;\r\n++vp_dev->msix_used_vectors;\r\n}\r\nreturn 0;\r\nerror:\r\nvp_free_vectors(vdev);\r\nreturn err;\r\n}\r\nstatic int vp_request_intx(struct virtio_device *vdev)\r\n{\r\nint err;\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nerr = request_irq(vp_dev->pci_dev->irq, vp_interrupt,\r\nIRQF_SHARED, dev_name(&vdev->dev), vp_dev);\r\nif (!err)\r\nvp_dev->intx_enabled = 1;\r\nreturn err;\r\n}\r\nstatic struct virtqueue *vp_setup_vq(struct virtio_device *vdev, unsigned index,\r\nvoid (*callback)(struct virtqueue *vq),\r\nconst char *name,\r\nu16 msix_vec)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nstruct virtio_pci_vq_info *info = kmalloc(sizeof *info, GFP_KERNEL);\r\nstruct virtqueue *vq;\r\nunsigned long flags;\r\nif (!info)\r\nreturn ERR_PTR(-ENOMEM);\r\nvq = vp_dev->setup_vq(vp_dev, info, index, callback, name, msix_vec);\r\nif (IS_ERR(vq))\r\ngoto out_info;\r\ninfo->vq = vq;\r\nif (callback) {\r\nspin_lock_irqsave(&vp_dev->lock, flags);\r\nlist_add(&info->node, &vp_dev->virtqueues);\r\nspin_unlock_irqrestore(&vp_dev->lock, flags);\r\n} else {\r\nINIT_LIST_HEAD(&info->node);\r\n}\r\nvp_dev->vqs[index] = info;\r\nreturn vq;\r\nout_info:\r\nkfree(info);\r\nreturn vq;\r\n}\r\nstatic void vp_del_vq(struct virtqueue *vq)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\r\nstruct virtio_pci_vq_info *info = vp_dev->vqs[vq->index];\r\nunsigned long flags;\r\nspin_lock_irqsave(&vp_dev->lock, flags);\r\nlist_del(&info->node);\r\nspin_unlock_irqrestore(&vp_dev->lock, flags);\r\nvp_dev->del_vq(info);\r\nkfree(info);\r\n}\r\nvoid vp_del_vqs(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nstruct virtqueue *vq, *n;\r\nstruct virtio_pci_vq_info *info;\r\nlist_for_each_entry_safe(vq, n, &vdev->vqs, list) {\r\ninfo = vp_dev->vqs[vq->index];\r\nif (vp_dev->per_vq_vectors &&\r\ninfo->msix_vector != VIRTIO_MSI_NO_VECTOR)\r\nfree_irq(vp_dev->msix_entries[info->msix_vector].vector,\r\nvq);\r\nvp_del_vq(vq);\r\n}\r\nvp_dev->per_vq_vectors = false;\r\nvp_free_vectors(vdev);\r\nkfree(vp_dev->vqs);\r\nvp_dev->vqs = NULL;\r\n}\r\nstatic int vp_try_to_find_vqs(struct virtio_device *vdev, unsigned nvqs,\r\nstruct virtqueue *vqs[],\r\nvq_callback_t *callbacks[],\r\nconst char *names[],\r\nbool use_msix,\r\nbool per_vq_vectors)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nu16 msix_vec;\r\nint i, err, nvectors, allocated_vectors;\r\nvp_dev->vqs = kmalloc(nvqs * sizeof *vp_dev->vqs, GFP_KERNEL);\r\nif (!vp_dev->vqs)\r\nreturn -ENOMEM;\r\nif (!use_msix) {\r\nerr = vp_request_intx(vdev);\r\nif (err)\r\ngoto error_find;\r\n} else {\r\nif (per_vq_vectors) {\r\nnvectors = 1;\r\nfor (i = 0; i < nvqs; ++i)\r\nif (callbacks[i])\r\n++nvectors;\r\n} else {\r\nnvectors = 2;\r\n}\r\nerr = vp_request_msix_vectors(vdev, nvectors, per_vq_vectors);\r\nif (err)\r\ngoto error_find;\r\n}\r\nvp_dev->per_vq_vectors = per_vq_vectors;\r\nallocated_vectors = vp_dev->msix_used_vectors;\r\nfor (i = 0; i < nvqs; ++i) {\r\nif (!names[i]) {\r\nvqs[i] = NULL;\r\ncontinue;\r\n} else if (!callbacks[i] || !vp_dev->msix_enabled)\r\nmsix_vec = VIRTIO_MSI_NO_VECTOR;\r\nelse if (vp_dev->per_vq_vectors)\r\nmsix_vec = allocated_vectors++;\r\nelse\r\nmsix_vec = VP_MSIX_VQ_VECTOR;\r\nvqs[i] = vp_setup_vq(vdev, i, callbacks[i], names[i], msix_vec);\r\nif (IS_ERR(vqs[i])) {\r\nerr = PTR_ERR(vqs[i]);\r\ngoto error_find;\r\n}\r\nif (!vp_dev->per_vq_vectors || msix_vec == VIRTIO_MSI_NO_VECTOR)\r\ncontinue;\r\nsnprintf(vp_dev->msix_names[msix_vec],\r\nsizeof *vp_dev->msix_names,\r\n"%s-%s",\r\ndev_name(&vp_dev->vdev.dev), names[i]);\r\nerr = request_irq(vp_dev->msix_entries[msix_vec].vector,\r\nvring_interrupt, 0,\r\nvp_dev->msix_names[msix_vec],\r\nvqs[i]);\r\nif (err) {\r\nvp_del_vq(vqs[i]);\r\ngoto error_find;\r\n}\r\n}\r\nreturn 0;\r\nerror_find:\r\nvp_del_vqs(vdev);\r\nreturn err;\r\n}\r\nint vp_find_vqs(struct virtio_device *vdev, unsigned nvqs,\r\nstruct virtqueue *vqs[],\r\nvq_callback_t *callbacks[],\r\nconst char *names[])\r\n{\r\nint err;\r\nerr = vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names, true, true);\r\nif (!err)\r\nreturn 0;\r\nerr = vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names,\r\ntrue, false);\r\nif (!err)\r\nreturn 0;\r\nreturn vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names,\r\nfalse, false);\r\n}\r\nconst char *vp_bus_name(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nreturn pci_name(vp_dev->pci_dev);\r\n}\r\nint vp_set_vq_affinity(struct virtqueue *vq, int cpu)\r\n{\r\nstruct virtio_device *vdev = vq->vdev;\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nstruct virtio_pci_vq_info *info = vp_dev->vqs[vq->index];\r\nstruct cpumask *mask;\r\nunsigned int irq;\r\nif (!vq->callback)\r\nreturn -EINVAL;\r\nif (vp_dev->msix_enabled) {\r\nmask = vp_dev->msix_affinity_masks[info->msix_vector];\r\nirq = vp_dev->msix_entries[info->msix_vector].vector;\r\nif (cpu == -1)\r\nirq_set_affinity_hint(irq, NULL);\r\nelse {\r\ncpumask_clear(mask);\r\ncpumask_set_cpu(cpu, mask);\r\nirq_set_affinity_hint(irq, mask);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int virtio_pci_freeze(struct device *dev)\r\n{\r\nstruct pci_dev *pci_dev = to_pci_dev(dev);\r\nstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\r\nint ret;\r\nret = virtio_device_freeze(&vp_dev->vdev);\r\nif (!ret)\r\npci_disable_device(pci_dev);\r\nreturn ret;\r\n}\r\nstatic int virtio_pci_restore(struct device *dev)\r\n{\r\nstruct pci_dev *pci_dev = to_pci_dev(dev);\r\nstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\r\nint ret;\r\nret = pci_enable_device(pci_dev);\r\nif (ret)\r\nreturn ret;\r\npci_set_master(pci_dev);\r\nreturn virtio_device_restore(&vp_dev->vdev);\r\n}\r\nstatic void virtio_pci_release_dev(struct device *_d)\r\n{\r\nstruct virtio_device *vdev = dev_to_virtio(_d);\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nkfree(vp_dev);\r\n}\r\nstatic int virtio_pci_probe(struct pci_dev *pci_dev,\r\nconst struct pci_device_id *id)\r\n{\r\nstruct virtio_pci_device *vp_dev;\r\nint rc;\r\nvp_dev = kzalloc(sizeof(struct virtio_pci_device), GFP_KERNEL);\r\nif (!vp_dev)\r\nreturn -ENOMEM;\r\npci_set_drvdata(pci_dev, vp_dev);\r\nvp_dev->vdev.dev.parent = &pci_dev->dev;\r\nvp_dev->vdev.dev.release = virtio_pci_release_dev;\r\nvp_dev->pci_dev = pci_dev;\r\nINIT_LIST_HEAD(&vp_dev->virtqueues);\r\nspin_lock_init(&vp_dev->lock);\r\nrc = pci_enable_device(pci_dev);\r\nif (rc)\r\ngoto err_enable_device;\r\nif (force_legacy) {\r\nrc = virtio_pci_legacy_probe(vp_dev);\r\nif (rc == -ENODEV || rc == -ENOMEM)\r\nrc = virtio_pci_modern_probe(vp_dev);\r\nif (rc)\r\ngoto err_probe;\r\n} else {\r\nrc = virtio_pci_modern_probe(vp_dev);\r\nif (rc == -ENODEV)\r\nrc = virtio_pci_legacy_probe(vp_dev);\r\nif (rc)\r\ngoto err_probe;\r\n}\r\npci_set_master(pci_dev);\r\nrc = register_virtio_device(&vp_dev->vdev);\r\nif (rc)\r\ngoto err_register;\r\nreturn 0;\r\nerr_register:\r\nif (vp_dev->ioaddr)\r\nvirtio_pci_legacy_remove(vp_dev);\r\nelse\r\nvirtio_pci_modern_remove(vp_dev);\r\nerr_probe:\r\npci_disable_device(pci_dev);\r\nerr_enable_device:\r\nkfree(vp_dev);\r\nreturn rc;\r\n}\r\nstatic void virtio_pci_remove(struct pci_dev *pci_dev)\r\n{\r\nstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\r\nunregister_virtio_device(&vp_dev->vdev);\r\nif (vp_dev->ioaddr)\r\nvirtio_pci_legacy_remove(vp_dev);\r\nelse\r\nvirtio_pci_modern_remove(vp_dev);\r\npci_disable_device(pci_dev);\r\n}
