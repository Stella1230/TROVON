static inline struct Scsi_Host *virtio_scsi_host(struct virtio_device *vdev)\r\n{\r\nreturn vdev->priv;\r\n}\r\nstatic void virtscsi_compute_resid(struct scsi_cmnd *sc, u32 resid)\r\n{\r\nif (!resid)\r\nreturn;\r\nif (!scsi_bidi_cmnd(sc)) {\r\nscsi_set_resid(sc, resid);\r\nreturn;\r\n}\r\nscsi_in(sc)->resid = min(resid, scsi_in(sc)->length);\r\nscsi_out(sc)->resid = resid - scsi_in(sc)->resid;\r\n}\r\nstatic void virtscsi_complete_cmd(struct virtio_scsi *vscsi, void *buf)\r\n{\r\nstruct virtio_scsi_cmd *cmd = buf;\r\nstruct scsi_cmnd *sc = cmd->sc;\r\nstruct virtio_scsi_cmd_resp *resp = &cmd->resp.cmd;\r\nstruct virtio_scsi_target_state *tgt =\r\nscsi_target(sc->device)->hostdata;\r\ndev_dbg(&sc->device->sdev_gendev,\r\n"cmd %p response %u status %#02x sense_len %u\n",\r\nsc, resp->response, resp->status, resp->sense_len);\r\nsc->result = resp->status;\r\nvirtscsi_compute_resid(sc, virtio32_to_cpu(vscsi->vdev, resp->resid));\r\nswitch (resp->response) {\r\ncase VIRTIO_SCSI_S_OK:\r\nset_host_byte(sc, DID_OK);\r\nbreak;\r\ncase VIRTIO_SCSI_S_OVERRUN:\r\nset_host_byte(sc, DID_ERROR);\r\nbreak;\r\ncase VIRTIO_SCSI_S_ABORTED:\r\nset_host_byte(sc, DID_ABORT);\r\nbreak;\r\ncase VIRTIO_SCSI_S_BAD_TARGET:\r\nset_host_byte(sc, DID_BAD_TARGET);\r\nbreak;\r\ncase VIRTIO_SCSI_S_RESET:\r\nset_host_byte(sc, DID_RESET);\r\nbreak;\r\ncase VIRTIO_SCSI_S_BUSY:\r\nset_host_byte(sc, DID_BUS_BUSY);\r\nbreak;\r\ncase VIRTIO_SCSI_S_TRANSPORT_FAILURE:\r\nset_host_byte(sc, DID_TRANSPORT_DISRUPTED);\r\nbreak;\r\ncase VIRTIO_SCSI_S_TARGET_FAILURE:\r\nset_host_byte(sc, DID_TARGET_FAILURE);\r\nbreak;\r\ncase VIRTIO_SCSI_S_NEXUS_FAILURE:\r\nset_host_byte(sc, DID_NEXUS_FAILURE);\r\nbreak;\r\ndefault:\r\nscmd_printk(KERN_WARNING, sc, "Unknown response %d",\r\nresp->response);\r\ncase VIRTIO_SCSI_S_FAILURE:\r\nset_host_byte(sc, DID_ERROR);\r\nbreak;\r\n}\r\nWARN_ON(virtio32_to_cpu(vscsi->vdev, resp->sense_len) >\r\nVIRTIO_SCSI_SENSE_SIZE);\r\nif (sc->sense_buffer) {\r\nmemcpy(sc->sense_buffer, resp->sense,\r\nmin_t(u32,\r\nvirtio32_to_cpu(vscsi->vdev, resp->sense_len),\r\nVIRTIO_SCSI_SENSE_SIZE));\r\nif (resp->sense_len)\r\nset_driver_byte(sc, DRIVER_SENSE);\r\n}\r\nsc->scsi_done(sc);\r\natomic_dec(&tgt->reqs);\r\n}\r\nstatic void virtscsi_vq_done(struct virtio_scsi *vscsi,\r\nstruct virtio_scsi_vq *virtscsi_vq,\r\nvoid (*fn)(struct virtio_scsi *vscsi, void *buf))\r\n{\r\nvoid *buf;\r\nunsigned int len;\r\nunsigned long flags;\r\nstruct virtqueue *vq = virtscsi_vq->vq;\r\nspin_lock_irqsave(&virtscsi_vq->vq_lock, flags);\r\ndo {\r\nvirtqueue_disable_cb(vq);\r\nwhile ((buf = virtqueue_get_buf(vq, &len)) != NULL)\r\nfn(vscsi, buf);\r\nif (unlikely(virtqueue_is_broken(vq)))\r\nbreak;\r\n} while (!virtqueue_enable_cb(vq));\r\nspin_unlock_irqrestore(&virtscsi_vq->vq_lock, flags);\r\n}\r\nstatic void virtscsi_req_done(struct virtqueue *vq)\r\n{\r\nstruct Scsi_Host *sh = virtio_scsi_host(vq->vdev);\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nint index = vq->index - VIRTIO_SCSI_VQ_BASE;\r\nstruct virtio_scsi_vq *req_vq = &vscsi->req_vqs[index];\r\nvirtscsi_vq_done(vscsi, req_vq, virtscsi_complete_cmd);\r\n}\r\nstatic void virtscsi_poll_requests(struct virtio_scsi *vscsi)\r\n{\r\nint i, num_vqs;\r\nnum_vqs = vscsi->num_queues;\r\nfor (i = 0; i < num_vqs; i++)\r\nvirtscsi_vq_done(vscsi, &vscsi->req_vqs[i],\r\nvirtscsi_complete_cmd);\r\n}\r\nstatic void virtscsi_complete_free(struct virtio_scsi *vscsi, void *buf)\r\n{\r\nstruct virtio_scsi_cmd *cmd = buf;\r\nif (cmd->comp)\r\ncomplete_all(cmd->comp);\r\n}\r\nstatic void virtscsi_ctrl_done(struct virtqueue *vq)\r\n{\r\nstruct Scsi_Host *sh = virtio_scsi_host(vq->vdev);\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nvirtscsi_vq_done(vscsi, &vscsi->ctrl_vq, virtscsi_complete_free);\r\n}\r\nstatic int virtscsi_kick_event(struct virtio_scsi *vscsi,\r\nstruct virtio_scsi_event_node *event_node)\r\n{\r\nint err;\r\nstruct scatterlist sg;\r\nunsigned long flags;\r\nINIT_WORK(&event_node->work, virtscsi_handle_event);\r\nsg_init_one(&sg, &event_node->event, sizeof(struct virtio_scsi_event));\r\nspin_lock_irqsave(&vscsi->event_vq.vq_lock, flags);\r\nerr = virtqueue_add_inbuf(vscsi->event_vq.vq, &sg, 1, event_node,\r\nGFP_ATOMIC);\r\nif (!err)\r\nvirtqueue_kick(vscsi->event_vq.vq);\r\nspin_unlock_irqrestore(&vscsi->event_vq.vq_lock, flags);\r\nreturn err;\r\n}\r\nstatic int virtscsi_kick_event_all(struct virtio_scsi *vscsi)\r\n{\r\nint i;\r\nfor (i = 0; i < VIRTIO_SCSI_EVENT_LEN; i++) {\r\nvscsi->event_list[i].vscsi = vscsi;\r\nvirtscsi_kick_event(vscsi, &vscsi->event_list[i]);\r\n}\r\nreturn 0;\r\n}\r\nstatic void virtscsi_cancel_event_work(struct virtio_scsi *vscsi)\r\n{\r\nint i;\r\nspin_lock_irq(&vscsi->event_vq.vq_lock);\r\nvscsi->stop_events = true;\r\nspin_unlock_irq(&vscsi->event_vq.vq_lock);\r\nfor (i = 0; i < VIRTIO_SCSI_EVENT_LEN; i++)\r\ncancel_work_sync(&vscsi->event_list[i].work);\r\n}\r\nstatic void virtscsi_handle_transport_reset(struct virtio_scsi *vscsi,\r\nstruct virtio_scsi_event *event)\r\n{\r\nstruct scsi_device *sdev;\r\nstruct Scsi_Host *shost = virtio_scsi_host(vscsi->vdev);\r\nunsigned int target = event->lun[1];\r\nunsigned int lun = (event->lun[2] << 8) | event->lun[3];\r\nswitch (virtio32_to_cpu(vscsi->vdev, event->reason)) {\r\ncase VIRTIO_SCSI_EVT_RESET_RESCAN:\r\nscsi_add_device(shost, 0, target, lun);\r\nbreak;\r\ncase VIRTIO_SCSI_EVT_RESET_REMOVED:\r\nsdev = scsi_device_lookup(shost, 0, target, lun);\r\nif (sdev) {\r\nscsi_remove_device(sdev);\r\nscsi_device_put(sdev);\r\n} else {\r\npr_err("SCSI device %d 0 %d %d not found\n",\r\nshost->host_no, target, lun);\r\n}\r\nbreak;\r\ndefault:\r\npr_info("Unsupport virtio scsi event reason %x\n", event->reason);\r\n}\r\n}\r\nstatic void virtscsi_handle_param_change(struct virtio_scsi *vscsi,\r\nstruct virtio_scsi_event *event)\r\n{\r\nstruct scsi_device *sdev;\r\nstruct Scsi_Host *shost = virtio_scsi_host(vscsi->vdev);\r\nunsigned int target = event->lun[1];\r\nunsigned int lun = (event->lun[2] << 8) | event->lun[3];\r\nu8 asc = virtio32_to_cpu(vscsi->vdev, event->reason) & 255;\r\nu8 ascq = virtio32_to_cpu(vscsi->vdev, event->reason) >> 8;\r\nsdev = scsi_device_lookup(shost, 0, target, lun);\r\nif (!sdev) {\r\npr_err("SCSI device %d 0 %d %d not found\n",\r\nshost->host_no, target, lun);\r\nreturn;\r\n}\r\nif (asc == 0x2a && (ascq == 0x00 || ascq == 0x01 || ascq == 0x09))\r\nscsi_rescan_device(&sdev->sdev_gendev);\r\nscsi_device_put(sdev);\r\n}\r\nstatic void virtscsi_handle_event(struct work_struct *work)\r\n{\r\nstruct virtio_scsi_event_node *event_node =\r\ncontainer_of(work, struct virtio_scsi_event_node, work);\r\nstruct virtio_scsi *vscsi = event_node->vscsi;\r\nstruct virtio_scsi_event *event = &event_node->event;\r\nif (event->event &\r\ncpu_to_virtio32(vscsi->vdev, VIRTIO_SCSI_T_EVENTS_MISSED)) {\r\nevent->event &= ~cpu_to_virtio32(vscsi->vdev,\r\nVIRTIO_SCSI_T_EVENTS_MISSED);\r\nscsi_scan_host(virtio_scsi_host(vscsi->vdev));\r\n}\r\nswitch (virtio32_to_cpu(vscsi->vdev, event->event)) {\r\ncase VIRTIO_SCSI_T_NO_EVENT:\r\nbreak;\r\ncase VIRTIO_SCSI_T_TRANSPORT_RESET:\r\nvirtscsi_handle_transport_reset(vscsi, event);\r\nbreak;\r\ncase VIRTIO_SCSI_T_PARAM_CHANGE:\r\nvirtscsi_handle_param_change(vscsi, event);\r\nbreak;\r\ndefault:\r\npr_err("Unsupport virtio scsi event %x\n", event->event);\r\n}\r\nvirtscsi_kick_event(vscsi, event_node);\r\n}\r\nstatic void virtscsi_complete_event(struct virtio_scsi *vscsi, void *buf)\r\n{\r\nstruct virtio_scsi_event_node *event_node = buf;\r\nif (!vscsi->stop_events)\r\nqueue_work(system_freezable_wq, &event_node->work);\r\n}\r\nstatic void virtscsi_event_done(struct virtqueue *vq)\r\n{\r\nstruct Scsi_Host *sh = virtio_scsi_host(vq->vdev);\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nvirtscsi_vq_done(vscsi, &vscsi->event_vq, virtscsi_complete_event);\r\n}\r\nstatic int virtscsi_add_cmd(struct virtqueue *vq,\r\nstruct virtio_scsi_cmd *cmd,\r\nsize_t req_size, size_t resp_size)\r\n{\r\nstruct scsi_cmnd *sc = cmd->sc;\r\nstruct scatterlist *sgs[6], req, resp;\r\nstruct sg_table *out, *in;\r\nunsigned out_num = 0, in_num = 0;\r\nout = in = NULL;\r\nif (sc && sc->sc_data_direction != DMA_NONE) {\r\nif (sc->sc_data_direction != DMA_FROM_DEVICE)\r\nout = &scsi_out(sc)->table;\r\nif (sc->sc_data_direction != DMA_TO_DEVICE)\r\nin = &scsi_in(sc)->table;\r\n}\r\nsg_init_one(&req, &cmd->req, req_size);\r\nsgs[out_num++] = &req;\r\nif (out) {\r\nif (scsi_prot_sg_count(sc))\r\nsgs[out_num++] = scsi_prot_sglist(sc);\r\nsgs[out_num++] = out->sgl;\r\n}\r\nsg_init_one(&resp, &cmd->resp, resp_size);\r\nsgs[out_num + in_num++] = &resp;\r\nif (in) {\r\nif (scsi_prot_sg_count(sc))\r\nsgs[out_num + in_num++] = scsi_prot_sglist(sc);\r\nsgs[out_num + in_num++] = in->sgl;\r\n}\r\nreturn virtqueue_add_sgs(vq, sgs, out_num, in_num, cmd, GFP_ATOMIC);\r\n}\r\nstatic int virtscsi_kick_cmd(struct virtio_scsi_vq *vq,\r\nstruct virtio_scsi_cmd *cmd,\r\nsize_t req_size, size_t resp_size)\r\n{\r\nunsigned long flags;\r\nint err;\r\nbool needs_kick = false;\r\nspin_lock_irqsave(&vq->vq_lock, flags);\r\nerr = virtscsi_add_cmd(vq->vq, cmd, req_size, resp_size);\r\nif (!err)\r\nneeds_kick = virtqueue_kick_prepare(vq->vq);\r\nspin_unlock_irqrestore(&vq->vq_lock, flags);\r\nif (needs_kick)\r\nvirtqueue_notify(vq->vq);\r\nreturn err;\r\n}\r\nstatic void virtio_scsi_init_hdr(struct virtio_device *vdev,\r\nstruct virtio_scsi_cmd_req *cmd,\r\nstruct scsi_cmnd *sc)\r\n{\r\ncmd->lun[0] = 1;\r\ncmd->lun[1] = sc->device->id;\r\ncmd->lun[2] = (sc->device->lun >> 8) | 0x40;\r\ncmd->lun[3] = sc->device->lun & 0xff;\r\ncmd->tag = cpu_to_virtio64(vdev, (unsigned long)sc);\r\ncmd->task_attr = VIRTIO_SCSI_S_SIMPLE;\r\ncmd->prio = 0;\r\ncmd->crn = 0;\r\n}\r\nstatic void virtio_scsi_init_hdr_pi(struct virtio_device *vdev,\r\nstruct virtio_scsi_cmd_req_pi *cmd_pi,\r\nstruct scsi_cmnd *sc)\r\n{\r\nstruct request *rq = sc->request;\r\nstruct blk_integrity *bi;\r\nvirtio_scsi_init_hdr(vdev, (struct virtio_scsi_cmd_req *)cmd_pi, sc);\r\nif (!rq || !scsi_prot_sg_count(sc))\r\nreturn;\r\nbi = blk_get_integrity(rq->rq_disk);\r\nif (sc->sc_data_direction == DMA_TO_DEVICE)\r\ncmd_pi->pi_bytesout = cpu_to_virtio32(vdev,\r\nblk_rq_sectors(rq) *\r\nbi->tuple_size);\r\nelse if (sc->sc_data_direction == DMA_FROM_DEVICE)\r\ncmd_pi->pi_bytesin = cpu_to_virtio32(vdev,\r\nblk_rq_sectors(rq) *\r\nbi->tuple_size);\r\n}\r\nstatic int virtscsi_queuecommand(struct virtio_scsi *vscsi,\r\nstruct virtio_scsi_vq *req_vq,\r\nstruct scsi_cmnd *sc)\r\n{\r\nstruct Scsi_Host *shost = virtio_scsi_host(vscsi->vdev);\r\nstruct virtio_scsi_cmd *cmd = scsi_cmd_priv(sc);\r\nint req_size;\r\nBUG_ON(scsi_sg_count(sc) > shost->sg_tablesize);\r\nBUG_ON(sc->sc_data_direction == DMA_BIDIRECTIONAL);\r\ndev_dbg(&sc->device->sdev_gendev,\r\n"cmd %p CDB: %#02x\n", sc, sc->cmnd[0]);\r\nmemset(cmd, 0, sizeof(*cmd));\r\ncmd->sc = sc;\r\nBUG_ON(sc->cmd_len > VIRTIO_SCSI_CDB_SIZE);\r\n#ifdef CONFIG_BLK_DEV_INTEGRITY\r\nif (virtio_has_feature(vscsi->vdev, VIRTIO_SCSI_F_T10_PI)) {\r\nvirtio_scsi_init_hdr_pi(vscsi->vdev, &cmd->req.cmd_pi, sc);\r\nmemcpy(cmd->req.cmd_pi.cdb, sc->cmnd, sc->cmd_len);\r\nreq_size = sizeof(cmd->req.cmd_pi);\r\n} else\r\n#endif\r\n{\r\nvirtio_scsi_init_hdr(vscsi->vdev, &cmd->req.cmd, sc);\r\nmemcpy(cmd->req.cmd.cdb, sc->cmnd, sc->cmd_len);\r\nreq_size = sizeof(cmd->req.cmd);\r\n}\r\nif (virtscsi_kick_cmd(req_vq, cmd, req_size, sizeof(cmd->resp.cmd)) != 0)\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\nreturn 0;\r\n}\r\nstatic int virtscsi_queuecommand_single(struct Scsi_Host *sh,\r\nstruct scsi_cmnd *sc)\r\n{\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nstruct virtio_scsi_target_state *tgt =\r\nscsi_target(sc->device)->hostdata;\r\natomic_inc(&tgt->reqs);\r\nreturn virtscsi_queuecommand(vscsi, &vscsi->req_vqs[0], sc);\r\n}\r\nstatic struct virtio_scsi_vq *virtscsi_pick_vq_mq(struct virtio_scsi *vscsi,\r\nstruct scsi_cmnd *sc)\r\n{\r\nu32 tag = blk_mq_unique_tag(sc->request);\r\nu16 hwq = blk_mq_unique_tag_to_hwq(tag);\r\nreturn &vscsi->req_vqs[hwq];\r\n}\r\nstatic struct virtio_scsi_vq *virtscsi_pick_vq(struct virtio_scsi *vscsi,\r\nstruct virtio_scsi_target_state *tgt)\r\n{\r\nstruct virtio_scsi_vq *vq;\r\nunsigned long flags;\r\nu32 queue_num;\r\nlocal_irq_save(flags);\r\nif (atomic_inc_return(&tgt->reqs) > 1) {\r\nunsigned long seq;\r\ndo {\r\nseq = read_seqcount_begin(&tgt->tgt_seq);\r\nvq = tgt->req_vq;\r\n} while (read_seqcount_retry(&tgt->tgt_seq, seq));\r\n} else {\r\nwrite_seqcount_begin(&tgt->tgt_seq);\r\nif (unlikely(atomic_read(&tgt->reqs) > 1)) {\r\nvq = tgt->req_vq;\r\ngoto unlock;\r\n}\r\nqueue_num = smp_processor_id();\r\nwhile (unlikely(queue_num >= vscsi->num_queues))\r\nqueue_num -= vscsi->num_queues;\r\ntgt->req_vq = vq = &vscsi->req_vqs[queue_num];\r\nunlock:\r\nwrite_seqcount_end(&tgt->tgt_seq);\r\n}\r\nlocal_irq_restore(flags);\r\nreturn vq;\r\n}\r\nstatic int virtscsi_queuecommand_multi(struct Scsi_Host *sh,\r\nstruct scsi_cmnd *sc)\r\n{\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nstruct virtio_scsi_target_state *tgt =\r\nscsi_target(sc->device)->hostdata;\r\nstruct virtio_scsi_vq *req_vq;\r\nif (shost_use_blk_mq(sh))\r\nreq_vq = virtscsi_pick_vq_mq(vscsi, sc);\r\nelse\r\nreq_vq = virtscsi_pick_vq(vscsi, tgt);\r\nreturn virtscsi_queuecommand(vscsi, req_vq, sc);\r\n}\r\nstatic int virtscsi_tmf(struct virtio_scsi *vscsi, struct virtio_scsi_cmd *cmd)\r\n{\r\nDECLARE_COMPLETION_ONSTACK(comp);\r\nint ret = FAILED;\r\ncmd->comp = &comp;\r\nif (virtscsi_kick_cmd(&vscsi->ctrl_vq, cmd,\r\nsizeof cmd->req.tmf, sizeof cmd->resp.tmf) < 0)\r\ngoto out;\r\nwait_for_completion(&comp);\r\nif (cmd->resp.tmf.response == VIRTIO_SCSI_S_OK ||\r\ncmd->resp.tmf.response == VIRTIO_SCSI_S_FUNCTION_SUCCEEDED)\r\nret = SUCCESS;\r\nvirtscsi_poll_requests(vscsi);\r\nout:\r\nmempool_free(cmd, virtscsi_cmd_pool);\r\nreturn ret;\r\n}\r\nstatic int virtscsi_device_reset(struct scsi_cmnd *sc)\r\n{\r\nstruct virtio_scsi *vscsi = shost_priv(sc->device->host);\r\nstruct virtio_scsi_cmd *cmd;\r\nsdev_printk(KERN_INFO, sc->device, "device reset\n");\r\ncmd = mempool_alloc(virtscsi_cmd_pool, GFP_NOIO);\r\nif (!cmd)\r\nreturn FAILED;\r\nmemset(cmd, 0, sizeof(*cmd));\r\ncmd->sc = sc;\r\ncmd->req.tmf = (struct virtio_scsi_ctrl_tmf_req){\r\n.type = VIRTIO_SCSI_T_TMF,\r\n.subtype = cpu_to_virtio32(vscsi->vdev,\r\nVIRTIO_SCSI_T_TMF_LOGICAL_UNIT_RESET),\r\n.lun[0] = 1,\r\n.lun[1] = sc->device->id,\r\n.lun[2] = (sc->device->lun >> 8) | 0x40,\r\n.lun[3] = sc->device->lun & 0xff,\r\n};\r\nreturn virtscsi_tmf(vscsi, cmd);\r\n}\r\nstatic int virtscsi_change_queue_depth(struct scsi_device *sdev, int qdepth)\r\n{\r\nstruct Scsi_Host *shost = sdev->host;\r\nint max_depth = shost->cmd_per_lun;\r\nreturn scsi_change_queue_depth(sdev, min(max_depth, qdepth));\r\n}\r\nstatic int virtscsi_abort(struct scsi_cmnd *sc)\r\n{\r\nstruct virtio_scsi *vscsi = shost_priv(sc->device->host);\r\nstruct virtio_scsi_cmd *cmd;\r\nscmd_printk(KERN_INFO, sc, "abort\n");\r\ncmd = mempool_alloc(virtscsi_cmd_pool, GFP_NOIO);\r\nif (!cmd)\r\nreturn FAILED;\r\nmemset(cmd, 0, sizeof(*cmd));\r\ncmd->sc = sc;\r\ncmd->req.tmf = (struct virtio_scsi_ctrl_tmf_req){\r\n.type = VIRTIO_SCSI_T_TMF,\r\n.subtype = VIRTIO_SCSI_T_TMF_ABORT_TASK,\r\n.lun[0] = 1,\r\n.lun[1] = sc->device->id,\r\n.lun[2] = (sc->device->lun >> 8) | 0x40,\r\n.lun[3] = sc->device->lun & 0xff,\r\n.tag = cpu_to_virtio64(vscsi->vdev, (unsigned long)sc),\r\n};\r\nreturn virtscsi_tmf(vscsi, cmd);\r\n}\r\nstatic int virtscsi_target_alloc(struct scsi_target *starget)\r\n{\r\nstruct Scsi_Host *sh = dev_to_shost(starget->dev.parent);\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nstruct virtio_scsi_target_state *tgt =\r\nkmalloc(sizeof(*tgt), GFP_KERNEL);\r\nif (!tgt)\r\nreturn -ENOMEM;\r\nseqcount_init(&tgt->tgt_seq);\r\natomic_set(&tgt->reqs, 0);\r\ntgt->req_vq = &vscsi->req_vqs[0];\r\nstarget->hostdata = tgt;\r\nreturn 0;\r\n}\r\nstatic void virtscsi_target_destroy(struct scsi_target *starget)\r\n{\r\nstruct virtio_scsi_target_state *tgt = starget->hostdata;\r\nkfree(tgt);\r\n}\r\nstatic void __virtscsi_set_affinity(struct virtio_scsi *vscsi, bool affinity)\r\n{\r\nint i;\r\nint cpu;\r\nif ((vscsi->num_queues == 1 ||\r\nvscsi->num_queues != num_online_cpus()) && affinity) {\r\nif (vscsi->affinity_hint_set)\r\naffinity = false;\r\nelse\r\nreturn;\r\n}\r\nif (affinity) {\r\ni = 0;\r\nfor_each_online_cpu(cpu) {\r\nvirtqueue_set_affinity(vscsi->req_vqs[i].vq, cpu);\r\ni++;\r\n}\r\nvscsi->affinity_hint_set = true;\r\n} else {\r\nfor (i = 0; i < vscsi->num_queues; i++) {\r\nif (!vscsi->req_vqs[i].vq)\r\ncontinue;\r\nvirtqueue_set_affinity(vscsi->req_vqs[i].vq, -1);\r\n}\r\nvscsi->affinity_hint_set = false;\r\n}\r\n}\r\nstatic void virtscsi_set_affinity(struct virtio_scsi *vscsi, bool affinity)\r\n{\r\nget_online_cpus();\r\n__virtscsi_set_affinity(vscsi, affinity);\r\nput_online_cpus();\r\n}\r\nstatic int virtscsi_cpu_callback(struct notifier_block *nfb,\r\nunsigned long action, void *hcpu)\r\n{\r\nstruct virtio_scsi *vscsi = container_of(nfb, struct virtio_scsi, nb);\r\nswitch(action) {\r\ncase CPU_ONLINE:\r\ncase CPU_ONLINE_FROZEN:\r\ncase CPU_DEAD:\r\ncase CPU_DEAD_FROZEN:\r\n__virtscsi_set_affinity(vscsi, true);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic void virtscsi_init_vq(struct virtio_scsi_vq *virtscsi_vq,\r\nstruct virtqueue *vq)\r\n{\r\nspin_lock_init(&virtscsi_vq->vq_lock);\r\nvirtscsi_vq->vq = vq;\r\n}\r\nstatic void virtscsi_remove_vqs(struct virtio_device *vdev)\r\n{\r\nstruct Scsi_Host *sh = virtio_scsi_host(vdev);\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nvirtscsi_set_affinity(vscsi, false);\r\nvdev->config->reset(vdev);\r\nvdev->config->del_vqs(vdev);\r\n}\r\nstatic int virtscsi_init(struct virtio_device *vdev,\r\nstruct virtio_scsi *vscsi)\r\n{\r\nint err;\r\nu32 i;\r\nu32 num_vqs;\r\nvq_callback_t **callbacks;\r\nconst char **names;\r\nstruct virtqueue **vqs;\r\nnum_vqs = vscsi->num_queues + VIRTIO_SCSI_VQ_BASE;\r\nvqs = kmalloc(num_vqs * sizeof(struct virtqueue *), GFP_KERNEL);\r\ncallbacks = kmalloc(num_vqs * sizeof(vq_callback_t *), GFP_KERNEL);\r\nnames = kmalloc(num_vqs * sizeof(char *), GFP_KERNEL);\r\nif (!callbacks || !vqs || !names) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\ncallbacks[0] = virtscsi_ctrl_done;\r\ncallbacks[1] = virtscsi_event_done;\r\nnames[0] = "control";\r\nnames[1] = "event";\r\nfor (i = VIRTIO_SCSI_VQ_BASE; i < num_vqs; i++) {\r\ncallbacks[i] = virtscsi_req_done;\r\nnames[i] = "request";\r\n}\r\nerr = vdev->config->find_vqs(vdev, num_vqs, vqs, callbacks, names);\r\nif (err)\r\ngoto out;\r\nvirtscsi_init_vq(&vscsi->ctrl_vq, vqs[0]);\r\nvirtscsi_init_vq(&vscsi->event_vq, vqs[1]);\r\nfor (i = VIRTIO_SCSI_VQ_BASE; i < num_vqs; i++)\r\nvirtscsi_init_vq(&vscsi->req_vqs[i - VIRTIO_SCSI_VQ_BASE],\r\nvqs[i]);\r\nvirtscsi_set_affinity(vscsi, true);\r\nvirtscsi_config_set(vdev, cdb_size, VIRTIO_SCSI_CDB_SIZE);\r\nvirtscsi_config_set(vdev, sense_size, VIRTIO_SCSI_SENSE_SIZE);\r\nerr = 0;\r\nout:\r\nkfree(names);\r\nkfree(callbacks);\r\nkfree(vqs);\r\nif (err)\r\nvirtscsi_remove_vqs(vdev);\r\nreturn err;\r\n}\r\nstatic int virtscsi_probe(struct virtio_device *vdev)\r\n{\r\nstruct Scsi_Host *shost;\r\nstruct virtio_scsi *vscsi;\r\nint err;\r\nu32 sg_elems, num_targets;\r\nu32 cmd_per_lun;\r\nu32 num_queues;\r\nstruct scsi_host_template *hostt;\r\nif (!vdev->config->get) {\r\ndev_err(&vdev->dev, "%s failure: config access disabled\n",\r\n__func__);\r\nreturn -EINVAL;\r\n}\r\nnum_queues = virtscsi_config_get(vdev, num_queues) ? : 1;\r\nnum_targets = virtscsi_config_get(vdev, max_target) + 1;\r\nif (num_queues == 1)\r\nhostt = &virtscsi_host_template_single;\r\nelse\r\nhostt = &virtscsi_host_template_multi;\r\nshost = scsi_host_alloc(hostt,\r\nsizeof(*vscsi) + sizeof(vscsi->req_vqs[0]) * num_queues);\r\nif (!shost)\r\nreturn -ENOMEM;\r\nsg_elems = virtscsi_config_get(vdev, seg_max) ?: 1;\r\nshost->sg_tablesize = sg_elems;\r\nvscsi = shost_priv(shost);\r\nvscsi->vdev = vdev;\r\nvscsi->num_queues = num_queues;\r\nvdev->priv = shost;\r\nerr = virtscsi_init(vdev, vscsi);\r\nif (err)\r\ngoto virtscsi_init_failed;\r\nvscsi->nb.notifier_call = &virtscsi_cpu_callback;\r\nerr = register_hotcpu_notifier(&vscsi->nb);\r\nif (err) {\r\npr_err("registering cpu notifier failed\n");\r\ngoto scsi_add_host_failed;\r\n}\r\ncmd_per_lun = virtscsi_config_get(vdev, cmd_per_lun) ?: 1;\r\nshost->cmd_per_lun = min_t(u32, cmd_per_lun, shost->can_queue);\r\nshost->max_sectors = virtscsi_config_get(vdev, max_sectors) ?: 0xFFFF;\r\nshost->max_lun = virtscsi_config_get(vdev, max_lun) + 1 + 0x4000;\r\nshost->max_id = num_targets;\r\nshost->max_channel = 0;\r\nshost->max_cmd_len = VIRTIO_SCSI_CDB_SIZE;\r\nshost->nr_hw_queues = num_queues;\r\n#ifdef CONFIG_BLK_DEV_INTEGRITY\r\nif (virtio_has_feature(vdev, VIRTIO_SCSI_F_T10_PI)) {\r\nint host_prot;\r\nhost_prot = SHOST_DIF_TYPE1_PROTECTION | SHOST_DIF_TYPE2_PROTECTION |\r\nSHOST_DIF_TYPE3_PROTECTION | SHOST_DIX_TYPE1_PROTECTION |\r\nSHOST_DIX_TYPE2_PROTECTION | SHOST_DIX_TYPE3_PROTECTION;\r\nscsi_host_set_prot(shost, host_prot);\r\nscsi_host_set_guard(shost, SHOST_DIX_GUARD_CRC);\r\n}\r\n#endif\r\nerr = scsi_add_host(shost, &vdev->dev);\r\nif (err)\r\ngoto scsi_add_host_failed;\r\nvirtio_device_ready(vdev);\r\nif (virtio_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG))\r\nvirtscsi_kick_event_all(vscsi);\r\nscsi_scan_host(shost);\r\nreturn 0;\r\nscsi_add_host_failed:\r\nvdev->config->del_vqs(vdev);\r\nvirtscsi_init_failed:\r\nscsi_host_put(shost);\r\nreturn err;\r\n}\r\nstatic void virtscsi_remove(struct virtio_device *vdev)\r\n{\r\nstruct Scsi_Host *shost = virtio_scsi_host(vdev);\r\nstruct virtio_scsi *vscsi = shost_priv(shost);\r\nif (virtio_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG))\r\nvirtscsi_cancel_event_work(vscsi);\r\nscsi_remove_host(shost);\r\nunregister_hotcpu_notifier(&vscsi->nb);\r\nvirtscsi_remove_vqs(vdev);\r\nscsi_host_put(shost);\r\n}\r\nstatic int virtscsi_freeze(struct virtio_device *vdev)\r\n{\r\nstruct Scsi_Host *sh = virtio_scsi_host(vdev);\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nunregister_hotcpu_notifier(&vscsi->nb);\r\nvirtscsi_remove_vqs(vdev);\r\nreturn 0;\r\n}\r\nstatic int virtscsi_restore(struct virtio_device *vdev)\r\n{\r\nstruct Scsi_Host *sh = virtio_scsi_host(vdev);\r\nstruct virtio_scsi *vscsi = shost_priv(sh);\r\nint err;\r\nerr = virtscsi_init(vdev, vscsi);\r\nif (err)\r\nreturn err;\r\nerr = register_hotcpu_notifier(&vscsi->nb);\r\nif (err) {\r\nvdev->config->del_vqs(vdev);\r\nreturn err;\r\n}\r\nvirtio_device_ready(vdev);\r\nif (virtio_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG))\r\nvirtscsi_kick_event_all(vscsi);\r\nreturn err;\r\n}\r\nstatic int __init init(void)\r\n{\r\nint ret = -ENOMEM;\r\nvirtscsi_cmd_cache = KMEM_CACHE(virtio_scsi_cmd, 0);\r\nif (!virtscsi_cmd_cache) {\r\npr_err("kmem_cache_create() for virtscsi_cmd_cache failed\n");\r\ngoto error;\r\n}\r\nvirtscsi_cmd_pool =\r\nmempool_create_slab_pool(VIRTIO_SCSI_MEMPOOL_SZ,\r\nvirtscsi_cmd_cache);\r\nif (!virtscsi_cmd_pool) {\r\npr_err("mempool_create() for virtscsi_cmd_pool failed\n");\r\ngoto error;\r\n}\r\nret = register_virtio_driver(&virtio_scsi_driver);\r\nif (ret < 0)\r\ngoto error;\r\nreturn 0;\r\nerror:\r\nif (virtscsi_cmd_pool) {\r\nmempool_destroy(virtscsi_cmd_pool);\r\nvirtscsi_cmd_pool = NULL;\r\n}\r\nif (virtscsi_cmd_cache) {\r\nkmem_cache_destroy(virtscsi_cmd_cache);\r\nvirtscsi_cmd_cache = NULL;\r\n}\r\nreturn ret;\r\n}\r\nstatic void __exit fini(void)\r\n{\r\nunregister_virtio_driver(&virtio_scsi_driver);\r\nmempool_destroy(virtscsi_cmd_pool);\r\nkmem_cache_destroy(virtscsi_cmd_cache);\r\n}
