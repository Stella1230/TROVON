static bool tcp_in_window(u32 seq, u32 end_seq, u32 s_win, u32 e_win)\r\n{\r\nif (seq == s_win)\r\nreturn true;\r\nif (after(end_seq, s_win) && before(seq, e_win))\r\nreturn true;\r\nreturn seq == e_win && seq == end_seq;\r\n}\r\nstatic enum tcp_tw_status\r\ntcp_timewait_check_oow_rate_limit(struct inet_timewait_sock *tw,\r\nconst struct sk_buff *skb, int mib_idx)\r\n{\r\nstruct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);\r\nif (!tcp_oow_rate_limited(twsk_net(tw), skb, mib_idx,\r\n&tcptw->tw_last_oow_ack_time)) {\r\nreturn TCP_TW_ACK;\r\n}\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\nenum tcp_tw_status\r\ntcp_timewait_state_process(struct inet_timewait_sock *tw, struct sk_buff *skb,\r\nconst struct tcphdr *th)\r\n{\r\nstruct tcp_options_received tmp_opt;\r\nstruct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);\r\nbool paws_reject = false;\r\ntmp_opt.saw_tstamp = 0;\r\nif (th->doff > (sizeof(*th) >> 2) && tcptw->tw_ts_recent_stamp) {\r\ntcp_parse_options(skb, &tmp_opt, 0, NULL);\r\nif (tmp_opt.saw_tstamp) {\r\ntmp_opt.rcv_tsecr -= tcptw->tw_ts_offset;\r\ntmp_opt.ts_recent = tcptw->tw_ts_recent;\r\ntmp_opt.ts_recent_stamp = tcptw->tw_ts_recent_stamp;\r\npaws_reject = tcp_paws_reject(&tmp_opt, th->rst);\r\n}\r\n}\r\nif (tw->tw_substate == TCP_FIN_WAIT2) {\r\nif (paws_reject ||\r\n!tcp_in_window(TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq,\r\ntcptw->tw_rcv_nxt,\r\ntcptw->tw_rcv_nxt + tcptw->tw_rcv_wnd))\r\nreturn tcp_timewait_check_oow_rate_limit(\r\ntw, skb, LINUX_MIB_TCPACKSKIPPEDFINWAIT2);\r\nif (th->rst)\r\ngoto kill;\r\nif (th->syn && !before(TCP_SKB_CB(skb)->seq, tcptw->tw_rcv_nxt))\r\nreturn TCP_TW_RST;\r\nif (!th->ack ||\r\n!after(TCP_SKB_CB(skb)->end_seq, tcptw->tw_rcv_nxt) ||\r\nTCP_SKB_CB(skb)->end_seq == TCP_SKB_CB(skb)->seq) {\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\nif (!th->fin ||\r\nTCP_SKB_CB(skb)->end_seq != tcptw->tw_rcv_nxt + 1)\r\nreturn TCP_TW_RST;\r\ntw->tw_substate = TCP_TIME_WAIT;\r\ntcptw->tw_rcv_nxt = TCP_SKB_CB(skb)->end_seq;\r\nif (tmp_opt.saw_tstamp) {\r\ntcptw->tw_ts_recent_stamp = get_seconds();\r\ntcptw->tw_ts_recent = tmp_opt.rcv_tsval;\r\n}\r\nif (tcp_death_row.sysctl_tw_recycle &&\r\ntcptw->tw_ts_recent_stamp &&\r\ntcp_tw_remember_stamp(tw))\r\ninet_twsk_reschedule(tw, tw->tw_timeout);\r\nelse\r\ninet_twsk_reschedule(tw, TCP_TIMEWAIT_LEN);\r\nreturn TCP_TW_ACK;\r\n}\r\nif (!paws_reject &&\r\n(TCP_SKB_CB(skb)->seq == tcptw->tw_rcv_nxt &&\r\n(TCP_SKB_CB(skb)->seq == TCP_SKB_CB(skb)->end_seq || th->rst))) {\r\nif (th->rst) {\r\nif (sysctl_tcp_rfc1337 == 0) {\r\nkill:\r\ninet_twsk_deschedule_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\n}\r\ninet_twsk_reschedule(tw, TCP_TIMEWAIT_LEN);\r\nif (tmp_opt.saw_tstamp) {\r\ntcptw->tw_ts_recent = tmp_opt.rcv_tsval;\r\ntcptw->tw_ts_recent_stamp = get_seconds();\r\n}\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\nif (th->syn && !th->rst && !th->ack && !paws_reject &&\r\n(after(TCP_SKB_CB(skb)->seq, tcptw->tw_rcv_nxt) ||\r\n(tmp_opt.saw_tstamp &&\r\n(s32)(tcptw->tw_ts_recent - tmp_opt.rcv_tsval) < 0))) {\r\nu32 isn = tcptw->tw_snd_nxt + 65535 + 2;\r\nif (isn == 0)\r\nisn++;\r\nTCP_SKB_CB(skb)->tcp_tw_isn = isn;\r\nreturn TCP_TW_SYN;\r\n}\r\nif (paws_reject)\r\n__NET_INC_STATS(twsk_net(tw), LINUX_MIB_PAWSESTABREJECTED);\r\nif (!th->rst) {\r\nif (paws_reject || th->ack)\r\ninet_twsk_reschedule(tw, TCP_TIMEWAIT_LEN);\r\nreturn tcp_timewait_check_oow_rate_limit(\r\ntw, skb, LINUX_MIB_TCPACKSKIPPEDTIMEWAIT);\r\n}\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\nvoid tcp_time_wait(struct sock *sk, int state, int timeo)\r\n{\r\nconst struct inet_connection_sock *icsk = inet_csk(sk);\r\nconst struct tcp_sock *tp = tcp_sk(sk);\r\nstruct inet_timewait_sock *tw;\r\nbool recycle_ok = false;\r\nif (tcp_death_row.sysctl_tw_recycle && tp->rx_opt.ts_recent_stamp)\r\nrecycle_ok = tcp_remember_stamp(sk);\r\ntw = inet_twsk_alloc(sk, &tcp_death_row, state);\r\nif (tw) {\r\nstruct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);\r\nconst int rto = (icsk->icsk_rto << 2) - (icsk->icsk_rto >> 1);\r\nstruct inet_sock *inet = inet_sk(sk);\r\ntw->tw_transparent = inet->transparent;\r\ntw->tw_rcv_wscale = tp->rx_opt.rcv_wscale;\r\ntcptw->tw_rcv_nxt = tp->rcv_nxt;\r\ntcptw->tw_snd_nxt = tp->snd_nxt;\r\ntcptw->tw_rcv_wnd = tcp_receive_window(tp);\r\ntcptw->tw_ts_recent = tp->rx_opt.ts_recent;\r\ntcptw->tw_ts_recent_stamp = tp->rx_opt.ts_recent_stamp;\r\ntcptw->tw_ts_offset = tp->tsoffset;\r\ntcptw->tw_last_oow_ack_time = 0;\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nif (tw->tw_family == PF_INET6) {\r\nstruct ipv6_pinfo *np = inet6_sk(sk);\r\ntw->tw_v6_daddr = sk->sk_v6_daddr;\r\ntw->tw_v6_rcv_saddr = sk->sk_v6_rcv_saddr;\r\ntw->tw_tclass = np->tclass;\r\ntw->tw_flowlabel = be32_to_cpu(np->flow_label & IPV6_FLOWLABEL_MASK);\r\ntw->tw_ipv6only = sk->sk_ipv6only;\r\n}\r\n#endif\r\n#ifdef CONFIG_TCP_MD5SIG\r\ndo {\r\nstruct tcp_md5sig_key *key;\r\ntcptw->tw_md5_key = NULL;\r\nkey = tp->af_specific->md5_lookup(sk, sk);\r\nif (key) {\r\ntcptw->tw_md5_key = kmemdup(key, sizeof(*key), GFP_ATOMIC);\r\nif (tcptw->tw_md5_key && !tcp_alloc_md5sig_pool())\r\nBUG();\r\n}\r\n} while (0);\r\n#endif\r\nif (timeo < rto)\r\ntimeo = rto;\r\nif (recycle_ok) {\r\ntw->tw_timeout = rto;\r\n} else {\r\ntw->tw_timeout = TCP_TIMEWAIT_LEN;\r\nif (state == TCP_TIME_WAIT)\r\ntimeo = TCP_TIMEWAIT_LEN;\r\n}\r\ninet_twsk_schedule(tw, timeo);\r\n__inet_twsk_hashdance(tw, sk, &tcp_hashinfo);\r\ninet_twsk_put(tw);\r\n} else {\r\nNET_INC_STATS(sock_net(sk), LINUX_MIB_TCPTIMEWAITOVERFLOW);\r\n}\r\ntcp_update_metrics(sk);\r\ntcp_done(sk);\r\n}\r\nvoid tcp_twsk_destructor(struct sock *sk)\r\n{\r\n#ifdef CONFIG_TCP_MD5SIG\r\nstruct tcp_timewait_sock *twsk = tcp_twsk(sk);\r\nif (twsk->tw_md5_key)\r\nkfree_rcu(twsk->tw_md5_key, rcu);\r\n#endif\r\n}\r\nvoid tcp_openreq_init_rwin(struct request_sock *req,\r\nconst struct sock *sk_listener,\r\nconst struct dst_entry *dst)\r\n{\r\nstruct inet_request_sock *ireq = inet_rsk(req);\r\nconst struct tcp_sock *tp = tcp_sk(sk_listener);\r\nu16 user_mss = READ_ONCE(tp->rx_opt.user_mss);\r\nint full_space = tcp_full_space(sk_listener);\r\nint mss = dst_metric_advmss(dst);\r\nu32 window_clamp;\r\n__u8 rcv_wscale;\r\nif (user_mss && user_mss < mss)\r\nmss = user_mss;\r\nwindow_clamp = READ_ONCE(tp->window_clamp);\r\nreq->rsk_window_clamp = window_clamp ? : dst_metric(dst, RTAX_WINDOW);\r\nif (sk_listener->sk_userlocks & SOCK_RCVBUF_LOCK &&\r\n(req->rsk_window_clamp > full_space || req->rsk_window_clamp == 0))\r\nreq->rsk_window_clamp = full_space;\r\ntcp_select_initial_window(full_space,\r\nmss - (ireq->tstamp_ok ? TCPOLEN_TSTAMP_ALIGNED : 0),\r\n&req->rsk_rcv_wnd,\r\n&req->rsk_window_clamp,\r\nireq->wscale_ok,\r\n&rcv_wscale,\r\ndst_metric(dst, RTAX_INITRWND));\r\nireq->rcv_wscale = rcv_wscale;\r\n}\r\nstatic void tcp_ecn_openreq_child(struct tcp_sock *tp,\r\nconst struct request_sock *req)\r\n{\r\ntp->ecn_flags = inet_rsk(req)->ecn_ok ? TCP_ECN_OK : 0;\r\n}\r\nvoid tcp_ca_openreq_child(struct sock *sk, const struct dst_entry *dst)\r\n{\r\nstruct inet_connection_sock *icsk = inet_csk(sk);\r\nu32 ca_key = dst_metric(dst, RTAX_CC_ALGO);\r\nbool ca_got_dst = false;\r\nif (ca_key != TCP_CA_UNSPEC) {\r\nconst struct tcp_congestion_ops *ca;\r\nrcu_read_lock();\r\nca = tcp_ca_find_key(ca_key);\r\nif (likely(ca && try_module_get(ca->owner))) {\r\nicsk->icsk_ca_dst_locked = tcp_ca_dst_locked(dst);\r\nicsk->icsk_ca_ops = ca;\r\nca_got_dst = true;\r\n}\r\nrcu_read_unlock();\r\n}\r\nif (!ca_got_dst &&\r\n(!icsk->icsk_ca_setsockopt ||\r\n!try_module_get(icsk->icsk_ca_ops->owner)))\r\ntcp_assign_congestion_control(sk);\r\ntcp_set_ca_state(sk, TCP_CA_Open);\r\n}\r\nstruct sock *tcp_create_openreq_child(const struct sock *sk,\r\nstruct request_sock *req,\r\nstruct sk_buff *skb)\r\n{\r\nstruct sock *newsk = inet_csk_clone_lock(sk, req, GFP_ATOMIC);\r\nif (newsk) {\r\nconst struct inet_request_sock *ireq = inet_rsk(req);\r\nstruct tcp_request_sock *treq = tcp_rsk(req);\r\nstruct inet_connection_sock *newicsk = inet_csk(newsk);\r\nstruct tcp_sock *newtp = tcp_sk(newsk);\r\nnewtp->pred_flags = 0;\r\nnewtp->rcv_wup = newtp->copied_seq =\r\nnewtp->rcv_nxt = treq->rcv_isn + 1;\r\nnewtp->segs_in = 1;\r\nnewtp->snd_sml = newtp->snd_una =\r\nnewtp->snd_nxt = newtp->snd_up = treq->snt_isn + 1;\r\ntcp_prequeue_init(newtp);\r\nINIT_LIST_HEAD(&newtp->tsq_node);\r\ntcp_init_wl(newtp, treq->rcv_isn);\r\nnewtp->srtt_us = 0;\r\nnewtp->mdev_us = jiffies_to_usecs(TCP_TIMEOUT_INIT);\r\nnewtp->rtt_min[0].rtt = ~0U;\r\nnewicsk->icsk_rto = TCP_TIMEOUT_INIT;\r\nnewtp->packets_out = 0;\r\nnewtp->retrans_out = 0;\r\nnewtp->sacked_out = 0;\r\nnewtp->fackets_out = 0;\r\nnewtp->snd_ssthresh = TCP_INFINITE_SSTHRESH;\r\ntcp_enable_early_retrans(newtp);\r\nnewtp->tlp_high_seq = 0;\r\nnewtp->lsndtime = treq->snt_synack.stamp_jiffies;\r\nnewsk->sk_txhash = treq->txhash;\r\nnewtp->last_oow_ack_time = 0;\r\nnewtp->total_retrans = req->num_retrans;\r\nnewtp->snd_cwnd = TCP_INIT_CWND;\r\nnewtp->snd_cwnd_cnt = 0;\r\ntcp_init_xmit_timers(newsk);\r\n__skb_queue_head_init(&newtp->out_of_order_queue);\r\nnewtp->write_seq = newtp->pushed_seq = treq->snt_isn + 1;\r\nnewtp->rx_opt.saw_tstamp = 0;\r\nnewtp->rx_opt.dsack = 0;\r\nnewtp->rx_opt.num_sacks = 0;\r\nnewtp->urg_data = 0;\r\nif (sock_flag(newsk, SOCK_KEEPOPEN))\r\ninet_csk_reset_keepalive_timer(newsk,\r\nkeepalive_time_when(newtp));\r\nnewtp->rx_opt.tstamp_ok = ireq->tstamp_ok;\r\nif ((newtp->rx_opt.sack_ok = ireq->sack_ok) != 0) {\r\nif (sysctl_tcp_fack)\r\ntcp_enable_fack(newtp);\r\n}\r\nnewtp->window_clamp = req->rsk_window_clamp;\r\nnewtp->rcv_ssthresh = req->rsk_rcv_wnd;\r\nnewtp->rcv_wnd = req->rsk_rcv_wnd;\r\nnewtp->rx_opt.wscale_ok = ireq->wscale_ok;\r\nif (newtp->rx_opt.wscale_ok) {\r\nnewtp->rx_opt.snd_wscale = ireq->snd_wscale;\r\nnewtp->rx_opt.rcv_wscale = ireq->rcv_wscale;\r\n} else {\r\nnewtp->rx_opt.snd_wscale = newtp->rx_opt.rcv_wscale = 0;\r\nnewtp->window_clamp = min(newtp->window_clamp, 65535U);\r\n}\r\nnewtp->snd_wnd = (ntohs(tcp_hdr(skb)->window) <<\r\nnewtp->rx_opt.snd_wscale);\r\nnewtp->max_window = newtp->snd_wnd;\r\nif (newtp->rx_opt.tstamp_ok) {\r\nnewtp->rx_opt.ts_recent = req->ts_recent;\r\nnewtp->rx_opt.ts_recent_stamp = get_seconds();\r\nnewtp->tcp_header_len = sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;\r\n} else {\r\nnewtp->rx_opt.ts_recent_stamp = 0;\r\nnewtp->tcp_header_len = sizeof(struct tcphdr);\r\n}\r\nnewtp->tsoffset = 0;\r\n#ifdef CONFIG_TCP_MD5SIG\r\nnewtp->md5sig_info = NULL;\r\nif (newtp->af_specific->md5_lookup(sk, newsk))\r\nnewtp->tcp_header_len += TCPOLEN_MD5SIG_ALIGNED;\r\n#endif\r\nif (skb->len >= TCP_MSS_DEFAULT + newtp->tcp_header_len)\r\nnewicsk->icsk_ack.last_seg_size = skb->len - newtp->tcp_header_len;\r\nnewtp->rx_opt.mss_clamp = req->mss;\r\ntcp_ecn_openreq_child(newtp, req);\r\nnewtp->fastopen_rsk = NULL;\r\nnewtp->syn_data_acked = 0;\r\nnewtp->rack.mstamp.v64 = 0;\r\nnewtp->rack.advanced = 0;\r\n__TCP_INC_STATS(sock_net(sk), TCP_MIB_PASSIVEOPENS);\r\n}\r\nreturn newsk;\r\n}\r\nstruct sock *tcp_check_req(struct sock *sk, struct sk_buff *skb,\r\nstruct request_sock *req,\r\nbool fastopen)\r\n{\r\nstruct tcp_options_received tmp_opt;\r\nstruct sock *child;\r\nconst struct tcphdr *th = tcp_hdr(skb);\r\n__be32 flg = tcp_flag_word(th) & (TCP_FLAG_RST|TCP_FLAG_SYN|TCP_FLAG_ACK);\r\nbool paws_reject = false;\r\nbool own_req;\r\ntmp_opt.saw_tstamp = 0;\r\nif (th->doff > (sizeof(struct tcphdr)>>2)) {\r\ntcp_parse_options(skb, &tmp_opt, 0, NULL);\r\nif (tmp_opt.saw_tstamp) {\r\ntmp_opt.ts_recent = req->ts_recent;\r\ntmp_opt.ts_recent_stamp = get_seconds() - ((TCP_TIMEOUT_INIT/HZ)<<req->num_timeout);\r\npaws_reject = tcp_paws_reject(&tmp_opt, th->rst);\r\n}\r\n}\r\nif (TCP_SKB_CB(skb)->seq == tcp_rsk(req)->rcv_isn &&\r\nflg == TCP_FLAG_SYN &&\r\n!paws_reject) {\r\nif (!tcp_oow_rate_limited(sock_net(sk), skb,\r\nLINUX_MIB_TCPACKSKIPPEDSYNRECV,\r\n&tcp_rsk(req)->last_oow_ack_time) &&\r\n!inet_rtx_syn_ack(sk, req)) {\r\nunsigned long expires = jiffies;\r\nexpires += min(TCP_TIMEOUT_INIT << req->num_timeout,\r\nTCP_RTO_MAX);\r\nif (!fastopen)\r\nmod_timer_pending(&req->rsk_timer, expires);\r\nelse\r\nreq->rsk_timer.expires = expires;\r\n}\r\nreturn NULL;\r\n}\r\nif ((flg & TCP_FLAG_ACK) && !fastopen &&\r\n(TCP_SKB_CB(skb)->ack_seq !=\r\ntcp_rsk(req)->snt_isn + 1))\r\nreturn sk;\r\nif (paws_reject || !tcp_in_window(TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq,\r\ntcp_rsk(req)->rcv_nxt, tcp_rsk(req)->rcv_nxt + req->rsk_rcv_wnd)) {\r\nif (!(flg & TCP_FLAG_RST) &&\r\n!tcp_oow_rate_limited(sock_net(sk), skb,\r\nLINUX_MIB_TCPACKSKIPPEDSYNRECV,\r\n&tcp_rsk(req)->last_oow_ack_time))\r\nreq->rsk_ops->send_ack(sk, skb, req);\r\nif (paws_reject)\r\n__NET_INC_STATS(sock_net(sk), LINUX_MIB_PAWSESTABREJECTED);\r\nreturn NULL;\r\n}\r\nif (tmp_opt.saw_tstamp && !after(TCP_SKB_CB(skb)->seq, tcp_rsk(req)->rcv_nxt))\r\nreq->ts_recent = tmp_opt.rcv_tsval;\r\nif (TCP_SKB_CB(skb)->seq == tcp_rsk(req)->rcv_isn) {\r\nflg &= ~TCP_FLAG_SYN;\r\n}\r\nif (flg & (TCP_FLAG_RST|TCP_FLAG_SYN)) {\r\n__TCP_INC_STATS(sock_net(sk), TCP_MIB_ATTEMPTFAILS);\r\ngoto embryonic_reset;\r\n}\r\nif (!(flg & TCP_FLAG_ACK))\r\nreturn NULL;\r\nif (fastopen)\r\nreturn sk;\r\nif (req->num_timeout < inet_csk(sk)->icsk_accept_queue.rskq_defer_accept &&\r\nTCP_SKB_CB(skb)->end_seq == tcp_rsk(req)->rcv_isn + 1) {\r\ninet_rsk(req)->acked = 1;\r\n__NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPDEFERACCEPTDROP);\r\nreturn NULL;\r\n}\r\nchild = inet_csk(sk)->icsk_af_ops->syn_recv_sock(sk, skb, req, NULL,\r\nreq, &own_req);\r\nif (!child)\r\ngoto listen_overflow;\r\nsock_rps_save_rxhash(child, skb);\r\ntcp_synack_rtt_meas(child, req);\r\nreturn inet_csk_complete_hashdance(sk, child, req, own_req);\r\nlisten_overflow:\r\nif (!sysctl_tcp_abort_on_overflow) {\r\ninet_rsk(req)->acked = 1;\r\nreturn NULL;\r\n}\r\nembryonic_reset:\r\nif (!(flg & TCP_FLAG_RST)) {\r\nreq->rsk_ops->send_reset(sk, skb);\r\n} else if (fastopen) {\r\nreqsk_fastopen_remove(sk, req, true);\r\ntcp_reset(sk);\r\n}\r\nif (!fastopen) {\r\ninet_csk_reqsk_queue_drop(sk, req);\r\n__NET_INC_STATS(sock_net(sk), LINUX_MIB_EMBRYONICRSTS);\r\n}\r\nreturn NULL;\r\n}\r\nint tcp_child_process(struct sock *parent, struct sock *child,\r\nstruct sk_buff *skb)\r\n{\r\nint ret = 0;\r\nint state = child->sk_state;\r\ntcp_segs_in(tcp_sk(child), skb);\r\nif (!sock_owned_by_user(child)) {\r\nret = tcp_rcv_state_process(child, skb);\r\nif (state == TCP_SYN_RECV && child->sk_state != state)\r\nparent->sk_data_ready(parent);\r\n} else {\r\n__sk_add_backlog(child, skb);\r\n}\r\nbh_unlock_sock(child);\r\nsock_put(child);\r\nreturn ret;\r\n}
