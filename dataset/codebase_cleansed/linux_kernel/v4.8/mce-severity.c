static int error_context(struct mce *m)\r\n{\r\nif ((m->cs & 3) == 3)\r\nreturn IN_USER;\r\nif (mc_recoverable(m->mcgstatus) && ex_has_fault_handler(m->ip))\r\nreturn IN_KERNEL_RECOV;\r\nreturn IN_KERNEL;\r\n}\r\nstatic int mce_severity_amd_smca(struct mce *m, int err_ctx)\r\n{\r\nu32 addr = MSR_AMD64_SMCA_MCx_CONFIG(m->bank);\r\nu32 low, high;\r\nif (!mce_flags.succor)\r\nreturn MCE_PANIC_SEVERITY;\r\nif (rdmsr_safe(addr, &low, &high))\r\nreturn MCE_PANIC_SEVERITY;\r\nif ((low & MCI_CONFIG_MCAX) &&\r\n(m->status & MCI_STATUS_TCC) &&\r\n(err_ctx == IN_KERNEL))\r\nreturn MCE_PANIC_SEVERITY;\r\nreturn MCE_AR_SEVERITY;\r\n}\r\nstatic int mce_severity_amd(struct mce *m, int tolerant, char **msg, bool is_excp)\r\n{\r\nenum context ctx = error_context(m);\r\nif (m->status & MCI_STATUS_PCC)\r\nreturn MCE_PANIC_SEVERITY;\r\nif (m->status & MCI_STATUS_UC) {\r\nif (mce_flags.overflow_recov) {\r\nif (mce_flags.smca)\r\nreturn mce_severity_amd_smca(m, ctx);\r\nif (!(m->mcgstatus & MCG_STATUS_RIPV) && (ctx == IN_KERNEL))\r\nreturn MCE_PANIC_SEVERITY;\r\nreturn MCE_AR_SEVERITY;\r\n} else {\r\nif (m->status & MCI_STATUS_OVER)\r\nreturn MCE_PANIC_SEVERITY;\r\n}\r\nreturn MCE_UC_SEVERITY;\r\n}\r\nif (m->status & MCI_STATUS_DEFERRED)\r\nreturn MCE_DEFERRED_SEVERITY;\r\nreturn MCE_KEEP_SEVERITY;\r\n}\r\nstatic int mce_severity_intel(struct mce *m, int tolerant, char **msg, bool is_excp)\r\n{\r\nenum exception excp = (is_excp ? EXCP_CONTEXT : NO_EXCP);\r\nenum context ctx = error_context(m);\r\nstruct severity *s;\r\nfor (s = severities;; s++) {\r\nif ((m->status & s->mask) != s->result)\r\ncontinue;\r\nif ((m->mcgstatus & s->mcgmask) != s->mcgres)\r\ncontinue;\r\nif (s->ser == SER_REQUIRED && !mca_cfg.ser)\r\ncontinue;\r\nif (s->ser == NO_SER && mca_cfg.ser)\r\ncontinue;\r\nif (s->context && ctx != s->context)\r\ncontinue;\r\nif (s->excp && excp != s->excp)\r\ncontinue;\r\nif (msg)\r\n*msg = s->msg;\r\ns->covered = 1;\r\nif (s->sev >= MCE_UC_SEVERITY && ctx == IN_KERNEL) {\r\nif (panic_on_oops || tolerant < 1)\r\nreturn MCE_PANIC_SEVERITY;\r\n}\r\nreturn s->sev;\r\n}\r\n}\r\nvoid __init mcheck_vendor_init_severity(void)\r\n{\r\nif (boot_cpu_data.x86_vendor == X86_VENDOR_AMD)\r\nmce_severity = mce_severity_amd;\r\n}\r\nstatic void *s_start(struct seq_file *f, loff_t *pos)\r\n{\r\nif (*pos >= ARRAY_SIZE(severities))\r\nreturn NULL;\r\nreturn &severities[*pos];\r\n}\r\nstatic void *s_next(struct seq_file *f, void *data, loff_t *pos)\r\n{\r\nif (++(*pos) >= ARRAY_SIZE(severities))\r\nreturn NULL;\r\nreturn &severities[*pos];\r\n}\r\nstatic void s_stop(struct seq_file *f, void *data)\r\n{\r\n}\r\nstatic int s_show(struct seq_file *f, void *data)\r\n{\r\nstruct severity *ser = data;\r\nseq_printf(f, "%d\t%s\n", ser->covered, ser->msg);\r\nreturn 0;\r\n}\r\nstatic int severities_coverage_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open(file, &severities_seq_ops);\r\n}\r\nstatic ssize_t severities_coverage_write(struct file *file,\r\nconst char __user *ubuf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(severities); i++)\r\nseverities[i].covered = 0;\r\nreturn count;\r\n}\r\nstatic int __init severities_debugfs_init(void)\r\n{\r\nstruct dentry *dmce, *fsev;\r\ndmce = mce_get_debugfs_dir();\r\nif (!dmce)\r\ngoto err_out;\r\nfsev = debugfs_create_file("severities-coverage", 0444, dmce, NULL,\r\n&severities_coverage_fops);\r\nif (!fsev)\r\ngoto err_out;\r\nreturn 0;\r\nerr_out:\r\nreturn -ENOMEM;\r\n}
