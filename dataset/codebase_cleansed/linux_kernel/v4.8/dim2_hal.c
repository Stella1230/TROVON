static inline u32 bit_mask(u8 position)\r\n{\r\nreturn (u32)1 << position;\r\n}\r\nstatic inline bool dim_on_error(u8 error_id, const char *error_message)\r\n{\r\ndimcb_on_error(error_id, error_message);\r\nreturn false;\r\n}\r\nstatic int dbr_get_mask_size(u16 size)\r\n{\r\nint i;\r\nfor (i = 0; i < 6; i++)\r\nif (size <= (DBR_BLOCK_SIZE << i))\r\nreturn 1 << i;\r\nreturn 0;\r\n}\r\nstatic int alloc_dbr(u16 size)\r\n{\r\nint mask_size;\r\nint i, block_idx = 0;\r\nif (size <= 0)\r\nreturn DBR_SIZE;\r\nmask_size = dbr_get_mask_size(size);\r\nif (mask_size == 0)\r\nreturn DBR_SIZE;\r\nfor (i = 0; i < DBR_MAP_SIZE; i++) {\r\nu32 const blocks = (size + DBR_BLOCK_SIZE - 1) / DBR_BLOCK_SIZE;\r\nu32 mask = ~((~(u32)0) << blocks);\r\ndo {\r\nif ((g.dbr_map[i] & mask) == 0) {\r\ng.dbr_map[i] |= mask;\r\nreturn block_idx * DBR_BLOCK_SIZE;\r\n}\r\nblock_idx += mask_size;\r\nmask <<= mask_size - 1;\r\n} while ((mask <<= 1) != 0);\r\n}\r\nreturn DBR_SIZE;\r\n}\r\nstatic void free_dbr(int offs, int size)\r\n{\r\nint block_idx = offs / DBR_BLOCK_SIZE;\r\nu32 const blocks = (size + DBR_BLOCK_SIZE - 1) / DBR_BLOCK_SIZE;\r\nu32 mask = ~((~(u32)0) << blocks);\r\nmask <<= block_idx % 32;\r\ng.dbr_map[block_idx / 32] &= ~mask;\r\n}\r\nstatic u32 dim2_read_ctr(u32 ctr_addr, u16 mdat_idx)\r\n{\r\ndimcb_io_write(&g.dim2->MADR, ctr_addr);\r\nwhile ((dimcb_io_read(&g.dim2->MCTL) & 1) != 1)\r\ncontinue;\r\ndimcb_io_write(&g.dim2->MCTL, 0);\r\nreturn dimcb_io_read((&g.dim2->MDAT0) + mdat_idx);\r\n}\r\nstatic void dim2_write_ctr_mask(u32 ctr_addr, const u32 *mask, const u32 *value)\r\n{\r\nenum { MADR_WNR_BIT = 31 };\r\ndimcb_io_write(&g.dim2->MCTL, 0);\r\nif (mask[0] != 0)\r\ndimcb_io_write(&g.dim2->MDAT0, value[0]);\r\nif (mask[1] != 0)\r\ndimcb_io_write(&g.dim2->MDAT1, value[1]);\r\nif (mask[2] != 0)\r\ndimcb_io_write(&g.dim2->MDAT2, value[2]);\r\nif (mask[3] != 0)\r\ndimcb_io_write(&g.dim2->MDAT3, value[3]);\r\ndimcb_io_write(&g.dim2->MDWE0, mask[0]);\r\ndimcb_io_write(&g.dim2->MDWE1, mask[1]);\r\ndimcb_io_write(&g.dim2->MDWE2, mask[2]);\r\ndimcb_io_write(&g.dim2->MDWE3, mask[3]);\r\ndimcb_io_write(&g.dim2->MADR, bit_mask(MADR_WNR_BIT) | ctr_addr);\r\nwhile ((dimcb_io_read(&g.dim2->MCTL) & 1) != 1)\r\ncontinue;\r\ndimcb_io_write(&g.dim2->MCTL, 0);\r\n}\r\nstatic inline void dim2_write_ctr(u32 ctr_addr, const u32 *value)\r\n{\r\nu32 const mask[4] = { 0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF };\r\ndim2_write_ctr_mask(ctr_addr, mask, value);\r\n}\r\nstatic inline void dim2_clear_ctr(u32 ctr_addr)\r\n{\r\nu32 const value[4] = { 0, 0, 0, 0 };\r\ndim2_write_ctr(ctr_addr, value);\r\n}\r\nstatic void dim2_configure_cat(u8 cat_base, u8 ch_addr, u8 ch_type,\r\nbool read_not_write, bool sync_mfe)\r\n{\r\nu16 const cat =\r\n(read_not_write << CAT_RNW_BIT) |\r\n(ch_type << CAT_CT_SHIFT) |\r\n(ch_addr << CAT_CL_SHIFT) |\r\n(sync_mfe << CAT_MFE_BIT) |\r\n(false << CAT_MT_BIT) |\r\n(true << CAT_CE_BIT);\r\nu8 const ctr_addr = cat_base + ch_addr / 8;\r\nu8 const idx = (ch_addr % 8) / 2;\r\nu8 const shift = (ch_addr % 2) * 16;\r\nu32 mask[4] = { 0, 0, 0, 0 };\r\nu32 value[4] = { 0, 0, 0, 0 };\r\nmask[idx] = (u32)0xFFFF << shift;\r\nvalue[idx] = cat << shift;\r\ndim2_write_ctr_mask(ctr_addr, mask, value);\r\n}\r\nstatic void dim2_clear_cat(u8 cat_base, u8 ch_addr)\r\n{\r\nu8 const ctr_addr = cat_base + ch_addr / 8;\r\nu8 const idx = (ch_addr % 8) / 2;\r\nu8 const shift = (ch_addr % 2) * 16;\r\nu32 mask[4] = { 0, 0, 0, 0 };\r\nu32 value[4] = { 0, 0, 0, 0 };\r\nmask[idx] = (u32)0xFFFF << shift;\r\ndim2_write_ctr_mask(ctr_addr, mask, value);\r\n}\r\nstatic void dim2_configure_cdt(u8 ch_addr, u16 dbr_address, u16 hw_buffer_size,\r\nu16 packet_length)\r\n{\r\nu32 cdt[4] = { 0, 0, 0, 0 };\r\nif (packet_length)\r\ncdt[1] = ((packet_length - 1) << CDT1_BS_ISOC_SHIFT);\r\ncdt[3] =\r\n((hw_buffer_size - 1) << CDT3_BD_SHIFT) |\r\n(dbr_address << CDT3_BA_SHIFT);\r\ndim2_write_ctr(CDT + ch_addr, cdt);\r\n}\r\nstatic void dim2_clear_cdt(u8 ch_addr)\r\n{\r\nu32 cdt[4] = { 0, 0, 0, 0 };\r\ndim2_write_ctr(CDT + ch_addr, cdt);\r\n}\r\nstatic void dim2_configure_adt(u8 ch_addr)\r\n{\r\nu32 adt[4] = { 0, 0, 0, 0 };\r\nadt[0] =\r\n(true << ADT0_CE_BIT) |\r\n(true << ADT0_LE_BIT) |\r\n(0 << ADT0_PG_BIT);\r\ndim2_write_ctr(ADT + ch_addr, adt);\r\n}\r\nstatic void dim2_clear_adt(u8 ch_addr)\r\n{\r\nu32 adt[4] = { 0, 0, 0, 0 };\r\ndim2_write_ctr(ADT + ch_addr, adt);\r\n}\r\nstatic void dim2_start_ctrl_async(u8 ch_addr, u8 idx, u32 buf_addr,\r\nu16 buffer_size)\r\n{\r\nu8 const shift = idx * 16;\r\nu32 mask[4] = { 0, 0, 0, 0 };\r\nu32 adt[4] = { 0, 0, 0, 0 };\r\nmask[1] =\r\nbit_mask(ADT1_PS_BIT + shift) |\r\nbit_mask(ADT1_RDY_BIT + shift) |\r\n(ADT1_CTRL_ASYNC_BD_MASK << (ADT1_BD_SHIFT + shift));\r\nadt[1] =\r\n(true << (ADT1_PS_BIT + shift)) |\r\n(true << (ADT1_RDY_BIT + shift)) |\r\n((buffer_size - 1) << (ADT1_BD_SHIFT + shift));\r\nmask[idx + 2] = 0xFFFFFFFF;\r\nadt[idx + 2] = buf_addr;\r\ndim2_write_ctr_mask(ADT + ch_addr, mask, adt);\r\n}\r\nstatic void dim2_start_isoc_sync(u8 ch_addr, u8 idx, u32 buf_addr,\r\nu16 buffer_size)\r\n{\r\nu8 const shift = idx * 16;\r\nu32 mask[4] = { 0, 0, 0, 0 };\r\nu32 adt[4] = { 0, 0, 0, 0 };\r\nmask[1] =\r\nbit_mask(ADT1_RDY_BIT + shift) |\r\n(ADT1_ISOC_SYNC_BD_MASK << (ADT1_BD_SHIFT + shift));\r\nadt[1] =\r\n(true << (ADT1_RDY_BIT + shift)) |\r\n((buffer_size - 1) << (ADT1_BD_SHIFT + shift));\r\nmask[idx + 2] = 0xFFFFFFFF;\r\nadt[idx + 2] = buf_addr;\r\ndim2_write_ctr_mask(ADT + ch_addr, mask, adt);\r\n}\r\nstatic void dim2_clear_ctram(void)\r\n{\r\nu32 ctr_addr;\r\nfor (ctr_addr = 0; ctr_addr < 0x90; ctr_addr++)\r\ndim2_clear_ctr(ctr_addr);\r\n}\r\nstatic void dim2_configure_channel(\r\nu8 ch_addr, u8 type, u8 is_tx, u16 dbr_address, u16 hw_buffer_size,\r\nu16 packet_length, bool sync_mfe)\r\n{\r\ndim2_configure_cdt(ch_addr, dbr_address, hw_buffer_size, packet_length);\r\ndim2_configure_cat(MLB_CAT, ch_addr, type, is_tx ? 1 : 0, sync_mfe);\r\ndim2_configure_adt(ch_addr);\r\ndim2_configure_cat(AHB_CAT, ch_addr, type, is_tx ? 0 : 1, sync_mfe);\r\ndimcb_io_write(&g.dim2->ACMR0,\r\ndimcb_io_read(&g.dim2->ACMR0) | bit_mask(ch_addr));\r\n}\r\nstatic void dim2_clear_channel(u8 ch_addr)\r\n{\r\ndimcb_io_write(&g.dim2->ACMR0,\r\ndimcb_io_read(&g.dim2->ACMR0) & ~bit_mask(ch_addr));\r\ndim2_clear_cat(AHB_CAT, ch_addr);\r\ndim2_clear_adt(ch_addr);\r\ndim2_clear_cat(MLB_CAT, ch_addr);\r\ndim2_clear_cdt(ch_addr);\r\n}\r\nstatic void state_init(struct int_ch_state *state)\r\n{\r\nstate->request_counter = 0;\r\nstate->service_counter = 0;\r\nstate->idx1 = 0;\r\nstate->idx2 = 0;\r\nstate->level = 0;\r\n}\r\nstatic inline bool check_channel_address(u32 ch_address)\r\n{\r\nreturn ch_address > 0 && (ch_address % 2) == 0 &&\r\n(ch_address / 2) <= (u32)CAT_CL_MASK;\r\n}\r\nstatic inline bool check_packet_length(u32 packet_length)\r\n{\r\nu16 const max_size = ((u16)CDT3_BD_ISOC_MASK + 1u) / ISOC_DBR_FACTOR;\r\nif (packet_length <= 0)\r\nreturn false;\r\nif (packet_length > max_size)\r\nreturn false;\r\nif (packet_length - 1u > (u32)CDT1_BS_ISOC_MASK)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic inline bool check_bytes_per_frame(u32 bytes_per_frame)\r\n{\r\nu16 const max_size = ((u16)CDT3_BD_MASK + 1u) / SYNC_DBR_FACTOR;\r\nif (bytes_per_frame <= 0)\r\nreturn false;\r\nif (bytes_per_frame > max_size)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic inline u16 norm_ctrl_async_buffer_size(u16 buf_size)\r\n{\r\nu16 const max_size = (u16)ADT1_CTRL_ASYNC_BD_MASK + 1u;\r\nif (buf_size > max_size)\r\nreturn max_size;\r\nreturn buf_size;\r\n}\r\nstatic inline u16 norm_isoc_buffer_size(u16 buf_size, u16 packet_length)\r\n{\r\nu16 n;\r\nu16 const max_size = (u16)ADT1_ISOC_SYNC_BD_MASK + 1u;\r\nif (buf_size > max_size)\r\nbuf_size = max_size;\r\nn = buf_size / packet_length;\r\nif (n < 2u)\r\nreturn 0;\r\nreturn packet_length * n;\r\n}\r\nstatic inline u16 norm_sync_buffer_size(u16 buf_size, u16 bytes_per_frame)\r\n{\r\nu16 n;\r\nu16 const max_size = (u16)ADT1_ISOC_SYNC_BD_MASK + 1u;\r\nu32 const unit = bytes_per_frame * (u16)FRAMES_PER_SUBBUFF;\r\nif (buf_size > max_size)\r\nbuf_size = max_size;\r\nn = buf_size / unit;\r\nif (n < 1u)\r\nreturn 0;\r\nreturn unit * n;\r\n}\r\nstatic void dim2_cleanup(void)\r\n{\r\ndimcb_io_write(&g.dim2->MLBC0, false << MLBC0_MLBEN_BIT);\r\ndim2_clear_ctram();\r\ndimcb_io_write(&g.dim2->MIEN, 0);\r\ndimcb_io_write(&g.dim2->ACSR0, 0xFFFFFFFF);\r\ndimcb_io_write(&g.dim2->ACSR1, 0xFFFFFFFF);\r\ndimcb_io_write(&g.dim2->ACMR0, 0);\r\ndimcb_io_write(&g.dim2->ACMR1, 0);\r\n}\r\nstatic void dim2_initialize(bool enable_6pin, u8 mlb_clock)\r\n{\r\ndim2_cleanup();\r\ndimcb_io_write(&g.dim2->MLBC0,\r\nenable_6pin << MLBC0_MLBPEN_BIT |\r\nmlb_clock << MLBC0_MLBCLK_SHIFT |\r\nMLBC0_FCNT_VAL(FRAMES_PER_SUBBUFF) << MLBC0_FCNT_SHIFT |\r\ntrue << MLBC0_MLBEN_BIT);\r\ndimcb_io_write(&g.dim2->HCMR0, 0xFFFFFFFF);\r\ndimcb_io_write(&g.dim2->HCMR1, 0xFFFFFFFF);\r\ndimcb_io_write(&g.dim2->HCTL, bit_mask(HCTL_EN_BIT));\r\ndimcb_io_write(&g.dim2->ACTL,\r\nACTL_DMA_MODE_VAL_DMA_MODE_1 << ACTL_DMA_MODE_BIT |\r\ntrue << ACTL_SCE_BIT);\r\n}\r\nstatic bool dim2_is_mlb_locked(void)\r\n{\r\nu32 const mask0 = bit_mask(MLBC0_MLBLK_BIT);\r\nu32 const mask1 = bit_mask(MLBC1_CLKMERR_BIT) |\r\nbit_mask(MLBC1_LOCKERR_BIT);\r\nu32 const c1 = dimcb_io_read(&g.dim2->MLBC1);\r\nu32 const nda_mask = (u32)MLBC1_NDA_MASK << MLBC1_NDA_SHIFT;\r\ndimcb_io_write(&g.dim2->MLBC1, c1 & nda_mask);\r\nreturn (dimcb_io_read(&g.dim2->MLBC1) & mask1) == 0 &&\r\n(dimcb_io_read(&g.dim2->MLBC0) & mask0) != 0;\r\n}\r\nstatic inline bool service_channel(u8 ch_addr, u8 idx)\r\n{\r\nu8 const shift = idx * 16;\r\nu32 const adt1 = dim2_read_ctr(ADT + ch_addr, 1);\r\nif (((adt1 >> (ADT1_DNE_BIT + shift)) & 1) == 0)\r\nreturn false;\r\n{\r\nu32 mask[4] = { 0, 0, 0, 0 };\r\nu32 adt_w[4] = { 0, 0, 0, 0 };\r\nmask[1] =\r\nbit_mask(ADT1_DNE_BIT + shift) |\r\nbit_mask(ADT1_ERR_BIT + shift) |\r\nbit_mask(ADT1_RDY_BIT + shift);\r\ndim2_write_ctr_mask(ADT + ch_addr, mask, adt_w);\r\n}\r\ndimcb_io_write(&g.dim2->ACSR0, bit_mask(ch_addr));\r\nreturn true;\r\n}\r\nstatic void isoc_init(struct dim_channel *ch, u8 ch_addr, u16 packet_length)\r\n{\r\nstate_init(&ch->state);\r\nch->addr = ch_addr;\r\nch->packet_length = packet_length;\r\nch->bytes_per_frame = 0;\r\nch->done_sw_buffers_number = 0;\r\n}\r\nstatic void sync_init(struct dim_channel *ch, u8 ch_addr, u16 bytes_per_frame)\r\n{\r\nstate_init(&ch->state);\r\nch->addr = ch_addr;\r\nch->packet_length = 0;\r\nch->bytes_per_frame = bytes_per_frame;\r\nch->done_sw_buffers_number = 0;\r\n}\r\nstatic void channel_init(struct dim_channel *ch, u8 ch_addr)\r\n{\r\nstate_init(&ch->state);\r\nch->addr = ch_addr;\r\nch->packet_length = 0;\r\nch->bytes_per_frame = 0;\r\nch->done_sw_buffers_number = 0;\r\n}\r\nstatic bool channel_service_interrupt(struct dim_channel *ch)\r\n{\r\nstruct int_ch_state *const state = &ch->state;\r\nif (!service_channel(ch->addr, state->idx2))\r\nreturn false;\r\nstate->idx2 ^= 1;\r\nstate->request_counter++;\r\nreturn true;\r\n}\r\nstatic bool channel_start(struct dim_channel *ch, u32 buf_addr, u16 buf_size)\r\n{\r\nstruct int_ch_state *const state = &ch->state;\r\nif (buf_size <= 0)\r\nreturn dim_on_error(DIM_ERR_BAD_BUFFER_SIZE, "Bad buffer size");\r\nif (ch->packet_length == 0 && ch->bytes_per_frame == 0 &&\r\nbuf_size != norm_ctrl_async_buffer_size(buf_size))\r\nreturn dim_on_error(DIM_ERR_BAD_BUFFER_SIZE,\r\n"Bad control/async buffer size");\r\nif (ch->packet_length &&\r\nbuf_size != norm_isoc_buffer_size(buf_size, ch->packet_length))\r\nreturn dim_on_error(DIM_ERR_BAD_BUFFER_SIZE,\r\n"Bad isochronous buffer size");\r\nif (ch->bytes_per_frame &&\r\nbuf_size != norm_sync_buffer_size(buf_size, ch->bytes_per_frame))\r\nreturn dim_on_error(DIM_ERR_BAD_BUFFER_SIZE,\r\n"Bad synchronous buffer size");\r\nif (state->level >= 2u)\r\nreturn dim_on_error(DIM_ERR_OVERFLOW, "Channel overflow");\r\n++state->level;\r\nif (ch->packet_length || ch->bytes_per_frame)\r\ndim2_start_isoc_sync(ch->addr, state->idx1, buf_addr, buf_size);\r\nelse\r\ndim2_start_ctrl_async(ch->addr, state->idx1, buf_addr,\r\nbuf_size);\r\nstate->idx1 ^= 1;\r\nreturn true;\r\n}\r\nstatic u8 channel_service(struct dim_channel *ch)\r\n{\r\nstruct int_ch_state *const state = &ch->state;\r\nif (state->service_counter != state->request_counter) {\r\nstate->service_counter++;\r\nif (state->level == 0)\r\nreturn DIM_ERR_UNDERFLOW;\r\n--state->level;\r\nch->done_sw_buffers_number++;\r\n}\r\nreturn DIM_NO_ERROR;\r\n}\r\nstatic bool channel_detach_buffers(struct dim_channel *ch, u16 buffers_number)\r\n{\r\nif (buffers_number > ch->done_sw_buffers_number)\r\nreturn dim_on_error(DIM_ERR_UNDERFLOW, "Channel underflow");\r\nch->done_sw_buffers_number -= buffers_number;\r\nreturn true;\r\n}\r\nu8 dim_startup(struct dim2_regs __iomem *dim_base_address, u32 mlb_clock)\r\n{\r\ng.dim_is_initialized = false;\r\nif (!dim_base_address)\r\nreturn DIM_INIT_ERR_DIM_ADDR;\r\nif (mlb_clock >= 8)\r\nreturn DIM_INIT_ERR_MLB_CLOCK;\r\ng.dim2 = dim_base_address;\r\ng.dbr_map[0] = 0;\r\ng.dbr_map[1] = 0;\r\ndim2_initialize(mlb_clock >= 3, mlb_clock);\r\ng.dim_is_initialized = true;\r\nreturn DIM_NO_ERROR;\r\n}\r\nvoid dim_shutdown(void)\r\n{\r\ng.dim_is_initialized = false;\r\ndim2_cleanup();\r\n}\r\nbool dim_get_lock_state(void)\r\n{\r\nreturn dim2_is_mlb_locked();\r\n}\r\nstatic u8 init_ctrl_async(struct dim_channel *ch, u8 type, u8 is_tx,\r\nu16 ch_address, u16 hw_buffer_size)\r\n{\r\nif (!g.dim_is_initialized || !ch)\r\nreturn DIM_ERR_DRIVER_NOT_INITIALIZED;\r\nif (!check_channel_address(ch_address))\r\nreturn DIM_INIT_ERR_CHANNEL_ADDRESS;\r\nch->dbr_size = hw_buffer_size;\r\nch->dbr_addr = alloc_dbr(ch->dbr_size);\r\nif (ch->dbr_addr >= DBR_SIZE)\r\nreturn DIM_INIT_ERR_OUT_OF_MEMORY;\r\nchannel_init(ch, ch_address / 2);\r\ndim2_configure_channel(ch->addr, type, is_tx,\r\nch->dbr_addr, ch->dbr_size, 0, false);\r\nreturn DIM_NO_ERROR;\r\n}\r\nu16 dim_norm_ctrl_async_buffer_size(u16 buf_size)\r\n{\r\nreturn norm_ctrl_async_buffer_size(buf_size);\r\n}\r\nu16 dim_norm_isoc_buffer_size(u16 buf_size, u16 packet_length)\r\n{\r\nif (!check_packet_length(packet_length))\r\nreturn 0;\r\nreturn norm_isoc_buffer_size(buf_size, packet_length);\r\n}\r\nu16 dim_norm_sync_buffer_size(u16 buf_size, u16 bytes_per_frame)\r\n{\r\nif (!check_bytes_per_frame(bytes_per_frame))\r\nreturn 0;\r\nreturn norm_sync_buffer_size(buf_size, bytes_per_frame);\r\n}\r\nu8 dim_init_control(struct dim_channel *ch, u8 is_tx, u16 ch_address,\r\nu16 max_buffer_size)\r\n{\r\nreturn init_ctrl_async(ch, CAT_CT_VAL_CONTROL, is_tx, ch_address,\r\nmax_buffer_size);\r\n}\r\nu8 dim_init_async(struct dim_channel *ch, u8 is_tx, u16 ch_address,\r\nu16 max_buffer_size)\r\n{\r\nreturn init_ctrl_async(ch, CAT_CT_VAL_ASYNC, is_tx, ch_address,\r\nmax_buffer_size);\r\n}\r\nu8 dim_init_isoc(struct dim_channel *ch, u8 is_tx, u16 ch_address,\r\nu16 packet_length)\r\n{\r\nif (!g.dim_is_initialized || !ch)\r\nreturn DIM_ERR_DRIVER_NOT_INITIALIZED;\r\nif (!check_channel_address(ch_address))\r\nreturn DIM_INIT_ERR_CHANNEL_ADDRESS;\r\nif (!check_packet_length(packet_length))\r\nreturn DIM_ERR_BAD_CONFIG;\r\nch->dbr_size = packet_length * ISOC_DBR_FACTOR;\r\nch->dbr_addr = alloc_dbr(ch->dbr_size);\r\nif (ch->dbr_addr >= DBR_SIZE)\r\nreturn DIM_INIT_ERR_OUT_OF_MEMORY;\r\nisoc_init(ch, ch_address / 2, packet_length);\r\ndim2_configure_channel(ch->addr, CAT_CT_VAL_ISOC, is_tx, ch->dbr_addr,\r\nch->dbr_size, packet_length, false);\r\nreturn DIM_NO_ERROR;\r\n}\r\nu8 dim_init_sync(struct dim_channel *ch, u8 is_tx, u16 ch_address,\r\nu16 bytes_per_frame)\r\n{\r\nif (!g.dim_is_initialized || !ch)\r\nreturn DIM_ERR_DRIVER_NOT_INITIALIZED;\r\nif (!check_channel_address(ch_address))\r\nreturn DIM_INIT_ERR_CHANNEL_ADDRESS;\r\nif (!check_bytes_per_frame(bytes_per_frame))\r\nreturn DIM_ERR_BAD_CONFIG;\r\nch->dbr_size = bytes_per_frame * SYNC_DBR_FACTOR;\r\nch->dbr_addr = alloc_dbr(ch->dbr_size);\r\nif (ch->dbr_addr >= DBR_SIZE)\r\nreturn DIM_INIT_ERR_OUT_OF_MEMORY;\r\nsync_init(ch, ch_address / 2, bytes_per_frame);\r\ndim2_configure_channel(ch->addr, CAT_CT_VAL_SYNC, is_tx,\r\nch->dbr_addr, ch->dbr_size, 0, true);\r\nreturn DIM_NO_ERROR;\r\n}\r\nu8 dim_destroy_channel(struct dim_channel *ch)\r\n{\r\nif (!g.dim_is_initialized || !ch)\r\nreturn DIM_ERR_DRIVER_NOT_INITIALIZED;\r\ndim2_clear_channel(ch->addr);\r\nif (ch->dbr_addr < DBR_SIZE)\r\nfree_dbr(ch->dbr_addr, ch->dbr_size);\r\nch->dbr_addr = DBR_SIZE;\r\nreturn DIM_NO_ERROR;\r\n}\r\nvoid dim_service_irq(struct dim_channel *const *channels)\r\n{\r\nbool state_changed;\r\nif (!g.dim_is_initialized) {\r\ndim_on_error(DIM_ERR_DRIVER_NOT_INITIALIZED,\r\n"DIM is not initialized");\r\nreturn;\r\n}\r\nif (!channels) {\r\ndim_on_error(DIM_ERR_DRIVER_NOT_INITIALIZED, "Bad channels");\r\nreturn;\r\n}\r\ndo {\r\nstruct dim_channel *const *ch = channels;\r\nstate_changed = false;\r\nwhile (*ch) {\r\nstate_changed |= channel_service_interrupt(*ch);\r\n++ch;\r\n}\r\n} while (state_changed);\r\ndimcb_io_write(&g.dim2->MS0, 0);\r\ndimcb_io_write(&g.dim2->MS1, 0);\r\n}\r\nu8 dim_service_channel(struct dim_channel *ch)\r\n{\r\nif (!g.dim_is_initialized || !ch)\r\nreturn DIM_ERR_DRIVER_NOT_INITIALIZED;\r\nreturn channel_service(ch);\r\n}\r\nstruct dim_ch_state_t *dim_get_channel_state(struct dim_channel *ch,\r\nstruct dim_ch_state_t *state_ptr)\r\n{\r\nif (!ch || !state_ptr)\r\nreturn NULL;\r\nstate_ptr->ready = ch->state.level < 2;\r\nstate_ptr->done_buffers = ch->done_sw_buffers_number;\r\nreturn state_ptr;\r\n}\r\nbool dim_enqueue_buffer(struct dim_channel *ch, u32 buffer_addr,\r\nu16 buffer_size)\r\n{\r\nif (!ch)\r\nreturn dim_on_error(DIM_ERR_DRIVER_NOT_INITIALIZED,\r\n"Bad channel");\r\nreturn channel_start(ch, buffer_addr, buffer_size);\r\n}\r\nbool dim_detach_buffers(struct dim_channel *ch, u16 buffers_number)\r\n{\r\nif (!ch)\r\nreturn dim_on_error(DIM_ERR_DRIVER_NOT_INITIALIZED,\r\n"Bad channel");\r\nreturn channel_detach_buffers(ch, buffers_number);\r\n}
