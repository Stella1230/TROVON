static bool r100_is_in_vblank(struct radeon_device *rdev, int crtc)\r\n{\r\nif (crtc == 0) {\r\nif (RREG32(RADEON_CRTC_STATUS) & RADEON_CRTC_VBLANK_CUR)\r\nreturn true;\r\nelse\r\nreturn false;\r\n} else {\r\nif (RREG32(RADEON_CRTC2_STATUS) & RADEON_CRTC2_VBLANK_CUR)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\n}\r\nstatic bool r100_is_counter_moving(struct radeon_device *rdev, int crtc)\r\n{\r\nu32 vline1, vline2;\r\nif (crtc == 0) {\r\nvline1 = (RREG32(RADEON_CRTC_VLINE_CRNT_VLINE) >> 16) & RADEON_CRTC_V_TOTAL;\r\nvline2 = (RREG32(RADEON_CRTC_VLINE_CRNT_VLINE) >> 16) & RADEON_CRTC_V_TOTAL;\r\n} else {\r\nvline1 = (RREG32(RADEON_CRTC2_VLINE_CRNT_VLINE) >> 16) & RADEON_CRTC_V_TOTAL;\r\nvline2 = (RREG32(RADEON_CRTC2_VLINE_CRNT_VLINE) >> 16) & RADEON_CRTC_V_TOTAL;\r\n}\r\nif (vline1 != vline2)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nvoid r100_wait_for_vblank(struct radeon_device *rdev, int crtc)\r\n{\r\nunsigned i = 0;\r\nif (crtc >= rdev->num_crtc)\r\nreturn;\r\nif (crtc == 0) {\r\nif (!(RREG32(RADEON_CRTC_GEN_CNTL) & RADEON_CRTC_EN))\r\nreturn;\r\n} else {\r\nif (!(RREG32(RADEON_CRTC2_GEN_CNTL) & RADEON_CRTC2_EN))\r\nreturn;\r\n}\r\nwhile (r100_is_in_vblank(rdev, crtc)) {\r\nif (i++ % 100 == 0) {\r\nif (!r100_is_counter_moving(rdev, crtc))\r\nbreak;\r\n}\r\n}\r\nwhile (!r100_is_in_vblank(rdev, crtc)) {\r\nif (i++ % 100 == 0) {\r\nif (!r100_is_counter_moving(rdev, crtc))\r\nbreak;\r\n}\r\n}\r\n}\r\nvoid r100_page_flip(struct radeon_device *rdev, int crtc_id, u64 crtc_base, bool async)\r\n{\r\nstruct radeon_crtc *radeon_crtc = rdev->mode_info.crtcs[crtc_id];\r\nu32 tmp = ((u32)crtc_base) | RADEON_CRTC_OFFSET__OFFSET_LOCK;\r\nint i;\r\nWREG32(RADEON_CRTC_OFFSET + radeon_crtc->crtc_offset, tmp);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\nif (RREG32(RADEON_CRTC_OFFSET + radeon_crtc->crtc_offset) & RADEON_CRTC_OFFSET__GUI_TRIG_OFFSET)\r\nbreak;\r\nudelay(1);\r\n}\r\nDRM_DEBUG("Update pending now high. Unlocking vupdate_lock.\n");\r\ntmp &= ~RADEON_CRTC_OFFSET__OFFSET_LOCK;\r\nWREG32(RADEON_CRTC_OFFSET + radeon_crtc->crtc_offset, tmp);\r\n}\r\nbool r100_page_flip_pending(struct radeon_device *rdev, int crtc_id)\r\n{\r\nstruct radeon_crtc *radeon_crtc = rdev->mode_info.crtcs[crtc_id];\r\nreturn !!(RREG32(RADEON_CRTC_OFFSET + radeon_crtc->crtc_offset) &\r\nRADEON_CRTC_OFFSET__GUI_TRIG_OFFSET);\r\n}\r\nvoid r100_pm_get_dynpm_state(struct radeon_device *rdev)\r\n{\r\nint i;\r\nrdev->pm.dynpm_can_upclock = true;\r\nrdev->pm.dynpm_can_downclock = true;\r\nswitch (rdev->pm.dynpm_planned_action) {\r\ncase DYNPM_ACTION_MINIMUM:\r\nrdev->pm.requested_power_state_index = 0;\r\nrdev->pm.dynpm_can_downclock = false;\r\nbreak;\r\ncase DYNPM_ACTION_DOWNCLOCK:\r\nif (rdev->pm.current_power_state_index == 0) {\r\nrdev->pm.requested_power_state_index = rdev->pm.current_power_state_index;\r\nrdev->pm.dynpm_can_downclock = false;\r\n} else {\r\nif (rdev->pm.active_crtc_count > 1) {\r\nfor (i = 0; i < rdev->pm.num_power_states; i++) {\r\nif (rdev->pm.power_state[i].flags & RADEON_PM_STATE_SINGLE_DISPLAY_ONLY)\r\ncontinue;\r\nelse if (i >= rdev->pm.current_power_state_index) {\r\nrdev->pm.requested_power_state_index = rdev->pm.current_power_state_index;\r\nbreak;\r\n} else {\r\nrdev->pm.requested_power_state_index = i;\r\nbreak;\r\n}\r\n}\r\n} else\r\nrdev->pm.requested_power_state_index =\r\nrdev->pm.current_power_state_index - 1;\r\n}\r\nif ((rdev->pm.active_crtc_count > 0) &&\r\n(rdev->pm.power_state[rdev->pm.requested_power_state_index].clock_info[0].flags &\r\nRADEON_PM_MODE_NO_DISPLAY)) {\r\nrdev->pm.requested_power_state_index++;\r\n}\r\nbreak;\r\ncase DYNPM_ACTION_UPCLOCK:\r\nif (rdev->pm.current_power_state_index == (rdev->pm.num_power_states - 1)) {\r\nrdev->pm.requested_power_state_index = rdev->pm.current_power_state_index;\r\nrdev->pm.dynpm_can_upclock = false;\r\n} else {\r\nif (rdev->pm.active_crtc_count > 1) {\r\nfor (i = (rdev->pm.num_power_states - 1); i >= 0; i--) {\r\nif (rdev->pm.power_state[i].flags & RADEON_PM_STATE_SINGLE_DISPLAY_ONLY)\r\ncontinue;\r\nelse if (i <= rdev->pm.current_power_state_index) {\r\nrdev->pm.requested_power_state_index = rdev->pm.current_power_state_index;\r\nbreak;\r\n} else {\r\nrdev->pm.requested_power_state_index = i;\r\nbreak;\r\n}\r\n}\r\n} else\r\nrdev->pm.requested_power_state_index =\r\nrdev->pm.current_power_state_index + 1;\r\n}\r\nbreak;\r\ncase DYNPM_ACTION_DEFAULT:\r\nrdev->pm.requested_power_state_index = rdev->pm.default_power_state_index;\r\nrdev->pm.dynpm_can_upclock = false;\r\nbreak;\r\ncase DYNPM_ACTION_NONE:\r\ndefault:\r\nDRM_ERROR("Requested mode for not defined action\n");\r\nreturn;\r\n}\r\nrdev->pm.requested_clock_mode_index = 0;\r\nDRM_DEBUG_DRIVER("Requested: e: %d m: %d p: %d\n",\r\nrdev->pm.power_state[rdev->pm.requested_power_state_index].\r\nclock_info[rdev->pm.requested_clock_mode_index].sclk,\r\nrdev->pm.power_state[rdev->pm.requested_power_state_index].\r\nclock_info[rdev->pm.requested_clock_mode_index].mclk,\r\nrdev->pm.power_state[rdev->pm.requested_power_state_index].\r\npcie_lanes);\r\n}\r\nvoid r100_pm_init_profile(struct radeon_device *rdev)\r\n{\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 0;\r\n}\r\nvoid r100_pm_misc(struct radeon_device *rdev)\r\n{\r\nint requested_index = rdev->pm.requested_power_state_index;\r\nstruct radeon_power_state *ps = &rdev->pm.power_state[requested_index];\r\nstruct radeon_voltage *voltage = &ps->clock_info[0].voltage;\r\nu32 tmp, sclk_cntl, sclk_cntl2, sclk_more_cntl;\r\nif ((voltage->type == VOLTAGE_GPIO) && (voltage->gpio.valid)) {\r\nif (ps->misc & ATOM_PM_MISCINFO_VOLTAGE_DROP_SUPPORT) {\r\ntmp = RREG32(voltage->gpio.reg);\r\nif (voltage->active_high)\r\ntmp |= voltage->gpio.mask;\r\nelse\r\ntmp &= ~(voltage->gpio.mask);\r\nWREG32(voltage->gpio.reg, tmp);\r\nif (voltage->delay)\r\nudelay(voltage->delay);\r\n} else {\r\ntmp = RREG32(voltage->gpio.reg);\r\nif (voltage->active_high)\r\ntmp &= ~voltage->gpio.mask;\r\nelse\r\ntmp |= voltage->gpio.mask;\r\nWREG32(voltage->gpio.reg, tmp);\r\nif (voltage->delay)\r\nudelay(voltage->delay);\r\n}\r\n}\r\nsclk_cntl = RREG32_PLL(SCLK_CNTL);\r\nsclk_cntl2 = RREG32_PLL(SCLK_CNTL2);\r\nsclk_cntl2 &= ~REDUCED_SPEED_SCLK_SEL(3);\r\nsclk_more_cntl = RREG32_PLL(SCLK_MORE_CNTL);\r\nsclk_more_cntl &= ~VOLTAGE_DELAY_SEL(3);\r\nif (ps->misc & ATOM_PM_MISCINFO_ASIC_REDUCED_SPEED_SCLK_EN) {\r\nsclk_more_cntl |= REDUCED_SPEED_SCLK_EN;\r\nif (ps->misc & ATOM_PM_MISCINFO_DYN_CLK_3D_IDLE)\r\nsclk_cntl2 |= REDUCED_SPEED_SCLK_MODE;\r\nelse\r\nsclk_cntl2 &= ~REDUCED_SPEED_SCLK_MODE;\r\nif (ps->misc & ATOM_PM_MISCINFO_DYNAMIC_CLOCK_DIVIDER_BY_2)\r\nsclk_cntl2 |= REDUCED_SPEED_SCLK_SEL(0);\r\nelse if (ps->misc & ATOM_PM_MISCINFO_DYNAMIC_CLOCK_DIVIDER_BY_4)\r\nsclk_cntl2 |= REDUCED_SPEED_SCLK_SEL(2);\r\n} else\r\nsclk_more_cntl &= ~REDUCED_SPEED_SCLK_EN;\r\nif (ps->misc & ATOM_PM_MISCINFO_ASIC_DYNAMIC_VOLTAGE_EN) {\r\nsclk_more_cntl |= IO_CG_VOLTAGE_DROP;\r\nif (voltage->delay) {\r\nsclk_more_cntl |= VOLTAGE_DROP_SYNC;\r\nswitch (voltage->delay) {\r\ncase 33:\r\nsclk_more_cntl |= VOLTAGE_DELAY_SEL(0);\r\nbreak;\r\ncase 66:\r\nsclk_more_cntl |= VOLTAGE_DELAY_SEL(1);\r\nbreak;\r\ncase 99:\r\nsclk_more_cntl |= VOLTAGE_DELAY_SEL(2);\r\nbreak;\r\ncase 132:\r\nsclk_more_cntl |= VOLTAGE_DELAY_SEL(3);\r\nbreak;\r\n}\r\n} else\r\nsclk_more_cntl &= ~VOLTAGE_DROP_SYNC;\r\n} else\r\nsclk_more_cntl &= ~IO_CG_VOLTAGE_DROP;\r\nif (ps->misc & ATOM_PM_MISCINFO_DYNAMIC_HDP_BLOCK_EN)\r\nsclk_cntl &= ~FORCE_HDP;\r\nelse\r\nsclk_cntl |= FORCE_HDP;\r\nWREG32_PLL(SCLK_CNTL, sclk_cntl);\r\nWREG32_PLL(SCLK_CNTL2, sclk_cntl2);\r\nWREG32_PLL(SCLK_MORE_CNTL, sclk_more_cntl);\r\nif ((rdev->flags & RADEON_IS_PCIE) &&\r\n!(rdev->flags & RADEON_IS_IGP) &&\r\nrdev->asic->pm.set_pcie_lanes &&\r\n(ps->pcie_lanes !=\r\nrdev->pm.power_state[rdev->pm.current_power_state_index].pcie_lanes)) {\r\nradeon_set_pcie_lanes(rdev,\r\nps->pcie_lanes);\r\nDRM_DEBUG_DRIVER("Setting: p: %d\n", ps->pcie_lanes);\r\n}\r\n}\r\nvoid r100_pm_prepare(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *ddev = rdev->ddev;\r\nstruct drm_crtc *crtc;\r\nstruct radeon_crtc *radeon_crtc;\r\nu32 tmp;\r\nlist_for_each_entry(crtc, &ddev->mode_config.crtc_list, head) {\r\nradeon_crtc = to_radeon_crtc(crtc);\r\nif (radeon_crtc->enabled) {\r\nif (radeon_crtc->crtc_id) {\r\ntmp = RREG32(RADEON_CRTC2_GEN_CNTL);\r\ntmp |= RADEON_CRTC2_DISP_REQ_EN_B;\r\nWREG32(RADEON_CRTC2_GEN_CNTL, tmp);\r\n} else {\r\ntmp = RREG32(RADEON_CRTC_GEN_CNTL);\r\ntmp |= RADEON_CRTC_DISP_REQ_EN_B;\r\nWREG32(RADEON_CRTC_GEN_CNTL, tmp);\r\n}\r\n}\r\n}\r\n}\r\nvoid r100_pm_finish(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *ddev = rdev->ddev;\r\nstruct drm_crtc *crtc;\r\nstruct radeon_crtc *radeon_crtc;\r\nu32 tmp;\r\nlist_for_each_entry(crtc, &ddev->mode_config.crtc_list, head) {\r\nradeon_crtc = to_radeon_crtc(crtc);\r\nif (radeon_crtc->enabled) {\r\nif (radeon_crtc->crtc_id) {\r\ntmp = RREG32(RADEON_CRTC2_GEN_CNTL);\r\ntmp &= ~RADEON_CRTC2_DISP_REQ_EN_B;\r\nWREG32(RADEON_CRTC2_GEN_CNTL, tmp);\r\n} else {\r\ntmp = RREG32(RADEON_CRTC_GEN_CNTL);\r\ntmp &= ~RADEON_CRTC_DISP_REQ_EN_B;\r\nWREG32(RADEON_CRTC_GEN_CNTL, tmp);\r\n}\r\n}\r\n}\r\n}\r\nbool r100_gui_idle(struct radeon_device *rdev)\r\n{\r\nif (RREG32(RADEON_RBBM_STATUS) & RADEON_RBBM_ACTIVE)\r\nreturn false;\r\nelse\r\nreturn true;\r\n}\r\nbool r100_hpd_sense(struct radeon_device *rdev, enum radeon_hpd_id hpd)\r\n{\r\nbool connected = false;\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\nif (RREG32(RADEON_FP_GEN_CNTL) & RADEON_FP_DETECT_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_2:\r\nif (RREG32(RADEON_FP2_GEN_CNTL) & RADEON_FP2_DETECT_SENSE)\r\nconnected = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn connected;\r\n}\r\nvoid r100_hpd_set_polarity(struct radeon_device *rdev,\r\nenum radeon_hpd_id hpd)\r\n{\r\nu32 tmp;\r\nbool connected = r100_hpd_sense(rdev, hpd);\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\ntmp = RREG32(RADEON_FP_GEN_CNTL);\r\nif (connected)\r\ntmp &= ~RADEON_FP_DETECT_INT_POL;\r\nelse\r\ntmp |= RADEON_FP_DETECT_INT_POL;\r\nWREG32(RADEON_FP_GEN_CNTL, tmp);\r\nbreak;\r\ncase RADEON_HPD_2:\r\ntmp = RREG32(RADEON_FP2_GEN_CNTL);\r\nif (connected)\r\ntmp &= ~RADEON_FP2_DETECT_INT_POL;\r\nelse\r\ntmp |= RADEON_FP2_DETECT_INT_POL;\r\nWREG32(RADEON_FP2_GEN_CNTL, tmp);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nvoid r100_hpd_init(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *dev = rdev->ddev;\r\nstruct drm_connector *connector;\r\nunsigned enable = 0;\r\nlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nif (radeon_connector->hpd.hpd != RADEON_HPD_NONE)\r\nenable |= 1 << radeon_connector->hpd.hpd;\r\nradeon_hpd_set_polarity(rdev, radeon_connector->hpd.hpd);\r\n}\r\nradeon_irq_kms_enable_hpd(rdev, enable);\r\n}\r\nvoid r100_hpd_fini(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *dev = rdev->ddev;\r\nstruct drm_connector *connector;\r\nunsigned disable = 0;\r\nlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nif (radeon_connector->hpd.hpd != RADEON_HPD_NONE)\r\ndisable |= 1 << radeon_connector->hpd.hpd;\r\n}\r\nradeon_irq_kms_disable_hpd(rdev, disable);\r\n}\r\nvoid r100_pci_gart_tlb_flush(struct radeon_device *rdev)\r\n{\r\n}\r\nint r100_pci_gart_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->gart.ptr) {\r\nWARN(1, "R100 PCI GART already initialized\n");\r\nreturn 0;\r\n}\r\nr = radeon_gart_init(rdev);\r\nif (r)\r\nreturn r;\r\nrdev->gart.table_size = rdev->gart.num_gpu_pages * 4;\r\nrdev->asic->gart.tlb_flush = &r100_pci_gart_tlb_flush;\r\nrdev->asic->gart.get_page_entry = &r100_pci_gart_get_page_entry;\r\nrdev->asic->gart.set_page = &r100_pci_gart_set_page;\r\nreturn radeon_gart_table_ram_alloc(rdev);\r\n}\r\nint r100_pci_gart_enable(struct radeon_device *rdev)\r\n{\r\nuint32_t tmp;\r\ntmp = RREG32(RADEON_AIC_CNTL) | RADEON_DIS_OUT_OF_PCI_GART_ACCESS;\r\nWREG32(RADEON_AIC_CNTL, tmp);\r\nWREG32(RADEON_AIC_LO_ADDR, rdev->mc.gtt_start);\r\nWREG32(RADEON_AIC_HI_ADDR, rdev->mc.gtt_end);\r\nWREG32(RADEON_AIC_PT_BASE, rdev->gart.table_addr);\r\ntmp = RREG32(RADEON_AIC_CNTL) | RADEON_PCIGART_TRANSLATE_EN;\r\nWREG32(RADEON_AIC_CNTL, tmp);\r\nr100_pci_gart_tlb_flush(rdev);\r\nDRM_INFO("PCI GART of %uM enabled (table at 0x%016llX).\n",\r\n(unsigned)(rdev->mc.gtt_size >> 20),\r\n(unsigned long long)rdev->gart.table_addr);\r\nrdev->gart.ready = true;\r\nreturn 0;\r\n}\r\nvoid r100_pci_gart_disable(struct radeon_device *rdev)\r\n{\r\nuint32_t tmp;\r\ntmp = RREG32(RADEON_AIC_CNTL) | RADEON_DIS_OUT_OF_PCI_GART_ACCESS;\r\nWREG32(RADEON_AIC_CNTL, tmp & ~RADEON_PCIGART_TRANSLATE_EN);\r\nWREG32(RADEON_AIC_LO_ADDR, 0);\r\nWREG32(RADEON_AIC_HI_ADDR, 0);\r\n}\r\nuint64_t r100_pci_gart_get_page_entry(uint64_t addr, uint32_t flags)\r\n{\r\nreturn addr;\r\n}\r\nvoid r100_pci_gart_set_page(struct radeon_device *rdev, unsigned i,\r\nuint64_t entry)\r\n{\r\nu32 *gtt = rdev->gart.ptr;\r\ngtt[i] = cpu_to_le32(lower_32_bits(entry));\r\n}\r\nvoid r100_pci_gart_fini(struct radeon_device *rdev)\r\n{\r\nradeon_gart_fini(rdev);\r\nr100_pci_gart_disable(rdev);\r\nradeon_gart_table_ram_free(rdev);\r\n}\r\nint r100_irq_set(struct radeon_device *rdev)\r\n{\r\nuint32_t tmp = 0;\r\nif (!rdev->irq.installed) {\r\nWARN(1, "Can't enable IRQ/MSI because no handler is installed\n");\r\nWREG32(R_000040_GEN_INT_CNTL, 0);\r\nreturn -EINVAL;\r\n}\r\nif (atomic_read(&rdev->irq.ring_int[RADEON_RING_TYPE_GFX_INDEX])) {\r\ntmp |= RADEON_SW_INT_ENABLE;\r\n}\r\nif (rdev->irq.crtc_vblank_int[0] ||\r\natomic_read(&rdev->irq.pflip[0])) {\r\ntmp |= RADEON_CRTC_VBLANK_MASK;\r\n}\r\nif (rdev->irq.crtc_vblank_int[1] ||\r\natomic_read(&rdev->irq.pflip[1])) {\r\ntmp |= RADEON_CRTC2_VBLANK_MASK;\r\n}\r\nif (rdev->irq.hpd[0]) {\r\ntmp |= RADEON_FP_DETECT_MASK;\r\n}\r\nif (rdev->irq.hpd[1]) {\r\ntmp |= RADEON_FP2_DETECT_MASK;\r\n}\r\nWREG32(RADEON_GEN_INT_CNTL, tmp);\r\nRREG32(RADEON_GEN_INT_CNTL);\r\nreturn 0;\r\n}\r\nvoid r100_irq_disable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nWREG32(R_000040_GEN_INT_CNTL, 0);\r\nmdelay(1);\r\ntmp = RREG32(R_000044_GEN_INT_STATUS);\r\nWREG32(R_000044_GEN_INT_STATUS, tmp);\r\n}\r\nstatic uint32_t r100_irq_ack(struct radeon_device *rdev)\r\n{\r\nuint32_t irqs = RREG32(RADEON_GEN_INT_STATUS);\r\nuint32_t irq_mask = RADEON_SW_INT_TEST |\r\nRADEON_CRTC_VBLANK_STAT | RADEON_CRTC2_VBLANK_STAT |\r\nRADEON_FP_DETECT_STAT | RADEON_FP2_DETECT_STAT;\r\nif (irqs) {\r\nWREG32(RADEON_GEN_INT_STATUS, irqs);\r\n}\r\nreturn irqs & irq_mask;\r\n}\r\nint r100_irq_process(struct radeon_device *rdev)\r\n{\r\nuint32_t status, msi_rearm;\r\nbool queue_hotplug = false;\r\nstatus = r100_irq_ack(rdev);\r\nif (!status) {\r\nreturn IRQ_NONE;\r\n}\r\nif (rdev->shutdown) {\r\nreturn IRQ_NONE;\r\n}\r\nwhile (status) {\r\nif (status & RADEON_SW_INT_TEST) {\r\nradeon_fence_process(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\n}\r\nif (status & RADEON_CRTC_VBLANK_STAT) {\r\nif (rdev->irq.crtc_vblank_int[0]) {\r\ndrm_handle_vblank(rdev->ddev, 0);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[0]))\r\nradeon_crtc_handle_vblank(rdev, 0);\r\n}\r\nif (status & RADEON_CRTC2_VBLANK_STAT) {\r\nif (rdev->irq.crtc_vblank_int[1]) {\r\ndrm_handle_vblank(rdev->ddev, 1);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[1]))\r\nradeon_crtc_handle_vblank(rdev, 1);\r\n}\r\nif (status & RADEON_FP_DETECT_STAT) {\r\nqueue_hotplug = true;\r\nDRM_DEBUG("HPD1\n");\r\n}\r\nif (status & RADEON_FP2_DETECT_STAT) {\r\nqueue_hotplug = true;\r\nDRM_DEBUG("HPD2\n");\r\n}\r\nstatus = r100_irq_ack(rdev);\r\n}\r\nif (queue_hotplug)\r\nschedule_delayed_work(&rdev->hotplug_work, 0);\r\nif (rdev->msi_enabled) {\r\nswitch (rdev->family) {\r\ncase CHIP_RS400:\r\ncase CHIP_RS480:\r\nmsi_rearm = RREG32(RADEON_AIC_CNTL) & ~RS400_MSI_REARM;\r\nWREG32(RADEON_AIC_CNTL, msi_rearm);\r\nWREG32(RADEON_AIC_CNTL, msi_rearm | RS400_MSI_REARM);\r\nbreak;\r\ndefault:\r\nWREG32(RADEON_MSI_REARM_EN, RV370_MSI_REARM_EN);\r\nbreak;\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nu32 r100_get_vblank_counter(struct radeon_device *rdev, int crtc)\r\n{\r\nif (crtc == 0)\r\nreturn RREG32(RADEON_CRTC_CRNT_FRAME);\r\nelse\r\nreturn RREG32(RADEON_CRTC2_CRNT_FRAME);\r\n}\r\nstatic void r100_ring_hdp_flush(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nradeon_ring_write(ring, PACKET0(RADEON_HOST_PATH_CNTL, 0));\r\nradeon_ring_write(ring, rdev->config.r100.hdp_cntl |\r\nRADEON_HDP_READ_BUFFER_INVALIDATE);\r\nradeon_ring_write(ring, PACKET0(RADEON_HOST_PATH_CNTL, 0));\r\nradeon_ring_write(ring, rdev->config.r100.hdp_cntl);\r\n}\r\nvoid r100_fence_ring_emit(struct radeon_device *rdev,\r\nstruct radeon_fence *fence)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[fence->ring];\r\nradeon_ring_write(ring, PACKET0(RADEON_RB3D_DSTCACHE_CTLSTAT, 0));\r\nradeon_ring_write(ring, RADEON_RB3D_DC_FLUSH_ALL);\r\nradeon_ring_write(ring, PACKET0(RADEON_RB3D_ZCACHE_CTLSTAT, 0));\r\nradeon_ring_write(ring, RADEON_RB3D_ZC_FLUSH_ALL);\r\nradeon_ring_write(ring, PACKET0(RADEON_WAIT_UNTIL, 0));\r\nradeon_ring_write(ring, RADEON_WAIT_2D_IDLECLEAN | RADEON_WAIT_3D_IDLECLEAN);\r\nr100_ring_hdp_flush(rdev, ring);\r\nradeon_ring_write(ring, PACKET0(rdev->fence_drv[fence->ring].scratch_reg, 0));\r\nradeon_ring_write(ring, fence->seq);\r\nradeon_ring_write(ring, PACKET0(RADEON_GEN_INT_STATUS, 0));\r\nradeon_ring_write(ring, RADEON_SW_INT_FIRE);\r\n}\r\nbool r100_semaphore_ring_emit(struct radeon_device *rdev,\r\nstruct radeon_ring *ring,\r\nstruct radeon_semaphore *semaphore,\r\nbool emit_wait)\r\n{\r\nBUG();\r\nreturn false;\r\n}\r\nstruct radeon_fence *r100_copy_blit(struct radeon_device *rdev,\r\nuint64_t src_offset,\r\nuint64_t dst_offset,\r\nunsigned num_gpu_pages,\r\nstruct reservation_object *resv)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nstruct radeon_fence *fence;\r\nuint32_t cur_pages;\r\nuint32_t stride_bytes = RADEON_GPU_PAGE_SIZE;\r\nuint32_t pitch;\r\nuint32_t stride_pixels;\r\nunsigned ndw;\r\nint num_loops;\r\nint r = 0;\r\nstride_bytes &= 0x3fff;\r\npitch = stride_bytes / 64;\r\nstride_pixels = stride_bytes / 4;\r\nnum_loops = DIV_ROUND_UP(num_gpu_pages, 8191);\r\nndw = 64 + (10 * num_loops);\r\nr = radeon_ring_lock(rdev, ring, ndw);\r\nif (r) {\r\nDRM_ERROR("radeon: moving bo (%d) asking for %u dw.\n", r, ndw);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nwhile (num_gpu_pages > 0) {\r\ncur_pages = num_gpu_pages;\r\nif (cur_pages > 8191) {\r\ncur_pages = 8191;\r\n}\r\nnum_gpu_pages -= cur_pages;\r\nradeon_ring_write(ring, PACKET3(PACKET3_BITBLT_MULTI, 8));\r\nradeon_ring_write(ring,\r\nRADEON_GMC_SRC_PITCH_OFFSET_CNTL |\r\nRADEON_GMC_DST_PITCH_OFFSET_CNTL |\r\nRADEON_GMC_SRC_CLIPPING |\r\nRADEON_GMC_DST_CLIPPING |\r\nRADEON_GMC_BRUSH_NONE |\r\n(RADEON_COLOR_FORMAT_ARGB8888 << 8) |\r\nRADEON_GMC_SRC_DATATYPE_COLOR |\r\nRADEON_ROP3_S |\r\nRADEON_DP_SRC_SOURCE_MEMORY |\r\nRADEON_GMC_CLR_CMP_CNTL_DIS |\r\nRADEON_GMC_WR_MSK_DIS);\r\nradeon_ring_write(ring, (pitch << 22) | (src_offset >> 10));\r\nradeon_ring_write(ring, (pitch << 22) | (dst_offset >> 10));\r\nradeon_ring_write(ring, (0x1fff) | (0x1fff << 16));\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_write(ring, (0x1fff) | (0x1fff << 16));\r\nradeon_ring_write(ring, num_gpu_pages);\r\nradeon_ring_write(ring, num_gpu_pages);\r\nradeon_ring_write(ring, cur_pages | (stride_pixels << 16));\r\n}\r\nradeon_ring_write(ring, PACKET0(RADEON_DSTCACHE_CTLSTAT, 0));\r\nradeon_ring_write(ring, RADEON_RB2D_DC_FLUSH_ALL);\r\nradeon_ring_write(ring, PACKET0(RADEON_WAIT_UNTIL, 0));\r\nradeon_ring_write(ring,\r\nRADEON_WAIT_2D_IDLECLEAN |\r\nRADEON_WAIT_HOST_IDLECLEAN |\r\nRADEON_WAIT_DMA_GUI_IDLE);\r\nr = radeon_fence_emit(rdev, &fence, RADEON_RING_TYPE_GFX_INDEX);\r\nif (r) {\r\nradeon_ring_unlock_undo(rdev, ring);\r\nreturn ERR_PTR(r);\r\n}\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\nreturn fence;\r\n}\r\nstatic int r100_cp_wait_for_idle(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nu32 tmp;\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(R_000E40_RBBM_STATUS);\r\nif (!G_000E40_CP_CMDSTRM_BUSY(tmp)) {\r\nreturn 0;\r\n}\r\nudelay(1);\r\n}\r\nreturn -1;\r\n}\r\nvoid r100_ring_start(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nint r;\r\nr = radeon_ring_lock(rdev, ring, 2);\r\nif (r) {\r\nreturn;\r\n}\r\nradeon_ring_write(ring, PACKET0(RADEON_ISYNC_CNTL, 0));\r\nradeon_ring_write(ring,\r\nRADEON_ISYNC_ANY2D_IDLE3D |\r\nRADEON_ISYNC_ANY3D_IDLE2D |\r\nRADEON_ISYNC_WAIT_IDLEGUI |\r\nRADEON_ISYNC_CPSCRATCH_IDLEGUI);\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\n}\r\nstatic int r100_cp_init_microcode(struct radeon_device *rdev)\r\n{\r\nconst char *fw_name = NULL;\r\nint err;\r\nDRM_DEBUG_KMS("\n");\r\nif ((rdev->family == CHIP_R100) || (rdev->family == CHIP_RV100) ||\r\n(rdev->family == CHIP_RV200) || (rdev->family == CHIP_RS100) ||\r\n(rdev->family == CHIP_RS200)) {\r\nDRM_INFO("Loading R100 Microcode\n");\r\nfw_name = FIRMWARE_R100;\r\n} else if ((rdev->family == CHIP_R200) ||\r\n(rdev->family == CHIP_RV250) ||\r\n(rdev->family == CHIP_RV280) ||\r\n(rdev->family == CHIP_RS300)) {\r\nDRM_INFO("Loading R200 Microcode\n");\r\nfw_name = FIRMWARE_R200;\r\n} else if ((rdev->family == CHIP_R300) ||\r\n(rdev->family == CHIP_R350) ||\r\n(rdev->family == CHIP_RV350) ||\r\n(rdev->family == CHIP_RV380) ||\r\n(rdev->family == CHIP_RS400) ||\r\n(rdev->family == CHIP_RS480)) {\r\nDRM_INFO("Loading R300 Microcode\n");\r\nfw_name = FIRMWARE_R300;\r\n} else if ((rdev->family == CHIP_R420) ||\r\n(rdev->family == CHIP_R423) ||\r\n(rdev->family == CHIP_RV410)) {\r\nDRM_INFO("Loading R400 Microcode\n");\r\nfw_name = FIRMWARE_R420;\r\n} else if ((rdev->family == CHIP_RS690) ||\r\n(rdev->family == CHIP_RS740)) {\r\nDRM_INFO("Loading RS690/RS740 Microcode\n");\r\nfw_name = FIRMWARE_RS690;\r\n} else if (rdev->family == CHIP_RS600) {\r\nDRM_INFO("Loading RS600 Microcode\n");\r\nfw_name = FIRMWARE_RS600;\r\n} else if ((rdev->family == CHIP_RV515) ||\r\n(rdev->family == CHIP_R520) ||\r\n(rdev->family == CHIP_RV530) ||\r\n(rdev->family == CHIP_R580) ||\r\n(rdev->family == CHIP_RV560) ||\r\n(rdev->family == CHIP_RV570)) {\r\nDRM_INFO("Loading R500 Microcode\n");\r\nfw_name = FIRMWARE_R520;\r\n}\r\nerr = request_firmware(&rdev->me_fw, fw_name, rdev->dev);\r\nif (err) {\r\nprintk(KERN_ERR "radeon_cp: Failed to load firmware \"%s\"\n",\r\nfw_name);\r\n} else if (rdev->me_fw->size % 8) {\r\nprintk(KERN_ERR\r\n"radeon_cp: Bogus length %zu in firmware \"%s\"\n",\r\nrdev->me_fw->size, fw_name);\r\nerr = -EINVAL;\r\nrelease_firmware(rdev->me_fw);\r\nrdev->me_fw = NULL;\r\n}\r\nreturn err;\r\n}\r\nu32 r100_gfx_get_rptr(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nu32 rptr;\r\nif (rdev->wb.enabled)\r\nrptr = le32_to_cpu(rdev->wb.wb[ring->rptr_offs/4]);\r\nelse\r\nrptr = RREG32(RADEON_CP_RB_RPTR);\r\nreturn rptr;\r\n}\r\nu32 r100_gfx_get_wptr(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nu32 wptr;\r\nwptr = RREG32(RADEON_CP_RB_WPTR);\r\nreturn wptr;\r\n}\r\nvoid r100_gfx_set_wptr(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nWREG32(RADEON_CP_RB_WPTR, ring->wptr);\r\n(void)RREG32(RADEON_CP_RB_WPTR);\r\n}\r\nstatic void r100_cp_load_microcode(struct radeon_device *rdev)\r\n{\r\nconst __be32 *fw_data;\r\nint i, size;\r\nif (r100_gui_wait_for_idle(rdev)) {\r\nprintk(KERN_WARNING "Failed to wait GUI idle while "\r\n"programming pipes. Bad things might happen.\n");\r\n}\r\nif (rdev->me_fw) {\r\nsize = rdev->me_fw->size / 4;\r\nfw_data = (const __be32 *)&rdev->me_fw->data[0];\r\nWREG32(RADEON_CP_ME_RAM_ADDR, 0);\r\nfor (i = 0; i < size; i += 2) {\r\nWREG32(RADEON_CP_ME_RAM_DATAH,\r\nbe32_to_cpup(&fw_data[i]));\r\nWREG32(RADEON_CP_ME_RAM_DATAL,\r\nbe32_to_cpup(&fw_data[i + 1]));\r\n}\r\n}\r\n}\r\nint r100_cp_init(struct radeon_device *rdev, unsigned ring_size)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nunsigned rb_bufsz;\r\nunsigned rb_blksz;\r\nunsigned max_fetch;\r\nunsigned pre_write_timer;\r\nunsigned pre_write_limit;\r\nunsigned indirect2_start;\r\nunsigned indirect1_start;\r\nuint32_t tmp;\r\nint r;\r\nif (r100_debugfs_cp_init(rdev)) {\r\nDRM_ERROR("Failed to register debugfs file for CP !\n");\r\n}\r\nif (!rdev->me_fw) {\r\nr = r100_cp_init_microcode(rdev);\r\nif (r) {\r\nDRM_ERROR("Failed to load firmware!\n");\r\nreturn r;\r\n}\r\n}\r\nrb_bufsz = order_base_2(ring_size / 8);\r\nring_size = (1 << (rb_bufsz + 1)) * 4;\r\nr100_cp_load_microcode(rdev);\r\nr = radeon_ring_init(rdev, ring, ring_size, RADEON_WB_CP_RPTR_OFFSET,\r\nRADEON_CP_PACKET2);\r\nif (r) {\r\nreturn r;\r\n}\r\nrb_blksz = 9;\r\nmax_fetch = 1;\r\nring->align_mask = 16 - 1;\r\npre_write_timer = 64;\r\npre_write_limit = 0;\r\nindirect2_start = 80;\r\nindirect1_start = 16;\r\nWREG32(0x718, pre_write_timer | (pre_write_limit << 28));\r\ntmp = (REG_SET(RADEON_RB_BUFSZ, rb_bufsz) |\r\nREG_SET(RADEON_RB_BLKSZ, rb_blksz) |\r\nREG_SET(RADEON_MAX_FETCH, max_fetch));\r\n#ifdef __BIG_ENDIAN\r\ntmp |= RADEON_BUF_SWAP_32BIT;\r\n#endif\r\nWREG32(RADEON_CP_RB_CNTL, tmp | RADEON_RB_NO_UPDATE);\r\nDRM_INFO("radeon: ring at 0x%016lX\n", (unsigned long)ring->gpu_addr);\r\nWREG32(RADEON_CP_RB_BASE, ring->gpu_addr);\r\nWREG32(RADEON_CP_RB_CNTL, tmp | RADEON_RB_RPTR_WR_ENA | RADEON_RB_NO_UPDATE);\r\nWREG32(RADEON_CP_RB_RPTR_WR, 0);\r\nring->wptr = 0;\r\nWREG32(RADEON_CP_RB_WPTR, ring->wptr);\r\nWREG32(R_00070C_CP_RB_RPTR_ADDR,\r\nS_00070C_RB_RPTR_ADDR((rdev->wb.gpu_addr + RADEON_WB_CP_RPTR_OFFSET) >> 2));\r\nWREG32(R_000774_SCRATCH_ADDR, rdev->wb.gpu_addr + RADEON_WB_SCRATCH_OFFSET);\r\nif (rdev->wb.enabled)\r\nWREG32(R_000770_SCRATCH_UMSK, 0xff);\r\nelse {\r\ntmp |= RADEON_RB_NO_UPDATE;\r\nWREG32(R_000770_SCRATCH_UMSK, 0);\r\n}\r\nWREG32(RADEON_CP_RB_CNTL, tmp);\r\nudelay(10);\r\nWREG32(RADEON_CP_CSQ_MODE,\r\nREG_SET(RADEON_INDIRECT2_START, indirect2_start) |\r\nREG_SET(RADEON_INDIRECT1_START, indirect1_start));\r\nWREG32(RADEON_CP_RB_WPTR_DELAY, 0);\r\nWREG32(RADEON_CP_CSQ_MODE, 0x00004D4D);\r\nWREG32(RADEON_CP_CSQ_CNTL, RADEON_CSQ_PRIBM_INDBM);\r\npci_set_master(rdev->pdev);\r\nradeon_ring_start(rdev, RADEON_RING_TYPE_GFX_INDEX, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX]);\r\nr = radeon_ring_test(rdev, RADEON_RING_TYPE_GFX_INDEX, ring);\r\nif (r) {\r\nDRM_ERROR("radeon: cp isn't working (%d).\n", r);\r\nreturn r;\r\n}\r\nring->ready = true;\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);\r\nif (!ring->rptr_save_reg\r\n&& radeon_ring_supports_scratch_reg(rdev, ring)) {\r\nr = radeon_scratch_get(rdev, &ring->rptr_save_reg);\r\nif (r) {\r\nDRM_ERROR("failed to get scratch reg for rptr save (%d).\n", r);\r\nring->rptr_save_reg = 0;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid r100_cp_fini(struct radeon_device *rdev)\r\n{\r\nif (r100_cp_wait_for_idle(rdev)) {\r\nDRM_ERROR("Wait for CP idle timeout, shutting down CP.\n");\r\n}\r\nr100_cp_disable(rdev);\r\nradeon_scratch_free(rdev, rdev->ring[RADEON_RING_TYPE_GFX_INDEX].rptr_save_reg);\r\nradeon_ring_fini(rdev, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX]);\r\nDRM_INFO("radeon: cp finalized\n");\r\n}\r\nvoid r100_cp_disable(struct radeon_device *rdev)\r\n{\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);\r\nrdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;\r\nWREG32(RADEON_CP_CSQ_MODE, 0);\r\nWREG32(RADEON_CP_CSQ_CNTL, 0);\r\nWREG32(R_000770_SCRATCH_UMSK, 0);\r\nif (r100_gui_wait_for_idle(rdev)) {\r\nprintk(KERN_WARNING "Failed to wait GUI idle while "\r\n"programming pipes. Bad things might happen.\n");\r\n}\r\n}\r\nint r100_reloc_pitch_offset(struct radeon_cs_parser *p,\r\nstruct radeon_cs_packet *pkt,\r\nunsigned idx,\r\nunsigned reg)\r\n{\r\nint r;\r\nu32 tile_flags = 0;\r\nu32 tmp;\r\nstruct radeon_bo_list *reloc;\r\nu32 value;\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nvalue = radeon_get_ib_value(p, idx);\r\ntmp = value & 0x003fffff;\r\ntmp += (((u32)reloc->gpu_offset) >> 10);\r\nif (!(p->cs_flags & RADEON_CS_KEEP_TILING_FLAGS)) {\r\nif (reloc->tiling_flags & RADEON_TILING_MACRO)\r\ntile_flags |= RADEON_DST_TILE_MACRO;\r\nif (reloc->tiling_flags & RADEON_TILING_MICRO) {\r\nif (reg == RADEON_SRC_PITCH_OFFSET) {\r\nDRM_ERROR("Cannot src blit from microtiled surface\n");\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn -EINVAL;\r\n}\r\ntile_flags |= RADEON_DST_TILE_MICRO;\r\n}\r\ntmp |= tile_flags;\r\np->ib.ptr[idx] = (value & 0x3fc00000) | tmp;\r\n} else\r\np->ib.ptr[idx] = (value & 0xffc00000) | tmp;\r\nreturn 0;\r\n}\r\nint r100_packet3_load_vbpntr(struct radeon_cs_parser *p,\r\nstruct radeon_cs_packet *pkt,\r\nint idx)\r\n{\r\nunsigned c, i;\r\nstruct radeon_bo_list *reloc;\r\nstruct r100_cs_track *track;\r\nint r = 0;\r\nvolatile uint32_t *ib;\r\nu32 idx_value;\r\nib = p->ib.ptr;\r\ntrack = (struct r100_cs_track *)p->track;\r\nc = radeon_get_ib_value(p, idx++) & 0x1F;\r\nif (c > 16) {\r\nDRM_ERROR("Only 16 vertex buffers are allowed %d\n",\r\npkt->opcode);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn -EINVAL;\r\n}\r\ntrack->num_arrays = c;\r\nfor (i = 0; i < (c - 1); i+=2, idx+=3) {\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for packet3 %d\n",\r\npkt->opcode);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nidx_value = radeon_get_ib_value(p, idx);\r\nib[idx+1] = radeon_get_ib_value(p, idx + 1) + ((u32)reloc->gpu_offset);\r\ntrack->arrays[i + 0].esize = idx_value >> 8;\r\ntrack->arrays[i + 0].robj = reloc->robj;\r\ntrack->arrays[i + 0].esize &= 0x7F;\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for packet3 %d\n",\r\npkt->opcode);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nib[idx+2] = radeon_get_ib_value(p, idx + 2) + ((u32)reloc->gpu_offset);\r\ntrack->arrays[i + 1].robj = reloc->robj;\r\ntrack->arrays[i + 1].esize = idx_value >> 24;\r\ntrack->arrays[i + 1].esize &= 0x7F;\r\n}\r\nif (c & 1) {\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for packet3 %d\n",\r\npkt->opcode);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nidx_value = radeon_get_ib_value(p, idx);\r\nib[idx+1] = radeon_get_ib_value(p, idx + 1) + ((u32)reloc->gpu_offset);\r\ntrack->arrays[i + 0].robj = reloc->robj;\r\ntrack->arrays[i + 0].esize = idx_value >> 8;\r\ntrack->arrays[i + 0].esize &= 0x7F;\r\n}\r\nreturn r;\r\n}\r\nint r100_cs_parse_packet0(struct radeon_cs_parser *p,\r\nstruct radeon_cs_packet *pkt,\r\nconst unsigned *auth, unsigned n,\r\nradeon_packet0_check_t check)\r\n{\r\nunsigned reg;\r\nunsigned i, j, m;\r\nunsigned idx;\r\nint r;\r\nidx = pkt->idx + 1;\r\nreg = pkt->reg;\r\nif (pkt->one_reg_wr) {\r\nif ((reg >> 7) > n) {\r\nreturn -EINVAL;\r\n}\r\n} else {\r\nif (((reg + (pkt->count << 2)) >> 7) > n) {\r\nreturn -EINVAL;\r\n}\r\n}\r\nfor (i = 0; i <= pkt->count; i++, idx++) {\r\nj = (reg >> 7);\r\nm = 1 << ((reg >> 2) & 31);\r\nif (auth[j] & m) {\r\nr = check(p, pkt, idx, reg);\r\nif (r) {\r\nreturn r;\r\n}\r\n}\r\nif (pkt->one_reg_wr) {\r\nif (!(auth[j] & m)) {\r\nbreak;\r\n}\r\n} else {\r\nreg += 4;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint r100_cs_packet_parse_vline(struct radeon_cs_parser *p)\r\n{\r\nstruct drm_crtc *crtc;\r\nstruct radeon_crtc *radeon_crtc;\r\nstruct radeon_cs_packet p3reloc, waitreloc;\r\nint crtc_id;\r\nint r;\r\nuint32_t header, h_idx, reg;\r\nvolatile uint32_t *ib;\r\nib = p->ib.ptr;\r\nr = radeon_cs_packet_parse(p, &waitreloc, p->idx);\r\nif (r)\r\nreturn r;\r\nif (waitreloc.reg != RADEON_WAIT_UNTIL ||\r\nwaitreloc.count != 0) {\r\nDRM_ERROR("vline wait had illegal wait until segment\n");\r\nreturn -EINVAL;\r\n}\r\nif (radeon_get_ib_value(p, waitreloc.idx + 1) != RADEON_WAIT_CRTC_VLINE) {\r\nDRM_ERROR("vline wait had illegal wait until\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_cs_packet_parse(p, &p3reloc, p->idx + waitreloc.count + 2);\r\nif (r)\r\nreturn r;\r\nh_idx = p->idx - 2;\r\np->idx += waitreloc.count + 2;\r\np->idx += p3reloc.count + 2;\r\nheader = radeon_get_ib_value(p, h_idx);\r\ncrtc_id = radeon_get_ib_value(p, h_idx + 5);\r\nreg = R100_CP_PACKET0_GET_REG(header);\r\ncrtc = drm_crtc_find(p->rdev->ddev, crtc_id);\r\nif (!crtc) {\r\nDRM_ERROR("cannot find crtc %d\n", crtc_id);\r\nreturn -ENOENT;\r\n}\r\nradeon_crtc = to_radeon_crtc(crtc);\r\ncrtc_id = radeon_crtc->crtc_id;\r\nif (!crtc->enabled) {\r\nib[h_idx + 2] = PACKET2(0);\r\nib[h_idx + 3] = PACKET2(0);\r\n} else if (crtc_id == 1) {\r\nswitch (reg) {\r\ncase AVIVO_D1MODE_VLINE_START_END:\r\nheader &= ~R300_CP_PACKET0_REG_MASK;\r\nheader |= AVIVO_D2MODE_VLINE_START_END >> 2;\r\nbreak;\r\ncase RADEON_CRTC_GUI_TRIG_VLINE:\r\nheader &= ~R300_CP_PACKET0_REG_MASK;\r\nheader |= RADEON_CRTC2_GUI_TRIG_VLINE >> 2;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("unknown crtc reloc\n");\r\nreturn -EINVAL;\r\n}\r\nib[h_idx] = header;\r\nib[h_idx + 3] |= RADEON_ENG_DISPLAY_SELECT_CRTC1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int r100_get_vtx_size(uint32_t vtx_fmt)\r\n{\r\nint vtx_size;\r\nvtx_size = 2;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_W0)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_FPCOLOR)\r\nvtx_size += 3;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_FPALPHA)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_PKCOLOR)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_FPSPEC)\r\nvtx_size += 3;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_FPFOG)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_PKSPEC)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_ST0)\r\nvtx_size += 2;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_ST1)\r\nvtx_size += 2;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_Q1)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_ST2)\r\nvtx_size += 2;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_Q2)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_ST3)\r\nvtx_size += 2;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_Q3)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_Q0)\r\nvtx_size++;\r\nif (vtx_fmt & (0x7 << 15))\r\nvtx_size += (vtx_fmt >> 15) & 0x7;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_N0)\r\nvtx_size += 3;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_XY1)\r\nvtx_size += 2;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_Z1)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_W1)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_N1)\r\nvtx_size++;\r\nif (vtx_fmt & RADEON_SE_VTX_FMT_Z)\r\nvtx_size++;\r\nreturn vtx_size;\r\n}\r\nstatic int r100_packet0_check(struct radeon_cs_parser *p,\r\nstruct radeon_cs_packet *pkt,\r\nunsigned idx, unsigned reg)\r\n{\r\nstruct radeon_bo_list *reloc;\r\nstruct r100_cs_track *track;\r\nvolatile uint32_t *ib;\r\nuint32_t tmp;\r\nint r;\r\nint i, face;\r\nu32 tile_flags = 0;\r\nu32 idx_value;\r\nib = p->ib.ptr;\r\ntrack = (struct r100_cs_track *)p->track;\r\nidx_value = radeon_get_ib_value(p, idx);\r\nswitch (reg) {\r\ncase RADEON_CRTC_GUI_TRIG_VLINE:\r\nr = r100_cs_packet_parse_vline(p);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nbreak;\r\ncase RADEON_DST_PITCH_OFFSET:\r\ncase RADEON_SRC_PITCH_OFFSET:\r\nr = r100_reloc_pitch_offset(p, pkt, idx, reg);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase RADEON_RB3D_DEPTHOFFSET:\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\ntrack->zb.robj = reloc->robj;\r\ntrack->zb.offset = idx_value;\r\ntrack->zb_dirty = true;\r\nib[idx] = idx_value + ((u32)reloc->gpu_offset);\r\nbreak;\r\ncase RADEON_RB3D_COLOROFFSET:\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\ntrack->cb[0].robj = reloc->robj;\r\ntrack->cb[0].offset = idx_value;\r\ntrack->cb_dirty = true;\r\nib[idx] = idx_value + ((u32)reloc->gpu_offset);\r\nbreak;\r\ncase RADEON_PP_TXOFFSET_0:\r\ncase RADEON_PP_TXOFFSET_1:\r\ncase RADEON_PP_TXOFFSET_2:\r\ni = (reg - RADEON_PP_TXOFFSET_0) / 24;\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nif (!(p->cs_flags & RADEON_CS_KEEP_TILING_FLAGS)) {\r\nif (reloc->tiling_flags & RADEON_TILING_MACRO)\r\ntile_flags |= RADEON_TXO_MACRO_TILE;\r\nif (reloc->tiling_flags & RADEON_TILING_MICRO)\r\ntile_flags |= RADEON_TXO_MICRO_TILE_X2;\r\ntmp = idx_value & ~(0x7 << 2);\r\ntmp |= tile_flags;\r\nib[idx] = tmp + ((u32)reloc->gpu_offset);\r\n} else\r\nib[idx] = idx_value + ((u32)reloc->gpu_offset);\r\ntrack->textures[i].robj = reloc->robj;\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_PP_CUBIC_OFFSET_T0_0:\r\ncase RADEON_PP_CUBIC_OFFSET_T0_1:\r\ncase RADEON_PP_CUBIC_OFFSET_T0_2:\r\ncase RADEON_PP_CUBIC_OFFSET_T0_3:\r\ncase RADEON_PP_CUBIC_OFFSET_T0_4:\r\ni = (reg - RADEON_PP_CUBIC_OFFSET_T0_0) / 4;\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\ntrack->textures[0].cube_info[i].offset = idx_value;\r\nib[idx] = idx_value + ((u32)reloc->gpu_offset);\r\ntrack->textures[0].cube_info[i].robj = reloc->robj;\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_PP_CUBIC_OFFSET_T1_0:\r\ncase RADEON_PP_CUBIC_OFFSET_T1_1:\r\ncase RADEON_PP_CUBIC_OFFSET_T1_2:\r\ncase RADEON_PP_CUBIC_OFFSET_T1_3:\r\ncase RADEON_PP_CUBIC_OFFSET_T1_4:\r\ni = (reg - RADEON_PP_CUBIC_OFFSET_T1_0) / 4;\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\ntrack->textures[1].cube_info[i].offset = idx_value;\r\nib[idx] = idx_value + ((u32)reloc->gpu_offset);\r\ntrack->textures[1].cube_info[i].robj = reloc->robj;\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_PP_CUBIC_OFFSET_T2_0:\r\ncase RADEON_PP_CUBIC_OFFSET_T2_1:\r\ncase RADEON_PP_CUBIC_OFFSET_T2_2:\r\ncase RADEON_PP_CUBIC_OFFSET_T2_3:\r\ncase RADEON_PP_CUBIC_OFFSET_T2_4:\r\ni = (reg - RADEON_PP_CUBIC_OFFSET_T2_0) / 4;\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\ntrack->textures[2].cube_info[i].offset = idx_value;\r\nib[idx] = idx_value + ((u32)reloc->gpu_offset);\r\ntrack->textures[2].cube_info[i].robj = reloc->robj;\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_RE_WIDTH_HEIGHT:\r\ntrack->maxy = ((idx_value >> 16) & 0x7FF);\r\ntrack->cb_dirty = true;\r\ntrack->zb_dirty = true;\r\nbreak;\r\ncase RADEON_RB3D_COLORPITCH:\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nif (!(p->cs_flags & RADEON_CS_KEEP_TILING_FLAGS)) {\r\nif (reloc->tiling_flags & RADEON_TILING_MACRO)\r\ntile_flags |= RADEON_COLOR_TILE_ENABLE;\r\nif (reloc->tiling_flags & RADEON_TILING_MICRO)\r\ntile_flags |= RADEON_COLOR_MICROTILE_ENABLE;\r\ntmp = idx_value & ~(0x7 << 16);\r\ntmp |= tile_flags;\r\nib[idx] = tmp;\r\n} else\r\nib[idx] = idx_value;\r\ntrack->cb[0].pitch = idx_value & RADEON_COLORPITCH_MASK;\r\ntrack->cb_dirty = true;\r\nbreak;\r\ncase RADEON_RB3D_DEPTHPITCH:\r\ntrack->zb.pitch = idx_value & RADEON_DEPTHPITCH_MASK;\r\ntrack->zb_dirty = true;\r\nbreak;\r\ncase RADEON_RB3D_CNTL:\r\nswitch ((idx_value >> RADEON_RB3D_COLOR_FORMAT_SHIFT) & 0x1f) {\r\ncase 7:\r\ncase 8:\r\ncase 9:\r\ncase 11:\r\ncase 12:\r\ntrack->cb[0].cpp = 1;\r\nbreak;\r\ncase 3:\r\ncase 4:\r\ncase 15:\r\ntrack->cb[0].cpp = 2;\r\nbreak;\r\ncase 6:\r\ntrack->cb[0].cpp = 4;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Invalid color buffer format (%d) !\n",\r\n((idx_value >> RADEON_RB3D_COLOR_FORMAT_SHIFT) & 0x1f));\r\nreturn -EINVAL;\r\n}\r\ntrack->z_enabled = !!(idx_value & RADEON_Z_ENABLE);\r\ntrack->cb_dirty = true;\r\ntrack->zb_dirty = true;\r\nbreak;\r\ncase RADEON_RB3D_ZSTENCILCNTL:\r\nswitch (idx_value & 0xf) {\r\ncase 0:\r\ntrack->zb.cpp = 2;\r\nbreak;\r\ncase 2:\r\ncase 3:\r\ncase 4:\r\ncase 5:\r\ncase 9:\r\ncase 11:\r\ntrack->zb.cpp = 4;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\ntrack->zb_dirty = true;\r\nbreak;\r\ncase RADEON_RB3D_ZPASS_ADDR:\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for ib[%d]=0x%04X\n",\r\nidx, reg);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nib[idx] = idx_value + ((u32)reloc->gpu_offset);\r\nbreak;\r\ncase RADEON_PP_CNTL:\r\n{\r\nuint32_t temp = idx_value >> 4;\r\nfor (i = 0; i < track->num_texture; i++)\r\ntrack->textures[i].enabled = !!(temp & (1 << i));\r\ntrack->tex_dirty = true;\r\n}\r\nbreak;\r\ncase RADEON_SE_VF_CNTL:\r\ntrack->vap_vf_cntl = idx_value;\r\nbreak;\r\ncase RADEON_SE_VTX_FMT:\r\ntrack->vtx_size = r100_get_vtx_size(idx_value);\r\nbreak;\r\ncase RADEON_PP_TEX_SIZE_0:\r\ncase RADEON_PP_TEX_SIZE_1:\r\ncase RADEON_PP_TEX_SIZE_2:\r\ni = (reg - RADEON_PP_TEX_SIZE_0) / 8;\r\ntrack->textures[i].width = (idx_value & RADEON_TEX_USIZE_MASK) + 1;\r\ntrack->textures[i].height = ((idx_value & RADEON_TEX_VSIZE_MASK) >> RADEON_TEX_VSIZE_SHIFT) + 1;\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_PP_TEX_PITCH_0:\r\ncase RADEON_PP_TEX_PITCH_1:\r\ncase RADEON_PP_TEX_PITCH_2:\r\ni = (reg - RADEON_PP_TEX_PITCH_0) / 8;\r\ntrack->textures[i].pitch = idx_value + 32;\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_PP_TXFILTER_0:\r\ncase RADEON_PP_TXFILTER_1:\r\ncase RADEON_PP_TXFILTER_2:\r\ni = (reg - RADEON_PP_TXFILTER_0) / 24;\r\ntrack->textures[i].num_levels = ((idx_value & RADEON_MAX_MIP_LEVEL_MASK)\r\n>> RADEON_MAX_MIP_LEVEL_SHIFT);\r\ntmp = (idx_value >> 23) & 0x7;\r\nif (tmp == 2 || tmp == 6)\r\ntrack->textures[i].roundup_w = false;\r\ntmp = (idx_value >> 27) & 0x7;\r\nif (tmp == 2 || tmp == 6)\r\ntrack->textures[i].roundup_h = false;\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_PP_TXFORMAT_0:\r\ncase RADEON_PP_TXFORMAT_1:\r\ncase RADEON_PP_TXFORMAT_2:\r\ni = (reg - RADEON_PP_TXFORMAT_0) / 24;\r\nif (idx_value & RADEON_TXFORMAT_NON_POWER2) {\r\ntrack->textures[i].use_pitch = 1;\r\n} else {\r\ntrack->textures[i].use_pitch = 0;\r\ntrack->textures[i].width = 1 << ((idx_value >> RADEON_TXFORMAT_WIDTH_SHIFT) & RADEON_TXFORMAT_WIDTH_MASK);\r\ntrack->textures[i].height = 1 << ((idx_value >> RADEON_TXFORMAT_HEIGHT_SHIFT) & RADEON_TXFORMAT_HEIGHT_MASK);\r\n}\r\nif (idx_value & RADEON_TXFORMAT_CUBIC_MAP_ENABLE)\r\ntrack->textures[i].tex_coord_type = 2;\r\nswitch ((idx_value & RADEON_TXFORMAT_FORMAT_MASK)) {\r\ncase RADEON_TXFORMAT_I8:\r\ncase RADEON_TXFORMAT_RGB332:\r\ncase RADEON_TXFORMAT_Y8:\r\ntrack->textures[i].cpp = 1;\r\ntrack->textures[i].compress_format = R100_TRACK_COMP_NONE;\r\nbreak;\r\ncase RADEON_TXFORMAT_AI88:\r\ncase RADEON_TXFORMAT_ARGB1555:\r\ncase RADEON_TXFORMAT_RGB565:\r\ncase RADEON_TXFORMAT_ARGB4444:\r\ncase RADEON_TXFORMAT_VYUY422:\r\ncase RADEON_TXFORMAT_YVYU422:\r\ncase RADEON_TXFORMAT_SHADOW16:\r\ncase RADEON_TXFORMAT_LDUDV655:\r\ncase RADEON_TXFORMAT_DUDV88:\r\ntrack->textures[i].cpp = 2;\r\ntrack->textures[i].compress_format = R100_TRACK_COMP_NONE;\r\nbreak;\r\ncase RADEON_TXFORMAT_ARGB8888:\r\ncase RADEON_TXFORMAT_RGBA8888:\r\ncase RADEON_TXFORMAT_SHADOW32:\r\ncase RADEON_TXFORMAT_LDUDUV8888:\r\ntrack->textures[i].cpp = 4;\r\ntrack->textures[i].compress_format = R100_TRACK_COMP_NONE;\r\nbreak;\r\ncase RADEON_TXFORMAT_DXT1:\r\ntrack->textures[i].cpp = 1;\r\ntrack->textures[i].compress_format = R100_TRACK_COMP_DXT1;\r\nbreak;\r\ncase RADEON_TXFORMAT_DXT23:\r\ncase RADEON_TXFORMAT_DXT45:\r\ntrack->textures[i].cpp = 1;\r\ntrack->textures[i].compress_format = R100_TRACK_COMP_DXT35;\r\nbreak;\r\n}\r\ntrack->textures[i].cube_info[4].width = 1 << ((idx_value >> 16) & 0xf);\r\ntrack->textures[i].cube_info[4].height = 1 << ((idx_value >> 20) & 0xf);\r\ntrack->tex_dirty = true;\r\nbreak;\r\ncase RADEON_PP_CUBIC_FACES_0:\r\ncase RADEON_PP_CUBIC_FACES_1:\r\ncase RADEON_PP_CUBIC_FACES_2:\r\ntmp = idx_value;\r\ni = (reg - RADEON_PP_CUBIC_FACES_0) / 4;\r\nfor (face = 0; face < 4; face++) {\r\ntrack->textures[i].cube_info[face].width = 1 << ((tmp >> (face * 8)) & 0xf);\r\ntrack->textures[i].cube_info[face].height = 1 << ((tmp >> ((face * 8) + 4)) & 0xf);\r\n}\r\ntrack->tex_dirty = true;\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "Forbidden register 0x%04X in cs at %d\n",\r\nreg, idx);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint r100_cs_track_check_pkt3_indx_buffer(struct radeon_cs_parser *p,\r\nstruct radeon_cs_packet *pkt,\r\nstruct radeon_bo *robj)\r\n{\r\nunsigned idx;\r\nu32 value;\r\nidx = pkt->idx + 1;\r\nvalue = radeon_get_ib_value(p, idx + 2);\r\nif ((value + 1) > radeon_bo_size(robj)) {\r\nDRM_ERROR("[drm] Buffer too small for PACKET3 INDX_BUFFER "\r\n"(need %u have %lu) !\n",\r\nvalue + 1,\r\nradeon_bo_size(robj));\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int r100_packet3_check(struct radeon_cs_parser *p,\r\nstruct radeon_cs_packet *pkt)\r\n{\r\nstruct radeon_bo_list *reloc;\r\nstruct r100_cs_track *track;\r\nunsigned idx;\r\nvolatile uint32_t *ib;\r\nint r;\r\nib = p->ib.ptr;\r\nidx = pkt->idx + 1;\r\ntrack = (struct r100_cs_track *)p->track;\r\nswitch (pkt->opcode) {\r\ncase PACKET3_3D_LOAD_VBPNTR:\r\nr = r100_packet3_load_vbpntr(p, pkt, idx);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_INDX_BUFFER:\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for packet3 %d\n", pkt->opcode);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nib[idx+1] = radeon_get_ib_value(p, idx+1) + ((u32)reloc->gpu_offset);\r\nr = r100_cs_track_check_pkt3_indx_buffer(p, pkt, reloc->robj);\r\nif (r) {\r\nreturn r;\r\n}\r\nbreak;\r\ncase 0x23:\r\nr = radeon_cs_packet_next_reloc(p, &reloc, 0);\r\nif (r) {\r\nDRM_ERROR("No reloc for packet3 %d\n", pkt->opcode);\r\nradeon_cs_dump_packet(p, pkt);\r\nreturn r;\r\n}\r\nib[idx] = radeon_get_ib_value(p, idx) + ((u32)reloc->gpu_offset);\r\ntrack->num_arrays = 1;\r\ntrack->vtx_size = r100_get_vtx_size(radeon_get_ib_value(p, idx + 2));\r\ntrack->arrays[0].robj = reloc->robj;\r\ntrack->arrays[0].esize = track->vtx_size;\r\ntrack->max_indx = radeon_get_ib_value(p, idx+1);\r\ntrack->vap_vf_cntl = radeon_get_ib_value(p, idx+3);\r\ntrack->immd_dwords = pkt->count - 1;\r\nr = r100_cs_track_check(p->rdev, track);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_3D_DRAW_IMMD:\r\nif (((radeon_get_ib_value(p, idx + 1) >> 4) & 0x3) != 3) {\r\nDRM_ERROR("PRIM_WALK must be 3 for IMMD draw\n");\r\nreturn -EINVAL;\r\n}\r\ntrack->vtx_size = r100_get_vtx_size(radeon_get_ib_value(p, idx + 0));\r\ntrack->vap_vf_cntl = radeon_get_ib_value(p, idx + 1);\r\ntrack->immd_dwords = pkt->count - 1;\r\nr = r100_cs_track_check(p->rdev, track);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_3D_DRAW_IMMD_2:\r\nif (((radeon_get_ib_value(p, idx) >> 4) & 0x3) != 3) {\r\nDRM_ERROR("PRIM_WALK must be 3 for IMMD draw\n");\r\nreturn -EINVAL;\r\n}\r\ntrack->vap_vf_cntl = radeon_get_ib_value(p, idx);\r\ntrack->immd_dwords = pkt->count;\r\nr = r100_cs_track_check(p->rdev, track);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_3D_DRAW_VBUF_2:\r\ntrack->vap_vf_cntl = radeon_get_ib_value(p, idx);\r\nr = r100_cs_track_check(p->rdev, track);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_3D_DRAW_INDX_2:\r\ntrack->vap_vf_cntl = radeon_get_ib_value(p, idx);\r\nr = r100_cs_track_check(p->rdev, track);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_3D_DRAW_VBUF:\r\ntrack->vap_vf_cntl = radeon_get_ib_value(p, idx + 1);\r\nr = r100_cs_track_check(p->rdev, track);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_3D_DRAW_INDX:\r\ntrack->vap_vf_cntl = radeon_get_ib_value(p, idx + 1);\r\nr = r100_cs_track_check(p->rdev, track);\r\nif (r)\r\nreturn r;\r\nbreak;\r\ncase PACKET3_3D_CLEAR_HIZ:\r\ncase PACKET3_3D_CLEAR_ZMASK:\r\nif (p->rdev->hyperz_filp != p->filp)\r\nreturn -EINVAL;\r\nbreak;\r\ncase PACKET3_NOP:\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Packet3 opcode %x not supported\n", pkt->opcode);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint r100_cs_parse(struct radeon_cs_parser *p)\r\n{\r\nstruct radeon_cs_packet pkt;\r\nstruct r100_cs_track *track;\r\nint r;\r\ntrack = kzalloc(sizeof(*track), GFP_KERNEL);\r\nif (!track)\r\nreturn -ENOMEM;\r\nr100_cs_track_clear(p->rdev, track);\r\np->track = track;\r\ndo {\r\nr = radeon_cs_packet_parse(p, &pkt, p->idx);\r\nif (r) {\r\nreturn r;\r\n}\r\np->idx += pkt.count + 2;\r\nswitch (pkt.type) {\r\ncase RADEON_PACKET_TYPE0:\r\nif (p->rdev->family >= CHIP_R200)\r\nr = r100_cs_parse_packet0(p, &pkt,\r\np->rdev->config.r100.reg_safe_bm,\r\np->rdev->config.r100.reg_safe_bm_size,\r\n&r200_packet0_check);\r\nelse\r\nr = r100_cs_parse_packet0(p, &pkt,\r\np->rdev->config.r100.reg_safe_bm,\r\np->rdev->config.r100.reg_safe_bm_size,\r\n&r100_packet0_check);\r\nbreak;\r\ncase RADEON_PACKET_TYPE2:\r\nbreak;\r\ncase RADEON_PACKET_TYPE3:\r\nr = r100_packet3_check(p, &pkt);\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unknown packet type %d !\n",\r\npkt.type);\r\nreturn -EINVAL;\r\n}\r\nif (r)\r\nreturn r;\r\n} while (p->idx < p->chunk_ib->length_dw);\r\nreturn 0;\r\n}\r\nstatic void r100_cs_track_texture_print(struct r100_cs_track_texture *t)\r\n{\r\nDRM_ERROR("pitch %d\n", t->pitch);\r\nDRM_ERROR("use_pitch %d\n", t->use_pitch);\r\nDRM_ERROR("width %d\n", t->width);\r\nDRM_ERROR("width_11 %d\n", t->width_11);\r\nDRM_ERROR("height %d\n", t->height);\r\nDRM_ERROR("height_11 %d\n", t->height_11);\r\nDRM_ERROR("num levels %d\n", t->num_levels);\r\nDRM_ERROR("depth %d\n", t->txdepth);\r\nDRM_ERROR("bpp %d\n", t->cpp);\r\nDRM_ERROR("coordinate type %d\n", t->tex_coord_type);\r\nDRM_ERROR("width round to power of 2 %d\n", t->roundup_w);\r\nDRM_ERROR("height round to power of 2 %d\n", t->roundup_h);\r\nDRM_ERROR("compress format %d\n", t->compress_format);\r\n}\r\nstatic int r100_track_compress_size(int compress_format, int w, int h)\r\n{\r\nint block_width, block_height, block_bytes;\r\nint wblocks, hblocks;\r\nint min_wblocks;\r\nint sz;\r\nblock_width = 4;\r\nblock_height = 4;\r\nswitch (compress_format) {\r\ncase R100_TRACK_COMP_DXT1:\r\nblock_bytes = 8;\r\nmin_wblocks = 4;\r\nbreak;\r\ndefault:\r\ncase R100_TRACK_COMP_DXT35:\r\nblock_bytes = 16;\r\nmin_wblocks = 2;\r\nbreak;\r\n}\r\nhblocks = (h + block_height - 1) / block_height;\r\nwblocks = (w + block_width - 1) / block_width;\r\nif (wblocks < min_wblocks)\r\nwblocks = min_wblocks;\r\nsz = wblocks * hblocks * block_bytes;\r\nreturn sz;\r\n}\r\nstatic int r100_cs_track_cube(struct radeon_device *rdev,\r\nstruct r100_cs_track *track, unsigned idx)\r\n{\r\nunsigned face, w, h;\r\nstruct radeon_bo *cube_robj;\r\nunsigned long size;\r\nunsigned compress_format = track->textures[idx].compress_format;\r\nfor (face = 0; face < 5; face++) {\r\ncube_robj = track->textures[idx].cube_info[face].robj;\r\nw = track->textures[idx].cube_info[face].width;\r\nh = track->textures[idx].cube_info[face].height;\r\nif (compress_format) {\r\nsize = r100_track_compress_size(compress_format, w, h);\r\n} else\r\nsize = w * h;\r\nsize *= track->textures[idx].cpp;\r\nsize += track->textures[idx].cube_info[face].offset;\r\nif (size > radeon_bo_size(cube_robj)) {\r\nDRM_ERROR("Cube texture offset greater than object size %lu %lu\n",\r\nsize, radeon_bo_size(cube_robj));\r\nr100_cs_track_texture_print(&track->textures[idx]);\r\nreturn -1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int r100_cs_track_texture_check(struct radeon_device *rdev,\r\nstruct r100_cs_track *track)\r\n{\r\nstruct radeon_bo *robj;\r\nunsigned long size;\r\nunsigned u, i, w, h, d;\r\nint ret;\r\nfor (u = 0; u < track->num_texture; u++) {\r\nif (!track->textures[u].enabled)\r\ncontinue;\r\nif (track->textures[u].lookup_disable)\r\ncontinue;\r\nrobj = track->textures[u].robj;\r\nif (robj == NULL) {\r\nDRM_ERROR("No texture bound to unit %u\n", u);\r\nreturn -EINVAL;\r\n}\r\nsize = 0;\r\nfor (i = 0; i <= track->textures[u].num_levels; i++) {\r\nif (track->textures[u].use_pitch) {\r\nif (rdev->family < CHIP_R300)\r\nw = (track->textures[u].pitch / track->textures[u].cpp) / (1 << i);\r\nelse\r\nw = track->textures[u].pitch / (1 << i);\r\n} else {\r\nw = track->textures[u].width;\r\nif (rdev->family >= CHIP_RV515)\r\nw |= track->textures[u].width_11;\r\nw = w / (1 << i);\r\nif (track->textures[u].roundup_w)\r\nw = roundup_pow_of_two(w);\r\n}\r\nh = track->textures[u].height;\r\nif (rdev->family >= CHIP_RV515)\r\nh |= track->textures[u].height_11;\r\nh = h / (1 << i);\r\nif (track->textures[u].roundup_h)\r\nh = roundup_pow_of_two(h);\r\nif (track->textures[u].tex_coord_type == 1) {\r\nd = (1 << track->textures[u].txdepth) / (1 << i);\r\nif (!d)\r\nd = 1;\r\n} else {\r\nd = 1;\r\n}\r\nif (track->textures[u].compress_format) {\r\nsize += r100_track_compress_size(track->textures[u].compress_format, w, h) * d;\r\n} else\r\nsize += w * h * d;\r\n}\r\nsize *= track->textures[u].cpp;\r\nswitch (track->textures[u].tex_coord_type) {\r\ncase 0:\r\ncase 1:\r\nbreak;\r\ncase 2:\r\nif (track->separate_cube) {\r\nret = r100_cs_track_cube(rdev, track, u);\r\nif (ret)\r\nreturn ret;\r\n} else\r\nsize *= 6;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Invalid texture coordinate type %u for unit "\r\n"%u\n", track->textures[u].tex_coord_type, u);\r\nreturn -EINVAL;\r\n}\r\nif (size > radeon_bo_size(robj)) {\r\nDRM_ERROR("Texture of unit %u needs %lu bytes but is "\r\n"%lu\n", u, size, radeon_bo_size(robj));\r\nr100_cs_track_texture_print(&track->textures[u]);\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint r100_cs_track_check(struct radeon_device *rdev, struct r100_cs_track *track)\r\n{\r\nunsigned i;\r\nunsigned long size;\r\nunsigned prim_walk;\r\nunsigned nverts;\r\nunsigned num_cb = track->cb_dirty ? track->num_cb : 0;\r\nif (num_cb && !track->zb_cb_clear && !track->color_channel_mask &&\r\n!track->blend_read_enable)\r\nnum_cb = 0;\r\nfor (i = 0; i < num_cb; i++) {\r\nif (track->cb[i].robj == NULL) {\r\nDRM_ERROR("[drm] No buffer for color buffer %d !\n", i);\r\nreturn -EINVAL;\r\n}\r\nsize = track->cb[i].pitch * track->cb[i].cpp * track->maxy;\r\nsize += track->cb[i].offset;\r\nif (size > radeon_bo_size(track->cb[i].robj)) {\r\nDRM_ERROR("[drm] Buffer too small for color buffer %d "\r\n"(need %lu have %lu) !\n", i, size,\r\nradeon_bo_size(track->cb[i].robj));\r\nDRM_ERROR("[drm] color buffer %d (%u %u %u %u)\n",\r\ni, track->cb[i].pitch, track->cb[i].cpp,\r\ntrack->cb[i].offset, track->maxy);\r\nreturn -EINVAL;\r\n}\r\n}\r\ntrack->cb_dirty = false;\r\nif (track->zb_dirty && track->z_enabled) {\r\nif (track->zb.robj == NULL) {\r\nDRM_ERROR("[drm] No buffer for z buffer !\n");\r\nreturn -EINVAL;\r\n}\r\nsize = track->zb.pitch * track->zb.cpp * track->maxy;\r\nsize += track->zb.offset;\r\nif (size > radeon_bo_size(track->zb.robj)) {\r\nDRM_ERROR("[drm] Buffer too small for z buffer "\r\n"(need %lu have %lu) !\n", size,\r\nradeon_bo_size(track->zb.robj));\r\nDRM_ERROR("[drm] zbuffer (%u %u %u %u)\n",\r\ntrack->zb.pitch, track->zb.cpp,\r\ntrack->zb.offset, track->maxy);\r\nreturn -EINVAL;\r\n}\r\n}\r\ntrack->zb_dirty = false;\r\nif (track->aa_dirty && track->aaresolve) {\r\nif (track->aa.robj == NULL) {\r\nDRM_ERROR("[drm] No buffer for AA resolve buffer %d !\n", i);\r\nreturn -EINVAL;\r\n}\r\nsize = track->aa.pitch * track->cb[0].cpp * track->maxy;\r\nsize += track->aa.offset;\r\nif (size > radeon_bo_size(track->aa.robj)) {\r\nDRM_ERROR("[drm] Buffer too small for AA resolve buffer %d "\r\n"(need %lu have %lu) !\n", i, size,\r\nradeon_bo_size(track->aa.robj));\r\nDRM_ERROR("[drm] AA resolve buffer %d (%u %u %u %u)\n",\r\ni, track->aa.pitch, track->cb[0].cpp,\r\ntrack->aa.offset, track->maxy);\r\nreturn -EINVAL;\r\n}\r\n}\r\ntrack->aa_dirty = false;\r\nprim_walk = (track->vap_vf_cntl >> 4) & 0x3;\r\nif (track->vap_vf_cntl & (1 << 14)) {\r\nnverts = track->vap_alt_nverts;\r\n} else {\r\nnverts = (track->vap_vf_cntl >> 16) & 0xFFFF;\r\n}\r\nswitch (prim_walk) {\r\ncase 1:\r\nfor (i = 0; i < track->num_arrays; i++) {\r\nsize = track->arrays[i].esize * track->max_indx * 4;\r\nif (track->arrays[i].robj == NULL) {\r\nDRM_ERROR("(PW %u) Vertex array %u no buffer "\r\n"bound\n", prim_walk, i);\r\nreturn -EINVAL;\r\n}\r\nif (size > radeon_bo_size(track->arrays[i].robj)) {\r\ndev_err(rdev->dev, "(PW %u) Vertex array %u "\r\n"need %lu dwords have %lu dwords\n",\r\nprim_walk, i, size >> 2,\r\nradeon_bo_size(track->arrays[i].robj)\r\n>> 2);\r\nDRM_ERROR("Max indices %u\n", track->max_indx);\r\nreturn -EINVAL;\r\n}\r\n}\r\nbreak;\r\ncase 2:\r\nfor (i = 0; i < track->num_arrays; i++) {\r\nsize = track->arrays[i].esize * (nverts - 1) * 4;\r\nif (track->arrays[i].robj == NULL) {\r\nDRM_ERROR("(PW %u) Vertex array %u no buffer "\r\n"bound\n", prim_walk, i);\r\nreturn -EINVAL;\r\n}\r\nif (size > radeon_bo_size(track->arrays[i].robj)) {\r\ndev_err(rdev->dev, "(PW %u) Vertex array %u "\r\n"need %lu dwords have %lu dwords\n",\r\nprim_walk, i, size >> 2,\r\nradeon_bo_size(track->arrays[i].robj)\r\n>> 2);\r\nreturn -EINVAL;\r\n}\r\n}\r\nbreak;\r\ncase 3:\r\nsize = track->vtx_size * nverts;\r\nif (size != track->immd_dwords) {\r\nDRM_ERROR("IMMD draw %u dwors but needs %lu dwords\n",\r\ntrack->immd_dwords, size);\r\nDRM_ERROR("VAP_VF_CNTL.NUM_VERTICES %u, VTX_SIZE %u\n",\r\nnverts, track->vtx_size);\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("[drm] Invalid primitive walk %d for VAP_VF_CNTL\n",\r\nprim_walk);\r\nreturn -EINVAL;\r\n}\r\nif (track->tex_dirty) {\r\ntrack->tex_dirty = false;\r\nreturn r100_cs_track_texture_check(rdev, track);\r\n}\r\nreturn 0;\r\n}\r\nvoid r100_cs_track_clear(struct radeon_device *rdev, struct r100_cs_track *track)\r\n{\r\nunsigned i, face;\r\ntrack->cb_dirty = true;\r\ntrack->zb_dirty = true;\r\ntrack->tex_dirty = true;\r\ntrack->aa_dirty = true;\r\nif (rdev->family < CHIP_R300) {\r\ntrack->num_cb = 1;\r\nif (rdev->family <= CHIP_RS200)\r\ntrack->num_texture = 3;\r\nelse\r\ntrack->num_texture = 6;\r\ntrack->maxy = 2048;\r\ntrack->separate_cube = 1;\r\n} else {\r\ntrack->num_cb = 4;\r\ntrack->num_texture = 16;\r\ntrack->maxy = 4096;\r\ntrack->separate_cube = 0;\r\ntrack->aaresolve = false;\r\ntrack->aa.robj = NULL;\r\n}\r\nfor (i = 0; i < track->num_cb; i++) {\r\ntrack->cb[i].robj = NULL;\r\ntrack->cb[i].pitch = 8192;\r\ntrack->cb[i].cpp = 16;\r\ntrack->cb[i].offset = 0;\r\n}\r\ntrack->z_enabled = true;\r\ntrack->zb.robj = NULL;\r\ntrack->zb.pitch = 8192;\r\ntrack->zb.cpp = 4;\r\ntrack->zb.offset = 0;\r\ntrack->vtx_size = 0x7F;\r\ntrack->immd_dwords = 0xFFFFFFFFUL;\r\ntrack->num_arrays = 11;\r\ntrack->max_indx = 0x00FFFFFFUL;\r\nfor (i = 0; i < track->num_arrays; i++) {\r\ntrack->arrays[i].robj = NULL;\r\ntrack->arrays[i].esize = 0x7F;\r\n}\r\nfor (i = 0; i < track->num_texture; i++) {\r\ntrack->textures[i].compress_format = R100_TRACK_COMP_NONE;\r\ntrack->textures[i].pitch = 16536;\r\ntrack->textures[i].width = 16536;\r\ntrack->textures[i].height = 16536;\r\ntrack->textures[i].width_11 = 1 << 11;\r\ntrack->textures[i].height_11 = 1 << 11;\r\ntrack->textures[i].num_levels = 12;\r\nif (rdev->family <= CHIP_RS200) {\r\ntrack->textures[i].tex_coord_type = 0;\r\ntrack->textures[i].txdepth = 0;\r\n} else {\r\ntrack->textures[i].txdepth = 16;\r\ntrack->textures[i].tex_coord_type = 1;\r\n}\r\ntrack->textures[i].cpp = 64;\r\ntrack->textures[i].robj = NULL;\r\ntrack->textures[i].enabled = false;\r\ntrack->textures[i].lookup_disable = false;\r\ntrack->textures[i].roundup_w = true;\r\ntrack->textures[i].roundup_h = true;\r\nif (track->separate_cube)\r\nfor (face = 0; face < 5; face++) {\r\ntrack->textures[i].cube_info[face].robj = NULL;\r\ntrack->textures[i].cube_info[face].width = 16536;\r\ntrack->textures[i].cube_info[face].height = 16536;\r\ntrack->textures[i].cube_info[face].offset = 0;\r\n}\r\n}\r\n}\r\nstatic void r100_errata(struct radeon_device *rdev)\r\n{\r\nrdev->pll_errata = 0;\r\nif (rdev->family == CHIP_RV200 || rdev->family == CHIP_RS200) {\r\nrdev->pll_errata |= CHIP_ERRATA_PLL_DUMMYREADS;\r\n}\r\nif (rdev->family == CHIP_RV100 ||\r\nrdev->family == CHIP_RS100 ||\r\nrdev->family == CHIP_RS200) {\r\nrdev->pll_errata |= CHIP_ERRATA_PLL_DELAY;\r\n}\r\n}\r\nstatic int r100_rbbm_fifo_wait_for_entry(struct radeon_device *rdev, unsigned n)\r\n{\r\nunsigned i;\r\nuint32_t tmp;\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(RADEON_RBBM_STATUS) & RADEON_RBBM_FIFOCNT_MASK;\r\nif (tmp >= n) {\r\nreturn 0;\r\n}\r\nDRM_UDELAY(1);\r\n}\r\nreturn -1;\r\n}\r\nint r100_gui_wait_for_idle(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nuint32_t tmp;\r\nif (r100_rbbm_fifo_wait_for_entry(rdev, 64)) {\r\nprintk(KERN_WARNING "radeon: wait for empty RBBM fifo failed !"\r\n" Bad things might happen.\n");\r\n}\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(RADEON_RBBM_STATUS);\r\nif (!(tmp & RADEON_RBBM_ACTIVE)) {\r\nreturn 0;\r\n}\r\nDRM_UDELAY(1);\r\n}\r\nreturn -1;\r\n}\r\nint r100_mc_wait_for_idle(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nuint32_t tmp;\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(RADEON_MC_STATUS);\r\nif (tmp & RADEON_MC_IDLE) {\r\nreturn 0;\r\n}\r\nDRM_UDELAY(1);\r\n}\r\nreturn -1;\r\n}\r\nbool r100_gpu_is_lockup(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nu32 rbbm_status;\r\nrbbm_status = RREG32(R_000E40_RBBM_STATUS);\r\nif (!G_000E40_GUI_ACTIVE(rbbm_status)) {\r\nradeon_ring_lockup_update(rdev, ring);\r\nreturn false;\r\n}\r\nreturn radeon_ring_test_lockup(rdev, ring);\r\n}\r\nvoid r100_enable_bm(struct radeon_device *rdev)\r\n{\r\nuint32_t tmp;\r\ntmp = RREG32(RADEON_BUS_CNTL) & ~RADEON_BUS_MASTER_DIS;\r\nWREG32(RADEON_BUS_CNTL, tmp);\r\n}\r\nvoid r100_bm_disable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\ntmp = RREG32(R_000030_BUS_CNTL);\r\nWREG32(R_000030_BUS_CNTL, (tmp & 0xFFFFFFFF) | 0x00000044);\r\nmdelay(1);\r\nWREG32(R_000030_BUS_CNTL, (tmp & 0xFFFFFFFF) | 0x00000042);\r\nmdelay(1);\r\nWREG32(R_000030_BUS_CNTL, (tmp & 0xFFFFFFFF) | 0x00000040);\r\ntmp = RREG32(RADEON_BUS_CNTL);\r\nmdelay(1);\r\npci_clear_master(rdev->pdev);\r\nmdelay(1);\r\n}\r\nint r100_asic_reset(struct radeon_device *rdev, bool hard)\r\n{\r\nstruct r100_mc_save save;\r\nu32 status, tmp;\r\nint ret = 0;\r\nstatus = RREG32(R_000E40_RBBM_STATUS);\r\nif (!G_000E40_GUI_ACTIVE(status)) {\r\nreturn 0;\r\n}\r\nr100_mc_stop(rdev, &save);\r\nstatus = RREG32(R_000E40_RBBM_STATUS);\r\ndev_info(rdev->dev, "(%s:%d) RBBM_STATUS=0x%08X\n", __func__, __LINE__, status);\r\nWREG32(RADEON_CP_CSQ_CNTL, 0);\r\ntmp = RREG32(RADEON_CP_RB_CNTL);\r\nWREG32(RADEON_CP_RB_CNTL, tmp | RADEON_RB_RPTR_WR_ENA);\r\nWREG32(RADEON_CP_RB_RPTR_WR, 0);\r\nWREG32(RADEON_CP_RB_WPTR, 0);\r\nWREG32(RADEON_CP_RB_CNTL, tmp);\r\npci_save_state(rdev->pdev);\r\nr100_bm_disable(rdev);\r\nWREG32(R_0000F0_RBBM_SOFT_RESET, S_0000F0_SOFT_RESET_SE(1) |\r\nS_0000F0_SOFT_RESET_RE(1) |\r\nS_0000F0_SOFT_RESET_PP(1) |\r\nS_0000F0_SOFT_RESET_RB(1));\r\nRREG32(R_0000F0_RBBM_SOFT_RESET);\r\nmdelay(500);\r\nWREG32(R_0000F0_RBBM_SOFT_RESET, 0);\r\nmdelay(1);\r\nstatus = RREG32(R_000E40_RBBM_STATUS);\r\ndev_info(rdev->dev, "(%s:%d) RBBM_STATUS=0x%08X\n", __func__, __LINE__, status);\r\nWREG32(R_0000F0_RBBM_SOFT_RESET, S_0000F0_SOFT_RESET_CP(1));\r\nRREG32(R_0000F0_RBBM_SOFT_RESET);\r\nmdelay(500);\r\nWREG32(R_0000F0_RBBM_SOFT_RESET, 0);\r\nmdelay(1);\r\nstatus = RREG32(R_000E40_RBBM_STATUS);\r\ndev_info(rdev->dev, "(%s:%d) RBBM_STATUS=0x%08X\n", __func__, __LINE__, status);\r\npci_restore_state(rdev->pdev);\r\nr100_enable_bm(rdev);\r\nif (G_000E40_SE_BUSY(status) || G_000E40_RE_BUSY(status) ||\r\nG_000E40_TAM_BUSY(status) || G_000E40_PB_BUSY(status)) {\r\ndev_err(rdev->dev, "failed to reset GPU\n");\r\nret = -1;\r\n} else\r\ndev_info(rdev->dev, "GPU reset succeed\n");\r\nr100_mc_resume(rdev, &save);\r\nreturn ret;\r\n}\r\nvoid r100_set_common_regs(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *dev = rdev->ddev;\r\nbool force_dac2 = false;\r\nu32 tmp;\r\nWREG32(RADEON_OV0_SCALE_CNTL, 0);\r\nWREG32(RADEON_SUBPIC_CNTL, 0);\r\nWREG32(RADEON_VIPH_CONTROL, 0);\r\nWREG32(RADEON_I2C_CNTL_1, 0);\r\nWREG32(RADEON_DVI_I2C_CNTL_1, 0);\r\nWREG32(RADEON_CAP0_TRIG_CNTL, 0);\r\nWREG32(RADEON_CAP1_TRIG_CNTL, 0);\r\nswitch (dev->pdev->device) {\r\ncase 0x515e:\r\ncase 0x5969:\r\nforce_dac2 = true;\r\nbreak;\r\ncase 0x5159:\r\ncase 0x515a:\r\nif ((dev->pdev->subsystem_vendor == 0x1028 ) &&\r\n((dev->pdev->subsystem_device == 0x016c) ||\r\n(dev->pdev->subsystem_device == 0x016d) ||\r\n(dev->pdev->subsystem_device == 0x016e) ||\r\n(dev->pdev->subsystem_device == 0x016f) ||\r\n(dev->pdev->subsystem_device == 0x0170) ||\r\n(dev->pdev->subsystem_device == 0x017d) ||\r\n(dev->pdev->subsystem_device == 0x017e) ||\r\n(dev->pdev->subsystem_device == 0x0183) ||\r\n(dev->pdev->subsystem_device == 0x018a) ||\r\n(dev->pdev->subsystem_device == 0x019a)))\r\nforce_dac2 = true;\r\nbreak;\r\n}\r\nif (force_dac2) {\r\nu32 disp_hw_debug = RREG32(RADEON_DISP_HW_DEBUG);\r\nu32 tv_dac_cntl = RREG32(RADEON_TV_DAC_CNTL);\r\nu32 dac2_cntl = RREG32(RADEON_DAC_CNTL2);\r\ndac2_cntl &= ~RADEON_DAC2_DAC_CLK_SEL;\r\ndac2_cntl |= RADEON_DAC2_DAC2_CLK_SEL;\r\ndisp_hw_debug |= RADEON_CRT2_DISP1_SEL;\r\ntv_dac_cntl &= ~(RADEON_TV_DAC_PEDESTAL |\r\nRADEON_TV_DAC_STD_MASK |\r\nRADEON_TV_DAC_RDACPD |\r\nRADEON_TV_DAC_GDACPD |\r\nRADEON_TV_DAC_BDACPD |\r\nRADEON_TV_DAC_BGADJ_MASK |\r\nRADEON_TV_DAC_DACADJ_MASK);\r\ntv_dac_cntl |= (RADEON_TV_DAC_NBLANK |\r\nRADEON_TV_DAC_NHOLD |\r\nRADEON_TV_DAC_STD_PS2 |\r\n(0x58 << 16));\r\nWREG32(RADEON_TV_DAC_CNTL, tv_dac_cntl);\r\nWREG32(RADEON_DISP_HW_DEBUG, disp_hw_debug);\r\nWREG32(RADEON_DAC_CNTL2, dac2_cntl);\r\n}\r\ntmp = RREG32_PLL(RADEON_PLL_PWRMGT_CNTL);\r\ntmp &= ~RADEON_PM_MODE_SEL;\r\nWREG32_PLL(RADEON_PLL_PWRMGT_CNTL, tmp);\r\n}\r\nstatic void r100_vram_get_type(struct radeon_device *rdev)\r\n{\r\nuint32_t tmp;\r\nrdev->mc.vram_is_ddr = false;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nrdev->mc.vram_is_ddr = true;\r\nelse if (RREG32(RADEON_MEM_SDRAM_MODE_REG) & RADEON_MEM_CFG_TYPE_DDR)\r\nrdev->mc.vram_is_ddr = true;\r\nif ((rdev->family == CHIP_RV100) ||\r\n(rdev->family == CHIP_RS100) ||\r\n(rdev->family == CHIP_RS200)) {\r\ntmp = RREG32(RADEON_MEM_CNTL);\r\nif (tmp & RV100_HALF_MODE) {\r\nrdev->mc.vram_width = 32;\r\n} else {\r\nrdev->mc.vram_width = 64;\r\n}\r\nif (rdev->flags & RADEON_SINGLE_CRTC) {\r\nrdev->mc.vram_width /= 4;\r\nrdev->mc.vram_is_ddr = true;\r\n}\r\n} else if (rdev->family <= CHIP_RV280) {\r\ntmp = RREG32(RADEON_MEM_CNTL);\r\nif (tmp & RADEON_MEM_NUM_CHANNELS_MASK) {\r\nrdev->mc.vram_width = 128;\r\n} else {\r\nrdev->mc.vram_width = 64;\r\n}\r\n} else {\r\nrdev->mc.vram_width = 128;\r\n}\r\n}\r\nstatic u32 r100_get_accessible_vram(struct radeon_device *rdev)\r\n{\r\nu32 aper_size;\r\nu8 byte;\r\naper_size = RREG32(RADEON_CONFIG_APER_SIZE);\r\nif (rdev->family == CHIP_RV280 ||\r\nrdev->family >= CHIP_RV350) {\r\nWREG32_P(RADEON_HOST_PATH_CNTL, RADEON_HDP_APER_CNTL,\r\n~RADEON_HDP_APER_CNTL);\r\nDRM_INFO("Generation 2 PCI interface, using max accessible memory\n");\r\nreturn aper_size * 2;\r\n}\r\npci_read_config_byte(rdev->pdev, 0xe, &byte);\r\nif (byte & 0x80) {\r\nDRM_INFO("Generation 1 PCI interface in multifunction mode\n");\r\nDRM_INFO("Limiting VRAM to one aperture\n");\r\nreturn aper_size;\r\n}\r\nif (RREG32(RADEON_HOST_PATH_CNTL) & RADEON_HDP_APER_CNTL)\r\nreturn aper_size * 2;\r\nreturn aper_size;\r\n}\r\nvoid r100_vram_init_sizes(struct radeon_device *rdev)\r\n{\r\nu64 config_aper_size;\r\nrdev->mc.aper_base = pci_resource_start(rdev->pdev, 0);\r\nrdev->mc.aper_size = pci_resource_len(rdev->pdev, 0);\r\nrdev->mc.visible_vram_size = r100_get_accessible_vram(rdev);\r\nif (rdev->mc.visible_vram_size > rdev->mc.aper_size)\r\nrdev->mc.visible_vram_size = rdev->mc.aper_size;\r\nconfig_aper_size = RREG32(RADEON_CONFIG_APER_SIZE);\r\nif (rdev->flags & RADEON_IS_IGP) {\r\nuint32_t tom;\r\ntom = RREG32(RADEON_NB_TOM);\r\nrdev->mc.real_vram_size = (((tom >> 16) - (tom & 0xffff) + 1) << 16);\r\nWREG32(RADEON_CONFIG_MEMSIZE, rdev->mc.real_vram_size);\r\nrdev->mc.mc_vram_size = rdev->mc.real_vram_size;\r\n} else {\r\nrdev->mc.real_vram_size = RREG32(RADEON_CONFIG_MEMSIZE);\r\nif (rdev->mc.real_vram_size == 0) {\r\nrdev->mc.real_vram_size = 8192 * 1024;\r\nWREG32(RADEON_CONFIG_MEMSIZE, rdev->mc.real_vram_size);\r\n}\r\nif (rdev->mc.aper_size > config_aper_size)\r\nconfig_aper_size = rdev->mc.aper_size;\r\nif (config_aper_size > rdev->mc.real_vram_size)\r\nrdev->mc.mc_vram_size = config_aper_size;\r\nelse\r\nrdev->mc.mc_vram_size = rdev->mc.real_vram_size;\r\n}\r\n}\r\nvoid r100_vga_set_state(struct radeon_device *rdev, bool state)\r\n{\r\nuint32_t temp;\r\ntemp = RREG32(RADEON_CONFIG_CNTL);\r\nif (state == false) {\r\ntemp &= ~RADEON_CFG_VGA_RAM_EN;\r\ntemp |= RADEON_CFG_VGA_IO_DIS;\r\n} else {\r\ntemp &= ~RADEON_CFG_VGA_IO_DIS;\r\n}\r\nWREG32(RADEON_CONFIG_CNTL, temp);\r\n}\r\nstatic void r100_mc_init(struct radeon_device *rdev)\r\n{\r\nu64 base;\r\nr100_vram_get_type(rdev);\r\nr100_vram_init_sizes(rdev);\r\nbase = rdev->mc.aper_base;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nbase = (RREG32(RADEON_NB_TOM) & 0xffff) << 16;\r\nradeon_vram_location(rdev, &rdev->mc, base);\r\nrdev->mc.gtt_base_align = 0;\r\nif (!(rdev->flags & RADEON_IS_AGP))\r\nradeon_gtt_location(rdev, &rdev->mc);\r\nradeon_update_bandwidth_info(rdev);\r\n}\r\nvoid r100_pll_errata_after_index(struct radeon_device *rdev)\r\n{\r\nif (rdev->pll_errata & CHIP_ERRATA_PLL_DUMMYREADS) {\r\n(void)RREG32(RADEON_CLOCK_CNTL_DATA);\r\n(void)RREG32(RADEON_CRTC_GEN_CNTL);\r\n}\r\n}\r\nstatic void r100_pll_errata_after_data(struct radeon_device *rdev)\r\n{\r\nif (rdev->pll_errata & CHIP_ERRATA_PLL_DELAY) {\r\nmdelay(5);\r\n}\r\nif (rdev->pll_errata & CHIP_ERRATA_R300_CG) {\r\nuint32_t save, tmp;\r\nsave = RREG32(RADEON_CLOCK_CNTL_INDEX);\r\ntmp = save & ~(0x3f | RADEON_PLL_WR_EN);\r\nWREG32(RADEON_CLOCK_CNTL_INDEX, tmp);\r\ntmp = RREG32(RADEON_CLOCK_CNTL_DATA);\r\nWREG32(RADEON_CLOCK_CNTL_INDEX, save);\r\n}\r\n}\r\nuint32_t r100_pll_rreg(struct radeon_device *rdev, uint32_t reg)\r\n{\r\nunsigned long flags;\r\nuint32_t data;\r\nspin_lock_irqsave(&rdev->pll_idx_lock, flags);\r\nWREG8(RADEON_CLOCK_CNTL_INDEX, reg & 0x3f);\r\nr100_pll_errata_after_index(rdev);\r\ndata = RREG32(RADEON_CLOCK_CNTL_DATA);\r\nr100_pll_errata_after_data(rdev);\r\nspin_unlock_irqrestore(&rdev->pll_idx_lock, flags);\r\nreturn data;\r\n}\r\nvoid r100_pll_wreg(struct radeon_device *rdev, uint32_t reg, uint32_t v)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&rdev->pll_idx_lock, flags);\r\nWREG8(RADEON_CLOCK_CNTL_INDEX, ((reg & 0x3f) | RADEON_PLL_WR_EN));\r\nr100_pll_errata_after_index(rdev);\r\nWREG32(RADEON_CLOCK_CNTL_DATA, v);\r\nr100_pll_errata_after_data(rdev);\r\nspin_unlock_irqrestore(&rdev->pll_idx_lock, flags);\r\n}\r\nstatic void r100_set_safe_registers(struct radeon_device *rdev)\r\n{\r\nif (ASIC_IS_RN50(rdev)) {\r\nrdev->config.r100.reg_safe_bm = rn50_reg_safe_bm;\r\nrdev->config.r100.reg_safe_bm_size = ARRAY_SIZE(rn50_reg_safe_bm);\r\n} else if (rdev->family < CHIP_R200) {\r\nrdev->config.r100.reg_safe_bm = r100_reg_safe_bm;\r\nrdev->config.r100.reg_safe_bm_size = ARRAY_SIZE(r100_reg_safe_bm);\r\n} else {\r\nr200_set_safe_registers(rdev);\r\n}\r\n}\r\nstatic int r100_debugfs_rbbm_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nuint32_t reg, value;\r\nunsigned i;\r\nseq_printf(m, "RBBM_STATUS 0x%08x\n", RREG32(RADEON_RBBM_STATUS));\r\nseq_printf(m, "RBBM_CMDFIFO_STAT 0x%08x\n", RREG32(0xE7C));\r\nseq_printf(m, "CP_STAT 0x%08x\n", RREG32(RADEON_CP_STAT));\r\nfor (i = 0; i < 64; i++) {\r\nWREG32(RADEON_RBBM_CMDFIFO_ADDR, i | 0x100);\r\nreg = (RREG32(RADEON_RBBM_CMDFIFO_DATA) - 1) >> 2;\r\nWREG32(RADEON_RBBM_CMDFIFO_ADDR, i);\r\nvalue = RREG32(RADEON_RBBM_CMDFIFO_DATA);\r\nseq_printf(m, "[0x%03X] 0x%04X=0x%08X\n", i, reg, value);\r\n}\r\nreturn 0;\r\n}\r\nstatic int r100_debugfs_cp_ring_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nuint32_t rdp, wdp;\r\nunsigned count, i, j;\r\nradeon_ring_free_size(rdev, ring);\r\nrdp = RREG32(RADEON_CP_RB_RPTR);\r\nwdp = RREG32(RADEON_CP_RB_WPTR);\r\ncount = (rdp + ring->ring_size - wdp) & ring->ptr_mask;\r\nseq_printf(m, "CP_STAT 0x%08x\n", RREG32(RADEON_CP_STAT));\r\nseq_printf(m, "CP_RB_WPTR 0x%08x\n", wdp);\r\nseq_printf(m, "CP_RB_RPTR 0x%08x\n", rdp);\r\nseq_printf(m, "%u free dwords in ring\n", ring->ring_free_dw);\r\nseq_printf(m, "%u dwords in ring\n", count);\r\nif (ring->ready) {\r\nfor (j = 0; j <= count; j++) {\r\ni = (rdp + j) & ring->ptr_mask;\r\nseq_printf(m, "r[%04d]=0x%08x\n", i, ring->ring[i]);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int r100_debugfs_cp_csq_fifo(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nuint32_t csq_stat, csq2_stat, tmp;\r\nunsigned r_rptr, r_wptr, ib1_rptr, ib1_wptr, ib2_rptr, ib2_wptr;\r\nunsigned i;\r\nseq_printf(m, "CP_STAT 0x%08x\n", RREG32(RADEON_CP_STAT));\r\nseq_printf(m, "CP_CSQ_MODE 0x%08x\n", RREG32(RADEON_CP_CSQ_MODE));\r\ncsq_stat = RREG32(RADEON_CP_CSQ_STAT);\r\ncsq2_stat = RREG32(RADEON_CP_CSQ2_STAT);\r\nr_rptr = (csq_stat >> 0) & 0x3ff;\r\nr_wptr = (csq_stat >> 10) & 0x3ff;\r\nib1_rptr = (csq_stat >> 20) & 0x3ff;\r\nib1_wptr = (csq2_stat >> 0) & 0x3ff;\r\nib2_rptr = (csq2_stat >> 10) & 0x3ff;\r\nib2_wptr = (csq2_stat >> 20) & 0x3ff;\r\nseq_printf(m, "CP_CSQ_STAT 0x%08x\n", csq_stat);\r\nseq_printf(m, "CP_CSQ2_STAT 0x%08x\n", csq2_stat);\r\nseq_printf(m, "Ring rptr %u\n", r_rptr);\r\nseq_printf(m, "Ring wptr %u\n", r_wptr);\r\nseq_printf(m, "Indirect1 rptr %u\n", ib1_rptr);\r\nseq_printf(m, "Indirect1 wptr %u\n", ib1_wptr);\r\nseq_printf(m, "Indirect2 rptr %u\n", ib2_rptr);\r\nseq_printf(m, "Indirect2 wptr %u\n", ib2_wptr);\r\nseq_printf(m, "Ring fifo:\n");\r\nfor (i = 0; i < 256; i++) {\r\nWREG32(RADEON_CP_CSQ_ADDR, i << 2);\r\ntmp = RREG32(RADEON_CP_CSQ_DATA);\r\nseq_printf(m, "rfifo[%04d]=0x%08X\n", i, tmp);\r\n}\r\nseq_printf(m, "Indirect1 fifo:\n");\r\nfor (i = 256; i <= 512; i++) {\r\nWREG32(RADEON_CP_CSQ_ADDR, i << 2);\r\ntmp = RREG32(RADEON_CP_CSQ_DATA);\r\nseq_printf(m, "ib1fifo[%04d]=0x%08X\n", i, tmp);\r\n}\r\nseq_printf(m, "Indirect2 fifo:\n");\r\nfor (i = 640; i < ib1_wptr; i++) {\r\nWREG32(RADEON_CP_CSQ_ADDR, i << 2);\r\ntmp = RREG32(RADEON_CP_CSQ_DATA);\r\nseq_printf(m, "ib2fifo[%04d]=0x%08X\n", i, tmp);\r\n}\r\nreturn 0;\r\n}\r\nstatic int r100_debugfs_mc_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nuint32_t tmp;\r\ntmp = RREG32(RADEON_CONFIG_MEMSIZE);\r\nseq_printf(m, "CONFIG_MEMSIZE 0x%08x\n", tmp);\r\ntmp = RREG32(RADEON_MC_FB_LOCATION);\r\nseq_printf(m, "MC_FB_LOCATION 0x%08x\n", tmp);\r\ntmp = RREG32(RADEON_BUS_CNTL);\r\nseq_printf(m, "BUS_CNTL 0x%08x\n", tmp);\r\ntmp = RREG32(RADEON_MC_AGP_LOCATION);\r\nseq_printf(m, "MC_AGP_LOCATION 0x%08x\n", tmp);\r\ntmp = RREG32(RADEON_AGP_BASE);\r\nseq_printf(m, "AGP_BASE 0x%08x\n", tmp);\r\ntmp = RREG32(RADEON_HOST_PATH_CNTL);\r\nseq_printf(m, "HOST_PATH_CNTL 0x%08x\n", tmp);\r\ntmp = RREG32(0x01D0);\r\nseq_printf(m, "AIC_CTRL 0x%08x\n", tmp);\r\ntmp = RREG32(RADEON_AIC_LO_ADDR);\r\nseq_printf(m, "AIC_LO_ADDR 0x%08x\n", tmp);\r\ntmp = RREG32(RADEON_AIC_HI_ADDR);\r\nseq_printf(m, "AIC_HI_ADDR 0x%08x\n", tmp);\r\ntmp = RREG32(0x01E4);\r\nseq_printf(m, "AIC_TLB_ADDR 0x%08x\n", tmp);\r\nreturn 0;\r\n}\r\nint r100_debugfs_rbbm_init(struct radeon_device *rdev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nreturn radeon_debugfs_add_files(rdev, r100_debugfs_rbbm_list, 1);\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nint r100_debugfs_cp_init(struct radeon_device *rdev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nreturn radeon_debugfs_add_files(rdev, r100_debugfs_cp_list, 2);\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nint r100_debugfs_mc_info_init(struct radeon_device *rdev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nreturn radeon_debugfs_add_files(rdev, r100_debugfs_mc_info_list, 1);\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nint r100_set_surface_reg(struct radeon_device *rdev, int reg,\r\nuint32_t tiling_flags, uint32_t pitch,\r\nuint32_t offset, uint32_t obj_size)\r\n{\r\nint surf_index = reg * 16;\r\nint flags = 0;\r\nif (rdev->family <= CHIP_RS200) {\r\nif ((tiling_flags & (RADEON_TILING_MACRO|RADEON_TILING_MICRO))\r\n== (RADEON_TILING_MACRO|RADEON_TILING_MICRO))\r\nflags |= RADEON_SURF_TILE_COLOR_BOTH;\r\nif (tiling_flags & RADEON_TILING_MACRO)\r\nflags |= RADEON_SURF_TILE_COLOR_MACRO;\r\nif ((tiling_flags & (RADEON_TILING_MACRO|RADEON_TILING_MICRO))\r\n== 0)\r\npitch = 0;\r\n} else if (rdev->family <= CHIP_RV280) {\r\nif (tiling_flags & (RADEON_TILING_MACRO))\r\nflags |= R200_SURF_TILE_COLOR_MACRO;\r\nif (tiling_flags & RADEON_TILING_MICRO)\r\nflags |= R200_SURF_TILE_COLOR_MICRO;\r\n} else {\r\nif (tiling_flags & RADEON_TILING_MACRO)\r\nflags |= R300_SURF_TILE_MACRO;\r\nif (tiling_flags & RADEON_TILING_MICRO)\r\nflags |= R300_SURF_TILE_MICRO;\r\n}\r\nif (tiling_flags & RADEON_TILING_SWAP_16BIT)\r\nflags |= RADEON_SURF_AP0_SWP_16BPP | RADEON_SURF_AP1_SWP_16BPP;\r\nif (tiling_flags & RADEON_TILING_SWAP_32BIT)\r\nflags |= RADEON_SURF_AP0_SWP_32BPP | RADEON_SURF_AP1_SWP_32BPP;\r\nif (rdev->family < CHIP_R300)\r\nflags |= pitch / 16;\r\nelse\r\nflags |= pitch / 8;\r\nDRM_DEBUG_KMS("writing surface %d %d %x %x\n", reg, flags, offset, offset+obj_size-1);\r\nWREG32(RADEON_SURFACE0_INFO + surf_index, flags);\r\nWREG32(RADEON_SURFACE0_LOWER_BOUND + surf_index, offset);\r\nWREG32(RADEON_SURFACE0_UPPER_BOUND + surf_index, offset + obj_size - 1);\r\nreturn 0;\r\n}\r\nvoid r100_clear_surface_reg(struct radeon_device *rdev, int reg)\r\n{\r\nint surf_index = reg * 16;\r\nWREG32(RADEON_SURFACE0_INFO + surf_index, 0);\r\n}\r\nvoid r100_bandwidth_update(struct radeon_device *rdev)\r\n{\r\nfixed20_12 trcd_ff, trp_ff, tras_ff, trbs_ff, tcas_ff;\r\nfixed20_12 sclk_ff, mclk_ff, sclk_eff_ff, sclk_delay_ff;\r\nfixed20_12 peak_disp_bw, mem_bw, pix_clk, pix_clk2, temp_ff;\r\nfixed20_12 crit_point_ff = {0};\r\nuint32_t temp, data, mem_trcd, mem_trp, mem_tras;\r\nfixed20_12 memtcas_ff[8] = {\r\ndfixed_init(1),\r\ndfixed_init(2),\r\ndfixed_init(3),\r\ndfixed_init(0),\r\ndfixed_init_half(1),\r\ndfixed_init_half(2),\r\ndfixed_init(0),\r\n};\r\nfixed20_12 memtcas_rs480_ff[8] = {\r\ndfixed_init(0),\r\ndfixed_init(1),\r\ndfixed_init(2),\r\ndfixed_init(3),\r\ndfixed_init(0),\r\ndfixed_init_half(1),\r\ndfixed_init_half(2),\r\ndfixed_init_half(3),\r\n};\r\nfixed20_12 memtcas2_ff[8] = {\r\ndfixed_init(0),\r\ndfixed_init(1),\r\ndfixed_init(2),\r\ndfixed_init(3),\r\ndfixed_init(4),\r\ndfixed_init(5),\r\ndfixed_init(6),\r\ndfixed_init(7),\r\n};\r\nfixed20_12 memtrbs[8] = {\r\ndfixed_init(1),\r\ndfixed_init_half(1),\r\ndfixed_init(2),\r\ndfixed_init_half(2),\r\ndfixed_init(3),\r\ndfixed_init_half(3),\r\ndfixed_init(4),\r\ndfixed_init_half(4)\r\n};\r\nfixed20_12 memtrbs_r4xx[8] = {\r\ndfixed_init(4),\r\ndfixed_init(5),\r\ndfixed_init(6),\r\ndfixed_init(7),\r\ndfixed_init(8),\r\ndfixed_init(9),\r\ndfixed_init(10),\r\ndfixed_init(11)\r\n};\r\nfixed20_12 min_mem_eff;\r\nfixed20_12 mc_latency_sclk, mc_latency_mclk, k1;\r\nfixed20_12 cur_latency_mclk, cur_latency_sclk;\r\nfixed20_12 disp_latency, disp_latency_overhead, disp_drain_rate = {0},\r\ndisp_drain_rate2, read_return_rate;\r\nfixed20_12 time_disp1_drop_priority;\r\nint c;\r\nint cur_size = 16;\r\nint critical_point = 0, critical_point2;\r\nint stop_req, max_stop_req;\r\nstruct drm_display_mode *mode1 = NULL;\r\nstruct drm_display_mode *mode2 = NULL;\r\nuint32_t pixel_bytes1 = 0;\r\nuint32_t pixel_bytes2 = 0;\r\nu32 lb_size = 8192;\r\nif (!rdev->mode_info.mode_config_initialized)\r\nreturn;\r\nradeon_update_display_priority(rdev);\r\nif (rdev->mode_info.crtcs[0]->base.enabled) {\r\nmode1 = &rdev->mode_info.crtcs[0]->base.mode;\r\npixel_bytes1 = rdev->mode_info.crtcs[0]->base.primary->fb->bits_per_pixel / 8;\r\n}\r\nif (!(rdev->flags & RADEON_SINGLE_CRTC)) {\r\nif (rdev->mode_info.crtcs[1]->base.enabled) {\r\nmode2 = &rdev->mode_info.crtcs[1]->base.mode;\r\npixel_bytes2 = rdev->mode_info.crtcs[1]->base.primary->fb->bits_per_pixel / 8;\r\n}\r\n}\r\nmin_mem_eff.full = dfixed_const_8(0);\r\nif ((rdev->disp_priority == 2) && ASIC_IS_R300(rdev)) {\r\nuint32_t mc_init_misc_lat_timer = RREG32(R300_MC_INIT_MISC_LAT_TIMER);\r\nmc_init_misc_lat_timer &= ~(R300_MC_DISP1R_INIT_LAT_MASK << R300_MC_DISP1R_INIT_LAT_SHIFT);\r\nmc_init_misc_lat_timer &= ~(R300_MC_DISP0R_INIT_LAT_MASK << R300_MC_DISP0R_INIT_LAT_SHIFT);\r\nif (mode2)\r\nmc_init_misc_lat_timer |= (1 << R300_MC_DISP1R_INIT_LAT_SHIFT);\r\nif (mode1)\r\nmc_init_misc_lat_timer |= (1 << R300_MC_DISP0R_INIT_LAT_SHIFT);\r\nWREG32(R300_MC_INIT_MISC_LAT_TIMER, mc_init_misc_lat_timer);\r\n}\r\nsclk_ff = rdev->pm.sclk;\r\nmclk_ff = rdev->pm.mclk;\r\ntemp = (rdev->mc.vram_width / 8) * (rdev->mc.vram_is_ddr ? 2 : 1);\r\ntemp_ff.full = dfixed_const(temp);\r\nmem_bw.full = dfixed_mul(mclk_ff, temp_ff);\r\npix_clk.full = 0;\r\npix_clk2.full = 0;\r\npeak_disp_bw.full = 0;\r\nif (mode1) {\r\ntemp_ff.full = dfixed_const(1000);\r\npix_clk.full = dfixed_const(mode1->clock);\r\npix_clk.full = dfixed_div(pix_clk, temp_ff);\r\ntemp_ff.full = dfixed_const(pixel_bytes1);\r\npeak_disp_bw.full += dfixed_mul(pix_clk, temp_ff);\r\n}\r\nif (mode2) {\r\ntemp_ff.full = dfixed_const(1000);\r\npix_clk2.full = dfixed_const(mode2->clock);\r\npix_clk2.full = dfixed_div(pix_clk2, temp_ff);\r\ntemp_ff.full = dfixed_const(pixel_bytes2);\r\npeak_disp_bw.full += dfixed_mul(pix_clk2, temp_ff);\r\n}\r\nmem_bw.full = dfixed_mul(mem_bw, min_mem_eff);\r\nif (peak_disp_bw.full >= mem_bw.full) {\r\nDRM_ERROR("You may not have enough display bandwidth for current mode\n"\r\n"If you have flickering problem, try to lower resolution, refresh rate, or color depth\n");\r\n}\r\ntemp = RREG32(RADEON_MEM_TIMING_CNTL);\r\nif ((rdev->family == CHIP_RV100) || (rdev->flags & RADEON_IS_IGP)) {\r\nmem_trcd = ((temp >> 2) & 0x3) + 1;\r\nmem_trp = ((temp & 0x3)) + 1;\r\nmem_tras = ((temp & 0x70) >> 4) + 1;\r\n} else if (rdev->family == CHIP_R300 ||\r\nrdev->family == CHIP_R350) {\r\nmem_trcd = (temp & 0x7) + 1;\r\nmem_trp = ((temp >> 8) & 0x7) + 1;\r\nmem_tras = ((temp >> 11) & 0xf) + 4;\r\n} else if (rdev->family == CHIP_RV350 ||\r\nrdev->family <= CHIP_RV380) {\r\nmem_trcd = (temp & 0x7) + 3;\r\nmem_trp = ((temp >> 8) & 0x7) + 3;\r\nmem_tras = ((temp >> 11) & 0xf) + 6;\r\n} else if (rdev->family == CHIP_R420 ||\r\nrdev->family == CHIP_R423 ||\r\nrdev->family == CHIP_RV410) {\r\nmem_trcd = (temp & 0xf) + 3;\r\nif (mem_trcd > 15)\r\nmem_trcd = 15;\r\nmem_trp = ((temp >> 8) & 0xf) + 3;\r\nif (mem_trp > 15)\r\nmem_trp = 15;\r\nmem_tras = ((temp >> 12) & 0x1f) + 6;\r\nif (mem_tras > 31)\r\nmem_tras = 31;\r\n} else {\r\nmem_trcd = (temp & 0x7) + 1;\r\nmem_trp = ((temp >> 8) & 0x7) + 1;\r\nmem_tras = ((temp >> 12) & 0xf) + 4;\r\n}\r\ntrcd_ff.full = dfixed_const(mem_trcd);\r\ntrp_ff.full = dfixed_const(mem_trp);\r\ntras_ff.full = dfixed_const(mem_tras);\r\ntemp = RREG32(RADEON_MEM_SDRAM_MODE_REG);\r\ndata = (temp & (7 << 20)) >> 20;\r\nif ((rdev->family == CHIP_RV100) || rdev->flags & RADEON_IS_IGP) {\r\nif (rdev->family == CHIP_RS480)\r\ntcas_ff = memtcas_rs480_ff[data];\r\nelse\r\ntcas_ff = memtcas_ff[data];\r\n} else\r\ntcas_ff = memtcas2_ff[data];\r\nif (rdev->family == CHIP_RS400 ||\r\nrdev->family == CHIP_RS480) {\r\ndata = (temp >> 23) & 0x7;\r\nif (data < 5)\r\ntcas_ff.full += dfixed_const(data);\r\n}\r\nif (ASIC_IS_R300(rdev) && !(rdev->flags & RADEON_IS_IGP)) {\r\ntemp = RREG32(RADEON_MEM_CNTL);\r\ndata = (R300_MEM_NUM_CHANNELS_MASK & temp);\r\nif (data == 1) {\r\nif (R300_MEM_USE_CD_CH_ONLY & temp) {\r\ntemp = RREG32(R300_MC_IND_INDEX);\r\ntemp &= ~R300_MC_IND_ADDR_MASK;\r\ntemp |= R300_MC_READ_CNTL_CD_mcind;\r\nWREG32(R300_MC_IND_INDEX, temp);\r\ntemp = RREG32(R300_MC_IND_DATA);\r\ndata = (R300_MEM_RBS_POSITION_C_MASK & temp);\r\n} else {\r\ntemp = RREG32(R300_MC_READ_CNTL_AB);\r\ndata = (R300_MEM_RBS_POSITION_A_MASK & temp);\r\n}\r\n} else {\r\ntemp = RREG32(R300_MC_READ_CNTL_AB);\r\ndata = (R300_MEM_RBS_POSITION_A_MASK & temp);\r\n}\r\nif (rdev->family == CHIP_RV410 ||\r\nrdev->family == CHIP_R420 ||\r\nrdev->family == CHIP_R423)\r\ntrbs_ff = memtrbs_r4xx[data];\r\nelse\r\ntrbs_ff = memtrbs[data];\r\ntcas_ff.full += trbs_ff.full;\r\n}\r\nsclk_eff_ff.full = sclk_ff.full;\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nfixed20_12 agpmode_ff;\r\nagpmode_ff.full = dfixed_const(radeon_agpmode);\r\ntemp_ff.full = dfixed_const_666(16);\r\nsclk_eff_ff.full -= dfixed_mul(agpmode_ff, temp_ff);\r\n}\r\nif (ASIC_IS_R300(rdev)) {\r\nsclk_delay_ff.full = dfixed_const(250);\r\n} else {\r\nif ((rdev->family == CHIP_RV100) ||\r\nrdev->flags & RADEON_IS_IGP) {\r\nif (rdev->mc.vram_is_ddr)\r\nsclk_delay_ff.full = dfixed_const(41);\r\nelse\r\nsclk_delay_ff.full = dfixed_const(33);\r\n} else {\r\nif (rdev->mc.vram_width == 128)\r\nsclk_delay_ff.full = dfixed_const(57);\r\nelse\r\nsclk_delay_ff.full = dfixed_const(41);\r\n}\r\n}\r\nmc_latency_sclk.full = dfixed_div(sclk_delay_ff, sclk_eff_ff);\r\nif (rdev->mc.vram_is_ddr) {\r\nif (rdev->mc.vram_width == 32) {\r\nk1.full = dfixed_const(40);\r\nc = 3;\r\n} else {\r\nk1.full = dfixed_const(20);\r\nc = 1;\r\n}\r\n} else {\r\nk1.full = dfixed_const(40);\r\nc = 3;\r\n}\r\ntemp_ff.full = dfixed_const(2);\r\nmc_latency_mclk.full = dfixed_mul(trcd_ff, temp_ff);\r\ntemp_ff.full = dfixed_const(c);\r\nmc_latency_mclk.full += dfixed_mul(tcas_ff, temp_ff);\r\ntemp_ff.full = dfixed_const(4);\r\nmc_latency_mclk.full += dfixed_mul(tras_ff, temp_ff);\r\nmc_latency_mclk.full += dfixed_mul(trp_ff, temp_ff);\r\nmc_latency_mclk.full += k1.full;\r\nmc_latency_mclk.full = dfixed_div(mc_latency_mclk, mclk_ff);\r\nmc_latency_mclk.full += dfixed_div(temp_ff, sclk_eff_ff);\r\ntemp_ff.full = dfixed_const((2 * (cur_size - (rdev->mc.vram_is_ddr + 1))));\r\ntemp_ff.full += trcd_ff.full;\r\nif (temp_ff.full < tras_ff.full)\r\ntemp_ff.full = tras_ff.full;\r\ncur_latency_mclk.full = dfixed_div(temp_ff, mclk_ff);\r\ntemp_ff.full = dfixed_const(cur_size);\r\ncur_latency_sclk.full = dfixed_div(temp_ff, sclk_eff_ff);\r\ndisp_latency_overhead.full = dfixed_const(8);\r\ndisp_latency_overhead.full = dfixed_div(disp_latency_overhead, sclk_ff);\r\nmc_latency_mclk.full += disp_latency_overhead.full + cur_latency_mclk.full;\r\nmc_latency_sclk.full += disp_latency_overhead.full + cur_latency_sclk.full;\r\nif (mc_latency_mclk.full > mc_latency_sclk.full)\r\ndisp_latency.full = mc_latency_mclk.full;\r\nelse\r\ndisp_latency.full = mc_latency_sclk.full;\r\nif (ASIC_IS_RV100(rdev))\r\nmax_stop_req = 0x5c;\r\nelse\r\nmax_stop_req = 0x7c;\r\nif (mode1) {\r\nstop_req = mode1->hdisplay * pixel_bytes1 / 16;\r\nif (stop_req > max_stop_req)\r\nstop_req = max_stop_req;\r\ntemp_ff.full = dfixed_const((16/pixel_bytes1));\r\ndisp_drain_rate.full = dfixed_div(pix_clk, temp_ff);\r\ncrit_point_ff.full = dfixed_mul(disp_drain_rate, disp_latency);\r\ncrit_point_ff.full += dfixed_const_half(0);\r\ncritical_point = dfixed_trunc(crit_point_ff);\r\nif (rdev->disp_priority == 2) {\r\ncritical_point = 0;\r\n}\r\nif (max_stop_req - critical_point < 4)\r\ncritical_point = 0;\r\nif (critical_point == 0 && mode2 && rdev->family == CHIP_R300) {\r\ncritical_point = 0x10;\r\n}\r\ntemp = RREG32(RADEON_GRPH_BUFFER_CNTL);\r\ntemp &= ~(RADEON_GRPH_STOP_REQ_MASK);\r\ntemp |= (stop_req << RADEON_GRPH_STOP_REQ_SHIFT);\r\ntemp &= ~(RADEON_GRPH_START_REQ_MASK);\r\nif ((rdev->family == CHIP_R350) &&\r\n(stop_req > 0x15)) {\r\nstop_req -= 0x10;\r\n}\r\ntemp |= (stop_req << RADEON_GRPH_START_REQ_SHIFT);\r\ntemp |= RADEON_GRPH_BUFFER_SIZE;\r\ntemp &= ~(RADEON_GRPH_CRITICAL_CNTL |\r\nRADEON_GRPH_CRITICAL_AT_SOF |\r\nRADEON_GRPH_STOP_CNTL);\r\nWREG32(RADEON_GRPH_BUFFER_CNTL, ((temp & ~RADEON_GRPH_CRITICAL_POINT_MASK) |\r\n(critical_point << RADEON_GRPH_CRITICAL_POINT_SHIFT)));\r\n#if 0\r\nif ((rdev->family == CHIP_RS400) ||\r\n(rdev->family == CHIP_RS480)) {\r\ntemp = RREG32(RS400_DISP1_REG_CNTL);\r\ntemp &= ~(RS400_DISP1_START_REQ_LEVEL_MASK |\r\nRS400_DISP1_STOP_REQ_LEVEL_MASK);\r\nWREG32(RS400_DISP1_REQ_CNTL1, (temp |\r\n(critical_point << RS400_DISP1_START_REQ_LEVEL_SHIFT) |\r\n(critical_point << RS400_DISP1_STOP_REQ_LEVEL_SHIFT)));\r\ntemp = RREG32(RS400_DMIF_MEM_CNTL1);\r\ntemp &= ~(RS400_DISP1_CRITICAL_POINT_START_MASK |\r\nRS400_DISP1_CRITICAL_POINT_STOP_MASK);\r\nWREG32(RS400_DMIF_MEM_CNTL1, (temp |\r\n(critical_point << RS400_DISP1_CRITICAL_POINT_START_SHIFT) |\r\n(critical_point << RS400_DISP1_CRITICAL_POINT_STOP_SHIFT)));\r\n}\r\n#endif\r\nDRM_DEBUG_KMS("GRPH_BUFFER_CNTL from to %x\n",\r\n(unsigned int)RREG32(RADEON_GRPH_BUFFER_CNTL));\r\n}\r\nif (mode2) {\r\nu32 grph2_cntl;\r\nstop_req = mode2->hdisplay * pixel_bytes2 / 16;\r\nif (stop_req > max_stop_req)\r\nstop_req = max_stop_req;\r\ntemp_ff.full = dfixed_const((16/pixel_bytes2));\r\ndisp_drain_rate2.full = dfixed_div(pix_clk2, temp_ff);\r\ngrph2_cntl = RREG32(RADEON_GRPH2_BUFFER_CNTL);\r\ngrph2_cntl &= ~(RADEON_GRPH_STOP_REQ_MASK);\r\ngrph2_cntl |= (stop_req << RADEON_GRPH_STOP_REQ_SHIFT);\r\ngrph2_cntl &= ~(RADEON_GRPH_START_REQ_MASK);\r\nif ((rdev->family == CHIP_R350) &&\r\n(stop_req > 0x15)) {\r\nstop_req -= 0x10;\r\n}\r\ngrph2_cntl |= (stop_req << RADEON_GRPH_START_REQ_SHIFT);\r\ngrph2_cntl |= RADEON_GRPH_BUFFER_SIZE;\r\ngrph2_cntl &= ~(RADEON_GRPH_CRITICAL_CNTL |\r\nRADEON_GRPH_CRITICAL_AT_SOF |\r\nRADEON_GRPH_STOP_CNTL);\r\nif ((rdev->family == CHIP_RS100) ||\r\n(rdev->family == CHIP_RS200))\r\ncritical_point2 = 0;\r\nelse {\r\ntemp = (rdev->mc.vram_width * rdev->mc.vram_is_ddr + 1)/128;\r\ntemp_ff.full = dfixed_const(temp);\r\ntemp_ff.full = dfixed_mul(mclk_ff, temp_ff);\r\nif (sclk_ff.full < temp_ff.full)\r\ntemp_ff.full = sclk_ff.full;\r\nread_return_rate.full = temp_ff.full;\r\nif (mode1) {\r\ntemp_ff.full = read_return_rate.full - disp_drain_rate.full;\r\ntime_disp1_drop_priority.full = dfixed_div(crit_point_ff, temp_ff);\r\n} else {\r\ntime_disp1_drop_priority.full = 0;\r\n}\r\ncrit_point_ff.full = disp_latency.full + time_disp1_drop_priority.full + disp_latency.full;\r\ncrit_point_ff.full = dfixed_mul(crit_point_ff, disp_drain_rate2);\r\ncrit_point_ff.full += dfixed_const_half(0);\r\ncritical_point2 = dfixed_trunc(crit_point_ff);\r\nif (rdev->disp_priority == 2) {\r\ncritical_point2 = 0;\r\n}\r\nif (max_stop_req - critical_point2 < 4)\r\ncritical_point2 = 0;\r\n}\r\nif (critical_point2 == 0 && rdev->family == CHIP_R300) {\r\ncritical_point2 = 0x10;\r\n}\r\nWREG32(RADEON_GRPH2_BUFFER_CNTL, ((grph2_cntl & ~RADEON_GRPH_CRITICAL_POINT_MASK) |\r\n(critical_point2 << RADEON_GRPH_CRITICAL_POINT_SHIFT)));\r\nif ((rdev->family == CHIP_RS400) ||\r\n(rdev->family == CHIP_RS480)) {\r\n#if 0\r\ntemp = RREG32(RS400_DISP2_REQ_CNTL1);\r\ntemp &= ~(RS400_DISP2_START_REQ_LEVEL_MASK |\r\nRS400_DISP2_STOP_REQ_LEVEL_MASK);\r\nWREG32(RS400_DISP2_REQ_CNTL1, (temp |\r\n(critical_point2 << RS400_DISP1_START_REQ_LEVEL_SHIFT) |\r\n(critical_point2 << RS400_DISP1_STOP_REQ_LEVEL_SHIFT)));\r\ntemp = RREG32(RS400_DISP2_REQ_CNTL2);\r\ntemp &= ~(RS400_DISP2_CRITICAL_POINT_START_MASK |\r\nRS400_DISP2_CRITICAL_POINT_STOP_MASK);\r\nWREG32(RS400_DISP2_REQ_CNTL2, (temp |\r\n(critical_point2 << RS400_DISP2_CRITICAL_POINT_START_SHIFT) |\r\n(critical_point2 << RS400_DISP2_CRITICAL_POINT_STOP_SHIFT)));\r\n#endif\r\nWREG32(RS400_DISP2_REQ_CNTL1, 0x105DC1CC);\r\nWREG32(RS400_DISP2_REQ_CNTL2, 0x2749D000);\r\nWREG32(RS400_DMIF_MEM_CNTL1, 0x29CA71DC);\r\nWREG32(RS400_DISP1_REQ_CNTL1, 0x28FBC3AC);\r\n}\r\nDRM_DEBUG_KMS("GRPH2_BUFFER_CNTL from to %x\n",\r\n(unsigned int)RREG32(RADEON_GRPH2_BUFFER_CNTL));\r\n}\r\nif (mode1)\r\nrdev->mode_info.crtcs[0]->lb_vblank_lead_lines = DIV_ROUND_UP(lb_size, mode1->crtc_hdisplay);\r\nif (mode2)\r\nrdev->mode_info.crtcs[1]->lb_vblank_lead_lines = DIV_ROUND_UP(lb_size, mode2->crtc_hdisplay);\r\n}\r\nint r100_ring_test(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nuint32_t scratch;\r\nuint32_t tmp = 0;\r\nunsigned i;\r\nint r;\r\nr = radeon_scratch_get(rdev, &scratch);\r\nif (r) {\r\nDRM_ERROR("radeon: cp failed to get scratch reg (%d).\n", r);\r\nreturn r;\r\n}\r\nWREG32(scratch, 0xCAFEDEAD);\r\nr = radeon_ring_lock(rdev, ring, 2);\r\nif (r) {\r\nDRM_ERROR("radeon: cp failed to lock ring (%d).\n", r);\r\nradeon_scratch_free(rdev, scratch);\r\nreturn r;\r\n}\r\nradeon_ring_write(ring, PACKET0(scratch, 0));\r\nradeon_ring_write(ring, 0xDEADBEEF);\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(scratch);\r\nif (tmp == 0xDEADBEEF) {\r\nbreak;\r\n}\r\nDRM_UDELAY(1);\r\n}\r\nif (i < rdev->usec_timeout) {\r\nDRM_INFO("ring test succeeded in %d usecs\n", i);\r\n} else {\r\nDRM_ERROR("radeon: ring test failed (scratch(0x%04X)=0x%08X)\n",\r\nscratch, tmp);\r\nr = -EINVAL;\r\n}\r\nradeon_scratch_free(rdev, scratch);\r\nreturn r;\r\n}\r\nvoid r100_ring_ib_execute(struct radeon_device *rdev, struct radeon_ib *ib)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nif (ring->rptr_save_reg) {\r\nu32 next_rptr = ring->wptr + 2 + 3;\r\nradeon_ring_write(ring, PACKET0(ring->rptr_save_reg, 0));\r\nradeon_ring_write(ring, next_rptr);\r\n}\r\nradeon_ring_write(ring, PACKET0(RADEON_CP_IB_BASE, 1));\r\nradeon_ring_write(ring, ib->gpu_addr);\r\nradeon_ring_write(ring, ib->length_dw);\r\n}\r\nint r100_ib_test(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nstruct radeon_ib ib;\r\nuint32_t scratch;\r\nuint32_t tmp = 0;\r\nunsigned i;\r\nint r;\r\nr = radeon_scratch_get(rdev, &scratch);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to get scratch reg (%d).\n", r);\r\nreturn r;\r\n}\r\nWREG32(scratch, 0xCAFEDEAD);\r\nr = radeon_ib_get(rdev, RADEON_RING_TYPE_GFX_INDEX, &ib, NULL, 256);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to get ib (%d).\n", r);\r\ngoto free_scratch;\r\n}\r\nib.ptr[0] = PACKET0(scratch, 0);\r\nib.ptr[1] = 0xDEADBEEF;\r\nib.ptr[2] = PACKET2(0);\r\nib.ptr[3] = PACKET2(0);\r\nib.ptr[4] = PACKET2(0);\r\nib.ptr[5] = PACKET2(0);\r\nib.ptr[6] = PACKET2(0);\r\nib.ptr[7] = PACKET2(0);\r\nib.length_dw = 8;\r\nr = radeon_ib_schedule(rdev, &ib, NULL, false);\r\nif (r) {\r\nDRM_ERROR("radeon: failed to schedule ib (%d).\n", r);\r\ngoto free_ib;\r\n}\r\nr = radeon_fence_wait_timeout(ib.fence, false, usecs_to_jiffies(\r\nRADEON_USEC_IB_TEST_TIMEOUT));\r\nif (r < 0) {\r\nDRM_ERROR("radeon: fence wait failed (%d).\n", r);\r\ngoto free_ib;\r\n} else if (r == 0) {\r\nDRM_ERROR("radeon: fence wait timed out.\n");\r\nr = -ETIMEDOUT;\r\ngoto free_ib;\r\n}\r\nr = 0;\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(scratch);\r\nif (tmp == 0xDEADBEEF) {\r\nbreak;\r\n}\r\nDRM_UDELAY(1);\r\n}\r\nif (i < rdev->usec_timeout) {\r\nDRM_INFO("ib test succeeded in %u usecs\n", i);\r\n} else {\r\nDRM_ERROR("radeon: ib test failed (scratch(0x%04X)=0x%08X)\n",\r\nscratch, tmp);\r\nr = -EINVAL;\r\n}\r\nfree_ib:\r\nradeon_ib_free(rdev, &ib);\r\nfree_scratch:\r\nradeon_scratch_free(rdev, scratch);\r\nreturn r;\r\n}\r\nvoid r100_mc_stop(struct radeon_device *rdev, struct r100_mc_save *save)\r\n{\r\nrdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;\r\nWREG32(R_000740_CP_CSQ_CNTL, 0);\r\nsave->GENMO_WT = RREG8(R_0003C2_GENMO_WT);\r\nsave->CRTC_EXT_CNTL = RREG32(R_000054_CRTC_EXT_CNTL);\r\nsave->CRTC_GEN_CNTL = RREG32(R_000050_CRTC_GEN_CNTL);\r\nsave->CUR_OFFSET = RREG32(R_000260_CUR_OFFSET);\r\nif (!(rdev->flags & RADEON_SINGLE_CRTC)) {\r\nsave->CRTC2_GEN_CNTL = RREG32(R_0003F8_CRTC2_GEN_CNTL);\r\nsave->CUR2_OFFSET = RREG32(R_000360_CUR2_OFFSET);\r\n}\r\nWREG8(R_0003C2_GENMO_WT, C_0003C2_VGA_RAM_EN & save->GENMO_WT);\r\nWREG32(R_000260_CUR_OFFSET, save->CUR_OFFSET | S_000260_CUR_LOCK(1));\r\nWREG32(R_000054_CRTC_EXT_CNTL, save->CRTC_EXT_CNTL |\r\nS_000054_CRTC_DISPLAY_DIS(1));\r\nWREG32(R_000050_CRTC_GEN_CNTL,\r\n(C_000050_CRTC_CUR_EN & save->CRTC_GEN_CNTL) |\r\nS_000050_CRTC_DISP_REQ_EN_B(1));\r\nWREG32(R_000420_OV0_SCALE_CNTL,\r\nC_000420_OV0_OVERLAY_EN & RREG32(R_000420_OV0_SCALE_CNTL));\r\nWREG32(R_000260_CUR_OFFSET, C_000260_CUR_LOCK & save->CUR_OFFSET);\r\nif (!(rdev->flags & RADEON_SINGLE_CRTC)) {\r\nWREG32(R_000360_CUR2_OFFSET, save->CUR2_OFFSET |\r\nS_000360_CUR2_LOCK(1));\r\nWREG32(R_0003F8_CRTC2_GEN_CNTL,\r\n(C_0003F8_CRTC2_CUR_EN & save->CRTC2_GEN_CNTL) |\r\nS_0003F8_CRTC2_DISPLAY_DIS(1) |\r\nS_0003F8_CRTC2_DISP_REQ_EN_B(1));\r\nWREG32(R_000360_CUR2_OFFSET,\r\nC_000360_CUR2_LOCK & save->CUR2_OFFSET);\r\n}\r\n}\r\nvoid r100_mc_resume(struct radeon_device *rdev, struct r100_mc_save *save)\r\n{\r\nWREG32(R_00023C_DISPLAY_BASE_ADDR, rdev->mc.vram_start);\r\nif (!(rdev->flags & RADEON_SINGLE_CRTC)) {\r\nWREG32(R_00033C_CRTC2_DISPLAY_BASE_ADDR, rdev->mc.vram_start);\r\n}\r\nWREG8(R_0003C2_GENMO_WT, save->GENMO_WT);\r\nWREG32(R_000054_CRTC_EXT_CNTL, save->CRTC_EXT_CNTL);\r\nWREG32(R_000050_CRTC_GEN_CNTL, save->CRTC_GEN_CNTL);\r\nif (!(rdev->flags & RADEON_SINGLE_CRTC)) {\r\nWREG32(R_0003F8_CRTC2_GEN_CNTL, save->CRTC2_GEN_CNTL);\r\n}\r\n}\r\nvoid r100_vga_render_disable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\ntmp = RREG8(R_0003C2_GENMO_WT);\r\nWREG8(R_0003C2_GENMO_WT, C_0003C2_VGA_RAM_EN & tmp);\r\n}\r\nstatic void r100_debugfs(struct radeon_device *rdev)\r\n{\r\nint r;\r\nr = r100_debugfs_mc_info_init(rdev);\r\nif (r)\r\ndev_warn(rdev->dev, "Failed to create r100_mc debugfs file.\n");\r\n}\r\nstatic void r100_mc_program(struct radeon_device *rdev)\r\n{\r\nstruct r100_mc_save save;\r\nr100_mc_stop(rdev, &save);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nWREG32(R_00014C_MC_AGP_LOCATION,\r\nS_00014C_MC_AGP_START(rdev->mc.gtt_start >> 16) |\r\nS_00014C_MC_AGP_TOP(rdev->mc.gtt_end >> 16));\r\nWREG32(R_000170_AGP_BASE, lower_32_bits(rdev->mc.agp_base));\r\nif (rdev->family > CHIP_RV200)\r\nWREG32(R_00015C_AGP_BASE_2,\r\nupper_32_bits(rdev->mc.agp_base) & 0xff);\r\n} else {\r\nWREG32(R_00014C_MC_AGP_LOCATION, 0x0FFFFFFF);\r\nWREG32(R_000170_AGP_BASE, 0);\r\nif (rdev->family > CHIP_RV200)\r\nWREG32(R_00015C_AGP_BASE_2, 0);\r\n}\r\nif (r100_mc_wait_for_idle(rdev))\r\ndev_warn(rdev->dev, "Wait for MC idle timeout.\n");\r\nWREG32(R_000148_MC_FB_LOCATION,\r\nS_000148_MC_FB_START(rdev->mc.vram_start >> 16) |\r\nS_000148_MC_FB_TOP(rdev->mc.vram_end >> 16));\r\nr100_mc_resume(rdev, &save);\r\n}\r\nstatic void r100_clock_startup(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nif (radeon_dynclks != -1 && radeon_dynclks)\r\nradeon_legacy_set_clock_gating(rdev, 1);\r\ntmp = RREG32_PLL(R_00000D_SCLK_CNTL);\r\ntmp |= S_00000D_FORCE_CP(1) | S_00000D_FORCE_VIP(1);\r\nif ((rdev->family == CHIP_RV250) || (rdev->family == CHIP_RV280))\r\ntmp |= S_00000D_FORCE_DISP1(1) | S_00000D_FORCE_DISP2(1);\r\nWREG32_PLL(R_00000D_SCLK_CNTL, tmp);\r\n}\r\nstatic int r100_startup(struct radeon_device *rdev)\r\n{\r\nint r;\r\nr100_set_common_regs(rdev);\r\nr100_mc_program(rdev);\r\nr100_clock_startup(rdev);\r\nr100_enable_bm(rdev);\r\nif (rdev->flags & RADEON_IS_PCI) {\r\nr = r100_pci_gart_enable(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nr = radeon_wb_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_fence_driver_start_ring(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing CP fences (%d).\n", r);\r\nreturn r;\r\n}\r\nif (!rdev->irq.installed) {\r\nr = radeon_irq_kms_init(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nr100_irq_set(rdev);\r\nrdev->config.r100.hdp_cntl = RREG32(RADEON_HOST_PATH_CNTL);\r\nr = r100_cp_init(rdev, 1024 * 1024);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing CP (%d).\n", r);\r\nreturn r;\r\n}\r\nr = radeon_ib_pool_init(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "IB initialization failed (%d).\n", r);\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nint r100_resume(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->flags & RADEON_IS_PCI)\r\nr100_pci_gart_disable(rdev);\r\nr100_clock_startup(rdev);\r\nif (radeon_asic_reset(rdev)) {\r\ndev_warn(rdev->dev, "GPU reset failed ! (0xE40=0x%08X, 0x7C0=0x%08X)\n",\r\nRREG32(R_000E40_RBBM_STATUS),\r\nRREG32(R_0007C0_CP_STAT));\r\n}\r\nradeon_combios_asic_init(rdev->ddev);\r\nr100_clock_startup(rdev);\r\nradeon_surface_init(rdev);\r\nrdev->accel_working = true;\r\nr = r100_startup(rdev);\r\nif (r) {\r\nrdev->accel_working = false;\r\n}\r\nreturn r;\r\n}\r\nint r100_suspend(struct radeon_device *rdev)\r\n{\r\nradeon_pm_suspend(rdev);\r\nr100_cp_disable(rdev);\r\nradeon_wb_disable(rdev);\r\nr100_irq_disable(rdev);\r\nif (rdev->flags & RADEON_IS_PCI)\r\nr100_pci_gart_disable(rdev);\r\nreturn 0;\r\n}\r\nvoid r100_fini(struct radeon_device *rdev)\r\n{\r\nradeon_pm_fini(rdev);\r\nr100_cp_fini(rdev);\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_gem_fini(rdev);\r\nif (rdev->flags & RADEON_IS_PCI)\r\nr100_pci_gart_fini(rdev);\r\nradeon_agp_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nradeon_fence_driver_fini(rdev);\r\nradeon_bo_fini(rdev);\r\nradeon_atombios_fini(rdev);\r\nkfree(rdev->bios);\r\nrdev->bios = NULL;\r\n}\r\nvoid r100_restore_sanity(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\ntmp = RREG32(RADEON_CP_CSQ_CNTL);\r\nif (tmp) {\r\nWREG32(RADEON_CP_CSQ_CNTL, 0);\r\n}\r\ntmp = RREG32(RADEON_CP_RB_CNTL);\r\nif (tmp) {\r\nWREG32(RADEON_CP_RB_CNTL, 0);\r\n}\r\ntmp = RREG32(RADEON_SCRATCH_UMSK);\r\nif (tmp) {\r\nWREG32(RADEON_SCRATCH_UMSK, 0);\r\n}\r\n}\r\nint r100_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nr100_debugfs(rdev);\r\nr100_vga_render_disable(rdev);\r\nradeon_scratch_init(rdev);\r\nradeon_surface_init(rdev);\r\nr100_restore_sanity(rdev);\r\nif (!radeon_get_bios(rdev)) {\r\nif (ASIC_IS_AVIVO(rdev))\r\nreturn -EINVAL;\r\n}\r\nif (rdev->is_atom_bios) {\r\ndev_err(rdev->dev, "Expecting combios for RS400/RS480 GPU\n");\r\nreturn -EINVAL;\r\n} else {\r\nr = radeon_combios_init(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nif (radeon_asic_reset(rdev)) {\r\ndev_warn(rdev->dev,\r\n"GPU reset failed ! (0xE40=0x%08X, 0x7C0=0x%08X)\n",\r\nRREG32(R_000E40_RBBM_STATUS),\r\nRREG32(R_0007C0_CP_STAT));\r\n}\r\nif (radeon_boot_test_post_card(rdev) == false)\r\nreturn -EINVAL;\r\nr100_errata(rdev);\r\nradeon_get_clock_info(rdev->ddev);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nr = radeon_agp_init(rdev);\r\nif (r) {\r\nradeon_agp_disable(rdev);\r\n}\r\n}\r\nr100_mc_init(rdev);\r\nr = radeon_fence_driver_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_bo_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (rdev->flags & RADEON_IS_PCI) {\r\nr = r100_pci_gart_init(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nr100_set_safe_registers(rdev);\r\nradeon_pm_init(rdev);\r\nrdev->accel_working = true;\r\nr = r100_startup(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "Disabling GPU acceleration\n");\r\nr100_cp_fini(rdev);\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nif (rdev->flags & RADEON_IS_PCI)\r\nr100_pci_gart_fini(rdev);\r\nrdev->accel_working = false;\r\n}\r\nreturn 0;\r\n}\r\nuint32_t r100_mm_rreg_slow(struct radeon_device *rdev, uint32_t reg)\r\n{\r\nunsigned long flags;\r\nuint32_t ret;\r\nspin_lock_irqsave(&rdev->mmio_idx_lock, flags);\r\nwritel(reg, ((void __iomem *)rdev->rmmio) + RADEON_MM_INDEX);\r\nret = readl(((void __iomem *)rdev->rmmio) + RADEON_MM_DATA);\r\nspin_unlock_irqrestore(&rdev->mmio_idx_lock, flags);\r\nreturn ret;\r\n}\r\nvoid r100_mm_wreg_slow(struct radeon_device *rdev, uint32_t reg, uint32_t v)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&rdev->mmio_idx_lock, flags);\r\nwritel(reg, ((void __iomem *)rdev->rmmio) + RADEON_MM_INDEX);\r\nwritel(v, ((void __iomem *)rdev->rmmio) + RADEON_MM_DATA);\r\nspin_unlock_irqrestore(&rdev->mmio_idx_lock, flags);\r\n}\r\nu32 r100_io_rreg(struct radeon_device *rdev, u32 reg)\r\n{\r\nif (reg < rdev->rio_mem_size)\r\nreturn ioread32(rdev->rio_mem + reg);\r\nelse {\r\niowrite32(reg, rdev->rio_mem + RADEON_MM_INDEX);\r\nreturn ioread32(rdev->rio_mem + RADEON_MM_DATA);\r\n}\r\n}\r\nvoid r100_io_wreg(struct radeon_device *rdev, u32 reg, u32 v)\r\n{\r\nif (reg < rdev->rio_mem_size)\r\niowrite32(v, rdev->rio_mem + reg);\r\nelse {\r\niowrite32(reg, rdev->rio_mem + RADEON_MM_INDEX);\r\niowrite32(v, rdev->rio_mem + RADEON_MM_DATA);\r\n}\r\n}
