static inline struct pcilynx *\r\nlynx_get(struct pcilynx *lynx)\r\n{\r\nkref_get(&lynx->kref);\r\nreturn lynx;\r\n}\r\nstatic void\r\nlynx_release(struct kref *kref)\r\n{\r\nkfree(container_of(kref, struct pcilynx, kref));\r\n}\r\nstatic inline void\r\nlynx_put(struct pcilynx *lynx)\r\n{\r\nkref_put(&lynx->kref, lynx_release);\r\n}\r\nstatic int\r\npacket_buffer_init(struct packet_buffer *buffer, size_t capacity)\r\n{\r\nbuffer->data = kmalloc(capacity, GFP_KERNEL);\r\nif (buffer->data == NULL)\r\nreturn -ENOMEM;\r\nbuffer->head = (struct packet *) buffer->data;\r\nbuffer->tail = (struct packet *) buffer->data;\r\nbuffer->capacity = capacity;\r\nbuffer->lost_packet_count = 0;\r\natomic_set(&buffer->size, 0);\r\ninit_waitqueue_head(&buffer->wait);\r\nreturn 0;\r\n}\r\nstatic void\r\npacket_buffer_destroy(struct packet_buffer *buffer)\r\n{\r\nkfree(buffer->data);\r\n}\r\nstatic int\r\npacket_buffer_get(struct client *client, char __user *data, size_t user_length)\r\n{\r\nstruct packet_buffer *buffer = &client->buffer;\r\nsize_t length;\r\nchar *end;\r\nif (wait_event_interruptible(buffer->wait,\r\natomic_read(&buffer->size) > 0) ||\r\nlist_empty(&client->lynx->link))\r\nreturn -ERESTARTSYS;\r\nif (atomic_read(&buffer->size) == 0)\r\nreturn -ENODEV;\r\nend = buffer->data + buffer->capacity;\r\nlength = buffer->head->length;\r\nif (&buffer->head->data[length] < end) {\r\nif (copy_to_user(data, buffer->head->data, length))\r\nreturn -EFAULT;\r\nbuffer->head = (struct packet *) &buffer->head->data[length];\r\n} else {\r\nsize_t split = end - buffer->head->data;\r\nif (copy_to_user(data, buffer->head->data, split))\r\nreturn -EFAULT;\r\nif (copy_to_user(data + split, buffer->data, length - split))\r\nreturn -EFAULT;\r\nbuffer->head = (struct packet *) &buffer->data[length - split];\r\n}\r\natomic_sub(sizeof(struct packet) + length, &buffer->size);\r\nreturn length;\r\n}\r\nstatic void\r\npacket_buffer_put(struct packet_buffer *buffer, void *data, size_t length)\r\n{\r\nchar *end;\r\nbuffer->total_packet_count++;\r\nif (buffer->capacity <\r\natomic_read(&buffer->size) + sizeof(struct packet) + length) {\r\nbuffer->lost_packet_count++;\r\nreturn;\r\n}\r\nend = buffer->data + buffer->capacity;\r\nbuffer->tail->length = length;\r\nif (&buffer->tail->data[length] < end) {\r\nmemcpy(buffer->tail->data, data, length);\r\nbuffer->tail = (struct packet *) &buffer->tail->data[length];\r\n} else {\r\nsize_t split = end - buffer->tail->data;\r\nmemcpy(buffer->tail->data, data, split);\r\nmemcpy(buffer->data, data + split, length - split);\r\nbuffer->tail = (struct packet *) &buffer->data[length - split];\r\n}\r\natomic_add(sizeof(struct packet) + length, &buffer->size);\r\nwake_up_interruptible(&buffer->wait);\r\n}\r\nstatic inline void\r\nreg_write(struct pcilynx *lynx, int offset, u32 data)\r\n{\r\nwritel(data, lynx->registers + offset);\r\n}\r\nstatic inline u32\r\nreg_read(struct pcilynx *lynx, int offset)\r\n{\r\nreturn readl(lynx->registers + offset);\r\n}\r\nstatic inline void\r\nreg_set_bits(struct pcilynx *lynx, int offset, u32 mask)\r\n{\r\nreg_write(lynx, offset, (reg_read(lynx, offset) | mask));\r\n}\r\nstatic inline void\r\nrun_pcl(struct pcilynx *lynx, dma_addr_t pcl_bus,\r\nint dmachan)\r\n{\r\nreg_write(lynx, DMA0_CURRENT_PCL + dmachan * 0x20, pcl_bus);\r\nreg_write(lynx, DMA0_CHAN_CTRL + dmachan * 0x20,\r\nDMA_CHAN_CTRL_ENABLE | DMA_CHAN_CTRL_LINK);\r\n}\r\nstatic int\r\nset_phy_reg(struct pcilynx *lynx, int addr, int val)\r\n{\r\nif (addr > 15) {\r\ndev_err(&lynx->pci_device->dev,\r\n"PHY register address %d out of range\n", addr);\r\nreturn -1;\r\n}\r\nif (val > 0xff) {\r\ndev_err(&lynx->pci_device->dev,\r\n"PHY register value %d out of range\n", val);\r\nreturn -1;\r\n}\r\nreg_write(lynx, LINK_PHY, LINK_PHY_WRITE |\r\nLINK_PHY_ADDR(addr) | LINK_PHY_WDATA(val));\r\nreturn 0;\r\n}\r\nstatic int\r\nnosy_open(struct inode *inode, struct file *file)\r\n{\r\nint minor = iminor(inode);\r\nstruct client *client;\r\nstruct pcilynx *tmp, *lynx = NULL;\r\nmutex_lock(&card_mutex);\r\nlist_for_each_entry(tmp, &card_list, link)\r\nif (tmp->misc.minor == minor) {\r\nlynx = lynx_get(tmp);\r\nbreak;\r\n}\r\nmutex_unlock(&card_mutex);\r\nif (lynx == NULL)\r\nreturn -ENODEV;\r\nclient = kmalloc(sizeof *client, GFP_KERNEL);\r\nif (client == NULL)\r\ngoto fail;\r\nclient->tcode_mask = ~0;\r\nclient->lynx = lynx;\r\nINIT_LIST_HEAD(&client->link);\r\nif (packet_buffer_init(&client->buffer, 128 * 1024) < 0)\r\ngoto fail;\r\nfile->private_data = client;\r\nreturn nonseekable_open(inode, file);\r\nfail:\r\nkfree(client);\r\nlynx_put(lynx);\r\nreturn -ENOMEM;\r\n}\r\nstatic int\r\nnosy_release(struct inode *inode, struct file *file)\r\n{\r\nstruct client *client = file->private_data;\r\nstruct pcilynx *lynx = client->lynx;\r\nspin_lock_irq(&lynx->client_list_lock);\r\nlist_del_init(&client->link);\r\nspin_unlock_irq(&lynx->client_list_lock);\r\npacket_buffer_destroy(&client->buffer);\r\nkfree(client);\r\nlynx_put(lynx);\r\nreturn 0;\r\n}\r\nstatic unsigned int\r\nnosy_poll(struct file *file, poll_table *pt)\r\n{\r\nstruct client *client = file->private_data;\r\nunsigned int ret = 0;\r\npoll_wait(file, &client->buffer.wait, pt);\r\nif (atomic_read(&client->buffer.size) > 0)\r\nret = POLLIN | POLLRDNORM;\r\nif (list_empty(&client->lynx->link))\r\nret |= POLLHUP;\r\nreturn ret;\r\n}\r\nstatic ssize_t\r\nnosy_read(struct file *file, char __user *buffer, size_t count, loff_t *offset)\r\n{\r\nstruct client *client = file->private_data;\r\nreturn packet_buffer_get(client, buffer, count);\r\n}\r\nstatic long\r\nnosy_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\r\n{\r\nstruct client *client = file->private_data;\r\nspinlock_t *client_list_lock = &client->lynx->client_list_lock;\r\nstruct nosy_stats stats;\r\nswitch (cmd) {\r\ncase NOSY_IOC_GET_STATS:\r\nspin_lock_irq(client_list_lock);\r\nstats.total_packet_count = client->buffer.total_packet_count;\r\nstats.lost_packet_count = client->buffer.lost_packet_count;\r\nspin_unlock_irq(client_list_lock);\r\nif (copy_to_user((void __user *) arg, &stats, sizeof stats))\r\nreturn -EFAULT;\r\nelse\r\nreturn 0;\r\ncase NOSY_IOC_START:\r\nspin_lock_irq(client_list_lock);\r\nlist_add_tail(&client->link, &client->lynx->client_list);\r\nspin_unlock_irq(client_list_lock);\r\nreturn 0;\r\ncase NOSY_IOC_STOP:\r\nspin_lock_irq(client_list_lock);\r\nlist_del_init(&client->link);\r\nspin_unlock_irq(client_list_lock);\r\nreturn 0;\r\ncase NOSY_IOC_FILTER:\r\nspin_lock_irq(client_list_lock);\r\nclient->tcode_mask = arg;\r\nspin_unlock_irq(client_list_lock);\r\nreturn 0;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic void\r\npacket_irq_handler(struct pcilynx *lynx)\r\n{\r\nstruct client *client;\r\nu32 tcode_mask, tcode, timestamp;\r\nsize_t length;\r\nstruct timespec64 ts64;\r\nlength = __le32_to_cpu(lynx->rcv_pcl->pcl_status) & 0x00001fff;\r\ntcode = __le32_to_cpu(lynx->rcv_buffer[1]) >> 4 & 0xf;\r\nktime_get_real_ts64(&ts64);\r\ntimestamp = ts64.tv_nsec / NSEC_PER_USEC;\r\nlynx->rcv_buffer[0] = (__force __le32)timestamp;\r\nif (length == PHY_PACKET_SIZE)\r\ntcode_mask = 1 << TCODE_PHY_PACKET;\r\nelse\r\ntcode_mask = 1 << tcode;\r\nspin_lock(&lynx->client_list_lock);\r\nlist_for_each_entry(client, &lynx->client_list, link)\r\nif (client->tcode_mask & tcode_mask)\r\npacket_buffer_put(&client->buffer,\r\nlynx->rcv_buffer, length + 4);\r\nspin_unlock(&lynx->client_list_lock);\r\n}\r\nstatic void\r\nbus_reset_irq_handler(struct pcilynx *lynx)\r\n{\r\nstruct client *client;\r\nstruct timespec64 ts64;\r\nu32 timestamp;\r\nktime_get_real_ts64(&ts64);\r\ntimestamp = ts64.tv_nsec / NSEC_PER_USEC;\r\nspin_lock(&lynx->client_list_lock);\r\nlist_for_each_entry(client, &lynx->client_list, link)\r\npacket_buffer_put(&client->buffer, &timestamp, 4);\r\nspin_unlock(&lynx->client_list_lock);\r\n}\r\nstatic irqreturn_t\r\nirq_handler(int irq, void *device)\r\n{\r\nstruct pcilynx *lynx = device;\r\nu32 pci_int_status;\r\npci_int_status = reg_read(lynx, PCI_INT_STATUS);\r\nif (pci_int_status == ~0)\r\nreturn IRQ_NONE;\r\nif ((pci_int_status & PCI_INT_INT_PEND) == 0)\r\nreturn IRQ_NONE;\r\nif ((pci_int_status & PCI_INT_P1394_INT) != 0) {\r\nu32 link_int_status;\r\nlink_int_status = reg_read(lynx, LINK_INT_STATUS);\r\nreg_write(lynx, LINK_INT_STATUS, link_int_status);\r\nif ((link_int_status & LINK_INT_PHY_BUSRESET) > 0)\r\nbus_reset_irq_handler(lynx);\r\n}\r\nreg_write(lynx, PCI_INT_STATUS, pci_int_status);\r\nif ((pci_int_status & PCI_INT_DMA0_HLT) > 0) {\r\npacket_irq_handler(lynx);\r\nrun_pcl(lynx, lynx->rcv_start_pcl_bus, 0);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void\r\nremove_card(struct pci_dev *dev)\r\n{\r\nstruct pcilynx *lynx = pci_get_drvdata(dev);\r\nstruct client *client;\r\nmutex_lock(&card_mutex);\r\nlist_del_init(&lynx->link);\r\nmisc_deregister(&lynx->misc);\r\nmutex_unlock(&card_mutex);\r\nreg_write(lynx, PCI_INT_ENABLE, 0);\r\nfree_irq(lynx->pci_device->irq, lynx);\r\nspin_lock_irq(&lynx->client_list_lock);\r\nlist_for_each_entry(client, &lynx->client_list, link)\r\nwake_up_interruptible(&client->buffer.wait);\r\nspin_unlock_irq(&lynx->client_list_lock);\r\npci_free_consistent(lynx->pci_device, sizeof(struct pcl),\r\nlynx->rcv_start_pcl, lynx->rcv_start_pcl_bus);\r\npci_free_consistent(lynx->pci_device, sizeof(struct pcl),\r\nlynx->rcv_pcl, lynx->rcv_pcl_bus);\r\npci_free_consistent(lynx->pci_device, PAGE_SIZE,\r\nlynx->rcv_buffer, lynx->rcv_buffer_bus);\r\niounmap(lynx->registers);\r\npci_disable_device(dev);\r\nlynx_put(lynx);\r\n}\r\nstatic int\r\nadd_card(struct pci_dev *dev, const struct pci_device_id *unused)\r\n{\r\nstruct pcilynx *lynx;\r\nu32 p, end;\r\nint ret, i;\r\nif (pci_set_dma_mask(dev, DMA_BIT_MASK(32))) {\r\ndev_err(&dev->dev,\r\n"DMA address limits not supported for PCILynx hardware\n");\r\nreturn -ENXIO;\r\n}\r\nif (pci_enable_device(dev)) {\r\ndev_err(&dev->dev, "Failed to enable PCILynx hardware\n");\r\nreturn -ENXIO;\r\n}\r\npci_set_master(dev);\r\nlynx = kzalloc(sizeof *lynx, GFP_KERNEL);\r\nif (lynx == NULL) {\r\ndev_err(&dev->dev, "Failed to allocate control structure\n");\r\nret = -ENOMEM;\r\ngoto fail_disable;\r\n}\r\nlynx->pci_device = dev;\r\npci_set_drvdata(dev, lynx);\r\nspin_lock_init(&lynx->client_list_lock);\r\nINIT_LIST_HEAD(&lynx->client_list);\r\nkref_init(&lynx->kref);\r\nlynx->registers = ioremap_nocache(pci_resource_start(dev, 0),\r\nPCILYNX_MAX_REGISTER);\r\nlynx->rcv_start_pcl = pci_alloc_consistent(lynx->pci_device,\r\nsizeof(struct pcl), &lynx->rcv_start_pcl_bus);\r\nlynx->rcv_pcl = pci_alloc_consistent(lynx->pci_device,\r\nsizeof(struct pcl), &lynx->rcv_pcl_bus);\r\nlynx->rcv_buffer = pci_alloc_consistent(lynx->pci_device,\r\nRCV_BUFFER_SIZE, &lynx->rcv_buffer_bus);\r\nif (lynx->rcv_start_pcl == NULL ||\r\nlynx->rcv_pcl == NULL ||\r\nlynx->rcv_buffer == NULL) {\r\ndev_err(&dev->dev, "Failed to allocate receive buffer\n");\r\nret = -ENOMEM;\r\ngoto fail_deallocate;\r\n}\r\nlynx->rcv_start_pcl->next = cpu_to_le32(lynx->rcv_pcl_bus);\r\nlynx->rcv_pcl->next = cpu_to_le32(PCL_NEXT_INVALID);\r\nlynx->rcv_pcl->async_error_next = cpu_to_le32(PCL_NEXT_INVALID);\r\nlynx->rcv_pcl->buffer[0].control =\r\ncpu_to_le32(PCL_CMD_RCV | PCL_BIGENDIAN | 2044);\r\nlynx->rcv_pcl->buffer[0].pointer =\r\ncpu_to_le32(lynx->rcv_buffer_bus + 4);\r\np = lynx->rcv_buffer_bus + 2048;\r\nend = lynx->rcv_buffer_bus + RCV_BUFFER_SIZE;\r\nfor (i = 1; p < end; i++, p += 2048) {\r\nlynx->rcv_pcl->buffer[i].control =\r\ncpu_to_le32(PCL_CMD_RCV | PCL_BIGENDIAN | 2048);\r\nlynx->rcv_pcl->buffer[i].pointer = cpu_to_le32(p);\r\n}\r\nlynx->rcv_pcl->buffer[i - 1].control |= cpu_to_le32(PCL_LAST_BUFF);\r\nreg_set_bits(lynx, MISC_CONTROL, MISC_CONTROL_SWRESET);\r\nreg_write(lynx, DMA0_CHAN_CTRL, 0);\r\nreg_write(lynx, DMA_GLOBAL_REGISTER, 0x00 << 24);\r\n#if 0\r\nif ((get_phy_reg(lynx, 2) & 0xe0) == 0xe0) {\r\nlynx->phyic.reg_1394a = 1;\r\nPRINT(KERN_INFO, lynx->id,\r\n"found 1394a conform PHY (using extended register set)");\r\nlynx->phyic.vendor = get_phy_vendorid(lynx);\r\nlynx->phyic.product = get_phy_productid(lynx);\r\n} else {\r\nlynx->phyic.reg_1394a = 0;\r\nPRINT(KERN_INFO, lynx->id, "found old 1394 PHY");\r\n}\r\n#endif\r\nreg_write(lynx, FIFO_SIZES, 255);\r\nreg_set_bits(lynx, PCI_INT_ENABLE, PCI_INT_DMA_ALL);\r\nreg_write(lynx, LINK_INT_ENABLE,\r\nLINK_INT_PHY_TIME_OUT | LINK_INT_PHY_REG_RCVD |\r\nLINK_INT_PHY_BUSRESET | LINK_INT_IT_STUCK |\r\nLINK_INT_AT_STUCK | LINK_INT_SNTRJ |\r\nLINK_INT_TC_ERR | LINK_INT_GRF_OVER_FLOW |\r\nLINK_INT_ITF_UNDER_FLOW | LINK_INT_ATF_UNDER_FLOW);\r\nset_phy_reg(lynx, 4, 0);\r\nreg_set_bits(lynx, LINK_CONTROL, LINK_CONTROL_SNOOP_ENABLE);\r\nrun_pcl(lynx, lynx->rcv_start_pcl_bus, 0);\r\nif (request_irq(dev->irq, irq_handler, IRQF_SHARED,\r\ndriver_name, lynx)) {\r\ndev_err(&dev->dev,\r\n"Failed to allocate shared interrupt %d\n", dev->irq);\r\nret = -EIO;\r\ngoto fail_deallocate;\r\n}\r\nlynx->misc.parent = &dev->dev;\r\nlynx->misc.minor = MISC_DYNAMIC_MINOR;\r\nlynx->misc.name = "nosy";\r\nlynx->misc.fops = &nosy_ops;\r\nmutex_lock(&card_mutex);\r\nret = misc_register(&lynx->misc);\r\nif (ret) {\r\ndev_err(&dev->dev, "Failed to register misc char device\n");\r\nmutex_unlock(&card_mutex);\r\ngoto fail_free_irq;\r\n}\r\nlist_add_tail(&lynx->link, &card_list);\r\nmutex_unlock(&card_mutex);\r\ndev_info(&dev->dev,\r\n"Initialized PCILynx IEEE1394 card, irq=%d\n", dev->irq);\r\nreturn 0;\r\nfail_free_irq:\r\nreg_write(lynx, PCI_INT_ENABLE, 0);\r\nfree_irq(lynx->pci_device->irq, lynx);\r\nfail_deallocate:\r\nif (lynx->rcv_start_pcl)\r\npci_free_consistent(lynx->pci_device, sizeof(struct pcl),\r\nlynx->rcv_start_pcl, lynx->rcv_start_pcl_bus);\r\nif (lynx->rcv_pcl)\r\npci_free_consistent(lynx->pci_device, sizeof(struct pcl),\r\nlynx->rcv_pcl, lynx->rcv_pcl_bus);\r\nif (lynx->rcv_buffer)\r\npci_free_consistent(lynx->pci_device, PAGE_SIZE,\r\nlynx->rcv_buffer, lynx->rcv_buffer_bus);\r\niounmap(lynx->registers);\r\nkfree(lynx);\r\nfail_disable:\r\npci_disable_device(dev);\r\nreturn ret;\r\n}
