static void iser_qp_event_callback(struct ib_event *cause, void *context)\r\n{\r\niser_err("qp event %s (%d)\n",\r\nib_event_msg(cause->event), cause->event);\r\n}\r\nstatic void iser_event_handler(struct ib_event_handler *handler,\r\nstruct ib_event *event)\r\n{\r\niser_err("async event %s (%d) on device %s port %d\n",\r\nib_event_msg(event->event), event->event,\r\nevent->device->name, event->element.port_num);\r\n}\r\nstatic int iser_create_device_ib_res(struct iser_device *device)\r\n{\r\nstruct ib_device *ib_dev = device->ib_device;\r\nint ret, i, max_cqe;\r\nret = iser_assign_reg_ops(device);\r\nif (ret)\r\nreturn ret;\r\ndevice->comps_used = min_t(int, num_online_cpus(),\r\nib_dev->num_comp_vectors);\r\ndevice->comps = kcalloc(device->comps_used, sizeof(*device->comps),\r\nGFP_KERNEL);\r\nif (!device->comps)\r\ngoto comps_err;\r\nmax_cqe = min(ISER_MAX_CQ_LEN, ib_dev->attrs.max_cqe);\r\niser_info("using %d CQs, device %s supports %d vectors max_cqe %d\n",\r\ndevice->comps_used, ib_dev->name,\r\nib_dev->num_comp_vectors, max_cqe);\r\ndevice->pd = ib_alloc_pd(ib_dev);\r\nif (IS_ERR(device->pd))\r\ngoto pd_err;\r\nfor (i = 0; i < device->comps_used; i++) {\r\nstruct iser_comp *comp = &device->comps[i];\r\ncomp->cq = ib_alloc_cq(ib_dev, comp, max_cqe, i,\r\nIB_POLL_SOFTIRQ);\r\nif (IS_ERR(comp->cq)) {\r\ncomp->cq = NULL;\r\ngoto cq_err;\r\n}\r\n}\r\nif (!iser_always_reg) {\r\nint access = IB_ACCESS_LOCAL_WRITE |\r\nIB_ACCESS_REMOTE_WRITE |\r\nIB_ACCESS_REMOTE_READ;\r\ndevice->mr = ib_get_dma_mr(device->pd, access);\r\nif (IS_ERR(device->mr))\r\ngoto cq_err;\r\n}\r\nINIT_IB_EVENT_HANDLER(&device->event_handler, ib_dev,\r\niser_event_handler);\r\nif (ib_register_event_handler(&device->event_handler))\r\ngoto handler_err;\r\nreturn 0;\r\nhandler_err:\r\nif (device->mr)\r\nib_dereg_mr(device->mr);\r\ncq_err:\r\nfor (i = 0; i < device->comps_used; i++) {\r\nstruct iser_comp *comp = &device->comps[i];\r\nif (comp->cq)\r\nib_free_cq(comp->cq);\r\n}\r\nib_dealloc_pd(device->pd);\r\npd_err:\r\nkfree(device->comps);\r\ncomps_err:\r\niser_err("failed to allocate an IB resource\n");\r\nreturn -1;\r\n}\r\nstatic void iser_free_device_ib_res(struct iser_device *device)\r\n{\r\nint i;\r\nfor (i = 0; i < device->comps_used; i++) {\r\nstruct iser_comp *comp = &device->comps[i];\r\nib_free_cq(comp->cq);\r\ncomp->cq = NULL;\r\n}\r\n(void)ib_unregister_event_handler(&device->event_handler);\r\nif (device->mr)\r\n(void)ib_dereg_mr(device->mr);\r\nib_dealloc_pd(device->pd);\r\nkfree(device->comps);\r\ndevice->comps = NULL;\r\ndevice->mr = NULL;\r\ndevice->pd = NULL;\r\n}\r\nint iser_alloc_fmr_pool(struct ib_conn *ib_conn,\r\nunsigned cmds_max,\r\nunsigned int size)\r\n{\r\nstruct iser_device *device = ib_conn->device;\r\nstruct iser_fr_pool *fr_pool = &ib_conn->fr_pool;\r\nstruct iser_page_vec *page_vec;\r\nstruct iser_fr_desc *desc;\r\nstruct ib_fmr_pool *fmr_pool;\r\nstruct ib_fmr_pool_param params;\r\nint ret;\r\nINIT_LIST_HEAD(&fr_pool->list);\r\nspin_lock_init(&fr_pool->lock);\r\ndesc = kzalloc(sizeof(*desc), GFP_KERNEL);\r\nif (!desc)\r\nreturn -ENOMEM;\r\npage_vec = kmalloc(sizeof(*page_vec) + (sizeof(u64) * size),\r\nGFP_KERNEL);\r\nif (!page_vec) {\r\nret = -ENOMEM;\r\ngoto err_frpl;\r\n}\r\npage_vec->pages = (u64 *)(page_vec + 1);\r\nparams.page_shift = SHIFT_4K;\r\nparams.max_pages_per_fmr = size;\r\nparams.pool_size = cmds_max * 2;\r\nparams.dirty_watermark = cmds_max;\r\nparams.cache = 0;\r\nparams.flush_function = NULL;\r\nparams.access = (IB_ACCESS_LOCAL_WRITE |\r\nIB_ACCESS_REMOTE_WRITE |\r\nIB_ACCESS_REMOTE_READ);\r\nfmr_pool = ib_create_fmr_pool(device->pd, &params);\r\nif (IS_ERR(fmr_pool)) {\r\nret = PTR_ERR(fmr_pool);\r\niser_err("FMR allocation failed, err %d\n", ret);\r\ngoto err_fmr;\r\n}\r\ndesc->rsc.page_vec = page_vec;\r\ndesc->rsc.fmr_pool = fmr_pool;\r\nlist_add(&desc->list, &fr_pool->list);\r\nreturn 0;\r\nerr_fmr:\r\nkfree(page_vec);\r\nerr_frpl:\r\nkfree(desc);\r\nreturn ret;\r\n}\r\nvoid iser_free_fmr_pool(struct ib_conn *ib_conn)\r\n{\r\nstruct iser_fr_pool *fr_pool = &ib_conn->fr_pool;\r\nstruct iser_fr_desc *desc;\r\ndesc = list_first_entry(&fr_pool->list,\r\nstruct iser_fr_desc, list);\r\nlist_del(&desc->list);\r\niser_info("freeing conn %p fmr pool %p\n",\r\nib_conn, desc->rsc.fmr_pool);\r\nib_destroy_fmr_pool(desc->rsc.fmr_pool);\r\nkfree(desc->rsc.page_vec);\r\nkfree(desc);\r\n}\r\nstatic int\r\niser_alloc_reg_res(struct iser_device *device,\r\nstruct ib_pd *pd,\r\nstruct iser_reg_resources *res,\r\nunsigned int size)\r\n{\r\nstruct ib_device *ib_dev = device->ib_device;\r\nenum ib_mr_type mr_type;\r\nint ret;\r\nif (ib_dev->attrs.device_cap_flags & IB_DEVICE_SG_GAPS_REG)\r\nmr_type = IB_MR_TYPE_SG_GAPS;\r\nelse\r\nmr_type = IB_MR_TYPE_MEM_REG;\r\nres->mr = ib_alloc_mr(pd, mr_type, size);\r\nif (IS_ERR(res->mr)) {\r\nret = PTR_ERR(res->mr);\r\niser_err("Failed to allocate ib_fast_reg_mr err=%d\n", ret);\r\nreturn ret;\r\n}\r\nres->mr_valid = 0;\r\nreturn 0;\r\n}\r\nstatic void\r\niser_free_reg_res(struct iser_reg_resources *rsc)\r\n{\r\nib_dereg_mr(rsc->mr);\r\n}\r\nstatic int\r\niser_alloc_pi_ctx(struct iser_device *device,\r\nstruct ib_pd *pd,\r\nstruct iser_fr_desc *desc,\r\nunsigned int size)\r\n{\r\nstruct iser_pi_context *pi_ctx = NULL;\r\nint ret;\r\ndesc->pi_ctx = kzalloc(sizeof(*desc->pi_ctx), GFP_KERNEL);\r\nif (!desc->pi_ctx)\r\nreturn -ENOMEM;\r\npi_ctx = desc->pi_ctx;\r\nret = iser_alloc_reg_res(device, pd, &pi_ctx->rsc, size);\r\nif (ret) {\r\niser_err("failed to allocate reg_resources\n");\r\ngoto alloc_reg_res_err;\r\n}\r\npi_ctx->sig_mr = ib_alloc_mr(pd, IB_MR_TYPE_SIGNATURE, 2);\r\nif (IS_ERR(pi_ctx->sig_mr)) {\r\nret = PTR_ERR(pi_ctx->sig_mr);\r\ngoto sig_mr_failure;\r\n}\r\npi_ctx->sig_mr_valid = 0;\r\ndesc->pi_ctx->sig_protected = 0;\r\nreturn 0;\r\nsig_mr_failure:\r\niser_free_reg_res(&pi_ctx->rsc);\r\nalloc_reg_res_err:\r\nkfree(desc->pi_ctx);\r\nreturn ret;\r\n}\r\nstatic void\r\niser_free_pi_ctx(struct iser_pi_context *pi_ctx)\r\n{\r\niser_free_reg_res(&pi_ctx->rsc);\r\nib_dereg_mr(pi_ctx->sig_mr);\r\nkfree(pi_ctx);\r\n}\r\nstatic struct iser_fr_desc *\r\niser_create_fastreg_desc(struct iser_device *device,\r\nstruct ib_pd *pd,\r\nbool pi_enable,\r\nunsigned int size)\r\n{\r\nstruct iser_fr_desc *desc;\r\nint ret;\r\ndesc = kzalloc(sizeof(*desc), GFP_KERNEL);\r\nif (!desc)\r\nreturn ERR_PTR(-ENOMEM);\r\nret = iser_alloc_reg_res(device, pd, &desc->rsc, size);\r\nif (ret)\r\ngoto reg_res_alloc_failure;\r\nif (pi_enable) {\r\nret = iser_alloc_pi_ctx(device, pd, desc, size);\r\nif (ret)\r\ngoto pi_ctx_alloc_failure;\r\n}\r\nreturn desc;\r\npi_ctx_alloc_failure:\r\niser_free_reg_res(&desc->rsc);\r\nreg_res_alloc_failure:\r\nkfree(desc);\r\nreturn ERR_PTR(ret);\r\n}\r\nint iser_alloc_fastreg_pool(struct ib_conn *ib_conn,\r\nunsigned cmds_max,\r\nunsigned int size)\r\n{\r\nstruct iser_device *device = ib_conn->device;\r\nstruct iser_fr_pool *fr_pool = &ib_conn->fr_pool;\r\nstruct iser_fr_desc *desc;\r\nint i, ret;\r\nINIT_LIST_HEAD(&fr_pool->list);\r\nspin_lock_init(&fr_pool->lock);\r\nfr_pool->size = 0;\r\nfor (i = 0; i < cmds_max; i++) {\r\ndesc = iser_create_fastreg_desc(device, device->pd,\r\nib_conn->pi_support, size);\r\nif (IS_ERR(desc)) {\r\nret = PTR_ERR(desc);\r\ngoto err;\r\n}\r\nlist_add_tail(&desc->list, &fr_pool->list);\r\nfr_pool->size++;\r\n}\r\nreturn 0;\r\nerr:\r\niser_free_fastreg_pool(ib_conn);\r\nreturn ret;\r\n}\r\nvoid iser_free_fastreg_pool(struct ib_conn *ib_conn)\r\n{\r\nstruct iser_fr_pool *fr_pool = &ib_conn->fr_pool;\r\nstruct iser_fr_desc *desc, *tmp;\r\nint i = 0;\r\nif (list_empty(&fr_pool->list))\r\nreturn;\r\niser_info("freeing conn %p fr pool\n", ib_conn);\r\nlist_for_each_entry_safe(desc, tmp, &fr_pool->list, list) {\r\nlist_del(&desc->list);\r\niser_free_reg_res(&desc->rsc);\r\nif (desc->pi_ctx)\r\niser_free_pi_ctx(desc->pi_ctx);\r\nkfree(desc);\r\n++i;\r\n}\r\nif (i < fr_pool->size)\r\niser_warn("pool still has %d regions registered\n",\r\nfr_pool->size - i);\r\n}\r\nstatic int iser_create_ib_conn_res(struct ib_conn *ib_conn)\r\n{\r\nstruct iser_conn *iser_conn = to_iser_conn(ib_conn);\r\nstruct iser_device *device;\r\nstruct ib_device *ib_dev;\r\nstruct ib_qp_init_attr init_attr;\r\nint ret = -ENOMEM;\r\nint index, min_index = 0;\r\nBUG_ON(ib_conn->device == NULL);\r\ndevice = ib_conn->device;\r\nib_dev = device->ib_device;\r\nmemset(&init_attr, 0, sizeof init_attr);\r\nmutex_lock(&ig.connlist_mutex);\r\nfor (index = 0; index < device->comps_used; index++) {\r\nif (device->comps[index].active_qps <\r\ndevice->comps[min_index].active_qps)\r\nmin_index = index;\r\n}\r\nib_conn->comp = &device->comps[min_index];\r\nib_conn->comp->active_qps++;\r\nmutex_unlock(&ig.connlist_mutex);\r\niser_info("cq index %d used for ib_conn %p\n", min_index, ib_conn);\r\ninit_attr.event_handler = iser_qp_event_callback;\r\ninit_attr.qp_context = (void *)ib_conn;\r\ninit_attr.send_cq = ib_conn->comp->cq;\r\ninit_attr.recv_cq = ib_conn->comp->cq;\r\ninit_attr.cap.max_recv_wr = ISER_QP_MAX_RECV_DTOS;\r\ninit_attr.cap.max_send_sge = 2;\r\ninit_attr.cap.max_recv_sge = 1;\r\ninit_attr.sq_sig_type = IB_SIGNAL_REQ_WR;\r\ninit_attr.qp_type = IB_QPT_RC;\r\nif (ib_conn->pi_support) {\r\ninit_attr.cap.max_send_wr = ISER_QP_SIG_MAX_REQ_DTOS + 1;\r\ninit_attr.create_flags |= IB_QP_CREATE_SIGNATURE_EN;\r\niser_conn->max_cmds =\r\nISER_GET_MAX_XMIT_CMDS(ISER_QP_SIG_MAX_REQ_DTOS);\r\n} else {\r\nif (ib_dev->attrs.max_qp_wr > ISER_QP_MAX_REQ_DTOS) {\r\ninit_attr.cap.max_send_wr = ISER_QP_MAX_REQ_DTOS + 1;\r\niser_conn->max_cmds =\r\nISER_GET_MAX_XMIT_CMDS(ISER_QP_MAX_REQ_DTOS);\r\n} else {\r\ninit_attr.cap.max_send_wr = ib_dev->attrs.max_qp_wr;\r\niser_conn->max_cmds =\r\nISER_GET_MAX_XMIT_CMDS(ib_dev->attrs.max_qp_wr);\r\niser_dbg("device %s supports max_send_wr %d\n",\r\ndevice->ib_device->name, ib_dev->attrs.max_qp_wr);\r\n}\r\n}\r\nret = rdma_create_qp(ib_conn->cma_id, device->pd, &init_attr);\r\nif (ret)\r\ngoto out_err;\r\nib_conn->qp = ib_conn->cma_id->qp;\r\niser_info("setting conn %p cma_id %p qp %p\n",\r\nib_conn, ib_conn->cma_id,\r\nib_conn->cma_id->qp);\r\nreturn ret;\r\nout_err:\r\nmutex_lock(&ig.connlist_mutex);\r\nib_conn->comp->active_qps--;\r\nmutex_unlock(&ig.connlist_mutex);\r\niser_err("unable to alloc mem or create resource, err %d\n", ret);\r\nreturn ret;\r\n}\r\nstatic\r\nstruct iser_device *iser_device_find_by_ib_device(struct rdma_cm_id *cma_id)\r\n{\r\nstruct iser_device *device;\r\nmutex_lock(&ig.device_list_mutex);\r\nlist_for_each_entry(device, &ig.device_list, ig_list)\r\nif (device->ib_device->node_guid == cma_id->device->node_guid)\r\ngoto inc_refcnt;\r\ndevice = kzalloc(sizeof *device, GFP_KERNEL);\r\nif (device == NULL)\r\ngoto out;\r\ndevice->ib_device = cma_id->device;\r\nif (iser_create_device_ib_res(device)) {\r\nkfree(device);\r\ndevice = NULL;\r\ngoto out;\r\n}\r\nlist_add(&device->ig_list, &ig.device_list);\r\ninc_refcnt:\r\ndevice->refcount++;\r\nout:\r\nmutex_unlock(&ig.device_list_mutex);\r\nreturn device;\r\n}\r\nstatic void iser_device_try_release(struct iser_device *device)\r\n{\r\nmutex_lock(&ig.device_list_mutex);\r\ndevice->refcount--;\r\niser_info("device %p refcount %d\n", device, device->refcount);\r\nif (!device->refcount) {\r\niser_free_device_ib_res(device);\r\nlist_del(&device->ig_list);\r\nkfree(device);\r\n}\r\nmutex_unlock(&ig.device_list_mutex);\r\n}\r\nstatic int iser_conn_state_comp_exch(struct iser_conn *iser_conn,\r\nenum iser_conn_state comp,\r\nenum iser_conn_state exch)\r\n{\r\nint ret;\r\nret = (iser_conn->state == comp);\r\nif (ret)\r\niser_conn->state = exch;\r\nreturn ret;\r\n}\r\nvoid iser_release_work(struct work_struct *work)\r\n{\r\nstruct iser_conn *iser_conn;\r\niser_conn = container_of(work, struct iser_conn, release_work);\r\nwait_for_completion(&iser_conn->stop_completion);\r\nwait_for_completion(&iser_conn->ib_completion);\r\nmutex_lock(&iser_conn->state_mutex);\r\niser_conn->state = ISER_CONN_DOWN;\r\nmutex_unlock(&iser_conn->state_mutex);\r\niser_conn_release(iser_conn);\r\n}\r\nstatic void iser_free_ib_conn_res(struct iser_conn *iser_conn,\r\nbool destroy)\r\n{\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nstruct iser_device *device = ib_conn->device;\r\niser_info("freeing conn %p cma_id %p qp %p\n",\r\niser_conn, ib_conn->cma_id, ib_conn->qp);\r\nif (ib_conn->qp != NULL) {\r\nib_conn->comp->active_qps--;\r\nrdma_destroy_qp(ib_conn->cma_id);\r\nib_conn->qp = NULL;\r\n}\r\nif (destroy) {\r\nif (iser_conn->rx_descs)\r\niser_free_rx_descriptors(iser_conn);\r\nif (device != NULL) {\r\niser_device_try_release(device);\r\nib_conn->device = NULL;\r\n}\r\n}\r\n}\r\nvoid iser_conn_release(struct iser_conn *iser_conn)\r\n{\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nmutex_lock(&ig.connlist_mutex);\r\nlist_del(&iser_conn->conn_list);\r\nmutex_unlock(&ig.connlist_mutex);\r\nmutex_lock(&iser_conn->state_mutex);\r\nif (iser_conn->state != ISER_CONN_DOWN) {\r\niser_warn("iser conn %p state %d, expected state down.\n",\r\niser_conn, iser_conn->state);\r\niscsi_destroy_endpoint(iser_conn->ep);\r\niser_conn->state = ISER_CONN_DOWN;\r\n}\r\niser_free_ib_conn_res(iser_conn, true);\r\nmutex_unlock(&iser_conn->state_mutex);\r\nif (ib_conn->cma_id != NULL) {\r\nrdma_destroy_id(ib_conn->cma_id);\r\nib_conn->cma_id = NULL;\r\n}\r\nkfree(iser_conn);\r\n}\r\nint iser_conn_terminate(struct iser_conn *iser_conn)\r\n{\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nint err = 0;\r\nif (!iser_conn_state_comp_exch(iser_conn, ISER_CONN_UP,\r\nISER_CONN_TERMINATING))\r\nreturn 0;\r\niser_info("iser_conn %p state %d\n", iser_conn, iser_conn->state);\r\nif (iser_conn->iscsi_conn)\r\niscsi_suspend_queue(iser_conn->iscsi_conn);\r\nif (ib_conn->cma_id) {\r\nerr = rdma_disconnect(ib_conn->cma_id);\r\nif (err)\r\niser_err("Failed to disconnect, conn: 0x%p err %d\n",\r\niser_conn, err);\r\nib_drain_sq(ib_conn->qp);\r\n}\r\nreturn 1;\r\n}\r\nstatic void iser_connect_error(struct rdma_cm_id *cma_id)\r\n{\r\nstruct iser_conn *iser_conn;\r\niser_conn = (struct iser_conn *)cma_id->context;\r\niser_conn->state = ISER_CONN_TERMINATING;\r\n}\r\nstatic void\r\niser_calc_scsi_params(struct iser_conn *iser_conn,\r\nunsigned int max_sectors)\r\n{\r\nstruct iser_device *device = iser_conn->ib_conn.device;\r\nunsigned short sg_tablesize, sup_sg_tablesize;\r\nsg_tablesize = DIV_ROUND_UP(max_sectors * 512, SIZE_4K);\r\nsup_sg_tablesize = min_t(unsigned, ISCSI_ISER_MAX_SG_TABLESIZE,\r\ndevice->ib_device->attrs.max_fast_reg_page_list_len);\r\nif (sg_tablesize > sup_sg_tablesize) {\r\nsg_tablesize = sup_sg_tablesize;\r\niser_conn->scsi_max_sectors = sg_tablesize * SIZE_4K / 512;\r\n} else {\r\niser_conn->scsi_max_sectors = max_sectors;\r\n}\r\niser_conn->scsi_sg_tablesize = sg_tablesize;\r\niser_dbg("iser_conn %p, sg_tablesize %u, max_sectors %u\n",\r\niser_conn, iser_conn->scsi_sg_tablesize,\r\niser_conn->scsi_max_sectors);\r\n}\r\nstatic void iser_addr_handler(struct rdma_cm_id *cma_id)\r\n{\r\nstruct iser_device *device;\r\nstruct iser_conn *iser_conn;\r\nstruct ib_conn *ib_conn;\r\nint ret;\r\niser_conn = (struct iser_conn *)cma_id->context;\r\nif (iser_conn->state != ISER_CONN_PENDING)\r\nreturn;\r\nib_conn = &iser_conn->ib_conn;\r\ndevice = iser_device_find_by_ib_device(cma_id);\r\nif (!device) {\r\niser_err("device lookup/creation failed\n");\r\niser_connect_error(cma_id);\r\nreturn;\r\n}\r\nib_conn->device = device;\r\nif (iser_pi_enable) {\r\nif (!(device->ib_device->attrs.device_cap_flags &\r\nIB_DEVICE_SIGNATURE_HANDOVER)) {\r\niser_warn("T10-PI requested but not supported on %s, "\r\n"continue without T10-PI\n",\r\nib_conn->device->ib_device->name);\r\nib_conn->pi_support = false;\r\n} else {\r\nib_conn->pi_support = true;\r\n}\r\n}\r\niser_calc_scsi_params(iser_conn, iser_max_sectors);\r\nret = rdma_resolve_route(cma_id, 1000);\r\nif (ret) {\r\niser_err("resolve route failed: %d\n", ret);\r\niser_connect_error(cma_id);\r\nreturn;\r\n}\r\n}\r\nstatic void iser_route_handler(struct rdma_cm_id *cma_id)\r\n{\r\nstruct rdma_conn_param conn_param;\r\nint ret;\r\nstruct iser_cm_hdr req_hdr;\r\nstruct iser_conn *iser_conn = (struct iser_conn *)cma_id->context;\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nstruct iser_device *device = ib_conn->device;\r\nif (iser_conn->state != ISER_CONN_PENDING)\r\nreturn;\r\nret = iser_create_ib_conn_res(ib_conn);\r\nif (ret)\r\ngoto failure;\r\nmemset(&conn_param, 0, sizeof conn_param);\r\nconn_param.responder_resources = device->ib_device->attrs.max_qp_rd_atom;\r\nconn_param.initiator_depth = 1;\r\nconn_param.retry_count = 7;\r\nconn_param.rnr_retry_count = 6;\r\nmemset(&req_hdr, 0, sizeof(req_hdr));\r\nreq_hdr.flags = ISER_ZBVA_NOT_SUP;\r\nif (!device->remote_inv_sup)\r\nreq_hdr.flags |= ISER_SEND_W_INV_NOT_SUP;\r\nconn_param.private_data = (void *)&req_hdr;\r\nconn_param.private_data_len = sizeof(struct iser_cm_hdr);\r\nret = rdma_connect(cma_id, &conn_param);\r\nif (ret) {\r\niser_err("failure connecting: %d\n", ret);\r\ngoto failure;\r\n}\r\nreturn;\r\nfailure:\r\niser_connect_error(cma_id);\r\n}\r\nstatic void iser_connected_handler(struct rdma_cm_id *cma_id,\r\nconst void *private_data)\r\n{\r\nstruct iser_conn *iser_conn;\r\nstruct ib_qp_attr attr;\r\nstruct ib_qp_init_attr init_attr;\r\niser_conn = (struct iser_conn *)cma_id->context;\r\nif (iser_conn->state != ISER_CONN_PENDING)\r\nreturn;\r\n(void)ib_query_qp(cma_id->qp, &attr, ~0, &init_attr);\r\niser_info("remote qpn:%x my qpn:%x\n", attr.dest_qp_num, cma_id->qp->qp_num);\r\nif (private_data) {\r\nu8 flags = *(u8 *)private_data;\r\niser_conn->snd_w_inv = !(flags & ISER_SEND_W_INV_NOT_SUP);\r\n}\r\niser_info("conn %p: negotiated %s invalidation\n",\r\niser_conn, iser_conn->snd_w_inv ? "remote" : "local");\r\niser_conn->state = ISER_CONN_UP;\r\ncomplete(&iser_conn->up_completion);\r\n}\r\nstatic void iser_disconnected_handler(struct rdma_cm_id *cma_id)\r\n{\r\nstruct iser_conn *iser_conn = (struct iser_conn *)cma_id->context;\r\nif (iser_conn_terminate(iser_conn)) {\r\nif (iser_conn->iscsi_conn)\r\niscsi_conn_failure(iser_conn->iscsi_conn,\r\nISCSI_ERR_CONN_FAILED);\r\nelse\r\niser_err("iscsi_iser connection isn't bound\n");\r\n}\r\n}\r\nstatic void iser_cleanup_handler(struct rdma_cm_id *cma_id,\r\nbool destroy)\r\n{\r\nstruct iser_conn *iser_conn = (struct iser_conn *)cma_id->context;\r\niser_disconnected_handler(cma_id);\r\niser_free_ib_conn_res(iser_conn, destroy);\r\ncomplete(&iser_conn->ib_completion);\r\n}\r\nstatic int iser_cma_handler(struct rdma_cm_id *cma_id, struct rdma_cm_event *event)\r\n{\r\nstruct iser_conn *iser_conn;\r\nint ret = 0;\r\niser_conn = (struct iser_conn *)cma_id->context;\r\niser_info("%s (%d): status %d conn %p id %p\n",\r\nrdma_event_msg(event->event), event->event,\r\nevent->status, cma_id->context, cma_id);\r\nmutex_lock(&iser_conn->state_mutex);\r\nswitch (event->event) {\r\ncase RDMA_CM_EVENT_ADDR_RESOLVED:\r\niser_addr_handler(cma_id);\r\nbreak;\r\ncase RDMA_CM_EVENT_ROUTE_RESOLVED:\r\niser_route_handler(cma_id);\r\nbreak;\r\ncase RDMA_CM_EVENT_ESTABLISHED:\r\niser_connected_handler(cma_id, event->param.conn.private_data);\r\nbreak;\r\ncase RDMA_CM_EVENT_ADDR_ERROR:\r\ncase RDMA_CM_EVENT_ROUTE_ERROR:\r\ncase RDMA_CM_EVENT_CONNECT_ERROR:\r\ncase RDMA_CM_EVENT_UNREACHABLE:\r\ncase RDMA_CM_EVENT_REJECTED:\r\niser_connect_error(cma_id);\r\nbreak;\r\ncase RDMA_CM_EVENT_DISCONNECTED:\r\ncase RDMA_CM_EVENT_ADDR_CHANGE:\r\ncase RDMA_CM_EVENT_TIMEWAIT_EXIT:\r\niser_cleanup_handler(cma_id, false);\r\nbreak;\r\ncase RDMA_CM_EVENT_DEVICE_REMOVAL:\r\niser_cleanup_handler(cma_id, true);\r\nif (iser_conn->state != ISER_CONN_DOWN) {\r\niser_conn->ib_conn.cma_id = NULL;\r\nret = 1;\r\n}\r\nbreak;\r\ndefault:\r\niser_err("Unexpected RDMA CM event: %s (%d)\n",\r\nrdma_event_msg(event->event), event->event);\r\nbreak;\r\n}\r\nmutex_unlock(&iser_conn->state_mutex);\r\nreturn ret;\r\n}\r\nvoid iser_conn_init(struct iser_conn *iser_conn)\r\n{\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\niser_conn->state = ISER_CONN_INIT;\r\ninit_completion(&iser_conn->stop_completion);\r\ninit_completion(&iser_conn->ib_completion);\r\ninit_completion(&iser_conn->up_completion);\r\nINIT_LIST_HEAD(&iser_conn->conn_list);\r\nmutex_init(&iser_conn->state_mutex);\r\nib_conn->post_recv_buf_count = 0;\r\nib_conn->reg_cqe.done = iser_reg_comp;\r\n}\r\nint iser_connect(struct iser_conn *iser_conn,\r\nstruct sockaddr *src_addr,\r\nstruct sockaddr *dst_addr,\r\nint non_blocking)\r\n{\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nint err = 0;\r\nmutex_lock(&iser_conn->state_mutex);\r\nsprintf(iser_conn->name, "%pISp", dst_addr);\r\niser_info("connecting to: %s\n", iser_conn->name);\r\nib_conn->device = NULL;\r\niser_conn->state = ISER_CONN_PENDING;\r\nib_conn->cma_id = rdma_create_id(&init_net, iser_cma_handler,\r\n(void *)iser_conn,\r\nRDMA_PS_TCP, IB_QPT_RC);\r\nif (IS_ERR(ib_conn->cma_id)) {\r\nerr = PTR_ERR(ib_conn->cma_id);\r\niser_err("rdma_create_id failed: %d\n", err);\r\ngoto id_failure;\r\n}\r\nerr = rdma_resolve_addr(ib_conn->cma_id, src_addr, dst_addr, 1000);\r\nif (err) {\r\niser_err("rdma_resolve_addr failed: %d\n", err);\r\ngoto addr_failure;\r\n}\r\nif (!non_blocking) {\r\nwait_for_completion_interruptible(&iser_conn->up_completion);\r\nif (iser_conn->state != ISER_CONN_UP) {\r\nerr = -EIO;\r\ngoto connect_failure;\r\n}\r\n}\r\nmutex_unlock(&iser_conn->state_mutex);\r\nmutex_lock(&ig.connlist_mutex);\r\nlist_add(&iser_conn->conn_list, &ig.connlist);\r\nmutex_unlock(&ig.connlist_mutex);\r\nreturn 0;\r\nid_failure:\r\nib_conn->cma_id = NULL;\r\naddr_failure:\r\niser_conn->state = ISER_CONN_DOWN;\r\nconnect_failure:\r\nmutex_unlock(&iser_conn->state_mutex);\r\niser_conn_release(iser_conn);\r\nreturn err;\r\n}\r\nint iser_post_recvl(struct iser_conn *iser_conn)\r\n{\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nstruct iser_login_desc *desc = &iser_conn->login_desc;\r\nstruct ib_recv_wr wr, *wr_failed;\r\nint ib_ret;\r\ndesc->sge.addr = desc->rsp_dma;\r\ndesc->sge.length = ISER_RX_LOGIN_SIZE;\r\ndesc->sge.lkey = ib_conn->device->pd->local_dma_lkey;\r\ndesc->cqe.done = iser_login_rsp;\r\nwr.wr_cqe = &desc->cqe;\r\nwr.sg_list = &desc->sge;\r\nwr.num_sge = 1;\r\nwr.next = NULL;\r\nib_conn->post_recv_buf_count++;\r\nib_ret = ib_post_recv(ib_conn->qp, &wr, &wr_failed);\r\nif (ib_ret) {\r\niser_err("ib_post_recv failed ret=%d\n", ib_ret);\r\nib_conn->post_recv_buf_count--;\r\n}\r\nreturn ib_ret;\r\n}\r\nint iser_post_recvm(struct iser_conn *iser_conn, int count)\r\n{\r\nstruct ib_conn *ib_conn = &iser_conn->ib_conn;\r\nunsigned int my_rx_head = iser_conn->rx_desc_head;\r\nstruct iser_rx_desc *rx_desc;\r\nstruct ib_recv_wr *wr, *wr_failed;\r\nint i, ib_ret;\r\nfor (wr = ib_conn->rx_wr, i = 0; i < count; i++, wr++) {\r\nrx_desc = &iser_conn->rx_descs[my_rx_head];\r\nrx_desc->cqe.done = iser_task_rsp;\r\nwr->wr_cqe = &rx_desc->cqe;\r\nwr->sg_list = &rx_desc->rx_sg;\r\nwr->num_sge = 1;\r\nwr->next = wr + 1;\r\nmy_rx_head = (my_rx_head + 1) & iser_conn->qp_max_recv_dtos_mask;\r\n}\r\nwr--;\r\nwr->next = NULL;\r\nib_conn->post_recv_buf_count += count;\r\nib_ret = ib_post_recv(ib_conn->qp, ib_conn->rx_wr, &wr_failed);\r\nif (ib_ret) {\r\niser_err("ib_post_recv failed ret=%d\n", ib_ret);\r\nib_conn->post_recv_buf_count -= count;\r\n} else\r\niser_conn->rx_desc_head = my_rx_head;\r\nreturn ib_ret;\r\n}\r\nint iser_post_send(struct ib_conn *ib_conn, struct iser_tx_desc *tx_desc,\r\nbool signal)\r\n{\r\nstruct ib_send_wr *bad_wr, *wr = iser_tx_next_wr(tx_desc);\r\nint ib_ret;\r\nib_dma_sync_single_for_device(ib_conn->device->ib_device,\r\ntx_desc->dma_addr, ISER_HEADERS_LEN,\r\nDMA_TO_DEVICE);\r\nwr->next = NULL;\r\nwr->wr_cqe = &tx_desc->cqe;\r\nwr->sg_list = tx_desc->tx_sg;\r\nwr->num_sge = tx_desc->num_sge;\r\nwr->opcode = IB_WR_SEND;\r\nwr->send_flags = signal ? IB_SEND_SIGNALED : 0;\r\nib_ret = ib_post_send(ib_conn->qp, &tx_desc->wrs[0].send, &bad_wr);\r\nif (ib_ret)\r\niser_err("ib_post_send failed, ret:%d opcode:%d\n",\r\nib_ret, bad_wr->opcode);\r\nreturn ib_ret;\r\n}\r\nu8 iser_check_task_pi_status(struct iscsi_iser_task *iser_task,\r\nenum iser_data_dir cmd_dir, sector_t *sector)\r\n{\r\nstruct iser_mem_reg *reg = &iser_task->rdma_reg[cmd_dir];\r\nstruct iser_fr_desc *desc = reg->mem_h;\r\nunsigned long sector_size = iser_task->sc->device->sector_size;\r\nstruct ib_mr_status mr_status;\r\nint ret;\r\nif (desc && desc->pi_ctx->sig_protected) {\r\ndesc->pi_ctx->sig_protected = 0;\r\nret = ib_check_mr_status(desc->pi_ctx->sig_mr,\r\nIB_MR_CHECK_SIG_STATUS, &mr_status);\r\nif (ret) {\r\npr_err("ib_check_mr_status failed, ret %d\n", ret);\r\ngoto err;\r\n}\r\nif (mr_status.fail_status & IB_MR_CHECK_SIG_STATUS) {\r\nsector_t sector_off = mr_status.sig_err.sig_err_offset;\r\nsector_div(sector_off, sector_size + 8);\r\n*sector = scsi_get_lba(iser_task->sc) + sector_off;\r\npr_err("PI error found type %d at sector %llx "\r\n"expected %x vs actual %x\n",\r\nmr_status.sig_err.err_type,\r\n(unsigned long long)*sector,\r\nmr_status.sig_err.expected,\r\nmr_status.sig_err.actual);\r\nswitch (mr_status.sig_err.err_type) {\r\ncase IB_SIG_BAD_GUARD:\r\nreturn 0x1;\r\ncase IB_SIG_BAD_REFTAG:\r\nreturn 0x3;\r\ncase IB_SIG_BAD_APPTAG:\r\nreturn 0x2;\r\n}\r\n}\r\n}\r\nreturn 0;\r\nerr:\r\nreturn 0x1;\r\n}\r\nvoid iser_err_comp(struct ib_wc *wc, const char *type)\r\n{\r\nif (wc->status != IB_WC_WR_FLUSH_ERR) {\r\nstruct iser_conn *iser_conn = to_iser_conn(wc->qp->qp_context);\r\niser_err("%s failure: %s (%d) vend_err %x\n", type,\r\nib_wc_status_msg(wc->status), wc->status,\r\nwc->vendor_err);\r\nif (iser_conn->iscsi_conn)\r\niscsi_conn_failure(iser_conn->iscsi_conn,\r\nISCSI_ERR_CONN_FAILED);\r\n} else {\r\niser_dbg("%s failure: %s (%d)\n", type,\r\nib_wc_status_msg(wc->status), wc->status);\r\n}\r\n}
