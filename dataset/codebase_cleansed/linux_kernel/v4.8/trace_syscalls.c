static struct list_head *\r\nsyscall_get_enter_fields(struct trace_event_call *call)\r\n{\r\nstruct syscall_metadata *entry = call->data;\r\nreturn &entry->enter_fields;\r\n}\r\nstatic inline bool arch_syscall_match_sym_name(const char *sym, const char *name)\r\n{\r\nreturn !strcmp(sym + 3, name + 3);\r\n}\r\nstatic int\r\ntrace_get_syscall_nr(struct task_struct *task, struct pt_regs *regs)\r\n{\r\nif (unlikely(arch_trace_is_compat_syscall(regs)))\r\nreturn -1;\r\nreturn syscall_get_nr(task, regs);\r\n}\r\nstatic inline int\r\ntrace_get_syscall_nr(struct task_struct *task, struct pt_regs *regs)\r\n{\r\nreturn syscall_get_nr(task, regs);\r\n}\r\nstruct syscall_metadata *syscall_nr_to_meta(int nr)\r\n{\r\nif (!syscalls_metadata || nr >= NR_syscalls || nr < 0)\r\nreturn NULL;\r\nreturn syscalls_metadata[nr];\r\n}\r\nconst char *get_syscall_name(int syscall)\r\n{\r\nstruct syscall_metadata *entry;\r\nentry = syscall_nr_to_meta(syscall);\r\nif (!entry)\r\nreturn NULL;\r\nreturn entry->name;\r\n}\r\nstatic enum print_line_t\r\nprint_syscall_enter(struct trace_iterator *iter, int flags,\r\nstruct trace_event *event)\r\n{\r\nstruct trace_array *tr = iter->tr;\r\nstruct trace_seq *s = &iter->seq;\r\nstruct trace_entry *ent = iter->ent;\r\nstruct syscall_trace_enter *trace;\r\nstruct syscall_metadata *entry;\r\nint i, syscall;\r\ntrace = (typeof(trace))ent;\r\nsyscall = trace->nr;\r\nentry = syscall_nr_to_meta(syscall);\r\nif (!entry)\r\ngoto end;\r\nif (entry->enter_event->event.type != ent->type) {\r\nWARN_ON_ONCE(1);\r\ngoto end;\r\n}\r\ntrace_seq_printf(s, "%s(", entry->name);\r\nfor (i = 0; i < entry->nb_args; i++) {\r\nif (trace_seq_has_overflowed(s))\r\ngoto end;\r\nif (tr->trace_flags & TRACE_ITER_VERBOSE)\r\ntrace_seq_printf(s, "%s ", entry->types[i]);\r\ntrace_seq_printf(s, "%s: %lx%s", entry->args[i],\r\ntrace->args[i],\r\ni == entry->nb_args - 1 ? "" : ", ");\r\n}\r\ntrace_seq_putc(s, ')');\r\nend:\r\ntrace_seq_putc(s, '\n');\r\nreturn trace_handle_return(s);\r\n}\r\nstatic enum print_line_t\r\nprint_syscall_exit(struct trace_iterator *iter, int flags,\r\nstruct trace_event *event)\r\n{\r\nstruct trace_seq *s = &iter->seq;\r\nstruct trace_entry *ent = iter->ent;\r\nstruct syscall_trace_exit *trace;\r\nint syscall;\r\nstruct syscall_metadata *entry;\r\ntrace = (typeof(trace))ent;\r\nsyscall = trace->nr;\r\nentry = syscall_nr_to_meta(syscall);\r\nif (!entry) {\r\ntrace_seq_putc(s, '\n');\r\ngoto out;\r\n}\r\nif (entry->exit_event->event.type != ent->type) {\r\nWARN_ON_ONCE(1);\r\nreturn TRACE_TYPE_UNHANDLED;\r\n}\r\ntrace_seq_printf(s, "%s -> 0x%lx\n", entry->name,\r\ntrace->ret);\r\nout:\r\nreturn trace_handle_return(s);\r\n}\r\nstatic int __init\r\n__set_enter_print_fmt(struct syscall_metadata *entry, char *buf, int len)\r\n{\r\nint i;\r\nint pos = 0;\r\n#define LEN_OR_ZERO (len ? len - pos : 0)\r\npos += snprintf(buf + pos, LEN_OR_ZERO, "\"");\r\nfor (i = 0; i < entry->nb_args; i++) {\r\npos += snprintf(buf + pos, LEN_OR_ZERO, "%s: 0x%%0%zulx%s",\r\nentry->args[i], sizeof(unsigned long),\r\ni == entry->nb_args - 1 ? "" : ", ");\r\n}\r\npos += snprintf(buf + pos, LEN_OR_ZERO, "\"");\r\nfor (i = 0; i < entry->nb_args; i++) {\r\npos += snprintf(buf + pos, LEN_OR_ZERO,\r\n", ((unsigned long)(REC->%s))", entry->args[i]);\r\n}\r\n#undef LEN_OR_ZERO\r\nreturn pos;\r\n}\r\nstatic int __init set_syscall_print_fmt(struct trace_event_call *call)\r\n{\r\nchar *print_fmt;\r\nint len;\r\nstruct syscall_metadata *entry = call->data;\r\nif (entry->enter_event != call) {\r\ncall->print_fmt = "\"0x%lx\", REC->ret";\r\nreturn 0;\r\n}\r\nlen = __set_enter_print_fmt(entry, NULL, 0);\r\nprint_fmt = kmalloc(len + 1, GFP_KERNEL);\r\nif (!print_fmt)\r\nreturn -ENOMEM;\r\n__set_enter_print_fmt(entry, print_fmt, len + 1);\r\ncall->print_fmt = print_fmt;\r\nreturn 0;\r\n}\r\nstatic void __init free_syscall_print_fmt(struct trace_event_call *call)\r\n{\r\nstruct syscall_metadata *entry = call->data;\r\nif (entry->enter_event == call)\r\nkfree(call->print_fmt);\r\n}\r\nstatic int __init syscall_enter_define_fields(struct trace_event_call *call)\r\n{\r\nstruct syscall_trace_enter trace;\r\nstruct syscall_metadata *meta = call->data;\r\nint ret;\r\nint i;\r\nint offset = offsetof(typeof(trace), args);\r\nret = trace_define_field(call, SYSCALL_FIELD(int, nr, __syscall_nr),\r\nFILTER_OTHER);\r\nif (ret)\r\nreturn ret;\r\nfor (i = 0; i < meta->nb_args; i++) {\r\nret = trace_define_field(call, meta->types[i],\r\nmeta->args[i], offset,\r\nsizeof(unsigned long), 0,\r\nFILTER_OTHER);\r\noffset += sizeof(unsigned long);\r\n}\r\nreturn ret;\r\n}\r\nstatic int __init syscall_exit_define_fields(struct trace_event_call *call)\r\n{\r\nstruct syscall_trace_exit trace;\r\nint ret;\r\nret = trace_define_field(call, SYSCALL_FIELD(int, nr, __syscall_nr),\r\nFILTER_OTHER);\r\nif (ret)\r\nreturn ret;\r\nret = trace_define_field(call, SYSCALL_FIELD(long, ret, ret),\r\nFILTER_OTHER);\r\nreturn ret;\r\n}\r\nstatic void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)\r\n{\r\nstruct trace_array *tr = data;\r\nstruct trace_event_file *trace_file;\r\nstruct syscall_trace_enter *entry;\r\nstruct syscall_metadata *sys_data;\r\nstruct ring_buffer_event *event;\r\nstruct ring_buffer *buffer;\r\nunsigned long irq_flags;\r\nint pc;\r\nint syscall_nr;\r\nint size;\r\nsyscall_nr = trace_get_syscall_nr(current, regs);\r\nif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\r\nreturn;\r\ntrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);\r\nif (!trace_file)\r\nreturn;\r\nif (trace_trigger_soft_disabled(trace_file))\r\nreturn;\r\nsys_data = syscall_nr_to_meta(syscall_nr);\r\nif (!sys_data)\r\nreturn;\r\nsize = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;\r\nlocal_save_flags(irq_flags);\r\npc = preempt_count();\r\nbuffer = tr->trace_buffer.buffer;\r\nevent = trace_buffer_lock_reserve(buffer,\r\nsys_data->enter_event->event.type, size, irq_flags, pc);\r\nif (!event)\r\nreturn;\r\nentry = ring_buffer_event_data(event);\r\nentry->nr = syscall_nr;\r\nsyscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);\r\nevent_trigger_unlock_commit(trace_file, buffer, event, entry,\r\nirq_flags, pc);\r\n}\r\nstatic void ftrace_syscall_exit(void *data, struct pt_regs *regs, long ret)\r\n{\r\nstruct trace_array *tr = data;\r\nstruct trace_event_file *trace_file;\r\nstruct syscall_trace_exit *entry;\r\nstruct syscall_metadata *sys_data;\r\nstruct ring_buffer_event *event;\r\nstruct ring_buffer *buffer;\r\nunsigned long irq_flags;\r\nint pc;\r\nint syscall_nr;\r\nsyscall_nr = trace_get_syscall_nr(current, regs);\r\nif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\r\nreturn;\r\ntrace_file = rcu_dereference_sched(tr->exit_syscall_files[syscall_nr]);\r\nif (!trace_file)\r\nreturn;\r\nif (trace_trigger_soft_disabled(trace_file))\r\nreturn;\r\nsys_data = syscall_nr_to_meta(syscall_nr);\r\nif (!sys_data)\r\nreturn;\r\nlocal_save_flags(irq_flags);\r\npc = preempt_count();\r\nbuffer = tr->trace_buffer.buffer;\r\nevent = trace_buffer_lock_reserve(buffer,\r\nsys_data->exit_event->event.type, sizeof(*entry),\r\nirq_flags, pc);\r\nif (!event)\r\nreturn;\r\nentry = ring_buffer_event_data(event);\r\nentry->nr = syscall_nr;\r\nentry->ret = syscall_get_return_value(current, regs);\r\nevent_trigger_unlock_commit(trace_file, buffer, event, entry,\r\nirq_flags, pc);\r\n}\r\nstatic int reg_event_syscall_enter(struct trace_event_file *file,\r\nstruct trace_event_call *call)\r\n{\r\nstruct trace_array *tr = file->tr;\r\nint ret = 0;\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\r\nreturn -ENOSYS;\r\nmutex_lock(&syscall_trace_lock);\r\nif (!tr->sys_refcount_enter)\r\nret = register_trace_sys_enter(ftrace_syscall_enter, tr);\r\nif (!ret) {\r\nrcu_assign_pointer(tr->enter_syscall_files[num], file);\r\ntr->sys_refcount_enter++;\r\n}\r\nmutex_unlock(&syscall_trace_lock);\r\nreturn ret;\r\n}\r\nstatic void unreg_event_syscall_enter(struct trace_event_file *file,\r\nstruct trace_event_call *call)\r\n{\r\nstruct trace_array *tr = file->tr;\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\r\nreturn;\r\nmutex_lock(&syscall_trace_lock);\r\ntr->sys_refcount_enter--;\r\nRCU_INIT_POINTER(tr->enter_syscall_files[num], NULL);\r\nif (!tr->sys_refcount_enter)\r\nunregister_trace_sys_enter(ftrace_syscall_enter, tr);\r\nmutex_unlock(&syscall_trace_lock);\r\n}\r\nstatic int reg_event_syscall_exit(struct trace_event_file *file,\r\nstruct trace_event_call *call)\r\n{\r\nstruct trace_array *tr = file->tr;\r\nint ret = 0;\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\r\nreturn -ENOSYS;\r\nmutex_lock(&syscall_trace_lock);\r\nif (!tr->sys_refcount_exit)\r\nret = register_trace_sys_exit(ftrace_syscall_exit, tr);\r\nif (!ret) {\r\nrcu_assign_pointer(tr->exit_syscall_files[num], file);\r\ntr->sys_refcount_exit++;\r\n}\r\nmutex_unlock(&syscall_trace_lock);\r\nreturn ret;\r\n}\r\nstatic void unreg_event_syscall_exit(struct trace_event_file *file,\r\nstruct trace_event_call *call)\r\n{\r\nstruct trace_array *tr = file->tr;\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\r\nreturn;\r\nmutex_lock(&syscall_trace_lock);\r\ntr->sys_refcount_exit--;\r\nRCU_INIT_POINTER(tr->exit_syscall_files[num], NULL);\r\nif (!tr->sys_refcount_exit)\r\nunregister_trace_sys_exit(ftrace_syscall_exit, tr);\r\nmutex_unlock(&syscall_trace_lock);\r\n}\r\nstatic int __init init_syscall_trace(struct trace_event_call *call)\r\n{\r\nint id;\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nif (num < 0 || num >= NR_syscalls) {\r\npr_debug("syscall %s metadata not mapped, disabling ftrace event\n",\r\n((struct syscall_metadata *)call->data)->name);\r\nreturn -ENOSYS;\r\n}\r\nif (set_syscall_print_fmt(call) < 0)\r\nreturn -ENOMEM;\r\nid = trace_event_raw_init(call);\r\nif (id < 0) {\r\nfree_syscall_print_fmt(call);\r\nreturn id;\r\n}\r\nreturn id;\r\n}\r\nunsigned long __init __weak arch_syscall_addr(int nr)\r\n{\r\nreturn (unsigned long)sys_call_table[nr];\r\n}\r\nvoid __init init_ftrace_syscalls(void)\r\n{\r\nstruct syscall_metadata *meta;\r\nunsigned long addr;\r\nint i;\r\nsyscalls_metadata = kcalloc(NR_syscalls, sizeof(*syscalls_metadata),\r\nGFP_KERNEL);\r\nif (!syscalls_metadata) {\r\nWARN_ON(1);\r\nreturn;\r\n}\r\nfor (i = 0; i < NR_syscalls; i++) {\r\naddr = arch_syscall_addr(i);\r\nmeta = find_syscall_meta(addr);\r\nif (!meta)\r\ncontinue;\r\nmeta->syscall_nr = i;\r\nsyscalls_metadata[i] = meta;\r\n}\r\n}\r\nstatic void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\r\n{\r\nstruct syscall_metadata *sys_data;\r\nstruct syscall_trace_enter *rec;\r\nstruct hlist_head *head;\r\nint syscall_nr;\r\nint rctx;\r\nint size;\r\nsyscall_nr = trace_get_syscall_nr(current, regs);\r\nif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\r\nreturn;\r\nif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\r\nreturn;\r\nsys_data = syscall_nr_to_meta(syscall_nr);\r\nif (!sys_data)\r\nreturn;\r\nhead = this_cpu_ptr(sys_data->enter_event->perf_events);\r\nif (hlist_empty(head))\r\nreturn;\r\nsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\r\nsize = ALIGN(size + sizeof(u32), sizeof(u64));\r\nsize -= sizeof(u32);\r\nrec = perf_trace_buf_alloc(size, NULL, &rctx);\r\nif (!rec)\r\nreturn;\r\nrec->nr = syscall_nr;\r\nsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\r\n(unsigned long *)&rec->args);\r\nperf_trace_buf_submit(rec, size, rctx,\r\nsys_data->enter_event->event.type, 1, regs,\r\nhead, NULL);\r\n}\r\nstatic int perf_sysenter_enable(struct trace_event_call *call)\r\n{\r\nint ret = 0;\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nmutex_lock(&syscall_trace_lock);\r\nif (!sys_perf_refcount_enter)\r\nret = register_trace_sys_enter(perf_syscall_enter, NULL);\r\nif (ret) {\r\npr_info("event trace: Could not activate"\r\n"syscall entry trace point");\r\n} else {\r\nset_bit(num, enabled_perf_enter_syscalls);\r\nsys_perf_refcount_enter++;\r\n}\r\nmutex_unlock(&syscall_trace_lock);\r\nreturn ret;\r\n}\r\nstatic void perf_sysenter_disable(struct trace_event_call *call)\r\n{\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nmutex_lock(&syscall_trace_lock);\r\nsys_perf_refcount_enter--;\r\nclear_bit(num, enabled_perf_enter_syscalls);\r\nif (!sys_perf_refcount_enter)\r\nunregister_trace_sys_enter(perf_syscall_enter, NULL);\r\nmutex_unlock(&syscall_trace_lock);\r\n}\r\nstatic void perf_syscall_exit(void *ignore, struct pt_regs *regs, long ret)\r\n{\r\nstruct syscall_metadata *sys_data;\r\nstruct syscall_trace_exit *rec;\r\nstruct hlist_head *head;\r\nint syscall_nr;\r\nint rctx;\r\nint size;\r\nsyscall_nr = trace_get_syscall_nr(current, regs);\r\nif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\r\nreturn;\r\nif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\r\nreturn;\r\nsys_data = syscall_nr_to_meta(syscall_nr);\r\nif (!sys_data)\r\nreturn;\r\nhead = this_cpu_ptr(sys_data->exit_event->perf_events);\r\nif (hlist_empty(head))\r\nreturn;\r\nsize = ALIGN(sizeof(*rec) + sizeof(u32), sizeof(u64));\r\nsize -= sizeof(u32);\r\nrec = perf_trace_buf_alloc(size, NULL, &rctx);\r\nif (!rec)\r\nreturn;\r\nrec->nr = syscall_nr;\r\nrec->ret = syscall_get_return_value(current, regs);\r\nperf_trace_buf_submit(rec, size, rctx, sys_data->exit_event->event.type,\r\n1, regs, head, NULL);\r\n}\r\nstatic int perf_sysexit_enable(struct trace_event_call *call)\r\n{\r\nint ret = 0;\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nmutex_lock(&syscall_trace_lock);\r\nif (!sys_perf_refcount_exit)\r\nret = register_trace_sys_exit(perf_syscall_exit, NULL);\r\nif (ret) {\r\npr_info("event trace: Could not activate"\r\n"syscall exit trace point");\r\n} else {\r\nset_bit(num, enabled_perf_exit_syscalls);\r\nsys_perf_refcount_exit++;\r\n}\r\nmutex_unlock(&syscall_trace_lock);\r\nreturn ret;\r\n}\r\nstatic void perf_sysexit_disable(struct trace_event_call *call)\r\n{\r\nint num;\r\nnum = ((struct syscall_metadata *)call->data)->syscall_nr;\r\nmutex_lock(&syscall_trace_lock);\r\nsys_perf_refcount_exit--;\r\nclear_bit(num, enabled_perf_exit_syscalls);\r\nif (!sys_perf_refcount_exit)\r\nunregister_trace_sys_exit(perf_syscall_exit, NULL);\r\nmutex_unlock(&syscall_trace_lock);\r\n}\r\nstatic int syscall_enter_register(struct trace_event_call *event,\r\nenum trace_reg type, void *data)\r\n{\r\nstruct trace_event_file *file = data;\r\nswitch (type) {\r\ncase TRACE_REG_REGISTER:\r\nreturn reg_event_syscall_enter(file, event);\r\ncase TRACE_REG_UNREGISTER:\r\nunreg_event_syscall_enter(file, event);\r\nreturn 0;\r\n#ifdef CONFIG_PERF_EVENTS\r\ncase TRACE_REG_PERF_REGISTER:\r\nreturn perf_sysenter_enable(event);\r\ncase TRACE_REG_PERF_UNREGISTER:\r\nperf_sysenter_disable(event);\r\nreturn 0;\r\ncase TRACE_REG_PERF_OPEN:\r\ncase TRACE_REG_PERF_CLOSE:\r\ncase TRACE_REG_PERF_ADD:\r\ncase TRACE_REG_PERF_DEL:\r\nreturn 0;\r\n#endif\r\n}\r\nreturn 0;\r\n}\r\nstatic int syscall_exit_register(struct trace_event_call *event,\r\nenum trace_reg type, void *data)\r\n{\r\nstruct trace_event_file *file = data;\r\nswitch (type) {\r\ncase TRACE_REG_REGISTER:\r\nreturn reg_event_syscall_exit(file, event);\r\ncase TRACE_REG_UNREGISTER:\r\nunreg_event_syscall_exit(file, event);\r\nreturn 0;\r\n#ifdef CONFIG_PERF_EVENTS\r\ncase TRACE_REG_PERF_REGISTER:\r\nreturn perf_sysexit_enable(event);\r\ncase TRACE_REG_PERF_UNREGISTER:\r\nperf_sysexit_disable(event);\r\nreturn 0;\r\ncase TRACE_REG_PERF_OPEN:\r\ncase TRACE_REG_PERF_CLOSE:\r\ncase TRACE_REG_PERF_ADD:\r\ncase TRACE_REG_PERF_DEL:\r\nreturn 0;\r\n#endif\r\n}\r\nreturn 0;\r\n}
