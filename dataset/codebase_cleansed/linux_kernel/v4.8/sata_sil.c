static void sil_bmdma_stop(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nvoid __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];\r\nvoid __iomem *bmdma2 = mmio_base + sil_port[ap->port_no].bmdma2;\r\niowrite8(0, bmdma2);\r\nata_sff_dma_pause(ap);\r\n}\r\nstatic void sil_bmdma_setup(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nvoid __iomem *bmdma = ap->ioaddr.bmdma_addr;\r\niowrite32(ap->bmdma_prd_dma, bmdma + ATA_DMA_TABLE_OFS);\r\nap->ops->sff_exec_command(ap, &qc->tf);\r\n}\r\nstatic void sil_bmdma_start(struct ata_queued_cmd *qc)\r\n{\r\nunsigned int rw = (qc->tf.flags & ATA_TFLAG_WRITE);\r\nstruct ata_port *ap = qc->ap;\r\nvoid __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];\r\nvoid __iomem *bmdma2 = mmio_base + sil_port[ap->port_no].bmdma2;\r\nu8 dmactl = ATA_DMA_START;\r\nif (!rw)\r\ndmactl |= ATA_DMA_WR;\r\niowrite8(dmactl, bmdma2);\r\n}\r\nstatic void sil_fill_sg(struct ata_queued_cmd *qc)\r\n{\r\nstruct scatterlist *sg;\r\nstruct ata_port *ap = qc->ap;\r\nstruct ata_bmdma_prd *prd, *last_prd = NULL;\r\nunsigned int si;\r\nprd = &ap->bmdma_prd[0];\r\nfor_each_sg(qc->sg, sg, qc->n_elem, si) {\r\nu32 addr = (u32) sg_dma_address(sg);\r\nu32 sg_len = sg_dma_len(sg);\r\nprd->addr = cpu_to_le32(addr);\r\nprd->flags_len = cpu_to_le32(sg_len);\r\nVPRINTK("PRD[%u] = (0x%X, 0x%X)\n", si, addr, sg_len);\r\nlast_prd = prd;\r\nprd++;\r\n}\r\nif (likely(last_prd))\r\nlast_prd->flags_len |= cpu_to_le32(ATA_PRD_EOT);\r\n}\r\nstatic void sil_qc_prep(struct ata_queued_cmd *qc)\r\n{\r\nif (!(qc->flags & ATA_QCFLAG_DMAMAP))\r\nreturn;\r\nsil_fill_sg(qc);\r\n}\r\nstatic unsigned char sil_get_device_cache_line(struct pci_dev *pdev)\r\n{\r\nu8 cache_line = 0;\r\npci_read_config_byte(pdev, PCI_CACHE_LINE_SIZE, &cache_line);\r\nreturn cache_line;\r\n}\r\nstatic int sil_set_mode(struct ata_link *link, struct ata_device **r_failed)\r\n{\r\nstruct ata_port *ap = link->ap;\r\nvoid __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];\r\nvoid __iomem *addr = mmio_base + sil_port[ap->port_no].xfer_mode;\r\nstruct ata_device *dev;\r\nu32 tmp, dev_mode[2] = { };\r\nint rc;\r\nrc = ata_do_set_mode(link, r_failed);\r\nif (rc)\r\nreturn rc;\r\nata_for_each_dev(dev, link, ALL) {\r\nif (!ata_dev_enabled(dev))\r\ndev_mode[dev->devno] = 0;\r\nelse if (dev->flags & ATA_DFLAG_PIO)\r\ndev_mode[dev->devno] = 1;\r\nelse\r\ndev_mode[dev->devno] = 3;\r\n}\r\ntmp = readl(addr);\r\ntmp &= ~((1<<5) | (1<<4) | (1<<1) | (1<<0));\r\ntmp |= dev_mode[0];\r\ntmp |= (dev_mode[1] << 4);\r\nwritel(tmp, addr);\r\nreadl(addr);\r\nreturn 0;\r\n}\r\nstatic inline void __iomem *sil_scr_addr(struct ata_port *ap,\r\nunsigned int sc_reg)\r\n{\r\nvoid __iomem *offset = ap->ioaddr.scr_addr;\r\nswitch (sc_reg) {\r\ncase SCR_STATUS:\r\nreturn offset + 4;\r\ncase SCR_ERROR:\r\nreturn offset + 8;\r\ncase SCR_CONTROL:\r\nreturn offset;\r\ndefault:\r\nbreak;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int sil_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)\r\n{\r\nvoid __iomem *mmio = sil_scr_addr(link->ap, sc_reg);\r\nif (mmio) {\r\n*val = readl(mmio);\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int sil_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)\r\n{\r\nvoid __iomem *mmio = sil_scr_addr(link->ap, sc_reg);\r\nif (mmio) {\r\nwritel(val, mmio);\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic void sil_host_intr(struct ata_port *ap, u32 bmdma2)\r\n{\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nstruct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);\r\nu8 status;\r\nif (unlikely(bmdma2 & SIL_DMA_SATA_IRQ)) {\r\nu32 serror = 0xffffffff;\r\nsil_scr_read(&ap->link, SCR_ERROR, &serror);\r\nsil_scr_write(&ap->link, SCR_ERROR, serror);\r\nif (serror & SERR_PHYRDY_CHG) {\r\nap->link.eh_info.serror |= serror;\r\ngoto freeze;\r\n}\r\nif (!(bmdma2 & SIL_DMA_COMPLETE))\r\nreturn;\r\n}\r\nif (unlikely(!qc || (qc->tf.flags & ATA_TFLAG_POLLING))) {\r\nap->ops->sff_check_status(ap);\r\nreturn;\r\n}\r\nswitch (ap->hsm_task_state) {\r\ncase HSM_ST_FIRST:\r\nif (!(qc->dev->flags & ATA_DFLAG_CDB_INTR))\r\ngoto err_hsm;\r\nbreak;\r\ncase HSM_ST_LAST:\r\nif (ata_is_dma(qc->tf.protocol)) {\r\nap->ops->bmdma_stop(qc);\r\nif (bmdma2 & SIL_DMA_ERROR) {\r\nqc->err_mask |= AC_ERR_HOST_BUS;\r\nap->hsm_task_state = HSM_ST_ERR;\r\n}\r\n}\r\nbreak;\r\ncase HSM_ST:\r\nbreak;\r\ndefault:\r\ngoto err_hsm;\r\n}\r\nstatus = ap->ops->sff_check_status(ap);\r\nif (unlikely(status & ATA_BUSY))\r\ngoto err_hsm;\r\nata_bmdma_irq_clear(ap);\r\nata_sff_hsm_move(ap, qc, status, 0);\r\nif (unlikely(qc->err_mask) && ata_is_dma(qc->tf.protocol))\r\nata_ehi_push_desc(ehi, "BMDMA2 stat 0x%x", bmdma2);\r\nreturn;\r\nerr_hsm:\r\nqc->err_mask |= AC_ERR_HSM;\r\nfreeze:\r\nata_port_freeze(ap);\r\n}\r\nstatic irqreturn_t sil_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nvoid __iomem *mmio_base = host->iomap[SIL_MMIO_BAR];\r\nint handled = 0;\r\nint i;\r\nspin_lock(&host->lock);\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nu32 bmdma2 = readl(mmio_base + sil_port[ap->port_no].bmdma2);\r\nif (ap->flags & SIL_FLAG_NO_SATA_IRQ)\r\nbmdma2 &= ~SIL_DMA_SATA_IRQ;\r\nif (bmdma2 == 0xffffffff ||\r\n!(bmdma2 & (SIL_DMA_COMPLETE | SIL_DMA_SATA_IRQ)))\r\ncontinue;\r\nsil_host_intr(ap, bmdma2);\r\nhandled = 1;\r\n}\r\nspin_unlock(&host->lock);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic void sil_freeze(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];\r\nu32 tmp;\r\nwritel(0, mmio_base + sil_port[ap->port_no].sien);\r\ntmp = readl(mmio_base + SIL_SYSCFG);\r\ntmp |= SIL_MASK_IDE0_INT << ap->port_no;\r\nwritel(tmp, mmio_base + SIL_SYSCFG);\r\nreadl(mmio_base + SIL_SYSCFG);\r\niowrite8(ioread8(ap->ioaddr.bmdma_addr) & ~SIL_DMA_ENABLE,\r\nap->ioaddr.bmdma_addr);\r\nioread8(ap->ioaddr.bmdma_addr);\r\n}\r\nstatic void sil_thaw(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio_base = ap->host->iomap[SIL_MMIO_BAR];\r\nu32 tmp;\r\nap->ops->sff_check_status(ap);\r\nata_bmdma_irq_clear(ap);\r\nif (!(ap->flags & SIL_FLAG_NO_SATA_IRQ))\r\nwritel(SIL_SIEN_N, mmio_base + sil_port[ap->port_no].sien);\r\ntmp = readl(mmio_base + SIL_SYSCFG);\r\ntmp &= ~(SIL_MASK_IDE0_INT << ap->port_no);\r\nwritel(tmp, mmio_base + SIL_SYSCFG);\r\n}\r\nstatic void sil_dev_config(struct ata_device *dev)\r\n{\r\nstruct ata_port *ap = dev->link->ap;\r\nint print_info = ap->link.eh_context.i.flags & ATA_EHI_PRINTINFO;\r\nunsigned int n, quirks = 0;\r\nunsigned char model_num[ATA_ID_PROD_LEN + 1];\r\ndev->horkage |= ATA_HORKAGE_NOTRIM;\r\nata_id_c_string(dev->id, model_num, ATA_ID_PROD, sizeof(model_num));\r\nfor (n = 0; sil_blacklist[n].product; n++)\r\nif (!strcmp(sil_blacklist[n].product, model_num)) {\r\nquirks = sil_blacklist[n].quirk;\r\nbreak;\r\n}\r\nif (slow_down ||\r\n((ap->flags & SIL_FLAG_MOD15WRITE) &&\r\n(quirks & SIL_QUIRK_MOD15WRITE))) {\r\nif (print_info)\r\nata_dev_info(dev,\r\n"applying Seagate errata fix (mod15write workaround)\n");\r\ndev->max_sectors = 15;\r\nreturn;\r\n}\r\nif (quirks & SIL_QUIRK_UDMA5MAX) {\r\nif (print_info)\r\nata_dev_info(dev, "applying Maxtor errata fix %s\n",\r\nmodel_num);\r\ndev->udma_mask &= ATA_UDMA5;\r\nreturn;\r\n}\r\n}\r\nstatic void sil_init_controller(struct ata_host *host)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(host->dev);\r\nvoid __iomem *mmio_base = host->iomap[SIL_MMIO_BAR];\r\nu8 cls;\r\nu32 tmp;\r\nint i;\r\ncls = sil_get_device_cache_line(pdev);\r\nif (cls) {\r\ncls >>= 3;\r\ncls++;\r\nfor (i = 0; i < host->n_ports; i++)\r\nwritew(cls << 8 | cls,\r\nmmio_base + sil_port[i].fifo_cfg);\r\n} else\r\ndev_warn(&pdev->dev,\r\n"cache line size not set. Driver may not function\n");\r\nif (host->ports[0]->flags & SIL_FLAG_RERR_ON_DMA_ACT) {\r\nint cnt;\r\nfor (i = 0, cnt = 0; i < host->n_ports; i++) {\r\ntmp = readl(mmio_base + sil_port[i].sfis_cfg);\r\nif ((tmp & 0x3) != 0x01)\r\ncontinue;\r\nif (!cnt)\r\ndev_info(&pdev->dev,\r\n"Applying R_ERR on DMA activate FIS errata fix\n");\r\nwritel(tmp & ~0x3, mmio_base + sil_port[i].sfis_cfg);\r\ncnt++;\r\n}\r\n}\r\nif (host->n_ports == 4) {\r\ntmp = readl(mmio_base + sil_port[2].bmdma);\r\nif ((tmp & SIL_INTR_STEERING) == 0)\r\nwritel(tmp | SIL_INTR_STEERING,\r\nmmio_base + sil_port[2].bmdma);\r\n}\r\n}\r\nstatic bool sil_broken_system_poweroff(struct pci_dev *pdev)\r\n{\r\nstatic const struct dmi_system_id broken_systems[] = {\r\n{\r\n.ident = "HP Compaq nx6325",\r\n.matches = {\r\nDMI_MATCH(DMI_SYS_VENDOR, "Hewlett-Packard"),\r\nDMI_MATCH(DMI_PRODUCT_NAME, "HP Compaq nx6325"),\r\n},\r\n.driver_data = (void *)0x12UL,\r\n},\r\n{ }\r\n};\r\nconst struct dmi_system_id *dmi = dmi_first_match(broken_systems);\r\nif (dmi) {\r\nunsigned long slot = (unsigned long)dmi->driver_data;\r\nreturn slot == PCI_SLOT(pdev->devfn);\r\n}\r\nreturn false;\r\n}\r\nstatic int sil_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint board_id = ent->driver_data;\r\nstruct ata_port_info pi = sil_port_info[board_id];\r\nconst struct ata_port_info *ppi[] = { &pi, NULL };\r\nstruct ata_host *host;\r\nvoid __iomem *mmio_base;\r\nint n_ports, rc;\r\nunsigned int i;\r\nata_print_version_once(&pdev->dev, DRV_VERSION);\r\nn_ports = 2;\r\nif (board_id == sil_3114)\r\nn_ports = 4;\r\nif (sil_broken_system_poweroff(pdev)) {\r\npi.flags |= ATA_FLAG_NO_POWEROFF_SPINDOWN |\r\nATA_FLAG_NO_HIBERNATE_SPINDOWN;\r\ndev_info(&pdev->dev, "quirky BIOS, skipping spindown "\r\n"on poweroff and hibernation\n");\r\n}\r\nhost = ata_host_alloc_pinfo(&pdev->dev, ppi, n_ports);\r\nif (!host)\r\nreturn -ENOMEM;\r\nrc = pcim_enable_device(pdev);\r\nif (rc)\r\nreturn rc;\r\nrc = pcim_iomap_regions(pdev, 1 << SIL_MMIO_BAR, DRV_NAME);\r\nif (rc == -EBUSY)\r\npcim_pin_device(pdev);\r\nif (rc)\r\nreturn rc;\r\nhost->iomap = pcim_iomap_table(pdev);\r\nrc = dma_set_mask(&pdev->dev, ATA_DMA_MASK);\r\nif (rc)\r\nreturn rc;\r\nrc = dma_set_coherent_mask(&pdev->dev, ATA_DMA_MASK);\r\nif (rc)\r\nreturn rc;\r\nmmio_base = host->iomap[SIL_MMIO_BAR];\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nstruct ata_ioports *ioaddr = &ap->ioaddr;\r\nioaddr->cmd_addr = mmio_base + sil_port[i].tf;\r\nioaddr->altstatus_addr =\r\nioaddr->ctl_addr = mmio_base + sil_port[i].ctl;\r\nioaddr->bmdma_addr = mmio_base + sil_port[i].bmdma;\r\nioaddr->scr_addr = mmio_base + sil_port[i].scr;\r\nata_sff_std_ports(ioaddr);\r\nata_port_pbar_desc(ap, SIL_MMIO_BAR, -1, "mmio");\r\nata_port_pbar_desc(ap, SIL_MMIO_BAR, sil_port[i].tf, "tf");\r\n}\r\nsil_init_controller(host);\r\npci_set_master(pdev);\r\nreturn ata_host_activate(host, pdev->irq, sil_interrupt, IRQF_SHARED,\r\n&sil_sht);\r\n}\r\nstatic int sil_pci_device_resume(struct pci_dev *pdev)\r\n{\r\nstruct ata_host *host = pci_get_drvdata(pdev);\r\nint rc;\r\nrc = ata_pci_device_do_resume(pdev);\r\nif (rc)\r\nreturn rc;\r\nsil_init_controller(host);\r\nata_host_resume(host);\r\nreturn 0;\r\n}
